Journal Artificial Intelligence Research 39 (2010) 633-662

Submitted 05/10; published 11/10

Utility-Theoretic Approach Privacy Online Services
Andreas Krause

KRAUSEA @ CALTECH . EDU

California Institute Technology,
1200 E California Blvd.,
Pasadena, CA 91125, USA

Eric Horvitz

HORVITZ @ MICROSOFT. COM

Microsoft Research,
One Microsoft Way,
Redmond, WA 98052-6399, USA

Abstract
Online offerings web search, news portals, e-commerce applications face challenge providing high-quality service large, heterogeneous user base. Recent efforts
highlighted potential improve performance introducing methods personalize services
based special knowledge users context. example, users demographics,
location, past search browsing may useful enhancing results offered response
web search queries. However, reasonable concerns privacy users, providers,
government agencies acting behalf citizens, may limit access services information. introduce explore economics privacy personalization, people opt
share personal information, standing on-demand manner, return expected enhancements quality online service. focus example web search formulate
realistic objective functions search efficacy privacy. demonstrate find
provably near-optimal optimization utility-privacy tradeoff efficient manner. evaluate methodology data drawn log search activity volunteer participants.
separately assess users preferences privacy utility via large-scale survey, aimed
eliciting preferences peoples willingness trade sharing personal data returns
gains search efficiency. show significant level personalization achieved using
relatively small amount information users.

1. Introduction
Information preferences, activities, demographic attributes people using online
applications leveraged personalize services individuals groups users.
example, knowledge current locations users performing web searches help identify
informational goals. Researchers organizations pursued explicit implicit methods
personalizing online services. web search, explicit personalization methods rely users
indicating sets topics interest stored server client. Implicit methods make use
information collected absence user effort awareness. Data collected implicitly
web search include users locations search activities, capturing information
people specify reformulate queries click, dwell, navigate results. Beyond web
search, data collected users implicit manner used custom-tailor behaviors
broad spectrum online applications informational services like news summarizers

c
2010
AI Access Foundation. rights reserved.

fiK RAUSE & H ORVITZ

e-commerce services provide access online shopping, seek maximize sales
targeted advertising.
potential value harnessing data people enhance online services coupled
growing ubiquity online services raises reasonable concerns privacy. users
hosts online applications may benefit custom-tailoring services. However,
may uncomfortable access use personal information. increasing
discussion incursions privacy users implied general logging storing
online data (Adar, 2007). Beyond general anxieties sharing personal information, people may
specifically concerns becoming increasingly identifiable; increasing amounts
personal data acquired, users become members increasingly smaller groups people
associated attributes.
work date personalizing online services either ignored challenges privacy
focused efforts solely maximizing utility (c.f., Sugiyama, Hatano, & Ikoma, 2004)
completely bypassed use personal data. One vein research explored feasibility
personalizing services methods restrict collection analysis personal data
users computing devices (Horvitz, 2006). Research realm includes efforts personalize
web search making use content stored local machines, captured within index
desktop search service (Teevan, Dumais, & Horvitz, 2005; Xu, Zhang, & Wang, 2007). Rather
cut opportunities make personal data available enhancing online services limit personalization client-side analyses, introduce study utility-theoretic methods balance
costs sharing personal data online services return benefits personalization. decision-theoretic perspective privacy allow systems weigh benefits
enhancements come adaptation costs sensing storage according users
preferences.
characterize utility sharing attributes private data via value-of-information analyses
take consideration preferences users sharing personal information.
explicitly quantify preferences utility privacy solve optimization problem
find best trade. approach based two fundamental observations. first that,
practical applications, utility gained sharing personal data may often diminishing
returns property; acquiring information user adds decreasing amounts utility
personalization given already known users needs intentions. contrary,
information acquired user, concerning breach privacy becomes.
example, set individually non-identifying pieces information may, combined,
hone user membership small group, even identify individual. map
properties diminishing returns utility concomitant accelerating costs revelation
combinatorial concepts submodularity supermodularity, respectively.
Although economic perspective privacy relevant wide spectrum applications,
studies foundations privacy broadly, shall illustrate concepts application personalizing web search. employ probabilistic model predict web page
searcher going visit given search query attributes describing user. define
utility set personal attributes focusing power information gained respect prediction task. Similarly, use probabilistic model quantify risk
identifying users given set personal attributes. combine utility cost functions
single objective function, use find small set attributes maximally
increases likelihood predicting target website, making identification user
634

fiA U TILITY-T HEORETIC PPROACH P RIVACY NLINE ERVICES

difficult possible. challenges optimization identifying benefits costs
sharing information grappling computational hardness analysis. Solving
best set attributes users reveal (and hence optimal setting utility-privacy
tradeoff) NP-hard search problem, thus intractable general large sets attributes.
shall demonstrate use submodularity utility supermodularity privacy order find near-optimal tradeoff efficiently. knowledge, existing approach
(such LeFevre, DeWitt, & Ramakrishnan, 2006; Chen, LeFevre, & Ramakrishnan, 2007; Hore &
R. Jammalamadaka, 2007) provides theoretical guarantees. evaluate approach realworld search log data, well data collected user study 1,400 participants
focused elicitation preferences sharing sensitive information. results indicate
existence prominent sweet spots utility-privacy tradeoff curve,
utility achieved sharing minimal amount private information.
manuscript organized follows. Section 2, formalize utility-privacy tradeoff
optimization problem introduce objective functions. Section 3 identifies submodular
supermodular structure utility cost functions. Section 4, introduce algorithm
finding near-optimal solution, exploits combinatorial structure. Section 6,
describe experimental design user study. Section 5 describes experimental setup,
Section 7 presents empirical evaluation approach real-world search data. Section 8
presents related work. Section 9 reviews approaches deploying methodology described
paper, Section 10 presents summary conclusions.

2. Privacy-Aware Personalization
consider challenge personalization diagnosis uncertainty: seek predict
searchers information goals, given noisy clues query terms potentially additional attributes describe users interests activities. frame challenge probabilistically
(as done, e.g., Dou, Song, & Wen, 2007; Downey, Dumais, & Horvitz, 2007 search context),
modeling joint distribution P random variables, comprise target intention X,
request-specific attributes (e.g., query term) Q, identity user , several attributes V = {V1 , V2 , . . . , Vm } containing private information. attributes include user-specific
variables (such demographic information, search history, word frequencies local machine,
etc.) request-specific variables (such period time since identical query submitted). describe concrete attributes used work web search context Section 5.
Additional examples described Downey et al. (2007) Teevan et al. (2005). shall describe use statistical techniques learn predictive model P training data frequent
queries. Then, present methods trading utility privacy context model.
2.1 Utility Accessing Private Data
Upon receiving new request Q, given subset V attributes, use probabilistic model predict target intention performing inference, computing conditional
distribution P (X | Q, A). Then, use distribution inform decision of, e.g.,
search results present user. use notation #intents refer domain size X
(e.g., maximum number different webpages clicked users). hope personalization additional knowledge user (i.e., observed set attributes A) help
simplify prediction task, via reducing uncertainty P (X | Q, A). Based intuition,
635

fiK RAUSE & H ORVITZ

quantify uncertainty prediction using conditional Shannon entropy (c.f., Cover &
Thomas, 1991) associated variance target web sites following queries,
X
P (x, q, a) log2 P (x | q, a).
H(X | Q, A) =
x,q,a

Hence, subset V, define utility U (A) information gain, i.e., expected
entropy reduction achieved observing A:
U (A) = H(X | Q) H(X | Q, A)
X
P (x, q, a) [log2 P (x | q) log2 P (x | q, a)] .
=
x,q,a

click entropy previously found effective Dou et al. (2007).
2.2 Cost Sharing Private Data
Several different models privacy proposed prior work (c.f., Sweeney, 2002; Machanavajjhala, Kifer, Gehrke, & Venkitasubramaniam, 2006; Dwork, 2006). cost function motivated
consideration sets attributes V preferred make identification individuals difficult possible. consider observed attributes noisy observations
(unobserved) identity = user. Intuitively, want associate high cost C(A)
sets allow accurate prediction given A, low cost sets conditional distributions P (Y | A) highly uncertain. distribution P (Y ) users, hence
define identifiability loss function L(P (Y )) maps probability distributions users
real numbers. L chosen way, exists user P (Y = y) close
1, loss L(P (Y )) large. P (Y ) uniform distribution, L(P (Y )) close
0. explore different loss functions L below. Based loss functions, define
identifiability cost I(A) expected loss conditional distributions P (Y | = a),
expectation taken observations = a1 :
X
I(A) =
P (a)L(P (Y | = a)).


P addition identifiability, introduce additional additive cost component S(A) =
aA s(a), s(a) 0 nonnegative quantity modeling subjective sensitivity attribute a, additive costs, data acquisition cost, etc. final cost function C(A)
combination identifiability cost I(A) sensitivity S(A), i.e., C(A) = I(A) + S(A).
2.2.1 DENTIFIABILITY L OSS F UNCTIONS
several ways quantify identifiability. One approach representing loss L
negative entropy distribution P (Y ) users identity 2 , used quantify utility.
However, context privacy, choice rather poor: Consider case seek
quantify cost associated change identifiability user comes learning
1. Similarly, additionally take expectation request Q
2. Note instead users identity (composed attribute values) principle could refer particular
sensitive attribute (such as, e.g., sexual orientation).

636

fiA U TILITY-T HEORETIC PPROACH P RIVACY NLINE ERVICES

searchers gender. Assuming equal distribution males females, learning gender
searcher would halve space possible searchers, hence increasing entropy loss
one. However, increase independent whether start (a) one billion (b) two
searchers. contrast influence utility, halving search space pages consider
large gain, independent number pages start (Dou et al., 2007), diminishment anonymity enormous: case (a), adversary trying identify searcher based
knowing gender almost chance success, whereas case (b) would always
identify person. Motivated consideration, represent privacy cost experiments maxprob loss (Chen et al., 2007), Lm (P (Y )) = maxy P (y). loss function
interpreted follows: adversary seeks identify user , predicts likely user,
receives one unit reward user guessed correctly, 0 otherwise. identifiability cost
X
P (a) max(P (y | = a))
Im (A) =




expected win obtained adversary. objective function makes sense
believe adversary access data sources (and thus probability
distribution P captures assumptions adversarys inferences). also consider cost
function


X
I` (A) =
P (a) log 1 max(P (y | = a)) .




I` rescaled variant maxprob loss, property certainty (i.e., maxy (P (y |
= a) 1) severely penalized.
Another criterion identifiability k-anonymity (Sweeney, 2002). measure, data
set called k-anonymous, combination attributes matched least k people.
define probabilistic notion k-anonymity, Ik , using loss function Lk (P (Y )) 1
P nonzero less k values , 0 otherwise. identifiability cost
X
Ik (A) =
P (a)Lk (P (Y | = a)).


Ik (A) interpreted expected number violations k-anonymity; database (empirical distribution users) k-anonymous Ik (A) = 0. See Lebanon, Scannapieco,
Fouad, Bertino (2009) justification using decision-theoretic analysis quantify privacy inferential attacks side information handled.
experimentally compare cost metrics Section 7.1.
2.3 Optimizing Utility-Privacy Tradeoff
Previously, described quantify utility U (A) given set attributes A,
associated privacy cost C(A). goal find set A, U (A) large
possible, keeping C(A) small possible. optimize utility users tradeoff,
use scalarization (Boyd & Vandenberghe, 2004), define new, scalar objective
F (A) = U (A) C(A).

637

fiK RAUSE & H ORVITZ

Hereby, plays role privacy-to-utility conversion factor. goal solve following
optimization problem:
= argmax F (A)
(2.1)


varying , find different solutions .

choose small , find solutions
higher utility higher cost; large values lead lower utility, also lower privacy cost.
set attributes V large, (2.1) difficult search problem, number subsets
grows exponentially size V. shown solution problem hard
even approximate:
Theorem 2.1. constant > (11/e) exists algorithm guaranteed
find set A0 F1 (A0 ) maxA F1 (A), P = N P .
proofs theorems presented Appendix. Given complexity, cannot
expect find solution efficiently achieves even slightly (1 1/e) 63%
optimal score. However, find solution guaranteed achieve least 1/3
optimal value.
2.4 Hard Constraints Privacy Cost
Instead optimizing tradeoff F (A) = U (A) C(A), one may interested maximizing
utility U (A) subject hard constraint cost C(A), i.e., solve
= argmax U (A) s.t. C(A) B,

(2.2)



value B 0. example, users may interested maximizing utility enforcing k-anonymity (in case would constrain Ik (A) 0). solution would provide
per-user guarantees, i.e., k-anonymity never violated. principle, one could solve tradeoff
F (i.e., problem (2.1)) different values then, e.g., using binary search, choose
maximizes U (A) among feasible solutions (i.e., C(A) B). sense, (2.1) seen
Lagrangian relaxation (2.2).
following, focus tradeoff problem (2.1). Using procedure described
above, approach may useful solve constrained problem (2.2) practice (however
approximation guarantees hold problem (2.1)).

3. Properties Utility-Privacy Tradeoff
mentioned above, would expect intuitively information already
user (i.e., larger |A|), less observation new, previously unobserved, attribute would
help enhancing service. combinatorial notion submodularity formally captures intuition. set function G : 2V R mapping subsets V real numbers called submodular (Nemhauser, Wolsey, & Fisher, 1978), B V, V 0 V\B, holds G(A
{V 0 }) G(A) G(B {V 0 } G(B), i.e., adding V 0 set increases G adding V 0
superset B A. G called nondecreasing, B V holds G(A) G(B).
result Krause Guestrin (2005) shows that, certain common conditional independence conditions, reduction click entropy submodular nondecreasing:

638

fiA U TILITY-T HEORETIC PPROACH P RIVACY NLINE ERVICES

Theorem 3.1 (Krause & Guestrin,
Q 2005). attributes V conditionally independent given
X, i.e., P (V1 , . . . , Vm | X) = P (Vi | X) U (A) submodular A.
discussed earlier expect privacy cost behave differently: Adding new attribute would likely make stronger incursion personal privacy know great deal
user, less know little. increasing costs property corresponds combinatorial notion supermodularity: set function G : 2V R called supermodular (Nemhauser
et al., 1978), B V, V 0 V \ V , holds G(A {V 0 }) G(A)
G(B {V 0 } G(B), i.e., adding V 0 large set B increases G adding V 0 subset
B. fact, prove maxprob identifiability cost function introduced Section 2
supermodular.
Theorem 3.2. Assume, attributes V marginally independent, user completely
characterized attributes, i.e., = (V). maxprob loss Im (A) supermodular A.
Note attribute sensitivity S(A) per definition additive hence supermodular well.
Thus, positive linear combination supermodular functions, C(A) = I(A) + S(A) supermodular I(A) = Im (A). empirical evaluation, verify submodularity U (A)
supermodularity C(A) even without assumptions made Theorem 3.1 Theorem 3.2.
Motivated insights combinatorial properties utility privacy,
formulate general approach trading utility privacy. assume utility
U (A) submodular set function, C(A) supermodular set function. define
general utility-privacy tradeoff problem follows:
Problem 3.3. Given set V possible attributes select, nondecreasing submodular utility
function U (A), nondecreasing supermodular cost function C(A), constant 0, goal
find set
= argmax F (A) = argmax U (A) C(A)


(3.1)



Since C(A) supermodular C(A) submodular, since nonnegative linear combinations submodular set functions submodular well, scalarized objective
F (A) = U (A) C(A) submodular well. Hence, problem (3.1) requires maximization submodular set function.

4. Optimization Algorithms
number subsets V grows exponentially size n V, NP-hardness
Problem (2.1), cannot expect find optimal solution efficiently. Theorem 2.1 shows
NP-hard even approximate optimal solution better constant factor (11/e).
fundamental result Nemhauser et al. (1978) characterized performance simple greedy
algorithm, starts empty set = myopically adds attribute increases
score most, i.e., {argmaxV 0 F (A {V 0 })}, k elements selected
(where k specified constant). shown that, F nondecreasing, submodular F () =
0, greedy solution AG satisfies F (AG ) (1 1/e) max|A|=k F (A), i.e., greedy solution achieves value least factor 11/e optimal solution. Although result would
allow us perform tasks selecting near-optimal set k private attributes maximizing
639

fiK RAUSE & H ORVITZ

utility U (A) (which satisfies conditions result Nemhauser et al., 1978), unfortunately apply general case, objective F (A) nondecreasing.
problem maximizing non-monotone submodular functions resolved
Feige, Mirrokni, Vondrak (2007). local search algorithm, named LS, proved guarantee
near-optimal solution ALS , F nonnegative3 (but necessarily nondecreasing) submodular
function:
1. Let V argmaxV 0 V F ({V 0 }) init. {V }
2. exists element V 0 V \ F (A {V 0 }) > (1 +
{V 0 }, repeat step 2.
3. exists element V 0 F (A \ {V 0 }) > (1 +
\ {V 0 }, go back step 2.


)F (A),
n2


)F (A),
n2

let

let

4. Return ALS argmax{F (A), F (V \ A)}.
algorithm works iterative manner add remove element V 0 order increase
score, improvement achieved. Feige et al. (2007) prove following
Theorem:
Theorem 4.1 (Feige et al., 2007). F nonnegative submodular function, then, solution
ALS returned algorithm LS, holds


1

F (ALS )

max F (A).

3 n
LS uses O( 1 n3 log n) function evaluations.
Hence, LS returns solution ALS achieving least 1/3 optimal score.
4.1 Efficient Implementation
description Algorithm LS allows freedom implementing search steps 2
3. implementation, select greedy manner element V 0 increases
objective function. Furthermore, speed computation, use lazy evaluation find greedy
elements (Robertazzi & Schwartz, 1989).
algorithm LLS (c.f., Figure 1) performs sequence upwards downwards passes,
adding removing elements improve F least factor (1 + n2 ). upwards pass
done lazy mannerthe increments V lazily updated necessary. found
lazy computation reduce running time order magnitude. correctness
lazy procedure follows directly submodularity: Submodularity implies V
monotonically nonincreasing elements added A. lazy updates also
applied greedy downward pass. discovered Algorithm 1 usually terminates
one single downwards pass, without removing single element.
3. F takes negative values, normalized considering F 0 (A) = F (A) F (V), however
impact approximation guarantees.

640

fiA U TILITY-T HEORETIC PPROACH P RIVACY NLINE ERVICES

Input: Submodular function F
Output: Near-optimal selection personal attributes
begin
;
repeat
change = f alse;
/* Lazy greedy upward pass:
*/
foreach V V V F (A {V }) F (A); currentV true;
repeat
V 0 argmaxV V\A V ;
currentV 0 = true
V 0 > (1 + n2 )F (A)
{V 0 }; foreach V V currentV f alse
else
break;
end
else
V 0 F (A {V 0 }) F (A); currentV 0 true;
end
V 0 (1 + n2 )F (A) ;
/* Lazy greedy downward pass:
*/
foreach V V F (A \ {V }) F (A); currentV true;
repeat
V 0 argmaxV V ;
currentV 0 = true
V 0 > (1 + n2 )F (A)
\ {V 0 }; change = true; foreach V currentV f alse
else
break;
end
else
V 0 F (A \ {V 0 }) F (A); currentV 0 true;
end
V 0 (1 + n2 )F (A) ;
change = f alse ;
return argmax{F (A), F (V \ A)}
end
Algorithm 1: lazy local search (LLS) algorithm.

641

fiK RAUSE & H ORVITZ

4.2 Evaluating Utility Cost
run LLS, need able efficiently evaluate utility U (A) cost C(A). principle, compute objective functions empirical distribution training data,
explicitly evaluating sums defining U (A) C(A) (c.f., Section 2). However, approach
inefficient (N 2 ) N number training examples. Instead, estimate
U (A) C(A) sampling. Krause Guestrin (2005) show Hoeffding inequality (Hoeffding, 1963) used order approximately compute conditional entropies. Hoeffding
inequality allows us acquire bounds number samples needed order determine
expectation E[H] random variable H, H bounded. case click entropy reduction,
use random variable
H | [Q = q, = a] = H(X) H(X | q, a).
H deterministic function modeling click entropy reduction request Q = q attributes
= observed. Since Q random variables, H random well. Since H bounded
0 log2 (#intents), Hoeffding inequality applied, following holds:
Lemma 4.2 (Krause & Guestrin, 2005). > 0 > 0, need
&
'

1 log2 (#intents) 2
1
log
2


samples order estimate U (A) absolute error confidence least 1 .
identifiability loss I(A), proceed similar manner. maximum probability k-anonymity loss bounded 0 1. Using similar argument
proof Lemma 4.2, following result:


Lemma 4.3. > 0 > 0, need 212 log 1 samples order estimate C(A)
absolute error confidence least 1 .
generalize Theorem 4.1 also hold case utility cost estimated
small constant error. following theorem summarizes analysis:
Theorem 4.4. F (V) 0, LLS, using sampling estimate C(A) U (A),
computes solution ALLS


1

F (ALLS )

max F (A) nS ,

3 n
probability least 1 . algorithm uses


1 3
n log n




log2 (#intents)


2

1
log 3
n

!

samples.
Hence, algorithm LLS efficiently find solution ALLS achieves least constant fraction 1/3 times value optimal solution.
642

fiA U TILITY-T HEORETIC PPROACH P RIVACY NLINE ERVICES

4.3 Computing Online Bounds
bounds provided Theorem 4.4 offline, sense stated running
Algorithm 1. use submodularity U (A) supermodularity C(A) additionally
computing online bounds performance algorithm.
Theorem 4.5. Let A0 V arbitrary set attributes. V V \ define V =
U (A0 {V }) U (A0 ) C({V }). Let B = {V : V > 0}.
X
max F (A) U (A0 ) +
V .


V B

possible extend bounds case objective function F evaluated small absolute error via sampling.
4.4 Finding Optimal Solution
Although LLS allows us find near-optimal solution polynomial time, submodularity
F also exploited find optimal solution informed way, allowing us bypass exhaustive search exponentially many subsets A. Existing algorithms optimizing submodular functions include branch bound search, e.g., data-correcting algorithm Goldengorin, Sierksma, Tijssen, Tso (1999), well mixed-integer programming
(Nemhauser & Wolsey, 1981). approaches also require nonnegativity F .
mixed-integer programming approach Nemhauser et.al. effectively uses bounds similar
presented Theorem 4.5.

5. Search Log Data Attributes
estimate utility U (A) cost C(A) sets private attributes data. use search
log data, based total 247,684 queries performed 9,523 users 14 months
December 2005 January 2007. search data obtained users volunteered
participate public Microsoft data sharing program centering use information
search activities enhance search. data filtered include queries
performed least 30 different users, resulting total 914 different queries.
utility U (A), compute average reduction click entropy (in bits) respect
per-query distribution web pages chosen, defined Section 2. demographic
information search logs, compute 31 different user / query specific attributes. selecting
attributes, chose coarse discretization. attribute represented three
bits, attributes binary. consider following attributes, summarized
Table 1.
5.1 Demographic Attributes
first set attributes contains demographic information, voluntarily provided separately part signing set online services. attributes contain gender, age group,
occupation region, coarsely discretized three bits. Gender specified
86% users, age 94%, occupation 57%. 44% users specified gender male,
42% female. 8% users asserted less 18 years, 53% 18 55,
643

fiK RAUSE & H ORVITZ

33% 55 older. users US Canada (53%), followed 7% European Union 3% Asia. locations unspecified. 10% searchers specified
students.
5.2 Search Activity Attributes
next set attributes contains features extracted search history data. query,
determine whether query performed (AQRY; 70% queries
repeated), well whether searcher visited webpage (ACLK) (53%
clicks). consider sequence websites visited following query, associate
hostname first website surfer dwells least 30 seconds intended
target. attribute AFRQ describes whether user performed least one query day. 47%
searchers performed least one search per day. also log top-level domain (ATLV)
determined reverse DNS lookup query IP address, used domains .net, .com,
.org .edu. 83% queries associated one domains. determine
user ever performed queries least 2 different zip codes (AZIP; true 31%), cities (ACTY; true
31%) countries (ACRY; true 2%), performing reverse DNS lookup query IP addresses.
query, store whether query performed working hours (AWHR;
7 6 pm) workdays (AWDY; Mon-Fri) weekend (Sat, Sun), without accounting
holidays. Workdays account 73% queries, 40% queries done
working hours.
5.3 Topic Interests
looked websites visited user 2006 16 element top-level category
Open Directory Project directory (www.dmoz.org). category, use binary
attribute indicating whether user ever visited website category (acronyms topics
indicated prefix T). Topic classification available 96% queries.

6. Survey Privacy Preferences
Although identifiability important part privacy, people may different preferences
sharing individual attributes (Olson, Grudin, & Horvitz, 2005). set assess preferences cost benefits sharing different kinds personal data. Related work
explored elicitation private information (c.f., Huberman, Adar, & Fine, 2005; Wattal, Telang,
Mukhopadhyay, & Boatwright, 2005; Hann, Hui, Lee, & Png, 2002). familiar
similar study context web search. survey designed specifically probe preferences revealing different attributes private data return increases utility
service (in case, terms enhanced search efficiency). previous studies Olson et al.
(2005) show, willingness share information greatly depends type information
shared, information shared, information going used. designing survey, tried specific possible, specifying low-risk situation,
personal information would shared used respect single specified query,
discarded immediately thereafter. survey contained questions sensitivity
individual attributes concerns identifiability. survey distributed within Microsoft Corporation via online survey tool. motivated people take survey providing

644

fiA U TILITY-T HEORETIC PPROACH P RIVACY NLINE ERVICES

Figure 1: Willingness share attributes
5

Sensitivity

4

3

2

1

AFRQ TNWS TSCI TART TGMS TBUS THEA TSOC DGDR AQRY ACLK ACRY DOCC DMTL DCHD AWHR

Figure 2: Sensitivity individual attributes (with 95% confidence intervals)

participants lottery could win media player via random drawing. survey
open worldwide entries, received total 1,451 responses. Again, use acronyms
refer personal attributes, defined Table 1.

645

fiK RAUSE & H ORVITZ

6.1 Questions Individual Attributes
First, assessed attributes participants would willing share search engine
revealing attributes would double search performance. Interestingly, attributes probed,
50% study participants asserted would agree share information given
promised efficiency gain. Also, sharing rates similar estimated survey
(78% gender, 82% age, 64% occupation). least willingness share (54.4%
52.6% respectively) exhibited marital status (DMTL) whether participant
children (DCHD), closely followed occupation (63.9%). participants (92.7%) would rather
share region share interests include news-related webpages (TNWS). Figure 1
presents results question. also asked participants classify sensitivity
attributes Likert scale 1 (not sensitive) 5 (highly sensitive). order
questions randomized. Figure 2 presents results. frequency search engine usage
(AFRQ) well general topic interests, e.g., news pages (TNWS), considered
low sensitivity. Interestingly, found significant differences preferences
among participants even sharing service interests different topics; participants showed
significantly greater sensitivity sharing interest health society related websites (THEA,
TSOC) news science-related pages (TNWS, TSCI). biggest jump sensitivity
occurs attributes ACLK, referring sharing repeated visit website, ACRY,
referring recently traveled internationally. found participants sensitive
sharing whether work performing query (AWHR).
6.2 Questions Identifiability
also elicited preferences sharing personal data different degrees precision
different levels identifiability. First, sought identify changes sensitivity associated
sharing personal data increasingly higher resolution. specifically, inquired
sensitivities participants sharing ages level groups 20, 10, 5, 1 years,
exact birth dates. Similarly, asked sensitive participants would sharing
location region, country, state, city, zip code, address levels detail. Figures 3(a)
3(b) present mean sensitivity 95% confidence intervals experiment. also
assessed participants sensitivities search activity stored different ways.
specifically, asked users assess sensitivity storing topic classification
visited websites (i.e., whether news- , business-, health-related etc. site visited), storing
searches 1 3 years, storing searches indefinitely. Lastly, asked participants
sensitive would be, if, spite sharing information, would guaranteed
remain indistinguishable least k people (thereby eliciting preferences k kanonymity). Here, varied k among 1, 10, 100, 1,000, 10,000, 100,000 1 million. Figure 3(c)
presents results experiments.
draw number conclusions preferences population studied. First, storing
search activity generally considered sensitive sharing certain demographic information.
example, even storing topic classification visited web pages considered significantly sensitive sharing city birth year user. result indicates logging
search activity considered least threatening privacy sharing certain demographic information. survey also shows study participants strong preferences granularity
shared information. explained Section 7.2, use information obtained
646

fiA U TILITY-T HEORETIC PPROACH P RIVACY NLINE ERVICES

5

Sensitivity

4

3

2

1

region country state

(a) Age

city

zip

address

(b) Location

5

Sensitivity

4

3

2

1
(c) Storage

1M 100K 10K

1K

100

10

1

(d) Discriminability

Figure 3: Sensitivity sharing age (a) location (b) different levels discretization.
(c) Sensitivity storing searches varying amounts time. (d) Sensitivity kdiscriminability levels (right). Plots show 95% confidence intervals.

experiment explicitly take account peoples preferences trading privacy
utility.
6.3 Questions Utility
addition assessing sensitivity sharing different kinds personal information, asked
participants assess degree improvement would require order share attributes
given sensitivity level. specifically, asked: much would search engine
improve performance, would willing share information consider 1/2/....
response options, offered average improvements 25%, 50%, 100%, well outcome
immediately presenting desired page 95% time (which associated speedup
factor 4). also allowed participants opt never share information specified
sensitivity level. responses, conjunction earlier sensitivity assessments, allowed

647

fiK RAUSE & H ORVITZ

Figure 4: attributes currently stored?

Figure 5: Using sensitivity common currency

us establish sensitivity common currency utility cost. Figure 5 presents median, 25
75-percentiles responses k-discriminability question utility question.
6.4 Questions Current State
Additionally, assessed current understanding state privacy search. specifically, asked, whether participants believe current search engines store following
attributes: DGDR, DAGE, DOCC, DZIP, ASEA, DCRY, TNWS, DEML. found participants (96%) assume search engines know country (DCRY) searcher from. Also,
participants (86%) assume searches stored search engines. Fewer participants believe demographic information occupation (16%), age (28%) gender (34%)

648

fiA U TILITY-T HEORETIC PPROACH P RIVACY NLINE ERVICES

Figure 6: Utility (average click entropy reduction bits) according greedy ordering

Figure 7: Cost according greedy ordering

known search engine. result important baseline order understand
sensitivity classification individual attributes.

7. Results
describe empirical results calibrating optimizing utility-privacy tradeoff.
7.1 Computing Utility Cost
use empirical distribution data described Section 5, evaluate utility cost
sampling. sample row picked uniformly random search logs. find
queries matching selected attributes (A = a), compute conditional entropy click
distribution, well identifiability loss function. order avoid overfitting sparse data,

649

fiK RAUSE & H ORVITZ

median #bits required

4

3
Identifiability cost
(maxprob)

2

1

Median #bits
(from survey)

0
region

(a) Tradeoff-curve

country

state

city

zip

(b) Calibration

Figure 8: (a) Tradeoff-curve varying . (b) Calibrating tradeoff.

applied Dirichlet smoothing. experiments, use 1000 independent samples order
estimate U (A) I(A).
first apply greedy algorithm select increasing number attributes, maximizing
utility ignoring cost. Figure 6 presents greedy ordering achieved entropy reductions. greedy algorithm selects attributes DOCC, ATLV, DAGE, ACTY, AQRY, ACLK,
AWHR, TADT, AWDY, THOM, TCIN, DGDR, TGMS, TREG, order. selecting
attributes, utility increase significantly anymore. entropy reduction levels
roughly 1.92 bits. Figure 6 underscores diminishing-returns property click entropy reduction.
Similarly, generate greedy ordering attributes, order minimum incremental
cost. Figure 7 presents results experiment, using maxprob cost metric. expected,
curve looks convex (apart small variations due sampling process). cost initially increases slowly, growth increases attributes selected. behavior
empirically corroborates supermodularity assumption cost metric.
Figure 9 compares three cost metrics, attributes selected. three
metrics initially behave qualitatively similarly. However, k-anonymity metric flattens
25 31 attributes selected. expected, eventually enough personal information available order (almost) always reduce candidate set people less k = 100.
point, adding attributes dramatically increase cost anymore. However,
trading utility privacy, one interested solutions small cost, critical
region, cost function behaves supermodularly well.
7.2 Calibrating Tradeoff Assessed Preferences
use scalarization (3.1) trade utility cost. optimization, need
choose tradeoff parameter . Instead committing single value , generate solutions
increasing values . value, use LLS find approximate solution,
plot utility cost. Figure 8(a) shows tradeoff curve obtained experiment.
see curve exhibits prominent knee: values 1 10, small increases utility

650

fiA U TILITY-T HEORETIC PPROACH P RIVACY NLINE ERVICES

Figure 9: Cost comparison according greedy ordering

lead big increases cost, vice versa. Hence, knee, achieve near-maximal utility
near-minimum cost.
integrate peoples preference analysis tradeoff, perform following calibration procedure. search log data, determined increasing resolution
persons location increases privacy cost. vary location granularity region (coarsest)
zip code (finest). example, compute values Im ({zip code}), Im ({city}), etc.
data. explained Section 6.2, asked subjects assess sensitivity sharing
locations different levels precision. approach also allows us put identifiability cost
I(A) sensitivity S(A) units.
Similarly, assessed amount improvement search performance would required
order share attributes given sensitivity. associate number bits level
improvement: speedup factor x would require log2 x bits (i.e., doubling search
performance would require 1 bit, etc.). concatenat mappings location granularity
sensitivity, sensitivity utility (bits), compute median number bits required
sharing location granularity. Using approach, put sensitivity S(A) utility
U (A) units. Thereby, effectively use sensitivity common currency
utility cost. procedure (up discretization) invariant particular scale (such 1
5) used assess sensitivity.
perform linear regression analysis align cost curve estimated data
curve obtained survey. least-squares alignment presented Figure 8(b), obtained value 5.12. Note value maps exactly sweet spot 1 10
tradeoff curve Figure 8(b).
7.3 Optimizing Utility-Privacy Tradeoff
Based calibration described above, goal find set attributes maximizing
calibrated objective F (A) according (3.1).
First, use greedy algorithm obtain ordering attributes, similarly cases
optimize utility cost separately. Figure 10 presents results experiment.

651

fiK RAUSE & H ORVITZ

Figure 10: Greedy solutions calibrated objective

Figure 11: Comparison heuristics

Instead using greedy algorithm, use LLS approximately solve optimization
problem. algorithm terminates two upward downward passes, solution AFRQ,
ATLV, AWDY, AQRY, ACLK, DAGE TSPT. Note first element selected
initial greedy upward pass DOCC (the occupation), discarded first downward pass
again, since individual sensitivity quite high (c.f., Figure 2), additional information
provided remaining 6 attributes high enough warrant presence optimal
solution.
also compared optimized solution Aopt results various heuristic procedures.
example, compared candidate solution Adem select demographic attributes
(all attributes starting D); Atopic select topic interest attributes (starting T);
Asearch including search statistics (ATLV, AWDY, AWHR, AFRQ); AIP , entire IP address
AIP 2 , first two bytes IP address. Figure 11 presents results comparison.
optimized solution Aopt obtains best score 0.83, achieving click entropy reduction 1.4.

652

fiA U TILITY-T HEORETIC PPROACH P RIVACY NLINE ERVICES

Figure 12: Running times

search statistics Asearch performs second best, score 0.57, achieving drastically
lower utility 0.8. Demographic information Adem achieves higher utility 0.95, much
higher cost, hence even lower total score 0.3. Perhaps surprisingly, collection topic
interests, Atopic results negative total score -1.73, achieving less utility optimized
solution. believe reason knowledge exact topic interest profile
frequently suffices uniquely identify searcher. expected, IP address (even first 2
bytes) quite identifying data set, hence high cost. experiment shows
optimization problem non-trivial, optimized solution outperforms heuristic choices.
also measured running time algorithms, standard desktop PC (3 GHz) using
C#-implementation. Figure 12 presents running times greedy local search algorithms, without lazy evaluation trick. note local search algorithm
much slower greedy algorithm; frequently, single upward downward pass
necessary, small number attributes considered elimination
downward pass. also note using lazy evaluations drastically speeds running time
522.1 minutes without 225.7 lazy evaluations. obtain tradeoff curve like one
Figure 8(b), algorithm run value ; hence improvement important.
also estimated running time required exhaustive search. Here, considered sets
size 8 (assuming optimal solution similar size approximate solution).
Even optimistic estimate would require 50.1 years computation time.

8. Related Work
paper extended version paper appeared 23rd Conference Artificial Intelligence (AAAI) (Krause & Horvitz, 2008). present version significantly extended, including
several additional experimental results, detailed discussion LLS algorithm well new

653

fiK RAUSE & H ORVITZ

Label
DGDR
DAGE
DOCC
DREG
DMTL
DCHD
AQRY
ACLK
AFRQ
AZIP
ACTY
ACRY
AWHR
AWDY
ATLV
TART
TADT
TBUS
TCMP
TGMS
THEA
THOM
TKID
TNWS
TREC
TREF
TREG
TSCI
TSHP
TCIN
TSOC
TSPT
TWLD

Type
Demographic
Demographic
Demographic
Demographic
Demographic
Demographic
Activity
Activity
Activity
Activity
Activity
Activity
Activity
Activity
Activity
Topic
Topic
Topic
Topic
Topic
Topic
Topic
Topic
Topic
Topic
Topic
Topic
Topic
Topic
Topic
Topic
Topic
Topic

bits
1
2
3
2
1
1
1
1
1
1
1
1
1
1
2
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1

Description
Gender
Age group (<18, 18-50, >50)
Occupation (6 groups related jobs)
Region (4 geographic regions)
Marital status (*)
Whether searcher children (*)
Performed query
Visited website
User performs least 1 query per day average
User performed queries least 2 different zip codes
User performed queries least 2 different cities
User performed queries least 2 different countries
Current query performed working hours
Current query performed workday / weekend
Top-level domain query IP address (.com, .net, .org, .edu)
User previously visited arts related webpage
User previously visited webpage adult content
User previously visited business related webpage
User previously visited compute related webpage
User previously visited games related webpage
User previously visited health related webpage
User previously visited home related webpage
User previously visited kids / teens related webpage
User previously visited news related webpage
User previously visited recreation related webpage
User previously visited reference related webpage
User previously visited webpage regional content
User previously visited science related webpage
User previously visited shopping related webpage
User previously visited consumer information webpage
User previously visited society related webpage
User previously visited sports related webpage
User previously visited world related webpage

Table 1: 33 Attributes used experiments. Attributes marked (*) available search
log data. Total number bits = 38.

654

fiA U TILITY-T HEORETIC PPROACH P RIVACY NLINE ERVICES

theoretical bounds (Section 4.3). review work related key concepts methods
presented paper.
8.1 Personalized Search, Probabilistic Models Search
problem personalized search received great deal attention (c.f., Xu et al., 2007
overview recent work). Teevan et al. considered use local term frequencies reranking web search results (Teevan et al., 2005). personal data kept private analysis
personal information re-ranking occurs entirely client. Recently, Xu et al. considered
problem privacy preserving web search. Based local information, user profile built,
used personalization. Two parameters called minDetail expRatio used specify
preferences privacy. similar spirit, approach tradeoff cost benefit
sets attributes approach does. Moreover, approach consider aspect
discriminability across users.
efforts employ probabilistic models web search, e.g., predicting relevance. Examples include techniques proposed Downey et al. (2007). methods proposed
paper use probabilistic model, allows answer questions like
much would uncertainty decrease knew searchers gender.
8.2 Value Information Probabilistic Models
Optimizing value information cornerstone principled approaches information
gathering (Howard, 1966; Lindley, 1956; Heckerman, Horvitz, & Middleton, 1993), popularized decision analysis context influence diagrams (Howard & Matheson, 1984).
Several researchers (van der Gaag & Wessels, 1993; Cohn, Gharamani, & Jordan, 1996; Dittmer
& Jensen, 1997; Kapoor, Horvitz, & Basu, 2007) suggested myopic, i.e., greedy approaches
selectively gathering observations. algorithms typically theoretical guarantees.
Heckerman et al. (1993) propose method compute maximum expected utility specific
sets observations. provide large sample guarantees evaluation given sequence observations, use heuristic without guarantees select sequences. Krause
Guestrin (2009) develop dynamic programming based algorithms finding optimal sets
observations. However, algorithms apply chain structured graphical models. Krause
Guestrin (2005) show certain conditional independence assumptions, information gain submodular function, observation build paper. knowledge,
paper provides first principled approach efficiently, nonmyopically trading value
information privacy cost.
8.3 Valuation Private Information
problem estimating sensitivity monetary value private information studied extensively, e.g., economics literature. Huberman et al. (2005) propose second-price auction
estimating sensitivity demographic attributes. application specific approach,
Wattal et al. study, whether inclusion names personal product preferences enhance
effectiveness email marketing (Wattal et al., 2005). Hann et al. (2002) study economic
incentives affect individuals preferences different privacy policies, quantifying value
disallowing use personal information. Kleinberg, Papadimitriou, Raghavan (2001) quan-

655

fiK RAUSE & H ORVITZ

tify value private information using Shapley value coalitional game. approach
provides alternative, theoretically well-motivated way eliciting subjective cost sharing
set personal information, could potentially combined approach optimize
utility-privacy tradeoff.
8.4 Mathematical Notions Privacy
field mathematical (or cryptographic) privacy studied extensively (c.f., Adam
& Wortmann, 1989 survey early work). pioneering result definition kanonymity, development algorithms maintaining indiscriminability guarantee
(Sweeney, 2002). Follow work led notions indiscriminability, l-diversity
(Machanavajjhala et al., 2006) etc. notions describe properties databases isolation,
sometimes called non-interactive (Dwork, 2006). Often, inference attacks using auxiliary
knowledge problematic context. Lebanon et al. (2009) consider decision theoretic variants k-anonymity related notions. approach allows quantify risk (partially)
releasing sanitized records. consider approaches quantifying privacy cost,
present efficient algorithms guarantees trading utility privacy paper.
Another important class cryptographic approaches privacy consider protection privacy
context interactive analyses. approaches, database contains arbitrary amount
private information, securely guarded. Access database enabled via limited
form queries, guarantee privacy. One prominent example techniques notion differential privacy (Dwork, 2006). notion quantifies risk user incurred
participating database. Intuitively, queries allowed, corresponding results
significantly depend presence absence individuals database. Blum et al.
(2008) show differential privacy (and stronger variant called distributional privacy)
achieved even non-interactive setting. However approach efficient limited
class queries that, e.g., allow estimate click probabilities considered paper.
Although approaches provide crisp mathematical definitions privacy, designed
specific notion utility mind. Rather, specific privacy requirement formulated,
analyses show limits data usage consistent requirement. believe
utility-theoretic approach privacy complementary cryptographic definitions privacy. approach used develop privacy-aware design, existing techniques
differential privacy can, e.g., used guard access private information. utilitytheoretic analyses also allow new scenarios, identifying value specific private data
specific context, requesting data real time, short-term usage. applications
bypass assumption long-term, large-scale storage private data explored within
cryptographical analyses privacy.
8.5 Utility-Privacy Tradeoff
Algorithmic approaches optimizing tradeoff considered area privacypreserving data publishing, focuses anonymization techniques. settings, constraint privacy typically specified (in terms k-anonymity, Sweeney, 2002, l-diversity,
Machanavajjhala et al., 2006) recoding scheme applied maximizes specified quality metric. Recent work involves development greedy algorithm (LeFevre et al.,

656

fiA U TILITY-T HEORETIC PPROACH P RIVACY NLINE ERVICES

2006) branch bound search (Hore & R. Jammalamadaka, 2007). knowledge,
algorithms performance approximation guarantees.
approach different, explicitly quantify utility cost units,
optimize single scalar value information problem. Moreover, use application specific
utility function, rather distortion metric. Furthermore, algorithm guaranteed provide
near-optimal solutions optimization problem.

9. Discussion
proposed methodology could implemented variety ways. critical design
choices utility-privacy tradeoff optimized. following, shall
explore parameters context personalized search.
9.1 Location private information
Private information either located client (i.e., recipient service, e.g., web
searcher), server (i.e., service provider, e.g., search engine), channel.
9.2 Client-side Private Information
client-side setting, private information stored locally, never shared network;
configuration considered Teevan et al. (2005) Xu et al. (2007). approach, private information used re-rank search results locally, never transmitted across
network, avoiding risk misuse unintended release. However, private information
(easily) migrate user across multiple machines, privacy concerns effectively
replaced security concerns, requiring local machine compromised. proposed
methodology could useful mitigating security concerns; client services might optimized
acquire store relevant information.
9.3 Server-side Private Information
server side, designs privacy, especially regard storage usage behavioral
data, critical importance services users.
methods described used balance user sensitivity service utility, address
questions data logged, anonymization techniques used
(c.f., Adar, 2007 discussion difficulties possible options anonymizing web search
logs). Furthermore, specific personal (e.g., demographic) information could voluntarily made
available web searcher web service form of, e.g., user profile. settings,
proposed methodology could potentially used trade privacy utility.
9.4 Channel-side Private Information
also foresee applications private data transmitted per-request basis. setting,
proposed methodology used design private bits transmit maximize utility
minimizing privacy risk.

657

fiK RAUSE & H ORVITZ

9.5 Priori vs. Dynamic Tradeoff Optimization
Another important design parameter tradeoff privacy utility made.
9.5.1 PRIORI RADEOFF PTIMIZATION / P RIVACY-AWARE ERVICE ESIGN
One option apply proposed methodology priori, i.e., system used.
Here, utility-privacy tradeoff would determine information logged, collected
local profiles, private bits made part protocol used transmit service requests.
approach advantage always private bits used, inference attacks
combining private information different requests possible.
9.5.2 DYNAMIC PTIMIZATION
mentioned earlier, systems endowed ability make dynamic recommendations users take actions accordance user preferences course online activities.
Dynamic variants methods presented used identify best subset private information sharing optimize utility user. web search, depending
query, different kinds personal information may helpful disambiguation.
utility-theoretic approach privacy could used determine needs real time. Challenges
implementing real-time, interactive approach, include grappling possibility inference attacks combine bits different requests. Anonymization procedures
designed resist challenges. Another challenge computational efficiency, solving
optimization problem may required service request. main advantage employing
dynamic approach average number private bits (and hence identifiability cost) per
request could lower priori privacy-aware design. priori design requires collection private bits help disambiguating queries versus context-specific situations.
interactive approach would additionally allow users share private information per-request
basis. interactive decisions also require considerations preferences tradeoffs
private information acquired usersand rely design user interaction
models interfaces provide users awareness opportunities enhancing value
services controls guiding revelation private information. Recent developments
adaptive submodularity may provide methods necessary achieve dynamic, adaptive
optimization tradeoffs (Golovin & Krause, 2010).
9.6 Applications
increasing cost property characterizes identifiability cost potentially arises
contexts well. example, many algorithms, computational cost scales superlinearly
number dimensions / attributes considered. cases, problem trading information (such click entropy reduction) computation cost combinatorial structure utility-privacy tradeoff addressed paper. algorithmic/computational
considerations presented paper, lazy local search algorithm, sample complexity
analyses, apply contexts well.

658

fiA U TILITY-T HEORETIC PPROACH P RIVACY NLINE ERVICES

10. Conclusions
presented approach explicitly optimizing utility-privacy tradeoff personalized services web search. showed utility functions like click entropy reduction satisfy
submodularity, intuitive diminishing-returns property. contrast, privacy concerns show supermodularity; private information accrue, faster sensitivity risk identifiability grow. Based submodular utility supermodular cost functions, demonstrated
efficiently find provably near-optimal utility-privacy tradeoff. evaluated methodology real-world web search data. demonstrated quantitative tradeoff calibrated
according personal preferences, obtained user study 1,400 participants. Overall,
found significant personalization achieved using small amount information
users. believe principles methods employed utility-theoretic analysis
tradeoffs web search applicability personalization broad variety online
services. results underscore value taking decision-theoretic approach privacy,
seek jointly understand utility personalization achieved via access information users, preferences users costs benefits selectively sharing
personal data online services.
Acknowledgments
Andreas Krause intern Microsoft Research work performed. would like
thank searchers provided usage data use research, participants survey
privacy preferences, anonymous referees helpful comments suggestions.

Appendix A. Proofs
Proof Theorem 2.1. Let n = |cV |. prove result choice I(A), I(A) = 0
|A| < n/2 I(A) = 2M (|A|n/2) otherwise, = U (V) maximum achievable
utility. case, F1 (A) = U (A) 0 |A| n/2, F1 (A) < 0 |A| > n/2. Hence,
argmax F1 (A) = argmax U (A).


A:|A|n/2

However, Krause Guestrin (2005) show polynomial time algorithm
guaranteed find set A0 U (A0 ) (1 1/e) maxA:|A|n/2 U (A), P = N P .
Proof Theorem 3.2. Let = (A, B) (i.e., V partitioned B). Then,
X
X
Im (A) =
P (a) max P (b | a) =
P (a) max P (b)


b

= max P (b) = max
b

b


b



P (bi ) =






max P (bi ) =
bi



wi



wi = maxbi P (bi ). Now, Im (A) nondecreasing A. Furthermore, subsets A, A0 V
B = A0 , holds Im (B) = Im (A) 1. Furthermore, V V \ B
w = maxv P (V = v), Im (B {V }) = w1 Im (B) Im (A {V }) = w1 Im (A). Hence,
Im (B {V }) Im (B)
(w1 1)
=
= 1,
Im (A {V }) Im (A)
w1 1
659

fiK RAUSE & H ORVITZ

proves supermodularity Im (A).
Proof Theorem 4.4. Additive error carries Lemma 3.3. subsequently
proof Theorem 3.4. Feige et al. (2007). order guarantee confidence 1 , apply
union bound. sample complexity follows Lemma 4.2 Lemma 4.3.
Proof Theorem 4.5. Let C optimal solution. Since U nondecreasing,
F (C) = U (C) C(C) U (A0 C) C(C)
X
U (A) +
[U (A {V }) U (A)] C(C)
V C

X

U (A) +

[U (A {V }) U (A) C({V })]

V C

= U (A0 ) +

X

V U (A0 ) +

V C

X

V .

V B

References
Adam, N. R., & Wortmann, J. C. (1989). Security-control methods statistical databases:
comparative study. ACM Computing Surveys, 21(4), 515556.
Adar, E. (2007). User 4xxxxx9: Anonymizing query logs. Query Logs Workshop, World Wide
Web Conference.
Blum, A., Ligett, K., & Roth, A. (2008). learning theory approach non-interactive database
privacy. Symposium Theory Computing.
Boyd, S., & Vandenberghe, L. (2004). Convex Optimization. Cambridge University Press.
Chen, B., LeFevre, K., & Ramakrishnan, R. (2007). Privacy skyline: Privacy multidimensional
adversarial knowledge. International Conference Large Data Bases (VLDB).
Cohn, D. A., Gharamani, Z., & Jordan, M. I. (1996). Active learning statistical models. Journal
Artificial Intelligence Research, 4, 129145.
Cover, T. M., & Thomas, J. A. (1991). Elements Information Theory. Wiley Interscience.
Dittmer, S., & Jensen, F. (1997). Myopic value information influence diagrams. Conference
Uncertainty Artificial Intelligence (UAI), pp. 142149, San Francisco.
Dou, Z., Song, R., & Wen, J.-R. (2007). large-scale evaluation analysis personalized search
strategies. World Wide Web Conference (WWW).
Downey, D., Dumais, S., & Horvitz, E. (2007). Models searching browsing: Languages,
studies, applications. International Joint Conference Artificial Intelligence (IJCAI).
Dwork, C. (2006). Differential privacy. International Colloquium Automata, Languages
Programming (ICALP).
Feige, U., Mirrokni, V., & Vondrak, J. (2007). Maximizing non-monotone submodular functions.
IEEE Symposium Foundations Computer Science (FOCS).
660

fiA U TILITY-T HEORETIC PPROACH P RIVACY NLINE ERVICES

Goldengorin, B., Sierksma, G., Tijssen, G. A., & Tso, M. (1999). data-correcting algorithm
minimization supermodular functions. Management Science, 45(11), 15391551.
Golovin, D., & Krause, A. (2010). Adaptive submodularity: new approach active learning
stochastic optimization. International Conference Learning Theory (COLT).
Hann, I., Hui, K., Lee, T., & Png, I. (2002). Online-information privacy: Measuring cost-benefit
tradeoff. International Conference Information Systems.
Heckerman, D., Horvitz, E., & Middleton, B. (1993). approximate nonmyopic computation
value information. IEEE Trans. Pattern Analysis Machine Intelligence, 15, 292298.
Hoeffding, W. (1963). Probability inequalities sums bounded random variables. Journal
American Statistical Association, 58(301), 1330.
Hore, B., & R. Jammalamadaka, S. M. (2007). Flexible anonymization privacy preserving data
publishing: systematic search based approach. SIAM Conference Data Mining (SDM).
Horvitz, E. (2006). Machine learning, reasoning, intelligence daily life: Directions
challenges. Tech. rep. TR-2006-185, Microsoft Research.
Howard, R. A. (1966). Information value theory. IEEE Transactions Systems Science
Cybernetics (SSC-2).
Howard, R. A., & Matheson, J. (1984). Readings Principles Applications Decision
Analysis II, chap. Influence Diagrams, pp. 719762. Strategic Decision Group, Menlo Park.
Reprinted 2005 Decision Analysis 2(3) 127-143.
Huberman, B. A., Adar, E., & Fine, L. R. (2005). Valuating privacy. IEEE Security & Privacy, 3(5),
2225.
Kapoor, A., Horvitz, E., & Basu, S. (2007). Selective supervision: Guiding supervised learning
decision-theoretic active learning. International Joint Conference Artificial Intelligence
(IJCAI).
Kleinberg, J., Papadimitriou, C. H., & Raghavan, P. (2001). value private information.
TARK: Theoretical Aspects Reasoning Knowledge, 8.
Krause, A., & Guestrin, C. (2009). Optimal value information graphical models. Journal
Artificial Intelligence Research, 35, 557591.
Krause, A., & Horvitz, E. (2008). utility-theoretic approach privacy personalization.
Proc. 23rd Conference Artificial Intelligence (AAAI), Special Track AI & Web.
Krause, A., & Guestrin, C. (2005). Near-optimal nonmyopic value information graphical
models. Conference Uncertainty Artificial Intelligence (UAI).
Lebanon, G., Scannapieco, M., Fouad, M. R., & Bertino, E. (2009). Beyond k-anonymity: decision theoretic framework assessing privacy risk. Transactions Data Privacy, 2(3),
153183.
LeFevre, K., DeWitt, D., & Ramakrishnan, R. (2006). Mondrian multidimensional k-anonymity.
IEEE International Conference Data Engineering (ICDE).
Lindley, D. V. (1956). measure information provided experiment. Annals
Mathematical Statistics, 27, 9861005.

661

fiK RAUSE & H ORVITZ

Machanavajjhala, A., Kifer, D., Gehrke, J., & Venkitasubramaniam, M. (2006). L-diversity: Privacy
beyond k-anonymity. IEEE International Conference Data Engineering (ICDE).
Nemhauser, G., Wolsey, L., & Fisher, M. (1978). analysis approximations maximizing
submodular set functions. Mathematical Programming, 14, 265294.
Nemhauser, G. L., & Wolsey, L. A. (1981). Studies Graphs Discrete Programming, chap.
Maximizing Submodular Set Functions: Formulations Analysis Algorithms, pp. 279
301. North-Holland.
Olson, J. S., Grudin, J., & Horvitz, E. (2005). study preferences sharing privacy.
ACM Conference Human Factors Computing Systems (CHI).
Robertazzi, T. G., & Schwartz, S. C. (1989). accelerated sequential algorithm producing
D-optimal designs. SIAM Journal Scientific Statistical Computing, 10(2), 341358.
Sugiyama, K., Hatano, K., & Ikoma, T. (2004). Adaptive web search based user profile constructed without effort users. World Wide Web Conference (WWW).
Sweeney, L. (2002). k-anonymity: model protecting privacy. International Journal Uncertainty, Fuzziness Knowledge-based Systems, 10(5), 557570.
Teevan, J., Dumais, S. T., & Horvitz, E. (2005). Personalizing search via automated analysis
interests activities. International ACM SIGIR Conference.
van der Gaag, L., & Wessels, M. (1993). Selective evidence gathering diagnostic belief networks.
AISB Quart., 86, 2334.
Wattal, S., Telang, R., Mukhopadhyay, T., & Boatwright, P. (2005). Examining personalizationprivacy tradeoff empirical investigation email advertisements. Management Science.
Xu, Y., Zhang, B., & Wang, K. (2007). Privacy-enhancing personalized web search. World Wide
Web Conference (WWW).

662

fiJournal Artificial Intelligence Research 39 (2010) 745774

Submitted 03/10; published 12/10

Intrusion Detection using Continuous Time Bayesian Networks
Jing Xu
Christian R. Shelton

JINGXU @ CS . UCR . EDU
CSHELTON @ CS . UCR . EDU

Department Computer Science Engineering
University California, Riverside
Riverside, CA 92521, USA

Abstract
Intrusion detection systems (IDSs) fall two high-level categories: network-based systems
(NIDS) monitor network behaviors, host-based systems (HIDS) monitor system calls.
work, present general technique systems. use anomaly detection,
identifies patterns conforming historic norm. types systems, rates change
vary dramatically time (due burstiness) components (due service difference).
efficiently model systems, use continuous time Bayesian networks (CTBNs) avoid
specifying fixed update interval common discrete-time models. build generative models
normal training data, abnormal behaviors flagged based likelihood
norm. NIDS, construct hierarchical CTBN model network packet traces
use Rao-Blackwellized particle filtering learn parameters. illustrate power
method experiments detecting real worms identifying hosts two publicly
available network traces, MAWI dataset LBNL dataset. HIDS, develop novel
learning method deal finite resolution system log file time stamps, without losing
benefits continuous time model. demonstrate method detecting intrusions
DARPA 1998 BSM dataset.

1. Introduction
Misuse abuse computer systems critical issue system administrators. goal
detect attacks attempt compromise performance quality particular host machine.
time-consuming error-prone acquire labeled data contains good bad
behaviors build classifier. Additionally, frequency attacks developed make maintaining database previously seen attacks inefficient even infeasible.
Anomaly detection identify new attacks even attack type unknown beforehand. Unsupervised learning allows anomaly detector adapt changing environments, thereby extending
domain usefulness. modeling normal behavior historic clean data, identify
abnormal activity without direct prior model attack simply comparing deviation
learned norm.
network-based intrusion detection system (NIDS), network packet traces monitored.
Network traffic traces collect information networks data stream provide external
view network behavior. host-based intrusion detection system (HIDS), internal state
computing system analyzed. System call logs convenient way monitoring executing
programs behavior operating system calls.
systems composed activities happen dramatically different time granularity.
Users alternate busily using computer resting. busy period, burst
action may cause peak network traffic flow operating system usage. However,
c
2010
AI Access Foundation. rights reserved.

fiX U & HELTON

resting period, computer maintains regular running pattern, network system activities much less intense, e.g. automatically checking email every minutes. Even within
global modes variations. Therefore, dynamic model requires discretizing
time efficient. develop intrusion detection techniques using continuous time Bayesian
networks (CTBNs) (Nodelman, Shelton, & Koller, 2002) data types. Although two
data completely different formats semantic meaning, demonstrate flexibility
continuous time generative model (such CTBN) describe either.
first effort detect anomalies network traffic traces (NIDS). Abnormal traffic must
differ way normal traffic patterns. difference may subtle
difficult detect, subtle attack, longer attack take
stress patience attacker. Looking summarized information like flow statistics
helpful, especially stealthy worms mingle well normal traffic sacrificing
spreading speed scale. We, therefore, feel looking abnormalities detailed network
traffic flow level utile method finding attacks. network flow given host machine
sequence continuous-time asynchronous events. Furthermore, events form complex
structured system, statistical dependencies relate network activities like packet emissions
connections. employ CTBNs reason structured stochastic network processes.
CTBN model contains number observed network events (packet emissions concurrent port connections changes). allow model descriptive, also add latent
variables tie activity variables together. Exact inference method longer feasible.
Therefore, use Rao-Blackwellized particle filtering (RBPF) estimate parameters.
second effort detect intrusions using system call logs (HIDS). system log file contains ordered list calls made computers operating system executing program.
focus analyzing ordering context sequence, rather simply counting
overall statistics. CTBN natural way modeling sequential data. finite
resolution computer clock, system calls issued within clock tick assigned
time stamp. Therefore data stream consists long periods time activity, followed
sequences calls order correctly recorded, exact timing information lost.
poses new challenge CTBN reasoning. present learning method type
data without resorting time discretization.
validate NIDS technique MAWI dataset LBNL dataset, HIDS
technique DARPA 1998 BSM dataset. applications give good results compared
method.
Section 2 discuss related work intrusion detection. Section 3 review continuoustime Markov processes continuous time Bayesian networks. Section 4 describe CTBN
model RBPF inference algorithms NIDS problem. Section 5 describe
CTBN model parameter estimation algorithm HIDS, including deal imprecise timing measurements. Section 6 show experimental results applications.

2. Related Work
Much previous work intrusion detection focuses one area either detecting
network traffic mining system call logs. work Eskin, Arnold, Prerau, Portnoy,
Stolfo (2002) similar approach apply method kinds
746

fiI NTRUSION ETECTION USING CTBN

data. map data elements feature space detect anomalies determining points
lie sparse regions using cluster-based estimation, K-nearest neighbors one-class SVM.
use data-dependent normalization feature map network traffic data spectrum kernel
system call traces.
2.1 NIDS
network traffic data, build upon previous work (Xu & Shelton, 2008). made
assumption network activities independent across different ports. allowed us
factorize model port-level submodels standard exact inference techniques could used
parameter learning. paper, remove restriction. application-specific
reason traffic independent ports. tying traffic together, model describes
complicated structural dependencies among variables. derive Rao-Blackwellized particle
filtering algorithm estimate parameters model. work also differs
interested intrusion detection problem, host identity recognition well.
signature-based detection algorithm, share many assumptions Karagiannis,
Papagiannaki, Faloutsos (2005). particular, also assume access
internals machines networks, rules methods like Malan
Smith (2005), Cha (2005), Qin Lee (2004), Eskin et al. (2002). However, differ
approach rely preset values, require human intervention interpretation,
assume access network-wide traffic information. Network-wide data human
intervention advantages, also lead difficulties (data collation face
attack increased human effort), chose leave solution.
Many learning, adaptive, methods proposed network data.
example, Zuev Moore (2005) Soule, Salamatian, Taft, Emilion, Papagiannali (2004) approach problem classification task requires labeled data. Dewaele,
Fukuda, Borgnat (2007) profile statistical characteristics anomalies using random projection techniques (sketches) reduce data dimensionality multi-resolution non-Gaussian
marginal distribution extract anomalies different aggregation levels. goal papers
usually detect attacks rather classify non-attacks traffic type; applied attack
detection, would risk missing new types attacks. Furthermore, frequently treat
network activity separately, instead considering temporal context.
Lakhina, Crovella, Diot (2005) nice summary adaptive (or statistical) methods
look anomaly detection (instead classification). use entropy-based method
entire network traffic. Many methods, Ye, Emran, Chen, Vilbert
(2002), use either statistical tests subspace methods assume features connections
packets distributed normally. Rieck Laskov (2007) model language features like
n-grams words connection payloads. Xu, Zhang, Bhattacharyya (2005) also use
unsupervised methods, concentrate clustering traffic across whole network. Similarly,
Soule, Salamatian, Taft (2005) build anomaly detector based Markov models,
network traffic patterns whole function host level.
work Soule et al. (2004) similar statistical flavor work. also
fit distribution (in case, histogram modeled Dirichlet distribution) network data.
However, model flow-level statistics, whereas work level individual connections.
Additionally, attempting network-wide clustering flows instead anomaly detection.
747

fiX U & HELTON

work Moore Zuev (2005), like approach, models traffic graphical models,
particular, Naive Bayes networks. goal categorize network traffic instead detecting
attacks. Kruegel, Mutz, Robertson, Valeur (2003) present Bayesian approach detecting
problem event classification task care whether host attack
interval.
work Lazarevic, Ertoz, Kumar, Ozgur, Srivastava (2003) also similar work.
one papers attempt find attacks host level. employ nearest neighbor,
Mahalanobis distance approach, density-based local outliers method, using 23 features
connections. Although methods make standard i.i.d. assumption data
(and therefore miss temporal context connection) use 23 features (compared
features), compare results Section 6, closest prior work. Agosta,
Duik-Wasser, Chandrashekar, Livadas (2007) present adaptive detector whose threshold
time-varying. similar work also rely model-based algorithms.
employ host internal states like CPU loads available us.
great variety previous work, work novel detects
anomalies host level using timing features network activities. consider
connection (or packet) isolation, rather complex context. capture statistical
dynamic dependencies packets connections find sequences network traffic
anomalous group.
2.2 HIDS
Previous work detecting intrusions system call logs roughly grouped two categories: sequence-based feature-based. Sequence-based methods focus sequential order
events feature-based methods treat system calls independent data elements.
method belongs former category since use CTBN model dynamics sequences.
Time-delay embedding (tide) sequence time-delay embedding (stide) two examples
sequence based methods (Forrest, A.Hofmeyr, Somayaji, & A.Longstaff, 1996; A.Hofmeyr, Forrest, & Somayaji, 1998). generalize data building database storing previously seen
system call sub-sequences, test looking subsequences database. methods
straightforward often achieve good results. compare experiments. Tandon
Chan (2005) look richer set attributes like return value arguments associated
system call make use system call names.
Feature based methods like Hu, Liao, Vemuri (2003) use dataset use,
DARPA 1998 BSM dataset, training data noisy try find classification
hyperplane using robust support vector machines (RSVMs) separate normal system call profiles
intrusive ones. Eskin (2000) also works noisy data. make assumption
training data contains large portion normal elements anomalies. present mixture
distribution normal abnormal data calculate likelihood change data point
moved normal part abnormal part get optimum data partition.
Yeung Ding (2002) try use techniques. provide dynamic static behavioral models system call data. dynamic method, hidden Markov model (HMM)
used model normal system events likelihood calculated testing sequence
compared certain threshold. work system call traces problem close
748

fiI NTRUSION ETECTION USING CTBN

framework since also build dynamic model sequential data compute
likelihood testing example score. different CTBN models continuous time dynamics rather time-sliced behaviors. static method, represent
normal behavior command occurrence frequency distribution measure distance
testing example norm cross entropy. dataset use KDD archive dataset.
2.3 Work
Simma et al. (2008) also use continuous-time model reason network traffic. apply
method find dependences exterprise-level services. model non-Markovian,
also deals network events basic observational unit.
estimate parameters large network build network traffic data, use
Rao-Blackwellized particle filters (RBPFs). Doucet, de Freitas, Murphy, Russel (2000) propose
RBPF algorithm dynamic Bayesian networks works discrete time fashion exploiting
structure DBN. Ng, Pfeffer, Dearden (2005) extend RBPF continuous time dynamic systems apply method K-9 experimental Mars rover NASA Ames Research
Center. model hybrid system containing discrete continuous variables.
use particle filters discrete variables unscented filters continuous variables.
work similar apply RBPF CTBN. model contains discrete
variables evidence continuous time (as opposed snapshots system
state).

3. Continuous Time Bayesian Networks
begin briefly reviewing definition Markov processes continuous time Bayesian
networks (CTBNs).
3.1 Homogeneous Markov Process
finite-state, continuous-time, homogeneous Markov process Xt described initial distribution PX0 and, given state space V al(X) = {x1 , ..., xn }, n n matrix transition intensities:



QX =


qx1
q x2 x1
..
.

q x1 x2
qx2
..
.

q xn x1

q xn x2

. . . q x1 xn
. . . q x2 xn
..
..
.
.
. . . qxn




.


P
qxi xj intensity (or rate) transition state xi state xj qxi = j6=i qxi xj .
transient behavior Xt described follows. Variable X stays state x time
exponentially distributed parameter qx . probability density function f Xt remaining
x duration fx (q, t) = qx exp(qx t) 0. expected time next transition
given state currently x 1/qx . Upon transitioning, X shifts state x0 probability
xx0 = qxx0 /qx . Note given qx , xx0 qxx0 iosmorphic. sometime gives formulae
terms xx0 simplifies expression.
distribution state process X future time t, Px (t), computed
directly QX . PX0 distribution X time 0 (represented vector), then, letting
749

fiX U & HELTON

exp matrix exponential,
PX (t) = PX0 exp(QX t) .
3.2 Complete Data
Complete data HMP represented set trajectories = {1 , ...n }. trajectory
complete set state transitions: = {(xd , td , x0d )}, meaning X stayed state xd
duration td , transitioned state x0d . Therefore know exact state variable
X time 0 .
3.3 Sufficient Statistics Likelihood
Given HMP full data D, likelihood single state transition = {(xd , td , x0d )}

LX (q, : d) = (qxd exp(qxd td ))(xd x0d ) .
likelihood function decomposed transition:


LX (q, : D) = (
LX (q : d))(
LX ( : d))
dD

dD


[x,x0 ]
= ( qxM [x] exp(qx [x]))(
xx0
).
x x0 6=x

x

take log function, get log likelihood:
lX (q, : D) = lX (q : D) + lX ( : D)
X
X
=
(M [x] ln(qx ) qx [x] +
[x, x0 ] ln(xx0 )) .
x0 6=x

x

[x, x0 ]


[x] sufficient statistics HMP
model. [x, x0 ] number
P
times X transitions state x x0 . denote [x] = x0 [x, x0 ], total number
times system leaves state x. [x] total duration X stays state x.
3.4 Learning Complete Data
estimate parameters transition intensity matrix Q, maximize log likelihood function. yields maximum likelihood estimates:
qx =

[x]
,
[x]

xx0 =

[x, x0 ]
.
[x]

3.5 Incomplete Data
Incomplete data HMP composed partially observed trajectories = {1 , ...n }.
trajectory consists set = {(Sd , td , dt)} observations, Sd subsystem (a
nonempty subset states X) process. triplets specifies interval
evidence. states variable X subsystem Sd time td time td + dt.
observations may duration-free. i.e., observe X Sd time t, know
long stayed there. called point evidence generalized using triplet
notation described setting duration 0. partially observed trajectory,
observe sequences subsystems, observe state transitions within subsystems.
750

fiI NTRUSION ETECTION USING CTBN

3.6 Expected Sufficient Statistics Expected Likelihood
consider possible completions partially observed trajectory specify transitions
consistent partial trajectory. combining partial trajectory completion,
get full trajectory. define D+ = {1+ , ..., n+ } completions partial trajectories
D. Given model, distriubtion D+ , given D.
data D+ , expected sufficient statistics respect probability density possible completions data [x], [x, x0 ] [x]. expected log likelihood
E[lX (q, : D+ )] = E[lX (q : D+ )] + E[lX ( : D+ )]
X
X
(M [x] ln(qx ) qx [x] +
=
[x, x0 ] ln(xx0 )) .
x0 6=x

x

3.7 Learning Incomplete Data
expectation maximization (EM) algorithm used find local maximum likelihood
partial trajectory. EM algorithm iterates following E step step
convergence derived likelihood function.
E step: Given current HMP parameters, compute expected sufficient statistics: [x],
[x, x0 ] [x] data set D. complex part algorithm. give
details below.
step: computed expected sufficient statistics, update new model parameters
next EM iteration:
[x, x0 ]
[x]
, xx0 =
.
qx =
[x]
[x]
show calculate expected sufficient statistics using forward-backward
message passing method.
trajectory devided N intervals interval separated
adjacent event changes. Assume trajectory spans time interval [0, ), let [v, w]
observed evidence time v w, including events time stamp v w, let
(v, w) set evidence excluding v w. Let subsystem states
restricted interval.
define
= P (Xt , [0, t]), = P ( [t, ] | Xt )
vectors (indexed possible assignments Xt ). Similarly, define corresponding
distribution excludes certain point evidence follows.
= P (Xt , [0, t)),

t+ = P ( (t, ] | Xt ) .

Denote j vector 0s except j-th position 1, denote ij matrix
0s except element i-th row j-th column 1.
able show derived expected sufficient statistics. time,
Z
E[T [x]] =
P (Xt | [0, ])x dt
0
N
1 Z ti+1
X
1
=
P (Xt , [0, ])x dt .
P ( [0, ])
ti
i=0

751

fiX U & HELTON

constant fraction beginning last line serves make total expected time
j sum . integral interval expressed
Z

w

Z

w

v exp(QS (t v))xx exp(QS (w t))w dt ,

P (Xt , [0, ])x dt =
v

v

QS QX except elements correspond transitions set
0.
equation expected transition counts similarly defined:
N 1

E[M [x, x0 ]] =

X
qx,x0
+
[
ti x,x0 t+i
P ( [0, ])
i=1
N
1 Z ti+1
X
+
ti exp(QS (t ti ))x,x0 exp(QS (ti+1 t))ti+1 dt] .
i=0

ti

integrals appearing E[T ] E[M ] computed via standard ODE solver, like
Runge-Kutta method (Press, Teukolsky, Vetterling, & Flannery, 1992). method uses
adaptive step size move quickly times expected changes slowly
times rapid transitions.
remaining problem calculate . Let QSS0 transitioning intensity
matrix HMP one subsystem another 0 . matrix QX ,
elements corresponding transitions 0 non-zero.
ti = ti1 exp(QSi1 (ti ti1 )) ,
ti = ti QSi1 Si ,
ti = exp(QSi (ti+1 ti ))ti+1 ,
ti = QSi1 Si ti .
forward-backward calculation, also trivial answer queries
P (Xt = x | [0, ]) =

1
xx .
P ( )

3.8 Continuous Time Bayesian Networks
HMPs good modeling many dynamic systems, limitations
systems multiple components state space grows exponentially number
variables. HMP model variable independencies therefore use unified
state X represent joint behavior involving components system.
section, show continuous time Bayesian network used address issue.
Nodelman et al. (2002) extend theory HMPs present continuous time Bayesian networks (CTBNs), model joint dynamics several local variables allowing transition
model local variable X Markov process whose parametrization depends
subset variables U .
752

fiI NTRUSION ETECTION USING CTBN

3.9 Definition
first give definition inhomogeneous Markov process called conditional Markov process. critical concept us formally introduce CTBN framework.
Definition 1 (Nodelman, Shelton, & Koller, 2003) conditional Markov process X inhomogeneous Markov process whose intensity matrix varies function current values set
discrete conditioning variables U . parametrized using conditional intensity matrix (CIM)
QX|U set homogeneous intensity matrices QX|u , one instantiation values u U .
call U parents X. set U empty, CIM simply standard intensity
matrix.
CIMs provide way model temporal behavior one variable conditioned
variables. putting local models together, joint structured model continuous
time Bayesian network.
Definition 2 (Nodelman et al., 2003) continuous time Bayesian network N set stochastic processes X consists two components: initial distribution PX0 , specified Bayesian
network B set random variables X, continuous transition model, specified using
directed (possibly cyclic) graph G whose nodes X X; UX denotes parents X G.
variable X X associated conditional intensity matrix, QX|UX .
dynamics CTBN quantitatively defined graph. instantaneous evolution
variable depends current value parents graph. quantitative description
variables dynamics given set intensity matrices, one value parents.
means transition behavior variable controlled current values parents.
standard notion d-separation Bayesian networks carries CTBNs.
graphs cyclic variables represent processes (not single random variables), implications
little different. variable (process) still independent non-descendants given parents,
still independent everything given Markov blanket (any variable either parent,
child, parent child). Cycles cause parents also children, provided
considered both, definitions still hold. importantly, notion given works
full trajectory variable question known. Therefore, X grandchildren
independent given Xs childrens values single instant. Rather, independent
given Xs childrens full trajectories time 0 last time interest.
amalgamate variables CTBN together, get single homogeneous Markov
process joint state space. joint state intensity matrix, rate 0 assigned
transition involves changing one variables value exact time.
intensities found looking value corresponding conditional intensity matrix
variable changes. diagonal elements negative row sums.
Forward sampling done quickly CTBN without generating full joint intensity
matrix. keep track next event time variable (sampled relevant exponential distribution given current values parent). select earliest
event time change variable (sampling multinomial distribution implied row
variables relevant intensity matrix). next event time variable changed
children must resampled, variables time must resampled due
memoriless property exponential distribution. way sequence events (a trajectory)
sampled.
753

fiX U & HELTON

3.10 Learning
context CTBNs, model parameters consist CTBN structure G, initial distribution P0 parameterized regular Bayesian network, conditional intensity matrices (CIMs)
variable network. section, assume CTBN structure known us,
focus parameter learning. also assume model irreducible. initial
distribution P0 becomes less important context CTBN inference learning, especially
time range becomes significantly large. Therefore, parameter learning context
estimate conditional intensity matrices QXi |Ui variable Xi , Ui set
parent variables Xi .
3.10.1 L EARNING C OMPLETE DATA
Nodelman et al. (2003) presented efficient way learn CTBN model fully observed
trajectories. complete data, know full instantiations variables whole
trajectory. know CIM governing transition dynamics variable
time. sufficient statistics [x, x0 |u] number times X transitions state x
x0 given parent instantiation u [x|u] P
total duration X stays state x
given parent instantiation u. denote [x|u] = x0 [x, x0 |u].
likelihood function decomposed

LN (q, : D) =
LXi (qXi |Ui : D)LXi (Xi |Ui : D))
(1)
Xi X


LX (qX|U : D) =

YY
u

[x|u]

qx|u

exp(qx|u [x|u])

(2)

x


LX ( : D) =

YY
u


0
xx
0 |u [x, x |u] .

(3)

x x0 6=x

put functions together take log, get log likelihood component
single variable X:
lX (q, : D) = lX (q : D) + lX ( : D)
XX
=
[x|u] ln(qx |u) q[x|u] [x|u]
u

+

x

XX X
u

[x, x0 |u] ln(xx0 |u )).

(4)

x x0 6=x

maximizing log likelihood function, model parameters estimated
qx|u =

[x|u]
,
[x|u]

xx0 |u =

754

[x, x0 |u]
.
[x|u]

(5)

fiI NTRUSION ETECTION USING CTBN

3.10.2 L EARNING NCOMPLETE DATA
Nodelman, Shelton, Koller (2005) present expectation maximization (EM) algorithm
learn CTBN model partially observed trajectories D. expected sufficient statistics
[x, x0 |u], expected number times X transitions state x x0 parent set
U takes values u, [x|u], expected P
amount time X stays state x
parent instantiation u. denote [x|u] x0 [x, x0 |u]. expected log likelihood
decomposed way Equation 4, except sufficient statistics [x, x0 |u], [x|u]
[x|u] replaced expected sufficient statistics [x, x0 |u], [x|u] [x|u].
EM algorithm CTBN works essentially way HMP. expectation step calculate expected sufficient statistics using inference method (will described
Section 3.11). maximization step update model parameters:

qx|u =

[x|u]
,
[x|u]

xx0 |u =

[x, x0 |u]
.
[x|u]

3.11 Inference
given CTBN model (partially) observed data, would like query model.
example, may wish calculate expected sufficient statistics EM algorithm.
3.11.1 E XACT NFERENCE
Nodelman et al. (2005) provide exact inference algorithm using expectation maximization
reason learn parameters partially observed data. exact inference algorithm requires flattening variables single Markov process performing inference
HMP. problem makes state space grow exponentially large. Therefore, exact
inference method feasible problems small state spaces.
3.11.2 PPROXIMATE NFERENCE
issue addressed below, much work done CTBN approximate inference. Nodelman, Koller, Shelton (2005) present expectation propagation algorithm. Saria,
Nodelman, Koller (2007) give another message passing algorithm adapts time granularity. Cohn, El-Hay, Friedman, Kupferman (2009) provide mean field variational approach.
El-Hay, Friedman, Kupferman (2008) show Gibbs sampling method approach using Monte
Carlo expectation maximization. Fan Shelton (2008) give another sampling based approach
uses importance sampling. El-Hay, Cohn, Friedman, Kupferman (2010) describe different expectation propagation approach.
estimate parameters models build two applications (NIDS HIDS),
employ inference algorithms including exact inference Rao-Blackwellized particle filtering
(RBPF) algorithm, depending model size. Ng et al. (2005) extended RBPF CTBNs.
model hybrid system containing discrete continuous variable. used particle
filters discrete variables unscented filters continuous variable. work
similar work method applying RBPF CTBNs, model contains discrete
variables evidence continuous intervals.
755

fiX U & HELTON

PORT
80
8080
443
113
5101
995
51730
59822

DESCRIPTION
World Wide Web HTTP
HTTP Alternate
HTTP protocol TLS/SSL
Authentication Service
Talarian TCP
pop3 protocol TLS/SSL
unknown
unknown

PORT
80
139
443
445
1863
2678
1170
110

DESCRIPTION
World Wide Wed HTTP
NETBIOS Session Service
HTTP protocol TLS/SSL
Microsoft-DS
MSNP
Gadget Gate 2 Way
AT+C License Manager
Post Office Protocol - Version 3

Figure 1: Ranking frequent ports MAWI dataset (left) LBNL dataset (right).

3.12 CTBN Applications
Although inference learning algorithms well developed CTBNs,
applications real world problems. Nodelman Horvitz (2003) used CTBNs
reason users presence availability time. Ng et al. (2005) used CTBNs monitor
mobile robot. Nodelman et al. (2005) used CTBNs model life event history. Fan Shelton
(2009) modeled social networks via CTBNs. previous work (Xu & Shelton, 2008) presented
NIDS host machine using CTBNs, include HIDS.

4. Anomaly Detection Using Network Traffic
section, present algorithm detect anomalies network traffic data using CTBNs.
focus single host network. sequence timing events (e.g. packet
transimission connection establishment) important network traffic flow. matters
many connections initiated past minute, also timing:
evenly spaced trace probably normal, came quick burst suspicious.
Similarly, sequence important. connections made sequentially increasing ports
likely scanning virus, whereas set ports random order likely
normal traffic. merely simple examples. would like detect complex
patterns.
typical machine network may diverse activities various service types (e.g.
HTTP, SMTP). destination port number roughly describes type service particular network activity belongs. worms propagate malicious traffic toward certain well known
ports affect quality associated services. looking traffic associated different
ports sensitive subtle variations appear aggregate trace information
across ports. Figure 1 shows popular ports ranked frequencies network
traffic datasets use (described depth later). services are, extent,
independent other. therefore model ports traffic CTBN submodel.
denote whole observed traffic sequences particular host, j traffic
associated port j.
756

fiI NTRUSION ETECTION USING CTBN

G

N
H

Pin

Pout

Cinc

Cdec

Figure 2: CTBN model network traffic plate model. N number port .

4.1 CTBN Model Network Traffic
use port-level submodel previous work (Xu & Shelton, 2008). latent
variable H four fully observed toggle variables: Pin , Pout , Cinc , Cdec .
nodes packet-in, Pin , packet-out, Pout , represent transmission packet
host. intrinsic state: transmission packet essentially instantaneous
event. Therefore events (or transitions) without state. modeled using
toggle variable event evidence change state variable rate
transition associated state required same.
nodes connection-increase Cin connection-decrease Cdec together describe status
number concurrent connections C active host. Notice C increase
decrease one given event (the beginning ending time connection). assume
arrival new connection termination existing connection independent
number connections. Thus intensity connection starts (or stops)
connections. Therefore, also modeled toggle variables.
Node H 8 states represent different abstract attributes machines internal state.
toggle variables (Pin , Pout , Cinc Cdec ) allowed change 2 states
H required rate states. 2 hidden states per toggle
variable chosen balance expressive power model efficiency.
previous work, assumed traffic associated different ports independent
other, port-level submodels isolated. remove restriction introducing
another latent variable G ties port submodels together. full model shown Figure 2.
4.2 Parameter Learning Using RBPF
calculate expected sufficient statistics E-step EM parameter learning, exact
inference algorithm Nodelman et al. (2002) flattens variables joint intensity matrix
reasons resulting homogeneous Markov process. time complexity exponential
number variables. example, 9 port models, network contains 46 variables
total. Approximate inference techniques like clique tree algorithm (Nodelman et al., 2002),
message passing algorithms (Nodelman et al., 2005; Saria et al., 2007), importance sampling (Fan
757

fiX U & HELTON

& Shelton, 2008) Gibbs sampling (El-Hay et al., 2008) overcome problem sacrificing
accuracy.
notice model nice tree structure makes Rao-Blackwellized particle
filtering (RBPF) perfect fit. RBPF uses particle filter sample portion variables
analytically integrates rest. decomposes model structure efficiently thus reduces
sampling space.
denote N port-level hidden variables H1 , ..., HN , posterior
distribution
QN
whole model factorized P (G, H1 , ..., HN | ) = P (G | ) i=1 P (Hi | G, ). Note
G Hi processes, probability density complete trajectories. use
particle filter estimate Gs conditional distribution P (G | ) set sampled trajectories
G. difficult sample directly posterior distribution, use importance sampler
sample particle proposal distribution particles weighted ratio
likelihood posterior distribution likelihood proposal distribution (Doucet
et al., 2000). Since variable G latent parents, use forward sampling
sample particles P (G) weight particle simply likelihood
conditioned trajectory G (Fan & Shelton, 2008). port-level submodel dseparated rest network, given full trajectory G (see Section 3.9 d-separation
CTBNs). Since small (only 8 hidden states), marginalized exactly.
is, calculate P (i | G) (where portion trajectory submodel i) exactly,
marginalizing Hi - recursions Section 3.7.
expected sufficient statistics (ESS) variable X CTBN TX|U [x|u], expected amount time X stays state x given parent instantiation u, MX|U [x, x0 |u],
expected number transitions state x x0 given Xs parent instantiation u. Let g P (G),
)
= 1, . . . , particles. define likelihood weights wi = PP(g(g|
) let
P
W = wi sum weights. general importance sampling allows expected
sufficient statistic estimated following way, SS sufficient statistic:

E(g,h1 ,...,hN )P (G,H1 ,...,HN | ) [SS(g, h1 , . . . , hN )]
= EgP (G| ) Eh1 ,...,hN P (H1 ,...,HN |g, ) [SS(g, h1 , . . . , hN )]
1 X
wi Eh1 ,...,hN P (H1 ,...,HN |gi , ) [SS(g , h1 , . . . , hN )] .

W


expected sufficient statistics whole model two categories: depend
g, ESS(g), depend port model k, ESS(g, hk , k ). ESS(g) simply
summation counts (the amount time G stays state, number times G
transitions one state another) particles, weighted particle weights:

EgP (G| ) [SS(g)]

1 X
wi SS(g ) .
W


758

(6)

fiI NTRUSION ETECTION USING CTBN

Function Wholemodel Estep
input: current model , evidence
output: Expected sufficient statistics ESS
ESS := {ESS(g), ESS(s1 , g), . . . , ESS(sn , g)}
Initialize ESS empty
particle g {g 1 , . . . , g }, g P (G)
Sj {S1 , . . . , SN }
[P (j |g ), ESS(sj , g )] = Submodel Estep(g , [Sj ], j )
Sj {S1 , . . . , SN }
Q
ESS(sj , g) = ESS(sj , g) + k6=j P (k |g ) ESS(sj , g )
i)
ESSgi = CountGSS(gQ
ESS(g) = ESS(g) + j P (j |g ) ESSgi
Return ESS

Figure 3: Rao-Blackwellized particle filtering Estep whole model
ESS(g, hk , k ) calculated submodel independently:
Eg,h1 ,...,hN P (G,H1 ,...,HN | ) [SS(g, hk , k )]
Z
1 X
wi

P (hk |g , k )SS(g , hk , k ) dhk
W
hk

Q
Z
1 X j P (j |g )
P (hk |g , k )SS(g , hk , k ) dhk
=
W
P ( )
hk

Z
X

1

P (j |g )
P (hk , k |g )SS(g , hk , k ) dhk .
W
hk


(7)

j6=k

integrals possible trajectories hidden process Hk . first line holds
d-separation (we need average submodel k, given assignment G). second
line expands weight. last line combines weight term submodel k terms
integral get likelihood hk submodel data. constant proportionality
P
cancel subsequent maximization, reconstructed noting x TX|U [x|u]
total time
R interval.
last integral, hk P (hk , k |g )SS(g , hk , k ) dhk , P (j |g ) calculated using
technique described Nodelman et al. (2005), exact ESS calculation. calculations
similar integrals Section 3.7, except intensity matrices change interval
interval (they function sampled trajectory gi ).
full E-step algorithm shown Figure 3 (sk represents variables submodel
k). Function Submodel Estep calculates expected sufficient statistics likelihood
subnet model (Equation 7). Function CountGSS counts empirical time transition statistics
sampled trajectory G (Equation 6).
EM, use ESS true sufficient statistics maximize likelihood
respect parameters. regular CTBN variable X (such hidden variable G
H), Equation 5 performs maximization. toggle variables, e.g. Pi , likelihood
759

fiX U & HELTON

component toggle variable


MP

QPi |ui exp(QPi |u [U = u])

u

found setting qx|u value (QPi |u ) x (tieing parameters)
simplifying product x Equation 2. Thus maximum likelihood parameter estimate
QPi |u =

MPi
[U = u]

MPi number events variable Pi QPi |u parameter: rate
switching.
synchronize particles end window (see Section 6.1) resample
normal particle filter points. is, propagate particles forward, stop
end window, resample based weights, continue new set
particles. general, particles aligned time, except resampling points.
4.3 Online Testing Using Likelihood
CTBN model fitted historic data, detect attacks computing likelihood
window data (see Section 6.1) model. likelihood falls threshold,
flag window anomalous. Otherwise, mark normal.
experiments, fix window fixed time length, Tw . Therefore,
window interest starts time , wish calculate p( [T, + Tw ] | [0, ]) [s, t]
represents observed connections packets time time t. Again, use RBPF
estimate probability. samples time represent prior distribution P (G | [0, ]).
Propagating forward across window length Tw produces set trajectories G,
g . submodel k evalute P (k [T, + Tw ] | g ) exact marginalization (the sum
vector +Tw , forward message). weighted average (over samples g k ) product
submodel probabilities estimate P ( [T, + Tw ] | [0, ]).

5. Anomaly Detection Using System Calls
turn problem detecting anomalies using system call logs.
5.1 CTBN Model System Calls
System call logs monitor kernel activities machines. record detailed information
sequence system calls operating system. Many malicious attacks host revealed
directly internal logs.
analyze audit log format SUNs Solaris Basic Security Module (BSM) praudit audit
logs. user-level kernel event record least three tokens: header, subject, return.
event begins header format of: header, record length bytes, audit record version
number, event description, event description modifier, time date. subject line consists of:
subject, user audit ID, effective user ID, effective group ID, real user ID, real group ID, process
ID, session ID, terminal ID consisting device machine name. return return
value indicating success event closes record.
760

fiI NTRUSION ETECTION USING CTBN

H

S1

S2

Sn

Figure 4: CTBN model system call data

}

s1, s2, ..., sk

ti-1 ti-1+t

ti+t

ti

ti+1 ti+1+t

time

Figure 5: System call traces finite resolution clock (resolution = )
construct CTBN model similar port-level network model. Individual system calls
S1 , ..., SN , event description fields header token, transiently observed:
happen instantaneously duration. treat toggle variables like packets
network model. also introduce hidden variable H parent system calls variables
allow correlations among them. hidden variable designed model internal state
machine, although semantic meaning imposed method. Put together, system
call model looks like Figure 4.
state space hidden variable H size m, transition rate matrix H



QH =


qh1
q h2 h1
..
.

q h1 h2
qh2
..
.

q hm h1

q hm h2

. . . q h1 hm
. . . q h2 hm
..
..
.
.
. . . qhm




.


transition intensity rate toggle variable given current value parent H
qs|hi , = 1, ..., m.
estimate CTBN model parameters, use expectation maximization (EM)
algorithm. expected sufficient statistics need calculate model
Mhi hj , expected number times H transitions state j;
Thi , expected amount time H stays state i;
Ms|hi , expected number times system call evoked H state i.
761

fiX U & HELTON

maximum likelihood parameters
Mhi hj
Thi
Ms|hi
=
.
Thi

q hi hj =
qs|hi

5.2 Parameter Estimation Finite Resolution Clocks
finite resolution computer clocks, multiple instantaneous events (system calls)
occur within single clock tick. Therefore audit logs, batch system calls may recorded
executed time point, rather real time stamp, result finite
time accuracy. However, correct order events kept logs. is, know exactly
system call S2 follows S1 recorded order audit logs. Thus system
call timings partially observed. type partial observation previously
considered CTBN inference. typical trajectory [0, ] system call data shown
Figure 5: batch system calls evoked time ti next clock tick,
followed quiet period arbitrary length, yet another bunch events time
ti+1 on.
Let t1:t2 denote evidence interval [t1, t2), t1:t2+ denote evidence [t1, t2],
t1 :t2 denote evidence (t1, t2). define vectors
ti = p(Ht , 0:ti )


t+i = p(t+ :T |Ht+ )




Ht value H prior transition ti , Ht+ value afterward.


also define vectors
ti = p(Hti , 0:t+ )


ti = p(ti :T |Hti )
evidence transition time ti included. follow forward-backward algorithm
compute ti ti ti event. this, split interval [ti , ti+1 )
spike period [ti , ti + ) (t one resolution clock), batch
system calls, quite period [ti + , ti+1 ) events exist, propagations
separately.
spike period [ti , ti + ), observed event sequence s1 , s2 , ..., sk , construct
artificial Markov process X following intensity matrix.




QX =



QH Q1 0
...
0
0 QH Q2 . . .
0
..
..
..
..
..
.
.
.
.
.
0
0
. . . QH Qk
0
0
...
0 QH
762





.



fiI NTRUSION ETECTION USING CTBN





QH =


P
qh1 sS qs|h1
q h2 h1
..
.

qh2

q hm h1

q h1 h2
P
sS qs|h2
..
.

...
...
..
.
. . . qhm

q hm h2

q h1 hm
q h2 hm
..
.
P
sS qs|hm











Qi =


qsi |h1
0
..
.
0

0
qsi |h2
..
.

...
...
..
.

0
0
..
.

0

0

qsi |hm







X tracks evidence sequence s1 s2 ... sk . QX square block matrix dimension
(k + 1). block matrix. subsystem X k + 1 blocks states.
first block represents state H events. second block represents H exactly
one event, s1 , happens. third block represents H s1 followed s2 happens,
on. last block represents H events finish executing order. subsystem
zero transition intensities everywhere except along sequence pass. diagonal QH
matrix QH except transition intensities system call variables
subtracted. full system includes transitions observed.
transition rates set zero (to force system agree evidence), conditioning
change diagonal elements rate matrix (Nodelman et al., 2002). Within
k + 1 states block, H freely change value. Therefore, non-diagonal elements
QH intensities QH . Upon transitioning, X transit state
another according event sequence. Therefore, blocks 0 matrices except
immediate right diagonal blocks. transition behavior described matrix
Qi . Qi 0 intensities non-diagonal entries H change simultaneously.
diagonal element Qi (h, h) intensities event si happening, given current value
hidden state h.
take forward pass example describe propagation; backward pass
performed similarly. Right ti , ti dimensions. expand m(k + 1) dimensions
form ti non-zero probabilities first states. ti describes
distribution subsystem X. ti eQX represents probability distribution time ti + ,
given prefix observed sequence occurred. take last state probabilities
condition entire sequence happening, thus resulting m-dimensional vector, ti +t .
quiet period [ti + , ti+1 ), evidence observed. Therefore ti +t propagated
ti+1 using QH , rate matrix conditioned H events occuring:
ti+1 = ti +t exp(QH (ti+1 ti )) .
done full forward-backward pass whole trajectory, calculate expected sufficient statistics Mhi hj , Thi Ms|hi . Again, refer work Nodelman
et al. (2005) algorithm.
763

fiX U & HELTON

5.3 Testing Using Likelihood
learned model normal process system call logs, calculate
log-likelihood future process model. log-likelihood compared
predefined threshold. threshold, possible anomaly indicated. single
hidden variable, calculations done exactly.

6. Evaluation
evaluate methodology, constructed experiments two different types data: network
traffic traces system call logs. following sections, show experiment results
tasks.
dynamic Bayesian network (DBN) another popular technique graphical modeling
temporal data. slice time, events without state changes (instantaneous events)
difficult model. reasonable time resolution result multiple events
variable one time period. standard way encoding DBN. use toggle
variable, records parity number events time interval. Furthermore,
NIDS, events bursty. active times, multiple packets emited per second.
inactive times, may activity hours. Finding suitable sampling rate
maintains efficency model difficult. HIDS, problem acute.
know way modeling timing ambiguity DBN without throwing away timing
information adding mathematical framework essentially turns DBN CTBN
described here. general, could find suitable way apply DBN problems
without essentially turning DBN CTBN finely slicing time applying
numeric tricks speed inference amount converting stochastic matrices rate
matrices using numeric integration matrix exponential.
compared current adaptive methods problem individually. include nearest neighbor, support vector machines, sequence time-delaying embedding. give
details methods below.
6.1 Experiment Results Network Traffic
section, present experiment results NIDS.
6.1.1 DATASETS
verify approach two publicly available real network traffic trace repositories: MAWI
working group backbone traffic MAWI LBNL/ICSI internal enterprise traffic LBNL.
MAWI backbone traffic part WIDE project collected raw daily packet
header traces since 2001. records network traffic inter-Pacific tunnel
Japan USA. dataset uses tcpdump IP anonymizing tools record 15-minute
traces every day, consists mostly traffic Japanese universities. experiment,
use traces January 1st 4th 2008, 36,592,148 connections total time
one hour.
LBNL traces recorded medium-sized site, emphasis characterizing internal enterprise traffic. Publicly released anonymized form, LBNL data collects
764

fiI NTRUSION ETECTION USING CTBN

# packets flowing source destination
# packets flowing destination source
# connections source last 5 seconds
# connections destination last 5 seconds
# different services source last 5 seconds
# different services destination last 5 seconds
# connections source last 100 connections
# connections destination last 100 connections
# connections port source last 100 connections
# connections port destination last 100 connections
Figure 6: Features nearest neighbor approach work (Lazarevic et al., 2003).
100 hours network traces thousands internal hosts. publicly released, take
one hour traces January 7th, 2005 (the latest date available), 3,665,018 total connections.
6.1.2 W ORM ETECTION
start problem worm detection. split traffic traces host: half training
half testing. learn CTBN model training data hosts. Since
network data available clean traffic known intrusions, inject real attack traces
testing data. particular, inject IP Scanner, W32.Mydoom, Slammer. slide
fixed-time window testing traces, report single log-likelihood value sliding
window, compare predefined threshold. threshold, predict
abnormal time period. define ground truth window abnormal attack
traffic exists interval, normal otherwise. window size use 50 seconds.
consider windows contain least one network event.
compare method employing RBPF previous factored CTBN model (Xu &
Shelton, 2008), connection counting, nearest neighbor, Parzen-window detector (Yeung & Chow,
2002), one-class SVM spectrum string kernel (Leslie, Eskin, & Noble, 2002).
connection counting method straightforward. score window number
initiated connections window. worms aggregate many connections short time,
method captures particular anomaly well.
make nearest neighbor competitive, try extract reasonable set features. follow
feature selection work Lazarevic et al. (2003), use total 23 features.
features available data. available shown Figure 6. Notice
features associated connection record. apply nearest neighbor method
window based testing framework, first calculate nearest distance connection inside
window training set (which composed normal traffic only), assign maximum
among score window. Similarly, Parzen window approach, apply
feature set assign maximum density among connections inside window
score window.
Besides feature-based algorithms, would also like see sequence-based
approaches compare methods. algorithms widely used network anomaly
detection. Like approach, treat traffic traces stream data sequential contexts
765

fiX U & HELTON

1

1

0.8

0.8

0.8

0.6

0.4

Nearest Neighbor
Connection Count
Parzen Window
SVMSpectrum
CTBN, factored
CTBN, RBPF100

0.2

0
0

0.02

0.04
0.06
False Positive Rate

0.08

0.6

0.4

Nearest Neighbor
Connection Count
Parzen Window
SVMSpectrum
CTBN, factored
CTBN, RBPF100

0.2

0
0

0.1

0.02

0.08

0.6

0.4

0
0

0.1

1

0.8

0.8

0.8

0.6

Nearest Neighbor
Connection Count
Parzen Window
SVMSpectrum
CTBN, factored
CTBN, RBPF100

0
0

0.02

0.04
0.06
False Positive Rate

IP Scanning

0.08

0.1

0.6

0.4

Nearest Neighbor
Connection Count
Parzen Window
SVMSpectrum
CTBN, factored
CTBN, RBPF100

0.2

0
0

0.02

0.04
0.06
False Positive Rate

Mydoom

0.08

0.1

True Positive Rate

1

0.2

0.02

0.04
0.06
False Positive Rate

0.08

0.1

Slammer

1

0.4

Nearest Neighbor
Connection Count
Parzen Window
SVMSpectrum
CTBN, factored
CTBN, RBPF100

0.2

Mydoom

True Positive Rate

True Positive Rate

LBNL

IP Scanning

0.04
0.06
False Positive Rate

True Positive Rate

1

True Positive Rate

True Positive Rate

MAWI

explored. One-class SVM spectrum string kernel chosen comparison.
implemented spectrum kernel LIBSVM library (Chang & Lin, 2001). give network
activities (such connection starting ending, packet emmision receipt) inside portlevel submodel distinct symbol. sequence symbols fed algorithm inputs.
decision surface trained normal training traffic. testing, sliding window,
distance window string decision hyperplane reported window score.
also tried experiments using edit distance kernel, results dominated spectrum
kernel, report here.

0.6

0.4

Nearest Neighbor
Connection Count
Parzen Window
SVMSpectrum
CTBN, factored
CTBN, RBPF100

0.2

0
0

0.02

0.04
0.06
False Positive Rate

0.08

0.1

Slammer

Figure 7: ROC curves testing results IP scanning attack, Mydoom attack Slammer attack.
= 0.001. Top: MAWI. Bottom: LBNL.

injecting attack traffic, randomly pick starting point somewhere first half
test trace insert worm traffic duration equal times length full testing
trace. shorter is, harder detect anomaly. choose 0.02%
experiments work challenge detection tasks. also scaled back rates
worms. running full speed, worm easy detect method. slows
(and thus blends background traffic better), becomes difficult detect. let
scaling rate (e.g. 0.1 indicates worm running one-tenth normal speed).
method, set state space variable G 4 variable H 8. use
100 samples particle filtering, resample particles every 50 seconds. SVM
spectrum kernel method, choose sub-sequence length 5 parameter 0.8.
show ROC curves methods Figure 7. curves show overall performance 10 active hosts dataset. point curves corresponds
766

fiI NTRUSION ETECTION USING CTBN

1

1

0.8

0.8
True Positive Rate

True Positive Rate

different threshold algorithm. CTBN method out-performs algorithms except
single case Mydoom attack background LBNL traffic. many cases,
advantages CTBN approach pronounced.
MAWI data, factored non-factored CTBN models perform comparably.
believe data captures connections traverse trans-Pacific link.
Therefore, connections machine represented. makes reasoning
global pattern interaction machine difficult. LBNL data, one attack (IP
scanning) shows advantage non-factored model. One attack (Mydoom) shows distinct
advantage. one attack (Slammer) indicates advantage, depending desired false
positive rate. demonstrate advantage jointly modeling traffic across ports,
although clear advantage uniform traffic patterns attack types.

0.6

0.4

0.2

0.6

0.4

0.2
Connection Count
CTBN, RBPF100

0
0

0.02

0.04
0.06
False Positive Rate

0.08

Connection Count
CTBN, RBPF100

0.1

0
0

0.02

0.04
0.06
False Positive Rate

0.08

0.1

Figure 8: ROC curves testing results Slammer attack MAWI dataset demonstrating
effect slowing attack rate. Left: = 0.01. Right: = 0.001

also show ROC curves shift scale back worm running speed Figure 8.
firewalls built sensitive block malicious traffic, worms act stealthy
sneak through. demonstrate robustness method compared best competitor
(connection counts) speed worms attack.
6.1.3 H OST DENTIFICATION
Identifying individual hosts based network traffic patterns another useful application
model. instance, household usually installs network router. family members
computer connected router. outside Internet, network traffic going
router behaves coming one peer, actually coming different people.
Dad possibly read sports news kids surf social networks. interesting well
useful tell family member contributing current network traffic. Host identification
also used combat identity theft. network identity abused attacker, host
identification techniques help network administrator tell whether current network traffic
host consistent usual pattern not.
767

fiX U & HELTON

first set experiments construct host model fitting competition. 10
hosts picked worm detection tasks LBNL dataset compose testing pool. learn
coupled CTBN model host. split test traces (clean) particular host
segments lengths 15 seconds. segments, compute log-likelihood
segment learned model hosts (including own), label segment
host achieves highest value. compute confusion matrix C whose element Cij
equals fraction test traces host model j highest log-likelihood. expect
see highest hit rates fall diagonals ideally host best described
model. Table 9 shows results dataset LBNL. vast majority traffic windows
assigned correct host. exception host 1, diagonals distinctly higher
elements row. comparison, performed experiment using SVM
spectrum kernel method. Again, selected sub-sequence length 5 parameter
0.8. tried multiple methods normalization (of distance hyperplane)
variations parameters. produced poor results almost windows assigned
single host. omit table results.
Host
1
2
3
4
5
6
7
8
9
10

1
0.09
0.06
0
0
0
0
0.25
0
0.04
0

2
3
4
0.41 0.47 0
0.50 0.31 0
0
1
0
0
0
1
0.08 0.13 0
0.20 0.03 0
0
0.06 0.02
0.08 0.28 0
0.05 0.13 0.01
0.03 0.18 0.01

5
6
7
8
9
10
0
0
0
0.03 0
0
0
0.13 0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0.68 0.06 0.03 0.01 0
0.01
0.01 0.74 0
0.02 0
0
0
0
0.66 0
0
0.01
0
0.05 0
0.59 0
0
0.01 0.01 0.02 0
0.73 0
0
0.15 0.03 0.03 0
0.57

Figure 9: Confusion matrix LBNL host identification using CTBN
second experiment host traffic differentiation task. mingle network traffic
another host analyzed host. expect detection method successfully tell apart
two. verify idea, pick one host among 10 choose LBNL dataset
split traffic evenly training testing. learn model training data.
testing data, randomly choose period inject another hosts traffic worm.
goal identify period abnormal since hosts traffic longer behavior.
Figure 10 displays results two combination tests. parameters injecting
traffic worm = 0.02, = 0.001. left graph, nearest neighbor Parzen
window curve overlap, CTBN curves overlap. right graph, coupled CTBN curve
substantially outperforms curves.
6.2 Experiment Results System Call Logs
section, present experiment results HIDS.
768

fi1

1

0.8

0.8

0.6
0.4

Nearest Neighbor
Connection Count
Parzen Window
SVMSpectrum
CTBN, factored
CTBN, RBPF10

0.2
0
0

0.02

0.04
0.06
False Positive Rate

0.08

True Positive Rate

True Positive Rate

NTRUSION ETECTION USING CTBN

Nearest Neighbor
Connection Count
Parzen Window
SVMSpectrum
CTBN, factored
CTBN, RBPF10

0.6
0.4
0.2
0
0

0.1

0.02

0.04
0.06
False Positive Rate

0.08

0.1

Figure 10: ROC curves testing results host identification LBNL data. Left: host 1,
Nearest neighbor curve Parzen window curve overlap, CTBN curves overlap.
Right: host 2.

Week
1
2
3
4
5
6
7

# normal
processes
786
645
775
615
795
769
584

# attack
processes
2
4
20
331
10
24
0

System Call
close
ioctl
mmap
open
fcntl
stat
access

# occurrence
123403
68849
60886
42479
7416
6429
2791

System Call
execve
chdir
chroot
unlink
chown
mkdir
chmod

# occurrence
1741
1526
328
26
23
4
1

Figure 11: Left: DARPA BSM process summary. Right: DARPA BSM system call summary
6.2.1 DATASET
dataset used 1998 DARPA Intrusion Detection Evaluation Data Set MIT Lincoln
Laboratory. Seven weeks training data contain labeled network-based attacks midst
normal background data publicly available DARPA website. Solaris Basic Security
Module (BSM) praudit audit data system call logs provided research analysis. follow
Kang, Fuller, Honavar (2005) cross-index BSM logs produce labeled list file
labels individual processes. resulting statistics shown left table Figure 11.
frequency system calls appearing dataset summarized descending order
right Figure 11.
6.2.2 NOMALY ETECTION
experimental goal detect anomalous processes. train CTBN model normal
processes test mixture normal attack processes. state space
769

fi1

1

0.8

0.8
True Positive Rate

True Positive Rate

X U & HELTON

0.6
0.4
CTBN
SVMSpectrum
Stide
Nearest Neighbor

0.2
0
0

0.01

0.02
0.03
False Positive Rate

0.04

0.6
0.4
CTBN
SVMSpectrum
Stide
Nearest Neighbor

0.2

0.05

0
0

0.01

0.02
0.03
False Positive Rate

0.04

0.05

Figure 12: ROC curves BSM data detection. Left: Training week 1 combined testing
results week 2 7; Right: Training week 3 test week 4, Stide curve
CTBN curve overlap

hidden variable H set 2. log-likelihood whole process learned model
represents score process. compare score predefined threshold classify
process normal one system abuse.
implement sequence time-delaying embedding (stide) stide frequency threshold
(t-stide) comparison (Warrender, Forrest, & Pearlmutter, 1999). two algorithms build
database previously seen normal sequences system calls compare testing sequences
it. straightforward perform well empirically system call log
datasets. choose parameter k, sequence length 5, h, locality frame length,
50. results t-stide shown following resulting graphs since overlapped
stide almost cases.
approaches compare nearest neighbor one-class SVM spectrum
string kernel edit distance kernel. follow Hu et al. (2003) transform process
feature vector, consisting occurrence numbers system call process. nearest
distance testing process training set processes assigned score.
one-class SVM, processes composed strings system calls. Normal processes used
learning bounding surface signed distance assigned score. set subsequence length 5 parameter 0.5. Again, since edit distance kernel results
dominated spectrum kernel, show them.
Figure 12 displays results two experiment settings. left graph, train
model normal processes week 1 test processes weeks 2 7.
right graph, train normal processes week 3 test processes week
4, richest attack processes volume. attacks relatively rare compared normal
traffic, interested region ROC curves small false positive rates.
show curves area false positive rate falls region [0, 0.05].
CTBN method beats nearest neighbor SVM spectrum kernel experiments. stide
performs slightly better method combined test, achieves accuracy
770

fiI NTRUSION ETECTION USING CTBN

experiment using week 3 testing week 4. advantage CTBN model
stide easily combined prior knowledge data sources (such
network data NIDS). demonstrate loss performance flexibility.

7. Conclusions
realm temporal reasoning, introduced two additions CTBN literature. First,
demonstrated Rao-Blackwellized particle filter continuous evidence. Second, demonstrated learn reason data contains imprecise timings, still refraining
discretizing time.
realm intrusion detection, demonstrated framework performs well two
related tasks different data types. concentrating purely event timing, without
consideration complex features, able out-perform existing methods. continuoustime nature model aided greatly modeling bursty event sequences occur systems
logs network traffic. resort time slicing, either producing rapid slices
inefficient quite periods, lengthy slices miss timing bursty events.
combination two sources information (system calls network events) would
straight-forward model produced. believe would result accurate
detection. collection data difficult, however; leave interesting next step.

Acknowledgments
project supported Intel Research UC MICRO, Air Force Office Scientific
Research (FA9550-07-1-0076), Defense Advanced Research Project Agency (HR001109-1-0030).

References
Agosta, J. M., Duik-Wasser, C., Chandrashekar, J., & Livadas, C. (2007). adaptive anomaly
detector worm detection. Workshop Tackling Computer Systems Problems
Machine Learning Techniques.
A.Hofmeyr, S., Forrest, S., & Somayaji, A. (1998). Intrusion detection using sequences system
calls. Journal Computer Security, 6, 151180.
Cha, B. (2005). Host anomaly detection performance analysis based system call neuro-fuzzy
using soundex algorithm n-gram technique. Systems Communications (ICW).
Chang, C.-C., & Lin, C.-J. (2001). LIBSVM: library support vector machines. http://
www.csie.ntu.edu.tw/cjlin/libsvm.
Cohn, I., El-Hay, T., Friedman, N., & Kupferman, R. (2009). Mean field variational approximation
continous-time Bayesian networks. Uncertainty Artificial Intelligence.
Dewaele, G., Fukuda, K., & Borgnat, P. (2007). Extracting hidden anomalies using sketch non
Gaussian multiresulotion statistical detection procedures. ACM SIGCOMM.
Doucet, A., de Freitas, N., Murphy, K., & Russel, S. (2000). Rao-Blackwellised particle filtering
dynamic Bayesian networks. Uncertainty Artificial Intelligence.
771

fiX U & HELTON

El-Hay, T., Cohn, I., Friedman, N., & Kupferman, R. (2010). Continuous-time belief propagation.
Proceedings Twenty-Seventh International Conference Machine Learning.
El-Hay, T., Friedman, N., & Kupferman, R. (2008). Gibbs sampling factorized continous-time
Markov processes. Uncertainty Artificial Intelligence.
Eskin, E. (2000). Anomaly detection noisy data using learned probability distributions.
International Conference Machine Learning.
Eskin, E., Arnold, A., Prerau, M., Portnoy, L., & Stolfo, S. (2002). geometric framework
unsupervised anomaly detection: Detecting intrusions unlabeled data. Barbara, D., &
Jajodia, S. (Eds.), Applications Data Mining Computer Security. Kluwer.
Fan, Y., & Shelton, C. R. (2008). Sampling approximate inference continuous time Bayesian
networks. Symposium Artificial Intelligence Mathematics.
Fan, Y., & Shelton, C. R. (2009). Learning continuous-time social network dynamics. Proceedings Twenty-Fifth International Conference Uncertainty Artificial Intelligence.
Forrest, S., A.Hofmeyr, S., Somayaji, A., & A.Longstaff, T. (1996). sense self unix processes. IEEE Symposium Security Privacy, pp. 120128.
Hu, W., Liao, Y., & Vemuri, V. (2003). Robust support vector machines anomaly detection
computer security. International Conference Machine Learning Applications.
Kang, D.-K., Fuller, D., & Honavar, V. (2005). Learning classifiers misuse detetction using
bag system calls representation. IEEE International Conferences Intelligence
Security Informatics.
Karagiannis, T., Papagiannaki, K., & Faloutsos, M. (2005). BLINC: Multilevel traffic classification
dark. ACM SIGCOMM.
Kruegel, C., Mutz, D., Robertson, W., & Valeur, F. (2003). Bayesian event classification intrusion
detection. Annual Computer Security Applications Conference.
Lakhina, A., Crovella, M., & Diot, C. (2005). Mining anomalies using traffic feature distributions.
ACM SIGCOMM, pp. 2126.
Lazarevic, A., Ertoz, L., Kumar, V., Ozgur, A., & Srivastava, J. (2003). compare study anomaly
detection schemes network intrusion detection. SIAM International Conference Data
Mining.
LBNL.
LBNL/ICSI enterprise tracing project..
enterprise-tracing/Overview.html/.

http://www.icir.org/

Leslie, C., Eskin, E., & Noble, W. S. (2002). spectrum kernel: string kernel SVM protein
classification. Pacific Symposium Biocomputing 7:566-575.
Malan, D. J., & Smith, M. D. (2005). Host-based detection worms peer peer cooperation. Workshop Rapid Malcode.
MAWI. MAWI working group traffic archive.. http://mawi.nezu.wide.ad.jp/mawi/.
Moore, A. W., & Zuev, D. (2005). Internet traffic classification using Bayesian analysis techniques.
ACM SIGMETRICS.
Ng, B., Pfeffer, A., & Dearden, R. (2005). Continuous time particle filtering. National Conference
Artificial Intelligence, pp. 13601365.
772

fiI NTRUSION ETECTION USING CTBN

Nodelman, U., & Horvitz, E. (2003). Continuous time Bayesian networks inferring users presence activities extensions modeling evaluation. Tech. rep. MSR-TR-2003-97,
Microsoft Research.
Nodelman, U., Koller, D., & Shelton, C. R. (2005). Expectation propagation continuous time
Bayesian networks. Uncertainty Artificial Intelligence, pp. 431440.
Nodelman, U., Shelton, C. R., & Koller, D. (2002). Continuous time Bayesian networks. Uncertainty Artificial Intelligence, pp. 378387.
Nodelman, U., Shelton, C. R., & Koller, D. (2003). Learning continuous time Bayesian networks.
Uncertainty Artificial Intelligence, pp. 451458.
Nodelman, U., Shelton, C. R., & Koller, D. (2005). Expectation maximization complex duration
distributions continuous time Bayesian networks. Uncertainty Artificial Intelligence,
pp. 421430.
Press, W. H., Teukolsky, S. A., Vetterling, W. T., & Flannery, B. P. (1992). Numerical Recipes C
(Second edition). Cambridge University Press.
Qin, X., & Lee, W. (2004). Attack plan recognition prediction using causal networks. Annual
Computer Security Application Conference, pp. 370379.
Rieck, K., & Laskov, P. (2007). Language models detection unknown attacks network
traffic. Journal Computer Virology.
Saria, S., Nodelman, U., & Koller, D. (2007). Reasoning right time granularity. Uncertainty
Artificial Intelligence.
Simma, A., Goldszmidt, M., MacCormick, J., Barham, P., Black, R., Isaacs, R., & Mortier, R.
(2008). CT-NOR: Representing reasoning events continuous time. Uncertainty Artificial Intelligence.
Soule, A., Salamatian, L., Taft, N., Emilion, R., & Papagiannali, K. (2004). Flow classification
histogram. ACM SIGMETRICS.
Soule, A., Salamatian, K., & Taft, N. (2005). Combining filtering statistical methods
anomaly detection. Internet Measurement Conference, pp. 331344.
Tandon, G., & Chan, P. K. (2005). Learning useful system call attributes anomaly detection.
Florida Artificial Intelligence Research Society Conference, pp. 405-410.
Warrender, C., Forrest, S., & Pearlmutter, B. (1999). Detecting intrusions using system calls: Alternative data models. IEEE Symposium Security Privacy, IEEE Computer Society.
Xu, J., & Shelton, C. R. (2008). Continuous time Bayesian networks host level network intrusion
detection. European Conference Machine Learning.
Xu, K., Zhang, Z.-L., & Bhattacharyya, S. (2005). Profiling internet backbone traffic: Behavior
models applications. ACM SIGCOMM.
Ye, N., Emran, S. M., Chen, Q., & Vilbert, S. (2002). Multivariate statistical analysis audit trails
host-based intrusion detection. IEEE Transactions Computers, 51(7), 810820.
Yeung, D.-Y., & Chow, C. (2002). Parzen-window network intrusion detectors. International
Conference Pattern Recognition.
773

fiX U & HELTON

Yeung, D.-Y., & Ding, Y. (2002). User profiling intrusion detection using dynamic static
behavioral models. Advances Knowledge Discovery Data Mining, 2336, 494505.
Zuev, D., & Moore, A. (2005). Internet traffic classification using Bayesian analysis techniques.
ACM SIGMETRICS.

774

fiJournal Artificial Intelligence Research 39 (2010) 217-268

Submitted 12/09; published 09/10

Narrative Planning: Balancing Plot Character
Mark O. Riedl

riedl@cc.gatech.edu

School Interactive Computing
Georgia Institute Technology
Atlanta, GA 30332 USA

R. Michael Young

young@csc.ncsu.edu

Department Computer Science
North Carolina State University
Raleigh, NC 27695 USA

Abstract
Narrative, particular storytelling, important part human experience.
Consequently, computational systems reason narrative effective communicators, entertainers, educators, trainers. One central challenges
computational narrative reasoning narrative generation, automated creation meaningful event sequences. many factors logical aesthetic contribute
success narrative artifact. Central success understandability.
argue following two attributes narratives universal: (a) logical causal
progression plot, (b) character believability. Character believability perception audience actions performed characters negatively impact
audiences suspension disbelief. Specifically, characters must perceived
audience intentional agents. article, explore use refinement search
technique solving narrative generation problem find sound believable
sequence character actions transforms initial world state world state
goal propositions hold. describe novel refinement search planning algorithm
Intent-based Partial Order Causal Link (IPOCL) planner that, addition creating
causally sound plot progression, reasons character intentionality identifying possible character goals explain actions creating plan structures explain
characters commit goals. present results empirical evaluation
demonstrates narrative plans generated IPOCL algorithm support audience comprehension character intentions better plans generated conventional
partial-order planners.

1. Introduction
Narrative entertainment, form oral, written, visual storytelling, plays
central role many forms entertainment media, including novels, movies, television,
theatre. Narrative also used education training contexts motivate
illustrate. One reasons prevalence storytelling human culture may due
way narrative cognitive tool situated understanding (Bruner, 1990;
McKoon & Ratcliff, 1992; Gerrig, 1993, 1994; Graesser, Singer, & Trabasso, 1994).
evidence suggests we, humans, build cognitive structures represent
real events lives using models similar ones used narrative order better
understand world around us (Bruner, 1990). narrative intelligence (Blair & Meyer,
c
2010
AI Access Foundation. rights reserved.

fiRiedl & Young

1997; Mateas & Sengers, 1999) central cognitive processes employ across
range experiences, entertainment contexts active learning.
Computational systems reason narrative intelligence able interact
human users natural way understand collaborative contexts emerging
narrative able express storytelling. standard approach
incorporating storytelling computer system, however, script story design time
storys script execute without variation run-time. computer
system use scripted story means ability system adapt users
preferences abilities limited. story scripted system may completely
engage users interests may challenging user follow. Furthermore,
stories scripted design time, system limited number stories
present user. entertainment applications, limited number stories
limited number permutations single story results limited opportunities user
interaction (or limited replay value computational system computer game).
educational training applications, limited number stories limited number
permutations single story limits ability system adapt learners needs
abilities.
alternative approach generate stories either dynamically per-session basis
(one story per time system engaged). Narrative generation process involves
selection narrative content (the events presented audience), ordering
narrative content, presentation narrative content discourse. system
generate stories capable adapting narrative users preferences abilities,
expanded replay value, capable interacting user ways
initially envisioned system designers. many entertainment, educational,
training systems incorporate aspects storytelling, systems exist generate
novel narrative content order support particular needs preferences user.
ability customize narrative content user primary motivation
research effort described article.
Narrative content must understandable, regardless purpose system
utilizes narrative generator needs system user. many factors
logical aesthetic relate narrative understandability, focus two attributes
narratives consider relatively universal: (a) logical causal progression plot
(b) character believability. Logical progression plot refers property narrative
central events narrative obey rules world narrative
occurs. Character believability (Bates, 1994) perception audience
actions performed characters negatively impact audiences suspension
disbelief. Specifically, characters must perceived audience intentional agents
(Dennett, 1989). Thus believable narrative sequence one characters
perceived intentional agents.
article describe narrative generation system models fictional narrative creation process search-based planning process. resulting artifact
plan description temporally ordered sequence actions story world characters perform. plan, executed rendered natural language, tells
story. Plans found good computational representations narratives
plans encode attributes central narrative: action, temporality, causality
218

fiNarrative Planning: Balancing Plot Character

(Young, 1999). Unfortunately, solving planning problem also solve narrative generation problem planners consider many logical aesthetic
properties narratives. Specifically, planners consider character believability.
describe novel refinement search planner Intent-based Partial Order Causal Link
(IPOCL) planner that, addition creating causally sound plot progression, reasons
character intentionality (a) identifying possible character goals explain
actions (b) creating plan structures explain characters commit
goals. begin brief background narrative lay theoretical groundwork
planning-based narrative generation (Section 2). Section 3 discusses related work narrative generation. Section 4, lay algorithm, IPOCL, narrative planning
detail illustrate processing examples. Finally, Section 5, describe
evaluated system.

2. Narrative Planning
section cover relevant background narrative humanities
cognitive psychology. use introduced concepts related narrative build
argument using planning technologies generate narratives off-the-shelf
planners, emphasis goal satisfaction, insufficient.
2.1 Narrative Background
Narrative storytelling terms widely understood often well defined.
One definition given here:
Narrative: narrative recounting sequence events continuant
subject constitute whole (Prince, 1987).
narrative continuant subject constitute whole, events described
narrative single point relate single communicative goal (Chatman, 1993).
One can, however distinguish narratives tell story narratives
(Herman, 2002). narrative tells story certain properties one comes
expect. particular, story narrative plot outline main incidents
narrative structured particular effect audience time.
Narratologists break narrative two layers interpretation: fabula sjuzet
(Bal, 1998). fabula narrative enumeration events occur
story world time story begins time story ends. events
fabula temporally sequenced order occur, necessarily
order told. sjuzet narrative subset fabula
presented via narration audience. narrative written spoken word,
narration natural language. narrative cinematic presentation, narration
actions actors camera shots capture action.
narrated sjuzet directly exposed audience, fabula narrative
content narrative, narrative about. article, work
primarily concerned generation fabula. assume sjuzet
generated fabula distinct process (e.g., Callaway & Lester, 2002; Young, 2006;
Jhala, 2009; Bae & Young, 2008; Cheong & Young, 2008).
219

fiRiedl & Young

many aspects determine whether story accepted audience
good. Many aspects subjective nature, degree
audience empathizes protagonist. aspects appear universal
across wide variety genres. Cognitive psychologists determined ability
audience comprehend narrative strongly correlated causal structure
story (Trabasso & Sperry, 1985; van den Broek, 1988; Graesser, Lang, & Roberts,
1991; Graesser et al., 1994) attribution intentions characters
participants events (Graesser et al., 1991; Gerrig, 1993; Graesser et al., 1994). Story
comprehension requires audience (e.g. reader, hearer, viewer) perceive causal
connectedness story events infer intentionality characters. Accordingly,
two attributes narrative focus work narrative generation logical
causal progression character believability.
causality events inherent property narratives ensures whole
continuant subject (Chatman, 1993). Causality refers notion relationship temporally ordered events one event changes story world
particular way enables future events occur (Trabasso & van den Broek, 1985).
story considered successful, must contain degree causal coherence
allows audience follow logical succession events predict possible outcomes.
Attesting importance causality story, Trabasso Sperry (1985) found significant correlation recall event story existence part causal
chain terminates outcome story.
Character believability (Bates, 1994) perception audience actions
performed characters negatively impact audiences suspension disbelief.
Character believability partially dependent idiosyncrasies characters appearance physical movements. Physical appearance important visual media
animated film (Thomas & Johnson, 1981). Descriptions character appearances
also found written spoken presentations. Equally important way
internal attributes character personality, emotion, desires, intentions manifest decisions character makes behaviors character
performs (Thomas & Johnson, 1981; Bates, 1994; Loyall, 1997).1 definition character believability places emphasis goal-oriented nature characters. Goal-oriented
behavior primary requirement believability (Loyall, 1997; Charles, Lozano, Mead,
Bisquerra, & Cavazza, 2003). Specifically, we, humans, ascribe intentionality agents
minds (Dennett, 1989). implication character perceived
believable, one able to, observations character, infer predict
motivations intentions. article, approach narrative generation focuses
explicitly creating narrative sequences characters perceived intentional agents. research efforts directly addressed aspects character
believability, including personality (e.g., Carbonell, 1980; Reilly, 1996; Rizzo, Veloso, Miceli,
& Cesta, 1999; Sengers, 2000), emotion (e.g., Gratch & Marsella, 2004; Seif El-Nasr, Yen,
& Ioerger, 2000), appearance physical performance (e.g., Blumberg & Galyean,
1995; Maes, Darrell, Blumberg, & Pentland, 1995; Perlin & Goldberg, 1996; Loyall, 1997;
Hayes-Roth, van Gent, & Huber, 1997; Lester, Voerman, Towns, & Callaway, 1999).
1. Loyall (1997) enumerates many elements affect character believability autonomous agents.

220

fiNarrative Planning: Balancing Plot Character

2.2 Planning Model Narrative Generation
many parallels plans narrative level fabula. particular,
narrative sequence events describes story world changes time.
fabula, change instigated intentional actions story world characters, although
story world also changed unintentional acts accidents forces
nature. Likewise, plan set ordered operators transforms world one
state another state. operators plan events happen story
world, plan model fabula. Partially ordered plans allow operations
remain temporally unconstrained relative execution order matter.
semantics plan capabilities plan execution engine may determine
whether operations can, fact, executed parallel (Knoblock, 1994). Similarly,
events fabula occur simultaneously story world, even though narration
(e.g., sjuzet) events necessarily linear.
Planners implementations algorithms solve planning problem: given
domain theory, initial state I, goal situation G consisting set propositions,
find sound sequence actions maps initial state state G true.
domain theory model world change. example, one use
STRIPS (Fikes & Nilsson, 1971) STRIPS-like operators specify operations
performed world, applicable, world different
afterward. Various algorithms developed solve planning problems including
partial-order planners, constraint satisfaction planners, heuristic search planners.
Since plan used model fabula, planning algorithm also used
model dramatic authoring process humans use create narratives. Thus,
creation narrative considered problem solving activity one considers
fabula narrative sequence story-world events achieves outcome
desired author order effect impact audience.
article, present algorithm planning narratives. specifically solves
fabula planning problem.

Fabula Planning Problem: Given domain theory, find sound believable sequence
character actions transforms initial world state world state
goal propositions G hold.

domain theory, initial state, goal situation provided user fabula
generation system, call human author. fabula generation system tasked
selecting ordering set actions that, told (as opposed executed),
considered narrative.
algorithm presented subsequent sections considered one example
algorithm solves fabula generation problem. planning algorithms general, acknowledge algorithms may exist. next sections, explore
implications searching believable narrative plans.
221

fiRiedl & Young

2.2.1 Challenges Planning Computational Model Narrative
Generation
Algorithms solve planning problem find sequences operations sound,
meaning that, absence non-determinism, guaranteed find sequence
operations maps initial state state goal situation holds.
generating fabula, assume operations actions performed characters
exist story world. consequence planning problem definition
planners consider whether natural believable character perform
action given time plan; consider actions perspective
character audience, context whether necessary goal
situation achieved. argue limits applicability off-the-shelf planners
techniques generating stories.
illustrate limitation, present simple example. Suppose describe world
three characters: king, knight, princess. characters live castle
castle tower characters locked up. suppose goal situation
provided human author princess locked tower
king dead. Given reasonable domain theory e.g., set possible actions one
plan found planner is:
1. princess kills king.
2. princess locks tower.
plan valid perspective transforms initial state state
goal situation holds. make sense story? reader short
story left many questions mind. princess kill king?
princess lock tower? plans exist might make sense,
as:
1. king locks princess tower.
2. knight kills king.
Intuitively, easier reader find explanation makes sense second
story: princess must upset king knight must avenging princess.
Let us consider ways influence planner give us favorable plans.
One possibility could modify problem definition. example,
change initial state domain theory princesses cannot kill kings
characters cannot lock tower. modifications make sense? Suppose king attempting harm princess princess would justified
killing king. declare princesses never kill kings seems impose unnecessarily strong assumption narratives generated. Likewise, imagine
narratives makes sense lock oneself tower (perhaps escape danger). One advantages automated generation narratives algorithm
explore many possibilities and/or create narratives envisioned human
author. argument expanded Riedl Young (2006) context
creativity part computational system.
222

fiNarrative Planning: Balancing Plot Character

Another possibility provide heuristic function planner favorably
ranks plans demonstrate quality character believability. heuristic
increase probability planner find solution believable ranking plans
closer solution include actions create appearance
intentionality. example, planner good heuristic could, principal, find
following plan:
1. princess knight fall love.
2. king proposes princess.
3. princess refuses kings proposal.
4. king locks princess tower.
5. knight kills king.
Like previous example, plan king lock princess tower
knight kill king. inclusion actions 1 3, however, increase likelihood
reader find story believable; princesss refusal explains king locks
princess tower (the kings proposal establishes conditions princesss
refusal), princess knight falling love explains princess refuses
kings proposal knight kills king.
good heuristic ranks believability, however, increases probability
complete plan found desired properties making cost less explore
portions search space solutions likely exist. still possible
planner return plan believable situations finds shorter,
complete solution finds longer, complete, believable solution. occurs
planning problem solved sound sequence actions transforms
initial state one goal situation holds.
conclude fabula generation problem sufficiently different planning
problem wish automatically plan actions fabula, benefit
new definitions plan completeness mechanisms selecting actions move
planner toward complete solutions. consider greater detail means
character appear believable respect intentionality, detect character
believability fabula plans, planner select actions directly address
logical causal progression believability.
2.2.2 Intentionality Character Believability
Character believability partially due character intentionality story
likely considered believable story world characters appear motivated
individual goals desires. Stories likely found comprehensible
well-formed relationships character actions recognizable character goals
(Graesser et al., 1991, 1994). However, unlike causal properties story, structures plans processes planning algorithms correspond directly character
intentionality except goal propositions planning problem. However, complicated fact stories typically comprise multiple characters cannot
223

fiRiedl & Young

assumed goals human author, want achieve goal
situation propositions provided human author.
goal situation fabula planning thus reinterpreted outcome story.
However, propositions outcome necessarily intended story world
characters. Indeed, possible none propositions goal situation
intended story world characters. also necessarily case
story world characters declared intentions beginning story (in
initial state). is, characters may form intentions reaction conditions
world response actions characters.
Achieving character intentionality fabula planner requires decoupling characters intentions intentions human author declaration
initial state goal situation. Thus, distinguish author goals (Riedl, 2004,
2009) character goals. author goal description world author
would like fabula generator achieve. simplicity, consider single author
goal encoded outcome, although often advantageous human author
indicate several intermediate situations fabula pass means
providing additional guidance desires solution (cf., Riedl, 2009).
Character goals, hand, goals characters perceived pursue
portion overall fabula. Characters goals may different outcome
sense characters story desire outcome state seek achieve
it. Character goals may also adopted resolved throughout story. example,
previous section king appears develop goal punishing princess
refuses marry him. kings goal neither exists beginning story
persists outcome.
agent intentions decoupled initial world state goal situation,
planner must assume responsibility determining character goals agents
performing actions plan motivate intentions actions.
Failure distinguish author goals character goals results appearance
collusion characters achieve outcome situation makes
sense (e.g., protagonist antagonist) and/or act inconsistently erratically.2
approach incorporating character intentionality narrative planning described
Section 4.
illustrate decoupling character intentions, let us inspect example planning
problem Section 2.2.1 detail. goal situation two propositions: (a)
princess locked tower, (b) king dead. example
human authors intentions particular outcome reached likely
reasonable intentions story world characters. is, princess unlikely
intend locked king unlikely intend dead. Further,
clear reason princess knight intend king
dead, although declarations could made human author initialization
time. would reasonable reader see king appear fight back

2. Sengers (2000) refers phenomenon agent schizophrenia.

224

fiNarrative Planning: Balancing Plot Character

knight try avoid death. planning problem adversarial sense
uncertainty whether knight prevail.3
conclude fabula planner must select actions characters achieve
outcome situation also create appearance story world characters
intentions potentially distinct human authors desires. Since characters
intentions necessarily provided advance human author, reasonable goals
characters must discovered explain behaviors, fabula structure must
constructed illustrates formation intentions. reviewing related
work, describe one algorithm meets requirements solving fabula
generation problem laid earlier.

3. Related Work
Narrative generation systems often classified using one two approaches fictional fabula content creation. Simulation-based narrative generation systems (also referred
emergent systems Aylett, 1999, 2000) simulate story world.
simulation approach establish set characters world context. narrative generation system progressively determines actions characters
take time situational context evolves. Often simulation-based narrative generation systems employ decentralized, autonomous embodied agents represent story world
characters react evolving world state. Deliberative narrative generation systems
generate narratives solving problem choosing sequence actions
physical, mental, dialogue story world characters meet certain constraints
parameters (aesthetic, dramatic, pedagogical). narrative output
procedure. primary distinction simulation-based approaches deliberative
narrative generation system uses centralized reasoning algorithm often planner
determine optimal actions characters. limit discussion related narrative
generation research systems produce fabula content.
simulation-based (emergent) approach narrative generation based assertion best way generate narrative model behaviors decision-making
processes story world characters. Tale-Spin (Meehan, 1976) system generates
Aesops Fables based moment-to-moment inference character
do. inference engine based theories common-sense reasoning (Schank & Abelson, 1977). Meehan (1977) notes circumstances character goals well
chosen facts story world support character actions user
intends, generated narratives short oddly structured (see Meehan, 1977,
examples mis-spun narratives). Carnegie Mellon University Oz project (Bates,
1992, 1994; Mateas, 1997; Loyall, 1997) uses autonomous, reactive, embodied agents
represent characters virtual world. agents use shallow broad (Bates, Loyall,
& Reilly, 1992) decision-making routines cover wide repertoire believable-looking activities. first proposed Laurel (1986) later implemented Bates colleagues
(Bates, 1992; Kelso, Weyhrauch, & Bates, 1993; Weyhrauch, 1997), special agent, called
3. example agents perceived intentionally strive avoid human authors
desired outcome. Since goal situation human authors intention, goal situation must
achieved.

225

fiRiedl & Young

drama manager may necessary prevent uninteresting poorly structured narratives emerging. drama manager oversees coordinates character agent behavior
order coerce interesting well-structured performances autonomous
agents. I-Storytelling system (Cavazza, Charles, & Mead, 2002) likewise relies
autonomous, reactive agents represent story world characters. Unlike Oz project,
I-Storytelling system agents use hierarchical task network (HTN) planners achieve
pre-determined goals. Cavazza et al. note way virtual world configured, including initial position character agents, initial goals character
agents strongly influences outcome story; poor initial configurations may result
uninteresting narratives conflict.
Dehn (1981) asserts process computational story generation must process
includes satisfaction intentions human author. Deliberative narrative
generation systems often consider process narrative creation perspective
singular author authority resulting narrative structure working
achieve narrative sequence conforms particular given constraints parameters.
Universe system (Lebowitz, 1984, 1985, 1987) uses centralized hierarchical planner
produce open-ended narrative soap-opera episodes achieve narratological intentions human author. human author provides goal situation describes
outcome particular episode Universe systems planner finds sequence
character actions achieves goal using hierarchically related task networks describing common activity. general, hierarchical decomposition requires form grammar
rules. Story grammars Rumelhart (1975) criticized restrictive (Black & Wilensky, 1979; Wilensky, 1983). Tailor (Smith & Witten, 1991) uses
state-space search plan actions storys protagonist. protagonist given
goal achieve Tailor searches sequence actions protagonist take
achieve goal. antagonist present, Tailor uses adversarial search.
recent work deliberative narrative generation systems focused two areas:
role knowledge, specialized search algorithms. Minstrel system (Turner,
1994) implements model computational creativity based adaptation reuse
existing concepts create new stories. Minstrel system uses specialized routines
transform old stories new stories. Mexica (Perez Perez & Sharples, 2001) implements
model creative writing (cf., Sharples, 1999) conceptualizes writing cycle
cognitive engagement reflection. model employs combination case-based
reasoning probes database known existing stories elements match current
patterns emotion tension partial-order planning ensure coherence
story fragments. ProtoPropp system (Gervas, Daz-Agudo, Peinado, & Hervas,
2005) uses case-based reasoning approach creating narratives. ProtoPropp encodes
examples Russian folktales Propp (1968) functions based regularities
folktales identified Propp ontology new folktales created
retrieving, adapting, reusing parts old folktales. recently Porteous Cavazza
(2009) turned planning narrative structures using variation FF (Hoffmann &
Nebel, 2001) find sequence events brings goal situation. planner
consider character goals independent goal situation. Instead generation
algorithm uses landmarks partially ordered sets first-order logic literals must
made true throughout course solution means guiding planner toward
226

fiNarrative Planning: Balancing Plot Character

solution consistent human authors vision. Landmarks author goals (Riedl,
2004, 2009).
goal research devise narrative generation system generates narratives exhibit causal coherence character intentionality. favor deliberative
approach narrative generation deliberative approach provides mechanism
ensuring character actions chosen global structure mind. Contrast
simulation-based approaches choose character actions based temporally localized
information. Deliberative systems avoid problems logical causal progression
consider narrative sequence whole. However, deliberative narrative generation systems designed date conflate character goals human author
goals without consideration audience reader, viewer, etc. perspective.
algorithm, Intent-Driven Partial Order Causal Link (IPOCL) planner,
algorithm solves fabula generation problem. IPOCL algorithm based
class planning algorithms called Partial Order Causal Link (POCL) planners,
UCPOP (Penberthy & Weld, 1992; Weld, 1994) well known example. POCL planners
represent operators plan STRIPS (Fikes & Nilsson, 1971) STRIPS-like constructs
consisting operator name, precondition conditions must true
world operator executable effect conditions world
changed operator finishes execution. precondition effect consist
zero first-order logic literals. Operators may parameterized variables that,
bound ground symbols, allows single operator schema represent many possible
ground operators. POCL planners use following definition partially ordered plan,
using term step refer operators instantiated plan structure:
Definition 1 (POCL Plan): POCL plan tuple hS, B, O, Li
set plan steps, B set binding constraints parameters steps
S, set temporal orderings form s1 < s2 s1 , s2 S, L
set causal links form hs1 , p, q, s2 s1 , s2 p effect s1
q precondition s2 p unifies q.
Note use term step synonymously action operator. differs
usage term literature non-POCL planners SATPLAN
Graphplan.
POCL planners use iterative process identifying flaws plan revising
plan least-commitment manner. flaw reason plan cannot considered
valid solution. open condition flaw occurs precondition step goal
situation satisfied effects preceding step initial state. POCL
planner solves open condition step goal situation non-deterministically
choosing existing steps instantiating new steps effects unify goal
conditions. causal link (Penberthy & Weld, 1992) connects two plan steps s1 s2 via
p
condition p, written s1
s2 , s1 establishes condition p story world needed
subsequent step s2 order step s2 execute. Causal links used record
causal relationships steps record satisfaction open conditions. causal
threat flaw occurs effects one plan step possibly undo effects another plan
step. Causal threats resolved explicitly ordering conflicting steps. provide
227

fiRiedl & Young

POCL (hS, B, O, Li, F, )
first parameter plan. initial call POCL, two steps dummy
initial step whose effect initial state final step. F set flaws. initial call, F
contains open condition flaw goal literal goal situation. B = L = . set action
schemata. Output complete plan f ail.
I. Termination. B inconsistent, fail. Otherwise, F empty, return hS, B, O, Li.
II. Plan Refinement.
1. Goal selection. Select open condition flaw f = hsneed , pi F . Let F 0 = F {f }.
2. Operator selection. Let sadd step adds effect e unified p (to
create sadd , non-deterministically choose step sold already instantiate action schema
). step exists, backtrack. Otherwise, let 0 = {sadd }, O0 = {sadd < sneed },
B 0 = B Bnew Bnew bindings (e.g., assignments ground symbols variables)
needed make sadd add e, including bindings sadd itself, L0 = L{hsadd , e, p, sneed i}.
sadd 6= sold , add new open condition flaws F 0 every precondition sadd .
3. Threat resolution. step sthreat threatens causal link hsj , e, p, sk occurs
sj sk asserts e. every used step sthreat might threaten causal link
hsj , e, p, sk L0 , non-deterministically one following.
Promotion. sk possibly precedes sthreat , let O0 = O0 {sk < sthreat }.
Demotion. sthreat possibly precedes sj , let O0 = O0 {sthreat < sj }.
Separation. Let O0 = O0 {sj < sthreat , sthreat < sk } let B 0 = B 0 set variable
constraints needed ensure sthreat wont assert e.
III. Recursive invocation. Call POCL (hS 0 , B 0 , O0 , L0 i, F 0 , ).

Figure 1: POCL algorithm.

POCL planning algorithm Figure 1 point comparison later discussion
fabula planning algorithm.
next section, introduce algorithm, Intent-Driven Partial Order Causal
Link (IPOCL) planner, creates narratives that, perspective reader,
closely resemble results emergent narrative generation system regard character intentionality. Specifically, IPOCL modification existing search-based planning
algorithms support character intentionality independent author intentions. goal
generate narratives deliberative process characters appear
audience form intentions act achieve intentions simulated.
way, IPOCL produce narratives logical causal progression, meaning
achieve author-indicated outcomes states, believable characters.

4. Intent-Driven Planning
definition character believability work constrained focus perceived
intentionality character behavior story world. Perceived intentionality refers
way characters observed audience goals act achieve
goals. context computational storytelling systems, sufficient
character act intentionally audience capable inferring characters
228

fiNarrative Planning: Balancing Plot Character

intentions circumstances surround character story world.
audience story collection passive observers. Instead, audience actively
performs mental problem-solving activities predict characters
story evolve (Gerrig, 1993). makes sense, therefore, reason character
intentions motivations time generation perspective audience.
ensure every character action considered inclusion narrative
appear motivated intentional.
Intent-Driven Partial Order Causal Link (IPOCL) planner generates fabula
plans characters act intentionally intentionality observable.
IPOCL extends conventional POCL planning include expanded plan representation,
definition plan completeness, action selection mechanisms facilitate fabula
planner search solution authors goal achieved (e.g., outcome)
characters appear act intentionally. Conventionally, planners means-ends
tools solving problems. employing planning system generate fabula,
system must produce actions make plot line story, along temporal
ordering partial total execution times actions. make following
observations conventional planning problem:
Plans generated created single agent (Bratman, Israel,
Pollack, 1988) collection cooperating agents (Grosz & Sidner, 1990).4
goal situation intended one character agents agents
intend execute plan support achieving goal state.
order facilitate active mental processes audience suggested Gerrig,
observe solving fabula planning problem requires following:
Plans generated created multiple character agents necessarily
cooperating also necessarily adversarial.
goal situation describes properties world necessarily intended
character agents execute plan.
goal situation conventional planning problem partial description world
state obtained end plans execution. context narrative
planning, refer goal situation outcome describes world
must different narrative completed.
fabula generation algorithm described remainder section searches
space plans individual agent goals potentially distinct outcome
4. SharedPlans (Grosz & Sidner, 1990) formalism addresses situation one agent
collaborates construct joint plan achieving goal. Grosz Sidners approach addresses
cases agents intend joint goal achieved one agent goal
contracts part task another agent communicating intentions (Grosz & Kraus, 1996).
SharedPlans address coordination many individual plans single joint plan defining
agent intentions perform actions agent intentions goals sub-goals achieved constrain
behaviors individual agents working together. formalism, however, address
situations agents different goals cooperating contracting out.

229

fiRiedl & Young

ACTION ::= ACTION-NAME (VARIABLE )
actors: VARIABLE
happening: BOOLEAN
constraints: LITERAL
precondition: LITERAL
effect: LITERAL
LITERAL := PREDICATE ([VARIABLE | SYMBOL] )

Figure 2: Syntax action schemata IPOCL.
agents necessarily cooperating. Character agents either given
intentions part specification initial world state develop
course plan. IPOCL planning algorithm accomplishes expanding
representation plan structure include information intentions
individual agents. Algorithmically, IPOCL simultaneously searches space plans
space agent intentions. point process, agent intentions ensured
plausible use special reasoning process tests character intentionality
perspective audience attempts revise plan test fails.
4.1 Extensions Planning Problem Definition Language
IPOCL planning problem given Definition 2.
Definition 2 (IPOCL Planning Problem): IPOCL planning problem tuple,
hI, A, G, i, initial state, set symbols refer character
agents, G goal situation, set action schemata.
significant factor IPOCL planning problem A, set symbols refer
character agents world. symbols handled specially processes determining
character intentionality. extended traditional planning problem definition
language use character agents two ways:
Specification actions need intentional.
Specification parameters action refer character agents
intentionally performing action.
syntax specifying action schemata IPOCL given Figure 2.
POCL planners, use STRIPS-like representation preconditions effects. Additionally, constraints literals must unify initial state act
filter applicable parameter bindings.
distinguish two types actions: happenings (Prince, 1987) nonhappenings. Happenings actions occur without intention character
accidents, involuntary reactions stimuli, forces nature. Non-happening
events must intended character. clarity, assume that, unless indicated otherwise, actions non-happenings thus require actor action fulfills
230

fiNarrative Planning: Balancing Plot Character

Action: slay (?slayer, ?monster, ?place)
actors: ?slayer
constraints: knight(?slayer), monster(?monster), place(?place)
precondition: at(?slayer, ?place), at(?monster, ?place), alive(?slayer), alive(?monster)
effect: alive(?monster)
Action: marry (?groom, ?bride, ?place)
actors: ?groom, ?bride
constraints: male(?groom), female(?bride), place(?place)
precondition: at(?groom, ?place), at(?bride, ?place), loves(?groom, ?bride),
loves(?bride, ?groom), alive(?groom), alive(?bride)
effect: married(?groom), married(?bride), single(?groom), single(?bride),
married-to(?groom, ?bride), married-to(?bride, ?groom)
Action: appear-threatening (?monster, ?char, ?place)
actors: ?monster
happening:
constraints: monster(?monster), character(?char), place(?place)
precondition: at(?monster, ?place), at(?char, ?place), scary(?monster), ?monster6=?char
effect: intends(?char, alive(?monster))

Figure 3: Example IPOCL action schemata.
intention. actions occur world without intent (for example,
falling stairs), marked specifying happening slot true.
action non-happening, actors slot specifies parameters refer
symbols representing characters acting intentionally enact particular
action. say action performed character agent actors
slot action references a. Figure 3 shows three action schemata involving single
intentional actor, multiple intentional actors, intentional actor, respectively.
action schema Slay(?slayer, ?victim, ?place) specifies ?slayer refer
intentional actor. Note implication slaying cannot performed accidentally.
action schema Marry(?groom, ?bride, ?place) specifies two intentional actors,
?groom ?bride. Finally, Appear-threatening(?monster, ?char, ?place) indicates
?char appear become frightened monster. action need
intentional part ?monster ?char.
final note action definition use special intends predicate,
used effect action. Semantically intends predicate read
meaning reasonable character following goal response
action. Whether intention acted upon determine whether proposition
used, described next section. narrative told, mention
facts unused. intends predicate occurs action effects; used
action preconditions creates strong commitment actions used.
example, Marry require intends(?groom, married-to(?groom, ?bride)),
would preclude stories character wants single (but doesnt necessarily
want married) also stories character marries someone revenge
231

fiRiedl & Young

third party (the marriage one action chain leading another goal
none actions effects).
4.2 Character Intentionality Fabula Planning
storys audience actively performs problem-solving story progresses order
predict outcome fate story world characters, generated story
support cognitive processes. means providing narrative structure gives
enough information audience infer intentionality character behavior.
fabula planners perspective, character actions intentional (or happenings).
is, every character goal, portion actions complete fabula plan describe
actions performed character achieve character goal. formalize
follows:
Definition 3 (Frame Commitment): frame commitment tuple,
hS 0 , P, a, ga , sf i, 0 proper subset plan steps plan P = hS, B, O, Li,
symbolic reference character agent character agent actor
steps 0 , ga goal character agent pursing executing steps
0 , sf 0 referred final step ga one effects
steps 0 temporally precede sf step ordering plan P .
purpose frame commitment record characters internal character goal
ga actions plan character appear perform storytelling
achieve goal. However, perspective audience, enough declare
character goal; order make inferences character intentions
plans, audience must observe characters forming committing goals. Therefore,
frame commitment associated condition, eg , form intends(a, ga ),
indicates character commit internal character goal, must
state reasonable intend ga . condition eg must established
world plan step eg effect. is, something world causes
character commit ga . plan step causes eg consequently causes
frame commitment referred motivating step frame commitment.
motivating step necessarily temporally precedes plan steps frame commitment.
Informally, interval intentionality set actions 0 character perform
achieve internal character goal, ga .5
Character goals partially describe world state character commits achieving.
Commitments persist time character remain committed goal even
though desired world state undone (Bratman, 1987). IPOCL explicitly
represent release commitment except say interval intentionality
bounded temporally set steps interval intentionality.
5. interval intentionality roughly equates notion Full Individual Plan (FIP) SharedPlans formulation (Grosz & Sidner, 1990). full individual plan portion larger Full Shared
Plan (FSP) single agent responsible executing. distinction fabula plan
FSP full fabula plan made many individual FIPs generated collaborating
planning agents. Instead, fabula plan constructed whole individual character actions
make whole plan annotated indicate intention might used achieve.

232

fiNarrative Planning: Balancing Plot Character

Frame commitment a1
goal ga1

intends(a1, ga1)

Intention level
Domain level
s5 (a2)

s3 (a1)

s2 (a1)

p2

ga1

s1 (a2)

p3

s4 (a1)

Figure 4: IPOCL plan single frame commitment motivating step.
Character goals captured two ways. First, potential character intentions
recorded world states existence world state propositions form
intends(a, ga ). world state propositions record fact character
intention, indicate whether intention acted upon, capture
subsequent actions executed order character act intention.
Second, character intentions recorded frame commitment data structures. Frames
commitment elaborate intention also identifying actions fabula
plan character perform pursuit intention. Note interval
intentionality contain one step ga effect. necessary
case another action fabula plan undoes ga world condition must
reestablished.
IPOCL extends definition POCL plan data structure include frames
commitment. definition IPOCL plan follows.
Definition 4 (IPOCL Plan): IPOCL plan tuple hS, B, O, L, Ci
set plan steps, B set binding constraints free variables steps
S, set ordering constraints steps S, L set causal links
steps S, C set frames commitment.
sets S, B, O, L defined standard way (e.g., Penberthy & Weld, 1992).
frames commitment C defined Definition 3. See Figure 4 illustration
IPOCL plan single frame commitment motivating step frame.
actor step si indicated parentheses. IPOCL algorithm ensures
story world characters participate fabula plan appear act believably
respect intentionality. satisfy requirement, character actions IPOCL
plan (except marked needing intentional) must intentional final
solution plan happenings.
Definition 5 (Action Intentionality): action plan P intentional belongs
frame commitment P .
Unintentional actions part interval intentionality referred
orphans. order IPOCL plan considered complete, actions except
233

fiRiedl & Young

happenings must part least one frame commitment. character action
belong one interval intentionality. definition plan completeness
follows:
Definition 6 (Complete IPOCL Plan): IPOCL plan complete
(1) preconditions plan steps established, (2) causal threats6
resolved, (3) plan steps happenings intentional.
Conditions 1 2 together make conventional definition plan completeness,
termed causally complete. fabula plan IPOCL causally complete
without fully complete Definition 6. plan causally complete
fully complete, plan contains orphans. ways correct
orphans, IPOCL backtracks find another possible complete solution plan. Taken
together, Definitions 4 6 directly address high-level problem finding sound
believable sequence actions transforms initial world state world state
goal situation holds.
4.3 Integrating Intentionality Least-Commitment Planning
Frames commitment products process planner tests intentionality
character actions revises plan necessary. IPOCL, refinement search process,
uses iterative, least-commitment process identifying flaws plan revising
plan repair flaws. creates tree-like search space leaf nodes either
complete plans (under Definition 6) incomplete plans cannot repaired. Internal
nodes incomplete plans one flaws.
addition open conditions causal threat flaws adopted POCL define
three additional types flaws:
Definition 7 (Open Motivation Flaw): open motivation flaw plan P
tuple, hc, pi, c frame commitment P p sentence intends(a,
ga ) character c ga internal character goal c.
Definition 8 (Intent Flaw): intent flaw plan P tuple hs, ci
p
step P c frame commitment P
sj causal link
plan, part c, sj step P , part c, character
character sj c.
Definition 9 (Intentional Threat Flaw): intentional threat flaw plan P
tuple, hck , ci i, frame commitment ck internal character goal
negates internal character goal another frame commitment ci .
Open motivation flaws reflect fact characters must appear motivated goals.
is, something must cause character commit goal. open motivation
flaw means plan frame commitment whose interval intentionality
preceded motivating step. Intent flaws reflect fact plan step, s,
6. causal threat occurs when, due insufficient constraints action ordering partially ordered plan,
effects one action potentially undo preconditions another action.

234

fiNarrative Planning: Balancing Plot Character

performed character part frame commitment, c, held
character. is, step causally establishes precondition step, sj ,
part c. planner must non-deterministically decide whether step part
frame commitment. next sections describe algorithms identifying repairing
open motivation flaws intent flaws. facilitate this, IPOCL algorithm, shown
Figure 5, broken three parts: causal planning, motivation planning, intent
planning.
4.3.1 Causal Planning IPOCL
causal planning portion IPOCL algorithm implements conventional POCL
algorithm addition frame commitment discovery phase. Causal planning
occurs open condition needs resolved. is, step sneed
precondition p satisfied causal link. planner chooses plan
step sadd whose effect e unify p. accomplished non-deterministically
choosing existing plan step instantiating new action.
frame commitment discovery process triggered changes plan (e.g.
addition causal link plan structure). sadd newly instantiated step,
possibility final step (due backward-chaining nature
planning algorithm) previously undiscovered character intention. case,
one effects sadd , addition causally satisfying open condition,
intended character specified perform sadd . IPOCL non-deterministically chooses
one effects sadd (or effect, case sadd final step
yet-to-be-discovered intention). effect chosen, new frame commitment
constructed record characters commitment achieving effect world.
Step sadd made final step frames interval intentionality new
open motivation flaw annotates plan indicate planner must find motivating
step.
Regardless whether sadd newly instantiated existing plan step reused,
planner must consider possibility sadd part existing interval intentionality. Steps performed part one intention; Pollack (1992) refers
overloading. IPOCL performs search plan node frames commitment
sadd part of. search routine finds set frames C 00 cj C 00
one two following conditions holds:
p

1. frame commitment cj contains step sj sadd
sj causal link
plan sadd sj performed character.
2. frame commitment cj contains step sj frame ci
/ C 00
service sj sadd motivating step ci . Frame ci service step sj
final step ci effect establishes precondition sj , sj part
frame ck , ck 6= ci .
frame commitment ci C 00 , plan annotated intent flaw hsadd , cj i.
resolving flaws, planner determine whether step sadd becomes part
existing frames interval intentionality.
235

fiRiedl & Young

IPOCL (hS, B, O, L, Ci, F, )
first parameter plan, steps S, variable bindings B, ordering constraints O, causal links L,
frames commitment C. F set flaws (initially open conditions literal goal
situation). set action schemata. Output complete plan according Definition 6 f ail.
I. Termination. B inconsistent, fail. F empty S, c C | part c,
return hS, B, O, L, Ci. Otherwise, F empty, fail.
II. Plan Refinement. Non-deterministically one following.
Causal planning
1. Goal selection. Select open condition flaw f = hsneed , pi F . Let F 0 = F {f }.
2. Operator selection. Let sadd step adds effect e unified
p (to create sadd , non-deterministically choose step sold already instantiate
action schema ). step exists, backtrack. Otherwise, let 0 = {sadd },
O0 = {sadd < sneed }, B 0 = B Bnew Bnew bindings (e.g., assignments
ground symbols variables) needed make sadd add e, including bindings sadd
itself, L0 = L {hsadd , e, p, sneed i}. sadd 6= sold , add new open condition flaws F 0
every precondition sadd .
3. Frame discovery. Let C 0 = C.
a. sadd 6= sold , non-deterministically choose effect e sadd e = nil. e 6=
nil, construct new frame commitment c internal character goal e
character sadd , let sadd part c, let C 0 = C {c}, create new open motivation
flaw f = hci, let F 0 = F {f }.
b. Let C 00 set existing frames commitment used explain sadd .
C 00 , create intent flaw f = hsadd , di let F 0 = F {f }.
4. Threat resolution
Causal threat resolution. Performed II.3 POCL algorithm (Figure 1)
Intentional threat resolution. c1 C 0 c2 C 0 , character
c1 character c2 , e1 goal c1 , e2 goal c2 ,
e1 negates e2 , non-deterministically order c1 c2 vice versa s1 c1
s2 c2 , O0 = O0 {s1 < s2 } O0 = O0 {s2 < s1 }.
5. Recursive invocation. Call IPOCL (hS 0 , B 0 , O0 , L0 , C 0 i, F 0 , ).
Motivation planning
1. Goal selection. Select open motivation flaw f = hci F . Let p condition
c. Let F 0 = F {f }.
2. Operator selection. causal planning above, except
si c, O0 = O0 {sadd < si }.
3. Frame discovery. causal planning, above.
4. Threat resolution. causal planning, above.
5. Recursive invocation. Call IPOCL (hS 0 , B 0 , O0 , L0 , C 0 i, F 0 , ).
Intent planning
1. Goal selection. Select intent flaw f = hs, ci F . Let F 0 = F {f }.
2. Frame selection. Let O0 = O. Non-deterministically choose one following.
Make part c. Let sm motivating step c. O0 = O0 {sm < s}.
ci C ci ordered respect c, si ci , O0 = O0 {si < s}
O0 = O0 {s < si }. spred hspred , p, q, si L spred
character, create intent flaw f = hspred , ci let F 0 = F 0 {f }.
make part c.
3. Recursive invocation. Call IPOCL (hS, B, O0 , L, Ci, F 0 , ).

Figure 5: IPOCL algorithm.
236

fiNarrative Planning: Balancing Plot Character

f1: Frame commitment a1 goal ga1
f2: Frame commitment
a2 goal ga2

intends(a2, ga2)

Intention level
Domain level
s2 (a1)

s4 (a2)

p3

s3 (a2)

ga2

s1 (a2)

Figure 6: IPOCL plan one character contracted another character.
Condition 1 indicates two actions, sj sadd , performed
character earlier action, sadd , establishes condition world required
later action, sj , reasonable hypothesis part
intention. intent flaw earlier action indicates planner must,
point, decide whether support hypothesis incorporating actions
interval intentionality reject hypothesis leaving plan structure
unchanged. Condition 2 indicates situation agent requires certain world
state achieved make intentional actions feasible sub-goal contracted
(e.g., Grosz & Kraus, 1996) another agent. occurs motivating action
performed one character causes another character intention
service first characters actions, illustrated Figure 6. Character a1 perform
action s1 pursuit goal ga1 . Action s1 single precondition satisfied
action s3 performed character a2 pursuit goal ga2 . Action s2 motivating action
causes character a2 goal establish precondition step s1 . Since
motivating step performed character a1 , candidate Condition 2
incorporated frame commitment a1 .
frame discovery takes place, planner must resolve threats inadvertently introduced refined plan. two types threats: causal threats
intentional threats. standard POCL means detecting correcting causal
threats used (see Section 3). Intentional threats occur newly instantiated frame
commitment, ck , internal character goal negates internal character goal
frame commitment ci character. Character actions
fabula plan may unordered respect one another allows intervals
intentionality interleaved. possible agent character
hold conflicting desires, rational agent concurrently commit conflicting
desires (Bratman, 1987). case character two frames goals negate
other, IPOCL corrects intentional threats non-deterministically constraining
ordering ci ck . ordering frames commitment amounts explicitly ordering
actions part frame correspond ordering ci ck .
complicated cases goals ci ck negate
plans causally interfere other, IPOCL relies standard causal threat resolution
either order action sequences plan leaving frames unordered,
237

fiRiedl & Young

force algorithm backtrack. cases identified repaired without
additional semantic contextual reasoning.
4.3.2 Motivation Planning IPOCL
motivation planning portion IPOCL algorithm responsible ensuring
characters story world motivated. motivating step plan step one
effects causes character commit goal. Repairing open motivation flaw
consists non-deterministically finding plan step effect intends(a, ga ) either
choosing existing plan step instantiating action schema explicitly ordering
step plan steps part frame commitment. Motivation
planning similar causal planning except instead establishing causal link
two plan steps, establishes motivation link motivating step frame
commitment. Additionally, motivating step frame commitment explicitly
ordered steps frames interval intentionality. work presented
here, character agent cannot begin pursuing character goal committed
goal. Motivation planning involves frame discovery threat resolution phases
identical causal planning.
4.3.3 Intent Planning IPOCL
intent planning portion IPOCL algorithm determines interval membership
character actions except final steps intervals intentionality.
Intent planning repairs intent flaws. intent flaw decision point asks whether
plan step made part interval frame commitment c. Unlike
flaws repaired refining structure plan, intent flaws resolved
non-deterministically choosing one following:
Make step part interval c refine plan structure reflect
association.
make step part interval c, remove flaw annotation, leave
plan structure unchanged.7
former chosen, step becomes part interval intentionality frame
c. choice made, interval frame c updated appropriately
explicitly ordered motivating step frame c. Furthermore, change
steps membership status effect membership plan steps precede
s. Let spred establishing step step precedes causally linked
s. inclusion step interval frame c also makes possible establishing
steps included interval c following conditions hold:
Step spred performed character s.
7. intent flaw addressed making revisions plan structure, intent
flaw strictly flaw conventional sense. However, purpose maintaining consistency
existing revision mechanisms, find useful treat intent flaw flaw point
repaired.

238

fiNarrative Planning: Balancing Plot Character

Step spred part interval intentionality c.
intent flaw, f = hspred , ci already proposed and/or resolved.8
Intent flaws created establishing step three conditions hold. Intent planning thus operates spreading activation fashion. one step becomes
member frame commitment, entire sequence establishing steps may follow.
approach necessary since frames commitment created time
plan refinement. Intent flaws standard flaws sense mark potential
flaw instead actual flaw. cannot determine time action instantiated
whether necessary action part interval intentionality. frame
commitment belong may discovered yet, may yet
discovered action part frame commitment due adjacency
requirements.
propagation intent flaws makes possible plan steps become members
one frame commitment, desirable property IPOCL algorithm.
Every time character action belonging one frame commitment used satisfy
open condition successor action belongs different frame commitment,
system must non-deterministically decide whether establishing action belongs
frames commitment remains member original frame. decision
interval membership also constrains possible ordering motivating steps frames
commitment involved motivating steps temporally ordered actions
frame commitment motivating step establishes. step becomes
member one frame commitment, possible placement motivating steps
constrained Figure 7 motivating step must occur earliest step
frame commitment.
One thing yet discussed handle orphans. orphan step
plan belong interval intentionality. Orphans surreptitiously
repaired adopted intervals intentionality. happen
causally establish conditions necessary other, intentional actions. Orphaned actions
cannot repaired directly frames commitment discovered opportunistically
instead instantiated least-commitment approach (as plan steps are).
orphans remaining surreptitiously repaired time planning
process completes, planner must backtrack.
4.4 Example
IPOCL algorithm illustrated following story arch-villain bribes
President United States large sum money. example traces
single path fabula plan search space generated IPOCL. initial plan
node contains initial state step goal situation step. initial state contains
propositions describing state world story begins. goal situation
contains single proposition, corrupt(President), describes must different
8. inclusion condition ensures systematicity algorithm since
one causal link spred s. search algorithm systematic guaranteed never duplicate
portion search space.

239

fiRiedl & Young

f1: Frame commitment
Intention level
Domain level
s8

s5

s4: Pickup (a, gun)

s3: Load (a, gun)

s9

s2

s1: Shoot (a, deer, gun)

s7

s2: Rob (a, bank, gun)
Domain level
Intention level

f2: Frame commitment

Figure 7: IPOCL plan overlapping intervals intentionality single character.

world story complete. story generated IPOCL is,
effect, story President becomes corrupt.
goal proposition corrupt(President) non-deterministically established instantiating new character action, Bribe(Villain, President, $), states
Villain character bribe President character money. Bribe action
chosen corrupt(President) effect. planners perspective, Bribe action causally motivated open condition goal situation.
Upon instantiation Bribe action, frame discovery invoked. effects Bribe
action are:
corrupt(President) President corrupt.
controls(Villain, President) Villain exerts control President.
has(President, $) President money.
has(Villain, $) Villain money.
audiences perspective, effects reason Villain performs actions story.
planner non-deterministically chooses controls(Villain, President) character goal Villain character. Note case goal Villain differs
outcome story although action satisfies conditions.
reason planner could chosen corrupt(President) character goal
Villain. assumed either plan cannot completed alternative chosen heuristic function evaluated options determined
villains likely want control President anything else. Given
choice made, planner constructs frame commitment Villain character
240

fiNarrative Planning: Balancing Plot Character

Frame commitment Villain goal
controls(vil, prez)
intends(vil, controls(vil, prez))

Intention level
Domain level
init

has(vil, $) Bribe (vil, prez, $)

corrupt(prez)

goal

Figure 8: Example narrative plan discovering one action corresponding frame
commitment.

makes Bribe action final step frames interval intentionality. Even
new frame commitment, plan still flawed since reason Villain
character goal controlling President. is, Villain needs form
intention appear believable audience. open motivation flaw indicates
action plan must satisfy condition intends(Villain, controls(Villain,
President)) frame commitment.
Since frames commitment Villain, intent flaws occur.
Bribe action, however, precondition has(Villain, $) becomes open
condition; Villain character must money bribe President
it. planner chooses repair open motivation flaw single frame commitment first non-deterministically chooses initial state satisfy open motivation
condition. illustrates situation intention character story world
encoded part initial conditions. way,
domain engineer specified inputs IPOCL decided motivation
Villain want control President needed. may
satisfactory solution, valid solution. partial plan point shown Figure
8.
open condition has(Villain, $) Bribe action considered next. repair
flaw, planner non-deterministically instantiates new character action Give(Hero,
Villain, $) Hero character gives Villain money. planner must
consider, audiences, perspective, Hero character gives money
Villain. planner inspects effects Give action:
has(Villain, $) Villain money.
has(Hero, $) Hero money.
planner non-deterministically chooses has(Villain, $) goal Hero
attempting achieve. new frame commitment Heros goal created. Note
Heros intention matches open condition Give action instantiated
satisfy. indicates Heros commitment service Bribe action.
open motivation flaw created corresponds new frame commitment.
many actions establish Heros intention Villain
money: Villain might persuade Hero friends, Villain might coerce
241

fiRiedl & Young

Frame commitment Villain goal
controls(vil, prez)

intends(vil, controls(vil, prez))

Frame commitment Hero
goal has(vil, $)

has(vil, $)

Intention level
Domain level
init

has(hero, $)

Give (hero, vil, $)

has(vil, $)

Bribe (vil, prez, $)
corrupt(prez)

Coerce (vil, hero, (has vil $))

goal

Figure 9: Solution IPOCL plan graph example narrative.
Hero. latter, Coerce(Villain, Hero, has(Villain, $)), chosen planner: Villain character coerces Hero character goal has(Villain,
$).
point, planner must determine Villain coerces Hero.
several possibilities. First, frame discovery comes play determine Villain
intends effects Coerce action. Assume effect Coerce action
intends(Hero, has(Villain, $)). planner select effect construct
new frame commitment specifying Villain intends Hero intends
Villain money. Another option leave Coerce action orphan
time being. Let us suppose course planner chooses. search
current plan structure indicates Coerce action part Villains existing
commitment control President. possible Coerce motivating step
Heros frame commitment Heros frame commitment service
Bribe action, part Villains frame commitment. intent flaw associating
Coerce action Villains existing frame commitment created. Eventually,
spreading activation intent planning associate Coerce Villains frame
commitment. plan structure point shown Figure 9. remaining flaws
handled conventional causal planning.
4.5 Complexity IPOCL Algorithm
computational complexity IPOCL algorithm O(c(b(e + 1)a )n ),
n depth search space,
b number ways action instantiated (e.g., number
permutations legal parameter bindings),
e number effects instantiated action,
number actors instantiated action.
242

fiNarrative Planning: Balancing Plot Character

worst-case branching factor IPOCL search space b(e + 1)a . factor,
(e + 1) signifies new frame commitment constructed, planner must
choose e effects action (plus one signify condition effect
chosen). exponent reflects fact multiple characters intentionally
participating action, characters distinct intentions
performing action. example, action Marry(?groom, ?bride, ?place) six
effects (see Appendix action schema) two intentional actors (?groom
?bride).
depth IPOCL search space n number open condition flaws, open
motivation flaws, intent flaws, causal threats, intentional threats repaired.
worst-case, every newly instantiated step plan IPOCL also creates new
frame commitment corresponding open motivation flaw. nPOCL depth
solution search space POCL planning problem nIPOCL depth
corresponding solution search space IPOCL fabula planning problem,
nIPOCL bounded function nIPOCL = 2nPOCL .
narrative generated evaluation purposes (see Section 5). narrative, rendered natural language, given Figure 13 plan data structure presented
graphically Appendix (Figure 15). complete fabula plan exists depth
n = 82. average branching factor domain 6.56, worst branching
factor given node 98. node 98 children first flaw
planner solves for: married(Jafar, Jasmine), solved instantiating action
Marry(Jafar, Jasmine, ?place). operator schema six effects. two characters intentional actors meaning two frames commitment
generated. Finally, parameter ?place bound two ways. Note implementation IPOCL uses constraint propositions generate child node legal
permutation parameter bindings. provide domain-specific heuristic evaluation function favors plan structures certain preferred character goals (for example,
Jafar intends Jasmine dead included), complete plan generated
approximately 12.3 hours (approximately 11.6 hours spent garbage collection)
Intel Core2 Duo 3GHz system 3GB RAM 100GB virtual memory
R
running Allegro CL
8.0. conditions, IPOCL generates 1,857,373 nodes
visits 673,079 nodes. algorithm run domain-independent heuristic
adopted classical planning (e.g., number flaws plus plan length), problem cannot
solved system runs virtual memory. Appendix gives details
domain, fabula planning problem, heuristic used.
Practical experience IPOCL algorithm suggests better heuristic evaluation
functions needed guide search process. Without sufficient heuristic functions,
behavior IPOCL devolves nearly breadth-first. Practical experience algorithm
also suggests difficult write heuristic functions practically distinguish
sibling nodes. problem defining heuristic functions distinguish
sibling nodes plan search space arises POCL algorithms, exacerbated
IPOCL due increased number structural features need distinguished.
243

fiRiedl & Young

4.6 Limitations Future Work
algorithm solves fabula generation problem, IPOCL demonstrated
generate sound narrative structures support believability enforcement
character intentions. IPOCL able achieve effectively decoupling concept
character intentions author intentions. Consequently, intentionality character actions must opportunistically discovered time actions discovered.
opportunistic discovery character intentions action instantiation significantly
increases branching factor detriment ability generate long narratives.
However, feel opportunistic discovery intentions vital part expanding
space narratives searched include logical causal progression
also well-motivated thus believable characters. alternative use
grammar (cf., Rumelhart, 1975), hierarchical task networks (cf., Sacerdoti, 1977),
form hierarchical decomposition (cf., Young, Pollack, & Moore, 1994) intentions dealt one level abstraction specific character actions dealt
primitive level. However, using grammars, HTNs, decompositional techniques
generate narrative requires reasoning higher levels abstraction action
introduces potentially rigid top-down structuring plot limit systems ability
find solutions might exist cannot described grammar/task-network.
additional limitations need addressed. First, IPOCL
algorithm asserts non-happening character actions must part frame
commitment, therefore motivated event (or initial state), IPOCL also assumes
frame commitments interval intentionality terminates action
successfully achieves goal frame commitment. Essentially, every character acts
according intention every intention achieved. inherently limits types
narratives generated. example, narratives character tries
achieve goal fails several times finally succeeding unlikely. Narratives
one character hero defeats another villain cannot generated. Although,
possible generate narrative villain first achieves goal
hero achieves goal (thus defeating villain).
inability consider actions support intentions never achieved appears inherent limitation partial-order planning approach. particular,
backward-chaining nature algorithm biases approach toward explaining actions. ensure soundness, causal threats eliminated backtracking occurs.
possible forward-chaining approach could resolve issue, expense
promiscuous intention generation. One way force algorithm consider narrative
structures one character defeats another character fails several times
succeeding seed plan space intermediate author goals indicating sets
states solutions must pass (Riedl, 2009). approach, however,
presupposes human author knows, wants, predict resultant
narrative structure.
mentioned Section 4.3.1, IPOCL currently weak mechanisms detect
prevent contradictory intentions character. Better heuristics may help control
situations resolved ordering actions ordering frames
244

fiNarrative Planning: Balancing Plot Character

commitment. possible extend algorithm include common-sense reasoning
semantic analysis frame commitment level. However, work done.
general, better heuristics needed. Heuristics divided domain-dependent
domain-independent heuristics. Domain-dependent heuristics, case, refer
employ knowledge characters, setting, preferences narrative structure. example, generate example Figure 13, use heuristic
penalizes narratives contain character goals thought unreasonable based
intuitions characters types stories sought. Domain-independent
heuristics difficult identify might include preferences fewer frames
commitment longer action sequences. Domain-independent heuristics reward
narrative structures dramatic arc likely require complex models narrative psychology described Gerrig colleagues (Gerrig, 1993; Gerrig & Bernardo,
1994) implemented Fitzgerald, Kahlon, Riedl (2009) may work
intermediate, incomplete narratives.

5. Evaluation Character Intentionality IPOCL-Generated
Fabula Plans
order perform empirical evaluation readers perception character intentionality IPOCL-generated fabulas, designed objective evaluation procedure based
question-answering order reveal readers understanding character intentions without use subjective questionnaires (Riedl & Young, 2005). goal evaluation
determine IPOCL-generated fabulas supported cognitive processes readers apply comprehend character actions better fabulas generated conventional
planning algorithms. evaluation procedure outlined follows. Two planning-based
algorithms used generate plans interpreted fabulas: IPOCL algorithm
conventional POCL planning algorithm. planner provided identical initialization parameters. first plan generated algorithm selected presented
study participants. plans must read, simple natural language generation
process used produce natural language text fabula plan. Recall
purpose fabula plan executed plan execution system, contain
temporal event information told story. Participants recruited randomly
assigned one two groups. Participants POCL group read POCL-generated
narrative text. Participants IPOCL group read IPOCL-generated narrative text.
variation question-answering protocol work Graesser et al. (1991)
used elicit participants mental models narratives. particular, focused
questions elicit understanding story world character goals motivations.
evaluate question-answering performance across groups? QUEST (Graesser
et al., 1991) takes graphical representation story reliably predicts questionanswering performance human might also read story. One implicit
assumptions behind QUEST provided well-structured story
contained within storys narrative structure answers question one might
ask character goals motivations. exploit assumption means measuring well story actually supports human readers reasoning character goals
motivations. is, story support human comprehension, see
245

fiRiedl & Young

Czar three lovely daughters. One day three daughters
went walking woods. enjoying much forgot
time stayed long. dragon kidnapped three daughters.
dragged off, cried help. Three heroes heard cries set
rescue daughters. heroes came fought dragon rescued
maidens. heroes returned daughters palace. Czar
heard rescue, rewarded heroes.

Figure 10: example story work Graesser et al. (1991).
manifested human question-answering performance. QUEST knowledge structures
translated fabula plans vice versa (Christian & Young, 2004). QUEST
knowledge structures automatically generated fabula plans, run QUEST predict
question-answering performance compare QUEST predictions actual performance.
expect see IPOCL-generated narratives understandable alternative; find greater correspondence QUEST actual performance
IPOCL condition find POCL condition.
5.1 QUEST Model Question-Answering
QUEST model (Graesser et al., 1991) accounts goodness-of-answer (GOA)
judgments questions asked passages prose. One application QUEST
model show people build cognitive representations stories read capture
certain relationships events story perceived goals characters
story (Graesser et al., 1991). QUEST knowledge structures represented visually
directed graphs nodes referring either story events (typically character actions)
character goals. Directed links capture relationship story event nodes
terms causality relationship events character goals terms
intentionality. readers cognitive representation story queried reader
answers questions story. types questions supported QUEST model
are: why, how, when, enablement, consequence. example, story Figure 10
(Graesser et al., 1991, Fig. 1) corresponding QUEST knowledge structure shown
Figure 11 (Graesser et al., 1991, Fig. 2). two types nodes QUEST
knowledge structure: event nodes, correspond occurrences story world,
goal nodes, correspond goals characters have. links nodes
capture different types relationships events character goals.
Consequence (C): terminal event node consequence initiating event
node.
Reason (R): initiating goal node reason terminal goal node.
Initiate (I): initiating event node initiates terminal goal node.
Outcome (O): terminal event node outcome initiating goal node.
Implies (Im): initiating event node implies terminal event node.
246

fiNarrative Planning: Balancing Plot Character

Im


GOAL 10
Daughters get
help



C

R
GOAL 12
Daughters cry

EVENT 11
Daughters got
help



EVENT 14
Heroes heard
cries



GOAL 15
Heroes rescue
daughters



R

C

EVENT 13
Daughters
cried

GOAL 17
Heroes fight
dragon
R
GOAL 19
Heroes go
daughters
dragon

EVENT 16
Heroes
rescued
daughters


C

C




EVENT 18
Heroes
fought dragon
C
EVENT 20
Heroes came
daughters
dragon

Figure 11: example QUEST model Czar Daughters story
Graesser et al. (1991).

QUEST model defines arc search procedures type question (e.g. why, how,
when, enablement, consequence). arc search procedures, starting queried
node, distinguish legal answer nodes illegal answer nodes. is, nodes
reachable arc search procedures legal answer nodes. legality answers
weight structural distance correspond GOA judgments human story readers.
5.2 Procedure
procedure involves comparing subject question-answering performance QUEST
question-answering predictions two conditions. POCL condition based narrative structures generated conventional POCL planning algorithm. IPOCL condition based narrative structures generated IPOCL algorithm. planners
initialized identical information defining story world. story world
based loosely story Aladdin. initial parameters included following:
initial state defines story world, including (a) locations, (b) objects, (c)
characters, (d) relevant initial relationships above. Story
world characters include Aladdin, King Jafar, Princess Jasmine, dragon, genie.
library operators defining events performed story world
characters.
outcome: Jasmine Jafar married genie dead.
Note even though initialization parameters identical conditions,
differences respective planners handle parameters. particular,
IPOCL makes use additional information action schemata actors whether
action happening. POCL planner ignored information,
impact ability find valid solution. initialization information used IPOCL
ignored POCL planner follows. First, operators must specify
247

fiRiedl & Young

parameters intentional actors (and characters acted upon). Second,
operators tagged happenings. Finally, operators effects form
intends(a, p) variable bound ground symbol representing
character, p variable bound literal becomes one
characters internal goals. Effects form used IPOCL implementation
motivation planning ensure actions cause frames commitment.
Since operators preconditions form, POCL planner utilize
information. Appendix lists entire set initialization parameters used
evaluation.
fabula plans generated two planning algorithms shown Appendix.
plans human-readable, plan input Longbow discourse planner (Young et al., 1994). Longbow results plan consisting communicative acts
describe-character describe-event conveying temporally ordered information narrative. discourse plan steps rendered natural language
using simple template-matching procedure. resulting narrative texts POCL
condition IPOCL condition shown Figures 12 13, respectively. Similarities
two narratives make comparison study possible. Specifically, set events
IPOCL-generated narrative superset events POCL-generated narrative. one distinct action ordering difference two fabula plans:
IPOCL condition event King falls love Jasmine temporally constrained occur first, POCL condition ordering event
under-constrained falls late text. POCL condition, event come
earlier, participants may inferred relationship king falling love
Aladdins actions even though actual relationship generated QUEST
graph. believe ordering insignificant impact results.
fabula plans also converted structures QUEST use predict
question-answering performance. use procedure described Christian Young
(2004). algorithm generating QUEST graph structures plan
evaluated POCL plans involving single character.9 IPOCL plans, however, contain
additional structures frames commitment motivation links part
conventional plan representations. Consequently, algorithm generating QUEST
graph structure plan extended take consideration IPOCL plans.
additional study authors (not reported) determined QUEST knowledge structures derived IPOCL plans extended algorithm significantly predict questionanswering judgments structural distance ignored (p < 0.0005). modifications
Christian Youngs (2004) algorithm beyond scope paper, details
found work Riedl (2004).
evaluation involved questionnaire participants read story make
goodness-of-answer (GOA) judgments pairs question answers. questionanswer pair question intentional action performed character
story possible answer. example, question, Aladdin slay
9. Christian Young (2004) compare DPOCL plans QUEST knowledge structures. DPOCL
decompositional, partial order causal link planning algorithm (Young et al., 1994) extends
conventional POCL algorithm explicitly representing hierarchical relationships abstract
primitive planning operators.

248

fiNarrative Planning: Balancing Plot Character

woman named Jasmine. king named Jafar. story
King Jafar becomes married Jasmine. magic genie.
also story genie dies.
magic lamp. dragon. dragon magic lamp.
genie confined within magic lamp. brave knight named Aladdin.
Aladdin travels castle mountains. Aladdin slays dragon.
dragon dead. Aladdin takes magic lamp dead body dragon.
Aladdin travels mountains castle. Aladdin hands magic lamp
King Jafar. genie magic lamp. King Jafar rubs magic lamp
summons genie it. genie confined within magic lamp.
genie casts spell Jasmine making fall love King Jafar. Jasmine
madly love King Jafar. Aladdin slays genie. King Jafar married.
Jasmine beautiful. King Jafar sees Jasmine instantly falls love her.
King Jafar Jasmine wed extravagant ceremony.
genie dead. King Jafar Jasmine married. end.

Figure 12: Text story control condition.

woman named Jasmine. king named Jafar. story
King Jafar becomes married Jasmine. magic genie.
also story genie dies.
magic lamp. dragon. dragon magic lamp.
genie confined within magic lamp.
King Jafar married. Jasmine beautiful. King Jafar sees Jasmine
instantly falls love her. King Jafar wants marry Jasmine. brave
knight named Aladdin. Aladdin loyal death King Jafar. King Jafar orders
Aladdin get magic lamp him. Aladdin wants King Jafar magic
lamp. Aladdin travels castle mountains. Aladdin slays dragon.
dragon dead. Aladdin takes magic lamp dead body dragon.
Aladdin travels mountains castle. Aladdin hands magic lamp
King Jafar. genie magic lamp. King Jafar rubs magic lamp
summons genie it. genie confined within magic lamp. King
Jafar controls genie magic lamp. King Jafar uses magic lamp
command genie make Jasmine love him. genie wants Jasmine love
King Jafar. genie casts spell Jasmine making fall love King
Jafar. Jasmine madly love King Jafar. Jasmine wants marry King Jafar.
genie frightening appearance. genie appears threatening Aladdin.
Aladdin wants genie die. Aladdin slays genie. King Jafar Jasmine wed
extravagant ceremony.
genie dead. King Jafar Jasmine married. end.

Figure 13: Text story experimental condition.
dragon? might paired answer, King Jafar ordered Aladdin get
magic lamp him. participants asked rate goodness answer
given question four-point scale ranging bad answer good
answer. participants shown examples question-answer pairs rating
task began, otherwise given definition good poor trained make
judgment. Participants rated GOA question-answer pair every combination
249

fiRiedl & Young

goal nodes QUEST knowledge structure story. POCL condition
questionnaire 52 question-answer pairs IPOCL condition questionnaire
82 question-answer pairs due increased story plan length. Participants asked
read story text completely least proceeding ratings task
allowed refer back original text time rating task.
narrative, QUEST used predict whether question-answer pairs would
considered good poor based arc search procedure following forward
reason arcs, backward initiate arcs, backward outcome arcs (Graesser et al., 1991).
hypotheses experiment follows.
Hypothesis 1 Participants IPOCL condition higher mean GOA judgment ratings question-answer pairs identified QUEST good
participants POCL condition.
Hypothesis 2 Participants IPOCL condition lower mean GOA judgment ratings question-answer pairs identified QUEST poor
participants POCL condition.
actual question-answering performance participants results statistically higher
GOA ratings question-answer pairs judged QUEST good, greater
correspondence QUEST predictions actual performance. Likewise, actual
question-answering performance participants results statistically lower GOA ratings
question-answer pairs judged QUEST poor, greater correspondence QUEST predictions actual performance. Poor correspondence
QUEST predictions actual question-answering performance indication narrative lacks structure supports human understanding character goals, intentions,
motivations.
Thirty-two undergraduate students Computer Science program North Carolina
State University participated study. participants enrolled course Game
Design Development compensated time five extra credit points
final grade course.
5.3 Results Discussion
question-answer pair questionnaire assigned good rating poor
rating based QUEST prediction. Good question-answer pairs assigned value
4 poor question-answer pairs assigned value 1. Human GOA ratings
question-answer pairs also assigned values 1 4 1 corresponding
poor answer 4 corresponding good answer. results participants
answers questionnaire answers compiled Table 1. numbers mean
GOA ratings category condition. numbers parentheses standard deviations results. Mean human question-answering performance
agreement QUEST mean GOA ratings question-answer pairs categorized
good closer 4 mean GOA ratings question-answer pairs categorized
poor closer 1.
standard one-tailed t-test used compare mean GOA rating good
question-answer pairs IPOCL condition mean GOA rating good question250

fiNarrative Planning: Balancing Plot Character

Condition
IPOCL
POCL

Mean GOA rating good
question-answer pairs
(standard deviation)
3.1976 (0.1741)
2.9912 (0.4587)

Mean GOA rating poor
question-answer pairs
(standard deviation)
1.1898 (0.1406)
1.2969 (0.1802)

Table 1: Results evaluation study.
answer pairs POCL condition. result t-test 15 degrees freedom
yields = 1.6827 (p < 0.0585). result strongly suggestive Hypothesis 1
supported.
standard one-tailed t-test used compare mean GOA rating poor
question-answer pairs IPOCL condition mean GOA rating poor questionanswer pairs POCL condition. result t-test 15 degrees freedom
yields = 1.8743 (p < 0.05). Participants IPOCL condition significantly lower
GOA ratings poor question-answer pairs participants POCL condition.
Hypothesis 2 supported.
interesting note standard deviation results POCL condition
good question-answer pairs high. analysis reveals human participants
likely judge question-answer pair good lack evidence
possibility character action might intentional. speculate
reader/viewers simultaneously consider multiple hypotheses explaining character behavior
disproved. Regardless content communicative act, one
always able provide less plausible explanation meaning (Sadock,
1990).
couple limitations note. control narrative length.
possible effects measured result narrative length instead improved narrative structure generated IPOCL. believe unlikely, future
evaluations add filler sentences POCL condition narrative impact character intentionality control narrative matches length IPOCL
condition. According narrative comprehension theories Graesser et al. (1994)
Trabasso colleagues (Trabasso & Sperry, 1985; Trabasso & van den Broek, 1985),
filler sentences included readers mental model meaningful way
causally related concepts mental model
narrative. Consequently, felt safe leave filler sentences out. Another
limitation model discourse used Longbow discourse planner simplistic. Specifically, explicit statements character intentions incorporated
narrative text experimental condition due overly promiscuous discourse
model used Longbow discourse planner. believe results would
explicit statements excluded human readers good
inferring intentions stories (Graesser et al., 1991, 1994). However, complete
would control artifacts discourse generation.
conclude strong evidence narrative experimental condition supported reader comprehension character goals, intentions, motivations better
narrative control condition. Since generated identical initial251

fiRiedl & Young

ization parameters, significant independent variable generation algorithm.
infer improvement IPOCL condition POCL condition due
enhancements automated story generation capability introduced IPOCL
algorithm.

6. Conclusions
objective research presented develop approach generation
narrative fabula properties supporting audience perception character
intentionality causal plot progression. informal analysis related work suggests
narrative generation systems categorized using simulation-based deliberative approaches. Simulation-based approaches tend produce narratives reasonable
character believability unlikely produce narrative globally coherent plots.
due fact simulation-based approaches model characters attempt
optimize character decisions given moment. Thus simulation-based approaches
prone local maxima. Deliberative approaches reviewed article directly consider character intentions otherwise likely produce narratives causally
coherent plot progressions. due fact deliberative narrative generation
systems tend reason entire plot instead separately characters.
informal analysis, see evidence deliberative system cannot reliably produce narrative structures character believability (especially character intentionality).
use refinement search approach construct entire fabula perspective
author. approach consequently deliberative one. favor refinement search
partial-order plans appear good representation fabula narrative.
analysis, algorithms solve planning problem sufficient generating narratives character intentionality planning algorithms conventionally
designed provide singular agent ability achieve singular goal. Stories
likely involve multiple agents characters necessarily
cooperating achieve singular goal state. Accordingly, developed deliberative fabula generation algorithm reasons understandability characters
perspective hypothetical audience. IPOCL fabula generation algorithm treats
potential solution flawed unless audience capable understanding individual
(and potentially conflicting) goals character motivated characters
adopt goals throughout progression narrative. IPOCL contains routines repairing character intentionality flaws non-deterministically attributing goals
characters generating event sequences motivate goals.
adopting approach narrative generation IPOCL algorithm, realize
several limitations. First, IPOCL incapable producing narrative structures
character fails achieve goals. Character failure sort natural part
stories especially important comedy tragedy (Charles et al., 2003).
Unfortunately, planners produce plans fail e.g. cannot execute completion
planner prune branch search space backtrack. Conflict
arise characters characters adopt contradictory goals. However,
character succeed achieving goal, although happen serially
conflicting frames commitment temporally ordered. Second, work date,
252

fiNarrative Planning: Balancing Plot Character

assumed fabula sjuzet reasoned distinctly. is,
fabula generated indicating narrative about, separate process reason
narrative told. may suffice simple telling generated
narratives. Intuitively, order achieve sophisticated effects audience
suspense, one might consider narrative told generator
determining told.
believe work reported represents step towards achieving greater capability computer systems generate fictional narratives communication, entertainment, education, training. incremental step, building established artificial
intelligence technologies planning cognitive science principles. Non-subjective empirical evidence suggests achieved improvement narrative generation
alternative, conventional planners. Furthermore, believe created framework
continue make incremental improvements narrative generation capabilities. example, able incorporate ability handle folk psychological
models character personality (Riedl & Young, 2006). system generate stories
capable adapting narrative users preferences abilities, expanded replay
value, capable interacting user ways initially envisioned
system designers. Narrative generation one example instilling computational systems ability reason narrative result system
capable communicating, entertaining, educating, training.

253

fiRiedl & Young

Appendix A.
appendix contains details Aladdin planning domain used evaluation,
including planning problem specification, heuristics, complete diagrams plans generated accompanying QUEST diagrams, partial trace generated
creation Aladdin narrative.
A.1 Planning Problem Specification Study
POCL planning algorithm used evaluation study implementation
IPOCL algorithm use PDDL-like formulations. problem describes initial world state
goal situation. operator library contains operator schemata. evaluation
study, POCL planning algorithm IPOCL algorithm given inputs.
Note however parts inputs used POCL algorithm.
following propositions define initial state:
character(aladdin)
male(aladdin)
knight(aladdin)
at(aladdin, castle)
alive(aladdin)
single(aladdin)
loyal-to(aladdin, jafar)
character(jafar)
male(jafar)
king(jafar)
at(jafar, castle)
alive(jafar)
single(jafar)

character(jasmine)
female(jasmine)
at(jasmine, castle)
alive(jasmine)
single(jasmine)
beautiful(jasmine)
character(dragon)
monster(dragon)
dragon(dragon)
at(dragon, mountain)
alive(dragon)
scary(dragon)

character(genie)
monster(genie)
genie(genie)
in(genie, lamp)
confined(genie)
alive(genie)
scary(genie)
place(castle)
place(mountain)
thing(lamp)
magic-lamp(lamp)
has(dragon, lamp)

following propositions define outcome situation:
married-to(jafar, jasmine)

alive(genie)

following action schemata provided operator library evaluation study. Note deviations conventional PDDL. Constraints indicate immutable
propositions must always true. Constraints function like preconditions except
satisfied initial state operators negate proposition
used constraint operator schema. actors slot lists parameters
refer actors intend operation; assume first parameter always intentional actor. Further, one actor listed,
operator joint operation, meaning operator accomplished
many actors working team actors intend one effects operator.
happening true, operator allowed remain orphan. operators
effects form intends(?x, ?c) indicating effect one characters
bound ?x intention achieve literal bound ?c. operators
preconditions form; intention propositions exclusively used IPOCL
algorithm implementation.

254

fiNarrative Planning: Balancing Plot Character

Action: travel (?traveller, ?from, ?dest)
actors: ?traveller
constraints: character(?traveller), place(?from), place(?dest)
precondition: at(?traveller, ?from), alive(?traveller), ?from6=?dest
effect: at(?traveller, ?from), at(?traveller, ?dest)
Action: slay (?slayer, ?monster, ?place)
actors: ?slayer
constraints: knight(?slayer), monster(?monster), place(?place)
precondition: at(?slayer, ?place), at(?monster, ?place), alive(?slayer), alive(?monster)
effect: alive(?monster)
Action: pillage (?pillager, ?body, ?thing, ?place)
actors: ?pillager
constraints: character(?pillager), character(?body), thing(?thing), place(?place)
precondition: at(?pillager, ?place), at(?body, ?place), has(?body, ?thing),
alive(?body), alive(?pillager), ?pillager6=?body
effect: has(?body, ?thing), has(?pillager, ?thing)
Action: give (?giver, ?givee, ?thing, ?place)
actors: ?giver
constraints: character(?giver), character(?givee), thing(?thing), place(?place)
precondition: at(?giver, ?place), at(?givee, ?place), has(?giver, ?thing),
alive(?giver), alive(?givee), ?giver6=?givee
effect: has(?giver, ?thing), has(?givee, ?thing)
Action: summon (?char, ?genie, ?lamp, ?place)
actors: ?char
constraints: character(?char), genie(?genie), magic-lamp(?lamp), place(?place)
precondition: at(?char, ?place), has(?char, ?lamp), in(?genie, ?lamp),
alive(?char), alive(?genie), ?char6=?genie
effect: at(?genie, ?place), in(?genie, ?lamp), confined(?genie), controls(?char, ?genie, ?lamp)
Action: love-spell (?genie, ?target, ?lover)
actors: ?genie
constraints: genie(?genie), character(?target), character(?lover)
precondition: confined(?genie), loves(?target, ?lover), alive(?genie), alive(?target), alive(?lover),
?genie6=?target, ?genie6=?lover, ?target6=?lover
effect: loves(?target, ?lover), intends(?target, married-to(?target, ?lover))
Action: marry (?groom, ?bride, ?place)
actors: ?groom, ?bride
constraints: male(?groom), female(?bride), place(?place)
precondition: at(?groom, ?place), at(?bride, ?place), loves(?groom, ?bride), loves(?bride, ?groom),
alive(?groom), alive(?bride)
effect: married(?groom), married(?bride), single(?groom), single(?bride),
married-to(?groom, ?bride), married-to(?bride, ?groom)

255

fiRiedl & Young

Action: fall-in-love (?male, ?female, ?place)
actors: ?male
happening:
constraints: male(?male), female(?female), place(?place)
precondition: at(?male, ?place), at(?female, ?place), single(?male), alive(?male), alive(?female),
loves(?male, ?female), loves(?female, ?male), beautiful(?female)
effect: loves(?male, ?female), intends(?male, married-to(?male, ?female))
Action: order (?king, ?knight, ?place, ?objective)
actors: ?king
constraints: king(?king), knight(?knight), place(?place)
precondition: at(?king, ?place), at(?knight, ?place), alive(?king), alive(?knight),
loyal-to(?knight, ?king)
effect: intends(?knight, ?objective)
Action: command (?char, ?genie, ?lamp, ?objective)
actors: ?char
constraints: character(?char), genie(?genie), magic-lamp(?lamp)
precondition: has(?char, ?lamp), controls(?char, ?genie, ?lamp), alive(?char), alive(?genie),
?char6=?genie
effect: intends(?genie, ?objective)
Action: appear-threatening (?monster, ?char, ?place)
actors: ?monster
happening:
constraints: monster(?monster), character(?char), place(?place)
precondition: at(?monster, ?place), at(?char, ?place), scary(?monster), ?monster6=?char
effect: intends(?char, alive(?monster))

mentioned Section 4.5, required domain-dependent domain-independent
heuristics generate example fabula shown Figure 13 (the plan structure diagram
shown Figure 15). IPOCL, heuristics evaluate plan node return integer
solutions evaluated 0 higher number farther plan node
solution. used two heuristic functions whose return values added
together.
Domain-independent heuristic
1 action
1 flaw
10 frame commitment one frame per character
1000 orphans performed characters frames
commitment
Domain-dependent heuristic
5000 repeat actions
5000 frames commitment character-goal combinations
following lists:
256

fiNarrative Planning: Balancing Plot Character

Aladdin intends has(king, lamp), alive(genie), alive(dragon), has(hero,
lamp), married-to(hero, jasmine)
Jafar intends married-to(jafar, jasmine)
Jasmine intends married-to(jasmine, jafar), married-to(jasmine,
jafar)
Genie intends loves(jasmine, jafar), loves(jafar, jasmine), loves(aladdin,
jasmine), loves(jasmine, jafar)
1000 action marry associated two frames commitment
A.2 Plan Diagrams QUEST Structures Study
subsequent figures show plan diagrams corresponding QUEST structures
fabula generated evaluation.
Figure 14: fabula plan automatically generated POCL planning algorithm
POCL condition evaluation study.
Figure 15: fabula plan automatically generated IPOCL algorithm implementation IPOCL condition evaluation study.
Figure 16: QUEST structure corresponding fabula plan POCL
condition evaluation study.
Figure 17: QUEST structure corresponding fabula plan IPOCL
condition evaluation study.
Figures 14 15, solid boxes represent actions plan structure (where last
action goal step). Solid arrows represent causal links associated text
effect preceding action precondition successive action. Dashed arrows
temporal constraints found planning algorithm, indicating necessary temporally
ordering two actions added due promotion demotion strategies resolving
causal threats. Figure 15, ovals frames commitment horizontal dashed lines
represent membership actions frames commitment.

257

fiRiedl & Young

Key:
A: Aladdin
J: Jasmine
K: King Jafar
D: Dragon
G: Genie

Travel (A, castle, mount)
at(A, mount)

Slay (A, D, mount)

at(A, mount)
at(A, mount)

alive(D)

Pillage (A, D, lamp, mount)
Travel (A, mount, castle)
at(A, castle)

Give (A, K, lamp, castle)
has(K, lamp)

at(A, castle)

Summon (K, G, lamp, castle)
confined(G)

Fall-In-Love (K, J, castle)
loves(J, K)

at(G, castle)

Love-Spell (G, K, J)
love(J, K)

Slay (A, G, castle)
Marry (K, J, castle)
married(K, J)

alive(G)

Goal: married(K, J), alive(G)

Figure 14: Fabula plan representation story used POCL condition
evaluation study.

258

fiNarrative Planning: Balancing Plot Character

Fall-In-Love (K, J, castle)
intends(K, married(K, J))

Order (K, A, castle, (has K lamp))

intends(K, married(K, J))

at(A, mount)
at(A, mount)

Slay (A, D, mount)

at(A, mount)

alive(D)

Pillage (A, D, lamp, mount)

at(A, castle)
loves(J, K)

Give (A, K, lamp, castle)
has(K, lamp)

at(A, castle)
at(A, castle)

Summon (K, G, lamp, castle)
controls(K, G)

confined(G)

Command (K, G, castle, (loves J K))

at(G, castle)
at(G, castle)

Appear-Threat (G, A, castle)

intends(G, loves(J, K))

Genie intends
loves(J, K)

intends(A, alive(G))

Love-Spell (G, K, J)
loves(J, K)

Slay (A, G, castle)

Jasmine intends
married(J, K)

intends(J, married(J, K))

Marry (K, J, castle)

alive(G)

Aladdin intends
alive(G)

King intends married(K, J)

Travel (A, mount, castle)

Aladdin intends has(K, lamp)

Travel (A, castle, mount)

married(K, J)

Goal: married(K, J), alive(G)

Figure 15: Fabula plan representation story used experimental IPOCL
evaluation study.

259

fiRiedl & Young

C

GOAL 9
Aladdin give
lamp King

R

R
GOAL 7
Aladdin
travel
castle
GOAL 5
Aladdin
pillage lamp
Dragon

R







R
GOAL 3
Aladdin slay
Dragon
R
GOAL 1
Aladdin
travel
mountain

EVENT 10
Aladdin gave
lamp King
C
EVENT 8
Aladdin
traveled
castle



C

EVENT 4
Aladdin slew
Dragon
C
EVENT 2
Aladdin
traveled
mountain

GOAL 13
Genie cast
love-spell





EVENT 12
King
summoned
Genie
C
EVENT 14
Genie cast
love-spell

C

C

EVENT 6
Aladdin
pillaged lamp
Dragon
C



GOAL 11
King
summon
Genie

GOAL 15
Aladdin slay
Genie



EVENT 16
Aladdin slew
Genie

C
EVENT 17
King fell
love
Jasmine
GOAL 18
King marry
Jasmine

C
C


EVENT 20
King
Jasmine
married



GOAL 19
Jasmine
marry King

Figure 16: QUEST knowledge structure story plan POCL condition.

260

fiNarrative Planning: Balancing Plot Character

EVENT 1
King fell
love
Jasmine
C


GOAL 12
Aladdin give
lamp King

R

R
GOAL 10
Aladdin
travel
castle
GOAL 8
Aladdin
pillage lamp
Dragon

R







R
GOAL 6
Aladdin slay
Dragon
R
GOAL 4
Aladdin
travel
mountain

EVENT 13
Aladdin gave
lamp King
C
EVENT 11
Aladdin
traveled
castle

GOAL 23
King marry
Jasmine

C



C
EVENT 5
Aladdin
traveled
mountain

GOAL 24
Jasmine
marry King



C

GOAL 19
Genie cast
love-spell

C

R

EVENT 9
Aladdin
pillaged lamp
Dragon
EVENT 7
Aladdin slew
Dragon

EVENT 25
King
Jasmine
married



C


EVENT 20
Genie cast
love-spell



C




C

GOAL 17
King
command
Genie cast
R
GOAL 14
King
summon
Genie
R
GOAL 2
King order
Aladdin
get lamp




C


EVENT 18
King
commanded
Genie cast
C
EVENT 15
King
summoned
Genie

EVENT 16
Genie
appeared
frightening

C

C
EVENT 3
King ordered
Aladdin
get lamp

C

GOAL 21
Aladdin slay
Genie


C



EVENT 22
Aladdin slew
Genie

Figure 17: QUEST knowledge structure story plan IPOCL condition.

261

fiRiedl & Young

A.3 Trace
following portion trace generated IPOCL initialized fabula
planning problem specification heuristic. trace focuses generation
nodes plan space contribute final solution (shown graphically
Figure 15).
plan0
reason: initial plan
working on: open condition married-to(jafar, jasmine) step goal
children: 98 (visited 2; selecting 9)
plan 9
reason: created new step 1: marry(jafar, jasmine, castle) solve married-to(jafar, jasmine)
working on: open motivation intends(jafar, married-to(jafar, jasmine)) frame 2
children: 9 (visited 2; selecting 105)
plan 105
reason: created new step 2: fall-in-love(jafar, jasmine, castle) solve
intends(jafar, married-to(jafar, jasmine))
working on: open motivation intends(jasmine, married-to(jasmine, jafar)) frame 1
children: 3 (visited 1; selecting 122)
plan 122
reason: created new step 3: love-spell(genie, jasmine, jafar) solve
intends(jasmine, married-to(jasmine, jafar))
working on: open motivation intends(genie, loves(jasmine, jafar)) frame 3
children: 8 (visited 2; selecting 141)
plan 141
reason: created new step 4: command(jafar, genie, lamp, loves(jasmine, jafar)) solve
intends(genie, loves(jasmine, jafar))
working on: open condition alive(genie) step 4
children: 1 (visited 1; selecting 197)
...
plan 591
reason: created new step 6: give(aladdin, jafar, lamp, castle) solve has(jafar, lamp)
working on: open motivation intends(aladdin, has(jafar, lamp)) frame 4
children: 4 (visited 2; selecting 4675)
plan 4675
reason: created new step 7: order(jafar, aladdin, castle, has(jafar, lamp)) solve
intends(aladdin, has(jafar, lamp))
working on: open condition loyal-to(aladdin, jafar) step 7
children: 1 (visited 1; selecting 21578)
...
plan 21597
reason: created new step 8: pillage(aladdin, dragon, lamp, mountain) solve has(aladdin, lamp)
working on: open condition alive(aladdin) step 8
children: 1 (visited 1; selecting 21653)

262

fiNarrative Planning: Balancing Plot Character

...
plan 1398116
reason: created new step 12: slay(aladdin, genie, castle) solve alive(genie)
working on: causal threat alive(genie) 0 3, clobbered step 12
children: 1 (visited 1; selecting 1398282)
...
plan 1398289
reason: created new step 13: appear-threatening(genie, aladdin, mountain) solve
intends(aladdin, alive(genie))
working on: open condition scary(genie) step 13
children: 1 (visited 1; selecting 1398304)
...
plan 1398364
reason: adoption step 4 frame 2: jafar intends married-to(jafar, jasmine)
working on: intent flaw aladdin, possibly link step 8 frame 4: aladdin intends
has(jafar, lamp)
children: 2 (visited 2; selecting 1398368)
plan 1398368
reason: adoption step 8 frame 4: aladdin intends has(jafar, lamp)
working on: intent flaw aladdin, possibly link step 10 frame 4: aladdin intends
has(jafar, lamp)
children: 2 (visited 2; selecting: 1398376)
...
plan 1398384
reason: adoption step 2 frame 2: jafar intends married-to(jafar, jasmine)
working on: intent flaw jasmine, possibly link step 12 frame 1: jasmine intends
married-to(jasmine, jafar)
children: 2 (visited 2; selecting 1398400)
...
plan 1398576
reason: adoption step 7 frame 2: jafar intends married-to(jafar, jasmine)
working on: intent flaw aladdin, possibly link step 9 frame 4: aladdin intends
has(jafar, lamp)
children: 2 (visited 1; selecting 1398640)
plan 1398640
reason: adoption step 9 frame 4: aladdin intends has(jafar, lamp)
solution found

263

fiRiedl & Young

References
Aylett, R. (1999). Narrative virtual environments towards emergent narrative.
Mateas, M., & Sengers, P. (Eds.), Narrative Intelligence: Papers AAAI Fall
Symposium (Technical Report FS-99-01), pp. 8386. AAAI Press, Menlo Park.
Aylett, R. (2000). Emergent narrative, social immersion storification. Proceedings
1st International Workshop Narrative Interactive Learning Environments.
Bae, B.-C., & Young, R. M. (2008). use flashback foreshadowing surprise arousal
narrative using plan-based approach. Proceedings 1st International
Conference Interactive Digital Storytelling, pp. 156167.
Bal, M. (1998). Narratology: Introduction Theory Narrative. University
Toronto Press.
Bates, J. (1992). Virtual reality, art, entertainment. Presence: Journal Teleoperators Virtual Environments, 1 (1), 133138.
Bates, J. (1994). role emotion believable agents. Communications ACM,
37 (7), 122125.
Bates, J., Loyall, A., & Reilly, W. (1992). Integrating reactivity, goals, emotion
broad agent. Proceedings 14th Annual Conference Cognitive Science
Society, pp. 696706.
Black, J. B., & Wilensky, R. (1979). evaluation story grammars. Cognitive Science,
3, 213230.
Blair, D., & Meyer, T. (1997). Tools interactive virtual cinema. Trappl, R., &
Petta, P. (Eds.), Creating Personalities Synthetic Actors: Towards Autonomous
Personality Agents, pp. 8391. Springer.
Blumberg, B., & Galyean, T. (1995). Multi-level direction autonomous creatures
real-time virtual environments. Proceedings 22nd Annual Conference
Computer Graphics, pp. 4754.
Bratman, M. (1987). Intentions, Plans, Practical Reason. Harvard University Press,
Cambridge, MA.
Bruner, J. (1990). Acts Meaning. Harvard University Press, Cambridge.
Callaway, C., & Lester, J. (2002). Narrative prose generation. Artificial Intelligence, 139 (2),
213252.
Carbonell, J. (1980). Towards process model human personality traits. Artificial
Intelligence, 15, 4974.
Cavazza, M., Charles, F., & Mead, S. (2002). Planning characters behaviour interactive
storytelling. Journal Visualization Computer Animation, 13, 121131.
Charles, F., Lozano, M., Mead, S., Bisquerra, A., & Cavazza, M. (2003). Planning formalisms authoring interactive storytelling. Proceedings 1st International Conference Technologies Interactive Digital Storytelling Entertainment.
264

fiNarrative Planning: Balancing Plot Character

Chatman, S. (1993). Reading Narrative Fiction. Macmillan Publishing Company, New
York.
Cheong, Y.-G., & Young, R. M. (2008). Narrative generation suspense: Modeling
evaluation. Proceedings 1st International Conference Interactive Digital
Storytelling, pp. 144155.
Christian, D., & Young, R. (2004). Comparing cognitive computational models
narrative structure. Proceedings 19th National Conference Artificial Intelligence, pp. 385390.
Dehn, N. (1981). Story generation TALE-SPIN. Proceedings 7th International
Joint Conference Artificial Intelligence, pp. 1618.
Dennett, D. (1989). Intentional Stance. MIT Press, Cambridge, MA.
Fikes, R., & Nilsson, N. (1971). STRIPS: new approach application theorem
proving problem solving. Artificial Intelligence, 2, 189208.
Fitzgerald, A., Kahlon, G., & Riedl, M. O. (2009). computational model emotional
response stories. Proceedings 2nd Joint International Conference
Interactive Digital Storytelling, pp. 312315.
Gerrig, R. (1994). Narrative thought?. Personality Social Psychology Bulletin, 20 (6),
712715.
Gerrig, R. J. (1993). Experiencing Narrative Worlds: Psychological Activities
Reading. Yale University Press, New Haven.
Gerrig, R. J., & Bernardo, A. (1994). Readers problem-solvers experience
suspense. Poetics, 22, 459472.
Gervas, P., Daz-Agudo, B., Peinado, F., & Hervas, R. (2005). Story plot generation based
CBR. Journal Knowledge-Based Systems, 18 (45), 235242.
Graesser, A., Lang, K. L., & Roberts, R. M. (1991). Question answering context
stories. Journal Experimental Psychology: General, 120 (3), 254277.
Graesser, A., Singer, M., & Trabasso, T. (1994). Constructing inferences narrative
text comprehension. Psychological Review, 101 (3), 371395.
Gratch, J., & Marsella, S. (2004). domain-independent framework modeling emotion.
Journal Cognitive Systems Research, 5 (4), 269306.
Grosz, B., & Sidner, C. (1990). Plans discourse. Cohen, P., Morgan, J., & Pollack,
M. (Eds.), Intentions Communication, pp. 417444. MIT Press.
Grosz, B., & Kraus, S. (1996). Collaborative plans complex group action. Artificial
Intelligence, 86 (2), 269357.
Hayes-Roth, B., van Gent, R., & Huber, D. (1997). Acting character. Trappl, R.,
& Petta, P. (Eds.), Creating Personalities Synthetic Characters: Towards Autonomous Personality Agents, pp. 92112. Springer.
Herman, D. (2002). Story Logic: Problems Possibilities Narrative. University
Nebraska Press, Lincoln, NE.
265

fiRiedl & Young

Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generation
heuristic search. Journal Artificial Intelligence Research, 14, 253302.
Jhala, A. H. (2009). Cinematic Discourse Generation. Ph.D. thesis, North Carolina State
University.
Kelso, M., Weyhrauch, P., & Bates, J. (1993). Dramatic presence. Presence: Journal
Teleoperators Virtual Environments, 2 (1), 115.
Knoblock, C. (1994). Generating parallel execution plans partial-order planner.
Proceedings 2nd International Conference Artificial Intelligence Planning Systems, pp. 98103.
Laurel, B. (1986). Toward Design Computer-Based Interactive Fantasy System.
Ph.D. thesis, Ohio State University.
Lebowitz, M. (1984). Creating characters story-telling universe. Poetics, 13, 171194.
Lebowitz, M. (1985). Story-telling planning learning. Poetics, 14, 483502.
Lebowitz, M. (1987). Planning stories. Proceedings 9th Annual Conference
Cognitive Science Society, pp. 234242.
Lester, J., Voerman, J., Towns, S., & Callaway, C. (1999). Deictic believability: Coordinating gesture, locomotion, speech lifelike pedagogical agents. Applied Artificial
Intelligence, 13 (4-5), 383414.
Loyall, A. B. (1997). Believable Agents: Building Interactive Personalities. Ph.D. thesis,
School Computer Science, Carnegie Mellon University.
Maes, P., Darrell, T., Blumberg, B., & Pentland, A. (1995). ALIVE system: Fullbody interaction autonomous agents. Proceedings 1995 Conference
Computer Animation.
Mateas, M. (1997). Oz-centric review interactive drama believable agents. Technical report CMU-CS-97-156, School Computer Science, Carnegie Mellon University.
Mateas, M., & Sengers, P. (1999). Narrative intelligence. Mateas, M., & Sengers, P.
(Eds.), Narrative Intelligence: Papers 1999 Fall Symposium (Technical Report
FS-99-01), pp. 110. AAAI Press, Menlo Park, CA.
McKoon, G., & Ratcliff, R. (1992). Inference reading. Psychological Review, 99,
440466.
Meehan, J. R. (1976). Metanovel: Writing Stories Computers. Ph.D. thesis, Yale
University.
Meehan, J. R. (1977). TALE-SPIN: interactive program writes stories. Proceedings 5th International Joint Conference Artificial Intelligence, pp. 9198.
Penberthy, J. S., & Weld, D. S. (1992). UCPOP: sound, complete, partial-order planner
ADL. Proceedings 3rd International Conference Knowledge Representation
Reasoning, pp. 103114.
Perez Perez, R., & Sharples, M. (2001). MEXICA: computer model cognitive
account creative writing. Journal Experimental Theoretical Artificial Intelligence, 13, 119139.
266

fiNarrative Planning: Balancing Plot Character

Perlin, K., & Goldberg, A. (1996). Improv: system scripting interactive actors
virtual worlds. Proceedings 23rd International Conference Computer
Graphics Interactive Techniques, pp. 205216.
Pollack, M. (1992). uses plans. Artificial Intelligence, 57 (1), 4368.
Porteous, J., & Cavazza, M. (2009). Controlling narrative generation planning trajectories: role constraints. Proceedings 2nd International Conference
Interactive Digital Storytelling, pp. 234245.
Prince, G. (1987). Dictionary Narratology. University Nebraska Press, Lincoln.
Propp, V. (1968). Morphology Folktale. University Texas Press, Austin, TX.
Reilly, W. (1996). Believable Social Emotional Agents. Ph.D. thesis, School Computer
Science, Carnegie Mellon University.
Riedl, M. O. (2004). Narrative Generation: Balancing Plot Character. Ph.D. thesis,
North Carolina State University.
Riedl, M. O. (2009). Incorporating authorial intent generative narrative systems.
Louchart, S., Roberts, D., & Mehta, M. (Eds.), Intelligent Narrative Technologies II:
Papers 2009 Spring Symposium (Technical Report SS-09-06), pp. 9194, Palo
Alto, CA. AAAI Press.
Riedl, M. O., & Young, R. M. (2005). objective character believability evaluation procedure multi-agent story generation systems. Proceedings 5th International
Conference Intelligent Virtual Agents (IVA), pp. 278291.
Riedl, M. O., & Young, R. M. (2006). Story planning exploratory creativity: Techniques
expanding narrative search space. New Generation Computing, 24 (3), 303323.
Rizzo, P., Veloso, M., Miceli, M., & Cesta, A. (1999). Goal-based personalities social
behaviors believable agents. Applied Artificial Intelligence, 13, 239272.
Rumelhart, D. (1975). Notes schema stories. Bobrow, D., & Collins, A. (Eds.),
Representation Understanding: Studies Cognitive Science, pp. 185210. Academic Press, New York.
Sacerdoti, E. (1977). Structure Plans Behavior. Elsevier, New York.
Sadock, J. (1990). Comments Vanderveken Cohen Levesque. Cohen, P.,
Morgan, J., & Pollack, M. (Eds.), Intentions Communication, pp. 257270. MIT
Press, Cambridge, MA.
Schank, R., & Abelson, R. (1977). Scripts, Plans, Goals, Understanding: Inquiry
Human Knowledge Structures. Lawrence Erlbaum Associates.
Seif El-Nasr, M., Yen, J., & Ioerger, T. (2000). FLAME fuzzy logic adaptive model
emotions. Autonomous Agents Multi-Agent Systems, 3, 219257.
Sengers, P. (2000). Schizophrenia narrative artificial agents. Proceedings
1st International Workshop Narrative Interactive Learning Environments.
Sharples, M. (1999). Write: Writing Creative Design. Routledge, London.
Smith, T., & Witten, I. (1991). planning mechanism generating story texts. Literary
Linguistic Computation, 6 (2), 119126.
267

fiRiedl & Young

Thomas, F., & Johnson, O. (1981). Disney Animation: Illusion Life. Abbeville
Press, New York.
Trabasso, T., & Sperry, L. (1985). Causal relatedness importance story events.
Journal Memory Language, 24, 595611.
Trabasso, T., & van den Broek, P. (1985). Causal thinking representation
narrative events. Journal Memory Language, 24, 612630.
Turner, S. R. (1994). Creative Process: Computer Model Storytelling. Lawrence
Erlbaum Associates, Hillsdale, NJ.
van den Broek, P. (1988). effects causal relations hierarchical position
importance story statements. Journal Memory Language, 27, 122.
Weld, D. (1994). introduction least commitment planning. AI Magazine, 15, 2761.
Weyhrauch, P. (1997). Guiding Interactive Fiction. Ph.D. thesis, Carnegie Mellon University.
Wilensky, R. (1983). Story grammars versus story points. Behavioral Brain Sciences, 6, 579623.
Young, R. M. (1999). Notes use plan structures creation interactive plot.
Mateas, M., & Sengers, P. (Eds.), Narrative Intelligence: Papers AAAI
Fall Symposium (Technical Report FS-99-01), pp. 164167. AAAI Press, Menlo Park.
Young, R. (2006). Story discourse: bipartite model narrative generation virtual
worlds. Interaction Studies, 8 (2), 177208.
Young, R., Pollack, M., & Moore, J. (1994). Decomposition causality partial-order
planning. Proceedings Second International Conference Artificial Intelligence Planning Systems, pp. 188193.

268

fiJournal Artificial Intelligence Research 39 (2010) 483-532

Submitted 04/10; published 10/10

Kalman Temporal Differences
Matthieu Geist
Olivier Pietquin

matthieu.geist@supelec.fr
olivier.pietquin@supelec.fr

IMS research group
Supelec
Metz, France

Abstract
reinforcement learning suffers lack scalability, online value (and Q-)
function approximation received increasing interest last decade. contribution introduces novel approximation scheme, namely Kalman Temporal Differences
(KTD) framework, exhibits following features: sample-efficiency, non-linear approximation, non-stationarity handling uncertainty management. first KTD-based
algorithm provided deterministic Markov Decision Processes (MDP) produces
biased estimates case stochastic transitions. eXtended KTD framework
(XKTD), solving stochastic MDP, described. Convergence analyzed special cases
deterministic stochastic transitions. Related algorithms experimented
classical benchmarks. compare favorably state art exhibiting
announced features.

1. Introduction
Optimal control stochastic dynamic systems trend research long history.
machine learning response recurrent problem Reinforcement Learning (RL)
paradigm (Bertsekas & Tsitsiklis, 1996; Sutton & Barto, 1998; Sigaud & Buffet, 2010).
general paragon, artificial agent learns optimal control policy interactions
dynamic system (also considered environment). interaction,
agent receives immediate scalar reward information optimal policy searches
one maximizes cumulative reward long run.
Traditionally dynamic system controlled modeled Markov Decision
Process (MDP). MDP tuple {S, A, P, R, }, state space,
action space, P : s, p(.|s, a) P(S) family transition probabilities,
R : R bounded reward function, discount factor (weighting longterm rewards). According definitions, system stochastically steps state
state conditionally actions agent performed. transition (si , ai , si+1 )
associated immediate reward ri . policy : mapping states actions
drives action selection process agent. optimal policy one
maximizes cumulative reward long term.
cumulative reward locally estimated agent so-called value (respectively
Q-) function associating expected cumulative reward state (respectively stateaction pair). optimal policy therefore one maximizes functions
state state-action pair. Many RL algorithms aim estimating one functions
infer optimal policy. challenging cases, search optimal policy
c
2010
AI Access Foundation. rights reserved.

fiGeist & Pietquin

done online, controlling system. requires trial error process
dilemma immediate exploitation currently learnt policy exploration
improve policy occurs.
context, fair RL algorithm address important features:
allowing online learning;
handling large even continuous state spaces;
sample-efficient (learning good control policy interactions possible);
dealing non-stationarity (even system stationary, controlling
learning optimal policy induces non-stationarities; good reasons prefer
tracking convergence given Sutton, Koop, & Silver, 2007);
managing uncertainty (which useful information handling dilemma
exploration exploitation);
handling non-linearities (to deal max operator Bellman optimality
equation compact function representations neural networks).
aspects rarely addressed time state-of-the-art RL algorithms.
show proposed Kalman Temporal Differences (KTD) framework (Geist, Pietquin,
& Fricout, 2009a) addresses issues. based Kalman filtering paradigm
uses approximation scheme, namely Unscented Transform (UT) Julier
Uhlmann (2004), approximate value function. Originally Kalman (1960) filtering paradigm aims tracking hidden state (modeled random variable)
non-stationary dynamic system indirect observations state. idea underlying KTD cast value function approximation filtering problem, benefit
intrinsic advantages Kalman filtering: online second order learning, uncertainty
estimation non-stationarity handling. UT used deal non-linearities
derivative-free fashion, notably allows deriving second-order value iteration-like
algorithm (namely KTD-Q).
1.1 Formalism
value function V given policy associates state expected discounted
cumulative reward starting state following :

X
V (s) = E[
ri |s0 = s, ]

(1)

i=0

ri reward observed time i. Q-function adds degree freedom
choice first action:

X
Q (s, a) = E[
ri |s0 = s, a0 = a, ]
i=0

484

(2)

fiKalman Temporal Differences

Reinforcement learning aims finding (through interactions) policy maximises
value function every state:
= argmax(V )

(3)



Despite partial order (value functions vectors), maximum exists (Puterman,
1994). Two schemes (among others) lead solution. First, policy iteration implies
learning value function given policy, improving policy, new one
greedy respectively learnt value function. requires solving Bellman evaluation
equation (given value function Q-function):


V (s) = Es0 |s,(s) R(s, (s), s0 ) + V (s0 ) ,


Q (s, a) = Es0 |s,a R(s, a, s0 ) + Q (s0 , (s0 )) , s,

(4)
(5)

expectations depend transition probability conditioned current state-action
pair, action given policy case value function evaluation. second
scheme, called value iteration, aims directly finding optimal policy. requires solving
Bellman optimality equation (given Q-function):


0
0
Q (s, a) = Es0 |s,a R(s, a, ) + max Q (s , b) , s,


bA

(6)

parametric representation either value Q-function supposed
available (possible representations discussed hereafter) Temporal Differences (TD)
algorithms considered. TD algorithms form class online methods consist
correcting representation value (or Q-) function according so-called TD
error made it. Although formal definition TD error depends algorithm
(see Section 1.2), intuitively defined difference predicted reward
according current estimate value Q-function actual observed reward
time step i. TD algorithms generically written as:
= i1 + Ki

(7)

expression, i1 latest estimate value function (or set parameters
defining it), updated representation given observed transition, TD error,
Ki gain indicating direction representation target function
corrected.
state space action space finite small enough, exact
description value function possible, vector many components
state (-action) space (tabular representation). case large state and/or action
spaces, approximation necessary. classical choice RL linear parameterization,
value function approximated by:
V (s) =

p
X

wj j (s) = (s)T

j=1

485

(8)

fiGeist & Pietquin

(j )1jp set basis functions, defined beforehand,
weights wj parameters:
= w1 . . .

wp



(s) = 1 (s) . . .


p (s)

(9)

Many function approximation algorithms require representation ensure convergence (Tsitsiklis & Roy, 1997; Schoknecht, 2002), even applicable (Bradtke &
Barto, 1996; Boyan, 1999; Geramifard, Bowling, & Sutton, 2006). representations
possible neural networks set synaptic weights (usually resulting
nonlinear dependency value function parameters).
Adopting generic point view, problem addressed paper stated
as: given representation value function (or Q-function) summarized
parameter vector given Bellman equation solved, best gain K?
state-of-the-art answers question given following section.
1.2 State Art
paper focuses online methods. Standard RL algorithms TD evaluation,
SARSA Q-Learning (Sutton & Barto, 1998) share features unified view
based Equation (7) adopted following. equation, term TD
error. Suppose step transition (si , ai , ri , si+1 , ai+1 ) observed. TD-like RL
algorithms, algorithms aiming evaluating value function given policy ,
TD error is:
(10)
= ri + Vi1 (si+1 ) Vi1 (si )
SARSA-like algorithms, algorithms aim evaluating Q-function
given policy , TD error is:
= ri + Qi1 (si+1 , ai+1 ) Qi1 (si , ai )

(11)

Finally, Q-learning-like algorithms, algorithms aim computing optimal Q-function Q , TD error is:
= ri + max Qi1 (si+1 , b) Qi1 (si , ai )
bA

(12)

type temporal difference determines Bellman equation solved (evaluation
equation (10-11), optimality equation (12)), thus algorithm belongs
policy iteration value iteration family.
gain Ki specific algorithm. common reviewed here. TD,
SARSA Q-learning (for example, see Sutton & Barto, 1998), gain written

Ki = ei
(13)
classical learning rate stochastic approximation theory satisfy:

X

=

i=0


X
i=0

486

i2 <

(14)

fiKalman Temporal Differences

ei unitary vector zero everywhere except component corresponding
state si (or state-action (si , ai )) equal one (Kronecker function).
algorithms modified consider so-called eligibility traces (again, see Sutton
Barto), gain written
Ki =


X

ij ej

(15)

j=1

eligibility factor. Informally, approach keeps memory trajectories
order propagate updates previously visited states.
algorithms also extended take account approximate representation value function (Sutton & Barto, 1998), called direct algorithms (Baird,
1995). Without eligibility traces, gain written
Ki = i1 Vi1 (si )

(16)

i1 Vi1 (si ) gradient following parameter vector parameterized
value function current state. gain corresponds stochastic gradient descent
according cost function kV V k2 . V (si ) known directly observable,
replaced ri + V (si+1 ). general approach known bootstrapping (Sutton
& Barto, 1998). value function replaced straightforwardly Q-function
gain. direct algorithms also extended take account eligibility
traces, leads following gain:
Ki =


X

ij i1 Vi1 (sj )

(17)

j=1

Another well known approach set residual algorithms (Baird, 1995),
gain obtained minimization L2 -norm Bellman residual (i.e.,
difference left side right side Bellman equation, possibly
sampled transitions) using stochastic gradient descent:


(18)
Ki = i1 Vi1 (si ) Vi1 (si+1 )
next reviewed approach (recursive form the) Least-Squares Temporal Differences (LSTD) algorithm Bradtke Barto (1996), defined linear
parameterization (8) gain defined recursively:
Ci1 (si )
1 + ((si ) (si+1 ))T Ci1 (si )
Ci1 (si )((si ) (si+1 ))T Ci1
Ci = Ci1
1 + ((si ) (si+1 ))T Ci1 (si )
Ki =

(19)
(20)

(s) defined (9) matrix C0 must initialized. LSTD also seeks
minimize L2 -norm Bellman residual, however using least-squares approach
rather gradient descent using instrumental variable concept (Soderstrom
487

fiGeist & Pietquin

& Stoica, 2002) cope stochasticity transitions1 . algorithm also
extended eligibility traces (for details, see Boyan, 1999).
last reviewed approach, certainly closest contribution,
Gaussian Process Temporal Differences (GPTD) algorithm Engel (2005). linear parameterization V (s) = (s)T assumed2 following statistical generative model
(obtained Bellman evaluation equation) considered:





1 0 . . .

r1
n1
0 1 0 (s1 )
..
..
..
(21)
. + .
. = .. . .
..
.
.
.

ri
(si )
ni
0 ...
0
1
assuming noise nj white (and therefore centered), Gaussian variance j ,
prior parameters follows normal distribution, posterior distribution
(|r1 , . . . , ri ) analytically computed. Moreover, using Sherman-Morrison
formula, recursive algorithm satisfying Widrow-Hoff update rule (7) obtained
(assuming prior P0 ):
Ki =

i2

Pi = Pi1

Pi1 ((si ) (si+1 ))
+ ((si ) (si+1 ))T Pi1 ((si ) (si+1 ))

(22)

Pi1 ((si ) (si+1 ))((si ) (si+1 ))T Pi1
i2 + ((si ) (si+1 ))T Pi1 ((si ) (si+1 ))

(23)

Alternatively, GPTD (with parametric representation) seen linear leastsquares solution L2 Bellman residual minimization.
classical value function approximation algorithms presented,
however many exist. Nevertheless, knowledge none presents
features argued desirable. assumes linearity, least
ensure convergence (Tsitsiklis & Roy, 1997; Schoknecht, 2002) sometime even
applicable (Bradtke & Barto, 1996; Boyan, 1999; Geramifard et al., 2006).
algorithms assume linearity, residual ones (Baird, 1995), however
often practical (eg., value iteration-like residual algorithm proposed Baird,
method requires computing gradient max operator). methods
sample efficient others. Generally speaking, second order approaches tend
efficient first order one, LSTD usually recognized sample efficient
approach. Algorithms use learning rate partially cope non-stationarity,
using adaptive learning rate example. However LSTD approach known
1. point view historical. Since then, shown LSTD actually minimizes distance
value function projection onto hypothesis space image Bellman
operator (Lagoudakis & Parr, 2003).
2. Actually, Engels work general. models value function Gaussian process
uses dictionary method obtain sparse representation (without procedure, value function
would represented vector many components visited states). However, dictionary
method used preprocessing step, Gaussian process nonparametric representation reduces
proposed parametric linear representation, basis functions kernels. Constructing parameterization automatically online surely interest, proposed point view makes
comparisons easier.

488

fiKalman Temporal Differences

take account non-stationarity (which explains almost never used optimistic
policy iteration incremental actor-critic schemes), see example work Phua
Fitch (2007). Many recent approaches handling dilemma exploration
exploitation use uncertainty information (eg., see Dearden, Friedman, & Russell,
1998 Strehl, Li, Wiewiora, Langford, & Littman, 2006). However, far know,
algorithms allow providing uncertainty information within value approximation
context, among GPTD framework Engel (2005). However, contrary
contribution effective use information left future work. Like LSTD,
GPTD algorithms sample efficient handle non-stationarity3 . Yet, GPTD
KTD frameworks share similarities, discussed throughout paper.
motivation behind KTD handle aspects time.
1.3 Paper Outline
next section introduces alternative point view value function approximation
introduces informally Kalman filtering state-space representation, upon
contribution built.
Determinism MDP assumed Section 3 general Kalman Temporal Differences framework derived. Deterministic transitions linked white noise
assumption necessary KTD derivation. specialized using approximation scheme, Unscented Transform (UT) Julier Uhlmann (2004) derive family
practical algorithms. Section 4, colored noise model initially introduced Engel,
Mannor, Meir (2005) used extend KTD framework case stochastic transitions. eXtended KTD (XKTD) framework proposed, combination
off-policy learning discussed. Convergence analysed Section 5. white
noise assumption, shown KTD minimizes weighted square Bellman residual.
colored noise assumption, shown XKTD indeed performs least-squares
supervised learning associating state values observed Monte Carlo returns cumulative
rewards. solution LSTD(1), unbiased estimator value
function. Section 6 shows compute uncertainty value estimates
framework introduces form active learning scheme aims improving speed
convergence KTD-Q, KTD value iteration-like algorithm. proposed framework
experimented compared state art RL algorithms. experiment
classic RL benchmark aims highlighting specific features KTD. Last section
discusses position proposed framework related approaches offers
perspectives.

2. Alternative Point View
previous section presented standard vision reinforcement learning problem
formulation MDP framework. alternative point view
introduced.
3. LSTD GPTD could certainly extended non-stationary case, example introducing
forgetting factor. However, designed initially, aim
paper provide LSTD GPTD variations.

489

fiGeist & Pietquin

2.1 Informal Idea
paper, novel approach based alternative point view proposed.
stochastic dynamic system seen possessing underlying value functions V RS
state-action value functions Q RSA agent observe interacting
system. agent takes action, provokes state change generation
reward. reward actually local observation set underlying value functions
ruling behavior system. sequence observations, agent
infer information value functions. good estimate value function
V (s) (resp. state-action value function Q(s, a)) given conditional expectation
possible trajectories V (s) (resp. Q(s, a)) given sequence observed rewards:
Vi (s) = E[V (s)|r1 , . . . , ri ]

(24)

Qi (s, a) = E[Q(s, a)|r1 , . . . , ri ]

(25)

Interacting system therefore becomes mean generate observations
helps estimating value functions hidden properties system. value
function estimates, followed policy modified move towards optimal policy.
also legitimate adopt behavior allows gathering meaningful observations
relates exploration versus exploitation dilemma.
Two special cases value functions one associated followed policy
one associated optimal policy . rest paper concentrates
estimating two particular value functions associated Q-functions.
Equations (24) (25) solvable general case inferring hidden variables
observations typically treated Kalman filtering signal processing
optimal control communities. Value functions considered generated set
parameters search optimal set hidden parameters provides
best estimate value function (see Section 3.1). following, Kalman filtering
first introduced method casting (state-action) value function approximation
Kalman filtering framework using Bellman equations build so-called state-space
representation problem proposed.
2.2 Kalman Filtering
Originally, Kalman (1960) filtering paradigm aims tracking hidden state X (modeled random vector) non-stationary dynamic system indirect observations
{Y1 , . . . , Yi } state. so, time 1 algorithm computes prediction
state (Xi|i1 ) observation (Yi|i1 ) time i, knowing analytically states evolve
generate observations clarified below. actual next observation Yi known
(at time i), state prediction corrected obtain state estimate Xi|i using
observation prediction error (ei = Yi Yi|i1 ) according following Windrow-Hoff-like
equation:
Xi|i = Xi|i1 + Ki (Yi Yi|i1 ) = Xi|i1 + Ki ei
(26)
Ki Kalman gain described hereafter. original work
Kalman, linear form equation (26) constraint: adopting statistical point
view, goal Kalman filter recursively compute best linear estimate Xi
490

fiKalman Temporal Differences

state time given sequence observations {Y1 , . . . , Yi }. Kalman considers
best estimate one minimizes quadratic cost function
Ji (X) = E[kXi Xk2 |Y1 , . . . , Yi ]

(27)

compute optimal gain Ki constraints (26) (27), several assumptions
made.
First, evolution system supposed ruled so-called evolution equation
process equation (using possibly non-stationary fi function) known:
Xi+1 = fi (Xi ) + vi

(28)

Equation (28) links next state Xi+1 current one Xi vi random noise
usually named evolution noise process noise modeling uncertainty evolution.
Second, observations supposed linked states another known function gi
used typically called observation equation sensing equation:
Yi = gi (Xi ) + wi

(29)

Equation (29) relates current observation Yi current state Xi wi random
noise usually named observation noise modeling uncertainty induced noisy observation. noise together process noise origin state estimation
problem (estimating current state history observations).
Equations (28) (29) provide so-called state-space description system.
major assumptions Kalman vi wi additive, white independent noises
variance Pv Pw respectively, meaning that:
E[vi ] = E[wi ] = 0
E[vi wj ] = 0

(30)

i, j

E[vj vi ] = E[wj wi ] = 0

(31)
6= j

(32)

Given assumptions constrains (26) (27) adopting statistical
point view, Kalman filter algorithm provides optimal quantities Xi|i1 , Yi|i1
Ki :
Xi|i1 = E[Xi |Y1 , . . . , Yi1 ] = E[fi1 (Xi1 ) + vi1 |Y1 , . . . , Yi1 ]
= E[fi1 (Xi1 )|Y1 , . . . , Yi1 ] = E[fi1 (Xi1|i1 )],

(33)

Yi|i1 = E[Yi |Y1 , . . . , Yi1 ] = E[gi (Xi ) + wi |Y1 , . . . , Yi1 ]
= E[gi (Xi )|Y1 , . . . , Yi1 ] = E[gi (Xi1|i1 )],
Ki =

PXei Pe1
.


(34)
(35)

PXei = E[(Xi Xi|i1 )ei |Y1 , . . . , Yi1 ] Pei = cov(ei |Y1 , . . . , Yi1 ).
scope paper provide complete development leading
general results provided Kalman (1960). Yet, Section 3 provide
developments specific case RL.
491

fiGeist & Pietquin

Several important comments made stage. First, specific assumption
made distributions noises v w except zeromean known variances (Pv Pw ). Given this, Kalman filter provides best
linear estimator (in sense estimators update rule linear) systems state
may optimal. Yet, two noises Gaussian distributions,
totally described mean variance. specific case, linear estimate
thus optimal estimate Kalman filter algorithm provides optimal solution.
paper, Gaussian assumption never made best linear estimator
considered.
Second, linear assumption made concerning functions fi gi . Although
Kalman (1960) provides exact solutions estimation problem case linear
state-space equations, quantities involved (33), (34) (35) required.
exists approximation schemes estimate quantities even case non-linear
equations. Extended Kalman filters unscented transform (see Section 3.2.2)
schemes.
Finally, Kalman filtering mistaken Bayesian filtering. Bayesian filtering would consist computing complete posterior distribution state given
observations. Kalman filtering focuses first second moments
distribution (mean variance) constrained linear update. case Gaussian
distributions, Bayesian filtering reduces Kalman filtering complex
general case. paper, Kalman filtering considered.
2.3 State-space Formulation Value Function Evaluation Problem
providing general framework, underlying ideas introduced value
function V (s) evaluation problem. providing uncertainty information estimates considered desired feature, statistical point view adopted
parameter vector modeled set random variables. Another desired feature
track solution rather converging it. suggests adopting evolution
model value function (through parameters). However, dynamics value
function hard model, depend whether dynamic system controlled non-stationary value function evaluation takes place generalized policy
iteration scheme4 . heuristic evolution model following Occam razor principle
adopted parameters evolution modeled random walk:
= i1 + vi

(36)

equation, (true) parameter vector time vi evolution noise.
assumed white (that centered, two different time steps, noises independent),
hypothesis done distribution. parameter vector thus random
process. stationary (because E[i ] = E[i1 ]), harm case
value function stationary. hand, allow tracking non-stationary
value function (even evolution model true one, cannot anyway
obtained general case).
4. time policy improved, associated value function changes too. Therefore, value function
learnt non-stationary.

492

fiKalman Temporal Differences

Another issue link observed (the reward) needs inferred (the
parameter vector representing value function). Bellman evaluation equation
good candidate produce observation model:
ri = V (si ) V (si+1 )

(37)

However, solution Bellman equation necessarily lie hypothesis
space (the set functions represented parameter vector, given
representation). Therefore inductive bias ni , modeled
centered noise:
ri = Vi (si ) Vi (si+1 ) + ni
(38)
Notice Gaussian assumption made distribution noise.
Evolution observation models summarized following state-space formulation:
(
= i1 + vi
(39)
ri = Vi (si ) Vi (si+1 ) + ni
model value function approximation. assumed exists
parameter random process generates rewards Bellman evaluation
equation, observations noisy due inductive bias fact
sampled Bellman equation used instead true one. States actions
considered exogenous variables part definition observation
model time i. Estimating value function reduces estimation
hidden random process. addressed Bayesian filtering, aims estimating
whole distribution conditioned past observed rewards. paper
restrictive point view adopted, Kalman filtering one, mean variance
distribution estimated restriction linear update rules.

3. KTD: Deterministic Case
rest section focus deterministic Markov
decision processes. Transitions become deterministic Bellman equations (4-6) simplify
follows:
V (s) = R(s, (s), s0 ) + V (s0 ),
0





0

0

Q (s, a) = R(s, a, ) + Q (s , (s )), s,


0



0

Q (s, a) = R(s, a, ) + max Q (s , b), s,
bA

(40)
(41)
(42)

section provided derivation general KTD algorithm well
specializations practical implementations.
3.1 General Framework
general point view adopted now. transition generically noted as:


(si , si+1 )
ti = (si , ai , si+1 , ai+1 )


(si , ai , si+1 )
493

(43)

fiGeist & Pietquin

given aim value function evaluation, Q-function evaluation Qfunction optimization (in words, direct evaluation optimal Q-function).
Similarly, cases, following shortcuts hold:


Vi (si ) Vi (si+1 )
gti (i ) = Qi (si , ai ) Qi (si+1 , ai+1 )


Qi (si , ai ) maxbA Qi (si+1 , b)

(44)

TD errors written generically
= ri gti (i )

(45)

statistical point view adopted. said before, original Kalman (1960) filter
paradigm aims tracking hidden state (modeled random variable) nonstationary dynamic system indirect observations state. idea behind
KTD express value function approximation filtering problem: parameters
hidden state tracked (modeled random variables following random walk),
observation reward linked parameters Bellman equation.
problem sight stated so-called state-space formulation (this term
comes Kalman filtering literature confused state space
MDP):
(
= i1 + vi
(46)
ri = gti (i ) + ni
expression fundamental proposed framework. Using vocabulary
Kalman filtering, first equation evolution equation, specifies real
parameter vector follows random walk expectation corresponds optimal estimate value function. evolution noise vi white, independent variance
matrix Pvi (to chosen practitioner, discussed section 7). Notice
equation update parameters (addressed later), model
natural evolution time, according Kalman filtering paradigm described Section 2.2; notably allows handling non-stationarity targeted value function.
second equation observation equation, links observed transition value
(or Q-) function Bellman equation, see (44). observation noise ni supposed white, independent (scalar) variance Pni (also chosen practitioner
discussed section 7). Notice mandatory assumption hold
stochastic MDP, deterministic transitions supposed here. details
assumption consequences given Section 4. Given deterministic
transitions, model noise arises solution Bellman equation
necessarily exists hypothesis space induced parameterization. Notice
choice nature approximator (choice structure neural network,
basis functions linear parameterization, etc.) important topic reinforcement
learning generally machine learning. Nevertheless, addressed here,
chosen practitioner.
494

fiKalman Temporal Differences

3.1.1 Minimized Cost Function
objective could estimate whole distribution parameters conditioned
past observed rewards, addressed Bayesian filtering. However,
difficult problem general case. simple objective chosen: estimating
(deterministic) parameter vector minimizes expectation true parameters
mean-squared error conditioned past observed rewards. idea information
provided observed transitions associated rewards, knowing mean
posterior distribution enough. associated cost written as:


Ji () = E ki k2 |r1:i r1:i = r1 , . . . , ri

(47)

Notice random vector (of distribution known), deterministic
vector. Generally speaking, optimal solution minimum mean square error (MMSE)
estimator conditional expectation5 :
argmin Ji () = i|i = E [i |r1:i ]

(48)



However, except specific cases, estimator analytically computable. Instead,
aim find best linear estimator . written form quite
similar equation (7):
i|i = i|i1 + Ki ri
(49)
Equation (49), i|i estimate time i|i1 = E[i |r1:i1 ] prediction
according past observed rewards r1:i1 , given evolution equation. random walk
model following holds (recall evolution noise white):
i|i1 = E [i1 + vi |r1:i1 ] = E [i1 |r1:i1 ]
= i1|i1

(50)

innovation
ri = ri ri|i1

(51)

difference actual observed reward ri prediction ri|i1 based
previous estimate parameter vector observation equation (recall
observation noise also white):
ri|i1 = E [ri |r1:i1 ] = E [gti (i ) + ni |r1:i1 ]
= E [gti (i )|r1:i1 ]

(52)

Note innovation ri exactly temporal difference defined Equation (45),
random variable dependency random vector .
expectation conditioned past observed data: ri = E[i |r1:i ].
5. quite intuitive, best deterministic estimator (in least-squares sens) random variable
mean.

495

fiGeist & Pietquin

3.1.2 Optimal Gain
Using classical equalities, cost function rewritten trace matrix
variance parameters error:


Ji () = E ki k2 |r1:i


= E (i )T (i )|r1:i


= trace E (i )(i )T |r1:i
(53)
Recall restrict class linear (and unbiased) estimators depicted
Eq. (49). Therefore, cost function Ji (i|i ) considered, unknown
gain Ki :



Ji (i|i ) = trace cov i|i |r1:i
(54)
first step computation optimal gain express conditioned covariance
parameters function gain Ki . notations first introduced
(recall also (51), definition innovation):

= i|i


i|i1 = i|i1

i|i
Pi|i = cov i|i |r1:i
Pi|i1 = cov i|i1 |r1:i1
(55)
h



P = cov (r |r
r |r
) P = E
ri



1:i1

ri

i|i1

1:i1

various estimators unbiased, covariance expanded follows:


Pi|i = cov i|i |r1:i




= cov i|i1 + Ki ri |r1:i1


= cov i|i1 Ki ri |r1:i1

+ Ki Pri KiT
Pi|i = Pi|i1 Pri KiT Ki Pr


(56)

optimal gain thus obtained zeroing gradient respect Ki
trace matrix.
First note gradient linear, three matrices ad hoc dimensions A,
B C (that products ABAT AC well defined), B symmetric,
following algebraic identities hold:

trace ABAT = 2AB
(57)




trace AC
= trace CA
=C
(58)
thus using Equation (56) previous identities:

Ki trace Pi|i = 0


2Ki Pri 2Pri = 0



Ki = Pri Pr1

496

(59)

fiKalman Temporal Differences

Using Equations (56) (59), covariance matrix Pi|i recursively computed
follows:
Pi|i = Pi|i1 Ki Pri KiT
(60)
Recall Gaussian assumption made derive equations. Nevertheless,
Gaussian (and linear) assumptions, optimal update actually linear6 (for example, see Chen, 2003). Please also notice variance matrix encodes uncertainty
parameter estimates, intrinsic uncertainty considered MDP (it
variance random process value function mean).
3.1.3 General Algorithm
general KTD algorithm derived. breaks three stages.
first step consists computing predicted quantities i|i1 Pi|i1 . predictions
made past estimates, algorithm initialized priors 0|0 P0|0 .
Recall random walk model, Equation (50) holds, predicted covariance
also computed analytically:


Pi|i1 = cov i|i1 |r1:i1


= cov i1|i1 + vi |r1:i1
= Pi1|i1 + Pvi

(61)

(recall Pvi problem-dependent variance matrix evolution noise,
chosen practitioner).
second step compute statistics interest. specialized
algorithm Section 3.2. first statistic compute prediction ri|i1 (52).
second statistic compute covariance parameter vector
innovation:
h

Pri = E (i i|i1 )(ri ri|i1 )|r1:i1
(62)
However, state-space model (46), ri = gti (i ) + ni , observation noise
centered independent,
h

Pri = E (i i|i1 )(gti (i ) ri|i1 )|r1:i1
(63)
last statistic compute covariance innovation, written
(using characteristics observation noise):


Pri = E (ri ri|i1 )2 |r1:i1


= E (gti (i ) ri|i1 + ni )2 |r1:i1


= E (gti (i ) ri|i1 )2 |r1:i1 + Pni

(64)

(recall Pni variance observation noise).
6. words, case, Kalman filtering solution actually Bayesian filtering solution.

497

fiGeist & Pietquin

third last step algorithm correction step. consists computing
gain (59), correcting predicted parameter vector (49) updating associated
covariance matrix (60) accordingly. proposed general framework summarized
Algorithm 1. Notice similarity correction equation (i|i = i1|i1 + Ki (ri
ri|i1 )) Widrow-Hoff equation approximated value corrected
direction error (the innovation indeed TD error). gain Ki seen
set adaptive learning rates.
Algorithm 1: General KTD algorithm
Initialization: priors 0|0 P0|0 ;
1, 2, . . .
Observe transition ti reward ri ;
Prediction step;
i|i1 = i1|i1 ;
Pi|i1 = Pi1|i1 + Pvi ;
Compute statistics interest;
ri|i1 = E[gti (i )|r1:i1 ] ;
h

Pri = E (i i|i1 )(gti (i ) ri )|r1:i1 ;


Pri = E (gti (i ) ri|i1 )2 |r1:i1 + Pni ;
Correction step;
Ki = Pri Pr1
;


i|i = i|i1 + Ki ri ri|i1 ;
Pi|i = Pi|i1 Ki Pri KiT ;

3.2 Specializations
main difficulty applying KTD compute statistics interest ri|i1 , Pri
Pri (for statistics i|i1 Pi|i1 necessary). First, value function
evaluation case linear parameterization considered. related Bellman
equation (40). case analytical derivation possible. approximation
scheme, unscented transform (UT) Julier Uhlmann (2004), introduced.
allows solving problem nonlinear parameterization. Q-function evaluation
direct optimization follow.
3.2.1 KTD-V: Linear Parameterization
linear parameterization equation (8) adopted, V (s) = (s)T .
state-space formulation (46) thus rewritten as:
(
= i1 + vi
ri = ((si ) (si+1 ))T + ni
498

(65)

fiKalman Temporal Differences

Notice problem sight evaluation deterministic policy, action
observed. policy fixed, MDP reduces valued Markov chain.
shorten notations, Hi defined as:
Hi = (si ) (si+1 )

(66)

observation equation linear, statistics interest derived analytically.
prediction is:
ri|i1 = E [gti (i )|r1:i1 ]


= E HiT |r1:i1
= HiT E [i |r1:i1 ]
= HiT i|i1

(67)

covariance parameter vector innovation also computed
analytically:
h


Pri = E i|i1 gti (i ) ri|i1 |r1:i1
h

= E i|i1 HiT i|i1 |r1:i1
h


= E i|i1 i|i1
|r1:i1 Hi
= Pi|i1 Hi

(68)

covariance innovation derived analytically well:
h


2
gti (i ) ri|i1 |r1:i1 + Pni


2

= E Hi i|i1 |r1:i1 + Pni

Pri = E

= HiT Pi|i1 Hi + Pni

(69)

optimal gain thus defined algebraically recursively:
Ki =

Pi|i1 Hi

Hi Pi|i1 Hi +

Pni

(70)

KTD-V approach linear parameterization summarized Algorithm 2.
Notice gain shares similarities gain (19) LSTD algorithm
(Bradtke & Barto, 1996), surprise. LSTD based least-squares
minimization (however introduction instrumental variables order handle stochastic transitions), Kalman filter seen stochastic generalization
least-squares method. gain shares also similarities GPTD. Actually,
process noise set 0 (that Pvi = 0), KTD-V linear parameterization
499

fiGeist & Pietquin

Algorithm 2: KTD-V: linear parameterization
Initialization: priors 0|0 P0|0 ;
1, 2, . . .
Observe transition (si , si+1 ) reward ri ;
Prediction step;
i|i1 = i1|i1 ;
Pi|i1 = Pi1|i1 + Pvi1 ;
Compute statistics interest;
ri|i1 = HiT i|i1 ;
Pri = Pi|i1 Hi ;
Pri = HiT Pi|i1 Hi + Pni ;
/*
Hi = (si ) (si+1 )

*/

Correction step;
;
Ki = Pri Pr1


i|i = i|i1 + Ki ri ri|i1 ;
Pi|i = Pi|i1 Ki Pri KiT ;

GPTD algorithm7 , see Equation (22). surprise:
linear Gaussian hypothesis, state-space (65) zero evolution noise equivalent
statistical generative model (21). alternative point view approaches
provide least-squares solution L2 Bellman residual minimization.
Although linear parameterization widely used, one interested using nonlinear one (for optimal basis function search compact function representation
instance). Another case interest (addressed later) handle max operator
inherent Bellman optimality equation. proposed approach notably
differs Engels framework. Basically, issue computing statistics interest
KTD stated following problem: given mean covariance random
variable (i|i1 Pi|i1 KTD), mean covariance nonlinear (and
perhaps non-differentiable) mapping (gti KTD) random variable computed?
following section presents unscented transform, approximation scheme
designed handle problem.

7. again, GPTD general linear parameterization, gain (22) refereed
parametric GPTD Engel (2005). Nevertheless, non-parametric approach GPTD actually
constructs online kernel-based linear parameterization. end learning, parameterization constructed preprocessing step, non-parametric representation reduces linear
parametric representation. focus paper learn parameters representation
representation (which totally recognize problem importance), GPTD
always considered parametric form article.

500

fiKalman Temporal Differences

3.2.2 Unscented Transform
Lets abstract RL Kalman filtering consider problem non-linear mapping
random variable. Let X random vector, let mapping X. problem
compute mean covariance knowing mapping first second
order moments X. mapping linear, relation X written
= AX matrix ad hoc dimension (that number row times
number rows X). case, required mean covariance analytically
computed E[Y ] = AE[X] E[Y ] = AE[XX ]AT . result used
derive KTD-V algorithm Section 3.2.1.
mapping nonlinear, relation X written as:
= f (X)

(71)

first solution would approximate nonlinear mapping first order Taylor
expansion around E[X]. leads following approximations mean covariance :
E[Y ] f (E[X])

(72)

E[Y ] (f (E[X])) E[XX ] (f (E[X]))T

(73)

approach basis Extended Kalman Filtering (EKF) (for example, see Simon,
2006), extensively studied used past decades. However
limitations. First cannot handle non-derivable nonlinearities, thus cannot handle
Bellman optimality equation (6) max operator. requires compute
gradient mapping f , quite difficult even possible (eg., neural
networks). also supposes nonlinear mapping locally linearizable order
good approximation, unfortunately always case lead
quite bad results, exemplified Julier Uhlmann (2004).
basic idea unscented transform easier approximate arbitrary
random vector (with samples) arbitrary nonlinear function. principle sample
deterministically set so-called sigma-points expectation covariance
X. images points nonlinear mapping f computed,
used approximate statistics interest. shares similarities Monte-Carlo
methods, however sampling deterministic requires less samples drawn,
nonetheless guaranteeing given accuracy (Julier & Uhlmann, 2004).
original unscented transform described formally (some variants
introduced since then, basic principle same). Let n dimension
X. set 2n + 1 so-called sigma-points computed follows:
x(0) = X
x(j)
x(j)

p

= X +
(n + )PX
j
p

= X
(n + )PX

jn

j=0

(74)

1jn

(75)

n + 1 j 2n

(76)

well associated weights:
w0 =


n+



wj =
501

1
2 (n + )

j > 0

(77)

fiGeist & Pietquin

X mean X,pPX variance matrix, scaling factor controls
sampling spread, ( (n + )PX )j j th column Cholesky decomposition
matrix (n + )PX . image mapping f computed
sigma-points:
(j) = f (x(j) ), 0 j 2n
(78)
set sigma-points images finally used approximate first second
order moments , even PXY , covariance matrix X :
=

2n
X

wj (j)

(79)

j=0

PY

2n
X



wj (j)



(j)



(80)

j=0

PXY

2n
X




wj x(j) X (j)

(81)

j=0

Thanks unscented transform, possible address value function evaluation problem nonlinear parameterization, random vector X case
parameter vector, nonlinear mapping predicted reward.
3.2.3 KTD-V: Nonlinear Parameterization
section generic parameterization value function V considered:
neural network (Bishop, 1995), semi-parametric kernel representation (Geist, Pietquin,
& Fricout, 2008), function representation interest, long described
set p parameters. general state-space formulation (46) thus written as:
(
= i1 + vi
(82)
ri = Vi (si ) Vi (si+1 ) + ni
problem still compute statistics interest, becomes tractable
unscented transform. first thing compute set sigma-points known
statistics i|i1 Pi|i1 well associated weights using Equations (74-77),
described Section 3.2.2:
n

(j)
(83)
i|i1 = i|i1 , 0 j 2p
W = {wj , 0 j 2p}

(84)

images sigma-points computed (a predicted reward
sampled parameter vectors), using observation function state-space model (82),
linked Bellman evaluation equation (40):


(j)
Ri|i1 = ri|i1 = V(j) (si ) V(j) (si+1 ), 0 j 2p
(85)
i|i1

i|i1

502

fiKalman Temporal Differences

sigma-points images computed, statistics interest approximated by:
ri|i1

2p
X

(j)

wj ri|i1

(86)


2
(j)
wj ri|i1 ri|i1 + Pni

(87)




(j)
(j)
wj i|i1 i|i1 ri|i1 ri|i1

(88)

j=0

Pr

2p
X
j=0

Pri

2p
X
j=0

unscented transform longer approximation linear mapping, formulation still valid value function evaluation linear function approximation. KTD-V
nonlinear function approximation summarized Algorithm 3. Notice
general parameterization cannot taken account GPTD LSTD. possible direct algorithms (TD function approximation), however risk
divergence. illustrated Section 7.
3.2.4 KTD-SARSA
section focuses Q-function evaluation fixed given policy. associated
algorithm called KTD-SARSA, misleading. Indeed, SARSA sometime
understood Q-function evaluation algorithm associated optimistic policy iteration scheme (eg., -greedy policy). focus Q-function evaluation problem,
control part left apart. general parameterization Q , considering
Bellman evaluation equation (41), state-space model (46) rewritten as:
(
= i1 + vi
(89)
ri = Qi (si , ai ) Qi (si+1 , ai+1 ) + ni
fixed policy, value function evaluation state space induced Markov chain8
quite similar Q-function evaluation state-action space induced Markov chain.
thus straightforward extend KTD-V Q-function evaluation. Recall linear
parameterization, unscented transform leads exact computation statistics
interest, thus case Algorithm 3 (KTD-V) equivalent Algorithm 2.
sigma-point formulation KTD-SARSA given, also summarized
Algorithm 3.
LSTD GPTD also generalized Q-function evaluation (see respectively Lagoudakis & Parr, 2003 Engel, 2005). However, again, approaches
cannot handle nonlinear parameterization, contrary KTD-SARSA. Notice also
parameterization linear process noise zero, KTD-SARSA
algorithm GPTD Q-function evaluation (this direct extension equivalence GPTD KTD-V linear parameterization zero process noise, see
Sec. 3.2.1).
8. fixed policy, MDP reduces Markov chain.

503

fiGeist & Pietquin

Algorithm 3: KTD-V, KTD-SARSA KTD-Q
Initialization: priors 0|0 P0|0 ;
1, 2, . . .


(si , si+1 ) (KTD-V)
Observe transition ti = (si , ai , si+1 , ai+1 ) (KTD-SARSA)


(si , ai , si+1 ) (KTD-Q)

reward ri ;

Prediction Step;
i|i1 = i1|i1 ;
Pi|i1 = Pi1|i1 + Pvi ;
Sigma-points
n computation ;
(j)
i|i1 = i|i1 , 0 j 2p (from i|i1 Pi|i1 );
W = {wj , 0 j 2p } ;
Ri|i1 =

n
(j)

r
=
V
(KTD-V)
(j) (si ) V (j) (si+1 ), 0 j 2p

i|i1

i|i1
i|i1


n
(j)
ri|i1 = Q(j) (si , ai ) Q(j) (si+1 , ai+1 ), 0 j 2p (KTD-SARSA)
i|i1
i|i1

n



(j)

ri|i1 = Q (j) (si , ai ) maxbA Q (j) (si+1 , b), 0 j 2p (KTD-Q)


i|i1

;

i|i1

Compute statistics interest;
P
(j)
ri|i1 = 2p
j=0 wj ri|i1 ;
P
(j)
(j)
Pri = 2p
j=0 wj (i|i1 i|i1 )(ri|i1 ri|i1 );


2
P
(j)
Pri = 2p
+ Pni ;
j=0 wj ri|i1 ri|i1
Correction step;
Ki = Pri Pr1
;


i|i = i|i1 + Ki ri ri|i1 ;
Pi|i = Pi|i1 Ki Pri KiT ;

3.2.5 KTD-Q
section focuses Q-function optimization, finding approximate
solution Bellman optimality equation (42). general parameterization Q adopted.
state-space model (46) specialized follows:
(
= i1 + vi
ri = Qi (si , ai ) maxbA Qi (si+1 , b) + ni

(90)

linear nonlinear parameterizations distinguished, nonlinearities induced max operator. tricky handle, especially
non-differentiability.
504

fiKalman Temporal Differences

Hopefully, approximates random variable rather mapping, unscented transform derivative-free approximation. Given general KTD algorithm
introduced Section 3.1.3 unscented transform described Section 3.2.2,
possible derive KTD-Q, KTD algorithm Q-function direct optimization. One
first compute set sigma-points associated parameter vector, equations (83-84). mapping sigma-points observation equation
state-space model (90), contains max operator, computed:

n
(j)
(91)
Ri|i1 = ri|i1 = Q(j) (si , ai ) max Q(j) (si+1 , b), 0 j 2p
bA

i|i1

i|i1

Then, usual, sigma-points images used compute statistics
interest, equations (86-88). proposed KTD-Q summarized Algorithm 3.
Notice even parameterization linear, LSTD GPTD equivalent
algorithm. Actually, linearity observation model mandatory assumption
derivation algorithms, Bellman optimality operator cannot taken
account. far know, KTD-Q one first second order value iteration-like
algorithms. Choi Van Roy (2006) propose linear least-squares based bootstrapping
approach (to discussed Section 8) used Q-learning-like setting.
Yu Bertsekas (2007) also introduce least-squares-based Q-learning. However,
designed optimal stopping problems (which restrictive class MDP)
truly online (to update representation given new observation, followed
trajectory explicitly required). Roughly speaking, algorithm fitted-Q
least-squares supervised learning part new transition added
learning basis iteration. computational complexity cubic9 , higher
square complexity KTD, shown next section.
3.3 Algorithmic Complexity
Let p number parameters. unscented transform involves Cholesky decomposition computational complexity O(p3 ) general. However, variance
update (60) rank one update, Cholesky decomposition perfomed O(p2 )
(eg., see Gill, Golub, Murray, & Saunders, 1974). different algorithms imply evaluate
2p + 1 times gti function time-step. KTD-V KTD-SARSA general
parameterization, evaluation bounded O(p). KTD-Q, maximum
actions computed. notation represents cardinality action space finite, computational complexity algorithm used search maximum otherwise
(eg., number samples times evaluation complexity Monte Carlo).
evaluation bounded O(pA). Remaining operations basic linear algebra,
thus bounded O(p2 ). Therefore global computational complexity (per iteration)
KTD-V KTD-SARSA O(p2 ), KTD-Q O(Ap2 ). mean variance
matrix parameters maintained, memory complexity O(p2 ). Although
comparable LSTD GPTD complexity, higher many RL algorithms
linear complexity. Nevertheless, value function approximation approaches assume linear parameterization. KTD make hypothesis (even
9. However, paper proposes heuristics reduce complexity.

505

fiGeist & Pietquin

analyse convergence, shown Section 5.1) allows much compact representations value function. Thus quadratic complexity problem important
counterparts.

4. KTD: Stochastic Case
KTD framework presented far assumes deterministic transitions.
case, observation noise ni cannot assumed white (since would include MDP
stochasticity well inductive bias), whereas necessary condition KTD
derivation. First shown using KTD stochastic MDP involves bias.
colored noise model introduced alleviate problem, used extend KTD.
problem caused off-policy learning, prevents derivation XKTD-Q
algorithm, also discussed.
4.1 Stochastic Transitions Bias
One ignore problem use cost function (47) linked state-space model (46)
stochastic transitions. However, similarly approaches minimizing squared Bellman
residual, residual algorithms Baird (1995), cost function biased.
precisely, biased relatively stochasticity transitions (parameters transitions
different sources randomness). Additionally, cost function biased,
estimator minimizing (that i|i ) biased too.
Theorem 1. reward function depends current state-action pair,
transiting state, used stochastic Markov decision process, cost
function (47) biased (relatively stochasticity transitions), bias given by:



2
0


kKi k E covs0 |si ,(si ) (ri + V (s )) |r1:i1

kKi k2 E cov (ri gti ()) |r1:i1 = kKi k2 E covs0 |si ,(si ) (ri + Q (s0 , (s0 ))) |r1:i1

s0 |si ,ai



kKi k2 E covs0 |si ,ai (ri + maxaA Q (s0 , a)) |r1:i1
(92)
clear bias zero deterministic transitions.
Proof. assumption reward depend transiting state made
technically simplifying demonstration, conditioning cost function
past observed rewards. Yet done without loss generality. hypothesis,
state-space model considered stochastic MDP is:
(
= i1 + vi
(93)
ri = Es0 |si ,ai [gti (i )] + ni
ti defined random quantity ti = (si , ai , s0 ). Notice observation
equation (minus noise) Bellman equation stochastic transitions. difference
state-space model (46) transitions sampled averaged.
associated cost function is:



Ji () = trace Pi|i = trace Pi|i1 Pri KiT Ki Pr
Ki Pri KiT
(94)

506

fiKalman Temporal Differences

Calligraphic letters denote state-space model (93) notations (55)
state-space model (46), eg.:
h



Pri = E i|i1 ri |r1:i1 ri = ri ri|i1 = ri E Es0 |si ,ai [gti (i )] |r1:i1
(95)
Notice prediction reward unbiased, thus holds innovation:




Es0 |si ,ai ri|i1 = ri|i1 Es0 |si ,ai ri|i1 = ri|i1

(96)

term Pi|i1 depend transiting state s0 term Pri linear
innovation, unbiased:


Es0 |si ,ai Pi|i1 = Pi|i1 Es0 |si ,ai [Pri ] = Pri

(97)

case variance innovation:


Es0 |si ,ai [Pri ] = Es0 |si ,ai E ri2 |r1:i1



= E Es0 |si ,ai ri2 |r1:i1
h




2
= E r2i |r1:i1 + E Es0 |si ,ai ri2 Es0 |si ,ai [ri ] |r1:i1


= Pri + E cov (ri ) |r1:i1
s0 |si ,ai

(98)

Thus bias (Es0 |si ,ai [Ji ()] Ji ()) computed:


Es0 |si ,ai [Ji ()] Ji () = Es0 |si ,ai trace Ki (Pri Pri ) KiT
= trace(Ki KiT )Es0 |si ,ai [Pri Pri ]

= KiT Ki Es0 |si ,ai [Pri ] Pri


2
= kKi k E cov (ri gti ()) |r1:i1
s0 |si ,ai

(99)

Notice neither V (si ) Q (si , ai ) depends transiting state s0 . Thus proves
result expressed Theorem 1.
bias quite similar one arising minimization square Bellman
residual. result Theorem 2 (see Section 5) even strengthen parallel. solution
could introduce auxiliary filter remove bias, similarly introduction
auxiliary function made Antos, Szepesvari, Munos (2008). However extension
work straightforward. Another approach could estimate bias online
remove it, similarly done Jo Kim (2005) least-mean square filtering.
However Kalman filter much complex framework least-squares filter,
especially combined unscented transform. Another interesting perspective could
introduce colored observation noise done Engel (2005) Bayesian context
Gaussian process-based algorithms. last approach presented used extend
KTD next.
507

fiGeist & Pietquin

4.2 Colored Noise Model
First focus value function evaluation. Extension Q-function evaluation
straightforward, Q-function optimization discussed later, off-policy
aspect (the learnt policy behaviorial one). Bellman evaluation equation
solved Equation (4): shown directly using KTD stochastic problem induces bias minimized cost function. colored noise model
first proposed Engel et al. (2005) (the basis so-called Monte-Carlo GPTD
algorithm) first presented, adapted extend KTD framework.
policy fixed evaluation, MDP reduces valued Markov chain
probability transition p (.|s) = p(.|s, (s)) reward R (s, s0 ) = R(s, (s), s0 ).
value function defined expectation (over possible trajectories) following discount return random process:


(s) =


X

R (si , si+1 )|s0 = s, si+1 p (.|si )

(100)

i=0

equation naturally leads Bellman-like anti-causal recurrence:
(s) = R (s, s0 ) + (s0 ), s0 p (.|s)

(101)

random process also broken mean plus zero mean residual.
However definition mean value function V (s) = E[D (s)], writing
V (s) residual:
(s) = E[D (s)] + (D (s) E[D (s)]) = V (s) + V (s)

(102)

Substituting Equation (102) Equation (101), reward expressed function
value plus noise:
R (s, s0 ) = V (s) V (s0 ) + N (s, s0 )

(103)

noise defined as:
N (s, s0 ) = V (s) V (s0 )

(104)

done Engel et al. (2005), residuals supposed independent, leads
colored noise model. assumption really strong, transitions likely
render residuals dependent, however despite convergence guarantees given
Section 5.
Recall observation equation state-space formulation (46): ri = gti (i ) + ni .
KTD framework, observation noise ni assumed white, necessary
algorithm derivation. eXtended Kalman Temporal Differences (XKTD) framework,
colored noise model (104) used instead.
residual centered assumed independent, noise indeed moving
average (MA) noise (here sum two white noises):
ni = ui + ui1 ,

ui (0, i2 )

(105)

Notice white noise ui centered variance i2 , nevertheless assumption
made distribution (particularly Gaussian assumption).
508

fiKalman Temporal Differences

4.3 Extending KTD
quite easy use autoregressive (AR) process noise Kalman filter extending
evolution equation (for example, see Simon, 2006). However, far know,
case observation noise never addressed literature, whereas
necessary extend KTD. Notice noise model taken account quite
different way GPTD framework. Basically, done using partitioned matrix
inversion formula, possible due lack linearity assumption.
4.3.1 eXtended Kalman Temporal Differences
Rederiving KTD case noise done Section 3.1 would quite difficult.
Instead, proposed express scalar noise ni vectorial AR noise.
allows extending state-space model (46) new one Algorithm 1 applies rather
directly. Let auxiliary random variable. Scalar noise (105) equivalent
following vectorial AR noise:




i1
0 0
1
ui
(106)
=
+
ni
1 0
ni1

Indeed, vectorial AR noise, ni = i1 ui = ui , ni = ui + ui1

correct model. noise u0i = ui ui also centered variance
matrix is:


1
2
(107)
Pu0i =
2
new noise formulation defined, possible extend statespace formulation (46):
(
xi = F xi1 + vi0
(108)
ri = gti (xi )

parameter vector extended vectorial AR noise ni :

xTi = ni
(109)
Notice observation noise ni part extended parameter vector,
also estimated. evolution matrix F takes account structure
observation noise. Let p number parameters Ip identity matrix size p,
evolution matrix written bloc (0 denotes zero p 1 column vector):


Ip 0 0
F = 0T 0 0
(110)
0T 1 0
process noise vi also extended take account observation noise.
still centered, however variance matrix extended using variance matrix Pu0i (107):


Pv
0
0
i2
i2
(111)
Pvi0 = 0T

2
2
2
0

509

fiGeist & Pietquin

observation equation remains same:
ri = gti (xi ) = gti (i ) + ni

(112)

However observation noise part evolution equation,
estimated.
Using new state-space formulation, general XKTD algorithm derived.
summarized Algorithm 4. rather similar Algorithm 1 two slight changes:
state-space considered given Equation (108) prediction mean
covariance extended random vector xi done using evolution matrix F
(which identity KTD). Notice computational complexity
algorithms, parameter vector extended two scalars. KTD,
XKTD specialized XKTD-V (value function evaluation) XKTD-SARSA (Qfunction evaluation). reasoning Section 3.2 practical approaches
given Algorithm 5. Yet, specialization XKTD-Q straightforward
off-policy nature, explained section 4.3.2.
Recall KTD zero process noise linear parameterization algorithm GPTD (see Sec. 3.2.1). Actually, holds XKTD zero process noise
linear parameterization MC-GPTD (the algorithm obtained using colored
noise model GPTD framework, however different manner, see Engel et al., 2005).
easily (but lengthly) checked expanding XKTD equations linear case.
again, MC-GPTD certainly extended handle non-stationarities, even
less natural XKTD, cannot handle nonlinear parameterization.
point view, XKTD extends MC-GPTD.
Algorithm 4: General XKTD algorithm
Initialization: priors x0|0 P0|0 ;
1, 2, . . .
Observe transition ti reward ri ;
Prediction step;
xi|i1 = F xi1|i1 ;
Pi|i1 = F Pi1|i1 F + Pvi0 ;
Compute statistics interest (using UT);
ri|i1 = E[gti (i ) + ni |r1:i1 ] ;


Pxri = E (xi xi|i1 )(gti (i ) + ni ri|i1
)|r1:i1 ;

Pri = E (gti (i ) + ni ri|i1 )2 |r1:i1 ;
Correction step;
Ki = Pxri Pr1
;


xi|i = xi|i1 + Ki ri ri|i1 ;
Pi|i = Pi|i1 Ki Pri KiT ;

510

fiKalman Temporal Differences

Algorithm 5: XKTD-V XKTD-SARSA



0 0
P0|0 ;
Initialization: priors x0|0 = 0|0
1, 2, . . .
(
(si , si+1 ) (XKTD-V)
Observe transition ti =
(si , ai , si+1 , ai+1 ) (XKTD-SARSA)

reward ri ;

Prediction Step;
xi|i1 = F xi1|i1 ;
Pi|i1 = F Pi1|i1 F + Pvi0 ;
Sigma-points

n computation ;
(j)
Xi|i1 = xi|i1 , 0 j 2p + 4 (from xi|i1 Pi|i1 );
W = {wj , 0 j 2p + 4 } ;

(j)
(j)
(j)
(j)
/* notice (xi|i1 )T = (i|i1 )T i|i1 ni|i1
*/
R
=
i|i1
n

(j)
(j)

ri|i1 = V(j) (si ) V(j) (si+1 ) + ni|i1 , 0 j 2p + 4 (XKTD-V)
i|i1
i|i1
n

(j)
(j)

ri|i1 = Q(j) (si , ai ) Q(j) (si+1 , ai+1 ) + ni|i1 , 0 j 2p + 4 (XKTD-SARSA)
i|i1

i|i1

Compute statistics interest;
P
(j)
ri|i1 = 2p+4
j=0 wj ri|i1 ;
P
(j)
(j)
Pxri = 2p+4
j=0 wj (xi|i1 xi|i1 )(ri|i1 ri|i1 );

2
P
(j)
Pri = 2p+4
w
r

r
;
j
i|i1
j=0
i|i1
Correction step;
Ki = Pxri Pr1
;


xi|i = xi|i1 + Ki ri ri|i1 ;
Pi|i = Pi|i1 Ki Pri KiT ;

4.3.2 XKTD Off-policy Learning
Off-policy learning problem learning value one policy (the target policy)
following another one (the behavior policy). KTD-Q (or generally Q-learninglike algorithms) example off-policy learning: behavior policy sufficiently
exploratory policy learnt policy optimal one. generally, off-policy
learning interest, example reuse previous trajectories behavioral policy
cannot controlled.
Using colored observation noise results memory effect, similarly happens
eligibility traces classical TD algorithms (Sutton & Barto, 1998). classical eligibility-trace algorithms, XKTD applied off-policy learning fail
includes effect multi-step transitions, contaminated behavior
policy compensated way. discussion off-policy learning
511

;

fiGeist & Pietquin

memory effects, see example work Precup, Sutton, Singh (2000). link
memory effect Monte Carlo (and eligibility traces eligibility factor
set 1) shown convergence analysis Section 5. analyzed
XKTD equations showing parameters updated according past temporal
differences errors, current one.
show this, first step expand prediction equation:
xi|i1 = F xi1|i1



i|i1
i1|i1
i|i1 = 0
i1|i1
ni|i1

(113)

Let gti defined as:
gti = E[gti (i )|r1:i1 ]

(114)

KTD framework, gti actually predicted reward. However, case
XKTD framework, estimated noise also taken account.
predicted reward expanded using Eq. (113):
ri|i1 = E[gti (i ) + ni |r1:i1 ]
= gti + ni|i1
= gti + i1|i1
blockwise notation adopted Kalman gain:


Ki
Ki = Ki
Kni

(115)

(116)

stated, correction equation expanded:
xi|i = xi|i1 + Ki ri



Ki
i|i
i1|i1

i|i = 0 + Ki ri gti i1|i1
Kni
i1|i1
ni|i


last equation general update parameters derived:

i|i = i1|i1 + Ki ri gti Kwi1 ri1

(117)

(118)

parameters thus updated according temporal difference error time i,
= ri gti , innovation time 1, ri1 , (by recurrence) combination TD error time 1 innovation time 2, etc. update equation
highlights memory effect XKTD prevents use off-policy learning scenario. Notably, prevents derivation XKTD-Q algorithm. solution combine
off-policy learning colored noise could use importance sampling scheme,
well known approach Monte Carlo literature allows estimating quantities
linked distribution using samples drawn another distribution.
512

fiKalman Temporal Differences

5. Convergence Analysis
section provides convergence analysis KTD (deterministic MDPs)
XKTD (stochastic MDPs).
5.1 Deterministic Case
First convergence analysis KTD algorithm provided deterministic MDP.
leads result similar one residual algorithms (Baird, 1995), minimization squared Bellman residual. theorem makes strong assumptions
(actually GPTD framework, however without linear hypothesis). However, important remark even hypotheses satisfied, cost
function (47) still minimized. aim result link KTD classic RL
algorithms.
Theorem 2. assumptions posterior noise distributions Gaussian
prior Gaussian (of mean 0 variance P0 ), Kalman Temporal Differences algorithm (white observation noise assumption) minimizes following
regularized empirical cost function:
Ci () =


X
2
1
rj gtj () + ( 0 )T P01 ( 0 )
Pnj

(119)

j=0

Proof. First notice KTD indeed specific form Sigma-Point Kalman Filter
(SPKF). According van der Merwe (2004, ch. 4.5), given assumptions,
SPKF estimator (and thus KTD one) maximum posteriori (MAP) estimator:
i|i = iMAP = argmax p(|r1:i )

(120)



applying Bayes rule, posterior distribution p(|r1:i ) written (normalized) product likelihood p(r1:i |) prior distribution p():
p(|r1:i ) =

p(r1:i |)p()
p(r1:i )

(121)

normalization factor p(r1:i ) depend parameters, MAP thus reduces
likelihood times prior:
i|i = argmax p(r1:i |)p()
(122)


Recall that, KTD, observation noise assumed white. Therefore, joint
likelihood product local likelihoods:
i|i = argmax p(r1:i |)p() = argmax







p(rj |)p()

Moreover, noise prior supposed Gaussian, thus:

rj | N gtj (), Pnj N (0 , P0 )
513

(123)

j=1

(124)

fiGeist & Pietquin

hand, maximizing product densities equivalent minimizing sum
negatives logarithms:



X
i|i = argmin
ln(p(rj |)) + ln(p())
(125)


j=1

Gaussian assumption, distributions follows:
!
1 (rj gtj ())2
1
exp
p(rj |) = p
2
Pnj
2Pnj


1
1

1
( 0 ) P0 ( 0 )
p() =
p
1 exp
2
(2) 2 |P0 | 2

(126)
(127)

Consequently:

i|i




X
2
1
= argmin
rj gtj () + ( 0 )T P01 ( 0 )
P
nj


(128)

j=1

proves result.
remarks importance made. First, memoryless channel assumption
hold stochastic MDPs. Moreover, form minimized cost function (119)
strengthens parallel drawn Section 4.1 KTD squared Bellman residual
minimization. Second, chosen observation noise variance Pni allows weighting samples.
evolution noise variance appear directly minimized cost function, nevertheless empirically influences convergence tracking abilities algorithm.
example, helps handling non-stationarity avoiding local minima. prior P0 acts
regularization terms, help choose it. Notice regularization
term also appears recursive form LSTD algorithm (eg., see Kolter & Ng, 2009).
Finally, shown (again, see van der Merwe, 2004, ch. 4.5) SPKF (and thus
KTD) update indeed online form modified Gauss-Newton method, actually variant natural gradient descent. case, Fisher information matrix
1
Pi|i
, inverse variance matrix random parameters. natural gradient
approach shown quite efficient direct policy search (Kakade, 2001)
actor-critics (Peters, Vijayakumar, & Schaal, 2005), lets envision good empirical results KTD. experimented Section 7. KTD perhaps first reinforcement
learning value (and Q-) function approximation algorithm (in pure critic sense) involving
natural gradient.
5.2 Stochastic Case
convergence analysis provided XKTD stochastic MDPs. Again, theorem
makes strong assumptions, without harming minimization cost function (47)
satisfied.
514

fiKalman Temporal Differences

Theorem 3. Assume posterior noise distribution Gaussian, well prior
distribution (of mean 0 variance P0 ). XKTD estimator minimizes (weighted
regularized) square error linking state values Monte Carlo returns:

Ci () =


X


1

2
j=1 j1

V (sj )


X

2
tj rt + ( 0 )T P01 ( 0 )

(129)

t=j

Proof. result van der Merwe (2004, ch. 4.5) used. corresponding
proof made random walk evolution model (that identity evolution matrix),
however easily extended linear evolution model. thus applied
state-space model (108):
xi|i = xMAP
= argmax p(x|r1:i )
(130)

x

State-space model (108) equivalent state-space model (46) noise (105),
holds (non-extended) parameter vector:
i|i = argmax p(|r1:i ) = argmin( ln(p(|r1:i )))


(131)



applying Bayes rule, posterior distribution p(|r1:i ) (normalized) product
likelihood p(r1:i |) prior p():
p(|r1:i ) =

p(r1:i |)p()
p(r1:i )

(132)

normalization factor p(r1:i ) depend parameters, MAP therefore reduces
likelihood times prior:
i|i = argmax p(r1:i |)p()
(133)


However, observation noise longer white, possible express joint
likelihood product local likelihoods. Nevertheless, joint likelihood still
computable. this, notations introduced. Let Vi (), Ri Ni following
1 vectors:
Vi () = V (s1 ) V (s2 ) . . .

Ri = r1 r2 . . . ri

Ni = n1 n2 . . . ni


V (si )

(134)
(135)
(136)

Let Hi bidiagonal matrix defined as:



1 0 . . .
0 1 0


Hi = . .

.
.
.
.
.
.
.
0 ...
0
1
515

(137)

fiGeist & Pietquin

easy check inverse given by:

1
0 1

H1
= ..
. ...
0 ...

...

..
.
0


i1
...



1

(138)

Eventually, let Ni = E[Ni NiT ] variance matrix noise Ni , takes account
coloration. Given definition noise ni (105), tridiagonal matrix given by:
2

0 + 2 12
12
0
...


..
22
2
12


+


.
1
2
2

Ni =
(139)


..
..
..
2


.
.
.
i1
2
2
0
...
i1
i1
+ 2 i2
noise Gaussian, likelihood Gaussian too, colored observation noise. distribution is:
r1:i | N (Ri Hi Vi (), Ni )

(140)

Maximizing MAP equivalent minimizing negative logarithm, given
distribution (140) XKTD estimator satisfies:



1
(


))
(141)
(R

H
V
()
+
(


)
P
i|i = argmin (Ri Hi Vi ())T 1
0


0
0
Ni


noise variance rewritten according Hi diagonal matrix containing
residual variances:
2
)
Ni = Hi HTi = diag(02 , . . . , i1

(142)

Using last equation, XKTD estimator rewritten as:



1
i|i = argmin (Ri Hi Vi ())T 1
Ni (Ri Hi Vi ()) + ( 0 ) P0 ( 0 )



= argmin (Ri Hi Vi ())T (Hi HTi )1 (Ri Hi Vi ()) + ( 0 )T P01 ( 0 )




1
1
1
= argmin (H1
R

V
())

(H
R

V
())
+
(


)
P
(


)
(143)




0
0
0





Given inverse (138) Hi matrix, last equation proves result.
result shows (strong) assumptions, XKTD minimizes square
error linking state values Monte Carlo returns, strengthens discussion
inability XKTD used off-policy learning scenario Section 4.3.2. KTD,
residuals variance weights samples, prior acts regularization term,
help choose it. important fact result shows actually,
assumption residuals variance constant (that j2 = 2 ), XKTD minimizes
516

fiKalman Temporal Differences

cost-function (the recursive version of) LSTD(1), eligibility traces-based extension
LSTD eligibility factor 1 (see Boyan, 1999 proof LSTD(1) minimizes
cost-function (129)). consequence, XKTD asymptotically unbiased value function
estimator, LSTD(1)10 .

6. Active Learning Scheme
parameters modeled random variables, value (or Q-) function
function parameters, random variable given state (or state-action
pair). first shown compute expectation associated uncertainty
thanks unscented transform. dilemma exploration exploitation
benefit uncertainty information. approaches literature allows
handling value function approximation problem well computing uncertainty
values meantime. work Engel (2005) approach, however effective use
obtained uncertainty information left future work. proposed form
active learning sort totally explorative policy context KTD-Q.
contribution shown effectively speed learning Section 7.
6.1 Computing Uncertainty Values
Let V approximated value function parameterized random vector mean
variance matrix P . Let V (s) V2 (s) associated mean variance
given state s. order propagate uncertainty parameters value
function, first step compute sigma-points associated parameter vector
= {(j) , 0 j 2p} well corresponding weights W = {wj , 0 j 2p}
P , described Section 3.2. images sigma-points computed
given state using parameterized value function :
n

(j)
V (s) = V (s) = V(j) (s), 0 j 2p
(144)
Knowing images corresponding weights, possible compute statistics
interest, namely mean variance approximated value function:
V (s) =

2p
X

(j)

wj V (s)



V2 (s) =

j=0

2p
X


2
(j)
wj V (s) V (s)

(145)

j=0

Thus, given representation value function random parameter vector,
uncertainty propagated value function. Figure 1 illustrates uncertainty
computation. Extension Q-function straightforward. complexity (both computational memory) quadratic. So, time-step estimate i|i
associated variance Pi|i known, uncertainty information computed
KTD framework.
important remark made here. estimated variance provides
information uncertainty estimates, however take account
10. Notice LSTD(1) KTD minimize cost function, different way, thus
provide estimates asymptotically.

517

fiGeist & Pietquin

Figure 1: Uncertainty computation.
stochasticity MDP. get lower number samples increases. Roughly
speaking, seen indirect generalized counting number visits
given state state-action pair. Even stochastic MDP, vanish zero
number samples grows infinity: estimate uncertainty estimated
value function, variance stochastic process value function
expectation.
6.2 Form Active Learning
simple active learning scheme using uncertainty information provided here. KTDQ (determinism transitions assumed here) off-policy algorithm: learns
optimal policy following different behaviorial policy b. natural question
know behaviorial policy choose order speed learning. piece response
given here.
Let current temporal index. system state si , agent
choose action ai . considered algorithm KTD-Q, estimates i1|i1
Pi1|i1 available. used approximate uncertainty Q2
(si , a)
function parameterized i1 state si action a. Let Q
i1
corresponding variance. action ai chosen according following random
behaviorial policy:
Qi1 (si , ai )
b(ai |si ) = P
(146)
aA Qi1 (si , a)
totally explorative policy obtained, sense favorises less certain actions.
way among others use available uncertainty information, nevertheless
shown Section 7 quite efficient compared uniformly random behaviorial policy.
However, use wisely variance information general dilemma
exploration exploitation still open perspective.

7. Experiments
section provides set classical RL benchmarks aiming comparing KTD
variants state-of-the-art algorithms highlighting different aspects. Atomic
benchmarks chosen order highlight separately unitary properties KTD
(see Table 1), quite complex difficult task. Compared
algorithms TD, SARSA Q-learning function approximation well (recursive
518

fiKalman Temporal Differences

(non)stationarity
Tsitsiklis chain
Boyan chain
maze
inverted pendulum

(non)linearity
X

uncertainty

X
X
X

X

sample efficiency

stochasticity

X

X

X

Table 1: Experiments highlighted properties.
form of) LSTD (MC-) GPTD. sake reproducibility, parameter values
provided experiment. extensions eligibility traces considered
here, LSTD performs better TD() varying small effect LSTD()
performances, according Boyan (1999).
7.1 Choosing KTD Parameters
order use (X)KTD framework, parameters chosen: variance
observation noise (or variance residuals XKTD), priors variance
process noise. less common perhaps less intuitive choice
learning rate example, discussed here. evolution noise KTD
residual XKTD translate confidence practitioner ability chosen
parameterization represent true value function. known advance
value function lies hypothesis space (which case example tabular
case), corresponding variance chosen small (but never zero numerical
stability reasons). Another way choose variances interpret
weighting samples, see Eq. (119) (129). prior 0 initialized value
close one user thinks optimal, default value, example zero
vector. prior P0 quantifies certainty user prior 0 , lower less
certain. Another way interpret priors consider regularization terms,
shown Eq. (119) (129). choose process noise variance open question.
knowledge non-stationarity available, used choose matrix.
However, knowledge generally difficult obtain beforehand. article,
process noise form Pvi = Pi1|i1 used, 1 small positive constant.
artificial process noise emphasizes recent observed data, window emphasized
observations quantified . artificial process noise chosen, see
work van der Merwe (2004, ch. 3.5.2) quick survey. following, parameters
chosen trial error (for algorithms). Theyre perhaps best ones,
orders magnitude correct.
7.2 Tsitsiklis Chain
first experiment aims illustrating ability KTD handle nonlinear parameterizations convergence property. consists 3 states valued Markov chain first
proposed Tsitsiklis Roy (1997). State transits state probability 0.5
state 1 probability 0.5 (state 1 transiting state 1 3 equi-probability).
reward always zero, therefore optimal value function zero. chain
simple, however nonlinear parameterization causes TD function approximation divergence considered. Let = 0.05, let 3 3 identity matrix
519

fiGeist & Pietquin

3 3 matrix defined as:


1

= 32
1
2

1
2

1
3
2

3
2
1
2


(147)

1

value function parameterized single scalar , parameterization given
(notice V 3 1 vector):

V = exp ((M + I) ) V0 V0 = 10 7 3

(148)

parameterization proposed Tsitsiklis Roy (1997) illustrate
possible divergence TD case nonlinear parameterization. optimal parameter
obviously = .

Figure 2: Tsitsiklis chain.
KTD compared TD function approximation. LSTD GPTD
considered here, unable handle nonlinear parameterization. TD,
learning rate chosen equal = 2.103 initial parameter set 0 = 0.
KTD, priors set 0 = 0 P0 = 10. observation noise variance set
Pni = 103 . process noise described Section 7.2 used = 101 . Results
depicted Figure 2 shows parameter estimates function number
observed transitions. TD estimates diverge, expected. KTD handles nonlinear
parameterization converges toward good value (despite stochasticity transitions).
7.3 Boyan Chain
section KTD XKTD compared two second order value function approximation algorithms, namely (recursive) LSTD (parametric) MC-GPTD simple
valued Markov chain, Boyan (1999) chain. objective threefold: showing sample efficiency, demonstrating bias removal (of XKTD compared KTD) showing
non-stationarity handling.
520

fierror

Kalman Temporal Differences

1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

LSTD
MC-GPTD
KTD
XKTD

0

20

40

60
80
number episodes

100

120

140

Figure 3: Boyan chain.
Boyan chain 13-state Markov chain state s0 absorbing state, s1
transits s0 probability 1 reward -2, si transits either si1 si2 ,
2 12, probability 0.5 reward -3. feature vector (s) states
s12 , s8 , s4 s0 respectively [1, 0, 0, 0]T , [0, 1, 0, 0]T , [0, 0, 1, 0]T [0, 0, 0, 1]T .
feature vectors states obtained linear interpolation. approximated
value function thus V (s) = (s). optimal value function exactly linear
features, corresponding optimal parameter vector 1 = [24, 16, 8, 0]T .
measure quality algorithm normalized Euclidian distance
current parameter vector estimate optimal one k1 k k k computed. Notice
parameterization linear, measuring error
true estimated value functions, scaling factor. discount factor set
1 episodic task. algorithms, prior set P0|0 =
identity matrix. Choosing prior fair, yields choose
regularization term algorithms. MC-GPTD KTD variations, residual
variance (observation noise KTD) set i2 = 103 (Pni = 103 ). KTD variations,
process noise covariance set RLS (recursive least-squares)-like adaptive process
noise described Section 7.1, Pvi = Pi1|i1 Pi1|i1 denotes variance
parameters, 1 small positive constant, chosen equal 102 . Choosing
parameters requires practice, choosing learning rate
algorithms. algorithms initial parameter vector set zero. experiment
non-stationarity handling, change MDP simulated multiplying rewards
ten 70th episode (rewards become 20 30 instead 2 3).
optimal value function still linear feature vectors, optimal parameter vector
2 = 101 MDP change. Learning done 140 episodes, results
averaged 300 trials. Results presented Figure 3.
MDP change, KTD variations MC-GPTD converge faster LSTD
(and equally well). XKTD, well LSTD MC-GPTD, unbiased, contrary
KTD. Thus XKTD job designed for, removing bias due
stochastic transitions. MDP change, LSTD MC-GPTD fail track
value function. KTD manages it, still biased. XKTD tracks value function
without biased. GPTD results presented sake readability.
521

fiGeist & Pietquin

However, behavior KTD one MDP change, fails track
value function rewards switch (much like MC-GPTD). experiment shows
XKTD performs well KTD, however without bias problem,
motivation introducing new algorithm. sample-efficient tracks value
function rather converging (non-stationarity handling). argued
forgetting factors added LSTD GPTD. However naturally
done KTD framework, moreover exhibits interesting aspects
illustrated next sections.

7.4 Simple Maze
KTD framework, parameters modelled random variables.
function parameters, approximated value (or Q-) function random function.
thus possible compute variance associated value state shown
Section 6.1. necessary condition handle exploration-exploitation dilemma
value (or Q-) function approximation context. section uncertainty information
obtained KTD framework illustrated simple maze problem.
2d continuous state space unit square: (x, y) [0, 1]2 . Actions move
left, right, down, magnitude 0.05 case. reward +1
agent leaves maze = 1 x [ 38 , 58 ], 1 agent leaves maze = 1
x [0, 38 [] 58 , 1], 0 elsewhere. algorithm KTD-V. parameterization set
9 equispaced Gaussian kernels (centered {0, 0.5, 1} {0, 0.5, 1}) standard
deviation 0.5. forgetting factor set 0.9. agent starts random position
(x0 , y0 ) x0 sampled Gaussian distribution, x0 N ( 21 , 18 ), y0 sampled
uniform distribution, y0 U[0,0.05] . behaviorial policy value function
learnt going probability 0.9, go one three directions
probability 0.1
3 . initial parameter vector set zero, prior P0|0 = 10I,
noise covariances Pni = 1 Pvi = 0I.
value function learnt quite well, however point here. objective
illustrate value function uncertainty. learning done 30 episodes,
results given Figure 4, shows standard deviation approximated value
function state space. Considering x-axis, uncertainty lower middle
border. explained fact learning trajectories occur
frequently center domain. Considering y-axis, uncertainty lower
near upper bound (y = 1) near lower bound (y = 0). explained
fact retro-propagated values less certain. Thus uncertainty information
computed KTD-V meaningful simple example, useful
speed learning, eg., exploration/exploitation dilemma. Another application example
given Section 6.2 experimented Section 7.5. GPTD also provides
meaningful uncertainty information (Engel, Mannor, & Meir, 2003). However, far
know, never used practically. likely, uncertainty information cannot
derived LSTD (the main reason belief matrix maintained
LSTD symmetric, therefore cannot interpreted variance matrix).
522

fiKalman Temporal Differences

1

0.9

0.9

0.8

0.8

0.7

position

0.7

0.6

0.6

0.5

0.5

0.4

0.4

0.3

0.3
0.2

0.2

0.1

0.1

0

0
0

0.1

0.2

0.3

0.4 0.5 0.6
x position

0.7

0.8

0.9

1

Figure 4: Simple maze, uncertainty illustration.
7.5 Inverted Pendulum
last experiment inverted pendulum described Lagoudakis Parr (2003).
goal compare two value-iteration-like algorithms, namely KTD-Q Qlearning, aim learning directly optimal policy. LSTD GPTD cannot
considered here: unable handle nonlinearities (the nonlinearity max
operator here), cannot used Bellman optimality operator. proposed
active learning-like scheme also experimented: uses uncertainty computed KTD
speed convergence.
task requires balancing pendulum unknown length mass upright
position applying forces cart attached to. Three actions allowed: left
force (-1), right force (+1), force (0). associated state space consists vertical
angle angular velocity pendulum. Deterministic transitions computed
according physical dynamics system, depends current action a:
=

g sin() ml2 sin(2)/2 50 cos()a
4l/3 ml cos2 ()

(149)

g gravity constant, l mass length pendulum,
1
mass cart, = m+M
. zero reward given long angular position

[ 2 , 2 ]. Otherwise, episode ends reward 1 given. parameterization
composed constant term set 9 equispaced Gaussian kernels (centered
{ 4 , 0, 4 } {1, 0, 1} standard deviation 1) action. Thus
set 30 basis functions. discount factor set 0.95.
7.5.1 Learning Optimal Policy
First, algorithms ability learn optimal policy compared. Q-learning, learning
rate set = 0 nn00+1
+i 0 = 0.5 n0 = 200, according Lagoudakis Parr
523

fiGeist & Pietquin

(2003). KTD-Q, parameters set P0|0 = 10I, Pni = 1 Pvi = 0I.
algorithms initial parameter vector set zero. Training samples collected
online random episodes. agent starts randomly perturbed state close
equilibrium (0, 0) follows policy selects actions uniformly random.
average length episodes 10 steps, algorithms learnt
trajectories. Results summarized Figure 5.
10000

KTD-Q
Q-learning

steps

1000

100

10
0

100

200

300

400 500 600
number episodes

700

800

900

1000

Figure 5: Inverted pendulum, optimal policy learning.
trial, learning done 1000 episodes. Every 50 episodes, learning freezed
current policy evaluated. this, agent randomly initialized state
close equilibrium greedy policy followed end episode;
repeated 100 times averaged. Performance measured number steps
episode. Maximum number steps one episode bounded 3000 steps,
corresponds 5 minutes balancing pole without failure. Results Figure 5
averaged 100 trials presented semi-log scale.
KTD-Q learns optimal policy (that balancing pole maximum number
steps) asymptotically near-optimal policies learnt tens episodes.
results KTD-Q comparable ones LSPI algorithm (see Lagoudakis
& Parr, 2003, Fig. 16). number learning episodes, Q-learning
linear parameterization fails learn policy balances pole
tens time steps. Similar results Q-learning obtained Lagoudakis Parr
(2003).
7.5.2 Form Active Learning
parameters random variables, explained Section 6 illustrated Section 7.4, parameterized Q-function random function, KTD framework allows
computing variance associated value state. proposed experiment
aims using uncertainty information speed learning. learning
still done random trajectories. However, form active learning described
Section 6 considered now. environment initialized randomly before.
system given state, standard deviation Q-function computed
524

fiKalman Temporal Differences

action. deviations normalized, new action sampled randomly according probabilities weighted deviations. Thus, uncertain action
likely sampled. average length episodes 11 steps,
differ much uniformly random transitions. Consequently slightly help
improve speed convergence (at 10%, much less real improvement
100%). Results summarized Figure 6.
3000
2500
KTD-Q
Q-learning
active KTD-Q

steps

2000
1500
1000
500
0
0

50

100
150
200
number episodes

250

300

Figure 6: Inverted pendulum, random active learning.
trial, learning done 300 episodes. Less episodes considered show
speed convergence, however versions KTD perform well asymptotically.
Every 25 episodes, learning freezed current policy evaluated before. Performance measured number steps episode, maximum 3000
steps. Results Figure 6 averaged 100 trials. Notice scale longer
logarithmic. compares KTD-Q informed transitions (active KTD-Q) KTD-Q
uniformly random learning policy Q-learning. comparing two versions
KTD-Q, clear sampling actions according uncertainty speeds convergence.
almost doubled first 100 episodes: example, performance 1500 obtained
25 episodes active-KTD, whereas needs 50 episodes basic
KTD. Thus uncertainty information available thanks KTD framework
quite useful reinforcement learning.

8. Discussion Perspectives
section proposed framework discussed linked related approaches.
perspectives also given.
8.1 Discussion
Approaches related KTD framework proposed previously. Engel (2005)
proposes Gaussian process approach value function approximation. explained before,
principle model value function Gaussian process adopt generative
model linked Bellman evaluation equation. Links Engels approach
525

fiGeist & Pietquin

proposed one discussed throughout paper. Particularly, linear parameterization zero process noise KTD-V reduces GPTD XKTD-V MC-GPTD.
However, KTD framework handle non-stationarities (even recognize GPTD could
probably extended handle too) importantly handles non-linearities
derivative-free manner, allows considering nonlinear parameterizations
Bellman optimality operator. Engels framework allows constructing automatically
online kernel-based linear parameterization, advantage compared proposed framework. However, easily incorporated (see Geist et al., 2008
used preprocessing step, using online difficult). Kalman filtering strongly linked least-squares minimization (in linear case, former
generalization later), proposed approach shares similarities LSTD (Bradtke
& Barto, 1996). However, take account instrumental variables concept (Soderstrom & Stoica, 2002), used handle stochastic transitions (in
KTD framework, done thanks colored noise model). Moreover,
shown Section 5.2 XKTD-V (with linear parameterization evolution noise)
converges solution LSTD(1). Choi Van Roy (2006) introduced Kalman
filter designed handle fixed-point approximation case linear parameterization.
roughly seen bootstrapping version proposed KTD-V. Instead
observation equation state-space model (65), following observation equation used:
ri + (si+1 )T i1|i1 = (si )T + ni . words, reward considered
observation, approximation value function used compute pseudoobservation ri + (si+1 )T i1|i1 . update parameters made match
value function current state pseudo-observation (bootstrapping approach).
Alternatively, seen linear least-squares variation classic TD function approximation algorithm (which combines bootstrapping gradient descent). Phua
Fitch (2007) use bank classical Kalman filters learn parameters piecewise linear parameterization value function. roughly seen special case
proposed approach, however differences exist: one filter bank used
parameterization piecewise linear, exploited develop specificities
algorithm (notably concerning parameters update) proposed approach
make assumption value function.
proposed framework presents interesting aspects. First, suppose
stationarity. immediate application take account non-stationary MDP (Geist,
Pietquin, & Fricout, 2009b), exemplified Section 7.3. even interesting application control case. instance, LSTD algorithm known well behave
combined optimistic policy iteration scheme (-greedy policy example, see Phua
& Fitch, 2007), non-stationarities induced fact control learning interlaced. Similarly, Bhatnagar, Sutton, Ghavamzadeh, Lee (2008) prefer TD
LSTD actor incremental natural actor-critic approach propose, despite
fact less sample efficient. Kalman filtering thus proposed approaches
robust non-stationarity (to certain extent). Quite approaches aiming approximating value function take non-stationary problem account, algorithm
Phua Fitch (2007) one them. Another related approach (designed cope
interlacing control learning actor-critic context) two-timescale
526

fiKalman Temporal Differences

stochastic approximation (for example, see Konda & Tsitsiklis, 2003 Bhatnagar et al.,
2008).
Second, KTD models parameters random vector, possible compute uncertainty information values, explained Section 6.1 illustrated Section 7.4.
used derive form active learning (Sections 6.2 7.5), however uncertainty information could useful deal general problem dilemma
exploration exploitation, following idea done Dearden et al. (1998)
Strehl et al. (2006). point that, far know, rather approaches allows
dealing value function approximation value uncertainty time. One
approaches GPTD framework Engel (2005), however effective use
available uncertainty information left future work original publications
developed far. also noticed without probabilistic statistical approach value function approximation problem uncertainty information
would difficult obtain.
Third, KTD also allows handling nonlinearities. explicitly used KTD-Q
(the max operator severe nonlinearity), illustrated Section 7.5. Nonlinear
parameterization considered too, illustrated Section 7.2. nonlinear parameterization also used Geist et al. (2008) combined preliminary version
KTD-Q. Moreover, nonlinear parameterization allow compact representation
value function approximator, could somehow alleviate square complexity
proposed framework.
KTD shares drawback square Bellman residual minimization-based algorithms (which indeed according Theorem 2): value estimates biased
transitions dynamic system deterministic, illustrated Section 7.3.
Different algorithms propose various methods cope problem. residual algorithms (Baird, 1995), consist minimizing square Bellman residual using
gradient descent, proposed use double sampling order obtain unbiased
estimator. approach two major drawbacks: needs generative model,
sample inefficient. LSTD algorithm (Bradtke & Barto, 1996), consists
minimizing Bellman residual least-squares approach, instrumental variable (Soderstrom & Stoica, 2002) used enforce unbiasedness estimator.
approach easy extend nonlinearity non-stationarity (and thus online control).
Another generic approach remove sort bias proposed Antos et al.
(2008). consists introducing auxiliary function (in add value function)
role remove bias. resulting optimization problem longer quadratic, consists two interlocked square problems. used linear function approximator,
reduces LSTD algorithm, used neural network-based function
approximator Schneega, Udluft, Martinetz (2007). GPTD framework (Engel,
2005) uses colored noise model adapted extend KTD framework.
8.2 Conclusion Perspectives
Kalman-filter-based Temporal Differences framework introduced cope
number problems time: online learning, sample efficiency, non-stationarity
non-linearity handling well providing uncertainty information. actually
527

fiGeist & Pietquin

square-Bellman-minimization-based approach, original framework cannot handle stochastic transitions. thus extended using colored observation noise model. convergence analysis provided deterministic stochastic cases. Finally,
various aspects proposed approach experimentally demonstrated classical reinforcement learning benchmarks. Section 7.2 shows ability converge
nonlinear parameterizations, Section 7.3 shows colored noise induces unbiased
version KTD ability handle non-stationarities, Section 7.4 illustrates available
uncertainty information Section 7.5 shows value-iteration-like KTD-Q algorithm
well learning speed-up obtained thanks proposed active learning scheme.
State-of-the-art algorithms also considered, KTD compares favorably them.
KTD framework presents interesting perspectives. First, XKTD shown
effectively remove bias. noticed Engel (2005, ch. 4.5), noise models
envisioned (by analogy LSTD() example), however noise models choose
incorporate KTD framework still open questions. theoretical insights bias caused use KTD stochastic problems also
useful. Also, interesting perspective address off-policy problem considering
colored noise combine XKTD importance sampling. Another interesting perspective adapt eligibility traces principle proposed framework order fill
gap KTD (local update) XKTD (global update relation Monte
Carlo) (Geist & Pietquin, 2010a).
Second, KTD framework naturally extended partially observable
case. Indeed, inferring state system given past observations problem
benefit Bayesian filtering formalism close one proposed. well
known partially observable MDP (POMDP) expressed MDP
states distributions states POMDP. distributions estimated
(by using filtering approach example), naturally taken account
KTD: parameterization already function distribution parameters,
extended function distribution states manner.
KTD framework handles well nonlinearities. interesting perspective could use
neural network based representation value (or Q-) function, let hope
compact representation. way, probably easier address real world
problems, scaling mandatory.
Another difficulty choice different parameters, problemdependent. First noticed choosing type parameters
difficult choosing learning rates example, less usual RL community.
Concerning automatic choice parameters, adaptive filtering literature
help (Goodwin & Sin, 2009). form adaptive evolution noise used
experimental part paper, however many solutions envisioned.
said before, KTD could interesting alternative TD actor part
incremental natural actor-critic algorithms Bhatnagar et al. (2008). preliminary
works using KTD actor-critic architecture provided Geist Pietquin
(2010c). Talking natural gradient, parallel drawn KTD
framework natural gradient descent Section 5.1, could benefit
theoretical insights.
528

fiKalman Temporal Differences

value uncertainty available framework used form active
learning scheme, planned used address general problem
dilemma exploration exploitation, either adapting existing approaches
designed tabular case (Geist & Pietquin, 2010b) developing new methods.
Unscented Kalman filtering, work based, linked nonlinear leastsquares problems solved using statistical linearization approach (Geist & Pietquin, 2010e).
Underlying ideas used extend LSTD algorithm nonlinear parameterizations
well Bellman optimality operator (Geist & Pietquin, 2010d).
Finally, planned comparison state-of-the-art, theoretically
experimentally. Ultimately application ideas real world problem needed
asses utility. Concerning last point, plan apply proposed framework
dialogue management problem.

Acknowledgments
authors wish thank European Community (FP7/2007-2013, grant agreement
216594, CLASSiC project : www.classic-project.org) Region Lorraine financial
support. Matthieu Geist also wish thank ArcelorMittal Research financial support
2006-2009 PhD thesis.

References
Antos, A., Szepesvari, C., & Munos, R. (2008). Learning near-optimal policies Bellmanresidual minimization based fitted policy iteration single sample path. Machine
Learning, 71 (1), 89129.
Baird, L. C. (1995). Residual Algorithms: Reinforcement Learning Function Approximation. Proceedings International Conference Machine Learning (ICML
95), pp. 3037.
Bertsekas, D. P., & Tsitsiklis, J. N. (1996). Neuro-Dynamic Programming. Athena Scientific.
Bhatnagar, S., Sutton, R. S., Ghavamzadeh, M., & Lee, M. (2008). Incremental Natural
Actor-Critic Algorithms. Proceedings Twenty-First Annual Conference
Advances Neural Information Processing Systems (NIPS), Vancouver, Canada.
Bishop, C. M. (1995). Neural Networks Pattern Recognition. Oxford University Press,
New York, USA.
Boyan, J. A. (1999). Technical Update: Least-Squares Temporal Difference Learning. Machine Learning, 49 (2-3), 233246.
Bradtke, S. J., & Barto, A. G. (1996). Linear Least-Squares Algorithms Temporal
Difference Learning. Machine Learning, 22 (1-3), 3357.
Chen, Z. (2003). Bayesian Filtering : Kalman Filters Particle Filters, Beyond.
Tech. rep., Adaptive Systems Lab, McMaster University.
529

fiGeist & Pietquin

Choi, D., & Van Roy, B. (2006). Generalized Kalman Filter Fixed Point Approximation Efficient Temporal-Difference Learning. Discrete Event Dynamic Systems,
16, 207239.
Dearden, R., Friedman, N., & Russell, S. J. (1998). Bayesian q-learning. AAAI/IAAI,
pp. 761768.
Engel, Y. (2005). Algorithms Representations Reinforcement Learning. Ph.D. thesis,
Hebrew University.
Engel, Y., Mannor, S., & Meir, R. (2003). Bayes Meets Bellman: Gaussian Process
Approach Temporal Difference Learning. Proceedings International Conference Machine Learning (ICML 2003), pp. 154161.
Engel, Y., Mannor, S., & Meir, R. (2005). Reinforcement Learning Gaussian Processes.
Proceedings International Conference Machine Learning (ICML-05).
Geist, M., & Pietquin, O. (2010a). Eligibility Traces Colored Noises. Proceedings
IEEE International Conference Ultra Modern Control systems (ICUMT
2010), Moscow (Russia). IEEE.
Geist, M., & Pietquin, O. (2010b). Managing Uncertainty within Value Function Approximation Reinforcement Learning. Active Learning Experimental Design
workshop (collocated AISTATS 2010), Sardinia, Italy.
Geist, M., & Pietquin, O. (2010c). Revisiting natural actor-critics value function
approximation. Torra, V., Narukawa, Y., & Daumas, M. (Eds.), Proceedings
7th International Conference Modeling Decisions Artificial Intelligence (MDAI
2010), Vol. 6408 Lecture Notes Artificial Intelligence (LNAI), pp. 207218, Perpinya (France). Springer Verlag - Heidelberg Berlin.
Geist, M., & Pietquin, O. (2010d). Statistically Linearized Least-Squares Temporal Differences. Proceedings IEEE International Conference Ultra Modern Control
systems (ICUMT 2010), Moscow (Russia). IEEE.
Geist, M., & Pietquin, O. (2010e). Statistically Linearized Recursive Least Squares.
Proceedings IEEE International Workshop Machine Learning Signal
Processing (MLSP 2010), Kittila (Finland).
Geist, M., Pietquin, O., & Fricout, G. (2008). Bayesian Reward Filtering. et al., S. G.
(Ed.), Proceedings European Workshop Reinforcement Learning (EWRL
2008), Vol. 5323 Lecture Notes Artificial Intelligence, pp. 96109. Springer Verlag,
Lille (France).
Geist, M., Pietquin, O., & Fricout, G. (2009a). Kalman Temporal Differences: deterministic case. Proceedings IEEE International Symposium Adaptive Dynamic
Programming Reinforcement Learning (ADPRL 2009), Nashville, TN, USA.
Geist, M., Pietquin, O., & Fricout, G. (2009b). Tracking Reinforcement Learning.
Proceedings 16th International Conference Neural Information Processing
(ICONIP 2009), Bangkok (Thailande). Springer.
Geramifard, A., Bowling, M., & Sutton, R. S. (2006). Incremental Least-Squares Temporal
Difference Learning. Proceedings 21st Conference, American Association
Artificial Intelligence, pp. 356361.
530

fiKalman Temporal Differences

Gill, P. E., Golub, G. H., Murray, W., & Saunders, M. A. (1974). Methods Modifying
Matrix Factorization. Mathematics Computation, 28 (126), 505535.
Goodwin, G. C., & Sin, K. S. (2009). Adaptive Filtering Prediction Control. Dover
Publications, Inc., New York, NY, USA.
Jo, S., & Kim, S. W. (2005). Consistent Normalized Least Mean Square Filtering
Noisy Data Matrix. IEEE Transactions Signal Processing, 53 (6), 21122123.
Julier, S. J., & Uhlmann, J. K. (2004). Unscented filtering nonlinear estimation. Proceedings IEEE, 92 (3), 401422.
Kakade, S. (2001). natural policy gradient. Advances Neural Information Processing
Systems 14 [Neural Information Processing Systems (NIPS 2001), pp. 15311538,
Vancouver, British Columbia, Canada.
Kalman, R. E. (1960). New Approach Linear Filtering Prediction Problems.
Transactions ASMEJournal Basic Engineering, 82 (Series D), 3545.
Kolter, J. Z., & Ng, A. Y. (2009). Regularization Feature Selection Least-Squares
Temporal Difference Learning. proceedings 26th International Conference
Machine Learning (ICML 2009), Montreal Canada.
Konda, V. R., & Tsitsiklis, J. N. (2003). actor-critic algorithms. SIAM J. Control
Optim., 42 (4), 11431166.
Lagoudakis, M. G., & Parr, R. (2003). Least-Squares Policy Iteration. Journal Machine
Learning Research, 4, 11071149.
Peters, J., Vijayakumar, S., & Schaal, S. (2005). Natural Actor-Critic. et al., J. G. (Ed.),
Proceedings European Conference Machine Learning (ECML 2005), Lecture
Notes Artificial Intelligence. Springer Verlag.
Phua, C. W., & Fitch, R. (2007). Tracking Value Function Dynamics Improve Reinforcement Learning Piecewise Linear Function Approximation. Proceedings
International Conference Machine Learning (ICML 07).
Precup, D., Sutton, R. S., & Singh, S. P. (2000). Eligibility Traces Off-Policy Policy
Evaluation. Proceedings Seventeenth International Conference Machine
Learning (ICML00), pp. 759766, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.
Puterman, M. L. (1994). Markov Decision Processes: Discrete Stochastic Dynamic Programming. Wiley-Interscience.
Schneega, D., Udluft, S., & Martinetz, T. (2007). Improving optimality neural rewards
regression data-efficient batch near-optimal policy identification.. de Sa, J. M.,
Alexandre, L. A., Duch, W., & Mandic, D. P. (Eds.), ICANN, Vol. 4668 Lecture
Notes Computer Science, pp. 109118. Springer.
Schoknecht, R. (2002). Optimality Reinforcement Learning Algorithms Linear Function Approximation. Proceedings Conference Neural Information Processing Systems (NIPS 15).
Sigaud, O., & Buffet, O. (Eds.). (2010). Markov Decision Processes Artificial Intelligence. Wiley - ISTE.
531

fiGeist & Pietquin

Simon, D. (2006). Optimal State Estimation: Kalman, H Infinity, Nonlinear Approaches
(1. Auflage edition). Wiley & Sons.
Strehl, A. L., Li, L., Wiewiora, E., Langford, J., & Littman, M. L. (2006). Pac modelfree reinforcement learning. Proceedings 23rd International Conference
Machine Learning (ICML 2006), pp. 881888, Pittsburgh, PA, USA.
Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction (3rd edition). MIT Press.
Sutton, R. S., Koop, A., & Silver, D. (2007). role tracking stationary environments. ICML 07: Proceedings 24th international conference Machine
learning, pp. 871878, New York, NY, USA. ACM.
Soderstrom, T., & Stoica, P. (2002). Instrumental variable methods system identification.
Circuits, Systems, Signal Processing, 21, 19.
Tsitsiklis, J. N., & Roy, B. V. (1997). analysis temporal-difference learning
function approximation. IEEE Transactions Automatic Control, 42, 674690.
van der Merwe, R. (2004). Sigma-Point Kalman Filters Probabilistic Inference Dynamic State-Space Models. Ph.D. thesis, OGI School Science & Engineering, Oregon
Health & Science University, Portland, OR, USA.
Yu, H., & Bertsekas, D. P. (2007). Q-Learning Algorithms Optimal Stopping Based
Least Squares. Proceedings European Control Conference, Kos, Greece.

532

fiJournal Artificial Intelligence Research 39 (2010) 663-687

Submitted 6/10; published 11/10

Effective Algorithm Phase Transitions
Directed Hamiltonian Cycle Problem
Gerold Jager

gej@informatik.uni-kiel.de

Computer Science Institute,
Christian-Albrechts-University Kiel,
D-24118 Kiel, Germany

Weixiong Zhang

weixiong.zhang@wustl.edu

Department Computer Science Engineering,
Washington University,
St. Louis, Missouri 63130, United States

Abstract
Hamiltonian cycle problem (HCP) important combinatorial problem
applications many areas. among first problems used studying intrinsic properties, including phase transitions, combinatorial problems. thorough theoretical
experimental analyses made HCP undirected graphs, limited
amount work done HCP directed graphs (DHCP). main contribution work effective algorithm DHCP. algorithm explores
exploits close relationship DHCP Assignment Problem (AP)
utilizes technique based Boolean satisfiability (SAT). combining effective algorithms AP SAT, algorithm significantly outperforms previous exact DHCP
algorithms, including algorithm based award-winning Concorde TSP algorithm.
second result current study experimental analysis phase transitions
DHCP, verifying refining known phase transition DHCP.

1. Introduction
undirected graph G = (V, E) Hamiltonian contains Hamiltonian cycle (HC),
cycle visits vertex exactly once. Given graph, Hamiltonian cycle problem
(HCP) find HC prove HC exists graph. decision version
HCP among first problems proven N P-complete (Karp, 1972). HCP
well-known problem many applications different areas, e.g., Hamiltonian cycle
game game theory (Stojakovic & Szabo, 2005), problem finding knights tour
chessboard artificial intelligence (Henderson & Apodaca, 2008), DNA Physical
Mapping biology (Grebinski & Kucherov, 1996). Much research done
HCP undirected graphs. reviews, see work Bondy (1995), Christofides (1975),
Chvatal (1985), Gould (1991), Vandegriend (1998), Gutin Moscato (2000).
particular, many algorithms developed HCP (Angluin & Valiant, 1979;
Bollobas, Fenner & Frieze, 1987; Frieze, 1988a; Posa, 1976; Vandegriend, 1998), reviewed
Stony Brook Algorithm Repository (Skiena, 2008). One effective algorithm
HCP based related Traveling Salesman Problem (TSP) undirected weighted
graph, problem finding HC minimum total weight.
c
2010
AI Access Foundation. rights reserved.

fiJager & Zhang

HCP also canonical problem understanding intrinsic properties combinatorial problems. One problem property called phase transition. Consider
undirected graph Gn,m edges randomly chosen possible n(n 1)/2 edges
n vertices. expected keeping size n, i.e., number vertices,
constant increasing number edges m, probability random graph Gn,m
Hamiltonian increases 0 1. Surprisingly, probability Hamiltonian
Gn,m exhibits sharp, dramatic transition 0 1, transition occurs approximately = dc n (log n + log log n)/2c (Bollobas, 1985; Cheeseman, Kanefsky &
Taylor, 1991; Komlos & Szemeredi, 1983). Furthermore, experimentally shown
constant c 1.08 1.10, probability Gn,m Hamiltonian
1/2 (Vandegriend & Culberson, 1998). Phase transitions HCP also studied
different control parameters, example, called general constrainedness
parameter (Frank, Gent & Walsh, 1998). phase transition result HCP motivated substantial amount research phase transitions combinatorial problems,
particularly TSP (Zhang & Korf, 1996) Boolean satisfiability (Monasson, Zecchina,
Kirkpatrick & Selman, 1999).
study consider HCP directed graphs, call directed HCP,
DHCP short. addition known applications HCP mentioned above,
interesting application DHCP DHCP heuristics used solve
Bottleneck TSP (Kabadi & Punnen, 2002). contrast extensive amount work
HCP undirected graphs, research DHCP rather limited (Angluin
& Valiant, 1979; Bang-Jensen & Gutin, 2008; Kelly, 2007). first exact algorithm
DHCP developed Martello (1983). algorithm outputs fixed number h
HCs reports cannot find h HCs given directed graph. setting h = 1,
gives rise algorithm DHCP. recent years, algorithms based SAT
encoding introduced problem, e.g., absolute encoding (Hoos, 1999)
relative encoding (Prestwich, 2003; see also Velev & Gao, 2009). Furthermore,
probabilistic heuristic DHCP complexity O(n1.5 ) proposed (Frieze, 1988b).
shown random class Gn,m probability, given instance
HC found algorithm therefore exists, changes 0 1, n grows
infinity = n log n+cn, c constant. DHCP, phase transition result
similar HCP obtained well, namely phase transition occurs
= dc n (log n + log log n)c (McDiarmid, 1980), constant c expected
close 1.
Note research TSP also alluded DHCP algorithm. Using
technique 2-point reduction, asymmetric TSP (ATSP) distance city
city j may necessarily equal j converted symmetric
TSP, number vertices doubled (Jonker & Volgenant, 1983). Using
transformation, determine whether directed graph Hamiltonian solving
symmetric TSP using renowned Concorde algorithm (Applegate, Bixby, Chavatal &
Cook, 2005, 2006). Concorde solved many large benchmark instances (Cook, 2010),
including TSP instance 85, 900 cities (Applegate et al., 2009), date
largest solved practical TSP instance.
main contribution paper effective exact algorithm DHCP.
algorithm, utilize methods two well-known combinatorial problems, i.e., Assign664

fiAlgorithm Directed Hamiltonian Cyce Problem

ment Problem (AP) Boolean satisfiability (SAT); therefore denote algorithm
AP-SAT. Using random graphs many real world instances, experimentally compare
AP-SAT algorithm DHCP algorithm Martello (1983), TSP based approach takes advantage TSP solver Concorde (Applegate et al., 2005, 2006)
above-mentioned SAT encodings DHCP (Hoos, 1999; Prestwich, 2003).
results show AP-SAT algorithm significantly outperforms algorithms.
second contribution experimental study refinement known phase
transition result existence HC random directed graph (McDiarmid, 1980),
similarly done HCP (Vandegriend & Culberson, 1998).

2. Algorithm
Consider directed unweighted graph G = (V, E) nodes V edges E.
purpose solving DHCP, consider problem determining whether
exists collection cycles, may necessarily complete cycles, visiting
vertex exactly once. call problem directed Assignment Problem DAP
short. algorithm explores exploits intrinsic relationship DHCP
DAP. precisely, AP-SAT algorithm searches HC space DAP
solutions. first solves DAP. DAP solution forms HC, DAP solution
exists, algorithm terminates. DAP solver returns solution HC,
algorithm tries patch subcycles solution HC using well-known
Karp-Steele patching method (Karp & Steele, 1985). HC found either, DAP
patching steps iterated, difference another DAP solution might
found. cases considered study, algorithm find HC
determine solution exists two steps. algorithm fails solve
problem iterative steps, attempts enumerate DAP solutions
formulating DAP Boolean satisfiability problem repeatedly solving problem
using SAT solver adding constraints eliminate DAP solutions
encountered. discuss details steps rest section.
2.1 Solving Assignment Problem
Given n vertices matrix C = (cij )1i,jn Rn,n costs pairs
vertices, nAssignment Problemo(AP) find vertex permutation
Pn
= arg min
i=1 ci,(i) : n , n set permutations {1, . . . , n}.
Note AP solution viewed collection cycles visiting vertex exactly
once.
Many algorithms developed AP (Bertsekas, 1981; Goldberg & Kennedy,
1995; Jonker & Volgenant, 1987). (For experimental comparison AP algorithms see
DellAmico & Toth, 2000.) efficient one Hungarian algorithm, based
Konig-Egervarys theorem complexity O(n3 ). AP-SAT algorithm
use implementation Hungarian algorithm Jonker Volgenant (1987, 2004).
665

fiJager & Zhang

unweighted directed graph G = (V, E), DAP solved applying AP
algorithm AP instance defined matrix C = (cij )1i,jn

cij


0,
1,
=

1,

(i, j) E, 6= j
(i, j)
/ E, =
6 j
= j

map costs arcs G 0 costs remaining arcs 1.
AP algorithm returns solution cost 0, DAP solution G, since every arc
taken AP solution arc G. hand, returns solution cost
greater 0, DAP solution G least one arc solution
belong G.
first step AP-SAT algorithm DAP algorithm. HC G, one
exists, solution DAP. distinguish three cases end first
step:
cost AP solution greater 0, G HC, DHCP
instance solved solution.
AP solution cost 0 solution consists one cycle, found
HC DHCP instance also solved.
AP solution cost 0 AP solution one cycle, cannot
determine, based AP solution, whether G Hamiltonian.
continue next steps AP-SAT algorithm.
2.2 Karp-Steele Patching
DAP solution provide definitive answer problem, i.e., case
AP solution cost 0 AP solution contains one cycle, continue
search HC G. first patch subcycles attempt form HC, use
Karp-Steele patching (KSP) purpose, effective ATSP heuristic (Glover,
Gutin, Yeo & Zverovich, 2001; Goldengorin, Jager & Molitor, 2006; Karp & Steele, 1985).
operation patching two cycles C1 C2 AP solution defined follows:
two fixed arcs (v1 , w1 ) C1 (v2 , w2 ) C2 first deleted two arcs (v1 , w2 )
(v2 , w1 ) joining two cycles added. cost patching C1 C2 using (v1 , w2 )
(v2 , w1 ) equal
(C1 , C2 ) = c(v1 , w2 ) + c(v2 , w1 ) (c(v1 , w1 ) + c(v2 , w2 ))
i.e., (C1 , C2 ) difference total cost inserted arcs total cost
deleted arcs. step choose patch two cycles largest
number vertices. two cycles, two arcs chosen way
patching cost minimum among possible arc pairs. k 2 cycles,
repeat patching step k 1 times form one cycle end. apply KSP
AP instance defined Section 2.1. patching procedure provides HC, AP-SAT
algorithm terminated. Otherwise, continue next step.
666

fiAlgorithm Directed Hamiltonian Cyce Problem

2.3 Solving Variant APs
DAP may multiple solutions, DAP solutions may HCs.
increase chance finding HC apply AP step multiple times, since
computational cost AP KSP algorithms low. key avoid finding
DAP solution again. accomplish this, slightly alter arc costs
corresponding AP instance find DAP solutions, enhanced KSP
needed, increase possibility finding HC. words, add perturbation
component create multiple variant AP instances boost overall chance finding
HC. Note worst case DHCP instance contains HC, procedure
productive.
main idea create variant AP instance reduce chance subcycles
current AP solution chosen subsequent rounds solving APs.
done perturbing costs arcs G follows. arc
current DAP solution increase cost one. create AP instance different
Section 2.1, generalize AP instance follows. Let ci,j cost arc
(i, j) E, let


:= n max {ci,j | (i, j) E} + 1

i.e., greater n times largest cost arc G. set costs
edges E . AP instance Section 2.1 special case AP instance,
costs ci,j arcs (i, j) E 0. critical notice DAP solutions,
including HC, must costs less . before, solution contains HC,
algorithm terminates; otherwise, subcycles patched using KSP possibly
find HC. repeat step multiple times arc, appeared many
previous DAP solutions, unlikely appear next DAP solution,
arc, never occurred previous DAP solution, likely appear
next DAP solution.
Let r maximal number AP/KSP calls, i.e., number variant AP instances
solved. observed experiments r = n (see step 3 pseudo code
appendix) good choice. discussed detail Section 3.1.
2.4 Implicitly Enumerating DAP Solutions Using SAT
AP patching based steps discussed may still miss solution DHCP
instance. consider implicitly enumerate DAP solutions finding
solution DHCP, exists. idea systematically rule DAP
solutions discovered far search. end, first formulate
DAP Boolean satisfiability (SAT) problem (Dechter, 2003) forbid DAP solution
adding new constraints SAT model. elementary technique adding new
constraints purpose enumerating SAT solutions also applied
general SAT problem (e.g., see Jin, Han & Somenzi, 2005). Notice cannot
easily done AP framework constraints cannot properly added
AP. Moreover, take advantage research effort devoted
SAT, particular, use effective SAT solver called MiniSat (Een & Sorensson,
2003, 2010).
667

fiJager & Zhang

conjunctive normal form (CNF), SAT instance set Boolean variables
conjunction clauses, disjunction literals Boolean
variables negations. clause satisfied one literals True,
instance satisfied clauses satisfied. SAT problem find truth
assignment variables satisfy clauses satisfiable, determine
assignment exists. SAT first problem shown N P-complete (Cook, 1971;
Garey & Johnson, 1979; Karp, 1972).
formulate DAP SAT. solution DAP must obey following
restrictions:
vertex i, = 1, . . . , n, exactly one arc (i, j), 6= j, exists DAP solution.
vertex i, = 1, . . . , n, exactly one arc (j, i), j 6= i, exists DAP solution.
first introduce integer decision variable xi,j arc (i, j) E xi,j = 1 holds
arc (i, j) appears DAP solution. represent constraints
following integer linear program (ILP).
( Pn
xi,j = 1 = 1, . . . , n
Pj=1,(i,j)E
(1)
n
i=1,(i,j)E xi,j = 1 j = 1, . . . , n
xi,j {0, 1} (i, j) E. thus total 2n constraints. Note
use variables, one variable arc graph, substantially
smaller n2 variables sparse graphs. represent integer linear program (1)
SAT model similar work Lynce Marques-Silva (2006), replace
integer variables xi,j Boolean variables yi,j . enforce 2n restrictions SAT
formulation, need introduce constraints clauses. One restriction (1) means
exactly one n involved Boolean variables vertex set True
rest must False. represent this, introduce 2n2 auxiliary variables
z1 , z2 , . . . , z2n2 , n zs one restriction. Without loss generality, consider
first restriction, z1 , z2 , . . . , zn associated. use zk represent least one
y1,1 , y1,2 , . . . , y1,k True. Precisely, z variables defined follows.
z1 = y1,1 equivalently (y1,1 z1 ) (y1,1 z1 ).
zk = y1,k zk1 equivalently (zk y1,k ) (zk zk1 ) (zk y1,k zk1 )
k = 2, 3, . . . , n.
addition, need enforce one y1,i = 1, 2, . . . , n True.
means y1,k True, none y1,i < k True. formulated

zk1 y1,k k = 2, 3, . . . , n.
Finally, zn must True. restrictions (1) represented similarly.
SAT based representation allows us exclude non-Hamiltonian DAP solution
previously found search. done introducing new clauses explicitly
668

fiAlgorithm Directed Hamiltonian Cyce Problem

forbidding subcycles solution. Let subcycle (v1 , v2 , . . . , vk , v1 ).
add clause
yv1 ,v2 . . . yvk1 ,vk yvk ,v1
current SAT instance. result, updated SAT instance satisfiable,
meaning corresponding DHCP instance contain HC, gives rise
new DAP solution, allow previous DAP solution.
summary, AP- patching-related steps failed find solution, APSAT algorithm transforms problem instance SAT instance. collects
previous DAP solutions, includes least two subcycles, excludes
subcycles DAP solutions adding new clauses described above.
resulting SAT model solved. SAT model satisfiable, DHCP
algorithm terminates result problem instance Hamiltonian.
SAT model satisfiable solution one cycle, algorithm stops HC.
SAT model satisfiable, solution one subcycle, new clauses
introduced SAT model rule solution, algorithm repeats
solve revised formula. Since finite number DAP solutions, algorithm
terminates. worst case DAP solutions contain HC, SAT part
algorithm enumerate DAP solutions. overview, outline main
steps AP-SAT algorithm pseudo code appendix.
2.5 General Remarks
present experimental results, like comment method proposed
help appreciate features.
1. AP-SAT algorithm consists three main components, namely AP step,
KSP step SAT step. might interesting know components important one. this, distinguish completeness
efficacy algorithm. necessary step completeness SAT
step Section 2.4. step without previous steps leads also correct DHCP
algorithm. hand, AP-SAT algorithm effective AP
KSP steps called often SAT step called called
times. example, instance DAP solution exists existing HC
found previous steps, SAT part invoked all. Indeed,
experiments showed SAT step invoked test instances.
Regarding relative time needed AP KSP steps, consider density problem instances. instance small number arcs,
cases HC solution, also DAP solution.
case algorithm terminates first AP step need make
KSP call. hand, instance large number arcs require
many AP steps, many DAP solutions may exist HCs, thus HC
solution may found KSP. expected behavior could validated
experiments: time KSP steps smaller instances small number
arcs, larger instances large number arcs (see Figure 4).
669

fiJager & Zhang

2. AP-SAT algorithm also able solve HCP special case DHCP,
less effective case. reason symmetric case, arc
reverse arc often present DAP solution, resulting many small cycles two
vertices solution. Thus general enumerate large number DAP
solutions. worst case HC exists, DAP solutions
enumerated, giving rise long running time.
3. easily revise AP-SAT algorithm identify HCs directed graph.
Finding solutions desirable many applications, e.g., problem finding knights tour chessboard (Henderson & Apodaca, 2008; Kyek, Parberry &
Wegener, 1997). algorithms problem, see already mentioned algorithm
Martello (1983) algorithm Frieze Suen (1992). revision works
follows. HC exists, algorithm remains same. Consider case
least one HC exists. first HC found, original AP-SAT algorithm
terminates case. revised algorithm stage saves first HC,
continues search next HC. pseudo code appendix,
need replace STOP SAVE rows 8, 11, 23. Note
revised algorithm, SAT part always invoked least one HC exists.
Furthermore like original AP-SAT algorithm revised algorithm works also
symmetric case, less effective.
4. AP-SAT algorithm used restart scheme, i.e., repeatedly solved series AP
instances, derived modifying costs arcs appeared previous
AP solution. Although restart scheme random restart scheme,
developed constraint problems artificial intelligence (Gomes, Selman & Kautz,
1998), follow design principle trying avoid encounter
solutions subsequent runs, two schemes fundamentally different.
name indicated, random restart scheme depends random choices made
variable value selections process search variable assignment
constraint problem. contrast, restart scheme random; arcs
current AP solution receive higher costs subcycles current AP
solution less likely chosen again. words, restart scheme used
somewhat deterministic depends solution structures problem.
5. method used exclude subcycles solution current DAP instance subsequent SAT solving process follows principle popular idea
adding no-good constraints constraint satisfaction problem (Frost & Dechter,
1994; Richards & Richards, 2000; Zhang, Madigan, Moskewicz & Malik, 2001). Specifically, subcycles forbidden introducing additional constraints.

3. Experimental Results
implemented AP-SAT algorithm, DHCP algorithm Martello (1983),
DHCP algorithms based absolute SAT encoding (Hoos, 1999) relative
SAT encoding (Prestwich, 2003) C++ compared algorithm based
award-winning Concorde TSP program (Applegate et al., 2005, 2006). al670

fiAlgorithm Directed Hamiltonian Cyce Problem

gorithm Martello implemented version terminates whenever HC,
one exists, found. SAT based algorithms used AP solver Jonker
Volgenant (1987, 2004) MiniSat SAT solver Een Sorensson (2003, 2010).
apply Concorde, DHCP instance first transformed asymmetric TSP instance transformation Section 2.1 symmetric TSP instance
2-point reduction method (Jonker & Volgenant, 1983). implementation, 2-point
reduction works follows graph G = (V, E) V = {v1 , v2 , . . . , vn }.
1. Make copy vertices v1 , v2 , . . . , vn , create vertex set V 0 := {v10 , v20 ,
. . . , vn0 }.
2. Define new complete graph G0 vertex set V V 0 (symmetric) cost
function c0 : V V 0 {0; 1; 2}

0 1 = j n
1 1 6= j n, (vi , vj ) E
c0 (vi , vj0 ) :=

2 1 6= j n, (vi , vj )
/E
c0 (vi , vj ) := 2 1 6= j n
c0 (vi0 , vj0 ) := 2 1 6= j n
directed HC exists G TSP tour cost n exists G0 . Note
contrast general version 2-point reduction value required
here. also tried 3-point reduction method, principle similar 2-point
reduction, uses two (instead one) copies vertex set uses cost values
{0; 1}. details 3-point reduction, see work Karp (1972).
experimental results, included here, showed 3-point reduction runs
slower average 2-point reduction. Therefore, rest comparison,
consider 2-point reduction.
2-point reduction, Concorde started worst possible solution value
initial upper bound terminated soon lower bound indicates HC
impossible.
addition comparison, also experimentally analyzed AP-SAT algorithm
including asymptotic behavior, applied study phase transitions DHCP.
experiments carried PC Athlon 1900MP CPU 2 GB
memory.
3.1 Comparison DHCP Algorithms
experiments first tested random asymmetric instances Gn,m parameters
n = 100, 200, 400, 800, 1600 = dcn(log n+log log n)c c = 0.5, 0.6, . . . , 1.90, 2.00.
n c generated 50 random instances measured CPU time
instances. Furthermore, tested real-world random instances Dimacs
challenge (Johnson et al., 2002, 2008) non-random instances (Reinelt, 1991, 2008).
Whereas Tsplib contains 26 single asymmetric TSP instances sizes 17 443,
Dimacs challenge contains 10 asymmetric problem generators called amat, coin, crane,
disk, rect, rtilt, shop, stilt, super, tmat. Using generators generated 24
671

fiJager & Zhang

instances, 10 100 vertices, 10 316 vertices, 3 1000 vertices, 1 3162
vertices, leading 240 instances (for 10 problem generators 24 instances) overall.
transform asymmetric TSP instances back DHCP instances, seems reasonable
keep arcs small weights ignoring ones large weights.
words, generate DHCP instance chose smallest arcs corresponding
asymmetric TSP instance. interesting note difficult problem instances
problems Tsplib Dimacs appear degree parameter c around
2, value used experiments. contrast, difficult instances
random graphs occur degree parameter c 0.9 (see Section 3.3).
investigate variation running time, present one subfigure problem
class, i.e., 5 random classes sizes 100, 200, 400, 800, 1600, 10
Dimacs classes amat, coin, crane, disk, rect, rtilt, shop, stilt, super, tmat. y-axis
gives average times plus 95% confidence intervals, values seconds.
random classes x-axis describes degree parameter c, Dimacs
classes describes size n. results random instances summarized
Figure 1 Dimacs instances Figures 2, 3. Tsplib class consists
26 single instances completely different sizes, structures difficulties, present
results Table 1. experiment single algorithm single instance required
least 1 hour terminate due high memory requirement, set CPU
times 3600 seconds.

Figures 1 3 Table 1 show two SAT encodings competitive
AP-SAT, Concorde Martello algorithm. Furthermore, AP-SAT Concorde
stable Martello algorithm. Concorde failed solve 16 Dimacs instances
(3 coin, 3 crane, 4 rect, 5 stilt, 1 super types) within maximal allowed time 1 hour,
whereas AP-SAT algorithm failed 7 instances. Among 7 instances
AP-SAT failed, 6 stilt types, remaining instance (super3162) could
solved increased maximal allowed time 1 hour 4 hours (see Table 2).
Martello algorithm unable solve instances 800 larger size
high memory requirement. instances, failed 1 random instance size
400 degree parameter 0.9, 51 Dimacs instances (10 coin, 12 crane, 11 disk, 11 rect,
7 stilt types), 9 Tsplib instances (see Table 1). Nevertheless, Martello algorithm
outperformed Concorde smaller easier instances, indicating former
worse asymptotic running time. Overall, observed AP-SAT algorithm
clearly superior four algorithms. Among 4266 instances (4000 random
instances, 240 Dimacs instances 26 Tsplib instances) tested, 13 instances,
one four algorithms faster AP-SAT. problem instances include 4
random instances, namely 1 size 400 degree parameter 0.9, 3 size 800 degree
parameters 0.8, 0.9, 0.9, respectively, 8 Dimacs instances, namely coin1000-2, rect316-9,
stilt100-1, stilt100-5, stilt100-6, stilt100-7, stilt100-8, stilt316-2, Tsplib instance
br17 (see Table 1).
672

fiAlgorithm Directed Hamiltonian Cyce Problem

Figure 1: Comparison algorithms random instances.
Size 200
APSAT
Concorde
Martello
Abs. Encoding
Rel. Encoding
10,000
1,000
100
10
1
0.1

APSAT
Concorde
Martello

10,000

Average running time

Average running time

Size 100

1,000
100
10
1
0.1
0.01

0.01
0.001

0.001
0.0001

0.0001

0.5 0.6 0.7 0.8 0.9 1 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2

0.5 0.6 0.7 0.8 0.9 1 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2

Degree parameter c

Degree parameter c

Size 400

Size 800
APSAT
Concorde
Martello

100
10
1
0.1
0.01

APSAT
Concorde

10,000

Average running time

1,000

1,000
100
10
1
0.1
0.01

0.001

0.001

0.0001

0.0001

0.5 0.6 0.7 0.8 0.9 1 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2

0.5 0.6 0.7 0.8 0.9 1 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2

Degree parameter c

Degree parameter c
Size 1600
APSAT
Concorde

10,000

Average running time

Average running time

10,000

1,000
100
10
1
0.1
0.01
0.001
0.0001

0.5 0.6 0.7 0.8 0.9 1 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2

Degree parameter c

673

fiJager & Zhang

Figure 2: Comparison algorithms Dimacs instances, part 1.
coin instances
APSAT
Concorde
Martello
Abs. Encoding
Rel. Encoding
10,000
1,000
100
10
1
0.1

Average running time

Average running time

amat instances

APSAT
Concorde
Martello
Abs. Encoding
Rel. Encoding
10,000
1,000
100
10
1
0.1

0.01

0.01

0.001

0.001

0.0001

100

316

1000

0.0001

3162

100

316

Size

10,000
1,000
100
10
1
0.1

APSAT
Concorde
Martello
Abs. Encoding
Rel. Encoding
10,000
1,000
100
10
1
0.1

0.01

0.01

0.001

0.001
100

316

1000

0.0001

3162

100

316

Size

1,000
100
10
1
0.1

Average running time

Average running time

10,000

APSAT
Concorde
Martello
Abs. Encoding
Rel. Encoding
10,000
1,000
100
10
1
0.1

0.01

0.01

0.001

0.001
316

3162

rtilt instances
APSAT
Concorde
Martello
Abs. Encoding
Rel. Encoding

100

1000

Size

rect instances

0.0001

3162

disk instances
APSAT
Concorde
Martello
Abs. Encoding
Rel. Encoding

Average running time

Average running time

crane instances

0.0001

1000

Size

1000

0.0001

3162

Size

100

316

1000

Size

674

3162

fiAlgorithm Directed Hamiltonian Cyce Problem

Figure 3: Comparison algorithms Dimacs instances, part 2.
stilt instances
APSAT
Concorde
Martello
Abs. Encoding
Rel. Encoding
10,000
1,000
100
10
1
0.1

Average running time

Average running time

shop instances

APSAT
Concorde
Martello
Abs. Encoding
Rel. Encoding
10,000
1,000
100
10
1
0.1

0.01

0.01

0.001

0.001

0.0001

100

316

1000

0.0001

3162

100

316

Size

10,000
1,000
100
10
1
0.1

APSAT
Concorde
Martello
Abs. Encoding
Rel. Encoding
10,000
1,000
100
10
1
0.1

0.01

0.01

0.001

0.001
100

316

3162

tmat instances
APSAT
Concorde
Martello
Abs. Encoding
Rel. Encoding

Average running time

Average running time

super instances

0.0001

1000

Size

1000

0.0001

3162

Size

100

316

1000

Size

675

3162

fiJager & Zhang

Table 1: Comparison algorithms Tsplib instances.
Instance (Size)

AP-SAT

Concorde

br17 (17)
ftv33 (34)
ftv35 (36)
ftv38 (39)
p43 (43)
ftv44 (45)
ftv47 (48)
ry48p (48)
ft53 (53)
ftv55 (56)
ftv64 (65)
ft70 (70)
ftv70 (71)
kro124p (100)
ftv100 (101)
ftv110 (111)
ftv120 (121)
ftv130 (131)
ftv140 (141)
ftv150 (151)
ftv160 (161)
ftv170 (171)
rbg323 (323)
rbg358 (358)
rbg403 (403)
rbg443 (443)

4.05
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0.01
0.02
0.02
0.02

0.07
0.13
0.15
0.23
0.42
0.19
0.16
0.07
1.56
0.09
0.23
0.87
0.29
3.74
0.56
2.42
0.8
3.04
0.84
1.13
1.14
2.13
4.81
13.55
4.52
6.73

Running time algorithm
Martello Absolute Encoding
66.39
0
0
0
0
0
0
3600
0
0.01
0
0
0
0.04
3600
3600
3600
3600
3600
3600
3600
3600
0.09
0.14
0.18
0.21

676

0.85
3.29
5.59
2.96
65.58
1.97
5.23
53.96
20.31
11.13
119.96
34.18
1904.56
1993.33
1024.22
3600
3600
3600
593.65
2676.16
3600
3600
3600
3600
3600
3600

Relative Encoding
0.08
0
0
0.01
0.01
0.01
0.01
47.91
0.02
230.04
0.04
0.05
0.06
3600
3600
3600
3600
3600
3600
3600
3600
3600
5.12
6.98
10
13.24

fiAlgorithm Directed Hamiltonian Cyce Problem

3.2 Analysis AP-SAT
efficacy AP-SAT algorithm may due following reasons. Instances
HC likely DAP solution either, therefore algorithm
terminates first AP call. hand, instances HC likely
multiple HCs, one found quickly AP KSP steps.
difficult case many DAP solutions, none
HCs. case AP KSP steps may fail, SAT part invoked find
HC disprove existence HC.
following analyze instances AP-SAT fails requires much
time, analyze number r computing variant AP instances (which set
size instance n; see end Section 2.3). Therefore investigated three
procedures AP-SAT, namely AP, KSP SAT. observed SAT part
invoked 14 4266 instances tested. considered 14 two
instances (stilt3162 super3162), AP-SAT terminate 1 hour,
hard. analyze 16 hard instances increased maximal allowed time
1 hour 4 hours. Table 2 present running times AP, KSP SAT,
number calls three procedures, numbers AP KSP calls
given column, two numbers equal different one (see
pseudo code appendix). Furthermore, add two additional pieces information:
whether instance HC whether unknown, whether AP-SAT terminated
instance 4 hours. Table 2, Memory means part terminated due
high memory requirement. Note solution status instance stilt316-2 (no
HC) known, since Concorde contrast AP-SAT able solve it.
Table 2 shows running time AP/KSP contributed majority
total running time AP-SAT 4 16 hard instances, i.e., coin1000-2
rect316-9, two instances stilt3162 super3162 SAT invoked
all. 6 instances, AP-SAT terminate. 5 6 instances, i.e., stilt3162, stilt316-4, stilt316-5, stilt1000-1, stilt1000-2, SAT part terminate
reasonable amount time algorithm stopped due high memory requirement
SAT.
order determine r, re-ran instances Table 2 three different values
r, i.e., r = 0, r = n/2, r = 2n. results (not presented) showed AP-SAT
unable terminate r = n (i.e., 6 instances stilt316-2, stilt316-4, stilt316-5,
stilt1000-1, stilt1000-2, stilt3162), also failed stop values r.
remaining 10 instances, increasing r = n r = 2n reduce running times.
reasonable two instances coin1000-2 rect316-9 large AP/KSP time,
HC. hand, two instances ones
AP-SAT ran faster using smaller values r, namely coin1000-2 using r = n/2
rect316-9 using r = 0.
thus conclude r increased, rather decreased. hard
estimate memory requirements time SAT part, one alternative
difficult instances would start AP-SAT smaller parameter r stop
SAT part time one unsuccessful call. complete APSAT algorithm restarted larger r. instances, however, choice
677

fiJager & Zhang

Table 2: Comparison performance AP, KSP, SAT procedures AP-SAT
algorithm 16 hard instances.
Instance
br17
coin1000-2
rect100-2
rect316-9
stilt100-1
stilt100-5
stilt100-6
stilt100-7
stilt100-8
stilt316-2
stilt316-4
stilt316-5
stilt1000-1
stilt1000-2
stilt3162
super3162

Running time
AP
KSP
SAT
0
0
4.1
352.73
47.54
1.82
0.07
0.01
0.27
3.69
0.61
0.35
0.17
0
0.07
0.2
0.01
28.84
0.17
0.02
0.07
0.17
0.05
0.06
0.15
0.03
0.07
20.21
1.37 14378.42
13.15
0.71
Memory
21.14
1.63
Memory
1446.63 107.06 12846.31
1457.76 102.21 12840.03
13832.40
567.60
0
13244.88
441.46
0

Number calls
AK/KSP SAT
17
138
1000
1
100
1
316
1
100
1
100
41
100
1
100
1
100
1
316
1
316
1
316
1
1000
1
1000
1
650
0
1032
0

HC

Termin.






Yes




Unknown
Unknown
Unknown
Unknown
Unknown
Yes

Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes






Yes

Figure 4: Comparison performance AP KSP procedures AP-SAT random
instances size 1600.
AP
KSP

6

Average running time

5.5
5
4.5
4
3.5
3
2.5
2
1.5
1
0.5
0
0.5 0.6 0.7 0.8 0.9 1 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2

Degree parameter c

r relevant. difficult problem instances required perform comprehensive
analysis r.
Finally, Figure 4 compare times used AP KSP random instances
size 1600 degree parameter c = 0.5, 0.6, . . . , 1.90, 2.00.
observe AP time consuming KSP. smaller c effect
obvious instances solved result HC first
AP call, thus KSP need invoked all.
678

fiAlgorithm Directed Hamiltonian Cyce Problem

3.3 Phase Transitions DHCP
random undirected graphs Gn,m , arcs randomly chosen possible
n(n 1)/2 arcs n vertices graph, Komlos Szemeredi (1983) proved phase
transition c dn (log n + log log n)/2c c = 1 HCP. Vandegriend Culberson (1998) experimentally verified theoretical result, constant c 1.08
1.10. DHCP, arcs randomly chosen possible n(n 1) arcs,
McDiarmid proved phase transition = cdn(log n+log log n)c c = 1 (1980).
experiments aimed verify result determine multiplicative constant c.
directed graph may contain twice many arcs undirected counterpart, would
expect number arcs doubled well phase transition point. Therefore
tested = dc n (log n + log log n)c c = 0.5, 0.6, 0.7, 0.8, 0.81, 0.82, . . . , 1.19, 1.20,
1.30, 1.40, 1.50, 1.60, 1.70, 1.80, 1.90, 2.00, expected phase transition occur
c = 1. considered problem instances n = 128, 256, 512, 1024, 2048, 4096, 8192
vertices chose 1000 independently generated random graphs n c.
phase transition result shown Table 3 Figure 5, first parameter
c second parameter percentage Hamiltonian graphs among graphs
considered. observe phase transition DHCP similar HCP.
particular, evident Figure 5 phase transition becomes sharper, i.e.,
crossover among phase transition curves, problem size increases,
characteristic phase transitions complex systems. crossover occurs around
degree parameter c = 0.9, substantially different expected value
1. short, observations verified existence phase transition DHCP,
phase transition occurs dc n (log n + log log n)c approximately c = 0.9.
Furthermore, constant c = 0.9, probability Gn,m Hamiltonian
1/2. comparison, undirected graphs, constant 1.08 1.10
found (Vandegriend & Culberson, 1998).

3.4 Asymptotic Behavior AP-SAT
interesting characteristic algorithm asymptotic behavior. quantify
behavior AP-SAT algorithm, revisited experiments Section 3.3, i.e.,
experiments verified phase transitions DHCP. described earlier, considered random problem instances n = 128, 256, 512, 1024, 2048, 4096, 8192 vertices
chose 1000 independently generated random graphs n c.
measure worst-case asymptotic behavior AP-SAT, measured CPU times
algorithm difficult instances, i.e., instances degree parameter
c = 0.9 (see Section 3.3). results found Figure 6, x-axis
problem size y-axis average time required. Since both, x- y-axis
logarithmic scale log-log curve Figure 6 nearly linear, average running
time AP-SAT considered polynomial number n vertices
graph. reasonable, random instances SAT part called (see
Section 3.2), AP KSP combined complexity worse O(n3 ).
679

fiJager & Zhang

Table 3: Phase transition random instances.
c
0.5
0.6
0.7
0.8
0.81
0.82
0.83
0.84
0.85
0.86
0.87
0.88
0.89
0.9
0.91
0.92
0.93
0.94
0.95
0.96
0.97
0.98
0.99
1
1.01
1.02
1.03
1.04
1.05
1.06
1.07
1.08
1.09
1.1
1.11
1.12
1.13
1.14
1.15
1.16
1.17
1.18
1.19
1.2
1.3
1.4
1.5
1.6
1.7
1.8
1.9
2

128
0
0
5.1
23.3
25.5
27.8
30.6
32.4
33.6
37.6
39.8
44
46.8
49
52.8
55.5
59.2
60.1
62.7
63.6
67.2
68.8
69.4
71
72.8
74.2
75.8
76.9
77.4
78.4
81.7
81.6
83.3
85.1
85.4
86.3
86.6
86.7
87.3
88.5
88.7
87.8
88.5
89.1
95.7
96.4
99.1
99.7
99.7
99.8
100
100

256
0
0
3
21.9
24.2
28.4
28.9
31.8
34.1
36.5
39.1
43.5
47.3
52
53.2
54.4
58.4
60.1
61.7
65.3
65
67.9
71.8
74
74.3
75.4
75.4
76.6
78.6
79.3
79.2
82.4
83.2
84.4
87
87.4
88.6
88.9
89.2
89.2
91.2
92.6
92.9
93.8
97.2
98.8
99.1
99.6
99.8
99.8
100
100

512
0
0
2.6
21.5
23.9
27.4
33
34.9
35.6
36.9
38.3
42.4
47.3
49.8
52.3
56.9
59.5
61.5
60.8
64
66.2
68.3
72.1
72.1
74.5
76.3
79
82.1
84.4
86
87.3
88.4
88.6
88.8
89.3
89.7
90.1
90.7
90.9
92.6
93.1
93.6
93
93.3
97.5
99
99.9
99.8
100
99.9
99.9
100

Size
1024
0
0
1.3
18.7
20.6
23.1
25.8
32.9
30
35.4
40.8
43.8
45.8
52.5
54.7
54.1
60.8
63.6
64.9
66.2
67.9
71.2
73.8
73.6
78.3
81.1
81.9
83.2
85.2
85.9
88.1
87.1
87.2
86.8
90.9
90.3
89.5
92.2
93.2
93.9
94.1
95 0
95.5
96.2
98.8
99.5
99.9
99.9
100
99.9
99.9
100
680

2048
0
0
0.5
16.3
20.8
25
27
28.5
34.3
37.4
41
44.7
47.9
50.1
50.3
54.7
58.4
61.4
68.4
66.8
71.6
72.5
75
77.2
80.8
81.4
81
84.2
86.3
85.6
89.9
89.4
89.4
89.5
92
92.9
93
93.9
93.8
95.1
95.3
96.1
94.8
96.2
98.9
99.7
99.8
99.9
99.9
100
100
100

4096
0
0
0.1
14.1
17.9
20
23.3
29
33.4
34.7
35.9
40.2
47.7
48.6
52.7
59.4
60.7
65.6
68.3
72.7
71
75.7
77
79.8
78.7
82.4
83.4
85.3
88.3
85.9
90
90.3
92.6
92
93.8
93.3
93.9
94.1
94.2
95.5
94.7
95.8
97.3
97.6
98.7
99.5
99.9
100
99.9
100
100
100

8192
0
0
0.2
12.7
15.7
18.7
23.9
28.9
30
34.1
38.7
40.6
44.8
50.5
54.6
59.8
61.5
65.8
70.5
73.1
71.4
73.4
76.3
80
81.7
81.9
85.4
86.5
88.3
90.7
92.3
92
92.4
93.8
93.9
94
94.7
97.3
96.4
97.2
97.2
96.4
97.2
97.9
99.2
99.8
100
100
99.9
100
100
100

fiAlgorithm Directed Hamiltonian Cyce Problem

Figure 5: Phase transition random instances.
100
Size 128
Size 256
Size 512
Size 1024
Size 2048
Size 4096
Size 8192

Existence HCs %

80

60

40

20

0
0.4

0.6

0.8

1

1.2

1.4

Degree parameter c

681

1.6

1.8

2

fiJager & Zhang

Figure 6: Asymptotic behavior AP-SAT algorithm.
10,000
APSAT

Average running time

1,000
100
10
1
0.1
0.01
0.001
0.0001

128

256

512

1024

2048

4096

8192

Size

4. Summary
Hamiltonian cycle problem (HCP) important, canonical combinatorial problem.
Surprisingly, HCP directed graphs, called directed HCP DHCP,
effective exact algorithm developed. main result work novel
effective exact algorithm DHCP. algorithm utilizes existing algorithm
assignment problem existing method Boolean satisfiability (SAT). work
includes new SAT formulation HCP AP, potentially extended
problems TSP. experimental results random real problem
instances showed new algorithm superior four known algorithms including
one algorithm takes advantage award-winning Concorde TSP algorithm. Furthermore, first phase transition result combinatorial problems done HCP
later extended DHCP. paper experimentally verified existence
phase transition DHCP refined location phase transition
appears using new exact DHCP algorithm.

Acknowledgments
thank David S. Johnson AT&T Labs - Research Gregory Gutin Royal Holloway
University London many discussions related work insightful comments
manuscript. research supported part NSF grants IIS-0535257
DBI-0743797 Weixiong Zhang.

682

fiAlgorithm Directed Hamiltonian Cyce Problem

Appendix A. Pseudo Code AP-SAT Algorithm
INPUT Directed non-complete graph G = (V, E) |V | = n.
1 Define matrix C Section 2.1, := 1.
2 Define subcycle collection set W := .
3 = 1, . . . , n
4
Solve AP instance matrix C solution value g, AP solution
(v1 , vi1 ), (v2 , vi2 ) . . . , (vn1 , vin1 ), (vn , vin ), number cycles k.
5
g
6
STOP HC.
7
ELSE k = 1
8
STOP HC AP solution.
9
Apply KSP cycles, receive solution value h complete
cycle (w1 , w2 , . . . , wn , w1 ).
10
h = 0
11
STOP HC (w1 , w2 , . . . , wn , w1 ).
12
= 1, . . . , n
13
cvt ,vit = cvt ,vit + 1
14
= n max {ci,j | (i, j) E} + 1.
15
ci,j = (i, j)
/ E.
16
Add subcycle AP solution W .
17 Start SAT model explained Section 2.4.
18 subcycle (v1 , v2 , . . . , vk1 , vk , v1 ) W add clause
yv1 ,v2 . . . yvk1 ,vk yvk ,v1 SAT model.
19 Solve SAT model.
20 Variable setting exists model.
21
Add k subcycles solution SAT model W .
22
k = 1
23
STOP HC
subcycle.
24
GOTO 19.
25
ELSE STOP HC.
OUTPUT HC G, proof HC exists G.

References
Angluin, D. & Valiant, L.G. (1979). Fast Probabilistic Algorithms Hamiltonian Circuits
Matchings. J. Comput. System. Sci. 18(2), 155-193.
683

fiJager & Zhang

Applegate, D.L., Bixby, R.E., Chvatal, V. & Cook, W.J. (2005). Concorde Code:
http://www.tsp.gatech.edu/concorde.html
Applegate, D.L., Bixby, R.E., Chvatal, V. & Cook, W.J. (2006). Traveling Salesman
Problem. Computational Study. Princeton University Press.
Applegate, D.L., Bixby, R.E., Chvatal, V., Cook, W.J., Espinoza, D., Goycoolea, M.
& Helsgaun, K. (2009): Certification Optimal Tour 85,900 Cities.
Oper. Res. Lett. 37(1), 11-15.
Bang-Jensen, J. & Gutin, G. (2008). Chapter 5 in: Digraphs: Theory, Algorithms Applications. Springer, London. Free available:
http://www.cs.rhul.ac.uk/books/dbook/
Bertsekas, D.P. (1981). New Algorithm Assignment Problem. Math. Program. 21,
152-171.
Bollobas, B. (1985). Random Graphs. Academic Press, London.
Bollobas, B., Fenner, T.I. & Frieze, A.M. (1987). Algorithm Finding Hamiltonian
Paths Cycles Random Graphs. Combinatorica 7(4), 327-341.
Bondy, J.A. (1995). Basic Graph Theory: Paths Circuits. Graham, R.L., Grotschel,
M., Lovasz, L. (Eds.): Handbook Combinatorics (3-110). North-Holland, Amsterdam.
Cheeseman, P., Kanefsky, B. & Taylor, W.M. (1991). Really Hard Problems
Are. Mylopoulos, J., Reiter, R. (Eds.): Proc. 12th International Conference
Joint Artificial Intelligence (IJCAI), 331-337. Morgan Kaufmann.
Christofides, N. (1975). Graph Theory Algorithmic Approach. Academic Press, New
York.
Chvatal, V. (1985). Hamiltonian Cycles. Chapter 11 Lawler, E.L., Lenstra, J.K., Rinnooy
Kan, A.H.G., Shmoys, D.B. (Eds.): Traveling Salesman Problem. Guided Tour
Combinatorial Optimization. John Wiley & Sons, Chichester.
Cook, S.A. (1971). Complexity Theorem-Proving Procedures. Proc. 3rd Ann. ACM
Symp. Theory Computing (STOC), 151-158.
Cook, W.J. (2010). TSP Homepage:
http://www.tsp.gatech.edu/
Dechter, R. (2003). Constraint Processing. Morgan Kaufmann.
DellAmico, M. & Toth, P. (2000). Algorithms Codes Dense Assignment Problems:
State Art. Discrete Appl. Math. 100(1-2), 17-48.
Een, N. & Sorensson, N. (2003). Extensible SAT-Solver. Giunchiglia, E., Tacchella, A.
(Eds.): Proc. 6th International Conference Theory Applications Satisfiability
Testing (SAT). Lecture Notes Comput. Sci. 2919, 502-518.
Een, N. & Sorensson, N. (2010). MiniSat Code:
http://minisat.se
684

fiAlgorithm Directed Hamiltonian Cyce Problem

Frank, J., Gent, I. & Walsh, T. (1998). Asymptotic Finite Size Parameters Phase
Transitions: Hamiltonian Circuit Case Study. Inform. Process. Lett. 65(5), 241245.
Frieze, A.M. (1988a). Finding Hamiltonian Cycles Sparse Random Graphs. J. Combin. Theory Ser. B 44, 230-250.
Frieze, A.M. (1988b). Algorithm Finding Hamilton Cycles Random Directed
Graphs. J. Algorithms 9, 181-204.
Frieze, A.M. & Suen, S. (1992). Counting Hamilton Cycles Random Directed Graphs.
Random Structures Algorithms 9, 235-242.
Frost, D. & Dechter, R. (1994). Dead-End Driven Learning. Proc. 12th National Conference
Artificial Intelligence (AAAI), 294-300. AAAI Press.
Johnson, D.S. (2008). 8th Dimacs Implementation Challenge: Traveling Salesman Problem:
http://www.research.att.com/~dsj/chtsp/
Garey, M.R. & Johnson, D.S. (1979). Computers Intractability. Guide Theory
N P-Completeness. Freeman, New York.
Glover, F., Gutin, G., Yeo, A. & Zverovich, A. (2001). Construction Heuristics
Asymmetric TSP. European J. Oper. Res. 129, 555-568.
Goldberg, A.V. & Kennedy, R. (1995). Efficient Cost Scaling Algorithm Assignment Problem. Math. Program. 71, 153-177.
Goldengorin, B., Jager, G. & Molitor, P. (2006). Tolerance Based Contract-or-Patch Heuristic Asymmetric TSP. Erlebach, T. (Ed.): Proc. 3rd Workshop Combinatorial Algorithmic Aspects Networking (CAAN). Lecture Notes Comput. Sci. 4235, 86-97.
Gomes, C.P., Selman, B. & Kautz, H. (1998). Boosting Combinatorial Search
Randomization. Proc. 15th National Conference Artificial Intelligence (AAAI),
431-437. AAAI Press.
Gould, R.J. (1991). Updating Hamiltonian Problem Survey. J. Graph Theory 15(2),
121-157.
Grebinski, V. & Kucherov, G. (1996). Reconstructing Hamiltonian Circuit Querying
Graph: Application DNA Physical Mapping. IR 96-R-123, Centre de Recherche
en Informatique de Nancy.
Gutin, G. & Moscato, P. (2000). Hamiltonian Page:
http://alife.ccp14.ac.uk/memetic/~moscato/Hamilton.html
Henderson, R. & Apodaca, E. (2008). Knight Egodeth: Zen Raptured Quietude. BookSurge Publishing.
Hoos, H.H. (1999). SAT-Encodings, Search Space Structure, Local Search Performance.
Proc. 16th International Joint Conference Artificial Intelligence (IJCAI), 296-303.
Morgan Kaufmann.
685

fiJager & Zhang

Jin, H., Han, H. & Somenzi, F. (2005). Efficient Conflict Analysis Finding Satisfying
Assignments Boolean Circuit. Halbwachs, N., Zuck, L.D. (Eds.): Proc. 11th
International Conference Tools Algorithms Construction Analysis
Systems (TACAS). Lecture Notes Comput. Sci. 3440, 287-300.
Johnson, D.S., Gutin, G, McGeoch, L.A., Yeo, A., Zhang, W. & Zverovich, A. (2002).
Experimental Analysis Heuristics ATSP. Chapter 10 in: Gutin, G., Punnen,
A.P. (Eds.): Traveling Salesman Problem Variations. Kluwer.
Jonker, R. & Volgenant, A. (1983). Transforming Asymmetric Symmetric Traveling
Salesman Problems. Oper. Res. Lett. 2(4), 161-163.
Jonker, R. & Volgenant, A. (1987). Shortest Augmenting Path Algorithm Dense
Sparse Linear Assignment Problems. Computing 38, 325-340.
Jonker, R. & Volgenant, A. (2004). AP Code:
http://www.magiclogic.com/assignment.html
Kabadi, S.N. & Punnen, A.P. (2002). Bottleneck TSP. Chapter 15 in: Gutin, G., Punnen, A.P. (Eds.): Traveling Salesman Problem Variations. Kluwer.
Karp, R.M. (1972). Reducibility Among Combinatorial Problems. Miller, R.E., Thatcher,
J.W. (Eds.): Complexity Computer Computations, 85-103. New York: Plenum.
Karp, R.M. & Steele, J.M. (1985). Probabilistic Analysis Heuristics. Chapter 6 in: Lawler,
E.L., Lenstra, J.K., Rinnooy Kan, A.H.G., Shmoys, D.B. (Eds.): Traveling Salesman Problem. Guided Tour Combinatorial Optimization. John Wiley & Sons,
Chicester.
Kelly, L. (2007). Hamilton Cycles Directed Graphs. PhD Thesis, University Birmingham, United Kingdom.
Komlos, M. & Szemeredi, E. (1983). Limit Distribution Existence Hamiltonian
Cycle Random Graph. Discrete Math. 43, 55-63.
Kyek, O., Parberry, I. & Wegener, I. (1997). Bounds Number Knights Tours.
Discrete Appl. Math. 74(2), 171-181.
Lynce, I. & Marques-Silva, J. (2006). Efficient Haplotype Inference Boolean Satisfiability. Proc. 21st National Conference Artificial Intelligence (AAAI). AAAI Press.
Martello, S. (1983). Enumerative Algorithm Finding Hamiltonian Circuits Directed Graph. ACM Trans. Math. Software 9(1), 131-138.
McDiarmid, C.J.H. (1980). Cluster Percolation Random Graphs. Math. Program. Stud. 13, 17-25.
Monasson, R., Zecchina, R., Kirkpatrick, S., Selman, B. & Troyansky, L. (1999). Determining Computational Complexity Characteristic Phase Transitions. Nature 400,
133.
Prestwich, S. (2003). SAT Problems Chains Dependent Variables. Discrete
Appl. Math. 130(2), 329-350.
Posa, L. (1976). Hamiltonian Circuits Random Graphs. Discrete Math. 14, 359-364.
686

fiAlgorithm Directed Hamiltonian Cyce Problem

Reinelt, G. (1991). TSPLIB Traveling Salesman Problem Library. ORSA J. Comput. 3,
376-384.
Reinelt, G. (2008). Tsplib Library:
http://www.iwr.uni-heidelberg.de/groups/comopt/software/TSPLIB95/
Richards, E.T. & Richards, B. (2000). Non-Systematic Search No-Good Learning.
J. Automat. Reason. 24(4), 483-533.
Skiena, S. (2008). Stony Brook Algorithm Repository:
http://www.cs.sunysb.edu/~algorith/files/hamiltonian-cycle.shtml
Stojakovic, M. & Szabo, T. (2005). Positional Games Random Graphs. Random Structures Algorithms 26(1-2), 204-223.
Vandegriend, B. (1998). Finding Hamiltonian Cycles: Algorithms, Graphs Performance.
Master Thesis, University Alberta, Canada.
Vandegriend, B. & Culberson, J. (1998). Gn,m Phase Transition Hard
Hamiltonian Cycle Problem. J. Artificial Intelligence Res. 9, 219-245.
Velev, M.N. & Gao, P. (2009). Efficient SAT Techniques Absolute Encoding Permutation Problems: Application Hamiltonian Cycles. Proc. 8th Symposium Abstraction, Reformulation Approximation (SARA), 159-166.
Zhang, W. & Korf, R.E. (1996). Study Complexity Transitions Asymmetric
Traveling Salesman Problem. Artificial Intelligence 81, 223-39.
Zhang, L., Madigan, C.F., Moskewicz, M.H. & Malik, S. (2009). Efficient Conflict Driven
Learning Boolean Satisfiability Solver. Proc. IEEE/ACM International Conference Computer Aided Design (ICCAD), 279-285.

687

fiJournal Artificial Intelligence Research 39 (2010) 429-481

Submitted 02/10; published 10/10

Nominals, Inverses, Counting, Conjunctive Queries
or: Infinity Friend!
Sebastian Rudolph

rudolph@kit.edu

AIFB, Karlsruhe Institute Technology, DE

Birte Glimm

birte.glimm@comlab.ox.ac.uk

Oxford University Computing Laboratory, UK

Abstract
Description Logics knowledge representation formalisms provide, example,
logical underpinning W3C OWL standards. Conjunctive queries, standard
query language databases, recently gained significant attention expressive
formalism querying Description Logic knowledge bases. Several different techniques
deciding conjunctive query entailment available wide range DLs. Nevertheless,
combination nominals, inverse roles, number restrictions OWL 1 OWL 2
DL causes unsolvable problems techniques hitherto available. tackle problem
present decidability result entailment unions conjunctive queries DL
ALCHOIQb contains three problematic constructors simultaneously. Provided
queries contain simple roles, result also shows decidability entailment
(unions of) conjunctive queries logic underpins OWL 1 DL believe
presented results pave way progress towards conjunctive query
entailment decision procedures Description Logics underlying OWL standards.

1. Introduction
present decidability result entailment unions conjunctive queries
expressive Description Logic ALCHOIQb. article extended version conference paper Status QIO: Conjunctive Query Entailment Decidable, Proceedings
12th International Conference Principles Knowledge Representation Reasoning (KR 2010), May 0913, 2010 (Glimm & Rudolph, 2010).
Description Logics (DLs) family logic based knowledge representation formalisms
(Baader, Calvanese, McGuinness, Nardi, & Patel-Schneider, 2003). DLs correspond
function-free two variable fragment First-Order Logic (FOL) often extended
counting quantifiers (e.g., xn y(R(x, y))) DLs also closely related (2variable) guarded fragment since DL formulae naturally result guarded formulae
translated FOL. line restriction 2 variables, DL formulae contain
unary binary predicates, called concepts roles DLs. constructors
building complex expressions usually chosen key inference problems,
concept satisfiability, decidable. DL knowledge base (KB) consists TBox,
contains intensional knowledge concept definitions general background
knowledge (essentially FOL theory), ABox, contains extensional knowledge
used describe individuals (a set ground facts). Using database metaphor,
TBox corresponds schema, ABox corresponds data. contrast
c
2010
AI Access Foundation. rights reserved.

fiRudolph & Glimm

databases, however, DL knowledge bases, FOL general, adopt open world semantics,
i.e., represent information domain incomplete way.
Standard DL reasoning services include testing concepts satisfiability retrieving
certain instances given concept. latter retrieves, knowledge base consisting ABox TBox , (ABox) individuals instances given
(possibly complex) concept expression C, i.e., individuals
entail instance C. underlying reasoning problems well-understood,
computational complexity standard reasoning tasks given knowledge base
input range PTime-complete DLs limited expresivity DL-Lite
(Calvanese, De Giacomo, Lembo, Lenzerini, & Rosati, 2005), EL (Baader, 2003), ELP
(Krotzsch, Rudolph, & Hitzler, 2008) 2-NExpTime-complete expressive DLs
SROIQ (Kazakov, 2008).
Despite high worst case complexity standard reasoning problems
expressive DLs SROIQ, highly optimized implementations available,
e.g., FaCT++ (Tsarkov & Horrocks, 2006), Pellet (Sirin, Parsia, Cuenca Grau, Kalyanpur, & Katz, 2007), HermiT (Motik, Shearer, & Horrocks, 2009). systems
used wide range applications, e.g., biology (Sidhu, Dillon, Chang, & Sidhu,
2005), bio informatics (Wolstencroft, Brass, Horrocks, Lord, Sattler, Turi, & Stevens, 2005),
medicine (Golbreich, Zhang, & Bodenreider, 2006), information integration (Calvanese,
De Giacomo, Lenzerini, Nardi, & Rosati, 1998b), geography (Goodwin, 2005), geology (Jet
Propulsion Laboratory, 2006), defense (Lacy, Aviles, Fraser, Gerber, Mulvehill, & Gaskill,
2005), configuration (McGuinness & Wright, 1998). prominently, DLs known
use logical underpinning ontology languages, e.g., OIL, DAML+OIL,
W3C standard OWL 1 (Bechhofer, van Harmelen, Hendler, Horrocks, McGuinness, PatelSchneider, & Stein, 2004), successor OWL 2 (W3C OWL Working Group, 2009).
three species OWL 1: OWL Lite, OWL DL, OWL Full. OWL 2 extends
OWL 1 adds three sublanguages (called OWL 2 profiles): OWL EL, OWL QL,
OWL RL. OWL Lite corresponds DL SHIF standard reasoning
tasks ExpTime-complete, OWL 1 DL corresponds DL SHOIN ,
standard reasoning tasks NExpTime-complete, OWL 2 DL extends DL
SROIQ. OWL Full standard reasoning tasks longer decidable. new
QL, EL, RL profiles restrictive OWL DL profiles trades
different aspects OWLs expressive power return different computational and/or
implementational benefits. OWL EL corresponds DL EL ++ (Baader, Brandt, &
Lutz, 2005) basic reasoning problems performed time polynomial
respect size input knowledge base. OWL 2 QL based DL-Lite
family Description Logics, data complexity conjunctive query entailment
AC0 . Thus, conjunctive query answering implemented using standard relational
database technology. OWL 2 RL enables implementation polynomial time reasoning
algorithms using rule-extended database technologies.
data-intensive applications, querying KBs plays central role. Instance retrieval
is, aspects, rather weak form querying: although possibly complex concept
expressions used queries, query tree-like relational structures,
DL concept cannot express arbitrary cyclic structures. property known
tree model property considered important reason decidability
430

fiNominals, Inverses, Counting, Conjunctive Queries

Modal Description Logics (Gradel, 2001; Vardi, 1997) also heavily exploit
variant property establish decidability result. Conjunctive queries (CQs)
unions conjunctive queries (UCQs) well known database community
constitute expressive query language capabilities go well beyond standard
instance retrieval. FOL terms, CQs UCQs formulae positive existential
fragment. Free variables query (not bound existential quantifier) also called
answer variables distinguished variables, whereas existentially quantified variables
called non-distinguished.
query contains distinguished variables, query answer true false
query called Boolean query. Given knowledge base K Boolean UCQ
q, query entailment problem deciding whether q true false w.r.t. K, i.e.,
decide whether model K provides suitable assignment variables
q. query distinguished variables, answers query tuples
individual names (constants) knowledge base entails query
obtained replacing free variables individual names answer tuple.
answers also called certain answers. problem finding answer tuples
known query answering. present decidability result query entailment,
decision problem, restriction since query answering easily reduced
query entailment illustrate detail Section 3.
1.1 Related Work
Conjunctive queries first mentioned context Description Logics (DLs)
Levy Rousset (1996). first account conjunctive queries main topic given
Calvanese, De Giacomo, Lenzerini (1998a). particular recent years, problem
decidability conjunctive query entailment complexity problem different
logics gained significant attention. DLs SHIQ SHOQ decidability
2-ExpTime-completeness problem known (Glimm, Horrocks, Lutz, & Sattler,
2008a; Glimm, Horrocks, & Sattler, 2008b; Lutz, 2008; Eiter, Lutz, Ortiz, & Simkus,
2009). Conjunctive query entailment already 2-ExpTime-hard relatively weak
DL ALCI (Lutz, 2008), initially attributed inverse roles. Recently,
shown, however, also transitive roles together role hierarchies DL SH
make conjunctive query entailment 2-ExpTime-hard (Eiter et al., 2009). techniques
Glimm et al. SHIQ SHOQ (Glimm et al., 2008a, 2008b) reduce query entailment
standard reasoning task knowledge base satisfiability checking DL extended
role conjunctions. alternative technique so-called knots technique (Ortiz,
Simkus, & Eiter, 2008b), instance mosaic technique originating Modal
Logic. technique also gives worst-case optimal algorithms SHIQ several
sub-logics. Further, automata-based decision procedures positive existential
path queries (Calvanese, Eiter, & Ortiz, 2007, 2009). Positive existential path queries
generalize unions conjunctive queries and, therefore, decision procedures kind
query also provides decision procedures unions conjunctive queries. particular
recent extension (Calvanese et al., 2009) close conjunctive query entailment
decision procedure OWL 2, corresponds DL SROIQ, covers
431

fiRudolph & Glimm

SRIQ, SROQ, SROI. use three problematic constructors nominals,
inverses, number restrictions is, however, covered.
Regarding data complexity, i.e., complexity respect ABox (the data)
only, CQ entailment usually coNP-complete expressive logics. example, DLs
ALE SHIQ case (Glimm et al., 2008a) holds also CQ
entailment two variable guarded fragment counting (Pratt-Hartmann, 2009).
latter work quite closely related since many Description Logics translated
two variable guarded fragment counting, i.e., results Pratt-Hartmann also
hold SHIQ simple roles (roles transitive transitive
subrole) query. Given restriction query, also SHOQ SHOI
shown coNP-complete data complexity w.r.t. conjunctive query entailment
(Ortiz, Calvanese, & Eiter, 2008a).
Query entailment answering also studied context databases
incomplete information (Rosati, 2006b; van der Meyden, 1998; Grahne, 1991).
setting, DLs used schema languages, expressivity considered DLs
usually much lower expressivity DL ALCHOIQb consider
reasoning usually tractable. example, constructors provided logics
DL-Lite family (Calvanese, De Giacomo, Lembo, Lenzerini, & Rosati, 2007) chosen
standard reasoning tasks PTime regarding combined complexity
query entailment AC0 respect data complexity. Thus, TBox reasoning
done independently ABox ABox stored accessed using standard
database SQL engine. Another tractable DL EL (Baader, 2003). Conjunctive query
entailment EL is, however, tractable complexity increases coNP-complete
(Rosati, 2007b). Moreover EL++ (Baader et al., 2005), still tractable extension EL,
query entailment even undecidable (Krotzsch, Rudolph, & Hitzler, 2007). mainly
EL++ , one use unrestricted role compositions. allows encoding
context-free languages, conjunctive queries used check intersection
languages, known undecidable problem. Since logics used
databases incomplete information considerable less expressive ALCHOIQb,
techniques developed area transfer setting.
Given query entailment (computationally) harder task than, example,
knowledge base satisfiability, surprising decidability latter task
necessarily transfer problem CQ entailment. undecidability results transferred FOL since many DLs directly translated
equivalent FOL theory. example, known conjunctive query entailment
undecidable two variable fragment First-Order Logic L2 (Rosati, 2007a),
Rosati identifies relatively small set constructors cause undecidability (most
notably role negation axioms, i.e., axioms form x, (R(x, y) P (x, y)) R, P
binary predicates). Pratt-Hartmann (2009) recently established decidability CQ entailment two variable guarded fragment counting (GC2 ). worth noting
Pratt-Hartmann assumes background theory (that knowledge base
case) constant free formulae form =1 x(P (x)), used simulate constants/nominals, considered guarded. result covers, therefore,
DL ALCHIQb applicable case, input knowledge base (the
background theory) contains nominals (individual constants).
432

fiNominals, Inverses, Counting, Conjunctive Queries

implemented DL reasoners, e.g., KAON2,1 Pellet, RacerPro,2 provide
interface conjunctive query answering, although KAON2 RacerPro consider
named individuals ABox assignments variables. restriction
queries longer standard FOL semantics decidability obviously
issue since conjunctive query answering restriction reduced standard
instance retrieval replacing variables individual names ABox
testing entailment conjunct separately. Pellet goes beyond also provides
interface conjunctive queries FOL semantics restriction queries
kind tree shape. restriction decidability known since CQs
expressed normal concepts (possibly adding role conjunctions).
1.2 Contributions Overview
Given results, show great interest problem conjunctive query entailment expressive DLs, interesting DLs SHIF, SHOIN ,
SROIQ underpin widely adopted standards OWL Lite, OWL 1 DL, OWL 2
DL, respectively, decidability conjunctive query entailment established
OWL Lite. main obstacle devising decision procedure combination inverse
roles (I), nominals (O), number restrictions/counting quantifiers (F stands functionality, N unqualified number restrictions, Q qualified number restrictions).
complications arising combination constructors caused also major
hurdle development implementable algorithms knowledge base satisfiability
SHOIN extensions thereof, Horrocks Sattler (2005) devised tableau-based
decision procedure since extended SROIQ. Meanwhile also alternative
approaches resolution (Kazakov & Motik, 2008), hypertableau-based procedures
(Motik et al., 2009) available implemented.
key obstacle establishing decision procedure existence potentially
infinitely many new nominals, i.e., elements uniquely identifiable model
KB. example, consider KB K given Fig. 1. concept form {o}
interpreted singleton set, containing interpretation constant
o. simplicity, assume constant always interpreted itself, e.g.,
interpretation o. axiom form {o1 } v f.s.f .{o2 }
understood follows: constant o1 , must two elements, say d1 d2 ,
f (o1 , d1 ), s(d1 , d2 ), f (o2 , d2 ) holds. Note o2 occurs first element
f (o2 , d2 ) since inverse role (f ) used. Thus, interpretation KB must contain
three elements o1 , o2 , o3 , must interconnected following way: paths
f



f

shape lead o1 o2 well o2 o3 o3
o1 . Moreover, role f defined functional, meaning every element
one f -successor. also applies individuals oi , forces existence
s-cycle. Observe cyclic Boolean query {s(x, y), s(y, z), s(z, x)} checks
existence cycle cannot answered applying standard techniques
replacing variables individual names (oi ) rewriting query equivalent
1. http://kaon2.semanticweb.org
2. http://www.racer-systems.com

433

fiRudolph & Glimm

{o1 } v f.s.f .{o2 }
{o2 } v

f.s.f .{o

{o1 }

3}

f

f




{o3 } v f.s.f .{o1 }

{o2 }


f

{o3 }

func(f )

Figure 1: Example knowledge base K representation model, three
elements s-cycle so-called new nominals.

tree-shaped query. elements cycle behave nominals,
names them.
tackle problem conjunctive query entailment expressive DL contains three problematic constructors simultaneously prove decidability (unions
of) conjunctive queries. challenging part establish finite representability
countermodels case query given input entailed knowledge base.
results also hold SHOIQ knowledge bases, i.e., roles declared transitive,
provided queries contain simple roles (roles neither transitive
transitive subrole). essentially restriction placed roles
occur number restrictions since otherwise standard reasoning tasks become
undecidable. restriction, use standard techniques eliminating transitivity (Kazakov & Motik, 2008). Hence, also show decidability conjunctive query
entailment OWL DL, queries simple roles.
believe work also valuable understanding, general, structure
models DLs contain nominals, inverse roles, number restrictions. Furthermore,
devise non-trivial extensions standard techniques unraveling, believe
prove useful working expressive DLs.
paper organized follows: Section 2, give birds-eye view techniques
ideas used establish decidability. Section 3, give necessary definitions
introduce standard notations. Sections 4, 5, 6 present main results
use Section 7 show models satisfy query finitely
represented conclude Section 8.

2. Big Picture
going technical details, describe overall line argumentation
establishing decidability conjunctive query entailment ALCHOIQb.
2.1 Decidability via Finitely Representable Countermodels
Let K ALCHOIQb knowledge base let q conjunctive query question,
i.e., aim determine whether
K |= q.
Clearly, ALCHOIQb fragment first-order predicate logic equality, K
translated FOL sentence F OL(K). Likewise find FOL sentence F OL(q)
434

fiNominals, Inverses, Counting, Conjunctive Queries

q existentially quantified formula. Hence, checking entailment
equivalent determining whether first-order theory F OL(K) entails F OL(q).
result completeness theorem FOL (Godel, 1929), consequences finite FOL
theory recursively enumerable, provides us procedure terminates
K |= q. Hence, establish decidability providing another algorithm terminates
iff entailment hold i.e., so-called countermodel
model K 6|= q.
provide algorithm showing that, whenever countermodel
exists all, also countermodel finitely representable. precisely,
encoded word Rep(I) finite length finite alphabet, whereby
encoding Rep property every finite word effectively checked
whether represents countermodel given knowledge base query.
consequence thereof, create desired algorithm enumerates words,
checks countermodel, terminates soon found one.
2.2 Finite Representability Bounding Nominals Blocking
outline going show always finitely representable
countermodel, one all. taking arbitrary countermodel
cautiously transforming countermodel finitely representable. Cautiously
means make sure transformation preserve two properties
1) model underlying knowledge base K 2) entailing considered
query q.
result overall transformation going regular model, i.e., structure
substructures certain sense periodically repeated. common practice
DL theory construct kind models arbitrary ones blocking techniques,
whereby certain element configurations occurring twice original model detected
new model generated infinitely stringing together finite substructure
delimited two configurations.
case consider, technique cannot applied directly original countermodel. due intricate interplay nominals, inverse roles cardinality
constraints arbitrary even infinite number domain elements
forced behave like nominals; elements usually referred new
nominals DL setting. FOL, nominals often called kings new nominals
called court. case, presence infinitely many new nominals model
may prevent existence repeated configurations needed blocking.
overcome difficulty first applying transformation means
original countermodel converted countermodel finitely many new nominals. guarantees subsequent blocking-based transformation applicable
yield desired regular (and thus finitely representable) model.
2.3 Bounding Nominals Transformations Forest Quasi-Models
argumentation, introduce notion forest quasi-models. structures
satisfying originally considered knowledge base weakened form it.
435

fiRudolph & Glimm

return concession, exhibit proper forest structure easier handle
manipulate.
employ two techniques turn proper models forest quasi-models vice
versa: model unraveled yielding forest quasi-model. forest quasi-model
collapsed obtain proper model. techniques preserve certain structural properties.
strategy construct countermodel finitely many nominals consists
following three steps:
Take arbitrary countermodel unravel it.
Transform obtained forest quasi-model substituting critical parts wellbehaved ones,
Collapse obtained structure (proper) model.
mentioned critical parts giving rise new nominals.
least largely avoided (we care finite set critical parts
remaining).
central question is: mysterious well-behaved substitutes come from?
Fortunately, plethora critical parts brings remedy. use infinite
sets critical parts construct well-behaved ones infinite approximation process
(this infinity friend). thereby obtain parts present
structure before, well compatible hence used
reorganization.
informally introduced main line argumentation, move
technical details.

3. Preliminaries
first define syntax semantics roles, go SHOIQb-concepts,
individuals, knowledge bases. actually use full expressivity SHOIQb,
convenient umbrella DLs working define less
expressive DLs interest restrictions SHOIQb.
Definition 1 (Syntax SHOIQb). Let NC , NR , NI countable, infinite,
pairwise disjoint sets concept names, role names, individual names, respectively.
call = (NC , NR , NI ) signature. set rol(S) SHOIQb-roles (or roles
short) NR {r | r NR }, roles form r called inverse roles. role
inclusion axiom form r v r, roles. transitivity axiom form
trans(r) r role. role hierarchy H finite set role inclusion transitivity
axioms.
role hierarchy H, define function inv roles inv(r) := r r NR
inv(r) := r = role name NR . Further, define vH smallest transitive
reflexive relation roles r v H implies r vH inv(r) vH inv(s).
write r H r vH vH r. role r transitive w.r.t. H (notation r+ vH r)
436

fiNominals, Inverses, Counting, Conjunctive Queries

role exists r vH s, vH r, trans(s) H trans(inv(s)) H. role
called simple w.r.t. H role r r transitive w.r.t. H r vH s.
r rol(S) simple role, Boolean role expressions U defined follows:
U ::= r | U | U u U | U U.
use ` denote standard Boolean entailment set roles R rol(S) role
expressions. Let r rol(S), U Boolean role expression R. inductively define:
R ` r r R, R 6` r otherwise,
R ` U R 6` U , R 6` U otherwise,
R ` U u V R ` U R ` V , R 6` U u V otherwise,
R ` U V R ` U R ` V , R 6` U V otherwise.
Boolean role expression U safe 6` U .
Given signature = (NC , NR , NI ), set SHOIQb-concepts (or concepts
short) smallest set built inductively symbols using following
grammar, NI , NC , n IN0 , simple role, U role safe
Boolean role expression:
C ::= > | | {o} | | C | C1 u C2 | C1 C2 |
4
U.C | U.C | 6 n s.C | > n s.C.
Alternatively, safeness characterized follows: Boolean role expression U
safe if, transforming disjunctive normal form, disjunct contains least
one non-negated role. Intuitively, implies safe role expression never relate
individuals direct role relation other.
Definition 2 (Semantics SHOIQb-concepts). interpretation = (I , ) consists
non-empty set , domain I, function , maps every concept name
NC subset AI , every role name r NR binary relation rI ,
every individual name NI element aI . role name r NR ,

interpretation inverse role (r ) consists pairs h, 0
h 0 , rI .
semantics SHOIQb-concepts signature defined follows:
(r)I
>I
(C)I
(U.C)I
(U.C)I
(6 n s.C)I
(> n s.C)I

=
=
=
=
=
=
=

\ rI
(r1 u r2 )I = r1I r2I
(r1 r2 )I = r1I r2I



=
({o})I = {oI }
\ C
(C u D)I = C DI
(C D)I = C DI

0

0

{ | h, U , C }
{ | h, 0 U 0 C }
{ | ](sI (, C)) n}
{ | ](sI (, C)) n}

](M ) denotes cardinality set sI (, C) defined
{ 0 | h, 0 sI 0 C }.
concept C negation normal form (NNF) negation occurs front concept
names use nnf(C) denote negation normal form concept C.
4
437

fiRudolph & Glimm

concept transformed linear time equivalent one NNF pushing
negation inwards, making use de Morgans laws duality existential
universal restrictions, at-most at-least number restrictions form
6 n r.C > n r.C respectively (Horrocks, Sattler, & Tobies, 2000).
Definition 3 (Syntax Semantics Axioms Knowledge Bases). functionality
restriction expression func(f ) f role. C, concepts, general concept
inclusion (GCI) expression C v D. introduce C abbreviation
C v v C. finite set GCIs functionality restrictions called TBox.
.
.
(ABox) assertion expression form C(a), r(a, b), r(a, b), = b, =
6 b,
C concept, r role, a, b NI individual names. ABox finite set
assertions. knowledge base K triple (T , H, A) TBox, H role hierarchy,
ABox.
use con(K), rol(K), nom(K) denote, respectively, set concept names,
roles (including inverses), individual names occurring K. closure cl(K) K
smallest set containing nnf(C D) C v ; sub-concept C
C cl(K); nnf(C) C cl(K). role f functional K K contains
functionality axiom func(f ) inverse functional K K contains functionality
axiom func(inv(f )).
Let = (I , ) interpretation. satisfies role inclusion axiom r v
rI sI , satisfies transitivity axiom trans(r) rI transitive binary relation, role
hierarchy H satisfies role inclusion transitivity axioms H. interpretation
satisfies functionality restriction func(f ) if, , ]({ 0 | h, 0 f }) 1;
satisfies GCI C v C DI ; satisfies TBox satisfies functionality
restriction GCI . interpretation satisfies assertion C(a) aI C ,
.
.
r(a, b) haI , bI rI , r(a, b) haI , bI
/ rI , = b aI = bI , =
6 b aI 6= bI ;
satisfies ABox satisfies assertion A. say satisfies K satisfies
, H, A. case, say model K write |= K. say K
consistent K model.
4
knowledge base K clear context, simply say role f (inverse)
functional instead saying f (inverse) functional K.
names DLs indicate constructors supported. basic DL ALC
supports Boolean concept constructors GCIs, role hierarchies, functionality
restrictions et cetera. transitivity axioms added, use instead ALC. Inverse
roles indicated letter I, role inclusion axioms H, nominals, i.e., concepts
form {o} NI , O, functionality restrictions F, qualified number restrictions,
i.e., concepts form 6 n s.C > n s.C, Q, safe Boolean role expressions
b. number restrictions limited concepts form 6 n s.> > n s.>, use
letter N .
mostly refer particular DLs paper: DL SHOIQ obtained
SHOIQb disallowing Boolean role expressions. DLs SHIQ, SHOQ, SHOI
obtained SHOIQ disallowing nominals, inverse roles, number restrictions
(incl. functionality restrictions), respectively. Finally, DL ALCOIFb obtained
SHOIQb disallowing transitivity axioms (we use ALC instead name
DL indicate this), role inclusion axioms, concepts form 6 n s.C > n s.C.
438

fiNominals, Inverses, Counting, Conjunctive Queries

3.1 Conjunctive Queries Unions Conjunctive Queries
introduce Boolean conjunctive queries since basic form queries
concerned with. later also define non-Boolean queries show
reduced Boolean queries. Finally, unions conjunctive queries disjunction
conjunctive queries.
Definition 4 (Syntax Semantics Conjunctive Queries). Let = (NC , NR , NI )
signature NV countably infinite set variables disjoint NC , NR , NI .
term element NV NI . Let NC concept name, r NR role
name, t, t0 terms. atom expression A(t) r(t, t0 ) refer two
types atoms concept atoms role atoms respectively. Boolean conjunctive query
q non-empty set atoms. use var(q) denote set (existentially quantified)
variables occurring q term(q) denote set variables individual names
occurring q. usual, use ](q) denote cardinality q, simply
number atoms q, use |q| size q, i.e., number symbols necessary
write q.
Let = (I , ) interpretation. total function : term(q) evaluation
(a) = aI individual name occurring q. A(t), r(t, t0 ) atoms, write
|= A(t) (t) AI ;
|= r(t, t0 ) ((t), (t0 )) rI .
If, evaluation , |= atoms q, write |= q. say
satisfies q write |= q exists evaluation |= q. call
match q I.
Let K knowledge base q conjunctive query. |= K implies |= q, say
K entails q write K |= q.
4
query entailment problem defined follows: given knowledge base K
query q, decide whether K |= q.
Definition 5 (Unions Conjunctive Queries). union Boolean conjunctive queries
formula q1 . . . qn , disjunct qi Boolean conjunctive query.
knowledge base K entails union Boolean conjunctive queries q1 . . . qn , written
K |= q1 . . . qn , if, interpretation |= K,
|= qi 1 n.
4
clarify connection query entailment query answering.
query answering, let variables conjunctive query typed: variable either
existentially quantified (also called non-distinguished ) free (also called distinguished
answer variables). Let q query n variables (i.e., ](var(q)) = n), v1 , . . . , vm
(m n) answer variables. answers K q m-tuples (a1 , . . . , )
individual names that, models K, |= q satisfies (vi ) = aIi
1 m. Recall use nom(K) denote set individual names
occurring K (in form nominals ABox individuals). hard see (cf.
Chandra & Merlin, 1977) answers K q computed testing,
439

fiRudolph & Glimm

(a1 , . . . , ) nom(K)m , whether query q[v1 ,...,vm /a1 ,...,am ] obtained q replacing
occurrence vi ai 1 entailed K. set certain answers
q set m-tuples (a1 , . . . , ) K |= q[v1 ,...,vm /a1 ,...,am ] . Let
k = ](nom(K)) number individual names occurring K. Since K finite, clearly
k finite. Hence, deciding tuples belong set answers checked
k entailment tests.
algorithm present paper decides query entailment. reasons
devising decision procedure query entailment instead query answering twofold: first, query answering reduced query entailment shown above; second,
contrast query answering, query entailment decision problem studied
terms complexity theory.
3.2 Simplifying Assumptions
following, make several assumptions without loss generality,
simplify presentation decision procedure.
3.2.1 SHOIQ ALCHOIQb simplified ALCOIFb Knowledge Bases
following, work ALCOIFb knowledge bases. Nevertheless, results
also hold SHOIQ knowledge bases queries simple roles query
ALCHOIQb knowledge bases, i.e., knowledge base contains safe Boolean role
expressions, transitivity. restriction ALCOIFb without loss generality,
show now.
Provided query contains simple roles, use elimination techniques
transitivity (Kazakov & Motik, 2008) reduce SHOIQ knowledge base ALCHOIQ
knowledge base extended signature. eliminate qualified number restrictions role inclusion axioms transforming ALCHOIQb knowledge base
ALCOIFb knowledge base equivalent original one extension
signature (Rudolph, Krotzsch, & Hitzler, 2008). repeat formal proof here,
rather give informal argument reduction works.
assume knowledge base negation normal form, i.e., GCIs
form > v C C concept NNF. Now, consider concept expression form
> n r.C r role C concept. means least n distinct rneighbors satisfying C. However, situation enforced introducing n new roles
r1 , . . . , rn deemed r superrole (ri v r) pairwise
disjoint (> v (ri u rj ).). side conditions, concept expression
replaced r1 .C u . . . u rn .C.
somewhat dual argumentation possible concept expressions form 6 n r.C
restricting number r-neighbors satisfying C n. extend
signature introducing new roles r1 , . . . , rn , time, let cover outgoing
r-links following sense: whenever r-link leads domain element
satisfies C, one roles r1 , . . . , rn also leads there. Indeed, safe Boolean role
expressions allow expressing correspondence via concept description (r u r1 u
. . . u rn ).C. easy see, concept expression replace
additionally demand roles r1 , . . . , rn functional.
440

fiNominals, Inverses, Counting, Conjunctive Queries

{o} v r.A

v r.A

v s.B

func(f )

func(g )

B vC tD

C v f.E

v g.E

E v B {o}

r
{o}
E



r


f

B
C E



r


g

B
DE



r


f

B
C E



r


g

B
DE

r




f

B
C E

g



Figure 2: Knowledge base running example representation model
knowledge base.

Finally consider role hierarchy statement r v s, stating whenever two domain
elements 1 2 connected role r, also interconnected via s. Clearly,
statement reformulated as: two domain elements connected r
s. This, turn, equivalently rephrased saying domain element
r u s-neighbor or, expressed GCI, > v (r u s)..
transformations applied ALCHOIQb knowledge base, whereby
cardinality constraints role inclusion axioms eliminated. leaves us
equivalent ALCOIFb knowledge base extension signature.
Figure 2 displays ALCOIFb knowledge base according model,
refer running example throughout paper.
Furthermore, assume ABox internalized (e.g., C(a) replaced
equivalent GCI {a} v C, r(a, b) {a} v r.{b}, etc.). Thus, effectively decide query
entailment respect TBox since knowledge bases setting empty
ABox.
ALCOIFb TBox, always possible transform equivalent TBox
0 signature extension GCIs 0 one following simplified
forms:
l
G
Ai v
Bj | {o} | v U.B | v U.B | func(f ),
(1)
A(i) B(j) concept names, andindividual name, U safe Boolean
F role
expression, f role. = 0, interpret Ai > j = 0, interpret Bj
. ALCOIFb knowledge base K = (T , A) simplified simplified empty.
Every ALCOIFb knowledge base, form, transformed polynomial time desired form using standard structural transformation,
iteratively introduces definitions compound sub-concepts (Kazakov & Motik, 2008).
Thus, assume remainder knowledge base rewritten simplified
ALCOIFb knowledge base.
441

fiRudolph & Glimm

3.2.2 Connected Constant-free Queries
assume queries connected. precisely, let q conjunctive query.
say q connected if, t, t0 term(q), exists sequence t1 , . . . , tn
t1 = t, tn = t0 and, 1 < n, exists role name r r(ti , ti+1 ) q
r(ti+1 , ti ) q. collection q1 , . . . , qn queries partitioning q q = q1 . . . qn ,
term(qi ) term(qj ) = 1 < j n, qi connected.
Lemma 6. Let K knowledge base, q conjunctive query, q1 , . . . , qn partitioning
q. K |= q iff K |= qi 1 n.
proof given Tessaris (2001) and, lemma, clear restriction
connected queries indeed without loss generality since entailment q decided
checking entailment qi time. follows, therefore assume queries
connected without notice.
unions conjunctive queries, assume variable names disjunct
different variable names disjuncts. always achieved
naming variables apart. assume disjunct UCQ connected conjunctive query. without loss generality since UCQ contains unconnected
disjuncts always transformed conjunctive normal form; decide entailment resulting conjunct separately conjunct union connected
conjunctive queries (Glimm et al., 2008a). Note that, due transformation conjunctive normal form, resulting number unions connected conjunctive queries
test entailment exponential size original query.
assume queries contain constants (individual names) occur
position variables. presence nominals without loss generality:
individual name occurring q, extend knowledge base K axioms
{a} Na Na NC fresh concept name, replace occurrence q
fresh variable xa NV add concept atom Na (xa ) q.
3.2.3 General Notation
Throughout paper, concept names role expressions written upper case,
roles individual names written lower case. Unless stated otherwise, use
B concept names; C possibly complex concepts; r roles, f
functional inverse functional roles; U V safe Boolean role expressions;
nominals used TBox axioms occur complex concepts. Sub-
superscripts might appended necessary. stated otherwise, use q (possibly
subscripts) connected Boolean conjunctive query, K simplified ALCOIFb
knowledge base, interpretation (I , ), , evaluations.

4. Model Construction
section, introduce interpretations models kind forest shape.
main notion forest is, however, weak since also allow arbitrary
relations tree elements roots. Without relations, call result
strict forest. exploit nice properties trees forests following sections,
442

fiNominals, Inverses, Counting, Conjunctive Queries

replace parts interpretations give rise infinite number new nominals.
Since even models ALCOIFb knowledge base kind forest shape
really forests, also introduce approximations models nominals longer
interpreted singleton sets. call structures quasi-interpretations quasi-models
interpretations form real forests. Further, provide way
unraveling arbitrary model forest quasi-model knowledge base
way collapsing forest quasi-models back real models knowledge
base still kind forest shape.
Definition 7 (Forest (Quasi-)Interpretations (Quasi-)Models). tree nonempty, prefix-closed subset . w, w0 , call w0 successor w w0 = w c
c IN, denotes concatenation. call w0 predecessor w w = w0 c
c IN, w0 neighbor w w0 successor w vice versa. empty
word called root tree. use |w| denote length w.
forest F subset R , R countable, possibly infinite set elements
that, R, set {w | (, w) F } tree. pair (, ) F called
root F . (, w), (0 , w0 ) F , call (0 , w0 ) successor (, w) 0 = w0
successor w; (0 , w0 ) predecessor (, w) 0 = w0 predecessor w;
(0 , w0 ) neighbor (, w) (0 , w0 ) successor (, w) vice versa. node (, w)
ancestor node (0 , w0 ) = 0 w prefix w0 descendant
= 0 w0 prefix w.
forest interpretation knowledge base K interpretation = (I , )
satisfies following conditions:
FI1 forest roots R;
FI2 total surjective function : nom(K) R {} (o) = (, )
iff oI = (, );
FI3 role r rol(K), h(, w), (0 , w0 )i rI , either
(a) w = w0 = ,
(b) (, w) neighbor (0 , w0 ).
|= K, say forest model K. single root, call tree
interpretation tree model K, respectively.
Let K ALCOIFb knowledge base. nomFree(K), denote ALCIFb
knowledge base obtained K replacing nominal concept {o} nom(K)
fresh concept name . forest quasi-interpretation K interpretation
J = (J , J ) nomFree(K) satisfies following properties:
FQ1 J forest roots R;
FQ2 total surjective function : nom(K) R {} (o) = (, )
iff (, ) NoJ
FQ3 role r rol(K), h(, w), (0 , w0 )i rI , either
(a) w = w0 = ,
443

fiRudolph & Glimm

(b) (, w) neighbor (0 , w0 ).
Note condition FQ2 allows elements (, w) J w 6= (, w) NoJ .
call J strict condition FQ3, FQ3(b) allowed. J |= nomFree(K) say
J forest quasi-model K.
branching degree d(w) node w tree number successors w. Let
= (I , ) forest (quasi) interpretation K. k d(w) k
(, w) , say branching degree k.
4
remainder, use concept name , mean fresh concept name
introduced nomFree(K) nominal concept {o} nom(K). Elements
extension concept called nominal placeholders. Please note that,
forest quasi-interpretations J , several elements (, w) w 6=
(, w) NoJ .
following, define notion isomorphism forest interpretations. Note
demand structural identity w.r.t. concepts roles also w.r.t.
successor relation.
Definition 8 (Isomorphism Forest Interpretations). Let I, 0 two forest inter0
pretations K 1 , 2 , 10 , 20 . pairs h1 , 2 i, h10 , 20 isomorphic
w.r.t. K, written h1 , 2
=K h10 , 20 iff
0

1. h1 , 2 rI iff h10 , 20 rI r rol(K),
0

2. AI iff i0 AI {1, 2} con(K),
0

3. = oI iff i0 = oI {1, 2} nom(K).
say 0 isomorphic w.r.t. K, written:
=K 0 , bijection
0
: that, 1 , 2 , h1 , 2
=K h(1 ), (2 )i 1
successor 2 iff (1 ) successor (2 ).
4
clear context, omit subscript K
=K . extend definition
obvious way forest quasi-interpretations, i.e., omitting condition 3 defining
isomorphism respect K0 = nomFree(K).
Forest quasi-models have, intuitively, purpose intermediate step arbitrary models K forest models K. identifying interpretation
concept knowledge base K0 root interpretation ,
obtain interpretation would model K apart functionality restrictions
nominals might violated. show later eliminate relations forest back roots violate functionality restrictions
eventually obtain forest model forest quasi-model.
Another useful property quasi-interpretations that, simplified ALCIFb knowledge bases, checked locally whether interpretation actually model
K.
Definition 9 (Local K-consistency). Let = (I , ) interpretation simplified
ALCIFb knowledge base K . define local satisfaction concepts
occur simplified ALCIFb axioms follows:
444

fiNominals, Inverses, Counting, Conjunctive Queries

1. A1 , . . . , con(K):
(a) I, |=



(b) I, |=

F

Ai AIi 1 n; I, 6|=



Ai otherwise;
F
Ai AIi 1 n; I, 6|= Ai otherwise;

2. U safe Boolean role expression rol(K), con(K):
(a) I, |= U.A 0 h, 0 U I, 0 |= A;
I, 6|= U.A otherwise;
(b) I, |= U.A if, 0 h, 0 U , I, 0 |= A; I, 6|= U.A
otherwise;
3. f rol(K), I, |= func(f ) ]({ 0 | h, 0 f }) 1; I, 6|= func(f )
otherwise.
element locally satisfies GCI C v C, ALCIFb-concepts I, |= C
implies I, |= D. locally satisfies functionality restriction func(f ) I, |= func(f ).
element locally K-consistent locally satisfies axiom K.
4

Lemma 10. Let K simplified ALCIFb knowledge base = (I , ) interpretation K. model K iff element locally K-consistent.

Proof. simplified ALCIFb knowledge bases, axioms form v U.B
v U.B involve checking neighbors element and, since B concept name
simplified knowledge bases, immediate satisfaction B checked locally
neighbor question.
knowledge base K nominals, also use local K-consistency,
need additional global condition ensures nominals interpreted singleton
sets. following immediate consequence Lemma 10 extra condition 2
nominals:
Proposition 11. Let K simplified ALCOIFb knowledge base = (I , )
interpretation K. model K iff
1. element locally K-consistent and,
2. nom(K), exactly one element oI = .

445

fiRudolph & Glimm

show obtain forest quasi-model model K using
adapted version unraveling.
Definition 12 (Unraveling). Let K consistent ALCOIFb knowledge base =
(I , ) model K. Let choose function returns, concept C = U.B
cl(K) element (U.B)I element C, h, C, U
C, B .
Without loss generality, assume that, concepts C1 = U1 .B1 , C2 =
U2 .B2 cl(K) C1I C2I , choose(C1 , ) = 1 , choose(C2 , ) = 2 ,
h, 1
= h, 2 i, 1 = 2 .
unraveling element , denoted (I, ), interpretation
obtained follows: define set (I ) sequences
smallest set
sequence;
1 n n+1 sequence,
1 n sequence,
n > 2 hn , n1 f functional role f , n+1 6= n1 ,
n+1 = choose(C, n ) C = U.B cl(K).
fix set F {} bijection : F
(i) F forest,
(ii) (, ) = ,
(iii) (, w), (, w c) F w c successor w, (, w c) = (, w) n+1
n+1 .
forest F bijection exist prefix-closed set root . Thus,
map notion sequences forests.
nom(K), let NC fresh concept name. (, w) F , set
Tail(, w) = n (, w) = 1 n . Now, define unraveling interpretation
J = (J , J ) J = F and, (, w) J , define interpretation
concept role names follows:
(a) nom(K), NoJ = {(, w) J | Tail(, w) oI };
(b) concept name con(K), AJ = {(, w) J | Tail(, w) AI };
(c) role name r rol(K), h(, w), (, w0 )i rJ iff w0 neighbor w,
hTail(, w), Tail(, w0 )i rI .
Let R subset contains exactly oI =
nom(K). Let U set containing unraveling starting R.
union interpretations U called unraveling I, denoted (I),
unions interpretations defined natural way.
4
446

fiNominals, Inverses, Counting, Conjunctive Queries

E



BC
E

BD
E

f



BC
E

g

BC
E






r

BD
E

f

BD
E

f

g

BC
E

g

BC
E



..

.

r


BD
E
g

BC
E
f
..

r


r

r

r





r

BD
E
g

.

f
..

.

BD
E
g

f
..

E
..
.
E
..
.
E
..
.

.

Figure 3: Unraveling model displayed Figure 2.
Figure 3 shows unraveling example knowledge base model. dotted
lines non-root elements labeled indicate copy whole tree
appended since stop unraveling nominal placeholders.
might helpful think function Tail homomorphism (up signature
extension) elements unraveling J elements original model I.
Indeed, Tail satisfies following properties: (, w), ( 0 , w0 ) J ,
Tail(, w) = oI iff (, w) NoJ , nom(K),
Tail(, w) AI iff (, w) AJ , con(K),
hTail(, w), Tail( 0 , w0 )i rI iff h(, w), ( 0 , w0 )i rJ , r rol(K).
Unravelings first step process transforming arbitrary model K
forest model since resulting model forest quasi-model K, show
next lemma.
Lemma 13. Let K consistent ALCOIFb knowledge base = (I , ) model
K. J = (J , J ) = (I) strict forest quasi-model K.
Proof. Let K0 = nomFree(K). construction, J satisfies conditions FQ1 FQ3
forest quasi-models strictness condition. Since J obtained model
K, definition unravelings starting oI =
nom(K), condition (a) unravelings, is, nom(K), one root
(, ) J (, ) NoJ . Thus, J satisfies also property FQ2 J forest
quasi-interpretation K. show J model K0 demonstrating
(, w) J locally K0 -consistent. Since assume knowledge bases simplified,
consider axioms form (1).
447

fiRudolph & Glimm


F

Let Ax axiom form Ai v Bj assume
(, w) ( Ai )J .

condition (b) unravelings, w = Tail(, w) ( Ai )I and, since |= K,
w BjI j. condition (b) unravelings, (, w) BjJ
required.
Axioms form {o} K rewritten K0 . consider v
v separately. Let Ax form v nom(K) assume
(, w) AJ . condition (b), w = Tail(, w) AI and, since |= K,
w {oI }. condition (a) unravelings, (, w) NoJ
required. v nom(K), assume (, w) NoJ . condition (a),
w = Tail(, w) {oI } and, since |= K, w AI . condition (b)
unravelings, (, w) AJ required.
Let Ax axiom form v U.B assume (, w) AJ . condition (b), w = Tail(, w) AI and, since |= K, w0
hw , w0 U w0 B . Let ( 0 , w0 ) h(, w), ( 0 , w0 )i U J
( 0 , w0 )
/ B J . condition (c) unravelings, hw , w0 U
w0 = Tail( 0 , w0 ) condition (b) w0
/ B , contradiction.
Let Ax axiom form v U.B assume (, w) AJ . condition (b), w = Tail(, w) AI and, since |= K, least one
w0 hw , w0 U w0 B . case one
element, let w0 w0 = choose(C, w ). Then, definition sequences,
neighbor (, w0 ) (, w) Tail(, w0 ) = w0 . Let (, w) = 1 n , i.e., n = w .
distinguish two cases:
1. element w0 w0 = n1 . definition bijection , w =
w0 c, definition J (condition (c)) since hw , w0 U ,
h(, w), (, w0 )i U J . Then, since B concept name w0 B ,
condition (b) (, w0 ) B J , proves claim.
2. element w0 w0 6= n1 . definition sequences bijection
, (, w0 ) = 1 n w0 . Now, definition J (in particular
properties (b) (c)), h(, w), (, w0 )i U J and, since B concept
name, (, w0 ) B J , proves claim.
Let Ax axiom form func(r) r rol(K). Assume, contrary
shown, (, w) two distinct neighbors (, w1 ), (, w2 )
h(, w), (, w1 )i, h(, w), (, w2 )i rJ . Since function introduced unraveling
bijection, two distinct sequences s1 s2 (, w1 ) = s1 (, w2 ) = s2
Tail(, w1 ) = 1 , Tail(, w2 ) = 2 1 6= 2 . Since h(, w), (, w1 )i, h(, w), (, w2 )i
rJ get, due condition (c), hTail(, w), 1 i, hTail(, w), 2 rI , contradiction since |= K.
Since (, w) arbitrarily chosen, element domain J
locally K0 -consistent required J |= K0 Lemma 10.
Lemma 14. Let K consistent ALCOIFb knowledge base, = (I , ) model K,
J = (J , J ) = (I) unraveling I. J branching degree bounded
|cl(K)|.

448

fiNominals, Inverses, Counting, Conjunctive Queries

Proof. Let number axioms K. axiom simplified knowledge base
contain one existential restriction and, due definition function
choose used unraveling, are, sequence S, elements
1 , . . . , 1 sequence S. Since mapping
forest J sequences bijection, J forest branching degree m.
following steps, traverse forest quasi-model order elements
smaller tree depth always smaller order elements greater tree depth.
Elements tree depth ordered lexicographically. bounded branching
degree unravelings guarantees that, finite number steps, go
next level forest process nodes eventually. Further, merge nodes
that, finally, nominal placeholders (in extension ) interpreted
nominals without violating functionality restrictions. fact,
merge nominal placeholders, also elements related nominal placeholder
inverse functional role since, definition semantics, elements
correspond element model. order identify elements, define
notion backwards counting paths follows:
Definition 15 (Paths BCPs). Let = (I , ) interpretation. call 1 . . . n
path 1 n if, 1 < n, hi , i+1 riI role ri rol(K).
length |p| path p = 1 . . . n n 1. element path length
U

Un1

0. write 1 1 2 . . . n denote path 1 n hi , i+1 UiI
1 < n Ui safe Boolean role expression.
Let K ALCOIFb knowledge base = (I , ) forest model (a forest quasimodel) K. path p = 1 . . .n descending path root (, )
that, 1 n, = (, wi ) and, 1 < n, |wi | < |wi+1 |.
path p backwards counting path (BCP) n = oI (n NoI ) nominal
nom(K) and, 1 < n, hi , i+1 fiI inverse functional role
fi rol(K). path p descending BCP BCP descending path. Given
f1

fn

BCP p = 1 2 . . . n+1 n+1 oJ (n+1 NoJ ), call sequence f1 fn
path sketch p.
4
Please note element domain J already counts (descending) BCP
oJ (NoJ ) nom(K).
define order guarantees iterative parsing process,
process nodes, also merge nodes required that, finally, nominal
placeholders interpreted nominals without violating functionality restrictions.
Definition 16 (Ordering). convenience without loss generality, assume
set individual names NI ordered. Let K consistent ALCOIFb knowledge
base J forest quasi-interpretation K. extend order elements J


follows: let w1 = wp c11 cn1 , w2 = wp c12 cm
2 wp longest
common prefix w1 w2 , w1 < w2 either n < n = c11 < c12 .
(1 , ), (2 , ) J , let o1 nom(K) smallest nominal (1 , ) NoJ1
o2 nom(K) smallest nominal (2 , ) NoJ2 . (1 , w1 ) < (2 , w2 ) either
(i) |w1 | < |w2 | (ii) |w1 | = |w2 | o1 < o2 (ii) |w1 | = |w2 |, o1 = o2 w1 < w2 .
449

fiRudolph & Glimm

following, merging elements unraveling and, process, create
new roots form (w, ) elements form (, w) elements form
(w, w0 ) (, ww0 ). extend, therefore, order elements form follows:
(1 w1 , w10 ) < (2 w2 , w20 ) (1 , w1 w10 ) < (2 , w2 w20 ).
4
Roughly speaking, proceed follows order transform quasi-forest model
J forest model I: work way downwards trees level level along
descending BCPs use defined order purpose. definition
semantics, elements start descending BCP or, precisely, start
BCPs identical path sketches, correspond element forest
model produce. traversal forest quasi-model, distinguish
two situations: (i) encounter element (, w) starts descending BCP
seen another element starts descending BCP path
sketch. case, promote (, w) become new root node form (w, )
shift subtree rooted (, w) it; (ii) encounter node (, w) starts
descending BCP, already seen node (0 , w0 ) starts descending BCP
path sketch root form (0 w0 , ). case, delete
subtree rooted (, w) identify (, w) (0 w0 , ). (, w) f -successor
predecessor inverse functional role f , delete f -successors (0 w0 , )
subtrees order satisfy functionality restriction. use notion collapsing
admissibility characterize models predecessor (, w) satisfies
atomic concepts deleted successor (0 , w0 ), ensures local consistency
preserved. virtue notion, characterize forest quasi-models
collapsed proper models irrespective whether obtained unraveling
model not.
order keep domain forest promoting element (, w) new root,
build new domain elements form (w, ) (, w) elements
form (w, w0 ) descendants (, ww0 ) (, w).
Definition 17 (Equivalence Relation Collapsings). Let K ALCOIFb knowledge base, K0 = nomFree(K), J = (J , J ) forest quasi-interpretation K.
define smallest equivalence relation J satisfies 1 2 1 , 2 start
descending BCPs identical path sketches.
Let J strict forest quasi-interpretation K, J0 = (J0 , J0 ) = J (0 , w0 )
J
0
smallest element w0 6= starts descending BCP. call J0 initial
collapsing J (0 , w0 ) focus J0 .
Let Ji collapsing J (i , wi ) Ji focus Ji . obtain collapsing
Ji+1 = (Ji+1 , Ji+1 ) focus (i+1 , wi+1 ) J Ji according following two
cases:
1. element (, ) Ji (, ) smaller focus (i , wi )
(, ) (i , wi ). Ji+i obtained Ji renaming element (i , wi wi0 )
Ji (i wi , wi0 ).
2. element (, ) Ji (, ) smaller focus (i , wi )
(, ) (i , wi ). Let (, ) smallest element.
450

fiNominals, Inverses, Counting, Conjunctive Queries

(a) Ji+1 = Ji \ ({(i , wi wi0 ) | wi0 } {(, w) | w = c w0 , c IN, w0
, (i , wi ) predecessor (i , wi0 ) h(i , wi0 ), (i , wi )i f Ji
inverse functional role f rol(K) h(, c), (, )i f Ji });
(b) concept name con(K) (, w) Ji+1 , (, w) AJi+1 iff (, w)
AJi ;
(c) role name r rol(K) (1 , w1 ), (2 , w2 ) Ji+1 , h(1 , w1 ), (2 , w2 )i
rJi+1 iff
i. h(1 , w1 ), (2 , w2 )i rJi
ii. (1 , w1 ) predecessor (i , wi ) Ji (i.e., 1 = wi = w1 c
c IN), (2 , w2 ) = (, ), h(1 , w1 ), (i , wi )i rJi .
focus (i+1 , wi+1 ) Ji+1 smallest descending BCP (i , wi ) < (i+1 , wi+1 ).
collapsing Ji , let safe(Ji ) restriction Ji elements (, w)
(, w) Jj j i. J denote non-disjoint union interpretations
safe(Ji ) obtained subsequent collapsings Ji J . interpretation obtained
J interpreting nom(K) (, ) NoJ denoted collapse(J ) called
purified interpretation respect J. collapse(J ) |= K, call collapse(J ) purified
model K.
4
Figures 4 7 illustrate first collapsing steps unraveling depicted
Figure 3. Apart nominal placeholder concepts, concept interpretations
shown figures, assumed indicated Figure 3. edges
descending BCPs shown red color, dashed lines Figure 4 indicate levels
tree because, within tree, order nodes processed depends firstly
level. Within level, assume order increases left right.
numbers next nodes Figure 4 indicate, elements used focus element
collapsing step order. initial collapsing (Figure 4) focus
first non-root element starts BCP, indicate black border around
node black triangle pointing focus.
first collapsing step rename elements promote focus Figure 4
root. focus element highlighted Figure 5 starts BCP path sketch
different ones started smaller elements, rename elements
obtain new root (Figure 6). Now, focus nominal placeholder since nominal
placeholder BCPs, root path sketch use second case
Definition 17. resulting collapsing depicted Figure 7.
Finally, obtain collapsing unraveling shown Figure 3 one depicted
Figure 8.
show collapsing unraveling results forest model
K. aim is, however, show something general. want collapse
unravelings forest models, also forest quasi-models obtained
another way. Unfortunately, case collapsing forest quasi-model
results forest model K since elements merge collapsing process
necessarily satisfy atomic concepts. define, therefore, following
admissibility criterion characterizes forest quasi-models collapsed
forest models.
451

fiRudolph & Glimm





r

r



H
1

r
3

4
f

f
r
g








f

r



g

g

5
f
g

r

H

g


r

r


2
g



r



f



r


f



Figure 4: initial collapsing un- Figure 5: first collapsing step
raveling depicted Figure 3.
rename elements promote
focus Figure 4 root.

r

r


f

r
r

r

r

f





H

r



g

g



f


f



r

r

g



g

g






N

f



g

f





r







Figure 6: collapsing obtained Figure 7: collapsing obtained using
one depicted Figure 5.
second case Definition 17
collapsing Figure 6.

Definition 18 (Collapsing-admissibility). Let J forest quasi-interpretation
ALCOIFb knowledge base K. J collapsing-admissible exists function
ch : (cl(K) J ) J
1. concept C = U.B cl(K) C J , h, ch(C, )i U J
ch(C, ) B J . Moreover, functional role f h, ch(C, )i f J
ch(C, ) successor ,
2. concept C = U.B cl(K) elements , 0 C J start descending
BCPs identical path sketches, h, ch(C, )i
= h 0 , ch(C, 0 )i.
4
Lemma 19. Let K ALCOIFb knowledge base. unraveling J model
K collapsing-admissible.
452

fiNominals, Inverses, Counting, Conjunctive Queries

B
B
B
B
B
{o} E f C E g E f C E g E f C E g



r






r




r




r

r

r
..
.

Figure 8: Result collapsing unraveling Fig. 3. infinitely many new root
elements displayed top line.

Proof. define function ch directly function choose used unraveling follows: C cl(K) (, w) J (, w) = 1 . . . n
choose(C, Tail(, w)) = { 0 }, set ch(C, (, w)) = (, w0 ) (, w0 ) = (1 . . . n 0 )
1 . . . n 0 sequence (, w0 ) = (1 . . . n1 ) otherwise.
well-defined since function unravelings total bijective required
admissibility since elements start BCPs identical path sketches always
generated element I. first condition collapsing-admissibility holds
since unravelings, always add 1 . . . n 0 set sequences unless pair
hn , n1 interpretation functional role. case, function ch uses
predecessor instead successor, still admissible.
Lemma 20. Let K consistent ALCOIFb knowledge base, J = (J , J ) strict forest
quasi-model K branching degree b collapsing-admissible. collapse(J )
forest model K branching degree b.
Proof. Let K0 = nomFree(K). Since J forest quasi-model K assumption, J |= K0 .
first show collapsing Ji J forest quasi-model K, i.e., Ji |= K0 .
show collapsing Ji+1 produced admissible collapsing Ji
collapsing-admissible. Finally, show that, nom(K), exactly one
node J form (, ) (, ) NoJ , implies Proposition 11
collapse(J ) forest model K.
start first claim: initial collapsing immediate since J
forest quasi-model K. particular, J0 locally K0 -consistent. Assume Ji
locally K0 -consistent collapsing (i , wi ) focus Ji . show Ji+1 locally
453

fiRudolph & Glimm

K0 -consistent. Since K0 simplified assumption, consider axioms
form (1).
Ji+1 obtained according first case Definition 17, rename elements
domain order create new root node local K0 -consistency immediate.
assume, thus, Ji+1
according second case Definition 17.
obtained
F
Axioms form Ai v Bj {o} (rewritten K0 ) hold
immediately due condition 2.b collapsings.
Let Ax axiom form v U.B assume (, w) AJ .
interesting elements predecessor (i , wi0 ) focus (i , wi ) (, ). However,
(i , wi ) (, ) and, since J collapsing-admissible, (i , wi ) (, ) satisfy
atomic concepts respect con(K). Further, interpretation atomic concepts
changed due 2.b, implies local K0 -consistency kind axioms.
Let Ax axiom form v U.B assume (, w) AJi+1 . concentrate three interesting cases direct neighborhoods elements change:
1. start case focus (i , wi ) corresponding U -successor
(, w), i.e., = , wi = wc c IN, h(, w), (i , wi )i U Ji , (i , wi ) B Ji .
Since (, ) (i , wi ) equivalence class assumption, (, )
starts BCP path sketch (i , wi ) (, ) (i , wi ) satisfy
atomic concepts respect con(K). condition 2.(c)ii. ensures
(, ) required U -successor (, w) Ji+1 .
2. Assume (, w) = (, ), h(, ), (, c)i U Ji , (, c) B Ji , (, c)
/ Ji+1 ,
J
i+1
(, )
/ (U.B)
. Due 2.a, focus (i , wi ) predecessor (i , wi0 )
0
h(i , wi ), (i , wi )i f Ji inverse functional role f rol(K) h(, ), (, c)i
(f )Ji . Since f inverse functional Ji is, assumption, locally K0 -consistent,
successor (i , wi ci ) (i , wi ) h(i , wi ), (i , wi ci )i (f )Ji .
Similarly, element (0 , w0 ) h(, ), (0 , w0 )i (f )Ji . Then,
since Ji collapsing-admissible, (i , wi0 ) ch(U.B, (i , wi )), (, c)
ch(U.B, (, )), h(i , wi ), (i , wi0 )i
= h(, ), (, c)i since (i , wi ) (, ) start
descending BCPs identical path sketches. particular, h(i , wi ), (i , wi0 )i U Ji
(i , wi0 ) B Ji . Then, condition 2.(c)ii., h(, ), (i , wi0 )i U Ji+1 , condition 2.b, (i , wi0 ) B Ji+1 , and, thus, (, ) (U.B)Ji+1 required.
3. assume (i , wi ) predecessor (i , wi0 ) h(i , wi0 ), (i , wi )i f Ji
inverse functional role f rol(K) h(, c), (, )i f Ji , causing deletion
(, c) descendants, one which, say (, v) connected (, ),
h(, ), (, v)i U Ji (, v) B Ji . Now, inverse functional role
g h(, ), (, v)i g Ji , strictness collapsing-admissibility Ji
ensure existence c0 h(, ), (, c)i U Ji (, c) B Ji and,
consequently, also h(, ), (, c)i U Ji+1 (, c) B Ji+1 . h(, ), (, v)i g Ji
inverse functional role g, strictness initial collapsing implies
(, v) started descending BCP and, due defined order, must
focus root itself. contradicts, however, initial
assumption (, v) descendant (, ) done.
cases, elements Ji+1 required successors.
454

fiNominals, Inverses, Counting, Conjunctive Queries

Let Ax axiom form func(f ) f rol(K). concentrate relations
predecessor (i , wi0 ) focus (, ) since otherwise local K0 -consistency
immediate. predecessor exists focus since process elements ascending order starting non-root nodes. Assume h(i , wi0 ), (i , wi )i f Ji , case
h(i , wi0 ), (, )i f Ji+1 due 2.(c)ii. assume (, ) successor (, c) Ji
h(, c), (, )i f Ji . case, (, c)
/ Ji+1 according 2.a together
0
local K -consistency Ji , implies (i , wi0 ) element Ji+1
h(i , wi0 ), (, )i f Ji+1 .
show Ji+1 produced admissible collapsing Ji admissible collapsing. assumption, initial collapsing admissible, let Ji
admissible collapsing chi required function. distinguish two cases:
1. Let Ji+1 produced according first case collapsings. define function
chi+1 Ji+1 follows: C cl(K) Ji+1 , set chi+1 (C, ) = 0
0 = (i wi , w10 ) chi (C, ) = (i , wi wi0 ) (i , wi ) focus Ji 0 = chi (C, )
otherwise. Since change names elements leave interpretation
concepts roles before, function required admissibility.
2. Let Ji+1 produced according second case collapsings. define function
chi+1 Ji+1 follows: C cl(K),
(a) Ji+1
/ {(i , wi0 ), (, )} (i , wi0 ) predecessor focus
(i , wi ), set chi+1 (C, ) = 0 0 0 Ji+1 0 = chi (C, );
well-defined since successors (, ) (i , wi0 ) deleted Ji+1 .
(b) = (, ) (i , wi0 ) predecessor focus, chi+1 (C, ) = 0
0 = (i , wi0 ) chi (C, ) = (, c) (, c)
/ Ji+1 0 = chi (C, ) otherwise;
(c) = (i , wi0 ) predecessor focus, set chi+1 (C, ) = 0 0 = (, )
chi (C, ) = (i , wi ) 0 = chi (C, ) otherwise.
elements apart predecessor focus (i , wi0 ) root (, )
replaces (i , wi ), interpretation concepts roles remains
properties 2.b 2.c function required. (i , wi0 ), change
function cases (i , wi ) returned, (, ) returned. Since
(i , wi ) (, ), admissible. Similarly, successor (, c) (, ) contained Ji+1 , (i , wi0 ) used instead. admissible since, case,
h(i , wi ), (i , wi0 )i
= h(, ), (, c)i argued axioms form v U.B.
show that, nom(K), exactly one node J form
(, ) (, ) NoJ . Nominal placeholders descending BCPs definition and,
nominal placeholder becomes focus, merged root
equivalence class definition lower order. root exists
property FQ2 forest quasi-interpretations.
interpretation J obtained building non-disjoint union safe parts
collapsings, contain elements neither renamed deleted.
Thus, J contain nominal placeholders required. Considering one element
(, w) J , find successors root neighbors
455

fiRudolph & Glimm

(, w) Ji J . shown, Ji locally K0 -consistent
therefore (, w) consistent neighborhood. Hence J forest quasi-model K.
Now, interpreting nom(K) {(, ) J | (, ) NoJ } collapse(J ),
obtain forest model K, set roots {(, ) | (, ) J }.
bounded branching degree immediate consequence construction since
never add successors construction starting forest quasi-interpretation
J bounded branching degree assumption.
Since unravelings model K strict forest quasi-models K branching degree bounded |cl(K)| Lemma 13, unravelings collapsing-admissible
Lemma 19, immediate consequence Lemma 20 collapsing unraveling
yields forest model branching degree bounded |cl(K)|.
Corollary 21. Let K ALCOIFb knowledge base interpretation
|= K, purified interpretation collapse((I)) forest model K branching
degree b bounded |cl(K)|.
Since number roots might still infinite purified models, could,
now, obtained result unraveling arbitrary model, take
elements BCPs roots instead taking nominals creating new roots
collapsing process. next sections, however, show transform
unraveling counter-model query remains collapsing-admissible
end collapsed forest model finite number
roots still counter model query. transformation much
convenient work real (strict) trees forests, use (strict) forest
quasi-interpretations.
next sections, also use following alternative characterization result
collapsing, comes handy subsequent proofs.
start defining so-called pruning forest quasi-interpretation, is,
roughly speaking, structure obtained deleting nodes, erased
course collapsing process anyway.
Definition 22 (Pruning). Let J strict forest quasi-model ALCOIFb knowledge
base K collapsing-admissible let J0 , J1 , . . . , J defined Definition 17.
pruning J (written prune(J )) obtained restricting J set J
defined follows: contains hw1 , w2 w3 J hw1 w2 , w3 J
hw1 w2 , w3 focus Ji .
4
use equivalence relation elements start descending BCPs
identical path sketches Definition 17 construct interpretation pruning
identifying equivalent nodes, also known factorization.
Definition 23 (Factorization). Let K ALCOIFb knowledge base, J strict forest
quasi-interpretation K collapsing-admissible, L = prune(J ).
factorization L (denoted L/ ) defined forest quasi-interpretation = (M , )
= {[] | L };
456

fiNominals, Inverses, Counting, Conjunctive Queries

con(K), = {[] | AL },
r rol(K), rM = {h[] , [ 0 ] | h, 0 rL },
nom(K), oM = [] NoL .
4
Note interpretation nominals well defined as, definition,
-instances -equivalence class.
ready establish wanted correspondence: collapsing forest
quasi-interpretation essentially obtained first pruning factorizing it.
Lemma 24. Let J strict forest quasi-model ALCOIFb knowledge base K
let J collapsing-admissible. collapse(J )
= prune(J )/ . Moreover new roots
collapse(J ) correspond -equivalence classes contain J -elements start
descending BCPs J .
Proof. Considering first claim, note definition collapsing procedure,
every (w, w0 ) collapse(J ) exactly one pair w1 , w2 w = w1 w2
(w1 , w2 w0 ) prune(J ) . Moreover, case 1 construction assures collapse(J ) contains one element every -equivalence class prune(J )/ . Hence mapping
: collapse(J ) prune(J )/ (w, w0 ) = [(w1 , w2 w0 )] bijection and, consequence construction, isomorphism.
second claim also direct consequence construction collapsing.

5. Quasi-Entailment Quasi-Models
section, provide characterization forest quasi-models mirrors query
entailment corresponding proper models. argumentation,
talk initial part tree, i.e., part left branches cut
fixed length. forest interpretation = (I , ) n IN, therefore denote
cutn (I) interpretation obtained restricting pairs (, w)
|w| n.
following lemma ensures case purified models, find finitely
many unraveling trees depth n look different.
Lemma 25. Let K consistent ALCOIFb knowledge base. purified
interpretation |= K and, every n IN, finitely many
non-isomorphic trees depth n.
Proof. Since K model assumption, Corollary 21 guarantees
purified model K. particular, forest model branching degree bounded
size cl(K).
compute maximal number non-isomorphic trees depth n
domain I. denote bound Tn . argumentation close one used
Levy Rousset (1998) definition tree blocking.
457

fiRudolph & Glimm

Let c = |cl(K)| r = |rol(K)|. first consider trees depth n = 0. 2c
choices different subsets concepts cl(K). n > 0, concept level 0
trigger generation new successor number successors
0 c. Assume, now, single role name r rol(K)
node level smaller n root tree depth n 1 exactly
c ) non-isomorphic sub-trees
c successors node. case, O(2c Tn1
depth n. Taking account node necessarily c successors,
c ) number nonchoose number 0 c, get bound O(2c cTn1
isomorphic sub-trees depth n. Finally, since one choice r roles,
c )r ). abbreviate 2c cr x rc rewrite
get bound O(2c (cTn1
n1
n
obtained bound Tn = O(x(Tn1 )a ). Unfolding yields Tn = O((x1+a+...+a )(T0 )a )
n
n
n
bounded O((xa )(2c )a ) = O((x2c )a ). expanding abbreviated symbols,
n
obtain bound Tn O((2c cr )(rc) ).
considerations, introduce notion anchored n-components.
meant certain substructures forest quasi-interpretations. first
place, substructures contain connected set nodes W 0 situated closely
together original structure, closeness witnessed fact elements W 0 descendants node distance n . Moreover
nodes 0 W 0 , anchored n-component may (but need to)
contain finite number descending BCPs starting 0 .
Definition 26 (Anchored Components). Let J forest quasi-interpretation J .
interpretation C called anchored n-component J witness C
created restricting J set W J obtained follows:
Let J subtree J started let J,n := cutn (J ). Select
subset W 0 J,n closed predecessors.
every 0 W 0 , let P finite set (possibly empty) descending BCPs p starting
0 let W0 contain nodes p P .

Set W = W 0 0 W 0 W0 .
4
think forest quasi-model J query q. following definition
lemma employ notion anchored n-components come notion quentailment (short quasi-entailment), criterion reflects query-entailment world
forest quasi-models.
Definition 27 (Quentailment). Let q conjunctive query ](q) = n J
forest quasi-model ALCOIFb knowledge base K. say J quentails q (written
J | q) if, V = var(q), J contains connected anchored n-components C1 , . . . , C`
C
according functions : V 2 following hold:
Q1 every x V , least one Ci , (x) 6=
Q2 A(x) q, (x) AJ i.
458

fiNominals, Inverses, Counting, Conjunctive Queries

Q3 every r(x, y) q Ci 1 (x) 2 (y)
h1 , 2 rJ .
Q4 If, x V , connected anchored n-components Ci Cj
(x) 0 j (x),
sequence Cn1 , . . . , Cnk n1 = nk = j
sequence 1 , . . . , k 1 = k = 0 well nm (x)
1 < k,
that, every 1 < k,
Cnm contains descending BCP p1 started ,
Cnm+1 contains descending BCP p2 started m+1 ,
p1 p2 path sketch.
union conjunctive queries u = q1 . . . qh , say J quentails u (written
J | u) J | q q {q1 , . . . , qh }.
4
Note anchored component may contain none, one several instantiations
variable x V . Intuitively, definition ensures, find matches query parts
fitted together identifying BCP-equal elements yield complete query match.
Lemma 28. Let u = q1 . . . qh union conjunctive queries K ALCOIFb
knowledge base.
1. model K, (I) | u implies |= u.
2. strict forest quasi-model J K collapsing-admissible, collapse(J ) |= u
implies J | u.
Proof.
1. Let q disjunct u (I) | q, V = var(q), C1 , . . . , C`
connected anchored n-components witnessing quentailment. use function
Tail Definition 12 exploit properties homomorphism. Note Tail
maps nodes (I) individual I, start descending BCPs
path sketches. Due condition Q4 Definition 27, implies,
every x V every 1 (x) 2 j (x), Tail(1 ) = Tail(2 ). Hence,
total function : V defined letting (x) = whenever Tail() =
(x) 1 `, well-defined. show query
match q examining atoms q:
every unary atom A(x), definition quentailment ensures
exist Ci Ci (x) AJ . Then, definition Tail,
follows (x) = Tail() AI .
Likewise, every binary atom r(x, y), definition quentailment ensures
exists Ci 1 , 2 Ci 1 (x) 2 (y)
well h1 , 2 rJ . Again, definition Tail, follows h(x), (y)i =
hTail(1 ), Tail(2 )i rI .
459

fiRudolph & Glimm

2. prove this, employ alternative characterization collapsings established
0
0
0
Lemma 24. Let 0 = (I , ) = prune(J )/ let : V match
q 0 . use construct anchored n-components functions needed
show J quentails q.
Let V V contain variables maps singleton -equivalence class.
define V = {V1 , . . . , Vm } finest partitioning V that,
x, V , x partition whenever r(x, y) q r rol(K).
Next, assign every partition V 0 V set QV 0 query atoms containing
variables V 0 . construct every V 0 anchored n-component CV 0
function V 0 (initialized yielding inputs) follows:
every x V 0 , let CV 0 contain J -element (x) = {}. Note
0
consists -equivalence classes elements J , i.e., {}
0
one -equivalence classes . Moreover, set V 0 (x) = V 0 (x) {}.
every r(x, y) QV 0 6 V 0 (x) = {}, let CV 0 contain additional element 0 (y) h, 0 rJ (existence assured definition
collapsing via factorization) elements descending BCP
prune(J ) starting (existence assured since [ 0 ] singleton class).
Moreover set V 0 (y) = V 0 (y) { 0 }.
Likewise, every r(x, y) QV 0 x 6 V 0 (y) = {}, let CV 0 contain
additional element 0 (x) h 0 , rJ (existence assured definition collapsing via factorization) elements shortest descending
BCP prune(J ) starting 0 (existence assured since [ 0 ] singleton
class). Moreover set V 0 (x) = V 0 (x) { 0 }.
furthermore construct, query atom contains variables V ,
anchored n-component Ca function (again initialized always return
) follows:
= r(x, y), let Ca contain two nodes 1 2 1 (x)
2 (y) h1 , 2 rJ (existence assured definition via factorization)
well prune(J )-descending BCP starting 1 shortest
prune(J )-descending BCP starting 2 .
= A(x), let Ca contain node (x) AJ (existence
assured definition via factorization) well shortest prune(J )-descending BCP starting .
Let C contain CV 0 Ca defined far. Note C already satisfies conditions
Q1-Q3 Definition 27. add anchored n-components
order satisfy condition Q4 well. Let C0 initially empty. x V
(x) non-singleton equivalence class two C , C C (x)
0 (x), that, since 0 -equivalence class (x),
sequence 1 , . . . , k J -nodes = 1 0 = k every
i+1 start descending BCP path sketch. enhance C0 one
anchored component per contains corresponding descending
460

fiNominals, Inverses, Counting, Conjunctive Queries

(x1 )

r

r



{o}
E




BC
E

f

(x2 )

g

(x5 )

r




BD
E

(x3 ) f

r

r



BC
E

BD
E

g

(x4 )

r



BC
E
g

f





E
r

C1


1 (x1 )
r


1 (x2 )

C2

BC
E

r



BD
2 (x5 )1 (x3 )
E

f

g

BC
E

BD
f
2 (x3 )
E

f

r

BC
2 (x4 )
E



E
..
.

r




BD
E

r




BC
E

g

BC
E

g

BC
E

BD
E

f

BD
E

f

BD
E

f

r
..

.



g

g
..

E
..
.

g
..

.

.

E
..
.

..

.

Figure 9: Correspondence entailment quentailment.
BCPs. Then, construction, elements CC0 constitute necessary anchored
n-components justify J quentails q and, thus, J quentails u.

example correspondence (query) entailment quentailment,
consider conjunctive query
q = {r(x1 , x2 ), s(x2 , x3 ), f (x4 , x3 ), s(x5 , x4 )}.
match query example model Figure 2 displayed upper
part Figure 9, witnesses |= q. lower part, anchored components C1
C2 according functions 1 2 establish (I) | q.

6. Limits Forest Transformations
introducing following constructions detail, try provide highlevel explanation convey intuition behind subsequent steps. mentioned before,
one major obstacles decision procedure conjunctive query entailment
461

fiRudolph & Glimm

DLs including inverses, nominals, cardinality restrictions (or alternatively functionality), potentially infinitely many so-called new nominals: domain elements
identified linked proper nominal via BCP.
However, show every model knowledge base satisfy
conjunctive query (i.e., every countermodel), nice countermodel
finitely many new nominals (in subsequent section, argue ensures
existence procedure terminates query entailed knowledge
base question). provide construction transforms arbitrary countermodel
nice one first unraveling quasi forest model, substituting new
nominals uncritical elements finally collapsing result back proper model.
this, find appropriate substitutes new nominals.
substitutes fit environment without introducing new nominals.
Due global cardinality constraints BCPs impose elements, existence infinitely many new nominals implies witnessing BCPs must get
longer longer, looking finite-distance neighborhood,
new nominals look like non-nominal domain elements. state affairs
exploited essentially constructing new domain elements environment-limits.
way, new domain elements characterized property
approximated arbitrary precision already present domain elements possibly without present domain.3 see following new
domain elements serve substitutes looking for.
Definition 29 (Limits Model). Let = (I , ) model
ALCOIFb knowledge base K. tree interpretation J said generated (written:
J C ), isomorphic restriction (I, ) elements {(, cw) | (, cw)
(I,) , c 6 H} H IN.
set limits (written lim I) set tree interpretations J
every k IN, infinitely many cutk (L)
= cutk (J )
L C .
4
Figure 10 displays one limit element example model.
following lemma gives useful properties limits. Besides rather obvious compatibility considerations respect knowledge base satisfaction, claim 3
Lemma 30 provides us pleasant useful insight root node limit
never part BCP all.
Lemma 30. Let K ALCOIFb knowledge base, K0 = nomFree(K), purified model
K, n fixed natural number. following hold:

1. Let L0 tree interpretation infinitely many L0 =
cutn (L) LC. Then, least one limit J lim cutn (J )
=
L0 .
2. Every J lim locally K0 -consistent apart root (, ).
3. analogy, consider fact real number approximated sequence rational
numbers, even irrational.

462

fiNominals, Inverses, Counting, Conjunctive Queries






BC
E



BD
E

f

BD
E



BC
E

g

BC
E

g

BC
E



BD
E

f

BD
E

f

BD
E

f

BD
E

BC
E

g

BC
E

g

BC
E

g

BC
E

g




.

r
..

r

r

r



r

f

..

f
.

..

f
.

..

f
.

..

BC
E
f

.

..

.

Figure 10: One limit model Fig. 2
3. every J lim holds root (, ) BCP (, w) J .
4. J lim contains node starting two backwards counting paths path sketches
s1 s2 , element unraveling holds: direct neighborhood
isomorphic starts descending BCP path sketch s1
also starts descending BCP path sketch s2 .
5. Every J lim collapsing-admissible.
Proof.
1. Let b branching degree I, let Dn (by assumption infinite) set
L0
= cutn (L) L C , let Jn contain L.
Starting k = n, iteratively increase k construct sets Jk Dk
tree interpretations Lk . way, inductively prove properties.
induction hypothesis know Dk infinite Lk Lk
=
cutk (M) Jk . Lemma 25, finitely many non-isomorphic
tree interpretations depth k + 1 branching degree b, partition
Jk finitely many sets Jk,1 , . . . , Jk,m every two M, M0 Jk,i
satisfy cutk+1 (M)
= cutk+1 (M0 ). Likewise, define classes Dk,1 , . . . , Dk,m
Dk = Dk,1 . . . Dk,m Dk,i L C L Jk,i . Now,
Dk infinite, one Dk,i must infinite well set Dk+1 = Dk,i
Jk+1 = Jk,i . Hence, know Dk+1 infinite Lk+1
Lk+1
= cutk+1 (M) Jk+1 .
Thus, established infinite sequence Ln , Ln+1 , . . . Li
= cuti (Lj )
j > i. Without loss generality, assume isomorphic nodes named
identically, i.e., even Li = cuti (Lj ) j > i. define J
(non-disjoint) union Li . way established structure J
cutk (J ) = Lk know every k infinitely many (namely
elements Dk ) cutk (L)
= Lk L C . Hence J limit
element desired properties.
2. Let (, w) w 6= node J . choose cut|w|+1 (L)
=
cut|w|+1 (J ) L C (by definition, even infinitely many
463

fiRudolph & Glimm

choose from). L contains node whose direct neighborhood isomorphic
(, w). However, L contained (I, ) |= K assumption,
locally K0 -consistent hence is. Therefore (, w) locally K0 -consistent J .
3. Assume contrary, i.e., J lim BCP root (, )
(, w) J (, w) NoJ nom(K). Since functionality
definition BCPs, BCP uniquely identifies one domain individual.
definition lim I, however, infinitely many satisfying cut|w| (L)
=
cut|w| (J ) J C infinite number individuals
counting path oI . contradiction.
4. Choose k maximum length two BCPs. definition limit,
contains element cut|w|+k (L)
= cut|w|+k (J ) L C . Now,
let 0 L element (with respect isomorphism) corresponds
J . Then, 0 origin two descending BCPs path sketches s1
s2 . Let Tail( 0 ) = 0 . Since path sketches descending BCPs uniquely identify one
domain individual, every node unraveling starts descending BCP
path sketch s1 must caused 0 well. Furthermore (as
direct neighborhoods isomorphic specific design choose function
Definition 12 renders successors non-isomorphic), successors
uniquely correspond neighbors 0 turn successors 0 .
turn implies that, every successor , one finds successor 0
isomorphic direct neighbourhood. Yet, synchronicity argument inductively
applied thereby iterated BCP. Thus, obtain also starts
descending BCP path sketch s2 .
5. define function ch : (cl(K) J ) J essentially like proof
Lemma 19, namely referring function choose. given element J
starts BCP length ` J , choose 0 cut||+` (L)
= cut||+` (J )
L C 0 . L contained (I, 0 ), proceed define ch(C, )
demonstrated proof Lemma 19.

defined limit elements convenient building blocks restructuring forest
quasi-interpretations, following definition provides first hints inside
structure one existing node (and successors) safely exchanged limit
element.
Definition 31 (n-Secure Replacement). Let K ALCOIFb knowledge base, model
K, J forest quasi-model K J . strict tree quasi-interpretation
J 0 lim called n-secure replacement
cutn ((J , )) isomorphic cutn (J 0 ),
every anchored n-component J 0 witness 0 , isomorphic anchored
n-component J witness .
464

fiNominals, Inverses, Counting, Conjunctive Queries

E







.
..

BC
E

BD
E

f

BD
E


=



BC
E

g

BC
E

g

BC
E



BD
E

f

BD
E

f

BD
E

f

BD
E

BC
E

g

BC
E

g

BC
E

g

BC
E

g

r
/



r

r



r



f

..

f
.

..

f
.

..

f
.






r

..

BC
E
f

.

..



BD
E
g



r

BC
E

BD
E

f



BC
E

g

BC
E



BD
E

f

BD
E

f

BC
E

g

BC
E

g

BC
E

r

r

r

f
..



r





.



..


r



r

.

BD
E
g

f
..

.

BD
E
g

f
..

E
..
.
E
..
.
E
..
.

.

.

Figure 11: Forest quasi-model (right) according 3-secure replacement (left).
J n-secure replacement lim I, call n-replaceable w.r.t. I, otherwise
call n-irreplaceable w.r.t. I.
4
Figure 11 displays 3-secure replacement considered unraveling example
model.
defined elements forest quasi-model eligible replaced
limit element, make sure many elements (actually defined
terms original model) exempt replaced.
Lemma 32. Every purified model ALCOIFb knowledge base K contains
finitely many distinct elements start BCP cause n-irreplaceable nodes
unraveling I.

Proof. Assume converse: let purified model K contain infinite set elements
giving rise n-irreplaceable nodes (I). must L0
infinite set D0 every d0 D0 generates L cutn (L)
= L (since
Lemma 25, finitely many non-isomorphic choices L0 ). set D0
used guide construction specific limit element J lim according Lemma
30.1. Now, element (, w) J starting BCP, let l(,w) length
shortest BCP starting (, w). Then, let k maximum l(,w)
individuals (, w) J start BCP |w| n. construction, D0
contains one element d00 generating L cutk (L)
= cutk (J ) (actually infinitely many).
choice k Lemma 30.4, conclude J n-secure replacement
irreplaceable (I)-node caused d00 contradicts fact d00 D.
know, elements forest quasi-model replaced suitable limit
element. following definition exactly tells us, replacement carried out:
respective element successors deleted limit element (together
successors) inserted position.
465

fiRudolph & Glimm

E



BC
E

BD
E

f



BC
E

g

BC
E

BD
E

f

BD
E

f



BC
E

g

BC
E

g

BC
E



BD
E

f

BD
E

f

BD
E

f

BD
E

BC
E

g

BC
E

g

BC
E

g

BC
E

g





..

.

r

f

..

r


r

r


r

r



r






r

f

..

.

f
.

..

f
.

E
..
.
E
..
.

..

BC
E
f

.

..

.

Figure 12: Result replacing element 3-secure replacement depicted Figure 11. inserted component highlighted.

Definition 33 (Replacement Step). Let K ALCOIFb knowledge base, model
K, J forest quasi-model K, i.e., J |= K0 = nomFree(K). Let (, w) J
n-replaceable w.r.t. J 0 according n-replacement (, w) lim root
(, ).
define result replacing (, w) J 0 interpretation R
0

J
00
00
J
J
0
0
R = J
red {(, ww ) | (, w ) } red = ( \ {(, ww ) | |w | > 1})
0

0
0
J
con(K0 ), AR = (AJ J
red ) {(, ww ) | (, w ) }
J
0
00
0
00
r rol(K0 ), rR = (rJ J
red red ){h(, ww ), (, ww )i | h(, w ), (, w )i
0
rJ }
4

Figure 12 displays result carrying replacement step example.
following lemma assures replacement described above, new
anchored n-components introduced, instead anchored n-components present
n-secure transformation present completely contained inserted limit
element.
Lemma 34. Let K ALCOIFb knowledge base, model K, J forest quasimodel K, i.e., J |= K0 = nomFree(K), let (, w) J n-replaceable w.r.t. I. Let
J 0 n-replacement (, w) root (, ) R result replacing (, w)
J 0 . following hold:
1. cutn ((J , (, w))) isomorphic cutn ((R, (, w))).
466

fiNominals, Inverses, Counting, Conjunctive Queries

2. n 1, R locally K0 -consistent.
3. Whenever R contains anchored n-component C, one J J 0 contains
anchored n-component isomorphic C.
Proof.

1. direct consequence Definitions 31 33.

2. make case distinction element-wise investigating local consistency R
(note K K0 simplified local consistency node (, v) R
depends node direct neighbors):
v = ww0 w0 6= : direct neighborhood (, v) R isomorphic direct neighborhood (, w0 ) J 0 (recall (, ) root
J 0 ). Lemma 30.2, J 0 locally K0 -consistent except possibly (, ). Hence
also (, v) locally K0 -consistent R.
v 6= ww0 w0 , i.e., (, v) affected replacement:
direct neighborhood (, v) changed replacement and, therefore,
neighborhoods (, v) J R coincide. J locally K0 -consistent
assumption, (, v) R.
v = w: case, direct neighborhood (, v) changed remained
isomorphic. follows preceding statement (34.1).
3. Let (0 , w0 ) witness C. distinguish three cases:
0 = w prefix w0 . Then, clearly C completely contained J 0 .
0 = w0 prefix w. Let C 0 structure obtained restricting C
elements form (, ww00 ) renaming every element (, ww00 )
(, w00 ), (, ) root J 0 . C 0 anchored n-component
J 0 witness (, ). Now, definition replacing, J must contain
isomorphic copy C 0 witness (, w). Since part C (consisting
nodes (0 , w0 ) w prefix w0 ) altered
replacement, conclude J must contain isomorphic copy C.
Neither above. Then, (0 , w0 ) subtree rooted (0 , w0 ) contained
J part J affected replacement. Then, clearly
also C contained J .

ready defining whole process restructuring forest quasi-model
essentially substituting many nodes possible appropriate limit elements.
Definition 35 (n-Secure Transformation). Let model ALCOIFb knowledge
base K J unraveling I. interpretation J 0 called n-secure transformation
J obtained (possibly infinitely) repeating following step:
Choose one unvisited w.r.t. tree-depth minimal node (, w) n-replaceable
w.r.t. I. Replace (, w) one n-secure replacements lim mark (, w)
visited.
4
467

fiRudolph & Glimm

B
B
E f C E g E





BD
E

f

BD
E



BC
E

g

BC
E

g

BC
E



BD
E

f

BD
E

f

BD
E

f

BD
E

BC
E

g

BC
E

g

BC
E

g

BC
E

g

r

r

r
.

r





..



r

BC
E

r





r







r

f

..

f
.

..

f
.

..

f
.

..

BC
E
f

.

..

.

Figure 13: Result collapsing forest quasi-model displayed Figure 12.
Note well-defined every node visited formerly
irreplaceable node ever becomes replaceable. Hence every k IN, initial segment
cutk (J ) current intermediate structure J already isomorphic initial segment
cutk (J 0 ) J 0 bounded number replacement steps, due fact involved
structures bounded branching degree.
now, whole effort might still look bit contrived pointless, however,
following lemma establishes bunch properties end allow us deduce
existence well-behaved countermodel whenever all.
show process unraveling, n-secure transformation collapsing preserves property model knowledge base (with right choice n)
also preserves property entailing conjunctive query. Moreover, model conversion process ensures resulting model contains finitely many new nominals
(witnessed bound length BCPs). Figure 13 illustrates properties
example model. Note two new nominals left whereas collapsing original
unraveling yields infinitely many.
Lemma 36. Let purified model ALCOIFb knowledge base K, J unraveling I, J 0 n-secure transformation J . following hold:
1. J 0 strict forest quasi-model K.
2. J 0 collapsing-admissible.
3. collapse(J 0 ) model K.
4. natural number J 0 contain node whose shortest
descending BCP length greater m.
468

fiNominals, Inverses, Counting, Conjunctive Queries

5. J 0 contains anchored n-component C, J contains anchored n-component
isomorphic C.
6. If, union conjunctive queries u = q1 . . . qh , J |6 u n >
maxq{q1 ,...,qh } ](q), J 0 |6 u.
7. If, union conjunctive queries u = q1 . . . qh , 6|= u
n > maxq{q1 ,...,qh } ](q), collapse(J 0 ) 6|= u.
Proof.
1. Let K0 = nomFree(K). Due Lemma 13, J strict forest quasi-model
K. Lemma 34.2, replacement step preserves local K0 -consistency results, thus, forest quasi-model K. Since n-replacement strict tree
quasi-interpretation also strictness preserved. induction follows every interpretation produced n-secure transformation procedure strict forest quasimodel K. every node J 0 , direct predecessor direct successors
changed finitely many replacement steps local K0 -consistency
depends solely neighbors. Hence J 0 also locally K0 -consistent.
2. Lemma 19, J collapsing-admissible, Lemma 30.5 every limit is. Moreover, obvious proofs propositions, possible define
respective ch-functions recurring original choose-function I, hence every
two elements (even different) unravelings limits start descending BCPs
identical path sketches correspond element whence
separate ch-functions compatible other. Therefore, replacing element unraveling yields strict forest quasi-model collapsing-admissible.
Applying argument inductively yields every intermediate strict forest
quasi-model n-secure transformation collapsing-admissible. Finally,
according ch-function stabilizes finitely many replacement steps (together
neighborhood considered elements), also J 0 collapsing-admissible.
3. follows two previous facts (36.1 36.2) together Lemma 20.
4. Consider set causing n-irreplaceable nodes J . Lemma 32,
finite. obtain D0 removing start descending
BCPs.
D0 , let dBCP() denote set descending BCPs starting choose

:= max0


min


|p|

pdBCP()

assume 0 shortest descending BCP length greater
m. Obviously, 0 6 D0 , must (, w) generated 0 nreplaceable. However, n-secure transformation n-replaceable elements
replaced elements start descending BCPs due
Lemma 30.3.
469

fiRudolph & Glimm

5. prove induction replacement steps n-secure transformation
process showing true every intermediate replacement result R0 .
claim J 0 follows fact that, every considered C (which
always finite), finite part cut` (J 0 ) relevant every `,
bounded number replacement steps cut` (R0 ) = cut` (J 0 )
every intermediate R0 .
base case (zero replacement steps carried out), find R0 = J , claim
trivially true.
assume claim established R shown R0
created replacing (, w) R J 00 . Lemma 34.3, know
one following case:
R contains C. Yet, apply induction hypothesis conclude also
J contains C claimed.
J 00 contains C. But, since C finite, already contained cutk (J 00 )
k and, J 00 limit element, find one cutk ((I, )) =
cutk (J 00 ). Since purified, find (, w) J corresponds , i.e.,
J contains isomorphic copy (I, ) turn contains isomorphic
copy C.
6. actually straightforward consequence preceding proposition
definition quentailment.
indirect proof, suppose J |6 u n > maxq{q1 ,...,qh } ](q) J 0 | u,
latter witnessed J 0 | q q {q1 , . . . , qh }. definition, latter assures
existence adequate anchored n-components J 0 . Then, applying preceding
proposition (36.5), obtain isomorphic copies anchored n-components contained J which, definition, means J | q and, therefore, J | u.
Hence, contradiction, proves claim.
7. prove indirectly, assume 6|= u, n > maxq{q1 ,...,qh } ](q), collapse(J 0 ) |=
u, witnessed collapse(J 0 ) |= q q {q1 , . . . , qh }.
Then, Lemma 28.2, follows J 0 | q. previous proposition (36.6),
conclude J | q, turn implies |= q Lemma 28.1. implies |= u,
contradiction.

able establish first milestone way showing finite representability countermodels.
Theorem 37. every ALCOIFb knowledge base K K 6|= u, forest model
K finitely many roots 6|= u. Moreover, bounded branching degree.

470

fiNominals, Inverses, Counting, Conjunctive Queries

Proof. Let u = q1 . . . qh . Since inconsistent knowledge base entails every query,
assume K consistent and, since K 6|= u, model K 6|= u.
Choose n > maxq{q1 ,...,qh } ](q) let J 0 obtained carrying n-secure
transformation (I) let 0 = collapse(J 0 ). know 0 model K (via
Lemma 36.3) 0 6|= u (by Lemma 36.7).
Lemma 36.4, know fixed natural number shortest
descending BCP started node J 0 shorter m. Note
finitely many path sketches length m. means every node J 0 starts
descending BCP assigned one path sketch. However, entails
finitely many elements (i.e., -equivalence classes) 0 contain
J 0 -elements starting descending BCPs J 0 . implies, via Lemma 24, 0 contains
finitely many roots.
fact 0 bounded branching degree direct consequence fact
initial unraveling bounded branching degree, replacement change
branching degree collapsings assured Lemma 20.

7. Finite Representations Models
section, show construct finite representation forest model
knowledge base finite number roots. show
finite representations used check query entailment. order this, use
technique similar blocking techniques used tableau algorithms (see, e.g.,
Horrocks & Sattler, 2007). tableau algorithm builds so-called completion graph
finite representation model. completion graph essentially structure
forest quasi-models. contains root nodes nominals occurring input
knowledge base plus root nodes new nominals start BCPs. (new
old) nominal root tree, relations occur direct neighbors within
tree, elements within tree root, roots. initial completion
graph contains nodes nominals occurring input knowledge base. Concepts
expanded according set expansion rules, new nodes added graph
expanding existential restrictions. New nominals added so-called NN-rule
whenever element within tree relationship inverse functional role
root node represents nominal input knowledge base, i.e., BCP
created. order obtain finite representation, tableau algorithms usually employ
cycle detection mechanism, called blocking. Otherwise depth trees
number new nominals might grow infinitely. logics expressive ALCOIFb,
blocking usually requires two pairs elements. notation, (non-root) node n
predecessor n0 blocks node predecessor m0 , hn0 , ni
= hm0 , mi. order
obtain real model finite representation, part n copied
appended infinitely often. use similar technique obtain finite representation
forest model. Since want preserve non-entailment, working pairs
elements sufficient. Instead, take length n query account use
isomorphic trees depth n define blocking. technique first employed
deciding query entailment ALCN role conjunctions (Levy & Rousset, 1998)
recently extended logics ALCHIQ, ALCHOQ, ALCHOI (Ortiz, 2008;
471

fiRudolph & Glimm

Ortiz et al., 2008a) extends, result, DLs SHIQ, SHOQ, SHOI (i.e.,
transitivity) long query contains simple roles.
forest quasi-interpretations, use isomorphisms forest interpretations
parts them.
Definition 38 (Isomorphism Forest Interpretations). Let K ALCOIFb
0
0
knowledge base = (I , ), 0 = (I , ) two forest interpretations K. Without
loss generality, assume root = (, ) extension
unique concept N occur con(K). 0 called isomorphic
0
w.r.t. K, written:
=K 0 , iff bijection : that:
1 successor 2 iff (1 ) successor (2 ) 1 , 2 ,
0

h1 , 2 rI iff h(1 ), (2 )i rI 1 , 2 r rol(K),
0

AI iff () AI con(K) {N | = (, ) }.
0

= oI iff () = oI nom(K).
4
Usually, omit subscript K
=K assume clear context.
Definition 39 (n-Blocking). Let n fixed natural number = (I , )
(, w) , w 6= forest interpretation ALCOIFb knowledge base K.
n-blocking-tree w.r.t. (, w), denoted blocknI (, w), interpretation obtained
restricting elements {(, ww0 ) | |w0 | n} {(, ) | (, ) }. n-blocking-tree
blocknI (, w) n-blocks n-blocking-tree blocknI (, ww0 )
1. blocknI (, w) blocknI (, ww0 ) disjoint domains except root elements,
2. bijection elements blocknI (, w) elements blocknI (, ww0 )
witnesses blocknI (, w)
= blocknI (, ww0 ),
3. descendant (, wv) (, w), inverse functional role f root
(, ) h(, wv), (, )i f .
node (, v) n-blocked, (, v) either directly indirectly n-blocked ; (, v)
indirectly n-blocked, one ancestors n-blocked; (, v) directly n-blocked none
ancestors n-blocked (, v) leaf n-blocking-tree blocknI (, ww0 )
n-blocked; case say (, v) (directly) n-blocked (, ww0 )
bijection witnessing
=.
Without loss generality, assume n-blocking-trees used minimal
w.r.t. order elements (cf. Definition 16).
forest interpretation = (I , ) K n-representation K
1. finite,
2. contains indirectly n-blocked nodes,
3. nom(K), one element form (, ) oI =
(, )I ,
472

fiNominals, Inverses, Counting, Conjunctive Queries

4. element directly n-blocked locally K-consistent.
4
Note n = 1 restrictive standard pairwise blocking since two trees
depth one need isomorphic blocking occurs, whereas standard blocking
already occurs two isomorphic pairs nodes. DLs expressive ALCOIFb,
however, n greater 0 (at least trees depth 1) want transform
n-representations models knowledge base. show knowledge
base n-representation fixed n and, afterwards, use
n-representation build model knowledge base.
Lemma 40. Let K consistent ALCOIFb knowledge base u = q1 . . . qh union
conjunctive queries n fixed natural number greater max1ih |qi |. K 6|= u,
n-representation K satisfy u.
Proof. assumption, K consistent K 6|= u. Then, Theorem 37, forest
model K finitely many roots branching degree bounded |cl(K)|,
q {q1 , . . . , qh } holds 6|= q. show find n-representation R I.
use similar argumentation Lemma 25 show finitely many
non-isomorphic n-blocking trees. denote bound Tn . Let c = |cl(K)|, r =
|rol(K)|, (finite) number roots I. root annotated
special concept N assumption. n = 0, 2c choices. n > 0,
element 0 c successors 0 relations roots.
roots 2c+m choices concepts. use 2cm bound choice
concepts roots clearly bounds choice non-roots well. non-root
node level smaller n root tree depth n 1 node
sub-tree relations root. Assuming single
cm ) number non-isomorphic
role name r rol(K), get bound O(2c cmTn1
sub-trees depth n relations roots. Since one
cm )r ). abbreviate 2c (cm)r
choice r roles, get bound O(2c (cmTn1
x cmr rewrite obtained bound Tn = O(x(Tn1 )a ). Unfolding
n
n1
n
n
n
yields Tn = O((x1+a+...+a )(T0 )a ) bounded O((xa )(2c )a ) = O((x2c )a ).
n
expanding abbreviated symbols, obtain bound Tn O((2c (cm)r )(cmr) ).
Together fact obtained collapsing relations elements
within tree root collapsings never inverse functional roles, shows
n-representation tree rooted node (, )
depth greater Tn , two nodes (, w) (, ww0 ) blocknI (, w)
n-blocks blocknI (, ww0 ), simply discard indirectly n-blocked nodes
obtain desired n-representation.
Since 6|= q n-representation restriction I, non-entailment q clearly
preserved.
Please note would obtain bound fixed bound
number new nominals (roots) beforehand cannot use standard tableau
algorithms obtain result. reason number new nominals
(roots) tableau algorithms depends length longest path blocking
473

fiRudolph & Glimm

occurs. n-blocking-trees, however, also consider relations back
roots, means blocking occurs later roots have.
hand, delaying blocking may lead introduction new roots. Due
cyclic argument, termination cannot guaranteed tableau algorithms unless
fixed bound number new nominals beforehand. also reason
tableau algorithm entailment conjunctive queries simple roles
query Calvanese et al. (2009) sound, complete, terminating SHIQ, SHOQ,
SHOI knowledge bases, guaranteed terminate SHOIQ knowledge
bases (transitivity, i.e., DL instead ALC impact
this).
show, obtain model knowledge base K nrepresentation K. use technique directly inspired tableau algorithms
resembles process building tableau complete clash-free completion
graph. particular tableau algorithm Ortiz et al. (Ortiz, 2008; Ortiz et al., 2008a)
similar also uses tree blocking.
Definition 41 (Models n-Representations). Let R = (R , R ) n-representation
0
0
ALCOIFb knowledge base K. Let = 11 , . . . ,
sequence pairs elements

R
0
. |s| denote length s. sequence s, set last (s) =
0

0

0

0

m+1
last (s) = . | m+1
denote sequence 11 , . . . ,
, m+1 .
m+1
set R-induced elements, denoted elem(R), inductively defined follows:

= (, ) R ,




elem(R).

elem(R), = (, w) R , n-blocked, successor last (s),
| elem(R).
elem(R), = (, w) R , directly n-blocked 0 R ,
0
successor last (s), | elem(R).
define interpretation = (I , ) induced R follows:
= elem(R),
con(K), AI iff last (s) AR ,
nom(K), = oI iff last (s) = ,
s, s0 r rol(K), rI =
{hs, s0 | s0 = |
{hs, s0 | = s0 |
{hs, s0 | s0 =
{hs, s0 | =

0

0


hlast (s), last (s0 )i rR }
hlast (s), last (s0 )i rR }



hlast (s),

0
h, last (s )i

rR }
rR }.
4

interpretation nominals well-defined since n-representations forest interpretations K (hence, unique root nominal) pairs = (, )
never appended sequences elem(R).
474

fiNominals, Inverses, Counting, Conjunctive Queries

Lemma 42. Let K consistent ALCOIFb knowledge base, u = q1 . . . qh union
conjunctive queries, n 1 fixed natural number greater max1ih |qi |. R
n-representation K R 6|= u, model K 6|= u.
proof essentially one Ortiz et al. (2008a), adapted case,
work completely interpretations. n-representations correspond completion
graphs models tableaux case.
Proof. Let interpretation induced R. Since n-representations contain
relations element within tree root inverse functional role definition,
functionality restrictions violated I. Further, since K simplified R forest
interpretation K elements apart (directly) n-blocked ones locally
K-consistent, quite straightforward element induced interpretation
locally K-consistent. Together restriction nominals (property 3), implies
model K. essentially principle one used prove
tableaux constructed completion graphs proper representations models
input knowledge base.
Assume, contrary shown, |= u. disjunct
q {q1 , . . . , qh } match q |= q. use construct match
q R shifting mapping variables parts direct counterpart
R upwards.
define match graph G q undirected graph containing node
(x) = x var(q) containing edge hs, s0
s, s0 atom r(x, y) q, (x) = s, (y) = s0 . call nodes
G correspond roots root nodes G (i.e., nodes = )
call nodes tree nodes. Note restriction G tree nodes set trees
refer G1 , . . . , Gk tree depth smaller n.
x var(q) (x) = ( root node G), set (x) = last ( ).
Note root node R.
Gi {G1 , . . . , Gk }, distinguish two situations:
1. Gi contains node last (s) 6= last (s) (i.e., Gi contains path within
n-blocking tree copy path starting node blocks). Due
use n-blocking, single tree Gi never cover one n-blocking
tree use nodes two n-blocking trees (leaving one
entering next one less n steps). node s0 Gi |s0 | < |s|
x var(q) (x) = s0 , set (x) = (last (s0 )). s0 Gi
|s0 | |s| x var(q) (x) = s0 , set (x) = last (s0 ).
2. Gi contains node last (s) 6= last (s) (i.e., Gi contains path lies
completely within n-blocking tree path outside n-blocking-tree
n-blocking-tree). node Gi x var(q) (x) = s, set
(x) = last (s).
definition , induced model R, n-blocking, immediately
that, A(x) q, (x) AR . show that, r(x, y) q, h(x), (y)i rR ,
proves R |= q. distinguish three cases:
475

fiRudolph & Glimm

1. (x) = R . (x) = = (, ) R . distinguish three cases
(y):
0

(a) (y) = 0 also root, (y) = 0 = (0 , ) R and, since match
q definition induced interpretation R,
h(x), (y)i = h, 0 rR .
0

(b) (y) successor (x) I, i.e., (y) = = | 0 . n-blocked
(y) = 0 = (0 , c) R c IN. Again, since match q
definition induced interpretation R,
h(x), (y)i = h, 0 rR .
0

(c) (y) neither root ((y) 6= 0 0 R ) successor (x)
0
((y) 6= | 0 0 R ). (y) belongs graph match component Gi (y) = last ((y)) (y) = (last ((y))). Since isomorphism
n-blocking trees also takes relations root nodes account
parts direct counterparts R, h(x), (y)i rR .
0

2. (x) = 6= R . cases (y) = 0 0 R
above. assume, therefore, (y) = s0 |s0 | > 1. definition I,
means either = s0 | 0 s0 = s| 0 , 0 R . assume s0 = s| 0 .
opposite case analogous. definition match graph G, component
Gi G contains s0 . distinguish two cases:
(a) component Gi contains node last (s) 6= last (s).
interesting case last ((y)) 6= last ((y)), i.e., = s0 . (x) =
(last (s)) (y) = last (s0 ). Since last (s0 ) 6= last (s0 ), last (s0 )
node directly n-blocks last (s0 ) and, definition bijection
, witnesses isomorphism, (x) = (last (s))
predecessor (y) = last (s0 ) and, definition R, h(x), (y)i
rR .
(b) component Gi contains node last (s) 6= last (s). (x) =
last ((x)) (y) = last ((y)). definition R, immediately
h(x), (y)i rR .
case, h(x), (y)i rR , implies R |= q contradicting initial
assumption.
Lemma 40 guarantees that, case K 6|= q, always finite n-representation
R K R 6|= q Lemma 42 guarantees R transformed
model K 6|= q. suffices show enumerate (finite)
n-representations K check whether entail disjunct union conjunctive
queries. Together semi-decidability result FOL, get following theorem.
Theorem 43. Let K ALCOIFb knowledge base u = q1 . . . qh union
conjunctive queries. question whether K |= u decidable.

476

fiNominals, Inverses, Counting, Conjunctive Queries

8. Conclusions
solved long-standing open problem deciding conjunctive query entailment
presence nominals, inverse roles, qualified number restrictions. shown
problem decidable providing decision procedure proving correctness.
Since approach purely decision procedure, computational complexity
problem remains open.
result also shows decidability entailment unions conjunctive queries
SHOIQ SROIQ (underlying OWL DL OWL 2) disallow non-simple roles
binary query predicates. thereby reached first important milestone towards
tackling problem conjunctive queries OWL 1 DL OWL 2 DL.
Entailment unions conjunctive queries also closely related problem
adding rules DL knowledge base, e.g., form Datalog rules. Augmenting
DL KB arbitrary Datalog program easily leads undecidability (Levy & Rousset,
1998). order ensure decidability, interaction Datalog rules
DL knowledge base usually restricted imposing safeness condition. DL+log
framework (Rosati, 2006a) provides least restrictive integration proposed far
Rosati presents algorithm decides consistency DL+log knowledge base
reducing problem entailment unions conjunctive queries. Notably, Rosatis
results (2006a, Thm. 11) imply consistency ALCHOIQb knowledge base
extended (weakly-safe) Datalog rules decidable entailment unions
conjunctive queries ALCHOIQb decidable, established.
Corollary 44. consistency ALCHOIQb+log-knowledge bases (both FOL
semantics non-monotonic semantics) decidable.
Another related reasoning problem query containment. Given schema (or TBox)
two queries q q 0 , q contained q 0 w.r.t. iff every interpretation
satisfies q also satisfies q 0 . well known query containment w.r.t.
TBox reduced deciding entailment unions conjunctive queries w.r.t.
knowledge base (Calvanese et al., 1998a). Decidability unions conjunctive query
entailment ALCHOIQb implies, therefore, also decidability query containment w.r.t.
ALCHOIQb TBox.
two obvious avenues future work. embark extending
results order allow non-simple roles query predicates. non-trivial task
current approach heavily relies certain locality query matches,
relinquished considering non-simple roles. hand, eager
determine associated computational complexities provide techniques form
basis implementable algorithms.

Acknowledgments
stay Oxford collaboration started, Sebastian Rudolph supported
scholarschip German Academic Exchange Service (DAAD). Continuative work
subject enabled funding ExpresST project German Research
Foundation (DFG).
477

fiRudolph & Glimm

Birte Glimm supported EPSRC project HermiT: Reasoning Large
Ontologies.
thank three anonymous reviewers numerous helpful comments.
thank Ian Pratt-Hartmann (unknowingly) smashing graphomata, Maria Magdalena Ortiz de la Fuente establishing competitive atmosphere, Yevgeny Kazakov
breath-taking discussions black holes, Boris Motik motivating considerations
value academic life, last least God providing us extraordinary
weather notably infinity.

References
Baader, F. (2003). Terminological cycles description logic existential restrictions.
Proceedings 18th International Joint Conference Artificial Intelligence
(IJCAI 2003), pp. 325330.
Baader, F., Brandt, S., & Lutz, C. (2005). Pushing EL envelope. Proceedings
19th International Joint Conference Artificial Intelligence (IJCAI 2005). Morgan
Kaufmann, Los Altos.
Baader, F., Calvanese, D., McGuinness, D. L., Nardi, D., & Patel-Schneider, P. F. (2003).
Description Logic Handbook. Cambridge University Press.
Bechhofer, S., van Harmelen, F., Hendler, J., Horrocks, I., McGuinness, D. L., PatelSchneider, P. F., & Stein, L. A. (2004). OWL web ontology language reference. Tech.
rep., World Wide Web Consortium. http://www.w3.org/TR/2004/REC-owl-ref-20040210/.
Calvanese, D., De Giacomo, G., Lembo, D., Lenzerini, M., & Rosati, R. (2005). DL-Lite:
Tractable description logics ontologies. Veloso, M. M., & Kambhampati, S.
(Eds.), Proceedings 20th National Conference Artificial Intelligence (AAAI
2005), pp. 602607. AAAI Press/The MIT Press.
Calvanese, D., De Giacomo, G., Lembo, D., Lenzerini, M., & Rosati, R. (2007). Tractable
reasoning efficient query answering description logics: DL-Lite family.
Journal Automated Reasoning, 39 (3), 385429.
Calvanese, D., De Giacomo, G., & Lenzerini, M. (1998a). decidability query
containment constraints. Proceedings 17th ACM SIGACT SIGMOD
Symposium Principles Database Systems (PODS 1998), pp. 149158. ACM Press
Addison Wesley.
Calvanese, D., De Giacomo, G., Lenzerini, M., Nardi, D., & Rosati, R. (1998b). Description
logic framework information integration. Proceedings 6th International
Conference Principles Knowledge Representation Reasoning (KR 1998).
Calvanese, D., Eiter, T., & Ortiz, M. (2007). Answering regular path queries expressive description logics: automata-theoretic approach. Proceedings 22th
National Conference Artificial Intelligence (AAAI 2007).
Calvanese, D., Eiter, T., & Ortiz, M. (2009). Regular path queries expressive description
logics nominals. Proceedings 21st International Joint Conference
Artificial Intelligence (IJCAI 2009), pp. 714720. AAAI Press/The MIT Press.
478

fiNominals, Inverses, Counting, Conjunctive Queries

Chandra, A. K., & Merlin, P. M. (1977). Optimal implementation conjunctive queries
relational data bases. Proceedings 9th ACM Symposium Theory
Computing (STOC 1977), pp. 7790. ACM Press Addison Wesley.
Eiter, T., Lutz, C., Ortiz, M., & Simkus, M. (2009). Query answering description logics
transitive roles. Proceedings 21st International Joint Conference
Artificial Intelligence (IJCAI 2009), pp. 759764. AAAI Press/The MIT Press.
Glimm, B., Horrocks, I., Lutz, C., & Sattler, U. (2008a). Conjunctive query answering
description logic SHIQ. Journal Artificial Intelligence Research, 31, 151198.
Glimm, B., Horrocks, I., & Sattler, U. (2008b). Unions conjunctive queries SHOQ.
Proceedings 11th International Conference Principles Knowledge
Representation Reasoning (KR 2008). AAAI Press/The MIT Press.
Glimm, B., & Rudolph, S. (2010). Status QIO: Conjunctive query entailment decidable.
Proceedings 12th International Conference Principles Knowledge
Representation Reasoning (KR 2010), pp. 225235. AAAI Press/The MIT Press.
Godel, K. (1929). Uber die Vollstandigkeit des Logikkalkuls. Ph.D. thesis, Universitat Wien.
Golbreich, C., Zhang, S., & Bodenreider, O. (2006). foundational model anatomy
OWL: Experience perspectives. Journal Web Semantics, 4 (3).
Goodwin, J. (2005). Experiences using OWL ordnance survey. Proceedings
1st OWL Experiences Directions Workshop (OWLED 2005), Vol. 188
CEUR Workshop Proceedings. CEUR (http://ceur-ws.org/).
Gradel, E. (2001). modal logics robustly decidable?. Paun, G., Rozenberg,
G., & Salomaa, A. (Eds.), Current Trends Theoretical Computer Science, Entering
21th Century, Vol. 2, pp. 393408. World Scientific.
Grahne, G. (1991). Problem Incomplete Information Relational Databases. Lecture
Notes Computer Science. Springer-Verlag.
Horrocks, I., & Sattler, U. (2005). tableaux decision procedure SHOIQ. Proceedings
19th International Joint Conference Artificial Intelligence (IJCAI 2005).
Horrocks, I., & Sattler, U. (2007). tableau decision procedure SHOIQ. Journal
Automated Reasoning, 39 (3), 249276.
Horrocks, I., Sattler, U., & Tobies, S. (2000). Reasoning Individuals Description
Logic SHIQ. McAllester, D. (Ed.), Proceedings 17th Conference Automated Deduction (CADE 2000), No. 1831 Lecture Notes Artificial Intelligence,
pp. 482496. Springer-Verlag.
Jet Propulsion Laboratory, C. I. o. T. (2006). Semantic web earth environmental
terminology (SWEET).. http://sweet.jpl.nasa.gov/.
Kazakov, Y. (2008). RIQ SROIQ harder SHOIQ. Proceedings
11th International Conference Principles Knowledge Representation
Reasoning (KR 2008). AAAI Press/The MIT Press.
Kazakov, Y., & Motik, B. (2008). resolution-based decision procedure SHOIQ.
Journal Automated Reasoning, 40 (23), 89116.
479

fiRudolph & Glimm

Krotzsch, M., Rudolph, S., & Hitzler, P. (2007). Conjunctive queries tractable fragment
OWL 1.1. Proceedings 7th International Semantic Web Conference (ISWC
2007), Vol. 4825 Lecture Notes Computer Science, pp. 310323. Springer-Verlag.
Krotzsch, M., Rudolph, S., & Hitzler, P. (2008). ELP: Tractable rules OWL 2.
Proceedings 8th International Semantic Web Conference (ISWC 2008), Vol.
5318 Lecture Notes Computer Science, pp. 649664. Springer-Verlag.
Lacy, L., Aviles, G., Fraser, K., Gerber, W., Mulvehill, A., & Gaskill, R. (2005). Experiences
using OWL military applications. Proceedings 1st OWL Experiences
Directions Workshop (OWLED 2005). CEUR (http://ceur-ws.org/).
Levy, A. Y., & Rousset, M.-C. (1996). CARIN: representation language combining horn
rules description logics. Proceedings 12th European Conference Artificial Intelligence (ECAI 1996), pp. 323327.
Levy, A. Y., & Rousset, M.-C. (1998). Combining horn rules description logics
CARIN. Artificial Intelligence, 104 (12), 165209.
Lutz, C. (2008). complexity conjunctive query answering expressive description
logics. Proceedings International Joint Conference Automated Reasoning
(IJCAR 2008), pp. 179193. Lecture Notes Computer Science.
McGuinness, D. L., & Wright, J. R. (1998). industrial strength description logic-based
configuration platform. IEEE Intelligent Systems, 13 (4).
Motik, B., Shearer, R., & Horrocks, I. (2009). Hypertableau reasoning description logics. Submitted journal. http://www.hermit-reasoner.com/publications/
msh08hypertableau-journal.pdf.
Ortiz, M. (2008). Extending CARIN description logics SH family. Proceedings Logics Artificial Intelligence, European Workshop (JELIA 2008), pp.
324337. Lecture Notes Artificial Intelligence.
Ortiz, M., Calvanese, D., & Eiter, T. (2008a). Data complexity query answering
expressive description logics via tableaux. Journal Automated Reasoning, 41 (1),
6198.
Ortiz, M., Simkus, M., & Eiter, T. (2008b). Conjunctive query answering sh using
knots. Proceedings 2008 Description Logic Workshop (DL 2008). CEUR
(http://ceur-ws.org/).
Pratt-Hartmann, I. (2009). Data-complexity two-variable fragment counting
quantifiers. Forthcoming Information Computation. http://arxiv.org/abs/0806.
1636.
Rosati, R. (2006a). DL+log: Tight integration description logics disjunctive datalog.
Proceedings 10th International Conference Principles Knowledge
Representation Reasoning (KR 2006), pp. 6878.
Rosati, R. (2006b). decidability finite controllability query processing
databases incomplete information. Proceedings 25th ACM SIGACT
SIGMOD Symposium Principles Database Systems (PODS 2006), pp. 356365.
ACM Press Addison Wesley.
480

fiNominals, Inverses, Counting, Conjunctive Queries

Rosati, R. (2007a). limits querying ontologies. Proceedings 11th International Conference Database Theory (ICDT 2007), Vol. 4353 Lecture Notes
Computer Science, pp. 164178. Springer-Verlag.
Rosati, R. (2007b). conjunctive query answering EL. Proceedings 2007
Description Logic Workshop (DL 2007). CEUR Workshop Proceedings.
Rudolph, S., Krotzsch, M., & Hitzler, P. (2008). Terminological reasoning SHIQ
ordered binary decision diagrams. Proc. 23rd National Conference Artificial
Intelligence (AAAI 2008), pp. 529534. AAAI Press/The MIT Press.
Sidhu, A., Dillon, T., Chang, E., & Sidhu, B. S. (2005). Protein ontology development using
OWL. Proceedings 1st OWL Experiences Directions Workshop (OWLED
2005), Vol. 188 CEUR Workshop Proceedings. CEUR (http://ceur-ws.org/).
Sirin, E., Parsia, B., Cuenca Grau, B., Kalyanpur, A., & Katz, Y. (2007). Pellet: practical
OWL-DL reasoner. Journal Web Semantics, 5 (2).
Tessaris, S. (2001). Questions answers: Reasoning querying Description Logic.
PhD thesis, University Manchester.
Tsarkov, D., & Horrocks, I. (2006). FaCT++ description logic reasoner: System description.
Proceedings International Joint Conference Automated Reasoning (IJCAR
2006), Vol. 4130 Lecture Notes Computer Science, pp. 292 297. Springer-Verlag.
van der Meyden, R. (1998). Logical approaches incomplete information: survey.
Logics Databases Information Systems, pp. 307356. Kluwer Academic Publishers.
Vardi, M. Y. (1997). modal logic robustly decidable?. Descriptive Complexity
Finite Models: Proceedings DIMACS Workshop, Vol. 31 DIMACS: Series
Discrete Mathematics Theoretical Computer Science, pp. 149184. American
Mathematical Society.
W3C OWL Working Group (2009).
OWL 2 web ontology language document
overview. Tech. rep., World Wide Web Consortium. http://www.w3.org/TR/2009/
REC-owl2-overview-20091027/.
Wolstencroft, K., Brass, A., Horrocks, I., Lord, P., Sattler, U., Turi, D., & Stevens, R.
(2005). Little Semantic Web Goes Long Way Biology. Proceedings
5th International Semantic Web Conference (ISWC 2005).

481

fiJournal Artificial Intelligence Research 39 (2010) 301-334

Submitted 2/10; published 9/10

Model-Based Active Testing Approach
Sequential Diagnosis
Alexander Feldman

a.b.feldman@tudelft.nl

Delft University Technology
Mekelweg 4, 2628 CD, Delft, Netherlands

Gregory Provan

g.provan@cs.ucc.ie

University College Cork
Department Computer Science
College Road, Cork, Ireland

Arjan van Gemund

a.j.c.vangemund@tudelft.nl

Delft University Technology
Mekelweg 4, 2628 CD, Delft, Netherlands

Abstract
Model-based diagnostic reasoning often leads large number diagnostic hypotheses. set diagnoses reduced taking account extra observations (passive
monitoring), measuring additional variables (probing) executing additional tests (sequential diagnosis/test sequencing). paper combine approaches
techniques Automated Test Pattern Generation (ATPG) Model-Based Diagnosis
(MBD) framework called Fractal (FRamework ACtive Testing ALgorithms).
Apart inputs outputs connect system environment, active
testing consider additional input variables sequence test vectors
supplied. address computationally hard problem computing optimal control assignments (as defined Fractal) terms greedy approximation algorithm called
FractalG . compare decrease number remaining minimal cardinality
diagnoses FractalG two Fractal algorithms: FractalATPG
FractalP . FractalATPG based ATPG sequential diagnosis FractalP
based probing and, although active testing algorithm, provides baseline comparing lower bound number reachable diagnoses Fractal algorithms.
empirically evaluate trade-offs three Fractal algorithms performing
extensive experimentation ISCAS85/74XXX benchmark combinational circuits.

1. Introduction
Combinational Model-Based Diagnosis (MBD) approaches (de Kleer & Williams, 1987)
often lead large number diagnoses, exponential number components,
worst-case. Combining multiple sensor readings (observation vectors) (Pietersma &
van Gemund, 2006) helps limited number cases approach inherently
passive, i.e., situations observations repeat (for example,
systems stationary, pending reconfiguration).
Sequential diagnosis algorithms (Shakeri, 1996) used alternative
passive approach, better decay number diagnostic hypotheses.
decay rate depends tests test dictionary matrix, bounded
c
2010
AI Access Foundation. rights reserved.

fiFeldman, Provan, & van Gemund

results tests binary outcomes. Algorithms sequential diagnosis suffer
number limitations. Early approaches assume single-faults multiple-fault
sequential diagnosis super-exponential (p2 harder) (Shakeri, Raghavan, Pattipati, &
Patterson-Hine, 2000).
observations (test outcomes) known advance, goal diagnostician
create policy minimizes diagnostic uncertainty average, i.e., one aims
minimizing average depth test tree. Pattipati Alexandridis (1990) shown
certain conditions (e.g., unit test costs equal prior fault probabilities) onestep look-ahead policy leads optimal average depth test tree; de Kleer, Raiman,
Shirley (1992) shown one-step look-ahead delivers good practical results
range combinational circuits.
paper proposes framework, called Fractal (FRamework ACtive Testing
ALgorithms) comparing different computational vs. optimality trade-offs various
techniques reducing diagnostic uncertainty. Fractal algorithms start
initial set multiple-fault diagnostic hypotheses (this initial set contain possible hypotheses) compute actions reducing initial set to, possible, single diagnostic
hypothesis (candidate). case probing (de Kleer & Williams, 1987), action consists measuring internal (hidden) variable. case sequential diagnosis (ATPG),
action consists applying set input (control) assignments disambiguate
health state component appears faulty initial diagnostic hypotheses. case active testing action consists applying set input (control)
assignments optimally reduce initial set hypotheses. framework active testing sequential diagnosis approaches differ compute input
(control) assignments. measure optimality algorithms computing speed
decay initial set hypotheses computational efficiency.
environment



system
CTL
FRACTAL

Figure 1: Active testing dataflow Fractal
Fractal, study influence input (IN) output (OUT) variables,
also control (CTL) variables. Controls similar inputs, except modified
users system connected environment. Use models first principles
controls Fractal allows us eliminate need designing explicit tests test
dictionaries. algorithms implicitly create test matrices leading optimal decay based
built-in testing capabilities system. call approach active testing;
technique using models first principles controls creating test sequences
reduce diagnostic uncertainty system. architecture use
Fractal active testing shown Fig. 1.
302

fiA Model-Based Active Testing Approach Sequential Diagnosis

reliable component failure rates may problematic obtain, assume equally
likely small prior probabilities failure measure diagnostic uncertainty
number Minimal Cardinality (MC) diagnoses. Fractal modified use arbitrary
failure probabilities even components likely faulty healthy.
would necessitate modifications algorithms (e.g., change bias
importance sampling, etc.). addition simplifying modeling, equiprobable failure
rates assumption also computational advantages. shown equal
small prior probabilities failure, diagnostic entropy, e.g., used de Kleer
Williams (1987), computed directly number MC diagnoses.
computational complexity deterministic algorithms sequential diagnosis increases respect fault-cardinality number tests (the size
test dictionary). enable performance scale real-world problems, may
high fault-cardinality large number tests, propose FractalGa low-cost greedy
stochastic approach maintains exponential decay number MC diagnoses. Instead assuming single faults timing out, FractalG may result suboptimal still
exponential decay.
study performance FractalG compared two alternatives: (1) FractalATPG , implements sequential diagnosis based Automated Test Pattern Generation (ATPG), (2) FractalP, implements probing (de Kleer & Williams, 1987).
ATPG successfully used electronic industry compute sets inputs
test component VLSI circuit. considered ATPG-based approach natural attempt reduce diagnostic ambiguity computing inputs
disambiguate status single component appears majority
diagnostic hypotheses.
FractalATPG derived sequential testing, deterministic myopic, allows us evaluate well single-step lookahead approach works given model.
Although probing classified technique sequential diagnosis, viewed
process generating tests using additional control circuitry (machine human)
execute probe output reveals internal variable. significance
shows lower bound number diagnoses achievable model extended
unlimited CTL circuitry.
contributions follows:
devise approach reducing diagnostic uncertainty, called active testing,
generalizes sequential diagnosis MBD, allows combination multiple passive
sensor readings, require explicit tests test dictionaries.
design FractalATPGa single-step look-ahead algorithm based ATPGfor
solving active testing problem.
design implement FractalGa greedy approximation algorithm active
testing overcomes limitations FractalATPG offers trade-off computational complexity vs. optimality reducing diagnostic uncertainty.
compare FractalG FractalATPG .
implement FractalP use computationally efficient, myopic (one-step
lookahead), easy-to-analyze baseline technique reducing diagnostic uncertainty.
303

fiFeldman, Provan, & van Gemund

Although FractalP technically active testing algorithm, implementation
probing active testing common framework unified experimentation
help understand cost vs. performance trade-offs (active passive) testing
vs. probing strategies.
present extensive empirical data 74XXX/ISCAS85 circuits, enable us
evaluate FractalATPG, FractalG, FractalP terms ability
reduce number remaining diagnoses according geometric decay function.
paper organized follows. Section 2 introduces related work. Section 3 presents basic MBD notions, concept remaining number diagnoses framework sequential diagnosis. Section 4 introduces stochastic sampling-based algorithm computing
expected number cardinality-minimal diagnoses. Section 5 describes FractalATPG,
FractalG, FractalP algorithms. Section 6 shows experimental results. Finally,
Sec. 7 summarizes paper discusses future work.

2. Related Work
Early work aimed diagnostic convergence de Kleer Williams (1987) compute
probe sequence reducing diagnostic entropy using myopic search strategy. Unlike
work, active testing assume probes available, indirectly
exposed diagnosis based test vectors, offers automated solution.
Generating test vectors deduce faults received considerable attention. Automatic
test pattern generation (ATPG) aims verifying particular, single-faults (Stephan, Brayton, & Sangiovanni-Vincentelli, 1996). ATPG differs active testing vectors
specific particular single-faults, whereas active testing generates sequence vectors
isolate unknown, multiple-faults, much harder problem.
Table 1: Properties techniques sequential diagnosis
Technique

Model

User Actions

Automatic
Tests

Performance

Cost

Passive monitoring
Sequential diagnosis
FractalATPG
FractalG
Probing (FractalP )

first principles
test dictionary
first principles
first principles
first principles

apply test
apply controls
apply controls
measure internals


yes
yes
-

variable1
good
variable3
good
binary search

low
variable2
medium
high
medium

1
2
3

Depends environment (IN/OUT data).
Speed deteriorates rapidly multiple-faults.
Depends model topology.

Table 1 summarizes properties various techniques sequential diagnosis discussed paper. Fractal eliminates need using tools building tests test
dictionaries, ones proposed Deb, Ghoshal, Malepati, Kleinman (2000).
approach tests test dictionaries automatically constructed design speci304

fiA Model-Based Active Testing Approach Sequential Diagnosis

fications models. time, Fractal delivers comparable better diagnostic
convergence reasonable computational price.
Active testing bears resemblance sequential diagnosis, also generates
sequence test vectors (Pattipati & Alexandridis, 1990; Raghavan, Shakeri, & Pattipati,
1999; Tu & Pattipati, 2003; Kundakcioglu & Unluyurt, 2007). principal difference
sequential diagnosis fault dictionary used (fault matrix). pre-compiled
dictionary following drawback: order limit (exponential) size dictionary, number stored test vectors extremely small compared test vector
space. severely constrains optimality vector sequence generated;
contrast, active testing computes arbitrary test vectors fly using model-based
approach. Furthermore, matrix specifies tests binary (pass/fail) outcome, whereas active testing exploits systems outputs, leading faster diagnostic
convergence. addition, allow inputs dynamic, makes framework
suitable online fault isolation.
sequential diagnosis problem studies optimal trees cost associated
test (Tu & Pattipati, 2003). costs equal, shown
optimization problem reduces next best control problem (assuming one uses information entropy). paper diagnostician given sequence tries
compute next optimal control assignment would try minimize expected number
remaining diagnoses |(S)|.
task harder Raghavan et al. (1999), since diagnosis task NPhard, even though diagnosis lookup uses fault dictionary; case compute
new diagnosis every test. Hence NP-hard sequential problem interleaved
complexity diagnostic inference step (in case complexity
diagnosis p2 -hard). Apart above-mentioned differences, note optimal
test sequencing infeasible size problems interested.
Model-Based Testing (MBT) (Struss, 1994) generalization sequential diagnosis.
purpose MBT compute inputs manifesting certain (faulty) behavior. main
differences active testing approach MBT (1) assumes inputs
controllable (2) MBT aims confirming single-fault behavior opposed maximally
decreasing diagnostic uncertainty.
Brodie, Rish, Ma, Odintsova (2003) cast models terms Bayesian networks.
notion entropy size diagnosis space, whereas Brodie et al. use decisiontheoretic notions entropy guide test selection. Brodie et al. extend past Bayesian
diagnostic approach (Rish, Brodie, & Ma, 2002) sequential construction probe sets
(probe sets collections of, example, pings subset nodes computer network). approach Brodie et al. limited networks although extended
modifying type Bayesian network shown Rish et al.; modification, however,
would necessitate computationally expensive Bayesian reasoning achieving good
approximation results probable explanations.
approach Brodie et al. (2003) compute modifications target
network topology propose control actions (for example, network server
fails respond dialed-up modem checked technician
higher cost). similarity Fractal active probing approaches
attempt reducing diagnostic uncertainty analyzing future state system
305

fiFeldman, Provan, & van Gemund

function action (sending set probes active probing application
control inputs FractalG FractalATPG).
solve different problem Heinz Sachenbacher (2008), Alur, Courcoubetis, Yannakakis (1995). approaches assume non-deterministic
model defined automaton. contrast, framework assumes static system (plant
model) must compute temporal sequence tests best isolate diagnosis.
Esser Struss (2007) also adopt automaton framework test generation, except that, unlike Heinz Sachenbacher (2008) Alur et al. (1995), transform
automaton relational specification, apply framework software diagnosis.
automaton-based framework accommodates general situations ours,
possibility systems state transition may uniquely determined state transition input, and/or systems state may
associated several possible observations. MBD framework, test consists
instantiation several variables, corresponds notion test sequence
within automaton framework Heinz Sachenbacher. framework Esser
Struss requires modeling possible faults, whereas Fractal works weak
strong-fault models1 . Interestingly, shown Esser Struss, modeling abnormal software behavior derived extent software functional requirements.
makes framework suitable software systems.
recent approach active diagnosis described Kuhn, Price, de Kleer, Do,
Zhou (2008), additional test vectors computed optimize diagnosis
system (a copier) remains operational. work differs plans (roughly
analogous test sequences) probability failure computed statically,
plan remains unmodified even fails achieve desired goal (a manifestation
failure probability close ). Conversely, Fractal dynamically computes next-best
control settings game-like manner. biggest difference Fractal
approach Kuhn et al. use models. Fractal compatible traditional
MBD (de Kleer & Williams, 1987) reuse existing models first principles
pervasive approach Kuhn et al. uses automaton set possible actions.
approach Kuhn et al. (2008) uses existing MBD planning algorithms,
integrates existing approaches; contrast, Fractal introduces new control algorithms
reuses external diagnostic oracle. advantage pervasive diagnosis approach
use planning engine generates complete sequence actions, opposed
one-step lookahead FractalG. Depending planning formalism, complexity
pervasive diagnosis dominated planning module, complex
computational task Fractal diagnosis. pervasive diagnosis
paper, however, report good average-case computational efficiency benchmark problems.
Last, paper Kuhn et al. limited single-fault diagnoses, although pervasive
diagnosis framework generalized multiple faults.
Feldman, Provan, van Gemund (2009a) introduce early version FractalG.
paper (1) generalizes Fractal framework, (2) introduces FractalATPG
FractalP, (3) extends experimental results, (4) provides comparison
different Fractal approaches.
1. Weak-fault models (also known models ignorance abnormal behavior) strong-fault models
discussed Feldman, Provan, van Gemund (2009b).

306

fiA Model-Based Active Testing Approach Sequential Diagnosis

3. Concepts Definitions
discussion starts introducing relevant MBD notions. Central MBD, model
artifact represented propositional Wff set variables V . define
four subsets variables: assumable, observable 2 , control, internal variables.
gives us initial definition:
Definition 1 (Active Testing System). active testing system ATS defined ATS =
hSD, COMPS, CTL, OBSi, SD propositional Wff variable set V , COMPS
OBS CTL V , COMPS, OBS, CTL subsets V containing assumable,
observable, control variables, respectively.
set internal variables denoted INT, INT = V \ {COMPS OBS CTL}.
Throughout paper assume OBS, COMPS, CTL disjoint, SD 6|=.
Sometimes convenient (but necessary) split OBS non-controllable inputs
outputs (OBS = OUT, = ).
3.1 Running Example
use Boolean circuit shown Fig. 2 running example illustrating
notions algorithm shown paper. 2-to-4 line demultiplexer consists
four Boolean inverters four and-gates.


b

h1

h3

p

q

h2

h4

r



h5



h6

h7

h8

o1

o2

o3

o4

Figure 2: demultiplexer circuit
expression h (o i) models inverter, variables i, o, h represent input, output, health respectively. Similarly, and-gate modeled h
(o i1 i2 i3 ). propositional formulae copied gate Fig. 2
variables subscripted renamed way ensure proper disambiguation
2. MBD literature assumable variables also referred component, failure-mode,
health variables. Observable variables also called measurable variables.

307

fiFeldman, Provan, & van Gemund

connect circuit. result following propositional model:

[h1 (a p)] [h2 (p r)]




[h

3 (b q)] [h4 (q s)]


h5 (o1 p q)
SD =
h

6 (o2 r q)



h7 (o3 p s)


h8 (o4 r s)

(1)

set assumable variables COMPS = {h1 , h2 , . . . , h8 }, observable variables
OBS = {a, b, o1 , o2 , o3 , o4 }, set control variables singleton CTL = {i}. Note
conventional selection sign health variables h1 , h2 , . . . , hn . authors
use ab abnormal.
3.2 Diagnosis
traditional query MBD computes terms assumable variables, explanations system description observation.
Definition 2 (Diagnosis). Given system ATS, observation variables
OBS, assignment variables COMPS, diagnosis iff SD 6|=.
set diagnoses SD observation denoted (SD, ). cardinality
diagnosis, denoted ||, defined number negative literals .
Continuing running example, consider observation vector 1 = b o4 .
total 256 possible assignments variables COMPS |(SD, 1 )| =
200. Example diagnoses 1 = h1 h2 . . . h7 h8 2 = h1 h2 h3 h4
h5 h6 h7 h8 . write sometimes diagnosis set notation, specifying set
negative literals only. Thus 2 would represented D2 = {h1 , h4 }.
Definition 3 (Minimal-Cardinality Diagnosis). diagnosis defined MinimalCardinality (MC) diagnosis exists | | < | |.
selection minimality criterion impossible compute diagnoses
set MC diagnoses without inference. MC diagnoses, however, often
used practice due prohibitive cost computing representation diagnoses
system observation (e.g., subset-minimal diagnoses).
Consider observation vector 2 = b o1 o4 . 6 MC diagnoses
cardinality 2 consistent SD 2 , counting MC diagnoses common
problem MBD.
number MC diagnoses system ATS observation denoted
| (SD, )|, (SD, ) set MC diagnoses SD . Given system
ATS, observation sequence defined k-tuple terms = h1 , 2 , . . . , k i,
(1 k) instantiation variables OBS.
Throughout paper, assume health system test
change test (i.e., inputs fault produce outputs) call
assumption stationary health.
308

fiA Model-Based Active Testing Approach Sequential Diagnosis

Lemma 1. Given system ATS, stationary health state components ,
observation sequence S, follows (SD, 1 ) (SD, 2 ) . . . (SD, k ).
Proof. statement follows immediately stationary health assumption
Def. 2.
Lemma 1 applied cases diagnoses considered.
compute subset-minimal diagnoses weak-fault model, example, intersection
operator redefined handle subsumptions. handle non-characterizing sets
diagnoses3 (e.g., MC first diagnoses), provide following definition.
Definition 4 (Consistency-Based Intersection). Given set diagnoses SD ,
posteriori observation , intersection diagnoses SD , denoted
(D, ), defined set (D D) holds
SD 6|=.
straightforward generalize definition observation sequence S.
Definition 5 (Remaining Minimal-Cardinality Diagnoses). Given diagnostic system ATS
observation sequence S, set remaining diagnoses (S) defined (S) =
( ( ( (SD, 1 ), 2 ), ), k ).
use |(S)| instead precise diagnostic entropy defined de Kleer
Williams (1987) subsequent works, allows low-complexity estimations (discussed
Sec. 4). particular, diagnoses minimal-cardinality failure probability
component same, gain diagnostic entropy directly
computed |(S)|.

4. Computing Expected Number MC Diagnoses
Active testing aims minimize expected number diagnoses result
possible set outputs may occur given control vector. section
present algorithm approximate expectation.
compute expected number diagnoses set observable variables
(M OBS). initial observation set MC diagnoses = (SD, ) modify
probability density function subsequent outputs (observations), i.e., subsequent
observation changes likelihood. (non-normalized) posteriori probability
observation , given function computes set MC diagnoses initial
observation , is:
Pr( |SD, ) =

| ( (SD, ), )|
| (SD, )|

(2)

formula computes probability given priori set diagnoses restricting
possible outputs, i.e., assume probability ratio number
3. characterizing set diagnoses, example set subset-minimal diagnoses, loosely defined
set diagnoses (complete) set diagnoses constructed without using
system description information.

309

fiFeldman, Provan, & van Gemund

remaining diagnoses number initial diagnoses. practice, many
Pr( |SD, ) = 0, certain fault heavily restricts possible outputs
system (i.e., set remaining diagnoses numerator empty).
expected number remaining MC diagnoses variable set , given initial
observation , weighted average intersection sizes possible instantiations variables (the weight probability output):

E (SD, |) =

X



| (D, )| Pr( |SD, )
X



Pr( |SD, )

(3)

= (SD, ) set possible assignments variables .
Replacing (2) (3) simplifying gives us following definition:
Definition 6 (Expected Minimal-Cardinality Diagnoses Intersection Size). Given system ATS initial observation , expected remaining number MC diagnoses
E (SD, OBS|) defined as:

E (SD, OBS|) =

X

OBS

X

| ( (SD, ), )|2

OBS

| ( (SD, ), )|

(4)

OBS set possible assignments variables OBS.
Two algorithms presented paper compute expected number remaining
MC diagnoses one variable. result expectation expression (4) simplifies to:
E (SD, v|) =

| ( (SD, ), v)|2 + | ( (SD, ), v)|2
| ( (SD, ), v)| + | ( (SD, ), v)|

(5)

complexity computing (5) depends length sequence S, complexity MC oracle computing (SD, ), complexity intersection
algorithm.
4.1 Computing Expectation Using Importance Sampling
overcome computational complexity evaluating expectation, employ
stochastic algorithm based importance sampling. key insight allows us
build fast method computing expected number remaining diagnoses
prior observation (and respectively set MC diagnoses) shifts probability
outputs. Hence, algorithm samples possible input assignments (recall
basic modeling assumption inputs equally likely) counts number
different observations, given set prior diagnoses, produce good approximation.
next introduce algorithm approximating expected number remaining
diagnoses.
310

fiA Model-Based Active Testing Approach Sequential Diagnosis

Algorithm 1 Approximate expectation (S)
1: function Expectation(ATS, , D) returns real
inputs: ATS (active testing system): model
(term): control vector
(set diagnoses): prior diagnoses
local variables: , , (terms): observation
(integer): sum remaining diagnoses, initially 0
q (integer): sum squares remaining diagnoses, initially 0
Z (set terms): samples
E (real): expectation
2:
Z
3:
repeat
4:
RandomInputs(SD, IN)
5:

6:
InferOutputs(SD, OUT, , )
7:
6 Z
8:
Z Z { }
9:
q q + | (D, )|2
10:
+ | (D, )|
11:
E q/s
12:
end
13:
end
14:
Terminate(E)
15:
return E
16: end function

Algorithm 1 uses couple auxiliary functions: RandomInputs assigns random values
inputs InferOutputs computes outputs system model, inputs
diagnosis.4 computation intersection size | (D, )| implemented
counting SD 6|=.
algorithm terminates termination criterion (checked Terminate)
satisfied. implementation, Terminate returns success last n iterations
(where n small constant) leave expected number diagnoses, E, unchanged,
terms integer representation. experiments show problems considered,
n < 100 yields negligible error.
complexity Alg. 1 determined complexity consistency checking (line
9 10) size D. denote complexity single consistency check
, complexity Alg. 1 becomes O(|D|). Although consistency checking
diagnostic problems NP -hard worst case, average-case problems easy.
implementation Expectation overcome complexity consistency checking
4. always possible general case. framework, number assumptions,
i.e., weak-fault model, well-formed circuit, etc. complexity InferOutputs thus depends
framework assumptions.

311

fiFeldman, Provan, & van Gemund

using incomplete Logic-Based Truth Maintenance System (LTMS) (Forbus & de Kleer,
1993).

5. Algorithms Reducing Diagnostic Uncertainty
section introduce three algorithms: FractalATPG, FractalG, FractalP.
5.1 Problem Definition Exhaustive Search
problem defined follows:
Problem 1 (Optimal Control Sequence). Given system ATS, sequence (of past observations controls) = h1 1 , 2 2 , , k k i, (1 k) OBS
assignments j (1 j k) CTL assignments, compute new CTL assignment
k+1 , that:
k+1 = argmin E ( (SD, S), {IN OUT}|)

(6)

CTL

CTL space possible control assignments.
Problem 1 different general sequential testing problem, formulated Shakeri
(1996). Shakeri formulation, different test costs different prior failure
probabilities, Problem 1 assumes equal costs equal small prior probabilities
failure. Pattipati Alexandridis (1990) show assumptions, minimizing
test cost step constitutes optimal policy minimizing expected test cost.
Hence, solving Problem 1 solving lesser problem generating optimal test strategy
given unit costs equal prior failure probability. Note use algorithm
optimizes Problem 1 heuristic algorithm solving sequential testing problem.
case expected cost would arbitrarily far optimum one, depending
cost distribution tests.
Consider running example initial observation vector (and control assignment) 3 3 = b o1 o2 o3 o4 , 3 = chosen initial
control input. four MC diagnoses SD 3 3 = {{h1 , h3 }, {h2 , h5 },
{h4 , h5 }, {h5 , h8 }}.
exhaustive algorithm would compute expected number diagnoses
2|CTL| next possible control assignments. running example one control
variable two possible control assignments (5 = 6 = i). compute
expected number diagnoses, possible control assignment possible
observation vector , count number initial diagnoses consistent
.
Computing intersection sizes running example gives us Table 2. Note that,
order save space, Table 2 contains rows Pr( ) 6= 0,
given initial diagnoses (and, result, | ( (SD, 3 3 ), )| =
6 0).
straightforward compute expected number diagnoses control assignment
help marginalization table. order (1) filter
lines consistent control assignment (2) compute sum
sum squares intersection sizes (the rightmost column Table 2).
312

fiA Model-Based Active Testing Approach Sequential Diagnosis

Table 2: Marginalization table SD 3




b o1 o2 o3 o4

F
F
F
F
F
F
F
F
F
F
F

F
F
F
F
F
F






F
F
F



F
F
F



F


F


F


F


F
F
F
F
F
F
F
F
F
F
F

F
F
F
F
F
F
F
F
F
F
F

F
F

F
F

F
F

F
F

Pr

| |

0.03125
0.0625
0.03125
0.03125
0.0625
0.03125
0.03125
0.0625
0.03125
0.03125
0.0625

1
2
1
1
2
1
1
2
1
1
2


F












F
F
F
F
F
F





b o1 o2 o3 o4

F
F
F



F
F
F



F
F
F
F


F




F
F
F


F
F
F
F

F

F
F

F
F
F


F
F
F



F
F
F
F

F
F

F

Pr

| |

0.03125
0.0625
0.03125
0.03125
0.03125
0.03125
0.0625
0.03125
0.03125
0.0625
0.125

1
2
1
1
1
1
2
1
1
2
4

compute E(SD, OBS|3 i), find sum sum squares
intersection sizes rows Table 2 column F. checked
E(SD, OBS|3 , i) = 24/16 = 1.5. Similarly, E(SD, OBS|3 i) = 34/16 = 2.125. Hence
optimal diagnostician would consider second measurement control setting = i.
obvious problem brute-force approach size marginalization table is, worst-case, exponential |OBS|. Although many rows
marginalization table skipped intersections empty (there consistent prior diagnoses respective observation vector control assignment),
construction table computationally demanding consider approximation algorithm (to construct Table 1 tiny example, exhaustive approach
perform total 512 consistency checks).
5.2 FractalATPG
Consider running example Sec. 3 observation 4 = b o1 o4 .
leads 6 double-fault MC diagnoses, shown Fig. 3.

1
2
3
4
5
6
E

h1

h2

h3

h4

h5

h6

h7

h8




































13
3

10
3

13
3

13
3







6








10
3







6

13
3

Figure 3: ATPG-Based active testing example
Instead searching space possible control assignments, directly compute control assignment tests specific component c using approach
313

fiFeldman, Provan, & van Gemund

ATPG. choose component c one decreases expected number remaining MC diagnoses minimizing E (SD, c| ). look Fig. 3
see knowing health h1 h3 leads E 3.33, h2 , h4 , h5 , h7 ,
E 4.33, h6 h7 E = 6. Choosing control setting computes
state h1 h3 intuitive state component makes balanced
partition prior diagnoses.
next present FractalATPG algorithm uses approach illustrated above.
Algorithm 2 ATPG-Based active testing algorithm
1: function FractalATPG (ATS, , ) returns control term
inputs: ATS (active testing system): model
(term): initial (non-modifiable) observation
(term): initial control
local variables: c (variable): component
f (integer): remaining diagnoses
(term): diagnosis
(term): control setting
H (set pairs): component/expectation pairs
(set terms): diagnoses

2:
(SD, )
3:
c COMPS
4:
f 0
5:

6:
c
7:
f f +1
8:
end
9:
end
10:
H hc, f 2 + (|D| f )2
11:
end
12:
H SortByExpectation(H)
13:
= 1 . . . |H|
14:
ATPG(ATS, , Hi hci)
15:
return
16:
end
17:
end
18:
return RandomControls()
19: end function
Algorithm 2 counts number prior diagnoses component appears (lines
4 - 8) result saved variable f . number used compute
expected number remaining MC diagnoses given component health (line 10).
component expected number diagnoses stored set H (line 10). set
H sorted increasing order expectation (line 12). iterate set
components order expectation (lines 13 17). component try compute
314

fiA Model-Based Active Testing Approach Sequential Diagnosis

ATPG vector tests it. cases vector may exist. worst case
ATPG vector test component, Alg. 2 better strategy
return random control assignment (line 18).
time complexity Alg. 2 determined complexity diagnostic search
(line 2) complexity ATPG (line 14). denote former
latter complexity FractalATPG becomes O(|COMPS|).
complexity ATPG usually lower diagnosis (abductive reasoning) ( < ),
complexity FractalATPG determined time computing MC diagnoses.
Computing ATPG vectors extensively studied (Bushnell & Agrawal, 2000)
although known NP -hard problem (Ibarra & Sahni, 1975), exists
evidence ATPG easy practical problems (Prasad, Chong, & Keutzer, 1999).
efficient ATPG algorithms integrate randomized approach Boolean difference (Bushnell
& Agrawal, 2000). former approach efficiently computes test vectors majority
components, latter computes test vectors remaining components using
DPLL-solver.
implement ATPG follows. First duplicate system description SD
renaming variable v : v 6 {IN CTL} v , thus generating SD (SD SD share
input control variables). create healthy assignment (for
assumable variables) 0 single fault assignment 0 differ
sign literal whose component want test. Finally, construct following
propositional expression:
#
"
_
(7)

SD SD 0
oOUT

operator denotes exclusive or, hence (o ) (o ).
propositional expression (7) leaves unconstrained controls
need. two instances system: healthy (SD 0 ) faulty (SD
). last term forces output healthy faulty system
different least one bit. compute ATPG control vector need one satisfiable
solution . Note ATPG control vector may exist ( |=), i.e., component
may testable given CTL SD . Often multiple satisfying control
assignments. case FractalATPG chooses arbitrary one. latter
mean satisfiable ATPG control vectors achieve uncertainty reduction.
FractalATPG becomes suboptimal control testing given component,
multiple controls. FractalATPG becomes completely random
components tested given choice controls.
two problems FractalATPG. First, FractalATPG assumes stationary
inputs, i.e., FractalATPG ignores source uncertainty. non-modifiable inputs, however, help decay process, hence FractalATPG conservative choosing
control assignmentsa feature leads suboptimality. bigger problem
FractalATPG decreases expected number remaining MC diagnoses computing
exact health one component. Here, problem FractalATPG tests one
component per step, tries compute control assignment computes
exact state component. active testing algorithm decrease diagnostic uncertainty computing probability distribution function state component.
315

fiFeldman, Provan, & van Gemund

natural extension FractalATPG algorithm computes state k
components simultaneously. latter approach assumes system k-component
testablean unrealistic assumption. experiments seen systems often
even single-component testable. Note computing exact states components
requirement decreasing diagnostic uncertainty. Instead computing
exact state one components, algorithm shown next section implicitly
builds probability density function health state component,
suffer problems FractalATPG .
5.3 FractalG
Consider SD example started Sec. 3, input variables = {i}, control variables CTL = {a, b}, initial input values = i, initial observation 3 = (a
b) (o1 o2 o3 o4 ). initial observation 3 leads 5 triple-fault MC diagnoses: (SD, 3 ) = {{h1 , h4 , h7 }, {h1 , h7 , h8 }, {h2 , h3 , h6 }, {h2 , h4 , h5 },
{h3 , h6 , h8 }}. also write = (SD, 3 ) choose one faults
truly injected fault (let = {h1 , h7 , h8 }).
Exhaustive

Greedy

k

1

E (SD, IN|1 )

k

1

E (SD, IN|1 )

1
2
3
4

b
b
b
ab

4.33
1.57
1.57
1.33

1
2
3

b
b
ab

4.33
1.57
1.33

k

2

E (SD, IN|2 )

k

2

E (SD, IN|2 )

1
2
3
4

b
b
b
ab

1.67
1
1
1.67

1
2
3

b
b
ab

1.67
1
1.67

| (D, 1 )| = 2

| (D, 1 )| = 2

| ( (D, 1 ), 2 )| = 1

| ( (D, 1 ), 2 )| = 1

Figure 4: Exhaustive greedy search optimal control assignment
left right parts Fig. 4 show two possible scenarios locating . left
exhaustive approach considers 2|CTL| control assignments, hence
cannot used solve practical problems. greedy scenario right side Fig. 4
decreases number computations expected number remaining MC diagnoses
2|CTL| |CTL|. idea flip one control variable time, compute expected
number remaining MC diagnoses keep flip (shown bold Fig. 4) E
decreases. Given initial control assignment consider space possible control
flips. space visualized lattice (Fig. 5 shows small example). Figure 5
316

fiA Model-Based Active Testing Approach Sequential Diagnosis

shows expected number MC diagnoses control assignment. Note probing
visualized similar way.
{i2 , i4 , i6 , i7 } 17.54

{i2 , i4 , i6 } 17.54 {i2 , i4 , i7 } 14.5 {i2 , i6 , i7 } 21.05 {i4 , i6 , i7 } 21.05

{i2 , i4 } 14.65 {i2 , i6 } 21.05 {i2 , i7 } 21.05 {i4 , i6 } 21.05 {i4 , i7 } 18.84 {i6 , i7 } 25

{i2 } 21.05 {i4 } 18.84 {i6 } 25 {i7 } 25

{} 25

Figure 5: Example expectation optimization lattice (74182, |CTL| = 4, |IN| = 5).
node shows set control flips expected number MC diagnoses.

practice, control literals mostly independent even though space control
assignments continuous general, large continuous subspaces. greedy
approach shown Alg. 3, computes control assignment given active testing
system prior observation.
Algorithm 3 Greedy active testing algorithm
1: function Fractal(ATS, ) returns control term
inputs: ATS (active testing system): model
(term): initial observation
local variables: , (terms): control configurations
E, E (reals): expectations
(set terms): diagnoses
l (literal): control literal

2:
(SD, )
3:
E Expectation(ATS, , D)
4:
l
5:
FlipLiteral(, l)
6:
E Expectation(ATS, , D)
7:
E < E
8:

9:
E E
10:
end
11:
end
12:
return
13: end function
317

fiFeldman, Provan, & van Gemund

set initial diagnoses computed initial observation line 2. line 5,
Alg. 3 flips next literal current control assignment. auxiliary FlipLiteral
subroutine simply changes sign specified literal term. flip
expected intersection size computed call Expectation (cf. Alg. 1).
new expected intersection size smaller current one, proposed control
assignment accepted current control assignment, search continues
there.
complexity FractalG determined complexity diagnostic search
(line 2) complexity Expectation (line 3 line 6). denote former
latter complexity FractalG becomes O(|CTL|).
, complexity FractalG FractalG. practice FractalG
requires computation compute sufficient decay. due design
Expectation (Alg. 1).
active-testing problem worst-case NP -hard (it reduced computing
diagnosis), see experimentation section, possible achieve good
average-case performance choosing appropriate MBD oracle. advantage
greedy approach, particular, number computations expected number
diagnoses linear number literals control assignment. done
price optimality (i.e., effect combinations controls neglected).
5.4 FractalP
Probing related active testing measuring internal variables thought
revealing internal control circuits. Alternatively, one add control circuitry model
reveals values internal variables. reveal hidden control potential
implement GDE probing (de Kleer & Williams, 1987) FractalP. approach
different GDE two ways. First, compute expected number remaining
MC diagnoses instead expected diagnostic entropy. Second, Fractal use
Assumption-Based Truth Maintenance System (ATMS) (de Kleer, 1986).
Consider running example Sec. 3 observation 5 = b o1
o2 o3 o4 . leads 5 triple-fault MC diagnoses: (SD, 3 ) = {{h1 , h4 , h7 },
{h1 , h7 , h8 }, {h2 , h3 , h6 }, {h2 , h4 , h5 }, {h3 , h6 , h8 }}. Subsequent measurement p gives us | ( (SD, 3 ), p)| = 3 p positive | ( (SD, 5 ), p)| = 2
otherwise. expected number MC diagnoses E (SD, {p}|3 ) = 2.6. Repeating
remaining internal variables results E (SD, {q}|3 ) = 2.6, E (SD, {r}|3 ) = 3.4,
E (SD, {s}|3 ) = 3.4. result see measuring p q less informative
measuring r s, intuitive r give balanced partitioning
circuit.
Problem 2 (Probe Sequencing). Given system ATS, observation partial
assignment internal variables , choose variable p set U unassigned
internal variables , that:
p = argmin E (SD, p| )

(8)

pU

Algorithm 4 solves Problem 2. Algorithm 4 computes expected number diagnoses
unobserved variable (lines 3 - 11). Starting set initial diagnoses
318

fiA Model-Based Active Testing Approach Sequential Diagnosis

(computed line 2), Alg. 4 perform total 2|D||V \{OBSCOMPS}| consistency checks
(lines 4 5) determine expected number MC diagnoses unobserved
variable.
next show probing algorithm introduced de Kleer Williams (1987)
adapted Fractal framework.
Algorithm 4 Probing algorithm
1: function FractalP(ATS, ) returns variable
inputs: ATS (active testing system): model
(term): observation
local variables: v, R (variables): probes
E, E (reals): expectations
p, q (reals): remaining diagnoses
(set terms): diagnoses

2:
(SD, )
3:
v V \ {COMPS OBS}
4:
p | (D, v)|
5:
q | (D, v)|
6:
E (p2 + q 2 )/(p + q)
7:
E < E
8:
Rv
9:
E E
10:
end
11:
end
12:
return R
13: end function
Instead computing expected number remaining MC diagnoses single variable
p, possible consider measuring pairs variables hp1 , p2 i, general, k-tuples
internal variables hp1 , p2 , . . . , pm |V \{OBSCOMPS}|. refer probing
involving 1 variable k-probing. Although shown users
significantly benefit terms diagnostic uncertainty performing k-probing (de Kleer
et al., 1992), easily modify FractalP consider multiple probes. Note
= |V \ {OBS COMPS}| probing problem, one way pick
internal variables.
complex operation FractalP computing initial set MC
diagnoses. addition that, |V \ {COMPS OBS}| consistency checks. Consistency checking is, general, easier diagnosis. Note Fractal algorithms
(FractalATPG , FractalG, FractalP) start computing set initial MC
diagnoses. Hence, difference performance determined complexity
reducing initial set (SD, ). According criterion, fastest algorithm
FractalP performs small number consistency checks, followed closely
FractalATPG (computing ATPG vectors). slowest algorithm FractalG,
computes expected number MC diagnoses given multiple variables.
319

fiFeldman, Provan, & van Gemund

6. Experimental Results
implemented Fractal approximately 3 000 lines C code (excluding
diagnostic engine Logic Based Truth Maintenance System). experiments
run 64-node dual-CPU cluster (each node configured two 2.4 GHz AMD Opteron
DP 250 processors 4 Gb RAM).
6.1 Experimental Setup
experimented well-known benchmark models ISCAS85 combinational
circuits (Brglez & Fujiwara, 1985). models derived ISCAS85 circuits computationally intensive (from diagnostic perspective), also considered four mediumsized circuits 74XXX family (Hansen, Yalcin, & Hayes, 1999). order use
system model MC diagnosis counting simulation, fault mode
logic gate stuck-at-opposite, i.e., faulty, output logic gate assumes
opposite value nominal. Without loss generality, gates allowed fail
models. different ATPG gates typically fail wires
modeled components fail failure modes stuck-at-zero stuck-at-one.
ATPG MBD modeling approaches achieve results.

Table 3: overview 74XXX/ISCAS85 circuits (V total number variables
C number clauses)

Name

Description

74182
74L85
74283
74181

4-bit
4-bit
4-bit
4-bit

c432
c499
c880
c1355
c1908
c2670
c3540
c5315
c6288
c7552

27-channel interrupt ctl.
32-bit SEC circuit
8-bit ALU
32-bit SEC circuit
16-bit SEC/DEC
12-bit ALU
8-bit ALU
9-bit ALU
32-bit multiplier
32-bit adder

CLA
comparator
adder
ALU

|IN|

|OUT|

Original
|COMPS|

9
11
9
14

5
3
5
8

36
41
60
41
33
233
50
178
32
207

7
32
26
32
25
140
22
123
32
108

Reduced
|COMPS|

V

C

19
33
36
65

47
77
81
144

150
236
244
456

6
15
14
21

160
202
383
546
880
1 193
1 669
2 307
2 416
3 512

356
445
826
1 133
1 793
2 695
3 388
4 792
4 864
7 232

514
714
1 112
1 610
2 378
3 269
4 608
6 693
7 216
9 656

59
58
77
58
160
167
353
385
1 456
545

addition original 74XXX/ISCAS85 models, performed cone reductions
described Siddiqi Huang (2007) de Kleer (2008). Recall perspective
MBD diagnostic engine, faults inside cone (where cone set components)
cannot distinguished, hence enough provide single health variable per cone.
call models single health variable per cone reduced. Table 3 describes models.
320

fiA Model-Based Active Testing Approach Sequential Diagnosis

initial observation vectors control settings used first step
Fractal inference. illustrate significant diagnostic convergence possible,
use initial observations leading high numbers initial MC diagnoses.
average diagnostic outcomes observations, repeat experiment
range initial observation vectors. cardinality MC diagnosis
significance Fractal, produces significant burden diagnostic oracle (Feldman, Provan, & van Gemund, 2008). order overcome computational difficulty,
limited experiments observation vectors leading double faults only.
circuit generated 1 000 non-masking double-faults, observation computed number initial MC diagnoses. 1 000 observation
vectors taken 100 largest number MC diagnoses. resulting
observations summarized Table 4. example, see staggering number
46 003 double faults under-constrained c7552 observation.
Table 4: Number MC diagnoses per observation vector
Name

Min

Original
Max
Mean

Min

Reduced
Max Mean

74182
74L85
74283
74181

25
32
48
93

25
88
60
175

25
50.2
51.8
113.5

2
5
6
10

2
13
9
19

2
7
7
13.3

c432
c499
c880
c1355
c1908
c2670
c3540
c5315
c6288
c7552

88
168
783
1 200
1 782
2 747
1 364
3 312
6 246
16 617

370
292
1 944
1 996
5 614
7 275
2 650
17 423
15 795
46 003

165.8
214.1
1 032.5
1 623.3
2 321.9
3 621.7
1 642.2
6 202.1
8 526.1
23 641.2

21
4
20
4
40
10
158
15
2 928
45

127
31
190
31
341
90
576
192
6 811
624

47.5
15.8
39.7
15
84.8
21.3
226
34.5
3 853
121.6

Since 74XXX/ISCAS85 circuits control variables abuse benchmark
designating fraction input variables controls.
define two policies generating next inputs: random stationary. latter
input policy (where input values change time) typical diagnostic worst-case
system environments are, example, paused pending diagnostic investigation,
provides us useful bounds analyzing Fractals performance.
Note use non-characterizing sets diagnoses (see Def. 4) may lead situation real (injected) fault initial set diagnoses. case
set remaining diagnoses (S) may become empty set number Fractal
steps. Although gives us diagnostic information, undesirable situation
non-characterizing sets diagnoses represent diagnostic probability mass minimize likelihood cases. constructed experimental
benchmark initial observations way avoid cases.
321

fiFeldman, Provan, & van Gemund

6.2 Expected Number MC Diagnoses
observed error Alg. 1 insensitive number composition
input variables. seen value expected number diagnoses
E approaches exact value E increasing number samples n. particular,
E equal exact value expected number MC diagnoses E, possible
input values considered. Figure 6 shows examples E approaching E three
benchmark models.
c432

c880

200

c1908

160

E

180

40

E

150

38

140
160

130

36

120

140
0

100

200 300
step

400

500

110

E
E
0

100

200 300
step

400

500

34

0

100

200 300
step

400

500

Figure 6: Convergence expected number MC diagnoses increasing sample size
Terminate approximates intermediate value E computing sequence E = hE1 ,
E2 , . . ., En i. standard error mean E defined as:

SEME = ,
n

(9)

standard deviation E. set Terminate terminate Alg. 1
n > 15 SEME < , circuit-dependent threshold constant. Table 5 shows
various circuits experimented on.
Table 5: Termination parameters Alg. 1
Original
Mean n Max n



74182
74L85
74283
74181

0.1
0.11
0.2
0.4

52.7
176.2
139.9
169.1

110
246
225
203

0.01
0.03
0.01
0.07

151.6
170.3
211.3
143.2

223
212
243
181

c432
c499
c880
c1355
c1908
c2670
c3540
c5315
c6288
c7552

0.72
0.77
3.57
4.3
14.01
12.77
13.6
23.35
33.18
68.11

48.2
36.4
93.9
51.3
19.5
40.5
78.9
34.2
37.2
68.7

99
61
163
93
35
78
196
39
144
91

0.18
0.02
0.1
0.01
0.62
0.1
0.66
0.09
19.1
3.73

108.6
55.7
156.3
121.4
18.8
65.2
89.6
36.0
39.4
73

158
92
204
148
25
102
132
48
74
122

322



Reduced
Mean n Max n

Name

fiA Model-Based Active Testing Approach Sequential Diagnosis

determined using following procedure. First, circuit, choose
arbitrary initial observation small set input variables (|IN| = 8). small
cardinality allows us compute true values E. Next, circuit run 10
pseudo-random experiments. choose smallest value SEME
corresponding E within 95% E. Table 5 shows average maximum number
steps Alg. 1 reaches value. cases upper bound n = 100 safe
termination criterion.
6.3 Comparison Algorithms
Consider weak-fault model chain n inverters set MC diagnoses (initially,
|D| = n). step single-variable probing eliminate 0.5|D| diagnoses.
also shown halving expected number remaining MC diagnoses theoretical
bound one-step lookahead strategy. result use geometric decay curve
N (k) = N0 pk + N

(10)

model diagnosis decay. case, N0 initial number diagnoses, N
value |(S)| converges, p decay rate constant. probing, N = 1.
experiments fit expected number remaining MC diagnoses E
actual number remaining MC diagnoses (S) Eqn. 10.
6.3.1 FractalATPG
Figure 7 shows reduction expected number MC diagnoses function (1)
number control variables |CTL| (2) time k. One easily see global
optimum reached quickly independent axes. decay shown c432
(Fig. 7, left) reduced c880 (Fig. 7, right). number control variables |CTL|
varies 0 36 c432 (|IN| = 36) 0 60 c880 (|IN| = 60).
c432

c880 (reduced)

300
300
200
E

E

200

100

100
0
2

4

6

8 10
12 14
k

30

20

10

0

0

0
2

|CTL|

4

6

20
8 10
12 14
k

60

40
|CTL|

Figure 7: Decay E, stationary inputs, FractalATPG
Using |(S)| instead E results similar plots (there high correlation E
|(S)|), hence omitted |(S)| plots. minimum, maximum mean
Pearsons linear correlation coefficient E Fig. 7 respective |(S)|
number control variables c432 min = 0.713, max = 0.999, avg = 0.951,
323

fiFeldman, Provan, & van Gemund

respectively. corresponding correlation coefficients reduced c880 min =
0.834, max = 1, avg = 0.972.
seen expected number remaining diagnoses E quickly reaches
global optimum increasing |CTL|, means turning even small number
input variables controls allows geometric decay diagnostic entropy.
results reduced c880 similar non-reduced c432. Hence, identification
cones helps performance diagnostic oracle, change convergence
behavior effect control variables.
Fitting geometric decay curves (Eqn. 10) |CTL| axes Fig. 7 produces better
fits c880 c432. Similarly, values N fits alongside k-axis
larger c432 c880. reason small number outputs c432
(cf. Table 3). circuits outputs, randomly turning limited number inputs
controls may lead fast decay small N , control-output connectivity
model essential decreasing diagnostic uncertainty.
Table 6 Table 7 summarize total 14 000 FractalATPG experiments
whole 74XXX/ISCAS85 benchmark. Table 6 shows correlation expected
number remaining MC diagnoses actual number remaining MC diagnoses.
second third columns Table 6 see minimum average correlations
E (S). third fourth cases specify fraction observations
> 0.95 > 0.975, respectively. Columns 6 9 repeat data
reduced 74XXX/ISCAS85 circuits.
Table 6: Linear correlation coefficient expected number remaining MC diagnoses
E actual number remaining diagnoses (S), |CTL| = 14 |IN|, stationary
inputs, FractalATPG

Name

min

avg

74182
74L85
74283
74181

0.55
0.46
0.46
0.46

0.98
0.91
0.91
0.88

c432
c499
c880
c1355
c1908
c2670
c3540
c5315
c6288
c7552

0
0.5
0.51
0
0.38
0
0.48
0.54
0.42
0.62

0.83
0.87
0.86
0.88
0.87
0.89
0.86
0.93
0.9
0.88

Original
> 0.95

Reduced
> 0.95

> 0.975

min

avg

> 0.975

0.82
0.52
0.69
0.48

0.79
0.44
0.61
0.39

1
0.45
0.45
0.45

1
0.81
0.84
0.86

1
0.4
0.38
0.44

1
0.39
0.31
0.35

0.24
0.32
0.28
0.32
0.31
0.31
0.29
0.48
0.41
0.44

0.16
0.15
0.18
0.18
0.18
0.16
0.19
0.39
0.24
0.13

0
0
0.51
0
0
0
0.06
0.47
0.4
0.45

0.81
0.86
0.85
0.87
0.79
0.79
0.82
0.88
0.9
0.89

0.29
0.42
0.3
0.47
0.22
0.19
0.3
0.44
0.36
0.43

0.23
0.33
0.19
0.34
0.15
0.12
0.23
0.32
0.21
0.23

Table 7 summarizes parameters geometric decay curves fitted (S). see
although (S) well approximated geometric decay curve (the average goodness324

fiA Model-Based Active Testing Approach Sequential Diagnosis

of-fit criterion R2 0.84) average decay constant p low (0.13 non-reduced
0.22 reduced 74XXX/ISCAS85 circuits).
Table 7: Decay rate p (minimal, maximal, average) goodness-of-fit R2 (average)
geometric decay best-fit (S), |CTL| = 41 |IN|, stationary inputs, FractalATPG

pmin

Original
pmax pavg

2
Ravg

pmin

Reduced
pmax pavg

2
Ravg

74182
74L85
74283
74181

0.3
0.06
0.18
0.11

0.52
0.75
0.68
0.71

0.43
0.48
0.57
0.5

0.95
0.88
0.78
0.86

0.5
0.35
0.31
0.18

0.5
0.64
0.6
0.64

0.5
0.5
0.48
0.5

1
0.92
0.94
0.9

c432
c499
c880
c1355
c1908
c2670
c3540
c5315
c6288
c7552

0.03
0.1
0.06
0.03
0.02
0.05
0.02
0.22
0.02
0.56

0.8
0.79
0.84
0.9
0.93
0.91
0.87
0.91
0.91
0.95

0.56
0.64
0.54
0.62
0.65
0.63
0.52
0.65
0.52
0.76

0.81
0.84
0.83
0.81
0.68
0.77
0.85
0.8
0.88
0.61

0.03
0.48
0.06
0.39
0.51
0.14
0.04
0.06
0.02
0.01

0.79
0.76
0.8
0.76
0.74
0.75
0.76
0.79
0.9
0.88

0.52
0.65
0.53
0.63
0.64
0.6
0.45
0.54
0.51
0.58

0.82
0.84
0.87
0.85
0.77
0.8
0.89
0.84
0.89
0.85

Average

0.13

0.82

0.58

0.81

0.22

0.74

0.55

0.87

Name

decay rate p depends mostly circuit topology, hence large variance Table 7.
Consider, example, artificial topology, n components, n output
variables produce health-state component specific control assignment
(e.g., self-test). topology p would small diagnostician needs
one test (control assignment) decrease number MC diagnoses one.
performance FractalATPG determined size model
diagnostic oracle. experiments overall time executing single scenario
varied 3.4 74182 1 015 c6288. satisfiability problems ATPG part
always easy DPLL solver spent milliseconds computing control assignments.
decay rate FractalATPG depends number composition controls.
follows see FractalG achieve similar decay rate smaller
number control variables.
6.3.2 FractalG
Figure 8 shows decay expected number remaining MC diagnoses FractalG.
reduction similar c432, see steeper reduction number
remaining MC diagnoses independent axes. Hence, greedy algorithm better
FractalATPG identifying control combinations small size, thereby leading
better decay rate.
325

fiFeldman, Provan, & van Gemund

c432

c880 (reduced)

250

100

200
^

^

E

E

150
100

50

50
0
5

10
k

15

30

10

20

0

0

0
20

5

|CTL|

10
k

40
15

60

|CTL|

Figure 8: Decay E (left) (S) (right), stationary inputs, FractalG
Table 8 Table 9 summarize whole 74XXX/ISCAS85 benchmark. Table 8 shows
FractalG, similar FractalATPG, results high average correlation (S)
E (avg > 0.79 circuits).
Table 8: Linear correlation coefficient expected number remaining MC diagnoses
E actual number remaining diagnoses (S), |CTL| = 14 |IN|, stationary
inputs, FractalG

Name

min

avg

74182
74L85
74283
74181

0.03
0
0
0

0.88
0.72
0.5
0.56

c432
c499
c880
c1355
c1908
c2670
c3540
c5315
c6288
c7552

0.01
0.01
0.05
0.08
0.05
0.01
0.34
0.27
0.09
0.78

0.75
0.88
0.77
0.86
0.81
0.83
0.73
0.78
0.81
0.86

Original
> 0.95

Reduced
> 0.95

> 0.975

min

avg

> 0.975

0.39
0.12
0.08
0.05

0.18
0.06
0.03
0.02

1
0.01
0
0

1
0.66
0.48
0.55

1
0.16
0.12
0.09

1
0.14
0.11
0.07

0.07
0.29
0.09
0.36
0.25
0.38
0.09
0.05
0.11
0.06

0.02
0.08
0.06
0.21
0.14
0.22
0.05
0
0.05
0.06

0.01
0
0
0.42
0
0.01
0
0
0.1
0.21

0.68
0.85
0.73
0.9
0.8
0.76
0.7
0.6
0.78
0.83

0.07
0.33
0.08
0.39
0.4
0.37
0.04
0.1
0.09
0.13

0.05
0.2
0.04
0.16
0.3
0.26
0.01
0.07
0.04
0.01

decay rates FractalATPG FractalG similar (cf. Table 7 Table 9),
but, visible Fig. 8, FractalG reduces number remaining MC diagnoses
quickly, fewer control variables. c432 combinational circuit difficult
active testing small number outputs compared number inputs
(cf. Table 3), hence reducing diagnostic utility.
summarize effect number controls diagnostic convergence,
fit geometric decay curve (Eqn. 10) (S) 100 initial observation
326

fiA Model-Based Active Testing Approach Sequential Diagnosis

Table 9: Decay rate p (minimal, maximal, average) goodness-of-fit R2 (average)
geometric decay best-fit (S), |CTL| = 14 |IN|, stationary inputs, FractalG
pmin

Original
pmax pavg

2
Ravg

pmin

Reduced
pmax pavg

2
Ravg

74182
74L85
74283
74181

0.24
0.05
0.12
0.15

0.53
0.74
0.67
0.75

0.43
0.47
0.42
0.48

0.95
0.9
0.9
0.9

0.5
0.25
0.35
0.15

0.5
0.65
0.58
0.69

0.5
0.49
0.44
0.44

1
0.93
0.96
0.93

c432
c499
c880
c1355
c1908
c2670
c3540
c5315
c6288
c7552

0.04
0.09
0.12
0.19
0.32
0.21
0.34
0.3
0.04
0.08

0.88
0.88
0.67
0.87
0.73
0.74
0.63
0.83
0.81
0.54

0.56
0.71
0.42
0.63
0.53
0.53
0.53
0.61
0.5
0.34

0.83
0.81
0.9
0.87
0.87
0.87
0.91
0.83
0.9
0.92

0.03
0.34
0.07
0.11
0.05
0.15
0.01
0.06
0.08
0.16

0.86
0.85
0.83
0.82
0.84
0.81
0.8
0.86
0.77
0.83

0.59
0.68
0.52
0.68
0.59
0.6
0.44
0.58
0.47
0.59

0.8
0.85
0.88
0.85
0.83
0.8
0.9
0.82
0.89
0.84

Average

0.16

0.73

0.51

0.88

0.17

0.76

0.54

0.88

Name

vectors various |CTL|. case, N0 initial number diagnoses, N
value |(S)| converges, p decay constant (the important parameter
fits). easy circuit chain topology, p = 12 , N0 halves every k steps,
binary search, hence p corresponds one bit. p = 41 , p corresponds two bits.
Table 10: Mean p various numbers control bits, stationary input policy, FractalG
Name

3 bits

c432
c499
c880
c1355
c1908
c2670
c3540
c5315
c6288
c7552

0.61
0.79
0.5
0.71
0.68
0.45
0.39
0.52
0.31
0.62

Original
4 bits 5 bits
0.69
0.83
0.55
0.72
0.7
0.49
0.38
0.62
0.41
0.77

0.42
0.77
0.62
0.59
0.41
0.39
0.43
0.67
0.23
0.3

3 bits
0.7
0.58
0.49
0.8
0.54
0.39
0.79
0.81
0.64
0.59

Reduced
4 bits 5 bits
0.71
0.62
0.47
0.82
0.52
0.44
0.8
0.72
0.7
0.34

0.57
0.52
0.44
0.75
0.3
0.42
0.61
0.79
0.59
0.38

Table 10 shows average p initial observations various numbers control
bits b = lg |CTL|. Table 10 include data 74XXX circuits
enough inputs (we need circuits least 32 inputs). Table 10 visible
327

fiFeldman, Provan, & van Gemund

exponential increase number control variables lead significant
decrease p. Hence, ISCAS85, even turning small number input variables
controls leads near-optimal decrease number remaining MC diagnoses.
performance FractalG worse FractalATPG due multivariable expectation. running time varied 7.1 74182 2 382
c6288. CPU time spent Expectation subroutine (cf. Alg. 1).
consistency check computationally easy, circuit thousands
them. Hence, improving performance LTMS would lead increase
performance FractalG.
6.3.3 FractalP
next discuss FractalP. mentioned earlier, probing different active testing
assumes full observability model, i.e., internal variables measured (cf.
Sec. 5). Furthermore, probing considers one internal variable per step, active testing
assigns value control variables.5
value decay rate p depends (1) topology circuit, (2) initial
observation (3) values subsequent probes. probing ISCAS85 see
values decay rate p close 0.5 (S) E. Figure 9 shows
actual expected number remaining MC diagnoses ( (S) E, respectively)
geometric fit E three probing scenarios.
c3540 (reduced)

c432

c5315

300

300

k

k

N0 p + N
(S )
E

200

N0 p + N
(S )
E

200

8000

N0 p k + N
(S )
E

6000
4000

100

100

2000
0

2

4

6
k

8

10

12

0

2

4

6
k

8

10

12

0

2

4

6
k

8

10

12

Figure 9: Actual number remaining MC diagnoses (S), expected number remaining
MC diagnoses E, geometric decay fit (S), stationary inputs, FractalP

plot Fig. 9 shows single probing session single initial observation. Figure 10
shows goodness-of-fit criterion R2 vs. decay rate constant p 100 observations
10 multiple runs Fig. 9 circuits.
visible Fig. 10 absolute values R2 (in cases) close
1. indicator probing experiments fit geometric decay model given
Eqn. 10 well. Figure 10 shows bad topology (c432 left), good topology
(c5315 right) achieves decay rate p close 0.5 (0.38 < p < 0.58) high
accuracy fit (0.9896 R2 1).
expected number remaining MC diagnoses good predictor actual number
MC diagnoses ISCAS85 circuits, shown Table 11. absolute values,
5. exist multi-probe generalizations probing (de Kleer et al., 1992).

328

fiA Model-Based Active Testing Approach Sequential Diagnosis

c5315

c3540 (reduced)
1

0.95

0.995

0.995

0.9

0.99

2

R

0.985

0.985

0.85

0.99

R

2

1

R

2

c432
1

0.8

0.98

0.98

0.75

0.975

0.975

0

0.5
p

1

0

0.5
p

0

1

0.5
p

1

Figure 10: Geometric decay rate vs. goodness-of-fit (S), FractalP
depend topology, see smaller correlation c432 observations.
cases, however, correlation significant, e.g., circuits observations
except c432 > 0.95.
Table 11: Linear correlation coefficient expected number remaining MC diagnoses E actual number remaining diagnoses (S), stationary inputs,
FractalP

Name

min

avg

74182
74L85
74283
74181

0.83
0.77
0.97
0.96

0.95
0.97
0.99
0.99

c432
c499
c880
c1355
c1908
c2670
c3540
c5315
c6288
c7552

0.66
0.97
0.98
0.99
0.98
0.98
0.97
0.99
0.92
0.95

0.97
1
1
1
1
1
1
1
1
1

Original
> 0.95

Reduced
> 0.95

> 0.975

min

avg

> 0.975

0.64
0.87
1
1

0.6
0.67
1
0.97

1
0.83
0.83
0.92

1
0.99
0.98
0.99

1
0.92
0.83
0.95

1
0.87
0.76
0.92

0.83
1
1
1
1
1
1
1
1
1

0.67
1
1
1
1
1
1
1
1
0.99

0.62
0.91
0.92
0.86
0.65
0.7
0.97
0.7
0.98
0.82

0.96
0.98
0.99
0.98
0.97
0.96
1
0.98
1
0.96

0.76
0.87
0.99
0.88
0.86
0.72
1
0.91
1
0.7

0.62
0.76
0.96
0.79
0.68
0.55
1
0.81
1
0.51

second third columns Table 11 see minimum average correlations E (S). third fourth cases specify fraction observations
> 0.95 > 0.975, respectively. Columns 6 9 repeat data
reduced 74XXX/ISCAS85 circuits.
Table 12 summarizes decay rate p goodness-of-fit criterion R2 observations circuits. c432, values p R2 dispersed,
experiments p strongly resembles chained-elements (i.e., p close 0.5).
minimum, maximum average values p (per circuit) given columns pmin ,
pmax , pavg , respectively.
329

fiFeldman, Provan, & van Gemund

Table 12: Decay rate p (minimal, maximal, average) goodness-of-fit R2 (average)
geometric decay best-fit (S), stationary inputs, FractalP

pmin

Original
pmax pavg

2
Ravg

pmin

Reduced
pmax pavg

2
Ravg

74182
74L85
74283
74181

0.26
0.21
0.31
0.3

0.64
0.7
0.64
0.66

0.54
0.52
0.49
0.5

0.95
0.97
0.99
0.99

0.5
0.25
0.4
0.27

0.5
0.55
0.58
0.56

0.5
0.45
0.49
0.42

1
0.97
0.96
0.99

c432
c499
c880
c1355
c1908
c2670
c3540
c5315
c6288
c7552

0.1
0.4
0.36
0.39
0.39
0.37
0.38
0.4
0.92
0.95

0.82
0.57
0.61
0.6
0.58
0.6
0.58
0.59
1
1

0.58
0.5
0.51
0.51
0.5
0.51
0.5
0.5
1
1

0.96
1
1
1
1
1
1
1
1
0.99

0.11
0.25
0.2
0.25
0.13
0.22
0.37
0.18
0.98
0.82

0.84
0.6
0.67
0.59
0.81
0.85
0.59
0.89
1
0.96

0.55
0.46
0.46
0.46
0.55
0.65
0.49
0.52
1
0.7

0.95
0.98
0.99
0.98
0.96
0.89
1
0.96
1
0.51

Average

0.41

0.69

0.58

0.99

0.35

0.71

0.55

0.94

Name

6.4 Experimental Summary
compare Table 6 Table 11 see average correlation avg decreases
significantly. Hence, assuming limited observability (i.e., assuming internals
measurable) decreases quality E predictor (S). increased statistical
dispersion visible increased range max min (cf. Table 6, max
always 1). example, consider c2670, standard deviation E vs. (S)
correlation coefficients = 0.0031 FractalP = 0.0783 FractalATPG.
difference dispersion correlation coefficients significant circuits,
smallest values c432, 0.0038 FractalP 0.0825 FractalATPG .
comparing Table 7, Table 9, Table 12 see mean decay rates
FractalATPG, FractalG, FractalP similar (the average p FractalG
0.7 average p FractalATPG 0.73). average goodness-of-fit criterion R2
exponential decays always good (0.88 FractalG, 0.84 FractalATPG),
almost perfect probing (0.97).
summary experiments best shown Fig. 11. factor sampling
error able perform exhaustive computations, chosen smallest
74182 circuit. original 74182 (a 4-bit carry-lookahead generator) 19 components,
9 inputs, 5 outputs. turned four inputs controls (hence, |IN| = 4
|CTL| = 4).
considered random control policy addition FractalP, FractalATPG,
FractalG. random control policy, step, random value assigned
control variable. also shown exhaustive control search expected
330

fiA Model-Based Active Testing Approach Sequential Diagnosis

number remaining MC diagnoses computed step, possible control
combination. works 74182 leads combinatorial blow-up
(larger) circuit.
74182, geometric decay fit

74182, remaining number MC diagnoses
40

40
Fractal P
Fractal ATPG
Fractal G
random controls
best controls

30

(S)

25

30

20
15

20
15
10

5

5
0
2

4

6

8

random controls
best controls

25

10

0

Fractal P
Fractal ATPG
Fractal G

35

N0 p k + N1

35

2

4

6

8

k

k

Figure 11: Comparison control policies
reduce stochastic error plotting Fig. 11, replaced sampling (for
computing expected number remaining MC diagnoses) exhaustive method;
possible |IN| = 5. randomized decision choose actual fault
initial ambiguity group. reduce error due stochastic fault injection,
tested 5 control policies 100 times.
see Fig. 11 least informed control policy (the random control policy
simply use E) shows worst decay number remaining diagnoses.
extreme, exhaustive control policy achieves best decay. price
policy terms computational effort, however, prohibitive. FractalG achieves
decay rates comparable exhaustive policy affordable average-case complexity.
FractalATPG better complexity FractalG, whole decay rate curve
FractalATPG bounded one computed FractalG.
Probing compare active testing approaches different assumptions observability model. Figure 11 shows decay rate probing
illustrate different decay curves depending observability assumptions.
experiment probing decay rate geometric fit p = 12 almost perfectly fits actual
number remaining MC diagnoses.

7. Conclusions
devised algorithm, FractalG, active testing (1) computationally
efficient (2) rapidly reduces diagnostic uncertainty (measured number
remaining MC diagnoses) manipulating set control variables. fully optimizing (2)
leads combinatorial blow-up, FractalG achieves compromise (1) (2)
using greedy approximation approach searching space control assignments
stochastic sampling method computing number remaining MC diagnoses.
result fast algorithm (optimizing whole Fractal scenario takes 1
331

fiFeldman, Provan, & van Gemund

74182 40 min c6288) decreases diagnostic uncertainty according
geometric decay curve. geometric decay curve fits Fractal data well (the
goodness-of-fit criterion R2 0.88 average) provides steep decay (the average decay
rate p 0.7).
applied FractalG real-world problem reducing diagnostic uncertainty heavy-duty printer (Feldman, 2010). purpose, modeled
Paper Input Module (PIM). PIM case-study, FractalG computed informative tests troubleshooting multiple sensor component failures. happens even
coarse-grained device model (only constraints per component), shows
unexpected benefit Fractal: trade-off modeling complexity vs. test effort.
optimality FractalG depends topology constraints input
model. create models leading arbitrarily bad optimality FractalG by,
example, directly encoding truth tables SD. practical situations, however, controls
independent. means applying single control rarely undoes effect
previous ones. also happens arbitrary inputs converted controls,
experimentation benchmark. Consider, example, multiplier (c6288). Leaving
inputs leads dont cares output hence components (full-adders,
and-gates) remain untested. Subsequently assigning values left-out inputs
unambiguously exonerate blame untested components, help narrowing
set diagnostic hypotheses.
important benefit applying Fractal industrial cases active
testing trade-offs modeling fidelity computational complexity extra testing.
enables users achieve good diagnostic certainty without large cost traditionally associated developing high fidelity models based physics failure precision
approaches.
compared optimality performance FractalG ATPG-based
algorithm sequential diagnosis, FractalATPG. average decay rate
algorithms similar (average p FractalATPG 0.73), average goodness-of-fit criterion R2 FractalATPG lower (0.84), means FractalG consistently
closer optimal solution FractalATPG . FractalG achieved better exponential decay compared algorithms except exhaustive control search. example,
difference decay rate p FractalG exhaustive search 74182
5.4%. exhaustive control approach, however, takes minutes complete even
circuit simple 74182, times-out model 20 controls.
result, conclude FractalG trades small decrease p significant
performance speedup.

References
Alur, R., Courcoubetis, C., & Yannakakis, M. (1995). Distinguishing tests nondeterministic probabilistic machines. Proc. ACM Symposium Theory Computing,
pp. 363372.
Brglez, F., & Fujiwara, H. (1985). neutral netlist 10 combinational benchmark circuits
target translator Fortran. Proc. ISCAS85, pp. 695698.
332

fiA Model-Based Active Testing Approach Sequential Diagnosis

Brodie, M., Rish, I., Ma, S., & Odintsova, N. (2003). Active probing strategies problem
diagnosis distributed systems. Proc. IJCAI03, pp. 13371338.
Bushnell, M. L., & Agrawal, V. D. (2000). Essentials Electronic Testing Digital,
Memory Mixed-Signal VLSI Circuits. Kluwer Academic Publishers, Boston.
de Kleer, J. (1986). Problem solving ATMS. Artificial Intelligence, 28 (2), 197224.
de Kleer, J. (2008). improved approach generating Max-Fault Min-Cardinality diagnoses. Proc. DX08, pp. 247252.
de Kleer, J., Raiman, O., & Shirley, M. (1992). One step lookahead pretty good.
Readings Model-Based Diagnosis, pp. 138142. Morgan Kaufmann Publishers, San
Francisco.
de Kleer, J., & Williams, B. (1987). Diagnosing multiple faults. Artificial Intelligence,
32 (1), 97130.
Deb, S., Ghoshal, S., Malepati, V. N., & Kleinman, D. L. (2000). Tele-diagnosis: Remote
monitoring large-scale systems. Proc. AEROCONF00, Vol. 6, pp. 3142.
Esser, M., & Struss, P. (2007). Fault-model-based test generation embedded software.
Proc. IJCAI07, pp. 342347.
Feldman, A. (2010). Approximation Algorithms Model-Based Diagnosis. Ph.D. thesis,
Delft University Technology.
Feldman, A., Provan, G., & van Gemund, A. (2008). Computing observation vectors
Max-Fault Min-Cardinality diagnoses. Proc. AAAI08, pp. 919924.
Feldman, A., Provan, G., & van Gemund, A. (2009a). FRACTAL: Efficient fault isolation
using active testing. Proc. IJCAI09, pp. 778784.
Feldman, A., Provan, G., & van Gemund, A. (2009b). Solving strong-fault diagnostic models
model relaxation. Proc. IJCAI09, pp. 785790.
Forbus, K., & de Kleer, J. (1993). Building Problem Solvers. MIT Press.
Hansen, M., Yalcin, H., & Hayes, J. (1999). Unveiling ISCAS-85 benchmarks: case
study reverse engineering. IEEE Design & Test, 16 (3), 7280.
Heinz, S., & Sachenbacher, M. (2008). Using model counting find optimal distinguishing
tests. Proc. COUNTING08, pp. 91106.
Ibarra, O. H., & Sahni, S. K. (1975). Polynomially complete fault detection problems. IEEE
Trans. Computers, 24 (3), 242249.
Kuhn, L., Price, B., de Kleer, J., Do, M., & Zhou, R. (2008). Pervasive diagnosis: Integration
active diagnosis production plans. Proc. DX08, pp. 106119.
Kundakcioglu, O. E., & Unluyurt, T. (2007). Bottom-up construction minimum-cost
and/or trees sequential fault diagnosis. IEEE Trans. SMC, 37 (5), 621629.
Pattipati, K., & Alexandridis, M. (1990). Application heuristic search information
theory sequential fault diagnosis. IEEE Trans. SMC, 20 (4), 872887.
Pietersma, J., & van Gemund, A. (2006). Temporal versus spatial observability modelbased diagnosis. Systems, Man Cybernetics, 2006, 6, 53255331.
333

fiFeldman, Provan, & van Gemund

Prasad, M. R., Chong, P., & Keutzer, K. (1999). ATPG easy. Proc. DAC99, pp.
2228.
Raghavan, V., Shakeri, M., & Pattipati, K. (1999). Optimal near-optimal test sequencing algorithms realistic test models. IEEE Trans. SMC, 29 (1), 1126.
Rish, I., Brodie, M., & Ma, S. (2002). Accuracy vs. efficiency trade-offs probabilistic
diagnosis. Proc. AAAI02, pp. 560566.
Shakeri, M. (1996). Advances System Fault Modeling Diagnosis. Ph.D. thesis,
University Connecticut.
Shakeri, M., Raghavan, V., Pattipati, K. R., & Patterson-Hine, A. (2000). Sequential testing
algorithms multiple fault diagnosis. IEEE Trans. SMC, 30 (1), 114.
Siddiqi, S., & Huang, J. (2007). Hierarchical diagnosis multiple faults. Proc. IJCAI07,
pp. 581586.
Stephan, P., Brayton, R., & Sangiovanni-Vincentelli, A. (1996). Combinational test generation using satisfiability. IEEE Trans. CAD Integrated Circuits Systems,
15 (9), 11671176.
Struss, P. (1994). Testing physical systems. Proc. AAAI94, pp. 251256.
Tu, F., & Pattipati, K. (2003). Rollout strategies sequential fault diagnosis. IEEE Trans.
SMC, 33 (1), 8699.

334

fiJournal Artificial Intelligence Research 39 (2010) 581632

Submitted 12/09; published 11/10

Clustering Want?
Inducing Ideal Clustering Minimal Feedback
Sajib Dasgupta
Vincent Ng

sajib@hlt.utdallas.edu
vince@hlt.utdallas.edu

Human Language Technology Research Institute
University Texas Dallas
800 West Campbell Road; Mail Station EC31
Richardson, TX 75080-3021 U.S.A.

Abstract
traditional research text clustering largely focused grouping documents
topic, conceivable user may want cluster documents along dimensions,
authors mood, gender, age, sentiment. Without knowing users intention,
clustering algorithm group documents along prominent dimension,
may one user desires. address problem clustering documents
along user-desired dimension, previous work focused learning similarity metric
data manually annotated users intention human construct
feature space interactive manner clustering process. goal
reducing reliance human knowledge fine-tuning similarity function selecting
relevant features required approaches, propose novel active clustering
algorithm, allows user easily select dimension along wants
cluster documents inspecting small number words. demonstrate
viability algorithm variety commonly-used sentiment datasets.

1. Introduction
Text clustering one major application domains demonstrating viability
clustering algorithm. traditional research text clustering largely focused
grouping documents topic, conceivable user may want cluster documents along dimensions, authors mood, gender, age, sentiment. Since
virtually existing text clustering algorithms produce one clustering given
set documents, natural question is: clustering necessarily one user desires? words, text clustering algorithm always produce clustering along
user-desired dimension?
answer question depends large extent whether user successfully communicate intention clustering algorithm. Traditionally,
achieved designing good similarity function capture similarity
pair documents, ideal clustering produced. typically involves
identify set features useful inducing desired clusters (Liu, Li,
Lee, & Yu, 2004). However, manually identifying right set features timeconsuming knowledge-intensive, may even require lot domain expertise.
fact resulting similarity function typically easily portable domains
particularly unappealing machine-learning perspective. overcome weakness,
c
2010
AI Access Foundation. rights reserved.

fiDasgupta & Ng

researchers attempted learn similarity metric side information (Xing, Ng,
Jordan, & Russell, 2002), constraints pairs documents must must
appear cluster (Wagstaff, Cardie, Rogers, & Schrodl, 2001).
contrast, recent work focused active clustering, clustering algorithm
incorporate user feedback clustering process help ensure documents grouped according user-desired dimension. One way
user incrementally construct set relevant features interactive fashion (Bekkerman, Raghavan, Allan, & Eguchi, 2007; Raghavan & Allan, 2007; Roth & Small, 2009).
Another way user correct mistakes made clustering algorithm
clustering iteration specifying whether two existing clusters merged
split (Balcan & Blum, 2008). major drawback associated active clustering
algorithms involve considerable amount human feedback, needs
provided iteration clustering process. Furthermore, identifying clusters
merging splitting Balcan Blums algorithm may easy appears:
merge split decision user makes, sample large number
documents cluster(s), read documents, base decision
extent documents (dis)similar other.
article, attack problem clustering documents according user interest
different angle. aim knowledge-lean approach problem
approach produce clustering documents along user-desired dimension
without relying human knowledge fine-tuning similarity function selecting
relevant features, unlike existing approaches. end, propose novel active
clustering algorithm, assumes input simple feature representation (composed
unigrams only) simple similarity function (i.e., dot product), operates
(1) inducing important clustering dimensions1 given set documents,
clustering dimension represented (small) number automatically selected words
representative dimension; (2) user choose dimension along
wants cluster documents examining automatically selected words.
comparison aforementioned feedback mechanisms, arguably much simpler:
require user cursory look small number features
dimension all, opposed user generate feature space
interactive manner identify clusters need merged split clustering
iteration.
evaluate active clustering algorithm task sentiment-based clustering,
goal cluster set documents (e.g., reviews) according polarity
(e.g., thumbs thumbs down) expressed author without using labeled
data. decision focus sentiment-based clustering motivated several reasons.
One reason relatively little work sentiment-based clustering.
mentioned before, existing work text clustering focused topic-based clustering,
high accuracies achieved even datasets large number classes
(e.g., 20 Newsgroups); despite large amount recent work sentiment analysis
1. use term clustering dimension refer dimension along set documents
clustered. example, set movie reviews clustered according genre (e.g., action, romantic,
documentary) sentiment (e.g., positive, negative, neutral).

582

fiInducing Ideal Clustering Minimal Feedback

Review 1
sound system seem little better
(the CDs skipping much). bottom line
didnt fix problem CDs still skipping noticeably,
although bad before. ...
Review 2
John Lynch wrote classic Spanish-American Revolutions 1808-1826.
describes events led independence Latin America Spain.
book starts Rio de La Plata ends Mexico Central America.
Curiously one note common pattern highly stratified societies lead Spanish ...
reluctance Spanish Monarchy (and later even liberals) led independence ...
interested better understanding Latin ??this great book must.
Lynch cleverly combines historical economic facts Hispanic American societies ...

Table 1: Snippets two reviews illustrate two challenges polarity classification.
One reviews sentimentally ambiguous (Review 1),
objective materials review significantly outnumber subjective counterparts
(Review 2).

opinion mining, much focused supervised methods (see Pang & Lee, 2008,
comprehensive survey field).
Another equally important reason focus sentiment-based clustering concerned challenges task presents natural language processing (NLP)
researchers. Broadly speaking, complexity sentiment-based clustering arises
two sources. First, reviews sentimentally ambiguous, containing positive negative sentiment-bearing words phrases. Review 1 Table 1 shows snippet
review DVD domain illustrates sentimental ambiguity problem:
phrases little better, skipping, bad convey positive sentiment,
phrases didnt fix skipping noticeably negative sentiment-bearing. Hence,
unless sentiment analyzer performs deeper linguistic analysis, difficult
analyzer determine polarity review. Second, objective materials review tend significantly outnumber subjective counterparts, reviewer typically
devotes large portion review describing features product assigning rating it; consequently, sentiment analyzer uses word- phrase-based
feature representation composed mostly features irrelevant respect
polarity determination. Shown Review 2 Table 1 snippet book review
illustrates problem. see, three words/phrases (classic, great
book, cleverly) review correspond objective materials.
aforementioned complications present significant challenges even supervised polarity classification systems, let alone sentiment-based clustering algorithms,
access labeled data. illustrate difficulty two complications impose sentiment-based clustering, consider task clustering set movie
reviews. Since review may contain description plot authors sentiment,
clustering algorithm may cluster reviews along either plot dimension sentiment
dimension; without knowing users intention, clustered along
583

fiDasgupta & Ng

prominent dimension. Assuming usual bag-of-words representation, prominent
dimension likely plot, uncommon review devoted almost
exclusively plot, author briefly expressing sentiment end
review. Even reviews contain mostly subjective materials, prominent
dimension may still sentiment owing aforementioned sentimental ambiguity
problem: presence positive negative sentiment-bearing words reviews renders sentiment dimension hidden (i.e., less prominent) far clustering
concerned.
sum, contributions article five-fold.
propose novel active clustering algorithm cluster set documents
along user-desired dimension without labeled data side information
manually specified automatically acquired must-link cannot-link constraints.
comparison existing active clustering approaches, algorithm appeal
requiring much simpler human feedback.
demonstrate viability algorithm evaluating performance
sentiment datasets, also via set human experiments, typically
absent papers involve algorithms incorporating user feedback.
results led deeper understanding spectral clustering. Specifically,
propose novel application top eigenvectors produced spectral clustering
algorithm, use unveil important clustering dimensions text
collection.
results also implications domain adaptation, topic recently
received lot attention NLP community. Specifically, show
sentiment dimension manually identified one domain used automatically
identify sentiment dimension new, similar, domain.
Preliminary results datasets possess one clustering dimension (e.g.,
collection book DVD reviews, clustered sentiment
type product concerned) indicate algorithm capable producing
multiple clusterings dataset, one along dimension. Hence, algorithm
potentially reveal information dataset possible traditional
clustering algorithms, produce single clustering data.
ability produce multiple clusterings particularly useful feature user
idea wants documents clustered (due
lack knowledge data, instance). Even user knowledge
data knows wants documents clustered, algorithm help
unveil hidden dimensions previously aware may also
interest her.
rest article organized follows. Section 2 presents basics spectral
clustering, facilitate discussion active clustering algorithm Section
3. describe human experiments evaluation results several sentiment datasets
Section 4 significance work Section 5. Finally, discuss related work
Section 6 conclude Section 7.
584

fiInducing Ideal Clustering Minimal Feedback

2. Spectral Clustering
given clustering task, important question ask is: clustering algorithm
use? popular choice k-means. Nevertheless, well-known k-means
major drawback able separate data points linearly separable
given feature space (e.g., see Dhillon, Guan, & Kulis, 2004; Cai, He, & Han, 2005).
Moreover, since k-means clusters documents directly given feature space,
text applications typically comprises hundreds thousands features, performance
could adversely affected curse dimensionality. Spectral clustering algorithms
developed response problems k-means. section, first present
one commonly-used algorithms spectral clustering (Section 2.1). Then,
provide intuition behind spectral clustering (Section 2.2). Finally, describe two ways
use resulting eigenvectors produce clustering (Section 2.3).
2.1 Algorithm
Let X={x1 , . . . , xn } set n data points clustered, : X X similarity
function defined X, similarity matrix captures pairwise similarities
(i.e., Si,j = s(xi , xj )). Like many clustering algorithms, spectral clustering algorithm
takes input outputs k-way partition C = {C1 , C2 , .., Ck } (i.e., ki=1 Ci = X
i, j : 6= j = Ci Cj = ). Equivalently, one think spectral clustering learning
partitioning function f , which, rest article, represented vector
f (i) {1, . . ., k} indicates cluster xi assigned. Note
cluster labels interchangeable even renamed without loss
generality.
Among well-known spectral clustering algorithms (e.g., Weiss, 1999; Shi & Malik,
2000; Kannan, Vempala, & Vetta, 2004), adopt one proposed Ng, Jordan,
Weiss (2001), arguably widely-used. main steps Ng et
al.s spectral clustering algorithm:
1. Create diagonal matrix whose (i,i)-th entry sum i-th row S,
construct Laplacian matrix2 L = 1/2 SD 1/2 .
2. Find eigenvalues eigenvectors L.
3. Create new matrix eigenvectors correspond largest eigenvalues.
4. data point rank-reduced point m-dimensional space. Normalize
point unit length (while retaining sign value).
5. Apply k-means cluster data points using resulting eigenvectors.
words, spectral clustering clusters data points low-dimensional space,
dimension corresponds top eigenvector Laplacian matrix.
2. follow Ng et al. (2001) employ normalized dual form usual Laplacian S.

585

fiDasgupta & Ng

2.2 Intuition behind Spectral Clustering
may immediately clear spectral clustering produces meaningful partitioning set points. theoretical justifications behind spectral clustering,
since mathematics quite involved, provide intuitive justification
clustering technique way sufficient reader understand active
clustering algorithm Section 3, refer interested reader Shi Maliks (2000)
seminal paper spectral clustering details. Since apply spectral clustering
produce 2-way clustering given set data points rest article,
center discussion 2-way clustering subsection.
Spectral clustering employs graph-theoretic notion grouping. Specifically, set
data points arbitrary feature space represented undirected weighted graph,
node corresponds data point, edge weight two nodes xi
xj similarity, Si,j .
Given graph formulation, reasonable way produce 2-way partitioning
data points minimize similarity resulting two clusters, C1 C2 .
Hence, reasonable objective function minimize cut value,
X
Cut(C1 , C2 ) =
Si,j (f (i) f (j))2 .
i,j

Without loss generality, define f follows.

1 : C1
f (i) =
1 : C2
mentioned before, use 1 1 cluster labels here, interchangeable
fact renamed whatever way want.
One problem minimizing cut value, noticed Wu Leahy (1993),
objective favors producing unbalanced clusters one contains
small number nodes. words, bias towards isolating small set
nodes. mentioned Shi Malik (2000), surprising, since
number edges involved cut (and hence cut value) tends increase sizes
two clusters become relatively balanced.
closer examination minimum cut criterion reveals problem: minimizes inter-cluster similarity, makes attempt maximize intra-cluster similarity.
address weakness, Shi Malik (2000) propose minimize instead normalized
cut value, N Cut, takes account inter-cluster dissimilarity intra-cluster
similarity. specifically,
Cut(C1 , C2 )
Cut(C1 , C2 )
+
,
assoc(C1 , C1 C2 ) assoc(C2 , C1 C2 )
P
assoc(A, B), computed xi A,xj B Si,j , total connection nodes
nodes B. Given definition, cut resulting unbalanced clusters
longer small N Cut value. see reason, consider case C1 consists
one node. case, assoc(C1 , C1 C2 ) = Cut(C1 , C2 ), making N Cut(C1 , C2 ) large.
N Cut(C1 , C2 ) =

586

fiInducing Ideal Clustering Minimal Feedback

algebra, express N Cut follows:
N Cut(C1 , C2 ) =

f (D S)f
f Df

subject constraints (Df )T 1 = 0
rP
d(i)


PiC2

iC1 d(i)
rP
f (i) =
d(i)


PiC1 d(i)
iC2

: C1
: C2

d(i) = D(i, i), defined Section 2.1.3 first constraint, specifies
Df orthogonal 1, intuitively understood follows: since 1, constant
vector entries 1, cannot used induce partition, constraint
avoids trivial solution points assigned cluster.
Unfortunately, Papadimitriou proves minimizing normalized cut NP-complete
problem, even special case graphs regular grids (see Shi & Malik, 2000,
proof). Hence, following Shi Malik, relax minimization problem dropping
second constraint allowing entry f take real value rather one
two discrete values, seeking real-valued solution following problem:
minn

f

f (D S)f
f Df

(1)

subject
Df 1.
Assuming g = 1/2 f , rewrite Problem (1)
minn

g

gT 1/2 (D S)D 1/2 g
gT g

(2)

subject
g 1/2 1.
Following standard Rayleigh-Ritz theorem, one prove solution
Problem (2), g, eigenvector corresponds second smallest eigenvalue
1/2 (D S)D 1/2 , equivalently, eigenvector corresponds second largest
eigenvector D1/2 SD 1/2 , Laplacian matrix L defined Section 2.1.
simplicity, henceforth refer eigenvector corresponds n-th largest
eigenvalue L simply n-th eigenvector denote en .4
3. Besides normalized cut, ratio cut (Chan, Schlag, & Zien, 1994), average association (Shi & Malik, 2000),
min-max cut (Ding, He, Zha, Gu, & Simon, 2001) also used objective functions
spectral clustering algorithms.
4. Given Problem (2) involves minimizing Rayleigh quotient, may seem somewhat unintuitive
solution second eigenvector L rather first eigenvector. reason attributed
constraint associated problem, specifies solution g perpendicular
D1/2 1, first eigenvector L.

587

fiDasgupta & Ng

idea behind spectral clustering: second eigenvector L approximate solution problem minimizing normalized cut.5 course, since second
eigenvector real-valued solution, convert partitioning function
used cluster data points. Section 2.3 explains two simple ways
converting eigenvector partitioning function.
turns eigenvectors L also convey useful information
data. Specifically, impose additional constraint Problem (2) forcing solution orthogonal second eigenvector L, solution becomes third
eigenvector. Hence, third eigenvector thought suboptimal solution
Problem (2), meaning also used impose reasonably good partition
data points. Perhaps importantly, since eigenvectors L orthogonal
(because L symmetric), clustering produced using third eigenvector
likely correspond different dimension data produced second
eigenvector.
generally, limit solution space real-valued vectors
orthogonal first eigenvectors L, solution constrained optimization
problem (m + 1)-th eigenvector L. words, top eigenvectors
L intuitively thought revealing important dimension data, although
subsequent eigenvectors progressively less ideal far clustering concerned.
2.3 Clustering Eigenvectors
Ng et al. (2001) point out, different authors still disagree eigenvectors
use, derive clusters them. subsection, describe two common
methods determining eigenvectors use, method, show
derive clusters using selected eigenvector(s). methods serve baselines
evaluation.
2.3.1 Method 1: Using Second Eigenvector
Since Shi Malik (2000) show second eigenvector, e2 , approximate solution
problem minimizing normalized cut, perhaps surprising
e2 commonly chosen eigenvector deriving partition. However, since e2
real-valued solution constrained optimization problem, need specify
derive clusters it.
Clustering using e2 trivial: since linearization points, one simple way
determine threshold partitioning them. However, follow Ng et al. (2001)
cluster points using 2-means one-dimensional space.
2.3.2 Method 2: Using Top Eigenvectors
Recall Section 2.1 eigen-decomposing Laplacian matrix, data point
represented co-ordinates. second method, use 2-means cluster data
points m-dimensional space, effectively exploiting top eigenvectors.
5. fact, since f = D1/2 g, pre-multiply second eigenvector L D1/2 get
solution Problem (1), following Ng et al. (2001), employ second eigenvector L directly
clustering, ignoring term D1/2 .

588

fiInducing Ideal Clustering Minimal Feedback

3. Active Clustering Algorithm
mentioned before, sentiment-based clustering challenging, part due fact
reviews clustered along one dimension. section, describe
active clustering algorithm, makes easy user specify dimension
along wants cluster data points sentiment. Recall algorithm first
applies spectral clustering reveal important dimensions data,
lets user select desired dimension (i.e., sentiment). motivate importance
user feedback, helps understand two baseline clustering algorithms described
Section 2.3, also based spectral methods rely user feedback, may always yield sentiment-based clustering. begin with, consider first
method, second eigenvector used induce partition. Recall
second eigenvector reveals prominent dimension data. Hence, sentiment
prominent dimension (which happen non-sentiment-bearing words
outnumber sentiment-bearing words bag-of-words representation review),
resulting clustering reviews may sentiment-oriented. similar line
reasoning used explain second baseline clustering algorithm,
clusters based top eigenvectors, may always work well. Since eigenvector corresponds different dimension (and, particular, correspond
non-sentiment dimensions), using represent review may hamper accurate computation similarity two reviews far clustering along sentiment
dimension concerned. rest section, discuss detail major steps
active clustering algorithm, allows easy incorporation user feedback.
3.1 Step 1: Identify Important Clustering Dimensions
rely simple method identifying important clustering dimensions given
text collection: employ top eigenvectors Laplacian important clustering dimensions. method motivated fact e2 , second eigenvector
Laplacian, optimal real-valued solution objective function spectral
clustering minimizes (i.e., normalized cut, Shi & Malik, 2000), therefore optimal
clustering dimension. importantly, exploit rarely-utilized observation discussed
Section 2.2: remaining eigenvectors suboptimal solutions (with ei suboptimal increases), top eigenvectors (i.e., small values),
less suboptimal, may still yield reasonably good (though optimal) clusterings
data therefore serve good clustering dimensions. Existing applications
spectral clustering mainly clustered data points space defined top
eigenvectors, attempted use ei (with > 2) separately
produce clusterings, unlike ours. Note first eigenvector, constant vector,
simply assigns data points cluster therefore typically ignored.
3.2 Step 2: Identify Relevant Features Partition
Given eigen-decomposition Step 1, first obtain second m-th
eigenvectors, correspond important dimensions data. next
question is: determine dimension captures user interest? One way
589

fiDasgupta & Ng

user inspect m1 partitions reviews decide
corresponds closely sentiment-based clustering. main drawback associated
kind user feedback user may read large number reviews
order make decision. Hence, reduce human effort, employ alternative
procedure: (1) identify informative features characterizing partition,
(2) user inspect features rather reviews. make easy
human identify clustering dimension, features chosen
useful distinguishing reviews two clusters.
identify rank informative features, employ method call maximum
margin feature ranking (MMFR).6 Recall maximum margin classifier (e.g., support
vector machine) separates data points two classes maximizing margin
separation. Specifically, maximum margin hyperplane defined w x b = 0,
x feature vector representing arbitrary data point, w (a weight vector) b (a
scalar) parameters learned solving following constrained optimization
problem:
X
1

min kwk2 + C
2

subject
ci (w xi b) 1 ,

1 n,

ci {+1, 1} class i-th training point xi , degree misclassification xi , C regularization parameter balances training error model
complexity.
use w identify informative features partition. Note
informative features large absolute weight values: feature large
positive (negative) weight strongly indicative positive (negative) class.7 exploit
observation identify informative features partition (1) training
binary SVM classifier8 partition, data points cluster assumed
class value; (2) sorting features according SVM-learned feature
weights; (3) generating two ranked lists informative features using top bottom
F features, respectively.
Given ranked lists generated 1 partitions, user select one
partitions/dimensions relevant sentiment inspecting many features
ranked lists needed. picking relevant dimension, user
label one two feature lists associated dimension positive
negative. Since feature list represents one clusters, cluster associated
positive list labeled positive cluster associated negative list
labeled negative.
6. Note commonly-used feature selection techniques log-likelihood ratio information
gain also applied identify informative features (see Yang & Pedersen, 1997,
overview).
7. notion using SVM feature weights measures feature informativeness also explored
work. See, instance, work Fung (2003), Gilad-Bachrach, Navot, Tishby (2004),
Kugler, Aoki, Kuroyanagi, Iwata, Nugroho (2005) details.
8. SVM classifiers article trained using SVMlight package (Joachims, 1999a),
learning parameters set default values.

590

fiInducing Ideal Clustering Minimal Feedback

comparison existing user feedback mechanisms assisting clustering algorithm,
requires comparatively little human intervention: require user select
dimension examining small number features, opposed user construct
feature space identify clusters need merged split required
methods.
3.3 Step 3: Identify Unambiguous Reviews
caveat, however. mentioned introduction, many reviews contain
positive negative sentiment-bearing words. ambiguous reviews likely
clustered incorrectly unambiguous counterparts. Since ranked lists
features derived partition, presence ambiguous reviews
adversely affect identification informative features using MMFR. result,
remove ambiguous reviews deriving informative features partition.
employ simple method identifying unambiguous reviews. computation
eigenvalues, data point factors orthogonal projections
data points affinity. Ambiguous data points receive orthogonal
projections positive negative data points, hence near zero
values pivot eigenvectors. words, points near zero values
eigenvectors ambiguous large absolute values. therefore sort
data points according corresponding values eigenvector, keep
top n/8 bottom n/8 data points. induce informative features
resulting 25% data points, present user select
desired partition.9
3.4 Step 4: Cluster Along Selected Eigenvector
Finally, employ 2-means cluster reviews along eigenvector selected
user, regardless whether review ambiguous not.

4. Evaluation
section, describe experiments aim evaluate effectiveness active
clustering algorithm provide insights it.
4.1 Experimental Setup
begin discussing details datasets, document preprocessing method,
implementation spectral clustering, evaluation metrics.
9. Note 25% somewhat arbitrary choice. Underlying choice merely assumption
fraction reviews unambiguous. see evaluation section, reviews
classified according polarity high accuracy; consequently, features induced
resulting clusters also high quality. Additional experiments revealed list top-ranking
features change significantly induced smaller number unambiguous reviews.

591

fiDasgupta & Ng

4.1.1 Datasets
use five sentiment datasets, including widely-used movie review dataset [MOV]
(Pang, Lee, & Vaithyanathan, 2002) well four datasets containing reviews four
different types products Amazon [Books (BOO), DVDs (DVD), Electronics (ELE),
Kitchen Appliances (KIT)] (Blitzer, Dredze, & Pereira, 2007). dataset 2000
labeled reviews (1000 positives 1000 negatives). illustrate difference
topic-based clustering sentiment-based clustering, also show topic-based clustering results POL, dataset created taking documents two sections
20 Newsgroups discuss issues cryptography politics, namely, sci.crypt
talks.politics.
4.1.2 Document Preprocessing
preprocess document, first tokenize downcase it, represent
vector unstemmed unigrams, assumes value 1 0 indicates
presence absence document. addition, remove vector punctuation,
numbers, words length one, words occur single review.
Following common practice information retrieval community, also exclude
words high document frequency, many stopwords domain-specific
general-purpose words (e.g., movies movie domain). preliminary examination
evaluation datasets reveals words typically comprise 12% vocabulary.
decision exactly many terms remove dataset subjective: large
corpus typically requires removals small corpus. consistent, simply
sort vocabulary document frequency remove top 1.5%. henceforth
refer document representation bag-of-words (BOW) representation.
4.1.3 Spectral Learning Setup
Following common practice spectral learning text domains (e.g., Kamvar, Klein,
& Manning, 2003; Cai et al., 2005), compute similarity two reviews
taking dot product feature vectors. Ng et al.s (2001) spectral clustering
algorithm, set diagonal entries similarity matrix 0. addition, set
5. words, consider second fifth eigenvectors, assuming
sufficient capturing desired clusterings.10
4.1.4 Evaluation Metrics
employ two evaluation metrics. First, report results dataset terms
accuracy, percentage documents label assigned system
gold-standard label. Second, following Kamvar et al. (2003), evaluate
clusters produced approach gold-standard clusters using Adjusted
Rand Index (ARI), corrected-for-chance version Rand Index.
specifically, given set N data points two clusterings points, U V ,
10. Note setting 5 somewhat arbitrary choice, number eigenvectors
used active clustering algorithm.

592

fiInducing Ideal Clustering Minimal Feedback

U = {U1 , U2 , . . . , Um } clusters V = {V1 , V2 , . . . , Vn } n clusters, ARI
computed follows:
nij
2

P bj
P
[ a2i
j 2 ]/
ARI(U, V ) = 1 P P b
P
ai P
j

j 2 ][ 2
j
2[ 2 +
P

ij

N
2
bj
N
2 ]/ 2



formula, nij number common objects Ui Vj ; whereas ai bj
number objects Ui Vj , respectively. ARI ranges 1 1; better clusterings
higher ARI values.
4.2 Baseline Systems
subsection, describe baseline results. first two baseline systems
ones described Section 2.3, last two arguably sophisticated clustering
algorithms employed attempt strengthen baseline results.
4.2.1 Clustering Using Second Eigenvector
first baseline, adopt Shi Maliks (2000) approach cluster reviews
using second eigenvector, e2 , described Section 2.3. Results POL
sentiment datasets, expressed terms accuracy ARI, shown row 1 Tables 2a
2b, respectively. Owing randomness choice seeds 2-means,
experimental results involving 2-means averaged ten independent runs.11
see, baseline achieves accuracy 93.7% POL, much lower
accuracies (of 5070%) sentiment datasets. performance trend
observed ARI. results provide suggestive evidence producing sentimentbased clustering requires different features producing topic-based clustering,
many cases, salient features tend topic-based. difference
sentiment-based clustering topic-based clustering illuminated
experiments Section 4.7.
addition, worth noting baseline achieves much lower accuracies
ARI values BOO, DVD, ELE remaining two sentiment datasets. Since
e2 captures prominent dimension, results suggest sentiment dimension
prominent dimension three datasets. fact, intuitively
plausible. instance, book domain, positive book reviews typically contain
short description content, reviewer briefly expressing sentiment
somewhere review. Similarly electronics domain: electronic product reviews
typically aspect-oriented, reviewer talking pros cons
aspect product (e.g., battery, durability). Since reviews likely contain
positive negative sentiment-bearing words, sentiment-based clustering unlikely
captured e2 .
11. Note clustering one-dimensional space (as baseline) yields stable results regardless
choice seeds: results ten runs exhibit nearly zero variance.

593

fiDasgupta & Ng

System Variation
2nd eigenvector
Top five eigenvectors
Interested Reader Model
NMF
system

POL
93.7
95.9
98.7
70.3
93.7

MOV
70.9
58.9
61.8
71.3
70.9

Accuracy
KIT BOO
69.7 58.9
64.0 59.9
62.2 52.5
66.9 52.1
69.7 69.5

DVD
55.3
60.4
50.6
50.3
70.8

ELE
50.8
63.8
50.2
63.8
65.8

(ARI)
DVD
0.01
0.03
0.01
0.01
0.17

ELE
0.01
0.07
0.01
0.08
0.10

(a)

System Variation
2nd eigenvector
Top five eigenvectors
Interested Reader Model
NMF
system

POL
0.76
0.84
0.94
0.16
0.76

Adjusted Rand Index
MOV KIT BOO
0.17 0.15 0.03
0.03
0.05 0.04
0.05
0.06 0.01
0.18 0.11 0.01
0.17 0.15 0.15

(b)

Table 2: Results terms (a) accuracy (b) Adjusted Rand Index six datasets
obtained using bag-of-words document representation. strongest result(s)
dataset boldfaced.

4.2.2 Clustering Using Top Five Eigenvectors
second baseline, represent data point using top five eigenvectors (i.e., e1
e5 ), cluster using 2-means five-dimensional space, described
Section 2.3. Hence, thought ensemble approach, clustering
decision collectively made five eigenvectors.12
Results shown row 2 Tables 2a 2b.13 comparison first baseline,
see improvements accuracy ARI POL three sentiment datasets
first baseline performs poorly (i.e., BOO, DVD, ELE), drastic
improvement observed ELE. However, performance remaining two sentiment
datasets deteriorates. results attributed fact BOO, DVD,
ELE, e2 capture sentiment dimension, since eigenvector
ensemble does, see improvements. hand, e2 already captured
sentiment dimension MOV KIT; result, employing additional dimensions,
may sentiment-related, may introduce noise computation
similarities reviews.
12. first eigenvector produce trivial clustering data points reside
cluster, commonly used combination top eigenvectors create low-dimensional
space data points clustered. See work Ng et al. (2001) details.
13. clustering five-dimensional space, observe results highly sensitive
choice seeds. instance, variances accuracy observed ten runs POL, MOV,
KIT, BOO, DVD, ELE 0, 2.38, 19.90, 24.70, 12.76, 4.43, respectively.

594

fiInducing Ideal Clustering Minimal Feedback

4.2.3 Clustering Using Interested Reader Model
third baseline Kamvar et al.s (2003) unsupervised clustering algorithm, which, according authors, ideally suited text clustering, recently proved
special case ratio-cut optimization (Kulis, Basu, Dhillon, & Mooney, 2009). Specifically, introduce new Laplacian inspired Interested Reader Model.
Laplacian computed (S + dmax D)/dmax , defined Section
2.1, except Si,j =0 one js k nearest neighbors j one k
nearest neighbors; dmax maximum rowsum S; identity matrix. Since
performance highly sensitive k, tested values 10, 15, . . ., 500 k report row 3 Tables 2a 2b best results. Somewhat disappointingly, despite
algorithmic sophistication fact reporting best results, baseline
offer consistent improvements previous two. comparison first
baseline, achieves better performance POL worse performance sentiment
datasets. Like first baseline, results BOO, DVD ELE particularly poor.
4.2.4 Clustering Using Non-Negative Matrix Factorization
Non-negative matrix factorization (NMF) recently shown Xu, Liu, Gong
(2003) effective document clustering. re-implementing algorithm,
evaluate six datasets.14 Shown row 4 Tables 2a 2b best results obtained running algorithm five times. comparison first baseline,
NMF achieves better performance ELE, comparable performance MOV, worse
performance remaining datasets.
4.3 Active Clustering Algorithm
subsection, describe human automatic experiments evaluating active
clustering algorithm.
4.3.1 Human Experiments
Unlike four baselines, active clustering algorithm requires users specify
four dimensions (defined second fifth eigenvectors) closely
related sentiment inspecting set features derived unambiguous reviews
dimension using MMFR. better understand easy human select
desired dimension given features, performed experiment independently
five humans (all computer science graduate students affiliated
research) computed agreement rate.
Specifically, dataset, showed human judge top 100 features
cluster according MMFR (see Tables 38 subset 100 features induced
six datasets, lightly shared columns correspond sentiment
dimension selected majority human judges).15 addition, informed
14. matrix factorization use code downloaded http://www.csie.ntu.edu.tw/cjlin/nmf/index.html.
15. human judges reported inspecting top 100 features sufficient identifying
sentiment dimension, note user clustering algorithm may request inspect many
features wants.

595

fiDasgupta & Ng

e2
C1
serder
armenian
turkey
armenians
muslims
sdpa
argic
davidian
dbd@ura
troops
C2
sternlight

pgp
crypto
algorithm

likely
access
idea
cryptograph

POL
e3
e4
C1
C1
beyer
serbs
arabs
palestinians
andi
muslims
research
wrong
israelis
department
tim
bosnia
uci
live
ab
matter
z@virginia
freedom
holocaust
politics
C2
escrow
sternlight
algorithm
access
net
des
privacy
uk
systems
pgp

C2
standard
sternlight
des
escrow
employer
net
york
jake
code
algorithm

e5
C1
escrow
serial
algorithm
chips
ensure
care
strong
police
omissions
excepted
C2
internet
uucp
uk
net
quote
ac
co

ai
mit

Table 3: Top ten features induced dimension POL domain. shaded
columns correspond dimensions selected human judges. e2 , . . ., e5 top eigenvectors; C1 C2 clusters.

596

fiInducing Ideal Clustering Minimal Feedback

e2
C1
relationship
son
tale
husband
perfect
drama
focus
strong
beautiful
nature
C2
worst
stupid
waste
bunch

video
worse
boring
guess
anyway

MOV
e3
e4
C1
C1
production
jokes
earth
kids
sequences
live
aliens
animation
war
disney
crew
animated
alien
laughs
planet
production
horror
voice
evil
hilarious
C2
sex
romantic
school
relationship
friends
jokes
laughs
sexual
cute
mother

C2
thriller
killer
murder
crime
police
car
dead
killed
starts
violence

e5
C1
starts
person
saw
feeling
lives
told
happen

felt
happened
C2
comic
sequences
michael
supporting
career
production
peter
style
latest
entertaining

Table 4: Top ten features induced dimension MOV domain. shaded
columns correspond dimensions selected human judges. e2 , . . ., e5 top eigenvectors; C1 C2 clusters.

597

fiDasgupta & Ng

BOO
e2
C1
history
must
modern
important
text
reference
excellent
provides
business


e3
C1
series
man
history
character
death

war
seems
political
american

e4
C1
loved
highly
easy
enjoyed
children

although
excellent
understand
three

e5
C1
must
wonderful
old
feel
away
children
year
someone
man
made

C2
plot

thought
boring
got
character


ending
fan

C2
buy
bought
information
easy
money
recipes
pictures
look
waste
copy

C2
money
bad
nothing
waste
buy
anything

already
instead
seems

C2
boring
series
history
pages
information

highly
page
excellent


Table 5: Top ten features induced dimension BOO domain. shaded
columns correspond dimensions selected human judges. e2 , . . ., e5 top eigenvectors; C1 C2 clusters.

598

fiInducing Ideal Clustering Minimal Feedback

ELE
e2
C1
mouse
cable
cables
case
red
monster
picture
kit
overall
paid

e3
C1
music
really
ipod

little
headphones
hard
excellent
need
fit

e4
C1
easy
used
card
fine
using
problems
fine
drive
computer
install

e5
C1
amazon
cable
card
recommend
dvd
camera
fast
far
printer
picture

C2
working
never

phone
days
headset
money
months
return
second

C2
worked
problem
never
item
amazon
working
support
months
returned
another

C2
money
worth
amazon

return
years
much
headphones
sony
received

C2
phone

worked
power
battery
unit
set
phones
range
little

Table 6: Top ten features induced dimension ELE domain. shaded
columns correspond dimensions selected human judges. e2 , . . ., e5 top eigenvectors; C1 C2 clusters.

599

fiDasgupta & Ng

e2
C1
love
clean
nice
size
set
kitchen
easily
sturdy
recommend
price
C2
months
still
back
never
worked
money

amazon
return
machine

KIT
e3
e4
C1
C1
works
really
water
nice
clean
works
work

ice
quality
makes
small
thing
sturdy
need
little
keep
think
best
item
C2
price
item
set
ordered
amazon
gift
got
quality
received
knives

C2

years
love
never
clean
months

pan

pans

e5
C1
pan
oven
cooking
made
pans
better
heat
cook
using
clean
C2
love
coffee

recommend
makes

size
little
maker
cup

Table 7: Top ten features induced dimension KIT domain. shaded
columns correspond dimensions selected human judges. e2 , . . ., e5 top eigenvectors; C1 C2 clusters.

600

fiInducing Ideal Clustering Minimal Feedback

e2
C1
worth
bought
series
money
season
fan
collection
music
tv
thought
C2
young

actors
men
cast
seems
job
beautiful
around
director

DVD
e3
e4
C1
C1
music
video
collection
music
excellent
found
wonderful
feel
must
bought
loved
workout
perfect
daughter
highly
recommend
makes

special
disappointed
C2
worst
money
thought
boring
nothing
minutes
waste
saw
pretty
reviews

C2
series
cast
fan
stars
original
comedy
actors
worth
classic
action

e5
C1
money
quality
video
worth
found
version
picture
waste
special
sound
C2
saw
watched
loved
enjoy
whole
got
family
series
season
liked

Table 8: Top ten features induced dimension DVD domain. shaded
columns correspond dimensions selected human judges. e2 , . . ., e5 top eigenvectors; C1 C2 clusters.

601

fiDasgupta & Ng

Judge
1
2
3
4
5
Agreement

POL
2,3,4
2,4
4
2,3
2
80%

MOV
2
2
2,4
2
2
100%

KIT
2
2
4
2
2
80%

BOO
4
4
4
4
4
100%

DVD
3
3
3
3
3
100%

ELE
3
3
3
3,4
3
100%

Table 9: Human agreement rate. Also shown eigenvectors selected five judges.
intended dimension: example, POL, judge told intended
clustering Politics vs. Science. Also, determined one dimension
relevant intended clustering, instructed rank dimensions
terms relevance, relevant one would appear first list.
dimensions (expressed terms IDs eigenvectors) selected
five judges dataset shown Table 9. agreement rate (shown
last row table) computed based highest-ranked dimension selected
judge. see, perfect agreement achieved four five sentiment
datasets, remaining two datasets, near-perfect agreement achieved.
results, together fact took five six minutes identify relevant
dimension, indicate asking human determine intended dimension based
solely informative features viable task.
4.3.2 Clustering Results
Next, cluster 2000 documents dataset using dimension selected
majority human judges. clustering results shown row 5 Tables 2a
2b. comparison best baseline dataset, see algorithm
performs substantially better BOO, DVD ELE, almost level MOV
KIT, slightly worse POL. Note improvements observed BOO, DVD
ELE attributed failure e2 capture sentiment dimension. Perhaps
importantly, exploiting human feedback, algorithm achieved stable
performance across datasets four baselines.16
4.3.3 Identification Unambiguous Documents
Recall features largest MMFR computed unambiguous
documents only. get idea accurate algorithm identifying unambiguous
documents is, show Table 10 accuracy obtained unambiguous documents
dataset clustered using eigenvector selected majority judges.
see, accuracy dataset higher corresponding accuracy
shown row 5 Table 2a. fact, accuracy 85% achieved
16. first baseline, since clustering one-dimensional space here, results
sensitive choice seeds, yielding zero variance ten independent runs.

602

fiInducing Ideal Clustering Minimal Feedback

Accuracy

POL
99.8

MOV
87.0

KIT
87.6

BOO
86.2

DVD
87.4

ELE
77.6

Table 10: Accuracies unambiguous documents.

# labels

POL
400

MOV
150

KIT
200

BOO
350

DVD
350

ELE
200

Table 11: Transductive SVM results.
one dataset. suggests method identifying unambiguous documents
reasonably accurate.
Note crucial able achieve high accuracy unambiguous documents: clustering accuracy low, features induced clusters may
accurate representation corresponding dimension, human judge may
difficult time identifying intended dimension. fact, human judges reported difficulty identifying correct dimension ELE dataset, attributed
part low accuracy achieved unambiguous documents.
4.3.4 User Feedback Versus Labeled Data
Recall four baselines unsupervised, whereas algorithm characterized
semi-supervised, relies user feedback select intended dimension. Hence,
surprising see average clustering performance algorithm
better baselines.
fairer comparison, conduct another experiment compare
algorithm semi-supervised sentiment classification system, uses transductive SVM underlying semi-supervised learner. specifically, goal
experiment determine many labeled documents needed order transductive learner achieve level performance algorithm. answer
question, first give transductive learner access 2000 documents
dataset unlabeled data. Next, randomly sample 50 unlabeled documents assign
true label. re-train classifier compute accuracy 2000
documents. keep adding labeled data (50 iteration) reaches
accuracy achieved algorithm. Results experiment shown Table 11.
Owing randomness involved selection unlabeled documents, results
averaged ten independent runs. see, user feedback equivalent
effort hand-annotating 275 documents per dataset average.
4.3.5 Multiple Relevant Eigenvectors
seen Table 9, human judges selected one eigenvector
datasets (e.g., {2,3,4} POL; {2,4} MOV; {3,4} ELE). However, never took
account extra eigenvectors previous experiments. better understand
603

fiDasgupta & Ng

system

POL
Acc ARI
95.9 0.84

MOV
Acc ARI
69.1 0.16

ELE
Acc ARI
65.1 0.10

Table 12: Results obtained using multiple relevant eigenvectors POL, MOV
ELE datasets.

Accuracy

POL
99.3

MOV
86.1

KIT
81.7

BOO
79.3

DVD
77.6

ELE
80.6

Table 13: Supervised classification accuracies.
whether extra eigenvectors help improve accuracy ARI, conduct another
experiment apply 2-means cluster documents space defined
selected eigenvectors. Table 12 shows accuracy ARI results averaged
ten independent runs. see, results POL considerably better
obtained highest-ranked eigenvector used, suggesting
extra eigenvectors contain useful information. However, results MOV ELE drop
slightly addition extra eigenvectors, indicating extra sentiment
dimensions useful.
4.3.6 Supervised Classification Results
Next, present results supervised classification five sentiment datasets.
one expect largely unsupervised approach offer comparable performance
fully-supervised approach, believe fully-supervised results enable
reader get sense work stands among existing work identifying
sentiment datasets. Specifically, report Table 13 averaged 10-fold crossvalidation accuracies, SVM classifier trained nine folds tested
remaining fold fold experiment. see, results lag behind supervised
results 8.115.2% datasets.
4.4 Alternative Document Representations
experiments, represented document bag words
frequent 1.5% words removed. is, course, way represent
document. subsection, examine two alternative document representations
attempt better understand effect document representation classification results.
first document representation, represent document using unigrams
appear remove frequent words document vector.
bag-of-all-words (BOAW) representation motivated fact frequencies
function words like shown many studies useful features various kinds non-topic-based classification (e.g., Finn & Kushmerick, 2006; Stein, Argamon,
& Frieder, 2006; Abbasi, Chen, & Salem, 2008; Koppel, Schler, & Argamon, 2009).
604

fiInducing Ideal Clustering Minimal Feedback

System Variation
2nd eigenvector
Top five eigenvectors
Interested Reader Model
NMF
system

POL
70.6
94.7
61.2
59.2
84.3

MOV
54.3
60.6
61.1
54.6
65.9

Accuracy
KIT BOO
51.6 52.4
58.0 56.1
57.8 52.4
50.8 50.1
64.8 60.1

DVD
51.2
53.7
50.4
52.9
58.6

ELE
53.1
57.1
50.3
51.4
64.1

(a)

System Variation
2nd eigenvector
Top five eigenvectors
Interested Reader Model
NMF
system

POL
0.17
0.80
0.05
0.03
0.47

Adjusted Rand Index (ARI)
MOV KIT
BOO DVD
0.01
0.01
0.01
0.01
0.04
0.03
0.01
0.01
0.05
0.02
0.01
0.01
0.01 0.01 0.01 0.01
0.10
0.09
0.04 0.03

ELE
0.01
0.03
0.01
0.01
0.08

(b)

Table 14: Results terms (a) accuracy (b) Adjusted Rand Index six datasets
obtained using bag-of-all-words document representation. strongest result(s)
dataset boldfaced.

accuracy ARI results obtained re-running four baselines well system
using document representation shown Tables 14a 14b, respectively. Comparing Tables 2a 14a, see words used features, best
accuracy achieved dataset drops 311% high-frequency words
removed spectral clustering applied. Similar trends observed ARI
results shown Tables 2b 14b. Overall, results substantiate hypothesis
retaining high-frequency words document representation adverse effect
performance clustering algorithms.
Next, experiment another representation, specifically one document represented using sentiment-bearing words contains. understand
motivation behind bag-of-sentiment-words (BOSW) representation, recall introduction one way encourage clustering algorithm produce user-desired
clustering design feature space contains features
useful producing user-desired clustering. Since desire sentiment-based clustering, design feature space composed solely sentiment-bearing words. Since
hand-crafted subjectivity lexicon (i.e., lexicon word manually labeled
prior polarity17 ) English readily available, automatically construct feature
space consists words (positive negative) polarity according
subjectivity lexicon, represent document using resulting feature space.
17. prior polarity word polarity computed without regard context word
appears.

605

fiDasgupta & Ng

System Variation
2nd eigenvector
Top five eigenvectors
Interested Reader Model
NMF
system

MOV
69.1
60.7
54.6
68.8
69.1

KIT
62.3
57.9
50.3
59.0
62.3

Accuracy
BOO DVD
60.2 61.4
57.6
63.1
54.4
56.0
59.2 63.3
60.2 61.4

ELE
63.9
62.7
50.6
60.5
63.9

(a)

System Variation
2nd eigenvector
Top five eigenvectors
Interested Reader Model
NMF
system

Adjusted Rand Index (ARI)
MOV KIT BOO DVD ELE
0.15 0.06 0.04 0.05 0.08
0.04
0.03 0.03 0.07 0.06
0.01
0.01 0.01
0.01 0.01
0.14
0.03 0.03 0.07 0.04
0.15 0.06 0.04 0.05 0.08
(b)

Table 15: Results terms (a) accuracy (b) Adjusted Rand Index five
sentiment datasets obtained using bag-of-sentiment-words document representation.
strongest result(s) dataset boldfaced.

goal, then, determine whether BOSW document representation improve
sentiment-based clustering results obtained using BOW representation.
identify sentiment-bearing words experiment, employ subjectivity lexicon introduced work Wilson, Wiebe, Hoffmann (2005).18 lexicon contains
8221 words, hand-labeled prior polarity Positive, Negative,
Neutral. create new subjectivity lexicon L retain words
Wilson et al.s lexicon either Positive Negative polarity. BOSW
representation document composed words appear
L document.
accuracy ARI results baselines system obtained employing
BOSW representation shown Tables 15a 15b, respectively. Consider first
second eigenvector baseline, NMF, Interested Reader Model. comparison
corresponding results Tables 2a 2b, BOW representation
used, see performance improves BOO, DVD, ELE datasets
cases, drops MOV KIT datasets. top five eigenvectors baseline,
performance increases DVD slightly MOV, drops remaining datasets.
Finally, using BOSW representation causes performance system drop
datasets.
Overall, results seem suggest whether BOSW representation document yields better clustering results BOW representation rather dependent
underlying domain clustering algorithm. Nevertheless, see best
18. See http://www.cs.pitt.edu/mpqa/.

606

fiInducing Ideal Clustering Minimal Feedback

clustering accuracy/ARI achieved sentiment dataset using BOSW representation significantly lower obtained using BOW representation. speculate
two reasons poorer results. First, general-purpose subjectivity lexicon
cover sentiment-bearing words. particular, words sentiment-oriented
context particular domain neutral polarity otherwise may omitted BOSW document representation. Second, non-sentiment-bearing words
might useful identifying sentiment.
4.5 Domain Adaptation
mentioned introduction, majority existing approaches sentiment classification supervised. One weakness supervised approaches given
new domain, one needs go expensive process collecting large amount
annotated data order train accurate polarity classifier.19 One may argue
active clustering algorithm suffers weakness: user needs identify
sentiment dimension domain. One way address weakness domain
adaptation. Specifically, investigate whether sentiment dimension manually identified one domain (henceforth source domain) used automatically identify
sentiment dimension new domain (henceforth target domain). hypothesize
domain adaptation feasible, especially two domains sentimentally similar (i.e., significant overlap features characterize sentiment
dimensions two domains).
result, propose following method automatically identifying sentiment
dimension target domain, y, using sentiment dimension manually identified
source domain, x. Assume sentiment dimension domain x defined
x
x
eigenvector ex . Moreover, assume C1e C2e two vectors top-ranked
features (obtained using MMFR) characterize two clusters induced ex (with 100
features cluster). Now, given target domain y, first compute similarity
ex ys top eigenvectors, ey2 , . . ., ey5 , similarity two
eigenvectors ex ey defined
x



x



x



x



max((C1e , C1e ) + (C2e , C2e ), (C1e , C2e ) + (C2e , C1e ))
Here, similarity function computes similarity two feature vectors.
experiments, simply set dot product, allows us capture
degree overlap two feature vectors. Then, posit eigenvector
{ey2 , . . . , ey5 } highest overlap one defines sentiment dimension.20
determine effectiveness method, compare automatically selected
eigenvector human-selected eigenvector domain. Results shown
Table 16, row column j indicates sentiment dimension
target domain j successfully identified using sentiment dimension manually
19. collecting annotated data trivial dealing review data, necessarily
true kinds data. instance, people express opinions sentiment political blogs
floor debates, associated postings transcripts may explicitly annotated
sentiment labels.
20. Note two arguments max function correspond two different ways creating
mapping feature vectors two domains.

607

fiDasgupta & Ng

Domain
MOV
DVD
BOO
ELE
KIT

MOV


N
N
N

DVD



N


BOO
N


N
N

ELE
N
N
N



KIT
N





Table 16: Domain adaptation results.

identified source domain i, N indicates failure. instance, know
sentiment dimension DVD domain (through human feedback), domain
adaptation method used correctly identify sentiment domain MOV
vice versa. However, domain adaptation using method always successful.
instance, knowing sentiment dimension MOV allow us correctly predict
sentiment dimension ELE. Interestingly, ignore BOO/KIT pair, domain
adaptation exhibits symmetry. symmetry, mean domain x used
identify correct sentiment dimension domain y, domain used
identify correct sentiment dimension domain x. intuitively makes sense:
x successfully used identify sentiment dimension y, likely
two domains share lot sentiment words. Consequently, using adapt x also
likely successful. BOO/KIT pair represents case domain adaptation
successful one direction: domain adaptation successful BOO KIT,
similarity sentiment dimensions two domains high (see
discussion next paragraph details), contributes failure adaptation
direction.
mentioned beginning subsection, hypothesize domain adaptation likely successful two domains consideration similar
other. test hypothesis, show Table 17a similarity manually
identified eigenvector corresponding automatically identified eigenvector
pair domains. Three points deserve mention. First, long similarity value
least 14, domain adaptation successful; also, long similarity value 6,
domain adaptation unsuccessful. Hence, results substantiate hypothesis
domain adaptation likely successful two domains consideration
similar other. would interesting see two thresholds
used predict whether domain adaptation successful given new pair domains.
Second, domain adaptation directions likely successful similarity
value sufficiently high. mentioned before, similarity value high,
two domains share many sentiment words common, may turn contribute
successful domain adaptation directions. five domains considering,
long similarity value least 14, domain adaptation directions
successful. Third, worth reiterating even similarity value falls
threshold, imply domain adaptation fail. mentioned before,
sentiment dimension domain (correctly) identified long similarity
608

fiInducing Ideal Clustering Minimal Feedback

Domain
MOV
DVD
BOO
ELE
KIT

MOV

14
(6)
(3)
(1)

DVD
14

21
(8)
10

BOO
(6)
21

(6)
(11)

ELE
(2)
(10)
(10)

32

KIT
(3)
10
8
32


BOO
(4)
13

(5)
(8)

ELE
(2)
(9)
(6)

27

KIT
(3)
7
6
23


BOO
(2)
8

(1)
(3)

ELE
(0)
(1)
(4)

5

KIT
(0)
3
2
9


(a)

Domain
MOV
DVD
BOO
ELE
KIT

MOV

5
(4)
(2)
(1)

DVD
10

14
(8)
7
(b)

Domain
MOV
DVD
BOO
ELE
KIT

MOV

9
(2)
(0)
(1)

DVD
4

7
(0)
3
(c)

Table 17: Similarity results domain adaptation. (a) shows similarity
sentiment eigenvector source domain eigenvector similar target
domain. (b) shows similarity sentiment eigenvector source domain
second similar eigenvector target domain. (c) shows similarity gap,
difference corresponding entries (a) (b).

sentiment dimension domain x highest among four eigenvectors y,
case BOO/KIT domain pair.
far attempted correlate success domain adaptation similarity manually selected eigenvector source domain eigenvector
similar target domain. may worth also consider similarity
manually selected eigenvector second similar eigenvector
target domain, gap similarity may give indication success domain adaptation. determine whether better correlation success
domain adaptation similarity gap, compute (1) similarity
eigenvector manually selected source domain second similar eigenvector
target domain (see Table 17b) well (2) similarity gap (see Table 17c),
simply difference corresponding entries Tables 17a 17b.
see Table 17c, also appears correlation success
domain adaptation gap values. particular, gap value least 5, domain
609

fiDasgupta & Ng

adaptation successful; however, gap value 1, domain adaptation unsuccessful. Nevertheless, gap values help predict domain pairs
success domain adaptation cannot predicted using similarity values Table 17a
(e.g., domain pairs low similarity yet domain-adaptable). Moreover,
fail predict success domain adaptation many domain pairs, specifically
gap value 1 5.
4.6 Subjectivity Lexicon versus Human Feedback
One might argue access subjectivity lexicon, could use automatically identify right sentiment dimension, thus obviating need human feedback
altogether. subsection, investigate whether indeed feasible use handbuilt general-purpose sentiment lexicon identify eigenvector corresponds
sentiment dimension new domain.
experiment, use subjectivity lexicon L described Section 4.4.
mentioned before, L contains words Wilson et al.s (2005) subjectivity
lexicon marked prior polarity Positive Negative. procedure
automatically identifying sentiment dimension using L similar one described
domain adaptation section: second fifth eigenvectors, first
compute similarity eigenvector L, choose eigenvector
highest similarity L. domain adaptation, compute similarity
L eigenvector ex
x

x

x

x

max((C1L , C1e ) + (C2L , C2e ), (C1L , C2e ) + (C2L , C1e ))
C1L C2L represent words L labeled positive negative rex
x
spectively, C1e C2e top-ranked features (obtained using MMFR)
characterize two clusters induced ex (with 100 features cluster). similarity function computes similarity two feature vectors. domain
adaptation, simply set dot product.
results indicate successfully identified right eigenvector using L
five domains. Note L general-purpose (i.e., domain-independent)
lexicon containing generic sentiment-bearing words, good enough identify
correct sentiment dimension five different domains. worth noting sentiment
dimension MOV domain highest similarity L (i.e., 34) five
domains, suggesting highest-ranked sentiment features MOV domain (according MMFR) largely generic. DVD second largest similarity L (33),
followed BOO (26), KIT (16) ELE (16). comparatively low similarity values
KIT ELE indicative fact highest-ranked sentiment features
largely domain-specific.
Finally, although subjectivity lexicon obviates need human feedback,
emphasize undermine contribution feedback-oriented clustering
technique, following reasons. First, thinking text mining perspective, would
good approach knowledge-free possible. Employing handcrafted subjectivity lexicon makes system resource-dependent; fact, subjectivity
lexicon may readily available vast majority natural languages. Second,
610

fiInducing Ideal Clustering Minimal Feedback

want method potentially applicable non-sentiment domains (e.g., spam vs.
spam), faced problem hand-built lexicon may
available.
4.7 Single Data, Multiple Clusterings
mentioned previously, set documents clustered along different dimensions.
example, movie reviews clustered sentiment (positive vs. negative) genre
(e.g., action, romantic documentary). natural question is: produce different
clusterings given set documents, corresponds different dimension?
vast majority existing text clustering algorithms, answer no:
cluster along exactly one dimension, typically prominent dimension.
hand, since algorithm induces important clustering dimensions
dataset, principle used produce (distinct) clustering,
hypothesize generate multiple clusterings given dataset along important
dimensions.
test claim algorithm produce multiple clusterings, evaluate
four datasets possess multiple clustering dimensions, namely MOV-DVD, BOODVD, DVD-ELE, MOV-KIT.21 example, BOO-DVD dataset consists
reviews taken BOO DVD domains. Hence, augmented dataset
composed 4000 reviews (2000 two contributing domains),
clustered according either topic (e.g., Book vs. DVD) sentiment.22 Note
four pairs domains used create augmented datasets chosen carefully.
Specifically, two augmented datasets (MOV-DVD BOO-DVD) created
constituent domains mutually domain-adaptable according Table 16,
remaining two (DVD-ELE MOV-KIT) created constituent domains
domain-adaptable. goal see whether active clustering algorithm able
produce topic- sentiment-based clusterings datasets different levels
sentimental similarity.
clustering procedure almost identical one described Section 3. essence,
(1) compute top five eigenvectors Laplacian matrix; (2) learn top-ranked
features corresponding e2 e5 according MMFR; (3) ask human judges
identify eigenvectors corresponding topic dimension sentiment
dimension; (4) use 2-means produce two clusterings reviews, one according
selected topic dimension selected sentiment dimension.
Section 4.3, conducted human automatic experiments determine viability
algorithm.
21. reason employing augmented datasets obviate need
additional human annotations, also guarantee least two dimensions along
clusters formed, thus allowing us directly test ability produce multiple clusterings.
also possible evaluate algorithms ability generate multiple clusterings using MOV
dataset (by clustering along genre sentiment), decided leave future investigation, since
documents MOV annotated genre information.
22. confused topic-sentiment mixture models (Mei, Ling, Wondra, Su, & Zhai, 2007),
goal first use topic models mine major aspects product online review
assign ratings extracted aspect. hand, goal design clustering
algorithm capable generating multiple clusterings dataset.

611

fiDasgupta & Ng

Judge
1
2
3
4
5
Agreement

MOV-DVD
2
2
2
2
2
100%

BOO-DVD
2
2
2
2
2
100%

DVD-ELE
2
2
2
2
2
100%

MOV-KIT
2
2
2
2
2
100%

DVD-ELE
3
3,5
5,3
3
3
80%

MOV-KIT
3
3,5
3
5
3
80%

(a)

Judge
1
2
3
4
5
Agreement

MOV-DVD
3
3,4
3,4
3
3
100%

BOO-DVD
4,5
4,5
4,5
4,5
4,5
100%
(b)

Table 18: Human agreement rate selecting (a) topic dimension (b) sentiment
dimension augmented datasets. Also shown eigenvectors selected
human judges.

4.7.1 Human Experiments
employed five human judges involved human experiments Section 4.3
independently determine topic dimension sentiment dimension
four augmented datasets using top features according MMFR. before,
human judge identifies one relevant eigenvector particular dimension,
ask rank eigenvectors according relevance. Finally, take topic/sentiment
dimension ranked first largest number judges human-selected
topic/sentiment dimension.
Tables 18a 18b show respectively topic sentiment dimensions (expressed
terms IDs eigenvectors) selected five judges augmented
dataset. Also shown tables human agreement rate, computed
based highest-ranked dimension selected judge. Several points
human experiments deserve mention.
First, dataset, human judges managed find one eigenvector (out
top five) corresponds topic least one eigenvector corresponds
sentiment. Perhaps importantly, human agreement rate least 80%
achieved four datasets respect selecting eigenvector(s) correspond
topic sentiment dimensions. results together provide suggestive evidence
(1) eigen-decomposition procedure active clustering algorithm effective
enough unearth topic sentiment dimensions present
612

fiInducing Ideal Clustering Minimal Feedback

dataset, (2) proposal incorporating user feedback via inspecting small
number features viable.
Second, topic sentiment prominent dimensions datasets,
fact second eigenvector captures topic dimension four datasets suggests
topic prominent dimension sentiment. fact, human judges
reported topic dimension identified quite easily, achieving perfect agreement
identifying topic dimension. provides empirical evidence speculation
topic typically (though always) prominent dimension sentiment
dimensions exist dataset.
Third, reasonably high human agreement rate identifying sentiment dimension achieved (perfect agreement two datasets 80% agreement rate
remaining two; see Table 18b details), human judges reported difficult identify sentiment dimension(s), especially two datasets composed
sentimentally dissimilar domains.
attempt gain insight judges found difficult identify
sentiment dimension(s), show Tables 1922 top-ranked features induced
dimension using MMFR four augmented datasets, lightly shaded columns
correspond eigenvectors chosen topic dimension darkly shaded columns
correspond eigenvectors chosen sentiment dimension. examining
results, believe points deserve mention.
First, top features generated sentiment eigenvector(s) MOV-DVD
BOO-DVD, two datasets composed sentimentally similar constituent domains,
clearly sentiment-oriented, making relatively easy human judges determine
sentiment eigenvector(s). case DVD-ELE MOV-KIT, two datasets
composed dissimilar domains, top features noisier (i.e., many
necessarily sentiment-oriented), thus making tougher judges locate
sentiment eigenvector(s). fact, one see top features generated
sentiment eigenvector(s) Tables 1922 MOV-DVD BOO-DVD
clearly sentiment-oriented DVD-ELE MOV-KIT.
surprising sentimentally dissimilar constituent domains are, noisier top features generated sentiment eigenvector(s) are,
however. constituent domains sentimentally similar, tend many
sentiment-bearing words common. implies sentiment-bearing words
appear frequently augmented datasets constituent datasets.
Hence, combining two domains helps boost influence sentiment-bearing
words, increasing chance appearing higher list features ranked
MMFR. reinforcement effect intuitively explains sentiment eigenvector
clearly dominated sentiment words datasets composed sentimentally similar domains. hand, constituent domains sentimentally dissimilar, tend
many sentiment-bearing words common. result, influence
sentiment-bearing words present one two constituent domains
diluted larger number non-sentiment-bearing words result combining
two domains. words, features clearly sentiment-oriented
one rather domains may longer appear sufficiently high ranked list
features. fact, saw Tables 21 22, sentiment eigenvector contaminated
613

fiDasgupta & Ng

e2
C1
roles
drama
murder
meets
crime
supporting
involving
convincing
tale
lead
C2
bought
season
buy
disappointed
fan
amazon
buying
copy
dvds
watched

MOV-DVD
e3
e4
C1
C1
wonderful recommend
excellent
fan
beautiful
liked
personal
book
collection
read
view
excellent
art
amazing
highly
definitely
fantastic
highly
deal
absolutely
C2
stupid
boring
dull
mean
terrible
save
lame
run
guys
except

C2
buy
house
rent
waste
wait
kill
murder
obvious
season
dvds

e5
C1
kids
children
loved
child
son
daughter
boy
school
wonderful
heart
C2
quality
dark
war
horror
release
fan
earth
production
suspense
sound

Table 19: Top ten features induced dimension MOV-DVD domain.
lightly darkly shaded columns correspond topic sentiment dimensions respectively
selected human judges. e2 , . . ., e5 top eigenvectors; C1 C2 clusters.

614

fiInducing Ideal Clustering Minimal Feedback

e2
C1
reader
important
subject
understanding
modern
information
examples
political
business
nature
C2
saw
watched
actors
liked
music
season
humor
comedy
favorite
ending

BOO-DVD
e3
e4
C1
C1
bought
excellent
disappointed wonderful
easy
highly
information collection
price
music
waste
special
workout
classic
helpful
video
expected
perfect
reviews
amazing

e5
C1
loved
enjoyed
children
year
wonderful
child
fun
son
friends
highly

C2
young
men
cast
role
actors
script
scene
war
performance
action

C2
version
quality
waste
worst
review
original
edition
collection
amazon
format

C2
boring
ending
waste
reviews

novel
maybe
pages
stupid
finish

Table 20: Top ten features induced dimension BOO-DVD domain.
lightly darkly shaded columns correspond topic sentiment dimensions respectively
selected human judges. e2 , . . ., e5 top eigenvectors; C1 C2 clusters.

615

fiDasgupta & Ng

e2
C1
funny
acting
family
actors
action
plot
enjoy
young
wonderful
comedy
C2
unit
battery
purchased
device
problems
tried
working
plug
charge
computer

DVD-ELE
e3
e4
C1
C1
easy
fine
small
problems
perfect
worked
excellent
months
highly
easy
nice
working
low
computer
comfortable
day
ipod
card
headphones
drive
C2
amazon
item
review
company
return
took
check
saw
card
worked

C2
amazon
tv
purchase
disappointed
item
purchased
reviews
wanted
received
ipod

e5
C1
video
card
camera
fast
easy
cable
picture
pictures
paper
digital
C2
phone
waste
unit
battery
getting
low
power
hear
worst
batteries

Table 21: Top ten features induced dimension DVD-ELE domain.
lightly darkly shaded columns correspond topic sentiment dimensions respectively
selected human judges. e2 , . . ., e5 top eigenvectors; C1 C2 clusters.

616

fiInducing Ideal Clustering Minimal Feedback

e2
C1
james
directed
sex
hour
drama
relationship
death
direction
tv
michael
C2
food
recommend
pot
purchased
mine
kitchen
mixer
handle
size
store

MOV-KIT
e3
e4
C1
C1
pan
coffee
cooking
clean
clean
machine
pans
ice
cook
maker
heat
plastic
oven
cup
heavy
fill
food
months
stick
working
C2
months
purchased
worked
broke
amazon
coffee
replacement
month
tried
service

C2
item
price
sheets
ordered
amazon
received
beautiful
dishes
arrived
sets

e5
C1
price
clean
kitchen
knife
knives
size
sharp
dishwasher
cutting
attractive
C2
pan
toaster
oven
pans
heat
return
bottom
worked
read
toast

Table 22: Top ten features induced dimension MOV-KIT domain.
lightly darkly shaded columns correspond topic sentiment dimensions respectively
selected human judges. e2 , . . ., e5 top eigenvectors; C1 C2 clusters.

617

fiDasgupta & Ng

2nd eigenvector
Top five eigenvectors
Interested Reader Model
NMF
system

MOV-DVD
Acc ARI
77.1 0.29
62.4 0.08
84.2 0.53
56.3 0.02
77.1 0.29

BOO-DVD
Acc ARI
77.8 0.31
77.2 0.31
63.1 0.07
69.2 0.15
77.8 0.31

DVD-ELE
Acc ARI
94.2 0.78
93.9 0.78
94.8 0.80
94.4 0.79
94.2 0.78

MOV-KIT
Acc ARI
99.3 0.97
99.3 0.97
99.6 0.99
70.6 0.17
99.3 0.97

DVD-ELE
Acc ARI
50.9 0.00
50.4 0.00
50.9 0.00
51.1 0.00
61.1 0.05

MOV-KIT
Acc ARI
50.0 0.00
50.0 0.00
50.1 0.00
61.6 0.05
59.2 0.03

(a)

2nd eigenvector
Top five eigenvectors
Interested Reader Model
NMF
system

MOV-DVD
Acc ARI
54.4 0.01
68.3 0.13
53.4 0.01
66.9 0.11
71.4 0.18

BOO-DVD
Acc ARI
52.3 0.01
52.0 0.00
52.1 0.01
51.7 0.00
68.8 0.14
(b)

Table 23: Results (a) topic-based clustering (b) sentiment-based clustering
four augmented datasets. strongest results dataset boldfaced.

number features necessarily sentiment-bearing, make difficult
human judges identify sentiment dimension.
Another interesting point note datasets, seems
one eigenvector correspond sentiment. instance, BOO-DVD dataset,
five human judges agreed e4 e5 correspond sentiment dimension.
closer examination two eigenvectors (shown Table 20) reveals interesting
pattern: e4 , positive features (in C1 ) came DVD domain negative
features (in C2 ) came BOO domain; whereas e5 , positive features (in
C1 ) came BOO domain negative features (in C2 ) came DVD.
words, e4 partitions reviews according positive DVD negative
BOO, whereas e5 reverse. suggests eigen-decomposition procedure
smart enough merge positive negative sentiment-bearing words
two domains together. Perhaps even importantly, e4 e5
partitioning reviews along sentiment dimension also topic dimension.
4.7.2 Clustering Results
Rows 14 Tables 23a 23b show topic- sentiment-based clustering results
four baseline text clustering algorithms described Section 4.2. Note
baselines produce one clustering documents per dataset.
Hence, baseline, topic-based clustering results produced comparing
clustering gold-standard topic-based clustering, sentiment-based
618

fiInducing Ideal Clustering Minimal Feedback

clustering results produced comparing clustering gold-standard
sentiment-based clustering.
see topic-based results Table 23a, baseline cluster
using second eigenvector achieves best average clustering results four
augmented datasets. potentially attributed fact e2 corresponds
topic dimension four datasets according human judges, described
human experiments. However, clustering using e2 produce best clustering
results four datasets. fact, Interested Reader Model achieves best results
MOV-DVD, DVD-ELE, MOV-KIT. Nevertheless, results BOO-DVD
worst among baselines. true top five eigenvectors baseline
NMF: yielded poor results MOV-DVD; addition, NMFs results
BOO-DVD MOV-KIT promising either.
far sentiment-based baseline clustering results concerned (see rows 14
Table 23b), best average performance achieved NMF. Except three cases
(NMF MOV-DVD MOV-KIT, well top five eigenvectors MOV-DVD),
baseline results particularly promising, accuracy results low fifties
ARI results close zero.
topic- sentiment-based clustering results produced algorithm shown
row 5 Tables 23a 23b. Specifically, results obtained grouping
reviews according eigenvectors manually selected topic sentiment dimensions, respectively. Hence, unlike baselines, topic-based clustering
sentiment-based clustering produced algorithm different other.
before, cases human judges selected one eigenvector dimension, use eigenvector ranked first frequently. see,
accuracies topic-based clustering reasonably high, ranging 77.1% 99.3%.
results suggest possible achieve high-performance topic-based (or
precisely, domain-based) clustering dataset even another prominent clustering dimension (i.e., sentiment) present. hand, despite existence eigenvectors
clearly capture sentiment dimension datasets (e.g., e3 MOV-DVD
dataset), sentiment-based clustering accuracies ARI values lower
topic-based clustering. potentially attributed reason mentioned
introduction: fact reviews sentimentally ambiguous makes non-trivial
classify. comparison four baselines, algorithm achieves best
average performance four datasets also comparatively stable performance
across datasets.
worth noting sentiment-based clustering results produced algorithm
MOV-DVD BOO-DVD higher DVD-ELE MOV-KIT.
perhaps surprising: discussed before, human judges found difficult
identify sentiment eigenvector DVD-ELE MOV-KIT MOV-DVD
BOO-DVD, owing part fact many top-ranked features sentiment
eigenvector DVD-ELE MOV-KIT sentiment-oriented, turn
attributed fact datasets correspond domain pairs
sentimentally dissimilar. mentioned above, two sentimentally dissimilar constituent
domains tend many sentiment-bearing words common, consequently,
influence sentiment-bearing words present one two constituent
619

fiDasgupta & Ng

domains diluted larger number non-sentiment-bearing words result
combining two domains, making difficult produce good sentiment-based
clustering. hand, combining two domains helps boost influence
sentiment-bearing words, increasing chance appearing higher
list features ranked MMFR producing good sentiment-based clustering.
Interestingly, algorithm achieves better topic-based clustering results two
datasets DVD-ELE MOV-KIT achieves poorer sentiment-based clustering results. fact, topic-based clustering accuracies DVD-ELE MOV-KIT
near perfect: 94.2% 99.3% DVD-ELE MOV-KIT respectively.
means coincidence: constituent domains augmented dataset highly
dissimilar (i.e., word usage tends differ considerably other), topic clusters well-separated hence high topic-based clustering results
achieved. similar line reasoning explain algorithm finds comparatively
difficult produce good topic-based clustering MOV-DVD BOO-DVD,
constituent domains similar.
results seem suggest higher topic-based accuracy/ARI implies lower
sentiment-based accuracy/ARI vice versa. speculate constituent
domains similar, sentiment-bearing features tend similar result,
sentiment-based results tend good topic-based results tend poor. Additional
experiments needed determine reason.
Overall, results provide supporting evidence feedback-oriented algorithm
produce multiple clusterings dataset. particular, even though sentimentbased clustering accuracies high topic-based clustering accuracies
augmented datasets, current level performance algorithm arguably reasonable, especially considering fact sentiment-based clustering challenging task
traditional clustering algorithms fail even produce one clustering.
4.7.3 Multiple Relevant Eigenvectors
Recall Table 18b four augmented datasets, least one
judge indicated one eigenvector relevant sentiment dimension.
However, producing sentiment-based clustering results using system Table 23b, used eigenvector ranked frequently human judges.
better understand whether using relevant eigenvectors help improve results sentiment-based clustering, repeat experiment apply 2-means
cluster documents space defined eigenvectors determined
relevant least one judge. specifically, cluster following set
eigenvectors: {3,4} MOV-DVD, {4,5} BOO-DVD, {3,5} DVD-ELE, {3,5}
MOV-KIT.
accuracy ARI results experiment shown Table 24. comparison
results last row Table 23b, see using additional relevant eigenvectors
yields better results BOO-DVD dataset. may easy
determine reason, believe poorer results observed BOO-DVD
attributed impurity e5 , captures sentiment also topic,
discussed before. hand, additional sentiment eigenvectors chosen
620

fiInducing Ideal Clustering Minimal Feedback

system

MOV-DVD
Acc ARI
72.2 0.19

BOO-DVD
Acc ARI
55.7 0.01

DVD-ELE
Acc ARI
66.2 0.10

MOV-KIT
Acc ARI
59.8 0.04

Table 24: Results sentiment-based clustering obtained using multiple relevant eigenvectors four augmented datasets.
three augmented datasets seem impurity problem,
capture sentiment dimension one constituent domains.

5. Significance Work
believe approach significant following aspects.
1. Producing clustering according user interest. proposed novel framework enabled spectral clustering algorithm take account human
feedback produce clustering along dimension interest user.
particularly appealing aspect approach concerned relatively minimal human feedback demands, user needs take cursory look
small number features representative induced dimension.
worth noting human inspect select automatically induced
clustering dimension new form interaction human clustering
algorithm. enables human easily engage various clustering tasks help improve performance easy, low-effort manner. believe approach,
belongs emerging family interactive algorithms allows user
make small, guiding tweaks thereby get results much better would otherwise
possible, future information retrieval.
2. Inducing human-interpretable clustering dimensions. dimensions produced spectral clustering dimensionality reduction algorithms (e.g., Latent
Semantic Indexing (LSI), Deerwester, Dumais, Furnas, Landauer, & Harshman, 1990)
generally considered non-interpretable (Sebastiani, 2002), unlike dimension
original feature space, typically corresponds word type therefore interpreted human easily. results preliminary study challenge
common wisdom. show context text clustering dimension
low-dimensional space induced spectral clustering interpreted
human. believe ability produce human-interpretable dimensions enables us
employ spectral clustering (and perhaps dimensionality reduction-based clustering algorithms) text processing intelligent manner. especially
case respect selecting dimensions pertinent task
hand. example, existing applications spectral clustering topic-based
clustering task (e.g., Xu et al., 2003; He, Cai, Liu, & Ma, 2004; Hu, Deng, Guo, & Xu,
2007), dimensions low-dimensional space typically used. Since
showed dimensions produced spectral clustering dataset
necessarily topic-related, potentially improve topic-based clustering results
621

fiDasgupta & Ng

employing non-topic-related dimensions clustering process. addition,
since induced dimensions correspond non-topic dimensions,
use produce non-topic-based clusterings. particular, given recent surge
interest NLP community text classification along non-topic dimensions
sentiment gender (e.g., Garera & Yarowsky, 2009; Jurafsky, Ranganath, &
McFarland, 2009), approach offers solution tasks rely
labeled data, unlike majority existing approaches non-topic-based text classification, supervised nature. Overall, believe NLP researchers
fully exploited power spectral clustering, hence rewards
understanding spectral clustering light results may significant.
3. Producing multiple clusterings. majority existing text clustering
algorithms produce single clustering dataset, approach potentially
used produce multiple clusterings, one along important clustering
dimensions induced via novel application spectral clustering.
Finally, worth mentioning task inducing clustering dimensions reminiscent influential topic modeling task (Blei, Ng, & Jordon, 2003), whose goal
discover major topics set documents unsupervised manner. Note
two tasks fundamentally different: topic model attempts discover major
topics set documents, dimension model aims discover major clustering
dimensions. Nevertheless, two models bear resemblance many ways.
First, employ clustering discover information text collection unsupervised manner. Second, display learned information human using
representative words: topic model represents induced topic using words
representative topic, dimension model represents induced clustering
dimension using words representative two document clusters involved dimension. Finally, induced topics clustering dimensions human-recognizable,
are, human needed assign labels them. believe induction
clustering dimensions potential substantially enhance capability existing
text analysis algorithms discover knowledge text collection unsupervised
manner complementing information induced topic model.

6. Related Work
introduction, discussed related work producing user-desired clustering.
section, focus discussing related work topic-based clustering classification, sentiment classification, active learning, producing multiple clusterings computational
stylistics.
Topic-based text clustering. Traditional research text clustering focused primarily topic-based clustering, owing large part DARPAs Topic Detection
Tracking initiative 1990s. Many different clustering algorithms used, including non-hierarhical algorithms k-means Expectation-Maximization (EM)
hierarchical algorithms single-link, complete-link, group-average, singlepass (Hatzivassiloglou, Gravano, & Maganti, 2000). algorithms cluster given set
622

fiInducing Ideal Clustering Minimal Feedback

documents feature space typically spanned unigrams. However,
clustering high-dimensional space allow distance two documents reliably computed due curse dimensionality. Consequently,
recent work focused development algorithms cluster documents lowdimensional space constructed via dimensionality reduction. Representative members
family dimensionality reduction-based clustering algorithms include traditional algorithms based LSI (Deerwester et al., 1990), well recently proposed
(and arguably better performing) algorithms spectral clustering (Shi & Malik, 2000;
Ng et al., 2001), non-negative matrix factorization (Xu et al., 2003), locality preserving indexing (He et al., 2004), locality discriminating indexing (Hu et al., 2007). Despite
development new clustering algorithms, primarily evaluated
respect ability produce topic-based clusterings.
Topic-based text classification. Yang Liu (1999) put it, text classification
inherently supervised learning task. fact, arguably one popular
tasks supervised learning techniques applied information retrieval
community 1990s (see Sebastiani, 2002, comprehensive overview related work
machine learning text classification). Nevertheless, annotated documents
needed training high-performance supervised text classifier expensive
obtain. result, researchers investigated possibility performing text
classification little even labeled data. attempts led development
general-purpose semi-supervised text classification algorithms combine labeled
unlabeled data using transduction (Joachims, 1999b) EM (Nigam, McCallum, Thrun, &
Mitchell, 2000), latter used combination active learning (McCallum & Nigam, 1998). recently, Sandler (2005) proposed unsupervised text
classification algorithm based mixture modeling LSI-based dimensionality
reduction.
Sentiment classification. mentioned introduction, despite large amount
recent work sentiment analysis opinion mining, much focused supervised
methods (see Pang & Lee, 2008, comprehensive survey field). One weakness existing supervised polarity classification systems typically
domain- language-specific. Hence, given new domain language, one needs
go expensive process collecting large amount annotated data order
train high-performance polarity classifier. recent attempts made
leverage existing sentiment corpora lexicons automatically create annotated resources
new domains languages. However, methods require existence either
parallel corpus/machine translation engine projecting/translating annotations/lexicons
resource-rich language target language (Banea, Mihalcea, Wiebe, & Hassan,
2008; Wan, 2008), domain similar enough target domain (Blitzer et al.,
2007). target domain language fails meet requirement, sentiment-based
clustering unsupervised polarity classification become appealing alternatives. Unfortunately, exceptions (e.g., semi-supervised sentiment analysis, Riloff & Wiebe,
2003; Sindhwani & Melville, 2008; Dasgupta & Ng, 2009a; Li, Zhang, & Sindhwani, 2009),
tasks largely under-investigated NLP community. Turneys (2002) work
perhaps one notable examples unsupervised polarity classification. However,
623

fiDasgupta & Ng

system learns semantic orientation phrases review unsupervised manner, information used predict polarity review heuristically.
Domain adaptation. Domain adaptation, also known transfer learning, one
focal research areas machine learning NLP recent years, goal
leverage labeled data available one domain (the source domain) build
classifier another domain (the target domain). Techniques domain adaptation
applied various NLP tasks, including part-of-speech tagging, noun phrase chunking,
syntactic parsing, named entity recognition, word sense disambiguation (e.g., Daume III
& Marcu, 2006; Chan & Ng, 2007; Duame III, 2007; Jiang & Zhai, 2007a, 2007b).
particular relevance work domain adaptation techniques specifically developed
text sentiment classification (e.g., Blitzer, McDonald, & Pereira, 2006; Finn &
Kushmerick, 2006; Blitzer et al., 2007; Gao, Fan, Jiang, & Han, 2008; Ling, Dai, Xue, Yang,
& Yu, 2008; Tan, Cheng, Wang, & Xu, 2009). worth noting domain adaptation
setting different traditional setting. Traditionally, sophisticated classifiers and/or
automatically constructed mapping features two domains used
adaptation process. setting, however, simply utilize sentiment dimension
manually selected source domain automatically identify sentiment
dimension target domain.
Active clustering. Active learning heavily investigated machine learning paradigm
aims achieve better generalization bounds lower annotation costs (Cohn, Atlas,
& Ladner, 1994). traditional active learning setting, human requested
annotate data points classifier uncertain (e.g., Cohn et al., 1994),
recent research active learning involved asking human identify label
features useful classification task hand (e.g., Bekkerman et al., 2007;
Raghavan & Allan, 2007; Druck, Settles, & McCallum, 2009; Roth & Small, 2009).
mentioned introduction, active learning applied clustering setting,
goal encouraging algorithm produce user-intended clustering
data clustered along multiple dimensions. Different variants active clustering
proposed. request human label pair data points must-link
cannot-link indicate whether two points must must reside cluster
(e.g., Wagstaff et al., 2001; Bilenko, Basu, & Mooney, 2004), others human
determine whether two clusters merged split hierarchical clustering
process (e.g., Balcan & Blum, 2008). active clustering algorithm yet another variant:
ask human select clustering desires set automatically produced
clusterings.
Generation multiple clusterings. notion text collections may clustered
multiple independent ways discussed literature computational stylistics
(see Lim, Lee, & Kim, 2005; Biber & Kurjian, 2006; Grieve-Smith, 2006; Tambouratzis &
Vassiliou, 2007; Gries, Wulff, & Davies, 2010, example). machine learning,
attempts design algorithms producing multiple clusterings dataset.
operate semi-supervised setting (e.g., Gondek & Hofmann, 2004;
Davidson & Qi, 2007), totally unsupervised (e.g., Caruana, Elhawary, Nguyen,
& Smith, 2006; Jain, Meka, & Dhillon, 2008). instance, Caruana et al.s (2006) meta
clustering algorithm produces different clusterings dataset running k-means
624

fiInducing Ideal Clustering Minimal Feedback

times, time random selection seeds random weighting features.
goal present local minimum found k-means possible clustering. However,
propose mechanism determining clusterings one
user desires. approach, relies spectral clustering rather k-means
producing multiple clusterings, fills gap soliciting user feedback determine
user-desired clustering.

7. Conclusions Future Work
Unsupervised clustering algorithms typically group objects along prominent dimension, part owing objective simultaneously maximizing inter-cluster similarity intra-cluster dissimilarity. Hence, users intended clustering dimension
prominent dimension, unsupervised clustering algorithms fail
miserably. address problem, proposed active clustering algorithm,
allows us mine user-intended, possibly hidden, dimension data produce
desired clustering. mechanism differs competing methods requires
limited feedback: select intended dimension, user needs inspect
small number features. demonstrated viability via set human automatic
experiments challenging, yet under-investigated task sentiment-based clustering, obtaining promising results. Additional experiments provided suggestive evidence
(1) domain adaptation successfully applied identify sentiment dimension
new domain domains consideration sentimentally similar; (2) hand-crafted
subjectivity lexicon, available, used replace user feedback needed select
sentiment eigenvector domain; (3) algorithm potentially used
produce multiple clusterings datasets possess multiple clustering dimensions.
Equally importantly, empirically demonstrated possible human
interpret dimension produced spectral clustering algorithm, contrary common
wisdom dimensions automatically constructed rank-reduced space noninterpretable. believe NLP researchers fully exploited power spectral
clustering, hence rewards understanding spectral clustering light results
may significant. Finally, proposal represent induced clustering dimension
sets informative features facilitates exploratory text analysis, potentially enhancing
capability existing text analysis algorithms complementing information provided
unsupervised models (e.g., topic model).
future work, plan explore several extensions active clustering algorithm.
First, active clustering algorithm potentially used produce multiple clusterings dataset, one interesting future direction would examine theoretical
guarantees, determining whether able produce distinct clusterings qualitatively strong (see Dasgupta & Ng, 2010a, 2010b, example). Second, plan use
algorithm combination existing feedback-oriented methods (e.g., Bekkerman et al.,
2007; Roth & Small, 2009) improving performance. instance, instead
user construct relevant feature space scratch, simply extend set
informative features identified user-selected dimension. Third, since none
steps algorithm specifically designed sentiment classification, plan apply
non-topic-based text classification tasks recently received lot in625

fiDasgupta & Ng

terest NLP community, gender classification (i.e., task determining
gender author document). Finally, plan adopt richer representation
document exploits features polarity-oriented words obtained hand-built
machine-learned sentiment lexicons (e.g., Hu & Liu, 2004; Wiebe, Wilson, Bruce, Bell,
& Martin, 2004; Andreevskaia & Bergler, 2006; Mohammad, Dunne, & Dorr, 2009; Rao
& Ravichandran, 2009), derived finer-grained (i.e., sentential, sub-sentential,
phrase-based) sentiment analysis methods (e.g., Wilson et al., 2005; Kennedy & Inkpen,
2006; Polanyi & Zaenen, 2006; McDonald, Hannan, Neylon, Wells, & Reynar, 2007; Choi
& Cardie, 2008), richer features may make easier user identify
desired dimension using method.

Bibliographic Note
Portions work previously presented conference publication (Dasgupta &
Ng, 2009b). current article extends work several ways, notably: (1)
detailed introduction spectral clustering (Section 2.2); (2) inclusion two
baseline systems (Section 4.2); (3) investigation effect document representation
clustering performance (Section 4.4); (4) addition three new sections focusing
issues domain adaptation (Section 4.5), employing manually constructed subjectivity
lexicon (Section 4.6), producing multiple clusterings dataset (Section 4.7); well
(5) description significance work (Section 5).

Acknowledgments
authors acknowledge support National Science Foundation (NSF) grant IIS0812261. thank four anonymous reviewers helpful comments
unanimously recommending article publication JAIR. opinions, findings,
conclusions recommendations expressed article authors
necessarily reflect views official policies, either expressed implied, NSF.

References
Abbasi, A., Chen, H., & Salem, A. (2008). Sentiment analysis multiple languages: Feature
selection opinion classification web forums. ACM Transactions Information
Systems, 26 (3).
Andreevskaia, A., & Bergler, S. (2006). Mining WordNet fuzzy sentiment: Sentiment
tag extraction WordNet glosses. Proceedings 11th Conference
European Chapter Association Computational Linguistics (EACL), pp. 209
216.
Balcan, M.-F., & Blum, A. (2008). Clustering interactive feedback. Proceedings
19th International Conference Algorithmic Learning Theory (ALT), pp. 316
328.
Banea, C., Mihalcea, R., Wiebe, J., & Hassan, S. (2008). Multilingual subjectivity analysis using machine translation. Proceedings 2008 Conference Empirical
Methods Natural Language Processing (EMNLP), pp. 127135.
626

fiInducing Ideal Clustering Minimal Feedback

Bekkerman, R., Raghavan, H., Allan, J., & Eguchi, K. (2007). Interactive clustering
text collections according user-specified criterion. Proceedings 20th
International Joint Conference Artificial Intelligence (IJCAI), pp. 684689.
Biber, D., & Kurjian, J. (2006). Towards taxonomy web registers text types:
multidimensional analysis. Language Computers, 59 (1), 109131.
Bilenko, M., Basu, S., & Mooney, R. J. (2004). Integrating constraints machine learning
semi-supervised clustering. Proceedings 21st International Conference
Machine Learning (ICML), pp. 8188.
Blei, D. M., Ng, A. Y., & Jordon, M. I. (2003). Latent Dirichlet Allocation. Journal
Machine Learning Research, 3, 9931022.
Blitzer, J., Dredze, M., & Pereira, F. (2007). Biographies, bollywood, boom-boxes
blenders: Domain adaptation sentiment classification. Proceedings 45th
Annual Meeting Association Computational Linguistics (ACL), pp. 440447.
Blitzer, J., McDonald, R., & Pereira, F. (2006). Domain adaptation structural correspondence learning. Proceedings 2006 Conference Empirical Methods
Natural Language Processing (EMNLP), pp. 120128.
Cai, D., He, X., & Han, J. (2005). Document clustering using locality preserving indexing.
IEEE Transactions Knowledge Data Engineering, 17 (12), 16241637.
Caruana, R., Elhawary, M. F., Nguyen, N., & Smith, C. (2006). Meta clustering.
Proceedings 6th IEEE International Conference Data Mining (ICDM), pp. 107
118.
Chan, P. K., Schlag, D. F., & Zien, J. Y. (1994). Spectral k-way ratio-cut partitioning
clustering. IEEE Transactions Computer-Aided Design, 13, 10881096.
Chan, Y. S., & Ng, H. T. (2007). Domain adaptation active learning word sense
disambiguation. Proceedings 45th Annual Meeting Association
Computational Linguistics (ACL), pp. 4956.
Choi, Y., & Cardie, C. (2008). Learning compositional semantics structural inference subsentential sentiment analysis. Proceedings 2008 Conference
Empirical Methods Natural Language Processing (EMNLP), pp. 793801.
Cohn, D., Atlas, L., & Ladner, R. (1994). Improving generalization active learning.
Machine Learning, 15 (2), 201221.
Dasgupta, S., & Ng, V. (2009a). Mine easy, classify hard: semi-supervised approach automatic sentiment classification. Proceedings Joint Conference
47th Annual Meeting ACL 4th International Joint Conference
Natural Language Processing AFNLP (ACL-IJCNLP), pp. 701709.
Dasgupta, S., & Ng, V. (2009b). Topic-wise, sentiment-wise, otherwise? Identifying
hidden dimension unsupervised text classification. Proceedings 2009
Conference Empirical Methods Natural Language Processing (EMNLP), pp.
580589.
Dasgupta, S., & Ng, V. (2010a). Mining clustering dimensions. Proceedings 27th
International Conference Machine Learning (ICML), pp. 263270.
627

fiDasgupta & Ng

Dasgupta, S., & Ng, V. (2010b). Towards subjectifying text clustering. Proceedings
33rd Annual International ACM SIGIR Conference Research Development
Information Retrieval (SIGIR), pp. 483490.
Daume III, H., & Marcu, D. (2006). Domain adaptation statistical classifiers. Journal
Artificial Intelligence Research, 26, 101126.
Davidson, I., & Qi, Z. (2007). Finding alternative clusterings using constraints. Proceedings 8th IEEE International Conference Data Mining (ICDM), pp. 773778.
Deerwester, S., Dumais, S. T., Furnas, G. W., Landauer, T. K., & Harshman, R. (1990).
Indexing latent semantic analysis. Journal American Society Information
Science, 41 (6), 391407.
Dhillon, I., Guan, Y., & Kulis, B. (2004). Kernel k-means, spectral clustering normalized cuts. Proceedings 10th ACM SIGKDD International Conference
Knowledge Discovery Data Mining (KDD), pp. 551556.
Ding, C., He, X., Zha, H., Gu, M., & Simon, H. D. (2001). min-max cut algorithm
graph partitioning data clustering. Proceedings 2001 International
Conference Data Mining (ICDM), pp. 107114.
Druck, G., Settles, B., & McCallum, A. (2009). Active learning labeling features. Proceedings 2009 Conference Empirical Methods Natural Language Processing
(EMNLP), pp. 8190.
Duame III, H. (2007). Frustratingly easy domain adaptation. Proceedings 45th
Annual Meeting Association Computational Linguistics (ACL), pp. 256263.
Finn, A., & Kushmerick, N. (2006). Learning classify documents according genre.
Journal American Society Information Science Technology, 57 (11),
15061518.
Fung, G. (2003). disputed Federalist Papers: SVM feature selection via concave minimization. Proceedings 2003 Conference Diversity Computing, pp.
4246.
Gao, J., Fan, W., Jiang, J., & Han, J. (2008). Knowledge transfer via multiple model local
structure mapping. Proceeding 14th ACM SIGKDD International Conference
Knowledge Discovery Data Mining (KDD), pp. 283291.
Garera, N., & Yarowsky, D. (2009). Modeling latent biographic attributes conversational
genres. Proceedings Joint Conference 47th Annual Meeting
ACL 4th International Joint Conference Natural Language Processing
AFNLP (ACL-IJCNLP), pp. 710718.
Gilad-Bachrach, R., Navot, A., & Tishby, N. (2004). Margin based feature selection theory
algorithms. Proceedings 21st International Conference Machine
Learning (ICML), pp. 4350.
Gondek, D., & Hofmann, T. (2004). Non-redundant data clustering. Proceedings
4th IEEE International Conference Data Mining (ICDM), pp. 7582.
Gries, S., Wulff, S., & Davies, M. (2010). Corpus-linguistic Applications: Current Studies,
New Directions. Rodopi.
628

fiInducing Ideal Clustering Minimal Feedback

Grieve-Smith, A. (2006). envelope variation multidimensional register genre
analyses. Language Computers, 60 (1), 2142.
Hatzivassiloglou, V., Gravano, L., & Maganti, A. (2000). investigation linguistic
features clustering algorithms topical document clustering. Proceedings
23rd Annual International ACM SIGIR Conference Research Development
Information Retrieval (SIGIR), pp. 224231.
He, X., Cai, D., Liu, H., & Ma, W.-Y. (2004). Locality preserving indexing document
representation. Proceedings 27th Annual International ACM SIGIR Conference Research Development Information Retrieval (SIGIR), pp. 96103.
Hu, J., Deng, W., Guo, J., & Xu, W. (2007). Locality discriminating indexing document
classification. Proceedings 30th Annual International ACM SIGIR Conference
Research Development Information Retrieval (SIGIR) (Poster), pp. 689
690.
Hu, M., & Liu, B. (2004). Mining opinion features customer reviews. Proceedings
19th National Conference Artificial Intelligence (AAAI), pp. 755760.
Jain, P., Meka, R., & Dhillon, I. S. (2008). Simultaneous unsupervised learning disparate
clusterings. Proceedings SIAM International Conference Data Mining (SDM),
pp. 858869.
Jiang, J., & Zhai, C. (2007a). Instance weighting domain adaptation NLP. Proceedings 45th Annual Meeting Association Computational Linguistics
(ACL), pp. 254271.
Jiang, J., & Zhai, C. (2007b). two-stage approach domain adaptation statistical
classifiers. Proceedings 16th Conference Information Knowledge
Management (CIKM), pp. 401410.
Joachims, T. (1999a). Making large-scale SVM learning practical. Scholkopf, B., &
Smola, A. (Eds.), Advances Kernel Methods - Support Vector Learning, pp. 4456.
MIT Press.
Joachims, T. (1999b). Transductive inference text classification using support vector
machines. Proceedings 16th International Conference Machine Learning
(ICML), pp. 200209.
Jurafsky, D., Ranganath, R., & McFarland, D. (2009). Extracting social meaning: Identifying interactional style spoken conversation. Proceedings Human Language
Technologies: 2009 Annual Conference North American Chapter
Association Computational Linguistics (NAACL HLT), pp. 638646.
Kamvar, S., Klein, D., & Manning, C. (2003). Spectral learning. Proceedings 19th
International Joint Conference Artificial Intelligence (IJCAI), pp. 561566.
Kannan, R., Vempala, S., & Vetta, A. (2004). clusterings: Good, bad spectral.
Journal ACM, 51 (3), 497515.
Kennedy, A., & Inkpen, D. (2006). Sentiment classifiation movie reviews using contextual
valence shifters. Computational Intelligence, 22 (2), 110125.
629

fiDasgupta & Ng

Koppel, M., Schler, J., & Argamon, S. (2009). Computational methods authorship attribution. Journal American Society Information Science Technology,
60 (1), 926.
Kugler, M., Aoki, K., Kuroyanagi, S., Iwata, A., & Nugroho, A. (2005). Feature subset
selection support vector machines using confident margin. Proceedings
2005 IEEE International Joint Conference Neural Networks (IJCNN), pp. 907912.
Kulis, B., Basu, S., Dhillon, I., & Mooney, R. (2009). Semi-supervised graph-based clustering: kernel approach. Machine Learning, 74 (1), 122.
Li, T., Zhang, Y., & Sindhwani, V. (2009). non-negative matrix tri-factorization approach
sentiment classification lexical prior knowledge. Proceedings Joint
Conference 47th Annual Meeting ACL 4th International Joint
Conference Natural Language Processing AFNLP (ACL-IJCNLP), pp. 244
252.
Lim, C., Lee, K., & Kim, G. (2005). Multiple sets features automatic genre classification web documents. Information Processing Management, 41 (5), 12631276.
Ling, X., Dai, W., Xue, G., Yang, Q., & Yu, Y. (2008). Spectral domain-transfer learning.
Proceeding 14th ACM SIGKDD International Conference Knowledge
Discovery Data Mining (KDD), pp. 488496.
Liu, B., Li, X., Lee, W. S., & Yu, P. S. (2004). Text classification labeling words.
Proceedings 19th National Conference Artificial Intelligence (AAAI), pp.
425430.
McCallum, A. K., & Nigam, K. (1998). Employing EM pool-based active learning
text classification. Proceedings 15th International Conference Machine
Learning (ICML), pp. 350358, Madison, WI. Morgan Kaufmann.
McDonald, R., Hannan, K., Neylon, T., Wells, M., & Reynar, J. (2007). Structured models
fine-to-coarse sentiment analysis. Proceedings 45th Annual Meeting
Association Computational Linguistics (ACL), pp. 432439.
Mei, Q., Ling, X., Wondra, M., Su, H., & Zhai, C. (2007). Sentiment mixture: Modeling
facets opinions weblogs. Proceedings 16th World Wide Web Conference
(WWW), pp. 171180.
Mohammad, S., Dunne, C., & Dorr, B. (2009). Generating high-coverage semantic orientation lexicons overtly marked words thesaurus. Proceedings
2009 Conference Empirical Methods Natural Language Processing (EMNLP),
pp. 599608.
Ng, A., Jordan, M., & Weiss, Y. (2001). spectral clustering: Analysis algorithm.
Advances Neural Information Processing Systems 14 (NIPS).
Nigam, K., McCallum, A., Thrun, S., & Mitchell, T. (2000). Text classification labeled
unlabeled documents using EM. Machine Learning, 39 (2/3), 103134.
Pang, B., & Lee, L. (2008). Opinion mining sentiment analysis. Foundations Trends
Information Retrieval, 2 (12), 1135.
630

fiInducing Ideal Clustering Minimal Feedback

Pang, B., Lee, L., & Vaithyanathan, S. (2002). Thumbs up? Sentiment classification using
machine learning techniques. Proceedings 2002 Conference Empirical
Methods Natural Language Processing (EMNLP), pp. 7986. Association Computational Linguistics.
Polanyi, L., & Zaenen, A. (2006). Contextual valence shifters. Computing Attitude
Affect Text: Theory Applications. Springer Verlag.
Raghavan, H., & Allan, J. (2007). interactive algorithm asking incorporating
feature feedback support vector machines. Proceedings 30th Annual
International ACM SIGIR Conference Research Development Information
Retrieval (SIGIR), pp. 7986.
Rao, D., & Ravichandran, D. (2009). Semi-supervised polarity lexicon induction. Proceedings 12th Conference European Chapter Association Computational Linguistics (EACL), pp. 675682.
Riloff, E., & Wiebe, J. (2003). Learning extraction patterns subjective expressions.
Proceedings 2003 Conference Empirical Methods Natural Language
Processing (EMNLP), pp. 105112.
Roth, D., & Small, K. (2009). Interactive feature space construction using semantic information. Proceedings 13th Conference Computational Natural Language
Learning (CoNLL), pp. 6674.
Sandler, M. (2005). use linear programming unsupervised text classification.
Proceedings 11th ACM SIGKDD International Conference Knowledge
Discovery Data Mining (KDD), pp. 256264.
Sebastiani, F. (2002). Machine learning automated text categorization. ACM Computing
Surveys, 34 (1), 147.
Shi, J., & Malik, J. (2000). Normalized cuts image segmentation. IEEE Transactions
Pattern Analysis Machine Intelligence, 22 (8), 888905.
Sindhwani, V., & Melville, P. (2008). Document-word co-regularization semi-supervised
sentiment analysis. Proceedings 8th IEEE International Conference Data
Mining (ICDM), pp. 10251030.
Stein, S., Argamon, S., & Frieder, O. (2006). effect OCR errors stylistic text
classification. Proceedings 29th Annual International ACM SIGIR conference
Research Development Information Retrieval (SIGIR) (Poster), pp. 701
702.
Tambouratzis, G., & Vassiliou, M. (2007). Employing thematic variables enhancing classification accuracy within author discrimination experiments. Literary Linguistic
Computing, 22 (2), 207224.
Tan, S., Cheng, X., Wang, Y., & Xu, H. (2009). Adapting naive Bayes domain adaptation
sentiment analysis. Proceedings 31st European Conference Information
Retrieval (ECIR), pp. 337349.
Turney, P. (2002). Thumbs thumbs down? Semantic orientation applied unsupervised classification reviews. Proceedings 40th Annual Meeting
Association Computational Linguistics (ACL), pp. 417424.
631

fiDasgupta & Ng

Wagstaff, K., Cardie, C., Rogers, S., & Schrodl, S. (2001). Constrained k-means clustering
background knowledge. Proceedings 18th International Conference
Machine Learning (ICML), pp. 577584.
Wan, X. (2008). Using bilingual knowledge ensemble techniques unsupervised Chinese sentiment analysis. Proceedings 2008 Conference Empirical Methods
Natural Language Processing (EMNLP), pp. 553561.
Weiss, Y. (1999). Segmentation using eigenvectors: unifying view. Proceedings
International Conference Computer Vision (ICCV), pp. 975982.
Wiebe, J. M., Wilson, T., Bruce, R., Bell, M., & Martin, M. (2004). Learning subjective
language. Computational Linguistics, 30 (3), 277308.
Wilson, T., Wiebe, J. M., & Hoffmann, P. (2005). Recognizing contextual polarity
phrase-level sentiment analysis. Proceedings Joint Human Language Technology Conference 2005 Conference Empirical Methods Natural Language
Processing (HLT/EMNLP), pp. 347354.
Wu, Z., & Leahy, R. M. (1993). optimal graph theoretic appproach data clustering
application image segmentation. IEEE Transactions Pattern Analysis
Machine Intelligence, 15 (11), 11011113.
Xing, E. P., Ng, A. Y., Jordan, M. I., & Russell, S. J. (2002). Distance metric learning
application clustering side-information. Advances Neural Information
Processing Systems 15 (NIPS), pp. 505512.
Xu, W., Liu, X., & Gong, Y. (2003). Document clustering based non-negative matrix
factorization. Proceedings 26th Annual International ACM SIGIR Conference
Research Development Information Retrieval (SIGIR), pp. 267273.
Yang, Y., & Liu, X. (1999). re-examination text categorization methods. Proceedings 22nd Annual International ACM SIGIR Conference Research
Development Information Retrieval (SIGIR), pp. 4249.
Yang, Y., & Pedersen, J. O. (1997). comparative study feature selection text categorization. Proceedings 14th International Conference Machine Learning
(ICML), pp. 412420.

632

fiJournal Artificial Intelligence Research 39 (2010) 1-49

Submitted 05/10; published 09/10

Planning Noisy Probabilistic Relational Rules
Tobias Lang
Marc Toussaint

tobias.lang@tu-berlin.de
mtoussai@cs.tu-berlin.de

Machine Learning Robotics Group
Technische Universitat Berlin
Franklinstrae 28/29, 10587 Berlin, Germany

Abstract
Noisy probabilistic relational rules promising world model representation several reasons. compact generalize world instantiations. usually
interpretable learned effectively action experiences complex
worlds. investigate reasoning rules grounded relational domains. algorithms exploit compactness rules efficient flexible decision-theoretic planning.
first approach, combine rules Upper Confidence Bounds applied
Trees (UCT) algorithm based look-ahead trees. second approach converts
rules structured dynamic Bayesian network representation predicts effects
action sequences using approximate inference beliefs world states. evaluate
effectiveness approaches planning simulated complex 3D robot manipulation scenario articulated manipulator realistic physics domains
probabilistic planning competition. Empirical results show methods solve
problems existing methods fail.

1. Introduction
Building systems act autonomously complex environments central goal Artificial Intelligence. Nowadays, A.I. systems par particularly intelligent humans
specialized tasks playing chess. hopelessly inferior almost humans, however, deceivingly simple tasks everyday-life, clearing desktop,
preparing cup tea manipulating chess figures: current state art reasoning, planning, learning, perception, locomotion, manipulation far removed
human-level abilities, cannot yet contemplate working actual domain interest (Pasula, Zettlemoyer, & Kaelbling, 2007). Performing common object manipulations
indeed challenging task real world: choose large number
distinct actions uncertain outcomes number possible situations basically
unseizable.
act real world, accomplish two tasks. First, need understand
world works: example, pile plates stable place big plates
bottom; hard job build tower balls; filling tea cup may lead
dirty table cloth. Autonomous agents need learn world knowledge experience
adapt new environments rely human hand-crafting. paper,
employ recent solution learning (Pasula et al., 2007). know possible
effects actions, face second challenging problem: use acquired
knowledge reasonable time find sequence actions suitable achieve goals?
c
2010
AI Access Foundation. rights reserved.

fiLang & Toussaint

paper investigates novel algorithms tackle second task, namely planning.
pursue model-based approach planning complex domains. contrast modelfree approaches compute policies directly experience respect fixed goals
(also called habit-based decision making), follow purposive decision-making approach
(Botvinick & An, 2009) use learned models plan goal current state
hand. particular, simulate probabilistic effects action sequences. approach
interesting parallels recent neurobiology cognitive science results suggesting
behavior intelligent mammals driven internal simulation emulation:
found motor structures cortex activated planning,
execution motor commands suppressed (Hesslow, 2002; Grush, 2004).
Probabilistic relational world model representations received significant attention
last years. enable generalize object identities unencountered situations objects similar types account indeterministic action effects noise.
review several approaches together related work Section 2. Noisy
indeterministic deictic (NID) rules (Pasula et al., 2007) capture world dynamics
elegant compact way. particularly appealing learned effectively
experience. existing approach planning rules relies growing
full look-ahead trees grounded domain. Due large action space
stochasticity world, computational burden plan single action
method given situation overwhelmingly large. paper proposes two novel
ways reasoning efficiently grounded domain using learned NID rules, enabling fast
planning complex environments varying goals. First, apply existing Upper
Confidence bounds applied Trees (UCT) algorithm (Kocsis & Szepesvari, 2006) NID
rules. contrast full-grown look-ahead trees, UCT samples actions selectively, thereby
cutting suboptimal parts tree early. Second, introduce Probabilistic Relational
Action-sampling DBNs planning Algorithm (PRADA) uses probabilistic inference
cope uncertain action outcomes. Instead growing look-ahead trees sampled successor states like previous approaches, PRADA applies approximate inference
techniques propagate effects actions. particular, make three contributions
PRADA: (i) Following idea framing planning probabilistic inference problem (Shachter, 1988; Toussaint, Storkey, & Harmeling, 2010), convert NID rules
dynamic Bayesian network (DBN) representation. (ii) derive approximate inference method cope state complexity time-slice resulting network.
Thereby, efficiently predict effects action sequences. (iii) planning based
sampling action-sequences, propose sampling distribution plans takes predicted state distributions account. evaluate planning approaches simulated
complex 3D robot manipulation environment realistic physics, articulated humanoid manipulating objects different types (see Fig. 4). domain contains billions
world states large number potential actions. learn NID rules experience
environment apply planning approaches different planning
scenarios increasing difficulty. Furthermore, provide results approaches
planning domains recent international probabilistic planning competition.
purpose, discuss relation NID rules probabilistic planning
domain definition language (PPDDL) used specification domains.
2

fiPlanning Noisy Probabilistic Relational Rules

begin paper discussing related work Section 2 reviewing
background work, namely stochastic relational representations, NID rules, formalization decision-theoretic planning graphical models Section 3. Section 4,
present two planning algorithms build look-ahead trees cope stochastic
actions. Section 5, introduce PRADA uses approximate inference planning.
Section 6, present empirical evaluation demonstrating utility planning
approaches. Finally, conclude outline future directions research.

2. Related Work
problem decision-making planning stochastic relational domains approached different ways. field relational reinforcement learning (RRL) (Dzeroski,
de Raedt, & Driessens, 2001; van Otterlo, 2009) investigates value functions Q-functions
defined possible ground states actions relational domain. key
idea describe important world features terms abstract logical formulas enabling
generalization objects situations. Model-free RRL approaches learn value functions
states actions directly experience. Q-function estimators include relational
regression trees (Dzeroski et al., 2001) instance-based regression using distance metrics relational states graph kernels (Driessens, Ramon, & Gartner, 2006).
Model-free approaches enable planning specific problem type used training
examples, e.g. on(X, ), thus may inappropriate situations goals
agent change quickly, e.g. on(X, ) inhand(X). contrast, model-based RRL
approaches first learn relational world model state transition experiences
use model planning, example form relational probability trees
individual state attributes (Croonenborghs, Ramon, Blockeel, & Bruynooghe, 2007)
SVMs using graph kernels (Halbritter & Geibel, 2007). stochastic relational NID rules
Pasula et al. (2007) particularly appealing action model representation,
shown empirically learn dynamics complex environments.
probabilistic relational world model available (either learned handcrafted),
one pursue decision-theoretic planning different ways. Within machine learning
community, popular direction research formalizes problem relational Markov
decision process (RMDP) develops dynamic programming algorithms compute solutions, i.e. policies complete state action spaces. Many algorithms reason
lifted abstract representation without grounding referring particular problem instances. Boutilier, Reiter, Price (2001) introduce Symbolic Dynamic Programming,
first exact solution technique RMDPs uses logical regression construct
minimal logical partitions state space required make necessary value function
distinctions. approach implemented difficult keep firstorder state formulas consistent manageable size. Based ideas, Kersting, van
Otterlo, de Raedt (2004) propose exact value iteration algorithm RMDPs using
logic-programming, called ReBel. employ restricted language represent RMDPs
reason efficiently state formulas. Holldobler Skvortsova (2004)
present first-order value iteration algorithm (FOVIA) using different restricted language.
Karabaev Skvortsova (2005) extend FOVIA combining first-order reasoning
actions heuristic search restricted states reachable initial
3

fiLang & Toussaint

state. Wang, Joshi, Khardon (2008) derive value iteration algorithm based using
first-order decision diagrams (FODDs) goal regression. introduce reduction operators FODDs keep representation small, may require complex reasoning;
empirical evaluation provided. Joshi, Kersting, Khardon (2009) apply
model checking reduce FODDs generalize arbitrary quantification.
techniques form interesting research direction reason exactly
abstract RMDPs. employ different methods ensure exact regression theorem proving, logical simplification, consistency checking. Therefore, principled approximations techniques discover good policies difficult domains
likewise worth investigating. instance, Gretton Thiebaux (2004) employ first-order
regression generate suitable hypothesis language use policy induction; thereby, approach avoids formula rewriting theorem proving, still
requiring model-checking. Sanner Boutilier (2007, 2009) present first-order approximate linear programming approach (FOALP). Prior producing plans, approximate
value function based linear combinations abstract first-order value functions,
showing impressive results solving RMDPs millions states. Fern, Yoon,
Givan (2006) consider variant approximate policy iteration (API) replace
value-function learning step learning step policy space. make use
policy-space bias described generic relational knowledge representation simulate trajectories improve learned policy. Kersting Driessens (2008) describe
non-parametric policy gradient approach deal propositional, continuous
relational domains unified way.
Instead working lifted representation, one may reason grounded domain.
makes straightforward account two special characteristics NID rules:
noise outcome uniqueness requirement rules. grounding RMDP
specifies rewards set goal states, one might principle apply traditional A.I. planning methods used propositional representations (Weld, 1999; Boutilier,
Dean, & Hanks, 1999). Traditionally, planning often cast search problem
state action space, restricting oneself portion state space considered contain goal states reachable current state within limited
horizon. Much research within planning community focused deterministic domains thus cant applied straightforwardly stochastic worlds. common approach
probabilistic planning, however, determinize planning problem apply deterministic planners (Kuter, Nau, Reisner, & Goldman, 2008). Indeed, FF-Replan (Yoon,
Fern, & Givan, 2007) extension using hindsight optimization (Yoon, Fern, Givan, &
Kambhampati, 2008) shown impressive performance many probabilistic planning
competition domains. common variant FF-Replan considers probabilistic outcome action separate deterministic action, ignoring respective probabilities.
runs deterministic Fast-Forward (FF) planner (Hoffmann & Nebel, 2001)
determinized problem. FF uses relaxation planning problem: ignores delete
effects actions applies clever heuristics prune search space. FF-Replan outputs
sequence actions expected states. time action execution leads state
plan, FF-Replan replan, i.e., recompute new plan scratch
current state. good performance FF-Replan many probabilistic domains
explained structure problems (Little & Thiebaux, 2007).
4

fiPlanning Noisy Probabilistic Relational Rules

argued FF-Replan less appropriate domains probability
reaching dead-end non-negligible outcome probabilities actions need
taken account construct good policy.
Many participants recent probabilistic planning competition (IPPC, 2008)
extend FF-Replan deal probabilities action outcomes (see competition
website brief descriptions algorithms). winner competition, RFF
(Teichteil-Konigsbuch, Kuter, & Infantes, 2010), computes robust policy offline generating successive execution paths leading goal using FF. resulting policy
low probability failing. LPPFF uses subgoals generated determinization
probabilistic planning problem divide smaller manageable problems. HMDPPs
strategy similar all-outcomes-determinization FF-Replan, accounts
probability associated outcome. SEH (Wu, Kalyanam, & Givan, 2008) extends
heuristic function FF-Replan cope local optima plans using stochastic
enforced hill-climbing.
common approach reasoning general reward-maximization context
avoids explicitly dealing uncertainty build look-ahead trees sampling successor
states. Two algorithms follow idea, namely SST (Kearns, Mansour, & Ng, 2002)
UCT (Kocsis & Szepesvari, 2006), investigated paper.
Another approach Buffet Aberdeen (2009) directly optimizes parameterized
policy using gradient descent. factor global policy simple approximate policies
starting action sample trajectories cope probabilistic effects.
Instead sampling state transitions, propose planning algorithm PRADA
paper (based Lang & Toussaint, 2009a) accounts uncertainty principled
way using approximate inference. Domshlak Hoffmann (2007) propose interesting
planning approach comes closest work. introduce probabilistic extension FF planner, using complex algorithms building probabilistic relaxed planning
graphs. construct dynamic Bayesian networks (DBNs) hand-crafted STRIPS operators reason actions states using weighted model counting. DBN
representation, however, inadequate type stochastic relational rules use,
reasons naive DBN model discuss Sec. 5.1 inappropriate. Planning inference approaches (Toussaint & Storkey, 2006) spread information
also backwards DBNs calculate posteriors actions (resulting policies
complete state spaces). use backward propagation even full planning
inference relational domains open issue.
approaches working grounded representation common number
states actions grow exponentially number objects. apply
domains many objects, approaches need combined complementary
methods reduce state action space complexity relational domains.
instance, one focus envelopes states high-utility subsets state
space (Gardiol & Kaelbling, 2003), one ground representation respect
relevant objects (Lang & Toussaint, 2009b), one exploit equivalence actions
(Gardiol & Kaelbling, 2007), particularly useful combination ignoring
certain predicates functions relational logic language (Gardiol & Kaelbling, 2008).
5

fiLang & Toussaint

3. Background
section, set theoretical background planning algorithms
present subsequent sections. First, describe relational representations define world
states actions. present noisy indeterministic deictic (NID) rules detail
thereafter define problem decision-theoretic planning stochastic relational
domains. Finally, briefly review dynamic Bayesian networks.
3.1 State Action Representation
relational domain represented relational logic language L: set logical
predicates P set logical functions F contain relationships properties
hold domain objects. set logical predicates comprises possible actions
domain. concrete instantiation relational domain made finite set
objects O. arguments predicate function concrete, i.e. taken O,
call grounded. concrete world state fully described conjunction grounded
(potentially negated) predicates function values. Concrete actions described
positive grounded predicates A. arguments predicates functions also
abstract logical variables represent object. predicate function
abstract arguments, call abstract. Abstract predicates functions enable
generalization objects situations. speak grounding formula
apply substitution maps variables appearing objects O.
relational model transition dynamics specifies P (s0 |a, s), probability
successor state s0 action performed state s. paper, usually
non-deterministic distribution. typically defined compactly terms formulas
abstract predicates functions. enables abstraction object identities
concrete domain instantiations. instance, consider set N cups: effects trying
grab cups may described single abstract model instead
using N individual models. apply given world state, one needs ground
respect objects domain. NID rules elegant way specify
model described following.
3.2 Noisy Indeterministic Deictic Rules
want learn relational model stochastic world use planning. Pasula
et al. (2007) recently introduced appealing action model representation based
noisy indeterministic deictic (NID) rules combine several advantages:
relational representation enabling generalization objects situations,
indeterministic action outcomes probabilities account stochastic domains,
deictic references actions reduce action space,
noise outcomes avoid explicit modeling rare overly complex outcomes,
existence effective learning algorithm.
6

fiPlanning Noisy Probabilistic Relational Rules

Table 1 shows exemplary NID rule complex robot manipulation domain.
Fig. 1 depicts situation rule used prediction. Formally, NID rule
r given

pr,1
: r,1 (X )




..
.
(1)
ar (X ) : r (X )

:
r,mr (X )
p

r,m
r


pr,0
: r,0
X set logical variables rule (which represent (sub-)set abstract
objects). rules define world models formulas abstract, i.e.,
arguments logical variables. rule r consists preconditions, namely action
ar applied X state P
context r fulfilled, mr +1 different outcomes
associated probabilities pr,i 0, i=0 pr,i = 1. outcome r,i (X ) describes
predicates functions change rule applied. context r (X ) outcomes
r,i (X ) conjunctions (potentially negated) literals constructed predicates
P well equality statements comparing functions F constant values. Besides
explicitely stated outcomes r,i (i > 0), so-called noise outcome r,0 models implicitly
potential outcomes rule. particular, includes rare overly
complex outcomes typical noisy domains, want cover explicitly
compactness generalization reasons. instance, context rule depicted
Fig. 1 potential, highly improbable outcome grab blue cube pushing
objects table: noise outcome allows account without burden
explicitly stating it.
arguments action a(Xa ) may true subset Xa X variables X
rule. remaining variables called deictic references = X \ Xa denote
objects relative agent action performed. Using deictic references
advantage decrease arity action predicates. turn reduces size
action space least order magnitude, significant effects
planning problem. instance, consider binary action predicate world
n objects n2 groundings contrast unary action predicate n
groundings.
above, let denote substitution maps variables constant objects, : X O.
Applying abstract rule r(X ) yields ground rule r((X )). say ground rule r
covers state ground action |= r = ar . Let set ground NID
rules. define (a) := {r | r , ar = a} set rules provide predictions
action a. r rule (a) cover state s, call unique covering rule
s. state-action pair (s, a) unique covering rule r, calculate P (s0 | s, a)
taking outcomes r account weighted respective probabilities,
r

0

0

P (s |s, a) = P (s |s, r) =


X

pr,i P (s0 |r,i , s) + pr,0 P (s0 |r,0 , s),

(2)

i=1

where, > 0, P (s0 | r,i , s) deterministic distribution one unique
state constructed taking changes r,i account. distribution given
7

fiLang & Toussaint

Table 1: Example NID rule complex robot manipulation scenario, models
try grab ball X. cube implicitly defined one X (deictic
referencing). X ends robots hand high probability, might
also fall table. small probability something unpredictable happens.
Confer Fig. 1 example application.

grab(X) : on(X, ), ball(X), cube(Y ), table(Z)

0.7 : inhand(X), on(X, )
0.2 : on(X, Z), on(X, )


0.1 : noise

Figure 1: NID rule defined Table 1 used predict effects action
grab(ball) situation left side. right side depicts possible
successor states predicted rule. noise outcome indicated
question mark define unique successor state.

noise outcome, P (s0 | r,0 , s), unknown needs estimated. Pasula et al. use
worst case constant bound pmin P (s0 |r,0 , s) lower bound P (s0 |s, a). Alternatively,
come well-defined distribution, one may assign low probability many
successor states. described detail Sec. 5.2, planning algorithm PRADA
exploits factored state representation grounded relational domain achieve
predicting state attribute change low probability.
state-action pair (s, a) unique covering rule r (e.g. two rules cover
(s, a) providing conflicting predictions), one predict effects means
noisy default rule r explains effects changing state attributes noise:
P (s0 |s, r ) = P (s0 | r ,0 , s). Essentially, using r expresses know
happen. meaningful thus disadvantageous planning. (Hence, one
bias NID rules learner learn rules contexts likely mutually
exclusive.) reason, concept unique covering rules crucial planning
NID rules. Here, pay price using deictic references: using
abstract NID rule prediction, always ensure deictic references
unique groundings. may require examining large part state representation,
8

fiPlanning Noisy Probabilistic Relational Rules

proper storage ground state efficient indexing techniques logical formula
evaluation needed.
ability learn models environment experience crucial requirement
autonomous agents. problem learning rule-sets general NP-hard, efficiency guarantees sample complexity given many learning subtasks
suitable restrictions (Walsh, 2010). Pasula et al. (2007) proposed supervised batch
learning algorithm complete NID rules. algorithm learns structure rules
well parameters experience triples (s, a, s0 ), stating observed successor
state s0 action applied state s. performs greedy search space
rule-sets. optimizes tradeoff maximizing likelihood experience
triples minimizing complexity current hypothesis rule-set optimizing
scoring metric
X
X
S() =
log P (s0 | s, rs,a )
P EN (r) ,
(3)
(s,a,s0 )

r

rs,a either unique covering rule (s, a) noisy default rule r
scaling parameter controls influence regularization. P EN (r) penalizes
complexity rule defined total number literals r.
noise outcome NID rules crucial learning. learning algorithm initialized rule-set comprising noisy default rule r iteratively adds
new rules modifies existing ones using set search operators. noise outcome
allows avoiding overfitting, need model rare overly complex outcomes
explicitly. drawback successor state distribution P (s0 | r,0 , s) unknown.
deal problem, learning algorithm uses lower bound pmin approximate
distribution, described above. algorithm uses greedy heuristics attempt
learn complete rules, guarantees behavior given. Pasula et al., however, report impressive results complex noisy environments. Sec. 6.1, confirm
results simulated noisy robot manipulation scenario. major motivation employing NID rules learn observed actions state transitions.
Furthermore, planning approach PRADA exploit simple structure (which
similar probabilistic STRIPS operators) convert DBN representation.
provide detailed comparison NID rules PPDDL Appendix B. NID
rules support features sophisticated domain description language
PPDDL, compactly capture dynamics many interesting planning domains.
3.3 Decision-Theoretic Planning
problem decision-theoretic planning find actions given state
expected maximize future rewards states actions (Boutilier et al., 1999).
classical planning, reward usually defined terms clear-cut goal
either fulfilled fulfilled state. expressed means logical
formula . Typically, formula partial state description exists
one state holds. example, goal might put romance
books specific shelf, matter remaining books lying. case,
planning involves finding sequence actions executing starting
9

fiLang & Toussaint

result world state s0 s0 |= . stochastic domains, however, outcomes
actions uncertain. Probabilistic planning inherently harder deterministic
counterpart (Littman, Goldsmith, & Mundhenk, 1997). particular, achieving goal
state certainty typically unrealistic. Instead, one may define lower bound
probability achieving goal state. second source uncertainty next uncertain
action outcomes uncertainty initial state s. ignore latter
following always assume deterministic initial states. see later, however,
straightforward incorporate uncertainty initial state using one proposed
planning approaches.
Instead classical planning task finished achieved state
goal fulfilled, task may also ongoing. instance, goal might
keep desktop tidy. formalized means reward function states,
yields high reward desirable states (for simplicity, assume rewards
depend actions). approach taken reinforcement learning formalisms
(Sutton & Barto, 1998). Classical planning goals easily formalized
reward function. cast scenario planning stochastic relational domain
relational Markov decision process (RMDP) framework (Boutilier et al., 2001). follow
notation van Otterlo (2009) define RMDP 4-tuple (S, A, T, R). contrast
enumerated state spaces, state space relational structure defined
logical predicates P functions F, yield ground atoms arguments taken
set domain objects O. action space defined positive predicates
arguments O. : [0, 1] transition distribution R : R
reward function. R make use factored relational representation
abstract states actions, discussed following. Typically,
state space action space relational domain large. Consider
instance domain 5 objects use 3 binary predicates represent states:
2
case, number states 235 = 275 . Relational world models encapsulate transition
probabilities compact way exploiting relational structure. example, NID rules
described Eq. (2) achieve generalized partial world state descriptions
form conjunctions abstract literals. compactness models, however,
carry directly planning problem.
(deterministic) policy : tells us action take given state.
fixed horizon discount
0 < < 1, interested maximizing
Pd factor
r . value factored state defined
discounted total reward r =


t=0
expected return state following policy :
V (s) = E[r | s0 = s; ] .

(4)

solution RMDP, thus problem planning, optimal policy
maximizes expected return. defined Bellman equation:
X


V (s) = R(s) + max[
P (s0 | s, a)V (s0 )] .
aA

10

s0

(5)

fiPlanning Noisy Probabilistic Relational Rules

Similarly, one define value Q (s, a) action state expected return
action taken state s, using policy select subsequent actions:
Q (s, a) = E[r | s0 = s, a0 = a; ]
X
= R(s) +
V (s0 )P (s0 | s, a) .

(6)
(7)

s0

Q-values optimal policy let us define optimal action optimal
value state


= argmax Q (s, a)



(8)

aA




V (s) = max Q (s, a) .
aA

(9)

enumerated unstructured state spaces, state Q-values computed using dynamic programming methods resulting optimal policies complete state space.
Recently, promising approaches exploiting relational structure proposed apply similar ideas solve approximate solutions RDMPs abstract level (without
referring concrete objects O) (see related work Sec. 2). Alternatively, one may
reason grounded relational domain. makes straightforward account
noise outcome uniqueness requirement NID rules. Usually, one focuses estimating optimal action values given state. approach appealing agents
varying goals, quickly coming plan problem hand
appropriate computing abstract policy complete state space. Although
grounding simplifies problem, decision-theoretic planning propositionalized representation challenging task complex stochastic domains. Sections 4 5,
present different algorithms reasoning grounded relational domain estimating
optimal Q-values actions (and action-sequences) given state.
3.4 Dynamic Bayesian Networks
Dynamic Bayesian networks (DBNs) model development stochastic systems
time. PRADA planning algorithm introduce Sec. 5 makes use
kind graphical model evaluate stochastic effects action sequences factored
grounded relational world states. Therefore, briefly review Bayesian networks
dynamic extension here.
Bayesian network (BN) (Jensen, 1996) compact representation joint probability distribution set random variables X means directed acyclic graph
G. nodes G represent random variables, edges define dependencies thereby express conditional independence assumptions. value x variable
X X depends values immediate ancestors G, called
parents P a(X) X. Conditional probability functions node define P (X | P a(X)).
case discrete variables, may defined form conditional probability tables.
BN compact representation distribution X nodes
parents conditional probability functions significant local structure.
play crucial role development graphical models PRADA.
11

fiLang & Toussaint

DBN (Murphy, 2002) extends BN formalism model dynamic system evolving
time. Usually, focus discrete-time stochastic processes. underlying
system (in case, world state) represented BN B, DBN maintains
copy BN every time-step. DBN defined pair BNs (B0 , B ),
B0 (deterministic uncertain) prior defines state system
initial state = 0, B two-slice BN defines dependencies two
successive time-steps + 1. implements first-order Markov assumption:
variables time + 1 depend variables time + 1 variables t.

4. Planning Look-Ahead Trees
plan NID rules, one treat domain described
ulary relational Markov decision process discussed Sec.
present two value-based reinforcement learning algorithms
generative model build look-ahead trees starting initial
used estimate values actions states.

relational logic vocab3.3. following,
employ NID rules
state. trees

4.1 Sparse Sampling Trees
Sparse Sampling Tree (SST) algorithm (Kearns et al., 2002) MDP planning samples
randomly sparse, full-grown look-ahead trees states starting given state
root. suffices compute near-optimal actions state MDP. Given
planning horizon branching factor b, SST works follows (see Fig. 2): tree
node (representing state), (i) SST takes possible actions account, (ii)
action takes b samples successor state distribution using generative model
transitions, e.g. transition model MDP, build tree nodes next
level. Values tree nodes computed recursively leaves root using
Bellman equation: given node, Q-value possible action estimated
averaging values b children states action; then, maximizing
Q-value actions chosen estimate value given node. SST
favorable property independent total number states MDP,
examines restricted subset state space. Nonetheless, exponential
time horizon taken account.
Pasula et al. (2007) apply SST planning NID rules. sampling noise
outcome planning SST, assume stay state, discount
estimated value. refer adaptation speak SST planning
remainder paper. action unique covering rule, use noisy
default rule r predict effects. always better perform othing action
instead staying state get punished. Hence, SST planning one
discard actions given state unique covering rules.
SST near-optimal, practice feasible small branching factor
b planning horizon d. Let number actions a. number nodes
horizon (ba)d . (This number reduced outcome rule sampled
multiple times.) illustration, assume 10 possible actions per time-step
set parameters = 4 b = 4 (the choice Pasula et al. experiments). plan
single action given state, one visit (10 4)4 = 2, 560, 000 states. smaller
12

fiPlanning Noisy Probabilistic Relational Rules

Figure 2: SST planning algorithm samples sparse, full-grown look-ahead trees
estimate values actions states.

choices b lead faster planning, result significant accuracy loss realistic
domains. Kearns et al. note, SST useful special structure permits
compact representation available. Sec. 5, introduce alternative planning
approach based approximate inference exploits structure NID rules.
4.2 Sampling Trees Upper Confidence Bounds
Upper Confidence Bounds applied Trees (UCT) algorithm (Kocsis & Szepesvari,
2006) also samples search tree subsequent states starting current state root.
contrast SST generates b successor states every action state, idea
UCT choose actions selectively given state thus sample selectively
successor state distribution. UCT tries identify large subsets suboptimal actions early
sampling procedure focus promising parts look-ahead tree instead.
UCT builds look-ahead tree repeatedly sampling simulated episodes
initial state using generative model, e.g. transition model MDP. episode
sequence states, rewards actions limited horizon d: s0 , r0 , a1 , s1 , r1 , a2 . . . sd , rd .
simulated episode, values tree nodes (representing states) updated
online simulation policy improved respect new values. result,
distinct value estimated state-action pair tree Monte-Carlo simulation.
precisely, UCT follows following policy tree node s: exist actions
explored yet, UCT samples one using uniform
distribution. Otherwise, actions explored least once, UCT selects
action maximizes upper confidence bound QO
U CT (s, a) estimated action
13

fiLang & Toussaint

value QU CT (s, a),

QO
U CT (s, a)

= QU CT (s, a) + c

log ns
,
ns,a

U CT (s) = argmax QO
U CT (s, a) ,

(10)
(11)



ns,a counts number times actionPa selected state s, ns
counts total number visits state s, ns = ns,a . bias parameter c defines
influence number previous action selections thereby controls extent
upper confidence bound.
end episode, value encountered state-action pair (st , ), 0
< d, updated using total discounted rewards:
nst ,at nst ,at + 1 ,
QU CT (st , ) QU CT (st , ) +

(12)
1
nst ,at


X

[

0

rt0 QU CT (st , )] .

(13)

t0 =t

policy UCT implements exploration-exploitation tradeoff: balances
exploring currently suboptimal-looking actions selected seldom thus far
exploiting currently best-looking actions get precise estimates values.
total number episodes controls accuracy UCTs estimates balanced
overall running time.
UCT achieved remarkable results challenging domains game Go
(Gelly & Silver, 2007). best knowledge, first apply UCT
planning stochastic relational domains, using NID rules generative model. adapt
UCT cope noise outcomes fashion SST: assume stay
state discount obtained rewards. Thus, UCT takes actions unique
covering rules account, reasons SST does.

5. Planning Approximate Inference
Uncertain action outcomes characterize complex environments, make planning relational domains substantially difficult. sampling-based approaches discussed
previous section tackle problem repeatedly generating samples outcome
distribution action using transition probabilities MDP. leads lookahead trees easily blow planning horizon. Instead sampling successor
states, one may maintain distribution states, so-called belief. following,
introduce approach planning grounded stochastic relation domains propagates beliefs states sense state monitoring. First, show create
compact graphical models NID rules. develop approximate inference method
efficiently propagate beliefs. hand, describe Probabilistic Relational
Action-sampling DBNs planning Algorithm (PRADA), samples action-sequences
informed way evaluates using approximate inference DBNs. Then,
example presented illustrate reasoning PRADA. Finally, discuss PRADA
comparison approaches previous section, SST UCT, present simple
extension PRADA.
14

fiPlanning Noisy Probabilistic Relational Rules

(a)

(b)

Figure 3: Graphical models NID rules: (a) Naive DBN; (b) DBN exploiting NID factorization

5.1 Graphical Models NID Rules
Decision-theoretic problems agents need choose appropriate actions represented means Markov chains dynamic Bayesian networks (DBNs)
augmented decision nodes specify agents actions (Boutilier et al., 1999).
following, discuss convert NID rules DBNs PRADA algorithm
use plan probabilistic inference. denote random variables upper case letters
(e.g. S), values corresponding lower case letters (e.g., dom(S)), variable
vectors bold upper case letters (e.g. = (S1 , S2 , S3 )) value vectors bold lower
case letters (e.g. = (s1 , s2 , s3 )). also use column notation, e.g. s2:4 = (s2 , s3 , s4 ).
naive way convert NID rules DBNs shown Fig. 3(a). States represented
vector = (S1 , . . . , SN ) ground predicate P binary Si
ground function F Sj range according represented
function. Actions represented integer variable indicates action
vector ground action predicates A. reward gained state represented
U may depend subset state variables. possible express
arbitrary reward expectations P (U | S) binary U (Cooper, 1988). define
transition dynamics using NID rules naive model? Assume given set
fully abstract NID rules. compute groundings rules w.r.t. objects
domain get set K different ground NID rules. parents state variable
Si0 successor time-step include action variable respective variable Si
predecessor time-step. parents Si0 determined follows:
rule r literal corresponding Si0 appears outcomes r, variables
Sk corresponding literals preconditions r parents Si0 . typically Si0
manipulated several actions turn modeled several rules, total
number parents Si0 large. problem worsened usage deictic
references NID rules, increase total number K ground rules .
resulting local structure conditional probability function Si0 complex, one
account uniqueness covering rules. complex dependencies
two time-slices make representation unfeasible planning.
15

fiLang & Toussaint

Therefore, exploit structure NID rules model state transition
compact graphical model shown Fig. 3(b) representing joint distribution
P (u0 , s0 , o, r, | a, s)

=

P (u0 | s0 ) P (s0 | o, r, s) P (o | r) P (r | a, ) P ( | s) ,

(14)

explain detail following. before, assume given set
fully abstract NID rules, compute set K different ground NID rules
w.r.t. objects domain. addition S, S0 , A, U U 0 above, use
binary random variable rule model event context holds,
case required literals hold. Let I() indicator function 1
argument evaluates true 0 otherwise. Then,


K
K


^
P ( | s) =
P (i |s(i ) ) =
Sj = sri ,j .
(15)

i=1

i=1

j(i )

V

use express logical conjunction 1 n . function () yields set
indices state variables s, depends. sri denotes configuration
state variables corresponding literals context ri . use integer-valued
variable R ranging K +1 possible values identify rule predicts effects
action. exists, unique covering rule current state-action pair,
i.e., rule r (a) modeling action whose context holds:


^
P (R = r|a, ) = r (a) r = 1
r 0 = 0 .
(16)
r0 (a)\{r}

unique covering rule exists, predict changes indicated special value
R = 0 (assuming execute action, similarly SST UCT do):


^
^
P (R = 0 | a, ) =
r = 1
r 0 = 0 .
(17)
r0 (a)\{r}

r(a)

integer-valued variable represents outcome action predicted
rule. ranges possible values maximum number outcomes
rules have. ensure sound semantics, introduce empty dummy outcomes
zero-probability rules whose number outcomes less . probability
outcome defined corresponding rule:
P (O = | r) = pr,o .
define probability successor state

P (s0 | o, s, r) =
P (s0i | o, si , r) ,

(18)

(19)



one unique state constructed taking changes according
r,o account: outcome specifies value Si0 , value probability
16

fiPlanning Noisy Probabilistic Relational Rules

one. Otherwise, value state variable persists previous time-step.
rules usually change small subset s, persistence often applies. resulting
dependency P (s0i | o, r, si ) variable Si0 time-step + 1 compact. contrast
naive DBN Fig. 3(a), three parents, namely variables outcome,
rule predecessor previous time-step. simplifies specification
conditional probability function 0 significantly enables efficient inference,
see later. probability reward given


^
P (U 0 = 1 | s0 ) =
Sj0 = j .
(20)
j(U 0 )

function (U 0 ) yields set indices state variables s0 , U 0 depends.
configuration variables corresponds planning goal denoted
. Uncertain initial states naturally accounted specifying priors P (s0 ).
renounce specification prior here, however, initial state s0 always given
experiments later enable comparison look-ahead tree based approaches SST
UCT require deterministic initial states (which might also sampled
prior). choice distribution P (a) used sampling actions described
Sec. 5.3.
simplicity ignored derived predicates functions defined
terms predicates functions presentation graphical model. Derived
concepts may increase compactness rules. dependencies among concepts acyclic,
straightforward include derived concepts model intra-state dependencies
corresponding variables. Indeed, use derived predicates experiments.
interested inferring posterior state distributions P (st | a0:t1 ) given sequence previous actions (where omit conditioning initial state simplicity).
Exact inference intractable graphical model. constructing junction tree,
get cliques comprise whole Markov slices (all variables representing state
certain time-step): consider eliminating state variables St+1 . Due moralization,
outcome variable connected state variables St . elimination O,
variables St form clique. Thus, make use approximate inference
techniques. General loopy belief propagation (LBP) unfeasible due deterministic
dependencies small cycles inhibit convergence. also conducted preliminary tests small networks damping factor, without success. interesting
open question whether ways alternate propagating deterministic information running LBP remaining parts network, e.g., whether methods
MC-SAT (Poon & Domingos, 2007) successfully applied decision-making contexts ours. next subsection, propose different approximate inference scheme
using factored frontier (FF). FF algorithm describes forward inference procedure
computes exact marginals next time-step subject factored approximation
previous time-step. Here, advantage exploit structure
involved DBNs come formulas marginals. FF related passing
forward messages. contrast LBP, information propagated backwards. Note
approach condition rewards (as full planning inference) samples
actions, backward reasoning uninformative.
17

fiLang & Toussaint

5.2 Approximate Inference
following, present efficient method approximate inference previously
proposed DBNs exploiting factorization NID rules. focus mathematical
derivations. illustrative example provided Sec. 5.4.
follow idea factored frontier (FF) algorithm (Murphy & Weiss, 2001)
approximate belief product marginals:

P (st | a0:t1 )
P (sti | a0:t1 ) .
(21)


define
(sti ) := P (sti | a0:t1 )
(st ) := P (st | a0:t1 )

N


(22)
(sti )

(23)

i=1

derive FF filter DBN model Fig. 3(b). interested inferring
state distribution time + 1 given action sequence a0:t calculate marginals
state attributes
t+1
(st+1
| a0:t )
) = P (si
X
=
P (st+1
| rt , a0:t1 ) P (rt | a0:t ) .


(24)
(25)

rt

Eq. (25), use rules prediction, weighted respective posteriors P (rt | a0:t ).
reflects fact depending state use different rules model
action. weight P (rt | a0:t ) 0 rules modeling action . remaining
rules model , weights correspond posterior parts
state space according rule used prediction.
compute first term (25)
X
P (st+1
| rt , a0:t1 ) =
P (st+1
| rt , sti ) P (sti | rt , a0:t1 )


sti



X

P (st+1
| rt , sti ) (sti ) .


(26)

sti

Here, sum possible values variable Si previous time-step t. Intuitively, take account potential pasts arrive value st+1
next

, st ) enables us easily predict probabilities
time-step. resulting term P (st+1
|
r


next time-step discussed below. prediction weighted marginal
(sti ) respective previous value. approximation (26) assumes sti conditionally independent rt . true general choice rule prediction
depends current state thus also attribute Si . improve approximation one examine whether sti part context rt : case, infer
state sti knowing rt . However, found approximation sufficient.
18

fiPlanning Noisy Probabilistic Relational Rules

one would expect, calculate successor state distribution P (st+1
| rt , sti )


taking different outcomes r account weighted respective probabilities
P (o | rt ),
X
P (st+1
| rt , sti ) =
P (st+1
| o, rt , sti ) P (o | rt ) .
(27)




shows us update belief Sit+1 predict rule rt . P (st+1
| o, rt , sti )

t+1
deterministic distribution. changes value Si , si set accordingly. Otherwise, value sti persists.
Lets turn computation second term Eq. (25), P (rt | a0:t ), posterior
rules. trick use context variables exploit assumption
rule r models state transition uniquely covers (at , st ), indicated
appropriate assignment . reduced expression
involving marginals (). start
X
P (Rt = r | a0:t ) =
P (Rt = r | , a0:t ) P (t | a0:t )





^

= I(r (at )) P tr = 1,

tr0 = 0 | a0:t1

r0 (at )\{r}




^

= I(r (at )) P (tr = 1 | a0:t1 ) P

tr0 = 0 | tr = 1, a0:t1 .

r0 (at )\{r}

(28)
simplify summation , consider unique assignment
context variables r used prediction: provided models action, indicated
I(r (at )), case context tr holds, contexts tr0
competing rules r0 action hold.
calculate second term (28) summing states
X

X
P (tr = 1 | a0:t1 ) =
P (tr = 1 | st ) (st )
P (tr = 1 | st )
(stj )
(29)
st

=



st

(Sjt = sr,j )

.

j

(30)

j(tr )

approximation (29) FF assumption. (30), sr denotes configuration
state variables according context r like (15). sum variables
context r. variables rs context remain: terms (Sjt = sr,j ) correspond
probabilities respective literals.
third term (28) joint posterior contexts competing rules r0
given rs context already holds. interested situation none
contexts hold. calculate


^

P
tr0 = 0 | tr = 1, a0:t1
P (tr0 = 0 | tr = 1, a0:t1 ) ,
(31)
r0 (at )\{r}

r0 (at )\{r}

19

fiLang & Toussaint

approximating product individual posteriors. latter computed
X
P (tr0 = 0 | tr = 1, a0:t1 ) =
P (tr0 = 0 | st ) P (st | tr = 1, a0:t1 )
(32)



r r0
1.0 Q

1.0 i(t ), (Si = sr0 ,i ) otherwise
,

r0


(33)

i6(r )

if-condition expresses logical contradiction contexts r r0 .
contexts contradict, r0 context surely hold given rs context holds.
Otherwise, know state attributes apppearing contexts r r0
hold condition r = 1. Therefore, examine remaining state
attributes r0 context. Again, approximate posterior FF marginals.
Finally, compute reward probability straightforwardly
X

P (U = 1 | st )P (st | a0:t1 , s0 )
(Sit = ) ,
(34)
P (U = 1 | a0:t1 ) =
st

i(U )

denotes configuration state variables corresponding planning goal
(20). above, summation states simplified FF assumption resulting
product marginals required state attributes.
overall computational costs propagating effects action quadratic
number rules action (for rule calculate probability
none others applies) linear maximum numbers context literals
manipulated state attributes rules.
inference framework requires approximation distribution P (s0 | r,0 , s)
(cf. Eq. (2)) cope noise outcome NID rules. training data used
learn rules, estimate predicates functions change value time follows: let
Sc contain corresponding variables. estimate rule r average number
N r changed state attributes noise outcome applies. Due factored frontier
approach, consider noise effects variable independently. approximate
r
probability Si Sc changes rs noise outcome | SNC | . case change,
changed values Si equal probability.
5.3 Planning
DBN representation Fig. 3(b) together approximate inference method described last subsection enable us derive novel planning algorithm stochastic
relational domains: Probabilistic Relational Action-sampling DBNs planning Algorithm (PRADA) plans sampling action sequences informed way based predicted
beliefs states evaluating action sequences using approximate inference.
precisely, sample sequences actions a0:T 1 length . 0 < ,
infer posteriors states P (st | a0:t1 , s0 ) rewards P (ut | a0:t1 , s0 ) (in sense
filtering state monitoring). Then, calculate value action sequence
discount factor 0 < < 1
Q(s0 , a0:T 1 ) :=


X

P (U = 1 | a0:t1 , s0 ) .

t=0

20

(35)

fiPlanning Noisy Probabilistic Relational Rules

choose first action best sequence = argmaxa0:T 1 Q(a0:T 1 , s0 ),
value exceeds certain threshold (e.g., = 0). Otherwise, continue sampling actionsequences either action found planning given up. quality found
plan controlled total number action-sequence samples traded
time available planning.
aim strategy sample good action sequences high probability.
propose choose equal probability among actions unique covering
rule current state. Thereby, avoid use noisy default rule r
models action effects noise thus poor use planning. action time t,
PRADA samples distribution


^
X

tr0 = 0 | a0:t1 .
(36)
P tr = 1,
Psample
(a)
r(a)

r0 (a)\{r}

sum rules action a: rule add posterior
unique covering rule, i.e. context tr holds, contexts tr0 competing
rules r0 hold. sampling distribution takes current state distribution
account. Thus, probability sample action sequence predicting state sequence
s0 , . . . , sT depends likelihood state sequence given a: likely required outcomes are, likely next actions sampled. Using policy,
PRADA miss actions SST UCT explore, following proposition
states (proof Appendix A).
Proposition 1: set action sequences PRADA samples non-zero probability
super-set ones SST UCT.
experiments, replan action executed without reusing knowledge previous time-steps. simple strategy helps get general impression
PRADAs planning performance complexity. strategies easily conceivable.
instance, one might execute entire sequence without replanning, trading faster
computation times potential loss achieved reward. noisy environments,
might seem better strategy combine reuse previous plans replanning.
instance, one could omit first action previous plan, executed,
examine suitability remaining actions new state. consider
single best action sequence, many planning domains might also beneficial
marginalize sequences first action. instance, action a1
might lead number reasonable sequences, none best, another
action a2 first one good sequence, also many bad ones case one
might favor a1 .
5.4 Illustrative Example
Let us consider small planning problem Table 2 illustrate reasoning procedure
PRADA. domain noisy cubeworld represented predicates table(X), cube(X),
on(X, ), inhand(X) clear(X) Y.on(Y, X) robot perform two types
actions: may either lift cube X means action grab(X) put cube
21

fiLang & Toussaint

held hand top another object X using puton(X). start state s0 shown 2(a)
contains three cubes a, b c stacked pile table t. goal shown 2(b)
get middle cube b on-top top cube a. world model provides three abstract
NID rules predict action effects, shown Table 2(c). first rule uncertain
outcomes: models grab object another object. contrast, grabbing
clear object (Rule 2) putting object somewhere (Rule 3) always leads
successor state.
First, PRADA constructs DBN represent planning problem. purpose,
computes grounded rules respect objects = {a, b, c, t} shown 2(d).
potential grounded rules ignored: one deduce abstract rules
predicates changeable. combination specifications s0 , prunes
grounded rules. instance, know s0 table. Thus, ground rule
action argument X = needs constructed rules require cube(X).
Based DBN, PRADA samples action-sequences evaluates expected
rewards. following, investigate procedure sampling action-sequence
(grab(b), puton(a)). Table 2(e) presents inferred values DBN variables
auxiliary quantities. marginals (Eq. (22)) state variables = 0
set deterministically according s0 . calculate posteriors context variables
P ( | a0:t1 ) according Eq. (30). example, = 0 one rule
probability 1.0 actions grab(a), grab(b) grab(c). contrast,
rules non-zero probability various puton() actions. help Eq. (33),
calculate probability rule r unique covering rule respective
action (listed Unique rule; note condition fixed action thus
far): case context r r holds, contexts r0 competing rules
r0 action hold. = 0, posterior r alone.
resulting probabilities used calculate sampling distribution Eq. (36): first,
compute probability action unique covering rule simple
sum probabilities previous step (listed Action coverage table); then,
normalize values get sampling distribution Psample (). = 0, results
sampling distribution uniform three actions unique rules. Assume
sample a0 = grab(b) (grabbing blue cube b). Variable R specifies ground rules
use predicting state marginals next time-step. infer posterior
according Eq. (28). Here, P (R0 = (1, b/act) | a0 ) = 1.0.
Things get interesting = 1. Here, observe effects factored
frontier. instance, consider calculating posterior context r ground rule
r = (1, b/att) (grabbing blue cube b yellow a) using Eq. (30),
P ((1,b/att) | a0 ) (on(a, b)) (on(b, t)) (cube(a)) (cube(b)) (table(t))
= 0.2 0.2 1.0 1.0 1.0 = 0.04.
contrast, exact value P ((1,b/att) | a0 ) = 0.2, according third outcome
abstract Rule 1 used predict a0 . imprecision due ignoring correlations: FF
regards marginals on(a, b) on(b, t) independent, fact fully
correlated.
= 1, action grab(a) three ground rules non-zero context probabilities
(grabbing either b, c t). due three different outcomes abstract
22

fiPlanning Noisy Probabilistic Relational Rules

Table 2: Example PRADAs factored frontier inference
(a) Start state
s0 = {on(a, b), on(b, c), on(c, t),
cube(a), cube(b), cube(c), table(t)}

(b) Goal
= {on(b, a)}

(c) Abstract NID rules example situations
Rule 1:
grab(X) : on(Y, X), on(X, Z), cube(X), cube(Y ), table(T )

0.5 : inhand(X), on(Y, Z), on(Y, X), on(X, Z)
0.3 : inhand(X), on(Y, ), on(Y, X), on(X, Z)


0.2 : on(X, ), on(X, Z)

Rule 2:
grab(X) : cube(X), clear(X), on(X, )

1.0 : inhand(X), on(X, )


(e) Inferred posteriors PRADAs
FF
inference

action-sequence
(grab(b), puton(a))
t=0

t=1

t=2

State marginals
on(a, b)
on(a, c)
on(a, t)
on(b, a)
on(b, c)
on(b, t)
on(c, t)
inhand(b)
clear(a)
clear(b)
clear(c)
Goal U

1.0
0.0
0.0
0.0
1.0
0.0
1.0
0.0
1.0
0.0
0.0
0.0

0.2
0.5
0.3
0.0
0.0
0.2
1.0
0.8
1.0
0.8
0.5
0.0

0.2
0.5
0.3
0.8
0.0
0.2
1.0
0.16
0.2
0.8
0.5
0.8

P ( | a0:t1 )
(1,b/act)
(1,b/att)
(1,c/btt)
(2,a/b)
(2,a/c)
(2,a/t)
(2,b/t)
(2,c/t)
(3,a/b)
(3,c/b)
(3,t/b)

1.0
0.0
1.0
1.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0

0.0
0.04
0.5
0.2
0.5
0.3
0.16
0.5
0.8
0.8
0.8

Unique rule
(1, b/act)
1.0
0.0
(1, b/att)
0.0 0.0336
(1, c/att)
0.0
0.25
(1, c/btt)
1.0
0.0
(2, a/b)
1.0
0.07
(2, a/c)
0.0
0.28
(2, a/t)
0.0
0.12
(2, b/t)
0.0 0.154
(2, c/t)
0.0
0.25
(3, a/b)
0.0
0.8
(3, c/b)
0.0
0.8
(3, t/b)
0.0
0.8
Action coverage
grab(a)
1.0
0.47
grab(b)
1.0 0.187
grab(c)
1.0
0.5
puton(a)
0.0
0.8
puton(c)
0.0
0.8
puton(t)
0.0
0.8
Sample distribution
Psample (grab(a))
0.33 0.132
Psample (grab(b))
0.33 0.0526
Psample (grab(c))
0.33 0.141
Psample (puton(a))
0.0 0.225
Psample (puton(c))
0.0 0.225
Psample (puton(t))
0.0 0.225
P (Rt = rt | a0:t )
Rt = (1, b/act)
1.0
0.0
Rt = (3, a/b)
0.0
0.8
Rt = 0
0.0
0.2

Rule 3:
puton(X) : inhand(Y ), cube(Y )

1.0 : on(Y, X), inhand(X)


(d) Grounded NID rules
Grounded Rule Action
Substitution
(1, a/bbt)
grab(a) {X a, b, Z b, t}
(1, a/bct)
grab(a) {X a, b, Z c, t}
...
(1, c/bbt)
grab(c) {X c, b, Z b, t}
(2, a/b)
grab(a)
{X a, b}
(2, a/c)
grab(a)
{X a, c}
(2, a/t)
grab(a)
{X a, t}
...
(2, c/t)
grab(c)
{X c, t}
(3, a/b)
puton(a)
{X a, b}
(3, a/c)
puton(a)
{X a, c}
...
(3, t/c)
puton(t)
{X a, c}

23

fiLang & Toussaint

Rule 1. example, calculate probability rule (2, a/c) (grabbing c)
unique covering rule grab(a) = 1
P ((2,a/c) ,(2,a/b) , (2,a/t) | a0 )
P ((2,a/c) | a0 ) (1. P ((2,a/b) | a0 )) (1. P ((2,a/t) | a0 ))
= 0.5 (1. 0.2) (1. 0.3) = 0.28 .
calculations, determine sampling distribution = 1. Assume
sample action puton(a). results rule (3/a, b) (putting b a) used
prediction 0.8 probability since probability unique covering rule
action puton(a). remaining mass 0.2 posterior assigned parts
state space unique covering rule available puton(a). case, use
default rule R = 0 (corresponding performing action) probability
0.2 values state variables persist.
Finally, let us infer marginals = 2 using Eq. (25). example, calculate
(inhand(b)t=2 ). Let i(b) brief inhand(b). sum ground rules rt=1 taking
potential values i(b)t=1 i(b)t=1 previous time-step = 1 account,
X
(i(b)t=2 )
P (rt=1 | a0:1 ) ( P (i(b)t=2 | rt=1 , i(b)t=1 ) (i(b)t=1 )
rt=1

+ P (i(b)t=2 | rt=1 , i(b)t=1 ) (i(b)t=1 ) )
= 0.8 (0.0 0.2 + 0.0 0.8) + 0.2 (0.0 0.2 + 1.0 0.8) = 0.16 .
discussed above, ground rule (3/a, b) default rule play role
prediction. effect, belief b inhand decreases 0.8 0.16 tried
put b a, expected. Similarly, calculate posterior on(b, a) 0.8.
also expected probability reach goal performing actions grab(b)
puton(a). (Here, PRADAs inferred value coincides true posterior.)
comparison, probability reach goal 1.0 performing actions
grab(a), puton(t), grab(b) puton(a), i.e., clear b grab it. plan
safer, i.e., higher probability, takes actions.
5.5 Comparison Planning Approaches
prominent difference presented planning approaches way
account stochasticity action effects. one hand, SST UCT repeatedly take samples successor state distributions estimate value action
building look-ahead trees. hand, PRADA maintains beliefs states
propagates indetermistic action effects forward. precisely, PRADA SST follow
opposite approaches: PRADA samples actions calculates state transitions approximately means probabilistic inference, SST considers actions (and thus exact
action search) samples state transitions. price considering actions
SSTs overwhelmingly large computational cost. UCT remedies issue samples action sequences thus state transitions selectively: uses previously sampled episodes
build upper confidence bounds estimates action values specific states,
used adapt policy next episode. straightforward translate
24

fiPlanning Noisy Probabilistic Relational Rules

adaptive policy PRADA since PRADA works beliefs states instead states
directly. Therefore, chose simple policy PRADA sample randomly
actions unique covering rule state (in form sampling distribution
account beliefs states).
PRADA returns whole plan transform world state one goal
fulfilled probability exceeding given threshold , spirit conformant planning probabilistic planning observability (Kushmerick, Hanks, & Weld, 1995).
Due outcome-sampling, SST UCT cannot return plan straightforward way. Instead, provide policy many successor states based estimates
action-values look-ahead tree. estimates states deeper tree
less reliable built less episodes. action executed
new state observed, estimates reused. Thus far, PRADA take
knowledge gained previous action-sequence samples account adapt policy.
elegant way achieve better exploit goal knowledge might use backpropagation
DBNs plan completely inference (Toussaint & Storkey, 2006).
beyond scope paper, clear principled way
large state action spaces relational domains. Alternatively, PRADA could give high
weight second action previous best plan. Sec. 5.6, show another
simple way make use previous episodes find better plans.
PRADA afford simple action-sampling strategy evaluates large numbers
action-sequences efficiently grow look-ahead trees account
indeterministic effects. points important difference: three algorithms faced
search spaces action sequences exponential horizon. calculate
value given action sequence, however, SST UCT still need exponential time due
outcome sampling. contrast, PRADA propagates state transitions forward
thus linear horizon.
Like approximate planning algorithms, neither SST, UCT PRADA expected perform ideally situations. SST UCT sample action outcomes hence
face problems important outcomes small probability. instance, consider
agent wants escape room two locked doors. hits first door
made wood chance 0.05 break escape. second door made
iron chance 0.001 break. SST UCT may take long time
detect 50 times better repeatedly hit wooden door. contrast, PRADA
recognizes immediately reasoned actions takes
outcomes account. hand, PRADAs approximate inference procedure correlations among state variables get lost SST UCT preserve
sample complete successor states. impair PRADAs planning performance
situations correlations crucial. Consider following simple domain two
state attributes b. agent choose two actions modeled rules

action1 :
action2 :






0.5 : a, b
,
0.5 : a, b



0.5 : a, b
0.5 : b,




25

.

fiLang & Toussaint

goal make attributes either true false, i.e., = (a b) (a b).
actions, resulting marginals (a) = 0.5, (a) = 0.5, (b) = 0.5
(b) = 0.5. Due factored frontier, PRADA cannot distinguish actions
although action1 achieve goal, action2 not.
PRADAs estimated probabilities states rewards may differ significantly
true values. harm performance many domains experiments
indicate (Sec. 6). suppose reason PRADAs estimated probabilities imprecise, enable correct ranking action sequences planning,
interested choosing best action instead calculating correctly value.
difference proposed algorithms way handle noise
outcome rules: PRADA assigns small probability successor states spirit
noise outcome. contrast, SST UCT make sense sample
distribution, single successor state extremely low probability
inadequate estimate state action values. Hence, use described workaround
assume stay state, discounting obtained rewards.
straightforward PRADA deal uncertain initial states. Uncertainty
initial states common complex environments may instance caused partial
observability noisy sensors. uncertainty natural representation belief
state PRADA works on. contrast, SST UCT cannot account uncertain initial
states directly, would sample prior distribution.
5.6 Extension: Adaptive PRADA
present simple extension PRADA increase planning accuracy.
exploit fact PRADA evaluates complete sequences actions contrast SST
UCT actions taken > 0 depend sampled outcomes. Adaptive
PRADA (A-PRADA) examines best action sequence found PRADA. PRADA
chooses first action sequence without reasoning, A-PRADA inspects
single action sequence decides simulation whether deleted.
resulting shortened sequence may lead increased expected reward. case
actions significant effects achieving goal decrease success
probability. actions omitted, states high reward reached earlier
rewards discounted less. instance, consider goal grab blue ball:
action sequence grabs red cube, puts onto table grabs blue
ball improved omitting first two actions unrelated goal.
precisely, A-PRADA takes PRADAs action sequence aP highest value
investigates iteratively action whether deleted. action
deleted plan resulting plan higher reward likelihood. idea
formalized Algorithm 1. crucial calculation algorithm compute values
Q(s0 , a0:T 1 ) defined Eq. (28) restated convenience:
0

Q(s ,

0:T 1

)=


X

P (U = 1 | a0:t1 , s0 ) .

t=1

PRADAs approximate inference procedure particularly suitable calculating required P (U = 1 | a0:t1 , s0 ). performs calculation time linear length
26

fiPlanning Noisy Probabilistic Relational Rules

Algorithm 1 Adaptive PRADA (A-PRADA)
Input: PRADAs plan aP
Output: A-PRADAs plan aA
1: aA aP
2: = 0 = 1
3:
true
4:
Let plan length .
5:
a0:t1 a0:t1
B Omit

t+1:T 1
t:T 2
6:

aA
7:
1 othing
8:
Q(s0 , a) > Q(s0 , aA )
9:
aA
10:
else
11:
break
12:
end
13:
end
14: end
15: return aA

action sequence, SST UCT would require time exponential
outcome sampling.

6. Evaluation
implemented presented planning algorithms learning algorithm
NID rules C++. code available www.user.tu-berlin.de/lang/prada/.
evaluate approaches two different scenarios. first intrinsically noisy complex simulated environment learn NID rules experience use
plan. Second, apply algorithms benchmarks Uncertainty Part
International Planning Competition 2008.
6.1 Simulated Robot Manipulation Environment
perform experiments simulated complex robot manipulation environment
robot manipulates objects scattered table (Fig. 4). report results three
series experiments different tasks increasing difficulty, first describe domain
detail. use 3D rigid-body dynamics simulator (ODE) enables realistic behavior objects. simulator available www.user.tu-berlin.de/lang/DWSim/.
Objects cubes balls different sizes colors. robot grab objects
put top objects table. actions robot affected
noise. domain, towers objects straight-lined; easier put object
top big cube top small cube difficult put something
top ball; piles objects may topple over; objects may fall table case
become reach robot.
represent domain predicates on(X, ), inhand(X), upright(X), out(X) (if
object fallen table), function size(X) unary typing predicates cube(X),
ball(X), table(X). predicates obtained querying state simulator
27

fiLang & Toussaint

Figure 4: simulated robot plays cubes balls different sizes scattered
table. Objects fallen table cannot manipulated anymore.

translating according simple hand-made guidelines, thereby sidestepping difficult
problem converting agents observations internal representation. instance,
on(a, b) holds b exert friction forces z-coordinate greater
one b, x- y-coordinates similar. Besides primitive
concepts, also use derived predicate clear(X) Y.on(Y, X). found
predicate enable compact accurate rules, reflected values
objective function rule learning algorithm given Eq. (3).
define three different types actions. actions correspond motor primitives
whose effects want learn exploit. grab(X) action triggers robot open
hand, move hand next X, let grab X raise robot arm again.
execution action influenced factors. example, different
object held hand before, fall either table third
object ; objects top X, likely fall down.
puton(X) action centers robots hand certain distance X, opens
raises hand again. instance, object Z X, object
potentially inhand may end Z Z might fall X. othing() action triggers
movement robots arm. robot might choose action thinks
action could harmful respect expected reward. emphasize
actions always execute, regardless state world. Also, actions
rather unintuitive humans trying grab table put object top
carried out. robot learn effects motor primitives.
Due intrinsic noise complexity, simulated robot manipulation scenario
challenging domain learning compact world models well planning.
objects f different object sizes, action space contains 2o+1 actions
2
state space huge f 2o +6o different states (not excluding states one would classify
impossible given intuition real world physics).
use rule learning algorithm Pasula et al. (2007) parameter
settings learn three different sets fully abstract NID rules. rule-set learned
28

fiPlanning Noisy Probabilistic Relational Rules

independent training sets 500 experience triples (s, a, s0 ) specify world
changed state successor state s0 action executed, assuming full
observability. Training data learn rules generated world six cubes four
balls two different sizes performing random actions slight bias build high
piles. resulting rule-sets contain 9, 10 10 rules respectively. rule-sets provide
approximate partial models true world dynamics. generalize situations
experiences, may account situations completely different
agent seen before. enforce compactness avoid overfitting, rules
regularized; hence, learning algorithm may sometimes favor model rarely experienced
state transitions low-probability outcomes general rules, thereby trading
accuracy compactness. combination general noisiness world
causes need carefully account probabilities world reasoning
rules.
perform three series experiments planning tasks increasing difficulty.
series, test planners different worlds varying numbers cubes
balls. Thus, transfer knowledge gained training world different, similar
worlds using abstract NID rules. object number, create five different worlds.
Per rule-set world, perform three independent runs different random seeds.
evaluate different planning approaches, compute mean performances
planning times fixed (but randomly generated) set 45 trials (3 learned rule-sets,
5 worlds, 3 random seeds).
choose parameters planning algorithms follows. SST, report results different branching factors b, far resulting runtimes allow. Similarly, UCT
(A-)PRADA parameter balances planning time quality
found actions. UCT, number episodes, (A-)PRADA
number sampled action-sequences. Depending experiment, set
heuristically tradeoff planning time quality reasonable.
particular, fair comparison pay attention UCT, PRADA A-PRADA get
planning times, reported otherwise. Furthermore, UCT set
bias parameter c 1.0 found heuristically perform best. planners
experiments, set discounting factor future rewards = 0.95. crucial
parameter planning horizon d, heavily influences planning time. course,
cannot known a-priori. Therefore, reported otherwise, deliberately set larger
required UCT (A-)PRADA suggest algorithms also effective
estimated. Indeed, found experiments long
small, exact choice significant effects UCTs (A-)PRADAs
planning quality unlike effects planning times. contrast, set horizon
SST always small possible, case planning times still large.
planning algorithm find suitable action given situation, restart
planning procedure: SST builds new tree, UCT runs episodes (A-)PRADA
takes new action-sequence samples. given situation 10 planning runs suitable
action still found, trial fails.
Furthermore, use FF-Replan (Yoon et al., 2007) baseline. discuss
detail related work Sec. 2, FF-Replan determinizes planning problem,
thereby ignoring outcome probabilities. FF-Replan shown impressive results
29

fiLang & Toussaint

domains probabilistic planning competitions. domains carefully designed
humans: action dynamics definitions complete, accurate consistent
used true world dynamics according experiments contrast learned
NID rules use estimate approximate partial models robot manipulation
domain. able use derived predicate clear(X) FF-Replan implementation
experiments, included appropriate literals predicate hand
outcomes rules SST, UCT (A-)PRADA implementations infer
values automatically definition clear(X). report results FF-Replan
(almost original) learned rules using all-outcomes determinization scheme, denoted
FF-Replan-All below. (Using single-outcome schemes always led worse performance.)
rules general (putting restrictions arguments
deictic references); case, actions appear applicable given state make
sense intuitive human perspective hurts FF-Replan much
methods, resulting large planning times FF-Replan. instance, rule may model
toppling small tower including object X trying put object top
tower: one outcome might specify end X. possible
cube, course, learning algorithm may choose omit typing predicate
cube(X) due regularization, prefers compact rules none experiences might
require additional predicate. Therefore, created modified rule-sets hand
introduced typing predicates appropriate make contexts distinct. Below,
denote results modified rule-sets FF-Replan-All* FF-Replan-Single*,
using all-outcomes single most-probable outcome determinization schemes.
6.1.1 High Towers
first series experiments, investigate building high towers planning
task work Pasula et al. (2007). precisely, reward state defined
average height objects. constitutes easy planning problem many different
actions may increase reward (object identities matter) small planning
horizon sufficient. set SST horizon = 4 (Pasula et al. choice) different
branching factors b UCT (A-)PRADA horizon = 6. experiments, initial
states contain already stacked objects, reward performing actions
0. Table 3 Fig. 5 present results. SST competitive. branching factor
b > 1, slower UCT (A-)PRADA least order magnitude.
b = 1, performance poor. series experiments, designed worlds 10
objects contain many big cubes. explains relatively good performance SST
worlds, number good plans large. mentioned above, control UCT,
PRADA A-PRADA times available planning. three
approaches perform far better SST almost experiments. difference
UCT, PRADA A-PRADA never significant.
series experiments indicates planning approaches using full-grown lookahead trees like SST inappropriate even easy planning problems. contrast, approaches exploit look-ahead trees clever way UCT seem best
choice easy tasks require small planning horizon solved many
alternative good plans. performance planning approaches using approximate
30

fiPlanning Noisy Probabilistic Relational Rules

Table 3: High towers problem. Reward denotes discounted total reward different
numbers objects (cubes/balls table). reward performing actions
0. data points averages 45 trials created 3 learned rule-sets,
5 worlds 3 random seeds. Standard deviations mean estimators
shown. FF-Replan-All* FF-Replan-Single* use hand-made modifications
original learned rule-sets. Fig. 5 visualizes results.
Objects

Planner
FF-Replan-All
FF-Replan-All*
FF-Replan-Single*

6+1

SST (b=1)
SST (b=2)
SST (b=3)
UCT
PRADA
A-PRADA

SST (b=1)
SST (b=2)
SST (b=3)
UCT
PRADA
A-PRADA

SST (b=1)
SST (b=2)
SST (b=3)
UCT
PRADA
A-PRADA

6.65 1.01
6.29 0.80
4.48 0.94

41.07 9.63
7.54 4.09
4.61 2.75

1.19
1.01
0.94
0.99
1.25
1.27

9.03 0.80
121.40 11.12
595.43 55.95
7.45 0.19
6.01 0.07
6.36 0.07

5.10 1.01
3.08 0.87
2.82 0.87

76.86 20.98
28.65 16.81
1.72 0.27








1.07
1.21
0.87
1.07
1.21
1.47

23.57 3.48
335.5 52.4
1613.3 249.2
15.54 0.40
15.24 0.27
16.30 0.27

6.97 1.21
7.36 1.07
5.76 1.21

121.99 27.43
33.45 12.80
4.14 1.08








119.26 10.59
1748.7 170.2
8424 851
31.71 5.83
31.58 1.14
35.22 0.40

9.62
12.36
11.09
17.11
16.10
16.29

FF-Replan-All
FF-Replan-All*
FF-Replan-Single*
10+1

Trial time (s)

11.68
12.90
12.80
16.01
15.54
16.12

FF-Replan-All
FF-Replan-All*
FF-Replan-Single*
8+1

Reward

15.12
14.48
16.48
17.71
16.21
16.78

31








1.34
1.20
1.19
1.08
1.07
1.14

fiLang & Toussaint

FF-Replan-All
FF-Replan-All*
FF-Replan-Single*
SST b=1
SST b=2
SST b=3
UCT
PRADA
A-PRADA

15
10
5

1000

Trial time (s)

Discounted total reward

10000

100
10
1

6

8
Objects

10

6

(a) Reward

8
Objects

10

(b) Time

Figure 5: High towers problem Visualization results presented Table 3. reward
performing actions 0. data points averages 45 trials created
3 learned rule-sets, 5 worlds 3 random seeds. Error bars standard
deviations mean estimators shown. Please note log-scale (b).

inference, PRADA A-PRADA, however, comes close one UCT, showing also
suitability scenarios.
FF-Replan focuses exploiting conjunctive goal structures cannot deal quantified goals. grounded reward structure task consists disjunction
different tower combinations, FF-Replan pick arbitrary tower combination
goal. Therefore, apply FF-Replan sample tower combinations according rewards achieve (i.e., situations high towers probable) exclude
combinations balls bottom towers prohibited reward
structure. Yoon et al. note, obvious pitfall [goal formula sampling] approach
groundings goal reachable much expensive reach
initial state. FF-Replan cannot find plan, execute action,
sample new ground goal formula next time-step, preserving already achieved
tower structures.
FF-Replan performs significantly worse previous planning approaches.
major reason FF-Replan often comes plans exploiting low-probability
outcomes rules contrast SST, UCT (A-)PRADA reason
probabilities. illustrate this, consider example rule Fig. 1 models putting
ball top cube. two explicit outcomes: ball usually ends
cube; sometimes, however, falls table. FF-Replan misuse rule tricky
way put ball table ignoring often fail. results FFReplan-Single* show, taking probable outcomes account remedy
problem: often two three outcomes similar probabilities
choice seems unjustified; sometimes, intuitively expected outcome split
different outcomes low probabilities, however vary features irrelevant
planning problem (such upright()).
32

fiPlanning Noisy Probabilistic Relational Rules

Table 4: Desktop clearance problem. Reward denotes discounted total reward different numbers objects (cubes/balls table). reward performing
actions 0. data points averages 45 trials created 3 learned rulesets, 5 worlds 3 random seeds. Standard deviations mean estimators
shown. FF-Replan-All* FF-Replan-Single* use hand-made modifications
original learned rule-sets. Fig. 6 visualizes results.
Obj.

Planner
FF-Replan-All
FF-Replan-All*
FF-Replan-Single*

6+1

SST (b=1)
UCT
PRADA
A-PRADA

SST (b=1)
UCT
PRADA
A-PRADA

SST (b=1)
UCT
PRADA
A-PRADA

3.81 0.67
5.86 0.87
6.53 1.07

19.1 6.5
1.1 0.7
0.7 0.8

0.75
0.86
0.86
0.80

1382.6 80.4
52.2 0.7
40.9 0.7
42.3 0.7

5.93 1.00
6.21 1.05
6.02 0.94

29.8 8.7
3.5 0.6
0.8 0.7






2.01
1.08
1.54
1.57

8157 978
151.4 2.0
154.5 1.9
157.4 2.0

3.30 0.74
3.53 0.87
3.91 0.86

60.9 12.1
20.7 5.4
5.2 1.3


10.13 0.80
12.81 1.14
13.91 1.12

> 8h
415.7 7.4
385.3 4.7
394.5 4.0

8.43
10.29
14.63
14.87

FF-Replan-All
FF-Replan-All*
FF-Replan-Single*
10+1

Trial time (s)

5.35
9.60
10.94
12.79

FF-Replan-All
FF-Replan-All*
FF-Replan-Single*
8+1

Reward






6.1.2 Desktop Clearance
task second series experiments clear desktop. Objects lying
splattered table beginning. object cleared part tower
containing objects class. object class simply defined terms
color additionally provided state representation robot. reward
robot defined number cleared objects. experiments, classes contain
2-4 objects 1 ball (in order enable successful piling). starting situations contain piles, objects different classes. Thus, reward
performing actions 0. Desktop clearance difficult building high towers,
number good plans yielding high rewards significantly reduced.
set planning horizon = 6 optimal SST required clear
class 4 objects, namely grabing putting three objects. above, contrast set
= 10 UCT (A-)PRADA show deal overestimation
usually unknown optimal horizon d. Table 4 Fig. 6 present results. horizon
= 6 overburdens SST seen large planning times. Even b = 1, SST
takes almost 40 minutes average worlds 6 objects, 2 hours worlds
8 objects. Therefore, try SST greater b. contrast, planning times
33

fi16

10000

14

FF-Replan-All
FF-Replan-All*
FF-Replan-Single*
SST b=1
UCT
PRADA
A-PRADA

12
10
8
6
4
2
6

8
Objects

1000
Trial time (s)

Discounted total reward

Lang & Toussaint

100
10
1
6

10

(a) Reward

8
Objects

10

(b) Time

Figure 6: Desktop clearance problem. Visualization results presented Table 4.
reward performing actions 0. data points averages 45 trials
created 3 learned rule-sets, 5 worlds 3 random seeds. Error bars
standard deviations mean estimators shown. Note log-scale (b).

UCT, PRADA A-PRADA, controlled enable
reasonable performance, two orders magnitude smaller, although overestimating
planning horizon: trial take average 45s worlds 6 objects, 2 12
minutes worlds 8 objects 6-7 minutes worlds 10 objects. Nonetheless, UCT,
PRADA A-PRADA perform significantly better SST. worlds, PRADA
A-PRADA turn outperform UCT, particular worlds many objects. A-PRADA
finds best plans among planners. planners gain reward worlds 8 objects
comparison worlds 6 objects, number objects cleared increases
well number classes thus good plans. worlds 10 objects contain
numbers object classes like worlds 8 objects, objects,
making planning difficult.
Overall, findings Desktop clearance experiments indicate SST
inappropriate, UCT achieves good performance planning scenarios require medium
planning horizons several, many alternative plans. Approaches
using approximate inference like PRADA A-PRADA, however, seem appropriate scenarios intermediate difficulty.
Furthermore, results indicate FF-Replan inadequate clearance task.
sample target classes randomly provide goal structure FF-Replan; tower
structure within target class turn also randomly chosen. bad performance
FF-Replan due reasons described previous experiments; particular
plans FF-Replan often rely low-probability outcomes.
34

fiPlanning Noisy Probabilistic Relational Rules

Table 5: Reverse tower problem. trial times numbers executed actions given
successful trials different numbers objects (cubes table).
data points averages 45 trials created 3 learned rule-sets, 5 worlds
3 random seeds. Standard deviations mean estimators shown. FFReplan-All* FF-Replan-Single* use hand-made modifications original
learned rule-sets.
Objects

5+1

6+1

7+1

Planner

Success rate

Trial time (s)

Executed actions

FF-Replan-All
FF-Replan-All*
FF-Replan-Single*

0.02
1.00
0.67

7.1 0.0
26.7 2.7
7.0 0.9

12.0 0.10
13.1 0.9
13.6 1.1

SST (b=1)
SST (b=2)
UCT
PRADA
A-PRADA

0.00
0.00
0.38
0.71
0.82

> 1 day
2504.9 491.1
27.0 1.8
25.4 0.8

19.5 4.0
13.2 0.7
10.9 0.8

FF-Replan-All
FF-Replan-All*
FF-Replan-Single*

0.00
1.00
0.64

589.2 73.7
52.7 5.3

12.0 0.8
17.3 2.1

UCT
PRADA
A-PRADA

0.00
0.47
0.56

>4 h
66.4 3.9
77.5 8.3

13.6 0.9
14.4 2.5

FF-Replan-All
FF-Replan-All*
FF-Replan-Single*

0.00
0.42
0.56

2234.2 81.1
687.4 86.4

15.1 1.3
17.5 2.0

PRADA
A-PRADA

0.24
0.23

871.3 126.6
783.7 132.6

18.2 1.2
15.1 1.8

6.1.3 Reverse Tower
explore limits UCT, PRADA A-PRADA, conducted final series
experiments task reverse towers C cubes requires least 2C
actions (each cube needs grabbed put somewhere least once). Apart
long planning horizon, difficult due noise simulated world: towers
become unstable topple cubes falling table. decrease noise
slightly obtain reliable results, forbid robot grab objects clear
(i.e., objects). set limit 50 executed actions trial. thereafter
reversed tower still built, trial fails. trial also fails one required
objects falls table.
Table 5 presents results. cannot get SST optimal planning horizon = 10
solve problem even five cubes. Although space possible actions reduced
due mentioned restriction, SST enormous runtimes. b = 1, SST find
suitable actions (no leaves goal state) several starting situations increased
planning horizon leads high probability sampling least one unfavorable outcome
required action. b 2, single tree traversal SST takes day.
found UCT also require large planning times order achieve reasonable success
rate. Therefore, set planning horizons optimal UCT. worlds 5 cubes, UCT
optimal = 10 success rate 40% taking average 40
35

fiLang & Toussaint

minutes case success. 6 cubes, however, UCT optimal = 12 never succeeds
even planning times exceed 4 hours. contrast, afford overestimating
horizon = 20 PRADA A-PRADA. worlds 5 cubes, PRADA A-PRADA
achieve success rates 71% 82% respectively less half minute. A-PRADAs
average number executed actions case success almost optimal. worlds 6
cubes, success rates PRADA A-PRADA still 50%, taking bit
minute average case success. trials fail, often due
cubes falling table cannot find appropriate actions. Cubes
falling table also main reason success rates PRADA A-PRADA
drop 23% 24% respectively worlds 7 cubes towers become rather unstable.
Planning times successful trials, however, also increase 13 minutes indicating
limitations planning approaches. Nonetheless, mean number executed
actions successful trials still almost optimal A-PRADA.
Overall, Reverse tower experiments indicate planning approaches using lookahead trees fail tasks require long planning horizons achieved
plans. Given huge action state spaces relational domains, chances
UCT simulates episode exactly required actions successor states
small. Planning approaches using approximate inference like PRADA A-PRADA
crucial advantage stochasticity actions affect runtime
exponentially planning horizon. course, search space action-sequences still
exponential planning horizon problems requiring long horizons hard
solve also them. experiments show using simple, though principled
extension A-PRADA, gain significant performance improvements.
results also show FF-Replan fails provide good plans using original
learned rule-sets. surprising characteristics Reverse tower task seem
favor FF-Replan comparison methods: single conjunctive goal
structure number good plans small plans require long horizons.
results FF-Replan-All* FF-Replan-Single* indicate, FF-Replan achieve
good performance adapted rule-sets modified hand restrict
number possible actions state. constitutes proof concept
FF-Replan, shows difficulty applying FF-Replan learned rule-sets.

6.1.4 Summary
results demonstrate successful planning learned world models (here
form rules) may require explicitly account quantification predictive uncertainty. concretely, methods applying look-ahead trees (UCT) approximate
inference ((A-)PRADA) outperform FF-Replan different tasks varying difficulty. Furthermore, (A-)PRADA solve planning tasks long horizons, UCT fails.
one post-processes learned rules hand clarify application contexts
planning problem uses conjunctive goal structure requires long plans,
FF-Replan performs better UCT (A-)PRADA.
36

fiPlanning Noisy Probabilistic Relational Rules

6.2 IPPC 2008 Benchmarks
second part evaluation, apply proposed approaches benchmarks
latest international probabilistic planning competition, Uncertainty Part
International Planning Competition 2008 (IPPC, 2008). involved domains differ
many characteristics, number actions, required planning horizons
reward structures. competition results show, planning algorithm performs
best everywhere. Thus, benchmarks give idea types problems SST,
UCT (A-)PRADA may useful. convert PPDDL domain specifications
NID rules along lines described Sec. B.1. resulting rule-sets used run
implementations SST, UCT (A-)PRADA benchmark problems.
seven benchmark domains consists 15 problem instances. instance
specifies goal starting state. Instances vary problem size, also
reward structures (including action costs), direct comparison always
possible. competition, instance considered independently: planners
given restricted amount time (10 minutes problems 1-5 domain 40
minutes others) cover many repetitions problem instance
possible maximum 100 trials. Trials differed random seeds resulting
potentially different state transitions. planners evaluated respect
number trials ending goal state collected reward averaged trials.
Eight planners entered competition, including FF-Replan official participant. discussed related work Sec. 2. results,
voluminous presented here, refer reader website competition. Below, provide qualitative comparison methods results
planners. attempt direct quantitative comparison several reasons. First,
different hardware prevents timing comparisons. Second, competition participants
frequently able successfully cover trials single instances domain.
difficult tell reasons results tables: planner might
overburdened problem, might faced temporary technical problems
client-server architecture framework competition could cope certain
PPDDL constructs could rewritten simpler format.
Third importantly, optimized implementations reuse previous planning efforts. Instead, fully replan single action (within trial
across trials). competition evaluation scheme puts replanners disadvantage (in
particular replan single action). Instead replanning, good strategy
competition spend planning time starting first trial reuse
resulting insights (such conditional plans value functions) subsequent trials
minimum additional planning. Indeed, strategy often adopted
many trial time results indicate. acknowledge fair procedure evaluate
planners compute policies large parts state-space acting. feel,
however, counter idea approaches: UCT (A-)PRADA
meant flexible planning varying goals different situations. Thus,
interested average time compute good actions successfully solve problem
instance prior knowledge available.
37

fiLang & Toussaint

Table 6: Benchmarks IPPC 2008. first column table specifies problem
instance. Suc. success rate. trial time number executed
actions given successful trials. applicable, reward
trials shown. results achieved full replanning within trial
across trials.
(a) Search Rescue
Planner

Suc. Trial Time (s)

Actions

(c) Blocksworld

Reward

SST
UCT
01
PRADA
A-PRADA

100
54
100
100

37.90.1
1.40.1
1.10.1
1.10.1

SST
UCT
PRADA
A-PRADA

100
56
100
100

220.20.1
4.10.3
1.60.1
1.60.1

9.80.2
12.20.6
12.90.7
12.80.4

SST
UCT
PRADA
A-PRADA

71
57
99
99

955.50.5
12.90.6
1.40.1
1.40.1

9.80.2 166285
13.60.6 68063
18.01.0 148088
17.91.1 148088

Actions

Reward

UCT
04 PRADA
A-PRADA

61
100
100

24.91.6
1.40.0
1.40.0

16.10.8 720057
11.90.4 146089
11.50.3 150087

SST
UCT
01
PRADA
A-PRADA

0
0
100
100





257.86.3 46.81.0
143.83.1 43.11.1



1.000.0
1.000.0

05

UCT
PRADA
A-PRADA

46
89
92

40.12.1
6.80.3
6.50.3

16.81.4 60064
21.80.9 124083
21.00.9 132081

02

PRADA
A-PRADA

100
100

285.27.8 46.21.3
215.84.2 39.60.9

20.000.0
20.000.0

06

UCT
PRADA
A-PRADA

39
83
84

71.75.6
10.10.9
10.00.9

19.51.3 41059
24.31.3 124090
23.71.2 124090

03

UCT
PRADA
A-PRADA

100
100
50

07

UCT
PRADA
A-PRADA

53
98
98

230.313.2
10.10.4
9.90.4

21.51.4 54062
18.50.8 147088
18.00.8 149087

04

PRADA
A-PRADA

28
60

959.035.5 76.13.2
519.215.3 72.02.4

0.30.5
0.60.1

UCT
PRADA
A-PRADA

34
59
59

332.924.1 21.711.5
20.20.8 30.41.7
19.90.8 29.91.7

05

08

UCT
PRADA
A-PRADA

54
61
2

9972776 37.93.5
345.48.5 68.41.6
528.638.8 38.00.0

606149
46524
41134

UCT
09 PRADA
A-PRADA

30
63
65

752.872.3
30.21.2
30.01.1

08

PRADA
A-PRADA

3
10

336188 87.02.3
157948 85.32.7

0.190.1
0.290.3

09

PRADA
A-PRADA

28
0

144925 85.91.5
(1750.3)


136531
112630

10

PRADA
A-PRADA

21
21

97.910.2
92.19.8

26.82.8
26.72.8

18027
18027

11

PRADA
A-PRADA

17
18

151.712.3
154.111.9

302.5
30.22.6

25029
25029

12

PRADA
A-PRADA

38
21

210.872.1 30.110.5 636253
219.828.5 30.72.8 55655

02

03

9.20.2 144090
11.40.3 90070
10.50.4 146089
10.40.4 146089

Planner

156083
880100
146089
144090

36059
91082
91082

0
100
100
100


9.90.3
8.50.2
8.00.2

02

UCT
PRADA
A-PRADA

100
57
65

64.12.2 12.40.3
30.10.7
90.2
33.70.8 11.40.3

03

UCT
PRADA
A-PRADA

89
19
21

390.58.5 18.60.4
119.24.9 12.30.5
121.05.3 14.30.7

UCT
04 PRADA
A-PRADA

82
6
4

149719 26.00.5
2967143 17.51.1
244.243.6 15.52.8



0.80.0
0.60.0

03

10

57.03.3 21.51.8 -9.60.0

Suc. Trial Time (s)

1285.28.1 32.80.0 929.82.1
165.72.9 52.51.1 865.13.3
457.87.1 35.00.7 754.121.5

(e) Exploding Blocksworld
Planner

Actions

SST
UCT
PRADA
A-PRADA

01





17.80.4 23.00.7
18.40.5 22.30.8

Planner

26.42.4 36048
27.51.6 93080
27.51.6 101084

Suc. Trial Time (s)

Reward

0
0
53
63

PRADA

Suc. Trial Time (s)

(d) Boxworld

(b) Triangle-Tireworld
Planner

Actions

SST
UCT
01
PRADA
A-PRADA


6.90.2
6.40.2
6.10.2

38

Suc. Trial Time (s)
86071224
111.814.0
3.60.0
3.90.0

Actions

SST
UCT
01
PRADA
A-PRADA

5
3
62
61

02

PRADA
A-PRADA

28
29

11.90.3 14.40.5
12.70.2 13.20.5

03

PRADA
A-PRADA

36
30

14.30.3 12.60.6
16.80.3 12.50.5

04

PRADA
A-PRADA

27
26

30.31.2 14.80.5
14.91.1 15.20.5

05

PRADA
A-PRADA

100
100

06

PRADA
A-PRADA

51
61

128.52.9 16.90.7
97.55.3 17.30.8

07

PRADA
A-PRADA

14
72

125.06.9 15.30.4
154.85.5 17.61.0

5.50.1
5.50.1

9.60.6
9.30.4
8.60.8
8.40.8

6.60.1
6.60.1

fiPlanning Noisy Probabilistic Relational Rules

Therefore, single problem instance perform 100 trials different random
seeds using full replanning. trial aborted goal state reached within
maximum number actions varying slightly benchmark (about 50 actions).
present success rates mean estimators trial times, executed actions
rewards standard deviations Table 6 problem instances least
one trial successfully covered reasonable time.
Search Rescue (Table 6(a)) domain SST (with branching factor
1) able find plans within reasonable time significantly larger runtimes
UCT (A-)PRADA. success rates rewards indicate PRADA APRADA superior UCT scale rather big problem instances. give idea
w.r.t. IPPC evaluation scheme: UCT solves successfully 54 trials first instance
within 10 minutes full replanning, PRADA A-PRADA solve trials
full replanning. fact, despite replanning single action, PRADA A-PRADA
show success rates best planners benchmark except large
problem instances (within competition, participants FSP-RBH FSP-RDH
achieved comparably satisfactory results). conjecture success methods
due fact domain requires account carefully outcome probabilities,
involve long planning horizons.
Triangle-Tireworld (Table 6(b)) domain UCT outperforms PRADA
A-PRADA, although higher computational cost. depth-first-like style
planning UCT seems useful domain. give idea w.r.t. IPPC evaluation
scheme: UCT performs 60 successful trials first instance within 10 minutes,
PRADA A-PRADA achieve 72 74 trials resp. using full replanning; UCT solves
trials difficult instances. required planning horizons increase quickly
problem instances. approaches cannot cope large problem instances,
three competition participants (RFF-BG, RFF-PG, HMDPP) could cover.
methods face problems required planning horizons large,
number plans non-zero probability small. becomes evident
Blocksworld benchmark (Table 6(c)). domain different robot manipulation environment first evaluation Sec. 6.1. latter considerably
stochastic provides actions given situation (e.g., may grab objects within
pile). Blocksworld domain approaches inferior FF-Replan.
give idea w.r.t. IPPC evaluation scheme: UCT perform single successful
trial first instance within 10 minutes, PRADA A-PRADA achieve 16
17 trials resp. using full replanning.
Boxworld domain (Table 6(d)), approaches exploit fact
delivery boxes (almost) independent delivery boxes (in problem
instances helped intermediate rewards delivered boxes). contrast
UCT, PRADA A-PRADA scale relatively large problem instances. PRADA
A-PRADA solve 100 trials first problem instance, requiring average 4.3
min 2.4 min resp. full replanning. two competition participants solved
trials successfully domain (RFF-BG RFF-PG). give idea w.r.t. IPPC
evaluation scheme: UCT perform single successful trial within 10 minutes,
PRADA completes 2 A-PRADA 4 trials. small number explained
large plan lengths single action computed full replanning.
39

fiLang & Toussaint

Finally, Exploding Blocksworld domain (Table 6(e)) PRADA A-PRADA
perform better good competition participants. give idea w.r.t. IPPC
evaluation scheme: UCT achieves single successful trial within 10 minutes,
PRADA A-PRADA complete 56 61 trials resp..
perform experiments either SysAdmin Schedule domain. PPDDL specifications cannot converted NID rules due involved
universal effects. contrast, possible Boxworld domain despite
universal effects there: Boxworld problem instances, universally quantified
variables always refer exactly one object exploit conversion NID rules.
(Note understood trick implement deictic references PPDDL
means universal effects. according action operator, however, odd semantics:
boxes could end two different cities time.) Furthermore, ignored
Rectangle-Tireworld domain, together Triangle-Tireworld domain makes
2-Tireworlds benchmark, problem instances faulty goal descriptions:
include not(dead) (this critical name winner competition
personally communicated Olivier Buffet).
6.2.1 Summary
majority PPDDL descriptions IPPC benchmarks converted
NID rules, indicating broad spectrum planning problems covered
NID rules. results demonstrate approaches perform comparably better
state-of-the-art planners many traditional hand-crafted planning problems.
hints generality methods probabilistic planning beyond type robotic
manipulation domains considered Sec. 6.1. methods perform particularly well
domains outcome probabilities need carefully accounted for. face problems
required planning horizons large, number plans non-zero
probability small; avoided intermediate rewards.

7. Discussion
presented two approaches planning probabilistic relational rules grounded
domains. methods designed work learned rules provide approximate
partial models noisy worlds. first approach adaptation UCT algorithm
samples look-ahead trees cope action stochasticity. second approach,
called PRADA, models uncertainty states explicitly terms beliefs employs
approximate inference graphical models planning. combine planning
algorithms existing rule learning algorithm, intelligent agent (i) learn
compact model dynamics complex noisy environment (ii) quickly derive appropriate actions varying goals. Results complex simulated robotics domain show
methods outperform state-of-the-art planner FF-Replan number different planning tasks. contrast FF-Replan, methods reason probabilities
action outcomes. necessary world dynamics noisy partial
approximate world models available.
However, planners also perform remarkably well many traditional probabilistic
planning problems. demonstrated results IPPC benchmarks,
40

fiPlanning Noisy Probabilistic Relational Rules

shown PPDDL descriptions converted large extent kind rules
planners use. hints general-purpose character particularly PRADA
potential benefits techniques probabilistic planning. instance, methods
expected perform similarly well large propositional MDPs exhibit
relational structure.
far, planning approaches deal reasonable time problems containing
10-15 objects (implying billions world states) requiring planning horizons
15-20 time-steps. Nonetheless, approaches still limited rely
reasoning grounded representation. many objects need represented
representation language gets rich, approaches need combined
methods reduce state action space complexity (Lang & Toussaint, 2009b).
7.1 Outlook
current form, approximate inference procedure PRADA relies specific
compact DBNs compiled rules. development similar factored frontier filters
arbitrary DBNs, e.g. derived general PPDDL descriptions, promising.
Similarly, adaptation PRADAs factored frontier techniques existing probabilistic
planners worth investigation.
Using probabilistic relational rules backward planning appears appealing.
straightforward learn NID rules regress actions providing reversed triples (s0 , a, s)
rule learning algorithm, stating predecessor state state s0 action
applied before. Backward planning, combined forward planning,
received lot attention classical planning may fruitful planning
look-ahead trees well planning using approximate inference. means propagating backwards DBNs, one may ultimately derive algorithms calculate
posteriors actions, leading true planning inference (instead sampling actions).
important direction improving PRADA algorithm make adapt
action-sequence sampling strategy experience previous samples. introduced simple extension, A-PRADA, achieve this, sophisticated methods
conceivable. Learning rule-sets online exploiting immediately planning method also important direction future research order enable acting
real world, want behave effectively right start. Improving
rule framework efficient effective planning another interesting issue.
instance, instead using noisy default rule, one may use mixture models deal
actions several (non-unique) covering rules, general use parallel rules work
different hierarchical levels different aspects underlying system.

Acknowledgments
thank anonymous reviewers careful thorough comments
greatly improved paper. thank Sungwook Yoon providing us implementation
FF-Replan. thank Olivier Buffet answering questions probabilistic
planning competition 2008. work supported German Research Foundation
(DFG), Emmy Noether fellowship 409/1-3.
41

fiLang & Toussaint

Appendix A. Proof Proposition 1
Proposition 1 (Sec. 5.3) set action sequences PRADA samples non-zero
probability super-set ones SST UCT.
Proof: Let a0:T 1 action sequence sampled SST (or UCT). Thus,
exists state sequence s0:T rule sequence r0:T 1 every state st
(t < ), action unique covering rule rt predicts successor state st+1
probability pt > 0. For, pt = 0, st+1 would never sampled SST (or UCT).
show t, 0 < : P (st | a0:t1 , s0 ) > 0. case

Psample (at ) > 0 unique covering rule rt st eventually sampled.
P (s0 ) = 1 > 0 obvious. assume P (st | a0:t1 , s0 ) > 0. execute ,
get P (st+1 | a0:t , s0 ) pt P (st | a0:t1 , s0 ) > 0. posterior P (st+1 | a0:t , s0 ) greater
(first inequality) due persistence previous states non-zero probability
also lead st+1 given .
set action sequences PRADA samples larger SST (or UCT)
SST (or UCT) refuses model noise outcomes rules. Assume action state
state unique covering rule. episode
simulated means rule predictions noise outcome, action never
sampled SST (or UCT) (as required states never sampled). contrast, PRADA
also models effects noise outcome giving low probability possible
successor states heuristic described above.

Appendix B. Relation NID rules PPDDL
use NID rules (Sec. 3.2) relational model transition dynamics probabilistic actions. Besides allowing negative literals preconditions, NID rules extend
probabilistic STRIPS operators (Kushmerick et al., 1995; Blum & Langford, 1999) two
special constructs, namely deictic references noise outcomes, crucial learning compact rule-sets. alternative language specify probabilistic relational planning
problems used International Probabilistic Planning Competitions (IPPC, 2008)
probabilistic planning domain definition language (PPDDL) (Younes & Littman, 2004).
PPDDL probabilistic extension subset PDDL, derived deterministic
action description language (ADL). ADL, turn, introduced universal conditional
effects negative precondition literals (deterministic) STRIPS representation.
Thus, PPDDL allows usage syntactic constructs beyond expressive
power NID rules; however, many PPDDL descriptions converted NID rules.
taking closer look convert PPDDL NID rule representations
other, clarify meant action formalisms, giving
intuition line thinking using either these. understand abstract
action abstract action predicate, e.g. pickup(X). Intuitively, defines certain type
action. stochastic state transitions according abstract action specified
abstract NID rules well abstract PPDDL action operators (also called schemata).
Typically, several different abstract NID rules model abstract action, specifying
state transitions different contexts. contrast, usually one abstract PPDDL action
42

fiPlanning Noisy Probabilistic Relational Rules

operator used model abstract action: context-dependent effects modeled
means conditional universal effects.
make predictions specific situation concrete action (a grounded action
predicate pickup(greenCube)), strategy within NID rule framework
ground set abstract NID rules examine ground rules cover state-action
pair. exactly one ground rule, chosen prediction.
rule one (the contexts NID rules mutually
exclusive), one chooses noisy default rule, essentially saying one know
happen (other strategies conceivable, pursued here). contrast,
usually exactly one operator per abstract action PPDDL domains,
need concept operator uniqueness distinguish ground actions
operators.
B.1 Converting PPDDL NID rules
following, discuss convert PPDDL features NID rule representation.
may impossible convert PPDDL action operator single NID rule,
one may often translate set rules polynomial increase size
representation. Table 7 provides example converted PPDDL action operator
IPPC domain Exploding Blocksworld. NID rules support many,
features sophisticated domain description language PPDDL provides, using rules
lead compact representations possible domains. experiments, however,
show dynamics many interesting planning domains specified compactly.
Furthermore, additional expressive power rule contexts gained using derived
predicates allow bring various kinds logical formulas quantification.
Conditional Effects conditional effect PPDDL operator takes form C
E. accounted two NID rules: first rule adds C context
E outcomes, second adds C context ignores E.
Universal Effects PPDDL allows define universal effects. specify effects
objects meet preconditions. example reboot action SysAdmin
domain IPPC 2008 competition: specifies every computer one
rebooted independently go probability 0.2 connected computer
already down. cannot expressed NID rule framework.
refer objects action arguments via deictic references, require
deictic references unique. reboot action, would need unique way refer
computer cannot achieved without significant modifications (for
example, enumerating computers via separate predicates).
Disjunctive Preconditions Quantification PPDDL operators allow disjunctive preconditions, including implications. instance, Search-and-rescue domain
IPPC 2008 competition defines action operator goto(X) precondition
(X 6= base) humanAlive(). disjunction B ( B) accounted
either using two NID rules, first rule context second
rule B. Alternatively, one may introduce derived predicate C B.
general, trick derived predicates allows overcome syntactical limitations NID
43

fiLang & Toussaint

Table 7: Example converting PPDDL action operator NID rules. putDownoperator IPPC benchmark domain Exploding Blocksworld (a) contains
conditional effect accounted two NID rules either exclude
(b) include (c) condition context.
( : action putDown

(a)

: parameters (?b block)
: precondition (and (holding ?b) (noDestroyedT able))
: ef f ect (and (emptyhand) (onT able ?b) (not (holding ?b))
(probabilistic 2/5 (when (noDetonated ?b) (and (not (noDestroyedT able)) (not (noDetonated?b))))))
)
(b)
putDown(X) : block(X), holding(X), noDestroyedT able(), noDetonated(X)

1.0 : emptyhand(X), onT able(X), holding(X)

(c)
putDown(X) : block(X), holding(X), noDestroyedT able(), noDetonated(X)

0.6 : emptyhand(X), onT able(X), holding(X)

0.4 : emptyhand(X), onT able(X), holding(X), noDestroyedT able(), noDetonated(X)

rules bring various kinds logical formulas quantifications. discussed
Pasula et al. (2007), derived predicates important prerequisite able learn
compact accurate rules.
Types Terms may typed PPDDL, e.g. driveT o(C city). Typing objects
variables predicates functions achieved NID rules usage typing
predicates within context, e.g. using additional predicate city(C).
State Transition Rewards PPDDL, one encode Markovian rewards associated
state transitions (including action costs negative rewards) using fluents update
rules action effects. One achieve NID rules associating rewards
outcomes rules.
B.2 Converting NID rules PPDDL
show following way NID rules used SST, UCT PRADA
planning time handled via polynomial blowup representational size.
basic building blocks NID rule, i.e. context well outcomes, transfer
one-to-one PPDDL action operators. deictic references, uniqueness requirement
covering rules noise outcome need special attention.
Deictic References Deictic references NID rules allow refer objects
action arguments. PPDDL, one refer objects means universal
conditional effects. important restriction, however: deictic reference needs
pick single unique object order apply. picks none many, rule fails
apply. two ways ensure uniqueness requirement within PPDDL. First,
44

fiPlanning Noisy Probabilistic Relational Rules

allowing quantified preconditions, explicit uniqueness precondition deictic
reference introduced. Using universal quantification, constrains objects
satisfying preconditions identical, i.e., X, : (X, ) (Y, )
X = , variables. Alternatively, uniqueness deictic references
achieved careful planning problem specification, however cannot
guaranteed learning rules.
Uniqueness covering rules contexts NID rules mutually
exclusive. want use rule prediction (as planning), need ensure
uniquely covers given state-action pair. procedural evaluation process NID
rules encoded declaratively PPDDL using modified conditions explicitly
negate contexts competing rules. instance, three NID rules
potentially overlapping contexts A, B, C (propositional simplicity), PPDDL
action operator may define four conditions: c1 = {A B C}, c2 = {A B C},
c3 = {A B C}, c4 = {(A B C) (A B) (A C) (B C)}. Conditions c1 ,
c2 c3 test uniqueness corresponding NID rules subsume outcomes.
Condition c4 tests non-uniqueness (either covering rule multiple covering rules)
models potential changes noise, analogous situations NID rule context
noisy default rule would used.
Noise outcome noise outcome NID rule subsumes seldom utterly complex
outcomes. relaxes frame assumption: even explicitly stated things may change
certain probability. comes price difficulty ensure well-defined
successor state distribution P (s0 | s, a). contrast, PPDDL needs explicitly specify
everything might change. may important reason difficult come
effective learning algorithm PPDDL.
principle PPDDL provide noise outcome, way approaches
account planning encoded PPDDL. either treat noise outcome
effects (in SST UCT; basically noop operator then) trivially
translated PPDDL; consider probability state attribute change
independently (in PRADA) encoded PPDDL independent universal
probabilistic effects.
noise outcome allows always make predictions arbitrary action:
multiple covering rules, may use (albeit informative) prediction
default rule. cases dealt PPDDL action operators using explicit
conditions described previous paragraph.

References
Blum, A., & Langford, J. (1999). Probabilistic planning graphplan framework.
Proc. Fifth European Conference Planning (ECP), pp. 319332.
Botvinick, M. M., & An, J. (2009). Goal-directed decision making prefrontal cortex:
computational framework. Advances Neural Information Processing Systems
(NIPS), pp. 169176.
45

fiLang & Toussaint

Boutilier, C., Dean, T., & Hanks, S. (1999). Decision-theoretic planning: Structural assumptions computational leverage. Journal Artificial Intelligence Research,
11, 194.
Boutilier, C., Reiter, R., & Price, B. (2001). Symbolic dynamic programming first-order
MDPs. Proc. Int. Conf. Artificial Intelligence (IJCAI), pp. 690700.
Buffet, O., & Aberdeen, D. (2009). factored policy-gradient planner. Artificial Intelligence Journal, 173 (5-6), 722747.
Cooper, G. (1988). method using belief networks influence diagrams. Proc.
Fourth Workshop Uncertainty Artificial Intelligence, pp. 5563.
Croonenborghs, T., Ramon, J., Blockeel, H., & Bruynooghe, M. (2007). Online learning
exploiting relational models reinforcement learning. Proc. Int. Conf.
Artificial Intelligence (IJCAI), pp. 726731.
Domshlak, C., & Hoffmann, J. (2007). Probabilistic planning via heuristic forward search
weighted model counting. Journal Artificial Intelligence Research, 30, 565620.
Driessens, K., Ramon, J., & Gartner, T. (2006). Graph kernels Gaussian processes
relational reinforcement learning. Machine Learning, 64 (1-3), 91119.
Dzeroski, S., de Raedt, L., & Driessens, K. (2001). Relational reinforcement learning.
Machine Learning, 43, 752.
Fern, A., Yoon, S., & Givan, R. (2006). Approximate policy iteration policy language
bias: solving relational markov decision processes. Journal Artificial Intelligence
Research, 25 (1), 75118.
Gardiol, N. H., & Kaelbling, L. P. (2003). Envelope-based planning relational MDPs.
Proc. Conf. Neural Information Processing Systems (NIPS).
Gardiol, N. H., & Kaelbling, L. P. (2007). Action-space partitioning planning. Proc.
AAAI Conf. Artificial Intelligence (AAAI), pp. 980986.
Gardiol, N. H., & Kaelbling, L. P. (2008). Adaptive envelope MDPs relational
equivalence-based planning. Tech. rep. MIT-CSAIL-TR-2008-050, MIT CS & AI Lab,
Cambridge, MA.
Gelly, S., & Silver, D. (2007). Combining online offline knowledge UCT. Proc.
Int. Conf. Machine Learning (ICML), pp. 273280.
Gretton, C., & Thiebaux, S. (2004). Exploiting first-order rgeression inductive policy
selection. Proc. Conf. Uncertainty Artificial Intelligence (UAI), pp.
217225.
Grush, R. (2004). Conscious thought simulation behaviour perception. Behaviorial
brain sciences, 27, 377442.
46

fiPlanning Noisy Probabilistic Relational Rules

Halbritter, F., & Geibel, P. (2007). Learning models relational MDPs using graph kernels.
Proc. Mexican Conference Artificial Intelligence (MICAI), pp. 409419.
Hesslow, G. (2002). Conscious thought simulation behaviour perception. Trends
Cognitive Science, 6 (6), 242247.
Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generation
heuristic search. Journal Artificial Intelligence Research, 14, 253302.
Holldobler, S., & Skvortsova, O. (2004). logic-based approach dynamic programming.
AAAI-Workshop: Learning planning MDPs, pp. 3136.
IPPC

(2008).
Sixth International Planning Competition,
http://ippc-2008.loria.fr/wiki/index.php/Main Page.

Uncertainty

Part..

Jensen, F. (1996). introduction Bayesian networks. Springer Verlag, New York.
Joshi, S., Kersting, K., & Khardon, R. (2009). Generalized first-order decision diagrams
first-order MDPs. Proc. Int. Conf. Artificial Intelligence (IJCAI), pp.
19161921.
Karabaev, E., & Skvortsova, O. (2005). heuristic search algorithm solving first-order
MDPs. Proc. Conf. Uncertainty Artificial Intelligence (UAI), pp.
292299.
Kearns, M. J., Mansour, Y., & Ng, A. Y. (2002). sparse sampling algorithm nearoptimal planning large Markov decision processes. Machine Learning, 49 (2-3),
193208.
Kersting, K., & Driessens, K. (2008). Nonparametric policy gradients: unified treatment propositional relational domains. Proc. Int. Conf. Machine
Learning (ICML), pp. 456463.
Kersting, K., van Otterlo, M., & de Raedt, L. (2004). Bellman goes relational. Proc.
Int. Conf. Machine Learning (ICML), pp. 465472.
Kocsis, L., & Szepesvari, C. (2006). Bandit based monte-carlo planning. Proc.
European Conf. Machine Learning (ECML), pp. 837844.
Kushmerick, N., Hanks, S., & Weld, D. (1995). algorithm probabilistic planning.
Artificial Intelligence, 78 (1-2), 239286.
Kuter, U., Nau, D. S., Reisner, E., & Goldman, R. P. (2008). Using classical planners
solve nondeterministic planning problems. Proc. Int. Conf. Automated
Planning Scheduling (ICAPS), pp. 190197.
Lang, T., & Toussaint, M. (2009a). Approximate inference planning stochastic relational worlds. Proc. Int. Conf. Machine Learning (ICML), pp. 585592.
Lang, T., & Toussaint, M. (2009b). Relevance grounding planning relational domains.
Proc. European Conf. Machine Learning (ECML), pp. 736751.
47

fiLang & Toussaint

Little, I., & Thiebaux, S. (2007). Probabilistic planning vs replanning. ICAPS-Workshop
International Planning Competition: Past, Present Future.
Littman, M. L., Goldsmith, J., & Mundhenk, M. (1997). computational complexity
probabilistic planning. Journal Artificial Intelligence Research, 9, 136.
Murphy, K. P. (2002). Dynamic Bayesian Networks: Representation, Inference Learning. Ph.D. thesis, UC Berkeley.
Murphy, K. P., & Weiss, Y. (2001). factored frontier algorithm approximate inference DBNs. Proc. Conf. Uncertainty Artificial Intelligence (UAI),
pp. 378385.
Pasula, H. M., Zettlemoyer, L. S., & Kaelbling, L. P. (2007). Learning symbolic models
stochastic domains. Journal Artificial Intelligence Research, 29, 309352.
Poon, H., & Domingos, P. (2007). Sound efficient inference probabilistic
deterministic dependencies. Proc. AAAI Conf. Artificial Intelligence
(AAAI).
Sanner, S., & Boutilier, C. (2007). Approximate solution techniques factored first-order
MDPs. Proc. Int. Conf. Automated Planning Scheduling (ICAPS),
pp. 288295.
Sanner, S., & Boutilier, C. (2009). Practical solution techniques first-order MDPs.
Artificial Intelligence, 173 (5-6), 748788.
Shachter, R. (1988). Probabilistic inference influence diagrams. Operations Research,
36, 589605.
Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MIT
Press.
Teichteil-Konigsbuch, F., Kuter, U., & Infantes, G. (2010). Aggregation generating
policies MDPs. appear Proc. Int. Conf. Autonomous Agents
Multiagent Systems.
Toussaint, M., & Storkey, A. (2006). Probabilistic inference solving discrete continuous state Markov decision processes. Proc. Int. Conf. Machine Learning
(ICML), pp. 945952.
Toussaint, M., Storkey, A., & Harmeling, S. (2010). Expectation-maximization methods
solving (PO)MDPs optimal control problems. Chiappa, S., & Barber, D.
(Eds.), Inference Learning Dynamic Models. Cambridge University Press.
van Otterlo, M. (2009). Logic Adaptive Behavior. IOS Press, Amsterdam.
Walsh, T. J. (2010). Efficient learning relational models sequential decision making.
Ph.D. thesis, Rutgers, State University New Jersey, New Brunswick, NJ.
48

fiPlanning Noisy Probabilistic Relational Rules

Wang, C., Joshi, S., & Khardon, R. (2008). First order decision diagrams relational
MDPs. Journal Artificial Intelligence Research, 31, 431472.
Weld, D. S. (1999). Recent advances AI planning. AI Magazine, 20 (2), 93123.
Wu, J.-H., Kalyanam, R., & Givan, R. (2008). Stochastic enforced hill-climbing. Proc.
Int. Conf. Automated Planning Scheduling (ICAPS), pp. 396403.
Yoon, S. W., Fern, A., & Givan, R. (2007). FF-Replan: baseline probabilistic planning.
Proc. Int. Conf. Automated Planning Scheduling (ICAPS), pp. 352
359.
Yoon, S. W., Fern, A., Givan, R., & Kambhampati, S. (2008). Probabilistic planning via
determinization hindsight. Proc. AAAI Conf. Artificial Intelligence
(AAAI), pp. 10101016.
Younes, H. L., & Littman, M. L. (2004). PPDDL1.0: extension PDDL expressing
planning domains probabilistic effects. Tech. rep., Carnegie Mellon University.

49

fiJournal Artificial Intelligence Research 39 (2010) 689743

Submitted 05/10; published 12/10

Best-First Heuristic Search Multicore Machines
Ethan Burns
Sofia Lemons
Wheeler Ruml

EABURNS CS . UNH . EDU
SOFIA . LEMONS CS UNH . EDU
RUML CS . UNH . EDU

Department Computer Science
University New Hampshire
Durham, NH 03824 USA

Rong Zhou

RZHOU PARC . COM

Embedded Reasoning Area
Palo Alto Research Center
Palo Alto, CA 94304 USA

Abstract
harness modern multicore processors, imperative develop parallel versions fundamental algorithms. paper, compare different approaches parallel best-first search
shared-memory setting. present new method, PBNF, uses abstraction partition state
space detect duplicate states without requiring frequent locking. PBNF allows speculative
expansions necessary keep threads busy. identify fix potential livelock conditions
approach, proving correctness using temporal logic. approach general, allowing
extend easily suboptimal anytime heuristic search. empirical comparison STRIPS
planning, grid pathfinding, sliding tile puzzle problems using 8-core machines, show
A*, weighted A* Anytime weighted A* implemented using PBNF yield faster search
improved versions previous parallel search proposals.

1. Introduction
widely anticipated future microprocessors faster clock rates, instead
computing cores per chip. Tasks exist effective parallel algorithms
suffer slowdown relative total system performance. artificial intelligence, heuristic
search fundamental widely-used problem solving framework. paper, compare
different approaches parallelizing best-first search, popular method underlying algorithms
Dijkstras algorithm A* (Hart, Nilsson, & Raphael, 1968).
best-first search, two sets nodes maintained: open closed. Open contains search
frontier: nodes generated yet expanded. A*, open nodes sorted
f value, estimated lowest cost solution path going node. Open typically
implemented using priority queue. Closed contains previously generated nodes, allowing
search detect states reached via multiple paths search space avoid expanding
multiple times. closed list typically implemented hash table. central challenge
parallelizing best-first search avoiding contention threads accessing open
closed lists. look variety methods parallelizing best-first search, focusing
algorithms based two techniques: parallel structured duplicate detection parallel
retracting A*.
c
2010
AI Access Foundation. rights reserved.

fiB URNS , L EMONS , RUML , & Z HOU

Parallel structured duplicate detection (PSDD) originally developed Zhou Hansen
(2007) parallel breadth-first search, order reduce contention shared data structures
allowing threads enjoy periods synchronization-free search. PSDD requires user supply
abstraction function maps multiple states, called nblock, single abstract state.
present new algorithm based PSDD called Parallel Best-N Block-First (PBNF1 ). Unlike PSDD,
PBNF extends easily domains non-uniform non-integer move costs inadmissible
heuristics. Using PBNF infinite search space give rise livelock, threads continue
search goal never expanded. discuss condition avoided
PBNF using method call hot nblocks, well use bounded model checking test
effectiveness. addition, provide proof correctness PBNF framework, showing
liveness completeness general case.
Parallel retracting A* (PRA*) created Evett, Hendler, Mahanti, Nau (1995). PRA*
distributes search space among threads using hash nodes state. PRA*, duplicate
detection performed locally; communication peers required transfer generated
search-nodes home processor. PRA* sensitive choice hashing function used
distribute search space. show new hashing function, based state space
abstraction used PSDD, give PRA* significantly better performance domains.
Additionally, show communication cost incurred naive implementation PRA*
prohibitively expensive. Kishimoto, Fukunaga, Botea (2009) present method helps
alleviate cost communication PRA* using asynchronous message passing primitives.
evaluate PRA* (and variants), PBNF algorithms empirically using dual quadcore Intel machines. study behavior three popular search domains: STRIPS planning,
grid pathfinding, venerable sliding tile puzzle. empirical results show simplest
parallel search algorithms easily outperformed serial A* search even run
eight threads. results also indicate adding abstraction PRA* algorithm give
larger increase performance simply using asynchronous communication, although using
modifications together may outperform either one used own. Overall, PBNF
algorithm often gives best performance.
addition finding optimal solutions, show adapt several algorithms
bounded suboptimal search, quickly finding w -admissible solutions (with cost within factor w
optimal). provide new pruning criteria parallel suboptimal search prove algorithms using retain w -admissibility. results show that, sufficiently difficult problems,
parallel search may significantly outperform serial weighted A* search. also found
advantage parallel suboptimal search increases problem difficulty.
Finally, demonstrate parallel searches, PBNF PRA*, lead naturally
effective anytime algorithms. also evaluate obvious parallel anytime search strategies
running multiple weighted A* searches parallel different weights. show
parallel anytime searches able find better solutions faster serial counterparts
also able converge quickly optimal solutions.

1. Peanut Butter N (marshmallow) Fluff, also known fluffernutter, well-known childrens sandwich
USA.

690

fiB EST-F IRST EARCH ULTICORE ACHINES

2. Previous Approaches
much previous work parallel search. briefly summarize selected proposals
turning foundation work, PRA* PSDD algorithms.
2.1 Depth- Breadth-first Approaches
Early work parallel heuristic search investigated approaches based depth-first search. Two
examples distributed tree search (Ferguson & Korf, 1988), parallel window search (Powley
& Korf, 1991).
Distributed tree search begins single thread, given initial state expand.
time node generated unused thread assigned node. threads allocated
tree depth-first manner free threads assign. occurs,
thread continue searching children depth-first search. solution
subtree found passed tree parent thread child thread becomes free
re-allocated elsewhere tree. Parent threads go sleep children search,
waking children terminate, passing solutions upward parents recursively.
keep closed list, depth-first search cannot detect duplicate states give
good search performance domains many duplicate states, grid pathfinding
planning domains.
Parallel window search parallelizes iterative deepening A* (IDA*, see Korf, 1985) algorithm. parallel window search, thread assigned cost-bound perform costbounded depth-first search search space. problem approach IDA*
spend least half search time final iteration since every iteration still performed
single thread, search limited speed single thread. addition, nonuniform costs foil iterative deepening, may good way choose new
upper-bounds give search geometric growth.
Holzmann Bosnacki (2007) able successfully parallelize depth-first search
model checking. authors able demonstrate technique distributes nodes
based search depth able achieve near linear speedup domain model checking.
research used graphics processing units (GPUs) parallelize breadth-first search
use two-player games (Edelkamp & Sulewski, 2010). following sections describe
algorithms intent parallelizing best-first search.
2.2 Simple Parallel Best-first Search
simplest approach parallel best-first search open closed lists shared
among threads (Kumar, Ramesh, & Rao, 1988). maintain consistency data structures,
mutual exclusion locks (mutexes) need used ensure single thread accesses data
structure time. call search parallel A*. Since node expanded taken
open list node generated looked closed list every thread,
approach requires lot synchronization overhead ensure consistency data structures.
see Section 4.3, naive approach performs worse serial A*.
much work designing complex data structures retain correctness
concurrent access. idea behind special wait-free data structures many threads
use portions data structure concurrently without interfering one another.
691

fiB URNS , L EMONS , RUML , & Z HOU

approaches use special compare-and-swap primitive ensure that, modifying
structure, get modified another thread. implemented simple parallel A* search,
call lock-free parallel A*, threads access single shared, concurrent priority
queue concurrent hash table open closed lists, respectively. implemented
concurrent priority queue data structure Sundell Tsigas (2005). closed list, used
concurrent hash table implemented array buckets, concurrent
ordered list developed Harris (2001). lock-free data structures used implement LPA*
require special lock-free memory manager uses reference counting compare-and-swap
based stack implement free list (Valois, 1995). see that, even sophistocated
structures, straightforward parallel implementation A* give competitive performance.
One way avoiding contention altogether allow one thread handle synchronization
work done threads. K -Best-First Search (Felner, Kraus, & Korf, 2003) expands
best k nodes once, handled different thread. implementation,
master thread takes k best nodes open gives one worker. workers expand
nodes master checks children duplicates inserts open list.
allows open closed used without locking, however, order adhere strict
k -best-first ordering approach requires master thread wait workers finish
expansions handing new nodes. domains used paper, node expansion
particularly slow, show method scale well.
One way reduce contention search access closed list less frequently. technique called delayed duplicate detection (DDD) (Korf, 2003), originally developed externalmemory search, used temporarily delay access closed list. several variations proposed, basic principle behind DDD generated nodes added
single list certain condition met (a depth level fully expanded, maximum list
size reached (Stern & Dill, 1998), etc.) condition met, list sorted
draw duplicate nodes together. nodes list checked closed list,
best version kept inserted onto open list. initial DDD algorithm used
breadth-first frontier search therefore previous depth-layer required duplicate
detection. parallel version later presented Niewiadomski, Amaral, Holte (2006a),
split depth layer sections maintained separate input output lists each.
later merged order perform usual sorting duplicate detection methods.
large synchronization step, however, incur costs similar KBFS. also depends upon
expensive workload distribution scheme ensure processors work do, decreasing bottleneck effect nodes distributed unevenly, increasing algorithms
overhead. later parallel best-first frontier search based DDD presented (Niewiadomski,
Amaral, & Holte, 2006b), incurs even overhead requiring synchronization
threads maintain strict best-first ordering.
Jabbar Edelkamp (2006) present algorithm called parallel external A* (PEA*) uses
distributed computing nodes external memory perform best-first search. PEA* splits
search space set buckets contain nodes g h values.
algorithm performs best-first search exploring buckets lowest f value beginning
one lowest g. master node manages requests distribute portions current
bucket various processing nodes expanding single bucket performed parallel.
avoid contention, PEA* relies operating system synchronize access files
shared among nodes. Jabbar Edelkamp used PEA* algorithm parallelize
692

fiB EST-F IRST EARCH ULTICORE ACHINES

model-checker achieved almost linear speedup. partitioning g h works
domains general nodes g h values. tends case
domains real-valued edge costs. turn attention two algorithms reappear
throughout rest paper: PRA* PSDD.
2.3 Parallel Retracting A*
PRA* (Evett et al., 1995) attempts avoid contention assigning separate open closed lists
thread. hash state representation used assign nodes appropriate thread
generated. (Full PRA* also includes retraction scheme reduces memory use
exchange increased computation time; consider feature paper.)
choice hash function influences performance algorithm, since determines way
work distributed. Note standard PRA*, thread may communicate
peers, thread needs synchronized message queue peers add nodes.
multicore setting, implemented requiring thread take lock message queue.
Typically, requires thread sending (or receiving) message wait operation
complete continue searching. less bottleneck single
global, shared open list, see still expensive. also interesting
note PRA* variants mentioned practice type delayed duplicate detection,
store duplicates temporarily checking thread-local closed list
possibly inserting open list.
2.3.1 MPROVEMENTS
Kishimoto et al. (2009) note original PRA* implementation improved removing synchronization requirement message queues nodes. Instead, use
asynchronous send receive functionality MPI message passing library (Snir & Otto,
1998) implement asynchronous version PRA* call Hash Distributed A* (HDA*).
HDA* distributes nodes using hash function way PRA*, except sending
receiving nodes happens asynchronously. means threads free continue searching
nodes communicated peers transit.
contact authors HDA*, created implementation HDA* multicore
machines extra overhead message passing asynchronous communication threads shared memory setting. Also, implementation HDA* allows us
make fair comparison algorithms sharing common data structures priority
queues hash tables.
implementation, HDA* thread given single queue incoming nodes one
outgoing queue peer thread. queues implemented dynamically sized arrays
pointers search nodes. generating nodes, thread performs non-blocking call
acquire lock2 appropriate peers incoming queue, acquiring lock available
immediately returning failure busy, rather waiting. lock acquired simple
pointer copy transfers search node neighboring thread. non-blocking call fails
nodes placed outgoing queue peer. operation require lock
outgoing queue local current thread. certain number expansions, thread
attempts flush outgoing queues, never forced wait lock send nodes.
2. One non-blocking call pthread mutex trylock function POSIX standard.

693

fiB URNS , L EMONS , RUML , & Z HOU

Figure 1: simple abstraction. Self-loops eliminated.
also attempts consume incoming queue waits lock open list empty,
case work do. Using simple efficient implementation,
confirmed results Kishimoto et al. (2009) show asynchronous version
PRA* (called HDA*) outperforms standard synchronous version. Full results presented
Section 4.
PRA* HDA* use simple representation-based node hashing scheme one,
example, used look nodes closed lists. present two new variants, APRA*
AHDA*, make use state space abstraction distribute search nodes among processors.
Instead assigning nodes thread, thread assigned set blocks search space
block corresponds state abstract space. intuition behind approach
children single node assigned small subset remote threads
and, fact, often assigned back expanding thread itself. reduces number
edges communication graph among threads search, reducing chances thread
contention. Abstract states distributed evenly among threads using modulus operator
hope open nodes always available thread.
2.4 Parallel Structured Duplicate Detection
PSDD major previously-proposed alternative PRA*. intention PSDD avoid
need lock every node generation avoid explicitly passing individual nodes
threads. builds idea structured duplicate detection (SDD), originally developed external memory search (Zhou & Hansen, 2004). SDD uses abstraction function,
many-to-one mapping states original search space states abstract space.
abstract node state mapped called image. nblock set nodes
state space image abstract space. abstraction function creates abstract graph nodes images nodes state space. two states successors
state space, images successors abstract graph. Figure 1 shows state space
graph (left) consisting 36 nodes abstract graph (right) consists nine nodes.
node abstract graph represents grouping four nodes, called nblock, original state
space, shown dotted lines state space graph left.
694

fiB EST-F IRST EARCH ULTICORE ACHINES

Figure 2: Two disjoint duplicate detection scopes.

nblock open closed list. avoid contention, thread acquire exclusive
access nblock. Additionally, thread acquires exclusive access nblocks correspond successors abstract graph nblock searching. nblock
call set nblocks successors abstract graph duplicate detection scope.
abstract nodes access required order perform
perfect duplicate detection expanding nodes given nblock. thread expands
node n nblock b children n must fall within b one nblocks successors
b abstract graph. Threads determine whether new states generated expanding
n duplicates simply checking closed lists nblocks duplicate detection scope.
require synchronization thread exclusive access set nblocks.
PSDD, abstract graph used find nblocks whose duplicate detection scopes disjoint. nblocks searched parallel without locking node expansions.
Figure 2 shows two disjoint duplicate detection scopes delineated dashed lines different
patterns. nblock use thread whose duplicate detection scope also
use considered free. free nblock available thread acquire searching. Free nblocks found explicitly tracking, nblock b, (b), number nblocks
among bs successors use another thread. nblock b acquired
(b) = 0.
advantage PSDD requires single lock, one controlling manipulation
abstract graph, lock needs acquired threads finding new free
nblock search. means threads need synchronize expanding nodes,
common operation.
Zhou Hansen (2007) used PSDD parallelize breadth-first heuristic search (Zhou & Hansen,
2006). algorithm, nblock two lists open nodes. One list contains open nodes
current search depth contains nodes next search depth. thread,
nodes current search depth acquired nblock expanded. children
generated put open list next depth nblock map (which
duplicate detection scope nblock searched) long duplicates.
current nblock nodes current depth, swapped free nblock
695

fiB URNS , L EMONS , RUML , & Z HOU

open nodes depth. nblocks open nodes current depth,
threads synchronize progress together next depth. admissible heuristic used
prune nodes fall current solution upper bound.
2.4.1 MPROVEMENTS
PSDD viewed general framework parallel search, terminology, PSDD
refers instance SDD parallel setting uses layer-based synchronization breadthfirst search. subsection, present two algorithms use PSDD framework attempt
improve PSDD algorithm specific ways.
implemented Zhou Hansen (2007), PSDD algorithm uses heuristic estimate
node pruning; effective tight upper bound already available.
cope situations good bound available, implemented novel algorithm
using PSDD framework uses iterative deepening (IDPSDD) increase bound.
report below, approach effective domains grid pathfinding
geometrically increasing number nodes within successive f bounds.
Another drawback PSDD breadth-first search cannot guarantee optimality domains
operators differing costs. anticipation problems, Zhou Hansen (2004)
suggest two possible extensions work, best-first search speculative best-first layering
approach allows larger layers cases nodes (or nblocks)
f value. knowledge, first implement test algorithms.
Best-first PSDD (BFPSDD) uses f value layers instead depth layers. means
nodes expanded given layer (lowest) f value. BFPSDD provides bestfirst search order, may incur excessive synchronization overhead nodes
f layer. ameliorate this, loosen best-first ordering enforcing least nodes
expanded abandoning non-empty nblock. (Zhou & Hansen, 2007 credit Edelkamp &
Schrodl, 2000 idea.) Also, populating list free nblocks layer,
nblocks nodes current layers f value used minimum k nblocks
added k four times number threads. (This value k gave better performance
values tested.) allows us add additional nblocks small layers order amortize
cost synchronization. addition, tried alternative implementation BFPSDD used
range f values layer. parameter f used proscribe width (in f values)
layer search. implementation perform well present results
it. either enhancements, threads may expand nodes f values greater
current layer. first solution found may optimal, search continues
remaining nodes pruned incumbent solution.
surveyed existing approaches parallel best-first search, present new
approach comprises main algorithmic contribution paper.

3. Parallel Best-N Block-First (PBNF)
ideal scenario, threads would busy expanding nblocks contain nodes lowest
f values. approximate this, combine PSDDs duplicate detection scopes idea
Localized A* algorithm Edelkamp Schrodl (2000). Localized A*, designed
improve locality external memory search, maintains sets nodes reside
memory page. decision set process next made help heap sets
696

fiB EST-F IRST EARCH ULTICORE ACHINES

1. nblock open nodes
2. lock; b best free nblock; unlock
3. b worse best free nblock weve done fewer min expansions
4.
best open node b
5.
f (m) f (incumbent), prune open nodes b
6.
else goal
7.
f (m) < f (incumbent)
8.
lock; incumbent m; unlock
9.
else child c
10.
c closed list nblock
11.
insert c open list appropriate nblock
Figure 3: sketch basic PBNF search, showing locking.
ordered minimum f value set. maintaining heap free nblocks ordered
nblocks best f value, approximate ideal parallel search. call algorithm Parallel
Best-N Block-First (PBNF) search.
PBNF, threads use heap free nblocks acquire free nblock best open
node. thread search acquired nblock long contains nodes better
nblock front heap. acquired nblock becomes worse best free
one, thread attempt release current nblock acquire better one contains
open nodes lower f values. layer synchronization, threads need wait
unless nblocks free. first solution found may suboptimal, search must continue
open nodes f values worse incumbent solution. Figure 3 shows high-level
pseudo-code algorithm.
PBNF designed tolerate search order approximately best-first,
freedom introduce optimizations reduce overhead. possible nblock
small number nodes better best free nblock, avoid excessive switching
requiring minimum number expansions. Due minimum expansion requirement
possible nodes expanded thread arbitrarily worse frontier node
minimum f . refer expansions speculative. viewed trading node
quality reduced contention abstract graph. Section 4.1 shows results experiment
evaluates trade off.
implementation also attempts reduce time thread forced wait lock
using non-blocking operations acquire lock whenever possible. Rather sleeping lock
cannot acquired, non-blocking lock operation (such pthread mutex trylock)
immediately return failure. allows thread continue expanding current nblock lock
busy. optimizations introduce additional speculative expansions would
performed serial best-first search.
3.1 Livelock
greedy free-for-all order PBNF threads acquire free nblocks lead livelock
domains infinite state spaces. threads always acquire new nblocks without waiting
open nodes layer expanded, possible nblock containing goal
697

fiB URNS , L EMONS , RUML , & Z HOU

never become free. assurance nblocks duplicate detection
scope ever unused time. example, imagine situation threads
constantly releasing acquiring nblocks prevent goal nblock becoming free.
fix this, developed method called hot nblocks threads altruistically release
nblock interfering better nblock. call enhanced algorithm Safe PBNF.
use term interference scope b refer set nblocks that, acquired,
would prevent b free. interference scope includes bs successors
abstract graph, predecessors too. Safe PBNF, whenever thread checks heap
free nblocks determine release current nblock, also ensures acquired
nblock better interferes (nblocks whose interference scope
acquired nblock in). finds better one, flags nblock hot. thread finds
blocking hot nblock release nblock attempt free hot nblock.
nblock b define h (b) number hot nblocks b interference scope of.
h (b) 6= 0, b removed heap free nblocks. ensures thread acquire
nblock preventing hot nblock becoming free.
Consider, example, abstract graph containing four nblocks connected linear fashion:
B C . possible execution PBNF alternate thread expanding
nblocks C . situation arrises nblocks B never considered free.
goals located nblock B then, infinite search space may livelock.
Safe variant PBNF, however, expanding either C thread make sure
check f value best open node nblock B periodically. best node B seen
better nodes C B flagged hot nblocks C
longer eligable expansion nblock B acquired.
formally, let N set nblocks, Predecessors(x ) Successors(x ) sets
predecessors successors abstract graph nblock x , H set hot nblocks,
IntScope(b) = {l N : x Successors(b) : l Predecessors(x )} interference scope
nblock b x partial order nblocks x iff minimum f
value open nodes x lower y. three cases consider
attempting set nblock b hot undirected abstract graph:
1. H IntScope(b) = {} H {x N : b IntScope(x )} = {}; none nblocks b
interferes interfere b hot, b set hot.
2. x H : x IntScope(b) x b; b interfered better nblock already
hot, b must set hot.
3. x H : x IntScope(b) b x ; b interfered nblock x worse
b x already hot. x must un-flagged hot (updating h values appropriately)
place b set hot.
Directed abstract graphs two additional cases:
4. x H : b IntScope(x ) b x ; b interfering nblock x b better x
un-flag x hot set b hot.
5. x H : b IntScope(x ) x b; b interfering nblock x x better b
set b hot.
698

fiB EST-F IRST EARCH ULTICORE ACHINES

scheme ensures never two hot nblocks interfering one another
nblock set hot best nblock interference scope. verify below,
approach guarantees property nblock flagged hot eventually become free.
Full pseudo-code Safe PBNF given Appendix A.
3.2 Correctness PBNF
Given complexity parallel shared-memory algorithms, reassuring proofs
correctness. subsection verify PBNF exhibits various desirable properties:
3.2.1 OUNDNESS
Soundness holds trivially solution returned pass goal test.
3.2.2 EADLOCK
one lock PBNF thread currently holds never attempts acquire
second time, deadlock cannot arise.
3.2.3 L IVELOCK
interaction different threads PBNF quite complex, modeled
system using TLA+ (Lamport, 2002) specification language. Using TLC model checker
(Yu, Manolios, & Lamport, 1999) able demonstrate sequence states give rise
livelock plain PBNF. Using similar model unable find example livelock
Safe PBNF using three threads 12 nblocks undirected ring-shaped abstract
graph three threads eight nblocks directed graph.
model state system represented four variables: state, acquired, isHot
Succs. state variable contains current action thread performing (either search
nextblock). acquired variable function thread ID acquired nblock
value None currently nblock. variable isHot function
nblocks either TRUE FALSE depending whether given nblock flagged hot.
Finally, Succs variable gives set successor nblocks nblock order build
nblock graph.
model two actions: doSearch doNextBlock. doSearch action models search
stage performed PBNF thread. Since interested determining livelock,
action abstracts away search procedure merely models thread may
choose valid nblock flag hot. setting nblock hot, thread changes state
next time selected perform action try acquire new nblock.
doNextBlock simulates thread choosing next nblock one available. thread
acquires nblock (if one free) sets state next time selected perform
action search.
TLA+ source model located Appendix B.
Formal proof: addition model checking, TLA+ specification language designed
allow formal proofs properties. allows properties proved unbounded space.
Using model completed formal proof hot nblock eventually become free
699

fiB URNS , L EMONS , RUML , & Z HOU

regardless number threads abstract graph. present English summary.
First, need helpful lemma:
Lemma 1 nblock n hot, least one nblock interference scope
use. Also, n interfering hot nblocks.
Proof: Initially nblocks hot. change thread searches releases
nblock. search, thread set n hot acquired nblock
interference scope n. Additionally, thread may set n hot create
interference another hot nblock. release, n hot, either final acquired nblock
interference scope released n longer hot, n still least one busy nblock
interference scope.
2
ready key theorem:
Theorem 1 nblock n becomes hot, eventually added free list
longer hot.
Proof: show number acquired nblocks interference scope hot nblock
n strictly decreasing. Therefore, n eventually become free.
Assume nblock n hot. Lemma 1, thread p nblock interference scope n, n interfering interfered hot nblocks. Assume
thread q nblock interference scope n. four cases:
1. p searches nblock. p acquire new nblock therefore number nblocks
preventing n becoming free increase. p sets nblock hot,
interference scope n Lemma 1. p release nblock sees n hot
(see case 2).
2. p releases nblock acquires new nblock free list. number acquired
nblocks interference scope n decreases one p releases nblock. Since m,
new nblock acquired p, free list, interference scope n.
3. q searches nblock. q acquire new nblock therefore number nblocks
preventing n becoming free increase. q sets nblock hot,
interference scope n Lemma 1.
4. q releases nblock (if one) acquires new nblock free list. Since m,
new nblock acquired q, free list, interference scope n
number nblocks preventing n becoming free increase.
2
prove progress property really care about:
Theorem 2 node n minimum f value eventually expanded.
Proof: consider ns nblock. three cases:
1. nblock expanded. n minimum f , front open
expanded.
700

fiB EST-F IRST EARCH ULTICORE ACHINES

2. nblock free. holds node minimum f value, front
free list selected next expansion, reducing case 1.
3. nblock free list interference scope another nblock
currently expanded. thread expanding nblock checks interference
scope, mark better nblock hot. Theorem 1, eventually reach case 2.
2
3.2.4 C OMPLETENESS
follows easily liveness:
Corollary 1 heuristic admissible search space finite, goal returned one
reachable.
Proof: heuristic admissible, inherit completeness serial A* (Nilsson, 1980)
Theorem 2. Nodes re-expanded g value improved, happen
finite number times, finite number expansions suffice exhaust search space. 2
3.2.5 PTIMALITY
PBNFs expansion order strictly best-first, operates like anytime algorithm,
optimality follows argument algorithms Anytime A* (Hansen &
Zhou, 2007).
Theorem 3 PBNF return optimal solutions.
Proof: finding incumbent solution, search continues expand nodes minimum
f value among frontier nodes greater equal incumbent solution cost. means
search terminate optimal solution.
2
discussing adapt PBNF suboptimal anytime search, first evaluate
performance optimal problem solving.

4. Empirical Evaluation: Optimal Search
implemented tested parallel heuristic search algorithms described three
different benchmark domains: grid pathfinding, sliding tile puzzle, STRIPS planning.
discuss domain turn. exception planning domain, algorithms
programmed C++ using POSIX threading library run dual quad-core Intel Xeon E5320
1.86GHz processors 16Gb RAM. planning results algorithms written independently C pseudo code Appendix A. gives us additional confidence
correctness pseudo code performance claims. planning experiments run
dual quad-core Intel Xeon X5450 3.0GHz processors limited roughly 2GB RAM. open
lists free lists implemented binary heaps except PSDD IDPSDD used
queue giving less overhead since require access minimum valued elements.
closed lists implemented hash tables. PRA* APRA* used queues incoming nodes,
hash table used detect duplicates open closed. grids sliding tiles,
701

fiB URNS , L EMONS , RUML , & Z HOU

used jemalloc library (Evans, 2006), special multi-thread-aware malloc implementation,
instead standard glibc (version 2.7) malloc, found latter scales poorly
6 threads. configured jemalloc use 32 memory arenas per CPU. planning, custom
memory manager used also thread-aware uses memory pool thread.
grids sliding tiles abstractions hand-coded and, nblock data structures created
lazily, visited part abstract graph instantiated. time taken create
abstraction accounted wall time measurements two domains. STRIPS
planning abstractions created automatically creation times abstractions
reported separately described Section 4.5.
4.1 Tuning PBNF
section present results set experiments designed test behavior
PBNF parameters changed. study effects two important parameters
PBNF algorithm: minimum expansions required switching search new nblock
size abstraction. study used twenty 5000x5000 four-connected grid pathfinding
instances unit cost moves cell 0.35 probability obstacle.
heuristic used Manhattan distance goal location. Error bars plots show 95%
confidence intervals legends sorted mean dependent variable plot.
PBNF algorithm, thread must perform minimum number expansions
able acquire new nblock searching. Requiring expansions switches
expected reduce contention nblock graphs lock could increase total number
expanded nodes. created instrumented version PBNF algorithm tracks
time threads spent trying acquire lock amount time threads
spent waiting free nblock. fixed size abstraction 62,500 nblocks
varied number threads (from 1 8) minimum expansions (1, 8, 16, 32 64 minimum
expansions).
upper left panel Figure 4 shows average amount CPU time seconds
thread spent waiting acquire lock (y-axis) minimum expansions parameter increased (x-axis). line plot represents different number threads. see
configuration used amount time trying acquire lock eight threads
one minimum expansion. number threads decreased, less contention
lock fewer threads take it. number minimum required expansions
increased contention also reduced. Around eight minimum expansions benefit increasing value seemed greatly diminish.
upper right panel Figure 4 shows results CPU time spent waiting free
nblock (y-axis) minimum expansions increased (x-axis). different amount
time waiting lock because, case, thread successfully acquired lock
found free nblocks available search. see configuration
eight threads one minimum expansions caused longest amount time waiting
free nblock. number threads decreased required number minimum
expansions increased wait time decreased. amount time spent waiting, however, seems
fairly insignificant order magnitude smaller lock time. Again, see
around eight minimum expansions benefit increasing seemed diminish.
702

fi8
7
6
5
4
3
2
1

0.3

average time waiting (seconds)

average time acquiring locks (seconds)

B EST-F IRST EARCH ULTICORE ACHINES

0.2

0.1

8
7
6
5
4
3
2
1

0.02

0.01

0.0
20

40

60

20

total nodes expanded (1K nodes)

minimum expansions

40

60

minimum expansions

2,600

2,500

8
7
6
5
4
3
2
1

2,400

20

40

60

minimum expansions

Figure 4: PBNF locking behavior vs minimum expansions grid pathfinding 62,500
nblocks. line represents different number threads.

final panel, bottom Figure 4, shows total number nodes expanded (y-axis,
thousands nodes) minimum expansions increased. Increasing minimum
number expansions thread must make switching nblock better nodes
caused search algorithm explore space may covered strict
best-first search. speculative expansions performed total number
nodes encountered search increased. also see adding threads increased
number expanded nodes too.
results experiment appears requiring eight expansions switching nblocks decreasing benefit respect locking waiting time.
non-instrumented implementation PBNF found slightly greater values minimum
expansion parameter lead best total wall times. domain use value
gave best total wall time non-instrumented PBNF implementation.
703

fiB URNS , L EMONS , RUML , & Z HOU

0.9

8
7
6
5
4
3
2
1

8
7
6
5
4
3
2
1

0.08

average time waiting (seconds)

average time acquiring locks (seconds)

1.2

0.6

0.3

0.06

0.04

0.02

0.0
50

100

150

200

250

50

total nodes expanded (1K nodes)

abstraction size (1K nblocks)

100

150

200

250

abstraction size (1K nblocks)

2,600

2,500

8
7
6
5
4
3
2
1

2,400

50

100

150

200

250

abstraction size (1K nblocks)

Figure 5: PBNF abstraction size: 5000x5000 grid pathfinding, 32 minimum expansions.

Since PBNF uses abstraction decompose search space also important understand
effect abstraction size search performance. hypothesis using abstract
states would lead small number free nblocks therefore making threads spend lot
time waiting nblock become free. hand, many abstract states
nodes nblock. happens, threads perform small
amount work exhausting open nodes nblock forced switch
new portion search space. time thread must switch nblocks contention
lock increased. Figure 5 shows results experiment performed verify
theory. plot fixed minimum expansions parameter 32 (which gave best
total wall time grid pathfinding) varied number threads (from 1 8) size
abstraction (10,000, 62,500 250,000 nblocks).
upper left panel Figure 5 shows plot amount CPU seconds spent trying acquire lock (y-axis) versus size abstraction (x-axis). expected, abstraction
coarse little time spent waiting lock, size abstraction grew
704

fiB EST-F IRST EARCH ULTICORE ACHINES

number threads increased amount time spent locking increased. eight threads
250,000 nblocks 1 second CPU time spent waiting acquire lock. suspect
threads exhausting open nodes nblocks were, therefore,
forced take lock acquire new portion search space.
upper right panel Figure 5 shows amount time threads spent waiting
nblock become free successfully acquired lock find nblocks
available. Again, suspected, amount time threads wait free nblock decreases
abstraction size increased. available nblocks, disjoint portions
search space available. experiments minimum expansions, amount
time spent waiting seems relatively insignificant compared time spent acquiring locks.
bottom panel Figure 5 shows number nodes expanded increased
size abstraction increased. finer grained abstractions algorithm expanded
nodes. time thread switches new nblock forced perform
least minimum number expansions, therefore switches, forced expansions.
4.2 Tuning PRA*
turn looking performance impact PRA* abstraction asynchronous communication. First, compare PRA* without asynchronous communication. Results
set experiments twenty 5000x5000 grid pathfinding set 250 random 15-puzzle instances solvable A* 3 million expansions shown Figure 6. line labeled
sync. (PRA*) used synchronous communication, async. sends, used synchronous receives asynchronous sends, async. receives, used synchronous sends asynchronous receives async.
(HDA*), used asynchronous communication sends receives. before, legend
sorted mean performance error bars represent 95% confidence intervals
mean. vertical lines plots life cost grid pathfinding domains show
configurations unable solve instances within 180 second time limit.
combination asynchronous sends receives provided best performance.
also see plots making sends asynchronous provided benefit
making receives asynchronous. because, without asynchronous sends, node generated stop generating thread order communicate. Even communication batched,
send may required go separate neighbor therefore single send operation may
required per-generation. receives, worst case receiving thread must stop
expansion receive next batch nodes. Since branching factor typical search space
approximately constant approximately constant factor send communications
receive communications worst case. Therefore, making sends asynchronous reduces
communication cost receives.
Figure 7 shows results experiment compares PRA* using abstraction distribute
nodes among threads versus PRA* asynchronous communication. lines labeled
follows: sync. (PRA*) used synchronous communication, async. (HDA*) used asynchronous communication sync. abst. (APRA*) used synchronous communication
used abstraction distribute nodes among threads async. abst. (AHDA*) used combination asynchronous communication abstraction. Again, vertical lines plots
life cost grid pathfinding domains show configurations unable solve instances
within 180 second time limit.
705

fiB URNS , L EMONS , RUML , & Z HOU

Grid Unit Four-way
sync. (PRA*)
async. receives
async. sends
async. (HDA*)

sync. (PRA*)
async. receives
async. sends
async. (HDA*)

30

wall time (seconds)

30

wall time (seconds)

Grid Unit Eight-way

20

20

10

10

2

4

6

8

2

4

threads
Grid Life Four-way
200

6

8

threads
Grid Life Eight-way
200

sync. (PRA*)
async. receives
async. sends
async. (HDA*)

sync. (PRA*)
async. receives
async. sends
async. (HDA*)

wall time (seconds)

wall time (seconds)

160

120

80

100

40
0
2

4

6

8

threads

2

6

8

threads

sync. (PRA*)
async. receives
async. sends
async. (HDA*)

10

wall time (seconds)

4

15-Puzzles: 250 easy

8

6

4

2

4

6

8

threads

Figure 6: PRA* synchronization: 5000x5000 grids easy sliding tile instances.

clear plots configurations PRA* used abstraction gave better
performance PRA* without abstraction grid pathfinding domain. reason
706

fiB EST-F IRST EARCH ULTICORE ACHINES

Grid Unit Four-way
sync. (PRA*)
async. (HDA*)
sync. abst. (APRA*)
async. abst. (AHDA*)

sync. (PRA*)
async. (HDA*)
sync. abst. (APRA*)
async. abst. (AHDA*)

30

wall time (seconds)

30

wall time (seconds)

Grid Unit Eight-way

20

20

10

10

2

4

6

8

2

4

threads
Grid Life Four-way
200

6

8

threads
Grid Life Eight-way
200

sync. (PRA*)
async. (HDA*)
sync. abst. (APRA*)
async. abst. (AHDA*)

sync. (PRA*)
async. (HDA*)
sync. abst. (APRA*)
async. abst. (AHDA*)

wall time (seconds)

wall time (seconds)

160

120

80

100

40

0
2

4

6

8

threads

4

6

8

threads

sync. (PRA*)
async. (HDA*)
sync. abst. (APRA*)
async. abst. (AHDA*)

10

wall time (seconds)

2

15 Puzzles: 250 easy

8

6

4

2

4

6

8

threads

Figure 7: PRA* abstraction: 5000x5000 grids easy sliding tile instances.

abstraction grid pathfinding often assign successors node expanded
back thread generated them. happens communication required
707

fiB URNS , L EMONS , RUML , & Z HOU

nodes simply checked local closed list placed local open list
duplicates. abstraction, time communication required
node edge abstract state expanded. case, children map
different abstract state communication required. experiment also shows
benefits abstraction greater benefits asynchronous communication grid
pathfinding problems. see trends sliding tile instances, however
quite pronounced; confidence intervals often overlap.
Overall, appears combination PRA* abstraction distributing nodes
among different threads using asynchronous communication gave best performance.
following section show results comparison variant PRA*, Safe
PBNF algorithm best-first variant PSDD.
4.3 Grid Pathfinding
section, evaluate parallel algorithms grid pathfinding domain. goal
domain navigate grid initial location goal location avoiding
obstacles. used two cost models (discussed below) four-way eight-way movement.
four-way grids, cells blocked probability 0.35 eight-way grids
cells blocked probability 0.45. abstraction function used maps blocks
adjacent cells abstract state, forming coarser abstract grid overlaid original
space. heuristic Manhattan distance goal location. hash values states
(which used distribute nodes PRA* HDA*) computed as: x ymax + state
location. gives minimum perfect hash value state. domain able
tune size abstraction results show execution best abstraction size
algorithm relevant.
4.3.1 F -WAY U NIT C OST
unit-cost model, move cost: one.
Less Promising Algorithms Figure 8, shows performance comparison algorithms that,
average, slower serial A*. algorithms tested 20 unit-cost four-way
movement 1200x2000 grids start location bottom left corner goal location
bottom right. x-axis shows number threads used solve instance y-axis
shows mean wall clock time seconds. error bars give 95% confidence interval
mean wall clock time legend sorted mean performance.
figure see PSDD gave worst average solution times. suspect
lack tight upper bound PSDD uses pruning. see A*
shared lock-free open closed list (LPA*) took, average, second longest amount time
solve problems. LPA*s performance improved 5 threads started drop
threads added. overhead special lock-free memory manager along
fact access lock-free data structures may require back-offs retries could account
poor performance compared serial A*. next algorithm, going top
legend, KBFS slowly increased performance threads added however
able beat serial A*. simple parallel A* implementation (PA*) using locks
open closed lists performed worse threads added four started
give slow performance increase matching KBFS. PRA* algorithm using simple
708

fiB EST-F IRST EARCH ULTICORE ACHINES

15

PSDD
LPA*
KBFS
PA*
PRA*
Serial A*

wall time (seconds)

12

9

6

3

2

4

6

8

threads

Figure 8: Simple parallel algorithms unit cost, four-way 2000x1200 grid pathfinding.

state representation based hashing function gave best performance graph fairly
erratic number threads changed, sometimes increasing sometimes decreasing. 6
8 threads, PRA* faster serial A*.
also implemented IDPSDD algorithm tries find upper bound
PSDD search using iterative deepening, results shown grid pathfinding domains. non-geometric growth number states increasing cost bound leads
poor performance iterative deepening grid pathfinding. Due poor performance
algorithms, show results remaining grid, tiles planning domains
(with exception PSDD makes reappearance STRIPS planning evaluation
Section 4.5, supply upper bound).
Promising Algorithms upper left plot Figure 9 shows performance algorithms
unit-cost four-way grid pathfinding problems. y-axis represents speedup serial A*
x-axis shows number threads use data point. Error bars indicate 95%
confidence intervals mean 20 different instances. Algorithms legend ordered
average performance. line labeled Perfect speedup shows perfect linear speedup
additional thread increases performance linearly.
practical reference point speedup shown Achievable speedup line.
perfect machine n processors, running n cores take time decreases linearly
n. real machine, however, hardware considerations memory bus contention prevent n-fold speedup. estimate overhead machines, ran sets
n independent A* searches parallel 1 n 8 calculated total time set
finish. perfect machine sets would take time set n = 1.
compute Achievable speedup ratio actual completion times time
709

fiB URNS , L EMONS , RUML , & Z HOU

Grid Unit Four-way

Grid Unit Eight-way
8

Perfect speedup
Achievable speedup
Safe PBNF
AHDA*
BFPSDD

6

speedup serial A*

speedup serial A*

8

4

Perfect speedup
Achievable speedup
Safe PBNF
AHDA*
BFPSDD

6

4

2

2

2

4

6

8

2

threads
Grid Life Four-way

6

8

6

8

threads
Grid Life Eight-way
8

Perfect speedup
Achievable speedup
Safe PBNF
AHDA*
BFPSDD

6

speedup serial A*

speedup serial A*

8

4

4

2

Perfect speedup
Achievable speedup
AHDA*
Safe PBNF
BFPSDD

6

4

2

2

4

6

8

threads

speedup serial A*

8

2

4

threads

15 Puzzles: 250 easy
Perfect speedup
Achievable speedup
Safe PBNF
AHDA*

6

4

2

2

4

6

8

threads

Figure 9: Speedup results grid pathfinding sliding tile puzzle.

set n = 1. threads given completion times sets, hC1 , C2 , ..., Cn i,
1
achievable speedup(t) = tC
Ct .
710

fiB EST-F IRST EARCH ULTICORE ACHINES

upper left panel shows comparison AHDA* (PRA* asynchronous communication abstraction), BFPSDD Safe PBNF algorithm larger (5000x5000) unit-cost
four-way problems. Safe PBNF superior algorithms, steadily decreasing solution times threads added average speedup serial A* 6x
using eight threads. AHDA* less stable performance, sometimes giving sharp speedup
increase sometimes giving decreased performance threads added. seven
threads AHDA* gave best performance, able reach 6x speedup serial A*
search. BFPSDD algorithm solved problems faster threads added however
competitive PBNF AHDA* giving 3x speedup serial A* eight
threads.
4.3.2 F -WAY L IFE C OST
Moves life cost model cost row number state move
performedmoves top grid free, moves bottom cost 4999 (Ruml & Do,
2007). differentiates shortest cheapest paths shown
important distinction (Richter & Westphal, 2010; Cushing, Bentor, & Kambhampati, 2010).
left center plot Figure 9 shows results format unit-cost variant
number threads x axis speedup serial A* axis. average, Safe PBNF
gave better speedup AHDA*, however AHDA* outperformed PBNF six seven threads.
eight threads, however, APRA* perform better seven threads. algorithms achieve speedups close Achievable speedup domain.
BFPSDD gave worst performance increase threads added reaching 3x
speedup.
4.3.3 E IGHT-WAY U NIT C OST
eight-way movement path
planning problems, horizontal vertical moves cost 1,
diagonal movements cost 2. real-valued costs make domain different previous
two path planning domains. upper right panel Figure 9 shows number threads x
axis speedup serial A* axis unit cost eight-way movement domain. see
Safe PBNF gave best average performance reaching 6x speedup eight threads.
AHDA* outperform Safe PBNF average, however able achieve 6x
speedup serial A* seven threads. however, see AHDA* give
stable performance increases threads. BFPSDD improved threads added
eight never reached 3x speedup.
4.3.4 E IGHT-WAY L IFE C OST
model combines eight-way movement life cost models; tends difficult path planning domain presented paper. right center panel Figure 9 shows threads
x axis speedup serial A* axis. AHDA* gave best average speedup
serial A* search, peaking 6x speedup seven threads. Although outperformed Safe
PBNF average eight threads AHDA* sharp decrease performance reaching
almost 5x speedup Safe PBNF around 6x speedup serial A*. BFPSDD peaks
3x speedup eight threads.
711

fiB URNS , L EMONS , RUML , & Z HOU

AHDA* minus Safe PBNF wall time (seconds)

15 puzzles 250 easy AHDA* vs Safe PBNF paired difference
(AHDA*) - (Safe PBNF)
zero

2

1

0
2

4

6

8

threads

Figure 10: Comparison wall clock time Safe PBNF versus AHDA* sliding tile puzzle.

4.4 Sliding Tile Puzzle
sliding tile puzzle common domain benchmarking heuristic search algorithms.
results, use 250 randomly generated 15-puzzles serial A* able solve within 3 million
expansions.
abstraction used sliding tile puzzles ignores numbers set tiles.
example, results shown Safe PBNF bottom panel Figure 9 use abstraction
looks position blank, one two tiles. abstraction gives 3360 nblocks. order
AHDA* get maximum amount expansions map back expanding thread (as
described grids), abstraction uses one, two three tile. Since position
blank ignored, state generation move one, two three tiles generate
child nblock parent therefore requiring communication. heuristic
used algorithms Manhattan distance heuristic. hash value used tiles states
perfect hash value based techniques presented Korf Schultze (2005).
bottom panel Figure 9 shows results AHDA*, Safe PBNF sliding
tiles puzzle instances. plot number threads x axis speedup serial
A* axis. Safe PBNF best mean performance overlap confidence
intervals AHDA*. BFPSDD unable show speedup serial A* performance
shown plot.
sliding tile puzzles vary much difficulty, domain also paireddifference test, shown Figure 10. data used Figure 10 collected set
runs shown bottom panel Figure 9. y-axis figure, however, average,
instances, time AHDA* took instance minus time Safe PBNF
took. paired test gives powerful view algorithms relative performance. Values
greater 0.0 represent instances Safe PBNF faster AHDA* values lower
712

fiB EST-F IRST EARCH ULTICORE ACHINES

0.0 represent instances AHDA* faster. error bars show 95% confidence
interval mean. clearly see Safe PBNF algorithm significantly faster
AHDA* across numbers threads 1 8.
4.5 STRIPS Planning
addition path planning sliding tiles domains, algorithms also embedded
domain-independent optimal sequential STRIPS planner. contrast previous two domains
node expansion quick therefore difficult achieve good parallel speedup,
node expansion STRIPS planning relatively slow. planner used experiments uses
regression max-pair admissible heuristic Haslum Geffner (2000). abstraction
function used domain generated dynamically per-problem basis and, following Zhou
Hansen (2007), time taken account solution times presented
algorithms. abstraction function generated greedily searching space possible
abstraction functions (Zhou & Hansen, 2006). algorithm needs evaluate one candidate abstraction unselected state variables, trivially parallelized
multiple threads work different candidate abstractions.
Table 1 presents results A*, AHDA*, PBNF, Safe PBNF, PSDD (given optimal upper
bound pruning using divide-and-conquer solution reconstruction), APRA* BFPSDD.
values cell total wall time seconds taken solve instance. value
indicates program ran memory. best result problem results
within 10% best marked bold. Generally, parallel algorithms able
solve instances faster allowed threads. parallel algorithms
able solve instances much faster serial A* seven threads. PBNF algorithm (either
PBNF Safe PBNF) gave best solution times three domains. Interestingly,
plain PBNF often little faster safe version, failed solve two problems.
likely due livelock, although could also simply hot nblocks fix forces
Safe PNBF follow different search order PBNF. AHDA* tended give second-best
solution times, followed PSDD given optimal solution cost up-front pruning.
BFPSDD often better APRA*,
column, labeled Abst. shows time taken parallel algorithms serially
generate abstraction function. Even abstraction generation time added solution
times parallel algorithms outperform A* seven threads, except block-14 domain
time taken generate abstraction actually longer time A* took solve
problem.
4.6 Understanding Search Performance
seen PBNF algorithm tends better performance AHDA* algorithm
optimal search. section show results set experiments attempts
determine factors allow PBNF perform better domains. considered three
hypotheses. First, PBNF may achieve better performance expands fewer nodes f
values greater optimal solution cost. Second, PBNF may achieve better search performance
tends many fewer nodes priority queue AHDA*. Finally, PBNF
may achieve better search performance spends less time coordinating threads.
following subsections show results experiments performed test
713

fiB URNS , L EMONS , RUML , & Z HOU

threads
logistics-6
blocks-14
gripper-7
satellite-6
elevator-12
freecell-3
depots-7
driverlog-11
gripper-8

threads
logistics-6
blocks-14
gripper-7
satellite-6
elevator-12
freecell-3
depots-7
driverlog-11
gripper-8

threads
logistics-6
blocks-14
gripper-7
satellite-6
elevator-12
freecell-3
depots-7
driverlog-11
gripper-8

A*
1
2.30
5.19
117.78
130.85
335.74
199.06




1
1.17
6.21
39.58
77.02
150.39
127.07
156.36
154.15
235.46

1
1.44
7.37
62.61
95.11
215.19
153.71
319.48
334.28
569.26

AHDA*
1
3
5
7
1.44
0.70 0.48 0.40
7.13
5.07 2.25 2.13
59.51 33.95 15.97 12.69
95.50 33.59 24.11 18.24
206.16 96.82 67.68 57.10
147.96 93.55 38.24 27.37
299.66 126.34 50.97 39.10
315.51 85.17 51.28 48.91
532.51 239.22 97.61 76.34
SafePBNF
3
5
0.64
0.56
2.69
2.20
16.87
11.23
24.09
17.29
53.45
34.23
47.10
38.07
63.04
42.91
59.98
38.84
98.21
63.65

7
0.62
2.02
9.21
13.67
27.02
37.02
34.66
31.22
51.50

APRA*
3
5
7
0.75
1.09
0.81
5.30
3.26
2.92
43.13 37.62 26.78
42.85 67.38 52.82
243.24 211.45 169.92
122.00 63.47 37.94
138.30 67.24 49.58
99.37 89.73 104.87
351.87 236.93 166.19

1
1.20
6.36
65.74
61.53
162.76
126.31
159.98
155.93
387.81

1
1.27
6.28
39.66
68.14
156.64
185.68


229.88

PBNF
3
5
0.72 0.58
3.76 2.70
16.43 10.92
34.15 20.84
56.25 34.84
64.06 44.05




95.63 60.87

PSDD
3
5
0.78
0.68
3.57
2.96
29.37
21.88
23.56
16.71
62.68
43.34
53.76
45.47
73.00
57.65
63.20
41.85
172.01
120.79

BFPSDD
1
3
5
2.11
1.06 0.79
7.78
4.32 3.87
41.56 18.02 12.21
62.01 24.06 20.43
151.50 58.52 40.95
131.30 57.14 47.74
167.24 66.89 48.32
152.08 61.63 42.81
243.44 101.11 70.84

Table 1: Wall time STRIPS planning problems.

714

7
0.53
2.63
8.57
16.57
26.72
36.08


48.32

7
0.64
2.87
19.19
13.26
36.66
43.71
54.70
34.02
105.54
Abst.

7
0.71
3.40
10.20
13.54
32.48
45.07
42.68
34.70
59.18

1
0.42
7.9
0.8
1
0.7
17
3.6
9.7
1.1

fiB EST-F IRST EARCH ULTICORE ACHINES

AHDA*
Safe PBNF

AHDA*
Safe PBNF

6e+08

4e+07

Cumulative expansions

Cumulative expansions

5e+07

3e+07

2e+07

4e+08

2e+08

1e+07

0

0
0.7

0.8

0.9

1

Factor optimal cost

0.6

0.9

1.2

Factor optimal cost

Figure 11: Cumulative normalized f value counts nodes expanded eight threads unitcost four-way grid pathfinding (left) 15-puzzle (right).

three hypotheses. results experiments agree first two hypotheses, however,
appears third hypothesis hold and, fact, PBNF occasionally spends time
coordinating threads AHDA*.
4.6.1 N ODE Q UALITY
PBNF AHDA* merely approximate best-first order, may expand
nodes f values greater optimal solution cost. thread expands node
f value greater optimal solution cost effort waste nodes
must expanded searching optimal solution f values less
optimal cost. addition this, search algorithms may re-expand nodes lower
cost path found. happens work wasted first sub-optimal expansion
node.
Threads PBNF able choose nblock expand based quality nodes
free nblocks. AHDA*, however, thread must expand nodes assigned
it. hypothesized PBNF may expand fewer nodes f values greater
optimal solution cost threads control quality nodes
choose expand.
collected f value node expanded PBNF AHDA*. Figure 11 shows
cumulative counts f values nodes expanded PBNF AHDA* set
unit-cost four-way 5000x5000 grid pathfinding instances used Section 4.3 (right)
15-puzzle instances used Section 4.4 (left). plots, x axis shows f value
expanded nodes factor optimal solution cost given instance. axis shows
cumulative count nodes expanded given normalized f set instances.
715

fiMean CPU time (seconds)

B URNS , L EMONS , RUML , & Z HOU

3e-05

2e-05

1e-05

0

SafePBNF
AHDA*
Grid pathfinding

SafePBNF
AHDA*
15-puzzle

Figure 12: Mean CPU time per open list operation.
looking y-location right-most tip line find total number nodes
expanded algorithm summed instances.
left panel Figure 11 see algorithms tended expand
small number nodes f values greater optimal solution cost grid
pathfinding domain. AHDA* algorithm expanded nodes total set instances.
PBNF AHDA* must expand nodes optimal solution cost.
this, way AHDA* greater number expansions nodes factor
1 re-expanded nodes. appears AHDA* re-expanded nodes PBNF
seems account fact AHDA* expanded nodes total.
right half Figure 11 shows results 15-puzzle. see that, again, AHDA*
expanded nodes total PBNF. domain algorithms expanded approximately
number nodes f values less optimal solution cost. also see
plot AHDA* expanded many nodes f values greater equal
optimal solution cost. summary, PBNF expanded fewer nodes better quality nodes
AHDA* grid pathfinding sliding tiles domains. speculate may happen
PBNF threads allowed choose portion space search
choose based low f value. AHDA* threads must search nodes map
nodes may good.
4.6.2 PEN L IST IZES
found that, since PBNF breaks search space many different nblocks, tends
data structures many fewer entries AHDA*, breaks search space
based number threads. Since interested general-purpose algorithms handle
domains real-valued costs (like eight-way grid pathfinding) PBNF AHDA* use binary
heaps implement open lists. PBNF one heap per nblock (that one per abstract state)
whereas AHDA* one heap per thread. number nblocks greater
716

fiB EST-F IRST EARCH ULTICORE ACHINES

number threads AHDA* many nodes PBNF heaps. causes
heap operations AHDA* take longer heap operations PBNF.
cost operations large heaps shown greatly impact overall performance
algorithm (Dai & Hansen, 2007). order determine extent large heaps effect
performance AHDA* added timers heap operations algorithms. Figure 12
shows mean CPU time single open list operation unit-cost four-way grid pathfinding
domain 15-puzzle. boxes show second third quartiles line drawn
across median. whiskers show extremes data except data points residing
beyond first third quartile 1.5 times inter-quartile range signified
circle. shaded rectangle shows 95% confidence interval mean. see that,
cases, AHDA* tended spend time performing heap operations PBNF
typically spent nearly time per heap operation. Heap operations must performed
node expanded may required node generation. Even though times
tens microseconds frequency operations high single search.
Finally, described Hansen Zhou (2007), reduction open list sizes also explain good single thread performance PBNF experiences STRIPS planning (see Table 1).
Hansen Zhou point that, although A* optimally efficient terms node expansions,
necessarily optimal respect wall time. found benefit managing smaller
open lists enabled Anytime weighted A* algorithm outperform A* wall time even though
expanded nodes converging optimal solution. describe Section 9,
good single thread performance may also caused speculative expansions pruning.
4.6.3 C OOORDINATION OVERHEAD
third hypothesis amount time algorithm spent coordination overhead might differ. parallel algorithms must spend time accessing data structures
shared among multiple threads. cause overhead two places. first place coordination overhead seen synchronization access shared data structures. PBNF
two modes locking nblock graph. First, thread ownership nblock open
nodes remain expanded use try lock work could
done fails acquire lock. Otherwise, nodes thread could expand
attempt acquire lock nblock graph using normal operation blocks
failure. AHDA* use try lock receive queue expansion nodes
queue open list. implementation AHDA* use blocking lock
operation thread nodes remaining expand nodes remaining send
receive buffers.
second place overhead may incurred threads nodes expand.
PBNF occurs thread exhausts current nblock free nblocks
acquire. thread must wait new nblock becomes free. AHDA* open nodes map
thread may nodes expand. situation thread busy-wait
node arrives receive queue. either situation, locking waiting, time wasted
threads actively searching space.
evaluating coordination overhead, combine amount time spent waiting
lock amount time waiting without nodes expand. Figure 13 shows per-thread
coordination times locks, waiting sum two normalized total wall time.
717

fipercentage wall time

B URNS , L EMONS , RUML , & Z HOU

8

4

percentage wall time

SafePBNF AHDA*
Locks

SafePBNF AHDA*
Wait

SafePBNF AHDA*
Sum

SafePBNF AHDA*
Wait

SafePBNF AHDA*
Sum

80

40

SafePBNF AHDA*
Locks

Figure 13: Per-thread ratio coordination time wall time unit-cost four-way pathfinding (top)
15-puzzle (bottom).

Unlike previous set boxplots, individual data points residing extremes signified
circles order improve readability. Locks column plot shows distribution
times spent thread waiting lock, Wait column shows distribution times
threads spent waiting without nodes available expand Sum column shows
distribution sum mean lock wait times.
left side Figure 13 shows results grid pathfinding. Locks column see
threads AHDA* spent almost time acquiring locks. expected AHDA*
uses asynchronous communication. appears amount time threads PBNF spent
acquiring locks significantly greater AHDA*. Wait column plot
shows PBNF AHDA* appeared threads spend nearly amount time
waiting without nodes expand. Finally, Sum column shows threads PBNF
spent time overall coordinating threads.
bottom half Figure 13 shows coordination overhead 15-puzzle domain. Again,
see threads AHDA* spent almost time acquiring lock. Individual threads PBNF,
however, tended spend larger fraction time waiting locks sliding tiles domain
718

fiB EST-F IRST EARCH ULTICORE ACHINES

grid pathfinding. Wait column figure see AHDA* spent
time PBNF without nodes expand. Finally, see that, all, PBNF spent time
coordinating threads AHDA*.
Overall experiments verified first two hypotheses PBNF expanded better
quality nodes AHDA* spent less time performing priority queue operations
AHDA*. also found third hypothesis hold threads PBNF tended
coordination overhead AHDA* seems out-weighed two
factors.
4.7 Summary
section shown results empirical evaluation optimal parallel best-first
search algorithms. shown several simple parallel algorithms actually slower
serial A* search even offered computing power. Additionally showed empirical results set algorithms make good use parallelism outperform serial A*.
Overall Safe PBNF algorithm gave best consistent performance latter set
algorithms. AHDA* variant PRA* second fastest mean performance domains.
also shown using abstraction PRA* style search distribute nodes among
different threads give significant boost speed reducing amount communication. modification PRA* appears lot helpful simply using asynchronous
communication. Using improvements conjunction (AHDA*), yields competitive
algorithm additional feature relying shared memory.
Finally, performed set experiments attempt explain Safe PBNF tended
give better search performance AHDA*. experiments looked three factors: node quality,
open list sizes thread-coordination overhead. concluded PBNF faster
expands fewer nodes suboptimal f values takes less time perform priority queue
operations.

5. Bounded Suboptimal Search
Sometimes acceptable even preferable search solution optimal. Suboptimal
solutions often found much quickly lower memory requirements optimal
solutions. section show create bounded-suboptimal variants best
optimal parallel search algorithms.
Weighted A* (Pohl, 1970), variant A* orders search f (n) = g(n) + w h(n),
w > 1, probably popular suboptimal search. guarantees that, admissible
heuristic h weight w , solution returned w -admissible (within w factor
optimal solution cost) (Davis, Bramanti-Gregor, & Wang, 1988).
possible modify AHDA*, BFPSDD, PBNF use weights find suboptimal solutions, call algorithms wAHDA*, wBFPSDD wPBNF. optimal search,
parallelism implies strict f search order followed. proof weighted A*s
w -optimality depends crucially following strict f order, parallel variants must
prove quality solution either exploring pruning nodes. Thus finding effective
pruning rules important performance. assume throughout h admissible.
719

fiB URNS , L EMONS , RUML , & Z HOU

5.1 Pruning Poor Nodes
Let current incumbent solution w suboptimality bound. node n clearly
pruned f (n) g(s). according following theorem, need retain n
optimal path solution factor w better s. much stronger rule.
Theorem 4 prune node n w f (n) g(s) without sacrificing w -admissibility.
Proof: incumbent w -admissible, safely prune node, consider case
g(s) > w g(opt), opt optimal goal. Note without pruning, always exists
node p open list (or generated) best path opt. Let f cost
optimal solution. admissibility h definition p, w f (p) w f (p) = w g(opt).
pruning rule discards p, would imply g(s) w f (p) thus g(s) w g(opt),
contradicts premise. Therefore, open node leading optimal solution pruned
incumbent w -admissible. search terminate open empty
terminate incumbent w -admissible replaced optimal solution.
2
make explicit useful corollary:
Corollary 2 prune node n f (n) g(s) without sacrificing w -admissibility.

Proof: Clearly w f (n) f (n), Theorem 4 applies.
2
corollary, use pruning shortcut: open list sorted increasing f
node front f g(s), prune entire open list.
5.2 Pruning Duplicate Nodes
searching inconsistent heuristic, weighted A*, possible search
find better path already-expanded state. Likhachev, Gordon, Thrun (2003) noted that,
provided underlying heuristic function h consistent, weighted A* still return w admissible solution duplicate states pruned search. ensures state
expanded search. Unfortunately, proof depends expanding
exactly best-first order, violated several parallel search algorithms consider
here. However, still prove duplicates dropped. Consider expansion
node n re-generates duplicate state already expanded. propose
following weak duplicate dropping criterion: new copy pruned old g(d )
g(n) + w c (n, ), c (n, ) optimal cost node n node .
Theorem 5 Even weak dropping rule applied, always node p optimal
solution path open g(p) w g (p).
Proof: proceed induction iterations search. theorem clearly holds expansion
initial state. induction step, note node p removed open
expanded. child pi lies along optimal path added open, theorem holds.
way wont added exists previous duplicate copy pi pruning rule holds,
i.e., g(pi ) g(pi1 ) + w c (pi1 , pi ). inductive hypothesis, g(pi1 ) w g (pi1 ),
2
definition g (pi1 ) + c (pi1 , pi ) = g (pi ), g(pi ) w g (pi ).
Note use technique prohibits using global minimum f value lower bound
optimal solutions cost, g values inflated factor w . However,
incumbent search global minimum f value g(s), serial
weighted A* search, w -admissibility assured:
720

fiB EST-F IRST EARCH ULTICORE ACHINES

Corollary 3 minimum f value g(s), incumbent, g(s)
w g (opt)
Proof: Recall node p Theorem 5. g(s) f (p) = g(p) + w h(p) w (g (p) + h(p))
w g (opt).
2
remains empirical question whether pruning rather weak criterion lead better
performance practice. results indicate provide advantage grid pathfinding
domain. Results presented Section 6.1. noted that, extra pruning
preserve w -admissibility, may result solutions lower quality resulting search
without pruning.
5.3 Optimistic Search
Korf (1993) showed weighted A* typically returns solutions better bound, w ,
would suggest. take advantage this, Thayer Ruml (2008) use optimistic approach
bounded suboptimal search works two stages: aggressive search using weight greater
desired optimality bound find incumbent solution cleanup phase prove
incumbent indeed within bound. intuition behind approach wA*
find solution within tight bound (much tighter w g(opt)), search continue
looking nodes f order bound proved. Thayer Ruml show that, indeed,
approach surpass speed wA* given optimality bound. implemented
optimistic version PBNF (oPBNF).
One requirements oPBNF must access minimum f value
nodes order prove bound incumbent solution. aggressive search stage,
open lists heap free nblocks sorted f instead f couple additions need
made. First, nblock additional priority queue containing open search nodes sorted
f . call queue openf . openf queue simply maintained adding removing
nodes nodes added removed f ordered open list nblock. Second,
priority queue, called minf , nblocks maintained, sorted lowest f value
nblock time last release. minf used track lower bound minimum f value
nodes. accomplished lazily updating minf nblock released
thread. thread releases nblock, sifts released nblock successors
new positions minf queue. nblocks whose minimum f values could
changed releasing thread. Since global minimum f value nodes strictly
increasing (assuming consistent heuristic) guarantee f value front
minf queue strictly increasing lower bound global minimum f value
given time. Using lower bound, able prove whether incumbent solution
properly bounded.
oPBNF needs decide switch aggressive search phase cleanup
phase optimistic search. originally proposed, optimistic search performs aggressive search
first incumbent found switches cleanup (when f (n) g(s), n
best node based f incumbent solution) aggressive search (when f (n) <
g(s)) hedge case current incumbent within bound. oPBNF,
left choice: switch aggressive search cleanup global basis
per-nblock basis. choose switch per-nblock basis assumption
threads could cleaning areas search space low f values threads look
721

fiB URNS , L EMONS , RUML , & Z HOU

better solutions areas search space low f values. oPBNF, deciding
one nblock better another (when deciding switch set nblock hot), choice
longer based solely best f value given nblock, instead based f
value first, f value break ties best f value bound incumbent.
acquiring new nblock, thread takes either free nblock best f value best f
value depending nblock better (where notion better described previous
sentence). Finally, expanding nodes, thread selects aggressive search cleanup based
criteria standard optimistic search nodes within acquired nblock.

6. Empirical Evaluation: Bounded Suboptimal Search
implemented tested weighted versions parallel search algorithms discussed above:
wAHDA*, wAPRA*, wBFPSDD, wPBNF oPBNF. algorithms prune nodes based
w f criterion presented Theorem 4 prune entire open lists f Corollary 2. Search
terminates nodes pruned incumbent solution. experiments
run three benchmark domains optimal search: grid pathfinding, sliding tile
puzzle, STRIPS planning.
6.1 Grid Pathfinding
Results presented Table 2 show performance parallel search algorithms terms
speedup serial weighted A* grid pathfinding problems. Duplicate states already
expanded dropped serial wA* algorithm, discussed Likhachev et al. (2003).
rows table show number threads different algorithms whereas columns
weights used various domains. entry shows mean speedup serial weighted
A*. performed Wilcoxon signed-rank test determine mean values significantly
different; elements bold represent values significantly different (p < 0.05)
best mean value given column. general, parallel algorithms show increased
speedup threads added low weights, decreased speedup weight increased.
unit-cost four-way movement grids, weights 1.1, 1.2 wPBNF algorithm
fastest algorithms tested reaching five times speed wA* weight
1.1 4.5x weight 1.2 . weight 1.4 wPBNF, wBFPSDD wAHDA*
show significant difference performance 8 threads. wAHDA* best speed
algorithms weight 1.8. wAPRA* never gave best performance domain.
eight-way movement grids wPBNF gave best performance weight 1.1 1.4,
although latter case best performance decrease speed wA*
achieved 1 thread. wAHDA* fastest weight 1.2, however, scale
expected number threads increased. Finally wAPRA* gave least performance
decrease weighted A* weight 1.8 1 thread. case, algorithms slower
serial weighted A* wAPRA* gave closest performance serial search. wBFPSDD
never gave best performance domain.
life-cost domain wPBNF outperformed algorithms weights 1.1, 1.2 1.4.
weight 1.8, wPBNFs performance quickly dropped, however wAHDA* best results
4x speedup wA*, although performance appears inconsistent significantly different much lower speedup values weight.
wAPRA* never gave best performance domain.
722

fiwAPRA*

wAHDA*

threads

wBFPSDD

wPBNF

B EST-F IRST EARCH ULTICORE ACHINES

1
2
3
4
5
6
7
8
1
2
3
4
5
6
7
8
1
2
3
4
5
6
7
8
1
2
3
4
5
6
7
8

Unit Four-way Grids
1.1
1.2
1.4
1.8
0.98 0.91 0.51 0.73
1.74 1.65 1.07 0.87
2.47 2.33 1.62 0.89
3.12 2.92 2.13 0.90
3.76 3.52 2.48 0.91
4.30 3.99 2.80 0.89
4.78 4.40 3.01 0.88
5.09 4.66 3.11 0.87
0.82 0.84 0.96 0.94
1.26 1.26 1.45 0.91
1.65 1.65 1.90 0.84
1.93 1.92 2.09 0.79
2.24 2.24 2.36 0.75
2.51 2.51 2.58 0.71
2.73 2.69 2.63 0.67
2.91 2.84 2.68 0.63
0.87 0.79 0.32 0.56
1.35 1.17 0.63 0.84
1.90 1.69 1.30 1.30
2.04 2.10 1.57 1.30
1.77 2.08 1.79 0.97
3.23 3.03 2.18 1.33
3.91 3.78 2.56 1.30
3.79 3.64 3.02 1.13
0.88 0.81 0.32 0.56
0.51 0.44 0.22 0.36
0.36 0.32 0.20 0.26
0.50 0.44 0.30 0.41
0.55 0.56 0.39 0.48
0.52 0.49 0.31 0.30
0.73 0.67 0.40 0.36
1.09 1.07 0.82 0.77

weight
Unit Eight-way Grids
1.1
1.2
1.4
1.8
0.93 1.37 0.73 0.74
1.65 1.82 0.57 0.66
2.36 1.77 0.55 0.61
2.97 1.72 0.53 0.58
3.55 1.67 0.52 0.56
4.04 1.61 0.50 0.54
4.40 1.55 0.49 0.51
4.70 1.49 0.45 0.46
0.87 0.79 0.43 0.33
1.37 1.10 0.43 0.35
1.80 1.22 0.41 0.33
2.13 1.25 0.42 0.33
2.47 1.31 0.39 0.32
2.74 1.21 0.36 0.30
2.94 1.26 0.34 0.29
3.10 1.23 0.32 0.26
0.79 1.10 0.66 0.76
1.04 1.99 0.62 0.61
2.08 2.93 0.64 0.62
2.48 2.84 0.56 0.54
2.49 2.52 0.42 0.41
3.73 2.83 0.49 0.45
4.45 2.89 0.45 0.41
4.39 2.58 0.37 0.38
0.80 1.11 0.67 0.77
0.35 0.69 0.31 0.28
0.41 0.65 0.23 0.22
0.43 0.73 0.22 0.19
0.49 0.87 0.23 0.19
0.50 0.65 0.16 0.14
0.62 0.73 0.17 0.14
0.89 1.38 0.28 0.22

Life Four-way Grids
1.1
1.2
1.4
1.8
0.65 0.66 0.84 0.67
1.15 1.17 1.59 0.39
1.65 1.67 2.32 0.39
2.08 2.10 2.96 0.49
2.53 2.55 3.63 1.49
2.94 2.95 4.20 1.64
3.31 3.33 4.63 2.12
3.61 3.64 5.11 1.06
0.52 0.53 0.58 0.60
0.83 0.83 0.92 0.76
1.10 1.09 1.26 0.84
1.29 1.29 1.48 0.89
1.53 1.51 1.61 0.93
1.73 1.72 1.78 0.93
1.91 1.89 1.94 0.91
2.06 2.03 2.10 0.85
0.56 0.55 0.71 0.22
0.88 0.86 1.29 0.32
1.09 1.39 1.86 0.56
1.60 1.64 2.24 0.56
1.88 1.92 2.58 0.41
2.15 2.17 3.02 1.50
2.39 2.41 3.50 1.07
2.38 2.42 3.55 4.16
0.56 0.56 0.72 0.23
0.35 0.34 0.46 0.12
0.23 0.26 0.32 0.10
0.42 0.43 0.55 0.16
0.54 0.56 0.67 0.20
0.39 0.39 0.49 0.13
0.49 0.49 0.65 0.18
1.00 0.98 1.22 0.42

Table 2: Grid Pathfinding: Average speedup serial weighted A* various numbers
threads.

723

fiB URNS , L EMONS , RUML , & Z HOU

threads
1
2
3
4
5
6
7
8

1.4
0.68
1.35
1.48
1.70
2.04
2.16
2.55
2.71

wPBNF
1.7
2.0
0.44 0.38
0.81 1.00
0.97 0.85
1.20 0.93
1.38 0.97
1.30 1.19
1.46 1.04
1.71 1.10

3.0
0.69
0.63
0.56
0.60
0.74
0.67
0.62
0.60

1.4
0.61
1.18
1.53
1.91
2.33
2.28
2.71
2.70

wAHDA*
1.7
2.0
0.60 0.59
1.11 1.32
1.30 1.40
1.57 1.55
1.70 1.27
1.72 1.24
1.50 1.03
1.51 1.24

3.0
0.54
0.78
0.73
0.74
0.66
0.52
0.44
0.44

threads
1
2
3
4
5
6
7
8

1.4
0.65
0.87
1.05
1.09
1.27
1.33
1.49
1.53

wBFPSDD
1.7
2.0
0.61 0.44
0.74 0.49
0.72 0.63
1.00 0.57
0.97 0.65
1.17 0.61
1.10 0.59
1.08 0.62

3.0
0.35
0.43
0.46
0.45
0.40
0.39
0.34
0.33

1.4
0.61
1.18
1.45
1.77
2.32
2.18
2.63
2.34

wAPRA*
1.7
2.0
0.59 0.59
1.08 1.36
1.25 1.32
1.50 1.36
1.62 1.26
1.54 1.83
1.40 1.09
1.61 1.22

3.0
0.54
0.78
0.78
0.62
0.64
0.47
0.43
0.41

Table 3: 15-puzzle: Average speedup serial weighted A* various numbers threads.

oPBNF

threads
1
2
3
4
5
6
7
8

Unit Four-way Grids
1.1
1.2
1.4
1.8
0.54 0.99 0.74 0.47
0.99 2.00 1.05 0.45
1.40 2.89 1.19 0.45
1.76 3.62 1.26 0.44
2.11 4.29 1.33 0.43
2.43 4.84 1.35 0.44
2.70 5.44 1.37 0.43
2.97 6.01 1.39 0.42

Unit Eight-way Grids
1.1
1.2
1.4
1.8
0.74 0.76 0.09 0.05
1.26 0.71 0.09 0.05
1.64 0.70 0.09 0.05
1.90 0.69 0.09 0.05
2.09 0.68 0.08 0.05
2.21 0.68 0.08 0.05
2.29 0.67 0.08 0.04
2.30 0.67 0.08 0.04

250 easy 15-puzzles
1.4
1.7
2.0
3.0
0.56 0.58 0.77 0.60
0.85 1.07 0.83 0.72
1.06 0.94 0.79 0.80
1.01 0.82 0.93 0.69
1.20 1.21 0.97 0.74
1.32 0.83 0.99 0.67
1.14 0.93 0.88 0.71
1.33 0.87 0.81 0.64

Table 4: Average speedup serial optimistic search various numbers threads.

724

fiB EST-F IRST EARCH ULTICORE ACHINES

Overall, see wPBNF often best speedup results eight threads weights
less 1.8. wAHDA*, however, gave best performance weight 1.8 across grid
pathfinding domains. wBFPSDD often gave speedup serial weighted A*, however
quite competitive wPBNF wAHDA*. wAPRA* rarely able outperform
serial search.
Table 4 shows results optimistic variant PBNF algorithm (oPBNF). cell
table shows mean speedup oPBNF serial optimistic search. again, bold
cells entries significantly different best value column. unit-cost
four-way pathfinding problems oPBNF gave performance increase optimistic search two
threads weights less 1.8. weight 1.2, oPBNF tended give
best speedup, may optimistic search performed poorly particular weight.
unit-cost eight-way pathfinding, see oPBNF performs comparably unit-cost domain
weight 1.1, however, higher weights algorithm slower serial optimistic
search.
6.2 Sliding Tile Puzzles
sliding tiles domain, used standard Korf 100 15-puzzles (Korf, 1985). Results
presented Table 3. wPBNF, wAHDA* wAPRA* tended give comparable performance
sliding tile puzzle domain values significantly different weights
1.4 1.7. weight 3.0, wAHDA* gave least performance decrease weighted A*
2 threads.
right-most column Table 4 shows results optimistic PBNF 250 15-puzzle
instances solvable A* fewer 3 million expansions. oPBNF gave best performance weight 1.4. weights greater 1.4 oPBNF unable outperform serial
counterpart. greater weights oPBNF tended perform better smaller numbers threads.
One trend seen sliding tiles domain grid pathfinding domain
speedup parallel algorithms serial suboptimal search decreases weight
increased. suspect decrease relative performance due problems becoming
sufficiently easy (in terms node expansions) overhead parallelism becomes harmful
overall search. problems require many node expansions cost parallelism (additional
expansions, spawning threads, synchronization albeit small, waiting threads complete, etc.)
amortized search effort. problems require small number expansions,
however, overhead accounts total search time serial algorithm could
potentially faster.
confirm understanding effect problem size speedup, Figure 14 shows comparison wPBNF weighted A* 100 Korf 15-puzzle instances using eight threads.
point represents run one instance particular weight, y-axis represents wPBNF
speedup relative serial wA*, x-axis represents number nodes expanded wA*.
Different glyphs represents different weight values used wPBNF wA*. figure
shows that, wPBNF outperform wA* easier problems, benefits wPBNF
wA* increased problem difficulty increased. speed gain instances run
weight 1.4 (the lowest weight tested) leveled 10 times faster wA*.
machine eight cores. instances seem speedup greater
10x. explained speculative expansions wPBNF performs may
725

fiB URNS , L EMONS , RUML , & Z HOU

Sliding Tiles wPBNF v.s. wA*
W

log10(Times faster wA*)

1
W



WW W
W
W
W

WW
W
W
WS
W WW
WSS W WW
W W W WW
SS
W
W
W
W
W
W W
W W WW
SS

W
W
WSW SWWW
W
SS
WS SSW
W

SW W
WWW
WW
SW
W WW WWW

W


W WW WW
SS
SS
W W
SS SSSSSW
W


W
W
SSS SW
WS
W
WW

SS SSS


SS W
W
W




W
W


WS
WS
W

SS
SS SS
W


SS
SSS SS
SS
SW

W
W

0

-1

W



3

4

5

W
W

W

wPBNF-1.4
wPBNF-1.7
wPBNF-2.0
wPBNF-3.0
wPBNF-5.0

W



6

log10(Nodes expanded wA*)

Figure 14: wPBNF speedup wA* function problem difficulty.
find bounded solution faster weighted A* due pruning nodes f values
equal resulting solution. poor behavior wPBNF easy problems
likely due overhead described above. effect problem difficulty means wPBNF
outperformed wA* often low weights, problems required expansions,
less often higher weights, problems completed quickly.
6.3 STRIPS Planning
Table 5 shows performance parallel search algorithms STRIPS planning problems,
terms speedup versus serial weighted A*. table columns represent various weights
rows represent different planning problems two seven threads. Bold values represent table entries within 10% best performance given domain.
algorithms better speedup seven threads two. wPBNF gave best speedup
number domains followed wAHDA* fastest three domains
seven threads. two threads couple domains (satellite-6 freecell-3)
wBFPSDD gave speedup, however never seven threads. wAPRA* always
slower three remaining algorithms. one problem, freecell-3, serial weighted A* performs much worse weight increases. Interestingly, wPBNF wBFPSDD show
pathology, thus record speedups 1,700 times.
6.4 Summary
section, seen bounded suboptimal variants parallel searches give
better performance serial progenitors. also shown that, sliding tile puzzle,
parallel search gives advantage serial search problem difficulty increases
suspect result holds domains too. suspect overhead
using parallelism amortized search time easy problems.
726

fi7 threads

2 threads

7 threads

2 threads

B EST-F IRST EARCH ULTICORE ACHINES

logistics-8
blocks-16
gripper-7
satellite-6
elevator-12
freecell-3
depots-13
driverlog-11
gripper-8
logistics-8
blocks-16
gripper-7
satellite-6
elevator-12
freecell-3
depots-13
driverlog-11
gripper-8

logistics-8
blocks-16
gripper-7
satellite-6
elevator-12
freecell-3
depots-13
driverlog-11
gripper-8
logistics-8
blocks-16
gripper-7
satellite-6
elevator-12
freecell-3
depots-13
driverlog-11
gripper-8

1.5
0.99
1.29
0.76
0.68
0.65
1.03
0.73
0.91
0.63
3.19
3.04
1.71
1.11
0.94
3.09
2.38
1.90
1.70

1.5
2.68
0.93
2.01
2.02
2.02
2.06
2.70
0.85
2.06
7.10
2.87
5.67
4.42
6.32
7.01
3.12
1.72
5.85

wAPRA*
2
3
1.02
0.59
0.88
4.12
0.76
0.77
0.93
0.70
0.72
0.71
1.00
1.78
1.25
0.97
0.79
0.94
0.61
0.62
3.10
3.26
1.37
1.08
1.74
1.73
1.01
1.29
0.97
1.04
7.99
2.67
5.36
1.13
1.25
0.93
1.68
1.68

5
1.37
0.30
0.77
0.75
0.77
1.61
1.08
0.93
0.62
2.58
0.37
1.82
1.44
1.02
2.93
1.17
0.92
1.74

1.5
1.25
1.52
1.36
1.15
1.16
1.49
0.92
1.30
1.14
4.59
3.60
3.71
3.22
2.77
4.77
2.98
3.52
3.71

wAHDA*
2
3
1.11
0.80
1.09
4.86
1.35
1.33
1.09
1.28
1.20
1.27
1.20
7.56
1.29
0.96
0.97
0.96
1.16
1.15
4.60
3.61
1.62
0.56
3.66
3.74
3.57
3.05
2.88
2.98
2.71
48.66
6.09
1.22
1.48
0.95
3.63
3.67

wPBNF
3
4.06
0.48
1.99
5.90
2.21
8.11
0.82
0.69
2.08
1.91
0.37
5.07
2.68
6.60
131.12
0.87
0.67
5.40

5
1.00
1.32
2.02
3.04
2.15
10.69
0.81
0.62
2.07
0.46
1.26
5.18
5.89
7.10
1,721.33
0.88
0.42
5.44

1.5
1.86
0.34
1.91
1.71
1.76
1.42
1.48
0.85
2.00
3.17
0.49
4.33
3.13
3.68
2.12
1.88
1.26
4.62

wBFPSDD
2
3
5
2.12
1.14
0.15
0.19
0.16
0.32
1.89
1.86
1.84
2.22
7.50
2.80
1.76
1.81
2.18
0.54 16.88
55.75
1.58
0.18
0.14
0.11
0.19
0.21
1.96
1.97
1.98
3.59
0.62
0.10
0.22
0.11
0.32
4.28
4.14
4.05
2.31
3.01
1.05
3.78
4.04
3.95
0.70 44.49 137.19
1.87
0.15
0.12
0.21
0.30
0.23
4.55
4.55
4.51

2
2.27
0.54
1.99
1.53
2.08
0.84
4.49
0.19
2.04
6.88
0.70
5.09
2.85
6.31
2.31
1.80
0.43
5.31

5
1.51
0.38
1.30
1.44
1.22
1.40
1.09
0.93
1.16
2.58
0.32
3.83
3.60
3.03
4.77
1.17
0.92
4.00

Table 5: Speed-up serial weighted A* STRIPS planning problems various weights.

727

fiB URNS , L EMONS , RUML , & Z HOU

7. Anytime Search
popular alternative bounded suboptimal search anytime search, highly suboptimal
solution returned quickly improved solutions returned time algorithm
terminated (or incumbent solution proved optimal). two popular anytime
heuristic search algorithms Anytime weighted A* (AwA*) (Hansen & Zhou, 2007) anytime
repairing A* (ARA*) (Likhachev, Gordon, & Thrun, 2003). AwA* weighted A* search
allowed continue finding first solution, pruning unweighted f (n) g(s)
incumbent solution n node considered expansion. ARA* uses weighted
search weight lowered solution meeting current suboptimality bound
found special INCONS list kept allows search expand node
search weight.
section present anytime versions best performing parallel searches
previous sections. used PBNF framework implement Anytime weighted PBNF (AwPBNF) Anytime Repairing PBNF (ARPBNF). use PRA* framework create anytime
weighted AHDA* (AwAHDA*). also show performance simple algorithm
runs parallel weighted A* searches differing weights. planning domain, implemented anytime weighted BFPSDD (AwBFPSDD) comparison well.
parallel searches inherently continue searching first solutions found,
serve naturally anytime algorithms style Anytime weighted A*. main
difference standard, optimal versions algorithms anytime variants
anytime versions sort open lists heap free nblocks f (n) = g(n) +
w h(n). fact, cases optimal search degenerate case anytime search
w = 1. approach (simply using w > 1) used implement algorithms except
ARPBNF multi-weighted A*.
Next, discuss details ARPBNF algorithm. Following that, introduce
new parallel anytime algorithm called multi-weighted A*. Finally, show results set
comparisons performed anytime algorithms discussed sections.
7.1 Anytime Repairing PBNF
ARPBNF parallel anytime search algorithm based ARA* (Likhachev et al., 2003).
ARPBNF, open lists heap nblocks sorted f AwPBNF, instead merely
continuing search incumbent proved optimal, ARPBNF uses weight schedule.
time incumbent found, weight heuristic value lowered specified amount,
open lists resorted search continues. final iteration, weight 1.0
optimal solution found.
following procedure used resort nblocks parallel incumbent solutions:
1. thread calling resort (the one found goal) becomes leader taking
lock nblock graph setting resort flag. (If flag already set,
another thread already leader current thread becomes worker). flag
set leader thread releases lock nblock graph waits nblocks
values zero (no nblocks acquired).
2. Threads check resort flag expansion, set threads release nblocks
become worker threads wait leader set start flag.
728

fiB EST-F IRST EARCH ULTICORE ACHINES

3. nblocks = 0, leader re-takes lock nblock graph ensures
values still zero (if not, releases lock retries). leader sets
global weight value next weight weight schedule populates lock-free
queue nblocks. queue populated, leader sets start flag.
4. threads greedily dequeue nblocks resort queue empty.
5. nblocks resorted, leader thread clears resort flag start flag
releases lock nblock graph. threads acquire new nblocks
search continue.
modeled procedure TLA+ showed live-lock dead-lock free
4 threads 5 nblocks use TLC model checker (Yu et al., 1999). model
simple include appendix.
7.2 Multi-weighted A*
section introduce new simple parallel anytime algorithm called multi-weighted A*.
PBNF PRA* frameworks parallelizing anytime algorithms thought one
end spectrum parallel anytime algorithms. PBNF PRA* threads working
finding single solution given quality; opposite end spectrum thread would
working find solution. compare algorithm end spectrum
implemented algorithm call multi-weighted A* allocates available threads
weighted A* searches. thread finishes first generally thread searching
greatest weight therefore solution worst quality. next thread
finish next greatest weight, on. final thread complete generally
searching weight 1.0, performing standard A* search, return optimal solution.
algorithm given schedule weighs decreasing order. largest weights
schedule distributed among available threads. threads begin searching using wA*
given weight values. thread finds new solution better current one,
updates incumbent shared threads allow pruning. thread
finds better incumbent solution, w -admissible respect weight thread
searching with. thread finishes (either finding solution pruning entire open list), takes
highest unclaimed weight schedule starts fresh search using weight.
weights left schedule, thread terminates. threads terminated,
search complete. final weight schedule 1.0, last solution found
optimal.
One benefits multi-weighted A* simple algorithm implement.
However, see below, doesnt benefit much added parallelism. reason
may because, weight schedule exhausted (a thread searching lowest
weight, 1.0) threads complete searches sit idle entire search terminates. Since
final weight take longest, may majority search time. dynamic
schedule could used keep threads busy optimal solution found. One could also
attempt use threads using multi-threaded search weight,
wPBNF wAHDA*. leave extensions future work.
729

fiB URNS , L EMONS , RUML , & Z HOU

Solution Cost (factor optimal)

1.1

1.0

1.1

1.0
0.2

0.4

0.6

0.8

1.0

wt sched 1
wt sched 2
wt sched 3
wt sched 4

1.1

1.0
0.2

0.4

0.6

0.8

1.0

0.2

0.4

0.6

0.8

Wall time relative serial A*

Wall time relative serial A*

Wall time relative serial A*

Grid Unit Four-way AwA* lower hull

Grid Unit Four-way AwPBNF (8 threads) lower hull

Grid Unit Four-way ARA* lower hull

1.2

1.2

AwA*
Solution Cost (factor optimal)

Solution Cost (factor optimal)

Grid Unit Four-way ARA* raw data
1.2

3.4
1.8
1.4
1.1
1.2

1.1

1.0

1.2

AwPBNF 8 threads
Solution Cost (factor optimal)

Solution Cost (factor optimal)

Grid Unit Four-way AwPBNF (8 threads) raw data
1.2

3.4
1.8
1.4
1.2
1.1

Solution Cost (factor optimal)

Grid Unit Four-way AwA* raw data
1.2

1.1

1.0
0.2

0.4

0.6

0.8

Wall time relative serial A*

1.0

1.0

ARA*

1.1

1.0
0.2

0.4

0.6

0.8

Wall time relative serial A*

1.0

0.2

0.4

0.6

0.8

Wall time relative serial A*

Figure 15: Raw data profiles (top) lower hull profiles (bottom) AwA* (left), AwPBNF (center), ARA* (right). Grid unit-cost four-way pathfinding.

8. Empirical Evaluation: Anytime Search
implementation empirical setup similar used suboptimal search. ARA*,
ARPBNF Multi-wA* considered four different weight schedules: {7.4, 4.2, 2.6, 1.9, 1.5,
1.3, 1.1, 1}, {4.2, 2.6, 1.9, 1.5, 1.3, 1.1, 1.05, 1}, {3, 2.8, . . . , 1.2, 1}, {5, 4.8, . . . , 1.2, 1}. AwA*
anytime parallel algorithms consider weights of: 1.1, 1.2, 1.4, 1.8 3.4 grid
pathfinding 1.4, 1.7, 2.0, 3.0 5.0 sliding tiles domain. fully evaluate anytime
algorithms, necessary consider performance profile, i.e., expected solution quality
function time. easily plotted, ignores fact anytime algorithms
considered paper free parameter, namely weight schedule weights used
accelerate search. order compare algorithms, make assumption that,
particular application, user attempt find parameter setting giving good performance
timescale interested in. assumption, plot performance
anytime algorithm computing, time point, best performance achieved
parameter settings tried algorithm minimum solution cost parameter
settings given algorithm given time point. refer concept lower hull
profiles, takes minimum profiles parameter setting.
730

1.0

fiB EST-F IRST EARCH ULTICORE ACHINES

Grid Unit Four-way 2 threads

Grid Unit Four-way 8 threads
1.2

ARA*
ARPBNF 2 threads
AwA*
Multi wA* 2 threads
AwAHDA* 2 threads
AwPBNF 2 threads

Solution Cost (factor optimal)

Solution Cost (factor optimal)

1.2

1.1

1.0

ARA*
AwA*
Multi wA* 8 threads
ARPBNF 8 threads
AwAHDA* 8 threads
AwPBNF 8 threads

1.1

1.0
0.4

0.8

1.2

1.6

2.0

Wall time relative serial A*

0.4

0.8

1.2

1.6

2.0

Wall time relative serial A*

Figure 16: Grid unit-cost four-way pathfinding lower hull anytime profiles.
top row Figure 15 shows example raw data three algorithms
5000x5000 unit-cost four-way grid pathfinding problems. y-axis plots solution quality factor optimal x-axis wall clock time relative amount
time A* took find optimal solution. bottom row figure shows lower hull
respective data displayed above. comparing two images left display data
AwA* algorithm, one see three big steps lower hull plot different weight used hull found better solution time bound.
center panel Figure 15 shows AwPBNF algorithm gives similar performance AwA*,
however often faster. surprising since AwPBNF based AwA* approach
running eight threads instead one. final panel Figure 15 shows ARA*, uses
weight schedules instead single weight.
Figures 16-17 present lower hulls serial parallel algorithms grid pathfinding
sliding tile puzzle. panel, y-axis represents solution cost factor optimal
cost. Figure 16 x-axis represents wall time relative amount time serial A* took
find optimal solution. allows comparison anytime algorithms standard
serial A*. Since A* able solve Korfs 100 15-puzzle instances machine,
x-axis Figure 17 absolute wall time seconds. serial parallel algorithms
plotted. profiles start algorithm first returns solution ends algorithm
proved optimality 180 second cutoff (since Multi-wA* consume memory
quickly algorithms, gave 120 second cutoff sliding tile puzzle prevent
thrashing).
8.1 Four-Way Unit Cost Grids
Figure 16 shows anytime performance unit cost four-way movement grid pathfinding problems. AwAHDA* AwPBNF found best solutions quicker algorithms.
731

fiB URNS , L EMONS , RUML , & Z HOU

Korfs 100 15-puzzles 2 threads

1.016

1.012

1.008

1.004

40

80

120

ARA*
Multi wA* 8 threads
ARPBNF 8 threads
AwA*
AwPBNF 8 threads
AwAHDA* 8 threads

1.02

Solution Cost (factor optimal)

ARA*
Multi wA* 2 threads
ARPBNF 2 threads
AwAHDA* 2 threads
AwA*
AwPBNF 2 threads

1.02

Solution Cost (factor optimal)

Korfs 100 15-puzzels 8 threads

160

1.016

1.012

1.008

1.004

40

Wall time (seconds)

80

120

160

Wall time (seconds)

Figure 17: Korfs 100 15-puzzles lower hull anytime profiles.
algorithms improved amount time taken find better solutions threads
added. AwPBNF converged quickly threads added. Even two threads
AwPBNF first algorithm converge optimal solution 60% time serial A*.
next two algorithms Multi-wA* anytime repairing PBNF (ARPBNF). Multi-wA* converged quickly threads added, performance finding intermediate solutions
change much different numbers threads. ARPBNF, hand, took longer
find good solutions low thread counts, threads added started perform better,
eventually matching Multi wA* eight threads. algorithms improved solution
quality steadily AwPBNF AwAHDA* large jumps lower hulls.
jumps corresponds hull switching different weight value (compare
raw data AwPBNF Figure 15). parallel algorithms found good solutions faster
serial AwA* serial ARA*. parallel algorithms, however, took longer prove optimality
AwA* domain.
8.2 Sliding Tile Puzzles
Figure 17 presents lower hulls anytime algorithms Korfs 100 instances 15-puzzle.
figure, x-axes show total wall clock time seconds. times normalized
A* able solve instances. panels, see AwAHDA* tended
find good solutions faster algorithms. AwA* AwPBNF performed similarly
two threads number threads increased AwPBNF begun find better solutions faster
AwA*. ARPBNF took longer find good solutions AwPBNF AwAHDA*
able find better solutions faster serial counterpart. simple Multi wA* algorithm
performed worst parallel algorithms. Increasing number threads used Multi-wA*
seem increase solution quality. ARA* gave worst performance domain;
profile curve seen top three panels.
732

fi7 threads

2 threads

7 threads

2 threads

B EST-F IRST EARCH ULTICORE ACHINES

logistics-6
blocks-14
gripper-7
satellite-6
elevator-12
freecell-3
depots-7
driverlog-11
gripper-8
logistics-6
blocks-14
gripper-7
satellite-6
elevator-12
freecell-3
depots-7
driverlog-11

1.5
1.09
1.36
0.78
0.77
0.64
1.37
1.24
1.15
0.61
1.45
2.54
1.77
1.22
0.93
3.64
3.60
3.04

logistics-6
blocks-14
gripper-7
satellite-6
elevator-12
freecell-3
depots-7
driverlog-11
gripper-8
logistics-6
blocks-14
gripper-7
satellite-6
elevator-12
freecell-3
depots-7
driverlog-11

1.5
1.06
1.91
2.05
1.58
2.01
1.93
1.94
1.95
2.04
2.04
3.72
5.61
5.96
6.18
3.54
5.74
5.78

AwAPRA*
2
3
1.06
1.40
7.76 56.41
0.77
0.76
0.78
0.78
0.67
0.69
1.43
4.61
1.30
1.30
1.19
1.11
0.62
0.62
1.43
1.81
15.63 98.52
1.68
1.71
1.22
1.26
0.93
0.95
3.75 11.59
3.64
3.65
3.20
3.05
AwPBNF
2
3
1.35
1.94
1.99
13.22
1.96
1.99
1.96
1.98
2.07
2.13
1.06
2.78
2.00
2.01
2.10
1.99
2.05
2.09
2.46
4.19
22.37
25.69
5.05
5.03
4.66
5.74
6.03
6.20
1.50
15.32
5.52
5.48
5.83
5.73

5
1.40
>90.16
0.75
0.76
0.70
1.37
2.68
1.20
0.62
1.81
>177.08
1.73
1.26
0.94
4.44
7.60
3.17

5
1.98
>22.36
1.95
1.91
2.07
6.23
4.10
0.77
2.06
4.21
>7.20
5.06
4.70
6.05
11.46
10.84
2.18

1.5
1.23
1.62
1.35
1.26
1.20
1.66
1.51
1.50
1.16
2.87
3.30
3.75
3.56
2.77
5.00
4.41
4.74

1.5
0.68
1.02
1.94
1.85
1.74
1.45
1.44
1.73
2.01
1.02
1.60
4.30
4.10
3.71
1.78
2.02
2.58

AwAHDA*
2
3
1.21
1.59
9.90
63.60
1.33
1.32
1.23
1.24
1.19
1.16
1.68
5.65
1.51
1.50
1.55
1.46
1.11
1.14
2.81
3.65
19.91 132.97
3.69
3.61
3.46
3.51
2.75
2.79
4.97
16.36
4.42
4.40
4.82
4.66
AwBFPSDD
2
3
0.91
0.91
1.18
7.71
1.89
1.94
1.87
1.49
1.74
1.75
1.46
1.97
1.45
1.32
1.78
1.59
2.00
1.98
1.35
1.37
1.96
12.10
4.24
4.16
3.54
4.16
3.74
3.73
1.82
2.59
1.96
1.92
2.86
2.57

5
1.66
>110.16
1.33
1.23
1.17
1.95
3.18
1.54
1.11
3.74
>231.45
3.67
3.50
2.77
21.57
9.25
4.87

5
0.56
>11.92
1.82
1.80
1.69
3.08
2.40
1.41
1.96
0.92
>19.94
3.96
3.88
3.38
4.14
3.68
2.34

Table 6: Speed-up anytime search optimality serial AwA* STRIPS planning using
various weights.

8.3 STRIPS Planning
Table 6 shows speedup parallel anytime algorithms serial anytime A*. algorithms
run optimal solution proved. (For weight 5, AwA* ran memory
blocks-14, speedup values weight instance lower bounds.) bold entries
733

fi7 Threads

B URNS , L EMONS , RUML , & Z HOU

logistics-6
blocks-14
gripper-7
satellite-6
elevator-12
freecell-3
depots-7
driverlog-11
gripper-8

1.5
1.48
1.24
1.07
1.10
1.06
1.05
1.20
1.16
1.06

AwPBNF
2
3
1.84 2.36
1.22 0.21
0.99 0.99
0.87 1.08
1.04 1.04
0.44 0.99
1.15 1.15
1.15 1.19
0.99 0.99

5
2.27
0.03
1.00
0.88
1.03
0.29
1.08
0.43
1.00

1.5
0.68
0.87
0.93
0.88
0.77
0.64
0.54
0.53
0.99

AwBFPSDD
2
3
0.93 0.71
0.18 0.16
0.95 0.93
0.77 0.91
0.78 0.76
0.64 0.20
0.53 0.52
0.58 0.54
0.98 0.99

5
0.54
0.16
0.92
0.90
0.73
0.14
0.49
0.50
0.97

1.5
1.12
1.46
0.99
0.99
1.02
1.13




AwAPRA*
2
3
1.08 1.08
1.46 1.42
1.03 1.01
1.00 1.01
1.00 1.00
1.16 0.82







5
0.98
0.94
0.99
1.02
1.00
0.10




Table 7: Speed-up anytime search optimality PBNF STRIPS planning problems using
various weights.

table represent values within 10% best performance given domain.
algorithms, speedup serial generally increased threads higher weight.
PBNF gave fastest performance except two domains (blocks-14 freecell-3).
two domains AwAHDA* gave best performance least factor 10x AwPBNF.
Hansen Zhou (2007) show AwA* lead speedup A* weight values
certain domains. Finding suboptimal solution quickly allows f pruning keeps open list
short quick manipulate, resulting faster performance even though AwA* expands
nodes A*. found similar phenomenon corresponding parallel case. Table 7 shows
speedup unweighted optimal PBNF using various weights anytime algorithms.
significant fraction values greater 1, representing speedup using anytime
algorithm instead standard optimal parallel search. general, speedup seems variable
weight increases. weight 1.5, AwPBNF always provides speedup.
8.4 Summary
part paper shown create new parallel anytime search algorithms
based frameworks introduced previous sections. also created new parallel
anytime algorithm simply runs many weighted A* searches differing weights.
experiments, seen AwPBNF AwAHDA* found higher quality solutions faster
algorithms showed improved performance threads added.
Additionally, ARPBNF, parallel algorithm based ARA*, improved threads
tended give smoother increase solution quality former two algorithms, although
find solutions quite quickly unable converge optimal solution
sliding tiles domain within given time limit. Running multiple weighted A* searches
give solutions faster number threads increased, convergence performance
mixed.

9. Discussion
explored set best-first search algorithms exploit parallel capabilities modern
CPUs. First looked parallel optimal search (Safe) PBNF, several variants PRA*
734

fiB EST-F IRST EARCH ULTICORE ACHINES

set simpler previously proposed algorithms. Overall, Safe PBNF gave best performance
optimal search. Next created set bounded-suboptimal search algorithms based PBNF,
successful variants PRA*, BFPSDD algorithm. PBNF PRA* asynchronous
communication abstraction (AHDA*) gave best performance all, PBNF
slightly better average. addition, showed results suggest boundedsuboptimal PBNF advantage serial weighted A* search problem difficulty
increases. Finally converted PBNF PRA* anytime algorithms compared
serial anytime algorithms new algorithm called multi-weighted A*. found
anytime weighted PBNF anytime variant AHDA* gave best anytime performance
occasionally able find solutions faster non-anytime counterparts.
results show PBNF outperforms PSDD. believe lack
layer-based synchronization better utilization heuristic cost-to-go information. fact
BFPSDD got better f layers widened suggestive evidence. Another less obvious
reason PBNF may perform better best-first search larger frontier size
breadth-first heuristic search used PSDD. larger frontier size tend create
nblocks containing open search nodes. disjoint duplicate detection scopes
nodes open lists and, therefore, potential increased parallelism.
results show that, even single thread, PBNF outperform serial A* search
(see Table 1). may attributed part speculative behavior PBNF algorithm.
Since PBNF uses minimum number expansions testing switch nblock
better f values, search sub-optimal nodes A* would search. order
get optimal solutions, PBNF acts anytime algorithm; stores incumbent solutions prunes
prove optimal solution. Zhou Hansen show approach
ability perform better A* (Hansen & Zhou, 2007) upper bound pruning,
reduces number expansions nodes f value equal optimal solution
cost reduce number open nodes, increasing speed operations open list.
PBNF may also give good single thread performance breaks search frontier
many small open lists (one nblock). this, priority queue operations
PBNF performs much smaller queues A*, uses one big single queue (see
Section 4.6.2).
9.1 Possible Extensions
basic guideline creating good abstractions SDD (and PBNF) minimize
connectivity abstract states, aspects abstraction could explored.
instance, discovering features good include abstract away may helpful
users PBNF. much focus one feature could cause good nodes focused small
subset nblocks (Zhou & Hansen, 2009). Likewise, size abstraction could examined
detail. Although always use constant abstraction size current work simplicity
seems likely abstraction size change number threads changes perhaps even
based features domain problem instance. guideline could devised, ratio
number nblocks threads h value start state, problem-adaptive abstraction
size would much simpler real world use. Additionally, edge partitioning (Zhou & Hansen,
2007) could allow us reduce connectivity abstraction used PBNF, study
necessary discover full impact technique PBNFs behavior.
735

fiB URNS , L EMONS , RUML , & Z HOU

possible future extensions PBNF include adaptive minimum expansion values, use
external memory, extension distributed setting. preliminary work adapting minimum expansion values indicated simply increasing decreasing based lock failures
successes either neutral negative effect performance. One reason may
minimum expansions parameter adds speculation.
may possible combine PBNF PRA* distributed memory setting. algorithm
may use technique based PRA* distribute portions search space among different nodes
cluster work stations using multicore search PBNF node.
additional technique explored paper running multicore search algorithms threads available cores. technique used improve
performance parallel delayed duplicate detection (Korf, 1993; Korf & Schultze, 2005)
heavily I/O intensive. Using approach, one thread blocked I/O another thread
make use newly available processing core. Even without disk I/O technique may
useful threads spend lot time waiting acquire locks.

10. Conclusions
paper investigated algorithms best-first search multicore machines.
shown set previously proposed algorithms parallel best-first search much slower
running A* serially. presented novel hashing function PRA* takes advantage
locality search space gives superior performance. Additionally, verified results presented Kishimoto et al. (2009) using asynchronous communication PRA* allows
perform better using synchronous communication. present new algorithm, PBNF,
approximates best-first search ordering trying keep threads busy. proved
correctness PBNF search framework used derive new suboptimal anytime
algorithms.
performed comprehensive empirical comparison optimal, suboptimal anytime variations parallel best-first search algorithms. results demonstrate using good
abstraction distribute nodes PRA* beneficial asynchronous communication,
two techniques used together (yielding AHDA*). also found original breadth-first PSDD algorithm give competitive behavior without tight upper bound
pruning. implemented novel extension PSDD, BFPSDD, gives reasonable performance domains tested. experiments, however, demonstrate new PBNF
AHDA* algorithms outperformed algorithms. PBNF performs best optimal
bounded-suboptimal search PBNF AHDA* gave competitive anytime performance.

Acknowledgments
gratefully acknowledge support NSF (grant IIS-0812141), DARPA CSSG program
(grant HR0011-09-1-0021) helpful suggestions Jordan Thayer. results
previously reported Burns, Lemons, Zhou, Ruml (2009b) Burns, Lemons, Ruml,
Zhou (2009a).
736

fiB EST-F IRST EARCH ULTICORE ACHINES

Appendix A. Pseudo-code Safe PBNF
following pseudo code three global structures. first pointer current
incumbent solution, incumbent, second done flag set true thread recognizes
search complete third nblock graph. nblock graph structure contains
list free nblocks, freelist along h values nblock. simplicity,
code uses single lock access either structure. thread also local exp count. best
function set nblocks results nblock containing open node lowest f value.
EARCH ( INITIAL NODE )
1. insert initial node open
2. p processors, HREAD EARCH()
3. threads still running, wait()
4. return incumbent
HREAD EARCH ()
1. b NULL
2. done
3.
b N EXT N BLOCK(b)
4.
exp 0
5.
HOULD WITCH(b, exp)
6.
best open node b
7.
> incumbent prune
8.
goal
9.
< incumbent
10.
lock; incumbent m; unlock
11.
else duplicate
12.
children expand(m)
13.
child children
14.
insert child open appropriate nblock
15.
exp exp + 1
HOULD WITCH ( B , EXP )
1. b empty return true
2. exp < min-expansions return false
3. exp 0
4. best(freelist) < b best(interferenceScope(b)) < b
5.
best(interferenceScope(b)) < best(freelist)
6.
ET H OT(best(interferenceScope(b)))
7.
return true
8. lock
9. b interferenceScope(b)
10.
hot(b ) ET C OLD(b )
11. unlock
12. return false

737

fiB URNS , L EMONS , RUML , & Z HOU

ET H OT ( B )
1. lock
2. hot(b) (b) > 0
3.
interferenceScope(b) : < b hot(i )
4.
hot(b) true
5.
interferenceScope(b)
6.
hot(m ) ET C OLD(m )
7.
(m ) = 0 h (m ) = 0
8.
empty
9.
freelist freelist \ {m }
10.
h (m ) h (m ) + 1
11. unlock
ET C OLD ( B )
1. hot(b) false
2. interferenceScope(b)
3.
h (m ) h (m ) 1
4.
(m ) = 0 h (m ) = 0 empty
5.
hot(m )
6.
ET C OLD(m )
7.
freelist freelist {m }
8.
wake sleeping threads
R ELEASE ( B )
1. b interferenceScope(b)
2.
(b ) (b ) 1
3.
(b ) = 0 h (b ) = 0 b empty
4.
hot(b )
5.
ET C OLD(b )
6.
freelist freelist {b }
7.
wake sleeping threads
N EXT N BLOCK ( B )
1. b open nodes b set hot lock
2. else trylock() fails return b
3. b 6= NULL
4.
bestScope best(interferenceScope(b))
5.
b < bestScope b < best(freelist)
6.
unlock; return b
7.
R ELEASE(b)
8. (l nblocks : (l ) = 0) freelist empty
9.
done true
10.
wake sleeping threads
11. freelist empty done, sleep
12. done n NULL
738

fiB EST-F IRST EARCH ULTICORE ACHINES

13. else
14.
best(freelist)
15.
b interferenceScope(m)
16.
(b ) (b ) + 1
17. unlock
18. return

739

fiB URNS , L EMONS , RUML , & Z HOU

Appendix B. TLA+ Model: Hot N blocks
present model used show Safe PBNF live-lock free. Refer Section 3.2.3.
MODULE HotNblocks
FiniteSets, Naturals
CONSTANTS nnblocks, nprocs, search, nextblock , none
VARIABLES state, acquired , isHot, Succs

Vars = hstate, acquired , isHot, Succsi

States = {search, nextblock }

Nblocks = 0 . . nnblocks 1

Procs = 0 . . nprocs 1
ASSUME nnblocks nprocs nprocs > 0 nnblocks > 1 none
/ Nblocks Cardinality(States) = 2

Preds(x ) = {y Nblocks : x Succs[y]} Set predecessors Nblock x

IntScope(x ) = Preds(x ) UNION {Preds(y) : Succs[x ]} interference scope x

IntBy(x ) = {y Nblocks : x IntScope(y)} Set Nblocks x interferes.

Busy(A) = UNION {Succs[x ] : x A} Set Nblocks busy given set acquired nblocks

Overlap(x , A) = IntScope(x ) Set Busy Nblocks overlapping successors x

Hot(A) = {x Nblocks : isHot[x ] Overlap(x , A) 6= {}} Set hot nblocks given set acquired nblocks

HotInterference(A) = UNION {IntScope(x ) : x Hot(A)} Set Nblocks interference scopes hot nblocks

Free(A) = {x Nblocks : Overlap(x , A) = {} x
/ HotInterference(A)} Free Nblocks

Acquired = {acquired [x ] : x Procs} \ {none} Set Nblocks currently acquired

OverlapAmt(x ) = Cardinality(Overlap(x , Acquired )) number nblocks overlapping x .

doNextBlock (x ) = UNCHANGED hSuccsi
state[x ] = nextblock acquired [x ] = none Free(Acquired ) 6= {}
Free(Acquired \ {acquired [x ]}) 6= {}
Free(Acquired \ {acquired [x ]}) : acquired = [acquired EXCEPT ! [x ] = y]
state = [state EXCEPT ! [x ] = search]
isHot = [y Nblocks 7 Free(Acquired \ {acquired [x ]})
FALSE ELSE isHot[y]]
ELSE acquired = [acquired EXCEPT ![x ] = none]
isHot = [y Nblocks 7 Free(Acquired )
FALSE ELSE isHot[y]]
UNCHANGED hstatei

doSearch(x ) = UNCHANGED hacquired , Succsi
state[x ] = search state = [state EXCEPT ![x ] = nextblock ]
UNCHANGED hisHoti
IntBy(acquired [x ]) : isHot[y]
IntScope(y) Hot(Acquired ) = {}

/ HotInterference(Acquired )
isHot = [isHot EXCEPT ![y] = TRUE]

Init = state = [x Procs 7 nextblock ] acquired = [x Procs 7 none]
isHot = [x Nblocks 7 FALSE]
EXTENDS

basic graph nblock connected neighbors forming loop.

Succs = [x Nblocks 7

x = 0 {nnblocks 1, x + 1}
x = nnblocks 1 {0, x 1} ELSE {x 1, x + 1}]

Next = x Procs : (doNextBlock (x ) doSearch(x ))

Fairness = x Procs : WFVars (doNextBlock (x ) doSearch(x ))

Prog = Init 2[Next]Vars Fairness

HotNblocks = x Nblocks : isHot[x ] ; isHot[x ] property prove


ELSE

740

fiB EST-F IRST EARCH ULTICORE ACHINES

References
Burns, E., Lemons, S., Ruml, W., & Zhou, R. (2009a). Suboptimal anytime heuristic search
multi-core machines. Proceedings Seventeenth International Conference Automated Planning Scheduling (ICAPS-09).
Burns, E., Lemons, S., Zhou, R., & Ruml, W. (2009b). Best-first heuristic search multi-core
machines. Proceedings 14th International Joint Conference Artificial Intelligence
(IJCAI-09).
Cushing, W., Bentor, J., & Kambhampati, S. (2010). Cost based search considered harmful.
2010 International Symposium Combinatorial Search (SOCS-10).
Dai, P., & Hansen, E. A. (2007). Prioritizing bellman backups without priority queue. Proceedings Nineteenth International Conference Automated Planning Scheduling
(ICAPS-09).
Davis, H. W., Bramanti-Gregor, A., & Wang, J. (1988). advantages using depth breadth
components heuristic search. Methodologies Intelligent Systems 3, pp. 1928.
Edelkamp, S., & Schrodl, S. (2000). Localizing A*. Proceedings Seventeenth National
Conference Artificial Intelligence (AAAI-00), pp. 885890. AAAI Press.
Edelkamp, S., & Sulewski, D. (2010). GPU exploration two-player games perfect hash
functions. 2010 International Symposium Combinatorial Search (SOCS-10).
Evans, J. (2006). scalable concurrent malloc(3) implementation FreeBSD. Proceedings
BSDCan 2006.
Evett, M., Hendler, J., Mahanti, A., & Nau, D. (1995). PRA* - massively-parallel heuristic-search.
Journal Parallel Distributed Computing, 25(2), 133143.
Felner, A., Kraus, S., & Korf, R. (2003). KBFS: K-best-first search. Annals Mathematics
Artificial Intelligence, 39(1-2), 1939.
Ferguson, C., & Korf, R. E. (1988). Distributed tree search applications alpha-beta pruning. Proceedings Seventh National Conference Artificial Intelligence (AAAI-88).
Hansen, E. A., & Zhou, R. (2007). Anytime heuristic search. Journal Artificial Intelligence
Research, 28, 267297.
Harris, T. L. (2001). pragmatic implementation non-blocking linked-lists. Lecture Notes
Computer Science, Vol. 2180/2001, pp. 300314. Springer Berlin / Heidelberg.
Hart, P. E., Nilsson, N. J., & Raphael, B. (1968). formal basis heuristic determination
minimum cost paths. IEEE Transactions Systems Science Cybernetics, SSC-4(2),
100107.
Haslum, P., & Geffner, H. (2000). Admissible heuristics optimal planning. Proceedings
Fifth Internationas Conference Artificial Intelligence Planning Scheduling Systems
(AIPS-00), pp. 140149.
Holzmann, G. J., & Bosnacki, D. (2007). design multicore extension SPIN model
checker. IEEE Transactions Software Engineering, 33(10), 659674.
741

fiB URNS , L EMONS , RUML , & Z HOU

Jabbar, S., & Edelkamp, S. (2006). Parallel external directed model checking linear I/O.
Emerson, E., & Namjoshi, K. (Eds.), Verification, Model Checking, Abstract Interpretation, Vol. 3855 Lecture Notes Computer Science, pp. 237251. Springer Berlin / Heidelberg.
Kishimoto, A., Fukunaga, A., & Botea, A. (2009). Scalable, parallel best-first search optimal
sequential planning. Proceedings Nineteenth International Conference Automated
Planning Scheduling (ICAPS-09).
Korf, R. E. (1985). Iterative-deepening-A*: optimal admissible tree search. Proceedings
International Joint Conference Artificial Intelligence (IJCAI-85), pp. 10341036.
Korf, R. E. (1993). Linear-space best-first search. Artificial Intelligence, 62(1), 4178.
Korf, R. E. (2003). Delayed duplicate detection: extended abstract. Proceedings Eighteenth
International Joint Conference Articial Intelligence (IJCAI-03), pp. 15391541.
Korf, R. E., & Schultze, P. (2005). Large-scale parallel breadth-first search. Proceedings
Twentieth National Conference Articial Intelligence (AAAI-05), pp. 13801385.
Kumar, V., Ramesh, K., & Rao, V. N. (1988). Parallel best-first search state-space graphs: summary results. Proceedings Seventh National Conference Artificial Intelligence
(AAAI-88), pp. 122127.
Lamport, L. (2002). Specifying Systems: TLA+ Language Tools Hardware Software
Engineers. Addison-Wesley.
Likhachev, M., Gordon, G., & Thrun, S. (2003). ARA*: Anytime A* provable bounds
sub-optimality. Proceedings Seventeenth Annual Conference Neural Information
Porcessing Systems (NIPS-03).
Likhachev, M., Gordon, G., & Thrun, S. (2003). ARA*: Formal analysis. Tech. rep. CMU-CS-03148, Carnegie Mellon University School Computer Science.
Niewiadomski, R., Amaral, J., & Holte, R. (2006a). parallel external-memory frontier breadthfirst traversal algorithm clusters workstations. Proceedings 2006 International
Conference Parallel Processing (ICPP-06), pp. 531538.
Niewiadomski, R., Amaral, J. N., & Holte, R. C. (2006b). Sequential parallel algorithms
frontier A* delayed duplicate detection. Proceedings 21st national conference
Artificial intelligence (AAAI-06), pp. 10391044. AAAI Press.
Nilsson, N. J. (1980). Principles Artificial Intelligence. Tioga Publishing Co.
Pohl, I. (1970). Heuristic search viewed path finding graph. Artificial Intelligence, 1, 193
204.
Powley, C., & Korf, R. E. (1991). Single-agent parallel window search. IEEE Transactions Pattern
Analysis Machine Intelligence, 13(5), 466477.
Richter, S., & Westphal, M. (2010). LAMA planner: Guiding cost-based anytime planning
landmarks. Journal Artificial Intelligence Research, 39.
Ruml, W., & Do, M. B. (2007). Best-first utility-guided search. Proceedings IJCAI-07, pp.
23782384.
742

fiB EST-F IRST EARCH ULTICORE ACHINES

Snir, M., & Otto, S. (1998). MPI-The Complete Reference: MPI Core. MIT Press, Cambridge,
MA, USA.
Stern, U., & Dill, D. L. (1998). Using magnetic disk instead main memory mur verifier.
Computer Aided Verification, pp. 172183. Springer.
Sundell, H., & Tsigas, P. (2005). Fast lock-free concurrent priority queues multi-thread
systems. Parallel Distributed Processing Symposium, International, 65(5), 609627.
Thayer, J. T., & Ruml, W. (2008). Faster weighted A*: optimistic approach bounded
suboptimal search. Proceedings Eighteenth International Conference Automated
Planning Scheduling (ICAPS-08).
Valois, J. D. (1995). Lock-Free Data Structures. Ph.D. thesis, Rensselaer Polytechnic Institute.
Yu, Y., Manolios, P., & Lamport, L. (1999). Model checking TLA+ specifications. Correct
Hardware Design Verification Methods, pp. 5466. Springer Berlin / Heidlberg.
Zhou, R., & Hansen, E. (2006). Domain-independent structured duplicate detection. Proceedings
Twenty-First National Conference Artificial Intelligence (AAAI-06), pp. 10821087.
Zhou, R., & Hansen, E. (2007). Edge partitioning external-memory graph search. Proceedings
Twentieth International Joint Conference Artificial Intelligence (IJCAI-07).
Zhou, R., & Hansen, E. (2009). Dynamic state-space partitioning external-memory graph search.
2009 International Symposium Combinatorial Search (SOCS-09).
Zhou, R., & Hansen, E. A. (2004). Structured duplicate detection external-memory graph search.
Proceedings Nineteenth National Conference Artificial Intelligence (AAAI-04).
Zhou, R., & Hansen, E. A. (2006). Breadth-first heuristic search. Artificial Intelligence, 170(45),
385408.
Zhou, R., & Hansen, E. A. (2007). Parallel structured duplicate detection. Proceedings
Twenty-Second Conference Artificial Intelligence (AAAI-07).

743

fiJournal Artificial Intelligence Research 39 (2010) 373-427

Submitted 4/10; published 10/10

Constraint Satisfaction Framework Executing
Perceptions Actions Diagrammatic Reasoning
Bonny Banerjee
B. Chandrasekaran

banerjee.28@osu.edu
chandra@cse.ohio-state.edu

Laboratory Artificial Intelligence Research
Department Computer Science & Engineering
Ohio State University, Columbus, OH 43210, USA

Abstract
Diagrammatic reasoning (DR) pervasive human problem solving powerful adjunct symbolic reasoning based language-like representations. research reported
paper contribution building general purpose DR system extension
soar-like problem solving architecture. work framework DR
modeled process subtasks solved, appropriate, either inference
symbolic representations interaction diagram, i.e., perceiving specied information diagram modifying/creating objects diagram specied ways
according problem solving needs. perceptions actions DR systems built
far hand-coded specic application, even rest system built
using general architecture. absence general framework executing perceptions/actions poses major hindrance using opportunistically essence
open-ended search problem solving.
goal develop framework executing wide variety specied perceptions actions across tasks/domains without human intervention. observe
domain/task-specic visual perceptions/actions transformed domain/taskindependent spatial problems. specify spatial problem quantied constraint
satisfaction problem real domain using open-ended vocabulary properties, relations actions involving three kinds diagrammatic objects points, curves, regions.
Solving spatial problem specication requires computing equivalent simplied quantier-free expression, complexity inherently doubly exponential.
represent objects conguration simple elements facilitate decomposition
complex problems simpler similar subproblems. show that, symbolic
solution subproblem expressed concisely, quantiers eliminated
spatial problems low-order polynomial time using similar previously solved subproblems. requires determining similarity two problems, existence mapping
computable polynomial time, designing memory storing previously solved problems facilitate search. ecacy idea shown time
complexity analysis. demonstrate proposed approach executing perceptions
actions involved DR tasks two army applications.

1. Introduction
research reported paper contribution building problem solving agents
articial intelligence (AI) use diagrams, much people do, AI
not, given almost exclusive emphasis AI language-like predicate-symbolic representations. Diagrammatic reasoning (DR) emerging area research number
c
2010
AI Access Foundation. rights reserved.

fiBanerjee & Chandrasekaran

elds, including AI (Glasgow, Narayanan, & Chandrasekaran, 1995; Chandrasekaran,
Kurup, & Banerjee, 2005), logic (Barwise & Etchemendy, 1998; Allwein & Barwise, 1999),
psychology (Tversky, 2000; Tricket & Trafton, 2006). research DR
one way dealing diagrams, dierent research issues addressed dierent
researchers. research reported paper considers DR problem solving activity
agent (human articial) makes use two forms representation spatial
representation form 2D diagrams symbolic representation contains information predicate-symbolic form similar logic natural language. schematic
DR architecture, proposed Chandrasekaran et al. (2002, 2004, 2005), illustrated
Figure 1.
Problem
Spatial problem
specification language

Spatial
Problem
Solver

Problem
Solver
Solution
spatial problem

Diagram

Solution

Inference
Rules
Symbolic
Information
Traditional AI
problem solver

Figure 1: diagrammatic reasoning architecture.

1.1 Diagrammatic Reasoning Problem Solving Activity
DR architecture shares idea problem solving search problem state space
(Laird, Rosenbloom, & Newell, 1986; Newell, 1990). approach, starting
initial state, agent applies operators bring state transitions reach goal
state. goal either reached decomposed subgoals use general
domain knowledge. Reaching goal subgoal requires information generated
traditional problem solving architectures (e.g., soar Laird, Newell, & Rosenbloom,
1987, act-r Anderson, 1993) inference using predicate-symbolic representation.
DR architecture, agent extract information diagrams applying perceptionlike operations addition inference using predicate-symbolic representation reach
goal/subgoal. agent also create modify objects diagram propose new
states goal might reached subsequent perceptions inferences.
illustrate conceptualization DR, let us consider real-world problem.
army commander, planning strategic operations, uses terrain map chalk path
troops safely travel one base camp location L1 another L2 within given
time. information regarding nature terrain (e.g., slow-go no-go
regions, altitude dierent parts terrain, speed troops travel
dierent kinds terrain) estimate maximum repower range enemy.
commander, veteran eld, well aware possibility troops
might ambushed along path enemy might hiding neighboring
regions. problem solving might proceed follows. diagram consisting part
374

fiExecuting Perceptions Actions Diagrammatic Reasoning

terrain map interest particular problem given, along peripheries
no-go regions two points, L1 L2 (see Figure 2(a)). commander
draws one shorter paths L1 L2 maintaining maximum distance
neighboring no-go regions (see Figure 2(b)). knows kinds spatial relations
points route points enemy could hiding correspond
ambush potential. uses knowledge perceive (and mark) portions
path prone ambush due enemies hiding behind neighboring no-go regions
(see Figure 2(c)). portion found, path inferred safe. length
safe path traversed given time, considered suitable path
operation. path drawn safe satisfy time constraint, another path
drawn (see Figure 2(d)) analyzed. procedure continues paths
exhausted. suitable path still found, least risky path might considered
operation. worst case, commander might infer operation
possible. problem similar vein, described above, considered Forbus,
Usher, Chapman (2003).
example, noteworthy problem solver (the commander) opportunistically brings together symbolic knowledge (such as, repower range enemies)
perception action diagram solve real-world problem. phenomenon
characteristic DR whenever used solve problems dierent domains, as,
economics, geometry, engineering, computer-aided design, military, on. observe
executing perceptions actions require solving purely spatial problems
involvement domain knowledge. spatial problems described terms
diagrammatic objects, as, points, curves, regions, spatial properties (e.g.,
length curve) relations (e.g., point curve) involving them. example, perceiving portions path prone ambush due enemies hiding behind mountain
range requires computing set points q curve (the path) c1 q within
specied distance (the repower range) point p curve (the mountain
range) c2 (see Figure 22(b)). Formally, written
RiskyP ortionsof P ath(q, c1 , c2 , d) On(q, c1 )p, On(p, c2 )DistanceLessT han(p, q, d)
DistanceLessT han(p, q, d) Distance(p, q)
p point. paper, propose general ecient framework spatial
problem solving autonomously execute perceptions actions DR.
1.2 Mean Diagram?
Definition 1. Diagram. diagram set labeled 2D objects {O1 , O2 , ...On }
located clearly inside (i.e., intersection touching) common region (or bounding box)
B. objects three types points, curves, regions.
Definition 2. Diagrammatic Object. diagrammatic object 3-tuple < L, , E >
L label, type (point, curve region), E spatial extent.
spatial extent diagrammatic object set points constituent object.
375

fiBanerjee & Chandrasekaran

(a) given diagram consisting two points, L1
L2 , three region obstacles.

(b) One shorter paths L1 L2
avoiding obstacles drawn.

(c) Portions path prone ambush perceived marked.

(d) Another path drawn analyzed
risk.

Figure 2: Diagrammatic reasoning army commander nding safe path transporting troops L1 L2 within given time.

Definition 3. Diagrammatic Image. diagrammatic image, I, diagram
set points constituent objects diagram. Thus, D= {O1 , O2 , ...On }
diagram Oi =<L(Oi ),T (Oi ),E(Oi ) >, diagrammatic image I(D) given
n

I(D) =
E(Oi )
i1

denition diagram, due Chandrasekaran et al. (2002, 2004, 2005), supports
functional representation diagram articial agent. diagram external
medium (e.g., piece paper, computer screen) is, one level, image consisting pixels
dierent intensities. another level, interpreted representation consisting
spatial objects domain interest. abstract diagram ideal, i.e., points
dimensionless, curves thickness, etc. external diagram, points curves
consist least one pixel nite dimensions. need interchange
two forms diagrams reasoning interaction purposes. rest paper,
376

fiExecuting Perceptions Actions Diagrammatic Reasoning

term diagram refer abstract diagram only, unless otherwise stated.
interested diagrams line drawings color intensity variation.
diagrams form substantial class diagrams everyday use.
1.3 Perceptions Actions Diagrammatic Reasoning
Definition 4. Perception. perception act extracting new piece information diagram. new piece information satisfies constraints specified terms
properties relations among existing objects diagram boolean real
number diagrammatic object(s). Thus, perception P mapping diagram
set booleans {T rue, F alse} real numbers set diagrammatic objects
satisfying constraints C.
C

P : {T rue, F alse} ,

I(D ) I(D)

Definition 5. Action. action act introducing new object(s), modifying
deleting existing object(s) diagram satisfying constraints specified terms
properties relations among existing objects. Thus, action mapping
diagram new set diagrammatic objects satisfying constraints C.
C

: DD ,

I(D) = I(D )

last couple decades, numerous DR systems built dierent applications dierent domains. following review well-known DR systems
problem solving agent reasons using diagrams. review help realize
role perception action DR, spatial problems implicit perceptions
actions.
Sketchy (Pisan, 1995) computer implementation model graph understanding. recognizes diagrammatic objects - points, lines, regions, vocabulary
properties relations includes coordinate point, right of, above, inside, steeper,
bigger, vertical, change slope, touches, intersects, line, border, forms border, etc.
representing conceptual relationships domains, as, thermodynamics economics.
domain translator responsible converting domain-specic conceptual questions
domain-independent graphical relations. Examples perception supply-demand
graph economics include price eects supply, demand, market price
product, requires solving visual problems, as, point supply equal
demand? (corresponding spatial problem: compute intersection two curves),
price supply line quantity 350? (corresponding spatial problem:
compute point curve whose one coordinate given), quantity price
directly proportional? (corresponding spatial problem: check whether slope curve
two points positive constant not), quantity price inversely
proportional? (corresponding spatial problem: check whether slope curve
two points negative constant not), etc. Actions model required due
nature task. Examples graphs understood sketchy shown Figure
3.
377

fiBanerjee & Chandrasekaran

(a) Graph economics

(b) Graph thermodynamics

Figure 3: Examples graphs understood sketchy. Reproduced permission
Pisan (1994).

Figure 4: example deected frame analysis (from civil engineering) redraw.
Reproduced permission Tessler et al. (1995).

378

fiExecuting Perceptions Actions Diagrammatic Reasoning

redraw system (Tessler et al., 1995) combines diagrammatic symbolic reasoning qualitatively determine deected shape frame structure load,
structural analysis problem civil engineering. uses vocabulary properties relations including get-angular-displacement, get-displacement, symmetrical-p, connected-to,
near, left, above, rotate, bend, translate, smooth, etc. three kinds diagrammatic objects lines, splines, circles. Though properties relations domain-independent,
some, as, bend reect assumptions implicit domain task
dened accordingly. Perceptions actions called inspection manipulation operators system. underlying representation combination grid-based
Cartesian coordinates shapes represented using grid element
grid corresponds point diagram lines represented set coordinate
points. Examples perception action include deecting beam direction
load, checking whether beam column perpendicular particular rigid
joint, etc. require solving visual problems, as, Bend Beam3 negative
direction y-axis (corresponding spatial problem: compute curve given slope
given point), Make angle Beam3 Column3 Joint3 90 degrees without modifying Beam3 (corresponding spatial problem: compute curve makes
particular angle given point given curve), Get angle Beam3
Column3 ends connected Joint3 (corresponding spatial problem: compute
angle two curves given point), etc. example deected frame analysis
redraw shown Figure 4.
archimedes system (Lindsay, 1998) assists human demonstrating theorems
Euclidean geometry modifying/creating diagrams according instructions
thereafter perceiving/inferencing diagram. operates two diagrammatic objects - points line segments, recognizes shapes, as, square, triangle, path,
etc. underlying representation array- grid-based. perceptions, called retrieval
processes, dierent classes, as, verify relationship, test condition, etc.
actions, called construction processes, also dierent classes, as, create object
certain properties, transform object, etc. Executing perceptions actions require solving spatial problems, as, create segment parallel given segment
given point, rotate object check whether coincides another object, etc.
example geometry theorem demonstrated archimedes shown Figure 5.
diamond (Jamnik, 2001), system proving mathematical theorems, uses
sequence actions diagrams assisted human prove specic ground instances
generalizes induction. uses mixture Cartesian topological representations
represent dot (equivalent point Cartesian representation) diagrammatic
object discrete space, line area (or region) diagrammatic objects
continuous space. Elementary shapes, as, row, column, ell, frame, constructed
dots, derived shapes, as, square, triangle, rectangle, etc. constructed
elementary derived shapes. vocabulary consists atomic onestep operations (e.g., rotate, translate, cut, join, project 3D 2D, remove, insert
segment, etc.). Spatial problems system composite operations composed
atomic ones, as, draw right-angled triangle, translate rotate triangle, etc.
system need execute perceptions information diagram perceived
379

fiBanerjee & Chandrasekaran

Figure 5: example geometry theorem demonstrated archimedes.

Figure 6: example mathematical theorem proven diamond. theorem
Nelson (1993).

380

fiExecuting Perceptions Actions Diagrammatic Reasoning

human decides actions applied proof search. example
mathematical theorem proven diamond shown Figure 6.
Georep (Ferguson & Forbus, 2000) takes input line drawing vector graphics
representation creates predicate calculus representation drawings spatial relations. Five primitive shape types recognized, namely line segments, circular arcs, circles
ellipses, splines (open closed), positioned text. Properties relations,
as, proximity detection, orientation detection (e.g., horizontal, vertical, above, beside), parallelism, connectivity (e.g., detecting corner, intersection, mid-connection, touch), etc.
deployed accomplish task. underlying representation vector graphics line
drawings. Systems, as, magi (Ferguson, 1994), juxta (Ferguson & Forbus, 1998),
coadd built using georep symmetry detection, critiquing diagrams based
captions, producing description units, areas, tasks course
action diagram, respectively. georep, due limitation task, need
execute action. Examples visual problems georep include guring cup
contains liquid (corresponding spatial problem: compare areas polygons representing cups), determine whether gure symmetric (corresponding spatial
problem: check whether one polygon congruent reection polygon),
etc. example ambush analysis georep shown Figure 7.

Figure 7: example ambush analysis georep. Reproduced permission
Forbus et al. (2003).

preceding discussion leads observation DR systems require perceiving and/or acting diagrams, every perception/action requires solving
domain-independent spatial problem. Thus, general-purpose DR system solving
problems applications across multiple domains would require solving large variety
non-trivial domain-independent spatial problems. spatial problems described
381

fiBanerjee & Chandrasekaran

terms three diagrammatic objects points, curves, regions, spatial properties
relations involving them.
1.4 Problem
perceptions actions solved DR system? Typically, human developing DR system identies priori problem solving steps including set perceptions
actions, hand-codes ecient algorithms solving them. problem
solving steps need altered future result, new perception arises,
developer write another algorithm obtaining solution. Thus, algorithms need
hand-coded perception/action. Clearly, inconvenient time consuming developing DR system, allow fast easy experimentation
dierent problem solving strategies problem. drawbacks
magnied goal build general-purpose DR system large variety perceptions actions possible feasible ascertain priori,
develop store algorithms for. Hence, goal investigate spatial problem solver
(SPS) eciently solving spatial problems implicit perceptions/actions without human
intervention.1
1.5 Contributions
paper, make following contributions:
1. observe wide variety visual perceptions/actions DR applications
transformed domain/task-independent spatial problems. developed language
specifying spatial problems (i.e., spatial relations actions) quantied constraint
satisfaction problems (QCSPs) rst-order logic using xed set mathematical/logical
operators real domain open-ended vocabulary properties, relations
actions. spatial relation action involving points expressed using
operators real variables rst-order logic included vocabulary.
Further, spatial relation action involving curves and/or regions expressed
using relations On(p, c) and/or Inside(p, r) p point, c curve, r region,
relation/action involving points rst-order logic included
vocabulary. vocabulary grows richer spatial relations actions specied.
2. spatial relation action included vocabulary solvable
SPS. Real QCSPs known computationally intractable, substantial part
spatial problem solving literature concentrates constraint satisfaction problems (CSPs).
developed general framework solving spatial problems specied QCSPs.
framework bypasses process quantier elimination (QE) computational bottleneck doubly exponential problem taking help previously solved similar
spatial problems. show that, symbolic solution problem expressed
1. reader keep DR architecture mind. shown Figure 1, two problem
solvers main problem solver always referred problem solver (this might
human) spatial problem solver referred SPS (this strictly
human intervention). problem solver responsible entire problem solving strategy including
converting domain-specific perceptions actions domain-independent spatial problems. SPS
responsible solving domain-independent spatial problems receives problem
solver. important get confused roles played two.

382

fiExecuting Perceptions Actions Diagrammatic Reasoning

concisely, quantiers eliminated spatial problems low-order polynomial time
using similar previously solved problems. framework leaves room ecient
convenient incorporating future results least two possible directions learning
constraints examples (automatic constraint acquisition) carefully exploiting rich
portfolio QE algorithms.
rest paper organized follows. next section, discuss language
specifying spatial problem SPS. Section 3 describes SPS. Section 4 analyzes
computational complexity SPS. Section 5 shows proposed SPS
augmented traditional AI problem solver (soar) reasoning diagrams two
real-world applications. Finally, end discussion conclusion.

2. Specification Language
section, discuss high-level language nite, extensible, human-usable,
expressive enough describe wide variety 2D spatial problems relevant DR.
problems specied language accepted input SPS solved
without human intervention. specication language independent SPS, i.e.,
problem specication remains unchanged even underlying representation
reasoning strategy SPS change.
2.1 Diagrammatic Objects
specication language recognizes three kinds diagrammatic objects points, curves,
regions.
Point. point basic diagrammatic object. objects dened terms
set points.
Curve. curve set points it. approximate curve piecewise-linearly.
Thus, curve c approximated sequence n points {p1 , p2 , ...pn }, c set
points lies constituent line segments, i.e.
c {p : On(p, {p1 , p2 }) On(p, {p2 , p3 }) ...On(p, {pn1 , pn })}
p (x, y), x, , {pi , pi+1 } line segment pi pi+1 . call
points {p1 , p2 , ...pn } vertex points. sake simplicity specication, problem
solver write sequence vertex points {p1 , p2 , ...pn } specify curve c.
Region. region set points inside boundary. boundary region
closed curve approximated piecewise-linearly. Thus, region simple (convex
concave) polygon. simple polygon triangulated point inside
region inside one triangles. Thus, boundary region r approximated
sequence n points {p1 , p2 , ...pn },
r {p : Inside(p, (r)[1]) Inside(p, (r)[2]) ...Inside(p, (r)[m])}
number triangles region r triangulation, (r)[i] ith triangle
r, p (x, y), x, . sake simplicity specication, problem solver
write sequence vertex points {p1 , p2 , ...pn } boundary curve specify
383

fiBanerjee & Chandrasekaran

region r. Whether sequence vertex points corresponds curve region
determined automatically system context property/relation predicate.
dene Inside section 3.1.
Further, SPS asked recognize kind diagrammatic object(s) obtained
solution spatial problem. achieved function Recognize(Dext )
Dext external diagram (i.e., constituted pixels unlike abstract diagram).
example, set points behind curve c respect given point p
region object curve object depending nature c location respect
p. order recognize output, SPS colors corresponding set pixels
external diagram pixel predetermined resolution corresponds point.
set colored pixels grouped two adjacent pixels always belong
group. group pixels constitutes diagrammatic object. boundary pixels
group determined. group consists less three pixels, consider
point object. group consists two pixels width (both horizontal
vertical) always less three pixels, consider curve object. Otherwise,
group constitutes region object.
2.2 Vocabulary
Unlike certain well-known qualitative spatial reasoning calculi (e.g., intersection calculus
Egenhofer, 1991, cardinal direction calculus Frank, 1991, region connection calculus
Randell, Cui, & Cohn, 1992), interested nding minimal set spatial
relations vocabulary based closed set predicates. Rather, vocabulary
based closed set operators (to discussed shortly section 2.3). spatial
relations actions included vocabulary follows:
1. spatial relation action involving points expressed using
xed set operators real variables rst-order logic.
2. spatial relation action involving points, curves regions expressed
rst-order logic using xed set operators, real variables, relation/action
#1, relations On(p, c) and/or Inside(p, r) p point, c curve, r
region.
3. spatial relation action involving points, curves regions expressed
rst-order logic using xed set operators, real variables, relation/action
#1 #2.
Thus, vocabulary open-ended addition new properties relations
encouraged problem cannot easily expressed using existing ones. observation that, human often encounters new perceptions/actions
specied using already known ones. However, large vocabulary helps specify
new ones conveniently. DR literature (Pisan, 1995; Tessler et al., 1995; Lindsay, 1998; Jamnik, 2001; Ferguson & Forbus, 2000; Chandrasekaran et al., 2004; Banerjee &
Chandrasekaran, 2004), identied vocabulary properties, relations actions
based wide usage expressing variety real-world spatial problems dierent
domains. vocabulary used paper starting point specifying
spatial problems. follows examples properties, relations actions
vocabulary.
384

fiExecuting Perceptions Actions Diagrammatic Reasoning

Properties. Associated kind object properties location
point; location, closedness length curve; location, area periphery
region, periphery region refers boundary curve. user also
dene particular shapes (e.g., circle, triangle, annulus, etc.) curves regions
appropriate reasoning domain. Dierent shapes might specic
properties, as, radius circle, height triangle, etc. easily associated
objects vocabulary user. DR also requires solving spatial problems
concerning discrete set points. problems, properties, as, Centroid(S)
V ariance(S), set points, included vocabulary.
Relations. vocabulary also contains widely used relations (or relational
predicates) involving points, as, Lef tof (p1 , p2 ), opof (p1 , p2 ), Collinear(p1 , p2 , p3 ),
Between(p1 , p2 , p3 ) p1 , p2 , p3 points. relation involving points
included vocabulary needed. On(p, c), p point c curve,
fundamental relation involving curve Inside(p, r), p point r region, fundamental relation involving region vocabulary relation
involving curves regions uses and/or Inside. relational predicates involving curves regions vocabulary Intersect(c1 , c2 ), IntersectionP oints(q, c1 , c2 ),
ouches(c1 , c2 ), Subcurveof (c1 , c2 ) c1 , c2 curves, Subregionof (r1 , r2 )
r1 , r2 regions.
Actions. Further, set predicates identifying emergent objects modications existing objects. example, ranslate(q, O, tx , ty ) returns translation object
tx units along x-axis ty units along y-axis, Rotate(q, O, c, ) returns rotation
object respect point c center degrees anti-clockwise direction,
Ref lect(q, O, {a, b}) returns reection object respect line segment {a, b}
(i.e., point point b), Scale(q, O, c, sx , sy ) returns scaling object
respect point c sx units along x-axis sy units along y-axis. curve
region, predicates dened using corresponding action involving point
predicates and/or Inside.

2.3 Language
language problem solver (human articial) species spatial
problem SPS. internal representations objects, properties, relations,
problem-solving strategies hidden problem solver. specication language
remains unchanged even underlying representation problem-solving strategy
changed. use rst-order predicate logic specication language, previously reported
Banerjee Chandrasekaran (2007).
Operators. language recognizes set boolean operators {, , }, set arithmetic operators {+, , , }, set relational operators {<, >, =, =}, quantiers
{, }. brackets () used express precedence brackets {} used
express set. paper, often use certain combination operators, as, ,
, , etc. sake brevity.
385

fiBanerjee & Chandrasekaran

Domain. language allows problem solver specify domain set
variables assume values. Unless otherwise stated, domain real plane
2 point variable real line non-diagrammatic variable.
Functions. Further, language recognizes two functions aximize(f, {x, y, ...}, C)
inimize(f, {x, y, ...}, C), maximizes minimizes function f respect
variables {x, y, ...} satisfying boolean combination constraints C (which might
involve quantiers) returns maximum minimum value f respectively along
conditions variables.
Quantified Constraint Satisfaction Problem. instance constraint satisfaction problem (CSP) consists tuple < V, D, C > V nite set variables,
domain, C= {C 1 , ...C k } set constraints. constraint C consists pair
< , Ri > list mi variables Ri mi -ary relation domain D.
question decide whether assignment mapping variable
domain element constraints satised. variables CSP
thought implicitly existentially quantied.
useful generalization CSP quantied constraint satisfaction problem,
variables may existentially universally quantied. instance
QCSP consists quantied formula rst-order logic, consists ordered list
variables associated quantiers along set constraints. QCSP
expressed follows:
(v1 , ...vm ) Q(xn , ...x1 ) (v1 , ...vm , x1 , ...xn )
Q(xn , ...x1 ) Qn xn , ...Q1 x1
Qi {, }, {x1 , ...xn } set quantied variables, {v1 , ...vm } set free
variables, V= {v1 , ...vm , x1 , ...xn }, quantier-free expression called matrix.
representation quantied expression , written sequence quantiers followed matrix, referred prenex form. Example QCSP follows:
Subcurveof (c1 , c) p, On(p, c1 ) On(p, c)
c1 , c curves 2 . example, two constraints:
< {p, c1 }, >
< {p, c}, >
Further, V= {p} = 2 . variables c, c1 given. question
decide whether assignment mapping p element 2 logical
combination constraints satised. assignment exists, c1
subcurve c; otherwise is.
Decision, Function Optimization problems. proposed specication
language, spatial problem expressed QCSP V consists variables type
point, curve region = 2 . Solving spatial problem involves:
1. free variables V (i.e., variables V quantied), deciding
whether exists mapping V satisfying C.
386

fiExecuting Perceptions Actions Diagrammatic Reasoning

2. free variables V, computing conditions free variables
mapping V satisfying C exists.
Thus, spatial problem classied decision function optimization
problem real domain. rst case constitutes decision problem yields True
False solution. second case constitutes function problem involves computing
diagrammatic object(s) described conditions free variables. spatial
problem requires computing best mapping V satisfying C, called
optimization problem.
Let us consider example. Given curve c two points p, q, spatial problem
BehindCurve(q, c, p) dened deciding whether q behind c respect
p. might specied deciding whether curve c line segment {p, q}
intersect. Thus,
BehindCurve(q, c, p) Intersect(c, {p, q})
particular instances q, p, c, solution problem rue F alse, hence
decision problem (see Figure 8). particular instances p, c, generalized
coordinates q i.e., q (x, y), solution problem logical combination
conditions involving x y, plotted constitutes region object (see Figure
9). Hence, function problem. decision problem merely requires checking
whether given instance object satises constraints not, function
problem requires computing conditions general object satisfy constraints.

Figure 8: BehindCurve decision problem. One points q behind c
respect p one not.

Again, given curve c two points p, q, spatial problem F urthestBehindCurve(q,
c, p) dened deciding whether q furthest point behind c respect
p. might specied deciding whether q lies behind c respect p
387

fiBanerjee & Chandrasekaran

Figure 9: BehindCurve function problem. shaded region r behind c
respect p.

distance p q maximum. Thus,
F urthestBehindCurve(q, c, p) BehindCurve(q, c, p) b, BehindCurve(b, c, p)
CompareDistance(b, p, q, p)
CompareDistance(a, b, c, d) Distance(a, b) Distance(c, d)
particular instances q, p, c, solution problem rue F alse, hence
decision problem. particular instances p, c, generalized coordinates q i.e.,
q (x, y), solution problem logical combination conditions involving
x y, plotted constitutes single point object, assuming one
furthest point behind c respect p, dependent nature c
Distance function dened (see Figure 10).
alternative way specifying problem F urthestBehindCurve(q, c, p)
explicitly asking maximize distance p q q satises constraint
BehindCurve(q, c, p), written as:
F urthestBehindCurve(q, c, p) aximize(Distance(q, p), {q}, BehindCurve(q, c, p))
outputs conditions involving x y, constitutes single point object.
aximize (or inimize) function assumes pool candidates choose
best satisfy set constraints. fact stated explicitly
using aximize (or inimize) function makes specication dicult
come also cumbersome. ip side, specication problem
using aximize (or inimize) function cannot used decision problem.
is, whether particular instance object best candidate satises
388

fiExecuting Perceptions Actions Diagrammatic Reasoning

q

Figure 10: F urthestBehindCurve optimization problem. point q
furthest point behind c respect p.

constraints cannot computed specication, unlike former specication.
problem type, computes best candidate pool candidates,
called optimization problem.
Definition 6. Spatial Problem. spatial problem (or problem) QCSP
variable (quantified free) type point, domain 2 .
Thus, spatial problem mapping diagram satisfying logical combination constraints C set booleans {T rue, F alse} real numbers diagrammatic
objects , i.e.,
C

: D{T rue, F alse}
Solving spatial problem requires eliminating quantiers solving algebraic equations/inequalities arrive simplied expression. computational bottleneck
solving spatial problem quantier elimination (QE) inherently doubly exponential (Davenport & Heintz, 1988). recently, Brown Davenport (2007)
shown real QE doubly-exponential even one free variable
polynomials quantied input linear. paper, concentrate primarily QE part spatial problem solving hence, solution equivalent
quantifier-free expression necessarily simplified one. Theoretically,
best complexity QE achieved far O(s(l+1)(ki +1) d(l+1)ki ) number
polynomials, maximum degree coecients real, l number
free
variables, ki number variables ith quantier block k =
ki
number quantied variables (Basu, Pollack, & Roy, 2003). However, algorithm
complicated yet practical implementation. general elaborately
implemented method real QE cylindrical algebraic decomposition CAD (Collins
389

fiBanerjee & Chandrasekaran

k1

& Hong, 1991), complexity (sd)O(1) . Another implemented method, QE
virtual substitution (Weispfenning, 1988), restricted formulas quantied
variables occur quadratically. complexity method doubly exponential
number blocks variables delimited alternations existential universal quantiers. Thus, exist general algorithms QE, large real-world
problems, soon becomes time consuming.

3. Spatial Problem Solver
paper, concentrate developing ecient SPS without sacricing generality.
goal design SPS bypass general QE algorithms much possible,
either taking help previously solved similar problems memory obtain
solution using set practical algorithms developed
limited class problems. describe overall control mechanism SPS (see
Figure 11).
many domains, as, military, spatial problems involve diagrammatic objects
arbitrary shaped (e.g., mountainous regions) often cannot approximated enough
well-dened shapes solution reliably depend specics shape.
example, solution problem nding places behind mountain one
hide enemy depends critically particular shape mountain. Due
nature domains, choose represent curves piecewise-linearly regions
polygons. Piecewise-linear curves polygonal regions unions line segments
triangular regions respectively, facilitate decomposition complex problems
simpler similar subproblems. observe similar subproblems involving
existential universal quantiers occur regularly spatial problem solving
process solved one QE algorithms (e.g., CAD), thereby incurring doubly
exponential time. minimize enormous computational cost reusing solutions
subproblems previously solved.
Given spatial problem specication language, SPS replaces numerical values problem symbolic variables, transforms symbolic problem
specication modeling language (to described shortly) progressively replacing
objects/predicates base objects/predicates internal denitions. denition
cannot found, ags error halts till provided. rst step, SPS decomposes disjunctions and/or conjunctions subproblems prenex form.
see later, subproblems similar one
solved, solution others computed it. Next, searches memory
problems similar . memory contains symbolic problems corresponding quantier-free symbolic solutions. mapped one problems,
solution readily obtained reverse-mapping corresponding symbolic solution
memory. Obtaining solution way completely bypasses QE process,
computational bottleneck SPS, thereby reducing computational costs considerably. SPS cannot map problem memory, sends problem
classier classies sends appropriate QE algorithm. problem classier combination QE algorithms borrowed Mathematica (Wolfram,
2003). SPS solves new subproblem, subproblem solution stored
390

fiExecuting Perceptions Actions Diagrammatic Reasoning

Problem
specification language

Convert problem modeling language: Search
vocabulary replace terms specification
definitions, exists; otherwise request definition

Problem
modeling language
Decompose problem conjunctions and/or
disjunctions subproblems prenex form

first subproblem I1 ,
search memory
similar subproblem

Match found

Memory

Match found

Compute solution
subproblem I1
help solution
matched problem

Problem classifier
combination constraint
solvers quantifier
elimination algorithms

Subproblem I1

solution

Compute solutions subproblems
solution I1 combine

Solution

Figure 11: Flow diagram spatial problem solver.
memory solution used similar problem encountered future.
Thus, SPS grows ecient solves problems. Finally, SPS computes
solution given problem combining solutions subproblems.
Unfortunately, problems, quantiers cannot eliminated symbolically reasonable time. SPS tries prescribed time, resorts practical
391

fiBanerjee & Chandrasekaran

methods, as, techniques especially suited low degree polynomials (e.g., Dolzmann,
Sturm, & Weispfenning, 1998) approximate methods obtaining subset solution sucient immediate purposes (e.g., Ratschan, 2006; Lasaruk & Sturm, 2006).
shown, integer linear programming (e.g., Leyton-Brown, Nudelman, & Shoham,
2002) satisability testing (e.g., Xu, Hutter, Hoos, & Leyton-Brown, 2008),
best on-average solver out-performed carefully exploiting portfolio possibly
poorer on-average solvers, accordingly, researchers experimented dierent
ways selecting portfolio solvers (see example, Xu et al., 2008; Pulina & Tacchella,
2007; Sayag, Fine, & Mansour, 2006; Streeter, Golovin, & Smith, 2007; Gebruers, Hnich,
Bridge, & Freuder, 2005; OMahony, Hebrard, Holland, Nugent, & OSullivan, 2008).
none work involve solving QCSPs real domain, directly usable
purposes discussed paper. However, expect
result extend QCSP solvers real domain, building smartly
selecting portfolio QCSP solvers promising line future research.
approach, subproblem deemed symbolically unsolvable prescribed time,
specication stored memory future, similar problem directly
subjected practical methods, thereby saving prescribed time.
3.1 Modeling Language
language problem described terms underlying representations objects/properties/relations form readily subjected algebraic
manipulation. location point p represented pair (x, y), x, ,
coordinates.
Notation. x- y-coordinates point p denoted p.x p.y respectively.
distance two points, p q, given
Distance(p, q)



(p.x q.x)2 + (p.y q.y)2

location curve c represented sequence vertex points {p1 , p2 , ...pn }.
Notation. number vertex points curve c denoted #(c), ith vertex
point denoted c[i], ith line segment denoted {c[i], c[i + 1]}.
line segment ls specied pair vertex (or terminal) points. x-
y-coordinates ls represented parametrically
fx (ls, t) ls[1].x + (ls[2].x ls[1].x)
fy (ls, t) ls[1].y + (ls[2].y ls[1].y)
parameter, 0 1. relation On(p, ls), p point, given
On(p, ls) t, 0 1 fx (ls, t) = p.x fy (ls, t) = p.y
Length line segment ls given

392

fiExecuting Perceptions Actions Diagrammatic Reasoning

Length(ls) Distance(ls[1], ls[2])
Length curve c given


#(c)1

Length(c)

Length({c[i], c[i + 1]})

i1

location region r represented location periphery
piecewise linear closed curve. discussed section 2.1, internally region triangulated
(computable linear time shown Chazelle, 1991; Seidel, 19912 ) aim
reducing simplifying computations (more section 3.2).
Notation. triangulation, number triangles region r denoted # (r)
ith triangle r denoted (r)[i].
area triangle given
Area()

1
2

3


[i].x [i\3 + 1].y [i\3 + 1].x [i].y

i1

Note area triangle positive sequence vertex points periphery
given counter-clockwise direction, otherwise negative. Area region r given
# (r)

Area(r)



Area((r)[i])

i1

relation Inside(p, ), p point triangle, given
Inside(p, ) 3i1 Lef tof (p, {[i], [i\3 + 1]})
Lef tof (p, ls) Area({ls[1], ls[2], p}) > 0
ls line segment.
action ranslate(q, c, tx , ty ) q (x, y), c curve, tx , ty real numbers, given
ranslate(q, p, tx , ty ) q.x = p.x + tx q.y = p.y + ty
ranslate(q, c, tx , ty ) a, On(a, c) ranslate(q, a, tx , ty )
Definition 7. Base Object. base object simplest form diagrammatic object.
point simplest form. line segment simplest form curve.
triangular region simplest form region. Thus, internally, three base
objects point, line segment, triangle.
Definition 8. Base Predicate. base predicate predicate accepts base
objects arguments.
2. Vik (2001) discusses implementation Mathematica.

393

fiBanerjee & Chandrasekaran

Examples base predicates include Lef tof (p1 , p2 ), Between(p1 , p2 , p3 ), On(p, ls),
Inside(p, ), p, p1 , p2 , p3 points, ls line segment, triangular region.
#(c)1

Lemma 1. On(p, c) i1

On(p, {c[i], c[i + 1]})

Proof. proof follows representation curve, described section 2.1.
# (r)


Lemma 2. Inside(p, r) i1
Inside(p, (r)[i])

Proof. proof follows representation region, described section 2.1.
relations included vocabulary internally dened terms base predicates. example, predicate, Intersect(c1 , c2 ) c1 , c2 curves, dened
terms base predicates
Intersect(c1 , c2 )
a, On(a, c1 ) On(a, c2 )
#(c )1

a, i11

#(c )1

On(a, {c1 [i], c1 [i + 1]}) j12

On(a, {c2 [j], c2 [j + 1]})

3.2 Decomposing Problem
Definition 9. Decomposition. Decomposition process replacing relational
predicates, involving free variables types curve region, spatial problem (quantified expression) conjunctions/disjunctions base predicates taking conjunctions/disjunctions front expression. expression following conjunctions/disjunctions subproblem.
Example. Decomposition problem Intersect(c1 , c2 ) a, On(a, c1 ) On(a, c2 )
occurs follows:
Intersect(c1 , c2 ) a, On(a, c1 ) On(a, c2 )
#(c )1

a, i11

#(c )1

On(a, {c1 [i], c1 [i+1]})j12

On(a, {c2 [j], c2 [j+1]}) (bef ore decomposition)

#(c )1 #(c2 )1
j1 a, On(a, {c1 [i], c1 [i+1]})On(a, {c2 [j], c2 [j+1]})

i11

#(c )1

i11

#(c )1

j12

(af ter decomposition)

Intersect ({c1 [i], c1 [i + 1]}, {c2 [j], c2 [j + 1]})

Intersect ({c1 [i], c1 [i + 1]}, {c2 [j], c2 [j + 1]}) subproblem. However, question
#(c )1 #(c )1
arises Intersect(c1 , c2 ) i11 j12 Intersect ({c1 [i], c1 [i+1]}, {c2 [j], c2 [j +1]})?
is, replace ?
Theorem 1. problem equivalent decomposition
contain following forms:
394

fiExecuting Perceptions Actions Diagrammatic Reasoning

F1:

p, On(p, c) Inside(p, r)

F2:

p, On(p, c) Inside(p, r)

F3:

p, Inside(p, r) Inside(p, r1 )

F4:

p, Inside(p, r) Inside(p, r1 )

(complement F1)

(complement F3)

c curve, r, r1 regions, c, r, r1 free variables.
Proof. discussed section 2.2, framework, On(p, c) Inside(p, r) two
fundamental relations using relation involving curve region specied.
Also, framework, point quantiable variable, {, } quantiers, {, , } boolean operators sucient express boolean expression.
Thus, spatial problem involving curves (and points regions) logical
combination smaller problems following form:
Qp, Rel(p, c) Q {, }, Rel {On, On}
spatial problem involving regions (and points curves) logical combination smaller problems following form:
Qp, Rel(p, c) Q {, }, Rel {Inside, Inside}
spatial problem involving curves regions (and points) logical combination
smaller problems following form:
Qp, Rel1 (p, c) Rel2 (p, r)
Q {, }, Rel1 {On, On}, Rel2 {Inside, Inside}, {, }
spatial problem involving two curves, c c1 , (and points) logical combination
smaller problems following form:
Qp, Rel1 (p, c) Rel2 (p, c1 )
Q {, }, Rel1 {On, On}, Rel2 {On, On}, {, }
Again, spatial problem involving two regions, r r1 , (and points) logical combination smaller problems following form:
Qp, Rel1 (p, r) Rel2 (p, r1 )
Q {, }, Rel1 {Inside, Inside}, Rel2 {Inside, Inside}, {, }
symbolically solved problems (56 total) two ways directly
decomposing p (x, y), c {p1 , p2 , ...pn } (n 2), pi (xpi , ypi ), c1 {a1 , a2 , ...au }
395

fiBanerjee & Chandrasekaran

(u 2), ai (xai , yai ), r {q1 , q2 , ...qm } (m 3), qi (xqi , yqi ), r1 {b1 , b2 , ...bv }
(v 3), bi (xbi , ybi ). turned solutions two ways equivalent
problems, except four cases stated theorem statement. Note F 2
specication computing whether curve c entirely inside region r not. Let
lsi ith line segment c (1 n 1) j j th triangular region r
(1 j 2). found
p, On(p, c) Inside(p, r)
m2
p, (n1
i1 On(p, lsi )) (j1 Inside(p, j ))
m2
p, n1
i1 j1 (On(p, lsi ) Inside(p, j ))
m2
n1
i1 j1 (p, On(p, lsi ) Inside(p, j ))

because, c entirely inside r, necessary line segments c
inside triangle r; line segment c span across multiple triangles r c
still inside r. Figure 12(a) shows example c inside r line segment
c spans across two triangles r. case, solution problem
rue computed directly F alse computed via decomposition.
rst case F 1 theorem statement explained similarly. forms F 1 F 2
rewritten follows:
F1 :

p, On(p, c) Inside(p, r)
p, On(p, c) Inside(p, r) r B r

F2 :

p, On(p, c) Inside(p, r)
p, On(p, c) Inside(p, r) r B r

B rectangular region (boundary) containing diagram discussed section
1.2. Note rewritten forms equivalent decomposition.
Again, F 4 specication computing whether region r entirely inside region
r1 not. Let 1,i ith triangle r1 (1 v 2) j j th triangular
region r (1 j 2). found
p, Inside(p, r) Inside(p, r1 )
v2
p, (m2
j1 Inside(p, j )) (i1 Inside(p, 1,i ))
v2
p, m2
j1 i1 (Inside(p, j ) Inside(p, 1,i ))
v2
m2
j1 i1 (p, Inside(p, j ) Inside(p, 1,i ))

396

fiExecuting Perceptions Actions Diagrammatic Reasoning

r

r
c

(a) Curve c inside region r line
segment c inside one triangle r.

r1

(b) Region r inside region r1 triangle r inside one triangle r1 .

Figure 12: Examples show decomposition curves regions problems containing forms F 1, F 2, F 3, F 4.

because, r entirely inside r1 , necessary triangles r
inside triangle r1 ; triangle r span across multiple triangles r1 r
still inside r1 . Figure 12(b) shows example r inside r1 triangle r
spans across two triangles r1 . case, solution problem rue
computed directly F alse computed via decomposition. third case
F 3 theorem statement explained similarly. forms F 3 F 4
rewritten follows:
F3 :

p, Inside(p, r) Inside(p, r1 )
p, Inside(p, r) Inside(p, r1 ) r1 B r1

F4 :

p, Inside(p, r) Inside(p, r1 )
p, Inside(p, r) Inside(p, r1 ) r1 B r1

Again, rewritten forms equivalent decomposition.

Theorem 2. subproblem resulting decomposing problem contains base predicates
only.
Proof. problem decomposable due presence relational predicates, involving
free variables types curve region, specication. stated section 2.2,
problem involving curve region specied framework using relation(s)
involving points relation Inside. Thus, relation Rel(q, c) involving
point q curve c rewritten as:
Rel(q, c) a, On(a, c) Rel (q, a)

397

fiBanerjee & Chandrasekaran

Rel(q, c) a, On(a, c) Rel (q, a)
Rel base predicate involving points q a. cases, expression
right-hand side contains base predicates only. Let problem involving
points curves regions. Let us replace occurrence non-base predicates
involving curve, as, Rel(q, c), equivalent expression consisting
base predicates involving points line segments only. resulting expression
consists base predicates involving points On. lemma 1, non-base
rewritten disjunctions base On. Therefore, resulting expression consists
base predicates involving points only.
Similarly, relation Rel(q, r) involving point q region r rewritten as:
Rel(q, r) a, Inside(a, r) Rel (q, a)

Rel(q, r) a, Inside(a, r) Rel (q, a)
Rel base predicate involving points q a. problem involving
points regions curves, replacing occurrence non-base predicates involving
region, as, Rel(q, r), equivalent expression consisting Inside base
predicates involving points only, using lemma 2, results expression
consisting base predicates involving points triangular regions only.
processes employed involves curves regions. Thus, subproblem
resulting decomposing problem contain base predicates only.
3.3 Mapping Similar Problem
Definition 10. Similarity. define two spatial problems (quantified expressions)
similar exists one-to-one correspondence variables (free quantified).
Given two similar problems, 1 2 , solution 1 1 , goal construct
one-to-one mapping variables 1 2 solution 2
obtained replacing variables 1 corresponding variables, thereby
completely bypassing QE process computational bottleneck SPS. one-toone mapping exists 1 2 logically equivalent. However, equivalence checking
logical expressions NP-hard (Dershowitz & Jouannaud, 1990; Goldberg & Novikov,
2003). Thus, equivalence checking cannot used determine similarity eciently.
Problem features. Let quantier free expression expressed
prenex form, i.e.,
(v1 , ...vm ) Q(xn , ...x1 ) (v1 , ...vm , x1 , ...xn )
variable xi appears Q Q contains redundant variables.
quantier block qb Q maximal contiguous subsequence Q every variable
qb quantier type. quantier blocks ordered sequence
appearance Q; qb1 qb2 qb1 equal appears qb2 Q. quantied
398

fiExecuting Perceptions Actions Diagrammatic Reasoning



...
P1

V

P2

P3

V

P4



P6

P5
Figure 13: Parse tree matrix problem conjunctive normal form.

variable xi appears quantier block qb(xi ), ordering quantier blocks imposes partial order quantied variables. variables
quantier block unordered.
Let 1 Q1 1 2 Q2 2 1 2 parse trees 1 2 respectively. example, matrix problem conjunctive normal form might look like:
P1 (P2 P3 ) (P4 P5 P6 ) ...
Pi predicate. subproblem, Pi base predicate. parse
tree sentence shown Figure 13.
Two trees, 1 2 , isomorphic exists bijection : 1 2 preserves adjacency root vertex, i.e., (u) adjacent (w) u adjacent w,
(root(1 )) = root(2 ). follows two isomorphic trees maximum height
number vertices height. Let l maximum height
number vertices height i. function , dened

(< 1 , ... >) =






i1

integer, <> denotes sequence, ith smallest prime number,
maps sequence integers unique integer. problem , tuple ()
constructed follows:

399

fiBanerjee & Chandrasekaran

() =

< l,
(# vertices dierent heights parse tree),
# quantier blocks,
order quantier blocks,
(# variables dierent quantier blocks) >

Definition 11. Structural Equivalence. Two spatial problems (quantified expressions),
1 2 , structurally equivalent satisfy following conditions:
1. (1 ) = (2 )
2. 1 2 isomorphic other, 1 2 parse trees matrices
1 2 respectively.
3. contents (predicate boolean operator {, , }) pair corresponding nodes
1 2 identical.
4. exists one-to-one correspondence variables arguments
predicates contained pair corresponding nodes 1 2 . Moreover, two
mappings obtained two pairs corresponding nodes 1 2 contradict
other.
see section 4, structural equivalence two problems computed
time linear size parse trees. Note two problems structurally
equivalent, logically equivalent vice versa. example, expressions (P P ) Q Q, P Q base predicates, logically equivalent,
structurally equivalent since parse trees isomorphic. general, logical
equivalence imply structural equivalence redundancies (redundant
variables and/or predicates) one problems. sake computational eciency, use structural equivalence determine similarity two problems.
Theorem 3. subproblems obtained decomposing problem always similar.
Proof. Let us assume, contradiction, exists problem decomposes
subproblems two them, j k , dissimilar. Without loss generality,
assume subproblems except k similar j . Then,

n

(ni11=1 ni22=1 ... ipp=1 Qi1 i2 ...ip i1 i2 ...ip ) Qk k , {, },
j {i1 i2 ...ip |0 i1 n1 , 0 i2 n2 , ...0 ip np },
Qj {Qi1 i2 ...ip |0 i1 n1 , 0 i2 n2 , ...0 ip np }
n

ni11=1 ni22=1 ... ipp=1 (Qi1 i2 ...ip Qk )(i1 i2 ...ip k )
ni11=1 ni22=1 ... ipp=1 Qi1 i2 ...ip i1 i2 ...ip
n

Thus, subproblems similar contradicts assumption. Hence proof
follows.
Intuitively, proposed framework, curve represented arbitrary number vertices, line segment always represented two end points. Similarly,
400

fiExecuting Perceptions Actions Diagrammatic Reasoning

periphery region represented arbitrary number vertices, periphery
triangular region always represented three vertices. Hence, two line segments
triangular regions always represented similarly dier coordinates
constituent vertices, unlike two curves regions. base predicates dened terms
base objects points, line segments, triangular regions. Thus, predicate
dened conjunctions disjunctions base predicates, base predicates always
similar. Decomposition problem subproblems merely replaces one
predicates similar base predicates. Hence, subproblems similar.
3.4 Memory Organization
Memory SPS hierarchically organized stores problems disjoint classes based
progressively problems features (see Figure 14). decomposing problem
subproblems computing , subproblems value ,
SPS checks whether parse trees isomorphic mapping exists
variables. Since memory hierarchy constant height, insertion problem
searching potential class similar problems executed constant time. Also,
features classify problems discriminative enough create large number
classes (leaf nodes), class containing problems, thereby reducing search
problems belonging class.

4. Computational Complexity
analyze time complexity algorithms used framework.
implementation, problem data structure consisting two elds P arseT ree
Solution. P arseT ree stores lexicographically sorted parse tree matrix
Solution stores symbolic solution concise form. parse tree
constructed time O(t) number base predicates boolean
operators {, , } . boolean operators occupy non-leaf nodes parse tree
base predicates occupy leaf nodes. Lexicographically sorting tree requires
lexicographically sorting contents children non-leaf node tree. Let
number boolean operators ti number children ith boolean


operator. Thus,
ti = 1. Note since base predicate always followed
i1

boolean operator, = constant. Lexicographically sorting list
contents children node requires O(ti logti ) time. Thus, total time required


repeating process non-leaf nodes
O(ti logti ). Since average number
i1



children per node

i1



tree



i1

1





O(

ti =

t1
, total time required lexicographically sort


t1
t1
log ) = O(t).



401

fiBanerjee & Chandrasekaran

l
l1

...

lk

[ (# vertices different

[ (# vertices different

levels parse tree)

levels parse tree)



1

...

Dm

#(qb)

q1

...

#(qb)

qr

...

order qbs

o1

...

...

order qbs

os

...

[ (# variables

[ (# variables

different qb's)

different qb's)

E

1

...

Et

...

Problems

Problems

Figure 14: Hierarchical problem classication memory. height hierarchy,
branches correspond dierent values features captured .
example, l1 lk correspond k dierent maximum heights
parse trees matrices spatial problems.

Given two problems 1 , 2 , algorithm Similar(1 , 2 ) computes whether 1
2 similar (see Figure 15). Since computing requires O(t) time,
line 1 requires O(t) time. Since checking whether two trees isomorphic requires
O(t) time (as shown Aho, Hopcroft, & Ullman, 1974), line 6 requires O(t) time. Lines 9
11 requires O(t) time. Thus, algorithm runs O(t) time.
Given unsolved problem similar solved problem similar , algorithm
ComputeSolutionF romSimilarP roblem(, similar ) computes solution variable mapping similar (see Figure 16). V ariableM ap list entry
pair < v, vsimilar >, v free variable vsimilar corresponding free
variable similar . Let size V ariableM ap k . lines 5 11 requires
O(tk ) time since number nodes similar number arguments
predicate small. Lines 12 13 requires O(k ) time size
solution similar . Thus, algorithm runs O(tk + k ) time.
Finally, given unsolved problem memory emory stores problems hierarchically (as described section 3.4), algorithm EliminateQuantif iers(, emory)
computes solution variable mapping similar problem emory,
problem exists; otherwise solves using problem classier combination constraint
402

fiExecuting Perceptions Actions Diagrammatic Reasoning

Similar(1 , 2 )
1. (1 ) = (2 ),
2.
return F alse
3. else
4.
1 1 .P arseT ree
5.
2 2 .P arseT ree
6.
Isomorphic(1 , 2 ) = F alse,
7.
return F alse
8.
else
9.
node 1
10.
predicate boolean operator corresponding node 2
match,
11.
return F alse
12. return rue

Figure 15: Algorithm deciding whether two problems 1 , 2 similar
computing structural equivalence. problem quantied expression.

ComputeSolutionF romSimilarP roblem(, similar )
1. .P arseT ree
2. similar similar .P arseT ree
3. similar similar .Solution
4. similar
5. node similar
6.
node contains predicate (say P ),
7.
j 1 # arguments P
8.
v variable occupying j th argument P
9.
vsimilar variable occupying j th argument P similar
10.
V ariableM ap.Contains(v) = F alse,
11.
V ariableM ap.Add(< v, vsimilar >)
12. 1 |V ariableM ap|
13.
Replace occurrences V ariableM ap[i, 2] V ariableM ap[i, 1]
14. return

Figure 16: Algorithm computing solution problem mapping variables
similar problem similar . problem quantied expression
solution equivalent quantier-free expression.

solvers QE algorithms (as described section 3). algorithm shown Figure
17.
403

fiBanerjee & Chandrasekaran

Let n subproblems problem. problem, predicates already base predicates rest written conjunctions/disjunctions
base predicates thereby leading decomposition problem subproblems.
example, section 1.1, problem RiskyP ortionsof P ath(q, c1 , c2 , d) dened terms
base predicate DistanceLessT han(p, q, d) (i.e., Distance(p, q) d) nonbase predicates On(q, c1 ) On(p, c2 ). non-base predicates written
disjunctions base predicates, as, On(q, {c1 [i], c1 [i + 1]}) On(q, {c2 [j], c2 [j +
1]}), respectively, thereby leading decomposition RiskyP ortionsof P ath subproblems. subproblems inherits base predicates problem (e.g.,
DistanceLessT han(p, q, d)) also includes new base predicates (e.g., On(q, {c1 [i], c1 [i+
1]}), On(q, {c2 [j], c2 [j + 1]})) obtained non-base predicates. Let number
polynomials base predicates problem number polynomials due
newly obtained base predicates subproblem. Since subproblems similar,
+ polynomials. total number polynomials problem
O( + n).
Let maximum degree polynomial subproblem. Since subproblems
similar, maximum degree d. maximum degree polynomials
problem also objects represented piecewise-linearly, case 2.
objects represented piecewise-linearly, degree much larger
two might lead situation problem might solvable reasonable
time.
Let k number quantied variables problem. subproblem
also k quantied variables. Let computational complexity using general QE
algorithm solving problem (n) solving subproblem (1),
k1
doubly exponential function, as, using CAD, (n) = (sd)O(1) . Note
(n) nT (1), i.e., ecient solve subproblem using general QE
algorithm solve whole problem using algorithm.
algorithm EliminateQuantif iers(, emory), lines 4 7 require O(n) time.
Lines 8 9 require O(t) time each. Since line 13 requires O(t) time, lines 11
16 require O(mt) time. Line 18 requires time (1) lines 20 23 require
O((n1)(tk +k )) time. Thus, entire algorithm runs O(T (1)+mt+(n1)(tk +k ))
time. Note size symbolic solution, symbolic solution
expressed concisely, small. Since number boolean operators
order number base predicates base predicate dened terms
least one polynomial, = O(s) = O( + n). Thus, complexity algorithm
O(T (1) + (m + (n 1)k )s + (n 1)k ). seen
nT (1) > (1) + (m + (n 1)k )s + (n 1)k
or,

(( + )d)O(1)

k1


> ( n1
+ k )( + n) + k

true provided large. is, ecient solve problem variable
mapping solve subproblem using general QE algorithm provided size
stored symbolic solution large. every decomposable problem, complexity
QE reduced above.
404

fiExecuting Perceptions Actions Diagrammatic Reasoning

EliminateQuantif iers(, emory)
1. .Solution
2. Decompose subproblems Qi , 1 n
p

np
n1
n2

nk
i1 =1 i2 =1 ... ip =1 Qi , n =
k1

3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.
15.
16.
17.
18.
19.
20.
21.
22.
23.

i1
k p 1
j 1 nk
ith operator ( ) decomposed right left
ii+1
Construct parse tree matrix 1
Compute ()
f lag 0
j 1
emory,j j th problem emory
Similar(M emory,j , 1 ) = rue,
similar emory,j
f lag 1
break loop
f lag = 0,
1 .Solution ComputeSolutionF romQEAlgorithms(1 )
similar 1
(2 f lag + 2)\3 n
.Solution ComputeSolutionF romSimilarP roblem(i , similar )
.Solution .Solution .Solution
return .Solution

Figure 17: Algorithm computing solution spatial problem taking help
previously solved similar problems emory, thereby bypassing quantier
elimination whenever possible. problem quantied expression
solution equivalent quantier-free expression.

problem encountered SPS rst time, solved decomposing subproblems, solving rst subproblem using general QE algorithm
obtaining solution rest subproblems mapping variables
rst subproblem. Since subproblem solution stored memory, similar
subproblem encountered future, SPS bypasses QE algorithm completely
solves variable mapping. case, line 18 algorithm never executed,
time complexity solving problem
(m + nk )s + nk

405

fiBanerjee & Chandrasekaran

considerable savings compared complexity solving entire problem
k1
using general QE algorithm (e.g., complexity CAD (sd)O(1) ), provided
large. SPS solves problems, probability encounter similar problem
memory increases thereby leading scenario incurs complexity low
order polynomial compared doubly exponential.3
Example. illustrate problem solving process, let us consider spatial problem BehindCurve(q, c, p) (described section 2.3). point p (px , py ) curve
c {p1 , p2 , ...pn } pi (xi , yi ) point, decomposition problem occurs
follows:

BehindCurve(q, c, p)
Intersect(c, {p, q})
a, On(a, c) On(a, {p, q})
a, (n1
i=1 On(a, {pi , pi+1 })) On(a, {p, q})
n1
i=1 (a, On(a, {pi , pi+1 }) On(a, {p, q}))

n1
i=1 (Qi )

n1
i=1
Thus (n 1) subproblems ,
On(a, {pi , pi+1 }) On(a, {p, q})
Qi
a, On(a, {pi , pi+1 }) On(a, {p, q})
Figure 18, (i ) =< 2, 21 33 , 1, < >, 21 > = 1, 2, ...n 1. theorem 3,
similar since subproblems problem. SPS
3. noted approximating continuous curve sequence line segments drawbacks. example, point p continuous curve c might piecewise-linear
approximation c. SPS accept parameter specifies maximum length line
segment used approximation. current implementation, leave onus determining maximum length problem solver. context, deserves mention loss
information inevitable almost kind approximation. example, space
diagram approximated finite number pixels, shown Banerjee Chandrasekaran (2010),
diagrammatic objects lose certain spatial information might detrimental spatial problem
solving avoided knowing minimum allowable resolution (or maximum length one
side square pixel).

406

fiExecuting Perceptions Actions Diagrammatic Reasoning



On(a,{p1,p2})

On(a,{p,q})

Figure 18: Parse tree matrix rst subproblem BehindCurve problem.

nd problem memory similar rst subproblem 1 , sent problem
classier sends appropriate QE algorithm. problem denition, tuple
, parse tree, solution stored memory follows:
1 (q, {p1 , p2 }, p) a, On(a, {p1 , p2 }) On(a, {p, q})
1 ((x, y), {(x1 , y1 ), (x2 , y2 )}, (px , py ))
(px x < 0 px x1 0 x1 x 0 py x1 py x + px x1 px y1 + xy1 = 0) (x px <
0 x1 px 0 x x1 0 py x1 py x + px x1 px y1 + xy1 = 0) ...
arguments 1 free variables. subproblems solved
replacing variables 1 mapped variables. problem similar 1 found
memory, 1 also solved replacing mapped variables,
subproblems.
Note that, example, BehindCurve problem, absence appropriate
vocabulary properties/relations, would specied (see redlog Weispfenning, 2001):
BehindCurve((x, y), {(p1,x , p1,y ), (p2,x , p2,y ), ...(pn,x , pn,y )}, (px , py ))
ax , ay , t, 0 1 px + t(x px ) = ax py + t(y py ) = ay n1
i1 (ti , 0 ti
1 pi,x + ti (pi+1,x pi,x ) = ax py + ti (pi+1,y pi,y ) = ay )
total number quantiers n + 3, dependent number line segments
forming curve huge complicated curves many real-world applications. SPS, due appropriate decomposition problems subproblems,
number quantiers subproblem always xed (4 case) irrespective
spatial complexity object(s) (curve case). symbolic solutions
simple subproblems stored future use possible systems like redlog. Needless say, though solving problem using systems produce
solution, much faster.
407

fiBanerjee & Chandrasekaran

5. Applications
section, illustrate SPS deployed conjunction problem
solver, human articial (such as, soar), solving spatial problems without human intervention needed DR. Two applications considered entity re-identication
ambush analysis deemed important military domain. subproblems SPS autonomously decomposes spatial problem shown.
Problems military domain involve wide variety objects arbitrary properties
relations, hence, help illustrate expressiveness specication language
eciency generality SPS.
implementation, used bisoar, due Kurup Chandrasekaran (2007),
bimodal version soar (Laird et al., 1987), problem solver uses two kinds operators predicate-symbolic operators applied information predicate-symbolic
form perception-like operators applied diagram bring state
transitions reach goal state initial state. human responsible providing
broad problem solving strategy class problems; given specic problem
class, bisoar uses predicate-symbolic perception-like operators accordingly.
Since used bisoar number dierent domains (e.g., military, Euclidean geometry, physics, civil engineering; Banerjee & Chandrasekaran, 2007 provide examples)
still continue so, knows several dierent problem solving strategies operators, predicate-symbolic perception-like. emphasis section
eciently bisoar solves problems eciently perception-like operators
executed without incorporating knowledge jeopardizes generality
general-purpose problem solver. spatial problem, compare performance
proposed SPS CAD algorithm terms actual computation time
determined taking average least 10 runs. see, SPS excels
signicant margin cases.
5.1 Entity Re-identification
entity re-identication problem core task US Armys All-Source Analysis
System (ASAS). ASAS receives new report sighting entity T3 type (e.g.
tanks). task decide new sighting entities
database earlier sightings, entirely new entity. Reasoning dynamically
integrate information dierent sources database sightings, mobility vehicles,
sensor reports, terrain map information make decision. follow novel
capability using failure expectation: H true, observed,
since not, H likely case, H hypotheses observations
respectively (Josephson & Josephson, 1996; Chandrasekaran et al., 2004). following,
consider simple version problem illustrate task solved using DR
spatial problems involved therein.
Figure 19(a) shows terrain interest mountainous closed regions marking
impassable areas entities type (e.g., tanks). Let T3 entity newly sighted
time t3 located point p3 T1 , T2 two entities located points p1 ,
p2 last sighted times t1 , t2 respectively. T1 T2 retrieved database
potential T3 based partial identity information. Also,
408

fiExecuting Perceptions Actions Diagrammatic Reasoning

T2

T1

T3

(a) Terrain, impassable regions, sighted tanks.

(c) short path T1 T3 .

(b) short path T2 T3 .

(d) path plausible homotopy
class.

Figure 19: Reasoning steps entity re-identication
area interest, three enemy regions obstacles {r1 , r2 , r3 } (as shown Figure
19(a)) given repower/sight range enemy. Reasoning proceeds follows.
T1 reach p3 within time t3 t1 , T3 might T1 . Similarly T2 . Since
mountainous region (or obstacle) hiding place enemies repower range d,
existence entity shows probably traverse territory
within repower range. Further, might sensor elds report database
sense entities. entity sensed sensor eld times t1
t3 , T1 could followed path passed sensor eld.
constraints taken account reasoning. information might
available database once. follows simple scenario discussion
spatial problems occur.
problem solver (e.g., commander) wants know whether exists contiguous
safe region containing points p1 p3 . species problem Saf eRegion follows:
Saf eRegion(q, {r1 , r2 , ...rn }, d)

409

fiBanerjee & Chandrasekaran

a, (ni1 Inside(a, ri )) Distance(q, a)
# (ri )


a, (ni1 j1

# (ri )


a, (ni1 j1

Inside(a, (ri )[j])) Distance(q, a)

Inside(a, (ri )[j])) Distance(q, a)

# (ri )

a, Inside(a, (ri )[j]) Distance(q, a)

# (ri )

a, Inside(a, (ri )[j]) Distance(q, a)

# (ri )

Saf eRegion (q, {(ri )[j]}, d)


ni1 j1

ni1 j1

ni1 j1

q (x, y). Decomposition problem SPS shown above. subproblem symbolically solved solution stored memory along subproblem
specication. order compare actual times required solve problem, constructed simple diagram consisting four polygonal regions depicting obstacles (see
Figure 20(a)). four regions
r1 {(10, 10), (30, 10), (30, 30), (10, 30)},
r2 {(20, 0), (0, 0), (10, 20)},
r3 {(0, 20), (10, 40), (10, 40)},
r4 {(50, 20), (70, 20), (80, 40), (60, 50), (40, 40)},
2. Triangulation regions produced seven triangles. subproblem
symbolically solved stored, solving problem required 0.25 seconds solving
using CAD algorithm required 5.5 seconds.
diagram shaded safe region input Recognize function computes vertices boundaries shaded region, shown Figure 20(b). Next
problem solver wants know whether exists path points p1 p3 safely
avoiding obstacles enemy repower range, whether path traversed
time t3 t1 . Let v velocity sighted entity piece symbolic knowledge
available database. Then, maximum length path traversable given
time L = v (t3 t1 ). Let l L rational number. Then, problem path
existence two points path lies inside region r less
given length l specied as:
P athExists(s, t, r, l)
q, Inside(q, r) Distance(s, q) + Distance(q, t) l
# (r)


q, (i1
Inside(q, (r)[i])) Distance(s, q) + Distance(q, t) l

410

fiExecuting Perceptions Actions Diagrammatic Reasoning

r3

r3

r4

r4

r1

r1

r2

r2



(a) unshaded polygons obstacles.
shaded region safe region, computed
SPS.

(b) points shown vertices boundaries safe region computed
Recognize function.





r3

r3

r4

r1

r2

r4

r1

r2







(c) Paths lying safe region less
given length two points, computed
SPS.

(d) Paths lying safe region less
given length two points, computed
CAD algorithm.

Figure 20: simplied scenario illustrate performance proposed SPS compared CAD algorithm entity re-identication.

# (r)


i1
q, Inside(q, (r)[i]) Distance(s, q) + Distance(q, t) l

# (r)


i1
P athExists (s, t, (r)[i], l)

411

fiBanerjee & Chandrasekaran

Decomposition problem SPS shown above. subproblem symbolically
solved stored. Again, resort simple diagram Figure 20 compare actual
computation times P athExists(s, t, r, l) problem, (0, 45), (20, 5),
r Recognize(Saf eRegion((x, y), {r1 , r2 , ...rn }, 2)), dierent sets regions ri
dierent values l. Triangulation r produced 8, 7, 7, 9 24 triangles {r1 }, {r2 },
{r3 }, {r4 } {r1 , r2 , r3 , r4 } respectively. subproblem symbolically solved
stored, computation times required solving problem using proposed SPS
signicantly less using CAD algorithm (see Table 1).

Table 1: Comparison computation times (in seconds) CAD algorithm
proposed SPS P athExists(s, t, r, l) problem, (0, 45),
(20, 5), r Recognize(Saf eRegion((x, y), {r1 , r2 , ...rn }, 2)). 2.8 GHz PC
4 GB RAM, 5356 MB virtual memory 32-bit operating system used.
implementation done athematica. Below, res refers result,
refers rue, F refers F alse, OOM refers memory.

l
100
500
1000
1009
1010
2000
4000
8000
16000

{r1 }
CAD,SPS,res
2.78, 0.41, F
2.77, 0.42, F
2.66, 0.39, F
2.28, 0.42,
2.28, 0.41,
1.88, 0.39,
1.88, 0.34,
1.88, 0.33,
1.88, 0.33,

{r2 }
CAD,SPS,res
498.22, 0.53, F
482.77, 0.44, F
118.97, 0.55,
119.28, 0.52,
120.06, 0.53,
120.38, 0.42,
120.73, 0.39,
121.58, 0.34,
121.45, 0.34,

{r3 }
CAD,SPS,res
470.74, 0.5, F
476.97, 0.5, F
135.03, 0.49,
134.75, 0.5,
135.02, 0.52,
135.3, 0.38,
135.08, 0.34,
135.03, 0.33,
135.13, 0.36,

{r4 }
CAD,SPS,res
OOM, 0.47, F
OOM, 0.48, F
OOM, 0.49,
OOM, 0.52,
OOM, 0.47,
OOM, 0.44,
OOM, 0.31,
OOM, 0.39,
OOM, 0.36,

{r1 , r2 , r3 , r4 }
CAD,SPS,res
OOM, 1.42, F
OOM, 1.42, F
OOM, 1.42, F
OOM, 1.42, F
OOM, 1.41,
OOM, 1.19,
OOM, 1.0,
OOM, 0.98,
OOM, 0.92,

general, P athExists(s, t, r, l) problem specied as:
P athExists(s, t, r, l)
q1 , q2 , ...qn , (a, On(a, {s, q1 , q2 , ...qn , t}) Inside(a, r)) Length({s, q1 , q2 , ...qn , t}) l
q1 , q2 , ...qn , (a, On(a, c) Inside(a, r)) Length(c) l
q1 , q2 , ...qn , (a, On(a, c) Inside(a, r)) Length(c) l
# (r)


q1 , q2 , ...qn , (a, On(a, c) (k1
Inside(a, (r)[k]))) Length(c) l

# (r)


q1 , q2 , ...qn , (a, On(a, c) (k1
Inside(a, (r)[k]))) Length(c) l

412

fiExecuting Perceptions Actions Diagrammatic Reasoning

# (r)


k1
q1 , q2 , ...qn , (a, On(a, c) Inside(a, (r)[k])) Length(c) l

# (r)


k1
P athExists (s, t, (r)[k], l)

c {s, q1 , q2 , ...qn , t} r Br. Note even though c curve, On(a, c)
cannot decomposed since c free variable (see denition Decomposition
section 3.2). Also, note problem contains form F 2 discussed heorem
1, r used.
exists path points p1 p3 safely avoiding obstacles enemy
repower range traversed time t3 t1 , problem solver wants
compute path(s). problem specied as:
F indP ath(q, s, t, r, l)
Inside(q, r) Distance(s, q) + Distance(q, t) l
# (r)


(i1
Inside(q, (r)[i])) Distance(s, q) + Distance(q, t) l

# (r)


i1
Inside(q, (r)[i]) Distance(s, q) + Distance(q, t) l

# (r)


i1
F indP ath (q, s, t, (r)[i], l)

q (x, y). Since quantiers, solving problem decomposition
variable mapping achieve reduction computation time anysignicant amount.
region consisting paths satisfy constraints (l 1010) shown
Figure 20(c). quality solution depends Recognize function. example,
solution shown Figure 20(d) accurate Figure 20(c) Recognize
function failed determine vertices safe region accurately. alternate denition
semi-linear motion planning problem found Weispfenning (2001),
semi-linear path consists n translations along straight lines parallel
one given k vectors.
results, problem solver infers T3 might T1 . Next repeats
entities T3 T2 , nds exists path points p2 p3
safely avoiding obstacles enemy repower range traversed
time t3 t2 . T3 might T2 well. sensor database informs two
sensor elds SENSOR1, SENSOR2 area interest report
passing vehicle. Problem solver wants verify whether paths passes
sensor elds. species problem Intersect(r1 , r2 ) compute
intersection two regions r1 r2 .
IntersectRegions(r1 , r2 )
q, Inside(q, r1 ) Inside(q, r2 )
# (r1 )


q, (i1

# (r2 )


Inside(q, (r1 )[i])) (i1

Inside(q, (r2 )[j]))

413

fiBanerjee & Chandrasekaran

# (r1 )


i1

# (r2 )


j1

IntersectRegions ((r1 )[i], (r2 )[j])


computes

problem
IntersectRegions(paths13 , s1 ) paths13 Recognize(F indP ath(q, p1 , p3 , r, l))
s1 region covered SENSOR1. scenario Figure 19(c), solution rue.
Next problem solver wants know whether exists path points p1
p3 safely avoiding obstacles enemy repower range traversed
time t3 t1 . computes P athExists(p1 , p3 , r13 , l), r13 Recognize(paths13 s1 ),
returns rue. inference follows T3 might T2 . reasoning
repeated T3 T2 ; Intersect(paths23 , s2 ) returns rue P athExists(p2 , p3 , r23 , l)
returns F alse (see Figure 19(b)). inference follows T3 cannot T1 . Hence,
problem solver identies T3 T2 .
entity reidentication problem could also solved computing shortest paths pairs p1 , p3 p2 , p3 avoiding sensors checking whether
lengths satisfy time constraints. requires computing shortest path two points p1 p3 safely avoiding obstacles enemy repower range (i.e.,
lying entirely within safe region r). Since path loop
share intermediate vertices, any, vertices r, path
#(r) intermediate vertices. Let r {p1 , p3 }, #(S), c {q1 , q2 , ...qm }
shortest path, q1 p1 , qm p3 , qi r (2 1). Then, problem
computing shortest path specied
F indShortestP ath(r, c)
inimize(Length(c), {c[2], c[3], ...c[m 1]}, CurveInsideRegion(c, r))
CurveInsideRegion(c, r) constraint specied decomposed
follows.
CurveInsideRegion(c, r)
a, On(a, c) Inside(a, r)
a, On(a, c) Inside(a, r)
a, On(a, c) Inside(a, r)
#(c)1

a, (i1

# (r)

a, On(a, {c[i], c[i + 1]}) Inside(a, (r)[j])

# (r)

CurveInsideRegion ({c[i], c[i + 1]}, (r)[j])

#(c)1


j1

#(c)1


j1

i1
i1

# (r)


On(a, {c[i], c[i + 1]})) (j1
Inside(a, (r)[j])))

414

fiExecuting Perceptions Actions Diagrammatic Reasoning

r Br. Since problem form F 2, r used. subproblem symbolically solved stored, solving problem CurveInsideRegion(c, r),

c {(0, 45), (14, 42), (35, 42), (15, 35), (34, 32), (36, 19), (47, 15), (87, 15), (30, 7), (20, 5)},
r Recognize(Saf eRegion((x, y), {r1 , r2 , r3 , r4 }, 2)),
SPS required 3.11 seconds solving using CAD algorithm required 175.01 seconds (see Figure 21(a)). shortest path obtained solving
F indShortestP ath(r, c) problem shown Figure 21(b).

(a) path c two points lying inside
shaded region r.

(b) Shortest path two points computed
F indShortestP ath(r, c) problem.

Figure 21: Paths two points lying inside safe (shaded) region.

5.2 Ambush Analysis
two main factors range repower sight determine area covered
military unit. Presence terrain features, as, mountains, limit factors
allow units hide opponents. hidden units enjoy advantage
concealing resources intentions opponents also attack
opponents catching unawares traveling along path within
sight repower range hidden units, thereby ambushing them. Thus,
utmost importance military unit priori determine areas portions
path prone ambush traversing them. already described section 1.1
problem solver (e.g., army commander) reasons using diagrams gure safest
path transport troops one base camp another given time. section,
given curve region hiding place repower sight ranges, show
415

fiBanerjee & Chandrasekaran

regions portions path prone ambush eciently computed proposed
SPS.
Given curve c repower sight range d, spatial problem
RiskyRegion(q, c, d) dened set points covered range c. Thus,
problem specication is:
RiskyRegion(q, c, d)
a, On(a, c) Distance(a, q)
#(c)1

a, (i1

On(a, {c[i], c[i + 1]})) Distance(a, q)

#(c)1

a, On(a, {c[i], c[i + 1]}) Distance(a, q)

#(c)1

RiskyRegion (q, {c[i], c[i + 1]}, d)

i1
i1

q (x, y). order compare actual computation times required solve
problem, constructed simple diagram consisting two curves, path mntn,

path {(25, 10), (5, 10), (3, 15), (7, 17), (2, 18), (2, 18), (7, 15),
(3, 12), (5, 10), (40, 10)}
mntn {(5, 5), (7, 2), (9, 9), (6, 12), (0, 4), (2, 3), (15, 5), (25, 12), (30, 20)}
solution problem RiskyRegion(q, mntn, d) shaded region shown Figure
22(a) mntn obstacle hiding (e.g., mountain range) 15. problem
RiskyRegion(q, r, d) region r specied replacing predicate On(p, c)
Inside(p, r).
Again, given curve c1 path, curve c2 hiding, repower range d,
problem RiskyP ortionsof P ath(q, c1 , c2 , d) dened parts c1 covered range
c2 . Thus,
RiskyP ortionsof P ath(q, c1 , c2 , d)
On(q, c1 ) p, On(p, c2 ) Distance(p, q)
#(c )1

p, (i11

#(c )1

j12

#(c )1

j12

i11
i11

#(c )1

On(q, {c1 [i], c1 [i+1]}))(j12

#(c )1

#(c )1

On(p, {c2 [j], c2 [j +1]}))Distance(p, q)

p, On(q, {c1 [i], c1 [i+1]}))On(p, {c2 [j], c2 [j +1]})Distance(p, q)
RiskyP ortionsof P ath (q, {c1 [i], c1 [i + 1]}, {c2 [j], c2 [j + 1]}, d)

416

fiExecuting Perceptions Actions Diagrammatic Reasoning

(a) shaded region, computed
problem RiskyRegion(q, mntn, 15), risky
region prone ambush due enemies hiding
mntn. portions path inside risky region risky portions path.

(b) bold parts path, computed
problem RiskyP ortionsof P ath(q, path,
mntn, 15), risky portions path.
shaded region, computed problem BehindCurvewrtRiskyP ath(q, mntn, path),
enemies could hiding troops traveling path.

(c) Troops traveling rskyprtn1 , risky portion (in bold) path, careful
ambushed enemies hiding shaded region rskyprtn1 within firepower range
region, computed problem
BehindCurvewrtRiskyP athDistance(q, mntn,
rskyprtn1 , 20).

(d) Troops traveling rskyprtn2 , risky portion (in bold) path, careful
ambushed enemies hiding shaded region rskyprtn2 within firepower range
region, computed problem
BehindCurvewrtRiskyP athDistance(q, mntn,
rskyprtn2 , 20).

Figure 22: simplied scenario illustrate performance proposed SPS ambush analysis.

417

fiBanerjee & Chandrasekaran

q (x, y). Alternatively, problem specied
RiskyP ortionsof P ath(q, c1 , r2 , d)
On(q, c1 ) Inside(q, r2 )
#(c )1

(i11

# (r2 )


On(q, {c1 [i], c1 [i + 1]})) (j1

# (r2 )

On(q, {c1 [i], c1 [i + 1]}) Inside(q, (r2 )[j])

# (r2 )

RiskyP ortionsof P ath (q, {c1 [i], c1 [i + 1]}, (r2 )[j], d)

#(c )1


j1

#(c )1


j1

i11

i11

Inside(q, (r2 )[j]))

r2 Recognize(RiskyRegion((x, y), c2 , d)) q (x, y).
solution
problem RiskyP ortionsof P ath(q, path, mntn, d), 15, parts
path inside shaded region shown Figure 22(a). Figure 22(b) shows
risky portions path rskyprtn1 , rskyprtn2 bold obtained
Recognize(RiskyP ortionsof P ath(q, c1 , c2 , d)).
rskyprtn1 {(16, 10), (5, 10), (3.7, 12.6)}
rskyprtn2 {(3, 12), (5, 10), (16.1, 10)}
Note latter specication free quantiers former not. However,
solution computed latter specication might less accuracy
former due use Recognize function. hiding place region r
instead curve c2 , problem RiskyP ortionsof P ath(q, c1 , r, d) specied
replacing predicate On(p, c2 ) Inside(p, r). portions path marked Figure
2(c) computed specication.
region behind c2 enemies might hiding set points
behind c2 respect point risky portions curve c1 . Thus, c risky
portion path,
BehindCurvewrtRiskyP ath(q, c2 , c)
a, On(a, c) BehindCurve(q, c2 , a)
a, On(a, c) Intersect(c2 , {a, q})
a, On(a, c) (b, On(b, c2 ) On(b, {a, q}))
#(c)1

a, b, (i1
#(c)1

i1

#(c )1

j12

#(c )1

On(a, {c[i], c[i + 1]})) (j12

On(b, {c2 [j], c2 [j + 1]})) On(b, {a, q})

(a, b, On(a, {c[i], c[i + 1]}) On(b, {c2 [j], c2 [j + 1]}) On(b, {a, q}))

418

fiExecuting Perceptions Actions Diagrammatic Reasoning

#(c)1

i1

#(c )1

j12

BehindCurvewrtRiskyP ath (q, {c2 [j], c2 [j + 1]}, {c[i], c[i + 1]})


q (x, y). solution problem BehindCurvewrtRiskyP ath(q, mntn, rskyprtn1 )
BehindCurvewrtRiskyP ath(q, mntn, rskyprtn2 ) shaded region shown Figure 22(b). hiding place region r instead curve c2 , problem
BehindCurvewrtRiskyP ath(q, r, c) specied replacing predicate On(p, c2 )
Inside(p, r).
However, enemies might hiding anywhere behind mountain within
distance ambush friendly units. Hence, reasonable problem commander friendly side compute would
BehindCurvewrtRiskyP athDistance(q, c2 , c, d) distance
enemies ambush them. problem specied as:
BehindCurvewrtRiskyP athDistance(q, c2 , c, d)
a, On(a, c) BehindCurve(q, c2 , a) Distance(a, q)
a, On(a, c) Intersect(c2 , {a, q}) Distance(a, q)
a, On(a, c) (b, On(b, c2 ) On(b, {a, q})) Distance(a, q)
#(c)1

#(c )1

a, b, (i1 On(a, {c[i], c[i + 1]})) (j12
Distance(a, q)
#(c)1

On(b, {c2 [j], c2 [j + 1]})) On(b, {a, q})

#(c )1

i1 j12
(a, b, On(a, {c[i], c[i + 1]}) On(b, {c2 [j], c2 [j + 1]}) On(b, {a, q}))
Distance(a, q)
#(c)1

i1
1]}, d)

#(c )1

j12

BehindCurvewrtRiskyP athDistance (q, {c2 [j], c2 [j + 1]}, {c[i], c[i +


q

(x, y).
solutions problems BehindCurvewrtRiskyP athDistance(q, mntn, rskyprtn1 , d)
BehindCurvewrtRiskyP athDistance(q, mntn, rskyprtn2 , d), 20,
shaded regions shown Figure 22(c), 22(d) respectively. hiding place region r
instead curve c2 , problem BehindCurvewrtRiskyP athDistance(q, r, c, d)
specied replacing predicate On(p, c2 ) Inside(p, r). comparison
CAD algorithm proposed SPS actual times required compute problems
relevant ambush analysis discussed shown Table 2.

419

fiBanerjee & Chandrasekaran

Table 2: Comparison computation times (in seconds) CAD algorithm
SPS dierent problems relevant ambush analysis. 2.8 GHz PC
4 GB RAM, 5356 MB virtual memory 32-bit operating system used.
implementation done athematica. following function
problems q (x, y).
P roblem
RiskyRegion(q, mntn, 15)
RiskyP ortionsof P ath(q, path, mntn, 15)
BehindCurve(q, mntn, (5, 10))
BehindCurvewrtRiskyP ath(q, mntn, path)
BehindCurvewrtRiskyP ath(q, mntn, rskyprtn1 )
BehindCurvewrtRiskyP ath(q, mntn, rskyprtn2 )
BehindCurvewrtRiskyP athDistance(q, mntn, rskyprtn1 , 20)
BehindCurvewrtRiskyP athDistance(q, mntn, rskyprtn2 , 20)

SPS
0.11
0.3
0.27
50.2
8.04
10.92
6.16
6.3

CAD
0.11
0.48
0.71
102.88
11.89
17.48
16.08
15.33

6. Discussion
Spatial problem solving area active research since Sutherlands sketchpad
(1963). need access, communicate manipulate spatial information precisely
(much engineers scientists do) using high-level language (much common people
use) one frontiers AI. well-known capabilities
oered rst-order predicate logic that, rst-order logic generally intractable
except limited domains. umbrella Qualitative Spatial Reasoning (QSR),
researchers investigated plethora spatial calculi, prominent
mereotopological calculi (Clarke, 1981; Bennett, 1997), cardinal direction calculus (Frank,
1991, 1992; Skiadopoulos & Koubarakis, 2004), double cross calculus (Freksa, 1992), 4and 9-intersection calculi (Egenhofer, 1991; Egenhofer & Franzosa, 1991), ip-op calculus
(Ligozat, 1993), dipole calculus (Moratz, Renz, & Wolter, 2000; Schlieder, 1995; Dylla &
Moratz, 2005), various region connection calculi (Randell et al., 1992; Bennett, Isli,
& Cohn, 1997; Gerevini & Nebel, 2002; Cohn, Bennett, Gooday, & Gotts, 1997; Duntsch,
Wang, & McCloskey, 1999; Gerevini & Renz, 1998). two main points distinction
QSR approach spatial problem solving reported paper.
1. dierent QSR calculi emphasize dierent aspects space, as, ontological issues, topology, distance, orientation, shape, etc. Depending spatial aspect interest, calculus based minimal set spatial relations.
example, 9-intersection calculus (Egenhofer & Franzosa, 1991)
based nine spatial relations {r0 , r1 , r3 , r6 , r7 , r10 , r11 , r14 , r15 } two spatial regions, double cross calculus (Freksa, 1992) based fteen spatial relations
{lf, lp, lc, ll, lb, sf, sp, sc, sl, sb, rf, rp, rc, rl, rb} among three points, etc. framework
based minimal set spatial relations; based xed set mathematical/logical operators (see section 2.3). spatial relation among points
expressed using real variables xed set operators rst-order logic included
vocabulary. spatial relation involving curves and/or regions expressed
420

fiExecuting Perceptions Actions Diagrammatic Reasoning

rst-order logic using spatial relations among points relations Inside
included vocabulary.
2. spatial problems interest QSR community CSPs involving either
points (e.g., double cross calculus) regions (e.g., 4- 9-intersection calculi, region
connection calculi) closed set properties/relations often limited binary
domain. general-purpose SPS helping human perceive act diagrams
dierent real-world applications need solve QCSPs involving points, curves
regions open-ended vocabulary properties/relations/actions entire
real domain, framework oers. Since QE computational bottleneck
SPS, concentrate eorts real QE algorithms, discussed towards
end section 2.3.
Naturally, question arises convenient human specify spatial
problem QCSP? acknowledge process specifying spatial problem
QCSP eortless explaining another human natural language,
taken rst step making process less strenuous oering vocabulary
predicates open-ended. QCSP-solving systems, as, redlog (Dolzmann
& Sturm, 1999) qepcad (Brown, 2003), oer vocabulary spatial problem
solving makes dicult user specify problem dig deep
ocean equations inequalities cannot communicate naturally terms high-level
predicates.4 still far building systems understand communication
natural language. However, research automatic constraint acquisition examples
already underway. Vu OSullivan (2008) discuss recent advances direction.
use ideas results work, dicult see
ideas conjunction work reported paper able build
convenient ecient spatial problem solving framework.

7. Conclusion
DR requires perceiving specied information diagram modifying/creating objects
diagram specied ways according problem solving needs. number DR systems
built last couple decades, developers ascertained
priori hand-coded required perceptions actions. approach building
DR systems defeats purpose open-ended exploration essence human-like
problem solving. goal, paper, develop general ecient framework
executing perceptions actions relevant reasoning 2D diagrams across
wide variety domains tasks. make two important contributions:
1. observe wide variety visual perceptions/actions DR applications
transformed domain/task-independent spatial problems. observation makes
possible use well-established constraint satisfaction framework spatial problem
solving. developed language specify spatial problems QCSPs
real domain using open-ended vocabulary properties, relations actions involving
three kinds diagrammatic objects points, curves, regions. Solution spatial problem
equivalent simplied quantier-free expression. reduces goal developing
general ecient SPS solving 2D spatial problems without human intervention.
4. fair, redlog qepcad developed solving spatial problems QCSP.

421

fiBanerjee & Chandrasekaran

2. spatial problems specied QCSPs rst-order logic. QE, inherently
doubly exponential problem, computational bottleneck SPS. represented
objects (points, curves, regions) conguration simple elements facilitate decomposition complex problems simpler similar subproblems. showed that,
symbolic solution subproblem expressed concisely, QE achieved
low-order polynomial time storing problems solutions memory
similar problem encountered future, solved mapping solution
similar previously solved problem. SPS grows ecient solves problems.
Even though used CAD algorithm QE compared complexity results
CADs, approach means limited particular algorithm. complexity QE algorithm signicantly improved spatial problem solving
using idea problem decomposition variable mapping, discussed paper.
framework leaves room ecient convenient incorporating future
results least two possible directions learning constraints examples (automatic
constraint acquisition) carefully exploiting rich portfolio QE algorithms solving
new problems.

Acknowledgments
research partially supported participation Advanced Decision Architectures Collaborative Technology Alliance sponsored U.S. Army Research Laboratory
Cooperative Agreement DAAD19-01-2-0009. thank anonymous reviewers
constructive comments.

References
Aho, A. V., Hopcroft, J. E., & Ullman, J. D. (1974). Design Analysis Computer
Algorithms. Addison-Wesley.
Allwein, G., & Barwise, J. (1999). Logical reasoning diagrams. Journal Logic,
Language Information, 8 (3), 387390.
Anderson, J. R. (1993). Rules Mind. Lawrence Erlbaum Associates, Hillsdale, NJ.
Banerjee, B., & Chandrasekaran, B. (2004). Perceptual action routines diagrammatic
reasoning entity re-identication. Proc. 24th Army Science Conf., Orlando, FL.
Banerjee, B., & Chandrasekaran, B. (2007). constraint satisfaction framework visual
problem solving. Benhamou, F., Jussien, N., & OSullivan, B. (Eds.), Trends
Constraint Programming, chap. 26, pp. 383393. ISTE, London.
Banerjee, B., & Chandrasekaran, B. (2010). spatial search framework executing
perceptions actions diagrammatic reasoning. Goel, A. K., Jamnik, M., &
Narayanan, N. H. (Eds.), Diagrammatic Representation Inference, Lecture Notes
AI, Vol. 6170, pp. 144159. Springer, Heidelberg.
Barwise, J., & Etchemendy, J. (1998). computational architecture heterogeneous
reasoning. Gilboa, I. (Ed.), Proc. 7th Conf. Theoretical Aspects Rationality
Knowledge, pp. 127. Morgan Kaufmann.
422

fiExecuting Perceptions Actions Diagrammatic Reasoning

Basu, S., Pollack, R., & Roy, M.-F. (2003). Algorithms real algebraic geometry. SpringerVerlag.
Bennett, B. (1997). Logical Representations Automated Reasoning Spatial Relationships. Ph.D. thesis, School Computer Studies, University Leeds.
Bennett, B., Isli, A., & Cohn, A. G. (1997). composition table provide
complete tractable proof procedure relational constraint language?. Proc.
IJCAI Workshop Spatial Temporal Reasoning, Nagoya, Japan.
Brown, C. W. (2003). QEPCAD B: program computing semi-algebraic sets using
cylindrical algebraic decomposition. ACM SIGSAM Bulletin, 37 (4), 97108.
Brown, C. W., & Davenport, J. H. (2007). complexity quantier elimination
cylindrical algebraic decomposition. Proc. Intl. Symp. Symbolic Algebraic Computation, pp. 5460. ACM, NY.
Chandrasekaran, B., Josephson, J. R., Banerjee, B., Kurup, U., & Winkler, R. (2002).
Diagrammatic reasoning support situation understanding planning. Proc.
23rd Army Science Conf., Orlando, FL.
Chandrasekaran, B., Kurup, U., & Banerjee, B. (2005). diagrammatic reasoning architecture: Design, implementation experiments. Proc. AAAI Spring Symp.,
Reasoning Mental External Diagrams: Computational Modeling Spatial
Assistance, pp. 108113, Stanford University, CA.
Chandrasekaran, B., Kurup, U., Banerjee, B., Josephson, J. R., & Winkler, R. (2004).
architecture problem solving diagrams. Blackwell, A., Marriott, K., &
Shimojima, A. (Eds.), Lecture Notes AI, Vol. 2980, pp. 151165. Springer-Verlag.
Chazelle, B. (1991). Triangulating simple polygon linear time. Discrete Computational Geometry, 6, 485524.
Clarke, B. L. (1981). calculus individuals based connection. Notre Dame Journal
Formal Logic, 22, 204218.
Cohn, A. G., Bennett, B., Gooday, J. M., & Gotts, N. (1997). RCC: calculus region
based qualitative spatial reasoning. GeoInformatica, 1, 275316.
Collins, G. E., & Hong, H. (1991). Partial cylindrical algebraic decomposition quantier
elimination. Journal Symbolic Computation, 12 (3), 299328.
Davenport, J. H., & Heintz, J. (1988). Real quantier elimination doubly exponential.
Journal Symbolic Computation, 5 (1-2), 2935.
Dershowitz, N., & Jouannaud, J. P. (1990). Rewrite systems. Handbook Theoretical
Computer Science, Vol. B, chap. 6, pp. 243320. Elsevier, North Holland: Amsterdam.
Dolzmann, A., & Sturm, T. (1999). REDLOG user manual, edition 2.0 version 2.0.
Tech. rep. MIP-9905, FMI, Universitt Passau, Passau, Germany.
Dolzmann, A., Sturm, T., & Weispfenning, V. (1998). Real quantier elimination practice.
Matzat, B. H., Greuel, G.-M., & Hiss, G. (Eds.), Algorithmic Algebra Number
Theory, pp. 221247. Springer, Berlin.
423

fiBanerjee & Chandrasekaran

Duntsch, I., Wang, H., & McCloskey, S. (1999). Relation algebras qualitative spatial
reasoning. Fundamenta Informaticae, 39 (3), 229249.
Dylla, F., & Moratz, R. (2005). Exploiting qualitative spatial neighborhoods situation
calculus. Freksa, C., Knau, M., Krieg-Brckner, B., Nebel, B., & Barkowsky, T.
(Eds.), Spatial Cognition IV. Reasoning, Action, Interaction, Vol. 3343 Lecture
Notes Computer Science, pp. 304322. Springer.
Egenhofer, M. J. (1991). Reasoning binary topological relations. Gunther, O.,
& Schek, H.-J. (Eds.), Proc. 2nd Symp. Large Spatial Databases, Vol. 525 Lecture
Notes Computer Science, pp. 143160. Springer.
Egenhofer, M. J., & Franzosa, R. D. (1991). Point set topological relations. Intl. Journal
Geographical Information Systems, 5, 161174.
Ferguson, R. W. (1994). MAGI: Analogy-based encoding using symmetry regularity.
Proc. 16th Annual Conf. Cognitive Science Society, pp. 283288, Atlanta, GA.
Ferguson, R. W., & Forbus, K. D. (1998). Telling juxtapositions: Using repetition
alignable dierence diagram understanding. Holyoak, K., Gentner, D., & Kokinov, B. (Eds.), Advances Analogy Research, pp. 109117. Soa, New Bulgarian
University.
Ferguson, R. W., & Forbus, K. D. (2000). GEOREP: exible tool spatial representation
line drawings. Proc. 18th Natl. Conf. AI, pp. 510516, Austin, TX.
Forbus, K. D., Usher, J., & Chapman, V. (2003). Qualitative spatial reasoning sketch
maps. Riedl, J., & Hill, R. (Eds.), Proc. 15th Annual Conf. Innovative Applications
AI, pp. 8592, Acapulco, Mexico. AAAI Press, Menlo Park, CA. ISBN 978-1-57735188-7.
Frank, A. U. (1991). Qualitative spatial reasoning cardinal directions. Kaindl, H.
(Ed.), Proc. 7th Austrian Conf. AI, Vol. 287 Informatik-Fachberichte, pp. 157167.
Springer.
Frank, A. U. (1992). Qualitative spatial reasoning distances directions geographic space. Journal Visual Languages Computing, 3, 343371.
Freksa, C. (1992). Using orientation information qualitative spatial reasoning. Frank,
A. U., Campari, I., & Formentini, U. (Eds.), Spatio-Temporal Reasoning, Vol. 639
Lecture Notes Computer Science, pp. 162178. Springer.
Gebruers, C., Hnich, B., Bridge, D., & Freuder, E. (2005). Using CBR select solution
strategies constraint programming. Proc. 6th Intl. Conf. Case-based Reasoning,
pp. 222236. Springer.
Gerevini, A., & Nebel, B. (2002). Qualitative spatio-temporal reasoning rcc-8
allens interval calculus: Computational complexity. Proc. 15th European Conf. AI,
pp. 312316. IOS Press.
Gerevini, A., & Renz, J. (1998). Combining topological qualitative size constraints
spatial reasoning. Proc. 4th Intl. Conf. Principles Practice Constraint
Programming, pp. 220234. Springer.
424

fiExecuting Perceptions Actions Diagrammatic Reasoning

Glasgow, J., Narayanan, N. H., & Chandrasekaran, B. (1995). Diagrammatic Reasoning:
Cognitive Computational Perspectives. AAAI Press.
Goldberg, E., & Novikov, Y. (2003). complexity equivalence checking. Tech. rep.
CDNL-TR-2003-0826, Cadence Berkeley Labs, CA.
Jamnik, M. (2001). Mathematical Reasoning Diagrams: Intuition Automation.
CSLI Press, Stanford University, CA.
Josephson, J. R., & Josephson, S. G. (1996). Abductive Inference: Computation, Philosophy,
Technology. Cambridge University Press, Cambridge, MA.
Kurup, U., & Chandrasekaran, B. (2007). bimodal cognitive architecture: Explorations
architectural explanation spatial reasoning. AAAI Spring Symp. Control Mechanisms Spatial Knowledge Processing Cognitive/Intelligent Systems, Stanford
University, CA.
Laird, J. E., Newell, A., & Rosenbloom, P. S. (1987). SOAR: architecture general
intelligence. Artificial Intelligence, 33, 164.
Laird, J. E., Rosenbloom, P. S., & Newell, A. (1986). Universal Subgoaling Chunking.
Kluwer Academic Publishers.
Lasaruk, A., & Sturm, T. (2006). Weak quantier elimination full linear theory
integers. uniform generalization Presburger arithmetic. Technical report
MIP-0604, FMI, Universitt Passau, Germany.
Leyton-Brown, K., Nudelman, E., & Shoham, Y. (2002). Learning empirical hardness
optimization problems: case combinatorial auctions. Proc. 8th Intl. Conf.
Principles Practice Constraint Programming, pp. 556572.
Ligozat, G. (1993). Qualitative triangulation spatial reasoning. Frank, A. U., &
Campari, I. (Eds.), Spatial Information Theory: Theoretical Basis GIS, Vol. 716
Lecture Notes Computer Science, pp. 5468. Springer.
Lindsay, R. K. (1998). Using diagrams understand geometry. Computational Intelligence,
14 (2), 238272.
Moratz, R., Renz, J., & Wolter, D. (2000). Qualitative spatial reasoning line segments.
Proc. 14th European Conf. AI, pp. 234238. IOS Press.
Nelson, R. B. (1993). Proofs without Words: Exercises Visual Thinking. Mathematical Association America, Washington, DC.
Newell, A. (1990). Unified Theories Cognition. Harvard University Press, Cambridge,
MA.
OMahony, E., Hebrard, E., Holland, A., Nugent, C., & OSullivan, B. (2008). Using casebased reasoning algorithm portfolio constraint solving. van Dongen, M.
R. C., Lecoutre, C., & Roussel, O. (Eds.), Proc. 3rd Intl. CSP Solver Competition,
pp. 5362.
Pisan, Y. (1994). Visual reasoning graphs. 8th Intl. Workshop Qualitative Reasoning
Physical Systems, Nara, Japan.
425

fiBanerjee & Chandrasekaran

Pisan, Y. (1995). visual routines based model graph understanding. Proc. 17th
Annual Conf. Cognitive Science Society, pp. 692697, Pittsburgh. Lawrence Erlbaum
Associates. ISBN: 0-8058-2159-7.
Pulina, L., & Tacchella, A. (2007). multi-engine solver quantied boolean formulas.
Proc. 13th Intl. Conf. Principles Practice Constraint Programming, pp.
574589.
Randell, D. A., Cui, Z., & Cohn, A. G. (1992). spatial logic based regions connection. Nebel, B., Swartout, W., & Rich, C. (Eds.), Proc. 3rd Intl. Conf. Principles
Knowledge Representation Reasoning, pp. 165176. Morgan Kaufmann.
Ratschan, S. (2006). Ecient solving quantied inequality constraints real
numbers. ACM Trans. Computational Logic, 7 (4), 723748.
Sayag, T., Fine, S., & Mansour, Y. (2006). Combining multiple heuristics. Proc. 23rd
Intl. Symp. Theoretical Aspects Computer Science, Vol. 2884 Lecture Notes
Computer Science, pp. 242253. Springer.
Schlieder, C. (1995). Reasoning ordering. Frank, A. U., & Kuhn, W. (Eds.),
Spatial Information Theory: Theoretical Basis GIS, Vol. 988 Lecture Notes
Computer Science, pp. 341349. Springer.
Seidel, R. (1991). simple fast incremental randomized algorithm computing
trapezoidal decompositions triangulating polygons. Computational Geometry:
Theory Applications, 1 (1), 5164.
Skiadopoulos, S., & Koubarakis, M. (2004). Composing cardinal direction relations. Artificial Intelligence, 152 (2), 143171.
Streeter, M. J., Golovin, D., & Smith, S. F. (2007). Combining multiple heuristics online.
Proc. 22nd Conf. AI, pp. 11971203. AAAI Press.
Sutherland, I. E. (1963). Sketchpad: man-machine graphical communication system.
Proc. Spring Joint Computer Conf., pp. 329346.
Tessler, S., Iwasaki, Y., & Law, K. (1995). Qualitative structural analysis using diagrammatic reasoning. Glasgow, J., Narayanan, N. H., & Chandrasekaran, B. (Eds.),
Diagrammatic Reasoning: Cognitive Computational Perspectives, chap. 21, pp.
711730. AAAI Press, Menlo Park, CA. ISBN 0-262-57112-9.
Tricket, S. B., & Trafton, J. G. (2006). Toward comprehensive model graph comprehension: Making case spatial cognition. Barker-Plummer, D., Cox, R., &
Swoboda, N. (Eds.), Lecture Notes AI, Vol. 4045, pp. 286300. Berlin: SpringerVerlag.
Tversky, B. (2000). ways maps diagrams communicate. Freksa, C.,
Brauer, W., Habel, C., & Wender, K. F. (Eds.), Spatial Cognition II: Integrating
Abstract Theories, Empirical Studies, Formal Methods, Practical Applications,
Vol. 1849 Lecture Notes Computer Science, pp. 7279. Berlin: Springer-Verlag.
Vik, S. (2001). implementation near-linear polygon triangulation algorithm
general polygons. Senior thesis Macalester College, St. Paul, Minnesota. Available
online http://sigbjorn.vik.name/projects/Triangulation.pdf.
426

fiExecuting Perceptions Actions Diagrammatic Reasoning

Vu, X. H., & OSullivan, B. (2008). unifying framework generalized constraint acquisition. Intl. Journal AI Tools, 17 (5), 803833.
Weispfenning, V. (1988). complexity linear problems elds. Journal Symbolic
Computation, 5 (12), 327.
Weispfenning, V. (2001). Semilinear motion planning REDLOG. Applicable Algebra
Engineering, Communication Computing, 12, 455475.
Wolfram, S. (2003).
Mathematica Book (5th edition).
http://documents.wolfram.com/.

Available online

Xu, L., Hutter, F., Hoos, H. H., & Leyton-Brown, K. (2008). SATzilla: Portfolio-based
algorithm selection SAT. Journal Artificial Intelligence Research, 32, 565606.

427

fiJournal Artificial Intelligence Research 39 (2010) 127177

Submitted 11/09; published 09/10

LAMA Planner:
Guiding Cost-Based Anytime Planning Landmarks
Silvia Richter

silvia.richter@nicta.com.au

IIIS, Griffith University, Australia
NICTA QRL, Australia

Matthias Westphal

westpham@informatik.uni-freiburg.de

Albert-Ludwigs-Universitat Freiburg
Institut fur Informatik
Freiburg, Germany

Abstract
LAMA classical planning system based heuristic forward search. core feature
use pseudo-heuristic derived landmarks, propositional formulas must true
every solution planning task. LAMA builds Fast Downward planning system, using
finite-domain rather binary state variables multi-heuristic search. latter employed
combine landmark heuristic variant well-known FF heuristic. heuristics
cost-sensitive, focusing high-quality solutions case actions non-uniform cost.
weighted search used iteratively decreasing weights, planner continues
search plans better quality search terminated.
LAMA showed best performance among planners sequential satisficing track
International Planning Competition 2008. paper present system detail investigate features LAMA crucial performance. present individual results
domains used competition, demonstrating good bad cases techniques
implemented LAMA. Overall, find using landmarks improves performance, whereas
incorporation action costs heuristic estimators proves beneficial. show
domains search ignores cost solves far problems, raising question
deal action costs effectively future. iterated weighted search greatly
improves results, shows synergy effects use landmarks.

1. Introduction
last decade, heuristic search become dominant approach domain-independent satisficing planning. Starting additive heuristic Bonet Geffner (2001), implemented
HSP planning system, much research conducted search heuristic estimators
efficient calculate yet powerful guiding search towards goal state. FF planning system Hoffmann Nebel (2001), using heuristic estimator based relaxed planning
graphs, broke ground showing best performance among fully automated systems International Planning Competition 2000, continues state art today. Ever since,
heuristic-search approaches played prominent role classical sequential satisficing
tracks biennial competition, Fast Downward (Helmert, 2006) winning 2004 SGPlan (Chen, Wah, & Hsu, 2006) placing first 2006.
LAMA planning system youngest member line, winning sequential satisficing track International Planning Competition (IPC) 2008. LAMA classical planning
c
2010
AI Access Foundation. rights reserved.

fiRichter & Westphal

system based heuristic search. follows footsteps HSP, FF, Fast Downward
uses earlier work many respects. particular, builds Fast Downward extending
three major ways:
1. Landmarks. LAMA, Fast Downwards causal graph heuristic replaced variant
FF heuristic (Hoffmann & Nebel, 2001) heuristic estimates derived landmarks.
Landmarks propositional formulas become true point every plan
task hand (Porteous, Sebastia, & Hoffmann, 2001). LAMA uses landmarks
direct search towards states many landmarks already achieved. Via
preferred operators, landmarks also used additional source search control
complements heuristic estimates. recent work, shown use landmarks
addition FF heuristic improve performance, leading problems
solved shorter solution paths (Richter, Helmert, & Westphal, 2008).
2. Action costs. landmark heuristic proposed earlier (Richter et al., 2008)
FF heuristic adapted use action costs. However, LAMA focus purely
cost-to-go, i. e., estimated cost reaching goal given search node.
danger cost-sensitive planner may concentrate much finding cheap plan,
expense finding plan within given time limit. LAMA weighs estimated
cost-to-go (as measure plan quality) estimated goal distance (as measure
remaining search effort) combining values two estimates.
3. Anytime search. LAMA continues search better solutions exhausted
search space interrupted. finding initial solution greedy best-first search,
conducts series weighted searches decreasing weights, restarting search
time initial state improved solution found. recent work,
shown approach efficient planning benchmarks compared anytime
methods (Richter, Thayer, & Ruml, 2010).
International Planning Competition 2008, LAMA outperformed competitors
substantial margin. result expected authors, previous work concerning
LAMAs putative core feature, landmark heuristic (Richter et al., 2008), showed some,
tremendous improvement base configuration without landmarks. paper aims
provide reference description LAMA well extensive evaluation performance
competition.
Detailed description LAMA. present distinguishing components planner
detail, describing landmarks generated used LAMA, action costs
incorporated heuristic estimators anytime search proceeds. aspects LAMA presented previous publications (Richter et al., 2008, 2010;
Helmert, 2006). However, aspects adequately covered publications, particular procedure finding landmarks, described detail.
relevant aspects described previous work, like landmark heuristic, summarised
convenience reader. aim paper, together previous ones, form
comprehensive picture LAMA system.
Experimental evaluation LAMA. Building this, conduct experimental evaluation focusing aspects differentiate LAMA predecessor systems like FF
128

fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarks

Fast Downward. repeat comparisons published earlier work, like comparison
LAMAs anytime method anytime algorithms (Richter et al., 2010),
comparison LAMAs methods handling landmarks alternative landmark approaches
(Richter et al., 2008). Instead, aim elicit much performance LAMA
system whole enhanced three distinguishing features described
(landmarks, action costs anytime search). answer question, contrast several
variations planner using various subsets features.
find using cost-sensitive heuristics pay IPC 2008 benchmark tasks.
results show cost-sensitive variant FF heuristic used LAMA performs significantly worse traditional unit-cost version heuristic. Similarly,
cost-sensitive planners competition fared worse baseline planner FF ignored action costs, demonstrating cost-based planning presents considerable challenge.
conduct full analysis reasons this, showcase problems cost-sensitive FF
heuristic example domains provide informed hypotheses encountered effects.
Landmarks prove particularly helpful context. unit-cost case landmarks
lead moderate increase performance, case planning action costs
substantially improve coverage (the number problems solved), thus effectively mitigating
problems cost-sensitive FF heuristic LAMA. anytime search significantly improves
quality solutions throughout even acts synergy landmarks one domain.

2. Preliminaries
use planning formalism state variables finite (rather binary) range, similar
one employed Helmert (2009). based SAS+ planning model (Backstrom & Nebel,
1995), extends conditional effects. LAMA also handles axioms way
Fast Downward (Helmert, 2006), formalise axioms here, since important
purposes.
Definition 1. Planning tasks finite-domain representation (FDR tasks)
planning task finite-domain representation (FDR task) given 5-tuple hV, s0 , s? , O, Ci
following components:
V finite set state variables, associated finite domain Dv .
fact pair hv, di (also written v 7 d), v V Dv . partial variable
assignment set facts, different variable. (We use set notation
hv, di function notation s(v) = interchangeably.) state variable
assignment defined variables V.
s0 state called initial state.
s? partial variable assignment called goal.
finite set operators. operator hpre, effi consists partial variable assignment
pre called precondition, finite set effects eff. Effects triplets hcond, v, di,
cond (possibly empty) partial variable assignment called effect condition, v
affected variable Dv called new value v.
129

fiRichter & Westphal

C : N+0 integer-valued non-negative action cost function.
operator = hpre, effi applicable state pre s, effects consistent,
i. e., state s0 s0 (v) = hcond, v, di eff cond s, s0 (v) = s(v)
otherwise. case, say operator applied resulting state s0
write s[o] s0 .
operator sequences = ho1 , . . . , i, write s[] s[o1 ] . . . [on ] (only defined operator applicable respective state). operator sequence called plan s? s0 [].
P
cost sum action costs operators, ni=1 C(oi ).
state variable v planning task finite-domain representation associated directed
graph called domain transition graph, captures ways value v may
change (Jonsson & Backstrom, 1998; Helmert, 2006). vertex set graph Dv ,
contains arc two nodes d0 exists operator change value
v d0 . Formally:
Definition 2. Domain transition graph
domain transition graph (DTG) state variable v V FDR task hV, s0 , s? , O, Ci
digraph hDv , Ai includes arc hd, d0 iff , d0 , operator hpre, effi
hcond, v, d0 eff, union conditions pre cond holds either contains v =
contain v = Dv .

3. System Architecture
LAMA builds Fast Downward system (Helmert, 2006), inheriting overall structure
large parts functionality planner. Like Fast Downward, LAMA accepts input
PDDL2.2 Level 1 format (Fox & Long, 2003; Edelkamp & Hoffmann, 2004), including ADL
conditions effects derived predicates (axioms). Furthermore, LAMA extended
handle action costs introduced IPC 2008 (Helmert, Do, & Refanidis, 2008). Like Fast
Downward, LAMA consists three separate components:
translation module
knowledge compilation module
search module
components implemented separate programs invoked sequence.
following, provide brief description translation knowledge compilation modules.
main changes LAMA, compared Fast Downward, implemented search module,
discuss detail.
3.1 Translation
translation module, short translator, transforms PDDL input planning task finitedomain representation specified Definition 1. main components translator
efficient grounding algorithm instantiating schematic operators axioms, invariant
130

fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarks

synthesis algorithm determining groups mutually exclusive facts. fact groups consequently replaced single state variable, encoding fact (if any) group satisfied
given world state. Details component found recent article Helmert (2009).
groups mutually exclusive facts (mutexes) found translation later used
determine orderings landmarks. reason, LAMA use finite-domain
representations offered IPC 2008 (object fluents), instead performs translation
binary finite-domain variables. mutexes computed translation module
needed new encoding planning task, module extended LAMA retain
found mutexes later use landmarks.
changes made, compared translation module described Helmert,
add capability handling action costs, implement extension concerning parsing
complex operator effect formulas, limit runtime invariant synthesis algorithm.
invariant synthesis may time critical, particular large (grounded) PDDL input, limit
maximum number considered mutex candidates algorithm, abort it, necessary,
five minutes. Note finding mutexes change way translation module
works; mutexes found, resulting encoding planning task contains simply
(binary-domain) state variables PDDL input. analysing competition results,
found synthesis algorithm aborted tasks one domain (Cyber
Security).
3.2 Knowledge Compilation
Using finite-domain representation generated translator, knowledge compilation module responsible building number data structures play central role subsequent
landmark generation search. Firstly, domain transition graphs (see Definition 2) produced
encode ways state variable may change value operator applications axioms. Furthermore, data structures constructed efficiently determining set
applicable operators state evaluating values derived state variables. refer
Helmert (2006) detail knowledge compilation component, LAMA inherits
unchanged Fast Downward.
3.3 Search
search module responsible actual planning. Two algorithms heuristic search
implemented LAMA: (a) greedy best-first search, aimed finding solution quickly
possible, (b) weighted search allows balancing speed solution quality.
algorithms variations standard textbook methods, using open closed lists. greedy
best-first search always expands state minimal heuristic value h among open states
never expands state once. order encourage cost-efficient plans without incurring
much overhead, breaks ties equally promising states preferring states
reached cheaper operators, i. e., taking account last operator path considered
state search space. (The cost entire path could used expense increased
time space requirements, consider this.) Weighted search (Pohl, 1970)
associates costs states expands state minimal f 0 -value, f 0 = w h + g,
weight w integer 1, g best known cost reaching considered state
131

fiRichter & Westphal

initial state. contrast greedy search, weighted search re-expands states whenever finds
cheaper paths them.
addition, search algorithms use three types search enhancements inherited Fast
Downward (Helmert, 2006; Richter & Helmert, 2009). Firstly, multiple heuristics employed
within multi-queue approach guide search. Secondly, preferred operators similar
helpful actions FF allow giving precedence operators deemed helpful
others state. Thirdly, deferred heuristic evaluation mitigates impact large branching
factors assuming heuristic estimates fairly accurate. following, discuss
techniques resulting algorithms detail give pseudo code greedy best-first
search. weighted search similar, point differences two
algorithms along way.
Multi-queue heuristic search. LAMA uses two heuristic functions guide search: namegiving landmark heuristic (see Section 5), variant well-known FF heuristic (see Section 6). two heuristics used separate queues, thus exploiting strengths utilised
heuristics orthogonal way (Helmert, 2006; Roger & Helmert, 2010). end, separate
open lists maintained two heuristics. States always evaluated respect
heuristics, successors added open lists (in case value corresponding heuristic open list). choosing state evaluate expand next,
search algorithm alternates different queues based numerical priorities assigned
queue. priorities discussed later.
Deferred heuristic evaluation. use deferred heuristic evaluation means states
heuristically evaluated upon generation, upon expansion, i. e., states generated
greedy best-first search, put open list heuristic value,
parent. removed open list evaluated heuristically,
heuristic estimate turn used successors. use deferred evaluation
weighted search analogous, using f 0 instead h sorting criterion open lists.
many states generated expanded, deferred evaluation leads substantial reduction number heuristic estimates computed. However, deferred evaluation incurs loss
heuristic accuracy, search longer use h-values f 0 -values differentiate
successors state (all successors associated parents value open list). Preferred
operators helpful context provide alternative way determine promising
successors.
Preferred operators. Operators deemed particularly useful given state marked
preferred. computed heuristic estimators along heuristic value
state (see Sections 6 5). use preferred operators, greedy best-first search well
weighted search, planner maintains additional preferred-operator queue
heuristic. state evaluated expanded, successor states reached via
preferred operator (the preferred states) put preferred-operator queues, addition
put regular queues like non-preferred states. (Analogously regular states,
state preferred least one heuristic added preferred-operator queues. allows
cross-fertilisation information exchange different heuristics.) States
preferred-operator queues evaluated earlier average, form part queues
higher chance selected point time non-preferred states. addition,
132

fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarks

LAMA (like IPC 2004 version Fast Downward) gives even higher precedence preferred
successors via following mechanism. planner keeps priority counter queue,
initialised 0. iteration, next state removed queue highest
priority. Whenever state removed queue, priority queue decreased 1.
priorities changed outside routine, method alternate queues,
thus expanding states preferred queues regular queues equally often. increase use
preferred operators, LAMA increases priorities preferred-operator queues large
number boost value 1000 whenever progress made, i. e., whenever state discovered
better heuristic estimate previously expanded states. Subsequently, next 1000 states
removed preferred-operator queues. another improving state found within 1000
states, boosts accumulate and, accordingly, takes longer states regular queues
expanded again.
Alternative methods using preferred operators include one employed YAHSP
system (Vidal, 2004), preferred operators always used non-preferred ones. contrast, scheme necessarily empty preferred queues switching back regular
queues. FF planner (Hoffmann & Nebel, 2001), emphasis preferred operators even
stronger YAHPS: search FF restricted preferred operators either goal
found restricted search space exhausted (in case new search started without preferred operators). Compared approaches, method using preferred operators
LAMA, conjunction deferred heuristic evaluation, shown result substantial
performance improvement deliver best results classical setting operators unit costs
(Richter & Helmert, 2009). choice 1000 boost value critical here, found
various values 100 50000 give similarly good results. outside range
performance drop noticeably.
Note using action costs, use preferred operators may even helpful
classical setting. example, operators cost 0, heuristic using pure
cost estimates might assign heuristic value 0 states state space, giving
guidance search all. Preferred operators, however, still provide heuristic guidance
case case unit action costs. extreme example, similar cases
appear practice, e. g. IPC 2008 domain Openstacks, operators except one
opening new stack associated cost 0.
Pseudo code. Algorithm 1 shows pseudo code greedy best-first search. main loop
(lines 2536) runs either goal found (lines 2729) search space
exhausted (lines 3233). closed list contains seen states also keeps track links
states parents, plan efficiently extracted goal state
found (line 28). iteration loop, search adds current state (initially
start state) closed list processes (lines 3031), unless state processed
before, case ignored (line 26). contrast, weighted search processes states
whenever reached via path lower cost before, updates parent links
closed list accordingly. search selects next open list used (the one
highest priority, line 34), decreases priority extracts next state processed (lines
3536). processing state includes calculating heuristic values preferred operators
heuristics (lines 34), expanding it, inserting successors appropriate open
133

fiRichter & Westphal

Global variables:
= hV, s0 , s? , O, Ci
regFF , pref FF , regLM , pref LM
best seen value
priority
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30:
31:
32:
33:
34:
35:
36:

. Planning task solve
. Regular preferred open lists heuristic
. Best heuristic value seen far heuristic
. Numerical priority queue

function expand state(s)
progress False
h {FF, LM}
h(s), preferred ops(h, s) heuristic value preferred operators given h
h(s) < best seen value[h]
progress True
best seen value[h] h(s)
progress
. Boost preferred-operator queues
priority[pref FF ] priority[pref FF ] + 1000
priority[pref LM ] priority[pref LM ] + 1000
succesor states { s[o] | applicable }
s0 succesor states
h {FF, LM}
add s0 queue regh value h(s)
. Deferred evaluation
0
reached operator preferred ops(h, s)
add s0 queue pref FF value FF(s), queue pref LM value LM(s)
function greedy bfs lama
closed list
h {FF, LM}
. Initialize FF landmark heuristics
best seen value[h]
l {reg, pref }
. Regular preferred open lists heuristic
lh
priority[lh ] 0
current state s0
loop
current state < closed list
= s?
extract plan tracing current state back initial state closed list
return
closed list closed list {current state}
expand state(current state)
queues empty
return failure
. plan exists
q non-empty queue highest priority
priority[q] priority[q] 1
. Get lowest-valued state queue q
current state pop state(q)
Algorithm 1: greedy best-first-search search enhancements used LAMA.
134

fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarks

lists (lines 1116). determined new best state found (lines 5-7), preferredoperator queues boosted 1000 (lines 8-10).
3.3.1 Restarting Anytime Search
LAMA developed International Planning Competition 2008 tailored conditions competition several ways. detail, conditions follows.
previous competitions coverage, plan quality runtime used varying degrees order
determine effectiveness classical planning system, IPC 2008 introduced new integrated
performance criterion. operator PDDL input associated non-negative integer
action cost, aim find plan lowest-possible total cost within given time limit
30 minutes per task. Given planner solves task within time limit, new
performance measure depends plan quality, runtime, thus suggests guiding
search towards cheapest goal rather closest goal well using available time
find best plan possible.
Guiding search towards cheap goals may achieved two ways, LAMA
implements: firstly, heuristics estimate cost-to-go, i. e., cost reaching goal
given state, rather distance-to-go, i. e., number operators required reach
goal. landmark heuristic FF heuristic employed LAMA therefore capable
using action costs. Secondly, search algorithm take cost-to-go given
state account, also cost necessary reaching state. case weighted
search used LAMA. make available time, LAMA employs anytime
approach: first runs greedy best-first search, aimed finding solution quickly possible.
plan found, searches progressively better solutions running series weighted
searches decreasing weight. cost best known solution used pruning
search, decreasing weight time makes search progressively less greedy, trading
speed solution quality.
Several anytime algorithms based weighted proposed (Hansen & Zhou, 2007;
Likhachev, Ferguson, Gordon, Stentz, & Thrun, 2008). underlying idea continue
weighted search past first solution, possibly adjusting search parameters like weight
pruning bound, thus progressively find better solutions. anytime approach used LAMA
differs existing algorithms continue weighted search
finds solution. Instead, start new weighted search, i. e., discard open lists
previous search re-start initial state. resulting duplicate effort,
restarts help overcome bad decisions made early (comparatively greedy) search iterations
high weight (Richter et al., 2010). explained follows: finding goal state
sg , open lists usually contain many states close sg search space,
ancestors sg expanded; furthermore, states likely low heuristic values
proximity sg . Hence, search continued (even updating open
lists lower weights), likely expand states around sg considering states
close initial state. critical, means search concentrating
improving end current plan, opposed beginning. bad beginning plan,
however, may severe negative influence quality, may impossible improve
quality plan substantially without changing early operators.
135

fiRichter & Westphal

3.8
10.6
3.4
9.8
2.6
8.2
1.8
7.6
1.0
7.0
1.0
8.0

3.8
9.6
3.4
8.8
2.6
8.2
1.8
7.6
1.0
7.0

g1

3.8
8.6



4.0
9.0

2.6
8.2
1.8
7.6
1.0
7.0
1.0
8.0

g2

(a) initial search, w = 2

2.6
8.9
2.6
8.9
2.6
8.9

2.6
7.9
1.8
6.7
1.8
7.7
1.8
8.7

3.8
8.7
3.4
8.1
2.6
6.9
1.8
6.7
1.0
6.5
1.0
7.5

3.8
7.7

X



4.0
7.0

X
X
X
X

g1

2.6 1.9 2.0
6.9 6.85 8.0
1.8 1.9 1.0
6.7 6.85 6.5
1.0 1.9 1.0
6.5 7.85 6.5
1.0 1.9
7.5 8.85

2.0
9.0
1.0
7.5

g2

(b) continued search, w = 1.5

3.8
7.7
3.4
7.1

3.8
6.7



4.0
7.0

2.0
6.0
1.0
5.5
1.0
6.5

4.0
8.0
3.0
6.5
2.0
6.0
1.0
5.5

g2

3.0
7.5
2.0
6.0
1.0
5.5
1.0
6.5

g1
(c) restarted search, w = 1.5

Figure 1: effect low-h bias. grid states generated search, h-values shown
f 0 -values. (a) Initial weighted search finds solution cost 6. (b) Continued search
expands many states around previous Open list (grey cells), finding another sub-optimal solution
cost 6. (c) Restarted search quickly finds optimal solution cost 5.

136

fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarks

Consider example search problem shown Figure 1. task reach goal state
(g1 g2) start state gridworld, agent move cost 1
8 neighbours cell blocked. heuristic values inaccurate estimates
straight-line goal distances cells. particular, heuristic values underestimate distances
left half grid. conduct weighted search weight 2 Figure 1a (assuming
simplicity standard textbook search, i. e., preferred operators deferred evaluation).
heuristic values left happen lower right s, search
expands states left finds goal g1 cost 6. grey cells generated,
expanded search phase, i. e., open list. Figure 1b, search continues
reduced weight 1.5. solution cost 5 consists turning right going g2.
However, search first expand states open list f 0 -value smaller 7.
expanding substantial number states, second solution finds path starts
left takes long way around obstacle g2, cost 6. instead restart
empty open list first solution (Figure 1c), fewer states expanded. critical
state right expanded quickly optimal path found.
Note example, particular systematic errors heuristic values
leads greedy search astray makes restarts useful. planning, especially using
deferred evaluation, heuristic values may also fairly inaccurate, restarts useful.
experimental comparison tasks IPC 1998 IPC 2006 (Richter et al., 2010)
restarting approach performed notably better tested methods, dominating similar algorithms based weighted (Hansen, Zilberstein, & Danilchenko, 1997; Hansen & Zhou, 2007;
Likhachev, Gordon, & Thrun, 2004; Likhachev et al., 2008), well anytime approaches
(Zhou & Hansen, 2005; Aine, Chakrabarti, & Kumar, 2007).
3.3.2 Using cost distance estimates
heuristic estimators used LAMA cost-sensitive, aiming guide search towards
high-quality solutions. Focusing planner purely action costs, however, may dangerous,
cheap plans may longer difficult find, worst case could mean
planner fails find plan within given time limit. Zero-cost operators present particular
challenge: since zero-cost operators always added search path free, even costsensitive search algorithm like weighted may explore long search paths without getting
closer goal. Methods suggested allow trade-off putative cost-to-go
estimated goal distance (Gerevini & Serina, 2002; Ruml & Do, 2007). However, require user specify relative importance cost versus distance up-front, choice
obvious context IPC 2008. LAMA gives equal weight cost distance estimates adding two values computation heuristic functions (for details,
see Sections 5 6). measure simple one, effect changes depending
magnitude variation action costs problem: smaller action costs are,
method favours short plans cheap plans. example, 5 zero-cost operators result estimated cost 5, whereas 2 operators cost 1 result estimated cost 4. LAMA would thus
prefer 2 operators cost 1 5 zero-cost operators. contrast, action costs
planning task larger length typical plans, cost estimates dominate distance estimates LAMA completely guided costs. Nevertheless simple measure proves
useful IPC 2008 benchmarks, outperforming pure cost search experiments. so137

fiRichter & Westphal


C

B

E

plane

box

truck

Figure 2: simple Logistics task: transport box location B location E.

phisticated methods automatically balancing cost distance (for example normalising
action costs given task respect mean median) topic future work.

4. Landmarks
Landmarks subgoals must achieved every plan. first introduced Porteous,
Sebastia Hoffmann (2001) later studied depth authors (Hoffmann,
Porteous, & Sebastia, 2004). Using landmarks guide search solution planning
intuitive approach humans might use. Consider well-known benchmark domain Logistics,
goal deliver objects (e. g. boxes) various locations using fleet vehicles.
Cities consist sets locations, trucks may transport boxes within city, whereas planes
used cities. example Logistics task shown Figure 2. Arguably first
mental step human would perform, trying solve task Figure 2, realise
box must transported two cities, left city (locations AD) right city
(location E), therefore, box transported plane. turn means
box airport location C, loaded plane. partitions
task two subproblems, one transporting box airport location C, one
delivering city. subproblems smaller easier solve
original task.
Landmarks capture precisely intermediate conditions used direct search:
facts L1 = box C L2 = box plane landmarks task shown Figure 2.
knowledge, well knowledge L1 must become true L2 , automatically
extracted task preprocessing step (Hoffmann et al., 2004).
LAMA uses landmarks derive goal-distance estimates heuristic search. measures
goal distance state number landmarks still need achieved path
state goal. Orderings landmarks used infer landmarks
achieved next, whether certain landmarks achieved once. addition,
preferred operators (Helmert, 2006) used suggest operators achieve landmarks
need become true next. recently shown, method using landmarks leads
substantially better performance previous use landmarks Hoffmann et al.,
terms coverage terms plan quality (Richter et al., 2008). discuss differences
approach detail Section 4.3. following section define
138

fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarks


plane1
E

C

B
box

plane2
F

truck2


truck1

Figure 3: Extended logistics task: transport box location B location F.
landmarks orderings formally, including useful special cases detected
efficiently.
4.1 Definitions
Hoffmann et al. (2004) define landmarks facts true point every plan
given planning task. also introduce disjunctive landmarks, defined sets facts
least one needs true point. subsume landmark definitions
general definition based propositional formulas, believe useful future work
topic landmarks. noted, however, LAMA currently supports fact
landmarks disjunctions facts (for details, see Section 4.2). Hoffmann et al. show
PSPACE-hard determine whether given fact landmark, whether ordering holds
two landmarks. complexity results carry straight-forward way
general case propositional formulas, repeat proofs.
Definition 3. Landmark
Let = hV, s0 , s? , O, Ci planning task finite-domain representation, let = ho1 , . . . ,
operator sequence applicable s0 , let i, j {0, . . . , n}.
propositional formula facts called fact formula.
fact F true time iff F s0 [ho1 , . . . , oi i].
fact formula true time iff holds given truth value facts time
i. time < 0, considered true.
fact formula landmark iff plan , true time.
propositional formula facts added time iff true time
, time 1 (it considered added time 0 true s0 ).
fact formula first added time iff true time , time j < i.
Note facts initial state facts goal always landmarks definition.
landmarks discussed earlier example task Figure 2 facts. However,
complex landmarks may required larger tasks. Consider extended version
139

fiRichter & Westphal

example, city right two airports, multiple planes trucks,
depicted Figure 3. previous landmark L1 = box C still landmark
extended example. However, L2 = box plane corresponding fact landmark
task, since neither box plane1 box plane2 landmark. disjunction box
plane1 box plane2 , however, landmark. following refer landmarks
facts fact landmarks, disjunctions facts disjunctive landmarks.
use disjunctive landmarks shown improve performance, compared using fact
landmarks (Richter et al., 2008), complex landmarks introduce additional difficulty
regard detection handling planning. mentioned before, LAMA currently
uses fact landmarks disjunctive landmarks, rather general propositional formulas.
extension complex types landmarks interesting topic future work. (See Keyder,
Richter Helmert, 2010, discussion conjunctive landmarks).
Various kinds orderings landmarks defined exploited planning
phase. define three types orderings landmarks, equivalent formulations
definitions Hoffmann et al. (2004) adapted FDR setting:
Definition 4. Orderings landmarks
Let landmarks FDR planning task .
say natural ordering , written , plan
true time i, true time j < i.
say necessary ordering , written n , plan
added time i, true time 1.
say greedy-necessary ordering , written gn ,
plan first added time i, true time 1.
Natural orderings general; every necessary greedy-necessary ordering natural,
vice versa. Similarly, every necessary ordering greedy-necessary, vice versa.
Knowing natural ordering also necessary greedy-necessary allows deducing additional
information plausible temporal relationships landmarks, described later
section. Also, landmark heuristic LAMA uses knowledge deduce whether landmark
needs achieved once. theoretical concept, necessary orderings ( always true
step ) straightforward appealing greedy-necessary orderings (
true step becomes true first time). However, methods find landmarks
conjunction orderings often find many landmarks using general
concept greedy-necessary orderings (Hoffmann et al., 2004). LAMA follows paradigm
finds greedy-necessary (as well natural) orderings, necessary orderings. example
Figure 3, box truck1 must true box C also box F. first
orderings greedy-necessary, necessary, second neither greedy-necessary
necessary, natural.
Hoffmann et al. (2004) propose kinds orderings landmarks usefully exploited. example, reasonable orderings, first introduced context
top-level goals (Koehler & Hoffmann, 2000), orderings necessarily hold given
planning task. However, adhering orderings may save effort solving task.
example task, reasonable load box onto truck1 driving truck airport
140

fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarks

C. However, order guaranteed hold every plan, possible, though reasonable, drive truck C first, drive B collect box, return C. idea
landmark must become false order achieve landmark , needed ,
reasonable achieve (as otherwise, would achieve twice).
idea may applied iteratively, sometimes able find new, induced reasonable orderings
restrict focus plans obey first set reasonable orderings. Hoffmann et al. call
reasonable orderings found second pass obedient-reasonable orderings. authors
note conducting two iterations process worthwhile, typically
result notable additional benefit. following definition characterises two types
orderings formally.
Definition 5. Reasonable orderings landmarks
Let landmarks FDR planning task .
say reasonable ordering , written r , every plan
added time first added time j < j, holds true
time {i + 1, . . . , j} true time k j k.
say plan obeys set orderings O, orderings x O, regardless
type, holds first added time true time j i.
say obedient-reasonable ordering regard set
orderings O, written
r , every plan obeying added time
first added time j < j, holds true time {i + 1, . . . , j}
true time k j k.
definitions equivalent Hoffmann et al. (2004), except care
plans rather arbitrary operator sequences, allowing us (theoretically) identify
reasonable orderings. practice, use approximation techniques Hoffmann et al.,
thus generating orderings.
problem reasonable obedient-reasonable orderings may cyclic, i. e.,
chains orderings r x . . . r landmarks may exist (Hoffmann et al., 2004).
case natural orderings, definition implies cannot cyclic
solvable tasks.
addition, definitions given problematic special cases. Note definition reasonable ordering r includes case exist < j
added time first added time j, i. e., case holds plans first
added (a) (b) time .1 (a) implies reasonable orderings
generalisation natural orderings, might regarded desirable property, (b) may lead
undesirable orderings. example, holds r r pairs ,
first added time plans, instance true initial state.
Similarly, holds r . use definitions despite weaknesses here,
simply note planner create contentious orderings. LAMA
create reflexive orderings r ; r , true initial state created
assumed proven must true strictly point plan (see also Section
1. According personal communication authors, case overlooked Hoffmann et al.

141

fiRichter & Westphal

truck1
truck1 B

box B

box truck1
truck1 C
plane1 C plane2 C

box C

box plane1 box plane2
box F
Figure 4: Partial landmark graph example task shown Figure 3. Bold arcs represent natural
orderings, dashed arcs represent reasonable orderings.

4.2.5). re-definition reasonable orderings, addressing problems definition Hoffmann et al. identifying precisely wanted/unwanted cases, topic future work. Closely
connected question whether reasonable orderings interpreted strict orderings,
achieved (as definition obedience above), whether allow
achieving simultaneously. use strict sense obedience reasons consistency
previous work Hoffmann et al., aligns better intended meaning
reasonable orderings, even though strict interpretation obedience fit contentious
cases discussed above.
Landmarks orderings may represented using directed graph called landmark graph.
partial landmark graph extended example depicted Figure 4. following section
4.2 contains extensive description landmarks orderings discovered LAMA.
Readers interested exact details process may skip description, central
rest paper. Section 4.3 discusses approach finding using landmarks
relates previous work. Section 5 describes landmarks used heuristic estimator
LAMA.
4.2 Extracting Landmarks Orderings
mentioned before, deciding whether given formula landmark deciding orderings landmarks PSPACE-hard problems. Thus, practical methods finding landmarks
incomplete (they may fail find given landmark ordering) unsound (they may falsely declare formula landmark, determine false ordering). Several polynomial methods
proposed finding fact landmarks disjunctive landmarks, back-chaining
goals task, using criteria based relaxed planning graph (Porteous et al., 2001; Hoffmann et al., 2004; Porteous & Cresswell, 2002), forward propagation planning graph
(Zhu & Givan, 2003).
142

fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarks

algorithm used LAMA finding landmarks orderings partly based
previous back-chaining methods mentioned above, adapting finite-domain representation including conditional effects. addition, algorithm exploits finite-domain representation using domain transition graphs find landmarks. discuss differences
method previous ones detail Section 4.3. idea back-chaining
start set known landmarks find new fact landmarks disjunctive landmarks
must true plan already known landmark may become true. procedure starts
set goal facts, stops new landmarks found. method
identifies new landmarks orderings considering, given fact landmark disjunctive
landmark true initial state:
shared preconditions possible first achievers. operator preconditions
effect conditions shared effects potentially first achieve . method
adapted previous work (see Section 4.3).
fact landmarks v 7 d, domain transition graph (DTG) v. Here, identify nodes
DTG (i. e., values d0 v) must necessarily traversed order reach d.
restricted relaxed planning graph lacking operators could possibly achieve . (There
subtleties involving conditional effects explained later.) Every landmark
occur last level graph achieved .
previous work (Porteous et al., 2001; Hoffmann et al., 2004), subsequently use discovered landmarks orderings derive reasonable obedient-reasonable orderings postprocessing step. following, give detailed description step procedure
finding landmarks orderings LAMA. High-level pseudo code algorithm, containing
steps described following sections 4.2.14.2.4, shown Algorithm 2.
4.2.1 Back-Chaining: Landmarks via Shared Preconditions Possible First Achievers
First achievers fact landmark disjunctive landmark operators potentially
make true applied end partial plan never made true before.
call fact precondition first achievers shared precondition. least
one first achievers must applied make true, must true achieved,
thus landmark, ordering gn . effect condition operator
treated like precondition context, interested finding conditions
must hold become true. following use term extended preconditions
operator denote union preconditions effect conditions .
extended preconditions shared achievers fact calculated line 19 Algorithm 2.
addition, create disjunctive landmarks selecting, precondition facts first
achievers, sets facts set contains one extended precondition fact first
achiever (line 22). one first achievers must applied make true, one facts
must true , disjunction thus landmark, ordering gn . Since
number disjunctive landmarks exponential number achievers , restrict
disjunctions facts stem predicate symbol, deemed
helpful (Hoffmann et al., 2004). Furthermore, discard fact sets size greater
four, though found restriction little impact compared predicate restriction.
143

fiRichter & Westphal

Global variables:
= hV, s0 , s? , O, Ci
LG = hL, Oi
queue
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30:
31:

. Planning task solve
. Landmark graph
. Landmarks back-chained

function add landmark ordering(, x )
fact L : . |=
. Prefer fact landmarks
L L \ {}
. Remove disjunctive landmark
\ { ( x ), ( x ) | L }
. Remove obsolete orderings
L : . var() var() , . Abort overlap existing landmark
return
< L
. Add new landmark graph
L L {}
queue queue {}
{ x }
. Add new ordering graph
function identify landmarks
LG hs? ,
. Landmark graph starts goals, orderings
queue s?
orderings
. Additional orderings (see Section 4.2.3)
queue ,
pop(queue)
s0 6|=
RRPG restricted relaxed plan graph
preshared shared extended preconditions extracted RRPG
preshared
add landmark ordering(, gn )
predisj sets facts covering shared extended preconditions given RRPG
predisj
s0 6|=
add landmark ordering(, gn )
fact
prelookahead extract landmarks DTG variable using RRPG
prelookahead
add landmark ordering(, )
potential orderings potential orderings { F | F never true RRPG }
add orderings landmarks potential orderings

Algorithm 2: Identifying landmarks orderings via back-chaining, domain transition graphs
restricted relaxed planning graphs.

144

fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarks

p1



B

t1

E

t2

C

p2



F

Figure 5: Domain transition graph location box extended example (Figure 3).

Since PSPACE-hard determine set first achievers landmark (Hoffmann et al.,
2004), use over-approximation containing every operator possibly first achiever
(Porteous & Cresswell, 2002). intersecting extended preconditions (possibly)
operators lose correctness, though may miss landmarks. approximation first achievers done help restricted relaxed planning graph.
construction graph leave operators would add unconditionally, also
ignore conditional effects could potentially add . relaxed planning graph
levels out, last set facts over-approximation facts achieved
planning task. operator applicable given over-approximating set achieves
possible first achiever .
4.2.2 Landmarks via Domain Transition Graphs
Given fact landmark L = {v 7 l}, use domain transition graph v find fact
landmarks v 7 l0 (line 27) follows. DTG contains node occurs every path
initial state value s0 (v) variable landmark value l, node corresponds
landmark value l0 v: know every plan achieving L requires v takes value l0 ,
hence fact L0 = {v 7 l0 } introduced new landmark ordered naturally L.
find kinds landmarks, iteratively remove one node DTG test simple
graph algorithm whether s0 (v) l still connected not, removed node corresponds
landmark. improve procedure removing, preprocessing step, nodes
know cannot true achieving L. nodes correspond
facts L appear restricted RPG never adds L. Removing nodes
may decrease number paths reaching L may thus allow us find landmarks.
Consider landmark graph extended example, shown Figure 4.
landmarks orderings found via back-chaining procedure described previous
section, landmarks direct preconditions achieving successors graph.
two exceptions: box truck1 box C. two landmarks however found
DTG method. DTG Figure 5 immediately shows box location must take
value t1 value C path initial value B goal value F.
145

fiRichter & Westphal

4.2.3 Additional Orderings Restricted Relaxed Planning Graphs
restricted relaxed planning graph (RRPG) described Section 4.2.1, given landmark leaves operators could possibly achieve , used extract additional
orderings landmarks. landmark appear graph cannot reached
, thus introduce natural ordering . efficiency reasons, construct
RRPG (line 18), i. e., needed find possible first achievers
back-chaining procedure. extract orderings facts
reached (line 30). facts F later recognised landmarks,
introduce ordering F (line 31).
4.2.4 Overlapping Landmarks
Due iterative nature algorithm possible find disjunctive landmarks
least one facts already known fact landmark. cases, let fact
landmarks take precedence disjunctive ones, i. e., disjunctive landmark discovered
includes already known fact landmark, add disjunctive landmark. Conversely,
soon fact landmark found part already known disjunctive landmark, discard
disjunctive landmark including orderings2 , add fact landmark instead. keep
procedure resulting landmark graph simple, furthermore allow landmarks
overlap. Whenever fact newly discovered disjunctive landmark also part
already known landmark, add newly discovered landmark. cases handled
function add landmark ordering (lines 1 10).
4.2.5 Generating Reasonable Obedient-Reasonable Orderings
want introduce reasonable ordering L r L0 two (distinct) fact landmarks L
L0 holds (a) L0 must true time first achieving L, (b) achieving
L0 L would require making L0 false achieve L. approximate (a) (b)
proposed Hoffmann et al. (2004) sufficient conditions. case (a), test L0 s?
chain natural greedy-necessary orderings landmarks L = L1 . . . Ln ,
n > 1, Ln1 , L0 greedy-necessary ordering L0 gn Ln . (b) check whether (i) L
L0 inconsistent, i. e., mutually exclusive, (ii) operators achieving L effect
inconsistent L0 , (iii) landmark L00 inconsistent L0 ordering
L00 gn L.
Inconsistencies facts easily identified finite-domain representation
facts form v 7 v 7 d0 , i. e., map variable different values.
addition, LAMA uses groups inconsistent facts computed translator component.
second pass, obedient-reasonable orderings added. done method
above, except reasonable orderings used addition natural greedy-necessary
orderings derive fact landmark L0 must true landmark L. Finally, use
simple greedy algorithm break possible cycles due reasonable obedient-reasonable orderings landmark graph, every time cycle identified, one involved reasonable
2. Note ordering {F, G} neither implies F G general. Conversely, {F, G} neither
implies F G.

146

fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarks

obedient-reasonable orderings removed. algorithm removes obedient-reasonable orderings
rather reasonable orderings whenever possible.
4.3 Related Work
Orderings landmarks generalisation goal orderings, frequently
exploited planning search past. particular, approach Irani Cheng (Irani &
Cheng, 1987; Cheng & Irani, 1989) preprocessing procedure like analyses planning
task extract necessary orderings goals, imposed search algorithm.
goal ordered goal B approach plan necessarily true B.
Koehler Hoffmann (2000) introduce reasonable orderings goals.
Hoffmann et al. (2004), article detailing earlier work Porteous et al. (2001), introduce
idea landmarks, generalise necessary reasonable orderings goals landmarks,
propose methods finding using landmarks planning. proposed method finding
landmarks, subsequently extended Porteous Cresswell (2002), closely
related ours. Hoffmann et al. propose method finding fact landmarks proceeds three
stages. First, potential landmarks orderings suggested fast candidate generation procedure. Second, filtering procedure evaluates sufficient condition landmarks candidate
fact, removing fail test. Third, reasonable obedient-reasonable orderings landmarks approximated. step largely identical approach ours,
except use different methods recognise inconsistencies facts.
generation landmark candidates done via back-chaining goal much like
approach, intersecting preconditions operators first achieve fact F
appear F relaxed planning graph. Note even operators share
common precondition L, might first achievers F (appearing F relaxed
planning graph) L precondition, hence L landmark. test whether
landmark candidate L found via back-chaining indeed landmark, Hoffmann et al. (2004)
build restricted relaxed planning task leaving operators could add L. task
unsolvable, L landmark. sufficient, necessary condition: L necessary
solving relaxed task also necessary solving original task, converse
true. verification procedure guarantees method Hoffmann et al. generates true
landmarks; however, unsound orderings may established due unsound landmark candidates.
unsound landmarks pruned failing verification test, unsound orderings may
remain.
Porteous Cresswell (2002) propose alternative approximation first achievers
fact F use. consider first achievers possibly applicable F
thus guarantee correctness found landmarks orderings. also find disjunctive
landmarks. method landmark detection differs adding detection landmarks
via domain transition graphs, detection additional orderings via restricted relaxed planning
graphs. Porteous Cresswell additionally reason multiple occurrences landmarks (if
landmark achieved, made false re-achieved several times plans),
not.
approach Hoffmann et al. (2004) exploits landmarks decomposing planning task
smaller subtasks, making landmarks intermediary goals. Instead searching goal
task, iteratively aims achieve landmark minimal respect orderings.
147

fiRichter & Westphal

detail, first builds landmark graph (with landmarks vertices orderings arcs). Possible
cycles broken removing arcs. sources resulting directed acyclic graph
handed base planner disjunctive goal, plan generated achieve one
landmarks . landmark, along incident arcs, removed landmark
graph, process repeats end state generated plan. landmark graph
becomes empty, base planner asked generate plan original goal. (Note even
though goal facts landmarks thus achieved previously, may violated
again.)
base planner solving subtasks planner used; Hoffmann et al. (2004)
experimented FF. found decomposition subtasks lead directed search, solving larger instances plain FF many domains. However, found
method leads worse average performance IPC benchmarks 1998 2006
using Fast Downward base planner (Richter et al., 2008). Furthermore, method Hoffmann et al. often produces solutions longer produced base planner,
disjunctive search control frequently switches different parts task may
destructive interactions. Sometimes even leads dead ends, approach fails
solvable tasks. contrast, approach incorporates landmark information searching
original goal planning task via heuristic function derived landmarks (see next
section). recently shown, avoids possibility dead-ends usually generates
better-quality solutions (Richter et al., 2008).
Sebastia et al. (2006) extend work Hoffmann et al. employing refined preprocessing technique groups landmarks consistent sets, minimising destructive interactions
sets. Taking sets intermediary goals, avoid increased plan length
experienced Hoffmann et al. (2004). However, according authors preprocessing
computationally expensive may take longer solving original problem.
Zhu Givan (2003) propose technique finding landmarks propagating necessary
predecessor information planning graph. definition landmarks encompasses operators
necessary plan (called action landmarks), furthermore introduce notion
causal landmark fact landmarks required precondition operators
every plan. argue fact landmarks causal accidental effects
warrant sought explicitly. algorithm computes action landmarks causal
fact landmarks time propagating information construction relaxed
planning graph. extended variant algorithm also able infer multiple occurrences
landmarks. Gregory et al. (2004) build work find disjunctive landmarks
symmetry breaking.
Similar work, Zhu Givan (2003) use causal fact landmarks action landmarks
estimate goal distance given state. end, treat fact landmark virtual
action (sets operators achieve fact landmark) obtain distance estimate bin
packing. items packed bins real landmark actions (singletons) virtual
actions, bin may contain elements pairwise intersection elements
non-empty. Zhu Givan employ greedy algorithm estimate minimum number bins
use value distance estimate. experimental results preliminary, however,
demonstrate significant advantage method FF planner.
148

fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarks

5. Landmark Heuristic
LAMA planning system uses landmarks calculate heuristic estimates. Since know
landmarks must achieved order reach goal, approximate goal distance
state reached path (i. e., sequence states) estimated number landmarks
still need achieved onwards. landmarks given

L(s, ) B L \ Accepted(s, ) ReqAgain(s, )
L set discovered landmarks, Accepted(s, ) set accepted landmarks,
ReqAgain(s, ) set accepted landmarks required again, following
definitions based given landmarks graph (L, O) :




L | |= @( x )
= hi





0
0
Accepted(s, ) B
= 0 ; hoi
Accepted(s0 [ ], ) L | |=





( x ) : Accepted(s0 [0 ], 0 )

ReqAgain(s, ) B Accepted(s, ) | 6|=

s? |= ( gn ) : < Accepted(s, )
landmark first accepted state true state, landmarks ordered
accepted predecessor state generated. landmark
accepted, remains accepted successor states. initial state, accepted landmarks
true initial state predecessors landmark graph.
accepted landmark required true (a) forms part goal
(b) must true directly landmark (i. e., gn ) accepted s.
latter case, since know must still achieved must true time step
, holds must achieved again. number |L(s, )| heuristic value
assigned state s. Pseudo code heuristic given Algorithm 3.
landmark heuristic assign non-zero value state goal state, since
goals landmarks always counted required per condition (a) above. However,
heuristic may also assign non-zero value goal state. happens plans found
obey reasonable orderings landmark graph, case goal state may
reached without landmarks accepted.3 Hence, need explicitly test states goal
condition order identify goal states search.
Note heuristic path-dependent, i. e., depends sequence states
reached initial state. raises question happens state reached
via several paths. LAMA, heuristic state calculated once, first reached.
alternative option would re-evaluate time new path discovered, taking
account information paths known time. Karpas Domshlak (2009) note,
calculate landmarks accepted given set paths P Accepted(s, P) B

P Accepted(s, ), since holds landmark achieved along paths P must
3. special case r become true simultaneously, could avoid accepting
(Buffet & Hoffmann, 2010), could modify definition reasonable orderings
r hold unless must become true strictly . general problem goal states may
assigned non-zero value, however, still persists even modifications.

149

fiRichter & Westphal

Global variables:
= hV, s0 , s? , O, Ci
LG = hL, Oi
Accepted

. Planning task solve
. Landmark graph
. Landmarks accepted states evaluated far

function lm count heuristic(s, )
= hi
. Initial state


Accepted(s, ) L | s0 |= @( x )
else
0 ho1 , . . . , on1 = ho1 , . . . ,
parent s0 [0 ]
. Accepted(parent, 0 ) calculated
Reached { L | |= ( x ) : Accepted(parent, 0 ) }
Accepted(s, ) Accepted(parent, 0 ) Reached
NotAccepted L \ Accepted(s, )
ReqGoal { n Accepted(s, ) | 6|= s? |= }

ReqPrecon Accepted(s, ) | 6|= : ( gn ) < Accepted(s, )
return |NotAccepted ReqGoal ReqPrecon|
Algorithm 3: landmark count heuristic.

achieved onwards. heuristic value derived analogous
way before.
landmark heuristic outlined estimates goal distance states, i. e., number
operator applications needed reach goal state given state. participate IPC 2008,
made function cost-sensitive weighting landmarks estimate minimum
cost. Apart estimating goal distance counting number landmarks still need
achieved state, estimate cost-to-go state sum minimum costs
landmarks. cost counted landmark minimum action cost
first achievers. (Alternative, sophisticated methods computing costs landmarks
conceivable potential topic future work.) heuristic value LAMA assigns
state however pure cost-to-go estimate, rather sum cost estimate
distance estimate. thus accounting costs-to-go goal distances states,
measure aims balance speed search quality plans, particular counter-act
problems may arise zero-cost operators (see Section 3.3).
also generate preferred operators along landmark heuristic. operator preferred
state applying achieves acceptable landmark next step, i. e., landmark whose predecessors already accepted. acceptable landmark achieved within one step,
preferred operators occur relaxed plan nearest acceptable landmark.
nearest landmark cost-unaware setting one relaxed reachable minimal number
operators, cost-sensitive setting landmark reachable cheapest hadd cost
(see Section 6), cost distance estimates taken account. nearest
landmark computed building relaxed planning graph or, equivalently, performing relaxed exploration (which LAMA does, see Section 6), determining earliest least
costly occurrence acceptable landmark structure. relaxed plan landmark
150

fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarks

extracted, operators plan form preferred operators applicable
current state.

6. Cost-Sensitive FF/add Heuristic
first introduced landmark heuristic (Richter et al., 2008), proved competitive own, compared established heuristics like FF heuristic (Hoffmann & Nebel,
2001). However, joint use FF heuristic landmark heuristic multi-heuristic
search improved performance planning system, compared using FF heuristic.
thus path LAMA follows. FF heuristic based relaxation planning task
ignores delete effects, FDR tasks translates allowing state variables hold several
values simultaneously.
FF heuristic state computed two phases: first phase, forward phase,
calculates estimate fact planning task costly achieve fact
relaxed task. Concurrently, selects operator called best support fact F,
greedy approximation cheapest achiever (an achiever F costs making
applicable applying minimal among achievers F, starting s). second
phase, plan relaxed task constructed based best supports fact. done
chaining backwards goals, selecting best supports goals, recursively
selecting best supports preconditions already selected operators. union
best supports constitutes relaxed plan (i. e., fact best support added
relaxed plan once, even fact needed several times precondition). length
resulting relaxed plan heuristic estimate reported s.
forward phase viewed propagating cost information operators facts
relaxed planning graph (Hoffmann & Nebel, 2001). However, graph need
explicitly constructed compute heuristic. Instead, form generalised Dijkstra cheapestpath algorithm described Liu, Koenig Furcy (2002) used LAMA, propagates
costs preconditions applicable operators operators effects. method,
operator fact represented once, reducing time space requirements O(NK),
N size relaxed planning task K depth relaxed planning graph,
O(N). order deal conditional effects, operators n effects split n operators
one effect each, corresponding effect conditions moved preconditions
operators. n operators selected inclusion relaxed plan, original
operator included instead (again, operator included relaxed plan once).
cost estimate operator original FF heuristic depth relaxed planning
graph, case planning unit-cost operators equivalent (Fuentetaja, Borrajo, &
Linares Lopez, 2009) propagating costs via hmax criterion (Bonet & Geffner, 2001). hmax
criterion estimates cost operator maximum costs preconditions, plus
action cost operator (1 planning without action costs). cost fact
estimated cost cheapest achiever, zero fact true current state s.
originally proposed unit-cost planning, heuristic adapted cost-based planning
straightforward way using action costs cost propagation phase, reporting total cost
resulting relaxed plan, rather length, heuristic estimate.
Using criteria cost propagation results variations FF heuristic (Bryce & Kambhampati, 2007; Fuentetaja et al., 2009). One variant previously proposed litera151

fiRichter & Westphal

ture (Do & Kambhampati, 2003) use hadd criterion (Bonet & Geffner, 2001). similar
hmax criterion except estimating cost operators via sum, rather maximum,
costs preconditions. following use term FF/add variant
FF heuristic. Independently us, Keyder Geffner (2008) implemented FF/add heuristic
call ha planner FF(ha ) IPC 2008. formal specification FF/add heuristic
found paper. heuristic function LAMA similar cost-sensitive FF/add
heuristic. However, landmark heuristic, LAMA purely guided action costs,
rather uses cost distance estimates equally. means cost propagation,
operator contributes action cost plus 1 distance, rather action cost,
propagated cost estimates.

7. Experiments
evaluate much central features LAMA contributes performance,
conducted number experiments comparing different configurations features.
focus detailed evaluation benchmark tasks International Planning Competition
(IPC) 2008, interested setting planning action costs. effect landmarks
classical planning tasks without actions costs studied previous work (Richter et al.,
2008), provide summarising results case, using domains IPCs 19982006,
Section 7.6. benchmark set IPC 2008 comprises 9 domains 30 tasks each, resulting
total 270 tasks. one domains (Openstacks), two different formulations available
(STRIPS ADL). competition, report better result two formulations
planner.
described Section 1, LAMA builds platform provided Fast Downward three
major ways: (1) use landmarks, (2) using cost-sensitive heuristics guide search
cheap plans, (3) employing anytime search continue search better solutions
time remains. examine usefulness landmarks, conduct experiments without
them, keeping planner features fixed. use action costs LAMA result
number design decisions. landmark heuristic FF/add heuristic made
cost-sensitive. However, rather focusing purely action costs, LAMA uses distance
estimates cost estimates combination (see Section 3.3) balance speed quality
search. measure benefit combining approach, test three different approaches
dealing costs: (a) using traditional cost-unaware heuristics (distance estimates), (b) using
purely cost-sensitive heuristics (though using distance estimates tie-breaking), (c) using
combination distance cost estimates, LAMA. different choices regarding
landmarks approaches action costs thus result following six planner configurations:
F: Use cost-unaware FF/add heuristic (estimating goal distance).
Fc : Use purely cost-sensitive FF/add heuristic (estimating cost-to-go).
F+c : Use FF/add heuristic combines action costs distances.
FL: Use cost-unaware variants FF/add heuristic landmark heuristic.
FLc : Use purely cost-sensitive variants heuristics.
FL+c : Use variants combine action costs distances heuristics.
152

fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarks

Note contrast setting optimal planning (Karpas & Domshlak, 2009), landmark
heuristic competitive case, landmarks LAMA used provide
additional information already guided search. such, include configurations using landmarks heuristic estimators detailed results. However, provide
summarising results supporting claim competitive.
configuration run iterated (anytime) search. highlighting contribution
iterated search, report first solutions vs. final solutions, final solution
configuration last, best, solution finds within 30-minute timeout. (Note
quality solution always determined cost, irrespective whether heuristic used
calculate cost-sensitive not.) discussing three possible approaches costs (costunaware search, purely cost-sensitive search, LAMAs combination distances costs)
write X, Xc , X+c denote three cost approaches independently heuristics used.
measure performance using criterion employed IPC 2008 (Helmert
et al., 2008). planner configuration run 30 minutes per task. timeout, planner
aggregates ratio c /c total score c cost plan found, c cost
best known solution (e. g., reference solution calculated competition organisers,
best solution found participating planners).
Experiments run hardware used competition, cluster machines Intel
Xeon CPUs 2.66GHz clock speed. time memory limits set values
competition, using timeout 30 minutes memory limit 2 GB. following,
first provide general overview results. discuss special cases, i. e., domains
results certain configurations deviate overall trend, try give plausible
explanations may happen.
7.1 Overview Results
section, show purely cost-based FF/add configuration Fc solves significantly
fewer tasks cost-unaware counterpart F. Fc finds higher-quality solutions,
make low coverage (number solved tasks) measuring performance
IPC criterion. Using landmarks improves quality slightly, cost-unaware search using landmarks (FL) achieves highest IPC performance score amongst configurations. using
cost-sensitive FF/add heuristic, adding landmarks (resulting configurations FLc FL+c )
increases coverage substantially, incurring small loss quality. Iterated search improves scores configurations significantly. Lastly, using combination cost
distance estimates heuristics (X+c ) superior pure cost-based search using iterated search. Together, using landmarks combination cost distance estimates (FL+c )
achieves nearly performance FL configuration.
following, support findings experimental data. Section 7.1.1 (Performance Terms IPC Score), show cost-sensitive FF/add heuristic scores
lowly terms IPC criterion, landmarks combination cost distance estimates together make bad performance. Furthermore, results demonstrate magnitude impact iterated search performance scores. Section 7.1.2 (Coverage),
show bad performance cost-sensitive FF/add heuristic due solving fewer
tasks, use landmarks mitigates problem. Section 7.1.3 (Quality), present
data showing purely cost-sensitive FF/add heuristic finds higher-quality plans cost153

fiRichter & Westphal

Domain

Base

C3

Cyber Security
Elevators
Openstacks
PARC Printer
Peg Solitaire
Scanalyzer
Sokoban
Transport
Woodworking
Total
(Total IPC 2008)

4
21
21
27
20
24
21
18
14
169
(176)

9
16
10
18
20
23
18
6
24
143
(151)

Domain

F

Cyber Security
Elevators
Openstacks
PARC Printer
Peg Solitaire
Scanalyzer
Sokoban
Transport
Woodworking
Total

20
22
20
20
20
19
18
18
22
180

IPC Planners
FF(ha ) FF(has )
20
9
8
16
21
24
15
15
22
150
(157)

20
10
8
23
23
24
18
14
22
162
(169)

First solutions
FL FLc
Fc
F+c

FL+c

24
9
23
16
23
21
20
15
20
171

27
16
14
21
21
21
19
23
20
182

24
9
20
16
20
20
19
15
20
162

20
23
13
23
20
22
18
24
20
182

28
14
13
21
22
21
19
24
20
183

LAMA
28
20
27
21
29
26
24
27
25
227
(236)

Slowed LAMA
10
100

FL+c

27
20
27
19
29
25
22
25
24
218
()

28
22
27
22
29
26
23
26
24
227
()

26
17
26
12
26
22
15
21
17
183
()

Final solutions (iterated search)
F
Fc
F+c
FL FLc FL+c
23
29
27
23
29
24
24
19
23
220

24
10
29
16
29
24
24
17
21
194

25
15
28
16
29
25
24
17
22
201

26
27
27
24
29
29
22
24
20
229

28
16
28
22
29
24
23
26
23
217

28
22
27
22
29
26
23
26
24
227

Table 1: Performance scores (rounded whole numbers) planners scoring 100 points
IPC 2008 (top) 6 experimental configurations (bottom). Scores IPC planners recalculated (see text). LAMA 10 100 refer results achieved LAMA slowed
factors 10 100, respectively. FL+c essentially IPC planner LAMA.

unaware FF/add heuristic first search, iterated search, difference
disappears. Furthermore, iterated search intermediate approach using cost distance
estimates scores higher purely cost-based search. LAMAs approach using landmarks
combination cost distance estimates (FL+c ) thus effectively mitigates bad performance cost-sensitive FF/add heuristic.
7.1.1 Performance Terms IPC Score
scores planners scoring 100 points IPC 2008 shown top part
Table 1. Apart LAMA, includes base planner run competition organisers (FF
preprocessing step compiles away action costs), FF(ha ) FF(has ) planners Keyder
154

fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarks

Geffner (2008) C3 planner Lipovetzky Geffner (2009). plans found
planners obtained competition website (Helmert et al., 2008). However,
scores plans depend best known solutions tasks. scores show
thus differ ones published IPC 2008, re-calculated reflect new
best solutions found experiments. illustrate magnitude change, original total
scores IPC planners shown parentheses last table row.
configuration FL+c results essentially planner (the IPC version of)
LAMA, report results again, minor corrections implemented LAMA
since competition. addition, planner makes arbitrary decisions points
execution due underlying programming library methods, leading varying results. However,
Table 1 shows differences FL+c LAMA small. furthermore
added columns table showing hypothetical results LAMA would obtained
search slowed constant factors 10 100, respectively (i. e., results obtained
cutting search 3 minutes, 18 seconds, respectively). numbers show
LAMA still outperforms IPC planners even severe handicap, demonstrating
good performance LAMA mainly due efficient implementation.
bottom part Table 1 contains results six experimental configurations
first search iteration (left) 30-minute timeout (right). seen, use
landmarks iterated search lead significant improvements performance. Even one
two features planner performs notably better competitors IPC 2008.
(Note however baseline planner performed badly Cyber Security due problems
reading large task descriptions.) combination, benefits landmarks iterated
search grow further: cost-unaware search use landmarks results 2 additional score points
first solutions, 9 additional points final solutions. Similar results hold
cost-sensitive configurations. mainly due Openstacks domain, using landmarks
highly detrimental solution quality first solutions. Iterated search mitigates problem
improving quality similar levels without landmarks. Overall, thus slight
synergy effect landmarks iterated search, making joint benefit two features
larger sum individual contributions. effect landmarks Openstacks
domain discussed detail later.
use cost-sensitive search pay experiments. Cost-unaware search
always least roughly equal, often substantially better cost-sensitive configurations.
Cost-sensitive planning seems problem LAMA, also participating planners IPC 2008: notably, cost-sensitive competitors LAMA fare worse
cost-ignoring baseline. LAMA, best performance achieved using cost-unaware search
landmarks iterated search. However, using combination cost distance estimates instead (FL+c ) leads performance almost equally good. particular, FL+c substantially
better pure cost search FLc iterated search used.
detailed view data provided Figure 6, show performance
time six experimental configurations. data point 100 seconds, example, shows
score corresponding planner would achieved timeout 100 seconds.
top panel shows, cost-sensitive search consistently worse cost-unaware search using
FF/add heuristic. Using landmarks (see centre panel), two settings FL FL+c achieve
better performance F, though FL+c needs 2 minutes surpass F, FL within 5
seconds. Pure cost search, even landmarks (FLc ), performs worse F times.
155

fiRichter & Westphal

240
220

Score

200
180
160
F
Fc
F+c

140
120
1

10

100
Time (seconds)

1000

240
220

Score

200
180
160
F
FL
FLc
FL+c

140
120
1

10

100
Time (seconds)

1000

240
220

Score

200
180
160
F
FL
FLc
FL+c

140
120
1

10

100
Time (seconds)

1000

Figure 6: Score time using iterated search (top centre panel) without iterated search,
i. e., showing first solutions (bottom panel).

156

fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarks

Domain

Base

C3

FF(ha )

FF(has )

LAMA

FL+c

Cyber Security
Elevators
Openstacks
PARC Printer
Peg Solitaire
Scanalyzer
Sokoban
Transport
Woodworking
Total

4
30
30
30
30
30
27
29
17
227

15
30
30
18
30
27
22
12
28
212

23
23
25
16
29
28
17
23
29
213

22
26
26
23
29
28
20
22
29
225

30
24
30
22
30
30
25
30
30
251

30
25
30
23
30
30
24
30
30
252

Domain

F

Fc

F+c

FL

FLc

FL+c

Cyber Security
Elevators
Openstacks
PARC Printer
Peg Solitaire
Scanalyzer
Sokoban
Transport
Woodworking
Total

30
30
30
25
30
28
25
26
30
254

28
15
30
16
30
30
25
22
28
224

29
16
30
16
30
29
24
21
28
223

30
30
30
24
30
30
23
29
28
254

30
22
30
23
30
30
24
30
30
249

30
25
30
23
30
30
24
30
30
252

Table 2: Coverage planners scoring 100 points IPC 2008 (top) 6 experimental
configurations (bottom). Results IPC planners taken competition. FL+c
essentially IPC planner LAMA.

bottom panel Figure 6 shows using iterated search, performance 4 best
configurations FL, F, FL+c , FLc fairly similar eventually, cost-sensitive approaches
need time cost-unaware configurations reach performance levels.
7.1.2 Coverage
bad performance cost-sensitive search surprising, given performance criterion
awards higher scores cheaper plans. One explanation could mainly due different coverage. finding plans high quality substantially harder finding plans low
quality, focusing nearest goals rather cheapest goals may solve tasks within
given time limit. Table 2 show coverage considered planners configurations.
numbers confirm using landmarks, coverage cost-unaware search indeed
substantially higher coverage cost-sensitive search. However, landmarks, differences coverage various cost approaches small. particular, landmarks
improve coverage cost-unaware search, bring cost-sensitive configurations
157

fiRichter & Westphal

Domain
Cyber Security
Elevators
Openstacks
PARC Printer
Peg Solitaire
Scanalyzer
Sokoban
Transport
Woodworking
Total

Domain
Cyber Security
Elevators
Openstacks
PARC Printer
Peg Solitaire
Scanalyzer
Sokoban
Transport
Woodworking
Total

Fc / F
Tasks C. Ratio
28
15
30
16
30
28
23
21
28
219

0.64
1.16
0.83
0.79
0.87
0.94
0.94
1.01
1.02
0.88

Fc / F
Tasks C. Ratio
28
15
30
16
30
28
23
21
28
219

0.81
1.51
0.95
0.97
0.99
1.01
1.01
0.98
0.99
0.99

F+c / F
Tasks C. Ratio
29
16
30
16
30
28
22
21
28
220

0.69
1.15
1.00
0.79
1.02
0.93
0.98
1.00
1.02
0.94

F+c / F
Tasks C. Ratio
29
16
30
16
30
28
22
21
28
220

0.82
1.05
0.96
0.97
1.00
0.93
1.00
0.89
0.94
0.94

FLc / Fc
Tasks C. Ratio
28
14
30
15
30
30
24
22
28
221

0.81
0.89
1.98
1.05
1.04
0.98
0.98
0.89
1.07
1.06

FLc / Fc
Tasks C. Ratio
28
14
30
15
30
30
24
22
28
221

0.81
0.89
1.04
1.01
1.02
1.02
1.02
0.89
1.00
0.97

FL+c / F+c
Tasks C. Ratio
29
16
30
15
30
29
23
21
28
221

0.83
0.92
1.46
1.05
0.95
1.00
1.00
0.89
1.06
1.01

FL+c / F+c
Tasks C. Ratio
29
16
30
15
30
29
23
21
28
221

0.82
0.99
1.04
1.01
1.01
1.01
1.00
0.89
1.01
0.97

Table 3: Average ratio first solution costs (top) best solution costs iterative search
(bottom) various pairs configurations commonly solved tasks.
coverage level cost-unaware search. Landmarks thus seem helpful
overcoming coverage problems cost-sensitive search.
mentioned before, landmark heuristic however competitive. Using
landmark heuristic FF/add heuristic results IPC 2008 performance scores
164 167 iterated search, coverage points 185 189 three possible
cost settings. substantially worse performance scores greater 194 coverage
points greater 223 achieved LAMA configurations.
7.1.3 Quality
next step, look purely solution quality. Firstly, want answer question whether
improvement coverage achieved landmarks cost-sensitive search comes price
solution quality, i. e., whether using landmarks directs search close goals rather cheap
goals. Secondly, would like know solution quality differs cost-sensitive
cost-unaware configurations. particular, much quality lose combining
158

fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarks

distance cost estimates (X+c ) opposed using pure cost search (Xc )? score used IPC
2008 Table 1 incorporates coverage quality information counting unsolved tasks
0 method allows ranking several planners solving different subsets total benchmark
set. interested examining quality independent coverage, must restrict focus tasks solved compared planners. Table 3 contains quality information comparing
solution costs several configurations, compare configurations pair-wise order
maximise number commonly solved tasks. top part Table 3 contains comparisons
involving first solutions found configuration, bottom part table concerns
best solutions found iterative search. pair configurations show number
tasks solved both, geometric mean cost ratio plans find.
expected, cost-sensitive configurations Fc F+c find cheaper plans costunaware configuration F average, particular pure cost search Fc finds high-quality
first plans (see first column top part table). Fc F+c , however, difference F large. domains, notably Elevators, plans found
cost-sensitive heuristics actually worse plans found cost-unaware search.
Landmarks deteriorate quality first plans Fc ; F+c , starts worse
quality Fc , noticeably deteriorated landmarks. configurations, however, main negative impact landmarks Openstacks domain, plans become
nearly twice expensive Fc , 50% expensive F+c . contrast, remaining
8 domains average plan quality configurations landmarks even slightly better
average without landmarks.
note iterative search remarkable impact relative performance different configurations. looking solutions found iterative search, Fc actually performs
worse F+c , whereas way round first solutions (compare first two
columns top row versus bottom row table). explained extent
fact reasons cause Fc low coverage also prevent improving much time. show selected domains later, cost-sensitive heuristic often
expands many nodes cost-unaware search, leading observed behaviour.
likely due fact finding plans high quality hard thus unsuccessful many
benchmark tasks. example, domains cost-sensitive search leads large local
minima exist cost-unaware search. generally, good plans often longer
bad plans, may lead increased complexity particular domains heuristic
values inaccurate. showcase problems cost-sensitive search detail
Elevators PARC Printer domains later on.
iterative search, landmarks deteriorate quality either Fc F+c average,
negative impact Openstacks domain longer present. (This effect Openstacks
domain discussed detail later.)
Summarising findings, say landmarks effectively support cost-sensitive
FF/add heuristic finding solutions, without steering search away good solutions. Similarly, combining distance cost estimates X+c leads search finding solutions quickly
without overly sacrificing quality, demonstrated superior anytime performance compared
pure cost search.
way example, present detailed results four nine competition domains.
choose domains deem particular interest results either exaggerate contradict general trends discussed far. domains Elevators PARC Printer
159

fiRichter & Westphal

8
7
6
5
4
3
2
1
0
Figure 7: example elevators task.

highlight problems cost-sensitive search; Cyber Security cost-sensitive search performs
uncharacteristically well; Openstacks domain landmarks lead usual
improvement, rather deterioration performance.
7.2 Elevators
Elevators domain models transportation passengers building via fast slow elevators, elevator certain passenger capacity access certain floors. Passengers
may change elevators get final destination, furthermore two different types
elevators different associated cost functions. contrast Miconic domain, used
earlier international planning competition (Bacchus, 2001), also models transporting passengers via elevators, one elevator access floors
one (unit-cost) operator. Elevators, floors building grouped blocks, overlapping one floor. Slow elevators operate within block access floors within
block. Fast elevators access blocks, certain floors within block (in
first 10 IPC tasks every second floor, 20 tasks every fourth floor). Fast elevators
usually expensive slow elevators except distance two floors, elevator
types cost same. However, fast elevators may sometimes advantageous transporting
passengers blocks (as avoid need passengers switch elevators shared
floor blocks), usually higher capacity.
example task eight floors, grouped two blocks, shown Figure 7.
total four elevators, two slow ones two fast ones. cost function used 30 IPC tasks
moving elevator current location target floor 6 + n slow elevators 2 + 3n
fast elevators, n distance travelled (the number floors current location
elevator target). Operators concerning passengers boarding leaving elevators
free cost. Assuming cost function, cheaper example transport passenger
located floor 0 using two slow elevators (changing floor 4) using direct fast elevator.
Elevators one domains configurations using cost-sensitive FF/add heuristic
solve far fewer problems cost-unaware counterparts. Using landmarks increases coverage,
solve problem completely. Furthermore, notable problems
cost-sensitive configurations solve, solutions often worse quality solutions
cost-unaware configurations. Table 4 illustrates fact first solutions found using
160

fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarks

Task
01
02
03
04
05
06
07
08
09
11
12
13
14
20
21
Avg.

Quality (IPC Score)
F
Fc
F+c
0.57 0.59
0.53
0.69 0.72
0.72
0.88 0.58
0.51
0.71 0.70
0.72
0.68 0.54
0.54
0.60 0.60
0.61
0.38 0.46
0.40
0.84 0.54
0.51
0.71 0.54
0.57
0.66 0.52
0.52
0.70 0.54
0.58
0.58 0.51
0.54
0.70 0.70
0.70
0.67 0.47
0.58
0.70 0.63
0.71
0.67 0.58
0.58

F
26
27
21
34
33
56
71
47
54
39
55
60
81
132
84
55

Length
Fc
24
25
41
45
50
64
81
62
81
51
79
84
101
173
83
67

F+c
27
25
42
47
50
53
83
65
59
47
79
72
95
154
82
65

Table 4: Comparison plan qualities (measured via IPC scores) plan lengths first
solutions F, Fc , F+c Elevators. Shown tasks solved three configurations,
bold print indicating best solution.

FF/add heuristic. iterative search (not shown), solution quality F+c improves
similar level F, whereas Fc remains substantially worse.
full explanation configurations involving cost-sensitive
FF/add heuristic perform badly domain, several factors seem play role. Firstly,
attempt optimise costs, cost-sensitive FF/add heuristic focuses relatively complex solutions
involving mainly slow elevators many transfers passengers elevators,
relaxed plans less accurate (i. e., translate less well actual plans), case
cost-unaware heuristic. Secondly, costs associated movements elevators dominate
heuristic values, causing local minima cost-sensitive heuristic. Thirdly, capacity
constraints associated elevators may lead plateaus bad-quality plans particular
cost-sensitive heuristic. following sections, describe factors detail.
Lastly, found deferred heuristic evaluation technique used LAMA (see Section 3.3) perform well domain. using deferred evaluation, Fc configuration solves 3 additional tasks (though quality solutions remains worse F
configuration). partly explains FF(ha ) planner Keyder Geffner (2008)
substantially higher coverage Fc configuration domain. two planners use
heuristic, differ several aspects. Apart deferred evaluation aspects include search algorithm used (greedy best-first search vs. enhanced hill-climbing) method
using preferred operators (maintaining additional queues preferred states vs. pruning nonpreferred successor states).
161

fiRichter & Westphal

F
Fc
F+c

Slow moves
275
405
404

Fast moves
45
21
12

Ratio fast/slow
6.11
19.29
33.67

Table 5: Total elevator moves ratio fast/slow moves first solutions found F, Fc ,
F+c configurations, 15 Elevators instances solved three configurations.
7.2.1 Slow vs. Fast Elevators
examining results, found Fc F+c configurations tend produce plans
slow elevators used passengers, F configuration uses
fast elevators often (cf. Table 5). surprising, individual passenger,
travelling starting point destination tends cheaper slow elevator (unless
distance short), whereas fewer operators typically required travelling fast
elevator. independence assumptions inherent FF/add heuristic (see Section 6) lead
constructing relaxed plans aim optimise transportation passenger individually,
rather taking synergy effects account.
plans produced Fc F+c also longer, average, plans produced F (see
Table 4), one reason predominant use slow elevators requires passengers
change elevators often. plans become longer involve passengers
travelling slow elevators, heuristic estimates may become worse. example,
relaxed plans extracted computation heuristic likely abstract away details
passengers travel elevator (e. g., since passenger picked
delivered certain location, elevator may teleport back location extra
cost relaxed plan pick deliver subsequent passengers). Generally, found
relaxed plans initial state produced Fc F+c tend similar length cost
produced F, final solutions produced Fc F+c worse F. One reason
probably increased complexity planning passenger change-overs
elevators combination worse relaxed plans poses problem cost-sensitive
FF/add heuristic.
7.2.2 Local Minima Due Elevator-Movement Costs
Since action costs model distances, total cost relaxed plan depends target floors
relative current position elevator. Fc F+c , action costs moving
elevator usually dominate estimates FF/add heuristic. Consider two example tasks
Figure 8, differ initial state elevators. elevators need travel
three floors solution plan, due abstracted delete effects relaxed plan initial state
include operators travel two floors starting floor elevator
(i. e., elevator teleported back starting floor without cost). left task,
relaxed cost visiting three floors lower right task, cost left task
sum going floor 4 floor 8, going floor 4 floor 0, resulting total cost
10 + 10 = 20. right task, relaxed cost visiting floors cost going
floor 0 floor 4, floor 0 floor 8, resulting total cost 10 + 14 = 24. left
task, passenger boarded elevator floor 4, immediate successor states
162

fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarks

action cost

action cost

8
7
6
5
4
3
2
1
0

8
7
6
5
4
3
2
1
0

Figure 8: Action cost effects Elevators relaxed setting. Travelling 4 floors costs 10,
travelling 8 floors costs 14. tasks solution cost (34), left task lower
relaxed cost (20) right task (24).

worse heuristic estimate due movement costs elevator. particular, correct action
moving elevator floor 8 (to deliver passenger) results state worse heuristic
value. increased number waiting passengers floor 4, planning system would
therefore try boarding possible subsets passengers moving elevator. even
elevator moved floor 8, heuristic estimate improve passenger
dropped either (a) elevator moved back floor 4, (b) second passenger
boarded elevator moved floor 0.
Consequently, movement costs may dominate progress obtained transporting passengers
number successive states. words, planner often blindly achieve
progress move elevators towards middle position given remaining target floors,
order cost-sensitive heuristic report progress. cost-unaware heuristic, situation
less severe, number elevator movements relaxed plan increase,
hence planner encounters plateau search space rather local minimum. use
preferred operators may help escape plateau relatively quickly, whereas local minimum
much harder escape from. Two approaches exist may circumvent problem. Firstly,
use enforced hill-climbing (Hoffmann & Nebel, 2001) rather greedy best-first search
likely avoid exploration entire local minima: approach, breadth-first search
conducted first state minima/plateau improving state found. Secondly,
improved heuristic could used approximates optimal relaxed cost h+ exactly.
cost minima shown Figure 8 brought independence assumptions inherent
FF/add heuristic, estimate relaxed cost goal fact individually cheapest
possible way. optimal relaxed plan, however, costs left task right task.
accurate approximation optimal relaxed cost h+ could therefore mitigate described
cost minima. Keyder Geffner (2009) recently proposed improvement FF/add
heuristic4 shown particularly useful Elevators PARC Printer domains.
4. Keyder & Geffners approach, relaxed plan extracted FF/add heuristic improved iteratively (1)
selecting fact F, (2) fixing operators related F (because contribute achieving F
rely achievement), (3) computing cheaper way achieving F given operators fixed
previous step.

163

fiRichter & Westphal

7.2.3 Plateaus Due Capacity Constraints
general, relaxed plans Elevators domain often bad quality. One reasons
way capacity elevators encoded operators passengers boarding leaving
elevators. passenger p transported elevator e, one preconditions p leaving e
n passengers boarded e, n number greater 0. constructing relaxed
plan, FF/add heuristic recursively selects operators achieve necessary precondition
cheapest way. results boarding passenger closest e initial state, even
passenger p0 different p, achieve condition passenger boarded.
relaxed plan contain operators boarding p p0 e, may furthermore
contain operators boarding p0 whatever elevator e0 deemed best transporting p0 .
Hence, relaxed plans often contain many unnecessary boarding operators.
mentioned Section 3.3, greedy best-first search LAMA breaks ties equally
promising operators trying cheaper operator first. Consequently, zero-cost operators
passengers boarding leaving elevators tried first state. found soon one
passenger boarded certain elevator, relaxed plans next state often substantially
different, passengers assigned elevator. explained
fact soon one passenger elevator, precondition leaving elevator
least one person boarded, fulfilled (rather incurring additional cost).
example tasks examined, found effect results committing bad boarding
operators: LAMA may initially try bad boarding operator, e. g. boarding nearest passenger
elevator satisfy capacity precondition another passenger, described above.
relaxed plan successor state assigns passengers elevator, lower cost. Due
improved heuristic value successor state, LAMA retains plan prefix, even though
first operator bad one. plausible (though explore experimentally)
effect stronger configurations involving cost-sensitive heuristic, costs
relaxed plans vary strongly one state next.
importantly, capacity constraints lead plateaus search space, correct boarding leaving operators often recognised good operators. example, capacity
elevator c, boarding first c 1 passengers need transported elevator
usually leads improved heuristic values. However, boarding c-th passenger result
state better heuristic value passengers need transported via
elevator, c-th passenger boarding destroys precondition must
room elevator passengers board. Similarly, correct leaving passenger may
lead improved heuristic value makes elevator empty passengers need
transported elevator later (because last passenger leaving destroys precondition
leaving must least one passenger boarded).
effects exist cost-sensitive cost-unaware heuristic. However,
typically occur within plateaus (F) local minima (Fc , F+c ) created elevator positions,
described previous section, means affect cost-sensitive configurations
severely. plateaus become particularly large several passengers waiting
floor, e. g. passengers accumulating floor shared two blocks order switch
elevators. planner tries board possible subsets people available elevators (as
zero-cost boarding leaving operators always tried first), moving elevators even
dropping passengers floors, may still fail find state better heuristic value.
164

fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarks

First plans
Final plans

Fc
F+c
Fc
F+c

Solved
15
16
15
16

Original tasks
qual. > F qual. < F
3
10
5
10
0
15
5
6

capacity constraints
Solved qual. > F qual. < F
29
17
6
30
22
3
29
9
20
30
15
11

Table 6: Relative qualities solutions original Elevators domain modified variant
domain elevators unlimited capacity. Shown total number tasks solved
cost-sensitive configurations Fc F+c , well number tasks configurations find better/worse plan cost-unaware configuration F.
examining number states local minima configurations, found
Fc F+c indeed encounter many states F. example, percentage cases
state worse best known state typically around 10% (in rare cases 25%) F.
Fc F+c , hand, numbers usually 35%, often 50%,
large problems even 80%.
verify capacity constraints indeed contribute bad performance costsensitive heuristic domain, removed constraints IPC tasks ran
resulting problems F, Fc F+c configurations. surprisingly, tasks become much
easier solve, elevators transport passengers once. interestingly though,
bad plan qualities produced cost-sensitive configurations (relative cost-unaware
configuration) indeed become much less frequent, Table 6 shows.
summary, findings suggest bad performance cost-sensitive FF/add heuristic
Elevators domain due bad-quality relaxed plans (brought focus slow
elevators capacity constraints) plateaus local minima search space (resulting
movement costs elevators capacity constraints).
7.3 PARC Printer
PARC Printer domain (Do, Ruml, & Zhou, 2008) models operation multi-engine printer
capable processing several printing jobs time. sheet must printed needs pass
several printer components starting feeder travelling transporters,
printing engines possibly inverters ending finishing tray. various sheets
belonging print job must arrive correct order finisher tray, may travel
along different paths using various printing engines. colour printing engines ones
print black white, colour printing expensive. action costs operators
comparatively large, ranging 2000 200,000. Colour-printing
expensive operator, operators printing black white cost roughly half much,
operators transporting sheets relatively cheap.
Like Elevators domain, cost-sensitive FF/add heuristic perform well here,
Fc F+c failing solve many tasks cost-unaware configuration F able
solve. (Note Fc F+c perform similarly domain, large action costs outweigh distance estimates F+c .) However, contrast Elevators domain, Fc F+c
configurations result notably improved plan quality compared F. overview number
165

fiRichter & Westphal

Tasks solved 30
Avg. quality first solution
Avg. quality final solution

F
25
0.79
0.96

F+c
16
1.00
1.00

FL
24
0.93
1.00

FL+c
23
0.95
0.99

Table 7: Coverage vs. quality PARC Printer domain. Average qualities average IPC scores
calculated tasks solved configurations.

problems solved average quality first solutions shown Table 7. using landmarks, differences cost-sensitive cost-unaware configurations strongly reduced,
three landmark configurations achieving better performance F configuration.
Like Elevators, found quality relaxed plans poor. cost-unaware case,
relaxed plan transports sheets feeder finishing tray via shortest path, irrespective
whether suitable printing engine lies path. path feeder finishing tray
passes printing engine, frequently involves printing wrong image paper,
additional operators relaxed plan handle transportation feeder suitable
printing engine print correct image sheet well. cost-sensitive heuristic
used, relaxed plans furthermore become substantially longer, using many transportation operators
reach cheap printing engine. Analogously Elevators domain, increased complexity
associated longer plans (in combination bad quality relaxed plans) thus
likely reason bad performance cost-sensitive heuristic. However, landmarks
mitigate problem, numbers solved tasks Table 7 clearly show. Landmarks found
domain encompass printing correct image sheet, disjunctive
landmark denotes possible printers sheet. helps counteract tendencies
cost-sensitive FF/add heuristic transport sheets wrong printers.
summary, PARC Printer like Elevators domain cost-sensitive FF/add heuristic
performs badly, though contrast Elevators problem purely one coverage, solution quality. Even Elevators, landmarks overcome problems cost-sensitive
configurations, improving similar performance levels cost-unaware configurations.
7.4 Cyber Security
Cyber Security domain stands domain cost-sensitive configurations perform
significantly better cost-unaware counterparts, especially looking first solutions.
(Iterative search reduces gap, close completely.) domain models vulnerabilities computer networks insider attacks (Boddy, Gohde, Haigh, & Harp, 2005). task
consists gaining access sensitive information using various malware programs physically
accessing computers offices. Action costs model likelihood attack fail, i. e., risk
exposed. example, many actions office attacker, like using computer,
involve cost, whereas entering offices moderately costly, directly instructing
people install specific software high associated cost. particular, action costs used
model desire finding different methods attack setting. example, several
tasks domain differ costs associate certain operators.
Cyber Security domain, taking action costs account pays notably: Fc
F+c configurations solve 2 1 problems less, respectively, F configuration (see Table 2),
166

fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarks

IPC score first solutions
IPC score final solutions

F
20.44
23.12

FL
20.43
25.93

F+c
23.67
24.69

FL+c
26.60
27.53

Table 8: IPC scores Cyber security domain.

nevertheless result better total score. Using landmarks, cost-sensitive configurations
improved solve problems maintaining high quality solutions,
resulting even larger performance gap FLc (27.59 points) FL+c (26.60 points)
one side, FL (20.43 points) side.
plans found cost-unaware search often involve physically accessing computers
offices sending viruses email, result large cost. Lower costs
achieved complex plans making sophisticated use software. opposed Elevators
PARC Printer domains, relaxed plans Cyber Security good quality.
explains performance cost-sensitive heuristic negatively impacted longer
plans. Using iterative search improves performance FL F nearly levels
cost-sensitive counterparts (see Table 8).
7.5 Openstacks
Openstacks domain models combinatorial optimisation problem minimum maximum simultaneous open stacks (Fink & Vo, 1999; Gerevini, Haslum, Long, Saetti, & Dimopoulos, 2009),
task minimise storage space needed manufacturing facility. manufacturer receives number orders, comprising number products. one product
made time, manufacturer always produce total required quantity product
(over orders) beginning production different product. time first product order produced time products order produced,
order said open requires stack (a temporary storage space). problem consists
ordering products maximum number stacks open time minimised.
easy find solution problem (any product order solution, requiring n
stacks worst case n number orders), finding optimal solution NP-hard.
minimisation aspect modelled planning tasks via action costs, operator
opening new stacks cost 1, operators zero cost. domain
previously used IPC 2006 (Gerevini et al., 2009). earlier formulation domain
unit costs, equivalent cost formulation described above. Since number operators open stacks every plan given task, minimising plan length
equivalent minimising action costs.
noticed domain using landmarks resulted plans substantially worse quality,
compared using landmarks. particular, true first plans found, whereas
use anytime search improves results configurations similar levels. Across cost
settings, using landmark heuristic combination FF/add heuristic typically produces
plans majority orders started early, resulting large number simultaneously open stacks, whereas using FF/add heuristic leads plans products
corresponding open orders manufactured earlier, starting new orders delayed
earlier orders shipped. mainly due fact landmarks found
167

fiRichter & Westphal

5000
4500

F+c
FL+c

Expanded Nodes

4000
3500
3000
2500
2000
1500
1000
500
0
5

10

15
Tasks

20

25

30

Figure 9: Number expanded search nodes without landmarks first search iteration
(best-first search) Openstacks domain.

LAMA regarding opening stacks, means due choice action costs
domain, landmarks cost zero landmark heuristic able distinguish
plans different cost. landmarks found LAMA relate starting shipping orders
well making products.5 However, even landmarks regarding opening stacks
found, would helpful: landmarks state certain things must achieved,
certain things need achieved. Landmarks thus used limit number
open stacks. landmark orderings furthermore helpful deciding order
products, product orders possiblewhich means natural orderings exist
corresponding landmarksand product order results form wasted effort captured
reasonable landmark orderings.
mentioned above, landmarks found LAMA minimal cost zero. Therefore,
landmark heuristic fails estimate cost goal, distinguishes states via
number missing started shipped orders products. (These goal distance estimates used
directly FL, combined all-zero landmark heuristic cost estimates FL+c , tiebreakers amongst zero-cost estimates FLc , resulting relative ranking states
landmark heuristic three cases.) soon one stack open, order operator
starts achieves landmark minimal respect landmark orderings (namely
landmark stating must started), planner thus tends start orders soon possible.
landmark heuristic able take account future costs arise bad product
orderings. also problem FF/add heuristic, albeit less severe one: FF/add
heuristic accounts cost opening (exactly) one new stack whenever least one stack
needed, heuristic thus prefer states require stacks.
landmark heuristic does, however, provide good estimate goal distance. Since
landmark heuristic prefers states closer goal state regard costs, use results
5. size disjunctions limited LAMA, would always find landmark stacks avail(1)
stacks avail(2) stacks avail(n) stating least one n stacks must open point. However, landmark stating two stacks need open would require complex form landmarks
involving conjunction, LAMA cannot handle.

168

fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarks

1

Plan Quality

0.8

0.6

0.4

0.2

0

F+c
FL+c
5

10

15
Tasks

20

25

30

Figure 10: Plan quality (measured via IPC scores) without landmarks first search
iteration (best-first search) Openstacks domain.

1
50
45
40
35
Cost 30
25
20
15
10
5
0 10

Plan Quality

0.8
0.6
0.4
0.2
0

F+c
FL+c

100
Time (seconds)
5

10

15
Tasks

20

25

1000

5

30
25
20
15 Tasks
10

30

Figure 11: Effect iterative search Openstacks domain. Left: plan quality (IPC score)
best plan found within 30 minutes without landmarks. Right: evolution plan costs
landmarks (FL+c ) time.
plans stacks opened needed. reflected empirical results,
additional use landmark heuristic drastically reduces number expanded search nodes
(see Figure 9), leads higher-cost plans (see Figure 10). Without iterative search, LAMA
configuration FL+c achieves 13.85 points domain, compared 19.77 points
using landmarks (configuration F+c ).
Using iterative search, negative effect landmarks quality mitigated,
seen Figure 11. FL+c generates 21 distinct, time improved, plans per problem.
end, difference points merely 27.40 FL+c vs. 28.30 F+c . score reached
less 5 minutes iterated search per task.
Thus, Openstacks example domain landmarks detrimental solution
quality. However, using landmarks provides benefit speeding planning reducing
169

fiRichter & Westphal

number expanded nodes. allows iterative search effectively improve solution quality
given time limit final results using landmarks similar using
landmarks.
7.6 Domains Previous Competitions
Tables 9 10 show results IPC domains previous years (19982006). domains contain action costs, cost-sensitive configurations LAMA applicable
LAMA runs FL configuration. configurations examined LAMA thus FL
F, iterated search without, FL iterated search shown LAMA. Also
given results two IPC-winning systems previous years, FF Fast Downward.
FF Fast Downward, ran current versions. particular Fast Downward evolved
substantially since 2004 competition version, original causal graph heuristic
replaced better context-enhanced additive heuristic (Helmert & Geffner, 2008). correspondence authors, version Fast Downward used one featuring recent
work Richter Helmert (2009).
Table 9 shows, LAMA performs better FF Fast Downward terms
IPC 2008 criterion. true even turn landmarks iterated search LAMA,
turn options simultaneously. viewing large difference
scores iterated versus non-iterated search LAMA, note domains best known
reference results used score calculation (in contrast 2008 tasks,
reference results generated manually domain-specific solvers competition
organisers). means planner producing best solution task awarded
highest-possible score 1, even though better solutions might exist. may skew results favour
planner delivers cheaper solutions, i. e., exaggerate differences planners.
Table 10 shows LAMAs edge Fast Downward due higher-quality solutions rather
coverage, Fast Downward solves problems. Compared FF, LAMA better coverage, gap LAMA FF substantially larger gap LAMA
Fast Downward. Note F LAMA configurations roughly correspond results
published base heur earlier work (Richter et al., 2008). However, subsequent changes
code support action costs negatively affect particular Philosophers domain,
observe significant decrease coverage. also one reasons difference
coverage LAMA closely related Fast Downward system.
Comparing various experimental configurations LAMA, note use landmarks leads moderate improvements coverage solution quality. mentioned above,
iterative search significantly improves performance terms IPC 2008 score.

8. Conclusion Outlook
article, given detailed account LAMA planning system. system uses
two heuristic functions multi-heuristic state-space search: cost-sensitive version FF
heuristic, landmark heuristic guiding search towards states many subgoals
already achieved. Action costs employed heuristic functions guide search
cheap goals rather close goals, iterative search improves solution quality time
remains.
170

fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarks

Domain

FF

F. Downw.

LAMA

F

FLfirst

Ffirst

Airport (50)
Assembly (30)
Blocks (35)
Depot (22)
Driverlog (20)
Freecell (80)
Grid (5)
Gripper (20)
Logistics 1998 (35)
Logistics 2000 (28)
Miconic (150)
Miconic Full ADL (150)
Miconic Simple ADL (150)
Movie (30)
MPrime (35)
Mystery (30)
Openstacks (30)
Optical Telegraphs (48)
Pathways (30)
Philosophers (48)
Pipesworld Notank. (50)
Pipesworld Tank. (50)
PSR Small (50)
Rovers (40)
Satellite (36)
Schedule (150)
Storage (30)
TPP (30)
Trucks (30)
Zenotravel (20)
Total (1512)
PSR Large (50)
PSR Middle (50)

35
29
30
20
13
69
4
20
35
28
150
124
140
30
28
14
29
12
19
11
25
16
41
38
35
99
16
23
10
19
1162



39
28
17
13
14
66
4
15
33
25
118
95
105
30
34
18
29
4
28
48
31
28
49
35
30
132
16
26
13
17
1143
26
40

35
30
33
16
19
73
5
20
34
28
150
136
148
30
35
19
29
2
28
29
43
36
50
39
33
147
19
30
13
19
1330
28
50

33
30
34
15
20
75
5
20
33
28
143
136
150
30
33
16
30
2
27
34
42
38
50
39
31
139
20
29
16
20
1318
16
41

35
29
22
13
16
62
4
20
33
28
150
107
117
30
31
18
29
2
28
29
26
27
49
37
32
137
16
28
12
18
1185
22
37

33
29
17
12
15
65
4
18
32
28
117
107
113
30
29
14
30
2
27
34
27
28
49
37
27
129
18
27
15
18
1129
14
35

Table 9: Performance scores (rounded whole numbers) FF, Fast Downward LAMA
well experimental alternative configurations LAMA (F: without landmarks, FLfirst : without
iterated search, Ffirst : without landmarks without iterated search).

171

fiRichter & Westphal

Domain

FF

F. Downw.

LAMA

F

Airport (50)
Assembly (30)
Blocks (35)
Depot (22)
Driverlog (20)
Freecell (80)
Grid (5)
Gripper (20)
Logistics 1998 (35)
Logistics 2000 (28)
Miconic (150)
Miconic Full ADL (150)
Miconic Simple ADL (150)
Movie (30)
MPrime (35)
Mystery (30)
Openstacks (30)
Optical Telegraphs (48)
Pathways (30)
Philosophers (48)
Pipesworld Notank. (50)
Pipesworld Tank. (50)
PSR Small (50)
Rovers (40)
Satellite (36)
Schedule (150)
Storage (30)
TPP (30)
Trucks (30)
Zenotravel (20)
Total (1512)
PSR Large (50)
PSR Middle (50)

37
30
31
22
15
80
5
20
35
28
150
136
150
30
34
16
30
13
20
13
36
21
41
40
36
133
18
28
11
20
1279



40
30
35
19
20
79
5
20
35
28
150
139
150
30
35
19
30
5
29
48
43
38
50
39
35
150
18
30
15
20
1384
31
50

36
30
35
17
20
79
5
20
35
28
150
137
150
30
35
19
30
2
29
29
44
38
50
40
34
150
19
30
13
20
1354
29
50

34
30
35
16
20
78
5
20
35
28
150
138
150
30
35
16
30
2
28
34
43
40
50
40
31
144
20
30
16
20
1348
16
41

Table 10: Coverage (problems solved) FF, Fast Downward LAMA well experimental F configuration LAMA without landmarks.

172

fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarks

conducted extensive experimental study set benchmark tasks
last international planning competition, order identify much features
planner contributes performance setting planning action costs. discussed
overall results provided plausible explanations deviating behaviour special cases.
noticeable outcome experiments using cost-sensitive heuristics
produce desired outcome. particular, cost-sensitive FF/add heuristic performs significantly
worse FF/add heuristic ignores costs. due cost-sensitive heuristic solving
far fewer tasks leading little improvement solution quality tasks solve,
especially using iterated search. investigating reasons effect, found
cost-sensitive FF/add heuristic reacts strongly bad relaxed plans, i. e., particular
domains relaxed plans computed heuristic low quality costsensitive heuristic likely perform worse cost-unaware heuristic. showed
Elevators domain, action costs may also introduce local minima search space without
action costs search space FF/add heuristic would plateaus. Moreover, increased
complexity planning cheaper goal potentially away initial state may
lead worse performance.
Landmarks prove helpful context, mitigate problems costsensitive FF/add heuristic. Using landmarks, coverage cost-sensitive search improved
nearly level cost-unaware search, deteriorating solution quality. Despite
mitigating effect landmarks, however, LAMA would still achieved slightly higher
score IPC 2008 simply ignored costs, rather using cost-sensitive heuristics.
cost-unaware search, found landmarks improve coverage solution quality domains
IPCs 19982006. domains IPC 2008, landmarks improved solution quality
cost-unaware search, increase (already high) coverage.
Iterative search improves results notably experimental configurations, raising
score LAMA quarter IPC 2008 domains. Openstacks domain, could
furthermore observe synergy effect iterative search landmarks. landmarks
usually improve quality, domain lead bad plans accounting action costs.
However, speed planning planner evaluates substantially fewer states. Iterative
search effectively improves initial bad plans benefiting speed-up provided
landmarks. general, use landmarks means quickly find good solutions,
using iterative search way improve plan quality time. Overall, found domains
used IPC 2008 constitute varied benchmark set reveals various strengths weaknesses
planning system.
Building results presented article, identify several directions future work.
Firstly, results suggest research cost-sensitive heuristics needed. would
like conduct thorough analysis short-comings cost-sensitive FF/add heuristic, answer question whether might overcome. Keyder Geffner (2009)
propose method extracting better relaxed plans best supports computed costsensitive FF/add heuristic, resulting improved coverage. However, large ledge costunaware heuristic experiments suggests cost-unaware FF/add heuristic still better improved cost-sensitive heuristic Keyder Geffner. would interesting
examine degree problems experienced FF/add heuristic extend
delete-relaxation heuristics, whether heuristics based delete relaxation could
effectively adapted action costs. addition, future work could explore benefit combin173

fiRichter & Westphal

ing traditional distance estimators cost-sensitive heuristics sophisticated ways
mechanism currently used LAMA (see discussion Section 3.3.2).
Secondly, believe useful future research improve definition reasonable
orderings, eliminating problems definition Hoffmann et al. mentioned Section 4.1.
Thirdly, would like extend use landmarks system several ways. one,
current approach take account whether landmark must achieved several
times. Supporting multiple occurrences landmarks would beneficial Openstacks
domain, example, could help minimise creation stacks accounting
costs. methods exist detecting multiplicity landmarks (Porteous & Cresswell, 2002;
Zhu & Givan, 2003), crucial develop techniques deriving orderings
individual occurrences landmarks. Furthermore, would like extend LAMA support
complex landmarks like conjunctions simple formulas. addition representing
using landmarks landmark heuristic involves development new methods
detecting along corresponding orderings.

Acknowledgments
authors thank Malte Helmert, Charles Gretton, Sylvie Thiebaux Patrik Haslum well
anonymous reviewers helpful feedback earlier drafts paper.
computing resources experiments graciously provided Pompeu Fabra University. thank Hector Palacios support conducting experiments.
NICTA funded Australian Government, represented Department Broadband, Communications Digital Economy, Australian Research Council,
ICT Centre Excellence program.
work partially supported Deutsche Forschungsgemeinschaft part Transregional Collaborative Research Center SFB/TR 8 Spatial Cognition, project R4-[LogoSpace].

References
Aine, S., Chakrabarti, P. P., & Kumar, R. (2007). AWA* window constrained anytime heuristic search algorithm. Veloso, M. M. (Ed.), Proceedings 20th International Joint
Conference Artificial Intelligence (IJCAI 2007), pp. 22502255.
Bacchus, F. (2001). AIPS00 planning competition. AI Magazine, 22(3), 4756.
Backstrom, C., & Nebel, B. (1995). Complexity results SAS+ planning. Computational Intelligence, 11(4), 625655.
Boddy, M., Gohde, J., Haigh, T., & Harp, S. (2005). Course action generation cyber security
using classical planning. Biundo, S., Myers, K., & Rajan, K. (Eds.), Proceedings
Fifteenth International Conference Automated Planning Scheduling (ICAPS 2005),
pp. 1221. AAAI Press.
Bonet, B., & Geffner, H. (2001). Planning heuristic search. Artificial Intelligence, 129(1), 533.
Bryce, D., & Kambhampati, S. (2007). tutorial planning graph based reachability heuristics.
AI Magazine, 28(1), 4783.
174

fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarks

Buffet, O., & Hoffmann, J. (2010). glitters gold: Using landmarks reward shaping
FPG. Proceedings ICAPS 2010 Workshop Planning Scheduling
Uncertainty.
Chen, Y., Wah, B. W., & Hsu, C.-W. (2006). Temporal planning using subgoal partitioning
resolution SGPlan. Journal Artificial Intelligence Research, 26, 323369.
Cheng, J., & Irani, K. B. (1989). Ordering problem subgoals. Sridharan, N. S. (Ed.), Proceedings
11th International Joint Conference Artificial Intelligence (IJCAI 1989), pp. 931
936. Morgan Kaufmann.
Do, M. B., & Kambhampati, S. (2003). Sapa: scalable multi-objective heuristic metric temporal
planner. Journal Artificial Intelligence Research, 20, 155194.
Do, M. B., Ruml, W., & Zhou, R. (2008). On-line planning scheduling: application controlling modular printers. Proceedings Twenty-Third AAAI Conference Artificial
Intelligence (AAAI 2008), pp. 15191523. AAAI Press.
Edelkamp, S., & Hoffmann, J. (2004). PDDL2.2: language classical part 4th
International Planning Competition. Tech. rep. 195, Albert-Ludwigs-Universitat Freiburg,
Institut fur Informatik.
Fink, A., & Vo, S. (1999). Applications modern heuristic search methods pattern sequencing
problems. Computers Operations Research, 26(1), 1734.
Fox, M., & Long, D. (2003). PDDL2.1: extension PDDL expressing temporal planning
domains. Journal Artificial Intelligence Research, 20, 61124.
Fuentetaja, R., Borrajo, D., & Linares Lopez, C. (2009). unified view cost-based heuristics.
ICAPS 2009 Workshop Heuristics Domain-Independent Planning, pp. 7077.
Gerevini, A., Haslum, P., Long, D., Saetti, A., & Dimopoulos, Y. (2009). Deterministic planning
fifth international planning competition: PDDL3 experimental evaluation
planners. Artificial Intelligence, 173(56), 619668.
Gerevini, A., & Serina, I. (2002). LPG: planner based local search planning graphs
action costs. Ghallab, M., Hertzberg, J., & Traverso, P. (Eds.), Proceedings Sixth
International Conference Artificial Intelligence Planning Scheduling (AIPS 2002), pp.
1322. AAAI Press.
Gregory, P., Cresswell, S., Long, D., & Porteous, J. (2004). extraction disjunctive landmarks planning problems via symmetry reduction. Proceedings Fourth International Workshop Symmetry Constraint Satisfaction Problems, pp. 3441.
Hansen, E. A., & Zhou, R. (2007). Anytime heuristic search. Journal Artificial Intelligence
Research, 28, 267297.
Hansen, E. A., Zilberstein, S., & Danilchenko, V. A. (1997). Anytime heuristic search: First results.
Technical report cmpsci 97-50, University Massachusetts, Amherst.
Helmert, M. (2006). Fast Downward planning system. Journal Artificial Intelligence Research, 26, 191246.
Helmert, M. (2009). Concise finite-domain representations PDDL planning tasks. Artificial
Intelligence, 173, 503535.
175

fiRichter & Westphal

Helmert, M., Do, M., & Refanidis, I. (2008). IPC 2008, deterministic part. Web site, http://ipc.
informatik.uni-freiburg.de.
Helmert, M., & Geffner, H. (2008). Unifying causal graph additive heuristics. Rintanen,
J., Nebel, B., Beck, J. C., & Hansen, E. (Eds.), Proceedings Eighteenth International
Conference Automated Planning Scheduling (ICAPS 2008), pp. 140147. AAAI Press.
Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generation heuristic
search. Journal Artificial Intelligence Research, 14, 253302.
Hoffmann, J., Porteous, J., & Sebastia, L. (2004). Ordered landmarks planning. Journal
Artificial Intelligence Research, 22, 215278.
Irani, K. B., & Cheng, J. (1987). Subgoal ordering goal augmentation heuristic problem
solving. McDermott, J. P. (Ed.), Proceedings 10th International Joint Conference
Artificial Intelligence (IJCAI 1987), pp. 10181024. Morgan Kaufmann.
Jonsson, P., & Backstrom, C. (1998). State-variable planning structural restrictions: Algorithms complexity. Artificial Intelligence, 100(12), 125176.
Karpas, E., & Domshlak, C. (2009). Cost-optimal planning landmarks. Proceedings
21st International Joint Conference Artificial Intelligence (IJCAI 2009), pp. 17281733.
Keyder, E., & Geffner, H. (2008). Heuristics planning action costs revisited. Proceedings
18th European Conference Artificial Intelligence (ECAI 2008), pp. 588592.
Keyder, E., & Geffner, H. (2009). Trees shortest paths vs. Steiner trees: Understanding improving delete relaxation heuristics. Proceedings 21st International Joint Conference
Artificial Intelligence (IJCAI 2009), pp. 17341749.
Keyder, E., Richter, S., & Helmert, M. (2010). Sound complete landmarks and/or graphs.
Coelho, H., Studer, R., & Wooldridge, M. (Eds.), Proceedings 19th European Conference Artificial Intelligence (ECAI 2010), pp. 335340.
Koehler, J., & Hoffmann, J. (2000). reasonable forced goal orderings use
agenda-driven planning algorithm. Journal Artificial Intelligence Research, 12, 338386.
Likhachev, M., Ferguson, D., Gordon, G. J., Stentz, A., & Thrun, S. (2008). Anytime search
dynamic graphs. Artificial Intelligence, 172(14), 16131643.
Likhachev, M., Gordon, G. J., & Thrun, S. (2004). ARA*: Anytime A* provable bounds
sub-optimality. Thrun, S., Saul, L. K., & Scholkopf, B. (Eds.), Advances Neural
Information Processing Systems 16 (NIPS 2003).
Lipovetzky, N., & Geffner, H. (2009). Inference decomposition planning using causal consistent chains. Gerevini, A., Howe, A., Cesta, A., & Refanidis, I. (Eds.), Proceedings
Nineteenth International Conference Automated Planning Scheduling (ICAPS 2009).
AAAI Press.
Liu, Y., Koenig, S., & Furcy, D. (2002). Speeding calculation heuristics heuristic
search-based planning. Proceedings Eighteenth National Conference Artificial
Intelligence (AAAI 2002), pp. 484491. AAAI Press.
Pohl, I. (1970). Heuristic search viewed path finding graph. Artificial Intelligence, 1, 193
204.
176

fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarks

Porteous, J., & Cresswell, S. (2002). Extending landmarks analysis reason resources
repetition. Proceedings 21st Workshop UK Planning Scheduling Special
Interest Group (PLANSIG 02), pp. 4554.
Porteous, J., Sebastia, L., & Hoffmann, J. (2001). extraction, ordering, usage landmarks planning. Cesta, A., & Borrajo, D. (Eds.), Pre-proceedings Sixth European
Conference Planning (ECP 2001), pp. 3748, Toledo, Spain.
Richter, S., & Helmert, M. (2009). Preferred operators deferred evaluation satisficing planning. Gerevini, A., Howe, A., Cesta, A., & Refanidis, I. (Eds.), Proceedings Nineteenth International Conference Automated Planning Scheduling (ICAPS 2009), pp.
273280. AAAI Press.
Richter, S., Helmert, M., & Westphal, M. (2008). Landmarks revisited. Proceedings
Twenty-Third AAAI Conference Artificial Intelligence (AAAI 2008), pp. 975982. AAAI
Press.
Richter, S., Thayer, J. T., & Ruml, W. (2010). joy forgetting: Faster anytime search via
restarting. Brafman, R., Geffner, H., Hoffmann, J., & Kautz, H. (Eds.), Proceedings
Twentieth International Conference Automated Planning Scheduling (ICAPS 2010).
AAAI Press. appear.
Roger, G., & Helmert, M. (2010). more, merrier: Combining heuristic estimators satisficing planning. Brafman, R., Geffner, H., Hoffmann, J., & Kautz, H. (Eds.), Proceedings
Twentieth International Conference Automated Planning Scheduling (ICAPS
2010), pp. 246249. AAAI Press.
Ruml, W., & Do, M. B. (2007). Best-first utility-guided search. Veloso, M. M. (Ed.), Proceedings
20th International Joint Conference Artificial Intelligence (IJCAI 2007), pp. 2378
2384.
Sebastia, L., Onaindia, E., & Marzal, E. (2006). Decomposition planning problems. AI Communications, 19(1), 4981.
Vidal, V. (2004). lookahead strategy heuristic search planning. Zilberstein, S., Koehler, J.,
& Koenig, S. (Eds.), Proceedings Fourteenth International Conference Automated
Planning Scheduling (ICAPS 2004), pp. 150159. AAAI Press.
Zhou, R., & Hansen, E. A. (2005). Beam-stack search: Integrating backtracking beam search.
Biundo, S., Myers, K., & Rajan, K. (Eds.), Proceedings Fifteenth International
Conference Automated Planning Scheduling (ICAPS 2005), pp. 9098. AAAI Press.
Zhu, L., & Givan, R. (2003). Landmark extraction via planning graph propagation. ICAPS 2003
Doctoral Consortium, pp. 156160.

177

fiJournal Artificial Intelligence Research 39 (2010) 269 - 300

Submitted 04/10; published 09/10

Case-Based Subgoaling Real-Time Heuristic Search
Video Game Pathfinding
Vadim Bulitko

BULITKO @ UALBERTA . CA

Department Computing Science, University Alberta
Edmonton, Alberta, T6G 2E8, CANADA

Yngvi Bjornsson

YNGVI @ RU .

School Computer Science, Reykjavik University
Menntavegi 1, IS-101 Reykjavik, ICELAND

Ramon Lawrence

RAMON . LAWRENCE @ UBC . CA

Computer Science, University British Columbia Okanagan
3333 University Way, Kelowna, British Columbia, V1V 1V7, CANADA

Abstract
Real-time heuristic search algorithms satisfy constant bound amount planning per
action, independent problem size. result, scale well problems become larger.
property would make well suited video games Artificial Intelligence controlled agents must react quickly user commands agents actions. downside,
real-time search algorithms employ learning methods frequently lead poor solution quality
cause agent appear irrational re-visiting problem states repeatedly.
situation changed recently new algorithm, LRTA*, attempted eliminate learning automatically selecting subgoals. LRTA* well poised video games, except
complex memory-demanding pre-computation phase builds database
subgoals. paper, propose simpler memory-efficient way pre-computing
subgoals thereby eliminating main obstacle applying state-of-the-art real-time search methods video games. new algorithm solves number randomly chosen problems off-line,
compresses solutions series subgoals stores database. presented
novel problem on-line, queries database similar previously solved case
uses subgoals solve problem. domain pathfinding four large video game
maps, new algorithm delivers solutions eight times better using 57 times less memory
requiring 14% less pre-computation time.

1. Introduction
Heuristic search core area Artificial Intelligence (AI) research algorithms
widely used planning, game-playing agent control. paper interested realtime heuristic search algorithms satisfy constant upper bound amount planning
per action, independent problem size. property important number applications
including autonomous robots agents video games. common problem video games
searching path two locations. games, agents expected act quickly
response players commands agents actions. result, many game companies
impose constant time limit amount path planning per move (e.g., one millisecond
simultaneously moving agents).
c
2010
AI Access Foundation. rights reserved.

fiB ULITKO , B J ORNSSON , & L AWRENCE

practice time limit satisfied limiting problem size priori, scientifically
interesting approach impose time per-move limit regardless problem size.
severely limits range applicable heuristic search algorithms. instance, static search
algorithms A* (Hart, Nilsson, & Raphael, 1968), IDA* (Korf, 1985) PRA* (Sturtevant & Buro, 2005; Sturtevant, 2007), re-planning algorithms D* (Stenz, 1995), anytime
algorithms ARA* (Likhachev, Gordon, & Thrun, 2004) anytime re-planning algorithms
AD* (Likhachev, Ferguson, Gordon, Stentz, & Thrun, 2005) cannot guarantee constant
bound planning time per action. produce complete, possibly abstract, solution first action taken. problem increases size, planning
time inevitably increase, exceeding priori finite upper bound.
Real-time search addresses problem fundamentally different way. Instead computing
complete, possibly abstract, solution first action taken, real-time search algorithms
compute (or plan) first actions agent take. usually done conducting
lookahead search fixed depth (also known search horizon, search depth lookahead
depth) around agents current state using heuristic (i.e., estimate remaining
travel cost) select next actions. actions taken planning-execution
cycle repeats (Korf, 1990). Since goal state seen local searches, agent
runs risks selecting suboptimal actions. address problem, real-time heuristic search
algorithms update (or learn) heuristic function time.
learning process precluded real-time heuristic search agents widely deployed pathfinding video games. problem agents tend scrub (i.e., repeatedly re-visit) state space due need fill heuristic depressions (Ishida, 1992). result,
solution quality quite low and, visually, scrubbing behavior perceived irrational.
Since seminal work LRTA* (Korf, 1990), researchers attempted speed
learning process. briefly describe efforts related work section. Here, note
various approaches brought improvements, breakthrough performance
achieved virtually eliminating learning process LRTA* (Bulitko, Lustrek, Schaeffer,
Bjornsson, & Sigmundarson, 2008). done computing heuristic respect
near-by subgoal distant goal. Offline, LRTA* constructs high-level graph regions using
state abstractions, calculates optimal paths region pairs, stores subgoals
states paths cross region boundaries. online search, LRTA* consults
database find next subgoal respect current goal regions. Since heuristic
functions usually relax problem (e.g., Euclidean distance heuristic ignores obstacles
map), tend accurate closer goal. result, heuristic function respect
near-by goal tends accurate and, therefore, requires less adjustment (i.e., learning).
Consequently, solution quality improved scrubbing behavior reduced.
paper, adapt idea subgoaling make following four contributions. First,
simplify pre-processing step LRTA*. Instead using state abstraction select subgoals, employ nearest-neighbour algorithm database solved cases. Second, introduce idea compressing solution path series subgoals easily
reached previous one. so, use hill-climbing proxy notion easy
reachability LRTA*. Third, employ kd-trees order access case base effectively.
Finally, evaluate new algorithm empirically large-scale problem spaces.
new algorithm called k Nearest Neighbor LRTA* (or kNN LRTA*) and, rest
paper, set k = 1. paper extends previous conference publication (Bulitko & Bjornsson,
270

fiC ASE -BASED UBGOALING R EAL -T IME H EURISTIC EARCH

2009) following ways. store multiple goals per path reduce number database accesses use kd-trees speed database access. Additionally, make optimizations
on-line component kNN LRTA*: evaluating small number similar database
entries, interrupting LRTA* starts learning excessively engaging start end path optimizations. empirical evaluation side, use native multi-million state static video game
maps compare algorithm newly published state-of-the-art non-learning real-time search
algorithm (Bjornsson, Bulitko, & Sturtevant, 2009).
rest paper organized follows. Sections 2 3 formulate problem
real-time heuristic search show core LRTA* algorithm extended subgoal
selection. Section 4 analyzes related research. Section 5 provides intuition new algorithm
following details pseudocode Section 6. Section 7 give theoretical analysis and,
Section 8, empirically evaluate algorithm domain pathfinding. Section 9 summarizes
empirical results. conclude discussion current shortcomings future work.

2. Problem Formulation
define heuristic search problem directed graph containing finite set states (vertices)
weighted edges, single state designated goal state. every time step, search
agent single current state, vertex search graph, takes action (or makes move)
traversing out-edge current state. traversing edge states s1 s2
agent changes current state s1 s2 . say state visited agent
agents current state point time. usual field real-time
heuristic search, assume path planning happens moves (i.e., agent
think traversing edge). plan move - travel edge loop continues agent
arrives goal state, thereby solving problem.
edge positive cost associated it. total cost edges traversed agent
start state arrives goal state called solution cost. require algorithms
complete (i.e., produce path start goal finite amount time path exists).
order guarantee completeness real-time heuristic search make assumption safe
explorability search problems. Specifically, costs finite states s1 , s2 , s3 ,
path s1 s2 path s1 s3 also path
s2 s3 .
Formally, algorithms discussed paper applicable heuristic search problem. keep presentation focused intuitive well afford large-scale empirical
evaluation, use particular type heuristic search problem, pathfinding grid worlds,
rest paper. discuss applicability new methods suggest heuristic
search general planning problems Section 11.
video-game map settings, states vacant square grid cells. cell connected four
cardinally (i.e., west, north, east, south) four diagonally neighboring cells. Outbound edges
vertex moves available corresponding cell rest paper use
terms action move interchangeably. edge costs defined 1 cardinal moves 1.4
diagonal moves.1
agent plans next action considering states local search space surrounding
current position. heuristic function (or simply heuristic) estimates (remaining) travel cost
1. use 1.4 instead Euclidean


2 avoid errors floating point computations.

271

fiB ULITKO , B J ORNSSON , & L AWRENCE

state goal. used agent rank available actions select
promising one. paper consider admissible consistent heuristic functions
overestimate actual remaining cost goal whose difference values two
states exceed cost optimal path states. paper use octile
distance minimum cumulative edge cost two vertices ignoring map obstacles
heuristic. heuristic admissible consistent uses 1 1.4 edge costs. agent
modify heuristic function state avoid getting stuck local minima heuristic
function, well improve action selection experience.
defining property real-time heuristic search amount planning agent
per action upper bound depend total number states problem
space. Fast planning preferred guarantees agents quick reaction new goal specification. measure mean planning time per action terms CPU time. use number
states expanded CPU-independent measure time algorithms evaluated
paper frequently perform time-consuming operations expanding states. Also note
total planning time per problem important non-real-time search, irrelevant video
game pathfinding compute entire path outright.
second performance measure study sub-optimality defined ratio
lution cost
found agent (c) minimum solution cost (c ) minus one times 100%:
c
c 1 100. illustrate, suboptimality 0% indicates optimal path suboptimality
50% indicates path 1.5 times costly optimal path.

3. LRTA*: Core Algorithm
core real-time heuristic search algorithms algorithm called Learning Real-Time
A* (LRTA*) (Korf, 1990). shown Figure 1 operates follows. long goal state
sglobal goal reached, algorithm interleaves planning execution lines 4 7.
generalized version added new step line 3 selecting goal sgoal (the original algorithm
uses sglobal goal times). describe details subgoal selection later paper.
line 4, cost-limited breadth-first search duplicate detection used find frontier states
cost gmax away current state s. frontier state s, value sum
cost shortest path s, denoted g(s, s), estimated cost shortest path
sgoal (i.e., heuristic value h(s, sgoal )). state minimizes sum identified s0
line 5. Ties broken favour higher g values. Remaining ties broken fixed order.
heuristic value current state updated line 6 (we keep separate heuristic tables
different goals never decrease heuristics). Finally, take one step towards
promising frontier state s0 line 7.
LRTA* special case value iteration real-time dynamic programming (Barto, Bradtke,
& Singh, 1995) problem prevented use video game pathfinding. Specifically, updates single heuristic value per move basis heuristic values near-by states.
means initial heuristic values overly optimistic (i.e., low), LRTA*
frequently re-visit states multiple times, time making updates small magnitude.
behavior known scrubbing2 appears highly irrational observer.
2. term coined Nathan Sturtevant.

272

fiC ASE -BASED UBGOALING R EAL -T IME H EURISTIC EARCH

LRTA*(sstart , sglobal goal , gmax )
1
2
3
4
5
6
7
8

sstart
6= sglobal goal
subgoal selected current subgoal reached select (new) subgoal sgoal
generate successor states gmax cost, generating frontier
find frontier state s0 lowest g(s, s0 ) + h(s0 , sgoal )
update h(s, sgoal ) g(s, s0 ) + h(s0 , sgoal )
change one step towards s0
end
Figure 1: LRTA* algorithm dynamic subgoal selection.

4. Related Research
Since seminal work LRTA* described previous section, researchers attempted
speed learning process. resulting algorithms described following
four attributes:
local search space set states whose heuristic values accessed planning
stage. two common choices full-width limited-depth lookahead (Korf, 1990; Shimbo &
Ishida, 2003; Shue & Zamani, 1993; Shue, Li, & Zamani, 2001; Furcy & Koenig, 2000; Hernandez
& Meseguer, 2005a, 2005b; Sigmundarson & Bjornsson, 2006; Rayner, Davison, Bulitko, Anderson, & Lu, 2007) A*-shaped lookahead (Koenig, 2004; Koenig & Likhachev, 2006). Additional choices decision-theoretic based shaping (Russell & Wefald, 1991) dynamic lookahead depth-selection (Bulitko, 2004; Lustrek & Bulitko, 2006). Finally, searching smaller,
abstracted state used well (Bulitko, Sturtevant, Lu, & Yau, 2007).
local learning space set states whose heuristic values updated. Common
choices are: current state (Korf, 1990; Shimbo & Ishida, 2003; Shue & Zamani, 1993; Shue
et al., 2001; Furcy & Koenig, 2000; Bulitko, 2004), states within local search space (Koenig,
2004; Koenig & Likhachev, 2006) previously visited states neighbors (Hernandez &
Meseguer, 2005a, 2005b; Sigmundarson & Bjornsson, 2006; Rayner et al., 2007).
learning rule used update heuristic values states learning space.
common choices mini-min (Korf, 1990; Shue & Zamani, 1993; Shue et al., 2001;
Hernandez & Meseguer, 2005a, 2005b; Sigmundarson & Bjornsson, 2006; Rayner et al., 2007),
weighted versions (Shimbo & Ishida, 2003), max mins (Bulitko, 2004), modified Dijkstras
algorithm (Koenig, 2004), updates respect shortest path current state
best-looking state frontier local search space (Koenig & Likhachev, 2006). Additionally, several algorithms learn one heuristic function (Russell & Wefald, 1991; Furcy &
Koenig, 2000; Shimbo & Ishida, 2003).
control strategy decides move following planning learning phases. Commonly used strategies include: first move optimal path promising frontier
state (Korf, 1990; Furcy & Koenig, 2000; Hernandez & Meseguer, 2005a, 2005b), entire
path (Bulitko, 2004), backtracking moves (Shue & Zamani, 1993; Shue et al., 2001; Bulitko,
2004; Sigmundarson & Bjornsson, 2006).
Given multitude proposed algorithms, unification efforts undertaken. particular, Bulitko Lee (2006) suggested framework, called Learning Real Time Search (LRTS),
273

fiB ULITKO , B J ORNSSON , & L AWRENCE

combine extend LRTA* (Korf, 1990), weighted LRTA* (Shimbo & Ishida, 2003), SLA* (Shue
& Zamani, 1993), SLA*T (Shue et al., 2001), large extent, -Trap (Bulitko, 2004).
dimensions described above, LRTS operates follows. uses full-width fixed-depth local search
space transposition tables prune duplicate states. LRTS uses max mins learning rule
update heuristic value current state (its local learning space). control strategy moves
agent promising frontier state cumulative volume heuristic function updates
trial user-specified quota backtracks previous state otherwise.
approaches listed brought various improvements, breakthrough performance came form subgoaling. Since commonly used heuristics simplify problem
hand (e.g., octile distance grid-world pathfinding ignores obstacles), using LRTA*
near-by subgoals effectively increases heuristic quality thus reduces amount learning.
Although general planning goal often represented conjunction simple subgoals,
best knowledge, real-time heuristic search algorithm implement subgoaling
LRTA* (Bulitko, Bjornsson, Lustrek, Schaeffer, & Sigmundarson, 2007; Bulitko et al., 2008).
pre-processing phase, LRTA* uses clique abstraction Sturtevant Buro (2005)
create smaller search graph. clique abstraction collapses set fully connected states
single abstract state applied iteratively compute progressively smaller graphs.
example, 2-level abstraction applies clique abstraction graph already abstracted once. Similarly, a-level abstraction applies clique abstraction times. assume
abstraction reduces graph constant factor , a-level abstract graph would contain times fewer states original graph. abstraction technique effect partitions
map number regions, region corresponding single abstract state.
every pair distinct abstract states, LRTA* computes optimal path corresponding
representative states (e.g., centroids regions) original non-abstracted space. path
followed exits region corresponding start abstract state. entry state
next region recorded subgoal pair abstract states. pre-processing step
finished, LRTA* runs LRTA* given problem selects subgoal recorded current
goal regions. off-line on-line steps illustrated Figure 2.
underlying intuition reaching entry-to-the-next-region state requires LRTA*
navigate within single region is, therefore, easy default heuristic function. result,
LRTA* would rarely need adjust heuristic thereby virtually eliminating costly learning
process resulting scrubbing.
three key problems LRTA*. First, due fact entry states (i.e., subgoals) computed stored pair distinct regions, number regions
kept relatively small. LRTA* accomplished applying clique abstraction
procedure multiple times regions become progressively larger fewer number.
side effect regions longer cliques may, fact, quite complex themselves.
result, LRTA* may encounter heuristic depressions within region (e.g., would actually
happen LRTA* tries go E right diagram Figure 2). Second, state
original space needs assigned region. Since regions irregular shape, explicit
membership records must maintained. may require much additional memory storing
original grid-based map. Third, clique abstraction non-trivial process puts extra
programming burden practitioners (e.g., game developers).
Another recent high-performance real-time search algorithm Time-Bounded A* (TBA*)
Bjornsson et al. (2009), time-bounded variant classic A*. expands states A*
274

fiC ASE -BASED UBGOALING R EAL -T IME H EURISTIC EARCH

2

2

2

2

2

2

7

7

2

7
7

2

5

5

5

5

5

7

2

1

1

1

1

5

7

2

1

1

5

7

2

1

1

1

3

6

2

1

1

3

3

6

2
4

G

3
4

4

4

4

6

C2

C1

E



E

6
6

6

6

Figure 2: Example LRTA* operation. Left: off-line, map partitioned seven regions
(or abstract states). vacant cell labeled region number. Center: off-line,
optimal path centroids two regions (C1 C2 ) computed entry
state next region (E) recorded subgoal pair regions. Right: online, agent intends travel G, determines corresponding regions
sets pre-computed entry state E subgoal.

fashion using closed list open list, away original start state, towards goal
goal state expanded. However, unlike A* plans complete path committing
first action, TBA* time-slices planning interrupting search periodically acts. Initially,
complete path goal known, agent takes action moves towards
promising state open list. subsequent time slice alternative promising path
formed agent path, backtracks steps necessary. interleaving
planning, acting, backtracking done way real-time behavior completeness ensured. size time-slice given parameter algorithm, using
metric number states allowed expand planning must interrupted. Within
single time-slice, however, operations state expansions backtracing closed list (to
form path promising state open list) must performed. cost latter
type operations thus converted state expansion equivalence (typically several backtracing
steps performed computational cost single state expansion). key aspect
TBA* LRTA*-based algorithms retains closed open lists planning steps.
Thus, planning step start planning scratch, continues open
closed lists previous planning step. Also, need update heuristics online
ensure completeness, require precomputation phase. lack precomputation
certainly strong side, negatives include high suboptimality amount time per move
low high on-line space complexity due storing closed open lists.
research related work realm non-real-time heuristic search pattern
databases widely used store pre-calculated distance information abstractions
original (ground) search space (Culberson & Schaeffer, 1998). recent approach using precalculated state-space information calculate true distances selected state pairs
use whenever possible make distance estimates search guidance heuristic
h informative. Two enhanced heuristics differential heuristic (Cazenave, 2006;
Sturtevant, Felner, Barrer, Schaeffer, & Burch, 2009) canonical heuristic (Sturtevant et al.,
275

fiB ULITKO , B J ORNSSON , & L AWRENCE

2009). former case, true distance pre-calculated states small subset
states S, so-called canonical states. on-line search heuristic distance
two arbitrary states b calculated maximum h(a, b) = |d(a, s) d(b, s)|
canonical states S. latter case, state state space true distance
closest canonical state pre-calculated stored true distance
pairs canonical states. search, heuristic distance two states
b calculated h(a, b) = d(C(a), C(b)) d(a, C(a)) d(b, C(b)) C(s) returns
closest canonical state s. heuristics may return lower distance estimate
unmodified heuristic, practice one chooses maximum two. idea similar
canonical heuristic proposed earlier specialized context, heuristic function
improved pre-calculating true distances several strategically chosen passageways
game map (Bjornsson & Halldorsson, 2006). heuristics used real-time search.
large volume work case-based planning (e.g., Nebel & Koehler, 1995).
includes path planning, case-based approaches used augment heuristic search
tasks route selection road maps mobile robot navigation. approaches typically pre-compute store paths, opposed distances, selected states, use
model solutions related pathfinding tasks case-based reasoning (CBR) fashion. One
early works combining search case-based reasoning pathfinding road maps
done within planning learning system P RODIGY (Carbonell, Knoblock, & Minton, 1990),
goal generating near-optimal routes autonomous navigation vehicle trying
achieve multiple goals driving city (Haigh & Veloso, 1993). authors acknowledge
benefits approach situation necessary interleave planning execution. Subsequent work case-based route selection though mainly focused augmenting
non-interleaving path-planning algorithms, A* Dijkstra, focus work
best build case base, example, identify, compute, store paths critical
junctions many paths pass (Anwar & Yoshida, 2001; Weng, Wei, Qu, & Cai, 2009).
mobile robot navigation, two heuristic search algorithms working ground space using
CBR-based approach introduced Branting Aha (1995). simpler one, looking
path states b, searches pre-calculated case base path contains
b. match found best path returned, otherwise regular A* search invoked
calculate solution path. second, elaborate, algorithm searches case base
match fashion first, none found, adapts existing case fit new
task. done using A* join b existing path case base new
overall distance minimized. still ongoing research area, example, work
storing case base graph structure called case-graph gradually builds waypoint-like
navigation network (Hodal & Dvorak, 2008). Note many existing algorithms
real-time generate modify complete plans.

5. Intuition kNN LRTA*
design kNN LRTA* address three shortcomings LRTA* listed earlier.
so, identify two key aspects subgoal-based real-time heuristic search. First, need
define set subgoals would efficient compute store off-line. Second, need
define way agent find subgoal relevant current problem on-line.
276

fiC ASE -BASED UBGOALING R EAL -T IME H EURISTIC EARCH

Intuitively, LRTA*-controlled agent state going state sgoal best
subgoal state sideal subgoal resides optimal path sgoal reached
LRTA* along optimal path state re-visitation. Given multiple optimal
paths two states, unclear computationally efficiently detect LRTA* agents
deviation optimal path immediately occurs.
positive side, detecting state re-visitation done computationally efficiently running simple greedy hill-climbing agent. based fact hill-climbing agent
reach state b state without encountering local minimum plateau heuristic
LRTA* agent travel b without state re-visitation (Theorem 5). Thus, propose
efficiently computable approximation sideal subgoal . Namely, define subgoal pair
states sgoal state skNN LRTA* subgoal farthest along optimal path sgoal
reached simple hill-climbing agent (defined rigorously following section).
summary, select subgoals eliminate scrubbing (Theorem 5) guarantee
LRTA* agent keeps optimal path subgoals (Theorem 6). practice, however,
tiny fraction subgoals reached hill-climbing agent suboptimally even
suboptimality minor.
approximation ideal subgoal allows us effectively compute series subgoals
given pair start goal states. Intuitively, compress optimal path series
key states reached predecessor without scrubbing.
compression allows us save large amount memory without much impact time-per-move.
Indeed, hill-climbing one key states next requires inspecting immediate
neighbors current state selecting one greedily. re-visitation-free reachability
one subgoal another addresses first key shortcoming LRTA* agent may
get trapped within single complex region thus unable reach prescribed subgoal.
However, still infeasible compute compress optimal path every
two distinct states original search space. solve problem compressing
pre-determined fixed number optimal paths random states off-line. on-line kNN
LRTA*, tasked going sgoal , retrieves similar compressed path
database uses associated subgoals. define (dis-)similarity database path
agents current situation maximum heuristic distances paths beginning sgoal paths end. use maximum would like ends
path heuristically close agents current state goal respectively. Indeed,
heuristic distance ignores walls thus large heuristic distance paths either end tends
make end hill-climbing unreachable.
Note high similarity (i.e., distances low) guarantee path
useful kNN LRTA* agent. instance, beginning path heuristically
close agent side long wall, making unreachable without lot
learning associated scrubbing. address problem complement fast-tocompute similarity metric computationally demanding move-limited reachability checks
detailed below.
illustrate intuition simple example. Figure 3 shows kNN LRTA* operation offline. map, two random start goal pairs selected optimal paths computed
them. path compressed series subgoals subgoals
reached previous one via hill-climbing. path S1 G1 compressed
two subgoals path compressed single subgoal.
277

fiB ULITKO , B J ORNSSON , & L AWRENCE

G1

G2

G1

G2

G1

G2

1

S1

S1

S1
S2

S2

S2

2

1

Figure 3: Example kNN LRTA* off-line operation. Left: two subgoals (start,goal) pairs
chosen: (S1 , G1 ) (S2 , G2 ). Center: optimal paths computed
running A*. Right: two paths compressed total three subgoals.

database two records built, kNN LRTA* tasked solving problem
on-line. Figure 4 tasked going state state G. database scanned
similarity (S, G) two database records determined. records
sorted similarity: (S1 , G1 ) followed (S2 , G2 ). agent runs reachability checks:
Si Gi G runs database indices order record similarity.
example, S1 found unreachable hill-climbing thus record (S1 , G1 )
discarded. second record passes hill-climbing checks agent tasked going
first subgoal (shown 1 figure).
G

G

G

G1

G2



G1

G2





S1

S1
S2

S2

1

Figure 4: Example kNN LRTA* on-line operation. Left: agent intends travel
G. Center: similarity (S, G) (S1 , G1 ) (S2 , G2 ) computed. Right:
(S1 , G1 ) similar (S, G) (S2 , G2 ), beginning S1 reachable
via hill-climbing hence record (S2 , G2 ) selected agent tasked
going subgoal 1.
similarity plus hill-climbing check approach makes state abstraction LRTA* unnecessary, thereby addressing two key shortcomings: high memory requirements
complex pre-computation phase.
278

fiC ASE -BASED UBGOALING R EAL -T IME H EURISTIC EARCH

6. kNN LRTA* Detail
section flesh kNN LRTA* enough detail researchers implement it.
start basic version describe several significant enhancements.
6.1 Basic kNN LRTA*
kNN LRTA* consists two parts: database pre-computation (off-line) LRTA* dynamically selected subgoals (on-line). Pseudocode off-line part presented Figure 5.
top-level function computeSubgoals takes user-controlled parameter N search graph
(e.g., grid-based map pathfinding) builds subgoal database N compressed paths.
path generated line 4 start goal states randomly chosen line 3.
path exist short (line 5), discard re-generate start goal
states. compression takes place inthe function compress, returns sequence states
np
, sgoal np 0 number subgoals (line 6).
p = sstart , s1subgoal , . . . , ssubgoal
sequence p compressed representation path p forms single record subgoal
database (line 7).
subgoal database computeSubgoals(N, G)
1 subgoal database
2 n = 1, . . . , N
3
generate random pair states (sstart , sgoal )
4
compute optimal path p sstart sgoal A*
5
p = |p| < 3 go step 3 end
6
p compress(p)
7
add p subgoal database
8 end
Figure 5: kNN LRTA* off-line: building subgoal database.
Pseudocode function compress found Figure 6. takes path p = (sstart , . . . , sgoal ) =
(s1 , . . . , st ) argument returns subset states reachable via
hill-climbing (and thus without scrubbing). code builds sequence indices states
put subgoals. long path exhausted (line 2), next
candidate subgoal defined index line 3. Note state index = end()+1
always hill-climbing reachable state index end() two states
immediate neighbours. run binary search defined scope indices [l, r] lines
4 5. middle scope calculated line 7 hill-climbing reachability
latest computed subgoal send() checked line 8. middle indeed hill-climbing reachable
scope moved upper half (line 10) candidate subgoal updated (line 9).
Otherwise, scope binary search moved lower half line 12. binary
search completed, candidate subgoal added line 15.3 convert sequence
indices sequence states line 17.
function reachable(sa , sb ) checks hill-climbing agent reach state sb
state sa . pseudocode found Figure 7. start climbing state sa (line 1). long
3. use parentheses set operations indicate ordered set.

279

fiB ULITKO , B J ORNSSON , & L AWRENCE

compress((s1 , . . . , st ))
1 (1)
2 6
3
end() + 1
4
l i+1
5
rt
6
l r
7
b l+r
2 c
8
reachable(send() , sm )
9
im
10
l m+1
11
else
12
r m1
13
end
14
end
15
(i)
16 end
17
Figure 6: kNN LRTA* off-line: compressing path sequence subgoals.
reachable(sa , sb )
1 sa
2 6= sb
3
generate immediate successor states s, generating frontier
4
h(s) mins00 frontier (h(s00 )) break
5
find frontier state s0 lowest g(s, s0 ) + h(s0 , sb )
6
s0
7 end
8 (s = sb )
Figure 7: Checking one state reachable another. function called on-line,
fixed cap put number iterations loop.
goal reached (line 2), generate immediate successors current state (line 3)
check local heuristic minimum plateau (line 4). terminate climb
declare sb hill-climbing reachable sa . Otherwise climb towards frontier state
lowest g + h value (lines 5 6). use g + h instead h make move selection
correspond LRTA*. Additionally, ties broken exactly way
LRTA* algorithm Figure 1. Note whenever function reachable called
on-line phase, impose fixed cutoff number steps hill-climbing allowed travel.
done place upper bound time complexity reachability check independent
number states search graph, required real-time operation.
on-line phase kNN LRTA*, run LRTA* per Figure 1. Dynamic subgoal selection
(line 3) done per pseudocode Figure 8. Given start goal state, scan subgoal
280

fiC ASE -BASED UBGOALING R EAL -T IME H EURISTIC EARCH

database and, record, compute heuristic distance start state records
first state well heuristic distance goal state records last state. mentioned earlier, define (dis-)similarity problem record maximum
two heuristic distances. done similar records start end
close agents current position goal terms heuristic distance.
database records sorted similarity agents current global goal states
(line 1) and, starting similar record, check start end hill-climbing
reachable agents current state agents global goal respectively (line 4). either
reachability check fails, go onto next record. Otherwise, stop database search (line
6). exhaust database find reachable record, resort global goal (line 9).
record found, subgoals fed one one LRTA* line 3 Figure 1.
intuition similarity metric uses heuristic distance and, therefore, ignores
constraints problem (e.g., walls grid-based pathfinding). Thus, database record
high similarity value may relevant agents situation start goal may
side wall means subgoals reachable LRTA* without
scrubbing therefore useless agent.
r selectSubgoals(s, sglobal goal )
1
2
3
4
5
6
7
8
9

(r1 , . . . , rN ) database records least similar
= 1, . . . , N
retrieve ri = (sstart , . . . , send )
reachable(s, sstart ) reachable(send , sglobal goal )
r ri
return
end
end

r s, sglobal goal
Figure 8: kNN LRTA* on-line: selecting subgoals.

6.2 Enhanced kNN LRTA*
presented basic kNN LRTA* algorithm. section introduce six enhancements.
First, selecting database record function selectSubgoals, check global
goal reachable agents current state. done calling function reachable.
global goal indeed reachable via move-limited hill-climbing set agents goal
look subgoal. Otherwise, turn database subgoals.
Second, selected database record routine selectSubgoals, run reachability
check agents current state first subgoal record. first subgoal
reachable set goal LRTA*. Otherwise, set LRTA* go start state
record already checked reachable within function selectSubgoals.
Third, LRTA* reaches last subgoal (i.e., state record immediately prior
end record), checks global goal reachable it. so, global goal used
next subgoal. Otherwise, agent heads end record reach
global goal guaranteed record selection criteria.
281

fiB ULITKO , B J ORNSSON , & L AWRENCE

first three enhancements addresses trade-off path optimality planning
time per move. Specifically, calling function reachable, real-time, increases kNN LRTA*
planning time per move but, time, leads potentially shorter solution due better
subgoal selection. Recall function reachable satisfies real-time operation constraint
place priori limit number moves take.
Reachability checks constitute substantial portion kNN LRTA*s planning time per move.
substantial contributor accessing record database computing record similarity.
basic algorithm described always computes similarity database records and,
worst case, runs reachability checks records function selectSubgoals.
depend search graph size thus real-time, still speed follows.
fourth enhancement run reachability checks fixed number similar
records. done simply substituting total number database records N
fixed constant N line 2 Figure 8. intuition fairly similar records
worth checking reachability.
N enhancement substantially reduce amount planning time taken
reachability checks. However, similarity still computed records database
(line 1 Figure 8). fifth enhancement speeds step employing kd-trees instead
linear database scan. kd-tree (Moore, 1991) spatial tree index sublinear time
complexity nearest-neighbor searches. Specifically, kd-tree indexes start end states
subgoal database records. tree node thus four-tuple (xstart , ystart , xend , yend ). index
works dividing search space along dimension level tree. search space
divided xstart root node tree, ystart next level down, xend next level,
yend next, cycle repeats. example, root node (4, 5, 8, 9),
start state coordinates (4, 5) end state coordinates (8, 9). Further, nodes
left subtree xstart 4, nodes right subtree xstart > 4.
illustrate, consider tree Figure 9 subgoal record whose start state (8, 4)
whose goal state (4, 9). records represented kd-tree node (8, 4, 4, 9).
right subtree root xstart = 8 greater roots value 4. left
subtree next node value 4 ystart less nodes value 5. third
level, left subtree value 4 xend less 6. Finally, right subtree
parent level four value yend = 9 greater 8 parent.
4,5,8,9
startX <= 4

startY <= 7

7,5,6,4
startY > 7

4,5,4,5
endX <= 4

3,2,2,1

startY <= 5

2,8,3,3
endX > 4

1,6,8,3

divide start xcoordinate

startX > 4

3,7,6,6

endX <= 3

1,9,2,6

8,3,6,4
endX > 3

5,9,4,6

endX <= 6

3,8,5,4

endX > 6

6,2,5,8
endY <= 8

8,3,3,7

divide start ycoordinate

startY > 5

9,1,9,3
endY > 8

endX <= 4

9,9,4,4

endX > 4

divide end xcoordinate

9,9,5,5
divide end ycoordinate

8,4,4,9

Figure 9: kd-tree database access.
structure allows nearest-neighbors computed without searching paths tree
index eliminating subtrees based distance. instance, search currently
best records found far, encounters node tree guaranteed
282

fiC ASE -BASED UBGOALING R EAL -T IME H EURISTIC EARCH

nodes farther away records search target, subtree searched.
nearest-neighbor search algorithm explained Moore (1991). Note kd-tree index
works regular grid pathfinding problems necessarily heuristic search problems.
instance, high-cost edges connecting states similar coordinates low-cost edges connecting
states distant coordinates would present problem kd-tree index.
Given subgoal database, build kd-tree index off-line store together
database. On-line, use kd-tree identify records relevant agents current start
goal states (line 1 Figure 8). compute similarity metric records.
sixth enhancement deals case kNN LRTA* unable find subgoal
resorts global goal. happens function selectSubgoals (line 9 Figure 8). failure
find subgoal caused none similar records passing reachability checks.
resort global goal indicates insufficient database coverage current area
space start goal state pairs. Given records compressed optimal paths
randomly generated start goal states, database coverage likely uneven. Thus resorting
global goal permanent step agent traveling global goal likely
enter area covered database sooner later. point, record selection process
repeated, hopefully resulting database hit. implement intuition kNN LRTA*
imposing travel quota LRTA* function selectSubgoals fails find reachable record.
quota computed heuristic distance agents current state global goal
multiplied fixed constant greater 1. agent exhausts quota, selectSubgoals
called again. fails find reachable subgoal second time row, quota
set infinity leading interruptions. necessary guarantee completeness.
Additionally, interrupting LRTA* indefinitely many times increases average planning time per move
due subgoal selection attempts.
also experimented idea database record form (s1 , . . . , sn )
used entirety. Indeed, fragments (i.e., (si , . . . , sj ) 1 < j n)
used within kNN LRTA* fashion entire record. implemented
idea running kd-tree search fragments database records addition whole
records. results disappointing several ways. First, kd-tree algorithm becomes
complex kd-tree query time increases. Second, record fragments crowd hits
kd-tree returns similarity metric computed. practice means
kd-tree returns similar hill-climbing unreachable records and, thus, causes kNN LRTA*
resort global goal often. fixed increasing accordingly
similarity computation hill-climbing checks become costly.

7. Theoretical Analysis
section prove completeness algorithm analyze complexity.
7.1 Off-line Complexity
Off-line kNN LRTA* generates N records space states. Let diameter space (i.e.,
number states along longest possible shortest path two states) .
Theorem 1 Off-line worst-case space complexity kNN LRTA* O(N + S).
283

fiB ULITKO , B J ORNSSON , & L AWRENCE

Proof. worst case optimal path kNN LRTA* generates randomly selected start
goal long minimally compressible. Minimum compression means every state
path stored. N records property total amount database storage
O(N ). Additionally, A* run record worst-case space complexity S. 2

Theorem 2 Off-line worst-case time complexity kNN LRTA* O(N log + N log N ).
Proof. kNN LRTA* runs A* compute optimal path N pairs randomly generated start
goal states. consistent heuristic constraints problem formulation,
A*s worst case time complexity O(S log S). Since S, A*s complexity dominates
worst-case time complexity function compress O(S log ). Additionally, building
kd-tree takes O(N log N ). 2
7.2 On-line Complexity
section assume LRTA* generates immediate neighbors current state
move. grid pathfinding easily accomplished setting gmax = 1.4.
generally, guaranteed substituting line 4 Figure 1 generate immediate
successor states s.
Theorem 3 kNN LRTA*s on-line worst-case space complexity O(dmax + S) dmax
maximum out-degree vertex total number states.
Proof. open list kNN LRTA* maximum number immediate neighbors
state (i.e., dmax ). LRTA* learns, store updated heuristic values,
S. Hence overall space complexity O(dmax + S). Note grid pathfinding
dmax dmax increase map size, thereby reducing upper bound O(S). 2

Theorem 4 kNN LRTA*s per-move worst-case time complexity O(dmax +N +M log )
dmax maximum out-degree vertex, N total number records database
number candidate records selected kd-tree.
Proof. move kNN LRTA* invokes LRTA* generates dmax states.
moves, kNN LRTA* additionally searches database find appropriate record. database
search starts querying kd-tree records (M N ). balanced kd-trees
time complexity sub-linear N , worst case time step still O(N ). sort
records similarity O(M log ) time. Finally, move-limited hill-climbing checks
run records, collectively taking O(M ) time. Thus, overall per-move time
complexity O(dmax + N + log ) worst case. 2
Note bound depend and, therefore, makes kNN LRTA* real-time
definition. Also note grid pathfinding dmax N N makes kNN LRTA*s
per move time complexity simply O(N ).
284

fiC ASE -BASED UBGOALING R EAL -T IME H EURISTIC EARCH

7.3 Completeness
Theorem 5 two states s1 s2 , s2 hill-climbing reachable s1 LRTA*
agent starting s1 reach s2 without state re-visitation (i.e., scrubbing).
Proof. First, show hill-climbing agent (as specified function reachable
Figure 7) reach s2 s1 never re-visit states way. Suppose,
case. exists state s3 re-visited hill-climbing agent. ties
broken fixed order, hill-climbing agent arrives s3 second time,
continue following path first visit will, therefore, arrive s3
third time on. words, infinite loop re-visiting s3 repeatedly.
contradicts fact able reach s2 .
conclude path s1 s2 followed hill-climbing agent
free repeated states. show LRTA* agent starting s1 follow exactly
path hill-climbing agent. Observe difference hill-climbing
agent (Figure 7) LRTA* agent (Figure 1) heuristic update rule line 6 latter
figure. update rule increase heuristic values (i.e., make less attractive
agent) already visited states. Since hill-climbing agent never re-visits states
traveling s1 s2 , increase heuristic values caused LRTA* affect
LRTA*s move choice (line 5 Figure 1). result, LRTA* follow precisely path
s1 s2 hill-climbing agent thus re-visit states. 2
Theorem 6 exist two states s1 s2 s2 hill-climbing reachable s1
path hill-climbing agent follows optimal (i.e., shortest).
Proof. proof constructive presented Figure 10. darkened cells walls. hillclimbing agent, starting state s1 hug wall way state s2 .The resulting
path cost 16.4. optimal path, however, takes advantage diagonal moves making
non-greedy move going around wall agent. cost 15. 2
Theorem 7 kNN LRTA* complete size subgoal database underlying kNN
LRTA* generates least immediate neighbors current state.
Proof. prove completeness need show pair states s1 s2 ,
path s1 s2 , kNN LRTA* reach s2 s1 .
Given problem, subgoal selection module kNN LRTA* (Figure 8) either return
record form r = (sstart , . . . , send ) instruct LRTA* go global goal. latter
case, kNN LRTA* complete underlying LRTA* complete (Korf, 1990) long
generates immediate neighbors current state.
former case, LRTA* guaranteed reach either sstart first subgoal r due
way r selected. states r reached, LRTA* guaranteed reach
subsequent states due completeness basic LRTA* way subgoals
generated. Note interruptibility enhancement interfere completeness
interrupt going global goal once. 2

285

fiB ULITKO , B J ORNSSON , & L AWRENCE

s1

s2

Figure 10: Hill-climbing reachability guarantee optimality.

8. Empirical Evaluation
Pathfinding video games challenging task, frequently requiring many units plan paths
simultaneously react promptly user commands. task made even challenging
ever-growing map sizes little computational resources allocated in-game AI. Accordingly,
recent work field real-time heuristic search uses video game pathfinding testbed.
8.1 Test Problems
Maps modelled game levels Baldurs Gate (BioWare Corp., 1998) WarCraft III:
Reign Chaos (Blizzard Entertainment, 2002) common choice (e.g., Sturtevant &
Buro, 2005; Bulitko et al., 2008). maps, however, small todays standards
represent state industry. paper, developed new set maps modelled
game levels Counter-Strike: Source (Valve Corporation, 2004), popular on-line first-person
shooter. game level geometry specified vector format. developed software
convert grid arbitrary resolution. previous papers commonly used maps
range 104 105 grid cells (e.g., 150 141 512 512 cells Sturtevant, 2007;
Bulitko & Bjornsson, 2009), new maps nine thirteen million vacant cells (i.e.,
states). two three orders magnitude increase size. point reference,
entire road network Western Europe used state-of-the-art route planning approximately
eighteen million vertices (Geisberger, Sanders, Schultes, & Delling, 2008).
experiments paper run set 1000 randomly generated problems across
four maps shown Figure 11. 250 problems map constrained
solution cost least 1000. grid dimensions varied 4096 4604 7261
4096 cells. problem computed optimal solution cost running A*. optimal
cost range [1003.8, 2999.8] mean 1881.76, median 1855.2 standard
deviation 549.74. also measured A* difficulty defined ratio number states
expanded A* number edges resulting optimal path. 1000 problems,
286

fiC ASE -BASED UBGOALING R EAL -T IME H EURISTIC EARCH

Figure 11: maps used empirical evaluation.

A* difficulty range [1, 199.8] mean 62.60, median 36.47 standard
deviation 64.14.
algorithms compared implemented Java using common data structures much
possible. used Java version 6 SUSE Enterprise Linux 10 2.1 GHz AMD Opteron
processor 32 Gbytes RAM. timings reported single-threaded computations.

8.2 Algorithms Evaluated
evaluated kNN LRTA* following parameters. Database size values
{1000, 5000, 10000, 40000, 60000, 80000} records. On-line, allowed hill-climbing test
climb 250 steps concluding destination state hill-climbing reachable.
value picked experimentation appropriate record density
map. Indeed, larger database requires fewer hill-climbing steps maintain likelihood
finding hill-climbing reachable record given problem.
287

fiB ULITKO , B J ORNSSON , & L AWRENCE

ran reachability checks 10 similar records.4 Whenever selectSubgoals failed
find matching record, allowed LRTA* travel towards global goal 3 times
heuristic estimate remaining path. that, LRTA* interrupted second attempt
find appropriate subgoal run. LRTA*s parameter gmax set cost
expensive edge (i.e., 1.4) LRTA* generated immediate neighbors current state.
also ran two recent high-performance real-time search algorithms compare kNN LRTA*
against: LRTA* TBA*. LRTA* run databases computed abstraction levels
{9, 10, 11, 12}. TBA* run time slices {5, 10, 20, 50, 100, 500, 1000, 2000, 5000}.
cost ratio expanding state backtracing set 10.
chose space control parameters via trial error, three considerations mind.
First, cover enough space clearly determine relationship control
parameters algorithms performance. Second, attempted establish pareto-optimal
frontier (i.e., determine algorithms dominate others simultaneously outperforming
along two performance measures time per move suboptimality). Third, parameter values
could run algorithms practical amount time (e.g., building
database LRTA*(8) would taken us 800 hours practical). detail
observations respect three considerations below.
8.3 Solution Suboptimality Per-Move Planning Time
begin comparisons looking average solution suboptimality versus average time per
move. left plot Figure 12 shows overall picture plotting algorithms parameters.
right plot zooms high-performance area. Table 1 shows individual values. kNN
LRTA* produces highest quality solutions, followed TBA*.
LRTA* mean suboptimality 819.72% delivers paths 9 times
costlier optimal paths. suboptimality impractical pathfinding included
LRTA*(9) right subplot Figure 12 illustrate substantial gap solution quality
LRTA* kNN LRTA*. Optimality LRTA* solutions improved lowering abstraction level database pre-computation increases rapidly discuss below.
TBA* produces solutions substantially less costly LRTA* cannot reach kNN LRTA*
database size 60 80 thousand records. Additionally, TBA* noticeably slower
per move expands one state allocates time backtracking well.
time per move decreased lowering value cutoff already cutoff 10,
TBA* produces unacceptably suboptimal solutions (666.5% suboptimal). result, kNN LRTA*
dominates TBA* outperforming respect measures. intuitive TBA*
benefit subgoal precomputation.
hand, LRTA* stands non-dominated due low time per move.
also intuitive scan database similar records check hillclimbing reachability them. differences LRTA* kNN LRTA* are, however,
4 microseconds per move.
sake reference, also included A* results table. A* real-time algorithm average time per move tends increase number states map. Also,
4. also experimented querying kd-tree 100 similar records found minor improvement suboptimality together significant increase mean time per move. frequently
hill-climbing-reachable database record among top 10 candidates thus extra time spent querying
kd-tree 90 records sorting wasted.

288

fi0

0

LRTA* (9)
kNN LRTA* (60000)
2
kNN LRTA* (80000)
200
C ASE -BASED UBGOALING R EAL -T IME H EURISTIC EARCH TBA* (50)
0
TBA* (100)
50
100
150
50
100
150
00
Mean precomputation time (hours per map)
0 Mean online
50memory (Kbytes
100per problem) 150
Mean precomputation time (hours per map)

Mean suboptimality (%)

10

Meanmemory
suboptimality
(%)per problem)
Mean online
(Kbytes

4

x 10

LRTA*
kNN LRTA*
TBA*

8
6
4
2
0

0

50
100
150
200
250
Mean time per move (seconds)

300

150
1000
LRTA* (9)
kNN LRTA* (60000)
kNN LRTA* (80000)
TBA* (50)
TBA* (100)

800
100
600
400
50

LRTA*
kNN LRTA*
TBA*

200

0
00
0

50
100
150
200
250
50
100
Mean
per move
move (seconds)
(seconds)
Mean time
time per

2010/1/8, 16:29:14 : Java results mm_cs_4_1000 scenario

300
150

Mean time per move (microseconds)
7.56
6.88
6.40
6.55
3.73
3.93
4.26
3.94
14.31
26.34
83.31
117.52
208.03

Solution suboptimality (%)
6851.62
620.63
12.77
11.96
15999.23
8497.09
6831.74
819.72
1504.54
666.50
131.12
64.66
0

Table 1: Suboptimality versus time per move.
spends time first move computes entire path. Subsequent moves
require trivial computation. table, define A*s mean time per move total planning
time problem divided number moves path A* finds. average quantity
problems. kNN LRTA* 30 times faster A* per move.
Note kNN LRTA*s time per move decreases larger databases. intuitive
database records higher probability earlier record short list records
reachability checks run pass checks (line 4 Figure 8). Consequently,
time-consuming reachability checks administered function selectSubgoals,
saving time per move. time savings, resulting larger database, outweigh extra time
spent traversing correspondingly larger kd-tree form short list similar records.
fact indicates kd-tree approach scales well database size.
289

400


kN
kN



200
0

0

Mean

150

100

50

0

0

Mea

2010/1/8, 16:39:16 : Java results mm_cs_4_1000 sc

Figure 12: Suboptimality vs. time per move: algorithms (left), high-performance region (right).
Algorithm
kNN LRTA*(10000)
kNN LRTA*(40000)
kNN LRTA*(60000)
kNN LRTA*(80000)
LRTA*(12)
LRTA*(11)
LRTA*(10)
LRTA*(9)
TBA*(5)
TBA*(10)
TBA*(50)
TBA*(100)
A*

Mean subo

2

4
400

Mean online memory (Kbytes per problem)

Mean subo
Mean

Mean

4

fi2

B ULITKO , B J ORNSSON , & L AWRENCE
0.5
1
Mean relative database size (per map)

0
00
0

1.5

4

10
1000

LRTA*
kNN LRTA*

8

4

LRTA* (9)
kNN LRTA* (40000)
kNN LRTA* (60000)
LRTA*
kNN LRTA* (80000)
kNN LRTA*

2
200

50
100
Mean precomputation time (hours per map)

0

150

0

10
Mean

Mean suboptimality (%)
Mean online memory (Kbytes per problem)

kNN LRTA*

800

kNN LRTA* (40000)
kNN LRTA* (60000)
Solution suboptimality
(%)
kNN LRTA* (80000)
LRTA*
6851.62
kNN LRTA*

Algorithm
Pre-computation time per map (hours)
10
600
kNN
13.10
6 LRTA*(10000)
kNN LRTA*(40000)
51.89
620.63
400
kNN
LRTA*(60000)
77.30
12.77
4
5
103.09
11.96
kNN LRTA*(80000)
200
0.25
15999.23
2D LRTA*(12)
LRTA*(11)
1.57
8497.09
0
0
2
4
11.95
6831.746
0D LRTA*(10)
0
0
2
4
6
8
10
0
2
4 move (seconds)
6
8
Mean
time per
LRTA*(9)
89.88
819.72
Mean time per move
(seconds)
Mean time per move (seconds)

8

10

800
600
400


kN
kN
kN

200
0

505
100
15015
10
(hours
perproblem)
map)
Mean precomputation
online memorytime
(Kbytes
per

4
Figurex 10
13:
Suboptimality versus database pre-computation time per map. Left: pre-computing
1000
10
15
algorithms. Right: high-performance
subplot.
LRTA* (9)
LRTA*

Mean suboptimality (%)

0

1000

4
400

2

8

0

x 10

6
600

0

200

60
1.5

8
800

6

0


kN
kN
kN

4

x 10

Mean suboptimality (%)
Mean suboptimality (%)

Mean suboptimality (%)

10

10
20
30
40
50
0.5
1 per map)
Mean database
size (MBytes
Mean relative database size (per map)

400

Mean suboptimality (%)

0

LRTA* (9)
kNN LRTA* (40000)
kNN LRTA* (60000)
kNN LRTA* (80000)

0

Mean

Mean online memory (Kbytes per problem)

0

2
200

Mean sub

4
400

Mean sub
Mean

Mean

4

1.5

1


kN
kN
kN

0.5

0

0

2
Mea

2010/1/8, 17:34:36 : Java results mm_cs_4_10

2010/1/8, 17:41:03 : Java results mm_cs_4_1000 scenario

Table 2: Suboptimality versus database pre-computation time.
8.4 Database Pre-computation Time
Suboptimality versus database pre-computation time shown Figure 13. left subplot demonstrates parametrizations LRTA* kNN LRTA* right plot focuses better
performing configurations. Table 2 shows individual values.
kNN LRTA* three advantages LRTA*. First, kNN LRTA* 40 60 thousand records easily dominates LRTA*(9): better suboptimality requiring less precomputation time. kNN LRTA*(80000) overkill maps improve suboptimality much (11.96% versus 12.77% achievable 60000 records) longest
precomputation time.
Second, database computation parallelized easily case kNN LRTA*
individual records completely independent other. case LRTA*.
Additionally, LRTA* requires building map abstraction complex parallel.
Third, number records kNN LRTA* database controlled much easily
LRTA*. Specifically, LRTA* one controls level abstraction.
number Sa abstract states abstraction level approximately Sa number
290

fiC ASE -BASED UBGOALING R EAL -T IME H EURISTIC EARCH

original non-abstract states constant reduction factor (Bulitko et al., 2007). number
Na records LRTA* database Sa (Sa 1). Thus, ratio Na Na1 is:
Na1
Na

=

Sa1 (Sa1 1)
=
Sa (Sa 1)


a1




1
a1

1


=

a1 2
= (2 ).


Thus decreasing level abstraction one, LRTA* database size grows least
quadratically . maps, clique abstraction approximately 3 means
nearly order magnitude database size (and pre-computation time) go
one level abstraction. illustrate, building database LRTA*(8) estimated take
800 CPU-hours. hand, number records kNN LRTA* database
user-specified parameter, affording much greater control.
particular interest pair kNN LRTA* database 10000 LRTA*
abstraction level 10 perform closely measures. discuss differences
database sizes next section.
8.5 Database Size
Memory premium video games, especially consoles. TBA* space complexity comes
open closed list builds on-line. kNN LRTA* LRTA* expand
single state (the agents current state) thus closed list one state open list
eight states (as grid cell maps eight neighbors). However, two
algorithms consume memory store updated heuristic values. Additionally, store
subgoal databases. section focus database size. next section cover
total memory consumed on-line: open closed lists well updated heuristic values.
LRTA* database record stores exactly three states. kNN LRTA* records two
states number records fixed algorithm parameter. Additionally, kNN
LRTA* stores start end states record kd-tree. define relative database size
ratio total number states stored records total number map grid cells.
addition subgoal records, LRTA* databases contain explicit region assignment
state. Consequently, LRTA* databases relative size least 1. extra storage
major weakness LRTA* comparison kNN LRTA*. illustrate, implementation
use 32 bits index states, storing region assignment grid cell translates average
84 megabytes per map. Full results found Figure 14 Table 3.
Algorithm
kNN LRTA*(10000)
kNN LRTA*(40000)
kNN LRTA*(60000)
kNN LRTA*(80000)
LRTA*(12)
LRTA*(11)
LRTA*(10)
LRTA*(9)

Pre-computation time
13.10
51.89
77.30
103.09
0.25
1.57
11.95
89.88

Records
10000
40000
60000
80000
251.5
1896.5
14872.0
116048.5

Relative size
0.00308
0.01234
0.01851
0.02468
1.00001
1.00009
1.00068
1.00532

Size (megabytes)
0.25
1.00
1.51
2.01
84.96
84.97
85.02
85.40

Table 3: Database statistics. values averages per map. Pre-computation time hours.
291

fiB ULITKO , B J ORNSSON , & L AWRENCE

10
1000

LRTA*
kNN LRTA*

8
800

6

LRTA*
kNN LRTA*

6
600

4

4
400

2
0

1000

Mean suboptimality (%)

8

x 10

Mean suboptimality (%)
Mean suboptimality (%)

Mean suboptimality (%)

4

x 10

2
200

0

0.5
1
Mean relative database size (per map)

00
0

1.5

LRTA* (9)
kNN LRTA* (60000)
kNN LRTA* (80000)

20
60 1
80
0.5 40
Mean relative
database
size (MBytes
permap)
map)
Mean
database
size (per

1000
10

LRTA* (9)
LRTA*
requiring much less memory and,kNN


time,
LRTA*
(60000)
kNN
LRTA*
8
LRTA* (80000) 57
instance, kNN800
LRTA*(60000)
requires kNN
approximately

suboptimality
(%)
Mean onlineMean
memory
(Kbytes per
problem)

Mean suboptimality (%)

0

2

4

6

8

10

Mean time
per move (seconds)
8.6 On-line Space
Complexity

0

0

20
Mean

0

2
Mean cum

800
600
400
200
0

3

5

x 10

4
3
2
1


kN
kN

0
0
2
Mean time per move (seconds)
Mea
2
4
6
8
10
Mean time per move (seconds)
2010/1/11, 17:09:07 : Java results mm_cs_4_

first analyze specifically

amount
results
memory
allocated byscenario
algorithms on-line.
2010/1/11,
17:11:03
: Java
mm_cs_4_1000
algorithm solves particular problem, record maximum size open closed lists
well total number states whose heuristic values updated. count updated
heuristic value one state terms storage required.5 Adding three measures together,
5. Multiple heuristic updates state increase amount storage.

292


kN
kN

200

1000

Mean suboptimality (%)

Mean suboptimality (%)

Mean suboptimality (%)
Mean suboptimality (%)

Again, kNN LRTA* dominates
8
producing
solutions better quality.
times less database memory LRTA*(9) simultaneously producing solutions
600
6
6

eight times better.
Let us re-visit interesting case kNN LRTA*(10000)
LRTA*(10) closely
400
4
4
match respect database pre-computation time solution suboptimality. Table 3 reveals, kNN LRTA*(10000) uses approximately 340
200 times less memory LRTA*(10):
2
2
256 kilobytes versus 85.02 megabytes.
0
Note
LRTA*(10) averages approximately 49%
records per map kNN
0
00
20
40
60
80
100
120
0
100
150 less pre-computation
0 Mean 2precomputation
4
6is
10
LRTA*(10000)
but50requires approximately
9%
time.
time (hours
per 8
map)(i)
Mean precomputation time (hours per map)
Mean cumulative online memory (Kbytes)x 104
LRTA* averages fewer subgoals per record kNN LRTA* (ii) computing LRTA* subgoals
require reachability checks time-consuming process.
4
1000
x 10
Also note despite 49% records, 0.06
LRTA* affords 0.3%
improvement

10
LRTA*
(9)
LRTA*generally, additional experiments demonstrated
kNN LRTA* (60000)
solution quality kNN LRTA*. DMore

800
kNN LRTA*
kNN LRTA* (80000)
kNN8 LRTA* tends outperform LRTA* solution0.05
quality given number records.
two factors play here. First, kNN LRTA*0.04
records often contain
several subgoals
600
LRTA*
6
guaranteed
reachable without scrubbing. LRTA*
records offers
kNN LRTA*
0.03
guarantees subgoal may difficult reach
400 agents start state abstract
4
regions
become large complex. upside, LRTA* spaces records systematic
0.02
fashion one record per pair regions thereby200
providing potentially better coverage
2
afforded randomly selected starts ends
kNN LRTA* database records. appears
0.01
former factor overcomes latter, leading kNN0LRTA*s
better
per-record
suboptimality.
0
2
4
6
8
0

400

0

LRTA*

LRTA*
kNN
LRTA*

0

600

100
1.5

4
4
Figurex 10
14:
Suboptimality vs. database size: algorithms x(left),
high-performance region (right).
10

10

800

Mean online memory (Kbytes per problem)

4

10

fiC ASE -BASED UBGOALING R EAL -T IME H EURISTIC EARCH

Algorithm
kNN LRTA*(10000)
kNN LRTA*(40000)
kNN LRTA*(60000)
kNN LRTA*(80000)
LRTA*(12)
LRTA*(11)
LRTA*(10)
LRTA*(9)
TBA*(5)
TBA*(10)
TBA*(50)
TBA*(100)
A*

Strictly on-line memory (Kbytes)
8.62
5.04
4.23
4.22
18.76
11.09
8.24
3.04
1353.94
1353.94
1353.94
1353.94
1353.94

Solution suboptimality (%)
6851.62
620.63
12.77
11.96
15999.23
8497.09
6831.74
819.72
1504.54
666.50
83.31
64.66
0

Table 4: Strictly on-line memory versus solution suboptimality.

record amount strictly on-line memory per problem. Averaging strictly on-line memory
problems, list results Table 4.
kNN LRTA* dominates LRTA* points except LRTA*(9) lowest mean
strictly on-line memory 3.04 Kbytes per problem. TBA*, effectively time-sliced A*,
update heuristic values all. However, open closed lists contribute highest
memory consumption 1353.94 Kbytes. intuitive TBA* use subgoals therefore must fill potentially large heuristic depressions open closed lists. Also, notice
total size lists change cutoff state expansions independent
agents moves TBA*. A* identical memory consumption expands states
way TBA*. Again, kNN LRTA* dominates TBA* cutoff values, using less memory
producing better solutions.
Strictly on-line memory gives insight algorithms present complete picture. Specifically, LRTA* kNN LRTA* must load databases on-line memory.
Thus define cumulative on-line memory strictly on-line memory plus size
database loaded. values found Figure 15 Table 5.
Several observations due. First, TBA* longer dominated due low memory consumption. Second, LRTA* league due explicitly labelling every state
corresponding region well computing subgoals pairs regions. Third, LRTA*
sweet spot memory consumption corresponds abstraction level 11. higher
level abstraction reduces database size enough compensate updated heuristic values. Lower abstraction levels reduce amount learning enough compensate
large number subgoals database.
293

fi50
2

1.5

20
40
60
80
Mean
(MBytes
map)
0.005 database
0.01 size
0.015
0.02per 0.025
Mean relative database size (per map)

100
0.03

kNN LRTA* (60000)
kNN LRTA* (80000)
TBA* (50)
L AWRENCETBA* (100)

50

B ULITKO , B J ORNSSON , &

0
0
0
0

(per map)

Mean subo

Mean
Mean
subos

1

LRTA*
kNN LRTA*
TBA*

4

0

0

0.5
1
1.5
2
2.5
Mean database size (MBytes per map)

3

4

Mean suboptimality (%)

100
6

150

LRTA*
kNN LRTA*
kNN(60000)
LRTA*
kNN LRTA*
(80000)
TBA*
TBA* (50)
TBA* (100)

4
50

2

100

50

0

2
6 100
8
10
50 4
150
4
Mean
online
(Kbytes)
Mean cumulative
precomputation
timememory
(hours per
map)x 10

kNN LRTA* (60000)
kNN LRTA* (80000)
TBA* (50)
TBA* (100)
0

500
1000
1500
2000
2500
Mean cumulative online memory (Kbytes)

Figure
15: Suboptimality versus cumulative on-line memory. Left: algorithms. Right: high1.5
150
1.5
performance subplot.
kNN LRTA* (60000)
Mean online memory (Kbytes per problem)

LRTA*
kNN LRTA*
TBA*

8

00
00

150

Mean online
memory
(Kbytes(%)
per problem)
Mean
suboptimality

00
urs per map)

Meansuboptimality
suboptimality
(%)
Mean
(%)

LRTA*
kNN LRTA*
TBA*

x 10
10
150

kNN LRTA* (80000)
TBA* (50)
Cumulative
TBA* (100) on-line

Algorithm
memory (Kbytes) Solution suboptimality (%)
1
kNN LRTA*(10000)
265.65
6851.62
kNN LRTA*(40000)
1034.08
620.63
kNN LRTA*(60000)
1547.85
12.77
LRTA*
50
0.5
0.5
kNN LRTA*
kNN LRTA* (60000)
kNN
LRTA*(80000)
2062.20
11.96
TBA*
kNN LRTA* (80000)
LRTA*(12)
87019.74
15999.23
TBA* (50)
LRTA*(11)
87018.50
TBA* (100) 8497.09
0
0
0D
87066.34
6831.74
0 LRTA*(10)
50
100
150
0
50
100
150
00
250
300
0
50
100
150
200
250
300
Mean
time
per
move
(seconds)
Mean
time
per
move
(seconds)
LRTA*(9)
819.72
Mean time per move (seconds) 87456.35
econds)
TBA*(5)
1353.94
1504.54
2010/1/13, 21:37:18 : Java results mm_cs_4_1000 scenario
3, 21:30:33 : Java results mm_cs_4_1000
scenario
TBA*(10)
1353.94
666.50
TBA*(50)
1353.94
83.31
TBA*(100)
1353.94
64.66
A*
1353.94
0
100
1

Table 5: Solution suboptimality versus cumulative on-line memory.
8.7 Simultaneous Pathfinding Multiple Agents
single agent pathfinding time, analysis holds TBA*
memory efficient choice. However, video games, anywhere half dozen thousand
agents (e.g., Gas Powered Games, 2007) pathfinding simultaneously map.
scenario favors kNN LRTA* LRTA* whose subgoal databases map-specific
independent start goal states. Consequently, multiple agents running LRTA* kNN
LRTA* share subgoal database.6 contrast, memory consumed TBA*
specific given agent cannot shared agents operating map.
6. Note multiple agents cannot, generally speaking, share heuristic h computed updated
respect different goals.

294

fiC ASE -BASED UBGOALING R EAL -T IME H EURISTIC EARCH

Hence total amount cumulative on-line memory K agents operating simultaneously
equals amount database memory plus K times amount strictly on-line memory.
break-even point algorithm respect algorithm B defined minimal
number agents using collectively consume less memory number agents
using B. Table 6 lists break-even points LRTA* kNN LRTA* respect TBA*.
Algorithm
kNN LRTA*(10000)
kNN LRTA*(40000)
kNN LRTA*(60000)
kNN LRTA*(80000)
LRTA*(9)
LRTA*(10)
LRTA*(11)
LRTA*(12)

Break-even point respect TBA* (number agents)
1
1
2
2
65
65
66
66

Table 6: Break-even points kNN LRTA* LRTA* respect TBA*.
kNN LRTA* ten forty thousand record databases requires less cumulative on-line
memory TBA* hence break-even point one agent. sixty eighty thousand
records, two kNN LRTA* agents take less total cumulative on-line memory two TBA* agents.
takes 65 66 simultaneously pathfinding agents amortize large LRTA* databases
gain memory advantage TBA*.

9. Discussion
first time high-performance real-time search algorithms TBA*, LRTA* kNN
LRTA* evaluated contemporarily sized maps. results, presented detail previous section, summarized representative algorithms Table 7.
Dimension
Suboptimality
Time per move
Cumulative memory
Break-even point
Pre-computation time

kNN LRTA* versus algorithms
kNN LRTA* 8.16 times better LRTA* 1.46 times better TBA*
kNN LRTA* 18.36 times better TBA* 62% worse LRTA*
kNN LRTA* 57 times better LRTA* 13% times worse TBA*
kNN LRTA* takes less memory TBA* two agents
kNN LRTA* 14% better LRTA*

Table 7: Comparisons kNN LRTA*(60000) LRTA*(9) TBA*(100).
kNN LRTA* achieves best suboptimality three algorithms. kNN LRTA* substantially faster per move TBA* par LRTA*. terms cumulative on-line
memory, kNN LRTA* outperforms LRTA* two orders magnitude 13% worse
TBA*. Furthermore, two simultaneously planning agents, kNN LRTA* takes less
memory TBA*. contrast, takes 65 LRTA* agents amortize database
gain memory advantage TBA*. Off-line, kNN LRTA* outperforms LRTA* achieving
295

fiB ULITKO , B J ORNSSON , & L AWRENCE

order magnitude better solutions database two orders magnitude smaller size
slightly faster compute.
results comparisons TBA* expected TBA* benefit precomputation, comparison kNN LRTA* LRTA* unearthed unexpected results.
Specifically, subgoal databases kNN LRTA* effective use pre-computation time
memory LRTA*. lower memory consumption kNN LRTA* databases
achieved store explicit region membership. Better pre-computation times come
compute shortest paths pairs abstract times. Finally, kNN LRTA*
better LRTA* per record basis. compressing entire optimal path
series subgoals reachable via hill-climbing guarantees single
subgoal reached, underlying LRTA* agent reach global goal without scrubbing.
contrast, LRTA* subgoals difficult reach agents current position. even
reached, difficulties recur subsequent subgoals.
terms applications, kNN LRTA* algorithm choice use video game
pathfinding. instance, kNN LRTA*(60000) 30 times faster per average move commonly used A* produces solutions less 15% suboptimal. performance
comes cost 77 hours pre-computation time per map easily reduced
10 hours modern eight-core workstation. negligible comparing amount
time game company spends hand-crafting single map.

10. Current Shortcomings Future Work
Despite outperforming existing state-of-the-art real-time search algorithms problems overall,
kNN LRTA* several shortcomings. First, database records generated randomly
selected start end states. means coverage space necessarily even:
small, difficult reach, regions space may never get suitable record
easy reach regions may get multiple redundant records covering it.
Increasing database efficiency would allow smaller database afford equal coverage
hence equal on-line performance. turn reduce pre-computation time kNN
LRTA* database presently reach 100 hours per map. computation
sped nearly linear scale using multi-core processors time affordable
game company side, players would want home-made game maps processed
matter seconds minutes.
Making subgoal coverage uniform accomplished via forgoing random start
end selection favor space partitioning. However, unlike LRTA*s abstract regions built via
repeated applications clique abstraction, partitions states reachable
LRTA* without scrubbing. start end states database records
selected within partitions. reduce amount pre-computation one compute
subgoals compressing optimal paths neighboring regions (as opposed distinct
abstract regions LRTA* does). Note unlike LRTA*, partitioning necessarily
off-line explicit region assignment stored every state. result, on-line memory
consumption comparable better existing kNN LRTA*.
philosophically oriented project would develop self-aware agent. Specifically,
agent would analyze performance core algorithm (e.g., LRTA*) decide
296

fiC ASE -BASED UBGOALING R EAL -T IME H EURISTIC EARCH

appropriate partitioning scheme. similar meta-level control previously attempted
dynamic selection lookahead depth real-time search (e.g., Russell & Wefald, 1991).

11. Beyond Grid Pathfinding
presented evaluated kNN LRTA* grid-based pathfinding. Formally, algorithm,
exception kd-tree module, applicable arbitrary weighted graphs satisfy constraints beginning Section 2. principle, applicable general planning
using ideas search-based planners ASP (Bonet, Loerincs, & Geffner, 1997), HSPfamily (Bonet & Geffner, 2001), FF (Hoffmann, 2000), SHERPA (Koenig, Furcy, & Bauer, 2002)
LDFS (Bonet & Geffner, 2006).
described earlier paper, using kd-tree index requires certain correspondence
coordinate similarity heuristic distance. Extending kd-trees developing appropriate
new index structures arbitrary graph open research question. interim solution
apply kNN LRTA* arbitrary search problems without kd-tree module. will, however,
slow on-line part similarity must computed agents current situation
every single record database. positive side, computing kd-trees speed
off-line part kNN LRTA*.
Finally, kNN LRTA* theoretically applicable arbitrary search problems,
clear well perform respect competitors LRTA* TBA*.
investigation left future work.

12. Conclusions
paper considered problem real-time heuristic search whose planning time per move
depend number states. proposed new mechanism selecting subgoals
automatically. resulting algorithm shown theoretically complete and, large video
game maps, substantially outperformed previous state-of-the-art algorithms LRTA* TBA*
along several important performance measures.

Acknowledgments
research supported grants National Science Engineering Research Council
Canada (NSERC); Icelandic Centre Research (RANNIS); Marie Curie Fellowship
European Community programme Structuring ERA contract number MIRG-CT2005-017284. appreciate help Josh Sterling, Stephen Hladky Daniel Huntley.

References
Anwar, M. A., & Yoshida, T. (2001). Integrating OO road network database, cases knowledge
route finding. ACM Symposium Applied Computing (SAC), pp. 215219. ACM.
Barto, A. G., Bradtke, S. J., & Singh, S. P. (1995). Learning act using real-time dynamic programming. Artificial Intelligence, 72(1), 81138.
BioWare Corp. (1998). Baldurs Gate., Published Interplay, http://www.bioware.com/bgate/,
November 30, 1998.
297

fiB ULITKO , B J ORNSSON , & L AWRENCE

Bjornsson, Y., Bulitko, V., & Sturtevant, N. (2009). TBA*: Time-bounded A*. Proceedings
International Joint Conference Artificial Intelligence (IJCAI), pp. 431 436, Pasadena,
California. AAAI Press.
Bjornsson, Y., & Halldorsson, K. (2006). Improved heuristics optimal path-finding game
maps. Laird, J. E., & Schaeffer, J. (Eds.), Proceedings Second Artificial Intelligence
Interactive Digital Entertainment Conference (AIIDE), June 20-23, 2006, Marina del
Rey, California, pp. 914. AAAI Press.
Blizzard Entertainment (2002). Warcraft III: Reign chaos., Published Blizzard Entertainment,
http://www.blizzard.com/war3, July 3, 2002.
Bonet, B., & Geffner, H. (2001). Planning heuristic search. Artificial Intelligence, 129(12),
533.
Bonet, B., & Geffner, H. (2006). Learning depth-first search: unified approach heuristic search
deterministic non-deterministic settings, application MDPs. Proceedings
International Conference Automated Planning Scheduling (ICAPS), pp. 142
151, Cumbria, UK.
Bonet, B., Loerincs, G., & Geffner, H. (1997). fast robust action selection mechanism
planning. Proceedings National Conference Artificial Intelligence (AAAI), pp.
714719, Providence, Rhode Island. AAAI Press / MIT Press.
Branting, K., & Aha, D. W. (1995). Stratified case-based reasoning: Reusing hierarchical problem
solving episodes. Proceedings International Joint Conference Artificial Intelligence (IJCAI), pp. 384390.
Bulitko, V. (2004).
Learning adaptive real-time search.
Tech.
http://arxiv.org/abs/cs.AI/0407016, Computer Science Research Repository (CoRR).

rep.

Bulitko, V., & Bjornsson, Y. (2009). kNN LRTA*: Simple subgoaling real-time search.
Proceedings Artificial Intelligence Interactive Digital Entertainment (AIIDE), pp. 27,
Stanford, California. AAAI Press.
Bulitko, V., Bjornsson, Y., Lustrek, M., Schaeffer, J., & Sigmundarson, S. (2007). Dynamic Control Path-Planning Real-Time Heuristic Search. Proceedings International
Conference Automated Planning Scheduling (ICAPS), pp. 4956, Providence, RI.
Bulitko, V., & Lee, G. (2006). Learning real time search: unifying framework. Journal
Artificial Intelligence Research (JAIR), 25, 119157.
Bulitko, V., Lustrek, M., Schaeffer, J., Bjornsson, Y., & Sigmundarson, S. (2008). Dynamic control
real-time heuristic search. Journal Artificial Intelligence Research (JAIR), 32, 419 452.
Bulitko, V., Sturtevant, N., Lu, J., & Yau, T. (2007). Graph abstraction real-time heuristic search.
Journal Artificial Intelligence Research (JAIR), 30, 51100.
Carbonell, J. G., Knoblock, C., & Minton, S. (1990). Prodigy: integrated architecture planning learning. Lehn, K. V. (Ed.), Architectures Intelligence. Lawrence Erlbaum
Associates.
Cazenave, T. (2006). Optimizations data structures, heuristics algorithms path-finding
maps. Louis, S. J., & Kendall, G. (Eds.), Proceedings 2006 IEEE Symposium
298

fiC ASE -BASED UBGOALING R EAL -T IME H EURISTIC EARCH

Computational Intelligence Games (CIG06), University Nevada, Reno, campus
Reno/Lake Tahoe, 22-24 May, 2006, pp. 2733. IEEE.
Culberson, J., & Schaeffer, J. (1998). Pattern Databases. Computational Intelligence, 14(3), 318
334.
Furcy, D., & Koenig, S. (2000). Speeding convergence real-time search. Proceedings
National Conference Artificial Intelligence (AAAI), pp. 891897.
Gas

Powered Games (2007).
Supreme Commander.,
http://www.supremecommander.com/, February 20, 2007.

Published



THQ,

Geisberger, R., Sanders, P., Schultes, D., & Delling, D. (2008). Contraction hierarchies: Faster
simpler hierarchical routing road networks. McGeoch, C. C. (Ed.), WEA, Vol. 5038
Lecture Notes Computer Science, pp. 319333. Springer.
Haigh, K., & Veloso, M. (1993). Combining search analogical reasoning path planning
road maps. Proceedings AAAI-93 Workshop Case-Based Reasoning, pp. 7985,
Washington, DC. AAAI. AAAI Press technical report WS-93-01.
Hart, P., Nilsson, N., & Raphael, B. (1968). formal basis heuristic determination
minimum cost paths. IEEE Transactions Systems Science Cybernetics, 4(2), 100107.
Hernandez, C., & Meseguer, P. (2005a). Improving convergence LRTA*(k). Proceedings
International Joint Conference Artificial Intelligence (IJCAI), Workshop Planning
Learning Priori Unknown Dynamic Domains, pp. 6975, Edinburgh, UK.
Hernandez, C., & Meseguer, P. (2005b). LRTA*(k). Proceedings International Joint
Conference Artificial Intelligence (IJCAI), pp. 12381243, Edinburgh, UK.
Hodal, J., & Dvorak, J. (2008). Using case-based reasoning mobile robot path planning. Engineering Mechanics, 15, 181191.
Hoffmann, J. (2000). heuristic domain independent planning use enforced hillclimbing algorithm. Proceedings 12th International Symposium Methodologies
Intelligent Systems (ISMIS), pp. 216227.
Ishida, T. (1992). Moving target search intelligence. National Conference Artificial
Intelligence (AAAI), pp. 525532.
Koenig, S. (2004). comparison fast search methods real-time situated agents. Proceedings Int. Joint Conf. Autonomous Agents Multiagent Systems, pp. 864 871.
Koenig, S., Furcy, D., & Bauer, C. (2002). Heuristic search-based replanning. Proceedings
Int. Conference Artificial Intelligence Planning Scheduling, pp. 294301.
Koenig, S., & Likhachev, M. (2006). Real-time adaptive A*. Proceedings International
Joint Conference Autonomous Agents Multiagent Systems (AAMAS), pp. 281288.
Korf, R. (1985). Depth-first iterative deepening: optimal admissible tree search. Artificial Intelligence, 27(3), 97109.
Korf, R. (1990). Real-time heuristic search. Artificial Intelligence, 42(23), 189211.
Likhachev, M., Ferguson, D. I., Gordon, G. J., Stentz, A., & Thrun, S. (2005). Anytime dynamic
A*: anytime, replanning algorithm. ICAPS, pp. 262271.
299

fiB ULITKO , B J ORNSSON , & L AWRENCE

Likhachev, M., Gordon, G. J., & Thrun, S. (2004). ARA*: Anytime A* provable bounds
sub-optimality. Thrun, S., Saul, L., & Scholkopf, B. (Eds.), Advances Neural Information Processing Systems 16. MIT Press, Cambridge, MA.
Lustrek, M., & Bulitko, V. (2006). Lookahead pathology real-time path-finding. Proceedings
National Conference Artificial Intelligence (AAAI), Workshop Learning Search,
pp. 108114, Boston, Massachusetts.
Moore, A. (1991). Efficient Memory-based Learning Robot Control. Ph.D. thesis, University
Cambridge.
Nebel, B., & Koehler, J. (1995). Plan reuse versus plan generation: theoretical empirical
analysis. Artificial Intelligence, 76, 427454.
Rayner, D. C., Davison, K., Bulitko, V., Anderson, K., & Lu, J. (2007). Real-time heuristic search
priority queue. Proceedings International Joint Conference Artificial
Intelligence (IJCAI), pp. 23722377, Hyderabad, India.
Russell, S., & Wefald, E. (1991). right thing: Studies limited rationality. MIT Press.
Shimbo, M., & Ishida, T. (2003). Controlling learning process real-time heuristic search.
Artificial Intelligence, 146(1), 141.
Shue, L.-Y., Li, S.-T., & Zamani, R. (2001). intelligent heuristic algorithm project scheduling
problems. Proceedings 32nd Annual Meeting Decision Sciences Institute, San
Francisco.
Shue, L.-Y., & Zamani, R. (1993). admissible heuristic search algorithm. Proceedings
7th International Symposium Methodologies Intelligent Systems (ISMIS-93), Vol. 689
LNAI, pp. 6975.
Sigmundarson, S., & Bjornsson, Y. (2006). Value Back-Propagation vs. Backtracking RealTime Search. Proceedings National Conference Artificial Intelligence (AAAI),
Workshop Learning Search, pp. 136141, Boston, Massachusetts, USA.
Stenz, A. (1995). focussed D* algorithm real-time replanning. Proceedings
International Joint Conference Artificial Intelligence (IJCAI), pp. 16521659.
Sturtevant, N. (2007). Memory-efficient abstractions pathfinding. Proceedings third
conference Artificial Intelligence Interactive Digital Entertainment, pp. 3136, Stanford, California.
Sturtevant, N., & Buro, M. (2005). Partial pathfinding using map abstraction refinement.
Proceedings National Conference Artificial Intelligence (AAAI), pp. 13921397,
Pittsburgh, Pennsylvania.
Sturtevant, N. R., Felner, A., Barrer, M., Schaeffer, J., & Burch, N. (2009). Memory-based heuristics
explicit state spaces. Boutilier, C. (Ed.), IJCAI 2009, Proceedings 21st International Joint Conference Artificial Intelligence, Pasadena, California, USA, July 11-17,
2009, pp. 609614.
Valve Corporation (2004).
Counter-Strike: Source., Published Valve Corporation,
http://store.steampowered.com/app/240/, October 7, 2004.
Weng, M., Wei, X., Qu, R., & Cai, Z. (2009). path planning algorithm based typical case
reasoning. Geo-spatial Information Science, 12, 6671.
300

fiJournal Artificial Intelligence Research 39 (2010) 533-579

Submitted 12/09; published 10/10

Theta*: Any-Angle Path Planning Grids
Kenny Daniel
Alex Nash
Sven Koenig

KFDANIEL @ USC . EDU
ANASH @ USC . EDU
SKOENIG @ USC . EDU

Computer Science Department
University Southern California
Los Angeles, California 90089-0781, USA

Ariel Felner

FELNER @ BGU . AC . IL

Department Information Systems Engineering
Ben-Gurion University Negev
Beer-Sheva, 85104, Israel

Abstract
Grids blocked unblocked cells often used represent terrain robotics video
games. However, paths formed grid edges longer true shortest paths terrain
since headings artificially constrained. present two new correct complete anyangle path-planning algorithms avoid shortcoming. Basic Theta* Angle-Propagation
Theta* variants A* propagate information along grid edges without constraining
paths grid edges. Basic Theta* simple understand implement, fast finds short paths.
However, guaranteed find true shortest paths. Angle-Propagation Theta* achieves
better worst-case complexity per vertex expansion Basic Theta* propagating angle ranges
expands vertices, complex, fast finds slightly longer paths.
refer Basic Theta* Angle-Propagation Theta* collectively Theta*. Theta* unique
properties, analyze detail. show experimentally finds shorter paths
A* post-smoothed paths Field D* (the version A* know
propagates information along grid edges without constraining paths grid edges) runtime
comparable A* grids. Finally, extend Theta* grids contain unblocked cells
non-uniform traversal costs introduce variants Theta* provide different tradeoffs
path length runtime.

1. Introduction
article, study path planning robotics video games (Choset, Lynch, Hutchinson,
Kantor, Burgard, Kavraki, & Thrun, 2005; Deloura, 2000; Patel, 2000; Murphy, 2000; Rabin, 2002),
two-dimensional continuous terrain discretized grid blocked unblocked
cells. objective find short unblocked path given start vertex given goal vertex
(both corners cells). A* finds grid paths (that is, paths constrained grid edges) quickly,
grid paths often true shortest paths (that is, shortest paths terrain) since potential
headings artificially constrained multiples 45 degrees, shown Figure 1(a) (Yap, 2002).
shortcoming led introduction call any-angle path planning (Nash, Daniel,
Koenig, & Felner, 2007; Ferguson & Stentz, 2006). Any-angle path-planning algorithms find paths
c
2010
AI Access Foundation. rights reserved.

fiDANIEL , NASH , KOENIG , & F ELNER



1

2

3

4

5



start

B

C

1

2

3

4

5

start

B

C

goal
(a) Grid path

goal
(b) True shortest path

Figure 1: Grid path versus true shortest path
without constraining headings paths, shown Figure 1(b). present two new
correct complete any-angle path-planning algorithms. Basic Theta* Angle-Propagation
Theta* variants A* propagate information along grid edges (to achieve short
runtime) without constraining paths grid edges (to find any-angle paths). Unlike A* visibility
graphs, guaranteed find true shortest paths. asterisk names thus
denote optimality rather similarity A*. Basic Theta* simple understand
implement, fast finds short paths. Angle-Propagation Theta* achieves worst-case complexity
per vertex expansion constant rather linear number cells (like Basic
Theta*) propagating angle ranges expands vertices, complex, fast
finds slightly longer paths. refer Basic Theta* Angle-Propagation Theta* collectively
Theta*. Theta* unique properties, analyze detail. show experimentally
finds shorter paths A* post-smoothed paths Field D* (the version
A* know propagates information along grid edges without constraining paths grid
edges) runtime comparable A* grids. Finally, extend Theta* grids
contain unblocked cells non-uniform traversal costs introduce variants Theta*
provide different tradeoffs path length runtime.

2. Path-Planning Problem Notation
section, describe path-planning problem study article, namely path
planning eight-neighbor grids blocked unblocked cells uniform size. Cells labeled
either blocked (grey) unblocked (white). use corners cells (rather centers)
vertices. set vertices. path-planning problem find unblocked path
given start vertex sstart given goal vertex sgoal .
path unblocked iff vertex path line-of-sight successor path. Vertex
line-of-sight vertex , written LineOfSight(s, ), iff straight line vertex
vertex neither passes interior blocked cells passes blocked cells
share edge. Pseudocode implementing line-of-sight function given Appendix A.
simplicity, allow straight line pass diagonally touching blocked cells.
c(s, ) length straight line vertex vertex . nghbrsvis (s) set visible
neighbors vertex eight compass directions, neighbors vertex
534

fiT HETA *: NY-A NGLE PATH P LANNING



G RIDS

line-of-sight vertex s. Figure 1 shows example visible neighbors vertex B4
vertices A3, A4, A5, B3, B5, C3 C4.

3. Existing Terrain Discretizations
Continuous terrain needs discretized path planning. section, compare grids
existing terrain discretizations. use grids discretize terrain since widely used
robotics video games (Deloura, 2000; Murphy, 2000; Rabin, 2004) several desirable
properties:
Grids simple data structures allow simple path-planning algorithms.
Terrain easily discretized grid laying grid terrain labeling
cells partially completely obstructed blocked.
Grids provide comprehensive picture traversable surfaces continuous terrain.
essential path planning algorithm used dynamic environment
must interact navigation planner. example robot video game character
encounters temporary blockage path, easily determine whether best
divert left (unblocked) right (blocked) (Tozour, 2004).
Cells store information addition traversability, amount gold
hidden region terrain corresponds cell rendering region
displaying terrain.
information stored cells accessed quickly since grids random access data
structures.
precision path navigation planning improved simply increasing grid
resolution.
list alternative terrain discretizations, assuming simplicity obstacles
terrain polygonal.
Voronoi graphs (Aurenhammer, 1991) discretize terrain biasing paths away
blocked polygons. resulting paths thus much longer true shortest paths.
discretization work Mitchell Papadimitriou (1991) partitions terrain
regions linear hyperbolic edges, allows one find true shortest paths
time space complexity O(m5/3 ), number corners blocked polygons.
Thus, runtime path planning grow superlinearly number corners blocked
polygons.
Framed Quadtrees (Yahja, Stentz, Singh, & Brumitt, 1998) recursively subdivide terrain
four equally sized cells cells completely obstructed, completely unobstructed
sufficiently small size. resulting paths unnecessary heading changes (that is,
heading changes occur free space rather corners blocked polygons).
535

fiDANIEL , NASH , KOENIG , & F ELNER

1 Main()
2
g(sstart ) := 0;
3
parent(sstart ) := sstart ;
4
open := ;
5
open.Insert(sstart , g(sstart ) + h(sstart ));
6
closed := ;
7
open 6=
8
:= open.Pop();
= sgoal
9
10
return path found;
11
12
13
14
15
16
17
18
19

closed := closed {s};
/* following line executed AP Theta*.
[UpdateBounds(s)];
foreach nghbrsvis (s)
6 closed
6 open
g(s ) := ;
parent(s ) := N U LL;

*/;

UpdateVertex(s, );

20
return path found;
21 end
22 UpdateVertex(s,s)
23
g(s) + c(s, ) < g(s )
24
g(s ) := g(s) + c(s, );
25
parent(s ) := s;
26
open
27
open.Remove(s );
28

open.Insert(s , g(s ) + h(s ));

29 end

Algorithm 1: A*

Probabilistic roadmaps (Kavraki, Svestka, Latombe, & Overmars, 1996) rapidly-exploring
random trees (LaValle & Kuffner, 2001) place vertices randomly (in addition start
goal vertex). Two vertices connected via straight line iff line-of-sight.
random placement vertices needs tuned carefully since influences runtime
path planning, likelihood finding path length path.
Visibility graphs (Lee, 1978; Lozano-Perez & Wesley, 1979) use corners blocked
polygon vertices (in addition start goal vertex). Two vertices connected via
straight line iff line-of-sight, allows one find true shortest paths.
runtime path planning grow superlinearly number vertices since number
edges grow quadratically number vertices.

4. Existing Path-Planning Algorithms
section, describe existing path-planning algorithms, variants A*
(Hart, Nilsson, & Raphael, 1968). A* popular path-planning algorithm robotics video
games. Algorithm 1 shows pseudocode A*. Line 13 ignored. A* maintains three
values every vertex s:
536

fiT HETA *: NY-A NGLE PATH P LANNING



G RIDS

g-value g(s) length shortest path start vertex vertex found
far thus estimate start distance vertex s.
user-provided h-value h(s) estimate goal distance vertex s. A* uses
h-value calculate f-value focus A* search. f-value f (s) = g(s) + h(s)
estimate length shortest path start vertex via vertex goal vertex.
parent parent(s) used extract path start vertex goal vertex A*
terminates.
A* also maintains two global data structures:
open list priority queue contains vertices A* considers expansion.
pseudocode, open.Insert(s, x) inserts vertex key x priority queue open,
open.Remove(s) removes vertex priority queue open, open.Pop() removes
vertex smallest key priority queue open returns it.
closed list set contains vertices A* already expanded. ensures
A* expands every vertex once.
A* sets g-value every vertex infinity parent every vertex NULL
encounters vertex first time [Lines 17-18]. sets g-value start vertex zero
parent start vertex start vertex [Lines 2-3]. sets open closed
lists empty list inserts start vertex open list f-value key
[4-6]. A* repeatedly executes following procedure: open list empty, reports
path [Line 20]. Otherwise, identifies vertex smallest f-value
open list [Line 8]. vertex goal vertex, A* reports found path [Line 10].
Path extraction [not shown pseudocode] follows parents goal vertex start
vertex retrieve path start vertex goal vertex reverse. Otherwise, A* removes
vertex open list [Line 8] expands inserting vertex closed list [Line
11] generating unexpanded visible neighbors, follows: A* checks whether
g-value vertex plus length straight line vertex vertex smaller
g-value vertex [Line 23]. so, sets g-value vertex g-value vertex
plus length straight line vertex vertex , sets parent vertex vertex
finally inserts vertex open list f-value key or, already
open list, sets key f-value [Lines 24-28]. repeats procedure.
summarize, A* updates g-value parent unexpanded visible neighbor
vertex procedure UpdateVertex, considers path start vertex vertex [= g(s)]
vertex vertex straight line [= c(s, )], resulting length g(s) + c(s, )
[Line 23]. A* updates g-value parent vertex considered path shorter
shortest path start vertex vertex found far [= g(s )].
describe several existing path-planning algorithms versions A*
trade two conflicting criteria, namely runtime path length, shown Figure 2.
introduce order decreasing path lengths.
537

fiDANIEL , NASH , KOENIG , & F ELNER

10

1

Runtime

A*
A* PS
FD*

0.1

Visibility Graphs
Basic Theta*

0.01

0.001
1

1.01

1.02

1.03

1.04

1.05

1.06

Path Length / Length True Shortest Path

Figure 2: Runtime versus path length (relative length true shortest path) random 100
100 grids 20 percent blocked cells

30 PostSmoothPath([s0 , . . . , sn ])
31
k := 0;
32
tk := s0 ;
33
foreach := 1 . . . n 1
34
LineOfSight(tk , si+1 )
35
k := k + 1;
36
tk := si ;
37
k := k + 1;
38
tk := sn ;
39
return [t0 , . . . , tk ];
40 end

Algorithm 2: Post-smoothing

4.1 A* Grids
One run A* grids, is, graphs given grid vertices edges. resulting
paths artificially constrained formed edges grid, seen Figure
1(a). result paths found A* grids equivalent true shortest paths
unrealistic looking since either deviate substantially true shortest paths
many heading changes, provides motivation smoothing them. use octile
distances, computed using Algorithm 5, h-values experiments.
538

fiT HETA *: NY-A NGLE PATH P LANNING

1

2

3

4

5





G RIDS

6
goal
true shortest path

B
shortest grid path
A* PS path

C

start

Figure 3: A* PS path versus true shortest path

4.2 A* Post-Smoothed Paths (A* PS)
One run A* post-smoothed paths (A* PS) (Thorpe, 1984). A* PS runs A* grids
smoothes resulting path post-processing step, often shortens increase
runtime. Algorithm 2 shows pseudocode simple smoothing algorithm A* PS uses
experiments (Botea, Muller, & Schaeffer, 2004), provides good tradeoff
runtime path length. Assume A* grids finds path [s0 , s1 , . . . , sn ] s0 = sstart
sn = sgoal . A* PS uses first vertex path current vertex. checks whether
current vertex s0 line-of-sight successor s2 successor path. so, A*
PS removes intermediate vertex s1 path, thus shortening it. A* PS repeats
procedure checking whether current vertex s0 line-of-sight successor s3
successor path, on. soon current vertex line-of-sight
successor successor path, A* PS advances current vertex repeats procedure
reaches end path. use straight-line distances h(s) = c(s, sgoal ) h-values
experiments.
A* PS typically finds shorter paths A* grids, guaranteed find true shortest paths.
Figure 3 shows example. Assume A* PS finds dotted blue path, one many
shortest grid paths. smoothes path solid blue path, true shortest
path. dashed red path, moves (rather below) blocked cell B2-B3-C3-C2
true shortest path. A* PS guaranteed find true shortest paths considers grid
paths A* search thus cannot make informed decisions regarding paths
A* search, motivates interleaving searching smoothing. fact, Theta* similar
A* PS except interleaves searching smoothing.
4.3 Field D* (FD*)
One run Field D* (Ferguson & Stentz, 2006) (FD*). FD* propagates information along grid
edges without constraining paths grid edges. FD* designed use D* Lite (Koenig &
Likhachev, 2002) fast replanning (by reusing information previous A* search speed
next one) searches goal vertex start vertex. version FD* uses
A* searches start vertex goal vertex, like path-planning algorithms
article, allows us compare fairly, except replanning abilities. (Theta*
currently process extended fast replanning Nash, Koenig, & Likhachev, 2009.)
539

fiDANIEL , NASH , KOENIG , & F ELNER

1

B

2

3

4

2.00

2.32

2.83

1.00

1.41

2.41

5

sgoal
0.45



C



0.55

X

sstart
0.00

1.00

2.00

3.00

1.00

1.41

2.32

3.27

Field D* path
Figure 4: FD* path

Figure 5: Screenshot FD* path versus true shortest path
FD* updates g-value parent unexpanded visible neighbor vertex s,
considers paths start vertex point X (not necessarily vertex) perimeter
vertex [= g(X)] line-of-sight vertex , perimeter formed connecting
neighbors vertex , point X vertex straight line [= c(X, )], resulting
length g(X) + c(X, ). FD* updates g-value parent vertex considered
path shorter shortest path start vertex vertex found far [= g(s )]. use
straight-line distances h(s) = c(s, sgoal ) h-values experiments.
Figure 4 shows example. perimeter vertex = B4 formed connecting
neighbors vertex B4, shown bold. Consider point X perimeter. FD* know
g-value point X since stores g-values vertices. calculates g-value using
linear interpolation g-values two vertices perimeter adjacent
point X. Thus, linearly interpolates g(B3) = 2.41 g(C3) = 2.00, resulting
g(X) = 0.55 2.41 + 0.45 2.00 = 2.23 since 0.55 0.45 distances point X
vertices B3 C3, respectively. calculated g-value point X different true start
distance [= 2.55] even though g-values vertices B3 C3 equal true start
distances. reason mistake simple. exist true shortest paths start vertex
either vertex C3 vertex B3 goal vertex. Thus, linear interpolation assumption
predicts must also exist short path start vertex point along
edge connects vertices B3 C3 goal vertex. However, case since
540

fiT HETA *: NY-A NGLE PATH P LANNING



1

2

3

4



G RIDS

5

start

B

C

goal
true shortest path
(a) Simple visibility graph

(b) Terrain resulting complex visibility graph

Figure 6: Visibility graphs
paths need circumnavigate blocked cell B2-B3-C3-C2, makes longer expected.
result miscalculating g-value point X, FD* sets parent vertex B4 point X,
resulting path unnecessary heading change point X longer even
shortest grid path.
authors FD* recognize paths found FD* frequently unnecessary heading
changes suggest use one-step look-ahead algorithm path extraction (Ferguson &
Stentz, 2006), FD* uses experiments. one-step look-ahead algorithm allows FD*
avoid unnecessary heading changes, like one Figure 4, eliminate
them. Figure 5 shows example FD* path red corresponding true shortest
path blue. FD* path still many unnecessary heading changes.
4.4 A* Visibility Graphs
One run A* visibility graphs. visibility graph grid blocked unblocked
cells contains start vertex, goal vertex corners blocked cells (Lozano-Perez &
Wesley, 1979). use straight-line distances h(s) = c(s, sgoal ) h-values experiments.
A* visibility graphs finds true shortest paths, shown Figure 6(a). True shortest paths
heading changes corners blocked cells, paths found A* grids, A* PS
FD* unnecessary heading changes. hand, A* visibility graphs
slow. propagates information along visibility graph edges, whose number grow quadratically
number cells, A* grids, A* PS FD* propagate information along grid edges,
whose number grows linearly number cells. one constructed visibility graphs
A* search, one would need perform line-of-sight check every pair corners
blocked cells determine whether visibility graph edge them,
requires least 2,556 line-of-sight checks room Figure 6(b) (Tozour, 2004).
number line-of-sight checks performed A* visibility graphs reduced constructing
541

fiDANIEL , NASH , KOENIG , & F ELNER

41 UpdateVertex(s,s)
42
LineOfSight(parent(s), )
43
/* Path 2 */
44
g(parent(s)) + c(parent(s), ) < g(s )
45
g(s ) := g(parent(s)) + c(parent(s), );
46
parent(s ) := parent(s);
47
open
48
open.Remove(s );
open.Insert(s , g(s ) + h(s ));

49
50
51
52
53
54
55
56
57

else
/* Path 1 */
g(s) + c(s, ) < g(s )
g(s ) := g(s) + c(s, );
parent(s ) := s;
open
open.Remove(s );
open.Insert(s , g(s ) + h(s ));

58 end

Algorithm 3: Basic Theta*

visibility graphs A* search. expands vertex, performs line-of-sight checks
expanded vertex corners blocked cells (and goal vertex).
significantly reduce number line-of-sight checks performed environments,
simple outdoor terrain, fails others, cluttered indoor terrain.
complex optimizations, reduced visibility graphs reduce number line-ofsight checks, sufficiently speed A* visibility graphs (Liu & Arimoto, 1992).

5. Basic Theta*
section, introduce Theta* (Nash et al., 2007), version A* any-angle path
planning propagates information along grid edges without constraining paths grid edges.
combines ideas behind A* visibility graphs (where heading changes occur
corners blocked cells) A* grids (where number edges grows linearly
number cells). paths slightly longer true shortest paths (as found A*
visibility graphs), yet slightly slower A* grids, shown Figure 2. key
difference Theta* A* grids parent vertex vertex
using Theta*, parent vertex neighbor vertex using A*.
first introduce Basic Theta*, simple version Theta*.
Algorithm 3 shows pseudocode Basic Theta*. Procedure Main identical A*
Algorithm 1 thus shown. Line 13 ignored. use straight-line distances
h(s) = c(s, sgoal ) h-values experiments.
5.1 Operation Basic Theta*
Basic Theta* simple. identical A* except that, updates g-value parent
unexpanded visible neighbor vertex procedure UpdateVertex, considers two paths
542

fiT HETA *: NY-A NGLE PATH P LANNING

1

2

3

4



1

sgoal



B



C

Path 1

G RIDS

2

3

4



sstart

B

C

5



Path 2

sstart





sgoal

Path 1

(a) Path 2 unblocked

5

Path 2

(b) Path 2 blocked

Figure 7: Paths 1 2 considered Basic Theta*

instead one path considered A*. Figure 7(a) shows example. Basic Theta*
expanding vertex B3 parent A4 needs update g-value parent unexpanded
visible neighbor C3. Basic Theta* considers two paths:

Path 1: Basic Theta* considers path start vertex vertex [= g(s)]
vertex vertex straight line [= c(s, )], resulting length g(s) + c(s, ) [Line
52]. Path 1 path considered A*. corresponds dashed red path [A4, B3, C3]
Figure 7(a)).
Path 2: Basic Theta* also considers path start vertex parent vertex [=
g(parent(s))] parent vertex vertex straight line [= c(parent(s), )],
resulting length g(parent(s)) + c(parent(s), ) [Line 44]. Path 2 considered
A* allows Basic Theta* construct any-angle paths. corresponds solid blue
path [A4, C3] Figure 7(a).

Path 2 longer Path 1 due triangle inequality. triangle inequality states
length side triangle longer sum lengths two sides.
applies since Path 1 consists path start vertex parent vertex s,
straight line parent vertex vertex (Line A) straight line vertex
vertex (Line B), Path 2 consists path start vertex parent vertex
straight line parent vertex vertex (Line C) Lines A, B C form
triangle. Path 1 guaranteed unblocked Path 2 not. Thus, Basic Theta* chooses Path
2 Path 1 vertex line-of-sight parent vertex Path 2 thus unblocked.
Figure 7(a) shows example. Otherwise, Basic Theta* chooses Path 1 Path 2. Figure 7(b)
shows example. Basic Theta* updates g-value parent vertex chosen path
shorter shortest path start vertex vertex found far [= g(s )]. use
straight-line distances h(s) = c(s, sgoal ) h-values experiments.
543

fiDANIEL , NASH , KOENIG , & F ELNER

1

2

5

4

3

1



1.00

0.00

1.00

A4

sstart

A4

B

1.41

1.00

1.41

A4

A4

A4

C

sgoal

2

3

B

C

A4

sgoal

2

1.00

A4

sstart

A4

2.41

1.41

1.00

1.41

B3

A4

A4

A4

2.83

2.24

2.00

A4

A4

A4

(b)

3

4

3.82

3.41

1.00

0.00

1.00

B2

B2

A4

sstart

A4

B

3.41

2.41

1.41

1.00

1.41

B3

B3

A4

A4

A4

3.65

2.83

2.24

2.00

B3

A4

A4

A4

sgoal

1

5



C

5

0.00

(a)
1

4
1.00



2

3

4

5



3.82

3.41

1.00

0.00

1.00

B2

B2

A4

sstart

A4

B

3.41

2.41

1.41

1.00

1.41

B3

B3

A4

A4

A4

C

3.65

2.83

2.24

2.00

B3

A4

A4

A4

sgoal

(c)

(d)

Figure 8: Example trace Basic Theta*

5.2 Example Trace Basic Theta*
Figure 8 shows example trace Basic Theta*. vertices labeled g-values
parents. arrows point parents. Red circles indicate vertices expanded,
blue arrows indicate vertices generated current expansion. First, Basic Theta*
expands start vertex A4 parent A4, shown Figure 8(a). sets parent unexpanded
visible neighbors vertex A4 vertex A4, like A* would do. Second, Basic Theta* expands
vertex B3 parent A4, shown Figure 8(b). Vertex B2 unexpanded visible neighbor
vertex B3 line-of-sight vertex A4. Basic Theta* thus updates according
Path 1 sets parent vertex B3. hand, vertices C2, C3 C4 unexpanded
visible neighbors vertex B3 line-of-sight vertex A4. Basic Theta* thus updates
according Path 2 sets parents vertex A4. (The g-values parents
unexpanded visible neighbors vertex B3 updated.) Third, Basic Theta* expands vertex
B2 parent B3, shown Figure 8(c). Vertices A1 A2 unexpanded visible neighbors
vertex B2 line-of-sight vertex B3. Basic Theta* thus updates according
Path 1 sets parents vertex B2. hand, vertices B1 C1 unexpanded
visible neighbors vertex B2 line-of-sight vertex B3. Basic Theta* thus updates
according Path 2 sets parents vertex B3. Fourth, Basic Theta* expands goal
vertex C1 parent B3 terminates, shown Figure 8(d). Path extraction follows
parents goal vertex C1 start vertex A4 retrieve true shortest path [A4, B3, C1]
start vertex goal vertex reverse.
544

fiT HETA *: NY-A NGLE PATH P LANNING



G RIDS

5.3 Properties Basic Theta*
discuss properties Basic Theta*.
5.3.1 C ORRECTNESS



C OMPLETENESS

Basic Theta* correct (that is, finds unblocked paths start vertex goal vertex)
complete (that is, finds path start vertex goal vertex one exists). use
following lemmata proof.
Lemma 1. exists unblocked path two vertices also exists unblocked
grid path two vertices.
Proof. unblocked path two vertices exists iff unblocked any-angle path [s0 , . . . , sn ]
exists two vertices. Consider path segment sk sk+1 any-angle path.
path segment horizontal vertical, consider unblocked grid path vertex sk
vertex sk+1 coincides path segment. Otherwise, consider sequence (b0 , . . . , bm )
unblocked cells whose interior path segment passes through. two consecutive cells
bj bj+1 share least one vertex sj+1 since cells either share edge diagonally
touching. (If share one vertex, pick one arbitrarily.) Consider grid path [s0 =
sk , s1 , . . . , sm , sm+1 = sk+1 ]. grid path vertex sk vertex sk+1 unblocked since
two consecutive vertices corners unblocked cell thus visible neighbors.
Repeat procedure every path segment any-angle path concatenate resulting
grid paths unblocked grid path vertex s0 vertex sn . (If several consecutive vertices
grid path identical, one removed.)
Lemma 2. point execution Basic Theta*, following parents vertex
open closed lists start vertex retrieves unblocked path start vertex
vertex reverse.
Proof. prove induction lemma holds parent vertex union
open closed lists union open closed lists. statement holds
initially start vertex vertex union open closed lists
parent. show statement continues hold whenever vertex changes either
parent membership union open closed lists. vertex member
union open closed lists, continues member. vertex become member
union open closed lists Basic Theta* expands vertex updates
g-value parent unexpanded visible neighbor vertex procedure UpdateVertex.
Vertex thus closed list, parent union open closed lists according
induction assumption. Thus, following parents vertex (or parent) start
vertex retrieves unblocked path start vertex vertex (or parent, respectively)
reverse according induction assumption. Basic Theta* updates vertex according Path
1, statement continues hold since vertices visible neighbors path
segment vertex vertex thus unblocked. Basic Theta* updates vertex according
Path 2, statement continues hold since Basic Theta* explicitly checks path
545

fiDANIEL , NASH , KOENIG , & F ELNER

segment parent vertex vertex unblocked. ways
parent vertex change.
Theorem 1. Basic Theta* terminates path extraction retrieves unblocked path start
vertex goal vertex path exists. Otherwise, Basic Theta* terminates reports
unblocked path exists.
Proof. following properties together prove theorem. proofs utilize fact Basic
Theta* terminates iff open empty expands goal vertex. start vertex initially
open list. vertex initially neither open closed lists. vertex neither
open closed lists inserted open list. vertex open list removed
open list inserted closed list. vertex closed list remains closed list.
Property 1: Basic Theta* terminates. expands one vertex open list
iteration. process, removes vertex open list never insert
open list again. Since number vertices finite, open list eventually becomes
empty Basic Theta* terminate terminated earlier already.
Property 2: Basic Theta* terminates open list empty,
exist unblocked path start vertex goal vertex. prove contrapositive.
Assume exists unblocked path start vertex goal vertex. prove
contradiction Basic Theta* terminate open list empty.
Thus, assume also Basic Theta* terminates open list empty. Then,
exists unblocked grid path [s0 = sstart , . . . , sn = sgoal ] start vertex goal
vertex according Lemma 1. Choose vertex si first vertex grid path
closed list Basic Theta* terminates. goal vertex closed list
Basic Theta* terminates since Basic Theta* would otherwise terminated
expanded goal vertex. Thus, vertex si exists. Vertex si start vertex since start
vertex would otherwise open list Basic Theta* could terminated
open list empty. Thus, vertex si predecessor grid path. predecessor
closed list Basic Theta* terminates since vertex si first vertex grid
path closed list Basic Theta* terminates. Basic Theta* expanded
predecessor, added vertex si open list. Thus, vertex si still open list
Basic Theta* terminates. Basic Theta* could terminated open
list empty, contradiction.
Property 3: Basic Theta* terminates expands goal vertex, path extraction
retrieves unblocked path start vertex goal vertex following
parents goal vertex start vertex retrieves unblocked path start
vertex goal vertex reverse according Lemma 2.

546

fiT HETA *: NY-A NGLE PATH P LANNING



1

2

3

4

5



G RIDS

6

7

8

9

10

6

7

8

9

10

B

C



E

start

(a)


1

2

3

4

5

B

C



E

start

(b)

true shortest path

Basic Theta* path

Figure 9: Basic Theta* paths versus true shortest paths

5.3.2 PTIMALITY
Basic Theta* optimal (that is, guaranteed find true shortest paths)
parent vertex either visible neighbor vertex parent visible neighbor,
always case true shortest paths. Figure 9(a) shows example dashed
red path [E1, B9] true shortest path start vertex E1 vertex B9 since vertex E1 lineof-sight vertex B9. However, vertex E1 neither visible neighbor parent visible
neighbor vertex B9 since vertex E1 line-of-sight vertices (highlighted
red). Thus, Basic Theta* cannot set parent vertex B9 vertex E1 find true
shortest path vertex E1 vertex B9. Similarly, Figure 9(b) shows example
dashed red path [E1, D8, C10] true shortest path vertex E1 vertex C10. However, vertex
D8 neither visible neighbor parent visible neighbor vertex C10 since start vertex
E1 either line-of-sight Basic Theta* found paths vertex E1
547

fiDANIEL , NASH , KOENIG , & F ELNER



1 sstart

2

3

4

5

6

B

C

f=6.02


f=6.00

true shortest path

sgoal
f=6.00

Basic Theta* path

Figure 10: Heading changes Basic Theta*

contain vertex D8. fact, truly shortest paths vertex E1 visible neighbors vertex
C10 vertex E1 line-of-sight move (rather below) blocked cell C7C8-D8-D7. Thus, Basic Theta* cannot set parent vertex C10 vertex D8 thus
find true shortest path vertex E1 vertex C10. solid blue path vertex E1 vertex
B9 Figure 9(a) solid blue path vertex E1 vertex C10 Figure 9(b) less
factor 1.002 longer true shortest paths.
5.3.3 H EADING C HANGES
Basic Theta* takes advantage fact true shortest paths heading changes
corners blocked cells. However, paths found Basic Theta* occasionally
unnecessary heading changes. Figure 10 shows example Basic Theta* finds solid blue
path [A1, D5, D6] vertex A1 vertex D6. reason mistake simple. Assume
open list contains vertices C5 D5. f-value vertex C5 f (C5) = g(C5) +
h(C5) = 4.61 + 1.41 = 6.02 parent vertex C4. f-value vertex D5 f (D5) =
5.00 + 1.00 = 6.00 parent vertex A1. Thus Basic Theta* expands vertex D5
vertex C5 (since f-value smaller). Basic Theta* expands vertex D5 parent A1,
generates vertex D6. Vertex D6 unexpanded visible neighbor vertex D5
line-of-sight vertex A1. Basic Theta* thus updates according Path 1, sets f-value
f (D6) = 6.00 + 0.00 = 6.00, sets parent vertex D5 inserts open list. Thus
Basic Theta* expands goal vertex D6 vertex C5 (since f-value smaller) terminates.
Path extraction follows parents goal vertex D6 start vertex A1 retrieve solid
blue path [A1, D5, D6]. Thus, Basic Theta* never expands vertex C5, would resulted
setting parent vertex D6 vertex C4 according Path 2 path extraction retrieving
dashed red path [A1, C4, D6] true shortest path. solid blue path vertex A1
vertex D6 Figure 10 less factor 1.027 longer true shortest path.
548

fiT HETA *: NY-A NGLE PATH P LANNING



G RIDS

59 UpdateVertex(s,s)
60
6= sstart lb(s) (s, parent(s), ) ub(s)
61
/* Path 2 */
62
g(parent(s)) + c(parent(s), ) < g(s )
63
g(s ) := g(parent(s)) + c(parent(s), );
64
parent(s ) := parent(s);
65
open
66
open.Remove(s );
open.Insert(s , g(s ) + h(s ));

67
68
69
70
71
72
73
74
75

else
/* Path 1 */
g(s) + c(s, ) < g(s )
g(s ) := g(s) + c(s, );
parent(s ) := s;
open
open.Remove(s );
open.Insert(s , g(s ) + h(s ));

76 end
77 UpdateBounds(s)
78
lb(s) := ; ub(s) := ;
79
6= sstart
80
foreach blocked cell b adjacent
81
corners(b) : parent(s) = (s, parent(s), ) < 0
82
((s, parent(s), ) = 0 c(parent(s), ) c(parent(s), s))
83
lb(s) = 0;
84
85
86
87
88
89
90
91
92
93
94
95
96
97

corners(b) : parent(s) = (s, parent(s), ) > 0
((s, parent(s), ) = 0 c(parent(s), ) c(parent(s), s))
ub(s) = 0;
foreach nghbrsvis (s)
closed parent(s) = parent(s ) 6= sstart
lb(s ) + (s, parent(s), ) 0
lb(s) := max(lb(s), lb(s ) + (s, parent(s), ));
ub(s ) + (s, parent(s), ) 0
ub(s) := min(ub(s), ub(s ) + (s, parent(s), ));
c(parent(s), ) < c(parent(s), s) parent(s) 6= (s 6 closed parent(s) 6= parent(s ))

(s, parent(s), ) < 0
lb(s) := max(lb(s), (s, parent(s), ));
(s, parent(s), ) > 0
ub(s) := min(ub(s), (s, parent(s), ));

98 end

Algorithm 4: AP Theta*

6. Angle-Propagation Theta* (AP Theta*)
runtime Basic Theta* per vertex expansion (that is, runtime consumed generation unexpanded visible neighbors expanding vertex) linear number
cells since runtime line-of-sight check linear number cells.
section, introduce Angle-Propagation Theta* (AP Theta*), reduces runtime Basic
549

fiDANIEL , NASH , KOENIG , & F ELNER



1

2

B

3

4



1

5

6



2

C



E



F

Figure 11: Region points line-of-sight vertex
Theta* per vertex expansion linear constant.1 key difference AP Theta*
Basic Theta* AP Theta* propagates angle ranges uses determine whether
two vertices line-of-sight.
light source vertex light cannot pass blocked cells, cells
shadows line-of-sight vertex cells line-of-sight vertex.
contiguous region points line-of-sight vertex characterized two
rays emanating vertex thus angle range defined two angle bounds. Figure
11 shows example points within red angle range defined two angle bounds
1 2 line-of-sight vertex s. AP Theta* calculates angle range vertex
expands vertex propagates along grid edges, resulting constant runtime per
vertex expansion since angle ranges propagated constant time line-of-sight
checks performed constant time well.
Algorithm 4 shows pseudocode AP Theta*. Procedure Main identical A*
Algorithm 1 thus shown. Line 13 executed. use straight-line distances
h(s) = c(s, sgoal ) h-values experiments.
6.1 Definition Angle Ranges
discuss key concept angle range. AP Theta* maintains two additional values
every vertex s, namely lower angle bound lb(s) vertex upper angle bound ub(s)
vertex s, together form angle range [lb(s), ub(s)] vertex s. angle bounds correspond
headings rays (measured degrees) originate parent vertex s. heading
ray parent vertex vertex zero degrees. visible neighbor vertex
guaranteed line-of-sight parent vertex (but necessarily if) heading
ray parent vertex visible neighbor vertex contained angle
1. AP Theta* provides significant improvement worst case complexity Basic Theta*, experimental results Section 7 show slower finds slightly longer paths Basic Theta*.

550

fiT HETA *: NY-A NGLE PATH P LANNING

1

2

3

4





G RIDS

5

sstart
lb

B

18O


27
C

sgoal



ub

Figure 12: Angle range AP Theta*
range vertex s. Figure 12 shows example vertex C3 parent A4 angle range
[18, 27]. Thus, visible neighbors vertex C3 red region guaranteed line-ofsight parent vertex C3. example, vertex C4 guaranteed line-of-sight
parent vertex C3 vertex B2 not. AP Theta* therefore assumes vertex B2
line-of-sight parent vertex C3.
define concept angle range formally. (s, p, ) [90, 90], gives
AP Theta* name, angle (measured degrees) ray vertex p vertex
ray vertex p vertex . positive ray vertex p vertex clockwise
ray vertex p vertex , zero ray vertex p vertex heading
ray vertex p vertex , negative ray vertex p vertex counterclockwise
ray vertex p vertex . Figure 12 shows example (C3, A4, C4) = 27
(C3, A4, B3) = 18. visible neighbor vertex guaranteed line-of-sight
parent vertex (but necessarily if) lb(s) (s, parent(s), ) ub(s) (Visibility
Property).
6.2 Update Angle Ranges
discuss AP Theta* calculates angle range vertex expands vertex.
calculation complicated fact AP Theta* guaranteed sufficient
information determine angle range exactly since order vertex expansions depends
variety factors, h-values. case, AP Theta* constrain angle range
necessary guarantee Visibility Property holds finds unblocked paths.
AP Theta* expands vertex s, sets angle range vertex initially [, ], meaning
visible neighbors vertex guaranteed line-of-sight parent vertex.
constrains angle range vertex start vertex.
AP Theta* constrains angle range vertex based blocked cell b adjacent
vertex (that is, vertex corner b, written corners(b)) provided least one
two conditions satisfied:
Case 1: every corner blocked cell b satisfies least one following conditions:
parent(s) =
551

fiDANIEL , NASH , KOENIG , & F ELNER

(s, parent(s), ) < 0
(s, parent(s), ) = 0 c(parent(s), ) c(parent(s), s),
AP Theta* assumes vertex line-of-sight parent vertex
ray parent vertex vertex counterclockwise ray
parent vertex vertex , is, (s, parent(s), ) < 0. AP Theta* therefore sets
lower angle bound vertex (s, parent(s), s) = 0 [Line 83].
Case 2: every corner blocked cell b satisfies least one following conditions:
parent(s) =
(s, parent(s), ) > 0
(s, parent(s), ) = 0 c(parent(s), ) c(parent(s), s),
AP Theta* assumes vertex line-of-sight parent vertex
ray parent vertex vertex clockwise ray parent
vertex vertex , is, (s, parent(s), ) > 0. AP Theta* therefore sets upper
angle bound vertex (s, parent(s), s) = 0 [Line 86].
AP Theta* also constrains angle range vertex based visible neighbor vertex
provided least one two conditions satisfied:
Case 3: vertex satisfies following conditions:
closed

parent(s) = parent(s )
6= sstart ,
AP Theta* constrains angle range vertex intersecting angle range
vertex [Lines 90 92]. that, first shifts angle range vertex
(s, parent(s), ) degrees take account angle range vertex calibrated
heading ray joint parent vertices vertex zero
degrees, angle range vertex calibrated heading ray
joint parent vertices vertex zero degrees. Lines 89 91 ensure
lower angle bound always remains non-positive upper angle bound always remains
non-negative, respectively. fact lower angle bounds non-positive (and
upper angle bounds non-negative) intuitive vertex assigned parent vertex p
angle ray vertex p vertex included angle range
vertex s.
Case 4: vertex satisfies following conditions:
c(parent(s), ) < c(parent(s), s)
parent(s) 6=
552

fiT HETA *: NY-A NGLE PATH P LANNING



G RIDS

6 closed parent(s) 6= parent(s ),
AP Theta* insufficient information vertex . AP Theta* therefore cannot
determine angle range vertex exactly makes conservative assumption
vertex barely line-of-sight parent vertex [Lines 95 97].
Visibility Property holds AP Theta* updated angle range vertex procedure
UpdateBounds. Thus, AP Theta* checks whether visible neighbor vertex
line-of-sight parent vertex s, checks whether lb(s) (s, parent(s), )
ub(s) [Line 60] true instead whether LineOfSight(parent(s), ) [Line 42] true .
differences AP Theta* Basic Theta*.
Figure 13(a) shows example AP Theta* calculates angle range vertex A4. sets
angle range [, ]. Figure 13(b) shows example AP Theta* calculates angle
range vertex B3. sets angle range initially [, ]. sets lower angle bound
0 degrees according Case 1 based blocked cell A2-A3-B3-B2 [Line 83]. sets
upper angle bound 45 degrees according Case 4 based vertex B4, unexpanded
thus closed list [Line 97]. Figure 13(c) shows example AP Theta* calculates
angle range vertex B2. sets angle range initially [, ]. sets lower
angle bound 0 degrees according Case 1 based blocked cell A2-A3-B3-B2 [Line 83].
Assume vertex C1 goal vertex. Figure 13(d) shows example AP Theta*
calculates angle range vertex C1. sets angle range initially [, ]. sets
lower angle bound -27 degrees according Case 3 based vertex B2 [Line 90] upper
angle bound 18 degrees according Case 4 based vertex C2, unexpanded thus
closed list [Line 97].
6.3 Example Trace AP Theta*
Figure 13 shows example trace AP Theta* using path-planning problem Figure 8.
labels vertices include angle ranges.
6.4 Properties AP Theta*
discuss properties AP Theta*. AP Theta* operates way Basic Theta*
thus similar properties Basic Theta*. example, AP Theta* correct complete.
guaranteed find true shortest paths, paths occasionally unnecessary heading
changes.
AP Theta* sometimes constrains angle ranges necessary guarantee finds
unblocked paths, means line-of-sight checks sometimes fail incorrectly case
update vertices according Path 1 rather Path 2. AP Theta* still complete since
finds unblocked grid path line-of-sight checks fail, always exists unblocked
grid path exists unblocked any-angle path. However, paths found AP Theta*
longer found Basic Theta*. Figure 14 shows example. AP Theta* expands
vertex C4 parent B1 calculates angle range vertex C4, vertex C3 unexpanded
thus closed list. means AP Theta* insufficient information vertex
553

fiDANIEL , NASH , KOENIG , & F ELNER

2

3

4

1

5

1.00

0.00

1.00

A4

sstart

A4

3

4

1.00
A4

]

8
8

[ ,

2



B

1.41

1.00

1.41

A4

A4

A4

C

2.41

1.41

1.00

1.41

B3

A4
[0,45]

A4

A4

C

2.83

2.24

2.00

A4

A4

A4

2

(b)

3

3.82

3.41

B2

B2

4

1

5

0.00

1.00
A4

1.00
A4

sstart

2

3

3.82

3.41

B2

B2

4
1.00
A4

]

2.41

B3

B3
[0, ]

C

3.65

2.83

B3

A4

1.41
A4
[0,45]

1.00
A4

2.24
A4

2.00
A4

B

1.41
A4

3.41

2.41

B3

B3
[0, ]

3.65

2.83

B3
[27,18]

A4

8

3.41

8

B

5

0.00

sstart

1.00
A4

[ , ]

8
8

[ ,



8
8

1

1.00
A4

sstart
[ , ]

B

(a)


5

0.00
8
8

1


C

(c)

1.41
A4
[0,45]

1.00
A4

2.24
A4

2.00
A4

1.41
A4

(d)

Figure 13: Example trace AP Theta*
1

2

3

4

5

6




B

C



start

1111
0000
0000
1111
0000
1111
0000
1111
0000
1111
0000
1111
0000
1111
0000
1111
0000
1111

sgoal

Basic Theta* path

AP Theta* path

Figure 14: Basic Theta* path versus AP Theta* path
C3 because, example, know whether cell C2-C3-D3-D2 unblocked. AP
Theta* therefore cannot determine angle range vertex C4 exactly makes conservative
assumption vertex C3 barely line-of-sight vertex B1 sets lower angle bound
vertex C4 according Case 4 based vertex C3. uses resulting angle range
determine unexpanded visible neighbor D4 vertex C4 guaranteed line-ofsight vertex B1. However, vertex D4 line-of-sight vertex B1 cell C2-C3-D3-D2
554

fiT HETA *: NY-A NGLE PATH P LANNING



G RIDS

Figure 15: Map Baldurs Gate II
unblocked. AP Theta* eventually finds solid blue path [B1, C3, D4] start vertex B1
vertex D4, Basic Theta* finds dashed red path [B1, D4], true shortest path.
correctness completeness proof Basic Theta* needs get changed slightly AP Theta*
since AP Theta* performs line-of-sight checks differently.
Theorem 2. AP Theta* terminates path extraction retrieves unblocked path start
vertex goal vertex path exists. Otherwise, AP Theta* terminates reports
unblocked path exists.
Proof. proof similar proof Theorem 1 since AP Theta* uses angle ranges
determine whether Path 2 blocked determine whether Path 1 blocked.
property needs proved differently two vertices indeed line-of-sight
(but necessarily if) line-of-sight check AP Theta* succeeds, see Appendix B.

7. Experimental Results
section, compare Basic Theta* AP Theta* A* grids, A* PS, FD* A*
visibility graphs respect path length, number vertex expansions, runtime (measured
seconds) number heading changes.
compare path-planning algorithms 100 100 500 500 grids different percentages randomly blocked cells (random grids) scaled maps real-time strategy
game Baldurs Gate II (game maps). Figure 15 (Bulitko, Sturtevant, & Kazakevich, 2005) shows
example game map. start goal vertices south-west corners cells. random
grids, start vertex south-west cell. goal vertex cell randomly chosen
column cells furthest east. Cells blocked randomly one-unit border unblocked
cells guarantees path start vertex goal vertex. game maps, start
goal vertices randomly chosen corners unblocked cells. average 500
random 100 100 grids, 500 random 500 500 grids 118 game maps.
555

fiDANIEL , NASH , KOENIG , & F ELNER

500500

100100

FD*
Game Maps
Random Grids 0%
Random Grids 5%
Random Grids 10%
Random Grids 20%
Random Grids 30%
Game Maps
Random Grids 0%
Random Grids 5%
Random Grids 10%
Random Grids 20%
Random Grids 30%

40.04
114.49
114.15
114.74
115.20
115.45
223.64
576.19
568.63
576.23
580.19
581.73

Basic Theta* AP Theta* A* Visibility Graphs A* Grids
(true shortest path)
39.98
40.05
39.96
41.77
114.33
114.33
114.33
120.31
113.94
113.94
113.83
119.76
114.51
114.51
114.32
119.99
114.93
114.95
114.69
120.31
115.22
115.25
114.96
120.41
223.30
224.40
N/A
233.66
575.41
575.41
N/A
604.80
567.30
567.34
N/A
596.45
574.57
574.63
N/A
603.51
578.41
578.51
N/A
604.93
580.18
580.35
N/A
606.38

A* PS
40.02
114.33
114.71
115.46
116.16
116.69
223.70
575.41
573.46
581.03
585.62
588.98

Table 1: Path length

500500

100100

FD*
Game Maps
Random Grids 0%
Random Grids 5%
Random Grids 10%
Random Grids 20%
Random Grids 30%
Game Maps
Random Grids 0%
Random Grids 5%
Random Grids 10%
Random Grids 20%
Random Grids 30%

0.0111
0.0229
0.0275
0.0305
0.0367
0.0429
0.1925
0.3628
0.4514
0.5608
0.6992
0.8562

Basic Theta* AP Theta* A* Visibility Graphs A* Grids
(true shortest path)
0.0060
0.0084
0.4792
0.0048
0.0073
0.0068
0.0061
0.0053
0.0090
0.0111
0.0766
0.0040
0.0111
0.0145
0.3427
0.0048
0.0150
0.0208
1.7136
0.0084
0.0183
0.0263
3.7622
0.0119
0.1166
0.1628
N/A
0.0767
0.1000
0.0234
N/A
0.0122
0.1680
0.1962
N/A
0.0176
0.2669
0.3334
N/A
0.0573
0.3724
0.5350
N/A
0.1543
0.5079
0.7291
N/A
0.3238

A* PS
0.0052
0.0208
0.0206
0.0204
0.0222
0.0240
0.1252
0.6270
0.6394
0.6717
0.6852
0.7355

Table 2: Runtime

500500

100100

FD*
Game Maps
Random Grids 0%
Random Grids 5%
Random Grids 10%
Random Grids 20%
Random Grids 30%
Game Maps
Random Grids 0%
Random Grids 5%
Random Grids 10%
Random Grids 20%
Random Grids 30%

247.07
592.74
760.17
880.21
1175.42
1443.44
6846.62
11468.11
15804.81
19874.62
26640.83
34313.28

Basic Theta* AP Theta* A* Visibility Graphs A* Grids
(true shortest path)
228.45
226.42
68.23
197.19
240.42
139.53
1.00
99.00
430.06
361.17
35.35
111.96
591.31
520.91
106.23
169.98
851.79
813.14
357.33
386.41
1113.40
1089.96
659.36
620.18
6176.37
6220.58
N/A
5580.32
2603.40
663.34
N/A
499.00
7450.85
5917.25
N/A
755.66
11886.95
10405.34
N/A
2203.83
18621.61
17698.75
N/A
6777.15
25744.57
25224.92
N/A
14641.36

A* PS
315.08
1997.29
1974.27
1936.56
2040.10
2153.28
9673.88
49686.47
49355.41
50924.01
50358.66
53732.82

Table 3: Number vertex expansions

path-planning algorithms implemented C# executed 3.7 GHz Core 2 Duo 2
GByte RAM. implementations optimized possibly improved.
556

fiT HETA *: NY-A NGLE PATH P LANNING

500500

100100

FD*
Game Maps
Random Grids 0%
Random Grids 5%
Random Grids 10%
Random Grids 20%
Random Grids 30%
Game Maps
Random Grids 0%
Random Grids 5%
Random Grids 10%
Random Grids 20%
Random Grids 30%

34.25
123.40
113.14
106.66
98.76
96.27
219.70
667.00
592.65
559.69
506.10
481.16

G RIDS



Basic Theta* AP Theta* A* Visibility Graphs A* Grids
(true shortest paths)
3.08
3.64
2.92
5.21
0.00
0.00
0.00
0.99
5.14
6.03
5.06
6.00
8.96
9.87
8.84
10.85
15.21
15.96
14.74
19.42
19.96
20.62
19.44
26.06
4.18
7.58
N/A
10.19
0.00
0.00
N/A
1.00
21.91
27.99
N/A
24.68
41.60
47.40
N/A
49.73
72.49
76.79
N/A
91.40
97.21
100.31
N/A
123.81

A* PS
2.83
0.00
4.53
8.48
14.45
18.35
3.84
0.00
22.27
43.16
69.44
89.43

592

0.9

589

0.8

586

0.7

583

0.6

580

0.5

Runtime

Path Length

Table 4: Number heading changes

577

0.4

574

0.3

571

0.2

568

0.1

565

0
0

5

10

20

30

0

5

10

% Blocked
FD*

Basic Theta*

20

30

% Blocked

AP Theta*

A* PS

FD*

Basic Theta*

(a) Path length

AP Theta*

A* PS

A*

(b) Runtime

60000

800

700

Number Heading Changes

50000

Vertex Expansions

40000

30000

20000

600

500

400

300

200
10000
100

0

0
0

5

10

20

30

0

5

% Blocked
FD*

Basic Theta*

10

20

30

% Blocked

AP Theta*

A* PS

A*

FD*

(c) Number vertex expansions

Basic Theta*

AP Theta*

A* PS

A*

(d) Number heading changes

Figure 16: Random 500 500 grids

557

fiDANIEL , NASH , KOENIG , & F ELNER

99 h(s)
x := |s.x (sgoal ).x|;
100
:= |s.y (sgoal ).y|;
101

102
largest := max(x , );
103
smallest := min(x , );

104
return 2 smallest + (largest smallest);
105 end

Algorithm 5: Calculation octile distances

A* grids, A* PS, FD* A* visibility graphs break ties among vertices fvalue open list favor vertices larger g-values (when decide vertex
expand next) since tie-breaking scheme typically results fewer vertex expansions thus
shorter runtimes A*. Care must thus taken calculating g-values, h-values fvalues precisely. numerical precision
floating point numbers improved A*
grids representing form + 2n integers n. Basic Theta* AP
Theta* break ties favor vertices smaller g-values reasons explained Section 9.
use path-planning algorithms consistent h-values since consistent h-values result
short paths A*. Consistent h-values satisfy triangle inequality, is, h-value
goal vertex zero h-value potential non-goal parent vertex greater
distance potential non-goal parent vertex vertex plus h-value
vertex (Hart et al., 1968; Pearl, 1984). Consistent h-values lower bounds corresponding
goal distances vertices. Increasing consistent h-values typically decreases number vertex
expansions A* thus also runtime A*. thus use path-planning algorithms
largest consistent h-values easy calculate. Basic Theta*, AP Theta*, FD*
A* visibility graphs, goal distances vertices equal true goal distances,
is, goal distances grids paths constrained grid edges. therefore use
path planning algorithms straight-line distances h(s) = c(s, sgoal ) h-values
experiments. straight-line distances goal distances grids without blocked cells
paths constrained grid edges. A* grids A* PS, goal distances vertices
equal goal distances grids paths constrained grid edges. could therefore
use larger octile distances h-values experiments. octile distances
goal distances grids without blocked cells paths constrained grid edges. Algorithm
5 shows calculate octile distance given vertex s, s.x s.y x
coordinates vertex s, respectively. indeed use A* grids octile distances A*
PS straight-line distances since smoothing typically able shorten resulting
paths much increase number vertex expansions thus runtime. Grids without
blocked cells provide example. octile
distances h-values, A* grids finds paths
diagonal movements (whose lengths 2) precede horizontal vertical movements
(whose lengths 1) paths largest number diagonal movements
longest ones among paths number movements due tie-breaking scheme
used. hand, straight-line distances h-values, A* grids finds paths
interleave diagonal movements horizontal vertical movements (which means
likely lots opportunities smooth paths even grids blocked
cells) closer straight line start goal vertices (which means
likely paths closer true shortest paths even grids blocked cells),
558

fiT HETA *: NY-A NGLE PATH P LANNING



G RIDS

Figure 17: True shortest paths found FD* (left), A* PS (middle) Basic Theta* (right)
h-values vertices closer straight line typically smaller h-values
vertices farther away straight line.
Tables 1-4 report experimental results. runtime A* visibility graphs (which finds
true shortest paths) long 500 500 grids thus omitted. Figure 16 visualizes
experimental results random 500 500 grids. path length A* grids much larger
path lengths path-planning algorithms thus omitted.
make following observations path lengths:
path-planning algorithms order increasing path lengths tend be: A* visibility
graphs (which finds true shortest paths), Basic Theta*, AP Theta*, FD*, A* PS A*
grids. random 500 500 grids 20 percent blocked cells, Basic Theta* finds shorter
paths AP Theta* 70 percent time, shorter paths FD* 97 percent time,
shorter paths A* PS 94 percent time shorter paths A* grids 99 percent
time.
paths found Basic Theta* AP Theta* almost short true shortest paths even
though AP Theta* sometimes constrains angle ranges necessary. example,
average less factor 1.003 longer true shortest paths 100 100
grids.
Basic Theta* finds true shortest paths often FD* A* PS. Figure 17 shows
example light green vertex center start vertex red, green
blue vertices represent goal vertices FD*, A* PS Basic Theta* find true shortest
paths, respectively.
make following observations runtimes. path-planning algorithms order
increasing runtimes tend be: A* grids, Basic Theta*, AP Theta*, A* PS, FD* A*
visibility graphs.
make following observations numbers vertex expansions. path-planning
algorithms order increasing numbers vertex expansions tend be: A* visibility graphs,
A* grids, AP Theta*, Basic Theta*, FD* A* PS. (The number vertex expansions A*
grids A* PS different use different h-values.)
559

fiDANIEL , NASH , KOENIG , & F ELNER

Runtime
Runtime per Vertex Expansion

FD*
5.21
0.000021

Basic Theta*
3.65
0.000015

AP Theta*
5.70
0.000023

A* PS
3.06
0.000012

Table 5: Path-planning algorithms without post-processing steps random 500 500 grids
20 percent blocked cells

Finally, make following observations number heading changes. pathplanning algorithms order increasing numbers heading changes tend be: A* PS, A*
visibility graphs, Basic Theta*, AP Theta*, A* grids FD*.
exceptions trends reported above. therefore perform paired t-tests.
show confidence level = 0.01 Basic Theta* indeed finds shorter paths AP Theta*,
A* PS FD* Basic Theta* indeed shorter runtime AP Theta*, A* PS
FD*.
summarize, A* visibility graphs finds true shortest paths slow. hand, A*
grids finds long paths fast. Any-angle path planning lies two extremes.
Basic Theta* dominates AP Theta*, A* PS FD* terms tradeoff runtime
path length. finds paths almost short true shortest paths almost fast
A* grids. also simpler implement AP Theta*. Therefore, build Basic Theta*
remainder article, although report experimental results AP Theta*
well. However, AP Theta* reduces runtime Basic Theta* per vertex expansion linear
constant. currently unknown whether constant time line-of-sight checks devised
make AP Theta* faster Basic Theta*. interesting area future research since
AP Theta* potentially first step toward significantly reducing runtime any-angle path
planning via sophisticated line-of-sight checks.

8. Extensions Theta*
section, extend Basic Theta* find paths given start vertex vertices
find paths grids contain unblocked cells non-uniform traversal costs.
8.1 Single Source Paths
far, Basic Theta* found paths given start vertex given goal vertex. discuss
version Basic Theta* finds single source paths (that is, paths given start vertex
vertices) terminating open list empty instead either open list
empty expands goal vertex.
Finding single source paths requires path-planning algorithms expand number
vertices, minimizes influence h-values runtime thus results clean
comparison since h-values sometimes chosen trade runtime path length.
runtimes A* PS FD* effected Basic Theta* AP Theta*
finding single source paths since require post-smoothing path-extraction steps
560

fiT HETA *: NY-A NGLE PATH P LANNING



1

2

3

4

5



G RIDS

6
I6

I5
I4

B

I3
I2
I1

C

I0

Basic Theta* path Non-Uniform Traversal Costs

Figure 18: Basic Theta* grids contain unblocked cells non-uniform traversal costs

(a) Small contiguous regions uniform traversal costs
Path Cost
Runtime

A* Grids
4773.59
11.28

FD*
4719.26
14.98

Basic Theta*
4730.96
19.02

(b) Large contiguous regions uniform traversal costs
Path Cost
Runtime

A* Grids
1251.88
3.42

FD*
1208.89
5.31

Basic Theta*
1207.06
5.90

Table 6: Path-planning algorithms random 1000 1000 grids non-uniform traversal costs

path, thus need post-process many paths. Table 5 reports runtimes path-planning
algorithms without post-processing steps. runtime Basic Theta* per vertex expansion
similar A* PS shorter either AP Theta* FD* later two
algorithms require floating point operations.
8.2 Non-Uniform Traversal Costs
far, Basic Theta* found paths grids contain unblocked cells uniform traversal
costs. case, true shortest paths heading changes corners blocked cells
triangle inequality holds, means Path 2 longer Path 1. discuss
version Basic Theta* finds paths grids contain unblocked cells non-uniform
traversal costs computing comparing path lengths (which path costs) appropriately.
case, true shortest paths also heading changes boundaries unblocked
cells different traversal costs triangle inequality longer guaranteed hold,
means Path 2 costly Path 1. Thus, Basic Theta* longer unconditionally
chooses Path 2 Path 1 Path 2 unblocked [Line 42] chooses path smaller
cost. uses standard Cohen-Sutherland clipping algorithm computer graphics (Foley, van
Dam, Feiner, & Hughes, 1992) calculate cost Path 2 line-of-sight check. Figure
18 shows example path segment C1A6 vertex C1 vertex A6. straight line
split line segments points intersects cell boundaries. cost path
segment sum costs line segments Ii Ii+1 , cost line segment
product length traversal cost corresponding unblocked cell.
found changing test Line 52 Algorithm 3 strictly less less
equal slightly reduces runtime Basic Theta*. result fact faster
compute cost path segment corresponds Path 1 Path 2 since tends consist
fewer line segments.
561

fiDANIEL , NASH , KOENIG , & F ELNER



2

1

3

4

5



goal

1

2

3

4

5

goal
h =2.24

h =3.16
B

B

g =1.41
g =2.24
C

C

start

start

(a)

(b)

Figure 19: Non-monotonicity f-values Basic Theta*

compare Basic Theta* A* grids FD* respect path cost runtime
(measured seconds) since A* easily adapted grids contain unblocked cells
non-uniform traversal costs FD* designed case. compare path-planning
algorithms 1000 1000 grids, cell assigned integer traversal cost 1 15
(corresponding unblocked cell) infinity (corresponding blocked cell), similar
technique used work Ferguson Stentz (2006) . path lies boundary
two cells different traversal costs, use smaller traversal cost two cells.
start goal vertices south-west corners cells. start vertex south-west cell.
goal vertex cell randomly chosen column cells furthest east. average
100 random grids. Table 6 (a) reports results every traversal cost chosen uniform
probability, resulting small contiguous regions uniform traversal costs. path cost
runtime FD* smaller Basic Theta*. path cost A* grids
1 percent larger FD* although runtime much smaller FD*. Thus,
any-angle planning large advantage A* grids. Table 6(b) reports results
traversal cost one chosen probability 50 percent traversal costs chosen
uniform probability, resulting large contiguous regions uniform traversal costs. path
cost Basic Theta* smaller FD* runtime
FD*. paths found FD* tend many unnecessary heading changes regions
traversal costs Basic Theta*, outweighs paths found Basic
Theta* necessary heading changes boundary two cells different
traversal costs. path cost A* grids 3 percent larger Basic Theta*.
Thus, any-angle planning larger advantage A* grids.

9. Trading Runtime Path Length: Exploiting h-Values
strategies trading runtime path length A* grids Basic Theta* share.
However, behavior different even though two algorithms similar
pseudocode. section, develop versions Basic Theta* might able find shorter
paths increase runtime, including versions use weighted h-values weights less
one, break ties among vertices f-value open list favor vertices
smaller g-values (when decide vertex expand next) re-expand vertices whose
f-values decreased.
562

fiT HETA *: NY-A NGLE PATH P LANNING



G RIDS

use path-planning algorithms consistent h-values. A* grids following
properties (Pearl, 1984): f-value expanded vertex larger f-value
unexpanded visible neighbors updating according Path 1, implies
f-value vertex expanded vertex larger f-value
vertex. Consequently, point time search vertex expanded,
following parents expanded vertex start vertex retrieves shortest path
start vertex expanded vertex reverse, implies A* cannot find shorter paths
expanding vertices once. Basic Theta* different properties: f-value
expanded vertex larger f-value one unexpanded visible neighbors
updating according Path 2, implies f-value vertex expanded
vertex larger f-value vertex. Consequently,
point time search vertex expanded, following parents
expanded vertex start vertex guaranteed retrieve shortest path start vertex
vertex reverse, implies Basic Theta* might find shorter paths expanding
vertices once. Figure 19 shows example. Basic Theta* expands start vertex C1
parent C1, generates vertex B2. Vertex B2 unexpanded visible neighbor vertex C1
line-of-sight vertex C1. Basic Theta* thus updates according Path 2 (which
Path 1 case), sets f-value f (B2) = 1.41 + 3.16 = 4.57, sets parent vertex
C1 inserts open list (Figure 19(a)). Basic Theta* later expands vertex B2
parent C1, generates vertex B3. Vertex B3 unexpanded visible neighbor vertex B2
line-of-sight vertex C1. Basic Theta* thus updates according Path 2, sets f-value
f (B3) = 2.24 + 2.24 = 4.48, sets parent vertex C1 inserts open list (Figure
19(b)). Thus, f-value expanded vertex B2 indeed larger f-value unexpanded
visible neighbor B3 updating according Path 2 increase g-value vertex
B2 vertex B3 [= 0.83] less decrease h-value vertex B2 vertex B3 [= 0.92].
Basic Theta* later expands vertex B3, f-value vertex B2 [= 4.57] expanded
vertex B3 indeed larger f-value vertex B3 [= 4.48].
properties suggest Basic Theta* might able find shorter paths increase
runtime re-expanding vertices expanding additional vertices (for example using weighted
h-values weights less one) A* cannot. time, standard optimizations
A* decrease runtime might also able decrease runtime Basic Theta* (such
breaking ties among vertices f-value open list favor vertices larger
g-values). section investigate tradeoffs.
9.1 Weighted h-Values
far, Basic Theta* used consistent h-values h(s). A* consistent h-values finds paths
length matter small large h-values are. Decreasing consistent h-values typically
increases number vertex expansions A*. therefore discuss version Basic
Theta* might able find shorter paths increase runtime using weighted h-values
weights less one. version Basic Theta* uses h-values h(s) = w c(s, sgoal )
given weight 0 w < 1 thus similar Weighted A* (Pohl, 1973), except Weighted
A* typically uses weights greater one. Figure 20(a) shows example resulting effect
number vertex expansions path length. green vertex north-east start

563

fiDANIEL , NASH , KOENIG , & F ELNER

(a) Expanded vertices Basic Theta* different weights
578.6

250000

578.4
200000
578.2

Path Length

150000

577.8

100000
577.6

Vertex Expansions

578

577.4
50000
577.2

577

0
0

0.25

0.5

0.75

0.8

0.85

0.9

0.95

1

w
Basic Theta* Path Length

AP Theta* Path Length

Basic Theta* Vertex Expansions

AP Theta* Vertex Expansions

(b) Random 500 500 grids 20 percent blocked cells

Figure 20: Weighted h-values

vertex, red vertex south-west goal vertex. Basic Theta* weight 1.00 (as
used far) expands orange vertices finds red path. Basic Theta* weight 0.75
expands blue vertices finds blue path. Thus, Basic Theta* expands vertices
564

fiT HETA *: NY-A NGLE PATH P LANNING

Path Length
Number Vertex Expansions
Runtime

Smaller g-Values
Basic Theta* AP Theta*
578.41
578.51
18621.61
17698.75
0.3724
0.5350



G RIDS

Larger g-Values
Basic Theta* AP Theta*
578.44
578.55
18668.03
17744.94
0.3829
0.5389

Table 7: Random 500 500 grids 20 percent blocked cells


weight 0.75 weight 1.00 resulting path shorter since passes vertices
expanded weight 0.75 weight 1.00.
Figure 20(b) reports effect different weights path length number vertex expansions Basic Theta* AP Theta* random 500 500 grids 20 percent blocked cells.
(The graphs number vertex expansions Basic Theta* AP Theta* nearly coincide.)
Decreasing weight decreases path length increase number vertex expansions
thus runtime. path length decreases AP Theta* Basic Theta* since AP
Theta* constrain angle ranges necessary thus benefits two ways expanding vertices. However, neither Basic Theta* AP Theta* guaranteed find true
shortest paths even weights zero.
9.2 Tie Breaking
far, Basic Theta* broken ties among vertices open list f-value favor
vertices larger g-values (when decides vertex expand next). A* consistent
h-values finds paths length matter tie-breaking scheme uses. Breaking ties
favor vertices smaller g-values typically increases number vertex expansions
thus runtime. therefore discuss version Basic Theta* might able find shorter
paths increase runtime breaking ties favor vertices smaller g-values. Figure 21
shows example resulting effect path length. Vertices C4 B4 f-value
vertex B4 larger g-value since f (C4) = 3.83+1.41 = 5.24 f (B4) = 4.24+1 = 5.24.
Basic Theta* breaks ties favor vertices larger g-values, expands vertex B4
parent E1 vertex C4 parent C3 eventually expands goal vertex parent B4
terminates. Path extraction follows parents goal vertex B5 start vertex E1
retrieve dashed red path [E1, B4, B5]. However, Basic Theta* breaks ties favor vertices
smaller g-values, expands vertex C4 parent C3 vertex B4 parent E1
eventually expands goal vertex parent C3 terminates. Path extraction follows
parents goal vertex B5 start vertex E1 retrieve shorter solid blue path [E1, C3,
B5].
Table 7 reports effect tie-breaking scheme path length, number vertex expansions
runtime Basic Theta* AP Theta* random 500 500 grids 20 percent blocked
cells. Breaking ties favor vertices smaller g-values neither changes path length,
number vertex expansions runtime significantly. effect tie-breaking scheme
small since fewer vertices f-value Basic Theta* AP Theta* A*
grids number possible g-values h-values larger any-angle path planning.
565

fiDANIEL , NASH , KOENIG , & F ELNER



1

2

3

B

4

5

goal

C



E

start

Basic Theta* path (Larger g-values)

Basic Theta* path (Smaller g-values)

Figure 21: Basic Theta* paths different tie-breaking schemes

Path Length
Number Vertex Expansions
Runtime

Basic Theta* without Vertex Re-Expansions
578.41
18621.61
0.3724

Basic Theta* Vertex Re-Expansions
577.60
22836.37
0.5519

Table 8: Random 500 500 grids 20 percent blocked cells

also second method breaking ties effect path length. far, Basic Theta*
chosen Path 2 Path 1 unexpanded visible neighbor vertex line-of-sight
parent vertex. However, choose Path 1 Path 2 paths equally long,
increases runtime due additional comparison. Figure 21 shows example
resulting effect path length. Assume Basic Theta* expands vertex B4 vertex C4.
Basic Theta* chooses Path 2 Path 1 expands vertex B4 parent E1 eventually
expands goal vertex B5 parent B4 terminates. Path extraction follows parents
goal vertex B5 start vertex E1 retrieve dashed red path [E1, B4, B5]. However,
Basic Theta* chooses Path 1 Path 2 expands vertex B4 parent C3 eventually
expands goal vertex B5 parent C3 terminates. Path extraction follows parents
goal vertex B5 start vertex E1 retrieve shorter solid blue path [E1, C3, B5].
9.3 Re-Expanding Vertices
far, Basic Theta* used closed list ensure expands vertex once. A*
consistent h-values re-expand vertices whether uses closed list since
cannot find shorter path start vertex vertex expanding vertex.
hand, Basic Theta* re-expand vertices use closed list since find shorter
path start vertex vertex expanding vertex. re-inserts vertex
566

fiT HETA *: NY-A NGLE PATH P LANNING



1

2

3

4

5

6



7

G RIDS

8

B

9

goal

C



E

start

Basic Theta* path

Basic Theta* path vertex re-expansions

Figure 22: Basic Theta* paths without vertex re-expansions
open list eventually re-expands it.2 Figure 22 shows example effect vertex
re-expansions path length. Basic Theta* without vertex re-expansions eventually expands vertex
C8 parent D4. Vertex C9 unexpanded visible neighbor vertex C8 line-of-sight
vertex D4. Basic Theta* without vertex re-expansions thus updates according Path 2
sets parent vertex D4. termination, path extraction follows parents goal vertex
B9 start vertex E1 retrieve dashed red path [E1, D4, C9, B9]. However, Basic Theta*
vertex re-expansions eventually expands vertex C8 parent D4 later re-expands vertex C8
parent E1. Vertex C9 visible neighbor vertex C8 line-of-sight vertex E1.
Basic Theta* vertex re-expansions thus updates according Path 2 sets parent
vertex E1. termination, path extraction follows parents goal vertex B9 start vertex
E1 retrieve shorter solid blue path [E1, C9, B9].
Theorem 3. Basic Theta* vertex re-expansions terminates path extraction returns
unblocked path start vertex goal vertex path exists. Otherwise, Basic
Theta* vertex re-expansions terminates reports unblocked path exists.

Proof. proof similar proof Theorem 1. property needs proved
differently Basic Theta* vertex re-expansions terminates since longer true
never insert vertex open list removed vertex open list.
However, since number vertices finite, finite number acyclic paths
start vertex vertex. Therefore, number possible g-values finite. Therefore, Basic
Theta* vertex re-expansions reduce g-value vertex finite number times
thus inserts vertex open list finite number times. Thus, open list eventually
becomes empty Basic Theta* terminate terminated earlier already.
2. Basic Theta* vertex re-expansions could also delay expansion goal vertex (for example, increasing
f-value artificially) re-expand vertices terminates version Basic Theta*
vertex re-expansions that.

567

fiDANIEL , NASH , KOENIG , & F ELNER

Table 8 reports effect vertex re-expansions path length, number vertex expansions
runtime Basic Theta* random 500 500 grids 20 percent blocked cells. Vertex
re-expansions decrease path length slightly increase number vertex expansions
thus runtime.

10. Trading Runtime Path Length: Approaches
additional strategies trading runtime path length specific Basic
Theta*. section, develop versions Basic Theta* might able find shorter
paths increase runtime examining paths, including versions check line-ofsight parent parent, use key vertices identify promising parents increase
number visible neighbors thus number potential parents updating vertices
according Path 1.
10.1 Three Paths
far, Basic Theta* considered two paths (namely Paths 1 2) updates gvalue parent unexpanded visible neighbor vertex s. discuss version
Basic Theta* considers third path, namely path start vertex parent
parent vertex [= g(parent(parent(s)))] vertex straight line [=
c(parent(parent(s)), )], resulting length g(parent(parent(s))) + c(parent(parent(s)), ).
version Basic Theta* might able find shorter paths increase runtime since
third path longer Path 2 due triangle inequality. However, experimental results
(not reported here) show third path decrease path length significantly
original version Basic Theta* already determines parent parent vertex
line-of-sight vertex shares parent vertex s. Thus, unlikely
parent parent vertex line-of-sight vertex thus third path
unblocked.
10.2 Key Vertices
far, Basic Theta* considered two paths (namely Paths 1 2) updates g-value
parent unexpanded visible neighbor vertex s. parent vertex either
visible neighbor vertex parent visible neighbor, always case
true shortest paths. discuss version Basic Theta* considers additional paths,
namely paths start vertex cached key vertices vertex straight
line. version Basic Theta* might able find shorter paths increase runtime
due fact parent vertex also one key vertices. However,
experimental results (not reported here) show key vertices decrease path length slightly
larger increase runtime due overhead select key vertices, maintain
consider larger number paths.

568

fiT HETA *: NY-A NGLE PATH P LANNING

(a) Branching factor 4

(b) Branching factor 8



G RIDS

(c) Branching factor 16

Figure 23: Grids different branching factors

0.6

581
580.5

0.5

580

0.4

579
0.3

578.5

Runtime

Path Length

579.5

578
0.2

577.5
577

0.1

576.5
576

0
4

Basic Theta*

16

Branching Factor
Path Length

Runtime

Figure 24: Basic Theta* random 500 500 grids 20 percent blocked cells

10.3 Larger Branching Factors
far, Basic Theta* operated eight-neighbor grids. discuss version Basic Theta*
operates grids different numbers neighbors thus different branching factors.
Figure 23 shows neighbors center vertex branching factors 4, 8 16 respectively.
version Basic Theta* might able find shorter paths increase runtime since
larger branching factors increase number visible neighbors vertices thus number
potential parents updating according Path 1. Figure 24 reports effect larger
branching factors path length runtime Basic Theta* random 500 500 grids
20 percent blocked cells. Larger branching factors indeed decrease path length increase
runtime.
569

fiDANIEL , NASH , KOENIG , & F ELNER

11. Conclusions
Any-angle path-planning algorithms find paths without artificially constraining headings
paths. presented two new correct complete any-angle path-planning algorithms. Basic
Theta* Angle-Propagation Theta* (AP Theta*) variants A* propagate information along grid edges (to achieve short runtime) without constraining paths grid edges (to find
any-angle paths). Basic Theta* simple understand implement, fast finds short paths.
However, guaranteed find true shortest paths. AP Theta* achieves worst-case complexity per vertex expansion constant (like A* grids) rather linear number
cells (like Basic Theta*) propagating angle ranges expands vertices. However,
AP Theta* complex Basic Theta*, fast finds slightly longer paths.
proved correctness completeness Basic Theta* AP Theta* compared
three existing any-angle path-planning algorithms, namely A* post-smoothed
paths (A* PS), A* visibility graphs Field D* (FD*), version A* know
propagates information along grid edges without constraining paths grid edges. Basic
Theta* AP Theta* (unlike A* PS) consider paths constrained grid edges
search thus make informed decisions regarding paths search. Basic Theta*
AP Theta* (unlike FD*) take advantage fact true shortest paths heading changes
corners blocked cells.
A* visibility graphs finds true shortest paths slow. hand, A* grids finds
long paths fast. Any-angle path planning lies two extremes. Basic Theta*
dominates AP Theta*, A* PS FD* terms tradeoffs runtime path length.
finds paths almost short true shortest paths almost fast A* grids.
extended Basic Theta* find paths given start vertex vertices find
paths grids contain cells non-uniform traversal costs. f-value expanded vertex
Basic Theta* (unlike A* grids) consistent h-values larger f-value one
unexpanded visible neighbors, means Basic Theta* might able find
shorter paths increase runtime re-expanding vertices expanding additional vertices.
thus developed versions Basic Theta* use weighted h-values weights less one,
break ties among vertices f-value open list favor vertices smaller
g-values (when decide vertex expand next), re-expand vertices whose f-values
decreased, check line-of-sight parent parent, use key vertices identify
promising parents increase number visible neighbors.
future, intend develop worst-case bound path lengths Basic Theta* AP
Theta*, better understand properties investigate faster versions AP Theta*
perform line-of-sight checks constant time.

Appendix A. Checking Line-of-Sight
appendix, explain perform line-of-sight checks fast. simplicity, allow
straight lines pass diagonally touching blocked cells. Performing line-of-sight check
similar determining points plot raster display drawing straight line two points. plotted points correspond cells straight line passes through.
570

fiT HETA *: NY-A NGLE PATH P LANNING



G RIDS

106 LineOfSight(s, s)
107
x0 := s.x;
108
y0 := s.y;
109
x1 := .x;
110
y1 := .y;
111
dy := y1 y0 ;
112
dx := x1 x0 ;
113
f := 0;
114
dy < 0
115
dy := dy ;
116
sy := 1;
117
118

else

119
120
121

dx < 0
dx := dx ;
sx := 1;

122
123

else

124
125
126
127
128
129

dx dy
x0 6= x1
f := f + dy ;
f dx
grid(x0 + ((sx 1)/2), y0 + ((sy 1)/2))
return false;

sy := 1;

sx := 1;

y0 := y0 + sy ;
f := f dx ;

130
131
132
133

f 6= 0 grid(x0 + ((sx 1)/2), y0 + ((sy 1)/2))
return false;

134
135

dy = 0 grid(x0 + ((sx 1)/2), y0 ) grid(x0 + ((sx 1)/2), y0 1)
return false;

136

x0 := x0 + sx ;

137
138
139
140
141
142

else
y0 6= y1
f := f + dx ;
f dy
grid(x0 + ((sx 1)/2), y0 + ((sy 1)/2))
return false;
x0 := x0 + sx ;
f := f dy ;

143
144
145
146

f 6= 0 grid(x0 + ((sx 1)/2), y0 + ((sy 1)/2))
return false;

147
148

dx = 0 grid(x0 , y0 + ((sy 1)/2)) grid(x0 1, y0 + ((sy 1)/2))
return false;

149

y0 := y0 + sy ;

150
return true;
151 end

Algorithm 6: Line-of-sight algorithm

Thus, two vertices line-of-sight iff none plotted points correspond blocked cells.
allows Basic Theta* perform line-of-sight checks standard Bresenham line-drawing
algorithm computer graphics (Bresenham, 1965), uses fast logical integer operations rather floating-point operations. Algorithm 6 shows resulting line-of-sight algorithm,
571

fiDANIEL , NASH , KOENIG , & F ELNER

II

yaxis



p
b0

xaxis

b1

b2
b3

b4

b5
b6

b7

b8
b9



III

b 10

Upper Boundary

IV
Lower Boundary

Figure 25: Parent, blocked cell boundary vertices
s.x s.y x coordinates vertex s, respectively, grid represents grid
grid(x, y) true iff corresponding cell blocked.

Appendix B. AP Theta* Returns Unblocked Paths
appendix, prove AP Theta* never returns blocked path.
Theorem 4. AP Theta* never returns blocked path.
Proof. define path blocked iff least one vertex path line-of-sight
successor path. Thus, path blocked iff least one path segments passes
interior blocked cell passes two blocked cells share edge.
first prove AP Theta* never returns path path segment passes
interior blocked cell. prove contradiction AP Theta* cannot assign parent p
vertex path segment parent p vertex passes interior
blocked cell b. Assume otherwise. simplify proof, translate rotate grid
blocked cell b immediately south-west origin b0 grid parent p quadrant
II, shown Figure 25. define quadrant vertex follows, s.x s.y
x coordinates vertex s, respectively:
Quadrant north-east quadrant (excluding x-axis) given s.x 0 s.y > 0.
Quadrant II north-west quadrant (excluding y-axis) given s.x < 0 s.y 0.
Quadrant III south-west quadrant (excluding x-axis) given s.x 0 s.y < 0.
572

fiT HETA *: NY-A NGLE PATH P LANNING

northwest(s)
west(s)
southwest(s)

north(s)


south(s)



G RIDS

northeast(s)
east(s)
southeast(s)

Figure 26: Neighbors vertex
Quadrant IV south-east quadrant (excluding y-axis including origin b0 ) given
s.x > 0 s.y 0 s.x = 0 s.y = 0.
refer neighbors vertex east(s), northeast(s), north(s), northwest(s), west(s),
southwest(s), south(s), southeast(s), shown Figure 26.
Assume light source vertex p light cannot pass blocked cell b,
creates shadow. vertex shadow iff straight line parent p vertex
passes interior blocked cell b. distinguish two parts perimeter
shadow, namely upper lower boundary, shown Figure 25. define boundary vertex
vertex shadow least one neighbor (although necessarily visible
neighbor) shadow. origin b0 shadow neighbor south(b0 )
shadow. Thus, origin b0 boundary vertex. consider upper boundary without
loss generality. Then, boundary vertex (to precise: upper boundary vertex) vertex
(s, p, b0 ) 0 (that is, upper boundary thus outside shadow)
least one neighbor (s , p, b0 ) > 0 (that is, upper boundary thus inside
shadow). easy see boundary vertices quadrant IV form infinite
boundary path [b0 , b1 , . . .] starts origin b0 repeatedly moves either south east,
is, bi+1 = south(bi ) bi+1 = east(bi ).
define vertex sufficiently constrained iff (s, p, b0 ) lb(s) parent p.
vertex sufficiently constrained, remains sufficiently constrained since operation AP
Theta* decrease lower angle bound lb(s). prove following every boundary
vertex sufficiently constrained time expanded expanded parent p. Consider
vertex upper boundary (that is, (s, p, b0 ) > 0 thus (b0 , p, s) < 0)
visible neighbor boundary vertex bi . Vertex cannot updated according Path 1
assigned parent p time parent p expanded since straight line parent p
vertex passes interior blocked cell therefore visible neighbors.
cannot updated according Path 2 assigned parent p time boundary
vertex bi expanded parent p boundary vertex bi sufficiently constrained
time thus (bi , p, b0 ) lb(bi ), implies (bi , p, s) = (bi , p, b0 ) + (b0 , p, s) <
(bi , p, b0 ) lb(bi ) condition Line 60 remains unsatisfied. Consequently, vertex
shadow parent p.
prove induction order vertex expansions every boundary vertex
sufficiently constrained time expanded expanded parent p. Assume
boundary vertex b0 expanded parent p. Then, condition Line 81 satisfied
573

fiDANIEL , NASH , KOENIG , & F ELNER

Line 83 executed blocked cell b time boundary vertex b0 expanded parent p.
Boundary vertex b0 sufficiently constrained afterwards since lower angle bound set zero.
assume boundary vertex bi > 0 expanded parent p. Then, boundary vertex bi
cannot identical parent p (since different quadrants) start vertex (since
start vertex parent p). Boundary vertex bi cannot updated according Path
1 assigned parent p time parent p expanded since p.x < 0 (bi ).x > 0
thus neighbors. Consequently, boundary vertex bi must updated according
Path 2 assigned parent p time one visible neighbors x expanded
parent p. Vertex x must upper boundary (that is, (x, p, b0 ) 0) cannot
identical parent p (since different quadrants). distinguish two cases:
Assume vertex x boundary vertex. sufficiently constrained time expanded parent p according induction assumption (that is, (x, p, b0 ) lb(x))
since expanded boundary vertex bi . Boundary vertex bi updated according
Path 2 time vertex x expanded parent p. Thus, condition Line
60 satisfied time (that is, lb(x) (x, p, bi )) thus lb(x) + (bi , p, x) =
lb(x) (x, p, bi ) 0. Then, conditions Lines 88 89 satisfied
Line 90 executed = x time boundary vertex bi expanded parent
p. Boundary vertex bi sufficiently constrained afterwards since lower angle bound
set max(lb(bi ), lb(x) + (bi , p, x)) (bi , p, b0 ) = (bi , p, x) + (x, p, b0 )
lb(x) + (bi , p, x) max(lb(bi ), lb(x) + (bi , p, x)).
Assume vertex x boundary vertex.
Lemma 3. Assume vertex boundary vertex bi visible neighbors, c(p, bi ) <
c(p, s) (s, p, bi ) < 0. Assume boundary vertex bi sufficiently constrained
time vertex expanded parent p boundary vertex bi expanded parent
p time. Then, vertex sufficiently constrained time expanded
expanded parent p.
Proof. Assume vertex expanded parent p. Then, (s, p, b0 ) = (s, p, bi ) +
(bi , p, b0 ) < 0 since (s, p, bi ) < 0 (bi , p, b0 ) 0. distinguish two cases:
Assume boundary vertex bi expanded vertex expanded
parent parent p. Then, conditions Lines 93 94 satisfied
Line 95 executed = bi time vertex expanded parent
p. Vertex sufficiently constrained afterwards since lower angle bound set
max(lb(s), (s, p, bi )) (s, p, b0 ) = (s, p, bi ) + (bi , p, b0 ) (s, p, bi )
max(lb(s), (s, p, bi )).
Assume boundary vertex bi expanded parent p vertex expanded
parent p. Boundary vertex bi sufficiently constrained time vertex
expanded parent p according premise (that is, (bi , p, b0 ) lb(bi )). Furthermore, lb(bi ) 0 (since operation AP Theta* make lower angle bound
positive) thus lb(bi ) + (s, p, bi ) 0. Then, conditions Lines 88 89
satisfied Line 90 executed = bi time vertex expanded
parent p. Vertex sufficiently constrained afterwards since lower angle bound
574

fiT HETA *: NY-A NGLE PATH P LANNING



G RIDS

set max(lb(s), lb(bi ) + (s, p, bi )) (s, p, b0 ) = (s, p, bi ) + (bi , p, b0 )
lb(bi ) + (s, p, bi ) max(lb(s), lb(bi ) + (s, p, bi )).

Boundary vertex bi either immediately south east boundary vertex bi1 since
boundary path moves south east. distinguish three subcases:
Assume parent p x-axis quadrant II. Then, boundary path
along x-axis. Vertices west(bi ) east(bi ) boundary vertices, vertices
southwest(bi ), south(bi ), southeast(bi ) upper boundary. Thus,
vertex x identical one vertices northwest(bi ), north(bi ) northeast(bi ).
cases, boundary vertex bj immediately south vertex x. vertices x
bj visible neighbors, would blocked cells immediately southwest south-east vertex x vertices x bi could thus visible neighbors.
Thus, vertices x bj visible neighbors. Furthermore, boundary vertex bj immediately south vertex x thus c(p, bj ) < c(p, x) (x, p, bj ) < 0. Finally,
boundary vertex bj sufficiently constrained according induction assumption
time boundary vertex bi expanded parent p boundary vertex bj
expanded parent p time. Thus, vertex x sufficiently constrained time
expanded parent p according Lemma 3 (that is, (x, p, b0 ) lb(x)). Consequently, conditions Lines 88 89 satisfied (for reason given before)
Line 90 executed = x time boundary vertex bi expanded parent
p. Boundary vertex bi sufficiently constrained afterwards since lower angle bound
set max(lb(bi ), lb(x) + (bi , p, x)) (bi , p, b0 ) = (bi , p, x) + (x, p, b0 )
lb(x) + (bi , p, x) max(lb(bi ), lb(x) + (bi , p, x)).
Assume parent p x-axis quadrant II boundary vertex
bi immediately east boundary vertex bi1 thus c(p, bi1 ) < c(p, bi )
(bi , p, bi1 ) < 0. Furthermore, boundary vertex bi1 sufficiently constrained according induction assumption time boundary vertex bi expanded
parent p boundary vertex bi1 expanded parent p time. boundary vertices bi1 bi visible neighbors, boundary vertex bi sufficiently
constrained time expanded parent p according Lemma 3. boundary
vertices bi1 bi visible neighbors, must blocked cells immediately north-west south-west boundary vertex bi . Then, Line 81 satisfied
Line 83 executed blocked cell immediately south-west boundary vertex bi
time boundary vertex bi expanded parent p. Boundary vertex bi sufficiently
constrained afterwards since lower angle bound set zero.
Assume parent p x-axis quadrant II boundary vertex bi
immediately south boundary vertex bi1 .
Lemma 4. Assume vertex quadrant IV upper boundary.
Then, vertex boundary vertex iff vertex immediately south-west vertex
upper boundary.
575

fiDANIEL , NASH , KOENIG , & F ELNER

Proof. vertex immediately south-west vertex upper boundary,
vertex boundary vertex definition. hand, vertex
upper boundary (that is, (s , p, b0 ) 0), vertex boundary
vertex every neighbor upper boundary. neighbors
vertex
east(s), northeast(s), north(s), northwest(s),
west(s), southwest(s), south(s) southeast(s).
or, equivalently,
east(east(north(s ))), east(east(north(north(s )))), east(north(north(s ))),
north(north(s )), north(s ), , east(s ) east(east(s )).
Thus, every neighbor vertex reached vertex repeatedly moving either north east thus (s , p, ) 0. Consequently, (s , p, b0 ) =
(s , p, ) + (s , p, b0 ) 0 thus every neighbor vertex
upper boundary.
distinguish two subcases:
Assume boundary vertex bi+1 immediately east boundary vertex
bi . Vertices north(bi ) east(bi ) boundary vertices. Vertices west(bi ),
southwest(bi ) south(bi ) south-west boundary vertices bi1 , bi bi+1 ,
respectively, thus upper boundary according Lemma 4. Vertices
northwest(bi ) southeast(bi ) either boundary vertices south-west
boundary vertices bi2 bi+2 , respectively, upper boundary
according Lemma 4. Thus, vertex x identical vertex northwest(bi ).
Assume boundary vertex bi+1 immediately south boundary vertex bi .
Vertices north(bi ) south(bi ) boundary vertices. Vertices west(bi )
southwest(bi ) south-west boundary vertices bi1 bi , respectively,
thus upper boundary according Lemma 4. Vertex northwest(bi )
either boundary vertex south-west boundary vertex bi2
upper boundary according Lemma 4. Thus, vertex x identical one vertices
northeast(bi ), east(bi ) southeast(bi ).
cases, vertex x immediately east boundary vertex bj thus c(p, bj ) <
c(p, x) (x, p, bj ) < 0. vertices x bj visible neighbors,
would blocked cells immediately north-west south-west vertex x vertices
x bi could visible neighbors. Thus, vertices x bj visible neighbors.
Furthermore, boundary vertex bj sufficiently constrained according induction
assumption time boundary vertex bi expanded parent p boundary vertex bj expanded parent p time. Thus, vertex x sufficiently
constrained time expanded parent p according Lemma 3 (that is,
(x, p, b0 ) lb(x)). Consequently, conditions Lines 88 89 satisfied (for
reason given before) Line 90 executed = x time boundary vertex
bi expanded parent p. Boundary vertex bi sufficiently constrained afterwards
since lower angle bound set max(lb(bi ), lb(x) + (bi , p, x)) (bi , p, b0 ) =
(bi , p, x) + (x, p, b0 ) lb(x) + (bi , p, x) max(lb(bi ), lb(x) + (bi , p, x)).
576

fiT HETA *: NY-A NGLE PATH P LANNING



G RIDS

concludes proof every boundary vertex sufficiently constrained time
expanded expanded parent p thus also proof AP Theta* never returns path
path segment passes interior blocked cell.
prove AP Theta* never returns path path segment passes two
blocked cells share edge. prove contradiction AP Theta* cannot assign
parent p vertex path segment parent p vertex passes two
blocked cells share edge. Assume otherwise consider first time AP Theta* assigns
parent p vertex path segment parent p vertex passes
two blocked cells share edge. path segment must either horizontal vertical. Vertex
cannot updated according Path 1 assigned parent p time parent p
expanded since straight line parent p vertex passes interior
blocked cell therefore visible neighbors. cannot updated according
Path 2 assigned parent p time visible neighbor expanded parent p
since either a) neighbor would colinear vertices p straight line
parent p vertex would thus pass interior blocked cell b) neighbor would
colinear vertices p straight line parent p vertex would pass
two blocked cells share edge, contradiction assumption. concludes
proof AP Theta* never returns path path segment passes two blocked
cells share edge.
Thus, AP Theta* never returns blocked path.

Appendix C. Acknowledgments
article extension earlier publication (Nash et al., 2007) contains additional
expositions, examples proofs. thank Vadim Bulitko University Alberta
making maps real-time game Baldurs Gate II available us. research done
Ariel Felner spent sabbatical University Southern California, visiting Sven Koenig.
research partly supported U.S. Army Research Laboratory (ARL) U.S.
Army Research Office (ARO) award Sven Koenig grant W911NF-08-1-0468, Office
Naval Research (ONR) award Sven Koenig grant N00014-09-1-1031, National
Science Foundation (NSF) award Sven Koenig grant 0413196 Israeli Science
Foundation (ISF) award Ariel Felner grants 728/06 305/09. Alex Nash funded
Northrop Grumman Corporation. views conclusions contained document
authors interpreted representing official policies, either
expressed implied, sponsoring organizations, agencies, companies U.S. government.

References
Aurenhammer, F. (1991). Voronoi diagramsa survey fundamental geometric data structure.
ACM Computing Surveys, 23(3), 345405.
Botea, A., Muller, M., & Schaeffer, J. (2004). Near optimal hierarchical path-finding. Journal
Game Development, 1(1), 122.
577

fiDANIEL , NASH , KOENIG , & F ELNER

Bresenham, J. (1965). Algorithm computer control digital plotter. IBM Systems Journal,
4(1), 2530.
Bulitko, V., Sturtevant, N., & Kazakevich, M. (2005). Speeding learning real-time search via
automatic state abstraction. Proceedings AAAI Conference Artificial Intelligence,
pp. 13491354.
Choset, H., Lynch, K., Hutchinson, S., Kantor, G., Burgard, W., Kavraki, L., & Thrun, S. (2005).
Principles Robot Motion: Theory, Algorithms, Implementations. MIT Press.
Deloura, M. (2000). Game Programming Gems. Charles River Media.
Ferguson, D., & Stentz, A. (2006). Using interpolation improve path planning: Field D*
algorithm. Journal Field Robotics, 23(2), 79101.
Foley, J., van Dam, A., Feiner, S., & Hughes, J. (1992). Computer Graphics: Principles Practice. Addison-Wesley.
Hart, P., Nilsson, N., & Raphael, B. (1968). formal basis heuristic determination
minimum cost paths. IEEE Transactions Systems Science Cybernetics, SCC-4(2),
100107.
Kavraki, L., Svestka, P., Latombe, J., & Overmars, M. (1996). Probabilistic roadmaps path
planning high-dimensional configuration spaces. IEEE Transactions Robotics Automation, 12(4), 566580.
Koenig, S., & Likhachev, M. (2002). D* Lite. Proceedings AAAI Conference Artificial
Intelligence, pp. 476483.
LaValle, S., & Kuffner, J. (2001). Rapidly-exploring random trees: Progress prospects.
Donald, B., Lynch, K., & Rus, D. (Eds.), Algorithmic Computational Robotics: New
Directions, pp. 293308. K Peters.
Lee, D.-T. (1978). Proximity reachability plane. Ph.D. thesis, University Illinois
Urbana-Champaign.
Liu, Y.-H., & Arimoto, S. (1992). Path planning using tangent graph mobile robots among
polygonal curved obstacles. International Journal Robotics Research, 11(4), 376382.
Lozano-Perez, T., & Wesley, M. (1979). algorithm planning collision-free paths among
polyhedral obstacles. Communication ACM, 22, 560570.
Mitchell, J., & Papadimitriou, C. (1991). weighted region problem: Finding shortest paths
weighted planar subdivision. Journal ACM, 38(1), 1873.
Murphy, R. (2000). Introduction AI Robotics. MIT Press.
Nash, A., Daniel, K., Koenig, S., & Felner, A. (2007). Theta*: Any-angle path planning grids.
Proceedings AAAI Conference Artificial Intelligence, pp. 11771183.
Nash, A., Koenig, S., & Likhachev, M. (2009). Incremental Phi*: Incremental any-angle path planning grids. Proceedings International Joint Conference Aritificial Intelligence,
pp. 18241830.
Patel, A. (2000).
Amits Game Programming Information.
available online
http://theory.stanford.edu/amitp/GameProgramming/MapRepresentations.html.
578

fiT HETA *: NY-A NGLE PATH P LANNING



G RIDS

Pearl, J. (1984). Heuristics: Intelligent Search Strategies Computer Problem Solving. AddisonWesley.
Pohl, I. (1973). avoidance (relative) catastrophe, heuristic competence, genuine dynamic
weighting computational issues heuristic problem solving. Proceedings International Joint Conference Artificial Intelligence, pp. 1217.
Rabin, S. (2002). AI Game Programming Wisdom. Charles River Media.
Rabin, S. (2004). AI Game Programming Wisdom 2. Charles River Media.
Thorpe, C. (1984). Path relaxation: Path planning mobile robot. Proceedings AAAI
Conference Artificial Intelligence, pp. 318321.
Tozour, P. (2004). Search space representations. Rabin, S. (Ed.), AI Game Programming Wisdom
2, pp. 85102. Charles River Media.
Yahja, A., Stentz, A., Singh, S., & Brumitt, B. (1998). Framed-quadtree path planning mobile
robots operating sparse environments. Proceedings International Conference
Robotics Automation, pp. 650655.
Yap, P. (2002). Grid-based path-finding. Proceedings Canadian Conference Artificial
Intelligence, pp. 4455.

579

fiJournal Artificial Intelligence Research 39 (2010) 335-371

Submitted 10/09; published 09/10

Active Tuples-based Scheme Bounding Posterior Beliefs
Bozhena Bidyuk

bbidyuk@google.com

Google Inc.
19540 Jamboree Rd
Irvine, CA 92612

Rina Dechter

dechter@ics.uci.edu

Donald Bren School Information Computer Science
University California Irvine
Irvine, CA 92697-3425

Emma Rollon

erollon@lsi.upc.edu

Departament de Llenguatges Sistemes Informatics
Universitat Politecnica de Catalunya
Barcelona, Spain

Abstract
paper presents scheme computing lower upper bounds posterior
marginals Bayesian networks discrete variables. power lies ability use
available scheme bounds probability evidence posterior marginals
enhance performance anytime manner. scheme uses cutset conditioning
principle tighten existing bounding schemes facilitate anytime behavior, utilizing
fixed number cutset tuples. accuracy bounds improves number
used cutset tuples increases computation time. demonstrate empirically
value scheme bounding posterior marginals probability evidence using
variant bound propagation algorithm plug-in scheme.

1. Introduction
paper addresses problem bounding probability evidence posterior
marginals Bayesian networks discrete variables. Deriving bounds posteriors
given accuracy clearly NP-hard problem (Abdelbar & Hedetniemi, 1998; Dagum
& Luby, 1993; Roth, 1996) indeed, available approximation algorithms provide
little guarantee quality approximations. Still, approaches
presented past years bounding posterior marginals (Horvitz, Suermondt, &
Cooper, 1989; Poole, 1996, 1998; Mannino & Mookerjee, 2002; Mooij & Kappen, 2008)
bounding probability evidence (Dechter & Rish, 2003; Larkin, 2003; Leisink &
Kappen, 2003).
paper develop framework accept bounding scheme improve
bounds anytime manner using cutset-conditioning principle (Pearl, 1988).
facilitate scheme develop expression converts bounds probability
evidence bounds posterior marginals.
Given Bayesian network defined set variables X , variable X X ,
domain value x D(X), posterior marginal P (x|e) (where e subset assignments
variables, called evidence) computed directly two joint probabilities,
c
2010
AI Access Foundation. rights reserved.

fiBidyuk, Dechter & Rollon

P (x, e) P (e):
P (x|e) =

P (x, e)
P (e)

(1)

Given set C={C1 , ..., Cp } X cutset variables (e.g., loop-cutset), compute

Q
probability evidence enumerating cutset tuples ci D(C) = pi=1 D(Ci )
using formula:

X
P (ci , e)
(2)
P (e) =
i=1

= |D(C)|. also compute posterior marginals using expression:
P (x|e) =


X

P (x|ci , e)P (ci |e)

(3)

i=1

computation P (ci , e) assignment c = ci linear network size C
loop-cutset exponential w C w-cutset (see definition Section 2).
limitation cutset-conditioning method, defined Eq. (2) (3),
number cutset tuples grows exponentially cutset size.
two basic approaches handling combinatorial explosion cutsetconditioning scheme. One sample cutset space subsequently approximate
distribution P (C|e) samples, shown Bidyuk Dechter (2007).
second approach, use here, enumerate h tuples bound
rest. shall refer selected tuples active tuples. lower bound P (e)
obtained computing exactly quantities P (ci , e) 1 h resulting partial
sum Eq. (2). approach likely perform well selected h tuples contain
probability mass P (e). However, approach cannot applied directly
obtain bounds posterior marginals Eq. (3). Even partial sum Eq. (3)
requires computing P (ci |e) turn requires normalization constant P (e).
obtain naive bounds posterior marginals Eq. (1) using P L (e) P U (e) denote
available lower upper bounds joint probabilities:
P L (x, e)
P U (x, e)

P
(x|e)

P U (e)
P L (e)
However, bounds usually perform poorly often yield upper bound > 1.
Horvitz et. al (1989) first propose scheme bounding posterior marginals
based subset cutset tuples. proposed select h highest probability tuples
P (c) derived lower upper bounds sum Eq. (3) joint probabilities
P (ci , e) priors P (ci ) 1 h. resulting bounded conditioning algorithm
shown compute good bounds posterior marginals variables
Alarm network (with = 108). However, intervals lower upper bound
values increase probability evidence becomes smaller prior distribution
becomes bad predictor high probability tuples P (C|e) P (c) becomes bad
upper bound P (c, e).
expression derive paper yields significantly improved formulation
results Active Tuples Bounds (AT B) framework. generated bounds facilitate
336

fiActive Tuples-based Scheme Bounding Posterior Beliefs

anytime performance provably tighter bounds computed bounded
conditioning. addition, expression accommodates use off-the-shelf scheme
bounds probability evidence. Namely, B accepts algorithm bounding
P (e) generates algorithm bounds posterior marginals. Moreover, also
tighten input bounds P (e).
time complexity B linear number active (explored) cutset tuples
h. complexity bounding P (e) O(T ), bounding probability mass
unexplored tuples O(T h (d 1) |C|) |C| number variables cutset
maximum domain size.
evaluate framework experimentally, using variant bound propagation (BdP )
(Leisink & Kappen, 2003) plug-in bounding scheme. BdP computes bounds
iteratively solving linear optimization problem variable minimum
maximum objective function correspond lower upper bounds posterior
marginals. performance BdP demonstrated Alarm network, Ising
grid network, regular bipartite graphs. Since bound propagation exponential
Markov boundary size, since requires solving linear programming problems
many times, overhead plug-in scheme high cost-effective.
therefore utilize variant bound propagation called ABdP +, introduced Bidyuk
Dechter (2006b), trades accuracy speed.
use Gibbs cutset sampling (Bidyuk & Dechter, 2003a, 2003b) finding highprobability cutset tuples. schemes, stochastic local search (Kask & Dechter,
1999) also used. investigation generating high-probability cutset tuples
outside primary scope paper.
show empirically B using bound propagation often superior bound
propagation alone given comparable time resources. importantly,
Bs accuracy improves time. also demonstrate power B improving
bounds probability evidence. latter main focus paper,
lower upper bounds probability evidence contained expression
bounding posterior marginals.
paper organized follows. Section 2 provides background previously proposed method bounded conditioning. Section 3 presents analyzes B framework. Section 4 describes implementation details using bound propagation
B plug-in presents empirical evaluation. Section 5 discusses related work,
Section 6 concludes.

2. Background
background, define key concepts describe bounded conditioning algorithm
inspired work.
2.1 Preliminaries
section, define essential terminology provide background information
Bayesian networks.

337

fiBidyuk, Dechter & Rollon

Definition 2.1 (graph concepts) directed graph pair G=< V, E >, V =
{X1 , ..., Xn } set nodes E = {(Xi , Xj )|Xi , Xj V} set edges. Given
(Xi , Xj ) E, Xi called parent Xj , Xj called child Xi . set
Xi parents denoted pa(Xi ), pai , set Xi children denoted ch(Xi ),
chi . family Xi includes Xi parents. moral graph directed graph
G undirected graph obtained connecting parents nodes G
removing arrows. cycle-cutset undirected graph subset nodes that,
removed, yields graph without cycles. loop directed graph G subgraph
G whose underlying graph cycle (undirected). directed graph acyclic
directed loops. directed graph singly-connected (also called poly-tree),
underlying undirected graph cycles. Otherwise, called multiply-connected.
Definition 2.2 (loop-cutset) vertex v sink respect loop L two
edges adjacent v L directed v. vertex sink respect
loop L called allowed vertex respect L. loop-cutset directed graph G
set vertices contains least one allowed vertex respect loop G.
Definition 2.3 (Bayesian network) Let X = {X1 , ..., Xn } set random variables
multi-valued domains D(X1 ), ..., D(Xn ). Bayesian network B (Pearl, 1988)
pair <G, P> G directed acyclic graph whose nodes variables X
P = {P (Xi |pai ) | = 1, ..., n} set conditional probability tables (CPTs) associated
Xi . B represents joint probability distribution product form:
P (x1 , ...., xn ) =

n


P (xi |pa(Xi ))

i=1

evidence e instantiated subset variables E X .
Definition 2.4 (Markov blanket Markov boundary) Markov blanket Xi
subset variables X Xi conditionally independent variables
given . Markov boundary Xi minimal Markov blanket (Pearl, 1988).
following discussion identify Markov boundary Xi Markov blanket
consisting Xi parents, children, parents children.
Definition 2.5 (Relevant Subnetwork) Given evidence e, relevant subnetwork
Xi relativde e subnetwork B obtained removing descendants Xi
observed observed descendants.
observations change, Markov boundary Xi stay
relevant subnetwork may change. inference tasks defined relative specific
set observations e, often convenient restrict attention Markov boundary
Xi relevant subnetwork Xi .
common query Bayesian networks belief updating task
computing posterior distribution P (Xi |e) given evidence e query variable
Xi X . Another query compute probability evidence P (e). tasks NPhard (Cooper, 1990). Finding approximate posterior marginals fixed accuracy also
338

fiActive Tuples-based Scheme Bounding Posterior Beliefs

NP-hard (Dagum & Luby, 1993; Abdelbar & Hedetniemi, 1998). network
poly-tree, belief updating inference tasks accomplished time linear
size network. general, exact inference exponential induced width
networks moral graph.
Definition 2.6 (induced width) width node ordered undirected graph
number nodes neighbors precede ordering. width ordering
o, denoted w(o), width nodes. induced width ordered graph, w (o),
width ordered graph obtained processing nodes last first.
Definition 2.7 (w-cutset) w-cutset Bayesian network B subset variables
C that, removed moral graph network, induced width w.
Throughout paper, consider Bayesian network set variables X ,
evidence variables E X evidence E = e, cutset C = {C1 , ..., Cp } X \E.
Lower-caseQc = {c1 , ..., cp } denote arbitrary instantiation cutset C, =
|D(C)| = Ci C |D(Ci )| denote number different cutset tuples.
2.2 Bounded Conditioning

Bounded conditioning (BC) anytime scheme computing posterior bounds Bayesian
networks proposed Horvitz et. al (1989). derived loop-cutset conditioning
method (see Eq. 3). Given node X X domain value x D(X), derive
bounds following formula:
P (x|e) =


X





P (x|c , e)P (c |e) =

h
X





P (x|c , e)P (c |e) +

i=1

i=1


X

P (x|ci , e)P (ci |e)

(4)

i=h+1

hard-to-compute P (ci |e) replaced h normalization formula:
Ph



i=1 P (x|c , e)P (c , e)
P



i=1 P (c , e) +
i=h+1 P (c , e)

P (x|e) = Ph

+


X

P (x|ci , e)P (ci |e)

(5)

i=h+1

BC computes exactly P (ci , e) P (x|ci , e) h cutsetPtuples bounds rest.

lower bound obtained Eq. (5) replacing
i=h+1 P (c , e) denomiPM

nator sum priors i=h+1 P (c ) simply dropping sum right:
L
PBC
(x|e)

Ph


i=1 P (x, c , e)
P



i=h+1 P (c )
i=1 P (c , e) +

, Ph

(6)

P

upper bound obtained Eq. (5) replacing
i=h+1 P (c , e) denominator zero, replacing P (x|ci , e) P (ci |e) > h upper bounds
1 derived upper bound (not provided here) respectively:
PM
Ph


i=h+1 P (c )
U
i=1 P (x, c , e)
PBC (x|e) , Ph
+ Ph
Ph

L
U
i=1 P (c , e)
i=1 P (c |e) + 1
i=1 P (c |e)
339

fiBidyuk, Dechter & Rollon

Applying definitions P L (ci |e) =

Ph

i=1

P (ci ,e)
PM

P (ci ,e)+

i=h+1

P (ci )

P U (ci |e) =

P (ci ,e)
Ph

i=1 P (c ,e)

Horvitz et al. (1989), get:
P
Ph
PM
Ph




(
i=h+1 P (c ))( i=1 P (c , e) +
i=h+1 P (c ))
U
i=1 P (x, c , e)
+
PBC (x|e) , Ph
P
h


i=1 P (c , e)
i=1 P (c , e)



(7)

bounds expressed Eq. (6) (7) converge exact posterior marginals
h . However, show that,

Theorem 2.1 (bounded conditioning bounds interval) interval lower
upper bounds computed bounded conditioning lower bounded probability mass
prior distribution P (C) unexplored cutset tuples:
U
h, PBC
(x|e)



L
PBC
(x|e)




X

P (ci )

i=h+1

Proof. See Appendix A.



3. Architecture Active Tuples Bounds
section, describe Active Tuples Bounds (AT B) framework. builds
principles bounded conditioning. Namely, given cutset C method
generating h cutset tuples, probabilities P (c, e) h tuples evaluated exactly
rest upper lower bounded. worst bounds P (c, e) lower bound
0 upper bound P (c). B bounds improved using plug-in algorithm
computes tighter bounds participating joint probabilities. always computes
tighter bounds bounded conditioning, even using 0 P (c) bound P (c, e).
rest section, c1:q = {c1 , ..., cq } q < |C| denotes generic partial
instantiation first q variables C, ci1:q indicates particular partial assignment.
Given h cutset tuples, 0 h , assume without loss generality
first h tuples according enumeration order, variable X X \E x D(X),
rewrite Eq. (3) as:
Ph
PM
PM



i=1 P (x, c , e) +
i=h+1 P (x, c , e)
i=1 P (x, c , e)
P (x|e) = PM
(8)
= Ph
P




i=1 P (c , e)
i=h+1 P (c , e)
i=1 P (c , e) +

probabilities P (x, ci , e) P (ci , e), 1 h, computed polynomial time
C loop-cutset timePand space exponentialPin w C w-cutset. question



compute bound
i=h+1 P (c , e) efficient manner.
i=h+1 P (x, c , e)
h+1
approach first replaces sums tuples c ,...,cM sum
polynomial number (in h) partially-instantiated tuples. that, develop new
expressions lower upper bounds posterior marginals function
lower upper bounds joint probabilities P (x, c1:q , e) P (c1:q , e). assume
derivation algorithm compute bounds, refer
PAL (x, c1:q , e) (resp. PAL (c1:q , e)) PAU (x, c1:q , e) (resp. PAU (c1:q , e)) respectively.
340

fiActive Tuples-based Scheme Bounding Posterior Beliefs

C1
0

1

C2
0

1

2

C3

C3

0

1

0

1

C4
0

C4
1

0

1

Figure 1: search tree cutset C = {C1 , ..., C4 }.
3.1 Bounding Number Processed Tuples
formally define partially-insantiated tuples replace sum exponential number uninstantiated tuples (h + 1 ) sum polynomial
number partially-instantiated tuples (h + 1 0 ) Eq. 8.
Consider fully-expanded search tree depth |C| cutset search space expanded
order C1 ,...,Cp . path root leaf depth |C| corresponds full
cutset tuple. call path active path corresponding tuple active
tuple. obtain truncated search tree trimming branches
active paths:
Definition 3.1 (truncated search tree) Given search tree covering search space
H variables = {Y1 , . . . , Ym } X , truncated search tree relative subset
= {y 1 , ..., } D(Y1 ) ... D(Ym ) full assignments, obtained marking edges
paths appearing removing unmarked edges nodes except
emanating marked nodes.
Let = {c1 , . . . , ch }. Clearly, leaves depth q < |C| truncated search
tree relative correspond partially instantiated cutset tuples c1:q
extended full cutset assignments.
Example 3.1 Consider Bayesian network B cutset variables C={C1 , ..., C4 }, domain values D(C1 )=D(C3 )=D(C4 )={0, 1}, D(C2 )={0, 1, 2}, four fully-instantiated tuples {0, 1, 0, 0}, {0, 1, 0, 1}, {0, 2, 1, 0}, {0, 2, 1, 1}. Figure 1 shows truncated search tree,
remaining partially instantiated tuples {0, 0}, {0, 1, 1}, {0, 2, 0}, {1}.
Proposition 3.1 Let C cutset, maximum domain size, h number
generated cutset tuples. number partially-instantiated cutset tuples
truncated search tree bounded O(h (d 1) |C|).
341

fiBidyuk, Dechter & Rollon

Proof. Since every node path root C1 leaf Cp
(d 1) emanating leaves, theorem clearly holds.
Let 0 number truncated tuples. enumerate partially instantiated
tuples, denoting j-th tuple cj1:qj , 1 j 0 , qj tuples length. Clearly,
probability mass cutset tuples ch+1 , ..., cM captured sum
truncated tuples. Namely:
Proposition 3.2

X

0



P (c , e) =

P (cj1:qj , e)

(9)

j=1

i=h+1

X


X
0



P (x, c , e) =


X

P (x, cj1:qj , e)

(10)

j=1

i=h+1


Therefore, bound sums tuples h + 1 Eq. (8) bounding
polynomial (in h) number partially-instantiated tuples follows,
P (x|e) =

Ph


i=1 P (x, c , e)
Ph

i=1 P (c , e)

+
+

PM 0

j
j=1 P (x, c1:qj , e)
PM 0
j
j=1 P (c1:qj , e)

(11)

3.2 Bounding Probability Truncated Tuples

following, develop lower upper bound expressions used B.
3.2.1 Lower Bounds
First, decompose P (cj1:qj , e), 0 j 0 , follows. Given variable X X
distinguished value x D(X):
P (cj1:qj , e) =

X

P (x0 , cj1:qj , e) = P (x, cj1:qj , e) +

X

P (x0 , cj1:qj , e)

(12)

x0 6=x

x0 D(X)

Replacing P (cj1:qj , e) Eq. (11) right-hand side Eq. (12), get:
P (x|e) = Ph

i=1 P (c

PM 0
j

j=1 P (x, c1:qj , e)
i=1 P (x, c , e) +
PM 0 P
P 0
j
0 j
+
j=1
x0 6=x P (x , c1:qj , e)
j=1 P (x, c1:qj , e) +

Ph

, e)

(13)

use following two lemmas:

Lemma 3.1 Given positive numbers > 0, b > 0, 0, < b, then:

342


b



a+
b+ .



fiActive Tuples-based Scheme Bounding Posterior Beliefs

Lemma 3.2 Given positive numbers a, b, , L , U , < b L U , then:
+ L
a+
+ U


b + L
b+
b + U


proof lemmas straight forward.
Lemma 3.2 says sums numerator denominator component common, replacing larger value U numerator
denominator yields larger fraction. Replacing smaller value L places
yields smaller fraction.
Observe Eq. (13) sums numerator denominator
contain P (x, cj1:qj , e). Hence, apply Lemma 3.2. obtain lower bound
replacing P (x, cj1:qj , e), 1 j 0 , Eq. (13) corresponding lower bounds
numerator denominator, yielding:
h
X

0



P (x, c , e) +

i=1

P (x|e)

h
X

P (ci , e) +


X

PAL (x, cj1:qj , e)

j=1

M0
X

PAL (x, cj1:qj , e) +

P (x0 , cj1:qj , e)

j=1 x0 6=x

j=1

i=1

(14)

0

X
X

P
Subsequently, grouping PAL (x, cj1:qj , e) x0 6=x P (x0 , cj1:qj , e) one sum replacing
P
PAL (x, cj1:qj , e) + x0 6=x P (x0 , cj1:qj , e) corresponding upper bound (increasing denominator), obtain:

P (x|e)

h
X

0

P (x, c , e) +

i=1

h
X



P (c , e) +



M0
X


X

PAL (x, cj1:qj , e)

j=1

U B[PAL (x, cj1:qj , e)

j=1

i=1

, PAL (x|e)
+

X

P (x

0

(15)

, cj1:qj , e)]

x0 6=x

upper bound UB obtained follows:
(
P
X
PAL (x, cj1:qj , e) + x0 6=x PAU (x0 , cj1:qj , e)
j
0 j
L
P (x , c1:qj , e)] , min
U B[PA (x, c1:qj , e) +
PAU (cj1:qj , e)
0
x 6=x

(16)
P
0 , cj , e).
U (x0 , cj , e) is, obviously, upper bound
P
(x
P
1:qj
1:qj
x0 6=x
x0 6=x
P
j
j
j
U
L
0
value PA (c1:qj , e) also upper bound since PA (x, c1:qj , e)+ x0 6=x P (x , c1:qj , e) P (cj1:qj , e)

value

P

PAU (cj1:qj , e). Neither bound expression Eq. (16) dominates other. Thus, compute minimum two values.
343

fiBidyuk, Dechter & Rollon

Please note numerator Eq. (15) also provides anytime lower bound
joint probability P (x, e) used compute lower bound probability
evidence. general, lower bound denoted PAL (e) obtained by:
P (e)

h
X

0



P (c , e) +


X

PAL (cj1:qj , e) , PAL (e)

(17)

j=1

i=1

3.2.2 Upper Bound
upper bound expression obtained similar manner. Since numerator
denominator Eq. (13) contain addends P (x, cj1:qj , e), using Lemma 3.2 replace
P (x, cj1:qj , e) upper bound PAU (x, cj1:qj , e) yielding:

P (x|e)

h
X

0



P (x, c , e) +



P (c , e) +

PAU (x, cj1:qj , e)

j=1

i=1

h
X


X

M0
X

PAU (x, cj1:qj , e)

+

P (x

0

, cj1:qj , e)

j=1 x0 6=x

j=1

i=1

(18)

0

X
X

Subsequently, replacing P (x0 , cj1:qj , e), x0 6= x, lower bound (reducing denominator), obtain new upper bound expression P (x|e):

P (x|e)

h
X

0



P (x, c , e) +

i=1

P (ci , e) +

PAU (x, cj1:qj , e)

j=1

i=1

h
X


X

M0
X

PAU (x, cj1:qj , e) +

M0
X

, PAU (x|e)
X

(19)

PAL (x0 , cj1:qj , e)

j=1 x0 6=x

j=1

Similar lower bound, numerator upper bound expression PAU (x|e) provides anytime upper bound joint probability P (x, ci , e) generalized
upper bound probability evidence:
P (e)

h
X
i=1

0



P (c , e) +


X

PAU (cj1:qj , e) , PAU (e)

(20)

j=1

derived bounds PAL (x|e) PAU (x|e) never worse obtained bounded
conditioning, show Section 3.4.
3.3 Algorithmic Description
Figure 2 summarizes active tuples-based bounding scheme B. steps 1 2,
generate h fully-instantiated cutset tuples compute exactly probabilities P (ci , e)
P (X, ci , e) h, X X \(C E), using, example, bucket-elimination algorithm
(Dechter, 1999). step 3, compute bounds partially instantiated tuples using
algorithm A. step 4, compute lower upper bounds posterior marginals
using expressions (15) (19), respectively.
344

fiActive Tuples-based Scheme Bounding Posterior Beliefs

Active Tuples-based Bounds Architecture
Input: Bayesian network (B), variables X , evidence E X , cutset C X \E, constant
h, algorithm computing lower upper bounds joint probabilities.
Output: lower bounds P L , upper bounds P U .
1. Generate h cutset tuples.
2. Compute:
Ph
i=1 P (ci , e)
Ph
Sx i=1 P (x, ci , e), x D(X), X X \(C E)
3. Traverse partially-instantiated tuples:
0
3.1 Generate truncated tree associated h tuples let c11:q1 , ..., cM
1:qM 0
0 partial assignments.
3.2 x D(X), X X \(C E), compute:
PM 0 L
(x, cj1:qj , e)
LBA (x) j=1 PA
U BA (x)

0
U BA
(x)

4. Compute bounds:

PM 0

j=1

PM 0

j=1

U
PA
(x, cj1:qj , e)

U B[P (x, cj1:qj , e) +

L
PA
(x|e)
U
PA
(x|e)

=
=

P

x0 6=x

PA (x0 , cj1:qj , e)]

Sx +LBA (x)
0 (x)
S+U BA

Sx +U BA (x)
S+U BA (x)+LBA (x)

L
u
5. Output {PA
(x|e)} {PA
(x|e)}.

Figure 2: Active Tuples Bounds Architecture

Example 3.2 Consider Bayesian network B described Example 3.1. Recall
B cutset C = {C1 , ..., C4 } domains D(C1 ) = D(C3 ) = D(C4 ) = {0, 1}
D(C2 ) = {0, 1, 2}. total number cutset tuples = 24. Let X 6 C variable
B domain D(X) = {x, x0 }. compute bounds P (x|e). Assume generated
four cutset tuples (h = 4) before:

c1 = {C1 = 0, C2 = 1, C3 = 0, C4 = 0} = {0, 1, 0, 0}
c2 = {C1 = 0, C2 = 1, C3 = 0, C4 = 1} = {0, 1, 0, 1}
c3 = {C1 = 0, C2 = 2, C3 = 1, C4 = 0} = {0, 2, 1, 0}
c4 = {C1 = 0, C2 = 2, C3 = 1, C4 = 1} = {0, 2, 1, 1}

corresponding truncated search tree shown Figure 1. tuple {0, 1, 0, 0},
compute exactly probabilities P (x, C1 =0, C2 =1, C3 =0, C4 =0, e) P (C1 =0, C2 =1,
C3 = 0, C4 = 0). Similarly, obtain exact probabilities P (x, C1 = 0, C2 = 1, C3 = 0,
C4 = 1) P (C1 = 0, C2 = 1, C3 = 0, C4 = 1) second cutset instance {0, 1, 0, 1}.
345

fiBidyuk, Dechter & Rollon

Since h = 4,

Ph

i=1 P (x

4
X

0 , ci , e)



Ph

i=1 P (c

, e)

are:

P (x, ci , e) = P (x, c1 , e) + P (x, c2 , e) + P (x, c3 , e) + P (x, c4 , e)

i=1

4
X

P (ci , e) = P (c1 , e) + P (c2 , e) + P (c3 , e) + P (c4 , e)

i=1

remaining partial tuples are: c11:2 = {0, 0}, c21:3 = {0, 1, 1}, c31:3 = {0, 2, 0}, c41:1 =
{1}. Since 4 tuples full cutsets, compute bounds joint probabilities.
Using notation Figure 2, sums partially instantiated tuples
form:
U BA (x) , PAU (x, c11:2 , e) + PAU (x, c21:3 , e) + PAU (x, c31:3 , e) + PAU (x, c41:1 , e)
LBA (x) , PAL (x, c11:2 , e) + PAL (x, c21:3 , e) + PAL (x, c31:3 , e) + PAL (x, c41:1 , e)
Eq. (19) get:
PAU (x|e)

P4


i=1 P (x, c , e) + U BA (x)

0
i=1 P (c , e) + U BA (x) + LBA (x )

= P4

Eq. (15) (16) get:
PAL (x|e)

P4


i=1 P (x, c , e) + LBA (x)

0
i=1 P (c , e) + LBA (x) + U BA (x )

= P4

total number tuples processed 0 = 4 + 4 = 8 < 24.
3.4 B Properties
section analyze time complexity B framework, evaluate worstcase lower upper bounds, analyze monotonicity properties bounds interval
(as function h).
Theorem 3.1 (complexity) Given algorithm computes lower upper bounds
joint probabilities P (c1:qi , e) P (x, c1:qi , e) time O(T ), loop-cutset C, PAL (x|e)
PAU (x|e) computed time O(h N + h (d 1) |C|) maximum
domain size N problem input size.
Proof. Since C loop-cutset, exact probabilities P (ci , e) P (x, ci , e)
computed time O(N ). Proposition 3.1, O(h (d 1) |C|) partiallyinstantiated tuples. Since algorithm computes upper lower bounds P (cj1:qj , e)
P (x, cj1:qj , e) time O(T ), bounds partially-instantiated tuples computed
time O(T h (d 1) |C|)).

346

fiActive Tuples-based Scheme Bounding Posterior Beliefs

Let plug-in algorithm brute-force algorithm, denoted BF , trivially
L (x, cj , e) = 0, P U (x, cj , e) = P (cj ), U B[P (cj , e)] = P (cj ).
instantiates PBF
1:qj
1:qj
1:qj
1:qj
1:qj
BF
Then, Eq. (15):
L
PBF
(x|e)

,

Ph


i=1 P (x, c , e)
Ph
P
j
M0

i=1 P (c , e) +
j=1 P (c1:qj )

Eq. (19):

U
PBF
(x|e)

,

PM 0
j

j=1 P (c1:qj )
i=1 P (x, c , e) +
Ph
PM 0
j

i=1 P (c , e) +
j=1 P (c1:qj )

Ph

Ph


i=1 P (x, c , e)
P

j

j=h+1 P (c )
i=1 P (c , e) +

= Ph

=

Ph

PM

j
i=1 P (x, c , e) +
j=h+1 P (c )
Ph
PM

j
i=1 P (c , e) +
j=h+1 P (c )

(21)

(22)

Assuming algorithm computes bounds least good computed
L (x|e) P U (x|e) worst-case bounds computed B.
BF , PBF
BF
Now, ready compute upper bound B bounds interval:
Theorem 3.2 (AT B bounds interval upper bound) B length interval lower upper bounds upper bounded monotonic non-increasing function
h:
PM
j
j=h+1 P (c )
U
L
PA (x|e) PA (x|e) Ph
, Ih
PM
, e) +
j)
P
(c
P
(c
i=1
j=h+1

Proof. See Appendix C.



Next show B lower upper bounds good better bounds
computed BC.
L (x|e).
Theorem 3.3 (tighter lower bound) PAL (x|e) PBC
L (x|e) worst-case lower bound computed B. Since P L (x|e) =
Proof. PBF
BF
L
L (x|e), P L (x|e) P L (x|e).
PBC (x|e), PAL (x|e) PBF


BC

U (x|e).
Theorem 3.4 (tighter upper bound) PAU (x|e) PBC
U (x|e) worst-case upper bound computed B. Since P U (x|e)
Proof. PBF
BF
U (x|e) due lemma 3.1, follows P U (x|e) P U (x|e).
PBC


BC

4. Experimental Evaluation
purpose experiments evaluate performance B framework
two probabilistic tasks single-variable posterior marginals probability evidence.
experiments first task conducted 1.8Ghz CPU 512 MB RAM,
experiments second task conducted 2.66GHz CPU 2GB RAM.
347

fiBidyuk, Dechter & Rollon

Recall B control parameter h fixes number cutset tuples
algorithm computes exact joint probability. Given fixed h, quality
bounds presumably depend ability select h high probability cutset tuples.
implementation, use optimized version Gibbs sampling,
sampling process maintains list h tuples highest joint probability.
noted, schemes considered subtask part future work.
obtain loop-cutset using mga algorithm (Becker & Geiger, 1996).
report results, describe bound propagation variants,
use plug-in algorithm also stand-alone bounding scheme.
4.1 Bound Propagation
Bound propagation (BdP ) (Leisink & Kappen, 2003) iterative algorithm bounds
posterior marginals variable. bounds initialized 0 1 iteratively
improved solving linear optimization problem variable X X
minimum maximum objective function correspond lower upper bound
posterior marginal P (x|e), x D(X).
cannot directly plug BdP B bound P (c1:q , e) bounds
conditional probabilities. Thus, factorize P (c1:q , e) follows:
P (c1:q , e) =



P (ej |e1 , . . . , ej1 , c1:q )P (c1:q )

ej E

factor P (ej |e1 , . . . , ej1 , c1:q ) bounded BdP , P (c1:q ) computed
L
exactly since relevant subnetwork c1:q (see Def. 2.5) singly connected. Let PBdP
U
PBdP denote lower upper bounds computed BdP marginal.
bounds BdP computes joint probability are:


L
(ej |e1 , . . . , ej1 , c1:q )P (c1:q ) P (c1:q , e)
PBdP



U
(ej |e1 , . . . , ej1 , c1:q )P (c1:q )
PBdP

ej E

ej E

Note BdP bound large number tuples plugged B, therefore, solve large number linear optimization problems. number variables
problem exponential size Markov blanket X.
baseline comparison B, use experiments variant bound
propagation called BdP + (Bidyuk & Dechter, 2006b) exploits structure
network restrict computation P (x|e) relevant subnetwork X (see Def. 2.5).
Markov boundary X (see Def. 2.4) within relevant subnetwork X include
children X observed observed descedants; therefore,
subnetwork Markov boundary original network. Sometimes, Markov
boundary X still big compute limited memory resouces. BdP + uses
parameter k specify maximum size Markov boundary domain space.
algorithm skips variables whose Markov boundary domain size exceeds k,
lower upper bound values remain 0 1, respectively. variables
skipped, bounds computed BdP + remaining variables may less accurate.
348

fiActive Tuples-based Scheme Bounding Posterior Beliefs

network

N

w

|LC|

|D(LC)|

|E|

Time(BE)

Time(LC)

Alarm
Barley
cpcs54
cpcs179
cpcs360b
cpcs422b
Munin3
Munin4

37
48
54
179
360
422
1044
1041

4
7
15
8
21
22
7
8

5
12
15
8
26
47
30
49

108
> 227
32768
49152
26
27
> 230
> 249

1-4
4-8
2-8
12-24
11-23
4-10
257
235

0.01 sec
50 sec
1 sec
2 sec
20 min
50 min
8 sec
70 sec

0.05 sec
>22 hrs1
22 sec
37 sec
> 8 hrs1
> 2 109 hrs1
> 1700 hrs1
> 1 108 hrs1

Table 1: Complexity characteristics benchmarks UAI repository: N -number
nodes, w -induced width, |LC|-number nodes loop-cutset, |D(LC)|loop-cutset state space size, Time(BE) exact computation time via bucket
elimination, Time(LC) exact computation time via loop-cutset conditioning.
results averaged set network instances different evidence.
Evidence nodes values selected random.

preliminary tests showed plugging BdP + B timewise infeasible
(even small k). Instead, developed used different version bound propagation
called ABdP + (Bidyuk & Dechter, 2006b) plug-in algorithm A, costeffective terms accuracy time overhead. ABdP + includes enhancements
BdP +, solves linear optimization problem variable using approximation algorithm. implies obtain bounds faster accurate.
Roughly, relaxed linear optimization problem described fractional packing covering multiple knapsacks solved fast greedy algorithm (Bidyuk
& Dechter, 2006b). ABdP + also parameterized k control maximum size
linear optimization problem. Thus, B using ABdP + plug-in two control
parameters: h k.
4.2 Bounding Single-Variable Marginals
compare performance following three algorithms: B (with ABdP +
plug-in), BdP +, described previous section, BBdP + (Bidyuk & Dechter,
2006a). latter combination B BdP +. First, run algorithm B
ABdP + plug-in. Then, use bounds computed B initialize bounds
BdP + (instead 0 1) run BdP +. Note that, given fixed values h k,
BBdP + always compute tighter bounds either B BdP +. goal
analyze trade-off increase bounds accuracy computation
time overhead. also compare approximate decomposition (AD) (Larkin, 2003)
whenever feasible relevant. include results stand-alone
ABdP + since objective compare B bounds accurate bounds
obtained bound propagation. Bidyuk (2006) provides additional comparison various
refinements BdP (Bidyuk & Dechter, 2006b) mentioned earlier.

1. Times extrapolated.

349

fiBidyuk, Dechter & Rollon

4.2.1 Benchmarks
tested framework four different benchmarks: Alarm, Barley, CPCS, Munin.
Alarm network model monitoring patients undergoing surgery operating room
(Beinlich, Suermondt, Chavez, & Cooper, 1989). Barley network part decisionsupport system growing malting barley (Kristensen & Rasmussen, 2002). CPCS networks derived Computer-Based Patient Care Simulation system based
INTERNIST-1 Quick Medical Reference Expert systems (Pradhan, Provan, Middleton, & Henrion, 1994). experiment cpcs54, cpcs179, cpcs360b, cpcs422b
networks. Munin networks part expert system computer-aided electromyography (Andreassen, Jensen, Andersen, Falck, Kjaerulff, Woldbye, Srensen, Rosenfalck, &
Jensen, 1990). experiment Munin3 Munin4 networks. network,
generated 20 different sets evidence variables picked random. Barley network,
select evidence variables defined Kristensen Rasmussen (2002).
Table 1 summarizes characteristic network. one, table specifies
number variables N , induced width w , size loop cutset |LC|, number
loop-cutset tuples |D(LC)|, time needed compute exact posterior marginals
bucket-tree elimination (exponential induced width w ) cutset conditioning
(exponential size loop-cutset).
Computing posterior marginals exactly easy Alarm network, cpcs54,
cpcs179 using either bucket elimination cutset conditioning since small induced width small loop-cutset. include benchmarks proof concept
only. Several networks, Barley, Munin3, Munin4, also small induced width
and, hence, exact posterior marginals obtained bucket elimination. However, since B linear space, compared linear-space schemes
cutset-conditioning. perspective, Barley, Munin3, Munin4 hard.
example, Barley network 48 variables, induced width w = 7, exact inference bucket elimination takes 30 seconds. loop-cutset contains 12 variables,
number loop-cutset tuples exceeds 2 million variables large
domain sizes (up 67 values). Enumerating computing cutset tuples, rate
1000 tuples per second, would take 22 hours. Similar considerations apply
case Munin3 Munin4 networks.
4.2.2 Measures Performance
measure quality bounds via average length interval lower
upper bound:
P
P
U
L
XX
xD(X) (P (x|e) P (x|e))
P
I=
XX |D(X)|

approximate posterior marginal midpoint lower upper bound
order show whether bounds well-centered around posterior marginal P (x|e).
Namely:
P (x|e) =

PAU (x|e) + PAL (x|e)
2
350

fiActive Tuples-based Scheme Bounding Posterior Beliefs

measure average absolute error respect approximation:
P
P
XX
xD(X) |P (x|e) P (x|e)|
P
=
XX |D(X)|
Ph

P (x,ci ,e)

100% covered explored cutset
Finally, report %P (e) = i=1P (e)
tuples. Notably, benchmarks, thousand cutset tuples enough cover
> 90% P (e).
4.2.3 Results
summarize results benchmark tabular format charts. highlight
bold face first B data point average bounds interval good better
BdP +. charts show convergence bounds interval length function
h time.
B BBdP + maximum Markov boundary domain size fixed k = 210 .
BdP +, vary parameter k 214 219 . Note BdP + depends k,
h. tables, report best result obtained BdP + computation time
appears constant respect h. However, plot accuracy
time, include BdP + bounds obtained using smaller values parameter k. case
Alarm network, varying k make difference since full Markov boundary
domain size equals 210 < 214 . computation time BBdP + includes B plus
BdP + time.
Alarm network. Figure 3 reports results. Since maximum Markov boundary
Alarm network small, BdP + runs without limitations computes average bounds
interval 0.61 4.3 seconds. Note enumeration less 25% total
number cutset tuples covers 99% P (e). fact suggests schemes based
cutset conditioning suitable benchmark. Indeed, B outperforms
BdP +, computing accurate bounds starting first data point h = 25
mean interval B = 0.41 computation time 0.038 seconds, order
magnitude less BdP +. extreme efficiency B terms time clearly seen
right chart. x-axis scale logarithmic fit results. expected,
average bounds interval generated B BBdP + decrease number cutset
tuples h increases, demonstrating anytime property B respect h. Given
fixed h, BBdP + significant overhead time respect B (two orders
magnitude values h smaller 54) minor improvement accuracy.
Barley network. Figure 4 reports results. B BBdP + improve h increases.
However, improvement quite moderate time consuming due uniform shape distribution P (C|e) reflected small % P (e) covered
explored tuples (only 1% 562 tuples 52% 12478 tuples). example,
average B (resp. BBdP +) bounds interval decreases 0.279 (resp. 0.167), obtained
9 (resp. 10) seconds, 0.219 (resp. 0.142) obtained 139 (resp. 141) seconds. Given
fixed h, BBdP + substantially improves B bounds little time overhead (2 seconds
general). Namely, benchmark, BBdP + computation time dominated B
351

fiBidyuk, Dechter & Rollon

h
25
34
40
48
50
54

%P(e)
86
93
96
97
98
99


0.61
0.61
0.61
0.61
0.61
0.61

Alarm, N=37, w =5, |LC|=8, |DLC |=108, |E|=1-4
BdP +
B

time(sec)


time(sec)

0.21
4.3
0.41
0.12
0.038
0.35
0.21
4.3
0.31
0.09
0.039
0.27
0.21
4.3
0.25
0.07
0.044
0.22
0.21
4.3
0.24
0.05
0.051
0.15
0.21
4.3
0.16
0.04
0.052
0.12
0.21
4.3
0.13
0.03
0.059
0.09
ATB

Alarm, N=37, w*=5, |LC|=8, |E|=1-4

0.6
0.5
0.4
0.3
0.2

ATB
BdP+

BBdP+

0.7

Avg Bounds Interval

Avg Bounds Interval

Alarm, N=37, w*=5, |LC|=8, |E|=1-4

BdP+

0.7

BBdP +

time(sec)
0.10
3.4
0.08
2.3
0.06
2.1
0.04
1.5
0.03
1.2
0.02
0.86

BBdP+

0.6
0.5
0.4
0.3
0.2
0.1

0.1

0

0
0

10

20

30

40

50

0.01

60

0.1

1

10

time (sec)

h

Figure 3: Results Alarm network. table reports average bounds interval I,
average error , computation time (in seconds), percent probability
evidence P (e) covered fully-instantiated cutset tuples function h.
highlight bold face first B data point average bounds
interval good better BdP +. charts show convergence
bounds interval length function h time. BdP + uses full size Markov
boundary since domain size small (< 214 ), resulting one data point
chart right.

computation time. Note computation time stand-alone BdP + algorithm
less 2 seconds. Within time, BdP + yields average interval length 0.23,
B BBdP + spend 86 10 seconds, respectively, obtain quality
bounds. However, anytime behavior latter algorithms allows improve
time, desirable characteristic computing bounds. Moreover, note
overhead time respect B completely negligible.
CPCS networks. Figures 5 8 show results cpcs54, cpcs179, cpcs360b
cpcs422b, respectively. behavior algorithms networks similar.
previous benchmarks, B BBdP + bounds interval decreases h increases. Given
fixed h, BBdP + computes slightly better bounds intervals B networks
cpcs179. networks, BBdP + overhead time respect B.
overhead constant values h networks except cpcs54,
overhead decreases h increases. B BBdP + outperform BdP +. algorithms
compute bound interval length BdP +, improving computation time one
order magnitude. Consider example cpcs422b, challenging instance inference
scheme relatively large induced width loop-cutset size. B outperforms
BdP + 50 seconds starting h = 1181, BBdP + outperforms BdP + 37
352

fiActive Tuples-based Scheme Bounding Posterior Beliefs

h
562
1394
2722
4429
6016
7950
9297
12478

Barley, N =48, w =7, |LC|=12, |DLC | > 2 106 , |E|=4-8
BdP +
B


time(sec)


time(sec)

0.23
0.07
1.7
0.279
0.097
9
0.167
0.23
0.07
1.7
0.263
0.090
23
0.162
0.23
0.07
1.7
0.247
0.084
43
0.154
0.23
0.07
1.7
0.235
0.079
65
0.147
0.23
0.07
1.7
0.230
0.078
86
0.145
0.23
0.07
1.7
0.228
0.077
99
0.145
0.23
0.07
1.7
0.224
0.075
111
0.143
0.23
0.07
1.7
0.219
0.073
139
0.142

%P(e)
1
3
6
14
22
33
40
52

Barley, N=48, w*=7, |LC|=12, |E|=4-8

BBdP+

time(sec)
0.047
10
0.045
25
0.042
45
0.040
67
0.040
88
0.040
101
0.039
113
0.038
141
ATB

Barley, N=48, w*=7, |LC|=12, |E|=4-8

ATB
BdP+

0.25

0.2

0.15

BBdP+

0.3

Avg Bounds Interval

Avg Bounds Interval

BdP+

BBdP+

0.3

0.25

0.2

0.15

0.1

0.1
0

2000

4000

6000

8000

10000

12000

14000

0

20

40

60

80

100

120

time (sec)

h

Figure 4: Results Barley network. table reports average bounds interval I,
average error , computation time (in seconds), percent probability
evidence P (e) covered fully-instantiated cutset tuples function h.
highlight bold face first B data point average bounds
interval good better BdP +. charts show convergence
bounds interval length function h time.

seconds starting h = 253 (BdP + convergence shown plot, best
result reported table).
Larkin (2003) reported bounds cpcs360b cpcs422b using AD algorithm.
first network, AD achieved bounds interval length 0.03 10 seconds. Within
time, B computes average bounds interval 0.005. cpcs422b, AD achieved
bounds interval 0.15, obtained 30 seconds. Within time, B BBdP +
obtain comparable results computing average bounds interval 0.24 0.15, respectively.
important note comparison instances since evidence
nodes same. Larkins code available experiments.
Munin networks. Figure 9 reports results Munin networks. Let us first
consider Munin3 network. Given fixed h, B BBdP + compute almost identical
bound intervals BBdP + noticeable time overhead. Note two curves
chart showing convergence function h close hard distinguish,
points BBdP + chart showing convergence function time
shifted right respect ones B. B clearly superior BdP +
accuracy time. BdP + computes bounds interval 0.24 within 12 seconds,
B computes bounds interval 0.050 8 seconds. Munin4, given fixed
353

fiBidyuk, Dechter & Rollon

h
513
1114
1581
1933
2290
2609
3219
3926
6199
7274

%P(e)
10
19
29
34
40
46
53
59
63
68

cpcs54, N =54, |LC|=15, w =15, |DLC |=32678, |E|=2-8
BdP +
B


time(sec)


time(sec)

0.35
0.02
24
0.51
0.027
0.9
0.34
0.35
0.02
24
0.45
0.023
1.5
0.32
0.35
0.02
24
0.42
0.021
1.9
0.31
0.35
0.02
24
0.40
0.020
2.2
0.30
0.35
0.02
24
0.38
0.019
2.4
0.30
0.35
0.02
24
0.37
0.018
2.7
0.29
0.35
0.02
24
0.34
0.016
3.2
0.27
0.35
0.02
24
0.31
0.014
3.8
0.25
0.35
0.02
24
0.23
0.010
5.9
0.20
0.35
0.02
24
0.20
0.008
6.9
0.17
ATB

cpcs54, N=54, |LC|=15, w*=15, |E|=2-8

BBdP+

time(sec)
0.011
3.1
0.010
3.1
0.009
3.4
0.009
3.6
0.008
3.9
0.007
4.0
0.007
4.5
0.006
5.2
0.006
6.6
0.006
7.3

cpcs54, N=54, |LC|=15, w*=15, |E|=2-8

ATB

BdP+

0.6

Avg Bounds Interval

Avg Bounds Interval

BdP+

BBdP+

0.6
0.5
0.4
0.3
0.2
0.1
0

BBdP+

0.5
0.4
0.3
0.2
0.1
0

0

1000

2000

3000

4000

5000

6000

7000

8000

h

0

2

4

6

8

10

time (sec)

Figure 5: Results cpcs54 network. table reports average bounds interval I,
average error , computation time (in seconds), percent probability
evidence P (e) covered fully-instantiated cutset tuples function h.
highlight bold face first B data point average bounds
interval good better BdP +. charts show convergence
bounds interval length function h time.

h, BBdP + computes tighter bounds B time overhead. However,
improvement decreases h increases shown convergence curves either
function h time. Since loop-cutset size large, convergence B
relatively slow. BdP + computes bounds interval 0.23 within 15 seconds, B
BBdP + compute bounds quality within 54 21 seconds, respectively.
4.3 Bounding Probability Evidence
compare performance following three algorithms: B, mini-bucket elimination (M BE) (Dechter & Rish, 2003), variable elimination conditioning (V EC).
B, test different configurations control parameters (h, k). Note
h = 0, B equivalent plug-in algorithm A, case ABdP +.
4.3.1 Algorithms Benchmarks
general bounding algorithm graphical model problems. particular, given
Bayesian network, computes lower upper bound probability evidence.
354

fiActive Tuples-based Scheme Bounding Posterior Beliefs

h
242
334
406
574
801
996
1285
1669

%P(e)
70
75
78
82
85
87
88
90

cpcs179, N =179, w =8, |LC|=8, |DLC |=49152, |E|=12-24
BdP +
B


time(sec)


time(sec)

0.15
0.05
20
0.22
0.067
4
0.092
0.15
0.05
20
0.12
0.033
6
0.054
0.15
0.05
20
0.09
0.024
7
0.037
0.15
0.05
20
0.07
0.018
9
0.029
0.15
0.05
20
0.05
0.014
10
0.022
0.15
0.05
20
0.04
0.010
12
0.017
0.15
0.05
20
0.03
0.006
13
0.012
0.15
0.05
20
0.02
0.003
16
0.007
ATB

cpcs179, N=179, |LC|=8, w*=8, |E|=12-24

BBdP+

time(sec)
0.029
11
0.016
13
0.010
13
0.008
15
0.006
17
0.005
18
0.003
20
0.002
22
ATB

cpcs179, N=179, |LC|=8, w*=8, |E|=12-24

BdP+

BdP+
BBdP+

1.E-01

1.E-02

1.E-03

BBdP+

1.E+00

Avg Bounds Interval

Avg Bounds Interval

1.E+00

1.E-01

1.E-02

1.E-03

0

500

1000

1500

2000

2500

3000

h

0

5

10

15

20

25

time (sec)

Figure 6: Results cpcs179 network. table reports average bounds interval I,
average error , computation time (in seconds), percent probability
evidence P (e) covered fully-instantiated cutset tuples function h.
highlight bold face first B data point average bounds
interval good better BdP +. charts show convergence
bounds interval length function h time.

control parameter z, allows trading time space accuracy.
value control parameter z increases, algorithm computes tighter bounds using
time space, exponential z.
V EC algorithm combines conditioning variable elimination. based
w-cutset conditioning scheme. Namely, algorithm conditions instantiates
enough variables remaining problem conditioned instantiated variables
solved exactly using bucket elimination (Dechter, 1999). exact probability evidence computed summing exact solution output bucket elimination
possible instantiations w-cutset. V EC terminated completion, outputs partial sum yielding lower bound probability evidence.
implementation V EC publicly available1 .
tested B bounding P (e) three different benchmarks: Two-layer Noisy-Or,
grids coding networks. instances included UAI08 evaluation2 .
two-layer noisy-or networks, variables organized two layers ones
second layer 10 parents. probability table represents noisy OR-function.
1. http://graphmod.ics.uci.edu/group/Software
2. http://graphmod.ics.uci.edu/uai08/Evaluation/Report

355

fiBidyuk, Dechter & Rollon

h
121
282
501
722
938
1168
1388
1582
1757

%P(e)
83
92
96
97
98
98
99
99
99

cpcs360b, N=360, w = 21, |LC| = 26, |DLC |=226 , |E|=11-23
BdP +
B

time(sec)

time(sec)

0.027 0.009
55
0.0486 1.6E-2
5
0.0274
0.027 0.009
55
0.0046 9.0E-4
10
0.0032
0.027 0.009
55
0.0020 3.6E-4
15
0.0014
0.027 0.009
55
0.0012 2.4E-4
19
0.0009
0.027 0.009
55
0.0006 8.4E-5
25
0.0004
0.027 0.009
55
0.0005 7.5E-5
29
0.0004
0.027 0.009
55
0.0004 5.9E-5
35
0.0003
0.027 0.009
55
0.0003 5.3E-5
39
0.0002
0.027 0.009
55
0.0003 4.7E-5
43
0.0002

ATB

cpcs360b, N=360, |LC|=26, w*=21, |E|=11-23

cpcs360b, N=360, |LC|=26, w*=21, |E|=11-23
ATB

1.E+00

BBdP+
time(sec)
1.0E-2
7
8.5E-4
12
3.5E-4
17
2.3E-4
21
7.8E-5
27
6.9E-5
31
5.4E-5
37
4.8E-5
41
4.4E-5
46

BdP+

1.E+00

BdP+

BBdP+

Avg Bounds Interval

Avg Bounds Interval

BBdP+

1.E-01

1.E-02

1.E-03

1.E-01

1.E-02

1.E-03

1.E-04
1.E-04

1.E-05
0

200

400

600

800

1000

1200

h

0

5

10

15

20

25

30

Time (sec)

Figure 7: Results cpcs360b. table reports average bounds interval I, average
error , computation time (in seconds), percent probability evidence
P (e) covered fully-instantiated cutset tuples function h. highlight bold face first B data point average bounds interval
good better BdP +. charts show convergence bounds
interval length function h time.

parent variable yj value Pj [0..Pnoise ]. QThe CPT variable
second layer defined P (x = 0|y1 , . . . , yP ) = yj =1 Pj P (x = 1|y1 , . . . , yP ) =
1 P (x = 0|y1 , . . . , yP ). experiment class problems called bn2o instances
UAI08.
grid networks, variables organized grid. experiment
grids2 instances, called UAI08, characterized two parameters
(M, D), percentage determinism (i.e., percentage values CPTs
assigned either 0 1). parameter configuration, 10 samples generated
randomly assigning value 1 one leaf node. UAI08 competition, instances
named D-M -I, instance number.
Coding networks represented four layer Bayesian network nodes
layer. second third layer correspond input information bits parity check
bits respectively. parity check bit represents XOR function input bits. Input
parity check nodes binary output nodes real-valued. consider
BN 126 BN 134 instances UAI08 evaluation. one = 128, 4 parents
356

fiActive Tuples-based Scheme Bounding Posterior Beliefs

h
64
256
379
561
861
1181
1501
2427
3062
4598

%P(e)
1.7
2.0
2.6
2.9
3.4
4.5
5.4
8.0
9.5
12.2

cpcs422b, N=422, w = 22, |LC| = 47, |DLC |=247 , |E|=4-10
BdP +
ATB


time(sec)


time(sec)

0.19
0.06
120
0.28
0.100
21
0.19
0.19
0.06
120
0.24
0.090
26
0.15
0.19
0.06
120
0.22
0.078
32
0.14
0.19
0.06
120
0.20
0.073
36
0.13
0.19
0.06
120
0.19
0.068
43
0.12
0.19
0.06
120
0.18
0.064
50
0.12
0.19
0.06
120
0.17
0.062
56
0.12
0.19
0.06
120
0.16
0.058
73
0.12
0.19
0.06
120
0.16
0.057
83
0.12
0.19
0.06
120
0.16
0.053
110
0.11
ATB

cpcs422b, N=422, |LC|=47, w*=22, |E|=4-10
0.3

BBdP+

time(sec)
0.056
23
0.050
35
0.049
41
0.046
46
0.044
54
0.041
60
0.041
65
0.039
82
0.038
92
0.036
120

cpcs422b, N=422, |LC|=47, w*=22, |E|=4-10

ATB

0.3

BdP+

BdP+

0.25

Avg Bounds Interval

Avg Bounds Interval

BBdP+

0.2
0.15
0.1
0.05
0

BBdP+

0.25
0.2
0.15
0.1
0.05
0

0

100

200

300

400

500

600

0

20

40

60

80

100

120

140

time (sec)

h

Figure 8: Results cpcs422b. table reports average bounds interval I, average
error , computation time (in seconds), percent probability evidence
P (e) covered fully-instantiated cutset tuples function h. highlight bold face first B data point average bounds interval
good better BdP +. charts show convergence bounds
interval length function h time.

node channel noise variance ( = 0.40). networks hard
exact results available.
Table 2 summarizes characteristics network. one, table specifies
number variables N , induced width w , size loop cutset |LC|, number
loop-cutset tuples |D(LC)|, time needed compute exact posterior marginals
bucket-tree elimination (exponential induced width w ) cutset conditioning
(exponential size loop-cutset). indicates bucket-tree elimination
unfeasible terms memory demands. Note characteristics grid networks
depend sizes percentage determinism; characteristics
coding networks same.
purposes, consider V EC another exact algorithm compute exact
P (e) first second benchmarks lower bounding technique third
benchmark. fix control parameter z w-cutset V EC
algorithms require less 1.5GB space.
357

fiBidyuk, Dechter & Rollon

MUNIN3

h
196
441
882
1813
2695
2891
3185
3577
4312

%P(e)
64
72
78
79
80
81
82
82
83


0.24
0.24
0.24
0.24
0.24
0.24
0.24
0.24
0.24

Munin3, N=1044, w =7, |LC|=30, |E|=257
BdP+
ATB

time(sec)


time(sec)
0.1
12
0.050
0.020
8
0.1
12
0.030
0.011
12
0.1
12
0.025
0.009
18
0.1
12
0.020
0.007
32
0.1
12
0.018
0.006
46
0.1
12
0.017
0.006
49
0.1
12
0.014
0.005
54
0.1
12
0.013
0.004
68
0.1
12
0.011
0.004
80

Munin3, N=1044, |LC|=30, w*=7, |E|=257

0.10

0.01
0

500

1000

1500

BBdP+

time(sec)
0.020
16
0.012
20
0.009
26
0.007
40
0.007
54
0.006
57
0.005
62
0.004
76
0.004
88

Munin3, N=1044, |LC|=30, w*=7, |E|=257

ATB
BdP+
BBdP+

ATB
BdP+

1.00

Avg Bounds Interval

Avg Bounds Interval

1.00


0.048
0.029
0.025
0.019
0.017
0.016
0.014
0.012
0.010

BBdP+

0.10

0.01

2000

0

20

40

h

60

80

100

time (sec)

MUNIN4

h
245
441
1029
2058
3087
5194

%P(e)
1
7
11
17
20
24


0.23
0.23
0.23
0.23
0.23
0.23

Munin4, N=1041, w =8, |LC|=49, |E|=235
BdP+
ATB

time(sec)


time

0.1
15
0.39
0.16
14
0.24
0.1
15
0.32
0.13
17
0.22
0.1
15
0.28
0.12
34
0.21
0.1
15
0.25
0.11
54
0.19
0.1
15
0.22
0.11
83
0.18
0.1
15
0.21
0.09
134
0.17

Munin4, N=1041, |LC|=49, w*=8, |E|=235

BBdP+

time(sec)
0.102
21
0.095
24
0.089
44
0.082
65
0.077
91
0.072
145

Munin4, N=1041, |LC|=49, w*=8, |E|=235

ATB

ATB

BBdP+

Avg Bounds Interval

0.4
0.3
0.2
0.1
0.0
0

5000

10000

15000

20000

Avg Bounds Interval

BdP+

BdP+

0.4

BBdP+
0.3
0.2
0.1
0.0
0

50

100

150

200

250

time (sec)

h

Figure 9: Results munin3 munin4. tables report average bounds interval
I, average error , computation time (in seconds), percent probability
evidence P (e) covered fully-instantiated cutset tuples function h.
highlight bold face first B data point average bounds
interval good better BdP +. charts show convergence
bounds interval length function h time.
358

fiActive Tuples-based Scheme Bounding Posterior Beliefs

network
bn2o-15-30-15
bn2o-15-30-20
bn2o-15-30-25
Grids
Grids
Grids
Grids
coding

16
20
26
42

N

w

|LC|

|D(LC)|

|E|

Time(BE)

Time(LC)

45
50
55
16
20
26
42
512

22
25
24
22
29
40
70
54-61

24
26
25
116
185
325
863
59-64

224
226
225
2116
2185
2325
2863
259 -264

15
20
25
1
1
1
1
256

14.51
174.28
66.23
27.59





17.4 hrs
93.2 hrs
75.76 hrs
> 293 hrs1
> 266 hrs1
> 2306 hrs1
> 2844 hrs1
> 242 hrs1

Table 2: Complexity characteristics benchmarks UAI repository: N -number
nodes, w -induced width, |LC|-number nodes loop-cutset, |D(LC)|loop-cutset state space size, Time(BE) exact computation time via bucket
elimination, Time(LC) exact computation time via loop-cutset conditioning.
results averaged set network instances benchmark.

4.3.2 Results
summarize results benchmark tabular format. tables report
bounds computation time (in seconds) compared algorithm. B,
report results varying values control parameters (h, k). particular, consider values h range 4 200, values k set {210 , 212 , 214 }.
so, analyze impact control parameter performance algorithm.
Grey areas tables correspond (h, k) configurations cannot compared due
computation time.
Two-layer noisy-or networks. Table 3 shows results. expected, quality
bounds produced B improves values control parameters (h, k)
increase. observe best bounds obtained fixing h highest value
(i.e., 200) k smallest value (i.e., 210 ). However, increase value
h leads higher computation times increasing value k. taking
time account, comparing configurations similar time (see (h = 50, k = 210 )
(h = 4, k = 214 ), (h = 200, k = 210 ) (h = 50, k = 212 ), respectively), observe
configuration highest value h smallest value k outperforms
ones.
compared BE, clear superior approach. accuracy
algorithms depends whether look upper lower bounds. considering upper bounds, B outperforms instances 1b, 2b 3b. Note
instances, computes worse upper bounds trivial one (i.e., greater 1).
However, instances 1a, 2a 3a, computes tighter upper bounds B.
lower bounds, general B outperforms MBE instances 20 25 evidence
variables, accurate instances 15 evidence variables. Regarding computation time, B definitely slower BE.

1. Times extrapolated.

359

fiBidyuk, Dechter & Rollon

Inst.

P(e)

h %P(e)

ATB(h, k = 210 )
LB/UB
Time

ATB(h, k = 212 )
LB/UB
Time

ATB(h, k = 214 )
LB/UB
Time

MBE(z=18)
LB/UB
Time

bn2o-30-15-150, |E| = 15
1a 5.9E-05

1b 0.56565

2a 4.0E-07

2b 0.54111

3a 1.2E-04

3b 0.18869

4
50
200
4
50
200
4
50
200
4
50
200
4
50
200
4
50
200

0.0004
0.100
0.250
0.007
0.120
0.460
0.003
0.020
0.320
0.008
0.210
1.110
0.216
1.040
3.580
0.076
0.470
1.440

5.7E-10/5.3E-01
1.2E-07/1.1E-01
3.5E-07/5.7E-02
3.1E-04/9.3E-01
4.1E-03/8.6E-01
1.5E-02/8.5E-01
2.0E-11/1.3E-01
1.5E-10/1.0E-02
1.7E-09/4.0E-03
6.9E-03/7.9E-01
5.5E-02/7.8E-01
1.1E-01/7.5E-01
2.9E-07/1.7E-01
1.7E-06/4.6E-02
5.3E-06/2.7E-02
1.1E-03/7.7E-01
6.8E-03/6.3E-01
2.1E-02/5.4E-01

4
50
200
4
50
200
4
50
200
4
50
200
4
50
200
4
50
200

0.004
0.050
1.880
0.012
0.140
0.430
0.013
0.410
1.410
0.020
0.430
1.620
0.002
0.060
0.090
0.0002
0.110
0.660

5.4E-12/1.6E-02
9.1E-11/1.8E-03
2.8E-09/5.7E-04
1.0E-04/7.3E-01
3.3E-03/6.7E-01
1.1E-02/5.9E-01
3.8E-11/1.6E-02
1.4E-09/3.3E-03
4.5E-09/2.4E-03
6.4E-03/8.3E-01
3.0E-02/7.7E-01
5.9E-02/6.9E-01
8.3E-14/1.8E-03
2.2E-12/1.1E-04
3.6E-12/3.3E-05
4.5E-05/9.7E-01
5.4E-02/9.3E-01
1.1E-01/8.8E-01

4
50
200
4
50
200
4
50
200
4
50
200
4
50
200
4
50
200

0.0004
0.01
0.06
0.016
0.22
1.07
0.0004
0.0012
0.07
0.018
0.19
0.65
0.0001
0.01
0.20
0.0065
0.45
1.52

1.3E-14/6.6E-02
3.7E-13/3.3E-03
2.0E-12/1.1E-03
4.3E-04/8.1E-01
4.6E-03/7.2E-01
1.3E-02/6.5E-01
1.8E-12/1.9E-01
5.7E-12/4.5E-02
1.8E-10/2.2E-02
5.3E-04/7.6E-01
5.4E-03/7.4E-01
1.4E-02/7.1E-01
1.7E-16/1.1E-01
4.3E-14/1.9E-02
5.5E-13/7.1E-03
1.0E-03/7.9E-01
4.2E-02/7.7E-01
8.5E-02/7.5E-01

2
32
103
2
31
102
2
29
89
2
29
90
2
26
74
2
25
69

5.9E-10/4.8E-01
1.2E-07/9.4E-02

8 6.0E-10/4.4E-01
129

38

4.3E-04/9.3E-01
4.8E-03/8.6E-01

8 5.0E-04/9.3E-01
124

38

2.0E-11/1.1E-01
1.5E-10/8.9E-03

8 2.1E-11/8.5E-02
115

38

8.6E-03/8.0E-01
6.1E-02/7.7E-01

8 9.2E-03/8.0E-01
115

38

2.9E-07/1.5E-01
1.7E-06/4.2E-02

8 2.9E-07/1.4E-01
103

38

1.1E-03/7.7E-01
7.1E-03/6.3E-01

8 1.2E-03/7.7E-01
95

38

9.1E-06/4.8E-04

2

0.17277/1.42

2

8.4E-10/2.1E-05

2

0.02647/1.8

2

4.4E-07/1.5E-03

2

0.03089/0.81

2

2.4E-15/3.3E-04

3

9.8E-04/1.9

3

4.4E-15/8.0E-05

3

2.3E-05/2.9

3

5.2E-13/1.7E-06

3

5.3E-03/1.9

3

1.7E-16/3.1E-06

4

1.4E-03/1.4

4

1.8E-12/1.2E-05

4

7.2E-03/1.7

4

1.3E-15/4.9E-07

4

3.5E-03/2.7

4

bn2o-30-20-200, |E| = 20
1a 1.4E-07

1b 0.15654

2a 2.2E-07

2b 0.27695

3a 2.4E-09

3b 0.48039

3
62
195
3
64
218
3
52
169
3
51
145
3
58
198
3
64
194

5.4E-12/1.5E-02
9.1E-11/1.6E-03

16 5.4E-12/1.4E-02
264

67

1.1E-04/7.3E-01
3.6E-03/6.7E-01

16 1.1E-04/7.3E-01
279

68

3.8E-11/1.6E-02
1.3E-09/3.1E-03

16 3.8E-11/1.5E-02
211

70

7.3E-03/8.3E-01
3.3E-02/7.7E-01

16 8.0E-03/8.3E-01
197

68

8.3E-14/1.8E-03
2.2E-12/1.1E-04

16 8.3E-14/1.8E-03
236

68

5.1E-05/9.7E-01
5.9E-02/9.3E-01

16 6.2E-05/9.7E-01
277

68

bn2o-30-25-250, |E| = 25
1a 2.9E-09

1b 0.15183

2a 2.4E-07

2b 0.30895

3a 2.7E-10

3b 0.46801

6
119
396
6
120
381
6
112
402
6
107
367
6
119
409
6
106
337

1.3E-14/6.5E-02
3.7E-13/2.8E-03

22 1.3E-14/4.8E-02
429

99

5.7E-04/8.1E-01
6.7E-03/7.2E-01

22 6.2E-04/8.1E-01
437

99

1.8E-12/1.9E-01
5.7E-12/3.9E-02

22 1.8E-12/1.7E-01
398

99

5.9E-04/7.6E-01
6.1E-03/7.4E-01

22 6.3E-04/7.6E-01
374

99

1.7E-16/1.1E-01
4.3E-14/1.6E-02

22 1.7E-16/8.1E-02
427

99

1.2E-03/7.9E-01
4.8E-02/7.7E-01

22 1.3E-03/7.9E-01
352

98

Table 3: Results bn2o networks. table shows LB UB computed B
varying number cutset tuples h maximum domain k Markov
boundary.
360

fiActive Tuples-based Scheme Bounding Posterior Beliefs

(M, D)

P(e)

h

4
(16, 50) 0.6172 100
200
4
(20, 50) 0.4441 100
200
4
(20, 75) 0.4843 100
200
4
(26, 75) 0.6579 100
200
4
(26, 90) 0.8206 100
200
4
(42, 90) 0.4933 100
200

%P(e)
1.57E-14
3.50E-11
4.22E-11
1.07E-24
1.57E-21
1.13E-20
1.25E-09
2.40E-09
2.89E-09
3.88E-19
7.32E-19
1.55E-18
3.47E-08
3.41E-06
8.38E-06
8.65E-29
2.32E-25
3.48E-25

Grids2, |E| = 1
ATB(k = 210 ,h)
ATB(k = 212 ,h)
LB/UB
Time
LB/UB
Time
0.3127/0.8286
1 0.3127/0.8286
1
0.3127/0.8286
57 0.3127/0.8286
57
0.3127/0.8286
111
0.1765/0.4939
5 0.1765/0.4939
5
0.1765/0.4939
208 0.1765/0.4939
203
0.1765/0.4939
412
0.2106/0.7454
3 0.2106/0.7454
3
0.2106/0.7454
81 0.2106/0.7454
80
0.2106/0.7454
156
0.0506/0.9338
6 0.0506/0.9338
6
0.0506/0.9338
268 0.0506/0.9338
270
0.0506/0.9338
534
0.1858/0.8943
2 0.1858/0.8943
2
0.1858/0.8943
85 0.1858/0.8943
84
0.1858/0.8943
164
0.0048/0.9175
10 0.0048/0.9175
10
0.0048/0.9175
436 0.0048/0.9175
439
0.0048/0.9175
866

ATB(k = 214 ,h)
MBE
LB/UB
Time LB / UB Time
0.3127/0.8286
1
0/5.13
16
0.1765/0.4939

0.2106/0.7454

0.0506/0.9338

0.1858/0.8943

0.0048/0.9175

5
0/12411

39

0/1E+05

39

0/1E+10

84

0/1E+10

87

0/1E+10

110

3

6

2

10

Table 4: Results grid networks. table shows LB UB computed B
varying number cutset tuples h maximum length k conditional
probability tables Markov boundary.

Grid networks. Table 4 reports results. first thing observe
computes completely uninformative bounds. case, anytime behavior B
effective either. increase value control parameters (h, k) affect
accuracy. Since Markov boundary grid networks relatively small, smallest
tested value k higher Markov boundary size explains independence
k. Another reason ineffectiveness may high percentage determinism
networks. known sampling methods inefficient presence
determinism. consequence, percentage probability mass accumulated
h sampled tuples significant, cancels benefits computing exact probability evidence subset tuples. Therefore, cases sophisticated
sampling scheme used, example (Gogate & Dechter, 2007). Consequently,
deterministic grids, Bs performance controlled totally bound propagation
plugged-in algorithm.
Coding networks. Table 5 shows results. report percentage P (e)
covered fully-instantiated cutset tuples exact P (e) available.
set time limit V EC 1900 seconds (i.e., maximum computation time required
running B instances). report results k = 210 k = 214
increase value k effective result increased
accuracy. case, accuracy B increases value h increases. comparing B algorithms distinguish lower upper
bounds. Regarding lower bounds, B clearly outperforms V EC instances. Indeed, lower bound computed V EC loose. Regarding
361

fiBidyuk, Dechter & Rollon

Inst.

BN 126

BN 127

BN 128

BN 129

BN 130

BN 131

BN 132

BN 133

BN 134

h
4
50
150
4
50
150
4
50
150
4
50
150
4
50
150
4
50
150
4
50
150
4
50
150
4
50
150

coding, |E| = 256
ATB(k = 210 ,h)
ATB(k = 214 ,h)
LB/UB
Time
LB/UB
Time
1.9E-76/1.5E-41
50 1.9E-76/1.52E-41 3494
1.9E-69/2.5E-42
632
1.9E-58/1.3E-42 1442
5.3E-60/2.3E-43
55 5.3E-60/2.3E-43
399
1.3E-58/2.3E-44
426
1.6E-58/1.9E-44
946
7.2E-54/1.6E-42
85 7.2E-54/1.6E-42
582
4.9E-48/7.2E-43
637
4.9E-48/1.4E-43 1225
1.4E-72/8.2E-45
50 1.5E-72/8.2E-45
362
1.5E-64/2.1E-45
585
8.5E-64/5.4E-46 1400
4.7E-65/2.9E-44
47 4.7E-65/2.9E-44
324
6.3E-63/2.9E-45
619
3.7E-58/2.3E-45 1299
1.9E-60/1.3E-44
52 1.9E-60/1.3E-44
367
2.3E-54/3.7E-45
484
2.3E-54/1.1E-45 1276
2.3E-79/6.3E-44
50 2.3E-79/6.3E-44
363
3.6E-67/1.0E-44
689
1.5E-66/8.1E-45 1627
1.6E-56/2.7E-42
53 1.6E-56/2.7E-42
398
1.1E-54/2.4E-43
671
2.3E-54/9.5E-44 1846
8.9E-63/1.8E-43
47 8.9E-63/1.8E-43
355
1.2E-62/8.6E-45
606
6.1E-57/4.8E-45 1412

MBE(z=22)
LB/UB
Time

VEC
LB
Time

1.4E-139/1.5E-044

143 9.2E-102

1900

1.6E-134/1.0E-045

164 5.3E-115

1900

1.2E-144/5.1E-043

124 1.9E-112

1900

2.8E-139/4.8E-043

144 1.5E-115

1900

1.1E-132/1.9E-045

112

1.3E-96

1900

2.3E-141/3.2E-045

119 3.2E-102

1900

2.8E-134/2.3E-048

109 8.9E-111

1900

1.8E-136/4.1E-045

147 1.9E-109

1900

1.9E-148/3.9E-045

163 4.2E-111

1900

Table 5: Results coding networks. table shows LB UB computed B
varying number cutset tuples h maximum length k conditional
probability tables Markov boundary.

upper bounds, B(h = 150, k = 210 ) outperforms three instances (i.e., BN 128,
BN 129 BN 131). taking time account B outperforms
instance BN 129.
Summary empirical evaluation. demonstrated Bs bounds converge
h, number cutset tuples computed exactly, increases. speed convergence varied
among benchmarks. convergence faster active cutset tuples accounted
large percentage probability mass P (C|e), shown case cpcs54,
cpcs179, cpcs360 networks. Comparing variant bound propagation called
BdP +, B accurate given sufficient time even given time
bound, computed accurate bounds many benchmarks.
showed Bs bounds posterior marginals improved
used initial bounds BdP +. call hybrid B followed BdP +
BBdP + algorithm. experiments demonstrated added power BBdP +
exploiting time-accuracy trade-off.
also compared power B bound probability evidence
mini-bucket elimination (M BE). showed neither algorithm dominating
benchmarks. Given amount time, B computed accurate bounds
362

fiActive Tuples-based Scheme Bounding Posterior Beliefs

instances bn2o coding networks. B outperformed
instances grid networks computed bounds 0 1.
benchmark, however, B converged slowly. believe part due
grids large loop-cutset sizes.
compared Bs ability compute lower bound P (e) V EC coding
networks. V EC obtains bound computing partial sum cutset-conditioning
formula (see Eq. 2). comparing lower bounds generated B V EC,
gain insight trade-off enumerating cutset tuples bounding
uninstantiated tuples. Since Bs lower bound consistently tighter, conclude
bounding uninstantiated tuples cost-effective.

5. Related Work
three early approaches use principle B: Pooles algorithm
(1996), bounded conditioning (BC) (Horvitz et al., 1989) already described,
bounded recursive decomposition (Monti & Cooper, 1996). cases computation bounds composed exact inference subset tuples
bounding scheme total probabilities rest tuples.
Similar B, Pooles scheme based partial exploration search tree.
However, search tree corresponds state space variables whole
network hence, exponential total number variables. contrast, tree
structure used approach corresponds state space loop-cutset variables;
therefore, exponential loop-cutset size only. addition, Poole updates
bounding function tuple probability 0 (i.e., conflict) discovered.
discussed Section 2.2, BC also based cutset conditioning principle,
two main differences relative B: (i) probability mass missing
tuples bounded via prior probabilities, consequently (ii) proved, upper
bound expression looser.
Bounded recursive decomposition uses Stochastic simulation (Pearl, 1988) generate
highly probable instantiations variables, similar B, bounds
missing elements 0 prior values. Therefore approach resembles Pooles algorithm bounded conditioning. Unlike B, bounded recursive decomposition requires
instantiation variables network relies priors guide simulation. contrast, algorithm uses Gibbs sampling cutset likely
accurate selecting high probability tuples presence evidence. B subsumes three algorithms offering unifying approach bounding posteriors anytime
properties, able improve bounds investing time exploring cutset
tuples.
number alternative approaches computing bounds marginals.
Poole (1998) proposed context-specific bounds obtained simplifying conditional
probability tables. method performs variant bucket elimination intermediate tables collapsed grouping probability values together. However, since
method validated small car diagnosis network 10 variables, hard
draw conclusions. Larkin (2003) also obtains bounds simplifying intermediate
probability tables variable elimination order. solves optimization problem
363

fiBidyuk, Dechter & Rollon

find table decomposition minimizes error. Kearns Saul (1999, 1998) proposed specialized large deviation bounds approach layered networks, Mannino
Mookerjee (2002) suggested elaborate bounding scheme nonlinear objective
functions. Jaakkola Jordan (1999) proposed variational method computing lower
upper bounds posterior marginals Noisy-Or networks evaluated performance case diagnostic QMR-DT network. recent approaches (Tatikonda,
2003; Taga & Mase, 2006; Ihler, 2007; Mooij & Kappen, 2008) aim bound error
belief propagation marginals. first two approaches exponential size
Markov boundary. third approach linear size network, formulated
pairwise interactions only. Finally, fourth algorithm exponential number
domain values. Recently, Mooij Kappen (2008) proposed box propagation algorithm
propagates local bounds (convex sets probability distributions) subtree
factor graph representing problem, rooted variable interest.
important note approach offers anytime framework computing
bounds bounding algorithms used subroutine bound
joint probabilities partially-instantiated tuples within B therefore may improve
performance bounding scheme.
Regarding algorithms bound probability evidence, already mentioned
mini-bucket schemes compared Section 4.3. Another recent approach
tree-reweighted belief propagation (T RW -BP ) (Wainwright, Jaakkola, & Willsky, 2005).
RW -BP class message-passing algorithms compute upper bound P (e)
convex combination tree-structured distributions. recent paper, Rollon
Dechter (2010) compare RW -BP , box propagation (adapted computing probability evidence using chain rule), B-ABdP +. empirical evaluation
shows relative strength scheme different benchmarks (Rollon & Dechter,
2010). another recent work Wexler Meek (2008) proposed MAS, bounding
algorithm computing probability evidence. Shekhar (2009) describes adjustments required produce bounds using MAS Bayesian networks, potentials
less 1. forthcoming paper, Wexler Meek (2010) improve MAS scheme
obtain tighter bounds describe obtain bounds Bayesian networks P (e)
well inferential problems maximal posteriori probable
explanation problems. comparison approach left future work.

6. Summary Conclusions
paper explores general theme approximation bounding algorithms likelihood computation, task known hard. methods based one
two principles emerge, clear pooling together variety ideas single
framework yield significant improvement. current paper provides framework. utilizes principle cutset conditioning harnessing varied strengths
different methods. framework inherently anytime, important characteristic
approximation schemes.
Cutset conditioning universal principle. allows decomposing problem
collection tractable ones. subproblems solved exactly
others approximated. scheme controlled several parameters. w364

fiActive Tuples-based Scheme Bounding Posterior Beliefs

cutset condition subset variables treewidth bounded w.
subproblem solved exactly time space exponential w. number
subproblems large, use another parameter, h, control number
subproblems solved exactly. rest subproblems solved using off-the-shelf
bounding scheme.
developed expression incorporates aspects using parameters:
w - induced-width cutset, h - number cutset conditioning subproblems
solved exactly (e.g., bucket elimination), - approximation algorithm
bounds bounded subproblems. showed number subproblems
approximated polynomial h.
empirical evaluation general framework, called B, used loopcutset scheme (w = 1) chose bounding algorithm variant bound propagation
(Leisink & Kappen, 2003), yielding integrated scheme call ABdP +. experimented several benchmarks computing posterior marginals probability
evidence, compared relevant state art algorithms.
results demonstrate value B framework across benchmarks
tried. expected, anytime aspect visible showing improved accuracy
function time. significantly, even provided equal time space
resources, B showed remarkable superiority compared variant bound
propagation mini-bucket elimination algorithm (M BE) (Dechter & Rish,
2003). latter recently investigated Rollon Dechter (2010).
Overall, conclude B competitive algorithm bounding posterior marginals probability evidence. Generally, expect B perform well
networks whose cutset C small relative total number variables whose
distribution P (C|e) small number high probability tuples.
possibilities future work many. explore additional trade offs
increasing w therefore decreasing h improving selection h tuples.
looked one possible instantiation plug-in algorithm A. approximation
algorithms tried may offer different time/accuracy trade-offs. particular,
plan investigate effectiveness B using plug-in algorithm.

Acknowledgments
work supported part NSF award numbers IIS-0331707, IIS-0412854
IIS-0713118 NIH grant R01-HG004175-02.
Emma Rollons work done postdoctoral student Bren School
Information Computer Sciences, University California, Irvine.
work presented part (Bidyuk & Dechter, 2006a, 2006b).

Appendix A. Analysis Bounded Conditioning
Theorem 2.1 interval lower upper bounds computed bounded
conditioning lower bounded probability mass
prior distribution P (C)
PM
U (x|e) P L (x|e)

unexplored cutset tuples: h, PBC
i=h+1 P (c ).
BC
365

fiBidyuk, Dechter & Rollon

Proof.
U
PBC
(x|e)



L
PBC
(x|e)

=
+

=



PM

PM


i=1 P (c , e) +
i=h+1 P (c ))
Ph

i=1 P (c , e)
Ph
Ph


i=1 P (x, c , e)
i=1 P (x, c , e)
Ph
Ph
P




i=1 P (c , e)
i=1 P (c , e) +
i=h+1 P (c )
P
P
PM

h



i=h+1 P (c ))
i=h+1 P (c )( i=1 P (c , e) +
Ph

i=1 P (c , e)
P


2
X
X
(
i=h+1 P (c ))

P (c ) + Ph
P (ci )

, e)
P
(c
i=1
i=h+1
i=h+1
i=h+1 P (c

)(

Ph

Appendix B. Bounding Posteriors Cutset Nodes
far, considered computation posterior marginals variable X X \(C
E). focus computing bounds cutset node Ck C. Let c0k D(C)
value domain Ck . Then, compute exact posterior marginal P (ck |e) using Bayes
formula:
PM
P (c0k , e)
(c0 , ci )P (ci , e)
0
P (ck |e) =
(23)
= i=1
PM k
, e)
P (e)
P
(c
i=1

(c0k , ci ) Dirac delta-function (c0k , ci ) = 1 iff cik = c0k (c0k , ci ) = 0
otherwise. simplify notation, let Z = C\Z. Let Mk denote number tuples
state-space Z. re-write numerator as:

X

(c0k , ci )P (ci , e)

=

i=1

Mk
X

P (c0k , z , e)

i=1

denominator decomposed as:

X

P (ci , e) =

i=1

X

Mk
X

P (c0k , z , e)

ck D(Ck ) i=1

Then, re-write expression P (c0k |e) follows:
PM k
0

0
i=1 P (ck , z , e)
P (ck |e) = P
PM k

ck D(Ck )
i=1 P (ck , z , e)

(24)

Let hck number full cutset tuples cik = ck . Then, decompose
numerator Eq. (24) follows:
Mk
X
i=1

hc0

P (c0k , z , e)

=

k
X

P (c0k , z , e)

+

Mk
X

i=hc0 +1

i=1

k

366

P (c0k , z , e)

fiActive Tuples-based Scheme Bounding Posterior Beliefs

Similarly, decompose sums denominator:
X

Mk
X

P (ck , z , e) =

ck D(Ck ) i=1

hck
X

X



P (ck , z , e) +

X

Mk
X

P (ck , z , e)

ck D(Ck ) i=hck +1

ck D(Ck ) i=1

decomposition, Eq. (24) takes form:
P (c0k |e)

Phc0k


0
i=1 P (ck , z , e)

=P

ck D(Ck )

Phck

i=1 P (ck , z

, e)

+
+

P Mk

0

i=hc0 +1 P (ck , z , e)

P

k

ck D(Ck )

P Mk

i=hck +1 P (ck , z

, e)

(25)

Now, conciseness, group together fully instantiated tuples denominator:
hck
X

X

P (ck , z , e) =

h
X

P (ci , e)

i=1

ck D(Ck ) i=1

Then, Eq. (25) transforms into:
P (c0k |e)

Phc0k

0

i=1 P (ck , z , e)

= Ph

i=1

Now, replace sum

P (ci , e)

PM k

+

i=hc0 +1

+

PM k

P Mk

i=hck +1

0

i=hc0 +1 P (ck , z , e)

P

k


ck D(Ck ) P (ck , z , e)

(26)

unexplored cutset tuples sum

k

partially-instantiated cutset tuples. Denoting Mc0k = Mk hck + 1 number
partially instantiated cutset tuples Ck = ck , obtain:
0

PMc0k
j
0 , z , e) +
0
P
(c
i=1
j=1 P (ck , z1:qj , e)
k
P (c0k |e) = P
PMc0k P
j
h

ck D(Ck ) P (ck , z1:qj , e)
i=1 P (c , e) +
j=1
Phc0k

(27)

order obtain lower upper bounds formulation, separate sum joint
j
, e) Ck = c0k rest:
probabilities P (c0k , z1:q
j
P (c0k |e) =
Ph

i=1 P (c

, e)

0
PMc0k
j
0

0
i=1 P (ck , z , e) +
j=1 P (ck , z1:qj , e)
0
PMc0
PMc0 P
j
j
, e)
+ j=1k P (c0k , z1:q
, e) + j=1k ck 6=c0 P (ck , z1:q
j
j
k

Phc0k

(28)

expression above, probabilities P (ck , z , e) P (ci , e) computed exactly since
, e), however,
correspond full cutset instantiations. Probabilities P (ck , z1:q

bounded since partial cutset observed. Observing numerator
, e) replacing upper bound
denominator component P (c0k , z1:q

, e) numerator denominator, obtain upper bound
P U (c0k , z1:q

P (c0k |e) due Lemma 3.2:
P (c0k |e)
Ph

i=1

P (ci , e)

0
PMc0k U 0 j
0

i=1 P (ck , z , e) +
j=1 PA (ck , z1:qj , e)
0

P c0
PMc0 P
j
j
, e)
+ j=1k PAU (c0k , z1:q
, e) + j=1k ck 6=c0 P (ck , z1:q
j
j
k

Phc0k

367

(29)

fiBidyuk, Dechter & Rollon

j
Finally, replacing P (ck , z1:q
, e), ck 6= c0k , lower bound (also increasing fraction value),
j
obtain:

Phc0k

PMc0k
0

i=1 P (ck , z , e) +
j=1
PMc0k U 0 j
j=1 PA (ck , z1:qj , e) +

j
, e)
PAU (c0k , z1:q
j
= PcU
P
0 P
P

ck
j
h
L

ck 6=c0k PA (ck , z1:qj , e)
i=1 P (c , e) +
j=1
(30)
, e)
lower bound derivation similar. start Eq. (28) replace P (c0k , z1:q

numerator denominator lower bound. Lemma 3.2 guarantees
resulting fraction lower bound P (c0k |e):

P (c0k |e)

P (c0k |e)
Ph

i=1

P (ci , e)

0
PMc0k L 0 j
0

i=1 P (ck , z , e) +
j=1 PA (ck , z1:qj , e)
0

P c0
PMc0k P
j
j
+ j=1k PAL (c0k , z1:q
,
e)
+
ck 6=c0k P (ck , z1:qj , e)
j=1
j

Phc0k

(31)

P
j
j
, e)
Finally, grouping PAL (c0k , z1:q
ck 6=c0k P (ck , z1:qj , e) one sum replacing
j
P
j
j
PAL (c0k , z1:q
, e) upper bound, obtain lower bound PcL :
, e) + ck 6=c0 P (ck , z1:q
j
j
k

P (c0k |e)

0

0

i=1 P (ck , z , e) +


Ph

i=1



Phc0k

j
, e)
U B[PAL (c0k , z1:q
j

P (ci , e)

+

X

+

0

PMc0k

PMc0k
j=1

j
, e)
PAL (c0k , z1:q
j

j
L 0
j=1 U B[PA (ck , z1:qj , e)

j
, e)]
P (ck , z1:q
j

= min

ck 6=c0k

(

+

P

= PcL

(32)

j
ck 6=c0k P (ck , z1:qj , e)]

j
, e) +
PAL (c0k , z1:q
j
j
, e)
PAU (z1:q
j

P

ck 6=c0k

j
, e)
PAU (ck , z1:q
j

lower bound PcL cutset equivalent lower bound P L obtained Eq. (15).
respect computing bounds P (c0k , z1:q , e) Eq. (30) (32) practice,
distinguish two cases. demonstrate example upper bound.
first case, partially instantiated
tuple c1:q includes node Ck , namely

k q, decomposed c1:q = z1:q c0k that:
P U (c0k , z1:q , e) = P U (c1:q , e)

second case concerns partially instantiated tuples c1:q include node
Ck , namely k > q. case, compute upper bound decomposing:
P U (c0k , z1:q , e) = P U (ck |c1:q )P U (c1:q , e)

Appendix C. ATB Properties
Theorem 3.2 B bounds interval length upper bounded monotonic nonincreasing function h:
PM
j
j=h+1 P (c )
U
L
PA (x|e) PA (x|e) Ph
, Ih
P


j
i=1 P (c , e) +
j=h+1 P (c )
368

fiActive Tuples-based Scheme Bounding Posterior Beliefs

Proof. upper bound bounds interval follows fact that, PAU (x|e)
U (x|e) P L (x|e) definitions brute force lower PBF
BF
per bounds given Eq. (21) (22). need prove upper bound
monotonously non-increasing function h.
P
PM
j
j
P (ch ) +
j=h+1 P (c )
j=h P (c )
=
Ih1 = Ph1
P
P
P


h1
j
j


h
j=h P (c )
j=h+1 P (c )
i=1 P (c , e) +
i=1 P (c , e) + P (c ) +

PAL (x|e)

Since P (ch ) P (ch , e), replacing P (ch ) P (ch , e) applying Lemma 3.1, yields:
P
P
j
j
P (ch , e) +
P (ch , e) +
j=h+1 P (c )
j=h+1 P (c )
Ih1 Ph1
= Ph
PM
PM

h
j

j
i=1 P (c , e) + P (c , e) +
j=h+1 P (c )
i=1 P (c , e) +
j=h+1 P (c )
PM
j
j=h+1 P (c )
Ph
= Ih
P


j
i=1 P (c , e) +
j=h+1 P (c )

Thus, Ih1 Ih .



References
Abdelbar, A. M., & Hedetniemi, S. M. (1998). Approximating MAPs belief networks
NP-hard theorems. Artificial Intelligence, 102, 2138.
Andreassen, S., Jensen, F., Andersen, S., Falck, B., Kjaerulff, U., Woldbye, M., Srensen, A.,
Rosenfalck, A., & Jensen, F. (1990). Munin - expert EMG assistant. Desmedt,
J. E. (Ed.), Computer-Aided Electromyography Expert Systems, chap. 21. Elsevier
Science Publishers, Amsterdam.
Becker, A., & Geiger, D. (1996). sufficiently fast algorithm finding close optimal
junction trees. Proceedings 12th Conference Uncertainty Artificial
Intelligence (UAI-96), pp. 8189, Portland, Oregon, USA. Morgan Kaufmann.
Beinlich, I., Suermondt, G., Chavez, R., & Cooper, G. (1989). ALARM monitoring
system: case study two probabilistic inference techniques belief networks.
Proceedings Second European Conference AI Medicine. SpringerVerlag.
Bidyuk, B. (2006). Exploiting Graph Cutsets Sampling-Based Approximations
Bayesian Networks. Ph.D. Thesis. Ph.D. thesis, University California, Irvine.
Bidyuk, B., & Dechter, R. (2003a). Cycle-cutset sampling Bayesian networks. Proceedings 16th Canadian Conference Artificial Intelligence (AI2006), pp.
297312, Halifax, Canada.
Bidyuk, B., & Dechter, R. (2003b). Empirical study w-cutset sampling Bayesian networks. Proceedings 19th Conference Uncertainty Artificial Intelligence
(UAI-2003), pp. 3746, Acapulco, Mexico. Morgan Kaufmann.
Bidyuk, B., & Dechter, R. (2006a). anytime scheme bounding posterior beliefs.
Proceedings 21st National Conference Artificial Intelligence (AAAI2006),
pp. 10951100, Boston, MA, USA.
369

fiBidyuk, Dechter & Rollon

Bidyuk, B., & Dechter, R. (2006b). Improving bound propagation. Proceedings
17th European Conference AI (ECAI2006), pp. 342346, Riva Del Garda, Italy.
Bidyuk, B., & Dechter, R. (2007). Cutset sampling bayesian networks. Journal
Artificial Intelligence Research, 28, 148.
Cooper, G. (1990). computational complexity probabilistic inferences. Artificial
Intelligence, 42, 393405.
Dagum, P., & Luby, M. (1993). Approximating probabilistic inference Bayesian belief
networks NP-hard. Artificial Intelligence, 60 (1), 141153.
Dechter, R. (1999). Bucket elimination: unifying framework reasoning. Artificial
Intelligence, 113, 4185.
Dechter, R., & Rish, I. (2003). Mini-buckets: general scheme bounded inference.
Journal ACM, 50, 107153.
Gogate, V., & Dechter, R. (2007). Samplesearch: scheme searches consistent
samples. Proceedings 11th International Conference Artificial Intelligence
Statistics (AISTATS2007), pp. 198203.
Horvitz, E., Suermondt, H., & Cooper, G. (1989). Bounded conditioning: Flexible inference decisions scarce resources. Workshop Uncertainty Artificial
Intelligence, pp. 181193, Windsor, ON.
Ihler, A. (2007). Accuracy bounds belief propagation. Proceedings 23rd Conference Uncertainty Artificial Intelligence (UAI-2007), pp. 183190, Corvallis,
Oregon. AUAI Press.
Jaakkola, T. S., & Jordan, M. I. (1999). Variational probabilistic inference qmr-dt
network. Journal Artificial Intelligence Research, 10, 291322.
Kask, K., & Dechter, R. (1999). Stochastic local search Bayesian networks. Heckerman, D., & Whittaker, J. (Eds.), Workshop AI Statistics, pp. 113122. Morgan
Kaufmann.
Kearns, M., & Saul, L. (1998). Large deviation methods approximate probabilistic inference, rates convergence. Proceedings 14th Conference Uncertainty
Artificial Intelligence (UAI), pp. 311319. Morgan Kaufmann.
Kearns, M., & Saul, L. (1999). Inference multilayer networks via large deviation bounds.
Advances Neural Information Processing Systems, 11, 260266.
Kristensen, K., & Rasmussen, I. (2002). use Bayesian network design
decision support system growing malting Barley without use pesticides.
Computers Electronics Agriculture, 33, 197217.
Larkin, D. (2003). Approximate decomposition: method bounding estimating
probabilistic deterministic queries. Proceedings 19th Conference
Uncertainty Artificial Intelligence (UAI-2003), pp. 346353, Acapulco, Mexico.
Leisink, M. A. R., & Kappen, H. J. (2003). Bound propagation. Journal Artificial
Intelligence Research, 19, 139154.
370

fiActive Tuples-based Scheme Bounding Posterior Beliefs

Mannino, M. V., & Mookerjee, V. S. (2002). Probability bounds goal directed queries
Bayesian networks. IEEE Transactions Knowledge Data Engineering, 14 (5),
11961200.
Monti, S., & Cooper, G. (1996). Bounded recursive decomposition: search-based method
belief network inference limited resources. International Journal Approximate Reasoning, 15, 4975.
Mooij, J. M., & Kappen, H. J. (2008). Bounds marginal probability distributions.
Advances Neural Information Processing Systems 22 (NIPS2008), pp. 11051112,
Vancouver, British Columbia, Canada, December 8-11.
Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems. Morgan Kaufmann.
Poole, D. (1996). Probabilistic conflicts search algorithm estimating posterior
probabilities Bayesian networks. Artificial Intelligence, 88 (12), 69100.
Poole, D. (1998). Context-specific approximation probabilistic inference. Proceedings
14th Uncertainty Artificial Intelligence (UAI-98), pp. 447454.
Pradhan, M., Provan, G., Middleton, B., & Henrion, M. (1994). Knowledge engineering
large belief networks. Proceedings 10th Conference Uncertainty Artificial
Intelligence, Seattle, WA, pp. 484490.
Rollon, E., & Dechter, R. (2010). New mini-bucket partitioning heuristics bounding
probability evidence. Proceedings 24th National Conference Artificial
Intelligence (AAAI2010), pp. 11991204, Atlanta, GA.
Roth, D. (1996). hardness approximate reasoning. Artificial Intelligence, 82 (1-2),
273302.
Shekhar, S. (2009). Fixing extending multiplicative approximation scheme. Masters
thesis, School Information Computer Science, University California, Irvine.
Taga, N., & Mase, S. (2006). Error bounds marginal probabilities beliefs
loopy belief propagation algorithm. Advances Artificial Intelligence, Proceedings
5th Mexican International Conference Artificial Intelligence (MICAI2006), pp.
186196, Apizaco, Mexico, November 13-17.
Tatikonda, S. C. (2003). Convergence sum-product algorithm. Proceedings
IEEE Information Theory Workshop, pp. 222225.
Wainwright, M. J., Jaakkola, T., & Willsky, A. S. (2005). new class upper bounds
log partition function. IEEE Trans. Information Theory, 51 (7), 23132335.
Wexler, Y., & Meek, C. (2008). MAS: multiplicative approximation scheme probabilistic inference. Koller, D., Schuurmans, D., Bengio, Y., & Bottou, L. (Eds.),
Advances Neural Information Processing Systems 22 (NIPS2008), pp. 17611768.
MIT Press.
Wexler, Y., & Meek, C. (2010). Approximating max-sum-product problems using multiplicative error bounds. Bayesian Statistics 9, p. appear. Oxford University
Press.

371

fiJournal Artificial Intelligence Research 39 (2010) 179- 216

Submitted 04/10; published 09/10

Cooperative Games Overlapping Coalitions
Georgios Chalkiadakis

GC 2@ ECS . SOTON . AC . UK

School Electronics Computer Science,
University Southampton, SO17 1BJ, UK

Edith Elkind

EELKIND @ NTU . EDU . SG

School Physical Mathematical Sciences,
Nanyang Technological University, 637371, Singapore

Evangelos Markakis

MARKAKIS @ GMAIL . COM

Department Infomatics,
Athens University Economics Business, GR10434, Greece

Maria Polukarov
Nicholas R. Jennings

MP 3@ ECS . SOTON . AC . UK
NRJ @ ECS . SOTON . AC . UK

School Electronics Computer Science,
University Southampton, SO17 1BJ, UK

Abstract
usual models cooperative game theory, outcome coalition formation process
either grand coalition coalition structure consists disjoint coalitions. However,
many domains coalitions associated tasks, agent may involved executing
one task, thus may distribute resources among several coalitions. tackle
scenarios, introduce model cooperative games overlapping coalitionsor overlapping coalition formation (OCF) games. explore issue stability setting.
particular, introduce notion core, generalizes corresponding notion
traditional (non-overlapping) scenario. Then, quite general conditions, characterize
elements core, show element core maximizes social welfare.
also introduce concept balancedness overlapping coalitional games, use characterize coalition structures extended elements core. Finally, generalize
notion convexity setting, show natural assumptions convex games
non-empty core. Moreover, introduce two alternative notions stability OCF
allow wider range deviations, explore relationships among corresponding definitions core, well classic (non-overlapping) core Aubin core. illustrate
general properties three cores, also study computational perspective, thus
obtaining additional insights fundamental structure.

1. Introduction
Coalition formation, widely studied game theory economics (Myerson, 1991), attracted
much attention AI means forming teams autonomous selfish agents need cooperate
perform certain tasks (Sandholm & Lesser, 1997; Shehory & Kraus, 1998; Sandholm, Larson,
Andersson, Shehory, & Tohme, 1999; Manisterski, Sarne, & Kraus, 2008; Rahwan, Ramchurn,
Jennings, & Giovannucci, 2009). Traditionally, game theory literature assumed
outcome coalition formation process either grand coalition (i.e., set agents),
coalition structure consists disjoint coalitions (i.e., partition set agents).
natural settings, many scenarios interest assumption applicable.
c
2010
AI Access Foundation. rights reserved.

fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGS

Specifically, often natural associate coalitions tasks performed agents.
situations, agents may involved several tasks, therefore may need distribute
resources among coalitions participate. Indeed, overlaps may
necessary obtain good outcome, natural plethora interesting applications.
simple e-commerce example, consider online trading agents representing individuals virtual
enterprises, facing challenge allocating owners capital variety projects
(i.e., coalitions) simultaneously. many examples settings agent (be
software entity human) splits resources (such processing power, time money)
among several tasks. tasks, turn, may require participation one agent:
computation may run several servers, software project usually involves one engineer,
start-up may rely several investors. Thus, task corresponds coalition agents,
agents contributions coalitions may fractional, and, moreover, agents participate
several tasks once, resulting coalition structures overlapping coalitions. formation
overlapping coalitions particularly prevalent systems demanding multiagent multirobot
coordination, computational grid networks, sensor networkssee, e.g., work Patel et
al. (2005), Dang, Dash, Rogers, & Jennings (2006). date, however, essentially
theoretical treatment topic, exceptions (which discuss Section 3).
background, goal paper introduce study model explicitly
takes overlapping coalition formation (OCF) account. model applicable situations
agents need allocate different parts resources simultaneously serve different
tasks members different coalitions. Besides allowing overlapping coalitions, departs
conventional coalition formation framework two important aspects. First,
inherent superadditivity assumption work, hence grand coalition always
emerge. Thus, subsequent definition core incorporates coalition structures. Second, exactly interested outcomes grand coalition formation,
use standard transferable utility (TU) framework, agents make arbitrary payments
other. Instead, following seminal paper Aumann Dreze (1974), allow arbitrary
monetary transfers within coalitions, cross-coalitional transfers. is, agent contributing coalition expect receive payoff it. Indeed, argued Aumann
Dreze, inability agents work together share payoffs may one
primary reasons grand coalition form, particular coalition structure arises.
Finally, model take task (coalitional action) execution explicitly account; facilitates
possible extensions tackle coalition formation uncertainty.1
Apart defining model overlapping coalition formation, main contribution
work exploring stability concept core OCF setting. suggest three different
notions core, depending nature deviations allowed, since, shall see,
range permissible deviations overlapping setting much richer traditional
non-overlapping one. specifically, definition stability depends whether deviator
reduced contribution somebut allcoalitions, expects get payoff
coalitions abandon completely.
provide intuition, consider example two construction companies, 1 2,
currently partners (not necessarily partners) working construction projects (building university campus) B (building hospital). Assume partner 1 stakes
1. simplify notation, show incorporate coalitional actions model Section 10.

180

fiC OOPERATIVE G AMES OVERLAPPING C OALITIONS

project B, expecting extract great value, contributed 75% available resources, contributing remaining 25% A; partner 2 contributes resources (say
67%) project remaining fraction (say 33%) B. Thus, currently participate two
overlapping coalitions, one performing different task. Now, partner 2 feels unhappy
current payoff division arrangement, might consider abandoning project (by cancelling
project project leader, taking advantage contractual exit clause) order
commit resources profitable 2 project (say C). However, so, might hurt
project chances completion. mean 2s actions trigger spite company
1, might use available means kick 2 project B? company 2 lowered
degree participation instead withdrawing completely? much profits
completing would 2 entitled to? different answers one provide questions correspond different notions profitable deviations, and, therefore, different notions
core-stability. particular, demonstrate core notions put forward paper
substantially different respect sets outcomes characterize.
main technical results involve c-core, first core concept suggest. Among
three concepts core introduced paper, c-core closest standard definition
core general non-transferable utility (NTU) games. particular, provide conditions
existence c-core follows. quite general assumptions, first provide
characterization outcomes, i.e., pairs form (overlapping coalition structure, imputation),
c-core. proof based graph-theoretic argument, may independent
interest. corollary result, show outcome c-core maximizes social
welfare. Second, characterize coalition structures admit payoff allocations
resulting outcome c-core. done generalizing Bondareva-Shapley theorem
setting (note theorem hold arbitrary non-transferable utility games).
Furthermore, extend notion convexity coalitional games overlapping coalitions,
show mild assumptions convex OCF game non-empty c-core.
discuss properties three versions OCF-core suggest, relate
classic core. also demonstrate model core concepts differ fuzzy coalitional games (Aubin, 1981); though relevant model, work
fundamentally different. addition, initiate study computational aspects stability
overlapping setting. Note computational analysis coalitional games, even nonoverlapping scenarios, hindered fact that, general, coalitional games possess
compact representation, one may list value every possible coalition. Thus, existing work algorithmic aspects coalitional games focused game representations either incompletesuch as, e.g., weighted voting games (Elkind, Goldberg, Goldberg, & Wooldridge,
2009), induced subgraph games (Deng & Papadimitriou, 1994), network flow games (Bachrach
& Rosenschein, 2007)or guaranteed succinct specific subclasses games,
MC-nets (Ieong & Shoham, 2005) coalitional skill games (Bachrach & Rosenschein, 2008);
another approach show complexity bounds games representable polynomial-sized
circuits (Greco, Malizia, Palopoli, & Scarcello, 2009). issue even severe OCF
setting, specify value every partial coalition. Therefore, paper,
follow first approaches, introduce formalism threshold task games
capable describing large family overlapping coalition formation settings succinct manner. Within formalism, obtain negative positive results regarding complexity
181

fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGS

deciding questions membership non-emptiness OCF-core concepts. conclude
describing natural extensions model suggesting directions future work.2

2. Preliminaries
section, provide brief overview basic concepts cooperative game theory regarding non-overlapping coalition structures. begin, let N = {1, . . . , n} set players (or
agents). subset N called coalition. coalition structure (CS ) non-overlapping
environments partition set agents.
assumption transferable utility, coalition formation abstracted fairly
simple model. assumption postulates existence (divisible) commodity (e.g., money)
freely transferred among players. role characteristic function coalitional
game transferable utility (TU-game) specify single number denoting worth
coalition. Formally, characteristic function v : 2N 7 R defines value v(S) coalition
(von Neumann & Morgenstern, 1944). transferable utility game G completely specified
set players N characteristic function v; therefore write G = (N, v).
characteristic function describes payoffs available coalitions, prescribe way distributing payoffs. captured notion imputation, defined
follows. say allocation vector payoffs x = (x1 , . . . , xn ) assigning
Psome payoff
j N . allocation x efficient respect coalition structure CS jS xj = v(S)
CS ; called imputation efficient satisfies individual rationality, i.e.,
xj v({j}) j = 1, . . . , n. set imputations CS denoted I(CS ).
Now, rational agents seek maximize individual payoffs, stability underlying coalition structure becomes critical, agents might tempted abandon agreements
pursuit gains themselves. structure stable outcomes attained
coalitions payoff combinations agreed agents satisfy individual group
rationality. Given requirement, research coalition formation developed several notions
stability, among strongest well-studied ones core (Gillies, 1953). Taking
coalition structures account, core TU game set outcomes (CS , x), x I(CS ),
subgroup agents motivated depart coalitions CS .
Definition 1. Let CS coalition structure, let x Rn allocation payoffs
agents. core TUP
game (N, v) set pairs (CS , x) x I(CS )
N holds jS xj v(S).
Hence, coalition would ever block proposal core allocation. well-known
core strong notion, exist many games empty (Myerson, 1991).
core definition essentially definition provided Sandholm Lesser (1997)
(and also similar one given Dieckmann & Schwalbe, 1998). assume superadditivity characteristic function (i.e., v(U ) v(U ) + v(T ) disjoint coalitions U
) definition may consider outcomes CS simply grand
2. Parts work, namely model statement results, appeared preliminary
conference paper (Chalkiadakis, Elkind, Markakis, & Jennings, 2008). However, (a) introduction alternative
notions core related results presented entirely novel; (b) similarly, complexity-related
results entirely novel; (c) discussion properties cores in-depth comparison
fuzzy coalitional games appear first time well.

182

fiC OOPERATIVE G AMES OVERLAPPING C OALITIONS

P
coalition jN xj = v(N ). core definition becomes traditional definition
used vast majority economics literature (Osborne & Rubinstein, 1994).
environments interest work however mainly non-superadditive
make assumption characteristic function. Indeed, plethora realistic
application scenarios emergence grand coalition either guaranteed, might
perceivably harmful, plainly impossible (Sandholm & Lesser, 1997; Sandholm et al., 1999).
addition motivations, Aumann Dreze (1974) also provide thorough insightful
discussion coalition structures arise: put forward series arguments
might happen, explain coalition structures may emerge naturally even superadditive
environments variety reasons. Briefly, arguments describe subset agents
might find worthwhile bargain within framework specific structure, within
framework grand coalition; emergence coalition structure may reflect
considerations necessity excluded formal description game
impossible measure communicate. Exogenous arguments emergence coalition
structures naturally include impossibility communication among negotiators, law
prohibition grand coalition (Aumann & Dreze, 1974).

3. Related Work
work relevant research fuzzy coalitional games, introduced
Aubin (1981). Branzei, Dimitrov, & Tijs (2005) also provide detailed exposition games.
player fuzzy game participate coalition various levels, value coalition
depends participation levels agents S. Given model, Aubin defines
core fuzzy games (also referred Aubin core). Though model also allows partial
participation coalition, several crucial differences fuzzy games OCF
games, corresponding notions stability. postpone listing presenting
model results, Section 8.2. now, let us point that, distinction
work, formation coalition structures (overlapping not) addressed fuzzy
games literature.
Apart fuzzy games, little work exists overlapping coalition formation settings.
discuss notable exceptions, well related work core context
non-overlapping coalition structures.
begin, Shehory Kraus (1996) present setting overlapping coalition formation.
model, agents goals capabilitiesi.e., abilities execute certain actions.
serve goals, agents participate coalitions, contribute
capabilities, thus thought resources. authors propose heuristic
algorithms lead creation overlapping coalition structures. However, authors stop
short addressing question stability overlapping coalitions. Dang et al. (2006) also
examine heuristic algorithms overlapping coalition formation used surveillance multisensor networks. However, work deal payoff allocation issues,
view overlapping coalition formation problem game-theoretic perspective.
Conconi Perroni (2001) present model international multidimensional policy coordination non-cooperative setting: agreement structures countries overlapping,
namely country may participate multiple agreements, contributing number proposed
elementary strategies (which regarded chosen discrete sets resources).
183

fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGS

introduce equilibrium concept describe stability setting. However, contrast work, setting work Conconi Perroni non-cooperative,
apply agents continuous resources.
recently, Albizuri, Aurrecoechea, & Zarzuelo (2006) presented extension Owens
value (1977)which, turn, thought generalization Shapley value (1953)to
overlapping coalition formation setting. Specifically, present axiomatic characterization
configuration value. However, work Albizuri et al. exists notion
resources agent needs distribute across coalitions.
regard non-overlapping coalition structures presented Section 2, Sandholm
Lesser (1997) examine problem allocating computational resources coalitions.
restrict superadditive settings, discuss stability coalition structures instead.
particular, introduce notion bounded rational core explicitly takes account coalition structures. Apt & Radzik (2006) Apt & Witzel (2009) also restrain
coalition formation problems outcome grand coalition only. Instead, introduce
various stability notions abstract games whose outcomes coalition structures, discuss
simple transformations (e.g., split merge rules) stable partitions set players
may emerge. However, none papers considers extensions overlapping coalitions.

4. Model
section extend traditional model Section 2 cooperative games overlapping
coalitions. scenarios interest, even overlapping coalitions allowed, agent would
able participate possible coalitions due lack time, cash flow, energy. model
this, assume agent possesses certain amount resources distribute
among coalitions joins. Without loss generality, make normalization assume
agent one unit resource: agents contribution coalition thus given
fraction resources allocates it. also think agents participation
level, fraction time devotes coalition. course, agent may several types
resources (e.g., time money), contribution coalition would described
vector rather scalar. model, results, extend general
setting straightforward manner. Nevertheless, conciseness, restrict presentation
single-resource setting.
discussed above, non-overlapping model coalition subset agents, game
defined characteristic function v : 2N 7 R, representing maximum total payoff
coalition get. setting, partial coalition given vector r = (r1 , . . . , rn ),
rj fraction agent js resources contributed coalition (rj = 0 means j
member coalition). support partial coalition r denoted supp(r) defined
supp(r) = {j N | rj 6= 0}. define cooperative games overlapping
coalitions, overlapping coalition formation games (OCF-games short),
considering rest work.
Definition 2. OCF-game G player set N = {1, . . . , n} given function v : [0, 1]n
R, v(0n ) = 0.
Function v maps partial coalition r corresponding payoff. denote game
G = (N, v), or, N clear context, simply v. Clearly, classic coalition N
184

fiC OOPERATIVE G AMES OVERLAPPING C OALITIONS

represented vector eS , (eS )j = 1 j 0 otherwise.
economics literature, sometimes called crisp coalitions, whereas coalitions form
(r1 , . . . , rn ) least one rj (0, 1) referred fuzzy coalitions (Branzei et al., 2005).
avoid latter term work cause confusion fuzzy games, refer
instead coalitions kind partial coalitions, simply coalitions.
scenarios interest, v monotone, i.e., satisfies v(r) v(r ) r, r
rj rj j = 1, . . . , n. Note v monotone, v(r) 0 r [0, 1]n , since
set v(0, . . . , 0) = 0. discussion stability overlapping coalitions, assume
v monotone.
need specify possible outcomes OCF-game. non-overlapping setting,
outcome pair (CS , x), CS partition N x imputation CS .
extend definition scenario, start introducing notion coalition structure
overlapping coalitions. mostly interested coalition structures N ,
definition given coalition structures arbitrary subset N ,
useful defining maximum profit subset agents achieve (see definition
function v below).
Definition 3. set agents N , coalition structure finite list vectors
(partial coalitions) CS TP= (r 1 , . . . , r k ) satisfies (i) r [0, 1]n ; (ii) supp(r )
= 1, . . . , k; (iii) ki=1 rji 1 j . refer k size coalition
structure CS write |CS | = k. Also, CS denotes set coalition structures .
definition above, r = (r1i , r2i , . . . , rni ) corresponds partial coalition (rji
fraction resources agent j contributes r ). constraints state every
agent distributes one unit resources among various coalitions participates (those may include singleton coalition). allows coalitions overlapping. Note
coalition structure list rather set, i.e., contain two identical partial
coalitions. Observe
also agent required allocate resources, i.e.,
P
case ki=1 rji < 1. However, monotonicity, assume agent j
P
ki=1 rji = 1 (i.e., coalition structure fractional partition agents).
would like remark one could conceive models also allow agents form
overlapping coalitions. example, instead requiring agents distribute one unit
resources among partial coalitions, could constraints number (crisp) coalitions
agent could take part in. believe model flexible enough represent wide
range realisitc scenarios, focus throughout work, Section 10, discuss
several extensions model.
introduction overlapping coalition structures imposes new technical challenges.
instance, non-overlapping setting number different coalition structures
finite, setting infinitely many different partial coalitions, hence infinitely
many coalition structures. implies impossible find social welfare-maximizing
coalition structure enumerating candidate solutionsin fact, maximum may even
attained. contrast, non-OCF setting approach possiblethough, general,
P infeasible.
extend definition v coalition structures setting v(CS ) =
r CS v(r).
Furthermore, N define v (S) = supCS CS v(CS ). Intuitively, v (S)
least upper bound value members achieve forming coalition structure;
interested reader, note corresponds characteristic function games
185

fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGS

superadditive cover (Aumann & Dreze, 1974). Clearly, v (S) may exceed value coalition
itself, i.e., v(eS ), since may profitable players form several overlapping
coalitions S. say v bounded v (N ) < ; games interest, v likely
bounded.
setting agents necessarily form grand coalition, interested
reasoning coalition structures CS N . coalition structure impose restrictions
admissible ways distributing gains; payoff vector corresponds imputation
obtained distributing value coalition:
Definition 4. Given coalition structure CS CS N , |CS | = k, imputation CS k-tuple
x = (x1 , . . . , xk ), xi Rn = 1, . . . , k,
P
(Payoff Distribution) every partial coalition r CS nj=1 xij = v(r ) rji =
0 implies xij = 0;
(Individual Rationality)
total payoff agent j least large achieve
Pk

own: i=1 xj v ({j}).

set imputations CS denoted I(CS ). Notice Definition 4, profit
task assigned partial coalition distributed among agents involved executing it.
Thus, transfers payoff allowed outsiders. Note also individual rationality
constraint defined terms v rather v, even single agent may profitable
split several partial coalitions (e.g., many tasks, requires small
fraction resources).
Now, set outcomes interest us set feasible agreements:

Definition 5. feasible agreement (or outcome) set agents J N tuple (CS , x)
CS CS J , |CS | = k k N, x = (x1 , . . . , xk ) I(CS ). denote set
feasible agreements J F(J).
P
payoff pj agent j feasible agreement (CS , x) pj (CS , x) = ki=1 xij .
write p(CS , x) denote vector (p1 (CS , x), . . . , pn (CS , x)). Finally, note straightforward extend definitions games subsets agents. particular, require
imputation x I(CS J ) satisfies xij = 0 j 6 J.
Given model, ready define concept core cooperative games
overlapping coalitions.

5. Core Overlapping Coalitions
section, investigate several approaches defining stability OCF-games. Specifically,
propose analyze three alternative definitions core.
presenting core definitions, define new class games, using
running example, namely class threshold task games (TTGs). TTGs form simple,
expressive class coalitional games, used model collaboration multi-agent
systems. TTGs agents pool resources order accomplish tasks, idea agents contributing resources one task thus participating several coalitions simultaneously
extremely natural context. Thus, due simplicity, TTGs provide convenient
vehicle study core-stability overlapping setting, using
purpose throughout rest paper (though work limited class games).
186

fiC OOPERATIVE G AMES OVERLAPPING C OALITIONS

5.1 Threshold Task Games
Threshold task games defined follows.
Definition 6. threshold task game G = (N ; w; t) given by:
set agents N = {1, . . . , n};
vector w = (w1 , . . . , wn ) R+ agents weights;
list = (t1 , . . . , tm ) task types, task type tj described threshold
j 0 utility uj 0; write tj = (T j , uj ).
Intuitively, games describe scenarios agents split teams work tasks.
one type resource (e.g., time money) needed tasks, agent
certain amount resource corresponds weight wi (we chose term weight
avoid confusion use term resource context OCF-games).
types tasks, described resource requirement j utility uj . team
agents works tj total weight least j , means sufficient resources
complete task, obtains full value task uj . Otherwise, payoff task
0. assume infinitely many tasks type, one team agents chooses
work tj , prevent another team choosing tj well. follows,
assume list monotone, i.e., satisfies 1 < . . . < u1 < . . . < um . Indeed,
two task types ti , tj j , ui uj , safely assume team
agents choose work tj , hence tj deleted t. Hence, monotonicity
assumption made without loss generality.
description suggests interpret TTG G = (N, w, t) (non-overlapping)
coalitional game G = (N, v), N set
v(S) = max{0, max{uj | w(S) j }}
(note use standard convention max = ). games provide direct generalization weighted voting games (WVGs) coalition structures introduced Elkind, Chalkiadakis, & Jennings (2008). Indeed, WVGs coalition structures seen TTGs
one task type = t1 utility 1.
time, one also interpret TTGs games overlapping coalitions allowing
agent spread weight across several tasks. corresponding OCF-game G = (N, v)
given
n
X
v(r1 , . . . , rn ) = max{0, max{uj |
ri wi j }}.
i=1

is, partial coalition successfully complete task type tj earn value uj
total weight contributed agents partial coalition least j .
Example 1. Consider TTG G = (N ; w; t), N = {1, 2, 3}, w = (2, 2, 2) =
t1 = (3, 1). corresponding non-overlapping game G v({1}) = 0, v({1, 2}) =
v({1, 2, 3}) = 1. Note overlapping coalitions allowed, maximum social
welfare achievable coalition structure N 1, agents cannot split two disjoint
groups weight least 3.
187

fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGS

contrast, corresponding OCF-game G = (N, v) v(1, 0, 0) = 0, v(1, 1, 0) =
v(1, 1, 1) = 1, and, moreover, v(1, .5, 0) = 1 v(0, .5, 1) = 1. Hence maximum social
welfare 2 overlapping setting since second agent split weight two
coalitions enough resources complete task.
Example 1, clear TTG G, maximum social welfare achievable
overlapping version G least large maximum social welfare non-overlapping
version Gi.e., allowing agents split weights tasks increase efficiency.
Moreover, increase arbitrarily large even single agent. Indeed, consider one agent
weight w one task type = 1, u = 1. overlapping coalitions allowed,
agents total utility 1, overlapping scenario obtain w. interested
reader, Appendix discusses algorithmic aspects social welfare maximization TTGs,
overlapping non-overlapping scenario.
5.2 Three Definitions Core
explained Section 2 above, core-stability implies group agents able
profitably deviate configuration core. Hence, definition core depend
notion permissible deviations used. Now, non-overlapping setting deviator abandons coalition originally participated in, joins new coalition. Thus, reason
obtain payoff coalition left. overlapping setting, situation less clear-cut. Indeed, deviating, agent may abandon coalitions completely,
withdraw somebut allof contribution coalitions, keep contribution
remaining coalitions unchanged. question whether agent expect obtain
payoff partial coalitions non-deviators still contributing to.
first notion core assumes answer question no. Thus,
agent identified deviatori.e., alters contribution given coalitionhe longer
expects benefit cooperation non-deviators. monotonicity, means
deviators nothing gain contributing resources coalitions non-deviators. Therefore, first definition core present here, assume deviators
form coalitions among themselves, or, words, deviation seen overlapping
coalition structure set deviators. remark definition seen
straightforward generalization standard notion core: indeed, standard
setting, deviator completely withdraws coalitions non-deviators, benefits
coalitions deviators. formalize approach follows.
Definition 7. Given OCF-game G = (N, v) set agents J N , let (CS , x)
(CS , y) two outcomes G partial coalition CS either supp(s ) J
supp(s ) N \ J. say (CS , y) profitable deviation J (CS , x)
j J pj (CS , y) > pj (CS , x). say outcome (CS , x) core G
subset agents J profitable deviation it. is, set agents J N ,
coalition structure CS J J, imputation I(CS J ), pj (CS J , y) pj (CS , x)
agent j J.
definition, deviation CS restricted coalition structure
partial coalitions involving deviators non-deviatorsi.e., partial coalition
contains either deviators (supp(s ) J) non-deviators (supp(s ) N \ J). Thus,
188

fiC OOPERATIVE G AMES OVERLAPPING C OALITIONS

payoff players J receive CS would come partial coalitions
J only.
Example 2. Consider OCF-game G corresponds threshold task game G = (N ; w; t),
N = {1, 2}, w = (4, 6), = (t1 , t2 ) t1 = (5, 15), t2 = (4, 10) (one think
players two companies B discussed Section 1; tasks correspond
two construction projects). Suppose players form two partial coalitions r 1 r 2 total
weight 5 player 1 contributes unit weight r 1 3 units weight r 2 ,
player 2 contributes 4 units weight r 1 , 2 units weight r 2 , is, CS = (r 1 , r 2 ),
r 1 = ( 14 , 23 ), r 2 = ( 43 , 13 ). partial coalitions weight 5,
successfully complete t1 , resulting payoff 15 them. Now, suppose players
divide gains using imputation x = ((7, 8), (9, 6)). Then, total payoff obtained player
2 14, successfully deviate withdrawing coalitions, forming
single partial coalition weight 5. coalition complete t1 receive payoff 15 > 14.
hand, suppose players keep coalition structure, distribute
gains = ((7, 8), (8, 7)). player 2 longer gain withdrawing
coalitions. tempted withdraw resources r 1 , use 4 units weight
complete t2 earn u2 = 10 > 8. However, that, longer get share
payoffs r 2 . Hence, case deviation total payoff 10 < 15. Also, easy
see player 2 cannot gain deviating r 2 only, player 1 better CS
would own. Hence, (CS , y) OCF-core G.
sense, Definition 7 takes rather pessimistic, conservative, view members deviating group expect get non-deviators: indeed, Example 2 soon
player 2 withdraws partial coalition r 1 CS expects thrown r 2 , even
though r 2 affected deviation. Therefore, follows, refer notion
profitable deviation introduced Definition 7 c-profitable deviation, corresponding
notion core conservative core, c-core.
definition applicable deviation agent interpreted agents
indicator agent trustworthy, therefore one immediately stop collaboration him. kind reaction unusual, may coalitions
affected deviation may want punish deviators. case, deviators need
decide existing coalitions abandon existing coalitions keep
contribution intact. members partial coalitions react accordingly, sharing payoff affected deviation punishing deviators otherwise.
Therefore, refer corresponding notion core refined. giving formal
definition, first introduce notion agreement two coalition structures.
Definition 8. Given set agents J N , say two coalition structures CS CS
N agree outside J respect function f f bijection lists partial
coalitions {r CS | supp(r ) * J} {s CS | supp(s ) * J} f (r ) =
implies rji = sj j
/ J. Further, say CS CS agree outside J agree
outside J respect function f .
Intuitively, definition says two coalition structures agree outside J, contributions players J partial coalitions must outcomes.
J set deviators, condition captures fact deviation players J
189

fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGS

change behavior non-deviators; function f used establish correspondence partial coalitions involving non-deviators deviation.
illustration, consider following example.
Example 3. Consider game three players N = {1, 2, 3} coalition structure CS =
(q 1 , q 2 ), q 1 = (1, 12 , 21 ), q 2 = (0, 21 , 21 ). Let CS = (s1 , s2 , s3 ), s1 = (0, 0, 12 ),
s2 = (0, 21 , 12 ), s3 = (1, 12 , 0). Intuitively, CS obtained CS players 1 2
deviate abandoning joint project player 3 forming coalition own. Set
J = {1, 2}. hard see CS CS agree outside J respect function
f given f (q 1 ) = s1 , f (q 2 ) = s2 . hand, CS CS also agree outside J
respect function f given f (q 1 ) = s2 , f (q 2 ) = s1 ; function assumes
players 1 2 decided deviate, player 1 withdrew contribution q 1 player 2 withdrew
contribution q 2 .
Definition 9. Given OCF-game G = (N, v) set agents J N , let (CS , x) (CS , y)
two outcomes CS CS agree outside J respect function f . Suppose
partial coalition CS supp(s ) * J j J yj = xij
r = f 1 (s ) yj = 0 otherwise. say (CS , y) r-profitable deviation
J (CS , x) w.r.t. f j J pj (CS , y) > pj (CS , x). Further, say
(CS , y) r-profitable deviation J (CS , x) exists function f CS
CS agree outside J respect f (CS , y) r-profitable deviation J (CS , x)
w.r.t. f . say outcome (CS , x) refined core, r-core, G subset
agents J posesses r-profitable deviation it.
Definition 9, bijection f matches partial coalitions CS CS involve nondeviators; number coalitions coalition structures. Moreover,
contribution non-deviators partial coalitions matched f CS CS .
Now, also deviators change contribution partial coalition r,
claim share payoff, determined x. hand, deviators change
contribution r, entitled payoff. Observe allow deviators
pick favourable bijection f CS CS : instance, context
Example 3 would pick f rather f , thereby allowing deviators claim payoff
coalition (0, 21 , 12 ). words, assume deviators withdraw contributions
disturb non-deviators little possible.
Example 4. Consider game G outcome (CS , y) described Example 2.
argued player 2 cannot c-profitably deviate (CS , y), r-profitably deviate
withdrawing weight r 1 dedicating t2 . change contribution
r 2 , still claim payoff gets r 2 , total payoff 10 + 7 = 17 > 15.
hand, suppose players 1 2 split weights equally two
partial coalitions, forming structure CS = (q 1 , q 2 ), q 1 = q 2 = ( 21 , 12 ). Clearly,
q 1 q 2 weight 5, earn 15 completing t1 . Now, suppose
players distribute gains using imputation x = ((3, 12), (12, 3)). Now, players earn
15, none benefit withdrawing partial coalitions time,
therefore outcome (CS , x ) c-core. Moreover, players deviates
one coalition only, enough weight complete tasks, therefore
outcome (CS , x ) also r-core.
190

fiC OOPERATIVE G AMES OVERLAPPING C OALITIONS

provide another example, suggests set profitable deviations allowed
Definition 9 may still small.
Example 5. Consider game G coalition structure CS = (s1 , s2 ), player 1
contributes weight s1 , player 2 contributes 3 units weight s1 3 units
weight s2 , i.e., s1 = (1, 12 ), s2 = (0, 21 ). Observe v(s2 ) = 0, total weight
s2 3 only. Now, consider imputation z = ((3, 12), (0, 0)). Note player 2 could reduce
contribution s1 2 units weight without affecting value coalition, use
weight boost value s2 . However, allowed definition r-profitable
deviation, since soon player 2 alters contribution s1 , loses payoff 12
gets s1 . mean, however, outcome (CS , z) r-core G: players
1 2 collectively deviate ((1, 61 ), (0, 65 )). share payoff ((4, 11), (0, 15)),
constitute r-profitable deviation them.
Example 5 demonstrates Definition 9, considerably lax respect
deviators Definition 7, still strict: deviators punished soon
reduce contribution coalition, irrespective whether affects value coalition.
fact, according Definition 9, deviators would still punished even increase
contribution partial coalition non-deviators (though type deviation is, course,
unlikely). One way fix allow deviators claim share payoffs
coalition = f (r ) long v(s ) = v(r ). However, non-deviators even
generous deviators. Indeed, case deviators reduce contribution
particular partial coalition, coalition still able perform task, albeit smaller
value. value task still larger total amount payoff originally received
non-deviators partial coalition, deviators could allowed claim leftover
payoff. words, notion deviation assumes non-deviators objection
switching tasks, care payoff receive. may well case,
quite optimistic deviators expect kind reaction contemplate whether
deviate. Therefore, refer notion deviation o-profitable, call corresponding
solution concept optimistic core, o-core.
Definition 10. Given OCF-game G = (N, v) set agents J N , let (CS , x)
(CS , y) two outcomes CS CS agree outside J respect aP
function f .
Suppose also partial coalition CS supp(s ) * J jJ yj =
P
max{v(s ) kN \J xik , 0}, r = f 1 (s ). say (CS , y) o-profitable deviation J (CS , x) w.r.t. f j J pj (CS , y) > pj (CS, x). Further, say
(CS , y) o-profitable deviation J (CS , x) exists function f CS
CS agree outside J respect f (CS , y) o-profitable deviation J
(CS , x) w.r.t. f . say outcome (CS , x) optimistic core, o-core, G
subset agents J o-profitable deviation it.
Example 6. Consider game G discussed Examples 2, 4, 5, outcome
(CS , x ), CS = (q 1 , q 2 ), q 1 = q 2 = ( 12 , 12 ), x = ((3, 12), (12, 3)), described
Example 4. Note player 2 reduces contribution q 1 2, coalition would still
able earn 10 focusing task t2 . player 1 gets 3 units payoff q 1 anyway,
definition o-profitable deviation, player 2 entitled remaining payoff
modified partial coalition, i.e., 10 3 = 7. combine unit weight saved
191

fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGS

manner weight contributes q 2 , embark t2 making profit 10. Thus,
abandoning q 2 altogether reducing contribution q 1 , player 2 earn 7 + 10 > 15.
Thus, outcome (CS , x ) o-core G.
contrast, consider outcome combines CS symmetric payoff division
scheme, as, e.g., = ((7, 8), (8, 7)). Now, player 2 reduces contribution q 1 1,
resulting partial coalition earn 10 focusing t2 . payoffs, player 1 must receive 7,
leaving 3 player 2. player 2 still use remaining weight complete t2 ,
give total profit 10 + 3 = 13 < 15, i.e., deviation o-profitable. Similarly,
show withdrawing resources q 2 abandoning q 1 even less profitable
player 2. Finally, easy see player 1 o-profitable deviation either.
Hence, outcome (CS , y) o-core (G).

6. Core Characterization
previous section, introduced three definitions core overlapping coalition formation games. Among three definitions core, c-core, though sense conservative,
closest traditional definition core general NTU games (Osborne & Rubinstein,
1994). Indeed, unlike two definitions, assume interaction deviators non-deviators. motivates us study overlapping core variant detail,
proceed section next. promote readability, two sections
referring c-core simply core.
start providing characterization set outcomes core: essentially,
outcome core outcome total payments subset agents
match exceed maximum value achieved subset. proof relies
technical restrictions function v defines game. particular, require v
continuous, monotone bounded (observe game monotone bounded, v (S) <
N ), well satisfy another natural restriction defined later. assumptions
allow us avoid pathological situations may arise model generality,
supremum v (N ) unachievable (e.g., v strictly concave one arguments,
case finite coalition structure achieve v (N )).
Specifically, say game (N, v) U -finite (CS , x) |CS | > U
x I(CS ), exists (CS , y) |CS | U , I(CS ), pj (CS , x) pj (CS , y)
j = 1, . . . , n (i.e., outcome (CS , x) U coalitions exists another
outcome (CS , y) U coalitions weakly prefered (CS , x) agents).
condition holds, assume coalition structures arise game consist
U partial coalitions. natural restriction many practical scenarios, might
difficult agents maintain complicated collaboration pattern. holds when,
example, bound number partial coalitions agent involved in.
general U -finiteness imposes upper bound total number partial coalitions
support occur. natural example provided class games two
partial coalitions r, r supp(r) = supp(r ) rj + rj 1 j = 1, . . . , n,
v(r + r ) v(r) + v(r ). Note games assume coalition structure
contains two partial coalitions support S, least profitable players
merge partial coalitions. (However, notice imply superadditivity,
192

fiC OOPERATIVE G AMES OVERLAPPING C OALITIONS

mean grand coalition necessarily emerges, criterion refers
coalitions identical support.) Hence, game 2n -finite.
Remark 1. Note results U function n (as long U (n) < ).
Alternatively, instead imposing condition U -finiteness v(), could restrict set
allowed outcomes (or potential deviations) coalition structures U partial coalitions.
results hold model well.
state prove first main results.
Theorem 1. Given game (N, v), v monotone, continuous, bounded, U -finite
U N, outcome (CS , x) c-core (N, v) N
X
pj (CS , x) v (S).
(1)
jS

P
Proof. direction, suppose (CS , x) satisfies jS pj (CS , x) v (S)
N . Assume sake contradiction (CS , x) core, i.e., exists set S,
coalition structure CS CS imputation
pj (CS , y) > pj (CS , x)
P I(CS ) suchP

j S. v(CS ) =
jS pj (CS , x) v (S),
jS pj (CS , y) >

contradiction way v (S) defined.
direction, consider outcome (CS , x)
P satisfy (1); show
(CS , x) core. begin, set p = p(CS , x), assume jS pj < v (S)
N . show (CS , x) core, construct set , coalition structure
CS CS P
imputation I(CS ) pj (CS , y)P
> pj j . Fix

set satisfies jS pj < v (S). Choose small enough jS pj < v (S) ,
let CS = {CS CS | v(CS ) v (S) }. definition v (S), infinite
sequence coalition structures CS (t) satisfies limt v(CS (t) ) = v (S), set CS
non-empty. Given coalition structure CS CS , imputation I(CS SP
) respective
payoff vector q = p(CS , y), define total loss TL(CS , q) (CS , q) j:pj >qj (pj qj ).
Set TLmin = inf{TL(CS , q) | CS CS , I(CS ), q = p(CS , y)}. First, prove
exists coalition structure CS CS imputation I(CS ) achieve total
loss TLmin .
Lemma 1. theorems conditions, exists CS CS , imputation I(CS )
payoff vector q = p(CS , y) s.t. TL(CS , q) = TLmin .
(t)

Proof. definition TLmin , exists infinite sequence coalition structures CS , =
1, . . . , , respective imputations (t) , = 1, . . . , ,
lim TL(CS (t) , p(CS (t) , (t) )) = TLmin


(t)

CS CS = 1, . . . , . game U -finite, coalition structure
seen list U vectors [0, 1]n . adding all-zero partial coalitions necessary,
assume coalition structure list exactly U vectors [0, 1]n , ordered
lexicographically. v monotone bounded, exists B > 0 value
(t)
partial coalition CS 0 B. Consequently, (t) corresponds
193

fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGS

(t)

vector [0, B]nU . Hence, sequence (CS , (t) ), = 1, . . . , viewed subset
[0, B]K (for sufficiently large finite value K) hence limit point, denote
(CS , ). easy see limit sequence coalition structures coalition
P structure,

i.e., r CS r [0, 1]n , j = 1, . . . , n holds U
i=1 rj 1.
Moreover, continuity v, value partial coalition CS limit values
(t)
respective partial coalitions CS , = 1, . . . , . this, easy see
(t)
I(CS ). Also, CS CS , CS . Finally, p(, ) TL(, ) continuous
functions arguments, conclude TL(CS , p(CS , )) = TLmin .
Continuing proof Theorem, let (CS , y) outcome satisfies v(CS )
, TL(CS , p(CS , y)) = TLmin , whose existence guaranteed Lemma 1. Set
q = p(CS , y). Let us construct directed graph whose vertices agents
edge j exists coalition CS containing j y,
agent j gets non-zero payoff coalition, i.e., r k CS rjk , rik > 0
yjk > 0. Observe edge (j, i) , change k increasing
payoff small enough decreasing payoff j value without
violating constraints, i.e., z = (z 1 , . . . , z ) I(CS ), z l = l l 6= k
z k = (y1k , . . . , yjk , . . . , yik + , . . . , ynk ). Now, color vertices follows: vertex j red
agent j underpaid P
y, i.e., qj < pj , white j isPindifferent, i.e., qj = pj , green
overpaid, i.e., qj > pj . jS pj < v (S) jS qj = v(CS ) v (S) ,
graph contains least one green vertex. argued above, path green vertex j
red vertex i, transfer small amount payoff j hence decrease total
loss, contradiction choice (CS , y). Hence, given arbitrary green vertex
j, set vertices reachable j graph, denote R(j), contain
green white vertices.
would like argue agents R(j) successfully deviate (CS , x).
Indeed, let CS coalition structure consists coalitions agents R(j) form
among CS . Clearly, value CS equal total value coalitions
formed agents CS . Note also (CS , y), agents R(j) get
payoffs coalitions involve agents R(j). Indeed, suppose R(j) gets
non-zero payoff coalition involves agent k 6 R(j). edge
k, contradiction R(j) constructed. words, CS , payoffs
agents R(j) get come coalitions form among themselves, yet
agents green white, i.e., worse CS ,
(in particular, agent j) strictly better. finish proof, let agents
R(j) distribute payoffs way (CS , y), except player j transfers small
fraction payoffs white players R(j) (this possible construction).
last step ensures agent R(j) strictly better (CS , x). demonstrates
(CS , x) core, required.
v (S)

Remark 2. Note make use additional restrictions imposed v
prove direction theorem (these used proof Lemma 1). Hence,
implication holds arbitrary G.
easily verifiable Theorem 1 holds non-overlapping case coalition structures
well. result trivial prove setting, agents payoffs come one
194

fiC OOPERATIVE G AMES OVERLAPPING C OALITIONS

coalition; contrast, use involved combinatorial arguments transferring payoffs
among agents. also get following interesting result corollary:
Corollary 1. setting = N statement Theorem 1, conclude outcome
c-core maximizes social welfare.
turn attention characterizing set coalition structures CS admit payoff
allocations x corresponding tuple (CS , x) belongs core. is,
Theorem 1 saw necessary sufficient condition tuple (CS , x) belong core,
suppose given structure CS = (r 1 , . . . , r k ) want check whether
exists payoff allocation x (CS , x) belongs core. characterization
seen generalization notion balancedness context overlapping coalition
formation. classic setting, analogous question grand coalition admit
payoff allocation core, answered Bondareva (1963) Shapley (1967).
proceed result, define balancedness respect coalition structure.
Definition 11. Fix coalition structure CS = (r 1 , . . . , r k ), k N, let K = {1, ..., k}.
collection numbers {S }SN , {P
}iK called balanced w.r.t. given coalition structure CS
0 S, S:jS + = 1 K, j supp(r ).
Definition 12. game called balanced w.r.t. coalition structure CS = (r 1 , ...,P
r k )
every collection {S }SN , {i }iK balanced w.r.t. CS holds v (S) +
Pk


i=1 v(r ) v (N ).
proof following theorem based LP-duality, relies characterization
result Theorem 1; furthermore, proof illustrates condition balancedness introduced
arises rather naturally.
Theorem 2. Let (N, v) OCF-game, v monotone, continuous, bounded, U -finite
U N consider coalition structure CS = (r 1 , ..., r k ), k N. exists
imputation x s.t. (CS , x) belongs c-core game balanced w.r.t. CS .
Proof. Suppose exists payoff allocation x (CS , x) belongs core, let
K = {1, . . . , k}. following linear program (denoted LP) optimal solution:
P
x
min
PiK,jN
P ij

N
s.t.
r ) xij v (S)
PjS i:jsupp(

x
=
v(r
)
K
j ij
first constraint expresses condition Theorem 1, second fact payoff
partial coalition needs distributed exactly. Note variables xij
j 6 supp(r )recall Definition 4. precisely conditions need satisfied
(CS , x) core clearly optimal value LP v (N ) (using first constraint
Corollary 1). LP-duality theorem, means dual program also optimal
solution value v (N ). dual given by:
P
P
max PS v (S) + ki=1 v(r )
K, j supp(r )
s.t.
S:jS + = 1
0
N
195

fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGS

Hence feasible solution dual, value objective function P
v (N ),
implies balanced collection {S }SN , {i }iK , holds v (S) +
Pk


i=1 v(r ) v (N ).
direction, suppose balanced collection, holds. means
feasible solution, value dual v (N ). Therefore dual
bounded feasible (setting = 1 rest 0 feasible), implies
optimal solution. primal program also optimal solution x means
Theorem 1 (CS , x) belongs core.
Remark 3. traditional superadditive setting, condition balancedness somewhat
simpler intuitive. setting, characterization leads slightly complicated
expression, essentially due fact linear program describes core allocations
coalition structure requires larger set constraints.

7. Convex OCF-Games Non-Empty Core
section, first generalize notion convexity OCF-games proceed show
provides sufficient condition non-emptiness c-core.
Recall classical TU-games convexity means R N N \ R
holds v(S R) v(S) v(T R) v(T ). Thus, convexity classic TU-games setting
means useful coalition R join larger coalition smaller one.
apply intuition setting (recall F(S) denotes set feasible agreements S):
Definition 13. OCF-game G = (N, v) convex R N N \ R
following condition holds: (CS , xS ) F(S), (CS , xT ) F(T ),
(CS SR , xSR ) F(S R) satisfies pj (CS SR , xSR ) pj (CS , xS ) j S, exists
outcome (CS R , xT R ) F(T R) s.t.
pj (CS R , xT R ) pj (CS , xT )
pj (CS

R

,x

R

) pj (CS

SR

j ,
SR

,x

) j R.

definition similar flavour provided Suijs Borm (1999), generalization convexity defined context stochastic cooperative games. intuition behind
definition follows: Consider two fixed agreements, one one respectively.
time feasible agreement R members object compared agreement (i.e., members weakly better previous
agreement), feasible agreement R (i) members object agreement, compared previous agreement (ii) members R weakly
prefer agreement agreement R.
note different notion convexity defined fuzzy games Branzei,
Dimitrov, & Tijs (2003). definition deals marginal contribution partial coalition
joining another existing partial coalition, result join new partial coalition.
We, hand, quantify marginal contribution adding set players R, set
players , w.r.t. best overlapping coalition structure set R form. Secondly,
definition Branzei et al., well classic definition convexity, simply enforce property
function v(), concerning marginal contribution v(R ) v(T ). case, games
196

fiC OOPERATIVE G AMES OVERLAPPING C OALITIONS

fully transferable hence cannot simply talk difference values. Instead,
definition enforce existence coalition structure R individually
every player least well-off coalition structure R S, .
show convexity sufficient condition non-emptiness core,
analogy classic result convex TU-games (Shapley, 1971).
Theorem 3. OCF-game G = (N, v) convex v continuous, bounded, monotone
U -finite U N, c-core game empty.
Proof. Let G = (N, v) convex OCF-game. N , let GS restriction
G S. prove theorem, explicitly construct outcome (CS , x), x I(CS ),
show belongs core G: Fix arbitrary ordering players 1, 2, . . . , n 1, n.
construction takes place rounds. First, let p1 = v ({1}), p2 = v ({2}); assumptions
theorem using arguments similar proof Lemma 1, exist coalition
structures CS {1} , CS {2} achieve payoffs. Let CS 1 structure achieves
player 1 G{1} , let x1 corresponding imputation. know exists least one
coalition structure CS 2 CS {1,2} corresponding imputation x2 p1 (CS 2 , x2 ) p1 ,
p2 (CS 2 , x2 ) p2 (e.g., take union payoff-maximizing structures G{1} G{2} ,
combine corresponding imputations). exist one feasible agreement,
pick one preferred player 2. formally, choose feasible agreement (CS 2 , x2 )
maximizes payoff p2 (CS 2 , x2 ) (which least p2 ) feasible agreements
{1, 2} subject p1 (CS 2 , x2 ) p1 (CS 1 , x1 ) (by assumptions v(), maximum exists).
Now, let p3 maximum payoff agent 3 get G{3} . Again, exists least one
coalition structure CS 3 CS {1,2,3} corresponding imputation x3 agents 1, 2
(weakly) better (CS 2 , x2 ), 3 also weakly better own.
exist one feasible agreement, pick one maximizes 3s payoff, i.e., pick
agreement (CS 3 , x3 ) p3 (CS 3 , x3 ) maximized agreements {1, 2, 3} subject
constraints p1 (CS 3 , x3 ) p1 (CS 2 , x2 ), p2 (CS 3 , x3 ) p2 (CS 2 , x2 ).
Continuing manner, every round k pick outcome (CS k , xk ) maximizes
pk (CS k , xk ) subject constraints pi (CS k , xk ) pi (CS k1 , xk1 ) {1, ..., k 1};
assumptions v() ensure maxima exist. end, obtain feasible agreement
(CS n , xn ) N agents weakly better own, well weakly
better compared agreements previous rounds.
show (CS n , xn ) belongs core G. suffices prove following
stronger claim.
Claim 1. k = 1, . . . , n, feasible agreement (CS k , xk ) belongs core game
G{1,...,k} .
Proof. prove induction. k = 1, obvious (CS 1 , x1 ) belongs core
G{1} .
Now, suppose m, 2 n, (CS k , xk ) core(G{1,...,k} )
k < m. prove (CS , xm ) core G{1,...,m} .
Suppose, sake contradiction, case. subset
{1, ..., m} (CS , x ) F(S)
pi (CS , x ) > pi (CS , xm ) S.
197

(2)

fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGS

consider three different cases members S:
Case 1: 6 S. case know construction {1, . . . , 1}
pi (CS , xm ) pi (CS m1 , xm1 ), implies pi (CS , x ) > pi (CS m1 , xm1 )
S. Hence, tuple (CS , x ) deviation makes members strictly better
agreement (CS m1 , xm1 ). contradiction since induction (CS m1 , xm1 )
core(G{1,...,m1} ).
Case 2: = {1, . . . , m}. get contradiction constructed (CS , xm ).
Indeed, chose (CS , xm ) maximize pm (CS , xm ) subject constraints pi (CS , xm )
pi (CS m1 , xm1 ) = 1, . . . , 1. However, (2), outcome (CS , x ) also
satisfies constraints provides higher payoff (CS , xm ) does, contradiction.
Case 3: = {m}, strict subset {1, . . . , 1}. case utilize
convexity. Let CS coalition structure consists singleton coalitions agents
, let x corresponding imputation. construction, (CS , x ) feasible agreement
{m} pi (CS , x ) pi (CS , x ) . Let = {1, . . . , 1}.
Since (CS m1 , xm1 ) F(T ), applying Def. 13 R = {m}, get
exists feasible agreement (CS , x) {m} = {1, . . . , m} pi (CS , x)
pi (CS m1 , xm1 ) = 1, . . . , 1, pm (CS , x) pm (CS , x ). (2)
get pm (CS , x) > pm (CS , xm ), contradiction chose (CS , xm ).
Applying Claim 1 k = n, get core G non-empty.
traditional setting, game represented using oracle access v(S), trivial
algorithm computing element core convex games. Indeed, one set payoff
vector vector marginal contributions agents arbitrary permutation
set agents. setting, proof yield procedure constructing element
core, though polynomial-time one. procedure requires solving series optimization
questions, arbitrary convex games NP-hard. future, would like find
classes convex games proof yields polynomial-time algorithm. particular, looking
proof, would true games solve polynomial time following
problem: Given set agents N , feasible agreement S, outcome (CS , x),
agent k 6 S, find feasible agreement (CS , y) {k} maximizes pk (CS , y) subject
constraints pj (CS , y) pj (CS , x).

8. Properties Three Cores
Following detailed study c-core stability concept previous two sections,
section explore properties three notions OCF-core. particular,
investigate relationships among notions, study effects allowing overlapping
coalition formation stability underlying game. also compare OCF model
notions core fuzzy games setting notion fuzzy core (Aubin, 1981).
start exploring connection stability social welfare maximization
TTGs. demonstrated earlier paper, OCF-games two properties closely related. Indeed, Theorem 1 Corollary 1 show outcome c-core OCF-game
maximizes social welfare long characteristic function game satisfies number
technical conditions; Theorem 5 holds r-core o-core. However,
one conditions continuity, result directly apply TTGs. proof
198

fiC OOPERATIVE G AMES OVERLAPPING C OALITIONS

Theorem 1 adapted work TTG setting, also exists direct proof
following theorem.
Theorem 4. TTG G = (N ; w; t) outcome (CS , x) c-core(G),
v(CS ) v(CS ) coalition structure CS CS N .
Proof. Fix outcome (CS , x) c-core(G), let p payoff vector corresponds
(CS , x). Suppose exists coalition structure CS CS N v(CS ) > v(CS ).
Let CS = (r 1 , . . . , r k ). j = 1, . . . , k, let z j total weight partial coalition r j , i.e.,
set z j = r1j w1 + + rnj wn .
Now, consider coalition structure CS = (q 1 , . . . , q k ) given qij = z j /w(N ) N ,
P
j = 1, . . . , k; note kj=1 qij 1. total weight partial coalition q j
P
computed qij wi = z j . Therefore, q j CS accomplish task r j CS ,
hence v(CS ) = v(CS ) > v(CS ). Now, observe since CS players contribute
partial coalitions, restrictions value CS distributed among

)
players. particular, set = v(CS )v(CS
, construct imputation I(CS )
n
Pk
P
v(r j )
j
j
j
setting yij = v(CS
) (pi + ). Indeed,
yi = v(r ),
j=1 yi = pi + . Now,
clear entire set agents N deviate (CS , x) (CS , y); deviate
simultaneously, c-profitable deviation, contradiction (CS , x) c-core
G.
discussion Section 5.2 suggests natural relationship three notions
successful deviation, and, consequently, three cores. (In follows, refer
outcomes c-core, r-core o-core c-stable, r-stable o-stable, respectively.)
Theorem 5. OCF-game G, o-core(G) r-core(G) c-core(G). Moreover,
containments strict, i.e., exists OCF-game G o-core(G) r-core(G)
c-core(G).
Proof. Observe c-profitable deviation viewed r-profitable deviation
players abandon coalitions contributed to. Similarly, r-profitable deviation corresponds
o-profitable deviation whenever deviator changes contribution coalition,
withdraws resources it; note that, illustrated Example 5, deviators payoff
o-profitable deviation strictly higher original r-profitable deviation.
follows outcome r-stable also c-stable, outcome o-stable also
r-stable, thus proving first part theorem.
prove second part theorem, consider game G described Examples 2, 4, 5
6. demonstrated outcome (CS , x) c-core(G) \ r-core(G)
outcome (CS , x ) r-core(G) \ o-core(G).
Theorem 5 shows three notions stability substantially different respect
individual outcomes. However, exclude possibility equivalent seen
notions stability entire game, i.e., OCF-game G c-core(G) 6= iff
r-core(G) 6= iff o-core(G) 6= . show case. games used
proofs following two propositions threshold task games. However, they, too,
described terms agents weights tasks.
199

fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGS

Proposition 1. exists OCF-game G c-core(G) 6= r-core(G) = .
Proof. Consider OCF-game G = (N, v) seven agents N = {1, . . . , 7} whose weights
given w = (1, 1, 1, 1, 3, 3, 3), two task types t1 t2 values 100 2, respectively.
first task completed following four ways:
1 unit player 1s weight 2 units player 5s weight;
1 unit player 2s weight 2 units player 6s weight;
1 unit player 3s weight 2 units player 7s weight;
1 unit player 4s weight 2 units weight either players 5, 6, 7.
is, v(r) = 100 wi ri 1 wj rj 2,
(i, j) {(1, 5), (2, 6), (3, 7), (4, 5), (4, 6), (4, 7)}.
second task t2 requires 2 units weight total players 5, 6 7.
Consider coalition structure CS = (r 1 , r 2 , r 3 , r 4 ), given
2
r 1 = (1, 0, 0, 0, , 0, 0),
3
2
3
r = (0, 0, 1, 0, 0, 0, ),
3

2
r 2 = (0, 1, 0, 0, 0, , 0),
3
1 1
4
r = (0, 0, 0, 0, , , 0).
3 3

is, partial coalitions r 1 , r 2 r 3 successfully complete t1 , r 4 successfully completes t2 . Consider also imputation x I(CS ) given
x1 = (0, 0, 0, 0, 100, 0, 0),

x2 = (0, 0, 0, 0, 0, 100, 0),

x3 = (0, 0, 0, 0, 0, 0, 100),

x4 = (0, 0, 0, 0, 1, 1, 0).

Let p payoff vector corresponds x: p1 = p2 = p3 = p4 = 0, p5 =
p6 = 101, p7 = 100. hard see (CS , x) c-core(G). Indeed, suppose sake
contradiction set players J c-profitably deviate (CS , x). Since
(CS , x) maximizes social welfare, deviation cannot simultaneously profitable
players N , |J| < 7. Moreover, J cannot contain 2 players set = {5, 6, 7}:
indeed, one players deviates, loses 100 units payoff, replaced
forms coalition 4. However, since 4 cannot form two distinct coalitions value 100
each, possible. Therefore, J cannot contain players set S:
players already gets maximum payoff t1 , and, since two players
J, set deviators enough resources t2 . Finally, c-profitable
deviation players N \ S, task completed agents N \ only.
show r-core G empty. Suppose otherwise, let (CS , y)
outcome r-core G. Let p payoff vector corresponds y. hard
show outcome r-core G maximizes social welfare; proof similar
Theorem 4. Hence, assume without loss generality CS = (q 1 , q 2 , q 3 , q 4 )
v(q 1 ) = v(q 2 ) = v(q 3 ) = 100 v(q 4 ) = 2, and, moreover, q51 23 , q62 23 , q73 32 . follows
200

fiC OOPERATIVE G AMES OVERLAPPING C OALITIONS

either (a) q11 = q22 = q33 = 1 (b) q4j = 1 j {1, 2, 3} qii = 1 {1, 2, 3},
6= j. say player useful coalition r v(r ) < v(r), r given ri = 0,
rj = rj j 6= i. Observe r-stable outcome player get payoff
partial coalition useful: otherwise members coalition,
complete corresponding task own, r-profitably deviate. show
p1 = . . . = p4 = 0 case (a) case (b). Observe argument player
1 get payoff q 1 only, player 2 get payoff q 2 only, player 3 get payoff
q 3 only, player 4 get payoff exactly one coalitions q 1 , q 2 , q 3 .
case (a), clearly p4 = 0, player 4 useful coalition CS . Now, if,
e.g., y11 > 0, y51 < 100, players 4 5 r-profitably deviate forming coalition
performs t1 . Hence y11 = y22 = y33 = 0, therefore p1 = p2 = p3 = 0. case (b), assume
without loss generality q41 = 1. p1 = 0, player 1 useful coalition
CS , y41 = 0, since otherwise players 1 5 r-profitably deviate, and, consequently,
p4 = 0. implies also y22 = y33 = 0: if, e.g., y22 > 0, y62 < 100, players 4
6 r-profitably deviate forming coalition performs t1 . Hence, cases
p1 = = p4 = 0.
Now, v(q 4 ) = 2, y54 + y64 + y74 = 2, least one payoffs y54 , y64 y74
strictly positive. Assume without loss generality y54 = > 0. players 6, 7
partners q 2 q 3 (i.e., players , qi2 = 1, qi3 = 1) r-profitably deviate
(CS , y) forming coalition structure CS = (s1 , s2 , s3 ), s1 given
s1i = 1,

2
s16 = ,
3

s1 = 0 6= , 6,

s2i = 1,

2
s27 = ,
3

s2 = 0 6= , 7,

s2 given

s3 = (0, 0, 0, 0, 0, 13 , 13 ). construct imputation z CS setting zi1 =
zi2 = 4 , z61 = z72 = 100 4 , z63 = y64 + 2 , z73 = y74 + 2 , zij = 0 (i, j) 6=
(i , 1), (6, 1), (i , 2), (7, 2), (6, 3), (7, 3). hard see z I(CS ), and, moreover,
deviation (CS , z) r-profitable 6, 7, . Hence, (CS , y) r-core
G.
Proposition 2. exists OCF-game G r-core(G) 6= o-core(G) = .
Proof. Consider OCF-game G = (N, v) 3 agents N = {1, 2, 3} whose weights given
w = (8, 8, 8), 2 task types t1 t2 . first task needs 6 units weight player,
value 300, i.e. v(r1 , r2 , r3 ) = 300 wi ri 6 = 1, 2, 3. second task needs 4 units
weight total players
7 7and6 has2value
12. 1 2
1
2
1
Let CS = (r , r ), r = 8 , 8 , 8 , r = 8 , 8 , 8 . Clearly, v(r 1 ) = 300, v(r 2 ) = 2.
Consider also imputation x I(CS ) given x1 = (100, 100, 100), x2 = (0.5, 0.5, 1).
hard see (CS , x) r-core(G). Indeed, CS maximizes social welfare,
deviation simultaneously profitable agents. Furthermore, agent withdraws
contribution r 1 , lose associated payoff 100 deviation compensate
loss. Moreover, clear withdrawing contribution r 2 cannot profitable either,
way earn 2 = v(r 2 ) amount weight.
201

fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGS

show G empty o-core. Suppose sake contradiction
exists outcome (CS , y) o-core(G). hard show outcome o-core
G maximizes social welfare; proof similar Theorem 4. Hence, assume
CS = (q 1 , q 2 ), v(q 1 ) = 300, v(q 2 ) = 2, and, moreover, qi1 68 = 1, 2, 3.
y12 + y22 + y32 = 2, assume without loss generality y12 = > 0. means
players 2 3 o-profitably deviate (CS , y) follows: players 2 3 withdraw
q21 w2 6 q31 w3 6 units weight q 1 , respectively (as argued above, q21 w2 6,
q31 w3 6), well entire contribution q 2 , use resources complete t2 .
divide resulting payoff allocating y22 + 2 player 2 y32 + 2 player 3, constitutes
o-profitable deviation them. Thus, (CS , y) o-core G.
Thus, far section investigated relationships among notions overlapping core; also insightful compare non-overlapping fuzzy one.
proceed so.
8.1 Comparison Non-Overlapping Core
Given OCF-game G = (N, v), define non-overlapping game Gno = (N, v )
setting v (C) = v(r C ), partial coalition r C given riC = 1 C riC = 0
otherwise C N . Observe threshold task game G applying transformation
overlapping version G gives us exactly non-overlapping version G. compare
core game Gno overlapping cores original game G. particular, natural
ask whether core Gno empty o-core G (and hence Theorem 5 also
r-core c-core G) not, vice versa, i.e., whether c-core (the largest
overlapping cores) G empty core Gno not. Interestingly, turns
answer questions positive. demonstrate via examples based threshold
task games; argued above, game G Gno = G.
Proposition 3. exists TTG G core(G) = , o-core(G) 6= .
Proof. Consider threshold task game G = (N ; w; t), N = {1, 2, 3}, w = (2, 2, 2),
= t1 = (3, 1). G, coalition structure CS contains one coalition C v(C) = 1.
Let p = (p1 , p2 , p3 ) imputation CS . v(CS ) = 1, exists N pi > 0.
coalition C = N \ {i} successfully deviate (CS , p), w(C ) = 4,
p(C ) = 1 pi < 1. Hence, outcome G stable.
G, players form two successful partial coalitions. Now, consider outcome (CS , x),
CS = (r 1 , r 2 ) r 1 = (1, 12 , 0), r 2 = (0, 21 , 1), x1 = ( 23 , 31 , 0), x2 = (0, 31 , 23 ).
claim (CS , x) o-core G. Indeed, suppose sake contradiction
group players J o-profitable deviation (CS , x). |J| {1, 2, 3}.
easy see |J| =
6 1: player enough weight complete t1 own. Also, |J| =
6 2:
4
4
pair players earns 3 (CS , x), make 1 < 3 . Finally, |J| =
6 3,
(CS , x) maximizes social welfare. contradiction completes proof.
Intuitively, Proposition 3 holds G feasible outcomes G,
additional outcomes turn stable. flip side, G allows wider range
deviations, outcome stable respect G may unstable respect G.
next proposition illustrates this.
202

fiC OOPERATIVE G AMES OVERLAPPING C OALITIONS

Proposition 4. exists TTG G c-core(G) = , core(G) 6= .
Proof. Consider threshold task game G = (N ; w; t), N = {1, 2, 3}, w = (9, 1, 1),
= (t1 , t2 ) t1 = (8, 100), t2 = (2, 1).
G, player 1 work task t1 , players 2 3 cooperate task t2 , sharing
profits equally. Clearly, resulting outcome stable.
hand, G c-stable outcomes. Indeed, suppose outcome
(CS , x) c-core G, let p corresponding payoff vector. Theorem 4, CS
consists two partial coalitions: r 1 , completes t1 , r 2 , completes t2 . Hence,
v(CS ) = 101. p1 > 100, p2 + p3 < 1, hence players 2 3 deviate forming
coalition r = (0, 1, 1) complete t2 value 1. p1 < 100, player 1 deviate
forming coalition r = (1, 0, 0) complete t1 value 100. Hence, p1 = 100,
p2 + p3 = 1, therefore assume without loss generality p2 21 . Now, players
1 2 deviate forming coalition structure CS = ( 98 , 0, 0), ( 19 , 1, 0) distributing
payoffs ((100, 0, 0), ( 13 , 23 , 0)). conclude (CS , x) c-stable, contradiction.
8.2 Comparison Fuzzy Games
mentioned earlier paper, Aubin (1981) introduces notion fuzzy game,
player participate coalition various levels, value coalition depends
participation levels members. Thus, first glance, definition fuzzy game identical
definition OCF-game, given characteristic functions defined [0, 1]n .
However, several crucial differences fuzzy OCF-games.
First, fuzzy games OCF-games differ definition outcome. Indeed,
OCF-games outcome (overlapping) coalition structure together list payoff vectors,
fuzzy games allowable outcome formation grand coalition. Furthermore,
outcome OCF-core needs stable deviation set (possibly overlapping) coalition structure. Aubin core, outcomes need stable deviation
partial (fuzzy) coalition, necessarily deviations coalition structure. Indeed,
formation coalition structures (overlapping not) addressed fuzzy games literature.
One could try represent games overlapping coalition structures using fuzzy games
formalism. Indeed, given OCF-game, construct fuzzy game whose characteristic
function simulates behaviour characteristic function original OCF-game coalition structures. Specifically, given OCF-game G = (N, v), define related fuzzy game
G = (N, v ) follows. r [0, 1]n , define
1

k

CS r = {(q , . . . , q ) | k

1, qij

0 = 1, . . . , n, j = 1, . . . , k,

k
X

qij = ri },

j=1

set v (r) = supCS CS r v(CS ). is, partial coalition r, v identifies best
coalition structure CS obtained splitting r subcoalitions, returns value
v(CS ). resulting fuzzy game G similar original OCF-game G. example,
TTGs, transformation would enable members grand coalition work several tasks
simultaneously. generally, given TTG G, outcome (G) (i.e., payoff vector
grand coalition) corresponds social-welfare maximizing outcome (CS , x) G vice versa.
203

fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGS

fact, relationship holds OCF-game G corresponding fuzzy game G
long set {v(CS ) | CS CS (1,...,1) } compact (and thus contains least upper bound).
However, approach fails capture several delicate aspects overlapping coalition formation. main reason fuzzy game formulation, actual set tasks executed
partial coalition implicit definition characteristic function. Indeed, outcome
fuzzy game simply payoff vector, guaranteed set tasks
provides corresponding total payoff, set tasks cannot read description
outcome. leads number difficulties.
First, fuzzy games formalism would allow us reason partial coalition structures
suboptimal social welfare. Theorem 4 coalition structures unlikely
final outcomes game, dynamic coalition formation protocol may produce partial coalition
structures intermediate steps. Thus, using language fuzzy coalitions impairs ability
study processes lead formation partial coalition structures. processes
great interest practical perspective, important disadvantage fuzzy model.
Further, OCF representation, one-to-one correspondence partial
coalitions tasks. makes OCF approach intuitively appealing, suggests provides right level granularity reasoning partial coalition formation. Indeed, consider
problem computational perspective context TTGs. OCF representation finding socially optimal coalition structure difficult (see Appendix A), computing
value given partial coalition r straightforward: simply pick valuable task
completed using resources posessed r. contrast, fuzzy game framework,
two issues intertwined, even computing partial coalitions worth hard problem.
Even importantly, definition fuzzy core given Aubin (1981) appropriate
many natural scenarios, and, particular, TTGs. Specifically, fuzzy core fuzzy game
G = (N, v) defined setP
outcomes (N, p) p(N ) = v(1, . . . , 1)
partial coalition r holds ni=1 pi ri v(r). Essentially, means group
players deviates grand coalition via partial coalition r, deviating player receives
payoff r, original payoff grand coalition, scaled factor
(1 ri ). Thus, fuzzy core even optimistic deviators perspective ocore. Indeed, deviators worry grand coalition able leave.
simply assume withdraw, say, 40% resources, get 60%
used get. However, many gamesand, particular, TTGsif players abandon
grand coalition, latter may sufficient resources complete task. Clearly,
case deviators could possibly get payoff remains grand coalition. Thus,
fuzzy core may empty, even practice game stable. example proof
Proposition 5 illustrates this.

Proposition 5. exists TTG G o-core(G) 6= , fuzzy core corresponding fuzzy game (G) empty.

Proof. Consider TTG G given N = {1, 2}, w = (10, 10), = ((20, 20), (7, 9)),
induced OCF-game G. corresponding fuzzy game (G) = (N, v ) given
204

fiC OOPERATIVE G AMES OVERLAPPING C OALITIONS



20



18
v (r) =

9



0

r1 + r2 = 2
1.4 r1 + r2 < 2
0.7 r1 + r2 < 1.4
r1 + r2 < 0.7

hard see outcome (CS , x) G, CS = r = (1, 1) x = (10, 10)
o-stable. Moreover, intuitively, clear rational agent coalition agents would want
deviate outcome. hand, definition fuzzy core outcome
(10, 10) (G) stable: indeed, q = (.7, .7) p1 q1 + p2 q2 = 14 < 18 = v (q).
prove outcome (G) fuzzy core. Observe since v (1, 1) =
20, outcome (G) form (z1 , z2 ), z1 + z2 = 20. Clearly, outcome
z1 < 9 z2 < 9 unstable, partial coalition (1, 0) (respectively, (0, 1)) profitably
deviate it. Thus assume z1 9, z2 9, or, equivalently, z2 11, z1 11. Thus,
partial coalition q considered above, z1 q1 + z2 q2 11 1.4 = 15.4 < 18 = v(q),
means (z1 , z2 ) fuzzy core.
Remark 4. remedy difficulties illustrated above, devise notion stability
defined within framework fuzzy games, yet essentially equivalent
P c-core. Let

n

us say outcome p G f-stable r [0, 1] v (r) isupp(r ) pi ,
define f-core G set f-stable outcomes G . Note definition
different standard definition fuzzy core. TTGs, one show outcome
p G f-core G corresponding outcome (CS , x) G ccore G. proof makes use fact TTGs one distribute profit v (r)
deviating partial coalition r among members supp(r) arbitrarily. (In detail, one
construct partial coalition structure CS involving agents supp(r) performs tasks total
value v (r) agent supp(r) participates partial coalition CS .) Moreover,
equivalence true general OCF games whose characteristic functions satisfy natural
regularity conditions; proof similar proof Theorem 1. Unfortunately, f-core
provides analogue c-core fuzzy game setup, clear devise analogue
r-core o-core setting. Indeed, define concepts, would reason
partial coalitions hurt deviation. However, description outcome
fuzzy game indicate partial coalitions given player belongs to, cannot
determine tasks affected deviation.
conclude natural settings OCF-games provide realistic
nuanced model fuzzy games; threshold task games appear one example.

9. Computational Aspects Stability Threshold Task Games
section, investigate computational complexity core-related questions TTGs.
goal twofold. First, TTGs provide natural model agent collaboration, therefore
important understand allocate resources games stable manner. Second,
analysis highlights important differences three definitions core games
overlapping coalitions. particular, results presented section provide complexitytheoretic separation c-core, one hand, r-core o-core,
205

fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGS

hand. believe results type useful building better understanding stability
context general OCF games.
Unless explicitly stated otherwise, make usual assumption parameters
gamei.e., weights, thresholds task utilitiesare integers given binary. assumption
made without loss generality, necessary formal complexity-theoretic analysis.
9.1 Games Non-Overlapping Coalitions
start analyzing complexity TTGs non-overlapping setting. mentioned
Section 5.1, games seen generalization weighted voting games coalition
structures. Elkind, Chalkiadakis & Jennings (2008) show several stability-related questions
games computationally hard weights integers given binary. Hence,
formulate following proposition, whose proof follows immediately results.
Proposition 6. Given TTG G = (N ; w; t), coNP-hard decide whether corresponding
game G empty core. Also, given outcome (CS , p) G, coNP-complete decide
whether (CS , p) core G. results hold even one task type,
utility task 1.
hand, Elkind et al. (2008) provide polynomial-time algorithm checking
outcome weighted voting game core weights given unary. algorithm
based dynamic programming: given weighted voting game G described set players N ,
list weights w threshold , weight 1, . . . , w(N ) identifies minimum payoff
Pw coalition weight w, checks Pw < 1 w .
hard see similar approach works threshold task games well.
complication weight w, addition computing minimum payoff coalition
weight given imputation, compute maximum utility available
coalition weight, i.e., max{uj | w j }, compare two quantities. However,
additional steps easy (in particular, performed efficiently even task utilities
large). gives us following result.
Proposition 7. exists algorithm that, given TTG G = (N ; w; t) outcome (CS , p)
G, checks whether (CS , p) core G runs time poly(w(N ), |p|), |p|
number bits binary representation p.
weighted voting games unary weights, Elkind et al. (2008) also show that, constructing linear program uses algorithm Proposition 7 oracle, check
polynomial time whether given coalition structure CS stabilized, i.e., whether exists
payoff vector p I(CS ) (CS , p) core. algorithm easily adapted
work TTGs unary weights. Hence, question whether given coalition structure
stabilized poly-time solvable games, too.
9.2 Games Overlapping Coalitions
show that, similarly non-overlapping case, weights, thresholds utilities
TTG integers given binary, computationally hard check given outcome
corresponding OCF game stable. Moreover, hardness result holds three definitions stabilty, i.e., c-core, r-core, o-core. results perhaps
206

fiC OOPERATIVE G AMES OVERLAPPING C OALITIONS

surprising given similar result non-overlapping setting (i.e., Proposition 6 above),
reason behind computational hardness quite different. Indeed, reduction used proof
Proposition 6 based PARTITION, classic NP-hard problem asks whether, given
set weights, split two sets weight. Essentially, proof proceeds
constructing outcome stable certain subset agents cannot split
two groups weight. proof technique unlikely work overlapping
scenario, one always form two partial coalitions weight allowing agents
split weight equally two coalitions. Hence, proof following theorem uses
somewhat different approach.
Theorem 6. Given TTG G = (N ; w; t) outcome (CS , x) corresponding OCF game
G, coNP-complete decide whether (CS , x) c-core G.
Proof. reduction based U NBOUNDED K NAPSACK, well-known NP-hard problem.
instance U NBOUNDED K NAPSACK (Martello & Toth, 1990) given set items,
item size si value zi , knapsack size B target value Z. yesinstance fill knapsack using unlimited number copies item
total size resulting set items B,
PZ, i.e.,
P total value least
vector non-negative integers (1 , . . . , ) i=1 si B i=1 zi Z.
Otherwise, no-instance.
Consider instance = ((s1 , . . . , ); (z1 , . . . , z ); B; Z) U NBOUNDED K NAPSACK.
assume without loss generality sj < B, zj < Z j = 1, . . . , . Moreover,
assume monotone, i.e., si sj implies zi zj . Indeed, pair items
si sj , zi > zj , simply delete jth item, used optimal solution.
construct instance problem follows. Set N = {1} let w1 = B.
Set = (t1 , t2 , . . . , t+1 ), j = sj , uj = zj j = 1, . . . , +1 = B, u+1 = Z 1.
Due restrictions I, game G = (N ; w; t) threshold task game.
Consider outcome (CS , p) CS consists single partial coalition r r1 = 1
p I(CS ). B > sj j = 1, . . . , , coalition executes task t+1 receives
utility Z 1. Hence, player 1 c-profitably deviate (CS , p) find
collection tasks whose total resource requirement weight B whose total utility
least Z, i.e., started yes-instance U NBOUNDED K NAPSACK.
proof Theorem 6 outcome (CS , x) consists single partial coalition. Thus,
r-profitable deviation (CS , x) c-profitable. implies following corollary.
Corollary 2. Given TTG G outcome (CS , x) corresponding OCF game G,
coNP-complete decide (CS , x) r-core G.
o-core, situation somewhat complicated. However, careful examination
proof Theorem 6 allows us obtain following corollary.
Corollary 3. Given TTG G = (N ; w; t) outcome (CS , x) corresponding OCF
game G, coNP-complete decide (CS , x) o-core G.
Proof. proof Theorem 6, construct OCF game 1 player outcome (r, x).
Consider o-profitable deviation (CS, y) (r, x). deviation necessarily
c-profitable deviation (r, x): (CS , y), agent 1 may withdraw some,
207

fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGS

resources (r, x) therefore continue derive benefit it. However, single
agent, allocating resources original partial coalition r equivalent forming
new partial coalition using amount resources, i.e., given (CS, y), one construct
deviation (r, x) c-profitable agent 1. hand, c-profitable
deviation (r, x) also o-profitable. Hence, (r, x) o-stable c-stable, i.e.,
started no-instance U NBOUNDED K NAPSACK.
rest section, focus case parameters game (i.e.,
players weights, thresholds task utilities) integers given unary, or,
equivalently, polynomial number
Given game G = (N ; w; t),
Pplayers.
j + uj ).
tj = (T j , uj ) j = 1, . . . , m, let |G| = w(N ) +
(T
j=1
turns setting checking whether outcome c-core becomes easy.
Intuitively, reason group players decides deviate, agents
group easily decide proceed: need pool weights find profitable
set tasks completed using amount resources.
Theorem 7. exists algorithm that, given TTG G = (N ; w; t) outcome (CS , x)
corresponding OCF game G, checks whether (CS , x) c-core G runs time
poly(|G|, |x|), |x| size binary representation imputation x.
Proof. algorithm based dynamic programming. First, w = 1, . . . , w(N ), let Uw
maximum profit coalition weight w make, i.e.,




X

X
Uw = max
j uj |
j j w, (1 , . . . , ) Nm .


j=1

j=1

w = 1, . . . , w(N ), quantity Uw computed using dynamic programming
algorithm U NBOUNDED K NAPSACK. running time procedure polynomial |G|.
Now, let p payoff vector corresponds imputation x. = 1, . . . , n
w = 1, . . . , w(N ), set Pi,w = min{p(S) | {1, . . . , i}, w(S) = w}. quantities Pi,w
easily computed using dynamic programming. Indeed, P1,w = p1 w = w1
P1,w = + otherwise (we use convention min = +). Furthermore, compute
Pi+1,w given values (Pi,w )w =1,...,w setting Pi+1,w = min{Pi,w , pi + Pi,wwi }. running
time procedure poly(|G|, |p|).
Suppose computed Pn,w w = 1, . . . , w(N ). Observe value Pn,w
least amount received coalition weight w p. Now, w = 1, . . . , w(N ),
compare quantities Pn,w Uw . value w latter exceeds former,
coalition N could increase collective earnings deviating (CS , x), i.e.,
(CS , x) c-core G. hard see converse also true: Pn,w Uw
w = 1, . . . , w(N ), coalition c-profitable deviation (CS , x), hence
(CS , x) c-core G.
Clearly, algorithm runs time poly(|G|, |x|).
contrast, corresponding problems r-core o-core computationally hard.
Intuitively, reason decisions players make longer binary: instead
simply deciding whether deviate, decide coalitions
208

fiC OOPERATIVE G AMES OVERLAPPING C OALITIONS

non-deviators abandon. case o-core, also possibility reducing ones
contribution partial coalition rather abandoning altogether.
Theorem 8. Given TTG G = (N ; w; t) outcome (CS , x) corresponding OCF game
G, strongly coNP-complete decide whether (CS , x) r-core G.
Proof. hard see problem coNP: show outcome (CS , x)
r-core G, guess set deviators J deviation (CS , y), check (CS , y)
r-profitable J computing payoffs players J x y.
show coNP-hardness, reduce AXIMUM E DGE B ICLIQUE (Peeters, 2003).
instance AXIMUM E DGE B ICLIQUE given bipartite graph B = (L, R, E) set
vertices L R set edges E L R, parameter K. yes-instance B
contains biclique size least K, i.e., sets L L, R R |L | |R | K,
L R (, ) E. Otherwise, no-instance.
Suppose given instance (B, K) AXIMUM E DGE B ICLIQUE B =
(L, R, E), L = {1 , . . . , |L| }, R = {1 , . . . , |R| }. create instance problem
follows. Assume without loss generality |L| |R|, set n = |R|+1, k = |L|, = k 2 n2 ,
V = k 2 nM , create n players weights w1 = = wn1 = k, wn = k(kn n + 1)
2 task types t1 = (kn; V ) t2 = (K; (n 1)k + 1). Also, create coalition structure
CS = (r 1 , . . . , r k ) given rij = 1/k = 1, . . . , n j = 1, . . . , k. Observe
total weight rj CS kn, partial coalition performs t1 . Finally, construct
imputation x = (x1 , . . . , xk ), j = 1, . . . , k = 1, . . . , n 1, set xji = 1
Pn1 j
xi j = 1, . . . , k.
(i, j) E xji = otherwise. Also, set xjn = V i=1
Suppose started yes-instance AXIMUM E DGE B ICLIQUE, let (L , R )
corresponding subgraph B. subset players J = {i | R } r-profitably
deviate (CS , x) abandoning partial coalitions set = {r j | j L }, using
freed-up resources embark t2 . Indeed, x players J collectively earn
(n 1)k partial coalitions S, devote least K units weight coalitions.
Conversely, consider r-profitable deviation (CS , y), let J corresponding set
deviators. Suppose k1 coalitions CS work t1 , k2 coalitions work t2 . First, suppose
n J. Observe (CS , y) profitable player n k1 = k, k2 = 0: indeed,
(CS , x) player n earns least k(V (n 1)M ), whereas outcome completes less
2
k copies t1 earns (k 1)V + kKn ((n 1)k + 1) < k(V (n 1)M ). However,
deviation results executing k copies t1 must involve resources players, i.e.,
J = {1, . . . , n}, deviation cannot simultaneously profitable members
deviating set. Hence, n 6 J, therefore w(J) k(n 1). Consequently, k1 = 0

deviators total profit w(J)
K ((n 1)k + 1) < . means (CS , y)
r-profitable deviation player J abandons coalition r j CS xji = .
hand, successfully execute even one copy t2 , members J must collectively
withdraw least K units weight. Let R = {i | J}, let L correspond set
partial coalitions CS affected deviation; (L , R ) biclique size least K.
hard check proof Theorem 8 player withdraw part resources partial coalition CS still claim profit coalition. implies
checking whether given outcome o-core computationally hard, too.
209

fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGS

Corollary 4. Given TTG G outcome (CS , x) corresponding OCF game G,
strongly coNP-complete decide whether (CS , x) o-core G.
hand, combining techniques Theorem 7 Theorem 4 leads pseudopolynomial algorithm checking whether c-core TTG non-empty.
Theorem 9. Given TTG G = (N ; w; t), one check time poly(|G|) whether corresponding OCF game G non-empty c-core.
Proof. show c-core game G non-empty, social welfaremaximizing set tasks construct coalition structure CS executes set tasks
imputation x I(CS ) (CS , x) c-core G; moreover, CS agent
contributes coalition. Hence, algorithm first selects social welfare-maximizing set
tasks, constructs coalition structure perform set tasks, finally solves
linear program check coalition structure stabilized. details follow.
Assume simplicity contains task type = 1; case
add task type t0 = (1, 0) t. allows us assume coalition structure
agents resources committed tasks. Fix social welfare-maximizing multi-set tasks
{1 t1 , . . . , tm }. Suppose
let (CS , y) outcome c-core G.
Pmc-core(j G) 6= ,

Theorem 4, j=1 j u = v(CS ). Consider coalition structure CS contains
1 + + coalitions: first 1 coalitions weight 1 each, next 2 coalitions
weight 2 each, etc., agent distributes resources evenly coalitions, i.e.,
T1
contributes wi w(N
) units weight first 1 coalitions, etc. CS agents
contribute partial coalitions, v(CS ) = v(CS ), I(CS ). Moreover,
clear outcome (CS , y) c-core(G): c-profitable deviation (CS , y) also
c-profitable deviation (CS , y).
Proposition 9 weights given unary, find social welfare-maximizing
coalition structure CS = (r 1 , . . . , r k ) polynomial time. Consider following linear program:
pi 0 = 1, . . . , n
X

pi = v(CS )

X

pi Uw(J) J N,



iJ

Uw defined proof Theorem 7. linear program exponentially
many constraints, solved linear time ellipsoid method (Schrijver, 1986), since
polynomial-time separation oracle. Indeed, decide whether given candidate solution
feasible using algorithm described proof Theorem 7.
Clearly, linear program feasible solution p, imputation x given xji =
j
p v(r ) N j = 1, . . . , |CS | satisfies x I(CS ), and, moreover, (CS , x)
v(CS )

c-core(G). Conversely, feasible solution, CS cannot stabilized,
hence argument c-core G empty.
210

fiC OOPERATIVE G AMES OVERLAPPING C OALITIONS

10. Conclusions, Extensions, Future Work
paper introduced model cooperative games allows overlapping coalitions
takes account need resource allocation. so, generalized usual models
either grand coalition desirable outcome outcomes required
partitions set agents. Given model, defined studied depth notion
core (the c-core) generalization core traditional models cooperative game
theory. quite general conditions, provided characterization outcomethat
is, (coalition structure, imputation) pairto belong core. also showed outcome
core maximizes social welfare. Further, introduced notion balancedness OCFgames, showed coalition structure CS admits imputation x (CS , x)
core game balanced. Moreover, extended notion convexity
setting showed convex games non-empty core.
addition, considered two notions core-stability OCF-games, differ
(as well first one) deviators expect obtain collaboration non-deviators. Together, three notions core span wide range beliefs
deviators may hold regarding payoffs coalitions non-deviators, substantially
different respect sets outcomes characterize, respect
computational complexity. also compared OCF-games non-overlapping
analogues, showed social welfare maximization perspective, OCF-games may
provide higher total utility, easier work classic counterparts.
also argued OCF-games provide appropriate modelling framework fuzzy games
many scenarios; particular, certainly case threshold task games. summarize,
paper one first attempts provide theoretical treatment overlapping coalition
formation, study stability setting thorough manner.
10.1 Extensions
many environments, coalition formed, may choice actions execute.
deterministic setting one considered paper, coalition simply
choose action results highest possible payoff, probabilistic environment
choice difficult: coalition may want strike balance expected payoff
variance. address issue, incorporate coalitional actions model follows.
coalition allowed select action (usually finite) action space A. Without loss
generality, assume coalition undertake action A.3 value coalition
determined resource contribution levels members action selected. Therefore, characteristic function setting defined (r, a) pairs, r = (r1 , . . . , rn )
vector resources, action. definitions results generalize readily
situation coalition choice actions (simply put, presentation far
corresponds situation coalition exactly one action available it).
Another extension examined modelling available resources.
ease presentation assumed throughout paper exists one type (continuous) resource. Nevertheless, results still hold assume multiple types resources
(e.g., agents distribute time money among coalitions). Moreover,
3. situation case modeled setting value respective (coalition, action) pair
0.

211

fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGS

also studied discrete OCF setting, agent contribution levels taking values finite set
(i.e., agent may able contribute 20%, 21% resources given coalition).
setting obviously interest many applications involving countable resources (as
discretization effectively kind resources common practice). discrete resources,
number possible coalition structures finite (as coalition setting collection
resourcessee Section 4). definitions theorems carry setting
minor differences arguments used proofs.
10.2 Future Work
exist many exciting open questions future work. First all, important research direction develop better understanding scenarios overlapping coalitions naturally arise, identify appropriate stability concepts scenarios. believe
techniques developed paper prove useful purpose. Moreover, one first
priorities investigate alternative notions stability (i.e., o-core r-core)
proposed above, obtain relevant characterization results, c-core. Extending
solution concepts coalitional gamessuch as, e.g., Shapley valueto OCF settings
important research direction well.
also plan study computational complexity core-related questions
setting. First, initiated study complexity-theoretic aspects stability OCF
games, paper focused complexity checking whether given outcome
stable. Another natural problem domain studying complexity checking whether
game stable solutioni.e., whether c-core (r-core, o-core) non-empty. Theorem 9 makes
first steps direction, suggesting problem may easier overlapping setting
classic setting: indeed, Elkind et al. (2008) conjecture WVGs coalition
structures checking non-emptiness core hard unary weights.
Now, hardness results computing allocation core checking core nonempty traditional settingas work Chvatal (1978), Tamir (1991), Deng
Papadimitriou (1994), Sandholm et al. (1999), Conitzer Sandholm (2006)and hardness
results paper suggest one hope identify special classes games
efficient algorithms computing core allocations. noted earlier, element core
convex games computed traditional setting simply taking vector marginal
contributions agents arbitrary permutation set agents. setting, even
though proof yields procedure constructing element c-core, requires solving
series optimization questions, arbitrary convex games NP-hard. Naturally, would
desirable find classes convex games proof yields polynomial time algorithm.
also interested finding processes lead core necessarily convex games;
though randomized algorithms ones Dieckmann Schwalbe (1998) Chalkiadakis Boutilier (2004) trivially extend overlapping setting, would little practical value due huge space potential overlapping configurations. Therefore,
interested finding ways exploit known game structure prune search space potential
stable configurations. Another subject future research extending model allow infinite
coalition structures. Furthermore, would interesting establish links outcomes
core outcomes bargaining equilibria overlapping coalitional bargaining games.
212

fiC OOPERATIVE G AMES OVERLAPPING C OALITIONS

Finally, incorporation actions model allows investigation action stochasticity and, generally, uncertainty OCF setting. instance, coalitional action
associated distribution possible payoff outcomes resulting execution.
poses challenges study models theoretical practical standpoint, since
introduction uncertainty leads several intricacies readily resolved use deterministic concepts models, work Suijs Borm (1999), Suijs, Borm, Wagenaere, Tijs
(1999), Blankenburg, Klusch, Shehory (2003), Chalkiadakis Boutilier (2004) Chalkiadakis, Markakis, Boutilier (2007) demonstrates. related note, enriching model description capture type uncertainty (Chalkiadakis & Boutilier, 2004; Chalkiadakis et al.,
2007) would allow ready translation uncertainty regarding types (capabilities) players coalitional value uncertainty, still capturing potential stochasticity coalitional
action outcomes time.

11. Acknowledgments
would like thank anonymous reviewers constructive comments. research
supported ALADDIN (Autonomous Learning Agents Decentralised Data Information
Networks) project, jointly funded BAE Systems EPSRC strategic partnership
(EP/C548051/1); well EPSRC (GR/T10664/01), ESRC (ES/F035845/1), Singapore
NRF Research Fellowship 2009-08.

Appendix A. Algorithmic Aspects Social Welfare Maximization TTGs
appendix, study complexity finding social welfare-maximizing outcome TTGs,
overlapping non-overlapping scenario. Unless explicitly mentioned otherwise,
make standard assumption parameters description TTG (i.e., agents
weights, thresholds task utilities), integers given binary.
hard see finding non-overlapping coalition structure maximizes social
welfare NP-hard problem.
Proposition 8. Given TTG G = (N ; w; t) parameter K, NP-complete decide G
outcome (CS , p) v(CS ) K. holds even one task type, i.e., = t1 ,
weights, thresholds utilities given unary.
Proof. easy see problem NP. show NP-hardness, give reduction 3PARTITION (Garey & Johnson, 1990) problem. instance 3-PARTITION given
P3 list
non-negative integers = (a1 , . . . , a3 ) integer parameter B satisfies i=1 = B
B/4 < ai < B/2 = 1, . . . , 3. yes-instance elements
partitioned sets S1 , . . . , a(S1 ) = = a(S ) = B no-instance
otherwise.
Given instance 3-PARTITION, consider TTG G N = {1, . . . , 3}, wi = ai
= 1, . . . , 3 single task type = (T, u) = B u = 1. Clearly, deciding whether
maximum social welfare achievable G least equivalent checking whether given
instance 3-PARTITION yes-instance. Moreover, since 3-PARTITION known remain
NP-hard input given unary, true problem.
213

fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGS

contrast, finding social welfare-maximizing coalition structure OCF game corresponds TTG somewhat easier problem. Indeed, simply add together agents
weights, find optimal set tasks execute given amount resource. latter
problem equivalent U NBOUNDED K NAPSACK, known NP-hard inputs
given binary, polynomial-time solvable elements input given unary
2 items; details, see (Martello & Toth, 1990), Section 3.6. Consequently,
similar conclusion holds problem.
Proposition 9. Given TTG G = (N ; w; t) parameter K, NP-complete decide
G outcome (CS , x) v(CS) K. However, problem becomes polynomial-time
solvable weights, thresholds utilities given unary 2 task types.

References
Albizuri, M., Aurrecoechea, J., & Zarzuelo, J. (2006). Configuration values: Extensions
coalitional Owen value. Games Economic Behavior, 57, 117.
Apt, K., & Radzik, T. (2006). Stable partitions coalitional games.. Working Paper, available
http://arxiv.org/abs/cs.GT/0605132.
Apt, K., & Witzel, A. (2009). generic approach coalition formation. International Game
Theory Review (IGTR), 11, 347367.
Aubin, J.-P. (1981). Cooperative fuzzy games. Mathematics Operations Research, 6(1), 113.
Aumann, R., & Dreze, J. (1974). Cooperative games coalition structures. International Journal
Game Theory, 3(4), 217237.
Bachrach, Y., & Rosenschein, J. (2007). Computing Banzhaf power index network flow
games. Proc. 6th International Conference Autonomous Agents Multiagent
Systems (AAMAS-07), pp. 335341.
Bachrach, Y., & Rosenschein, J. (2008). Coalitional skill games. Proc. 7th International
Conference Autonomous Agents Multiagent Systems (AAMAS-08), pp. 10231030.
Blankenburg, B., Klusch, M., & Shehory, O. (2003). Fuzzy kernel-stable coalitions rational
agents. Proc. 2nd International Conference Autonomous Agents Multiagent
Systems (AAMAS-03), pp. 916.
Bondareva, O. N. (1963). applications linear programming methods theory cooperative games (in russian). Problemy Kibernetiki, 10, 119139.
Branzei, R., Dimitrov, D., & Tijs, S. (2005). Models cooperative game theory. Springer.
Branzei, R., Dimitrov, D., & Tijs, S. (2003). Convex fuzzy games participation monotonic
allocation schemes. Fuzzy Sets Systems, 139(2), 267281.
Chalkiadakis, G., & Boutilier, C. (2004). Bayesian reinforcement learning coalition formation
uncertainty. Proc. 3rd International Conference Autonomous Agents
Multiagent Systems (AAMAS-04), pp. 10901097.
Chalkiadakis, G., Elkind, E., Markakis, E., & Jennings, N. R. (2008). Overlapping coalition formation. Proc. 4th International Workshop Internet Network Economics
(WINE-08), pp. 307 321.
214

fiC OOPERATIVE G AMES OVERLAPPING C OALITIONS

Chalkiadakis, G., Markakis, E., & Boutilier, C. (2007). Coalition formation uncertainty:
Bargaining equilibria Bayesian core stability concept. Proc. 6th International
Conference Autonomous Agents Multiagent Systems (AAMAS-07), pp. 400407.
Chvatal, V. (1978). Rational behavior computational complexity.. Technical Report SOCS-78.9,
School Computer Science, McGill University, Montreal.
Conconi, P., & Perroni, C. (2001). Issue linkage issue tie-in multilateral negotiations.. CESifo
Working Paper No. 601.
Conitzer, V., & Sandholm, T. (2006). Complexity constructing solutions core based
synergies among coalitions. Artificial Intelligence, 170(6-7), 607619.
Dang, V. D., Dash, R. K., Rogers, A., & Jennings, N. R. (2006). Overlapping coalition formation
efficient data fusion multi-sensor networks. Proc. 21st National Conference
AI (AAAI-06), pp. 635640.
Deng, X., & Papadimitriou, C. (1994). complexity cooperative solution concepts. Mathematics Operation Research, 19, 257266.
Dieckmann, T., & Schwalbe, U. (1998). Dynamic coalition formation core.. Economics
Department Working Paper Series, Department Economics, National University Ireland
- Maynooth.
Elkind, E., Chalkiadakis, G., & Jennings, N. R. (2008). Coalition structures weighted voting
games. Proc. 18th European Conference Artificial Intelligence (ECAI-2008), pp.
393 397.
Elkind, E., Goldberg, L. A., Goldberg, P. W., & Wooldridge, M. (2009). Computational complexity
weighted voting games. Annals Mathematics Artificial Intelligence, 2(56), 109131.
Garey, M. R., & Johnson, D. S. (1990). Computers Intractability; Guide Theory
NP-Completeness. W. H. Freeman & Co.
Gillies, D. (1953). Theorems n-Person Games. Ph.D. thesis, Department Mathematics,
Princeton University, Princeton.
Greco, G., Malizia, E., Palopoli, L., & Scarcello, F. (2009). complexity compact coalitional games. Proc. 21st International Joint Conference Artificial Intelligence
(IJCAI-09), pp. 147152.
Ieong, S., & Shoham, Y. (2005). Marginal contribution nets: compact representation scheme
coalitional games. Proc. Sixth ACM Conference Electronic Commerce (ACM
EC05), pp. 193202.
Manisterski, E., Sarne, D., & Kraus, S. (2008). Cooperative search concurrent interactions.
Journal Artificial Intelligence Research (JAIR), 32(136).
Martello, S., & Toth, P. (1990). Knapsack Problems: Algorithms Computer Implementations.
John Wiley & Sons.
Myerson, R. (1991). Game Theory: Analysis Conflict. Harvard University Press.
Osborne, M., & Rubinstein, A. (1994). course game theory. MIT Press.
Owen, G. (1977). Values games priori unions. Henn, R., & Moeschlin, O. (Eds.),
Mathematical Economics Game Theory, pp. 7687. Springer-Verlag.
215

fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGS

Patel, J., Teacy, W., Jennings, N. R., Luck, M., Chalmers, S., Oren, N., Norman, T., Preece, A., Gray,
P., Shercliff, G., Stockreisser, P., Shao, J., Gray, W., Fiddian, N., & Thompson, S. (2005).
Agent-based virtual organisations Grid. Multiagent Grid Systems, 1(4), 237249.
Peeters, R. (2003). maximum edge biclique problem NP-complete. Discrete Applied Mathematics, 131(3), 651654.
Rahwan, T., Ramchurn, S., Jennings, N. R., & Giovannucci, A. (2009). anytime algorithm
optimal coalition structure generation. Journal Artificial Intelligence Research (JAIR),
34(521567).
Sandholm, T., Larson, K., Andersson, M., Shehory, O., & Tohme, F. (1999). Coalition structure
generation worst case guarantees. Artificial Intelligence, 111(12), 209238.
Sandholm, T., & Lesser, V. (1997). Coalitions among computationally bounded agents. Artificial
Intelligence, 94(1), 99137.
Schrijver, A. (1986). Theory Linear Integer Programming. John Wiley & Sons.
Shapley, L. S. (1967). balanced sets cores. Naval Research Logistics Quarterly, 14, 453
460.
Shapley, L. (1953). value n-person games. Kuhn, H., & Tucker, A. (Eds.), Contributions
Theory Games II, pp. 307317. Princeton University Press, Princeton.
Shapley, L. (1971). Cores convex games. International Journal Game Theory, 1, 1126.
Shehory, O., & Kraus, S. (1996). Formation overlapping coalitions precedence-ordered taskexecution among autonomous agents. Proc. 2nd International Conference MultiAgent Systems (ICMAS-96), pp. 330337.
Shehory, O., & Kraus, S. (1998). Methods task allocation via agent coalition formation. Artificial
Intelligence, 101(12), 165200.
Suijs, J., & Borm, P. (1999). Stochastic cooperative games: superadditivity, convexity certainty
equivalents. Journal Games Economic Behavior, 27, 331345.
Suijs, J., Borm, P., Wagenaere, A. D., & Tijs, S. (1999). Cooperative games stochastic payoffs.
European Journal Operational Research, 113, 193205.
Tamir, A. (1991). core network synthesis games. Mathematical Programming, 50, 123
135.
von Neumann, J., & Morgenstern, O. (1944). Theory Games Economic Behavior. Princeton
University Press, Princeton.

216

fiJournal Artificial Intelligence Research 39 (2010) 51-126

Submitted 4/10; published 9/10

Implicit Abstraction Heuristics
Michael Katz
Carmel Domshlak

dugi@tx.technion.ac.il
dcarmel@ie.technion.ac.il

Faculty Industrial Engineering & Management,
Technion, Israel

Abstract
State-space search explicit abstraction heuristics state art costoptimal planning. heuristics inherently limited, nonetheless, size
abstract space must bounded some, even large, constant. Targeting
shortcoming, introduce notion (additive) implicit abstractions,
planning task abstracted instances tractable fragments optimal planning.
introduce concrete setting framework, called fork-decomposition,
based two novel fragments tractable cost-optimal planning. induced admissible
heuristics studied formally empirically. study testifies accuracy
fork decomposition heuristics, yet empirical evaluation also stresses tradeoff
accuracy runtime complexity computing them. Indeed,
power explicit abstraction heuristics comes precomputing heuristic
function offline determining h(s) evaluated state fast lookup
database. contrast, fork-decomposition heuristics calculated
polynomial time, computing far fast. address problem,
show time-per-node complexity bottleneck fork-decomposition heuristics
successfully overcome. demonstrate equivalent explicit abstraction
notion database exists fork-decomposition abstractions well, despite
exponential-size abstract spaces. verify empirically heuristic search
databased fork-decomposition heuristics favorably competes state art
cost-optimal planning.

1. Introduction
Heuristic search, either progression space world states regression space subgoals, common successful approach classical planning.
probably popular approach cost-optimal planning, is, finding plan
minimal total cost actions. difference various heuristic-search
algorithms optimal planning mainly admissible heuristic functions employ.
state-space search, heuristic estimates cost achieving goal given
state guarantees overestimate cost.
useful heuristic function must accurate well efficiently computable. Improving
accuracy heuristic function without substantially worsening time complexity
computing usually translates faster search optimal solutions. last
decade, numerous computational ideas evolved new admissible heuristics classical
planning; include delete-relaxing max heuristic hmax (Bonet & Geffner, 2001), critical path heuristics hm (Haslum & Geffner, 2000), landmark heuristics hL , hLA (Karpas &
Domshlak, 2009) hLM-cut (Helmert & Domshlak, 2009), abstraction heuristics
c
2010
AI Access Foundation. rights reserved.

fiKatz & Domshlak

pattern database heuristics (Edelkamp, 2001) merge-and-shrink heuristics (Helmert,
Haslum, & Hoffmann, 2007). focus work abstraction heuristics.
Generally speaking, abstraction planning task given mapping :
states planning tasks transition system states abstract
transition system that, states s, s0 S, cost (s) (s0 ) upperbounded cost s0 . abstraction heuristic value h (s) cost
(s) closest goal state abstract transition system. Perhaps well-known
abstraction heuristics pattern database (PDB) heuristics, based projecting
planning task onto subset state variables explicitly searching optimal
plans abstract space. years, PDB heuristics shown
effective several hard search problems, including cost-optimal planning (Culberson &
Schaeffer, 1998; Edelkamp, 2001; Felner, Korf, & Hanan, 2004; Haslum, Botea, Helmert,
Bonet, & Koenig, 2007). conceptual limitation heuristics, however,
size abstract space dimensionality must fixed.1 recent merge-andshrink abstractions generalize PDB heuristics overcome latter limitation (Helmert
et al., 2007). Instead perfectly reflecting state variables, merge-and-shrink
abstractions allow imperfectly reflecting variables. demonstrated formal
empirical analysis Helmert et al., flexibility often makes merge-and-shrink
abstractions much effective PDBs. However, merge-and-shrink abstract
spaces still searched explicitly, thus still fixed size. quality
heuristics estimates still obtained many problems, limitation critical
obstacle many others.
goal paper push envelope abstraction heuristics beyond explicit
abstractions. introduce principled way obtain abstraction heuristics limit neither dimensionality size abstract spaces. basic idea behind
call implicit abstractions simple intuitive: instead relying abstract problems
easy solve small, rely abstract problems belonging
provably tractable fragments optimal planning. key point that, least theoretically, moving implicit abstractions removes requirement abstractions size
small. contribution, however, showing implicit abstractions far
theoretical interest only. Specifically,
1. specify acyclic causal-graph decompositions, general framework additive implicit abstractions based decomposing problem hand along causal
graph. introduce concrete family abstractions, called fork decompositions, based two novel fragments tractable cost-optimal planning.
Following type analysis suggested Helmert Mattmuller (2008), formally analyze asymptotic performance ratio fork-decomposition heuristics
prove worst-case accuracy selected domains comparable
(even parametric) state-of-the-art admissible heuristics. empirically evaluate accuracy fork-decomposition heuristics large set domains
recent planning competitions show accuracy competitive
state art.
1. necessarily apply symbolic PDBs which, tasks, may exponentially reduce
PDBs representation (Edelkamp, 2002).

52

fiImplicit Abstraction Heuristics

2. key attraction explicit abstractions state-to-goal costs abstract
space precomputed stored memory preprocessing phase
heuristic evaluation search done simple lookup. necessary condition would seem small size abstract space. However,
show equivalent PDB merge-and-shrinks notion database
exists fork-decomposition abstractions well, despite exponential-size abstract spaces latter. databased implicit abstractions based proper
partitioning heuristic computation parts shared search
states parts must computed online per state. empirical evaluation
shows equipped databased fork-decomposition heuristics favorably
competes state art cost-optimal planning.
work revision extension formulation results presented Katz
Domshlak (2008, 2009), turn based ideas first sketched also Katz
Domshlak (2007a).

2. Preliminaries
consider classical planning tasks corresponding state models single initial state
deterministic actions. Specifically, consider state models captured sas+
formalism (Backstrom & Nebel, 1995) nonnegative action costs. planning task
given quintuple = hV, A, I, G, costi, where:
V set state variables, v V associated finite domain
D(v). subset variables V 0 V , denote set assignments V 0
D(V 0 ) = vV 0 D(v). complete assignment V called state, = D(V )
state space . initial state. goal G partial assignment V ;
state goal state iff G s.
finite set actions. action pair hpre(a), eff(a)i partial assignments
V called preconditions effects, respectively. Av denote actions
affecting value v. cost : R0+ real-valued, nonnegative action cost
function.
variable v value D(v), instantiation v denoted v : .
partial assignment p, V(p) V denotes subset state variables instantiated p.
turn, V 0 V(p), p[V 0 ] denote value V 0 p; V 0 = {v} singleton,
use p[v] p[V 0 ]. sequence actions variable v V , v denote
restriction actions changing value v; is, v maximal subsequence
consisting actions Av .
action applicable state iff s[v] = pre(a)[v] v V(pre(a)). Applying
changes value v V(eff(a)) eff(a)[v]. resulting state denoted sJaK;
sJha1 , . . . , ak iK denote state obtained sequential application (respectively
applicable) actions a1 , . . . , ak starting state s. action sequence s-plan
G sJha1 , . . . , ak iK, cost-optimal (or, follows, optimal) s-plan
sum action costs minimal among s-plans. purpose (optimal) planning
finding (optimal) I-plan. pair states s1 , s2 S, cost(s1 , s2 ) refer
53

fiKatz & Domshlak

p2

B

c2

F
c


c1





c

c



E
p

c3

C

p

G
p1

(a)

(b)


c

B




F


E

C

E



B

C



E

F

G

G
c

(c)

c

(d)

Figure 1: Logistics-style example adapted Helmert (2006) illustrated (a).
goal deliver p1 C G p2 F E using cars c1 , c2 , c3
truck t, making sure c3 ends F . cars may use city roads (thin
edges); truck may use highway (thick edge). Figures (b), (c),
(d) depict, respectively, causal graph problem, domain transition
graphs (labels omitted) c1 c2 (left), (center), c3 (right),
identical domain transition graphs p1 p2 .

cost cost-optimal plan s1 s2 ; h (s) = mins0 G cost(s, s0 ) custom notation
cost optimal s-plan . Finally, important roles follows played
pair standard graphical structures induced planning tasks.
causal graph CG() digraph nodes V . arc (v, v 0 ) CG()
iff v 6= v 0 exists action (v, v 0 ) V(eff(a)) V(pre(a))
V(eff(a)). case, say (v, v 0 ) induced a. succ(v) pred(v)
respectively denote sets immediate successors predecessors v CG().
domain transition graph DTG(v, ) variable v V arc-labeled digraph
nodes D(v) arc (, 0 ) labeled pre(a)[V \ {v}] cost(a)
exists graph iff eff(a)[v] = 0 , either pre(a)[v] = v 6 V(pre(a)).
illustrate various constructs, use slight variation Logistics-style example
Helmert (2006). example depicted Figure 1a, sas+
54

fiImplicit Abstraction Heuristics

V

= {p1 , p2 , c1 , c2 , c3 , t}

D(p1 ) = D(p2 ) = {A, B, C, D, E, F, G, c1 , c2 , c3 , t}
D(c1 ) = D(c2 ) = {A, B, C, D}

D(c3 ) = {E, F, G}
D(t) = {D, E}

= {p1 : C, p2 : F, : E, c1 : A, c2 : B, c3 : G}

G = {p1 : G, p2 : E, c3 : F },

actions corresponding possible loads unloads, well single-segment movements vehicles. instance, action captures loading p1 c1 C,
pre(a) = {p1 : C, c1 : C}, eff(a) = {p1 : c1 }. actions example unit cost.
causal graph example, well domain transition graphs state
variables, depicted Figures 1b-1d.
Heuristic functions used informed-search procedures estimate cost (of
cheapest path) search node nearest goal node. focus statedependent, admissible abstraction heuristics. heuristic function h state-dependent
estimate search node depends problem state associated node,
is, h : R0+ {}. heuristics use days state-dependent (though
see, e.g., Richter, Helmert, & Westphal, 2008 Karpas & Domshlak, 2009 different
case). heuristic h admissible h(s) h (s) states s. h1 h2 two
admissible heuristics, h2 (s) h1 (s) states s, say h1 dominates h2 .
set admissible heuristics h1 , . . . , hm , pointwise maximum always
admissible heuristic, dominating individual heuristic set. sets admissible heuristics, pointwise sum also admissible dominates pointwise
maximum. Many recent works cost-optimal planning based additive ensembles admissible heuristics, includes critical-path heuristics (Haslum, Bonet, &
Geffner, 2005; Coles, Fox, Long, & Smith, 2008), pattern database heuristics (Edelkamp,
2001; Haslum et al., 2007), landmark heuristics (Karpas & Domshlak, 2009; Helmert &
Domshlak, 2009). particular, Katz Domshlak (2007a, 2008) Yang et al. (2007,
2008) independently introduced general criterion admissible additive ensembles
heuristics, called former work action cost partitioning. criterion formalized follows. Let = hV, A, I, G,
planning task {costi : R0+ }m
i=1
Pcosti

family cost functions i=1 costi (a) cost(a) actions A. {hi }m
i=1
set

arbitrary
admissible
heuristic
functions


=
hV,
A,
I,
G,
cost
i,
respectively,


P


i=1 hi also admissible heuristic . set cost functions {costi }i=1
seen partition action costs cost.

3. Abstractions Abstraction Heuristics
semantics planning task given induced state-transition model, often
called transition graph .

55

fiKatz & Domshlak

Definition 1 transition graph tuple = (S, L, Tr, s0 , ? , $) finite
set states, L finite set transition labels, Tr L set (labeled)
transitions, s0 initial state, ? set goal states, $ : L R0+
transition cost function.
state subset states 0 T, cost(s, 0 ) cost (of
cheapest respect $ path) state 0 along transitions T;
state 0 reachable s, cost(s, 0 ) = .
path s0 ? plan T, cheapest plans called optimal.
states transition graph T() induced planning task = hV, A, I, G, costi
states . transition labels T() actions A; transition
(s, a, sJaK) Tr iff applicable s; initial state s0 = I; set goal states
? = {s | G}; transition cost function $ = cost.
proceed
formally specifying notion abstraction. definition abstraction resembles
Prieditis (1993), right beginning specify general notion
additive abstraction. Informally, additive abstraction refer set abstractions
interconstrained requirement jointly overestimate transition-path costs
abstracted transition graph.
Definition 2 additive abstraction transition graph = (S, L, Tr, s0 , ? , $)
set pairs {hTi , i}m
i=1 where, 1 m,
Ti = (Si , Li , Tri , s0i , Si? , $i ) transition graph,
: Si function, called abstraction mapping,
(s0 ) = s0i , (s) Si? ? , and,
pairs states s, s0 holds

X
i=1

cost(i (s), (s0 )) cost(s, s0 ).

(1)

words use particular notion abstraction. term abstraction
usually associated simplifying original system, reducing factoring details
less crucial given context. details reduced better
preserved depends, course, context. instance, context formal
verification, abstract transition graphs required decrease reachability
states; is, path s0 original transition graph,
path (s) (s0 ) abstract transition graph (Clarke,
Grumberg, & Peled, 1999). addition, reachability also increased little
possible. Beyond that, precise relationship path costs original
abstract transition graphs secondary importance. contrast, abstractions
designed induce admissible heuristic functions heuristic search, relationship
path costs captured Eq. 1 must obeyed. However, requirements
beyond general requirement Eq. 1 overestimate distances
56

fiImplicit Abstraction Heuristics

states unnecessary. Hence, particular, Definition 2 generalizes notion
abstraction Helmert et al. (2007) replacing condition preserving individual
transitions labels, is, ((s), l, (s0 )) (s, l, s0 ), weaker condition stated
Eq. 1. reader, course, may well ask whether generality condition
Eq. 1 beyond condition Helmert et al. (2007) really delivers practical gain,
later show answer question affirmative. now, proceed
adding requirements essential making abstraction usable basis heuristic
functions.
Definition 3 Let planning task states S, let {hTi , i}m
i=1 additive
abstraction transition graph T(). = O(poly(||||)) and, states
1P
m, cost cost(i (s), Si? ) Ti computable time O(poly(||||)),
?
hA (s) =
i=1 cost(i (s), Si ) abstraction heuristic function .
Note admissibility hA implied cost conservation condition Eq. 1. illustrate connection abstractions admissible heuristics, consider three
well-known mechanisms devising admissible planning heuristics: delete relaxation (Bonet
& Geffner, 2001), critical-path relaxation (Haslum & Geffner, 2000),2 pattern database
heuristics (Edelkamp, 2001).
First, typically considered way, delete relaxation planning task
? , $ ),
= hV, A, I, G, costi correspond abstraction hT+ = (S+ , L+ , Tr+ , s0+ , S+
+
+
transition
graph
T().
Assuming
unique
naming


variable
values



deS
noting D+ = vV D(v), abstract states S+ power-set D+ ,
labels L+ = {a, a+ | A}. transitions come two sources: abstract state
s+ S+ original action applicable s+ , (s+ , a, s+ JaK) Tr+
(s+ , a+ , s+ eff(a)) Tr+ . minor abuse notation, initial state
? = {s | G}, abstraction
goal states abstraction s0+ = S+
+
+
+
mapping + simply identity function. easy show that, state
? ) = h+ (s), h+ (s) delete-relaxation
planning task , cost(+ (s), S+
estimate cost goal. aside, note delete-relaxation
abstraction hT+ , + particular exemplifies nothing Definition 2 requires
size abstract state space limited size original state space.
event, however, abstraction hT+ , + induce heuristic terms Definition 3
computing h+ (s) known NP-hard (Bylander, 1994).
situation critical-path relaxation exactly opposite. computing
corresponding family admissible estimates hm polynomial-time fixed m,
computation based computing shortest paths abstraction
planning task. state graph hm computed AND/OR-graph (and
OR-graph transition graphs), actual computation hm corresponds
computing critical tree (and shortest path) goal. best
knowledge, precise relation critical path abstraction heuristics currently
open question (Helmert & Domshlak, 2009).
Overall, abstraction heuristics toolbox planning days appear
explicit homomorphism abstractions, whose best-known representative probably
2. assume reader familiar two relaxations. not, discussion safely
skipped.

57

fiKatz & Domshlak

pattern database (PDB) heuristics. Given planning task state variables V ,
PDB heuristic based projecting onto subset variables V V .
homomorphism abstraction maps two states s1 , s2 abstract state iff
s1 [V ] = s2 [V ]. Inspired (similarly named) domain-specific heuristics search
problems (n2 1)-puzzles Rubiks Cube (Culberson & Schaeffer, 1998; Hernadvolgyi & Holte, 1999; Felner et al., 2004), PDB heuristics successfully exploited domain-independent planning well (Edelkamp, 2001, 2002; Haslum et al.,
2007). key decision constructing PDBs sets variables problem
projected (Edelkamp, 2006; Haslum et al., 2007). However, apart need
automatically select good projections, two limitations PDB heuristics size
abstract space dimensionality. First, number abstract states
small enough allow reachability analysis exhaustive search. Moreover,
O(1) bound |S | typically set explicitly fit time memory limitations
system. Second, since PDB abstractions projections, explicit constraint |S |
implies fixed-dimensionality constraint |V | = O(1). planning tasks with, informally,
many alternative resources, limitation pitfall. instance, suppose {i }
i=1
sequence Logistics problems growing size |Vi | = i. package
transported (i) vehicles, starting i, h account
movements vehicles essential solving (Helmert & Mattmuller, 2008).
Aiming preserving attractiveness PDB heuristic eliminating bottleneck fixed dimensionality, Helmert et al. (2007) generalized methodology
Drager, Finkbeiner, Podelski (2006) introduced called merge-and-shrink
(MS) abstractions planning. MS abstractions homomorphisms generalize PDB
abstractions allowing flexibility selection pairs states contracted.
problems state space viewed synchronized product projections onto
single state variables. Starting atomic abstractions, product
computed iteratively composing two abstract spaces, replacing product.
PDB size abstract space controlled limiting number
product compositions, MS abstractions controlled interleaving iterative composition projections abstraction partial composites. Helmert et al. (2007)
proposed concrete strategy interleaved abstraction/refinement scheme empirically demonstrated power merge-and-shrink abstraction heuristics. Like PDBs,
however, MS abstractions explicit abstractions, thus computing heuristic values also based explicitly searching optimal plans abstract spaces. Hence,
merge-and-shrink abstractions escape fixed-dimensionality constraint PDBs,
constraint abstract space fixed size still holds.

4. Implicit Abstractions
Focusing O(1) bound posted explicit abstractions size abstract
space, first observation explicit abstractions necessarily way
proceed abstraction heuristics. Given planning task states S, suppose
transform different planning task
1. transformation induces abstraction mapping : state
space ,
58

fiImplicit Abstraction Heuristics

2. transformation , well computing state S,
done time polynomial ||||.
planning-task-to-planning-task transformations mind, define
call (additive) implicit abstractions.
Definition 4 additive implicit abstraction planning task set pairs


= {hi , i}m
i=1 {i }i=1 planning tasks {hT(i ), i}i=1
additive abstraction T().
Let us examine notion implicit abstractions closely. First, implicit
abstractions allow natural additive combination admissible heuristics abstract
tasks. composition formulated Theorem 1, extending original criterion
admissibility additive heuristics described Section 2. Second, formulated
Theorem 2, implicit abstractions composed via functional composition
abstraction mappings. two easy-to-prove properties implicit abstractions allow us
take desired step implicit abstractions implicit abstraction heuristics.
Theorem 1 (Admissibility) Let planning task = {hi , i}m
i=1 additive implicit abstraction
.
If,


1



m,
h


admissible
heuristic
,

Pm
function h(s) = i=1 hi (i (s)) admissible heuristic .
Proof: proof straightforward. Let = (S, L, Tr, s0 , ? , $) transition graph
, let state S. 1 m, let Ti = (Si , Li , Tri , s0i , Si? , $i )
transition graph .
First, hi admissible heuristic , si Si? ,
hi (i (s)) cost(i (s), si ).
Now, state s0 ? , Definition 2 (s0 ) Si? , Eq. 1

X
i=1

thus
h(s) =


X
i=1

cost(i (s), (s0 )) cost(s, s0 ),

hi (i (s))

giving us admissible estimate


X

i=1

h (s).

cost(i (s), (s0 )) cost(s, s0 ),


Theorem 2 (Composition) Let planning task = {hi , i}m
i=1 addimi
tive implicit abstraction . If,
i,j , i,j i}j=1 additive
1 m, Ai = m{h

implicit abstraction , A0 =
{h
,



i}

additive implicit abi,j
i,j
j=1
i=1
straction .
Proof: Let = (S, L, Tr, s0 , ? , $) transition graph . 1 m,
let Ti = (Si , Li , Tri , s0i , Si? , $i ) transition graph , 1 j mi , let
? , $ ) transition graph . need show
Ti,j = (Si,j , Li,j , Tri,j , s0i,j , Si,j
i,j
i,j
i,j abstraction mapping Definition 2. i,j abstraction
mappings,
59

fiKatz & Domshlak

s0i,j = i,j (s0i ) = i,j (i (s0 )) = i,j (s0 ),
? ,
? (s) Si? thus i,j (i (s)) = i,j (s) Si,j
P
0
0
si , s0i Si , cost(si , s0i )
j=1 cost(i,j (si ), i,j (si )), thus s, S,

cost(s, s0 )


X
i=1

cost(i (s), (s0 ))
=

mi
X
X
i=1 j=1
mi
X
X
i=1 j=1

cost(i,j (i (s)), i,j (i (s0 )))
cost(i,j (s), i,j (s0 )).


Together, Theorems 1 2 suggest following scheme deriving abstraction heuristics. Given additive implicit abstraction = {hi , i}m
i=1 , individual abstract
tasks belong tractable fragments optimal planning, use practice
(sum the) true costs admissible estimates costs . Otherwise, optimal planning abstract tasks cannot proven polynomial-time
solvable, abstract tasks, obtaining admissible estimates
true costs .
Definition 5 Let planning task states S, let = {hi , i}m
i=1
additive implicit abstraction . = O(poly(||||)), and, allP
states

1 m, h (i (s)) polynomial-time computable, hA (s) =
i=1 h (i (s))
implicit abstraction heuristic function .
Compared explicit abstraction heuristics PDB heuristics merge-andshrink heuristics, direction implicit abstraction heuristics is, least principle,
appealing neither dimensionality even size state spaces induced
implicit abstractions required bounded something restrictive, all.
pitfall, however, implicit abstraction heuristics correspond tractable fragments
optimal planning, palette known fragments extremely limited (Backstrom
& Nebel, 1995; Bylander, 1994; Jonsson & Backstrom, 1998; Jonsson, 2007; Katz & Domshlak, 2007b). fact, none far appeared us convenient automatically devising useful problem transformations above. Fortunately, show next boundaries
tractability expanded right way, allowing us successfully materialize
idea implicit abstraction heuristics.
following, key role played causal graphs induced planning
tasks. Informally, basic idea behind call causal-graph decompositions
abstract given planning task along subgraph causal graph, goal
obtaining abstract problems specific structure. Naturally, numerous possibilities
obtaining structure-oriented abstractions. present one decomposition
tailored abstractions around acyclic subgraphs. Informally, decomposition
seen sequential application two kinds task transformations: dropping
preconditions (Pearl, 1984) (certain form of) breaking actions conjunctive effects
single-effect actions.
60

fiImplicit Abstraction Heuristics

Definition 6 Let = hV, A, I, G, costi planning task, let G = (VG , EG )
acyclic subgraph causal graph CG(). planning task G = hVG , AG , IG , GG , costG
acyclic causal-graph decomposition respect G
1. IG = I[VG ], GG = G[VG ],

2. AG = aA AG (a) AG (a) = {a1 , . . . , al(a) } set actions VG
that, topological respect G ordering variables {v1 , . . . , vl(a) } =
V(eff(a)) VG , 1 l(a),
(
eff(a)[v],
v = vi

eff(a )[v] =
unspecified, otherwise

(2)

(v, vi ) EG v 6 V(eff(a)) v = vi
pre(a)[v],
pre(ai )[v] = eff(a)[v],
(v, vi ) EG v V(eff(a))


unspecified, otherwise
3. action A,

X
a0 AG (a)

costG (a0 ) cost(a).

(3)

hard verify Definition 6 planning task acyclic
causal-graph decomposition G , causal graph CG(G ) exactly subgraph G underlying decomposition. illustrate notion acyclic causal-graph decomposition,
consider planning task = hV, A, I, G, costi five state variables V = {u, v, x, y, z},
two unit-cost actions = {a1 , a2 } Figure 2a, initial state = {u : 0, v : 0, x : 0, : 0, z : 0},
goal G = {u : 1, v : 1, x : 0, : 1, z : 1}. causal graph CG() depicted Figure 2a.
Figures 2b-c show two subgraphs G1 G2 CG(), respectively, well action sets AG1 (a1 ) = {a11 , a21 , a31 } AG1 (a2 ) = {a12 , a22 , a32 } Figure 2(b), action
sets AG2 (a1 ) = {a11 , a21 , a31 } AG2 (a2 ) = {a12 , a22 , a32 } Figure 2(c). {1, 2}, let
= hV, Ai , I, G, costi planning task Ai = AGi (a1 )AGi (a2 ) costi (a) = 1/3
Ai . two planning tasks (individually) satisfy conditions Definition 6 respect Gi , thus acyclic causal-graph decompositions
respect Gi .
proceed specifying implicit abstractions defined via acyclic causal-graph
decompositions.
Definition 7 Let = hV, A, I, G, costi planning task states S, let G = {Gi =

(VGi , EGi )}m
i=1 set acyclic subgraphs causal graph CG(). = {hGi , i}i=1
acyclic causal-graph abstraction G if, set cost functions
{costi : R0+ }m
i=1 satisfying
:


X
i=1

costi (a) cost(a),

have, 1 m,
61

(4)

fiKatz & Domshlak

a1 = h{x : 0, : 0, z : 0}, {x : 1, : 1, z : 1}i

a11 = h{x : 0}, {x : 1}i
a21 = h{x : 1, : 0}, {y : 1}i
a31 = h{x : 1, z : 0}, {z : 1}i

a11 = h{y : 0}, {y : 1}i
a21 = h{z : 0}, {z : 1}i
a31 = h{y : 1, z : 1, x : 0}, {x : 1}i

a2 = h{u : 0, v : 0, x : 1}, {u : 1, v : 1, x : 0}i

a12 = h{x : 1}, {x : 0}i
a22 = h{x : 0, u : 0}, {u : 1}i
a32 = h{x : 0, v : 0}, {v : 1}i

a12 = h{u : 0}, {u : 1}i
a22 = h{v : 0}, {v : 1}i
a32 = h{u : 1, v : 1, x : 1}, {x : 0}i

u

a1

a2

x

a2
a2



x
a1

a22

a1

v

z

u

a31

a32 a21



v

(a)

u

(b)

a32

z



v
a32

a31

z
a31

x
(c)

Figure 2: (a) actions causal graph CG() planning graph example
illustrating Definition 2. (b) Subgraph G1 CG() induced action sets
AG1 (a1 ) AG1 (a2 ). (c) Subgraph G2 CG() induced action sets
AG2 (a1 ) AG2 (a2 ). arcs CG() subgraphs G1 G2
labeled actions inducing arcs.

Gi = hVGi , AGi , IGi , GGi , costGi acyclic causal-graph decomposition =
hV, A, I, G, costi respect Gi ,
abstraction mapping : Si projection mapping (s) = s[VGi ].
Theorem 3 Acyclic causal-graph abstractions planning tasks additive implicit
abstractions tasks.
Proof: Let = hV, A, I, G, costi planning task, let = {hGi , i}m
i=1
acyclic causal-graph abstraction set subgraphs G = {Gi = (VGi , EGi )}m
i=1 .
Let = (S, L, Tr, s0 , ? , $) transition graph , and, 1 m, Ti =
(Si , Li , Tri , s0i , Si? , $i ) transition graph Gi . need show abstraction mapping Definition 2.
First, Definitions 6 7,
s0i = IGi = I[VGi ] = s0 [VGi ] = (s0 ),
? G thus (s) = s[VGi ] G[VGi ] = GGi , providing us
(s) Si? .
Now, state action pre(a) s, (s) state Gi
pre(a)[VGi ] (s). Let action sequence = ha1 , a2 , . . . , al(a) constructed
Eq. 2. inductively prove applicable (s). First, v VGi ,
either pre(a1 )[v] = pre(a)[v], pre(a1 )[v] unspecified, thus 1 = ha1 applicable
(s). inductive hypothesis j = ha1 , a2 , . . . , aj applicable (s),
0
let s0 = (s)Jj K. Eq. 2, 1 j 0 j, aj changes value vj 0 eff(a)[vj 0 ],
62

fiImplicit Abstraction Heuristics

change vj 0 along j . Likewise, since actions constructed
Eq. 2 unary-effect, {v1 , . . . , vj } variables VGi affected along j . Hence,
v VGi , v = vj 0 , 1 j 0 j, s0 [v] = eff(a)[v] = pre(aj+1 )[v], otherwise,
s0 [v] = (s)[v], pre(aj+1 )[v] specified, pre(aj+1 )[v] = pre(a)[v] = (s)[v].
implies aj+1 applicable s0 and, result, j+1 = ha1 , a2 , . . . , aj+1 applicable
(s), finalizing inductive proof. Likewise, exactly arguments affect
l(a)
{aj }j=1 (s) immediately imply that, = ha1 , a2 , . . . , al(a) i, (sJaK) = (s)JK.
Next, A, Eqs. 3 4

X

X

i=1 a0 AGi (a)

costGi (a0 )


X
i=1

costi (a) cost(a).

(5)

Now, let s, s0 pair original states cost(s, s0 ) < , let % =
0
ha1 , . . . , ak sequence
Pk labels along cheapest path T. that,
0
cost(s, ) = cost(%) = j=1 cost(aj ). decomposition path sequences
actions Eq. 2 aP(not P
neccesarily cheapest) path (s) (s0 ) Ti ,
k
0
thus cost(i (s), (s )) j=1 a0 AG (aj ) costGi (a0 ), providing us



X
i=1

0

cost(i (s), (s ))
(5)



X
k
X

X

0

costGi (a ) =

i=1 j=1 a0 AGi (aj )
k
X

k X

X

X

costGi (a0 )

j=1 i=1 a0 AGi (aj )

cost(aj ) = cost(s, s0 ).

j=1


Thus, decompose given task set tractable acyclic causalgraph decompositions = {G1 , . . . , Gm }, solve tasks polynomial
time, derive additive admissible heuristic . proceed considering
concrete acyclic causal-graph decomposition, note Definition 2 leaves decision
actual partition action costs rather open. follows adopt
straightforward, uniform action cost partition theScost action equally
split among non-redundant representatives
i=1 AGi (a). However, better
choice action cost partition sometimes made. fact, sometimes even
optimized (Katz & Domshlak, 2010)

5. Fork Decompositions
proceed introducing two concrete acyclic causal-graph decompositions that,
combined certain variable domain abstractions, provide us implicit abstraction heuristics. called fork-decomposition heuristics based two novel
fragments tractable cost-optimal planning tasks fork inverted-fork structured
causal graphs.
Definition 8 planning task variables V , variable v V ,
63

fiKatz & Domshlak

(1) v-fork subgraph Gvf CG() nodes VGvf = {v} succ(v) edges
EGvf = {(v, u) | u succ(v)},
(2) v-ifork (short inverted fork) subgraph Gvi CG() nodes VGvi =
{v} pred(v) edges EGvi = {(u, v) | u pred(v)}.
sets v-forks v-iforks denoted GF = {Gvf }vV GI =
{Gvi }vV , respectively.
planning task state variables v, v-fork v-ifork
acyclic digraphs, allowing us define three implicit abstractions follows.
Definition 9 planning task = hV, A, I, G, costi,

(1) acyclic causal-graph abstraction AF = {hfv , vf i}vV GF called
F-abstraction, set abstract planning tasks F = {fv }vV called
F-decomposition ;
(2) acyclic causal-graph abstraction AI = {hiv , vi i}vV GI called
I-abstraction, set abstract planning tasks = {iv }vV called
I-decomposition ;
(3) acyclic causal-graph abstraction AFI = {hfv , vf i, hiv , vi i}vV
GFI = GF GI called FI-abstraction, set abstract planning tasks
FI = {fv , iv }vV called FI-decomposition .

Definition 9 better understood considering FI-abstraction problem
Logistics example; Figure 3 schematically illustrates process. simplify
example, eliminate GFI single-node subgraphs, obtaining
AFI = {hfc1 , cf 1 i, {hfc2 , cf 2 i, {hfc3 , cf 3 i, {hft , tf i, {hip1 , pi 1 i, {hip2 , pi 2 i}.
Considering action sets problems FI = {fc1 , fc2 , fc3 , ft , ip1 , ip2 }, see
original driving action one nonredundant (that is, changing variable)
representative three abstract planning tasks, load/unload action
one nonredundant representative five tasks. instance, action drive-c1 from-A-to-D one nonredundant representative tasks {fc1 , ip1 , ip2 },
action load-p1 -into-c1 -at-A one nonredundant representative tasks
{fc1 , fc2 , fc3 , ft , ip1 }. Since assume uniform partition action costs, cost
driving load/unload action relevant abstract planning task thus set
1/3 1/5, respectively. Theorem 3 AFI additive implicit
abstraction , Theorem 1

X
hFI =
hf + hi ,
(6)
v

v

vV

admissible estimate h . question good estimate is.
optimal cost solving running example 19. Taking reference well-known
admissible heuristics hmax (Bonet & Geffner, 2001) h2 (Haslum & Geffner, 2000),
hmax (I) = 8 h2 (I) = 13. Considering FI-abstraction, optimal plans
tasks FI follows.
64

fiImplicit Abstraction Heuristics

fc1 : load-p1 -into-c2 -at-C, unload-p1 -from-c2 -at-D, load-p1 -into-t-at-D,
unload-p1 -from-t-at-E, load-p1 -into-c3 -at-E, unload-p1 -from-c3 -at-G,
load-p2 -into-c3 -at-F, unload-p2 -from-c3 -at-E.
fc2 : load-p1 -into-c1 -at-C, unload-p1 -from-c1 -at-D, load-p1 -into-t-at-D,
unload-p1 -from-t-at-E, load-p1 -into-c3 -at-E, unload-p1 -from-c3 -at-G,
load-p2 -into-c3 -at-F, unload-p2 -from-c3 -at-E.
fc3 : load-p1 -into-c1 -at-C, unload-p1 -from-c1 -at-D, load-p1 -into-t-at-D,
unload-p1 -from-t-at-E, drive-c3 -from-G-to-E, load-p1 -into-c3 -at-E,
drive-c3 -from-E-to-G, unload-p1 -from-c3 -at-G, drive-c3 -from-G-to-E,
drive-c3 -from-E-to-F, load-p2 -into-c3 -at-F, drive-c3 -from-F-to-E,
unload-p2 -from-c3 -at-E, drive-c3 -from-E-to-F.
ft : load-p1 -into-c1 -at-C, unload-p1 -from-c1 -at-D, drive-t-from-E-to-D,
load-p1 -into-t-at-D, drive-t-from-D-to-E, unload-p1 -from-t-at-E,
load-p1 -into-c3 -at-E, unload-p1 -from-c3 -at-G, load-p2 -into-c3 -at-F,
unload-p2 -from-c3 -at-E.
ip1 : drive-c1 -from-A-to-D, drive-c1 -from-D-to-C, load-p1 -into-c1 -at-C,
drive-c1 -from-C-to-D, unload-p1 -from-c1 -at-D, drive-t-from-E-to-D,
load-p1 -into-t-at-D, drive-t-from-D-to-E, unload-p1 -from-t-at-E,
drive-c3 -from-G-to-E, load-p1 -into-c3 -at-E, drive-c3 -from-E-to-G,
unload-p1 -from-c3 -at-G, drive-c3 -from-G-to-E, drive-c3 -from-E-to-F.
ip2 : drive-c3 -from-G-to-E, drive-c3 -from-E-to-F, load-p2 -into-c3 -at-F,
drive-c3 -from-F-to-E, unload-p2 -from-c3 -at-E, drive-c3 -from-E-to-F.
Hence,
hFI = hf

c1

=

8
5

+ hf

+

8
5

+

c2

+

hf
8
5

c3

+

6
3

hf

+
+

8
5



+

2
3

+

hi

+

6
5

p1

+

9
3

+

hf

+

2
5

p2

+

4
3

= 15,

(7)

hFI appears least promising.
Unfortunately, despite seeming simplicity planning tasks FI , turns
implicit fork-decomposition abstractions Definitions 9 fit requirements
implicit abstraction heuristics Definition 5. causal graphs planning
tasks F form directed forks directed inverted forks, respectively, and,
general, number variables planning task large (|V |).
problem even satisficing planning sas+ fragments fork inverted
fork causal graphs NP-complete (Domshlak & Dinitz, 2001). fact, recent results
Chen Gimenez (2008) show planning sas+ fragment characterized
nontrivial form causal graph NP-hard. Moreover, even domain transition graphs
state variables strongly connected (as example), optimal planning
fork inverted fork structured problems remain NP-hard (see Helmert 2003, 2004
respective results). Next, however, show end story
fork decompositions.
65

fiKatz & Domshlak



B

c1

p2

c2

CG()

F
c!





p!

G

p1

c#



E
c3

C

c"

p"

{fv , iv }vV
fc1

c!

p!

c!

p"

c"

c#



ip1

p!

CG(
CG(p1ip1))

CG(fcfc11))
CG(

Figure 3: Schematic illustration FI-decomposition running Logistics example
hardness optimal planning problems fork inverted fork causal
graphs casts shadow relevance fork decompositions, closer look proofs
corresponding hardness results Domshlak Dinitz (2001) Helmert (2003, 2004)
reveals particular rely root variables large domains. Exploiting
observation, show reliance incidental characterize two substantial
islands tractability within structural fragments sas+ .
Theorem 4 (Tractable Forks) Given planning task = hV, A, I, G, costi fork
causal graph rooted r V , |D(r)| = 2, time complexity cost-optimal planning
polynomial ||||.
Proof: Observe that, planning task theorem, fork structure
causal graph CG() implies actions unary-effect, leaf variable
v succ(r) preconditions actions affecting v itself. algorithm based
following three properties satisfied optimal plans .
(i) leaf variable v succ(r), path v I[v] G[v] induced
DTG(v, ) either cycle-free contains zero-cost cycles. case
otherwise nonzero-cost cycles eliminated v preserving
validity, violating assumed optimality . Without loss generality,
follows assume path v DTG(v, ) cycle-free; case fork
causal graphs, always select optimal satisfies requirement
v succ(r). Thus, |v | |D(v)| 1.
(ii) fixed sequence value changes r, forks leaves become mutually
independent; is, ability change value one affect
ability change value others.
66

fiImplicit Abstraction Heuristics

(iii) r binary-valued, v V \ {r} demanding leaf variable
terms number value changes required r action preconditions
along v , value changes r along , except for, possibly,
final value change G[r]. Thus, particular, |r | maxvsucc(r) |D(v)|.
begin introducing auxiliary notations. |D(r)| = 2, let D(r) = {0, 1}
I[r] = 0. Let (r) alternating 0/1 sequence starting 0, 0
odd 1 even positions. sequence (r) |(r)| = 1 action
change rs value 1, |(r)| = 2 action change rs value 1
action restore value 0, otherwise, |(r)| = 1 + maxvsucc(r) |D(v)|. Let
[(r)] set nonempty prefixes (r) G[r] unspecified; otherwise, let
set nonempty prefixes (r) ending G[r]. Note that, [(r)] = ,
problem trivially unsolvable; follows assume case.
v succ(r), let DT G0v DT G1v subgraphs domain transition graphs
DTG(v, ), obtained removing DTG(v, ) arcs labeled r : 1 r : 0,
respectively.
algorithm incrementally constructs set R valid plans , starting
R = .
(1) v succ(r), pair vs values x, D(v), compute cheapest
(that is, cost-minimal) paths v0 (x, y) v1 (x, y) x DT G0v DT G1v ,
respectively. pairs values x, y, one even paths may, course,
exist.
(2) sequence [(r)], v succ(r), construct layered digraph Lv ()
|| + 1 node layers L0 , . . . , L|| , L0 consists I[v], 1 ||,
[i]

Li consists nodes D(v) path v (x, y) node x Li1
constructed step (1). x Li1 , Li , Lv () contains arc
[i]
(x, y) weighted cost(v (x, y)).

(3) [(r)], let k = ||. candidate plan constructed follows.

(a) v succ(r), find cost-minimal path I[v] G[v] Lv ().
path exists, proceed next prefix [(r)]. Otherwise, note
i-th edge path (taking us x Li1 Li ) corresponds
[i]
cost-minimal path v (x, y) x y. Let us denote path x
Svi .

(b) Set R = R{ }, = 1 a[2] 2 . . .a[k] k , sequence obtained
arbitrary merge sequences {Svi }vsucc(r) , cheapest action
changing value r value .
(4) R = , fail, otherwise return = argmin R cost( ).
straightforward verify complexity procedure polynomial
description size . prove correctness, show procedure returns
plan solvable task , returned plan 0 satisfies cost(0 ) cost()
optimal plan .
67

fiKatz & Domshlak

Given solvable task , let optimal plan v leaf variables
v cycle-free. Let r = ha2 . . . , ak i; numbering actions along r starts
a2 simplify indexing later on. v succ(r), actions r divide v
subsequences v-changing actions v = 1v . . . kv , separated value changes
required r. is, 1 k, actions iv preconditioned
value r, any, two actions iv a0 i+1
preconditioned r,
v
pre(a)[r] 6= pre(a0 )[r]. Let [(r)] value sequence || = k = |r | + 1.
v succ(r), v path I[v] G[v] Lv (), therefore added
R algorithm, meaning algorithm finds solution. Now, R,
then, v succ(r), let Sv1 Sv2 . . . Svk cost-minimal path I[v] G[v]
Lv () Svi sequence actions changing value v preconditioned
either r : 0 nothing odd i, r : 1 nothing even i. Thus,
cost(Sv1 Sv2 . . . Svk ) =

k
X
i=1

cost(Svi ) cost(v ).

sequence obtained arbitrary merge sequences {Svi }vsucc(r) ,
cheapest action changing value r , = 1 a[2] 2 . . . a[k] k
applicable sequence actions achieves goal values v succ(r)
well r,
cost( ) = cost(S 1 a[2] 2 . . . a[k] k ) =

k
X

cost(a[i] ) +

i=2

cost(r ) +

k
X
i=1

X

cost(S )

cost(v ) = cost().

vsucc(r)

Hence, solvable, algorithm returns plan , plan must
optimal. Finally, solvable, R necessarily remains empty, thus
algorithm fails.

Theorem 4 concerns tractability tasks fork-structured causal graphs
roots binary domains, earlier work also reported additional tractability
result fork-structured causal graphs domains variables fixed
size, though necessarily binary-valued (Katz & Domshlak, 2008). discuss
result detail because, least far, found helpful
context devising effective abstraction heuristics.
Theorem 5 (Tractable Inverted Forks) Given planning task = hV, A, I, G, costi
inverted fork causal graph sink r V , |D(r)| = O(1), time complexity
cost-optimal planning polynomial ||||.
Proof: Let |D(r)| = d. Observe inverted-fork structure causal graph CG()
implies actions unary-effect, sink r preconditions
actions affecting r itself. Hence, follows assume G[r] specified; otherwise
68

fiImplicit Abstraction Heuristics

Given path ha1 , . . . , I[r] G[r] DTG(r, ):
:= hi
am+1 := hG[pred(r)],
foreach v pred(r) xv := I[v]
:= 1 + 1
foreach v pred(r)
pre(ai )[v] specified pre(ai )[v] 6= xv
pre(ai )[v] reachable xv DTG(v, ) fail
append actions induced cost-minimal path
pre(ai )[v] xv DTG(v, )
xv := pre(ai )[v]
< + 1 append action ai
return
Figure 4: Detailed outline step (3) planning algorithm inverted-fork structured
task.

breaks set trivial planning problems single variable each. Likewise,
properties follows that, optimal plan , path
r I[r] G[r] induced DTG(r, ) either cycle-free contains zerocost cycles. latter safely eliminated , thus assume r
cycle-free. Given that, simple algorithm finds cost-optimal plan time
(||||d + ||||3 ) follows.
(1) Create (|Ar |d1 ) cycle-free paths I[r] G[r] DTG(r, ).
(2) variable v pred(r), pair vs values x, D(v), compute
cost-minimal path x DTG(v, ). whole set cost-minimal paths
computed using (d|V |) applications Floyd-Warshall algorithm
domain transition graphs sinks parents pred(r).
(3) I[r]-to-G[r] path DTG(r, ) generated step (1), construct plan
based path r, cheapest paths computed (2). simple
construction, depicted Figure 4, possible values parent variable
changed independently values variables inverted fork.
(4) Take cheapest plan among constructed (3). plan constructed
step (3), unsolvable.
already observed that, cost-optimal plan , r one I[r]-to-G[r]
paths generated step (1). v pred(r), let Sv denote sequence values
D(v) required preconditions actions along r . v pred(r),
v corresponding (possibly cyclic) path I[v] G[v] DTG(v, ), traversing
values (= nodes) Sv order required Sv . turn, plan generated
(3) consists cost-minimal paths v pred(r). Therefore, least one
69

fiKatz & Domshlak

plans generated (3) must cost-optimal , minimization step (4) select
one them.

Theorems 4 5 clarify gap fork decompositions implicit abstraction
heuristics, bridge gap abstracting task given fork
decomposition . abstracting domains fork roots inverted-fork
sinks meet requirements tractable fragments. note that, itself, idea
domain decomposition new general (Hernadvolgyi & Holte, 1999)
domain-independent planning particular (Domshlak, Hoffmann, & Sabharwal, 2009).
fact, shrinking step algorithm building merge-and-shrink abstractions
precisely variable domain abstraction meta-variables constructed merging
steps (Helmert et al., 2007).
Definition 10 Let = hV, A, I, G, costi planning task states S, v V state
variable, = {1 , . . . , } set mappings D(v) sets 1 , . . . , ,
respectively. = {hi , i}m
i=1 domain abstraction if, set
cost functions {costi : R0+ }m
i=1 satisfying
:


X
i=1

costi (a) cost(a),

(8)

have, 1 m,
abstraction mapping states
u V :

(
(s[u]),
(s)[u] =
s[u],

u=v
,
u 6= v

and, extending partial assignments V 0 V (s[V 0 ]) = (s)[V 0 ],
= hV, Ai , Ii , Gi , costi planning task
1. Ii = (I), Gi = (G),
2. Ai = {ai = hi (pre(a)), (eff(a))i | A},

3. action A,

costi (ai ) = costi (a).

(9)

say domain decomposition = hV, A, I, G, costi respect .
Theorem 6 Domain abstractions planning tasks additive implicit abstractions
tasks.
Proof: Let = hV, A, I, G, costi planning task = {hi , i}m
i=1 domain
abstraction = {1 , . . . , }. Let = (S, L, Tr, s0 , ? , $) transition
graph . 1 m, let Ti = (Si , Li , Tri , s0i , Si? , $i ) transition graph
. need show abstraction mapping Definition 2.
First, Definition 10
70

fiImplicit Abstraction Heuristics

s0i = Ii = (I) = (s0 ),
? G thus (s) (G) = Gi , providing us
(s) Si? .
Now, state action pre(a) s, (s) state
pre(ai ) = (pre(a)) (s). Thus, ai applicable (s), show
applying ai (s) results (s)Jai K = (sJaK).
1. effect variables v V(eff(a)) = V(eff(ai )), eff(ai ) (s)Jai K
eff(ai ) = (eff(a)) (sJaK).
2. variables v 6 V(eff(a)), sJaK[v] = s[v] (s)Jai K[v] =
(s)[v], thus
(s)Jai K[v] = (s)[v] = (s[v]) = (sJaK[v]) = (sJaK)[v].
Next, A, Eqs. 8 9

X

costi (ai ) =

i=1


X
i=1

costi (a) cost(a).

(10)

Now, let s, s0 pair states cost(s, s0 ) , let % = ha1 , . . . , al
sequence
labels along cheapest path s0 T. that, cost(s, s0 ) = cost(%) =
Pl
j
j=1 cost(a ). decomposition path actions Definition 10
(not
cheapest) path (s) (s0 ) Ti , thus cost(i (s), (s0 ))
Pl neccesarily
j
j=1 costi (a ), providing us

X
i=1

cost(i (s), (s0 ))

X
l
X
i=1 j=1

costi (aji ) =

l X

X
j=1 i=1

(10)

costi (aji )

l
X

cost(aj ) = cost(s, s0 ).

j=1


put notion domain abstraction framework implicit abstractions,
ready connect fork decompositions implicit abstraction heuristics. Given
FI-abstraction AFI = {hfv , vf i, hiv , vi i}vV planning task = hV, A, I, G, costi,
fv FI , associate root v CG(fv ) mappings fv = {fv,1 , . . . , fv,kv }
kv = O(poly(||||)) fv,i : D(v) {0, 1}, abstract fv
f i}kv ,
Afv = {hfv,i , v,i
i=1
iv FI , associate sink v CG(iv ) mappings iv = {iv,1 , . . . , iv,kv0 }
kv0 = O(poly(||||)) iv,i : D(v) {0, 1, . . . , bv,i }, bv,i = O(1),
k0

i} v .
abstract iv Aiv = {hiv,i , v,i
i=1

71

fiKatz & Domshlak

Theorem 3, Theorem 6, composition Theorem 2, immediately


kv0
kv
[ [
[
f

{hfv,i , v,i
AFI =
vf i} {hiv,i , v,i
vi i}
(11)
vV

i=1

i=1

additive implicit abstraction . Hence, Theorem 1,


kv0
kv
X X
X

hFI =
hi
hf +
vV

v,i

i=1

i=1

v,i

(12)

admissible estimate h , and, Theorems 4 5, hFI also computable
time O(poly(||||)).
finalizes construction concrete family implicit abstraction heuristics.
illustrate mixture acyclic causal-graph domain abstractions above,
use running Logistics example. One bothersome question extent
abstracting fork decompositions using domain abstractions affects informativeness
heuristic estimate. Though generally degradation unavoidable, show
answer question sometimes somewhat surprising.
begin extreme setting, let domain abstractions roots forks
sinks inverted forks binary-valued domains. Among multiple options choosing mapping sets {fv } {iv }, use simple choice distinguishing different values variable v basis cost I[v] DTG(v, ).
Specifically, v V , set fv = iv , and, value D(v)
1 max0 D(v) d(I[v], 0 ),
(
0, d(I[v], ) <
fv,i () = iv,i () =
(13)
1, otherwise
example, problem fc1 decomposed (see domain transition graph c1
left Figure 1c) two problems, fc1 ,1 fc1 ,2 , binary abstract
domains c1 corresponding partitions {{A}, {B, C, D}} {{A, D}, {B, C}}
D(c1 ), respectively. yet another example, problem ip1 decomposed (see
domain transition graph p1 Figure 1d) six problems ip1 ,1 , . . . , ip1 ,6 along
abstractions D(p1 ) depicted Figure 5a. Now, given FI-decomposition
mappings {fv , iv }vV above, consider problem ip1 ,1 , obtained abstracting
along inverted fork p1 abstracting D(p1 ) using
(
0, {C}
ip1 ,1 () =
.
1, {A, B, D, E, F, G, c1 , c2 , c3 , t}
hard verify that, original actions affecting p1 , left ip1 ,1
actions conditioned c1 c2 . so, information lost3 remove
ip1 ,1 variables c3 t, well actions changing (only) variables,
3. information lost still keep either fork inverted fork variable .

72

fiImplicit Abstraction Heuristics



c



B

C



E

c

F

G

c

(a)


c



B

C





c

E

c

F

G



c

B

C



E

c

D(p1 ) fp1 ,1



c

F



G

B

C



E

c

c

D(p1 ) fp1 ,2

F

G

c

D(p1 ) fp1 ,3

(b)
Figure 5: Domain abstractions D(p1 ). (a) Binary-valued domain abstractions: values inside outside dashed contour mapped 0 1, respectively.
(b) Ternary-valued domain abstractions: values mapped
abstract value shown nodes color borderline.

redistribute cost removed actions representatives
originals . latter revision action cost partition obtained directly
replacing cost-partitioning steps corresponding Eqs. 3-4 8-9 single, joint
action cost partitioning applied final additive implicit abstraction AFI Eq. 11
satisfying

kv
X X
cost(a)

vV



0

X

costfv,i (fv,i (a0 )) +

i=1 a0 f (a)
G

kv
X

X


costiv,i (iv,i (a0 )) .

(14)

i=1 a0 (a)
G
v

v

follows, uniform action cost partition refer partition cost
action equally split among nonredundant representatives final additive
implicit abstraction.
Overall, computing hFI Eq. 12 binary-valued domain abstractions
7
uniform action cost partition provides us hFI (I) = 12 15
, knowing
FI
original costs integers safely adjust h (I) = 13. Hence, even
severe domain abstractions above, estimate hFI example task
lower h2 .
Let us slightly refine domain abstractions sinks inverted forks
ternary range {0, 1, 2}. mappings {fv } remain unchanged, {iv } set
73

fiKatz & Domshlak



0, d(I[v], ) < 2i 1

D(v) : v,i () = 1, d(I[v], ) = 2i 1


2, d(I[v], ) > 2i 1

.

(15)

example, problem ip1 decomposed ip1 ,1 , . . . , ip1 ,3 along abstractions
D(p1 ) depicted Figure 5b. Applying computation hFI Eq. 12
new set domain abstractions gives hFI (I) = 15 12 , which, again, safely
adjusted hFI (I) = 16. Note value higher hFI = 15 obtained using
(generally intractable) pure fork-decomposition abstractions Eq. 6. first view,
outcome may seem counterintuitive domain abstractions applied fork
decomposition, one would expect coarser abstraction provide less precise estimates.
This, however, necessarily case employed action cost partition ad hoc.
instance, domain abstraction sink inverted fork may create independence
sink parent variables, exploiting domain-abstraction specific
independence relations leads targeted action cost partition via Eq. 14.
see surprising estimate improvement obtained, note
domain abstraction Eq. 15 applied example, truck-moving actions
drive-t-from-D-to-E drive-t-from-E-to-D appear three abstractions ft , ip1 ip2 ,
domain abstraction appear five abstractions ft,1 , ip1 ,1 , ip1 ,2 , ip1 ,3
ip2 ,1 . However, closer look action sets five abstractions reveals
dependencies p1 CG(ip1 ,1 ) CG(ip1 ,3 ), p2 CG(ip2 ,1 ) redundant,
thus keeping representatives move-D-E move-E-D corresponding abstract
tasks entirely unnecessary. Hence, all, two truck-moving actions appear
two post-domain-abstraction tasks. Moreover, abstractions truck-moving
actions fully counted, contrast predomain-abstraction tasks portion
cost actions allocated ip2 simply gets lost.

6. Experimental Evaluation: Take
evaluate practical attractiveness fork-decomposition heuristics, conducted empirical study wide sample planning domains International
Planning Competitions (IPC) 1998-2006, plus non-IPC Schedule-STRIPS domain.4
domains selected allow comparative evaluation other, baseline
state-of-the-art, approaches/planners, supported PDDL features
time evaluation.
Later formally prove that, ad hoc action cost partitions uniform
partition, none three fork decompositions Definition 9 dominated
two. Hence, implemented three additive fork-decomposition heuristics, hF ,
hI , hFI , within standard heuristic forward search framework Fast Downward
planner (Helmert, 2006) using algorithm full duplicate elimination. hF
heuristic corresponds ensemble (not clearly redundant) fork subgraphs
4. Schedule-STRIPS appears domains distribution IPC-2000. Later became aware
fact domain excluded competition encoding generated problems
various planners.

74

fiImplicit Abstraction Heuristics

domain



airport-ipc4
blocks-ipc2
depots-ipc3
driverlog-ipc3
freecell-ipc3
grid-ipc1
gripper-ipc1
logistics-ipc1
logistics-ipc2
miconic-strips-ipc2
mprime-ipc1
mystery-ipc1
openstacks-ipc5
pathways-ipc5
pipes-notank-ipc4
pipes-tank-ipc4
psr-small-ipc4
rovers-ipc5
satellite-ipc4
schedule-strips
tpp-ipc5
trucks-ipc5
zenotravel-ipc3

21
30
7
12
5
2
20
6
22
85
24
21
7
4
21
14
50
7
6
43
6
9
11

total

433

hF

11
17
2
9
3
1
5
3
21
45
17
16
7
4
9
6
47
5
6
42
5
5
8

%S
52
57
29
75
60
50
25
50
95
53
71
76
100
100
43
43
94
71
100
98
83
56
73
294

hI

14
15
2
10
2
1
5
2
15
42
17
15
7
4
11
6
48
6
6
35
5
5
9

%S
67
50
29
83
40
50
25
33
68
49
71
71
100
100
52
43
96
86
100
81
83
56
82
282

hFI

11
15
2
9
2
1
5
2
14
40
17
16
7
4
8
6
47
6
5
39
5
5
8

%S
52
50
29
75
40
50
25
33
64
47
71
76
100
100
38
43
94
86
83
91
83
56
73

MS -104

MS -105


19
18
7
12
5
2
7
4
16
54
21
17
7
3
20
13
50
6
6
22
6
6
11


17
20
4
12
1
2
7
5
21
55
12
13
7
4
12
7
50
7
6
1
6
5
11

274

%S
90
60
100
100
100
100
35
67
73
64
88
81
100
75
95
93
100
86
100
51
100
67
100
332

%S
81
67
57
100
20
100
35
83
95
65
50
62
100
100
57
50
100
100
100
2
100
56
100
285

HSPF


15
30
4
9
5
0
6
3
16
45
8
11
7
4
13
7
50
6
5
11
5
9
8

%S
71
100
57
75
100
0
30
50
73
53
33
52
100
100
62
50
100
86
83
26
83
100
73

277

Gamer

11
30
4
11
2
2
20
6
20
85
9
8
7
4
11
6
47
5
6
3
5
3
10

%S
52
100
57
92
40
100
100
100
91
100
38
38
100
100
52
43
94
71
100
7
83
33
91
315

blind

18
18
4
7
4
1
7
2
10
50
19
18
7
4
14
10
48
5
4
29
5
5
7

%S
86
60
57
58
80
50
35
33
45
59
79
86
100
100
67
71
96
71
67
67
83
56
64
296

hmax

20
18
4
8
5
2
7
2
10
50
24
18
7
4
17
10
49
6
5
31
6
7
8

%S
95
60
57
67
100
100
35
33
45
59
100
86
100
100
81
71
98
86
83
72
100
78
73
318

Table 1: summary experimental results. Per domain, denotes number
tasks solved planner. Per planner/domain, number tasks solved
planner given absolute number (s) percentage
solved planners (%S). last row summarize number solved
instances.

causal graph, domains roots abstracted using leave-one-value-out
binary-valued domain decompositions follows:
(
0, =
D(v) : fv,i () =
.
(16)
1, otherwise
hI heuristic inverted fork subgraphs, domains
sinks abstracted using distance-to-goal-value ternary-valued domain decompositions5 Eq. 17.


0, d(, G[v]) < 2i 1

D(v) : v,i () = 1, d(, G[v]) = 2i 1 .
(17)


2, d(, G[v]) > 2i 1
ensemble hFI heuristic union hF hI . action cost
partition three heuristics call uniform.
make comparison two baseline approaches, namely blind heuristic
value 0 goal states 1 otherwise, hmax heuristic (Bonet & Geffner,
2001), well state-of-the-art abstraction heuristics, represented mergeand-shrink abstractions Helmert et al. (2007). latter constructed
5. distance-from-initial-value reasonable evaluation initial state, leave-onevalue-out fork roots distance-to-goal-value inverted-fork sinks typically much
attractive evaluation states examined .

75

fiKatz & Domshlak

linear, f -preserving abstraction strategy proposed authors, two
fixed bounds size abstract state spaces, notably |S | < 104 |S | < 105 .
four (baseline merge-and-shrink) heuristics implemented Helmert et al.
(2007) within planning system fork-decomposition heuristics, allowing
fairly unbiased comparison. also compare Gamer (Edelkamp & Kissmann,
2009) HSPF (Haslum, 2008) planners, winner runner-up sequential
optimization track IPC-2008. algorithmic side, Gamer based bidirectional
blind search using sophisticated symbolic-search techniques, HSPF uses
additive critical-path heuristic. experiments conducted 3GHz Intel E8400
CPU 2 GB memory, using 1.5 GB memory limit 30 minute timeout.
exception Gamer, used similar machines 4 GB memory 2
GB memory limit; done provide Gamer environment
configured.
Table 1 summarizes experimental results terms number tasks solved
planner. impression fork-decomposition heuristics Table 1 somewhat
mixed. one hand, performance three fork-decomposition based planners
comparable one settings merge-and-shrink heuristic, clearly
testifies framework implicit abstractions theoretical interest only.
hand, planners, except merge-and-shrink heuristic
|S | < 104 , failed outperform baseline hmax heuristic. important
us that, unfortunately, three fork-decomposition based planners failed outperform
even basic blind search.
This, however, end story fork-decomposition heuristics.
hope found detailed results Tables 9-14 appendix. appears
Table 10, on, e.g., Logistics-ipc2 domain, hF almost consistently leads expanding
fewer search nodes (better two merge-and-shrink heuristics
domain) MS -105 , difference hitting four orders magnitude. However, time
complexity hF per search node substantially higher MS -105 ,
two expanding rate approximately 40 100000 nodes per second, respectively.
outcome simple: time limits (and memory limit 1.5 GB) hF
solves tasks Logistics-ipc2 MS -105 (task 12-1 solved hF 2519.01
seconds), standard time limit half hour used Table 10.
follows examine possibility exploiting informativeness fork-decomposition
heuristics falling trap costly per-node heuristic evaluation.

7. Back Theory: h-Partitions Databased Implicit Abstraction
Accuracy low time complexity desired yet competing properties heuristic
functions. many powerful heuristics, abstraction heuristics particular, computing
h(s) state isolation impractical: computing h(s) polynomial
description size , often efficient enough performed search node.
However, costly heuristics obstacle largely overcome sharing
computation evaluations h different states. possible,
shared parts computing h problem states precomputed memorized
search, reused search evaluations h different
76

fiImplicit Abstraction Heuristics

states. mixed offline/online heuristic computation henceforth called h-partition,
define time complexity h-partition complexity computing h
set states. Given subset k problem states 0 S, h-partitions time
complexity computing {h(s) | 0 } expressed O(X + kY ), O(X) O(Y )
are, respectively, complexity (offline) pre-search (online) per-node parts
computing h(s).
days h-partitions adopted various optimal planners using criticalpath heuristics hm > 1 (Haslum et al., 2005), landmark heuristics hL hLA (Karpas
& Domshlak, 2009), PDB merge-and-shrink abstraction heuristics (Edelkamp,
2001; Helmert et al., 2007). Without effective h-partitions, optimal search
heuristics would scale well, h-partitions constitutes state
art cost-optimal planning. instance, attractive property PDB abstractions
complexity natural h -partition. Instead computing h (s) = h ((s))
scratch evaluated state (impractical tiny projections), practice
precompute store h (s0 ) abstract states s0 , per-node
computation h (s) boils hash-table lookup h ((s)) perfect hash
function. terms, time space complexity PDB h -partition set
k states O(|S |(log(|S |) + |A|) + k) O(|S |), respectively. precisely
makes PDB heuristics attractive practice. respect, picture mergeand-shrink abstractions much similar. order composites
formed choice abstract states contract crucial complexity
natural h -partitions, time space complexity concrete linear abstraction
strategy Helmert et al. respectively O(|V ||S |(log(|S |) + |A|) + k |V |) O(|S |).
Similarly PDB abstractions, per-node computation h (s) merge-and-shrink
abstraction lookup data structure storing h ((s)) abstract states
(s) . Hence, pre-search computation MS abstractions
costly PDBs, online part computing heuristic values still extremely
efficient. per-node efficiency provides merge-and-shrink heuristics impressive
practical effectiveness numerous IPC domains (Helmert et al., 2007).
sum up, say fixed size abstract spaces induced explicit abstractions PDBs merge-and-shrink limitation also key obtaining
effective h-partitions. contrast, escaping limitation implicit abstractions might
trap us pay high price search-node evaluation. show, however, time-per-node complexity bottleneck fork-decomposition heuristics
successfully overcome. Specifically, show equivalent PDBs mergeand-shrink notion database exists fork-decomposition abstractions well, despite
exponential-size abstract spaces. course, unlike PDB merge-and-shrink
abstractions, databased fork-decomposition heuristics (and cannot) provide us
purely lookup online computation h (s). online part h -partition
nontrivial sense complexity cannot O(1). comes next
prove existence effective h-partitions fork inverted fork abstractions.
Section 8 empirically show h-partitions lead fast pre-search
per-node computations, allowing informativeness fork-decomposition heuristics
successfully exploited practice.

77

fiKatz & Domshlak

Theorem 7 Let = hV, A, I, G, costi planning task fork causal graph rooted
binary-valued variable r. exists h -partition that, set k states,
time space complexity h -partition is, respectively, O(d3 |V | + |Ar | + kd|V |)
O(d2 |V |), = maxv D(v).
Proof: proof modification polynomial-time algorithm computing
h (s) state task used proof Theorem 4 (Tractable Forks). Given
state s, let D(r) = {0, 1}, s[r] = 0. follows, two roots
values D(r), denotes opposite value 1 ; (r), [(r)], DTG 0v DTG 1v
defined exactly proof Theorem 4.
(1) two values r D(r) root variable, leaf variable v V \ {r},
pair values , 0 D(v), let p,0 ;r cost cheapest sequence
actions changing v 0 provided r : r . whole set {p,0 ;r } leaves
v V \{r} computed straightforward variant all-pairs-shortest-paths,
Floyd-Warshall algorithm DTG v r time O(d3 |V |).
(2) leaf variable v V \ {r}, 1 + 1, D(v), let g;i cost
cheapest sequence actions changing s[v] provided sequence [(r)],
|| = i, value changes r. values {p,0 ;r } step (1), set {g;i }
given solution recursive equation


ps[v],;s[r] ,
i=1






min g0 ;i1 + p0 ,;s[r] ,
1 < , odd
0

g;i =
,

0 ;i1 + p0 ,;s[r] ,
min
g
1
<



,


even



0


g
< + 1
;i1 ,
= |D(v)| + 1. Given that,

h (s) =

min

cost() +

[(r)]


X

gG[v];|| ,

vV \{r}

P||
cost() = i=2 cost(a[i] ), a[i] cheapest action changing
value r [i 1] [i].
Note step (1) already state-independent, heavy step (2) not. However,
state dependence step (2) mostly overcome follows. v V \ {r},
D(v), 1 + 1, r D(r), let g;i (r ) cost cheapest sequence
actions changing G[v] provided value changes r induce 0/1 sequence length
starting r . set {g;i (r )} given solution recursive equation


,
i=1

p,G[v];
r

g0 ;i1 (r ) + p,0 ;r , 1 <
,
g;i (r ) = min
0


g
< + 1
;i1 (r ),
78

(18)

fiImplicit Abstraction Heuristics

24

0

1

r ||

24

0
1

1
1

1

0
100

1
0

1 1
1
50

1

2

3
0
100

3
0

0

1

0
100

0

0

2

1

1 1
1
50

1

5
0

1

1

4

1
2
3
4
5
6
7
1
2
3
4
5
6
7

cost()

v :0

v :1 v :2 v :3

u:0

u:1 u:2 u:3 u:4 u:5

0
24
48
72
96
120
144
0
24
48
72
96
120
144

100
100
100
100
3
3
3

100
3
3
3
3
3


2
2
2
2
2
2


2
2
2
2
2

201
201
53
53
5
5
5

101
101
53
53
5
5

200 101 100
200 101 100
102 3
2
102 3
2
4
3
2
4
3
2
4
3
2

52 51
2
52 51
2
4
3
2
4
3
2
4
3
2
4
3
2


1
1
1
1
1
1
1
1
1
1
1
1
1

0
0
0
0
0
0
0
0
0
0
0
0
0
0

(a)

1
1
1
1
1
1
1

1
1
1
1
1
1

0
0
0
0
0
0
0
0
0
0
0
0
0
0

(b)

Figure 6: database fork-structured problem binary-valued root variable r
two children v u, G[r] = 0, G[v] = 3, G[u] = 5. (a) depicts
domain transition graphs r (top), v (middle), u (bottom); numbers
edge precondition r cost respective
action. (b) depicts database created algorithm. instance, entry
row r : 0 || = 5 column v : 0 captures value gv:0;5 (r : 0) computed
Eq. 18. shaded entries examined online computation
h (r : 0, v : 0, u : 0).
solved time O(d3 |V |). Note equation independent
evaluated state s, yet {g;i (r )} allow computing h (s) given state via

h (s) =

min



cost() +

[(r|s[r])]

X

gs[v];|| (s[r])

(19)

vV \{r}

(r|r ) defined similarly (r) respect initial value r r.
new formulation, computation performed online, per
search node, final minimization [(r|s[r])] Eq. 19, lightest
part whole algorithm anyway. major computations, notably {p,0 ;r }
{g;i (r )}, performed offline shared evaluated states.
space required store information O(d2 |V |) contains fixed amount
information per pair values variable. time complexity offline computation O(d3 |V | + |Ar |); |Ar | component stems precomputing costs cost().
time complexity online computation per state O(d|V |); |V | comes
internal summation comes size [(r|s[r])].

Figure 6b shows database created fork-structured problem binary-valued
root r, two children v u, G[r] = 0, G[v] = 3, G[u] = 5; domain transition
79

fiKatz & Domshlak

graphs v u depicted Figure 6(a). Online computation h (s) Eq. 19
= (r : 0, v : 0, u : 0) sums shaded entries four rows
entries, minimizes resulting four sums, minimum obtained
row r : 0 || = 5.
Theorem 8 Let = hV, A, I, G, costi planning task inverted fork causal graph
sink r |D(r)| = b = O(1). exists h -partition that, set
k states, time space complexity h -partition O(b|V ||Ar |b1 + d3 |V | +
k|V ||Ar |b1 ) O(|V ||Ar |b1 + d2 |V |), respectively, = maxv D(v).
Proof: Like proof Theorem 7, proof Theorem 8 based modification
polynomial-time algorithm computing h (s) used proof Theorem 5
(Tractable Inverted Forks).
(1) parent variable v V \ {r}, pair values , 0 D(v), let p,0
cost cheapest sequence actions changing 0 . whole set {p,0 }
computed using Floyd-Warshall algorithm domain transition graph
v time O(d3 |V |).
(2) Given state s, cycle-free path = ha1 , . . . , s[r] G[r] DTG(v, ),
let g cost cheapest plan based , cheapest paths
{p,0 } computed step (1). g computed
g =


X
i=1

cost(ai ) +


X
X

pprei [v],prei+1 [v] ,

i=0 vV \{r}

pre0 , . . . , prem+1 values required parents r along path .
is, v V \ {r}, 0 + 1,


s[v],
i=0



G[v],
= + 1, G[v] specified
prei [v] =
.

pre(a
)[v],
1



m,

pre(a
)[v]

specified





pre [v]
otherwise
i1
that, h (s) = min g .
Note step (1) state-independent, step (2) not. However, dependence
step (2) evaluated state substantially relaxed. O(1)
different values r, possible consider cycle-free paths G[r] values r.
path , parent variable v V \ {r}, know first value
v required would be. Given that, precompute cost-optimal plans induced
assuming parents start first required values. remainder
computation h (s) delegated online, modified step (2) follows.
r D(r) cycle-free path = ha1 , . . . , r G[r]
DTG(r, ), let proxy state


v=r
r ,
[v] = G[v],
1 : pre(ai )[v] unspecified ,


pre(ai )[v], = argminj {pre(aj )[v] specified}
80

fiImplicit Abstraction Heuristics

is, nontrivial part captures first values V \ {r} required along .6 Given
that, let g cost cheapest plan based , cheapest
paths {p,0 } computed (1). g computed
g =


X





cost(ai ) +

i=1

X

pprei [v],prei+1 [v] ,

vV \{r}

where, v V \ {r}, 1 + 1,


[v],
i=1



G[v],
= + 1, G[v] specified
prei [v] =
.

pre(ai )[v], 2 m, pre(ai )[v] specified



pre [v], otherwise
i1
Storing pairs (g , ) accomplishes offline part computation. Now, given
search state s, compute

h (s) =

min

s.t.
[r]=s[r]



g +

X

ps[v],s [v] .

(20)

vV \{r}

number cycle-free paths G[r] DTG(r, ) (|Ar |b1 ), g
path computed time O(b|V |). Hence, overall offline time complexity
O(b|V ||Ar |b1 + d3 |V |), space complexity (including storage proxy states
) O(|V ||Ar |b1 + d2 |V |). time complexity online computation per state via
Eq. 20 O(|V ||Ar |b1 ); |V | comes internal summation |Ar |b1 upper
bound number cycle-free paths s[r] G[r].

Figure 7(b) shows database created inverted fork structured problem
ternary-valued sink variable r, two parents u v, G[r] = 2, G[u] = 0, G[v] = 2.
domain transition graphs u v depicted top Figure 7(a); actual
identities actions affecting two parents important here. actions affecting
sink r
a1 = h{u : 1, r : 0}, {r : 1}i
a2 = h{v : 1, r : 0}, {r : 1}i

a3 = h{u : 2, r : 1}, {r : 2}i

a4 = h{v : 1, r : 1}, {r : 2}i.
domain transition graph r depicted bottom Figure 7(a). Online computation h (s) Eq. 20 = (r : 0, v : 0, u : 0) sums shaded entries
four rows entries, minimizes resulting four sums,
minimum obtained lowest row.
81

fiKatz & Domshlak

0

2

50

0

50

50

2

1
1

1

100

1

u:2

u:1

1

1

0

1

2

v:1

v:1

50

100

r



ha1 , a3
0 ha1 , a4
ha2 , a3
ha2 a4
ha3
1
ha4

(a)



g

u:0

u:1 u:2

v :0

u : 1, v : 2
u : 1, v : 1
u : 2, v : 1
u : 0, v : 1
u : 2, v : 2
u : 0, v : 1

202
153
153
152
101
102

100
100
50
0
50
0

0
50
0
50
100 0
50 100
100 0
50 100

1
101
101
101
1
101

v :1 v :2
2
0
0
0
2
0

0
100
100
100
0
100

(b)

Figure 7: database inverted fork-structured problem O(1) bounded sink
variable r two parents u v, G[r] = 2, G[u] = 0, G[v] = 2.
(a) depicts domain transition graphs u (top left), v (top right), r
(bottom); numbers edge preconditions
cost respective action, respectively. (b) depicts database created
algorithm. shaded entries examined online computation
h (r : 0, u : 0, v : 0).

8. Experimental Evaluation: Take II
evaluate practical attractiveness databased fork-decomposition heuristics,
repeated empirical evaluation Section 6, databased versions
heuristics. detailed results evaluation relegated Tables 15-20
appendix, summarized Table 2. domain, column
captures number tasks domain solved least one planner
suite. Per planner/domain, number tasks solved planner given
absolute number (s) percentage solved planners
(%S). Boldfaced results indicate best performance within corresponding domain.
last three rows summarize performance planners via three measures.
first number tasks solved 23 domains; basically performance
evaluation measure used optimization track IPC-2008. domains equally
challenging equally discriminate planners performance, second
domain-normalized performance measure
s(p) =

X
domain

#tasks solved planner p
.
#tasks solved planners

Finally, third measure corresponds number domains w planner
question solved least many tasks planner.
Overall, Table 2 clearly suggests heuristic search databased fork-decomposition
heuristics favorably competes state art optimal planning. particular,
6. ease presentation, omit case v required neither along , goal;
variables simply ignored accounting cost .

82

fiImplicit Abstraction Heuristics

domain



airport-ipc4
blocks-ipc2
depots-ipc3
driverlog-ipc3
freecell-ipc3
grid-ipc1
gripper-ipc1
logistics-ipc2
logistics-ipc1
miconic-strips-ipc2
mprime-ipc1
mystery-ipc1
openstacks-ipc5
pathways-ipc5
pipes-notank-ipc4
pipes-tank-ipc4
psr-small-ipc4
rovers-ipc5
satellite-ipc4
schedule-strips
tpp-ipc5
trucks-ipc5
zenotravel-ipc3

22
30
7
12
5
2
20
22
7
85
24
21
7
4
21
14
50
7
6
46
6
9
11

total

w

438

hF

22
21
7
12
5
2
7
22
6
51
23
21
7
4
17
11
49
6
6
46
6
6
11

%S
100
70
100
100
100
100
35
100
86
60
96
100
100
100
81
79
98
86
100
100
100
67
100

368
20.56
14

hI

20
18
4
12
4
1
7
16
4
50
22
18
7
4
15
9
49
7
6
40
6
7
11

%S
91
60
57
100
80
50
35
73
57
59
92
86
100
100
71
64
98
100
100
87
100
78
100

337
18.38
7

hFI

21
18
7
12
4
1
7
16
5
50
21
21
7
4
16
9
49
6
6
46
6
7
11

%S
95
60
100
100
80
50
35
73
71
59
88
100
100
100
76
64
98
86
100
100
100
78
100

350
19.13
9

MS -104

MS -105


19
18
7
12
5
2
7
16
4
54
21
17
7
3
20
13
50
6
6
22
6
6
11


17
20
4
12
1
2
7
21
5
55
12
13
7
4
12
7
50
7
6
1
6
5
11

%S
86
60
100
100
100
100
35
73
57
64
88
81
100
75
95
93
100
86
100
48
100
67
100

332
19.07
11

%S
77
67
57
100
20
100
35
95
71
65
50
62
100
100
57
50
100
100
100
2
100
56
100

285
16.64
9

HSPF


15
30
4
9
5
0
6
16
3
45
8
11
7
4
13
7
50
6
5
11
5
9
8

%S
68
100
57
75
100
0
30
73
43
53
33
52
100
100
62
50
100
86
83
24
83
100
73

277
15.45
6

Gamer

11
30
4
11
2
2
20
20
6
85
9
8
7
4
11
6
47
5
6
3
5
3
10

%S
50
100
57
92
40
100
100
91
86
100
38
38
100
100
52
43
94
71
100
7
83
33
91

315
16.66
8

blind

18
18
4
7
4
1
7
10
2
50
19
18
7
4
14
10
48
5
4
29
5
5
7

%S
82
60
57
58
80
50
35
45
29
59
79
86
100
100
67
71
96
71
67
63
83
56
64

296
15.58
2

hmax

20
18
4
8
5
2
7
10
2
50
24
18
7
4
17
10
49
6
5
31
6
7
8

%S
91
60
57
67
100
100
35
45
29
59
100
86
100
100
81
71
98
86
83
67
100
78
73

318
17.66
6

Table 2: summary experimental results databased versions forkdecomposition heuristics. Per domain, denotes number tasks solved
planner. Per planner/domain, number tasks solved planner
given absolute number (s) percentage solved
planners (%S). Boldfaced results indicate best performance within
corresponding domain. last three rows summarize number solved instances, domain-normalized measure solved instances (s), number
domains planners achieved superior performance (w).

forks heuristic hF exhibited best overall performance according
three measures. terms absolute number solved instances, three
fork-decomposition heuristics outperformed planners suite. contribution
databasing success fork-decomposition heuristics dramatic. Looking
back results fully online heuristic computation depicted Table 1, note
total number solved instances fork-decomposition heuristics hF , hI , hFI
increased 74, 55, 76, respectively, made whole difference.
also performed comparative evaluation planning domains
recent IPC-2008. IPC-2008 domains differ previous domains actions
various costs, and, importantly, many actions zero cost. latter
issue heuristic-search planners heuristic functions cannot differentiate
subplans cost zero, differ length. case, comparative
side evaluation IPC-2008 domains differ several points previous
one. First, neither merge-and-shrink hmax heuristics, implementation
supporting arbitrary action costs. Hence, comparison Gamer, HSPF ,
blind search. Second, ensure admissibility blind search, latter
modified return non-goal states cost cheapest applicable action. Finally,
planners run 3GHz Intel E8400 CPU 4 GB memory, using 2 GB memory
83

fiKatz & Domshlak

domain



elevators-strips-ipc6
openstacks-strips-ipc6
parcprinter-strips-ipc6
pegsol-strips-ipc6
scanalyzer-strips-ipc6
sokoban-strips-ipc6
transport-strips-ipc6
woodworking-strips-ipc6

22
21
16
27
12
28
11
14

total

w

152

hF

18
19
14
27
12
25
11
8

%S
82
90
88
100
100
89
100
57

134
7.06
3

hI

14
19
13
27
6
26
11
8

%S
64
90
81
100
50
93
100
57

124
6.35
2

hFI

15
19
13
27
6
27
11
8

%S
68
90
81
100
50
96
100
57

126
6.43
3

HSPF


7
21
16
27
6
13
9
9

%S
32
100
100
100
50
46
82
64

108
5.74
3

Gamer

22
19
9
24
11
20
11
14

%S
100
90
56
89
92
71
100
100

130
6.99
3

blind

11
19
10
27
12
20
11
7

%S
50
90
63
100
100
71
100
50

117
6.24
3

Table 3: summary experimental results. Per domain, denotes number
tasks solved planner. Per planner/domain, number tasks solved
planner given absolute number (s) percentage
solved planners (%S). Boldfaced results indicate best performance
within corresponding domain. last three rows summarize number
solved instances, domain-normalized measure solved instances (s),
number domains planners achieved superior performance (w).

limit 30 minute timeout. results evaluation summarized Table 3;
detailed results refer reader Tables 21-22 appendix. Overall,
results show fork-decomposition heuristics much competitive
IPC-2008 domains well.

9. Formal Analysis: Asymptotic Performance Ratios
Empirical evaluation concrete set benchmark tasks standard important
methodology assessing effectiveness heuristic estimates: allows us study
tradeoff accuracy heuristics complexity computing them.
However, rightfully noted Helmert Mattmuller (2008), evaluations almost
never lead absolute statements type Heuristic h well-suited solving problems benchmark suite X, relative statements type Heuristic h
expands fewer nodes heuristic h0 benchmark suite X. Moreover, one would probably like obtain formal evidence effectiveness heuristic proceeding
implementation, especially complicated heuristic procedures underlying proofs Theorems 7 8. formal analysis effectiveness
fork-decomposition heuristics using methodology suggested exploited Helmert
Mattmuller motivated primarily desire formal evidence.
Given planning domain heuristic h, Helmert Mattmuller (2008) consider
asymptotic performance ratio h D. goal find value (h, D) [0, 1]

(1) states problems D, h(s) (h, D) h (s) + o(h (s)),
(2) family problems {n }nN solvable, non-goal states {sn }nN
sn n , limn h (sn ) = , h(sn ) (h, D) h (sn ) + o(h (sn )).
84

fiImplicit Abstraction Heuristics

Domain

h+

hk

hPDB

hPDB
add

hF

hI

hFI

Gripper
Logistics
Blocksworld
Miconic-Strips
Satellite

2/3
3/4
1/4
6/7
1/2

0
0
0
0
0

0
0
0
0
0

2/3
1/2
0
1/2
1/6

2/3
1/2
0
5/6
1/6

0
1/2
0
1/2
1/6

4/9
1/2
0
1/2
1/6

Table 4: Performance ratios multiple heuristics selected planning domains; ratios
h+ , hk , hPDB , hPDB
add Helmert Mattmuller (2008).

words, h never worse (, domain, )h (plus sublinear term),
become bad (h, D) h (plus sublinear term) arbitrarily large inputs; note
existence uniqueness (h, D) guaranteed h D.
Helmert Mattmuller (2008) study asymptotic performance ratio standard admissible heuristics set well-known benchmark domains first four
IPCs. results Gripper, Logistics, Blocksworld, Miconic, Satellite
shown first four columns Table 4.
h+ estimate corresponds optimal cost solving well-known delete
relaxation original planning task, generally NP-hard compute (Bylander, 1994).
hk , k N+ , family heuristics based relaxation cost
achieving partial assignment approximated highest cost achieving
sub-assignment size k (Haslum & Geffner, 2000); computing hk exponential
k.
hPDB hPDB
add heuristics regular (maximized over) additive pattern
database heuristics size pattern assumed O(log(n))
n = |V |, and, importantly, choice patterns assumed optimal.
results provide us baseline evaluating fork-decomposition heuristics
hI , hFI . First, however, Theorem 9 shows three heuristics worth
analyzing alone strictly informative two, depending
planning task and/or state evaluated.7
hF ,

Theorem 9 (Undominance) uniform action cost partition, none heuristic
functions hF , hI , hFI dominates another.
Proof: proof example two tasks, 1 2 , illustrate following
two cases: hF (I) > hFI (I) > hI (I) hF (I) < hFI (I) < hI (I). two tasks
defined set binary-valued variables V = {v1 , v2 , v3 , u1 , u2 , u3 },
initial state = {v1 : 0, v2 : 0, v3 : 0, u1 : 0, u2 : 0, u3 : 0}, goal
7. Theorem 9 formulated proven uniform action cost partition use throughout
paper, including experiments. per-step optimal action cost partitions (Katz & Domshlak, 2010),
trivial show hFI dominates hF hI planning tasks.

85

fiKatz & Domshlak

A1

u1

u2

u3

v1

v2

v3

a1
a2
a3
a4
a5
a6
a7
a8
a9

h{v1 : 0, u1 : 0, u2 : 0, u3 : 0}, {v1 : 1}i
h{v2 : 0, u1 : 1, u2 : 0, u3 : 1}, {v2 : 1}i
h{v3 : 0, u1 : 1, u2 : 1, u3 : 0}, {v3 1}i
h{u1 : 0}, {u1 : 1}i
h{u1 : 1}, {u1 : 0}i
h{u2 : 0}, {u2 : 1}i
h{u2 : 1}, {u2 : 0}i
h{u3 : 0}, {u3 : 1}i
h{u3 : 1}, {u3 : 0}i

(a)

1
F

1


1
FI

1/3
1/3
1/3
1
1
1
1
1
1

1
1
1
1/3
1/3
1/3
1/3
1/3
1/3

1/4
1/4
1/4
1/4
1/4
1/4
1/4
1/4
1/4

(c)

u1

u2

u3

v1 v2 v3

v1 v2 v3

v1 v2 v3

Guf 1

Guf 2

Guf 3

u1 u2 u3

u1 u2 u3

u1 u2 u3

v1

v2

v3

Gvi 1

Gvi 2

Gvi 3

A2
a1
a2
a3
a4
a5
a6
a7
a8
a9
a10
a11
a12

(b)

h{v1 : 0, u1 : 1}, {v1 : 1}i
h{v1 : 0, u2 : 1}, {v1 : 1}i
h{v1 : 0, u3 : 1}, {v1 : 1}i
h{v2 : 0, u1 : 1}, {v2 : 1}i
h{v2 : 0, u2 : 1}, {v2 : 1}i
h{v2 : 0, u3 : 1}, {v2 : 1}i
h{v3 : 0, u1 : 1}, {v3 : 1}i
h{v3 : 0, u2 : 1}, {v3 : 1}i
h{v3 : 0, u3 : 1}, {v3 : 1}i
h{u1 : 0}, {u1 : 1}i
h{u2 : 0}, {u2 : 1}i
h{u3 : 0}, {u3 : 1}i

2
F

2


2
FI

1/3
1/3
1/3
1/3
1/3
1/3
1/3
1/3
1/3
1
1
1

1
1
1
1
1
1
1
1
1
1/3
1/3
1/3

1/4
1/4
1/4
1/4
1/4
1/4
1/4
1/4
1/4
1/4
1/4
1/4

(d)

Figure 8: Illustrations proof Theorem 9: (a) causal graphs 1 2 , (b) fork
inverted fork subgraphs (same) causal graph 1 2 ,
action sets (c) 1 (d) 2 , well costs action representatives
abstract problem along subgraphs. Considering example
first row table (c), action a1 1 single representative
three fork abstractions, well representative inverted-fork abstraction
1G . Hence, cost representatives F-decomposition 1/3,
v1

cost sole representative I-decomposition 1.

G = {v1 : 1, v2 : 1, v3 : 1}. difference 1 2 action sets, listed
Figure 8c-d, actions unit-cost actions. two tasks induce identical
causal graphs, depicted Figure 8a. Hence, collections v-forks v-iforks
tasks also identical; depicted Figure 8b. fractional costs tasks
action representatives corresponding abstract problems given Figure 8c-d.
Figure 9 shows optimal plans abstract problems F-decompositions 1F =
{1G f , 1G f , 1G f } 2F = {2G f , 2G f , 2G f }, I-decompositions 1I = {1G , 1G , 1G }
u1

u2

u3

u1

u2

u3

v1

v2

v3

2I = {2G , 2G , 2G }, FI-decompositions 1FI = 1F 1I 2FI = 2F 2I .
v1

v2

v3

last column tables captures estimates three heuristics initial
states 1 2 , respectively. Together, two cases show none forkdecomposition heuristic functions hF , hI , hFI dominates other, and, since
86

fiImplicit Abstraction Heuristics

h
hF

hI

h

FI

task
1G f
u1
1G f
u2
1G f
u3
1G
v1
1G
v2
1G
v3
1G f
u1
1G f
u2
1G f
u3
1G
v1
1G
v2
1G
v

optimal plan

cost

ha1 , a4 , a2 , a3

2

ha1 , a2 , a6 , a3

2

ha1 , a3 , a8 , a2

2

ha1

1

ha4 , a8 , a2

5/3

ha4 , a6 , a3

5/3

ha1 , a4 , a2 , a3

1

ha1 , a2 , a6 , a3

1

ha1 , a3 , a8 , a2

1

ha1

1/4

ha4 , a8 , a2

3/4

ha4 , a6 , a3

3/4

h(I)

h
hF

6

hI

4 31

4 43

h

3

FI

task

optimal plan

2G f
u1
2G f
u2
2G f
u3
2G
v1
2G
v2
2G
v3
2G f
u1
2G f
u2
2G f
u3
2G
v1
2G
v2
2G
v

ha2 , a5 , a8

1

ha1 , a4 , a7

1

ha1 , a4 , a7

cost

h(I)
3

1

ha10 , a1

4/3

ha10 , a4

4/3

ha10 , a7

4/3

ha2 , a5 , a8

3/4

ha1 , a4 , a7

3/4

ha1 , a4 , a7

3/4

ha10 , a1

1/2

ha10 , a4

1/2

ha10 , a7

1/2

4

15/4

3

(a)

(b)

Figure 9: Illustrations proof Theorem 9: Optimal plans abstract problems (a) 1 , hF (I) > hFI (I) > hI (I), (b) 2 ,
hF (I) < hFI (I) < hI (I).

variables binary-valued, claim holds conjunction arbitrary variable
domain abstractions.

One conclusion Theorem 9 worth studying asymptotic performance
ratios three heuristics. last three columns Table 4 present results
hF , hI , hFI Gripper, Logistics, Blocksworld, Miconic, Satellite
domains. also studied performance ratios max{hF , hI , hFI }, five
domains appear identical hF . (Note ratio max
necessarily identical max ratios, thus analysis worthwhile.) Taking
conservative position, performance ratios fork-decomposition heuristics
Table 4 worst-case sense
(i) neither optimize action cost partition (setting uniform rest
paper) eliminate clearly redundant abstractions,
(ii) use domain abstractions (up to) ternary-valued abstract domains only.
domains fork roots abstracted using leave-one-out binary-valued
domain decompositions Eq. 16 domains inverted-fork sinks
abstracted using distance-from-initial-value ternary-valued domain decompositions
Eq. 15.
Overall, results fork-decomposition heuristics Table 4 gratifying. First,
note performance ratios hk hPDB 0. every subgoal
set size k (for hk ) size log(n) (for hPDB ) reached number steps
depends k (respectively, log(n)), n, h (sn ) grows linearly n
five domains. leaves us hPDB
add state-of-the-art (tractable
87

fiKatz & Domshlak

and) admissible heuristic compare with. Table 4 shows asymptotic performance
F
ratio hF heuristic least good hPDB
add five domains, h
+
PDB
superior hPDB
add Miconic, getting quite close h . comparing hadd
fork-decomposition heuristics, crucial recall ratios devised Helmert
Mattmuller hPDB
add respect optimal, manually-selected set patterns.
contrast, selection variable subsets fork-decomposition heuristics completely
nonparametric, thus requires tuning abstraction-selection process.
rest section prove asymptotic performance ratios hF , hI ,
FI
h Table 4 five domains. begin brief outline results
obtained. familiarity domains assumed. Next, domain addressed
detail: provide informal domain description well sas+ representation,
prove lower upper bounds ratios three heuristics.
Gripper Assuming n > 0 balls moved one room another, three
heuristics hF , hI , hFI account required pickup drop actions,
O(1)-portion move actions. However, former actions responsible 2/3
optimal-plan length (= cost). Now, basic uniform action-cost partition,
hF , hI , hFI account whole, O(1/n), 2/3 total pickup/drop
actions cost, respectively, providing ratios Table 4.8
Logistics optimal plan contains least many load/unload actions move actions,
three heuristics hF , hI , hFI fully account former, providing lower bound
1/2. instance three heuristics achieve exactly 1/2 consists two
trucks t1 , t2 , airplanes, one city, n packages initial goal
locations packages trucks pair-wise different.
Blocksworld Arguments similar Helmert Mattmuller (2008) hPDB
add .
Miconic three heuristics fully account loads/unload actions. addition, hF
accounts full cost move actions passengers initial locations,
half cost move actions. provides us lower
bounds 1/2 5/6, respectively. Tightness 1/2 hI hFI shown
task consisting n passengers, 2n + 1 floors, initial goal locations
pair-wise different. Tightness 5/6 hF shown task consisting n
passengers, n + 1 floors, elevator passengers initially floor n + 1,
passenger wishes get floor i.
Satellite length optimal plan problem n images taken k
satellites moved end-positions 6n + k. three heuristics fully
account image-taking actions one satellite-moving action per satellite
above, providing lower bound 61 . Tightness 1/6 three heuristics
shown task follows: Two satellites instruments {i}li=1 {i}2l
i=l+1 ,

respectively, l = n n. pair instruments {i, l + i} take images
modes {m0 , mi }. set directions {dj }nj=0 set image objectives
8. note slight modification uniform action-cost partition results ratio 2/3
three heuristics. optimizations, however, outside scope here.

88

fiImplicit Abstraction Heuristics

right

lef

robot

right
b1

b1



bn

...
f
Gright

lef
bn

...

b1

right

robot
bn

b1

f
Glef


(a)

...

robot

bn

f
Grobot

lef

b
Gbi , b Balls

(b)

Figure 10: Grippers (a) causal graph (b) corresponding collection v-forks
v-iforks

{oi }ni=1 that, 1 l, oi = (d0 , mi ) and, l < n, oi = (di , m0 ).
Finally, calibration direction pair instruments {i, l + i} di .
9.1 Gripper
domain consists one robot robot two arms Arms = {right, lef t}, two rooms
Rooms = {r1, r2}, set Balls n balls. robot pick ball arm
arm Arms arm empty, release ball b Balls arm arm arm currently
holds b, move one room another. balls robot initially room
r1, arms empty, goal move balls room r2. natural
description planning task sas+ follows.


Variables V = {robot} Arms Balls domains
D(robot) = Rooms

D(lef t) = D(right) = Balls {empty}

b Balls : D(b) = Rooms {robot}.

Initial state = {b : r1 | b Balls} {robot : r1, right : empty, lef : empty}.
Goal G = {b : r2 | b Balls}.
Actions
={M ove(r, r0 ) | {r, r0 } Rooms}

[

{P ickup(b, arm, r), Drop(b, arm, r) | b Balls, arm Arms, r Rooms},

move robot: ove(r, r0 ) = h{robot : r}, {robot : r0 }i,

pickup ball:
P ickup(b, arm, r) = h{b : r, arm : empty, robot : r}, {b : robot, arm : b}i,

drop ball: Drop(b, arm, r) = h{b : robot, arm : b, robot : r}, {b : r, arm : empty}i.

(parametric n) causal graph task depicted Figure 10a.
89

fiKatz & Domshlak

frobot

Action
0

ove(r, r )
P ickup(b, arm, r)
Drop(b, arm, r)

farm,empty

1
1
1

0
2
2

farm,b

farm,b0

0
2
2

0
1
1

farm0 ,
0
1
1

ib
1
2
2

ib0
1
1
1

F



FI

1

1
n
1
n+1
1
n+1

1
n+1
1
3n+6
1
3n+6

1
2n+5
1
2n+5

Table 5: Number representatives original Gripper action abstract task,
well partition action costs representatives
frobot

fright,empty
fright,b
fright,b0
flef t,
ib
ib0

P ickup(b, right, r1) = h{robot : r1, b : r1}, {b : robot}i
P ickup(b, right, r1)1 = h{right : empty}, {right : b}i,
P ickup(b, right, r1)2 = h{right : b, b : r1}, {b : robot}i
P ickup(b, right, r1)1 = h{right : empty}, {right : b}i,
P ickup(b, right, r1)2 = h{right : b, b : r1}, {b : robot}i
P ickup(b, right, r1) = h{right : b, b : r1}, {b : robot}i
P ickup(b, right, r1) = h{right : b, b : r1}, {b : robot}i
P ickup(b, right, r1)1 = h{right : empty}, {right : b}i,
P ickup(b, right, r1)2 = h{right : b, robot : r1, b : r1}, {b : robot}i
P ickup(b, right, r1) = h{right : empty}, {right : b}i

Table 6: sets representatives original action P ickup(b, right, r1) abstract
tasks

9.1.1 Fork Decomposition
Since variables robot, right, lef goal value, collection v-forks
v-iforks Figure 10b. domains inverted fork sinks ternary valued.
domains fork roots abstracted Eq. 16 (leave one out), thus
F = {frobot } {fright, , flef t, | {empty} Balls},
= {ib | b Balls},

FI = {frobot } {fright, , flef t, | {empty} Balls} {ib | b Balls}.
original action, number representatives abstract task, well
cost assigned representative, listed Table 5. Table 6 illustrates derivation numbers via decomposition example action P ickup(b, right, r1)
fork decomposition abstractions. action one nonredundant representative
frobot , two representatives fright,empty fright,b , one representative
fright,b0 b0 Balls \ {b}, one representative flef t, Balls {empty},
two representatives ib , one representative ib0 b0 Balls \ {b}.
1
1
results cost 2n+5
representative F , n+1
representative ,
1
3n+6 representative FI .
Given that, optimal plans abstract tasks follows.
90

fiImplicit Abstraction Heuristics

h

task
frobot

hF

fright,
flef t,

hI

ib
frobot

hFI

fright,
flef t,
ib

optimal plan
hP ickup(b1 , right, r1), . . . , P ickup(bn , right, r1),
, ove(r1, r2), Drop(b1 , right, r2), . . . , Drop(bn , right, r2)i
hP ickup(b1 , lef t, r1), . . . , P ickup(bn , lef t, r1),
, Drop(b1 , lef t, r2), . . . , Drop(bn , lef t, r2)i
hP ickup(b1 , right, r1), . . . , P ickup(bn , right, r1),
, Drop(b1 , right, r2), . . . , Drop(bn , right, r2)i
hP ickup(b, right, r1)1 , P ickup(b, right, r1)2 , ove(r1, r2), Drop(b, lef t, r2)2
hP ickup(b1 , right, r1), . . . , P ickup(bn , right, r1), ove(r1, r2),
, Drop(b1 , right, r2), . . . , Drop(bn , right, r2)i
hP ickup(b1 , lef t, r1), . . . , P ickup(bn , lef t, r1),
, Drop(b1 , lef t, r2), . . . , Drop(bn , lef t, r2)i
hP ickup(b1 , right, r1), . . . , P ickup(bn , right, r1),
, Drop(b1 , right, r2), . . . , Drop(bn , right, r2)i
hP ickup(b, right, r1)1 , P ickup(b, right, r1)2 , ove(r1, r2), Drop(b, lef t, r2)2

cost

#

4n+5
2n+5

1

2n
2n+5

n+1

2n
2n+5

n+1

3
1
+ n
n+1
1
2n +
3n+6
n+1

n

2n
3n+6

n+1

2n
3n+6

n+1

3
3n+6

1
+ n+1

h(I)

2n 2n5
2n+5

4n+1
n+1

1
4n
3

+ 4n+6
3n+6

n

Assuming n > 0 balls moved one room another, cost optimal
plan original task 3n 1 n even, 3n n odd. Therefore,
asymptotic performance ratios heuristics hF , hI , hFI Gripper 2/3, 0, 4/9,
respectively.
9.2 Logistics
Logistics task consists k cities, x airplanes, trucks n packages.
city associated set Li = {li1 . . . , lii } locations within city; union

locations cities denoted L = ki=1 Li . addition, precisely one location
city airport, set airports LA = {l11 . . . , lk1 } L. truck
move within city located, airplanes fly airports.
airplanes denoted U = {u1 , . . . , ux }, trucks = {t1 , . . . , ty },
packages P = {p1 , . . . , pn }. Let Ti = {t | I[t] Li } denote trucks city i,
P = P1 P2 P3 P4 P5 denote partition packages follows:
package P1 = {p P | I[p], G[p] LA } initially airport
needs moved another airport,
package P2 = {p P | I[p] LA Li , G[p] Lj \ LA , 6= j} initially
airport needs moved non-airport location another city,
package P3 = {p P | I[p] Li , G[p] Li } needs moved within one
city,
package P4 = {p P | I[p] Li \ LA , G[p] LA \ Li } needs moved
non-airport location one city airport city,
package P5 = {p P | I[p] Li \ LA , G[p] Lj \ LA , 6= j} needs moved
non-airport location one city non-airport location another city.
natural Logistics task description sas+ follows.
Variables V = U P domains
u U : D(u) = LA ,

1 k, Ti : D(t) = Li ,

p P : D(p) = L U T.
91

fiKatz & Domshlak

u1 ux

t1

ty

u
p1 . . .

p1

pi pn
(a)

u1 . . . ux


pn

Guf , u U

p1 . . .

pn

Gtf ,
(b)

t1 . . . ty
p

Gpi , p P

Figure 11: Logisticss (a) causal graph (b) corresponding collection v-forks
v-iforks

Initial state (LA )x L1 Lk (L)n .
Goal G = {p1 : l1 , . . . , pn : ln } (L)n .
Actions
A=

k [ [
[

i=1 lLi tTi



[ [
lLA uU


{Lt(p, t, l), U t(p, t, l) | p P } {M t(t, l, l0 ) |, l0 Li \ {l}}


{La(p, u, l), U a(p, u, l) | p P } {M a(u, l, l0 ) | l0 LA \ {l}} ,


load package p onto truck location l: Lt(p, t, l) = h{p : l, : l}, {p : t}i,
unload package p truck location l: U t(p, t, l) = h{p : t, : l}, {p : l}i,
move truck location l location l0 : t(t, l, l0 ) = h{t : l}, {t : l0 }i,
load package p onto airplane u l: La(p, u, l) = h{p : l, u : l}, {p : u}i,
unload package p airplane u l: U a(p, u, l) = h{p : u, u : l}, {p : l}i,
move airplane u location l l0 : a(u, l, l0 ) = h{u : l}, {u : l0 }i.
(parametrized n, x, y) causal graph Logistics tasks depicted Figure 11a.
9.2.1 Fork Decomposition
Since variables u U goal value, collection v-forks viforks Figure 11b. domains inverted-fork sinks abstracted
Eq. 15 (distance-from-initial-value), domains fork roots abstracted
92

fiImplicit Abstraction Heuristics

fu,l fu,l0 fu,l00 fu0 ,l ft,l ft,l0 ft,l00 ft0 ,l ip,m F FI

Action
0

t(t, l, l )
a(u, l, l0 )

0
1

0
1

0
0

0
0

1
0

1
0

0
0

0
0

1
2
1
2

1
1

1
1
ni 2+ni
1
1
ni 2+ni

(a)
I[p] LA Li
I[p] Li \ LA
p P1 p P2 p P3 p P3 p P4
p P5
fu,l ft,l ip0 ,m ip,1 ip,1 ip,2 ip,1 ip,1 ip,1 ip,2 ip,1 ip,2 ip,3 F FI

Action
l Li
l Lj
La(p, u, l), U a(p, u, l)

Lt(p, t, l), U t(p, t, l)

1
1
1

1
1
1

0
0
0

1
0
1

1
0
1

0
1
0

1
0
1

1
0
0

1
0
0

0
0
1

1
0
0

0
0
1

0
1
0

1
nf
1
nf
1
nf

1
1
1

1
nf +1
1
nf +1
1
nf +1

(b)
Figure 12: Number representatives original Logistics action abstract
task, well partition action costs representatives;
tables (a) (b) capture move load/unload actions, respectively

Eq. 16 (leave-one-out). Thus,
F =

[ [
uU lLA

=

FI =

{fu,l }

[

[

k [ [
[
i=1 tTi lLi

{ip,1 }
{ip,2 }
pP
pP2 P4 P5
[ [
uU lLA

{fu,l }



{ft,l },

[
pP5

k [ [
[
i=1 tTi lLi

{ip,3 },

{ft,l }

[
pP

{ip,1 }

[

{ip,2 }

pP2 P4 P5

[
pP5

{ip,3 }.

P
total number forks nf = |F | = |U | |LA | + ki=1 |Ti | |Li |, total number
inverted forks ni = |I | = |P1 | + 2 |P2 | + |P3 | + 2 |P4 | + 3 |P5 |. action
A, number representatives abstract task, well cost assigned
representative, given Figure 12. row tables Figure 12
corresponds certain Logistics action, column (except last three) represents
abstract task, entry captures number representatives action
corresponding task. last three columns show portion total cost
given action representative task, three heuristics question.
9.2.2 Lower Bound
Note optimal plan Logistics task contains least many load/unload
actions move actions. Thus, following lemma provides us lower bound
1/2 three heuristics question.

93

fiKatz & Domshlak

Lemma 1 Logistics task, hF , hI , hFI account full cost load/unload
actions required optimal plan task.
Proof: Logistics task, optimal plans task contain amount
load/unload actions package p P follows.

p P1 :

2 actions one load onto airplane, one unload airplane,

p P2 : 4 actions one load onto airplane, one unload airplane, one load
onto truck, one unload truck,
p P3 :

2 actions one load onto truck, one unload truck,

p P4 : 4 actions one load onto truck, one unload truck, one load onto
airplane, one unload airplane,
p P5 : 6 actions two loads onto trucks, two unloads trucks, one load
onto airplane, one unload airplane.
Consider fork-decomposition F . optimal plan abstract tasks
contain number load/unload actions exactly (the effects actions
remain unchanged tasks). cost representative load/unload
action n1f , nf abstract tasks. Therefore, heuristic hF fully accounts
cost required load/unload actions.
consider fork-decomposition . domain-decomposition
index abstraction, optimal plan abstract task ip,m include one load
one unload actions follows.
p P1 :

one load onto airplane one unload airplane,

p P2 , = 1:

one load onto airplane one unload airplane,

p P2 , = 2:

one load onto truck one unload truck,

p P3 :

one load onto truck one unload truck,

p P4 , = 1:

one load onto truck one unload truck,

p P4 , = 2:

one load onto airplane, one unload airplane,

p P5 , = 1:

one load onto truck one unload truck,

p P5 , = 2:

one load onto airplane one unload airplane,

p P5 , = 3:

one load onto truck one unload truck.

cost representative load/unload actions 1, thus heuristic hI fully
accounts cost required load/unload actions.
Finally, consider fork-decomposition FI . optimal plan forkstructured abstract tasks contain number load/unload actions F .
cost representative load/unload actions nf1+1 nf abstract
tasks. addition, load/unload actions also appear exactly one inverted
fork-structured abstract task. Therefore heuristic hFI also fully accounts cost
required load/unload actions.

94

fiImplicit Abstraction Heuristics

t1
p1

t2

...

pn

p1

Gtf1

t1

...

t2

pn

p
Gpi , p P

Gtf2

Figure 13: Collection v-forks v-iforks Logistics task used proof
upper bound 1/2

9.2.3 Upper Bound
instance three heuristics achieve exactly 1/2 consists two trucks t1 , t2 ,
airplanes, one city, n packages initial goal locations packages
pairwise different, trucks initially located yet another location.
+
formally, L = {li }2n
i=0 , = {t1 , t2 }, sas encoding Logistics task
follows.
Variables V = {t1 , t2 , p1 , . . . , pn } domains
: D(t) = L,

p P : D(p) = L T.
Initial state = {t1 : l0 , t2 : l0 , p1 : l1 , . . . , pn : ln }.
Goal G = {p1 : ln+1 , . . . , pn : l2n }.
Actions = {Lt(p, t, l), U t(p, t, l) | l L, T, p P } {M t(t, l, l0 ) | T, {l, l0 }
L}.
collection v-forks v-iforks task depicted Figure 13. domains
inverted-fork sinks abstracted Eq. 15 (distance-from-initial-value),
domains fork roots abstracted Eq. 16 (leave-one-out), therefore

F = {ft1 ,l ft2 ,l | l L},
= {ip,1 | p P },

FI = {ft1 ,l ft2 ,l | l L} {ip,1 | p P }.
total number forks thus nf = 4n + 2 total number inverted forks
ni = n. partition action costs Logistics tasks described Figure 12.
P = P3 thus action cost partition follows.
ft,l

Action
0

t(t, l, l )
Lt(p, t, l)
U t(p, t, l)

1
1
1

ft,l0
1
1
1

ft,l00
0
1
1

ft0 ,l
0
1
1

95

ip,1
1
1
1

ip0 ,1

F



FI

0
0
0

1
2
1
4n+2
1
4n+2

1
n

1
n+2
1
4n+3
1
4n+3

1
1

fiKatz & Domshlak

Given that, optimal plans abstract task
h

task

hF

ft1 ,l
ft2 ,l
ipi ,1
ft1 ,l
ft2 ,l
ipi ,1

hI
hFI

optimal plan
hLt(p1 , t2 , l1 ), . . . , Lt(pn , t2 , ln ), U t(p1 , t2 , ln+1 ), . . . , U t(pn , t2 , l2n )i
hLt(p1 , t1 , l1 ), . . . , Lt(pn , t1 , ln ), U t(p1 , t1 , ln+1 ), . . . , U t(pn , t1 , l2n )i
hM t(t1 , l0 , li ), Lt(pi , t1 , li ), t(t1 , li , ln+i ), U t(pi , t1 , ln+i )i
hLt(p1 , t2 , l1 ), . . . , Lt(pn , t2 , ln ), U t(p1 , t2 , ln+1 ), . . . , U t(pn , t2 , l2n )i
hLt(p1 , t1 , l1 ), . . . , Lt(pn , t1 , ln ), U t(p1 , t1 , ln+1 ), . . . , U t(pn , t1 , l2n )i
hM t(t1 , l0 , li ), Lt(pi , t1 , li ), t(t1 , li , ln+i ), U t(pi , t1 , ln+i )i

cost

#

2n
4n+2
2n
4n+2
2
+2
n
2n
4n+3
2n
4n+3

2n + 1
2n + 1
n
2n + 1
2n + 1
n

2
n+2

+

2
4n+3

h(I)
2n
2n + 2
2n +

2n
n+2

optimal plan original task, e.g., hM t(t1 , l0 , l1 ), Lt(p1 , t1 , l1 ), t(t1 , l1 , l2 ), Lt(p2 , t1 , l2 ),
t(t1 , l2 , l3 ), . . . , Lt(pn , t1 , ln ), t(t1 , ln , ln+1 ), U t(p1 , t1 , ln+1 ), t(t1 , ln+1 , ln+2 ), U t(p2 , t1 , ln+2 ),
t(t1 , ln+2 , ln+3 ), . . . , U t(pn , t1 , l2n )i,

cost 4n, providing us upper bound
1/2 three heuristics. Putting lower upper bounds together, asymptotic
ratio three heuristics question 1/2.
9.3 Blocksworld
Blocksworld task consists table table, crane c, n + 1 blocks B =
{b1 , . . . , bn+1 }. block either table, top block,
held crane. crane pick block currently holds nothing,
block block top it. crane drop held block table
top block.
Consider Blocksworld task follows. blocks initially form tower
b1 , . . . , bn , bn+1 bn+1 table, goal move form
tower b1 , . . . , bn1 , bn+1 , bn bn table. is, goal swap
lowest two blocks tower. natural description task sas+ follows.
Variables V = {b, clearb | b B} {c} domains
D(c) = {empty} B,

b B : D(b) = {table, c} B \ {b},
D(clearb ) = {yes, no}.

Initial state
= {c : empty, bn+1 : table, clearb1 : yes}
[
{bi : bi+1 | 1 n}

[

{clearb : | b B \ {b1 }} .
Goal G = {bn : table, bn+1 : bn , bn1 : bn+1 } {bi : bi+1 | 1 n 2}.
Actions = {PT (b), DT (b) | b B} {P (b, b0 ), D(b, b0 ) | {b, b0 } B}
pick block b table: PT (b) = h{c : empty, b : table, clearb : yes}, {cb, b : c}i,
pick block b block b0 :
P (b, b0 ) = h{c : empty, b : b0 , clearb : yes, clearb0 : no}, {c : b, b : c, clearb0 : yes}i,
96

fiImplicit Abstraction Heuristics

c

clearb1 . . . clearbn+1

c
b
Gbi , b {bn1 , bn , bn+1 }

clearb0

clearb

c
b0

b

bn1

bn

clearb
bn+1

bn1

Gcf
(a)

bn

bn+1

f
Gclear
,b B
b

(b)

Figure 14: (a) Causal graph (b) corresponding collection v-forks v-iforks
Blocksworld task used proof

drop block b table: DT (b) = h{c : b, b : c}, {c : empty, b : table}i,
drop block b block b0 :
D(b, b0 ) = h{c : b, b : c, clearb0 : yes}, {c : empty, b : b0 , clearb0 : no}i.

schematic version causal graph task depicted Figure 14a. Since
variables bn1 , bn , bn+1 goal values different values initial
state, collection v-forks v-iforks Figure 14b. (leave-one-out,
Eq. 16) domain abstraction variable c, c-fork Gcf breaks n + 2 abstract
tasks. sinks v-iforks Gbi n1 , Gbi n , Gbi n+1 also go process domain
decomposition (distance-from-initial-value, Eq. 15). However, due structure
domain transition graphs block variables, domain decomposition results
single abstract task v-iforks. Thus
F ={fc,empty } {fc,b | b B} {fclearb | b B},
={ibn1 ,1 , ibn ,1 , ibn+1 ,1 },

FI ={fc,empty } {fc,b | b B} {fclearb | b B} ibn1 ,1 , ibn ,1 , ibn+1 ,1 }.
technically straightforward verify that, abstract task F , , FI ,
exists plan (i) involves representatives actions
{P (bn1 , bn ), DT (bn1 ), P (bn , bn+1 ), DT (bn ), PT (bn+1 ), D(bn+1 , bn ), PT (bn1 ), D(bn1 , bn+1 )} ,
(21)
(ii) involves representative original action once. Even together
plans account total cost eight actions Eq. 21, total cost
plans (and thus estimates three heuristics) upper-bounded 8,
optimal plan original task, e.g., hP (b1 , b2 ), DT (b1 ), P (b2 , b3 ), DT (b2 ), . . . , P (bn , bn+1 ), DT (bn ),
PT (bn+1 ), D(bn+1 , bn ), PT (bn1 ), D(bn1 , bn+1 ), PT (bn2 ), D(bn2 , bn1 ), . . . , PT (b1 ), D(b1 , b2 )i, cost
97

fiKatz & Domshlak

e

p1



e
p1

pn

Gef

(a)

e
pn

(b)

p
Gpi , p P

Figure 15: Miconics (a) causal graph (b) corresponding collection v-forks
v-iforks

4n. Hence, asymptotic performance ratio three heuristics Blocksworld
domain 0.
9.4 Miconic
Miconic task consists one elevator e, set floors F , passengers P .
elevator move |F | floors floor load and/or unload passengers.
natural sas+ description Miconic task follows.
Variables V = {e} P domains
D(e) = F,

p P : D(p) = F {e}.
Initial state = {e : fe } {p : fp | p P } (F )|P |+1 .
Goal G = {p : fp0 | p P } (F )|P | .
Actions = {In(p, f ), Out(p, f ) | f F, p P } {M ove(f, f 0 ) | {f, f 0 } F },
load passenger p e floor f : In(p, f ) = h{e : f, p : f }, {p : e}i,
unload passenger p e floor f : Out(p, f ) = h{e : f, p : e}, {p : f }i,
move elevator floor f floor f 0 : ove(f, f 0 ) = h{e : f }, {e : f 0 }i.
(parametrized n) causal graph Miconic tasks depicted Figure 15a,
Figure 15b depicts corresponding collection v-forks v-iforks. domains
inverted-fork sinks abstracted Eq. 15 (distance-from-initial-value),
domains fork roots abstracted Eq. 16 (leave-one-out). Thus,
F = {fe,f | f F },
= {ip,1 | p P },

FI = {fe,f | f F } {ip,1 | p P }.
total number fork-structured abstract tasks thus nf = |F | = |F |
total number inverted fork structured abstract tasks ni = |I | = |P |.
action A, number representatives abstract task, well cost
assigned representative, given Table 7.
98

fiImplicit Abstraction Heuristics

Action
ove(f, f 0 )
In(p, f )
In(p0 , f )
Out(p, f )
Out(p0 , f )

fe,f fe,f 0 fe,f 00 ip,1 ip0 ,1 F FI
1
1
1
1
1

1
1
1
1
1

0
1
1
1
1

1
1
0
1
0

1
0
1
0
1

1
2
1
nf
1
nf
1
nf
1
nf

1
1
ni 2+ni
1 nf1+1
1 nf1+1
1 nf1+1
1 nf1+1

Table 7: Number representatives original Miconic action abstract task,
well partition action costs among representatives

9.4.1 Lower Bounds
First, Miconic special case Logistics domain, Lemma 1 applies analogously, package P3 corresponding passenger. Thus, p P ,
three heuristics account full cost load/unload actions required optimal
plan task.
Let us focus abstract tasks F = {fe,f | f F }. Recall task fe,f
induced e-fork and, terms domain decomposition, distinguishes
floor f somewhere else. Without loss generality, set floors F
restricted initial goal values variables, optimal
plan move elevator floor f neither initial goal location
passenger elevator. Let FI = {I[p] | p P } FG = {G[p] | p P }. costs
optimal plans abstract task fe,f follows.
f FI FG : Let p, p0 P pair passengers initial goal locations f ,
respectively; is, I[p] = G[p0 ] = f . f = I[e], plan fe,f move
elevator f order load passenger p0 , move elevator back
f order unload passenger p0 . Therefore cost plan fe,f
|
least 2|P
|F | + 1, (see last three columns Table 7) first component
summation comes summing costs representatives load/unload
actions passengers, second component sum costs
representatives two respective move actions. Similarly, f 6= I[e],
plan fe,f move elevator f order load passenger p,
move elevator f order unload p. Therefore, well, cost
|
plan fe,f least 2|P
|F | + 1.

f FI \ FG : Let p P passenger initially f , is, I[p] = f . f = I[e],
plan fe,f move elevator f order unload p, thus
cost plan fe,f least

2|P |
|F |

+ 12 . Otherwise, f 6= I[e], plan

fe,f move elevator f order load p, move elevator
f order unload p. Hence, case, cost plan fe,f
least

2|P |
|F |

+ 1.
99

fiKatz & Domshlak

f FG \ FI : Let p P passenger must arrive floor f , is, G[p] = f .
f = I[e], plan fe,f move elevator f order load p,
move elevator back f order unload p. Hence, well,
|
cost plan fe,f least 2|P
|F | + 1. Otherwise, f 6= I[e], plan

fe,f move elevator f order unload p, thus cost plan

fe,f least

2|P |
|F |

+ 12 .

f 6 FG FI : f = I[e], plan fe,f include move f order

|
1
load/unload passengers, thus cost plan fe,f least 2|P
|F | + 2 .
Otherwise, f 6= I[e], elevator initially set locations,
|
thus cost plan fe,f least 2|P
|F | .

Putting case-by-case analysis together,

|FG \FI |

,
I[e] FI FG
2|P | + |FI FG | + |FI \ FG | +
2


2|P | + |F F | + |F \ F | 1 + 1 + |FG \FI | , I[e] F \ F

G

G

G
2
2
.
hF (I)
|FG \FI |1

2|P
|
+
|F

F
|
+
|F
\
F
|
+
1
+
,
I[e]

F
\
F

G

G
G


2


2|P | + |F F | + |F \ F | + |FG \FI |1 + 1 ,
I[e] 6 FG FI

G

G
2
2

Note value second case lowest. gives us lower bound hF
estimate Eq. 22.
|FG \ FI |
1
+ |FI FG | .
(22)
2
2
Now, let us provide upper bound length (= cost) optimal plan
Miconic task. First, let P 0 P denote set passengers initial goal
locations FI FG . Let m(P 0 , FI FG ) denote length optimal traversal
floors FI FG that, passenger p P 0 , visit I[p] comes visit
G[p]. Given that, case-by-case basis, (not necessarily optimal) plan Miconic
task hand follows.
hF (I) 2|P | + |FI \ FG | +

I[e] FI FG : Collect passengers I[e] any, traverse floors
FI \ FG collect passengers floors, move elevator first
floor f optimal path traversing floors FI FG , drop passengers
whose destination f , collect new passengers any, keep moving along
collecting dropping passengers initial target floors,
traverse FG \ FI , dropping remaining passengers destinations.
cost plan (and thus optimal plan) upper-bounded Eq. 23
below.
h (I) 2|P | + |FI \ FG | + m(P 0 , FI FG ) + |FG \ FI |.
(23)
I[e] FI \ FG : Collect passengers I[e] any, traverse floors
FI \ FG collect passengers floors making sure traversal
ends first floor f optimal path traversing floors FI FG ,
follow collecting dropping passengers initial target floors,
traverse FG \ FI , dropping remaining passengers destinations.
first case, cost plan upper-bounded Eq. 23.
100

fiImplicit Abstraction Heuristics

I[e] 6 FI : Traverse floors FI \ FG collect passengers floors,
move along optimal path traversing floors FI FG collecting
dropping passengers initial target floors, traverse floors
FG \ FI , dropping remaining passengers destinations. well,
cost plan upper-bounded expression Eq. 23.
Lemma 2 Miconic task passengers P ,

hF (I)
h (I)



5|P |1
6|P | .

Proof: Recall P 0 P set passengers initial goal locations
FI FG . First give two upper bounds length optimal traversal
floors FI FG that, passenger p P 0 , visit I[p] comes visit
G[p]. Theorem 5.3.3 Helmert (2008)
m(P 0 , FI FG ) = |FI FG | + (G 0 ),

(24)

(G 0 ) size minimum feedback vertex set directed graph G 0 =
(V 0 , E 0 ), V 0 = FI FG E 0 containing arc f f 0 passenger
p P 0 initially floor f arrive floor f 0 .
Note (G 0 ) trivially bounded number graph nodes V 0 . addition,
observe that, order nodes V 0 , arcs E 0 partitioned forward
0
backward arcs, one subsets must contain |E2 | arcs. Removing
G 0 nodes origins arcs smaller subset E 0 results
directed acyclic graph. Hence, set removed nodes (not necessarily minimum)
0
feedback vertex set G 0 , size set larger |E2 | . Putting two
bounds (G 0 ) together Eq. 24 obtain


|P 0 |
0
m(P , FI FG ) min 2|FI FG |, |FI FG | +
.
(25)
2
disjointness FG \ FI FI FG , fact goal
passengers P 0 FI , |FG \ FI | |P | |P 0 |. Eqs. 22 23
2|P | + |FI \ FG | + |FG2\FI | + |FI FG | 12
hF

.
h
2|P | + |FI \ FG | + |FG \ FI | + m(P 0 , FI FG )

(26)

F

interested lower bound ratio hh , right-hand side
inequality minimized, thus safely set |FI \ FG | = 0 |FG \ FI | =
|P | |P 0 |, obtaining
0

|
2|P | + |P ||P
+ |FI FG | 12
hF
5|P | |P 0 | + 2|FI FG | 1
2

=
.
h
2|P | + |P | |P 0 | + m(P 0 , FI FG )
6|P | 2|P 0 | + 2m(P 0 , FI FG )

(27)

Let us examine right-most expression Eq. 27 respect two upper bounds
m(P 0 , FI FG ) Eq. 25.

minimum obtained 2|FI FG |, m(P 0 , FI FG ) 2|FI FG |
0
|FI FG | + |P2 | , last inequality reformulated
2|FI FG | |P 0 | 0.
101

fiKatz & Domshlak

allows us provide lower bound right-most expression Eq. 27,
F
thus hh
hF
5|P | |P 0 | + 2|FI FG | 1
5|P | + (2|FI FG | |P 0 |) 1
5|P | 1



.
h
6|P | 2|P 0 | + 2m(P 0 , FI FG )
6|P | + 2(2|FI FG | |P 0 |)
6|P |
(28)
0

0

minimum obtained |FI FG |+ |P2 | , m(P 0 , FI FG ) |FI FG |+ |P2 | <
2|FI FG |, last inequality reformulated
2|FI FG | |P 0 | > 0.
allows us provide lower bound

hF
h

via Eq. 27

5|P | |P 0 | + 2|FI FG | 1
5|P | + (2|FI FG | |P 0 |) 1
5|P | 1
hF



.

0
0
0
h
6|P | 2|P | + 2m(P , FI FG )
6|P | + (2|FI FG | |P |)
6|P |
(29)
Note lower bounds
lemma.

hF
h

Eq. 28 Eq. 29 required claim


9.4.2 Upper Bounds
Miconic task heuristic hF achieves performance ratio exactly 5/6
consists elevator e, floors F = {fi }ni=0 , passengers P = {pi }ni=1 , passengers
elevator initially f0 , target floors passengers pairwise
disjoint. sas+ encoding Miconic task follows.
Variables V = {e} P domains D(e) = F p P : D(p) = F {e}.
Initial state = {e : f0 , p1 : f0 , . . . , pn : f0 }.
Goal G = {p1 : f1 , . . . , pn : fn }.
Actions = {In(p, f ), Out(p, f ) | f F, p P } {M ove(f, f 0 ) | {f, f 0 } F }.
causal graph task corresponding collection v-forks (consisting
one e-fork) depicted Figure 15. domain e abstracted Eq. 16
(leave-one-out), providing us
F = {fe,f0 , fe,f1 , . . . , fe,fn }.
costs action representatives abstract tasks given Table 7
nf = n + 1. optimal plans abstract tasks F
task optimal plan
fe,f0
fe,f1
fe,fn

cost

hIn(p1 , f0 ), . . . , In(pn , f0 ), ove(f0 , f1 ), Out(p1 , f1 ), . . . , Out(pn , fn )i
hIn(p1 , f0 ), . . . , In(pn , f0 ), Out(p2 , f2 ), . . . , Out(pn , fn ), ove(f0 , f1 ), Out(p1 , f1 )i
hIn(p1 , f0 ), . . . , In(pn , f0 ), Out(p1 , f1 ), . . . , Out(pn1 , fn1 ), ove(f0 , fn ), Out(pn , fn )i

102

1
2
1
2
1
2

+
+
+

2n
n+1
2n
n+1
2n
n+1

#

hF (I)

n+1

5n+1
2

fiImplicit Abstraction Heuristics

optimal plan original task, hIn(p1 , f0 ), . . . , In(pn , f0 ), ove(f0 , f1 ), Out(p1 , f1 ),
cost 3n, providing us
F
upper bound 5/6 h heuristic Miconic. Putting upper bound together
previously obtained lower bound 5/6, conclude asymptotic performance
ratio hF Miconic 5/6.
Miconic task heuristics hI hFI achieve exactly 1/2 consists
n
elevator e, floors F = {fi }2n
i=0 , passengers P = {pi }i=1 , initial target floors
passengers elevator pairwise disjoint. task description sas+
follows.
ove(f1 , f2 ), Out(p2 , f2 ), ove(f2 , f3 ), . . . , Out(pn , fn )i,

Variables V = {e} P domains D(e) = F p P : D(p) = F {e}.
Initial state = {e : f0 , p1 : f1 , . . . , pn : fn }.
Goal G = {p1 : fn+1 , . . . , pn : f2n }.
Actions = {In(p, f ), Out(p, f ) | f F, p P } {M ove(f, f 0 ) | {f, f 0 } F }.
causal graph task corresponding collection v-forks v-iforks
depicted Figure 15. domains inverted-fork sinks abstracted Eq. 15
(distance-from-initial-value), domains fork roots abstracted
Eq. 16 (leave-one-out). provides us
= {ip1 ,1 , . . . , ipn ,1 },

FI = {fe,f0 , fe,f1 , . . . , fe,fn , fe,fn+1 , . . . , fe,f2n , ip1 ,1 , . . . , ipn ,1 }.
costs action representatives abstract tasks given Table 7
nf = 2n + 1 ni = n. optimal plans abstract tasks FI
h

task

optimal plan

hI

ipi ,1
fe,f0

hM ove(f0 , fi ), In(pi , fi ), ove(fi , fn+i ), Out(pi , fn+i )i
hM ove(f0 , f1 ), In(p1 , f1 ), . . . , In(pn , fn ),
Out(p1 , fn+1 ), . . . , Out(pn , f2n )i
hM ove(f0 , f1 ), In(p1 , f1 ), ove(f1 , f2 ), In(p2 , f2 ), . . . , In(pn , fn ),
Out(p1 , fn+1 ), . . . , Out(pn , f2n )i
hM ove(f0 , fn ), In(pn , fn ), ove(fn , f1 ),
In(p1 , f1 ), . . . , In(pn1 , fn1 ), Out(p1 , fn+1 ), . . . , Out(pn , f2n )i
hIn(p1 , f1 ), . . . , In(pn , fn ), Out(p2 , fn+2 ), . . . , Out(pn , f2n ),
ove(f0 , fn+1 ), Out(p1 , fn+1 )i
hIn(p1 , f1 ), . . . , In(pn , fn ), Out(p1 , fn+1 ), . . . , Out(pn1 , f2n1 ),
ove(f0 , f2n ), Out(pn , f2n )i
hM ove(f0 , fi ), In(pi , fi ), ove(fi , fn+i ), Out(pi , fn+i )i

hFI

fe,f1
fe,fn
fe,f

n+1

fe,f2n
ipi ,1

cost

#

h(I)

n
1

2n + 2

1
n+2

+2
2n
+ 2n+2

2
n+2

+

2n
2n+2

n

2
n+2

+

2n
2n+2

1
n+2

+

2n
2n+2

1
n+2

+

2n
2n+2

2
n+2

+

2
2n+2

2
n

2n +

5n+1
n+2

n

n

optimal plan original task, hM ove(f0 , f1 ), In(p1 , f1 ), ove(f1 , f2 ), In(p2 , f2 ),
ove(f2 , f3 ), . . . , In(pn , fn ), ove(fn , fn+1 ), Out(p1 , fn+1 ), ove(fn+1 , fn+2 ), Out(p2 , fn+2 ),
ove(fn+2 , fn+3 ), . . . , Out(pn , f2n )i, cost 4n, providing us upper bound
1/2 hI hFI heuristics Miconic. Putting upper bound together
previously obtained lower bound 1/2, conclude asymptotic performance ratio
hI hFI Miconic 1/2.

103

fiKatz & Domshlak

9.5 Satellite
Satellite domain quite complex. Satellite tasks
consists satellites S,
finite set instruments onboard, = sS . set image
modes M, mode M, set Im instruments supporting
mode m. Likewise, set directions L, image objectives LM, functions
cal : 7 L, p0 : 7 L, p : S0 7 L S0 S, cal calibration target
direction function, p0 initial direction function, p goal pointing direction
function.
Let us denote Oi = {o = (d,Sm) | Im } subset images
taken instrument i, Os = iIs Oi subset images taken
instruments satellite s, Sm = {s | Im 6= } subset satellites
take images mode m. problem description sas+ follows.
Variables V = {Oni , Ci | I} domains
: D(s) = L,

: D(Oni ) = D(Ci ) = {0, 1},
: D(o) = {0, 1}.

Initial state = {s : p0 (s) | S} {Oni : 0, Ci : 0 | I} {o : 0 | O}.
Goal G = {s : p (s) | S0 } {o : 1 | O}.
Actions
[

A=
{T urn(s, d, d0 ) | {d, d0 } L} {SwOn(i, s), Cal(i, s), SwOf f (i) | }
sS

{T akeIm(o, d, s, i) | = (d, m) O, Sm , Im },

turn satellite: urn(s, d, d0 ) = h{s : d}, {s : d0 }i,

power instrument: SwOn(i, s) = h{Oni0 : 0 | i0 }, {Oni : 1}i,
power instrument: SwOf f (i) = h{Oni : 1}, {Oni : 0, Ci : 0}i,

calibrate instrument: Cal(i, s) = h{Ci : 0, Oni : 1, : cal(i)}, {Ci : 1}i,
take image: akeIm(o, d, s, i) = h{o : 0, Ci : 1, : d}, {o : 1}i.

9.5.1 Fork Decomposition
causal graph example Satellite task representative subset collection
v-forks v-iforks depicted Figure 16. Since variables {Oni , Ci | I}S \S0
goal value, collection v-forks v-iforks follows general
case.
satellite S, s-fork leaves Os .
104

fiImplicit Abstraction Heuristics

o1

o2

o3

o4

s1

C3

s2

s2

C1

C2

C4

On1

On2

On3

On4

C5

C7

o1

C6

o3

C5
o4

Gsf 2
s1

o3

C6
o1

f
GC
5
s2

C2

C7
o3

f
GC
6
C4

o4
f
GC
7

C7

On7
o4
On5

On6

(a)

Goi 4
(b)

Figure 16: Satellite example task (a) causal graph (b) representative subset
collection v-forks v-iforks

instrument I, Ci -fork leaves Oi .
image objective = (d, m) O, o-ifork parents {Ci | Im }Sm .
root domains forks rooted instruments inverted-fork sinks
binary first place, root domains forks rooted satellites
abstracted Eq. 16 (leave-one-out). provides us
F = {fs,d | S, L} {fCi | I},
= {io | O},

FI = {fs,d | S, L} {fCi | I} {io | O}.
total number forks thus nf = |S| |L| + |I| total number inverted
forks ni = |O|. action A, number representatives abstract
task, well cost assigned representative, given Figure 17.
9.5.2 Lower Bounds
First, note optimal plan Satellite task contains 6 actions per image
objective one action per satellite S0 I[s] 6= G[s]. show
three heuristics fully account cost least one action per image
objective one action per satellite. provide us lower
bound 1/6 asymptotic performance ratios three heuristics.
Lemma 3 Satellite task, hF , hI , hFI fully account cost least
one Take Image action akeIm(o, d, s, i) image objective O.
Proof: image objective = (d, m) O, actions akeIm(o, d, s, i) = h{o :
0, Ci : 1, : d}, {o : 1}i appear optimal plans |Sm | |L| fork abstract tasks rooted
105

fiKatz & Domshlak

fs,d

Action
0

urn(s, d, )
SwOn(i, s)
Cal(i, s)
SwOf f (i)

1
0
0
0

fs,d0
1
0
0
0

fs,d00

fs0 ,d

0
0
0
0

0
0
0
0

fCi
0
0
1
1

fCi0
0
0
0
0

Oi Os \ Oi 6 Os
io
io
io
F
1
0
1
1

1
0
0
0

1
2

0
0
0
0

0
1
1

1
|O |

FI
1
|O |+2

0

0

1
|Oi |
1
|Oi |

1
|Oi |+1
1
|Oi |+1

(a)

Action
akeIm(o, d, s, i),
= (d, m)

s0 Sm s0 6 Sm i0 Im i0 6 Im
fs0 ,d0
fs0 ,d0
fCi0
fCi0
io io0
1

0

1

0

1

0

F



FI

1
|Sm ||L|+|Im |

1

1
|Sm ||L|+|Im |+1

(b)
Figure 17: Number representatives original Satellite action abstract
task, well partition action costs representatives;
table (a) shows Turn, Switch On, Switch Off, Calibrate actions,
table (b) shows Take Image actions

satellites, |Im | fork abstract tasks rooted instrument calibration status variables Ci ,
one inverted-fork abstract task sink o. Together costs action
representatives abstract problems (see Figure 17),
hF : cost representative
tasks,

1
|Sm ||L|+|Im |

|Sm | |L| + |Im | fork abstract

hI : cost representative 1 one inverted fork abstract task,
hFI : cost representative
tasks.

1
|Sm ||L|+|Im |+1

|Sm | |L| + |Im | + 1 abstract

Therefore, O, cost one akeIm(o, d, s, i) action fully accounted
three heuristics.

Lemma 4 Satellite task, hF , hI , hFI fully account cost least
one Turn action urn(s, d, d0 ) S0 I[s] 6= G[s].
Proof: S0 satellite I[s] 6= G[s], action urn(s, I[s], d0 ) appear
optimal plan fs,I[s] , action urn(s, d, G[s]) appear optimal plan
fs,G[s] , Os , action urn(s, d, G[s]) appear optimal plan
io . Together costs action representatives abstract problems (see
Figure 17)
hF : cost representative

1
2

2 fork abstract tasks,
106

fiImplicit Abstraction Heuristics

hI : cost representative
hFI : cost representative

1
|Os |

|Os | inverted fork abstract tasks,

1
|Os |+2

|Os | + 2 abstract tasks.

Therefore, S0 I[s] 6= G[s], cost one urn(s, d, d0 ) action
fully accounted three heuristics.

h
h

Together, Lemmas 3 4 imply that, h {hF , hI , hFI }, Satellite
1/6.

9.5.3 Upper Bound
Satellite task three heuristics achieve ratio exactly 1/6 consists
two identical satellites = {s, s0 } l instruments each, = Is0 = {1, . . . , l} {l +
1, . . . , 2l}, instruments {i, l+i} two modes each: m0 mi . set
n + 1 directions L = {dI , d1 , . . . , dn } set n image objectives = {o1 , . . . , }, oi =
(dI , mi ) 1 l oi = (di , m0 ) l < n. calibration direction
instruments {i, l + i} di . sas+ encoding planning task follows.
Variables V = {Oni , Ci | I}.
Initial state = {s : dI | S} {Oni : 0, Ci : 0 | I} {o : 0 | O}.
Goal G = {o : 1 | O}.
Actions
[

A=
{T urn(s, d, d0 ) | {d, d0 } L} {SwOn(i, s), Cal(i, s), SwOf f (i) | }
sS


[
sS

{T akeIm((dI , mi ), dI , s, i) | }

n
[


{T akeIm((dj , m0 ), dj , s, i) | } .

j=l+1

causal graph task depicted Figure 18a. state variables {Oni , Ci |
I} goal value, thus collection v-forks v-iforks task
Figure 18b. domains inverted-fork sinks binary, domains
fork roots abstracted Eq. 16 (leave-one-out). provides us
F = {fs,d , fs0 ,d | L} {fCi | I},
= {io | O},

FI = {fs,d , fs0 ,d | L} {fCi | I} {io | O}.
total number forks task nf = 2n + 2l + 2 total number inverted
forks ni = n. costs action representatives abstract task given
0
Figure 17, |Os | = |Os | = |O| = n, |Oi | = n l + 1, |Sm | = 2, |Im0 | = 2l, |Imi | = 2,
|L| = n + 1.
optimal plans per abstract task depicted Table 8, optimal plan
original problem, hSwOn(1, s), urn(s, dI , d1 ), Cal(1, s), urn(s, d1 , dI ), akeIm(o1 , dI , s, 1),
107

fiKatz & Domshlak

s0


o1

C1

ok

oi

Cl+1

Cl

Ci

ol+1



s0

o1 . . .

o1 . . .

Gsf

Gsf 0

Cl+i

C2l


Oni

On1

Ci



s0

Ci

oi

ol+1 . . .
f
GC
,i




Cl+i

s0

C1 . . . C2l

Onl+i

Onl

Onl+1

On2l

oi

oi

Goi , 1 l

Goi , l < n

(a)

(b)

Figure 18: (a) Causal graph (b) corresponding collection v-forks v-iforks
Satellite task used proof upper bound 1/6

h

hF

hI

hFI

task

optimal plan

cost

hT akeIm(o1 , dI , s0 , l+1), . . . , akeIm(ol , dI , s0 , 2l),
fs,d
akeIm(ol+1 , dl+1 , s0 , 2l), . . . , akeIm(on , dn , s0 , 2l)i
hT akeIm(o1 , dI , s, 1), . . . , akeIm(ol , dI , s, l),
f
s0 ,d
akeIm(ol+1 , dl+1 , s, l), . . . , akeIm(on , dn , s, l)i
hT akeIm(oi , dI , s0 , l + i),
f
Ci ,
akeIm(ol+1 , dl+1 , s0 , 2l), . . . , akeIm(on , dn , s0 , 2l)i
hT akeIm(oi , dI , s, i),
fCi , Is0
akeIm(ol+1 , dl+1 , s, l), . . . , akeIm(on , dn , s, l)i
ioj , 1 j l hT urn(s, dI , dj ), Cal(j, s), urn(s, dj , dI ), akeIm(oj , dI , s, j)i
ioj , l < j n hT urn(s, dI , d1 ), Cal(1, s), urn(s, d1 , dj ), akeIm(oj , dI , s, 1)i
hT akeIm(o1 , dI , s0 , l + 1), . . . , akeIm(ol , dI , s0 , 2l),
fs,d
akeIm(ol+1 , dl+1 , s0 , 2l), . . . , akeIm(on , dn , s0 , 2l)i
hT akeIm(o1 , dI , s, 1), . . . , akeIm(ol , dI , s, l),
f
s0 ,d
akeIm(ol+1 , dl+1 , s, l), . . . , akeIm(on , dn , s, l)i
hT akeIm(oi , dI , s0 , l + i),
f
Ci ,
akeIm(ol+1 , dl+1 , s0 , 2l), . . . , akeIm(on , dn , s0 , 2l)i
hT akeIm(oi , dI , s, i),
fCi , Is0
akeIm(ol+1 , dl+1 , s, l), . . . , akeIm(on , dn , s, l)i
ioj , 1 j l hT urn(s, dI , dj ), Cal(j, s), urn(s, dj , dI ), akeIm(oj , dI , s, j)i
ioj , l < j n hT urn(s, dI , d1 ), Cal(1, s), urn(s, d1 , dj ), akeIm(oj , dI , s, 1)i

#

l
2n+4

+

nl
2n+2l+2

n+1

l
2n+4

+

nl
2n+2l+2

n+1

1
2n+4

+

nl
2n+2l+2

l

nl
1
+ 2n+2l+2
2n+4
2
1
+ nl+1
+1
n
2
1
+
+1
n
nl+1

l
l
nl

h(I)

n

l
2n+5

+

nl
2n+2l+3

n+1

l
2n+5

+

nl
2n+2l+3

n+1

1
2n+5

+

nl
2n+2l+3

l

nl
1
+ 2n+2l+3
2n+5
2
1
+ nl+2 +
n+2
1
2n+5
2
1
+ nl+2
+
n+2
1
2n+2l+3

l

n + 2+
n
nl+1

n+

l

2n
n+2

+

n
nl+2

nl

Table 8: Optimal plans abstract tasks overall heuristic estimates
Satellite task used proof upper bound 1/6

SwOf f (1), . . . SwOn(l 1, s), urn(s, dI , dl1 ), Cal(l 1, s), urn(s, dl1 , dI ), akeIm(ol1 , dI , s, l 1),
SwOf f (l 1), SwOn(l, s), urn(s, dI , dl ), Cal(l, s), urn(s, dl , dI ), akeIm(ol , dI , s, l), urn(s, dI , dl+1 ),
akeIm(ol+1 , dl+1 , s, l), . . . , urn(s, dn1 , dn ), akeIm(on , dn , s, l)i,

108

cost 4l + 2n 1.

fiImplicit Abstraction Heuristics


l = n n, provides us asymptotic performance ratio 1/6 three
heuristics.

10. Summary
considered heuristic search cost-optimal planning introduced domain-independent
framework devising admissible heuristics using additive implicit abstractions.
implicit abstraction corresponds abstracting planning task hand instance
tractable fragment optimal planning. key motivation investigation escape restriction explicit abstractions, pattern-database merge-and-shrink
abstractions, abstract spaces fixed size. presented concrete scheme additive
implicit abstractions decomposing planning task along causal graph suggested
concrete realization idea, called fork-decomposition, based two novel fragments tractable cost-optimal planning. studied induced admissible heuristics
formally empirically, showed favorably compete informativeness
state-of-the-art admissible heuristics theory practice. empirical
evaluation stressed tradeoff accuracy heuristics runtime complexity computing them. alleviate problem expensive per-search-node runtime
complexity fork-decomposition heuristics, showed equivalent explicit
abstractions notion database exists also fork-decomposition abstractions,
despite exponential-size abstract spaces. subsequent empirical evaluation
heuristic search databases fork-decomposition heuristics showed
favorably competes state art cost-optimal planning.
basic principles implicit abstraction framework motivate research
numerous directions, importantly (i) discovering new islands tractability
optimal planning, (ii) abstracting general planning tasks islands. Likewise, promise combining implicit abstractions techniques deriving admissible heuristic estimates. first step towards combining implicit abstractions
polynomial-time discoverable landmarks planning tasks recently taken
Domshlak, Katz, Lefler (2010). believe various combinations techniques might well improve informativeness heuristics, without substantially increasing runtime complexity.

Acknowledgments
work authors partly supported Israel Science Foundation grants 670/07
1101/07.

109

fiKatz & Domshlak

Appendix A. Detailed Results Empirical Evaluation
hF
task

hI

h nodes time nodes

hFI
time nodes

time

MS-104

MS-105

nodes

nodes

time

HSPF

time

nodes

9
0.00
10
0.00
18
0.03
21
0.01
22
0.01
42
0.17
42
0.17
96231549.13
89525 466.14
19
0.01
22
0.01
40
0.21
38
0.21
8968 238.16
8931 267.81
3053401077.90

9
10
29
21
22
42
42
203
12956
19
22
40
38
62
59

time

blind
nodes time

hmax
nodes time

airport-ipc4
01
02
03
04
05
06
07
08
09
10
11
12
13
14
15
16
17
19
21
22
36

8
9
17
20
21
41
41
62
71
18
21
39
37
60
58
79
88
90
101
148
109

10 0.01
12 0.03
86 0.25
22 0.02
23 1.29
51336.72
51437.00

9 0.00
15 0.01
133 0.07
21 0.02
30 0.06
639 1.54
632 1.53
21544166.51

9 0.00
15 0.03
93 0.31
21 0.02
27 1.43
567 45.25
550 44.15

19 0.02
23 1.90
47554.18
43447.48

19 0.02
30 0.08
728 2.76
663 2.60
25110334.72
23317307.60

19 0.03
27 2.13
568 71.23
479 59.82

9 0.00
10 0.00
18 0.04
21 0.02
22 0.01
42 0.16
42 0.17
24372 25.42
152408 64.92
19 0.02
22 0.02
40 0.21
38 0.20
30637 51.23
28798 46.20
1031524200.95

7326372.92
1119943762.02
34365853.70

102

10.28

0.72
11 0.00
9 0.00
1.23
13 0.00
10 0.00
5.10
164 0.00
57 0.00
1.32
23 0.00
21 0.00
46.54
27 0.00
22 0.00
123.13
738 0.01
418 0.02
117.56
742 0.01
405 0.02
602.09 27032 0.28
9687 0.90
993.07 175717 2.47 56484 7.62
2.45
21 0.00
19 0.00
65.36
27 0.00
22 0.01
169.02
873 0.01
392 0.03
134.87
822 0.01
342 0.03
714.76 35384 0.39
9196 1.11
647.05 33798 0.38
8200 1.01
124746719.72 221993 49.03
1043661310.89
831632253.21
18809 0.42
3184 1.12
159967105.29
63061 1.44

blocks-ipc2
04-0
04-1
04-2
05-0
05-1
05-2
06-0
06-1
06-2
07-0
07-1
07-2
08-0
08-1
08-2
09-0
09-1
09-2
10-0
10-1
10-2
11-0
11-1
11-2
12-0
12-1
13-0
13-1
14-0
14-1

6
15 0.01
46 0.01
17 0.01
7 0.03
7
0.03
7
0.36
93 0.00
25 0.00
10
14 0.01
31 0.00
15 0.00
11 0.04
11
0.03
11
0.39
66 0.00
23 0.00
6
7 0.01
26 0.00
10 0.00
7 0.04
7
0.03
7
0.38
63 0.00
18 0.00
12
32 0.03
302 0.06
113 0.08
13 0.30
13
0.96
13
1.32
467 0.00
145 0.00
10
37 0.03
280 0.06
98 0.07
11 0.29
11
0.96
11
1.36
567 0.00
135 0.00
16
152 0.09
596 0.10
348 0.18
17 0.29
17
0.95
17
1.49
792 0.00
297 0.00
12
33 0.04
766 0.27
207 0.25
13 0.95
13
8.56
13
4.10
1826 0.00
276 0.00
10
41 0.07 2395 0.74
578 0.78
11 0.90
11
8.34
11
4.17
4887 0.01
755 0.01
20
855 0.80 5444 1.23 3352 2.88
733 0.87
85
8.84
31
4.29
6385 0.02
2556 0.03
20
278 0.56 20183 8.26 4022 8.18
577 1.93
144 23.32
22 11.47 37157 0.14
5943 0.11
22 691011.22 59207 17.37 38539 49.71
10071 1.70
1835 21.05
174 11.25 63376 0.21 33194 0.46
20 1458 2.85 46009 15.05 18854 29.61
1855 1.59
782 20.37
90 10.99 55218 0.19 18293 0.29
18 1533 4.79344157179.42 69830208.07
5557 3.67
678 36.80
25 26.00 519107 2.28 94671 2.07
20 1004027.97517514236.64191352475.33
45711 3.88
11827 33.49
151 26.57 636498 2.60 199901 3.85
16
479 1.79237140136.18 32567110.76
277 3.63
54 32.53
17 25.85 433144 1.93 52717 1.30
30
1233374 16.00 971409 77.74
464 56.76798464936.763840589 85.00
28 343518.17
95068 7.35
58873 63.15
82 56.98591457229.731200345 32.06
26 637935.22
161719 13.54
20050 82.45
81 57.02596316030.021211463 32.15
34
1800 114.26
32
12063665 228.76
1835 115.19
34
3685 116.75
32
7046739 141.44
2678 213.32
30
1510 203.79
34
3984 213.97
34
1184 370.06
34
614 382.34
42
83996 860.45
44
1634381104.27
38
27791063.02
36
71541087.40

depots-ipc3
01
02
03
04
07
10
13

10
15
27
30
21
24
25

114 0.24
113410.82

279 0.11
9344 12.40

161 0.32
2638 22.68

11 0.00
11
0.00
45
0.77
329 0.00
136 0.00
738 3.24
16
1.14
898 11.56 15404 0.11
3771 0.17
348288 20.69 239313 222.35 103089 247.13293039827.201204646 97.62
1284048 52.05 1273762 529.34
211820 37.54
41328 324.19650110071.581331701166.76
3241083157.52
1427824116.06

grid-ipc1
01
02

14
26

57160.28

1117

9.49

472 55.87

660 8.63
467 121.10
3392724 50.35 3244132 241.94

6446 0.08

190 0.10
664016231.26

Table 9: Runtimes cost-optimal heuristic-search planners Airport,
Blocksworld, Depots, Grid domains. description planners given Section 6; fork-decomposition heuristics computed
fully online. Column task denotes problem instance, column h denotes optimal
solution length. columns capture run time number expanded
nodes.

110

fiImplicit Abstraction Heuristics

hF
task

h

nodes

hI

hFI

time

nodes

time nodes

time

0.05
18.27
0.25
19.15
45.02
5.21
9.56

37
18452
190
10778
11400
795
1730

0.01
37
10.29 15794
0.13
163
17.14 7665
18.91 10984
3.60
492
7.71 1006

0.04
23.80
0.31
29.88
46.16
6.05
13.80

HSPF

MS-104

MS-105

nodes

time

nodes

time

nodes

8 0.04
20 0.13
13 0.16
17 0.49
2614 0.60
291 1.35
14 1.42
287823 7.34
15504 1.70
18 1.64
34137 1.99
1298884 19.52

8
20
13
17
19
12
14
2952
23
18
10790
870875

0.03
0.26
0.25
2.41
4.58
9.72
15.35
20.31
10.43
18.54
17.01
35.33

44
15998
863
22933
24877
3804
25801

blind
time

nodes

time

hmax
nodes
time

driverlog-ipc3
01
02
03
04
05
06
07
08
09
10
11
13

7
19
12
16
18
11
13
22
22
17
19
26

49
15713
164
6161
13640
608
864

4304 199.81
433951421.90

198651 849.04
16099 85.74 4037 200.52
41445 186.53 390691395.51

0.47
182 0.00
20
4.55
68927 0.36
54283
1.25
16031 0.09
2498
12.20 999991 8.12 393673
18.77 6290803 61.57 1724611
10.08 681757 7.64
54451
41.34 6349767 81.53 493480

18234 68.22
5596231193.00

0.00
0.52
0.03
6.56
34.73
1.71
17.31

6141130 330.22

freecell-ipc3
01
02
03
04
05

8
234
1.54
14 30960 107.07
18 197647 877.16
26
30

974
4.88
274
3.25
75150 230.54 37131 224.62

87 3.12
31487 40.40
95805140.96
943074 86.78
5950977243.74

9 38.74

9 13.01
3437 0.03
1043
0.15
466 70.29 130883 1.46
41864 10.77
1589 169.39 944843 11.45 210503 75.62
15848 341.02 3021326 38.80 600525 247.70
40642 916.44
14080351062.25

gripper-ipc1
01
02
03
04
05
06
07

11
214
0.04
240
0.02
214
0.05
12 0.00
12 0.00
33
0.11
236 0.00
208
0.00
17
1768
0.54
1832
0.36 1803
0.75
18 0.11
18 0.08
680
0.37
1826 0.01
1760
0.01
23 11626
5.38 11736
4.05 11689
8.11
11514 0.47
2094 1.75
7370
1.52
11736 0.04
11616
0.08
29 68380 43.58 68558 35.24 68479 70.72
68380 1.24
68190 8.05
55568 10.29
68558 0.27
68368
0.56
35 376510 328.10 376784 296.59376653 560.93
376510 3.52 376510 19.46 344386 79.96 376772 1.59 376496
3.51
41
1982032 13.42 1982032 42.16 1911592 577.49 1982394 9.59 1982016 21.57
47
10091986 61.6610091986106.84
10092464 51.1010091968 119.64

logistics-ipc1
01
05
31
32
33

26
22
13
20
27

3293 945.35
436
9.67
392
2.57

1981
2704

2.53
2.24

1284
962

21.84
5.53

21
0.02
193
0.06
65
20
0.03
570
0.13
293
16
0.02
117
0.03
79
28
0.05
2550
0.98 1171
18
0.03
675
0.19
427
9
0.02
24
0.01
13
26
0.06
4249
1.85 2461
15
0.03
181
0.09
99
26
0.05
2752
1.22 1394
25
0.04
2395
0.94 1428
37
0.42 251287 203.64 98053
1689 10.08
32
0.42 82476 78.73 35805
45
0.6611836081306.92
37
0.54 351538 407.06167038
31
0.50 59336 80.88 25359
46
2.26
43
2.10
697 26.78
21959 696.23
43
2.78

0.06
0.16
0.05
1.09
0.31
0.02
2.54
0.13
1.51
1.34
386.80

1918881 41.03
768161 18.69
494 0.42
21 0.16

949586 34.82
609393 35.27
14 2.11
21 0.72
529338 32.55

2119551700.26
6.58
7.08

155645
245325

1.66
2.07

32282
81156

0.57
1.00

21 0.05
20 0.04
16 0.05
28 0.38
18 0.38
9 0.38
26 1.23
15 1.26
26 1.26
25 1.22
37 4.87
49 4.94
32 6.90
45 7.21
37 9.46
31 9.43
668834 29.73
1457130 43.00
701106 37.42

21
0.34
20
0.37
16
0.36
28
0.58
18
0.72
9
0.78
26
1.03
15
1.16
26
1.03
25
1.02
24317 35.46
362179 453.06
14890 33.50
114155 198.84
32017 83.16
6720 26.48

11246
9249
4955
109525
22307
1031
490207
24881
476661
422557

0.05
0.04
0.02
0.64
0.13
0.00
3.40
0.16
3.32
2.95

4884
4185
1205
74694
6199
280
202229
3604
200012
133521

0.03
0.03
0.01
0.59
0.05
0.00
1.92
0.03
1.98
1.29

3636

0.07

481
9598

logistics-ipc2
04-0
04-1
04-2
05-0
05-1
05-2
06-0
06-1
06-2
06-9
07-0
07-1
08-0
08-1
09-0
09-1
10-0
10-1
11-0
11-1
12-0
12-1

20
19
15
27
17
8
25
14
25
24
36
44
31
44
36
30
45
42
48
60
42
68

161.33
883.68
168.73

21
20
16
28
18
9
26
15
26
25
525
666324
1042
16708
20950
31

0.03
0.03
0.04
0.10
0.10
0.09
0.18
0.18
0.19
0.18
0.65
8.83
0.96
1.15
1.56
1.27

775996 43.56
2222340 87.47

mprime-ipc1
01
02
03
04
05
07
08
09
11
12
15
16
17
19
21
25
26
27
28
29
31
32
34
35

5
7
4
8
11
5
6
8
7
6
6
6
4
6
6
4
6
5
7
4
4
7
4
5

196
0.19
11604 422.83
427 35.09
3836
6.62
3314

14.91

10
0.03
440451620.68
7
0.50
1775
1.17
47

0.15

19838 454.91 1001881798.69
9
0.16
219
0.54
16320 192.10
8118 46.69
252 171.97

24
0.07
2565 242.83
11
3.15
1093
3.44
346

3.07

5227 284.13
8
0.16
5243 95.01
448 447.49

6 2.00
3317 88.58
36 33.64
9 6.09
1705009127.53
1667 46.72
1469752403.45
21993 36.25
8 4.69
34763 11.45

6 20.45
5463.85
9 82.71

108

49.59

19076 781.74

9868 0.67
599590 23.58
18744

8 62.68
42055143.27

22 394.26
25665 724.12

473 81.42

0.56

2197646 71.69
73260 2.21
108652 3.50
425144 32.17
172736 42.48

453 671.03
123039313.25
75

0.10

30

54
2.28
8
0.03
182
4.53
248 52.86
31759 133.33
234 11.65
392
3.09

1772
403
56
46
12436
46
290

0.04

29

0.08

33.82
9
0.23
37
1.11
32
7.83
19
34.94 11839
2.13
23
2.54
84

1.31
0.08
1.79
11.79
95.52
3.08
1.89

5 0.48
172432 46.33
6 11.59
8 1.88
5 14.92
419 99.87
19429 21.61
450151.69
359 3.63

5 2.75
189154454.69
6154.43
8 22.55
5201.40
7269292.37
6 43.43

1503293103.23
383 0.00
819590 61.01
84079 3.50
128 146.80
17333 0.25
3187 0.17
3584 0.19
110731701.00 115479 2.75
3618 0.19
706 96.55
2476 0.05
85

8.71

68
0.04
12606 36.65
5
0.07
200
0.24
14881571638.78
11
0.04
7650 84.33
19023 30.26
915
0.54
1520
1.78
1039 178.55
7962 35.65
5
1.06
36013 533.75
15250 101.75
6
0.00
440
2.69
831
2.08
211
0.06
7
0.10
11
0.17
3096
1.74
11
0.18
44
0.03

Table 10: Similar Table 9 Driverlog, Freecell, Gripper, Logistics-ipc1,
Logistics-ipc2, Mprime domains.
111

fiKatz & Domshlak

hF
task

h

nodes

hI
time

nodes

hFI
time nodes

time

MS-104

MS-105

nodes

nodes

time

time

HSPF

nodes

blind
time

nodes

time

hmax
nodes time

miconic-strips-ipc2
01-0
01-1
01-2
01-3
01-4
02-0
02-1
02-2
02-3
02-4
03-0
03-1
03-2
03-3
03-4
04-0
04-1
04-2
04-3
04-4
05-0
05-1
05-2
05-3
05-4
06-0
06-1
06-2
06-3
06-4
07-0
07-1
07-2
07-3
07-4
08-0
08-1
08-2
08-3
08-4
09-0
09-1
09-2
09-3
09-4
10-0
10-1
10-2
10-3
10-4
11-0
11-1
11-2
11-3
11-4

4
3
4
4
4
7
7
7
7
7
10
11
10
10
10
14
13
15
15
15
17
17
15
17
18
19
19
20
20
21
23
24
22
22
25
27
27
26
28
27
31
30
30
32
28
33
32
32
34
33
37
34
38
38
35

5 0.00
5
0.00
5 0.00
5 0.00
5
0.00
5 0.00
5 0.00
5
0.00
5 0.00
5 0.00
5
0.00
5 0.00
5 0.00
5
0.00
5 0.00
19 0.00
22
0.00
19 0.00
21 0.00
23
0.00
21 0.00
21 0.00
23
0.00
21 0.00
24 0.01
24
0.00
24 0.00
19 0.00
22
0.00
19 0.00
86 0.01
129
0.01
98 0.01
120 0.01
168
0.01
147 0.01
137 0.01
143
0.01
137 0.01
96 0.01
153
0.01
117 0.01
103 0.01
149
0.01
115 0.01
524 0.06
843
0.08
686 0.12
505 0.06
817
0.08
663 0.12
685 0.08
942
0.09
802 0.13
681 0.07
942
0.09
798 0.13
685 0.07
942
0.09
802 0.13
2468 0.37
4009
0.66 3307 0.93
2807 0.42
4345
0.71 3677 1.01
1596 0.29
2981
0.55 2275 0.73
2256 0.36
3799
0.62 3104 0.87
3210 0.46
4732
0.78 4267 1.11
9379 1.98 17665
4.74 13531 5.90
9106 1.93 18134
4.75 14052 5.94
10900 2.19 19084
4.90 15111 6.28
12127 2.43 21708
5.69 17807 7.19
13784 2.62 23255
5.93 19536 7.66
53662 13.29 96092 37.56 79449 46.76
56328 13.86 99109 38.56 83677 47.49
48141 12.52 96139 38.02 78471 46.17
46867 12.11 93117 36.63 75424 44.43
84250 18.24 126595 46.11111984 61.34
272580 81.51 485051 267.27408114317.78
284415 86.93 527216 288.07446837347.43
207931 66.37 414294 235.89330993271.03
369479104.29 598031 320.33527216392.87
297516 87.65 507910 278.64431432333.91
1461729497.72
1207894438.6923351661787.13
1294691460.1123404111791.16
1840936589.09
1252484467.94

5 0.00
5 0.00
4 0.00
4 0.00
5 0.00
5 0.00
5 0.00
5 0.00
5 0.00
5 0.00
8 0.00
8 0.00
8 0.00
8 0.00
8 0.00
8 0.00
8 0.00
8 0.00
8 0.00
8 0.00
11 0.00
11 0.00
12 0.00
12 0.00
11 0.00
11 0.00
11 0.00
11 0.00
11 0.00
11 0.00
15 0.01
15 0.01
14 0.01
14 0.01
16 0.01
16 0.01
16 0.01
16 0.01
16 0.01
16 0.01
18 0.06
18 0.05
18 0.06
18 0.05
16 0.06
16 0.05
18 0.06
18 0.05
19 0.06
19 0.05
20 0.18
20 0.32
20 0.18
20 0.32
21 0.18
21 0.32
21 0.17
21 0.32
22 0.17
22 0.32
24 0.32
24 1.75
7001 0.38
25 1.75
1646 0.33
23 1.71
1861 0.33
23 1.74
23159 0.52
26 1.71
41629 0.91
28 4.18
42679 0.90
28 4.25
37744 0.86
27 4.25
140453 1.94
29 4.21
62933 1.16
28 4.12
684737 9.07 126918 8.89
406041 5.61 100937 8.73
442547 6.06 82946 8.63
765455 10.00 277302 11.14
317692 4.65
29 7.03
2436164 35.24 863244 23.76
2340169 34.09 335745 15.68
1735477 25.29 486286 17.72
3952148 55.86 940556 24.24
2715866 39.44 625559 19.91
11473359183.604724980 93.56
7535468124.801934943 47.91
14645785233.686330198120.71
5809711110.10
5853546 95.561082086 32.22

5
0.01
4
0.00
5
0.01
5
0.00
5
0.01
26
0.01
26
0.01
27
0.00
20
0.01
23
0.01
100
0.03
140
0.02
122
0.02
131
0.02
114
0.02
669
0.10
634
0.11
822
0.12
820
0.12
821
0.12
2829
0.44
3260
0.49
1594
0.32
2568
0.42
3953
0.55
9312
1.76
10252
1.96
11247
2.11
14216
2.56
16880
3.04
56686 14.31
63035 16.33
55751 13.98
53121 13.27
96327 24.76
290649 104.18
339177 123.10
204614 73.39
435617 160.49
315339 111.84
1555286 794.93
1344815 683.05
1357681 692.11
20831681051.95
1231554 605.01

5 0.00
5 0.00
5 0.00
4 0.00
5 0.00
5 0.00
5 0.00
5 0.00
5 0.00
5 0.00
30 0.00
20 0.00
30 0.00
22 0.00
30 0.00
22 0.00
26 0.00
17 0.00
31 0.00
20 0.00
193 0.00
105 0.00
218 0.00
150 0.00
164 0.00
92 0.00
197 0.00
130 0.00
190 0.00
114 0.00
1182 0.00
866 0.00
1176 0.00
860 0.00
1277 0.00
969 0.00
1319 0.00
970 0.00
1334 0.00
969 0.00
6350 0.03
4387 0.03
6602 0.03
4664 0.03
5565 0.03
3524 0.03
5944 0.03
4140 0.03
6949 0.04
5268 0.04
30786 0.20
21194 0.20
30093 0.20
21255 0.20
32390 0.21
21694 0.21
32574 0.21
24552 0.23
33793 0.22
26167 0.24
155466 1.22 116685 1.32
164470 1.29 118494 1.33
161342 1.27 119688 1.36
155176 1.23 114649 1.30
168219 1.33 140128 1.58
755255 7.16 594032 7.95
794365 7.56 636587 8.66
731622 6.92 534711 7.37
833421 7.97 690267 9.29
771608 7.33 613253 8.43
3685552 41.04 3006991 49.12
3649801 40.32 2893803 47.54
3576134 39.61 2895182 47.26
3796035 42.13 3304570 53.29
3589382 39.29 2956995 48.84
15804498200.9013267920250.58
16472633208.3913720664256.89
15867374201.0112497087236.89
16309701208.4213801989262.53
16472551209.1313925654262.57

mystery-ipc1
01
02
03
04
07
09
11
12
15
16
17
18
19
20
24
25
26
27
28
29
30

5
7
4


8
7

6

4

6
7

4
6
5
7
4
9

7 0.01
2404 64.94
73 1.92
0 0.01
0 0.00
3049 47.68
9 0.02

0 0.14
354200.98
0 0.00

0 0.13
9 0.02
1807 50.40
14 0.27
8 0.01
31 0.26

6
0.00
8012 234.10
7
0.12
0
0.00
10764 137.61
33
0.03
2093419 938.05

85 26.31
0
0.00
4968 183.24

10
1835
159
47
14

0.01
25.34
1.61
0.02
0.10

6 0.01
722 47.50
11 0.59
0 0.00
0 0.00
1215 40.75
8 0.02

0 0.19
83 90.17
0 0.00

0 0.30
9 0.02
1344 60.20
6 0.22
15 0.02
10 0.17

6 0.20
1672 82.70
5 16.46

6

1.79

10

5.38

5193.75

65 811.87

0 0.00
0 0.00
3165 29.34
8 1.51
8 16.59
2102777 14.612102729 27.84

0
0.00
3868 670.08
34 41.20

198445.85
0 0.00
0 0.00
12478 96.38
285069 59.22 547246578.39
5 0.10
2526 5.94
6 4.80
8 0.63
5 8.94
42112 28.07

5 0.10
346 70.78
6 80.48
8 6.77
5107.10
44893357.07

0

0.00

14
1.22
3107 291.36
7 243.78
31 16.67
27 536.30

30 0.00
770852 21.85
507 0.02

0.00
4.47
0.03

0 0.00
0 0.00
138289 2.18
1458 1.44
426 0.00
19 0.00
2102777 15.09 1177842 21.87
279973 13.21
135 2.62
5400 0.41
0 0.00
133871 3.65
686125 23.28
31 0.00
8455 0.10
2174 0.03
843 0.00
153 0.01
1977063 38.26

Table 11: Similar Table 9 Miconic Mystery domains.
112

8
2368
5

5
0
1516
718

0.35
0.00
5.44
3.76

6 0.00
37 0.05
73 0.04
32 0.00
7 0.02
26686 28.27

fiImplicit Abstraction Heuristics

hF
task

h

hI

hFI

MS-104

MS-105

time

nodes

nodes

2264
0.49
3895
1.19
3070
1.36
2617
0.56
4485
1.32
3561
1.57
2264
0.49
3895
1.15
3070
1.36
2264
0.49
3895
1.15
3070
1.36
2264
0.48
3895
1.15
3070
1.35
366768 255.00 7797101599.86 5874821498.20
410728 277.99 7606681546.44 6067821515.46

24
24
24
24
24
621008
594758

nodes

time

nodes

time

nodes

time

time

HSPF

nodes

blind

hmax
nodes
time

time

nodes

time

0.06
2000
1.02
0.06
2378
1.07
0.06
2000
1.02
0.06
2000
1.02
0.05
2000
1.02
7.86 379735 217.37
7.34 405564 226.32

4822
5501
4822
4822
4822
882874
836647

0.01
0.02
0.01
0.02
0.01
4.91
4.62

4016
4594
4016
4016
4016
822514
787163

0.03
0.04
0.03
0.03
0.03
18.71
17.81

1624
2984
87189
456143

0.00
0.02
1.06
8.22

36
348
4346
104068

0.00
0.01
0.16
2.61

openstacks-ipc5
01
02
03
04
05
06
07

23
23
23
23
23
45
46

0.05
24
0.06
24
0.06
24
0.06
24
0.06
24
4.85 279614
4.69 264535

pathways-ipc5
01
02
03
04

6
12
18
17

1624
2755
44928
126950

0.03
0.08
2.59
11.45

1299
2307
20416
33788

0.02
0.06
1.06
2.97

1299
2437
29106
58738

0.03
0.09
2.14
7.07

7
1946
21671

1.14
2.56
6.43

7 0.79
13 42.11
14901129.23
98484288.39

1405
990
14772
34206

0.28
0.29
6.99
27.00

pipesworld-notankage-ipc4
01
02
03
04
05
06
07
08
09
10
11
12
13
14
15
17
19
21
23
24
41

5
12
8
11
8
10
8
10
13
18
20
24
16
30
26
22
24
14
18
24
12

121
0.15
1413
2.05
1742
5.26
7007 24.71
4093 27.45
12401 105.37
4370 71.75
18851 406.67

109
0.05
1542
0.86
3001
3.31
8911 12.43
6805 19.74
27377 103.75
9168 68.10
56189 483.28

121
0.18
1413
2.42
1742
6.43
7007 30.79
4093 35.40
12401 140.53
4370 105.53
20584 600.94

4729501577.22
117475 899.72

238331663.46

49035 495.53

6 0.04
6 0.04
6
2.79
121 0.00
13
0.00
169 0.30
13 0.17
435
3.07
1808 0.01
792
0.02
9 1.15
9 0.69
128
3.84
3293 0.02
262
0.02
651 1.95
12 7.05
812
8.84
16088 0.11
2925
0.13
77 5.63
9 21.15
155 16.53
11128 0.12
1121
0.15
1299 5.26
61 39.31
1151 23.41
49905 0.48
7102
0.72
233 19.78
9 59.70
185 29.88
46502 0.57
2631
0.48
561 12.42
497 94.69
1673 48.84 273585 3.39
22874
3.58
104875 25.48
10478 74.26 5513309 80.62 321861 68.99
2982520 66.89
6898321439.64
111212451579.77
90598 9.20 52159 43.24 108503 625.52 710123 3.86 107061 14.51
594661 12.41 416184109.43 4332961117.57 2467804 13.83 464982 56.82
12835 34.28
242241019.65 481045 3.14
33417
6.38
13255718119.54
648132 65.43
4921698 34.90 555619 105.49
3200672 90.07
8767431150.88
3992 18.13
948159.63
157782 1.31
8966
2.42
296506 49.11 104750256.13
481859 229.00
7315150142.82
114257 250.18

pipesworld-tankage-ipc4
01
02
03
04
05
06
07
08
11
13
15
17
21
31

5
12
8
11
8
10
8
11
22
16
30
44
14
39

77
0.13
126
0.07
105
0.20
960
1.20
1005
0.60
960
1.55
20803 155.53 52139 158.91 20803 207.57
1102841004.10 157722 668.67 1102841408.50
6531 73.63 13148 79.04
6531 112.61
20171 329.40 43583 310.24 20171 460.45

6 3.54
110 3.04
244 22.64
3892 16.68
376 15.46
1794328.18

6 0.13
13 0.20
9 36.89
12155.03
9120.06
11201.44

6
3.88
128 0.00
179
6.04
1012 0.01
818 24.47
52983 0.77
8116 64.68 221429 3.06
313 59.99
12764 0.21
3102 97.31
58487 0.87
2695 339.76 5404036198.08

13
0.01
659
0.02
1802
1.33
41540 14.49
2834
1.61
15746
6.61
104531 420.47

4116344 30.67

752867 334.42

4423951 65.44
1726598 13.56

126845 222.23
919764 381.66

96043191.77
660104 28.60 660102162.93
188517122.11
2546587141.12
12850247352.46
13241 69.80
1357801124.64

tpp-ipc5
01
02
03
04
05
06

5
8
11
14
19
25

6
9
12
15
623

0.00
0.00
0.00
0.01
0.52

6
11
27
78
5110

0.00
0.00
0.00
0.01
1.36

6
9
16
47
1455

0.00
0.00
0.00
0.01
1.21

6 0.00
9 0.00
12 0.00
15 0.01
20 0.36
947059 14.22

6 0.00
9 0.00
12 0.00
15 0.00
20 0.77
74798 23.97

6
9
12
15
624

0.01
0.01
0.03
0.07
0.48

7
26
116
494
24698

0.00
0.00
0.00
0.00
0.12

6
0.00
16
0.00
83
0.00
430
0.00
17398
0.15
9267024 216.69

trucks-ipc5
01
02
03
04
05
06
07
08
09

13
1691
0.41
1027
0.22
1039
0.40
14 0.03
14 0.02
285
0.56
5774 0.02
402
0.01
17
9624
2.68
2898
0.57
2957
1.35
4192 0.22
18 0.17
1413
1.04
28348 0.14
939
0.03
20
80693 71.37 20752 19.93 22236 31.25
199405 2.89 173790 6.88
4049
4.43 379582 2.97
9465
0.40
23 17538661237.601205793 850.3413156721394.88 2591561 29.172568634 56.96
8817
7.75 2990366 26.65 209140
9.43
25
23444940392.99
14744 23.12
1248571 90.78
30
308920 343.47
23 21347281313.60 719751 408.75 755608 820.55 7575415 88.918080496117.13 43270 27.6212410588117.92 223011 19.34
25
49663 47.61
3106944 403.36
28
233577 248.21

Table 12: Similar Table 9 Openstacks, Pathways, Pipesworld-NoTankage,
Pipesworld-Tankage, TPP, Trucks domains.

113

fiKatz & Domshlak

hF
task

h

nodes

hI
time

nodes

hFI
time

nodes

time

MS-104

MS-105

nodes time

nodes

time

HSPF

nodes

blind
time

hmax
nodes time

nodes

time

0.00
9
0.01
11
0.00
20
0.08
71
0.00
20
0.04
33
0.00
12
0.34
332
0.00
23
0.11
154
0.00
9
0.01
11
0.00
26
0.09
122
0.00
9
0.12
128
0.00
9
0.06
49
0.04
18
1.04
1358
0.00
96
0.19
153
0.00
40
0.17
153
0.00
59
0.16
95
0.00
13
0.06
27
2.58
356 18.99
3562
0.12
2287
1.34
2742
0.00
13
0.03
16
0.00
29
0.21
158
0.77
6338
4.46
9009
0.00
52
0.18
84
0.00
21
0.12
42
0.87
22315
8.16 189516
0.01
30
0.43
200
0.00
21
0.12
42
37.93
28 780.38
8913
0.00
52
0.28
182
0.01
179
0.85
773
0.00
49
0.29
95
1.43
3337
7.12 244499
0.02
393
1.35
2295
6.55
7530 32.97 53911
0.00
352
0.74
435
0.63
947
2.29
2291
0.00
158
0.50
227
6.36
7448
8.27 165170
14.07 188564 111.991669788
0.01
277
2.10
1532
0.01
33
0.74
562
0.07
146
1.78
4103
12.86
23371 87.911036992
0.00
21
0.16
54
0.18
1773
1.29
1908
0.00
256
0.50
333
0.05
407
2.18
4142
0.00
121
0.74
434
4.05
19865
6.91 80785
0.04
515
2.32
5075
11.08 200559 101.21
23.32 27728751408.64
0.02
390
1.40
690

0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.02
0.01
0.00
0.00
0.04
0.00
0.00
0.67
0.00
0.00
0.12
0.00
0.00
0.00
1.27
0.01
0.25
0.00
0.01
0.00
0.63
9.44
0.00
0.00
0.01
6.74
0.00
0.01
0.00
0.01
0.00
0.25
0.01

9 0.00
47 0.00
28 0.00
102 0.00
69 0.00
9 0.00
62 0.00
52 0.00
20 0.00
376 0.01
142 0.00
113 0.00
86 0.00
18 0.00
324 0.02
1876 0.01
14 0.00
91 0.00
6925 0.08
75 0.00
31 0.00
177138 1.43
116 0.00
31 0.00
854 0.18
142 0.00
616 0.00
79 0.00
192459 2.32
1834 0.01
16766 0.36
424 0.00
1073 0.01
216 0.00
61548 1.06
717884 18.27
1342 0.01
357 0.00
2597 0.02
229210 9.51
35 0.00
1636 0.01
315 0.00
3235 0.02
358 0.00
65984 0.63
4406 0.02
19020089286.02

0.00

642

psr-small-ipc4
01
02
03
04
05
06
07
08
09
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50

8
11
11
10
11
8
11
8
8
7
19
16
15
9
10
25
9
12
25
17
10
33
12
10
9
17
21
14
21
22
19
24
21
21
22
22
23
13
23
20
10
30
20
19
20
34
27
37
47
23

10
52
31
66
75
10
61
24
18
131
149
120
90
19
1200
2328
15
85
8025
80
28
163299
77
28
485
144
616
79
142772
1791
11278
431
1480
223
65965
571766
1307
301
2486
31
1855
328
2990
347
60888
4104

637

0.00
10
0.00
10
0.00
0.01
55
0.00
52
0.01
0.01
31
0.00
31
0.00
0.04
91
0.03
73
0.06
0.01
79
0.01
75
0.02
0.00
10
0.00
10
0.00
0.01
61
0.00
61
0.01
0.01
29
0.00
25
0.01
0.01
19
0.00
18
0.00
0.20
183
0.18
155
0.32
0.03
149
0.02
149
0.04
0.03
123
0.02
120
0.04
0.02
90
0.01
90
0.02
0.00
19
0.00
19
0.00
6.55
708
6.25
769
9.91
0.65
2158
0.34
2176
0.85
0.00
15
0.00
15
0.00
0.03
90
0.01
85
0.03
4.31
7856
2.19
7876
5.80
0.02
80
0.01
80
0.02
0.01
28
0.00
28
0.01
405.65 176058 245.42 168685 617.45
0.04
93
0.03
77
0.06
0.01
28
0.00
28
0.01
84.24
463 145.38
482 213.42
0.05
150
0.03
146
0.06
0.33
675
0.21
650
0.49
0.02
79
0.01
79
0.02
436.34 187319 307.77 159325 709.89
1.25
1982
0.80
1883
1.90
25.93
6810 38.66
8297 53.43
0.17
431
0.10
431
0.25
0.84
1436
0.30
1391
1.00
0.07
223
0.04
223
0.09
160.36 63186 39.55 68281 199.30
392.49 371834 786.06 4584021094.61
1.29
1417
0.95
1363
2.10
0.20
372
0.15
326
0.32
2.49
2942
1.64
2682
3.91
1826081384.90
0.01
34
0.00
31
0.01
0.50
1747
0.17
1739
0.59
0.09
328
0.05
328
0.12
3.25
3430
2.30
3121
5.24
0.16
376
0.11
359
0.25
51.77 61842 21.14 61563 68.33
5.27
4522
3.93
4284
8.70

0.39

659

0.26

645

9 0.00
9
12 0.00
12
12 0.00
12
11 0.00
11
12 0.00
12
9 0.00
9
12 0.00
12
9 0.00
9
9 0.00
9
8 0.04
8
20 0.00
20
17 0.00
17
16 0.00
16
10 0.00
10
11 0.46
11
975 0.11
26
10 0.00
10
13 0.00
13
2910 0.27
26
18 0.00
18
11 0.00
11
34 0.28
34
13 0.00
13
11 0.00
11
10 5.42
10
18 0.00
18
22 0.01
22
15 0.00
15
22 0.39
22
23 0.01
23
2647 0.89
723
25 0.00
25
446 0.26
22
22 0.00
22
24021 0.83 11113
48350 2.98
2783
24 0.02
24
14 0.01
14
24 0.08
24
38837 1.88
7767
11 0.00
11
1117 0.18
31
21 0.00
21
20 0.05
20
21 0.01
21
36941 0.67 32582
28 0.04
28
129627 2.37
2500
204836815.84 594399
0.60
24 0.02
24

0.00

rovers-ipc5
01
02
03
04
05
07
12

10
8
11
8
22
18
19

147
0.01
147
0.01
147
0.02
11 0.03
11 0.03
48
0.07
1104 0.00
283 0.00
44
0.01
44
0.01
44
0.01
9 0.00
9 0.00
16
0.03
254 0.00
129 0.00
672
0.11
419
0.05
448
0.10
12 0.11
12 0.12
804
0.16
3543 0.02
757 0.00
47
0.02
20
0.00
24
0.01
9 0.04
9 0.04
58
0.08
897 0.00
223 0.00
808084 237.13 410712 123.64 522937 231.28 61726711.48 375808 18.46 298400 101.658559690126.19 4318309 81.53
741649 517.1816822451780.27 328088451.022212903 59.20 1459792 866.93
9618062199.91
5187273166.77

satellite-ipc4
01
02
03
04
05
06

9
24
0.00
32
0.00
13
86
0.02
337
0.10
11
2249
1.24
656
0.53
17
9817 10.65 14860 24.90
15 2795691251.83 46453 515.80
20 1496577 968.2415723271721.87

29
0.00
241
0.13
728
0.82
11250 26.18
61692 877.26

10 0.00
10 0.00
14 0.01
14 0.01
12 0.56
12 0.64
4152 0.99
18 4.43
81972 7.26 148667 69.28
276922974.73 307962 32.52

46
0.06
89
646
0.21
1728
1945
0.93 15185
15890
9.50 345663
267513 565.18

2 0.00
2 0.00
7 0.00
7 0.00
7 0.21
7 0.90
9 0.20
9 0.89
12 0.25
12 1.90
12 0.38
12 3.54
16 0.38
16 3.48
14354 2.00
12 14.48
251703551.18 611457 30.47
132287134.84 137872 25.44
31003011.28 110726 26.65

2
0.45
2
9
0.46
58
40
3.42
5160
215
3.44
5256
422
7.70 82289
1957 11.81 596531
34890 30.36 405626
83533 292.05

0.00
0.01
0.17
4.70

59
940
6822
180815

0.00
0.00
0.11
3.37

10751017371.43

zenotravel-ipc3
01
02
03
04
05
06
07
08
09
10
11

1
6
6
8
11
11
15
11
21
22
14

2
17
28
99
177
2287
5088
3268

0.01
0.02
0.08
0.15
0.32
5.51
9.63
43.96

2
18
18
88
220
1144
4234
1026

0.00
0.02
0.12
0.26
0.22
2.00
5.56
8.92

769041090.67

2
17
12
81
136
504
4199
1655

0.01
0.02
0.11
0.30
0.36
2.40
10.58
30.06

0.00
0.00
0.04
0.03
0.63
5.90
3.56

2 0.00
22 0.00
492 0.02
665 0.01
12466 0.33
85931 2.47
115348 2.60
687846 50.76

Table 13: Similar Table 9 PSR, Rovers, Satellite, Zenotravel domains.

114

fiImplicit Abstraction Heuristics

hF
task

h nodes

hI
timenodes

hFI
timenodes

MS-104
time nodes

MS-105

timenodes

HSPF

time nodes

blind
hmax
time nodes time nodes
time

schedule-strips
02-0
02-1
02-2
02-3
02-4
02-5
02-6
02-7
02-8
02-9
03-0
03-1
03-2
03-3
03-4
03-5
03-6
03-7
03-8
03-9
04-0
04-1
04-2
04-3
04-4
04-5
04-6
04-7
04-8
04-9
05-0
05-1
05-3
05-4
05-5
05-6
05-7
05-8
05-9
06-2
06-4
07-0
07-9

3
5
0.15
5
0.14
5
0.22
2
3
0.16
4
0.11
3
0.18
2
3
0.32
3
0.17
3
0.40
3
26
0.50
37
0.76
26
0.61
3
68
1.34 188
2.24 220
7.20
2
3
0.33
3
0.14
3
0.38
2
3
0.14
5
0.12
3
0.17
2
3
0.30
3
0.13
3
0.34
2
3
0.32
3
0.14
3
0.38
3
5
0.15
5
0.14
5
0.22
4
40
2.72 407 12.16 140 14.55
2
3
0.51
3
0.35
3
0.72
4
27
1.16
50
1.83
33
2.33
4
15
0.79
91
2.39
15
0.96
3
4
1.11
16
2.08
4
1.52
4
73
6.13 471 16.71
74
8.32
4
72
1.27
75
1.80
69
1.33
4
28
1.05
50
1.83
28
1.43
4
273 11.53 266 11.46 273 17.48
4
8
0.96
31
1.77
14
2.13
5
373 13.91 1498 74.46 167 24.60
6 175591373.8010707 626.54
5
209
9.88 406 20.85
66
5.30
5
142 10.47 674 33.29 251 29.28
5
921 64.48 450 46.95 574 116.65
6
483 47.25 4544 268.77 850 187.46
6
779 27.0911610 361.74 1834 102.68
5
99 18.48 424 38.04 163 40.04
5
102 16.01 573 31.87 111 23.35
4 1043 80.06 996 76.64 1050 143.48
5
163 41.61 483 63.23 167 62.53
6 2701 213.92
1257 286.28
7
136221693.68
6
989 100.02 3433 229.05 582 100.05
6
198 21.67 9550 767.94 347 68.64
7 6033 743.61
103251508.56
6
944 131.19175621446.20 2107 379.70
7 1190 172.59
2709 730.54
6 1537 140.49158291248.19 2717 547.56
6
888 243.14
1709 730.36
8 115351776.87
7 2489 786.76
8 68291559.86

4 511.10
3 104.98
3 231.99
4 56.51
3
3
3
3
4

363.11
121.84
323.77
316.53
251.46

5 191.03
5 259.13
5 682.30
5 121.58
5 195.72
5 235.48
71115.76
6 267.29
7
7
6
6
5

837.68
459.19
936.68
711.65
316.22

41743.32

5
3
3
4
4
3
3
3
3
5

577.39
754.26
495.56
658.90
484.62
667.32
697.42
604.06
668.79
577.16

76 0.02
5
0.09
6 0.02
3
0.07
5 0.02
3
0.07
529 0.03
95
0.45
543 0.03
108
0.44
3 0.03
3
0.07
6 0.02
3
0.06
13 0.02
3
0.07
8 0.02
3
0.07
76 0.03
5
0.09
11915 0.60 1127
8.98
31 0.04
25
0.37
3617 0.23 1228
9.56
3379 0.23
170
1.85
41223.90
301 0.06
22
0.27
12217 0.64 1175 12.43
2663 0.19 1542 11.73
12859 0.68 1323 13.47
12616 0.65 1590 11.13
4339 0.27
913
7.69
31219326.88 22993 273.38
55206949.79
47696 4.97 9703 131.69
89272 8.74 12941 163.84
62013 6.03 13614 168.07
1079781399.99
1071151001.40
61327 5.97 8683 103.50
34046729.56 15122 181.98
41673 4.27 5480 83.69
14335022.71 43336 751.35

120602 989.42

Table 14: Similar Table 9 (non-IPC) Schedule-STRIPS domain.

115

fiKatz & Domshlak
hF
task

h

nodes

hI
time

nodes

hFI
time

nodes

time

MS-104

MS-105

nodes

nodes

time

HSPF

time

nodes

9
0.00
10
0.00
18
0.03
21
0.01
22
0.01
42
0.17
42
0.17
96231549.13
89525 466.14
19
0.01
22
0.01
40
0.21
38
0.21
8968 238.16
8931 267.81
3053401077.90

9
10
29
21
22
42
42
203
12956
19
22
40
38
62
59

time

blind
nodes time

hmax
nodes time

airport-ipc4
01
02
03
04
05
06
07
08
09
10
11
12
13
14
15
16
17
19
21
22
36
37

8
10
0.01
9 0.00
9
0.00
9 0.00
9
12
0.01
15 0.00
15
0.01
10 0.00
17
86
0.02
133 0.01
93
0.02
18 0.04
20
22
0.01
21 0.00
21
0.01
21 0.02
21
23
0.08
30 0.02
27
0.09
22 0.01
41
513
0.16
639 0.06
567
0.19
42 0.16
41
514
0.15
632 0.05
550
0.19
42 0.17
62
12733
1.89 21544 1.36 14398
4.02
24372 25.42
71
88670 16.58 136717 9.60 90412 38.78 152408 64.92
18
19
0.01
19 0.01
19
0.01
19 0.02
21
23
0.10
30 0.03
27
0.12
22 0.02
39
475
0.20
728 0.07
568
0.25
40 0.21
37
434
0.20
663 0.07
479
0.24
38 0.20
60
12040
2.90 25110 1.86 15948
4.64
30637 51.23
58
11477
2.74 23317 1.71 14557
4.25
28798 46.20
79 267277 77.39 824491 97.12 353592 114.58 1031524200.95
88 2460667 708.82
26786891235.79
90 1354353 592.533400142492.061462739 660.17
101
5156 48.29 11259 3.72
4773 51.13
7326372.92
148 6066481110.091063668318.90 4778361082.91 1119943762.02
109
9504 129.73 34986 14.41
9436 140.75
34365853.70
142
37873 820.33

102

10.28

0.72
11 0.00
9 0.00
1.23
13 0.00
10 0.00
5.10
164 0.00
57 0.00
1.32
23 0.00
21 0.00
46.54
27 0.00
22 0.00
123.13
738 0.01
418 0.02
117.56
742 0.01
405 0.02
602.09 27032 0.28
9687 0.90
993.07 175717 2.47 56484 7.62
2.45
21 0.00
19 0.00
65.36
27 0.00
22 0.01
169.02
873 0.01
392 0.03
134.87
822 0.01
342 0.03
714.76 35384 0.39
9196 1.11
647.05 33798 0.38
8200 1.01
124746719.72 221993 49.03
1043661310.89
831632253.21
18809 0.42
3184 1.12
159967105.29
63061 1.44

blocks-ipc2
04-0
04-1
04-2
05-0
05-1
05-2
06-0
06-1
06-2
07-0
07-1
07-2
08-0
08-1
08-2
09-0
09-1
09-2
10-0
10-1
10-2
11-0
11-1
11-2
12-0
12-1
13-0
13-1
14-0
14-1

6
15
10
14
6
7
12
32
10
37
16
152
12
33
10
41
20
855
20
278
22
6910
20
1458
18
1533
20
10040
16
479
30 134185
28
3435
26
6379
34 1524599
32 610206
34 1516087
32
30
34
34
34
42
44
38
36

0.00
46 0.00
17
0.00
7 0.03
7
0.03
0.00
31 0.00
15
0.00
11 0.04
11
0.03
0.00
26 0.00
10
0.00
7 0.04
7
0.03
0.00
302 0.01
113
0.00
13 0.30
13
0.96
0.00
280 0.00
98
0.00
11 0.29
11
0.96
0.00
596 0.00
348
0.01
17 0.29
17
0.95
0.00
766 0.01
207
0.01
13 0.95
13
8.56
0.00
2395 0.03
578
0.02
11 0.90
11
8.34
0.01
5444 0.05
3352
0.06
733 0.87
85
8.84
0.01 20183 0.28
4022
0.12
577 1.93
144 23.32
0.10 59207 0.60 38539
0.67
10071 1.70
1835 21.05
0.02 46009 0.52 18854
0.39
1855 1.59
782 20.37
0.03 344157 5.46 69830
2.09
5557 3.67
678 36.80
0.17 517514 7.22 191352
4.91
45711 3.88
11827 33.49
0.02 237140 4.08 32567
1.09
277 3.63
54 32.53
3.107405904117.144346535 118.23 1233374 16.00 971409 77.74
0.094145371 77.54 917197 33.32
95068 7.35
58873 63.15
0.174145278 78.21 923365 33.79 161719 13.54
20050 82.45
36.52
15.79
12063665 228.76
37.71
7046739 141.44

7
0.36
93 0.00
25 0.00
11
0.39
66 0.00
23 0.00
7
0.38
63 0.00
18 0.00
13
1.32
467 0.00
145 0.00
11
1.36
567 0.00
135 0.00
17
1.49
792 0.00
297 0.00
13
4.10
1826 0.00
276 0.00
11
4.17
4887 0.01
755 0.01
31
4.29
6385 0.02
2556 0.03
22 11.47 37157 0.14
5943 0.11
174 11.25 63376 0.21 33194 0.46
90 10.99 55218 0.19 18293 0.29
25 26.00 519107 2.28 94671 2.07
151 26.57 636498 2.60 199901 3.85
17 25.85 433144 1.93 52717 1.30
464 56.76798464936.763840589 85.00
82 56.98591457229.731200345 32.06
81 57.02596316030.021211463 32.15
1800 114.26
1835 115.19
3685 116.75
2678 213.32
1510 203.79
3984 213.97
1184 370.06
614 382.34
83996 860.45
1634381104.27
27791063.02
71541087.40

depots-ipc3
01
02
03
04
07
10
13

10
114
0.01
279 0.01
161
0.02
11 0.00
11
0.00
45
0.77
329 0.00
136 0.00
15
1134
0.08
9344 0.31
2638
0.22
738 3.24
16
1.14
898 11.56 15404 0.11
3771 0.17
27 134428
8.592520703159.84 581726 66.43 348288 20.69 239313 222.35 103089 247.13293039827.201204646 97.62
30 1254545 101.18
5835295 923.87 1284048 52.05 1273762 529.34
21 109765
9.174271196336.59 487961 76.02 211820 37.54
41328 324.19650110071.581331701166.76
24 2964635 283.55
60814781187.66 3241083157.52
25 1003709 152.30
81618721559.21 1427824116.06

driverlog-ipc3
01
02
03
04
05
06
07
08
09
10
11
13

7
49
0.00
37 0.00
37
0.00
8 0.04
19
15713
0.42 18452 0.27 15794
0.55
20 0.13
12
164
0.00
190 0.00
163
0.01
13 0.16
16
6161
0.42 10778 0.30
7665
0.62
17 0.49
18
13640
1.01 11400 0.36 10984
1.07
2614 0.60
11
608
0.09
795 0.06
492
0.11
291 1.35
13
864
0.14
1730 0.11
1006
0.21
14 1.42
22 669994 75.741181268 61.32 694996 104.59 287823 7.34
22 150255 14.72 198651 11.44 164109 23.06
15504 1.70
17
4304
0.44 16099 1.21
4037
0.69
18 1.64
19
43395
4.99 41445 2.22 39069
5.90
34137 1.99
26 1303099 325.711014865144.641098694 422.20 1298884 19.52

8
20
13
17
19
12
14
2952
23
18
10790
870875

0.03
44
0.47
182 0.00
20 0.00
0.26 15998
4.55 68927 0.36 54283 0.52
0.25
863
1.25 16031 0.09
2498 0.03
2.41 22933 12.20 999991 8.12 393673 6.56
4.58 24877 18.77629080361.571724611 34.73
9.72
3804 10.08 681757 7.64 54451 1.71
15.35 25801 41.34634976781.53 493480 17.31
20.31
10.43
18.54 18234 68.22
17.01 5596231193.00
6141130330.22
35.33

Table 15: Runtimes cost-optimal heuristic-search planners Airport,
Blocksworld, Depots, Driverlog domains.
description
planners given Section 6; fork-decomposition heuristics via
structural-pattern databases. Column task denotes problem instance, column
h denotes optimal solution length. columns capture run time
number expanded nodes.
116

fiImplicit Abstraction Heuristics

hF
taskh

nodes

hI
time

nodes

hFI
time

nodes

time

MS-104

MS-105

nodes

nodes

time

time

HSPF

nodes

blind
time

nodes

time

hmax
nodes
time

freecell-ipc3
01
02
03
04
05

8
14
18
26
30

234
0.10
974
0.15
274 0.17
30960
1.95
75150
5.53
37131 4.79
197647 14.41 533995 78.27 240161 51.24
997836 60.67 1921470 232.95 1218329213.02
6510089 448.22

87 3.12
31487 40.40
95805140.96
943074 86.78
5950977243.74

9 38.74

9 13.01
3437 0.03
1043
0.15
466 70.29 130883 1.46
41864 10.77
1589 169.39 944843 11.45 210503 75.62
15848 341.02 3021326 38.80 600525 247.70
40642 916.44
14080351062.25

grid-ipc1
01
02

14
26

571
0.60
33302741078.55

1117

0.34

472

0.78

660 8.63
467121.10
3392724 50.35 3244132241.94

6446

0.08

190
0.10
664016 231.26

gripper-ipc1
01
02
03
04
05
06
07

11
214
0.00
240
0.00
214 0.00
12 0.00
12 0.00
33
0.11
236 0.00
208
0.00
17
1768
0.02
1832
0.01
1803 0.03
18 0.11
18 0.08
680
0.37
1826 0.01
1760
0.01
23
11626
0.19
11736
0.08
11689 0.22
11514 0.47
2094 1.75
7370
1.52
11736 0.04
11616
0.08
29
68380
1.46
68558
0.51
68479 1.63
68380 1.24
68190 8.05
55568 10.29
68558 0.27
68368
0.56
35
376510 10.07 376784
3.20 376653 11.11
376510 3.52 376510 19.46 344386 79.96 376772 1.59 376496
3.51
41 1982032 70.91 1982408 19.08 1982227 77.81 1982032 13.42 1982032 42.16 1911592 577.49 1982394 9.59 1982016 21.57
47 10091986 438.4110092464 105.6710092241478.67 10091986 61.6610091986106.84
10092464 51.1010091968 119.64

logistics-ipc1
01
05
31
32
33
35

26
22
13
20
27
30

77763
7.14 1469610
3293
0.46 850312
436
0.03
1981
392
0.01
2704
312180 27.19
477883 183.08

95.49
42.43
0.07
0.07

830292 98.59
173477 18.19
1284 0.09
962 0.05
3617185427.52

1918881 41.03
768161 18.69
494 0.42
21 0.16

949586 34.82
609393 35.27
14 2.11
21 0.72
529338 32.55

2119551700.26
6.58
7.08

155645
245325

1.66
2.07

32282
81156

0.57
1.00

21 0.05
20 0.04
16 0.05
28 0.38
18 0.38
9 0.38
26 1.23
15 1.26
26 1.26
25 1.22
37 4.87
49 4.94
32 6.90
45 7.21
37 9.46
31 9.43
668834 29.73
1457130 43.00
701106 37.42

21
0.34
20
0.37
16
0.36
28
0.58
18
0.72
9
0.78
26
1.03
15
1.16
26
1.03
25
1.02
24317 35.46
362179 453.06
14890 33.50
114155 198.84
32017 83.16
6720 26.48

11246
9249
4955
109525
22307
1031
490207
24881
476661
422557

0.05
0.04
0.02
0.64
0.13
0.00
3.40
0.16
3.32
2.95

4884
4185
1205
74694
6199
280
202229
3604
200012
133521

0.03
0.03
0.01
0.59
0.05
0.00
1.92
0.03
1.98
1.29

3636

0.07

481
9598

logistics-ipc2
04-0 20
04-1 19
04-2 15
05-0 27
05-1 17
05-2 8
06-0 25
06-1 14
06-2 25
06-9 24
07-0 36
07-1 44
08-0 31
08-1 44
09-0 36
09-1 30
10-0 45
10-1 42
11-0 48
11-1 60
12-0 42
12-1 68

21
20
16
28
18
9
26
15
26
25
37
1689
32
45
37
31
46
43
697
21959
43
106534

0.00
193
0.00
570
0.00
117
0.00
2550
0.00
675
0.00
24
0.00
4249
0.00
181
0.00
2752
0.00
2395
0.00 251287
0.07 3532213
0.00
82476
0.01 1183608
0.00 351538
0.00
59336
0.01
0.01
0.09
2.22
0.02
11.64

0.00
65 0.00
0.01
293 0.00
0.00
79 0.00
0.05
1171 0.03
0.01
427 0.01
0.00
13 0.00
0.09
2461 0.07
0.00
99 0.00
0.06
1394 0.04
0.04
1428 0.04
7.52
98053 4.59
99.33 1705009 72.35
2.69
35805 1.78
45.72 462244 25.36
13.75 167038 9.76
2.48
25359 1.73

21
20
16
28
18
9
26
15
26
25
525
666324
1042
16708
20950
31

0.03
0.03
0.04
0.10
0.10
0.09
0.18
0.18
0.19
0.18
0.65
8.83
0.96
1.15
1.56
1.27

775996 43.56
2222340 87.47

mprime-ipc1
01
02
03
04
05
07
08
09
11
12
15
16
17
19
21
25
26
27
28
29
31
32
34
35

5
7
4
8
11
5
6
8
7
6
6
6
4
6
6
4
6
5
7
4
4
7
4
5

196
0.02
10
0.01
11604
2.72
44045 80.68
427
0.27
7
0.08
3836
0.22
1775
0.10
1745027 195.08
3314
0.25
47
0.03
485381 491.53 13767801426.21
19838
2.92 100188 74.85
9
0.02
219
0.03
16320
1.89
8118
0.73
252
0.76
2746 10.47
727401 521.78
174221 55.09
75
0.01
77622 24.69
54
0.16
8
0.01
182
0.12
248
0.51
31759
1.73
234
0.26
392
0.07

51590 135.00
453 18.78
95361 485.79
34022 47.43
30
0.01
147854 48.25
1772
1.50
403
0.02
56
0.08
46
0.68
12436
1.46
46
0.16
290
0.06

24 0.01
2565 4.20
11 0.16
1093 0.09
604756592.60
346 0.08
5227
8
5243

6.31
0.03
1.13

448 2.76
451 21.40

6 2.00
3317 88.58
36 33.64
9 6.09
1705009127.53
1667 46.72
1469752403.45
21993 36.25
8 4.69
34763 11.45

6 20.45
5463.85
9 82.71

108

49.59

19076 781.74

9868 0.67
599590 23.58
18744

8 62.68
42055143.27

0.56

2197646 71.69
22 394.26
73260 2.21
25665 724.12 108652 3.50

473 81.42

425144 32.17
172736 42.48

123039313.25
169400392.30
29 0.01
68239106.35
9 0.18
37 0.02
32 0.11
19 1.00
11839 1.93
23 0.28
84 0.08

5 0.48
172432 46.33
6 11.59
8 1.88
5 14.92
419 99.87
19429 21.61
450151.69
359 3.63

5 2.75
189154454.69
6154.43
8 22.55
5201.40
7269292.37
6 43.43

1503293103.23
383 0.00
819590 61.01
84079 3.50
128 146.80
17333 0.25
3187 0.17
3584 0.19
110731701.00 115479 2.75
3618 0.19
706 96.55
2476 0.05
85

8.71

68
0.04
12606 36.65
5
0.07
200
0.24
14881571638.78
11
0.04
7650 84.33
19023 30.26
915
0.54
1520
1.78
1039 178.55
7962 35.65
5
1.06
36013 533.75
15250 101.75
6
0.00
440
2.69
831
2.08
211
0.06
7
0.10
11
0.17
3096
1.74
11
0.18
44
0.03

Table 16: Similar Table 15 Freecell, Grid, Gripper, Logistics-ipc1,
Logistics-ipc2, Mprime domains.

117

fiKatz & Domshlak

hF
task

h

nodes

hI
time

nodes

hFI
time

nodes

time

MS-104

MS-105

nodes

nodes

time

time

HSPF

nodes

blind
time

nodes

time

hmax
nodes time

miconic-strips-ipc2
01-0
01-1
01-2
01-3
01-4
02-0
02-1
02-2
02-3
02-4
03-0
03-1
03-2
03-3
03-4
04-0
04-1
04-2
04-3
04-4
05-0
05-1
05-2
05-3
05-4
06-0
06-1
06-2
06-3
06-4
07-0
07-1
07-2
07-3
07-4
08-0
08-1
08-2
08-3
08-4
09-0
09-1
09-2
09-3
09-4
10-0
10-1
10-2
10-3
10-4
11-0
11-1
11-2
11-3
11-4

4
5 0.00
5 0.00
5 0.00
5 0.00
5 0.00
3
5 0.00
5 0.00
5 0.00
4 0.00
4 0.00
4
5 0.00
5 0.00
5 0.00
5 0.00
5 0.00
4
5 0.00
5 0.00
5 0.00
5 0.00
5 0.00
4
5 0.00
5 0.00
5 0.00
5 0.00
5 0.00
7
19 0.00
22 0.00
19 0.00
8 0.00
8 0.00
7
21 0.00
23 0.00
21 0.00
8 0.00
8 0.00
7
21 0.00
23 0.00
21 0.00
8 0.00
8 0.00
7
24 0.00
24 0.00
24 0.00
8 0.00
8 0.00
7
19 0.00
22 0.00
19 0.00
8 0.00
8 0.00
10
86 0.00
129 0.00
98 0.00
11 0.00
11 0.00
11
120 0.00
168 0.00
147 0.00
12 0.00
12 0.00
10
137 0.00
143 0.00
137 0.00
11 0.00
11 0.00
10
96 0.00
153 0.00
117 0.00
11 0.00
11 0.00
10
103 0.00
149 0.00
115 0.00
11 0.00
11 0.00
14
524 0.00
843 0.00
686 0.01
15 0.01
15 0.01
13
505 0.00
817 0.00
663 0.01
14 0.01
14 0.01
15
685 0.00
942 0.00
802 0.01
16 0.01
16 0.01
15
681 0.00
942 0.00
798 0.01
16 0.01
16 0.01
15
685 0.00
942 0.00
802 0.01
16 0.01
16 0.01
17
2468 0.03
4009 0.03
3307 0.05
18 0.06
18 0.05
17
2807 0.04
4345 0.03
3677 0.06
18 0.06
18 0.05
15
1596 0.02
2981 0.02
2275 0.04
16 0.06
16 0.05
17
2256 0.03
3799 0.03
3104 0.05
18 0.06
18 0.05
18
3210 0.04
4732 0.03
4267 0.06
19 0.06
19 0.05
19
9379 0.18
17665 0.15 13531 0.26
20 0.18
20 0.32
19
9106 0.17
18134 0.15 14052 0.27
20 0.18
20 0.32
20
10900 0.20
19084 0.16 15111 0.28
21 0.18
21 0.32
20
12127 0.23
21708 0.18 17807 0.33
21 0.17
21 0.32
21
13784 0.24
23255 0.19 19536 0.35
22 0.17
22 0.32
23
53662 1.19
96092 0.97 79449 1.76
24 0.32
24 1.75
24
56328 1.24
99109 0.96 83677 1.83
7001 0.38
25 1.75
22
48141 1.10
96139 0.94 78471 1.77
1646 0.33
23 1.71
22
46867 1.08
93117 0.92 75424 1.69
1861 0.33
23 1.74
25
84250 1.70 126595 1.22 111984 2.36
23159 0.52
26 1.71
27
272580 7.05 485051 5.51 408114 10.53
41629 0.91
28 4.18
27
284415 7.56 527216 6.01 446837 11.58
42679 0.90
28 4.25
26
207931 5.60 414294 4.79 330993 8.90
37744 0.86
27 4.25
28
369479 9.25 598031 6.74 527216 13.30
140453 1.94
29 4.21
27
297516 7.74 507910 5.79 431432 11.04
62933 1.16
28 4.12
31 1461729 43.82 2491975 32.672138656 63.58
684737 9.07 126918 8.89
30 1207894 37.47 2335166 30.761952916 59.39
406041 5.61 100937 8.73
30 1294691 40.03 2340411 30.971972234 59.25
442547 6.06 82946 8.63
32 1840936 52.68 2889342 38.122571844 74.47
765455 10.00 277302 11.14
28 1252484 40.34 2352633 31.351944297 59.37
317692 4.65
29 7.03
33 5716041202.3710316603153.808774563300.08 2436164 35.24 863244 23.76
32 5601282201.4310789013162.699144153315.23 2340169 34.09 335745 15.68
32 4153191155.86 9148616138.697466572265.86 1735477 25.29 486286 17.72
34 6108094214.6810960203167.109400386320.13 3952148 55.86 940556 24.24
33 5920127211.4011075136170.829448049322.74 2715866 39.44 625559 19.91
37
11473359183.604724980 93.56
34 15349953668.77
7535468124.801934943 47.91
38
14645785233.686330198120.71
38
5809711110.10
35
5853546 95.561082086 32.22

5
0.01
4
0.00
5
0.01
5
0.00
5
0.01
26
0.01
26
0.01
27
0.00
20
0.01
23
0.01
100
0.03
140
0.02
122
0.02
131
0.02
114
0.02
669
0.10
634
0.11
822
0.12
820
0.12
821
0.12
2829
0.44
3260
0.49
1594
0.32
2568
0.42
3953
0.55
9312
1.76
10252
1.96
11247
2.11
14216
2.56
16880
3.04
56686 14.31
63035 16.33
55751 13.98
53121 13.27
96327 24.76
290649 104.18
339177 123.10
204614 73.39
435617 160.49
315339 111.84
1555286 794.93
1344815 683.05
1357681 692.11
20831681051.95
1231554 605.01

5 0.00
5 0.00
5 0.00
4 0.00
5 0.00
5 0.00
5 0.00
5 0.00
5 0.00
5 0.00
30 0.00
20 0.00
30 0.00
22 0.00
30 0.00
22 0.00
26 0.00
17 0.00
31 0.00
20 0.00
193 0.00
105 0.00
218 0.00
150 0.00
164 0.00
92 0.00
197 0.00
130 0.00
190 0.00
114 0.00
1182 0.00
866 0.00
1176 0.00
860 0.00
1277 0.00
969 0.00
1319 0.00
970 0.00
1334 0.00
969 0.00
6350 0.03
4387 0.03
6602 0.03
4664 0.03
5565 0.03
3524 0.03
5944 0.03
4140 0.03
6949 0.04
5268 0.04
30786 0.20
21194 0.20
30093 0.20
21255 0.20
32390 0.21
21694 0.21
32574 0.21
24552 0.23
33793 0.22
26167 0.24
155466 1.22 116685 1.32
164470 1.29 118494 1.33
161342 1.27 119688 1.36
155176 1.23 114649 1.30
168219 1.33 140128 1.58
755255 7.16 594032 7.95
794365 7.56 636587 8.66
731622 6.92 534711 7.37
833421 7.97 690267 9.29
771608 7.33 613253 8.43
3685552 41.04 3006991 49.12
3649801 40.32 2893803 47.54
3576134 39.61 2895182 47.26
3796035 42.13 3304570 53.29
3589382 39.29 2956995 48.84
15804498200.9013267920250.58
16472633208.3913720664256.89
15867374201.0112497087236.89
16309701208.4213801989262.53
16472551209.1313925654262.57

mystery-ipc1
01
02
03
04
07
09
11
12
15
16
17
18
19
20
24
25
26
27
28
29
30

5
7
4


8
7

6

4

6
7

4
6
5
7
4
9

7 0.00
6 0.00
6 0.00
2404 0.50
8012 11.19
722 1.01
73 0.08
7 0.04
11 0.10
0 0.00
0 0.00
0 0.00
0 0.00
0 0.00
3049 0.37
10764 5.66
1215 1.01
9 0.01
33 0.01
8 0.01
2102777 33.84 2093419 55.582093419 76.80
28271 20.21
21572 41.22
5079 44.42
0 0.15
0 0.27
354 1.32
85 2.74
83 3.59
0 0.00
0 0.00
0 0.00
21717 4.87
4968 5.26 16276 29.28
89887 46.32
84572153.53 53114173.34
0 0.13
0 0.30
9 0.00
10 0.00
9 0.01
1807 0.27
1835 0.30
1344 0.69
14 0.05
159 0.09
6 0.07
8 0.00
47 0.00
15 0.00
31 0.04
14 0.03
10 0.06
23175 5.16
76480169.86
7232 13.30

6 0.20
1672 82.70
5 16.46

6

1.79

10

5.38

5193.75

65 811.87

0 0.00
0 0.00
3165 29.34
8 1.51
8 16.59
2102777 14.612102729 27.84

0
0.00
3868 670.08
34 41.20

198445.85
0 0.00
0 0.00
12478 96.38
285069 59.22 547246578.39
5 0.10
2526 5.94
6 4.80
8 0.63
5 8.94
42112 28.07

5 0.10
346 70.78
6 80.48
8 6.77
5107.10
44893357.07

0

0.00

14
1.22
3107 291.36
7 243.78
31 16.67
27 536.30

30 0.00
770852 21.85
507 0.02

0.00
4.47
0.03

0 0.00
0 0.00
138289 2.18
1458 1.44
426 0.00
19 0.00
2102777 15.09 1177842 21.87
279973 13.21
135 2.62
5400 0.41
0 0.00
133871 3.65
686125 23.28
31 0.00
8455 0.10
2174 0.03
843 0.00
153 0.01
1977063 38.26

Table 17: Similar Table 15 Miconic Mystery domains.
118

8
2368
5

5
0
1516
718

0.35
0.00
5.44
3.76

6 0.00
37 0.05
73 0.04
32 0.00
7 0.02
26686 28.27

fiImplicit Abstraction Heuristics

hF
task h

nodes

hI
time

nodes

hFI

MS-104

MS-105

nodes

time

nodes

nodes

time

0.03
3070
0.04
3561
0.03
3070
0.03
3070
0.03
3070
18.93 587482
18.33 606782

0.05
0.05
0.05
0.05
0.05
22.20
22.53

24
24
24
24
24
621008
594758

0.05
24
0.06
24
0.06
24
0.06
24
0.06
24
4.85 279614
4.69 264535

0.06
0.06
0.06
0.06
0.05
7.86
7.34

0.00
0.02
0.43
1.31

7
1946
21671

time

time

HSPF

nodes

blind
time

hmax
nodes
time

nodes

time

2000
1.02
4822
2378
1.07
5501
2000
1.02
4822
2000
1.02
4822
2000
1.02
4822
379735 217.37 882874
405564 226.32 836647

0.01
0.02
0.01
0.02
0.01
4.91
4.62

4016
4594
4016
4016
4016
822514
787163

0.03
0.04
0.03
0.03
0.03
18.71
17.81

0.00
0.02
1.06
8.22

36
348
4346
104068

0.00
0.01
0.16
2.61

openstacks-ipc5
01
02
03
04
05
06
07

23
23
23
23
23
45
46

2264
2617
2264
2264
2264
366768
410728

0.02
3895
0.03
4485
0.02
3895
0.02
3895
0.02
3895
7.52 779710
8.23 760668

pathways-ipc5
01
02
03
04

6
12
18
17

1624
2755
44928
126950

0.00
0.02
0.62
2.66

1299
2307
20416
33788

0.00
0.01
0.25
0.59

1299
2437
29106
58738

1.14
2.56
6.43

7 0.79
13 42.11
14901129.23
98484288.39

1405
990
14772
34206

0.28
1624
0.29
2984
6.99 87189
27.00 456143

pipesworld-notankage-ipc4
01
02
03
04
05
06
07
08
09
10
11
12
13
14
15
17
19
21
23
24
41

5
12
8
11
8
10
8
10
13
18
20
24
16
30
26
22
24
14
18
24
12

121
0.02
109
0.01
121
0.02
1413
0.06
1542
0.02
1413
0.08
1742
0.14
3001
0.07
1742
0.18
7007
0.45
8911
0.22
7007
0.59
4093
0.49
6805
0.26
4093
0.65
12401
1.44 27377
1.34 12401
2.03
4370
0.97
9168
0.77
4370
1.34
18851
3.84 56189
6.21 20584
6.42
1092472 160.712419903 151.991092472 219.75
313952
684234
39998

27.68 472950 29.55 313952 43.90
75.721319980 133.58 686186 145.41
6.02 117475 18.08 40226 12.69

1594863 254.432588849 192.901594863 353.40
54373931588.68
23833
4.02 49035
7.76 23833
7.87
2285790 568.937047138 871.032282678 843.28
502308 370.68

6 0.04
6 0.04
169 0.30
13 0.17
9 1.15
9 0.69
651 1.95
12 7.05
77 5.63
9 21.15
1299 5.26
61 39.31
233 19.78
9 59.70
561 12.42
497 94.69
104875 25.48
2982520 66.89
90598 9.20 52159 43.24
594661 12.41 416184109.43
12835 34.28
13255718119.54
648132 65.43
3200672 90.07
8767431150.88
3992 18.13
948159.63
296506 49.11 104750256.13
7315150142.82

6
2.79
121 0.00
13
0.00
435
3.07
1808 0.01
792
0.02
128
3.84
3293 0.02
262
0.02
812
8.84 16088 0.11
2925
0.13
155 16.53 11128 0.12
1121
0.15
1151 23.41 49905 0.48
7102
0.72
185 29.88 46502 0.57
2631
0.48
1673 48.84 273585 3.39
22874
3.58
10478 74.265513309 80.62 321861 68.99
6898321439.64
111212451579.77
108503 625.52 710123 3.86 107061 14.51
4332961117.572467804 13.83 464982 56.82
242241019.65 481045 3.14
33417
6.38
4921698 34.90

157782

1.31

5023081092.50

555619 105.49

8966
2.42
481859 229.00
114257 250.18

pipesworld-tankage-ipc4
01
02
03
04
05
06
07
08
11
13
15
17
21
31

5
77
0.02
126
0.01
105
0.02
6 3.54
6 0.13
12
960
0.05
1005
0.02
960
0.06
110 3.04
13 0.20
8
20803
1.89 52139
2.46 20803
2.82
244 22.64
9 36.89
11 110284
8.06 157722
9.60 110284 14.05
3892 16.68
12155.03
8
6531
0.86 13148
1.03
6531
1.32
376 15.46
9120.06
10
20171
2.41 43583
4.32 20171
4.41
1794328.18
11201.44
8 202706 73.8326437521379.11 202706 208.81
11
96043191.77
22 2345399 296.872629204 662.942365735 838.85
660104 28.60 660102162.93
16
188517122.11
30 96520911721.67
2546587141.12
44
12850247352.46
14 839847 250.39
13241 69.80
39 1501847 240.381568963 661.881504072 850.16 1357801124.64

6
3.88
128 0.00
179
6.04
1012 0.01
818 24.47 52983 0.77
8116 64.68 221429 3.06
313 59.99 12764 0.21
3102 97.31 58487 0.87
2695 339.765404036198.08

13
0.01
659
0.02
1802
1.33
41540 14.49
2834
1.61
15746
6.61
104531 420.47

4116344 30.67

752867 334.42

4423951 65.44
1726598 13.56

126845 222.23
919764 381.66

rovers-ipc5
01
02
03
04
05
07
12

10
147
0.00
147
8
44
0.00
44
11
672
0.01
419
8
47
0.00
20
22 808084 22.61 410712
18 4546797 191.34 741649
19
1529551

0.00
147
0.00
0.00
44
0.00
0.00
448
0.01
0.00
24
0.00
9.23 522937 18.29
21.011682245 102.77
76.46

11 0.03
11 0.03
48
0.07
1104 0.00
283
0.00
9 0.00
9 0.00
16
0.03
254 0.00
129
0.00
12 0.11
12 0.12
804
0.16
3543 0.02
757
0.00
9 0.04
9 0.04
58
0.08
897 0.00
223
0.00
617267 11.48 375808 18.46 298400 101.658559690126.19 4318309 81.53
3280884 51.022212903 59.20 1459792 866.93
9618062 199.91
5187273166.77

0.00
29
0.00
0.00
241
0.01
0.01
728
0.04
0.38 11250
0.76
4.92 61692 18.85
51.681518261 105.65

10 0.00
10 0.00
14 0.01
14 0.01
12 0.56
12 0.64
4152 0.99
18 4.43
81972 7.26 148667 69.28
2769229 74.73 307962 32.52

satellite-ipc4
01
02
03
04
05
06

9
24
13
86
11
2249
17
9817
15 279569
20 1496577

0.00
32
0.00
337
0.08
656
0.57 14860
49.47 46453
92.221572327

46
0.06
89
646
0.21
1728
1945
0.93 15185
15890
9.50 345663
267513 565.18

0.00
0.01
0.17
4.70

59
940
6822
180815

0.00
0.00
0.11
3.37

10751017 371.43

Table 18: Similar Table 15 Openstacks, Pathways, PipesworldNoTankage, Pipesworld-Tankage, Rovers, Satellite domains.

119

fiKatz & Domshlak

hF
task h

nodes

hI
time

nodes

hFI
time

nodes

time

MS-104

MS-105

nodes

nodes

time

time

HSPF

nodes

blind
time

hmax
nodes time

nodes

time

0.00
9
0.01
11
0.00
20
0.08
71
0.00
20
0.04
33
0.00
12
0.34
332
0.00
23
0.11
154
0.00
9
0.01
11
0.00
26
0.09
122
0.00
9
0.12
128
0.00
9
0.06
49
0.04
18
1.04
1358
0.00
96
0.19
153
0.00
40
0.17
153
0.00
59
0.16
95
0.00
13
0.06
27
2.58
356 18.99
3562
0.12
2287
1.34
2742
0.00
13
0.03
16
0.00
29
0.21
158
0.77
6338
4.46
9009
0.00
52
0.18
84
0.00
21
0.12
42
0.87
22315
8.16 189516
0.01
30
0.43
200
0.00
21
0.12
42
37.93
28 780.38
8913
0.00
52
0.28
182
0.01
179
0.85
773
0.00
49
0.29
95
1.43
3337
7.12 244499
0.02
393
1.35
2295
6.55
7530 32.97
53911
0.00
352
0.74
435
0.63
947
2.29
2291
0.00
158
0.50
227
6.36
7448
8.27 165170
14.07 188564 111.99 1669788
0.01
277
2.10
1532
0.01
33
0.74
562
0.07
146
1.78
4103
12.86
23371 87.91 1036992
0.00
21
0.16
54
0.18
1773
1.29
1908
0.00
256
0.50
333
0.05
407
2.18
4142
0.00
121
0.74
434
4.05
19865
6.91
80785
0.04
515
2.32
5075
11.08 200559 101.21
23.32 27728751408.64
0.02
390
1.40
690

0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.02
0.01
0.00
0.00
0.04
0.00
0.00
0.67
0.00
0.00
0.12
0.00
0.00
0.00
1.27
0.01
0.25
0.00
0.01
0.00
0.63
9.44
0.00
0.00
0.01
6.74
0.00
0.01
0.00
0.01
0.00
0.25
0.01

9 0.00
47 0.00
28 0.00
102 0.00
69 0.00
9 0.00
62 0.00
52 0.00
20 0.00
376 0.01
142 0.00
113 0.00
86 0.00
18 0.00
324 0.02
1876 0.01
14 0.00
91 0.00
6925 0.08
75 0.00
31 0.00
177138 1.43
116 0.00
31 0.00
854 0.18
142 0.00
616 0.00
79 0.00
192459 2.32
1834 0.01
16766 0.36
424 0.00
1073 0.01
216 0.00
61548 1.06
717884 18.27
1342 0.01
357 0.00
2597 0.02
229210 9.51
35 0.00
1636 0.01
315 0.00
3235 0.02
358 0.00
65984 0.63
4406 0.02
19020089286.02

0.00

642

psr-small-ipc4
01
02
03
04
05
06
07
08
09
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50

8
10 0.00
10 0.00
10 0.00
11
52 0.00
55 0.00
52 0.00
11
31 0.00
31 0.00
31 0.00
10
66 0.00
91 0.00
73 0.00
11
75 0.00
79 0.00
75 0.00
8
10 0.00
10 0.00
10 0.00
11
61 0.00
61 0.00
61 0.00
8
24 0.00
29 0.00
25 0.00
8
18 0.00
19 0.00
18 0.00
7
131 0.01
183 0.00
155 0.01
19
149 0.00
149 0.00
149 0.00
16
120 0.00
123 0.00
120 0.00
15
90 0.00
90 0.00
90 0.00
9
19 0.00
19 0.00
19 0.00
10
1200 0.08
708 0.03
769 0.09
25
2328 0.02
2158 0.01
2176 0.03
9
15 0.00
15 0.00
15 0.00
12
85 0.00
90 0.00
85 0.00
25
8025 0.11
7856 0.05
7876 0.12
17
80 0.00
80 0.00
80 0.00
10
28 0.00
28 0.00
28 0.00
33
163299 4.17 176058 1.56 168685 5.01
12
77 0.00
93 0.00
77 0.00
10
28 0.00
28 0.00
28 0.00
9
485 3.06
463 0.58
482 3.28
17
144 0.00
150 0.00
146 0.00
21
616 0.01
675 0.00
650 0.01
14
79 0.00
79 0.00
79 0.00
21
142772 4.55 187319 2.12 159325 5.80
22
1791 0.03
1982 0.01
1883 0.04
19
11278 0.25
6810 0.08
8297 0.24
24
431 0.01
431 0.00
431 0.01
21
1480 0.02
1436 0.01
1391 0.03
21
223 0.00
223 0.00
223 0.00
22
65965 1.43
63186 0.46
68281 1.70
22
571766 12.62 371834 3.41 458402 11.77
23
1307 0.03
1417 0.01
1363 0.03
13
301 0.01
372 0.00
326 0.01
23
2486 0.05
2942 0.02
2682 0.07
20
259683 8.59 182608 2.70 270195 11.73
10
31 0.00
34 0.00
31 0.00
30
1855 0.02
1747 0.01
1739 0.02
20
328 0.00
328 0.00
328 0.00
19
2990 0.07
3430 0.03
3121 0.08
20
347 0.00
376 0.00
359 0.01
34
60888 0.86
61842 0.31
61563 0.99
27
4104 0.09
4522 0.03
4284 0.11
37 12080249604.4317435137247.2013514084784.80
47
23
637 0.01
659 0.01
645 0.02

9 0.00
9
12 0.00
12
12 0.00
12
11 0.00
11
12 0.00
12
9 0.00
9
12 0.00
12
9 0.00
9
9 0.00
9
8 0.04
8
20 0.00
20
17 0.00
17
16 0.00
16
10 0.00
10
11 0.46
11
975 0.11
26
10 0.00
10
13 0.00
13
2910 0.27
26
18 0.00
18
11 0.00
11
34 0.28
34
13 0.00
13
11 0.00
11
10 5.42
10
18 0.00
18
22 0.01
22
15 0.00
15
22 0.39
22
23 0.01
23
2647 0.89
723
25 0.00
25
446 0.26
22
22 0.00
22
24021 0.83 11113
48350 2.98
2783
24 0.02
24
14 0.01
14
24 0.08
24
38837 1.88
7767
11 0.00
11
1117 0.18
31
21 0.00
21
20 0.05
20
21 0.01
21
36941 0.67 32582
28 0.04
28
129627 2.37
2500
2048368 15.84 594399
24 0.02
24

0.00

tpp-ipc5
01
02
03
04
05
06

5
8
11
14
19
25

6 0.00
6 0.00
6 0.00
9 0.00
11 0.00
9 0.00
12 0.00
27 0.00
16 0.00
15 0.00
78 0.00
47 0.00
623 0.02
5110 0.08
1455 0.05
5843306179.03 6916518 95.86 6153923222.35

6 0.00
9 0.00
12 0.00
15 0.01
20 0.36
947059 14.22

6 0.00
9 0.00
12 0.00
15 0.00
20 0.77
74798 23.97

6
9
12
15
624

0.01
0.01
0.03
0.07
0.48

7
26
116
494
24698

0.00
0.00
0.00
0.00
0.12

6 0.00
16 0.00
83 0.00
430 0.00
17398 0.15
9267024216.69

trucks-ipc5
01
02
03
04
05
06
07
08
09

13
1691 0.03
1027 0.01
1039 0.03
14 0.03
14 0.02
17
9624 0.23
2898 0.04
2957 0.11
4192 0.22
18 0.17
20
80693 2.99
20752 0.44
22236 1.14
199405 2.89 173790 6.88
23 1753866 48.55 1205793 23.48 1315672 50.35 2591561 29.172568634 56.96
25 12472562515.50 8007189242.98 9483222512.55 23444940392.99
30
23 2134728 96.15 719751 16.91 755608 50.72 7575415 88.918080496117.13
25
5199440221.76 6630689687.95
28

285
0.56
5774 0.02
402 0.01
1413
1.04
28348 0.14
939 0.03
4049
4.43 379582 2.97
9465 0.40
8817
7.75 2990366 26.65 209140 9.43
14744 23.12
1248571 90.78
308920 343.47
43270 27.6212410588117.92 223011 19.34
49663 47.61
3106944403.36
233577 248.21

zenotravel-ipc3
01
02
03
04
05
06
07
08
09
10
11

1
6
6
8
11
11
15
11
21
22
14

2 0.00
2 0.00
2 0.00
17 0.00
18 0.00
17 0.00
28 0.01
18 0.01
12 0.01
99 0.01
88 0.01
81 0.01
177 0.01
220 0.01
136 0.02
2287 0.10
1144 0.05
504 0.05
5088 0.16
4234 0.09
4199 0.19
3268 0.35
1026 0.12
1655 0.32
2844771177.70 2842546176.05 2433822262.84
2283679295.65 1921903196.38 1832871383.99
139687 18.63
76904 8.20
93782 19.51

2 0.00
2 0.00
7 0.00
7 0.00
7 0.21
7 0.90
9 0.20
9 0.89
12 0.25
12 1.90
12 0.38
12 3.54
16 0.38
16 3.48
14354 2.00
12 14.48
2517035 51.18 611457 30.47
1322871 34.84 137872 25.44
310030 11.28 110726 26.65

2
0.45
9
0.46
40
3.42
215
3.44
422
7.70
1957 11.81
34890 30.36
83533 292.05

2
58
5160
5256
82289
596531
405626

0.00
0.00
0.04
0.03
0.63
5.90
3.56

2 0.00
22 0.00
492 0.02
665 0.01
12466 0.33
85931 2.47
115348 2.60
687846 50.76

Table 19: Similar Table 15 PSR, TPP, Trucks, Zenotravel domains.
120

fiImplicit Abstraction Heuristics

hF
task

h

hI

hFI

nodes timenodes time nodes

MS-104
time nodes

MS-105

timenodes

HSPF

time nodes

blind
hmax
time nodes time nodes
time

schedule-strips
02-0
02-1
02-2
02-3
02-4
02-5
02-6
02-7
02-8
02-9
03-0
03-1
03-2
03-3
03-4
03-5
03-6
03-7
03-8
03-9
04-0
04-1
04-2
04-3
04-4
04-5
04-6
04-7
04-8
04-9
05-0
05-1
05-2
05-3
05-4
05-5
05-6
05-7
05-8
05-9
06-2
06-4
06-6
07-0
07-7
07-9

3
5 0.07
5 0.04
5 0.08
2
3 0.08
4 0.05
3 0.10
2
3 0.17
3 0.06
3 0.19
3
26 0.17
37 0.06
26 0.18
3
68 0.17 188 0.07
220 0.26
2
3 0.17
3 0.05
3 0.19
2
3 0.07
5 0.04
3 0.09
2
3 0.15
3 0.05
3 0.17
2
3 0.17
3 0.05
3 0.19
3
5 0.07
5 0.04
5 0.08
4
40 0.31 407 0.16
140 0.45
2
3 0.22
3 0.08
3 0.25
4
27 0.21
50 0.09
33 0.25
4
15 0.13
91 0.09
15 0.15
3
4 0.39
16 0.10
4 0.44
4
73 0.38 471 0.14
74 0.43
4
72 0.12
75 0.08
69 0.13
4
28 0.23
50 0.09
28 0.25
4
273 0.43 266 0.14
273 0.48
4
8 0.23
31 0.09
14 0.27
5
373 0.45 1498 0.50
167 0.54
6 1755915.4510707 3.48 17686 17.58
5
209 0.40 406 0.19
66 0.34
5
142 0.40 674 0.25
251 0.58
5
921 1.14 450 0.31
574 1.39
6
483 0.95 4544 1.11
850 2.11
6
779 0.5611610 2.44 1834 1.43
5
99 0.58 424 0.31
163 0.78
5
102 0.52 573 0.24
111 0.60
4
1043 1.27 996 0.67 1050 1.66
5
163 0.86 483 0.51
167 1.05
6
2701 2.951887811.36 1257 3.10
7 11885586.65
158640178.66
7 2715924.884144713.08 13622 16.72
6
989 1.63 3433 1.29
582 1.36
6
198 0.61 9550 4.61
347 1.05
7
603311.164987316.17 10325 16.63
6
944 1.9217562 9.03 2107 4.10
7
1190 2.436153920.22 2709 7.24
6
1537 2.2415829 6.85 2717 5.45
6
888 3.292698622.47 1709 6.91
8 1153520.81
56273131.69
8 1558946.68
41764133.76
7
2489 9.10
6995 25.49
8 1072641.01
38251154.49
8
682919.20
30148109.49

4 511.10
3 104.98
3 231.99
4 56.51
3
3
3
3
4

363.11
121.84
323.77
316.53
251.46

5 191.03
5 259.13
5 682.30
5 121.58
5 195.72
5 235.48
71115.76
6 267.29
7
7
6
6
5

837.68
459.19
936.68
711.65
316.22

41743.32

5
3
3
4
4
3
3
3
3
5

577.39
754.26
495.56
658.90
484.62
667.32
697.42
604.06
668.79
577.16

76 0.02
5
0.09
6 0.02
3
0.07
5 0.02
3
0.07
529 0.03
95
0.45
543 0.03
108
0.44
3 0.03
3
0.07
6 0.02
3
0.06
13 0.02
3
0.07
8 0.02
3
0.07
76 0.03
5
0.09
11915 0.60 1127
8.98
31 0.04
25
0.37
3617 0.23 1228
9.56
3379 0.23
170
1.85
41223.90
301 0.06
22
0.27
12217 0.64 1175 12.43
2663 0.19 1542 11.73
12859 0.68 1323 13.47
12616 0.65 1590 11.13
4339 0.27
913
7.69
31219326.88 22993 273.38
55206949.79
47696 4.97 9703 131.69
89272 8.74 12941 163.84
62013 6.03 13614 168.07
1079781399.99
1071151001.40
61327 5.97 8683 103.50
34046729.56 15122 181.98
41673 4.27 5480 83.69
14335022.71 43336 751.35

120602 989.42

Table 20: Similar Table 15 (non-IPC) Schedule-STRIPS domain.

121

fiKatz & Domshlak

hF
task

h

nodes

hI

hFI

HSPF

blind

time

nodes

time

nodes

time

nodes

time

nodes

time

0.39
0.45
4.00
10.59
68.19
125.83
1.34
3.39
18.43
43.80
31.37
327.82
5.99
112.11
335.39
291.88
203.57
249.28

10507
5184
219439
294029
3269854
3869775
50734
78362
432280
1325517
2823019

0.84
1.12
13.43
74.29
290.07
1167.78
4.64
23.84
66.00
337.57
570.43

8333
4044
139760
146396
2113017
1965371
31545
46386
297147
687420
1255479

1.03
1.46
15.62
62.26
317.53
965.39
5.00
21.36
68.80
290.86
425.27

12935
4810
276441
278087

30.55
42.63
469.96
885.94

26670
16162
650316
1025329
9567169

0.40
0.49
11.32
29.51
174.38

72109
74663

190.25
325.43

145170
152021
1426461
6238743

2.53
4.47
32.06
199.63

79574
859710
10935187

9.93
349.90
1208.05

66582
757718
7542146

13.62
395.63
1319.93

123510

443.99

194669
1633295

4.28
57.19

4430537

1578.04

49
144
317
2208
4220
998
61253
70808
4920
5261
98783
10580
398023
157304
711526
411732
421646
34754
812451
473553
173929

0.37
0.73
1.32
2.63
4.87
5.66
40.74
57.12
18.26
23.40
105.44
43.05
443.57
222.14
1034.92
671.53
745.34
186.40
1731.49
1018.62
651.93

193
769
1665
8113
17151
3288
201137
234328
114281
72673
563261
341169
2547985
1233115
11926297
4928793
8065113
953049

0.00
0.00
0.01
0.06
0.16
0.02
2.31
2.92
1.32
0.76
7.17
4.11
35.07
17.19
184.57
75.73
128.80
14.32

1536764

27.62

12
19
334
993
6922
19613
10
153
8348
422571
9
22
260
2281
68293
121897

0.20
1.44
0.72
11.21
35.00
115.36
0.55
3.39
18.14
792.78
0.09
0.51
2.03
6.38
145.47
404.98

20
1375
4903
12302518

0.00
0.01
0.03
126.46

23
5138
1130810

0.00
0.05
12.72

16
2485
285823

0.00
0.02
3.32

44047
45529
45882
10175657
10310817
10321465
54
54
54
10170980
10254740
10294023

0.68
0.54
0.49
314.87
242.27
222.66
0.01
0.01
0.01
113.29
95.91
88.03

elevators-strips-ipc6
01
02
03
04
05
06
11
12
13
14
15
18
21
22
23
24
25
26

42
26
55
40
55
53
56
54
59
63
66
61
48
54
69
56
63
48

7483
2898
61649
60039
909822
716238
18313
21812
186526
248709
201777
1057327
71003
890048
4089071
1430559
1384406
699757

openstacks-strips-ipc6
01
02
03
04
05
06
07
08
09
10
11
12
13
14
15
16
17
18
19
21
22

2
2
2
3
4
2
5
5
3
3
4
3
4
4
4
4
4
3
4
3
4

209
769
1729
8209
16705
3658
195109
228847
116425
77681
575677
354913
2596593
1260363
11995225
5064737
8193065
1020905

0.00
0.02
0.04
0.17
0.41
0.11
5.85
7.77
5.03
3.57
28.75
19.85
150.86
81.43
867.27
379.45
673.91
88.15

209
769
1729
8209
16705
3658
195109
228847
116425
77681
575677
354913
2596593
1260363
11995225
5064737
8193065
1020905

0.00
0.00
0.01
0.07
0.18
0.04
2.45
3.23
1.61
1.10
9.11
5.63
46.30
23.36
245.32
104.37
179.00
22.24

209
769
1729
8209
16705
3658
195109
228847
116425
77681
575677
354913
2596593
1260363
11995225
5064737
8193065
1020905

0.00
0.02
0.04
0.20
0.48
0.13
6.85
9.06
5.77
4.14
32.97
22.85
172.13
93.01
987.24
432.44
765.15
99.67

1805050

204.83

1805050

48.73

1805050

233.98

0.01
0.02
0.04
13.85
219.49
613.02
0.01
0.07
5.83
463.93
0.00
0.01
0.28
8.49

15
183
821
77520
892002
3529327
24
1243
144084

0.00
0.01
0.01
2.28
31.78
148.95
0.00
0.04
4.27

15
179
668
68116
822442
3443221
24
1135
97683

0.00
0.02
0.03
7.56
115.96
557.75
0.01
0.08
9.25

13
303
15825
694503

0.00
0.01
0.47
24.62

13
282
8778
316839

0.00
0.02
0.63
31.37

1.68
1.88
1.90
687.38
870.50
869.52
0.14
0.15
0.14
834.36
720.23
643.41

22012
37569
43298

5.20
4.36
4.02

19809
37524
43298

6.39
6.07
5.71

21259
29253
37754

13.69
13.92
14.05

51
51
51

0.08
0.08
0.08

46
46
46

0.20
0.19
0.19

6
6
6

0.05
0.05
0.05

parcprinter-strips-ipc6
01
02
03
04
05
06
11
12
13
14
21
22
23
24
25
26

169009
438047
807114
876094
1145132
1514200
182808
510256
693064
1020512
143411
375821
519232
751642
1215840
1216460

19
240
880
142314
1780073
4113487
25
1183
74201
4491265
13
225
4376
96748

scanalyzer-strips-ipc6
01
02
03
04
05
06
22
23
24
25
26
27

18
22
26
24
30
36
13
13
13
26
30
34

19788
37182
43115
3947796
9193480
10140909
46
46
46
8974317
9936832
10202674

Table 21: Runtimes cost-optimal heuristic-search planners Elevators,
Openstacks-strips-08, Parcprinter, Scanalyzer domains. description planners given Section 6; fork-decomposition heuristics via structural-pattern databases. Column task denotes problem instance,
column h denotes optimal solution length. columns capture run time
number expanded nodes.

122

fiImplicit Abstraction Heuristics

hF
task

h

hI

nodes

hFI

HSPF

blind

time

nodes

time

nodes

time

nodes

time

nodes

time

0.02
0.07
0.07
0.07
0.03
0.16
0.08
2.56
0.36
2.45
1.08
2.98
2.51
4.82
5.84
0.83
22.38
4.93
20.71
27.36
41.78
5.66
97.46
106.00
68.95
553.11
523.12

10
83
209
181
251
901
110
25253
3951
28241
12881
37358
33374
55127
73733
10598
300972
50222
257988
293860
494477
48190
954593
1219589
899323
6943124
2121936

0.02
0.12
0.12
0.12
0.02
0.14
0.12
0.71
0.20
0.77
0.38
0.86
0.76
1.29
1.67
0.33
6.38
1.37
5.62
8.56
11.49
1.43
25.16
31.83
25.33
177.06
82.61

10
83
209
181
251
901
110
25253
3951
28241
12881
37358
33374
55127
73733
10598
300972
50222
257988
293860
494477
48190
954593
1219589
899323
6943124
2121936

0.03
0.18
0.19
0.19
0.04
0.27
0.18
2.89
0.53
3.21
1.36
3.63
3.09
5.63
7.09
1.10
27.00
5.55
24.49
36.43
50.51
5.95
108.53
136.27
107.61
719.81
339.83

6
20
50
15
43
247
26
7898
757
7522
5979
21133
25897
17144
37810
7939
282810
10358
90950
83693
141906
13123
181830
271157
201932
2031156
132701

0.16
5.17
6.91
1.82
5.62
25.68
11.67
28.50
23.02
28.25
20.60
32.73
33.29
32.20
38.72
27.70
124.39
29.81
61.77
63.99
87.89
30.94
114.89
157.50
122.27
1024.04
118.20

11
66
174
192
242
1265
215
30776
3538
29658
13430
38561
32370
62047
76150
10090
294396
62726
275969
328583
545896
69465
1258767
1324907
830182
7178802
6091864

0.00
0.01
0.00
0.01
0.01
0.01
0.01
0.15
0.03
0.14
0.06
0.18
0.15
0.29
0.35
0.05
1.44
0.29
1.29
1.63
2.64
0.33
6.17
6.69
4.33
37.78
34.53

372
551
394
130524
50
526
47522
2114443
23083
69797
271598
155166
169436
20737
7943562
335238
80459
2109516
5238957
648
337852
5866700
3565151
14504610

0.03
0.02
0.01
5.57
0.32
0.04
2.81
135.12
1.47
3.17
15.63
10.98
8.93
1.05
602.99
20.20
4.17
156.88
354.84
0.14
74.21
473.77
222.48
1151.55

287
497
177
45048
203202
534
42195
1204212
26189
21291
282061
60655
294710
6984
7742698
242778
40425
119938
3558809
648
450027
4053413
3613835
2244156
23044275
12138101

0.01
0.01
0.00
0.28
7.28
0.01
0.38
11.27
0.26
0.18
2.09
0.70
3.63
0.07
84.75
1.66
0.29
0.97
33.60
0.69
14.64
45.18
50.31
30.10
275.91
152.95

269
509
173
44198
3073
526
28163
1080337
16013
20741
271598
46865
169436
6952
7456505
240912
36889
119784
3459314
648
76647
3868663
2563159
1759660
17832156
10473204
8738457

0.02
0.02
0.01
2.07
0.96
0.04
1.84
74.55
1.12
1.07
16.87
3.69
10.26
0.41
622.89
15.14
2.05
9.18
251.38
0.79
16.85
335.31
181.66
154.33
1612.04
996.25
1131.26

1079
700
621
282895

6.17
4.57
2.63
177.07

6815
75669

6.83
174.92

459188
620685
440869

400.45
315.43
586.91

1631677
178574

994.61
121.96

852948
239522

859.44
220.86

1762
1348
1165
320446
9607487
10526
315405
13329538
818693
852150
531305
4705742
2363177
255203
21598353
935561
317984
7219504
23255133
649

0.01
0.00
0.00
1.43
81.84
0.04
1.49
77.70
4.09
4.07
2.71
25.21
12.60
1.17
120.25
4.74
1.43
39.20
130.46
0.01

2074534

679.61
12
874
225310
1462063
111
9976
224986
67
4455
56897
292004

0.00
0.10
48.69
714.49
0.01
1.41
74.09
0.00
0.37
13.82
120.98

16
998
257608
1660874
103
11130
246069
62
5408
70579
382588

0.01
0.15
59.28
856.87
0.02
1.70
89.04
0.01
0.54
19.32
196.82

60
1567
380982

0.48
6.36
274.86

135
14874
373133
62
7544
100347

0.94
19.85
454.55
0.50
7.71
92.93

64
2093
408643
4204372
164
14796
408449
112
7610
106548
1663856

0.00
0.01
3.69
50.69
0.00
0.12
4.36
0.00
0.06
1.07
19.29

119
409
80794
50
11665
113386
16
1931
4673

0.85
3.03
136.95
0.93
18.49
273.76
0.91
5.96
9.05

9086
21076

0.09
0.30

3487
1862476

0.05
37.91

227
177942
962698

0.00
3.97
23.76

pegsol-strips-ipc6
01
02
03
04
05
06
07
08
09
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27

2
5
4
4
4
4
3
6
5
6
7
8
9
7
8
8
10
7
8
7
8
6
8
8
8
9
7

12
84
208
193
266
1343
217
31681
3743
29756
13832
39340
33379
63096
77932
10491
299676
63247
279822
329570
548254
69922
1262645
1326517
830637
7196836
6092258

sokoban-strips-ipc6
01
02
03
04
05
06
07
08
09
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
30

11
9
10
29
8
9
15
31
19
30
35
32
20
29
76
50
37
49
47
2
10
44
31
50
39
33
23
14

transport-strips-ipc6
01
02
03
04
11
12
13
21
22
23
24

54
131
250
318
456
594
550
478
632
630
614

60
1558
380375
3526204
135
14873
372845
62
7544
100269
1587821

0.01
0.06
10.47
164.35
0.02
0.37
15.07
0.01
0.18
3.65
77.96

woodworking-strips-ipc6
01
02
03
11
12
13
21
22
23

170
185
275
130
225
215
95
185
195

4313
5550

0.23
0.34

3716
5054

0.10
0.14

4157
5408

0.28
0.41

860
328229
4413726
54
31189
44641

0.10
41.44
954.34
0.02
4.66
8.39

987
328728
4125788
54
67528
155426

0.05
16.57
455.35
0.02
3.26
9.71

897
328930
4404104
53
38912
64840

0.13
52.03
1297.06
0.03
6.83
14.42

Table 22: Similar Table 21 Pegsol, Sokoban, Transport, Woodworking domains.
123

fiKatz & Domshlak

References
Backstrom, C., & Nebel, B. (1995). Complexity results SAS+ planning. Computational
Intelligence, 11 (4), 625655.
Bonet, B., & Geffner, H. (2001). Planning heuristic search. Artificial Intelligence, 129 (1
2), 533.
Bylander, T. (1994). computational complexity propositional STRIPS planning.
Artificial Intelligence, 69 (1-2), 165204.
Chen, H., & Gimenez, O. (2008). Causal graphs structurally restricted planning. Proceedings 18th International Conference Automated Planning Scheduling
(ICAPS), pp. 3643, Sydney, Australia.
Clarke, E., Grumberg, O., & Peled, D. (1999). Model Checking. MIT Press.
Coles, A. I., Fox, M., Long, D., & Smith, A. J. (2008). Additive-disjunctive heuristics
optimal planning. Proceedings 18th International Conference Automated
Planning Scheduling (ICAPS), pp. 4451.
Culberson, J., & Schaeffer, J. (1998). Pattern databases. Computational Intelligence, 14 (4),
318334.
Domshlak, C., & Dinitz, Y. (2001). Multi-agent off-line coordination: Structure complexity. Proceedings Sixth European Conference Planning (ECP), pp. 277288.
Domshlak, C., Hoffmann, J., & Sabharwal, A. (2009). Friends foes? planning
satisfiability abstract CNF encodings. Journal Artificial Intelligence Research,
36, 415469.
Domshlak, C., Katz, M., & Lefler, S. (2010). abstractions met landmarks. Proceedings 20th International Conference Automated Planning Scheduling
(ICAPS), pp. 5056, Toronto, Canada.
Drager, K., Finkbeiner, B., & Podelski, A. (2006). Directed model checking distancepreserving abstractions. Valmari, A. (Ed.), Proceedings 13th International
SPIN Workshop Model Checking Software, Vol. 3925 Lecture Notes Computer
Science, pp. 1936, Berlin Heidelberg. Springer-Verlag.
Edelkamp, S. (2001). Planning pattern databases. Proceedings European
Conference Planning (ECP), pp. 1334.
Edelkamp, S. (2002). Symbolic pattern databases heuristic search planning. Proceedings International Conference AI Planning Scheduling (AIPS), pp.
274293.
Edelkamp, S. (2006). Automated creation pattern database search heuristics. Proceedings 4th Workshop Model Checking Artificial Intelligence (MoChArt).
Edelkamp, S., & Kissmann, P. (2009). Optimal symbolic planning action costs
preferences. Proceedings 21st International Joint Conference Artificial
Intelligence (IJCAI), pp. 16901695, Pasadena, CA, US.
Felner, A., Korf, R. E., & Hanan, S. (2004). Additive pattern database heuristics. Journal
Artificial Intelligence Research, 22, 279318.
124

fiImplicit Abstraction Heuristics

Haslum, P. (2008). Additive reversed relaxed reachability heuristics revisited. Proceedings 6th International Planning Competition.
Haslum, P., Bonet, B., & Geffner, H. (2005). New admissible heuristics domainindependent planning. Proceedings Twentieth National Conference Artificial Intelligence (AAAI), pp. 11631168.
Haslum, P., Botea, A., Helmert, M., Bonet, B., & Koenig, S. (2007). Domain-independent
construction pattern database heuristics cost-optimal planning. Proceedings
19th National Conference Artificial Intelligence (AAAI), pp. 10071012.
Haslum, P., & Geffner, H. (2000). Admissible heuristics optimal planning. Proceedings Fifth International Conference Artificial Intelligence Planning Systems
(ICAPS), pp. 140149.
Helmert, M. (2003). Complexity results standard benchmark domains planning.
Artificial Intelligence, 146 (2), 219262.
Helmert, M. (2004). planning heuristic based causal graph analysis. Proceedings
14th International Conference Automated Planning Scheduling (ICAPS),
pp. 161170, Whistler, Canada.
Helmert, M. (2006). Fast Downward planning system. Journal Artificial Intelligence
Research, 26, 191246.
Helmert, M., & Domshlak, C. (2009). Landmarks, critical paths abstractions: Whats
difference anyway?. Proceedings 19th International Conference Automated Planning Scheduling (ICAPS), pp. 162169, Thessaloniki, Greece.
Helmert, M., Haslum, P., & Hoffmann, J. (2007). Flexible abstraction heuristics optimal
sequential planning. Proceedings 17th International Conference Automated
Planning Scheduling (ICAPS), pp. 176183, Providence, RI, USA.
Helmert, M., & Mattmuller, R. (2008). Accuracy admissible heuristic functions selected planning domains. Proceedings 23rd AAAI Conference Artificial
Intelligence, pp. 938943, Chicago, USA.
Helmert, M. (2008). Understanding Planning Tasks: Domain Complexity Heuristic
Decomposition, Vol. 4929 Lecture Notes Computer Science. Springer.
Hernadvolgyi, I., & Holte, R. (1999). PSVN: vector representation production systems.
Tech. rep. 1999-07, University Ottawa.
Jonsson, A. (2007). role macros tractable planning causal graphs. Proceedings International Joint Conference Artificial Intelligence (IJCAI-07),
pp. 19361941.
Jonsson, P., & Backstrom, C. (1998). State-variable planning structural restrictions:
Algorithms complexity. Artificial Intelligence, 100 (12), 125176.
Karpas, E., & Domshlak, C. (2009). Cost-optimal planning landmarks. Proceedings
International Joint Conference Artificial Intelligence (IJCAI-09), pp. 1728
1733, Pasadena, CA, USA.
125

fiKatz & Domshlak

Katz, M., & Domshlak, C. (2007a). Structural patterns heuristics. ICAPS-07 Workshop Heuristics Domain-independent Planning: Progress, Ideas, Limitations,
Challenges, Providence, RI, USA.
Katz, M., & Domshlak, C. (2007b). Structural patterns tractable sequentially-optimal
planning. Proceedings 17th International Conference Automated Planning
Scheduling (ICAPS), pp. 200207, Providence, RI, USA.
Katz, M., & Domshlak, C. (2008). Structural patterns heuristics via fork decomposition.
Proceedings 18th International Conference Automated Planning Scheduling (ICAPS), pp. 182189, Sydney, Australia.
Katz, M., & Domshlak, C. (2009). Structural-pattern databases. Proceedings
19th International Conference Automated Planning Scheduling (ICAPS), pp.
186193, Thessaloniki, Greece.
Katz, M., & Domshlak, C. (2010). Optimal admissible composition abstraction heuristics.
Artificial Intelligence, 174, 767798.
Pearl, J. (1984). Heuristics - Intelligent Search Strategies Computer Problem Solving.
Addison-Wesley.
Prieditis, A. (1993). Machine discovery effective admissible heuristics. Machine Learning,
12, 117141.
Richter, S., Helmert, M., & Westphal, M. (2008). Landmarks revisited. Proceedings
Twenty-Third National Conference Artificial Intelligence (AAAI), pp. 975982,
Chicago, IL, USA.
Yang, F., Culberson, J., & Holte, R. (2007). general additive search abstraction. Tech.
rep. TR07-06, University Alberta.
Yang, F., Culberson, J., Holte, R., Zahavi, U., & Felner, A. (2008). general theory
additive state space abstractions. Journal Artificial Intelligence Research, 32,
631662.

126

fi
