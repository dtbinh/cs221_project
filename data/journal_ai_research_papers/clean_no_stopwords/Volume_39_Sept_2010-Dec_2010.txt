Journal Artificial Intelligence Research 39 (2010) 633-662Submitted 05/10; published 11/10Utility-Theoretic Approach Privacy Online ServicesAndreas KrauseKRAUSEA @ CALTECH . EDUCalifornia Institute Technology,1200 E California Blvd.,Pasadena, CA 91125, USAEric HorvitzHORVITZ @ MICROSOFT. COMMicrosoft Research,One Microsoft Way,Redmond, WA 98052-6399, USAAbstractOnline offerings web search, news portals, e-commerce applications face challenge providing high-quality service large, heterogeneous user base. Recent effortshighlighted potential improve performance introducing methods personalize servicesbased special knowledge users context. example, users demographics,location, past search browsing may useful enhancing results offered responseweb search queries. However, reasonable concerns privacy users, providers,government agencies acting behalf citizens, may limit access services information. introduce explore economics privacy personalization, people optshare personal information, standing on-demand manner, return expected enhancements quality online service. focus example web search formulaterealistic objective functions search efficacy privacy. demonstrate findprovably near-optimal optimization utility-privacy tradeoff efficient manner. evaluate methodology data drawn log search activity volunteer participants.separately assess users preferences privacy utility via large-scale survey, aimedeliciting preferences peoples willingness trade sharing personal data returnsgains search efficiency. show significant level personalization achieved usingrelatively small amount information users.1. IntroductionInformation preferences, activities, demographic attributes people using onlineapplications leveraged personalize services individuals groups users.example, knowledge current locations users performing web searches help identifyinformational goals. Researchers organizations pursued explicit implicit methodspersonalizing online services. web search, explicit personalization methods rely usersindicating sets topics interest stored server client. Implicit methods make useinformation collected absence user effort awareness. Data collected implicitlyweb search include users locations search activities, capturing informationpeople specify reformulate queries click, dwell, navigate results. Beyond websearch, data collected users implicit manner used custom-tailor behaviorsbroad spectrum online applications informational services like news summarizersc2010AI Access Foundation. rights reserved.fiK RAUSE & H ORVITZe-commerce services provide access online shopping, seek maximize salestargeted advertising.potential value harnessing data people enhance online services coupledgrowing ubiquity online services raises reasonable concerns privacy. usershosts online applications may benefit custom-tailoring services. However,may uncomfortable access use personal information. increasingdiscussion incursions privacy users implied general logging storingonline data (Adar, 2007). Beyond general anxieties sharing personal information, people mayspecifically concerns becoming increasingly identifiable; increasing amountspersonal data acquired, users become members increasingly smaller groups peopleassociated attributes.work date personalizing online services either ignored challenges privacyfocused efforts solely maximizing utility (c.f., Sugiyama, Hatano, & Ikoma, 2004)completely bypassed use personal data. One vein research explored feasibilitypersonalizing services methods restrict collection analysis personal datausers computing devices (Horvitz, 2006). Research realm includes efforts personalizeweb search making use content stored local machines, captured within indexdesktop search service (Teevan, Dumais, & Horvitz, 2005; Xu, Zhang, & Wang, 2007). Rathercut opportunities make personal data available enhancing online services limit personalization client-side analyses, introduce study utility-theoretic methods balancecosts sharing personal data online services return benefits personalization. decision-theoretic perspective privacy allow systems weigh benefitsenhancements come adaptation costs sensing storage according userspreferences.characterize utility sharing attributes private data via value-of-information analysestake consideration preferences users sharing personal information.explicitly quantify preferences utility privacy solve optimization problemfind best trade. approach based two fundamental observations. first that,practical applications, utility gained sharing personal data may often diminishingreturns property; acquiring information user adds decreasing amounts utilitypersonalization given already known users needs intentions. contrary,information acquired user, concerning breach privacy becomes.example, set individually non-identifying pieces information may, combined,hone user membership small group, even identify individual. mapproperties diminishing returns utility concomitant accelerating costs revelationcombinatorial concepts submodularity supermodularity, respectively.Although economic perspective privacy relevant wide spectrum applications,studies foundations privacy broadly, shall illustrate concepts application personalizing web search. employ probabilistic model predict web pagesearcher going visit given search query attributes describing user. defineutility set personal attributes focusing power information gained respect prediction task. Similarly, use probabilistic model quantify riskidentifying users given set personal attributes. combine utility cost functionssingle objective function, use find small set attributes maximallyincreases likelihood predicting target website, making identification user634fiA U TILITY-T HEORETIC PPROACH P RIVACY NLINE ERVICESdifficult possible. challenges optimization identifying benefits costssharing information grappling computational hardness analysis. Solvingbest set attributes users reveal (and hence optimal setting utility-privacytradeoff) NP-hard search problem, thus intractable general large sets attributes.shall demonstrate use submodularity utility supermodularity privacy order find near-optimal tradeoff efficiently. knowledge, existing approach(such LeFevre, DeWitt, & Ramakrishnan, 2006; Chen, LeFevre, & Ramakrishnan, 2007; Hore &R. Jammalamadaka, 2007) provides theoretical guarantees. evaluate approach realworld search log data, well data collected user study 1,400 participantsfocused elicitation preferences sharing sensitive information. results indicateexistence prominent sweet spots utility-privacy tradeoff curve,utility achieved sharing minimal amount private information.manuscript organized follows. Section 2, formalize utility-privacy tradeoffoptimization problem introduce objective functions. Section 3 identifies submodularsupermodular structure utility cost functions. Section 4, introduce algorithmfinding near-optimal solution, exploits combinatorial structure. Section 6,describe experimental design user study. Section 5 describes experimental setup,Section 7 presents empirical evaluation approach real-world search data. Section 8presents related work. Section 9 reviews approaches deploying methodology describedpaper, Section 10 presents summary conclusions.2. Privacy-Aware Personalizationconsider challenge personalization diagnosis uncertainty: seek predictsearchers information goals, given noisy clues query terms potentially additional attributes describe users interests activities. frame challenge probabilistically(as done, e.g., Dou, Song, & Wen, 2007; Downey, Dumais, & Horvitz, 2007 search context),modeling joint distribution P random variables, comprise target intention X,request-specific attributes (e.g., query term) Q, identity user , several attributes V = {V1 , V2 , . . . , Vm } containing private information. attributes include user-specificvariables (such demographic information, search history, word frequencies local machine,etc.) request-specific variables (such period time since identical query submitted). describe concrete attributes used work web search context Section 5.Additional examples described Downey et al. (2007) Teevan et al. (2005). shall describe use statistical techniques learn predictive model P training data frequentqueries. Then, present methods trading utility privacy context model.2.1 Utility Accessing Private DataUpon receiving new request Q, given subset V attributes, use probabilistic model predict target intention performing inference, computing conditionaldistribution P (X | Q, A). Then, use distribution inform decision of, e.g.,search results present user. use notation #intents refer domain size X(e.g., maximum number different webpages clicked users). hope personalization additional knowledge user (i.e., observed set attributes A) helpsimplify prediction task, via reducing uncertainty P (X | Q, A). Based intuition,635fiK RAUSE & H ORVITZquantify uncertainty prediction using conditional Shannon entropy (c.f., Cover &Thomas, 1991) associated variance target web sites following queries,XP (x, q, a) log2 P (x | q, a).H(X | Q, A) =x,q,aHence, subset V, define utility U (A) information gain, i.e., expectedentropy reduction achieved observing A:U (A) = H(X | Q) H(X | Q, A)XP (x, q, a) [log2 P (x | q) log2 P (x | q, a)] .=x,q,aclick entropy previously found effective Dou et al. (2007).2.2 Cost Sharing Private DataSeveral different models privacy proposed prior work (c.f., Sweeney, 2002; Machanavajjhala, Kifer, Gehrke, & Venkitasubramaniam, 2006; Dwork, 2006). cost function motivatedconsideration sets attributes V preferred make identification individuals difficult possible. consider observed attributes noisy observations(unobserved) identity = user. Intuitively, want associate high cost C(A)sets allow accurate prediction given A, low cost sets conditional distributions P (Y | A) highly uncertain. distribution P (Y ) users, hencedefine identifiability loss function L(P (Y )) maps probability distributions usersreal numbers. L chosen way, exists user P (Y = y) close1, loss L(P (Y )) large. P (Y ) uniform distribution, L(P (Y )) close0. explore different loss functions L below. Based loss functions, defineidentifiability cost I(A) expected loss conditional distributions P (Y | = a),expectation taken observations = a1 :XI(A) =P (a)L(P (Y | = a)).P addition identifiability, introduce additional additive cost component S(A) =aA s(a), s(a) 0 nonnegative quantity modeling subjective sensitivity attribute a, additive costs, data acquisition cost, etc. final cost function C(A)combination identifiability cost I(A) sensitivity S(A), i.e., C(A) = I(A) + S(A).2.2.1 DENTIFIABILITY L OSS F UNCTIONSseveral ways quantify identifiability. One approach representing loss Lnegative entropy distribution P (Y ) users identity 2 , used quantify utility.However, context privacy, choice rather poor: Consider case seekquantify cost associated change identifiability user comes learning1. Similarly, additionally take expectation request Q2. Note instead users identity (composed attribute values) principle could refer particularsensitive attribute (such as, e.g., sexual orientation).636fiA U TILITY-T HEORETIC PPROACH P RIVACY NLINE ERVICESsearchers gender. Assuming equal distribution males females, learning gendersearcher would halve space possible searchers, hence increasing entropy lossone. However, increase independent whether start (a) one billion (b) twosearchers. contrast influence utility, halving search space pages considerlarge gain, independent number pages start (Dou et al., 2007), diminishment anonymity enormous: case (a), adversary trying identify searcher basedknowing gender almost chance success, whereas case (b) would alwaysidentify person. Motivated consideration, represent privacy cost experiments maxprob loss (Chen et al., 2007), Lm (P (Y )) = maxy P (y). loss functioninterpreted follows: adversary seeks identify user , predicts likely user,receives one unit reward user guessed correctly, 0 otherwise. identifiability costXP (a) max(P (y | = a))Im (A) =expected win obtained adversary. objective function makes sensebelieve adversary access data sources (and thus probabilitydistribution P captures assumptions adversarys inferences). also consider costfunctionXI` (A) =P (a) log 1 max(P (y | = a)) .I` rescaled variant maxprob loss, property certainty (i.e., maxy (P (y |= a) 1) severely penalized.Another criterion identifiability k-anonymity (Sweeney, 2002). measure, dataset called k-anonymous, combination attributes matched least k people.define probabilistic notion k-anonymity, Ik , using loss function Lk (P (Y )) 1P nonzero less k values , 0 otherwise. identifiability costXIk (A) =P (a)Lk (P (Y | = a)).Ik (A) interpreted expected number violations k-anonymity; database (empirical distribution users) k-anonymous Ik (A) = 0. See Lebanon, Scannapieco,Fouad, Bertino (2009) justification using decision-theoretic analysis quantify privacy inferential attacks side information handled.experimentally compare cost metrics Section 7.1.2.3 Optimizing Utility-Privacy TradeoffPreviously, described quantify utility U (A) given set attributes A,associated privacy cost C(A). goal find set A, U (A) largepossible, keeping C(A) small possible. optimize utility users tradeoff,use scalarization (Boyd & Vandenberghe, 2004), define new, scalar objectiveF (A) = U (A) C(A).637fiK RAUSE & H ORVITZHereby, plays role privacy-to-utility conversion factor. goal solve followingoptimization problem:= argmax F (A)(2.1)varying , find different solutions .choose small , find solutionshigher utility higher cost; large values lead lower utility, also lower privacy cost.set attributes V large, (2.1) difficult search problem, number subsetsgrows exponentially size V. shown solution problem hardeven approximate:Theorem 2.1. constant > (11/e) exists algorithm guaranteedfind set A0 F1 (A0 ) maxA F1 (A), P = N P .proofs theorems presented Appendix. Given complexity, cannotexpect find solution efficiently achieves even slightly (1 1/e) 63%optimal score. However, find solution guaranteed achieve least 1/3optimal value.2.4 Hard Constraints Privacy CostInstead optimizing tradeoff F (A) = U (A) C(A), one may interested maximizingutility U (A) subject hard constraint cost C(A), i.e., solve= argmax U (A) s.t. C(A) B,(2.2)value B 0. example, users may interested maximizing utility enforcing k-anonymity (in case would constrain Ik (A) 0). solution would provideper-user guarantees, i.e., k-anonymity never violated. principle, one could solve tradeoffF (i.e., problem (2.1)) different values then, e.g., using binary search, choosemaximizes U (A) among feasible solutions (i.e., C(A) B). sense, (2.1) seenLagrangian relaxation (2.2).following, focus tradeoff problem (2.1). Using procedure describedabove, approach may useful solve constrained problem (2.2) practice (howeverapproximation guarantees hold problem (2.1)).3. Properties Utility-Privacy Tradeoffmentioned above, would expect intuitively information alreadyuser (i.e., larger |A|), less observation new, previously unobserved, attribute wouldhelp enhancing service. combinatorial notion submodularity formally captures intuition. set function G : 2V R mapping subsets V real numbers called submodular (Nemhauser, Wolsey, & Fisher, 1978), B V, V 0 V\B, holds G(A{V 0 }) G(A) G(B {V 0 } G(B), i.e., adding V 0 set increases G adding V 0superset B A. G called nondecreasing, B V holds G(A) G(B).result Krause Guestrin (2005) shows that, certain common conditional independence conditions, reduction click entropy submodular nondecreasing:638fiA U TILITY-T HEORETIC PPROACH P RIVACY NLINE ERVICESTheorem 3.1 (Krause & Guestrin,Q 2005). attributes V conditionally independent givenX, i.e., P (V1 , . . . , Vm | X) = P (Vi | X) U (A) submodular A.discussed earlier expect privacy cost behave differently: Adding new attribute would likely make stronger incursion personal privacy know great dealuser, less know little. increasing costs property corresponds combinatorial notion supermodularity: set function G : 2V R called supermodular (Nemhauseret al., 1978), B V, V 0 V \ V , holds G(A {V 0 }) G(A)G(B {V 0 } G(B), i.e., adding V 0 large set B increases G adding V 0 subsetB. fact, prove maxprob identifiability cost function introduced Section 2supermodular.Theorem 3.2. Assume, attributes V marginally independent, user completelycharacterized attributes, i.e., = (V). maxprob loss Im (A) supermodular A.Note attribute sensitivity S(A) per definition additive hence supermodular well.Thus, positive linear combination supermodular functions, C(A) = I(A) + S(A) supermodular I(A) = Im (A). empirical evaluation, verify submodularity U (A)supermodularity C(A) even without assumptions made Theorem 3.1 Theorem 3.2.Motivated insights combinatorial properties utility privacy,formulate general approach trading utility privacy. assume utilityU (A) submodular set function, C(A) supermodular set function. definegeneral utility-privacy tradeoff problem follows:Problem 3.3. Given set V possible attributes select, nondecreasing submodular utilityfunction U (A), nondecreasing supermodular cost function C(A), constant 0, goalfind set= argmax F (A) = argmax U (A) C(A)(3.1)Since C(A) supermodular C(A) submodular, since nonnegative linear combinations submodular set functions submodular well, scalarized objectiveF (A) = U (A) C(A) submodular well. Hence, problem (3.1) requires maximization submodular set function.4. Optimization Algorithmsnumber subsets V grows exponentially size n V, NP-hardnessProblem (2.1), cannot expect find optimal solution efficiently. Theorem 2.1 showsNP-hard even approximate optimal solution better constant factor (11/e).fundamental result Nemhauser et al. (1978) characterized performance simple greedyalgorithm, starts empty set = myopically adds attribute increasesscore most, i.e., {argmaxV 0 F (A {V 0 })}, k elements selected(where k specified constant). shown that, F nondecreasing, submodular F () =0, greedy solution AG satisfies F (AG ) (1 1/e) max|A|=k F (A), i.e., greedy solution achieves value least factor 11/e optimal solution. Although result wouldallow us perform tasks selecting near-optimal set k private attributes maximizing639fiK RAUSE & H ORVITZutility U (A) (which satisfies conditions result Nemhauser et al., 1978), unfortunately apply general case, objective F (A) nondecreasing.problem maximizing non-monotone submodular functions resolvedFeige, Mirrokni, Vondrak (2007). local search algorithm, named LS, proved guaranteenear-optimal solution ALS , F nonnegative3 (but necessarily nondecreasing) submodularfunction:1. Let V argmaxV 0 V F ({V 0 }) init. {V }2. exists element V 0 V \ F (A {V 0 }) > (1 +{V 0 }, repeat step 2.3. exists element V 0 F (A \ {V 0 }) > (1 +\ {V 0 }, go back step 2.)F (A),n2)F (A),n2letlet4. Return ALS argmax{F (A), F (V \ A)}.algorithm works iterative manner add remove element V 0 order increasescore, improvement achieved. Feige et al. (2007) prove followingTheorem:Theorem 4.1 (Feige et al., 2007). F nonnegative submodular function, then, solutionALS returned algorithm LS, holds1F (ALS )max F (A).3 nLS uses O( 1 n3 log n) function evaluations.Hence, LS returns solution ALS achieving least 1/3 optimal score.4.1 Efficient Implementationdescription Algorithm LS allows freedom implementing search steps 23. implementation, select greedy manner element V 0 increasesobjective function. Furthermore, speed computation, use lazy evaluation find greedyelements (Robertazzi & Schwartz, 1989).algorithm LLS (c.f., Figure 1) performs sequence upwards downwards passes,adding removing elements improve F least factor (1 + n2 ). upwards passdone lazy mannerthe increments V lazily updated necessary. foundlazy computation reduce running time order magnitude. correctnesslazy procedure follows directly submodularity: Submodularity implies Vmonotonically nonincreasing elements added A. lazy updates alsoapplied greedy downward pass. discovered Algorithm 1 usually terminatesone single downwards pass, without removing single element.3. F takes negative values, normalized considering F 0 (A) = F (A) F (V), howeverimpact approximation guarantees.640fiA U TILITY-T HEORETIC PPROACH P RIVACY NLINE ERVICESInput: Submodular function FOutput: Near-optimal selection personal attributesbegin;repeatchange = f alse;/* Lazy greedy upward pass:*/foreach V V V F (A {V }) F (A); currentV true;repeatV 0 argmaxV V\A V ;currentV 0 = trueV 0 > (1 + n2 )F (A){V 0 }; foreach V V currentV f alseelsebreak;endelseV 0 F (A {V 0 }) F (A); currentV 0 true;endV 0 (1 + n2 )F (A) ;/* Lazy greedy downward pass:*/foreach V V F (A \ {V }) F (A); currentV true;repeatV 0 argmaxV V ;currentV 0 = trueV 0 > (1 + n2 )F (A)\ {V 0 }; change = true; foreach V currentV f alseelsebreak;endelseV 0 F (A \ {V 0 }) F (A); currentV 0 true;endV 0 (1 + n2 )F (A) ;change = f alse ;return argmax{F (A), F (V \ A)}endAlgorithm 1: lazy local search (LLS) algorithm.641fiK RAUSE & H ORVITZ4.2 Evaluating Utility Costrun LLS, need able efficiently evaluate utility U (A) cost C(A). principle, compute objective functions empirical distribution training data,explicitly evaluating sums defining U (A) C(A) (c.f., Section 2). However, approachinefficient (N 2 ) N number training examples. Instead, estimateU (A) C(A) sampling. Krause Guestrin (2005) show Hoeffding inequality (Hoeffding, 1963) used order approximately compute conditional entropies. Hoeffdinginequality allows us acquire bounds number samples needed order determineexpectation E[H] random variable H, H bounded. case click entropy reduction,use random variableH | [Q = q, = a] = H(X) H(X | q, a).H deterministic function modeling click entropy reduction request Q = q attributes= observed. Since Q random variables, H random well. Since H bounded0 log2 (#intents), Hoeffding inequality applied, following holds:Lemma 4.2 (Krause & Guestrin, 2005). > 0 > 0, need&'1 log2 (#intents) 21log2samples order estimate U (A) absolute error confidence least 1 .identifiability loss I(A), proceed similar manner. maximum probability k-anonymity loss bounded 0 1. Using similar argumentproof Lemma 4.2, following result:Lemma 4.3. > 0 > 0, need 212 log 1 samples order estimate C(A)absolute error confidence least 1 .generalize Theorem 4.1 also hold case utility cost estimatedsmall constant error. following theorem summarizes analysis:Theorem 4.4. F (V) 0, LLS, using sampling estimate C(A) U (A),computes solution ALLS1F (ALLS )max F (A) nS ,3 nprobability least 1 . algorithm uses1 3n log nlog2 (#intents)21log 3n!samples.Hence, algorithm LLS efficiently find solution ALLS achieves least constant fraction 1/3 times value optimal solution.642fiA U TILITY-T HEORETIC PPROACH P RIVACY NLINE ERVICES4.3 Computing Online Boundsbounds provided Theorem 4.4 offline, sense stated runningAlgorithm 1. use submodularity U (A) supermodularity C(A) additionallycomputing online bounds performance algorithm.Theorem 4.5. Let A0 V arbitrary set attributes. V V \ define V =U (A0 {V }) U (A0 ) C({V }). Let B = {V : V > 0}.Xmax F (A) U (A0 ) +V .V Bpossible extend bounds case objective function F evaluated small absolute error via sampling.4.4 Finding Optimal SolutionAlthough LLS allows us find near-optimal solution polynomial time, submodularityF also exploited find optimal solution informed way, allowing us bypass exhaustive search exponentially many subsets A. Existing algorithms optimizing submodular functions include branch bound search, e.g., data-correcting algorithm Goldengorin, Sierksma, Tijssen, Tso (1999), well mixed-integer programming(Nemhauser & Wolsey, 1981). approaches also require nonnegativity F .mixed-integer programming approach Nemhauser et.al. effectively uses bounds similarpresented Theorem 4.5.5. Search Log Data Attributesestimate utility U (A) cost C(A) sets private attributes data. use searchlog data, based total 247,684 queries performed 9,523 users 14 monthsDecember 2005 January 2007. search data obtained users volunteeredparticipate public Microsoft data sharing program centering use informationsearch activities enhance search. data filtered include queriesperformed least 30 different users, resulting total 914 different queries.utility U (A), compute average reduction click entropy (in bits) respectper-query distribution web pages chosen, defined Section 2. demographicinformation search logs, compute 31 different user / query specific attributes. selectingattributes, chose coarse discretization. attribute represented threebits, attributes binary. consider following attributes, summarizedTable 1.5.1 Demographic Attributesfirst set attributes contains demographic information, voluntarily provided separately part signing set online services. attributes contain gender, age group,occupation region, coarsely discretized three bits. Gender specified86% users, age 94%, occupation 57%. 44% users specified gender male,42% female. 8% users asserted less 18 years, 53% 18 55,643fiK RAUSE & H ORVITZ33% 55 older. users US Canada (53%), followed 7% European Union 3% Asia. locations unspecified. 10% searchers specifiedstudents.5.2 Search Activity Attributesnext set attributes contains features extracted search history data. query,determine whether query performed (AQRY; 70% queriesrepeated), well whether searcher visited webpage (ACLK) (53%clicks). consider sequence websites visited following query, associatehostname first website surfer dwells least 30 seconds intendedtarget. attribute AFRQ describes whether user performed least one query day. 47%searchers performed least one search per day. also log top-level domain (ATLV)determined reverse DNS lookup query IP address, used domains .net, .com,.org .edu. 83% queries associated one domains. determineuser ever performed queries least 2 different zip codes (AZIP; true 31%), cities (ACTY; true31%) countries (ACRY; true 2%), performing reverse DNS lookup query IP addresses.query, store whether query performed working hours (AWHR;7 6 pm) workdays (AWDY; Mon-Fri) weekend (Sat, Sun), without accountingholidays. Workdays account 73% queries, 40% queries doneworking hours.5.3 Topic Interestslooked websites visited user 2006 16 element top-level categoryOpen Directory Project directory (www.dmoz.org). category, use binaryattribute indicating whether user ever visited website category (acronyms topicsindicated prefix T). Topic classification available 96% queries.6. Survey Privacy PreferencesAlthough identifiability important part privacy, people may different preferencessharing individual attributes (Olson, Grudin, & Horvitz, 2005). set assess preferences cost benefits sharing different kinds personal data. Related workexplored elicitation private information (c.f., Huberman, Adar, & Fine, 2005; Wattal, Telang,Mukhopadhyay, & Boatwright, 2005; Hann, Hui, Lee, & Png, 2002). familiarsimilar study context web search. survey designed specifically probe preferences revealing different attributes private data return increases utilityservice (in case, terms enhanced search efficiency). previous studies Olson et al.(2005) show, willingness share information greatly depends type informationshared, information shared, information going used. designing survey, tried specific possible, specifying low-risk situation,personal information would shared used respect single specified query,discarded immediately thereafter. survey contained questions sensitivityindividual attributes concerns identifiability. survey distributed within Microsoft Corporation via online survey tool. motivated people take survey providing644fiA U TILITY-T HEORETIC PPROACH P RIVACY NLINE ERVICESFigure 1: Willingness share attributes5Sensitivity4321AFRQ TNWS TSCI TART TGMS TBUS THEA TSOC DGDR AQRY ACLK ACRY DOCC DMTL DCHD AWHRFigure 2: Sensitivity individual attributes (with 95% confidence intervals)participants lottery could win media player via random drawing. surveyopen worldwide entries, received total 1,451 responses. Again, use acronymsrefer personal attributes, defined Table 1.645fiK RAUSE & H ORVITZ6.1 Questions Individual AttributesFirst, assessed attributes participants would willing share search enginerevealing attributes would double search performance. Interestingly, attributes probed,50% study participants asserted would agree share information givenpromised efficiency gain. Also, sharing rates similar estimated survey(78% gender, 82% age, 64% occupation). least willingness share (54.4%52.6% respectively) exhibited marital status (DMTL) whether participantchildren (DCHD), closely followed occupation (63.9%). participants (92.7%) would rathershare region share interests include news-related webpages (TNWS). Figure 1presents results question. also asked participants classify sensitivityattributes Likert scale 1 (not sensitive) 5 (highly sensitive). orderquestions randomized. Figure 2 presents results. frequency search engine usage(AFRQ) well general topic interests, e.g., news pages (TNWS), consideredlow sensitivity. Interestingly, found significant differences preferencesamong participants even sharing service interests different topics; participants showedsignificantly greater sensitivity sharing interest health society related websites (THEA,TSOC) news science-related pages (TNWS, TSCI). biggest jump sensitivityoccurs attributes ACLK, referring sharing repeated visit website, ACRY,referring recently traveled internationally. found participants sensitivesharing whether work performing query (AWHR).6.2 Questions Identifiabilityalso elicited preferences sharing personal data different degrees precisiondifferent levels identifiability. First, sought identify changes sensitivity associatedsharing personal data increasingly higher resolution. specifically, inquiredsensitivities participants sharing ages level groups 20, 10, 5, 1 years,exact birth dates. Similarly, asked sensitive participants would sharinglocation region, country, state, city, zip code, address levels detail. Figures 3(a)3(b) present mean sensitivity 95% confidence intervals experiment. alsoassessed participants sensitivities search activity stored different ways.specifically, asked users assess sensitivity storing topic classificationvisited websites (i.e., whether news- , business-, health-related etc. site visited), storingsearches 1 3 years, storing searches indefinitely. Lastly, asked participantssensitive would be, if, spite sharing information, would guaranteedremain indistinguishable least k people (thereby eliciting preferences k kanonymity). Here, varied k among 1, 10, 100, 1,000, 10,000, 100,000 1 million. Figure 3(c)presents results experiments.draw number conclusions preferences population studied. First, storingsearch activity generally considered sensitive sharing certain demographic information.example, even storing topic classification visited web pages considered significantly sensitive sharing city birth year user. result indicates loggingsearch activity considered least threatening privacy sharing certain demographic information. survey also shows study participants strong preferences granularityshared information. explained Section 7.2, use information obtained646fiA U TILITY-T HEORETIC PPROACH P RIVACY NLINE ERVICES5Sensitivity4321region country state(a) Agecityzipaddress(b) Location5Sensitivity4321(c) Storage1M 100K 10K1K100101(d) DiscriminabilityFigure 3: Sensitivity sharing age (a) location (b) different levels discretization.(c) Sensitivity storing searches varying amounts time. (d) Sensitivity kdiscriminability levels (right). Plots show 95% confidence intervals.experiment explicitly take account peoples preferences trading privacyutility.6.3 Questions Utilityaddition assessing sensitivity sharing different kinds personal information, askedparticipants assess degree improvement would require order share attributesgiven sensitivity level. specifically, asked: much would search engineimprove performance, would willing share information consider 1/2/....response options, offered average improvements 25%, 50%, 100%, well outcomeimmediately presenting desired page 95% time (which associated speedupfactor 4). also allowed participants opt never share information specifiedsensitivity level. responses, conjunction earlier sensitivity assessments, allowed647fiK RAUSE & H ORVITZFigure 4: attributes currently stored?Figure 5: Using sensitivity common currencyus establish sensitivity common currency utility cost. Figure 5 presents median, 2575-percentiles responses k-discriminability question utility question.6.4 Questions Current StateAdditionally, assessed current understanding state privacy search. specifically, asked, whether participants believe current search engines store followingattributes: DGDR, DAGE, DOCC, DZIP, ASEA, DCRY, TNWS, DEML. found participants (96%) assume search engines know country (DCRY) searcher from. Also,participants (86%) assume searches stored search engines. Fewer participants believe demographic information occupation (16%), age (28%) gender (34%)648fiA U TILITY-T HEORETIC PPROACH P RIVACY NLINE ERVICESFigure 6: Utility (average click entropy reduction bits) according greedy orderingFigure 7: Cost according greedy orderingknown search engine. result important baseline order understandsensitivity classification individual attributes.7. Resultsdescribe empirical results calibrating optimizing utility-privacy tradeoff.7.1 Computing Utility Costuse empirical distribution data described Section 5, evaluate utility costsampling. sample row picked uniformly random search logs. findqueries matching selected attributes (A = a), compute conditional entropy clickdistribution, well identifiability loss function. order avoid overfitting sparse data,649fiK RAUSE & H ORVITZmedian #bits required43Identifiability cost(maxprob)21Median #bits(from survey)0region(a) Tradeoff-curvecountrystatecityzip(b) CalibrationFigure 8: (a) Tradeoff-curve varying . (b) Calibrating tradeoff.applied Dirichlet smoothing. experiments, use 1000 independent samples orderestimate U (A) I(A).first apply greedy algorithm select increasing number attributes, maximizingutility ignoring cost. Figure 6 presents greedy ordering achieved entropy reductions. greedy algorithm selects attributes DOCC, ATLV, DAGE, ACTY, AQRY, ACLK,AWHR, TADT, AWDY, THOM, TCIN, DGDR, TGMS, TREG, order. selectingattributes, utility increase significantly anymore. entropy reduction levelsroughly 1.92 bits. Figure 6 underscores diminishing-returns property click entropy reduction.Similarly, generate greedy ordering attributes, order minimum incrementalcost. Figure 7 presents results experiment, using maxprob cost metric. expected,curve looks convex (apart small variations due sampling process). cost initially increases slowly, growth increases attributes selected. behaviorempirically corroborates supermodularity assumption cost metric.Figure 9 compares three cost metrics, attributes selected. threemetrics initially behave qualitatively similarly. However, k-anonymity metric flattens25 31 attributes selected. expected, eventually enough personal information available order (almost) always reduce candidate set people less k = 100.point, adding attributes dramatically increase cost anymore. However,trading utility privacy, one interested solutions small cost, criticalregion, cost function behaves supermodularly well.7.2 Calibrating Tradeoff Assessed Preferencesuse scalarization (3.1) trade utility cost. optimization, needchoose tradeoff parameter . Instead committing single value , generate solutionsincreasing values . value, use LLS find approximate solution,plot utility cost. Figure 8(a) shows tradeoff curve obtained experiment.see curve exhibits prominent knee: values 1 10, small increases utility650fiA U TILITY-T HEORETIC PPROACH P RIVACY NLINE ERVICESFigure 9: Cost comparison according greedy orderinglead big increases cost, vice versa. Hence, knee, achieve near-maximal utilitynear-minimum cost.integrate peoples preference analysis tradeoff, perform following calibration procedure. search log data, determined increasing resolutionpersons location increases privacy cost. vary location granularity region (coarsest)zip code (finest). example, compute values Im ({zip code}), Im ({city}), etc.data. explained Section 6.2, asked subjects assess sensitivity sharinglocations different levels precision. approach also allows us put identifiability costI(A) sensitivity S(A) units.Similarly, assessed amount improvement search performance would requiredorder share attributes given sensitivity. associate number bits levelimprovement: speedup factor x would require log2 x bits (i.e., doubling searchperformance would require 1 bit, etc.). concatenat mappings location granularitysensitivity, sensitivity utility (bits), compute median number bits requiredsharing location granularity. Using approach, put sensitivity S(A) utilityU (A) units. Thereby, effectively use sensitivity common currencyutility cost. procedure (up discretization) invariant particular scale (such 15) used assess sensitivity.perform linear regression analysis align cost curve estimated datacurve obtained survey. least-squares alignment presented Figure 8(b), obtained value 5.12. Note value maps exactly sweet spot 1 10tradeoff curve Figure 8(b).7.3 Optimizing Utility-Privacy TradeoffBased calibration described above, goal find set attributes maximizingcalibrated objective F (A) according (3.1).First, use greedy algorithm obtain ordering attributes, similarly casesoptimize utility cost separately. Figure 10 presents results experiment.651fiK RAUSE & H ORVITZFigure 10: Greedy solutions calibrated objectiveFigure 11: Comparison heuristicsInstead using greedy algorithm, use LLS approximately solve optimizationproblem. algorithm terminates two upward downward passes, solution AFRQ,ATLV, AWDY, AQRY, ACLK, DAGE TSPT. Note first element selectedinitial greedy upward pass DOCC (the occupation), discarded first downward passagain, since individual sensitivity quite high (c.f., Figure 2), additional informationprovided remaining 6 attributes high enough warrant presence optimalsolution.also compared optimized solution Aopt results various heuristic procedures.example, compared candidate solution Adem select demographic attributes(all attributes starting D); Atopic select topic interest attributes (starting T);Asearch including search statistics (ATLV, AWDY, AWHR, AFRQ); AIP , entire IP addressAIP 2 , first two bytes IP address. Figure 11 presents results comparison.optimized solution Aopt obtains best score 0.83, achieving click entropy reduction 1.4.652fiA U TILITY-T HEORETIC PPROACH P RIVACY NLINE ERVICESFigure 12: Running timessearch statistics Asearch performs second best, score 0.57, achieving drasticallylower utility 0.8. Demographic information Adem achieves higher utility 0.95, muchhigher cost, hence even lower total score 0.3. Perhaps surprisingly, collection topicinterests, Atopic results negative total score -1.73, achieving less utility optimizedsolution. believe reason knowledge exact topic interest profilefrequently suffices uniquely identify searcher. expected, IP address (even first 2bytes) quite identifying data set, hence high cost. experiment showsoptimization problem non-trivial, optimized solution outperforms heuristic choices.also measured running time algorithms, standard desktop PC (3 GHz) usingC#-implementation. Figure 12 presents running times greedy local search algorithms, without lazy evaluation trick. note local search algorithmmuch slower greedy algorithm; frequently, single upward downward passnecessary, small number attributes considered eliminationdownward pass. also note using lazy evaluations drastically speeds running time522.1 minutes without 225.7 lazy evaluations. obtain tradeoff curve like oneFigure 8(b), algorithm run value ; hence improvement important.also estimated running time required exhaustive search. Here, considered setssize 8 (assuming optimal solution similar size approximate solution).Even optimistic estimate would require 50.1 years computation time.8. Related Workpaper extended version paper appeared 23rd Conference Artificial Intelligence (AAAI) (Krause & Horvitz, 2008). present version significantly extended, includingseveral additional experimental results, detailed discussion LLS algorithm well new653fiK RAUSE & H ORVITZLabelDGDRDAGEDOCCDREGDMTLDCHDAQRYACLKAFRQAZIPACTYACRYAWHRAWDYATLVTARTTADTTBUSTCMPTGMSTHEATHOMTKIDTNWSTRECTREFTREGTSCITSHPTCINTSOCTSPTTWLDTypeDemographicDemographicDemographicDemographicDemographicDemographicActivityActivityActivityActivityActivityActivityActivityActivityActivityTopicTopicTopicTopicTopicTopicTopicTopicTopicTopicTopicTopicTopicTopicTopicTopicTopicTopicbits123211111111112111111111111111111DescriptionGenderAge group (<18, 18-50, >50)Occupation (6 groups related jobs)Region (4 geographic regions)Marital status (*)Whether searcher children (*)Performed queryVisited websiteUser performs least 1 query per day averageUser performed queries least 2 different zip codesUser performed queries least 2 different citiesUser performed queries least 2 different countriesCurrent query performed working hoursCurrent query performed workday / weekendTop-level domain query IP address (.com, .net, .org, .edu)User previously visited arts related webpageUser previously visited webpage adult contentUser previously visited business related webpageUser previously visited compute related webpageUser previously visited games related webpageUser previously visited health related webpageUser previously visited home related webpageUser previously visited kids / teens related webpageUser previously visited news related webpageUser previously visited recreation related webpageUser previously visited reference related webpageUser previously visited webpage regional contentUser previously visited science related webpageUser previously visited shopping related webpageUser previously visited consumer information webpageUser previously visited society related webpageUser previously visited sports related webpageUser previously visited world related webpageTable 1: 33 Attributes used experiments. Attributes marked (*) available searchlog data. Total number bits = 38.654fiA U TILITY-T HEORETIC PPROACH P RIVACY NLINE ERVICEStheoretical bounds (Section 4.3). review work related key concepts methodspresented paper.8.1 Personalized Search, Probabilistic Models Searchproblem personalized search received great deal attention (c.f., Xu et al., 2007overview recent work). Teevan et al. considered use local term frequencies reranking web search results (Teevan et al., 2005). personal data kept private analysispersonal information re-ranking occurs entirely client. Recently, Xu et al. consideredproblem privacy preserving web search. Based local information, user profile built,used personalization. Two parameters called minDetail expRatio used specifypreferences privacy. similar spirit, approach tradeoff cost benefitsets attributes approach does. Moreover, approach consider aspectdiscriminability across users.efforts employ probabilistic models web search, e.g., predicting relevance. Examples include techniques proposed Downey et al. (2007). methods proposedpaper use probabilistic model, allows answer questions likemuch would uncertainty decrease knew searchers gender.8.2 Value Information Probabilistic ModelsOptimizing value information cornerstone principled approaches informationgathering (Howard, 1966; Lindley, 1956; Heckerman, Horvitz, & Middleton, 1993), popularized decision analysis context influence diagrams (Howard & Matheson, 1984).Several researchers (van der Gaag & Wessels, 1993; Cohn, Gharamani, & Jordan, 1996; Dittmer& Jensen, 1997; Kapoor, Horvitz, & Basu, 2007) suggested myopic, i.e., greedy approachesselectively gathering observations. algorithms typically theoretical guarantees.Heckerman et al. (1993) propose method compute maximum expected utility specificsets observations. provide large sample guarantees evaluation given sequence observations, use heuristic without guarantees select sequences. KrauseGuestrin (2009) develop dynamic programming based algorithms finding optimal setsobservations. However, algorithms apply chain structured graphical models. KrauseGuestrin (2005) show certain conditional independence assumptions, information gain submodular function, observation build paper. knowledge,paper provides first principled approach efficiently, nonmyopically trading valueinformation privacy cost.8.3 Valuation Private Informationproblem estimating sensitivity monetary value private information studied extensively, e.g., economics literature. Huberman et al. (2005) propose second-price auctionestimating sensitivity demographic attributes. application specific approach,Wattal et al. study, whether inclusion names personal product preferences enhanceeffectiveness email marketing (Wattal et al., 2005). Hann et al. (2002) study economicincentives affect individuals preferences different privacy policies, quantifying valuedisallowing use personal information. Kleinberg, Papadimitriou, Raghavan (2001) quan-655fiK RAUSE & H ORVITZtify value private information using Shapley value coalitional game. approachprovides alternative, theoretically well-motivated way eliciting subjective cost sharingset personal information, could potentially combined approach optimizeutility-privacy tradeoff.8.4 Mathematical Notions Privacyfield mathematical (or cryptographic) privacy studied extensively (c.f., Adam& Wortmann, 1989 survey early work). pioneering result definition kanonymity, development algorithms maintaining indiscriminability guarantee(Sweeney, 2002). Follow work led notions indiscriminability, l-diversity(Machanavajjhala et al., 2006) etc. notions describe properties databases isolation,sometimes called non-interactive (Dwork, 2006). Often, inference attacks using auxiliaryknowledge problematic context. Lebanon et al. (2009) consider decision theoretic variants k-anonymity related notions. approach allows quantify risk (partially)releasing sanitized records. consider approaches quantifying privacy cost,present efficient algorithms guarantees trading utility privacy paper.Another important class cryptographic approaches privacy consider protection privacycontext interactive analyses. approaches, database contains arbitrary amountprivate information, securely guarded. Access database enabled via limitedform queries, guarantee privacy. One prominent example techniques notion differential privacy (Dwork, 2006). notion quantifies risk user incurredparticipating database. Intuitively, queries allowed, corresponding resultssignificantly depend presence absence individuals database. Blum et al.(2008) show differential privacy (and stronger variant called distributional privacy)achieved even non-interactive setting. However approach efficient limitedclass queries that, e.g., allow estimate click probabilities considered paper.Although approaches provide crisp mathematical definitions privacy, designedspecific notion utility mind. Rather, specific privacy requirement formulated,analyses show limits data usage consistent requirement. believeutility-theoretic approach privacy complementary cryptographic definitions privacy. approach used develop privacy-aware design, existing techniquesdifferential privacy can, e.g., used guard access private information. utilitytheoretic analyses also allow new scenarios, identifying value specific private dataspecific context, requesting data real time, short-term usage. applicationsbypass assumption long-term, large-scale storage private data explored withincryptographical analyses privacy.8.5 Utility-Privacy TradeoffAlgorithmic approaches optimizing tradeoff considered area privacypreserving data publishing, focuses anonymization techniques. settings, constraint privacy typically specified (in terms k-anonymity, Sweeney, 2002, l-diversity,Machanavajjhala et al., 2006) recoding scheme applied maximizes specified quality metric. Recent work involves development greedy algorithm (LeFevre et al.,656fiA U TILITY-T HEORETIC PPROACH P RIVACY NLINE ERVICES2006) branch bound search (Hore & R. Jammalamadaka, 2007). knowledge,algorithms performance approximation guarantees.approach different, explicitly quantify utility cost units,optimize single scalar value information problem. Moreover, use application specificutility function, rather distortion metric. Furthermore, algorithm guaranteed providenear-optimal solutions optimization problem.9. Discussionproposed methodology could implemented variety ways. critical designchoices utility-privacy tradeoff optimized. following, shallexplore parameters context personalized search.9.1 Location private informationPrivate information either located client (i.e., recipient service, e.g., websearcher), server (i.e., service provider, e.g., search engine), channel.9.2 Client-side Private Informationclient-side setting, private information stored locally, never shared network;configuration considered Teevan et al. (2005) Xu et al. (2007). approach, private information used re-rank search results locally, never transmitted acrossnetwork, avoiding risk misuse unintended release. However, private information(easily) migrate user across multiple machines, privacy concerns effectivelyreplaced security concerns, requiring local machine compromised. proposedmethodology could useful mitigating security concerns; client services might optimizedacquire store relevant information.9.3 Server-side Private Informationserver side, designs privacy, especially regard storage usage behavioraldata, critical importance services users.methods described used balance user sensitivity service utility, addressquestions data logged, anonymization techniques used(c.f., Adar, 2007 discussion difficulties possible options anonymizing web searchlogs). Furthermore, specific personal (e.g., demographic) information could voluntarily madeavailable web searcher web service form of, e.g., user profile. settings,proposed methodology could potentially used trade privacy utility.9.4 Channel-side Private Informationalso foresee applications private data transmitted per-request basis. setting,proposed methodology used design private bits transmit maximize utilityminimizing privacy risk.657fiK RAUSE & H ORVITZ9.5 Priori vs. Dynamic Tradeoff OptimizationAnother important design parameter tradeoff privacy utility made.9.5.1 PRIORI RADEOFF PTIMIZATION / P RIVACY-AWARE ERVICE ESIGNOne option apply proposed methodology priori, i.e., system used.Here, utility-privacy tradeoff would determine information logged, collectedlocal profiles, private bits made part protocol used transmit service requests.approach advantage always private bits used, inference attackscombining private information different requests possible.9.5.2 DYNAMIC PTIMIZATIONmentioned earlier, systems endowed ability make dynamic recommendations users take actions accordance user preferences course online activities.Dynamic variants methods presented used identify best subset private information sharing optimize utility user. web search, dependingquery, different kinds personal information may helpful disambiguation.utility-theoretic approach privacy could used determine needs real time. Challengesimplementing real-time, interactive approach, include grappling possibility inference attacks combine bits different requests. Anonymization proceduresdesigned resist challenges. Another challenge computational efficiency, solvingoptimization problem may required service request. main advantage employingdynamic approach average number private bits (and hence identifiability cost) perrequest could lower priori privacy-aware design. priori design requires collection private bits help disambiguating queries versus context-specific situations.interactive approach would additionally allow users share private information per-requestbasis. interactive decisions also require considerations preferences tradeoffsprivate information acquired usersand rely design user interactionmodels interfaces provide users awareness opportunities enhancing valueservices controls guiding revelation private information. Recent developmentsadaptive submodularity may provide methods necessary achieve dynamic, adaptiveoptimization tradeoffs (Golovin & Krause, 2010).9.6 Applicationsincreasing cost property characterizes identifiability cost potentially arisescontexts well. example, many algorithms, computational cost scales superlinearlynumber dimensions / attributes considered. cases, problem trading information (such click entropy reduction) computation cost combinatorial structure utility-privacy tradeoff addressed paper. algorithmic/computationalconsiderations presented paper, lazy local search algorithm, sample complexityanalyses, apply contexts well.658fiA U TILITY-T HEORETIC PPROACH P RIVACY NLINE ERVICES10. Conclusionspresented approach explicitly optimizing utility-privacy tradeoff personalized services web search. showed utility functions like click entropy reduction satisfysubmodularity, intuitive diminishing-returns property. contrast, privacy concerns show supermodularity; private information accrue, faster sensitivity risk identifiability grow. Based submodular utility supermodular cost functions, demonstratedefficiently find provably near-optimal utility-privacy tradeoff. evaluated methodology real-world web search data. demonstrated quantitative tradeoff calibratedaccording personal preferences, obtained user study 1,400 participants. Overall,found significant personalization achieved using small amount informationusers. believe principles methods employed utility-theoretic analysistradeoffs web search applicability personalization broad variety onlineservices. results underscore value taking decision-theoretic approach privacy,seek jointly understand utility personalization achieved via access information users, preferences users costs benefits selectively sharingpersonal data online services.AcknowledgmentsAndreas Krause intern Microsoft Research work performed. would likethank searchers provided usage data use research, participants surveyprivacy preferences, anonymous referees helpful comments suggestions.Appendix A. ProofsProof Theorem 2.1. Let n = |cV |. prove result choice I(A), I(A) = 0|A| < n/2 I(A) = 2M (|A|n/2) otherwise, = U (V) maximum achievableutility. case, F1 (A) = U (A) 0 |A| n/2, F1 (A) < 0 |A| > n/2. Hence,argmax F1 (A) = argmax U (A).A:|A|n/2However, Krause Guestrin (2005) show polynomial time algorithmguaranteed find set A0 U (A0 ) (1 1/e) maxA:|A|n/2 U (A), P = N P .Proof Theorem 3.2. Let = (A, B) (i.e., V partitioned B). Then,XXIm (A) =P (a) max P (b | a) =P (a) max P (b)b= max P (b) = maxbbbP (bi ) =max P (bi ) =biwiwi = maxbi P (bi ). Now, Im (A) nondecreasing A. Furthermore, subsets A, A0 VB = A0 , holds Im (B) = Im (A) 1. Furthermore, V V \ Bw = maxv P (V = v), Im (B {V }) = w1 Im (B) Im (A {V }) = w1 Im (A). Hence,Im (B {V }) Im (B)(w1 1)== 1,Im (A {V }) Im (A)w1 1659fiK RAUSE & H ORVITZproves supermodularity Im (A).Proof Theorem 4.4. Additive error carries Lemma 3.3. subsequentlyproof Theorem 3.4. Feige et al. (2007). order guarantee confidence 1 , applyunion bound. sample complexity follows Lemma 4.2 Lemma 4.3.Proof Theorem 4.5. Let C optimal solution. Since U nondecreasing,F (C) = U (C) C(C) U (A0 C) C(C)XU (A) +[U (A {V }) U (A)] C(C)V CXU (A) +[U (A {V }) U (A) C({V })]V C= U (A0 ) +XV U (A0 ) +V CXV .V BReferencesAdam, N. R., & Wortmann, J. C. (1989). Security-control methods statistical databases:comparative study. ACM Computing Surveys, 21(4), 515556.Adar, E. (2007). User 4xxxxx9: Anonymizing query logs. Query Logs Workshop, World WideWeb Conference.Blum, A., Ligett, K., & Roth, A. (2008). learning theory approach non-interactive databaseprivacy. Symposium Theory Computing.Boyd, S., & Vandenberghe, L. (2004). Convex Optimization. Cambridge University Press.Chen, B., LeFevre, K., & Ramakrishnan, R. (2007). Privacy skyline: Privacy multidimensionaladversarial knowledge. International Conference Large Data Bases (VLDB).Cohn, D. A., Gharamani, Z., & Jordan, M. I. (1996). Active learning statistical models. JournalArtificial Intelligence Research, 4, 129145.Cover, T. M., & Thomas, J. A. (1991). Elements Information Theory. Wiley Interscience.Dittmer, S., & Jensen, F. (1997). Myopic value information influence diagrams. ConferenceUncertainty Artificial Intelligence (UAI), pp. 142149, San Francisco.Dou, Z., Song, R., & Wen, J.-R. (2007). large-scale evaluation analysis personalized searchstrategies. World Wide Web Conference (WWW).Downey, D., Dumais, S., & Horvitz, E. (2007). Models searching browsing: Languages,studies, applications. International Joint Conference Artificial Intelligence (IJCAI).Dwork, C. (2006). Differential privacy. International Colloquium Automata, LanguagesProgramming (ICALP).Feige, U., Mirrokni, V., & Vondrak, J. (2007). Maximizing non-monotone submodular functions.IEEE Symposium Foundations Computer Science (FOCS).660fiA U TILITY-T HEORETIC PPROACH P RIVACY NLINE ERVICESGoldengorin, B., Sierksma, G., Tijssen, G. A., & Tso, M. (1999). data-correcting algorithmminimization supermodular functions. Management Science, 45(11), 15391551.Golovin, D., & Krause, A. (2010). Adaptive submodularity: new approach active learningstochastic optimization. International Conference Learning Theory (COLT).Hann, I., Hui, K., Lee, T., & Png, I. (2002). Online-information privacy: Measuring cost-benefittradeoff. International Conference Information Systems.Heckerman, D., Horvitz, E., & Middleton, B. (1993). approximate nonmyopic computationvalue information. IEEE Trans. Pattern Analysis Machine Intelligence, 15, 292298.Hoeffding, W. (1963). Probability inequalities sums bounded random variables. JournalAmerican Statistical Association, 58(301), 1330.Hore, B., & R. Jammalamadaka, S. M. (2007). Flexible anonymization privacy preserving datapublishing: systematic search based approach. SIAM Conference Data Mining (SDM).Horvitz, E. (2006). Machine learning, reasoning, intelligence daily life: Directionschallenges. Tech. rep. TR-2006-185, Microsoft Research.Howard, R. A. (1966). Information value theory. IEEE Transactions Systems ScienceCybernetics (SSC-2).Howard, R. A., & Matheson, J. (1984). Readings Principles Applications DecisionAnalysis II, chap. Influence Diagrams, pp. 719762. Strategic Decision Group, Menlo Park.Reprinted 2005 Decision Analysis 2(3) 127-143.Huberman, B. A., Adar, E., & Fine, L. R. (2005). Valuating privacy. IEEE Security & Privacy, 3(5),2225.Kapoor, A., Horvitz, E., & Basu, S. (2007). Selective supervision: Guiding supervised learningdecision-theoretic active learning. International Joint Conference Artificial Intelligence(IJCAI).Kleinberg, J., Papadimitriou, C. H., & Raghavan, P. (2001). value private information.TARK: Theoretical Aspects Reasoning Knowledge, 8.Krause, A., & Guestrin, C. (2009). Optimal value information graphical models. JournalArtificial Intelligence Research, 35, 557591.Krause, A., & Horvitz, E. (2008). utility-theoretic approach privacy personalization.Proc. 23rd Conference Artificial Intelligence (AAAI), Special Track AI & Web.Krause, A., & Guestrin, C. (2005). Near-optimal nonmyopic value information graphicalmodels. Conference Uncertainty Artificial Intelligence (UAI).Lebanon, G., Scannapieco, M., Fouad, M. R., & Bertino, E. (2009). Beyond k-anonymity: decision theoretic framework assessing privacy risk. Transactions Data Privacy, 2(3),153183.LeFevre, K., DeWitt, D., & Ramakrishnan, R. (2006). Mondrian multidimensional k-anonymity.IEEE International Conference Data Engineering (ICDE).Lindley, D. V. (1956). measure information provided experiment. AnnalsMathematical Statistics, 27, 9861005.661fiK RAUSE & H ORVITZMachanavajjhala, A., Kifer, D., Gehrke, J., & Venkitasubramaniam, M. (2006). L-diversity: Privacybeyond k-anonymity. IEEE International Conference Data Engineering (ICDE).Nemhauser, G., Wolsey, L., & Fisher, M. (1978). analysis approximations maximizingsubmodular set functions. Mathematical Programming, 14, 265294.Nemhauser, G. L., & Wolsey, L. A. (1981). Studies Graphs Discrete Programming, chap.Maximizing Submodular Set Functions: Formulations Analysis Algorithms, pp. 279301. North-Holland.Olson, J. S., Grudin, J., & Horvitz, E. (2005). study preferences sharing privacy.ACM Conference Human Factors Computing Systems (CHI).Robertazzi, T. G., & Schwartz, S. C. (1989). accelerated sequential algorithm producingD-optimal designs. SIAM Journal Scientific Statistical Computing, 10(2), 341358.Sugiyama, K., Hatano, K., & Ikoma, T. (2004). Adaptive web search based user profile constructed without effort users. World Wide Web Conference (WWW).Sweeney, L. (2002). k-anonymity: model protecting privacy. International Journal Uncertainty, Fuzziness Knowledge-based Systems, 10(5), 557570.Teevan, J., Dumais, S. T., & Horvitz, E. (2005). Personalizing search via automated analysisinterests activities. International ACM SIGIR Conference.van der Gaag, L., & Wessels, M. (1993). Selective evidence gathering diagnostic belief networks.AISB Quart., 86, 2334.Wattal, S., Telang, R., Mukhopadhyay, T., & Boatwright, P. (2005). Examining personalizationprivacy tradeoff empirical investigation email advertisements. Management Science.Xu, Y., Zhang, B., & Wang, K. (2007). Privacy-enhancing personalized web search. World WideWeb Conference (WWW).662fiJournal Artificial Intelligence Research 39 (2010) 745774Submitted 03/10; published 12/10Intrusion Detection using Continuous Time Bayesian NetworksJing XuChristian R. SheltonJINGXU @ CS . UCR . EDUCSHELTON @ CS . UCR . EDUDepartment Computer Science EngineeringUniversity California, RiversideRiverside, CA 92521, USAAbstractIntrusion detection systems (IDSs) fall two high-level categories: network-based systems(NIDS) monitor network behaviors, host-based systems (HIDS) monitor system calls.work, present general technique systems. use anomaly detection,identifies patterns conforming historic norm. types systems, rates changevary dramatically time (due burstiness) components (due service difference).efficiently model systems, use continuous time Bayesian networks (CTBNs) avoidspecifying fixed update interval common discrete-time models. build generative modelsnormal training data, abnormal behaviors flagged based likelihoodnorm. NIDS, construct hierarchical CTBN model network packet tracesuse Rao-Blackwellized particle filtering learn parameters. illustrate powermethod experiments detecting real worms identifying hosts two publiclyavailable network traces, MAWI dataset LBNL dataset. HIDS, develop novellearning method deal finite resolution system log file time stamps, without losingbenefits continuous time model. demonstrate method detecting intrusionsDARPA 1998 BSM dataset.1. IntroductionMisuse abuse computer systems critical issue system administrators. goaldetect attacks attempt compromise performance quality particular host machine.time-consuming error-prone acquire labeled data contains good badbehaviors build classifier. Additionally, frequency attacks developed make maintaining database previously seen attacks inefficient even infeasible.Anomaly detection identify new attacks even attack type unknown beforehand. Unsupervised learning allows anomaly detector adapt changing environments, thereby extendingdomain usefulness. modeling normal behavior historic clean data, identifyabnormal activity without direct prior model attack simply comparing deviationlearned norm.network-based intrusion detection system (NIDS), network packet traces monitored.Network traffic traces collect information networks data stream provide externalview network behavior. host-based intrusion detection system (HIDS), internal statecomputing system analyzed. System call logs convenient way monitoring executingprograms behavior operating system calls.systems composed activities happen dramatically different time granularity.Users alternate busily using computer resting. busy period, burstaction may cause peak network traffic flow operating system usage. However,c2010AI Access Foundation. rights reserved.fiX U & HELTONresting period, computer maintains regular running pattern, network system activities much less intense, e.g. automatically checking email every minutes. Even withinglobal modes variations. Therefore, dynamic model requires discretizingtime efficient. develop intrusion detection techniques using continuous time Bayesiannetworks (CTBNs) (Nodelman, Shelton, & Koller, 2002) data types. Although twodata completely different formats semantic meaning, demonstrate flexibilitycontinuous time generative model (such CTBN) describe either.first effort detect anomalies network traffic traces (NIDS). Abnormal traffic mustdiffer way normal traffic patterns. difference may subtledifficult detect, subtle attack, longer attack takestress patience attacker. Looking summarized information like flow statisticshelpful, especially stealthy worms mingle well normal traffic sacrificingspreading speed scale. We, therefore, feel looking abnormalities detailed networktraffic flow level utile method finding attacks. network flow given host machinesequence continuous-time asynchronous events. Furthermore, events form complexstructured system, statistical dependencies relate network activities like packet emissionsconnections. employ CTBNs reason structured stochastic network processes.CTBN model contains number observed network events (packet emissions concurrent port connections changes). allow model descriptive, also add latentvariables tie activity variables together. Exact inference method longer feasible.Therefore, use Rao-Blackwellized particle filtering (RBPF) estimate parameters.second effort detect intrusions using system call logs (HIDS). system log file contains ordered list calls made computers operating system executing program.focus analyzing ordering context sequence, rather simply countingoverall statistics. CTBN natural way modeling sequential data. finiteresolution computer clock, system calls issued within clock tick assignedtime stamp. Therefore data stream consists long periods time activity, followedsequences calls order correctly recorded, exact timing information lost.poses new challenge CTBN reasoning. present learning method typedata without resorting time discretization.validate NIDS technique MAWI dataset LBNL dataset, HIDStechnique DARPA 1998 BSM dataset. applications give good results comparedmethod.Section 2 discuss related work intrusion detection. Section 3 review continuoustime Markov processes continuous time Bayesian networks. Section 4 describe CTBNmodel RBPF inference algorithms NIDS problem. Section 5 describeCTBN model parameter estimation algorithm HIDS, including deal imprecise timing measurements. Section 6 show experimental results applications.2. Related WorkMuch previous work intrusion detection focuses one area either detectingnetwork traffic mining system call logs. work Eskin, Arnold, Prerau, Portnoy,Stolfo (2002) similar approach apply method kinds746fiI NTRUSION ETECTION USING CTBNdata. map data elements feature space detect anomalies determining pointslie sparse regions using cluster-based estimation, K-nearest neighbors one-class SVM.use data-dependent normalization feature map network traffic data spectrum kernelsystem call traces.2.1 NIDSnetwork traffic data, build upon previous work (Xu & Shelton, 2008). madeassumption network activities independent across different ports. allowed usfactorize model port-level submodels standard exact inference techniques could usedparameter learning. paper, remove restriction. application-specificreason traffic independent ports. tying traffic together, model describescomplicated structural dependencies among variables. derive Rao-Blackwellized particlefiltering algorithm estimate parameters model. work also differsinterested intrusion detection problem, host identity recognition well.signature-based detection algorithm, share many assumptions Karagiannis,Papagiannaki, Faloutsos (2005). particular, also assume accessinternals machines networks, rules methods like MalanSmith (2005), Cha (2005), Qin Lee (2004), Eskin et al. (2002). However, differapproach rely preset values, require human intervention interpretation,assume access network-wide traffic information. Network-wide data humanintervention advantages, also lead difficulties (data collation faceattack increased human effort), chose leave solution.Many learning, adaptive, methods proposed network data.example, Zuev Moore (2005) Soule, Salamatian, Taft, Emilion, Papagiannali (2004) approach problem classification task requires labeled data. Dewaele,Fukuda, Borgnat (2007) profile statistical characteristics anomalies using random projection techniques (sketches) reduce data dimensionality multi-resolution non-Gaussianmarginal distribution extract anomalies different aggregation levels. goal papersusually detect attacks rather classify non-attacks traffic type; applied attackdetection, would risk missing new types attacks. Furthermore, frequently treatnetwork activity separately, instead considering temporal context.Lakhina, Crovella, Diot (2005) nice summary adaptive (or statistical) methodslook anomaly detection (instead classification). use entropy-based methodentire network traffic. Many methods, Ye, Emran, Chen, Vilbert(2002), use either statistical tests subspace methods assume features connectionspackets distributed normally. Rieck Laskov (2007) model language features liken-grams words connection payloads. Xu, Zhang, Bhattacharyya (2005) also useunsupervised methods, concentrate clustering traffic across whole network. Similarly,Soule, Salamatian, Taft (2005) build anomaly detector based Markov models,network traffic patterns whole function host level.work Soule et al. (2004) similar statistical flavor work. alsofit distribution (in case, histogram modeled Dirichlet distribution) network data.However, model flow-level statistics, whereas work level individual connections.Additionally, attempting network-wide clustering flows instead anomaly detection.747fiX U & HELTONwork Moore Zuev (2005), like approach, models traffic graphical models,particular, Naive Bayes networks. goal categorize network traffic instead detectingattacks. Kruegel, Mutz, Robertson, Valeur (2003) present Bayesian approach detectingproblem event classification task care whether host attackinterval.work Lazarevic, Ertoz, Kumar, Ozgur, Srivastava (2003) also similar work.one papers attempt find attacks host level. employ nearest neighbor,Mahalanobis distance approach, density-based local outliers method, using 23 featuresconnections. Although methods make standard i.i.d. assumption data(and therefore miss temporal context connection) use 23 features (comparedfeatures), compare results Section 6, closest prior work. Agosta,Duik-Wasser, Chandrashekar, Livadas (2007) present adaptive detector whose thresholdtime-varying. similar work also rely model-based algorithms.employ host internal states like CPU loads available us.great variety previous work, work novel detectsanomalies host level using timing features network activities. considerconnection (or packet) isolation, rather complex context. capture statisticaldynamic dependencies packets connections find sequences network trafficanomalous group.2.2 HIDSPrevious work detecting intrusions system call logs roughly grouped two categories: sequence-based feature-based. Sequence-based methods focus sequential orderevents feature-based methods treat system calls independent data elements.method belongs former category since use CTBN model dynamics sequences.Time-delay embedding (tide) sequence time-delay embedding (stide) two examplessequence based methods (Forrest, A.Hofmeyr, Somayaji, & A.Longstaff, 1996; A.Hofmeyr, Forrest, & Somayaji, 1998). generalize data building database storing previously seensystem call sub-sequences, test looking subsequences database. methodsstraightforward often achieve good results. compare experiments. TandonChan (2005) look richer set attributes like return value arguments associatedsystem call make use system call names.Feature based methods like Hu, Liao, Vemuri (2003) use dataset use,DARPA 1998 BSM dataset, training data noisy try find classificationhyperplane using robust support vector machines (RSVMs) separate normal system call profilesintrusive ones. Eskin (2000) also works noisy data. make assumptiontraining data contains large portion normal elements anomalies. present mixturedistribution normal abnormal data calculate likelihood change data pointmoved normal part abnormal part get optimum data partition.Yeung Ding (2002) try use techniques. provide dynamic static behavioral models system call data. dynamic method, hidden Markov model (HMM)used model normal system events likelihood calculated testing sequencecompared certain threshold. work system call traces problem close748fiI NTRUSION ETECTION USING CTBNframework since also build dynamic model sequential data computelikelihood testing example score. different CTBN models continuous time dynamics rather time-sliced behaviors. static method, representnormal behavior command occurrence frequency distribution measure distancetesting example norm cross entropy. dataset use KDD archive dataset.2.3 WorkSimma et al. (2008) also use continuous-time model reason network traffic. applymethod find dependences exterprise-level services. model non-Markovian,also deals network events basic observational unit.estimate parameters large network build network traffic data, useRao-Blackwellized particle filters (RBPFs). Doucet, de Freitas, Murphy, Russel (2000) proposeRBPF algorithm dynamic Bayesian networks works discrete time fashion exploitingstructure DBN. Ng, Pfeffer, Dearden (2005) extend RBPF continuous time dynamic systems apply method K-9 experimental Mars rover NASA Ames ResearchCenter. model hybrid system containing discrete continuous variables.use particle filters discrete variables unscented filters continuous variables.work similar apply RBPF CTBN. model contains discretevariables evidence continuous time (as opposed snapshots systemstate).3. Continuous Time Bayesian Networksbegin briefly reviewing definition Markov processes continuous time Bayesiannetworks (CTBNs).3.1 Homogeneous Markov Processfinite-state, continuous-time, homogeneous Markov process Xt described initial distribution PX0 and, given state space V al(X) = {x1 , ..., xn }, n n matrix transition intensities:QX =qx1q x2 x1...q x1 x2qx2...q xn x1q xn x2. . . q x1 xn. . . q x2 xn....... . . qxn.Pqxi xj intensity (or rate) transition state xi state xj qxi = j6=i qxi xj .transient behavior Xt described follows. Variable X stays state x timeexponentially distributed parameter qx . probability density function f Xt remainingx duration fx (q, t) = qx exp(qx t) 0. expected time next transitiongiven state currently x 1/qx . Upon transitioning, X shifts state x0 probabilityxx0 = qxx0 /qx . Note given qx , xx0 qxx0 iosmorphic. sometime gives formulaeterms xx0 simplifies expression.distribution state process X future time t, Px (t), computeddirectly QX . PX0 distribution X time 0 (represented vector), then, letting749fiX U & HELTONexp matrix exponential,PX (t) = PX0 exp(QX t) .3.2 Complete DataComplete data HMP represented set trajectories = {1 , ...n }. trajectorycomplete set state transitions: = {(xd , td , x0d )}, meaning X stayed state xdduration td , transitioned state x0d . Therefore know exact state variableX time 0 .3.3 Sufficient Statistics LikelihoodGiven HMP full data D, likelihood single state transition = {(xd , td , x0d )}LX (q, : d) = (qxd exp(qxd td ))(xd x0d ) .likelihood function decomposed transition:LX (q, : D) = (LX (q : d))(LX ( : d))dDdD[x,x0 ]= ( qxM [x] exp(qx [x]))(xx0).x x0 6=xxtake log function, get log likelihood:lX (q, : D) = lX (q : D) + lX ( : D)XX=(M [x] ln(qx ) qx [x] +[x, x0 ] ln(xx0 )) .x0 6=xx[x, x0 ][x] sufficient statistics HMPmodel. [x, x0 ] numberPtimes X transitions state x x0 . denote [x] = x0 [x, x0 ], total numbertimes system leaves state x. [x] total duration X stays state x.3.4 Learning Complete Dataestimate parameters transition intensity matrix Q, maximize log likelihood function. yields maximum likelihood estimates:qx =[x],[x]xx0 =[x, x0 ].[x]3.5 Incomplete DataIncomplete data HMP composed partially observed trajectories = {1 , ...n }.trajectory consists set = {(Sd , td , dt)} observations, Sd subsystem (anonempty subset states X) process. triplets specifies intervalevidence. states variable X subsystem Sd time td time td + dt.observations may duration-free. i.e., observe X Sd time t, knowlong stayed there. called point evidence generalized using tripletnotation described setting duration 0. partially observed trajectory,observe sequences subsystems, observe state transitions within subsystems.750fiI NTRUSION ETECTION USING CTBN3.6 Expected Sufficient Statistics Expected Likelihoodconsider possible completions partially observed trajectory specify transitionsconsistent partial trajectory. combining partial trajectory completion,get full trajectory. define D+ = {1+ , ..., n+ } completions partial trajectoriesD. Given model, distriubtion D+ , given D.data D+ , expected sufficient statistics respect probability density possible completions data [x], [x, x0 ] [x]. expected log likelihoodE[lX (q, : D+ )] = E[lX (q : D+ )] + E[lX ( : D+ )]XX(M [x] ln(qx ) qx [x] +=[x, x0 ] ln(xx0 )) .x0 6=xx3.7 Learning Incomplete Dataexpectation maximization (EM) algorithm used find local maximum likelihoodpartial trajectory. EM algorithm iterates following E step stepconvergence derived likelihood function.E step: Given current HMP parameters, compute expected sufficient statistics: [x],[x, x0 ] [x] data set D. complex part algorithm. givedetails below.step: computed expected sufficient statistics, update new model parametersnext EM iteration:[x, x0 ][x], xx0 =.qx =[x][x]show calculate expected sufficient statistics using forward-backwardmessage passing method.trajectory devided N intervals interval separatedadjacent event changes. Assume trajectory spans time interval [0, ), let [v, w]observed evidence time v w, including events time stamp v w, let(v, w) set evidence excluding v w. Let subsystem statesrestricted interval.define= P (Xt , [0, t]), = P ( [t, ] | Xt )vectors (indexed possible assignments Xt ). Similarly, define correspondingdistribution excludes certain point evidence follows.= P (Xt , [0, t)),t+ = P ( (t, ] | Xt ) .Denote j vector 0s except j-th position 1, denote ij matrix0s except element i-th row j-th column 1.able show derived expected sufficient statistics. time,ZE[T [x]] =P (Xt | [0, ])x dt0N1 Z ti+1X1=P (Xt , [0, ])x dt .P ( [0, ])tii=0751fiX U & HELTONconstant fraction beginning last line serves make total expected timej sum . integral interval expressedZwZwv exp(QS (t v))xx exp(QS (w t))w dt ,P (Xt , [0, ])x dt =vvQS QX except elements correspond transitions set0.equation expected transition counts similarly defined:N 1E[M [x, x0 ]] =Xqx,x0+[ti x,x0 t+iP ( [0, ])i=1N1 Z ti+1X+ti exp(QS (t ti ))x,x0 exp(QS (ti+1 t))ti+1 dt] .i=0tiintegrals appearing E[T ] E[M ] computed via standard ODE solver, likeRunge-Kutta method (Press, Teukolsky, Vetterling, & Flannery, 1992). method usesadaptive step size move quickly times expected changes slowlytimes rapid transitions.remaining problem calculate . Let QSS0 transitioning intensitymatrix HMP one subsystem another 0 . matrix QX ,elements corresponding transitions 0 non-zero.ti = ti1 exp(QSi1 (ti ti1 )) ,ti = ti QSi1 Si ,ti = exp(QSi (ti+1 ti ))ti+1 ,ti = QSi1 Si ti .forward-backward calculation, also trivial answer queriesP (Xt = x | [0, ]) =1xx .P ( )3.8 Continuous Time Bayesian NetworksHMPs good modeling many dynamic systems, limitationssystems multiple components state space grows exponentially numbervariables. HMP model variable independencies therefore use unifiedstate X represent joint behavior involving components system.section, show continuous time Bayesian network used address issue.Nodelman et al. (2002) extend theory HMPs present continuous time Bayesian networks (CTBNs), model joint dynamics several local variables allowing transitionmodel local variable X Markov process whose parametrization dependssubset variables U .752fiI NTRUSION ETECTION USING CTBN3.9 Definitionfirst give definition inhomogeneous Markov process called conditional Markov process. critical concept us formally introduce CTBN framework.Definition 1 (Nodelman, Shelton, & Koller, 2003) conditional Markov process X inhomogeneous Markov process whose intensity matrix varies function current values setdiscrete conditioning variables U . parametrized using conditional intensity matrix (CIM)QX|U set homogeneous intensity matrices QX|u , one instantiation values u U .call U parents X. set U empty, CIM simply standard intensitymatrix.CIMs provide way model temporal behavior one variable conditionedvariables. putting local models together, joint structured model continuoustime Bayesian network.Definition 2 (Nodelman et al., 2003) continuous time Bayesian network N set stochastic processes X consists two components: initial distribution PX0 , specified Bayesiannetwork B set random variables X, continuous transition model, specified usingdirected (possibly cyclic) graph G whose nodes X X; UX denotes parents X G.variable X X associated conditional intensity matrix, QX|UX .dynamics CTBN quantitatively defined graph. instantaneous evolutionvariable depends current value parents graph. quantitative descriptionvariables dynamics given set intensity matrices, one value parents.means transition behavior variable controlled current values parents.standard notion d-separation Bayesian networks carries CTBNs.graphs cyclic variables represent processes (not single random variables), implicationslittle different. variable (process) still independent non-descendants given parents,still independent everything given Markov blanket (any variable either parent,child, parent child). Cycles cause parents also children, providedconsidered both, definitions still hold. importantly, notion given worksfull trajectory variable question known. Therefore, X grandchildrenindependent given Xs childrens values single instant. Rather, independentgiven Xs childrens full trajectories time 0 last time interest.amalgamate variables CTBN together, get single homogeneous Markovprocess joint state space. joint state intensity matrix, rate 0 assignedtransition involves changing one variables value exact time.intensities found looking value corresponding conditional intensity matrixvariable changes. diagonal elements negative row sums.Forward sampling done quickly CTBN without generating full joint intensitymatrix. keep track next event time variable (sampled relevant exponential distribution given current values parent). select earliestevent time change variable (sampling multinomial distribution implied rowvariables relevant intensity matrix). next event time variable changedchildren must resampled, variables time must resampled duememoriless property exponential distribution. way sequence events (a trajectory)sampled.753fiX U & HELTON3.10 Learningcontext CTBNs, model parameters consist CTBN structure G, initial distribution P0 parameterized regular Bayesian network, conditional intensity matrices (CIMs)variable network. section, assume CTBN structure known us,focus parameter learning. also assume model irreducible. initialdistribution P0 becomes less important context CTBN inference learning, especiallytime range becomes significantly large. Therefore, parameter learning contextestimate conditional intensity matrices QXi |Ui variable Xi , Ui setparent variables Xi .3.10.1 L EARNING C OMPLETE DATANodelman et al. (2003) presented efficient way learn CTBN model fully observedtrajectories. complete data, know full instantiations variables wholetrajectory. know CIM governing transition dynamics variabletime. sufficient statistics [x, x0 |u] number times X transitions state xx0 given parent instantiation u [x|u] Ptotal duration X stays state xgiven parent instantiation u. denote [x|u] = x0 [x, x0 |u].likelihood function decomposedLN (q, : D) =LXi (qXi |Ui : D)LXi (Xi |Ui : D))(1)Xi XLX (qX|U : D) =YYu[x|u]qx|uexp(qx|u [x|u])(2)xLX ( : D) =YYu0xx0 |u [x, x |u] .(3)x x0 6=xput functions together take log, get log likelihood componentsingle variable X:lX (q, : D) = lX (q : D) + lX ( : D)XX=[x|u] ln(qx |u) q[x|u] [x|u]u+xXX Xu[x, x0 |u] ln(xx0 |u )).(4)x x0 6=xmaximizing log likelihood function, model parameters estimatedqx|u =[x|u],[x|u]xx0 |u =754[x, x0 |u].[x|u](5)fiI NTRUSION ETECTION USING CTBN3.10.2 L EARNING NCOMPLETE DATANodelman, Shelton, Koller (2005) present expectation maximization (EM) algorithmlearn CTBN model partially observed trajectories D. expected sufficient statistics[x, x0 |u], expected number times X transitions state x x0 parent setU takes values u, [x|u], expected Pamount time X stays state xparent instantiation u. denote [x|u] x0 [x, x0 |u]. expected log likelihooddecomposed way Equation 4, except sufficient statistics [x, x0 |u], [x|u][x|u] replaced expected sufficient statistics [x, x0 |u], [x|u] [x|u].EM algorithm CTBN works essentially way HMP. expectation step calculate expected sufficient statistics using inference method (will describedSection 3.11). maximization step update model parameters:qx|u =[x|u],[x|u]xx0 |u =[x, x0 |u].[x|u]3.11 Inferencegiven CTBN model (partially) observed data, would like query model.example, may wish calculate expected sufficient statistics EM algorithm.3.11.1 E XACT NFERENCENodelman et al. (2005) provide exact inference algorithm using expectation maximizationreason learn parameters partially observed data. exact inference algorithm requires flattening variables single Markov process performing inferenceHMP. problem makes state space grow exponentially large. Therefore, exactinference method feasible problems small state spaces.3.11.2 PPROXIMATE NFERENCEissue addressed below, much work done CTBN approximate inference. Nodelman, Koller, Shelton (2005) present expectation propagation algorithm. Saria,Nodelman, Koller (2007) give another message passing algorithm adapts time granularity. Cohn, El-Hay, Friedman, Kupferman (2009) provide mean field variational approach.El-Hay, Friedman, Kupferman (2008) show Gibbs sampling method approach using MonteCarlo expectation maximization. Fan Shelton (2008) give another sampling based approachuses importance sampling. El-Hay, Cohn, Friedman, Kupferman (2010) describe different expectation propagation approach.estimate parameters models build two applications (NIDS HIDS),employ inference algorithms including exact inference Rao-Blackwellized particle filtering(RBPF) algorithm, depending model size. Ng et al. (2005) extended RBPF CTBNs.model hybrid system containing discrete continuous variable. used particlefilters discrete variables unscented filters continuous variable. worksimilar work method applying RBPF CTBNs, model contains discretevariables evidence continuous intervals.755fiX U & HELTONPORT80808044311351019955173059822DESCRIPTIONWorld Wide Web HTTPHTTP AlternateHTTP protocol TLS/SSLAuthentication ServiceTalarian TCPpop3 protocol TLS/SSLunknownunknownPORT80139443445186326781170110DESCRIPTIONWorld Wide Wed HTTPNETBIOS Session ServiceHTTP protocol TLS/SSLMicrosoft-DSMSNPGadget Gate 2 WayAT+C License ManagerPost Office Protocol - Version 3Figure 1: Ranking frequent ports MAWI dataset (left) LBNL dataset (right).3.12 CTBN ApplicationsAlthough inference learning algorithms well developed CTBNs,applications real world problems. Nodelman Horvitz (2003) used CTBNsreason users presence availability time. Ng et al. (2005) used CTBNs monitormobile robot. Nodelman et al. (2005) used CTBNs model life event history. Fan Shelton(2009) modeled social networks via CTBNs. previous work (Xu & Shelton, 2008) presentedNIDS host machine using CTBNs, include HIDS.4. Anomaly Detection Using Network Trafficsection, present algorithm detect anomalies network traffic data using CTBNs.focus single host network. sequence timing events (e.g. packettransimission connection establishment) important network traffic flow. mattersmany connections initiated past minute, also timing:evenly spaced trace probably normal, came quick burst suspicious.Similarly, sequence important. connections made sequentially increasing portslikely scanning virus, whereas set ports random order likelynormal traffic. merely simple examples. would like detect complexpatterns.typical machine network may diverse activities various service types (e.g.HTTP, SMTP). destination port number roughly describes type service particular network activity belongs. worms propagate malicious traffic toward certain well knownports affect quality associated services. looking traffic associated differentports sensitive subtle variations appear aggregate trace informationacross ports. Figure 1 shows popular ports ranked frequencies networktraffic datasets use (described depth later). services are, extent,independent other. therefore model ports traffic CTBN submodel.denote whole observed traffic sequences particular host, j trafficassociated port j.756fiI NTRUSION ETECTION USING CTBNGNHPinPoutCincCdecFigure 2: CTBN model network traffic plate model. N number port .4.1 CTBN Model Network Trafficuse port-level submodel previous work (Xu & Shelton, 2008). latentvariable H four fully observed toggle variables: Pin , Pout , Cinc , Cdec .nodes packet-in, Pin , packet-out, Pout , represent transmission packethost. intrinsic state: transmission packet essentially instantaneousevent. Therefore events (or transitions) without state. modeled usingtoggle variable event evidence change state variable ratetransition associated state required same.nodes connection-increase Cin connection-decrease Cdec together describe statusnumber concurrent connections C active host. Notice C increasedecrease one given event (the beginning ending time connection). assumearrival new connection termination existing connection independentnumber connections. Thus intensity connection starts (or stops)connections. Therefore, also modeled toggle variables.Node H 8 states represent different abstract attributes machines internal state.toggle variables (Pin , Pout , Cinc Cdec ) allowed change 2 statesH required rate states. 2 hidden states per togglevariable chosen balance expressive power model efficiency.previous work, assumed traffic associated different ports independentother, port-level submodels isolated. remove restriction introducinganother latent variable G ties port submodels together. full model shown Figure 2.4.2 Parameter Learning Using RBPFcalculate expected sufficient statistics E-step EM parameter learning, exactinference algorithm Nodelman et al. (2002) flattens variables joint intensity matrixreasons resulting homogeneous Markov process. time complexity exponentialnumber variables. example, 9 port models, network contains 46 variablestotal. Approximate inference techniques like clique tree algorithm (Nodelman et al., 2002),message passing algorithms (Nodelman et al., 2005; Saria et al., 2007), importance sampling (Fan757fiX U & HELTON& Shelton, 2008) Gibbs sampling (El-Hay et al., 2008) overcome problem sacrificingaccuracy.notice model nice tree structure makes Rao-Blackwellized particlefiltering (RBPF) perfect fit. RBPF uses particle filter sample portion variablesanalytically integrates rest. decomposes model structure efficiently thus reducessampling space.denote N port-level hidden variables H1 , ..., HN , posteriordistributionQNwhole model factorized P (G, H1 , ..., HN | ) = P (G | ) i=1 P (Hi | G, ). NoteG Hi processes, probability density complete trajectories. useparticle filter estimate Gs conditional distribution P (G | ) set sampled trajectoriesG. difficult sample directly posterior distribution, use importance samplersample particle proposal distribution particles weighted ratiolikelihood posterior distribution likelihood proposal distribution (Doucetet al., 2000). Since variable G latent parents, use forward samplingsample particles P (G) weight particle simply likelihoodconditioned trajectory G (Fan & Shelton, 2008). port-level submodel dseparated rest network, given full trajectory G (see Section 3.9 d-separationCTBNs). Since small (only 8 hidden states), marginalized exactly.is, calculate P (i | G) (where portion trajectory submodel i) exactly,marginalizing Hi - recursions Section 3.7.expected sufficient statistics (ESS) variable X CTBN TX|U [x|u], expected amount time X stays state x given parent instantiation u, MX|U [x, x0 |u],expected number transitions state x x0 given Xs parent instantiation u. Let g P (G),)= 1, . . . , particles. define likelihood weights wi = PP(g(g|) letPW = wi sum weights. general importance sampling allows expectedsufficient statistic estimated following way, SS sufficient statistic:E(g,h1 ,...,hN )P (G,H1 ,...,HN | ) [SS(g, h1 , . . . , hN )]= EgP (G| ) Eh1 ,...,hN P (H1 ,...,HN |g, ) [SS(g, h1 , . . . , hN )]1 Xwi Eh1 ,...,hN P (H1 ,...,HN |gi , ) [SS(g , h1 , . . . , hN )] .Wexpected sufficient statistics whole model two categories: dependg, ESS(g), depend port model k, ESS(g, hk , k ). ESS(g) simplysummation counts (the amount time G stays state, number times Gtransitions one state another) particles, weighted particle weights:EgP (G| ) [SS(g)]1 Xwi SS(g ) .W758(6)fiI NTRUSION ETECTION USING CTBNFunction Wholemodel Estepinput: current model , evidenceoutput: Expected sufficient statistics ESSESS := {ESS(g), ESS(s1 , g), . . . , ESS(sn , g)}Initialize ESS emptyparticle g {g 1 , . . . , g }, g P (G)Sj {S1 , . . . , SN }[P (j |g ), ESS(sj , g )] = Submodel Estep(g , [Sj ], j )Sj {S1 , . . . , SN }QESS(sj , g) = ESS(sj , g) + k6=j P (k |g ) ESS(sj , g )i)ESSgi = CountGSS(gQESS(g) = ESS(g) + j P (j |g ) ESSgiReturn ESSFigure 3: Rao-Blackwellized particle filtering Estep whole modelESS(g, hk , k ) calculated submodel independently:Eg,h1 ,...,hN P (G,H1 ,...,HN | ) [SS(g, hk , k )]Z1 XwiP (hk |g , k )SS(g , hk , k ) dhkWhkQZ1 X j P (j |g )P (hk |g , k )SS(g , hk , k ) dhk=WP ( )hkZX1P (j |g )P (hk , k |g )SS(g , hk , k ) dhk .Whk(7)j6=kintegrals possible trajectories hidden process Hk . first line holdsd-separation (we need average submodel k, given assignment G). secondline expands weight. last line combines weight term submodel k termsintegral get likelihood hk submodel data. constant proportionalityPcancel subsequent maximization, reconstructed noting x TX|U [x|u]total timeR interval.last integral, hk P (hk , k |g )SS(g , hk , k ) dhk , P (j |g ) calculated usingtechnique described Nodelman et al. (2005), exact ESS calculation. calculationssimilar integrals Section 3.7, except intensity matrices change intervalinterval (they function sampled trajectory gi ).full E-step algorithm shown Figure 3 (sk represents variables submodelk). Function Submodel Estep calculates expected sufficient statistics likelihoodsubnet model (Equation 7). Function CountGSS counts empirical time transition statisticssampled trajectory G (Equation 6).EM, use ESS true sufficient statistics maximize likelihoodrespect parameters. regular CTBN variable X (such hidden variable GH), Equation 5 performs maximization. toggle variables, e.g. Pi , likelihood759fiX U & HELTONcomponent toggle variableMPQPi |ui exp(QPi |u [U = u])ufound setting qx|u value (QPi |u ) x (tieing parameters)simplifying product x Equation 2. Thus maximum likelihood parameter estimateQPi |u =MPi[U = u]MPi number events variable Pi QPi |u parameter: rateswitching.synchronize particles end window (see Section 6.1) resamplenormal particle filter points. is, propagate particles forward, stopend window, resample based weights, continue new setparticles. general, particles aligned time, except resampling points.4.3 Online Testing Using LikelihoodCTBN model fitted historic data, detect attacks computing likelihoodwindow data (see Section 6.1) model. likelihood falls threshold,flag window anomalous. Otherwise, mark normal.experiments, fix window fixed time length, Tw . Therefore,window interest starts time , wish calculate p( [T, + Tw ] | [0, ]) [s, t]represents observed connections packets time time t. Again, use RBPFestimate probability. samples time represent prior distribution P (G | [0, ]).Propagating forward across window length Tw produces set trajectories G,g . submodel k evalute P (k [T, + Tw ] | g ) exact marginalization (the sumvector +Tw , forward message). weighted average (over samples g k ) productsubmodel probabilities estimate P ( [T, + Tw ] | [0, ]).5. Anomaly Detection Using System Callsturn problem detecting anomalies using system call logs.5.1 CTBN Model System CallsSystem call logs monitor kernel activities machines. record detailed informationsequence system calls operating system. Many malicious attacks host revealeddirectly internal logs.analyze audit log format SUNs Solaris Basic Security Module (BSM) praudit auditlogs. user-level kernel event record least three tokens: header, subject, return.event begins header format of: header, record length bytes, audit record versionnumber, event description, event description modifier, time date. subject line consists of:subject, user audit ID, effective user ID, effective group ID, real user ID, real group ID, processID, session ID, terminal ID consisting device machine name. return returnvalue indicating success event closes record.760fiI NTRUSION ETECTION USING CTBNHS1S2SnFigure 4: CTBN model system call data}s1, s2, ..., skti-1 ti-1+tti+ttiti+1 ti+1+ttimeFigure 5: System call traces finite resolution clock (resolution = )construct CTBN model similar port-level network model. Individual system callsS1 , ..., SN , event description fields header token, transiently observed:happen instantaneously duration. treat toggle variables like packetsnetwork model. also introduce hidden variable H parent system calls variablesallow correlations among them. hidden variable designed model internal statemachine, although semantic meaning imposed method. Put together, systemcall model looks like Figure 4.state space hidden variable H size m, transition rate matrix HQH =qh1q h2 h1...q h1 h2qh2...q hm h1q hm h2. . . q h1 hm. . . q h2 hm....... . . qhm.transition intensity rate toggle variable given current value parent Hqs|hi , = 1, ..., m.estimate CTBN model parameters, use expectation maximization (EM)algorithm. expected sufficient statistics need calculate modelMhi hj , expected number times H transitions state j;Thi , expected amount time H stays state i;Ms|hi , expected number times system call evoked H state i.761fiX U & HELTONmaximum likelihood parametersMhi hjThiMs|hi=.Thiq hi hj =qs|hi5.2 Parameter Estimation Finite Resolution Clocksfinite resolution computer clocks, multiple instantaneous events (system calls)occur within single clock tick. Therefore audit logs, batch system calls may recordedexecuted time point, rather real time stamp, result finitetime accuracy. However, correct order events kept logs. is, know exactlysystem call S2 follows S1 recorded order audit logs. Thus systemcall timings partially observed. type partial observation previouslyconsidered CTBN inference. typical trajectory [0, ] system call data shownFigure 5: batch system calls evoked time ti next clock tick,followed quiet period arbitrary length, yet another bunch events timeti+1 on.Let t1:t2 denote evidence interval [t1, t2), t1:t2+ denote evidence [t1, t2],t1 :t2 denote evidence (t1, t2). define vectorsti = p(Ht , 0:ti )t+i = p(t+ :T |Ht+ )Ht value H prior transition ti , Ht+ value afterward.also define vectorsti = p(Hti , 0:t+ )ti = p(ti :T |Hti )evidence transition time ti included. follow forward-backward algorithmcompute ti ti ti event. this, split interval [ti , ti+1 )spike period [ti , ti + ) (t one resolution clock), batchsystem calls, quite period [ti + , ti+1 ) events exist, propagationsseparately.spike period [ti , ti + ), observed event sequence s1 , s2 , ..., sk , constructartificial Markov process X following intensity matrix.QX =QH Q1 0...00 QH Q2 . . .0...............00. . . QH Qk00...0 QH762.fiI NTRUSION ETECTION USING CTBNQH =Pqh1 sS qs|h1q h2 h1...qh2q hm h1q h1 h2PsS qs|h2............. . . qhmq hm h2q h1 hmq h2 hm...PsS qs|hmQi =qsi |h10...00qsi |h2............00...00qsi |hmX tracks evidence sequence s1 s2 ... sk . QX square block matrix dimension(k + 1). block matrix. subsystem X k + 1 blocks states.first block represents state H events. second block represents H exactlyone event, s1 , happens. third block represents H s1 followed s2 happens,on. last block represents H events finish executing order. subsystemzero transition intensities everywhere except along sequence pass. diagonal QHmatrix QH except transition intensities system call variablessubtracted. full system includes transitions observed.transition rates set zero (to force system agree evidence), conditioningchange diagonal elements rate matrix (Nodelman et al., 2002). Withink + 1 states block, H freely change value. Therefore, non-diagonal elementsQH intensities QH . Upon transitioning, X transit stateanother according event sequence. Therefore, blocks 0 matrices exceptimmediate right diagonal blocks. transition behavior described matrixQi . Qi 0 intensities non-diagonal entries H change simultaneously.diagonal element Qi (h, h) intensities event si happening, given current valuehidden state h.take forward pass example describe propagation; backward passperformed similarly. Right ti , ti dimensions. expand m(k + 1) dimensionsform ti non-zero probabilities first states. ti describesdistribution subsystem X. ti eQX represents probability distribution time ti + ,given prefix observed sequence occurred. take last state probabilitiescondition entire sequence happening, thus resulting m-dimensional vector, ti +t .quiet period [ti + , ti+1 ), evidence observed. Therefore ti +t propagatedti+1 using QH , rate matrix conditioned H events occuring:ti+1 = ti +t exp(QH (ti+1 ti )) .done full forward-backward pass whole trajectory, calculate expected sufficient statistics Mhi hj , Thi Ms|hi . Again, refer work Nodelmanet al. (2005) algorithm.763fiX U & HELTON5.3 Testing Using Likelihoodlearned model normal process system call logs, calculatelog-likelihood future process model. log-likelihood comparedpredefined threshold. threshold, possible anomaly indicated. singlehidden variable, calculations done exactly.6. Evaluationevaluate methodology, constructed experiments two different types data: networktraffic traces system call logs. following sections, show experiment resultstasks.dynamic Bayesian network (DBN) another popular technique graphical modelingtemporal data. slice time, events without state changes (instantaneous events)difficult model. reasonable time resolution result multiple eventsvariable one time period. standard way encoding DBN. use togglevariable, records parity number events time interval. Furthermore,NIDS, events bursty. active times, multiple packets emited per second.inactive times, may activity hours. Finding suitable sampling ratemaintains efficency model difficult. HIDS, problem acute.know way modeling timing ambiguity DBN without throwing away timinginformation adding mathematical framework essentially turns DBN CTBNdescribed here. general, could find suitable way apply DBN problemswithout essentially turning DBN CTBN finely slicing time applyingnumeric tricks speed inference amount converting stochastic matrices ratematrices using numeric integration matrix exponential.compared current adaptive methods problem individually. include nearest neighbor, support vector machines, sequence time-delaying embedding. givedetails methods below.6.1 Experiment Results Network Trafficsection, present experiment results NIDS.6.1.1 DATASETSverify approach two publicly available real network traffic trace repositories: MAWIworking group backbone traffic MAWI LBNL/ICSI internal enterprise traffic LBNL.MAWI backbone traffic part WIDE project collected raw daily packetheader traces since 2001. records network traffic inter-Pacific tunnelJapan USA. dataset uses tcpdump IP anonymizing tools record 15-minutetraces every day, consists mostly traffic Japanese universities. experiment,use traces January 1st 4th 2008, 36,592,148 connections total timeone hour.LBNL traces recorded medium-sized site, emphasis characterizing internal enterprise traffic. Publicly released anonymized form, LBNL data collects764fiI NTRUSION ETECTION USING CTBN# packets flowing source destination# packets flowing destination source# connections source last 5 seconds# connections destination last 5 seconds# different services source last 5 seconds# different services destination last 5 seconds# connections source last 100 connections# connections destination last 100 connections# connections port source last 100 connections# connections port destination last 100 connectionsFigure 6: Features nearest neighbor approach work (Lazarevic et al., 2003).100 hours network traces thousands internal hosts. publicly released, takeone hour traces January 7th, 2005 (the latest date available), 3,665,018 total connections.6.1.2 W ORM ETECTIONstart problem worm detection. split traffic traces host: half traininghalf testing. learn CTBN model training data hosts. Sincenetwork data available clean traffic known intrusions, inject real attack tracestesting data. particular, inject IP Scanner, W32.Mydoom, Slammer. slidefixed-time window testing traces, report single log-likelihood value slidingwindow, compare predefined threshold. threshold, predictabnormal time period. define ground truth window abnormal attacktraffic exists interval, normal otherwise. window size use 50 seconds.consider windows contain least one network event.compare method employing RBPF previous factored CTBN model (Xu &Shelton, 2008), connection counting, nearest neighbor, Parzen-window detector (Yeung & Chow,2002), one-class SVM spectrum string kernel (Leslie, Eskin, & Noble, 2002).connection counting method straightforward. score window numberinitiated connections window. worms aggregate many connections short time,method captures particular anomaly well.make nearest neighbor competitive, try extract reasonable set features. followfeature selection work Lazarevic et al. (2003), use total 23 features.features available data. available shown Figure 6. Noticefeatures associated connection record. apply nearest neighbor methodwindow based testing framework, first calculate nearest distance connection insidewindow training set (which composed normal traffic only), assign maximumamong score window. Similarly, Parzen window approach, applyfeature set assign maximum density among connections inside windowscore window.Besides feature-based algorithms, would also like see sequence-basedapproaches compare methods. algorithms widely used network anomalydetection. Like approach, treat traffic traces stream data sequential contexts765fiX U & HELTON110.80.80.80.60.4Nearest NeighborConnection CountParzen WindowSVMSpectrumCTBN, factoredCTBN, RBPF1000.2000.020.040.06False Positive Rate0.080.60.4Nearest NeighborConnection CountParzen WindowSVMSpectrumCTBN, factoredCTBN, RBPF1000.2000.10.020.080.60.4000.110.80.80.80.6Nearest NeighborConnection CountParzen WindowSVMSpectrumCTBN, factoredCTBN, RBPF100000.020.040.06False Positive RateIP Scanning0.080.10.60.4Nearest NeighborConnection CountParzen WindowSVMSpectrumCTBN, factoredCTBN, RBPF1000.2000.020.040.06False Positive RateMydoom0.080.1True Positive Rate10.20.020.040.06False Positive Rate0.080.1Slammer10.4Nearest NeighborConnection CountParzen WindowSVMSpectrumCTBN, factoredCTBN, RBPF1000.2MydoomTrue Positive RateTrue Positive RateLBNLIP Scanning0.040.06False Positive RateTrue Positive Rate1True Positive RateTrue Positive RateMAWIexplored. One-class SVM spectrum string kernel chosen comparison.implemented spectrum kernel LIBSVM library (Chang & Lin, 2001). give networkactivities (such connection starting ending, packet emmision receipt) inside portlevel submodel distinct symbol. sequence symbols fed algorithm inputs.decision surface trained normal training traffic. testing, sliding window,distance window string decision hyperplane reported window score.also tried experiments using edit distance kernel, results dominated spectrumkernel, report here.0.60.4Nearest NeighborConnection CountParzen WindowSVMSpectrumCTBN, factoredCTBN, RBPF1000.2000.020.040.06False Positive Rate0.080.1SlammerFigure 7: ROC curves testing results IP scanning attack, Mydoom attack Slammer attack.= 0.001. Top: MAWI. Bottom: LBNL.injecting attack traffic, randomly pick starting point somewhere first halftest trace insert worm traffic duration equal times length full testingtrace. shorter is, harder detect anomaly. choose 0.02%experiments work challenge detection tasks. also scaled back ratesworms. running full speed, worm easy detect method. slows(and thus blends background traffic better), becomes difficult detect. letscaling rate (e.g. 0.1 indicates worm running one-tenth normal speed).method, set state space variable G 4 variable H 8. use100 samples particle filtering, resample particles every 50 seconds. SVMspectrum kernel method, choose sub-sequence length 5 parameter 0.8.show ROC curves methods Figure 7. curves show overall performance 10 active hosts dataset. point curves corresponds766fiI NTRUSION ETECTION USING CTBN110.80.8True Positive RateTrue Positive Ratedifferent threshold algorithm. CTBN method out-performs algorithms exceptsingle case Mydoom attack background LBNL traffic. many cases,advantages CTBN approach pronounced.MAWI data, factored non-factored CTBN models perform comparably.believe data captures connections traverse trans-Pacific link.Therefore, connections machine represented. makes reasoningglobal pattern interaction machine difficult. LBNL data, one attack (IPscanning) shows advantage non-factored model. One attack (Mydoom) shows distinctadvantage. one attack (Slammer) indicates advantage, depending desired falsepositive rate. demonstrate advantage jointly modeling traffic across ports,although clear advantage uniform traffic patterns attack types.0.60.40.20.60.40.2Connection CountCTBN, RBPF100000.020.040.06False Positive Rate0.08Connection CountCTBN, RBPF1000.1000.020.040.06False Positive Rate0.080.1Figure 8: ROC curves testing results Slammer attack MAWI dataset demonstratingeffect slowing attack rate. Left: = 0.01. Right: = 0.001also show ROC curves shift scale back worm running speed Figure 8.firewalls built sensitive block malicious traffic, worms act stealthysneak through. demonstrate robustness method compared best competitor(connection counts) speed worms attack.6.1.3 H OST DENTIFICATIONIdentifying individual hosts based network traffic patterns another useful applicationmodel. instance, household usually installs network router. family memberscomputer connected router. outside Internet, network traffic goingrouter behaves coming one peer, actually coming different people.Dad possibly read sports news kids surf social networks. interesting welluseful tell family member contributing current network traffic. Host identificationalso used combat identity theft. network identity abused attacker, hostidentification techniques help network administrator tell whether current network traffichost consistent usual pattern not.767fiX U & HELTONfirst set experiments construct host model fitting competition. 10hosts picked worm detection tasks LBNL dataset compose testing pool. learncoupled CTBN model host. split test traces (clean) particular hostsegments lengths 15 seconds. segments, compute log-likelihoodsegment learned model hosts (including own), label segmenthost achieves highest value. compute confusion matrix C whose element Cijequals fraction test traces host model j highest log-likelihood. expectsee highest hit rates fall diagonals ideally host best describedmodel. Table 9 shows results dataset LBNL. vast majority traffic windowsassigned correct host. exception host 1, diagonals distinctly higherelements row. comparison, performed experiment using SVMspectrum kernel method. Again, selected sub-sequence length 5 parameter0.8. tried multiple methods normalization (of distance hyperplane)variations parameters. produced poor results almost windows assignedsingle host. omit table results.Host1234567891010.090.0600000.2500.0402340.41 0.47 00.50 0.31 00100010.08 0.13 00.20 0.03 000.06 0.020.08 0.28 00.05 0.13 0.010.03 0.18 0.0156789100000.03 0000.13 00000000000000000.68 0.06 0.03 0.01 00.010.01 0.74 00.02 00000.66 000.0100.05 00.59 000.01 0.01 0.02 00.73 000.15 0.03 0.03 00.57Figure 9: Confusion matrix LBNL host identification using CTBNsecond experiment host traffic differentiation task. mingle network trafficanother host analyzed host. expect detection method successfully tell aparttwo. verify idea, pick one host among 10 choose LBNL datasetsplit traffic evenly training testing. learn model training data.testing data, randomly choose period inject another hosts traffic worm.goal identify period abnormal since hosts traffic longer behavior.Figure 10 displays results two combination tests. parameters injectingtraffic worm = 0.02, = 0.001. left graph, nearest neighbor Parzenwindow curve overlap, CTBN curves overlap. right graph, coupled CTBN curvesubstantially outperforms curves.6.2 Experiment Results System Call Logssection, present experiment results HIDS.768fi110.80.80.60.4Nearest NeighborConnection CountParzen WindowSVMSpectrumCTBN, factoredCTBN, RBPF100.2000.020.040.06False Positive Rate0.08True Positive RateTrue Positive RateNTRUSION ETECTION USING CTBNNearest NeighborConnection CountParzen WindowSVMSpectrumCTBN, factoredCTBN, RBPF100.60.40.2000.10.020.040.06False Positive Rate0.080.1Figure 10: ROC curves testing results host identification LBNL data. Left: host 1,Nearest neighbor curve Parzen window curve overlap, CTBN curves overlap.Right: host 2.Week1234567# normalprocesses786645775615795769584# attackprocesses242033110240System Callcloseioctlmmapopenfcntlstataccess# occurrence123403688496088642479741664292791System Callexecvechdirchrootunlinkchownmkdirchmod# occurrence17411526328262341Figure 11: Left: DARPA BSM process summary. Right: DARPA BSM system call summary6.2.1 DATASETdataset used 1998 DARPA Intrusion Detection Evaluation Data Set MIT LincolnLaboratory. Seven weeks training data contain labeled network-based attacks midstnormal background data publicly available DARPA website. Solaris Basic SecurityModule (BSM) praudit audit data system call logs provided research analysis. followKang, Fuller, Honavar (2005) cross-index BSM logs produce labeled list filelabels individual processes. resulting statistics shown left table Figure 11.frequency system calls appearing dataset summarized descending orderright Figure 11.6.2.2 NOMALY ETECTIONexperimental goal detect anomalous processes. train CTBN model normalprocesses test mixture normal attack processes. state space769fi110.80.8True Positive RateTrue Positive RateX U & HELTON0.60.4CTBNSVMSpectrumStideNearest Neighbor0.2000.010.020.03False Positive Rate0.040.60.4CTBNSVMSpectrumStideNearest Neighbor0.20.05000.010.020.03False Positive Rate0.040.05Figure 12: ROC curves BSM data detection. Left: Training week 1 combined testingresults week 2 7; Right: Training week 3 test week 4, Stide curveCTBN curve overlaphidden variable H set 2. log-likelihood whole process learned modelrepresents score process. compare score predefined threshold classifyprocess normal one system abuse.implement sequence time-delaying embedding (stide) stide frequency threshold(t-stide) comparison (Warrender, Forrest, & Pearlmutter, 1999). two algorithms builddatabase previously seen normal sequences system calls compare testing sequencesit. straightforward perform well empirically system call logdatasets. choose parameter k, sequence length 5, h, locality frame length,50. results t-stide shown following resulting graphs since overlappedstide almost cases.approaches compare nearest neighbor one-class SVM spectrumstring kernel edit distance kernel. follow Hu et al. (2003) transform processfeature vector, consisting occurrence numbers system call process. nearestdistance testing process training set processes assigned score.one-class SVM, processes composed strings system calls. Normal processes usedlearning bounding surface signed distance assigned score. set subsequence length 5 parameter 0.5. Again, since edit distance kernel resultsdominated spectrum kernel, show them.Figure 12 displays results two experiment settings. left graph, trainmodel normal processes week 1 test processes weeks 2 7.right graph, train normal processes week 3 test processes week4, richest attack processes volume. attacks relatively rare compared normaltraffic, interested region ROC curves small false positive rates.show curves area false positive rate falls region [0, 0.05].CTBN method beats nearest neighbor SVM spectrum kernel experiments. stideperforms slightly better method combined test, achieves accuracy770fiI NTRUSION ETECTION USING CTBNexperiment using week 3 testing week 4. advantage CTBN modelstide easily combined prior knowledge data sources (suchnetwork data NIDS). demonstrate loss performance flexibility.7. Conclusionsrealm temporal reasoning, introduced two additions CTBN literature. First,demonstrated Rao-Blackwellized particle filter continuous evidence. Second, demonstrated learn reason data contains imprecise timings, still refrainingdiscretizing time.realm intrusion detection, demonstrated framework performs well tworelated tasks different data types. concentrating purely event timing, withoutconsideration complex features, able out-perform existing methods. continuoustime nature model aided greatly modeling bursty event sequences occur systemslogs network traffic. resort time slicing, either producing rapid slicesinefficient quite periods, lengthy slices miss timing bursty events.combination two sources information (system calls network events) wouldstraight-forward model produced. believe would result accuratedetection. collection data difficult, however; leave interesting next step.Acknowledgmentsproject supported Intel Research UC MICRO, Air Force Office ScientificResearch (FA9550-07-1-0076), Defense Advanced Research Project Agency (HR001109-1-0030).ReferencesAgosta, J. M., Duik-Wasser, C., Chandrashekar, J., & Livadas, C. (2007). adaptive anomalydetector worm detection. Workshop Tackling Computer Systems ProblemsMachine Learning Techniques.A.Hofmeyr, S., Forrest, S., & Somayaji, A. (1998). Intrusion detection using sequences systemcalls. Journal Computer Security, 6, 151180.Cha, B. (2005). Host anomaly detection performance analysis based system call neuro-fuzzyusing soundex algorithm n-gram technique. Systems Communications (ICW).Chang, C.-C., & Lin, C.-J. (2001). LIBSVM: library support vector machines. http://www.csie.ntu.edu.tw/cjlin/libsvm.Cohn, I., El-Hay, T., Friedman, N., & Kupferman, R. (2009). Mean field variational approximationcontinous-time Bayesian networks. Uncertainty Artificial Intelligence.Dewaele, G., Fukuda, K., & Borgnat, P. (2007). Extracting hidden anomalies using sketch nonGaussian multiresulotion statistical detection procedures. ACM SIGCOMM.Doucet, A., de Freitas, N., Murphy, K., & Russel, S. (2000). Rao-Blackwellised particle filteringdynamic Bayesian networks. Uncertainty Artificial Intelligence.771fiX U & HELTONEl-Hay, T., Cohn, I., Friedman, N., & Kupferman, R. (2010). Continuous-time belief propagation.Proceedings Twenty-Seventh International Conference Machine Learning.El-Hay, T., Friedman, N., & Kupferman, R. (2008). Gibbs sampling factorized continous-timeMarkov processes. Uncertainty Artificial Intelligence.Eskin, E. (2000). Anomaly detection noisy data using learned probability distributions.International Conference Machine Learning.Eskin, E., Arnold, A., Prerau, M., Portnoy, L., & Stolfo, S. (2002). geometric frameworkunsupervised anomaly detection: Detecting intrusions unlabeled data. Barbara, D., &Jajodia, S. (Eds.), Applications Data Mining Computer Security. Kluwer.Fan, Y., & Shelton, C. R. (2008). Sampling approximate inference continuous time Bayesiannetworks. Symposium Artificial Intelligence Mathematics.Fan, Y., & Shelton, C. R. (2009). Learning continuous-time social network dynamics. Proceedings Twenty-Fifth International Conference Uncertainty Artificial Intelligence.Forrest, S., A.Hofmeyr, S., Somayaji, A., & A.Longstaff, T. (1996). sense self unix processes. IEEE Symposium Security Privacy, pp. 120128.Hu, W., Liao, Y., & Vemuri, V. (2003). Robust support vector machines anomaly detectioncomputer security. International Conference Machine Learning Applications.Kang, D.-K., Fuller, D., & Honavar, V. (2005). Learning classifiers misuse detetction usingbag system calls representation. IEEE International Conferences IntelligenceSecurity Informatics.Karagiannis, T., Papagiannaki, K., & Faloutsos, M. (2005). BLINC: Multilevel traffic classificationdark. ACM SIGCOMM.Kruegel, C., Mutz, D., Robertson, W., & Valeur, F. (2003). Bayesian event classification intrusiondetection. Annual Computer Security Applications Conference.Lakhina, A., Crovella, M., & Diot, C. (2005). Mining anomalies using traffic feature distributions.ACM SIGCOMM, pp. 2126.Lazarevic, A., Ertoz, L., Kumar, V., Ozgur, A., & Srivastava, J. (2003). compare study anomalydetection schemes network intrusion detection. SIAM International Conference DataMining.LBNL.LBNL/ICSI enterprise tracing project..enterprise-tracing/Overview.html/.http://www.icir.org/Leslie, C., Eskin, E., & Noble, W. S. (2002). spectrum kernel: string kernel SVM proteinclassification. Pacific Symposium Biocomputing 7:566-575.Malan, D. J., & Smith, M. D. (2005). Host-based detection worms peer peer cooperation. Workshop Rapid Malcode.MAWI. MAWI working group traffic archive.. http://mawi.nezu.wide.ad.jp/mawi/.Moore, A. W., & Zuev, D. (2005). Internet traffic classification using Bayesian analysis techniques.ACM SIGMETRICS.Ng, B., Pfeffer, A., & Dearden, R. (2005). Continuous time particle filtering. National ConferenceArtificial Intelligence, pp. 13601365.772fiI NTRUSION ETECTION USING CTBNNodelman, U., & Horvitz, E. (2003). Continuous time Bayesian networks inferring users presence activities extensions modeling evaluation. Tech. rep. MSR-TR-2003-97,Microsoft Research.Nodelman, U., Koller, D., & Shelton, C. R. (2005). Expectation propagation continuous timeBayesian networks. Uncertainty Artificial Intelligence, pp. 431440.Nodelman, U., Shelton, C. R., & Koller, D. (2002). Continuous time Bayesian networks. Uncertainty Artificial Intelligence, pp. 378387.Nodelman, U., Shelton, C. R., & Koller, D. (2003). Learning continuous time Bayesian networks.Uncertainty Artificial Intelligence, pp. 451458.Nodelman, U., Shelton, C. R., & Koller, D. (2005). Expectation maximization complex durationdistributions continuous time Bayesian networks. Uncertainty Artificial Intelligence,pp. 421430.Press, W. H., Teukolsky, S. A., Vetterling, W. T., & Flannery, B. P. (1992). Numerical Recipes C(Second edition). Cambridge University Press.Qin, X., & Lee, W. (2004). Attack plan recognition prediction using causal networks. AnnualComputer Security Application Conference, pp. 370379.Rieck, K., & Laskov, P. (2007). Language models detection unknown attacks networktraffic. Journal Computer Virology.Saria, S., Nodelman, U., & Koller, D. (2007). Reasoning right time granularity. UncertaintyArtificial Intelligence.Simma, A., Goldszmidt, M., MacCormick, J., Barham, P., Black, R., Isaacs, R., & Mortier, R.(2008). CT-NOR: Representing reasoning events continuous time. Uncertainty Artificial Intelligence.Soule, A., Salamatian, L., Taft, N., Emilion, R., & Papagiannali, K. (2004). Flow classificationhistogram. ACM SIGMETRICS.Soule, A., Salamatian, K., & Taft, N. (2005). Combining filtering statistical methodsanomaly detection. Internet Measurement Conference, pp. 331344.Tandon, G., & Chan, P. K. (2005). Learning useful system call attributes anomaly detection.Florida Artificial Intelligence Research Society Conference, pp. 405-410.Warrender, C., Forrest, S., & Pearlmutter, B. (1999). Detecting intrusions using system calls: Alternative data models. IEEE Symposium Security Privacy, IEEE Computer Society.Xu, J., & Shelton, C. R. (2008). Continuous time Bayesian networks host level network intrusiondetection. European Conference Machine Learning.Xu, K., Zhang, Z.-L., & Bhattacharyya, S. (2005). Profiling internet backbone traffic: Behaviormodels applications. ACM SIGCOMM.Ye, N., Emran, S. M., Chen, Q., & Vilbert, S. (2002). Multivariate statistical analysis audit trailshost-based intrusion detection. IEEE Transactions Computers, 51(7), 810820.Yeung, D.-Y., & Chow, C. (2002). Parzen-window network intrusion detectors. InternationalConference Pattern Recognition.773fiX U & HELTONYeung, D.-Y., & Ding, Y. (2002). User profiling intrusion detection using dynamic staticbehavioral models. Advances Knowledge Discovery Data Mining, 2336, 494505.Zuev, D., & Moore, A. (2005). Internet traffic classification using Bayesian analysis techniques.ACM SIGMETRICS.774fiJournal Artificial Intelligence Research 39 (2010) 217-268Submitted 12/09; published 09/10Narrative Planning: Balancing Plot CharacterMark O. Riedlriedl@cc.gatech.eduSchool Interactive ComputingGeorgia Institute TechnologyAtlanta, GA 30332 USAR. Michael Youngyoung@csc.ncsu.eduDepartment Computer ScienceNorth Carolina State UniversityRaleigh, NC 27695 USAAbstractNarrative, particular storytelling, important part human experience.Consequently, computational systems reason narrative effective communicators, entertainers, educators, trainers. One central challengescomputational narrative reasoning narrative generation, automated creation meaningful event sequences. many factors logical aesthetic contributesuccess narrative artifact. Central success understandability.argue following two attributes narratives universal: (a) logical causalprogression plot, (b) character believability. Character believability perception audience actions performed characters negatively impactaudiences suspension disbelief. Specifically, characters must perceivedaudience intentional agents. article, explore use refinement searchtechnique solving narrative generation problem find sound believablesequence character actions transforms initial world state world stategoal propositions hold. describe novel refinement search planning algorithmIntent-based Partial Order Causal Link (IPOCL) planner that, addition creatingcausally sound plot progression, reasons character intentionality identifying possible character goals explain actions creating plan structures explaincharacters commit goals. present results empirical evaluationdemonstrates narrative plans generated IPOCL algorithm support audience comprehension character intentions better plans generated conventionalpartial-order planners.1. IntroductionNarrative entertainment, form oral, written, visual storytelling, playscentral role many forms entertainment media, including novels, movies, television,theatre. Narrative also used education training contexts motivateillustrate. One reasons prevalence storytelling human culture may dueway narrative cognitive tool situated understanding (Bruner, 1990;McKoon & Ratcliff, 1992; Gerrig, 1993, 1994; Graesser, Singer, & Trabasso, 1994).evidence suggests we, humans, build cognitive structures representreal events lives using models similar ones used narrative order betterunderstand world around us (Bruner, 1990). narrative intelligence (Blair & Meyer,c2010AI Access Foundation. rights reserved.fiRiedl & Young1997; Mateas & Sengers, 1999) central cognitive processes employ acrossrange experiences, entertainment contexts active learning.Computational systems reason narrative intelligence able interacthuman users natural way understand collaborative contexts emergingnarrative able express storytelling. standard approachincorporating storytelling computer system, however, script story design timestorys script execute without variation run-time. computersystem use scripted story means ability system adapt userspreferences abilities limited. story scripted system may completelyengage users interests may challenging user follow. Furthermore,stories scripted design time, system limited number storiespresent user. entertainment applications, limited number storieslimited number permutations single story results limited opportunities userinteraction (or limited replay value computational system computer game).educational training applications, limited number stories limited numberpermutations single story limits ability system adapt learners needsabilities.alternative approach generate stories either dynamically per-session basis(one story per time system engaged). Narrative generation process involvesselection narrative content (the events presented audience), orderingnarrative content, presentation narrative content discourse. systemgenerate stories capable adapting narrative users preferences abilities,expanded replay value, capable interacting user waysinitially envisioned system designers. many entertainment, educational,training systems incorporate aspects storytelling, systems exist generatenovel narrative content order support particular needs preferences user.ability customize narrative content user primary motivationresearch effort described article.Narrative content must understandable, regardless purpose systemutilizes narrative generator needs system user. many factorslogical aesthetic relate narrative understandability, focus two attributesnarratives consider relatively universal: (a) logical causal progression plot(b) character believability. Logical progression plot refers property narrativecentral events narrative obey rules world narrativeoccurs. Character believability (Bates, 1994) perception audienceactions performed characters negatively impact audiences suspensiondisbelief. Specifically, characters must perceived audience intentional agents(Dennett, 1989). Thus believable narrative sequence one charactersperceived intentional agents.article describe narrative generation system models fictional narrative creation process search-based planning process. resulting artifactplan description temporally ordered sequence actions story world characters perform. plan, executed rendered natural language, tellsstory. Plans found good computational representations narrativesplans encode attributes central narrative: action, temporality, causality218fiNarrative Planning: Balancing Plot Character(Young, 1999). Unfortunately, solving planning problem also solve narrative generation problem planners consider many logical aestheticproperties narratives. Specifically, planners consider character believability.describe novel refinement search planner Intent-based Partial Order Causal Link(IPOCL) planner that, addition creating causally sound plot progression, reasonscharacter intentionality (a) identifying possible character goals explainactions (b) creating plan structures explain characters commitgoals. begin brief background narrative lay theoretical groundworkplanning-based narrative generation (Section 2). Section 3 discusses related work narrative generation. Section 4, lay algorithm, IPOCL, narrative planningdetail illustrate processing examples. Finally, Section 5, describeevaluated system.2. Narrative Planningsection cover relevant background narrative humanitiescognitive psychology. use introduced concepts related narrative buildargument using planning technologies generate narratives off-the-shelfplanners, emphasis goal satisfaction, insufficient.2.1 Narrative BackgroundNarrative storytelling terms widely understood often well defined.One definition given here:Narrative: narrative recounting sequence events continuantsubject constitute whole (Prince, 1987).narrative continuant subject constitute whole, events describednarrative single point relate single communicative goal (Chatman, 1993).One can, however distinguish narratives tell story narratives(Herman, 2002). narrative tells story certain properties one comesexpect. particular, story narrative plot outline main incidentsnarrative structured particular effect audience time.Narratologists break narrative two layers interpretation: fabula sjuzet(Bal, 1998). fabula narrative enumeration events occurstory world time story begins time story ends. eventsfabula temporally sequenced order occur, necessarilyorder told. sjuzet narrative subset fabulapresented via narration audience. narrative written spoken word,narration natural language. narrative cinematic presentation, narrationactions actors camera shots capture action.narrated sjuzet directly exposed audience, fabula narrativecontent narrative, narrative about. article, workprimarily concerned generation fabula. assume sjuzetgenerated fabula distinct process (e.g., Callaway & Lester, 2002; Young, 2006;Jhala, 2009; Bae & Young, 2008; Cheong & Young, 2008).219fiRiedl & Youngmany aspects determine whether story accepted audiencegood. Many aspects subjective nature, degreeaudience empathizes protagonist. aspects appear universalacross wide variety genres. Cognitive psychologists determined abilityaudience comprehend narrative strongly correlated causal structurestory (Trabasso & Sperry, 1985; van den Broek, 1988; Graesser, Lang, & Roberts,1991; Graesser et al., 1994) attribution intentions charactersparticipants events (Graesser et al., 1991; Gerrig, 1993; Graesser et al., 1994). Storycomprehension requires audience (e.g. reader, hearer, viewer) perceive causalconnectedness story events infer intentionality characters. Accordingly,two attributes narrative focus work narrative generation logicalcausal progression character believability.causality events inherent property narratives ensures wholecontinuant subject (Chatman, 1993). Causality refers notion relationship temporally ordered events one event changes story worldparticular way enables future events occur (Trabasso & van den Broek, 1985).story considered successful, must contain degree causal coherenceallows audience follow logical succession events predict possible outcomes.Attesting importance causality story, Trabasso Sperry (1985) found significant correlation recall event story existence part causalchain terminates outcome story.Character believability (Bates, 1994) perception audience actionsperformed characters negatively impact audiences suspension disbelief.Character believability partially dependent idiosyncrasies characters appearance physical movements. Physical appearance important visual mediaanimated film (Thomas & Johnson, 1981). Descriptions character appearancesalso found written spoken presentations. Equally important wayinternal attributes character personality, emotion, desires, intentions manifest decisions character makes behaviors characterperforms (Thomas & Johnson, 1981; Bates, 1994; Loyall, 1997).1 definition character believability places emphasis goal-oriented nature characters. Goal-orientedbehavior primary requirement believability (Loyall, 1997; Charles, Lozano, Mead,Bisquerra, & Cavazza, 2003). Specifically, we, humans, ascribe intentionality agentsminds (Dennett, 1989). implication character perceivedbelievable, one able to, observations character, infer predictmotivations intentions. article, approach narrative generation focusesexplicitly creating narrative sequences characters perceived intentional agents. research efforts directly addressed aspects characterbelievability, including personality (e.g., Carbonell, 1980; Reilly, 1996; Rizzo, Veloso, Miceli,& Cesta, 1999; Sengers, 2000), emotion (e.g., Gratch & Marsella, 2004; Seif El-Nasr, Yen,& Ioerger, 2000), appearance physical performance (e.g., Blumberg & Galyean,1995; Maes, Darrell, Blumberg, & Pentland, 1995; Perlin & Goldberg, 1996; Loyall, 1997;Hayes-Roth, van Gent, & Huber, 1997; Lester, Voerman, Towns, & Callaway, 1999).1. Loyall (1997) enumerates many elements affect character believability autonomous agents.220fiNarrative Planning: Balancing Plot Character2.2 Planning Model Narrative Generationmany parallels plans narrative level fabula. particular,narrative sequence events describes story world changes time.fabula, change instigated intentional actions story world characters, althoughstory world also changed unintentional acts accidents forcesnature. Likewise, plan set ordered operators transforms world onestate another state. operators plan events happen storyworld, plan model fabula. Partially ordered plans allow operationsremain temporally unconstrained relative execution order matter.semantics plan capabilities plan execution engine may determinewhether operations can, fact, executed parallel (Knoblock, 1994). Similarly,events fabula occur simultaneously story world, even though narration(e.g., sjuzet) events necessarily linear.Planners implementations algorithms solve planning problem: givendomain theory, initial state I, goal situation G consisting set propositions,find sound sequence actions maps initial state state G true.domain theory model world change. example, one useSTRIPS (Fikes & Nilsson, 1971) STRIPS-like operators specify operationsperformed world, applicable, world differentafterward. Various algorithms developed solve planning problems includingpartial-order planners, constraint satisfaction planners, heuristic search planners.Since plan used model fabula, planning algorithm also usedmodel dramatic authoring process humans use create narratives. Thus,creation narrative considered problem solving activity one considersfabula narrative sequence story-world events achieves outcomedesired author order effect impact audience.article, present algorithm planning narratives. specifically solvesfabula planning problem.Fabula Planning Problem: Given domain theory, find sound believable sequencecharacter actions transforms initial world state world stategoal propositions G hold.domain theory, initial state, goal situation provided user fabulageneration system, call human author. fabula generation system taskedselecting ordering set actions that, told (as opposed executed),considered narrative.algorithm presented subsequent sections considered one examplealgorithm solves fabula generation problem. planning algorithms general, acknowledge algorithms may exist. next sections, exploreimplications searching believable narrative plans.221fiRiedl & Young2.2.1 Challenges Planning Computational Model NarrativeGenerationAlgorithms solve planning problem find sequences operations sound,meaning that, absence non-determinism, guaranteed find sequenceoperations maps initial state state goal situation holds.generating fabula, assume operations actions performed charactersexist story world. consequence planning problem definitionplanners consider whether natural believable character performaction given time plan; consider actions perspectivecharacter audience, context whether necessary goalsituation achieved. argue limits applicability off-the-shelf plannerstechniques generating stories.illustrate limitation, present simple example. Suppose describe worldthree characters: king, knight, princess. characters live castlecastle tower characters locked up. suppose goal situationprovided human author princess locked towerking dead. Given reasonable domain theory e.g., set possible actions oneplan found planner is:1. princess kills king.2. princess locks tower.plan valid perspective transforms initial state stategoal situation holds. make sense story? reader shortstory left many questions mind. princess kill king?princess lock tower? plans exist might make sense,as:1. king locks princess tower.2. knight kills king.Intuitively, easier reader find explanation makes sense secondstory: princess must upset king knight must avenging princess.Let us consider ways influence planner give us favorable plans.One possibility could modify problem definition. example,change initial state domain theory princesses cannot kill kingscharacters cannot lock tower. modifications make sense? Suppose king attempting harm princess princess would justifiedkilling king. declare princesses never kill kings seems impose unnecessarily strong assumption narratives generated. Likewise, imaginenarratives makes sense lock oneself tower (perhaps escape danger). One advantages automated generation narratives algorithmexplore many possibilities and/or create narratives envisioned humanauthor. argument expanded Riedl Young (2006) contextcreativity part computational system.222fiNarrative Planning: Balancing Plot CharacterAnother possibility provide heuristic function planner favorablyranks plans demonstrate quality character believability. heuristicincrease probability planner find solution believable ranking planscloser solution include actions create appearanceintentionality. example, planner good heuristic could, principal, findfollowing plan:1. princess knight fall love.2. king proposes princess.3. princess refuses kings proposal.4. king locks princess tower.5. knight kills king.Like previous example, plan king lock princess towerknight kill king. inclusion actions 1 3, however, increase likelihoodreader find story believable; princesss refusal explains king locksprincess tower (the kings proposal establishes conditions princesssrefusal), princess knight falling love explains princess refuseskings proposal knight kills king.good heuristic ranks believability, however, increases probabilitycomplete plan found desired properties making cost less exploreportions search space solutions likely exist. still possibleplanner return plan believable situations finds shorter,complete solution finds longer, complete, believable solution. occursplanning problem solved sound sequence actions transformsinitial state one goal situation holds.conclude fabula generation problem sufficiently different planningproblem wish automatically plan actions fabula, benefitnew definitions plan completeness mechanisms selecting actions moveplanner toward complete solutions. consider greater detail meanscharacter appear believable respect intentionality, detect characterbelievability fabula plans, planner select actions directly addresslogical causal progression believability.2.2.2 Intentionality Character BelievabilityCharacter believability partially due character intentionality storylikely considered believable story world characters appear motivatedindividual goals desires. Stories likely found comprehensiblewell-formed relationships character actions recognizable character goals(Graesser et al., 1991, 1994). However, unlike causal properties story, structures plans processes planning algorithms correspond directly characterintentionality except goal propositions planning problem. However, complicated fact stories typically comprise multiple characters cannot223fiRiedl & Youngassumed goals human author, want achieve goalsituation propositions provided human author.goal situation fabula planning thus reinterpreted outcome story.However, propositions outcome necessarily intended story worldcharacters. Indeed, possible none propositions goal situationintended story world characters. also necessarily casestory world characters declared intentions beginning story (ininitial state). is, characters may form intentions reaction conditionsworld response actions characters.Achieving character intentionality fabula planner requires decoupling characters intentions intentions human author declarationinitial state goal situation. Thus, distinguish author goals (Riedl, 2004,2009) character goals. author goal description world authorwould like fabula generator achieve. simplicity, consider single authorgoal encoded outcome, although often advantageous human authorindicate several intermediate situations fabula pass meansproviding additional guidance desires solution (cf., Riedl, 2009).Character goals, hand, goals characters perceived pursueportion overall fabula. Characters goals may different outcomesense characters story desire outcome state seek achieveit. Character goals may also adopted resolved throughout story. example,previous section king appears develop goal punishing princessrefuses marry him. kings goal neither exists beginning storypersists outcome.agent intentions decoupled initial world state goal situation,planner must assume responsibility determining character goals agentsperforming actions plan motivate intentions actions.Failure distinguish author goals character goals results appearancecollusion characters achieve outcome situation makessense (e.g., protagonist antagonist) and/or act inconsistently erratically.2approach incorporating character intentionality narrative planning describedSection 4.illustrate decoupling character intentions, let us inspect example planningproblem Section 2.2.1 detail. goal situation two propositions: (a)princess locked tower, (b) king dead. examplehuman authors intentions particular outcome reached likelyreasonable intentions story world characters. is, princess unlikelyintend locked king unlikely intend dead. Further,clear reason princess knight intend kingdead, although declarations could made human author initializationtime. would reasonable reader see king appear fight back2. Sengers (2000) refers phenomenon agent schizophrenia.224fiNarrative Planning: Balancing Plot Characterknight try avoid death. planning problem adversarial senseuncertainty whether knight prevail.3conclude fabula planner must select actions characters achieveoutcome situation also create appearance story world charactersintentions potentially distinct human authors desires. Since charactersintentions necessarily provided advance human author, reasonable goalscharacters must discovered explain behaviors, fabula structure mustconstructed illustrates formation intentions. reviewing relatedwork, describe one algorithm meets requirements solving fabulageneration problem laid earlier.3. Related WorkNarrative generation systems often classified using one two approaches fictional fabula content creation. Simulation-based narrative generation systems (also referredemergent systems Aylett, 1999, 2000) simulate story world.simulation approach establish set characters world context. narrative generation system progressively determines actions characterstake time situational context evolves. Often simulation-based narrative generation systems employ decentralized, autonomous embodied agents represent story worldcharacters react evolving world state. Deliberative narrative generation systemsgenerate narratives solving problem choosing sequence actionsphysical, mental, dialogue story world characters meet certain constraintsparameters (aesthetic, dramatic, pedagogical). narrative outputprocedure. primary distinction simulation-based approaches deliberativenarrative generation system uses centralized reasoning algorithm often plannerdetermine optimal actions characters. limit discussion related narrativegeneration research systems produce fabula content.simulation-based (emergent) approach narrative generation based assertion best way generate narrative model behaviors decision-makingprocesses story world characters. Tale-Spin (Meehan, 1976) system generatesAesops Fables based moment-to-moment inference characterdo. inference engine based theories common-sense reasoning (Schank & Abelson, 1977). Meehan (1977) notes circumstances character goals wellchosen facts story world support character actions userintends, generated narratives short oddly structured (see Meehan, 1977,examples mis-spun narratives). Carnegie Mellon University Oz project (Bates,1992, 1994; Mateas, 1997; Loyall, 1997) uses autonomous, reactive, embodied agentsrepresent characters virtual world. agents use shallow broad (Bates, Loyall,& Reilly, 1992) decision-making routines cover wide repertoire believable-looking activities. first proposed Laurel (1986) later implemented Bates colleagues(Bates, 1992; Kelso, Weyhrauch, & Bates, 1993; Weyhrauch, 1997), special agent, called3. example agents perceived intentionally strive avoid human authorsdesired outcome. Since goal situation human authors intention, goal situation mustachieved.225fiRiedl & Youngdrama manager may necessary prevent uninteresting poorly structured narratives emerging. drama manager oversees coordinates character agent behaviororder coerce interesting well-structured performances autonomousagents. I-Storytelling system (Cavazza, Charles, & Mead, 2002) likewise reliesautonomous, reactive agents represent story world characters. Unlike Oz project,I-Storytelling system agents use hierarchical task network (HTN) planners achievepre-determined goals. Cavazza et al. note way virtual world configured, including initial position character agents, initial goals characteragents strongly influences outcome story; poor initial configurations may resultuninteresting narratives conflict.Dehn (1981) asserts process computational story generation must processincludes satisfaction intentions human author. Deliberative narrativegeneration systems often consider process narrative creation perspectivesingular author authority resulting narrative structure workingachieve narrative sequence conforms particular given constraints parameters.Universe system (Lebowitz, 1984, 1985, 1987) uses centralized hierarchical plannerproduce open-ended narrative soap-opera episodes achieve narratological intentions human author. human author provides goal situation describesoutcome particular episode Universe systems planner finds sequencecharacter actions achieves goal using hierarchically related task networks describing common activity. general, hierarchical decomposition requires form grammarrules. Story grammars Rumelhart (1975) criticized restrictive (Black & Wilensky, 1979; Wilensky, 1983). Tailor (Smith & Witten, 1991) usesstate-space search plan actions storys protagonist. protagonist givengoal achieve Tailor searches sequence actions protagonist takeachieve goal. antagonist present, Tailor uses adversarial search.recent work deliberative narrative generation systems focused two areas:role knowledge, specialized search algorithms. Minstrel system (Turner,1994) implements model computational creativity based adaptation reuseexisting concepts create new stories. Minstrel system uses specialized routinestransform old stories new stories. Mexica (Perez Perez & Sharples, 2001) implementsmodel creative writing (cf., Sharples, 1999) conceptualizes writing cyclecognitive engagement reflection. model employs combination case-basedreasoning probes database known existing stories elements match currentpatterns emotion tension partial-order planning ensure coherencestory fragments. ProtoPropp system (Gervas, Daz-Agudo, Peinado, & Hervas,2005) uses case-based reasoning approach creating narratives. ProtoPropp encodesexamples Russian folktales Propp (1968) functions based regularitiesfolktales identified Propp ontology new folktales createdretrieving, adapting, reusing parts old folktales. recently Porteous Cavazza(2009) turned planning narrative structures using variation FF (Hoffmann &Nebel, 2001) find sequence events brings goal situation. plannerconsider character goals independent goal situation. Instead generationalgorithm uses landmarks partially ordered sets first-order logic literals mustmade true throughout course solution means guiding planner toward226fiNarrative Planning: Balancing Plot Charactersolution consistent human authors vision. Landmarks author goals (Riedl,2004, 2009).goal research devise narrative generation system generates narratives exhibit causal coherence character intentionality. favor deliberativeapproach narrative generation deliberative approach provides mechanismensuring character actions chosen global structure mind. Contrastsimulation-based approaches choose character actions based temporally localizedinformation. Deliberative systems avoid problems logical causal progressionconsider narrative sequence whole. However, deliberative narrative generation systems designed date conflate character goals human authorgoals without consideration audience reader, viewer, etc. perspective.algorithm, Intent-Driven Partial Order Causal Link (IPOCL) planner,algorithm solves fabula generation problem. IPOCL algorithm basedclass planning algorithms called Partial Order Causal Link (POCL) planners,UCPOP (Penberthy & Weld, 1992; Weld, 1994) well known example. POCL plannersrepresent operators plan STRIPS (Fikes & Nilsson, 1971) STRIPS-like constructsconsisting operator name, precondition conditions must trueworld operator executable effect conditions worldchanged operator finishes execution. precondition effect consistzero first-order logic literals. Operators may parameterized variables that,bound ground symbols, allows single operator schema represent many possibleground operators. POCL planners use following definition partially ordered plan,using term step refer operators instantiated plan structure:Definition 1 (POCL Plan): POCL plan tuple hS, B, O, Liset plan steps, B set binding constraints parameters stepsS, set temporal orderings form s1 < s2 s1 , s2 S, Lset causal links form hs1 , p, q, s2 s1 , s2 p effect s1q precondition s2 p unifies q.Note use term step synonymously action operator. differsusage term literature non-POCL planners SATPLANGraphplan.POCL planners use iterative process identifying flaws plan revisingplan least-commitment manner. flaw reason plan cannot consideredvalid solution. open condition flaw occurs precondition step goalsituation satisfied effects preceding step initial state. POCLplanner solves open condition step goal situation non-deterministicallychoosing existing steps instantiating new steps effects unify goalconditions. causal link (Penberthy & Weld, 1992) connects two plan steps s1 s2 viapcondition p, written s1s2 , s1 establishes condition p story world neededsubsequent step s2 order step s2 execute. Causal links used recordcausal relationships steps record satisfaction open conditions. causalthreat flaw occurs effects one plan step possibly undo effects another planstep. Causal threats resolved explicitly ordering conflicting steps. provide227fiRiedl & YoungPOCL (hS, B, O, Li, F, )first parameter plan. initial call POCL, two steps dummyinitial step whose effect initial state final step. F set flaws. initial call, Fcontains open condition flaw goal literal goal situation. B = L = . set actionschemata. Output complete plan f ail.I. Termination. B inconsistent, fail. Otherwise, F empty, return hS, B, O, Li.II. Plan Refinement.1. Goal selection. Select open condition flaw f = hsneed , pi F . Let F 0 = F {f }.2. Operator selection. Let sadd step adds effect e unified p (tocreate sadd , non-deterministically choose step sold already instantiate action schema). step exists, backtrack. Otherwise, let 0 = {sadd }, O0 = {sadd < sneed },B 0 = B Bnew Bnew bindings (e.g., assignments ground symbols variables)needed make sadd add e, including bindings sadd itself, L0 = L{hsadd , e, p, sneed i}.sadd 6= sold , add new open condition flaws F 0 every precondition sadd .3. Threat resolution. step sthreat threatens causal link hsj , e, p, sk occurssj sk asserts e. every used step sthreat might threaten causal linkhsj , e, p, sk L0 , non-deterministically one following.Promotion. sk possibly precedes sthreat , let O0 = O0 {sk < sthreat }.Demotion. sthreat possibly precedes sj , let O0 = O0 {sthreat < sj }.Separation. Let O0 = O0 {sj < sthreat , sthreat < sk } let B 0 = B 0 set variableconstraints needed ensure sthreat wont assert e.III. Recursive invocation. Call POCL (hS 0 , B 0 , O0 , L0 i, F 0 , ).Figure 1: POCL algorithm.POCL planning algorithm Figure 1 point comparison later discussionfabula planning algorithm.next section, introduce algorithm, Intent-Driven Partial Order CausalLink (IPOCL) planner, creates narratives that, perspective reader,closely resemble results emergent narrative generation system regard character intentionality. Specifically, IPOCL modification existing search-based planningalgorithms support character intentionality independent author intentions. goalgenerate narratives deliberative process characters appearaudience form intentions act achieve intentions simulated.way, IPOCL produce narratives logical causal progression, meaningachieve author-indicated outcomes states, believable characters.4. Intent-Driven Planningdefinition character believability work constrained focus perceivedintentionality character behavior story world. Perceived intentionality refersway characters observed audience goals act achievegoals. context computational storytelling systems, sufficientcharacter act intentionally audience capable inferring characters228fiNarrative Planning: Balancing Plot Characterintentions circumstances surround character story world.audience story collection passive observers. Instead, audience activelyperforms mental problem-solving activities predict charactersstory evolve (Gerrig, 1993). makes sense, therefore, reason characterintentions motivations time generation perspective audience.ensure every character action considered inclusion narrativeappear motivated intentional.Intent-Driven Partial Order Causal Link (IPOCL) planner generates fabulaplans characters act intentionally intentionality observable.IPOCL extends conventional POCL planning include expanded plan representation,definition plan completeness, action selection mechanisms facilitate fabulaplanner search solution authors goal achieved (e.g., outcome)characters appear act intentionally. Conventionally, planners means-endstools solving problems. employing planning system generate fabula,system must produce actions make plot line story, along temporalordering partial total execution times actions. make followingobservations conventional planning problem:Plans generated created single agent (Bratman, Israel,Pollack, 1988) collection cooperating agents (Grosz & Sidner, 1990).4goal situation intended one character agents agentsintend execute plan support achieving goal state.order facilitate active mental processes audience suggested Gerrig,observe solving fabula planning problem requires following:Plans generated created multiple character agents necessarilycooperating also necessarily adversarial.goal situation describes properties world necessarily intendedcharacter agents execute plan.goal situation conventional planning problem partial description worldstate obtained end plans execution. context narrativeplanning, refer goal situation outcome describes worldmust different narrative completed.fabula generation algorithm described remainder section searchesspace plans individual agent goals potentially distinct outcome4. SharedPlans (Grosz & Sidner, 1990) formalism addresses situation one agentcollaborates construct joint plan achieving goal. Grosz Sidners approach addressescases agents intend joint goal achieved one agent goalcontracts part task another agent communicating intentions (Grosz & Kraus, 1996).SharedPlans address coordination many individual plans single joint plan definingagent intentions perform actions agent intentions goals sub-goals achieved constrainbehaviors individual agents working together. formalism, however, addresssituations agents different goals cooperating contracting out.229fiRiedl & YoungACTION ::= ACTION-NAME (VARIABLE )actors: VARIABLEhappening: BOOLEANconstraints: LITERALprecondition: LITERALeffect: LITERALLITERAL := PREDICATE ([VARIABLE | SYMBOL] )Figure 2: Syntax action schemata IPOCL.agents necessarily cooperating. Character agents either givenintentions part specification initial world state developcourse plan. IPOCL planning algorithm accomplishes expandingrepresentation plan structure include information intentionsindividual agents. Algorithmically, IPOCL simultaneously searches space plansspace agent intentions. point process, agent intentions ensuredplausible use special reasoning process tests character intentionalityperspective audience attempts revise plan test fails.4.1 Extensions Planning Problem Definition LanguageIPOCL planning problem given Definition 2.Definition 2 (IPOCL Planning Problem): IPOCL planning problem tuple,hI, A, G, i, initial state, set symbols refer characteragents, G goal situation, set action schemata.significant factor IPOCL planning problem A, set symbols refercharacter agents world. symbols handled specially processes determiningcharacter intentionality. extended traditional planning problem definitionlanguage use character agents two ways:Specification actions need intentional.Specification parameters action refer character agentsintentionally performing action.syntax specifying action schemata IPOCL given Figure 2.POCL planners, use STRIPS-like representation preconditions effects. Additionally, constraints literals must unify initial state actfilter applicable parameter bindings.distinguish two types actions: happenings (Prince, 1987) nonhappenings. Happenings actions occur without intention characteraccidents, involuntary reactions stimuli, forces nature. Non-happeningevents must intended character. clarity, assume that, unless indicated otherwise, actions non-happenings thus require actor action fulfills230fiNarrative Planning: Balancing Plot CharacterAction: slay (?slayer, ?monster, ?place)actors: ?slayerconstraints: knight(?slayer), monster(?monster), place(?place)precondition: at(?slayer, ?place), at(?monster, ?place), alive(?slayer), alive(?monster)effect: alive(?monster)Action: marry (?groom, ?bride, ?place)actors: ?groom, ?brideconstraints: male(?groom), female(?bride), place(?place)precondition: at(?groom, ?place), at(?bride, ?place), loves(?groom, ?bride),loves(?bride, ?groom), alive(?groom), alive(?bride)effect: married(?groom), married(?bride), single(?groom), single(?bride),married-to(?groom, ?bride), married-to(?bride, ?groom)Action: appear-threatening (?monster, ?char, ?place)actors: ?monsterhappening:constraints: monster(?monster), character(?char), place(?place)precondition: at(?monster, ?place), at(?char, ?place), scary(?monster), ?monster6=?chareffect: intends(?char, alive(?monster))Figure 3: Example IPOCL action schemata.intention. actions occur world without intent (for example,falling stairs), marked specifying happening slot true.action non-happening, actors slot specifies parameters refersymbols representing characters acting intentionally enact particularaction. say action performed character agent actorsslot action references a. Figure 3 shows three action schemata involving singleintentional actor, multiple intentional actors, intentional actor, respectively.action schema Slay(?slayer, ?victim, ?place) specifies ?slayer referintentional actor. Note implication slaying cannot performed accidentally.action schema Marry(?groom, ?bride, ?place) specifies two intentional actors,?groom ?bride. Finally, Appear-threatening(?monster, ?char, ?place) indicates?char appear become frightened monster. action needintentional part ?monster ?char.final note action definition use special intends predicate,used effect action. Semantically intends predicate readmeaning reasonable character following goal responseaction. Whether intention acted upon determine whether propositionused, described next section. narrative told, mentionfacts unused. intends predicate occurs action effects; usedaction preconditions creates strong commitment actions used.example, Marry require intends(?groom, married-to(?groom, ?bride)),would preclude stories character wants single (but doesnt necessarilywant married) also stories character marries someone revenge231fiRiedl & Youngthird party (the marriage one action chain leading another goalnone actions effects).4.2 Character Intentionality Fabula Planningstorys audience actively performs problem-solving story progresses orderpredict outcome fate story world characters, generated storysupport cognitive processes. means providing narrative structure givesenough information audience infer intentionality character behavior.fabula planners perspective, character actions intentional (or happenings).is, every character goal, portion actions complete fabula plan describeactions performed character achieve character goal. formalizefollows:Definition 3 (Frame Commitment): frame commitment tuple,hS 0 , P, a, ga , sf i, 0 proper subset plan steps plan P = hS, B, O, Li,symbolic reference character agent character agent actorsteps 0 , ga goal character agent pursing executing steps0 , sf 0 referred final step ga one effectssteps 0 temporally precede sf step ordering plan P .purpose frame commitment record characters internal character goalga actions plan character appear perform storytellingachieve goal. However, perspective audience, enough declarecharacter goal; order make inferences character intentionsplans, audience must observe characters forming committing goals. Therefore,frame commitment associated condition, eg , form intends(a, ga ),indicates character commit internal character goal, muststate reasonable intend ga . condition eg must establishedworld plan step eg effect. is, something world causescharacter commit ga . plan step causes eg consequently causesframe commitment referred motivating step frame commitment.motivating step necessarily temporally precedes plan steps frame commitment.Informally, interval intentionality set actions 0 character performachieve internal character goal, ga .5Character goals partially describe world state character commits achieving.Commitments persist time character remain committed goal eventhough desired world state undone (Bratman, 1987). IPOCL explicitlyrepresent release commitment except say interval intentionalitybounded temporally set steps interval intentionality.5. interval intentionality roughly equates notion Full Individual Plan (FIP) SharedPlans formulation (Grosz & Sidner, 1990). full individual plan portion larger Full SharedPlan (FSP) single agent responsible executing. distinction fabula planFSP full fabula plan made many individual FIPs generated collaboratingplanning agents. Instead, fabula plan constructed whole individual character actionsmake whole plan annotated indicate intention might used achieve.232fiNarrative Planning: Balancing Plot CharacterFrame commitment a1goal ga1intends(a1, ga1)Intention levelDomain levels5 (a2)s3 (a1)s2 (a1)p2ga1s1 (a2)p3s4 (a1)Figure 4: IPOCL plan single frame commitment motivating step.Character goals captured two ways. First, potential character intentionsrecorded world states existence world state propositions formintends(a, ga ). world state propositions record fact characterintention, indicate whether intention acted upon, capturesubsequent actions executed order character act intention.Second, character intentions recorded frame commitment data structures. Framescommitment elaborate intention also identifying actions fabulaplan character perform pursuit intention. Note intervalintentionality contain one step ga effect. necessarycase another action fabula plan undoes ga world condition mustreestablished.IPOCL extends definition POCL plan data structure include framescommitment. definition IPOCL plan follows.Definition 4 (IPOCL Plan): IPOCL plan tuple hS, B, O, L, Ciset plan steps, B set binding constraints free variables stepsS, set ordering constraints steps S, L set causal linkssteps S, C set frames commitment.sets S, B, O, L defined standard way (e.g., Penberthy & Weld, 1992).frames commitment C defined Definition 3. See Figure 4 illustrationIPOCL plan single frame commitment motivating step frame.actor step si indicated parentheses. IPOCL algorithm ensuresstory world characters participate fabula plan appear act believablyrespect intentionality. satisfy requirement, character actions IPOCLplan (except marked needing intentional) must intentional finalsolution plan happenings.Definition 5 (Action Intentionality): action plan P intentional belongsframe commitment P .Unintentional actions part interval intentionality referredorphans. order IPOCL plan considered complete, actions except233fiRiedl & Younghappenings must part least one frame commitment. character actionbelong one interval intentionality. definition plan completenessfollows:Definition 6 (Complete IPOCL Plan): IPOCL plan complete(1) preconditions plan steps established, (2) causal threats6resolved, (3) plan steps happenings intentional.Conditions 1 2 together make conventional definition plan completeness,termed causally complete. fabula plan IPOCL causally completewithout fully complete Definition 6. plan causally completefully complete, plan contains orphans. ways correctorphans, IPOCL backtracks find another possible complete solution plan. Takentogether, Definitions 4 6 directly address high-level problem finding soundbelievable sequence actions transforms initial world state world stategoal situation holds.4.3 Integrating Intentionality Least-Commitment PlanningFrames commitment products process planner tests intentionalitycharacter actions revises plan necessary. IPOCL, refinement search process,uses iterative, least-commitment process identifying flaws plan revisingplan repair flaws. creates tree-like search space leaf nodes eithercomplete plans (under Definition 6) incomplete plans cannot repaired. Internalnodes incomplete plans one flaws.addition open conditions causal threat flaws adopted POCL definethree additional types flaws:Definition 7 (Open Motivation Flaw): open motivation flaw plan Ptuple, hc, pi, c frame commitment P p sentence intends(a,ga ) character c ga internal character goal c.Definition 8 (Intent Flaw): intent flaw plan P tuple hs, cipstep P c frame commitment Psj causal linkplan, part c, sj step P , part c, charactercharacter sj c.Definition 9 (Intentional Threat Flaw): intentional threat flaw plan Ptuple, hck , ci i, frame commitment ck internal character goalnegates internal character goal another frame commitment ci .Open motivation flaws reflect fact characters must appear motivated goals.is, something must cause character commit goal. open motivationflaw means plan frame commitment whose interval intentionalitypreceded motivating step. Intent flaws reflect fact plan step, s,6. causal threat occurs when, due insufficient constraints action ordering partially ordered plan,effects one action potentially undo preconditions another action.234fiNarrative Planning: Balancing Plot Characterperformed character part frame commitment, c, heldcharacter. is, step causally establishes precondition step, sj ,part c. planner must non-deterministically decide whether step partframe commitment. next sections describe algorithms identifying repairingopen motivation flaws intent flaws. facilitate this, IPOCL algorithm, shownFigure 5, broken three parts: causal planning, motivation planning, intentplanning.4.3.1 Causal Planning IPOCLcausal planning portion IPOCL algorithm implements conventional POCLalgorithm addition frame commitment discovery phase. Causal planningoccurs open condition needs resolved. is, step sneedprecondition p satisfied causal link. planner chooses planstep sadd whose effect e unify p. accomplished non-deterministicallychoosing existing plan step instantiating new action.frame commitment discovery process triggered changes plan (e.g.addition causal link plan structure). sadd newly instantiated step,possibility final step (due backward-chaining natureplanning algorithm) previously undiscovered character intention. case,one effects sadd , addition causally satisfying open condition,intended character specified perform sadd . IPOCL non-deterministically choosesone effects sadd (or effect, case sadd final stepyet-to-be-discovered intention). effect chosen, new frame commitmentconstructed record characters commitment achieving effect world.Step sadd made final step frames interval intentionality newopen motivation flaw annotates plan indicate planner must find motivatingstep.Regardless whether sadd newly instantiated existing plan step reused,planner must consider possibility sadd part existing interval intentionality. Steps performed part one intention; Pollack (1992) refersoverloading. IPOCL performs search plan node frames commitmentsadd part of. search routine finds set frames C 00 cj C 00one two following conditions holds:p1. frame commitment cj contains step sj saddsj causal linkplan sadd sj performed character.2. frame commitment cj contains step sj frame ci/ C 00service sj sadd motivating step ci . Frame ci service step sjfinal step ci effect establishes precondition sj , sj partframe ck , ck 6= ci .frame commitment ci C 00 , plan annotated intent flaw hsadd , cj i.resolving flaws, planner determine whether step sadd becomes partexisting frames interval intentionality.235fiRiedl & YoungIPOCL (hS, B, O, L, Ci, F, )first parameter plan, steps S, variable bindings B, ordering constraints O, causal links L,frames commitment C. F set flaws (initially open conditions literal goalsituation). set action schemata. Output complete plan according Definition 6 f ail.I. Termination. B inconsistent, fail. F empty S, c C | part c,return hS, B, O, L, Ci. Otherwise, F empty, fail.II. Plan Refinement. Non-deterministically one following.Causal planning1. Goal selection. Select open condition flaw f = hsneed , pi F . Let F 0 = F {f }.2. Operator selection. Let sadd step adds effect e unifiedp (to create sadd , non-deterministically choose step sold already instantiateaction schema ). step exists, backtrack. Otherwise, let 0 = {sadd },O0 = {sadd < sneed }, B 0 = B Bnew Bnew bindings (e.g., assignmentsground symbols variables) needed make sadd add e, including bindings sadditself, L0 = L {hsadd , e, p, sneed i}. sadd 6= sold , add new open condition flaws F 0every precondition sadd .3. Frame discovery. Let C 0 = C.a. sadd 6= sold , non-deterministically choose effect e sadd e = nil. e 6=nil, construct new frame commitment c internal character goal echaracter sadd , let sadd part c, let C 0 = C {c}, create new open motivationflaw f = hci, let F 0 = F {f }.b. Let C 00 set existing frames commitment used explain sadd .C 00 , create intent flaw f = hsadd , di let F 0 = F {f }.4. Threat resolutionCausal threat resolution. Performed II.3 POCL algorithm (Figure 1)Intentional threat resolution. c1 C 0 c2 C 0 , characterc1 character c2 , e1 goal c1 , e2 goal c2 ,e1 negates e2 , non-deterministically order c1 c2 vice versa s1 c1s2 c2 , O0 = O0 {s1 < s2 } O0 = O0 {s2 < s1 }.5. Recursive invocation. Call IPOCL (hS 0 , B 0 , O0 , L0 , C 0 i, F 0 , ).Motivation planning1. Goal selection. Select open motivation flaw f = hci F . Let p conditionc. Let F 0 = F {f }.2. Operator selection. causal planning above, exceptsi c, O0 = O0 {sadd < si }.3. Frame discovery. causal planning, above.4. Threat resolution. causal planning, above.5. Recursive invocation. Call IPOCL (hS 0 , B 0 , O0 , L0 , C 0 i, F 0 , ).Intent planning1. Goal selection. Select intent flaw f = hs, ci F . Let F 0 = F {f }.2. Frame selection. Let O0 = O. Non-deterministically choose one following.Make part c. Let sm motivating step c. O0 = O0 {sm < s}.ci C ci ordered respect c, si ci , O0 = O0 {si < s}O0 = O0 {s < si }. spred hspred , p, q, si L spredcharacter, create intent flaw f = hspred , ci let F 0 = F 0 {f }.make part c.3. Recursive invocation. Call IPOCL (hS, B, O0 , L, Ci, F 0 , ).Figure 5: IPOCL algorithm.236fiNarrative Planning: Balancing Plot Characterf1: Frame commitment a1 goal ga1f2: Frame commitmenta2 goal ga2intends(a2, ga2)Intention levelDomain levels2 (a1)s4 (a2)p3s3 (a2)ga2s1 (a2)Figure 6: IPOCL plan one character contracted another character.Condition 1 indicates two actions, sj sadd , performedcharacter earlier action, sadd , establishes condition world requiredlater action, sj , reasonable hypothesis partintention. intent flaw earlier action indicates planner must,point, decide whether support hypothesis incorporating actionsinterval intentionality reject hypothesis leaving plan structureunchanged. Condition 2 indicates situation agent requires certain worldstate achieved make intentional actions feasible sub-goal contracted(e.g., Grosz & Kraus, 1996) another agent. occurs motivating actionperformed one character causes another character intentionservice first characters actions, illustrated Figure 6. Character a1 performaction s1 pursuit goal ga1 . Action s1 single precondition satisfiedaction s3 performed character a2 pursuit goal ga2 . Action s2 motivating actioncauses character a2 goal establish precondition step s1 . Sincemotivating step performed character a1 , candidate Condition 2incorporated frame commitment a1 .frame discovery takes place, planner must resolve threats inadvertently introduced refined plan. two types threats: causal threatsintentional threats. standard POCL means detecting correcting causalthreats used (see Section 3). Intentional threats occur newly instantiated framecommitment, ck , internal character goal negates internal character goalframe commitment ci character. Character actionsfabula plan may unordered respect one another allows intervalsintentionality interleaved. possible agent characterhold conflicting desires, rational agent concurrently commit conflictingdesires (Bratman, 1987). case character two frames goals negateother, IPOCL corrects intentional threats non-deterministically constrainingordering ci ck . ordering frames commitment amounts explicitly orderingactions part frame correspond ordering ci ck .complicated cases goals ci ck negateplans causally interfere other, IPOCL relies standard causal threat resolutioneither order action sequences plan leaving frames unordered,237fiRiedl & Youngforce algorithm backtrack. cases identified repaired withoutadditional semantic contextual reasoning.4.3.2 Motivation Planning IPOCLmotivation planning portion IPOCL algorithm responsible ensuringcharacters story world motivated. motivating step plan step oneeffects causes character commit goal. Repairing open motivation flawconsists non-deterministically finding plan step effect intends(a, ga ) eitherchoosing existing plan step instantiating action schema explicitly orderingstep plan steps part frame commitment. Motivationplanning similar causal planning except instead establishing causal linktwo plan steps, establishes motivation link motivating step framecommitment. Additionally, motivating step frame commitment explicitlyordered steps frames interval intentionality. work presentedhere, character agent cannot begin pursuing character goal committedgoal. Motivation planning involves frame discovery threat resolution phasesidentical causal planning.4.3.3 Intent Planning IPOCLintent planning portion IPOCL algorithm determines interval membershipcharacter actions except final steps intervals intentionality.Intent planning repairs intent flaws. intent flaw decision point asks whetherplan step made part interval frame commitment c. Unlikeflaws repaired refining structure plan, intent flaws resolvednon-deterministically choosing one following:Make step part interval c refine plan structure reflectassociation.make step part interval c, remove flaw annotation, leaveplan structure unchanged.7former chosen, step becomes part interval intentionality framec. choice made, interval frame c updated appropriatelyexplicitly ordered motivating step frame c. Furthermore, changesteps membership status effect membership plan steps precedes. Let spred establishing step step precedes causally linkeds. inclusion step interval frame c also makes possible establishingsteps included interval c following conditions hold:Step spred performed character s.7. intent flaw addressed making revisions plan structure, intentflaw strictly flaw conventional sense. However, purpose maintaining consistencyexisting revision mechanisms, find useful treat intent flaw flaw pointrepaired.238fiNarrative Planning: Balancing Plot CharacterStep spred part interval intentionality c.intent flaw, f = hspred , ci already proposed and/or resolved.8Intent flaws created establishing step three conditions hold. Intent planning thus operates spreading activation fashion. one step becomesmember frame commitment, entire sequence establishing steps may follow.approach necessary since frames commitment created timeplan refinement. Intent flaws standard flaws sense mark potentialflaw instead actual flaw. cannot determine time action instantiatedwhether necessary action part interval intentionality. framecommitment belong may discovered yet, may yetdiscovered action part frame commitment due adjacencyrequirements.propagation intent flaws makes possible plan steps become membersone frame commitment, desirable property IPOCL algorithm.Every time character action belonging one frame commitment used satisfyopen condition successor action belongs different frame commitment,system must non-deterministically decide whether establishing action belongsframes commitment remains member original frame. decisioninterval membership also constrains possible ordering motivating steps framescommitment involved motivating steps temporally ordered actionsframe commitment motivating step establishes. step becomesmember one frame commitment, possible placement motivating stepsconstrained Figure 7 motivating step must occur earliest stepframe commitment.One thing yet discussed handle orphans. orphan stepplan belong interval intentionality. Orphans surreptitiouslyrepaired adopted intervals intentionality. happencausally establish conditions necessary other, intentional actions. Orphaned actionscannot repaired directly frames commitment discovered opportunisticallyinstead instantiated least-commitment approach (as plan steps are).orphans remaining surreptitiously repaired time planningprocess completes, planner must backtrack.4.4 ExampleIPOCL algorithm illustrated following story arch-villain bribesPresident United States large sum money. example tracessingle path fabula plan search space generated IPOCL. initial plannode contains initial state step goal situation step. initial state containspropositions describing state world story begins. goal situationcontains single proposition, corrupt(President), describes must different8. inclusion condition ensures systematicity algorithm sinceone causal link spred s. search algorithm systematic guaranteed never duplicateportion search space.239fiRiedl & Youngf1: Frame commitmentIntention levelDomain levels8s5s4: Pickup (a, gun)s3: Load (a, gun)s9s2s1: Shoot (a, deer, gun)s7s2: Rob (a, bank, gun)Domain levelIntention levelf2: Frame commitmentFigure 7: IPOCL plan overlapping intervals intentionality single character.world story complete. story generated IPOCL is,effect, story President becomes corrupt.goal proposition corrupt(President) non-deterministically established instantiating new character action, Bribe(Villain, President, $), statesVillain character bribe President character money. Bribe actionchosen corrupt(President) effect. planners perspective, Bribe action causally motivated open condition goal situation.Upon instantiation Bribe action, frame discovery invoked. effects Bribeaction are:corrupt(President) President corrupt.controls(Villain, President) Villain exerts control President.has(President, $) President money.has(Villain, $) Villain money.audiences perspective, effects reason Villain performs actions story.planner non-deterministically chooses controls(Villain, President) character goal Villain character. Note case goal Villain differsoutcome story although action satisfies conditions.reason planner could chosen corrupt(President) character goalVillain. assumed either plan cannot completed alternative chosen heuristic function evaluated options determinedvillains likely want control President anything else. Givenchoice made, planner constructs frame commitment Villain character240fiNarrative Planning: Balancing Plot CharacterFrame commitment Villain goalcontrols(vil, prez)intends(vil, controls(vil, prez))Intention levelDomain levelinithas(vil, $) Bribe (vil, prez, $)corrupt(prez)goalFigure 8: Example narrative plan discovering one action corresponding framecommitment.makes Bribe action final step frames interval intentionality. Evennew frame commitment, plan still flawed since reason Villaincharacter goal controlling President. is, Villain needs formintention appear believable audience. open motivation flaw indicatesaction plan must satisfy condition intends(Villain, controls(Villain,President)) frame commitment.Since frames commitment Villain, intent flaws occur.Bribe action, however, precondition has(Villain, $) becomes opencondition; Villain character must money bribe Presidentit. planner chooses repair open motivation flaw single frame commitment first non-deterministically chooses initial state satisfy open motivationcondition. illustrates situation intention character story worldencoded part initial conditions. way,domain engineer specified inputs IPOCL decided motivationVillain want control President needed. maysatisfactory solution, valid solution. partial plan point shown Figure8.open condition has(Villain, $) Bribe action considered next. repairflaw, planner non-deterministically instantiates new character action Give(Hero,Villain, $) Hero character gives Villain money. planner mustconsider, audiences, perspective, Hero character gives moneyVillain. planner inspects effects Give action:has(Villain, $) Villain money.has(Hero, $) Hero money.planner non-deterministically chooses has(Villain, $) goal Heroattempting achieve. new frame commitment Heros goal created. NoteHeros intention matches open condition Give action instantiatedsatisfy. indicates Heros commitment service Bribe action.open motivation flaw created corresponds new frame commitment.many actions establish Heros intention Villainmoney: Villain might persuade Hero friends, Villain might coerce241fiRiedl & YoungFrame commitment Villain goalcontrols(vil, prez)intends(vil, controls(vil, prez))Frame commitment Herogoal has(vil, $)has(vil, $)Intention levelDomain levelinithas(hero, $)Give (hero, vil, $)has(vil, $)Bribe (vil, prez, $)corrupt(prez)Coerce (vil, hero, (has vil $))goalFigure 9: Solution IPOCL plan graph example narrative.Hero. latter, Coerce(Villain, Hero, has(Villain, $)), chosen planner: Villain character coerces Hero character goal has(Villain,$).point, planner must determine Villain coerces Hero.several possibilities. First, frame discovery comes play determine Villainintends effects Coerce action. Assume effect Coerce actionintends(Hero, has(Villain, $)). planner select effect constructnew frame commitment specifying Villain intends Hero intendsVillain money. Another option leave Coerce action orphantime being. Let us suppose course planner chooses. searchcurrent plan structure indicates Coerce action part Villains existingcommitment control President. possible Coerce motivating stepHeros frame commitment Heros frame commitment serviceBribe action, part Villains frame commitment. intent flaw associatingCoerce action Villains existing frame commitment created. Eventually,spreading activation intent planning associate Coerce Villains framecommitment. plan structure point shown Figure 9. remaining flawshandled conventional causal planning.4.5 Complexity IPOCL Algorithmcomputational complexity IPOCL algorithm O(c(b(e + 1)a )n ),n depth search space,b number ways action instantiated (e.g., numberpermutations legal parameter bindings),e number effects instantiated action,number actors instantiated action.242fiNarrative Planning: Balancing Plot Characterworst-case branching factor IPOCL search space b(e + 1)a . factor,(e + 1) signifies new frame commitment constructed, planner mustchoose e effects action (plus one signify condition effectchosen). exponent reflects fact multiple characters intentionallyparticipating action, characters distinct intentionsperforming action. example, action Marry(?groom, ?bride, ?place) sixeffects (see Appendix action schema) two intentional actors (?groom?bride).depth IPOCL search space n number open condition flaws, openmotivation flaws, intent flaws, causal threats, intentional threats repaired.worst-case, every newly instantiated step plan IPOCL also creates newframe commitment corresponding open motivation flaw. nPOCL depthsolution search space POCL planning problem nIPOCL depthcorresponding solution search space IPOCL fabula planning problem,nIPOCL bounded function nIPOCL = 2nPOCL .narrative generated evaluation purposes (see Section 5). narrative, rendered natural language, given Figure 13 plan data structure presentedgraphically Appendix (Figure 15). complete fabula plan exists depthn = 82. average branching factor domain 6.56, worst branchingfactor given node 98. node 98 children first flawplanner solves for: married(Jafar, Jasmine), solved instantiating actionMarry(Jafar, Jasmine, ?place). operator schema six effects. two characters intentional actors meaning two frames commitmentgenerated. Finally, parameter ?place bound two ways. Note implementation IPOCL uses constraint propositions generate child node legalpermutation parameter bindings. provide domain-specific heuristic evaluation function favors plan structures certain preferred character goals (for example,Jafar intends Jasmine dead included), complete plan generatedapproximately 12.3 hours (approximately 11.6 hours spent garbage collection)Intel Core2 Duo 3GHz system 3GB RAM 100GB virtual memoryRrunning Allegro CL8.0. conditions, IPOCL generates 1,857,373 nodesvisits 673,079 nodes. algorithm run domain-independent heuristicadopted classical planning (e.g., number flaws plus plan length), problem cannotsolved system runs virtual memory. Appendix gives detailsdomain, fabula planning problem, heuristic used.Practical experience IPOCL algorithm suggests better heuristic evaluationfunctions needed guide search process. Without sufficient heuristic functions,behavior IPOCL devolves nearly breadth-first. Practical experience algorithmalso suggests difficult write heuristic functions practically distinguishsibling nodes. problem defining heuristic functions distinguishsibling nodes plan search space arises POCL algorithms, exacerbatedIPOCL due increased number structural features need distinguished.243fiRiedl & Young4.6 Limitations Future Workalgorithm solves fabula generation problem, IPOCL demonstratedgenerate sound narrative structures support believability enforcementcharacter intentions. IPOCL able achieve effectively decoupling conceptcharacter intentions author intentions. Consequently, intentionality character actions must opportunistically discovered time actions discovered.opportunistic discovery character intentions action instantiation significantlyincreases branching factor detriment ability generate long narratives.However, feel opportunistic discovery intentions vital part expandingspace narratives searched include logical causal progressionalso well-motivated thus believable characters. alternative usegrammar (cf., Rumelhart, 1975), hierarchical task networks (cf., Sacerdoti, 1977),form hierarchical decomposition (cf., Young, Pollack, & Moore, 1994) intentions dealt one level abstraction specific character actions dealtprimitive level. However, using grammars, HTNs, decompositional techniquesgenerate narrative requires reasoning higher levels abstraction actionintroduces potentially rigid top-down structuring plot limit systems abilityfind solutions might exist cannot described grammar/task-network.additional limitations need addressed. First, IPOCLalgorithm asserts non-happening character actions must part framecommitment, therefore motivated event (or initial state), IPOCL also assumesframe commitments interval intentionality terminates actionsuccessfully achieves goal frame commitment. Essentially, every character actsaccording intention every intention achieved. inherently limits typesnarratives generated. example, narratives character triesachieve goal fails several times finally succeeding unlikely. Narrativesone character hero defeats another villain cannot generated. Although,possible generate narrative villain first achieves goalhero achieves goal (thus defeating villain).inability consider actions support intentions never achieved appears inherent limitation partial-order planning approach. particular,backward-chaining nature algorithm biases approach toward explaining actions. ensure soundness, causal threats eliminated backtracking occurs.possible forward-chaining approach could resolve issue, expensepromiscuous intention generation. One way force algorithm consider narrativestructures one character defeats another character fails several timessucceeding seed plan space intermediate author goals indicating setsstates solutions must pass (Riedl, 2009). approach, however,presupposes human author knows, wants, predict resultantnarrative structure.mentioned Section 4.3.1, IPOCL currently weak mechanisms detectprevent contradictory intentions character. Better heuristics may help controlsituations resolved ordering actions ordering frames244fiNarrative Planning: Balancing Plot Charactercommitment. possible extend algorithm include common-sense reasoningsemantic analysis frame commitment level. However, work done.general, better heuristics needed. Heuristics divided domain-dependentdomain-independent heuristics. Domain-dependent heuristics, case, referemploy knowledge characters, setting, preferences narrative structure. example, generate example Figure 13, use heuristicpenalizes narratives contain character goals thought unreasonable basedintuitions characters types stories sought. Domain-independentheuristics difficult identify might include preferences fewer framescommitment longer action sequences. Domain-independent heuristics rewardnarrative structures dramatic arc likely require complex models narrative psychology described Gerrig colleagues (Gerrig, 1993; Gerrig & Bernardo,1994) implemented Fitzgerald, Kahlon, Riedl (2009) may workintermediate, incomplete narratives.5. Evaluation Character Intentionality IPOCL-GeneratedFabula Plansorder perform empirical evaluation readers perception character intentionality IPOCL-generated fabulas, designed objective evaluation procedure basedquestion-answering order reveal readers understanding character intentions without use subjective questionnaires (Riedl & Young, 2005). goal evaluationdetermine IPOCL-generated fabulas supported cognitive processes readers apply comprehend character actions better fabulas generated conventionalplanning algorithms. evaluation procedure outlined follows. Two planning-basedalgorithms used generate plans interpreted fabulas: IPOCL algorithmconventional POCL planning algorithm. planner provided identical initialization parameters. first plan generated algorithm selected presentedstudy participants. plans must read, simple natural language generationprocess used produce natural language text fabula plan. Recallpurpose fabula plan executed plan execution system, containtemporal event information told story. Participants recruited randomlyassigned one two groups. Participants POCL group read POCL-generatednarrative text. Participants IPOCL group read IPOCL-generated narrative text.variation question-answering protocol work Graesser et al. (1991)used elicit participants mental models narratives. particular, focusedquestions elicit understanding story world character goals motivations.evaluate question-answering performance across groups? QUEST (Graesseret al., 1991) takes graphical representation story reliably predicts questionanswering performance human might also read story. One implicitassumptions behind QUEST provided well-structured storycontained within storys narrative structure answers question one mightask character goals motivations. exploit assumption means measuring well story actually supports human readers reasoning character goalsmotivations. is, story support human comprehension, see245fiRiedl & YoungCzar three lovely daughters. One day three daughterswent walking woods. enjoying much forgottime stayed long. dragon kidnapped three daughters.dragged off, cried help. Three heroes heard cries setrescue daughters. heroes came fought dragon rescuedmaidens. heroes returned daughters palace. Czarheard rescue, rewarded heroes.Figure 10: example story work Graesser et al. (1991).manifested human question-answering performance. QUEST knowledge structurestranslated fabula plans vice versa (Christian & Young, 2004). QUESTknowledge structures automatically generated fabula plans, run QUEST predictquestion-answering performance compare QUEST predictions actual performance.expect see IPOCL-generated narratives understandable alternative; find greater correspondence QUEST actual performanceIPOCL condition find POCL condition.5.1 QUEST Model Question-AnsweringQUEST model (Graesser et al., 1991) accounts goodness-of-answer (GOA)judgments questions asked passages prose. One application QUESTmodel show people build cognitive representations stories read capturecertain relationships events story perceived goals charactersstory (Graesser et al., 1991). QUEST knowledge structures represented visuallydirected graphs nodes referring either story events (typically character actions)character goals. Directed links capture relationship story event nodesterms causality relationship events character goals termsintentionality. readers cognitive representation story queried readeranswers questions story. types questions supported QUEST modelare: why, how, when, enablement, consequence. example, story Figure 10(Graesser et al., 1991, Fig. 1) corresponding QUEST knowledge structure shownFigure 11 (Graesser et al., 1991, Fig. 2). two types nodes QUESTknowledge structure: event nodes, correspond occurrences story world,goal nodes, correspond goals characters have. links nodescapture different types relationships events character goals.Consequence (C): terminal event node consequence initiating eventnode.Reason (R): initiating goal node reason terminal goal node.Initiate (I): initiating event node initiates terminal goal node.Outcome (O): terminal event node outcome initiating goal node.Implies (Im): initiating event node implies terminal event node.246fiNarrative Planning: Balancing Plot CharacterImGOAL 10Daughters gethelpCRGOAL 12Daughters cryEVENT 11Daughters gothelpEVENT 14Heroes heardcriesGOAL 15Heroes rescuedaughtersRCEVENT 13DaughterscriedGOAL 17Heroes fightdragonRGOAL 19Heroes godaughtersdragonEVENT 16HeroesrescueddaughtersCCEVENT 18Heroesfought dragonCEVENT 20Heroes camedaughtersdragonFigure 11: example QUEST model Czar Daughters storyGraesser et al. (1991).QUEST model defines arc search procedures type question (e.g. why, how,when, enablement, consequence). arc search procedures, starting queriednode, distinguish legal answer nodes illegal answer nodes. is, nodesreachable arc search procedures legal answer nodes. legality answersweight structural distance correspond GOA judgments human story readers.5.2 Procedureprocedure involves comparing subject question-answering performance QUESTquestion-answering predictions two conditions. POCL condition based narrative structures generated conventional POCL planning algorithm. IPOCL condition based narrative structures generated IPOCL algorithm. plannersinitialized identical information defining story world. story worldbased loosely story Aladdin. initial parameters included following:initial state defines story world, including (a) locations, (b) objects, (c)characters, (d) relevant initial relationships above. Storyworld characters include Aladdin, King Jafar, Princess Jasmine, dragon, genie.library operators defining events performed story worldcharacters.outcome: Jasmine Jafar married genie dead.Note even though initialization parameters identical conditions,differences respective planners handle parameters. particular,IPOCL makes use additional information action schemata actors whetheraction happening. POCL planner ignored information,impact ability find valid solution. initialization information used IPOCLignored POCL planner follows. First, operators must specify247fiRiedl & Youngparameters intentional actors (and characters acted upon). Second,operators tagged happenings. Finally, operators effects formintends(a, p) variable bound ground symbol representingcharacter, p variable bound literal becomes onecharacters internal goals. Effects form used IPOCL implementationmotivation planning ensure actions cause frames commitment.Since operators preconditions form, POCL planner utilizeinformation. Appendix lists entire set initialization parameters usedevaluation.fabula plans generated two planning algorithms shown Appendix.plans human-readable, plan input Longbow discourse planner (Young et al., 1994). Longbow results plan consisting communicative actsdescribe-character describe-event conveying temporally ordered information narrative. discourse plan steps rendered natural languageusing simple template-matching procedure. resulting narrative texts POCLcondition IPOCL condition shown Figures 12 13, respectively. Similaritiestwo narratives make comparison study possible. Specifically, set eventsIPOCL-generated narrative superset events POCL-generated narrative. one distinct action ordering difference two fabula plans:IPOCL condition event King falls love Jasmine temporally constrained occur first, POCL condition ordering eventunder-constrained falls late text. POCL condition, event comeearlier, participants may inferred relationship king falling loveAladdins actions even though actual relationship generated QUESTgraph. believe ordering insignificant impact results.fabula plans also converted structures QUEST use predictquestion-answering performance. use procedure described Christian Young(2004). algorithm generating QUEST graph structures planevaluated POCL plans involving single character.9 IPOCL plans, however, containadditional structures frames commitment motivation links partconventional plan representations. Consequently, algorithm generating QUESTgraph structure plan extended take consideration IPOCL plans.additional study authors (not reported) determined QUEST knowledge structures derived IPOCL plans extended algorithm significantly predict questionanswering judgments structural distance ignored (p < 0.0005). modificationsChristian Youngs (2004) algorithm beyond scope paper, detailsfound work Riedl (2004).evaluation involved questionnaire participants read story makegoodness-of-answer (GOA) judgments pairs question answers. questionanswer pair question intentional action performed characterstory possible answer. example, question, Aladdin slay9. Christian Young (2004) compare DPOCL plans QUEST knowledge structures. DPOCLdecompositional, partial order causal link planning algorithm (Young et al., 1994) extendsconventional POCL algorithm explicitly representing hierarchical relationships abstractprimitive planning operators.248fiNarrative Planning: Balancing Plot Characterwoman named Jasmine. king named Jafar. storyKing Jafar becomes married Jasmine. magic genie.also story genie dies.magic lamp. dragon. dragon magic lamp.genie confined within magic lamp. brave knight named Aladdin.Aladdin travels castle mountains. Aladdin slays dragon.dragon dead. Aladdin takes magic lamp dead body dragon.Aladdin travels mountains castle. Aladdin hands magic lampKing Jafar. genie magic lamp. King Jafar rubs magic lampsummons genie it. genie confined within magic lamp.genie casts spell Jasmine making fall love King Jafar. Jasminemadly love King Jafar. Aladdin slays genie. King Jafar married.Jasmine beautiful. King Jafar sees Jasmine instantly falls love her.King Jafar Jasmine wed extravagant ceremony.genie dead. King Jafar Jasmine married. end.Figure 12: Text story control condition.woman named Jasmine. king named Jafar. storyKing Jafar becomes married Jasmine. magic genie.also story genie dies.magic lamp. dragon. dragon magic lamp.genie confined within magic lamp.King Jafar married. Jasmine beautiful. King Jafar sees Jasmineinstantly falls love her. King Jafar wants marry Jasmine. braveknight named Aladdin. Aladdin loyal death King Jafar. King Jafar ordersAladdin get magic lamp him. Aladdin wants King Jafar magiclamp. Aladdin travels castle mountains. Aladdin slays dragon.dragon dead. Aladdin takes magic lamp dead body dragon.Aladdin travels mountains castle. Aladdin hands magic lampKing Jafar. genie magic lamp. King Jafar rubs magic lampsummons genie it. genie confined within magic lamp. KingJafar controls genie magic lamp. King Jafar uses magic lampcommand genie make Jasmine love him. genie wants Jasmine loveKing Jafar. genie casts spell Jasmine making fall love KingJafar. Jasmine madly love King Jafar. Jasmine wants marry King Jafar.genie frightening appearance. genie appears threatening Aladdin.Aladdin wants genie die. Aladdin slays genie. King Jafar Jasmine wedextravagant ceremony.genie dead. King Jafar Jasmine married. end.Figure 13: Text story experimental condition.dragon? might paired answer, King Jafar ordered Aladdin getmagic lamp him. participants asked rate goodness answergiven question four-point scale ranging bad answer goodanswer. participants shown examples question-answer pairs ratingtask began, otherwise given definition good poor trained makejudgment. Participants rated GOA question-answer pair every combination249fiRiedl & Younggoal nodes QUEST knowledge structure story. POCL conditionquestionnaire 52 question-answer pairs IPOCL condition questionnaire82 question-answer pairs due increased story plan length. Participants askedread story text completely least proceeding ratings taskallowed refer back original text time rating task.narrative, QUEST used predict whether question-answer pairs wouldconsidered good poor based arc search procedure following forwardreason arcs, backward initiate arcs, backward outcome arcs (Graesser et al., 1991).hypotheses experiment follows.Hypothesis 1 Participants IPOCL condition higher mean GOA judgment ratings question-answer pairs identified QUEST goodparticipants POCL condition.Hypothesis 2 Participants IPOCL condition lower mean GOA judgment ratings question-answer pairs identified QUEST poorparticipants POCL condition.actual question-answering performance participants results statistically higherGOA ratings question-answer pairs judged QUEST good, greatercorrespondence QUEST predictions actual performance. Likewise, actualquestion-answering performance participants results statistically lower GOA ratingsquestion-answer pairs judged QUEST poor, greater correspondence QUEST predictions actual performance. Poor correspondenceQUEST predictions actual question-answering performance indication narrative lacks structure supports human understanding character goals, intentions,motivations.Thirty-two undergraduate students Computer Science program North CarolinaState University participated study. participants enrolled course GameDesign Development compensated time five extra credit pointsfinal grade course.5.3 Results Discussionquestion-answer pair questionnaire assigned good rating poorrating based QUEST prediction. Good question-answer pairs assigned value4 poor question-answer pairs assigned value 1. Human GOA ratingsquestion-answer pairs also assigned values 1 4 1 correspondingpoor answer 4 corresponding good answer. results participantsanswers questionnaire answers compiled Table 1. numbers meanGOA ratings category condition. numbers parentheses standard deviations results. Mean human question-answering performanceagreement QUEST mean GOA ratings question-answer pairs categorizedgood closer 4 mean GOA ratings question-answer pairs categorizedpoor closer 1.standard one-tailed t-test used compare mean GOA rating goodquestion-answer pairs IPOCL condition mean GOA rating good question250fiNarrative Planning: Balancing Plot CharacterConditionIPOCLPOCLMean GOA rating goodquestion-answer pairs(standard deviation)3.1976 (0.1741)2.9912 (0.4587)Mean GOA rating poorquestion-answer pairs(standard deviation)1.1898 (0.1406)1.2969 (0.1802)Table 1: Results evaluation study.answer pairs POCL condition. result t-test 15 degrees freedomyields = 1.6827 (p < 0.0585). result strongly suggestive Hypothesis 1supported.standard one-tailed t-test used compare mean GOA rating poorquestion-answer pairs IPOCL condition mean GOA rating poor questionanswer pairs POCL condition. result t-test 15 degrees freedomyields = 1.8743 (p < 0.05). Participants IPOCL condition significantly lowerGOA ratings poor question-answer pairs participants POCL condition.Hypothesis 2 supported.interesting note standard deviation results POCL conditiongood question-answer pairs high. analysis reveals human participantslikely judge question-answer pair good lack evidencepossibility character action might intentional. speculatereader/viewers simultaneously consider multiple hypotheses explaining character behaviordisproved. Regardless content communicative act, onealways able provide less plausible explanation meaning (Sadock,1990).couple limitations note. control narrative length.possible effects measured result narrative length instead improved narrative structure generated IPOCL. believe unlikely, futureevaluations add filler sentences POCL condition narrative impact character intentionality control narrative matches length IPOCLcondition. According narrative comprehension theories Graesser et al. (1994)Trabasso colleagues (Trabasso & Sperry, 1985; Trabasso & van den Broek, 1985),filler sentences included readers mental model meaningful waycausally related concepts mental modelnarrative. Consequently, felt safe leave filler sentences out. Anotherlimitation model discourse used Longbow discourse planner simplistic. Specifically, explicit statements character intentions incorporatednarrative text experimental condition due overly promiscuous discoursemodel used Longbow discourse planner. believe results wouldexplicit statements excluded human readers goodinferring intentions stories (Graesser et al., 1991, 1994). However, completewould control artifacts discourse generation.conclude strong evidence narrative experimental condition supported reader comprehension character goals, intentions, motivations betternarrative control condition. Since generated identical initial251fiRiedl & Youngization parameters, significant independent variable generation algorithm.infer improvement IPOCL condition POCL condition dueenhancements automated story generation capability introduced IPOCLalgorithm.6. Conclusionsobjective research presented develop approach generationnarrative fabula properties supporting audience perception characterintentionality causal plot progression. informal analysis related work suggestsnarrative generation systems categorized using simulation-based deliberative approaches. Simulation-based approaches tend produce narratives reasonablecharacter believability unlikely produce narrative globally coherent plots.due fact simulation-based approaches model characters attemptoptimize character decisions given moment. Thus simulation-based approachesprone local maxima. Deliberative approaches reviewed article directly consider character intentions otherwise likely produce narratives causallycoherent plot progressions. due fact deliberative narrative generationsystems tend reason entire plot instead separately characters.informal analysis, see evidence deliberative system cannot reliably produce narrative structures character believability (especially character intentionality).use refinement search approach construct entire fabula perspectiveauthor. approach consequently deliberative one. favor refinement searchpartial-order plans appear good representation fabula narrative.analysis, algorithms solve planning problem sufficient generating narratives character intentionality planning algorithms conventionallydesigned provide singular agent ability achieve singular goal. Storieslikely involve multiple agents characters necessarilycooperating achieve singular goal state. Accordingly, developed deliberative fabula generation algorithm reasons understandability charactersperspective hypothetical audience. IPOCL fabula generation algorithm treatspotential solution flawed unless audience capable understanding individual(and potentially conflicting) goals character motivated charactersadopt goals throughout progression narrative. IPOCL contains routines repairing character intentionality flaws non-deterministically attributing goalscharacters generating event sequences motivate goals.adopting approach narrative generation IPOCL algorithm, realizeseveral limitations. First, IPOCL incapable producing narrative structurescharacter fails achieve goals. Character failure sort natural partstories especially important comedy tragedy (Charles et al., 2003).Unfortunately, planners produce plans fail e.g. cannot execute completionplanner prune branch search space backtrack. Conflictarise characters characters adopt contradictory goals. However,character succeed achieving goal, although happen seriallyconflicting frames commitment temporally ordered. Second, work date,252fiNarrative Planning: Balancing Plot Characterassumed fabula sjuzet reasoned distinctly. is,fabula generated indicating narrative about, separate process reasonnarrative told. may suffice simple telling generatednarratives. Intuitively, order achieve sophisticated effects audiencesuspense, one might consider narrative told generatordetermining told.believe work reported represents step towards achieving greater capability computer systems generate fictional narratives communication, entertainment, education, training. incremental step, building established artificialintelligence technologies planning cognitive science principles. Non-subjective empirical evidence suggests achieved improvement narrative generationalternative, conventional planners. Furthermore, believe created frameworkcontinue make incremental improvements narrative generation capabilities. example, able incorporate ability handle folk psychologicalmodels character personality (Riedl & Young, 2006). system generate storiescapable adapting narrative users preferences abilities, expanded replayvalue, capable interacting user ways initially envisionedsystem designers. Narrative generation one example instilling computational systems ability reason narrative result systemcapable communicating, entertaining, educating, training.253fiRiedl & YoungAppendix A.appendix contains details Aladdin planning domain used evaluation,including planning problem specification, heuristics, complete diagrams plans generated accompanying QUEST diagrams, partial trace generatedcreation Aladdin narrative.A.1 Planning Problem Specification StudyPOCL planning algorithm used evaluation study implementationIPOCL algorithm use PDDL-like formulations. problem describes initial world stategoal situation. operator library contains operator schemata. evaluationstudy, POCL planning algorithm IPOCL algorithm given inputs.Note however parts inputs used POCL algorithm.following propositions define initial state:character(aladdin)male(aladdin)knight(aladdin)at(aladdin, castle)alive(aladdin)single(aladdin)loyal-to(aladdin, jafar)character(jafar)male(jafar)king(jafar)at(jafar, castle)alive(jafar)single(jafar)character(jasmine)female(jasmine)at(jasmine, castle)alive(jasmine)single(jasmine)beautiful(jasmine)character(dragon)monster(dragon)dragon(dragon)at(dragon, mountain)alive(dragon)scary(dragon)character(genie)monster(genie)genie(genie)in(genie, lamp)confined(genie)alive(genie)scary(genie)place(castle)place(mountain)thing(lamp)magic-lamp(lamp)has(dragon, lamp)following propositions define outcome situation:married-to(jafar, jasmine)alive(genie)following action schemata provided operator library evaluation study. Note deviations conventional PDDL. Constraints indicate immutablepropositions must always true. Constraints function like preconditions exceptsatisfied initial state operators negate propositionused constraint operator schema. actors slot lists parametersrefer actors intend operation; assume first parameter always intentional actor. Further, one actor listed,operator joint operation, meaning operator accomplishedmany actors working team actors intend one effects operator.happening true, operator allowed remain orphan. operatorseffects form intends(?x, ?c) indicating effect one charactersbound ?x intention achieve literal bound ?c. operatorspreconditions form; intention propositions exclusively used IPOCLalgorithm implementation.254fiNarrative Planning: Balancing Plot CharacterAction: travel (?traveller, ?from, ?dest)actors: ?travellerconstraints: character(?traveller), place(?from), place(?dest)precondition: at(?traveller, ?from), alive(?traveller), ?from6=?desteffect: at(?traveller, ?from), at(?traveller, ?dest)Action: slay (?slayer, ?monster, ?place)actors: ?slayerconstraints: knight(?slayer), monster(?monster), place(?place)precondition: at(?slayer, ?place), at(?monster, ?place), alive(?slayer), alive(?monster)effect: alive(?monster)Action: pillage (?pillager, ?body, ?thing, ?place)actors: ?pillagerconstraints: character(?pillager), character(?body), thing(?thing), place(?place)precondition: at(?pillager, ?place), at(?body, ?place), has(?body, ?thing),alive(?body), alive(?pillager), ?pillager6=?bodyeffect: has(?body, ?thing), has(?pillager, ?thing)Action: give (?giver, ?givee, ?thing, ?place)actors: ?giverconstraints: character(?giver), character(?givee), thing(?thing), place(?place)precondition: at(?giver, ?place), at(?givee, ?place), has(?giver, ?thing),alive(?giver), alive(?givee), ?giver6=?giveeeffect: has(?giver, ?thing), has(?givee, ?thing)Action: summon (?char, ?genie, ?lamp, ?place)actors: ?charconstraints: character(?char), genie(?genie), magic-lamp(?lamp), place(?place)precondition: at(?char, ?place), has(?char, ?lamp), in(?genie, ?lamp),alive(?char), alive(?genie), ?char6=?genieeffect: at(?genie, ?place), in(?genie, ?lamp), confined(?genie), controls(?char, ?genie, ?lamp)Action: love-spell (?genie, ?target, ?lover)actors: ?genieconstraints: genie(?genie), character(?target), character(?lover)precondition: confined(?genie), loves(?target, ?lover), alive(?genie), alive(?target), alive(?lover),?genie6=?target, ?genie6=?lover, ?target6=?lovereffect: loves(?target, ?lover), intends(?target, married-to(?target, ?lover))Action: marry (?groom, ?bride, ?place)actors: ?groom, ?brideconstraints: male(?groom), female(?bride), place(?place)precondition: at(?groom, ?place), at(?bride, ?place), loves(?groom, ?bride), loves(?bride, ?groom),alive(?groom), alive(?bride)effect: married(?groom), married(?bride), single(?groom), single(?bride),married-to(?groom, ?bride), married-to(?bride, ?groom)255fiRiedl & YoungAction: fall-in-love (?male, ?female, ?place)actors: ?malehappening:constraints: male(?male), female(?female), place(?place)precondition: at(?male, ?place), at(?female, ?place), single(?male), alive(?male), alive(?female),loves(?male, ?female), loves(?female, ?male), beautiful(?female)effect: loves(?male, ?female), intends(?male, married-to(?male, ?female))Action: order (?king, ?knight, ?place, ?objective)actors: ?kingconstraints: king(?king), knight(?knight), place(?place)precondition: at(?king, ?place), at(?knight, ?place), alive(?king), alive(?knight),loyal-to(?knight, ?king)effect: intends(?knight, ?objective)Action: command (?char, ?genie, ?lamp, ?objective)actors: ?charconstraints: character(?char), genie(?genie), magic-lamp(?lamp)precondition: has(?char, ?lamp), controls(?char, ?genie, ?lamp), alive(?char), alive(?genie),?char6=?genieeffect: intends(?genie, ?objective)Action: appear-threatening (?monster, ?char, ?place)actors: ?monsterhappening:constraints: monster(?monster), character(?char), place(?place)precondition: at(?monster, ?place), at(?char, ?place), scary(?monster), ?monster6=?chareffect: intends(?char, alive(?monster))mentioned Section 4.5, required domain-dependent domain-independentheuristics generate example fabula shown Figure 13 (the plan structure diagramshown Figure 15). IPOCL, heuristics evaluate plan node return integersolutions evaluated 0 higher number farther plan nodesolution. used two heuristic functions whose return values addedtogether.Domain-independent heuristic1 action1 flaw10 frame commitment one frame per character1000 orphans performed characters framescommitmentDomain-dependent heuristic5000 repeat actions5000 frames commitment character-goal combinationsfollowing lists:256fiNarrative Planning: Balancing Plot CharacterAladdin intends has(king, lamp), alive(genie), alive(dragon), has(hero,lamp), married-to(hero, jasmine)Jafar intends married-to(jafar, jasmine)Jasmine intends married-to(jasmine, jafar), married-to(jasmine,jafar)Genie intends loves(jasmine, jafar), loves(jafar, jasmine), loves(aladdin,jasmine), loves(jasmine, jafar)1000 action marry associated two frames commitmentA.2 Plan Diagrams QUEST Structures Studysubsequent figures show plan diagrams corresponding QUEST structuresfabula generated evaluation.Figure 14: fabula plan automatically generated POCL planning algorithmPOCL condition evaluation study.Figure 15: fabula plan automatically generated IPOCL algorithm implementation IPOCL condition evaluation study.Figure 16: QUEST structure corresponding fabula plan POCLcondition evaluation study.Figure 17: QUEST structure corresponding fabula plan IPOCLcondition evaluation study.Figures 14 15, solid boxes represent actions plan structure (where lastaction goal step). Solid arrows represent causal links associated texteffect preceding action precondition successive action. Dashed arrowstemporal constraints found planning algorithm, indicating necessary temporallyordering two actions added due promotion demotion strategies resolvingcausal threats. Figure 15, ovals frames commitment horizontal dashed linesrepresent membership actions frames commitment.257fiRiedl & YoungKey:A: AladdinJ: JasmineK: King JafarD: DragonG: GenieTravel (A, castle, mount)at(A, mount)Slay (A, D, mount)at(A, mount)at(A, mount)alive(D)Pillage (A, D, lamp, mount)Travel (A, mount, castle)at(A, castle)Give (A, K, lamp, castle)has(K, lamp)at(A, castle)Summon (K, G, lamp, castle)confined(G)Fall-In-Love (K, J, castle)loves(J, K)at(G, castle)Love-Spell (G, K, J)love(J, K)Slay (A, G, castle)Marry (K, J, castle)married(K, J)alive(G)Goal: married(K, J), alive(G)Figure 14: Fabula plan representation story used POCL conditionevaluation study.258fiNarrative Planning: Balancing Plot CharacterFall-In-Love (K, J, castle)intends(K, married(K, J))Order (K, A, castle, (has K lamp))intends(K, married(K, J))at(A, mount)at(A, mount)Slay (A, D, mount)at(A, mount)alive(D)Pillage (A, D, lamp, mount)at(A, castle)loves(J, K)Give (A, K, lamp, castle)has(K, lamp)at(A, castle)at(A, castle)Summon (K, G, lamp, castle)controls(K, G)confined(G)Command (K, G, castle, (loves J K))at(G, castle)at(G, castle)Appear-Threat (G, A, castle)intends(G, loves(J, K))Genie intendsloves(J, K)intends(A, alive(G))Love-Spell (G, K, J)loves(J, K)Slay (A, G, castle)Jasmine intendsmarried(J, K)intends(J, married(J, K))Marry (K, J, castle)alive(G)Aladdin intendsalive(G)King intends married(K, J)Travel (A, mount, castle)Aladdin intends has(K, lamp)Travel (A, castle, mount)married(K, J)Goal: married(K, J), alive(G)Figure 15: Fabula plan representation story used experimental IPOCLevaluation study.259fiRiedl & YoungCGOAL 9Aladdin givelamp KingRRGOAL 7AladdintravelcastleGOAL 5Aladdinpillage lampDragonRRGOAL 3Aladdin slayDragonRGOAL 1AladdintravelmountainEVENT 10Aladdin gavelamp KingCEVENT 8AladdintraveledcastleCEVENT 4Aladdin slewDragonCEVENT 2AladdintraveledmountainGOAL 13Genie castlove-spellEVENT 12KingsummonedGenieCEVENT 14Genie castlove-spellCCEVENT 6Aladdinpillaged lampDragonCGOAL 11KingsummonGenieGOAL 15Aladdin slayGenieEVENT 16Aladdin slewGenieCEVENT 17King fellloveJasmineGOAL 18King marryJasmineCCEVENT 20KingJasminemarriedGOAL 19Jasminemarry KingFigure 16: QUEST knowledge structure story plan POCL condition.260fiNarrative Planning: Balancing Plot CharacterEVENT 1King fellloveJasmineCGOAL 12Aladdin givelamp KingRRGOAL 10AladdintravelcastleGOAL 8Aladdinpillage lampDragonRRGOAL 6Aladdin slayDragonRGOAL 4AladdintravelmountainEVENT 13Aladdin gavelamp KingCEVENT 11AladdintraveledcastleGOAL 23King marryJasmineCCEVENT 5AladdintraveledmountainGOAL 24Jasminemarry KingCGOAL 19Genie castlove-spellCREVENT 9Aladdinpillaged lampDragonEVENT 7Aladdin slewDragonEVENT 25KingJasminemarriedCEVENT 20Genie castlove-spellCCGOAL 17KingcommandGenie castRGOAL 14KingsummonGenieRGOAL 2King orderAladdinget lampCEVENT 18KingcommandedGenie castCEVENT 15KingsummonedGenieEVENT 16GenieappearedfrighteningCCEVENT 3King orderedAladdinget lampCGOAL 21Aladdin slayGenieCEVENT 22Aladdin slewGenieFigure 17: QUEST knowledge structure story plan IPOCL condition.261fiRiedl & YoungA.3 Tracefollowing portion trace generated IPOCL initialized fabulaplanning problem specification heuristic. trace focuses generationnodes plan space contribute final solution (shown graphicallyFigure 15).plan0reason: initial planworking on: open condition married-to(jafar, jasmine) step goalchildren: 98 (visited 2; selecting 9)plan 9reason: created new step 1: marry(jafar, jasmine, castle) solve married-to(jafar, jasmine)working on: open motivation intends(jafar, married-to(jafar, jasmine)) frame 2children: 9 (visited 2; selecting 105)plan 105reason: created new step 2: fall-in-love(jafar, jasmine, castle) solveintends(jafar, married-to(jafar, jasmine))working on: open motivation intends(jasmine, married-to(jasmine, jafar)) frame 1children: 3 (visited 1; selecting 122)plan 122reason: created new step 3: love-spell(genie, jasmine, jafar) solveintends(jasmine, married-to(jasmine, jafar))working on: open motivation intends(genie, loves(jasmine, jafar)) frame 3children: 8 (visited 2; selecting 141)plan 141reason: created new step 4: command(jafar, genie, lamp, loves(jasmine, jafar)) solveintends(genie, loves(jasmine, jafar))working on: open condition alive(genie) step 4children: 1 (visited 1; selecting 197)...plan 591reason: created new step 6: give(aladdin, jafar, lamp, castle) solve has(jafar, lamp)working on: open motivation intends(aladdin, has(jafar, lamp)) frame 4children: 4 (visited 2; selecting 4675)plan 4675reason: created new step 7: order(jafar, aladdin, castle, has(jafar, lamp)) solveintends(aladdin, has(jafar, lamp))working on: open condition loyal-to(aladdin, jafar) step 7children: 1 (visited 1; selecting 21578)...plan 21597reason: created new step 8: pillage(aladdin, dragon, lamp, mountain) solve has(aladdin, lamp)working on: open condition alive(aladdin) step 8children: 1 (visited 1; selecting 21653)262fiNarrative Planning: Balancing Plot Character...plan 1398116reason: created new step 12: slay(aladdin, genie, castle) solve alive(genie)working on: causal threat alive(genie) 0 3, clobbered step 12children: 1 (visited 1; selecting 1398282)...plan 1398289reason: created new step 13: appear-threatening(genie, aladdin, mountain) solveintends(aladdin, alive(genie))working on: open condition scary(genie) step 13children: 1 (visited 1; selecting 1398304)...plan 1398364reason: adoption step 4 frame 2: jafar intends married-to(jafar, jasmine)working on: intent flaw aladdin, possibly link step 8 frame 4: aladdin intendshas(jafar, lamp)children: 2 (visited 2; selecting 1398368)plan 1398368reason: adoption step 8 frame 4: aladdin intends has(jafar, lamp)working on: intent flaw aladdin, possibly link step 10 frame 4: aladdin intendshas(jafar, lamp)children: 2 (visited 2; selecting: 1398376)...plan 1398384reason: adoption step 2 frame 2: jafar intends married-to(jafar, jasmine)working on: intent flaw jasmine, possibly link step 12 frame 1: jasmine intendsmarried-to(jasmine, jafar)children: 2 (visited 2; selecting 1398400)...plan 1398576reason: adoption step 7 frame 2: jafar intends married-to(jafar, jasmine)working on: intent flaw aladdin, possibly link step 9 frame 4: aladdin intendshas(jafar, lamp)children: 2 (visited 1; selecting 1398640)plan 1398640reason: adoption step 9 frame 4: aladdin intends has(jafar, lamp)solution found263fiRiedl & YoungReferencesAylett, R. (1999). Narrative virtual environments towards emergent narrative.Mateas, M., & Sengers, P. (Eds.), Narrative Intelligence: Papers AAAI FallSymposium (Technical Report FS-99-01), pp. 8386. AAAI Press, Menlo Park.Aylett, R. (2000). Emergent narrative, social immersion storification. Proceedings1st International Workshop Narrative Interactive Learning Environments.Bae, B.-C., & Young, R. M. (2008). use flashback foreshadowing surprise arousalnarrative using plan-based approach. Proceedings 1st InternationalConference Interactive Digital Storytelling, pp. 156167.Bal, M. (1998). Narratology: Introduction Theory Narrative. UniversityToronto Press.Bates, J. (1992). Virtual reality, art, entertainment. Presence: Journal Teleoperators Virtual Environments, 1 (1), 133138.Bates, J. (1994). role emotion believable agents. Communications ACM,37 (7), 122125.Bates, J., Loyall, A., & Reilly, W. (1992). Integrating reactivity, goals, emotionbroad agent. Proceedings 14th Annual Conference Cognitive ScienceSociety, pp. 696706.Black, J. B., & Wilensky, R. (1979). evaluation story grammars. Cognitive Science,3, 213230.Blair, D., & Meyer, T. (1997). Tools interactive virtual cinema. Trappl, R., &Petta, P. (Eds.), Creating Personalities Synthetic Actors: Towards AutonomousPersonality Agents, pp. 8391. Springer.Blumberg, B., & Galyean, T. (1995). Multi-level direction autonomous creaturesreal-time virtual environments. Proceedings 22nd Annual ConferenceComputer Graphics, pp. 4754.Bratman, M. (1987). Intentions, Plans, Practical Reason. Harvard University Press,Cambridge, MA.Bruner, J. (1990). Acts Meaning. Harvard University Press, Cambridge.Callaway, C., & Lester, J. (2002). Narrative prose generation. Artificial Intelligence, 139 (2),213252.Carbonell, J. (1980). Towards process model human personality traits. ArtificialIntelligence, 15, 4974.Cavazza, M., Charles, F., & Mead, S. (2002). Planning characters behaviour interactivestorytelling. Journal Visualization Computer Animation, 13, 121131.Charles, F., Lozano, M., Mead, S., Bisquerra, A., & Cavazza, M. (2003). Planning formalisms authoring interactive storytelling. Proceedings 1st International Conference Technologies Interactive Digital Storytelling Entertainment.264fiNarrative Planning: Balancing Plot CharacterChatman, S. (1993). Reading Narrative Fiction. Macmillan Publishing Company, NewYork.Cheong, Y.-G., & Young, R. M. (2008). Narrative generation suspense: Modelingevaluation. Proceedings 1st International Conference Interactive DigitalStorytelling, pp. 144155.Christian, D., & Young, R. (2004). Comparing cognitive computational modelsnarrative structure. Proceedings 19th National Conference Artificial Intelligence, pp. 385390.Dehn, N. (1981). Story generation TALE-SPIN. Proceedings 7th InternationalJoint Conference Artificial Intelligence, pp. 1618.Dennett, D. (1989). Intentional Stance. MIT Press, Cambridge, MA.Fikes, R., & Nilsson, N. (1971). STRIPS: new approach application theoremproving problem solving. Artificial Intelligence, 2, 189208.Fitzgerald, A., Kahlon, G., & Riedl, M. O. (2009). computational model emotionalresponse stories. Proceedings 2nd Joint International ConferenceInteractive Digital Storytelling, pp. 312315.Gerrig, R. (1994). Narrative thought?. Personality Social Psychology Bulletin, 20 (6),712715.Gerrig, R. J. (1993). Experiencing Narrative Worlds: Psychological ActivitiesReading. Yale University Press, New Haven.Gerrig, R. J., & Bernardo, A. (1994). Readers problem-solvers experiencesuspense. Poetics, 22, 459472.Gervas, P., Daz-Agudo, B., Peinado, F., & Hervas, R. (2005). Story plot generation basedCBR. Journal Knowledge-Based Systems, 18 (45), 235242.Graesser, A., Lang, K. L., & Roberts, R. M. (1991). Question answering contextstories. Journal Experimental Psychology: General, 120 (3), 254277.Graesser, A., Singer, M., & Trabasso, T. (1994). Constructing inferences narrativetext comprehension. Psychological Review, 101 (3), 371395.Gratch, J., & Marsella, S. (2004). domain-independent framework modeling emotion.Journal Cognitive Systems Research, 5 (4), 269306.Grosz, B., & Sidner, C. (1990). Plans discourse. Cohen, P., Morgan, J., & Pollack,M. (Eds.), Intentions Communication, pp. 417444. MIT Press.Grosz, B., & Kraus, S. (1996). Collaborative plans complex group action. ArtificialIntelligence, 86 (2), 269357.Hayes-Roth, B., van Gent, R., & Huber, D. (1997). Acting character. Trappl, R.,& Petta, P. (Eds.), Creating Personalities Synthetic Characters: Towards Autonomous Personality Agents, pp. 92112. Springer.Herman, D. (2002). Story Logic: Problems Possibilities Narrative. UniversityNebraska Press, Lincoln, NE.265fiRiedl & YoungHoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generationheuristic search. Journal Artificial Intelligence Research, 14, 253302.Jhala, A. H. (2009). Cinematic Discourse Generation. Ph.D. thesis, North Carolina StateUniversity.Kelso, M., Weyhrauch, P., & Bates, J. (1993). Dramatic presence. Presence: JournalTeleoperators Virtual Environments, 2 (1), 115.Knoblock, C. (1994). Generating parallel execution plans partial-order planner.Proceedings 2nd International Conference Artificial Intelligence Planning Systems, pp. 98103.Laurel, B. (1986). Toward Design Computer-Based Interactive Fantasy System.Ph.D. thesis, Ohio State University.Lebowitz, M. (1984). Creating characters story-telling universe. Poetics, 13, 171194.Lebowitz, M. (1985). Story-telling planning learning. Poetics, 14, 483502.Lebowitz, M. (1987). Planning stories. Proceedings 9th Annual ConferenceCognitive Science Society, pp. 234242.Lester, J., Voerman, J., Towns, S., & Callaway, C. (1999). Deictic believability: Coordinating gesture, locomotion, speech lifelike pedagogical agents. Applied ArtificialIntelligence, 13 (4-5), 383414.Loyall, A. B. (1997). Believable Agents: Building Interactive Personalities. Ph.D. thesis,School Computer Science, Carnegie Mellon University.Maes, P., Darrell, T., Blumberg, B., & Pentland, A. (1995). ALIVE system: Fullbody interaction autonomous agents. Proceedings 1995 ConferenceComputer Animation.Mateas, M. (1997). Oz-centric review interactive drama believable agents. Technical report CMU-CS-97-156, School Computer Science, Carnegie Mellon University.Mateas, M., & Sengers, P. (1999). Narrative intelligence. Mateas, M., & Sengers, P.(Eds.), Narrative Intelligence: Papers 1999 Fall Symposium (Technical ReportFS-99-01), pp. 110. AAAI Press, Menlo Park, CA.McKoon, G., & Ratcliff, R. (1992). Inference reading. Psychological Review, 99,440466.Meehan, J. R. (1976). Metanovel: Writing Stories Computers. Ph.D. thesis, YaleUniversity.Meehan, J. R. (1977). TALE-SPIN: interactive program writes stories. Proceedings 5th International Joint Conference Artificial Intelligence, pp. 9198.Penberthy, J. S., & Weld, D. S. (1992). UCPOP: sound, complete, partial-order plannerADL. Proceedings 3rd International Conference Knowledge RepresentationReasoning, pp. 103114.Perez Perez, R., & Sharples, M. (2001). MEXICA: computer model cognitiveaccount creative writing. Journal Experimental Theoretical Artificial Intelligence, 13, 119139.266fiNarrative Planning: Balancing Plot CharacterPerlin, K., & Goldberg, A. (1996). Improv: system scripting interactive actorsvirtual worlds. Proceedings 23rd International Conference ComputerGraphics Interactive Techniques, pp. 205216.Pollack, M. (1992). uses plans. Artificial Intelligence, 57 (1), 4368.Porteous, J., & Cavazza, M. (2009). Controlling narrative generation planning trajectories: role constraints. Proceedings 2nd International ConferenceInteractive Digital Storytelling, pp. 234245.Prince, G. (1987). Dictionary Narratology. University Nebraska Press, Lincoln.Propp, V. (1968). Morphology Folktale. University Texas Press, Austin, TX.Reilly, W. (1996). Believable Social Emotional Agents. Ph.D. thesis, School ComputerScience, Carnegie Mellon University.Riedl, M. O. (2004). Narrative Generation: Balancing Plot Character. Ph.D. thesis,North Carolina State University.Riedl, M. O. (2009). Incorporating authorial intent generative narrative systems.Louchart, S., Roberts, D., & Mehta, M. (Eds.), Intelligent Narrative Technologies II:Papers 2009 Spring Symposium (Technical Report SS-09-06), pp. 9194, PaloAlto, CA. AAAI Press.Riedl, M. O., & Young, R. M. (2005). objective character believability evaluation procedure multi-agent story generation systems. Proceedings 5th InternationalConference Intelligent Virtual Agents (IVA), pp. 278291.Riedl, M. O., & Young, R. M. (2006). Story planning exploratory creativity: Techniquesexpanding narrative search space. New Generation Computing, 24 (3), 303323.Rizzo, P., Veloso, M., Miceli, M., & Cesta, A. (1999). Goal-based personalities socialbehaviors believable agents. Applied Artificial Intelligence, 13, 239272.Rumelhart, D. (1975). Notes schema stories. Bobrow, D., & Collins, A. (Eds.),Representation Understanding: Studies Cognitive Science, pp. 185210. Academic Press, New York.Sacerdoti, E. (1977). Structure Plans Behavior. Elsevier, New York.Sadock, J. (1990). Comments Vanderveken Cohen Levesque. Cohen, P.,Morgan, J., & Pollack, M. (Eds.), Intentions Communication, pp. 257270. MITPress, Cambridge, MA.Schank, R., & Abelson, R. (1977). Scripts, Plans, Goals, Understanding: InquiryHuman Knowledge Structures. Lawrence Erlbaum Associates.Seif El-Nasr, M., Yen, J., & Ioerger, T. (2000). FLAME fuzzy logic adaptive modelemotions. Autonomous Agents Multi-Agent Systems, 3, 219257.Sengers, P. (2000). Schizophrenia narrative artificial agents. Proceedings1st International Workshop Narrative Interactive Learning Environments.Sharples, M. (1999). Write: Writing Creative Design. Routledge, London.Smith, T., & Witten, I. (1991). planning mechanism generating story texts. LiteraryLinguistic Computation, 6 (2), 119126.267fiRiedl & YoungThomas, F., & Johnson, O. (1981). Disney Animation: Illusion Life. AbbevillePress, New York.Trabasso, T., & Sperry, L. (1985). Causal relatedness importance story events.Journal Memory Language, 24, 595611.Trabasso, T., & van den Broek, P. (1985). Causal thinking representationnarrative events. Journal Memory Language, 24, 612630.Turner, S. R. (1994). Creative Process: Computer Model Storytelling. LawrenceErlbaum Associates, Hillsdale, NJ.van den Broek, P. (1988). effects causal relations hierarchical positionimportance story statements. Journal Memory Language, 27, 122.Weld, D. (1994). introduction least commitment planning. AI Magazine, 15, 2761.Weyhrauch, P. (1997). Guiding Interactive Fiction. Ph.D. thesis, Carnegie Mellon University.Wilensky, R. (1983). Story grammars versus story points. Behavioral Brain Sciences, 6, 579623.Young, R. M. (1999). Notes use plan structures creation interactive plot.Mateas, M., & Sengers, P. (Eds.), Narrative Intelligence: Papers AAAIFall Symposium (Technical Report FS-99-01), pp. 164167. AAAI Press, Menlo Park.Young, R. (2006). Story discourse: bipartite model narrative generation virtualworlds. Interaction Studies, 8 (2), 177208.Young, R., Pollack, M., & Moore, J. (1994). Decomposition causality partial-orderplanning. Proceedings Second International Conference Artificial Intelligence Planning Systems, pp. 188193.268fiJournal Artificial Intelligence Research 39 (2010) 483-532Submitted 04/10; published 10/10Kalman Temporal DifferencesMatthieu GeistOlivier Pietquinmatthieu.geist@supelec.frolivier.pietquin@supelec.frIMS research groupSupelecMetz, FranceAbstractreinforcement learning suffers lack scalability, online value (and Q-)function approximation received increasing interest last decade. contribution introduces novel approximation scheme, namely Kalman Temporal Differences(KTD) framework, exhibits following features: sample-efficiency, non-linear approximation, non-stationarity handling uncertainty management. first KTD-basedalgorithm provided deterministic Markov Decision Processes (MDP) producesbiased estimates case stochastic transitions. eXtended KTD framework(XKTD), solving stochastic MDP, described. Convergence analyzed special casesdeterministic stochastic transitions. Related algorithms experimentedclassical benchmarks. compare favorably state art exhibitingannounced features.1. IntroductionOptimal control stochastic dynamic systems trend research long history.machine learning response recurrent problem Reinforcement Learning (RL)paradigm (Bertsekas & Tsitsiklis, 1996; Sutton & Barto, 1998; Sigaud & Buffet, 2010).general paragon, artificial agent learns optimal control policy interactionsdynamic system (also considered environment). interaction,agent receives immediate scalar reward information optimal policy searchesone maximizes cumulative reward long run.Traditionally dynamic system controlled modeled Markov DecisionProcess (MDP). MDP tuple {S, A, P, R, }, state space,action space, P : s, p(.|s, a) P(S) family transition probabilities,R : R bounded reward function, discount factor (weighting longterm rewards). According definitions, system stochastically steps statestate conditionally actions agent performed. transition (si , ai , si+1 )associated immediate reward ri . policy : mapping states actionsdrives action selection process agent. optimal policy onemaximizes cumulative reward long term.cumulative reward locally estimated agent so-called value (respectivelyQ-) function associating expected cumulative reward state (respectively stateaction pair). optimal policy therefore one maximizes functionsstate state-action pair. Many RL algorithms aim estimating one functionsinfer optimal policy. challenging cases, search optimal policyc2010AI Access Foundation. rights reserved.fiGeist & Pietquindone online, controlling system. requires trial error processdilemma immediate exploitation currently learnt policy explorationimprove policy occurs.context, fair RL algorithm address important features:allowing online learning;handling large even continuous state spaces;sample-efficient (learning good control policy interactions possible);dealing non-stationarity (even system stationary, controllinglearning optimal policy induces non-stationarities; good reasons prefertracking convergence given Sutton, Koop, & Silver, 2007);managing uncertainty (which useful information handling dilemmaexploration exploitation);handling non-linearities (to deal max operator Bellman optimalityequation compact function representations neural networks).aspects rarely addressed time state-of-the-art RL algorithms.show proposed Kalman Temporal Differences (KTD) framework (Geist, Pietquin,& Fricout, 2009a) addresses issues. based Kalman filtering paradigmuses approximation scheme, namely Unscented Transform (UT) JulierUhlmann (2004), approximate value function. Originally Kalman (1960) filtering paradigm aims tracking hidden state (modeled random variable)non-stationary dynamic system indirect observations state. idea underlying KTD cast value function approximation filtering problem, benefitintrinsic advantages Kalman filtering: online second order learning, uncertaintyestimation non-stationarity handling. UT used deal non-linearitiesderivative-free fashion, notably allows deriving second-order value iteration-likealgorithm (namely KTD-Q).1.1 Formalismvalue function V given policy associates state expected discountedcumulative reward starting state following :XV (s) = E[ri |s0 = s, ](1)i=0ri reward observed time i. Q-function adds degree freedomchoice first action:XQ (s, a) = E[ri |s0 = s, a0 = a, ]i=0484(2)fiKalman Temporal DifferencesReinforcement learning aims finding (through interactions) policy maximisesvalue function every state:= argmax(V )(3)Despite partial order (value functions vectors), maximum exists (Puterman,1994). Two schemes (among others) lead solution. First, policy iteration implieslearning value function given policy, improving policy, new onegreedy respectively learnt value function. requires solving Bellman evaluationequation (given value function Q-function):V (s) = Es0 |s,(s) R(s, (s), s0 ) + V (s0 ) ,Q (s, a) = Es0 |s,a R(s, a, s0 ) + Q (s0 , (s0 )) , s,(4)(5)expectations depend transition probability conditioned current state-actionpair, action given policy case value function evaluation. secondscheme, called value iteration, aims directly finding optimal policy. requires solvingBellman optimality equation (given Q-function):00Q (s, a) = Es0 |s,a R(s, a, ) + max Q (s , b) , s,bA(6)parametric representation either value Q-function supposedavailable (possible representations discussed hereafter) Temporal Differences (TD)algorithms considered. TD algorithms form class online methods consistcorrecting representation value (or Q-) function according so-called TDerror made it. Although formal definition TD error depends algorithm(see Section 1.2), intuitively defined difference predicted rewardaccording current estimate value Q-function actual observed rewardtime step i. TD algorithms generically written as:= i1 + Ki(7)expression, i1 latest estimate value function (or set parametersdefining it), updated representation given observed transition, TD error,Ki gain indicating direction representation target functioncorrected.state space action space finite small enough, exactdescription value function possible, vector many componentsstate (-action) space (tabular representation). case large state and/or actionspaces, approximation necessary. classical choice RL linear parameterization,value function approximated by:V (s) =pXwj j (s) = (s)Tj=1485(8)fiGeist & Pietquin(j )1jp set basis functions, defined beforehand,weights wj parameters:= w1 . . .wp(s) = 1 (s) . . .p (s)(9)Many function approximation algorithms require representation ensure convergence (Tsitsiklis & Roy, 1997; Schoknecht, 2002), even applicable (Bradtke &Barto, 1996; Boyan, 1999; Geramifard, Bowling, & Sutton, 2006). representationspossible neural networks set synaptic weights (usually resultingnonlinear dependency value function parameters).Adopting generic point view, problem addressed paper statedas: given representation value function (or Q-function) summarizedparameter vector given Bellman equation solved, best gain K?state-of-the-art answers question given following section.1.2 State Artpaper focuses online methods. Standard RL algorithms TD evaluation,SARSA Q-Learning (Sutton & Barto, 1998) share features unified viewbased Equation (7) adopted following. equation, term TDerror. Suppose step transition (si , ai , ri , si+1 , ai+1 ) observed. TD-like RLalgorithms, algorithms aiming evaluating value function given policy ,TD error is:(10)= ri + Vi1 (si+1 ) Vi1 (si )SARSA-like algorithms, algorithms aim evaluating Q-functiongiven policy , TD error is:= ri + Qi1 (si+1 , ai+1 ) Qi1 (si , ai )(11)Finally, Q-learning-like algorithms, algorithms aim computing optimal Q-function Q , TD error is:= ri + max Qi1 (si+1 , b) Qi1 (si , ai )bA(12)type temporal difference determines Bellman equation solved (evaluationequation (10-11), optimality equation (12)), thus algorithm belongspolicy iteration value iteration family.gain Ki specific algorithm. common reviewed here. TD,SARSA Q-learning (for example, see Sutton & Barto, 1998), gain writtenKi = ei(13)classical learning rate stochastic approximation theory satisfy:X=i=0Xi=0486i2 <(14)fiKalman Temporal Differencesei unitary vector zero everywhere except component correspondingstate si (or state-action (si , ai )) equal one (Kronecker function).algorithms modified consider so-called eligibility traces (again, see SuttonBarto), gain writtenKi =Xij ej(15)j=1eligibility factor. Informally, approach keeps memory trajectoriesorder propagate updates previously visited states.algorithms also extended take account approximate representation value function (Sutton & Barto, 1998), called direct algorithms (Baird,1995). Without eligibility traces, gain writtenKi = i1 Vi1 (si )(16)i1 Vi1 (si ) gradient following parameter vector parameterizedvalue function current state. gain corresponds stochastic gradient descentaccording cost function kV V k2 . V (si ) known directly observable,replaced ri + V (si+1 ). general approach known bootstrapping (Sutton& Barto, 1998). value function replaced straightforwardly Q-functiongain. direct algorithms also extended take account eligibilitytraces, leads following gain:Ki =Xij i1 Vi1 (sj )(17)j=1Another well known approach set residual algorithms (Baird, 1995),gain obtained minimization L2 -norm Bellman residual (i.e.,difference left side right side Bellman equation, possiblysampled transitions) using stochastic gradient descent:(18)Ki = i1 Vi1 (si ) Vi1 (si+1 )next reviewed approach (recursive form the) Least-Squares Temporal Differences (LSTD) algorithm Bradtke Barto (1996), defined linearparameterization (8) gain defined recursively:Ci1 (si )1 + ((si ) (si+1 ))T Ci1 (si )Ci1 (si )((si ) (si+1 ))T Ci1Ci = Ci11 + ((si ) (si+1 ))T Ci1 (si )Ki =(19)(20)(s) defined (9) matrix C0 must initialized. LSTD also seeksminimize L2 -norm Bellman residual, however using least-squares approachrather gradient descent using instrumental variable concept (Soderstrom487fiGeist & Pietquin& Stoica, 2002) cope stochasticity transitions1 . algorithm alsoextended eligibility traces (for details, see Boyan, 1999).last reviewed approach, certainly closest contribution,Gaussian Process Temporal Differences (GPTD) algorithm Engel (2005). linear parameterization V (s) = (s)T assumed2 following statistical generative model(obtained Bellman evaluation equation) considered:1 0 . . .r1n10 1 0 (s1 )......(21). + .. = .. . ......ri(si )ni0 ...01assuming noise nj white (and therefore centered), Gaussian variance j ,prior parameters follows normal distribution, posterior distribution(|r1 , . . . , ri ) analytically computed. Moreover, using Sherman-Morrisonformula, recursive algorithm satisfying Widrow-Hoff update rule (7) obtained(assuming prior P0 ):Ki =i2Pi = Pi1Pi1 ((si ) (si+1 ))+ ((si ) (si+1 ))T Pi1 ((si ) (si+1 ))(22)Pi1 ((si ) (si+1 ))((si ) (si+1 ))T Pi1i2 + ((si ) (si+1 ))T Pi1 ((si ) (si+1 ))(23)Alternatively, GPTD (with parametric representation) seen linear leastsquares solution L2 Bellman residual minimization.classical value function approximation algorithms presented,however many exist. Nevertheless, knowledge none presentsfeatures argued desirable. assumes linearity, leastensure convergence (Tsitsiklis & Roy, 1997; Schoknecht, 2002) sometime evenapplicable (Bradtke & Barto, 1996; Boyan, 1999; Geramifard et al., 2006).algorithms assume linearity, residual ones (Baird, 1995), howeveroften practical (eg., value iteration-like residual algorithm proposed Baird,method requires computing gradient max operator). methodssample efficient others. Generally speaking, second order approaches tendefficient first order one, LSTD usually recognized sample efficientapproach. Algorithms use learning rate partially cope non-stationarity,using adaptive learning rate example. However LSTD approach known1. point view historical. Since then, shown LSTD actually minimizes distancevalue function projection onto hypothesis space image Bellmanoperator (Lagoudakis & Parr, 2003).2. Actually, Engels work general. models value function Gaussian processuses dictionary method obtain sparse representation (without procedure, value functionwould represented vector many components visited states). However, dictionarymethod used preprocessing step, Gaussian process nonparametric representation reducesproposed parametric linear representation, basis functions kernels. Constructing parameterization automatically online surely interest, proposed point view makescomparisons easier.488fiKalman Temporal Differencestake account non-stationarity (which explains almost never used optimisticpolicy iteration incremental actor-critic schemes), see example work PhuaFitch (2007). Many recent approaches handling dilemma explorationexploitation use uncertainty information (eg., see Dearden, Friedman, & Russell,1998 Strehl, Li, Wiewiora, Langford, & Littman, 2006). However, far know,algorithms allow providing uncertainty information within value approximationcontext, among GPTD framework Engel (2005). However, contrarycontribution effective use information left future work. Like LSTD,GPTD algorithms sample efficient handle non-stationarity3 . Yet, GPTDKTD frameworks share similarities, discussed throughout paper.motivation behind KTD handle aspects time.1.3 Paper Outlinenext section introduces alternative point view value function approximationintroduces informally Kalman filtering state-space representation, uponcontribution built.Determinism MDP assumed Section 3 general Kalman Temporal Differences framework derived. Deterministic transitions linked white noiseassumption necessary KTD derivation. specialized using approximation scheme, Unscented Transform (UT) Julier Uhlmann (2004) derive familypractical algorithms. Section 4, colored noise model initially introduced Engel,Mannor, Meir (2005) used extend KTD framework case stochastic transitions. eXtended KTD (XKTD) framework proposed, combinationoff-policy learning discussed. Convergence analysed Section 5. whitenoise assumption, shown KTD minimizes weighted square Bellman residual.colored noise assumption, shown XKTD indeed performs least-squaressupervised learning associating state values observed Monte Carlo returns cumulativerewards. solution LSTD(1), unbiased estimator valuefunction. Section 6 shows compute uncertainty value estimatesframework introduces form active learning scheme aims improving speedconvergence KTD-Q, KTD value iteration-like algorithm. proposed frameworkexperimented compared state art RL algorithms. experimentclassic RL benchmark aims highlighting specific features KTD. Last sectiondiscusses position proposed framework related approaches offersperspectives.2. Alternative Point Viewprevious section presented standard vision reinforcement learning problemformulation MDP framework. alternative point viewintroduced.3. LSTD GPTD could certainly extended non-stationary case, example introducingforgetting factor. However, designed initially, aimpaper provide LSTD GPTD variations.489fiGeist & Pietquin2.1 Informal Ideapaper, novel approach based alternative point view proposed.stochastic dynamic system seen possessing underlying value functions V RSstate-action value functions Q RSA agent observe interactingsystem. agent takes action, provokes state change generationreward. reward actually local observation set underlying value functionsruling behavior system. sequence observations, agentinfer information value functions. good estimate value functionV (s) (resp. state-action value function Q(s, a)) given conditional expectationpossible trajectories V (s) (resp. Q(s, a)) given sequence observed rewards:Vi (s) = E[V (s)|r1 , . . . , ri ](24)Qi (s, a) = E[Q(s, a)|r1 , . . . , ri ](25)Interacting system therefore becomes mean generate observationshelps estimating value functions hidden properties system. valuefunction estimates, followed policy modified move towards optimal policy.also legitimate adopt behavior allows gathering meaningful observationsrelates exploration versus exploitation dilemma.Two special cases value functions one associated followed policyone associated optimal policy . rest paper concentratesestimating two particular value functions associated Q-functions.Equations (24) (25) solvable general case inferring hidden variablesobservations typically treated Kalman filtering signal processingoptimal control communities. Value functions considered generated setparameters search optimal set hidden parameters providesbest estimate value function (see Section 3.1). following, Kalman filteringfirst introduced method casting (state-action) value function approximationKalman filtering framework using Bellman equations build so-called state-spacerepresentation problem proposed.2.2 Kalman FilteringOriginally, Kalman (1960) filtering paradigm aims tracking hidden state X (modeled random vector) non-stationary dynamic system indirect observations{Y1 , . . . , Yi } state. so, time 1 algorithm computes predictionstate (Xi|i1 ) observation (Yi|i1 ) time i, knowing analytically states evolvegenerate observations clarified below. actual next observation Yi known(at time i), state prediction corrected obtain state estimate Xi|i usingobservation prediction error (ei = Yi Yi|i1 ) according following Windrow-Hoff-likeequation:Xi|i = Xi|i1 + Ki (Yi Yi|i1 ) = Xi|i1 + Ki ei(26)Ki Kalman gain described hereafter. original workKalman, linear form equation (26) constraint: adopting statistical pointview, goal Kalman filter recursively compute best linear estimate Xi490fiKalman Temporal Differencesstate time given sequence observations {Y1 , . . . , Yi }. Kalman considersbest estimate one minimizes quadratic cost functionJi (X) = E[kXi Xk2 |Y1 , . . . , Yi ](27)compute optimal gain Ki constraints (26) (27), several assumptionsmade.First, evolution system supposed ruled so-called evolution equationprocess equation (using possibly non-stationary fi function) known:Xi+1 = fi (Xi ) + vi(28)Equation (28) links next state Xi+1 current one Xi vi random noiseusually named evolution noise process noise modeling uncertainty evolution.Second, observations supposed linked states another known function giused typically called observation equation sensing equation:Yi = gi (Xi ) + wi(29)Equation (29) relates current observation Yi current state Xi wi randomnoise usually named observation noise modeling uncertainty induced noisy observation. noise together process noise origin state estimationproblem (estimating current state history observations).Equations (28) (29) provide so-called state-space description system.major assumptions Kalman vi wi additive, white independent noisesvariance Pv Pw respectively, meaning that:E[vi ] = E[wi ] = 0E[vi wj ] = 0(30)i, jE[vj vi ] = E[wj wi ] = 0(31)6= j(32)Given assumptions constrains (26) (27) adopting statisticalpoint view, Kalman filter algorithm provides optimal quantities Xi|i1 , Yi|i1Ki :Xi|i1 = E[Xi |Y1 , . . . , Yi1 ] = E[fi1 (Xi1 ) + vi1 |Y1 , . . . , Yi1 ]= E[fi1 (Xi1 )|Y1 , . . . , Yi1 ] = E[fi1 (Xi1|i1 )],(33)Yi|i1 = E[Yi |Y1 , . . . , Yi1 ] = E[gi (Xi ) + wi |Y1 , . . . , Yi1 ]= E[gi (Xi )|Y1 , . . . , Yi1 ] = E[gi (Xi1|i1 )],Ki =PXei Pe1.(34)(35)PXei = E[(Xi Xi|i1 )ei |Y1 , . . . , Yi1 ] Pei = cov(ei |Y1 , . . . , Yi1 ).scope paper provide complete development leadinggeneral results provided Kalman (1960). Yet, Section 3 providedevelopments specific case RL.491fiGeist & PietquinSeveral important comments made stage. First, specific assumptionmade distributions noises v w except zeromean known variances (Pv Pw ). Given this, Kalman filter provides bestlinear estimator (in sense estimators update rule linear) systems statemay optimal. Yet, two noises Gaussian distributions,totally described mean variance. specific case, linear estimatethus optimal estimate Kalman filter algorithm provides optimal solution.paper, Gaussian assumption never made best linear estimatorconsidered.Second, linear assumption made concerning functions fi gi . AlthoughKalman (1960) provides exact solutions estimation problem case linearstate-space equations, quantities involved (33), (34) (35) required.exists approximation schemes estimate quantities even case non-linearequations. Extended Kalman filters unscented transform (see Section 3.2.2)schemes.Finally, Kalman filtering mistaken Bayesian filtering. Bayesian filtering would consist computing complete posterior distribution state givenobservations. Kalman filtering focuses first second momentsdistribution (mean variance) constrained linear update. case Gaussiandistributions, Bayesian filtering reduces Kalman filtering complexgeneral case. paper, Kalman filtering considered.2.3 State-space Formulation Value Function Evaluation Problemproviding general framework, underlying ideas introduced valuefunction V (s) evaluation problem. providing uncertainty information estimates considered desired feature, statistical point view adoptedparameter vector modeled set random variables. Another desired featuretrack solution rather converging it. suggests adopting evolutionmodel value function (through parameters). However, dynamics valuefunction hard model, depend whether dynamic system controlled non-stationary value function evaluation takes place generalized policyiteration scheme4 . heuristic evolution model following Occam razor principleadopted parameters evolution modeled random walk:= i1 + vi(36)equation, (true) parameter vector time vi evolution noise.assumed white (that centered, two different time steps, noises independent),hypothesis done distribution. parameter vector thus randomprocess. stationary (because E[i ] = E[i1 ]), harm casevalue function stationary. hand, allow tracking non-stationaryvalue function (even evolution model true one, cannot anywayobtained general case).4. time policy improved, associated value function changes too. Therefore, value functionlearnt non-stationary.492fiKalman Temporal DifferencesAnother issue link observed (the reward) needs inferred (theparameter vector representing value function). Bellman evaluation equationgood candidate produce observation model:ri = V (si ) V (si+1 )(37)However, solution Bellman equation necessarily lie hypothesisspace (the set functions represented parameter vector, givenrepresentation). Therefore inductive bias ni , modeledcentered noise:ri = Vi (si ) Vi (si+1 ) + ni(38)Notice Gaussian assumption made distribution noise.Evolution observation models summarized following state-space formulation:(= i1 + vi(39)ri = Vi (si ) Vi (si+1 ) + nimodel value function approximation. assumed existsparameter random process generates rewards Bellman evaluationequation, observations noisy due inductive bias factsampled Bellman equation used instead true one. States actionsconsidered exogenous variables part definition observationmodel time i. Estimating value function reduces estimationhidden random process. addressed Bayesian filtering, aims estimatingwhole distribution conditioned past observed rewards. paperrestrictive point view adopted, Kalman filtering one, mean variancedistribution estimated restriction linear update rules.3. KTD: Deterministic Caserest section focus deterministic Markovdecision processes. Transitions become deterministic Bellman equations (4-6) simplifyfollows:V (s) = R(s, (s), s0 ) + V (s0 ),000Q (s, a) = R(s, a, ) + Q (s , (s )), s,00Q (s, a) = R(s, a, ) + max Q (s , b), s,bA(40)(41)(42)section provided derivation general KTD algorithm wellspecializations practical implementations.3.1 General Frameworkgeneral point view adopted now. transition generically noted as:(si , si+1 )ti = (si , ai , si+1 , ai+1 )(si , ai , si+1 )493(43)fiGeist & Pietquingiven aim value function evaluation, Q-function evaluation Qfunction optimization (in words, direct evaluation optimal Q-function).Similarly, cases, following shortcuts hold:Vi (si ) Vi (si+1 )gti (i ) = Qi (si , ai ) Qi (si+1 , ai+1 )Qi (si , ai ) maxbA Qi (si+1 , b)(44)TD errors written generically= ri gti (i )(45)statistical point view adopted. said before, original Kalman (1960) filterparadigm aims tracking hidden state (modeled random variable) nonstationary dynamic system indirect observations state. idea behindKTD express value function approximation filtering problem: parametershidden state tracked (modeled random variables following random walk),observation reward linked parameters Bellman equation.problem sight stated so-called state-space formulation (this termcomes Kalman filtering literature confused state spaceMDP):(= i1 + vi(46)ri = gti (i ) + niexpression fundamental proposed framework. Using vocabularyKalman filtering, first equation evolution equation, specifies realparameter vector follows random walk expectation corresponds optimal estimate value function. evolution noise vi white, independent variancematrix Pvi (to chosen practitioner, discussed section 7). Noticeequation update parameters (addressed later), modelnatural evolution time, according Kalman filtering paradigm described Section 2.2; notably allows handling non-stationarity targeted value function.second equation observation equation, links observed transition value(or Q-) function Bellman equation, see (44). observation noise ni supposed white, independent (scalar) variance Pni (also chosen practitionerdiscussed section 7). Notice mandatory assumption holdstochastic MDP, deterministic transitions supposed here. detailsassumption consequences given Section 4. Given deterministictransitions, model noise arises solution Bellman equationnecessarily exists hypothesis space induced parameterization. Noticechoice nature approximator (choice structure neural network,basis functions linear parameterization, etc.) important topic reinforcementlearning generally machine learning. Nevertheless, addressed here,chosen practitioner.494fiKalman Temporal Differences3.1.1 Minimized Cost Functionobjective could estimate whole distribution parameters conditionedpast observed rewards, addressed Bayesian filtering. However,difficult problem general case. simple objective chosen: estimating(deterministic) parameter vector minimizes expectation true parametersmean-squared error conditioned past observed rewards. idea informationprovided observed transitions associated rewards, knowing meanposterior distribution enough. associated cost written as:Ji () = E ki k2 |r1:i r1:i = r1 , . . . , ri(47)Notice random vector (of distribution known), deterministicvector. Generally speaking, optimal solution minimum mean square error (MMSE)estimator conditional expectation5 :argmin Ji () = i|i = E [i |r1:i ](48)However, except specific cases, estimator analytically computable. Instead,aim find best linear estimator . written form quitesimilar equation (7):i|i = i|i1 + Ki ri(49)Equation (49), i|i estimate time i|i1 = E[i |r1:i1 ] predictionaccording past observed rewards r1:i1 , given evolution equation. random walkmodel following holds (recall evolution noise white):i|i1 = E [i1 + vi |r1:i1 ] = E [i1 |r1:i1 ]= i1|i1(50)innovationri = ri ri|i1(51)difference actual observed reward ri prediction ri|i1 basedprevious estimate parameter vector observation equation (recallobservation noise also white):ri|i1 = E [ri |r1:i1 ] = E [gti (i ) + ni |r1:i1 ]= E [gti (i )|r1:i1 ](52)Note innovation ri exactly temporal difference defined Equation (45),random variable dependency random vector .expectation conditioned past observed data: ri = E[i |r1:i ].5. quite intuitive, best deterministic estimator (in least-squares sens) random variablemean.495fiGeist & Pietquin3.1.2 Optimal GainUsing classical equalities, cost function rewritten trace matrixvariance parameters error:Ji () = E ki k2 |r1:i= E (i )T (i )|r1:i= trace E (i )(i )T |r1:i(53)Recall restrict class linear (and unbiased) estimators depictedEq. (49). Therefore, cost function Ji (i|i ) considered, unknowngain Ki :Ji (i|i ) = trace cov i|i |r1:i(54)first step computation optimal gain express conditioned covarianceparameters function gain Ki . notations first introduced(recall also (51), definition innovation):= i|ii|i1 = i|i1i|iPi|i = cov i|i |r1:iPi|i1 = cov i|i1 |r1:i1(55)hP = cov (r |rr |r) P = Eri1:i1rii|i11:i1various estimators unbiased, covariance expanded follows:Pi|i = cov i|i |r1:i= cov i|i1 + Ki ri |r1:i1= cov i|i1 Ki ri |r1:i1+ Ki Pri KiTPi|i = Pi|i1 Pri KiT Ki Pr(56)optimal gain thus obtained zeroing gradient respect Kitrace matrix.First note gradient linear, three matrices ad hoc dimensions A,B C (that products ABAT AC well defined), B symmetric,following algebraic identities hold:trace ABAT = 2AB(57)trace AC= trace CA=C(58)thus using Equation (56) previous identities:Ki trace Pi|i = 02Ki Pri 2Pri = 0Ki = Pri Pr1496(59)fiKalman Temporal DifferencesUsing Equations (56) (59), covariance matrix Pi|i recursively computedfollows:Pi|i = Pi|i1 Ki Pri KiT(60)Recall Gaussian assumption made derive equations. Nevertheless,Gaussian (and linear) assumptions, optimal update actually linear6 (for example, see Chen, 2003). Please also notice variance matrix encodes uncertaintyparameter estimates, intrinsic uncertainty considered MDP (itvariance random process value function mean).3.1.3 General Algorithmgeneral KTD algorithm derived. breaks three stages.first step consists computing predicted quantities i|i1 Pi|i1 . predictionsmade past estimates, algorithm initialized priors 0|0 P0|0 .Recall random walk model, Equation (50) holds, predicted covariancealso computed analytically:Pi|i1 = cov i|i1 |r1:i1= cov i1|i1 + vi |r1:i1= Pi1|i1 + Pvi(61)(recall Pvi problem-dependent variance matrix evolution noise,chosen practitioner).second step compute statistics interest. specializedalgorithm Section 3.2. first statistic compute prediction ri|i1 (52).second statistic compute covariance parameter vectorinnovation:hPri = E (i i|i1 )(ri ri|i1 )|r1:i1(62)However, state-space model (46), ri = gti (i ) + ni , observation noisecentered independent,hPri = E (i i|i1 )(gti (i ) ri|i1 )|r1:i1(63)last statistic compute covariance innovation, written(using characteristics observation noise):Pri = E (ri ri|i1 )2 |r1:i1= E (gti (i ) ri|i1 + ni )2 |r1:i1= E (gti (i ) ri|i1 )2 |r1:i1 + Pni(64)(recall Pni variance observation noise).6. words, case, Kalman filtering solution actually Bayesian filtering solution.497fiGeist & Pietquinthird last step algorithm correction step. consists computinggain (59), correcting predicted parameter vector (49) updating associatedcovariance matrix (60) accordingly. proposed general framework summarizedAlgorithm 1. Notice similarity correction equation (i|i = i1|i1 + Ki (riri|i1 )) Widrow-Hoff equation approximated value correcteddirection error (the innovation indeed TD error). gain Ki seenset adaptive learning rates.Algorithm 1: General KTD algorithmInitialization: priors 0|0 P0|0 ;1, 2, . . .Observe transition ti reward ri ;Prediction step;i|i1 = i1|i1 ;Pi|i1 = Pi1|i1 + Pvi ;Compute statistics interest;ri|i1 = E[gti (i )|r1:i1 ] ;hPri = E (i i|i1 )(gti (i ) ri )|r1:i1 ;Pri = E (gti (i ) ri|i1 )2 |r1:i1 + Pni ;Correction step;Ki = Pri Pr1;i|i = i|i1 + Ki ri ri|i1 ;Pi|i = Pi|i1 Ki Pri KiT ;3.2 Specializationsmain difficulty applying KTD compute statistics interest ri|i1 , PriPri (for statistics i|i1 Pi|i1 necessary). First, value functionevaluation case linear parameterization considered. related Bellmanequation (40). case analytical derivation possible. approximationscheme, unscented transform (UT) Julier Uhlmann (2004), introduced.allows solving problem nonlinear parameterization. Q-function evaluationdirect optimization follow.3.2.1 KTD-V: Linear Parameterizationlinear parameterization equation (8) adopted, V (s) = (s)T .state-space formulation (46) thus rewritten as:(= i1 + viri = ((si ) (si+1 ))T + ni498(65)fiKalman Temporal DifferencesNotice problem sight evaluation deterministic policy, actionobserved. policy fixed, MDP reduces valued Markov chain.shorten notations, Hi defined as:Hi = (si ) (si+1 )(66)observation equation linear, statistics interest derived analytically.prediction is:ri|i1 = E [gti (i )|r1:i1 ]= E HiT |r1:i1= HiT E [i |r1:i1 ]= HiT i|i1(67)covariance parameter vector innovation also computedanalytically:hPri = E i|i1 gti (i ) ri|i1 |r1:i1h= E i|i1 HiT i|i1 |r1:i1h= E i|i1 i|i1|r1:i1 Hi= Pi|i1 Hi(68)covariance innovation derived analytically well:h2gti (i ) ri|i1 |r1:i1 + Pni2= E Hi i|i1 |r1:i1 + PniPri = E= HiT Pi|i1 Hi + Pni(69)optimal gain thus defined algebraically recursively:Ki =Pi|i1 HiHi Pi|i1 Hi +Pni(70)KTD-V approach linear parameterization summarized Algorithm 2.Notice gain shares similarities gain (19) LSTD algorithm(Bradtke & Barto, 1996), surprise. LSTD based least-squaresminimization (however introduction instrumental variables order handle stochastic transitions), Kalman filter seen stochastic generalizationleast-squares method. gain shares also similarities GPTD. Actually,process noise set 0 (that Pvi = 0), KTD-V linear parameterization499fiGeist & PietquinAlgorithm 2: KTD-V: linear parameterizationInitialization: priors 0|0 P0|0 ;1, 2, . . .Observe transition (si , si+1 ) reward ri ;Prediction step;i|i1 = i1|i1 ;Pi|i1 = Pi1|i1 + Pvi1 ;Compute statistics interest;ri|i1 = HiT i|i1 ;Pri = Pi|i1 Hi ;Pri = HiT Pi|i1 Hi + Pni ;/*Hi = (si ) (si+1 )*/Correction step;;Ki = Pri Pr1i|i = i|i1 + Ki ri ri|i1 ;Pi|i = Pi|i1 Ki Pri KiT ;GPTD algorithm7 , see Equation (22). surprise:linear Gaussian hypothesis, state-space (65) zero evolution noise equivalentstatistical generative model (21). alternative point view approachesprovide least-squares solution L2 Bellman residual minimization.Although linear parameterization widely used, one interested using nonlinear one (for optimal basis function search compact function representationinstance). Another case interest (addressed later) handle max operatorinherent Bellman optimality equation. proposed approach notablydiffers Engels framework. Basically, issue computing statistics interestKTD stated following problem: given mean covariance randomvariable (i|i1 Pi|i1 KTD), mean covariance nonlinear (andperhaps non-differentiable) mapping (gti KTD) random variable computed?following section presents unscented transform, approximation schemedesigned handle problem.7. again, GPTD general linear parameterization, gain (22) refereedparametric GPTD Engel (2005). Nevertheless, non-parametric approach GPTD actuallyconstructs online kernel-based linear parameterization. end learning, parameterization constructed preprocessing step, non-parametric representation reduces linearparametric representation. focus paper learn parameters representationrepresentation (which totally recognize problem importance), GPTDalways considered parametric form article.500fiKalman Temporal Differences3.2.2 Unscented TransformLets abstract RL Kalman filtering consider problem non-linear mappingrandom variable. Let X random vector, let mapping X. problemcompute mean covariance knowing mapping first secondorder moments X. mapping linear, relation X written= AX matrix ad hoc dimension (that number row timesnumber rows X). case, required mean covariance analyticallycomputed E[Y ] = AE[X] E[Y ] = AE[XX ]AT . result usedderive KTD-V algorithm Section 3.2.1.mapping nonlinear, relation X written as:= f (X)(71)first solution would approximate nonlinear mapping first order Taylorexpansion around E[X]. leads following approximations mean covariance :E[Y ] f (E[X])(72)E[Y ] (f (E[X])) E[XX ] (f (E[X]))T(73)approach basis Extended Kalman Filtering (EKF) (for example, see Simon,2006), extensively studied used past decades. Howeverlimitations. First cannot handle non-derivable nonlinearities, thus cannot handleBellman optimality equation (6) max operator. requires computegradient mapping f , quite difficult even possible (eg., neuralnetworks). also supposes nonlinear mapping locally linearizable ordergood approximation, unfortunately always case leadquite bad results, exemplified Julier Uhlmann (2004).basic idea unscented transform easier approximate arbitraryrandom vector (with samples) arbitrary nonlinear function. principle sampledeterministically set so-called sigma-points expectation covarianceX. images points nonlinear mapping f computed,used approximate statistics interest. shares similarities Monte-Carlomethods, however sampling deterministic requires less samples drawn,nonetheless guaranteeing given accuracy (Julier & Uhlmann, 2004).original unscented transform described formally (some variantsintroduced since then, basic principle same). Let n dimensionX. set 2n + 1 so-called sigma-points computed follows:x(0) = Xx(j)x(j)p= X +(n + )PXjp= X(n + )PXjnj=0(74)1jn(75)n + 1 j 2n(76)well associated weights:w0 =n+wj =50112 (n + )j > 0(77)fiGeist & PietquinX mean X,pPX variance matrix, scaling factor controlssampling spread, ( (n + )PX )j j th column Cholesky decompositionmatrix (n + )PX . image mapping f computedsigma-points:(j) = f (x(j) ), 0 j 2n(78)set sigma-points images finally used approximate first secondorder moments , even PXY , covariance matrix X :=2nXwj (j)(79)j=0PY2nXwj (j)(j)(80)j=0PXY2nXwj x(j) X (j)(81)j=0Thanks unscented transform, possible address value function evaluation problem nonlinear parameterization, random vector X caseparameter vector, nonlinear mapping predicted reward.3.2.3 KTD-V: Nonlinear Parameterizationsection generic parameterization value function V considered:neural network (Bishop, 1995), semi-parametric kernel representation (Geist, Pietquin,& Fricout, 2008), function representation interest, long describedset p parameters. general state-space formulation (46) thus written as:(= i1 + vi(82)ri = Vi (si ) Vi (si+1 ) + niproblem still compute statistics interest, becomes tractableunscented transform. first thing compute set sigma-points knownstatistics i|i1 Pi|i1 well associated weights using Equations (74-77),described Section 3.2.2:n(j)(83)i|i1 = i|i1 , 0 j 2pW = {wj , 0 j 2p}(84)images sigma-points computed (a predicted rewardsampled parameter vectors), using observation function state-space model (82),linked Bellman evaluation equation (40):(j)Ri|i1 = ri|i1 = V(j) (si ) V(j) (si+1 ), 0 j 2p(85)i|i1i|i1502fiKalman Temporal Differencessigma-points images computed, statistics interest approximated by:ri|i12pX(j)wj ri|i1(86)2(j)wj ri|i1 ri|i1 + Pni(87)(j)(j)wj i|i1 i|i1 ri|i1 ri|i1(88)j=0Pr2pXj=0Pri2pXj=0unscented transform longer approximation linear mapping, formulation still valid value function evaluation linear function approximation. KTD-Vnonlinear function approximation summarized Algorithm 3. Noticegeneral parameterization cannot taken account GPTD LSTD. possible direct algorithms (TD function approximation), however riskdivergence. illustrated Section 7.3.2.4 KTD-SARSAsection focuses Q-function evaluation fixed given policy. associatedalgorithm called KTD-SARSA, misleading. Indeed, SARSA sometimeunderstood Q-function evaluation algorithm associated optimistic policy iteration scheme (eg., -greedy policy). focus Q-function evaluation problem,control part left apart. general parameterization Q , consideringBellman evaluation equation (41), state-space model (46) rewritten as:(= i1 + vi(89)ri = Qi (si , ai ) Qi (si+1 , ai+1 ) + nifixed policy, value function evaluation state space induced Markov chain8quite similar Q-function evaluation state-action space induced Markov chain.thus straightforward extend KTD-V Q-function evaluation. Recall linearparameterization, unscented transform leads exact computation statisticsinterest, thus case Algorithm 3 (KTD-V) equivalent Algorithm 2.sigma-point formulation KTD-SARSA given, also summarizedAlgorithm 3.LSTD GPTD also generalized Q-function evaluation (see respectively Lagoudakis & Parr, 2003 Engel, 2005). However, again, approachescannot handle nonlinear parameterization, contrary KTD-SARSA. Notice alsoparameterization linear process noise zero, KTD-SARSAalgorithm GPTD Q-function evaluation (this direct extension equivalence GPTD KTD-V linear parameterization zero process noise, seeSec. 3.2.1).8. fixed policy, MDP reduces Markov chain.503fiGeist & PietquinAlgorithm 3: KTD-V, KTD-SARSA KTD-QInitialization: priors 0|0 P0|0 ;1, 2, . . .(si , si+1 ) (KTD-V)Observe transition ti = (si , ai , si+1 , ai+1 ) (KTD-SARSA)(si , ai , si+1 ) (KTD-Q)reward ri ;Prediction Step;i|i1 = i1|i1 ;Pi|i1 = Pi1|i1 + Pvi ;Sigma-pointsn computation ;(j)i|i1 = i|i1 , 0 j 2p (from i|i1 Pi|i1 );W = {wj , 0 j 2p } ;Ri|i1 =n(j)r=V(KTD-V)(j) (si ) V (j) (si+1 ), 0 j 2pi|i1i|i1i|i1n(j)ri|i1 = Q(j) (si , ai ) Q(j) (si+1 , ai+1 ), 0 j 2p (KTD-SARSA)i|i1i|i1n(j)ri|i1 = Q (j) (si , ai ) maxbA Q (j) (si+1 , b), 0 j 2p (KTD-Q)i|i1;i|i1Compute statistics interest;P(j)ri|i1 = 2pj=0 wj ri|i1 ;P(j)(j)Pri = 2pj=0 wj (i|i1 i|i1 )(ri|i1 ri|i1 );2P(j)Pri = 2p+ Pni ;j=0 wj ri|i1 ri|i1Correction step;Ki = Pri Pr1;i|i = i|i1 + Ki ri ri|i1 ;Pi|i = Pi|i1 Ki Pri KiT ;3.2.5 KTD-Qsection focuses Q-function optimization, finding approximatesolution Bellman optimality equation (42). general parameterization Q adopted.state-space model (46) specialized follows:(= i1 + viri = Qi (si , ai ) maxbA Qi (si+1 , b) + ni(90)linear nonlinear parameterizations distinguished, nonlinearities induced max operator. tricky handle, especiallynon-differentiability.504fiKalman Temporal DifferencesHopefully, approximates random variable rather mapping, unscented transform derivative-free approximation. Given general KTD algorithmintroduced Section 3.1.3 unscented transform described Section 3.2.2,possible derive KTD-Q, KTD algorithm Q-function direct optimization. Onefirst compute set sigma-points associated parameter vector, equations (83-84). mapping sigma-points observation equationstate-space model (90), contains max operator, computed:n(j)(91)Ri|i1 = ri|i1 = Q(j) (si , ai ) max Q(j) (si+1 , b), 0 j 2pbAi|i1i|i1Then, usual, sigma-points images used compute statisticsinterest, equations (86-88). proposed KTD-Q summarized Algorithm 3.Notice even parameterization linear, LSTD GPTD equivalentalgorithm. Actually, linearity observation model mandatory assumptionderivation algorithms, Bellman optimality operator cannot takenaccount. far know, KTD-Q one first second order value iteration-likealgorithms. Choi Van Roy (2006) propose linear least-squares based bootstrappingapproach (to discussed Section 8) used Q-learning-like setting.Yu Bertsekas (2007) also introduce least-squares-based Q-learning. However,designed optimal stopping problems (which restrictive class MDP)truly online (to update representation given new observation, followedtrajectory explicitly required). Roughly speaking, algorithm fitted-Qleast-squares supervised learning part new transition addedlearning basis iteration. computational complexity cubic9 , highersquare complexity KTD, shown next section.3.3 Algorithmic ComplexityLet p number parameters. unscented transform involves Cholesky decomposition computational complexity O(p3 ) general. However, varianceupdate (60) rank one update, Cholesky decomposition perfomed O(p2 )(eg., see Gill, Golub, Murray, & Saunders, 1974). different algorithms imply evaluate2p + 1 times gti function time-step. KTD-V KTD-SARSA generalparameterization, evaluation bounded O(p). KTD-Q, maximumactions computed. notation represents cardinality action space finite, computational complexity algorithm used search maximum otherwise(eg., number samples times evaluation complexity Monte Carlo).evaluation bounded O(pA). Remaining operations basic linear algebra,thus bounded O(p2 ). Therefore global computational complexity (per iteration)KTD-V KTD-SARSA O(p2 ), KTD-Q O(Ap2 ). mean variancematrix parameters maintained, memory complexity O(p2 ). Althoughcomparable LSTD GPTD complexity, higher many RL algorithmslinear complexity. Nevertheless, value function approximation approaches assume linear parameterization. KTD make hypothesis (even9. However, paper proposes heuristics reduce complexity.505fiGeist & Pietquinanalyse convergence, shown Section 5.1) allows much compact representations value function. Thus quadratic complexity problem importantcounterparts.4. KTD: Stochastic CaseKTD framework presented far assumes deterministic transitions.case, observation noise ni cannot assumed white (since would include MDPstochasticity well inductive bias), whereas necessary condition KTDderivation. First shown using KTD stochastic MDP involves bias.colored noise model introduced alleviate problem, used extend KTD.problem caused off-policy learning, prevents derivation XKTD-Qalgorithm, also discussed.4.1 Stochastic Transitions BiasOne ignore problem use cost function (47) linked state-space model (46)stochastic transitions. However, similarly approaches minimizing squared Bellmanresidual, residual algorithms Baird (1995), cost function biased.precisely, biased relatively stochasticity transitions (parameters transitionsdifferent sources randomness). Additionally, cost function biased,estimator minimizing (that i|i ) biased too.Theorem 1. reward function depends current state-action pair,transiting state, used stochastic Markov decision process, costfunction (47) biased (relatively stochasticity transitions), bias given by:20kKi k E covs0 |si ,(si ) (ri + V (s )) |r1:i1kKi k2 E cov (ri gti ()) |r1:i1 = kKi k2 E covs0 |si ,(si ) (ri + Q (s0 , (s0 ))) |r1:i1s0 |si ,aikKi k2 E covs0 |si ,ai (ri + maxaA Q (s0 , a)) |r1:i1(92)clear bias zero deterministic transitions.Proof. assumption reward depend transiting state madetechnically simplifying demonstration, conditioning cost functionpast observed rewards. Yet done without loss generality. hypothesis,state-space model considered stochastic MDP is:(= i1 + vi(93)ri = Es0 |si ,ai [gti (i )] + niti defined random quantity ti = (si , ai , s0 ). Notice observationequation (minus noise) Bellman equation stochastic transitions. differencestate-space model (46) transitions sampled averaged.associated cost function is:Ji () = trace Pi|i = trace Pi|i1 Pri KiT Ki PrKi Pri KiT(94)506fiKalman Temporal DifferencesCalligraphic letters denote state-space model (93) notations (55)state-space model (46), eg.:hPri = E i|i1 ri |r1:i1 ri = ri ri|i1 = ri E Es0 |si ,ai [gti (i )] |r1:i1(95)Notice prediction reward unbiased, thus holds innovation:Es0 |si ,ai ri|i1 = ri|i1 Es0 |si ,ai ri|i1 = ri|i1(96)term Pi|i1 depend transiting state s0 term Pri linearinnovation, unbiased:Es0 |si ,ai Pi|i1 = Pi|i1 Es0 |si ,ai [Pri ] = Pri(97)case variance innovation:Es0 |si ,ai [Pri ] = Es0 |si ,ai E ri2 |r1:i1= E Es0 |si ,ai ri2 |r1:i1h2= E r2i |r1:i1 + E Es0 |si ,ai ri2 Es0 |si ,ai [ri ] |r1:i1= Pri + E cov (ri ) |r1:i1s0 |si ,ai(98)Thus bias (Es0 |si ,ai [Ji ()] Ji ()) computed:Es0 |si ,ai [Ji ()] Ji () = Es0 |si ,ai trace Ki (Pri Pri ) KiT= trace(Ki KiT )Es0 |si ,ai [Pri Pri ]= KiT Ki Es0 |si ,ai [Pri ] Pri2= kKi k E cov (ri gti ()) |r1:i1s0 |si ,ai(99)Notice neither V (si ) Q (si , ai ) depends transiting state s0 . Thus provesresult expressed Theorem 1.bias quite similar one arising minimization square Bellmanresidual. result Theorem 2 (see Section 5) even strengthen parallel. solutioncould introduce auxiliary filter remove bias, similarly introductionauxiliary function made Antos, Szepesvari, Munos (2008). However extensionwork straightforward. Another approach could estimate bias onlineremove it, similarly done Jo Kim (2005) least-mean square filtering.However Kalman filter much complex framework least-squares filter,especially combined unscented transform. Another interesting perspective couldintroduce colored observation noise done Engel (2005) Bayesian contextGaussian process-based algorithms. last approach presented used extendKTD next.507fiGeist & Pietquin4.2 Colored Noise ModelFirst focus value function evaluation. Extension Q-function evaluationstraightforward, Q-function optimization discussed later, off-policyaspect (the learnt policy behaviorial one). Bellman evaluation equationsolved Equation (4): shown directly using KTD stochastic problem induces bias minimized cost function. colored noise modelfirst proposed Engel et al. (2005) (the basis so-called Monte-Carlo GPTDalgorithm) first presented, adapted extend KTD framework.policy fixed evaluation, MDP reduces valued Markov chainprobability transition p (.|s) = p(.|s, (s)) reward R (s, s0 ) = R(s, (s), s0 ).value function defined expectation (over possible trajectories) following discount return random process:(s) =XR (si , si+1 )|s0 = s, si+1 p (.|si )(100)i=0equation naturally leads Bellman-like anti-causal recurrence:(s) = R (s, s0 ) + (s0 ), s0 p (.|s)(101)random process also broken mean plus zero mean residual.However definition mean value function V (s) = E[D (s)], writingV (s) residual:(s) = E[D (s)] + (D (s) E[D (s)]) = V (s) + V (s)(102)Substituting Equation (102) Equation (101), reward expressed functionvalue plus noise:R (s, s0 ) = V (s) V (s0 ) + N (s, s0 )(103)noise defined as:N (s, s0 ) = V (s) V (s0 )(104)done Engel et al. (2005), residuals supposed independent, leadscolored noise model. assumption really strong, transitions likelyrender residuals dependent, however despite convergence guarantees givenSection 5.Recall observation equation state-space formulation (46): ri = gti (i ) + ni .KTD framework, observation noise ni assumed white, necessaryalgorithm derivation. eXtended Kalman Temporal Differences (XKTD) framework,colored noise model (104) used instead.residual centered assumed independent, noise indeed movingaverage (MA) noise (here sum two white noises):ni = ui + ui1 ,ui (0, i2 )(105)Notice white noise ui centered variance i2 , nevertheless assumptionmade distribution (particularly Gaussian assumption).508fiKalman Temporal Differences4.3 Extending KTDquite easy use autoregressive (AR) process noise Kalman filter extendingevolution equation (for example, see Simon, 2006). However, far know,case observation noise never addressed literature, whereasnecessary extend KTD. Notice noise model taken account quitedifferent way GPTD framework. Basically, done using partitioned matrixinversion formula, possible due lack linearity assumption.4.3.1 eXtended Kalman Temporal DifferencesRederiving KTD case noise done Section 3.1 would quite difficult.Instead, proposed express scalar noise ni vectorial AR noise.allows extending state-space model (46) new one Algorithm 1 applies ratherdirectly. Let auxiliary random variable. Scalar noise (105) equivalentfollowing vectorial AR noise:i10 01ui(106)=+ni1 0ni1Indeed, vectorial AR noise, ni = i1 ui = ui , ni = ui + ui1correct model. noise u0i = ui ui also centered variancematrix is:12(107)Pu0i =2new noise formulation defined, possible extend statespace formulation (46):(xi = F xi1 + vi0(108)ri = gti (xi )parameter vector extended vectorial AR noise ni :xTi = ni(109)Notice observation noise ni part extended parameter vector,also estimated. evolution matrix F takes account structureobservation noise. Let p number parameters Ip identity matrix size p,evolution matrix written bloc (0 denotes zero p 1 column vector):Ip 0 0F = 0T 0 0(110)0T 1 0process noise vi also extended take account observation noise.still centered, however variance matrix extended using variance matrix Pu0i (107):Pv00i2i2(111)Pvi0 = 0T2220509fiGeist & Pietquinobservation equation remains same:ri = gti (xi ) = gti (i ) + ni(112)However observation noise part evolution equation,estimated.Using new state-space formulation, general XKTD algorithm derived.summarized Algorithm 4. rather similar Algorithm 1 two slight changes:state-space considered given Equation (108) prediction meancovariance extended random vector xi done using evolution matrix F(which identity KTD). Notice computational complexityalgorithms, parameter vector extended two scalars. KTD,XKTD specialized XKTD-V (value function evaluation) XKTD-SARSA (Qfunction evaluation). reasoning Section 3.2 practical approachesgiven Algorithm 5. Yet, specialization XKTD-Q straightforwardoff-policy nature, explained section 4.3.2.Recall KTD zero process noise linear parameterization algorithm GPTD (see Sec. 3.2.1). Actually, holds XKTD zero process noiselinear parameterization MC-GPTD (the algorithm obtained using colorednoise model GPTD framework, however different manner, see Engel et al., 2005).easily (but lengthly) checked expanding XKTD equations linear case.again, MC-GPTD certainly extended handle non-stationarities, evenless natural XKTD, cannot handle nonlinear parameterization.point view, XKTD extends MC-GPTD.Algorithm 4: General XKTD algorithmInitialization: priors x0|0 P0|0 ;1, 2, . . .Observe transition ti reward ri ;Prediction step;xi|i1 = F xi1|i1 ;Pi|i1 = F Pi1|i1 F + Pvi0 ;Compute statistics interest (using UT);ri|i1 = E[gti (i ) + ni |r1:i1 ] ;Pxri = E (xi xi|i1 )(gti (i ) + ni ri|i1)|r1:i1 ;Pri = E (gti (i ) + ni ri|i1 )2 |r1:i1 ;Correction step;Ki = Pxri Pr1;xi|i = xi|i1 + Ki ri ri|i1 ;Pi|i = Pi|i1 Ki Pri KiT ;510fiKalman Temporal DifferencesAlgorithm 5: XKTD-V XKTD-SARSA0 0P0|0 ;Initialization: priors x0|0 = 0|01, 2, . . .((si , si+1 ) (XKTD-V)Observe transition ti =(si , ai , si+1 , ai+1 ) (XKTD-SARSA)reward ri ;Prediction Step;xi|i1 = F xi1|i1 ;Pi|i1 = F Pi1|i1 F + Pvi0 ;Sigma-pointsn computation ;(j)Xi|i1 = xi|i1 , 0 j 2p + 4 (from xi|i1 Pi|i1 );W = {wj , 0 j 2p + 4 } ;(j)(j)(j)(j)/* notice (xi|i1 )T = (i|i1 )T i|i1 ni|i1*/R=i|i1n(j)(j)ri|i1 = V(j) (si ) V(j) (si+1 ) + ni|i1 , 0 j 2p + 4 (XKTD-V)i|i1i|i1n(j)(j)ri|i1 = Q(j) (si , ai ) Q(j) (si+1 , ai+1 ) + ni|i1 , 0 j 2p + 4 (XKTD-SARSA)i|i1i|i1Compute statistics interest;P(j)ri|i1 = 2p+4j=0 wj ri|i1 ;P(j)(j)Pxri = 2p+4j=0 wj (xi|i1 xi|i1 )(ri|i1 ri|i1 );2P(j)Pri = 2p+4wrr;ji|i1j=0i|i1Correction step;Ki = Pxri Pr1;xi|i = xi|i1 + Ki ri ri|i1 ;Pi|i = Pi|i1 Ki Pri KiT ;4.3.2 XKTD Off-policy LearningOff-policy learning problem learning value one policy (the target policy)following another one (the behavior policy). KTD-Q (or generally Q-learninglike algorithms) example off-policy learning: behavior policy sufficientlyexploratory policy learnt policy optimal one. generally, off-policylearning interest, example reuse previous trajectories behavioral policycannot controlled.Using colored observation noise results memory effect, similarly happenseligibility traces classical TD algorithms (Sutton & Barto, 1998). classical eligibility-trace algorithms, XKTD applied off-policy learning failincludes effect multi-step transitions, contaminated behaviorpolicy compensated way. discussion off-policy learning511;fiGeist & Pietquinmemory effects, see example work Precup, Sutton, Singh (2000). linkmemory effect Monte Carlo (and eligibility traces eligibility factorset 1) shown convergence analysis Section 5. analyzedXKTD equations showing parameters updated according past temporaldifferences errors, current one.show this, first step expand prediction equation:xi|i1 = F xi1|i1i|i1i1|i1i|i1 = 0i1|i1ni|i1(113)Let gti defined as:gti = E[gti (i )|r1:i1 ](114)KTD framework, gti actually predicted reward. However, caseXKTD framework, estimated noise also taken account.predicted reward expanded using Eq. (113):ri|i1 = E[gti (i ) + ni |r1:i1 ]= gti + ni|i1= gti + i1|i1blockwise notation adopted Kalman gain:KiKi = KiKni(115)(116)stated, correction equation expanded:xi|i = xi|i1 + Ki riKii|ii1|i1i|i = 0 + Ki ri gti i1|i1Knii1|i1ni|ilast equation general update parameters derived:i|i = i1|i1 + Ki ri gti Kwi1 ri1(117)(118)parameters thus updated according temporal difference error time i,= ri gti , innovation time 1, ri1 , (by recurrence) combination TD error time 1 innovation time 2, etc. update equationhighlights memory effect XKTD prevents use off-policy learning scenario. Notably, prevents derivation XKTD-Q algorithm. solution combineoff-policy learning colored noise could use importance sampling scheme,well known approach Monte Carlo literature allows estimating quantitieslinked distribution using samples drawn another distribution.512fiKalman Temporal Differences5. Convergence Analysissection provides convergence analysis KTD (deterministic MDPs)XKTD (stochastic MDPs).5.1 Deterministic CaseFirst convergence analysis KTD algorithm provided deterministic MDP.leads result similar one residual algorithms (Baird, 1995), minimization squared Bellman residual. theorem makes strong assumptions(actually GPTD framework, however without linear hypothesis). However, important remark even hypotheses satisfied, costfunction (47) still minimized. aim result link KTD classic RLalgorithms.Theorem 2. assumptions posterior noise distributions Gaussianprior Gaussian (of mean 0 variance P0 ), Kalman Temporal Differences algorithm (white observation noise assumption) minimizes followingregularized empirical cost function:Ci () =X21rj gtj () + ( 0 )T P01 ( 0 )Pnj(119)j=0Proof. First notice KTD indeed specific form Sigma-Point Kalman Filter(SPKF). According van der Merwe (2004, ch. 4.5), given assumptions,SPKF estimator (and thus KTD one) maximum posteriori (MAP) estimator:i|i = iMAP = argmax p(|r1:i )(120)applying Bayes rule, posterior distribution p(|r1:i ) written (normalized) product likelihood p(r1:i |) prior distribution p():p(|r1:i ) =p(r1:i |)p()p(r1:i )(121)normalization factor p(r1:i ) depend parameters, MAP thus reduceslikelihood times prior:i|i = argmax p(r1:i |)p()(122)Recall that, KTD, observation noise assumed white. Therefore, jointlikelihood product local likelihoods:i|i = argmax p(r1:i |)p() = argmaxp(rj |)p()Moreover, noise prior supposed Gaussian, thus:rj | N gtj (), Pnj N (0 , P0 )513(123)j=1(124)fiGeist & Pietquinhand, maximizing product densities equivalent minimizing sumnegatives logarithms:Xi|i = argminln(p(rj |)) + ln(p())(125)j=1Gaussian assumption, distributions follows:!1 (rj gtj ())21expp(rj |) = p2Pnj2Pnj111( 0 ) P0 ( 0 )p() =p1 exp2(2) 2 |P0 | 2(126)(127)Consequently:i|iX21= argminrj gtj () + ( 0 )T P01 ( 0 )Pnj(128)j=1proves result.remarks importance made. First, memoryless channel assumptionhold stochastic MDPs. Moreover, form minimized cost function (119)strengthens parallel drawn Section 4.1 KTD squared Bellman residualminimization. Second, chosen observation noise variance Pni allows weighting samples.evolution noise variance appear directly minimized cost function, nevertheless empirically influences convergence tracking abilities algorithm.example, helps handling non-stationarity avoiding local minima. prior P0 actsregularization terms, help choose it. Notice regularizationterm also appears recursive form LSTD algorithm (eg., see Kolter & Ng, 2009).Finally, shown (again, see van der Merwe, 2004, ch. 4.5) SPKF (and thusKTD) update indeed online form modified Gauss-Newton method, actually variant natural gradient descent. case, Fisher information matrix1Pi|i, inverse variance matrix random parameters. natural gradientapproach shown quite efficient direct policy search (Kakade, 2001)actor-critics (Peters, Vijayakumar, & Schaal, 2005), lets envision good empirical results KTD. experimented Section 7. KTD perhaps first reinforcementlearning value (and Q-) function approximation algorithm (in pure critic sense) involvingnatural gradient.5.2 Stochastic Caseconvergence analysis provided XKTD stochastic MDPs. Again, theoremmakes strong assumptions, without harming minimization cost function (47)satisfied.514fiKalman Temporal DifferencesTheorem 3. Assume posterior noise distribution Gaussian, well priordistribution (of mean 0 variance P0 ). XKTD estimator minimizes (weightedregularized) square error linking state values Monte Carlo returns:Ci () =X12j=1 j1V (sj )X2tj rt + ( 0 )T P01 ( 0 )(129)t=jProof. result van der Merwe (2004, ch. 4.5) used. correspondingproof made random walk evolution model (that identity evolution matrix),however easily extended linear evolution model. thus appliedstate-space model (108):xi|i = xMAP= argmax p(x|r1:i )(130)xState-space model (108) equivalent state-space model (46) noise (105),holds (non-extended) parameter vector:i|i = argmax p(|r1:i ) = argmin( ln(p(|r1:i )))(131)applying Bayes rule, posterior distribution p(|r1:i ) (normalized) productlikelihood p(r1:i |) prior p():p(|r1:i ) =p(r1:i |)p()p(r1:i )(132)normalization factor p(r1:i ) depend parameters, MAP therefore reduceslikelihood times prior:i|i = argmax p(r1:i |)p()(133)However, observation noise longer white, possible express jointlikelihood product local likelihoods. Nevertheless, joint likelihood stillcomputable. this, notations introduced. Let Vi (), Ri Ni following1 vectors:Vi () = V (s1 ) V (s2 ) . . .Ri = r1 r2 . . . riNi = n1 n2 . . . niV (si )(134)(135)(136)Let Hi bidiagonal matrix defined as:1 0 . . .0 1 0Hi = . ........0 ...01515(137)fiGeist & Pietquineasy check inverse given by:10 1H1= ... ...0 .........0i1...1(138)Eventually, let Ni = E[Ni NiT ] variance matrix noise Ni , takes accountcoloration. Given definition noise ni (105), tridiagonal matrix given by:20 + 2 12120.....22212+.122Ni =(139)......2...i1220...i1i1+ 2 i2noise Gaussian, likelihood Gaussian too, colored observation noise. distribution is:r1:i | N (Ri Hi Vi (), Ni )(140)Maximizing MAP equivalent minimizing negative logarithm, givendistribution (140) XKTD estimator satisfies:1())(141)(RHV()+()Pi|i = argmin (Ri Hi Vi ())T 1000Ninoise variance rewritten according Hi diagonal matrix containingresidual variances:2)Ni = Hi HTi = diag(02 , . . . , i1(142)Using last equation, XKTD estimator rewritten as:1i|i = argmin (Ri Hi Vi ())T 1Ni (Ri Hi Vi ()) + ( 0 ) P0 ( 0 )= argmin (Ri Hi Vi ())T (Hi HTi )1 (Ri Hi Vi ()) + ( 0 )T P01 ( 0 )111= argmin (H1RV())(HRV())+()P()(143)000Given inverse (138) Hi matrix, last equation proves result.result shows (strong) assumptions, XKTD minimizes squareerror linking state values Monte Carlo returns, strengthens discussioninability XKTD used off-policy learning scenario Section 4.3.2. KTD,residuals variance weights samples, prior acts regularization term,help choose it. important fact result shows actually,assumption residuals variance constant (that j2 = 2 ), XKTD minimizes516fiKalman Temporal Differencescost-function (the recursive version of) LSTD(1), eligibility traces-based extensionLSTD eligibility factor 1 (see Boyan, 1999 proof LSTD(1) minimizescost-function (129)). consequence, XKTD asymptotically unbiased value functionestimator, LSTD(1)10 .6. Active Learning Schemeparameters modeled random variables, value (or Q-) functionfunction parameters, random variable given state (or state-actionpair). first shown compute expectation associated uncertaintythanks unscented transform. dilemma exploration exploitationbenefit uncertainty information. approaches literature allowshandling value function approximation problem well computing uncertaintyvalues meantime. work Engel (2005) approach, however effective useobtained uncertainty information left future work. proposed formactive learning sort totally explorative policy context KTD-Q.contribution shown effectively speed learning Section 7.6.1 Computing Uncertainty ValuesLet V approximated value function parameterized random vector meanvariance matrix P . Let V (s) V2 (s) associated mean variancegiven state s. order propagate uncertainty parameters valuefunction, first step compute sigma-points associated parameter vector= {(j) , 0 j 2p} well corresponding weights W = {wj , 0 j 2p}P , described Section 3.2. images sigma-points computedgiven state using parameterized value function :n(j)V (s) = V (s) = V(j) (s), 0 j 2p(144)Knowing images corresponding weights, possible compute statisticsinterest, namely mean variance approximated value function:V (s) =2pX(j)wj V (s)V2 (s) =j=02pX2(j)wj V (s) V (s)(145)j=0Thus, given representation value function random parameter vector,uncertainty propagated value function. Figure 1 illustrates uncertaintycomputation. Extension Q-function straightforward. complexity (both computational memory) quadratic. So, time-step estimate i|iassociated variance Pi|i known, uncertainty information computedKTD framework.important remark made here. estimated variance providesinformation uncertainty estimates, however take account10. Notice LSTD(1) KTD minimize cost function, different way, thusprovide estimates asymptotically.517fiGeist & PietquinFigure 1: Uncertainty computation.stochasticity MDP. get lower number samples increases. Roughlyspeaking, seen indirect generalized counting number visitsgiven state state-action pair. Even stochastic MDP, vanish zeronumber samples grows infinity: estimate uncertainty estimatedvalue function, variance stochastic process value functionexpectation.6.2 Form Active Learningsimple active learning scheme using uncertainty information provided here. KTDQ (determinism transitions assumed here) off-policy algorithm: learnsoptimal policy following different behaviorial policy b. natural questionknow behaviorial policy choose order speed learning. piece responsegiven here.Let current temporal index. system state si , agentchoose action ai . considered algorithm KTD-Q, estimates i1|i1Pi1|i1 available. used approximate uncertainty Q2(si , a)function parameterized i1 state si action a. Let Qi1corresponding variance. action ai chosen according following randombehaviorial policy:Qi1 (si , ai )b(ai |si ) = P(146)aA Qi1 (si , a)totally explorative policy obtained, sense favorises less certain actions.way among others use available uncertainty information, neverthelessshown Section 7 quite efficient compared uniformly random behaviorial policy.However, use wisely variance information general dilemmaexploration exploitation still open perspective.7. Experimentssection provides set classical RL benchmarks aiming comparing KTDvariants state-of-the-art algorithms highlighting different aspects. Atomicbenchmarks chosen order highlight separately unitary properties KTD(see Table 1), quite complex difficult task. Comparedalgorithms TD, SARSA Q-learning function approximation well (recursive518fiKalman Temporal Differences(non)stationarityTsitsiklis chainBoyan chainmazeinverted pendulum(non)linearityXuncertaintyXXXXsample efficiencystochasticityXXXTable 1: Experiments highlighted properties.form of) LSTD (MC-) GPTD. sake reproducibility, parameter valuesprovided experiment. extensions eligibility traces consideredhere, LSTD performs better TD() varying small effect LSTD()performances, according Boyan (1999).7.1 Choosing KTD Parametersorder use (X)KTD framework, parameters chosen: varianceobservation noise (or variance residuals XKTD), priors varianceprocess noise. less common perhaps less intuitive choicelearning rate example, discussed here. evolution noise KTDresidual XKTD translate confidence practitioner ability chosenparameterization represent true value function. known advancevalue function lies hypothesis space (which case example tabularcase), corresponding variance chosen small (but never zero numericalstability reasons). Another way choose variances interpretweighting samples, see Eq. (119) (129). prior 0 initialized valueclose one user thinks optimal, default value, example zerovector. prior P0 quantifies certainty user prior 0 , lower lesscertain. Another way interpret priors consider regularization terms,shown Eq. (119) (129). choose process noise variance open question.knowledge non-stationarity available, used choose matrix.However, knowledge generally difficult obtain beforehand. article,process noise form Pvi = Pi1|i1 used, 1 small positive constant.artificial process noise emphasizes recent observed data, window emphasizedobservations quantified . artificial process noise chosen, seework van der Merwe (2004, ch. 3.5.2) quick survey. following, parameterschosen trial error (for algorithms). Theyre perhaps best ones,orders magnitude correct.7.2 Tsitsiklis Chainfirst experiment aims illustrating ability KTD handle nonlinear parameterizations convergence property. consists 3 states valued Markov chain firstproposed Tsitsiklis Roy (1997). State transits state probability 0.5state 1 probability 0.5 (state 1 transiting state 1 3 equi-probability).reward always zero, therefore optimal value function zero. chainsimple, however nonlinear parameterization causes TD function approximation divergence considered. Let = 0.05, let 3 3 identity matrix519fiGeist & Pietquin3 3 matrix defined as:1= 3212121323212(147)1value function parameterized single scalar , parameterization given(notice V 3 1 vector):V = exp ((M + I) ) V0 V0 = 10 7 3(148)parameterization proposed Tsitsiklis Roy (1997) illustratepossible divergence TD case nonlinear parameterization. optimal parameterobviously = .Figure 2: Tsitsiklis chain.KTD compared TD function approximation. LSTD GPTDconsidered here, unable handle nonlinear parameterization. TD,learning rate chosen equal = 2.103 initial parameter set 0 = 0.KTD, priors set 0 = 0 P0 = 10. observation noise variance setPni = 103 . process noise described Section 7.2 used = 101 . Resultsdepicted Figure 2 shows parameter estimates function numberobserved transitions. TD estimates diverge, expected. KTD handles nonlinearparameterization converges toward good value (despite stochasticity transitions).7.3 Boyan Chainsection KTD XKTD compared two second order value function approximation algorithms, namely (recursive) LSTD (parametric) MC-GPTD simplevalued Markov chain, Boyan (1999) chain. objective threefold: showing sample efficiency, demonstrating bias removal (of XKTD compared KTD) showingnon-stationarity handling.520fierrorKalman Temporal Differences10.90.80.70.60.50.40.30.20.10LSTDMC-GPTDKTDXKTD020406080number episodes100120140Figure 3: Boyan chain.Boyan chain 13-state Markov chain state s0 absorbing state, s1transits s0 probability 1 reward -2, si transits either si1 si2 ,2 12, probability 0.5 reward -3. feature vector (s) statess12 , s8 , s4 s0 respectively [1, 0, 0, 0]T , [0, 1, 0, 0]T , [0, 0, 1, 0]T [0, 0, 0, 1]T .feature vectors states obtained linear interpolation. approximatedvalue function thus V (s) = (s). optimal value function exactly linearfeatures, corresponding optimal parameter vector 1 = [24, 16, 8, 0]T .measure quality algorithm normalized Euclidian distancecurrent parameter vector estimate optimal one k1 k k k computed. Noticeparameterization linear, measuring errortrue estimated value functions, scaling factor. discount factor set1 episodic task. algorithms, prior set P0|0 =identity matrix. Choosing prior fair, yields chooseregularization term algorithms. MC-GPTD KTD variations, residualvariance (observation noise KTD) set i2 = 103 (Pni = 103 ). KTD variations,process noise covariance set RLS (recursive least-squares)-like adaptive processnoise described Section 7.1, Pvi = Pi1|i1 Pi1|i1 denotes varianceparameters, 1 small positive constant, chosen equal 102 . Choosingparameters requires practice, choosing learning ratealgorithms. algorithms initial parameter vector set zero. experimentnon-stationarity handling, change MDP simulated multiplying rewardsten 70th episode (rewards become 20 30 instead 2 3).optimal value function still linear feature vectors, optimal parameter vector2 = 101 MDP change. Learning done 140 episodes, resultsaveraged 300 trials. Results presented Figure 3.MDP change, KTD variations MC-GPTD converge faster LSTD(and equally well). XKTD, well LSTD MC-GPTD, unbiased, contraryKTD. Thus XKTD job designed for, removing bias duestochastic transitions. MDP change, LSTD MC-GPTD fail trackvalue function. KTD manages it, still biased. XKTD tracks value functionwithout biased. GPTD results presented sake readability.521fiGeist & PietquinHowever, behavior KTD one MDP change, fails trackvalue function rewards switch (much like MC-GPTD). experiment showsXKTD performs well KTD, however without bias problem,motivation introducing new algorithm. sample-efficient tracks valuefunction rather converging (non-stationarity handling). arguedforgetting factors added LSTD GPTD. However naturallydone KTD framework, moreover exhibits interesting aspectsillustrated next sections.7.4 Simple MazeKTD framework, parameters modelled random variables.function parameters, approximated value (or Q-) function random function.thus possible compute variance associated value state shownSection 6.1. necessary condition handle exploration-exploitation dilemmavalue (or Q-) function approximation context. section uncertainty informationobtained KTD framework illustrated simple maze problem.2d continuous state space unit square: (x, y) [0, 1]2 . Actions moveleft, right, down, magnitude 0.05 case. reward +1agent leaves maze = 1 x [ 38 , 58 ], 1 agent leaves maze = 1x [0, 38 [] 58 , 1], 0 elsewhere. algorithm KTD-V. parameterization set9 equispaced Gaussian kernels (centered {0, 0.5, 1} {0, 0.5, 1}) standarddeviation 0.5. forgetting factor set 0.9. agent starts random position(x0 , y0 ) x0 sampled Gaussian distribution, x0 N ( 21 , 18 ), y0 sampleduniform distribution, y0 U[0,0.05] . behaviorial policy value functionlearnt going probability 0.9, go one three directionsprobability 0.13 . initial parameter vector set zero, prior P0|0 = 10I,noise covariances Pni = 1 Pvi = 0I.value function learnt quite well, however point here. objectiveillustrate value function uncertainty. learning done 30 episodes,results given Figure 4, shows standard deviation approximated valuefunction state space. Considering x-axis, uncertainty lower middleborder. explained fact learning trajectories occurfrequently center domain. Considering y-axis, uncertainty lowernear upper bound (y = 1) near lower bound (y = 0). explainedfact retro-propagated values less certain. Thus uncertainty informationcomputed KTD-V meaningful simple example, usefulspeed learning, eg., exploration/exploitation dilemma. Another application examplegiven Section 6.2 experimented Section 7.5. GPTD also providesmeaningful uncertainty information (Engel, Mannor, & Meir, 2003). However, farknow, never used practically. likely, uncertainty information cannotderived LSTD (the main reason belief matrix maintainedLSTD symmetric, therefore cannot interpreted variance matrix).522fiKalman Temporal Differences10.90.90.80.80.7position0.70.60.60.50.50.40.40.30.30.20.20.10.10000.10.20.30.4 0.5 0.6x position0.70.80.91Figure 4: Simple maze, uncertainty illustration.7.5 Inverted Pendulumlast experiment inverted pendulum described Lagoudakis Parr (2003).goal compare two value-iteration-like algorithms, namely KTD-Q Qlearning, aim learning directly optimal policy. LSTD GPTD cannotconsidered here: unable handle nonlinearities (the nonlinearity maxoperator here), cannot used Bellman optimality operator. proposedactive learning-like scheme also experimented: uses uncertainty computed KTDspeed convergence.task requires balancing pendulum unknown length mass uprightposition applying forces cart attached to. Three actions allowed: leftforce (-1), right force (+1), force (0). associated state space consists verticalangle angular velocity pendulum. Deterministic transitions computedaccording physical dynamics system, depends current action a:=g sin() ml2 sin(2)/2 50 cos()a4l/3 ml cos2 ()(149)g gravity constant, l mass length pendulum,1mass cart, = m+M. zero reward given long angular position[ 2 , 2 ]. Otherwise, episode ends reward 1 given. parameterizationcomposed constant term set 9 equispaced Gaussian kernels (centered{ 4 , 0, 4 } {1, 0, 1} standard deviation 1) action. Thusset 30 basis functions. discount factor set 0.95.7.5.1 Learning Optimal PolicyFirst, algorithms ability learn optimal policy compared. Q-learning, learningrate set = 0 nn00+1+i 0 = 0.5 n0 = 200, according Lagoudakis Parr523fiGeist & Pietquin(2003). KTD-Q, parameters set P0|0 = 10I, Pni = 1 Pvi = 0I.algorithms initial parameter vector set zero. Training samples collectedonline random episodes. agent starts randomly perturbed state closeequilibrium (0, 0) follows policy selects actions uniformly random.average length episodes 10 steps, algorithms learnttrajectories. Results summarized Figure 5.10000KTD-QQ-learningsteps1000100100100200300400 500 600number episodes7008009001000Figure 5: Inverted pendulum, optimal policy learning.trial, learning done 1000 episodes. Every 50 episodes, learning freezedcurrent policy evaluated. this, agent randomly initialized stateclose equilibrium greedy policy followed end episode;repeated 100 times averaged. Performance measured number stepsepisode. Maximum number steps one episode bounded 3000 steps,corresponds 5 minutes balancing pole without failure. Results Figure 5averaged 100 trials presented semi-log scale.KTD-Q learns optimal policy (that balancing pole maximum numbersteps) asymptotically near-optimal policies learnt tens episodes.results KTD-Q comparable ones LSPI algorithm (see Lagoudakis& Parr, 2003, Fig. 16). number learning episodes, Q-learninglinear parameterization fails learn policy balances poletens time steps. Similar results Q-learning obtained Lagoudakis Parr(2003).7.5.2 Form Active Learningparameters random variables, explained Section 6 illustrated Section 7.4, parameterized Q-function random function, KTD framework allowscomputing variance associated value state. proposed experimentaims using uncertainty information speed learning. learningstill done random trajectories. However, form active learning describedSection 6 considered now. environment initialized randomly before.system given state, standard deviation Q-function computed524fiKalman Temporal Differencesaction. deviations normalized, new action sampled randomly according probabilities weighted deviations. Thus, uncertain actionlikely sampled. average length episodes 11 steps,differ much uniformly random transitions. Consequently slightly helpimprove speed convergence (at 10%, much less real improvement100%). Results summarized Figure 6.30002500KTD-QQ-learningactive KTD-Qsteps2000150010005000050100150200number episodes250300Figure 6: Inverted pendulum, random active learning.trial, learning done 300 episodes. Less episodes considered showspeed convergence, however versions KTD perform well asymptotically.Every 25 episodes, learning freezed current policy evaluated before. Performance measured number steps episode, maximum 3000steps. Results Figure 6 averaged 100 trials. Notice scale longerlogarithmic. compares KTD-Q informed transitions (active KTD-Q) KTD-Quniformly random learning policy Q-learning. comparing two versionsKTD-Q, clear sampling actions according uncertainty speeds convergence.almost doubled first 100 episodes: example, performance 1500 obtained25 episodes active-KTD, whereas needs 50 episodes basicKTD. Thus uncertainty information available thanks KTD frameworkquite useful reinforcement learning.8. Discussion Perspectivessection proposed framework discussed linked related approaches.perspectives also given.8.1 DiscussionApproaches related KTD framework proposed previously. Engel (2005)proposes Gaussian process approach value function approximation. explained before,principle model value function Gaussian process adopt generativemodel linked Bellman evaluation equation. Links Engels approach525fiGeist & Pietquinproposed one discussed throughout paper. Particularly, linear parameterization zero process noise KTD-V reduces GPTD XKTD-V MC-GPTD.However, KTD framework handle non-stationarities (even recognize GPTD couldprobably extended handle too) importantly handles non-linearitiesderivative-free manner, allows considering nonlinear parameterizationsBellman optimality operator. Engels framework allows constructing automaticallyonline kernel-based linear parameterization, advantage compared proposed framework. However, easily incorporated (see Geist et al., 2008used preprocessing step, using online difficult). Kalman filtering strongly linked least-squares minimization (in linear case, formergeneralization later), proposed approach shares similarities LSTD (Bradtke& Barto, 1996). However, take account instrumental variables concept (Soderstrom & Stoica, 2002), used handle stochastic transitions (inKTD framework, done thanks colored noise model). Moreover,shown Section 5.2 XKTD-V (with linear parameterization evolution noise)converges solution LSTD(1). Choi Van Roy (2006) introduced Kalmanfilter designed handle fixed-point approximation case linear parameterization.roughly seen bootstrapping version proposed KTD-V. Insteadobservation equation state-space model (65), following observation equation used:ri + (si+1 )T i1|i1 = (si )T + ni . words, reward consideredobservation, approximation value function used compute pseudoobservation ri + (si+1 )T i1|i1 . update parameters made matchvalue function current state pseudo-observation (bootstrapping approach).Alternatively, seen linear least-squares variation classic TD function approximation algorithm (which combines bootstrapping gradient descent). PhuaFitch (2007) use bank classical Kalman filters learn parameters piecewise linear parameterization value function. roughly seen special caseproposed approach, however differences exist: one filter bank usedparameterization piecewise linear, exploited develop specificitiesalgorithm (notably concerning parameters update) proposed approachmake assumption value function.proposed framework presents interesting aspects. First, supposestationarity. immediate application take account non-stationary MDP (Geist,Pietquin, & Fricout, 2009b), exemplified Section 7.3. even interesting application control case. instance, LSTD algorithm known well behavecombined optimistic policy iteration scheme (-greedy policy example, see Phua& Fitch, 2007), non-stationarities induced fact control learning interlaced. Similarly, Bhatnagar, Sutton, Ghavamzadeh, Lee (2008) prefer TDLSTD actor incremental natural actor-critic approach propose, despitefact less sample efficient. Kalman filtering thus proposed approachesrobust non-stationarity (to certain extent). Quite approaches aiming approximating value function take non-stationary problem account, algorithmPhua Fitch (2007) one them. Another related approach (designed copeinterlacing control learning actor-critic context) two-timescale526fiKalman Temporal Differencesstochastic approximation (for example, see Konda & Tsitsiklis, 2003 Bhatnagar et al.,2008).Second, KTD models parameters random vector, possible compute uncertainty information values, explained Section 6.1 illustrated Section 7.4.used derive form active learning (Sections 6.2 7.5), however uncertainty information could useful deal general problem dilemmaexploration exploitation, following idea done Dearden et al. (1998)Strehl et al. (2006). point that, far know, rather approaches allowsdealing value function approximation value uncertainty time. Oneapproaches GPTD framework Engel (2005), however effective useavailable uncertainty information left future work original publicationsdeveloped far. also noticed without probabilistic statistical approach value function approximation problem uncertainty informationwould difficult obtain.Third, KTD also allows handling nonlinearities. explicitly used KTD-Q(the max operator severe nonlinearity), illustrated Section 7.5. Nonlinearparameterization considered too, illustrated Section 7.2. nonlinear parameterization also used Geist et al. (2008) combined preliminary versionKTD-Q. Moreover, nonlinear parameterization allow compact representationvalue function approximator, could somehow alleviate square complexityproposed framework.KTD shares drawback square Bellman residual minimization-based algorithms (which indeed according Theorem 2): value estimates biasedtransitions dynamic system deterministic, illustrated Section 7.3.Different algorithms propose various methods cope problem. residual algorithms (Baird, 1995), consist minimizing square Bellman residual usinggradient descent, proposed use double sampling order obtain unbiasedestimator. approach two major drawbacks: needs generative model,sample inefficient. LSTD algorithm (Bradtke & Barto, 1996), consistsminimizing Bellman residual least-squares approach, instrumental variable (Soderstrom & Stoica, 2002) used enforce unbiasedness estimator.approach easy extend nonlinearity non-stationarity (and thus online control).Another generic approach remove sort bias proposed Antos et al.(2008). consists introducing auxiliary function (in add value function)role remove bias. resulting optimization problem longer quadratic, consists two interlocked square problems. used linear function approximator,reduces LSTD algorithm, used neural network-based functionapproximator Schneega, Udluft, Martinetz (2007). GPTD framework (Engel,2005) uses colored noise model adapted extend KTD framework.8.2 Conclusion PerspectivesKalman-filter-based Temporal Differences framework introduced copenumber problems time: online learning, sample efficiency, non-stationaritynon-linearity handling well providing uncertainty information. actually527fiGeist & Pietquinsquare-Bellman-minimization-based approach, original framework cannot handle stochastic transitions. thus extended using colored observation noise model. convergence analysis provided deterministic stochastic cases. Finally,various aspects proposed approach experimentally demonstrated classical reinforcement learning benchmarks. Section 7.2 shows ability convergenonlinear parameterizations, Section 7.3 shows colored noise induces unbiasedversion KTD ability handle non-stationarities, Section 7.4 illustrates availableuncertainty information Section 7.5 shows value-iteration-like KTD-Q algorithmwell learning speed-up obtained thanks proposed active learning scheme.State-of-the-art algorithms also considered, KTD compares favorably them.KTD framework presents interesting perspectives. First, XKTD showneffectively remove bias. noticed Engel (2005, ch. 4.5), noise modelsenvisioned (by analogy LSTD() example), however noise models chooseincorporate KTD framework still open questions. theoretical insights bias caused use KTD stochastic problems alsouseful. Also, interesting perspective address off-policy problem consideringcolored noise combine XKTD importance sampling. Another interesting perspective adapt eligibility traces principle proposed framework order fillgap KTD (local update) XKTD (global update relation MonteCarlo) (Geist & Pietquin, 2010a).Second, KTD framework naturally extended partially observablecase. Indeed, inferring state system given past observations problembenefit Bayesian filtering formalism close one proposed. wellknown partially observable MDP (POMDP) expressed MDPstates distributions states POMDP. distributions estimated(by using filtering approach example), naturally taken accountKTD: parameterization already function distribution parameters,extended function distribution states manner.KTD framework handles well nonlinearities. interesting perspective could useneural network based representation value (or Q-) function, let hopecompact representation. way, probably easier address real worldproblems, scaling mandatory.Another difficulty choice different parameters, problemdependent. First noticed choosing type parametersdifficult choosing learning rates example, less usual RL community.Concerning automatic choice parameters, adaptive filtering literaturehelp (Goodwin & Sin, 2009). form adaptive evolution noise usedexperimental part paper, however many solutions envisioned.said before, KTD could interesting alternative TD actor partincremental natural actor-critic algorithms Bhatnagar et al. (2008). preliminaryworks using KTD actor-critic architecture provided Geist Pietquin(2010c). Talking natural gradient, parallel drawn KTDframework natural gradient descent Section 5.1, could benefittheoretical insights.528fiKalman Temporal Differencesvalue uncertainty available framework used form activelearning scheme, planned used address general problemdilemma exploration exploitation, either adapting existing approachesdesigned tabular case (Geist & Pietquin, 2010b) developing new methods.Unscented Kalman filtering, work based, linked nonlinear leastsquares problems solved using statistical linearization approach (Geist & Pietquin, 2010e).Underlying ideas used extend LSTD algorithm nonlinear parameterizationswell Bellman optimality operator (Geist & Pietquin, 2010d).Finally, planned comparison state-of-the-art, theoreticallyexperimentally. Ultimately application ideas real world problem neededasses utility. Concerning last point, plan apply proposed frameworkdialogue management problem.Acknowledgmentsauthors wish thank European Community (FP7/2007-2013, grant agreement216594, CLASSiC project : www.classic-project.org) Region Lorraine financialsupport. Matthieu Geist also wish thank ArcelorMittal Research financial support2006-2009 PhD thesis.ReferencesAntos, A., Szepesvari, C., & Munos, R. (2008). Learning near-optimal policies Bellmanresidual minimization based fitted policy iteration single sample path. MachineLearning, 71 (1), 89129.Baird, L. C. (1995). Residual Algorithms: Reinforcement Learning Function Approximation. Proceedings International Conference Machine Learning (ICML95), pp. 3037.Bertsekas, D. P., & Tsitsiklis, J. N. (1996). Neuro-Dynamic Programming. Athena Scientific.Bhatnagar, S., Sutton, R. S., Ghavamzadeh, M., & Lee, M. (2008). Incremental NaturalActor-Critic Algorithms. Proceedings Twenty-First Annual ConferenceAdvances Neural Information Processing Systems (NIPS), Vancouver, Canada.Bishop, C. M. (1995). Neural Networks Pattern Recognition. Oxford University Press,New York, USA.Boyan, J. A. (1999). Technical Update: Least-Squares Temporal Difference Learning. Machine Learning, 49 (2-3), 233246.Bradtke, S. J., & Barto, A. G. (1996). Linear Least-Squares Algorithms TemporalDifference Learning. Machine Learning, 22 (1-3), 3357.Chen, Z. (2003). Bayesian Filtering : Kalman Filters Particle Filters, Beyond.Tech. rep., Adaptive Systems Lab, McMaster University.529fiGeist & PietquinChoi, D., & Van Roy, B. (2006). Generalized Kalman Filter Fixed Point Approximation Efficient Temporal-Difference Learning. Discrete Event Dynamic Systems,16, 207239.Dearden, R., Friedman, N., & Russell, S. J. (1998). Bayesian q-learning. AAAI/IAAI,pp. 761768.Engel, Y. (2005). Algorithms Representations Reinforcement Learning. Ph.D. thesis,Hebrew University.Engel, Y., Mannor, S., & Meir, R. (2003). Bayes Meets Bellman: Gaussian ProcessApproach Temporal Difference Learning. Proceedings International Conference Machine Learning (ICML 2003), pp. 154161.Engel, Y., Mannor, S., & Meir, R. (2005). Reinforcement Learning Gaussian Processes.Proceedings International Conference Machine Learning (ICML-05).Geist, M., & Pietquin, O. (2010a). Eligibility Traces Colored Noises. ProceedingsIEEE International Conference Ultra Modern Control systems (ICUMT2010), Moscow (Russia). IEEE.Geist, M., & Pietquin, O. (2010b). Managing Uncertainty within Value Function Approximation Reinforcement Learning. Active Learning Experimental Designworkshop (collocated AISTATS 2010), Sardinia, Italy.Geist, M., & Pietquin, O. (2010c). Revisiting natural actor-critics value functionapproximation. Torra, V., Narukawa, Y., & Daumas, M. (Eds.), Proceedings7th International Conference Modeling Decisions Artificial Intelligence (MDAI2010), Vol. 6408 Lecture Notes Artificial Intelligence (LNAI), pp. 207218, Perpinya (France). Springer Verlag - Heidelberg Berlin.Geist, M., & Pietquin, O. (2010d). Statistically Linearized Least-Squares Temporal Differences. Proceedings IEEE International Conference Ultra Modern Controlsystems (ICUMT 2010), Moscow (Russia). IEEE.Geist, M., & Pietquin, O. (2010e). Statistically Linearized Recursive Least Squares.Proceedings IEEE International Workshop Machine Learning SignalProcessing (MLSP 2010), Kittila (Finland).Geist, M., Pietquin, O., & Fricout, G. (2008). Bayesian Reward Filtering. et al., S. G.(Ed.), Proceedings European Workshop Reinforcement Learning (EWRL2008), Vol. 5323 Lecture Notes Artificial Intelligence, pp. 96109. Springer Verlag,Lille (France).Geist, M., Pietquin, O., & Fricout, G. (2009a). Kalman Temporal Differences: deterministic case. Proceedings IEEE International Symposium Adaptive DynamicProgramming Reinforcement Learning (ADPRL 2009), Nashville, TN, USA.Geist, M., Pietquin, O., & Fricout, G. (2009b). Tracking Reinforcement Learning.Proceedings 16th International Conference Neural Information Processing(ICONIP 2009), Bangkok (Thailande). Springer.Geramifard, A., Bowling, M., & Sutton, R. S. (2006). Incremental Least-Squares TemporalDifference Learning. Proceedings 21st Conference, American AssociationArtificial Intelligence, pp. 356361.530fiKalman Temporal DifferencesGill, P. E., Golub, G. H., Murray, W., & Saunders, M. A. (1974). Methods ModifyingMatrix Factorization. Mathematics Computation, 28 (126), 505535.Goodwin, G. C., & Sin, K. S. (2009). Adaptive Filtering Prediction Control. DoverPublications, Inc., New York, NY, USA.Jo, S., & Kim, S. W. (2005). Consistent Normalized Least Mean Square FilteringNoisy Data Matrix. IEEE Transactions Signal Processing, 53 (6), 21122123.Julier, S. J., & Uhlmann, J. K. (2004). Unscented filtering nonlinear estimation. Proceedings IEEE, 92 (3), 401422.Kakade, S. (2001). natural policy gradient. Advances Neural Information ProcessingSystems 14 [Neural Information Processing Systems (NIPS 2001), pp. 15311538,Vancouver, British Columbia, Canada.Kalman, R. E. (1960). New Approach Linear Filtering Prediction Problems.Transactions ASMEJournal Basic Engineering, 82 (Series D), 3545.Kolter, J. Z., & Ng, A. Y. (2009). Regularization Feature Selection Least-SquaresTemporal Difference Learning. proceedings 26th International ConferenceMachine Learning (ICML 2009), Montreal Canada.Konda, V. R., & Tsitsiklis, J. N. (2003). actor-critic algorithms. SIAM J. ControlOptim., 42 (4), 11431166.Lagoudakis, M. G., & Parr, R. (2003). Least-Squares Policy Iteration. Journal MachineLearning Research, 4, 11071149.Peters, J., Vijayakumar, S., & Schaal, S. (2005). Natural Actor-Critic. et al., J. G. (Ed.),Proceedings European Conference Machine Learning (ECML 2005), LectureNotes Artificial Intelligence. Springer Verlag.Phua, C. W., & Fitch, R. (2007). Tracking Value Function Dynamics Improve Reinforcement Learning Piecewise Linear Function Approximation. ProceedingsInternational Conference Machine Learning (ICML 07).Precup, D., Sutton, R. S., & Singh, S. P. (2000). Eligibility Traces Off-Policy PolicyEvaluation. Proceedings Seventeenth International Conference MachineLearning (ICML00), pp. 759766, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.Puterman, M. L. (1994). Markov Decision Processes: Discrete Stochastic Dynamic Programming. Wiley-Interscience.Schneega, D., Udluft, S., & Martinetz, T. (2007). Improving optimality neural rewardsregression data-efficient batch near-optimal policy identification.. de Sa, J. M.,Alexandre, L. A., Duch, W., & Mandic, D. P. (Eds.), ICANN, Vol. 4668 LectureNotes Computer Science, pp. 109118. Springer.Schoknecht, R. (2002). Optimality Reinforcement Learning Algorithms Linear Function Approximation. Proceedings Conference Neural Information Processing Systems (NIPS 15).Sigaud, O., & Buffet, O. (Eds.). (2010). Markov Decision Processes Artificial Intelligence. Wiley - ISTE.531fiGeist & PietquinSimon, D. (2006). Optimal State Estimation: Kalman, H Infinity, Nonlinear Approaches(1. Auflage edition). Wiley & Sons.Strehl, A. L., Li, L., Wiewiora, E., Langford, J., & Littman, M. L. (2006). Pac modelfree reinforcement learning. Proceedings 23rd International ConferenceMachine Learning (ICML 2006), pp. 881888, Pittsburgh, PA, USA.Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction (3rd edition). MIT Press.Sutton, R. S., Koop, A., & Silver, D. (2007). role tracking stationary environments. ICML 07: Proceedings 24th international conference Machinelearning, pp. 871878, New York, NY, USA. ACM.Soderstrom, T., & Stoica, P. (2002). Instrumental variable methods system identification.Circuits, Systems, Signal Processing, 21, 19.Tsitsiklis, J. N., & Roy, B. V. (1997). analysis temporal-difference learningfunction approximation. IEEE Transactions Automatic Control, 42, 674690.van der Merwe, R. (2004). Sigma-Point Kalman Filters Probabilistic Inference Dynamic State-Space Models. Ph.D. thesis, OGI School Science & Engineering, OregonHealth & Science University, Portland, OR, USA.Yu, H., & Bertsekas, D. P. (2007). Q-Learning Algorithms Optimal Stopping BasedLeast Squares. Proceedings European Control Conference, Kos, Greece.532fiJournal Artificial Intelligence Research 39 (2010) 663-687Submitted 6/10; published 11/10Effective Algorithm Phase TransitionsDirected Hamiltonian Cycle ProblemGerold Jagergej@informatik.uni-kiel.deComputer Science Institute,Christian-Albrechts-University Kiel,D-24118 Kiel, GermanyWeixiong Zhangweixiong.zhang@wustl.eduDepartment Computer Science Engineering,Washington University,St. Louis, Missouri 63130, United StatesAbstractHamiltonian cycle problem (HCP) important combinatorial problemapplications many areas. among first problems used studying intrinsic properties, including phase transitions, combinatorial problems. thorough theoreticalexperimental analyses made HCP undirected graphs, limitedamount work done HCP directed graphs (DHCP). main contribution work effective algorithm DHCP. algorithm exploresexploits close relationship DHCP Assignment Problem (AP)utilizes technique based Boolean satisfiability (SAT). combining effective algorithms AP SAT, algorithm significantly outperforms previous exact DHCPalgorithms, including algorithm based award-winning Concorde TSP algorithm.second result current study experimental analysis phase transitionsDHCP, verifying refining known phase transition DHCP.1. Introductionundirected graph G = (V, E) Hamiltonian contains Hamiltonian cycle (HC),cycle visits vertex exactly once. Given graph, Hamiltonian cycle problem(HCP) find HC prove HC exists graph. decision versionHCP among first problems proven N P-complete (Karp, 1972). HCPwell-known problem many applications different areas, e.g., Hamiltonian cyclegame game theory (Stojakovic & Szabo, 2005), problem finding knights tourchessboard artificial intelligence (Henderson & Apodaca, 2008), DNA PhysicalMapping biology (Grebinski & Kucherov, 1996). Much research doneHCP undirected graphs. reviews, see work Bondy (1995), Christofides (1975),Chvatal (1985), Gould (1991), Vandegriend (1998), Gutin Moscato (2000).particular, many algorithms developed HCP (Angluin & Valiant, 1979;Bollobas, Fenner & Frieze, 1987; Frieze, 1988a; Posa, 1976; Vandegriend, 1998), reviewedStony Brook Algorithm Repository (Skiena, 2008). One effective algorithmHCP based related Traveling Salesman Problem (TSP) undirected weightedgraph, problem finding HC minimum total weight.c2010AI Access Foundation. rights reserved.fiJager & ZhangHCP also canonical problem understanding intrinsic properties combinatorial problems. One problem property called phase transition. Considerundirected graph Gn,m edges randomly chosen possible n(n 1)/2 edgesn vertices. expected keeping size n, i.e., number vertices,constant increasing number edges m, probability random graph Gn,mHamiltonian increases 0 1. Surprisingly, probability HamiltonianGn,m exhibits sharp, dramatic transition 0 1, transition occurs approximately = dc n (log n + log log n)/2c (Bollobas, 1985; Cheeseman, Kanefsky &Taylor, 1991; Komlos & Szemeredi, 1983). Furthermore, experimentally shownconstant c 1.08 1.10, probability Gn,m Hamiltonian1/2 (Vandegriend & Culberson, 1998). Phase transitions HCP also studieddifferent control parameters, example, called general constrainednessparameter (Frank, Gent & Walsh, 1998). phase transition result HCP motivated substantial amount research phase transitions combinatorial problems,particularly TSP (Zhang & Korf, 1996) Boolean satisfiability (Monasson, Zecchina,Kirkpatrick & Selman, 1999).study consider HCP directed graphs, call directed HCP,DHCP short. addition known applications HCP mentioned above,interesting application DHCP DHCP heuristics used solveBottleneck TSP (Kabadi & Punnen, 2002). contrast extensive amount workHCP undirected graphs, research DHCP rather limited (Angluin& Valiant, 1979; Bang-Jensen & Gutin, 2008; Kelly, 2007). first exact algorithmDHCP developed Martello (1983). algorithm outputs fixed number hHCs reports cannot find h HCs given directed graph. setting h = 1,gives rise algorithm DHCP. recent years, algorithms based SATencoding introduced problem, e.g., absolute encoding (Hoos, 1999)relative encoding (Prestwich, 2003; see also Velev & Gao, 2009). Furthermore,probabilistic heuristic DHCP complexity O(n1.5 ) proposed (Frieze, 1988b).shown random class Gn,m probability, given instanceHC found algorithm therefore exists, changes 0 1, n growsinfinity = n log n+cn, c constant. DHCP, phase transition resultsimilar HCP obtained well, namely phase transition occurs= dc n (log n + log log n)c (McDiarmid, 1980), constant c expectedclose 1.Note research TSP also alluded DHCP algorithm. Usingtechnique 2-point reduction, asymmetric TSP (ATSP) distance citycity j may necessarily equal j converted symmetricTSP, number vertices doubled (Jonker & Volgenant, 1983). Usingtransformation, determine whether directed graph Hamiltonian solvingsymmetric TSP using renowned Concorde algorithm (Applegate, Bixby, Chavatal &Cook, 2005, 2006). Concorde solved many large benchmark instances (Cook, 2010),including TSP instance 85, 900 cities (Applegate et al., 2009), datelargest solved practical TSP instance.main contribution paper effective exact algorithm DHCP.algorithm, utilize methods two well-known combinatorial problems, i.e., Assign664fiAlgorithm Directed Hamiltonian Cyce Problemment Problem (AP) Boolean satisfiability (SAT); therefore denote algorithmAP-SAT. Using random graphs many real world instances, experimentally compareAP-SAT algorithm DHCP algorithm Martello (1983), TSP based approach takes advantage TSP solver Concorde (Applegate et al., 2005, 2006)above-mentioned SAT encodings DHCP (Hoos, 1999; Prestwich, 2003).results show AP-SAT algorithm significantly outperforms algorithms.second contribution experimental study refinement known phasetransition result existence HC random directed graph (McDiarmid, 1980),similarly done HCP (Vandegriend & Culberson, 1998).2. AlgorithmConsider directed unweighted graph G = (V, E) nodes V edges E.purpose solving DHCP, consider problem determining whetherexists collection cycles, may necessarily complete cycles, visitingvertex exactly once. call problem directed Assignment Problem DAPshort. algorithm explores exploits intrinsic relationship DHCPDAP. precisely, AP-SAT algorithm searches HC space DAPsolutions. first solves DAP. DAP solution forms HC, DAP solutionexists, algorithm terminates. DAP solver returns solution HC,algorithm tries patch subcycles solution HC using well-knownKarp-Steele patching method (Karp & Steele, 1985). HC found either, DAPpatching steps iterated, difference another DAP solution mightfound. cases considered study, algorithm find HCdetermine solution exists two steps. algorithm fails solveproblem iterative steps, attempts enumerate DAP solutionsformulating DAP Boolean satisfiability problem repeatedly solving problemusing SAT solver adding constraints eliminate DAP solutionsencountered. discuss details steps rest section.2.1 Solving Assignment ProblemGiven n vertices matrix C = (cij )1i,jn Rn,n costs pairsvertices, nAssignment Problemo(AP) find vertex permutationPn= arg mini=1 ci,(i) : n , n set permutations {1, . . . , n}.Note AP solution viewed collection cycles visiting vertex exactlyonce.Many algorithms developed AP (Bertsekas, 1981; Goldberg & Kennedy,1995; Jonker & Volgenant, 1987). (For experimental comparison AP algorithms seeDellAmico & Toth, 2000.) efficient one Hungarian algorithm, basedKonig-Egervarys theorem complexity O(n3 ). AP-SAT algorithmuse implementation Hungarian algorithm Jonker Volgenant (1987, 2004).665fiJager & Zhangunweighted directed graph G = (V, E), DAP solved applying APalgorithm AP instance defined matrix C = (cij )1i,jncij0,1,=1,(i, j) E, 6= j(i, j)/ E, =6 j= jmap costs arcs G 0 costs remaining arcs 1.AP algorithm returns solution cost 0, DAP solution G, since every arctaken AP solution arc G. hand, returns solution costgreater 0, DAP solution G least one arc solutionbelong G.first step AP-SAT algorithm DAP algorithm. HC G, oneexists, solution DAP. distinguish three cases end firststep:cost AP solution greater 0, G HC, DHCPinstance solved solution.AP solution cost 0 solution consists one cycle, foundHC DHCP instance also solved.AP solution cost 0 AP solution one cycle, cannotdetermine, based AP solution, whether G Hamiltonian.continue next steps AP-SAT algorithm.2.2 Karp-Steele PatchingDAP solution provide definitive answer problem, i.e., caseAP solution cost 0 AP solution contains one cycle, continuesearch HC G. first patch subcycles attempt form HC, useKarp-Steele patching (KSP) purpose, effective ATSP heuristic (Glover,Gutin, Yeo & Zverovich, 2001; Goldengorin, Jager & Molitor, 2006; Karp & Steele, 1985).operation patching two cycles C1 C2 AP solution defined follows:two fixed arcs (v1 , w1 ) C1 (v2 , w2 ) C2 first deleted two arcs (v1 , w2 )(v2 , w1 ) joining two cycles added. cost patching C1 C2 using (v1 , w2 )(v2 , w1 ) equal(C1 , C2 ) = c(v1 , w2 ) + c(v2 , w1 ) (c(v1 , w1 ) + c(v2 , w2 ))i.e., (C1 , C2 ) difference total cost inserted arcs total costdeleted arcs. step choose patch two cycles largestnumber vertices. two cycles, two arcs chosen waypatching cost minimum among possible arc pairs. k 2 cycles,repeat patching step k 1 times form one cycle end. apply KSPAP instance defined Section 2.1. patching procedure provides HC, AP-SATalgorithm terminated. Otherwise, continue next step.666fiAlgorithm Directed Hamiltonian Cyce Problem2.3 Solving Variant APsDAP may multiple solutions, DAP solutions may HCs.increase chance finding HC apply AP step multiple times, sincecomputational cost AP KSP algorithms low. key avoid findingDAP solution again. accomplish this, slightly alter arc costscorresponding AP instance find DAP solutions, enhanced KSPneeded, increase possibility finding HC. words, add perturbationcomponent create multiple variant AP instances boost overall chance findingHC. Note worst case DHCP instance contains HC, procedureproductive.main idea create variant AP instance reduce chance subcyclescurrent AP solution chosen subsequent rounds solving APs.done perturbing costs arcs G follows. arccurrent DAP solution increase cost one. create AP instance differentSection 2.1, generalize AP instance follows. Let ci,j cost arc(i, j) E, let:= n max {ci,j | (i, j) E} + 1i.e., greater n times largest cost arc G. set costsedges E . AP instance Section 2.1 special case AP instance,costs ci,j arcs (i, j) E 0. critical notice DAP solutions,including HC, must costs less . before, solution contains HC,algorithm terminates; otherwise, subcycles patched using KSP possiblyfind HC. repeat step multiple times arc, appeared manyprevious DAP solutions, unlikely appear next DAP solution,arc, never occurred previous DAP solution, likely appearnext DAP solution.Let r maximal number AP/KSP calls, i.e., number variant AP instancessolved. observed experiments r = n (see step 3 pseudo codeappendix) good choice. discussed detail Section 3.1.2.4 Implicitly Enumerating DAP Solutions Using SATAP patching based steps discussed may still miss solution DHCPinstance. consider implicitly enumerate DAP solutions findingsolution DHCP, exists. idea systematically rule DAPsolutions discovered far search. end, first formulateDAP Boolean satisfiability (SAT) problem (Dechter, 2003) forbid DAP solutionadding new constraints SAT model. elementary technique adding newconstraints purpose enumerating SAT solutions also appliedgeneral SAT problem (e.g., see Jin, Han & Somenzi, 2005). Notice cannoteasily done AP framework constraints cannot properly addedAP. Moreover, take advantage research effort devotedSAT, particular, use effective SAT solver called MiniSat (Een & Sorensson,2003, 2010).667fiJager & Zhangconjunctive normal form (CNF), SAT instance set Boolean variablesconjunction clauses, disjunction literals Booleanvariables negations. clause satisfied one literals True,instance satisfied clauses satisfied. SAT problem find truthassignment variables satisfy clauses satisfiable, determineassignment exists. SAT first problem shown N P-complete (Cook, 1971;Garey & Johnson, 1979; Karp, 1972).formulate DAP SAT. solution DAP must obey followingrestrictions:vertex i, = 1, . . . , n, exactly one arc (i, j), 6= j, exists DAP solution.vertex i, = 1, . . . , n, exactly one arc (j, i), j 6= i, exists DAP solution.first introduce integer decision variable xi,j arc (i, j) E xi,j = 1 holdsarc (i, j) appears DAP solution. represent constraintsfollowing integer linear program (ILP).( Pnxi,j = 1 = 1, . . . , nPj=1,(i,j)E(1)ni=1,(i,j)E xi,j = 1 j = 1, . . . , nxi,j {0, 1} (i, j) E. thus total 2n constraints. Noteuse variables, one variable arc graph, substantiallysmaller n2 variables sparse graphs. represent integer linear program (1)SAT model similar work Lynce Marques-Silva (2006), replaceinteger variables xi,j Boolean variables yi,j . enforce 2n restrictions SATformulation, need introduce constraints clauses. One restriction (1) meansexactly one n involved Boolean variables vertex set Truerest must False. represent this, introduce 2n2 auxiliary variablesz1 , z2 , . . . , z2n2 , n zs one restriction. Without loss generality, considerfirst restriction, z1 , z2 , . . . , zn associated. use zk represent least oney1,1 , y1,2 , . . . , y1,k True. Precisely, z variables defined follows.z1 = y1,1 equivalently (y1,1 z1 ) (y1,1 z1 ).zk = y1,k zk1 equivalently (zk y1,k ) (zk zk1 ) (zk y1,k zk1 )k = 2, 3, . . . , n.addition, need enforce one y1,i = 1, 2, . . . , n True.means y1,k True, none y1,i < k True. formulatedzk1 y1,k k = 2, 3, . . . , n.Finally, zn must True. restrictions (1) represented similarly.SAT based representation allows us exclude non-Hamiltonian DAP solutionpreviously found search. done introducing new clauses explicitly668fiAlgorithm Directed Hamiltonian Cyce Problemforbidding subcycles solution. Let subcycle (v1 , v2 , . . . , vk , v1 ).add clauseyv1 ,v2 . . . yvk1 ,vk yvk ,v1current SAT instance. result, updated SAT instance satisfiable,meaning corresponding DHCP instance contain HC, gives risenew DAP solution, allow previous DAP solution.summary, AP- patching-related steps failed find solution, APSAT algorithm transforms problem instance SAT instance. collectsprevious DAP solutions, includes least two subcycles, excludessubcycles DAP solutions adding new clauses described above.resulting SAT model solved. SAT model satisfiable, DHCPalgorithm terminates result problem instance Hamiltonian.SAT model satisfiable solution one cycle, algorithm stops HC.SAT model satisfiable, solution one subcycle, new clausesintroduced SAT model rule solution, algorithm repeatssolve revised formula. Since finite number DAP solutions, algorithmterminates. worst case DAP solutions contain HC, SAT partalgorithm enumerate DAP solutions. overview, outline mainsteps AP-SAT algorithm pseudo code appendix.2.5 General Remarkspresent experimental results, like comment method proposedhelp appreciate features.1. AP-SAT algorithm consists three main components, namely AP step,KSP step SAT step. might interesting know components important one. this, distinguish completenessefficacy algorithm. necessary step completeness SATstep Section 2.4. step without previous steps leads also correct DHCPalgorithm. hand, AP-SAT algorithm effective APKSP steps called often SAT step called calledtimes. example, instance DAP solution exists existing HCfound previous steps, SAT part invoked all. Indeed,experiments showed SAT step invoked test instances.Regarding relative time needed AP KSP steps, consider density problem instances. instance small number arcs,cases HC solution, also DAP solution.case algorithm terminates first AP step need makeKSP call. hand, instance large number arcs requiremany AP steps, many DAP solutions may exist HCs, thus HCsolution may found KSP. expected behavior could validatedexperiments: time KSP steps smaller instances small numberarcs, larger instances large number arcs (see Figure 4).669fiJager & Zhang2. AP-SAT algorithm also able solve HCP special case DHCP,less effective case. reason symmetric case, arcreverse arc often present DAP solution, resulting many small cycles twovertices solution. Thus general enumerate large number DAPsolutions. worst case HC exists, DAP solutionsenumerated, giving rise long running time.3. easily revise AP-SAT algorithm identify HCs directed graph.Finding solutions desirable many applications, e.g., problem finding knights tour chessboard (Henderson & Apodaca, 2008; Kyek, Parberry &Wegener, 1997). algorithms problem, see already mentioned algorithmMartello (1983) algorithm Frieze Suen (1992). revision worksfollows. HC exists, algorithm remains same. Consider caseleast one HC exists. first HC found, original AP-SAT algorithmterminates case. revised algorithm stage saves first HC,continues search next HC. pseudo code appendix,need replace STOP SAVE rows 8, 11, 23. Noterevised algorithm, SAT part always invoked least one HC exists.Furthermore like original AP-SAT algorithm revised algorithm works alsosymmetric case, less effective.4. AP-SAT algorithm used restart scheme, i.e., repeatedly solved series APinstances, derived modifying costs arcs appeared previousAP solution. Although restart scheme random restart scheme,developed constraint problems artificial intelligence (Gomes, Selman & Kautz,1998), follow design principle trying avoid encountersolutions subsequent runs, two schemes fundamentally different.name indicated, random restart scheme depends random choices madevariable value selections process search variable assignmentconstraint problem. contrast, restart scheme random; arcscurrent AP solution receive higher costs subcycles current APsolution less likely chosen again. words, restart scheme usedsomewhat deterministic depends solution structures problem.5. method used exclude subcycles solution current DAP instance subsequent SAT solving process follows principle popular ideaadding no-good constraints constraint satisfaction problem (Frost & Dechter,1994; Richards & Richards, 2000; Zhang, Madigan, Moskewicz & Malik, 2001). Specifically, subcycles forbidden introducing additional constraints.3. Experimental Resultsimplemented AP-SAT algorithm, DHCP algorithm Martello (1983),DHCP algorithms based absolute SAT encoding (Hoos, 1999) relativeSAT encoding (Prestwich, 2003) C++ compared algorithm basedaward-winning Concorde TSP program (Applegate et al., 2005, 2006). al670fiAlgorithm Directed Hamiltonian Cyce Problemgorithm Martello implemented version terminates whenever HC,one exists, found. SAT based algorithms used AP solver JonkerVolgenant (1987, 2004) MiniSat SAT solver Een Sorensson (2003, 2010).apply Concorde, DHCP instance first transformed asymmetric TSP instance transformation Section 2.1 symmetric TSP instance2-point reduction method (Jonker & Volgenant, 1983). implementation, 2-pointreduction works follows graph G = (V, E) V = {v1 , v2 , . . . , vn }.1. Make copy vertices v1 , v2 , . . . , vn , create vertex set V 0 := {v10 , v20 ,. . . , vn0 }.2. Define new complete graph G0 vertex set V V 0 (symmetric) costfunction c0 : V V 0 {0; 1; 2}0 1 = j n1 1 6= j n, (vi , vj ) Ec0 (vi , vj0 ) :=2 1 6= j n, (vi , vj )/Ec0 (vi , vj ) := 2 1 6= j nc0 (vi0 , vj0 ) := 2 1 6= j ndirected HC exists G TSP tour cost n exists G0 . Notecontrast general version 2-point reduction value requiredhere. also tried 3-point reduction method, principle similar 2-pointreduction, uses two (instead one) copies vertex set uses cost values{0; 1}. details 3-point reduction, see work Karp (1972).experimental results, included here, showed 3-point reduction runsslower average 2-point reduction. Therefore, rest comparison,consider 2-point reduction.2-point reduction, Concorde started worst possible solution valueinitial upper bound terminated soon lower bound indicates HCimpossible.addition comparison, also experimentally analyzed AP-SAT algorithmincluding asymptotic behavior, applied study phase transitions DHCP.experiments carried PC Athlon 1900MP CPU 2 GBmemory.3.1 Comparison DHCP Algorithmsexperiments first tested random asymmetric instances Gn,m parametersn = 100, 200, 400, 800, 1600 = dcn(log n+log log n)c c = 0.5, 0.6, . . . , 1.90, 2.00.n c generated 50 random instances measured CPU timeinstances. Furthermore, tested real-world random instances Dimacschallenge (Johnson et al., 2002, 2008) non-random instances (Reinelt, 1991, 2008).Whereas Tsplib contains 26 single asymmetric TSP instances sizes 17 443,Dimacs challenge contains 10 asymmetric problem generators called amat, coin, crane,disk, rect, rtilt, shop, stilt, super, tmat. Using generators generated 24671fiJager & Zhanginstances, 10 100 vertices, 10 316 vertices, 3 1000 vertices, 1 3162vertices, leading 240 instances (for 10 problem generators 24 instances) overall.transform asymmetric TSP instances back DHCP instances, seems reasonablekeep arcs small weights ignoring ones large weights.words, generate DHCP instance chose smallest arcs correspondingasymmetric TSP instance. interesting note difficult problem instancesproblems Tsplib Dimacs appear degree parameter c around2, value used experiments. contrast, difficult instancesrandom graphs occur degree parameter c 0.9 (see Section 3.3).investigate variation running time, present one subfigure problemclass, i.e., 5 random classes sizes 100, 200, 400, 800, 1600, 10Dimacs classes amat, coin, crane, disk, rect, rtilt, shop, stilt, super, tmat. y-axisgives average times plus 95% confidence intervals, values seconds.random classes x-axis describes degree parameter c, Dimacsclasses describes size n. results random instances summarizedFigure 1 Dimacs instances Figures 2, 3. Tsplib class consists26 single instances completely different sizes, structures difficulties, presentresults Table 1. experiment single algorithm single instance requiredleast 1 hour terminate due high memory requirement, set CPUtimes 3600 seconds.Figures 1 3 Table 1 show two SAT encodings competitiveAP-SAT, Concorde Martello algorithm. Furthermore, AP-SAT Concordestable Martello algorithm. Concorde failed solve 16 Dimacs instances(3 coin, 3 crane, 4 rect, 5 stilt, 1 super types) within maximal allowed time 1 hour,whereas AP-SAT algorithm failed 7 instances. Among 7 instancesAP-SAT failed, 6 stilt types, remaining instance (super3162) couldsolved increased maximal allowed time 1 hour 4 hours (see Table 2).Martello algorithm unable solve instances 800 larger sizehigh memory requirement. instances, failed 1 random instance size400 degree parameter 0.9, 51 Dimacs instances (10 coin, 12 crane, 11 disk, 11 rect,7 stilt types), 9 Tsplib instances (see Table 1). Nevertheless, Martello algorithmoutperformed Concorde smaller easier instances, indicating formerworse asymptotic running time. Overall, observed AP-SAT algorithmclearly superior four algorithms. Among 4266 instances (4000 randominstances, 240 Dimacs instances 26 Tsplib instances) tested, 13 instances,one four algorithms faster AP-SAT. problem instances include 4random instances, namely 1 size 400 degree parameter 0.9, 3 size 800 degreeparameters 0.8, 0.9, 0.9, respectively, 8 Dimacs instances, namely coin1000-2, rect316-9,stilt100-1, stilt100-5, stilt100-6, stilt100-7, stilt100-8, stilt316-2, Tsplib instancebr17 (see Table 1).672fiAlgorithm Directed Hamiltonian Cyce ProblemFigure 1: Comparison algorithms random instances.Size 200APSATConcordeMartelloAbs. EncodingRel. Encoding10,0001,0001001010.1APSATConcordeMartello10,000Average running timeAverage running timeSize 1001,0001001010.10.010.010.0010.0010.00010.00010.5 0.6 0.7 0.8 0.9 1 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 20.5 0.6 0.7 0.8 0.9 1 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2Degree parameter cDegree parameter cSize 400Size 800APSATConcordeMartello1001010.10.01APSATConcorde10,000Average running time1,0001,0001001010.10.010.0010.0010.00010.00010.5 0.6 0.7 0.8 0.9 1 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 20.5 0.6 0.7 0.8 0.9 1 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2Degree parameter cDegree parameter cSize 1600APSATConcorde10,000Average running timeAverage running time10,0001,0001001010.10.010.0010.00010.5 0.6 0.7 0.8 0.9 1 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2Degree parameter c673fiJager & ZhangFigure 2: Comparison algorithms Dimacs instances, part 1.coin instancesAPSATConcordeMartelloAbs. EncodingRel. Encoding10,0001,0001001010.1Average running timeAverage running timeamat instancesAPSATConcordeMartelloAbs. EncodingRel. Encoding10,0001,0001001010.10.010.010.0010.0010.000110031610000.00013162100316Size10,0001,0001001010.1APSATConcordeMartelloAbs. EncodingRel. Encoding10,0001,0001001010.10.010.010.0010.00110031610000.00013162100316Size1,0001001010.1Average running timeAverage running time10,000APSATConcordeMartelloAbs. EncodingRel. Encoding10,0001,0001001010.10.010.010.0010.0013163162rtilt instancesAPSATConcordeMartelloAbs. EncodingRel. Encoding1001000Sizerect instances0.00013162disk instancesAPSATConcordeMartelloAbs. EncodingRel. EncodingAverage running timeAverage running timecrane instances0.00011000Size10000.00013162Size1003161000Size6743162fiAlgorithm Directed Hamiltonian Cyce ProblemFigure 3: Comparison algorithms Dimacs instances, part 2.stilt instancesAPSATConcordeMartelloAbs. EncodingRel. Encoding10,0001,0001001010.1Average running timeAverage running timeshop instancesAPSATConcordeMartelloAbs. EncodingRel. Encoding10,0001,0001001010.10.010.010.0010.0010.000110031610000.00013162100316Size10,0001,0001001010.1APSATConcordeMartelloAbs. EncodingRel. Encoding10,0001,0001001010.10.010.010.0010.0011003163162tmat instancesAPSATConcordeMartelloAbs. EncodingRel. EncodingAverage running timeAverage running timesuper instances0.00011000Size10000.00013162Size1003161000Size6753162fiJager & ZhangTable 1: Comparison algorithms Tsplib instances.Instance (Size)AP-SATConcordebr17 (17)ftv33 (34)ftv35 (36)ftv38 (39)p43 (43)ftv44 (45)ftv47 (48)ry48p (48)ft53 (53)ftv55 (56)ftv64 (65)ft70 (70)ftv70 (71)kro124p (100)ftv100 (101)ftv110 (111)ftv120 (121)ftv130 (131)ftv140 (141)ftv150 (151)ftv160 (161)ftv170 (171)rbg323 (323)rbg358 (358)rbg403 (403)rbg443 (443)4.050000000000000000000000.010.020.020.020.070.130.150.230.420.190.160.071.560.090.230.870.293.740.562.420.83.040.841.131.142.134.8113.554.526.73Running time algorithmMartello Absolute Encoding66.39000000360000.010000.04360036003600360036003600360036000.090.140.180.216760.853.295.592.9665.581.975.2353.9620.3111.13119.9634.181904.561993.331024.22360036003600593.652676.16360036003600360036003600Relative Encoding0.08000.010.010.010.0147.910.02230.040.040.050.063600360036003600360036003600360036005.126.981013.24fiAlgorithm Directed Hamiltonian Cyce Problem3.2 Analysis AP-SATefficacy AP-SAT algorithm may due following reasons. InstancesHC likely DAP solution either, therefore algorithmterminates first AP call. hand, instances HC likelymultiple HCs, one found quickly AP KSP steps.difficult case many DAP solutions, noneHCs. case AP KSP steps may fail, SAT part invoked findHC disprove existence HC.following analyze instances AP-SAT fails requires muchtime, analyze number r computing variant AP instances (which setsize instance n; see end Section 2.3). Therefore investigated threeprocedures AP-SAT, namely AP, KSP SAT. observed SAT partinvoked 14 4266 instances tested. considered 14 twoinstances (stilt3162 super3162), AP-SAT terminate 1 hour,hard. analyze 16 hard instances increased maximal allowed time1 hour 4 hours. Table 2 present running times AP, KSP SAT,number calls three procedures, numbers AP KSP callsgiven column, two numbers equal different one (seepseudo code appendix). Furthermore, add two additional pieces information:whether instance HC whether unknown, whether AP-SAT terminatedinstance 4 hours. Table 2, Memory means part terminated duehigh memory requirement. Note solution status instance stilt316-2 (noHC) known, since Concorde contrast AP-SAT able solve it.Table 2 shows running time AP/KSP contributed majoritytotal running time AP-SAT 4 16 hard instances, i.e., coin1000-2rect316-9, two instances stilt3162 super3162 SAT invokedall. 6 instances, AP-SAT terminate. 5 6 instances, i.e., stilt3162, stilt316-4, stilt316-5, stilt1000-1, stilt1000-2, SAT part terminatereasonable amount time algorithm stopped due high memory requirementSAT.order determine r, re-ran instances Table 2 three different valuesr, i.e., r = 0, r = n/2, r = 2n. results (not presented) showed AP-SATunable terminate r = n (i.e., 6 instances stilt316-2, stilt316-4, stilt316-5,stilt1000-1, stilt1000-2, stilt3162), also failed stop values r.remaining 10 instances, increasing r = n r = 2n reduce running times.reasonable two instances coin1000-2 rect316-9 large AP/KSP time,HC. hand, two instances onesAP-SAT ran faster using smaller values r, namely coin1000-2 using r = n/2rect316-9 using r = 0.thus conclude r increased, rather decreased. hardestimate memory requirements time SAT part, one alternativedifficult instances would start AP-SAT smaller parameter r stopSAT part time one unsuccessful call. complete APSAT algorithm restarted larger r. instances, however, choice677fiJager & ZhangTable 2: Comparison performance AP, KSP, SAT procedures AP-SATalgorithm 16 hard instances.Instancebr17coin1000-2rect100-2rect316-9stilt100-1stilt100-5stilt100-6stilt100-7stilt100-8stilt316-2stilt316-4stilt316-5stilt1000-1stilt1000-2stilt3162super3162Running timeAPKSPSAT004.1352.7347.541.820.070.010.273.690.610.350.1700.070.20.0128.840.170.020.070.170.050.060.150.030.0720.211.37 14378.4213.150.71Memory21.141.63Memory1446.63 107.06 12846.311457.76 102.21 12840.0313832.40567.60013244.88441.460Number callsAK/KSP SAT1713810001100131611001100411001100110013161316131611000110001650010320HCTermin.YesUnknownUnknownUnknownUnknownUnknownYesYesYesYesYesYesYesYesYesYesYesFigure 4: Comparison performance AP KSP procedures AP-SAT randominstances size 1600.APKSP6Average running time5.554.543.532.521.510.500.5 0.6 0.7 0.8 0.9 1 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2Degree parameter cr relevant. difficult problem instances required perform comprehensiveanalysis r.Finally, Figure 4 compare times used AP KSP random instancessize 1600 degree parameter c = 0.5, 0.6, . . . , 1.90, 2.00.observe AP time consuming KSP. smaller c effectobvious instances solved result HC firstAP call, thus KSP need invoked all.678fiAlgorithm Directed Hamiltonian Cyce Problem3.3 Phase Transitions DHCPrandom undirected graphs Gn,m , arcs randomly chosen possiblen(n 1)/2 arcs n vertices graph, Komlos Szemeredi (1983) proved phasetransition c dn (log n + log log n)/2c c = 1 HCP. Vandegriend Culberson (1998) experimentally verified theoretical result, constant c 1.081.10. DHCP, arcs randomly chosen possible n(n 1) arcs,McDiarmid proved phase transition = cdn(log n+log log n)c c = 1 (1980).experiments aimed verify result determine multiplicative constant c.directed graph may contain twice many arcs undirected counterpart, wouldexpect number arcs doubled well phase transition point. Thereforetested = dc n (log n + log log n)c c = 0.5, 0.6, 0.7, 0.8, 0.81, 0.82, . . . , 1.19, 1.20,1.30, 1.40, 1.50, 1.60, 1.70, 1.80, 1.90, 2.00, expected phase transition occurc = 1. considered problem instances n = 128, 256, 512, 1024, 2048, 4096, 8192vertices chose 1000 independently generated random graphs n c.phase transition result shown Table 3 Figure 5, first parameterc second parameter percentage Hamiltonian graphs among graphsconsidered. observe phase transition DHCP similar HCP.particular, evident Figure 5 phase transition becomes sharper, i.e.,crossover among phase transition curves, problem size increases,characteristic phase transitions complex systems. crossover occurs arounddegree parameter c = 0.9, substantially different expected value1. short, observations verified existence phase transition DHCP,phase transition occurs dc n (log n + log log n)c approximately c = 0.9.Furthermore, constant c = 0.9, probability Gn,m Hamiltonian1/2. comparison, undirected graphs, constant 1.08 1.10found (Vandegriend & Culberson, 1998).3.4 Asymptotic Behavior AP-SATinteresting characteristic algorithm asymptotic behavior. quantifybehavior AP-SAT algorithm, revisited experiments Section 3.3, i.e.,experiments verified phase transitions DHCP. described earlier, considered random problem instances n = 128, 256, 512, 1024, 2048, 4096, 8192 verticeschose 1000 independently generated random graphs n c.measure worst-case asymptotic behavior AP-SAT, measured CPU timesalgorithm difficult instances, i.e., instances degree parameterc = 0.9 (see Section 3.3). results found Figure 6, x-axisproblem size y-axis average time required. Since both, x- y-axislogarithmic scale log-log curve Figure 6 nearly linear, average runningtime AP-SAT considered polynomial number n verticesgraph. reasonable, random instances SAT part called (seeSection 3.2), AP KSP combined complexity worse O(n3 ).679fiJager & ZhangTable 3: Phase transition random instances.c0.50.60.70.80.810.820.830.840.850.860.870.880.890.90.910.920.930.940.950.960.970.980.9911.011.021.031.041.051.061.071.081.091.11.111.121.131.141.151.161.171.181.191.21.31.41.51.61.71.81.92128005.123.325.527.830.632.433.637.639.84446.84952.855.559.260.162.763.667.268.869.47172.874.275.876.977.478.481.781.683.385.185.486.386.686.787.388.588.787.888.589.195.796.499.199.799.799.810010025600321.924.228.428.931.834.136.539.143.547.35253.254.458.460.161.765.36567.971.87474.375.475.476.678.679.379.282.483.284.48787.488.688.989.289.291.292.692.993.897.298.899.199.699.899.8100100512002.621.523.927.43334.935.636.938.342.447.349.852.356.959.561.560.86466.268.372.172.174.576.37982.184.48687.388.488.688.889.389.790.190.790.992.693.193.69393.397.59999.999.810099.999.9100Size1024001.318.720.623.125.832.93035.440.843.845.852.554.754.160.863.664.966.267.971.273.873.678.381.181.983.285.285.988.187.187.286.890.990.389.592.293.293.994.195 095.596.298.899.599.999.910099.999.91006802048000.516.320.8252728.534.337.44144.747.950.150.354.758.461.468.466.871.672.57577.280.881.48184.286.385.689.989.489.489.59292.99393.993.895.195.396.194.896.298.999.799.899.999.91001001004096000.114.117.92023.32933.434.735.940.247.748.652.759.460.765.668.372.77175.77779.878.782.483.485.388.385.99090.392.69293.893.393.994.194.295.594.795.897.397.698.799.599.910099.91001001008192000.212.715.718.723.928.93034.138.740.644.850.554.659.861.565.870.573.171.473.476.38081.781.985.486.588.390.792.39292.493.893.99494.797.396.497.297.296.497.297.999.299.810010099.9100100100fiAlgorithm Directed Hamiltonian Cyce ProblemFigure 5: Phase transition random instances.100Size 128Size 256Size 512Size 1024Size 2048Size 4096Size 8192Existence HCs %8060402000.40.60.811.21.4Degree parameter c6811.61.82fiJager & ZhangFigure 6: Asymptotic behavior AP-SAT algorithm.10,000APSATAverage running time1,0001001010.10.010.0010.00011282565121024204840968192Size4. SummaryHamiltonian cycle problem (HCP) important, canonical combinatorial problem.Surprisingly, HCP directed graphs, called directed HCP DHCP,effective exact algorithm developed. main result work noveleffective exact algorithm DHCP. algorithm utilizes existing algorithmassignment problem existing method Boolean satisfiability (SAT). workincludes new SAT formulation HCP AP, potentially extendedproblems TSP. experimental results random real probleminstances showed new algorithm superior four known algorithms includingone algorithm takes advantage award-winning Concorde TSP algorithm. Furthermore, first phase transition result combinatorial problems done HCPlater extended DHCP. paper experimentally verified existencephase transition DHCP refined location phase transitionappears using new exact DHCP algorithm.Acknowledgmentsthank David S. Johnson AT&T Labs - Research Gregory Gutin Royal HollowayUniversity London many discussions related work insightful commentsmanuscript. research supported part NSF grants IIS-0535257DBI-0743797 Weixiong Zhang.682fiAlgorithm Directed Hamiltonian Cyce ProblemAppendix A. Pseudo Code AP-SAT AlgorithmINPUT Directed non-complete graph G = (V, E) |V | = n.1 Define matrix C Section 2.1, := 1.2 Define subcycle collection set W := .3 = 1, . . . , n4Solve AP instance matrix C solution value g, AP solution(v1 , vi1 ), (v2 , vi2 ) . . . , (vn1 , vin1 ), (vn , vin ), number cycles k.5g6STOP HC.7ELSE k = 18STOP HC AP solution.9Apply KSP cycles, receive solution value h completecycle (w1 , w2 , . . . , wn , w1 ).10h = 011STOP HC (w1 , w2 , . . . , wn , w1 ).12= 1, . . . , n13cvt ,vit = cvt ,vit + 114= n max {ci,j | (i, j) E} + 1.15ci,j = (i, j)/ E.16Add subcycle AP solution W .17 Start SAT model explained Section 2.4.18 subcycle (v1 , v2 , . . . , vk1 , vk , v1 ) W add clauseyv1 ,v2 . . . yvk1 ,vk yvk ,v1 SAT model.19 Solve SAT model.20 Variable setting exists model.21Add k subcycles solution SAT model W .22k = 123STOP HCsubcycle.24GOTO 19.25ELSE STOP HC.OUTPUT HC G, proof HC exists G.ReferencesAngluin, D. & Valiant, L.G. (1979). Fast Probabilistic Algorithms Hamiltonian CircuitsMatchings. J. Comput. System. Sci. 18(2), 155-193.683fiJager & ZhangApplegate, D.L., Bixby, R.E., Chvatal, V. & Cook, W.J. (2005). Concorde Code:http://www.tsp.gatech.edu/concorde.htmlApplegate, D.L., Bixby, R.E., Chvatal, V. & Cook, W.J. (2006). Traveling SalesmanProblem. Computational Study. Princeton University Press.Applegate, D.L., Bixby, R.E., Chvatal, V., Cook, W.J., Espinoza, D., Goycoolea, M.& Helsgaun, K. (2009): Certification Optimal Tour 85,900 Cities.Oper. Res. Lett. 37(1), 11-15.Bang-Jensen, J. & Gutin, G. (2008). Chapter 5 in: Digraphs: Theory, Algorithms Applications. Springer, London. Free available:http://www.cs.rhul.ac.uk/books/dbook/Bertsekas, D.P. (1981). New Algorithm Assignment Problem. Math. Program. 21,152-171.Bollobas, B. (1985). Random Graphs. Academic Press, London.Bollobas, B., Fenner, T.I. & Frieze, A.M. (1987). Algorithm Finding HamiltonianPaths Cycles Random Graphs. Combinatorica 7(4), 327-341.Bondy, J.A. (1995). Basic Graph Theory: Paths Circuits. Graham, R.L., Grotschel,M., Lovasz, L. (Eds.): Handbook Combinatorics (3-110). North-Holland, Amsterdam.Cheeseman, P., Kanefsky, B. & Taylor, W.M. (1991). Really Hard ProblemsAre. Mylopoulos, J., Reiter, R. (Eds.): Proc. 12th International ConferenceJoint Artificial Intelligence (IJCAI), 331-337. Morgan Kaufmann.Christofides, N. (1975). Graph Theory Algorithmic Approach. Academic Press, NewYork.Chvatal, V. (1985). Hamiltonian Cycles. Chapter 11 Lawler, E.L., Lenstra, J.K., RinnooyKan, A.H.G., Shmoys, D.B. (Eds.): Traveling Salesman Problem. Guided TourCombinatorial Optimization. John Wiley & Sons, Chichester.Cook, S.A. (1971). Complexity Theorem-Proving Procedures. Proc. 3rd Ann. ACMSymp. Theory Computing (STOC), 151-158.Cook, W.J. (2010). TSP Homepage:http://www.tsp.gatech.edu/Dechter, R. (2003). Constraint Processing. Morgan Kaufmann.DellAmico, M. & Toth, P. (2000). Algorithms Codes Dense Assignment Problems:State Art. Discrete Appl. Math. 100(1-2), 17-48.Een, N. & Sorensson, N. (2003). Extensible SAT-Solver. Giunchiglia, E., Tacchella, A.(Eds.): Proc. 6th International Conference Theory Applications SatisfiabilityTesting (SAT). Lecture Notes Comput. Sci. 2919, 502-518.Een, N. & Sorensson, N. (2010). MiniSat Code:http://minisat.se684fiAlgorithm Directed Hamiltonian Cyce ProblemFrank, J., Gent, I. & Walsh, T. (1998). Asymptotic Finite Size Parameters PhaseTransitions: Hamiltonian Circuit Case Study. Inform. Process. Lett. 65(5), 241245.Frieze, A.M. (1988a). Finding Hamiltonian Cycles Sparse Random Graphs. J. Combin. Theory Ser. B 44, 230-250.Frieze, A.M. (1988b). Algorithm Finding Hamilton Cycles Random DirectedGraphs. J. Algorithms 9, 181-204.Frieze, A.M. & Suen, S. (1992). Counting Hamilton Cycles Random Directed Graphs.Random Structures Algorithms 9, 235-242.Frost, D. & Dechter, R. (1994). Dead-End Driven Learning. Proc. 12th National ConferenceArtificial Intelligence (AAAI), 294-300. AAAI Press.Johnson, D.S. (2008). 8th Dimacs Implementation Challenge: Traveling Salesman Problem:http://www.research.att.com/~dsj/chtsp/Garey, M.R. & Johnson, D.S. (1979). Computers Intractability. Guide TheoryN P-Completeness. Freeman, New York.Glover, F., Gutin, G., Yeo, A. & Zverovich, A. (2001). Construction HeuristicsAsymmetric TSP. European J. Oper. Res. 129, 555-568.Goldberg, A.V. & Kennedy, R. (1995). Efficient Cost Scaling Algorithm Assignment Problem. Math. Program. 71, 153-177.Goldengorin, B., Jager, G. & Molitor, P. (2006). Tolerance Based Contract-or-Patch Heuristic Asymmetric TSP. Erlebach, T. (Ed.): Proc. 3rd Workshop Combinatorial Algorithmic Aspects Networking (CAAN). Lecture Notes Comput. Sci. 4235, 86-97.Gomes, C.P., Selman, B. & Kautz, H. (1998). Boosting Combinatorial SearchRandomization. Proc. 15th National Conference Artificial Intelligence (AAAI),431-437. AAAI Press.Gould, R.J. (1991). Updating Hamiltonian Problem Survey. J. Graph Theory 15(2),121-157.Grebinski, V. & Kucherov, G. (1996). Reconstructing Hamiltonian Circuit QueryingGraph: Application DNA Physical Mapping. IR 96-R-123, Centre de Rechercheen Informatique de Nancy.Gutin, G. & Moscato, P. (2000). Hamiltonian Page:http://alife.ccp14.ac.uk/memetic/~moscato/Hamilton.htmlHenderson, R. & Apodaca, E. (2008). Knight Egodeth: Zen Raptured Quietude. BookSurge Publishing.Hoos, H.H. (1999). SAT-Encodings, Search Space Structure, Local Search Performance.Proc. 16th International Joint Conference Artificial Intelligence (IJCAI), 296-303.Morgan Kaufmann.685fiJager & ZhangJin, H., Han, H. & Somenzi, F. (2005). Efficient Conflict Analysis Finding SatisfyingAssignments Boolean Circuit. Halbwachs, N., Zuck, L.D. (Eds.): Proc. 11thInternational Conference Tools Algorithms Construction AnalysisSystems (TACAS). Lecture Notes Comput. Sci. 3440, 287-300.Johnson, D.S., Gutin, G, McGeoch, L.A., Yeo, A., Zhang, W. & Zverovich, A. (2002).Experimental Analysis Heuristics ATSP. Chapter 10 in: Gutin, G., Punnen,A.P. (Eds.): Traveling Salesman Problem Variations. Kluwer.Jonker, R. & Volgenant, A. (1983). Transforming Asymmetric Symmetric TravelingSalesman Problems. Oper. Res. Lett. 2(4), 161-163.Jonker, R. & Volgenant, A. (1987). Shortest Augmenting Path Algorithm DenseSparse Linear Assignment Problems. Computing 38, 325-340.Jonker, R. & Volgenant, A. (2004). AP Code:http://www.magiclogic.com/assignment.htmlKabadi, S.N. & Punnen, A.P. (2002). Bottleneck TSP. Chapter 15 in: Gutin, G., Punnen, A.P. (Eds.): Traveling Salesman Problem Variations. Kluwer.Karp, R.M. (1972). Reducibility Among Combinatorial Problems. Miller, R.E., Thatcher,J.W. (Eds.): Complexity Computer Computations, 85-103. New York: Plenum.Karp, R.M. & Steele, J.M. (1985). Probabilistic Analysis Heuristics. Chapter 6 in: Lawler,E.L., Lenstra, J.K., Rinnooy Kan, A.H.G., Shmoys, D.B. (Eds.): Traveling Salesman Problem. Guided Tour Combinatorial Optimization. John Wiley & Sons,Chicester.Kelly, L. (2007). Hamilton Cycles Directed Graphs. PhD Thesis, University Birmingham, United Kingdom.Komlos, M. & Szemeredi, E. (1983). Limit Distribution Existence HamiltonianCycle Random Graph. Discrete Math. 43, 55-63.Kyek, O., Parberry, I. & Wegener, I. (1997). Bounds Number Knights Tours.Discrete Appl. Math. 74(2), 171-181.Lynce, I. & Marques-Silva, J. (2006). Efficient Haplotype Inference Boolean Satisfiability. Proc. 21st National Conference Artificial Intelligence (AAAI). AAAI Press.Martello, S. (1983). Enumerative Algorithm Finding Hamiltonian Circuits Directed Graph. ACM Trans. Math. Software 9(1), 131-138.McDiarmid, C.J.H. (1980). Cluster Percolation Random Graphs. Math. Program. Stud. 13, 17-25.Monasson, R., Zecchina, R., Kirkpatrick, S., Selman, B. & Troyansky, L. (1999). Determining Computational Complexity Characteristic Phase Transitions. Nature 400,133.Prestwich, S. (2003). SAT Problems Chains Dependent Variables. DiscreteAppl. Math. 130(2), 329-350.Posa, L. (1976). Hamiltonian Circuits Random Graphs. Discrete Math. 14, 359-364.686fiAlgorithm Directed Hamiltonian Cyce ProblemReinelt, G. (1991). TSPLIB Traveling Salesman Problem Library. ORSA J. Comput. 3,376-384.Reinelt, G. (2008). Tsplib Library:http://www.iwr.uni-heidelberg.de/groups/comopt/software/TSPLIB95/Richards, E.T. & Richards, B. (2000). Non-Systematic Search No-Good Learning.J. Automat. Reason. 24(4), 483-533.Skiena, S. (2008). Stony Brook Algorithm Repository:http://www.cs.sunysb.edu/~algorith/files/hamiltonian-cycle.shtmlStojakovic, M. & Szabo, T. (2005). Positional Games Random Graphs. Random Structures Algorithms 26(1-2), 204-223.Vandegriend, B. (1998). Finding Hamiltonian Cycles: Algorithms, Graphs Performance.Master Thesis, University Alberta, Canada.Vandegriend, B. & Culberson, J. (1998). Gn,m Phase Transition HardHamiltonian Cycle Problem. J. Artificial Intelligence Res. 9, 219-245.Velev, M.N. & Gao, P. (2009). Efficient SAT Techniques Absolute Encoding Permutation Problems: Application Hamiltonian Cycles. Proc. 8th Symposium Abstraction, Reformulation Approximation (SARA), 159-166.Zhang, W. & Korf, R.E. (1996). Study Complexity Transitions AsymmetricTraveling Salesman Problem. Artificial Intelligence 81, 223-39.Zhang, L., Madigan, C.F., Moskewicz, M.H. & Malik, S. (2009). Efficient Conflict DrivenLearning Boolean Satisfiability Solver. Proc. IEEE/ACM International Conference Computer Aided Design (ICCAD), 279-285.687fiJournal Artificial Intelligence Research 39 (2010) 429-481Submitted 02/10; published 10/10Nominals, Inverses, Counting, Conjunctive Queriesor: Infinity Friend!Sebastian Rudolphrudolph@kit.eduAIFB, Karlsruhe Institute Technology, DEBirte Glimmbirte.glimm@comlab.ox.ac.ukOxford University Computing Laboratory, UKAbstractDescription Logics knowledge representation formalisms provide, example,logical underpinning W3C OWL standards. Conjunctive queries, standardquery language databases, recently gained significant attention expressiveformalism querying Description Logic knowledge bases. Several different techniquesdeciding conjunctive query entailment available wide range DLs. Nevertheless,combination nominals, inverse roles, number restrictions OWL 1 OWL 2DL causes unsolvable problems techniques hitherto available. tackle problempresent decidability result entailment unions conjunctive queries DLALCHOIQb contains three problematic constructors simultaneously. Providedqueries contain simple roles, result also shows decidability entailment(unions of) conjunctive queries logic underpins OWL 1 DL believepresented results pave way progress towards conjunctive queryentailment decision procedures Description Logics underlying OWL standards.1. Introductionpresent decidability result entailment unions conjunctive queriesexpressive Description Logic ALCHOIQb. article extended version conference paper Status QIO: Conjunctive Query Entailment Decidable, Proceedings12th International Conference Principles Knowledge Representation Reasoning (KR 2010), May 0913, 2010 (Glimm & Rudolph, 2010).Description Logics (DLs) family logic based knowledge representation formalisms(Baader, Calvanese, McGuinness, Nardi, & Patel-Schneider, 2003). DLs correspondfunction-free two variable fragment First-Order Logic (FOL) often extendedcounting quantifiers (e.g., xn y(R(x, y))) DLs also closely related (2variable) guarded fragment since DL formulae naturally result guarded formulaetranslated FOL. line restriction 2 variables, DL formulae containunary binary predicates, called concepts roles DLs. constructorsbuilding complex expressions usually chosen key inference problems,concept satisfiability, decidable. DL knowledge base (KB) consists TBox,contains intensional knowledge concept definitions general backgroundknowledge (essentially FOL theory), ABox, contains extensional knowledgeused describe individuals (a set ground facts). Using database metaphor,TBox corresponds schema, ABox corresponds data. contrastc2010AI Access Foundation. rights reserved.fiRudolph & Glimmdatabases, however, DL knowledge bases, FOL general, adopt open world semantics,i.e., represent information domain incomplete way.Standard DL reasoning services include testing concepts satisfiability retrievingcertain instances given concept. latter retrieves, knowledge base consisting ABox TBox , (ABox) individuals instances given(possibly complex) concept expression C, i.e., individualsentail instance C. underlying reasoning problems well-understood,computational complexity standard reasoning tasks given knowledge baseinput range PTime-complete DLs limited expresivity DL-Lite(Calvanese, De Giacomo, Lembo, Lenzerini, & Rosati, 2005), EL (Baader, 2003), ELP(Krotzsch, Rudolph, & Hitzler, 2008) 2-NExpTime-complete expressive DLsSROIQ (Kazakov, 2008).Despite high worst case complexity standard reasoning problemsexpressive DLs SROIQ, highly optimized implementations available,e.g., FaCT++ (Tsarkov & Horrocks, 2006), Pellet (Sirin, Parsia, Cuenca Grau, Kalyanpur, & Katz, 2007), HermiT (Motik, Shearer, & Horrocks, 2009). systemsused wide range applications, e.g., biology (Sidhu, Dillon, Chang, & Sidhu,2005), bio informatics (Wolstencroft, Brass, Horrocks, Lord, Sattler, Turi, & Stevens, 2005),medicine (Golbreich, Zhang, & Bodenreider, 2006), information integration (Calvanese,De Giacomo, Lenzerini, Nardi, & Rosati, 1998b), geography (Goodwin, 2005), geology (JetPropulsion Laboratory, 2006), defense (Lacy, Aviles, Fraser, Gerber, Mulvehill, & Gaskill,2005), configuration (McGuinness & Wright, 1998). prominently, DLs knownuse logical underpinning ontology languages, e.g., OIL, DAML+OIL,W3C standard OWL 1 (Bechhofer, van Harmelen, Hendler, Horrocks, McGuinness, PatelSchneider, & Stein, 2004), successor OWL 2 (W3C OWL Working Group, 2009).three species OWL 1: OWL Lite, OWL DL, OWL Full. OWL 2 extendsOWL 1 adds three sublanguages (called OWL 2 profiles): OWL EL, OWL QL,OWL RL. OWL Lite corresponds DL SHIF standard reasoningtasks ExpTime-complete, OWL 1 DL corresponds DL SHOIN ,standard reasoning tasks NExpTime-complete, OWL 2 DL extends DLSROIQ. OWL Full standard reasoning tasks longer decidable. newQL, EL, RL profiles restrictive OWL DL profiles tradesdifferent aspects OWLs expressive power return different computational and/orimplementational benefits. OWL EL corresponds DL EL ++ (Baader, Brandt, &Lutz, 2005) basic reasoning problems performed time polynomialrespect size input knowledge base. OWL 2 QL based DL-Litefamily Description Logics, data complexity conjunctive query entailmentAC0 . Thus, conjunctive query answering implemented using standard relationaldatabase technology. OWL 2 RL enables implementation polynomial time reasoningalgorithms using rule-extended database technologies.data-intensive applications, querying KBs plays central role. Instance retrievalis, aspects, rather weak form querying: although possibly complex conceptexpressions used queries, query tree-like relational structures,DL concept cannot express arbitrary cyclic structures. property knowntree model property considered important reason decidability430fiNominals, Inverses, Counting, Conjunctive QueriesModal Description Logics (Gradel, 2001; Vardi, 1997) also heavily exploitvariant property establish decidability result. Conjunctive queries (CQs)unions conjunctive queries (UCQs) well known database communityconstitute expressive query language capabilities go well beyond standardinstance retrieval. FOL terms, CQs UCQs formulae positive existentialfragment. Free variables query (not bound existential quantifier) also calledanswer variables distinguished variables, whereas existentially quantified variablescalled non-distinguished.query contains distinguished variables, query answer true falsequery called Boolean query. Given knowledge base K Boolean UCQq, query entailment problem deciding whether q true false w.r.t. K, i.e.,decide whether model K provides suitable assignment variablesq. query distinguished variables, answers query tuplesindividual names (constants) knowledge base entails queryobtained replacing free variables individual names answer tuple.answers also called certain answers. problem finding answer tuplesknown query answering. present decidability result query entailment,decision problem, restriction since query answering easily reducedquery entailment illustrate detail Section 3.1.1 Related WorkConjunctive queries first mentioned context Description Logics (DLs)Levy Rousset (1996). first account conjunctive queries main topic givenCalvanese, De Giacomo, Lenzerini (1998a). particular recent years, problemdecidability conjunctive query entailment complexity problem differentlogics gained significant attention. DLs SHIQ SHOQ decidability2-ExpTime-completeness problem known (Glimm, Horrocks, Lutz, & Sattler,2008a; Glimm, Horrocks, & Sattler, 2008b; Lutz, 2008; Eiter, Lutz, Ortiz, & Simkus,2009). Conjunctive query entailment already 2-ExpTime-hard relatively weakDL ALCI (Lutz, 2008), initially attributed inverse roles. Recently,shown, however, also transitive roles together role hierarchies DL SHmake conjunctive query entailment 2-ExpTime-hard (Eiter et al., 2009). techniquesGlimm et al. SHIQ SHOQ (Glimm et al., 2008a, 2008b) reduce query entailmentstandard reasoning task knowledge base satisfiability checking DL extendedrole conjunctions. alternative technique so-called knots technique (Ortiz,Simkus, & Eiter, 2008b), instance mosaic technique originating ModalLogic. technique also gives worst-case optimal algorithms SHIQ severalsub-logics. Further, automata-based decision procedures positive existentialpath queries (Calvanese, Eiter, & Ortiz, 2007, 2009). Positive existential path queriesgeneralize unions conjunctive queries and, therefore, decision procedures kindquery also provides decision procedures unions conjunctive queries. particularrecent extension (Calvanese et al., 2009) close conjunctive query entailmentdecision procedure OWL 2, corresponds DL SROIQ, covers431fiRudolph & GlimmSRIQ, SROQ, SROI. use three problematic constructors nominals,inverses, number restrictions is, however, covered.Regarding data complexity, i.e., complexity respect ABox (the data)only, CQ entailment usually coNP-complete expressive logics. example, DLsALE SHIQ case (Glimm et al., 2008a) holds also CQentailment two variable guarded fragment counting (Pratt-Hartmann, 2009).latter work quite closely related since many Description Logics translatedtwo variable guarded fragment counting, i.e., results Pratt-Hartmann alsohold SHIQ simple roles (roles transitive transitivesubrole) query. Given restriction query, also SHOQ SHOIshown coNP-complete data complexity w.r.t. conjunctive query entailment(Ortiz, Calvanese, & Eiter, 2008a).Query entailment answering also studied context databasesincomplete information (Rosati, 2006b; van der Meyden, 1998; Grahne, 1991).setting, DLs used schema languages, expressivity considered DLsusually much lower expressivity DL ALCHOIQb considerreasoning usually tractable. example, constructors provided logicsDL-Lite family (Calvanese, De Giacomo, Lembo, Lenzerini, & Rosati, 2007) chosenstandard reasoning tasks PTime regarding combined complexityquery entailment AC0 respect data complexity. Thus, TBox reasoningdone independently ABox ABox stored accessed using standarddatabase SQL engine. Another tractable DL EL (Baader, 2003). Conjunctive queryentailment EL is, however, tractable complexity increases coNP-complete(Rosati, 2007b). Moreover EL++ (Baader et al., 2005), still tractable extension EL,query entailment even undecidable (Krotzsch, Rudolph, & Hitzler, 2007). mainlyEL++ , one use unrestricted role compositions. allows encodingcontext-free languages, conjunctive queries used check intersectionlanguages, known undecidable problem. Since logics useddatabases incomplete information considerable less expressive ALCHOIQb,techniques developed area transfer setting.Given query entailment (computationally) harder task than, example,knowledge base satisfiability, surprising decidability latter tasknecessarily transfer problem CQ entailment. undecidability results transferred FOL since many DLs directly translatedequivalent FOL theory. example, known conjunctive query entailmentundecidable two variable fragment First-Order Logic L2 (Rosati, 2007a),Rosati identifies relatively small set constructors cause undecidability (mostnotably role negation axioms, i.e., axioms form x, (R(x, y) P (x, y)) R, Pbinary predicates). Pratt-Hartmann (2009) recently established decidability CQ entailment two variable guarded fragment counting (GC2 ). worth notingPratt-Hartmann assumes background theory (that knowledge basecase) constant free formulae form =1 x(P (x)), used simulate constants/nominals, considered guarded. result covers, therefore,DL ALCHIQb applicable case, input knowledge base (thebackground theory) contains nominals (individual constants).432fiNominals, Inverses, Counting, Conjunctive Queriesimplemented DL reasoners, e.g., KAON2,1 Pellet, RacerPro,2 provideinterface conjunctive query answering, although KAON2 RacerPro considernamed individuals ABox assignments variables. restrictionqueries longer standard FOL semantics decidability obviouslyissue since conjunctive query answering restriction reduced standardinstance retrieval replacing variables individual names ABoxtesting entailment conjunct separately. Pellet goes beyond also providesinterface conjunctive queries FOL semantics restriction querieskind tree shape. restriction decidability known since CQsexpressed normal concepts (possibly adding role conjunctions).1.2 Contributions OverviewGiven results, show great interest problem conjunctive query entailment expressive DLs, interesting DLs SHIF, SHOIN ,SROIQ underpin widely adopted standards OWL Lite, OWL 1 DL, OWL 2DL, respectively, decidability conjunctive query entailment establishedOWL Lite. main obstacle devising decision procedure combination inverseroles (I), nominals (O), number restrictions/counting quantifiers (F stands functionality, N unqualified number restrictions, Q qualified number restrictions).complications arising combination constructors caused also majorhurdle development implementable algorithms knowledge base satisfiabilitySHOIN extensions thereof, Horrocks Sattler (2005) devised tableau-baseddecision procedure since extended SROIQ. Meanwhile also alternativeapproaches resolution (Kazakov & Motik, 2008), hypertableau-based procedures(Motik et al., 2009) available implemented.key obstacle establishing decision procedure existence potentiallyinfinitely many new nominals, i.e., elements uniquely identifiable modelKB. example, consider KB K given Fig. 1. concept form {o}interpreted singleton set, containing interpretation constanto. simplicity, assume constant always interpreted itself, e.g.,interpretation o. axiom form {o1 } v f.s.f .{o2 }understood follows: constant o1 , must two elements, say d1 d2 ,f (o1 , d1 ), s(d1 , d2 ), f (o2 , d2 ) holds. Note o2 occurs first elementf (o2 , d2 ) since inverse role (f ) used. Thus, interpretation KB must containthree elements o1 , o2 , o3 , must interconnected following way: pathsffshape lead o1 o2 well o2 o3 o3o1 . Moreover, role f defined functional, meaning every elementone f -successor. also applies individuals oi , forces existences-cycle. Observe cyclic Boolean query {s(x, y), s(y, z), s(z, x)} checksexistence cycle cannot answered applying standard techniquesreplacing variables individual names (oi ) rewriting query equivalent1. http://kaon2.semanticweb.org2. http://www.racer-systems.com433fiRudolph & Glimm{o1 } v f.s.f .{o2 }{o2 } vf.s.f .{o{o1 }3}ff{o3 } v f.s.f .{o1 }{o2 }f{o3 }func(f )Figure 1: Example knowledge base K representation model, threeelements s-cycle so-called new nominals.tree-shaped query. elements cycle behave nominals,names them.tackle problem conjunctive query entailment expressive DL contains three problematic constructors simultaneously prove decidability (unionsof) conjunctive queries. challenging part establish finite representabilitycountermodels case query given input entailed knowledge base.results also hold SHOIQ knowledge bases, i.e., roles declared transitive,provided queries contain simple roles (roles neither transitivetransitive subrole). essentially restriction placed rolesoccur number restrictions since otherwise standard reasoning tasks becomeundecidable. restriction, use standard techniques eliminating transitivity (Kazakov & Motik, 2008). Hence, also show decidability conjunctive queryentailment OWL DL, queries simple roles.believe work also valuable understanding, general, structuremodels DLs contain nominals, inverse roles, number restrictions. Furthermore,devise non-trivial extensions standard techniques unraveling, believeprove useful working expressive DLs.paper organized follows: Section 2, give birds-eye view techniquesideas used establish decidability. Section 3, give necessary definitionsintroduce standard notations. Sections 4, 5, 6 present main resultsuse Section 7 show models satisfy query finitelyrepresented conclude Section 8.2. Big Picturegoing technical details, describe overall line argumentationestablishing decidability conjunctive query entailment ALCHOIQb.2.1 Decidability via Finitely Representable CountermodelsLet K ALCHOIQb knowledge base let q conjunctive query question,i.e., aim determine whetherK |= q.Clearly, ALCHOIQb fragment first-order predicate logic equality, Ktranslated FOL sentence F OL(K). Likewise find FOL sentence F OL(q)434fiNominals, Inverses, Counting, Conjunctive Queriesq existentially quantified formula. Hence, checking entailmentequivalent determining whether first-order theory F OL(K) entails F OL(q).result completeness theorem FOL (Godel, 1929), consequences finite FOLtheory recursively enumerable, provides us procedure terminatesK |= q. Hence, establish decidability providing another algorithm terminatesiff entailment hold i.e., so-called countermodelmodel K 6|= q.provide algorithm showing that, whenever countermodelexists all, also countermodel finitely representable. precisely,encoded word Rep(I) finite length finite alphabet, wherebyencoding Rep property every finite word effectively checkedwhether represents countermodel given knowledge base query.consequence thereof, create desired algorithm enumerates words,checks countermodel, terminates soon found one.2.2 Finite Representability Bounding Nominals Blockingoutline going show always finitely representablecountermodel, one all. taking arbitrary countermodelcautiously transforming countermodel finitely representable. Cautiouslymeans make sure transformation preserve two properties1) model underlying knowledge base K 2) entailing consideredquery q.result overall transformation going regular model, i.e., structuresubstructures certain sense periodically repeated. common practiceDL theory construct kind models arbitrary ones blocking techniques,whereby certain element configurations occurring twice original model detectednew model generated infinitely stringing together finite substructuredelimited two configurations.case consider, technique cannot applied directly original countermodel. due intricate interplay nominals, inverse roles cardinalityconstraints arbitrary even infinite number domain elementsforced behave like nominals; elements usually referred newnominals DL setting. FOL, nominals often called kings new nominalscalled court. case, presence infinitely many new nominals modelmay prevent existence repeated configurations needed blocking.overcome difficulty first applying transformation meansoriginal countermodel converted countermodel finitely many new nominals. guarantees subsequent blocking-based transformation applicableyield desired regular (and thus finitely representable) model.2.3 Bounding Nominals Transformations Forest Quasi-Modelsargumentation, introduce notion forest quasi-models. structuressatisfying originally considered knowledge base weakened form it.435fiRudolph & Glimmreturn concession, exhibit proper forest structure easier handlemanipulate.employ two techniques turn proper models forest quasi-models viceversa: model unraveled yielding forest quasi-model. forest quasi-modelcollapsed obtain proper model. techniques preserve certain structural properties.strategy construct countermodel finitely many nominals consistsfollowing three steps:Take arbitrary countermodel unravel it.Transform obtained forest quasi-model substituting critical parts wellbehaved ones,Collapse obtained structure (proper) model.mentioned critical parts giving rise new nominals.least largely avoided (we care finite set critical partsremaining).central question is: mysterious well-behaved substitutes come from?Fortunately, plethora critical parts brings remedy. use infinitesets critical parts construct well-behaved ones infinite approximation process(this infinity friend). thereby obtain parts presentstructure before, well compatible hence usedreorganization.informally introduced main line argumentation, movetechnical details.3. Preliminariesfirst define syntax semantics roles, go SHOIQb-concepts,individuals, knowledge bases. actually use full expressivity SHOIQb,convenient umbrella DLs working define lessexpressive DLs interest restrictions SHOIQb.Definition 1 (Syntax SHOIQb). Let NC , NR , NI countable, infinite,pairwise disjoint sets concept names, role names, individual names, respectively.call = (NC , NR , NI ) signature. set rol(S) SHOIQb-roles (or rolesshort) NR {r | r NR }, roles form r called inverse roles. roleinclusion axiom form r v r, roles. transitivity axiom formtrans(r) r role. role hierarchy H finite set role inclusion transitivityaxioms.role hierarchy H, define function inv roles inv(r) := r r NRinv(r) := r = role name NR . Further, define vH smallest transitivereflexive relation roles r v H implies r vH inv(r) vH inv(s).write r H r vH vH r. role r transitive w.r.t. H (notation r+ vH r)436fiNominals, Inverses, Counting, Conjunctive Queriesrole exists r vH s, vH r, trans(s) H trans(inv(s)) H. rolecalled simple w.r.t. H role r r transitive w.r.t. H r vH s.r rol(S) simple role, Boolean role expressions U defined follows:U ::= r | U | U u U | U U.use ` denote standard Boolean entailment set roles R rol(S) roleexpressions. Let r rol(S), U Boolean role expression R. inductively define:R ` r r R, R 6` r otherwise,R ` U R 6` U , R 6` U otherwise,R ` U u V R ` U R ` V , R 6` U u V otherwise,R ` U V R ` U R ` V , R 6` U V otherwise.Boolean role expression U safe 6` U .Given signature = (NC , NR , NI ), set SHOIQb-concepts (or conceptsshort) smallest set built inductively symbols using followinggrammar, NI , NC , n IN0 , simple role, U role safeBoolean role expression:C ::= > | | {o} | | C | C1 u C2 | C1 C2 |4U.C | U.C | 6 n s.C | > n s.C.Alternatively, safeness characterized follows: Boolean role expression Usafe if, transforming disjunctive normal form, disjunct contains leastone non-negated role. Intuitively, implies safe role expression never relateindividuals direct role relation other.Definition 2 (Semantics SHOIQb-concepts). interpretation = (I , ) consistsnon-empty set , domain I, function , maps every concept nameNC subset AI , every role name r NR binary relation rI ,every individual name NI element aI . role name r NR ,interpretation inverse role (r ) consists pairs h, 0h 0 , rI .semantics SHOIQb-concepts signature defined follows:(r)I>I(C)I(U.C)I(U.C)I(6 n s.C)I(> n s.C)I=======\ rI(r1 u r2 )I = r1I r2I(r1 r2 )I = r1I r2I=({o})I = {oI }\ C(C u D)I = C DI(C D)I = C DI00{ | h, U , C }{ | h, 0 U 0 C }{ | ](sI (, C)) n}{ | ](sI (, C)) n}](M ) denotes cardinality set sI (, C) defined{ 0 | h, 0 sI 0 C }.concept C negation normal form (NNF) negation occurs front conceptnames use nnf(C) denote negation normal form concept C.4437fiRudolph & Glimmconcept transformed linear time equivalent one NNF pushingnegation inwards, making use de Morgans laws duality existentialuniversal restrictions, at-most at-least number restrictions form6 n r.C > n r.C respectively (Horrocks, Sattler, & Tobies, 2000).Definition 3 (Syntax Semantics Axioms Knowledge Bases). functionalityrestriction expression func(f ) f role. C, concepts, general conceptinclusion (GCI) expression C v D. introduce C abbreviationC v v C. finite set GCIs functionality restrictions called TBox...(ABox) assertion expression form C(a), r(a, b), r(a, b), = b, =6 b,C concept, r role, a, b NI individual names. ABox finite setassertions. knowledge base K triple (T , H, A) TBox, H role hierarchy,ABox.use con(K), rol(K), nom(K) denote, respectively, set concept names,roles (including inverses), individual names occurring K. closure cl(K) Ksmallest set containing nnf(C D) C v ; sub-concept CC cl(K); nnf(C) C cl(K). role f functional K K containsfunctionality axiom func(f ) inverse functional K K contains functionalityaxiom func(inv(f )).Let = (I , ) interpretation. satisfies role inclusion axiom r vrI sI , satisfies transitivity axiom trans(r) rI transitive binary relation, rolehierarchy H satisfies role inclusion transitivity axioms H. interpretationsatisfies functionality restriction func(f ) if, , ]({ 0 | h, 0 f }) 1;satisfies GCI C v C DI ; satisfies TBox satisfies functionalityrestriction GCI . interpretation satisfies assertion C(a) aI C ,..r(a, b) haI , bI rI , r(a, b) haI , bI/ rI , = b aI = bI , =6 b aI 6= bI ;satisfies ABox satisfies assertion A. say satisfies K satisfies, H, A. case, say model K write |= K. say Kconsistent K model.4knowledge base K clear context, simply say role f (inverse)functional instead saying f (inverse) functional K.names DLs indicate constructors supported. basic DL ALCsupports Boolean concept constructors GCIs, role hierarchies, functionalityrestrictions et cetera. transitivity axioms added, use instead ALC. Inverseroles indicated letter I, role inclusion axioms H, nominals, i.e., conceptsform {o} NI , O, functionality restrictions F, qualified number restrictions,i.e., concepts form 6 n s.C > n s.C, Q, safe Boolean role expressionsb. number restrictions limited concepts form 6 n s.> > n s.>, useletter N .mostly refer particular DLs paper: DL SHOIQ obtainedSHOIQb disallowing Boolean role expressions. DLs SHIQ, SHOQ, SHOIobtained SHOIQ disallowing nominals, inverse roles, number restrictions(incl. functionality restrictions), respectively. Finally, DL ALCOIFb obtainedSHOIQb disallowing transitivity axioms (we use ALC instead nameDL indicate this), role inclusion axioms, concepts form 6 n s.C > n s.C.438fiNominals, Inverses, Counting, Conjunctive Queries3.1 Conjunctive Queries Unions Conjunctive Queriesintroduce Boolean conjunctive queries since basic form queriesconcerned with. later also define non-Boolean queries showreduced Boolean queries. Finally, unions conjunctive queries disjunctionconjunctive queries.Definition 4 (Syntax Semantics Conjunctive Queries). Let = (NC , NR , NI )signature NV countably infinite set variables disjoint NC , NR , NI .term element NV NI . Let NC concept name, r NR rolename, t, t0 terms. atom expression A(t) r(t, t0 ) refer twotypes atoms concept atoms role atoms respectively. Boolean conjunctive queryq non-empty set atoms. use var(q) denote set (existentially quantified)variables occurring q term(q) denote set variables individual namesoccurring q. usual, use ](q) denote cardinality q, simplynumber atoms q, use |q| size q, i.e., number symbols necessarywrite q.Let = (I , ) interpretation. total function : term(q) evaluation(a) = aI individual name occurring q. A(t), r(t, t0 ) atoms, write|= A(t) (t) AI ;|= r(t, t0 ) ((t), (t0 )) rI .If, evaluation , |= atoms q, write |= q. saysatisfies q write |= q exists evaluation |= q. callmatch q I.Let K knowledge base q conjunctive query. |= K implies |= q, sayK entails q write K |= q.4query entailment problem defined follows: given knowledge base Kquery q, decide whether K |= q.Definition 5 (Unions Conjunctive Queries). union Boolean conjunctive queriesformula q1 . . . qn , disjunct qi Boolean conjunctive query.knowledge base K entails union Boolean conjunctive queries q1 . . . qn , writtenK |= q1 . . . qn , if, interpretation |= K,|= qi 1 n.4clarify connection query entailment query answering.query answering, let variables conjunctive query typed: variable eitherexistentially quantified (also called non-distinguished ) free (also called distinguishedanswer variables). Let q query n variables (i.e., ](var(q)) = n), v1 , . . . , vm(m n) answer variables. answers K q m-tuples (a1 , . . . , )individual names that, models K, |= q satisfies (vi ) = aIi1 m. Recall use nom(K) denote set individual namesoccurring K (in form nominals ABox individuals). hard see (cf.Chandra & Merlin, 1977) answers K q computed testing,439fiRudolph & Glimm(a1 , . . . , ) nom(K)m , whether query q[v1 ,...,vm /a1 ,...,am ] obtained q replacingoccurrence vi ai 1 entailed K. set certain answersq set m-tuples (a1 , . . . , ) K |= q[v1 ,...,vm /a1 ,...,am ] . Letk = ](nom(K)) number individual names occurring K. Since K finite, clearlyk finite. Hence, deciding tuples belong set answers checkedk entailment tests.algorithm present paper decides query entailment. reasonsdevising decision procedure query entailment instead query answering twofold: first, query answering reduced query entailment shown above; second,contrast query answering, query entailment decision problem studiedterms complexity theory.3.2 Simplifying Assumptionsfollowing, make several assumptions without loss generality,simplify presentation decision procedure.3.2.1 SHOIQ ALCHOIQb simplified ALCOIFb Knowledge Basesfollowing, work ALCOIFb knowledge bases. Nevertheless, resultsalso hold SHOIQ knowledge bases queries simple roles queryALCHOIQb knowledge bases, i.e., knowledge base contains safe Boolean roleexpressions, transitivity. restriction ALCOIFb without loss generality,show now.Provided query contains simple roles, use elimination techniquestransitivity (Kazakov & Motik, 2008) reduce SHOIQ knowledge base ALCHOIQknowledge base extended signature. eliminate qualified number restrictions role inclusion axioms transforming ALCHOIQb knowledge baseALCOIFb knowledge base equivalent original one extensionsignature (Rudolph, Krotzsch, & Hitzler, 2008). repeat formal proof here,rather give informal argument reduction works.assume knowledge base negation normal form, i.e., GCIsform > v C C concept NNF. Now, consider concept expression form> n r.C r role C concept. means least n distinct rneighbors satisfying C. However, situation enforced introducing n new rolesr1 , . . . , rn deemed r superrole (ri v r) pairwisedisjoint (> v (ri u rj ).). side conditions, concept expressionreplaced r1 .C u . . . u rn .C.somewhat dual argumentation possible concept expressions form 6 n r.Crestricting number r-neighbors satisfying C n. extendsignature introducing new roles r1 , . . . , rn , time, let cover outgoingr-links following sense: whenever r-link leads domain elementsatisfies C, one roles r1 , . . . , rn also leads there. Indeed, safe Boolean roleexpressions allow expressing correspondence via concept description (r u r1 u. . . u rn ).C. easy see, concept expression replaceadditionally demand roles r1 , . . . , rn functional.440fiNominals, Inverses, Counting, Conjunctive Queries{o} v r.Av r.Av s.Bfunc(f )func(g )B vC tDC v f.Ev g.EE v B {o}r{o}ErfBC ErgBDErfBC ErgBDErfBC EgFigure 2: Knowledge base running example representation modelknowledge base.Finally consider role hierarchy statement r v s, stating whenever two domainelements 1 2 connected role r, also interconnected via s. Clearly,statement reformulated as: two domain elements connected rs. This, turn, equivalently rephrased saying domain elementr u s-neighbor or, expressed GCI, > v (r u s)..transformations applied ALCHOIQb knowledge base, wherebycardinality constraints role inclusion axioms eliminated. leaves usequivalent ALCOIFb knowledge base extension signature.Figure 2 displays ALCOIFb knowledge base according model,refer running example throughout paper.Furthermore, assume ABox internalized (e.g., C(a) replacedequivalent GCI {a} v C, r(a, b) {a} v r.{b}, etc.). Thus, effectively decide queryentailment respect TBox since knowledge bases setting emptyABox.ALCOIFb TBox, always possible transform equivalent TBox0 signature extension GCIs 0 one following simplifiedforms:lGAi vBj | {o} | v U.B | v U.B | func(f ),(1)A(i) B(j) concept names, andindividual name, U safe BooleanF roleexpression, f role. = 0, interpret Ai > j = 0, interpret Bj. ALCOIFb knowledge base K = (T , A) simplified simplified empty.Every ALCOIFb knowledge base, form, transformed polynomial time desired form using standard structural transformation,iteratively introduces definitions compound sub-concepts (Kazakov & Motik, 2008).Thus, assume remainder knowledge base rewritten simplifiedALCOIFb knowledge base.441fiRudolph & Glimm3.2.2 Connected Constant-free Queriesassume queries connected. precisely, let q conjunctive query.say q connected if, t, t0 term(q), exists sequence t1 , . . . , tnt1 = t, tn = t0 and, 1 < n, exists role name r r(ti , ti+1 ) qr(ti+1 , ti ) q. collection q1 , . . . , qn queries partitioning q q = q1 . . . qn ,term(qi ) term(qj ) = 1 < j n, qi connected.Lemma 6. Let K knowledge base, q conjunctive query, q1 , . . . , qn partitioningq. K |= q iff K |= qi 1 n.proof given Tessaris (2001) and, lemma, clear restrictionconnected queries indeed without loss generality since entailment q decidedchecking entailment qi time. follows, therefore assume queriesconnected without notice.unions conjunctive queries, assume variable names disjunctdifferent variable names disjuncts. always achievednaming variables apart. assume disjunct UCQ connected conjunctive query. without loss generality since UCQ contains unconnecteddisjuncts always transformed conjunctive normal form; decide entailment resulting conjunct separately conjunct union connectedconjunctive queries (Glimm et al., 2008a). Note that, due transformation conjunctive normal form, resulting number unions connected conjunctive queriestest entailment exponential size original query.assume queries contain constants (individual names) occurposition variables. presence nominals without loss generality:individual name occurring q, extend knowledge base K axioms{a} Na Na NC fresh concept name, replace occurrence qfresh variable xa NV add concept atom Na (xa ) q.3.2.3 General NotationThroughout paper, concept names role expressions written upper case,roles individual names written lower case. Unless stated otherwise, useB concept names; C possibly complex concepts; r roles, ffunctional inverse functional roles; U V safe Boolean role expressions;nominals used TBox axioms occur complex concepts. Sub-superscripts might appended necessary. stated otherwise, use q (possiblysubscripts) connected Boolean conjunctive query, K simplified ALCOIFbknowledge base, interpretation (I , ), , evaluations.4. Model Constructionsection, introduce interpretations models kind forest shape.main notion forest is, however, weak since also allow arbitraryrelations tree elements roots. Without relations, call resultstrict forest. exploit nice properties trees forests following sections,442fiNominals, Inverses, Counting, Conjunctive Queriesreplace parts interpretations give rise infinite number new nominals.Since even models ALCOIFb knowledge base kind forest shapereally forests, also introduce approximations models nominals longerinterpreted singleton sets. call structures quasi-interpretations quasi-modelsinterpretations form real forests. Further, provide wayunraveling arbitrary model forest quasi-model knowledge baseway collapsing forest quasi-models back real models knowledgebase still kind forest shape.Definition 7 (Forest (Quasi-)Interpretations (Quasi-)Models). tree nonempty, prefix-closed subset . w, w0 , call w0 successor w w0 = w cc IN, denotes concatenation. call w0 predecessor w w = w0 cc IN, w0 neighbor w w0 successor w vice versa. emptyword called root tree. use |w| denote length w.forest F subset R , R countable, possibly infinite set elementsthat, R, set {w | (, w) F } tree. pair (, ) F calledroot F . (, w), (0 , w0 ) F , call (0 , w0 ) successor (, w) 0 = w0successor w; (0 , w0 ) predecessor (, w) 0 = w0 predecessor w;(0 , w0 ) neighbor (, w) (0 , w0 ) successor (, w) vice versa. node (, w)ancestor node (0 , w0 ) = 0 w prefix w0 descendant= 0 w0 prefix w.forest interpretation knowledge base K interpretation = (I , )satisfies following conditions:FI1 forest roots R;FI2 total surjective function : nom(K) R {} (o) = (, )iff oI = (, );FI3 role r rol(K), h(, w), (0 , w0 )i rI , either(a) w = w0 = ,(b) (, w) neighbor (0 , w0 ).|= K, say forest model K. single root, call treeinterpretation tree model K, respectively.Let K ALCOIFb knowledge base. nomFree(K), denote ALCIFbknowledge base obtained K replacing nominal concept {o} nom(K)fresh concept name . forest quasi-interpretation K interpretationJ = (J , J ) nomFree(K) satisfies following properties:FQ1 J forest roots R;FQ2 total surjective function : nom(K) R {} (o) = (, )iff (, ) NoJFQ3 role r rol(K), h(, w), (0 , w0 )i rI , either(a) w = w0 = ,443fiRudolph & Glimm(b) (, w) neighbor (0 , w0 ).Note condition FQ2 allows elements (, w) J w 6= (, w) NoJ .call J strict condition FQ3, FQ3(b) allowed. J |= nomFree(K) sayJ forest quasi-model K.branching degree d(w) node w tree number successors w. Let= (I , ) forest (quasi) interpretation K. k d(w) k(, w) , say branching degree k.4remainder, use concept name , mean fresh concept nameintroduced nomFree(K) nominal concept {o} nom(K). Elementsextension concept called nominal placeholders. Please note that,forest quasi-interpretations J , several elements (, w) w 6=(, w) NoJ .following, define notion isomorphism forest interpretations. Notedemand structural identity w.r.t. concepts roles also w.r.t.successor relation.Definition 8 (Isomorphism Forest Interpretations). Let I, 0 two forest inter0pretations K 1 , 2 , 10 , 20 . pairs h1 , 2 i, h10 , 20 isomorphicw.r.t. K, written h1 , 2=K h10 , 20 iff01. h1 , 2 rI iff h10 , 20 rI r rol(K),02. AI iff i0 AI {1, 2} con(K),03. = oI iff i0 = oI {1, 2} nom(K).say 0 isomorphic w.r.t. K, written:=K 0 , bijection0: that, 1 , 2 , h1 , 2=K h(1 ), (2 )i 1successor 2 iff (1 ) successor (2 ).4clear context, omit subscript K=K . extend definitionobvious way forest quasi-interpretations, i.e., omitting condition 3 definingisomorphism respect K0 = nomFree(K).Forest quasi-models have, intuitively, purpose intermediate step arbitrary models K forest models K. identifying interpretationconcept knowledge base K0 root interpretation ,obtain interpretation would model K apart functionality restrictionsnominals might violated. show later eliminate relations forest back roots violate functionality restrictionseventually obtain forest model forest quasi-model.Another useful property quasi-interpretations that, simplified ALCIFb knowledge bases, checked locally whether interpretation actually modelK.Definition 9 (Local K-consistency). Let = (I , ) interpretation simplifiedALCIFb knowledge base K . define local satisfaction conceptsoccur simplified ALCIFb axioms follows:444fiNominals, Inverses, Counting, Conjunctive Queries1. A1 , . . . , con(K):(a) I, |=(b) I, |=FAi AIi 1 n; I, 6|=Ai otherwise;FAi AIi 1 n; I, 6|= Ai otherwise;2. U safe Boolean role expression rol(K), con(K):(a) I, |= U.A 0 h, 0 U I, 0 |= A;I, 6|= U.A otherwise;(b) I, |= U.A if, 0 h, 0 U , I, 0 |= A; I, 6|= U.Aotherwise;3. f rol(K), I, |= func(f ) ]({ 0 | h, 0 f }) 1; I, 6|= func(f )otherwise.element locally satisfies GCI C v C, ALCIFb-concepts I, |= Cimplies I, |= D. locally satisfies functionality restriction func(f ) I, |= func(f ).element locally K-consistent locally satisfies axiom K.4Lemma 10. Let K simplified ALCIFb knowledge base = (I , ) interpretation K. model K iff element locally K-consistent.Proof. simplified ALCIFb knowledge bases, axioms form v U.Bv U.B involve checking neighbors element and, since B concept namesimplified knowledge bases, immediate satisfaction B checked locallyneighbor question.knowledge base K nominals, also use local K-consistency,need additional global condition ensures nominals interpreted singletonsets. following immediate consequence Lemma 10 extra condition 2nominals:Proposition 11. Let K simplified ALCOIFb knowledge base = (I , )interpretation K. model K iff1. element locally K-consistent and,2. nom(K), exactly one element oI = .445fiRudolph & Glimmshow obtain forest quasi-model model K usingadapted version unraveling.Definition 12 (Unraveling). Let K consistent ALCOIFb knowledge base =(I , ) model K. Let choose function returns, concept C = U.Bcl(K) element (U.B)I element C, h, C, UC, B .Without loss generality, assume that, concepts C1 = U1 .B1 , C2 =U2 .B2 cl(K) C1I C2I , choose(C1 , ) = 1 , choose(C2 , ) = 2 ,h, 1= h, 2 i, 1 = 2 .unraveling element , denoted (I, ), interpretationobtained follows: define set (I ) sequencessmallest setsequence;1 n n+1 sequence,1 n sequence,n > 2 hn , n1 f functional role f , n+1 6= n1 ,n+1 = choose(C, n ) C = U.B cl(K).fix set F {} bijection : F(i) F forest,(ii) (, ) = ,(iii) (, w), (, w c) F w c successor w, (, w c) = (, w) n+1n+1 .forest F bijection exist prefix-closed set root . Thus,map notion sequences forests.nom(K), let NC fresh concept name. (, w) F , setTail(, w) = n (, w) = 1 n . Now, define unraveling interpretationJ = (J , J ) J = F and, (, w) J , define interpretationconcept role names follows:(a) nom(K), NoJ = {(, w) J | Tail(, w) oI };(b) concept name con(K), AJ = {(, w) J | Tail(, w) AI };(c) role name r rol(K), h(, w), (, w0 )i rJ iff w0 neighbor w,hTail(, w), Tail(, w0 )i rI .Let R subset contains exactly oI =nom(K). Let U set containing unraveling starting R.union interpretations U called unraveling I, denoted (I),unions interpretations defined natural way.4446fiNominals, Inverses, Counting, Conjunctive QueriesEBCEBDEfBCEgBCErBDEfBDEfgBCEgBCE...rBDEgBCEf..rrrrrBDEg.f...BDEgf..E...E...E....Figure 3: Unraveling model displayed Figure 2.Figure 3 shows unraveling example knowledge base model. dottedlines non-root elements labeled indicate copy whole treeappended since stop unraveling nominal placeholders.might helpful think function Tail homomorphism (up signatureextension) elements unraveling J elements original model I.Indeed, Tail satisfies following properties: (, w), ( 0 , w0 ) J ,Tail(, w) = oI iff (, w) NoJ , nom(K),Tail(, w) AI iff (, w) AJ , con(K),hTail(, w), Tail( 0 , w0 )i rI iff h(, w), ( 0 , w0 )i rJ , r rol(K).Unravelings first step process transforming arbitrary model Kforest model since resulting model forest quasi-model K, shownext lemma.Lemma 13. Let K consistent ALCOIFb knowledge base = (I , ) modelK. J = (J , J ) = (I) strict forest quasi-model K.Proof. Let K0 = nomFree(K). construction, J satisfies conditions FQ1 FQ3forest quasi-models strictness condition. Since J obtained modelK, definition unravelings starting oI =nom(K), condition (a) unravelings, is, nom(K), one root(, ) J (, ) NoJ . Thus, J satisfies also property FQ2 J forestquasi-interpretation K. show J model K0 demonstrating(, w) J locally K0 -consistent. Since assume knowledge bases simplified,consider axioms form (1).447fiRudolph & GlimmFLet Ax axiom form Ai v Bj assume(, w) ( Ai )J .condition (b) unravelings, w = Tail(, w) ( Ai )I and, since |= K,w BjI j. condition (b) unravelings, (, w) BjJrequired.Axioms form {o} K rewritten K0 . consider vv separately. Let Ax form v nom(K) assume(, w) AJ . condition (b), w = Tail(, w) AI and, since |= K,w {oI }. condition (a) unravelings, (, w) NoJrequired. v nom(K), assume (, w) NoJ . condition (a),w = Tail(, w) {oI } and, since |= K, w AI . condition (b)unravelings, (, w) AJ required.Let Ax axiom form v U.B assume (, w) AJ . condition (b), w = Tail(, w) AI and, since |= K, w0hw , w0 U w0 B . Let ( 0 , w0 ) h(, w), ( 0 , w0 )i U J( 0 , w0 )/ B J . condition (c) unravelings, hw , w0 Uw0 = Tail( 0 , w0 ) condition (b) w0/ B , contradiction.Let Ax axiom form v U.B assume (, w) AJ . condition (b), w = Tail(, w) AI and, since |= K, least onew0 hw , w0 U w0 B . case oneelement, let w0 w0 = choose(C, w ). Then, definition sequences,neighbor (, w0 ) (, w) Tail(, w0 ) = w0 . Let (, w) = 1 n , i.e., n = w .distinguish two cases:1. element w0 w0 = n1 . definition bijection , w =w0 c, definition J (condition (c)) since hw , w0 U ,h(, w), (, w0 )i U J . Then, since B concept name w0 B ,condition (b) (, w0 ) B J , proves claim.2. element w0 w0 6= n1 . definition sequences bijection, (, w0 ) = 1 n w0 . Now, definition J (in particularproperties (b) (c)), h(, w), (, w0 )i U J and, since B conceptname, (, w0 ) B J , proves claim.Let Ax axiom form func(r) r rol(K). Assume, contraryshown, (, w) two distinct neighbors (, w1 ), (, w2 )h(, w), (, w1 )i, h(, w), (, w2 )i rJ . Since function introduced unravelingbijection, two distinct sequences s1 s2 (, w1 ) = s1 (, w2 ) = s2Tail(, w1 ) = 1 , Tail(, w2 ) = 2 1 6= 2 . Since h(, w), (, w1 )i, h(, w), (, w2 )irJ get, due condition (c), hTail(, w), 1 i, hTail(, w), 2 rI , contradiction since |= K.Since (, w) arbitrarily chosen, element domain Jlocally K0 -consistent required J |= K0 Lemma 10.Lemma 14. Let K consistent ALCOIFb knowledge base, = (I , ) model K,J = (J , J ) = (I) unraveling I. J branching degree bounded|cl(K)|.448fiNominals, Inverses, Counting, Conjunctive QueriesProof. Let number axioms K. axiom simplified knowledge basecontain one existential restriction and, due definition functionchoose used unraveling, are, sequence S, elements1 , . . . , 1 sequence S. Since mappingforest J sequences bijection, J forest branching degree m.following steps, traverse forest quasi-model order elementssmaller tree depth always smaller order elements greater tree depth.Elements tree depth ordered lexicographically. bounded branchingdegree unravelings guarantees that, finite number steps, gonext level forest process nodes eventually. Further, merge nodesthat, finally, nominal placeholders (in extension ) interpretednominals without violating functionality restrictions. fact,merge nominal placeholders, also elements related nominal placeholderinverse functional role since, definition semantics, elementscorrespond element model. order identify elements, definenotion backwards counting paths follows:Definition 15 (Paths BCPs). Let = (I , ) interpretation. call 1 . . . npath 1 n if, 1 < n, hi , i+1 riI role ri rol(K).length |p| path p = 1 . . . n n 1. element path lengthUUn10. write 1 1 2 . . . n denote path 1 n hi , i+1 UiI1 < n Ui safe Boolean role expression.Let K ALCOIFb knowledge base = (I , ) forest model (a forest quasimodel) K. path p = 1 . . .n descending path root (, )that, 1 n, = (, wi ) and, 1 < n, |wi | < |wi+1 |.path p backwards counting path (BCP) n = oI (n NoI ) nominalnom(K) and, 1 < n, hi , i+1 fiI inverse functional rolefi rol(K). path p descending BCP BCP descending path. Givenf1fnBCP p = 1 2 . . . n+1 n+1 oJ (n+1 NoJ ), call sequence f1 fnpath sketch p.4Please note element domain J already counts (descending) BCPoJ (NoJ ) nom(K).define order guarantees iterative parsing process,process nodes, also merge nodes required that, finally, nominalplaceholders interpreted nominals without violating functionality restrictions.Definition 16 (Ordering). convenience without loss generality, assumeset individual names NI ordered. Let K consistent ALCOIFb knowledgebase J forest quasi-interpretation K. extend order elements Jfollows: let w1 = wp c11 cn1 , w2 = wp c12 cm2 wp longestcommon prefix w1 w2 , w1 < w2 either n < n = c11 < c12 .(1 , ), (2 , ) J , let o1 nom(K) smallest nominal (1 , ) NoJ1o2 nom(K) smallest nominal (2 , ) NoJ2 . (1 , w1 ) < (2 , w2 ) either(i) |w1 | < |w2 | (ii) |w1 | = |w2 | o1 < o2 (ii) |w1 | = |w2 |, o1 = o2 w1 < w2 .449fiRudolph & Glimmfollowing, merging elements unraveling and, process, createnew roots form (w, ) elements form (, w) elements form(w, w0 ) (, ww0 ). extend, therefore, order elements form follows:(1 w1 , w10 ) < (2 w2 , w20 ) (1 , w1 w10 ) < (2 , w2 w20 ).4Roughly speaking, proceed follows order transform quasi-forest modelJ forest model I: work way downwards trees level level alongdescending BCPs use defined order purpose. definitionsemantics, elements start descending BCP or, precisely, startBCPs identical path sketches, correspond element forestmodel produce. traversal forest quasi-model, distinguishtwo situations: (i) encounter element (, w) starts descending BCPseen another element starts descending BCP pathsketch. case, promote (, w) become new root node form (w, )shift subtree rooted (, w) it; (ii) encounter node (, w) startsdescending BCP, already seen node (0 , w0 ) starts descending BCPpath sketch root form (0 w0 , ). case, deletesubtree rooted (, w) identify (, w) (0 w0 , ). (, w) f -successorpredecessor inverse functional role f , delete f -successors (0 w0 , )subtrees order satisfy functionality restriction. use notion collapsingadmissibility characterize models predecessor (, w) satisfiesatomic concepts deleted successor (0 , w0 ), ensures local consistencypreserved. virtue notion, characterize forest quasi-modelscollapsed proper models irrespective whether obtained unravelingmodel not.order keep domain forest promoting element (, w) new root,build new domain elements form (w, ) (, w) elementsform (w, w0 ) descendants (, ww0 ) (, w).Definition 17 (Equivalence Relation Collapsings). Let K ALCOIFb knowledge base, K0 = nomFree(K), J = (J , J ) forest quasi-interpretation K.define smallest equivalence relation J satisfies 1 2 1 , 2 startdescending BCPs identical path sketches.Let J strict forest quasi-interpretation K, J0 = (J0 , J0 ) = J (0 , w0 )J0smallest element w0 6= starts descending BCP. call J0 initialcollapsing J (0 , w0 ) focus J0 .Let Ji collapsing J (i , wi ) Ji focus Ji . obtain collapsingJi+1 = (Ji+1 , Ji+1 ) focus (i+1 , wi+1 ) J Ji according following twocases:1. element (, ) Ji (, ) smaller focus (i , wi )(, ) (i , wi ). Ji+i obtained Ji renaming element (i , wi wi0 )Ji (i wi , wi0 ).2. element (, ) Ji (, ) smaller focus (i , wi )(, ) (i , wi ). Let (, ) smallest element.450fiNominals, Inverses, Counting, Conjunctive Queries(a) Ji+1 = Ji \ ({(i , wi wi0 ) | wi0 } {(, w) | w = c w0 , c IN, w0, (i , wi ) predecessor (i , wi0 ) h(i , wi0 ), (i , wi )i f Jiinverse functional role f rol(K) h(, c), (, )i f Ji });(b) concept name con(K) (, w) Ji+1 , (, w) AJi+1 iff (, w)AJi ;(c) role name r rol(K) (1 , w1 ), (2 , w2 ) Ji+1 , h(1 , w1 ), (2 , w2 )irJi+1 iffi. h(1 , w1 ), (2 , w2 )i rJiii. (1 , w1 ) predecessor (i , wi ) Ji (i.e., 1 = wi = w1 cc IN), (2 , w2 ) = (, ), h(1 , w1 ), (i , wi )i rJi .focus (i+1 , wi+1 ) Ji+1 smallest descending BCP (i , wi ) < (i+1 , wi+1 ).collapsing Ji , let safe(Ji ) restriction Ji elements (, w)(, w) Jj j i. J denote non-disjoint union interpretationssafe(Ji ) obtained subsequent collapsings Ji J . interpretation obtainedJ interpreting nom(K) (, ) NoJ denoted collapse(J ) calledpurified interpretation respect J. collapse(J ) |= K, call collapse(J ) purifiedmodel K.4Figures 4 7 illustrate first collapsing steps unraveling depictedFigure 3. Apart nominal placeholder concepts, concept interpretationsshown figures, assumed indicated Figure 3. edgesdescending BCPs shown red color, dashed lines Figure 4 indicate levelstree because, within tree, order nodes processed depends firstlylevel. Within level, assume order increases left right.numbers next nodes Figure 4 indicate, elements used focus elementcollapsing step order. initial collapsing (Figure 4) focusfirst non-root element starts BCP, indicate black border aroundnode black triangle pointing focus.first collapsing step rename elements promote focus Figure 4root. focus element highlighted Figure 5 starts BCP path sketchdifferent ones started smaller elements, rename elementsobtain new root (Figure 6). Now, focus nominal placeholder since nominalplaceholder BCPs, root path sketch use second caseDefinition 17. resulting collapsing depicted Figure 7.Finally, obtain collapsing unraveling shown Figure 3 one depictedFigure 8.show collapsing unraveling results forest modelK. aim is, however, show something general. want collapseunravelings forest models, also forest quasi-models obtainedanother way. Unfortunately, case collapsing forest quasi-modelresults forest model K since elements merge collapsing processnecessarily satisfy atomic concepts. define, therefore, followingadmissibility criterion characterizes forest quasi-models collapsedforest models.451fiRudolph & GlimmrrH1r34ffrgfrgg5fgrHgrr2grfrfFigure 4: initial collapsing un- Figure 5: first collapsing stepraveling depicted Figure 3.rename elements promotefocus Figure 4 root.rrfrrrrfHrggffrrgggNfgfrFigure 6: collapsing obtained Figure 7: collapsing obtained usingone depicted Figure 5.second case Definition 17collapsing Figure 6.Definition 18 (Collapsing-admissibility). Let J forest quasi-interpretationALCOIFb knowledge base K. J collapsing-admissible exists functionch : (cl(K) J ) J1. concept C = U.B cl(K) C J , h, ch(C, )i U Jch(C, ) B J . Moreover, functional role f h, ch(C, )i f Jch(C, ) successor ,2. concept C = U.B cl(K) elements , 0 C J start descendingBCPs identical path sketches, h, ch(C, )i= h 0 , ch(C, 0 )i.4Lemma 19. Let K ALCOIFb knowledge base. unraveling J modelK collapsing-admissible.452fiNominals, Inverses, Counting, Conjunctive QueriesBBBBB{o} E f C E g E f C E g E f C E grrrrrr...Figure 8: Result collapsing unraveling Fig. 3. infinitely many new rootelements displayed top line.Proof. define function ch directly function choose used unraveling follows: C cl(K) (, w) J (, w) = 1 . . . nchoose(C, Tail(, w)) = { 0 }, set ch(C, (, w)) = (, w0 ) (, w0 ) = (1 . . . n 0 )1 . . . n 0 sequence (, w0 ) = (1 . . . n1 ) otherwise.well-defined since function unravelings total bijective requiredadmissibility since elements start BCPs identical path sketches alwaysgenerated element I. first condition collapsing-admissibility holdssince unravelings, always add 1 . . . n 0 set sequences unless pairhn , n1 interpretation functional role. case, function ch usespredecessor instead successor, still admissible.Lemma 20. Let K consistent ALCOIFb knowledge base, J = (J , J ) strict forestquasi-model K branching degree b collapsing-admissible. collapse(J )forest model K branching degree b.Proof. Let K0 = nomFree(K). Since J forest quasi-model K assumption, J |= K0 .first show collapsing Ji J forest quasi-model K, i.e., Ji |= K0 .show collapsing Ji+1 produced admissible collapsing Jicollapsing-admissible. Finally, show that, nom(K), exactly onenode J form (, ) (, ) NoJ , implies Proposition 11collapse(J ) forest model K.start first claim: initial collapsing immediate since Jforest quasi-model K. particular, J0 locally K0 -consistent. Assume Jilocally K0 -consistent collapsing (i , wi ) focus Ji . show Ji+1 locally453fiRudolph & GlimmK0 -consistent. Since K0 simplified assumption, consider axiomsform (1).Ji+1 obtained according first case Definition 17, rename elementsdomain order create new root node local K0 -consistency immediate.assume, thus, Ji+1according second case Definition 17.obtainedFAxioms form Ai v Bj {o} (rewritten K0 ) holdimmediately due condition 2.b collapsings.Let Ax axiom form v U.B assume (, w) AJ .interesting elements predecessor (i , wi0 ) focus (i , wi ) (, ). However,(i , wi ) (, ) and, since J collapsing-admissible, (i , wi ) (, ) satisfyatomic concepts respect con(K). Further, interpretation atomic conceptschanged due 2.b, implies local K0 -consistency kind axioms.Let Ax axiom form v U.B assume (, w) AJi+1 . concentrate three interesting cases direct neighborhoods elements change:1. start case focus (i , wi ) corresponding U -successor(, w), i.e., = , wi = wc c IN, h(, w), (i , wi )i U Ji , (i , wi ) B Ji .Since (, ) (i , wi ) equivalence class assumption, (, )starts BCP path sketch (i , wi ) (, ) (i , wi ) satisfyatomic concepts respect con(K). condition 2.(c)ii. ensures(, ) required U -successor (, w) Ji+1 .2. Assume (, w) = (, ), h(, ), (, c)i U Ji , (, c) B Ji , (, c)/ Ji+1 ,Ji+1(, )/ (U.B). Due 2.a, focus (i , wi ) predecessor (i , wi0 )0h(i , wi ), (i , wi )i f Ji inverse functional role f rol(K) h(, ), (, c)i(f )Ji . Since f inverse functional Ji is, assumption, locally K0 -consistent,successor (i , wi ci ) (i , wi ) h(i , wi ), (i , wi ci )i (f )Ji .Similarly, element (0 , w0 ) h(, ), (0 , w0 )i (f )Ji . Then,since Ji collapsing-admissible, (i , wi0 ) ch(U.B, (i , wi )), (, c)ch(U.B, (, )), h(i , wi ), (i , wi0 )i= h(, ), (, c)i since (i , wi ) (, ) startdescending BCPs identical path sketches. particular, h(i , wi ), (i , wi0 )i U Ji(i , wi0 ) B Ji . Then, condition 2.(c)ii., h(, ), (i , wi0 )i U Ji+1 , condition 2.b, (i , wi0 ) B Ji+1 , and, thus, (, ) (U.B)Ji+1 required.3. assume (i , wi ) predecessor (i , wi0 ) h(i , wi0 ), (i , wi )i f Jiinverse functional role f rol(K) h(, c), (, )i f Ji , causing deletion(, c) descendants, one which, say (, v) connected (, ),h(, ), (, v)i U Ji (, v) B Ji . Now, inverse functional roleg h(, ), (, v)i g Ji , strictness collapsing-admissibility Jiensure existence c0 h(, ), (, c)i U Ji (, c) B Ji and,consequently, also h(, ), (, c)i U Ji+1 (, c) B Ji+1 . h(, ), (, v)i g Jiinverse functional role g, strictness initial collapsing implies(, v) started descending BCP and, due defined order, mustfocus root itself. contradicts, however, initialassumption (, v) descendant (, ) done.cases, elements Ji+1 required successors.454fiNominals, Inverses, Counting, Conjunctive QueriesLet Ax axiom form func(f ) f rol(K). concentrate relationspredecessor (i , wi0 ) focus (, ) since otherwise local K0 -consistencyimmediate. predecessor exists focus since process elements ascending order starting non-root nodes. Assume h(i , wi0 ), (i , wi )i f Ji , caseh(i , wi0 ), (, )i f Ji+1 due 2.(c)ii. assume (, ) successor (, c) Jih(, c), (, )i f Ji . case, (, c)/ Ji+1 according 2.a together0local K -consistency Ji , implies (i , wi0 ) element Ji+1h(i , wi0 ), (, )i f Ji+1 .show Ji+1 produced admissible collapsing Ji admissible collapsing. assumption, initial collapsing admissible, let Jiadmissible collapsing chi required function. distinguish two cases:1. Let Ji+1 produced according first case collapsings. define functionchi+1 Ji+1 follows: C cl(K) Ji+1 , set chi+1 (C, ) = 00 = (i wi , w10 ) chi (C, ) = (i , wi wi0 ) (i , wi ) focus Ji 0 = chi (C, )otherwise. Since change names elements leave interpretationconcepts roles before, function required admissibility.2. Let Ji+1 produced according second case collapsings. define functionchi+1 Ji+1 follows: C cl(K),(a) Ji+1/ {(i , wi0 ), (, )} (i , wi0 ) predecessor focus(i , wi ), set chi+1 (C, ) = 0 0 0 Ji+1 0 = chi (C, );well-defined since successors (, ) (i , wi0 ) deleted Ji+1 .(b) = (, ) (i , wi0 ) predecessor focus, chi+1 (C, ) = 00 = (i , wi0 ) chi (C, ) = (, c) (, c)/ Ji+1 0 = chi (C, ) otherwise;(c) = (i , wi0 ) predecessor focus, set chi+1 (C, ) = 0 0 = (, )chi (C, ) = (i , wi ) 0 = chi (C, ) otherwise.elements apart predecessor focus (i , wi0 ) root (, )replaces (i , wi ), interpretation concepts roles remainsproperties 2.b 2.c function required. (i , wi0 ), changefunction cases (i , wi ) returned, (, ) returned. Since(i , wi ) (, ), admissible. Similarly, successor (, c) (, ) contained Ji+1 , (i , wi0 ) used instead. admissible since, case,h(i , wi ), (i , wi0 )i= h(, ), (, c)i argued axioms form v U.B.show that, nom(K), exactly one node J form(, ) (, ) NoJ . Nominal placeholders descending BCPs definition and,nominal placeholder becomes focus, merged rootequivalence class definition lower order. root existsproperty FQ2 forest quasi-interpretations.interpretation J obtained building non-disjoint union safe partscollapsings, contain elements neither renamed deleted.Thus, J contain nominal placeholders required. Considering one element(, w) J , find successors root neighbors455fiRudolph & Glimm(, w) Ji J . shown, Ji locally K0 -consistenttherefore (, w) consistent neighborhood. Hence J forest quasi-model K.Now, interpreting nom(K) {(, ) J | (, ) NoJ } collapse(J ),obtain forest model K, set roots {(, ) | (, ) J }.bounded branching degree immediate consequence construction sincenever add successors construction starting forest quasi-interpretationJ bounded branching degree assumption.Since unravelings model K strict forest quasi-models K branching degree bounded |cl(K)| Lemma 13, unravelings collapsing-admissibleLemma 19, immediate consequence Lemma 20 collapsing unravelingyields forest model branching degree bounded |cl(K)|.Corollary 21. Let K ALCOIFb knowledge base interpretation|= K, purified interpretation collapse((I)) forest model K branchingdegree b bounded |cl(K)|.Since number roots might still infinite purified models, could,now, obtained result unraveling arbitrary model, takeelements BCPs roots instead taking nominals creating new rootscollapsing process. next sections, however, show transformunraveling counter-model query remains collapsing-admissibleend collapsed forest model finite numberroots still counter model query. transformation muchconvenient work real (strict) trees forests, use (strict) forestquasi-interpretations.next sections, also use following alternative characterization resultcollapsing, comes handy subsequent proofs.start defining so-called pruning forest quasi-interpretation, is,roughly speaking, structure obtained deleting nodes, erasedcourse collapsing process anyway.Definition 22 (Pruning). Let J strict forest quasi-model ALCOIFb knowledgebase K collapsing-admissible let J0 , J1 , . . . , J defined Definition 17.pruning J (written prune(J )) obtained restricting J set Jdefined follows: contains hw1 , w2 w3 J hw1 w2 , w3 Jhw1 w2 , w3 focus Ji .4use equivalence relation elements start descending BCPsidentical path sketches Definition 17 construct interpretation pruningidentifying equivalent nodes, also known factorization.Definition 23 (Factorization). Let K ALCOIFb knowledge base, J strict forestquasi-interpretation K collapsing-admissible, L = prune(J ).factorization L (denoted L/ ) defined forest quasi-interpretation = (M , )= {[] | L };456fiNominals, Inverses, Counting, Conjunctive Queriescon(K), = {[] | AL },r rol(K), rM = {h[] , [ 0 ] | h, 0 rL },nom(K), oM = [] NoL .4Note interpretation nominals well defined as, definition,-instances -equivalence class.ready establish wanted correspondence: collapsing forestquasi-interpretation essentially obtained first pruning factorizing it.Lemma 24. Let J strict forest quasi-model ALCOIFb knowledge base Klet J collapsing-admissible. collapse(J )= prune(J )/ . Moreover new rootscollapse(J ) correspond -equivalence classes contain J -elements startdescending BCPs J .Proof. Considering first claim, note definition collapsing procedure,every (w, w0 ) collapse(J ) exactly one pair w1 , w2 w = w1 w2(w1 , w2 w0 ) prune(J ) . Moreover, case 1 construction assures collapse(J ) contains one element every -equivalence class prune(J )/ . Hence mapping: collapse(J ) prune(J )/ (w, w0 ) = [(w1 , w2 w0 )] bijection and, consequence construction, isomorphism.second claim also direct consequence construction collapsing.5. Quasi-Entailment Quasi-Modelssection, provide characterization forest quasi-models mirrors queryentailment corresponding proper models. argumentation,talk initial part tree, i.e., part left branches cutfixed length. forest interpretation = (I , ) n IN, therefore denotecutn (I) interpretation obtained restricting pairs (, w)|w| n.following lemma ensures case purified models, find finitelymany unraveling trees depth n look different.Lemma 25. Let K consistent ALCOIFb knowledge base. purifiedinterpretation |= K and, every n IN, finitely manynon-isomorphic trees depth n.Proof. Since K model assumption, Corollary 21 guaranteespurified model K. particular, forest model branching degree boundedsize cl(K).compute maximal number non-isomorphic trees depth ndomain I. denote bound Tn . argumentation close one usedLevy Rousset (1998) definition tree blocking.457fiRudolph & GlimmLet c = |cl(K)| r = |rol(K)|. first consider trees depth n = 0. 2cchoices different subsets concepts cl(K). n > 0, concept level 0trigger generation new successor number successors0 c. Assume, now, single role name r rol(K)node level smaller n root tree depth n 1 exactlyc ) non-isomorphic sub-treesc successors node. case, O(2c Tn1depth n. Taking account node necessarily c successors,c ) number nonchoose number 0 c, get bound O(2c cTn1isomorphic sub-trees depth n. Finally, since one choice r roles,c )r ). abbreviate 2c cr x rc rewriteget bound O(2c (cTn1n1nobtained bound Tn = O(x(Tn1 )a ). Unfolding yields Tn = O((x1+a+...+a )(T0 )a )nnnbounded O((xa )(2c )a ) = O((x2c )a ). expanding abbreviated symbols,nobtain bound Tn O((2c cr )(rc) ).considerations, introduce notion anchored n-components.meant certain substructures forest quasi-interpretations. firstplace, substructures contain connected set nodes W 0 situated closelytogether original structure, closeness witnessed fact elements W 0 descendants node distance n . Moreovernodes 0 W 0 , anchored n-component may (but need to)contain finite number descending BCPs starting 0 .Definition 26 (Anchored Components). Let J forest quasi-interpretation J .interpretation C called anchored n-component J witness Ccreated restricting J set W J obtained follows:Let J subtree J started let J,n := cutn (J ). Selectsubset W 0 J,n closed predecessors.every 0 W 0 , let P finite set (possibly empty) descending BCPs p starting0 let W0 contain nodes p P .Set W = W 0 0 W 0 W0 .4think forest quasi-model J query q. following definitionlemma employ notion anchored n-components come notion quentailment (short quasi-entailment), criterion reflects query-entailment worldforest quasi-models.Definition 27 (Quentailment). Let q conjunctive query ](q) = n Jforest quasi-model ALCOIFb knowledge base K. say J quentails q (writtenJ | q) if, V = var(q), J contains connected anchored n-components C1 , . . . , C`Caccording functions : V 2 following hold:Q1 every x V , least one Ci , (x) 6=Q2 A(x) q, (x) AJ i.458fiNominals, Inverses, Counting, Conjunctive QueriesQ3 every r(x, y) q Ci 1 (x) 2 (y)h1 , 2 rJ .Q4 If, x V , connected anchored n-components Ci Cj(x) 0 j (x),sequence Cn1 , . . . , Cnk n1 = nk = jsequence 1 , . . . , k 1 = k = 0 well nm (x)1 < k,that, every 1 < k,Cnm contains descending BCP p1 started ,Cnm+1 contains descending BCP p2 started m+1 ,p1 p2 path sketch.union conjunctive queries u = q1 . . . qh , say J quentails u (writtenJ | u) J | q q {q1 , . . . , qh }.4Note anchored component may contain none, one several instantiationsvariable x V . Intuitively, definition ensures, find matches query partsfitted together identifying BCP-equal elements yield complete query match.Lemma 28. Let u = q1 . . . qh union conjunctive queries K ALCOIFbknowledge base.1. model K, (I) | u implies |= u.2. strict forest quasi-model J K collapsing-admissible, collapse(J ) |= uimplies J | u.Proof.1. Let q disjunct u (I) | q, V = var(q), C1 , . . . , C`connected anchored n-components witnessing quentailment. use functionTail Definition 12 exploit properties homomorphism. Note Tailmaps nodes (I) individual I, start descending BCPspath sketches. Due condition Q4 Definition 27, implies,every x V every 1 (x) 2 j (x), Tail(1 ) = Tail(2 ). Hence,total function : V defined letting (x) = whenever Tail() =(x) 1 `, well-defined. show querymatch q examining atoms q:every unary atom A(x), definition quentailment ensuresexist Ci Ci (x) AJ . Then, definition Tail,follows (x) = Tail() AI .Likewise, every binary atom r(x, y), definition quentailment ensuresexists Ci 1 , 2 Ci 1 (x) 2 (y)well h1 , 2 rJ . Again, definition Tail, follows h(x), (y)i =hTail(1 ), Tail(2 )i rI .459fiRudolph & Glimm2. prove this, employ alternative characterization collapsings established000Lemma 24. Let 0 = (I , ) = prune(J )/ let : V matchq 0 . use construct anchored n-components functions neededshow J quentails q.Let V V contain variables maps singleton -equivalence class.define V = {V1 , . . . , Vm } finest partitioning V that,x, V , x partition whenever r(x, y) q r rol(K).Next, assign every partition V 0 V set QV 0 query atoms containingvariables V 0 . construct every V 0 anchored n-component CV 0function V 0 (initialized yielding inputs) follows:every x V 0 , let CV 0 contain J -element (x) = {}. Note0consists -equivalence classes elements J , i.e., {}0one -equivalence classes . Moreover, set V 0 (x) = V 0 (x) {}.every r(x, y) QV 0 6 V 0 (x) = {}, let CV 0 contain additional element 0 (y) h, 0 rJ (existence assured definitioncollapsing via factorization) elements descending BCPprune(J ) starting (existence assured since [ 0 ] singleton class).Moreover set V 0 (y) = V 0 (y) { 0 }.Likewise, every r(x, y) QV 0 x 6 V 0 (y) = {}, let CV 0 containadditional element 0 (x) h 0 , rJ (existence assured definition collapsing via factorization) elements shortest descendingBCP prune(J ) starting 0 (existence assured since [ 0 ] singletonclass). Moreover set V 0 (x) = V 0 (x) { 0 }.furthermore construct, query atom contains variables V ,anchored n-component Ca function (again initialized always return) follows:= r(x, y), let Ca contain two nodes 1 2 1 (x)2 (y) h1 , 2 rJ (existence assured definition via factorization)well prune(J )-descending BCP starting 1 shortestprune(J )-descending BCP starting 2 .= A(x), let Ca contain node (x) AJ (existenceassured definition via factorization) well shortest prune(J )-descending BCP starting .Let C contain CV 0 Ca defined far. Note C already satisfies conditionsQ1-Q3 Definition 27. add anchored n-componentsorder satisfy condition Q4 well. Let C0 initially empty. x V(x) non-singleton equivalence class two C , C C (x)0 (x), that, since 0 -equivalence class (x),sequence 1 , . . . , k J -nodes = 1 0 = k everyi+1 start descending BCP path sketch. enhance C0 oneanchored component per contains corresponding descending460fiNominals, Inverses, Counting, Conjunctive Queries(x1 )rr{o}EBCEf(x2 )g(x5 )rBDE(x3 ) frrBCEBDEg(x4 )rBCEgfErC11 (x1 )r1 (x2 )C2BCErBD2 (x5 )1 (x3 )EfgBCEBDf2 (x3 )EfrBC2 (x4 )EE...rBDErBCEgBCEgBCEBDEfBDEfBDEfr...gg..E...g....E......Figure 9: Correspondence entailment quentailment.BCPs. Then, construction, elements CC0 constitute necessary anchoredn-components justify J quentails q and, thus, J quentails u.example correspondence (query) entailment quentailment,consider conjunctive queryq = {r(x1 , x2 ), s(x2 , x3 ), f (x4 , x3 ), s(x5 , x4 )}.match query example model Figure 2 displayed upperpart Figure 9, witnesses |= q. lower part, anchored components C1C2 according functions 1 2 establish (I) | q.6. Limits Forest Transformationsintroducing following constructions detail, try provide highlevel explanation convey intuition behind subsequent steps. mentioned before,one major obstacles decision procedure conjunctive query entailment461fiRudolph & GlimmDLs including inverses, nominals, cardinality restrictions (or alternatively functionality), potentially infinitely many so-called new nominals: domain elementsidentified linked proper nominal via BCP.However, show every model knowledge base satisfyconjunctive query (i.e., every countermodel), nice countermodelfinitely many new nominals (in subsequent section, argue ensuresexistence procedure terminates query entailed knowledgebase question). provide construction transforms arbitrary countermodelnice one first unraveling quasi forest model, substituting newnominals uncritical elements finally collapsing result back proper model.this, find appropriate substitutes new nominals.substitutes fit environment without introducing new nominals.Due global cardinality constraints BCPs impose elements, existence infinitely many new nominals implies witnessing BCPs must getlonger longer, looking finite-distance neighborhood,new nominals look like non-nominal domain elements. state affairsexploited essentially constructing new domain elements environment-limits.way, new domain elements characterized propertyapproximated arbitrary precision already present domain elements possibly without present domain.3 see following newdomain elements serve substitutes looking for.Definition 29 (Limits Model). Let = (I , ) modelALCOIFb knowledge base K. tree interpretation J said generated (written:J C ), isomorphic restriction (I, ) elements {(, cw) | (, cw)(I,) , c 6 H} H IN.set limits (written lim I) set tree interpretations Jevery k IN, infinitely many cutk (L)= cutk (J )L C .4Figure 10 displays one limit element example model.following lemma gives useful properties limits. Besides rather obvious compatibility considerations respect knowledge base satisfaction, claim 3Lemma 30 provides us pleasant useful insight root node limitnever part BCP all.Lemma 30. Let K ALCOIFb knowledge base, K0 = nomFree(K), purified modelK, n fixed natural number. following hold:1. Let L0 tree interpretation infinitely many L0 =cutn (L) LC. Then, least one limit J lim cutn (J )=L0 .2. Every J lim locally K0 -consistent apart root (, ).3. analogy, consider fact real number approximated sequence rationalnumbers, even irrational.462fiNominals, Inverses, Counting, Conjunctive QueriesBCEBDEfBDEBCEgBCEgBCEBDEfBDEfBDEfBDEBCEgBCEgBCEgBCEg.r..rrrrf..f...f...f...BCEf....Figure 10: One limit model Fig. 23. every J lim holds root (, ) BCP (, w) J .4. J lim contains node starting two backwards counting paths path sketchess1 s2 , element unraveling holds: direct neighborhoodisomorphic starts descending BCP path sketch s1also starts descending BCP path sketch s2 .5. Every J lim collapsing-admissible.Proof.1. Let b branching degree I, let Dn (by assumption infinite) setL0= cutn (L) L C , let Jn contain L.Starting k = n, iteratively increase k construct sets Jk Dktree interpretations Lk . way, inductively prove properties.induction hypothesis know Dk infinite Lk Lk=cutk (M) Jk . Lemma 25, finitely many non-isomorphictree interpretations depth k + 1 branching degree b, partitionJk finitely many sets Jk,1 , . . . , Jk,m every two M, M0 Jk,isatisfy cutk+1 (M)= cutk+1 (M0 ). Likewise, define classes Dk,1 , . . . , Dk,mDk = Dk,1 . . . Dk,m Dk,i L C L Jk,i . Now,Dk infinite, one Dk,i must infinite well set Dk+1 = Dk,iJk+1 = Jk,i . Hence, know Dk+1 infinite Lk+1Lk+1= cutk+1 (M) Jk+1 .Thus, established infinite sequence Ln , Ln+1 , . . . Li= cuti (Lj )j > i. Without loss generality, assume isomorphic nodes namedidentically, i.e., even Li = cuti (Lj ) j > i. define J(non-disjoint) union Li . way established structure Jcutk (J ) = Lk know every k infinitely many (namelyelements Dk ) cutk (L)= Lk L C . Hence J limitelement desired properties.2. Let (, w) w 6= node J . choose cut|w|+1 (L)=cut|w|+1 (J ) L C (by definition, even infinitely many463fiRudolph & Glimmchoose from). L contains node whose direct neighborhood isomorphic(, w). However, L contained (I, ) |= K assumption,locally K0 -consistent hence is. Therefore (, w) locally K0 -consistent J .3. Assume contrary, i.e., J lim BCP root (, )(, w) J (, w) NoJ nom(K). Since functionalitydefinition BCPs, BCP uniquely identifies one domain individual.definition lim I, however, infinitely many satisfying cut|w| (L)=cut|w| (J ) J C infinite number individualscounting path oI . contradiction.4. Choose k maximum length two BCPs. definition limit,contains element cut|w|+k (L)= cut|w|+k (J ) L C . Now,let 0 L element (with respect isomorphism) correspondsJ . Then, 0 origin two descending BCPs path sketches s1s2 . Let Tail( 0 ) = 0 . Since path sketches descending BCPs uniquely identify onedomain individual, every node unraveling starts descending BCPpath sketch s1 must caused 0 well. Furthermore (asdirect neighborhoods isomorphic specific design choose functionDefinition 12 renders successors non-isomorphic), successorsuniquely correspond neighbors 0 turn successors 0 .turn implies that, every successor , one finds successor 0isomorphic direct neighbourhood. Yet, synchronicity argument inductivelyapplied thereby iterated BCP. Thus, obtain also startsdescending BCP path sketch s2 .5. define function ch : (cl(K) J ) J essentially like proofLemma 19, namely referring function choose. given element Jstarts BCP length ` J , choose 0 cut||+` (L)= cut||+` (J )L C 0 . L contained (I, 0 ), proceed define ch(C, )demonstrated proof Lemma 19.defined limit elements convenient building blocks restructuring forestquasi-interpretations, following definition provides first hints insidestructure one existing node (and successors) safely exchanged limitelement.Definition 31 (n-Secure Replacement). Let K ALCOIFb knowledge base, modelK, J forest quasi-model K J . strict tree quasi-interpretationJ 0 lim called n-secure replacementcutn ((J , )) isomorphic cutn (J 0 ),every anchored n-component J 0 witness 0 , isomorphic anchoredn-component J witness .464fiNominals, Inverses, Counting, Conjunctive QueriesE...BCEBDEfBDE=BCEgBCEgBCEBDEfBDEfBDEfBDEBCEgBCEgBCEgBCEgr/rrrf..f...f...f.r..BCEf...BDEgrBCEBDEfBCEgBCEBDEfBDEfBCEgBCEgBCErrrf..r...rr.BDEgf...BDEgf..E...E...E.....Figure 11: Forest quasi-model (right) according 3-secure replacement (left).J n-secure replacement lim I, call n-replaceable w.r.t. I, otherwisecall n-irreplaceable w.r.t. I.4Figure 11 displays 3-secure replacement considered unraveling examplemodel.defined elements forest quasi-model eligible replacedlimit element, make sure many elements (actually definedterms original model) exempt replaced.Lemma 32. Every purified model ALCOIFb knowledge base K containsfinitely many distinct elements start BCP cause n-irreplaceable nodesunraveling I.Proof. Assume converse: let purified model K contain infinite set elementsgiving rise n-irreplaceable nodes (I). must L0infinite set D0 every d0 D0 generates L cutn (L)= L (sinceLemma 25, finitely many non-isomorphic choices L0 ). set D0used guide construction specific limit element J lim according Lemma30.1. Now, element (, w) J starting BCP, let l(,w) lengthshortest BCP starting (, w). Then, let k maximum l(,w)individuals (, w) J start BCP |w| n. construction, D0contains one element d00 generating L cutk (L)= cutk (J ) (actually infinitely many).choice k Lemma 30.4, conclude J n-secure replacementirreplaceable (I)-node caused d00 contradicts fact d00 D.know, elements forest quasi-model replaced suitable limitelement. following definition exactly tells us, replacement carried out:respective element successors deleted limit element (togethersuccessors) inserted position.465fiRudolph & GlimmEBCEBDEfBCEgBCEBDEfBDEfBCEgBCEgBCEBDEfBDEfBDEfBDEBCEgBCEgBCEgBCEg...rf..rrrrrrrf...f...f.E...E.....BCEf....Figure 12: Result replacing element 3-secure replacement depicted Figure 11. inserted component highlighted.Definition 33 (Replacement Step). Let K ALCOIFb knowledge base, modelK, J forest quasi-model K, i.e., J |= K0 = nomFree(K). Let (, w) Jn-replaceable w.r.t. J 0 according n-replacement (, w) lim root(, ).define result replacing (, w) J 0 interpretation R0J0000JJ00R = Jred {(, ww ) | (, w ) } red = ( \ {(, ww ) | |w | > 1})000Jcon(K0 ), AR = (AJ Jred ) {(, ww ) | (, w ) }J000000r rol(K0 ), rR = (rJ Jred red ){h(, ww ), (, ww )i | h(, w ), (, w )i0rJ }4Figure 12 displays result carrying replacement step example.following lemma assures replacement described above, newanchored n-components introduced, instead anchored n-components presentn-secure transformation present completely contained inserted limitelement.Lemma 34. Let K ALCOIFb knowledge base, model K, J forest quasimodel K, i.e., J |= K0 = nomFree(K), let (, w) J n-replaceable w.r.t. I. LetJ 0 n-replacement (, w) root (, ) R result replacing (, w)J 0 . following hold:1. cutn ((J , (, w))) isomorphic cutn ((R, (, w))).466fiNominals, Inverses, Counting, Conjunctive Queries2. n 1, R locally K0 -consistent.3. Whenever R contains anchored n-component C, one J J 0 containsanchored n-component isomorphic C.Proof.1. direct consequence Definitions 31 33.2. make case distinction element-wise investigating local consistency R(note K K0 simplified local consistency node (, v) Rdepends node direct neighbors):v = ww0 w0 6= : direct neighborhood (, v) R isomorphic direct neighborhood (, w0 ) J 0 (recall (, ) rootJ 0 ). Lemma 30.2, J 0 locally K0 -consistent except possibly (, ). Hencealso (, v) locally K0 -consistent R.v 6= ww0 w0 , i.e., (, v) affected replacement:direct neighborhood (, v) changed replacement and, therefore,neighborhoods (, v) J R coincide. J locally K0 -consistentassumption, (, v) R.v = w: case, direct neighborhood (, v) changed remainedisomorphic. follows preceding statement (34.1).3. Let (0 , w0 ) witness C. distinguish three cases:0 = w prefix w0 . Then, clearly C completely contained J 0 .0 = w0 prefix w. Let C 0 structure obtained restricting Celements form (, ww00 ) renaming every element (, ww00 )(, w00 ), (, ) root J 0 . C 0 anchored n-componentJ 0 witness (, ). Now, definition replacing, J must containisomorphic copy C 0 witness (, w). Since part C (consistingnodes (0 , w0 ) w prefix w0 ) alteredreplacement, conclude J must contain isomorphic copy C.Neither above. Then, (0 , w0 ) subtree rooted (0 , w0 ) containedJ part J affected replacement. Then, clearlyalso C contained J .ready defining whole process restructuring forest quasi-modelessentially substituting many nodes possible appropriate limit elements.Definition 35 (n-Secure Transformation). Let model ALCOIFb knowledgebase K J unraveling I. interpretation J 0 called n-secure transformationJ obtained (possibly infinitely) repeating following step:Choose one unvisited w.r.t. tree-depth minimal node (, w) n-replaceablew.r.t. I. Replace (, w) one n-secure replacements lim mark (, w)visited.4467fiRudolph & GlimmBBE f C E g EBDEfBDEBCEgBCEgBCEBDEfBDEfBDEfBDEBCEgBCEgBCEgBCEgrrr.r..rBCErrrf..f...f...f...BCEf....Figure 13: Result collapsing forest quasi-model displayed Figure 12.Note well-defined every node visited formerlyirreplaceable node ever becomes replaceable. Hence every k IN, initial segmentcutk (J ) current intermediate structure J already isomorphic initial segmentcutk (J 0 ) J 0 bounded number replacement steps, due fact involvedstructures bounded branching degree.now, whole effort might still look bit contrived pointless, however,following lemma establishes bunch properties end allow us deduceexistence well-behaved countermodel whenever all.show process unraveling, n-secure transformation collapsing preserves property model knowledge base (with right choice n)also preserves property entailing conjunctive query. Moreover, model conversion process ensures resulting model contains finitely many new nominals(witnessed bound length BCPs). Figure 13 illustrates propertiesexample model. Note two new nominals left whereas collapsing originalunraveling yields infinitely many.Lemma 36. Let purified model ALCOIFb knowledge base K, J unraveling I, J 0 n-secure transformation J . following hold:1. J 0 strict forest quasi-model K.2. J 0 collapsing-admissible.3. collapse(J 0 ) model K.4. natural number J 0 contain node whose shortestdescending BCP length greater m.468fiNominals, Inverses, Counting, Conjunctive Queries5. J 0 contains anchored n-component C, J contains anchored n-componentisomorphic C.6. If, union conjunctive queries u = q1 . . . qh , J |6 u n >maxq{q1 ,...,qh } ](q), J 0 |6 u.7. If, union conjunctive queries u = q1 . . . qh , 6|= un > maxq{q1 ,...,qh } ](q), collapse(J 0 ) 6|= u.Proof.1. Let K0 = nomFree(K). Due Lemma 13, J strict forest quasi-modelK. Lemma 34.2, replacement step preserves local K0 -consistency results, thus, forest quasi-model K. Since n-replacement strict treequasi-interpretation also strictness preserved. induction follows every interpretation produced n-secure transformation procedure strict forest quasimodel K. every node J 0 , direct predecessor direct successorschanged finitely many replacement steps local K0 -consistencydepends solely neighbors. Hence J 0 also locally K0 -consistent.2. Lemma 19, J collapsing-admissible, Lemma 30.5 every limit is. Moreover, obvious proofs propositions, possible definerespective ch-functions recurring original choose-function I, hence everytwo elements (even different) unravelings limits start descending BCPsidentical path sketches correspond element whenceseparate ch-functions compatible other. Therefore, replacing element unraveling yields strict forest quasi-model collapsing-admissible.Applying argument inductively yields every intermediate strict forestquasi-model n-secure transformation collapsing-admissible. Finally,according ch-function stabilizes finitely many replacement steps (togetherneighborhood considered elements), also J 0 collapsing-admissible.3. follows two previous facts (36.1 36.2) together Lemma 20.4. Consider set causing n-irreplaceable nodes J . Lemma 32,finite. obtain D0 removing start descendingBCPs.D0 , let dBCP() denote set descending BCPs starting choose:= max0min|p|pdBCP()assume 0 shortest descending BCP length greaterm. Obviously, 0 6 D0 , must (, w) generated 0 nreplaceable. However, n-secure transformation n-replaceable elementsreplaced elements start descending BCPs dueLemma 30.3.469fiRudolph & Glimm5. prove induction replacement steps n-secure transformationprocess showing true every intermediate replacement result R0 .claim J 0 follows fact that, every considered C (whichalways finite), finite part cut` (J 0 ) relevant every `,bounded number replacement steps cut` (R0 ) = cut` (J 0 )every intermediate R0 .base case (zero replacement steps carried out), find R0 = J , claimtrivially true.assume claim established R shown R0created replacing (, w) R J 00 . Lemma 34.3, knowone following case:R contains C. Yet, apply induction hypothesis conclude alsoJ contains C claimed.J 00 contains C. But, since C finite, already contained cutk (J 00 )k and, J 00 limit element, find one cutk ((I, )) =cutk (J 00 ). Since purified, find (, w) J corresponds , i.e.,J contains isomorphic copy (I, ) turn contains isomorphiccopy C.6. actually straightforward consequence preceding propositiondefinition quentailment.indirect proof, suppose J |6 u n > maxq{q1 ,...,qh } ](q) J 0 | u,latter witnessed J 0 | q q {q1 , . . . , qh }. definition, latter assuresexistence adequate anchored n-components J 0 . Then, applying precedingproposition (36.5), obtain isomorphic copies anchored n-components contained J which, definition, means J | q and, therefore, J | u.Hence, contradiction, proves claim.7. prove indirectly, assume 6|= u, n > maxq{q1 ,...,qh } ](q), collapse(J 0 ) |=u, witnessed collapse(J 0 ) |= q q {q1 , . . . , qh }.Then, Lemma 28.2, follows J 0 | q. previous proposition (36.6),conclude J | q, turn implies |= q Lemma 28.1. implies |= u,contradiction.able establish first milestone way showing finite representability countermodels.Theorem 37. every ALCOIFb knowledge base K K 6|= u, forest modelK finitely many roots 6|= u. Moreover, bounded branching degree.470fiNominals, Inverses, Counting, Conjunctive QueriesProof. Let u = q1 . . . qh . Since inconsistent knowledge base entails every query,assume K consistent and, since K 6|= u, model K 6|= u.Choose n > maxq{q1 ,...,qh } ](q) let J 0 obtained carrying n-securetransformation (I) let 0 = collapse(J 0 ). know 0 model K (viaLemma 36.3) 0 6|= u (by Lemma 36.7).Lemma 36.4, know fixed natural number shortestdescending BCP started node J 0 shorter m. Notefinitely many path sketches length m. means every node J 0 startsdescending BCP assigned one path sketch. However, entailsfinitely many elements (i.e., -equivalence classes) 0 containJ 0 -elements starting descending BCPs J 0 . implies, via Lemma 24, 0 containsfinitely many roots.fact 0 bounded branching degree direct consequence factinitial unraveling bounded branching degree, replacement changebranching degree collapsings assured Lemma 20.7. Finite Representations Modelssection, show construct finite representation forest modelknowledge base finite number roots. showfinite representations used check query entailment. order this, usetechnique similar blocking techniques used tableau algorithms (see, e.g.,Horrocks & Sattler, 2007). tableau algorithm builds so-called completion graphfinite representation model. completion graph essentially structureforest quasi-models. contains root nodes nominals occurring inputknowledge base plus root nodes new nominals start BCPs. (newold) nominal root tree, relations occur direct neighbors withintree, elements within tree root, roots. initial completiongraph contains nodes nominals occurring input knowledge base. Conceptsexpanded according set expansion rules, new nodes added graphexpanding existential restrictions. New nominals added so-called NN-rulewhenever element within tree relationship inverse functional roleroot node represents nominal input knowledge base, i.e., BCPcreated. order obtain finite representation, tableau algorithms usually employcycle detection mechanism, called blocking. Otherwise depth treesnumber new nominals might grow infinitely. logics expressive ALCOIFb,blocking usually requires two pairs elements. notation, (non-root) node npredecessor n0 blocks node predecessor m0 , hn0 , ni= hm0 , mi. orderobtain real model finite representation, part n copiedappended infinitely often. use similar technique obtain finite representationforest model. Since want preserve non-entailment, working pairselements sufficient. Instead, take length n query account useisomorphic trees depth n define blocking. technique first employeddeciding query entailment ALCN role conjunctions (Levy & Rousset, 1998)recently extended logics ALCHIQ, ALCHOQ, ALCHOI (Ortiz, 2008;471fiRudolph & GlimmOrtiz et al., 2008a) extends, result, DLs SHIQ, SHOQ, SHOI (i.e.,transitivity) long query contains simple roles.forest quasi-interpretations, use isomorphisms forest interpretationsparts them.Definition 38 (Isomorphism Forest Interpretations). Let K ALCOIFb00knowledge base = (I , ), 0 = (I , ) two forest interpretations K. Withoutloss generality, assume root = (, ) extensionunique concept N occur con(K). 0 called isomorphic0w.r.t. K, written:=K 0 , iff bijection : that:1 successor 2 iff (1 ) successor (2 ) 1 , 2 ,0h1 , 2 rI iff h(1 ), (2 )i rI 1 , 2 r rol(K),0AI iff () AI con(K) {N | = (, ) }.0= oI iff () = oI nom(K).4Usually, omit subscript K=K assume clear context.Definition 39 (n-Blocking). Let n fixed natural number = (I , )(, w) , w 6= forest interpretation ALCOIFb knowledge base K.n-blocking-tree w.r.t. (, w), denoted blocknI (, w), interpretation obtainedrestricting elements {(, ww0 ) | |w0 | n} {(, ) | (, ) }. n-blocking-treeblocknI (, w) n-blocks n-blocking-tree blocknI (, ww0 )1. blocknI (, w) blocknI (, ww0 ) disjoint domains except root elements,2. bijection elements blocknI (, w) elements blocknI (, ww0 )witnesses blocknI (, w)= blocknI (, ww0 ),3. descendant (, wv) (, w), inverse functional role f root(, ) h(, wv), (, )i f .node (, v) n-blocked, (, v) either directly indirectly n-blocked ; (, v)indirectly n-blocked, one ancestors n-blocked; (, v) directly n-blocked noneancestors n-blocked (, v) leaf n-blocking-tree blocknI (, ww0 )n-blocked; case say (, v) (directly) n-blocked (, ww0 )bijection witnessing=.Without loss generality, assume n-blocking-trees used minimalw.r.t. order elements (cf. Definition 16).forest interpretation = (I , ) K n-representation K1. finite,2. contains indirectly n-blocked nodes,3. nom(K), one element form (, ) oI =(, )I ,472fiNominals, Inverses, Counting, Conjunctive Queries4. element directly n-blocked locally K-consistent.4Note n = 1 restrictive standard pairwise blocking since two treesdepth one need isomorphic blocking occurs, whereas standard blockingalready occurs two isomorphic pairs nodes. DLs expressive ALCOIFb,however, n greater 0 (at least trees depth 1) want transformn-representations models knowledge base. show knowledgebase n-representation fixed n and, afterwards, usen-representation build model knowledge base.Lemma 40. Let K consistent ALCOIFb knowledge base u = q1 . . . qh unionconjunctive queries n fixed natural number greater max1ih |qi |. K 6|= u,n-representation K satisfy u.Proof. assumption, K consistent K 6|= u. Then, Theorem 37, forestmodel K finitely many roots branching degree bounded |cl(K)|,q {q1 , . . . , qh } holds 6|= q. show find n-representation R I.use similar argumentation Lemma 25 show finitely manynon-isomorphic n-blocking trees. denote bound Tn . Let c = |cl(K)|, r =|rol(K)|, (finite) number roots I. root annotatedspecial concept N assumption. n = 0, 2c choices. n > 0,element 0 c successors 0 relations roots.roots 2c+m choices concepts. use 2cm bound choiceconcepts roots clearly bounds choice non-roots well. non-rootnode level smaller n root tree depth n 1 nodesub-tree relations root. Assuming singlecm ) number non-isomorphicrole name r rol(K), get bound O(2c cmTn1sub-trees depth n relations roots. Since onecm )r ). abbreviate 2c (cm)rchoice r roles, get bound O(2c (cmTn1x cmr rewrite obtained bound Tn = O(x(Tn1 )a ). Unfoldingnn1nnnyields Tn = O((x1+a+...+a )(T0 )a ) bounded O((xa )(2c )a ) = O((x2c )a ).nexpanding abbreviated symbols, obtain bound Tn O((2c (cm)r )(cmr) ).Together fact obtained collapsing relations elementswithin tree root collapsings never inverse functional roles, showsn-representation tree rooted node (, )depth greater Tn , two nodes (, w) (, ww0 ) blocknI (, w)n-blocks blocknI (, ww0 ), simply discard indirectly n-blocked nodesobtain desired n-representation.Since 6|= q n-representation restriction I, non-entailment q clearlypreserved.Please note would obtain bound fixed boundnumber new nominals (roots) beforehand cannot use standard tableaualgorithms obtain result. reason number new nominals(roots) tableau algorithms depends length longest path blocking473fiRudolph & Glimmoccurs. n-blocking-trees, however, also consider relations backroots, means blocking occurs later roots have.hand, delaying blocking may lead introduction new roots. Duecyclic argument, termination cannot guaranteed tableau algorithms unlessfixed bound number new nominals beforehand. also reasontableau algorithm entailment conjunctive queries simple rolesquery Calvanese et al. (2009) sound, complete, terminating SHIQ, SHOQ,SHOI knowledge bases, guaranteed terminate SHOIQ knowledgebases (transitivity, i.e., DL instead ALC impactthis).show, obtain model knowledge base K nrepresentation K. use technique directly inspired tableau algorithmsresembles process building tableau complete clash-free completiongraph. particular tableau algorithm Ortiz et al. (Ortiz, 2008; Ortiz et al., 2008a)similar also uses tree blocking.Definition 41 (Models n-Representations). Let R = (R , R ) n-representation00ALCOIFb knowledge base K. Let = 11 , . . . ,sequence pairs elementsR0. |s| denote length s. sequence s, set last (s) =0000m+1last (s) = . | m+1denote sequence 11 , . . . ,, m+1 .m+1set R-induced elements, denoted elem(R), inductively defined follows:= (, ) R ,elem(R).elem(R), = (, w) R , n-blocked, successor last (s),| elem(R).elem(R), = (, w) R , directly n-blocked 0 R ,0successor last (s), | elem(R).define interpretation = (I , ) induced R follows:= elem(R),con(K), AI iff last (s) AR ,nom(K), = oI iff last (s) = ,s, s0 r rol(K), rI ={hs, s0 | s0 = |{hs, s0 | = s0 |{hs, s0 | s0 ={hs, s0 | =00hlast (s), last (s0 )i rR }hlast (s), last (s0 )i rR }hlast (s),0h, last (s )irR }rR }.4interpretation nominals well-defined since n-representations forest interpretations K (hence, unique root nominal) pairs = (, )never appended sequences elem(R).474fiNominals, Inverses, Counting, Conjunctive QueriesLemma 42. Let K consistent ALCOIFb knowledge base, u = q1 . . . qh unionconjunctive queries, n 1 fixed natural number greater max1ih |qi |. Rn-representation K R 6|= u, model K 6|= u.proof essentially one Ortiz et al. (2008a), adapted case,work completely interpretations. n-representations correspond completiongraphs models tableaux case.Proof. Let interpretation induced R. Since n-representations containrelations element within tree root inverse functional role definition,functionality restrictions violated I. Further, since K simplified R forestinterpretation K elements apart (directly) n-blocked ones locallyK-consistent, quite straightforward element induced interpretationlocally K-consistent. Together restriction nominals (property 3), impliesmodel K. essentially principle one used provetableaux constructed completion graphs proper representations modelsinput knowledge base.Assume, contrary shown, |= u. disjunctq {q1 , . . . , qh } match q |= q. use construct matchq R shifting mapping variables parts direct counterpartR upwards.define match graph G q undirected graph containing node(x) = x var(q) containing edge hs, s0s, s0 atom r(x, y) q, (x) = s, (y) = s0 . call nodesG correspond roots root nodes G (i.e., nodes = )call nodes tree nodes. Note restriction G tree nodes set treesrefer G1 , . . . , Gk tree depth smaller n.x var(q) (x) = ( root node G), set (x) = last ( ).Note root node R.Gi {G1 , . . . , Gk }, distinguish two situations:1. Gi contains node last (s) 6= last (s) (i.e., Gi contains path withinn-blocking tree copy path starting node blocks). Dueuse n-blocking, single tree Gi never cover one n-blockingtree use nodes two n-blocking trees (leaving oneentering next one less n steps). node s0 Gi |s0 | < |s|x var(q) (x) = s0 , set (x) = (last (s0 )). s0 Gi|s0 | |s| x var(q) (x) = s0 , set (x) = last (s0 ).2. Gi contains node last (s) 6= last (s) (i.e., Gi contains path liescompletely within n-blocking tree path outside n-blocking-treen-blocking-tree). node Gi x var(q) (x) = s, set(x) = last (s).definition , induced model R, n-blocking, immediatelythat, A(x) q, (x) AR . show that, r(x, y) q, h(x), (y)i rR ,proves R |= q. distinguish three cases:475fiRudolph & Glimm1. (x) = R . (x) = = (, ) R . distinguish three cases(y):0(a) (y) = 0 also root, (y) = 0 = (0 , ) R and, since matchq definition induced interpretation R,h(x), (y)i = h, 0 rR .0(b) (y) successor (x) I, i.e., (y) = = | 0 . n-blocked(y) = 0 = (0 , c) R c IN. Again, since match qdefinition induced interpretation R,h(x), (y)i = h, 0 rR .0(c) (y) neither root ((y) 6= 0 0 R ) successor (x)0((y) 6= | 0 0 R ). (y) belongs graph match component Gi (y) = last ((y)) (y) = (last ((y))). Since isomorphismn-blocking trees also takes relations root nodes accountparts direct counterparts R, h(x), (y)i rR .02. (x) = 6= R . cases (y) = 0 0 Rabove. assume, therefore, (y) = s0 |s0 | > 1. definition I,means either = s0 | 0 s0 = s| 0 , 0 R . assume s0 = s| 0 .opposite case analogous. definition match graph G, componentGi G contains s0 . distinguish two cases:(a) component Gi contains node last (s) 6= last (s).interesting case last ((y)) 6= last ((y)), i.e., = s0 . (x) =(last (s)) (y) = last (s0 ). Since last (s0 ) 6= last (s0 ), last (s0 )node directly n-blocks last (s0 ) and, definition bijection, witnesses isomorphism, (x) = (last (s))predecessor (y) = last (s0 ) and, definition R, h(x), (y)irR .(b) component Gi contains node last (s) 6= last (s). (x) =last ((x)) (y) = last ((y)). definition R, immediatelyh(x), (y)i rR .case, h(x), (y)i rR , implies R |= q contradicting initialassumption.Lemma 40 guarantees that, case K 6|= q, always finite n-representationR K R 6|= q Lemma 42 guarantees R transformedmodel K 6|= q. suffices show enumerate (finite)n-representations K check whether entail disjunct union conjunctivequeries. Together semi-decidability result FOL, get following theorem.Theorem 43. Let K ALCOIFb knowledge base u = q1 . . . qh unionconjunctive queries. question whether K |= u decidable.476fiNominals, Inverses, Counting, Conjunctive Queries8. Conclusionssolved long-standing open problem deciding conjunctive query entailmentpresence nominals, inverse roles, qualified number restrictions. shownproblem decidable providing decision procedure proving correctness.Since approach purely decision procedure, computational complexityproblem remains open.result also shows decidability entailment unions conjunctive queriesSHOIQ SROIQ (underlying OWL DL OWL 2) disallow non-simple rolesbinary query predicates. thereby reached first important milestone towardstackling problem conjunctive queries OWL 1 DL OWL 2 DL.Entailment unions conjunctive queries also closely related problemadding rules DL knowledge base, e.g., form Datalog rules. AugmentingDL KB arbitrary Datalog program easily leads undecidability (Levy & Rousset,1998). order ensure decidability, interaction Datalog rulesDL knowledge base usually restricted imposing safeness condition. DL+logframework (Rosati, 2006a) provides least restrictive integration proposed farRosati presents algorithm decides consistency DL+log knowledge basereducing problem entailment unions conjunctive queries. Notably, Rosatisresults (2006a, Thm. 11) imply consistency ALCHOIQb knowledge baseextended (weakly-safe) Datalog rules decidable entailment unionsconjunctive queries ALCHOIQb decidable, established.Corollary 44. consistency ALCHOIQb+log-knowledge bases (both FOLsemantics non-monotonic semantics) decidable.Another related reasoning problem query containment. Given schema (or TBox)two queries q q 0 , q contained q 0 w.r.t. iff every interpretationsatisfies q also satisfies q 0 . well known query containment w.r.t.TBox reduced deciding entailment unions conjunctive queries w.r.t.knowledge base (Calvanese et al., 1998a). Decidability unions conjunctive queryentailment ALCHOIQb implies, therefore, also decidability query containment w.r.t.ALCHOIQb TBox.two obvious avenues future work. embark extendingresults order allow non-simple roles query predicates. non-trivial taskcurrent approach heavily relies certain locality query matches,relinquished considering non-simple roles. hand, eagerdetermine associated computational complexities provide techniques formbasis implementable algorithms.Acknowledgmentsstay Oxford collaboration started, Sebastian Rudolph supportedscholarschip German Academic Exchange Service (DAAD). Continuative worksubject enabled funding ExpresST project German ResearchFoundation (DFG).477fiRudolph & GlimmBirte Glimm supported EPSRC project HermiT: Reasoning LargeOntologies.thank three anonymous reviewers numerous helpful comments.thank Ian Pratt-Hartmann (unknowingly) smashing graphomata, Maria Magdalena Ortiz de la Fuente establishing competitive atmosphere, Yevgeny Kazakovbreath-taking discussions black holes, Boris Motik motivating considerationsvalue academic life, last least God providing us extraordinaryweather notably infinity.ReferencesBaader, F. (2003). Terminological cycles description logic existential restrictions.Proceedings 18th International Joint Conference Artificial Intelligence(IJCAI 2003), pp. 325330.Baader, F., Brandt, S., & Lutz, C. (2005). Pushing EL envelope. Proceedings19th International Joint Conference Artificial Intelligence (IJCAI 2005). MorganKaufmann, Los Altos.Baader, F., Calvanese, D., McGuinness, D. L., Nardi, D., & Patel-Schneider, P. F. (2003).Description Logic Handbook. Cambridge University Press.Bechhofer, S., van Harmelen, F., Hendler, J., Horrocks, I., McGuinness, D. L., PatelSchneider, P. F., & Stein, L. A. (2004). OWL web ontology language reference. Tech.rep., World Wide Web Consortium. http://www.w3.org/TR/2004/REC-owl-ref-20040210/.Calvanese, D., De Giacomo, G., Lembo, D., Lenzerini, M., & Rosati, R. (2005). DL-Lite:Tractable description logics ontologies. Veloso, M. M., & Kambhampati, S.(Eds.), Proceedings 20th National Conference Artificial Intelligence (AAAI2005), pp. 602607. AAAI Press/The MIT Press.Calvanese, D., De Giacomo, G., Lembo, D., Lenzerini, M., & Rosati, R. (2007). Tractablereasoning efficient query answering description logics: DL-Lite family.Journal Automated Reasoning, 39 (3), 385429.Calvanese, D., De Giacomo, G., & Lenzerini, M. (1998a). decidability querycontainment constraints. Proceedings 17th ACM SIGACT SIGMODSymposium Principles Database Systems (PODS 1998), pp. 149158. ACM PressAddison Wesley.Calvanese, D., De Giacomo, G., Lenzerini, M., Nardi, D., & Rosati, R. (1998b). Descriptionlogic framework information integration. Proceedings 6th InternationalConference Principles Knowledge Representation Reasoning (KR 1998).Calvanese, D., Eiter, T., & Ortiz, M. (2007). Answering regular path queries expressive description logics: automata-theoretic approach. Proceedings 22thNational Conference Artificial Intelligence (AAAI 2007).Calvanese, D., Eiter, T., & Ortiz, M. (2009). Regular path queries expressive descriptionlogics nominals. Proceedings 21st International Joint ConferenceArtificial Intelligence (IJCAI 2009), pp. 714720. AAAI Press/The MIT Press.478fiNominals, Inverses, Counting, Conjunctive QueriesChandra, A. K., & Merlin, P. M. (1977). Optimal implementation conjunctive queriesrelational data bases. Proceedings 9th ACM Symposium TheoryComputing (STOC 1977), pp. 7790. ACM Press Addison Wesley.Eiter, T., Lutz, C., Ortiz, M., & Simkus, M. (2009). Query answering description logicstransitive roles. Proceedings 21st International Joint ConferenceArtificial Intelligence (IJCAI 2009), pp. 759764. AAAI Press/The MIT Press.Glimm, B., Horrocks, I., Lutz, C., & Sattler, U. (2008a). Conjunctive query answeringdescription logic SHIQ. Journal Artificial Intelligence Research, 31, 151198.Glimm, B., Horrocks, I., & Sattler, U. (2008b). Unions conjunctive queries SHOQ.Proceedings 11th International Conference Principles KnowledgeRepresentation Reasoning (KR 2008). AAAI Press/The MIT Press.Glimm, B., & Rudolph, S. (2010). Status QIO: Conjunctive query entailment decidable.Proceedings 12th International Conference Principles KnowledgeRepresentation Reasoning (KR 2010), pp. 225235. AAAI Press/The MIT Press.Godel, K. (1929). Uber die Vollstandigkeit des Logikkalkuls. Ph.D. thesis, Universitat Wien.Golbreich, C., Zhang, S., & Bodenreider, O. (2006). foundational model anatomyOWL: Experience perspectives. Journal Web Semantics, 4 (3).Goodwin, J. (2005). Experiences using OWL ordnance survey. Proceedings1st OWL Experiences Directions Workshop (OWLED 2005), Vol. 188CEUR Workshop Proceedings. CEUR (http://ceur-ws.org/).Gradel, E. (2001). modal logics robustly decidable?. Paun, G., Rozenberg,G., & Salomaa, A. (Eds.), Current Trends Theoretical Computer Science, Entering21th Century, Vol. 2, pp. 393408. World Scientific.Grahne, G. (1991). Problem Incomplete Information Relational Databases. LectureNotes Computer Science. Springer-Verlag.Horrocks, I., & Sattler, U. (2005). tableaux decision procedure SHOIQ. Proceedings19th International Joint Conference Artificial Intelligence (IJCAI 2005).Horrocks, I., & Sattler, U. (2007). tableau decision procedure SHOIQ. JournalAutomated Reasoning, 39 (3), 249276.Horrocks, I., Sattler, U., & Tobies, S. (2000). Reasoning Individuals DescriptionLogic SHIQ. McAllester, D. (Ed.), Proceedings 17th Conference Automated Deduction (CADE 2000), No. 1831 Lecture Notes Artificial Intelligence,pp. 482496. Springer-Verlag.Jet Propulsion Laboratory, C. I. o. T. (2006). Semantic web earth environmentalterminology (SWEET).. http://sweet.jpl.nasa.gov/.Kazakov, Y. (2008). RIQ SROIQ harder SHOIQ. Proceedings11th International Conference Principles Knowledge RepresentationReasoning (KR 2008). AAAI Press/The MIT Press.Kazakov, Y., & Motik, B. (2008). resolution-based decision procedure SHOIQ.Journal Automated Reasoning, 40 (23), 89116.479fiRudolph & GlimmKrotzsch, M., Rudolph, S., & Hitzler, P. (2007). Conjunctive queries tractable fragmentOWL 1.1. Proceedings 7th International Semantic Web Conference (ISWC2007), Vol. 4825 Lecture Notes Computer Science, pp. 310323. Springer-Verlag.Krotzsch, M., Rudolph, S., & Hitzler, P. (2008). ELP: Tractable rules OWL 2.Proceedings 8th International Semantic Web Conference (ISWC 2008), Vol.5318 Lecture Notes Computer Science, pp. 649664. Springer-Verlag.Lacy, L., Aviles, G., Fraser, K., Gerber, W., Mulvehill, A., & Gaskill, R. (2005). Experiencesusing OWL military applications. Proceedings 1st OWL ExperiencesDirections Workshop (OWLED 2005). CEUR (http://ceur-ws.org/).Levy, A. Y., & Rousset, M.-C. (1996). CARIN: representation language combining hornrules description logics. Proceedings 12th European Conference Artificial Intelligence (ECAI 1996), pp. 323327.Levy, A. Y., & Rousset, M.-C. (1998). Combining horn rules description logicsCARIN. Artificial Intelligence, 104 (12), 165209.Lutz, C. (2008). complexity conjunctive query answering expressive descriptionlogics. Proceedings International Joint Conference Automated Reasoning(IJCAR 2008), pp. 179193. Lecture Notes Computer Science.McGuinness, D. L., & Wright, J. R. (1998). industrial strength description logic-basedconfiguration platform. IEEE Intelligent Systems, 13 (4).Motik, B., Shearer, R., & Horrocks, I. (2009). Hypertableau reasoning description logics. Submitted journal. http://www.hermit-reasoner.com/publications/msh08hypertableau-journal.pdf.Ortiz, M. (2008). Extending CARIN description logics SH family. Proceedings Logics Artificial Intelligence, European Workshop (JELIA 2008), pp.324337. Lecture Notes Artificial Intelligence.Ortiz, M., Calvanese, D., & Eiter, T. (2008a). Data complexity query answeringexpressive description logics via tableaux. Journal Automated Reasoning, 41 (1),6198.Ortiz, M., Simkus, M., & Eiter, T. (2008b). Conjunctive query answering sh usingknots. Proceedings 2008 Description Logic Workshop (DL 2008). CEUR(http://ceur-ws.org/).Pratt-Hartmann, I. (2009). Data-complexity two-variable fragment countingquantifiers. Forthcoming Information Computation. http://arxiv.org/abs/0806.1636.Rosati, R. (2006a). DL+log: Tight integration description logics disjunctive datalog.Proceedings 10th International Conference Principles KnowledgeRepresentation Reasoning (KR 2006), pp. 6878.Rosati, R. (2006b). decidability finite controllability query processingdatabases incomplete information. Proceedings 25th ACM SIGACTSIGMOD Symposium Principles Database Systems (PODS 2006), pp. 356365.ACM Press Addison Wesley.480fiNominals, Inverses, Counting, Conjunctive QueriesRosati, R. (2007a). limits querying ontologies. Proceedings 11th International Conference Database Theory (ICDT 2007), Vol. 4353 Lecture NotesComputer Science, pp. 164178. Springer-Verlag.Rosati, R. (2007b). conjunctive query answering EL. Proceedings 2007Description Logic Workshop (DL 2007). CEUR Workshop Proceedings.Rudolph, S., Krotzsch, M., & Hitzler, P. (2008). Terminological reasoning SHIQordered binary decision diagrams. Proc. 23rd National Conference ArtificialIntelligence (AAAI 2008), pp. 529534. AAAI Press/The MIT Press.Sidhu, A., Dillon, T., Chang, E., & Sidhu, B. S. (2005). Protein ontology development usingOWL. Proceedings 1st OWL Experiences Directions Workshop (OWLED2005), Vol. 188 CEUR Workshop Proceedings. CEUR (http://ceur-ws.org/).Sirin, E., Parsia, B., Cuenca Grau, B., Kalyanpur, A., & Katz, Y. (2007). Pellet: practicalOWL-DL reasoner. Journal Web Semantics, 5 (2).Tessaris, S. (2001). Questions answers: Reasoning querying Description Logic.PhD thesis, University Manchester.Tsarkov, D., & Horrocks, I. (2006). FaCT++ description logic reasoner: System description.Proceedings International Joint Conference Automated Reasoning (IJCAR2006), Vol. 4130 Lecture Notes Computer Science, pp. 292 297. Springer-Verlag.van der Meyden, R. (1998). Logical approaches incomplete information: survey.Logics Databases Information Systems, pp. 307356. Kluwer Academic Publishers.Vardi, M. Y. (1997). modal logic robustly decidable?. Descriptive ComplexityFinite Models: Proceedings DIMACS Workshop, Vol. 31 DIMACS: SeriesDiscrete Mathematics Theoretical Computer Science, pp. 149184. AmericanMathematical Society.W3C OWL Working Group (2009).OWL 2 web ontology language documentoverview. Tech. rep., World Wide Web Consortium. http://www.w3.org/TR/2009/REC-owl2-overview-20091027/.Wolstencroft, K., Brass, A., Horrocks, I., Lord, P., Sattler, U., Turi, D., & Stevens, R.(2005). Little Semantic Web Goes Long Way Biology. Proceedings5th International Semantic Web Conference (ISWC 2005).481fiJournal Artificial Intelligence Research 39 (2010) 301-334Submitted 2/10; published 9/10Model-Based Active Testing ApproachSequential DiagnosisAlexander Feldmana.b.feldman@tudelft.nlDelft University TechnologyMekelweg 4, 2628 CD, Delft, NetherlandsGregory Provang.provan@cs.ucc.ieUniversity College CorkDepartment Computer ScienceCollege Road, Cork, IrelandArjan van Gemunda.j.c.vangemund@tudelft.nlDelft University TechnologyMekelweg 4, 2628 CD, Delft, NetherlandsAbstractModel-based diagnostic reasoning often leads large number diagnostic hypotheses. set diagnoses reduced taking account extra observations (passivemonitoring), measuring additional variables (probing) executing additional tests (sequential diagnosis/test sequencing). paper combine approachestechniques Automated Test Pattern Generation (ATPG) Model-Based Diagnosis(MBD) framework called Fractal (FRamework ACtive Testing ALgorithms).Apart inputs outputs connect system environment, activetesting consider additional input variables sequence test vectorssupplied. address computationally hard problem computing optimal control assignments (as defined Fractal) terms greedy approximation algorithm calledFractalG . compare decrease number remaining minimal cardinalitydiagnoses FractalG two Fractal algorithms: FractalATPGFractalP . FractalATPG based ATPG sequential diagnosis FractalPbased probing and, although active testing algorithm, provides baseline comparing lower bound number reachable diagnoses Fractal algorithms.empirically evaluate trade-offs three Fractal algorithms performingextensive experimentation ISCAS85/74XXX benchmark combinational circuits.1. IntroductionCombinational Model-Based Diagnosis (MBD) approaches (de Kleer & Williams, 1987)often lead large number diagnoses, exponential number components,worst-case. Combining multiple sensor readings (observation vectors) (Pietersma &van Gemund, 2006) helps limited number cases approach inherentlypassive, i.e., situations observations repeat (for example,systems stationary, pending reconfiguration).Sequential diagnosis algorithms (Shakeri, 1996) used alternativepassive approach, better decay number diagnostic hypotheses.decay rate depends tests test dictionary matrix, boundedc2010AI Access Foundation. rights reserved.fiFeldman, Provan, & van Gemundresults tests binary outcomes. Algorithms sequential diagnosis suffernumber limitations. Early approaches assume single-faults multiple-faultsequential diagnosis super-exponential (p2 harder) (Shakeri, Raghavan, Pattipati, &Patterson-Hine, 2000).observations (test outcomes) known advance, goal diagnosticiancreate policy minimizes diagnostic uncertainty average, i.e., one aimsminimizing average depth test tree. Pattipati Alexandridis (1990) showncertain conditions (e.g., unit test costs equal prior fault probabilities) onestep look-ahead policy leads optimal average depth test tree; de Kleer, Raiman,Shirley (1992) shown one-step look-ahead delivers good practical resultsrange combinational circuits.paper proposes framework, called Fractal (FRamework ACtive TestingALgorithms) comparing different computational vs. optimality trade-offs varioustechniques reducing diagnostic uncertainty. Fractal algorithms startinitial set multiple-fault diagnostic hypotheses (this initial set contain possible hypotheses) compute actions reducing initial set to, possible, single diagnostichypothesis (candidate). case probing (de Kleer & Williams, 1987), action consists measuring internal (hidden) variable. case sequential diagnosis (ATPG),action consists applying set input (control) assignments disambiguatehealth state component appears faulty initial diagnostic hypotheses. case active testing action consists applying set input (control)assignments optimally reduce initial set hypotheses. framework active testing sequential diagnosis approaches differ compute input(control) assignments. measure optimality algorithms computing speeddecay initial set hypotheses computational efficiency.environmentsystemCTLFRACTALFigure 1: Active testing dataflow FractalFractal, study influence input (IN) output (OUT) variables,also control (CTL) variables. Controls similar inputs, except modifiedusers system connected environment. Use models first principlescontrols Fractal allows us eliminate need designing explicit tests testdictionaries. algorithms implicitly create test matrices leading optimal decay basedbuilt-in testing capabilities system. call approach active testing;technique using models first principles controls creating test sequencesreduce diagnostic uncertainty system. architecture useFractal active testing shown Fig. 1.302fiA Model-Based Active Testing Approach Sequential Diagnosisreliable component failure rates may problematic obtain, assume equallylikely small prior probabilities failure measure diagnostic uncertaintynumber Minimal Cardinality (MC) diagnoses. Fractal modified use arbitraryfailure probabilities even components likely faulty healthy.would necessitate modifications algorithms (e.g., change biasimportance sampling, etc.). addition simplifying modeling, equiprobable failurerates assumption also computational advantages. shown equalsmall prior probabilities failure, diagnostic entropy, e.g., used de KleerWilliams (1987), computed directly number MC diagnoses.computational complexity deterministic algorithms sequential diagnosis increases respect fault-cardinality number tests (the sizetest dictionary). enable performance scale real-world problems, mayhigh fault-cardinality large number tests, propose FractalGa low-cost greedystochastic approach maintains exponential decay number MC diagnoses. Instead assuming single faults timing out, FractalG may result suboptimal stillexponential decay.study performance FractalG compared two alternatives: (1) FractalATPG , implements sequential diagnosis based Automated Test Pattern Generation (ATPG), (2) FractalP, implements probing (de Kleer & Williams, 1987).ATPG successfully used electronic industry compute sets inputstest component VLSI circuit. considered ATPG-based approach natural attempt reduce diagnostic ambiguity computing inputsdisambiguate status single component appears majoritydiagnostic hypotheses.FractalATPG derived sequential testing, deterministic myopic, allows us evaluate well single-step lookahead approach works given model.Although probing classified technique sequential diagnosis, viewedprocess generating tests using additional control circuitry (machine human)execute probe output reveals internal variable. significanceshows lower bound number diagnoses achievable model extendedunlimited CTL circuitry.contributions follows:devise approach reducing diagnostic uncertainty, called active testing,generalizes sequential diagnosis MBD, allows combination multiple passivesensor readings, require explicit tests test dictionaries.design FractalATPGa single-step look-ahead algorithm based ATPGforsolving active testing problem.design implement FractalGa greedy approximation algorithm activetesting overcomes limitations FractalATPG offers trade-off computational complexity vs. optimality reducing diagnostic uncertainty.compare FractalG FractalATPG .implement FractalP use computationally efficient, myopic (one-steplookahead), easy-to-analyze baseline technique reducing diagnostic uncertainty.303fiFeldman, Provan, & van GemundAlthough FractalP technically active testing algorithm, implementationprobing active testing common framework unified experimentationhelp understand cost vs. performance trade-offs (active passive) testingvs. probing strategies.present extensive empirical data 74XXX/ISCAS85 circuits, enable usevaluate FractalATPG, FractalG, FractalP terms abilityreduce number remaining diagnoses according geometric decay function.paper organized follows. Section 2 introduces related work. Section 3 presents basic MBD notions, concept remaining number diagnoses framework sequential diagnosis. Section 4 introduces stochastic sampling-based algorithm computingexpected number cardinality-minimal diagnoses. Section 5 describes FractalATPG,FractalG, FractalP algorithms. Section 6 shows experimental results. Finally,Sec. 7 summarizes paper discusses future work.2. Related WorkEarly work aimed diagnostic convergence de Kleer Williams (1987) computeprobe sequence reducing diagnostic entropy using myopic search strategy. Unlikework, active testing assume probes available, indirectlyexposed diagnosis based test vectors, offers automated solution.Generating test vectors deduce faults received considerable attention. Automatictest pattern generation (ATPG) aims verifying particular, single-faults (Stephan, Brayton, & Sangiovanni-Vincentelli, 1996). ATPG differs active testing vectorsspecific particular single-faults, whereas active testing generates sequence vectorsisolate unknown, multiple-faults, much harder problem.Table 1: Properties techniques sequential diagnosisTechniqueModelUser ActionsAutomaticTestsPerformanceCostPassive monitoringSequential diagnosisFractalATPGFractalGProbing (FractalP )first principlestest dictionaryfirst principlesfirst principlesfirst principlesapply testapply controlsapply controlsmeasure internalsyesyes-variable1goodvariable3goodbinary searchlowvariable2mediumhighmedium123Depends environment (IN/OUT data).Speed deteriorates rapidly multiple-faults.Depends model topology.Table 1 summarizes properties various techniques sequential diagnosis discussed paper. Fractal eliminates need using tools building tests testdictionaries, ones proposed Deb, Ghoshal, Malepati, Kleinman (2000).approach tests test dictionaries automatically constructed design speci304fiA Model-Based Active Testing Approach Sequential Diagnosisfications models. time, Fractal delivers comparable better diagnosticconvergence reasonable computational price.Active testing bears resemblance sequential diagnosis, also generatessequence test vectors (Pattipati & Alexandridis, 1990; Raghavan, Shakeri, & Pattipati,1999; Tu & Pattipati, 2003; Kundakcioglu & Unluyurt, 2007). principal differencesequential diagnosis fault dictionary used (fault matrix). pre-compileddictionary following drawback: order limit (exponential) size dictionary, number stored test vectors extremely small compared test vectorspace. severely constrains optimality vector sequence generated;contrast, active testing computes arbitrary test vectors fly using model-basedapproach. Furthermore, matrix specifies tests binary (pass/fail) outcome, whereas active testing exploits systems outputs, leading faster diagnosticconvergence. addition, allow inputs dynamic, makes frameworksuitable online fault isolation.sequential diagnosis problem studies optimal trees cost associatedtest (Tu & Pattipati, 2003). costs equal, shownoptimization problem reduces next best control problem (assuming one uses information entropy). paper diagnostician given sequence triescompute next optimal control assignment would try minimize expected numberremaining diagnoses |(S)|.task harder Raghavan et al. (1999), since diagnosis task NPhard, even though diagnosis lookup uses fault dictionary; case computenew diagnosis every test. Hence NP-hard sequential problem interleavedcomplexity diagnostic inference step (in case complexitydiagnosis p2 -hard). Apart above-mentioned differences, note optimaltest sequencing infeasible size problems interested.Model-Based Testing (MBT) (Struss, 1994) generalization sequential diagnosis.purpose MBT compute inputs manifesting certain (faulty) behavior. maindifferences active testing approach MBT (1) assumes inputscontrollable (2) MBT aims confirming single-fault behavior opposed maximallydecreasing diagnostic uncertainty.Brodie, Rish, Ma, Odintsova (2003) cast models terms Bayesian networks.notion entropy size diagnosis space, whereas Brodie et al. use decisiontheoretic notions entropy guide test selection. Brodie et al. extend past Bayesiandiagnostic approach (Rish, Brodie, & Ma, 2002) sequential construction probe sets(probe sets collections of, example, pings subset nodes computer network). approach Brodie et al. limited networks although extendedmodifying type Bayesian network shown Rish et al.; modification, however,would necessitate computationally expensive Bayesian reasoning achieving goodapproximation results probable explanations.approach Brodie et al. (2003) compute modifications targetnetwork topology propose control actions (for example, network serverfails respond dialed-up modem checked technicianhigher cost). similarity Fractal active probing approachesattempt reducing diagnostic uncertainty analyzing future state system305fiFeldman, Provan, & van Gemundfunction action (sending set probes active probing applicationcontrol inputs FractalG FractalATPG).solve different problem Heinz Sachenbacher (2008), Alur, Courcoubetis, Yannakakis (1995). approaches assume non-deterministicmodel defined automaton. contrast, framework assumes static system (plantmodel) must compute temporal sequence tests best isolate diagnosis.Esser Struss (2007) also adopt automaton framework test generation, except that, unlike Heinz Sachenbacher (2008) Alur et al. (1995), transformautomaton relational specification, apply framework software diagnosis.automaton-based framework accommodates general situations ours,possibility systems state transition may uniquely determined state transition input, and/or systems state mayassociated several possible observations. MBD framework, test consistsinstantiation several variables, corresponds notion test sequencewithin automaton framework Heinz Sachenbacher. framework EsserStruss requires modeling possible faults, whereas Fractal works weakstrong-fault models1 . Interestingly, shown Esser Struss, modeling abnormal software behavior derived extent software functional requirements.makes framework suitable software systems.recent approach active diagnosis described Kuhn, Price, de Kleer, Do,Zhou (2008), additional test vectors computed optimize diagnosissystem (a copier) remains operational. work differs plans (roughlyanalogous test sequences) probability failure computed statically,plan remains unmodified even fails achieve desired goal (a manifestationfailure probability close ). Conversely, Fractal dynamically computes next-bestcontrol settings game-like manner. biggest difference Fractalapproach Kuhn et al. use models. Fractal compatible traditionalMBD (de Kleer & Williams, 1987) reuse existing models first principlespervasive approach Kuhn et al. uses automaton set possible actions.approach Kuhn et al. (2008) uses existing MBD planning algorithms,integrates existing approaches; contrast, Fractal introduces new control algorithmsreuses external diagnostic oracle. advantage pervasive diagnosis approachuse planning engine generates complete sequence actions, opposedone-step lookahead FractalG. Depending planning formalism, complexitypervasive diagnosis dominated planning module, complexcomputational task Fractal diagnosis. pervasive diagnosispaper, however, report good average-case computational efficiency benchmark problems.Last, paper Kuhn et al. limited single-fault diagnoses, although pervasivediagnosis framework generalized multiple faults.Feldman, Provan, van Gemund (2009a) introduce early version FractalG.paper (1) generalizes Fractal framework, (2) introduces FractalATPGFractalP, (3) extends experimental results, (4) provides comparisondifferent Fractal approaches.1. Weak-fault models (also known models ignorance abnormal behavior) strong-fault modelsdiscussed Feldman, Provan, van Gemund (2009b).306fiA Model-Based Active Testing Approach Sequential Diagnosis3. Concepts Definitionsdiscussion starts introducing relevant MBD notions. Central MBD, modelartifact represented propositional Wff set variables V . definefour subsets variables: assumable, observable 2 , control, internal variables.gives us initial definition:Definition 1 (Active Testing System). active testing system ATS defined ATS =hSD, COMPS, CTL, OBSi, SD propositional Wff variable set V , COMPSOBS CTL V , COMPS, OBS, CTL subsets V containing assumable,observable, control variables, respectively.set internal variables denoted INT, INT = V \ {COMPS OBS CTL}.Throughout paper assume OBS, COMPS, CTL disjoint, SD 6|=.Sometimes convenient (but necessary) split OBS non-controllable inputsoutputs (OBS = OUT, = ).3.1 Running Exampleuse Boolean circuit shown Fig. 2 running example illustratingnotions algorithm shown paper. 2-to-4 line demultiplexer consistsfour Boolean inverters four and-gates.bh1h3pqh2h4rh5h6h7h8o1o2o3o4Figure 2: demultiplexer circuitexpression h (o i) models inverter, variables i, o, h represent input, output, health respectively. Similarly, and-gate modeled h(o i1 i2 i3 ). propositional formulae copied gate Fig. 2variables subscripted renamed way ensure proper disambiguation2. MBD literature assumable variables also referred component, failure-mode,health variables. Observable variables also called measurable variables.307fiFeldman, Provan, & van Gemundconnect circuit. result following propositional model:[h1 (a p)] [h2 (p r)][h3 (b q)] [h4 (q s)]h5 (o1 p q)SD =h6 (o2 r q)h7 (o3 p s)h8 (o4 r s)(1)set assumable variables COMPS = {h1 , h2 , . . . , h8 }, observable variablesOBS = {a, b, o1 , o2 , o3 , o4 }, set control variables singleton CTL = {i}. Noteconventional selection sign health variables h1 , h2 , . . . , hn . authorsuse ab abnormal.3.2 Diagnosistraditional query MBD computes terms assumable variables, explanations system description observation.Definition 2 (Diagnosis). Given system ATS, observation variablesOBS, assignment variables COMPS, diagnosis iff SD 6|=.set diagnoses SD observation denoted (SD, ). cardinalitydiagnosis, denoted ||, defined number negative literals .Continuing running example, consider observation vector 1 = b o4 .total 256 possible assignments variables COMPS |(SD, 1 )| =200. Example diagnoses 1 = h1 h2 . . . h7 h8 2 = h1 h2 h3 h4h5 h6 h7 h8 . write sometimes diagnosis set notation, specifying setnegative literals only. Thus 2 would represented D2 = {h1 , h4 }.Definition 3 (Minimal-Cardinality Diagnosis). diagnosis defined MinimalCardinality (MC) diagnosis exists | | < | |.selection minimality criterion impossible compute diagnosesset MC diagnoses without inference. MC diagnoses, however, oftenused practice due prohibitive cost computing representation diagnosessystem observation (e.g., subset-minimal diagnoses).Consider observation vector 2 = b o1 o4 . 6 MC diagnosescardinality 2 consistent SD 2 , counting MC diagnoses commonproblem MBD.number MC diagnoses system ATS observation denoted| (SD, )|, (SD, ) set MC diagnoses SD . Given systemATS, observation sequence defined k-tuple terms = h1 , 2 , . . . , k i,(1 k) instantiation variables OBS.Throughout paper, assume health system testchange test (i.e., inputs fault produce outputs) callassumption stationary health.308fiA Model-Based Active Testing Approach Sequential DiagnosisLemma 1. Given system ATS, stationary health state components ,observation sequence S, follows (SD, 1 ) (SD, 2 ) . . . (SD, k ).Proof. statement follows immediately stationary health assumptionDef. 2.Lemma 1 applied cases diagnoses considered.compute subset-minimal diagnoses weak-fault model, example, intersectionoperator redefined handle subsumptions. handle non-characterizing setsdiagnoses3 (e.g., MC first diagnoses), provide following definition.Definition 4 (Consistency-Based Intersection). Given set diagnoses SD ,posteriori observation , intersection diagnoses SD , denoted(D, ), defined set (D D) holdsSD 6|=.straightforward generalize definition observation sequence S.Definition 5 (Remaining Minimal-Cardinality Diagnoses). Given diagnostic system ATSobservation sequence S, set remaining diagnoses (S) defined (S) =( ( ( (SD, 1 ), 2 ), ), k ).use |(S)| instead precise diagnostic entropy defined de KleerWilliams (1987) subsequent works, allows low-complexity estimations (discussedSec. 4). particular, diagnoses minimal-cardinality failure probabilitycomponent same, gain diagnostic entropy directlycomputed |(S)|.4. Computing Expected Number MC DiagnosesActive testing aims minimize expected number diagnoses resultpossible set outputs may occur given control vector. sectionpresent algorithm approximate expectation.compute expected number diagnoses set observable variables(M OBS). initial observation set MC diagnoses = (SD, ) modifyprobability density function subsequent outputs (observations), i.e., subsequentobservation changes likelihood. (non-normalized) posteriori probabilityobservation , given function computes set MC diagnoses initialobservation , is:Pr( |SD, ) =| ( (SD, ), )|| (SD, )|(2)formula computes probability given priori set diagnoses restrictingpossible outputs, i.e., assume probability ratio number3. characterizing set diagnoses, example set subset-minimal diagnoses, loosely definedset diagnoses (complete) set diagnoses constructed without usingsystem description information.309fiFeldman, Provan, & van Gemundremaining diagnoses number initial diagnoses. practice, manyPr( |SD, ) = 0, certain fault heavily restricts possible outputssystem (i.e., set remaining diagnoses numerator empty).expected number remaining MC diagnoses variable set , given initialobservation , weighted average intersection sizes possible instantiations variables (the weight probability output):E (SD, |) =X| (D, )| Pr( |SD, )XPr( |SD, )(3)= (SD, ) set possible assignments variables .Replacing (2) (3) simplifying gives us following definition:Definition 6 (Expected Minimal-Cardinality Diagnoses Intersection Size). Given system ATS initial observation , expected remaining number MC diagnosesE (SD, OBS|) defined as:E (SD, OBS|) =XOBSX| ( (SD, ), )|2OBS| ( (SD, ), )|(4)OBS set possible assignments variables OBS.Two algorithms presented paper compute expected number remainingMC diagnoses one variable. result expectation expression (4) simplifies to:E (SD, v|) =| ( (SD, ), v)|2 + | ( (SD, ), v)|2| ( (SD, ), v)| + | ( (SD, ), v)|(5)complexity computing (5) depends length sequence S, complexity MC oracle computing (SD, ), complexity intersectionalgorithm.4.1 Computing Expectation Using Importance Samplingovercome computational complexity evaluating expectation, employstochastic algorithm based importance sampling. key insight allows usbuild fast method computing expected number remaining diagnosesprior observation (and respectively set MC diagnoses) shifts probabilityoutputs. Hence, algorithm samples possible input assignments (recallbasic modeling assumption inputs equally likely) counts numberdifferent observations, given set prior diagnoses, produce good approximation.next introduce algorithm approximating expected number remainingdiagnoses.310fiA Model-Based Active Testing Approach Sequential DiagnosisAlgorithm 1 Approximate expectation (S)1: function Expectation(ATS, , D) returns realinputs: ATS (active testing system): model(term): control vector(set diagnoses): prior diagnoseslocal variables: , , (terms): observation(integer): sum remaining diagnoses, initially 0q (integer): sum squares remaining diagnoses, initially 0Z (set terms): samplesE (real): expectation2:Z3:repeat4:RandomInputs(SD, IN)5:6:InferOutputs(SD, OUT, , )7:6 Z8:Z Z { }9:q q + | (D, )|210:+ | (D, )|11:E q/s12:end13:end14:Terminate(E)15:return E16: end functionAlgorithm 1 uses couple auxiliary functions: RandomInputs assigns random valuesinputs InferOutputs computes outputs system model, inputsdiagnosis.4 computation intersection size | (D, )| implementedcounting SD 6|=.algorithm terminates termination criterion (checked Terminate)satisfied. implementation, Terminate returns success last n iterations(where n small constant) leave expected number diagnoses, E, unchanged,terms integer representation. experiments show problems considered,n < 100 yields negligible error.complexity Alg. 1 determined complexity consistency checking (line9 10) size D. denote complexity single consistency check, complexity Alg. 1 becomes O(|D|). Although consistency checkingdiagnostic problems NP -hard worst case, average-case problems easy.implementation Expectation overcome complexity consistency checking4. always possible general case. framework, number assumptions,i.e., weak-fault model, well-formed circuit, etc. complexity InferOutputs thus dependsframework assumptions.311fiFeldman, Provan, & van Gemundusing incomplete Logic-Based Truth Maintenance System (LTMS) (Forbus & de Kleer,1993).5. Algorithms Reducing Diagnostic Uncertaintysection introduce three algorithms: FractalATPG, FractalG, FractalP.5.1 Problem Definition Exhaustive Searchproblem defined follows:Problem 1 (Optimal Control Sequence). Given system ATS, sequence (of past observations controls) = h1 1 , 2 2 , , k k i, (1 k) OBSassignments j (1 j k) CTL assignments, compute new CTL assignmentk+1 , that:k+1 = argmin E ( (SD, S), {IN OUT}|)(6)CTLCTL space possible control assignments.Problem 1 different general sequential testing problem, formulated Shakeri(1996). Shakeri formulation, different test costs different prior failureprobabilities, Problem 1 assumes equal costs equal small prior probabilitiesfailure. Pattipati Alexandridis (1990) show assumptions, minimizingtest cost step constitutes optimal policy minimizing expected test cost.Hence, solving Problem 1 solving lesser problem generating optimal test strategygiven unit costs equal prior failure probability. Note use algorithmoptimizes Problem 1 heuristic algorithm solving sequential testing problem.case expected cost would arbitrarily far optimum one, dependingcost distribution tests.Consider running example initial observation vector (and control assignment) 3 3 = b o1 o2 o3 o4 , 3 = chosen initialcontrol input. four MC diagnoses SD 3 3 = {{h1 , h3 }, {h2 , h5 },{h4 , h5 }, {h5 , h8 }}.exhaustive algorithm would compute expected number diagnoses2|CTL| next possible control assignments. running example one controlvariable two possible control assignments (5 = 6 = i). computeexpected number diagnoses, possible control assignment possibleobservation vector , count number initial diagnoses consistent.Computing intersection sizes running example gives us Table 2. Note that,order save space, Table 2 contains rows Pr( ) 6= 0,given initial diagnoses (and, result, | ( (SD, 3 3 ), )| =6 0).straightforward compute expected number diagnoses control assignmenthelp marginalization table. order (1) filterlines consistent control assignment (2) compute sumsum squares intersection sizes (the rightmost column Table 2).312fiA Model-Based Active Testing Approach Sequential DiagnosisTable 2: Marginalization table SD 3b o1 o2 o3 o4FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFPr| |0.031250.06250.031250.031250.06250.031250.031250.06250.031250.031250.062512112112112FFFFFFFb o1 o2 o3 o4FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFPr| |0.031250.06250.031250.031250.031250.031250.06250.031250.031250.06250.12512111121124compute E(SD, OBS|3 i), find sum sum squaresintersection sizes rows Table 2 column F. checkedE(SD, OBS|3 , i) = 24/16 = 1.5. Similarly, E(SD, OBS|3 i) = 34/16 = 2.125. Henceoptimal diagnostician would consider second measurement control setting = i.obvious problem brute-force approach size marginalization table is, worst-case, exponential |OBS|. Although many rowsmarginalization table skipped intersections empty (there consistent prior diagnoses respective observation vector control assignment),construction table computationally demanding consider approximation algorithm (to construct Table 1 tiny example, exhaustive approachperform total 512 consistency checks).5.2 FractalATPGConsider running example Sec. 3 observation 4 = b o1 o4 .leads 6 double-fault MC diagnoses, shown Fig. 3.123456Eh1h2h3h4h5h6h7h813310313313361036133Figure 3: ATPG-Based active testing exampleInstead searching space possible control assignments, directly compute control assignment tests specific component c using approach313fiFeldman, Provan, & van GemundATPG. choose component c one decreases expected number remaining MC diagnoses minimizing E (SD, c| ). look Fig. 3see knowing health h1 h3 leads E 3.33, h2 , h4 , h5 , h7 ,E 4.33, h6 h7 E = 6. Choosing control setting computesstate h1 h3 intuitive state component makes balancedpartition prior diagnoses.next present FractalATPG algorithm uses approach illustrated above.Algorithm 2 ATPG-Based active testing algorithm1: function FractalATPG (ATS, , ) returns control terminputs: ATS (active testing system): model(term): initial (non-modifiable) observation(term): initial controllocal variables: c (variable): componentf (integer): remaining diagnoses(term): diagnosis(term): control settingH (set pairs): component/expectation pairs(set terms): diagnoses2:(SD, )3:c COMPS4:f 05:6:c7:f f +18:end9:end10:H hc, f 2 + (|D| f )211:end12:H SortByExpectation(H)13:= 1 . . . |H|14:ATPG(ATS, , Hi hci)15:return16:end17:end18:return RandomControls()19: end functionAlgorithm 2 counts number prior diagnoses component appears (lines4 - 8) result saved variable f . number used computeexpected number remaining MC diagnoses given component health (line 10).component expected number diagnoses stored set H (line 10). setH sorted increasing order expectation (line 12). iterate setcomponents order expectation (lines 13 17). component try compute314fiA Model-Based Active Testing Approach Sequential DiagnosisATPG vector tests it. cases vector may exist. worst caseATPG vector test component, Alg. 2 better strategyreturn random control assignment (line 18).time complexity Alg. 2 determined complexity diagnostic search(line 2) complexity ATPG (line 14). denote formerlatter complexity FractalATPG becomes O(|COMPS|).complexity ATPG usually lower diagnosis (abductive reasoning) ( < ),complexity FractalATPG determined time computing MC diagnoses.Computing ATPG vectors extensively studied (Bushnell & Agrawal, 2000)although known NP -hard problem (Ibarra & Sahni, 1975), existsevidence ATPG easy practical problems (Prasad, Chong, & Keutzer, 1999).efficient ATPG algorithms integrate randomized approach Boolean difference (Bushnell& Agrawal, 2000). former approach efficiently computes test vectors majoritycomponents, latter computes test vectors remaining components usingDPLL-solver.implement ATPG follows. First duplicate system description SDrenaming variable v : v 6 {IN CTL} v , thus generating SD (SD SD shareinput control variables). create healthy assignment (forassumable variables) 0 single fault assignment 0 differsign literal whose component want test. Finally, construct followingpropositional expression:#"_(7)SD SD 0oOUToperator denotes exclusive or, hence (o ) (o ).propositional expression (7) leaves unconstrained controlsneed. two instances system: healthy (SD 0 ) faulty (SD). last term forces output healthy faulty systemdifferent least one bit. compute ATPG control vector need one satisfiablesolution . Note ATPG control vector may exist ( |=), i.e., componentmay testable given CTL SD . Often multiple satisfying controlassignments. case FractalATPG chooses arbitrary one. lattermean satisfiable ATPG control vectors achieve uncertainty reduction.FractalATPG becomes suboptimal control testing given component,multiple controls. FractalATPG becomes completely randomcomponents tested given choice controls.two problems FractalATPG. First, FractalATPG assumes stationaryinputs, i.e., FractalATPG ignores source uncertainty. non-modifiable inputs, however, help decay process, hence FractalATPG conservative choosingcontrol assignmentsa feature leads suboptimality. bigger problemFractalATPG decreases expected number remaining MC diagnoses computingexact health one component. Here, problem FractalATPG tests onecomponent per step, tries compute control assignment computesexact state component. active testing algorithm decrease diagnostic uncertainty computing probability distribution function state component.315fiFeldman, Provan, & van Gemundnatural extension FractalATPG algorithm computes state kcomponents simultaneously. latter approach assumes system k-componenttestablean unrealistic assumption. experiments seen systems ofteneven single-component testable. Note computing exact states componentsrequirement decreasing diagnostic uncertainty. Instead computingexact state one components, algorithm shown next section implicitlybuilds probability density function health state component,suffer problems FractalATPG .5.3 FractalGConsider SD example started Sec. 3, input variables = {i}, control variables CTL = {a, b}, initial input values = i, initial observation 3 = (ab) (o1 o2 o3 o4 ). initial observation 3 leads 5 triple-fault MC diagnoses: (SD, 3 ) = {{h1 , h4 , h7 }, {h1 , h7 , h8 }, {h2 , h3 , h6 }, {h2 , h4 , h5 },{h3 , h6 , h8 }}. also write = (SD, 3 ) choose one faultstruly injected fault (let = {h1 , h7 , h8 }).ExhaustiveGreedyk1E (SD, IN|1 )k1E (SD, IN|1 )1234bbbab4.331.571.571.33123bbab4.331.571.33k2E (SD, IN|2 )k2E (SD, IN|2 )1234bbbab1.67111.67123bbab1.6711.67| (D, 1 )| = 2| (D, 1 )| = 2| ( (D, 1 ), 2 )| = 1| ( (D, 1 ), 2 )| = 1Figure 4: Exhaustive greedy search optimal control assignmentleft right parts Fig. 4 show two possible scenarios locating . leftexhaustive approach considers 2|CTL| control assignments, hencecannot used solve practical problems. greedy scenario right side Fig. 4decreases number computations expected number remaining MC diagnoses2|CTL| |CTL|. idea flip one control variable time, compute expectednumber remaining MC diagnoses keep flip (shown bold Fig. 4) Edecreases. Given initial control assignment consider space possible controlflips. space visualized lattice (Fig. 5 shows small example). Figure 5316fiA Model-Based Active Testing Approach Sequential Diagnosisshows expected number MC diagnoses control assignment. Note probingvisualized similar way.{i2 , i4 , i6 , i7 } 17.54{i2 , i4 , i6 } 17.54 {i2 , i4 , i7 } 14.5 {i2 , i6 , i7 } 21.05 {i4 , i6 , i7 } 21.05{i2 , i4 } 14.65 {i2 , i6 } 21.05 {i2 , i7 } 21.05 {i4 , i6 } 21.05 {i4 , i7 } 18.84 {i6 , i7 } 25{i2 } 21.05 {i4 } 18.84 {i6 } 25 {i7 } 25{} 25Figure 5: Example expectation optimization lattice (74182, |CTL| = 4, |IN| = 5).node shows set control flips expected number MC diagnoses.practice, control literals mostly independent even though space controlassignments continuous general, large continuous subspaces. greedyapproach shown Alg. 3, computes control assignment given active testingsystem prior observation.Algorithm 3 Greedy active testing algorithm1: function Fractal(ATS, ) returns control terminputs: ATS (active testing system): model(term): initial observationlocal variables: , (terms): control configurationsE, E (reals): expectations(set terms): diagnosesl (literal): control literal2:(SD, )3:E Expectation(ATS, , D)4:l5:FlipLiteral(, l)6:E Expectation(ATS, , D)7:E < E8:9:E E10:end11:end12:return13: end function317fiFeldman, Provan, & van Gemundset initial diagnoses computed initial observation line 2. line 5,Alg. 3 flips next literal current control assignment. auxiliary FlipLiteralsubroutine simply changes sign specified literal term. flipexpected intersection size computed call Expectation (cf. Alg. 1).new expected intersection size smaller current one, proposed controlassignment accepted current control assignment, search continuesthere.complexity FractalG determined complexity diagnostic search(line 2) complexity Expectation (line 3 line 6). denote formerlatter complexity FractalG becomes O(|CTL|)., complexity FractalG FractalG. practice FractalGrequires computation compute sufficient decay. due designExpectation (Alg. 1).active-testing problem worst-case NP -hard (it reduced computingdiagnosis), see experimentation section, possible achieve goodaverage-case performance choosing appropriate MBD oracle. advantagegreedy approach, particular, number computations expected numberdiagnoses linear number literals control assignment. doneprice optimality (i.e., effect combinations controls neglected).5.4 FractalPProbing related active testing measuring internal variables thoughtrevealing internal control circuits. Alternatively, one add control circuitry modelreveals values internal variables. reveal hidden control potentialimplement GDE probing (de Kleer & Williams, 1987) FractalP. approachdifferent GDE two ways. First, compute expected number remainingMC diagnoses instead expected diagnostic entropy. Second, Fractal useAssumption-Based Truth Maintenance System (ATMS) (de Kleer, 1986).Consider running example Sec. 3 observation 5 = b o1o2 o3 o4 . leads 5 triple-fault MC diagnoses: (SD, 3 ) = {{h1 , h4 , h7 },{h1 , h7 , h8 }, {h2 , h3 , h6 }, {h2 , h4 , h5 }, {h3 , h6 , h8 }}. Subsequent measurement p gives us | ( (SD, 3 ), p)| = 3 p positive | ( (SD, 5 ), p)| = 2otherwise. expected number MC diagnoses E (SD, {p}|3 ) = 2.6. Repeatingremaining internal variables results E (SD, {q}|3 ) = 2.6, E (SD, {r}|3 ) = 3.4,E (SD, {s}|3 ) = 3.4. result see measuring p q less informativemeasuring r s, intuitive r give balanced partitioningcircuit.Problem 2 (Probe Sequencing). Given system ATS, observation partialassignment internal variables , choose variable p set U unassignedinternal variables , that:p = argmin E (SD, p| )(8)pUAlgorithm 4 solves Problem 2. Algorithm 4 computes expected number diagnosesunobserved variable (lines 3 - 11). Starting set initial diagnoses318fiA Model-Based Active Testing Approach Sequential Diagnosis(computed line 2), Alg. 4 perform total 2|D||V \{OBSCOMPS}| consistency checks(lines 4 5) determine expected number MC diagnoses unobservedvariable.next show probing algorithm introduced de Kleer Williams (1987)adapted Fractal framework.Algorithm 4 Probing algorithm1: function FractalP(ATS, ) returns variableinputs: ATS (active testing system): model(term): observationlocal variables: v, R (variables): probesE, E (reals): expectationsp, q (reals): remaining diagnoses(set terms): diagnoses2:(SD, )3:v V \ {COMPS OBS}4:p | (D, v)|5:q | (D, v)|6:E (p2 + q 2 )/(p + q)7:E < E8:Rv9:E E10:end11:end12:return R13: end functionInstead computing expected number remaining MC diagnoses single variablep, possible consider measuring pairs variables hp1 , p2 i, general, k-tuplesinternal variables hp1 , p2 , . . . , pm |V \{OBSCOMPS}|. refer probinginvolving 1 variable k-probing. Although shown userssignificantly benefit terms diagnostic uncertainty performing k-probing (de Kleeret al., 1992), easily modify FractalP consider multiple probes. Note= |V \ {OBS COMPS}| probing problem, one way pickinternal variables.complex operation FractalP computing initial set MCdiagnoses. addition that, |V \ {COMPS OBS}| consistency checks. Consistency checking is, general, easier diagnosis. Note Fractal algorithms(FractalATPG , FractalG, FractalP) start computing set initial MCdiagnoses. Hence, difference performance determined complexityreducing initial set (SD, ). According criterion, fastest algorithmFractalP performs small number consistency checks, followed closelyFractalATPG (computing ATPG vectors). slowest algorithm FractalG,computes expected number MC diagnoses given multiple variables.319fiFeldman, Provan, & van Gemund6. Experimental Resultsimplemented Fractal approximately 3 000 lines C code (excludingdiagnostic engine Logic Based Truth Maintenance System). experimentsrun 64-node dual-CPU cluster (each node configured two 2.4 GHz AMD OpteronDP 250 processors 4 Gb RAM).6.1 Experimental Setupexperimented well-known benchmark models ISCAS85 combinationalcircuits (Brglez & Fujiwara, 1985). models derived ISCAS85 circuits computationally intensive (from diagnostic perspective), also considered four mediumsized circuits 74XXX family (Hansen, Yalcin, & Hayes, 1999). order usesystem model MC diagnosis counting simulation, fault modelogic gate stuck-at-opposite, i.e., faulty, output logic gate assumesopposite value nominal. Without loss generality, gates allowed failmodels. different ATPG gates typically fail wiresmodeled components fail failure modes stuck-at-zero stuck-at-one.ATPG MBD modeling approaches achieve results.Table 3: overview 74XXX/ISCAS85 circuits (V total number variablesC number clauses)NameDescription7418274L8574283741814-bit4-bit4-bit4-bitc432c499c880c1355c1908c2670c3540c5315c6288c755227-channel interrupt ctl.32-bit SEC circuit8-bit ALU32-bit SEC circuit16-bit SEC/DEC12-bit ALU8-bit ALU9-bit ALU32-bit multiplier32-bit adderCLAcomparatoradderALU|IN||OUT|Original|COMPS|9119145358364160413323350178322077322632251402212332108Reduced|COMPS|VC1933366547778114415023624445661514211602023835468801 1931 6692 3072 4163 5123564458261 1331 7932 6953 3884 7924 8647 2325147141 1121 6102 3783 2694 6086 6937 2169 656595877581601673533851 456545addition original 74XXX/ISCAS85 models, performed cone reductionsdescribed Siddiqi Huang (2007) de Kleer (2008). Recall perspectiveMBD diagnostic engine, faults inside cone (where cone set components)cannot distinguished, hence enough provide single health variable per cone.call models single health variable per cone reduced. Table 3 describes models.320fiA Model-Based Active Testing Approach Sequential Diagnosisinitial observation vectors control settings used first stepFractal inference. illustrate significant diagnostic convergence possible,use initial observations leading high numbers initial MC diagnoses.average diagnostic outcomes observations, repeat experimentrange initial observation vectors. cardinality MC diagnosissignificance Fractal, produces significant burden diagnostic oracle (Feldman, Provan, & van Gemund, 2008). order overcome computational difficulty,limited experiments observation vectors leading double faults only.circuit generated 1 000 non-masking double-faults, observation computed number initial MC diagnoses. 1 000 observationvectors taken 100 largest number MC diagnoses. resultingobservations summarized Table 4. example, see staggering number46 003 double faults under-constrained c7552 observation.Table 4: Number MC diagnoses per observation vectorNameMinOriginalMaxMeanMinReducedMax Mean7418274L857428374181253248932588601752550.251.8113.52561021391927713.3c432c499c880c1355c1908c2670c3540c5315c6288c7552881687831 2001 7822 7471 3643 3126 24616 6173702921 9441 9965 6147 2752 65017 42315 79546 003165.8214.11 032.51 623.32 321.93 621.71 642.26 202.18 526.123 641.22142044010158152 928451273119031341905761926 81162447.515.839.71584.821.322634.53 853121.6Since 74XXX/ISCAS85 circuits control variables abuse benchmarkdesignating fraction input variables controls.define two policies generating next inputs: random stationary. latterinput policy (where input values change time) typical diagnostic worst-casesystem environments are, example, paused pending diagnostic investigation,provides us useful bounds analyzing Fractals performance.Note use non-characterizing sets diagnoses (see Def. 4) may lead situation real (injected) fault initial set diagnoses. caseset remaining diagnoses (S) may become empty set number Fractalsteps. Although gives us diagnostic information, undesirable situationnon-characterizing sets diagnoses represent diagnostic probability mass minimize likelihood cases. constructed experimentalbenchmark initial observations way avoid cases.321fiFeldman, Provan, & van Gemund6.2 Expected Number MC Diagnosesobserved error Alg. 1 insensitive number compositioninput variables. seen value expected number diagnosesE approaches exact value E increasing number samples n. particular,E equal exact value expected number MC diagnoses E, possibleinput values considered. Figure 6 shows examples E approaching E threebenchmark models.c432c880200c1908160E18040E15038140160130361201400100200 300step400500110EE0100200 300step400500340100200 300step400500Figure 6: Convergence expected number MC diagnoses increasing sample sizeTerminate approximates intermediate value E computing sequence E = hE1 ,E2 , . . ., En i. standard error mean E defined as:SEME = ,n(9)standard deviation E. set Terminate terminate Alg. 1n > 15 SEME < , circuit-dependent threshold constant. Table 5 showsvarious circuits experimented on.Table 5: Termination parameters Alg. 1OriginalMean n Max n7418274L8574283741810.10.110.20.452.7176.2139.9169.11102462252030.010.030.010.07151.6170.3211.3143.2223212243181c432c499c880c1355c1908c2670c3540c5315c6288c75520.720.773.574.314.0112.7713.623.3533.1868.1148.236.493.951.319.540.578.934.237.268.7996116393357819639144910.180.020.10.010.620.10.660.0919.13.73108.655.7156.3121.418.865.289.636.039.47315892204148251021324874122322ReducedMean n Max nNamefiA Model-Based Active Testing Approach Sequential Diagnosisdetermined using following procedure. First, circuit, choosearbitrary initial observation small set input variables (|IN| = 8). smallcardinality allows us compute true values E. Next, circuit run 10pseudo-random experiments. choose smallest value SEMEcorresponding E within 95% E. Table 5 shows average maximum numbersteps Alg. 1 reaches value. cases upper bound n = 100 safetermination criterion.6.3 Comparison AlgorithmsConsider weak-fault model chain n inverters set MC diagnoses (initially,|D| = n). step single-variable probing eliminate 0.5|D| diagnoses.also shown halving expected number remaining MC diagnoses theoreticalbound one-step lookahead strategy. result use geometric decay curveN (k) = N0 pk + N(10)model diagnosis decay. case, N0 initial number diagnoses, Nvalue |(S)| converges, p decay rate constant. probing, N = 1.experiments fit expected number remaining MC diagnoses Eactual number remaining MC diagnoses (S) Eqn. 10.6.3.1 FractalATPGFigure 7 shows reduction expected number MC diagnoses function (1)number control variables |CTL| (2) time k. One easily see globaloptimum reached quickly independent axes. decay shown c432(Fig. 7, left) reduced c880 (Fig. 7, right). number control variables |CTL|varies 0 36 c432 (|IN| = 36) 0 60 c880 (|IN| = 60).c432c880 (reduced)300300200EE20010010002468 1012 14k3020100002|CTL|46208 1012 14k6040|CTL|Figure 7: Decay E, stationary inputs, FractalATPGUsing |(S)| instead E results similar plots (there high correlation E|(S)|), hence omitted |(S)| plots. minimum, maximum meanPearsons linear correlation coefficient E Fig. 7 respective |(S)|number control variables c432 min = 0.713, max = 0.999, avg = 0.951,323fiFeldman, Provan, & van Gemundrespectively. corresponding correlation coefficients reduced c880 min =0.834, max = 1, avg = 0.972.seen expected number remaining diagnoses E quickly reachesglobal optimum increasing |CTL|, means turning even small numberinput variables controls allows geometric decay diagnostic entropy.results reduced c880 similar non-reduced c432. Hence, identificationcones helps performance diagnostic oracle, change convergencebehavior effect control variables.Fitting geometric decay curves (Eqn. 10) |CTL| axes Fig. 7 produces betterfits c880 c432. Similarly, values N fits alongside k-axislarger c432 c880. reason small number outputs c432(cf. Table 3). circuits outputs, randomly turning limited number inputscontrols may lead fast decay small N , control-output connectivitymodel essential decreasing diagnostic uncertainty.Table 6 Table 7 summarize total 14 000 FractalATPG experimentswhole 74XXX/ISCAS85 benchmark. Table 6 shows correlation expectednumber remaining MC diagnoses actual number remaining MC diagnoses.second third columns Table 6 see minimum average correlationsE (S). third fourth cases specify fraction observations> 0.95 > 0.975, respectively. Columns 6 9 repeat datareduced 74XXX/ISCAS85 circuits.Table 6: Linear correlation coefficient expected number remaining MC diagnosesE actual number remaining diagnoses (S), |CTL| = 14 |IN|, stationaryinputs, FractalATPGNameminavg7418274L8574283741810.550.460.460.460.980.910.910.88c432c499c880c1355c1908c2670c3540c5315c6288c755200.50.5100.3800.480.540.420.620.830.870.860.880.870.890.860.930.90.88Original> 0.95Reduced> 0.95> 0.975minavg> 0.9750.820.520.690.480.790.440.610.3910.450.450.4510.810.840.8610.40.380.4410.390.310.350.240.320.280.320.310.310.290.480.410.440.160.150.180.180.180.160.190.390.240.13000.510000.060.470.40.450.810.860.850.870.790.790.820.880.90.890.290.420.30.470.220.190.30.440.360.430.230.330.190.340.150.120.230.320.210.23Table 7 summarizes parameters geometric decay curves fitted (S). seealthough (S) well approximated geometric decay curve (the average goodness324fiA Model-Based Active Testing Approach Sequential Diagnosisof-fit criterion R2 0.84) average decay constant p low (0.13 non-reduced0.22 reduced 74XXX/ISCAS85 circuits).Table 7: Decay rate p (minimal, maximal, average) goodness-of-fit R2 (average)geometric decay best-fit (S), |CTL| = 41 |IN|, stationary inputs, FractalATPGpminOriginalpmax pavg2RavgpminReducedpmax pavg2Ravg7418274L8574283741810.30.060.180.110.520.750.680.710.430.480.570.50.950.880.780.860.50.350.310.180.50.640.60.640.50.50.480.510.920.940.9c432c499c880c1355c1908c2670c3540c5315c6288c75520.030.10.060.030.020.050.020.220.020.560.80.790.840.90.930.910.870.910.910.950.560.640.540.620.650.630.520.650.520.760.810.840.830.810.680.770.850.80.880.610.030.480.060.390.510.140.040.060.020.010.790.760.80.760.740.750.760.790.90.880.520.650.530.630.640.60.450.540.510.580.820.840.870.850.770.80.890.840.890.85Average0.130.820.580.810.220.740.550.87Namedecay rate p depends mostly circuit topology, hence large variance Table 7.Consider, example, artificial topology, n components, n outputvariables produce health-state component specific control assignment(e.g., self-test). topology p would small diagnostician needsone test (control assignment) decrease number MC diagnoses one.performance FractalATPG determined size modeldiagnostic oracle. experiments overall time executing single scenariovaried 3.4 74182 1 015 c6288. satisfiability problems ATPG partalways easy DPLL solver spent milliseconds computing control assignments.decay rate FractalATPG depends number composition controls.follows see FractalG achieve similar decay rate smallernumber control variables.6.3.2 FractalGFigure 8 shows decay expected number remaining MC diagnoses FractalG.reduction similar c432, see steeper reduction numberremaining MC diagnoses independent axes. Hence, greedy algorithm betterFractalATPG identifying control combinations small size, thereby leadingbetter decay rate.325fiFeldman, Provan, & van Gemundc432c880 (reduced)250100200^^EE15010050500510k15301020000205|CTL|10k401560|CTL|Figure 8: Decay E (left) (S) (right), stationary inputs, FractalGTable 8 Table 9 summarize whole 74XXX/ISCAS85 benchmark. Table 8 showsFractalG, similar FractalATPG, results high average correlation (S)E (avg > 0.79 circuits).Table 8: Linear correlation coefficient expected number remaining MC diagnosesE actual number remaining diagnoses (S), |CTL| = 14 |IN|, stationaryinputs, FractalGNameminavg7418274L8574283741810.030000.880.720.50.56c432c499c880c1355c1908c2670c3540c5315c6288c75520.010.010.050.080.050.010.340.270.090.780.750.880.770.860.810.830.730.780.810.86Original> 0.95Reduced> 0.95> 0.975minavg> 0.9750.390.120.080.050.180.060.030.0210.010010.660.480.5510.160.120.0910.140.110.070.070.290.090.360.250.380.090.050.110.060.020.080.060.210.140.220.0500.050.060.01000.4200.01000.10.210.680.850.730.90.80.760.70.60.780.830.070.330.080.390.40.370.040.10.090.130.050.20.040.160.30.260.010.070.040.01decay rates FractalATPG FractalG similar (cf. Table 7 Table 9),but, visible Fig. 8, FractalG reduces number remaining MC diagnosesquickly, fewer control variables. c432 combinational circuit difficultactive testing small number outputs compared number inputs(cf. Table 3), hence reducing diagnostic utility.summarize effect number controls diagnostic convergence,fit geometric decay curve (Eqn. 10) (S) 100 initial observation326fiA Model-Based Active Testing Approach Sequential DiagnosisTable 9: Decay rate p (minimal, maximal, average) goodness-of-fit R2 (average)geometric decay best-fit (S), |CTL| = 14 |IN|, stationary inputs, FractalGpminOriginalpmax pavg2RavgpminReducedpmax pavg2Ravg7418274L8574283741810.240.050.120.150.530.740.670.750.430.470.420.480.950.90.90.90.50.250.350.150.50.650.580.690.50.490.440.4410.930.960.93c432c499c880c1355c1908c2670c3540c5315c6288c75520.040.090.120.190.320.210.340.30.040.080.880.880.670.870.730.740.630.830.810.540.560.710.420.630.530.530.530.610.50.340.830.810.90.870.870.870.910.830.90.920.030.340.070.110.050.150.010.060.080.160.860.850.830.820.840.810.80.860.770.830.590.680.520.680.590.60.440.580.470.590.80.850.880.850.830.80.90.820.890.84Average0.160.730.510.880.170.760.540.88Namevectors various |CTL|. case, N0 initial number diagnoses, Nvalue |(S)| converges, p decay constant (the important parameterfits). easy circuit chain topology, p = 12 , N0 halves every k steps,binary search, hence p corresponds one bit. p = 41 , p corresponds two bits.Table 10: Mean p various numbers control bits, stationary input policy, FractalGName3 bitsc432c499c880c1355c1908c2670c3540c5315c6288c75520.610.790.50.710.680.450.390.520.310.62Original4 bits 5 bits0.690.830.550.720.70.490.380.620.410.770.420.770.620.590.410.390.430.670.230.33 bits0.70.580.490.80.540.390.790.810.640.59Reduced4 bits 5 bits0.710.620.470.820.520.440.80.720.70.340.570.520.440.750.30.420.610.790.590.38Table 10 shows average p initial observations various numbers controlbits b = lg |CTL|. Table 10 include data 74XXX circuitsenough inputs (we need circuits least 32 inputs). Table 10 visible327fiFeldman, Provan, & van Gemundexponential increase number control variables lead significantdecrease p. Hence, ISCAS85, even turning small number input variablescontrols leads near-optimal decrease number remaining MC diagnoses.performance FractalG worse FractalATPG due multivariable expectation. running time varied 7.1 74182 2 382c6288. CPU time spent Expectation subroutine (cf. Alg. 1).consistency check computationally easy, circuit thousandsthem. Hence, improving performance LTMS would lead increaseperformance FractalG.6.3.3 FractalPnext discuss FractalP. mentioned earlier, probing different active testingassumes full observability model, i.e., internal variables measured (cf.Sec. 5). Furthermore, probing considers one internal variable per step, active testingassigns value control variables.5value decay rate p depends (1) topology circuit, (2) initialobservation (3) values subsequent probes. probing ISCAS85 seevalues decay rate p close 0.5 (S) E. Figure 9 showsactual expected number remaining MC diagnoses ( (S) E, respectively)geometric fit E three probing scenarios.c3540 (reduced)c432c5315300300kkN0 p + N(S )E200N0 p + N(S )E2008000N0 p k + N(S )E6000400010010020000246k810120246k810120246k81012Figure 9: Actual number remaining MC diagnoses (S), expected number remainingMC diagnoses E, geometric decay fit (S), stationary inputs, FractalPplot Fig. 9 shows single probing session single initial observation. Figure 10shows goodness-of-fit criterion R2 vs. decay rate constant p 100 observations10 multiple runs Fig. 9 circuits.visible Fig. 10 absolute values R2 (in cases) close1. indicator probing experiments fit geometric decay model givenEqn. 10 well. Figure 10 shows bad topology (c432 left), good topology(c5315 right) achieves decay rate p close 0.5 (0.38 < p < 0.58) highaccuracy fit (0.9896 R2 1).expected number remaining MC diagnoses good predictor actual numberMC diagnoses ISCAS85 circuits, shown Table 11. absolute values,5. exist multi-probe generalizations probing (de Kleer et al., 1992).328fiA Model-Based Active Testing Approach Sequential Diagnosisc5315c3540 (reduced)10.950.9950.9950.90.992R0.9850.9850.850.99R21R2c43210.80.980.980.750.9750.97500.5p100.5p010.5p1Figure 10: Geometric decay rate vs. goodness-of-fit (S), FractalPdepend topology, see smaller correlation c432 observations.cases, however, correlation significant, e.g., circuits observationsexcept c432 > 0.95.Table 11: Linear correlation coefficient expected number remaining MC diagnoses E actual number remaining diagnoses (S), stationary inputs,FractalPNameminavg7418274L8574283741810.830.770.970.960.950.970.990.99c432c499c880c1355c1908c2670c3540c5315c6288c75520.660.970.980.990.980.980.970.990.920.950.97111111111Original> 0.95Reduced> 0.95> 0.975minavg> 0.9750.640.87110.60.6710.9710.830.830.9210.990.980.9910.920.830.9510.870.760.920.831111111110.67111111110.990.620.910.920.860.650.70.970.70.980.820.960.980.990.980.970.9610.9810.960.760.870.990.880.860.7210.9110.70.620.760.960.790.680.5510.8110.51second third columns Table 11 see minimum average correlations E (S). third fourth cases specify fraction observations> 0.95 > 0.975, respectively. Columns 6 9 repeat datareduced 74XXX/ISCAS85 circuits.Table 12 summarizes decay rate p goodness-of-fit criterion R2 observations circuits. c432, values p R2 dispersed,experiments p strongly resembles chained-elements (i.e., p close 0.5).minimum, maximum average values p (per circuit) given columns pmin ,pmax , pavg , respectively.329fiFeldman, Provan, & van GemundTable 12: Decay rate p (minimal, maximal, average) goodness-of-fit R2 (average)geometric decay best-fit (S), stationary inputs, FractalPpminOriginalpmax pavg2RavgpminReducedpmax pavg2Ravg7418274L8574283741810.260.210.310.30.640.70.640.660.540.520.490.50.950.970.990.990.50.250.40.270.50.550.580.560.50.450.490.4210.970.960.99c432c499c880c1355c1908c2670c3540c5315c6288c75520.10.40.360.390.390.370.380.40.920.950.820.570.610.60.580.60.580.59110.580.50.510.510.50.510.50.5110.96111111110.990.110.250.20.250.130.220.370.180.980.820.840.60.670.590.810.850.590.8910.960.550.460.460.460.550.650.490.5210.70.950.980.990.980.960.8910.9610.51Average0.410.690.580.990.350.710.550.94Name6.4 Experimental Summarycompare Table 6 Table 11 see average correlation avg decreasessignificantly. Hence, assuming limited observability (i.e., assuming internalsmeasurable) decreases quality E predictor (S). increased statisticaldispersion visible increased range max min (cf. Table 6, maxalways 1). example, consider c2670, standard deviation E vs. (S)correlation coefficients = 0.0031 FractalP = 0.0783 FractalATPG.difference dispersion correlation coefficients significant circuits,smallest values c432, 0.0038 FractalP 0.0825 FractalATPG .comparing Table 7, Table 9, Table 12 see mean decay ratesFractalATPG, FractalG, FractalP similar (the average p FractalG0.7 average p FractalATPG 0.73). average goodness-of-fit criterion R2exponential decays always good (0.88 FractalG, 0.84 FractalATPG),almost perfect probing (0.97).summary experiments best shown Fig. 11. factor samplingerror able perform exhaustive computations, chosen smallest74182 circuit. original 74182 (a 4-bit carry-lookahead generator) 19 components,9 inputs, 5 outputs. turned four inputs controls (hence, |IN| = 4|CTL| = 4).considered random control policy addition FractalP, FractalATPG,FractalG. random control policy, step, random value assignedcontrol variable. also shown exhaustive control search expected330fiA Model-Based Active Testing Approach Sequential Diagnosisnumber remaining MC diagnoses computed step, possible controlcombination. works 74182 leads combinatorial blow-up(larger) circuit.74182, geometric decay fit74182, remaining number MC diagnoses4040Fractal PFractal ATPGFractal Grandom controlsbest controls30(S)253020152015105502468random controlsbest controls25100Fractal PFractal ATPGFractal G35N0 p k + N1352468kkFigure 11: Comparison control policiesreduce stochastic error plotting Fig. 11, replaced sampling (forcomputing expected number remaining MC diagnoses) exhaustive method;possible |IN| = 5. randomized decision choose actual faultinitial ambiguity group. reduce error due stochastic fault injection,tested 5 control policies 100 times.see Fig. 11 least informed control policy (the random control policysimply use E) shows worst decay number remaining diagnoses.extreme, exhaustive control policy achieves best decay. pricepolicy terms computational effort, however, prohibitive. FractalG achievesdecay rates comparable exhaustive policy affordable average-case complexity.FractalATPG better complexity FractalG, whole decay rate curveFractalATPG bounded one computed FractalG.Probing compare active testing approaches different assumptions observability model. Figure 11 shows decay rate probingillustrate different decay curves depending observability assumptions.experiment probing decay rate geometric fit p = 12 almost perfectly fits actualnumber remaining MC diagnoses.7. Conclusionsdevised algorithm, FractalG, active testing (1) computationallyefficient (2) rapidly reduces diagnostic uncertainty (measured numberremaining MC diagnoses) manipulating set control variables. fully optimizing (2)leads combinatorial blow-up, FractalG achieves compromise (1) (2)using greedy approximation approach searching space control assignmentsstochastic sampling method computing number remaining MC diagnoses.result fast algorithm (optimizing whole Fractal scenario takes 1331fiFeldman, Provan, & van Gemund74182 40 min c6288) decreases diagnostic uncertainty accordinggeometric decay curve. geometric decay curve fits Fractal data well (thegoodness-of-fit criterion R2 0.88 average) provides steep decay (the average decayrate p 0.7).applied FractalG real-world problem reducing diagnostic uncertainty heavy-duty printer (Feldman, 2010). purpose, modeledPaper Input Module (PIM). PIM case-study, FractalG computed informative tests troubleshooting multiple sensor component failures. happens evencoarse-grained device model (only constraints per component), showsunexpected benefit Fractal: trade-off modeling complexity vs. test effort.optimality FractalG depends topology constraints inputmodel. create models leading arbitrarily bad optimality FractalG by,example, directly encoding truth tables SD. practical situations, however, controlsindependent. means applying single control rarely undoes effectprevious ones. also happens arbitrary inputs converted controls,experimentation benchmark. Consider, example, multiplier (c6288). Leavinginputs leads dont cares output hence components (full-adders,and-gates) remain untested. Subsequently assigning values left-out inputsunambiguously exonerate blame untested components, help narrowingset diagnostic hypotheses.important benefit applying Fractal industrial cases activetesting trade-offs modeling fidelity computational complexity extra testing.enables users achieve good diagnostic certainty without large cost traditionally associated developing high fidelity models based physics failure precisionapproaches.compared optimality performance FractalG ATPG-basedalgorithm sequential diagnosis, FractalATPG. average decay ratealgorithms similar (average p FractalATPG 0.73), average goodness-of-fit criterion R2 FractalATPG lower (0.84), means FractalG consistentlycloser optimal solution FractalATPG . FractalG achieved better exponential decay compared algorithms except exhaustive control search. example,difference decay rate p FractalG exhaustive search 741825.4%. exhaustive control approach, however, takes minutes complete evencircuit simple 74182, times-out model 20 controls.result, conclude FractalG trades small decrease p significantperformance speedup.ReferencesAlur, R., Courcoubetis, C., & Yannakakis, M. (1995). Distinguishing tests nondeterministic probabilistic machines. Proc. ACM Symposium Theory Computing,pp. 363372.Brglez, F., & Fujiwara, H. (1985). neutral netlist 10 combinational benchmark circuitstarget translator Fortran. Proc. ISCAS85, pp. 695698.332fiA Model-Based Active Testing Approach Sequential DiagnosisBrodie, M., Rish, I., Ma, S., & Odintsova, N. (2003). Active probing strategies problemdiagnosis distributed systems. Proc. IJCAI03, pp. 13371338.Bushnell, M. L., & Agrawal, V. D. (2000). Essentials Electronic Testing Digital,Memory Mixed-Signal VLSI Circuits. Kluwer Academic Publishers, Boston.de Kleer, J. (1986). Problem solving ATMS. Artificial Intelligence, 28 (2), 197224.de Kleer, J. (2008). improved approach generating Max-Fault Min-Cardinality diagnoses. Proc. DX08, pp. 247252.de Kleer, J., Raiman, O., & Shirley, M. (1992). One step lookahead pretty good.Readings Model-Based Diagnosis, pp. 138142. Morgan Kaufmann Publishers, SanFrancisco.de Kleer, J., & Williams, B. (1987). Diagnosing multiple faults. Artificial Intelligence,32 (1), 97130.Deb, S., Ghoshal, S., Malepati, V. N., & Kleinman, D. L. (2000). Tele-diagnosis: Remotemonitoring large-scale systems. Proc. AEROCONF00, Vol. 6, pp. 3142.Esser, M., & Struss, P. (2007). Fault-model-based test generation embedded software.Proc. IJCAI07, pp. 342347.Feldman, A. (2010). Approximation Algorithms Model-Based Diagnosis. Ph.D. thesis,Delft University Technology.Feldman, A., Provan, G., & van Gemund, A. (2008). Computing observation vectorsMax-Fault Min-Cardinality diagnoses. Proc. AAAI08, pp. 919924.Feldman, A., Provan, G., & van Gemund, A. (2009a). FRACTAL: Efficient fault isolationusing active testing. Proc. IJCAI09, pp. 778784.Feldman, A., Provan, G., & van Gemund, A. (2009b). Solving strong-fault diagnostic modelsmodel relaxation. Proc. IJCAI09, pp. 785790.Forbus, K., & de Kleer, J. (1993). Building Problem Solvers. MIT Press.Hansen, M., Yalcin, H., & Hayes, J. (1999). Unveiling ISCAS-85 benchmarks: casestudy reverse engineering. IEEE Design & Test, 16 (3), 7280.Heinz, S., & Sachenbacher, M. (2008). Using model counting find optimal distinguishingtests. Proc. COUNTING08, pp. 91106.Ibarra, O. H., & Sahni, S. K. (1975). Polynomially complete fault detection problems. IEEETrans. Computers, 24 (3), 242249.Kuhn, L., Price, B., de Kleer, J., Do, M., & Zhou, R. (2008). Pervasive diagnosis: Integrationactive diagnosis production plans. Proc. DX08, pp. 106119.Kundakcioglu, O. E., & Unluyurt, T. (2007). Bottom-up construction minimum-costand/or trees sequential fault diagnosis. IEEE Trans. SMC, 37 (5), 621629.Pattipati, K., & Alexandridis, M. (1990). Application heuristic search informationtheory sequential fault diagnosis. IEEE Trans. SMC, 20 (4), 872887.Pietersma, J., & van Gemund, A. (2006). Temporal versus spatial observability modelbased diagnosis. Systems, Man Cybernetics, 2006, 6, 53255331.333fiFeldman, Provan, & van GemundPrasad, M. R., Chong, P., & Keutzer, K. (1999). ATPG easy. Proc. DAC99, pp.2228.Raghavan, V., Shakeri, M., & Pattipati, K. (1999). Optimal near-optimal test sequencing algorithms realistic test models. IEEE Trans. SMC, 29 (1), 1126.Rish, I., Brodie, M., & Ma, S. (2002). Accuracy vs. efficiency trade-offs probabilisticdiagnosis. Proc. AAAI02, pp. 560566.Shakeri, M. (1996). Advances System Fault Modeling Diagnosis. Ph.D. thesis,University Connecticut.Shakeri, M., Raghavan, V., Pattipati, K. R., & Patterson-Hine, A. (2000). Sequential testingalgorithms multiple fault diagnosis. IEEE Trans. SMC, 30 (1), 114.Siddiqi, S., & Huang, J. (2007). Hierarchical diagnosis multiple faults. Proc. IJCAI07,pp. 581586.Stephan, P., Brayton, R., & Sangiovanni-Vincentelli, A. (1996). Combinational test generation using satisfiability. IEEE Trans. CAD Integrated Circuits Systems,15 (9), 11671176.Struss, P. (1994). Testing physical systems. Proc. AAAI94, pp. 251256.Tu, F., & Pattipati, K. (2003). Rollout strategies sequential fault diagnosis. IEEE Trans.SMC, 33 (1), 8699.334fiJournal Artificial Intelligence Research 39 (2010) 581632Submitted 12/09; published 11/10Clustering Want?Inducing Ideal Clustering Minimal FeedbackSajib DasguptaVincent Ngsajib@hlt.utdallas.eduvince@hlt.utdallas.eduHuman Language Technology Research InstituteUniversity Texas Dallas800 West Campbell Road; Mail Station EC31Richardson, TX 75080-3021 U.S.A.Abstracttraditional research text clustering largely focused grouping documentstopic, conceivable user may want cluster documents along dimensions,authors mood, gender, age, sentiment. Without knowing users intention,clustering algorithm group documents along prominent dimension,may one user desires. address problem clustering documentsalong user-desired dimension, previous work focused learning similarity metricdata manually annotated users intention human constructfeature space interactive manner clustering process. goalreducing reliance human knowledge fine-tuning similarity function selectingrelevant features required approaches, propose novel active clusteringalgorithm, allows user easily select dimension along wantscluster documents inspecting small number words. demonstrateviability algorithm variety commonly-used sentiment datasets.1. IntroductionText clustering one major application domains demonstrating viabilityclustering algorithm. traditional research text clustering largely focusedgrouping documents topic, conceivable user may want cluster documents along dimensions, authors mood, gender, age, sentiment. Sincevirtually existing text clustering algorithms produce one clustering givenset documents, natural question is: clustering necessarily one user desires? words, text clustering algorithm always produce clustering alonguser-desired dimension?answer question depends large extent whether user successfully communicate intention clustering algorithm. Traditionally,achieved designing good similarity function capture similaritypair documents, ideal clustering produced. typically involvesidentify set features useful inducing desired clusters (Liu, Li,Lee, & Yu, 2004). However, manually identifying right set features timeconsuming knowledge-intensive, may even require lot domain expertise.fact resulting similarity function typically easily portable domainsparticularly unappealing machine-learning perspective. overcome weakness,c2010AI Access Foundation. rights reserved.fiDasgupta & Ngresearchers attempted learn similarity metric side information (Xing, Ng,Jordan, & Russell, 2002), constraints pairs documents must mustappear cluster (Wagstaff, Cardie, Rogers, & Schrodl, 2001).contrast, recent work focused active clustering, clustering algorithmincorporate user feedback clustering process help ensure documents grouped according user-desired dimension. One wayuser incrementally construct set relevant features interactive fashion (Bekkerman, Raghavan, Allan, & Eguchi, 2007; Raghavan & Allan, 2007; Roth & Small, 2009).Another way user correct mistakes made clustering algorithmclustering iteration specifying whether two existing clusters mergedsplit (Balcan & Blum, 2008). major drawback associated active clusteringalgorithms involve considerable amount human feedback, needsprovided iteration clustering process. Furthermore, identifying clustersmerging splitting Balcan Blums algorithm may easy appears:merge split decision user makes, sample large numberdocuments cluster(s), read documents, base decisionextent documents (dis)similar other.article, attack problem clustering documents according user interestdifferent angle. aim knowledge-lean approach problemapproach produce clustering documents along user-desired dimensionwithout relying human knowledge fine-tuning similarity function selectingrelevant features, unlike existing approaches. end, propose novel activeclustering algorithm, assumes input simple feature representation (composedunigrams only) simple similarity function (i.e., dot product), operates(1) inducing important clustering dimensions1 given set documents,clustering dimension represented (small) number automatically selected wordsrepresentative dimension; (2) user choose dimension alongwants cluster documents examining automatically selected words.comparison aforementioned feedback mechanisms, arguably much simpler:require user cursory look small number featuresdimension all, opposed user generate feature spaceinteractive manner identify clusters need merged split clusteringiteration.evaluate active clustering algorithm task sentiment-based clustering,goal cluster set documents (e.g., reviews) according polarity(e.g., thumbs thumbs down) expressed author without using labeleddata. decision focus sentiment-based clustering motivated several reasons.One reason relatively little work sentiment-based clustering.mentioned before, existing work text clustering focused topic-based clustering,high accuracies achieved even datasets large number classes(e.g., 20 Newsgroups); despite large amount recent work sentiment analysis1. use term clustering dimension refer dimension along set documentsclustered. example, set movie reviews clustered according genre (e.g., action, romantic,documentary) sentiment (e.g., positive, negative, neutral).582fiInducing Ideal Clustering Minimal FeedbackReview 1sound system seem little better(the CDs skipping much). bottom linedidnt fix problem CDs still skipping noticeably,although bad before. ...Review 2John Lynch wrote classic Spanish-American Revolutions 1808-1826.describes events led independence Latin America Spain.book starts Rio de La Plata ends Mexico Central America.Curiously one note common pattern highly stratified societies lead Spanish ...reluctance Spanish Monarchy (and later even liberals) led independence ...interested better understanding Latin ??this great book must.Lynch cleverly combines historical economic facts Hispanic American societies ...Table 1: Snippets two reviews illustrate two challenges polarity classification.One reviews sentimentally ambiguous (Review 1),objective materials review significantly outnumber subjective counterparts(Review 2).opinion mining, much focused supervised methods (see Pang & Lee, 2008,comprehensive survey field).Another equally important reason focus sentiment-based clustering concerned challenges task presents natural language processing (NLP)researchers. Broadly speaking, complexity sentiment-based clustering arisestwo sources. First, reviews sentimentally ambiguous, containing positive negative sentiment-bearing words phrases. Review 1 Table 1 shows snippetreview DVD domain illustrates sentimental ambiguity problem:phrases little better, skipping, bad convey positive sentiment,phrases didnt fix skipping noticeably negative sentiment-bearing. Hence,unless sentiment analyzer performs deeper linguistic analysis, difficultanalyzer determine polarity review. Second, objective materials review tend significantly outnumber subjective counterparts, reviewer typicallydevotes large portion review describing features product assigning rating it; consequently, sentiment analyzer uses word- phrase-basedfeature representation composed mostly features irrelevant respectpolarity determination. Shown Review 2 Table 1 snippet book reviewillustrates problem. see, three words/phrases (classic, greatbook, cleverly) review correspond objective materials.aforementioned complications present significant challenges even supervised polarity classification systems, let alone sentiment-based clustering algorithms,access labeled data. illustrate difficulty two complications impose sentiment-based clustering, consider task clustering set moviereviews. Since review may contain description plot authors sentiment,clustering algorithm may cluster reviews along either plot dimension sentimentdimension; without knowing users intention, clustered along583fiDasgupta & Ngprominent dimension. Assuming usual bag-of-words representation, prominentdimension likely plot, uncommon review devoted almostexclusively plot, author briefly expressing sentiment endreview. Even reviews contain mostly subjective materials, prominentdimension may still sentiment owing aforementioned sentimental ambiguityproblem: presence positive negative sentiment-bearing words reviews renders sentiment dimension hidden (i.e., less prominent) far clusteringconcerned.sum, contributions article five-fold.propose novel active clustering algorithm cluster set documentsalong user-desired dimension without labeled data side informationmanually specified automatically acquired must-link cannot-link constraints.comparison existing active clustering approaches, algorithm appealrequiring much simpler human feedback.demonstrate viability algorithm evaluating performancesentiment datasets, also via set human experiments, typicallyabsent papers involve algorithms incorporating user feedback.results led deeper understanding spectral clustering. Specifically,propose novel application top eigenvectors produced spectral clusteringalgorithm, use unveil important clustering dimensions textcollection.results also implications domain adaptation, topic recentlyreceived lot attention NLP community. Specifically, showsentiment dimension manually identified one domain used automaticallyidentify sentiment dimension new, similar, domain.Preliminary results datasets possess one clustering dimension (e.g.,collection book DVD reviews, clustered sentimenttype product concerned) indicate algorithm capable producingmultiple clusterings dataset, one along dimension. Hence, algorithmpotentially reveal information dataset possible traditionalclustering algorithms, produce single clustering data.ability produce multiple clusterings particularly useful feature useridea wants documents clustered (duelack knowledge data, instance). Even user knowledgedata knows wants documents clustered, algorithm helpunveil hidden dimensions previously aware may alsointerest her.rest article organized follows. Section 2 presents basics spectralclustering, facilitate discussion active clustering algorithm Section3. describe human experiments evaluation results several sentiment datasetsSection 4 significance work Section 5. Finally, discuss related workSection 6 conclude Section 7.584fiInducing Ideal Clustering Minimal Feedback2. Spectral Clusteringgiven clustering task, important question ask is: clustering algorithmuse? popular choice k-means. Nevertheless, well-known k-meansmajor drawback able separate data points linearly separablegiven feature space (e.g., see Dhillon, Guan, & Kulis, 2004; Cai, He, & Han, 2005).Moreover, since k-means clusters documents directly given feature space,text applications typically comprises hundreds thousands features, performancecould adversely affected curse dimensionality. Spectral clustering algorithmsdeveloped response problems k-means. section, first presentone commonly-used algorithms spectral clustering (Section 2.1). Then,provide intuition behind spectral clustering (Section 2.2). Finally, describe two waysuse resulting eigenvectors produce clustering (Section 2.3).2.1 AlgorithmLet X={x1 , . . . , xn } set n data points clustered, : X X similarityfunction defined X, similarity matrix captures pairwise similarities(i.e., Si,j = s(xi , xj )). Like many clustering algorithms, spectral clustering algorithmtakes input outputs k-way partition C = {C1 , C2 , .., Ck } (i.e., ki=1 Ci = Xi, j : 6= j = Ci Cj = ). Equivalently, one think spectral clustering learningpartitioning function f , which, rest article, represented vectorf (i) {1, . . ., k} indicates cluster xi assigned. Notecluster labels interchangeable even renamed without lossgenerality.Among well-known spectral clustering algorithms (e.g., Weiss, 1999; Shi & Malik,2000; Kannan, Vempala, & Vetta, 2004), adopt one proposed Ng, Jordan,Weiss (2001), arguably widely-used. main steps Ng etal.s spectral clustering algorithm:1. Create diagonal matrix whose (i,i)-th entry sum i-th row S,construct Laplacian matrix2 L = 1/2 SD 1/2 .2. Find eigenvalues eigenvectors L.3. Create new matrix eigenvectors correspond largest eigenvalues.4. data point rank-reduced point m-dimensional space. Normalizepoint unit length (while retaining sign value).5. Apply k-means cluster data points using resulting eigenvectors.words, spectral clustering clusters data points low-dimensional space,dimension corresponds top eigenvector Laplacian matrix.2. follow Ng et al. (2001) employ normalized dual form usual Laplacian S.585fiDasgupta & Ng2.2 Intuition behind Spectral Clusteringmay immediately clear spectral clustering produces meaningful partitioning set points. theoretical justifications behind spectral clustering,since mathematics quite involved, provide intuitive justificationclustering technique way sufficient reader understand activeclustering algorithm Section 3, refer interested reader Shi Maliks (2000)seminal paper spectral clustering details. Since apply spectral clusteringproduce 2-way clustering given set data points rest article,center discussion 2-way clustering subsection.Spectral clustering employs graph-theoretic notion grouping. Specifically, setdata points arbitrary feature space represented undirected weighted graph,node corresponds data point, edge weight two nodes xixj similarity, Si,j .Given graph formulation, reasonable way produce 2-way partitioningdata points minimize similarity resulting two clusters, C1 C2 .Hence, reasonable objective function minimize cut value,XCut(C1 , C2 ) =Si,j (f (i) f (j))2 .i,jWithout loss generality, define f follows.1 : C1f (i) =1 : C2mentioned before, use 1 1 cluster labels here, interchangeablefact renamed whatever way want.One problem minimizing cut value, noticed Wu Leahy (1993),objective favors producing unbalanced clusters one containssmall number nodes. words, bias towards isolating small setnodes. mentioned Shi Malik (2000), surprising, sincenumber edges involved cut (and hence cut value) tends increase sizestwo clusters become relatively balanced.closer examination minimum cut criterion reveals problem: minimizes inter-cluster similarity, makes attempt maximize intra-cluster similarity.address weakness, Shi Malik (2000) propose minimize instead normalizedcut value, N Cut, takes account inter-cluster dissimilarity intra-clustersimilarity. specifically,Cut(C1 , C2 )Cut(C1 , C2 )+,assoc(C1 , C1 C2 ) assoc(C2 , C1 C2 )Passoc(A, B), computed xi A,xj B Si,j , total connection nodesnodes B. Given definition, cut resulting unbalanced clusterslonger small N Cut value. see reason, consider case C1 consistsone node. case, assoc(C1 , C1 C2 ) = Cut(C1 , C2 ), making N Cut(C1 , C2 ) large.N Cut(C1 , C2 ) =586fiInducing Ideal Clustering Minimal Feedbackalgebra, express N Cut follows:N Cut(C1 , C2 ) =f (D S)ff Dfsubject constraints (Df )T 1 = 0rPd(i)PiC2iC1 d(i)rPf (i) =d(i)PiC1 d(i)iC2: C1: C2d(i) = D(i, i), defined Section 2.1.3 first constraint, specifiesDf orthogonal 1, intuitively understood follows: since 1, constantvector entries 1, cannot used induce partition, constraintavoids trivial solution points assigned cluster.Unfortunately, Papadimitriou proves minimizing normalized cut NP-completeproblem, even special case graphs regular grids (see Shi & Malik, 2000,proof). Hence, following Shi Malik, relax minimization problem droppingsecond constraint allowing entry f take real value rather onetwo discrete values, seeking real-valued solution following problem:minnff (D S)ff Df(1)subjectDf 1.Assuming g = 1/2 f , rewrite Problem (1)minnggT 1/2 (D S)D 1/2 ggT g(2)subjectg 1/2 1.Following standard Rayleigh-Ritz theorem, one prove solutionProblem (2), g, eigenvector corresponds second smallest eigenvalue1/2 (D S)D 1/2 , equivalently, eigenvector corresponds second largesteigenvector D1/2 SD 1/2 , Laplacian matrix L defined Section 2.1.simplicity, henceforth refer eigenvector corresponds n-th largesteigenvalue L simply n-th eigenvector denote en .43. Besides normalized cut, ratio cut (Chan, Schlag, & Zien, 1994), average association (Shi & Malik, 2000),min-max cut (Ding, He, Zha, Gu, & Simon, 2001) also used objective functionsspectral clustering algorithms.4. Given Problem (2) involves minimizing Rayleigh quotient, may seem somewhat unintuitivesolution second eigenvector L rather first eigenvector. reason attributedconstraint associated problem, specifies solution g perpendicularD1/2 1, first eigenvector L.587fiDasgupta & Ngidea behind spectral clustering: second eigenvector L approximate solution problem minimizing normalized cut.5 course, since secondeigenvector real-valued solution, convert partitioning functionused cluster data points. Section 2.3 explains two simple waysconverting eigenvector partitioning function.turns eigenvectors L also convey useful informationdata. Specifically, impose additional constraint Problem (2) forcing solution orthogonal second eigenvector L, solution becomes thirdeigenvector. Hence, third eigenvector thought suboptimal solutionProblem (2), meaning also used impose reasonably good partitiondata points. Perhaps importantly, since eigenvectors L orthogonal(because L symmetric), clustering produced using third eigenvectorlikely correspond different dimension data produced secondeigenvector.generally, limit solution space real-valued vectorsorthogonal first eigenvectors L, solution constrained optimizationproblem (m + 1)-th eigenvector L. words, top eigenvectorsL intuitively thought revealing important dimension data, althoughsubsequent eigenvectors progressively less ideal far clustering concerned.2.3 Clustering EigenvectorsNg et al. (2001) point out, different authors still disagree eigenvectorsuse, derive clusters them. subsection, describe two commonmethods determining eigenvectors use, method, showderive clusters using selected eigenvector(s). methods serve baselinesevaluation.2.3.1 Method 1: Using Second EigenvectorSince Shi Malik (2000) show second eigenvector, e2 , approximate solutionproblem minimizing normalized cut, perhaps surprisinge2 commonly chosen eigenvector deriving partition. However, since e2real-valued solution constrained optimization problem, need specifyderive clusters it.Clustering using e2 trivial: since linearization points, one simple waydetermine threshold partitioning them. However, follow Ng et al. (2001)cluster points using 2-means one-dimensional space.2.3.2 Method 2: Using Top EigenvectorsRecall Section 2.1 eigen-decomposing Laplacian matrix, data pointrepresented co-ordinates. second method, use 2-means cluster datapoints m-dimensional space, effectively exploiting top eigenvectors.5. fact, since f = D1/2 g, pre-multiply second eigenvector L D1/2 getsolution Problem (1), following Ng et al. (2001), employ second eigenvector L directlyclustering, ignoring term D1/2 .588fiInducing Ideal Clustering Minimal Feedback3. Active Clustering Algorithmmentioned before, sentiment-based clustering challenging, part due factreviews clustered along one dimension. section, describeactive clustering algorithm, makes easy user specify dimensionalong wants cluster data points sentiment. Recall algorithm firstapplies spectral clustering reveal important dimensions data,lets user select desired dimension (i.e., sentiment). motivate importanceuser feedback, helps understand two baseline clustering algorithms describedSection 2.3, also based spectral methods rely user feedback, may always yield sentiment-based clustering. begin with, consider firstmethod, second eigenvector used induce partition. Recallsecond eigenvector reveals prominent dimension data. Hence, sentimentprominent dimension (which happen non-sentiment-bearing wordsoutnumber sentiment-bearing words bag-of-words representation review),resulting clustering reviews may sentiment-oriented. similar linereasoning used explain second baseline clustering algorithm,clusters based top eigenvectors, may always work well. Since eigenvector corresponds different dimension (and, particular, correspondnon-sentiment dimensions), using represent review may hamper accurate computation similarity two reviews far clustering along sentimentdimension concerned. rest section, discuss detail major stepsactive clustering algorithm, allows easy incorporation user feedback.3.1 Step 1: Identify Important Clustering Dimensionsrely simple method identifying important clustering dimensions giventext collection: employ top eigenvectors Laplacian important clustering dimensions. method motivated fact e2 , second eigenvectorLaplacian, optimal real-valued solution objective function spectralclustering minimizes (i.e., normalized cut, Shi & Malik, 2000), therefore optimalclustering dimension. importantly, exploit rarely-utilized observation discussedSection 2.2: remaining eigenvectors suboptimal solutions (with ei suboptimal increases), top eigenvectors (i.e., small values),less suboptimal, may still yield reasonably good (though optimal) clusteringsdata therefore serve good clustering dimensions. Existing applicationsspectral clustering mainly clustered data points space defined topeigenvectors, attempted use ei (with > 2) separatelyproduce clusterings, unlike ours. Note first eigenvector, constant vector,simply assigns data points cluster therefore typically ignored.3.2 Step 2: Identify Relevant Features PartitionGiven eigen-decomposition Step 1, first obtain second m-theigenvectors, correspond important dimensions data. nextquestion is: determine dimension captures user interest? One way589fiDasgupta & Nguser inspect m1 partitions reviews decidecorresponds closely sentiment-based clustering. main drawback associatedkind user feedback user may read large number reviewsorder make decision. Hence, reduce human effort, employ alternativeprocedure: (1) identify informative features characterizing partition,(2) user inspect features rather reviews. make easyhuman identify clustering dimension, features chosenuseful distinguishing reviews two clusters.identify rank informative features, employ method call maximummargin feature ranking (MMFR).6 Recall maximum margin classifier (e.g., supportvector machine) separates data points two classes maximizing marginseparation. Specifically, maximum margin hyperplane defined w x b = 0,x feature vector representing arbitrary data point, w (a weight vector) b (ascalar) parameters learned solving following constrained optimizationproblem:X1min kwk2 + C2subjectci (w xi b) 1 ,1 n,ci {+1, 1} class i-th training point xi , degree misclassification xi , C regularization parameter balances training error modelcomplexity.use w identify informative features partition. Noteinformative features large absolute weight values: feature largepositive (negative) weight strongly indicative positive (negative) class.7 exploitobservation identify informative features partition (1) trainingbinary SVM classifier8 partition, data points cluster assumedclass value; (2) sorting features according SVM-learned featureweights; (3) generating two ranked lists informative features using top bottomF features, respectively.Given ranked lists generated 1 partitions, user select onepartitions/dimensions relevant sentiment inspecting many featuresranked lists needed. picking relevant dimension, userlabel one two feature lists associated dimension positivenegative. Since feature list represents one clusters, cluster associatedpositive list labeled positive cluster associated negative listlabeled negative.6. Note commonly-used feature selection techniques log-likelihood ratio informationgain also applied identify informative features (see Yang & Pedersen, 1997,overview).7. notion using SVM feature weights measures feature informativeness also exploredwork. See, instance, work Fung (2003), Gilad-Bachrach, Navot, Tishby (2004),Kugler, Aoki, Kuroyanagi, Iwata, Nugroho (2005) details.8. SVM classifiers article trained using SVMlight package (Joachims, 1999a),learning parameters set default values.590fiInducing Ideal Clustering Minimal Feedbackcomparison existing user feedback mechanisms assisting clustering algorithm,requires comparatively little human intervention: require user selectdimension examining small number features, opposed user constructfeature space identify clusters need merged split requiredmethods.3.3 Step 3: Identify Unambiguous Reviewscaveat, however. mentioned introduction, many reviews containpositive negative sentiment-bearing words. ambiguous reviews likelyclustered incorrectly unambiguous counterparts. Since ranked listsfeatures derived partition, presence ambiguous reviewsadversely affect identification informative features using MMFR. result,remove ambiguous reviews deriving informative features partition.employ simple method identifying unambiguous reviews. computationeigenvalues, data point factors orthogonal projectionsdata points affinity. Ambiguous data points receive orthogonalprojections positive negative data points, hence near zerovalues pivot eigenvectors. words, points near zero valueseigenvectors ambiguous large absolute values. therefore sortdata points according corresponding values eigenvector, keeptop n/8 bottom n/8 data points. induce informative featuresresulting 25% data points, present user selectdesired partition.93.4 Step 4: Cluster Along Selected EigenvectorFinally, employ 2-means cluster reviews along eigenvector selecteduser, regardless whether review ambiguous not.4. Evaluationsection, describe experiments aim evaluate effectiveness activeclustering algorithm provide insights it.4.1 Experimental Setupbegin discussing details datasets, document preprocessing method,implementation spectral clustering, evaluation metrics.9. Note 25% somewhat arbitrary choice. Underlying choice merely assumptionfraction reviews unambiguous. see evaluation section, reviewsclassified according polarity high accuracy; consequently, features inducedresulting clusters also high quality. Additional experiments revealed list top-rankingfeatures change significantly induced smaller number unambiguous reviews.591fiDasgupta & Ng4.1.1 Datasetsuse five sentiment datasets, including widely-used movie review dataset [MOV](Pang, Lee, & Vaithyanathan, 2002) well four datasets containing reviews fourdifferent types products Amazon [Books (BOO), DVDs (DVD), Electronics (ELE),Kitchen Appliances (KIT)] (Blitzer, Dredze, & Pereira, 2007). dataset 2000labeled reviews (1000 positives 1000 negatives). illustrate differencetopic-based clustering sentiment-based clustering, also show topic-based clustering results POL, dataset created taking documents two sections20 Newsgroups discuss issues cryptography politics, namely, sci.crypttalks.politics.4.1.2 Document Preprocessingpreprocess document, first tokenize downcase it, representvector unstemmed unigrams, assumes value 1 0 indicatespresence absence document. addition, remove vector punctuation,numbers, words length one, words occur single review.Following common practice information retrieval community, also excludewords high document frequency, many stopwords domain-specificgeneral-purpose words (e.g., movies movie domain). preliminary examinationevaluation datasets reveals words typically comprise 12% vocabulary.decision exactly many terms remove dataset subjective: largecorpus typically requires removals small corpus. consistent, simplysort vocabulary document frequency remove top 1.5%. henceforthrefer document representation bag-of-words (BOW) representation.4.1.3 Spectral Learning SetupFollowing common practice spectral learning text domains (e.g., Kamvar, Klein,& Manning, 2003; Cai et al., 2005), compute similarity two reviewstaking dot product feature vectors. Ng et al.s (2001) spectral clusteringalgorithm, set diagonal entries similarity matrix 0. addition, set5. words, consider second fifth eigenvectors, assumingsufficient capturing desired clusterings.104.1.4 Evaluation Metricsemploy two evaluation metrics. First, report results dataset termsaccuracy, percentage documents label assigned systemgold-standard label. Second, following Kamvar et al. (2003), evaluateclusters produced approach gold-standard clusters using AdjustedRand Index (ARI), corrected-for-chance version Rand Index.specifically, given set N data points two clusterings points, U V ,10. Note setting 5 somewhat arbitrary choice, number eigenvectorsused active clustering algorithm.592fiInducing Ideal Clustering Minimal FeedbackU = {U1 , U2 , . . . , Um } clusters V = {V1 , V2 , . . . , Vn } n clusters, ARIcomputed follows:nij2P bjP[ a2ij 2 ]/ARI(U, V ) = 1 P P bPai Pjj 2 ][ 2j2[ 2 +PijN2bjN2 ]/ 2formula, nij number common objects Ui Vj ; whereas ai bjnumber objects Ui Vj , respectively. ARI ranges 1 1; better clusteringshigher ARI values.4.2 Baseline Systemssubsection, describe baseline results. first two baseline systemsones described Section 2.3, last two arguably sophisticated clusteringalgorithms employed attempt strengthen baseline results.4.2.1 Clustering Using Second Eigenvectorfirst baseline, adopt Shi Maliks (2000) approach cluster reviewsusing second eigenvector, e2 , described Section 2.3. Results POLsentiment datasets, expressed terms accuracy ARI, shown row 1 Tables 2a2b, respectively. Owing randomness choice seeds 2-means,experimental results involving 2-means averaged ten independent runs.11see, baseline achieves accuracy 93.7% POL, much loweraccuracies (of 5070%) sentiment datasets. performance trendobserved ARI. results provide suggestive evidence producing sentimentbased clustering requires different features producing topic-based clustering,many cases, salient features tend topic-based. differencesentiment-based clustering topic-based clustering illuminatedexperiments Section 4.7.addition, worth noting baseline achieves much lower accuraciesARI values BOO, DVD, ELE remaining two sentiment datasets. Sincee2 captures prominent dimension, results suggest sentiment dimensionprominent dimension three datasets. fact, intuitivelyplausible. instance, book domain, positive book reviews typically containshort description content, reviewer briefly expressing sentimentsomewhere review. Similarly electronics domain: electronic product reviewstypically aspect-oriented, reviewer talking pros consaspect product (e.g., battery, durability). Since reviews likely containpositive negative sentiment-bearing words, sentiment-based clustering unlikelycaptured e2 .11. Note clustering one-dimensional space (as baseline) yields stable results regardlesschoice seeds: results ten runs exhibit nearly zero variance.593fiDasgupta & NgSystem Variation2nd eigenvectorTop five eigenvectorsInterested Reader ModelNMFsystemPOL93.795.998.770.393.7MOV70.958.961.871.370.9AccuracyKIT BOO69.7 58.964.0 59.962.2 52.566.9 52.169.7 69.5DVD55.360.450.650.370.8ELE50.863.850.263.865.8(ARI)DVD0.010.030.010.010.17ELE0.010.070.010.080.10(a)System Variation2nd eigenvectorTop five eigenvectorsInterested Reader ModelNMFsystemPOL0.760.840.940.160.76Adjusted Rand IndexMOV KIT BOO0.17 0.15 0.030.030.05 0.040.050.06 0.010.18 0.11 0.010.17 0.15 0.15(b)Table 2: Results terms (a) accuracy (b) Adjusted Rand Index six datasetsobtained using bag-of-words document representation. strongest result(s)dataset boldfaced.4.2.2 Clustering Using Top Five Eigenvectorssecond baseline, represent data point using top five eigenvectors (i.e., e1e5 ), cluster using 2-means five-dimensional space, describedSection 2.3. Hence, thought ensemble approach, clusteringdecision collectively made five eigenvectors.12Results shown row 2 Tables 2a 2b.13 comparison first baseline,see improvements accuracy ARI POL three sentiment datasetsfirst baseline performs poorly (i.e., BOO, DVD, ELE), drasticimprovement observed ELE. However, performance remaining two sentimentdatasets deteriorates. results attributed fact BOO, DVD,ELE, e2 capture sentiment dimension, since eigenvectorensemble does, see improvements. hand, e2 already capturedsentiment dimension MOV KIT; result, employing additional dimensions,may sentiment-related, may introduce noise computationsimilarities reviews.12. first eigenvector produce trivial clustering data points residecluster, commonly used combination top eigenvectors create low-dimensionalspace data points clustered. See work Ng et al. (2001) details.13. clustering five-dimensional space, observe results highly sensitivechoice seeds. instance, variances accuracy observed ten runs POL, MOV,KIT, BOO, DVD, ELE 0, 2.38, 19.90, 24.70, 12.76, 4.43, respectively.594fiInducing Ideal Clustering Minimal Feedback4.2.3 Clustering Using Interested Reader Modelthird baseline Kamvar et al.s (2003) unsupervised clustering algorithm, which, according authors, ideally suited text clustering, recently provedspecial case ratio-cut optimization (Kulis, Basu, Dhillon, & Mooney, 2009). Specifically, introduce new Laplacian inspired Interested Reader Model.Laplacian computed (S + dmax D)/dmax , defined Section2.1, except Si,j =0 one js k nearest neighbors j one knearest neighbors; dmax maximum rowsum S; identity matrix. Sinceperformance highly sensitive k, tested values 10, 15, . . ., 500 k report row 3 Tables 2a 2b best results. Somewhat disappointingly, despitealgorithmic sophistication fact reporting best results, baselineoffer consistent improvements previous two. comparison firstbaseline, achieves better performance POL worse performance sentimentdatasets. Like first baseline, results BOO, DVD ELE particularly poor.4.2.4 Clustering Using Non-Negative Matrix FactorizationNon-negative matrix factorization (NMF) recently shown Xu, Liu, Gong(2003) effective document clustering. re-implementing algorithm,evaluate six datasets.14 Shown row 4 Tables 2a 2b best results obtained running algorithm five times. comparison first baseline,NMF achieves better performance ELE, comparable performance MOV, worseperformance remaining datasets.4.3 Active Clustering Algorithmsubsection, describe human automatic experiments evaluating activeclustering algorithm.4.3.1 Human ExperimentsUnlike four baselines, active clustering algorithm requires users specifyfour dimensions (defined second fifth eigenvectors) closelyrelated sentiment inspecting set features derived unambiguous reviewsdimension using MMFR. better understand easy human selectdesired dimension given features, performed experiment independentlyfive humans (all computer science graduate students affiliatedresearch) computed agreement rate.Specifically, dataset, showed human judge top 100 featurescluster according MMFR (see Tables 38 subset 100 features inducedsix datasets, lightly shared columns correspond sentimentdimension selected majority human judges).15 addition, informed14. matrix factorization use code downloaded http://www.csie.ntu.edu.tw/cjlin/nmf/index.html.15. human judges reported inspecting top 100 features sufficient identifyingsentiment dimension, note user clustering algorithm may request inspect manyfeatures wants.595fiDasgupta & Nge2C1serderarmenianturkeyarmeniansmuslimssdpaargicdavidiandbd@uratroopsC2sternlightpgpcryptoalgorithmlikelyaccessideacryptographPOLe3e4C1C1beyerserbsarabspalestiniansandimuslimsresearchwrongisraelisdepartmenttimbosniauciliveabmatterz@virginiafreedomholocaustpoliticsC2escrowsternlightalgorithmaccessnetdesprivacyuksystemspgpC2standardsternlightdesescrowemployernetyorkjakecodealgorithme5C1escrowserialalgorithmchipsensurecarestrongpoliceomissionsexceptedC2internetuucpuknetquoteaccoaimitTable 3: Top ten features induced dimension POL domain. shadedcolumns correspond dimensions selected human judges. e2 , . . ., e5 top eigenvectors; C1 C2 clusters.596fiInducing Ideal Clustering Minimal Feedbacke2C1relationshipsontalehusbandperfectdramafocusstrongbeautifulnatureC2worststupidwastebunchvideoworseboringguessanywayMOVe3e4C1C1productionjokesearthkidssequenceslivealiensanimationwardisneycrewanimatedalienlaughsplanetproductionhorrorvoiceevilhilariousC2sexromanticschoolrelationshipfriendsjokeslaughssexualcutemotherC2thrillerkillermurdercrimepolicecardeadkilledstartsviolencee5C1startspersonsawfeelinglivestoldhappenfelthappenedC2comicsequencesmichaelsupportingcareerproductionpeterstylelatestentertainingTable 4: Top ten features induced dimension MOV domain. shadedcolumns correspond dimensions selected human judges. e2 , . . ., e5 top eigenvectors; C1 C2 clusters.597fiDasgupta & NgBOOe2C1historymustmodernimportanttextreferenceexcellentprovidesbusinesse3C1seriesmanhistorycharacterdeathwarseemspoliticalamericane4C1lovedhighlyeasyenjoyedchildrenalthoughexcellentunderstandthreee5C1mustwonderfuloldfeelawaychildrenyearsomeonemanmadeC2plotthoughtboringgotcharacterendingfanC2buyboughtinformationeasymoneyrecipespictureslookwastecopyC2moneybadnothingwastebuyanythingalreadyinsteadseemsC2boringserieshistorypagesinformationhighlypageexcellentTable 5: Top ten features induced dimension BOO domain. shadedcolumns correspond dimensions selected human judges. e2 , . . ., e5 top eigenvectors; C1 C2 clusters.598fiInducing Ideal Clustering Minimal FeedbackELEe2C1mousecablecablescaseredmonsterpicturekitoverallpaide3C1musicreallyipodlittleheadphoneshardexcellentneedfite4C1easyusedcardfineusingproblemsfinedrivecomputerinstalle5C1amazoncablecardrecommenddvdcamerafastfarprinterpictureC2workingneverphonedaysheadsetmoneymonthsreturnsecondC2workedproblemneveritemamazonworkingsupportmonthsreturnedanotherC2moneyworthamazonreturnyearsmuchheadphonessonyreceivedC2phoneworkedpowerbatteryunitsetphonesrangelittleTable 6: Top ten features induced dimension ELE domain. shadedcolumns correspond dimensions selected human judges. e2 , . . ., e5 top eigenvectors; C1 C2 clusters.599fiDasgupta & Nge2C1lovecleannicesizesetkitcheneasilysturdyrecommendpriceC2monthsstillbackneverworkedmoneyamazonreturnmachineKITe3e4C1C1worksreallywaternicecleanworksworkicequalitymakessmallthingsturdyneedlittlekeepthinkbestitemC2priceitemsetorderedamazongiftgotqualityreceivedknivesC2yearslovenevercleanmonthspanpanse5C1panovencookingmadepansbetterheatcookusingcleanC2lovecoffeerecommendmakessizelittlemakercupTable 7: Top ten features induced dimension KIT domain. shadedcolumns correspond dimensions selected human judges. e2 , . . ., e5 top eigenvectors; C1 C2 clusters.600fiInducing Ideal Clustering Minimal Feedbacke2C1worthboughtseriesmoneyseasonfancollectionmusictvthoughtC2youngactorsmencastseemsjobbeautifularounddirectorDVDe3e4C1C1musicvideocollectionmusicexcellentfoundwonderfulfeelmustboughtlovedworkoutperfectdaughterhighlyrecommendmakesspecialdisappointedC2worstmoneythoughtboringnothingminuteswastesawprettyreviewsC2seriescastfanstarsoriginalcomedyactorsworthclassicactione5C1moneyqualityvideoworthfoundversionpicturewastespecialsoundC2sawwatchedlovedenjoywholegotfamilyseriesseasonlikedTable 8: Top ten features induced dimension DVD domain. shadedcolumns correspond dimensions selected human judges. e2 , . . ., e5 top eigenvectors; C1 C2 clusters.601fiDasgupta & NgJudge12345AgreementPOL2,3,42,442,3280%MOV222,422100%KIT2242280%BOO44444100%DVD33333100%ELE3333,43100%Table 9: Human agreement rate. Also shown eigenvectors selected five judges.intended dimension: example, POL, judge told intendedclustering Politics vs. Science. Also, determined one dimensionrelevant intended clustering, instructed rank dimensionsterms relevance, relevant one would appear first list.dimensions (expressed terms IDs eigenvectors) selectedfive judges dataset shown Table 9. agreement rate (shownlast row table) computed based highest-ranked dimension selectedjudge. see, perfect agreement achieved four five sentimentdatasets, remaining two datasets, near-perfect agreement achieved.results, together fact took five six minutes identify relevantdimension, indicate asking human determine intended dimension basedsolely informative features viable task.4.3.2 Clustering ResultsNext, cluster 2000 documents dataset using dimension selectedmajority human judges. clustering results shown row 5 Tables 2a2b. comparison best baseline dataset, see algorithmperforms substantially better BOO, DVD ELE, almost level MOVKIT, slightly worse POL. Note improvements observed BOO, DVDELE attributed failure e2 capture sentiment dimension. Perhapsimportantly, exploiting human feedback, algorithm achieved stableperformance across datasets four baselines.164.3.3 Identification Unambiguous DocumentsRecall features largest MMFR computed unambiguousdocuments only. get idea accurate algorithm identifying unambiguousdocuments is, show Table 10 accuracy obtained unambiguous documentsdataset clustered using eigenvector selected majority judges.see, accuracy dataset higher corresponding accuracyshown row 5 Table 2a. fact, accuracy 85% achieved16. first baseline, since clustering one-dimensional space here, resultssensitive choice seeds, yielding zero variance ten independent runs.602fiInducing Ideal Clustering Minimal FeedbackAccuracyPOL99.8MOV87.0KIT87.6BOO86.2DVD87.4ELE77.6Table 10: Accuracies unambiguous documents.# labelsPOL400MOV150KIT200BOO350DVD350ELE200Table 11: Transductive SVM results.one dataset. suggests method identifying unambiguous documentsreasonably accurate.Note crucial able achieve high accuracy unambiguous documents: clustering accuracy low, features induced clusters mayaccurate representation corresponding dimension, human judge maydifficult time identifying intended dimension. fact, human judges reported difficulty identifying correct dimension ELE dataset, attributedpart low accuracy achieved unambiguous documents.4.3.4 User Feedback Versus Labeled DataRecall four baselines unsupervised, whereas algorithm characterizedsemi-supervised, relies user feedback select intended dimension. Hence,surprising see average clustering performance algorithmbetter baselines.fairer comparison, conduct another experiment comparealgorithm semi-supervised sentiment classification system, uses transductive SVM underlying semi-supervised learner. specifically, goalexperiment determine many labeled documents needed order transductive learner achieve level performance algorithm. answerquestion, first give transductive learner access 2000 documentsdataset unlabeled data. Next, randomly sample 50 unlabeled documents assigntrue label. re-train classifier compute accuracy 2000documents. keep adding labeled data (50 iteration) reachesaccuracy achieved algorithm. Results experiment shown Table 11.Owing randomness involved selection unlabeled documents, resultsaveraged ten independent runs. see, user feedback equivalenteffort hand-annotating 275 documents per dataset average.4.3.5 Multiple Relevant Eigenvectorsseen Table 9, human judges selected one eigenvectordatasets (e.g., {2,3,4} POL; {2,4} MOV; {3,4} ELE). However, never tookaccount extra eigenvectors previous experiments. better understand603fiDasgupta & NgsystemPOLAcc ARI95.9 0.84MOVAcc ARI69.1 0.16ELEAcc ARI65.1 0.10Table 12: Results obtained using multiple relevant eigenvectors POL, MOVELE datasets.AccuracyPOL99.3MOV86.1KIT81.7BOO79.3DVD77.6ELE80.6Table 13: Supervised classification accuracies.whether extra eigenvectors help improve accuracy ARI, conduct anotherexperiment apply 2-means cluster documents space definedselected eigenvectors. Table 12 shows accuracy ARI results averagedten independent runs. see, results POL considerably betterobtained highest-ranked eigenvector used, suggestingextra eigenvectors contain useful information. However, results MOV ELE dropslightly addition extra eigenvectors, indicating extra sentimentdimensions useful.4.3.6 Supervised Classification ResultsNext, present results supervised classification five sentiment datasets.one expect largely unsupervised approach offer comparable performancefully-supervised approach, believe fully-supervised results enablereader get sense work stands among existing work identifyingsentiment datasets. Specifically, report Table 13 averaged 10-fold crossvalidation accuracies, SVM classifier trained nine folds testedremaining fold fold experiment. see, results lag behind supervisedresults 8.115.2% datasets.4.4 Alternative Document Representationsexperiments, represented document bag wordsfrequent 1.5% words removed. is, course, way representdocument. subsection, examine two alternative document representationsattempt better understand effect document representation classification results.first document representation, represent document using unigramsappear remove frequent words document vector.bag-of-all-words (BOAW) representation motivated fact frequenciesfunction words like shown many studies useful features various kinds non-topic-based classification (e.g., Finn & Kushmerick, 2006; Stein, Argamon,& Frieder, 2006; Abbasi, Chen, & Salem, 2008; Koppel, Schler, & Argamon, 2009).604fiInducing Ideal Clustering Minimal FeedbackSystem Variation2nd eigenvectorTop five eigenvectorsInterested Reader ModelNMFsystemPOL70.694.761.259.284.3MOV54.360.661.154.665.9AccuracyKIT BOO51.6 52.458.0 56.157.8 52.450.8 50.164.8 60.1DVD51.253.750.452.958.6ELE53.157.150.351.464.1(a)System Variation2nd eigenvectorTop five eigenvectorsInterested Reader ModelNMFsystemPOL0.170.800.050.030.47Adjusted Rand Index (ARI)MOV KITBOO DVD0.010.010.010.010.040.030.010.010.050.020.010.010.01 0.01 0.01 0.010.100.090.04 0.03ELE0.010.030.010.010.08(b)Table 14: Results terms (a) accuracy (b) Adjusted Rand Index six datasetsobtained using bag-of-all-words document representation. strongest result(s)dataset boldfaced.accuracy ARI results obtained re-running four baselines well systemusing document representation shown Tables 14a 14b, respectively. Comparing Tables 2a 14a, see words used features, bestaccuracy achieved dataset drops 311% high-frequency wordsremoved spectral clustering applied. Similar trends observed ARIresults shown Tables 2b 14b. Overall, results substantiate hypothesisretaining high-frequency words document representation adverse effectperformance clustering algorithms.Next, experiment another representation, specifically one document represented using sentiment-bearing words contains. understandmotivation behind bag-of-sentiment-words (BOSW) representation, recall introduction one way encourage clustering algorithm produce user-desiredclustering design feature space contains featuresuseful producing user-desired clustering. Since desire sentiment-based clustering, design feature space composed solely sentiment-bearing words. Sincehand-crafted subjectivity lexicon (i.e., lexicon word manually labeledprior polarity17 ) English readily available, automatically construct featurespace consists words (positive negative) polarity accordingsubjectivity lexicon, represent document using resulting feature space.17. prior polarity word polarity computed without regard context wordappears.605fiDasgupta & NgSystem Variation2nd eigenvectorTop five eigenvectorsInterested Reader ModelNMFsystemMOV69.160.754.668.869.1KIT62.357.950.359.062.3AccuracyBOO DVD60.2 61.457.663.154.456.059.2 63.360.2 61.4ELE63.962.750.660.563.9(a)System Variation2nd eigenvectorTop five eigenvectorsInterested Reader ModelNMFsystemAdjusted Rand Index (ARI)MOV KIT BOO DVD ELE0.15 0.06 0.04 0.05 0.080.040.03 0.03 0.07 0.060.010.01 0.010.01 0.010.140.03 0.03 0.07 0.040.15 0.06 0.04 0.05 0.08(b)Table 15: Results terms (a) accuracy (b) Adjusted Rand Index fivesentiment datasets obtained using bag-of-sentiment-words document representation.strongest result(s) dataset boldfaced.goal, then, determine whether BOSW document representation improvesentiment-based clustering results obtained using BOW representation.identify sentiment-bearing words experiment, employ subjectivity lexicon introduced work Wilson, Wiebe, Hoffmann (2005).18 lexicon contains8221 words, hand-labeled prior polarity Positive, Negative,Neutral. create new subjectivity lexicon L retain wordsWilson et al.s lexicon either Positive Negative polarity. BOSWrepresentation document composed words appearL document.accuracy ARI results baselines system obtained employingBOSW representation shown Tables 15a 15b, respectively. Consider firstsecond eigenvector baseline, NMF, Interested Reader Model. comparisoncorresponding results Tables 2a 2b, BOW representationused, see performance improves BOO, DVD, ELE datasetscases, drops MOV KIT datasets. top five eigenvectors baseline,performance increases DVD slightly MOV, drops remaining datasets.Finally, using BOSW representation causes performance system dropdatasets.Overall, results seem suggest whether BOSW representation document yields better clustering results BOW representation rather dependentunderlying domain clustering algorithm. Nevertheless, see best18. See http://www.cs.pitt.edu/mpqa/.606fiInducing Ideal Clustering Minimal Feedbackclustering accuracy/ARI achieved sentiment dataset using BOSW representation significantly lower obtained using BOW representation. speculatetwo reasons poorer results. First, general-purpose subjectivity lexiconcover sentiment-bearing words. particular, words sentiment-orientedcontext particular domain neutral polarity otherwise may omitted BOSW document representation. Second, non-sentiment-bearing wordsmight useful identifying sentiment.4.5 Domain Adaptationmentioned introduction, majority existing approaches sentiment classification supervised. One weakness supervised approaches givennew domain, one needs go expensive process collecting large amountannotated data order train accurate polarity classifier.19 One may argueactive clustering algorithm suffers weakness: user needs identifysentiment dimension domain. One way address weakness domainadaptation. Specifically, investigate whether sentiment dimension manually identified one domain (henceforth source domain) used automatically identifysentiment dimension new domain (henceforth target domain). hypothesizedomain adaptation feasible, especially two domains sentimentally similar (i.e., significant overlap features characterize sentimentdimensions two domains).result, propose following method automatically identifying sentimentdimension target domain, y, using sentiment dimension manually identifiedsource domain, x. Assume sentiment dimension domain x definedxxeigenvector ex . Moreover, assume C1e C2e two vectors top-rankedfeatures (obtained using MMFR) characterize two clusters induced ex (with 100features cluster). Now, given target domain y, first compute similarityex ys top eigenvectors, ey2 , . . ., ey5 , similarity twoeigenvectors ex ey definedxxxxmax((C1e , C1e ) + (C2e , C2e ), (C1e , C2e ) + (C2e , C1e ))Here, similarity function computes similarity two feature vectors.experiments, simply set dot product, allows us capturedegree overlap two feature vectors. Then, posit eigenvector{ey2 , . . . , ey5 } highest overlap one defines sentiment dimension.20determine effectiveness method, compare automatically selectedeigenvector human-selected eigenvector domain. Results shownTable 16, row column j indicates sentiment dimensiontarget domain j successfully identified using sentiment dimension manually19. collecting annotated data trivial dealing review data, necessarilytrue kinds data. instance, people express opinions sentiment political blogsfloor debates, associated postings transcripts may explicitly annotatedsentiment labels.20. Note two arguments max function correspond two different ways creatingmapping feature vectors two domains.607fiDasgupta & NgDomainMOVDVDBOOELEKITMOVNNNDVDNBOONNNELENNNKITNTable 16: Domain adaptation results.identified source domain i, N indicates failure. instance, knowsentiment dimension DVD domain (through human feedback), domainadaptation method used correctly identify sentiment domain MOVvice versa. However, domain adaptation using method always successful.instance, knowing sentiment dimension MOV allow us correctly predictsentiment dimension ELE. Interestingly, ignore BOO/KIT pair, domainadaptation exhibits symmetry. symmetry, mean domain x usedidentify correct sentiment dimension domain y, domain usedidentify correct sentiment dimension domain x. intuitively makes sense:x successfully used identify sentiment dimension y, likelytwo domains share lot sentiment words. Consequently, using adapt x alsolikely successful. BOO/KIT pair represents case domain adaptationsuccessful one direction: domain adaptation successful BOO KIT,similarity sentiment dimensions two domains high (seediscussion next paragraph details), contributes failure adaptationdirection.mentioned beginning subsection, hypothesize domain adaptation likely successful two domains consideration similarother. test hypothesis, show Table 17a similarity manuallyidentified eigenvector corresponding automatically identified eigenvectorpair domains. Three points deserve mention. First, long similarity valueleast 14, domain adaptation successful; also, long similarity value 6,domain adaptation unsuccessful. Hence, results substantiate hypothesisdomain adaptation likely successful two domains considerationsimilar other. would interesting see two thresholdsused predict whether domain adaptation successful given new pair domains.Second, domain adaptation directions likely successful similarityvalue sufficiently high. mentioned before, similarity value high,two domains share many sentiment words common, may turn contributesuccessful domain adaptation directions. five domains considering,long similarity value least 14, domain adaptation directionssuccessful. Third, worth reiterating even similarity value fallsthreshold, imply domain adaptation fail. mentioned before,sentiment dimension domain (correctly) identified long similarity608fiInducing Ideal Clustering Minimal FeedbackDomainMOVDVDBOOELEKITMOV14(6)(3)(1)DVD1421(8)10BOO(6)21(6)(11)ELE(2)(10)(10)32KIT(3)10832BOO(4)13(5)(8)ELE(2)(9)(6)27KIT(3)7623BOO(2)8(1)(3)ELE(0)(1)(4)5KIT(0)329(a)DomainMOVDVDBOOELEKITMOV5(4)(2)(1)DVD1014(8)7(b)DomainMOVDVDBOOELEKITMOV9(2)(0)(1)DVD47(0)3(c)Table 17: Similarity results domain adaptation. (a) shows similaritysentiment eigenvector source domain eigenvector similar targetdomain. (b) shows similarity sentiment eigenvector source domainsecond similar eigenvector target domain. (c) shows similarity gap,difference corresponding entries (a) (b).sentiment dimension domain x highest among four eigenvectors y,case BOO/KIT domain pair.far attempted correlate success domain adaptation similarity manually selected eigenvector source domain eigenvectorsimilar target domain. may worth also consider similaritymanually selected eigenvector second similar eigenvectortarget domain, gap similarity may give indication success domain adaptation. determine whether better correlation successdomain adaptation similarity gap, compute (1) similarityeigenvector manually selected source domain second similar eigenvectortarget domain (see Table 17b) well (2) similarity gap (see Table 17c),simply difference corresponding entries Tables 17a 17b.see Table 17c, also appears correlation successdomain adaptation gap values. particular, gap value least 5, domain609fiDasgupta & Ngadaptation successful; however, gap value 1, domain adaptation unsuccessful. Nevertheless, gap values help predict domain pairssuccess domain adaptation cannot predicted using similarity values Table 17a(e.g., domain pairs low similarity yet domain-adaptable). Moreover,fail predict success domain adaptation many domain pairs, specificallygap value 1 5.4.6 Subjectivity Lexicon versus Human FeedbackOne might argue access subjectivity lexicon, could use automatically identify right sentiment dimension, thus obviating need human feedbackaltogether. subsection, investigate whether indeed feasible use handbuilt general-purpose sentiment lexicon identify eigenvector correspondssentiment dimension new domain.experiment, use subjectivity lexicon L described Section 4.4.mentioned before, L contains words Wilson et al.s (2005) subjectivitylexicon marked prior polarity Positive Negative. procedureautomatically identifying sentiment dimension using L similar one describeddomain adaptation section: second fifth eigenvectors, firstcompute similarity eigenvector L, choose eigenvectorhighest similarity L. domain adaptation, compute similarityL eigenvector exxxxxmax((C1L , C1e ) + (C2L , C2e ), (C1L , C2e ) + (C2L , C1e ))C1L C2L represent words L labeled positive negative rexxspectively, C1e C2e top-ranked features (obtained using MMFR)characterize two clusters induced ex (with 100 features cluster). similarity function computes similarity two feature vectors. domainadaptation, simply set dot product.results indicate successfully identified right eigenvector using Lfive domains. Note L general-purpose (i.e., domain-independent)lexicon containing generic sentiment-bearing words, good enough identifycorrect sentiment dimension five different domains. worth noting sentimentdimension MOV domain highest similarity L (i.e., 34) fivedomains, suggesting highest-ranked sentiment features MOV domain (according MMFR) largely generic. DVD second largest similarity L (33),followed BOO (26), KIT (16) ELE (16). comparatively low similarity valuesKIT ELE indicative fact highest-ranked sentiment featureslargely domain-specific.Finally, although subjectivity lexicon obviates need human feedback,emphasize undermine contribution feedback-oriented clusteringtechnique, following reasons. First, thinking text mining perspective, wouldgood approach knowledge-free possible. Employing handcrafted subjectivity lexicon makes system resource-dependent; fact, subjectivitylexicon may readily available vast majority natural languages. Second,610fiInducing Ideal Clustering Minimal Feedbackwant method potentially applicable non-sentiment domains (e.g., spam vs.spam), faced problem hand-built lexicon mayavailable.4.7 Single Data, Multiple Clusteringsmentioned previously, set documents clustered along different dimensions.example, movie reviews clustered sentiment (positive vs. negative) genre(e.g., action, romantic documentary). natural question is: produce differentclusterings given set documents, corresponds different dimension?vast majority existing text clustering algorithms, answer no:cluster along exactly one dimension, typically prominent dimension.hand, since algorithm induces important clustering dimensionsdataset, principle used produce (distinct) clustering,hypothesize generate multiple clusterings given dataset along importantdimensions.test claim algorithm produce multiple clusterings, evaluatefour datasets possess multiple clustering dimensions, namely MOV-DVD, BOODVD, DVD-ELE, MOV-KIT.21 example, BOO-DVD dataset consistsreviews taken BOO DVD domains. Hence, augmented datasetcomposed 4000 reviews (2000 two contributing domains),clustered according either topic (e.g., Book vs. DVD) sentiment.22 Notefour pairs domains used create augmented datasets chosen carefully.Specifically, two augmented datasets (MOV-DVD BOO-DVD) createdconstituent domains mutually domain-adaptable according Table 16,remaining two (DVD-ELE MOV-KIT) created constituent domainsdomain-adaptable. goal see whether active clustering algorithm ableproduce topic- sentiment-based clusterings datasets different levelssentimental similarity.clustering procedure almost identical one described Section 3. essence,(1) compute top five eigenvectors Laplacian matrix; (2) learn top-rankedfeatures corresponding e2 e5 according MMFR; (3) ask human judgesidentify eigenvectors corresponding topic dimension sentimentdimension; (4) use 2-means produce two clusterings reviews, one accordingselected topic dimension selected sentiment dimension.Section 4.3, conducted human automatic experiments determine viabilityalgorithm.21. reason employing augmented datasets obviate needadditional human annotations, also guarantee least two dimensions alongclusters formed, thus allowing us directly test ability produce multiple clusterings.also possible evaluate algorithms ability generate multiple clusterings using MOVdataset (by clustering along genre sentiment), decided leave future investigation, sincedocuments MOV annotated genre information.22. confused topic-sentiment mixture models (Mei, Ling, Wondra, Su, & Zhai, 2007),goal first use topic models mine major aspects product online reviewassign ratings extracted aspect. hand, goal design clusteringalgorithm capable generating multiple clusterings dataset.611fiDasgupta & NgJudge12345AgreementMOV-DVD22222100%BOO-DVD22222100%DVD-ELE22222100%MOV-KIT22222100%DVD-ELE33,55,33380%MOV-KIT33,535380%(a)Judge12345AgreementMOV-DVD33,43,433100%BOO-DVD4,54,54,54,54,5100%(b)Table 18: Human agreement rate selecting (a) topic dimension (b) sentimentdimension augmented datasets. Also shown eigenvectors selectedhuman judges.4.7.1 Human Experimentsemployed five human judges involved human experiments Section 4.3independently determine topic dimension sentiment dimensionfour augmented datasets using top features according MMFR. before,human judge identifies one relevant eigenvector particular dimension,ask rank eigenvectors according relevance. Finally, take topic/sentimentdimension ranked first largest number judges human-selectedtopic/sentiment dimension.Tables 18a 18b show respectively topic sentiment dimensions (expressedterms IDs eigenvectors) selected five judges augmenteddataset. Also shown tables human agreement rate, computedbased highest-ranked dimension selected judge. Several pointshuman experiments deserve mention.First, dataset, human judges managed find one eigenvector (outtop five) corresponds topic least one eigenvector correspondssentiment. Perhaps importantly, human agreement rate least 80%achieved four datasets respect selecting eigenvector(s) correspondtopic sentiment dimensions. results together provide suggestive evidence(1) eigen-decomposition procedure active clustering algorithm effectiveenough unearth topic sentiment dimensions present612fiInducing Ideal Clustering Minimal Feedbackdataset, (2) proposal incorporating user feedback via inspecting smallnumber features viable.Second, topic sentiment prominent dimensions datasets,fact second eigenvector captures topic dimension four datasets suggeststopic prominent dimension sentiment. fact, human judgesreported topic dimension identified quite easily, achieving perfect agreementidentifying topic dimension. provides empirical evidence speculationtopic typically (though always) prominent dimension sentimentdimensions exist dataset.Third, reasonably high human agreement rate identifying sentiment dimension achieved (perfect agreement two datasets 80% agreement rateremaining two; see Table 18b details), human judges reported difficult identify sentiment dimension(s), especially two datasets composedsentimentally dissimilar domains.attempt gain insight judges found difficult identifysentiment dimension(s), show Tables 1922 top-ranked features induceddimension using MMFR four augmented datasets, lightly shaded columnscorrespond eigenvectors chosen topic dimension darkly shaded columnscorrespond eigenvectors chosen sentiment dimension. examiningresults, believe points deserve mention.First, top features generated sentiment eigenvector(s) MOV-DVDBOO-DVD, two datasets composed sentimentally similar constituent domains,clearly sentiment-oriented, making relatively easy human judges determinesentiment eigenvector(s). case DVD-ELE MOV-KIT, two datasetscomposed dissimilar domains, top features noisier (i.e., manynecessarily sentiment-oriented), thus making tougher judges locatesentiment eigenvector(s). fact, one see top features generatedsentiment eigenvector(s) Tables 1922 MOV-DVD BOO-DVDclearly sentiment-oriented DVD-ELE MOV-KIT.surprising sentimentally dissimilar constituent domains are, noisier top features generated sentiment eigenvector(s) are,however. constituent domains sentimentally similar, tend manysentiment-bearing words common. implies sentiment-bearing wordsappear frequently augmented datasets constituent datasets.Hence, combining two domains helps boost influence sentiment-bearingwords, increasing chance appearing higher list features rankedMMFR. reinforcement effect intuitively explains sentiment eigenvectorclearly dominated sentiment words datasets composed sentimentally similar domains. hand, constituent domains sentimentally dissimilar, tendmany sentiment-bearing words common. result, influencesentiment-bearing words present one two constituent domainsdiluted larger number non-sentiment-bearing words result combiningtwo domains. words, features clearly sentiment-orientedone rather domains may longer appear sufficiently high ranked listfeatures. fact, saw Tables 21 22, sentiment eigenvector contaminated613fiDasgupta & Nge2C1rolesdramamurdermeetscrimesupportinginvolvingconvincingtaleleadC2boughtseasonbuydisappointedfanamazonbuyingcopydvdswatchedMOV-DVDe3e4C1C1wonderful recommendexcellentfanbeautifullikedpersonalbookcollectionreadviewexcellentartamazinghighlydefinitelyfantastichighlydealabsolutelyC2stupidboringdullmeanterriblesavelamerunguysexceptC2buyhouserentwastewaitkillmurderobviousseasondvdse5C1kidschildrenlovedchildsondaughterboyschoolwonderfulheartC2qualitydarkwarhorrorreleasefanearthproductionsuspensesoundTable 19: Top ten features induced dimension MOV-DVD domain.lightly darkly shaded columns correspond topic sentiment dimensions respectivelyselected human judges. e2 , . . ., e5 top eigenvectors; C1 C2 clusters.614fiInducing Ideal Clustering Minimal Feedbacke2C1readerimportantsubjectunderstandingmoderninformationexamplespoliticalbusinessnatureC2sawwatchedactorslikedmusicseasonhumorcomedyfavoriteendingBOO-DVDe3e4C1C1boughtexcellentdisappointed wonderfuleasyhighlyinformation collectionpricemusicwastespecialworkoutclassichelpfulvideoexpectedperfectreviewsamazinge5C1lovedenjoyedchildrenyearwonderfulchildfunsonfriendshighlyC2youngmencastroleactorsscriptscenewarperformanceactionC2versionqualitywasteworstrevieworiginaleditioncollectionamazonformatC2boringendingwastereviewsnovelmaybepagesstupidfinishTable 20: Top ten features induced dimension BOO-DVD domain.lightly darkly shaded columns correspond topic sentiment dimensions respectivelyselected human judges. e2 , . . ., e5 top eigenvectors; C1 C2 clusters.615fiDasgupta & Nge2C1funnyactingfamilyactorsactionplotenjoyyoungwonderfulcomedyC2unitbatterypurchaseddeviceproblemstriedworkingplugchargecomputerDVD-ELEe3e4C1C1easyfinesmallproblemsperfectworkedexcellentmonthshighlyeasyniceworkinglowcomputercomfortabledayipodcardheadphonesdriveC2amazonitemreviewcompanyreturntookchecksawcardworkedC2amazontvpurchasedisappointeditempurchasedreviewswantedreceivedipode5C1videocardcamerafasteasycablepicturepicturespaperdigitalC2phonewasteunitbatterygettinglowpowerhearworstbatteriesTable 21: Top ten features induced dimension DVD-ELE domain.lightly darkly shaded columns correspond topic sentiment dimensions respectivelyselected human judges. e2 , . . ., e5 top eigenvectors; C1 C2 clusters.616fiInducing Ideal Clustering Minimal Feedbacke2C1jamesdirectedsexhourdramarelationshipdeathdirectiontvmichaelC2foodrecommendpotpurchasedminekitchenmixerhandlesizestoreMOV-KITe3e4C1C1pancoffeecookingcleancleanmachinepansicecookmakerheatplasticovencupheavyfillfoodmonthsstickworkingC2monthspurchasedworkedbrokeamazoncoffeereplacementmonthtriedserviceC2itempricesheetsorderedamazonreceivedbeautifuldishesarrivedsetse5C1pricecleankitchenknifeknivessizesharpdishwashercuttingattractiveC2pantoasterovenpansheatreturnbottomworkedreadtoastTable 22: Top ten features induced dimension MOV-KIT domain.lightly darkly shaded columns correspond topic sentiment dimensions respectivelyselected human judges. e2 , . . ., e5 top eigenvectors; C1 C2 clusters.617fiDasgupta & Ng2nd eigenvectorTop five eigenvectorsInterested Reader ModelNMFsystemMOV-DVDAcc ARI77.1 0.2962.4 0.0884.2 0.5356.3 0.0277.1 0.29BOO-DVDAcc ARI77.8 0.3177.2 0.3163.1 0.0769.2 0.1577.8 0.31DVD-ELEAcc ARI94.2 0.7893.9 0.7894.8 0.8094.4 0.7994.2 0.78MOV-KITAcc ARI99.3 0.9799.3 0.9799.6 0.9970.6 0.1799.3 0.97DVD-ELEAcc ARI50.9 0.0050.4 0.0050.9 0.0051.1 0.0061.1 0.05MOV-KITAcc ARI50.0 0.0050.0 0.0050.1 0.0061.6 0.0559.2 0.03(a)2nd eigenvectorTop five eigenvectorsInterested Reader ModelNMFsystemMOV-DVDAcc ARI54.4 0.0168.3 0.1353.4 0.0166.9 0.1171.4 0.18BOO-DVDAcc ARI52.3 0.0152.0 0.0052.1 0.0151.7 0.0068.8 0.14(b)Table 23: Results (a) topic-based clustering (b) sentiment-based clusteringfour augmented datasets. strongest results dataset boldfaced.number features necessarily sentiment-bearing, make difficulthuman judges identify sentiment dimension.Another interesting point note datasets, seemsone eigenvector correspond sentiment. instance, BOO-DVD dataset,five human judges agreed e4 e5 correspond sentiment dimension.closer examination two eigenvectors (shown Table 20) reveals interestingpattern: e4 , positive features (in C1 ) came DVD domain negativefeatures (in C2 ) came BOO domain; whereas e5 , positive features (inC1 ) came BOO domain negative features (in C2 ) came DVD.words, e4 partitions reviews according positive DVD negativeBOO, whereas e5 reverse. suggests eigen-decomposition proceduresmart enough merge positive negative sentiment-bearing wordstwo domains together. Perhaps even importantly, e4 e5partitioning reviews along sentiment dimension also topic dimension.4.7.2 Clustering ResultsRows 14 Tables 23a 23b show topic- sentiment-based clustering resultsfour baseline text clustering algorithms described Section 4.2. Notebaselines produce one clustering documents per dataset.Hence, baseline, topic-based clustering results produced comparingclustering gold-standard topic-based clustering, sentiment-based618fiInducing Ideal Clustering Minimal Feedbackclustering results produced comparing clustering gold-standardsentiment-based clustering.see topic-based results Table 23a, baseline clusterusing second eigenvector achieves best average clustering results fouraugmented datasets. potentially attributed fact e2 correspondstopic dimension four datasets according human judges, describedhuman experiments. However, clustering using e2 produce best clusteringresults four datasets. fact, Interested Reader Model achieves best resultsMOV-DVD, DVD-ELE, MOV-KIT. Nevertheless, results BOO-DVDworst among baselines. true top five eigenvectors baselineNMF: yielded poor results MOV-DVD; addition, NMFs resultsBOO-DVD MOV-KIT promising either.far sentiment-based baseline clustering results concerned (see rows 14Table 23b), best average performance achieved NMF. Except three cases(NMF MOV-DVD MOV-KIT, well top five eigenvectors MOV-DVD),baseline results particularly promising, accuracy results low fiftiesARI results close zero.topic- sentiment-based clustering results produced algorithm shownrow 5 Tables 23a 23b. Specifically, results obtained groupingreviews according eigenvectors manually selected topic sentiment dimensions, respectively. Hence, unlike baselines, topic-based clusteringsentiment-based clustering produced algorithm different other.before, cases human judges selected one eigenvector dimension, use eigenvector ranked first frequently. see,accuracies topic-based clustering reasonably high, ranging 77.1% 99.3%.results suggest possible achieve high-performance topic-based (orprecisely, domain-based) clustering dataset even another prominent clustering dimension (i.e., sentiment) present. hand, despite existence eigenvectorsclearly capture sentiment dimension datasets (e.g., e3 MOV-DVDdataset), sentiment-based clustering accuracies ARI values lowertopic-based clustering. potentially attributed reason mentionedintroduction: fact reviews sentimentally ambiguous makes non-trivialclassify. comparison four baselines, algorithm achieves bestaverage performance four datasets also comparatively stable performanceacross datasets.worth noting sentiment-based clustering results produced algorithmMOV-DVD BOO-DVD higher DVD-ELE MOV-KIT.perhaps surprising: discussed before, human judges found difficultidentify sentiment eigenvector DVD-ELE MOV-KIT MOV-DVDBOO-DVD, owing part fact many top-ranked features sentimenteigenvector DVD-ELE MOV-KIT sentiment-oriented, turnattributed fact datasets correspond domain pairssentimentally dissimilar. mentioned above, two sentimentally dissimilar constituentdomains tend many sentiment-bearing words common, consequently,influence sentiment-bearing words present one two constituent619fiDasgupta & Ngdomains diluted larger number non-sentiment-bearing words resultcombining two domains, making difficult produce good sentiment-basedclustering. hand, combining two domains helps boost influencesentiment-bearing words, increasing chance appearing higherlist features ranked MMFR producing good sentiment-based clustering.Interestingly, algorithm achieves better topic-based clustering results twodatasets DVD-ELE MOV-KIT achieves poorer sentiment-based clustering results. fact, topic-based clustering accuracies DVD-ELE MOV-KITnear perfect: 94.2% 99.3% DVD-ELE MOV-KIT respectively.means coincidence: constituent domains augmented dataset highlydissimilar (i.e., word usage tends differ considerably other), topic clusters well-separated hence high topic-based clustering resultsachieved. similar line reasoning explain algorithm finds comparativelydifficult produce good topic-based clustering MOV-DVD BOO-DVD,constituent domains similar.results seem suggest higher topic-based accuracy/ARI implies lowersentiment-based accuracy/ARI vice versa. speculate constituentdomains similar, sentiment-bearing features tend similar result,sentiment-based results tend good topic-based results tend poor. Additionalexperiments needed determine reason.Overall, results provide supporting evidence feedback-oriented algorithmproduce multiple clusterings dataset. particular, even though sentimentbased clustering accuracies high topic-based clustering accuraciesaugmented datasets, current level performance algorithm arguably reasonable, especially considering fact sentiment-based clustering challenging tasktraditional clustering algorithms fail even produce one clustering.4.7.3 Multiple Relevant EigenvectorsRecall Table 18b four augmented datasets, least onejudge indicated one eigenvector relevant sentiment dimension.However, producing sentiment-based clustering results using system Table 23b, used eigenvector ranked frequently human judges.better understand whether using relevant eigenvectors help improve results sentiment-based clustering, repeat experiment apply 2-meanscluster documents space defined eigenvectors determinedrelevant least one judge. specifically, cluster following seteigenvectors: {3,4} MOV-DVD, {4,5} BOO-DVD, {3,5} DVD-ELE, {3,5}MOV-KIT.accuracy ARI results experiment shown Table 24. comparisonresults last row Table 23b, see using additional relevant eigenvectorsyields better results BOO-DVD dataset. may easydetermine reason, believe poorer results observed BOO-DVDattributed impurity e5 , captures sentiment also topic,discussed before. hand, additional sentiment eigenvectors chosen620fiInducing Ideal Clustering Minimal FeedbacksystemMOV-DVDAcc ARI72.2 0.19BOO-DVDAcc ARI55.7 0.01DVD-ELEAcc ARI66.2 0.10MOV-KITAcc ARI59.8 0.04Table 24: Results sentiment-based clustering obtained using multiple relevant eigenvectors four augmented datasets.three augmented datasets seem impurity problem,capture sentiment dimension one constituent domains.5. Significance Workbelieve approach significant following aspects.1. Producing clustering according user interest. proposed novel framework enabled spectral clustering algorithm take account humanfeedback produce clustering along dimension interest user.particularly appealing aspect approach concerned relatively minimal human feedback demands, user needs take cursory looksmall number features representative induced dimension.worth noting human inspect select automatically inducedclustering dimension new form interaction human clusteringalgorithm. enables human easily engage various clustering tasks help improve performance easy, low-effort manner. believe approach,belongs emerging family interactive algorithms allows usermake small, guiding tweaks thereby get results much better would otherwisepossible, future information retrieval.2. Inducing human-interpretable clustering dimensions. dimensions produced spectral clustering dimensionality reduction algorithms (e.g., LatentSemantic Indexing (LSI), Deerwester, Dumais, Furnas, Landauer, & Harshman, 1990)generally considered non-interpretable (Sebastiani, 2002), unlike dimensionoriginal feature space, typically corresponds word type therefore interpreted human easily. results preliminary study challengecommon wisdom. show context text clustering dimensionlow-dimensional space induced spectral clustering interpretedhuman. believe ability produce human-interpretable dimensions enables usemploy spectral clustering (and perhaps dimensionality reduction-based clustering algorithms) text processing intelligent manner. especiallycase respect selecting dimensions pertinent taskhand. example, existing applications spectral clustering topic-basedclustering task (e.g., Xu et al., 2003; He, Cai, Liu, & Ma, 2004; Hu, Deng, Guo, & Xu,2007), dimensions low-dimensional space typically used. Sinceshowed dimensions produced spectral clustering datasetnecessarily topic-related, potentially improve topic-based clustering results621fiDasgupta & Ngemploying non-topic-related dimensions clustering process. addition,since induced dimensions correspond non-topic dimensions,use produce non-topic-based clusterings. particular, given recent surgeinterest NLP community text classification along non-topic dimensionssentiment gender (e.g., Garera & Yarowsky, 2009; Jurafsky, Ranganath, &McFarland, 2009), approach offers solution tasks relylabeled data, unlike majority existing approaches non-topic-based text classification, supervised nature. Overall, believe NLP researchersfully exploited power spectral clustering, hence rewardsunderstanding spectral clustering light results may significant.3. Producing multiple clusterings. majority existing text clusteringalgorithms produce single clustering dataset, approach potentiallyused produce multiple clusterings, one along important clusteringdimensions induced via novel application spectral clustering.Finally, worth mentioning task inducing clustering dimensions reminiscent influential topic modeling task (Blei, Ng, & Jordon, 2003), whose goaldiscover major topics set documents unsupervised manner. Notetwo tasks fundamentally different: topic model attempts discover majortopics set documents, dimension model aims discover major clusteringdimensions. Nevertheless, two models bear resemblance many ways.First, employ clustering discover information text collection unsupervised manner. Second, display learned information human usingrepresentative words: topic model represents induced topic using wordsrepresentative topic, dimension model represents induced clusteringdimension using words representative two document clusters involved dimension. Finally, induced topics clustering dimensions human-recognizable,are, human needed assign labels them. believe inductionclustering dimensions potential substantially enhance capability existingtext analysis algorithms discover knowledge text collection unsupervisedmanner complementing information induced topic model.6. Related Workintroduction, discussed related work producing user-desired clustering.section, focus discussing related work topic-based clustering classification, sentiment classification, active learning, producing multiple clusterings computationalstylistics.Topic-based text clustering. Traditional research text clustering focused primarily topic-based clustering, owing large part DARPAs Topic DetectionTracking initiative 1990s. Many different clustering algorithms used, including non-hierarhical algorithms k-means Expectation-Maximization (EM)hierarchical algorithms single-link, complete-link, group-average, singlepass (Hatzivassiloglou, Gravano, & Maganti, 2000). algorithms cluster given set622fiInducing Ideal Clustering Minimal Feedbackdocuments feature space typically spanned unigrams. However,clustering high-dimensional space allow distance two documents reliably computed due curse dimensionality. Consequently,recent work focused development algorithms cluster documents lowdimensional space constructed via dimensionality reduction. Representative membersfamily dimensionality reduction-based clustering algorithms include traditional algorithms based LSI (Deerwester et al., 1990), well recently proposed(and arguably better performing) algorithms spectral clustering (Shi & Malik, 2000;Ng et al., 2001), non-negative matrix factorization (Xu et al., 2003), locality preserving indexing (He et al., 2004), locality discriminating indexing (Hu et al., 2007). Despitedevelopment new clustering algorithms, primarily evaluatedrespect ability produce topic-based clusterings.Topic-based text classification. Yang Liu (1999) put it, text classificationinherently supervised learning task. fact, arguably one populartasks supervised learning techniques applied information retrievalcommunity 1990s (see Sebastiani, 2002, comprehensive overview related workmachine learning text classification). Nevertheless, annotated documentsneeded training high-performance supervised text classifier expensiveobtain. result, researchers investigated possibility performing textclassification little even labeled data. attempts led developmentgeneral-purpose semi-supervised text classification algorithms combine labeledunlabeled data using transduction (Joachims, 1999b) EM (Nigam, McCallum, Thrun, &Mitchell, 2000), latter used combination active learning (McCallum & Nigam, 1998). recently, Sandler (2005) proposed unsupervised textclassification algorithm based mixture modeling LSI-based dimensionalityreduction.Sentiment classification. mentioned introduction, despite large amountrecent work sentiment analysis opinion mining, much focused supervisedmethods (see Pang & Lee, 2008, comprehensive survey field). One weakness existing supervised polarity classification systems typicallydomain- language-specific. Hence, given new domain language, one needsgo expensive process collecting large amount annotated data ordertrain high-performance polarity classifier. recent attempts madeleverage existing sentiment corpora lexicons automatically create annotated resourcesnew domains languages. However, methods require existence eitherparallel corpus/machine translation engine projecting/translating annotations/lexiconsresource-rich language target language (Banea, Mihalcea, Wiebe, & Hassan,2008; Wan, 2008), domain similar enough target domain (Blitzer et al.,2007). target domain language fails meet requirement, sentiment-basedclustering unsupervised polarity classification become appealing alternatives. Unfortunately, exceptions (e.g., semi-supervised sentiment analysis, Riloff & Wiebe,2003; Sindhwani & Melville, 2008; Dasgupta & Ng, 2009a; Li, Zhang, & Sindhwani, 2009),tasks largely under-investigated NLP community. Turneys (2002) workperhaps one notable examples unsupervised polarity classification. However,623fiDasgupta & Ngsystem learns semantic orientation phrases review unsupervised manner, information used predict polarity review heuristically.Domain adaptation. Domain adaptation, also known transfer learning, onefocal research areas machine learning NLP recent years, goalleverage labeled data available one domain (the source domain) buildclassifier another domain (the target domain). Techniques domain adaptationapplied various NLP tasks, including part-of-speech tagging, noun phrase chunking,syntactic parsing, named entity recognition, word sense disambiguation (e.g., Daume III& Marcu, 2006; Chan & Ng, 2007; Duame III, 2007; Jiang & Zhai, 2007a, 2007b).particular relevance work domain adaptation techniques specifically developedtext sentiment classification (e.g., Blitzer, McDonald, & Pereira, 2006; Finn &Kushmerick, 2006; Blitzer et al., 2007; Gao, Fan, Jiang, & Han, 2008; Ling, Dai, Xue, Yang,& Yu, 2008; Tan, Cheng, Wang, & Xu, 2009). worth noting domain adaptationsetting different traditional setting. Traditionally, sophisticated classifiers and/orautomatically constructed mapping features two domains usedadaptation process. setting, however, simply utilize sentiment dimensionmanually selected source domain automatically identify sentimentdimension target domain.Active clustering. Active learning heavily investigated machine learning paradigmaims achieve better generalization bounds lower annotation costs (Cohn, Atlas,& Ladner, 1994). traditional active learning setting, human requestedannotate data points classifier uncertain (e.g., Cohn et al., 1994),recent research active learning involved asking human identify labelfeatures useful classification task hand (e.g., Bekkerman et al., 2007;Raghavan & Allan, 2007; Druck, Settles, & McCallum, 2009; Roth & Small, 2009).mentioned introduction, active learning applied clustering setting,goal encouraging algorithm produce user-intended clusteringdata clustered along multiple dimensions. Different variants active clusteringproposed. request human label pair data points must-linkcannot-link indicate whether two points must must reside cluster(e.g., Wagstaff et al., 2001; Bilenko, Basu, & Mooney, 2004), others humandetermine whether two clusters merged split hierarchical clusteringprocess (e.g., Balcan & Blum, 2008). active clustering algorithm yet another variant:ask human select clustering desires set automatically producedclusterings.Generation multiple clusterings. notion text collections may clusteredmultiple independent ways discussed literature computational stylistics(see Lim, Lee, & Kim, 2005; Biber & Kurjian, 2006; Grieve-Smith, 2006; Tambouratzis &Vassiliou, 2007; Gries, Wulff, & Davies, 2010, example). machine learning,attempts design algorithms producing multiple clusterings dataset.operate semi-supervised setting (e.g., Gondek & Hofmann, 2004;Davidson & Qi, 2007), totally unsupervised (e.g., Caruana, Elhawary, Nguyen,& Smith, 2006; Jain, Meka, & Dhillon, 2008). instance, Caruana et al.s (2006) metaclustering algorithm produces different clusterings dataset running k-means624fiInducing Ideal Clustering Minimal Feedbacktimes, time random selection seeds random weighting features.goal present local minimum found k-means possible clustering. However,propose mechanism determining clusterings oneuser desires. approach, relies spectral clustering rather k-meansproducing multiple clusterings, fills gap soliciting user feedback determineuser-desired clustering.7. Conclusions Future WorkUnsupervised clustering algorithms typically group objects along prominent dimension, part owing objective simultaneously maximizing inter-cluster similarity intra-cluster dissimilarity. Hence, users intended clustering dimensionprominent dimension, unsupervised clustering algorithms failmiserably. address problem, proposed active clustering algorithm,allows us mine user-intended, possibly hidden, dimension data producedesired clustering. mechanism differs competing methods requireslimited feedback: select intended dimension, user needs inspectsmall number features. demonstrated viability via set human automaticexperiments challenging, yet under-investigated task sentiment-based clustering, obtaining promising results. Additional experiments provided suggestive evidence(1) domain adaptation successfully applied identify sentiment dimensionnew domain domains consideration sentimentally similar; (2) hand-craftedsubjectivity lexicon, available, used replace user feedback needed selectsentiment eigenvector domain; (3) algorithm potentially usedproduce multiple clusterings datasets possess multiple clustering dimensions.Equally importantly, empirically demonstrated possible humaninterpret dimension produced spectral clustering algorithm, contrary commonwisdom dimensions automatically constructed rank-reduced space noninterpretable. believe NLP researchers fully exploited power spectralclustering, hence rewards understanding spectral clustering light resultsmay significant. Finally, proposal represent induced clustering dimensionsets informative features facilitates exploratory text analysis, potentially enhancingcapability existing text analysis algorithms complementing information providedunsupervised models (e.g., topic model).future work, plan explore several extensions active clustering algorithm.First, active clustering algorithm potentially used produce multiple clusterings dataset, one interesting future direction would examine theoreticalguarantees, determining whether able produce distinct clusterings qualitatively strong (see Dasgupta & Ng, 2010a, 2010b, example). Second, plan usealgorithm combination existing feedback-oriented methods (e.g., Bekkerman et al.,2007; Roth & Small, 2009) improving performance. instance, insteaduser construct relevant feature space scratch, simply extend setinformative features identified user-selected dimension. Third, since nonesteps algorithm specifically designed sentiment classification, plan applynon-topic-based text classification tasks recently received lot in625fiDasgupta & Ngterest NLP community, gender classification (i.e., task determininggender author document). Finally, plan adopt richer representationdocument exploits features polarity-oriented words obtained hand-builtmachine-learned sentiment lexicons (e.g., Hu & Liu, 2004; Wiebe, Wilson, Bruce, Bell,& Martin, 2004; Andreevskaia & Bergler, 2006; Mohammad, Dunne, & Dorr, 2009; Rao& Ravichandran, 2009), derived finer-grained (i.e., sentential, sub-sentential,phrase-based) sentiment analysis methods (e.g., Wilson et al., 2005; Kennedy & Inkpen,2006; Polanyi & Zaenen, 2006; McDonald, Hannan, Neylon, Wells, & Reynar, 2007; Choi& Cardie, 2008), richer features may make easier user identifydesired dimension using method.Bibliographic NotePortions work previously presented conference publication (Dasgupta &Ng, 2009b). current article extends work several ways, notably: (1)detailed introduction spectral clustering (Section 2.2); (2) inclusion twobaseline systems (Section 4.2); (3) investigation effect document representationclustering performance (Section 4.4); (4) addition three new sections focusingissues domain adaptation (Section 4.5), employing manually constructed subjectivitylexicon (Section 4.6), producing multiple clusterings dataset (Section 4.7); well(5) description significance work (Section 5).Acknowledgmentsauthors acknowledge support National Science Foundation (NSF) grant IIS0812261. thank four anonymous reviewers helpful commentsunanimously recommending article publication JAIR. opinions, findings,conclusions recommendations expressed article authorsnecessarily reflect views official policies, either expressed implied, NSF.ReferencesAbbasi, A., Chen, H., & Salem, A. (2008). Sentiment analysis multiple languages: Featureselection opinion classification web forums. ACM Transactions InformationSystems, 26 (3).Andreevskaia, A., & Bergler, S. (2006). Mining WordNet fuzzy sentiment: Sentimenttag extraction WordNet glosses. Proceedings 11th ConferenceEuropean Chapter Association Computational Linguistics (EACL), pp. 209216.Balcan, M.-F., & Blum, A. (2008). Clustering interactive feedback. Proceedings19th International Conference Algorithmic Learning Theory (ALT), pp. 316328.Banea, C., Mihalcea, R., Wiebe, J., & Hassan, S. (2008). Multilingual subjectivity analysis using machine translation. Proceedings 2008 Conference EmpiricalMethods Natural Language Processing (EMNLP), pp. 127135.626fiInducing Ideal Clustering Minimal FeedbackBekkerman, R., Raghavan, H., Allan, J., & Eguchi, K. (2007). Interactive clusteringtext collections according user-specified criterion. Proceedings 20thInternational Joint Conference Artificial Intelligence (IJCAI), pp. 684689.Biber, D., & Kurjian, J. (2006). Towards taxonomy web registers text types:multidimensional analysis. Language Computers, 59 (1), 109131.Bilenko, M., Basu, S., & Mooney, R. J. (2004). Integrating constraints machine learningsemi-supervised clustering. Proceedings 21st International ConferenceMachine Learning (ICML), pp. 8188.Blei, D. M., Ng, A. Y., & Jordon, M. I. (2003). Latent Dirichlet Allocation. JournalMachine Learning Research, 3, 9931022.Blitzer, J., Dredze, M., & Pereira, F. (2007). Biographies, bollywood, boom-boxesblenders: Domain adaptation sentiment classification. Proceedings 45thAnnual Meeting Association Computational Linguistics (ACL), pp. 440447.Blitzer, J., McDonald, R., & Pereira, F. (2006). Domain adaptation structural correspondence learning. Proceedings 2006 Conference Empirical MethodsNatural Language Processing (EMNLP), pp. 120128.Cai, D., He, X., & Han, J. (2005). Document clustering using locality preserving indexing.IEEE Transactions Knowledge Data Engineering, 17 (12), 16241637.Caruana, R., Elhawary, M. F., Nguyen, N., & Smith, C. (2006). Meta clustering.Proceedings 6th IEEE International Conference Data Mining (ICDM), pp. 107118.Chan, P. K., Schlag, D. F., & Zien, J. Y. (1994). Spectral k-way ratio-cut partitioningclustering. IEEE Transactions Computer-Aided Design, 13, 10881096.Chan, Y. S., & Ng, H. T. (2007). Domain adaptation active learning word sensedisambiguation. Proceedings 45th Annual Meeting AssociationComputational Linguistics (ACL), pp. 4956.Choi, Y., & Cardie, C. (2008). Learning compositional semantics structural inference subsentential sentiment analysis. Proceedings 2008 ConferenceEmpirical Methods Natural Language Processing (EMNLP), pp. 793801.Cohn, D., Atlas, L., & Ladner, R. (1994). Improving generalization active learning.Machine Learning, 15 (2), 201221.Dasgupta, S., & Ng, V. (2009a). Mine easy, classify hard: semi-supervised approach automatic sentiment classification. Proceedings Joint Conference47th Annual Meeting ACL 4th International Joint ConferenceNatural Language Processing AFNLP (ACL-IJCNLP), pp. 701709.Dasgupta, S., & Ng, V. (2009b). Topic-wise, sentiment-wise, otherwise? Identifyinghidden dimension unsupervised text classification. Proceedings 2009Conference Empirical Methods Natural Language Processing (EMNLP), pp.580589.Dasgupta, S., & Ng, V. (2010a). Mining clustering dimensions. Proceedings 27thInternational Conference Machine Learning (ICML), pp. 263270.627fiDasgupta & NgDasgupta, S., & Ng, V. (2010b). Towards subjectifying text clustering. Proceedings33rd Annual International ACM SIGIR Conference Research DevelopmentInformation Retrieval (SIGIR), pp. 483490.Daume III, H., & Marcu, D. (2006). Domain adaptation statistical classifiers. JournalArtificial Intelligence Research, 26, 101126.Davidson, I., & Qi, Z. (2007). Finding alternative clusterings using constraints. Proceedings 8th IEEE International Conference Data Mining (ICDM), pp. 773778.Deerwester, S., Dumais, S. T., Furnas, G. W., Landauer, T. K., & Harshman, R. (1990).Indexing latent semantic analysis. Journal American Society InformationScience, 41 (6), 391407.Dhillon, I., Guan, Y., & Kulis, B. (2004). Kernel k-means, spectral clustering normalized cuts. Proceedings 10th ACM SIGKDD International ConferenceKnowledge Discovery Data Mining (KDD), pp. 551556.Ding, C., He, X., Zha, H., Gu, M., & Simon, H. D. (2001). min-max cut algorithmgraph partitioning data clustering. Proceedings 2001 InternationalConference Data Mining (ICDM), pp. 107114.Druck, G., Settles, B., & McCallum, A. (2009). Active learning labeling features. Proceedings 2009 Conference Empirical Methods Natural Language Processing(EMNLP), pp. 8190.Duame III, H. (2007). Frustratingly easy domain adaptation. Proceedings 45thAnnual Meeting Association Computational Linguistics (ACL), pp. 256263.Finn, A., & Kushmerick, N. (2006). Learning classify documents according genre.Journal American Society Information Science Technology, 57 (11),15061518.Fung, G. (2003). disputed Federalist Papers: SVM feature selection via concave minimization. Proceedings 2003 Conference Diversity Computing, pp.4246.Gao, J., Fan, W., Jiang, J., & Han, J. (2008). Knowledge transfer via multiple model localstructure mapping. Proceeding 14th ACM SIGKDD International ConferenceKnowledge Discovery Data Mining (KDD), pp. 283291.Garera, N., & Yarowsky, D. (2009). Modeling latent biographic attributes conversationalgenres. Proceedings Joint Conference 47th Annual MeetingACL 4th International Joint Conference Natural Language ProcessingAFNLP (ACL-IJCNLP), pp. 710718.Gilad-Bachrach, R., Navot, A., & Tishby, N. (2004). Margin based feature selection theoryalgorithms. Proceedings 21st International Conference MachineLearning (ICML), pp. 4350.Gondek, D., & Hofmann, T. (2004). Non-redundant data clustering. Proceedings4th IEEE International Conference Data Mining (ICDM), pp. 7582.Gries, S., Wulff, S., & Davies, M. (2010). Corpus-linguistic Applications: Current Studies,New Directions. Rodopi.628fiInducing Ideal Clustering Minimal FeedbackGrieve-Smith, A. (2006). envelope variation multidimensional register genreanalyses. Language Computers, 60 (1), 2142.Hatzivassiloglou, V., Gravano, L., & Maganti, A. (2000). investigation linguisticfeatures clustering algorithms topical document clustering. Proceedings23rd Annual International ACM SIGIR Conference Research DevelopmentInformation Retrieval (SIGIR), pp. 224231.He, X., Cai, D., Liu, H., & Ma, W.-Y. (2004). Locality preserving indexing documentrepresentation. Proceedings 27th Annual International ACM SIGIR Conference Research Development Information Retrieval (SIGIR), pp. 96103.Hu, J., Deng, W., Guo, J., & Xu, W. (2007). Locality discriminating indexing documentclassification. Proceedings 30th Annual International ACM SIGIR ConferenceResearch Development Information Retrieval (SIGIR) (Poster), pp. 689690.Hu, M., & Liu, B. (2004). Mining opinion features customer reviews. Proceedings19th National Conference Artificial Intelligence (AAAI), pp. 755760.Jain, P., Meka, R., & Dhillon, I. S. (2008). Simultaneous unsupervised learning disparateclusterings. Proceedings SIAM International Conference Data Mining (SDM),pp. 858869.Jiang, J., & Zhai, C. (2007a). Instance weighting domain adaptation NLP. Proceedings 45th Annual Meeting Association Computational Linguistics(ACL), pp. 254271.Jiang, J., & Zhai, C. (2007b). two-stage approach domain adaptation statisticalclassifiers. Proceedings 16th Conference Information KnowledgeManagement (CIKM), pp. 401410.Joachims, T. (1999a). Making large-scale SVM learning practical. Scholkopf, B., &Smola, A. (Eds.), Advances Kernel Methods - Support Vector Learning, pp. 4456.MIT Press.Joachims, T. (1999b). Transductive inference text classification using support vectormachines. Proceedings 16th International Conference Machine Learning(ICML), pp. 200209.Jurafsky, D., Ranganath, R., & McFarland, D. (2009). Extracting social meaning: Identifying interactional style spoken conversation. Proceedings Human LanguageTechnologies: 2009 Annual Conference North American ChapterAssociation Computational Linguistics (NAACL HLT), pp. 638646.Kamvar, S., Klein, D., & Manning, C. (2003). Spectral learning. Proceedings 19thInternational Joint Conference Artificial Intelligence (IJCAI), pp. 561566.Kannan, R., Vempala, S., & Vetta, A. (2004). clusterings: Good, bad spectral.Journal ACM, 51 (3), 497515.Kennedy, A., & Inkpen, D. (2006). Sentiment classifiation movie reviews using contextualvalence shifters. Computational Intelligence, 22 (2), 110125.629fiDasgupta & NgKoppel, M., Schler, J., & Argamon, S. (2009). Computational methods authorship attribution. Journal American Society Information Science Technology,60 (1), 926.Kugler, M., Aoki, K., Kuroyanagi, S., Iwata, A., & Nugroho, A. (2005). Feature subsetselection support vector machines using confident margin. Proceedings2005 IEEE International Joint Conference Neural Networks (IJCNN), pp. 907912.Kulis, B., Basu, S., Dhillon, I., & Mooney, R. (2009). Semi-supervised graph-based clustering: kernel approach. Machine Learning, 74 (1), 122.Li, T., Zhang, Y., & Sindhwani, V. (2009). non-negative matrix tri-factorization approachsentiment classification lexical prior knowledge. Proceedings JointConference 47th Annual Meeting ACL 4th International JointConference Natural Language Processing AFNLP (ACL-IJCNLP), pp. 244252.Lim, C., Lee, K., & Kim, G. (2005). Multiple sets features automatic genre classification web documents. Information Processing Management, 41 (5), 12631276.Ling, X., Dai, W., Xue, G., Yang, Q., & Yu, Y. (2008). Spectral domain-transfer learning.Proceeding 14th ACM SIGKDD International Conference KnowledgeDiscovery Data Mining (KDD), pp. 488496.Liu, B., Li, X., Lee, W. S., & Yu, P. S. (2004). Text classification labeling words.Proceedings 19th National Conference Artificial Intelligence (AAAI), pp.425430.McCallum, A. K., & Nigam, K. (1998). Employing EM pool-based active learningtext classification. Proceedings 15th International Conference MachineLearning (ICML), pp. 350358, Madison, WI. Morgan Kaufmann.McDonald, R., Hannan, K., Neylon, T., Wells, M., & Reynar, J. (2007). Structured modelsfine-to-coarse sentiment analysis. Proceedings 45th Annual MeetingAssociation Computational Linguistics (ACL), pp. 432439.Mei, Q., Ling, X., Wondra, M., Su, H., & Zhai, C. (2007). Sentiment mixture: Modelingfacets opinions weblogs. Proceedings 16th World Wide Web Conference(WWW), pp. 171180.Mohammad, S., Dunne, C., & Dorr, B. (2009). Generating high-coverage semantic orientation lexicons overtly marked words thesaurus. Proceedings2009 Conference Empirical Methods Natural Language Processing (EMNLP),pp. 599608.Ng, A., Jordan, M., & Weiss, Y. (2001). spectral clustering: Analysis algorithm.Advances Neural Information Processing Systems 14 (NIPS).Nigam, K., McCallum, A., Thrun, S., & Mitchell, T. (2000). Text classification labeledunlabeled documents using EM. Machine Learning, 39 (2/3), 103134.Pang, B., & Lee, L. (2008). Opinion mining sentiment analysis. Foundations TrendsInformation Retrieval, 2 (12), 1135.630fiInducing Ideal Clustering Minimal FeedbackPang, B., Lee, L., & Vaithyanathan, S. (2002). Thumbs up? Sentiment classification usingmachine learning techniques. Proceedings 2002 Conference EmpiricalMethods Natural Language Processing (EMNLP), pp. 7986. Association Computational Linguistics.Polanyi, L., & Zaenen, A. (2006). Contextual valence shifters. Computing AttitudeAffect Text: Theory Applications. Springer Verlag.Raghavan, H., & Allan, J. (2007). interactive algorithm asking incorporatingfeature feedback support vector machines. Proceedings 30th AnnualInternational ACM SIGIR Conference Research Development InformationRetrieval (SIGIR), pp. 7986.Rao, D., & Ravichandran, D. (2009). Semi-supervised polarity lexicon induction. Proceedings 12th Conference European Chapter Association Computational Linguistics (EACL), pp. 675682.Riloff, E., & Wiebe, J. (2003). Learning extraction patterns subjective expressions.Proceedings 2003 Conference Empirical Methods Natural LanguageProcessing (EMNLP), pp. 105112.Roth, D., & Small, K. (2009). Interactive feature space construction using semantic information. Proceedings 13th Conference Computational Natural LanguageLearning (CoNLL), pp. 6674.Sandler, M. (2005). use linear programming unsupervised text classification.Proceedings 11th ACM SIGKDD International Conference KnowledgeDiscovery Data Mining (KDD), pp. 256264.Sebastiani, F. (2002). Machine learning automated text categorization. ACM ComputingSurveys, 34 (1), 147.Shi, J., & Malik, J. (2000). Normalized cuts image segmentation. IEEE TransactionsPattern Analysis Machine Intelligence, 22 (8), 888905.Sindhwani, V., & Melville, P. (2008). Document-word co-regularization semi-supervisedsentiment analysis. Proceedings 8th IEEE International Conference DataMining (ICDM), pp. 10251030.Stein, S., Argamon, S., & Frieder, O. (2006). effect OCR errors stylistic textclassification. Proceedings 29th Annual International ACM SIGIR conferenceResearch Development Information Retrieval (SIGIR) (Poster), pp. 701702.Tambouratzis, G., & Vassiliou, M. (2007). Employing thematic variables enhancing classification accuracy within author discrimination experiments. Literary LinguisticComputing, 22 (2), 207224.Tan, S., Cheng, X., Wang, Y., & Xu, H. (2009). Adapting naive Bayes domain adaptationsentiment analysis. Proceedings 31st European Conference InformationRetrieval (ECIR), pp. 337349.Turney, P. (2002). Thumbs thumbs down? Semantic orientation applied unsupervised classification reviews. Proceedings 40th Annual MeetingAssociation Computational Linguistics (ACL), pp. 417424.631fiDasgupta & NgWagstaff, K., Cardie, C., Rogers, S., & Schrodl, S. (2001). Constrained k-means clusteringbackground knowledge. Proceedings 18th International ConferenceMachine Learning (ICML), pp. 577584.Wan, X. (2008). Using bilingual knowledge ensemble techniques unsupervised Chinese sentiment analysis. Proceedings 2008 Conference Empirical MethodsNatural Language Processing (EMNLP), pp. 553561.Weiss, Y. (1999). Segmentation using eigenvectors: unifying view. ProceedingsInternational Conference Computer Vision (ICCV), pp. 975982.Wiebe, J. M., Wilson, T., Bruce, R., Bell, M., & Martin, M. (2004). Learning subjectivelanguage. Computational Linguistics, 30 (3), 277308.Wilson, T., Wiebe, J. M., & Hoffmann, P. (2005). Recognizing contextual polarityphrase-level sentiment analysis. Proceedings Joint Human Language Technology Conference 2005 Conference Empirical Methods Natural LanguageProcessing (HLT/EMNLP), pp. 347354.Wu, Z., & Leahy, R. M. (1993). optimal graph theoretic appproach data clusteringapplication image segmentation. IEEE Transactions Pattern AnalysisMachine Intelligence, 15 (11), 11011113.Xing, E. P., Ng, A. Y., Jordan, M. I., & Russell, S. J. (2002). Distance metric learningapplication clustering side-information. Advances Neural InformationProcessing Systems 15 (NIPS), pp. 505512.Xu, W., Liu, X., & Gong, Y. (2003). Document clustering based non-negative matrixfactorization. Proceedings 26th Annual International ACM SIGIR ConferenceResearch Development Information Retrieval (SIGIR), pp. 267273.Yang, Y., & Liu, X. (1999). re-examination text categorization methods. Proceedings 22nd Annual International ACM SIGIR Conference ResearchDevelopment Information Retrieval (SIGIR), pp. 4249.Yang, Y., & Pedersen, J. O. (1997). comparative study feature selection text categorization. Proceedings 14th International Conference Machine Learning(ICML), pp. 412420.632fiJournal Artificial Intelligence Research 39 (2010) 1-49Submitted 05/10; published 09/10Planning Noisy Probabilistic Relational RulesTobias LangMarc Toussainttobias.lang@tu-berlin.demtoussai@cs.tu-berlin.deMachine Learning Robotics GroupTechnische Universitat BerlinFranklinstrae 28/29, 10587 Berlin, GermanyAbstractNoisy probabilistic relational rules promising world model representation several reasons. compact generalize world instantiations. usuallyinterpretable learned effectively action experiences complexworlds. investigate reasoning rules grounded relational domains. algorithms exploit compactness rules efficient flexible decision-theoretic planning.first approach, combine rules Upper Confidence Bounds appliedTrees (UCT) algorithm based look-ahead trees. second approach convertsrules structured dynamic Bayesian network representation predicts effectsaction sequences using approximate inference beliefs world states. evaluateeffectiveness approaches planning simulated complex 3D robot manipulation scenario articulated manipulator realistic physics domainsprobabilistic planning competition. Empirical results show methods solveproblems existing methods fail.1. IntroductionBuilding systems act autonomously complex environments central goal Artificial Intelligence. Nowadays, A.I. systems par particularly intelligent humansspecialized tasks playing chess. hopelessly inferior almost humans, however, deceivingly simple tasks everyday-life, clearing desktop,preparing cup tea manipulating chess figures: current state art reasoning, planning, learning, perception, locomotion, manipulation far removedhuman-level abilities, cannot yet contemplate working actual domain interest (Pasula, Zettlemoyer, & Kaelbling, 2007). Performing common object manipulationsindeed challenging task real world: choose large numberdistinct actions uncertain outcomes number possible situations basicallyunseizable.act real world, accomplish two tasks. First, need understandworld works: example, pile plates stable place big platesbottom; hard job build tower balls; filling tea cup may leaddirty table cloth. Autonomous agents need learn world knowledge experienceadapt new environments rely human hand-crafting. paper,employ recent solution learning (Pasula et al., 2007). know possibleeffects actions, face second challenging problem: use acquiredknowledge reasonable time find sequence actions suitable achieve goals?c2010AI Access Foundation. rights reserved.fiLang & Toussaintpaper investigates novel algorithms tackle second task, namely planning.pursue model-based approach planning complex domains. contrast modelfree approaches compute policies directly experience respect fixed goals(also called habit-based decision making), follow purposive decision-making approach(Botvinick & An, 2009) use learned models plan goal current statehand. particular, simulate probabilistic effects action sequences. approachinteresting parallels recent neurobiology cognitive science results suggestingbehavior intelligent mammals driven internal simulation emulation:found motor structures cortex activated planning,execution motor commands suppressed (Hesslow, 2002; Grush, 2004).Probabilistic relational world model representations received significant attentionlast years. enable generalize object identities unencountered situations objects similar types account indeterministic action effects noise.review several approaches together related work Section 2. Noisyindeterministic deictic (NID) rules (Pasula et al., 2007) capture world dynamicselegant compact way. particularly appealing learned effectivelyexperience. existing approach planning rules relies growingfull look-ahead trees grounded domain. Due large action spacestochasticity world, computational burden plan single actionmethod given situation overwhelmingly large. paper proposes two novelways reasoning efficiently grounded domain using learned NID rules, enabling fastplanning complex environments varying goals. First, apply existing UpperConfidence bounds applied Trees (UCT) algorithm (Kocsis & Szepesvari, 2006) NIDrules. contrast full-grown look-ahead trees, UCT samples actions selectively, therebycutting suboptimal parts tree early. Second, introduce Probabilistic RelationalAction-sampling DBNs planning Algorithm (PRADA) uses probabilistic inferencecope uncertain action outcomes. Instead growing look-ahead trees sampled successor states like previous approaches, PRADA applies approximate inferencetechniques propagate effects actions. particular, make three contributionsPRADA: (i) Following idea framing planning probabilistic inference problem (Shachter, 1988; Toussaint, Storkey, & Harmeling, 2010), convert NID rulesdynamic Bayesian network (DBN) representation. (ii) derive approximate inference method cope state complexity time-slice resulting network.Thereby, efficiently predict effects action sequences. (iii) planning basedsampling action-sequences, propose sampling distribution plans takes predicted state distributions account. evaluate planning approaches simulatedcomplex 3D robot manipulation environment realistic physics, articulated humanoid manipulating objects different types (see Fig. 4). domain contains billionsworld states large number potential actions. learn NID rules experienceenvironment apply planning approaches different planningscenarios increasing difficulty. Furthermore, provide results approachesplanning domains recent international probabilistic planning competition.purpose, discuss relation NID rules probabilistic planningdomain definition language (PPDDL) used specification domains.2fiPlanning Noisy Probabilistic Relational Rulesbegin paper discussing related work Section 2 reviewingbackground work, namely stochastic relational representations, NID rules, formalization decision-theoretic planning graphical models Section 3. Section 4,present two planning algorithms build look-ahead trees cope stochasticactions. Section 5, introduce PRADA uses approximate inference planning.Section 6, present empirical evaluation demonstrating utility planningapproaches. Finally, conclude outline future directions research.2. Related Workproblem decision-making planning stochastic relational domains approached different ways. field relational reinforcement learning (RRL) (Dzeroski,de Raedt, & Driessens, 2001; van Otterlo, 2009) investigates value functions Q-functionsdefined possible ground states actions relational domain. keyidea describe important world features terms abstract logical formulas enablinggeneralization objects situations. Model-free RRL approaches learn value functionsstates actions directly experience. Q-function estimators include relationalregression trees (Dzeroski et al., 2001) instance-based regression using distance metrics relational states graph kernels (Driessens, Ramon, & Gartner, 2006).Model-free approaches enable planning specific problem type used trainingexamples, e.g. on(X, ), thus may inappropriate situations goalsagent change quickly, e.g. on(X, ) inhand(X). contrast, model-based RRLapproaches first learn relational world model state transition experiencesuse model planning, example form relational probability treesindividual state attributes (Croonenborghs, Ramon, Blockeel, & Bruynooghe, 2007)SVMs using graph kernels (Halbritter & Geibel, 2007). stochastic relational NID rulesPasula et al. (2007) particularly appealing action model representation,shown empirically learn dynamics complex environments.probabilistic relational world model available (either learned handcrafted),one pursue decision-theoretic planning different ways. Within machine learningcommunity, popular direction research formalizes problem relational Markovdecision process (RMDP) develops dynamic programming algorithms compute solutions, i.e. policies complete state action spaces. Many algorithms reasonlifted abstract representation without grounding referring particular problem instances. Boutilier, Reiter, Price (2001) introduce Symbolic Dynamic Programming,first exact solution technique RMDPs uses logical regression constructminimal logical partitions state space required make necessary value functiondistinctions. approach implemented difficult keep firstorder state formulas consistent manageable size. Based ideas, Kersting, vanOtterlo, de Raedt (2004) propose exact value iteration algorithm RMDPs usinglogic-programming, called ReBel. employ restricted language represent RMDPsreason efficiently state formulas. Holldobler Skvortsova (2004)present first-order value iteration algorithm (FOVIA) using different restricted language.Karabaev Skvortsova (2005) extend FOVIA combining first-order reasoningactions heuristic search restricted states reachable initial3fiLang & Toussaintstate. Wang, Joshi, Khardon (2008) derive value iteration algorithm based usingfirst-order decision diagrams (FODDs) goal regression. introduce reduction operators FODDs keep representation small, may require complex reasoning;empirical evaluation provided. Joshi, Kersting, Khardon (2009) applymodel checking reduce FODDs generalize arbitrary quantification.techniques form interesting research direction reason exactlyabstract RMDPs. employ different methods ensure exact regression theorem proving, logical simplification, consistency checking. Therefore, principled approximations techniques discover good policies difficult domainslikewise worth investigating. instance, Gretton Thiebaux (2004) employ first-orderregression generate suitable hypothesis language use policy induction; thereby, approach avoids formula rewriting theorem proving, stillrequiring model-checking. Sanner Boutilier (2007, 2009) present first-order approximate linear programming approach (FOALP). Prior producing plans, approximatevalue function based linear combinations abstract first-order value functions,showing impressive results solving RMDPs millions states. Fern, Yoon,Givan (2006) consider variant approximate policy iteration (API) replacevalue-function learning step learning step policy space. make usepolicy-space bias described generic relational knowledge representation simulate trajectories improve learned policy. Kersting Driessens (2008) describenon-parametric policy gradient approach deal propositional, continuousrelational domains unified way.Instead working lifted representation, one may reason grounded domain.makes straightforward account two special characteristics NID rules:noise outcome uniqueness requirement rules. grounding RMDPspecifies rewards set goal states, one might principle apply traditional A.I. planning methods used propositional representations (Weld, 1999; Boutilier,Dean, & Hanks, 1999). Traditionally, planning often cast search problemstate action space, restricting oneself portion state space considered contain goal states reachable current state within limitedhorizon. Much research within planning community focused deterministic domains thus cant applied straightforwardly stochastic worlds. common approachprobabilistic planning, however, determinize planning problem apply deterministic planners (Kuter, Nau, Reisner, & Goldman, 2008). Indeed, FF-Replan (Yoon,Fern, & Givan, 2007) extension using hindsight optimization (Yoon, Fern, Givan, &Kambhampati, 2008) shown impressive performance many probabilistic planningcompetition domains. common variant FF-Replan considers probabilistic outcome action separate deterministic action, ignoring respective probabilities.runs deterministic Fast-Forward (FF) planner (Hoffmann & Nebel, 2001)determinized problem. FF uses relaxation planning problem: ignores deleteeffects actions applies clever heuristics prune search space. FF-Replan outputssequence actions expected states. time action execution leads stateplan, FF-Replan replan, i.e., recompute new plan scratchcurrent state. good performance FF-Replan many probabilistic domainsexplained structure problems (Little & Thiebaux, 2007).4fiPlanning Noisy Probabilistic Relational Rulesargued FF-Replan less appropriate domains probabilityreaching dead-end non-negligible outcome probabilities actions needtaken account construct good policy.Many participants recent probabilistic planning competition (IPPC, 2008)extend FF-Replan deal probabilities action outcomes (see competitionwebsite brief descriptions algorithms). winner competition, RFF(Teichteil-Konigsbuch, Kuter, & Infantes, 2010), computes robust policy offline generating successive execution paths leading goal using FF. resulting policylow probability failing. LPPFF uses subgoals generated determinizationprobabilistic planning problem divide smaller manageable problems. HMDPPsstrategy similar all-outcomes-determinization FF-Replan, accountsprobability associated outcome. SEH (Wu, Kalyanam, & Givan, 2008) extendsheuristic function FF-Replan cope local optima plans using stochasticenforced hill-climbing.common approach reasoning general reward-maximization contextavoids explicitly dealing uncertainty build look-ahead trees sampling successorstates. Two algorithms follow idea, namely SST (Kearns, Mansour, & Ng, 2002)UCT (Kocsis & Szepesvari, 2006), investigated paper.Another approach Buffet Aberdeen (2009) directly optimizes parameterizedpolicy using gradient descent. factor global policy simple approximate policiesstarting action sample trajectories cope probabilistic effects.Instead sampling state transitions, propose planning algorithm PRADApaper (based Lang & Toussaint, 2009a) accounts uncertainty principledway using approximate inference. Domshlak Hoffmann (2007) propose interestingplanning approach comes closest work. introduce probabilistic extension FF planner, using complex algorithms building probabilistic relaxed planninggraphs. construct dynamic Bayesian networks (DBNs) hand-crafted STRIPS operators reason actions states using weighted model counting. DBNrepresentation, however, inadequate type stochastic relational rules use,reasons naive DBN model discuss Sec. 5.1 inappropriate. Planning inference approaches (Toussaint & Storkey, 2006) spread informationalso backwards DBNs calculate posteriors actions (resulting policiescomplete state spaces). use backward propagation even full planninginference relational domains open issue.approaches working grounded representation common numberstates actions grow exponentially number objects. applydomains many objects, approaches need combined complementarymethods reduce state action space complexity relational domains.instance, one focus envelopes states high-utility subsets statespace (Gardiol & Kaelbling, 2003), one ground representation respectrelevant objects (Lang & Toussaint, 2009b), one exploit equivalence actions(Gardiol & Kaelbling, 2007), particularly useful combination ignoringcertain predicates functions relational logic language (Gardiol & Kaelbling, 2008).5fiLang & Toussaint3. Backgroundsection, set theoretical background planning algorithmspresent subsequent sections. First, describe relational representations define worldstates actions. present noisy indeterministic deictic (NID) rules detailthereafter define problem decision-theoretic planning stochastic relationaldomains. Finally, briefly review dynamic Bayesian networks.3.1 State Action Representationrelational domain represented relational logic language L: set logicalpredicates P set logical functions F contain relationships propertieshold domain objects. set logical predicates comprises possible actionsdomain. concrete instantiation relational domain made finite setobjects O. arguments predicate function concrete, i.e. taken O,call grounded. concrete world state fully described conjunction grounded(potentially negated) predicates function values. Concrete actions describedpositive grounded predicates A. arguments predicates functions alsoabstract logical variables represent object. predicate functionabstract arguments, call abstract. Abstract predicates functions enablegeneralization objects situations. speak grounding formulaapply substitution maps variables appearing objects O.relational model transition dynamics specifies P (s0 |a, s), probabilitysuccessor state s0 action performed state s. paper, usuallynon-deterministic distribution. typically defined compactly terms formulasabstract predicates functions. enables abstraction object identitiesconcrete domain instantiations. instance, consider set N cups: effects tryinggrab cups may described single abstract model insteadusing N individual models. apply given world state, one needs groundrespect objects domain. NID rules elegant way specifymodel described following.3.2 Noisy Indeterministic Deictic Ruleswant learn relational model stochastic world use planning. Pasulaet al. (2007) recently introduced appealing action model representation basednoisy indeterministic deictic (NID) rules combine several advantages:relational representation enabling generalization objects situations,indeterministic action outcomes probabilities account stochastic domains,deictic references actions reduce action space,noise outcomes avoid explicit modeling rare overly complex outcomes,existence effective learning algorithm.6fiPlanning Noisy Probabilistic Relational RulesTable 1 shows exemplary NID rule complex robot manipulation domain.Fig. 1 depicts situation rule used prediction. Formally, NID ruler givenpr,1: r,1 (X )...(1)ar (X ) : r (X ):r,mr (X )pr,mrpr,0: r,0X set logical variables rule (which represent (sub-)set abstractobjects). rules define world models formulas abstract, i.e.,arguments logical variables. rule r consists preconditions, namely actionar applied X state Pcontext r fulfilled, mr +1 different outcomesassociated probabilities pr,i 0, i=0 pr,i = 1. outcome r,i (X ) describespredicates functions change rule applied. context r (X ) outcomesr,i (X ) conjunctions (potentially negated) literals constructed predicatesP well equality statements comparing functions F constant values. Besidesexplicitely stated outcomes r,i (i > 0), so-called noise outcome r,0 models implicitlypotential outcomes rule. particular, includes rare overlycomplex outcomes typical noisy domains, want cover explicitlycompactness generalization reasons. instance, context rule depictedFig. 1 potential, highly improbable outcome grab blue cube pushingobjects table: noise outcome allows account without burdenexplicitly stating it.arguments action a(Xa ) may true subset Xa X variables Xrule. remaining variables called deictic references = X \ Xa denoteobjects relative agent action performed. Using deictic referencesadvantage decrease arity action predicates. turn reduces sizeaction space least order magnitude, significant effectsplanning problem. instance, consider binary action predicate worldn objects n2 groundings contrast unary action predicate ngroundings.above, let denote substitution maps variables constant objects, : X O.Applying abstract rule r(X ) yields ground rule r((X )). say ground rule rcovers state ground action |= r = ar . Let set ground NIDrules. define (a) := {r | r , ar = a} set rules provide predictionsaction a. r rule (a) cover state s, call unique covering rules. state-action pair (s, a) unique covering rule r, calculate P (s0 | s, a)taking outcomes r account weighted respective probabilities,r00P (s |s, a) = P (s |s, r) =Xpr,i P (s0 |r,i , s) + pr,0 P (s0 |r,0 , s),(2)i=1where, > 0, P (s0 | r,i , s) deterministic distribution one uniquestate constructed taking changes r,i account. distribution given7fiLang & ToussaintTable 1: Example NID rule complex robot manipulation scenario, modelstry grab ball X. cube implicitly defined one X (deicticreferencing). X ends robots hand high probability, mightalso fall table. small probability something unpredictable happens.Confer Fig. 1 example application.grab(X) : on(X, ), ball(X), cube(Y ), table(Z)0.7 : inhand(X), on(X, )0.2 : on(X, Z), on(X, )0.1 : noiseFigure 1: NID rule defined Table 1 used predict effects actiongrab(ball) situation left side. right side depicts possiblesuccessor states predicted rule. noise outcome indicatedquestion mark define unique successor state.noise outcome, P (s0 | r,0 , s), unknown needs estimated. Pasula et al. useworst case constant bound pmin P (s0 |r,0 , s) lower bound P (s0 |s, a). Alternatively,come well-defined distribution, one may assign low probability manysuccessor states. described detail Sec. 5.2, planning algorithm PRADAexploits factored state representation grounded relational domain achievepredicting state attribute change low probability.state-action pair (s, a) unique covering rule r (e.g. two rules cover(s, a) providing conflicting predictions), one predict effects meansnoisy default rule r explains effects changing state attributes noise:P (s0 |s, r ) = P (s0 | r ,0 , s). Essentially, using r expresses knowhappen. meaningful thus disadvantageous planning. (Hence, onebias NID rules learner learn rules contexts likely mutuallyexclusive.) reason, concept unique covering rules crucial planningNID rules. Here, pay price using deictic references: usingabstract NID rule prediction, always ensure deictic referencesunique groundings. may require examining large part state representation,8fiPlanning Noisy Probabilistic Relational Rulesproper storage ground state efficient indexing techniques logical formulaevaluation needed.ability learn models environment experience crucial requirementautonomous agents. problem learning rule-sets general NP-hard, efficiency guarantees sample complexity given many learning subtaskssuitable restrictions (Walsh, 2010). Pasula et al. (2007) proposed supervised batchlearning algorithm complete NID rules. algorithm learns structure ruleswell parameters experience triples (s, a, s0 ), stating observed successorstate s0 action applied state s. performs greedy search spacerule-sets. optimizes tradeoff maximizing likelihood experiencetriples minimizing complexity current hypothesis rule-set optimizingscoring metricXXS() =log P (s0 | s, rs,a )P EN (r) ,(3)(s,a,s0 )rrs,a either unique covering rule (s, a) noisy default rule rscaling parameter controls influence regularization. P EN (r) penalizescomplexity rule defined total number literals r.noise outcome NID rules crucial learning. learning algorithm initialized rule-set comprising noisy default rule r iteratively addsnew rules modifies existing ones using set search operators. noise outcomeallows avoiding overfitting, need model rare overly complex outcomesexplicitly. drawback successor state distribution P (s0 | r,0 , s) unknown.deal problem, learning algorithm uses lower bound pmin approximatedistribution, described above. algorithm uses greedy heuristics attemptlearn complete rules, guarantees behavior given. Pasula et al., however, report impressive results complex noisy environments. Sec. 6.1, confirmresults simulated noisy robot manipulation scenario. major motivation employing NID rules learn observed actions state transitions.Furthermore, planning approach PRADA exploit simple structure (whichsimilar probabilistic STRIPS operators) convert DBN representation.provide detailed comparison NID rules PPDDL Appendix B. NIDrules support features sophisticated domain description languagePPDDL, compactly capture dynamics many interesting planning domains.3.3 Decision-Theoretic Planningproblem decision-theoretic planning find actions given stateexpected maximize future rewards states actions (Boutilier et al., 1999).classical planning, reward usually defined terms clear-cut goaleither fulfilled fulfilled state. expressed means logicalformula . Typically, formula partial state description existsone state holds. example, goal might put romancebooks specific shelf, matter remaining books lying. case,planning involves finding sequence actions executing starting9fiLang & Toussaintresult world state s0 s0 |= . stochastic domains, however, outcomesactions uncertain. Probabilistic planning inherently harder deterministiccounterpart (Littman, Goldsmith, & Mundhenk, 1997). particular, achieving goalstate certainty typically unrealistic. Instead, one may define lower boundprobability achieving goal state. second source uncertainty next uncertainaction outcomes uncertainty initial state s. ignore latterfollowing always assume deterministic initial states. see later, however,straightforward incorporate uncertainty initial state using one proposedplanning approaches.Instead classical planning task finished achieved stategoal fulfilled, task may also ongoing. instance, goal mightkeep desktop tidy. formalized means reward function states,yields high reward desirable states (for simplicity, assume rewardsdepend actions). approach taken reinforcement learning formalisms(Sutton & Barto, 1998). Classical planning goals easily formalizedreward function. cast scenario planning stochastic relational domainrelational Markov decision process (RMDP) framework (Boutilier et al., 2001). follownotation van Otterlo (2009) define RMDP 4-tuple (S, A, T, R). contrastenumerated state spaces, state space relational structure definedlogical predicates P functions F, yield ground atoms arguments takenset domain objects O. action space defined positive predicatesarguments O. : [0, 1] transition distribution R : Rreward function. R make use factored relational representationabstract states actions, discussed following. Typically,state space action space relational domain large. Considerinstance domain 5 objects use 3 binary predicates represent states:2case, number states 235 = 275 . Relational world models encapsulate transitionprobabilities compact way exploiting relational structure. example, NID rulesdescribed Eq. (2) achieve generalized partial world state descriptionsform conjunctions abstract literals. compactness models, however,carry directly planning problem.(deterministic) policy : tells us action take given state.fixed horizon discount0 < < 1, interested maximizingPd factorr . value factored state defineddiscounted total reward r =t=0expected return state following policy :V (s) = E[r | s0 = s; ] .(4)solution RMDP, thus problem planning, optimal policymaximizes expected return. defined Bellman equation:XV (s) = R(s) + max[P (s0 | s, a)V (s0 )] .aA10s0(5)fiPlanning Noisy Probabilistic Relational RulesSimilarly, one define value Q (s, a) action state expected returnaction taken state s, using policy select subsequent actions:Q (s, a) = E[r | s0 = s, a0 = a; ]X= R(s) +V (s0 )P (s0 | s, a) .(6)(7)s0Q-values optimal policy let us define optimal action optimalvalue state= argmax Q (s, a)(8)aAV (s) = max Q (s, a) .aA(9)enumerated unstructured state spaces, state Q-values computed using dynamic programming methods resulting optimal policies complete state space.Recently, promising approaches exploiting relational structure proposed apply similar ideas solve approximate solutions RDMPs abstract level (withoutreferring concrete objects O) (see related work Sec. 2). Alternatively, one mayreason grounded relational domain. makes straightforward accountnoise outcome uniqueness requirement NID rules. Usually, one focuses estimating optimal action values given state. approach appealing agentsvarying goals, quickly coming plan problem handappropriate computing abstract policy complete state space. Althoughgrounding simplifies problem, decision-theoretic planning propositionalized representation challenging task complex stochastic domains. Sections 4 5,present different algorithms reasoning grounded relational domain estimatingoptimal Q-values actions (and action-sequences) given state.3.4 Dynamic Bayesian NetworksDynamic Bayesian networks (DBNs) model development stochastic systemstime. PRADA planning algorithm introduce Sec. 5 makes usekind graphical model evaluate stochastic effects action sequences factoredgrounded relational world states. Therefore, briefly review Bayesian networksdynamic extension here.Bayesian network (BN) (Jensen, 1996) compact representation joint probability distribution set random variables X means directed acyclic graphG. nodes G represent random variables, edges define dependencies thereby express conditional independence assumptions. value x variableX X depends values immediate ancestors G, calledparents P a(X) X. Conditional probability functions node define P (X | P a(X)).case discrete variables, may defined form conditional probability tables.BN compact representation distribution X nodesparents conditional probability functions significant local structure.play crucial role development graphical models PRADA.11fiLang & ToussaintDBN (Murphy, 2002) extends BN formalism model dynamic system evolvingtime. Usually, focus discrete-time stochastic processes. underlyingsystem (in case, world state) represented BN B, DBN maintainscopy BN every time-step. DBN defined pair BNs (B0 , B ),B0 (deterministic uncertain) prior defines state systeminitial state = 0, B two-slice BN defines dependencies twosuccessive time-steps + 1. implements first-order Markov assumption:variables time + 1 depend variables time + 1 variables t.4. Planning Look-Ahead Treesplan NID rules, one treat domain describedulary relational Markov decision process discussed Sec.present two value-based reinforcement learning algorithmsgenerative model build look-ahead trees starting initialused estimate values actions states.relational logic vocab3.3. following,employ NID rulesstate. trees4.1 Sparse Sampling TreesSparse Sampling Tree (SST) algorithm (Kearns et al., 2002) MDP planning samplesrandomly sparse, full-grown look-ahead trees states starting given stateroot. suffices compute near-optimal actions state MDP. Givenplanning horizon branching factor b, SST works follows (see Fig. 2): treenode (representing state), (i) SST takes possible actions account, (ii)action takes b samples successor state distribution using generative modeltransitions, e.g. transition model MDP, build tree nodes nextlevel. Values tree nodes computed recursively leaves root usingBellman equation: given node, Q-value possible action estimatedaveraging values b children states action; then, maximizingQ-value actions chosen estimate value given node. SSTfavorable property independent total number states MDP,examines restricted subset state space. Nonetheless, exponentialtime horizon taken account.Pasula et al. (2007) apply SST planning NID rules. sampling noiseoutcome planning SST, assume stay state, discountestimated value. refer adaptation speak SST planningremainder paper. action unique covering rule, use noisydefault rule r predict effects. always better perform othing actioninstead staying state get punished. Hence, SST planning onediscard actions given state unique covering rules.SST near-optimal, practice feasible small branching factorb planning horizon d. Let number actions a. number nodeshorizon (ba)d . (This number reduced outcome rule sampledmultiple times.) illustration, assume 10 possible actions per time-stepset parameters = 4 b = 4 (the choice Pasula et al. experiments). plansingle action given state, one visit (10 4)4 = 2, 560, 000 states. smaller12fiPlanning Noisy Probabilistic Relational RulesFigure 2: SST planning algorithm samples sparse, full-grown look-ahead treesestimate values actions states.choices b lead faster planning, result significant accuracy loss realisticdomains. Kearns et al. note, SST useful special structure permitscompact representation available. Sec. 5, introduce alternative planningapproach based approximate inference exploits structure NID rules.4.2 Sampling Trees Upper Confidence BoundsUpper Confidence Bounds applied Trees (UCT) algorithm (Kocsis & Szepesvari,2006) also samples search tree subsequent states starting current state root.contrast SST generates b successor states every action state, ideaUCT choose actions selectively given state thus sample selectivelysuccessor state distribution. UCT tries identify large subsets suboptimal actions earlysampling procedure focus promising parts look-ahead tree instead.UCT builds look-ahead tree repeatedly sampling simulated episodesinitial state using generative model, e.g. transition model MDP. episodesequence states, rewards actions limited horizon d: s0 , r0 , a1 , s1 , r1 , a2 . . . sd , rd .simulated episode, values tree nodes (representing states) updatedonline simulation policy improved respect new values. result,distinct value estimated state-action pair tree Monte-Carlo simulation.precisely, UCT follows following policy tree node s: exist actionsexplored yet, UCT samples one using uniformdistribution. Otherwise, actions explored least once, UCT selectsaction maximizes upper confidence bound QOU CT (s, a) estimated action13fiLang & Toussaintvalue QU CT (s, a),QOU CT (s, a)= QU CT (s, a) + clog ns,ns,aU CT (s) = argmax QOU CT (s, a) ,(10)(11)ns,a counts number times actionPa selected state s, nscounts total number visits state s, ns = ns,a . bias parameter c definesinfluence number previous action selections thereby controls extentupper confidence bound.end episode, value encountered state-action pair (st , ), 0< d, updated using total discounted rewards:nst ,at nst ,at + 1 ,QU CT (st , ) QU CT (st , ) +(12)1nst ,atX[0rt0 QU CT (st , )] .(13)t0 =tpolicy UCT implements exploration-exploitation tradeoff: balancesexploring currently suboptimal-looking actions selected seldom thus farexploiting currently best-looking actions get precise estimates values.total number episodes controls accuracy UCTs estimates balancedoverall running time.UCT achieved remarkable results challenging domains game Go(Gelly & Silver, 2007). best knowledge, first apply UCTplanning stochastic relational domains, using NID rules generative model. adaptUCT cope noise outcomes fashion SST: assume staystate discount obtained rewards. Thus, UCT takes actions uniquecovering rules account, reasons SST does.5. Planning Approximate InferenceUncertain action outcomes characterize complex environments, make planning relational domains substantially difficult. sampling-based approaches discussedprevious section tackle problem repeatedly generating samples outcomedistribution action using transition probabilities MDP. leads lookahead trees easily blow planning horizon. Instead sampling successorstates, one may maintain distribution states, so-called belief. following,introduce approach planning grounded stochastic relation domains propagates beliefs states sense state monitoring. First, show createcompact graphical models NID rules. develop approximate inference methodefficiently propagate beliefs. hand, describe Probabilistic RelationalAction-sampling DBNs planning Algorithm (PRADA), samples action-sequencesinformed way evaluates using approximate inference DBNs. Then,example presented illustrate reasoning PRADA. Finally, discuss PRADAcomparison approaches previous section, SST UCT, present simpleextension PRADA.14fiPlanning Noisy Probabilistic Relational Rules(a)(b)Figure 3: Graphical models NID rules: (a) Naive DBN; (b) DBN exploiting NID factorization5.1 Graphical Models NID RulesDecision-theoretic problems agents need choose appropriate actions represented means Markov chains dynamic Bayesian networks (DBNs)augmented decision nodes specify agents actions (Boutilier et al., 1999).following, discuss convert NID rules DBNs PRADA algorithmuse plan probabilistic inference. denote random variables upper case letters(e.g. S), values corresponding lower case letters (e.g., dom(S)), variablevectors bold upper case letters (e.g. = (S1 , S2 , S3 )) value vectors bold lowercase letters (e.g. = (s1 , s2 , s3 )). also use column notation, e.g. s2:4 = (s2 , s3 , s4 ).naive way convert NID rules DBNs shown Fig. 3(a). States representedvector = (S1 , . . . , SN ) ground predicate P binary Siground function F Sj range according representedfunction. Actions represented integer variable indicates actionvector ground action predicates A. reward gained state representedU may depend subset state variables. possible expressarbitrary reward expectations P (U | S) binary U (Cooper, 1988). definetransition dynamics using NID rules naive model? Assume given setfully abstract NID rules. compute groundings rules w.r.t. objectsdomain get set K different ground NID rules. parents state variableSi0 successor time-step include action variable respective variable Sipredecessor time-step. parents Si0 determined follows:rule r literal corresponding Si0 appears outcomes r, variablesSk corresponding literals preconditions r parents Si0 . typically Si0manipulated several actions turn modeled several rules, totalnumber parents Si0 large. problem worsened usage deicticreferences NID rules, increase total number K ground rules .resulting local structure conditional probability function Si0 complex, oneaccount uniqueness covering rules. complex dependenciestwo time-slices make representation unfeasible planning.15fiLang & ToussaintTherefore, exploit structure NID rules model state transitioncompact graphical model shown Fig. 3(b) representing joint distributionP (u0 , s0 , o, r, | a, s)=P (u0 | s0 ) P (s0 | o, r, s) P (o | r) P (r | a, ) P ( | s) ,(14)explain detail following. before, assume given setfully abstract NID rules, compute set K different ground NID rulesw.r.t. objects domain. addition S, S0 , A, U U 0 above, usebinary random variable rule model event context holds,case required literals hold. Let I() indicator function 1argument evaluates true 0 otherwise. Then,KK^P ( | s) =P (i |s(i ) ) =Sj = sri ,j .(15)i=1i=1j(i )Vuse express logical conjunction 1 n . function () yields setindices state variables s, depends. sri denotes configurationstate variables corresponding literals context ri . use integer-valuedvariable R ranging K +1 possible values identify rule predicts effectsaction. exists, unique covering rule current state-action pair,i.e., rule r (a) modeling action whose context holds:^P (R = r|a, ) = r (a) r = 1r 0 = 0 .(16)r0 (a)\{r}unique covering rule exists, predict changes indicated special valueR = 0 (assuming execute action, similarly SST UCT do):^^P (R = 0 | a, ) =r = 1r 0 = 0 .(17)r0 (a)\{r}r(a)integer-valued variable represents outcome action predictedrule. ranges possible values maximum number outcomesrules have. ensure sound semantics, introduce empty dummy outcomeszero-probability rules whose number outcomes less . probabilityoutcome defined corresponding rule:P (O = | r) = pr,o .define probability successor stateP (s0 | o, s, r) =P (s0i | o, si , r) ,(18)(19)one unique state constructed taking changes accordingr,o account: outcome specifies value Si0 , value probability16fiPlanning Noisy Probabilistic Relational Rulesone. Otherwise, value state variable persists previous time-step.rules usually change small subset s, persistence often applies. resultingdependency P (s0i | o, r, si ) variable Si0 time-step + 1 compact. contrastnaive DBN Fig. 3(a), three parents, namely variables outcome,rule predecessor previous time-step. simplifies specificationconditional probability function 0 significantly enables efficient inference,see later. probability reward given^P (U 0 = 1 | s0 ) =Sj0 = j .(20)j(U 0 )function (U 0 ) yields set indices state variables s0 , U 0 depends.configuration variables corresponds planning goal denoted. Uncertain initial states naturally accounted specifying priors P (s0 ).renounce specification prior here, however, initial state s0 always givenexperiments later enable comparison look-ahead tree based approaches SSTUCT require deterministic initial states (which might also sampledprior). choice distribution P (a) used sampling actions describedSec. 5.3.simplicity ignored derived predicates functions definedterms predicates functions presentation graphical model. Derivedconcepts may increase compactness rules. dependencies among concepts acyclic,straightforward include derived concepts model intra-state dependenciescorresponding variables. Indeed, use derived predicates experiments.interested inferring posterior state distributions P (st | a0:t1 ) given sequence previous actions (where omit conditioning initial state simplicity).Exact inference intractable graphical model. constructing junction tree,get cliques comprise whole Markov slices (all variables representing statecertain time-step): consider eliminating state variables St+1 . Due moralization,outcome variable connected state variables St . elimination O,variables St form clique. Thus, make use approximate inferencetechniques. General loopy belief propagation (LBP) unfeasible due deterministicdependencies small cycles inhibit convergence. also conducted preliminary tests small networks damping factor, without success. interestingopen question whether ways alternate propagating deterministic information running LBP remaining parts network, e.g., whether methodsMC-SAT (Poon & Domingos, 2007) successfully applied decision-making contexts ours. next subsection, propose different approximate inference schemeusing factored frontier (FF). FF algorithm describes forward inference procedurecomputes exact marginals next time-step subject factored approximationprevious time-step. Here, advantage exploit structureinvolved DBNs come formulas marginals. FF related passingforward messages. contrast LBP, information propagated backwards. Noteapproach condition rewards (as full planning inference) samplesactions, backward reasoning uninformative.17fiLang & Toussaint5.2 Approximate Inferencefollowing, present efficient method approximate inference previouslyproposed DBNs exploiting factorization NID rules. focus mathematicalderivations. illustrative example provided Sec. 5.4.follow idea factored frontier (FF) algorithm (Murphy & Weiss, 2001)approximate belief product marginals:P (st | a0:t1 )P (sti | a0:t1 ) .(21)define(sti ) := P (sti | a0:t1 )(st ) := P (st | a0:t1 )N(22)(sti )(23)i=1derive FF filter DBN model Fig. 3(b). interested inferringstate distribution time + 1 given action sequence a0:t calculate marginalsstate attributest+1(st+1| a0:t )) = P (siX=P (st+1| rt , a0:t1 ) P (rt | a0:t ) .(24)(25)rtEq. (25), use rules prediction, weighted respective posteriors P (rt | a0:t ).reflects fact depending state use different rules modelaction. weight P (rt | a0:t ) 0 rules modeling action . remainingrules model , weights correspond posterior partsstate space according rule used prediction.compute first term (25)XP (st+1| rt , a0:t1 ) =P (st+1| rt , sti ) P (sti | rt , a0:t1 )stiXP (st+1| rt , sti ) (sti ) .(26)stiHere, sum possible values variable Si previous time-step t. Intuitively, take account potential pasts arrive value st+1next, st ) enables us easily predict probabilitiestime-step. resulting term P (st+1|rnext time-step discussed below. prediction weighted marginal(sti ) respective previous value. approximation (26) assumes sti conditionally independent rt . true general choice rule predictiondepends current state thus also attribute Si . improve approximation one examine whether sti part context rt : case, inferstate sti knowing rt . However, found approximation sufficient.18fiPlanning Noisy Probabilistic Relational Rulesone would expect, calculate successor state distribution P (st+1| rt , sti )taking different outcomes r account weighted respective probabilitiesP (o | rt ),XP (st+1| rt , sti ) =P (st+1| o, rt , sti ) P (o | rt ) .(27)shows us update belief Sit+1 predict rule rt . P (st+1| o, rt , sti )t+1deterministic distribution. changes value Si , si set accordingly. Otherwise, value sti persists.Lets turn computation second term Eq. (25), P (rt | a0:t ), posteriorrules. trick use context variables exploit assumptionrule r models state transition uniquely covers (at , st ), indicatedappropriate assignment . reduced expressioninvolving marginals (). startXP (Rt = r | a0:t ) =P (Rt = r | , a0:t ) P (t | a0:t )^= I(r (at )) P tr = 1,tr0 = 0 | a0:t1r0 (at )\{r}^= I(r (at )) P (tr = 1 | a0:t1 ) Ptr0 = 0 | tr = 1, a0:t1 .r0 (at )\{r}(28)simplify summation , consider unique assignmentcontext variables r used prediction: provided models action, indicatedI(r (at )), case context tr holds, contexts tr0competing rules r0 action hold.calculate second term (28) summing statesXXP (tr = 1 | a0:t1 ) =P (tr = 1 | st ) (st )P (tr = 1 | st )(stj )(29)st=st(Sjt = sr,j ).j(30)j(tr )approximation (29) FF assumption. (30), sr denotes configurationstate variables according context r like (15). sum variablescontext r. variables rs context remain: terms (Sjt = sr,j ) correspondprobabilities respective literals.third term (28) joint posterior contexts competing rules r0given rs context already holds. interested situation nonecontexts hold. calculate^Ptr0 = 0 | tr = 1, a0:t1P (tr0 = 0 | tr = 1, a0:t1 ) ,(31)r0 (at )\{r}r0 (at )\{r}19fiLang & Toussaintapproximating product individual posteriors. latter computedXP (tr0 = 0 | tr = 1, a0:t1 ) =P (tr0 = 0 | st ) P (st | tr = 1, a0:t1 )(32)r r01.0 Q1.0 i(t ), (Si = sr0 ,i ) otherwise,r0(33)i6(r )if-condition expresses logical contradiction contexts r r0 .contexts contradict, r0 context surely hold given rs context holds.Otherwise, know state attributes apppearing contexts r r0hold condition r = 1. Therefore, examine remaining stateattributes r0 context. Again, approximate posterior FF marginals.Finally, compute reward probability straightforwardlyXP (U = 1 | st )P (st | a0:t1 , s0 )(Sit = ) ,(34)P (U = 1 | a0:t1 ) =sti(U )denotes configuration state variables corresponding planning goal(20). above, summation states simplified FF assumption resultingproduct marginals required state attributes.overall computational costs propagating effects action quadraticnumber rules action (for rule calculate probabilitynone others applies) linear maximum numbers context literalsmanipulated state attributes rules.inference framework requires approximation distribution P (s0 | r,0 , s)(cf. Eq. (2)) cope noise outcome NID rules. training data usedlearn rules, estimate predicates functions change value time follows: letSc contain corresponding variables. estimate rule r average numberN r changed state attributes noise outcome applies. Due factored frontierapproach, consider noise effects variable independently. approximaterprobability Si Sc changes rs noise outcome | SNC | . case change,changed values Si equal probability.5.3 PlanningDBN representation Fig. 3(b) together approximate inference method described last subsection enable us derive novel planning algorithm stochasticrelational domains: Probabilistic Relational Action-sampling DBNs planning Algorithm (PRADA) plans sampling action sequences informed way based predictedbeliefs states evaluating action sequences using approximate inference.precisely, sample sequences actions a0:T 1 length . 0 < ,infer posteriors states P (st | a0:t1 , s0 ) rewards P (ut | a0:t1 , s0 ) (in sensefiltering state monitoring). Then, calculate value action sequencediscount factor 0 < < 1Q(s0 , a0:T 1 ) :=XP (U = 1 | a0:t1 , s0 ) .t=020(35)fiPlanning Noisy Probabilistic Relational Ruleschoose first action best sequence = argmaxa0:T 1 Q(a0:T 1 , s0 ),value exceeds certain threshold (e.g., = 0). Otherwise, continue sampling actionsequences either action found planning given up. quality foundplan controlled total number action-sequence samples tradedtime available planning.aim strategy sample good action sequences high probability.propose choose equal probability among actions unique coveringrule current state. Thereby, avoid use noisy default rule rmodels action effects noise thus poor use planning. action time t,PRADA samples distribution^Xtr0 = 0 | a0:t1 .(36)P tr = 1,Psample(a)r(a)r0 (a)\{r}sum rules action a: rule add posteriorunique covering rule, i.e. context tr holds, contexts tr0 competingrules r0 hold. sampling distribution takes current state distributionaccount. Thus, probability sample action sequence predicting state sequences0 , . . . , sT depends likelihood state sequence given a: likely required outcomes are, likely next actions sampled. Using policy,PRADA miss actions SST UCT explore, following propositionstates (proof Appendix A).Proposition 1: set action sequences PRADA samples non-zero probabilitysuper-set ones SST UCT.experiments, replan action executed without reusing knowledge previous time-steps. simple strategy helps get general impressionPRADAs planning performance complexity. strategies easily conceivable.instance, one might execute entire sequence without replanning, trading fastercomputation times potential loss achieved reward. noisy environments,might seem better strategy combine reuse previous plans replanning.instance, one could omit first action previous plan, executed,examine suitability remaining actions new state. considersingle best action sequence, many planning domains might also beneficialmarginalize sequences first action. instance, action a1might lead number reasonable sequences, none best, anotheraction a2 first one good sequence, also many bad ones case onemight favor a1 .5.4 Illustrative ExampleLet us consider small planning problem Table 2 illustrate reasoning procedurePRADA. domain noisy cubeworld represented predicates table(X), cube(X),on(X, ), inhand(X) clear(X) Y.on(Y, X) robot perform two typesactions: may either lift cube X means action grab(X) put cube21fiLang & Toussaintheld hand top another object X using puton(X). start state s0 shown 2(a)contains three cubes a, b c stacked pile table t. goal shown 2(b)get middle cube b on-top top cube a. world model provides three abstractNID rules predict action effects, shown Table 2(c). first rule uncertainoutcomes: models grab object another object. contrast, grabbingclear object (Rule 2) putting object somewhere (Rule 3) always leadssuccessor state.First, PRADA constructs DBN represent planning problem. purpose,computes grounded rules respect objects = {a, b, c, t} shown 2(d).potential grounded rules ignored: one deduce abstract rulespredicates changeable. combination specifications s0 , prunesgrounded rules. instance, know s0 table. Thus, ground ruleaction argument X = needs constructed rules require cube(X).Based DBN, PRADA samples action-sequences evaluates expectedrewards. following, investigate procedure sampling action-sequence(grab(b), puton(a)). Table 2(e) presents inferred values DBN variablesauxiliary quantities. marginals (Eq. (22)) state variables = 0set deterministically according s0 . calculate posteriors context variablesP ( | a0:t1 ) according Eq. (30). example, = 0 one ruleprobability 1.0 actions grab(a), grab(b) grab(c). contrast,rules non-zero probability various puton() actions. help Eq. (33),calculate probability rule r unique covering rule respectiveaction (listed Unique rule; note condition fixed action thusfar): case context r r holds, contexts r0 competing rulesr0 action hold. = 0, posterior r alone.resulting probabilities used calculate sampling distribution Eq. (36): first,compute probability action unique covering rule simplesum probabilities previous step (listed Action coverage table); then,normalize values get sampling distribution Psample (). = 0, resultssampling distribution uniform three actions unique rules. Assumesample a0 = grab(b) (grabbing blue cube b). Variable R specifies ground rulesuse predicting state marginals next time-step. infer posterioraccording Eq. (28). Here, P (R0 = (1, b/act) | a0 ) = 1.0.Things get interesting = 1. Here, observe effects factoredfrontier. instance, consider calculating posterior context r ground ruler = (1, b/att) (grabbing blue cube b yellow a) using Eq. (30),P ((1,b/att) | a0 ) (on(a, b)) (on(b, t)) (cube(a)) (cube(b)) (table(t))= 0.2 0.2 1.0 1.0 1.0 = 0.04.contrast, exact value P ((1,b/att) | a0 ) = 0.2, according third outcomeabstract Rule 1 used predict a0 . imprecision due ignoring correlations: FFregards marginals on(a, b) on(b, t) independent, fact fullycorrelated.= 1, action grab(a) three ground rules non-zero context probabilities(grabbing either b, c t). due three different outcomes abstract22fiPlanning Noisy Probabilistic Relational RulesTable 2: Example PRADAs factored frontier inference(a) Start states0 = {on(a, b), on(b, c), on(c, t),cube(a), cube(b), cube(c), table(t)}(b) Goal= {on(b, a)}(c) Abstract NID rules example situationsRule 1:grab(X) : on(Y, X), on(X, Z), cube(X), cube(Y ), table(T )0.5 : inhand(X), on(Y, Z), on(Y, X), on(X, Z)0.3 : inhand(X), on(Y, ), on(Y, X), on(X, Z)0.2 : on(X, ), on(X, Z)Rule 2:grab(X) : cube(X), clear(X), on(X, )1.0 : inhand(X), on(X, )(e) Inferred posteriors PRADAsFFinferenceaction-sequence(grab(b), puton(a))t=0t=1t=2State marginalson(a, b)on(a, c)on(a, t)on(b, a)on(b, c)on(b, t)on(c, t)inhand(b)clear(a)clear(b)clear(c)Goal U1.00.00.00.01.00.01.00.01.00.00.00.00.20.50.30.00.00.21.00.81.00.80.50.00.20.50.30.80.00.21.00.160.20.80.50.8P ( | a0:t1 )(1,b/act)(1,b/att)(1,c/btt)(2,a/b)(2,a/c)(2,a/t)(2,b/t)(2,c/t)(3,a/b)(3,c/b)(3,t/b)1.00.01.01.00.00.00.00.00.00.00.00.00.040.50.20.50.30.160.50.80.80.8Unique rule(1, b/act)1.00.0(1, b/att)0.0 0.0336(1, c/att)0.00.25(1, c/btt)1.00.0(2, a/b)1.00.07(2, a/c)0.00.28(2, a/t)0.00.12(2, b/t)0.0 0.154(2, c/t)0.00.25(3, a/b)0.00.8(3, c/b)0.00.8(3, t/b)0.00.8Action coveragegrab(a)1.00.47grab(b)1.0 0.187grab(c)1.00.5puton(a)0.00.8puton(c)0.00.8puton(t)0.00.8Sample distributionPsample (grab(a))0.33 0.132Psample (grab(b))0.33 0.0526Psample (grab(c))0.33 0.141Psample (puton(a))0.0 0.225Psample (puton(c))0.0 0.225Psample (puton(t))0.0 0.225P (Rt = rt | a0:t )Rt = (1, b/act)1.00.0Rt = (3, a/b)0.00.8Rt = 00.00.2Rule 3:puton(X) : inhand(Y ), cube(Y )1.0 : on(Y, X), inhand(X)(d) Grounded NID rulesGrounded Rule ActionSubstitution(1, a/bbt)grab(a) {X a, b, Z b, t}(1, a/bct)grab(a) {X a, b, Z c, t}...(1, c/bbt)grab(c) {X c, b, Z b, t}(2, a/b)grab(a){X a, b}(2, a/c)grab(a){X a, c}(2, a/t)grab(a){X a, t}...(2, c/t)grab(c){X c, t}(3, a/b)puton(a){X a, b}(3, a/c)puton(a){X a, c}...(3, t/c)puton(t){X a, c}23fiLang & ToussaintRule 1. example, calculate probability rule (2, a/c) (grabbing c)unique covering rule grab(a) = 1P ((2,a/c) ,(2,a/b) , (2,a/t) | a0 )P ((2,a/c) | a0 ) (1. P ((2,a/b) | a0 )) (1. P ((2,a/t) | a0 ))= 0.5 (1. 0.2) (1. 0.3) = 0.28 .calculations, determine sampling distribution = 1. Assumesample action puton(a). results rule (3/a, b) (putting b a) usedprediction 0.8 probability since probability unique covering ruleaction puton(a). remaining mass 0.2 posterior assigned partsstate space unique covering rule available puton(a). case, usedefault rule R = 0 (corresponding performing action) probability0.2 values state variables persist.Finally, let us infer marginals = 2 using Eq. (25). example, calculate(inhand(b)t=2 ). Let i(b) brief inhand(b). sum ground rules rt=1 takingpotential values i(b)t=1 i(b)t=1 previous time-step = 1 account,X(i(b)t=2 )P (rt=1 | a0:1 ) ( P (i(b)t=2 | rt=1 , i(b)t=1 ) (i(b)t=1 )rt=1+ P (i(b)t=2 | rt=1 , i(b)t=1 ) (i(b)t=1 ) )= 0.8 (0.0 0.2 + 0.0 0.8) + 0.2 (0.0 0.2 + 1.0 0.8) = 0.16 .discussed above, ground rule (3/a, b) default rule play roleprediction. effect, belief b inhand decreases 0.8 0.16 triedput b a, expected. Similarly, calculate posterior on(b, a) 0.8.also expected probability reach goal performing actions grab(b)puton(a). (Here, PRADAs inferred value coincides true posterior.)comparison, probability reach goal 1.0 performing actionsgrab(a), puton(t), grab(b) puton(a), i.e., clear b grab it. plansafer, i.e., higher probability, takes actions.5.5 Comparison Planning Approachesprominent difference presented planning approaches wayaccount stochasticity action effects. one hand, SST UCT repeatedly take samples successor state distributions estimate value actionbuilding look-ahead trees. hand, PRADA maintains beliefs statespropagates indetermistic action effects forward. precisely, PRADA SST followopposite approaches: PRADA samples actions calculates state transitions approximately means probabilistic inference, SST considers actions (and thus exactaction search) samples state transitions. price considering actionsSSTs overwhelmingly large computational cost. UCT remedies issue samples action sequences thus state transitions selectively: uses previously sampled episodesbuild upper confidence bounds estimates action values specific states,used adapt policy next episode. straightforward translate24fiPlanning Noisy Probabilistic Relational Rulesadaptive policy PRADA since PRADA works beliefs states instead statesdirectly. Therefore, chose simple policy PRADA sample randomlyactions unique covering rule state (in form sampling distributionaccount beliefs states).PRADA returns whole plan transform world state one goalfulfilled probability exceeding given threshold , spirit conformant planning probabilistic planning observability (Kushmerick, Hanks, & Weld, 1995).Due outcome-sampling, SST UCT cannot return plan straightforward way. Instead, provide policy many successor states based estimatesaction-values look-ahead tree. estimates states deeper treeless reliable built less episodes. action executednew state observed, estimates reused. Thus far, PRADA takeknowledge gained previous action-sequence samples account adapt policy.elegant way achieve better exploit goal knowledge might use backpropagationDBNs plan completely inference (Toussaint & Storkey, 2006).beyond scope paper, clear principled waylarge state action spaces relational domains. Alternatively, PRADA could give highweight second action previous best plan. Sec. 5.6, show anothersimple way make use previous episodes find better plans.PRADA afford simple action-sampling strategy evaluates large numbersaction-sequences efficiently grow look-ahead trees accountindeterministic effects. points important difference: three algorithms facedsearch spaces action sequences exponential horizon. calculatevalue given action sequence, however, SST UCT still need exponential time dueoutcome sampling. contrast, PRADA propagates state transitions forwardthus linear horizon.Like approximate planning algorithms, neither SST, UCT PRADA expected perform ideally situations. SST UCT sample action outcomes henceface problems important outcomes small probability. instance, consideragent wants escape room two locked doors. hits first doormade wood chance 0.05 break escape. second door madeiron chance 0.001 break. SST UCT may take long timedetect 50 times better repeatedly hit wooden door. contrast, PRADArecognizes immediately reasoned actions takesoutcomes account. hand, PRADAs approximate inference procedure correlations among state variables get lost SST UCT preservesample complete successor states. impair PRADAs planning performancesituations correlations crucial. Consider following simple domain twostate attributes b. agent choose two actions modeled rulesaction1 :action2 :0.5 : a, b,0.5 : a, b0.5 : a, b0.5 : b,25.fiLang & Toussaintgoal make attributes either true false, i.e., = (a b) (a b).actions, resulting marginals (a) = 0.5, (a) = 0.5, (b) = 0.5(b) = 0.5. Due factored frontier, PRADA cannot distinguish actionsalthough action1 achieve goal, action2 not.PRADAs estimated probabilities states rewards may differ significantlytrue values. harm performance many domains experimentsindicate (Sec. 6). suppose reason PRADAs estimated probabilities imprecise, enable correct ranking action sequences planning,interested choosing best action instead calculating correctly value.difference proposed algorithms way handle noiseoutcome rules: PRADA assigns small probability successor states spiritnoise outcome. contrast, SST UCT make sense sampledistribution, single successor state extremely low probabilityinadequate estimate state action values. Hence, use described workaroundassume stay state, discounting obtained rewards.straightforward PRADA deal uncertain initial states. Uncertaintyinitial states common complex environments may instance caused partialobservability noisy sensors. uncertainty natural representation beliefstate PRADA works on. contrast, SST UCT cannot account uncertain initialstates directly, would sample prior distribution.5.6 Extension: Adaptive PRADApresent simple extension PRADA increase planning accuracy.exploit fact PRADA evaluates complete sequences actions contrast SSTUCT actions taken > 0 depend sampled outcomes. AdaptivePRADA (A-PRADA) examines best action sequence found PRADA. PRADAchooses first action sequence without reasoning, A-PRADA inspectssingle action sequence decides simulation whether deleted.resulting shortened sequence may lead increased expected reward. caseactions significant effects achieving goal decrease successprobability. actions omitted, states high reward reached earlierrewards discounted less. instance, consider goal grab blue ball:action sequence grabs red cube, puts onto table grabs blueball improved omitting first two actions unrelated goal.precisely, A-PRADA takes PRADAs action sequence aP highest valueinvestigates iteratively action whether deleted. actiondeleted plan resulting plan higher reward likelihood. ideaformalized Algorithm 1. crucial calculation algorithm compute valuesQ(s0 , a0:T 1 ) defined Eq. (28) restated convenience:0Q(s ,0:T 1)=XP (U = 1 | a0:t1 , s0 ) .t=1PRADAs approximate inference procedure particularly suitable calculating required P (U = 1 | a0:t1 , s0 ). performs calculation time linear length26fiPlanning Noisy Probabilistic Relational RulesAlgorithm 1 Adaptive PRADA (A-PRADA)Input: PRADAs plan aPOutput: A-PRADAs plan aA1: aA aP2: = 0 = 13:true4:Let plan length .5:a0:t1 a0:t1B Omitt+1:T 1t:T 26:aA7:1 othing8:Q(s0 , a) > Q(s0 , aA )9:aA10:else11:break12:end13:end14: end15: return aAaction sequence, SST UCT would require time exponentialoutcome sampling.6. Evaluationimplemented presented planning algorithms learning algorithmNID rules C++. code available www.user.tu-berlin.de/lang/prada/.evaluate approaches two different scenarios. first intrinsically noisy complex simulated environment learn NID rules experience useplan. Second, apply algorithms benchmarks Uncertainty PartInternational Planning Competition 2008.6.1 Simulated Robot Manipulation Environmentperform experiments simulated complex robot manipulation environmentrobot manipulates objects scattered table (Fig. 4). report results threeseries experiments different tasks increasing difficulty, first describe domaindetail. use 3D rigid-body dynamics simulator (ODE) enables realistic behavior objects. simulator available www.user.tu-berlin.de/lang/DWSim/.Objects cubes balls different sizes colors. robot grab objectsput top objects table. actions robot affectednoise. domain, towers objects straight-lined; easier put objecttop big cube top small cube difficult put somethingtop ball; piles objects may topple over; objects may fall table casebecome reach robot.represent domain predicates on(X, ), inhand(X), upright(X), out(X) (ifobject fallen table), function size(X) unary typing predicates cube(X),ball(X), table(X). predicates obtained querying state simulator27fiLang & ToussaintFigure 4: simulated robot plays cubes balls different sizes scatteredtable. Objects fallen table cannot manipulated anymore.translating according simple hand-made guidelines, thereby sidestepping difficultproblem converting agents observations internal representation. instance,on(a, b) holds b exert friction forces z-coordinate greaterone b, x- y-coordinates similar. Besides primitiveconcepts, also use derived predicate clear(X) Y.on(Y, X). foundpredicate enable compact accurate rules, reflected valuesobjective function rule learning algorithm given Eq. (3).define three different types actions. actions correspond motor primitiveswhose effects want learn exploit. grab(X) action triggers robot openhand, move hand next X, let grab X raise robot arm again.execution action influenced factors. example, differentobject held hand before, fall either table thirdobject ; objects top X, likely fall down.puton(X) action centers robots hand certain distance X, opensraises hand again. instance, object Z X, objectpotentially inhand may end Z Z might fall X. othing() action triggersmovement robots arm. robot might choose action thinksaction could harmful respect expected reward. emphasizeactions always execute, regardless state world. Also, actionsrather unintuitive humans trying grab table put object topcarried out. robot learn effects motor primitives.Due intrinsic noise complexity, simulated robot manipulation scenariochallenging domain learning compact world models well planning.objects f different object sizes, action space contains 2o+1 actions2state space huge f 2o +6o different states (not excluding states one would classifyimpossible given intuition real world physics).use rule learning algorithm Pasula et al. (2007) parametersettings learn three different sets fully abstract NID rules. rule-set learned28fiPlanning Noisy Probabilistic Relational Rulesindependent training sets 500 experience triples (s, a, s0 ) specify worldchanged state successor state s0 action executed, assuming fullobservability. Training data learn rules generated world six cubes fourballs two different sizes performing random actions slight bias build highpiles. resulting rule-sets contain 9, 10 10 rules respectively. rule-sets provideapproximate partial models true world dynamics. generalize situationsexperiences, may account situations completely differentagent seen before. enforce compactness avoid overfitting, rulesregularized; hence, learning algorithm may sometimes favor model rarely experiencedstate transitions low-probability outcomes general rules, thereby tradingaccuracy compactness. combination general noisiness worldcauses need carefully account probabilities world reasoningrules.perform three series experiments planning tasks increasing difficulty.series, test planners different worlds varying numbers cubesballs. Thus, transfer knowledge gained training world different, similarworlds using abstract NID rules. object number, create five different worlds.Per rule-set world, perform three independent runs different random seeds.evaluate different planning approaches, compute mean performancesplanning times fixed (but randomly generated) set 45 trials (3 learned rule-sets,5 worlds, 3 random seeds).choose parameters planning algorithms follows. SST, report results different branching factors b, far resulting runtimes allow. Similarly, UCT(A-)PRADA parameter balances planning time qualityfound actions. UCT, number episodes, (A-)PRADAnumber sampled action-sequences. Depending experiment, setheuristically tradeoff planning time quality reasonable.particular, fair comparison pay attention UCT, PRADA A-PRADA getplanning times, reported otherwise. Furthermore, UCT setbias parameter c 1.0 found heuristically perform best. plannersexperiments, set discounting factor future rewards = 0.95. crucialparameter planning horizon d, heavily influences planning time. course,cannot known a-priori. Therefore, reported otherwise, deliberately set largerrequired UCT (A-)PRADA suggest algorithms also effectiveestimated. Indeed, found experiments longsmall, exact choice significant effects UCTs (A-)PRADAsplanning quality unlike effects planning times. contrast, set horizonSST always small possible, case planning times still large.planning algorithm find suitable action given situation, restartplanning procedure: SST builds new tree, UCT runs episodes (A-)PRADAtakes new action-sequence samples. given situation 10 planning runs suitableaction still found, trial fails.Furthermore, use FF-Replan (Yoon et al., 2007) baseline. discussdetail related work Sec. 2, FF-Replan determinizes planning problem,thereby ignoring outcome probabilities. FF-Replan shown impressive results29fiLang & Toussaintdomains probabilistic planning competitions. domains carefully designedhumans: action dynamics definitions complete, accurate consistentused true world dynamics according experiments contrast learnedNID rules use estimate approximate partial models robot manipulationdomain. able use derived predicate clear(X) FF-Replan implementationexperiments, included appropriate literals predicate handoutcomes rules SST, UCT (A-)PRADA implementations infervalues automatically definition clear(X). report results FF-Replan(almost original) learned rules using all-outcomes determinization scheme, denotedFF-Replan-All below. (Using single-outcome schemes always led worse performance.)rules general (putting restrictions argumentsdeictic references); case, actions appear applicable given state makesense intuitive human perspective hurts FF-Replan muchmethods, resulting large planning times FF-Replan. instance, rule may modeltoppling small tower including object X trying put object toptower: one outcome might specify end X. possiblecube, course, learning algorithm may choose omit typing predicatecube(X) due regularization, prefers compact rules none experiences mightrequire additional predicate. Therefore, created modified rule-sets handintroduced typing predicates appropriate make contexts distinct. Below,denote results modified rule-sets FF-Replan-All* FF-Replan-Single*,using all-outcomes single most-probable outcome determinization schemes.6.1.1 High Towersfirst series experiments, investigate building high towers planningtask work Pasula et al. (2007). precisely, reward state definedaverage height objects. constitutes easy planning problem many differentactions may increase reward (object identities matter) small planninghorizon sufficient. set SST horizon = 4 (Pasula et al. choice) differentbranching factors b UCT (A-)PRADA horizon = 6. experiments, initialstates contain already stacked objects, reward performing actions0. Table 3 Fig. 5 present results. SST competitive. branching factorb > 1, slower UCT (A-)PRADA least order magnitude.b = 1, performance poor. series experiments, designed worlds 10objects contain many big cubes. explains relatively good performance SSTworlds, number good plans large. mentioned above, control UCT,PRADA A-PRADA times available planning. threeapproaches perform far better SST almost experiments. differenceUCT, PRADA A-PRADA never significant.series experiments indicates planning approaches using full-grown lookahead trees like SST inappropriate even easy planning problems. contrast, approaches exploit look-ahead trees clever way UCT seem bestchoice easy tasks require small planning horizon solved manyalternative good plans. performance planning approaches using approximate30fiPlanning Noisy Probabilistic Relational RulesTable 3: High towers problem. Reward denotes discounted total reward differentnumbers objects (cubes/balls table). reward performing actions0. data points averages 45 trials created 3 learned rule-sets,5 worlds 3 random seeds. Standard deviations mean estimatorsshown. FF-Replan-All* FF-Replan-Single* use hand-made modificationsoriginal learned rule-sets. Fig. 5 visualizes results.ObjectsPlannerFF-Replan-AllFF-Replan-All*FF-Replan-Single*6+1SST (b=1)SST (b=2)SST (b=3)UCTPRADAA-PRADASST (b=1)SST (b=2)SST (b=3)UCTPRADAA-PRADASST (b=1)SST (b=2)SST (b=3)UCTPRADAA-PRADA6.65 1.016.29 0.804.48 0.9441.07 9.637.54 4.094.61 2.751.191.010.940.991.251.279.03 0.80121.40 11.12595.43 55.957.45 0.196.01 0.076.36 0.075.10 1.013.08 0.872.82 0.8776.86 20.9828.65 16.811.72 0.271.071.210.871.071.211.4723.57 3.48335.5 52.41613.3 249.215.54 0.4015.24 0.2716.30 0.276.97 1.217.36 1.075.76 1.21121.99 27.4333.45 12.804.14 1.08119.26 10.591748.7 170.28424 85131.71 5.8331.58 1.1435.22 0.409.6212.3611.0917.1116.1016.29FF-Replan-AllFF-Replan-All*FF-Replan-Single*10+1Trial time (s)11.6812.9012.8016.0115.5416.12FF-Replan-AllFF-Replan-All*FF-Replan-Single*8+1Reward15.1214.4816.4817.7116.2116.78311.341.201.191.081.071.14fiLang & ToussaintFF-Replan-AllFF-Replan-All*FF-Replan-Single*SST b=1SST b=2SST b=3UCTPRADAA-PRADA151051000Trial time (s)Discounted total reward1000010010168Objects106(a) Reward8Objects10(b) TimeFigure 5: High towers problem Visualization results presented Table 3. rewardperforming actions 0. data points averages 45 trials created3 learned rule-sets, 5 worlds 3 random seeds. Error bars standarddeviations mean estimators shown. Please note log-scale (b).inference, PRADA A-PRADA, however, comes close one UCT, showing alsosuitability scenarios.FF-Replan focuses exploiting conjunctive goal structures cannot deal quantified goals. grounded reward structure task consists disjunctiondifferent tower combinations, FF-Replan pick arbitrary tower combinationgoal. Therefore, apply FF-Replan sample tower combinations according rewards achieve (i.e., situations high towers probable) excludecombinations balls bottom towers prohibited rewardstructure. Yoon et al. note, obvious pitfall [goal formula sampling] approachgroundings goal reachable much expensive reachinitial state. FF-Replan cannot find plan, execute action,sample new ground goal formula next time-step, preserving already achievedtower structures.FF-Replan performs significantly worse previous planning approaches.major reason FF-Replan often comes plans exploiting low-probabilityoutcomes rules contrast SST, UCT (A-)PRADA reasonprobabilities. illustrate this, consider example rule Fig. 1 models puttingball top cube. two explicit outcomes: ball usually endscube; sometimes, however, falls table. FF-Replan misuse rule trickyway put ball table ignoring often fail. results FFReplan-Single* show, taking probable outcomes account remedyproblem: often two three outcomes similar probabilitieschoice seems unjustified; sometimes, intuitively expected outcome splitdifferent outcomes low probabilities, however vary features irrelevantplanning problem (such upright()).32fiPlanning Noisy Probabilistic Relational RulesTable 4: Desktop clearance problem. Reward denotes discounted total reward different numbers objects (cubes/balls table). reward performingactions 0. data points averages 45 trials created 3 learned rulesets, 5 worlds 3 random seeds. Standard deviations mean estimatorsshown. FF-Replan-All* FF-Replan-Single* use hand-made modificationsoriginal learned rule-sets. Fig. 6 visualizes results.Obj.PlannerFF-Replan-AllFF-Replan-All*FF-Replan-Single*6+1SST (b=1)UCTPRADAA-PRADASST (b=1)UCTPRADAA-PRADASST (b=1)UCTPRADAA-PRADA3.81 0.675.86 0.876.53 1.0719.1 6.51.1 0.70.7 0.80.750.860.860.801382.6 80.452.2 0.740.9 0.742.3 0.75.93 1.006.21 1.056.02 0.9429.8 8.73.5 0.60.8 0.72.011.081.541.578157 978151.4 2.0154.5 1.9157.4 2.03.30 0.743.53 0.873.91 0.8660.9 12.120.7 5.45.2 1.310.13 0.8012.81 1.1413.91 1.12> 8h415.7 7.4385.3 4.7394.5 4.08.4310.2914.6314.87FF-Replan-AllFF-Replan-All*FF-Replan-Single*10+1Trial time (s)5.359.6010.9412.79FF-Replan-AllFF-Replan-All*FF-Replan-Single*8+1Reward6.1.2 Desktop Clearancetask second series experiments clear desktop. Objects lyingsplattered table beginning. object cleared part towercontaining objects class. object class simply defined termscolor additionally provided state representation robot. rewardrobot defined number cleared objects. experiments, classes contain2-4 objects 1 ball (in order enable successful piling). starting situations contain piles, objects different classes. Thus, rewardperforming actions 0. Desktop clearance difficult building high towers,number good plans yielding high rewards significantly reduced.set planning horizon = 6 optimal SST required clearclass 4 objects, namely grabing putting three objects. above, contrast set= 10 UCT (A-)PRADA show deal overestimationusually unknown optimal horizon d. Table 4 Fig. 6 present results. horizon= 6 overburdens SST seen large planning times. Even b = 1, SSTtakes almost 40 minutes average worlds 6 objects, 2 hours worlds8 objects. Therefore, try SST greater b. contrast, planning times33fi161000014FF-Replan-AllFF-Replan-All*FF-Replan-Single*SST b=1UCTPRADAA-PRADA1210864268Objects1000Trial time (s)Discounted total rewardLang & Toussaint100101610(a) Reward8Objects10(b) TimeFigure 6: Desktop clearance problem. Visualization results presented Table 4.reward performing actions 0. data points averages 45 trialscreated 3 learned rule-sets, 5 worlds 3 random seeds. Error barsstandard deviations mean estimators shown. Note log-scale (b).UCT, PRADA A-PRADA, controlled enablereasonable performance, two orders magnitude smaller, although overestimatingplanning horizon: trial take average 45s worlds 6 objects, 2 12minutes worlds 8 objects 6-7 minutes worlds 10 objects. Nonetheless, UCT,PRADA A-PRADA perform significantly better SST. worlds, PRADAA-PRADA turn outperform UCT, particular worlds many objects. A-PRADAfinds best plans among planners. planners gain reward worlds 8 objectscomparison worlds 6 objects, number objects cleared increaseswell number classes thus good plans. worlds 10 objects containnumbers object classes like worlds 8 objects, objects,making planning difficult.Overall, findings Desktop clearance experiments indicate SSTinappropriate, UCT achieves good performance planning scenarios require mediumplanning horizons several, many alternative plans. Approachesusing approximate inference like PRADA A-PRADA, however, seem appropriate scenarios intermediate difficulty.Furthermore, results indicate FF-Replan inadequate clearance task.sample target classes randomly provide goal structure FF-Replan; towerstructure within target class turn also randomly chosen. bad performanceFF-Replan due reasons described previous experiments; particularplans FF-Replan often rely low-probability outcomes.34fiPlanning Noisy Probabilistic Relational RulesTable 5: Reverse tower problem. trial times numbers executed actions givensuccessful trials different numbers objects (cubes table).data points averages 45 trials created 3 learned rule-sets, 5 worlds3 random seeds. Standard deviations mean estimators shown. FFReplan-All* FF-Replan-Single* use hand-made modifications originallearned rule-sets.Objects5+16+17+1PlannerSuccess rateTrial time (s)Executed actionsFF-Replan-AllFF-Replan-All*FF-Replan-Single*0.021.000.677.1 0.026.7 2.77.0 0.912.0 0.1013.1 0.913.6 1.1SST (b=1)SST (b=2)UCTPRADAA-PRADA0.000.000.380.710.82> 1 day2504.9 491.127.0 1.825.4 0.819.5 4.013.2 0.710.9 0.8FF-Replan-AllFF-Replan-All*FF-Replan-Single*0.001.000.64589.2 73.752.7 5.312.0 0.817.3 2.1UCTPRADAA-PRADA0.000.470.56>4 h66.4 3.977.5 8.313.6 0.914.4 2.5FF-Replan-AllFF-Replan-All*FF-Replan-Single*0.000.420.562234.2 81.1687.4 86.415.1 1.317.5 2.0PRADAA-PRADA0.240.23871.3 126.6783.7 132.618.2 1.215.1 1.86.1.3 Reverse Towerexplore limits UCT, PRADA A-PRADA, conducted final seriesexperiments task reverse towers C cubes requires least 2Cactions (each cube needs grabbed put somewhere least once). Apartlong planning horizon, difficult due noise simulated world: towersbecome unstable topple cubes falling table. decrease noiseslightly obtain reliable results, forbid robot grab objects clear(i.e., objects). set limit 50 executed actions trial. thereafterreversed tower still built, trial fails. trial also fails one requiredobjects falls table.Table 5 presents results. cannot get SST optimal planning horizon = 10solve problem even five cubes. Although space possible actions reduceddue mentioned restriction, SST enormous runtimes. b = 1, SST findsuitable actions (no leaves goal state) several starting situations increasedplanning horizon leads high probability sampling least one unfavorable outcomerequired action. b 2, single tree traversal SST takes day.found UCT also require large planning times order achieve reasonable successrate. Therefore, set planning horizons optimal UCT. worlds 5 cubes, UCToptimal = 10 success rate 40% taking average 4035fiLang & Toussaintminutes case success. 6 cubes, however, UCT optimal = 12 never succeedseven planning times exceed 4 hours. contrast, afford overestimatinghorizon = 20 PRADA A-PRADA. worlds 5 cubes, PRADA A-PRADAachieve success rates 71% 82% respectively less half minute. A-PRADAsaverage number executed actions case success almost optimal. worlds 6cubes, success rates PRADA A-PRADA still 50%, taking bitminute average case success. trials fail, often duecubes falling table cannot find appropriate actions. Cubesfalling table also main reason success rates PRADA A-PRADAdrop 23% 24% respectively worlds 7 cubes towers become rather unstable.Planning times successful trials, however, also increase 13 minutes indicatinglimitations planning approaches. Nonetheless, mean number executedactions successful trials still almost optimal A-PRADA.Overall, Reverse tower experiments indicate planning approaches using lookahead trees fail tasks require long planning horizons achievedplans. Given huge action state spaces relational domains, chancesUCT simulates episode exactly required actions successor statessmall. Planning approaches using approximate inference like PRADA A-PRADAcrucial advantage stochasticity actions affect runtimeexponentially planning horizon. course, search space action-sequences stillexponential planning horizon problems requiring long horizons hardsolve also them. experiments show using simple, though principledextension A-PRADA, gain significant performance improvements.results also show FF-Replan fails provide good plans using originallearned rule-sets. surprising characteristics Reverse tower task seemfavor FF-Replan comparison methods: single conjunctive goalstructure number good plans small plans require long horizons.results FF-Replan-All* FF-Replan-Single* indicate, FF-Replan achievegood performance adapted rule-sets modified hand restrictnumber possible actions state. constitutes proof conceptFF-Replan, shows difficulty applying FF-Replan learned rule-sets.6.1.4 Summaryresults demonstrate successful planning learned world models (hereform rules) may require explicitly account quantification predictive uncertainty. concretely, methods applying look-ahead trees (UCT) approximateinference ((A-)PRADA) outperform FF-Replan different tasks varying difficulty. Furthermore, (A-)PRADA solve planning tasks long horizons, UCT fails.one post-processes learned rules hand clarify application contextsplanning problem uses conjunctive goal structure requires long plans,FF-Replan performs better UCT (A-)PRADA.36fiPlanning Noisy Probabilistic Relational Rules6.2 IPPC 2008 Benchmarkssecond part evaluation, apply proposed approaches benchmarkslatest international probabilistic planning competition, Uncertainty PartInternational Planning Competition 2008 (IPPC, 2008). involved domains differmany characteristics, number actions, required planning horizonsreward structures. competition results show, planning algorithm performsbest everywhere. Thus, benchmarks give idea types problems SST,UCT (A-)PRADA may useful. convert PPDDL domain specificationsNID rules along lines described Sec. B.1. resulting rule-sets used runimplementations SST, UCT (A-)PRADA benchmark problems.seven benchmark domains consists 15 problem instances. instancespecifies goal starting state. Instances vary problem size, alsoreward structures (including action costs), direct comparison alwayspossible. competition, instance considered independently: plannersgiven restricted amount time (10 minutes problems 1-5 domain 40minutes others) cover many repetitions problem instancepossible maximum 100 trials. Trials differed random seeds resultingpotentially different state transitions. planners evaluated respectnumber trials ending goal state collected reward averaged trials.Eight planners entered competition, including FF-Replan official participant. discussed related work Sec. 2. results,voluminous presented here, refer reader website competition. Below, provide qualitative comparison methods resultsplanners. attempt direct quantitative comparison several reasons. First,different hardware prevents timing comparisons. Second, competition participantsfrequently able successfully cover trials single instances domain.difficult tell reasons results tables: planner mightoverburdened problem, might faced temporary technical problemsclient-server architecture framework competition could cope certainPPDDL constructs could rewritten simpler format.Third importantly, optimized implementations reuse previous planning efforts. Instead, fully replan single action (within trialacross trials). competition evaluation scheme puts replanners disadvantage (inparticular replan single action). Instead replanning, good strategycompetition spend planning time starting first trial reuseresulting insights (such conditional plans value functions) subsequent trialsminimum additional planning. Indeed, strategy often adoptedmany trial time results indicate. acknowledge fair procedure evaluateplanners compute policies large parts state-space acting. feel,however, counter idea approaches: UCT (A-)PRADAmeant flexible planning varying goals different situations. Thus,interested average time compute good actions successfully solve probleminstance prior knowledge available.37fiLang & ToussaintTable 6: Benchmarks IPPC 2008. first column table specifies probleminstance. Suc. success rate. trial time number executedactions given successful trials. applicable, rewardtrials shown. results achieved full replanning within trialacross trials.(a) Search RescuePlannerSuc. Trial Time (s)Actions(c) BlocksworldRewardSSTUCT01PRADAA-PRADA1005410010037.90.11.40.11.10.11.10.1SSTUCTPRADAA-PRADA10056100100220.20.14.10.31.60.11.60.19.80.212.20.612.90.712.80.4SSTUCTPRADAA-PRADA71579999955.50.512.90.61.40.11.40.19.80.2 16628513.60.6 6806318.01.0 14808817.91.1 148088ActionsRewardUCT04 PRADAA-PRADA6110010024.91.61.40.01.40.016.10.8 72005711.90.4 14608911.50.3 150087SSTUCT01PRADAA-PRADA00100100257.86.3 46.81.0143.83.1 43.11.11.000.01.000.005UCTPRADAA-PRADA46899240.12.16.80.36.50.316.81.4 6006421.80.9 12408321.00.9 13208102PRADAA-PRADA100100285.27.8 46.21.3215.84.2 39.60.920.000.020.000.006UCTPRADAA-PRADA39838471.75.610.10.910.00.919.51.3 4105924.31.3 12409023.71.2 12409003UCTPRADAA-PRADA1001005007UCTPRADAA-PRADA539898230.313.210.10.49.90.421.51.4 5406218.50.8 14708818.00.8 14908704PRADAA-PRADA2860959.035.5 76.13.2519.215.3 72.02.40.30.50.60.1UCTPRADAA-PRADA345959332.924.1 21.711.520.20.8 30.41.719.90.8 29.91.70508UCTPRADAA-PRADA546129972776 37.93.5345.48.5 68.41.6528.638.8 38.00.06061494652441134UCT09 PRADAA-PRADA306365752.872.330.21.230.01.108PRADAA-PRADA310336188 87.02.3157948 85.32.70.190.10.290.309PRADAA-PRADA280144925 85.91.5(1750.3)13653111263010PRADAA-PRADA212197.910.292.19.826.82.826.72.8180271802711PRADAA-PRADA1718151.712.3154.111.9302.530.22.6250292502912PRADAA-PRADA3821210.872.1 30.110.5 636253219.828.5 30.72.8 5565502039.20.2 14409011.40.3 9007010.50.4 14608910.40.4 146089Planner15608388010014608914409036059910829108201001001009.90.38.50.28.00.202UCTPRADAA-PRADA100576564.12.2 12.40.330.10.790.233.70.8 11.40.303UCTPRADAA-PRADA891921390.58.5 18.60.4119.24.9 12.30.5121.05.3 14.30.7UCT04 PRADAA-PRADA8264149719 26.00.52967143 17.51.1244.243.6 15.52.80.80.00.60.0031057.03.3 21.51.8 -9.60.0Suc. Trial Time (s)1285.28.1 32.80.0 929.82.1165.72.9 52.51.1 865.13.3457.87.1 35.00.7 754.121.5(e) Exploding BlocksworldPlannerActionsSSTUCTPRADAA-PRADA0117.80.4 23.00.718.40.5 22.30.8Planner26.42.4 3604827.51.6 9308027.51.6 101084Suc. Trial Time (s)Reward005363PRADASuc. Trial Time (s)(d) Boxworld(b) Triangle-TireworldPlannerActionsSSTUCT01PRADAA-PRADA6.90.26.40.26.10.238Suc. Trial Time (s)86071224111.814.03.60.03.90.0ActionsSSTUCT01PRADAA-PRADA53626102PRADAA-PRADA282911.90.3 14.40.512.70.2 13.20.503PRADAA-PRADA363014.30.3 12.60.616.80.3 12.50.504PRADAA-PRADA272630.31.2 14.80.514.91.1 15.20.505PRADAA-PRADA10010006PRADAA-PRADA5161128.52.9 16.90.797.55.3 17.30.807PRADAA-PRADA1472125.06.9 15.30.4154.85.5 17.61.05.50.15.50.19.60.69.30.48.60.88.40.86.60.16.60.1fiPlanning Noisy Probabilistic Relational RulesTherefore, single problem instance perform 100 trials different randomseeds using full replanning. trial aborted goal state reached withinmaximum number actions varying slightly benchmark (about 50 actions).present success rates mean estimators trial times, executed actionsrewards standard deviations Table 6 problem instances leastone trial successfully covered reasonable time.Search Rescue (Table 6(a)) domain SST (with branching factor1) able find plans within reasonable time significantly larger runtimesUCT (A-)PRADA. success rates rewards indicate PRADA APRADA superior UCT scale rather big problem instances. give ideaw.r.t. IPPC evaluation scheme: UCT solves successfully 54 trials first instancewithin 10 minutes full replanning, PRADA A-PRADA solve trialsfull replanning. fact, despite replanning single action, PRADA A-PRADAshow success rates best planners benchmark except largeproblem instances (within competition, participants FSP-RBH FSP-RDHachieved comparably satisfactory results). conjecture success methodsdue fact domain requires account carefully outcome probabilities,involve long planning horizons.Triangle-Tireworld (Table 6(b)) domain UCT outperforms PRADAA-PRADA, although higher computational cost. depth-first-like styleplanning UCT seems useful domain. give idea w.r.t. IPPC evaluationscheme: UCT performs 60 successful trials first instance within 10 minutes,PRADA A-PRADA achieve 72 74 trials resp. using full replanning; UCT solvestrials difficult instances. required planning horizons increase quicklyproblem instances. approaches cannot cope large problem instances,three competition participants (RFF-BG, RFF-PG, HMDPP) could cover.methods face problems required planning horizons large,number plans non-zero probability small. becomes evidentBlocksworld benchmark (Table 6(c)). domain different robot manipulation environment first evaluation Sec. 6.1. latter considerablystochastic provides actions given situation (e.g., may grab objects withinpile). Blocksworld domain approaches inferior FF-Replan.give idea w.r.t. IPPC evaluation scheme: UCT perform single successfultrial first instance within 10 minutes, PRADA A-PRADA achieve 1617 trials resp. using full replanning.Boxworld domain (Table 6(d)), approaches exploit factdelivery boxes (almost) independent delivery boxes (in probleminstances helped intermediate rewards delivered boxes). contrastUCT, PRADA A-PRADA scale relatively large problem instances. PRADAA-PRADA solve 100 trials first problem instance, requiring average 4.3min 2.4 min resp. full replanning. two competition participants solvedtrials successfully domain (RFF-BG RFF-PG). give idea w.r.t. IPPCevaluation scheme: UCT perform single successful trial within 10 minutes,PRADA completes 2 A-PRADA 4 trials. small number explainedlarge plan lengths single action computed full replanning.39fiLang & ToussaintFinally, Exploding Blocksworld domain (Table 6(e)) PRADA A-PRADAperform better good competition participants. give idea w.r.t. IPPCevaluation scheme: UCT achieves single successful trial within 10 minutes,PRADA A-PRADA complete 56 61 trials resp..perform experiments either SysAdmin Schedule domain. PPDDL specifications cannot converted NID rules due involveduniversal effects. contrast, possible Boxworld domain despiteuniversal effects there: Boxworld problem instances, universally quantifiedvariables always refer exactly one object exploit conversion NID rules.(Note understood trick implement deictic references PPDDLmeans universal effects. according action operator, however, odd semantics:boxes could end two different cities time.) Furthermore, ignoredRectangle-Tireworld domain, together Triangle-Tireworld domain makes2-Tireworlds benchmark, problem instances faulty goal descriptions:include not(dead) (this critical name winner competitionpersonally communicated Olivier Buffet).6.2.1 Summarymajority PPDDL descriptions IPPC benchmarks convertedNID rules, indicating broad spectrum planning problems coveredNID rules. results demonstrate approaches perform comparably betterstate-of-the-art planners many traditional hand-crafted planning problems.hints generality methods probabilistic planning beyond type roboticmanipulation domains considered Sec. 6.1. methods perform particularly welldomains outcome probabilities need carefully accounted for. face problemsrequired planning horizons large, number plans non-zeroprobability small; avoided intermediate rewards.7. Discussionpresented two approaches planning probabilistic relational rules groundeddomains. methods designed work learned rules provide approximatepartial models noisy worlds. first approach adaptation UCT algorithmsamples look-ahead trees cope action stochasticity. second approach,called PRADA, models uncertainty states explicitly terms beliefs employsapproximate inference graphical models planning. combine planningalgorithms existing rule learning algorithm, intelligent agent (i) learncompact model dynamics complex noisy environment (ii) quickly derive appropriate actions varying goals. Results complex simulated robotics domain showmethods outperform state-of-the-art planner FF-Replan number different planning tasks. contrast FF-Replan, methods reason probabilitiesaction outcomes. necessary world dynamics noisy partialapproximate world models available.However, planners also perform remarkably well many traditional probabilisticplanning problems. demonstrated results IPPC benchmarks,40fiPlanning Noisy Probabilistic Relational Rulesshown PPDDL descriptions converted large extent kind rulesplanners use. hints general-purpose character particularly PRADApotential benefits techniques probabilistic planning. instance, methodsexpected perform similarly well large propositional MDPs exhibitrelational structure.far, planning approaches deal reasonable time problems containing10-15 objects (implying billions world states) requiring planning horizons15-20 time-steps. Nonetheless, approaches still limited relyreasoning grounded representation. many objects need representedrepresentation language gets rich, approaches need combinedmethods reduce state action space complexity (Lang & Toussaint, 2009b).7.1 Outlookcurrent form, approximate inference procedure PRADA relies specificcompact DBNs compiled rules. development similar factored frontier filtersarbitrary DBNs, e.g. derived general PPDDL descriptions, promising.Similarly, adaptation PRADAs factored frontier techniques existing probabilisticplanners worth investigation.Using probabilistic relational rules backward planning appears appealing.straightforward learn NID rules regress actions providing reversed triples (s0 , a, s)rule learning algorithm, stating predecessor state state s0 actionapplied before. Backward planning, combined forward planning,received lot attention classical planning may fruitful planninglook-ahead trees well planning using approximate inference. means propagating backwards DBNs, one may ultimately derive algorithms calculateposteriors actions, leading true planning inference (instead sampling actions).important direction improving PRADA algorithm make adaptaction-sequence sampling strategy experience previous samples. introduced simple extension, A-PRADA, achieve this, sophisticated methodsconceivable. Learning rule-sets online exploiting immediately planning method also important direction future research order enable actingreal world, want behave effectively right start. Improvingrule framework efficient effective planning another interesting issue.instance, instead using noisy default rule, one may use mixture models dealactions several (non-unique) covering rules, general use parallel rules workdifferent hierarchical levels different aspects underlying system.Acknowledgmentsthank anonymous reviewers careful thorough commentsgreatly improved paper. thank Sungwook Yoon providing us implementationFF-Replan. thank Olivier Buffet answering questions probabilisticplanning competition 2008. work supported German Research Foundation(DFG), Emmy Noether fellowship 409/1-3.41fiLang & ToussaintAppendix A. Proof Proposition 1Proposition 1 (Sec. 5.3) set action sequences PRADA samples non-zeroprobability super-set ones SST UCT.Proof: Let a0:T 1 action sequence sampled SST (or UCT). Thus,exists state sequence s0:T rule sequence r0:T 1 every state st(t < ), action unique covering rule rt predicts successor state st+1probability pt > 0. For, pt = 0, st+1 would never sampled SST (or UCT).show t, 0 < : P (st | a0:t1 , s0 ) > 0. casePsample (at ) > 0 unique covering rule rt st eventually sampled.P (s0 ) = 1 > 0 obvious. assume P (st | a0:t1 , s0 ) > 0. execute ,get P (st+1 | a0:t , s0 ) pt P (st | a0:t1 , s0 ) > 0. posterior P (st+1 | a0:t , s0 ) greater(first inequality) due persistence previous states non-zero probabilityalso lead st+1 given .set action sequences PRADA samples larger SST (or UCT)SST (or UCT) refuses model noise outcomes rules. Assume action statestate unique covering rule. episodesimulated means rule predictions noise outcome, action neversampled SST (or UCT) (as required states never sampled). contrast, PRADAalso models effects noise outcome giving low probability possiblesuccessor states heuristic described above.Appendix B. Relation NID rules PPDDLuse NID rules (Sec. 3.2) relational model transition dynamics probabilistic actions. Besides allowing negative literals preconditions, NID rules extendprobabilistic STRIPS operators (Kushmerick et al., 1995; Blum & Langford, 1999) twospecial constructs, namely deictic references noise outcomes, crucial learning compact rule-sets. alternative language specify probabilistic relational planningproblems used International Probabilistic Planning Competitions (IPPC, 2008)probabilistic planning domain definition language (PPDDL) (Younes & Littman, 2004).PPDDL probabilistic extension subset PDDL, derived deterministicaction description language (ADL). ADL, turn, introduced universal conditionaleffects negative precondition literals (deterministic) STRIPS representation.Thus, PPDDL allows usage syntactic constructs beyond expressivepower NID rules; however, many PPDDL descriptions converted NID rules.taking closer look convert PPDDL NID rule representationsother, clarify meant action formalisms, givingintuition line thinking using either these. understand abstractaction abstract action predicate, e.g. pickup(X). Intuitively, defines certain typeaction. stochastic state transitions according abstract action specifiedabstract NID rules well abstract PPDDL action operators (also called schemata).Typically, several different abstract NID rules model abstract action, specifyingstate transitions different contexts. contrast, usually one abstract PPDDL action42fiPlanning Noisy Probabilistic Relational Rulesoperator used model abstract action: context-dependent effects modeledmeans conditional universal effects.make predictions specific situation concrete action (a grounded actionpredicate pickup(greenCube)), strategy within NID rule frameworkground set abstract NID rules examine ground rules cover state-actionpair. exactly one ground rule, chosen prediction.rule one (the contexts NID rules mutuallyexclusive), one chooses noisy default rule, essentially saying one knowhappen (other strategies conceivable, pursued here). contrast,usually exactly one operator per abstract action PPDDL domains,need concept operator uniqueness distinguish ground actionsoperators.B.1 Converting PPDDL NID rulesfollowing, discuss convert PPDDL features NID rule representation.may impossible convert PPDDL action operator single NID rule,one may often translate set rules polynomial increase sizerepresentation. Table 7 provides example converted PPDDL action operatorIPPC domain Exploding Blocksworld. NID rules support many,features sophisticated domain description language PPDDL provides, using ruleslead compact representations possible domains. experiments, however,show dynamics many interesting planning domains specified compactly.Furthermore, additional expressive power rule contexts gained using derivedpredicates allow bring various kinds logical formulas quantification.Conditional Effects conditional effect PPDDL operator takes form CE. accounted two NID rules: first rule adds C contextE outcomes, second adds C context ignores E.Universal Effects PPDDL allows define universal effects. specify effectsobjects meet preconditions. example reboot action SysAdmindomain IPPC 2008 competition: specifies every computer onerebooted independently go probability 0.2 connected computeralready down. cannot expressed NID rule framework.refer objects action arguments via deictic references, requiredeictic references unique. reboot action, would need unique way refercomputer cannot achieved without significant modifications (forexample, enumerating computers via separate predicates).Disjunctive Preconditions Quantification PPDDL operators allow disjunctive preconditions, including implications. instance, Search-and-rescue domainIPPC 2008 competition defines action operator goto(X) precondition(X 6= base) humanAlive(). disjunction B ( B) accountedeither using two NID rules, first rule context secondrule B. Alternatively, one may introduce derived predicate C B.general, trick derived predicates allows overcome syntactical limitations NID43fiLang & ToussaintTable 7: Example converting PPDDL action operator NID rules. putDownoperator IPPC benchmark domain Exploding Blocksworld (a) containsconditional effect accounted two NID rules either exclude(b) include (c) condition context.( : action putDown(a): parameters (?b block): precondition (and (holding ?b) (noDestroyedT able)): ef f ect (and (emptyhand) (onT able ?b) (not (holding ?b))(probabilistic 2/5 (when (noDetonated ?b) (and (not (noDestroyedT able)) (not (noDetonated?b)))))))(b)putDown(X) : block(X), holding(X), noDestroyedT able(), noDetonated(X)1.0 : emptyhand(X), onT able(X), holding(X)(c)putDown(X) : block(X), holding(X), noDestroyedT able(), noDetonated(X)0.6 : emptyhand(X), onT able(X), holding(X)0.4 : emptyhand(X), onT able(X), holding(X), noDestroyedT able(), noDetonated(X)rules bring various kinds logical formulas quantifications. discussedPasula et al. (2007), derived predicates important prerequisite able learncompact accurate rules.Types Terms may typed PPDDL, e.g. driveT o(C city). Typing objectsvariables predicates functions achieved NID rules usage typingpredicates within context, e.g. using additional predicate city(C).State Transition Rewards PPDDL, one encode Markovian rewards associatedstate transitions (including action costs negative rewards) using fluents updaterules action effects. One achieve NID rules associating rewardsoutcomes rules.B.2 Converting NID rules PPDDLshow following way NID rules used SST, UCT PRADAplanning time handled via polynomial blowup representational size.basic building blocks NID rule, i.e. context well outcomes, transferone-to-one PPDDL action operators. deictic references, uniqueness requirementcovering rules noise outcome need special attention.Deictic References Deictic references NID rules allow refer objectsaction arguments. PPDDL, one refer objects means universalconditional effects. important restriction, however: deictic reference needspick single unique object order apply. picks none many, rule failsapply. two ways ensure uniqueness requirement within PPDDL. First,44fiPlanning Noisy Probabilistic Relational Rulesallowing quantified preconditions, explicit uniqueness precondition deicticreference introduced. Using universal quantification, constrains objectssatisfying preconditions identical, i.e., X, : (X, ) (Y, )X = , variables. Alternatively, uniqueness deictic referencesachieved careful planning problem specification, however cannotguaranteed learning rules.Uniqueness covering rules contexts NID rules mutuallyexclusive. want use rule prediction (as planning), need ensureuniquely covers given state-action pair. procedural evaluation process NIDrules encoded declaratively PPDDL using modified conditions explicitlynegate contexts competing rules. instance, three NID rulespotentially overlapping contexts A, B, C (propositional simplicity), PPDDLaction operator may define four conditions: c1 = {A B C}, c2 = {A B C},c3 = {A B C}, c4 = {(A B C) (A B) (A C) (B C)}. Conditions c1 ,c2 c3 test uniqueness corresponding NID rules subsume outcomes.Condition c4 tests non-uniqueness (either covering rule multiple covering rules)models potential changes noise, analogous situations NID rule contextnoisy default rule would used.Noise outcome noise outcome NID rule subsumes seldom utterly complexoutcomes. relaxes frame assumption: even explicitly stated things may changecertain probability. comes price difficulty ensure well-definedsuccessor state distribution P (s0 | s, a). contrast, PPDDL needs explicitly specifyeverything might change. may important reason difficult comeeffective learning algorithm PPDDL.principle PPDDL provide noise outcome, way approachesaccount planning encoded PPDDL. either treat noise outcomeeffects (in SST UCT; basically noop operator then) triviallytranslated PPDDL; consider probability state attribute changeindependently (in PRADA) encoded PPDDL independent universalprobabilistic effects.noise outcome allows always make predictions arbitrary action:multiple covering rules, may use (albeit informative) predictiondefault rule. cases dealt PPDDL action operators using explicitconditions described previous paragraph.ReferencesBlum, A., & Langford, J. (1999). Probabilistic planning graphplan framework.Proc. Fifth European Conference Planning (ECP), pp. 319332.Botvinick, M. M., & An, J. (2009). Goal-directed decision making prefrontal cortex:computational framework. Advances Neural Information Processing Systems(NIPS), pp. 169176.45fiLang & ToussaintBoutilier, C., Dean, T., & Hanks, S. (1999). Decision-theoretic planning: Structural assumptions computational leverage. Journal Artificial Intelligence Research,11, 194.Boutilier, C., Reiter, R., & Price, B. (2001). Symbolic dynamic programming first-orderMDPs. Proc. Int. Conf. Artificial Intelligence (IJCAI), pp. 690700.Buffet, O., & Aberdeen, D. (2009). factored policy-gradient planner. Artificial Intelligence Journal, 173 (5-6), 722747.Cooper, G. (1988). method using belief networks influence diagrams. Proc.Fourth Workshop Uncertainty Artificial Intelligence, pp. 5563.Croonenborghs, T., Ramon, J., Blockeel, H., & Bruynooghe, M. (2007). Online learningexploiting relational models reinforcement learning. Proc. Int. Conf.Artificial Intelligence (IJCAI), pp. 726731.Domshlak, C., & Hoffmann, J. (2007). Probabilistic planning via heuristic forward searchweighted model counting. Journal Artificial Intelligence Research, 30, 565620.Driessens, K., Ramon, J., & Gartner, T. (2006). Graph kernels Gaussian processesrelational reinforcement learning. Machine Learning, 64 (1-3), 91119.Dzeroski, S., de Raedt, L., & Driessens, K. (2001). Relational reinforcement learning.Machine Learning, 43, 752.Fern, A., Yoon, S., & Givan, R. (2006). Approximate policy iteration policy languagebias: solving relational markov decision processes. Journal Artificial IntelligenceResearch, 25 (1), 75118.Gardiol, N. H., & Kaelbling, L. P. (2003). Envelope-based planning relational MDPs.Proc. Conf. Neural Information Processing Systems (NIPS).Gardiol, N. H., & Kaelbling, L. P. (2007). Action-space partitioning planning. Proc.AAAI Conf. Artificial Intelligence (AAAI), pp. 980986.Gardiol, N. H., & Kaelbling, L. P. (2008). Adaptive envelope MDPs relationalequivalence-based planning. Tech. rep. MIT-CSAIL-TR-2008-050, MIT CS & AI Lab,Cambridge, MA.Gelly, S., & Silver, D. (2007). Combining online offline knowledge UCT. Proc.Int. Conf. Machine Learning (ICML), pp. 273280.Gretton, C., & Thiebaux, S. (2004). Exploiting first-order rgeression inductive policyselection. Proc. Conf. Uncertainty Artificial Intelligence (UAI), pp.217225.Grush, R. (2004). Conscious thought simulation behaviour perception. Behaviorialbrain sciences, 27, 377442.46fiPlanning Noisy Probabilistic Relational RulesHalbritter, F., & Geibel, P. (2007). Learning models relational MDPs using graph kernels.Proc. Mexican Conference Artificial Intelligence (MICAI), pp. 409419.Hesslow, G. (2002). Conscious thought simulation behaviour perception. TrendsCognitive Science, 6 (6), 242247.Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generationheuristic search. Journal Artificial Intelligence Research, 14, 253302.Holldobler, S., & Skvortsova, O. (2004). logic-based approach dynamic programming.AAAI-Workshop: Learning planning MDPs, pp. 3136.IPPC(2008).Sixth International Planning Competition,http://ippc-2008.loria.fr/wiki/index.php/Main Page.UncertaintyPart..Jensen, F. (1996). introduction Bayesian networks. Springer Verlag, New York.Joshi, S., Kersting, K., & Khardon, R. (2009). Generalized first-order decision diagramsfirst-order MDPs. Proc. Int. Conf. Artificial Intelligence (IJCAI), pp.19161921.Karabaev, E., & Skvortsova, O. (2005). heuristic search algorithm solving first-orderMDPs. Proc. Conf. Uncertainty Artificial Intelligence (UAI), pp.292299.Kearns, M. J., Mansour, Y., & Ng, A. Y. (2002). sparse sampling algorithm nearoptimal planning large Markov decision processes. Machine Learning, 49 (2-3),193208.Kersting, K., & Driessens, K. (2008). Nonparametric policy gradients: unified treatment propositional relational domains. Proc. Int. Conf. MachineLearning (ICML), pp. 456463.Kersting, K., van Otterlo, M., & de Raedt, L. (2004). Bellman goes relational. Proc.Int. Conf. Machine Learning (ICML), pp. 465472.Kocsis, L., & Szepesvari, C. (2006). Bandit based monte-carlo planning. Proc.European Conf. Machine Learning (ECML), pp. 837844.Kushmerick, N., Hanks, S., & Weld, D. (1995). algorithm probabilistic planning.Artificial Intelligence, 78 (1-2), 239286.Kuter, U., Nau, D. S., Reisner, E., & Goldman, R. P. (2008). Using classical plannerssolve nondeterministic planning problems. Proc. Int. Conf. AutomatedPlanning Scheduling (ICAPS), pp. 190197.Lang, T., & Toussaint, M. (2009a). Approximate inference planning stochastic relational worlds. Proc. Int. Conf. Machine Learning (ICML), pp. 585592.Lang, T., & Toussaint, M. (2009b). Relevance grounding planning relational domains.Proc. European Conf. Machine Learning (ECML), pp. 736751.47fiLang & ToussaintLittle, I., & Thiebaux, S. (2007). Probabilistic planning vs replanning. ICAPS-WorkshopInternational Planning Competition: Past, Present Future.Littman, M. L., Goldsmith, J., & Mundhenk, M. (1997). computational complexityprobabilistic planning. Journal Artificial Intelligence Research, 9, 136.Murphy, K. P. (2002). Dynamic Bayesian Networks: Representation, Inference Learning. Ph.D. thesis, UC Berkeley.Murphy, K. P., & Weiss, Y. (2001). factored frontier algorithm approximate inference DBNs. Proc. Conf. Uncertainty Artificial Intelligence (UAI),pp. 378385.Pasula, H. M., Zettlemoyer, L. S., & Kaelbling, L. P. (2007). Learning symbolic modelsstochastic domains. Journal Artificial Intelligence Research, 29, 309352.Poon, H., & Domingos, P. (2007). Sound efficient inference probabilisticdeterministic dependencies. Proc. AAAI Conf. Artificial Intelligence(AAAI).Sanner, S., & Boutilier, C. (2007). Approximate solution techniques factored first-orderMDPs. Proc. Int. Conf. Automated Planning Scheduling (ICAPS),pp. 288295.Sanner, S., & Boutilier, C. (2009). Practical solution techniques first-order MDPs.Artificial Intelligence, 173 (5-6), 748788.Shachter, R. (1988). Probabilistic inference influence diagrams. Operations Research,36, 589605.Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MITPress.Teichteil-Konigsbuch, F., Kuter, U., & Infantes, G. (2010). Aggregation generatingpolicies MDPs. appear Proc. Int. Conf. Autonomous AgentsMultiagent Systems.Toussaint, M., & Storkey, A. (2006). Probabilistic inference solving discrete continuous state Markov decision processes. Proc. Int. Conf. Machine Learning(ICML), pp. 945952.Toussaint, M., Storkey, A., & Harmeling, S. (2010). Expectation-maximization methodssolving (PO)MDPs optimal control problems. Chiappa, S., & Barber, D.(Eds.), Inference Learning Dynamic Models. Cambridge University Press.van Otterlo, M. (2009). Logic Adaptive Behavior. IOS Press, Amsterdam.Walsh, T. J. (2010). Efficient learning relational models sequential decision making.Ph.D. thesis, Rutgers, State University New Jersey, New Brunswick, NJ.48fiPlanning Noisy Probabilistic Relational RulesWang, C., Joshi, S., & Khardon, R. (2008). First order decision diagrams relationalMDPs. Journal Artificial Intelligence Research, 31, 431472.Weld, D. S. (1999). Recent advances AI planning. AI Magazine, 20 (2), 93123.Wu, J.-H., Kalyanam, R., & Givan, R. (2008). Stochastic enforced hill-climbing. Proc.Int. Conf. Automated Planning Scheduling (ICAPS), pp. 396403.Yoon, S. W., Fern, A., & Givan, R. (2007). FF-Replan: baseline probabilistic planning.Proc. Int. Conf. Automated Planning Scheduling (ICAPS), pp. 352359.Yoon, S. W., Fern, A., Givan, R., & Kambhampati, S. (2008). Probabilistic planning viadeterminization hindsight. Proc. AAAI Conf. Artificial Intelligence(AAAI), pp. 10101016.Younes, H. L., & Littman, M. L. (2004). PPDDL1.0: extension PDDL expressingplanning domains probabilistic effects. Tech. rep., Carnegie Mellon University.49fiJournal Artificial Intelligence Research 39 (2010) 689743Submitted 05/10; published 12/10Best-First Heuristic Search Multicore MachinesEthan BurnsSofia LemonsWheeler RumlEABURNS CS . UNH . EDUSOFIA . LEMONS CS UNH . EDURUML CS . UNH . EDUDepartment Computer ScienceUniversity New HampshireDurham, NH 03824 USARong ZhouRZHOU PARC . COMEmbedded Reasoning AreaPalo Alto Research CenterPalo Alto, CA 94304 USAAbstractharness modern multicore processors, imperative develop parallel versions fundamental algorithms. paper, compare different approaches parallel best-first searchshared-memory setting. present new method, PBNF, uses abstraction partition statespace detect duplicate states without requiring frequent locking. PBNF allows speculativeexpansions necessary keep threads busy. identify fix potential livelock conditionsapproach, proving correctness using temporal logic. approach general, allowingextend easily suboptimal anytime heuristic search. empirical comparison STRIPSplanning, grid pathfinding, sliding tile puzzle problems using 8-core machines, showA*, weighted A* Anytime weighted A* implemented using PBNF yield faster searchimproved versions previous parallel search proposals.1. Introductionwidely anticipated future microprocessors faster clock rates, insteadcomputing cores per chip. Tasks exist effective parallel algorithmssuffer slowdown relative total system performance. artificial intelligence, heuristicsearch fundamental widely-used problem solving framework. paper, comparedifferent approaches parallelizing best-first search, popular method underlying algorithmsDijkstras algorithm A* (Hart, Nilsson, & Raphael, 1968).best-first search, two sets nodes maintained: open closed. Open contains searchfrontier: nodes generated yet expanded. A*, open nodes sortedf value, estimated lowest cost solution path going node. Open typicallyimplemented using priority queue. Closed contains previously generated nodes, allowingsearch detect states reached via multiple paths search space avoid expandingmultiple times. closed list typically implemented hash table. central challengeparallelizing best-first search avoiding contention threads accessing openclosed lists. look variety methods parallelizing best-first search, focusingalgorithms based two techniques: parallel structured duplicate detection parallelretracting A*.c2010AI Access Foundation. rights reserved.fiB URNS , L EMONS , RUML , & Z HOUParallel structured duplicate detection (PSDD) originally developed Zhou Hansen(2007) parallel breadth-first search, order reduce contention shared data structuresallowing threads enjoy periods synchronization-free search. PSDD requires user supplyabstraction function maps multiple states, called nblock, single abstract state.present new algorithm based PSDD called Parallel Best-N Block-First (PBNF1 ). Unlike PSDD,PBNF extends easily domains non-uniform non-integer move costs inadmissibleheuristics. Using PBNF infinite search space give rise livelock, threads continuesearch goal never expanded. discuss condition avoidedPBNF using method call hot nblocks, well use bounded model checking testeffectiveness. addition, provide proof correctness PBNF framework, showingliveness completeness general case.Parallel retracting A* (PRA*) created Evett, Hendler, Mahanti, Nau (1995). PRA*distributes search space among threads using hash nodes state. PRA*, duplicatedetection performed locally; communication peers required transfer generatedsearch-nodes home processor. PRA* sensitive choice hashing function useddistribute search space. show new hashing function, based state spaceabstraction used PSDD, give PRA* significantly better performance domains.Additionally, show communication cost incurred naive implementation PRA*prohibitively expensive. Kishimoto, Fukunaga, Botea (2009) present method helpsalleviate cost communication PRA* using asynchronous message passing primitives.evaluate PRA* (and variants), PBNF algorithms empirically using dual quadcore Intel machines. study behavior three popular search domains: STRIPS planning,grid pathfinding, venerable sliding tile puzzle. empirical results show simplestparallel search algorithms easily outperformed serial A* search even runeight threads. results also indicate adding abstraction PRA* algorithm givelarger increase performance simply using asynchronous communication, although usingmodifications together may outperform either one used own. Overall, PBNFalgorithm often gives best performance.addition finding optimal solutions, show adapt several algorithmsbounded suboptimal search, quickly finding w -admissible solutions (with cost within factor woptimal). provide new pruning criteria parallel suboptimal search prove algorithms using retain w -admissibility. results show that, sufficiently difficult problems,parallel search may significantly outperform serial weighted A* search. also foundadvantage parallel suboptimal search increases problem difficulty.Finally, demonstrate parallel searches, PBNF PRA*, lead naturallyeffective anytime algorithms. also evaluate obvious parallel anytime search strategiesrunning multiple weighted A* searches parallel different weights. showparallel anytime searches able find better solutions faster serial counterpartsalso able converge quickly optimal solutions.1. Peanut Butter N (marshmallow) Fluff, also known fluffernutter, well-known childrens sandwichUSA.690fiB EST-F IRST EARCH ULTICORE ACHINES2. Previous Approachesmuch previous work parallel search. briefly summarize selected proposalsturning foundation work, PRA* PSDD algorithms.2.1 Depth- Breadth-first ApproachesEarly work parallel heuristic search investigated approaches based depth-first search. Twoexamples distributed tree search (Ferguson & Korf, 1988), parallel window search (Powley& Korf, 1991).Distributed tree search begins single thread, given initial state expand.time node generated unused thread assigned node. threads allocatedtree depth-first manner free threads assign. occurs,thread continue searching children depth-first search. solutionsubtree found passed tree parent thread child thread becomes freere-allocated elsewhere tree. Parent threads go sleep children search,waking children terminate, passing solutions upward parents recursively.keep closed list, depth-first search cannot detect duplicate states givegood search performance domains many duplicate states, grid pathfindingplanning domains.Parallel window search parallelizes iterative deepening A* (IDA*, see Korf, 1985) algorithm. parallel window search, thread assigned cost-bound perform costbounded depth-first search search space. problem approach IDA*spend least half search time final iteration since every iteration still performedsingle thread, search limited speed single thread. addition, nonuniform costs foil iterative deepening, may good way choose newupper-bounds give search geometric growth.Holzmann Bosnacki (2007) able successfully parallelize depth-first searchmodel checking. authors able demonstrate technique distributes nodesbased search depth able achieve near linear speedup domain model checking.research used graphics processing units (GPUs) parallelize breadth-first searchuse two-player games (Edelkamp & Sulewski, 2010). following sections describealgorithms intent parallelizing best-first search.2.2 Simple Parallel Best-first Searchsimplest approach parallel best-first search open closed lists sharedamong threads (Kumar, Ramesh, & Rao, 1988). maintain consistency data structures,mutual exclusion locks (mutexes) need used ensure single thread accesses datastructure time. call search parallel A*. Since node expanded takenopen list node generated looked closed list every thread,approach requires lot synchronization overhead ensure consistency data structures.see Section 4.3, naive approach performs worse serial A*.much work designing complex data structures retain correctnessconcurrent access. idea behind special wait-free data structures many threadsuse portions data structure concurrently without interfering one another.691fiB URNS , L EMONS , RUML , & Z HOUapproaches use special compare-and-swap primitive ensure that, modifyingstructure, get modified another thread. implemented simple parallel A* search,call lock-free parallel A*, threads access single shared, concurrent priorityqueue concurrent hash table open closed lists, respectively. implementedconcurrent priority queue data structure Sundell Tsigas (2005). closed list, usedconcurrent hash table implemented array buckets, concurrentordered list developed Harris (2001). lock-free data structures used implement LPA*require special lock-free memory manager uses reference counting compare-and-swapbased stack implement free list (Valois, 1995). see that, even sophistocatedstructures, straightforward parallel implementation A* give competitive performance.One way avoiding contention altogether allow one thread handle synchronizationwork done threads. K -Best-First Search (Felner, Kraus, & Korf, 2003) expandsbest k nodes once, handled different thread. implementation,master thread takes k best nodes open gives one worker. workers expandnodes master checks children duplicates inserts open list.allows open closed used without locking, however, order adhere strictk -best-first ordering approach requires master thread wait workers finishexpansions handing new nodes. domains used paper, node expansionparticularly slow, show method scale well.One way reduce contention search access closed list less frequently. technique called delayed duplicate detection (DDD) (Korf, 2003), originally developed externalmemory search, used temporarily delay access closed list. several variations proposed, basic principle behind DDD generated nodes addedsingle list certain condition met (a depth level fully expanded, maximum listsize reached (Stern & Dill, 1998), etc.) condition met, list sorteddraw duplicate nodes together. nodes list checked closed list,best version kept inserted onto open list. initial DDD algorithm usedbreadth-first frontier search therefore previous depth-layer required duplicatedetection. parallel version later presented Niewiadomski, Amaral, Holte (2006a),split depth layer sections maintained separate input output lists each.later merged order perform usual sorting duplicate detection methods.large synchronization step, however, incur costs similar KBFS. also depends uponexpensive workload distribution scheme ensure processors work do, decreasing bottleneck effect nodes distributed unevenly, increasing algorithmsoverhead. later parallel best-first frontier search based DDD presented (Niewiadomski,Amaral, & Holte, 2006b), incurs even overhead requiring synchronizationthreads maintain strict best-first ordering.Jabbar Edelkamp (2006) present algorithm called parallel external A* (PEA*) usesdistributed computing nodes external memory perform best-first search. PEA* splitssearch space set buckets contain nodes g h values.algorithm performs best-first search exploring buckets lowest f value beginningone lowest g. master node manages requests distribute portions currentbucket various processing nodes expanding single bucket performed parallel.avoid contention, PEA* relies operating system synchronize access filesshared among nodes. Jabbar Edelkamp used PEA* algorithm parallelize692fiB EST-F IRST EARCH ULTICORE ACHINESmodel-checker achieved almost linear speedup. partitioning g h worksdomains general nodes g h values. tends casedomains real-valued edge costs. turn attention two algorithms reappearthroughout rest paper: PRA* PSDD.2.3 Parallel Retracting A*PRA* (Evett et al., 1995) attempts avoid contention assigning separate open closed liststhread. hash state representation used assign nodes appropriate threadgenerated. (Full PRA* also includes retraction scheme reduces memory useexchange increased computation time; consider feature paper.)choice hash function influences performance algorithm, since determines waywork distributed. Note standard PRA*, thread may communicatepeers, thread needs synchronized message queue peers add nodes.multicore setting, implemented requiring thread take lock message queue.Typically, requires thread sending (or receiving) message wait operationcomplete continue searching. less bottleneck singleglobal, shared open list, see still expensive. also interestingnote PRA* variants mentioned practice type delayed duplicate detection,store duplicates temporarily checking thread-local closed listpossibly inserting open list.2.3.1 MPROVEMENTSKishimoto et al. (2009) note original PRA* implementation improved removing synchronization requirement message queues nodes. Instead, useasynchronous send receive functionality MPI message passing library (Snir & Otto,1998) implement asynchronous version PRA* call Hash Distributed A* (HDA*).HDA* distributes nodes using hash function way PRA*, except sendingreceiving nodes happens asynchronously. means threads free continue searchingnodes communicated peers transit.contact authors HDA*, created implementation HDA* multicoremachines extra overhead message passing asynchronous communication threads shared memory setting. Also, implementation HDA* allows usmake fair comparison algorithms sharing common data structures priorityqueues hash tables.implementation, HDA* thread given single queue incoming nodes oneoutgoing queue peer thread. queues implemented dynamically sized arrayspointers search nodes. generating nodes, thread performs non-blocking callacquire lock2 appropriate peers incoming queue, acquiring lock availableimmediately returning failure busy, rather waiting. lock acquired simplepointer copy transfers search node neighboring thread. non-blocking call failsnodes placed outgoing queue peer. operation require lockoutgoing queue local current thread. certain number expansions, threadattempts flush outgoing queues, never forced wait lock send nodes.2. One non-blocking call pthread mutex trylock function POSIX standard.693fiB URNS , L EMONS , RUML , & Z HOUFigure 1: simple abstraction. Self-loops eliminated.also attempts consume incoming queue waits lock open list empty,case work do. Using simple efficient implementation,confirmed results Kishimoto et al. (2009) show asynchronous versionPRA* (called HDA*) outperforms standard synchronous version. Full results presentedSection 4.PRA* HDA* use simple representation-based node hashing scheme one,example, used look nodes closed lists. present two new variants, APRA*AHDA*, make use state space abstraction distribute search nodes among processors.Instead assigning nodes thread, thread assigned set blocks search spaceblock corresponds state abstract space. intuition behind approachchildren single node assigned small subset remote threadsand, fact, often assigned back expanding thread itself. reduces numberedges communication graph among threads search, reducing chances threadcontention. Abstract states distributed evenly among threads using modulus operatorhope open nodes always available thread.2.4 Parallel Structured Duplicate DetectionPSDD major previously-proposed alternative PRA*. intention PSDD avoidneed lock every node generation avoid explicitly passing individual nodesthreads. builds idea structured duplicate detection (SDD), originally developed external memory search (Zhou & Hansen, 2004). SDD uses abstraction function,many-to-one mapping states original search space states abstract space.abstract node state mapped called image. nblock set nodesstate space image abstract space. abstraction function creates abstract graph nodes images nodes state space. two states successorsstate space, images successors abstract graph. Figure 1 shows state spacegraph (left) consisting 36 nodes abstract graph (right) consists nine nodes.node abstract graph represents grouping four nodes, called nblock, original statespace, shown dotted lines state space graph left.694fiB EST-F IRST EARCH ULTICORE ACHINESFigure 2: Two disjoint duplicate detection scopes.nblock open closed list. avoid contention, thread acquire exclusiveaccess nblock. Additionally, thread acquires exclusive access nblocks correspond successors abstract graph nblock searching. nblockcall set nblocks successors abstract graph duplicate detection scope.abstract nodes access required order performperfect duplicate detection expanding nodes given nblock. thread expandsnode n nblock b children n must fall within b one nblocks successorsb abstract graph. Threads determine whether new states generated expandingn duplicates simply checking closed lists nblocks duplicate detection scope.require synchronization thread exclusive access set nblocks.PSDD, abstract graph used find nblocks whose duplicate detection scopes disjoint. nblocks searched parallel without locking node expansions.Figure 2 shows two disjoint duplicate detection scopes delineated dashed lines differentpatterns. nblock use thread whose duplicate detection scope alsouse considered free. free nblock available thread acquire searching. Free nblocks found explicitly tracking, nblock b, (b), number nblocksamong bs successors use another thread. nblock b acquired(b) = 0.advantage PSDD requires single lock, one controlling manipulationabstract graph, lock needs acquired threads finding new freenblock search. means threads need synchronize expanding nodes,common operation.Zhou Hansen (2007) used PSDD parallelize breadth-first heuristic search (Zhou & Hansen,2006). algorithm, nblock two lists open nodes. One list contains open nodescurrent search depth contains nodes next search depth. thread,nodes current search depth acquired nblock expanded. childrengenerated put open list next depth nblock map (whichduplicate detection scope nblock searched) long duplicates.current nblock nodes current depth, swapped free nblock695fiB URNS , L EMONS , RUML , & Z HOUopen nodes depth. nblocks open nodes current depth,threads synchronize progress together next depth. admissible heuristic usedprune nodes fall current solution upper bound.2.4.1 MPROVEMENTSPSDD viewed general framework parallel search, terminology, PSDDrefers instance SDD parallel setting uses layer-based synchronization breadthfirst search. subsection, present two algorithms use PSDD framework attemptimprove PSDD algorithm specific ways.implemented Zhou Hansen (2007), PSDD algorithm uses heuristic estimatenode pruning; effective tight upper bound already available.cope situations good bound available, implemented novel algorithmusing PSDD framework uses iterative deepening (IDPSDD) increase bound.report below, approach effective domains grid pathfindinggeometrically increasing number nodes within successive f bounds.Another drawback PSDD breadth-first search cannot guarantee optimality domainsoperators differing costs. anticipation problems, Zhou Hansen (2004)suggest two possible extensions work, best-first search speculative best-first layeringapproach allows larger layers cases nodes (or nblocks)f value. knowledge, first implement test algorithms.Best-first PSDD (BFPSDD) uses f value layers instead depth layers. meansnodes expanded given layer (lowest) f value. BFPSDD provides bestfirst search order, may incur excessive synchronization overhead nodesf layer. ameliorate this, loosen best-first ordering enforcing least nodesexpanded abandoning non-empty nblock. (Zhou & Hansen, 2007 credit Edelkamp &Schrodl, 2000 idea.) Also, populating list free nblocks layer,nblocks nodes current layers f value used minimum k nblocksadded k four times number threads. (This value k gave better performancevalues tested.) allows us add additional nblocks small layers order amortizecost synchronization. addition, tried alternative implementation BFPSDD usedrange f values layer. parameter f used proscribe width (in f values)layer search. implementation perform well present resultsit. either enhancements, threads may expand nodes f values greatercurrent layer. first solution found may optimal, search continuesremaining nodes pruned incumbent solution.surveyed existing approaches parallel best-first search, present newapproach comprises main algorithmic contribution paper.3. Parallel Best-N Block-First (PBNF)ideal scenario, threads would busy expanding nblocks contain nodes lowestf values. approximate this, combine PSDDs duplicate detection scopes ideaLocalized A* algorithm Edelkamp Schrodl (2000). Localized A*, designedimprove locality external memory search, maintains sets nodes residememory page. decision set process next made help heap sets696fiB EST-F IRST EARCH ULTICORE ACHINES1. nblock open nodes2. lock; b best free nblock; unlock3. b worse best free nblock weve done fewer min expansions4.best open node b5.f (m) f (incumbent), prune open nodes b6.else goal7.f (m) < f (incumbent)8.lock; incumbent m; unlock9.else child c10.c closed list nblock11.insert c open list appropriate nblockFigure 3: sketch basic PBNF search, showing locking.ordered minimum f value set. maintaining heap free nblocks orderednblocks best f value, approximate ideal parallel search. call algorithm ParallelBest-N Block-First (PBNF) search.PBNF, threads use heap free nblocks acquire free nblock best opennode. thread search acquired nblock long contains nodes betternblock front heap. acquired nblock becomes worse best freeone, thread attempt release current nblock acquire better one containsopen nodes lower f values. layer synchronization, threads need waitunless nblocks free. first solution found may suboptimal, search must continueopen nodes f values worse incumbent solution. Figure 3 shows high-levelpseudo-code algorithm.PBNF designed tolerate search order approximately best-first,freedom introduce optimizations reduce overhead. possible nblocksmall number nodes better best free nblock, avoid excessive switchingrequiring minimum number expansions. Due minimum expansion requirementpossible nodes expanded thread arbitrarily worse frontier nodeminimum f . refer expansions speculative. viewed trading nodequality reduced contention abstract graph. Section 4.1 shows results experimentevaluates trade off.implementation also attempts reduce time thread forced wait lockusing non-blocking operations acquire lock whenever possible. Rather sleeping lockcannot acquired, non-blocking lock operation (such pthread mutex trylock)immediately return failure. allows thread continue expanding current nblock lockbusy. optimizations introduce additional speculative expansions wouldperformed serial best-first search.3.1 Livelockgreedy free-for-all order PBNF threads acquire free nblocks lead livelockdomains infinite state spaces. threads always acquire new nblocks without waitingopen nodes layer expanded, possible nblock containing goal697fiB URNS , L EMONS , RUML , & Z HOUnever become free. assurance nblocks duplicate detectionscope ever unused time. example, imagine situation threadsconstantly releasing acquiring nblocks prevent goal nblock becoming free.fix this, developed method called hot nblocks threads altruistically releasenblock interfering better nblock. call enhanced algorithm Safe PBNF.use term interference scope b refer set nblocks that, acquired,would prevent b free. interference scope includes bs successorsabstract graph, predecessors too. Safe PBNF, whenever thread checks heapfree nblocks determine release current nblock, also ensures acquirednblock better interferes (nblocks whose interference scopeacquired nblock in). finds better one, flags nblock hot. thread findsblocking hot nblock release nblock attempt free hot nblock.nblock b define h (b) number hot nblocks b interference scope of.h (b) 6= 0, b removed heap free nblocks. ensures thread acquirenblock preventing hot nblock becoming free.Consider, example, abstract graph containing four nblocks connected linear fashion:B C . possible execution PBNF alternate thread expandingnblocks C . situation arrises nblocks B never considered free.goals located nblock B then, infinite search space may livelock.Safe variant PBNF, however, expanding either C thread make surecheck f value best open node nblock B periodically. best node B seenbetter nodes C B flagged hot nblocks Clonger eligable expansion nblock B acquired.formally, let N set nblocks, Predecessors(x ) Successors(x ) setspredecessors successors abstract graph nblock x , H set hot nblocks,IntScope(b) = {l N : x Successors(b) : l Predecessors(x )} interference scopenblock b x partial order nblocks x iff minimum fvalue open nodes x lower y. three cases considerattempting set nblock b hot undirected abstract graph:1. H IntScope(b) = {} H {x N : b IntScope(x )} = {}; none nblocks binterferes interfere b hot, b set hot.2. x H : x IntScope(b) x b; b interfered better nblock alreadyhot, b must set hot.3. x H : x IntScope(b) b x ; b interfered nblock x worseb x already hot. x must un-flagged hot (updating h values appropriately)place b set hot.Directed abstract graphs two additional cases:4. x H : b IntScope(x ) b x ; b interfering nblock x b better xun-flag x hot set b hot.5. x H : b IntScope(x ) x b; b interfering nblock x x better bset b hot.698fiB EST-F IRST EARCH ULTICORE ACHINESscheme ensures never two hot nblocks interfering one anothernblock set hot best nblock interference scope. verify below,approach guarantees property nblock flagged hot eventually become free.Full pseudo-code Safe PBNF given Appendix A.3.2 Correctness PBNFGiven complexity parallel shared-memory algorithms, reassuring proofscorrectness. subsection verify PBNF exhibits various desirable properties:3.2.1 OUNDNESSSoundness holds trivially solution returned pass goal test.3.2.2 EADLOCKone lock PBNF thread currently holds never attempts acquiresecond time, deadlock cannot arise.3.2.3 L IVELOCKinteraction different threads PBNF quite complex, modeledsystem using TLA+ (Lamport, 2002) specification language. Using TLC model checker(Yu, Manolios, & Lamport, 1999) able demonstrate sequence states give riselivelock plain PBNF. Using similar model unable find example livelockSafe PBNF using three threads 12 nblocks undirected ring-shaped abstractgraph three threads eight nblocks directed graph.model state system represented four variables: state, acquired, isHotSuccs. state variable contains current action thread performing (either searchnextblock). acquired variable function thread ID acquired nblockvalue None currently nblock. variable isHot functionnblocks either TRUE FALSE depending whether given nblock flagged hot.Finally, Succs variable gives set successor nblocks nblock order buildnblock graph.model two actions: doSearch doNextBlock. doSearch action models searchstage performed PBNF thread. Since interested determining livelock,action abstracts away search procedure merely models thread maychoose valid nblock flag hot. setting nblock hot, thread changes statenext time selected perform action try acquire new nblock.doNextBlock simulates thread choosing next nblock one available. threadacquires nblock (if one free) sets state next time selected performaction search.TLA+ source model located Appendix B.Formal proof: addition model checking, TLA+ specification language designedallow formal proofs properties. allows properties proved unbounded space.Using model completed formal proof hot nblock eventually become free699fiB URNS , L EMONS , RUML , & Z HOUregardless number threads abstract graph. present English summary.First, need helpful lemma:Lemma 1 nblock n hot, least one nblock interference scopeuse. Also, n interfering hot nblocks.Proof: Initially nblocks hot. change thread searches releasesnblock. search, thread set n hot acquired nblockinterference scope n. Additionally, thread may set n hot createinterference another hot nblock. release, n hot, either final acquired nblockinterference scope released n longer hot, n still least one busy nblockinterference scope.2ready key theorem:Theorem 1 nblock n becomes hot, eventually added free listlonger hot.Proof: show number acquired nblocks interference scope hot nblockn strictly decreasing. Therefore, n eventually become free.Assume nblock n hot. Lemma 1, thread p nblock interference scope n, n interfering interfered hot nblocks. Assumethread q nblock interference scope n. four cases:1. p searches nblock. p acquire new nblock therefore number nblockspreventing n becoming free increase. p sets nblock hot,interference scope n Lemma 1. p release nblock sees n hot(see case 2).2. p releases nblock acquires new nblock free list. number acquirednblocks interference scope n decreases one p releases nblock. Since m,new nblock acquired p, free list, interference scope n.3. q searches nblock. q acquire new nblock therefore number nblockspreventing n becoming free increase. q sets nblock hot,interference scope n Lemma 1.4. q releases nblock (if one) acquires new nblock free list. Since m,new nblock acquired q, free list, interference scope nnumber nblocks preventing n becoming free increase.2prove progress property really care about:Theorem 2 node n minimum f value eventually expanded.Proof: consider ns nblock. three cases:1. nblock expanded. n minimum f , front openexpanded.700fiB EST-F IRST EARCH ULTICORE ACHINES2. nblock free. holds node minimum f value, frontfree list selected next expansion, reducing case 1.3. nblock free list interference scope another nblockcurrently expanded. thread expanding nblock checks interferencescope, mark better nblock hot. Theorem 1, eventually reach case 2.23.2.4 C OMPLETENESSfollows easily liveness:Corollary 1 heuristic admissible search space finite, goal returned onereachable.Proof: heuristic admissible, inherit completeness serial A* (Nilsson, 1980)Theorem 2. Nodes re-expanded g value improved, happenfinite number times, finite number expansions suffice exhaust search space. 23.2.5 PTIMALITYPBNFs expansion order strictly best-first, operates like anytime algorithm,optimality follows argument algorithms Anytime A* (Hansen &Zhou, 2007).Theorem 3 PBNF return optimal solutions.Proof: finding incumbent solution, search continues expand nodes minimumf value among frontier nodes greater equal incumbent solution cost. meanssearch terminate optimal solution.2discussing adapt PBNF suboptimal anytime search, first evaluateperformance optimal problem solving.4. Empirical Evaluation: Optimal Searchimplemented tested parallel heuristic search algorithms described threedifferent benchmark domains: grid pathfinding, sliding tile puzzle, STRIPS planning.discuss domain turn. exception planning domain, algorithmsprogrammed C++ using POSIX threading library run dual quad-core Intel Xeon E53201.86GHz processors 16Gb RAM. planning results algorithms written independently C pseudo code Appendix A. gives us additional confidencecorrectness pseudo code performance claims. planning experiments rundual quad-core Intel Xeon X5450 3.0GHz processors limited roughly 2GB RAM. openlists free lists implemented binary heaps except PSDD IDPSDD usedqueue giving less overhead since require access minimum valued elements.closed lists implemented hash tables. PRA* APRA* used queues incoming nodes,hash table used detect duplicates open closed. grids sliding tiles,701fiB URNS , L EMONS , RUML , & Z HOUused jemalloc library (Evans, 2006), special multi-thread-aware malloc implementation,instead standard glibc (version 2.7) malloc, found latter scales poorly6 threads. configured jemalloc use 32 memory arenas per CPU. planning, custommemory manager used also thread-aware uses memory pool thread.grids sliding tiles abstractions hand-coded and, nblock data structures createdlazily, visited part abstract graph instantiated. time taken createabstraction accounted wall time measurements two domains. STRIPSplanning abstractions created automatically creation times abstractionsreported separately described Section 4.5.4.1 Tuning PBNFsection present results set experiments designed test behaviorPBNF parameters changed. study effects two important parametersPBNF algorithm: minimum expansions required switching search new nblocksize abstraction. study used twenty 5000x5000 four-connected grid pathfindinginstances unit cost moves cell 0.35 probability obstacle.heuristic used Manhattan distance goal location. Error bars plots show 95%confidence intervals legends sorted mean dependent variable plot.PBNF algorithm, thread must perform minimum number expansionsable acquire new nblock searching. Requiring expansions switchesexpected reduce contention nblock graphs lock could increase total numberexpanded nodes. created instrumented version PBNF algorithm trackstime threads spent trying acquire lock amount time threadsspent waiting free nblock. fixed size abstraction 62,500 nblocksvaried number threads (from 1 8) minimum expansions (1, 8, 16, 32 64 minimumexpansions).upper left panel Figure 4 shows average amount CPU time secondsthread spent waiting acquire lock (y-axis) minimum expansions parameter increased (x-axis). line plot represents different number threads. seeconfiguration used amount time trying acquire lock eight threadsone minimum expansion. number threads decreased, less contentionlock fewer threads take it. number minimum required expansionsincreased contention also reduced. Around eight minimum expansions benefit increasing value seemed greatly diminish.upper right panel Figure 4 shows results CPU time spent waiting freenblock (y-axis) minimum expansions increased (x-axis). different amounttime waiting lock because, case, thread successfully acquired lockfound free nblocks available search. see configurationeight threads one minimum expansions caused longest amount time waitingfree nblock. number threads decreased required number minimumexpansions increased wait time decreased. amount time spent waiting, however, seemsfairly insignificant order magnitude smaller lock time. Again, seearound eight minimum expansions benefit increasing seemed diminish.702fi876543210.3average time waiting (seconds)average time acquiring locks (seconds)B EST-F IRST EARCH ULTICORE ACHINES0.20.1876543210.020.010.020406020total nodes expanded (1K nodes)minimum expansions4060minimum expansions2,6002,500876543212,400204060minimum expansionsFigure 4: PBNF locking behavior vs minimum expansions grid pathfinding 62,500nblocks. line represents different number threads.final panel, bottom Figure 4, shows total number nodes expanded (y-axis,thousands nodes) minimum expansions increased. Increasing minimumnumber expansions thread must make switching nblock better nodescaused search algorithm explore space may covered strictbest-first search. speculative expansions performed total numbernodes encountered search increased. also see adding threads increasednumber expanded nodes too.results experiment appears requiring eight expansions switching nblocks decreasing benefit respect locking waiting time.non-instrumented implementation PBNF found slightly greater values minimumexpansion parameter lead best total wall times. domain use valuegave best total wall time non-instrumented PBNF implementation.703fiB URNS , L EMONS , RUML , & Z HOU0.987654321876543210.08average time waiting (seconds)average time acquiring locks (seconds)1.20.60.30.060.040.020.05010015020025050total nodes expanded (1K nodes)abstraction size (1K nblocks)100150200250abstraction size (1K nblocks)2,6002,500876543212,40050100150200250abstraction size (1K nblocks)Figure 5: PBNF abstraction size: 5000x5000 grid pathfinding, 32 minimum expansions.Since PBNF uses abstraction decompose search space also important understandeffect abstraction size search performance. hypothesis using abstractstates would lead small number free nblocks therefore making threads spend lottime waiting nblock become free. hand, many abstract statesnodes nblock. happens, threads perform smallamount work exhausting open nodes nblock forced switchnew portion search space. time thread must switch nblocks contentionlock increased. Figure 5 shows results experiment performed verifytheory. plot fixed minimum expansions parameter 32 (which gave besttotal wall time grid pathfinding) varied number threads (from 1 8) sizeabstraction (10,000, 62,500 250,000 nblocks).upper left panel Figure 5 shows plot amount CPU seconds spent trying acquire lock (y-axis) versus size abstraction (x-axis). expected, abstractioncoarse little time spent waiting lock, size abstraction grew704fiB EST-F IRST EARCH ULTICORE ACHINESnumber threads increased amount time spent locking increased. eight threads250,000 nblocks 1 second CPU time spent waiting acquire lock. suspectthreads exhausting open nodes nblocks were, therefore,forced take lock acquire new portion search space.upper right panel Figure 5 shows amount time threads spent waitingnblock become free successfully acquired lock find nblocksavailable. Again, suspected, amount time threads wait free nblock decreasesabstraction size increased. available nblocks, disjoint portionssearch space available. experiments minimum expansions, amounttime spent waiting seems relatively insignificant compared time spent acquiring locks.bottom panel Figure 5 shows number nodes expanded increasedsize abstraction increased. finer grained abstractions algorithm expandednodes. time thread switches new nblock forced performleast minimum number expansions, therefore switches, forced expansions.4.2 Tuning PRA*turn looking performance impact PRA* abstraction asynchronous communication. First, compare PRA* without asynchronous communication. Resultsset experiments twenty 5000x5000 grid pathfinding set 250 random 15-puzzle instances solvable A* 3 million expansions shown Figure 6. line labeledsync. (PRA*) used synchronous communication, async. sends, used synchronous receives asynchronous sends, async. receives, used synchronous sends asynchronous receives async.(HDA*), used asynchronous communication sends receives. before, legendsorted mean performance error bars represent 95% confidence intervalsmean. vertical lines plots life cost grid pathfinding domains showconfigurations unable solve instances within 180 second time limit.combination asynchronous sends receives provided best performance.also see plots making sends asynchronous provided benefitmaking receives asynchronous. because, without asynchronous sends, node generated stop generating thread order communicate. Even communication batched,send may required go separate neighbor therefore single send operation mayrequired per-generation. receives, worst case receiving thread must stopexpansion receive next batch nodes. Since branching factor typical search spaceapproximately constant approximately constant factor send communicationsreceive communications worst case. Therefore, making sends asynchronous reducescommunication cost receives.Figure 7 shows results experiment compares PRA* using abstraction distributenodes among threads versus PRA* asynchronous communication. lines labeledfollows: sync. (PRA*) used synchronous communication, async. (HDA*) used asynchronous communication sync. abst. (APRA*) used synchronous communicationused abstraction distribute nodes among threads async. abst. (AHDA*) used combination asynchronous communication abstraction. Again, vertical lines plotslife cost grid pathfinding domains show configurations unable solve instanceswithin 180 second time limit.705fiB URNS , L EMONS , RUML , & Z HOUGrid Unit Four-waysync. (PRA*)async. receivesasync. sendsasync. (HDA*)sync. (PRA*)async. receivesasync. sendsasync. (HDA*)30wall time (seconds)30wall time (seconds)Grid Unit Eight-way20201010246824threadsGrid Life Four-way20068threadsGrid Life Eight-way200sync. (PRA*)async. receivesasync. sendsasync. (HDA*)sync. (PRA*)async. receivesasync. sendsasync. (HDA*)wall time (seconds)wall time (seconds)160120801004002468threads268threadssync. (PRA*)async. receivesasync. sendsasync. (HDA*)10wall time (seconds)415-Puzzles: 250 easy8642468threadsFigure 6: PRA* synchronization: 5000x5000 grids easy sliding tile instances.clear plots configurations PRA* used abstraction gave betterperformance PRA* without abstraction grid pathfinding domain. reason706fiB EST-F IRST EARCH ULTICORE ACHINESGrid Unit Four-waysync. (PRA*)async. (HDA*)sync. abst. (APRA*)async. abst. (AHDA*)sync. (PRA*)async. (HDA*)sync. abst. (APRA*)async. abst. (AHDA*)30wall time (seconds)30wall time (seconds)Grid Unit Eight-way20201010246824threadsGrid Life Four-way20068threadsGrid Life Eight-way200sync. (PRA*)async. (HDA*)sync. abst. (APRA*)async. abst. (AHDA*)sync. (PRA*)async. (HDA*)sync. abst. (APRA*)async. abst. (AHDA*)wall time (seconds)wall time (seconds)160120801004002468threads468threadssync. (PRA*)async. (HDA*)sync. abst. (APRA*)async. abst. (AHDA*)10wall time (seconds)215 Puzzles: 250 easy8642468threadsFigure 7: PRA* abstraction: 5000x5000 grids easy sliding tile instances.abstraction grid pathfinding often assign successors node expandedback thread generated them. happens communication required707fiB URNS , L EMONS , RUML , & Z HOUnodes simply checked local closed list placed local open listduplicates. abstraction, time communication requirednode edge abstract state expanded. case, children mapdifferent abstract state communication required. experiment also showsbenefits abstraction greater benefits asynchronous communication gridpathfinding problems. see trends sliding tile instances, howeverquite pronounced; confidence intervals often overlap.Overall, appears combination PRA* abstraction distributing nodesamong different threads using asynchronous communication gave best performance.following section show results comparison variant PRA*, SafePBNF algorithm best-first variant PSDD.4.3 Grid Pathfindingsection, evaluate parallel algorithms grid pathfinding domain. goaldomain navigate grid initial location goal location avoidingobstacles. used two cost models (discussed below) four-way eight-way movement.four-way grids, cells blocked probability 0.35 eight-way gridscells blocked probability 0.45. abstraction function used maps blocksadjacent cells abstract state, forming coarser abstract grid overlaid originalspace. heuristic Manhattan distance goal location. hash values states(which used distribute nodes PRA* HDA*) computed as: x ymax + statelocation. gives minimum perfect hash value state. domain abletune size abstraction results show execution best abstraction sizealgorithm relevant.4.3.1 F -WAY U NIT C OSTunit-cost model, move cost: one.Less Promising Algorithms Figure 8, shows performance comparison algorithms that,average, slower serial A*. algorithms tested 20 unit-cost four-waymovement 1200x2000 grids start location bottom left corner goal locationbottom right. x-axis shows number threads used solve instance y-axisshows mean wall clock time seconds. error bars give 95% confidence intervalmean wall clock time legend sorted mean performance.figure see PSDD gave worst average solution times. suspectlack tight upper bound PSDD uses pruning. see A*shared lock-free open closed list (LPA*) took, average, second longest amount timesolve problems. LPA*s performance improved 5 threads started dropthreads added. overhead special lock-free memory manager alongfact access lock-free data structures may require back-offs retries could accountpoor performance compared serial A*. next algorithm, going toplegend, KBFS slowly increased performance threads added howeverable beat serial A*. simple parallel A* implementation (PA*) using locksopen closed lists performed worse threads added four startedgive slow performance increase matching KBFS. PRA* algorithm using simple708fiB EST-F IRST EARCH ULTICORE ACHINES15PSDDLPA*KBFSPA*PRA*Serial A*wall time (seconds)129632468threadsFigure 8: Simple parallel algorithms unit cost, four-way 2000x1200 grid pathfinding.state representation based hashing function gave best performance graph fairlyerratic number threads changed, sometimes increasing sometimes decreasing. 68 threads, PRA* faster serial A*.also implemented IDPSDD algorithm tries find upper boundPSDD search using iterative deepening, results shown grid pathfinding domains. non-geometric growth number states increasing cost bound leadspoor performance iterative deepening grid pathfinding. Due poor performancealgorithms, show results remaining grid, tiles planning domains(with exception PSDD makes reappearance STRIPS planning evaluationSection 4.5, supply upper bound).Promising Algorithms upper left plot Figure 9 shows performance algorithmsunit-cost four-way grid pathfinding problems. y-axis represents speedup serial A*x-axis shows number threads use data point. Error bars indicate 95%confidence intervals mean 20 different instances. Algorithms legend orderedaverage performance. line labeled Perfect speedup shows perfect linear speedupadditional thread increases performance linearly.practical reference point speedup shown Achievable speedup line.perfect machine n processors, running n cores take time decreases linearlyn. real machine, however, hardware considerations memory bus contention prevent n-fold speedup. estimate overhead machines, ran setsn independent A* searches parallel 1 n 8 calculated total time setfinish. perfect machine sets would take time set n = 1.compute Achievable speedup ratio actual completion times time709fiB URNS , L EMONS , RUML , & Z HOUGrid Unit Four-wayGrid Unit Eight-way8Perfect speedupAchievable speedupSafe PBNFAHDA*BFPSDD6speedup serial A*speedup serial A*84Perfect speedupAchievable speedupSafe PBNFAHDA*BFPSDD642224682threadsGrid Life Four-way6868threadsGrid Life Eight-way8Perfect speedupAchievable speedupSafe PBNFAHDA*BFPSDD6speedup serial A*speedup serial A*8442Perfect speedupAchievable speedupAHDA*Safe PBNFBFPSDD6422468threadsspeedup serial A*824threads15 Puzzles: 250 easyPerfect speedupAchievable speedupSafe PBNFAHDA*6422468threadsFigure 9: Speedup results grid pathfinding sliding tile puzzle.set n = 1. threads given completion times sets, hC1 , C2 , ..., Cn i,1achievable speedup(t) = tCCt .710fiB EST-F IRST EARCH ULTICORE ACHINESupper left panel shows comparison AHDA* (PRA* asynchronous communication abstraction), BFPSDD Safe PBNF algorithm larger (5000x5000) unit-costfour-way problems. Safe PBNF superior algorithms, steadily decreasing solution times threads added average speedup serial A* 6xusing eight threads. AHDA* less stable performance, sometimes giving sharp speedupincrease sometimes giving decreased performance threads added. seventhreads AHDA* gave best performance, able reach 6x speedup serial A*search. BFPSDD algorithm solved problems faster threads added howevercompetitive PBNF AHDA* giving 3x speedup serial A* eightthreads.4.3.2 F -WAY L IFE C OSTMoves life cost model cost row number state moveperformedmoves top grid free, moves bottom cost 4999 (Ruml & Do,2007). differentiates shortest cheapest paths shownimportant distinction (Richter & Westphal, 2010; Cushing, Bentor, & Kambhampati, 2010).left center plot Figure 9 shows results format unit-cost variantnumber threads x axis speedup serial A* axis. average, Safe PBNFgave better speedup AHDA*, however AHDA* outperformed PBNF six seven threads.eight threads, however, APRA* perform better seven threads. algorithms achieve speedups close Achievable speedup domain.BFPSDD gave worst performance increase threads added reaching 3xspeedup.4.3.3 E IGHT-WAY U NIT C OSTeight-way movement pathplanning problems, horizontal vertical moves cost 1,diagonal movements cost 2. real-valued costs make domain different previoustwo path planning domains. upper right panel Figure 9 shows number threads xaxis speedup serial A* axis unit cost eight-way movement domain. seeSafe PBNF gave best average performance reaching 6x speedup eight threads.AHDA* outperform Safe PBNF average, however able achieve 6xspeedup serial A* seven threads. however, see AHDA* givestable performance increases threads. BFPSDD improved threads addedeight never reached 3x speedup.4.3.4 E IGHT-WAY L IFE C OSTmodel combines eight-way movement life cost models; tends difficult path planning domain presented paper. right center panel Figure 9 shows threadsx axis speedup serial A* axis. AHDA* gave best average speedupserial A* search, peaking 6x speedup seven threads. Although outperformed SafePBNF average eight threads AHDA* sharp decrease performance reachingalmost 5x speedup Safe PBNF around 6x speedup serial A*. BFPSDD peaks3x speedup eight threads.711fiB URNS , L EMONS , RUML , & Z HOUAHDA* minus Safe PBNF wall time (seconds)15 puzzles 250 easy AHDA* vs Safe PBNF paired difference(AHDA*) - (Safe PBNF)zero2102468threadsFigure 10: Comparison wall clock time Safe PBNF versus AHDA* sliding tile puzzle.4.4 Sliding Tile Puzzlesliding tile puzzle common domain benchmarking heuristic search algorithms.results, use 250 randomly generated 15-puzzles serial A* able solve within 3 millionexpansions.abstraction used sliding tile puzzles ignores numbers set tiles.example, results shown Safe PBNF bottom panel Figure 9 use abstractionlooks position blank, one two tiles. abstraction gives 3360 nblocks. orderAHDA* get maximum amount expansions map back expanding thread (asdescribed grids), abstraction uses one, two three tile. Since positionblank ignored, state generation move one, two three tiles generatechild nblock parent therefore requiring communication. heuristicused algorithms Manhattan distance heuristic. hash value used tiles statesperfect hash value based techniques presented Korf Schultze (2005).bottom panel Figure 9 shows results AHDA*, Safe PBNF slidingtiles puzzle instances. plot number threads x axis speedup serialA* axis. Safe PBNF best mean performance overlap confidenceintervals AHDA*. BFPSDD unable show speedup serial A* performanceshown plot.sliding tile puzzles vary much difficulty, domain also paireddifference test, shown Figure 10. data used Figure 10 collected setruns shown bottom panel Figure 9. y-axis figure, however, average,instances, time AHDA* took instance minus time Safe PBNFtook. paired test gives powerful view algorithms relative performance. Valuesgreater 0.0 represent instances Safe PBNF faster AHDA* values lower712fiB EST-F IRST EARCH ULTICORE ACHINES0.0 represent instances AHDA* faster. error bars show 95% confidenceinterval mean. clearly see Safe PBNF algorithm significantly fasterAHDA* across numbers threads 1 8.4.5 STRIPS Planningaddition path planning sliding tiles domains, algorithms also embeddeddomain-independent optimal sequential STRIPS planner. contrast previous two domainsnode expansion quick therefore difficult achieve good parallel speedup,node expansion STRIPS planning relatively slow. planner used experiments usesregression max-pair admissible heuristic Haslum Geffner (2000). abstractionfunction used domain generated dynamically per-problem basis and, following ZhouHansen (2007), time taken account solution times presentedalgorithms. abstraction function generated greedily searching space possibleabstraction functions (Zhou & Hansen, 2006). algorithm needs evaluate one candidate abstraction unselected state variables, trivially parallelizedmultiple threads work different candidate abstractions.Table 1 presents results A*, AHDA*, PBNF, Safe PBNF, PSDD (given optimal upperbound pruning using divide-and-conquer solution reconstruction), APRA* BFPSDD.values cell total wall time seconds taken solve instance. valueindicates program ran memory. best result problem resultswithin 10% best marked bold. Generally, parallel algorithms ablesolve instances faster allowed threads. parallel algorithmsable solve instances much faster serial A* seven threads. PBNF algorithm (eitherPBNF Safe PBNF) gave best solution times three domains. Interestingly,plain PBNF often little faster safe version, failed solve two problems.likely due livelock, although could also simply hot nblocks fix forcesSafe PNBF follow different search order PBNF. AHDA* tended give second-bestsolution times, followed PSDD given optimal solution cost up-front pruning.BFPSDD often better APRA*,column, labeled Abst. shows time taken parallel algorithms seriallygenerate abstraction function. Even abstraction generation time added solutiontimes parallel algorithms outperform A* seven threads, except block-14 domaintime taken generate abstraction actually longer time A* took solveproblem.4.6 Understanding Search Performanceseen PBNF algorithm tends better performance AHDA* algorithmoptimal search. section show results set experiments attemptsdetermine factors allow PBNF perform better domains. considered threehypotheses. First, PBNF may achieve better performance expands fewer nodes fvalues greater optimal solution cost. Second, PBNF may achieve better search performancetends many fewer nodes priority queue AHDA*. Finally, PBNFmay achieve better search performance spends less time coordinating threads.following subsections show results experiments performed test713fiB URNS , L EMONS , RUML , & Z HOUthreadslogistics-6blocks-14gripper-7satellite-6elevator-12freecell-3depots-7driverlog-11gripper-8threadslogistics-6blocks-14gripper-7satellite-6elevator-12freecell-3depots-7driverlog-11gripper-8threadslogistics-6blocks-14gripper-7satellite-6elevator-12freecell-3depots-7driverlog-11gripper-8A*12.305.19117.78130.85335.74199.0611.176.2139.5877.02150.39127.07156.36154.15235.4611.447.3762.6195.11215.19153.71319.48334.28569.26AHDA*13571.440.70 0.48 0.407.135.07 2.25 2.1359.51 33.95 15.97 12.6995.50 33.59 24.11 18.24206.16 96.82 67.68 57.10147.96 93.55 38.24 27.37299.66 126.34 50.97 39.10315.51 85.17 51.28 48.91532.51 239.22 97.61 76.34SafePBNF350.640.562.692.2016.8711.2324.0917.2953.4534.2347.1038.0763.0442.9159.9838.8498.2163.6570.622.029.2113.6727.0237.0234.6631.2251.50APRA*3570.751.090.815.303.262.9243.13 37.62 26.7842.85 67.38 52.82243.24 211.45 169.92122.00 63.47 37.94138.30 67.24 49.5899.37 89.73 104.87351.87 236.93 166.1911.206.3665.7461.53162.76126.31159.98155.93387.8111.276.2839.6668.14156.64185.68229.88PBNF350.72 0.583.76 2.7016.43 10.9234.15 20.8456.25 34.8464.06 44.0595.63 60.87PSDD350.780.683.572.9629.3721.8823.5616.7162.6843.3453.7645.4773.0057.6563.2041.85172.01120.79BFPSDD1352.111.06 0.797.784.32 3.8741.56 18.02 12.2162.01 24.06 20.43151.50 58.52 40.95131.30 57.14 47.74167.24 66.89 48.32152.08 61.63 42.81243.44 101.11 70.84Table 1: Wall time STRIPS planning problems.71470.532.638.5716.5726.7236.0848.3270.642.8719.1913.2636.6643.7154.7034.02105.54Abst.70.713.4010.2013.5432.4845.0742.6834.7059.1810.427.90.810.7173.69.71.1fiB EST-F IRST EARCH ULTICORE ACHINESAHDA*Safe PBNFAHDA*Safe PBNF6e+084e+07Cumulative expansionsCumulative expansions5e+073e+072e+074e+082e+081e+07000.70.80.91Factor optimal cost0.60.91.2Factor optimal costFigure 11: Cumulative normalized f value counts nodes expanded eight threads unitcost four-way grid pathfinding (left) 15-puzzle (right).three hypotheses. results experiments agree first two hypotheses, however,appears third hypothesis hold and, fact, PBNF occasionally spends timecoordinating threads AHDA*.4.6.1 N ODE Q UALITYPBNF AHDA* merely approximate best-first order, may expandnodes f values greater optimal solution cost. thread expands nodef value greater optimal solution cost effort waste nodesmust expanded searching optimal solution f values lessoptimal cost. addition this, search algorithms may re-expand nodes lowercost path found. happens work wasted first sub-optimal expansionnode.Threads PBNF able choose nblock expand based quality nodesfree nblocks. AHDA*, however, thread must expand nodes assignedit. hypothesized PBNF may expand fewer nodes f values greateroptimal solution cost threads control quality nodeschoose expand.collected f value node expanded PBNF AHDA*. Figure 11 showscumulative counts f values nodes expanded PBNF AHDA* setunit-cost four-way 5000x5000 grid pathfinding instances used Section 4.3 (right)15-puzzle instances used Section 4.4 (left). plots, x axis shows f valueexpanded nodes factor optimal solution cost given instance. axis showscumulative count nodes expanded given normalized f set instances.715fiMean CPU time (seconds)B URNS , L EMONS , RUML , & Z HOU3e-052e-051e-050SafePBNFAHDA*Grid pathfindingSafePBNFAHDA*15-puzzleFigure 12: Mean CPU time per open list operation.looking y-location right-most tip line find total number nodesexpanded algorithm summed instances.left panel Figure 11 see algorithms tended expandsmall number nodes f values greater optimal solution cost gridpathfinding domain. AHDA* algorithm expanded nodes total set instances.PBNF AHDA* must expand nodes optimal solution cost.this, way AHDA* greater number expansions nodes factor1 re-expanded nodes. appears AHDA* re-expanded nodes PBNFseems account fact AHDA* expanded nodes total.right half Figure 11 shows results 15-puzzle. see that, again, AHDA*expanded nodes total PBNF. domain algorithms expanded approximatelynumber nodes f values less optimal solution cost. also seeplot AHDA* expanded many nodes f values greater equaloptimal solution cost. summary, PBNF expanded fewer nodes better quality nodesAHDA* grid pathfinding sliding tiles domains. speculate may happenPBNF threads allowed choose portion space searchchoose based low f value. AHDA* threads must search nodes mapnodes may good.4.6.2 PEN L IST IZESfound that, since PBNF breaks search space many different nblocks, tendsdata structures many fewer entries AHDA*, breaks search spacebased number threads. Since interested general-purpose algorithms handledomains real-valued costs (like eight-way grid pathfinding) PBNF AHDA* use binaryheaps implement open lists. PBNF one heap per nblock (that one per abstract state)whereas AHDA* one heap per thread. number nblocks greater716fiB EST-F IRST EARCH ULTICORE ACHINESnumber threads AHDA* many nodes PBNF heaps. causesheap operations AHDA* take longer heap operations PBNF.cost operations large heaps shown greatly impact overall performancealgorithm (Dai & Hansen, 2007). order determine extent large heaps effectperformance AHDA* added timers heap operations algorithms. Figure 12shows mean CPU time single open list operation unit-cost four-way grid pathfindingdomain 15-puzzle. boxes show second third quartiles line drawnacross median. whiskers show extremes data except data points residingbeyond first third quartile 1.5 times inter-quartile range signifiedcircle. shaded rectangle shows 95% confidence interval mean. see that,cases, AHDA* tended spend time performing heap operations PBNFtypically spent nearly time per heap operation. Heap operations must performednode expanded may required node generation. Even though timestens microseconds frequency operations high single search.Finally, described Hansen Zhou (2007), reduction open list sizes also explain good single thread performance PBNF experiences STRIPS planning (see Table 1).Hansen Zhou point that, although A* optimally efficient terms node expansions,necessarily optimal respect wall time. found benefit managing smalleropen lists enabled Anytime weighted A* algorithm outperform A* wall time even thoughexpanded nodes converging optimal solution. describe Section 9,good single thread performance may also caused speculative expansions pruning.4.6.3 C OOORDINATION OVERHEADthird hypothesis amount time algorithm spent coordination overhead might differ. parallel algorithms must spend time accessing data structuresshared among multiple threads. cause overhead two places. first place coordination overhead seen synchronization access shared data structures. PBNFtwo modes locking nblock graph. First, thread ownership nblock opennodes remain expanded use try lock work coulddone fails acquire lock. Otherwise, nodes thread could expandattempt acquire lock nblock graph using normal operation blocksfailure. AHDA* use try lock receive queue expansion nodesqueue open list. implementation AHDA* use blocking lockoperation thread nodes remaining expand nodes remaining sendreceive buffers.second place overhead may incurred threads nodes expand.PBNF occurs thread exhausts current nblock free nblocksacquire. thread must wait new nblock becomes free. AHDA* open nodes mapthread may nodes expand. situation thread busy-waitnode arrives receive queue. either situation, locking waiting, time wastedthreads actively searching space.evaluating coordination overhead, combine amount time spent waitinglock amount time waiting without nodes expand. Figure 13 shows per-threadcoordination times locks, waiting sum two normalized total wall time.717fipercentage wall timeB URNS , L EMONS , RUML , & Z HOU84percentage wall timeSafePBNF AHDA*LocksSafePBNF AHDA*WaitSafePBNF AHDA*SumSafePBNF AHDA*WaitSafePBNF AHDA*Sum8040SafePBNF AHDA*LocksFigure 13: Per-thread ratio coordination time wall time unit-cost four-way pathfinding (top)15-puzzle (bottom).Unlike previous set boxplots, individual data points residing extremes signifiedcircles order improve readability. Locks column plot shows distributiontimes spent thread waiting lock, Wait column shows distribution timesthreads spent waiting without nodes available expand Sum column showsdistribution sum mean lock wait times.left side Figure 13 shows results grid pathfinding. Locks column seethreads AHDA* spent almost time acquiring locks. expected AHDA*uses asynchronous communication. appears amount time threads PBNF spentacquiring locks significantly greater AHDA*. Wait column plotshows PBNF AHDA* appeared threads spend nearly amount timewaiting without nodes expand. Finally, Sum column shows threads PBNFspent time overall coordinating threads.bottom half Figure 13 shows coordination overhead 15-puzzle domain. Again,see threads AHDA* spent almost time acquiring lock. Individual threads PBNF,however, tended spend larger fraction time waiting locks sliding tiles domain718fiB EST-F IRST EARCH ULTICORE ACHINESgrid pathfinding. Wait column figure see AHDA* spenttime PBNF without nodes expand. Finally, see that, all, PBNF spent timecoordinating threads AHDA*.Overall experiments verified first two hypotheses PBNF expanded betterquality nodes AHDA* spent less time performing priority queue operationsAHDA*. also found third hypothesis hold threads PBNF tendedcoordination overhead AHDA* seems out-weighed twofactors.4.7 Summarysection shown results empirical evaluation optimal parallel best-firstsearch algorithms. shown several simple parallel algorithms actually slowerserial A* search even offered computing power. Additionally showed empirical results set algorithms make good use parallelism outperform serial A*.Overall Safe PBNF algorithm gave best consistent performance latter setalgorithms. AHDA* variant PRA* second fastest mean performance domains.also shown using abstraction PRA* style search distribute nodes amongdifferent threads give significant boost speed reducing amount communication. modification PRA* appears lot helpful simply using asynchronouscommunication. Using improvements conjunction (AHDA*), yields competitivealgorithm additional feature relying shared memory.Finally, performed set experiments attempt explain Safe PBNF tendedgive better search performance AHDA*. experiments looked three factors: node quality,open list sizes thread-coordination overhead. concluded PBNF fasterexpands fewer nodes suboptimal f values takes less time perform priority queueoperations.5. Bounded Suboptimal SearchSometimes acceptable even preferable search solution optimal. Suboptimalsolutions often found much quickly lower memory requirements optimalsolutions. section show create bounded-suboptimal variants bestoptimal parallel search algorithms.Weighted A* (Pohl, 1970), variant A* orders search f (n) = g(n) + w h(n),w > 1, probably popular suboptimal search. guarantees that, admissibleheuristic h weight w , solution returned w -admissible (within w factoroptimal solution cost) (Davis, Bramanti-Gregor, & Wang, 1988).possible modify AHDA*, BFPSDD, PBNF use weights find suboptimal solutions, call algorithms wAHDA*, wBFPSDD wPBNF. optimal search,parallelism implies strict f search order followed. proof weighted A*sw -optimality depends crucially following strict f order, parallel variants mustprove quality solution either exploring pruning nodes. Thus finding effectivepruning rules important performance. assume throughout h admissible.719fiB URNS , L EMONS , RUML , & Z HOU5.1 Pruning Poor NodesLet current incumbent solution w suboptimality bound. node n clearlypruned f (n) g(s). according following theorem, need retain noptimal path solution factor w better s. much stronger rule.Theorem 4 prune node n w f (n) g(s) without sacrificing w -admissibility.Proof: incumbent w -admissible, safely prune node, consider caseg(s) > w g(opt), opt optimal goal. Note without pruning, always existsnode p open list (or generated) best path opt. Let f costoptimal solution. admissibility h definition p, w f (p) w f (p) = w g(opt).pruning rule discards p, would imply g(s) w f (p) thus g(s) w g(opt),contradicts premise. Therefore, open node leading optimal solution prunedincumbent w -admissible. search terminate open emptyterminate incumbent w -admissible replaced optimal solution.2make explicit useful corollary:Corollary 2 prune node n f (n) g(s) without sacrificing w -admissibility.Proof: Clearly w f (n) f (n), Theorem 4 applies.2corollary, use pruning shortcut: open list sorted increasing fnode front f g(s), prune entire open list.5.2 Pruning Duplicate Nodessearching inconsistent heuristic, weighted A*, possible searchfind better path already-expanded state. Likhachev, Gordon, Thrun (2003) noted that,provided underlying heuristic function h consistent, weighted A* still return w admissible solution duplicate states pruned search. ensures stateexpanded search. Unfortunately, proof depends expandingexactly best-first order, violated several parallel search algorithms considerhere. However, still prove duplicates dropped. Consider expansionnode n re-generates duplicate state already expanded. proposefollowing weak duplicate dropping criterion: new copy pruned old g(d )g(n) + w c (n, ), c (n, ) optimal cost node n node .Theorem 5 Even weak dropping rule applied, always node p optimalsolution path open g(p) w g (p).Proof: proceed induction iterations search. theorem clearly holds expansioninitial state. induction step, note node p removed openexpanded. child pi lies along optimal path added open, theorem holds.way wont added exists previous duplicate copy pi pruning rule holds,i.e., g(pi ) g(pi1 ) + w c (pi1 , pi ). inductive hypothesis, g(pi1 ) w g (pi1 ),2definition g (pi1 ) + c (pi1 , pi ) = g (pi ), g(pi ) w g (pi ).Note use technique prohibits using global minimum f value lower boundoptimal solutions cost, g values inflated factor w . However,incumbent search global minimum f value g(s), serialweighted A* search, w -admissibility assured:720fiB EST-F IRST EARCH ULTICORE ACHINESCorollary 3 minimum f value g(s), incumbent, g(s)w g (opt)Proof: Recall node p Theorem 5. g(s) f (p) = g(p) + w h(p) w (g (p) + h(p))w g (opt).2remains empirical question whether pruning rather weak criterion lead betterperformance practice. results indicate provide advantage grid pathfindingdomain. Results presented Section 6.1. noted that, extra pruningpreserve w -admissibility, may result solutions lower quality resulting searchwithout pruning.5.3 Optimistic SearchKorf (1993) showed weighted A* typically returns solutions better bound, w ,would suggest. take advantage this, Thayer Ruml (2008) use optimistic approachbounded suboptimal search works two stages: aggressive search using weight greaterdesired optimality bound find incumbent solution cleanup phase proveincumbent indeed within bound. intuition behind approach wA*find solution within tight bound (much tighter w g(opt)), search continuelooking nodes f order bound proved. Thayer Ruml show that, indeed,approach surpass speed wA* given optimality bound. implementedoptimistic version PBNF (oPBNF).One requirements oPBNF must access minimum f valuenodes order prove bound incumbent solution. aggressive search stage,open lists heap free nblocks sorted f instead f couple additions needmade. First, nblock additional priority queue containing open search nodes sortedf . call queue openf . openf queue simply maintained adding removingnodes nodes added removed f ordered open list nblock. Second,priority queue, called minf , nblocks maintained, sorted lowest f valuenblock time last release. minf used track lower bound minimum f valuenodes. accomplished lazily updating minf nblock releasedthread. thread releases nblock, sifts released nblock successorsnew positions minf queue. nblocks whose minimum f values couldchanged releasing thread. Since global minimum f value nodes strictlyincreasing (assuming consistent heuristic) guarantee f value frontminf queue strictly increasing lower bound global minimum f valuegiven time. Using lower bound, able prove whether incumbent solutionproperly bounded.oPBNF needs decide switch aggressive search phase cleanupphase optimistic search. originally proposed, optimistic search performs aggressive searchfirst incumbent found switches cleanup (when f (n) g(s), nbest node based f incumbent solution) aggressive search (when f (n) <g(s)) hedge case current incumbent within bound. oPBNF,left choice: switch aggressive search cleanup global basisper-nblock basis. choose switch per-nblock basis assumptionthreads could cleaning areas search space low f values threads look721fiB URNS , L EMONS , RUML , & Z HOUbetter solutions areas search space low f values. oPBNF, decidingone nblock better another (when deciding switch set nblock hot), choicelonger based solely best f value given nblock, instead based fvalue first, f value break ties best f value bound incumbent.acquiring new nblock, thread takes either free nblock best f value best fvalue depending nblock better (where notion better described previoussentence). Finally, expanding nodes, thread selects aggressive search cleanup basedcriteria standard optimistic search nodes within acquired nblock.6. Empirical Evaluation: Bounded Suboptimal Searchimplemented tested weighted versions parallel search algorithms discussed above:wAHDA*, wAPRA*, wBFPSDD, wPBNF oPBNF. algorithms prune nodes basedw f criterion presented Theorem 4 prune entire open lists f Corollary 2. Searchterminates nodes pruned incumbent solution. experimentsrun three benchmark domains optimal search: grid pathfinding, sliding tilepuzzle, STRIPS planning.6.1 Grid PathfindingResults presented Table 2 show performance parallel search algorithms termsspeedup serial weighted A* grid pathfinding problems. Duplicate states alreadyexpanded dropped serial wA* algorithm, discussed Likhachev et al. (2003).rows table show number threads different algorithms whereas columnsweights used various domains. entry shows mean speedup serial weightedA*. performed Wilcoxon signed-rank test determine mean values significantlydifferent; elements bold represent values significantly different (p < 0.05)best mean value given column. general, parallel algorithms show increasedspeedup threads added low weights, decreased speedup weight increased.unit-cost four-way movement grids, weights 1.1, 1.2 wPBNF algorithmfastest algorithms tested reaching five times speed wA* weight1.1 4.5x weight 1.2 . weight 1.4 wPBNF, wBFPSDD wAHDA*show significant difference performance 8 threads. wAHDA* best speedalgorithms weight 1.8. wAPRA* never gave best performance domain.eight-way movement grids wPBNF gave best performance weight 1.1 1.4,although latter case best performance decrease speed wA*achieved 1 thread. wAHDA* fastest weight 1.2, however, scaleexpected number threads increased. Finally wAPRA* gave least performancedecrease weighted A* weight 1.8 1 thread. case, algorithms slowerserial weighted A* wAPRA* gave closest performance serial search. wBFPSDDnever gave best performance domain.life-cost domain wPBNF outperformed algorithms weights 1.1, 1.2 1.4.weight 1.8, wPBNFs performance quickly dropped, however wAHDA* best results4x speedup wA*, although performance appears inconsistent significantly different much lower speedup values weight.wAPRA* never gave best performance domain.722fiwAPRA*wAHDA*threadswBFPSDDwPBNFB EST-F IRST EARCH ULTICORE ACHINES12345678123456781234567812345678Unit Four-way Grids1.11.21.41.80.98 0.91 0.51 0.731.74 1.65 1.07 0.872.47 2.33 1.62 0.893.12 2.92 2.13 0.903.76 3.52 2.48 0.914.30 3.99 2.80 0.894.78 4.40 3.01 0.885.09 4.66 3.11 0.870.82 0.84 0.96 0.941.26 1.26 1.45 0.911.65 1.65 1.90 0.841.93 1.92 2.09 0.792.24 2.24 2.36 0.752.51 2.51 2.58 0.712.73 2.69 2.63 0.672.91 2.84 2.68 0.630.87 0.79 0.32 0.561.35 1.17 0.63 0.841.90 1.69 1.30 1.302.04 2.10 1.57 1.301.77 2.08 1.79 0.973.23 3.03 2.18 1.333.91 3.78 2.56 1.303.79 3.64 3.02 1.130.88 0.81 0.32 0.560.51 0.44 0.22 0.360.36 0.32 0.20 0.260.50 0.44 0.30 0.410.55 0.56 0.39 0.480.52 0.49 0.31 0.300.73 0.67 0.40 0.361.09 1.07 0.82 0.77weightUnit Eight-way Grids1.11.21.41.80.93 1.37 0.73 0.741.65 1.82 0.57 0.662.36 1.77 0.55 0.612.97 1.72 0.53 0.583.55 1.67 0.52 0.564.04 1.61 0.50 0.544.40 1.55 0.49 0.514.70 1.49 0.45 0.460.87 0.79 0.43 0.331.37 1.10 0.43 0.351.80 1.22 0.41 0.332.13 1.25 0.42 0.332.47 1.31 0.39 0.322.74 1.21 0.36 0.302.94 1.26 0.34 0.293.10 1.23 0.32 0.260.79 1.10 0.66 0.761.04 1.99 0.62 0.612.08 2.93 0.64 0.622.48 2.84 0.56 0.542.49 2.52 0.42 0.413.73 2.83 0.49 0.454.45 2.89 0.45 0.414.39 2.58 0.37 0.380.80 1.11 0.67 0.770.35 0.69 0.31 0.280.41 0.65 0.23 0.220.43 0.73 0.22 0.190.49 0.87 0.23 0.190.50 0.65 0.16 0.140.62 0.73 0.17 0.140.89 1.38 0.28 0.22Life Four-way Grids1.11.21.41.80.65 0.66 0.84 0.671.15 1.17 1.59 0.391.65 1.67 2.32 0.392.08 2.10 2.96 0.492.53 2.55 3.63 1.492.94 2.95 4.20 1.643.31 3.33 4.63 2.123.61 3.64 5.11 1.060.52 0.53 0.58 0.600.83 0.83 0.92 0.761.10 1.09 1.26 0.841.29 1.29 1.48 0.891.53 1.51 1.61 0.931.73 1.72 1.78 0.931.91 1.89 1.94 0.912.06 2.03 2.10 0.850.56 0.55 0.71 0.220.88 0.86 1.29 0.321.09 1.39 1.86 0.561.60 1.64 2.24 0.561.88 1.92 2.58 0.412.15 2.17 3.02 1.502.39 2.41 3.50 1.072.38 2.42 3.55 4.160.56 0.56 0.72 0.230.35 0.34 0.46 0.120.23 0.26 0.32 0.100.42 0.43 0.55 0.160.54 0.56 0.67 0.200.39 0.39 0.49 0.130.49 0.49 0.65 0.181.00 0.98 1.22 0.42Table 2: Grid Pathfinding: Average speedup serial weighted A* various numbersthreads.723fiB URNS , L EMONS , RUML , & Z HOUthreads123456781.40.681.351.481.702.042.162.552.71wPBNF1.72.00.44 0.380.81 1.000.97 0.851.20 0.931.38 0.971.30 1.191.46 1.041.71 1.103.00.690.630.560.600.740.670.620.601.40.611.181.531.912.332.282.712.70wAHDA*1.72.00.60 0.591.11 1.321.30 1.401.57 1.551.70 1.271.72 1.241.50 1.031.51 1.243.00.540.780.730.740.660.520.440.44threads123456781.40.650.871.051.091.271.331.491.53wBFPSDD1.72.00.61 0.440.74 0.490.72 0.631.00 0.570.97 0.651.17 0.611.10 0.591.08 0.623.00.350.430.460.450.400.390.340.331.40.611.181.451.772.322.182.632.34wAPRA*1.72.00.59 0.591.08 1.361.25 1.321.50 1.361.62 1.261.54 1.831.40 1.091.61 1.223.00.540.780.780.620.640.470.430.41Table 3: 15-puzzle: Average speedup serial weighted A* various numbers threads.oPBNFthreads12345678Unit Four-way Grids1.11.21.41.80.54 0.99 0.74 0.470.99 2.00 1.05 0.451.40 2.89 1.19 0.451.76 3.62 1.26 0.442.11 4.29 1.33 0.432.43 4.84 1.35 0.442.70 5.44 1.37 0.432.97 6.01 1.39 0.42Unit Eight-way Grids1.11.21.41.80.74 0.76 0.09 0.051.26 0.71 0.09 0.051.64 0.70 0.09 0.051.90 0.69 0.09 0.052.09 0.68 0.08 0.052.21 0.68 0.08 0.052.29 0.67 0.08 0.042.30 0.67 0.08 0.04250 easy 15-puzzles1.41.72.03.00.56 0.58 0.77 0.600.85 1.07 0.83 0.721.06 0.94 0.79 0.801.01 0.82 0.93 0.691.20 1.21 0.97 0.741.32 0.83 0.99 0.671.14 0.93 0.88 0.711.33 0.87 0.81 0.64Table 4: Average speedup serial optimistic search various numbers threads.724fiB EST-F IRST EARCH ULTICORE ACHINESOverall, see wPBNF often best speedup results eight threads weightsless 1.8. wAHDA*, however, gave best performance weight 1.8 across gridpathfinding domains. wBFPSDD often gave speedup serial weighted A*, howeverquite competitive wPBNF wAHDA*. wAPRA* rarely able outperformserial search.Table 4 shows results optimistic variant PBNF algorithm (oPBNF). celltable shows mean speedup oPBNF serial optimistic search. again, boldcells entries significantly different best value column. unit-costfour-way pathfinding problems oPBNF gave performance increase optimistic search twothreads weights less 1.8. weight 1.2, oPBNF tended givebest speedup, may optimistic search performed poorly particular weight.unit-cost eight-way pathfinding, see oPBNF performs comparably unit-cost domainweight 1.1, however, higher weights algorithm slower serial optimisticsearch.6.2 Sliding Tile Puzzlessliding tiles domain, used standard Korf 100 15-puzzles (Korf, 1985). Resultspresented Table 3. wPBNF, wAHDA* wAPRA* tended give comparable performancesliding tile puzzle domain values significantly different weights1.4 1.7. weight 3.0, wAHDA* gave least performance decrease weighted A*2 threads.right-most column Table 4 shows results optimistic PBNF 250 15-puzzleinstances solvable A* fewer 3 million expansions. oPBNF gave best performance weight 1.4. weights greater 1.4 oPBNF unable outperform serialcounterpart. greater weights oPBNF tended perform better smaller numbers threads.One trend seen sliding tiles domain grid pathfinding domainspeedup parallel algorithms serial suboptimal search decreases weightincreased. suspect decrease relative performance due problems becomingsufficiently easy (in terms node expansions) overhead parallelism becomes harmfuloverall search. problems require many node expansions cost parallelism (additionalexpansions, spawning threads, synchronization albeit small, waiting threads complete, etc.)amortized search effort. problems require small number expansions,however, overhead accounts total search time serial algorithm couldpotentially faster.confirm understanding effect problem size speedup, Figure 14 shows comparison wPBNF weighted A* 100 Korf 15-puzzle instances using eight threads.point represents run one instance particular weight, y-axis represents wPBNFspeedup relative serial wA*, x-axis represents number nodes expanded wA*.Different glyphs represents different weight values used wPBNF wA*. figureshows that, wPBNF outperform wA* easier problems, benefits wPBNFwA* increased problem difficulty increased. speed gain instances runweight 1.4 (the lowest weight tested) leveled 10 times faster wA*.machine eight cores. instances seem speedup greater10x. explained speculative expansions wPBNF performs may725fiB URNS , L EMONS , RUML , & Z HOUSliding Tiles wPBNF v.s. wA*Wlog10(Times faster wA*)1WWW WWWWWWWWWSW WWWSS W WWW W W WWSSWWWWWW WW W WWSSWWWSW SWWWWSSWS SSWWSW WWWWWWSWW WW WWWWW WW WWSSSSW WSS SSSSSWWWWSSS SWWSWWWSS SSSSS WWWWWWSWSWSSSS SSWSSSSS SSSSSWWW0-1W345WWWwPBNF-1.4wPBNF-1.7wPBNF-2.0wPBNF-3.0wPBNF-5.0W6log10(Nodes expanded wA*)Figure 14: wPBNF speedup wA* function problem difficulty.find bounded solution faster weighted A* due pruning nodes f valuesequal resulting solution. poor behavior wPBNF easy problemslikely due overhead described above. effect problem difficulty means wPBNFoutperformed wA* often low weights, problems required expansions,less often higher weights, problems completed quickly.6.3 STRIPS PlanningTable 5 shows performance parallel search algorithms STRIPS planning problems,terms speedup versus serial weighted A*. table columns represent various weightsrows represent different planning problems two seven threads. Bold values represent table entries within 10% best performance given domain.algorithms better speedup seven threads two. wPBNF gave best speedupnumber domains followed wAHDA* fastest three domainsseven threads. two threads couple domains (satellite-6 freecell-3)wBFPSDD gave speedup, however never seven threads. wAPRA* alwaysslower three remaining algorithms. one problem, freecell-3, serial weighted A* performs much worse weight increases. Interestingly, wPBNF wBFPSDD showpathology, thus record speedups 1,700 times.6.4 Summarysection, seen bounded suboptimal variants parallel searches givebetter performance serial progenitors. also shown that, sliding tile puzzle,parallel search gives advantage serial search problem difficulty increasessuspect result holds domains too. suspect overheadusing parallelism amortized search time easy problems.726fi7 threads2 threads7 threads2 threadsB EST-F IRST EARCH ULTICORE ACHINESlogistics-8blocks-16gripper-7satellite-6elevator-12freecell-3depots-13driverlog-11gripper-8logistics-8blocks-16gripper-7satellite-6elevator-12freecell-3depots-13driverlog-11gripper-8logistics-8blocks-16gripper-7satellite-6elevator-12freecell-3depots-13driverlog-11gripper-8logistics-8blocks-16gripper-7satellite-6elevator-12freecell-3depots-13driverlog-11gripper-81.50.991.290.760.680.651.030.730.910.633.193.041.711.110.943.092.381.901.701.52.680.932.012.022.022.062.700.852.067.102.875.674.426.327.013.121.725.85wAPRA*231.020.590.884.120.760.770.930.700.720.711.001.781.250.970.790.940.610.623.103.261.371.081.741.731.011.290.971.047.992.675.361.131.250.931.681.6851.370.300.770.750.771.611.080.930.622.580.371.821.441.022.931.170.921.741.51.251.521.361.151.161.490.921.301.144.593.603.713.222.774.772.983.523.71wAHDA*231.110.801.094.861.351.331.091.281.201.271.207.561.290.960.970.961.161.154.603.611.620.563.663.743.573.052.882.982.7148.666.091.221.480.953.633.67wPBNF34.060.481.995.902.218.110.820.692.081.910.375.072.686.60131.120.870.675.4051.001.322.023.042.1510.690.810.622.070.461.265.185.897.101,721.330.880.425.441.51.860.341.911.711.761.421.480.852.003.170.494.333.133.682.121.881.264.62wBFPSDD2352.121.140.150.190.160.321.891.861.842.227.502.801.761.812.180.54 16.8855.751.580.180.140.110.190.211.961.971.983.590.620.100.220.110.324.284.144.052.313.011.053.784.043.950.70 44.49 137.191.870.150.120.210.300.234.554.554.5122.270.541.991.532.080.844.490.192.046.880.705.092.856.312.311.800.435.3151.510.381.301.441.221.401.090.931.162.580.323.833.603.034.771.170.924.00Table 5: Speed-up serial weighted A* STRIPS planning problems various weights.727fiB URNS , L EMONS , RUML , & Z HOU7. Anytime Searchpopular alternative bounded suboptimal search anytime search, highly suboptimalsolution returned quickly improved solutions returned time algorithmterminated (or incumbent solution proved optimal). two popular anytimeheuristic search algorithms Anytime weighted A* (AwA*) (Hansen & Zhou, 2007) anytimerepairing A* (ARA*) (Likhachev, Gordon, & Thrun, 2003). AwA* weighted A* searchallowed continue finding first solution, pruning unweighted f (n) g(s)incumbent solution n node considered expansion. ARA* uses weightedsearch weight lowered solution meeting current suboptimality boundfound special INCONS list kept allows search expand nodesearch weight.section present anytime versions best performing parallel searchesprevious sections. used PBNF framework implement Anytime weighted PBNF (AwPBNF) Anytime Repairing PBNF (ARPBNF). use PRA* framework create anytimeweighted AHDA* (AwAHDA*). also show performance simple algorithmruns parallel weighted A* searches differing weights. planning domain, implemented anytime weighted BFPSDD (AwBFPSDD) comparison well.parallel searches inherently continue searching first solutions found,serve naturally anytime algorithms style Anytime weighted A*. maindifference standard, optimal versions algorithms anytime variantsanytime versions sort open lists heap free nblocks f (n) = g(n) +w h(n). fact, cases optimal search degenerate case anytime searchw = 1. approach (simply using w > 1) used implement algorithms exceptARPBNF multi-weighted A*.Next, discuss details ARPBNF algorithm. Following that, introducenew parallel anytime algorithm called multi-weighted A*. Finally, show results setcomparisons performed anytime algorithms discussed sections.7.1 Anytime Repairing PBNFARPBNF parallel anytime search algorithm based ARA* (Likhachev et al., 2003).ARPBNF, open lists heap nblocks sorted f AwPBNF, instead merelycontinuing search incumbent proved optimal, ARPBNF uses weight schedule.time incumbent found, weight heuristic value lowered specified amount,open lists resorted search continues. final iteration, weight 1.0optimal solution found.following procedure used resort nblocks parallel incumbent solutions:1. thread calling resort (the one found goal) becomes leader takinglock nblock graph setting resort flag. (If flag already set,another thread already leader current thread becomes worker). flagset leader thread releases lock nblock graph waits nblocksvalues zero (no nblocks acquired).2. Threads check resort flag expansion, set threads release nblocksbecome worker threads wait leader set start flag.728fiB EST-F IRST EARCH ULTICORE ACHINES3. nblocks = 0, leader re-takes lock nblock graph ensuresvalues still zero (if not, releases lock retries). leader setsglobal weight value next weight weight schedule populates lock-freequeue nblocks. queue populated, leader sets start flag.4. threads greedily dequeue nblocks resort queue empty.5. nblocks resorted, leader thread clears resort flag start flagreleases lock nblock graph. threads acquire new nblockssearch continue.modeled procedure TLA+ showed live-lock dead-lock free4 threads 5 nblocks use TLC model checker (Yu et al., 1999). modelsimple include appendix.7.2 Multi-weighted A*section introduce new simple parallel anytime algorithm called multi-weighted A*.PBNF PRA* frameworks parallelizing anytime algorithms thought oneend spectrum parallel anytime algorithms. PBNF PRA* threads workingfinding single solution given quality; opposite end spectrum thread wouldworking find solution. compare algorithm end spectrumimplemented algorithm call multi-weighted A* allocates available threadsweighted A* searches. thread finishes first generally thread searchinggreatest weight therefore solution worst quality. next threadfinish next greatest weight, on. final thread complete generallysearching weight 1.0, performing standard A* search, return optimal solution.algorithm given schedule weighs decreasing order. largest weightsschedule distributed among available threads. threads begin searching using wA*given weight values. thread finds new solution better current one,updates incumbent shared threads allow pruning. threadfinds better incumbent solution, w -admissible respect weight threadsearching with. thread finishes (either finding solution pruning entire open list), takeshighest unclaimed weight schedule starts fresh search using weight.weights left schedule, thread terminates. threads terminated,search complete. final weight schedule 1.0, last solution foundoptimal.One benefits multi-weighted A* simple algorithm implement.However, see below, doesnt benefit much added parallelism. reasonmay because, weight schedule exhausted (a thread searching lowestweight, 1.0) threads complete searches sit idle entire search terminates. Sincefinal weight take longest, may majority search time. dynamicschedule could used keep threads busy optimal solution found. One could alsoattempt use threads using multi-threaded search weight,wPBNF wAHDA*. leave extensions future work.729fiB URNS , L EMONS , RUML , & Z HOUSolution Cost (factor optimal)1.11.01.11.00.20.40.60.81.0wt sched 1wt sched 2wt sched 3wt sched 41.11.00.20.40.60.81.00.20.40.60.8Wall time relative serial A*Wall time relative serial A*Wall time relative serial A*Grid Unit Four-way AwA* lower hullGrid Unit Four-way AwPBNF (8 threads) lower hullGrid Unit Four-way ARA* lower hull1.21.2AwA*Solution Cost (factor optimal)Solution Cost (factor optimal)Grid Unit Four-way ARA* raw data1.23.41.81.41.11.21.11.01.2AwPBNF 8 threadsSolution Cost (factor optimal)Solution Cost (factor optimal)Grid Unit Four-way AwPBNF (8 threads) raw data1.23.41.81.41.21.1Solution Cost (factor optimal)Grid Unit Four-way AwA* raw data1.21.11.00.20.40.60.8Wall time relative serial A*1.01.0ARA*1.11.00.20.40.60.8Wall time relative serial A*1.00.20.40.60.8Wall time relative serial A*Figure 15: Raw data profiles (top) lower hull profiles (bottom) AwA* (left), AwPBNF (center), ARA* (right). Grid unit-cost four-way pathfinding.8. Empirical Evaluation: Anytime Searchimplementation empirical setup similar used suboptimal search. ARA*,ARPBNF Multi-wA* considered four different weight schedules: {7.4, 4.2, 2.6, 1.9, 1.5,1.3, 1.1, 1}, {4.2, 2.6, 1.9, 1.5, 1.3, 1.1, 1.05, 1}, {3, 2.8, . . . , 1.2, 1}, {5, 4.8, . . . , 1.2, 1}. AwA*anytime parallel algorithms consider weights of: 1.1, 1.2, 1.4, 1.8 3.4 gridpathfinding 1.4, 1.7, 2.0, 3.0 5.0 sliding tiles domain. fully evaluate anytimealgorithms, necessary consider performance profile, i.e., expected solution qualityfunction time. easily plotted, ignores fact anytime algorithmsconsidered paper free parameter, namely weight schedule weights usedaccelerate search. order compare algorithms, make assumption that,particular application, user attempt find parameter setting giving good performancetimescale interested in. assumption, plot performanceanytime algorithm computing, time point, best performance achievedparameter settings tried algorithm minimum solution cost parametersettings given algorithm given time point. refer concept lower hullprofiles, takes minimum profiles parameter setting.7301.0fiB EST-F IRST EARCH ULTICORE ACHINESGrid Unit Four-way 2 threadsGrid Unit Four-way 8 threads1.2ARA*ARPBNF 2 threadsAwA*Multi wA* 2 threadsAwAHDA* 2 threadsAwPBNF 2 threadsSolution Cost (factor optimal)Solution Cost (factor optimal)1.21.11.0ARA*AwA*Multi wA* 8 threadsARPBNF 8 threadsAwAHDA* 8 threadsAwPBNF 8 threads1.11.00.40.81.21.62.0Wall time relative serial A*0.40.81.21.62.0Wall time relative serial A*Figure 16: Grid unit-cost four-way pathfinding lower hull anytime profiles.top row Figure 15 shows example raw data three algorithms5000x5000 unit-cost four-way grid pathfinding problems. y-axis plots solution quality factor optimal x-axis wall clock time relative amounttime A* took find optimal solution. bottom row figure shows lower hullrespective data displayed above. comparing two images left display dataAwA* algorithm, one see three big steps lower hull plot different weight used hull found better solution time bound.center panel Figure 15 shows AwPBNF algorithm gives similar performance AwA*,however often faster. surprising since AwPBNF based AwA* approachrunning eight threads instead one. final panel Figure 15 shows ARA*, usesweight schedules instead single weight.Figures 16-17 present lower hulls serial parallel algorithms grid pathfindingsliding tile puzzle. panel, y-axis represents solution cost factor optimalcost. Figure 16 x-axis represents wall time relative amount time serial A* tookfind optimal solution. allows comparison anytime algorithms standardserial A*. Since A* able solve Korfs 100 15-puzzle instances machine,x-axis Figure 17 absolute wall time seconds. serial parallel algorithmsplotted. profiles start algorithm first returns solution ends algorithmproved optimality 180 second cutoff (since Multi-wA* consume memoryquickly algorithms, gave 120 second cutoff sliding tile puzzle preventthrashing).8.1 Four-Way Unit Cost GridsFigure 16 shows anytime performance unit cost four-way movement grid pathfinding problems. AwAHDA* AwPBNF found best solutions quicker algorithms.731fiB URNS , L EMONS , RUML , & Z HOUKorfs 100 15-puzzles 2 threads1.0161.0121.0081.0044080120ARA*Multi wA* 8 threadsARPBNF 8 threadsAwA*AwPBNF 8 threadsAwAHDA* 8 threads1.02Solution Cost (factor optimal)ARA*Multi wA* 2 threadsARPBNF 2 threadsAwAHDA* 2 threadsAwA*AwPBNF 2 threads1.02Solution Cost (factor optimal)Korfs 100 15-puzzels 8 threads1601.0161.0121.0081.00440Wall time (seconds)80120160Wall time (seconds)Figure 17: Korfs 100 15-puzzles lower hull anytime profiles.algorithms improved amount time taken find better solutions threadsadded. AwPBNF converged quickly threads added. Even two threadsAwPBNF first algorithm converge optimal solution 60% time serial A*.next two algorithms Multi-wA* anytime repairing PBNF (ARPBNF). Multi-wA* converged quickly threads added, performance finding intermediate solutionschange much different numbers threads. ARPBNF, hand, took longerfind good solutions low thread counts, threads added started perform better,eventually matching Multi wA* eight threads. algorithms improved solutionquality steadily AwPBNF AwAHDA* large jumps lower hulls.jumps corresponds hull switching different weight value (compareraw data AwPBNF Figure 15). parallel algorithms found good solutions fasterserial AwA* serial ARA*. parallel algorithms, however, took longer prove optimalityAwA* domain.8.2 Sliding Tile PuzzlesFigure 17 presents lower hulls anytime algorithms Korfs 100 instances 15-puzzle.figure, x-axes show total wall clock time seconds. times normalizedA* able solve instances. panels, see AwAHDA* tendedfind good solutions faster algorithms. AwA* AwPBNF performed similarlytwo threads number threads increased AwPBNF begun find better solutions fasterAwA*. ARPBNF took longer find good solutions AwPBNF AwAHDA*able find better solutions faster serial counterpart. simple Multi wA* algorithmperformed worst parallel algorithms. Increasing number threads used Multi-wA*seem increase solution quality. ARA* gave worst performance domain;profile curve seen top three panels.732fi7 threads2 threads7 threads2 threadsB EST-F IRST EARCH ULTICORE ACHINESlogistics-6blocks-14gripper-7satellite-6elevator-12freecell-3depots-7driverlog-11gripper-8logistics-6blocks-14gripper-7satellite-6elevator-12freecell-3depots-7driverlog-111.51.091.360.780.770.641.371.241.150.611.452.541.771.220.933.643.603.04logistics-6blocks-14gripper-7satellite-6elevator-12freecell-3depots-7driverlog-11gripper-8logistics-6blocks-14gripper-7satellite-6elevator-12freecell-3depots-7driverlog-111.51.061.912.051.582.011.931.941.952.042.043.725.615.966.183.545.745.78AwAPRA*231.061.407.76 56.410.770.760.780.780.670.691.434.611.301.301.191.110.620.621.431.8115.63 98.521.681.711.221.260.930.953.75 11.593.643.653.203.05AwPBNF231.351.941.9913.221.961.991.961.982.072.131.062.782.002.012.101.992.052.092.464.1922.3725.695.055.034.665.746.036.201.5015.325.525.485.835.7351.40>90.160.750.760.701.372.681.200.621.81>177.081.731.260.944.447.603.1751.98>22.361.951.912.076.234.100.772.064.21>7.205.064.706.0511.4610.842.181.51.231.621.351.261.201.661.511.501.162.873.303.753.562.775.004.414.741.50.681.021.941.851.741.451.441.732.011.021.604.304.103.711.782.022.58AwAHDA*231.211.599.9063.601.331.321.231.241.191.161.685.651.511.501.551.461.111.142.813.6519.91 132.973.693.613.463.512.752.794.9716.364.424.404.824.66AwBFPSDD230.910.911.187.711.891.941.871.491.741.751.461.971.451.321.781.592.001.981.351.371.9612.104.244.163.544.163.743.731.822.591.961.922.862.5751.66>110.161.331.231.171.953.181.541.113.74>231.453.673.502.7721.579.254.8750.56>11.921.821.801.693.082.401.411.960.92>19.943.963.883.384.143.682.34Table 6: Speed-up anytime search optimality serial AwA* STRIPS planning usingvarious weights.8.3 STRIPS PlanningTable 6 shows speedup parallel anytime algorithms serial anytime A*. algorithmsrun optimal solution proved. (For weight 5, AwA* ran memoryblocks-14, speedup values weight instance lower bounds.) bold entries733fi7 ThreadsB URNS , L EMONS , RUML , & Z HOUlogistics-6blocks-14gripper-7satellite-6elevator-12freecell-3depots-7driverlog-11gripper-81.51.481.241.071.101.061.051.201.161.06AwPBNF231.84 2.361.22 0.210.99 0.990.87 1.081.04 1.040.44 0.991.15 1.151.15 1.190.99 0.9952.270.031.000.881.030.291.080.431.001.50.680.870.930.880.770.640.540.530.99AwBFPSDD230.93 0.710.18 0.160.95 0.930.77 0.910.78 0.760.64 0.200.53 0.520.58 0.540.98 0.9950.540.160.920.900.730.140.490.500.971.51.121.460.990.991.021.13AwAPRA*231.08 1.081.46 1.421.03 1.011.00 1.011.00 1.001.16 0.8250.980.940.991.021.000.10Table 7: Speed-up anytime search optimality PBNF STRIPS planning problems usingvarious weights.table represent values within 10% best performance given domain.algorithms, speedup serial generally increased threads higher weight.PBNF gave fastest performance except two domains (blocks-14 freecell-3).two domains AwAHDA* gave best performance least factor 10x AwPBNF.Hansen Zhou (2007) show AwA* lead speedup A* weight valuescertain domains. Finding suboptimal solution quickly allows f pruning keeps open listshort quick manipulate, resulting faster performance even though AwA* expandsnodes A*. found similar phenomenon corresponding parallel case. Table 7 showsspeedup unweighted optimal PBNF using various weights anytime algorithms.significant fraction values greater 1, representing speedup using anytimealgorithm instead standard optimal parallel search. general, speedup seems variableweight increases. weight 1.5, AwPBNF always provides speedup.8.4 Summarypart paper shown create new parallel anytime search algorithmsbased frameworks introduced previous sections. also created new parallelanytime algorithm simply runs many weighted A* searches differing weights.experiments, seen AwPBNF AwAHDA* found higher quality solutions fasteralgorithms showed improved performance threads added.Additionally, ARPBNF, parallel algorithm based ARA*, improved threadstended give smoother increase solution quality former two algorithms, althoughfind solutions quite quickly unable converge optimal solutionsliding tiles domain within given time limit. Running multiple weighted A* searchesgive solutions faster number threads increased, convergence performancemixed.9. Discussionexplored set best-first search algorithms exploit parallel capabilities modernCPUs. First looked parallel optimal search (Safe) PBNF, several variants PRA*734fiB EST-F IRST EARCH ULTICORE ACHINESset simpler previously proposed algorithms. Overall, Safe PBNF gave best performanceoptimal search. Next created set bounded-suboptimal search algorithms based PBNF,successful variants PRA*, BFPSDD algorithm. PBNF PRA* asynchronouscommunication abstraction (AHDA*) gave best performance all, PBNFslightly better average. addition, showed results suggest boundedsuboptimal PBNF advantage serial weighted A* search problem difficultyincreases. Finally converted PBNF PRA* anytime algorithms comparedserial anytime algorithms new algorithm called multi-weighted A*. foundanytime weighted PBNF anytime variant AHDA* gave best anytime performanceoccasionally able find solutions faster non-anytime counterparts.results show PBNF outperforms PSDD. believe lacklayer-based synchronization better utilization heuristic cost-to-go information. factBFPSDD got better f layers widened suggestive evidence. Another less obviousreason PBNF may perform better best-first search larger frontier sizebreadth-first heuristic search used PSDD. larger frontier size tend createnblocks containing open search nodes. disjoint duplicate detection scopesnodes open lists and, therefore, potential increased parallelism.results show that, even single thread, PBNF outperform serial A* search(see Table 1). may attributed part speculative behavior PBNF algorithm.Since PBNF uses minimum number expansions testing switch nblockbetter f values, search sub-optimal nodes A* would search. orderget optimal solutions, PBNF acts anytime algorithm; stores incumbent solutions prunesprove optimal solution. Zhou Hansen show approachability perform better A* (Hansen & Zhou, 2007) upper bound pruning,reduces number expansions nodes f value equal optimal solutioncost reduce number open nodes, increasing speed operations open list.PBNF may also give good single thread performance breaks search frontiermany small open lists (one nblock). this, priority queue operationsPBNF performs much smaller queues A*, uses one big single queue (seeSection 4.6.2).9.1 Possible Extensionsbasic guideline creating good abstractions SDD (and PBNF) minimizeconnectivity abstract states, aspects abstraction could explored.instance, discovering features good include abstract away may helpfulusers PBNF. much focus one feature could cause good nodes focused smallsubset nblocks (Zhou & Hansen, 2009). Likewise, size abstraction could examineddetail. Although always use constant abstraction size current work simplicityseems likely abstraction size change number threads changes perhaps evenbased features domain problem instance. guideline could devised, rationumber nblocks threads h value start state, problem-adaptive abstractionsize would much simpler real world use. Additionally, edge partitioning (Zhou & Hansen,2007) could allow us reduce connectivity abstraction used PBNF, studynecessary discover full impact technique PBNFs behavior.735fiB URNS , L EMONS , RUML , & Z HOUpossible future extensions PBNF include adaptive minimum expansion values, useexternal memory, extension distributed setting. preliminary work adapting minimum expansion values indicated simply increasing decreasing based lock failuressuccesses either neutral negative effect performance. One reason mayminimum expansions parameter adds speculation.may possible combine PBNF PRA* distributed memory setting. algorithmmay use technique based PRA* distribute portions search space among different nodescluster work stations using multicore search PBNF node.additional technique explored paper running multicore search algorithms threads available cores. technique used improveperformance parallel delayed duplicate detection (Korf, 1993; Korf & Schultze, 2005)heavily I/O intensive. Using approach, one thread blocked I/O another threadmake use newly available processing core. Even without disk I/O technique mayuseful threads spend lot time waiting acquire locks.10. Conclusionspaper investigated algorithms best-first search multicore machines.shown set previously proposed algorithms parallel best-first search much slowerrunning A* serially. presented novel hashing function PRA* takes advantagelocality search space gives superior performance. Additionally, verified results presented Kishimoto et al. (2009) using asynchronous communication PRA* allowsperform better using synchronous communication. present new algorithm, PBNF,approximates best-first search ordering trying keep threads busy. provedcorrectness PBNF search framework used derive new suboptimal anytimealgorithms.performed comprehensive empirical comparison optimal, suboptimal anytime variations parallel best-first search algorithms. results demonstrate using goodabstraction distribute nodes PRA* beneficial asynchronous communication,two techniques used together (yielding AHDA*). also found original breadth-first PSDD algorithm give competitive behavior without tight upper boundpruning. implemented novel extension PSDD, BFPSDD, gives reasonable performance domains tested. experiments, however, demonstrate new PBNFAHDA* algorithms outperformed algorithms. PBNF performs best optimalbounded-suboptimal search PBNF AHDA* gave competitive anytime performance.Acknowledgmentsgratefully acknowledge support NSF (grant IIS-0812141), DARPA CSSG program(grant HR0011-09-1-0021) helpful suggestions Jordan Thayer. resultspreviously reported Burns, Lemons, Zhou, Ruml (2009b) Burns, Lemons, Ruml,Zhou (2009a).736fiB EST-F IRST EARCH ULTICORE ACHINESAppendix A. Pseudo-code Safe PBNFfollowing pseudo code three global structures. first pointer currentincumbent solution, incumbent, second done flag set true thread recognizessearch complete third nblock graph. nblock graph structure containslist free nblocks, freelist along h values nblock. simplicity,code uses single lock access either structure. thread also local exp count. bestfunction set nblocks results nblock containing open node lowest f value.EARCH ( INITIAL NODE )1. insert initial node open2. p processors, HREAD EARCH()3. threads still running, wait()4. return incumbentHREAD EARCH ()1. b NULL2. done3.b N EXT N BLOCK(b)4.exp 05.HOULD WITCH(b, exp)6.best open node b7.> incumbent prune8.goal9.< incumbent10.lock; incumbent m; unlock11.else duplicate12.children expand(m)13.child children14.insert child open appropriate nblock15.exp exp + 1HOULD WITCH ( B , EXP )1. b empty return true2. exp < min-expansions return false3. exp 04. best(freelist) < b best(interferenceScope(b)) < b5.best(interferenceScope(b)) < best(freelist)6.ET H OT(best(interferenceScope(b)))7.return true8. lock9. b interferenceScope(b)10.hot(b ) ET C OLD(b )11. unlock12. return false737fiB URNS , L EMONS , RUML , & Z HOUET H OT ( B )1. lock2. hot(b) (b) > 03.interferenceScope(b) : < b hot(i )4.hot(b) true5.interferenceScope(b)6.hot(m ) ET C OLD(m )7.(m ) = 0 h (m ) = 08.empty9.freelist freelist \ {m }10.h (m ) h (m ) + 111. unlockET C OLD ( B )1. hot(b) false2. interferenceScope(b)3.h (m ) h (m ) 14.(m ) = 0 h (m ) = 0 empty5.hot(m )6.ET C OLD(m )7.freelist freelist {m }8.wake sleeping threadsR ELEASE ( B )1. b interferenceScope(b)2.(b ) (b ) 13.(b ) = 0 h (b ) = 0 b empty4.hot(b )5.ET C OLD(b )6.freelist freelist {b }7.wake sleeping threadsN EXT N BLOCK ( B )1. b open nodes b set hot lock2. else trylock() fails return b3. b 6= NULL4.bestScope best(interferenceScope(b))5.b < bestScope b < best(freelist)6.unlock; return b7.R ELEASE(b)8. (l nblocks : (l ) = 0) freelist empty9.done true10.wake sleeping threads11. freelist empty done, sleep12. done n NULL738fiB EST-F IRST EARCH ULTICORE ACHINES13. else14.best(freelist)15.b interferenceScope(m)16.(b ) (b ) + 117. unlock18. return739fiB URNS , L EMONS , RUML , & Z HOUAppendix B. TLA+ Model: Hot N blockspresent model used show Safe PBNF live-lock free. Refer Section 3.2.3.MODULE HotNblocksFiniteSets, NaturalsCONSTANTS nnblocks, nprocs, search, nextblock , noneVARIABLES state, acquired , isHot, SuccsVars = hstate, acquired , isHot, SuccsiStates = {search, nextblock }Nblocks = 0 . . nnblocks 1Procs = 0 . . nprocs 1ASSUME nnblocks nprocs nprocs > 0 nnblocks > 1 none/ Nblocks Cardinality(States) = 2Preds(x ) = {y Nblocks : x Succs[y]} Set predecessors Nblock xIntScope(x ) = Preds(x ) UNION {Preds(y) : Succs[x ]} interference scope xIntBy(x ) = {y Nblocks : x IntScope(y)} Set Nblocks x interferes.Busy(A) = UNION {Succs[x ] : x A} Set Nblocks busy given set acquired nblocksOverlap(x , A) = IntScope(x ) Set Busy Nblocks overlapping successors xHot(A) = {x Nblocks : isHot[x ] Overlap(x , A) 6= {}} Set hot nblocks given set acquired nblocksHotInterference(A) = UNION {IntScope(x ) : x Hot(A)} Set Nblocks interference scopes hot nblocksFree(A) = {x Nblocks : Overlap(x , A) = {} x/ HotInterference(A)} Free NblocksAcquired = {acquired [x ] : x Procs} \ {none} Set Nblocks currently acquiredOverlapAmt(x ) = Cardinality(Overlap(x , Acquired )) number nblocks overlapping x .doNextBlock (x ) = UNCHANGED hSuccsistate[x ] = nextblock acquired [x ] = none Free(Acquired ) 6= {}Free(Acquired \ {acquired [x ]}) 6= {}Free(Acquired \ {acquired [x ]}) : acquired = [acquired EXCEPT ! [x ] = y]state = [state EXCEPT ! [x ] = search]isHot = [y Nblocks 7 Free(Acquired \ {acquired [x ]})FALSE ELSE isHot[y]]ELSE acquired = [acquired EXCEPT ![x ] = none]isHot = [y Nblocks 7 Free(Acquired )FALSE ELSE isHot[y]]UNCHANGED hstateidoSearch(x ) = UNCHANGED hacquired , Succsistate[x ] = search state = [state EXCEPT ![x ] = nextblock ]UNCHANGED hisHotiIntBy(acquired [x ]) : isHot[y]IntScope(y) Hot(Acquired ) = {}/ HotInterference(Acquired )isHot = [isHot EXCEPT ![y] = TRUE]Init = state = [x Procs 7 nextblock ] acquired = [x Procs 7 none]isHot = [x Nblocks 7 FALSE]EXTENDSbasic graph nblock connected neighbors forming loop.Succs = [x Nblocks 7x = 0 {nnblocks 1, x + 1}x = nnblocks 1 {0, x 1} ELSE {x 1, x + 1}]Next = x Procs : (doNextBlock (x ) doSearch(x ))Fairness = x Procs : WFVars (doNextBlock (x ) doSearch(x ))Prog = Init 2[Next]Vars FairnessHotNblocks = x Nblocks : isHot[x ] ; isHot[x ] property proveELSE740fiB EST-F IRST EARCH ULTICORE ACHINESReferencesBurns, E., Lemons, S., Ruml, W., & Zhou, R. (2009a). Suboptimal anytime heuristic searchmulti-core machines. Proceedings Seventeenth International Conference Automated Planning Scheduling (ICAPS-09).Burns, E., Lemons, S., Zhou, R., & Ruml, W. (2009b). Best-first heuristic search multi-coremachines. Proceedings 14th International Joint Conference Artificial Intelligence(IJCAI-09).Cushing, W., Bentor, J., & Kambhampati, S. (2010). Cost based search considered harmful.2010 International Symposium Combinatorial Search (SOCS-10).Dai, P., & Hansen, E. A. (2007). Prioritizing bellman backups without priority queue. Proceedings Nineteenth International Conference Automated Planning Scheduling(ICAPS-09).Davis, H. W., Bramanti-Gregor, A., & Wang, J. (1988). advantages using depth breadthcomponents heuristic search. Methodologies Intelligent Systems 3, pp. 1928.Edelkamp, S., & Schrodl, S. (2000). Localizing A*. Proceedings Seventeenth NationalConference Artificial Intelligence (AAAI-00), pp. 885890. AAAI Press.Edelkamp, S., & Sulewski, D. (2010). GPU exploration two-player games perfect hashfunctions. 2010 International Symposium Combinatorial Search (SOCS-10).Evans, J. (2006). scalable concurrent malloc(3) implementation FreeBSD. ProceedingsBSDCan 2006.Evett, M., Hendler, J., Mahanti, A., & Nau, D. (1995). PRA* - massively-parallel heuristic-search.Journal Parallel Distributed Computing, 25(2), 133143.Felner, A., Kraus, S., & Korf, R. (2003). KBFS: K-best-first search. Annals MathematicsArtificial Intelligence, 39(1-2), 1939.Ferguson, C., & Korf, R. E. (1988). Distributed tree search applications alpha-beta pruning. Proceedings Seventh National Conference Artificial Intelligence (AAAI-88).Hansen, E. A., & Zhou, R. (2007). Anytime heuristic search. Journal Artificial IntelligenceResearch, 28, 267297.Harris, T. L. (2001). pragmatic implementation non-blocking linked-lists. Lecture NotesComputer Science, Vol. 2180/2001, pp. 300314. Springer Berlin / Heidelberg.Hart, P. E., Nilsson, N. J., & Raphael, B. (1968). formal basis heuristic determinationminimum cost paths. IEEE Transactions Systems Science Cybernetics, SSC-4(2),100107.Haslum, P., & Geffner, H. (2000). Admissible heuristics optimal planning. ProceedingsFifth Internationas Conference Artificial Intelligence Planning Scheduling Systems(AIPS-00), pp. 140149.Holzmann, G. J., & Bosnacki, D. (2007). design multicore extension SPIN modelchecker. IEEE Transactions Software Engineering, 33(10), 659674.741fiB URNS , L EMONS , RUML , & Z HOUJabbar, S., & Edelkamp, S. (2006). Parallel external directed model checking linear I/O.Emerson, E., & Namjoshi, K. (Eds.), Verification, Model Checking, Abstract Interpretation, Vol. 3855 Lecture Notes Computer Science, pp. 237251. Springer Berlin / Heidelberg.Kishimoto, A., Fukunaga, A., & Botea, A. (2009). Scalable, parallel best-first search optimalsequential planning. Proceedings Nineteenth International Conference AutomatedPlanning Scheduling (ICAPS-09).Korf, R. E. (1985). Iterative-deepening-A*: optimal admissible tree search. ProceedingsInternational Joint Conference Artificial Intelligence (IJCAI-85), pp. 10341036.Korf, R. E. (1993). Linear-space best-first search. Artificial Intelligence, 62(1), 4178.Korf, R. E. (2003). Delayed duplicate detection: extended abstract. Proceedings EighteenthInternational Joint Conference Articial Intelligence (IJCAI-03), pp. 15391541.Korf, R. E., & Schultze, P. (2005). Large-scale parallel breadth-first search. ProceedingsTwentieth National Conference Articial Intelligence (AAAI-05), pp. 13801385.Kumar, V., Ramesh, K., & Rao, V. N. (1988). Parallel best-first search state-space graphs: summary results. Proceedings Seventh National Conference Artificial Intelligence(AAAI-88), pp. 122127.Lamport, L. (2002). Specifying Systems: TLA+ Language Tools Hardware SoftwareEngineers. Addison-Wesley.Likhachev, M., Gordon, G., & Thrun, S. (2003). ARA*: Anytime A* provable boundssub-optimality. Proceedings Seventeenth Annual Conference Neural InformationPorcessing Systems (NIPS-03).Likhachev, M., Gordon, G., & Thrun, S. (2003). ARA*: Formal analysis. Tech. rep. CMU-CS-03148, Carnegie Mellon University School Computer Science.Niewiadomski, R., Amaral, J., & Holte, R. (2006a). parallel external-memory frontier breadthfirst traversal algorithm clusters workstations. Proceedings 2006 InternationalConference Parallel Processing (ICPP-06), pp. 531538.Niewiadomski, R., Amaral, J. N., & Holte, R. C. (2006b). Sequential parallel algorithmsfrontier A* delayed duplicate detection. Proceedings 21st national conferenceArtificial intelligence (AAAI-06), pp. 10391044. AAAI Press.Nilsson, N. J. (1980). Principles Artificial Intelligence. Tioga Publishing Co.Pohl, I. (1970). Heuristic search viewed path finding graph. Artificial Intelligence, 1, 193204.Powley, C., & Korf, R. E. (1991). Single-agent parallel window search. IEEE Transactions PatternAnalysis Machine Intelligence, 13(5), 466477.Richter, S., & Westphal, M. (2010). LAMA planner: Guiding cost-based anytime planninglandmarks. Journal Artificial Intelligence Research, 39.Ruml, W., & Do, M. B. (2007). Best-first utility-guided search. Proceedings IJCAI-07, pp.23782384.742fiB EST-F IRST EARCH ULTICORE ACHINESSnir, M., & Otto, S. (1998). MPI-The Complete Reference: MPI Core. MIT Press, Cambridge,MA, USA.Stern, U., & Dill, D. L. (1998). Using magnetic disk instead main memory mur verifier.Computer Aided Verification, pp. 172183. Springer.Sundell, H., & Tsigas, P. (2005). Fast lock-free concurrent priority queues multi-threadsystems. Parallel Distributed Processing Symposium, International, 65(5), 609627.Thayer, J. T., & Ruml, W. (2008). Faster weighted A*: optimistic approach boundedsuboptimal search. Proceedings Eighteenth International Conference AutomatedPlanning Scheduling (ICAPS-08).Valois, J. D. (1995). Lock-Free Data Structures. Ph.D. thesis, Rensselaer Polytechnic Institute.Yu, Y., Manolios, P., & Lamport, L. (1999). Model checking TLA+ specifications. CorrectHardware Design Verification Methods, pp. 5466. Springer Berlin / Heidlberg.Zhou, R., & Hansen, E. (2006). Domain-independent structured duplicate detection. ProceedingsTwenty-First National Conference Artificial Intelligence (AAAI-06), pp. 10821087.Zhou, R., & Hansen, E. (2007). Edge partitioning external-memory graph search. ProceedingsTwentieth International Joint Conference Artificial Intelligence (IJCAI-07).Zhou, R., & Hansen, E. (2009). Dynamic state-space partitioning external-memory graph search.2009 International Symposium Combinatorial Search (SOCS-09).Zhou, R., & Hansen, E. A. (2004). Structured duplicate detection external-memory graph search.Proceedings Nineteenth National Conference Artificial Intelligence (AAAI-04).Zhou, R., & Hansen, E. A. (2006). Breadth-first heuristic search. Artificial Intelligence, 170(45),385408.Zhou, R., & Hansen, E. A. (2007). Parallel structured duplicate detection. ProceedingsTwenty-Second Conference Artificial Intelligence (AAAI-07).743fiJournal Artificial Intelligence Research 39 (2010) 373-427Submitted 4/10; published 10/10Constraint Satisfaction Framework ExecutingPerceptions Actions Diagrammatic ReasoningBonny BanerjeeB. Chandrasekaranbanerjee.28@osu.educhandra@cse.ohio-state.eduLaboratory Artificial Intelligence ResearchDepartment Computer Science & EngineeringOhio State University, Columbus, OH 43210, USAAbstractDiagrammatic reasoning (DR) pervasive human problem solving powerful adjunct symbolic reasoning based language-like representations. research reportedpaper contribution building general purpose DR system extensionsoar-like problem solving architecture. work framework DRmodeled process subtasks solved, appropriate, either inferencesymbolic representations interaction diagram, i.e., perceiving specied information diagram modifying/creating objects diagram specied waysaccording problem solving needs. perceptions actions DR systems builtfar hand-coded specic application, even rest system builtusing general architecture. absence general framework executing perceptions/actions poses major hindrance using opportunistically essenceopen-ended search problem solving.goal develop framework executing wide variety specied perceptions actions across tasks/domains without human intervention. observedomain/task-specic visual perceptions/actions transformed domain/taskindependent spatial problems. specify spatial problem quantied constraintsatisfaction problem real domain using open-ended vocabulary properties, relations actions involving three kinds diagrammatic objects points, curves, regions.Solving spatial problem specication requires computing equivalent simplied quantier-free expression, complexity inherently doubly exponential.represent objects conguration simple elements facilitate decompositioncomplex problems simpler similar subproblems. show that, symbolicsolution subproblem expressed concisely, quantiers eliminatedspatial problems low-order polynomial time using similar previously solved subproblems. requires determining similarity two problems, existence mappingcomputable polynomial time, designing memory storing previously solved problems facilitate search. ecacy idea shown timecomplexity analysis. demonstrate proposed approach executing perceptionsactions involved DR tasks two army applications.1. Introductionresearch reported paper contribution building problem solving agentsarticial intelligence (AI) use diagrams, much people do, AInot, given almost exclusive emphasis AI language-like predicate-symbolic representations. Diagrammatic reasoning (DR) emerging area research numberc2010AI Access Foundation. rights reserved.fiBanerjee & Chandrasekaranelds, including AI (Glasgow, Narayanan, & Chandrasekaran, 1995; Chandrasekaran,Kurup, & Banerjee, 2005), logic (Barwise & Etchemendy, 1998; Allwein & Barwise, 1999),psychology (Tversky, 2000; Tricket & Trafton, 2006). research DRone way dealing diagrams, dierent research issues addressed dierentresearchers. research reported paper considers DR problem solving activityagent (human articial) makes use two forms representation spatialrepresentation form 2D diagrams symbolic representation contains information predicate-symbolic form similar logic natural language. schematicDR architecture, proposed Chandrasekaran et al. (2002, 2004, 2005), illustratedFigure 1.ProblemSpatial problemspecification languageSpatialProblemSolverProblemSolverSolutionspatial problemDiagramSolutionInferenceRulesSymbolicInformationTraditional AIproblem solverFigure 1: diagrammatic reasoning architecture.1.1 Diagrammatic Reasoning Problem Solving ActivityDR architecture shares idea problem solving search problem state space(Laird, Rosenbloom, & Newell, 1986; Newell, 1990). approach, startinginitial state, agent applies operators bring state transitions reach goalstate. goal either reached decomposed subgoals use generaldomain knowledge. Reaching goal subgoal requires information generatedtraditional problem solving architectures (e.g., soar Laird, Newell, & Rosenbloom,1987, act-r Anderson, 1993) inference using predicate-symbolic representation.DR architecture, agent extract information diagrams applying perceptionlike operations addition inference using predicate-symbolic representation reachgoal/subgoal. agent also create modify objects diagram propose newstates goal might reached subsequent perceptions inferences.illustrate conceptualization DR, let us consider real-world problem.army commander, planning strategic operations, uses terrain map chalk pathtroops safely travel one base camp location L1 another L2 within giventime. information regarding nature terrain (e.g., slow-go no-goregions, altitude dierent parts terrain, speed troops traveldierent kinds terrain) estimate maximum repower range enemy.commander, veteran eld, well aware possibility troopsmight ambushed along path enemy might hiding neighboringregions. problem solving might proceed follows. diagram consisting part374fiExecuting Perceptions Actions Diagrammatic Reasoningterrain map interest particular problem given, along peripheriesno-go regions two points, L1 L2 (see Figure 2(a)). commanderdraws one shorter paths L1 L2 maintaining maximum distanceneighboring no-go regions (see Figure 2(b)). knows kinds spatial relationspoints route points enemy could hiding correspondambush potential. uses knowledge perceive (and mark) portionspath prone ambush due enemies hiding behind neighboring no-go regions(see Figure 2(c)). portion found, path inferred safe. lengthsafe path traversed given time, considered suitable pathoperation. path drawn safe satisfy time constraint, another pathdrawn (see Figure 2(d)) analyzed. procedure continues pathsexhausted. suitable path still found, least risky path might consideredoperation. worst case, commander might infer operationpossible. problem similar vein, described above, considered Forbus,Usher, Chapman (2003).example, noteworthy problem solver (the commander) opportunistically brings together symbolic knowledge (such as, repower range enemies)perception action diagram solve real-world problem. phenomenoncharacteristic DR whenever used solve problems dierent domains, as,economics, geometry, engineering, computer-aided design, military, on. observeexecuting perceptions actions require solving purely spatial problemsinvolvement domain knowledge. spatial problems described termsdiagrammatic objects, as, points, curves, regions, spatial properties (e.g.,length curve) relations (e.g., point curve) involving them. example, perceiving portions path prone ambush due enemies hiding behind mountainrange requires computing set points q curve (the path) c1 q withinspecied distance (the repower range) point p curve (the mountainrange) c2 (see Figure 22(b)). Formally, writtenRiskyP ortionsof P ath(q, c1 , c2 , d) On(q, c1 )p, On(p, c2 )DistanceLessT han(p, q, d)DistanceLessT han(p, q, d) Distance(p, q)p point. paper, propose general ecient framework spatialproblem solving autonomously execute perceptions actions DR.1.2 Mean Diagram?Definition 1. Diagram. diagram set labeled 2D objects {O1 , O2 , ...On }located clearly inside (i.e., intersection touching) common region (or bounding box)B. objects three types points, curves, regions.Definition 2. Diagrammatic Object. diagrammatic object 3-tuple < L, , E >L label, type (point, curve region), E spatial extent.spatial extent diagrammatic object set points constituent object.375fiBanerjee & Chandrasekaran(a) given diagram consisting two points, L1L2 , three region obstacles.(b) One shorter paths L1 L2avoiding obstacles drawn.(c) Portions path prone ambush perceived marked.(d) Another path drawn analyzedrisk.Figure 2: Diagrammatic reasoning army commander nding safe path transporting troops L1 L2 within given time.Definition 3. Diagrammatic Image. diagrammatic image, I, diagramset points constituent objects diagram. Thus, D= {O1 , O2 , ...On }diagram Oi =<L(Oi ),T (Oi ),E(Oi ) >, diagrammatic image I(D) givennI(D) =E(Oi )i1denition diagram, due Chandrasekaran et al. (2002, 2004, 2005), supportsfunctional representation diagram articial agent. diagram externalmedium (e.g., piece paper, computer screen) is, one level, image consisting pixelsdierent intensities. another level, interpreted representation consistingspatial objects domain interest. abstract diagram ideal, i.e., pointsdimensionless, curves thickness, etc. external diagram, points curvesconsist least one pixel nite dimensions. need interchangetwo forms diagrams reasoning interaction purposes. rest paper,376fiExecuting Perceptions Actions Diagrammatic Reasoningterm diagram refer abstract diagram only, unless otherwise stated.interested diagrams line drawings color intensity variation.diagrams form substantial class diagrams everyday use.1.3 Perceptions Actions Diagrammatic ReasoningDefinition 4. Perception. perception act extracting new piece information diagram. new piece information satisfies constraints specified termsproperties relations among existing objects diagram boolean realnumber diagrammatic object(s). Thus, perception P mapping diagramset booleans {T rue, F alse} real numbers set diagrammatic objectssatisfying constraints C.CP : {T rue, F alse} ,I(D ) I(D)Definition 5. Action. action act introducing new object(s), modifyingdeleting existing object(s) diagram satisfying constraints specified termsproperties relations among existing objects. Thus, action mappingdiagram new set diagrammatic objects satisfying constraints C.C: DD ,I(D) = I(D )last couple decades, numerous DR systems built dierent applications dierent domains. following review well-known DR systemsproblem solving agent reasons using diagrams. review help realizerole perception action DR, spatial problems implicit perceptionsactions.Sketchy (Pisan, 1995) computer implementation model graph understanding. recognizes diagrammatic objects - points, lines, regions, vocabularyproperties relations includes coordinate point, right of, above, inside, steeper,bigger, vertical, change slope, touches, intersects, line, border, forms border, etc.representing conceptual relationships domains, as, thermodynamics economics.domain translator responsible converting domain-specic conceptual questionsdomain-independent graphical relations. Examples perception supply-demandgraph economics include price eects supply, demand, market priceproduct, requires solving visual problems, as, point supply equaldemand? (corresponding spatial problem: compute intersection two curves),price supply line quantity 350? (corresponding spatial problem:compute point curve whose one coordinate given), quantity pricedirectly proportional? (corresponding spatial problem: check whether slope curvetwo points positive constant not), quantity price inverselyproportional? (corresponding spatial problem: check whether slope curvetwo points negative constant not), etc. Actions model required duenature task. Examples graphs understood sketchy shown Figure3.377fiBanerjee & Chandrasekaran(a) Graph economics(b) Graph thermodynamicsFigure 3: Examples graphs understood sketchy. Reproduced permissionPisan (1994).Figure 4: example deected frame analysis (from civil engineering) redraw.Reproduced permission Tessler et al. (1995).378fiExecuting Perceptions Actions Diagrammatic Reasoningredraw system (Tessler et al., 1995) combines diagrammatic symbolic reasoning qualitatively determine deected shape frame structure load,structural analysis problem civil engineering. uses vocabulary properties relations including get-angular-displacement, get-displacement, symmetrical-p, connected-to,near, left, above, rotate, bend, translate, smooth, etc. three kinds diagrammatic objects lines, splines, circles. Though properties relations domain-independent,some, as, bend reect assumptions implicit domain taskdened accordingly. Perceptions actions called inspection manipulation operators system. underlying representation combination grid-basedCartesian coordinates shapes represented using grid elementgrid corresponds point diagram lines represented set coordinatepoints. Examples perception action include deecting beam directionload, checking whether beam column perpendicular particular rigidjoint, etc. require solving visual problems, as, Bend Beam3 negativedirection y-axis (corresponding spatial problem: compute curve given slopegiven point), Make angle Beam3 Column3 Joint3 90 degrees without modifying Beam3 (corresponding spatial problem: compute curve makesparticular angle given point given curve), Get angle Beam3Column3 ends connected Joint3 (corresponding spatial problem: computeangle two curves given point), etc. example deected frame analysisredraw shown Figure 4.archimedes system (Lindsay, 1998) assists human demonstrating theoremsEuclidean geometry modifying/creating diagrams according instructionsthereafter perceiving/inferencing diagram. operates two diagrammatic objects - points line segments, recognizes shapes, as, square, triangle, path,etc. underlying representation array- grid-based. perceptions, called retrievalprocesses, dierent classes, as, verify relationship, test condition, etc.actions, called construction processes, also dierent classes, as, create objectcertain properties, transform object, etc. Executing perceptions actions require solving spatial problems, as, create segment parallel given segmentgiven point, rotate object check whether coincides another object, etc.example geometry theorem demonstrated archimedes shown Figure 5.diamond (Jamnik, 2001), system proving mathematical theorems, usessequence actions diagrams assisted human prove specic ground instancesgeneralizes induction. uses mixture Cartesian topological representationsrepresent dot (equivalent point Cartesian representation) diagrammaticobject discrete space, line area (or region) diagrammatic objectscontinuous space. Elementary shapes, as, row, column, ell, frame, constructeddots, derived shapes, as, square, triangle, rectangle, etc. constructedelementary derived shapes. vocabulary consists atomic onestep operations (e.g., rotate, translate, cut, join, project 3D 2D, remove, insertsegment, etc.). Spatial problems system composite operations composedatomic ones, as, draw right-angled triangle, translate rotate triangle, etc.system need execute perceptions information diagram perceived379fiBanerjee & ChandrasekaranFigure 5: example geometry theorem demonstrated archimedes.Figure 6: example mathematical theorem proven diamond. theoremNelson (1993).380fiExecuting Perceptions Actions Diagrammatic Reasoninghuman decides actions applied proof search. examplemathematical theorem proven diamond shown Figure 6.Georep (Ferguson & Forbus, 2000) takes input line drawing vector graphicsrepresentation creates predicate calculus representation drawings spatial relations. Five primitive shape types recognized, namely line segments, circular arcs, circlesellipses, splines (open closed), positioned text. Properties relations,as, proximity detection, orientation detection (e.g., horizontal, vertical, above, beside), parallelism, connectivity (e.g., detecting corner, intersection, mid-connection, touch), etc.deployed accomplish task. underlying representation vector graphics linedrawings. Systems, as, magi (Ferguson, 1994), juxta (Ferguson & Forbus, 1998),coadd built using georep symmetry detection, critiquing diagrams basedcaptions, producing description units, areas, tasks courseaction diagram, respectively. georep, due limitation task, needexecute action. Examples visual problems georep include guring cupcontains liquid (corresponding spatial problem: compare areas polygons representing cups), determine whether gure symmetric (corresponding spatialproblem: check whether one polygon congruent reection polygon),etc. example ambush analysis georep shown Figure 7.Figure 7: example ambush analysis georep. Reproduced permissionForbus et al. (2003).preceding discussion leads observation DR systems require perceiving and/or acting diagrams, every perception/action requires solvingdomain-independent spatial problem. Thus, general-purpose DR system solvingproblems applications across multiple domains would require solving large varietynon-trivial domain-independent spatial problems. spatial problems described381fiBanerjee & Chandrasekaranterms three diagrammatic objects points, curves, regions, spatial propertiesrelations involving them.1.4 Problemperceptions actions solved DR system? Typically, human developing DR system identies priori problem solving steps including set perceptionsactions, hand-codes ecient algorithms solving them. problemsolving steps need altered future result, new perception arises,developer write another algorithm obtaining solution. Thus, algorithms needhand-coded perception/action. Clearly, inconvenient time consuming developing DR system, allow fast easy experimentationdierent problem solving strategies problem. drawbacksmagnied goal build general-purpose DR system large variety perceptions actions possible feasible ascertain priori,develop store algorithms for. Hence, goal investigate spatial problem solver(SPS) eciently solving spatial problems implicit perceptions/actions without humanintervention.11.5 Contributionspaper, make following contributions:1. observe wide variety visual perceptions/actions DR applicationstransformed domain/task-independent spatial problems. developed languagespecifying spatial problems (i.e., spatial relations actions) quantied constraintsatisfaction problems (QCSPs) rst-order logic using xed set mathematical/logicaloperators real domain open-ended vocabulary properties, relationsactions. spatial relation action involving points expressed usingoperators real variables rst-order logic included vocabulary.Further, spatial relation action involving curves and/or regions expressedusing relations On(p, c) and/or Inside(p, r) p point, c curve, r region,relation/action involving points rst-order logic includedvocabulary. vocabulary grows richer spatial relations actions specied.2. spatial relation action included vocabulary solvableSPS. Real QCSPs known computationally intractable, substantial partspatial problem solving literature concentrates constraint satisfaction problems (CSPs).developed general framework solving spatial problems specied QCSPs.framework bypasses process quantier elimination (QE) computational bottleneck doubly exponential problem taking help previously solved similarspatial problems. show that, symbolic solution problem expressed1. reader keep DR architecture mind. shown Figure 1, two problemsolvers main problem solver always referred problem solver (this mighthuman) spatial problem solver referred SPS (this strictlyhuman intervention). problem solver responsible entire problem solving strategy includingconverting domain-specific perceptions actions domain-independent spatial problems. SPSresponsible solving domain-independent spatial problems receives problemsolver. important get confused roles played two.382fiExecuting Perceptions Actions Diagrammatic Reasoningconcisely, quantiers eliminated spatial problems low-order polynomial timeusing similar previously solved problems. framework leaves room ecientconvenient incorporating future results least two possible directions learningconstraints examples (automatic constraint acquisition) carefully exploiting richportfolio QE algorithms.rest paper organized follows. next section, discuss languagespecifying spatial problem SPS. Section 3 describes SPS. Section 4 analyzescomputational complexity SPS. Section 5 shows proposed SPSaugmented traditional AI problem solver (soar) reasoning diagrams tworeal-world applications. Finally, end discussion conclusion.2. Specification Languagesection, discuss high-level language nite, extensible, human-usable,expressive enough describe wide variety 2D spatial problems relevant DR.problems specied language accepted input SPS solvedwithout human intervention. specication language independent SPS, i.e.,problem specication remains unchanged even underlying representationreasoning strategy SPS change.2.1 Diagrammatic Objectsspecication language recognizes three kinds diagrammatic objects points, curves,regions.Point. point basic diagrammatic object. objects dened termsset points.Curve. curve set points it. approximate curve piecewise-linearly.Thus, curve c approximated sequence n points {p1 , p2 , ...pn }, c setpoints lies constituent line segments, i.e.c {p : On(p, {p1 , p2 }) On(p, {p2 , p3 }) ...On(p, {pn1 , pn })}p (x, y), x, , {pi , pi+1 } line segment pi pi+1 . callpoints {p1 , p2 , ...pn } vertex points. sake simplicity specication, problemsolver write sequence vertex points {p1 , p2 , ...pn } specify curve c.Region. region set points inside boundary. boundary regionclosed curve approximated piecewise-linearly. Thus, region simple (convexconcave) polygon. simple polygon triangulated point insideregion inside one triangles. Thus, boundary region r approximatedsequence n points {p1 , p2 , ...pn },r {p : Inside(p, (r)[1]) Inside(p, (r)[2]) ...Inside(p, (r)[m])}number triangles region r triangulation, (r)[i] ith triangler, p (x, y), x, . sake simplicity specication, problem solverwrite sequence vertex points {p1 , p2 , ...pn } boundary curve specify383fiBanerjee & Chandrasekaranregion r. Whether sequence vertex points corresponds curve regiondetermined automatically system context property/relation predicate.dene Inside section 3.1.Further, SPS asked recognize kind diagrammatic object(s) obtainedsolution spatial problem. achieved function Recognize(Dext )Dext external diagram (i.e., constituted pixels unlike abstract diagram).example, set points behind curve c respect given point pregion object curve object depending nature c location respectp. order recognize output, SPS colors corresponding set pixelsexternal diagram pixel predetermined resolution corresponds point.set colored pixels grouped two adjacent pixels always belonggroup. group pixels constitutes diagrammatic object. boundary pixelsgroup determined. group consists less three pixels, considerpoint object. group consists two pixels width (both horizontalvertical) always less three pixels, consider curve object. Otherwise,group constitutes region object.2.2 VocabularyUnlike certain well-known qualitative spatial reasoning calculi (e.g., intersection calculusEgenhofer, 1991, cardinal direction calculus Frank, 1991, region connection calculusRandell, Cui, & Cohn, 1992), interested nding minimal set spatialrelations vocabulary based closed set predicates. Rather, vocabularybased closed set operators (to discussed shortly section 2.3). spatialrelations actions included vocabulary follows:1. spatial relation action involving points expressed usingxed set operators real variables rst-order logic.2. spatial relation action involving points, curves regions expressedrst-order logic using xed set operators, real variables, relation/action#1, relations On(p, c) and/or Inside(p, r) p point, c curve, rregion.3. spatial relation action involving points, curves regions expressedrst-order logic using xed set operators, real variables, relation/action#1 #2.Thus, vocabulary open-ended addition new properties relationsencouraged problem cannot easily expressed using existing ones. observation that, human often encounters new perceptions/actionsspecied using already known ones. However, large vocabulary helps specifynew ones conveniently. DR literature (Pisan, 1995; Tessler et al., 1995; Lindsay, 1998; Jamnik, 2001; Ferguson & Forbus, 2000; Chandrasekaran et al., 2004; Banerjee &Chandrasekaran, 2004), identied vocabulary properties, relations actionsbased wide usage expressing variety real-world spatial problems dierentdomains. vocabulary used paper starting point specifyingspatial problems. follows examples properties, relations actionsvocabulary.384fiExecuting Perceptions Actions Diagrammatic ReasoningProperties. Associated kind object properties locationpoint; location, closedness length curve; location, area peripheryregion, periphery region refers boundary curve. user alsodene particular shapes (e.g., circle, triangle, annulus, etc.) curves regionsappropriate reasoning domain. Dierent shapes might specicproperties, as, radius circle, height triangle, etc. easily associatedobjects vocabulary user. DR also requires solving spatial problemsconcerning discrete set points. problems, properties, as, Centroid(S)V ariance(S), set points, included vocabulary.Relations. vocabulary also contains widely used relations (or relationalpredicates) involving points, as, Lef tof (p1 , p2 ), opof (p1 , p2 ), Collinear(p1 , p2 , p3 ),Between(p1 , p2 , p3 ) p1 , p2 , p3 points. relation involving pointsincluded vocabulary needed. On(p, c), p point c curve,fundamental relation involving curve Inside(p, r), p point r region, fundamental relation involving region vocabulary relationinvolving curves regions uses and/or Inside. relational predicates involving curves regions vocabulary Intersect(c1 , c2 ), IntersectionP oints(q, c1 , c2 ),ouches(c1 , c2 ), Subcurveof (c1 , c2 ) c1 , c2 curves, Subregionof (r1 , r2 )r1 , r2 regions.Actions. Further, set predicates identifying emergent objects modications existing objects. example, ranslate(q, O, tx , ty ) returns translation objecttx units along x-axis ty units along y-axis, Rotate(q, O, c, ) returns rotationobject respect point c center degrees anti-clockwise direction,Ref lect(q, O, {a, b}) returns reection object respect line segment {a, b}(i.e., point point b), Scale(q, O, c, sx , sy ) returns scaling objectrespect point c sx units along x-axis sy units along y-axis. curveregion, predicates dened using corresponding action involving pointpredicates and/or Inside.2.3 Languagelanguage problem solver (human articial) species spatialproblem SPS. internal representations objects, properties, relations,problem-solving strategies hidden problem solver. specication languageremains unchanged even underlying representation problem-solving strategychanged. use rst-order predicate logic specication language, previously reportedBanerjee Chandrasekaran (2007).Operators. language recognizes set boolean operators {, , }, set arithmetic operators {+, , , }, set relational operators {<, >, =, =}, quantiers{, }. brackets () used express precedence brackets {} usedexpress set. paper, often use certain combination operators, as, ,, , etc. sake brevity.385fiBanerjee & ChandrasekaranDomain. language allows problem solver specify domain setvariables assume values. Unless otherwise stated, domain real plane2 point variable real line non-diagrammatic variable.Functions. Further, language recognizes two functions aximize(f, {x, y, ...}, C)inimize(f, {x, y, ...}, C), maximizes minimizes function f respectvariables {x, y, ...} satisfying boolean combination constraints C (which mightinvolve quantiers) returns maximum minimum value f respectively alongconditions variables.Quantified Constraint Satisfaction Problem. instance constraint satisfaction problem (CSP) consists tuple < V, D, C > V nite set variables,domain, C= {C 1 , ...C k } set constraints. constraint C consists pair< , Ri > list mi variables Ri mi -ary relation domain D.question decide whether assignment mapping variabledomain element constraints satised. variables CSPthought implicitly existentially quantied.useful generalization CSP quantied constraint satisfaction problem,variables may existentially universally quantied. instanceQCSP consists quantied formula rst-order logic, consists ordered listvariables associated quantiers along set constraints. QCSPexpressed follows:(v1 , ...vm ) Q(xn , ...x1 ) (v1 , ...vm , x1 , ...xn )Q(xn , ...x1 ) Qn xn , ...Q1 x1Qi {, }, {x1 , ...xn } set quantied variables, {v1 , ...vm } set freevariables, V= {v1 , ...vm , x1 , ...xn }, quantier-free expression called matrix.representation quantied expression , written sequence quantiers followed matrix, referred prenex form. Example QCSP follows:Subcurveof (c1 , c) p, On(p, c1 ) On(p, c)c1 , c curves 2 . example, two constraints:< {p, c1 }, >< {p, c}, >Further, V= {p} = 2 . variables c, c1 given. questiondecide whether assignment mapping p element 2 logicalcombination constraints satised. assignment exists, c1subcurve c; otherwise is.Decision, Function Optimization problems. proposed specicationlanguage, spatial problem expressed QCSP V consists variables typepoint, curve region = 2 . Solving spatial problem involves:1. free variables V (i.e., variables V quantied), decidingwhether exists mapping V satisfying C.386fiExecuting Perceptions Actions Diagrammatic Reasoning2. free variables V, computing conditions free variablesmapping V satisfying C exists.Thus, spatial problem classied decision function optimizationproblem real domain. rst case constitutes decision problem yields TrueFalse solution. second case constitutes function problem involves computingdiagrammatic object(s) described conditions free variables. spatialproblem requires computing best mapping V satisfying C, calledoptimization problem.Let us consider example. Given curve c two points p, q, spatial problemBehindCurve(q, c, p) dened deciding whether q behind c respectp. might specied deciding whether curve c line segment {p, q}intersect. Thus,BehindCurve(q, c, p) Intersect(c, {p, q})particular instances q, p, c, solution problem rue F alse, hencedecision problem (see Figure 8). particular instances p, c, generalizedcoordinates q i.e., q (x, y), solution problem logical combinationconditions involving x y, plotted constitutes region object (see Figure9). Hence, function problem. decision problem merely requires checkingwhether given instance object satises constraints not, functionproblem requires computing conditions general object satisfy constraints.Figure 8: BehindCurve decision problem. One points q behind crespect p one not.Again, given curve c two points p, q, spatial problem F urthestBehindCurve(q,c, p) dened deciding whether q furthest point behind c respectp. might specied deciding whether q lies behind c respect p387fiBanerjee & ChandrasekaranFigure 9: BehindCurve function problem. shaded region r behind crespect p.distance p q maximum. Thus,F urthestBehindCurve(q, c, p) BehindCurve(q, c, p) b, BehindCurve(b, c, p)CompareDistance(b, p, q, p)CompareDistance(a, b, c, d) Distance(a, b) Distance(c, d)particular instances q, p, c, solution problem rue F alse, hencedecision problem. particular instances p, c, generalized coordinates q i.e.,q (x, y), solution problem logical combination conditions involvingx y, plotted constitutes single point object, assuming onefurthest point behind c respect p, dependent nature cDistance function dened (see Figure 10).alternative way specifying problem F urthestBehindCurve(q, c, p)explicitly asking maximize distance p q q satises constraintBehindCurve(q, c, p), written as:F urthestBehindCurve(q, c, p) aximize(Distance(q, p), {q}, BehindCurve(q, c, p))outputs conditions involving x y, constitutes single point object.aximize (or inimize) function assumes pool candidates choosebest satisfy set constraints. fact stated explicitlyusing aximize (or inimize) function makes specication dicultcome also cumbersome. ip side, specication problemusing aximize (or inimize) function cannot used decision problem.is, whether particular instance object best candidate satises388fiExecuting Perceptions Actions Diagrammatic ReasoningqFigure 10: F urthestBehindCurve optimization problem. point qfurthest point behind c respect p.constraints cannot computed specication, unlike former specication.problem type, computes best candidate pool candidates,called optimization problem.Definition 6. Spatial Problem. spatial problem (or problem) QCSPvariable (quantified free) type point, domain 2 .Thus, spatial problem mapping diagram satisfying logical combination constraints C set booleans {T rue, F alse} real numbers diagrammaticobjects , i.e.,C: D{T rue, F alse}Solving spatial problem requires eliminating quantiers solving algebraic equations/inequalities arrive simplied expression. computational bottlenecksolving spatial problem quantier elimination (QE) inherently doubly exponential (Davenport & Heintz, 1988). recently, Brown Davenport (2007)shown real QE doubly-exponential even one free variablepolynomials quantied input linear. paper, concentrate primarily QE part spatial problem solving hence, solution equivalentquantifier-free expression necessarily simplified one. Theoretically,best complexity QE achieved far O(s(l+1)(ki +1) d(l+1)ki ) numberpolynomials, maximum degree coecients real, l numberfreevariables, ki number variables ith quantier block k =kinumber quantied variables (Basu, Pollack, & Roy, 2003). However, algorithmcomplicated yet practical implementation. general elaboratelyimplemented method real QE cylindrical algebraic decomposition CAD (Collins389fiBanerjee & Chandrasekarank1& Hong, 1991), complexity (sd)O(1) . Another implemented method, QEvirtual substitution (Weispfenning, 1988), restricted formulas quantiedvariables occur quadratically. complexity method doubly exponentialnumber blocks variables delimited alternations existential universal quantiers. Thus, exist general algorithms QE, large real-worldproblems, soon becomes time consuming.3. Spatial Problem Solverpaper, concentrate developing ecient SPS without sacricing generality.goal design SPS bypass general QE algorithms much possible,either taking help previously solved similar problems memory obtainsolution using set practical algorithms developedlimited class problems. describe overall control mechanism SPS (seeFigure 11).many domains, as, military, spatial problems involve diagrammatic objectsarbitrary shaped (e.g., mountainous regions) often cannot approximated enoughwell-dened shapes solution reliably depend specics shape.example, solution problem nding places behind mountain onehide enemy depends critically particular shape mountain. Duenature domains, choose represent curves piecewise-linearly regionspolygons. Piecewise-linear curves polygonal regions unions line segmentstriangular regions respectively, facilitate decomposition complex problemssimpler similar subproblems. observe similar subproblems involvingexistential universal quantiers occur regularly spatial problem solvingprocess solved one QE algorithms (e.g., CAD), thereby incurring doublyexponential time. minimize enormous computational cost reusing solutionssubproblems previously solved.Given spatial problem specication language, SPS replaces numerical values problem symbolic variables, transforms symbolic problemspecication modeling language (to described shortly) progressively replacingobjects/predicates base objects/predicates internal denitions. denitioncannot found, ags error halts till provided. rst step, SPS decomposes disjunctions and/or conjunctions subproblems prenex form.see later, subproblems similar onesolved, solution others computed it. Next, searches memoryproblems similar . memory contains symbolic problems corresponding quantier-free symbolic solutions. mapped one problems,solution readily obtained reverse-mapping corresponding symbolic solutionmemory. Obtaining solution way completely bypasses QE process,computational bottleneck SPS, thereby reducing computational costs considerably. SPS cannot map problem memory, sends problemclassier classies sends appropriate QE algorithm. problem classier combination QE algorithms borrowed Mathematica (Wolfram,2003). SPS solves new subproblem, subproblem solution stored390fiExecuting Perceptions Actions Diagrammatic ReasoningProblemspecification languageConvert problem modeling language: Searchvocabulary replace terms specificationdefinitions, exists; otherwise request definitionProblemmodeling languageDecompose problem conjunctions and/ordisjunctions subproblems prenex formfirst subproblem I1 ,search memorysimilar subproblemMatch foundMemoryMatch foundCompute solutionsubproblem I1help solutionmatched problemProblem classifiercombination constraintsolvers quantifierelimination algorithmsSubproblem I1solutionCompute solutions subproblemssolution I1 combineSolutionFigure 11: Flow diagram spatial problem solver.memory solution used similar problem encountered future.Thus, SPS grows ecient solves problems. Finally, SPS computessolution given problem combining solutions subproblems.Unfortunately, problems, quantiers cannot eliminated symbolically reasonable time. SPS tries prescribed time, resorts practical391fiBanerjee & Chandrasekaranmethods, as, techniques especially suited low degree polynomials (e.g., Dolzmann,Sturm, & Weispfenning, 1998) approximate methods obtaining subset solution sucient immediate purposes (e.g., Ratschan, 2006; Lasaruk & Sturm, 2006).shown, integer linear programming (e.g., Leyton-Brown, Nudelman, & Shoham,2002) satisability testing (e.g., Xu, Hutter, Hoos, & Leyton-Brown, 2008),best on-average solver out-performed carefully exploiting portfolio possiblypoorer on-average solvers, accordingly, researchers experimented dierentways selecting portfolio solvers (see example, Xu et al., 2008; Pulina & Tacchella,2007; Sayag, Fine, & Mansour, 2006; Streeter, Golovin, & Smith, 2007; Gebruers, Hnich,Bridge, & Freuder, 2005; OMahony, Hebrard, Holland, Nugent, & OSullivan, 2008).none work involve solving QCSPs real domain, directly usablepurposes discussed paper. However, expectresult extend QCSP solvers real domain, building smartlyselecting portfolio QCSP solvers promising line future research.approach, subproblem deemed symbolically unsolvable prescribed time,specication stored memory future, similar problem directlysubjected practical methods, thereby saving prescribed time.3.1 Modeling Languagelanguage problem described terms underlying representations objects/properties/relations form readily subjected algebraicmanipulation. location point p represented pair (x, y), x, ,coordinates.Notation. x- y-coordinates point p denoted p.x p.y respectively.distance two points, p q, givenDistance(p, q)(p.x q.x)2 + (p.y q.y)2location curve c represented sequence vertex points {p1 , p2 , ...pn }.Notation. number vertex points curve c denoted #(c), ith vertexpoint denoted c[i], ith line segment denoted {c[i], c[i + 1]}.line segment ls specied pair vertex (or terminal) points. x-y-coordinates ls represented parametricallyfx (ls, t) ls[1].x + (ls[2].x ls[1].x)fy (ls, t) ls[1].y + (ls[2].y ls[1].y)parameter, 0 1. relation On(p, ls), p point, givenOn(p, ls) t, 0 1 fx (ls, t) = p.x fy (ls, t) = p.yLength line segment ls given392fiExecuting Perceptions Actions Diagrammatic ReasoningLength(ls) Distance(ls[1], ls[2])Length curve c given#(c)1Length(c)Length({c[i], c[i + 1]})i1location region r represented location peripherypiecewise linear closed curve. discussed section 2.1, internally region triangulated(computable linear time shown Chazelle, 1991; Seidel, 19912 ) aimreducing simplifying computations (more section 3.2).Notation. triangulation, number triangles region r denoted # (r)ith triangle r denoted (r)[i].area triangle givenArea()123[i].x [i\3 + 1].y [i\3 + 1].x [i].yi1Note area triangle positive sequence vertex points peripherygiven counter-clockwise direction, otherwise negative. Area region r given# (r)Area(r)Area((r)[i])i1relation Inside(p, ), p point triangle, givenInside(p, ) 3i1 Lef tof (p, {[i], [i\3 + 1]})Lef tof (p, ls) Area({ls[1], ls[2], p}) > 0ls line segment.action ranslate(q, c, tx , ty ) q (x, y), c curve, tx , ty real numbers, givenranslate(q, p, tx , ty ) q.x = p.x + tx q.y = p.y + tyranslate(q, c, tx , ty ) a, On(a, c) ranslate(q, a, tx , ty )Definition 7. Base Object. base object simplest form diagrammatic object.point simplest form. line segment simplest form curve.triangular region simplest form region. Thus, internally, three baseobjects point, line segment, triangle.Definition 8. Base Predicate. base predicate predicate accepts baseobjects arguments.2. Vik (2001) discusses implementation Mathematica.393fiBanerjee & ChandrasekaranExamples base predicates include Lef tof (p1 , p2 ), Between(p1 , p2 , p3 ), On(p, ls),Inside(p, ), p, p1 , p2 , p3 points, ls line segment, triangular region.#(c)1Lemma 1. On(p, c) i1On(p, {c[i], c[i + 1]})Proof. proof follows representation curve, described section 2.1.# (r)Lemma 2. Inside(p, r) i1Inside(p, (r)[i])Proof. proof follows representation region, described section 2.1.relations included vocabulary internally dened terms base predicates. example, predicate, Intersect(c1 , c2 ) c1 , c2 curves, denedterms base predicatesIntersect(c1 , c2 )a, On(a, c1 ) On(a, c2 )#(c )1a, i11#(c )1On(a, {c1 [i], c1 [i + 1]}) j12On(a, {c2 [j], c2 [j + 1]})3.2 Decomposing ProblemDefinition 9. Decomposition. Decomposition process replacing relationalpredicates, involving free variables types curve region, spatial problem (quantified expression) conjunctions/disjunctions base predicates taking conjunctions/disjunctions front expression. expression following conjunctions/disjunctions subproblem.Example. Decomposition problem Intersect(c1 , c2 ) a, On(a, c1 ) On(a, c2 )occurs follows:Intersect(c1 , c2 ) a, On(a, c1 ) On(a, c2 )#(c )1a, i11#(c )1On(a, {c1 [i], c1 [i+1]})j12On(a, {c2 [j], c2 [j+1]}) (bef ore decomposition)#(c )1 #(c2 )1j1 a, On(a, {c1 [i], c1 [i+1]})On(a, {c2 [j], c2 [j+1]})i11#(c )1i11#(c )1j12(af ter decomposition)Intersect ({c1 [i], c1 [i + 1]}, {c2 [j], c2 [j + 1]})Intersect ({c1 [i], c1 [i + 1]}, {c2 [j], c2 [j + 1]}) subproblem. However, question#(c )1 #(c )1arises Intersect(c1 , c2 ) i11 j12 Intersect ({c1 [i], c1 [i+1]}, {c2 [j], c2 [j +1]})?is, replace ?Theorem 1. problem equivalent decompositioncontain following forms:394fiExecuting Perceptions Actions Diagrammatic ReasoningF1:p, On(p, c) Inside(p, r)F2:p, On(p, c) Inside(p, r)F3:p, Inside(p, r) Inside(p, r1 )F4:p, Inside(p, r) Inside(p, r1 )(complement F1)(complement F3)c curve, r, r1 regions, c, r, r1 free variables.Proof. discussed section 2.2, framework, On(p, c) Inside(p, r) twofundamental relations using relation involving curve region specied.Also, framework, point quantiable variable, {, } quantiers, {, , } boolean operators sucient express boolean expression.Thus, spatial problem involving curves (and points regions) logicalcombination smaller problems following form:Qp, Rel(p, c) Q {, }, Rel {On, On}spatial problem involving regions (and points curves) logical combination smaller problems following form:Qp, Rel(p, c) Q {, }, Rel {Inside, Inside}spatial problem involving curves regions (and points) logical combinationsmaller problems following form:Qp, Rel1 (p, c) Rel2 (p, r)Q {, }, Rel1 {On, On}, Rel2 {Inside, Inside}, {, }spatial problem involving two curves, c c1 , (and points) logical combinationsmaller problems following form:Qp, Rel1 (p, c) Rel2 (p, c1 )Q {, }, Rel1 {On, On}, Rel2 {On, On}, {, }Again, spatial problem involving two regions, r r1 , (and points) logical combination smaller problems following form:Qp, Rel1 (p, r) Rel2 (p, r1 )Q {, }, Rel1 {Inside, Inside}, Rel2 {Inside, Inside}, {, }symbolically solved problems (56 total) two ways directlydecomposing p (x, y), c {p1 , p2 , ...pn } (n 2), pi (xpi , ypi ), c1 {a1 , a2 , ...au }395fiBanerjee & Chandrasekaran(u 2), ai (xai , yai ), r {q1 , q2 , ...qm } (m 3), qi (xqi , yqi ), r1 {b1 , b2 , ...bv }(v 3), bi (xbi , ybi ). turned solutions two ways equivalentproblems, except four cases stated theorem statement. Note F 2specication computing whether curve c entirely inside region r not. Letlsi ith line segment c (1 n 1) j j th triangular region r(1 j 2). foundp, On(p, c) Inside(p, r)m2p, (n1i1 On(p, lsi )) (j1 Inside(p, j ))m2p, n1i1 j1 (On(p, lsi ) Inside(p, j ))m2n1i1 j1 (p, On(p, lsi ) Inside(p, j ))because, c entirely inside r, necessary line segments cinside triangle r; line segment c span across multiple triangles r cstill inside r. Figure 12(a) shows example c inside r line segmentc spans across two triangles r. case, solution problemrue computed directly F alse computed via decomposition.rst case F 1 theorem statement explained similarly. forms F 1 F 2rewritten follows:F1 :p, On(p, c) Inside(p, r)p, On(p, c) Inside(p, r) r B rF2 :p, On(p, c) Inside(p, r)p, On(p, c) Inside(p, r) r B rB rectangular region (boundary) containing diagram discussed section1.2. Note rewritten forms equivalent decomposition.Again, F 4 specication computing whether region r entirely inside regionr1 not. Let 1,i ith triangle r1 (1 v 2) j j th triangularregion r (1 j 2). foundp, Inside(p, r) Inside(p, r1 )v2p, (m2j1 Inside(p, j )) (i1 Inside(p, 1,i ))v2p, m2j1 i1 (Inside(p, j ) Inside(p, 1,i ))v2m2j1 i1 (p, Inside(p, j ) Inside(p, 1,i ))396fiExecuting Perceptions Actions Diagrammatic Reasoningrrc(a) Curve c inside region r linesegment c inside one triangle r.r1(b) Region r inside region r1 triangle r inside one triangle r1 .Figure 12: Examples show decomposition curves regions problems containing forms F 1, F 2, F 3, F 4.because, r entirely inside r1 , necessary triangles rinside triangle r1 ; triangle r span across multiple triangles r1 rstill inside r1 . Figure 12(b) shows example r inside r1 triangle rspans across two triangles r1 . case, solution problem ruecomputed directly F alse computed via decomposition. third caseF 3 theorem statement explained similarly. forms F 3 F 4rewritten follows:F3 :p, Inside(p, r) Inside(p, r1 )p, Inside(p, r) Inside(p, r1 ) r1 B r1F4 :p, Inside(p, r) Inside(p, r1 )p, Inside(p, r) Inside(p, r1 ) r1 B r1Again, rewritten forms equivalent decomposition.Theorem 2. subproblem resulting decomposing problem contains base predicatesonly.Proof. problem decomposable due presence relational predicates, involvingfree variables types curve region, specication. stated section 2.2,problem involving curve region specied framework using relation(s)involving points relation Inside. Thus, relation Rel(q, c) involvingpoint q curve c rewritten as:Rel(q, c) a, On(a, c) Rel (q, a)397fiBanerjee & ChandrasekaranRel(q, c) a, On(a, c) Rel (q, a)Rel base predicate involving points q a. cases, expressionright-hand side contains base predicates only. Let problem involvingpoints curves regions. Let us replace occurrence non-base predicatesinvolving curve, as, Rel(q, c), equivalent expression consistingbase predicates involving points line segments only. resulting expressionconsists base predicates involving points On. lemma 1, non-baserewritten disjunctions base On. Therefore, resulting expression consistsbase predicates involving points only.Similarly, relation Rel(q, r) involving point q region r rewritten as:Rel(q, r) a, Inside(a, r) Rel (q, a)Rel(q, r) a, Inside(a, r) Rel (q, a)Rel base predicate involving points q a. problem involvingpoints regions curves, replacing occurrence non-base predicates involvingregion, as, Rel(q, r), equivalent expression consisting Inside basepredicates involving points only, using lemma 2, results expressionconsisting base predicates involving points triangular regions only.processes employed involves curves regions. Thus, subproblemresulting decomposing problem contain base predicates only.3.3 Mapping Similar ProblemDefinition 10. Similarity. define two spatial problems (quantified expressions)similar exists one-to-one correspondence variables (free quantified).Given two similar problems, 1 2 , solution 1 1 , goal constructone-to-one mapping variables 1 2 solution 2obtained replacing variables 1 corresponding variables, therebycompletely bypassing QE process computational bottleneck SPS. one-toone mapping exists 1 2 logically equivalent. However, equivalence checkinglogical expressions NP-hard (Dershowitz & Jouannaud, 1990; Goldberg & Novikov,2003). Thus, equivalence checking cannot used determine similarity eciently.Problem features. Let quantier free expression expressedprenex form, i.e.,(v1 , ...vm ) Q(xn , ...x1 ) (v1 , ...vm , x1 , ...xn )variable xi appears Q Q contains redundant variables.quantier block qb Q maximal contiguous subsequence Q every variableqb quantier type. quantier blocks ordered sequenceappearance Q; qb1 qb2 qb1 equal appears qb2 Q. quantied398fiExecuting Perceptions Actions Diagrammatic Reasoning...P1VP2P3VP4P6P5Figure 13: Parse tree matrix problem conjunctive normal form.variable xi appears quantier block qb(xi ), ordering quantier blocks imposes partial order quantied variables. variablesquantier block unordered.Let 1 Q1 1 2 Q2 2 1 2 parse trees 1 2 respectively. example, matrix problem conjunctive normal form might look like:P1 (P2 P3 ) (P4 P5 P6 ) ...Pi predicate. subproblem, Pi base predicate. parsetree sentence shown Figure 13.Two trees, 1 2 , isomorphic exists bijection : 1 2 preserves adjacency root vertex, i.e., (u) adjacent (w) u adjacent w,(root(1 )) = root(2 ). follows two isomorphic trees maximum heightnumber vertices height. Let l maximum heightnumber vertices height i. function , dened(< 1 , ... >) =i1integer, <> denotes sequence, ith smallest prime number,maps sequence integers unique integer. problem , tuple ()constructed follows:399fiBanerjee & Chandrasekaran() =< l,(# vertices dierent heights parse tree),# quantier blocks,order quantier blocks,(# variables dierent quantier blocks) >Definition 11. Structural Equivalence. Two spatial problems (quantified expressions),1 2 , structurally equivalent satisfy following conditions:1. (1 ) = (2 )2. 1 2 isomorphic other, 1 2 parse trees matrices1 2 respectively.3. contents (predicate boolean operator {, , }) pair corresponding nodes1 2 identical.4. exists one-to-one correspondence variables argumentspredicates contained pair corresponding nodes 1 2 . Moreover, twomappings obtained two pairs corresponding nodes 1 2 contradictother.see section 4, structural equivalence two problems computedtime linear size parse trees. Note two problems structurallyequivalent, logically equivalent vice versa. example, expressions (P P ) Q Q, P Q base predicates, logically equivalent,structurally equivalent since parse trees isomorphic. general, logicalequivalence imply structural equivalence redundancies (redundantvariables and/or predicates) one problems. sake computational eciency, use structural equivalence determine similarity two problems.Theorem 3. subproblems obtained decomposing problem always similar.Proof. Let us assume, contradiction, exists problem decomposessubproblems two them, j k , dissimilar. Without loss generality,assume subproblems except k similar j . Then,n(ni11=1 ni22=1 ... ipp=1 Qi1 i2 ...ip i1 i2 ...ip ) Qk k , {, },j {i1 i2 ...ip |0 i1 n1 , 0 i2 n2 , ...0 ip np },Qj {Qi1 i2 ...ip |0 i1 n1 , 0 i2 n2 , ...0 ip np }nni11=1 ni22=1 ... ipp=1 (Qi1 i2 ...ip Qk )(i1 i2 ...ip k )ni11=1 ni22=1 ... ipp=1 Qi1 i2 ...ip i1 i2 ...ipnThus, subproblems similar contradicts assumption. Hence prooffollows.Intuitively, proposed framework, curve represented arbitrary number vertices, line segment always represented two end points. Similarly,400fiExecuting Perceptions Actions Diagrammatic Reasoningperiphery region represented arbitrary number vertices, peripherytriangular region always represented three vertices. Hence, two line segmentstriangular regions always represented similarly dier coordinatesconstituent vertices, unlike two curves regions. base predicates dened termsbase objects points, line segments, triangular regions. Thus, predicatedened conjunctions disjunctions base predicates, base predicates alwayssimilar. Decomposition problem subproblems merely replaces onepredicates similar base predicates. Hence, subproblems similar.3.4 Memory OrganizationMemory SPS hierarchically organized stores problems disjoint classes basedprogressively problems features (see Figure 14). decomposing problemsubproblems computing , subproblems value ,SPS checks whether parse trees isomorphic mapping existsvariables. Since memory hierarchy constant height, insertion problemsearching potential class similar problems executed constant time. Also,features classify problems discriminative enough create large numberclasses (leaf nodes), class containing problems, thereby reducing searchproblems belonging class.4. Computational Complexityanalyze time complexity algorithms used framework.implementation, problem data structure consisting two elds P arseT reeSolution. P arseT ree stores lexicographically sorted parse tree matrixSolution stores symbolic solution concise form. parse treeconstructed time O(t) number base predicates booleanoperators {, , } . boolean operators occupy non-leaf nodes parse treebase predicates occupy leaf nodes. Lexicographically sorting tree requireslexicographically sorting contents children non-leaf node tree. Letnumber boolean operators ti number children ith booleanoperator. Thus,ti = 1. Note since base predicate always followedi1boolean operator, = constant. Lexicographically sorting listcontents children node requires O(ti logti ) time. Thus, total time requiredrepeating process non-leaf nodesO(ti logti ). Since average numberi1children per nodei1treei11O(ti =t1, total time required lexicographically sortt1t1log ) = O(t).401fiBanerjee & Chandrasekaranll1...lk[ (# vertices different[ (# vertices differentlevels parse tree)levels parse tree)1...Dm#(qb)q1...#(qb)qr...order qbso1......order qbsos...[ (# variables[ (# variablesdifferent qb's)different qb's)E1...Et...ProblemsProblemsFigure 14: Hierarchical problem classication memory. height hierarchy,branches correspond dierent values features captured .example, l1 lk correspond k dierent maximum heightsparse trees matrices spatial problems.Given two problems 1 , 2 , algorithm Similar(1 , 2 ) computes whether 12 similar (see Figure 15). Since computing requires O(t) time,line 1 requires O(t) time. Since checking whether two trees isomorphic requiresO(t) time (as shown Aho, Hopcroft, & Ullman, 1974), line 6 requires O(t) time. Lines 911 requires O(t) time. Thus, algorithm runs O(t) time.Given unsolved problem similar solved problem similar , algorithmComputeSolutionF romSimilarP roblem(, similar ) computes solution variable mapping similar (see Figure 16). V ariableM ap list entrypair < v, vsimilar >, v free variable vsimilar corresponding freevariable similar . Let size V ariableM ap k . lines 5 11 requiresO(tk ) time since number nodes similar number argumentspredicate small. Lines 12 13 requires O(k ) time sizesolution similar . Thus, algorithm runs O(tk + k ) time.Finally, given unsolved problem memory emory stores problems hierarchically (as described section 3.4), algorithm EliminateQuantif iers(, emory)computes solution variable mapping similar problem emory,problem exists; otherwise solves using problem classier combination constraint402fiExecuting Perceptions Actions Diagrammatic ReasoningSimilar(1 , 2 )1. (1 ) = (2 ),2.return F alse3. else4.1 1 .P arseT ree5.2 2 .P arseT ree6.Isomorphic(1 , 2 ) = F alse,7.return F alse8.else9.node 110.predicate boolean operator corresponding node 2match,11.return F alse12. return rueFigure 15: Algorithm deciding whether two problems 1 , 2 similarcomputing structural equivalence. problem quantied expression.ComputeSolutionF romSimilarP roblem(, similar )1. .P arseT ree2. similar similar .P arseT ree3. similar similar .Solution4. similar5. node similar6.node contains predicate (say P ),7.j 1 # arguments P8.v variable occupying j th argument P9.vsimilar variable occupying j th argument P similar10.V ariableM ap.Contains(v) = F alse,11.V ariableM ap.Add(< v, vsimilar >)12. 1 |V ariableM ap|13.Replace occurrences V ariableM ap[i, 2] V ariableM ap[i, 1]14. returnFigure 16: Algorithm computing solution problem mapping variablessimilar problem similar . problem quantied expressionsolution equivalent quantier-free expression.solvers QE algorithms (as described section 3). algorithm shown Figure17.403fiBanerjee & ChandrasekaranLet n subproblems problem. problem, predicates already base predicates rest written conjunctions/disjunctionsbase predicates thereby leading decomposition problem subproblems.example, section 1.1, problem RiskyP ortionsof P ath(q, c1 , c2 , d) dened termsbase predicate DistanceLessT han(p, q, d) (i.e., Distance(p, q) d) nonbase predicates On(q, c1 ) On(p, c2 ). non-base predicates writtendisjunctions base predicates, as, On(q, {c1 [i], c1 [i + 1]}) On(q, {c2 [j], c2 [j +1]}), respectively, thereby leading decomposition RiskyP ortionsof P ath subproblems. subproblems inherits base predicates problem (e.g.,DistanceLessT han(p, q, d)) also includes new base predicates (e.g., On(q, {c1 [i], c1 [i+1]}), On(q, {c2 [j], c2 [j + 1]})) obtained non-base predicates. Let numberpolynomials base predicates problem number polynomials duenewly obtained base predicates subproblem. Since subproblems similar,+ polynomials. total number polynomials problemO( + n).Let maximum degree polynomial subproblem. Since subproblemssimilar, maximum degree d. maximum degree polynomialsproblem also objects represented piecewise-linearly, case 2.objects represented piecewise-linearly, degree much largertwo might lead situation problem might solvable reasonabletime.Let k number quantied variables problem. subproblemalso k quantied variables. Let computational complexity using general QEalgorithm solving problem (n) solving subproblem (1),k1doubly exponential function, as, using CAD, (n) = (sd)O(1) . Note(n) nT (1), i.e., ecient solve subproblem using general QEalgorithm solve whole problem using algorithm.algorithm EliminateQuantif iers(, emory), lines 4 7 require O(n) time.Lines 8 9 require O(t) time each. Since line 13 requires O(t) time, lines 1116 require O(mt) time. Line 18 requires time (1) lines 20 23 requireO((n1)(tk +k )) time. Thus, entire algorithm runs O(T (1)+mt+(n1)(tk +k ))time. Note size symbolic solution, symbolic solutionexpressed concisely, small. Since number boolean operatorsorder number base predicates base predicate dened termsleast one polynomial, = O(s) = O( + n). Thus, complexity algorithmO(T (1) + (m + (n 1)k )s + (n 1)k ). seennT (1) > (1) + (m + (n 1)k )s + (n 1)kor,(( + )d)O(1)k1> ( n1+ k )( + n) + ktrue provided large. is, ecient solve problem variablemapping solve subproblem using general QE algorithm provided sizestored symbolic solution large. every decomposable problem, complexityQE reduced above.404fiExecuting Perceptions Actions Diagrammatic ReasoningEliminateQuantif iers(, emory)1. .Solution2. Decompose subproblems Qi , 1 npnpn1n2nki1 =1 i2 =1 ... ip =1 Qi , n =k13.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.i1k p 1j 1 nkith operator ( ) decomposed right leftii+1Construct parse tree matrix 1Compute ()f lag 0j 1emory,j j th problem emorySimilar(M emory,j , 1 ) = rue,similar emory,jf lag 1break loopf lag = 0,1 .Solution ComputeSolutionF romQEAlgorithms(1 )similar 1(2 f lag + 2)\3 n.Solution ComputeSolutionF romSimilarP roblem(i , similar ).Solution .Solution .Solutionreturn .SolutionFigure 17: Algorithm computing solution spatial problem taking helppreviously solved similar problems emory, thereby bypassing quantierelimination whenever possible. problem quantied expressionsolution equivalent quantier-free expression.problem encountered SPS rst time, solved decomposing subproblems, solving rst subproblem using general QE algorithmobtaining solution rest subproblems mapping variablesrst subproblem. Since subproblem solution stored memory, similarsubproblem encountered future, SPS bypasses QE algorithm completelysolves variable mapping. case, line 18 algorithm never executed,time complexity solving problem(m + nk )s + nk405fiBanerjee & Chandrasekaranconsiderable savings compared complexity solving entire problemk1using general QE algorithm (e.g., complexity CAD (sd)O(1) ), providedlarge. SPS solves problems, probability encounter similar problemmemory increases thereby leading scenario incurs complexity loworder polynomial compared doubly exponential.3Example. illustrate problem solving process, let us consider spatial problem BehindCurve(q, c, p) (described section 2.3). point p (px , py ) curvec {p1 , p2 , ...pn } pi (xi , yi ) point, decomposition problem occursfollows:BehindCurve(q, c, p)Intersect(c, {p, q})a, On(a, c) On(a, {p, q})a, (n1i=1 On(a, {pi , pi+1 })) On(a, {p, q})n1i=1 (a, On(a, {pi , pi+1 }) On(a, {p, q}))n1i=1 (Qi )n1i=1Thus (n 1) subproblems ,On(a, {pi , pi+1 }) On(a, {p, q})Qia, On(a, {pi , pi+1 }) On(a, {p, q})Figure 18, (i ) =< 2, 21 33 , 1, < >, 21 > = 1, 2, ...n 1. theorem 3,similar since subproblems problem. SPS3. noted approximating continuous curve sequence line segments drawbacks. example, point p continuous curve c might piecewise-linearapproximation c. SPS accept parameter specifies maximum length linesegment used approximation. current implementation, leave onus determining maximum length problem solver. context, deserves mention lossinformation inevitable almost kind approximation. example, spacediagram approximated finite number pixels, shown Banerjee Chandrasekaran (2010),diagrammatic objects lose certain spatial information might detrimental spatial problemsolving avoided knowing minimum allowable resolution (or maximum length oneside square pixel).406fiExecuting Perceptions Actions Diagrammatic ReasoningOn(a,{p1,p2})On(a,{p,q})Figure 18: Parse tree matrix rst subproblem BehindCurve problem.nd problem memory similar rst subproblem 1 , sent problemclassier sends appropriate QE algorithm. problem denition, tuple, parse tree, solution stored memory follows:1 (q, {p1 , p2 }, p) a, On(a, {p1 , p2 }) On(a, {p, q})1 ((x, y), {(x1 , y1 ), (x2 , y2 )}, (px , py ))(px x < 0 px x1 0 x1 x 0 py x1 py x + px x1 px y1 + xy1 = 0) (x px <0 x1 px 0 x x1 0 py x1 py x + px x1 px y1 + xy1 = 0) ...arguments 1 free variables. subproblems solvedreplacing variables 1 mapped variables. problem similar 1 foundmemory, 1 also solved replacing mapped variables,subproblems.Note that, example, BehindCurve problem, absence appropriatevocabulary properties/relations, would specied (see redlog Weispfenning, 2001):BehindCurve((x, y), {(p1,x , p1,y ), (p2,x , p2,y ), ...(pn,x , pn,y )}, (px , py ))ax , ay , t, 0 1 px + t(x px ) = ax py + t(y py ) = ay n1i1 (ti , 0 ti1 pi,x + ti (pi+1,x pi,x ) = ax py + ti (pi+1,y pi,y ) = ay )total number quantiers n + 3, dependent number line segmentsforming curve huge complicated curves many real-world applications. SPS, due appropriate decomposition problems subproblems,number quantiers subproblem always xed (4 case) irrespectivespatial complexity object(s) (curve case). symbolic solutionssimple subproblems stored future use possible systems like redlog. Needless say, though solving problem using systems producesolution, much faster.407fiBanerjee & Chandrasekaran5. Applicationssection, illustrate SPS deployed conjunction problemsolver, human articial (such as, soar), solving spatial problems without human intervention needed DR. Two applications considered entity re-identicationambush analysis deemed important military domain. subproblems SPS autonomously decomposes spatial problem shown.Problems military domain involve wide variety objects arbitrary propertiesrelations, hence, help illustrate expressiveness specication languageeciency generality SPS.implementation, used bisoar, due Kurup Chandrasekaran (2007),bimodal version soar (Laird et al., 1987), problem solver uses two kinds operators predicate-symbolic operators applied information predicate-symbolicform perception-like operators applied diagram bring statetransitions reach goal state initial state. human responsible providingbroad problem solving strategy class problems; given specic problemclass, bisoar uses predicate-symbolic perception-like operators accordingly.Since used bisoar number dierent domains (e.g., military, Euclidean geometry, physics, civil engineering; Banerjee & Chandrasekaran, 2007 provide examples)still continue so, knows several dierent problem solving strategies operators, predicate-symbolic perception-like. emphasis sectioneciently bisoar solves problems eciently perception-like operatorsexecuted without incorporating knowledge jeopardizes generalitygeneral-purpose problem solver. spatial problem, compare performanceproposed SPS CAD algorithm terms actual computation timedetermined taking average least 10 runs. see, SPS excelssignicant margin cases.5.1 Entity Re-identificationentity re-identication problem core task US Armys All-Source AnalysisSystem (ASAS). ASAS receives new report sighting entity T3 type (e.g.tanks). task decide new sighting entitiesdatabase earlier sightings, entirely new entity. Reasoning dynamicallyintegrate information dierent sources database sightings, mobility vehicles,sensor reports, terrain map information make decision. follow novelcapability using failure expectation: H true, observed,since not, H likely case, H hypotheses observationsrespectively (Josephson & Josephson, 1996; Chandrasekaran et al., 2004). following,consider simple version problem illustrate task solved using DRspatial problems involved therein.Figure 19(a) shows terrain interest mountainous closed regions markingimpassable areas entities type (e.g., tanks). Let T3 entity newly sightedtime t3 located point p3 T1 , T2 two entities located points p1 ,p2 last sighted times t1 , t2 respectively. T1 T2 retrieved databasepotential T3 based partial identity information. Also,408fiExecuting Perceptions Actions Diagrammatic ReasoningT2T1T3(a) Terrain, impassable regions, sighted tanks.(c) short path T1 T3 .(b) short path T2 T3 .(d) path plausible homotopyclass.Figure 19: Reasoning steps entity re-identicationarea interest, three enemy regions obstacles {r1 , r2 , r3 } (as shown Figure19(a)) given repower/sight range enemy. Reasoning proceeds follows.T1 reach p3 within time t3 t1 , T3 might T1 . Similarly T2 . Sincemountainous region (or obstacle) hiding place enemies repower range d,existence entity shows probably traverse territorywithin repower range. Further, might sensor elds report databasesense entities. entity sensed sensor eld times t1t3 , T1 could followed path passed sensor eld.constraints taken account reasoning. information mightavailable database once. follows simple scenario discussionspatial problems occur.problem solver (e.g., commander) wants know whether exists contiguoussafe region containing points p1 p3 . species problem Saf eRegion follows:Saf eRegion(q, {r1 , r2 , ...rn }, d)409fiBanerjee & Chandrasekarana, (ni1 Inside(a, ri )) Distance(q, a)# (ri )a, (ni1 j1# (ri )a, (ni1 j1Inside(a, (ri )[j])) Distance(q, a)Inside(a, (ri )[j])) Distance(q, a)# (ri )a, Inside(a, (ri )[j]) Distance(q, a)# (ri )a, Inside(a, (ri )[j]) Distance(q, a)# (ri )Saf eRegion (q, {(ri )[j]}, d)ni1 j1ni1 j1ni1 j1q (x, y). Decomposition problem SPS shown above. subproblem symbolically solved solution stored memory along subproblemspecication. order compare actual times required solve problem, constructed simple diagram consisting four polygonal regions depicting obstacles (seeFigure 20(a)). four regionsr1 {(10, 10), (30, 10), (30, 30), (10, 30)},r2 {(20, 0), (0, 0), (10, 20)},r3 {(0, 20), (10, 40), (10, 40)},r4 {(50, 20), (70, 20), (80, 40), (60, 50), (40, 40)},2. Triangulation regions produced seven triangles. subproblemsymbolically solved stored, solving problem required 0.25 seconds solvingusing CAD algorithm required 5.5 seconds.diagram shaded safe region input Recognize function computes vertices boundaries shaded region, shown Figure 20(b). Nextproblem solver wants know whether exists path points p1 p3 safelyavoiding obstacles enemy repower range, whether path traversedtime t3 t1 . Let v velocity sighted entity piece symbolic knowledgeavailable database. Then, maximum length path traversable giventime L = v (t3 t1 ). Let l L rational number. Then, problem pathexistence two points path lies inside region r lessgiven length l specied as:P athExists(s, t, r, l)q, Inside(q, r) Distance(s, q) + Distance(q, t) l# (r)q, (i1Inside(q, (r)[i])) Distance(s, q) + Distance(q, t) l410fiExecuting Perceptions Actions Diagrammatic Reasoningr3r3r4r4r1r1r2r2(a) unshaded polygons obstacles.shaded region safe region, computedSPS.(b) points shown vertices boundaries safe region computedRecognize function.r3r3r4r1r2r4r1r2(c) Paths lying safe region lessgiven length two points, computedSPS.(d) Paths lying safe region lessgiven length two points, computedCAD algorithm.Figure 20: simplied scenario illustrate performance proposed SPS compared CAD algorithm entity re-identication.# (r)i1q, Inside(q, (r)[i]) Distance(s, q) + Distance(q, t) l# (r)i1P athExists (s, t, (r)[i], l)411fiBanerjee & ChandrasekaranDecomposition problem SPS shown above. subproblem symbolicallysolved stored. Again, resort simple diagram Figure 20 compare actualcomputation times P athExists(s, t, r, l) problem, (0, 45), (20, 5),r Recognize(Saf eRegion((x, y), {r1 , r2 , ...rn }, 2)), dierent sets regions ridierent values l. Triangulation r produced 8, 7, 7, 9 24 triangles {r1 }, {r2 },{r3 }, {r4 } {r1 , r2 , r3 , r4 } respectively. subproblem symbolically solvedstored, computation times required solving problem using proposed SPSsignicantly less using CAD algorithm (see Table 1).Table 1: Comparison computation times (in seconds) CAD algorithmproposed SPS P athExists(s, t, r, l) problem, (0, 45),(20, 5), r Recognize(Saf eRegion((x, y), {r1 , r2 , ...rn }, 2)). 2.8 GHz PC4 GB RAM, 5356 MB virtual memory 32-bit operating system used.implementation done athematica. Below, res refers result,refers rue, F refers F alse, OOM refers memory.l10050010001009101020004000800016000{r1 }CAD,SPS,res2.78, 0.41, F2.77, 0.42, F2.66, 0.39, F2.28, 0.42,2.28, 0.41,1.88, 0.39,1.88, 0.34,1.88, 0.33,1.88, 0.33,{r2 }CAD,SPS,res498.22, 0.53, F482.77, 0.44, F118.97, 0.55,119.28, 0.52,120.06, 0.53,120.38, 0.42,120.73, 0.39,121.58, 0.34,121.45, 0.34,{r3 }CAD,SPS,res470.74, 0.5, F476.97, 0.5, F135.03, 0.49,134.75, 0.5,135.02, 0.52,135.3, 0.38,135.08, 0.34,135.03, 0.33,135.13, 0.36,{r4 }CAD,SPS,resOOM, 0.47, FOOM, 0.48, FOOM, 0.49,OOM, 0.52,OOM, 0.47,OOM, 0.44,OOM, 0.31,OOM, 0.39,OOM, 0.36,{r1 , r2 , r3 , r4 }CAD,SPS,resOOM, 1.42, FOOM, 1.42, FOOM, 1.42, FOOM, 1.42, FOOM, 1.41,OOM, 1.19,OOM, 1.0,OOM, 0.98,OOM, 0.92,general, P athExists(s, t, r, l) problem specied as:P athExists(s, t, r, l)q1 , q2 , ...qn , (a, On(a, {s, q1 , q2 , ...qn , t}) Inside(a, r)) Length({s, q1 , q2 , ...qn , t}) lq1 , q2 , ...qn , (a, On(a, c) Inside(a, r)) Length(c) lq1 , q2 , ...qn , (a, On(a, c) Inside(a, r)) Length(c) l# (r)q1 , q2 , ...qn , (a, On(a, c) (k1Inside(a, (r)[k]))) Length(c) l# (r)q1 , q2 , ...qn , (a, On(a, c) (k1Inside(a, (r)[k]))) Length(c) l412fiExecuting Perceptions Actions Diagrammatic Reasoning# (r)k1q1 , q2 , ...qn , (a, On(a, c) Inside(a, (r)[k])) Length(c) l# (r)k1P athExists (s, t, (r)[k], l)c {s, q1 , q2 , ...qn , t} r Br. Note even though c curve, On(a, c)cannot decomposed since c free variable (see denition Decompositionsection 3.2). Also, note problem contains form F 2 discussed heorem1, r used.exists path points p1 p3 safely avoiding obstacles enemyrepower range traversed time t3 t1 , problem solver wantscompute path(s). problem specied as:F indP ath(q, s, t, r, l)Inside(q, r) Distance(s, q) + Distance(q, t) l# (r)(i1Inside(q, (r)[i])) Distance(s, q) + Distance(q, t) l# (r)i1Inside(q, (r)[i]) Distance(s, q) + Distance(q, t) l# (r)i1F indP ath (q, s, t, (r)[i], l)q (x, y). Since quantiers, solving problem decompositionvariable mapping achieve reduction computation time anysignicant amount.region consisting paths satisfy constraints (l 1010) shownFigure 20(c). quality solution depends Recognize function. example,solution shown Figure 20(d) accurate Figure 20(c) Recognizefunction failed determine vertices safe region accurately. alternate denitionsemi-linear motion planning problem found Weispfenning (2001),semi-linear path consists n translations along straight lines parallelone given k vectors.results, problem solver infers T3 might T1 . Next repeatsentities T3 T2 , nds exists path points p2 p3safely avoiding obstacles enemy repower range traversedtime t3 t2 . T3 might T2 well. sensor database informs twosensor elds SENSOR1, SENSOR2 area interest reportpassing vehicle. Problem solver wants verify whether paths passessensor elds. species problem Intersect(r1 , r2 ) computeintersection two regions r1 r2 .IntersectRegions(r1 , r2 )q, Inside(q, r1 ) Inside(q, r2 )# (r1 )q, (i1# (r2 )Inside(q, (r1 )[i])) (i1Inside(q, (r2 )[j]))413fiBanerjee & Chandrasekaran# (r1 )i1# (r2 )j1IntersectRegions ((r1 )[i], (r2 )[j])computesproblemIntersectRegions(paths13 , s1 ) paths13 Recognize(F indP ath(q, p1 , p3 , r, l))s1 region covered SENSOR1. scenario Figure 19(c), solution rue.Next problem solver wants know whether exists path points p1p3 safely avoiding obstacles enemy repower range traversedtime t3 t1 . computes P athExists(p1 , p3 , r13 , l), r13 Recognize(paths13 s1 ),returns rue. inference follows T3 might T2 . reasoningrepeated T3 T2 ; Intersect(paths23 , s2 ) returns rue P athExists(p2 , p3 , r23 , l)returns F alse (see Figure 19(b)). inference follows T3 cannot T1 . Hence,problem solver identies T3 T2 .entity reidentication problem could also solved computing shortest paths pairs p1 , p3 p2 , p3 avoiding sensors checking whetherlengths satisfy time constraints. requires computing shortest path two points p1 p3 safely avoiding obstacles enemy repower range (i.e.,lying entirely within safe region r). Since path loopshare intermediate vertices, any, vertices r, path#(r) intermediate vertices. Let r {p1 , p3 }, #(S), c {q1 , q2 , ...qm }shortest path, q1 p1 , qm p3 , qi r (2 1). Then, problemcomputing shortest path speciedF indShortestP ath(r, c)inimize(Length(c), {c[2], c[3], ...c[m 1]}, CurveInsideRegion(c, r))CurveInsideRegion(c, r) constraint specied decomposedfollows.CurveInsideRegion(c, r)a, On(a, c) Inside(a, r)a, On(a, c) Inside(a, r)a, On(a, c) Inside(a, r)#(c)1a, (i1# (r)a, On(a, {c[i], c[i + 1]}) Inside(a, (r)[j])# (r)CurveInsideRegion ({c[i], c[i + 1]}, (r)[j])#(c)1j1#(c)1j1i1i1# (r)On(a, {c[i], c[i + 1]})) (j1Inside(a, (r)[j])))414fiExecuting Perceptions Actions Diagrammatic Reasoningr Br. Since problem form F 2, r used. subproblem symbolically solved stored, solving problem CurveInsideRegion(c, r),c {(0, 45), (14, 42), (35, 42), (15, 35), (34, 32), (36, 19), (47, 15), (87, 15), (30, 7), (20, 5)},r Recognize(Saf eRegion((x, y), {r1 , r2 , r3 , r4 }, 2)),SPS required 3.11 seconds solving using CAD algorithm required 175.01 seconds (see Figure 21(a)). shortest path obtained solvingF indShortestP ath(r, c) problem shown Figure 21(b).(a) path c two points lying insideshaded region r.(b) Shortest path two points computedF indShortestP ath(r, c) problem.Figure 21: Paths two points lying inside safe (shaded) region.5.2 Ambush Analysistwo main factors range repower sight determine area coveredmilitary unit. Presence terrain features, as, mountains, limit factorsallow units hide opponents. hidden units enjoy advantageconcealing resources intentions opponents also attackopponents catching unawares traveling along path withinsight repower range hidden units, thereby ambushing them. Thus,utmost importance military unit priori determine areas portionspath prone ambush traversing them. already described section 1.1problem solver (e.g., army commander) reasons using diagrams gure safestpath transport troops one base camp another given time. section,given curve region hiding place repower sight ranges, show415fiBanerjee & Chandrasekaranregions portions path prone ambush eciently computed proposedSPS.Given curve c repower sight range d, spatial problemRiskyRegion(q, c, d) dened set points covered range c. Thus,problem specication is:RiskyRegion(q, c, d)a, On(a, c) Distance(a, q)#(c)1a, (i1On(a, {c[i], c[i + 1]})) Distance(a, q)#(c)1a, On(a, {c[i], c[i + 1]}) Distance(a, q)#(c)1RiskyRegion (q, {c[i], c[i + 1]}, d)i1i1q (x, y). order compare actual computation times required solveproblem, constructed simple diagram consisting two curves, path mntn,path {(25, 10), (5, 10), (3, 15), (7, 17), (2, 18), (2, 18), (7, 15),(3, 12), (5, 10), (40, 10)}mntn {(5, 5), (7, 2), (9, 9), (6, 12), (0, 4), (2, 3), (15, 5), (25, 12), (30, 20)}solution problem RiskyRegion(q, mntn, d) shaded region shown Figure22(a) mntn obstacle hiding (e.g., mountain range) 15. problemRiskyRegion(q, r, d) region r specied replacing predicate On(p, c)Inside(p, r).Again, given curve c1 path, curve c2 hiding, repower range d,problem RiskyP ortionsof P ath(q, c1 , c2 , d) dened parts c1 covered rangec2 . Thus,RiskyP ortionsof P ath(q, c1 , c2 , d)On(q, c1 ) p, On(p, c2 ) Distance(p, q)#(c )1p, (i11#(c )1j12#(c )1j12i11i11#(c )1On(q, {c1 [i], c1 [i+1]}))(j12#(c )1#(c )1On(p, {c2 [j], c2 [j +1]}))Distance(p, q)p, On(q, {c1 [i], c1 [i+1]}))On(p, {c2 [j], c2 [j +1]})Distance(p, q)RiskyP ortionsof P ath (q, {c1 [i], c1 [i + 1]}, {c2 [j], c2 [j + 1]}, d)416fiExecuting Perceptions Actions Diagrammatic Reasoning(a) shaded region, computedproblem RiskyRegion(q, mntn, 15), riskyregion prone ambush due enemies hidingmntn. portions path inside risky region risky portions path.(b) bold parts path, computedproblem RiskyP ortionsof P ath(q, path,mntn, 15), risky portions path.shaded region, computed problem BehindCurvewrtRiskyP ath(q, mntn, path),enemies could hiding troops traveling path.(c) Troops traveling rskyprtn1 , risky portion (in bold) path, carefulambushed enemies hiding shaded region rskyprtn1 within firepower rangeregion, computed problemBehindCurvewrtRiskyP athDistance(q, mntn,rskyprtn1 , 20).(d) Troops traveling rskyprtn2 , risky portion (in bold) path, carefulambushed enemies hiding shaded region rskyprtn2 within firepower rangeregion, computed problemBehindCurvewrtRiskyP athDistance(q, mntn,rskyprtn2 , 20).Figure 22: simplied scenario illustrate performance proposed SPS ambush analysis.417fiBanerjee & Chandrasekaranq (x, y). Alternatively, problem speciedRiskyP ortionsof P ath(q, c1 , r2 , d)On(q, c1 ) Inside(q, r2 )#(c )1(i11# (r2 )On(q, {c1 [i], c1 [i + 1]})) (j1# (r2 )On(q, {c1 [i], c1 [i + 1]}) Inside(q, (r2 )[j])# (r2 )RiskyP ortionsof P ath (q, {c1 [i], c1 [i + 1]}, (r2 )[j], d)#(c )1j1#(c )1j1i11i11Inside(q, (r2 )[j]))r2 Recognize(RiskyRegion((x, y), c2 , d)) q (x, y).solutionproblem RiskyP ortionsof P ath(q, path, mntn, d), 15, partspath inside shaded region shown Figure 22(a). Figure 22(b) showsrisky portions path rskyprtn1 , rskyprtn2 bold obtainedRecognize(RiskyP ortionsof P ath(q, c1 , c2 , d)).rskyprtn1 {(16, 10), (5, 10), (3.7, 12.6)}rskyprtn2 {(3, 12), (5, 10), (16.1, 10)}Note latter specication free quantiers former not. However,solution computed latter specication might less accuracyformer due use Recognize function. hiding place region rinstead curve c2 , problem RiskyP ortionsof P ath(q, c1 , r, d) speciedreplacing predicate On(p, c2 ) Inside(p, r). portions path marked Figure2(c) computed specication.region behind c2 enemies might hiding set pointsbehind c2 respect point risky portions curve c1 . Thus, c riskyportion path,BehindCurvewrtRiskyP ath(q, c2 , c)a, On(a, c) BehindCurve(q, c2 , a)a, On(a, c) Intersect(c2 , {a, q})a, On(a, c) (b, On(b, c2 ) On(b, {a, q}))#(c)1a, b, (i1#(c)1i1#(c )1j12#(c )1On(a, {c[i], c[i + 1]})) (j12On(b, {c2 [j], c2 [j + 1]})) On(b, {a, q})(a, b, On(a, {c[i], c[i + 1]}) On(b, {c2 [j], c2 [j + 1]}) On(b, {a, q}))418fiExecuting Perceptions Actions Diagrammatic Reasoning#(c)1i1#(c )1j12BehindCurvewrtRiskyP ath (q, {c2 [j], c2 [j + 1]}, {c[i], c[i + 1]})q (x, y). solution problem BehindCurvewrtRiskyP ath(q, mntn, rskyprtn1 )BehindCurvewrtRiskyP ath(q, mntn, rskyprtn2 ) shaded region shown Figure 22(b). hiding place region r instead curve c2 , problemBehindCurvewrtRiskyP ath(q, r, c) specied replacing predicate On(p, c2 )Inside(p, r).However, enemies might hiding anywhere behind mountain withindistance ambush friendly units. Hence, reasonable problem commander friendly side compute wouldBehindCurvewrtRiskyP athDistance(q, c2 , c, d) distanceenemies ambush them. problem specied as:BehindCurvewrtRiskyP athDistance(q, c2 , c, d)a, On(a, c) BehindCurve(q, c2 , a) Distance(a, q)a, On(a, c) Intersect(c2 , {a, q}) Distance(a, q)a, On(a, c) (b, On(b, c2 ) On(b, {a, q})) Distance(a, q)#(c)1#(c )1a, b, (i1 On(a, {c[i], c[i + 1]})) (j12Distance(a, q)#(c)1On(b, {c2 [j], c2 [j + 1]})) On(b, {a, q})#(c )1i1 j12(a, b, On(a, {c[i], c[i + 1]}) On(b, {c2 [j], c2 [j + 1]}) On(b, {a, q}))Distance(a, q)#(c)1i11]}, d)#(c )1j12BehindCurvewrtRiskyP athDistance (q, {c2 [j], c2 [j + 1]}, {c[i], c[i +q(x, y).solutions problems BehindCurvewrtRiskyP athDistance(q, mntn, rskyprtn1 , d)BehindCurvewrtRiskyP athDistance(q, mntn, rskyprtn2 , d), 20,shaded regions shown Figure 22(c), 22(d) respectively. hiding place region rinstead curve c2 , problem BehindCurvewrtRiskyP athDistance(q, r, c, d)specied replacing predicate On(p, c2 ) Inside(p, r). comparisonCAD algorithm proposed SPS actual times required compute problemsrelevant ambush analysis discussed shown Table 2.419fiBanerjee & ChandrasekaranTable 2: Comparison computation times (in seconds) CAD algorithmSPS dierent problems relevant ambush analysis. 2.8 GHz PC4 GB RAM, 5356 MB virtual memory 32-bit operating system used.implementation done athematica. following functionproblems q (x, y).P roblemRiskyRegion(q, mntn, 15)RiskyP ortionsof P ath(q, path, mntn, 15)BehindCurve(q, mntn, (5, 10))BehindCurvewrtRiskyP ath(q, mntn, path)BehindCurvewrtRiskyP ath(q, mntn, rskyprtn1 )BehindCurvewrtRiskyP ath(q, mntn, rskyprtn2 )BehindCurvewrtRiskyP athDistance(q, mntn, rskyprtn1 , 20)BehindCurvewrtRiskyP athDistance(q, mntn, rskyprtn2 , 20)SPS0.110.30.2750.28.0410.926.166.3CAD0.110.480.71102.8811.8917.4816.0815.336. DiscussionSpatial problem solving area active research since Sutherlands sketchpad(1963). need access, communicate manipulate spatial information precisely(much engineers scientists do) using high-level language (much common peopleuse) one frontiers AI. well-known capabilitiesoered rst-order predicate logic that, rst-order logic generally intractableexcept limited domains. umbrella Qualitative Spatial Reasoning (QSR),researchers investigated plethora spatial calculi, prominentmereotopological calculi (Clarke, 1981; Bennett, 1997), cardinal direction calculus (Frank,1991, 1992; Skiadopoulos & Koubarakis, 2004), double cross calculus (Freksa, 1992), 4and 9-intersection calculi (Egenhofer, 1991; Egenhofer & Franzosa, 1991), ip-op calculus(Ligozat, 1993), dipole calculus (Moratz, Renz, & Wolter, 2000; Schlieder, 1995; Dylla &Moratz, 2005), various region connection calculi (Randell et al., 1992; Bennett, Isli,& Cohn, 1997; Gerevini & Nebel, 2002; Cohn, Bennett, Gooday, & Gotts, 1997; Duntsch,Wang, & McCloskey, 1999; Gerevini & Renz, 1998). two main points distinctionQSR approach spatial problem solving reported paper.1. dierent QSR calculi emphasize dierent aspects space, as, ontological issues, topology, distance, orientation, shape, etc. Depending spatial aspect interest, calculus based minimal set spatial relations.example, 9-intersection calculus (Egenhofer & Franzosa, 1991)based nine spatial relations {r0 , r1 , r3 , r6 , r7 , r10 , r11 , r14 , r15 } two spatial regions, double cross calculus (Freksa, 1992) based fteen spatial relations{lf, lp, lc, ll, lb, sf, sp, sc, sl, sb, rf, rp, rc, rl, rb} among three points, etc. frameworkbased minimal set spatial relations; based xed set mathematical/logical operators (see section 2.3). spatial relation among pointsexpressed using real variables xed set operators rst-order logic includedvocabulary. spatial relation involving curves and/or regions expressed420fiExecuting Perceptions Actions Diagrammatic Reasoningrst-order logic using spatial relations among points relations Insideincluded vocabulary.2. spatial problems interest QSR community CSPs involving eitherpoints (e.g., double cross calculus) regions (e.g., 4- 9-intersection calculi, regionconnection calculi) closed set properties/relations often limited binarydomain. general-purpose SPS helping human perceive act diagramsdierent real-world applications need solve QCSPs involving points, curvesregions open-ended vocabulary properties/relations/actions entirereal domain, framework oers. Since QE computational bottleneckSPS, concentrate eorts real QE algorithms, discussed towardsend section 2.3.Naturally, question arises convenient human specify spatialproblem QCSP? acknowledge process specifying spatial problemQCSP eortless explaining another human natural language,taken rst step making process less strenuous oering vocabularypredicates open-ended. QCSP-solving systems, as, redlog (Dolzmann& Sturm, 1999) qepcad (Brown, 2003), oer vocabulary spatial problemsolving makes dicult user specify problem dig deepocean equations inequalities cannot communicate naturally terms high-levelpredicates.4 still far building systems understand communicationnatural language. However, research automatic constraint acquisition examplesalready underway. Vu OSullivan (2008) discuss recent advances direction.use ideas results work, dicult seeideas conjunction work reported paper able buildconvenient ecient spatial problem solving framework.7. ConclusionDR requires perceiving specied information diagram modifying/creating objectsdiagram specied ways according problem solving needs. number DR systemsbuilt last couple decades, developers ascertainedpriori hand-coded required perceptions actions. approach buildingDR systems defeats purpose open-ended exploration essence human-likeproblem solving. goal, paper, develop general ecient frameworkexecuting perceptions actions relevant reasoning 2D diagrams acrosswide variety domains tasks. make two important contributions:1. observe wide variety visual perceptions/actions DR applicationstransformed domain/task-independent spatial problems. observation makespossible use well-established constraint satisfaction framework spatial problemsolving. developed language specify spatial problems QCSPsreal domain using open-ended vocabulary properties, relations actions involvingthree kinds diagrammatic objects points, curves, regions. Solution spatial problemequivalent simplied quantier-free expression. reduces goal developinggeneral ecient SPS solving 2D spatial problems without human intervention.4. fair, redlog qepcad developed solving spatial problems QCSP.421fiBanerjee & Chandrasekaran2. spatial problems specied QCSPs rst-order logic. QE, inherentlydoubly exponential problem, computational bottleneck SPS. representedobjects (points, curves, regions) conguration simple elements facilitate decomposition complex problems simpler similar subproblems. showed that,symbolic solution subproblem expressed concisely, QE achievedlow-order polynomial time storing problems solutions memorysimilar problem encountered future, solved mapping solutionsimilar previously solved problem. SPS grows ecient solves problems.Even though used CAD algorithm QE compared complexity resultsCADs, approach means limited particular algorithm. complexity QE algorithm signicantly improved spatial problem solvingusing idea problem decomposition variable mapping, discussed paper.framework leaves room ecient convenient incorporating futureresults least two possible directions learning constraints examples (automaticconstraint acquisition) carefully exploiting rich portfolio QE algorithms solvingnew problems.Acknowledgmentsresearch partially supported participation Advanced Decision Architectures Collaborative Technology Alliance sponsored U.S. Army Research LaboratoryCooperative Agreement DAAD19-01-2-0009. thank anonymous reviewersconstructive comments.ReferencesAho, A. V., Hopcroft, J. E., & Ullman, J. D. (1974). Design Analysis ComputerAlgorithms. Addison-Wesley.Allwein, G., & Barwise, J. (1999). Logical reasoning diagrams. Journal Logic,Language Information, 8 (3), 387390.Anderson, J. R. (1993). Rules Mind. Lawrence Erlbaum Associates, Hillsdale, NJ.Banerjee, B., & Chandrasekaran, B. (2004). Perceptual action routines diagrammaticreasoning entity re-identication. Proc. 24th Army Science Conf., Orlando, FL.Banerjee, B., & Chandrasekaran, B. (2007). constraint satisfaction framework visualproblem solving. Benhamou, F., Jussien, N., & OSullivan, B. (Eds.), TrendsConstraint Programming, chap. 26, pp. 383393. ISTE, London.Banerjee, B., & Chandrasekaran, B. (2010). spatial search framework executingperceptions actions diagrammatic reasoning. Goel, A. K., Jamnik, M., &Narayanan, N. H. (Eds.), Diagrammatic Representation Inference, Lecture NotesAI, Vol. 6170, pp. 144159. Springer, Heidelberg.Barwise, J., & Etchemendy, J. (1998). computational architecture heterogeneousreasoning. Gilboa, I. (Ed.), Proc. 7th Conf. Theoretical Aspects RationalityKnowledge, pp. 127. Morgan Kaufmann.422fiExecuting Perceptions Actions Diagrammatic ReasoningBasu, S., Pollack, R., & Roy, M.-F. (2003). Algorithms real algebraic geometry. SpringerVerlag.Bennett, B. (1997). Logical Representations Automated Reasoning Spatial Relationships. Ph.D. thesis, School Computer Studies, University Leeds.Bennett, B., Isli, A., & Cohn, A. G. (1997). composition table providecomplete tractable proof procedure relational constraint language?. Proc.IJCAI Workshop Spatial Temporal Reasoning, Nagoya, Japan.Brown, C. W. (2003). QEPCAD B: program computing semi-algebraic sets usingcylindrical algebraic decomposition. ACM SIGSAM Bulletin, 37 (4), 97108.Brown, C. W., & Davenport, J. H. (2007). complexity quantier eliminationcylindrical algebraic decomposition. Proc. Intl. Symp. Symbolic Algebraic Computation, pp. 5460. ACM, NY.Chandrasekaran, B., Josephson, J. R., Banerjee, B., Kurup, U., & Winkler, R. (2002).Diagrammatic reasoning support situation understanding planning. Proc.23rd Army Science Conf., Orlando, FL.Chandrasekaran, B., Kurup, U., & Banerjee, B. (2005). diagrammatic reasoning architecture: Design, implementation experiments. Proc. AAAI Spring Symp.,Reasoning Mental External Diagrams: Computational Modeling SpatialAssistance, pp. 108113, Stanford University, CA.Chandrasekaran, B., Kurup, U., Banerjee, B., Josephson, J. R., & Winkler, R. (2004).architecture problem solving diagrams. Blackwell, A., Marriott, K., &Shimojima, A. (Eds.), Lecture Notes AI, Vol. 2980, pp. 151165. Springer-Verlag.Chazelle, B. (1991). Triangulating simple polygon linear time. Discrete Computational Geometry, 6, 485524.Clarke, B. L. (1981). calculus individuals based connection. Notre Dame JournalFormal Logic, 22, 204218.Cohn, A. G., Bennett, B., Gooday, J. M., & Gotts, N. (1997). RCC: calculus regionbased qualitative spatial reasoning. GeoInformatica, 1, 275316.Collins, G. E., & Hong, H. (1991). Partial cylindrical algebraic decomposition quantierelimination. Journal Symbolic Computation, 12 (3), 299328.Davenport, J. H., & Heintz, J. (1988). Real quantier elimination doubly exponential.Journal Symbolic Computation, 5 (1-2), 2935.Dershowitz, N., & Jouannaud, J. P. (1990). Rewrite systems. Handbook TheoreticalComputer Science, Vol. B, chap. 6, pp. 243320. Elsevier, North Holland: Amsterdam.Dolzmann, A., & Sturm, T. (1999). REDLOG user manual, edition 2.0 version 2.0.Tech. rep. MIP-9905, FMI, Universitt Passau, Passau, Germany.Dolzmann, A., Sturm, T., & Weispfenning, V. (1998). Real quantier elimination practice.Matzat, B. H., Greuel, G.-M., & Hiss, G. (Eds.), Algorithmic Algebra NumberTheory, pp. 221247. Springer, Berlin.423fiBanerjee & ChandrasekaranDuntsch, I., Wang, H., & McCloskey, S. (1999). Relation algebras qualitative spatialreasoning. Fundamenta Informaticae, 39 (3), 229249.Dylla, F., & Moratz, R. (2005). Exploiting qualitative spatial neighborhoods situationcalculus. Freksa, C., Knau, M., Krieg-Brckner, B., Nebel, B., & Barkowsky, T.(Eds.), Spatial Cognition IV. Reasoning, Action, Interaction, Vol. 3343 LectureNotes Computer Science, pp. 304322. Springer.Egenhofer, M. J. (1991). Reasoning binary topological relations. Gunther, O.,& Schek, H.-J. (Eds.), Proc. 2nd Symp. Large Spatial Databases, Vol. 525 LectureNotes Computer Science, pp. 143160. Springer.Egenhofer, M. J., & Franzosa, R. D. (1991). Point set topological relations. Intl. JournalGeographical Information Systems, 5, 161174.Ferguson, R. W. (1994). MAGI: Analogy-based encoding using symmetry regularity.Proc. 16th Annual Conf. Cognitive Science Society, pp. 283288, Atlanta, GA.Ferguson, R. W., & Forbus, K. D. (1998). Telling juxtapositions: Using repetitionalignable dierence diagram understanding. Holyoak, K., Gentner, D., & Kokinov, B. (Eds.), Advances Analogy Research, pp. 109117. Soa, New BulgarianUniversity.Ferguson, R. W., & Forbus, K. D. (2000). GEOREP: exible tool spatial representationline drawings. Proc. 18th Natl. Conf. AI, pp. 510516, Austin, TX.Forbus, K. D., Usher, J., & Chapman, V. (2003). Qualitative spatial reasoning sketchmaps. Riedl, J., & Hill, R. (Eds.), Proc. 15th Annual Conf. Innovative ApplicationsAI, pp. 8592, Acapulco, Mexico. AAAI Press, Menlo Park, CA. ISBN 978-1-57735188-7.Frank, A. U. (1991). Qualitative spatial reasoning cardinal directions. Kaindl, H.(Ed.), Proc. 7th Austrian Conf. AI, Vol. 287 Informatik-Fachberichte, pp. 157167.Springer.Frank, A. U. (1992). Qualitative spatial reasoning distances directions geographic space. Journal Visual Languages Computing, 3, 343371.Freksa, C. (1992). Using orientation information qualitative spatial reasoning. Frank,A. U., Campari, I., & Formentini, U. (Eds.), Spatio-Temporal Reasoning, Vol. 639Lecture Notes Computer Science, pp. 162178. Springer.Gebruers, C., Hnich, B., Bridge, D., & Freuder, E. (2005). Using CBR select solutionstrategies constraint programming. Proc. 6th Intl. Conf. Case-based Reasoning,pp. 222236. Springer.Gerevini, A., & Nebel, B. (2002). Qualitative spatio-temporal reasoning rcc-8allens interval calculus: Computational complexity. Proc. 15th European Conf. AI,pp. 312316. IOS Press.Gerevini, A., & Renz, J. (1998). Combining topological qualitative size constraintsspatial reasoning. Proc. 4th Intl. Conf. Principles Practice ConstraintProgramming, pp. 220234. Springer.424fiExecuting Perceptions Actions Diagrammatic ReasoningGlasgow, J., Narayanan, N. H., & Chandrasekaran, B. (1995). Diagrammatic Reasoning:Cognitive Computational Perspectives. AAAI Press.Goldberg, E., & Novikov, Y. (2003). complexity equivalence checking. Tech. rep.CDNL-TR-2003-0826, Cadence Berkeley Labs, CA.Jamnik, M. (2001). Mathematical Reasoning Diagrams: Intuition Automation.CSLI Press, Stanford University, CA.Josephson, J. R., & Josephson, S. G. (1996). Abductive Inference: Computation, Philosophy,Technology. Cambridge University Press, Cambridge, MA.Kurup, U., & Chandrasekaran, B. (2007). bimodal cognitive architecture: Explorationsarchitectural explanation spatial reasoning. AAAI Spring Symp. Control Mechanisms Spatial Knowledge Processing Cognitive/Intelligent Systems, StanfordUniversity, CA.Laird, J. E., Newell, A., & Rosenbloom, P. S. (1987). SOAR: architecture generalintelligence. Artificial Intelligence, 33, 164.Laird, J. E., Rosenbloom, P. S., & Newell, A. (1986). Universal Subgoaling Chunking.Kluwer Academic Publishers.Lasaruk, A., & Sturm, T. (2006). Weak quantier elimination full linear theoryintegers. uniform generalization Presburger arithmetic. Technical reportMIP-0604, FMI, Universitt Passau, Germany.Leyton-Brown, K., Nudelman, E., & Shoham, Y. (2002). Learning empirical hardnessoptimization problems: case combinatorial auctions. Proc. 8th Intl. Conf.Principles Practice Constraint Programming, pp. 556572.Ligozat, G. (1993). Qualitative triangulation spatial reasoning. Frank, A. U., &Campari, I. (Eds.), Spatial Information Theory: Theoretical Basis GIS, Vol. 716Lecture Notes Computer Science, pp. 5468. Springer.Lindsay, R. K. (1998). Using diagrams understand geometry. Computational Intelligence,14 (2), 238272.Moratz, R., Renz, J., & Wolter, D. (2000). Qualitative spatial reasoning line segments.Proc. 14th European Conf. AI, pp. 234238. IOS Press.Nelson, R. B. (1993). Proofs without Words: Exercises Visual Thinking. Mathematical Association America, Washington, DC.Newell, A. (1990). Unified Theories Cognition. Harvard University Press, Cambridge,MA.OMahony, E., Hebrard, E., Holland, A., Nugent, C., & OSullivan, B. (2008). Using casebased reasoning algorithm portfolio constraint solving. van Dongen, M.R. C., Lecoutre, C., & Roussel, O. (Eds.), Proc. 3rd Intl. CSP Solver Competition,pp. 5362.Pisan, Y. (1994). Visual reasoning graphs. 8th Intl. Workshop Qualitative ReasoningPhysical Systems, Nara, Japan.425fiBanerjee & ChandrasekaranPisan, Y. (1995). visual routines based model graph understanding. Proc. 17thAnnual Conf. Cognitive Science Society, pp. 692697, Pittsburgh. Lawrence ErlbaumAssociates. ISBN: 0-8058-2159-7.Pulina, L., & Tacchella, A. (2007). multi-engine solver quantied boolean formulas.Proc. 13th Intl. Conf. Principles Practice Constraint Programming, pp.574589.Randell, D. A., Cui, Z., & Cohn, A. G. (1992). spatial logic based regions connection. Nebel, B., Swartout, W., & Rich, C. (Eds.), Proc. 3rd Intl. Conf. PrinciplesKnowledge Representation Reasoning, pp. 165176. Morgan Kaufmann.Ratschan, S. (2006). Ecient solving quantied inequality constraints realnumbers. ACM Trans. Computational Logic, 7 (4), 723748.Sayag, T., Fine, S., & Mansour, Y. (2006). Combining multiple heuristics. Proc. 23rdIntl. Symp. Theoretical Aspects Computer Science, Vol. 2884 Lecture NotesComputer Science, pp. 242253. Springer.Schlieder, C. (1995). Reasoning ordering. Frank, A. U., & Kuhn, W. (Eds.),Spatial Information Theory: Theoretical Basis GIS, Vol. 988 Lecture NotesComputer Science, pp. 341349. Springer.Seidel, R. (1991). simple fast incremental randomized algorithm computingtrapezoidal decompositions triangulating polygons. Computational Geometry:Theory Applications, 1 (1), 5164.Skiadopoulos, S., & Koubarakis, M. (2004). Composing cardinal direction relations. Artificial Intelligence, 152 (2), 143171.Streeter, M. J., Golovin, D., & Smith, S. F. (2007). Combining multiple heuristics online.Proc. 22nd Conf. AI, pp. 11971203. AAAI Press.Sutherland, I. E. (1963). Sketchpad: man-machine graphical communication system.Proc. Spring Joint Computer Conf., pp. 329346.Tessler, S., Iwasaki, Y., & Law, K. (1995). Qualitative structural analysis using diagrammatic reasoning. Glasgow, J., Narayanan, N. H., & Chandrasekaran, B. (Eds.),Diagrammatic Reasoning: Cognitive Computational Perspectives, chap. 21, pp.711730. AAAI Press, Menlo Park, CA. ISBN 0-262-57112-9.Tricket, S. B., & Trafton, J. G. (2006). Toward comprehensive model graph comprehension: Making case spatial cognition. Barker-Plummer, D., Cox, R., &Swoboda, N. (Eds.), Lecture Notes AI, Vol. 4045, pp. 286300. Berlin: SpringerVerlag.Tversky, B. (2000). ways maps diagrams communicate. Freksa, C.,Brauer, W., Habel, C., & Wender, K. F. (Eds.), Spatial Cognition II: IntegratingAbstract Theories, Empirical Studies, Formal Methods, Practical Applications,Vol. 1849 Lecture Notes Computer Science, pp. 7279. Berlin: Springer-Verlag.Vik, S. (2001). implementation near-linear polygon triangulation algorithmgeneral polygons. Senior thesis Macalester College, St. Paul, Minnesota. Availableonline http://sigbjorn.vik.name/projects/Triangulation.pdf.426fiExecuting Perceptions Actions Diagrammatic ReasoningVu, X. H., & OSullivan, B. (2008). unifying framework generalized constraint acquisition. Intl. Journal AI Tools, 17 (5), 803833.Weispfenning, V. (1988). complexity linear problems elds. Journal SymbolicComputation, 5 (12), 327.Weispfenning, V. (2001). Semilinear motion planning REDLOG. Applicable AlgebraEngineering, Communication Computing, 12, 455475.Wolfram, S. (2003).Mathematica Book (5th edition).http://documents.wolfram.com/.Available onlineXu, L., Hutter, F., Hoos, H. H., & Leyton-Brown, K. (2008). SATzilla: Portfolio-basedalgorithm selection SAT. Journal Artificial Intelligence Research, 32, 565606.427fiJournal Artificial Intelligence Research 39 (2010) 127177Submitted 11/09; published 09/10LAMA Planner:Guiding Cost-Based Anytime Planning LandmarksSilvia Richtersilvia.richter@nicta.com.auIIIS, Griffith University, AustraliaNICTA QRL, AustraliaMatthias Westphalwestpham@informatik.uni-freiburg.deAlbert-Ludwigs-Universitat FreiburgInstitut fur InformatikFreiburg, GermanyAbstractLAMA classical planning system based heuristic forward search. core featureuse pseudo-heuristic derived landmarks, propositional formulas must trueevery solution planning task. LAMA builds Fast Downward planning system, usingfinite-domain rather binary state variables multi-heuristic search. latter employedcombine landmark heuristic variant well-known FF heuristic. heuristicscost-sensitive, focusing high-quality solutions case actions non-uniform cost.weighted search used iteratively decreasing weights, planner continuessearch plans better quality search terminated.LAMA showed best performance among planners sequential satisficing trackInternational Planning Competition 2008. paper present system detail investigate features LAMA crucial performance. present individual resultsdomains used competition, demonstrating good bad cases techniquesimplemented LAMA. Overall, find using landmarks improves performance, whereasincorporation action costs heuristic estimators proves beneficial. showdomains search ignores cost solves far problems, raising questiondeal action costs effectively future. iterated weighted search greatlyimproves results, shows synergy effects use landmarks.1. Introductionlast decade, heuristic search become dominant approach domain-independent satisficing planning. Starting additive heuristic Bonet Geffner (2001), implementedHSP planning system, much research conducted search heuristic estimatorsefficient calculate yet powerful guiding search towards goal state. FF planning system Hoffmann Nebel (2001), using heuristic estimator based relaxed planninggraphs, broke ground showing best performance among fully automated systems International Planning Competition 2000, continues state art today. Ever since,heuristic-search approaches played prominent role classical sequential satisficingtracks biennial competition, Fast Downward (Helmert, 2006) winning 2004 SGPlan (Chen, Wah, & Hsu, 2006) placing first 2006.LAMA planning system youngest member line, winning sequential satisficing track International Planning Competition (IPC) 2008. LAMA classical planningc2010AI Access Foundation. rights reserved.fiRichter & Westphalsystem based heuristic search. follows footsteps HSP, FF, Fast Downwarduses earlier work many respects. particular, builds Fast Downward extendingthree major ways:1. Landmarks. LAMA, Fast Downwards causal graph heuristic replaced variantFF heuristic (Hoffmann & Nebel, 2001) heuristic estimates derived landmarks.Landmarks propositional formulas become true point every plantask hand (Porteous, Sebastia, & Hoffmann, 2001). LAMA uses landmarksdirect search towards states many landmarks already achieved. Viapreferred operators, landmarks also used additional source search controlcomplements heuristic estimates. recent work, shown use landmarksaddition FF heuristic improve performance, leading problemssolved shorter solution paths (Richter, Helmert, & Westphal, 2008).2. Action costs. landmark heuristic proposed earlier (Richter et al., 2008)FF heuristic adapted use action costs. However, LAMA focus purelycost-to-go, i. e., estimated cost reaching goal given search node.danger cost-sensitive planner may concentrate much finding cheap plan,expense finding plan within given time limit. LAMA weighs estimatedcost-to-go (as measure plan quality) estimated goal distance (as measureremaining search effort) combining values two estimates.3. Anytime search. LAMA continues search better solutions exhaustedsearch space interrupted. finding initial solution greedy best-first search,conducts series weighted searches decreasing weights, restarting searchtime initial state improved solution found. recent work,shown approach efficient planning benchmarks compared anytimemethods (Richter, Thayer, & Ruml, 2010).International Planning Competition 2008, LAMA outperformed competitorssubstantial margin. result expected authors, previous work concerningLAMAs putative core feature, landmark heuristic (Richter et al., 2008), showed some,tremendous improvement base configuration without landmarks. paper aimsprovide reference description LAMA well extensive evaluation performancecompetition.Detailed description LAMA. present distinguishing components plannerdetail, describing landmarks generated used LAMA, action costsincorporated heuristic estimators anytime search proceeds. aspects LAMA presented previous publications (Richter et al., 2008, 2010;Helmert, 2006). However, aspects adequately covered publications, particular procedure finding landmarks, described detail.relevant aspects described previous work, like landmark heuristic, summarisedconvenience reader. aim paper, together previous ones, formcomprehensive picture LAMA system.Experimental evaluation LAMA. Building this, conduct experimental evaluation focusing aspects differentiate LAMA predecessor systems like FF128fiThe LAMA Planner: Guiding Cost-Based Anytime Planning LandmarksFast Downward. repeat comparisons published earlier work, like comparisonLAMAs anytime method anytime algorithms (Richter et al., 2010),comparison LAMAs methods handling landmarks alternative landmark approaches(Richter et al., 2008). Instead, aim elicit much performance LAMAsystem whole enhanced three distinguishing features described(landmarks, action costs anytime search). answer question, contrast severalvariations planner using various subsets features.find using cost-sensitive heuristics pay IPC 2008 benchmark tasks.results show cost-sensitive variant FF heuristic used LAMA performs significantly worse traditional unit-cost version heuristic. Similarly,cost-sensitive planners competition fared worse baseline planner FF ignored action costs, demonstrating cost-based planning presents considerable challenge.conduct full analysis reasons this, showcase problems cost-sensitive FFheuristic example domains provide informed hypotheses encountered effects.Landmarks prove particularly helpful context. unit-cost case landmarkslead moderate increase performance, case planning action costssubstantially improve coverage (the number problems solved), thus effectively mitigatingproblems cost-sensitive FF heuristic LAMA. anytime search significantly improvesquality solutions throughout even acts synergy landmarks one domain.2. Preliminariesuse planning formalism state variables finite (rather binary) range, similarone employed Helmert (2009). based SAS+ planning model (Backstrom & Nebel,1995), extends conditional effects. LAMA also handles axioms wayFast Downward (Helmert, 2006), formalise axioms here, since importantpurposes.Definition 1. Planning tasks finite-domain representation (FDR tasks)planning task finite-domain representation (FDR task) given 5-tuple hV, s0 , s? , O, Cifollowing components:V finite set state variables, associated finite domain Dv .fact pair hv, di (also written v 7 d), v V Dv . partial variableassignment set facts, different variable. (We use set notationhv, di function notation s(v) = interchangeably.) state variableassignment defined variables V.s0 state called initial state.s? partial variable assignment called goal.finite set operators. operator hpre, effi consists partial variable assignmentpre called precondition, finite set effects eff. Effects triplets hcond, v, di,cond (possibly empty) partial variable assignment called effect condition, vaffected variable Dv called new value v.129fiRichter & WestphalC : N+0 integer-valued non-negative action cost function.operator = hpre, effi applicable state pre s, effects consistent,i. e., state s0 s0 (v) = hcond, v, di eff cond s, s0 (v) = s(v)otherwise. case, say operator applied resulting state s0write s[o] s0 .operator sequences = ho1 , . . . , i, write s[] s[o1 ] . . . [on ] (only defined operator applicable respective state). operator sequence called plan s? s0 [].Pcost sum action costs operators, ni=1 C(oi ).state variable v planning task finite-domain representation associated directedgraph called domain transition graph, captures ways value v maychange (Jonsson & Backstrom, 1998; Helmert, 2006). vertex set graph Dv ,contains arc two nodes d0 exists operator change valuev d0 . Formally:Definition 2. Domain transition graphdomain transition graph (DTG) state variable v V FDR task hV, s0 , s? , O, Cidigraph hDv , Ai includes arc hd, d0 iff , d0 , operator hpre, effihcond, v, d0 eff, union conditions pre cond holds either contains v =contain v = Dv .3. System ArchitectureLAMA builds Fast Downward system (Helmert, 2006), inheriting overall structurelarge parts functionality planner. Like Fast Downward, LAMA accepts inputPDDL2.2 Level 1 format (Fox & Long, 2003; Edelkamp & Hoffmann, 2004), including ADLconditions effects derived predicates (axioms). Furthermore, LAMA extendedhandle action costs introduced IPC 2008 (Helmert, Do, & Refanidis, 2008). Like FastDownward, LAMA consists three separate components:translation moduleknowledge compilation modulesearch modulecomponents implemented separate programs invoked sequence.following, provide brief description translation knowledge compilation modules.main changes LAMA, compared Fast Downward, implemented search module,discuss detail.3.1 Translationtranslation module, short translator, transforms PDDL input planning task finitedomain representation specified Definition 1. main components translatorefficient grounding algorithm instantiating schematic operators axioms, invariant130fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarkssynthesis algorithm determining groups mutually exclusive facts. fact groups consequently replaced single state variable, encoding fact (if any) group satisfiedgiven world state. Details component found recent article Helmert (2009).groups mutually exclusive facts (mutexes) found translation later useddetermine orderings landmarks. reason, LAMA use finite-domainrepresentations offered IPC 2008 (object fluents), instead performs translationbinary finite-domain variables. mutexes computed translation moduleneeded new encoding planning task, module extended LAMA retainfound mutexes later use landmarks.changes made, compared translation module described Helmert,add capability handling action costs, implement extension concerning parsingcomplex operator effect formulas, limit runtime invariant synthesis algorithm.invariant synthesis may time critical, particular large (grounded) PDDL input, limitmaximum number considered mutex candidates algorithm, abort it, necessary,five minutes. Note finding mutexes change way translation moduleworks; mutexes found, resulting encoding planning task contains simply(binary-domain) state variables PDDL input. analysing competition results,found synthesis algorithm aborted tasks one domain (CyberSecurity).3.2 Knowledge CompilationUsing finite-domain representation generated translator, knowledge compilation module responsible building number data structures play central role subsequentlandmark generation search. Firstly, domain transition graphs (see Definition 2) producedencode ways state variable may change value operator applications axioms. Furthermore, data structures constructed efficiently determining setapplicable operators state evaluating values derived state variables. referHelmert (2006) detail knowledge compilation component, LAMA inheritsunchanged Fast Downward.3.3 Searchsearch module responsible actual planning. Two algorithms heuristic searchimplemented LAMA: (a) greedy best-first search, aimed finding solution quicklypossible, (b) weighted search allows balancing speed solution quality.algorithms variations standard textbook methods, using open closed lists. greedybest-first search always expands state minimal heuristic value h among open statesnever expands state once. order encourage cost-efficient plans without incurringmuch overhead, breaks ties equally promising states preferring statesreached cheaper operators, i. e., taking account last operator path consideredstate search space. (The cost entire path could used expense increasedtime space requirements, consider this.) Weighted search (Pohl, 1970)associates costs states expands state minimal f 0 -value, f 0 = w h + g,weight w integer 1, g best known cost reaching considered state131fiRichter & Westphalinitial state. contrast greedy search, weighted search re-expands states whenever findscheaper paths them.addition, search algorithms use three types search enhancements inherited FastDownward (Helmert, 2006; Richter & Helmert, 2009). Firstly, multiple heuristics employedwithin multi-queue approach guide search. Secondly, preferred operators similarhelpful actions FF allow giving precedence operators deemed helpfulothers state. Thirdly, deferred heuristic evaluation mitigates impact large branchingfactors assuming heuristic estimates fairly accurate. following, discusstechniques resulting algorithms detail give pseudo code greedy best-firstsearch. weighted search similar, point differences twoalgorithms along way.Multi-queue heuristic search. LAMA uses two heuristic functions guide search: namegiving landmark heuristic (see Section 5), variant well-known FF heuristic (see Section 6). two heuristics used separate queues, thus exploiting strengths utilisedheuristics orthogonal way (Helmert, 2006; Roger & Helmert, 2010). end, separateopen lists maintained two heuristics. States always evaluated respectheuristics, successors added open lists (in case value corresponding heuristic open list). choosing state evaluate expand next,search algorithm alternates different queues based numerical priorities assignedqueue. priorities discussed later.Deferred heuristic evaluation. use deferred heuristic evaluation means statesheuristically evaluated upon generation, upon expansion, i. e., states generatedgreedy best-first search, put open list heuristic value,parent. removed open list evaluated heuristically,heuristic estimate turn used successors. use deferred evaluationweighted search analogous, using f 0 instead h sorting criterion open lists.many states generated expanded, deferred evaluation leads substantial reduction number heuristic estimates computed. However, deferred evaluation incurs lossheuristic accuracy, search longer use h-values f 0 -values differentiatesuccessors state (all successors associated parents value open list). Preferredoperators helpful context provide alternative way determine promisingsuccessors.Preferred operators. Operators deemed particularly useful given state markedpreferred. computed heuristic estimators along heuristic valuestate (see Sections 6 5). use preferred operators, greedy best-first search wellweighted search, planner maintains additional preferred-operator queueheuristic. state evaluated expanded, successor states reached viapreferred operator (the preferred states) put preferred-operator queues, additionput regular queues like non-preferred states. (Analogously regular states,state preferred least one heuristic added preferred-operator queues. allowscross-fertilisation information exchange different heuristics.) Statespreferred-operator queues evaluated earlier average, form part queueshigher chance selected point time non-preferred states. addition,132fiThe LAMA Planner: Guiding Cost-Based Anytime Planning LandmarksLAMA (like IPC 2004 version Fast Downward) gives even higher precedence preferredsuccessors via following mechanism. planner keeps priority counter queue,initialised 0. iteration, next state removed queue highestpriority. Whenever state removed queue, priority queue decreased 1.priorities changed outside routine, method alternate queues,thus expanding states preferred queues regular queues equally often. increase usepreferred operators, LAMA increases priorities preferred-operator queues largenumber boost value 1000 whenever progress made, i. e., whenever state discoveredbetter heuristic estimate previously expanded states. Subsequently, next 1000 statesremoved preferred-operator queues. another improving state found within 1000states, boosts accumulate and, accordingly, takes longer states regular queuesexpanded again.Alternative methods using preferred operators include one employed YAHSPsystem (Vidal, 2004), preferred operators always used non-preferred ones. contrast, scheme necessarily empty preferred queues switching back regularqueues. FF planner (Hoffmann & Nebel, 2001), emphasis preferred operators evenstronger YAHPS: search FF restricted preferred operators either goalfound restricted search space exhausted (in case new search started without preferred operators). Compared approaches, method using preferred operatorsLAMA, conjunction deferred heuristic evaluation, shown result substantialperformance improvement deliver best results classical setting operators unit costs(Richter & Helmert, 2009). choice 1000 boost value critical here, foundvarious values 100 50000 give similarly good results. outside rangeperformance drop noticeably.Note using action costs, use preferred operators may even helpfulclassical setting. example, operators cost 0, heuristic using purecost estimates might assign heuristic value 0 states state space, givingguidance search all. Preferred operators, however, still provide heuristic guidancecase case unit action costs. extreme example, similar casesappear practice, e. g. IPC 2008 domain Openstacks, operators except oneopening new stack associated cost 0.Pseudo code. Algorithm 1 shows pseudo code greedy best-first search. main loop(lines 2536) runs either goal found (lines 2729) search spaceexhausted (lines 3233). closed list contains seen states also keeps track linksstates parents, plan efficiently extracted goal statefound (line 28). iteration loop, search adds current state (initiallystart state) closed list processes (lines 3031), unless state processedbefore, case ignored (line 26). contrast, weighted search processes stateswhenever reached via path lower cost before, updates parent linksclosed list accordingly. search selects next open list used (the onehighest priority, line 34), decreases priority extracts next state processed (lines3536). processing state includes calculating heuristic values preferred operatorsheuristics (lines 34), expanding it, inserting successors appropriate open133fiRichter & WestphalGlobal variables:= hV, s0 , s? , O, CiregFF , pref FF , regLM , pref LMbest seen valuepriority1:2:3:4:5:6:7:8:9:10:11:12:13:14:15:16:17:18:19:20:21:22:23:24:25:26:27:28:29:30:31:32:33:34:35:36:. Planning task solve. Regular preferred open lists heuristic. Best heuristic value seen far heuristic. Numerical priority queuefunction expand state(s)progress Falseh {FF, LM}h(s), preferred ops(h, s) heuristic value preferred operators given hh(s) < best seen value[h]progress Truebest seen value[h] h(s)progress. Boost preferred-operator queuespriority[pref FF ] priority[pref FF ] + 1000priority[pref LM ] priority[pref LM ] + 1000succesor states { s[o] | applicable }s0 succesor statesh {FF, LM}add s0 queue regh value h(s). Deferred evaluation0reached operator preferred ops(h, s)add s0 queue pref FF value FF(s), queue pref LM value LM(s)function greedy bfs lamaclosed listh {FF, LM}. Initialize FF landmark heuristicsbest seen value[h]l {reg, pref }. Regular preferred open lists heuristiclhpriority[lh ] 0current state s0loopcurrent state < closed list= s?extract plan tracing current state back initial state closed listreturnclosed list closed list {current state}expand state(current state)queues emptyreturn failure. plan existsq non-empty queue highest prioritypriority[q] priority[q] 1. Get lowest-valued state queue qcurrent state pop state(q)Algorithm 1: greedy best-first-search search enhancements used LAMA.134fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarkslists (lines 1116). determined new best state found (lines 5-7), preferredoperator queues boosted 1000 (lines 8-10).3.3.1 Restarting Anytime SearchLAMA developed International Planning Competition 2008 tailored conditions competition several ways. detail, conditions follows.previous competitions coverage, plan quality runtime used varying degrees orderdetermine effectiveness classical planning system, IPC 2008 introduced new integratedperformance criterion. operator PDDL input associated non-negative integeraction cost, aim find plan lowest-possible total cost within given time limit30 minutes per task. Given planner solves task within time limit, newperformance measure depends plan quality, runtime, thus suggests guidingsearch towards cheapest goal rather closest goal well using available timefind best plan possible.Guiding search towards cheap goals may achieved two ways, LAMAimplements: firstly, heuristics estimate cost-to-go, i. e., cost reaching goalgiven state, rather distance-to-go, i. e., number operators required reachgoal. landmark heuristic FF heuristic employed LAMA therefore capableusing action costs. Secondly, search algorithm take cost-to-go givenstate account, also cost necessary reaching state. case weightedsearch used LAMA. make available time, LAMA employs anytimeapproach: first runs greedy best-first search, aimed finding solution quickly possible.plan found, searches progressively better solutions running series weightedsearches decreasing weight. cost best known solution used pruningsearch, decreasing weight time makes search progressively less greedy, tradingspeed solution quality.Several anytime algorithms based weighted proposed (Hansen & Zhou, 2007;Likhachev, Ferguson, Gordon, Stentz, & Thrun, 2008). underlying idea continueweighted search past first solution, possibly adjusting search parameters like weightpruning bound, thus progressively find better solutions. anytime approach used LAMAdiffers existing algorithms continue weighted searchfinds solution. Instead, start new weighted search, i. e., discard open listsprevious search re-start initial state. resulting duplicate effort,restarts help overcome bad decisions made early (comparatively greedy) search iterationshigh weight (Richter et al., 2010). explained follows: finding goal statesg , open lists usually contain many states close sg search space,ancestors sg expanded; furthermore, states likely low heuristic valuesproximity sg . Hence, search continued (even updating openlists lower weights), likely expand states around sg considering statesclose initial state. critical, means search concentratingimproving end current plan, opposed beginning. bad beginning plan,however, may severe negative influence quality, may impossible improvequality plan substantially without changing early operators.135fiRichter & Westphal3.810.63.49.82.68.21.87.61.07.01.08.03.89.63.48.82.68.21.87.61.07.0g13.88.64.09.02.68.21.87.61.07.01.08.0g2(a) initial search, w = 22.68.92.68.92.68.92.67.91.86.71.87.71.88.73.88.73.48.12.66.91.86.71.06.51.07.53.87.7X4.07.0XXXXg12.6 1.9 2.06.9 6.85 8.01.8 1.9 1.06.7 6.85 6.51.0 1.9 1.06.5 7.85 6.51.0 1.97.5 8.852.09.01.07.5g2(b) continued search, w = 1.53.87.73.47.13.86.74.07.02.06.01.05.51.06.54.08.03.06.52.06.01.05.5g23.07.52.06.01.05.51.06.5g1(c) restarted search, w = 1.5Figure 1: effect low-h bias. grid states generated search, h-values shownf 0 -values. (a) Initial weighted search finds solution cost 6. (b) Continued searchexpands many states around previous Open list (grey cells), finding another sub-optimal solutioncost 6. (c) Restarted search quickly finds optimal solution cost 5.136fiThe LAMA Planner: Guiding Cost-Based Anytime Planning LandmarksConsider example search problem shown Figure 1. task reach goal state(g1 g2) start state gridworld, agent move cost 18 neighbours cell blocked. heuristic values inaccurate estimatesstraight-line goal distances cells. particular, heuristic values underestimate distancesleft half grid. conduct weighted search weight 2 Figure 1a (assumingsimplicity standard textbook search, i. e., preferred operators deferred evaluation).heuristic values left happen lower right s, searchexpands states left finds goal g1 cost 6. grey cells generated,expanded search phase, i. e., open list. Figure 1b, search continuesreduced weight 1.5. solution cost 5 consists turning right going g2.However, search first expand states open list f 0 -value smaller 7.expanding substantial number states, second solution finds path startsleft takes long way around obstacle g2, cost 6. instead restartempty open list first solution (Figure 1c), fewer states expanded. criticalstate right expanded quickly optimal path found.Note example, particular systematic errors heuristic valuesleads greedy search astray makes restarts useful. planning, especially usingdeferred evaluation, heuristic values may also fairly inaccurate, restarts useful.experimental comparison tasks IPC 1998 IPC 2006 (Richter et al., 2010)restarting approach performed notably better tested methods, dominating similar algorithms based weighted (Hansen, Zilberstein, & Danilchenko, 1997; Hansen & Zhou, 2007;Likhachev, Gordon, & Thrun, 2004; Likhachev et al., 2008), well anytime approaches(Zhou & Hansen, 2005; Aine, Chakrabarti, & Kumar, 2007).3.3.2 Using cost distance estimatesheuristic estimators used LAMA cost-sensitive, aiming guide search towardshigh-quality solutions. Focusing planner purely action costs, however, may dangerous,cheap plans may longer difficult find, worst case could meanplanner fails find plan within given time limit. Zero-cost operators present particularchallenge: since zero-cost operators always added search path free, even costsensitive search algorithm like weighted may explore long search paths without gettingcloser goal. Methods suggested allow trade-off putative cost-to-goestimated goal distance (Gerevini & Serina, 2002; Ruml & Do, 2007). However, require user specify relative importance cost versus distance up-front, choiceobvious context IPC 2008. LAMA gives equal weight cost distance estimates adding two values computation heuristic functions (for details,see Sections 5 6). measure simple one, effect changes dependingmagnitude variation action costs problem: smaller action costs are,method favours short plans cheap plans. example, 5 zero-cost operators result estimated cost 5, whereas 2 operators cost 1 result estimated cost 4. LAMA would thusprefer 2 operators cost 1 5 zero-cost operators. contrast, action costsplanning task larger length typical plans, cost estimates dominate distance estimates LAMA completely guided costs. Nevertheless simple measure provesuseful IPC 2008 benchmarks, outperforming pure cost search experiments. so137fiRichter & WestphalCBEplaneboxtruckFigure 2: simple Logistics task: transport box location B location E.phisticated methods automatically balancing cost distance (for example normalisingaction costs given task respect mean median) topic future work.4. LandmarksLandmarks subgoals must achieved every plan. first introduced Porteous,Sebastia Hoffmann (2001) later studied depth authors (Hoffmann,Porteous, & Sebastia, 2004). Using landmarks guide search solution planningintuitive approach humans might use. Consider well-known benchmark domain Logistics,goal deliver objects (e. g. boxes) various locations using fleet vehicles.Cities consist sets locations, trucks may transport boxes within city, whereas planesused cities. example Logistics task shown Figure 2. Arguably firstmental step human would perform, trying solve task Figure 2, realisebox must transported two cities, left city (locations AD) right city(location E), therefore, box transported plane. turn meansbox airport location C, loaded plane. partitionstask two subproblems, one transporting box airport location C, onedelivering city. subproblems smaller easier solveoriginal task.Landmarks capture precisely intermediate conditions used direct search:facts L1 = box C L2 = box plane landmarks task shown Figure 2.knowledge, well knowledge L1 must become true L2 , automaticallyextracted task preprocessing step (Hoffmann et al., 2004).LAMA uses landmarks derive goal-distance estimates heuristic search. measuresgoal distance state number landmarks still need achieved pathstate goal. Orderings landmarks used infer landmarksachieved next, whether certain landmarks achieved once. addition,preferred operators (Helmert, 2006) used suggest operators achieve landmarksneed become true next. recently shown, method using landmarks leadssubstantially better performance previous use landmarks Hoffmann et al.,terms coverage terms plan quality (Richter et al., 2008). discuss differencesapproach detail Section 4.3. following section define138fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarksplane1ECBboxplane2Ftruck2truck1Figure 3: Extended logistics task: transport box location B location F.landmarks orderings formally, including useful special cases detectedefficiently.4.1 DefinitionsHoffmann et al. (2004) define landmarks facts true point every plangiven planning task. also introduce disjunctive landmarks, defined sets factsleast one needs true point. subsume landmark definitionsgeneral definition based propositional formulas, believe useful future worktopic landmarks. noted, however, LAMA currently supports factlandmarks disjunctions facts (for details, see Section 4.2). Hoffmann et al. showPSPACE-hard determine whether given fact landmark, whether ordering holdstwo landmarks. complexity results carry straight-forward waygeneral case propositional formulas, repeat proofs.Definition 3. LandmarkLet = hV, s0 , s? , O, Ci planning task finite-domain representation, let = ho1 , . . . ,operator sequence applicable s0 , let i, j {0, . . . , n}.propositional formula facts called fact formula.fact F true time iff F s0 [ho1 , . . . , oi i].fact formula true time iff holds given truth value facts timei. time < 0, considered true.fact formula landmark iff plan , true time.propositional formula facts added time iff true time, time 1 (it considered added time 0 true s0 ).fact formula first added time iff true time , time j < i.Note facts initial state facts goal always landmarks definition.landmarks discussed earlier example task Figure 2 facts. However,complex landmarks may required larger tasks. Consider extended version139fiRichter & Westphalexample, city right two airports, multiple planes trucks,depicted Figure 3. previous landmark L1 = box C still landmarkextended example. However, L2 = box plane corresponding fact landmarktask, since neither box plane1 box plane2 landmark. disjunction boxplane1 box plane2 , however, landmark. following refer landmarksfacts fact landmarks, disjunctions facts disjunctive landmarks.use disjunctive landmarks shown improve performance, compared using factlandmarks (Richter et al., 2008), complex landmarks introduce additional difficultyregard detection handling planning. mentioned before, LAMA currentlyuses fact landmarks disjunctive landmarks, rather general propositional formulas.extension complex types landmarks interesting topic future work. (See Keyder,Richter Helmert, 2010, discussion conjunctive landmarks).Various kinds orderings landmarks defined exploited planningphase. define three types orderings landmarks, equivalent formulationsdefinitions Hoffmann et al. (2004) adapted FDR setting:Definition 4. Orderings landmarksLet landmarks FDR planning task .say natural ordering , written , plantrue time i, true time j < i.say necessary ordering , written n , planadded time i, true time 1.say greedy-necessary ordering , written gn ,plan first added time i, true time 1.Natural orderings general; every necessary greedy-necessary ordering natural,vice versa. Similarly, every necessary ordering greedy-necessary, vice versa.Knowing natural ordering also necessary greedy-necessary allows deducing additionalinformation plausible temporal relationships landmarks, described latersection. Also, landmark heuristic LAMA uses knowledge deduce whether landmarkneeds achieved once. theoretical concept, necessary orderings ( always truestep ) straightforward appealing greedy-necessary orderings (true step becomes true first time). However, methods find landmarksconjunction orderings often find many landmarks using generalconcept greedy-necessary orderings (Hoffmann et al., 2004). LAMA follows paradigmfinds greedy-necessary (as well natural) orderings, necessary orderings. exampleFigure 3, box truck1 must true box C also box F. firstorderings greedy-necessary, necessary, second neither greedy-necessarynecessary, natural.Hoffmann et al. (2004) propose kinds orderings landmarks usefully exploited. example, reasonable orderings, first introduced contexttop-level goals (Koehler & Hoffmann, 2000), orderings necessarily hold givenplanning task. However, adhering orderings may save effort solving task.example task, reasonable load box onto truck1 driving truck airport140fiThe LAMA Planner: Guiding Cost-Based Anytime Planning LandmarksC. However, order guaranteed hold every plan, possible, though reasonable, drive truck C first, drive B collect box, return C. idealandmark must become false order achieve landmark , needed ,reasonable achieve (as otherwise, would achieve twice).idea may applied iteratively, sometimes able find new, induced reasonable orderingsrestrict focus plans obey first set reasonable orderings. Hoffmann et al. callreasonable orderings found second pass obedient-reasonable orderings. authorsnote conducting two iterations process worthwhile, typicallyresult notable additional benefit. following definition characterises two typesorderings formally.Definition 5. Reasonable orderings landmarksLet landmarks FDR planning task .say reasonable ordering , written r , every planadded time first added time j < j, holds truetime {i + 1, . . . , j} true time k j k.say plan obeys set orderings O, orderings x O, regardlesstype, holds first added time true time j i.say obedient-reasonable ordering regard setorderings O, writtenr , every plan obeying added timefirst added time j < j, holds true time {i + 1, . . . , j}true time k j k.definitions equivalent Hoffmann et al. (2004), except careplans rather arbitrary operator sequences, allowing us (theoretically) identifyreasonable orderings. practice, use approximation techniques Hoffmann et al.,thus generating orderings.problem reasonable obedient-reasonable orderings may cyclic, i. e.,chains orderings r x . . . r landmarks may exist (Hoffmann et al., 2004).case natural orderings, definition implies cannot cyclicsolvable tasks.addition, definitions given problematic special cases. Note definition reasonable ordering r includes case exist < jadded time first added time j, i. e., case holds plans firstadded (a) (b) time .1 (a) implies reasonable orderingsgeneralisation natural orderings, might regarded desirable property, (b) may leadundesirable orderings. example, holds r r pairs ,first added time plans, instance true initial state.Similarly, holds r . use definitions despite weaknesses here,simply note planner create contentious orderings. LAMAcreate reflexive orderings r ; r , true initial state createdassumed proven must true strictly point plan (see also Section1. According personal communication authors, case overlooked Hoffmann et al.141fiRichter & Westphaltruck1truck1 Bbox Bbox truck1truck1 Cplane1 C plane2 Cbox Cbox plane1 box plane2box FFigure 4: Partial landmark graph example task shown Figure 3. Bold arcs represent naturalorderings, dashed arcs represent reasonable orderings.4.2.5). re-definition reasonable orderings, addressing problems definition Hoffmann et al. identifying precisely wanted/unwanted cases, topic future work. Closelyconnected question whether reasonable orderings interpreted strict orderings,achieved (as definition obedience above), whether allowachieving simultaneously. use strict sense obedience reasons consistencyprevious work Hoffmann et al., aligns better intended meaningreasonable orderings, even though strict interpretation obedience fit contentiouscases discussed above.Landmarks orderings may represented using directed graph called landmark graph.partial landmark graph extended example depicted Figure 4. following section4.2 contains extensive description landmarks orderings discovered LAMA.Readers interested exact details process may skip description, centralrest paper. Section 4.3 discusses approach finding using landmarksrelates previous work. Section 5 describes landmarks used heuristic estimatorLAMA.4.2 Extracting Landmarks Orderingsmentioned before, deciding whether given formula landmark deciding orderings landmarks PSPACE-hard problems. Thus, practical methods finding landmarksincomplete (they may fail find given landmark ordering) unsound (they may falsely declare formula landmark, determine false ordering). Several polynomial methodsproposed finding fact landmarks disjunctive landmarks, back-chaininggoals task, using criteria based relaxed planning graph (Porteous et al., 2001; Hoffmann et al., 2004; Porteous & Cresswell, 2002), forward propagation planning graph(Zhu & Givan, 2003).142fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarksalgorithm used LAMA finding landmarks orderings partly basedprevious back-chaining methods mentioned above, adapting finite-domain representation including conditional effects. addition, algorithm exploits finite-domain representation using domain transition graphs find landmarks. discuss differencesmethod previous ones detail Section 4.3. idea back-chainingstart set known landmarks find new fact landmarks disjunctive landmarksmust true plan already known landmark may become true. procedure startsset goal facts, stops new landmarks found. methodidentifies new landmarks orderings considering, given fact landmark disjunctivelandmark true initial state:shared preconditions possible first achievers. operator preconditionseffect conditions shared effects potentially first achieve . methodadapted previous work (see Section 4.3).fact landmarks v 7 d, domain transition graph (DTG) v. Here, identify nodesDTG (i. e., values d0 v) must necessarily traversed order reach d.restricted relaxed planning graph lacking operators could possibly achieve . (Theresubtleties involving conditional effects explained later.) Every landmarkoccur last level graph achieved .previous work (Porteous et al., 2001; Hoffmann et al., 2004), subsequently use discovered landmarks orderings derive reasonable obedient-reasonable orderings postprocessing step. following, give detailed description step procedurefinding landmarks orderings LAMA. High-level pseudo code algorithm, containingsteps described following sections 4.2.14.2.4, shown Algorithm 2.4.2.1 Back-Chaining: Landmarks via Shared Preconditions Possible First AchieversFirst achievers fact landmark disjunctive landmark operators potentiallymake true applied end partial plan never made true before.call fact precondition first achievers shared precondition. leastone first achievers must applied make true, must true achieved,thus landmark, ordering gn . effect condition operatortreated like precondition context, interested finding conditionsmust hold become true. following use term extended preconditionsoperator denote union preconditions effect conditions .extended preconditions shared achievers fact calculated line 19 Algorithm 2.addition, create disjunctive landmarks selecting, precondition facts firstachievers, sets facts set contains one extended precondition fact firstachiever (line 22). one first achievers must applied make true, one factsmust true , disjunction thus landmark, ordering gn . Sincenumber disjunctive landmarks exponential number achievers , restrictdisjunctions facts stem predicate symbol, deemedhelpful (Hoffmann et al., 2004). Furthermore, discard fact sets size greaterfour, though found restriction little impact compared predicate restriction.143fiRichter & WestphalGlobal variables:= hV, s0 , s? , O, CiLG = hL, Oiqueue1:2:3:4:5:6:7:8:9:10:11:12:13:14:15:16:17:18:19:20:21:22:23:24:25:26:27:28:29:30:31:. Planning task solve. Landmark graph. Landmarks back-chainedfunction add landmark ordering(, x )fact L : . |=. Prefer fact landmarksL L \ {}. Remove disjunctive landmark\ { ( x ), ( x ) | L }. Remove obsolete orderingsL : . var() var() , . Abort overlap existing landmarkreturn< L. Add new landmark graphL L {}queue queue {}{ x }. Add new ordering graphfunction identify landmarksLG hs? ,. Landmark graph starts goals, orderingsqueue s?orderings. Additional orderings (see Section 4.2.3)queue ,pop(queue)s0 6|=RRPG restricted relaxed plan graphpreshared shared extended preconditions extracted RRPGpresharedadd landmark ordering(, gn )predisj sets facts covering shared extended preconditions given RRPGpredisjs0 6|=add landmark ordering(, gn )factprelookahead extract landmarks DTG variable using RRPGprelookaheadadd landmark ordering(, )potential orderings potential orderings { F | F never true RRPG }add orderings landmarks potential orderingsAlgorithm 2: Identifying landmarks orderings via back-chaining, domain transition graphsrestricted relaxed planning graphs.144fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarksp1Bt1Et2Cp2FFigure 5: Domain transition graph location box extended example (Figure 3).Since PSPACE-hard determine set first achievers landmark (Hoffmann et al.,2004), use over-approximation containing every operator possibly first achiever(Porteous & Cresswell, 2002). intersecting extended preconditions (possibly)operators lose correctness, though may miss landmarks. approximation first achievers done help restricted relaxed planning graph.construction graph leave operators would add unconditionally, alsoignore conditional effects could potentially add . relaxed planning graphlevels out, last set facts over-approximation facts achievedplanning task. operator applicable given over-approximating set achievespossible first achiever .4.2.2 Landmarks via Domain Transition GraphsGiven fact landmark L = {v 7 l}, use domain transition graph v find factlandmarks v 7 l0 (line 27) follows. DTG contains node occurs every pathinitial state value s0 (v) variable landmark value l, node correspondslandmark value l0 v: know every plan achieving L requires v takes value l0 ,hence fact L0 = {v 7 l0 } introduced new landmark ordered naturally L.find kinds landmarks, iteratively remove one node DTG test simplegraph algorithm whether s0 (v) l still connected not, removed node correspondslandmark. improve procedure removing, preprocessing step, nodesknow cannot true achieving L. nodes correspondfacts L appear restricted RPG never adds L. Removing nodesmay decrease number paths reaching L may thus allow us find landmarks.Consider landmark graph extended example, shown Figure 4.landmarks orderings found via back-chaining procedure described previoussection, landmarks direct preconditions achieving successors graph.two exceptions: box truck1 box C. two landmarks however foundDTG method. DTG Figure 5 immediately shows box location must takevalue t1 value C path initial value B goal value F.145fiRichter & Westphal4.2.3 Additional Orderings Restricted Relaxed Planning Graphsrestricted relaxed planning graph (RRPG) described Section 4.2.1, given landmark leaves operators could possibly achieve , used extract additionalorderings landmarks. landmark appear graph cannot reached, thus introduce natural ordering . efficiency reasons, constructRRPG (line 18), i. e., needed find possible first achieversback-chaining procedure. extract orderings factsreached (line 30). facts F later recognised landmarks,introduce ordering F (line 31).4.2.4 Overlapping LandmarksDue iterative nature algorithm possible find disjunctive landmarksleast one facts already known fact landmark. cases, let factlandmarks take precedence disjunctive ones, i. e., disjunctive landmark discoveredincludes already known fact landmark, add disjunctive landmark. Conversely,soon fact landmark found part already known disjunctive landmark, discarddisjunctive landmark including orderings2 , add fact landmark instead. keepprocedure resulting landmark graph simple, furthermore allow landmarksoverlap. Whenever fact newly discovered disjunctive landmark also partalready known landmark, add newly discovered landmark. cases handledfunction add landmark ordering (lines 1 10).4.2.5 Generating Reasonable Obedient-Reasonable Orderingswant introduce reasonable ordering L r L0 two (distinct) fact landmarks LL0 holds (a) L0 must true time first achieving L, (b) achievingL0 L would require making L0 false achieve L. approximate (a) (b)proposed Hoffmann et al. (2004) sufficient conditions. case (a), test L0 s?chain natural greedy-necessary orderings landmarks L = L1 . . . Ln ,n > 1, Ln1 , L0 greedy-necessary ordering L0 gn Ln . (b) check whether (i) LL0 inconsistent, i. e., mutually exclusive, (ii) operators achieving L effectinconsistent L0 , (iii) landmark L00 inconsistent L0 orderingL00 gn L.Inconsistencies facts easily identified finite-domain representationfacts form v 7 v 7 d0 , i. e., map variable different values.addition, LAMA uses groups inconsistent facts computed translator component.second pass, obedient-reasonable orderings added. done methodabove, except reasonable orderings used addition natural greedy-necessaryorderings derive fact landmark L0 must true landmark L. Finally, usesimple greedy algorithm break possible cycles due reasonable obedient-reasonable orderings landmark graph, every time cycle identified, one involved reasonable2. Note ordering {F, G} neither implies F G general. Conversely, {F, G} neitherimplies F G.146fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarksobedient-reasonable orderings removed. algorithm removes obedient-reasonable orderingsrather reasonable orderings whenever possible.4.3 Related WorkOrderings landmarks generalisation goal orderings, frequentlyexploited planning search past. particular, approach Irani Cheng (Irani &Cheng, 1987; Cheng & Irani, 1989) preprocessing procedure like analyses planningtask extract necessary orderings goals, imposed search algorithm.goal ordered goal B approach plan necessarily true B.Koehler Hoffmann (2000) introduce reasonable orderings goals.Hoffmann et al. (2004), article detailing earlier work Porteous et al. (2001), introduceidea landmarks, generalise necessary reasonable orderings goals landmarks,propose methods finding using landmarks planning. proposed method findinglandmarks, subsequently extended Porteous Cresswell (2002), closelyrelated ours. Hoffmann et al. propose method finding fact landmarks proceeds threestages. First, potential landmarks orderings suggested fast candidate generation procedure. Second, filtering procedure evaluates sufficient condition landmarks candidatefact, removing fail test. Third, reasonable obedient-reasonable orderings landmarks approximated. step largely identical approach ours,except use different methods recognise inconsistencies facts.generation landmark candidates done via back-chaining goal much likeapproach, intersecting preconditions operators first achieve fact Fappear F relaxed planning graph. Note even operators sharecommon precondition L, might first achievers F (appearing F relaxedplanning graph) L precondition, hence L landmark. test whetherlandmark candidate L found via back-chaining indeed landmark, Hoffmann et al. (2004)build restricted relaxed planning task leaving operators could add L. taskunsolvable, L landmark. sufficient, necessary condition: L necessarysolving relaxed task also necessary solving original task, conversetrue. verification procedure guarantees method Hoffmann et al. generates truelandmarks; however, unsound orderings may established due unsound landmark candidates.unsound landmarks pruned failing verification test, unsound orderings mayremain.Porteous Cresswell (2002) propose alternative approximation first achieversfact F use. consider first achievers possibly applicable Fthus guarantee correctness found landmarks orderings. also find disjunctivelandmarks. method landmark detection differs adding detection landmarksvia domain transition graphs, detection additional orderings via restricted relaxed planninggraphs. Porteous Cresswell additionally reason multiple occurrences landmarks (iflandmark achieved, made false re-achieved several times plans),not.approach Hoffmann et al. (2004) exploits landmarks decomposing planning tasksmaller subtasks, making landmarks intermediary goals. Instead searching goaltask, iteratively aims achieve landmark minimal respect orderings.147fiRichter & Westphaldetail, first builds landmark graph (with landmarks vertices orderings arcs). Possiblecycles broken removing arcs. sources resulting directed acyclic graphhanded base planner disjunctive goal, plan generated achieve onelandmarks . landmark, along incident arcs, removed landmarkgraph, process repeats end state generated plan. landmark graphbecomes empty, base planner asked generate plan original goal. (Note eventhough goal facts landmarks thus achieved previously, may violatedagain.)base planner solving subtasks planner used; Hoffmann et al. (2004)experimented FF. found decomposition subtasks lead directed search, solving larger instances plain FF many domains. However, foundmethod leads worse average performance IPC benchmarks 1998 2006using Fast Downward base planner (Richter et al., 2008). Furthermore, method Hoffmann et al. often produces solutions longer produced base planner,disjunctive search control frequently switches different parts task maydestructive interactions. Sometimes even leads dead ends, approach failssolvable tasks. contrast, approach incorporates landmark information searchingoriginal goal planning task via heuristic function derived landmarks (see nextsection). recently shown, avoids possibility dead-ends usually generatesbetter-quality solutions (Richter et al., 2008).Sebastia et al. (2006) extend work Hoffmann et al. employing refined preprocessing technique groups landmarks consistent sets, minimising destructive interactionssets. Taking sets intermediary goals, avoid increased plan lengthexperienced Hoffmann et al. (2004). However, according authors preprocessingcomputationally expensive may take longer solving original problem.Zhu Givan (2003) propose technique finding landmarks propagating necessarypredecessor information planning graph. definition landmarks encompasses operatorsnecessary plan (called action landmarks), furthermore introduce notioncausal landmark fact landmarks required precondition operatorsevery plan. argue fact landmarks causal accidental effectswarrant sought explicitly. algorithm computes action landmarks causalfact landmarks time propagating information construction relaxedplanning graph. extended variant algorithm also able infer multiple occurrenceslandmarks. Gregory et al. (2004) build work find disjunctive landmarkssymmetry breaking.Similar work, Zhu Givan (2003) use causal fact landmarks action landmarksestimate goal distance given state. end, treat fact landmark virtualaction (sets operators achieve fact landmark) obtain distance estimate binpacking. items packed bins real landmark actions (singletons) virtualactions, bin may contain elements pairwise intersection elementsnon-empty. Zhu Givan employ greedy algorithm estimate minimum number binsuse value distance estimate. experimental results preliminary, however,demonstrate significant advantage method FF planner.148fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarks5. Landmark HeuristicLAMA planning system uses landmarks calculate heuristic estimates. Since knowlandmarks must achieved order reach goal, approximate goal distancestate reached path (i. e., sequence states) estimated number landmarksstill need achieved onwards. landmarks givenL(s, ) B L \ Accepted(s, ) ReqAgain(s, )L set discovered landmarks, Accepted(s, ) set accepted landmarks,ReqAgain(s, ) set accepted landmarks required again, followingdefinitions based given landmarks graph (L, O) :L | |= @( x )= hi00Accepted(s, ) B= 0 ; hoiAccepted(s0 [ ], ) L | |=( x ) : Accepted(s0 [0 ], 0 )ReqAgain(s, ) B Accepted(s, ) | 6|=s? |= ( gn ) : < Accepted(s, )landmark first accepted state true state, landmarks orderedaccepted predecessor state generated. landmarkaccepted, remains accepted successor states. initial state, accepted landmarkstrue initial state predecessors landmark graph.accepted landmark required true (a) forms part goal(b) must true directly landmark (i. e., gn ) accepted s.latter case, since know must still achieved must true time step, holds must achieved again. number |L(s, )| heuristic valueassigned state s. Pseudo code heuristic given Algorithm 3.landmark heuristic assign non-zero value state goal state, sincegoals landmarks always counted required per condition (a) above. However,heuristic may also assign non-zero value goal state. happens plans foundobey reasonable orderings landmark graph, case goal state mayreached without landmarks accepted.3 Hence, need explicitly test states goalcondition order identify goal states search.Note heuristic path-dependent, i. e., depends sequence statesreached initial state. raises question happens state reachedvia several paths. LAMA, heuristic state calculated once, first reached.alternative option would re-evaluate time new path discovered, takingaccount information paths known time. Karpas Domshlak (2009) note,calculate landmarks accepted given set paths P Accepted(s, P) BP Accepted(s, ), since holds landmark achieved along paths P must3. special case r become true simultaneously, could avoid accepting(Buffet & Hoffmann, 2010), could modify definition reasonable orderingsr hold unless must become true strictly . general problem goal states mayassigned non-zero value, however, still persists even modifications.149fiRichter & WestphalGlobal variables:= hV, s0 , s? , O, CiLG = hL, OiAccepted. Planning task solve. Landmark graph. Landmarks accepted states evaluated farfunction lm count heuristic(s, )= hi. Initial stateAccepted(s, ) L | s0 |= @( x )else0 ho1 , . . . , on1 = ho1 , . . . ,parent s0 [0 ]. Accepted(parent, 0 ) calculatedReached { L | |= ( x ) : Accepted(parent, 0 ) }Accepted(s, ) Accepted(parent, 0 ) ReachedNotAccepted L \ Accepted(s, )ReqGoal { n Accepted(s, ) | 6|= s? |= }ReqPrecon Accepted(s, ) | 6|= : ( gn ) < Accepted(s, )return |NotAccepted ReqGoal ReqPrecon|Algorithm 3: landmark count heuristic.achieved onwards. heuristic value derived analogousway before.landmark heuristic outlined estimates goal distance states, i. e., numberoperator applications needed reach goal state given state. participate IPC 2008,made function cost-sensitive weighting landmarks estimate minimumcost. Apart estimating goal distance counting number landmarks still needachieved state, estimate cost-to-go state sum minimum costslandmarks. cost counted landmark minimum action costfirst achievers. (Alternative, sophisticated methods computing costs landmarksconceivable potential topic future work.) heuristic value LAMA assignsstate however pure cost-to-go estimate, rather sum cost estimatedistance estimate. thus accounting costs-to-go goal distances states,measure aims balance speed search quality plans, particular counter-actproblems may arise zero-cost operators (see Section 3.3).also generate preferred operators along landmark heuristic. operator preferredstate applying achieves acceptable landmark next step, i. e., landmark whose predecessors already accepted. acceptable landmark achieved within one step,preferred operators occur relaxed plan nearest acceptable landmark.nearest landmark cost-unaware setting one relaxed reachable minimal numberoperators, cost-sensitive setting landmark reachable cheapest hadd cost(see Section 6), cost distance estimates taken account. nearestlandmark computed building relaxed planning graph or, equivalently, performing relaxed exploration (which LAMA does, see Section 6), determining earliest leastcostly occurrence acceptable landmark structure. relaxed plan landmark150fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarksextracted, operators plan form preferred operators applicablecurrent state.6. Cost-Sensitive FF/add Heuristicfirst introduced landmark heuristic (Richter et al., 2008), proved competitive own, compared established heuristics like FF heuristic (Hoffmann & Nebel,2001). However, joint use FF heuristic landmark heuristic multi-heuristicsearch improved performance planning system, compared using FF heuristic.thus path LAMA follows. FF heuristic based relaxation planning taskignores delete effects, FDR tasks translates allowing state variables hold severalvalues simultaneously.FF heuristic state computed two phases: first phase, forward phase,calculates estimate fact planning task costly achieve factrelaxed task. Concurrently, selects operator called best support fact F,greedy approximation cheapest achiever (an achiever F costs makingapplicable applying minimal among achievers F, starting s). secondphase, plan relaxed task constructed based best supports fact. donechaining backwards goals, selecting best supports goals, recursivelyselecting best supports preconditions already selected operators. unionbest supports constitutes relaxed plan (i. e., fact best support addedrelaxed plan once, even fact needed several times precondition). lengthresulting relaxed plan heuristic estimate reported s.forward phase viewed propagating cost information operators factsrelaxed planning graph (Hoffmann & Nebel, 2001). However, graph needexplicitly constructed compute heuristic. Instead, form generalised Dijkstra cheapestpath algorithm described Liu, Koenig Furcy (2002) used LAMA, propagatescosts preconditions applicable operators operators effects. method,operator fact represented once, reducing time space requirements O(NK),N size relaxed planning task K depth relaxed planning graph,O(N). order deal conditional effects, operators n effects split n operatorsone effect each, corresponding effect conditions moved preconditionsoperators. n operators selected inclusion relaxed plan, originaloperator included instead (again, operator included relaxed plan once).cost estimate operator original FF heuristic depth relaxed planninggraph, case planning unit-cost operators equivalent (Fuentetaja, Borrajo, &Linares Lopez, 2009) propagating costs via hmax criterion (Bonet & Geffner, 2001). hmaxcriterion estimates cost operator maximum costs preconditions, plusaction cost operator (1 planning without action costs). cost factestimated cost cheapest achiever, zero fact true current state s.originally proposed unit-cost planning, heuristic adapted cost-based planningstraightforward way using action costs cost propagation phase, reporting total costresulting relaxed plan, rather length, heuristic estimate.Using criteria cost propagation results variations FF heuristic (Bryce & Kambhampati, 2007; Fuentetaja et al., 2009). One variant previously proposed litera151fiRichter & Westphalture (Do & Kambhampati, 2003) use hadd criterion (Bonet & Geffner, 2001). similarhmax criterion except estimating cost operators via sum, rather maximum,costs preconditions. following use term FF/add variantFF heuristic. Independently us, Keyder Geffner (2008) implemented FF/add heuristiccall ha planner FF(ha ) IPC 2008. formal specification FF/add heuristicfound paper. heuristic function LAMA similar cost-sensitive FF/addheuristic. However, landmark heuristic, LAMA purely guided action costs,rather uses cost distance estimates equally. means cost propagation,operator contributes action cost plus 1 distance, rather action cost,propagated cost estimates.7. Experimentsevaluate much central features LAMA contributes performance,conducted number experiments comparing different configurations features.focus detailed evaluation benchmark tasks International Planning Competition(IPC) 2008, interested setting planning action costs. effect landmarksclassical planning tasks without actions costs studied previous work (Richter et al.,2008), provide summarising results case, using domains IPCs 19982006,Section 7.6. benchmark set IPC 2008 comprises 9 domains 30 tasks each, resultingtotal 270 tasks. one domains (Openstacks), two different formulations available(STRIPS ADL). competition, report better result two formulationsplanner.described Section 1, LAMA builds platform provided Fast Downward threemajor ways: (1) use landmarks, (2) using cost-sensitive heuristics guide searchcheap plans, (3) employing anytime search continue search better solutionstime remains. examine usefulness landmarks, conduct experiments withoutthem, keeping planner features fixed. use action costs LAMA resultnumber design decisions. landmark heuristic FF/add heuristic madecost-sensitive. However, rather focusing purely action costs, LAMA uses distanceestimates cost estimates combination (see Section 3.3) balance speed qualitysearch. measure benefit combining approach, test three different approachesdealing costs: (a) using traditional cost-unaware heuristics (distance estimates), (b) usingpurely cost-sensitive heuristics (though using distance estimates tie-breaking), (c) usingcombination distance cost estimates, LAMA. different choices regardinglandmarks approaches action costs thus result following six planner configurations:F: Use cost-unaware FF/add heuristic (estimating goal distance).Fc : Use purely cost-sensitive FF/add heuristic (estimating cost-to-go).F+c : Use FF/add heuristic combines action costs distances.FL: Use cost-unaware variants FF/add heuristic landmark heuristic.FLc : Use purely cost-sensitive variants heuristics.FL+c : Use variants combine action costs distances heuristics.152fiThe LAMA Planner: Guiding Cost-Based Anytime Planning LandmarksNote contrast setting optimal planning (Karpas & Domshlak, 2009), landmarkheuristic competitive case, landmarks LAMA used provideadditional information already guided search. such, include configurations using landmarks heuristic estimators detailed results. However, providesummarising results supporting claim competitive.configuration run iterated (anytime) search. highlighting contributioniterated search, report first solutions vs. final solutions, final solutionconfiguration last, best, solution finds within 30-minute timeout. (Notequality solution always determined cost, irrespective whether heuristic usedcalculate cost-sensitive not.) discussing three possible approaches costs (costunaware search, purely cost-sensitive search, LAMAs combination distances costs)write X, Xc , X+c denote three cost approaches independently heuristics used.measure performance using criterion employed IPC 2008 (Helmertet al., 2008). planner configuration run 30 minutes per task. timeout, planneraggregates ratio c /c total score c cost plan found, c costbest known solution (e. g., reference solution calculated competition organisers,best solution found participating planners).Experiments run hardware used competition, cluster machines IntelXeon CPUs 2.66GHz clock speed. time memory limits set valuescompetition, using timeout 30 minutes memory limit 2 GB. following,first provide general overview results. discuss special cases, i. e., domainsresults certain configurations deviate overall trend, try give plausibleexplanations may happen.7.1 Overview Resultssection, show purely cost-based FF/add configuration Fc solves significantlyfewer tasks cost-unaware counterpart F. Fc finds higher-quality solutions,make low coverage (number solved tasks) measuring performanceIPC criterion. Using landmarks improves quality slightly, cost-unaware search using landmarks (FL) achieves highest IPC performance score amongst configurations. usingcost-sensitive FF/add heuristic, adding landmarks (resulting configurations FLc FL+c )increases coverage substantially, incurring small loss quality. Iterated search improves scores configurations significantly. Lastly, using combination costdistance estimates heuristics (X+c ) superior pure cost-based search using iterated search. Together, using landmarks combination cost distance estimates (FL+c )achieves nearly performance FL configuration.following, support findings experimental data. Section 7.1.1 (Performance Terms IPC Score), show cost-sensitive FF/add heuristic scoreslowly terms IPC criterion, landmarks combination cost distance estimates together make bad performance. Furthermore, results demonstrate magnitude impact iterated search performance scores. Section 7.1.2 (Coverage),show bad performance cost-sensitive FF/add heuristic due solving fewertasks, use landmarks mitigates problem. Section 7.1.3 (Quality), presentdata showing purely cost-sensitive FF/add heuristic finds higher-quality plans cost153fiRichter & WestphalDomainBaseC3Cyber SecurityElevatorsOpenstacksPARC PrinterPeg SolitaireScanalyzerSokobanTransportWoodworkingTotal(Total IPC 2008)42121272024211814169(176)9161018202318624143(151)DomainFCyber SecurityElevatorsOpenstacksPARC PrinterPeg SolitaireScanalyzerSokobanTransportWoodworkingTotal202220202019181822180IPC PlannersFF(ha ) FF(has )2098162124151522150(157)20108232324181422162(169)First solutionsFL FLcFcF+cFL+c2492316232120152017127161421212119232018224920162020191520162202313232022182420182281413212221192420183LAMA282027212926242725227(236)Slowed LAMA10100FL+c272027192925222524218()282227222926232624227()261726122622152117183()Final solutions (iterated search)FFcF+cFL FLc FL+c232927232924241923220241029162924241721194251528162925241722201262727242929222420229281628222924232623217282227222926232624227Table 1: Performance scores (rounded whole numbers) planners scoring 100 pointsIPC 2008 (top) 6 experimental configurations (bottom). Scores IPC planners recalculated (see text). LAMA 10 100 refer results achieved LAMA slowedfactors 10 100, respectively. FL+c essentially IPC planner LAMA.unaware FF/add heuristic first search, iterated search, differencedisappears. Furthermore, iterated search intermediate approach using cost distanceestimates scores higher purely cost-based search. LAMAs approach using landmarkscombination cost distance estimates (FL+c ) thus effectively mitigates bad performance cost-sensitive FF/add heuristic.7.1.1 Performance Terms IPC Scorescores planners scoring 100 points IPC 2008 shown top partTable 1. Apart LAMA, includes base planner run competition organisers (FFpreprocessing step compiles away action costs), FF(ha ) FF(has ) planners Keyder154fiThe LAMA Planner: Guiding Cost-Based Anytime Planning LandmarksGeffner (2008) C3 planner Lipovetzky Geffner (2009). plans foundplanners obtained competition website (Helmert et al., 2008). However,scores plans depend best known solutions tasks. scores showthus differ ones published IPC 2008, re-calculated reflect newbest solutions found experiments. illustrate magnitude change, original totalscores IPC planners shown parentheses last table row.configuration FL+c results essentially planner (the IPC version of)LAMA, report results again, minor corrections implemented LAMAsince competition. addition, planner makes arbitrary decisions pointsexecution due underlying programming library methods, leading varying results. However,Table 1 shows differences FL+c LAMA small. furthermoreadded columns table showing hypothetical results LAMA would obtainedsearch slowed constant factors 10 100, respectively (i. e., results obtainedcutting search 3 minutes, 18 seconds, respectively). numbers showLAMA still outperforms IPC planners even severe handicap, demonstratinggood performance LAMA mainly due efficient implementation.bottom part Table 1 contains results six experimental configurationsfirst search iteration (left) 30-minute timeout (right). seen, uselandmarks iterated search lead significant improvements performance. Even onetwo features planner performs notably better competitors IPC 2008.(Note however baseline planner performed badly Cyber Security due problemsreading large task descriptions.) combination, benefits landmarks iteratedsearch grow further: cost-unaware search use landmarks results 2 additional score pointsfirst solutions, 9 additional points final solutions. Similar results holdcost-sensitive configurations. mainly due Openstacks domain, using landmarkshighly detrimental solution quality first solutions. Iterated search mitigates problemimproving quality similar levels without landmarks. Overall, thus slightsynergy effect landmarks iterated search, making joint benefit two featureslarger sum individual contributions. effect landmarks Openstacksdomain discussed detail later.use cost-sensitive search pay experiments. Cost-unaware searchalways least roughly equal, often substantially better cost-sensitive configurations.Cost-sensitive planning seems problem LAMA, also participating planners IPC 2008: notably, cost-sensitive competitors LAMA fare worsecost-ignoring baseline. LAMA, best performance achieved using cost-unaware searchlandmarks iterated search. However, using combination cost distance estimates instead (FL+c ) leads performance almost equally good. particular, FL+c substantiallybetter pure cost search FLc iterated search used.detailed view data provided Figure 6, show performancetime six experimental configurations. data point 100 seconds, example, showsscore corresponding planner would achieved timeout 100 seconds.top panel shows, cost-sensitive search consistently worse cost-unaware search usingFF/add heuristic. Using landmarks (see centre panel), two settings FL FL+c achievebetter performance F, though FL+c needs 2 minutes surpass F, FL within 5seconds. Pure cost search, even landmarks (FLc ), performs worse F times.155fiRichter & Westphal240220Score200180160FFcF+c140120110100Time (seconds)1000240220Score200180160FFLFLcFL+c140120110100Time (seconds)1000240220Score200180160FFLFLcFL+c140120110100Time (seconds)1000Figure 6: Score time using iterated search (top centre panel) without iterated search,i. e., showing first solutions (bottom panel).156fiThe LAMA Planner: Guiding Cost-Based Anytime Planning LandmarksDomainBaseC3FF(ha )FF(has )LAMAFL+cCyber SecurityElevatorsOpenstacksPARC PrinterPeg SolitaireScanalyzerSokobanTransportWoodworkingTotal43030303030272917227153030183027221228212232325162928172329213222626232928202229225302430223030253030251302530233030243030252DomainFFcF+cFLFLcFL+cCyber SecurityElevatorsOpenstacksPARC PrinterPeg SolitaireScanalyzerSokobanTransportWoodworkingTotal303030253028252630254281530163030252228224291630163029242128223303030243030232928254302230233030243030249302530233030243030252Table 2: Coverage planners scoring 100 points IPC 2008 (top) 6 experimentalconfigurations (bottom). Results IPC planners taken competition. FL+cessentially IPC planner LAMA.bottom panel Figure 6 shows using iterated search, performance 4 bestconfigurations FL, F, FL+c , FLc fairly similar eventually, cost-sensitive approachesneed time cost-unaware configurations reach performance levels.7.1.2 Coveragebad performance cost-sensitive search surprising, given performance criterionawards higher scores cheaper plans. One explanation could mainly due different coverage. finding plans high quality substantially harder finding plans lowquality, focusing nearest goals rather cheapest goals may solve tasks withingiven time limit. Table 2 show coverage considered planners configurations.numbers confirm using landmarks, coverage cost-unaware search indeedsubstantially higher coverage cost-sensitive search. However, landmarks, differences coverage various cost approaches small. particular, landmarksimprove coverage cost-unaware search, bring cost-sensitive configurations157fiRichter & WestphalDomainCyber SecurityElevatorsOpenstacksPARC PrinterPeg SolitaireScanalyzerSokobanTransportWoodworkingTotalDomainCyber SecurityElevatorsOpenstacksPARC PrinterPeg SolitaireScanalyzerSokobanTransportWoodworkingTotalFc / FTasks C. Ratio2815301630282321282190.641.160.830.790.870.940.941.011.020.88Fc / FTasks C. Ratio2815301630282321282190.811.510.950.970.991.011.010.980.990.99F+c / FTasks C. Ratio2916301630282221282200.691.151.000.791.020.930.981.001.020.94F+c / FTasks C. Ratio2916301630282221282200.821.050.960.971.000.931.000.890.940.94FLc / FcTasks C. Ratio2814301530302422282210.810.891.981.051.040.980.980.891.071.06FLc / FcTasks C. Ratio2814301530302422282210.810.891.041.011.021.021.020.891.000.97FL+c / F+cTasks C. Ratio2916301530292321282210.830.921.461.050.951.001.000.891.061.01FL+c / F+cTasks C. Ratio2916301530292321282210.820.991.041.011.011.011.000.891.010.97Table 3: Average ratio first solution costs (top) best solution costs iterative search(bottom) various pairs configurations commonly solved tasks.coverage level cost-unaware search. Landmarks thus seem helpfulovercoming coverage problems cost-sensitive search.mentioned before, landmark heuristic however competitive. Usinglandmark heuristic FF/add heuristic results IPC 2008 performance scores164 167 iterated search, coverage points 185 189 three possiblecost settings. substantially worse performance scores greater 194 coveragepoints greater 223 achieved LAMA configurations.7.1.3 Qualitynext step, look purely solution quality. Firstly, want answer question whetherimprovement coverage achieved landmarks cost-sensitive search comes pricesolution quality, i. e., whether using landmarks directs search close goals rather cheapgoals. Secondly, would like know solution quality differs cost-sensitivecost-unaware configurations. particular, much quality lose combining158fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarksdistance cost estimates (X+c ) opposed using pure cost search (Xc )? score used IPC2008 Table 1 incorporates coverage quality information counting unsolved tasks0 method allows ranking several planners solving different subsets total benchmarkset. interested examining quality independent coverage, must restrict focus tasks solved compared planners. Table 3 contains quality information comparingsolution costs several configurations, compare configurations pair-wise ordermaximise number commonly solved tasks. top part Table 3 contains comparisonsinvolving first solutions found configuration, bottom part table concernsbest solutions found iterative search. pair configurations show numbertasks solved both, geometric mean cost ratio plans find.expected, cost-sensitive configurations Fc F+c find cheaper plans costunaware configuration F average, particular pure cost search Fc finds high-qualityfirst plans (see first column top part table). Fc F+c , however, difference F large. domains, notably Elevators, plans foundcost-sensitive heuristics actually worse plans found cost-unaware search.Landmarks deteriorate quality first plans Fc ; F+c , starts worsequality Fc , noticeably deteriorated landmarks. configurations, however, main negative impact landmarks Openstacks domain, plans becomenearly twice expensive Fc , 50% expensive F+c . contrast, remaining8 domains average plan quality configurations landmarks even slightly betteraverage without landmarks.note iterative search remarkable impact relative performance different configurations. looking solutions found iterative search, Fc actually performsworse F+c , whereas way round first solutions (compare first twocolumns top row versus bottom row table). explained extentfact reasons cause Fc low coverage also prevent improving much time. show selected domains later, cost-sensitive heuristic oftenexpands many nodes cost-unaware search, leading observed behaviour.likely due fact finding plans high quality hard thus unsuccessful manybenchmark tasks. example, domains cost-sensitive search leads large localminima exist cost-unaware search. generally, good plans often longerbad plans, may lead increased complexity particular domains heuristicvalues inaccurate. showcase problems cost-sensitive search detailElevators PARC Printer domains later on.iterative search, landmarks deteriorate quality either Fc F+c average,negative impact Openstacks domain longer present. (This effect Openstacksdomain discussed detail later.)Summarising findings, say landmarks effectively support cost-sensitiveFF/add heuristic finding solutions, without steering search away good solutions. Similarly, combining distance cost estimates X+c leads search finding solutions quicklywithout overly sacrificing quality, demonstrated superior anytime performance comparedpure cost search.way example, present detailed results four nine competition domains.choose domains deem particular interest results either exaggerate contradict general trends discussed far. domains Elevators PARC Printer159fiRichter & Westphal876543210Figure 7: example elevators task.highlight problems cost-sensitive search; Cyber Security cost-sensitive search performsuncharacteristically well; Openstacks domain landmarks lead usualimprovement, rather deterioration performance.7.2 ElevatorsElevators domain models transportation passengers building via fast slow elevators, elevator certain passenger capacity access certain floors. Passengersmay change elevators get final destination, furthermore two different typeselevators different associated cost functions. contrast Miconic domain, usedearlier international planning competition (Bacchus, 2001), also models transporting passengers via elevators, one elevator access floorsone (unit-cost) operator. Elevators, floors building grouped blocks, overlapping one floor. Slow elevators operate within block access floors withinblock. Fast elevators access blocks, certain floors within block (infirst 10 IPC tasks every second floor, 20 tasks every fourth floor). Fast elevatorsusually expensive slow elevators except distance two floors, elevatortypes cost same. However, fast elevators may sometimes advantageous transportingpassengers blocks (as avoid need passengers switch elevators sharedfloor blocks), usually higher capacity.example task eight floors, grouped two blocks, shown Figure 7.total four elevators, two slow ones two fast ones. cost function used 30 IPC tasksmoving elevator current location target floor 6 + n slow elevators 2 + 3nfast elevators, n distance travelled (the number floors current locationelevator target). Operators concerning passengers boarding leaving elevatorsfree cost. Assuming cost function, cheaper example transport passengerlocated floor 0 using two slow elevators (changing floor 4) using direct fast elevator.Elevators one domains configurations using cost-sensitive FF/add heuristicsolve far fewer problems cost-unaware counterparts. Using landmarks increases coverage,solve problem completely. Furthermore, notable problemscost-sensitive configurations solve, solutions often worse quality solutionscost-unaware configurations. Table 4 illustrates fact first solutions found using160fiThe LAMA Planner: Guiding Cost-Based Anytime Planning LandmarksTask010203040506070809111213142021Avg.Quality (IPC Score)FFcF+c0.57 0.590.530.69 0.720.720.88 0.580.510.71 0.700.720.68 0.540.540.60 0.600.610.38 0.460.400.84 0.540.510.71 0.540.570.66 0.520.520.70 0.540.580.58 0.510.540.70 0.700.700.67 0.470.580.70 0.630.710.67 0.580.58F262721343356714754395560811328455LengthFc2425414550648162815179841011738367F+c272542475053836559477972951548265Table 4: Comparison plan qualities (measured via IPC scores) plan lengths firstsolutions F, Fc , F+c Elevators. Shown tasks solved three configurations,bold print indicating best solution.FF/add heuristic. iterative search (not shown), solution quality F+c improvessimilar level F, whereas Fc remains substantially worse.full explanation configurations involving cost-sensitiveFF/add heuristic perform badly domain, several factors seem play role. Firstly,attempt optimise costs, cost-sensitive FF/add heuristic focuses relatively complex solutionsinvolving mainly slow elevators many transfers passengers elevators,relaxed plans less accurate (i. e., translate less well actual plans), casecost-unaware heuristic. Secondly, costs associated movements elevators dominateheuristic values, causing local minima cost-sensitive heuristic. Thirdly, capacityconstraints associated elevators may lead plateaus bad-quality plans particularcost-sensitive heuristic. following sections, describe factors detail.Lastly, found deferred heuristic evaluation technique used LAMA (see Section 3.3) perform well domain. using deferred evaluation, Fc configuration solves 3 additional tasks (though quality solutions remains worse Fconfiguration). partly explains FF(ha ) planner Keyder Geffner (2008)substantially higher coverage Fc configuration domain. two planners useheuristic, differ several aspects. Apart deferred evaluation aspects include search algorithm used (greedy best-first search vs. enhanced hill-climbing) methodusing preferred operators (maintaining additional queues preferred states vs. pruning nonpreferred successor states).161fiRichter & WestphalFFcF+cSlow moves275405404Fast moves452112Ratio fast/slow6.1119.2933.67Table 5: Total elevator moves ratio fast/slow moves first solutions found F, Fc ,F+c configurations, 15 Elevators instances solved three configurations.7.2.1 Slow vs. Fast Elevatorsexamining results, found Fc F+c configurations tend produce plansslow elevators used passengers, F configuration usesfast elevators often (cf. Table 5). surprising, individual passenger,travelling starting point destination tends cheaper slow elevator (unlessdistance short), whereas fewer operators typically required travelling fastelevator. independence assumptions inherent FF/add heuristic (see Section 6) leadconstructing relaxed plans aim optimise transportation passenger individually,rather taking synergy effects account.plans produced Fc F+c also longer, average, plans produced F (seeTable 4), one reason predominant use slow elevators requires passengerschange elevators often. plans become longer involve passengerstravelling slow elevators, heuristic estimates may become worse. example,relaxed plans extracted computation heuristic likely abstract away detailspassengers travel elevator (e. g., since passenger pickeddelivered certain location, elevator may teleport back location extracost relaxed plan pick deliver subsequent passengers). Generally, foundrelaxed plans initial state produced Fc F+c tend similar length costproduced F, final solutions produced Fc F+c worse F. One reasonprobably increased complexity planning passenger change-overselevators combination worse relaxed plans poses problem cost-sensitiveFF/add heuristic.7.2.2 Local Minima Due Elevator-Movement CostsSince action costs model distances, total cost relaxed plan depends target floorsrelative current position elevator. Fc F+c , action costs movingelevator usually dominate estimates FF/add heuristic. Consider two example tasksFigure 8, differ initial state elevators. elevators need travelthree floors solution plan, due abstracted delete effects relaxed plan initial stateinclude operators travel two floors starting floor elevator(i. e., elevator teleported back starting floor without cost). left task,relaxed cost visiting three floors lower right task, cost left tasksum going floor 4 floor 8, going floor 4 floor 0, resulting total cost10 + 10 = 20. right task, relaxed cost visiting floors cost goingfloor 0 floor 4, floor 0 floor 8, resulting total cost 10 + 14 = 24. lefttask, passenger boarded elevator floor 4, immediate successor states162fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarksaction costaction cost876543210876543210Figure 8: Action cost effects Elevators relaxed setting. Travelling 4 floors costs 10,travelling 8 floors costs 14. tasks solution cost (34), left task lowerrelaxed cost (20) right task (24).worse heuristic estimate due movement costs elevator. particular, correct actionmoving elevator floor 8 (to deliver passenger) results state worse heuristicvalue. increased number waiting passengers floor 4, planning system wouldtherefore try boarding possible subsets passengers moving elevator. evenelevator moved floor 8, heuristic estimate improve passengerdropped either (a) elevator moved back floor 4, (b) second passengerboarded elevator moved floor 0.Consequently, movement costs may dominate progress obtained transporting passengersnumber successive states. words, planner often blindly achieveprogress move elevators towards middle position given remaining target floors,order cost-sensitive heuristic report progress. cost-unaware heuristic, situationless severe, number elevator movements relaxed plan increase,hence planner encounters plateau search space rather local minimum. usepreferred operators may help escape plateau relatively quickly, whereas local minimummuch harder escape from. Two approaches exist may circumvent problem. Firstly,use enforced hill-climbing (Hoffmann & Nebel, 2001) rather greedy best-first searchlikely avoid exploration entire local minima: approach, breadth-first searchconducted first state minima/plateau improving state found. Secondly,improved heuristic could used approximates optimal relaxed cost h+ exactly.cost minima shown Figure 8 brought independence assumptions inherentFF/add heuristic, estimate relaxed cost goal fact individually cheapestpossible way. optimal relaxed plan, however, costs left task right task.accurate approximation optimal relaxed cost h+ could therefore mitigate describedcost minima. Keyder Geffner (2009) recently proposed improvement FF/addheuristic4 shown particularly useful Elevators PARC Printer domains.4. Keyder & Geffners approach, relaxed plan extracted FF/add heuristic improved iteratively (1)selecting fact F, (2) fixing operators related F (because contribute achieving Frely achievement), (3) computing cheaper way achieving F given operators fixedprevious step.163fiRichter & Westphal7.2.3 Plateaus Due Capacity Constraintsgeneral, relaxed plans Elevators domain often bad quality. One reasonsway capacity elevators encoded operators passengers boarding leavingelevators. passenger p transported elevator e, one preconditions p leaving en passengers boarded e, n number greater 0. constructing relaxedplan, FF/add heuristic recursively selects operators achieve necessary preconditioncheapest way. results boarding passenger closest e initial state, evenpassenger p0 different p, achieve condition passenger boarded.relaxed plan contain operators boarding p p0 e, may furthermorecontain operators boarding p0 whatever elevator e0 deemed best transporting p0 .Hence, relaxed plans often contain many unnecessary boarding operators.mentioned Section 3.3, greedy best-first search LAMA breaks ties equallypromising operators trying cheaper operator first. Consequently, zero-cost operatorspassengers boarding leaving elevators tried first state. found soon onepassenger boarded certain elevator, relaxed plans next state often substantiallydifferent, passengers assigned elevator. explainedfact soon one passenger elevator, precondition leaving elevatorleast one person boarded, fulfilled (rather incurring additional cost).example tasks examined, found effect results committing bad boardingoperators: LAMA may initially try bad boarding operator, e. g. boarding nearest passengerelevator satisfy capacity precondition another passenger, described above.relaxed plan successor state assigns passengers elevator, lower cost. Dueimproved heuristic value successor state, LAMA retains plan prefix, even thoughfirst operator bad one. plausible (though explore experimentally)effect stronger configurations involving cost-sensitive heuristic, costsrelaxed plans vary strongly one state next.importantly, capacity constraints lead plateaus search space, correct boarding leaving operators often recognised good operators. example, capacityelevator c, boarding first c 1 passengers need transported elevatorusually leads improved heuristic values. However, boarding c-th passenger resultstate better heuristic value passengers need transported viaelevator, c-th passenger boarding destroys precondition mustroom elevator passengers board. Similarly, correct leaving passenger maylead improved heuristic value makes elevator empty passengers needtransported elevator later (because last passenger leaving destroys preconditionleaving must least one passenger boarded).effects exist cost-sensitive cost-unaware heuristic. However,typically occur within plateaus (F) local minima (Fc , F+c ) created elevator positions,described previous section, means affect cost-sensitive configurationsseverely. plateaus become particularly large several passengers waitingfloor, e. g. passengers accumulating floor shared two blocks order switchelevators. planner tries board possible subsets people available elevators (aszero-cost boarding leaving operators always tried first), moving elevators evendropping passengers floors, may still fail find state better heuristic value.164fiThe LAMA Planner: Guiding Cost-Based Anytime Planning LandmarksFirst plansFinal plansFcF+cFcF+cSolved15161516Original tasksqual. > F qual. < F31051001556capacity constraintsSolved qual. > F qual. < F291763022329920301511Table 6: Relative qualities solutions original Elevators domain modified variantdomain elevators unlimited capacity. Shown total number tasks solvedcost-sensitive configurations Fc F+c , well number tasks configurations find better/worse plan cost-unaware configuration F.examining number states local minima configurations, foundFc F+c indeed encounter many states F. example, percentage casesstate worse best known state typically around 10% (in rare cases 25%) F.Fc F+c , hand, numbers usually 35%, often 50%,large problems even 80%.verify capacity constraints indeed contribute bad performance costsensitive heuristic domain, removed constraints IPC tasks ranresulting problems F, Fc F+c configurations. surprisingly, tasks become mucheasier solve, elevators transport passengers once. interestingly though,bad plan qualities produced cost-sensitive configurations (relative cost-unawareconfiguration) indeed become much less frequent, Table 6 shows.summary, findings suggest bad performance cost-sensitive FF/add heuristicElevators domain due bad-quality relaxed plans (brought focus slowelevators capacity constraints) plateaus local minima search space (resultingmovement costs elevators capacity constraints).7.3 PARC PrinterPARC Printer domain (Do, Ruml, & Zhou, 2008) models operation multi-engine printercapable processing several printing jobs time. sheet must printed needs passseveral printer components starting feeder travelling transporters,printing engines possibly inverters ending finishing tray. various sheetsbelonging print job must arrive correct order finisher tray, may travelalong different paths using various printing engines. colour printing engines onesprint black white, colour printing expensive. action costs operatorscomparatively large, ranging 2000 200,000. Colour-printingexpensive operator, operators printing black white cost roughly half much,operators transporting sheets relatively cheap.Like Elevators domain, cost-sensitive FF/add heuristic perform well here,Fc F+c failing solve many tasks cost-unaware configuration F ablesolve. (Note Fc F+c perform similarly domain, large action costs outweigh distance estimates F+c .) However, contrast Elevators domain, Fc F+cconfigurations result notably improved plan quality compared F. overview number165fiRichter & WestphalTasks solved 30Avg. quality first solutionAvg. quality final solutionF250.790.96F+c161.001.00FL240.931.00FL+c230.950.99Table 7: Coverage vs. quality PARC Printer domain. Average qualities average IPC scorescalculated tasks solved configurations.problems solved average quality first solutions shown Table 7. using landmarks, differences cost-sensitive cost-unaware configurations strongly reduced,three landmark configurations achieving better performance F configuration.Like Elevators, found quality relaxed plans poor. cost-unaware case,relaxed plan transports sheets feeder finishing tray via shortest path, irrespectivewhether suitable printing engine lies path. path feeder finishing traypasses printing engine, frequently involves printing wrong image paper,additional operators relaxed plan handle transportation feeder suitableprinting engine print correct image sheet well. cost-sensitive heuristicused, relaxed plans furthermore become substantially longer, using many transportation operatorsreach cheap printing engine. Analogously Elevators domain, increased complexityassociated longer plans (in combination bad quality relaxed plans) thuslikely reason bad performance cost-sensitive heuristic. However, landmarksmitigate problem, numbers solved tasks Table 7 clearly show. Landmarks founddomain encompass printing correct image sheet, disjunctivelandmark denotes possible printers sheet. helps counteract tendenciescost-sensitive FF/add heuristic transport sheets wrong printers.summary, PARC Printer like Elevators domain cost-sensitive FF/add heuristicperforms badly, though contrast Elevators problem purely one coverage, solution quality. Even Elevators, landmarks overcome problems cost-sensitiveconfigurations, improving similar performance levels cost-unaware configurations.7.4 Cyber SecurityCyber Security domain stands domain cost-sensitive configurations performsignificantly better cost-unaware counterparts, especially looking first solutions.(Iterative search reduces gap, close completely.) domain models vulnerabilities computer networks insider attacks (Boddy, Gohde, Haigh, & Harp, 2005). taskconsists gaining access sensitive information using various malware programs physicallyaccessing computers offices. Action costs model likelihood attack fail, i. e., riskexposed. example, many actions office attacker, like using computer,involve cost, whereas entering offices moderately costly, directly instructingpeople install specific software high associated cost. particular, action costs usedmodel desire finding different methods attack setting. example, severaltasks domain differ costs associate certain operators.Cyber Security domain, taking action costs account pays notably: FcF+c configurations solve 2 1 problems less, respectively, F configuration (see Table 2),166fiThe LAMA Planner: Guiding Cost-Based Anytime Planning LandmarksIPC score first solutionsIPC score final solutionsF20.4423.12FL20.4325.93F+c23.6724.69FL+c26.6027.53Table 8: IPC scores Cyber security domain.nevertheless result better total score. Using landmarks, cost-sensitive configurationsimproved solve problems maintaining high quality solutions,resulting even larger performance gap FLc (27.59 points) FL+c (26.60 points)one side, FL (20.43 points) side.plans found cost-unaware search often involve physically accessing computersoffices sending viruses email, result large cost. Lower costsachieved complex plans making sophisticated use software. opposed ElevatorsPARC Printer domains, relaxed plans Cyber Security good quality.explains performance cost-sensitive heuristic negatively impacted longerplans. Using iterative search improves performance FL F nearly levelscost-sensitive counterparts (see Table 8).7.5 OpenstacksOpenstacks domain models combinatorial optimisation problem minimum maximum simultaneous open stacks (Fink & Vo, 1999; Gerevini, Haslum, Long, Saetti, & Dimopoulos, 2009),task minimise storage space needed manufacturing facility. manufacturer receives number orders, comprising number products. one productmade time, manufacturer always produce total required quantity product(over orders) beginning production different product. time first product order produced time products order produced,order said open requires stack (a temporary storage space). problem consistsordering products maximum number stacks open time minimised.easy find solution problem (any product order solution, requiring nstacks worst case n number orders), finding optimal solution NP-hard.minimisation aspect modelled planning tasks via action costs, operatoropening new stacks cost 1, operators zero cost. domainpreviously used IPC 2006 (Gerevini et al., 2009). earlier formulation domainunit costs, equivalent cost formulation described above. Since number operators open stacks every plan given task, minimising plan lengthequivalent minimising action costs.noticed domain using landmarks resulted plans substantially worse quality,compared using landmarks. particular, true first plans found, whereasuse anytime search improves results configurations similar levels. Across costsettings, using landmark heuristic combination FF/add heuristic typically producesplans majority orders started early, resulting large number simultaneously open stacks, whereas using FF/add heuristic leads plans productscorresponding open orders manufactured earlier, starting new orders delayedearlier orders shipped. mainly due fact landmarks found167fiRichter & Westphal50004500F+cFL+cExpanded Nodes4000350030002500200015001000500051015Tasks202530Figure 9: Number expanded search nodes without landmarks first search iteration(best-first search) Openstacks domain.LAMA regarding opening stacks, means due choice action costsdomain, landmarks cost zero landmark heuristic able distinguishplans different cost. landmarks found LAMA relate starting shipping orderswell making products.5 However, even landmarks regarding opening stacksfound, would helpful: landmarks state certain things must achieved,certain things need achieved. Landmarks thus used limit numberopen stacks. landmark orderings furthermore helpful deciding orderproducts, product orders possiblewhich means natural orderings existcorresponding landmarksand product order results form wasted effort capturedreasonable landmark orderings.mentioned above, landmarks found LAMA minimal cost zero. Therefore,landmark heuristic fails estimate cost goal, distinguishes states vianumber missing started shipped orders products. (These goal distance estimates useddirectly FL, combined all-zero landmark heuristic cost estimates FL+c , tiebreakers amongst zero-cost estimates FLc , resulting relative ranking stateslandmark heuristic three cases.) soon one stack open, order operatorstarts achieves landmark minimal respect landmark orderings (namelylandmark stating must started), planner thus tends start orders soon possible.landmark heuristic able take account future costs arise bad productorderings. also problem FF/add heuristic, albeit less severe one: FF/addheuristic accounts cost opening (exactly) one new stack whenever least one stackneeded, heuristic thus prefer states require stacks.landmark heuristic does, however, provide good estimate goal distance. Sincelandmark heuristic prefers states closer goal state regard costs, use results5. size disjunctions limited LAMA, would always find landmark stacks avail(1)stacks avail(2) stacks avail(n) stating least one n stacks must open point. However, landmark stating two stacks need open would require complex form landmarksinvolving conjunction, LAMA cannot handle.168fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarks1Plan Quality0.80.60.40.20F+cFL+c51015Tasks202530Figure 10: Plan quality (measured via IPC scores) without landmarks first searchiteration (best-first search) Openstacks domain.150454035Cost 302520151050 10Plan Quality0.80.60.40.20F+cFL+c100Time (seconds)51015Tasks20251000530252015 Tasks1030Figure 11: Effect iterative search Openstacks domain. Left: plan quality (IPC score)best plan found within 30 minutes without landmarks. Right: evolution plan costslandmarks (FL+c ) time.plans stacks opened needed. reflected empirical results,additional use landmark heuristic drastically reduces number expanded search nodes(see Figure 9), leads higher-cost plans (see Figure 10). Without iterative search, LAMAconfiguration FL+c achieves 13.85 points domain, compared 19.77 pointsusing landmarks (configuration F+c ).Using iterative search, negative effect landmarks quality mitigated,seen Figure 11. FL+c generates 21 distinct, time improved, plans per problem.end, difference points merely 27.40 FL+c vs. 28.30 F+c . score reachedless 5 minutes iterated search per task.Thus, Openstacks example domain landmarks detrimental solutionquality. However, using landmarks provides benefit speeding planning reducing169fiRichter & Westphalnumber expanded nodes. allows iterative search effectively improve solution qualitygiven time limit final results using landmarks similar usinglandmarks.7.6 Domains Previous CompetitionsTables 9 10 show results IPC domains previous years (19982006). domains contain action costs, cost-sensitive configurations LAMA applicableLAMA runs FL configuration. configurations examined LAMA thus FLF, iterated search without, FL iterated search shown LAMA. Alsogiven results two IPC-winning systems previous years, FF Fast Downward.FF Fast Downward, ran current versions. particular Fast Downward evolvedsubstantially since 2004 competition version, original causal graph heuristicreplaced better context-enhanced additive heuristic (Helmert & Geffner, 2008). correspondence authors, version Fast Downward used one featuring recentwork Richter Helmert (2009).Table 9 shows, LAMA performs better FF Fast Downward termsIPC 2008 criterion. true even turn landmarks iterated search LAMA,turn options simultaneously. viewing large differencescores iterated versus non-iterated search LAMA, note domains best knownreference results used score calculation (in contrast 2008 tasks,reference results generated manually domain-specific solvers competitionorganisers). means planner producing best solution task awardedhighest-possible score 1, even though better solutions might exist. may skew results favourplanner delivers cheaper solutions, i. e., exaggerate differences planners.Table 10 shows LAMAs edge Fast Downward due higher-quality solutions rathercoverage, Fast Downward solves problems. Compared FF, LAMA better coverage, gap LAMA FF substantially larger gap LAMAFast Downward. Note F LAMA configurations roughly correspond resultspublished base heur earlier work (Richter et al., 2008). However, subsequent changescode support action costs negatively affect particular Philosophers domain,observe significant decrease coverage. also one reasons differencecoverage LAMA closely related Fast Downward system.Comparing various experimental configurations LAMA, note use landmarks leads moderate improvements coverage solution quality. mentioned above,iterative search significantly improves performance terms IPC 2008 score.8. Conclusion Outlookarticle, given detailed account LAMA planning system. system usestwo heuristic functions multi-heuristic state-space search: cost-sensitive version FFheuristic, landmark heuristic guiding search towards states many subgoalsalready achieved. Action costs employed heuristic functions guide searchcheap goals rather close goals, iterative search improves solution quality timeremains.170fiThe LAMA Planner: Guiding Cost-Based Anytime Planning LandmarksDomainFFF. Downw.LAMAFFLfirstFfirstAirport (50)Assembly (30)Blocks (35)Depot (22)Driverlog (20)Freecell (80)Grid (5)Gripper (20)Logistics 1998 (35)Logistics 2000 (28)Miconic (150)Miconic Full ADL (150)Miconic Simple ADL (150)Movie (30)MPrime (35)Mystery (30)Openstacks (30)Optical Telegraphs (48)Pathways (30)Philosophers (48)Pipesworld Notank. (50)Pipesworld Tank. (50)PSR Small (50)Rovers (40)Satellite (36)Schedule (150)Storage (30)TPP (30)Trucks (30)Zenotravel (20)Total (1512)PSR Large (50)PSR Middle (50)3529302013694203528150124140302814291219112516413835991623101911623928171314664153325118951053034182942848312849353013216261317114326403530331619735203428150136148303519292282943365039331471930131913302850333034152075520332814313615030331630227344238503931139202916201318164135292213166242033281501071173031182922829262749373213716281218118522373329171215654183228117107113302914302273427284937271291827151811291435Table 9: Performance scores (rounded whole numbers) FF, Fast Downward LAMAwell experimental alternative configurations LAMA (F: without landmarks, FLfirst : withoutiterated search, Ffirst : without landmarks without iterated search).171fiRichter & WestphalDomainFFF. Downw.LAMAFAirport (50)Assembly (30)Blocks (35)Depot (22)Driverlog (20)Freecell (80)Grid (5)Gripper (20)Logistics 1998 (35)Logistics 2000 (28)Miconic (150)Miconic Full ADL (150)Miconic Simple ADL (150)Movie (30)MPrime (35)Mystery (30)Openstacks (30)Optical Telegraphs (48)Pathways (30)Philosophers (48)Pipesworld Notank. (50)Pipesworld Tank. (50)PSR Small (50)Rovers (40)Satellite (36)Schedule (150)Storage (30)TPP (30)Trucks (30)Zenotravel (20)Total (1512)PSR Large (50)PSR Middle (50)3730312215805203528150136150303416301320133621414036133182811201279403035192079520352815013915030351930529484338503935150183015201384315036303517207952035281501371503035193022929443850403415019301320135429503430351620785203528150138150303516302283443405040311442030162013481641Table 10: Coverage (problems solved) FF, Fast Downward LAMA well experimental F configuration LAMA without landmarks.172fiThe LAMA Planner: Guiding Cost-Based Anytime Planning Landmarksconducted extensive experimental study set benchmark taskslast international planning competition, order identify much featuresplanner contributes performance setting planning action costs. discussedoverall results provided plausible explanations deviating behaviour special cases.noticeable outcome experiments using cost-sensitive heuristicsproduce desired outcome. particular, cost-sensitive FF/add heuristic performs significantlyworse FF/add heuristic ignores costs. due cost-sensitive heuristic solvingfar fewer tasks leading little improvement solution quality tasks solve,especially using iterated search. investigating reasons effect, foundcost-sensitive FF/add heuristic reacts strongly bad relaxed plans, i. e., particulardomains relaxed plans computed heuristic low quality costsensitive heuristic likely perform worse cost-unaware heuristic. showedElevators domain, action costs may also introduce local minima search space withoutaction costs search space FF/add heuristic would plateaus. Moreover, increasedcomplexity planning cheaper goal potentially away initial state maylead worse performance.Landmarks prove helpful context, mitigate problems costsensitive FF/add heuristic. Using landmarks, coverage cost-sensitive search improvednearly level cost-unaware search, deteriorating solution quality. Despitemitigating effect landmarks, however, LAMA would still achieved slightly higherscore IPC 2008 simply ignored costs, rather using cost-sensitive heuristics.cost-unaware search, found landmarks improve coverage solution quality domainsIPCs 19982006. domains IPC 2008, landmarks improved solution qualitycost-unaware search, increase (already high) coverage.Iterative search improves results notably experimental configurations, raisingscore LAMA quarter IPC 2008 domains. Openstacks domain, couldfurthermore observe synergy effect iterative search landmarks. landmarksusually improve quality, domain lead bad plans accounting action costs.However, speed planning planner evaluates substantially fewer states. Iterativesearch effectively improves initial bad plans benefiting speed-up providedlandmarks. general, use landmarks means quickly find good solutions,using iterative search way improve plan quality time. Overall, found domainsused IPC 2008 constitute varied benchmark set reveals various strengths weaknessesplanning system.Building results presented article, identify several directions future work.Firstly, results suggest research cost-sensitive heuristics needed. wouldlike conduct thorough analysis short-comings cost-sensitive FF/add heuristic, answer question whether might overcome. Keyder Geffner (2009)propose method extracting better relaxed plans best supports computed costsensitive FF/add heuristic, resulting improved coverage. However, large ledge costunaware heuristic experiments suggests cost-unaware FF/add heuristic still better improved cost-sensitive heuristic Keyder Geffner. would interestingexamine degree problems experienced FF/add heuristic extenddelete-relaxation heuristics, whether heuristics based delete relaxation couldeffectively adapted action costs. addition, future work could explore benefit combin173fiRichter & Westphaling traditional distance estimators cost-sensitive heuristics sophisticated waysmechanism currently used LAMA (see discussion Section 3.3.2).Secondly, believe useful future research improve definition reasonableorderings, eliminating problems definition Hoffmann et al. mentioned Section 4.1.Thirdly, would like extend use landmarks system several ways. one,current approach take account whether landmark must achieved severaltimes. Supporting multiple occurrences landmarks would beneficial Openstacksdomain, example, could help minimise creation stacks accountingcosts. methods exist detecting multiplicity landmarks (Porteous & Cresswell, 2002;Zhu & Givan, 2003), crucial develop techniques deriving orderingsindividual occurrences landmarks. Furthermore, would like extend LAMA supportcomplex landmarks like conjunctions simple formulas. addition representingusing landmarks landmark heuristic involves development new methodsdetecting along corresponding orderings.Acknowledgmentsauthors thank Malte Helmert, Charles Gretton, Sylvie Thiebaux Patrik Haslum wellanonymous reviewers helpful feedback earlier drafts paper.computing resources experiments graciously provided Pompeu Fabra University. thank Hector Palacios support conducting experiments.NICTA funded Australian Government, represented Department Broadband, Communications Digital Economy, Australian Research Council,ICT Centre Excellence program.work partially supported Deutsche Forschungsgemeinschaft part Transregional Collaborative Research Center SFB/TR 8 Spatial Cognition, project R4-[LogoSpace].ReferencesAine, S., Chakrabarti, P. P., & Kumar, R. (2007). AWA* window constrained anytime heuristic search algorithm. Veloso, M. M. (Ed.), Proceedings 20th International JointConference Artificial Intelligence (IJCAI 2007), pp. 22502255.Bacchus, F. (2001). AIPS00 planning competition. AI Magazine, 22(3), 4756.Backstrom, C., & Nebel, B. (1995). Complexity results SAS+ planning. Computational Intelligence, 11(4), 625655.Boddy, M., Gohde, J., Haigh, T., & Harp, S. (2005). Course action generation cyber securityusing classical planning. Biundo, S., Myers, K., & Rajan, K. (Eds.), ProceedingsFifteenth International Conference Automated Planning Scheduling (ICAPS 2005),pp. 1221. AAAI Press.Bonet, B., & Geffner, H. (2001). Planning heuristic search. Artificial Intelligence, 129(1), 533.Bryce, D., & Kambhampati, S. (2007). tutorial planning graph based reachability heuristics.AI Magazine, 28(1), 4783.174fiThe LAMA Planner: Guiding Cost-Based Anytime Planning LandmarksBuffet, O., & Hoffmann, J. (2010). glitters gold: Using landmarks reward shapingFPG. Proceedings ICAPS 2010 Workshop Planning SchedulingUncertainty.Chen, Y., Wah, B. W., & Hsu, C.-W. (2006). Temporal planning using subgoal partitioningresolution SGPlan. Journal Artificial Intelligence Research, 26, 323369.Cheng, J., & Irani, K. B. (1989). Ordering problem subgoals. Sridharan, N. S. (Ed.), Proceedings11th International Joint Conference Artificial Intelligence (IJCAI 1989), pp. 931936. Morgan Kaufmann.Do, M. B., & Kambhampati, S. (2003). Sapa: scalable multi-objective heuristic metric temporalplanner. Journal Artificial Intelligence Research, 20, 155194.Do, M. B., Ruml, W., & Zhou, R. (2008). On-line planning scheduling: application controlling modular printers. Proceedings Twenty-Third AAAI Conference ArtificialIntelligence (AAAI 2008), pp. 15191523. AAAI Press.Edelkamp, S., & Hoffmann, J. (2004). PDDL2.2: language classical part 4thInternational Planning Competition. Tech. rep. 195, Albert-Ludwigs-Universitat Freiburg,Institut fur Informatik.Fink, A., & Vo, S. (1999). Applications modern heuristic search methods pattern sequencingproblems. Computers Operations Research, 26(1), 1734.Fox, M., & Long, D. (2003). PDDL2.1: extension PDDL expressing temporal planningdomains. Journal Artificial Intelligence Research, 20, 61124.Fuentetaja, R., Borrajo, D., & Linares Lopez, C. (2009). unified view cost-based heuristics.ICAPS 2009 Workshop Heuristics Domain-Independent Planning, pp. 7077.Gerevini, A., Haslum, P., Long, D., Saetti, A., & Dimopoulos, Y. (2009). Deterministic planningfifth international planning competition: PDDL3 experimental evaluationplanners. Artificial Intelligence, 173(56), 619668.Gerevini, A., & Serina, I. (2002). LPG: planner based local search planning graphsaction costs. Ghallab, M., Hertzberg, J., & Traverso, P. (Eds.), Proceedings SixthInternational Conference Artificial Intelligence Planning Scheduling (AIPS 2002), pp.1322. AAAI Press.Gregory, P., Cresswell, S., Long, D., & Porteous, J. (2004). extraction disjunctive landmarks planning problems via symmetry reduction. Proceedings Fourth International Workshop Symmetry Constraint Satisfaction Problems, pp. 3441.Hansen, E. A., & Zhou, R. (2007). Anytime heuristic search. Journal Artificial IntelligenceResearch, 28, 267297.Hansen, E. A., Zilberstein, S., & Danilchenko, V. A. (1997). Anytime heuristic search: First results.Technical report cmpsci 97-50, University Massachusetts, Amherst.Helmert, M. (2006). Fast Downward planning system. Journal Artificial Intelligence Research, 26, 191246.Helmert, M. (2009). Concise finite-domain representations PDDL planning tasks. ArtificialIntelligence, 173, 503535.175fiRichter & WestphalHelmert, M., Do, M., & Refanidis, I. (2008). IPC 2008, deterministic part. Web site, http://ipc.informatik.uni-freiburg.de.Helmert, M., & Geffner, H. (2008). Unifying causal graph additive heuristics. Rintanen,J., Nebel, B., Beck, J. C., & Hansen, E. (Eds.), Proceedings Eighteenth InternationalConference Automated Planning Scheduling (ICAPS 2008), pp. 140147. AAAI Press.Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generation heuristicsearch. Journal Artificial Intelligence Research, 14, 253302.Hoffmann, J., Porteous, J., & Sebastia, L. (2004). Ordered landmarks planning. JournalArtificial Intelligence Research, 22, 215278.Irani, K. B., & Cheng, J. (1987). Subgoal ordering goal augmentation heuristic problemsolving. McDermott, J. P. (Ed.), Proceedings 10th International Joint ConferenceArtificial Intelligence (IJCAI 1987), pp. 10181024. Morgan Kaufmann.Jonsson, P., & Backstrom, C. (1998). State-variable planning structural restrictions: Algorithms complexity. Artificial Intelligence, 100(12), 125176.Karpas, E., & Domshlak, C. (2009). Cost-optimal planning landmarks. Proceedings21st International Joint Conference Artificial Intelligence (IJCAI 2009), pp. 17281733.Keyder, E., & Geffner, H. (2008). Heuristics planning action costs revisited. Proceedings18th European Conference Artificial Intelligence (ECAI 2008), pp. 588592.Keyder, E., & Geffner, H. (2009). Trees shortest paths vs. Steiner trees: Understanding improving delete relaxation heuristics. Proceedings 21st International Joint ConferenceArtificial Intelligence (IJCAI 2009), pp. 17341749.Keyder, E., Richter, S., & Helmert, M. (2010). Sound complete landmarks and/or graphs.Coelho, H., Studer, R., & Wooldridge, M. (Eds.), Proceedings 19th European Conference Artificial Intelligence (ECAI 2010), pp. 335340.Koehler, J., & Hoffmann, J. (2000). reasonable forced goal orderings useagenda-driven planning algorithm. Journal Artificial Intelligence Research, 12, 338386.Likhachev, M., Ferguson, D., Gordon, G. J., Stentz, A., & Thrun, S. (2008). Anytime searchdynamic graphs. Artificial Intelligence, 172(14), 16131643.Likhachev, M., Gordon, G. J., & Thrun, S. (2004). ARA*: Anytime A* provable boundssub-optimality. Thrun, S., Saul, L. K., & Scholkopf, B. (Eds.), Advances NeuralInformation Processing Systems 16 (NIPS 2003).Lipovetzky, N., & Geffner, H. (2009). Inference decomposition planning using causal consistent chains. Gerevini, A., Howe, A., Cesta, A., & Refanidis, I. (Eds.), ProceedingsNineteenth International Conference Automated Planning Scheduling (ICAPS 2009).AAAI Press.Liu, Y., Koenig, S., & Furcy, D. (2002). Speeding calculation heuristics heuristicsearch-based planning. Proceedings Eighteenth National Conference ArtificialIntelligence (AAAI 2002), pp. 484491. AAAI Press.Pohl, I. (1970). Heuristic search viewed path finding graph. Artificial Intelligence, 1, 193204.176fiThe LAMA Planner: Guiding Cost-Based Anytime Planning LandmarksPorteous, J., & Cresswell, S. (2002). Extending landmarks analysis reason resourcesrepetition. Proceedings 21st Workshop UK Planning Scheduling SpecialInterest Group (PLANSIG 02), pp. 4554.Porteous, J., Sebastia, L., & Hoffmann, J. (2001). extraction, ordering, usage landmarks planning. Cesta, A., & Borrajo, D. (Eds.), Pre-proceedings Sixth EuropeanConference Planning (ECP 2001), pp. 3748, Toledo, Spain.Richter, S., & Helmert, M. (2009). Preferred operators deferred evaluation satisficing planning. Gerevini, A., Howe, A., Cesta, A., & Refanidis, I. (Eds.), Proceedings Nineteenth International Conference Automated Planning Scheduling (ICAPS 2009), pp.273280. AAAI Press.Richter, S., Helmert, M., & Westphal, M. (2008). Landmarks revisited. ProceedingsTwenty-Third AAAI Conference Artificial Intelligence (AAAI 2008), pp. 975982. AAAIPress.Richter, S., Thayer, J. T., & Ruml, W. (2010). joy forgetting: Faster anytime search viarestarting. Brafman, R., Geffner, H., Hoffmann, J., & Kautz, H. (Eds.), ProceedingsTwentieth International Conference Automated Planning Scheduling (ICAPS 2010).AAAI Press. appear.Roger, G., & Helmert, M. (2010). more, merrier: Combining heuristic estimators satisficing planning. Brafman, R., Geffner, H., Hoffmann, J., & Kautz, H. (Eds.), ProceedingsTwentieth International Conference Automated Planning Scheduling (ICAPS2010), pp. 246249. AAAI Press.Ruml, W., & Do, M. B. (2007). Best-first utility-guided search. Veloso, M. M. (Ed.), Proceedings20th International Joint Conference Artificial Intelligence (IJCAI 2007), pp. 23782384.Sebastia, L., Onaindia, E., & Marzal, E. (2006). Decomposition planning problems. AI Communications, 19(1), 4981.Vidal, V. (2004). lookahead strategy heuristic search planning. Zilberstein, S., Koehler, J.,& Koenig, S. (Eds.), Proceedings Fourteenth International Conference AutomatedPlanning Scheduling (ICAPS 2004), pp. 150159. AAAI Press.Zhou, R., & Hansen, E. A. (2005). Beam-stack search: Integrating backtracking beam search.Biundo, S., Myers, K., & Rajan, K. (Eds.), Proceedings Fifteenth InternationalConference Automated Planning Scheduling (ICAPS 2005), pp. 9098. AAAI Press.Zhu, L., & Givan, R. (2003). Landmark extraction via planning graph propagation. ICAPS 2003Doctoral Consortium, pp. 156160.177fiJournal Artificial Intelligence Research 39 (2010) 269 - 300Submitted 04/10; published 09/10Case-Based Subgoaling Real-Time Heuristic SearchVideo Game PathfindingVadim BulitkoBULITKO @ UALBERTA . CADepartment Computing Science, University AlbertaEdmonton, Alberta, T6G 2E8, CANADAYngvi BjornssonYNGVI @ RU .School Computer Science, Reykjavik UniversityMenntavegi 1, IS-101 Reykjavik, ICELANDRamon LawrenceRAMON . LAWRENCE @ UBC . CAComputer Science, University British Columbia Okanagan3333 University Way, Kelowna, British Columbia, V1V 1V7, CANADAAbstractReal-time heuristic search algorithms satisfy constant bound amount planning peraction, independent problem size. result, scale well problems become larger.property would make well suited video games Artificial Intelligence controlled agents must react quickly user commands agents actions. downside,real-time search algorithms employ learning methods frequently lead poor solution qualitycause agent appear irrational re-visiting problem states repeatedly.situation changed recently new algorithm, LRTA*, attempted eliminate learning automatically selecting subgoals. LRTA* well poised video games, exceptcomplex memory-demanding pre-computation phase builds databasesubgoals. paper, propose simpler memory-efficient way pre-computingsubgoals thereby eliminating main obstacle applying state-of-the-art real-time search methods video games. new algorithm solves number randomly chosen problems off-line,compresses solutions series subgoals stores database. presentednovel problem on-line, queries database similar previously solved caseuses subgoals solve problem. domain pathfinding four large video gamemaps, new algorithm delivers solutions eight times better using 57 times less memoryrequiring 14% less pre-computation time.1. IntroductionHeuristic search core area Artificial Intelligence (AI) research algorithmswidely used planning, game-playing agent control. paper interested realtime heuristic search algorithms satisfy constant upper bound amount planningper action, independent problem size. property important number applicationsincluding autonomous robots agents video games. common problem video gamessearching path two locations. games, agents expected act quicklyresponse players commands agents actions. result, many game companiesimpose constant time limit amount path planning per move (e.g., one millisecondsimultaneously moving agents).c2010AI Access Foundation. rights reserved.fiB ULITKO , B J ORNSSON , & L AWRENCEpractice time limit satisfied limiting problem size priori, scientificallyinteresting approach impose time per-move limit regardless problem size.severely limits range applicable heuristic search algorithms. instance, static searchalgorithms A* (Hart, Nilsson, & Raphael, 1968), IDA* (Korf, 1985) PRA* (Sturtevant & Buro, 2005; Sturtevant, 2007), re-planning algorithms D* (Stenz, 1995), anytimealgorithms ARA* (Likhachev, Gordon, & Thrun, 2004) anytime re-planning algorithmsAD* (Likhachev, Ferguson, Gordon, Stentz, & Thrun, 2005) cannot guarantee constantbound planning time per action. produce complete, possibly abstract, solution first action taken. problem increases size, planningtime inevitably increase, exceeding priori finite upper bound.Real-time search addresses problem fundamentally different way. Instead computingcomplete, possibly abstract, solution first action taken, real-time search algorithmscompute (or plan) first actions agent take. usually done conductinglookahead search fixed depth (also known search horizon, search depth lookaheaddepth) around agents current state using heuristic (i.e., estimate remainingtravel cost) select next actions. actions taken planning-executioncycle repeats (Korf, 1990). Since goal state seen local searches, agentruns risks selecting suboptimal actions. address problem, real-time heuristic searchalgorithms update (or learn) heuristic function time.learning process precluded real-time heuristic search agents widely deployed pathfinding video games. problem agents tend scrub (i.e., repeatedly re-visit) state space due need fill heuristic depressions (Ishida, 1992). result,solution quality quite low and, visually, scrubbing behavior perceived irrational.Since seminal work LRTA* (Korf, 1990), researchers attempted speedlearning process. briefly describe efforts related work section. Here, notevarious approaches brought improvements, breakthrough performanceachieved virtually eliminating learning process LRTA* (Bulitko, Lustrek, Schaeffer,Bjornsson, & Sigmundarson, 2008). done computing heuristic respectnear-by subgoal distant goal. Offline, LRTA* constructs high-level graph regions usingstate abstractions, calculates optimal paths region pairs, stores subgoalsstates paths cross region boundaries. online search, LRTA* consultsdatabase find next subgoal respect current goal regions. Since heuristicfunctions usually relax problem (e.g., Euclidean distance heuristic ignores obstaclesmap), tend accurate closer goal. result, heuristic function respectnear-by goal tends accurate and, therefore, requires less adjustment (i.e., learning).Consequently, solution quality improved scrubbing behavior reduced.paper, adapt idea subgoaling make following four contributions. First,simplify pre-processing step LRTA*. Instead using state abstraction select subgoals, employ nearest-neighbour algorithm database solved cases. Second, introduce idea compressing solution path series subgoals easilyreached previous one. so, use hill-climbing proxy notion easyreachability LRTA*. Third, employ kd-trees order access case base effectively.Finally, evaluate new algorithm empirically large-scale problem spaces.new algorithm called k Nearest Neighbor LRTA* (or kNN LRTA*) and, restpaper, set k = 1. paper extends previous conference publication (Bulitko & Bjornsson,270fiC ASE -BASED UBGOALING R EAL -T IME H EURISTIC EARCH2009) following ways. store multiple goals per path reduce number database accesses use kd-trees speed database access. Additionally, make optimizationson-line component kNN LRTA*: evaluating small number similar databaseentries, interrupting LRTA* starts learning excessively engaging start end path optimizations. empirical evaluation side, use native multi-million state static video gamemaps compare algorithm newly published state-of-the-art non-learning real-time searchalgorithm (Bjornsson, Bulitko, & Sturtevant, 2009).rest paper organized follows. Sections 2 3 formulate problemreal-time heuristic search show core LRTA* algorithm extended subgoalselection. Section 4 analyzes related research. Section 5 provides intuition new algorithmfollowing details pseudocode Section 6. Section 7 give theoretical analysis and,Section 8, empirically evaluate algorithm domain pathfinding. Section 9 summarizesempirical results. conclude discussion current shortcomings future work.2. Problem Formulationdefine heuristic search problem directed graph containing finite set states (vertices)weighted edges, single state designated goal state. every time step, searchagent single current state, vertex search graph, takes action (or makes move)traversing out-edge current state. traversing edge states s1 s2agent changes current state s1 s2 . say state visited agentagents current state point time. usual field real-timeheuristic search, assume path planning happens moves (i.e., agentthink traversing edge). plan move - travel edge loop continues agentarrives goal state, thereby solving problem.edge positive cost associated it. total cost edges traversed agentstart state arrives goal state called solution cost. require algorithmscomplete (i.e., produce path start goal finite amount time path exists).order guarantee completeness real-time heuristic search make assumption safeexplorability search problems. Specifically, costs finite states s1 , s2 , s3 ,path s1 s2 path s1 s3 also paths2 s3 .Formally, algorithms discussed paper applicable heuristic search problem. keep presentation focused intuitive well afford large-scale empiricalevaluation, use particular type heuristic search problem, pathfinding grid worlds,rest paper. discuss applicability new methods suggest heuristicsearch general planning problems Section 11.video-game map settings, states vacant square grid cells. cell connected fourcardinally (i.e., west, north, east, south) four diagonally neighboring cells. Outbound edgesvertex moves available corresponding cell rest paper useterms action move interchangeably. edge costs defined 1 cardinal moves 1.4diagonal moves.1agent plans next action considering states local search space surroundingcurrent position. heuristic function (or simply heuristic) estimates (remaining) travel cost1. use 1.4 instead Euclidean2 avoid errors floating point computations.271fiB ULITKO , B J ORNSSON , & L AWRENCEstate goal. used agent rank available actions selectpromising one. paper consider admissible consistent heuristic functionsoverestimate actual remaining cost goal whose difference values twostates exceed cost optimal path states. paper use octiledistance minimum cumulative edge cost two vertices ignoring map obstaclesheuristic. heuristic admissible consistent uses 1 1.4 edge costs. agentmodify heuristic function state avoid getting stuck local minima heuristicfunction, well improve action selection experience.defining property real-time heuristic search amount planning agentper action upper bound depend total number states problemspace. Fast planning preferred guarantees agents quick reaction new goal specification. measure mean planning time per action terms CPU time. use numberstates expanded CPU-independent measure time algorithms evaluatedpaper frequently perform time-consuming operations expanding states. Also notetotal planning time per problem important non-real-time search, irrelevant videogame pathfinding compute entire path outright.second performance measure study sub-optimality defined ratiolution costfound agent (c) minimum solution cost (c ) minus one times 100%:cc 1 100. illustrate, suboptimality 0% indicates optimal path suboptimality50% indicates path 1.5 times costly optimal path.3. LRTA*: Core Algorithmcore real-time heuristic search algorithms algorithm called Learning Real-TimeA* (LRTA*) (Korf, 1990). shown Figure 1 operates follows. long goal statesglobal goal reached, algorithm interleaves planning execution lines 4 7.generalized version added new step line 3 selecting goal sgoal (the original algorithmuses sglobal goal times). describe details subgoal selection later paper.line 4, cost-limited breadth-first search duplicate detection used find frontier statescost gmax away current state s. frontier state s, value sumcost shortest path s, denoted g(s, s), estimated cost shortest pathsgoal (i.e., heuristic value h(s, sgoal )). state minimizes sum identified s0line 5. Ties broken favour higher g values. Remaining ties broken fixed order.heuristic value current state updated line 6 (we keep separate heuristic tablesdifferent goals never decrease heuristics). Finally, take one step towardspromising frontier state s0 line 7.LRTA* special case value iteration real-time dynamic programming (Barto, Bradtke,& Singh, 1995) problem prevented use video game pathfinding. Specifically, updates single heuristic value per move basis heuristic values near-by states.means initial heuristic values overly optimistic (i.e., low), LRTA*frequently re-visit states multiple times, time making updates small magnitude.behavior known scrubbing2 appears highly irrational observer.2. term coined Nathan Sturtevant.272fiC ASE -BASED UBGOALING R EAL -T IME H EURISTIC EARCHLRTA*(sstart , sglobal goal , gmax )12345678sstart6= sglobal goalsubgoal selected current subgoal reached select (new) subgoal sgoalgenerate successor states gmax cost, generating frontierfind frontier state s0 lowest g(s, s0 ) + h(s0 , sgoal )update h(s, sgoal ) g(s, s0 ) + h(s0 , sgoal )change one step towards s0endFigure 1: LRTA* algorithm dynamic subgoal selection.4. Related ResearchSince seminal work LRTA* described previous section, researchers attemptedspeed learning process. resulting algorithms described followingfour attributes:local search space set states whose heuristic values accessed planningstage. two common choices full-width limited-depth lookahead (Korf, 1990; Shimbo &Ishida, 2003; Shue & Zamani, 1993; Shue, Li, & Zamani, 2001; Furcy & Koenig, 2000; Hernandez& Meseguer, 2005a, 2005b; Sigmundarson & Bjornsson, 2006; Rayner, Davison, Bulitko, Anderson, & Lu, 2007) A*-shaped lookahead (Koenig, 2004; Koenig & Likhachev, 2006). Additional choices decision-theoretic based shaping (Russell & Wefald, 1991) dynamic lookahead depth-selection (Bulitko, 2004; Lustrek & Bulitko, 2006). Finally, searching smaller,abstracted state used well (Bulitko, Sturtevant, Lu, & Yau, 2007).local learning space set states whose heuristic values updated. Commonchoices are: current state (Korf, 1990; Shimbo & Ishida, 2003; Shue & Zamani, 1993; Shueet al., 2001; Furcy & Koenig, 2000; Bulitko, 2004), states within local search space (Koenig,2004; Koenig & Likhachev, 2006) previously visited states neighbors (Hernandez &Meseguer, 2005a, 2005b; Sigmundarson & Bjornsson, 2006; Rayner et al., 2007).learning rule used update heuristic values states learning space.common choices mini-min (Korf, 1990; Shue & Zamani, 1993; Shue et al., 2001;Hernandez & Meseguer, 2005a, 2005b; Sigmundarson & Bjornsson, 2006; Rayner et al., 2007),weighted versions (Shimbo & Ishida, 2003), max mins (Bulitko, 2004), modified Dijkstrasalgorithm (Koenig, 2004), updates respect shortest path current statebest-looking state frontier local search space (Koenig & Likhachev, 2006). Additionally, several algorithms learn one heuristic function (Russell & Wefald, 1991; Furcy &Koenig, 2000; Shimbo & Ishida, 2003).control strategy decides move following planning learning phases. Commonly used strategies include: first move optimal path promising frontierstate (Korf, 1990; Furcy & Koenig, 2000; Hernandez & Meseguer, 2005a, 2005b), entirepath (Bulitko, 2004), backtracking moves (Shue & Zamani, 1993; Shue et al., 2001; Bulitko,2004; Sigmundarson & Bjornsson, 2006).Given multitude proposed algorithms, unification efforts undertaken. particular, Bulitko Lee (2006) suggested framework, called Learning Real Time Search (LRTS),273fiB ULITKO , B J ORNSSON , & L AWRENCEcombine extend LRTA* (Korf, 1990), weighted LRTA* (Shimbo & Ishida, 2003), SLA* (Shue& Zamani, 1993), SLA*T (Shue et al., 2001), large extent, -Trap (Bulitko, 2004).dimensions described above, LRTS operates follows. uses full-width fixed-depth local searchspace transposition tables prune duplicate states. LRTS uses max mins learning ruleupdate heuristic value current state (its local learning space). control strategy movesagent promising frontier state cumulative volume heuristic function updatestrial user-specified quota backtracks previous state otherwise.approaches listed brought various improvements, breakthrough performance came form subgoaling. Since commonly used heuristics simplify problemhand (e.g., octile distance grid-world pathfinding ignores obstacles), using LRTA*near-by subgoals effectively increases heuristic quality thus reduces amount learning.Although general planning goal often represented conjunction simple subgoals,best knowledge, real-time heuristic search algorithm implement subgoalingLRTA* (Bulitko, Bjornsson, Lustrek, Schaeffer, & Sigmundarson, 2007; Bulitko et al., 2008).pre-processing phase, LRTA* uses clique abstraction Sturtevant Buro (2005)create smaller search graph. clique abstraction collapses set fully connected statessingle abstract state applied iteratively compute progressively smaller graphs.example, 2-level abstraction applies clique abstraction graph already abstracted once. Similarly, a-level abstraction applies clique abstraction times. assumeabstraction reduces graph constant factor , a-level abstract graph would contain times fewer states original graph. abstraction technique effect partitionsmap number regions, region corresponding single abstract state.every pair distinct abstract states, LRTA* computes optimal path correspondingrepresentative states (e.g., centroids regions) original non-abstracted space. pathfollowed exits region corresponding start abstract state. entry statenext region recorded subgoal pair abstract states. pre-processing stepfinished, LRTA* runs LRTA* given problem selects subgoal recorded currentgoal regions. off-line on-line steps illustrated Figure 2.underlying intuition reaching entry-to-the-next-region state requires LRTA*navigate within single region is, therefore, easy default heuristic function. result,LRTA* would rarely need adjust heuristic thereby virtually eliminating costly learningprocess resulting scrubbing.three key problems LRTA*. First, due fact entry states (i.e., subgoals) computed stored pair distinct regions, number regionskept relatively small. LRTA* accomplished applying clique abstractionprocedure multiple times regions become progressively larger fewer number.side effect regions longer cliques may, fact, quite complex themselves.result, LRTA* may encounter heuristic depressions within region (e.g., would actuallyhappen LRTA* tries go E right diagram Figure 2). Second, stateoriginal space needs assigned region. Since regions irregular shape, explicitmembership records must maintained. may require much additional memory storingoriginal grid-based map. Third, clique abstraction non-trivial process puts extraprogramming burden practitioners (e.g., game developers).Another recent high-performance real-time search algorithm Time-Bounded A* (TBA*)Bjornsson et al. (2009), time-bounded variant classic A*. expands states A*274fiC ASE -BASED UBGOALING R EAL -T IME H EURISTIC EARCH22222277277255555721111572115721113621133624G344446C2C1EE6666Figure 2: Example LRTA* operation. Left: off-line, map partitioned seven regions(or abstract states). vacant cell labeled region number. Center: off-line,optimal path centroids two regions (C1 C2 ) computed entrystate next region (E) recorded subgoal pair regions. Right: online, agent intends travel G, determines corresponding regionssets pre-computed entry state E subgoal.fashion using closed list open list, away original start state, towards goalgoal state expanded. However, unlike A* plans complete path committingfirst action, TBA* time-slices planning interrupting search periodically acts. Initially,complete path goal known, agent takes action moves towardspromising state open list. subsequent time slice alternative promising pathformed agent path, backtracks steps necessary. interleavingplanning, acting, backtracking done way real-time behavior completeness ensured. size time-slice given parameter algorithm, usingmetric number states allowed expand planning must interrupted. Withinsingle time-slice, however, operations state expansions backtracing closed list (toform path promising state open list) must performed. cost lattertype operations thus converted state expansion equivalence (typically several backtracingsteps performed computational cost single state expansion). key aspectTBA* LRTA*-based algorithms retains closed open lists planning steps.Thus, planning step start planning scratch, continues openclosed lists previous planning step. Also, need update heuristics onlineensure completeness, require precomputation phase. lack precomputationcertainly strong side, negatives include high suboptimality amount time per movelow high on-line space complexity due storing closed open lists.research related work realm non-real-time heuristic search patterndatabases widely used store pre-calculated distance information abstractionsoriginal (ground) search space (Culberson & Schaeffer, 1998). recent approach using precalculated state-space information calculate true distances selected state pairsuse whenever possible make distance estimates search guidance heuristich informative. Two enhanced heuristics differential heuristic (Cazenave, 2006;Sturtevant, Felner, Barrer, Schaeffer, & Burch, 2009) canonical heuristic (Sturtevant et al.,275fiB ULITKO , B J ORNSSON , & L AWRENCE2009). former case, true distance pre-calculated states small subsetstates S, so-called canonical states. on-line search heuristic distancetwo arbitrary states b calculated maximum h(a, b) = |d(a, s) d(b, s)|canonical states S. latter case, state state space true distanceclosest canonical state pre-calculated stored true distancepairs canonical states. search, heuristic distance two statesb calculated h(a, b) = d(C(a), C(b)) d(a, C(a)) d(b, C(b)) C(s) returnsclosest canonical state s. heuristics may return lower distance estimateunmodified heuristic, practice one chooses maximum two. idea similarcanonical heuristic proposed earlier specialized context, heuristic functionimproved pre-calculating true distances several strategically chosen passagewaysgame map (Bjornsson & Halldorsson, 2006). heuristics used real-time search.large volume work case-based planning (e.g., Nebel & Koehler, 1995).includes path planning, case-based approaches used augment heuristic searchtasks route selection road maps mobile robot navigation. approaches typically pre-compute store paths, opposed distances, selected states, usemodel solutions related pathfinding tasks case-based reasoning (CBR) fashion. Oneearly works combining search case-based reasoning pathfinding road mapsdone within planning learning system P RODIGY (Carbonell, Knoblock, & Minton, 1990),goal generating near-optimal routes autonomous navigation vehicle tryingachieve multiple goals driving city (Haigh & Veloso, 1993). authors acknowledgebenefits approach situation necessary interleave planning execution. Subsequent work case-based route selection though mainly focused augmentingnon-interleaving path-planning algorithms, A* Dijkstra, focus workbest build case base, example, identify, compute, store paths criticaljunctions many paths pass (Anwar & Yoshida, 2001; Weng, Wei, Qu, & Cai, 2009).mobile robot navigation, two heuristic search algorithms working ground space usingCBR-based approach introduced Branting Aha (1995). simpler one, lookingpath states b, searches pre-calculated case base path containsb. match found best path returned, otherwise regular A* search invokedcalculate solution path. second, elaborate, algorithm searches case basematch fashion first, none found, adapts existing case fit newtask. done using A* join b existing path case base newoverall distance minimized. still ongoing research area, example, workstoring case base graph structure called case-graph gradually builds waypoint-likenavigation network (Hodal & Dvorak, 2008). Note many existing algorithmsreal-time generate modify complete plans.5. Intuition kNN LRTA*design kNN LRTA* address three shortcomings LRTA* listed earlier.so, identify two key aspects subgoal-based real-time heuristic search. First, needdefine set subgoals would efficient compute store off-line. Second, needdefine way agent find subgoal relevant current problem on-line.276fiC ASE -BASED UBGOALING R EAL -T IME H EURISTIC EARCHIntuitively, LRTA*-controlled agent state going state sgoal bestsubgoal state sideal subgoal resides optimal path sgoal reachedLRTA* along optimal path state re-visitation. Given multiple optimalpaths two states, unclear computationally efficiently detect LRTA* agentsdeviation optimal path immediately occurs.positive side, detecting state re-visitation done computationally efficiently running simple greedy hill-climbing agent. based fact hill-climbing agentreach state b state without encountering local minimum plateau heuristicLRTA* agent travel b without state re-visitation (Theorem 5). Thus, proposeefficiently computable approximation sideal subgoal . Namely, define subgoal pairstates sgoal state skNN LRTA* subgoal farthest along optimal path sgoalreached simple hill-climbing agent (defined rigorously following section).summary, select subgoals eliminate scrubbing (Theorem 5) guaranteeLRTA* agent keeps optimal path subgoals (Theorem 6). practice, however,tiny fraction subgoals reached hill-climbing agent suboptimally evensuboptimality minor.approximation ideal subgoal allows us effectively compute series subgoalsgiven pair start goal states. Intuitively, compress optimal path serieskey states reached predecessor without scrubbing.compression allows us save large amount memory without much impact time-per-move.Indeed, hill-climbing one key states next requires inspecting immediateneighbors current state selecting one greedily. re-visitation-free reachabilityone subgoal another addresses first key shortcoming LRTA* agent mayget trapped within single complex region thus unable reach prescribed subgoal.However, still infeasible compute compress optimal path everytwo distinct states original search space. solve problem compressingpre-determined fixed number optimal paths random states off-line. on-line kNNLRTA*, tasked going sgoal , retrieves similar compressed pathdatabase uses associated subgoals. define (dis-)similarity database pathagents current situation maximum heuristic distances paths beginning sgoal paths end. use maximum would like endspath heuristically close agents current state goal respectively. Indeed,heuristic distance ignores walls thus large heuristic distance paths either end tendsmake end hill-climbing unreachable.Note high similarity (i.e., distances low) guarantee pathuseful kNN LRTA* agent. instance, beginning path heuristicallyclose agent side long wall, making unreachable without lotlearning associated scrubbing. address problem complement fast-tocompute similarity metric computationally demanding move-limited reachability checksdetailed below.illustrate intuition simple example. Figure 3 shows kNN LRTA* operation offline. map, two random start goal pairs selected optimal paths computedthem. path compressed series subgoals subgoalsreached previous one via hill-climbing. path S1 G1 compressedtwo subgoals path compressed single subgoal.277fiB ULITKO , B J ORNSSON , & L AWRENCEG1G2G1G2G1G21S1S1S1S2S2S221Figure 3: Example kNN LRTA* off-line operation. Left: two subgoals (start,goal) pairschosen: (S1 , G1 ) (S2 , G2 ). Center: optimal paths computedrunning A*. Right: two paths compressed total three subgoals.database two records built, kNN LRTA* tasked solving problemon-line. Figure 4 tasked going state state G. database scannedsimilarity (S, G) two database records determined. recordssorted similarity: (S1 , G1 ) followed (S2 , G2 ). agent runs reachability checks:Si Gi G runs database indices order record similarity.example, S1 found unreachable hill-climbing thus record (S1 , G1 )discarded. second record passes hill-climbing checks agent tasked goingfirst subgoal (shown 1 figure).GGGG1G2G1G2S1S1S2S21Figure 4: Example kNN LRTA* on-line operation. Left: agent intends travelG. Center: similarity (S, G) (S1 , G1 ) (S2 , G2 ) computed. Right:(S1 , G1 ) similar (S, G) (S2 , G2 ), beginning S1 reachablevia hill-climbing hence record (S2 , G2 ) selected agent taskedgoing subgoal 1.similarity plus hill-climbing check approach makes state abstraction LRTA* unnecessary, thereby addressing two key shortcomings: high memory requirementscomplex pre-computation phase.278fiC ASE -BASED UBGOALING R EAL -T IME H EURISTIC EARCH6. kNN LRTA* Detailsection flesh kNN LRTA* enough detail researchers implement it.start basic version describe several significant enhancements.6.1 Basic kNN LRTA*kNN LRTA* consists two parts: database pre-computation (off-line) LRTA* dynamically selected subgoals (on-line). Pseudocode off-line part presented Figure 5.top-level function computeSubgoals takes user-controlled parameter N search graph(e.g., grid-based map pathfinding) builds subgoal database N compressed paths.path generated line 4 start goal states randomly chosen line 3.path exist short (line 5), discard re-generate start goalstates. compression takes place inthe function compress, returns sequence statesnp, sgoal np 0 number subgoals (line 6).p = sstart , s1subgoal , . . . , ssubgoalsequence p compressed representation path p forms single record subgoaldatabase (line 7).subgoal database computeSubgoals(N, G)1 subgoal database2 n = 1, . . . , N3generate random pair states (sstart , sgoal )4compute optimal path p sstart sgoal A*5p = |p| < 3 go step 3 end6p compress(p)7add p subgoal database8 endFigure 5: kNN LRTA* off-line: building subgoal database.Pseudocode function compress found Figure 6. takes path p = (sstart , . . . , sgoal ) =(s1 , . . . , st ) argument returns subset states reachable viahill-climbing (and thus without scrubbing). code builds sequence indices statesput subgoals. long path exhausted (line 2), nextcandidate subgoal defined index line 3. Note state index = end()+1always hill-climbing reachable state index end() two statesimmediate neighbours. run binary search defined scope indices [l, r] lines4 5. middle scope calculated line 7 hill-climbing reachabilitylatest computed subgoal send() checked line 8. middle indeed hill-climbing reachablescope moved upper half (line 10) candidate subgoal updated (line 9).Otherwise, scope binary search moved lower half line 12. binarysearch completed, candidate subgoal added line 15.3 convert sequenceindices sequence states line 17.function reachable(sa , sb ) checks hill-climbing agent reach state sbstate sa . pseudocode found Figure 7. start climbing state sa (line 1). long3. use parentheses set operations indicate ordered set.279fiB ULITKO , B J ORNSSON , & L AWRENCEcompress((s1 , . . . , st ))1 (1)2 63end() + 14l i+15rt6l r7b l+r2 c8reachable(send() , sm )9im10l m+111else12r m113end14end15(i)16 end17Figure 6: kNN LRTA* off-line: compressing path sequence subgoals.reachable(sa , sb )1 sa2 6= sb3generate immediate successor states s, generating frontier4h(s) mins00 frontier (h(s00 )) break5find frontier state s0 lowest g(s, s0 ) + h(s0 , sb )6s07 end8 (s = sb )Figure 7: Checking one state reachable another. function called on-line,fixed cap put number iterations loop.goal reached (line 2), generate immediate successors current state (line 3)check local heuristic minimum plateau (line 4). terminate climbdeclare sb hill-climbing reachable sa . Otherwise climb towards frontier statelowest g + h value (lines 5 6). use g + h instead h make move selectioncorrespond LRTA*. Additionally, ties broken exactly wayLRTA* algorithm Figure 1. Note whenever function reachable calledon-line phase, impose fixed cutoff number steps hill-climbing allowed travel.done place upper bound time complexity reachability check independentnumber states search graph, required real-time operation.on-line phase kNN LRTA*, run LRTA* per Figure 1. Dynamic subgoal selection(line 3) done per pseudocode Figure 8. Given start goal state, scan subgoal280fiC ASE -BASED UBGOALING R EAL -T IME H EURISTIC EARCHdatabase and, record, compute heuristic distance start state recordsfirst state well heuristic distance goal state records last state. mentioned earlier, define (dis-)similarity problem record maximumtwo heuristic distances. done similar records start endclose agents current position goal terms heuristic distance.database records sorted similarity agents current global goal states(line 1) and, starting similar record, check start end hill-climbingreachable agents current state agents global goal respectively (line 4). eitherreachability check fails, go onto next record. Otherwise, stop database search (line6). exhaust database find reachable record, resort global goal (line 9).record found, subgoals fed one one LRTA* line 3 Figure 1.intuition similarity metric uses heuristic distance and, therefore, ignoresconstraints problem (e.g., walls grid-based pathfinding). Thus, database recordhigh similarity value may relevant agents situation start goal mayside wall means subgoals reachable LRTA* withoutscrubbing therefore useless agent.r selectSubgoals(s, sglobal goal )123456789(r1 , . . . , rN ) database records least similar= 1, . . . , Nretrieve ri = (sstart , . . . , send )reachable(s, sstart ) reachable(send , sglobal goal )r rireturnendendr s, sglobal goalFigure 8: kNN LRTA* on-line: selecting subgoals.6.2 Enhanced kNN LRTA*presented basic kNN LRTA* algorithm. section introduce six enhancements.First, selecting database record function selectSubgoals, check globalgoal reachable agents current state. done calling function reachable.global goal indeed reachable via move-limited hill-climbing set agents goallook subgoal. Otherwise, turn database subgoals.Second, selected database record routine selectSubgoals, run reachabilitycheck agents current state first subgoal record. first subgoalreachable set goal LRTA*. Otherwise, set LRTA* go start staterecord already checked reachable within function selectSubgoals.Third, LRTA* reaches last subgoal (i.e., state record immediately priorend record), checks global goal reachable it. so, global goal usednext subgoal. Otherwise, agent heads end record reachglobal goal guaranteed record selection criteria.281fiB ULITKO , B J ORNSSON , & L AWRENCEfirst three enhancements addresses trade-off path optimality planningtime per move. Specifically, calling function reachable, real-time, increases kNN LRTA*planning time per move but, time, leads potentially shorter solution due bettersubgoal selection. Recall function reachable satisfies real-time operation constraintplace priori limit number moves take.Reachability checks constitute substantial portion kNN LRTA*s planning time per move.substantial contributor accessing record database computing record similarity.basic algorithm described always computes similarity database records and,worst case, runs reachability checks records function selectSubgoals.depend search graph size thus real-time, still speed follows.fourth enhancement run reachability checks fixed number similarrecords. done simply substituting total number database records Nfixed constant N line 2 Figure 8. intuition fairly similar recordsworth checking reachability.N enhancement substantially reduce amount planning time takenreachability checks. However, similarity still computed records database(line 1 Figure 8). fifth enhancement speeds step employing kd-trees insteadlinear database scan. kd-tree (Moore, 1991) spatial tree index sublinear timecomplexity nearest-neighbor searches. Specifically, kd-tree indexes start end statessubgoal database records. tree node thus four-tuple (xstart , ystart , xend , yend ). indexworks dividing search space along dimension level tree. search spacedivided xstart root node tree, ystart next level down, xend next level,yend next, cycle repeats. example, root node (4, 5, 8, 9),start state coordinates (4, 5) end state coordinates (8, 9). Further, nodesleft subtree xstart 4, nodes right subtree xstart > 4.illustrate, consider tree Figure 9 subgoal record whose start state (8, 4)whose goal state (4, 9). records represented kd-tree node (8, 4, 4, 9).right subtree root xstart = 8 greater roots value 4. leftsubtree next node value 4 ystart less nodes value 5. thirdlevel, left subtree value 4 xend less 6. Finally, right subtreeparent level four value yend = 9 greater 8 parent.4,5,8,9startX <= 4startY <= 77,5,6,4startY > 74,5,4,5endX <= 43,2,2,1startY <= 52,8,3,3endX > 41,6,8,3divide start xcoordinatestartX > 43,7,6,6endX <= 31,9,2,68,3,6,4endX > 35,9,4,6endX <= 63,8,5,4endX > 66,2,5,8endY <= 88,3,3,7divide start ycoordinatestartY > 59,1,9,3endY > 8endX <= 49,9,4,4endX > 4divide end xcoordinate9,9,5,5divide end ycoordinate8,4,4,9Figure 9: kd-tree database access.structure allows nearest-neighbors computed without searching paths treeindex eliminating subtrees based distance. instance, search currentlybest records found far, encounters node tree guaranteed282fiC ASE -BASED UBGOALING R EAL -T IME H EURISTIC EARCHnodes farther away records search target, subtree searched.nearest-neighbor search algorithm explained Moore (1991). Note kd-tree indexworks regular grid pathfinding problems necessarily heuristic search problems.instance, high-cost edges connecting states similar coordinates low-cost edges connectingstates distant coordinates would present problem kd-tree index.Given subgoal database, build kd-tree index off-line store togetherdatabase. On-line, use kd-tree identify records relevant agents current startgoal states (line 1 Figure 8). compute similarity metric records.sixth enhancement deals case kNN LRTA* unable find subgoalresorts global goal. happens function selectSubgoals (line 9 Figure 8). failurefind subgoal caused none similar records passing reachability checks.resort global goal indicates insufficient database coverage current areaspace start goal state pairs. Given records compressed optimal pathsrandomly generated start goal states, database coverage likely uneven. Thus resortingglobal goal permanent step agent traveling global goal likelyenter area covered database sooner later. point, record selection processrepeated, hopefully resulting database hit. implement intuition kNN LRTA*imposing travel quota LRTA* function selectSubgoals fails find reachable record.quota computed heuristic distance agents current state global goalmultiplied fixed constant greater 1. agent exhausts quota, selectSubgoalscalled again. fails find reachable subgoal second time row, quotaset infinity leading interruptions. necessary guarantee completeness.Additionally, interrupting LRTA* indefinitely many times increases average planning time per movedue subgoal selection attempts.also experimented idea database record form (s1 , . . . , sn )used entirety. Indeed, fragments (i.e., (si , . . . , sj ) 1 < j n)used within kNN LRTA* fashion entire record. implementedidea running kd-tree search fragments database records addition wholerecords. results disappointing several ways. First, kd-tree algorithm becomescomplex kd-tree query time increases. Second, record fragments crowd hitskd-tree returns similarity metric computed. practice meanskd-tree returns similar hill-climbing unreachable records and, thus, causes kNN LRTA*resort global goal often. fixed increasing accordinglysimilarity computation hill-climbing checks become costly.7. Theoretical Analysissection prove completeness algorithm analyze complexity.7.1 Off-line ComplexityOff-line kNN LRTA* generates N records space states. Let diameter space (i.e.,number states along longest possible shortest path two states) .Theorem 1 Off-line worst-case space complexity kNN LRTA* O(N + S).283fiB ULITKO , B J ORNSSON , & L AWRENCEProof. worst case optimal path kNN LRTA* generates randomly selected startgoal long minimally compressible. Minimum compression means every statepath stored. N records property total amount database storageO(N ). Additionally, A* run record worst-case space complexity S. 2Theorem 2 Off-line worst-case time complexity kNN LRTA* O(N log + N log N ).Proof. kNN LRTA* runs A* compute optimal path N pairs randomly generated startgoal states. consistent heuristic constraints problem formulation,A*s worst case time complexity O(S log S). Since S, A*s complexity dominatesworst-case time complexity function compress O(S log ). Additionally, buildingkd-tree takes O(N log N ). 27.2 On-line Complexitysection assume LRTA* generates immediate neighbors current statemove. grid pathfinding easily accomplished setting gmax = 1.4.generally, guaranteed substituting line 4 Figure 1 generate immediatesuccessor states s.Theorem 3 kNN LRTA*s on-line worst-case space complexity O(dmax + S) dmaxmaximum out-degree vertex total number states.Proof. open list kNN LRTA* maximum number immediate neighborsstate (i.e., dmax ). LRTA* learns, store updated heuristic values,S. Hence overall space complexity O(dmax + S). Note grid pathfindingdmax dmax increase map size, thereby reducing upper bound O(S). 2Theorem 4 kNN LRTA*s per-move worst-case time complexity O(dmax +N +M log )dmax maximum out-degree vertex, N total number records databasenumber candidate records selected kd-tree.Proof. move kNN LRTA* invokes LRTA* generates dmax states.moves, kNN LRTA* additionally searches database find appropriate record. databasesearch starts querying kd-tree records (M N ). balanced kd-treestime complexity sub-linear N , worst case time step still O(N ). sortrecords similarity O(M log ) time. Finally, move-limited hill-climbing checksrun records, collectively taking O(M ) time. Thus, overall per-move timecomplexity O(dmax + N + log ) worst case. 2Note bound depend and, therefore, makes kNN LRTA* real-timedefinition. Also note grid pathfinding dmax N N makes kNN LRTA*sper move time complexity simply O(N ).284fiC ASE -BASED UBGOALING R EAL -T IME H EURISTIC EARCH7.3 CompletenessTheorem 5 two states s1 s2 , s2 hill-climbing reachable s1 LRTA*agent starting s1 reach s2 without state re-visitation (i.e., scrubbing).Proof. First, show hill-climbing agent (as specified function reachableFigure 7) reach s2 s1 never re-visit states way. Suppose,case. exists state s3 re-visited hill-climbing agent. tiesbroken fixed order, hill-climbing agent arrives s3 second time,continue following path first visit will, therefore, arrive s3third time on. words, infinite loop re-visiting s3 repeatedly.contradicts fact able reach s2 .conclude path s1 s2 followed hill-climbing agentfree repeated states. show LRTA* agent starting s1 follow exactlypath hill-climbing agent. Observe difference hill-climbingagent (Figure 7) LRTA* agent (Figure 1) heuristic update rule line 6 latterfigure. update rule increase heuristic values (i.e., make less attractiveagent) already visited states. Since hill-climbing agent never re-visits statestraveling s1 s2 , increase heuristic values caused LRTA* affectLRTA*s move choice (line 5 Figure 1). result, LRTA* follow precisely paths1 s2 hill-climbing agent thus re-visit states. 2Theorem 6 exist two states s1 s2 s2 hill-climbing reachable s1path hill-climbing agent follows optimal (i.e., shortest).Proof. proof constructive presented Figure 10. darkened cells walls. hillclimbing agent, starting state s1 hug wall way state s2 .The resultingpath cost 16.4. optimal path, however, takes advantage diagonal moves makingnon-greedy move going around wall agent. cost 15. 2Theorem 7 kNN LRTA* complete size subgoal database underlying kNNLRTA* generates least immediate neighbors current state.Proof. prove completeness need show pair states s1 s2 ,path s1 s2 , kNN LRTA* reach s2 s1 .Given problem, subgoal selection module kNN LRTA* (Figure 8) either returnrecord form r = (sstart , . . . , send ) instruct LRTA* go global goal. lattercase, kNN LRTA* complete underlying LRTA* complete (Korf, 1990) longgenerates immediate neighbors current state.former case, LRTA* guaranteed reach either sstart first subgoal r dueway r selected. states r reached, LRTA* guaranteed reachsubsequent states due completeness basic LRTA* way subgoalsgenerated. Note interruptibility enhancement interfere completenessinterrupt going global goal once. 2285fiB ULITKO , B J ORNSSON , & L AWRENCEs1s2Figure 10: Hill-climbing reachability guarantee optimality.8. Empirical EvaluationPathfinding video games challenging task, frequently requiring many units plan pathssimultaneously react promptly user commands. task made even challengingever-growing map sizes little computational resources allocated in-game AI. Accordingly,recent work field real-time heuristic search uses video game pathfinding testbed.8.1 Test ProblemsMaps modelled game levels Baldurs Gate (BioWare Corp., 1998) WarCraft III:Reign Chaos (Blizzard Entertainment, 2002) common choice (e.g., Sturtevant &Buro, 2005; Bulitko et al., 2008). maps, however, small todays standardsrepresent state industry. paper, developed new set maps modelledgame levels Counter-Strike: Source (Valve Corporation, 2004), popular on-line first-personshooter. game level geometry specified vector format. developed softwareconvert grid arbitrary resolution. previous papers commonly used mapsrange 104 105 grid cells (e.g., 150 141 512 512 cells Sturtevant, 2007;Bulitko & Bjornsson, 2009), new maps nine thirteen million vacant cells (i.e.,states). two three orders magnitude increase size. point reference,entire road network Western Europe used state-of-the-art route planning approximatelyeighteen million vertices (Geisberger, Sanders, Schultes, & Delling, 2008).experiments paper run set 1000 randomly generated problems acrossfour maps shown Figure 11. 250 problems map constrainedsolution cost least 1000. grid dimensions varied 4096 4604 72614096 cells. problem computed optimal solution cost running A*. optimalcost range [1003.8, 2999.8] mean 1881.76, median 1855.2 standarddeviation 549.74. also measured A* difficulty defined ratio number statesexpanded A* number edges resulting optimal path. 1000 problems,286fiC ASE -BASED UBGOALING R EAL -T IME H EURISTIC EARCHFigure 11: maps used empirical evaluation.A* difficulty range [1, 199.8] mean 62.60, median 36.47 standarddeviation 64.14.algorithms compared implemented Java using common data structures muchpossible. used Java version 6 SUSE Enterprise Linux 10 2.1 GHz AMD Opteronprocessor 32 Gbytes RAM. timings reported single-threaded computations.8.2 Algorithms Evaluatedevaluated kNN LRTA* following parameters. Database size values{1000, 5000, 10000, 40000, 60000, 80000} records. On-line, allowed hill-climbing testclimb 250 steps concluding destination state hill-climbing reachable.value picked experimentation appropriate record densitymap. Indeed, larger database requires fewer hill-climbing steps maintain likelihoodfinding hill-climbing reachable record given problem.287fiB ULITKO , B J ORNSSON , & L AWRENCEran reachability checks 10 similar records.4 Whenever selectSubgoals failedfind matching record, allowed LRTA* travel towards global goal 3 timesheuristic estimate remaining path. that, LRTA* interrupted second attemptfind appropriate subgoal run. LRTA*s parameter gmax set costexpensive edge (i.e., 1.4) LRTA* generated immediate neighbors current state.also ran two recent high-performance real-time search algorithms compare kNN LRTA*against: LRTA* TBA*. LRTA* run databases computed abstraction levels{9, 10, 11, 12}. TBA* run time slices {5, 10, 20, 50, 100, 500, 1000, 2000, 5000}.cost ratio expanding state backtracing set 10.chose space control parameters via trial error, three considerations mind.First, cover enough space clearly determine relationship controlparameters algorithms performance. Second, attempted establish pareto-optimalfrontier (i.e., determine algorithms dominate others simultaneously outperformingalong two performance measures time per move suboptimality). Third, parameter valuescould run algorithms practical amount time (e.g., buildingdatabase LRTA*(8) would taken us 800 hours practical). detailobservations respect three considerations below.8.3 Solution Suboptimality Per-Move Planning Timebegin comparisons looking average solution suboptimality versus average time permove. left plot Figure 12 shows overall picture plotting algorithms parameters.right plot zooms high-performance area. Table 1 shows individual values. kNNLRTA* produces highest quality solutions, followed TBA*.LRTA* mean suboptimality 819.72% delivers paths 9 timescostlier optimal paths. suboptimality impractical pathfinding includedLRTA*(9) right subplot Figure 12 illustrate substantial gap solution qualityLRTA* kNN LRTA*. Optimality LRTA* solutions improved lowering abstraction level database pre-computation increases rapidly discuss below.TBA* produces solutions substantially less costly LRTA* cannot reach kNN LRTA*database size 60 80 thousand records. Additionally, TBA* noticeably slowerper move expands one state allocates time backtracking well.time per move decreased lowering value cutoff already cutoff 10,TBA* produces unacceptably suboptimal solutions (666.5% suboptimal). result, kNN LRTA*dominates TBA* outperforming respect measures. intuitive TBA*benefit subgoal precomputation.hand, LRTA* stands non-dominated due low time per move.also intuitive scan database similar records check hillclimbing reachability them. differences LRTA* kNN LRTA* are, however,4 microseconds per move.sake reference, also included A* results table. A* real-time algorithm average time per move tends increase number states map. Also,4. also experimented querying kd-tree 100 similar records found minor improvement suboptimality together significant increase mean time per move. frequentlyhill-climbing-reachable database record among top 10 candidates thus extra time spent queryingkd-tree 90 records sorting wasted.288fi00LRTA* (9)kNN LRTA* (60000)2kNN LRTA* (80000)200C ASE -BASED UBGOALING R EAL -T IME H EURISTIC EARCH TBA* (50)0TBA* (100)501001505010015000Mean precomputation time (hours per map)0 Mean online50memory (Kbytes100per problem) 150Mean precomputation time (hours per map)Mean suboptimality (%)10Meanmemorysuboptimality(%)per problem)Mean online(Kbytes4x 10LRTA*kNN LRTA*TBA*86420050100150200250Mean time per move (seconds)3001501000LRTA* (9)kNN LRTA* (60000)kNN LRTA* (80000)TBA* (50)TBA* (100)80010060040050LRTA*kNN LRTA*TBA*20000005010015020025050100Meanper movemove (seconds)(seconds)Mean timetime per2010/1/8, 16:29:14 : Java results mm_cs_4_1000 scenario300150Mean time per move (microseconds)7.566.886.406.553.733.934.263.9414.3126.3483.31117.52208.03Solution suboptimality (%)6851.62620.6312.7711.9615999.238497.096831.74819.721504.54666.50131.1264.660Table 1: Suboptimality versus time per move.spends time first move computes entire path. Subsequent movesrequire trivial computation. table, define A*s mean time per move total planningtime problem divided number moves path A* finds. average quantityproblems. kNN LRTA* 30 times faster A* per move.Note kNN LRTA*s time per move decreases larger databases. intuitivedatabase records higher probability earlier record short list recordsreachability checks run pass checks (line 4 Figure 8). Consequently,time-consuming reachability checks administered function selectSubgoals,saving time per move. time savings, resulting larger database, outweigh extra timespent traversing correspondingly larger kd-tree form short list similar records.fact indicates kd-tree approach scales well database size.289400kNkN20000Mean1501005000Mea2010/1/8, 16:39:16 : Java results mm_cs_4_1000 scFigure 12: Suboptimality vs. time per move: algorithms (left), high-performance region (right).AlgorithmkNN LRTA*(10000)kNN LRTA*(40000)kNN LRTA*(60000)kNN LRTA*(80000)LRTA*(12)LRTA*(11)LRTA*(10)LRTA*(9)TBA*(5)TBA*(10)TBA*(50)TBA*(100)A*Mean subo24400Mean online memory (Kbytes per problem)Mean suboMeanMean4fi2B ULITKO , B J ORNSSON , & L AWRENCE0.51Mean relative database size (per map)00001.54101000LRTA*kNN LRTA*84LRTA* (9)kNN LRTA* (40000)kNN LRTA* (60000)LRTA*kNN LRTA* (80000)kNN LRTA*220050100Mean precomputation time (hours per map)0150010MeanMean suboptimality (%)Mean online memory (Kbytes per problem)kNN LRTA*800kNN LRTA* (40000)kNN LRTA* (60000)Solution suboptimality(%)kNN LRTA* (80000)LRTA*6851.62kNN LRTA*AlgorithmPre-computation time per map (hours)10600kNN13.106 LRTA*(10000)kNN LRTA*(40000)51.89620.63400kNNLRTA*(60000)77.3012.7745103.0911.96kNN LRTA*(80000)2000.2515999.232D LRTA*(12)LRTA*(11)1.578497.09002411.956831.7460D LRTA*(10)00246810024 move (seconds)68Meantime perLRTA*(9)89.88819.72Mean time per move(seconds)Mean time per move (seconds)810800600400kNkNkN20005051001501510(hoursperproblem)map)Mean precomputationonline memorytime(Kbytesper4Figurex 1013:Suboptimality versus database pre-computation time per map. Left: pre-computing10001015algorithms. Right: high-performancesubplot.LRTA* (9)LRTA*Mean suboptimality (%)010004400280x 1066000200601.5880060kNkNkN4x 10Mean suboptimality (%)Mean suboptimality (%)Mean suboptimality (%)1010203040500.51 per map)Mean databasesize (MBytesMean relative database size (per map)400Mean suboptimality (%)0LRTA* (9)kNN LRTA* (40000)kNN LRTA* (60000)kNN LRTA* (80000)0MeanMean online memory (Kbytes per problem)02200Mean sub4400Mean subMeanMean41.51kNkNkN0.5002Mea2010/1/8, 17:34:36 : Java results mm_cs_4_102010/1/8, 17:41:03 : Java results mm_cs_4_1000 scenarioTable 2: Suboptimality versus database pre-computation time.8.4 Database Pre-computation TimeSuboptimality versus database pre-computation time shown Figure 13. left subplot demonstrates parametrizations LRTA* kNN LRTA* right plot focuses betterperforming configurations. Table 2 shows individual values.kNN LRTA* three advantages LRTA*. First, kNN LRTA* 40 60 thousand records easily dominates LRTA*(9): better suboptimality requiring less precomputation time. kNN LRTA*(80000) overkill maps improve suboptimality much (11.96% versus 12.77% achievable 60000 records) longestprecomputation time.Second, database computation parallelized easily case kNN LRTA*individual records completely independent other. case LRTA*.Additionally, LRTA* requires building map abstraction complex parallel.Third, number records kNN LRTA* database controlled much easilyLRTA*. Specifically, LRTA* one controls level abstraction.number Sa abstract states abstraction level approximately Sa number290fiC ASE -BASED UBGOALING R EAL -T IME H EURISTIC EARCHoriginal non-abstract states constant reduction factor (Bulitko et al., 2007). numberNa records LRTA* database Sa (Sa 1). Thus, ratio Na Na1 is:Na1Na=Sa1 (Sa1 1)=Sa (Sa 1)a11a11=a1 2= (2 ).Thus decreasing level abstraction one, LRTA* database size grows leastquadratically . maps, clique abstraction approximately 3 meansnearly order magnitude database size (and pre-computation time) goone level abstraction. illustrate, building database LRTA*(8) estimated take800 CPU-hours. hand, number records kNN LRTA* databaseuser-specified parameter, affording much greater control.particular interest pair kNN LRTA* database 10000 LRTA*abstraction level 10 perform closely measures. discuss differencesdatabase sizes next section.8.5 Database SizeMemory premium video games, especially consoles. TBA* space complexity comesopen closed list builds on-line. kNN LRTA* LRTA* expandsingle state (the agents current state) thus closed list one state open listeight states (as grid cell maps eight neighbors). However, twoalgorithms consume memory store updated heuristic values. Additionally, storesubgoal databases. section focus database size. next section covertotal memory consumed on-line: open closed lists well updated heuristic values.LRTA* database record stores exactly three states. kNN LRTA* records twostates number records fixed algorithm parameter. Additionally, kNNLRTA* stores start end states record kd-tree. define relative database sizeratio total number states stored records total number map grid cells.addition subgoal records, LRTA* databases contain explicit region assignmentstate. Consequently, LRTA* databases relative size least 1. extra storagemajor weakness LRTA* comparison kNN LRTA*. illustrate, implementationuse 32 bits index states, storing region assignment grid cell translates average84 megabytes per map. Full results found Figure 14 Table 3.AlgorithmkNN LRTA*(10000)kNN LRTA*(40000)kNN LRTA*(60000)kNN LRTA*(80000)LRTA*(12)LRTA*(11)LRTA*(10)LRTA*(9)Pre-computation time13.1051.8977.30103.090.251.5711.9589.88Records10000400006000080000251.51896.514872.0116048.5Relative size0.003080.012340.018510.024681.000011.000091.000681.00532Size (megabytes)0.251.001.512.0184.9684.9785.0285.40Table 3: Database statistics. values averages per map. Pre-computation time hours.291fiB ULITKO , B J ORNSSON , & L AWRENCE101000LRTA*kNN LRTA*88006LRTA*kNN LRTA*660044400201000Mean suboptimality (%)8x 10Mean suboptimality (%)Mean suboptimality (%)Mean suboptimality (%)4x 10220000.51Mean relative database size (per map)0001.5LRTA* (9)kNN LRTA* (60000)kNN LRTA* (80000)2060 1800.5 40Mean relativedatabasesize (MBytespermap)map)Meandatabasesize (per100010LRTA* (9)LRTA*requiring much less memory and,kNNtime,LRTA*(60000)kNNLRTA*8LRTA* (80000) 57instance, kNN800LRTA*(60000)requires kNNapproximatelysuboptimality(%)Mean onlineMeanmemory(Kbytes perproblem)Mean suboptimality (%)0246810Mean timeper move (seconds)8.6 On-line SpaceComplexity0020Mean02Mean cum800600400200035x 104321kNkN002Mean time per move (seconds)Mea246810Mean time per move (seconds)2010/1/11, 17:09:07 : Java results mm_cs_4_first analyze specificallyamountresultsmemoryallocated byscenarioalgorithms on-line.2010/1/11,17:11:03: Javamm_cs_4_1000algorithm solves particular problem, record maximum size open closed listswell total number states whose heuristic values updated. count updatedheuristic value one state terms storage required.5 Adding three measures together,5. Multiple heuristic updates state increase amount storage.292kNkN2001000Mean suboptimality (%)Mean suboptimality (%)Mean suboptimality (%)Mean suboptimality (%)Again, kNN LRTA* dominates8producingsolutions better quality.times less database memory LRTA*(9) simultaneously producing solutions60066eight times better.Let us re-visit interesting case kNN LRTA*(10000)LRTA*(10) closely40044match respect database pre-computation time solution suboptimality. Table 3 reveals, kNN LRTA*(10000) uses approximately 340200 times less memory LRTA*(10):22256 kilobytes versus 85.02 megabytes.0NoteLRTA*(10) averages approximately 49%records per map kNN000204060801001200100150 less pre-computation0 Mean 2precomputation46is10LRTA*(10000)but50requires approximately9%time.time (hoursper 8map)(i)Mean precomputation time (hours per map)Mean cumulative online memory (Kbytes)x 104LRTA* averages fewer subgoals per record kNN LRTA* (ii) computing LRTA* subgoalsrequire reachability checks time-consuming process.41000x 10Also note despite 49% records, 0.06LRTA* affords 0.3%improvement10LRTA*(9)LRTA*generally, additional experiments demonstratedkNN LRTA* (60000)solution quality kNN LRTA*. DMore800kNN LRTA*kNN LRTA* (80000)kNN8 LRTA* tends outperform LRTA* solution0.05quality given number records.two factors play here. First, kNN LRTA*0.04records often containseveral subgoals600LRTA*6guaranteedreachable without scrubbing. LRTA*records offerskNN LRTA*0.03guarantees subgoal may difficult reach400 agents start state abstract4regionsbecome large complex. upside, LRTA* spaces records systematic0.02fashion one record per pair regions thereby200providing potentially better coverage2afforded randomly selected starts endskNN LRTA* database records. appears0.01former factor overcomes latter, leading kNN0LRTA*sbetterper-recordsuboptimality.0246804000LRTA*LRTA*kNNLRTA*06001001.544Figurex 1014:Suboptimality vs. database size: algorithms x(left),high-performance region (right).1010800Mean online memory (Kbytes per problem)410fiC ASE -BASED UBGOALING R EAL -T IME H EURISTIC EARCHAlgorithmkNN LRTA*(10000)kNN LRTA*(40000)kNN LRTA*(60000)kNN LRTA*(80000)LRTA*(12)LRTA*(11)LRTA*(10)LRTA*(9)TBA*(5)TBA*(10)TBA*(50)TBA*(100)A*Strictly on-line memory (Kbytes)8.625.044.234.2218.7611.098.243.041353.941353.941353.941353.941353.94Solution suboptimality (%)6851.62620.6312.7711.9615999.238497.096831.74819.721504.54666.5083.3164.660Table 4: Strictly on-line memory versus solution suboptimality.record amount strictly on-line memory per problem. Averaging strictly on-line memoryproblems, list results Table 4.kNN LRTA* dominates LRTA* points except LRTA*(9) lowest meanstrictly on-line memory 3.04 Kbytes per problem. TBA*, effectively time-sliced A*,update heuristic values all. However, open closed lists contribute highestmemory consumption 1353.94 Kbytes. intuitive TBA* use subgoals therefore must fill potentially large heuristic depressions open closed lists. Also, noticetotal size lists change cutoff state expansions independentagents moves TBA*. A* identical memory consumption expands statesway TBA*. Again, kNN LRTA* dominates TBA* cutoff values, using less memoryproducing better solutions.Strictly on-line memory gives insight algorithms present complete picture. Specifically, LRTA* kNN LRTA* must load databases on-line memory.Thus define cumulative on-line memory strictly on-line memory plus sizedatabase loaded. values found Figure 15 Table 5.Several observations due. First, TBA* longer dominated due low memory consumption. Second, LRTA* league due explicitly labelling every statecorresponding region well computing subgoals pairs regions. Third, LRTA*sweet spot memory consumption corresponds abstraction level 11. higherlevel abstraction reduces database size enough compensate updated heuristic values. Lower abstraction levels reduce amount learning enough compensatelarge number subgoals database.293fi5021.520406080Mean(MBytesmap)0.005 database0.01 size0.0150.02per 0.025Mean relative database size (per map)1000.03kNN LRTA* (60000)kNN LRTA* (80000)TBA* (50)L AWRENCETBA* (100)50B ULITKO , B J ORNSSON , &0000(per map)Mean suboMeanMeansubos1LRTA*kNN LRTA*TBA*4000.511.522.5Mean database size (MBytes per map)34Mean suboptimality (%)1006150LRTA*kNN LRTA*kNN(60000)LRTA*kNN LRTA*(80000)TBA*TBA* (50)TBA* (100)450210050026 10081050 41504Meanonline(Kbytes)Mean cumulativeprecomputationtimememory(hours permap)x 10kNN LRTA* (60000)kNN LRTA* (80000)TBA* (50)TBA* (100)05001000150020002500Mean cumulative online memory (Kbytes)Figure15: Suboptimality versus cumulative on-line memory. Left: algorithms. Right: high1.51501.5performance subplot.kNN LRTA* (60000)Mean online memory (Kbytes per problem)LRTA*kNN LRTA*TBA*80000150Mean onlinememory(Kbytes(%)per problem)Meansuboptimality00urs per map)Meansuboptimalitysuboptimality(%)Mean(%)LRTA*kNN LRTA*TBA*x 1010150kNN LRTA* (80000)TBA* (50)CumulativeTBA* (100) on-lineAlgorithmmemory (Kbytes) Solution suboptimality (%)1kNN LRTA*(10000)265.656851.62kNN LRTA*(40000)1034.08620.63kNN LRTA*(60000)1547.8512.77LRTA*500.50.5kNN LRTA*kNN LRTA* (60000)kNNLRTA*(80000)2062.2011.96TBA*kNN LRTA* (80000)LRTA*(12)87019.7415999.23TBA* (50)LRTA*(11)87018.50TBA* (100) 8497.09000D87066.346831.740 LRTA*(10)5010015005010015000250300050100150200250300Meantimepermove(seconds)Meantimepermove(seconds)LRTA*(9)819.72Mean time per move (seconds) 87456.35econds)TBA*(5)1353.941504.542010/1/13, 21:37:18 : Java results mm_cs_4_1000 scenario3, 21:30:33 : Java results mm_cs_4_1000scenarioTBA*(10)1353.94666.50TBA*(50)1353.9483.31TBA*(100)1353.9464.66A*1353.9401001Table 5: Solution suboptimality versus cumulative on-line memory.8.7 Simultaneous Pathfinding Multiple Agentssingle agent pathfinding time, analysis holds TBA*memory efficient choice. However, video games, anywhere half dozen thousandagents (e.g., Gas Powered Games, 2007) pathfinding simultaneously map.scenario favors kNN LRTA* LRTA* whose subgoal databases map-specificindependent start goal states. Consequently, multiple agents running LRTA* kNNLRTA* share subgoal database.6 contrast, memory consumed TBA*specific given agent cannot shared agents operating map.6. Note multiple agents cannot, generally speaking, share heuristic h computed updatedrespect different goals.294fiC ASE -BASED UBGOALING R EAL -T IME H EURISTIC EARCHHence total amount cumulative on-line memory K agents operating simultaneouslyequals amount database memory plus K times amount strictly on-line memory.break-even point algorithm respect algorithm B defined minimalnumber agents using collectively consume less memory number agentsusing B. Table 6 lists break-even points LRTA* kNN LRTA* respect TBA*.AlgorithmkNN LRTA*(10000)kNN LRTA*(40000)kNN LRTA*(60000)kNN LRTA*(80000)LRTA*(9)LRTA*(10)LRTA*(11)LRTA*(12)Break-even point respect TBA* (number agents)112265656666Table 6: Break-even points kNN LRTA* LRTA* respect TBA*.kNN LRTA* ten forty thousand record databases requires less cumulative on-linememory TBA* hence break-even point one agent. sixty eighty thousandrecords, two kNN LRTA* agents take less total cumulative on-line memory two TBA* agents.takes 65 66 simultaneously pathfinding agents amortize large LRTA* databasesgain memory advantage TBA*.9. Discussionfirst time high-performance real-time search algorithms TBA*, LRTA* kNNLRTA* evaluated contemporarily sized maps. results, presented detail previous section, summarized representative algorithms Table 7.DimensionSuboptimalityTime per moveCumulative memoryBreak-even pointPre-computation timekNN LRTA* versus algorithmskNN LRTA* 8.16 times better LRTA* 1.46 times better TBA*kNN LRTA* 18.36 times better TBA* 62% worse LRTA*kNN LRTA* 57 times better LRTA* 13% times worse TBA*kNN LRTA* takes less memory TBA* two agentskNN LRTA* 14% better LRTA*Table 7: Comparisons kNN LRTA*(60000) LRTA*(9) TBA*(100).kNN LRTA* achieves best suboptimality three algorithms. kNN LRTA* substantially faster per move TBA* par LRTA*. terms cumulative on-linememory, kNN LRTA* outperforms LRTA* two orders magnitude 13% worseTBA*. Furthermore, two simultaneously planning agents, kNN LRTA* takes lessmemory TBA*. contrast, takes 65 LRTA* agents amortize databasegain memory advantage TBA*. Off-line, kNN LRTA* outperforms LRTA* achieving295fiB ULITKO , B J ORNSSON , & L AWRENCEorder magnitude better solutions database two orders magnitude smaller sizeslightly faster compute.results comparisons TBA* expected TBA* benefit precomputation, comparison kNN LRTA* LRTA* unearthed unexpected results.Specifically, subgoal databases kNN LRTA* effective use pre-computation timememory LRTA*. lower memory consumption kNN LRTA* databasesachieved store explicit region membership. Better pre-computation times comecompute shortest paths pairs abstract times. Finally, kNN LRTA*better LRTA* per record basis. compressing entire optimal pathseries subgoals reachable via hill-climbing guarantees singlesubgoal reached, underlying LRTA* agent reach global goal without scrubbing.contrast, LRTA* subgoals difficult reach agents current position. evenreached, difficulties recur subsequent subgoals.terms applications, kNN LRTA* algorithm choice use video gamepathfinding. instance, kNN LRTA*(60000) 30 times faster per average move commonly used A* produces solutions less 15% suboptimal. performancecomes cost 77 hours pre-computation time per map easily reduced10 hours modern eight-core workstation. negligible comparing amounttime game company spends hand-crafting single map.10. Current Shortcomings Future WorkDespite outperforming existing state-of-the-art real-time search algorithms problems overall,kNN LRTA* several shortcomings. First, database records generated randomlyselected start end states. means coverage space necessarily even:small, difficult reach, regions space may never get suitable recordeasy reach regions may get multiple redundant records covering it.Increasing database efficiency would allow smaller database afford equal coveragehence equal on-line performance. turn reduce pre-computation time kNNLRTA* database presently reach 100 hours per map. computationsped nearly linear scale using multi-core processors time affordablegame company side, players would want home-made game maps processedmatter seconds minutes.Making subgoal coverage uniform accomplished via forgoing random startend selection favor space partitioning. However, unlike LRTA*s abstract regions built viarepeated applications clique abstraction, partitions states reachableLRTA* without scrubbing. start end states database recordsselected within partitions. reduce amount pre-computation one computesubgoals compressing optimal paths neighboring regions (as opposed distinctabstract regions LRTA* does). Note unlike LRTA*, partitioning necessarilyoff-line explicit region assignment stored every state. result, on-line memoryconsumption comparable better existing kNN LRTA*.philosophically oriented project would develop self-aware agent. Specifically,agent would analyze performance core algorithm (e.g., LRTA*) decide296fiC ASE -BASED UBGOALING R EAL -T IME H EURISTIC EARCHappropriate partitioning scheme. similar meta-level control previously attempteddynamic selection lookahead depth real-time search (e.g., Russell & Wefald, 1991).11. Beyond Grid Pathfindingpresented evaluated kNN LRTA* grid-based pathfinding. Formally, algorithm,exception kd-tree module, applicable arbitrary weighted graphs satisfy constraints beginning Section 2. principle, applicable general planningusing ideas search-based planners ASP (Bonet, Loerincs, & Geffner, 1997), HSPfamily (Bonet & Geffner, 2001), FF (Hoffmann, 2000), SHERPA (Koenig, Furcy, & Bauer, 2002)LDFS (Bonet & Geffner, 2006).described earlier paper, using kd-tree index requires certain correspondencecoordinate similarity heuristic distance. Extending kd-trees developing appropriatenew index structures arbitrary graph open research question. interim solutionapply kNN LRTA* arbitrary search problems without kd-tree module. will, however,slow on-line part similarity must computed agents current situationevery single record database. positive side, computing kd-trees speedoff-line part kNN LRTA*.Finally, kNN LRTA* theoretically applicable arbitrary search problems,clear well perform respect competitors LRTA* TBA*.investigation left future work.12. Conclusionspaper considered problem real-time heuristic search whose planning time per movedepend number states. proposed new mechanism selecting subgoalsautomatically. resulting algorithm shown theoretically complete and, large videogame maps, substantially outperformed previous state-of-the-art algorithms LRTA* TBA*along several important performance measures.Acknowledgmentsresearch supported grants National Science Engineering Research CouncilCanada (NSERC); Icelandic Centre Research (RANNIS); Marie Curie FellowshipEuropean Community programme Structuring ERA contract number MIRG-CT2005-017284. appreciate help Josh Sterling, Stephen Hladky Daniel Huntley.ReferencesAnwar, M. A., & Yoshida, T. (2001). Integrating OO road network database, cases knowledgeroute finding. ACM Symposium Applied Computing (SAC), pp. 215219. ACM.Barto, A. G., Bradtke, S. J., & Singh, S. P. (1995). Learning act using real-time dynamic programming. Artificial Intelligence, 72(1), 81138.BioWare Corp. (1998). Baldurs Gate., Published Interplay, http://www.bioware.com/bgate/,November 30, 1998.297fiB ULITKO , B J ORNSSON , & L AWRENCEBjornsson, Y., Bulitko, V., & Sturtevant, N. (2009). TBA*: Time-bounded A*. ProceedingsInternational Joint Conference Artificial Intelligence (IJCAI), pp. 431 436, Pasadena,California. AAAI Press.Bjornsson, Y., & Halldorsson, K. (2006). Improved heuristics optimal path-finding gamemaps. Laird, J. E., & Schaeffer, J. (Eds.), Proceedings Second Artificial IntelligenceInteractive Digital Entertainment Conference (AIIDE), June 20-23, 2006, Marina delRey, California, pp. 914. AAAI Press.Blizzard Entertainment (2002). Warcraft III: Reign chaos., Published Blizzard Entertainment,http://www.blizzard.com/war3, July 3, 2002.Bonet, B., & Geffner, H. (2001). Planning heuristic search. Artificial Intelligence, 129(12),533.Bonet, B., & Geffner, H. (2006). Learning depth-first search: unified approach heuristic searchdeterministic non-deterministic settings, application MDPs. ProceedingsInternational Conference Automated Planning Scheduling (ICAPS), pp. 142151, Cumbria, UK.Bonet, B., Loerincs, G., & Geffner, H. (1997). fast robust action selection mechanismplanning. Proceedings National Conference Artificial Intelligence (AAAI), pp.714719, Providence, Rhode Island. AAAI Press / MIT Press.Branting, K., & Aha, D. W. (1995). Stratified case-based reasoning: Reusing hierarchical problemsolving episodes. Proceedings International Joint Conference Artificial Intelligence (IJCAI), pp. 384390.Bulitko, V. (2004).Learning adaptive real-time search.Tech.http://arxiv.org/abs/cs.AI/0407016, Computer Science Research Repository (CoRR).rep.Bulitko, V., & Bjornsson, Y. (2009). kNN LRTA*: Simple subgoaling real-time search.Proceedings Artificial Intelligence Interactive Digital Entertainment (AIIDE), pp. 27,Stanford, California. AAAI Press.Bulitko, V., Bjornsson, Y., Lustrek, M., Schaeffer, J., & Sigmundarson, S. (2007). Dynamic Control Path-Planning Real-Time Heuristic Search. Proceedings InternationalConference Automated Planning Scheduling (ICAPS), pp. 4956, Providence, RI.Bulitko, V., & Lee, G. (2006). Learning real time search: unifying framework. JournalArtificial Intelligence Research (JAIR), 25, 119157.Bulitko, V., Lustrek, M., Schaeffer, J., Bjornsson, Y., & Sigmundarson, S. (2008). Dynamic controlreal-time heuristic search. Journal Artificial Intelligence Research (JAIR), 32, 419 452.Bulitko, V., Sturtevant, N., Lu, J., & Yau, T. (2007). Graph abstraction real-time heuristic search.Journal Artificial Intelligence Research (JAIR), 30, 51100.Carbonell, J. G., Knoblock, C., & Minton, S. (1990). Prodigy: integrated architecture planning learning. Lehn, K. V. (Ed.), Architectures Intelligence. Lawrence ErlbaumAssociates.Cazenave, T. (2006). Optimizations data structures, heuristics algorithms path-findingmaps. Louis, S. J., & Kendall, G. (Eds.), Proceedings 2006 IEEE Symposium298fiC ASE -BASED UBGOALING R EAL -T IME H EURISTIC EARCHComputational Intelligence Games (CIG06), University Nevada, Reno, campusReno/Lake Tahoe, 22-24 May, 2006, pp. 2733. IEEE.Culberson, J., & Schaeffer, J. (1998). Pattern Databases. Computational Intelligence, 14(3), 318334.Furcy, D., & Koenig, S. (2000). Speeding convergence real-time search. ProceedingsNational Conference Artificial Intelligence (AAAI), pp. 891897.GasPowered Games (2007).Supreme Commander.,http://www.supremecommander.com/, February 20, 2007.PublishedTHQ,Geisberger, R., Sanders, P., Schultes, D., & Delling, D. (2008). Contraction hierarchies: Fastersimpler hierarchical routing road networks. McGeoch, C. C. (Ed.), WEA, Vol. 5038Lecture Notes Computer Science, pp. 319333. Springer.Haigh, K., & Veloso, M. (1993). Combining search analogical reasoning path planningroad maps. Proceedings AAAI-93 Workshop Case-Based Reasoning, pp. 7985,Washington, DC. AAAI. AAAI Press technical report WS-93-01.Hart, P., Nilsson, N., & Raphael, B. (1968). formal basis heuristic determinationminimum cost paths. IEEE Transactions Systems Science Cybernetics, 4(2), 100107.Hernandez, C., & Meseguer, P. (2005a). Improving convergence LRTA*(k). ProceedingsInternational Joint Conference Artificial Intelligence (IJCAI), Workshop PlanningLearning Priori Unknown Dynamic Domains, pp. 6975, Edinburgh, UK.Hernandez, C., & Meseguer, P. (2005b). LRTA*(k). Proceedings International JointConference Artificial Intelligence (IJCAI), pp. 12381243, Edinburgh, UK.Hodal, J., & Dvorak, J. (2008). Using case-based reasoning mobile robot path planning. Engineering Mechanics, 15, 181191.Hoffmann, J. (2000). heuristic domain independent planning use enforced hillclimbing algorithm. Proceedings 12th International Symposium MethodologiesIntelligent Systems (ISMIS), pp. 216227.Ishida, T. (1992). Moving target search intelligence. National Conference ArtificialIntelligence (AAAI), pp. 525532.Koenig, S. (2004). comparison fast search methods real-time situated agents. Proceedings Int. Joint Conf. Autonomous Agents Multiagent Systems, pp. 864 871.Koenig, S., Furcy, D., & Bauer, C. (2002). Heuristic search-based replanning. ProceedingsInt. Conference Artificial Intelligence Planning Scheduling, pp. 294301.Koenig, S., & Likhachev, M. (2006). Real-time adaptive A*. Proceedings InternationalJoint Conference Autonomous Agents Multiagent Systems (AAMAS), pp. 281288.Korf, R. (1985). Depth-first iterative deepening: optimal admissible tree search. Artificial Intelligence, 27(3), 97109.Korf, R. (1990). Real-time heuristic search. Artificial Intelligence, 42(23), 189211.Likhachev, M., Ferguson, D. I., Gordon, G. J., Stentz, A., & Thrun, S. (2005). Anytime dynamicA*: anytime, replanning algorithm. ICAPS, pp. 262271.299fiB ULITKO , B J ORNSSON , & L AWRENCELikhachev, M., Gordon, G. J., & Thrun, S. (2004). ARA*: Anytime A* provable boundssub-optimality. Thrun, S., Saul, L., & Scholkopf, B. (Eds.), Advances Neural Information Processing Systems 16. MIT Press, Cambridge, MA.Lustrek, M., & Bulitko, V. (2006). Lookahead pathology real-time path-finding. ProceedingsNational Conference Artificial Intelligence (AAAI), Workshop Learning Search,pp. 108114, Boston, Massachusetts.Moore, A. (1991). Efficient Memory-based Learning Robot Control. Ph.D. thesis, UniversityCambridge.Nebel, B., & Koehler, J. (1995). Plan reuse versus plan generation: theoretical empiricalanalysis. Artificial Intelligence, 76, 427454.Rayner, D. C., Davison, K., Bulitko, V., Anderson, K., & Lu, J. (2007). Real-time heuristic searchpriority queue. Proceedings International Joint Conference ArtificialIntelligence (IJCAI), pp. 23722377, Hyderabad, India.Russell, S., & Wefald, E. (1991). right thing: Studies limited rationality. MIT Press.Shimbo, M., & Ishida, T. (2003). Controlling learning process real-time heuristic search.Artificial Intelligence, 146(1), 141.Shue, L.-Y., Li, S.-T., & Zamani, R. (2001). intelligent heuristic algorithm project schedulingproblems. Proceedings 32nd Annual Meeting Decision Sciences Institute, SanFrancisco.Shue, L.-Y., & Zamani, R. (1993). admissible heuristic search algorithm. Proceedings7th International Symposium Methodologies Intelligent Systems (ISMIS-93), Vol. 689LNAI, pp. 6975.Sigmundarson, S., & Bjornsson, Y. (2006). Value Back-Propagation vs. Backtracking RealTime Search. Proceedings National Conference Artificial Intelligence (AAAI),Workshop Learning Search, pp. 136141, Boston, Massachusetts, USA.Stenz, A. (1995). focussed D* algorithm real-time replanning. ProceedingsInternational Joint Conference Artificial Intelligence (IJCAI), pp. 16521659.Sturtevant, N. (2007). Memory-efficient abstractions pathfinding. Proceedings thirdconference Artificial Intelligence Interactive Digital Entertainment, pp. 3136, Stanford, California.Sturtevant, N., & Buro, M. (2005). Partial pathfinding using map abstraction refinement.Proceedings National Conference Artificial Intelligence (AAAI), pp. 13921397,Pittsburgh, Pennsylvania.Sturtevant, N. R., Felner, A., Barrer, M., Schaeffer, J., & Burch, N. (2009). Memory-based heuristicsexplicit state spaces. Boutilier, C. (Ed.), IJCAI 2009, Proceedings 21st International Joint Conference Artificial Intelligence, Pasadena, California, USA, July 11-17,2009, pp. 609614.Valve Corporation (2004).Counter-Strike: Source., Published Valve Corporation,http://store.steampowered.com/app/240/, October 7, 2004.Weng, M., Wei, X., Qu, R., & Cai, Z. (2009). path planning algorithm based typical casereasoning. Geo-spatial Information Science, 12, 6671.300fiJournal Artificial Intelligence Research 39 (2010) 533-579Submitted 12/09; published 10/10Theta*: Any-Angle Path Planning GridsKenny DanielAlex NashSven KoenigKFDANIEL @ USC . EDUANASH @ USC . EDUSKOENIG @ USC . EDUComputer Science DepartmentUniversity Southern CaliforniaLos Angeles, California 90089-0781, USAAriel FelnerFELNER @ BGU . AC . ILDepartment Information Systems EngineeringBen-Gurion University NegevBeer-Sheva, 85104, IsraelAbstractGrids blocked unblocked cells often used represent terrain robotics videogames. However, paths formed grid edges longer true shortest paths terrainsince headings artificially constrained. present two new correct complete anyangle path-planning algorithms avoid shortcoming. Basic Theta* Angle-PropagationTheta* variants A* propagate information along grid edges without constrainingpaths grid edges. Basic Theta* simple understand implement, fast finds short paths.However, guaranteed find true shortest paths. Angle-Propagation Theta* achievesbetter worst-case complexity per vertex expansion Basic Theta* propagating angle rangesexpands vertices, complex, fast finds slightly longer paths.refer Basic Theta* Angle-Propagation Theta* collectively Theta*. Theta* uniqueproperties, analyze detail. show experimentally finds shorter pathsA* post-smoothed paths Field D* (the version A* knowpropagates information along grid edges without constraining paths grid edges) runtimecomparable A* grids. Finally, extend Theta* grids contain unblocked cellsnon-uniform traversal costs introduce variants Theta* provide different tradeoffspath length runtime.1. Introductionarticle, study path planning robotics video games (Choset, Lynch, Hutchinson,Kantor, Burgard, Kavraki, & Thrun, 2005; Deloura, 2000; Patel, 2000; Murphy, 2000; Rabin, 2002),two-dimensional continuous terrain discretized grid blocked unblockedcells. objective find short unblocked path given start vertex given goal vertex(both corners cells). A* finds grid paths (that is, paths constrained grid edges) quickly,grid paths often true shortest paths (that is, shortest paths terrain) since potentialheadings artificially constrained multiples 45 degrees, shown Figure 1(a) (Yap, 2002).shortcoming led introduction call any-angle path planning (Nash, Daniel,Koenig, & Felner, 2007; Ferguson & Stentz, 2006). Any-angle path-planning algorithms find pathsc2010AI Access Foundation. rights reserved.fiDANIEL , NASH , KOENIG , & F ELNER12345startBC12345startBCgoal(a) Grid pathgoal(b) True shortest pathFigure 1: Grid path versus true shortest pathwithout constraining headings paths, shown Figure 1(b). present two newcorrect complete any-angle path-planning algorithms. Basic Theta* Angle-PropagationTheta* variants A* propagate information along grid edges (to achieve shortruntime) without constraining paths grid edges (to find any-angle paths). Unlike A* visibilitygraphs, guaranteed find true shortest paths. asterisk names thusdenote optimality rather similarity A*. Basic Theta* simple understandimplement, fast finds short paths. Angle-Propagation Theta* achieves worst-case complexityper vertex expansion constant rather linear number cells (like BasicTheta*) propagating angle ranges expands vertices, complex, fastfinds slightly longer paths. refer Basic Theta* Angle-Propagation Theta* collectivelyTheta*. Theta* unique properties, analyze detail. show experimentallyfinds shorter paths A* post-smoothed paths Field D* (the versionA* know propagates information along grid edges without constraining paths gridedges) runtime comparable A* grids. Finally, extend Theta* gridscontain unblocked cells non-uniform traversal costs introduce variants Theta*provide different tradeoffs path length runtime.2. Path-Planning Problem Notationsection, describe path-planning problem study article, namely pathplanning eight-neighbor grids blocked unblocked cells uniform size. Cells labeledeither blocked (grey) unblocked (white). use corners cells (rather centers)vertices. set vertices. path-planning problem find unblocked pathgiven start vertex sstart given goal vertex sgoal .path unblocked iff vertex path line-of-sight successor path. Vertexline-of-sight vertex , written LineOfSight(s, ), iff straight line vertexvertex neither passes interior blocked cells passes blocked cellsshare edge. Pseudocode implementing line-of-sight function given Appendix A.simplicity, allow straight line pass diagonally touching blocked cells.c(s, ) length straight line vertex vertex . nghbrsvis (s) set visibleneighbors vertex eight compass directions, neighbors vertex534fiT HETA *: NY-A NGLE PATH P LANNINGG RIDSline-of-sight vertex s. Figure 1 shows example visible neighbors vertex B4vertices A3, A4, A5, B3, B5, C3 C4.3. Existing Terrain DiscretizationsContinuous terrain needs discretized path planning. section, compare gridsexisting terrain discretizations. use grids discretize terrain since widely usedrobotics video games (Deloura, 2000; Murphy, 2000; Rabin, 2004) several desirableproperties:Grids simple data structures allow simple path-planning algorithms.Terrain easily discretized grid laying grid terrain labelingcells partially completely obstructed blocked.Grids provide comprehensive picture traversable surfaces continuous terrain.essential path planning algorithm used dynamic environmentmust interact navigation planner. example robot video game characterencounters temporary blockage path, easily determine whether bestdivert left (unblocked) right (blocked) (Tozour, 2004).Cells store information addition traversability, amount goldhidden region terrain corresponds cell rendering regiondisplaying terrain.information stored cells accessed quickly since grids random access datastructures.precision path navigation planning improved simply increasing gridresolution.list alternative terrain discretizations, assuming simplicity obstaclesterrain polygonal.Voronoi graphs (Aurenhammer, 1991) discretize terrain biasing paths awayblocked polygons. resulting paths thus much longer true shortest paths.discretization work Mitchell Papadimitriou (1991) partitions terrainregions linear hyperbolic edges, allows one find true shortest pathstime space complexity O(m5/3 ), number corners blocked polygons.Thus, runtime path planning grow superlinearly number corners blockedpolygons.Framed Quadtrees (Yahja, Stentz, Singh, & Brumitt, 1998) recursively subdivide terrainfour equally sized cells cells completely obstructed, completely unobstructedsufficiently small size. resulting paths unnecessary heading changes (that is,heading changes occur free space rather corners blocked polygons).535fiDANIEL , NASH , KOENIG , & F ELNER1 Main()2g(sstart ) := 0;3parent(sstart ) := sstart ;4open := ;5open.Insert(sstart , g(sstart ) + h(sstart ));6closed := ;7open 6=8:= open.Pop();= sgoal910return path found;111213141516171819closed := closed {s};/* following line executed AP Theta*.[UpdateBounds(s)];foreach nghbrsvis (s)6 closed6 openg(s ) := ;parent(s ) := N U LL;*/;UpdateVertex(s, );20return path found;21 end22 UpdateVertex(s,s)23g(s) + c(s, ) < g(s )24g(s ) := g(s) + c(s, );25parent(s ) := s;26open27open.Remove(s );28open.Insert(s , g(s ) + h(s ));29 endAlgorithm 1: A*Probabilistic roadmaps (Kavraki, Svestka, Latombe, & Overmars, 1996) rapidly-exploringrandom trees (LaValle & Kuffner, 2001) place vertices randomly (in addition startgoal vertex). Two vertices connected via straight line iff line-of-sight.random placement vertices needs tuned carefully since influences runtimepath planning, likelihood finding path length path.Visibility graphs (Lee, 1978; Lozano-Perez & Wesley, 1979) use corners blockedpolygon vertices (in addition start goal vertex). Two vertices connected viastraight line iff line-of-sight, allows one find true shortest paths.runtime path planning grow superlinearly number vertices since numberedges grow quadratically number vertices.4. Existing Path-Planning Algorithmssection, describe existing path-planning algorithms, variants A*(Hart, Nilsson, & Raphael, 1968). A* popular path-planning algorithm robotics videogames. Algorithm 1 shows pseudocode A*. Line 13 ignored. A* maintains threevalues every vertex s:536fiT HETA *: NY-A NGLE PATH P LANNINGG RIDSg-value g(s) length shortest path start vertex vertex foundfar thus estimate start distance vertex s.user-provided h-value h(s) estimate goal distance vertex s. A* usesh-value calculate f-value focus A* search. f-value f (s) = g(s) + h(s)estimate length shortest path start vertex via vertex goal vertex.parent parent(s) used extract path start vertex goal vertex A*terminates.A* also maintains two global data structures:open list priority queue contains vertices A* considers expansion.pseudocode, open.Insert(s, x) inserts vertex key x priority queue open,open.Remove(s) removes vertex priority queue open, open.Pop() removesvertex smallest key priority queue open returns it.closed list set contains vertices A* already expanded. ensuresA* expands every vertex once.A* sets g-value every vertex infinity parent every vertex NULLencounters vertex first time [Lines 17-18]. sets g-value start vertex zeroparent start vertex start vertex [Lines 2-3]. sets open closedlists empty list inserts start vertex open list f-value key[4-6]. A* repeatedly executes following procedure: open list empty, reportspath [Line 20]. Otherwise, identifies vertex smallest f-valueopen list [Line 8]. vertex goal vertex, A* reports found path [Line 10].Path extraction [not shown pseudocode] follows parents goal vertex startvertex retrieve path start vertex goal vertex reverse. Otherwise, A* removesvertex open list [Line 8] expands inserting vertex closed list [Line11] generating unexpanded visible neighbors, follows: A* checks whetherg-value vertex plus length straight line vertex vertex smallerg-value vertex [Line 23]. so, sets g-value vertex g-value vertexplus length straight line vertex vertex , sets parent vertex vertexfinally inserts vertex open list f-value key or, alreadyopen list, sets key f-value [Lines 24-28]. repeats procedure.summarize, A* updates g-value parent unexpanded visible neighborvertex procedure UpdateVertex, considers path start vertex vertex [= g(s)]vertex vertex straight line [= c(s, )], resulting length g(s) + c(s, )[Line 23]. A* updates g-value parent vertex considered path shortershortest path start vertex vertex found far [= g(s )].describe several existing path-planning algorithms versions A*trade two conflicting criteria, namely runtime path length, shown Figure 2.introduce order decreasing path lengths.537fiDANIEL , NASH , KOENIG , & F ELNER101RuntimeA*A* PSFD*0.1Visibility GraphsBasic Theta*0.010.00111.011.021.031.041.051.06Path Length / Length True Shortest PathFigure 2: Runtime versus path length (relative length true shortest path) random 100100 grids 20 percent blocked cells30 PostSmoothPath([s0 , . . . , sn ])31k := 0;32tk := s0 ;33foreach := 1 . . . n 134LineOfSight(tk , si+1 )35k := k + 1;36tk := si ;37k := k + 1;38tk := sn ;39return [t0 , . . . , tk ];40 endAlgorithm 2: Post-smoothing4.1 A* GridsOne run A* grids, is, graphs given grid vertices edges. resultingpaths artificially constrained formed edges grid, seen Figure1(a). result paths found A* grids equivalent true shortest pathsunrealistic looking since either deviate substantially true shortest pathsmany heading changes, provides motivation smoothing them. use octiledistances, computed using Algorithm 5, h-values experiments.538fiT HETA *: NY-A NGLE PATH P LANNING12345G RIDS6goaltrue shortest pathBshortest grid pathA* PS pathCstartFigure 3: A* PS path versus true shortest path4.2 A* Post-Smoothed Paths (A* PS)One run A* post-smoothed paths (A* PS) (Thorpe, 1984). A* PS runs A* gridssmoothes resulting path post-processing step, often shortens increaseruntime. Algorithm 2 shows pseudocode simple smoothing algorithm A* PS usesexperiments (Botea, Muller, & Schaeffer, 2004), provides good tradeoffruntime path length. Assume A* grids finds path [s0 , s1 , . . . , sn ] s0 = sstartsn = sgoal . A* PS uses first vertex path current vertex. checks whethercurrent vertex s0 line-of-sight successor s2 successor path. so, A*PS removes intermediate vertex s1 path, thus shortening it. A* PS repeatsprocedure checking whether current vertex s0 line-of-sight successor s3successor path, on. soon current vertex line-of-sightsuccessor successor path, A* PS advances current vertex repeats procedurereaches end path. use straight-line distances h(s) = c(s, sgoal ) h-valuesexperiments.A* PS typically finds shorter paths A* grids, guaranteed find true shortest paths.Figure 3 shows example. Assume A* PS finds dotted blue path, one manyshortest grid paths. smoothes path solid blue path, true shortestpath. dashed red path, moves (rather below) blocked cell B2-B3-C3-C2true shortest path. A* PS guaranteed find true shortest paths considers gridpaths A* search thus cannot make informed decisions regarding pathsA* search, motivates interleaving searching smoothing. fact, Theta* similarA* PS except interleaves searching smoothing.4.3 Field D* (FD*)One run Field D* (Ferguson & Stentz, 2006) (FD*). FD* propagates information along gridedges without constraining paths grid edges. FD* designed use D* Lite (Koenig &Likhachev, 2002) fast replanning (by reusing information previous A* search speednext one) searches goal vertex start vertex. version FD* usesA* searches start vertex goal vertex, like path-planning algorithmsarticle, allows us compare fairly, except replanning abilities. (Theta*currently process extended fast replanning Nash, Koenig, & Likhachev, 2009.)539fiDANIEL , NASH , KOENIG , & F ELNER1B2342.002.322.831.001.412.415sgoal0.45C0.55Xsstart0.001.002.003.001.001.412.323.27Field D* pathFigure 4: FD* pathFigure 5: Screenshot FD* path versus true shortest pathFD* updates g-value parent unexpanded visible neighbor vertex s,considers paths start vertex point X (not necessarily vertex) perimetervertex [= g(X)] line-of-sight vertex , perimeter formed connectingneighbors vertex , point X vertex straight line [= c(X, )], resultinglength g(X) + c(X, ). FD* updates g-value parent vertex consideredpath shorter shortest path start vertex vertex found far [= g(s )]. usestraight-line distances h(s) = c(s, sgoal ) h-values experiments.Figure 4 shows example. perimeter vertex = B4 formed connectingneighbors vertex B4, shown bold. Consider point X perimeter. FD* knowg-value point X since stores g-values vertices. calculates g-value usinglinear interpolation g-values two vertices perimeter adjacentpoint X. Thus, linearly interpolates g(B3) = 2.41 g(C3) = 2.00, resultingg(X) = 0.55 2.41 + 0.45 2.00 = 2.23 since 0.55 0.45 distances point Xvertices B3 C3, respectively. calculated g-value point X different true startdistance [= 2.55] even though g-values vertices B3 C3 equal true startdistances. reason mistake simple. exist true shortest paths start vertexeither vertex C3 vertex B3 goal vertex. Thus, linear interpolation assumptionpredicts must also exist short path start vertex point alongedge connects vertices B3 C3 goal vertex. However, case since540fiT HETA *: NY-A NGLE PATH P LANNING1234G RIDS5startBCgoaltrue shortest path(a) Simple visibility graph(b) Terrain resulting complex visibility graphFigure 6: Visibility graphspaths need circumnavigate blocked cell B2-B3-C3-C2, makes longer expected.result miscalculating g-value point X, FD* sets parent vertex B4 point X,resulting path unnecessary heading change point X longer evenshortest grid path.authors FD* recognize paths found FD* frequently unnecessary headingchanges suggest use one-step look-ahead algorithm path extraction (Ferguson &Stentz, 2006), FD* uses experiments. one-step look-ahead algorithm allows FD*avoid unnecessary heading changes, like one Figure 4, eliminatethem. Figure 5 shows example FD* path red corresponding true shortestpath blue. FD* path still many unnecessary heading changes.4.4 A* Visibility GraphsOne run A* visibility graphs. visibility graph grid blocked unblockedcells contains start vertex, goal vertex corners blocked cells (Lozano-Perez &Wesley, 1979). use straight-line distances h(s) = c(s, sgoal ) h-values experiments.A* visibility graphs finds true shortest paths, shown Figure 6(a). True shortest pathsheading changes corners blocked cells, paths found A* grids, A* PSFD* unnecessary heading changes. hand, A* visibility graphsslow. propagates information along visibility graph edges, whose number grow quadraticallynumber cells, A* grids, A* PS FD* propagate information along grid edges,whose number grows linearly number cells. one constructed visibility graphsA* search, one would need perform line-of-sight check every pair cornersblocked cells determine whether visibility graph edge them,requires least 2,556 line-of-sight checks room Figure 6(b) (Tozour, 2004).number line-of-sight checks performed A* visibility graphs reduced constructing541fiDANIEL , NASH , KOENIG , & F ELNER41 UpdateVertex(s,s)42LineOfSight(parent(s), )43/* Path 2 */44g(parent(s)) + c(parent(s), ) < g(s )45g(s ) := g(parent(s)) + c(parent(s), );46parent(s ) := parent(s);47open48open.Remove(s );open.Insert(s , g(s ) + h(s ));495051525354555657else/* Path 1 */g(s) + c(s, ) < g(s )g(s ) := g(s) + c(s, );parent(s ) := s;openopen.Remove(s );open.Insert(s , g(s ) + h(s ));58 endAlgorithm 3: Basic Theta*visibility graphs A* search. expands vertex, performs line-of-sight checksexpanded vertex corners blocked cells (and goal vertex).significantly reduce number line-of-sight checks performed environments,simple outdoor terrain, fails others, cluttered indoor terrain.complex optimizations, reduced visibility graphs reduce number line-ofsight checks, sufficiently speed A* visibility graphs (Liu & Arimoto, 1992).5. Basic Theta*section, introduce Theta* (Nash et al., 2007), version A* any-angle pathplanning propagates information along grid edges without constraining paths grid edges.combines ideas behind A* visibility graphs (where heading changes occurcorners blocked cells) A* grids (where number edges grows linearlynumber cells). paths slightly longer true shortest paths (as found A*visibility graphs), yet slightly slower A* grids, shown Figure 2. keydifference Theta* A* grids parent vertex vertexusing Theta*, parent vertex neighbor vertex using A*.first introduce Basic Theta*, simple version Theta*.Algorithm 3 shows pseudocode Basic Theta*. Procedure Main identical A*Algorithm 1 thus shown. Line 13 ignored. use straight-line distancesh(s) = c(s, sgoal ) h-values experiments.5.1 Operation Basic Theta*Basic Theta* simple. identical A* except that, updates g-value parentunexpanded visible neighbor vertex procedure UpdateVertex, considers two paths542fiT HETA *: NY-A NGLE PATH P LANNING12341sgoalBCPath 1G RIDS234sstartBC5Path 2sstartsgoalPath 1(a) Path 2 unblocked5Path 2(b) Path 2 blockedFigure 7: Paths 1 2 considered Basic Theta*instead one path considered A*. Figure 7(a) shows example. Basic Theta*expanding vertex B3 parent A4 needs update g-value parent unexpandedvisible neighbor C3. Basic Theta* considers two paths:Path 1: Basic Theta* considers path start vertex vertex [= g(s)]vertex vertex straight line [= c(s, )], resulting length g(s) + c(s, ) [Line52]. Path 1 path considered A*. corresponds dashed red path [A4, B3, C3]Figure 7(a)).Path 2: Basic Theta* also considers path start vertex parent vertex [=g(parent(s))] parent vertex vertex straight line [= c(parent(s), )],resulting length g(parent(s)) + c(parent(s), ) [Line 44]. Path 2 consideredA* allows Basic Theta* construct any-angle paths. corresponds solid bluepath [A4, C3] Figure 7(a).Path 2 longer Path 1 due triangle inequality. triangle inequality stateslength side triangle longer sum lengths two sides.applies since Path 1 consists path start vertex parent vertex s,straight line parent vertex vertex (Line A) straight line vertexvertex (Line B), Path 2 consists path start vertex parent vertexstraight line parent vertex vertex (Line C) Lines A, B C formtriangle. Path 1 guaranteed unblocked Path 2 not. Thus, Basic Theta* chooses Path2 Path 1 vertex line-of-sight parent vertex Path 2 thus unblocked.Figure 7(a) shows example. Otherwise, Basic Theta* chooses Path 1 Path 2. Figure 7(b)shows example. Basic Theta* updates g-value parent vertex chosen pathshorter shortest path start vertex vertex found far [= g(s )]. usestraight-line distances h(s) = c(s, sgoal ) h-values experiments.543fiDANIEL , NASH , KOENIG , & F ELNER1254311.000.001.00A4sstartA4B1.411.001.41A4A4A4Csgoal23BCA4sgoal21.00A4sstartA42.411.411.001.41B3A4A4A42.832.242.00A4A4A4(b)343.823.411.000.001.00B2B2A4sstartA4B3.412.411.411.001.41B3B3A4A4A43.652.832.242.00B3A4A4A4sgoal15C50.00(a)141.0023453.823.411.000.001.00B2B2A4sstartA4B3.412.411.411.001.41B3B3A4A4A4C3.652.832.242.00B3A4A4A4sgoal(c)(d)Figure 8: Example trace Basic Theta*5.2 Example Trace Basic Theta*Figure 8 shows example trace Basic Theta*. vertices labeled g-valuesparents. arrows point parents. Red circles indicate vertices expanded,blue arrows indicate vertices generated current expansion. First, Basic Theta*expands start vertex A4 parent A4, shown Figure 8(a). sets parent unexpandedvisible neighbors vertex A4 vertex A4, like A* would do. Second, Basic Theta* expandsvertex B3 parent A4, shown Figure 8(b). Vertex B2 unexpanded visible neighborvertex B3 line-of-sight vertex A4. Basic Theta* thus updates accordingPath 1 sets parent vertex B3. hand, vertices C2, C3 C4 unexpandedvisible neighbors vertex B3 line-of-sight vertex A4. Basic Theta* thus updatesaccording Path 2 sets parents vertex A4. (The g-values parentsunexpanded visible neighbors vertex B3 updated.) Third, Basic Theta* expands vertexB2 parent B3, shown Figure 8(c). Vertices A1 A2 unexpanded visible neighborsvertex B2 line-of-sight vertex B3. Basic Theta* thus updates accordingPath 1 sets parents vertex B2. hand, vertices B1 C1 unexpandedvisible neighbors vertex B2 line-of-sight vertex B3. Basic Theta* thus updatesaccording Path 2 sets parents vertex B3. Fourth, Basic Theta* expands goalvertex C1 parent B3 terminates, shown Figure 8(d). Path extraction followsparents goal vertex C1 start vertex A4 retrieve true shortest path [A4, B3, C1]start vertex goal vertex reverse.544fiT HETA *: NY-A NGLE PATH P LANNINGG RIDS5.3 Properties Basic Theta*discuss properties Basic Theta*.5.3.1 C ORRECTNESSC OMPLETENESSBasic Theta* correct (that is, finds unblocked paths start vertex goal vertex)complete (that is, finds path start vertex goal vertex one exists). usefollowing lemmata proof.Lemma 1. exists unblocked path two vertices also exists unblockedgrid path two vertices.Proof. unblocked path two vertices exists iff unblocked any-angle path [s0 , . . . , sn ]exists two vertices. Consider path segment sk sk+1 any-angle path.path segment horizontal vertical, consider unblocked grid path vertex skvertex sk+1 coincides path segment. Otherwise, consider sequence (b0 , . . . , bm )unblocked cells whose interior path segment passes through. two consecutive cellsbj bj+1 share least one vertex sj+1 since cells either share edge diagonallytouching. (If share one vertex, pick one arbitrarily.) Consider grid path [s0 =sk , s1 , . . . , sm , sm+1 = sk+1 ]. grid path vertex sk vertex sk+1 unblocked sincetwo consecutive vertices corners unblocked cell thus visible neighbors.Repeat procedure every path segment any-angle path concatenate resultinggrid paths unblocked grid path vertex s0 vertex sn . (If several consecutive verticesgrid path identical, one removed.)Lemma 2. point execution Basic Theta*, following parents vertexopen closed lists start vertex retrieves unblocked path start vertexvertex reverse.Proof. prove induction lemma holds parent vertex unionopen closed lists union open closed lists. statement holdsinitially start vertex vertex union open closed listsparent. show statement continues hold whenever vertex changes eitherparent membership union open closed lists. vertex memberunion open closed lists, continues member. vertex become memberunion open closed lists Basic Theta* expands vertex updatesg-value parent unexpanded visible neighbor vertex procedure UpdateVertex.Vertex thus closed list, parent union open closed lists accordinginduction assumption. Thus, following parents vertex (or parent) startvertex retrieves unblocked path start vertex vertex (or parent, respectively)reverse according induction assumption. Basic Theta* updates vertex according Path1, statement continues hold since vertices visible neighbors pathsegment vertex vertex thus unblocked. Basic Theta* updates vertex accordingPath 2, statement continues hold since Basic Theta* explicitly checks path545fiDANIEL , NASH , KOENIG , & F ELNERsegment parent vertex vertex unblocked. waysparent vertex change.Theorem 1. Basic Theta* terminates path extraction retrieves unblocked path startvertex goal vertex path exists. Otherwise, Basic Theta* terminates reportsunblocked path exists.Proof. following properties together prove theorem. proofs utilize fact BasicTheta* terminates iff open empty expands goal vertex. start vertex initiallyopen list. vertex initially neither open closed lists. vertex neitheropen closed lists inserted open list. vertex open list removedopen list inserted closed list. vertex closed list remains closed list.Property 1: Basic Theta* terminates. expands one vertex open listiteration. process, removes vertex open list never insertopen list again. Since number vertices finite, open list eventually becomesempty Basic Theta* terminate terminated earlier already.Property 2: Basic Theta* terminates open list empty,exist unblocked path start vertex goal vertex. prove contrapositive.Assume exists unblocked path start vertex goal vertex. provecontradiction Basic Theta* terminate open list empty.Thus, assume also Basic Theta* terminates open list empty. Then,exists unblocked grid path [s0 = sstart , . . . , sn = sgoal ] start vertex goalvertex according Lemma 1. Choose vertex si first vertex grid pathclosed list Basic Theta* terminates. goal vertex closed listBasic Theta* terminates since Basic Theta* would otherwise terminatedexpanded goal vertex. Thus, vertex si exists. Vertex si start vertex since startvertex would otherwise open list Basic Theta* could terminatedopen list empty. Thus, vertex si predecessor grid path. predecessorclosed list Basic Theta* terminates since vertex si first vertex gridpath closed list Basic Theta* terminates. Basic Theta* expandedpredecessor, added vertex si open list. Thus, vertex si still open listBasic Theta* terminates. Basic Theta* could terminated openlist empty, contradiction.Property 3: Basic Theta* terminates expands goal vertex, path extractionretrieves unblocked path start vertex goal vertex followingparents goal vertex start vertex retrieves unblocked path startvertex goal vertex reverse according Lemma 2.546fiT HETA *: NY-A NGLE PATH P LANNING12345G RIDS678910678910BCEstart(a)12345BCEstart(b)true shortest pathBasic Theta* pathFigure 9: Basic Theta* paths versus true shortest paths5.3.2 PTIMALITYBasic Theta* optimal (that is, guaranteed find true shortest paths)parent vertex either visible neighbor vertex parent visible neighbor,always case true shortest paths. Figure 9(a) shows example dashedred path [E1, B9] true shortest path start vertex E1 vertex B9 since vertex E1 lineof-sight vertex B9. However, vertex E1 neither visible neighbor parent visibleneighbor vertex B9 since vertex E1 line-of-sight vertices (highlightedred). Thus, Basic Theta* cannot set parent vertex B9 vertex E1 find trueshortest path vertex E1 vertex B9. Similarly, Figure 9(b) shows exampledashed red path [E1, D8, C10] true shortest path vertex E1 vertex C10. However, vertexD8 neither visible neighbor parent visible neighbor vertex C10 since start vertexE1 either line-of-sight Basic Theta* found paths vertex E1547fiDANIEL , NASH , KOENIG , & F ELNER1 sstart23456BCf=6.02f=6.00true shortest pathsgoalf=6.00Basic Theta* pathFigure 10: Heading changes Basic Theta*contain vertex D8. fact, truly shortest paths vertex E1 visible neighbors vertexC10 vertex E1 line-of-sight move (rather below) blocked cell C7C8-D8-D7. Thus, Basic Theta* cannot set parent vertex C10 vertex D8 thusfind true shortest path vertex E1 vertex C10. solid blue path vertex E1 vertexB9 Figure 9(a) solid blue path vertex E1 vertex C10 Figure 9(b) lessfactor 1.002 longer true shortest paths.5.3.3 H EADING C HANGESBasic Theta* takes advantage fact true shortest paths heading changescorners blocked cells. However, paths found Basic Theta* occasionallyunnecessary heading changes. Figure 10 shows example Basic Theta* finds solid bluepath [A1, D5, D6] vertex A1 vertex D6. reason mistake simple. Assumeopen list contains vertices C5 D5. f-value vertex C5 f (C5) = g(C5) +h(C5) = 4.61 + 1.41 = 6.02 parent vertex C4. f-value vertex D5 f (D5) =5.00 + 1.00 = 6.00 parent vertex A1. Thus Basic Theta* expands vertex D5vertex C5 (since f-value smaller). Basic Theta* expands vertex D5 parent A1,generates vertex D6. Vertex D6 unexpanded visible neighbor vertex D5line-of-sight vertex A1. Basic Theta* thus updates according Path 1, sets f-valuef (D6) = 6.00 + 0.00 = 6.00, sets parent vertex D5 inserts open list. ThusBasic Theta* expands goal vertex D6 vertex C5 (since f-value smaller) terminates.Path extraction follows parents goal vertex D6 start vertex A1 retrieve solidblue path [A1, D5, D6]. Thus, Basic Theta* never expands vertex C5, would resultedsetting parent vertex D6 vertex C4 according Path 2 path extraction retrievingdashed red path [A1, C4, D6] true shortest path. solid blue path vertex A1vertex D6 Figure 10 less factor 1.027 longer true shortest path.548fiT HETA *: NY-A NGLE PATH P LANNINGG RIDS59 UpdateVertex(s,s)606= sstart lb(s) (s, parent(s), ) ub(s)61/* Path 2 */62g(parent(s)) + c(parent(s), ) < g(s )63g(s ) := g(parent(s)) + c(parent(s), );64parent(s ) := parent(s);65open66open.Remove(s );open.Insert(s , g(s ) + h(s ));676869707172737475else/* Path 1 */g(s) + c(s, ) < g(s )g(s ) := g(s) + c(s, );parent(s ) := s;openopen.Remove(s );open.Insert(s , g(s ) + h(s ));76 end77 UpdateBounds(s)78lb(s) := ; ub(s) := ;796= sstart80foreach blocked cell b adjacent81corners(b) : parent(s) = (s, parent(s), ) < 082((s, parent(s), ) = 0 c(parent(s), ) c(parent(s), s))83lb(s) = 0;8485868788899091929394959697corners(b) : parent(s) = (s, parent(s), ) > 0((s, parent(s), ) = 0 c(parent(s), ) c(parent(s), s))ub(s) = 0;foreach nghbrsvis (s)closed parent(s) = parent(s ) 6= sstartlb(s ) + (s, parent(s), ) 0lb(s) := max(lb(s), lb(s ) + (s, parent(s), ));ub(s ) + (s, parent(s), ) 0ub(s) := min(ub(s), ub(s ) + (s, parent(s), ));c(parent(s), ) < c(parent(s), s) parent(s) 6= (s 6 closed parent(s) 6= parent(s ))(s, parent(s), ) < 0lb(s) := max(lb(s), (s, parent(s), ));(s, parent(s), ) > 0ub(s) := min(ub(s), (s, parent(s), ));98 endAlgorithm 4: AP Theta*6. Angle-Propagation Theta* (AP Theta*)runtime Basic Theta* per vertex expansion (that is, runtime consumed generation unexpanded visible neighbors expanding vertex) linear numbercells since runtime line-of-sight check linear number cells.section, introduce Angle-Propagation Theta* (AP Theta*), reduces runtime Basic549fiDANIEL , NASH , KOENIG , & F ELNER12B341562CEFFigure 11: Region points line-of-sight vertexTheta* per vertex expansion linear constant.1 key difference AP Theta*Basic Theta* AP Theta* propagates angle ranges uses determine whethertwo vertices line-of-sight.light source vertex light cannot pass blocked cells, cellsshadows line-of-sight vertex cells line-of-sight vertex.contiguous region points line-of-sight vertex characterized tworays emanating vertex thus angle range defined two angle bounds. Figure11 shows example points within red angle range defined two angle bounds1 2 line-of-sight vertex s. AP Theta* calculates angle range vertexexpands vertex propagates along grid edges, resulting constant runtime pervertex expansion since angle ranges propagated constant time line-of-sightchecks performed constant time well.Algorithm 4 shows pseudocode AP Theta*. Procedure Main identical A*Algorithm 1 thus shown. Line 13 executed. use straight-line distancesh(s) = c(s, sgoal ) h-values experiments.6.1 Definition Angle Rangesdiscuss key concept angle range. AP Theta* maintains two additional valuesevery vertex s, namely lower angle bound lb(s) vertex upper angle bound ub(s)vertex s, together form angle range [lb(s), ub(s)] vertex s. angle bounds correspondheadings rays (measured degrees) originate parent vertex s. headingray parent vertex vertex zero degrees. visible neighbor vertexguaranteed line-of-sight parent vertex (but necessarily if) headingray parent vertex visible neighbor vertex contained angle1. AP Theta* provides significant improvement worst case complexity Basic Theta*, experimental results Section 7 show slower finds slightly longer paths Basic Theta*.550fiT HETA *: NY-A NGLE PATH P LANNING1234G RIDS5sstartlbB18O27CsgoalubFigure 12: Angle range AP Theta*range vertex s. Figure 12 shows example vertex C3 parent A4 angle range[18, 27]. Thus, visible neighbors vertex C3 red region guaranteed line-ofsight parent vertex C3. example, vertex C4 guaranteed line-of-sightparent vertex C3 vertex B2 not. AP Theta* therefore assumes vertex B2line-of-sight parent vertex C3.define concept angle range formally. (s, p, ) [90, 90], givesAP Theta* name, angle (measured degrees) ray vertex p vertexray vertex p vertex . positive ray vertex p vertex clockwiseray vertex p vertex , zero ray vertex p vertex headingray vertex p vertex , negative ray vertex p vertex counterclockwiseray vertex p vertex . Figure 12 shows example (C3, A4, C4) = 27(C3, A4, B3) = 18. visible neighbor vertex guaranteed line-of-sightparent vertex (but necessarily if) lb(s) (s, parent(s), ) ub(s) (VisibilityProperty).6.2 Update Angle Rangesdiscuss AP Theta* calculates angle range vertex expands vertex.calculation complicated fact AP Theta* guaranteed sufficientinformation determine angle range exactly since order vertex expansions dependsvariety factors, h-values. case, AP Theta* constrain angle rangenecessary guarantee Visibility Property holds finds unblocked paths.AP Theta* expands vertex s, sets angle range vertex initially [, ], meaningvisible neighbors vertex guaranteed line-of-sight parent vertex.constrains angle range vertex start vertex.AP Theta* constrains angle range vertex based blocked cell b adjacentvertex (that is, vertex corner b, written corners(b)) provided least onetwo conditions satisfied:Case 1: every corner blocked cell b satisfies least one following conditions:parent(s) =551fiDANIEL , NASH , KOENIG , & F ELNER(s, parent(s), ) < 0(s, parent(s), ) = 0 c(parent(s), ) c(parent(s), s),AP Theta* assumes vertex line-of-sight parent vertexray parent vertex vertex counterclockwise rayparent vertex vertex , is, (s, parent(s), ) < 0. AP Theta* therefore setslower angle bound vertex (s, parent(s), s) = 0 [Line 83].Case 2: every corner blocked cell b satisfies least one following conditions:parent(s) =(s, parent(s), ) > 0(s, parent(s), ) = 0 c(parent(s), ) c(parent(s), s),AP Theta* assumes vertex line-of-sight parent vertexray parent vertex vertex clockwise ray parentvertex vertex , is, (s, parent(s), ) > 0. AP Theta* therefore sets upperangle bound vertex (s, parent(s), s) = 0 [Line 86].AP Theta* also constrains angle range vertex based visible neighbor vertexprovided least one two conditions satisfied:Case 3: vertex satisfies following conditions:closedparent(s) = parent(s )6= sstart ,AP Theta* constrains angle range vertex intersecting angle rangevertex [Lines 90 92]. that, first shifts angle range vertex(s, parent(s), ) degrees take account angle range vertex calibratedheading ray joint parent vertices vertex zerodegrees, angle range vertex calibrated heading rayjoint parent vertices vertex zero degrees. Lines 89 91 ensurelower angle bound always remains non-positive upper angle bound always remainsnon-negative, respectively. fact lower angle bounds non-positive (andupper angle bounds non-negative) intuitive vertex assigned parent vertex pangle ray vertex p vertex included angle rangevertex s.Case 4: vertex satisfies following conditions:c(parent(s), ) < c(parent(s), s)parent(s) 6=552fiT HETA *: NY-A NGLE PATH P LANNINGG RIDS6 closed parent(s) 6= parent(s ),AP Theta* insufficient information vertex . AP Theta* therefore cannotdetermine angle range vertex exactly makes conservative assumptionvertex barely line-of-sight parent vertex [Lines 95 97].Visibility Property holds AP Theta* updated angle range vertex procedureUpdateBounds. Thus, AP Theta* checks whether visible neighbor vertexline-of-sight parent vertex s, checks whether lb(s) (s, parent(s), )ub(s) [Line 60] true instead whether LineOfSight(parent(s), ) [Line 42] true .differences AP Theta* Basic Theta*.Figure 13(a) shows example AP Theta* calculates angle range vertex A4. setsangle range [, ]. Figure 13(b) shows example AP Theta* calculates anglerange vertex B3. sets angle range initially [, ]. sets lower angle bound0 degrees according Case 1 based blocked cell A2-A3-B3-B2 [Line 83]. setsupper angle bound 45 degrees according Case 4 based vertex B4, unexpandedthus closed list [Line 97]. Figure 13(c) shows example AP Theta* calculatesangle range vertex B2. sets angle range initially [, ]. sets lowerangle bound 0 degrees according Case 1 based blocked cell A2-A3-B3-B2 [Line 83].Assume vertex C1 goal vertex. Figure 13(d) shows example AP Theta*calculates angle range vertex C1. sets angle range initially [, ]. setslower angle bound -27 degrees according Case 3 based vertex B2 [Line 90] upperangle bound 18 degrees according Case 4 based vertex C2, unexpanded thusclosed list [Line 97].6.3 Example Trace AP Theta*Figure 13 shows example trace AP Theta* using path-planning problem Figure 8.labels vertices include angle ranges.6.4 Properties AP Theta*discuss properties AP Theta*. AP Theta* operates way Basic Theta*thus similar properties Basic Theta*. example, AP Theta* correct complete.guaranteed find true shortest paths, paths occasionally unnecessary headingchanges.AP Theta* sometimes constrains angle ranges necessary guarantee findsunblocked paths, means line-of-sight checks sometimes fail incorrectly caseupdate vertices according Path 1 rather Path 2. AP Theta* still complete sincefinds unblocked grid path line-of-sight checks fail, always exists unblockedgrid path exists unblocked any-angle path. However, paths found AP Theta*longer found Basic Theta*. Figure 14 shows example. AP Theta* expandsvertex C4 parent B1 calculates angle range vertex C4, vertex C3 unexpandedthus closed list. means AP Theta* insufficient information vertex553fiDANIEL , NASH , KOENIG , & F ELNER234151.000.001.00A4sstartA4341.00A4]88[ ,2B1.411.001.41A4A4A4C2.411.411.001.41B3A4[0,45]A4A4C2.832.242.00A4A4A42(b)33.823.41B2B24150.001.00A41.00A4sstart233.823.41B2B241.00A4]2.41B3B3[0, ]C3.652.83B3A41.41A4[0,45]1.00A42.24A42.00A4B1.41A43.412.41B3B3[0, ]3.652.83B3[27,18]A483.418B50.00sstart1.00A4[ , ]88[ ,8811.00A4sstart[ , ]B(a)50.00881C(c)1.41A4[0,45]1.00A42.24A42.00A41.41A4(d)Figure 13: Example trace AP Theta*123456BCstart111100000000111100001111000011110000111100001111000011110000111100001111sgoalBasic Theta* pathAP Theta* pathFigure 14: Basic Theta* path versus AP Theta* pathC3 because, example, know whether cell C2-C3-D3-D2 unblocked. APTheta* therefore cannot determine angle range vertex C4 exactly makes conservativeassumption vertex C3 barely line-of-sight vertex B1 sets lower angle boundvertex C4 according Case 4 based vertex C3. uses resulting angle rangedetermine unexpanded visible neighbor D4 vertex C4 guaranteed line-ofsight vertex B1. However, vertex D4 line-of-sight vertex B1 cell C2-C3-D3-D2554fiT HETA *: NY-A NGLE PATH P LANNINGG RIDSFigure 15: Map Baldurs Gate IIunblocked. AP Theta* eventually finds solid blue path [B1, C3, D4] start vertex B1vertex D4, Basic Theta* finds dashed red path [B1, D4], true shortest path.correctness completeness proof Basic Theta* needs get changed slightly AP Theta*since AP Theta* performs line-of-sight checks differently.Theorem 2. AP Theta* terminates path extraction retrieves unblocked path startvertex goal vertex path exists. Otherwise, AP Theta* terminates reportsunblocked path exists.Proof. proof similar proof Theorem 1 since AP Theta* uses angle rangesdetermine whether Path 2 blocked determine whether Path 1 blocked.property needs proved differently two vertices indeed line-of-sight(but necessarily if) line-of-sight check AP Theta* succeeds, see Appendix B.7. Experimental Resultssection, compare Basic Theta* AP Theta* A* grids, A* PS, FD* A*visibility graphs respect path length, number vertex expansions, runtime (measuredseconds) number heading changes.compare path-planning algorithms 100 100 500 500 grids different percentages randomly blocked cells (random grids) scaled maps real-time strategygame Baldurs Gate II (game maps). Figure 15 (Bulitko, Sturtevant, & Kazakevich, 2005) showsexample game map. start goal vertices south-west corners cells. randomgrids, start vertex south-west cell. goal vertex cell randomly chosencolumn cells furthest east. Cells blocked randomly one-unit border unblockedcells guarantees path start vertex goal vertex. game maps, startgoal vertices randomly chosen corners unblocked cells. average 500random 100 100 grids, 500 random 500 500 grids 118 game maps.555fiDANIEL , NASH , KOENIG , & F ELNER500500100100FD*Game MapsRandom Grids 0%Random Grids 5%Random Grids 10%Random Grids 20%Random Grids 30%Game MapsRandom Grids 0%Random Grids 5%Random Grids 10%Random Grids 20%Random Grids 30%40.04114.49114.15114.74115.20115.45223.64576.19568.63576.23580.19581.73Basic Theta* AP Theta* A* Visibility Graphs A* Grids(true shortest path)39.9840.0539.9641.77114.33114.33114.33120.31113.94113.94113.83119.76114.51114.51114.32119.99114.93114.95114.69120.31115.22115.25114.96120.41223.30224.40N/A233.66575.41575.41N/A604.80567.30567.34N/A596.45574.57574.63N/A603.51578.41578.51N/A604.93580.18580.35N/A606.38A* PS40.02114.33114.71115.46116.16116.69223.70575.41573.46581.03585.62588.98Table 1: Path length500500100100FD*Game MapsRandom Grids 0%Random Grids 5%Random Grids 10%Random Grids 20%Random Grids 30%Game MapsRandom Grids 0%Random Grids 5%Random Grids 10%Random Grids 20%Random Grids 30%0.01110.02290.02750.03050.03670.04290.19250.36280.45140.56080.69920.8562Basic Theta* AP Theta* A* Visibility Graphs A* Grids(true shortest path)0.00600.00840.47920.00480.00730.00680.00610.00530.00900.01110.07660.00400.01110.01450.34270.00480.01500.02081.71360.00840.01830.02633.76220.01190.11660.1628N/A0.07670.10000.0234N/A0.01220.16800.1962N/A0.01760.26690.3334N/A0.05730.37240.5350N/A0.15430.50790.7291N/A0.3238A* PS0.00520.02080.02060.02040.02220.02400.12520.62700.63940.67170.68520.7355Table 2: Runtime500500100100FD*Game MapsRandom Grids 0%Random Grids 5%Random Grids 10%Random Grids 20%Random Grids 30%Game MapsRandom Grids 0%Random Grids 5%Random Grids 10%Random Grids 20%Random Grids 30%247.07592.74760.17880.211175.421443.446846.6211468.1115804.8119874.6226640.8334313.28Basic Theta* AP Theta* A* Visibility Graphs A* Grids(true shortest path)228.45226.4268.23197.19240.42139.531.0099.00430.06361.1735.35111.96591.31520.91106.23169.98851.79813.14357.33386.411113.401089.96659.36620.186176.376220.58N/A5580.322603.40663.34N/A499.007450.855917.25N/A755.6611886.9510405.34N/A2203.8318621.6117698.75N/A6777.1525744.5725224.92N/A14641.36A* PS315.081997.291974.271936.562040.102153.289673.8849686.4749355.4150924.0150358.6653732.82Table 3: Number vertex expansionspath-planning algorithms implemented C# executed 3.7 GHz Core 2 Duo 2GByte RAM. implementations optimized possibly improved.556fiT HETA *: NY-A NGLE PATH P LANNING500500100100FD*Game MapsRandom Grids 0%Random Grids 5%Random Grids 10%Random Grids 20%Random Grids 30%Game MapsRandom Grids 0%Random Grids 5%Random Grids 10%Random Grids 20%Random Grids 30%34.25123.40113.14106.6698.7696.27219.70667.00592.65559.69506.10481.16G RIDSBasic Theta* AP Theta* A* Visibility Graphs A* Grids(true shortest paths)3.083.642.925.210.000.000.000.995.146.035.066.008.969.878.8410.8515.2115.9614.7419.4219.9620.6219.4426.064.187.58N/A10.190.000.00N/A1.0021.9127.99N/A24.6841.6047.40N/A49.7372.4976.79N/A91.4097.21100.31N/A123.81A* PS2.830.004.538.4814.4518.353.840.0022.2743.1669.4489.435920.95890.85860.75830.65800.5RuntimePath LengthTable 4: Number heading changes5770.45740.35710.25680.15650051020300510% BlockedFD*Basic Theta*2030% BlockedAP Theta*A* PSFD*Basic Theta*(a) Path lengthAP Theta*A* PSA*(b) Runtime60000800700Number Heading Changes50000Vertex Expansions40000300002000060050040030020010000100000510203005% BlockedFD*Basic Theta*102030% BlockedAP Theta*A* PSA*FD*(c) Number vertex expansionsBasic Theta*AP Theta*A* PSA*(d) Number heading changesFigure 16: Random 500 500 grids557fiDANIEL , NASH , KOENIG , & F ELNER99 h(s)x := |s.x (sgoal ).x|;100:= |s.y (sgoal ).y|;101102largest := max(x , );103smallest := min(x , );104return 2 smallest + (largest smallest);105 endAlgorithm 5: Calculation octile distancesA* grids, A* PS, FD* A* visibility graphs break ties among vertices fvalue open list favor vertices larger g-values (when decide vertexexpand next) since tie-breaking scheme typically results fewer vertex expansions thusshorter runtimes A*. Care must thus taken calculating g-values, h-values fvalues precisely. numerical precisionfloating point numbers improved A*grids representing form + 2n integers n. Basic Theta* APTheta* break ties favor vertices smaller g-values reasons explained Section 9.use path-planning algorithms consistent h-values since consistent h-values resultshort paths A*. Consistent h-values satisfy triangle inequality, is, h-valuegoal vertex zero h-value potential non-goal parent vertex greaterdistance potential non-goal parent vertex vertex plus h-valuevertex (Hart et al., 1968; Pearl, 1984). Consistent h-values lower bounds correspondinggoal distances vertices. Increasing consistent h-values typically decreases number vertexexpansions A* thus also runtime A*. thus use path-planning algorithmslargest consistent h-values easy calculate. Basic Theta*, AP Theta*, FD*A* visibility graphs, goal distances vertices equal true goal distances,is, goal distances grids paths constrained grid edges. therefore usepath planning algorithms straight-line distances h(s) = c(s, sgoal ) h-valuesexperiments. straight-line distances goal distances grids without blocked cellspaths constrained grid edges. A* grids A* PS, goal distances verticesequal goal distances grids paths constrained grid edges. could thereforeuse larger octile distances h-values experiments. octile distancesgoal distances grids without blocked cells paths constrained grid edges. Algorithm5 shows calculate octile distance given vertex s, s.x s.y xcoordinates vertex s, respectively. indeed use A* grids octile distances A*PS straight-line distances since smoothing typically able shorten resultingpaths much increase number vertex expansions thus runtime. Grids withoutblocked cells provide example. octiledistances h-values, A* grids finds pathsdiagonal movements (whose lengths 2) precede horizontal vertical movements(whose lengths 1) paths largest number diagonal movementslongest ones among paths number movements due tie-breaking schemeused. hand, straight-line distances h-values, A* grids finds pathsinterleave diagonal movements horizontal vertical movements (which meanslikely lots opportunities smooth paths even grids blockedcells) closer straight line start goal vertices (which meanslikely paths closer true shortest paths even grids blocked cells),558fiT HETA *: NY-A NGLE PATH P LANNINGG RIDSFigure 17: True shortest paths found FD* (left), A* PS (middle) Basic Theta* (right)h-values vertices closer straight line typically smaller h-valuesvertices farther away straight line.Tables 1-4 report experimental results. runtime A* visibility graphs (which findstrue shortest paths) long 500 500 grids thus omitted. Figure 16 visualizesexperimental results random 500 500 grids. path length A* grids much largerpath lengths path-planning algorithms thus omitted.make following observations path lengths:path-planning algorithms order increasing path lengths tend be: A* visibilitygraphs (which finds true shortest paths), Basic Theta*, AP Theta*, FD*, A* PS A*grids. random 500 500 grids 20 percent blocked cells, Basic Theta* finds shorterpaths AP Theta* 70 percent time, shorter paths FD* 97 percent time,shorter paths A* PS 94 percent time shorter paths A* grids 99 percenttime.paths found Basic Theta* AP Theta* almost short true shortest paths eventhough AP Theta* sometimes constrains angle ranges necessary. example,average less factor 1.003 longer true shortest paths 100 100grids.Basic Theta* finds true shortest paths often FD* A* PS. Figure 17 showsexample light green vertex center start vertex red, greenblue vertices represent goal vertices FD*, A* PS Basic Theta* find true shortestpaths, respectively.make following observations runtimes. path-planning algorithms orderincreasing runtimes tend be: A* grids, Basic Theta*, AP Theta*, A* PS, FD* A*visibility graphs.make following observations numbers vertex expansions. path-planningalgorithms order increasing numbers vertex expansions tend be: A* visibility graphs,A* grids, AP Theta*, Basic Theta*, FD* A* PS. (The number vertex expansions A*grids A* PS different use different h-values.)559fiDANIEL , NASH , KOENIG , & F ELNERRuntimeRuntime per Vertex ExpansionFD*5.210.000021Basic Theta*3.650.000015AP Theta*5.700.000023A* PS3.060.000012Table 5: Path-planning algorithms without post-processing steps random 500 500 grids20 percent blocked cellsFinally, make following observations number heading changes. pathplanning algorithms order increasing numbers heading changes tend be: A* PS, A*visibility graphs, Basic Theta*, AP Theta*, A* grids FD*.exceptions trends reported above. therefore perform paired t-tests.show confidence level = 0.01 Basic Theta* indeed finds shorter paths AP Theta*,A* PS FD* Basic Theta* indeed shorter runtime AP Theta*, A* PSFD*.summarize, A* visibility graphs finds true shortest paths slow. hand, A*grids finds long paths fast. Any-angle path planning lies two extremes.Basic Theta* dominates AP Theta*, A* PS FD* terms tradeoff runtimepath length. finds paths almost short true shortest paths almost fastA* grids. also simpler implement AP Theta*. Therefore, build Basic Theta*remainder article, although report experimental results AP Theta*well. However, AP Theta* reduces runtime Basic Theta* per vertex expansion linearconstant. currently unknown whether constant time line-of-sight checks devisedmake AP Theta* faster Basic Theta*. interesting area future research sinceAP Theta* potentially first step toward significantly reducing runtime any-angle pathplanning via sophisticated line-of-sight checks.8. Extensions Theta*section, extend Basic Theta* find paths given start vertex verticesfind paths grids contain unblocked cells non-uniform traversal costs.8.1 Single Source Pathsfar, Basic Theta* found paths given start vertex given goal vertex. discussversion Basic Theta* finds single source paths (that is, paths given start vertexvertices) terminating open list empty instead either open listempty expands goal vertex.Finding single source paths requires path-planning algorithms expand numbervertices, minimizes influence h-values runtime thus results cleancomparison since h-values sometimes chosen trade runtime path length.runtimes A* PS FD* effected Basic Theta* AP Theta*finding single source paths since require post-smoothing path-extraction steps560fiT HETA *: NY-A NGLE PATH P LANNING12345G RIDS6I6I5I4BI3I2I1CI0Basic Theta* path Non-Uniform Traversal CostsFigure 18: Basic Theta* grids contain unblocked cells non-uniform traversal costs(a) Small contiguous regions uniform traversal costsPath CostRuntimeA* Grids4773.5911.28FD*4719.2614.98Basic Theta*4730.9619.02(b) Large contiguous regions uniform traversal costsPath CostRuntimeA* Grids1251.883.42FD*1208.895.31Basic Theta*1207.065.90Table 6: Path-planning algorithms random 1000 1000 grids non-uniform traversal costspath, thus need post-process many paths. Table 5 reports runtimes path-planningalgorithms without post-processing steps. runtime Basic Theta* per vertex expansionsimilar A* PS shorter either AP Theta* FD* later twoalgorithms require floating point operations.8.2 Non-Uniform Traversal Costsfar, Basic Theta* found paths grids contain unblocked cells uniform traversalcosts. case, true shortest paths heading changes corners blocked cellstriangle inequality holds, means Path 2 longer Path 1. discussversion Basic Theta* finds paths grids contain unblocked cells non-uniformtraversal costs computing comparing path lengths (which path costs) appropriately.case, true shortest paths also heading changes boundaries unblockedcells different traversal costs triangle inequality longer guaranteed hold,means Path 2 costly Path 1. Thus, Basic Theta* longer unconditionallychooses Path 2 Path 1 Path 2 unblocked [Line 42] chooses path smallercost. uses standard Cohen-Sutherland clipping algorithm computer graphics (Foley, vanDam, Feiner, & Hughes, 1992) calculate cost Path 2 line-of-sight check. Figure18 shows example path segment C1A6 vertex C1 vertex A6. straight linesplit line segments points intersects cell boundaries. cost pathsegment sum costs line segments Ii Ii+1 , cost line segmentproduct length traversal cost corresponding unblocked cell.found changing test Line 52 Algorithm 3 strictly less lessequal slightly reduces runtime Basic Theta*. result fact fastercompute cost path segment corresponds Path 1 Path 2 since tends consistfewer line segments.561fiDANIEL , NASH , KOENIG , & F ELNER21345goal12345goalh =2.24h =3.16BBg =1.41g =2.24CCstartstart(a)(b)Figure 19: Non-monotonicity f-values Basic Theta*compare Basic Theta* A* grids FD* respect path cost runtime(measured seconds) since A* easily adapted grids contain unblocked cellsnon-uniform traversal costs FD* designed case. compare path-planningalgorithms 1000 1000 grids, cell assigned integer traversal cost 1 15(corresponding unblocked cell) infinity (corresponding blocked cell), similartechnique used work Ferguson Stentz (2006) . path lies boundarytwo cells different traversal costs, use smaller traversal cost two cells.start goal vertices south-west corners cells. start vertex south-west cell.goal vertex cell randomly chosen column cells furthest east. average100 random grids. Table 6 (a) reports results every traversal cost chosen uniformprobability, resulting small contiguous regions uniform traversal costs. path costruntime FD* smaller Basic Theta*. path cost A* grids1 percent larger FD* although runtime much smaller FD*. Thus,any-angle planning large advantage A* grids. Table 6(b) reports resultstraversal cost one chosen probability 50 percent traversal costs chosenuniform probability, resulting large contiguous regions uniform traversal costs. pathcost Basic Theta* smaller FD* runtimeFD*. paths found FD* tend many unnecessary heading changes regionstraversal costs Basic Theta*, outweighs paths found BasicTheta* necessary heading changes boundary two cells differenttraversal costs. path cost A* grids 3 percent larger Basic Theta*.Thus, any-angle planning larger advantage A* grids.9. Trading Runtime Path Length: Exploiting h-Valuesstrategies trading runtime path length A* grids Basic Theta* share.However, behavior different even though two algorithms similarpseudocode. section, develop versions Basic Theta* might able find shorterpaths increase runtime, including versions use weighted h-values weights lessone, break ties among vertices f-value open list favor verticessmaller g-values (when decide vertex expand next) re-expand vertices whosef-values decreased.562fiT HETA *: NY-A NGLE PATH P LANNINGG RIDSuse path-planning algorithms consistent h-values. A* grids followingproperties (Pearl, 1984): f-value expanded vertex larger f-valueunexpanded visible neighbors updating according Path 1, impliesf-value vertex expanded vertex larger f-valuevertex. Consequently, point time search vertex expanded,following parents expanded vertex start vertex retrieves shortest pathstart vertex expanded vertex reverse, implies A* cannot find shorter pathsexpanding vertices once. Basic Theta* different properties: f-valueexpanded vertex larger f-value one unexpanded visible neighborsupdating according Path 2, implies f-value vertex expandedvertex larger f-value vertex. Consequently,point time search vertex expanded, following parentsexpanded vertex start vertex guaranteed retrieve shortest path start vertexvertex reverse, implies Basic Theta* might find shorter paths expandingvertices once. Figure 19 shows example. Basic Theta* expands start vertex C1parent C1, generates vertex B2. Vertex B2 unexpanded visible neighbor vertex C1line-of-sight vertex C1. Basic Theta* thus updates according Path 2 (whichPath 1 case), sets f-value f (B2) = 1.41 + 3.16 = 4.57, sets parent vertexC1 inserts open list (Figure 19(a)). Basic Theta* later expands vertex B2parent C1, generates vertex B3. Vertex B3 unexpanded visible neighbor vertex B2line-of-sight vertex C1. Basic Theta* thus updates according Path 2, sets f-valuef (B3) = 2.24 + 2.24 = 4.48, sets parent vertex C1 inserts open list (Figure19(b)). Thus, f-value expanded vertex B2 indeed larger f-value unexpandedvisible neighbor B3 updating according Path 2 increase g-value vertexB2 vertex B3 [= 0.83] less decrease h-value vertex B2 vertex B3 [= 0.92].Basic Theta* later expands vertex B3, f-value vertex B2 [= 4.57] expandedvertex B3 indeed larger f-value vertex B3 [= 4.48].properties suggest Basic Theta* might able find shorter paths increaseruntime re-expanding vertices expanding additional vertices (for example using weightedh-values weights less one) A* cannot. time, standard optimizationsA* decrease runtime might also able decrease runtime Basic Theta* (suchbreaking ties among vertices f-value open list favor vertices largerg-values). section investigate tradeoffs.9.1 Weighted h-Valuesfar, Basic Theta* used consistent h-values h(s). A* consistent h-values finds pathslength matter small large h-values are. Decreasing consistent h-values typicallyincreases number vertex expansions A*. therefore discuss version BasicTheta* might able find shorter paths increase runtime using weighted h-valuesweights less one. version Basic Theta* uses h-values h(s) = w c(s, sgoal )given weight 0 w < 1 thus similar Weighted A* (Pohl, 1973), except WeightedA* typically uses weights greater one. Figure 20(a) shows example resulting effectnumber vertex expansions path length. green vertex north-east start563fiDANIEL , NASH , KOENIG , & F ELNER(a) Expanded vertices Basic Theta* different weights578.6250000578.4200000578.2Path Length150000577.8100000577.6Vertex Expansions578577.450000577.2577000.250.50.750.80.850.90.951wBasic Theta* Path LengthAP Theta* Path LengthBasic Theta* Vertex ExpansionsAP Theta* Vertex Expansions(b) Random 500 500 grids 20 percent blocked cellsFigure 20: Weighted h-valuesvertex, red vertex south-west goal vertex. Basic Theta* weight 1.00 (asused far) expands orange vertices finds red path. Basic Theta* weight 0.75expands blue vertices finds blue path. Thus, Basic Theta* expands vertices564fiT HETA *: NY-A NGLE PATH P LANNINGPath LengthNumber Vertex ExpansionsRuntimeSmaller g-ValuesBasic Theta* AP Theta*578.41578.5118621.6117698.750.37240.5350G RIDSLarger g-ValuesBasic Theta* AP Theta*578.44578.5518668.0317744.940.38290.5389Table 7: Random 500 500 grids 20 percent blocked cellsweight 0.75 weight 1.00 resulting path shorter since passes verticesexpanded weight 0.75 weight 1.00.Figure 20(b) reports effect different weights path length number vertex expansions Basic Theta* AP Theta* random 500 500 grids 20 percent blocked cells.(The graphs number vertex expansions Basic Theta* AP Theta* nearly coincide.)Decreasing weight decreases path length increase number vertex expansionsthus runtime. path length decreases AP Theta* Basic Theta* since APTheta* constrain angle ranges necessary thus benefits two ways expanding vertices. However, neither Basic Theta* AP Theta* guaranteed find trueshortest paths even weights zero.9.2 Tie Breakingfar, Basic Theta* broken ties among vertices open list f-value favorvertices larger g-values (when decides vertex expand next). A* consistenth-values finds paths length matter tie-breaking scheme uses. Breaking tiesfavor vertices smaller g-values typically increases number vertex expansionsthus runtime. therefore discuss version Basic Theta* might able find shorterpaths increase runtime breaking ties favor vertices smaller g-values. Figure 21shows example resulting effect path length. Vertices C4 B4 f-valuevertex B4 larger g-value since f (C4) = 3.83+1.41 = 5.24 f (B4) = 4.24+1 = 5.24.Basic Theta* breaks ties favor vertices larger g-values, expands vertex B4parent E1 vertex C4 parent C3 eventually expands goal vertex parent B4terminates. Path extraction follows parents goal vertex B5 start vertex E1retrieve dashed red path [E1, B4, B5]. However, Basic Theta* breaks ties favor verticessmaller g-values, expands vertex C4 parent C3 vertex B4 parent E1eventually expands goal vertex parent C3 terminates. Path extraction followsparents goal vertex B5 start vertex E1 retrieve shorter solid blue path [E1, C3,B5].Table 7 reports effect tie-breaking scheme path length, number vertex expansionsruntime Basic Theta* AP Theta* random 500 500 grids 20 percent blockedcells. Breaking ties favor vertices smaller g-values neither changes path length,number vertex expansions runtime significantly. effect tie-breaking schemesmall since fewer vertices f-value Basic Theta* AP Theta* A*grids number possible g-values h-values larger any-angle path planning.565fiDANIEL , NASH , KOENIG , & F ELNER123B45goalCEstartBasic Theta* path (Larger g-values)Basic Theta* path (Smaller g-values)Figure 21: Basic Theta* paths different tie-breaking schemesPath LengthNumber Vertex ExpansionsRuntimeBasic Theta* without Vertex Re-Expansions578.4118621.610.3724Basic Theta* Vertex Re-Expansions577.6022836.370.5519Table 8: Random 500 500 grids 20 percent blocked cellsalso second method breaking ties effect path length. far, Basic Theta*chosen Path 2 Path 1 unexpanded visible neighbor vertex line-of-sightparent vertex. However, choose Path 1 Path 2 paths equally long,increases runtime due additional comparison. Figure 21 shows exampleresulting effect path length. Assume Basic Theta* expands vertex B4 vertex C4.Basic Theta* chooses Path 2 Path 1 expands vertex B4 parent E1 eventuallyexpands goal vertex B5 parent B4 terminates. Path extraction follows parentsgoal vertex B5 start vertex E1 retrieve dashed red path [E1, B4, B5]. However,Basic Theta* chooses Path 1 Path 2 expands vertex B4 parent C3 eventuallyexpands goal vertex B5 parent C3 terminates. Path extraction follows parentsgoal vertex B5 start vertex E1 retrieve shorter solid blue path [E1, C3, B5].9.3 Re-Expanding Verticesfar, Basic Theta* used closed list ensure expands vertex once. A*consistent h-values re-expand vertices whether uses closed list sincecannot find shorter path start vertex vertex expanding vertex.hand, Basic Theta* re-expand vertices use closed list since find shorterpath start vertex vertex expanding vertex. re-inserts vertex566fiT HETA *: NY-A NGLE PATH P LANNING1234567G RIDS8B9goalCEstartBasic Theta* pathBasic Theta* path vertex re-expansionsFigure 22: Basic Theta* paths without vertex re-expansionsopen list eventually re-expands it.2 Figure 22 shows example effect vertexre-expansions path length. Basic Theta* without vertex re-expansions eventually expands vertexC8 parent D4. Vertex C9 unexpanded visible neighbor vertex C8 line-of-sightvertex D4. Basic Theta* without vertex re-expansions thus updates according Path 2sets parent vertex D4. termination, path extraction follows parents goal vertexB9 start vertex E1 retrieve dashed red path [E1, D4, C9, B9]. However, Basic Theta*vertex re-expansions eventually expands vertex C8 parent D4 later re-expands vertex C8parent E1. Vertex C9 visible neighbor vertex C8 line-of-sight vertex E1.Basic Theta* vertex re-expansions thus updates according Path 2 sets parentvertex E1. termination, path extraction follows parents goal vertex B9 start vertexE1 retrieve shorter solid blue path [E1, C9, B9].Theorem 3. Basic Theta* vertex re-expansions terminates path extraction returnsunblocked path start vertex goal vertex path exists. Otherwise, BasicTheta* vertex re-expansions terminates reports unblocked path exists.Proof. proof similar proof Theorem 1. property needs proveddifferently Basic Theta* vertex re-expansions terminates since longer truenever insert vertex open list removed vertex open list.However, since number vertices finite, finite number acyclic pathsstart vertex vertex. Therefore, number possible g-values finite. Therefore, BasicTheta* vertex re-expansions reduce g-value vertex finite number timesthus inserts vertex open list finite number times. Thus, open list eventuallybecomes empty Basic Theta* terminate terminated earlier already.2. Basic Theta* vertex re-expansions could also delay expansion goal vertex (for example, increasingf-value artificially) re-expand vertices terminates version Basic Theta*vertex re-expansions that.567fiDANIEL , NASH , KOENIG , & F ELNERTable 8 reports effect vertex re-expansions path length, number vertex expansionsruntime Basic Theta* random 500 500 grids 20 percent blocked cells. Vertexre-expansions decrease path length slightly increase number vertex expansionsthus runtime.10. Trading Runtime Path Length: Approachesadditional strategies trading runtime path length specific BasicTheta*. section, develop versions Basic Theta* might able find shorterpaths increase runtime examining paths, including versions check line-ofsight parent parent, use key vertices identify promising parents increasenumber visible neighbors thus number potential parents updating verticesaccording Path 1.10.1 Three Pathsfar, Basic Theta* considered two paths (namely Paths 1 2) updates gvalue parent unexpanded visible neighbor vertex s. discuss versionBasic Theta* considers third path, namely path start vertex parentparent vertex [= g(parent(parent(s)))] vertex straight line [=c(parent(parent(s)), )], resulting length g(parent(parent(s))) + c(parent(parent(s)), ).version Basic Theta* might able find shorter paths increase runtime sincethird path longer Path 2 due triangle inequality. However, experimental results(not reported here) show third path decrease path length significantlyoriginal version Basic Theta* already determines parent parent vertexline-of-sight vertex shares parent vertex s. Thus, unlikelyparent parent vertex line-of-sight vertex thus third pathunblocked.10.2 Key Verticesfar, Basic Theta* considered two paths (namely Paths 1 2) updates g-valueparent unexpanded visible neighbor vertex s. parent vertex eithervisible neighbor vertex parent visible neighbor, always casetrue shortest paths. discuss version Basic Theta* considers additional paths,namely paths start vertex cached key vertices vertex straightline. version Basic Theta* might able find shorter paths increase runtimedue fact parent vertex also one key vertices. However,experimental results (not reported here) show key vertices decrease path length slightlylarger increase runtime due overhead select key vertices, maintainconsider larger number paths.568fiT HETA *: NY-A NGLE PATH P LANNING(a) Branching factor 4(b) Branching factor 8G RIDS(c) Branching factor 16Figure 23: Grids different branching factors0.6581580.50.55800.45790.3578.5RuntimePath Length579.55780.2577.55770.1576.557604Basic Theta*16Branching FactorPath LengthRuntimeFigure 24: Basic Theta* random 500 500 grids 20 percent blocked cells10.3 Larger Branching Factorsfar, Basic Theta* operated eight-neighbor grids. discuss version Basic Theta*operates grids different numbers neighbors thus different branching factors.Figure 23 shows neighbors center vertex branching factors 4, 8 16 respectively.version Basic Theta* might able find shorter paths increase runtime sincelarger branching factors increase number visible neighbors vertices thus numberpotential parents updating according Path 1. Figure 24 reports effect largerbranching factors path length runtime Basic Theta* random 500 500 grids20 percent blocked cells. Larger branching factors indeed decrease path length increaseruntime.569fiDANIEL , NASH , KOENIG , & F ELNER11. ConclusionsAny-angle path-planning algorithms find paths without artificially constraining headingspaths. presented two new correct complete any-angle path-planning algorithms. BasicTheta* Angle-Propagation Theta* (AP Theta*) variants A* propagate information along grid edges (to achieve short runtime) without constraining paths grid edges (to findany-angle paths). Basic Theta* simple understand implement, fast finds short paths.However, guaranteed find true shortest paths. AP Theta* achieves worst-case complexity per vertex expansion constant (like A* grids) rather linear numbercells (like Basic Theta*) propagating angle ranges expands vertices. However,AP Theta* complex Basic Theta*, fast finds slightly longer paths.proved correctness completeness Basic Theta* AP Theta* comparedthree existing any-angle path-planning algorithms, namely A* post-smoothedpaths (A* PS), A* visibility graphs Field D* (FD*), version A* knowpropagates information along grid edges without constraining paths grid edges. BasicTheta* AP Theta* (unlike A* PS) consider paths constrained grid edgessearch thus make informed decisions regarding paths search. Basic Theta*AP Theta* (unlike FD*) take advantage fact true shortest paths heading changescorners blocked cells.A* visibility graphs finds true shortest paths slow. hand, A* grids findslong paths fast. Any-angle path planning lies two extremes. Basic Theta*dominates AP Theta*, A* PS FD* terms tradeoffs runtime path length.finds paths almost short true shortest paths almost fast A* grids.extended Basic Theta* find paths given start vertex vertices findpaths grids contain cells non-uniform traversal costs. f-value expanded vertexBasic Theta* (unlike A* grids) consistent h-values larger f-value oneunexpanded visible neighbors, means Basic Theta* might able findshorter paths increase runtime re-expanding vertices expanding additional vertices.thus developed versions Basic Theta* use weighted h-values weights less one,break ties among vertices f-value open list favor vertices smallerg-values (when decide vertex expand next), re-expand vertices whose f-valuesdecreased, check line-of-sight parent parent, use key vertices identifypromising parents increase number visible neighbors.future, intend develop worst-case bound path lengths Basic Theta* APTheta*, better understand properties investigate faster versions AP Theta*perform line-of-sight checks constant time.Appendix A. Checking Line-of-Sightappendix, explain perform line-of-sight checks fast. simplicity, allowstraight lines pass diagonally touching blocked cells. Performing line-of-sight checksimilar determining points plot raster display drawing straight line two points. plotted points correspond cells straight line passes through.570fiT HETA *: NY-A NGLE PATH P LANNINGG RIDS106 LineOfSight(s, s)107x0 := s.x;108y0 := s.y;109x1 := .x;110y1 := .y;111dy := y1 y0 ;112dx := x1 x0 ;113f := 0;114dy < 0115dy := dy ;116sy := 1;117118else119120121dx < 0dx := dx ;sx := 1;122123else124125126127128129dx dyx0 6= x1f := f + dy ;f dxgrid(x0 + ((sx 1)/2), y0 + ((sy 1)/2))return false;sy := 1;sx := 1;y0 := y0 + sy ;f := f dx ;130131132133f 6= 0 grid(x0 + ((sx 1)/2), y0 + ((sy 1)/2))return false;134135dy = 0 grid(x0 + ((sx 1)/2), y0 ) grid(x0 + ((sx 1)/2), y0 1)return false;136x0 := x0 + sx ;137138139140141142elsey0 6= y1f := f + dx ;f dygrid(x0 + ((sx 1)/2), y0 + ((sy 1)/2))return false;x0 := x0 + sx ;f := f dy ;143144145146f 6= 0 grid(x0 + ((sx 1)/2), y0 + ((sy 1)/2))return false;147148dx = 0 grid(x0 , y0 + ((sy 1)/2)) grid(x0 1, y0 + ((sy 1)/2))return false;149y0 := y0 + sy ;150return true;151 endAlgorithm 6: Line-of-sight algorithmThus, two vertices line-of-sight iff none plotted points correspond blocked cells.allows Basic Theta* perform line-of-sight checks standard Bresenham line-drawingalgorithm computer graphics (Bresenham, 1965), uses fast logical integer operations rather floating-point operations. Algorithm 6 shows resulting line-of-sight algorithm,571fiDANIEL , NASH , KOENIG , & F ELNERIIyaxispb0xaxisb1b2b3b4b5b6b7b8b9IIIb 10Upper BoundaryIVLower BoundaryFigure 25: Parent, blocked cell boundary verticess.x s.y x coordinates vertex s, respectively, grid represents gridgrid(x, y) true iff corresponding cell blocked.Appendix B. AP Theta* Returns Unblocked Pathsappendix, prove AP Theta* never returns blocked path.Theorem 4. AP Theta* never returns blocked path.Proof. define path blocked iff least one vertex path line-of-sightsuccessor path. Thus, path blocked iff least one path segments passesinterior blocked cell passes two blocked cells share edge.first prove AP Theta* never returns path path segment passesinterior blocked cell. prove contradiction AP Theta* cannot assign parent pvertex path segment parent p vertex passes interiorblocked cell b. Assume otherwise. simplify proof, translate rotate gridblocked cell b immediately south-west origin b0 grid parent p quadrantII, shown Figure 25. define quadrant vertex follows, s.x s.yx coordinates vertex s, respectively:Quadrant north-east quadrant (excluding x-axis) given s.x 0 s.y > 0.Quadrant II north-west quadrant (excluding y-axis) given s.x < 0 s.y 0.Quadrant III south-west quadrant (excluding x-axis) given s.x 0 s.y < 0.572fiT HETA *: NY-A NGLE PATH P LANNINGnorthwest(s)west(s)southwest(s)north(s)south(s)G RIDSnortheast(s)east(s)southeast(s)Figure 26: Neighbors vertexQuadrant IV south-east quadrant (excluding y-axis including origin b0 ) givens.x > 0 s.y 0 s.x = 0 s.y = 0.refer neighbors vertex east(s), northeast(s), north(s), northwest(s), west(s),southwest(s), south(s), southeast(s), shown Figure 26.Assume light source vertex p light cannot pass blocked cell b,creates shadow. vertex shadow iff straight line parent p vertexpasses interior blocked cell b. distinguish two parts perimetershadow, namely upper lower boundary, shown Figure 25. define boundary vertexvertex shadow least one neighbor (although necessarily visibleneighbor) shadow. origin b0 shadow neighbor south(b0 )shadow. Thus, origin b0 boundary vertex. consider upper boundary withoutloss generality. Then, boundary vertex (to precise: upper boundary vertex) vertex(s, p, b0 ) 0 (that is, upper boundary thus outside shadow)least one neighbor (s , p, b0 ) > 0 (that is, upper boundary thus insideshadow). easy see boundary vertices quadrant IV form infiniteboundary path [b0 , b1 , . . .] starts origin b0 repeatedly moves either south east,is, bi+1 = south(bi ) bi+1 = east(bi ).define vertex sufficiently constrained iff (s, p, b0 ) lb(s) parent p.vertex sufficiently constrained, remains sufficiently constrained since operation APTheta* decrease lower angle bound lb(s). prove following every boundaryvertex sufficiently constrained time expanded expanded parent p. Considervertex upper boundary (that is, (s, p, b0 ) > 0 thus (b0 , p, s) < 0)visible neighbor boundary vertex bi . Vertex cannot updated according Path 1assigned parent p time parent p expanded since straight line parent pvertex passes interior blocked cell therefore visible neighbors.cannot updated according Path 2 assigned parent p time boundaryvertex bi expanded parent p boundary vertex bi sufficiently constrainedtime thus (bi , p, b0 ) lb(bi ), implies (bi , p, s) = (bi , p, b0 ) + (b0 , p, s) <(bi , p, b0 ) lb(bi ) condition Line 60 remains unsatisfied. Consequently, vertexshadow parent p.prove induction order vertex expansions every boundary vertexsufficiently constrained time expanded expanded parent p. Assumeboundary vertex b0 expanded parent p. Then, condition Line 81 satisfied573fiDANIEL , NASH , KOENIG , & F ELNERLine 83 executed blocked cell b time boundary vertex b0 expanded parent p.Boundary vertex b0 sufficiently constrained afterwards since lower angle bound set zero.assume boundary vertex bi > 0 expanded parent p. Then, boundary vertex bicannot identical parent p (since different quadrants) start vertex (sincestart vertex parent p). Boundary vertex bi cannot updated according Path1 assigned parent p time parent p expanded since p.x < 0 (bi ).x > 0thus neighbors. Consequently, boundary vertex bi must updated accordingPath 2 assigned parent p time one visible neighbors x expandedparent p. Vertex x must upper boundary (that is, (x, p, b0 ) 0) cannotidentical parent p (since different quadrants). distinguish two cases:Assume vertex x boundary vertex. sufficiently constrained time expanded parent p according induction assumption (that is, (x, p, b0 ) lb(x))since expanded boundary vertex bi . Boundary vertex bi updated accordingPath 2 time vertex x expanded parent p. Thus, condition Line60 satisfied time (that is, lb(x) (x, p, bi )) thus lb(x) + (bi , p, x) =lb(x) (x, p, bi ) 0. Then, conditions Lines 88 89 satisfiedLine 90 executed = x time boundary vertex bi expanded parentp. Boundary vertex bi sufficiently constrained afterwards since lower angle boundset max(lb(bi ), lb(x) + (bi , p, x)) (bi , p, b0 ) = (bi , p, x) + (x, p, b0 )lb(x) + (bi , p, x) max(lb(bi ), lb(x) + (bi , p, x)).Assume vertex x boundary vertex.Lemma 3. Assume vertex boundary vertex bi visible neighbors, c(p, bi ) <c(p, s) (s, p, bi ) < 0. Assume boundary vertex bi sufficiently constrainedtime vertex expanded parent p boundary vertex bi expanded parentp time. Then, vertex sufficiently constrained time expandedexpanded parent p.Proof. Assume vertex expanded parent p. Then, (s, p, b0 ) = (s, p, bi ) +(bi , p, b0 ) < 0 since (s, p, bi ) < 0 (bi , p, b0 ) 0. distinguish two cases:Assume boundary vertex bi expanded vertex expandedparent parent p. Then, conditions Lines 93 94 satisfiedLine 95 executed = bi time vertex expanded parentp. Vertex sufficiently constrained afterwards since lower angle bound setmax(lb(s), (s, p, bi )) (s, p, b0 ) = (s, p, bi ) + (bi , p, b0 ) (s, p, bi )max(lb(s), (s, p, bi )).Assume boundary vertex bi expanded parent p vertex expandedparent p. Boundary vertex bi sufficiently constrained time vertexexpanded parent p according premise (that is, (bi , p, b0 ) lb(bi )). Furthermore, lb(bi ) 0 (since operation AP Theta* make lower angle boundpositive) thus lb(bi ) + (s, p, bi ) 0. Then, conditions Lines 88 89satisfied Line 90 executed = bi time vertex expandedparent p. Vertex sufficiently constrained afterwards since lower angle bound574fiT HETA *: NY-A NGLE PATH P LANNINGG RIDSset max(lb(s), lb(bi ) + (s, p, bi )) (s, p, b0 ) = (s, p, bi ) + (bi , p, b0 )lb(bi ) + (s, p, bi ) max(lb(s), lb(bi ) + (s, p, bi )).Boundary vertex bi either immediately south east boundary vertex bi1 sinceboundary path moves south east. distinguish three subcases:Assume parent p x-axis quadrant II. Then, boundary pathalong x-axis. Vertices west(bi ) east(bi ) boundary vertices, verticessouthwest(bi ), south(bi ), southeast(bi ) upper boundary. Thus,vertex x identical one vertices northwest(bi ), north(bi ) northeast(bi ).cases, boundary vertex bj immediately south vertex x. vertices xbj visible neighbors, would blocked cells immediately southwest south-east vertex x vertices x bi could thus visible neighbors.Thus, vertices x bj visible neighbors. Furthermore, boundary vertex bj immediately south vertex x thus c(p, bj ) < c(p, x) (x, p, bj ) < 0. Finally,boundary vertex bj sufficiently constrained according induction assumptiontime boundary vertex bi expanded parent p boundary vertex bjexpanded parent p time. Thus, vertex x sufficiently constrained timeexpanded parent p according Lemma 3 (that is, (x, p, b0 ) lb(x)). Consequently, conditions Lines 88 89 satisfied (for reason given before)Line 90 executed = x time boundary vertex bi expanded parentp. Boundary vertex bi sufficiently constrained afterwards since lower angle boundset max(lb(bi ), lb(x) + (bi , p, x)) (bi , p, b0 ) = (bi , p, x) + (x, p, b0 )lb(x) + (bi , p, x) max(lb(bi ), lb(x) + (bi , p, x)).Assume parent p x-axis quadrant II boundary vertexbi immediately east boundary vertex bi1 thus c(p, bi1 ) < c(p, bi )(bi , p, bi1 ) < 0. Furthermore, boundary vertex bi1 sufficiently constrained according induction assumption time boundary vertex bi expandedparent p boundary vertex bi1 expanded parent p time. boundary vertices bi1 bi visible neighbors, boundary vertex bi sufficientlyconstrained time expanded parent p according Lemma 3. boundaryvertices bi1 bi visible neighbors, must blocked cells immediately north-west south-west boundary vertex bi . Then, Line 81 satisfiedLine 83 executed blocked cell immediately south-west boundary vertex bitime boundary vertex bi expanded parent p. Boundary vertex bi sufficientlyconstrained afterwards since lower angle bound set zero.Assume parent p x-axis quadrant II boundary vertex biimmediately south boundary vertex bi1 .Lemma 4. Assume vertex quadrant IV upper boundary.Then, vertex boundary vertex iff vertex immediately south-west vertexupper boundary.575fiDANIEL , NASH , KOENIG , & F ELNERProof. vertex immediately south-west vertex upper boundary,vertex boundary vertex definition. hand, vertexupper boundary (that is, (s , p, b0 ) 0), vertex boundaryvertex every neighbor upper boundary. neighborsvertexeast(s), northeast(s), north(s), northwest(s),west(s), southwest(s), south(s) southeast(s).or, equivalently,east(east(north(s ))), east(east(north(north(s )))), east(north(north(s ))),north(north(s )), north(s ), , east(s ) east(east(s )).Thus, every neighbor vertex reached vertex repeatedly moving either north east thus (s , p, ) 0. Consequently, (s , p, b0 ) =(s , p, ) + (s , p, b0 ) 0 thus every neighbor vertexupper boundary.distinguish two subcases:Assume boundary vertex bi+1 immediately east boundary vertexbi . Vertices north(bi ) east(bi ) boundary vertices. Vertices west(bi ),southwest(bi ) south(bi ) south-west boundary vertices bi1 , bi bi+1 ,respectively, thus upper boundary according Lemma 4. Verticesnorthwest(bi ) southeast(bi ) either boundary vertices south-westboundary vertices bi2 bi+2 , respectively, upper boundaryaccording Lemma 4. Thus, vertex x identical vertex northwest(bi ).Assume boundary vertex bi+1 immediately south boundary vertex bi .Vertices north(bi ) south(bi ) boundary vertices. Vertices west(bi )southwest(bi ) south-west boundary vertices bi1 bi , respectively,thus upper boundary according Lemma 4. Vertex northwest(bi )either boundary vertex south-west boundary vertex bi2upper boundary according Lemma 4. Thus, vertex x identical one verticesnortheast(bi ), east(bi ) southeast(bi ).cases, vertex x immediately east boundary vertex bj thus c(p, bj ) <c(p, x) (x, p, bj ) < 0. vertices x bj visible neighbors,would blocked cells immediately north-west south-west vertex x verticesx bi could visible neighbors. Thus, vertices x bj visible neighbors.Furthermore, boundary vertex bj sufficiently constrained according inductionassumption time boundary vertex bi expanded parent p boundary vertex bj expanded parent p time. Thus, vertex x sufficientlyconstrained time expanded parent p according Lemma 3 (that is,(x, p, b0 ) lb(x)). Consequently, conditions Lines 88 89 satisfied (forreason given before) Line 90 executed = x time boundary vertexbi expanded parent p. Boundary vertex bi sufficiently constrained afterwardssince lower angle bound set max(lb(bi ), lb(x) + (bi , p, x)) (bi , p, b0 ) =(bi , p, x) + (x, p, b0 ) lb(x) + (bi , p, x) max(lb(bi ), lb(x) + (bi , p, x)).576fiT HETA *: NY-A NGLE PATH P LANNINGG RIDSconcludes proof every boundary vertex sufficiently constrained timeexpanded expanded parent p thus also proof AP Theta* never returns pathpath segment passes interior blocked cell.prove AP Theta* never returns path path segment passes twoblocked cells share edge. prove contradiction AP Theta* cannot assignparent p vertex path segment parent p vertex passes twoblocked cells share edge. Assume otherwise consider first time AP Theta* assignsparent p vertex path segment parent p vertex passestwo blocked cells share edge. path segment must either horizontal vertical. Vertexcannot updated according Path 1 assigned parent p time parent pexpanded since straight line parent p vertex passes interiorblocked cell therefore visible neighbors. cannot updated accordingPath 2 assigned parent p time visible neighbor expanded parent psince either a) neighbor would colinear vertices p straight lineparent p vertex would thus pass interior blocked cell b) neighbor wouldcolinear vertices p straight line parent p vertex would passtwo blocked cells share edge, contradiction assumption. concludesproof AP Theta* never returns path path segment passes two blockedcells share edge.Thus, AP Theta* never returns blocked path.Appendix C. Acknowledgmentsarticle extension earlier publication (Nash et al., 2007) contains additionalexpositions, examples proofs. thank Vadim Bulitko University Albertamaking maps real-time game Baldurs Gate II available us. research doneAriel Felner spent sabbatical University Southern California, visiting Sven Koenig.research partly supported U.S. Army Research Laboratory (ARL) U.S.Army Research Office (ARO) award Sven Koenig grant W911NF-08-1-0468, OfficeNaval Research (ONR) award Sven Koenig grant N00014-09-1-1031, NationalScience Foundation (NSF) award Sven Koenig grant 0413196 Israeli ScienceFoundation (ISF) award Ariel Felner grants 728/06 305/09. Alex Nash fundedNorthrop Grumman Corporation. views conclusions contained documentauthors interpreted representing official policies, eitherexpressed implied, sponsoring organizations, agencies, companies U.S. government.ReferencesAurenhammer, F. (1991). Voronoi diagramsa survey fundamental geometric data structure.ACM Computing Surveys, 23(3), 345405.Botea, A., Muller, M., & Schaeffer, J. (2004). Near optimal hierarchical path-finding. JournalGame Development, 1(1), 122.577fiDANIEL , NASH , KOENIG , & F ELNERBresenham, J. (1965). Algorithm computer control digital plotter. IBM Systems Journal,4(1), 2530.Bulitko, V., Sturtevant, N., & Kazakevich, M. (2005). Speeding learning real-time search viaautomatic state abstraction. Proceedings AAAI Conference Artificial Intelligence,pp. 13491354.Choset, H., Lynch, K., Hutchinson, S., Kantor, G., Burgard, W., Kavraki, L., & Thrun, S. (2005).Principles Robot Motion: Theory, Algorithms, Implementations. MIT Press.Deloura, M. (2000). Game Programming Gems. Charles River Media.Ferguson, D., & Stentz, A. (2006). Using interpolation improve path planning: Field D*algorithm. Journal Field Robotics, 23(2), 79101.Foley, J., van Dam, A., Feiner, S., & Hughes, J. (1992). Computer Graphics: Principles Practice. Addison-Wesley.Hart, P., Nilsson, N., & Raphael, B. (1968). formal basis heuristic determinationminimum cost paths. IEEE Transactions Systems Science Cybernetics, SCC-4(2),100107.Kavraki, L., Svestka, P., Latombe, J., & Overmars, M. (1996). Probabilistic roadmaps pathplanning high-dimensional configuration spaces. IEEE Transactions Robotics Automation, 12(4), 566580.Koenig, S., & Likhachev, M. (2002). D* Lite. Proceedings AAAI Conference ArtificialIntelligence, pp. 476483.LaValle, S., & Kuffner, J. (2001). Rapidly-exploring random trees: Progress prospects.Donald, B., Lynch, K., & Rus, D. (Eds.), Algorithmic Computational Robotics: NewDirections, pp. 293308. K Peters.Lee, D.-T. (1978). Proximity reachability plane. Ph.D. thesis, University IllinoisUrbana-Champaign.Liu, Y.-H., & Arimoto, S. (1992). Path planning using tangent graph mobile robots amongpolygonal curved obstacles. International Journal Robotics Research, 11(4), 376382.Lozano-Perez, T., & Wesley, M. (1979). algorithm planning collision-free paths amongpolyhedral obstacles. Communication ACM, 22, 560570.Mitchell, J., & Papadimitriou, C. (1991). weighted region problem: Finding shortest pathsweighted planar subdivision. Journal ACM, 38(1), 1873.Murphy, R. (2000). Introduction AI Robotics. MIT Press.Nash, A., Daniel, K., Koenig, S., & Felner, A. (2007). Theta*: Any-angle path planning grids.Proceedings AAAI Conference Artificial Intelligence, pp. 11771183.Nash, A., Koenig, S., & Likhachev, M. (2009). Incremental Phi*: Incremental any-angle path planning grids. Proceedings International Joint Conference Aritificial Intelligence,pp. 18241830.Patel, A. (2000).Amits Game Programming Information.available onlinehttp://theory.stanford.edu/amitp/GameProgramming/MapRepresentations.html.578fiT HETA *: NY-A NGLE PATH P LANNINGG RIDSPearl, J. (1984). Heuristics: Intelligent Search Strategies Computer Problem Solving. AddisonWesley.Pohl, I. (1973). avoidance (relative) catastrophe, heuristic competence, genuine dynamicweighting computational issues heuristic problem solving. Proceedings International Joint Conference Artificial Intelligence, pp. 1217.Rabin, S. (2002). AI Game Programming Wisdom. Charles River Media.Rabin, S. (2004). AI Game Programming Wisdom 2. Charles River Media.Thorpe, C. (1984). Path relaxation: Path planning mobile robot. Proceedings AAAIConference Artificial Intelligence, pp. 318321.Tozour, P. (2004). Search space representations. Rabin, S. (Ed.), AI Game Programming Wisdom2, pp. 85102. Charles River Media.Yahja, A., Stentz, A., Singh, S., & Brumitt, B. (1998). Framed-quadtree path planning mobilerobots operating sparse environments. Proceedings International ConferenceRobotics Automation, pp. 650655.Yap, P. (2002). Grid-based path-finding. Proceedings Canadian Conference ArtificialIntelligence, pp. 4455.579fiJournal Artificial Intelligence Research 39 (2010) 335-371Submitted 10/09; published 09/10Active Tuples-based Scheme Bounding Posterior BeliefsBozhena Bidyukbbidyuk@google.comGoogle Inc.19540 Jamboree RdIrvine, CA 92612Rina Dechterdechter@ics.uci.eduDonald Bren School Information Computer ScienceUniversity California IrvineIrvine, CA 92697-3425Emma Rollonerollon@lsi.upc.eduDepartament de Llenguatges Sistemes InformaticsUniversitat Politecnica de CatalunyaBarcelona, SpainAbstractpaper presents scheme computing lower upper bounds posteriormarginals Bayesian networks discrete variables. power lies ability useavailable scheme bounds probability evidence posterior marginalsenhance performance anytime manner. scheme uses cutset conditioningprinciple tighten existing bounding schemes facilitate anytime behavior, utilizingfixed number cutset tuples. accuracy bounds improves numberused cutset tuples increases computation time. demonstrate empiricallyvalue scheme bounding posterior marginals probability evidence usingvariant bound propagation algorithm plug-in scheme.1. Introductionpaper addresses problem bounding probability evidence posteriormarginals Bayesian networks discrete variables. Deriving bounds posteriorsgiven accuracy clearly NP-hard problem (Abdelbar & Hedetniemi, 1998; Dagum& Luby, 1993; Roth, 1996) indeed, available approximation algorithms providelittle guarantee quality approximations. Still, approachespresented past years bounding posterior marginals (Horvitz, Suermondt, &Cooper, 1989; Poole, 1996, 1998; Mannino & Mookerjee, 2002; Mooij & Kappen, 2008)bounding probability evidence (Dechter & Rish, 2003; Larkin, 2003; Leisink &Kappen, 2003).paper develop framework accept bounding scheme improvebounds anytime manner using cutset-conditioning principle (Pearl, 1988).facilitate scheme develop expression converts bounds probabilityevidence bounds posterior marginals.Given Bayesian network defined set variables X , variable X X ,domain value x D(X), posterior marginal P (x|e) (where e subset assignmentsvariables, called evidence) computed directly two joint probabilities,c2010AI Access Foundation. rights reserved.fiBidyuk, Dechter & RollonP (x, e) P (e):P (x|e) =P (x, e)P (e)(1)Given set C={C1 , ..., Cp } X cutset variables (e.g., loop-cutset), computeQprobability evidence enumerating cutset tuples ci D(C) = pi=1 D(Ci )using formula:XP (ci , e)(2)P (e) =i=1= |D(C)|. also compute posterior marginals using expression:P (x|e) =XP (x|ci , e)P (ci |e)(3)i=1computation P (ci , e) assignment c = ci linear network size Cloop-cutset exponential w C w-cutset (see definition Section 2).limitation cutset-conditioning method, defined Eq. (2) (3),number cutset tuples grows exponentially cutset size.two basic approaches handling combinatorial explosion cutsetconditioning scheme. One sample cutset space subsequently approximatedistribution P (C|e) samples, shown Bidyuk Dechter (2007).second approach, use here, enumerate h tuples boundrest. shall refer selected tuples active tuples. lower bound P (e)obtained computing exactly quantities P (ci , e) 1 h resulting partialsum Eq. (2). approach likely perform well selected h tuples containprobability mass P (e). However, approach cannot applied directlyobtain bounds posterior marginals Eq. (3). Even partial sum Eq. (3)requires computing P (ci |e) turn requires normalization constant P (e).obtain naive bounds posterior marginals Eq. (1) using P L (e) P U (e) denoteavailable lower upper bounds joint probabilities:P L (x, e)P U (x, e)P(x|e)P U (e)P L (e)However, bounds usually perform poorly often yield upper bound > 1.Horvitz et. al (1989) first propose scheme bounding posterior marginalsbased subset cutset tuples. proposed select h highest probability tuplesP (c) derived lower upper bounds sum Eq. (3) joint probabilitiesP (ci , e) priors P (ci ) 1 h. resulting bounded conditioning algorithmshown compute good bounds posterior marginals variablesAlarm network (with = 108). However, intervals lower upper boundvalues increase probability evidence becomes smaller prior distributionbecomes bad predictor high probability tuples P (C|e) P (c) becomes badupper bound P (c, e).expression derive paper yields significantly improved formulationresults Active Tuples Bounds (AT B) framework. generated bounds facilitate336fiActive Tuples-based Scheme Bounding Posterior Beliefsanytime performance provably tighter bounds computed boundedconditioning. addition, expression accommodates use off-the-shelf schemebounds probability evidence. Namely, B accepts algorithm boundingP (e) generates algorithm bounds posterior marginals. Moreover, alsotighten input bounds P (e).time complexity B linear number active (explored) cutset tuplesh. complexity bounding P (e) O(T ), bounding probability massunexplored tuples O(T h (d 1) |C|) |C| number variables cutsetmaximum domain size.evaluate framework experimentally, using variant bound propagation (BdP )(Leisink & Kappen, 2003) plug-in bounding scheme. BdP computes boundsiteratively solving linear optimization problem variable minimummaximum objective function correspond lower upper bounds posteriormarginals. performance BdP demonstrated Alarm network, Isinggrid network, regular bipartite graphs. Since bound propagation exponentialMarkov boundary size, since requires solving linear programming problemsmany times, overhead plug-in scheme high cost-effective.therefore utilize variant bound propagation called ABdP +, introduced BidyukDechter (2006b), trades accuracy speed.use Gibbs cutset sampling (Bidyuk & Dechter, 2003a, 2003b) finding highprobability cutset tuples. schemes, stochastic local search (Kask & Dechter,1999) also used. investigation generating high-probability cutset tuplesoutside primary scope paper.show empirically B using bound propagation often superior boundpropagation alone given comparable time resources. importantly,Bs accuracy improves time. also demonstrate power B improvingbounds probability evidence. latter main focus paper,lower upper bounds probability evidence contained expressionbounding posterior marginals.paper organized follows. Section 2 provides background previously proposed method bounded conditioning. Section 3 presents analyzes B framework. Section 4 describes implementation details using bound propagationB plug-in presents empirical evaluation. Section 5 discusses related work,Section 6 concludes.2. Backgroundbackground, define key concepts describe bounded conditioning algorithminspired work.2.1 Preliminariessection, define essential terminology provide background informationBayesian networks.337fiBidyuk, Dechter & RollonDefinition 2.1 (graph concepts) directed graph pair G=< V, E >, V ={X1 , ..., Xn } set nodes E = {(Xi , Xj )|Xi , Xj V} set edges. Given(Xi , Xj ) E, Xi called parent Xj , Xj called child Xi . setXi parents denoted pa(Xi ), pai , set Xi children denoted ch(Xi ),chi . family Xi includes Xi parents. moral graph directed graphG undirected graph obtained connecting parents nodes Gremoving arrows. cycle-cutset undirected graph subset nodes that,removed, yields graph without cycles. loop directed graph G subgraphG whose underlying graph cycle (undirected). directed graph acyclicdirected loops. directed graph singly-connected (also called poly-tree),underlying undirected graph cycles. Otherwise, called multiply-connected.Definition 2.2 (loop-cutset) vertex v sink respect loop L twoedges adjacent v L directed v. vertex sink respectloop L called allowed vertex respect L. loop-cutset directed graph Gset vertices contains least one allowed vertex respect loop G.Definition 2.3 (Bayesian network) Let X = {X1 , ..., Xn } set random variablesmulti-valued domains D(X1 ), ..., D(Xn ). Bayesian network B (Pearl, 1988)pair <G, P> G directed acyclic graph whose nodes variables XP = {P (Xi |pai ) | = 1, ..., n} set conditional probability tables (CPTs) associatedXi . B represents joint probability distribution product form:P (x1 , ...., xn ) =nP (xi |pa(Xi ))i=1evidence e instantiated subset variables E X .Definition 2.4 (Markov blanket Markov boundary) Markov blanket Xisubset variables X Xi conditionally independent variablesgiven . Markov boundary Xi minimal Markov blanket (Pearl, 1988).following discussion identify Markov boundary Xi Markov blanketconsisting Xi parents, children, parents children.Definition 2.5 (Relevant Subnetwork) Given evidence e, relevant subnetworkXi relativde e subnetwork B obtained removing descendants Xiobserved observed descendants.observations change, Markov boundary Xi stayrelevant subnetwork may change. inference tasks defined relative specificset observations e, often convenient restrict attention Markov boundaryXi relevant subnetwork Xi .common query Bayesian networks belief updating taskcomputing posterior distribution P (Xi |e) given evidence e query variableXi X . Another query compute probability evidence P (e). tasks NPhard (Cooper, 1990). Finding approximate posterior marginals fixed accuracy also338fiActive Tuples-based Scheme Bounding Posterior BeliefsNP-hard (Dagum & Luby, 1993; Abdelbar & Hedetniemi, 1998). networkpoly-tree, belief updating inference tasks accomplished time linearsize network. general, exact inference exponential induced widthnetworks moral graph.Definition 2.6 (induced width) width node ordered undirected graphnumber nodes neighbors precede ordering. width orderingo, denoted w(o), width nodes. induced width ordered graph, w (o),width ordered graph obtained processing nodes last first.Definition 2.7 (w-cutset) w-cutset Bayesian network B subset variablesC that, removed moral graph network, induced width w.Throughout paper, consider Bayesian network set variables X ,evidence variables E X evidence E = e, cutset C = {C1 , ..., Cp } X \E.Lower-caseQc = {c1 , ..., cp } denote arbitrary instantiation cutset C, =|D(C)| = Ci C |D(Ci )| denote number different cutset tuples.2.2 Bounded ConditioningBounded conditioning (BC) anytime scheme computing posterior bounds Bayesiannetworks proposed Horvitz et. al (1989). derived loop-cutset conditioningmethod (see Eq. 3). Given node X X domain value x D(X), derivebounds following formula:P (x|e) =XP (x|c , e)P (c |e) =hXP (x|c , e)P (c |e) +i=1i=1XP (x|ci , e)P (ci |e)(4)i=h+1hard-to-compute P (ci |e) replaced h normalization formula:Phi=1 P (x|c , e)P (c , e)Pi=1 P (c , e) +i=h+1 P (c , e)P (x|e) = Ph+XP (x|ci , e)P (ci |e)(5)i=h+1BC computes exactly P (ci , e) P (x|ci , e) h cutsetPtuples bounds rest.lower bound obtained Eq. (5) replacingi=h+1 P (c , e) denomiPMnator sum priors i=h+1 P (c ) simply dropping sum right:LPBC(x|e)Phi=1 P (x, c , e)Pi=h+1 P (c )i=1 P (c , e) +, Ph(6)Pupper bound obtained Eq. (5) replacingi=h+1 P (c , e) denominator zero, replacing P (x|ci , e) P (ci |e) > h upper bounds1 derived upper bound (not provided here) respectively:PMPhi=h+1 P (c )Ui=1 P (x, c , e)PBC (x|e) , Ph+ PhPhLUi=1 P (c , e)i=1 P (c |e) + 1i=1 P (c |e)339fiBidyuk, Dechter & RollonApplying definitions P L (ci |e) =Phi=1P (ci ,e)PMP (ci ,e)+i=h+1P (ci )P U (ci |e) =P (ci ,e)Phi=1 P (c ,e)Horvitz et al. (1989), get:PPhPMPh(i=h+1 P (c ))( i=1 P (c , e) +i=h+1 P (c ))Ui=1 P (x, c , e)+PBC (x|e) , PhPhi=1 P (c , e)i=1 P (c , e)(7)bounds expressed Eq. (6) (7) converge exact posterior marginalsh . However, show that,Theorem 2.1 (bounded conditioning bounds interval) interval lowerupper bounds computed bounded conditioning lower bounded probability massprior distribution P (C) unexplored cutset tuples:Uh, PBC(x|e)LPBC(x|e)XP (ci )i=h+1Proof. See Appendix A.3. Architecture Active Tuples Boundssection, describe Active Tuples Bounds (AT B) framework. buildsprinciples bounded conditioning. Namely, given cutset C methodgenerating h cutset tuples, probabilities P (c, e) h tuples evaluated exactlyrest upper lower bounded. worst bounds P (c, e) lower bound0 upper bound P (c). B bounds improved using plug-in algorithmcomputes tighter bounds participating joint probabilities. always computestighter bounds bounded conditioning, even using 0 P (c) bound P (c, e).rest section, c1:q = {c1 , ..., cq } q < |C| denotes generic partialinstantiation first q variables C, ci1:q indicates particular partial assignment.Given h cutset tuples, 0 h , assume without loss generalityfirst h tuples according enumeration order, variable X X \E x D(X),rewrite Eq. (3) as:PhPMPMi=1 P (x, c , e) +i=h+1 P (x, c , e)i=1 P (x, c , e)P (x|e) = PM(8)= PhPi=1 P (c , e)i=h+1 P (c , e)i=1 P (c , e) +probabilities P (x, ci , e) P (ci , e), 1 h, computed polynomial timeC loop-cutset timePand space exponentialPin w C w-cutset. questioncompute boundi=h+1 P (c , e) efficient manner.i=h+1 P (x, c , e)h+1approach first replaces sums tuples c ,...,cM sumpolynomial number (in h) partially-instantiated tuples. that, develop newexpressions lower upper bounds posterior marginals functionlower upper bounds joint probabilities P (x, c1:q , e) P (c1:q , e). assumederivation algorithm compute bounds, referPAL (x, c1:q , e) (resp. PAL (c1:q , e)) PAU (x, c1:q , e) (resp. PAU (c1:q , e)) respectively.340fiActive Tuples-based Scheme Bounding Posterior BeliefsC101C2012C3C30101C40C4101Figure 1: search tree cutset C = {C1 , ..., C4 }.3.1 Bounding Number Processed Tuplesformally define partially-insantiated tuples replace sum exponential number uninstantiated tuples (h + 1 ) sum polynomialnumber partially-instantiated tuples (h + 1 0 ) Eq. 8.Consider fully-expanded search tree depth |C| cutset search space expandedorder C1 ,...,Cp . path root leaf depth |C| corresponds fullcutset tuple. call path active path corresponding tuple activetuple. obtain truncated search tree trimming branchesactive paths:Definition 3.1 (truncated search tree) Given search tree covering search spaceH variables = {Y1 , . . . , Ym } X , truncated search tree relative subset= {y 1 , ..., } D(Y1 ) ... D(Ym ) full assignments, obtained marking edgespaths appearing removing unmarked edges nodes exceptemanating marked nodes.Let = {c1 , . . . , ch }. Clearly, leaves depth q < |C| truncated searchtree relative correspond partially instantiated cutset tuples c1:qextended full cutset assignments.Example 3.1 Consider Bayesian network B cutset variables C={C1 , ..., C4 }, domain values D(C1 )=D(C3 )=D(C4 )={0, 1}, D(C2 )={0, 1, 2}, four fully-instantiated tuples {0, 1, 0, 0}, {0, 1, 0, 1}, {0, 2, 1, 0}, {0, 2, 1, 1}. Figure 1 shows truncated search tree,remaining partially instantiated tuples {0, 0}, {0, 1, 1}, {0, 2, 0}, {1}.Proposition 3.1 Let C cutset, maximum domain size, h numbergenerated cutset tuples. number partially-instantiated cutset tuplestruncated search tree bounded O(h (d 1) |C|).341fiBidyuk, Dechter & RollonProof. Since every node path root C1 leaf Cp(d 1) emanating leaves, theorem clearly holds.Let 0 number truncated tuples. enumerate partially instantiatedtuples, denoting j-th tuple cj1:qj , 1 j 0 , qj tuples length. Clearly,probability mass cutset tuples ch+1 , ..., cM captured sumtruncated tuples. Namely:Proposition 3.2X0P (c , e) =P (cj1:qj , e)(9)j=1i=h+1XX0P (x, c , e) =XP (x, cj1:qj , e)(10)j=1i=h+1Therefore, bound sums tuples h + 1 Eq. (8) boundingpolynomial (in h) number partially-instantiated tuples follows,P (x|e) =Phi=1 P (x, c , e)Phi=1 P (c , e)++PM 0jj=1 P (x, c1:qj , e)PM 0jj=1 P (c1:qj , e)(11)3.2 Bounding Probability Truncated Tuplesfollowing, develop lower upper bound expressions used B.3.2.1 Lower BoundsFirst, decompose P (cj1:qj , e), 0 j 0 , follows. Given variable X Xdistinguished value x D(X):P (cj1:qj , e) =XP (x0 , cj1:qj , e) = P (x, cj1:qj , e) +XP (x0 , cj1:qj , e)(12)x0 6=xx0 D(X)Replacing P (cj1:qj , e) Eq. (11) right-hand side Eq. (12), get:P (x|e) = Phi=1 P (cPM 0jj=1 P (x, c1:qj , e)i=1 P (x, c , e) +PM 0 PP 0j0 j+j=1x0 6=x P (x , c1:qj , e)j=1 P (x, c1:qj , e) +Ph, e)(13)use following two lemmas:Lemma 3.1 Given positive numbers > 0, b > 0, 0, < b, then:342ba+b+ .fiActive Tuples-based Scheme Bounding Posterior BeliefsLemma 3.2 Given positive numbers a, b, , L , U , < b L U , then:+ La++ Ub + Lb+b + Uproof lemmas straight forward.Lemma 3.2 says sums numerator denominator component common, replacing larger value U numeratordenominator yields larger fraction. Replacing smaller value L placesyields smaller fraction.Observe Eq. (13) sums numerator denominatorcontain P (x, cj1:qj , e). Hence, apply Lemma 3.2. obtain lower boundreplacing P (x, cj1:qj , e), 1 j 0 , Eq. (13) corresponding lower boundsnumerator denominator, yielding:hX0P (x, c , e) +i=1P (x|e)hXP (ci , e) +XPAL (x, cj1:qj , e)j=1M0XPAL (x, cj1:qj , e) +P (x0 , cj1:qj , e)j=1 x0 6=xj=1i=1(14)0XXPSubsequently, grouping PAL (x, cj1:qj , e) x0 6=x P (x0 , cj1:qj , e) one sum replacingPPAL (x, cj1:qj , e) + x0 6=x P (x0 , cj1:qj , e) corresponding upper bound (increasing denominator), obtain:P (x|e)hX0P (x, c , e) +i=1hXP (c , e) +M0XXPAL (x, cj1:qj , e)j=1U B[PAL (x, cj1:qj , e)j=1i=1, PAL (x|e)+XP (x0(15), cj1:qj , e)]x0 6=xupper bound UB obtained follows:(PXPAL (x, cj1:qj , e) + x0 6=x PAU (x0 , cj1:qj , e)j0 jLP (x , c1:qj , e)] , minU B[PA (x, c1:qj , e) +PAU (cj1:qj , e)0x 6=x(16)P0 , cj , e).U (x0 , cj , e) is, obviously, upper boundP(xP1:qj1:qjx0 6=xx0 6=xPjjjUL0value PA (c1:qj , e) also upper bound since PA (x, c1:qj , e)+ x0 6=x P (x , c1:qj , e) P (cj1:qj , e)valuePPAU (cj1:qj , e). Neither bound expression Eq. (16) dominates other. Thus, compute minimum two values.343fiBidyuk, Dechter & RollonPlease note numerator Eq. (15) also provides anytime lower boundjoint probability P (x, e) used compute lower bound probabilityevidence. general, lower bound denoted PAL (e) obtained by:P (e)hX0P (c , e) +XPAL (cj1:qj , e) , PAL (e)(17)j=1i=13.2.2 Upper Boundupper bound expression obtained similar manner. Since numeratordenominator Eq. (13) contain addends P (x, cj1:qj , e), using Lemma 3.2 replaceP (x, cj1:qj , e) upper bound PAU (x, cj1:qj , e) yielding:P (x|e)hX0P (x, c , e) +P (c , e) +PAU (x, cj1:qj , e)j=1i=1hXXM0XPAU (x, cj1:qj , e)+P (x0, cj1:qj , e)j=1 x0 6=xj=1i=1(18)0XXSubsequently, replacing P (x0 , cj1:qj , e), x0 6= x, lower bound (reducing denominator), obtain new upper bound expression P (x|e):P (x|e)hX0P (x, c , e) +i=1P (ci , e) +PAU (x, cj1:qj , e)j=1i=1hXXM0XPAU (x, cj1:qj , e) +M0X, PAU (x|e)X(19)PAL (x0 , cj1:qj , e)j=1 x0 6=xj=1Similar lower bound, numerator upper bound expression PAU (x|e) provides anytime upper bound joint probability P (x, ci , e) generalizedupper bound probability evidence:P (e)hXi=10P (c , e) +XPAU (cj1:qj , e) , PAU (e)(20)j=1derived bounds PAL (x|e) PAU (x|e) never worse obtained boundedconditioning, show Section 3.4.3.3 Algorithmic DescriptionFigure 2 summarizes active tuples-based bounding scheme B. steps 1 2,generate h fully-instantiated cutset tuples compute exactly probabilities P (ci , e)P (X, ci , e) h, X X \(C E), using, example, bucket-elimination algorithm(Dechter, 1999). step 3, compute bounds partially instantiated tuples usingalgorithm A. step 4, compute lower upper bounds posterior marginalsusing expressions (15) (19), respectively.344fiActive Tuples-based Scheme Bounding Posterior BeliefsActive Tuples-based Bounds ArchitectureInput: Bayesian network (B), variables X , evidence E X , cutset C X \E, constanth, algorithm computing lower upper bounds joint probabilities.Output: lower bounds P L , upper bounds P U .1. Generate h cutset tuples.2. Compute:Phi=1 P (ci , e)PhSx i=1 P (x, ci , e), x D(X), X X \(C E)3. Traverse partially-instantiated tuples:03.1 Generate truncated tree associated h tuples let c11:q1 , ..., cM1:qM 00 partial assignments.3.2 x D(X), X X \(C E), compute:PM 0 L(x, cj1:qj , e)LBA (x) j=1 PAU BA (x)0U BA(x)4. Compute bounds:PM 0j=1PM 0j=1UPA(x, cj1:qj , e)U B[P (x, cj1:qj , e) +LPA(x|e)UPA(x|e)==Px0 6=xPA (x0 , cj1:qj , e)]Sx +LBA (x)0 (x)S+U BASx +U BA (x)S+U BA (x)+LBA (x)Lu5. Output {PA(x|e)} {PA(x|e)}.Figure 2: Active Tuples Bounds ArchitectureExample 3.2 Consider Bayesian network B described Example 3.1. RecallB cutset C = {C1 , ..., C4 } domains D(C1 ) = D(C3 ) = D(C4 ) = {0, 1}D(C2 ) = {0, 1, 2}. total number cutset tuples = 24. Let X 6 C variableB domain D(X) = {x, x0 }. compute bounds P (x|e). Assume generatedfour cutset tuples (h = 4) before:c1 = {C1 = 0, C2 = 1, C3 = 0, C4 = 0} = {0, 1, 0, 0}c2 = {C1 = 0, C2 = 1, C3 = 0, C4 = 1} = {0, 1, 0, 1}c3 = {C1 = 0, C2 = 2, C3 = 1, C4 = 0} = {0, 2, 1, 0}c4 = {C1 = 0, C2 = 2, C3 = 1, C4 = 1} = {0, 2, 1, 1}corresponding truncated search tree shown Figure 1. tuple {0, 1, 0, 0},compute exactly probabilities P (x, C1 =0, C2 =1, C3 =0, C4 =0, e) P (C1 =0, C2 =1,C3 = 0, C4 = 0). Similarly, obtain exact probabilities P (x, C1 = 0, C2 = 1, C3 = 0,C4 = 1) P (C1 = 0, C2 = 1, C3 = 0, C4 = 1) second cutset instance {0, 1, 0, 1}.345fiBidyuk, Dechter & RollonSince h = 4,Phi=1 P (x4X0 , ci , e)Phi=1 P (c, e)are:P (x, ci , e) = P (x, c1 , e) + P (x, c2 , e) + P (x, c3 , e) + P (x, c4 , e)i=14XP (ci , e) = P (c1 , e) + P (c2 , e) + P (c3 , e) + P (c4 , e)i=1remaining partial tuples are: c11:2 = {0, 0}, c21:3 = {0, 1, 1}, c31:3 = {0, 2, 0}, c41:1 ={1}. Since 4 tuples full cutsets, compute bounds joint probabilities.Using notation Figure 2, sums partially instantiated tuplesform:U BA (x) , PAU (x, c11:2 , e) + PAU (x, c21:3 , e) + PAU (x, c31:3 , e) + PAU (x, c41:1 , e)LBA (x) , PAL (x, c11:2 , e) + PAL (x, c21:3 , e) + PAL (x, c31:3 , e) + PAL (x, c41:1 , e)Eq. (19) get:PAU (x|e)P4i=1 P (x, c , e) + U BA (x)0i=1 P (c , e) + U BA (x) + LBA (x )= P4Eq. (15) (16) get:PAL (x|e)P4i=1 P (x, c , e) + LBA (x)0i=1 P (c , e) + LBA (x) + U BA (x )= P4total number tuples processed 0 = 4 + 4 = 8 < 24.3.4 B Propertiessection analyze time complexity B framework, evaluate worstcase lower upper bounds, analyze monotonicity properties bounds interval(as function h).Theorem 3.1 (complexity) Given algorithm computes lower upper boundsjoint probabilities P (c1:qi , e) P (x, c1:qi , e) time O(T ), loop-cutset C, PAL (x|e)PAU (x|e) computed time O(h N + h (d 1) |C|) maximumdomain size N problem input size.Proof. Since C loop-cutset, exact probabilities P (ci , e) P (x, ci , e)computed time O(N ). Proposition 3.1, O(h (d 1) |C|) partiallyinstantiated tuples. Since algorithm computes upper lower bounds P (cj1:qj , e)P (x, cj1:qj , e) time O(T ), bounds partially-instantiated tuples computedtime O(T h (d 1) |C|)).346fiActive Tuples-based Scheme Bounding Posterior BeliefsLet plug-in algorithm brute-force algorithm, denoted BF , triviallyL (x, cj , e) = 0, P U (x, cj , e) = P (cj ), U B[P (cj , e)] = P (cj ).instantiates PBF1:qj1:qj1:qj1:qj1:qjBFThen, Eq. (15):LPBF(x|e),Phi=1 P (x, c , e)PhPjM0i=1 P (c , e) +j=1 P (c1:qj )Eq. (19):UPBF(x|e),PM 0jj=1 P (c1:qj )i=1 P (x, c , e) +PhPM 0ji=1 P (c , e) +j=1 P (c1:qj )PhPhi=1 P (x, c , e)Pjj=h+1 P (c )i=1 P (c , e) += Ph=PhPMji=1 P (x, c , e) +j=h+1 P (c )PhPMji=1 P (c , e) +j=h+1 P (c )(21)(22)Assuming algorithm computes bounds least good computedL (x|e) P U (x|e) worst-case bounds computed B.BF , PBFBFNow, ready compute upper bound B bounds interval:Theorem 3.2 (AT B bounds interval upper bound) B length interval lower upper bounds upper bounded monotonic non-increasing functionh:PMjj=h+1 P (c )ULPA (x|e) PA (x|e) Ph, IhPM, e) +j)P(cP(ci=1j=h+1Proof. See Appendix C.Next show B lower upper bounds good better boundscomputed BC.L (x|e).Theorem 3.3 (tighter lower bound) PAL (x|e) PBCL (x|e) worst-case lower bound computed B. Since P L (x|e) =Proof. PBFBFLL (x|e), P L (x|e) P L (x|e).PBC (x|e), PAL (x|e) PBFBCU (x|e).Theorem 3.4 (tighter upper bound) PAU (x|e) PBCU (x|e) worst-case upper bound computed B. Since P U (x|e)Proof. PBFBFU (x|e) due lemma 3.1, follows P U (x|e) P U (x|e).PBCBC4. Experimental Evaluationpurpose experiments evaluate performance B frameworktwo probabilistic tasks single-variable posterior marginals probability evidence.experiments first task conducted 1.8Ghz CPU 512 MB RAM,experiments second task conducted 2.66GHz CPU 2GB RAM.347fiBidyuk, Dechter & RollonRecall B control parameter h fixes number cutset tuplesalgorithm computes exact joint probability. Given fixed h, qualitybounds presumably depend ability select h high probability cutset tuples.implementation, use optimized version Gibbs sampling,sampling process maintains list h tuples highest joint probability.noted, schemes considered subtask part future work.obtain loop-cutset using mga algorithm (Becker & Geiger, 1996).report results, describe bound propagation variants,use plug-in algorithm also stand-alone bounding scheme.4.1 Bound PropagationBound propagation (BdP ) (Leisink & Kappen, 2003) iterative algorithm boundsposterior marginals variable. bounds initialized 0 1 iterativelyimproved solving linear optimization problem variable X Xminimum maximum objective function correspond lower upper boundposterior marginal P (x|e), x D(X).cannot directly plug BdP B bound P (c1:q , e) boundsconditional probabilities. Thus, factorize P (c1:q , e) follows:P (c1:q , e) =P (ej |e1 , . . . , ej1 , c1:q )P (c1:q )ej Efactor P (ej |e1 , . . . , ej1 , c1:q ) bounded BdP , P (c1:q ) computedLexactly since relevant subnetwork c1:q (see Def. 2.5) singly connected. Let PBdPUPBdP denote lower upper bounds computed BdP marginal.bounds BdP computes joint probability are:L(ej |e1 , . . . , ej1 , c1:q )P (c1:q ) P (c1:q , e)PBdPU(ej |e1 , . . . , ej1 , c1:q )P (c1:q )PBdPej Eej ENote BdP bound large number tuples plugged B, therefore, solve large number linear optimization problems. number variablesproblem exponential size Markov blanket X.baseline comparison B, use experiments variant boundpropagation called BdP + (Bidyuk & Dechter, 2006b) exploits structurenetwork restrict computation P (x|e) relevant subnetwork X (see Def. 2.5).Markov boundary X (see Def. 2.4) within relevant subnetwork X includechildren X observed observed descedants; therefore,subnetwork Markov boundary original network. Sometimes, Markovboundary X still big compute limited memory resouces. BdP + usesparameter k specify maximum size Markov boundary domain space.algorithm skips variables whose Markov boundary domain size exceeds k,lower upper bound values remain 0 1, respectively. variablesskipped, bounds computed BdP + remaining variables may less accurate.348fiActive Tuples-based Scheme Bounding Posterior BeliefsnetworkNw|LC||D(LC)||E|Time(BE)Time(LC)AlarmBarleycpcs54cpcs179cpcs360bcpcs422bMunin3Munin4374854179360422104410414715821227851215826473049108> 22732768491522627> 230> 2491-44-82-812-2411-234-102572350.01 sec50 sec1 sec2 sec20 min50 min8 sec70 sec0.05 sec>22 hrs122 sec37 sec> 8 hrs1> 2 109 hrs1> 1700 hrs1> 1 108 hrs1Table 1: Complexity characteristics benchmarks UAI repository: N -numbernodes, w -induced width, |LC|-number nodes loop-cutset, |D(LC)|loop-cutset state space size, Time(BE) exact computation time via bucketelimination, Time(LC) exact computation time via loop-cutset conditioning.results averaged set network instances different evidence.Evidence nodes values selected random.preliminary tests showed plugging BdP + B timewise infeasible(even small k). Instead, developed used different version bound propagationcalled ABdP + (Bidyuk & Dechter, 2006b) plug-in algorithm A, costeffective terms accuracy time overhead. ABdP + includes enhancementsBdP +, solves linear optimization problem variable using approximation algorithm. implies obtain bounds faster accurate.Roughly, relaxed linear optimization problem described fractional packing covering multiple knapsacks solved fast greedy algorithm (Bidyuk& Dechter, 2006b). ABdP + also parameterized k control maximum sizelinear optimization problem. Thus, B using ABdP + plug-in two controlparameters: h k.4.2 Bounding Single-Variable Marginalscompare performance following three algorithms: B (with ABdP +plug-in), BdP +, described previous section, BBdP + (Bidyuk & Dechter,2006a). latter combination B BdP +. First, run algorithm BABdP + plug-in. Then, use bounds computed B initialize boundsBdP + (instead 0 1) run BdP +. Note that, given fixed values h k,BBdP + always compute tighter bounds either B BdP +. goalanalyze trade-off increase bounds accuracy computationtime overhead. also compare approximate decomposition (AD) (Larkin, 2003)whenever feasible relevant. include results stand-aloneABdP + since objective compare B bounds accurate boundsobtained bound propagation. Bidyuk (2006) provides additional comparison variousrefinements BdP (Bidyuk & Dechter, 2006b) mentioned earlier.1. Times extrapolated.349fiBidyuk, Dechter & Rollon4.2.1 Benchmarkstested framework four different benchmarks: Alarm, Barley, CPCS, Munin.Alarm network model monitoring patients undergoing surgery operating room(Beinlich, Suermondt, Chavez, & Cooper, 1989). Barley network part decisionsupport system growing malting barley (Kristensen & Rasmussen, 2002). CPCS networks derived Computer-Based Patient Care Simulation system basedINTERNIST-1 Quick Medical Reference Expert systems (Pradhan, Provan, Middleton, & Henrion, 1994). experiment cpcs54, cpcs179, cpcs360b, cpcs422bnetworks. Munin networks part expert system computer-aided electromyography (Andreassen, Jensen, Andersen, Falck, Kjaerulff, Woldbye, Srensen, Rosenfalck, &Jensen, 1990). experiment Munin3 Munin4 networks. network,generated 20 different sets evidence variables picked random. Barley network,select evidence variables defined Kristensen Rasmussen (2002).Table 1 summarizes characteristic network. one, table specifiesnumber variables N , induced width w , size loop cutset |LC|, numberloop-cutset tuples |D(LC)|, time needed compute exact posterior marginalsbucket-tree elimination (exponential induced width w ) cutset conditioning(exponential size loop-cutset).Computing posterior marginals exactly easy Alarm network, cpcs54,cpcs179 using either bucket elimination cutset conditioning since small induced width small loop-cutset. include benchmarks proof conceptonly. Several networks, Barley, Munin3, Munin4, also small induced widthand, hence, exact posterior marginals obtained bucket elimination. However, since B linear space, compared linear-space schemescutset-conditioning. perspective, Barley, Munin3, Munin4 hard.example, Barley network 48 variables, induced width w = 7, exact inference bucket elimination takes 30 seconds. loop-cutset contains 12 variables,number loop-cutset tuples exceeds 2 million variables largedomain sizes (up 67 values). Enumerating computing cutset tuples, rate1000 tuples per second, would take 22 hours. Similar considerations applycase Munin3 Munin4 networks.4.2.2 Measures Performancemeasure quality bounds via average length interval lowerupper bound:PPULXXxD(X) (P (x|e) P (x|e))PI=XX |D(X)|approximate posterior marginal midpoint lower upper boundorder show whether bounds well-centered around posterior marginal P (x|e).Namely:P (x|e) =PAU (x|e) + PAL (x|e)2350fiActive Tuples-based Scheme Bounding Posterior Beliefsmeasure average absolute error respect approximation:PPXXxD(X) |P (x|e) P (x|e)|P=XX |D(X)|PhP (x,ci ,e)100% covered explored cutsetFinally, report %P (e) = i=1P (e)tuples. Notably, benchmarks, thousand cutset tuples enough cover> 90% P (e).4.2.3 Resultssummarize results benchmark tabular format charts. highlightbold face first B data point average bounds interval good betterBdP +. charts show convergence bounds interval length functionh time.B BBdP + maximum Markov boundary domain size fixed k = 210 .BdP +, vary parameter k 214 219 . Note BdP + depends k,h. tables, report best result obtained BdP + computation timeappears constant respect h. However, plot accuracytime, include BdP + bounds obtained using smaller values parameter k. caseAlarm network, varying k make difference since full Markov boundarydomain size equals 210 < 214 . computation time BBdP + includes B plusBdP + time.Alarm network. Figure 3 reports results. Since maximum Markov boundaryAlarm network small, BdP + runs without limitations computes average boundsinterval 0.61 4.3 seconds. Note enumeration less 25% totalnumber cutset tuples covers 99% P (e). fact suggests schemes basedcutset conditioning suitable benchmark. Indeed, B outperformsBdP +, computing accurate bounds starting first data point h = 25mean interval B = 0.41 computation time 0.038 seconds, ordermagnitude less BdP +. extreme efficiency B terms time clearly seenright chart. x-axis scale logarithmic fit results. expected,average bounds interval generated B BBdP + decrease number cutsettuples h increases, demonstrating anytime property B respect h. Givenfixed h, BBdP + significant overhead time respect B (two ordersmagnitude values h smaller 54) minor improvement accuracy.Barley network. Figure 4 reports results. B BBdP + improve h increases.However, improvement quite moderate time consuming due uniform shape distribution P (C|e) reflected small % P (e) coveredexplored tuples (only 1% 562 tuples 52% 12478 tuples). example,average B (resp. BBdP +) bounds interval decreases 0.279 (resp. 0.167), obtained9 (resp. 10) seconds, 0.219 (resp. 0.142) obtained 139 (resp. 141) seconds. Givenfixed h, BBdP + substantially improves B bounds little time overhead (2 secondsgeneral). Namely, benchmark, BBdP + computation time dominated B351fiBidyuk, Dechter & Rollonh253440485054%P(e)8693969798990.610.610.610.610.610.61Alarm, N=37, w =5, |LC|=8, |DLC |=108, |E|=1-4BdP +Btime(sec)time(sec)0.214.30.410.120.0380.350.214.30.310.090.0390.270.214.30.250.070.0440.220.214.30.240.050.0510.150.214.30.160.040.0520.120.214.30.130.030.0590.09ATBAlarm, N=37, w*=5, |LC|=8, |E|=1-40.60.50.40.30.2ATBBdP+BBdP+0.7Avg Bounds IntervalAvg Bounds IntervalAlarm, N=37, w*=5, |LC|=8, |E|=1-4BdP+0.7BBdP +time(sec)0.103.40.082.30.062.10.041.50.031.20.020.86BBdP+0.60.50.40.30.20.10.100010203040500.01600.1110time (sec)hFigure 3: Results Alarm network. table reports average bounds interval I,average error , computation time (in seconds), percent probabilityevidence P (e) covered fully-instantiated cutset tuples function h.highlight bold face first B data point average boundsinterval good better BdP +. charts show convergencebounds interval length function h time. BdP + uses full size Markovboundary since domain size small (< 214 ), resulting one data pointchart right.computation time. Note computation time stand-alone BdP + algorithmless 2 seconds. Within time, BdP + yields average interval length 0.23,B BBdP + spend 86 10 seconds, respectively, obtain qualitybounds. However, anytime behavior latter algorithms allows improvetime, desirable characteristic computing bounds. Moreover, noteoverhead time respect B completely negligible.CPCS networks. Figures 5 8 show results cpcs54, cpcs179, cpcs360bcpcs422b, respectively. behavior algorithms networks similar.previous benchmarks, B BBdP + bounds interval decreases h increases. Givenfixed h, BBdP + computes slightly better bounds intervals B networkscpcs179. networks, BBdP + overhead time respect B.overhead constant values h networks except cpcs54,overhead decreases h increases. B BBdP + outperform BdP +. algorithmscompute bound interval length BdP +, improving computation time oneorder magnitude. Consider example cpcs422b, challenging instance inferencescheme relatively large induced width loop-cutset size. B outperformsBdP + 50 seconds starting h = 1181, BBdP + outperforms BdP + 37352fiActive Tuples-based Scheme Bounding Posterior Beliefsh56213942722442960167950929712478Barley, N =48, w =7, |LC|=12, |DLC | > 2 106 , |E|=4-8BdP +Btime(sec)time(sec)0.230.071.70.2790.09790.1670.230.071.70.2630.090230.1620.230.071.70.2470.084430.1540.230.071.70.2350.079650.1470.230.071.70.2300.078860.1450.230.071.70.2280.077990.1450.230.071.70.2240.0751110.1430.230.071.70.2190.0731390.142%P(e)1361422334052Barley, N=48, w*=7, |LC|=12, |E|=4-8BBdP+time(sec)0.047100.045250.042450.040670.040880.0401010.0391130.038141ATBBarley, N=48, w*=7, |LC|=12, |E|=4-8ATBBdP+0.250.20.15BBdP+0.3Avg Bounds IntervalAvg Bounds IntervalBdP+BBdP+0.30.250.20.150.10.102000400060008000100001200014000020406080100120time (sec)hFigure 4: Results Barley network. table reports average bounds interval I,average error , computation time (in seconds), percent probabilityevidence P (e) covered fully-instantiated cutset tuples function h.highlight bold face first B data point average boundsinterval good better BdP +. charts show convergencebounds interval length function h time.seconds starting h = 253 (BdP + convergence shown plot, bestresult reported table).Larkin (2003) reported bounds cpcs360b cpcs422b using AD algorithm.first network, AD achieved bounds interval length 0.03 10 seconds. Withintime, B computes average bounds interval 0.005. cpcs422b, AD achievedbounds interval 0.15, obtained 30 seconds. Within time, B BBdP +obtain comparable results computing average bounds interval 0.24 0.15, respectively.important note comparison instances since evidencenodes same. Larkins code available experiments.Munin networks. Figure 9 reports results Munin networks. Let us firstconsider Munin3 network. Given fixed h, B BBdP + compute almost identicalbound intervals BBdP + noticeable time overhead. Note two curveschart showing convergence function h close hard distinguish,points BBdP + chart showing convergence function timeshifted right respect ones B. B clearly superior BdP +accuracy time. BdP + computes bounds interval 0.24 within 12 seconds,B computes bounds interval 0.050 8 seconds. Munin4, given fixed353fiBidyuk, Dechter & Rollonh513111415811933229026093219392661997274%P(e)10192934404653596368cpcs54, N =54, |LC|=15, w =15, |DLC |=32678, |E|=2-8BdP +Btime(sec)time(sec)0.350.02240.510.0270.90.340.350.02240.450.0231.50.320.350.02240.420.0211.90.310.350.02240.400.0202.20.300.350.02240.380.0192.40.300.350.02240.370.0182.70.290.350.02240.340.0163.20.270.350.02240.310.0143.80.250.350.02240.230.0105.90.200.350.02240.200.0086.90.17ATBcpcs54, N=54, |LC|=15, w*=15, |E|=2-8BBdP+time(sec)0.0113.10.0103.10.0093.40.0093.60.0083.90.0074.00.0074.50.0065.20.0066.60.0067.3cpcs54, N=54, |LC|=15, w*=15, |E|=2-8ATBBdP+0.6Avg Bounds IntervalAvg Bounds IntervalBdP+BBdP+0.60.50.40.30.20.10BBdP+0.50.40.30.20.10010002000300040005000600070008000h0246810time (sec)Figure 5: Results cpcs54 network. table reports average bounds interval I,average error , computation time (in seconds), percent probabilityevidence P (e) covered fully-instantiated cutset tuples function h.highlight bold face first B data point average boundsinterval good better BdP +. charts show convergencebounds interval length function h time.h, BBdP + computes tighter bounds B time overhead. However,improvement decreases h increases shown convergence curves eitherfunction h time. Since loop-cutset size large, convergence Brelatively slow. BdP + computes bounds interval 0.23 within 15 seconds, BBBdP + compute bounds quality within 54 21 seconds, respectively.4.3 Bounding Probability Evidencecompare performance following three algorithms: B, mini-bucket elimination (M BE) (Dechter & Rish, 2003), variable elimination conditioning (V EC).B, test different configurations control parameters (h, k). Noteh = 0, B equivalent plug-in algorithm A, case ABdP +.4.3.1 Algorithms Benchmarksgeneral bounding algorithm graphical model problems. particular, givenBayesian network, computes lower upper bound probability evidence.354fiActive Tuples-based Scheme Bounding Posterior Beliefsh24233440657480199612851669%P(e)7075788285878890cpcs179, N =179, w =8, |LC|=8, |DLC |=49152, |E|=12-24BdP +Btime(sec)time(sec)0.150.05200.220.06740.0920.150.05200.120.03360.0540.150.05200.090.02470.0370.150.05200.070.01890.0290.150.05200.050.014100.0220.150.05200.040.010120.0170.150.05200.030.006130.0120.150.05200.020.003160.007ATBcpcs179, N=179, |LC|=8, w*=8, |E|=12-24BBdP+time(sec)0.029110.016130.010130.008150.006170.005180.003200.00222ATBcpcs179, N=179, |LC|=8, w*=8, |E|=12-24BdP+BdP+BBdP+1.E-011.E-021.E-03BBdP+1.E+00Avg Bounds IntervalAvg Bounds Interval1.E+001.E-011.E-021.E-03050010001500200025003000h0510152025time (sec)Figure 6: Results cpcs179 network. table reports average bounds interval I,average error , computation time (in seconds), percent probabilityevidence P (e) covered fully-instantiated cutset tuples function h.highlight bold face first B data point average boundsinterval good better BdP +. charts show convergencebounds interval length function h time.control parameter z, allows trading time space accuracy.value control parameter z increases, algorithm computes tighter bounds usingtime space, exponential z.V EC algorithm combines conditioning variable elimination. basedw-cutset conditioning scheme. Namely, algorithm conditions instantiatesenough variables remaining problem conditioned instantiated variablessolved exactly using bucket elimination (Dechter, 1999). exact probability evidence computed summing exact solution output bucket eliminationpossible instantiations w-cutset. V EC terminated completion, outputs partial sum yielding lower bound probability evidence.implementation V EC publicly available1 .tested B bounding P (e) three different benchmarks: Two-layer Noisy-Or,grids coding networks. instances included UAI08 evaluation2 .two-layer noisy-or networks, variables organized two layers onessecond layer 10 parents. probability table represents noisy OR-function.1. http://graphmod.ics.uci.edu/group/Software2. http://graphmod.ics.uci.edu/uai08/Evaluation/Report355fiBidyuk, Dechter & Rollonh1212825017229381168138815821757%P(e)839296979898999999cpcs360b, N=360, w = 21, |LC| = 26, |DLC |=226 , |E|=11-23BdP +Btime(sec)time(sec)0.027 0.009550.0486 1.6E-250.02740.027 0.009550.0046 9.0E-4100.00320.027 0.009550.0020 3.6E-4150.00140.027 0.009550.0012 2.4E-4190.00090.027 0.009550.0006 8.4E-5250.00040.027 0.009550.0005 7.5E-5290.00040.027 0.009550.0004 5.9E-5350.00030.027 0.009550.0003 5.3E-5390.00020.027 0.009550.0003 4.7E-5430.0002ATBcpcs360b, N=360, |LC|=26, w*=21, |E|=11-23cpcs360b, N=360, |LC|=26, w*=21, |E|=11-23ATB1.E+00BBdP+time(sec)1.0E-278.5E-4123.5E-4172.3E-4217.8E-5276.9E-5315.4E-5374.8E-5414.4E-546BdP+1.E+00BdP+BBdP+Avg Bounds IntervalAvg Bounds IntervalBBdP+1.E-011.E-021.E-031.E-011.E-021.E-031.E-041.E-041.E-05020040060080010001200h051015202530Time (sec)Figure 7: Results cpcs360b. table reports average bounds interval I, averageerror , computation time (in seconds), percent probability evidenceP (e) covered fully-instantiated cutset tuples function h. highlight bold face first B data point average bounds intervalgood better BdP +. charts show convergence boundsinterval length function h time.parent variable yj value Pj [0..Pnoise ]. QThe CPT variablesecond layer defined P (x = 0|y1 , . . . , yP ) = yj =1 Pj P (x = 1|y1 , . . . , yP ) =1 P (x = 0|y1 , . . . , yP ). experiment class problems called bn2o instancesUAI08.grid networks, variables organized grid. experimentgrids2 instances, called UAI08, characterized two parameters(M, D), percentage determinism (i.e., percentage values CPTsassigned either 0 1). parameter configuration, 10 samples generatedrandomly assigning value 1 one leaf node. UAI08 competition, instancesnamed D-M -I, instance number.Coding networks represented four layer Bayesian network nodeslayer. second third layer correspond input information bits parity checkbits respectively. parity check bit represents XOR function input bits. Inputparity check nodes binary output nodes real-valued. considerBN 126 BN 134 instances UAI08 evaluation. one = 128, 4 parents356fiActive Tuples-based Scheme Bounding Posterior Beliefsh6425637956186111811501242730624598%P(e)1.72.02.62.93.44.55.48.09.512.2cpcs422b, N=422, w = 22, |LC| = 47, |DLC |=247 , |E|=4-10BdP +ATBtime(sec)time(sec)0.190.061200.280.100210.190.190.061200.240.090260.150.190.061200.220.078320.140.190.061200.200.073360.130.190.061200.190.068430.120.190.061200.180.064500.120.190.061200.170.062560.120.190.061200.160.058730.120.190.061200.160.057830.120.190.061200.160.0531100.11ATBcpcs422b, N=422, |LC|=47, w*=22, |E|=4-100.3BBdP+time(sec)0.056230.050350.049410.046460.044540.041600.041650.039820.038920.036120cpcs422b, N=422, |LC|=47, w*=22, |E|=4-10ATB0.3BdP+BdP+0.25Avg Bounds IntervalAvg Bounds IntervalBBdP+0.20.150.10.050BBdP+0.250.20.150.10.0500100200300400500600020406080100120140time (sec)hFigure 8: Results cpcs422b. table reports average bounds interval I, averageerror , computation time (in seconds), percent probability evidenceP (e) covered fully-instantiated cutset tuples function h. highlight bold face first B data point average bounds intervalgood better BdP +. charts show convergence boundsinterval length function h time.node channel noise variance ( = 0.40). networks hardexact results available.Table 2 summarizes characteristics network. one, table specifiesnumber variables N , induced width w , size loop cutset |LC|, numberloop-cutset tuples |D(LC)|, time needed compute exact posterior marginalsbucket-tree elimination (exponential induced width w ) cutset conditioning(exponential size loop-cutset). indicates bucket-tree eliminationunfeasible terms memory demands. Note characteristics grid networksdepend sizes percentage determinism; characteristicscoding networks same.purposes, consider V EC another exact algorithm compute exactP (e) first second benchmarks lower bounding technique thirdbenchmark. fix control parameter z w-cutset V ECalgorithms require less 1.5GB space.357fiBidyuk, Dechter & RollonMUNIN3h196441882181326952891318535774312%P(e)6472787980818282830.240.240.240.240.240.240.240.240.24Munin3, N=1044, w =7, |LC|=30, |E|=257BdP+ATBtime(sec)time(sec)0.1120.0500.02080.1120.0300.011120.1120.0250.009180.1120.0200.007320.1120.0180.006460.1120.0170.006490.1120.0140.005540.1120.0130.004680.1120.0110.00480Munin3, N=1044, |LC|=30, w*=7, |E|=2570.100.01050010001500BBdP+time(sec)0.020160.012200.009260.007400.007540.006570.005620.004760.00488Munin3, N=1044, |LC|=30, w*=7, |E|=257ATBBdP+BBdP+ATBBdP+1.00Avg Bounds IntervalAvg Bounds Interval1.000.0480.0290.0250.0190.0170.0160.0140.0120.010BBdP+0.100.01200002040h6080100time (sec)MUNIN4h2454411029205830875194%P(e)17111720240.230.230.230.230.230.23Munin4, N=1041, w =8, |LC|=49, |E|=235BdP+ATBtime(sec)time0.1150.390.16140.240.1150.320.13170.220.1150.280.12340.210.1150.250.11540.190.1150.220.11830.180.1150.210.091340.17Munin4, N=1041, |LC|=49, w*=8, |E|=235BBdP+time(sec)0.102210.095240.089440.082650.077910.072145Munin4, N=1041, |LC|=49, w*=8, |E|=235ATBATBBBdP+Avg Bounds Interval0.40.30.20.10.005000100001500020000Avg Bounds IntervalBdP+BdP+0.4BBdP+0.30.20.10.0050100150200250time (sec)hFigure 9: Results munin3 munin4. tables report average bounds intervalI, average error , computation time (in seconds), percent probabilityevidence P (e) covered fully-instantiated cutset tuples function h.highlight bold face first B data point average boundsinterval good better BdP +. charts show convergencebounds interval length function h time.358fiActive Tuples-based Scheme Bounding Posterior Beliefsnetworkbn2o-15-30-15bn2o-15-30-20bn2o-15-30-25GridsGridsGridsGridscoding16202642Nw|LC||D(LC)||E|Time(BE)Time(LC)455055162026425122225242229407054-6124262511618532586359-642242262252116218523252863259 -264152025111125614.51174.2866.2327.5917.4 hrs93.2 hrs75.76 hrs> 293 hrs1> 266 hrs1> 2306 hrs1> 2844 hrs1> 242 hrs1Table 2: Complexity characteristics benchmarks UAI repository: N -numbernodes, w -induced width, |LC|-number nodes loop-cutset, |D(LC)|loop-cutset state space size, Time(BE) exact computation time via bucketelimination, Time(LC) exact computation time via loop-cutset conditioning.results averaged set network instances benchmark.4.3.2 Resultssummarize results benchmark tabular format. tables reportbounds computation time (in seconds) compared algorithm. B,report results varying values control parameters (h, k). particular, consider values h range 4 200, values k set {210 , 212 , 214 }.so, analyze impact control parameter performance algorithm.Grey areas tables correspond (h, k) configurations cannot compared duecomputation time.Two-layer noisy-or networks. Table 3 shows results. expected, qualitybounds produced B improves values control parameters (h, k)increase. observe best bounds obtained fixing h highest value(i.e., 200) k smallest value (i.e., 210 ). However, increase valueh leads higher computation times increasing value k. takingtime account, comparing configurations similar time (see (h = 50, k = 210 )(h = 4, k = 214 ), (h = 200, k = 210 ) (h = 50, k = 212 ), respectively), observeconfiguration highest value h smallest value k outperformsones.compared BE, clear superior approach. accuracyalgorithms depends whether look upper lower bounds. considering upper bounds, B outperforms instances 1b, 2b 3b. Noteinstances, computes worse upper bounds trivial one (i.e., greater 1).However, instances 1a, 2a 3a, computes tighter upper bounds B.lower bounds, general B outperforms MBE instances 20 25 evidencevariables, accurate instances 15 evidence variables. Regarding computation time, B definitely slower BE.1. Times extrapolated.359fiBidyuk, Dechter & RollonInst.P(e)h %P(e)ATB(h, k = 210 )LB/UBTimeATB(h, k = 212 )LB/UBTimeATB(h, k = 214 )LB/UBTimeMBE(z=18)LB/UBTimebn2o-30-15-150, |E| = 151a 5.9E-051b 0.565652a 4.0E-072b 0.541113a 1.2E-043b 0.188694502004502004502004502004502004502000.00040.1000.2500.0070.1200.4600.0030.0200.3200.0080.2101.1100.2161.0403.5800.0760.4701.4405.7E-10/5.3E-011.2E-07/1.1E-013.5E-07/5.7E-023.1E-04/9.3E-014.1E-03/8.6E-011.5E-02/8.5E-012.0E-11/1.3E-011.5E-10/1.0E-021.7E-09/4.0E-036.9E-03/7.9E-015.5E-02/7.8E-011.1E-01/7.5E-012.9E-07/1.7E-011.7E-06/4.6E-025.3E-06/2.7E-021.1E-03/7.7E-016.8E-03/6.3E-012.1E-02/5.4E-014502004502004502004502004502004502000.0040.0501.8800.0120.1400.4300.0130.4101.4100.0200.4301.6200.0020.0600.0900.00020.1100.6605.4E-12/1.6E-029.1E-11/1.8E-032.8E-09/5.7E-041.0E-04/7.3E-013.3E-03/6.7E-011.1E-02/5.9E-013.8E-11/1.6E-021.4E-09/3.3E-034.5E-09/2.4E-036.4E-03/8.3E-013.0E-02/7.7E-015.9E-02/6.9E-018.3E-14/1.8E-032.2E-12/1.1E-043.6E-12/3.3E-054.5E-05/9.7E-015.4E-02/9.3E-011.1E-01/8.8E-014502004502004502004502004502004502000.00040.010.060.0160.221.070.00040.00120.070.0180.190.650.00010.010.200.00650.451.521.3E-14/6.6E-023.7E-13/3.3E-032.0E-12/1.1E-034.3E-04/8.1E-014.6E-03/7.2E-011.3E-02/6.5E-011.8E-12/1.9E-015.7E-12/4.5E-021.8E-10/2.2E-025.3E-04/7.6E-015.4E-03/7.4E-011.4E-02/7.1E-011.7E-16/1.1E-014.3E-14/1.9E-025.5E-13/7.1E-031.0E-03/7.9E-014.2E-02/7.7E-018.5E-02/7.5E-01232103231102229892299022674225695.9E-10/4.8E-011.2E-07/9.4E-028 6.0E-10/4.4E-01129384.3E-04/9.3E-014.8E-03/8.6E-018 5.0E-04/9.3E-01124382.0E-11/1.1E-011.5E-10/8.9E-038 2.1E-11/8.5E-02115388.6E-03/8.0E-016.1E-02/7.7E-018 9.2E-03/8.0E-01115382.9E-07/1.5E-011.7E-06/4.2E-028 2.9E-07/1.4E-01103381.1E-03/7.7E-017.1E-03/6.3E-018 1.2E-03/7.7E-0195389.1E-06/4.8E-0420.17277/1.4228.4E-10/2.1E-0520.02647/1.824.4E-07/1.5E-0320.03089/0.8122.4E-15/3.3E-0439.8E-04/1.934.4E-15/8.0E-0532.3E-05/2.935.2E-13/1.7E-0635.3E-03/1.931.7E-16/3.1E-0641.4E-03/1.441.8E-12/1.2E-0547.2E-03/1.741.3E-15/4.9E-0743.5E-03/2.74bn2o-30-20-200, |E| = 201a 1.4E-071b 0.156542a 2.2E-072b 0.276953a 2.4E-093b 0.480393621953642183521693511453581983641945.4E-12/1.5E-029.1E-11/1.6E-0316 5.4E-12/1.4E-02264671.1E-04/7.3E-013.6E-03/6.7E-0116 1.1E-04/7.3E-01279683.8E-11/1.6E-021.3E-09/3.1E-0316 3.8E-11/1.5E-02211707.3E-03/8.3E-013.3E-02/7.7E-0116 8.0E-03/8.3E-01197688.3E-14/1.8E-032.2E-12/1.1E-0416 8.3E-14/1.8E-03236685.1E-05/9.7E-015.9E-02/9.3E-0116 6.2E-05/9.7E-0127768bn2o-30-25-250, |E| = 251a 2.9E-091b 0.151832a 2.4E-072b 0.308953a 2.7E-103b 0.468016119396612038161124026107367611940961063371.3E-14/6.5E-023.7E-13/2.8E-0322 1.3E-14/4.8E-02429995.7E-04/8.1E-016.7E-03/7.2E-0122 6.2E-04/8.1E-01437991.8E-12/1.9E-015.7E-12/3.9E-0222 1.8E-12/1.7E-01398995.9E-04/7.6E-016.1E-03/7.4E-0122 6.3E-04/7.6E-01374991.7E-16/1.1E-014.3E-14/1.6E-0222 1.7E-16/8.1E-02427991.2E-03/7.9E-014.8E-02/7.7E-0122 1.3E-03/7.9E-0135298Table 3: Results bn2o networks. table shows LB UB computed Bvarying number cutset tuples h maximum domain k Markovboundary.360fiActive Tuples-based Scheme Bounding Posterior Beliefs(M, D)P(e)h4(16, 50) 0.6172 1002004(20, 50) 0.4441 1002004(20, 75) 0.4843 1002004(26, 75) 0.6579 1002004(26, 90) 0.8206 1002004(42, 90) 0.4933 100200%P(e)1.57E-143.50E-114.22E-111.07E-241.57E-211.13E-201.25E-092.40E-092.89E-093.88E-197.32E-191.55E-183.47E-083.41E-068.38E-068.65E-292.32E-253.48E-25Grids2, |E| = 1ATB(k = 210 ,h)ATB(k = 212 ,h)LB/UBTimeLB/UBTime0.3127/0.82861 0.3127/0.828610.3127/0.828657 0.3127/0.8286570.3127/0.82861110.1765/0.49395 0.1765/0.493950.1765/0.4939208 0.1765/0.49392030.1765/0.49394120.2106/0.74543 0.2106/0.745430.2106/0.745481 0.2106/0.7454800.2106/0.74541560.0506/0.93386 0.0506/0.933860.0506/0.9338268 0.0506/0.93382700.0506/0.93385340.1858/0.89432 0.1858/0.894320.1858/0.894385 0.1858/0.8943840.1858/0.89431640.0048/0.917510 0.0048/0.9175100.0048/0.9175436 0.0048/0.91754390.0048/0.9175866ATB(k = 214 ,h)MBELB/UBTime LB / UB Time0.3127/0.828610/5.13160.1765/0.49390.2106/0.74540.0506/0.93380.1858/0.89430.0048/0.917550/12411390/1E+05390/1E+10840/1E+10870/1E+1011036210Table 4: Results grid networks. table shows LB UB computed Bvarying number cutset tuples h maximum length k conditionalprobability tables Markov boundary.Grid networks. Table 4 reports results. first thing observecomputes completely uninformative bounds. case, anytime behavior Beffective either. increase value control parameters (h, k) affectaccuracy. Since Markov boundary grid networks relatively small, smallesttested value k higher Markov boundary size explains independencek. Another reason ineffectiveness may high percentage determinismnetworks. known sampling methods inefficient presencedeterminism. consequence, percentage probability mass accumulatedh sampled tuples significant, cancels benefits computing exact probability evidence subset tuples. Therefore, cases sophisticatedsampling scheme used, example (Gogate & Dechter, 2007). Consequently,deterministic grids, Bs performance controlled totally bound propagationplugged-in algorithm.Coding networks. Table 5 shows results. report percentage P (e)covered fully-instantiated cutset tuples exact P (e) available.set time limit V EC 1900 seconds (i.e., maximum computation time requiredrunning B instances). report results k = 210 k = 214increase value k effective result increasedaccuracy. case, accuracy B increases value h increases. comparing B algorithms distinguish lower upperbounds. Regarding lower bounds, B clearly outperforms V EC instances. Indeed, lower bound computed V EC loose. Regarding361fiBidyuk, Dechter & RollonInst.BN 126BN 127BN 128BN 129BN 130BN 131BN 132BN 133BN 134h450150450150450150450150450150450150450150450150450150coding, |E| = 256ATB(k = 210 ,h)ATB(k = 214 ,h)LB/UBTimeLB/UBTime1.9E-76/1.5E-4150 1.9E-76/1.52E-41 34941.9E-69/2.5E-426321.9E-58/1.3E-42 14425.3E-60/2.3E-4355 5.3E-60/2.3E-433991.3E-58/2.3E-444261.6E-58/1.9E-449467.2E-54/1.6E-4285 7.2E-54/1.6E-425824.9E-48/7.2E-436374.9E-48/1.4E-43 12251.4E-72/8.2E-4550 1.5E-72/8.2E-453621.5E-64/2.1E-455858.5E-64/5.4E-46 14004.7E-65/2.9E-4447 4.7E-65/2.9E-443246.3E-63/2.9E-456193.7E-58/2.3E-45 12991.9E-60/1.3E-4452 1.9E-60/1.3E-443672.3E-54/3.7E-454842.3E-54/1.1E-45 12762.3E-79/6.3E-4450 2.3E-79/6.3E-443633.6E-67/1.0E-446891.5E-66/8.1E-45 16271.6E-56/2.7E-4253 1.6E-56/2.7E-423981.1E-54/2.4E-436712.3E-54/9.5E-44 18468.9E-63/1.8E-4347 8.9E-63/1.8E-433551.2E-62/8.6E-456066.1E-57/4.8E-45 1412MBE(z=22)LB/UBTimeVECLBTime1.4E-139/1.5E-044143 9.2E-10219001.6E-134/1.0E-045164 5.3E-11519001.2E-144/5.1E-043124 1.9E-11219002.8E-139/4.8E-043144 1.5E-11519001.1E-132/1.9E-0451121.3E-9619002.3E-141/3.2E-045119 3.2E-10219002.8E-134/2.3E-048109 8.9E-11119001.8E-136/4.1E-045147 1.9E-10919001.9E-148/3.9E-045163 4.2E-1111900Table 5: Results coding networks. table shows LB UB computed Bvarying number cutset tuples h maximum length k conditionalprobability tables Markov boundary.upper bounds, B(h = 150, k = 210 ) outperforms three instances (i.e., BN 128,BN 129 BN 131). taking time account B outperformsinstance BN 129.Summary empirical evaluation. demonstrated Bs bounds convergeh, number cutset tuples computed exactly, increases. speed convergence variedamong benchmarks. convergence faster active cutset tuples accountedlarge percentage probability mass P (C|e), shown case cpcs54,cpcs179, cpcs360 networks. Comparing variant bound propagation calledBdP +, B accurate given sufficient time even given timebound, computed accurate bounds many benchmarks.showed Bs bounds posterior marginals improvedused initial bounds BdP +. call hybrid B followed BdP +BBdP + algorithm. experiments demonstrated added power BBdP +exploiting time-accuracy trade-off.also compared power B bound probability evidencemini-bucket elimination (M BE). showed neither algorithm dominatingbenchmarks. Given amount time, B computed accurate bounds362fiActive Tuples-based Scheme Bounding Posterior Beliefsinstances bn2o coding networks. B outperformedinstances grid networks computed bounds 0 1.benchmark, however, B converged slowly. believe part duegrids large loop-cutset sizes.compared Bs ability compute lower bound P (e) V EC codingnetworks. V EC obtains bound computing partial sum cutset-conditioningformula (see Eq. 2). comparing lower bounds generated B V EC,gain insight trade-off enumerating cutset tuples boundinguninstantiated tuples. Since Bs lower bound consistently tighter, concludebounding uninstantiated tuples cost-effective.5. Related Workthree early approaches use principle B: Pooles algorithm(1996), bounded conditioning (BC) (Horvitz et al., 1989) already described,bounded recursive decomposition (Monti & Cooper, 1996). cases computation bounds composed exact inference subset tuplesbounding scheme total probabilities rest tuples.Similar B, Pooles scheme based partial exploration search tree.However, search tree corresponds state space variables wholenetwork hence, exponential total number variables. contrast, treestructure used approach corresponds state space loop-cutset variables;therefore, exponential loop-cutset size only. addition, Poole updatesbounding function tuple probability 0 (i.e., conflict) discovered.discussed Section 2.2, BC also based cutset conditioning principle,two main differences relative B: (i) probability mass missingtuples bounded via prior probabilities, consequently (ii) proved, upperbound expression looser.Bounded recursive decomposition uses Stochastic simulation (Pearl, 1988) generatehighly probable instantiations variables, similar B, boundsmissing elements 0 prior values. Therefore approach resembles Pooles algorithm bounded conditioning. Unlike B, bounded recursive decomposition requiresinstantiation variables network relies priors guide simulation. contrast, algorithm uses Gibbs sampling cutset likelyaccurate selecting high probability tuples presence evidence. B subsumes three algorithms offering unifying approach bounding posteriors anytimeproperties, able improve bounds investing time exploring cutsettuples.number alternative approaches computing bounds marginals.Poole (1998) proposed context-specific bounds obtained simplifying conditionalprobability tables. method performs variant bucket elimination intermediate tables collapsed grouping probability values together. However, sincemethod validated small car diagnosis network 10 variables, harddraw conclusions. Larkin (2003) also obtains bounds simplifying intermediateprobability tables variable elimination order. solves optimization problem363fiBidyuk, Dechter & Rollonfind table decomposition minimizes error. Kearns Saul (1999, 1998) proposed specialized large deviation bounds approach layered networks, ManninoMookerjee (2002) suggested elaborate bounding scheme nonlinear objectivefunctions. Jaakkola Jordan (1999) proposed variational method computing lowerupper bounds posterior marginals Noisy-Or networks evaluated performance case diagnostic QMR-DT network. recent approaches (Tatikonda,2003; Taga & Mase, 2006; Ihler, 2007; Mooij & Kappen, 2008) aim bound errorbelief propagation marginals. first two approaches exponential sizeMarkov boundary. third approach linear size network, formulatedpairwise interactions only. Finally, fourth algorithm exponential numberdomain values. Recently, Mooij Kappen (2008) proposed box propagation algorithmpropagates local bounds (convex sets probability distributions) subtreefactor graph representing problem, rooted variable interest.important note approach offers anytime framework computingbounds bounding algorithms used subroutine boundjoint probabilities partially-instantiated tuples within B therefore may improveperformance bounding scheme.Regarding algorithms bound probability evidence, already mentionedmini-bucket schemes compared Section 4.3. Another recent approachtree-reweighted belief propagation (T RW -BP ) (Wainwright, Jaakkola, & Willsky, 2005).RW -BP class message-passing algorithms compute upper bound P (e)convex combination tree-structured distributions. recent paper, RollonDechter (2010) compare RW -BP , box propagation (adapted computing probability evidence using chain rule), B-ABdP +. empirical evaluationshows relative strength scheme different benchmarks (Rollon & Dechter,2010). another recent work Wexler Meek (2008) proposed MAS, boundingalgorithm computing probability evidence. Shekhar (2009) describes adjustments required produce bounds using MAS Bayesian networks, potentialsless 1. forthcoming paper, Wexler Meek (2010) improve MAS schemeobtain tighter bounds describe obtain bounds Bayesian networks P (e)well inferential problems maximal posteriori probableexplanation problems. comparison approach left future work.6. Summary Conclusionspaper explores general theme approximation bounding algorithms likelihood computation, task known hard. methods based onetwo principles emerge, clear pooling together variety ideas singleframework yield significant improvement. current paper provides framework. utilizes principle cutset conditioning harnessing varied strengthsdifferent methods. framework inherently anytime, important characteristicapproximation schemes.Cutset conditioning universal principle. allows decomposing problemcollection tractable ones. subproblems solved exactlyothers approximated. scheme controlled several parameters. w364fiActive Tuples-based Scheme Bounding Posterior Beliefscutset condition subset variables treewidth bounded w.subproblem solved exactly time space exponential w. numbersubproblems large, use another parameter, h, control numbersubproblems solved exactly. rest subproblems solved using off-the-shelfbounding scheme.developed expression incorporates aspects using parameters:w - induced-width cutset, h - number cutset conditioning subproblemssolved exactly (e.g., bucket elimination), - approximation algorithmbounds bounded subproblems. showed number subproblemsapproximated polynomial h.empirical evaluation general framework, called B, used loopcutset scheme (w = 1) chose bounding algorithm variant bound propagation(Leisink & Kappen, 2003), yielding integrated scheme call ABdP +. experimented several benchmarks computing posterior marginals probabilityevidence, compared relevant state art algorithms.results demonstrate value B framework across benchmarkstried. expected, anytime aspect visible showing improved accuracyfunction time. significantly, even provided equal time spaceresources, B showed remarkable superiority compared variant boundpropagation mini-bucket elimination algorithm (M BE) (Dechter & Rish,2003). latter recently investigated Rollon Dechter (2010).Overall, conclude B competitive algorithm bounding posterior marginals probability evidence. Generally, expect B perform wellnetworks whose cutset C small relative total number variables whosedistribution P (C|e) small number high probability tuples.possibilities future work many. explore additional trade offsincreasing w therefore decreasing h improving selection h tuples.looked one possible instantiation plug-in algorithm A. approximationalgorithms tried may offer different time/accuracy trade-offs. particular,plan investigate effectiveness B using plug-in algorithm.Acknowledgmentswork supported part NSF award numbers IIS-0331707, IIS-0412854IIS-0713118 NIH grant R01-HG004175-02.Emma Rollons work done postdoctoral student Bren SchoolInformation Computer Sciences, University California, Irvine.work presented part (Bidyuk & Dechter, 2006a, 2006b).Appendix A. Analysis Bounded ConditioningTheorem 2.1 interval lower upper bounds computed boundedconditioning lower bounded probability massprior distribution P (C)PMU (x|e) P L (x|e)unexplored cutset tuples: h, PBCi=h+1 P (c ).BC365fiBidyuk, Dechter & RollonProof.UPBC(x|e)LPBC(x|e)=+=PMPMi=1 P (c , e) +i=h+1 P (c ))Phi=1 P (c , e)PhPhi=1 P (x, c , e)i=1 P (x, c , e)PhPhPi=1 P (c , e)i=1 P (c , e) +i=h+1 P (c )PPPMhi=h+1 P (c ))i=h+1 P (c )( i=1 P (c , e) +Phi=1 P (c , e)P2XX(i=h+1 P (c ))P (c ) + PhP (ci ), e)P(ci=1i=h+1i=h+1i=h+1 P (c)(PhAppendix B. Bounding Posteriors Cutset Nodesfar, considered computation posterior marginals variable X X \(CE). focus computing bounds cutset node Ck C. Let c0k D(C)value domain Ck . Then, compute exact posterior marginal P (ck |e) using Bayesformula:PMP (c0k , e)(c0 , ci )P (ci , e)0P (ck |e) =(23)= i=1PM k, e)P (e)P(ci=1(c0k , ci ) Dirac delta-function (c0k , ci ) = 1 iff cik = c0k (c0k , ci ) = 0otherwise. simplify notation, let Z = C\Z. Let Mk denote number tuplesstate-space Z. re-write numerator as:X(c0k , ci )P (ci , e)=i=1MkXP (c0k , z , e)i=1denominator decomposed as:XP (ci , e) =i=1XMkXP (c0k , z , e)ck D(Ck ) i=1Then, re-write expression P (c0k |e) follows:PM k00i=1 P (ck , z , e)P (ck |e) = PPM kck D(Ck )i=1 P (ck , z , e)(24)Let hck number full cutset tuples cik = ck . Then, decomposenumerator Eq. (24) follows:MkXi=1hc0P (c0k , z , e)=kXP (c0k , z , e)+MkXi=hc0 +1i=1k366P (c0k , z , e)fiActive Tuples-based Scheme Bounding Posterior BeliefsSimilarly, decompose sums denominator:XMkXP (ck , z , e) =ck D(Ck ) i=1hckXXP (ck , z , e) +XMkXP (ck , z , e)ck D(Ck ) i=hck +1ck D(Ck ) i=1decomposition, Eq. (24) takes form:P (c0k |e)Phc0k0i=1 P (ck , z , e)=Pck D(Ck )Phcki=1 P (ck , z, e)++P Mk0i=hc0 +1 P (ck , z , e)Pkck D(Ck )P Mki=hck +1 P (ck , z, e)(25)Now, conciseness, group together fully instantiated tuples denominator:hckXXP (ck , z , e) =hXP (ci , e)i=1ck D(Ck ) i=1Then, Eq. (25) transforms into:P (c0k |e)Phc0k0i=1 P (ck , z , e)= Phi=1Now, replace sumP (ci , e)PM k+i=hc0 +1+PM kP Mki=hck +10i=hc0 +1 P (ck , z , e)Pkck D(Ck ) P (ck , z , e)(26)unexplored cutset tuples sumkpartially-instantiated cutset tuples. Denoting Mc0k = Mk hck + 1 numberpartially instantiated cutset tuples Ck = ck , obtain:0PMc0kj0 , z , e) +0P(ci=1j=1 P (ck , z1:qj , e)kP (c0k |e) = PPMc0k Pjhck D(Ck ) P (ck , z1:qj , e)i=1 P (c , e) +j=1Phc0k(27)order obtain lower upper bounds formulation, separate sum jointj, e) Ck = c0k rest:probabilities P (c0k , z1:qjP (c0k |e) =Phi=1 P (c, e)0PMc0kj00i=1 P (ck , z , e) +j=1 P (ck , z1:qj , e)0PMc0PMc0 Pjj, e)+ j=1k P (c0k , z1:q, e) + j=1k ck 6=c0 P (ck , z1:qjjkPhc0k(28)expression above, probabilities P (ck , z , e) P (ci , e) computed exactly since, e), however,correspond full cutset instantiations. Probabilities P (ck , z1:qbounded since partial cutset observed. Observing numerator, e) replacing upper bounddenominator component P (c0k , z1:q, e) numerator denominator, obtain upper boundP U (c0k , z1:qP (c0k |e) due Lemma 3.2:P (c0k |e)Phi=1P (ci , e)0PMc0k U 0 j0i=1 P (ck , z , e) +j=1 PA (ck , z1:qj , e)0P c0PMc0 Pjj, e)+ j=1k PAU (c0k , z1:q, e) + j=1k ck 6=c0 P (ck , z1:qjjkPhc0k367(29)fiBidyuk, Dechter & RollonjFinally, replacing P (ck , z1:q, e), ck 6= c0k , lower bound (also increasing fraction value),jobtain:Phc0kPMc0k0i=1 P (ck , z , e) +j=1PMc0k U 0 jj=1 PA (ck , z1:qj , e) +j, e)PAU (c0k , z1:qj= PcUP0 PPckjhLck 6=c0k PA (ck , z1:qj , e)i=1 P (c , e) +j=1(30), e)lower bound derivation similar. start Eq. (28) replace P (c0k , z1:qnumerator denominator lower bound. Lemma 3.2 guaranteesresulting fraction lower bound P (c0k |e):P (c0k |e)P (c0k |e)Phi=1P (ci , e)0PMc0k L 0 j0i=1 P (ck , z , e) +j=1 PA (ck , z1:qj , e)0P c0PMc0k Pjj+ j=1k PAL (c0k , z1:q,e)+ck 6=c0k P (ck , z1:qj , e)j=1jPhc0k(31)Pjj, e)Finally, grouping PAL (c0k , z1:qck 6=c0k P (ck , z1:qj , e) one sum replacingjPjjPAL (c0k , z1:q, e) upper bound, obtain lower bound PcL :, e) + ck 6=c0 P (ck , z1:qjjkP (c0k |e)00i=1 P (ck , z , e) +Phi=1Phc0kj, e)U B[PAL (c0k , z1:qjP (ci , e)+X+0PMc0kPMc0kj=1j, e)PAL (c0k , z1:qjjL 0j=1 U B[PA (ck , z1:qj , e)j, e)]P (ck , z1:qj= minck 6=c0k(+P= PcL(32)jck 6=c0k P (ck , z1:qj , e)]j, e) +PAL (c0k , z1:qjj, e)PAU (z1:qjPck 6=c0kj, e)PAU (ck , z1:qjlower bound PcL cutset equivalent lower bound P L obtained Eq. (15).respect computing bounds P (c0k , z1:q , e) Eq. (30) (32) practice,distinguish two cases. demonstrate example upper bound.first case, partially instantiatedtuple c1:q includes node Ck , namelyk q, decomposed c1:q = z1:q c0k that:P U (c0k , z1:q , e) = P U (c1:q , e)second case concerns partially instantiated tuples c1:q include nodeCk , namely k > q. case, compute upper bound decomposing:P U (c0k , z1:q , e) = P U (ck |c1:q )P U (c1:q , e)Appendix C. ATB PropertiesTheorem 3.2 B bounds interval length upper bounded monotonic nonincreasing function h:PMjj=h+1 P (c )ULPA (x|e) PA (x|e) Ph, IhPji=1 P (c , e) +j=h+1 P (c )368fiActive Tuples-based Scheme Bounding Posterior BeliefsProof. upper bound bounds interval follows fact that, PAU (x|e)U (x|e) P L (x|e) definitions brute force lower PBFBFper bounds given Eq. (21) (22). need prove upper boundmonotonously non-increasing function h.PPMjjP (ch ) +j=h+1 P (c )j=h P (c )=Ih1 = Ph1PPPh1jjhj=h P (c )j=h+1 P (c )i=1 P (c , e) +i=1 P (c , e) + P (c ) +PAL (x|e)Since P (ch ) P (ch , e), replacing P (ch ) P (ch , e) applying Lemma 3.1, yields:PPjjP (ch , e) +P (ch , e) +j=h+1 P (c )j=h+1 P (c )Ih1 Ph1= PhPMPMhjji=1 P (c , e) + P (c , e) +j=h+1 P (c )i=1 P (c , e) +j=h+1 P (c )PMjj=h+1 P (c )Ph= IhPji=1 P (c , e) +j=h+1 P (c )Thus, Ih1 Ih .ReferencesAbdelbar, A. M., & Hedetniemi, S. M. (1998). Approximating MAPs belief networksNP-hard theorems. Artificial Intelligence, 102, 2138.Andreassen, S., Jensen, F., Andersen, S., Falck, B., Kjaerulff, U., Woldbye, M., Srensen, A.,Rosenfalck, A., & Jensen, F. (1990). Munin - expert EMG assistant. Desmedt,J. E. (Ed.), Computer-Aided Electromyography Expert Systems, chap. 21. ElsevierScience Publishers, Amsterdam.Becker, A., & Geiger, D. (1996). sufficiently fast algorithm finding close optimaljunction trees. Proceedings 12th Conference Uncertainty ArtificialIntelligence (UAI-96), pp. 8189, Portland, Oregon, USA. Morgan Kaufmann.Beinlich, I., Suermondt, G., Chavez, R., & Cooper, G. (1989). ALARM monitoringsystem: case study two probabilistic inference techniques belief networks.Proceedings Second European Conference AI Medicine. SpringerVerlag.Bidyuk, B. (2006). Exploiting Graph Cutsets Sampling-Based ApproximationsBayesian Networks. Ph.D. Thesis. Ph.D. thesis, University California, Irvine.Bidyuk, B., & Dechter, R. (2003a). Cycle-cutset sampling Bayesian networks. Proceedings 16th Canadian Conference Artificial Intelligence (AI2006), pp.297312, Halifax, Canada.Bidyuk, B., & Dechter, R. (2003b). Empirical study w-cutset sampling Bayesian networks. Proceedings 19th Conference Uncertainty Artificial Intelligence(UAI-2003), pp. 3746, Acapulco, Mexico. Morgan Kaufmann.Bidyuk, B., & Dechter, R. (2006a). anytime scheme bounding posterior beliefs.Proceedings 21st National Conference Artificial Intelligence (AAAI2006),pp. 10951100, Boston, MA, USA.369fiBidyuk, Dechter & RollonBidyuk, B., & Dechter, R. (2006b). Improving bound propagation. Proceedings17th European Conference AI (ECAI2006), pp. 342346, Riva Del Garda, Italy.Bidyuk, B., & Dechter, R. (2007). Cutset sampling bayesian networks. JournalArtificial Intelligence Research, 28, 148.Cooper, G. (1990). computational complexity probabilistic inferences. ArtificialIntelligence, 42, 393405.Dagum, P., & Luby, M. (1993). Approximating probabilistic inference Bayesian beliefnetworks NP-hard. Artificial Intelligence, 60 (1), 141153.Dechter, R. (1999). Bucket elimination: unifying framework reasoning. ArtificialIntelligence, 113, 4185.Dechter, R., & Rish, I. (2003). Mini-buckets: general scheme bounded inference.Journal ACM, 50, 107153.Gogate, V., & Dechter, R. (2007). Samplesearch: scheme searches consistentsamples. Proceedings 11th International Conference Artificial IntelligenceStatistics (AISTATS2007), pp. 198203.Horvitz, E., Suermondt, H., & Cooper, G. (1989). Bounded conditioning: Flexible inference decisions scarce resources. Workshop Uncertainty ArtificialIntelligence, pp. 181193, Windsor, ON.Ihler, A. (2007). Accuracy bounds belief propagation. Proceedings 23rd Conference Uncertainty Artificial Intelligence (UAI-2007), pp. 183190, Corvallis,Oregon. AUAI Press.Jaakkola, T. S., & Jordan, M. I. (1999). Variational probabilistic inference qmr-dtnetwork. Journal Artificial Intelligence Research, 10, 291322.Kask, K., & Dechter, R. (1999). Stochastic local search Bayesian networks. Heckerman, D., & Whittaker, J. (Eds.), Workshop AI Statistics, pp. 113122. MorganKaufmann.Kearns, M., & Saul, L. (1998). Large deviation methods approximate probabilistic inference, rates convergence. Proceedings 14th Conference UncertaintyArtificial Intelligence (UAI), pp. 311319. Morgan Kaufmann.Kearns, M., & Saul, L. (1999). Inference multilayer networks via large deviation bounds.Advances Neural Information Processing Systems, 11, 260266.Kristensen, K., & Rasmussen, I. (2002). use Bayesian network designdecision support system growing malting Barley without use pesticides.Computers Electronics Agriculture, 33, 197217.Larkin, D. (2003). Approximate decomposition: method bounding estimatingprobabilistic deterministic queries. Proceedings 19th ConferenceUncertainty Artificial Intelligence (UAI-2003), pp. 346353, Acapulco, Mexico.Leisink, M. A. R., & Kappen, H. J. (2003). Bound propagation. Journal ArtificialIntelligence Research, 19, 139154.370fiActive Tuples-based Scheme Bounding Posterior BeliefsMannino, M. V., & Mookerjee, V. S. (2002). Probability bounds goal directed queriesBayesian networks. IEEE Transactions Knowledge Data Engineering, 14 (5),11961200.Monti, S., & Cooper, G. (1996). Bounded recursive decomposition: search-based methodbelief network inference limited resources. International Journal Approximate Reasoning, 15, 4975.Mooij, J. M., & Kappen, H. J. (2008). Bounds marginal probability distributions.Advances Neural Information Processing Systems 22 (NIPS2008), pp. 11051112,Vancouver, British Columbia, Canada, December 8-11.Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems. Morgan Kaufmann.Poole, D. (1996). Probabilistic conflicts search algorithm estimating posteriorprobabilities Bayesian networks. Artificial Intelligence, 88 (12), 69100.Poole, D. (1998). Context-specific approximation probabilistic inference. Proceedings14th Uncertainty Artificial Intelligence (UAI-98), pp. 447454.Pradhan, M., Provan, G., Middleton, B., & Henrion, M. (1994). Knowledge engineeringlarge belief networks. Proceedings 10th Conference Uncertainty ArtificialIntelligence, Seattle, WA, pp. 484490.Rollon, E., & Dechter, R. (2010). New mini-bucket partitioning heuristics boundingprobability evidence. Proceedings 24th National Conference ArtificialIntelligence (AAAI2010), pp. 11991204, Atlanta, GA.Roth, D. (1996). hardness approximate reasoning. Artificial Intelligence, 82 (1-2),273302.Shekhar, S. (2009). Fixing extending multiplicative approximation scheme. Mastersthesis, School Information Computer Science, University California, Irvine.Taga, N., & Mase, S. (2006). Error bounds marginal probabilities beliefsloopy belief propagation algorithm. Advances Artificial Intelligence, Proceedings5th Mexican International Conference Artificial Intelligence (MICAI2006), pp.186196, Apizaco, Mexico, November 13-17.Tatikonda, S. C. (2003). Convergence sum-product algorithm. ProceedingsIEEE Information Theory Workshop, pp. 222225.Wainwright, M. J., Jaakkola, T., & Willsky, A. S. (2005). new class upper boundslog partition function. IEEE Trans. Information Theory, 51 (7), 23132335.Wexler, Y., & Meek, C. (2008). MAS: multiplicative approximation scheme probabilistic inference. Koller, D., Schuurmans, D., Bengio, Y., & Bottou, L. (Eds.),Advances Neural Information Processing Systems 22 (NIPS2008), pp. 17611768.MIT Press.Wexler, Y., & Meek, C. (2010). Approximating max-sum-product problems using multiplicative error bounds. Bayesian Statistics 9, p. appear. Oxford UniversityPress.371fiJournal Artificial Intelligence Research 39 (2010) 179- 216Submitted 04/10; published 09/10Cooperative Games Overlapping CoalitionsGeorgios ChalkiadakisGC 2@ ECS . SOTON . AC . UKSchool Electronics Computer Science,University Southampton, SO17 1BJ, UKEdith ElkindEELKIND @ NTU . EDU . SGSchool Physical Mathematical Sciences,Nanyang Technological University, 637371, SingaporeEvangelos MarkakisMARKAKIS @ GMAIL . COMDepartment Infomatics,Athens University Economics Business, GR10434, GreeceMaria PolukarovNicholas R. JenningsMP 3@ ECS . SOTON . AC . UKNRJ @ ECS . SOTON . AC . UKSchool Electronics Computer Science,University Southampton, SO17 1BJ, UKAbstractusual models cooperative game theory, outcome coalition formation processeither grand coalition coalition structure consists disjoint coalitions. However,many domains coalitions associated tasks, agent may involved executingone task, thus may distribute resources among several coalitions. tacklescenarios, introduce model cooperative games overlapping coalitionsor overlapping coalition formation (OCF) games. explore issue stability setting.particular, introduce notion core, generalizes corresponding notiontraditional (non-overlapping) scenario. Then, quite general conditions, characterizeelements core, show element core maximizes social welfare.also introduce concept balancedness overlapping coalitional games, use characterize coalition structures extended elements core. Finally, generalizenotion convexity setting, show natural assumptions convex gamesnon-empty core. Moreover, introduce two alternative notions stability OCFallow wider range deviations, explore relationships among corresponding definitions core, well classic (non-overlapping) core Aubin core. illustrategeneral properties three cores, also study computational perspective, thusobtaining additional insights fundamental structure.1. IntroductionCoalition formation, widely studied game theory economics (Myerson, 1991), attractedmuch attention AI means forming teams autonomous selfish agents need cooperateperform certain tasks (Sandholm & Lesser, 1997; Shehory & Kraus, 1998; Sandholm, Larson,Andersson, Shehory, & Tohme, 1999; Manisterski, Sarne, & Kraus, 2008; Rahwan, Ramchurn,Jennings, & Giovannucci, 2009). Traditionally, game theory literature assumedoutcome coalition formation process either grand coalition (i.e., set agents),coalition structure consists disjoint coalitions (i.e., partition set agents).natural settings, many scenarios interest assumption applicable.c2010AI Access Foundation. rights reserved.fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGSSpecifically, often natural associate coalitions tasks performed agents.situations, agents may involved several tasks, therefore may need distributeresources among coalitions participate. Indeed, overlaps maynecessary obtain good outcome, natural plethora interesting applications.simple e-commerce example, consider online trading agents representing individuals virtualenterprises, facing challenge allocating owners capital variety projects(i.e., coalitions) simultaneously. many examples settings agent (besoftware entity human) splits resources (such processing power, time money)among several tasks. tasks, turn, may require participation one agent:computation may run several servers, software project usually involves one engineer,start-up may rely several investors. Thus, task corresponds coalition agents,agents contributions coalitions may fractional, and, moreover, agents participateseveral tasks once, resulting coalition structures overlapping coalitions. formationoverlapping coalitions particularly prevalent systems demanding multiagent multirobotcoordination, computational grid networks, sensor networkssee, e.g., work Patel etal. (2005), Dang, Dash, Rogers, & Jennings (2006). date, however, essentiallytheoretical treatment topic, exceptions (which discuss Section 3).background, goal paper introduce study model explicitlytakes overlapping coalition formation (OCF) account. model applicable situationsagents need allocate different parts resources simultaneously serve differenttasks members different coalitions. Besides allowing overlapping coalitions, departsconventional coalition formation framework two important aspects. First,inherent superadditivity assumption work, hence grand coalition alwaysemerge. Thus, subsequent definition core incorporates coalition structures. Second, exactly interested outcomes grand coalition formation,use standard transferable utility (TU) framework, agents make arbitrary paymentsother. Instead, following seminal paper Aumann Dreze (1974), allow arbitrarymonetary transfers within coalitions, cross-coalitional transfers. is, agent contributing coalition expect receive payoff it. Indeed, argued AumannDreze, inability agents work together share payoffs may oneprimary reasons grand coalition form, particular coalition structure arises.Finally, model take task (coalitional action) execution explicitly account; facilitatespossible extensions tackle coalition formation uncertainty.1Apart defining model overlapping coalition formation, main contributionwork exploring stability concept core OCF setting. suggest three differentnotions core, depending nature deviations allowed, since, shall see,range permissible deviations overlapping setting much richer traditionalnon-overlapping one. specifically, definition stability depends whether deviatorreduced contribution somebut allcoalitions, expects get payoffcoalitions abandon completely.provide intuition, consider example two construction companies, 1 2,currently partners (not necessarily partners) working construction projects (building university campus) B (building hospital). Assume partner 1 stakes1. simplify notation, show incorporate coalitional actions model Section 10.180fiC OOPERATIVE G AMES OVERLAPPING C OALITIONSproject B, expecting extract great value, contributed 75% available resources, contributing remaining 25% A; partner 2 contributes resources (say67%) project remaining fraction (say 33%) B. Thus, currently participate twooverlapping coalitions, one performing different task. Now, partner 2 feels unhappycurrent payoff division arrangement, might consider abandoning project (by cancellingproject project leader, taking advantage contractual exit clause) ordercommit resources profitable 2 project (say C). However, so, might hurtproject chances completion. mean 2s actions trigger spite company1, might use available means kick 2 project B? company 2 lowereddegree participation instead withdrawing completely? much profitscompleting would 2 entitled to? different answers one provide questions correspond different notions profitable deviations, and, therefore, different notionscore-stability. particular, demonstrate core notions put forward papersubstantially different respect sets outcomes characterize.main technical results involve c-core, first core concept suggest. Amongthree concepts core introduced paper, c-core closest standard definitioncore general non-transferable utility (NTU) games. particular, provide conditionsexistence c-core follows. quite general assumptions, first providecharacterization outcomes, i.e., pairs form (overlapping coalition structure, imputation),c-core. proof based graph-theoretic argument, may independentinterest. corollary result, show outcome c-core maximizes socialwelfare. Second, characterize coalition structures admit payoff allocationsresulting outcome c-core. done generalizing Bondareva-Shapley theoremsetting (note theorem hold arbitrary non-transferable utility games).Furthermore, extend notion convexity coalitional games overlapping coalitions,show mild assumptions convex OCF game non-empty c-core.discuss properties three versions OCF-core suggest, relateclassic core. also demonstrate model core concepts differ fuzzy coalitional games (Aubin, 1981); though relevant model, workfundamentally different. addition, initiate study computational aspects stabilityoverlapping setting. Note computational analysis coalitional games, even nonoverlapping scenarios, hindered fact that, general, coalitional games possesscompact representation, one may list value every possible coalition. Thus, existing work algorithmic aspects coalitional games focused game representations either incompletesuch as, e.g., weighted voting games (Elkind, Goldberg, Goldberg, & Wooldridge,2009), induced subgraph games (Deng & Papadimitriou, 1994), network flow games (Bachrach& Rosenschein, 2007)or guaranteed succinct specific subclasses games,MC-nets (Ieong & Shoham, 2005) coalitional skill games (Bachrach & Rosenschein, 2008);another approach show complexity bounds games representable polynomial-sizedcircuits (Greco, Malizia, Palopoli, & Scarcello, 2009). issue even severe OCFsetting, specify value every partial coalition. Therefore, paper,follow first approaches, introduce formalism threshold task gamescapable describing large family overlapping coalition formation settings succinct manner. Within formalism, obtain negative positive results regarding complexity181fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGSdeciding questions membership non-emptiness OCF-core concepts. concludedescribing natural extensions model suggesting directions future work.22. Preliminariessection, provide brief overview basic concepts cooperative game theory regarding non-overlapping coalition structures. begin, let N = {1, . . . , n} set players (oragents). subset N called coalition. coalition structure (CS ) non-overlappingenvironments partition set agents.assumption transferable utility, coalition formation abstracted fairlysimple model. assumption postulates existence (divisible) commodity (e.g., money)freely transferred among players. role characteristic function coalitionalgame transferable utility (TU-game) specify single number denoting worthcoalition. Formally, characteristic function v : 2N 7 R defines value v(S) coalition(von Neumann & Morgenstern, 1944). transferable utility game G completely specifiedset players N characteristic function v; therefore write G = (N, v).characteristic function describes payoffs available coalitions, prescribe way distributing payoffs. captured notion imputation, definedfollows. say allocation vector payoffs x = (x1 , . . . , xn ) assigningPsome payoffj N . allocation x efficient respect coalition structure CS jS xj = v(S)CS ; called imputation efficient satisfies individual rationality, i.e.,xj v({j}) j = 1, . . . , n. set imputations CS denoted I(CS ).Now, rational agents seek maximize individual payoffs, stability underlying coalition structure becomes critical, agents might tempted abandon agreementspursuit gains themselves. structure stable outcomes attainedcoalitions payoff combinations agreed agents satisfy individual grouprationality. Given requirement, research coalition formation developed several notionsstability, among strongest well-studied ones core (Gillies, 1953). Takingcoalition structures account, core TU game set outcomes (CS , x), x I(CS ),subgroup agents motivated depart coalitions CS .Definition 1. Let CS coalition structure, let x Rn allocation payoffsagents. core TUPgame (N, v) set pairs (CS , x) x I(CS )N holds jS xj v(S).Hence, coalition would ever block proposal core allocation. well-knowncore strong notion, exist many games empty (Myerson, 1991).core definition essentially definition provided Sandholm Lesser (1997)(and also similar one given Dieckmann & Schwalbe, 1998). assume superadditivity characteristic function (i.e., v(U ) v(U ) + v(T ) disjoint coalitions U) definition may consider outcomes CS simply grand2. Parts work, namely model statement results, appeared preliminaryconference paper (Chalkiadakis, Elkind, Markakis, & Jennings, 2008). However, (a) introduction alternativenotions core related results presented entirely novel; (b) similarly, complexity-relatedresults entirely novel; (c) discussion properties cores in-depth comparisonfuzzy coalitional games appear first time well.182fiC OOPERATIVE G AMES OVERLAPPING C OALITIONSPcoalition jN xj = v(N ). core definition becomes traditional definitionused vast majority economics literature (Osborne & Rubinstein, 1994).environments interest work however mainly non-superadditivemake assumption characteristic function. Indeed, plethora realisticapplication scenarios emergence grand coalition either guaranteed, mightperceivably harmful, plainly impossible (Sandholm & Lesser, 1997; Sandholm et al., 1999).addition motivations, Aumann Dreze (1974) also provide thorough insightfuldiscussion coalition structures arise: put forward series argumentsmight happen, explain coalition structures may emerge naturally even superadditiveenvironments variety reasons. Briefly, arguments describe subset agentsmight find worthwhile bargain within framework specific structure, withinframework grand coalition; emergence coalition structure may reflectconsiderations necessity excluded formal description gameimpossible measure communicate. Exogenous arguments emergence coalitionstructures naturally include impossibility communication among negotiators, lawprohibition grand coalition (Aumann & Dreze, 1974).3. Related Workwork relevant research fuzzy coalitional games, introducedAubin (1981). Branzei, Dimitrov, & Tijs (2005) also provide detailed exposition games.player fuzzy game participate coalition various levels, value coalitiondepends participation levels agents S. Given model, Aubin definescore fuzzy games (also referred Aubin core). Though model also allows partialparticipation coalition, several crucial differences fuzzy games OCFgames, corresponding notions stability. postpone listing presentingmodel results, Section 8.2. now, let us point that, distinctionwork, formation coalition structures (overlapping not) addressed fuzzygames literature.Apart fuzzy games, little work exists overlapping coalition formation settings.discuss notable exceptions, well related work core contextnon-overlapping coalition structures.begin, Shehory Kraus (1996) present setting overlapping coalition formation.model, agents goals capabilitiesi.e., abilities execute certain actions.serve goals, agents participate coalitions, contributecapabilities, thus thought resources. authors propose heuristicalgorithms lead creation overlapping coalition structures. However, authors stopshort addressing question stability overlapping coalitions. Dang et al. (2006) alsoexamine heuristic algorithms overlapping coalition formation used surveillance multisensor networks. However, work deal payoff allocation issues,view overlapping coalition formation problem game-theoretic perspective.Conconi Perroni (2001) present model international multidimensional policy coordination non-cooperative setting: agreement structures countries overlapping,namely country may participate multiple agreements, contributing number proposedelementary strategies (which regarded chosen discrete sets resources).183fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGSintroduce equilibrium concept describe stability setting. However, contrast work, setting work Conconi Perroni non-cooperative,apply agents continuous resources.recently, Albizuri, Aurrecoechea, & Zarzuelo (2006) presented extension Owensvalue (1977)which, turn, thought generalization Shapley value (1953)tooverlapping coalition formation setting. Specifically, present axiomatic characterizationconfiguration value. However, work Albizuri et al. exists notionresources agent needs distribute across coalitions.regard non-overlapping coalition structures presented Section 2, SandholmLesser (1997) examine problem allocating computational resources coalitions.restrict superadditive settings, discuss stability coalition structures instead.particular, introduce notion bounded rational core explicitly takes account coalition structures. Apt & Radzik (2006) Apt & Witzel (2009) also restraincoalition formation problems outcome grand coalition only. Instead, introducevarious stability notions abstract games whose outcomes coalition structures, discusssimple transformations (e.g., split merge rules) stable partitions set playersmay emerge. However, none papers considers extensions overlapping coalitions.4. Modelsection extend traditional model Section 2 cooperative games overlappingcoalitions. scenarios interest, even overlapping coalitions allowed, agent wouldable participate possible coalitions due lack time, cash flow, energy. modelthis, assume agent possesses certain amount resources distributeamong coalitions joins. Without loss generality, make normalization assumeagent one unit resource: agents contribution coalition thus givenfraction resources allocates it. also think agents participationlevel, fraction time devotes coalition. course, agent may several typesresources (e.g., time money), contribution coalition would describedvector rather scalar. model, results, extend generalsetting straightforward manner. Nevertheless, conciseness, restrict presentationsingle-resource setting.discussed above, non-overlapping model coalition subset agents, gamedefined characteristic function v : 2N 7 R, representing maximum total payoffcoalition get. setting, partial coalition given vector r = (r1 , . . . , rn ),rj fraction agent js resources contributed coalition (rj = 0 means jmember coalition). support partial coalition r denoted supp(r) definedsupp(r) = {j N | rj 6= 0}. define cooperative games overlappingcoalitions, overlapping coalition formation games (OCF-games short),considering rest work.Definition 2. OCF-game G player set N = {1, . . . , n} given function v : [0, 1]nR, v(0n ) = 0.Function v maps partial coalition r corresponding payoff. denote gameG = (N, v), or, N clear context, simply v. Clearly, classic coalition N184fiC OOPERATIVE G AMES OVERLAPPING C OALITIONSrepresented vector eS , (eS )j = 1 j 0 otherwise.economics literature, sometimes called crisp coalitions, whereas coalitions form(r1 , . . . , rn ) least one rj (0, 1) referred fuzzy coalitions (Branzei et al., 2005).avoid latter term work cause confusion fuzzy games, referinstead coalitions kind partial coalitions, simply coalitions.scenarios interest, v monotone, i.e., satisfies v(r) v(r ) r, rrj rj j = 1, . . . , n. Note v monotone, v(r) 0 r [0, 1]n , sinceset v(0, . . . , 0) = 0. discussion stability overlapping coalitions, assumev monotone.need specify possible outcomes OCF-game. non-overlapping setting,outcome pair (CS , x), CS partition N x imputation CS .extend definition scenario, start introducing notion coalition structureoverlapping coalitions. mostly interested coalition structures N ,definition given coalition structures arbitrary subset N ,useful defining maximum profit subset agents achieve (see definitionfunction v below).Definition 3. set agents N , coalition structure finite list vectors(partial coalitions) CS TP= (r 1 , . . . , r k ) satisfies (i) r [0, 1]n ; (ii) supp(r )= 1, . . . , k; (iii) ki=1 rji 1 j . refer k size coalitionstructure CS write |CS | = k. Also, CS denotes set coalition structures .definition above, r = (r1i , r2i , . . . , rni ) corresponds partial coalition (rjifraction resources agent j contributes r ). constraints state everyagent distributes one unit resources among various coalitions participates (those may include singleton coalition). allows coalitions overlapping. Notecoalition structure list rather set, i.e., contain two identical partialcoalitions. Observealso agent required allocate resources, i.e.,Pcase ki=1 rji < 1. However, monotonicity, assume agent jPki=1 rji = 1 (i.e., coalition structure fractional partition agents).would like remark one could conceive models also allow agents formoverlapping coalitions. example, instead requiring agents distribute one unitresources among partial coalitions, could constraints number (crisp) coalitionsagent could take part in. believe model flexible enough represent widerange realisitc scenarios, focus throughout work, Section 10, discussseveral extensions model.introduction overlapping coalition structures imposes new technical challenges.instance, non-overlapping setting number different coalition structuresfinite, setting infinitely many different partial coalitions, hence infinitelymany coalition structures. implies impossible find social welfare-maximizingcoalition structure enumerating candidate solutionsin fact, maximum may evenattained. contrast, non-OCF setting approach possiblethough, general,P infeasible.extend definition v coalition structures setting v(CS ) =r CS v(r).Furthermore, N define v (S) = supCS CS v(CS ). Intuitively, v (S)least upper bound value members achieve forming coalition structure;interested reader, note corresponds characteristic function games185fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGSsuperadditive cover (Aumann & Dreze, 1974). Clearly, v (S) may exceed value coalitionitself, i.e., v(eS ), since may profitable players form several overlappingcoalitions S. say v bounded v (N ) < ; games interest, v likelybounded.setting agents necessarily form grand coalition, interestedreasoning coalition structures CS N . coalition structure impose restrictionsadmissible ways distributing gains; payoff vector corresponds imputationobtained distributing value coalition:Definition 4. Given coalition structure CS CS N , |CS | = k, imputation CS k-tuplex = (x1 , . . . , xk ), xi Rn = 1, . . . , k,P(Payoff Distribution) every partial coalition r CS nj=1 xij = v(r ) rji =0 implies xij = 0;(Individual Rationality)total payoff agent j least large achievePkown: i=1 xj v ({j}).set imputations CS denoted I(CS ). Notice Definition 4, profittask assigned partial coalition distributed among agents involved executing it.Thus, transfers payoff allowed outsiders. Note also individual rationalityconstraint defined terms v rather v, even single agent may profitablesplit several partial coalitions (e.g., many tasks, requires smallfraction resources).Now, set outcomes interest us set feasible agreements:Definition 5. feasible agreement (or outcome) set agents J N tuple (CS , x)CS CS J , |CS | = k k N, x = (x1 , . . . , xk ) I(CS ). denote setfeasible agreements J F(J).Ppayoff pj agent j feasible agreement (CS , x) pj (CS , x) = ki=1 xij .write p(CS , x) denote vector (p1 (CS , x), . . . , pn (CS , x)). Finally, note straightforward extend definitions games subsets agents. particular, requireimputation x I(CS J ) satisfies xij = 0 j 6 J.Given model, ready define concept core cooperative gamesoverlapping coalitions.5. Core Overlapping Coalitionssection, investigate several approaches defining stability OCF-games. Specifically,propose analyze three alternative definitions core.presenting core definitions, define new class games, usingrunning example, namely class threshold task games (TTGs). TTGs form simple,expressive class coalitional games, used model collaboration multi-agentsystems. TTGs agents pool resources order accomplish tasks, idea agents contributing resources one task thus participating several coalitions simultaneouslyextremely natural context. Thus, due simplicity, TTGs provide convenientvehicle study core-stability overlapping setting, usingpurpose throughout rest paper (though work limited class games).186fiC OOPERATIVE G AMES OVERLAPPING C OALITIONS5.1 Threshold Task GamesThreshold task games defined follows.Definition 6. threshold task game G = (N ; w; t) given by:set agents N = {1, . . . , n};vector w = (w1 , . . . , wn ) R+ agents weights;list = (t1 , . . . , tm ) task types, task type tj described thresholdj 0 utility uj 0; write tj = (T j , uj ).Intuitively, games describe scenarios agents split teams work tasks.one type resource (e.g., time money) needed tasks, agentcertain amount resource corresponds weight wi (we chose term weightavoid confusion use term resource context OCF-games).types tasks, described resource requirement j utility uj . teamagents works tj total weight least j , means sufficient resourcescomplete task, obtains full value task uj . Otherwise, payoff task0. assume infinitely many tasks type, one team agents chooseswork tj , prevent another team choosing tj well. follows,assume list monotone, i.e., satisfies 1 < . . . < u1 < . . . < um . Indeed,two task types ti , tj j , ui uj , safely assume teamagents choose work tj , hence tj deleted t. Hence, monotonicityassumption made without loss generality.description suggests interpret TTG G = (N, w, t) (non-overlapping)coalitional game G = (N, v), N setv(S) = max{0, max{uj | w(S) j }}(note use standard convention max = ). games provide direct generalization weighted voting games (WVGs) coalition structures introduced Elkind, Chalkiadakis, & Jennings (2008). Indeed, WVGs coalition structures seen TTGsone task type = t1 utility 1.time, one also interpret TTGs games overlapping coalitions allowingagent spread weight across several tasks. corresponding OCF-game G = (N, v)givennXv(r1 , . . . , rn ) = max{0, max{uj |ri wi j }}.i=1is, partial coalition successfully complete task type tj earn value ujtotal weight contributed agents partial coalition least j .Example 1. Consider TTG G = (N ; w; t), N = {1, 2, 3}, w = (2, 2, 2) =t1 = (3, 1). corresponding non-overlapping game G v({1}) = 0, v({1, 2}) =v({1, 2, 3}) = 1. Note overlapping coalitions allowed, maximum socialwelfare achievable coalition structure N 1, agents cannot split two disjointgroups weight least 3.187fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGScontrast, corresponding OCF-game G = (N, v) v(1, 0, 0) = 0, v(1, 1, 0) =v(1, 1, 1) = 1, and, moreover, v(1, .5, 0) = 1 v(0, .5, 1) = 1. Hence maximum socialwelfare 2 overlapping setting since second agent split weight twocoalitions enough resources complete task.Example 1, clear TTG G, maximum social welfare achievableoverlapping version G least large maximum social welfare non-overlappingversion Gi.e., allowing agents split weights tasks increase efficiency.Moreover, increase arbitrarily large even single agent. Indeed, consider one agentweight w one task type = 1, u = 1. overlapping coalitions allowed,agents total utility 1, overlapping scenario obtain w. interestedreader, Appendix discusses algorithmic aspects social welfare maximization TTGs,overlapping non-overlapping scenario.5.2 Three Definitions Coreexplained Section 2 above, core-stability implies group agents ableprofitably deviate configuration core. Hence, definition core dependnotion permissible deviations used. Now, non-overlapping setting deviator abandons coalition originally participated in, joins new coalition. Thus, reasonobtain payoff coalition left. overlapping setting, situation less clear-cut. Indeed, deviating, agent may abandon coalitions completely,withdraw somebut allof contribution coalitions, keep contributionremaining coalitions unchanged. question whether agent expect obtainpayoff partial coalitions non-deviators still contributing to.first notion core assumes answer question no. Thus,agent identified deviatori.e., alters contribution given coalitionhe longerexpects benefit cooperation non-deviators. monotonicity, meansdeviators nothing gain contributing resources coalitions non-deviators. Therefore, first definition core present here, assume deviatorsform coalitions among themselves, or, words, deviation seen overlappingcoalition structure set deviators. remark definition seenstraightforward generalization standard notion core: indeed, standardsetting, deviator completely withdraws coalitions non-deviators, benefitscoalitions deviators. formalize approach follows.Definition 7. Given OCF-game G = (N, v) set agents J N , let (CS , x)(CS , y) two outcomes G partial coalition CS either supp(s ) Jsupp(s ) N \ J. say (CS , y) profitable deviation J (CS , x)j J pj (CS , y) > pj (CS , x). say outcome (CS , x) core Gsubset agents J profitable deviation it. is, set agents J N ,coalition structure CS J J, imputation I(CS J ), pj (CS J , y) pj (CS , x)agent j J.definition, deviation CS restricted coalition structurepartial coalitions involving deviators non-deviatorsi.e., partial coalitioncontains either deviators (supp(s ) J) non-deviators (supp(s ) N \ J). Thus,188fiC OOPERATIVE G AMES OVERLAPPING C OALITIONSpayoff players J receive CS would come partial coalitionsJ only.Example 2. Consider OCF-game G corresponds threshold task game G = (N ; w; t),N = {1, 2}, w = (4, 6), = (t1 , t2 ) t1 = (5, 15), t2 = (4, 10) (one thinkplayers two companies B discussed Section 1; tasks correspondtwo construction projects). Suppose players form two partial coalitions r 1 r 2 totalweight 5 player 1 contributes unit weight r 1 3 units weight r 2 ,player 2 contributes 4 units weight r 1 , 2 units weight r 2 , is, CS = (r 1 , r 2 ),r 1 = ( 14 , 23 ), r 2 = ( 43 , 13 ). partial coalitions weight 5,successfully complete t1 , resulting payoff 15 them. Now, suppose playersdivide gains using imputation x = ((7, 8), (9, 6)). Then, total payoff obtained player2 14, successfully deviate withdrawing coalitions, formingsingle partial coalition weight 5. coalition complete t1 receive payoff 15 > 14.hand, suppose players keep coalition structure, distributegains = ((7, 8), (8, 7)). player 2 longer gain withdrawingcoalitions. tempted withdraw resources r 1 , use 4 units weightcomplete t2 earn u2 = 10 > 8. However, that, longer get sharepayoffs r 2 . Hence, case deviation total payoff 10 < 15. Also, easysee player 2 cannot gain deviating r 2 only, player 1 better CSwould own. Hence, (CS , y) OCF-core G.sense, Definition 7 takes rather pessimistic, conservative, view members deviating group expect get non-deviators: indeed, Example 2 soonplayer 2 withdraws partial coalition r 1 CS expects thrown r 2 , eventhough r 2 affected deviation. Therefore, follows, refer notionprofitable deviation introduced Definition 7 c-profitable deviation, correspondingnotion core conservative core, c-core.definition applicable deviation agent interpreted agentsindicator agent trustworthy, therefore one immediately stop collaboration him. kind reaction unusual, may coalitionsaffected deviation may want punish deviators. case, deviators needdecide existing coalitions abandon existing coalitions keepcontribution intact. members partial coalitions react accordingly, sharing payoff affected deviation punishing deviators otherwise.Therefore, refer corresponding notion core refined. giving formaldefinition, first introduce notion agreement two coalition structures.Definition 8. Given set agents J N , say two coalition structures CS CSN agree outside J respect function f f bijection lists partialcoalitions {r CS | supp(r ) * J} {s CS | supp(s ) * J} f (r ) =implies rji = sj j/ J. Further, say CS CS agree outside J agreeoutside J respect function f .Intuitively, definition says two coalition structures agree outside J, contributions players J partial coalitions must outcomes.J set deviators, condition captures fact deviation players J189fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGSchange behavior non-deviators; function f used establish correspondence partial coalitions involving non-deviators deviation.illustration, consider following example.Example 3. Consider game three players N = {1, 2, 3} coalition structure CS =(q 1 , q 2 ), q 1 = (1, 12 , 21 ), q 2 = (0, 21 , 21 ). Let CS = (s1 , s2 , s3 ), s1 = (0, 0, 12 ),s2 = (0, 21 , 12 ), s3 = (1, 12 , 0). Intuitively, CS obtained CS players 1 2deviate abandoning joint project player 3 forming coalition own. SetJ = {1, 2}. hard see CS CS agree outside J respect functionf given f (q 1 ) = s1 , f (q 2 ) = s2 . hand, CS CS also agree outside Jrespect function f given f (q 1 ) = s2 , f (q 2 ) = s1 ; function assumesplayers 1 2 decided deviate, player 1 withdrew contribution q 1 player 2 withdrewcontribution q 2 .Definition 9. Given OCF-game G = (N, v) set agents J N , let (CS , x) (CS , y)two outcomes CS CS agree outside J respect function f . Supposepartial coalition CS supp(s ) * J j J yj = xijr = f 1 (s ) yj = 0 otherwise. say (CS , y) r-profitable deviationJ (CS , x) w.r.t. f j J pj (CS , y) > pj (CS , x). Further, say(CS , y) r-profitable deviation J (CS , x) exists function f CSCS agree outside J respect f (CS , y) r-profitable deviation J (CS , x)w.r.t. f . say outcome (CS , x) refined core, r-core, G subsetagents J posesses r-profitable deviation it.Definition 9, bijection f matches partial coalitions CS CS involve nondeviators; number coalitions coalition structures. Moreover,contribution non-deviators partial coalitions matched f CS CS .Now, also deviators change contribution partial coalition r,claim share payoff, determined x. hand, deviators changecontribution r, entitled payoff. Observe allow deviatorspick favourable bijection f CS CS : instance, contextExample 3 would pick f rather f , thereby allowing deviators claim payoffcoalition (0, 21 , 12 ). words, assume deviators withdraw contributionsdisturb non-deviators little possible.Example 4. Consider game G outcome (CS , y) described Example 2.argued player 2 cannot c-profitably deviate (CS , y), r-profitably deviatewithdrawing weight r 1 dedicating t2 . change contributionr 2 , still claim payoff gets r 2 , total payoff 10 + 7 = 17 > 15.hand, suppose players 1 2 split weights equally twopartial coalitions, forming structure CS = (q 1 , q 2 ), q 1 = q 2 = ( 21 , 12 ). Clearly,q 1 q 2 weight 5, earn 15 completing t1 . Now, supposeplayers distribute gains using imputation x = ((3, 12), (12, 3)). Now, players earn15, none benefit withdrawing partial coalitions time,therefore outcome (CS , x ) c-core. Moreover, players deviatesone coalition only, enough weight complete tasks, thereforeoutcome (CS , x ) also r-core.190fiC OOPERATIVE G AMES OVERLAPPING C OALITIONSprovide another example, suggests set profitable deviations allowedDefinition 9 may still small.Example 5. Consider game G coalition structure CS = (s1 , s2 ), player 1contributes weight s1 , player 2 contributes 3 units weight s1 3 unitsweight s2 , i.e., s1 = (1, 12 ), s2 = (0, 21 ). Observe v(s2 ) = 0, total weights2 3 only. Now, consider imputation z = ((3, 12), (0, 0)). Note player 2 could reducecontribution s1 2 units weight without affecting value coalition, useweight boost value s2 . However, allowed definition r-profitabledeviation, since soon player 2 alters contribution s1 , loses payoff 12gets s1 . mean, however, outcome (CS , z) r-core G: players1 2 collectively deviate ((1, 61 ), (0, 65 )). share payoff ((4, 11), (0, 15)),constitute r-profitable deviation them.Example 5 demonstrates Definition 9, considerably lax respectdeviators Definition 7, still strict: deviators punished soonreduce contribution coalition, irrespective whether affects value coalition.fact, according Definition 9, deviators would still punished even increasecontribution partial coalition non-deviators (though type deviation is, course,unlikely). One way fix allow deviators claim share payoffscoalition = f (r ) long v(s ) = v(r ). However, non-deviators evengenerous deviators. Indeed, case deviators reduce contributionparticular partial coalition, coalition still able perform task, albeit smallervalue. value task still larger total amount payoff originally receivednon-deviators partial coalition, deviators could allowed claim leftoverpayoff. words, notion deviation assumes non-deviators objectionswitching tasks, care payoff receive. may well case,quite optimistic deviators expect kind reaction contemplate whetherdeviate. Therefore, refer notion deviation o-profitable, call correspondingsolution concept optimistic core, o-core.Definition 10. Given OCF-game G = (N, v) set agents J N , let (CS , x)(CS , y) two outcomes CS CS agree outside J respect aPfunction f .Suppose also partial coalition CS supp(s ) * J jJ yj =Pmax{v(s ) kN \J xik , 0}, r = f 1 (s ). say (CS , y) o-profitable deviation J (CS , x) w.r.t. f j J pj (CS , y) > pj (CS, x). Further, say(CS , y) o-profitable deviation J (CS , x) exists function f CSCS agree outside J respect f (CS , y) o-profitable deviation J(CS , x) w.r.t. f . say outcome (CS , x) optimistic core, o-core, Gsubset agents J o-profitable deviation it.Example 6. Consider game G discussed Examples 2, 4, 5, outcome(CS , x ), CS = (q 1 , q 2 ), q 1 = q 2 = ( 12 , 12 ), x = ((3, 12), (12, 3)), describedExample 4. Note player 2 reduces contribution q 1 2, coalition would stillable earn 10 focusing task t2 . player 1 gets 3 units payoff q 1 anyway,definition o-profitable deviation, player 2 entitled remaining payoffmodified partial coalition, i.e., 10 3 = 7. combine unit weight saved191fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGSmanner weight contributes q 2 , embark t2 making profit 10. Thus,abandoning q 2 altogether reducing contribution q 1 , player 2 earn 7 + 10 > 15.Thus, outcome (CS , x ) o-core G.contrast, consider outcome combines CS symmetric payoff divisionscheme, as, e.g., = ((7, 8), (8, 7)). Now, player 2 reduces contribution q 1 1,resulting partial coalition earn 10 focusing t2 . payoffs, player 1 must receive 7,leaving 3 player 2. player 2 still use remaining weight complete t2 ,give total profit 10 + 3 = 13 < 15, i.e., deviation o-profitable. Similarly,show withdrawing resources q 2 abandoning q 1 even less profitableplayer 2. Finally, easy see player 1 o-profitable deviation either.Hence, outcome (CS , y) o-core (G).6. Core Characterizationprevious section, introduced three definitions core overlapping coalition formation games. Among three definitions core, c-core, though sense conservative,closest traditional definition core general NTU games (Osborne & Rubinstein,1994). Indeed, unlike two definitions, assume interaction deviators non-deviators. motivates us study overlapping core variant detail,proceed section next. promote readability, two sectionsreferring c-core simply core.start providing characterization set outcomes core: essentially,outcome core outcome total payments subset agentsmatch exceed maximum value achieved subset. proof reliestechnical restrictions function v defines game. particular, require vcontinuous, monotone bounded (observe game monotone bounded, v (S) <N ), well satisfy another natural restriction defined later. assumptionsallow us avoid pathological situations may arise model generality,supremum v (N ) unachievable (e.g., v strictly concave one arguments,case finite coalition structure achieve v (N )).Specifically, say game (N, v) U -finite (CS , x) |CS | > Ux I(CS ), exists (CS , y) |CS | U , I(CS ), pj (CS , x) pj (CS , y)j = 1, . . . , n (i.e., outcome (CS , x) U coalitions exists anotheroutcome (CS , y) U coalitions weakly prefered (CS , x) agents).condition holds, assume coalition structures arise game consistU partial coalitions. natural restriction many practical scenarios, mightdifficult agents maintain complicated collaboration pattern. holds when,example, bound number partial coalitions agent involved in.general U -finiteness imposes upper bound total number partial coalitionssupport occur. natural example provided class games twopartial coalitions r, r supp(r) = supp(r ) rj + rj 1 j = 1, . . . , n,v(r + r ) v(r) + v(r ). Note games assume coalition structurecontains two partial coalitions support S, least profitable playersmerge partial coalitions. (However, notice imply superadditivity,192fiC OOPERATIVE G AMES OVERLAPPING C OALITIONSmean grand coalition necessarily emerges, criterion referscoalitions identical support.) Hence, game 2n -finite.Remark 1. Note results U function n (as long U (n) < ).Alternatively, instead imposing condition U -finiteness v(), could restrict setallowed outcomes (or potential deviations) coalition structures U partial coalitions.results hold model well.state prove first main results.Theorem 1. Given game (N, v), v monotone, continuous, bounded, U -finiteU N, outcome (CS , x) c-core (N, v) NXpj (CS , x) v (S).(1)jSPProof. direction, suppose (CS , x) satisfies jS pj (CS , x) v (S)N . Assume sake contradiction (CS , x) core, i.e., exists set S,coalition structure CS CS imputationpj (CS , y) > pj (CS , x)P I(CS ) suchPj S. v(CS ) =jS pj (CS , x) v (S),jS pj (CS , y) >contradiction way v (S) defined.direction, consider outcome (CS , x)P satisfy (1); show(CS , x) core. begin, set p = p(CS , x), assume jS pj < v (S)N . show (CS , x) core, construct set , coalition structureCS CS Pimputation I(CS ) pj (CS , y)P> pj j . Fixset satisfies jS pj < v (S). Choose small enough jS pj < v (S) ,let CS = {CS CS | v(CS ) v (S) }. definition v (S), infinitesequence coalition structures CS (t) satisfies limt v(CS (t) ) = v (S), set CSnon-empty. Given coalition structure CS CS , imputation I(CS SP) respectivepayoff vector q = p(CS , y), define total loss TL(CS , q) (CS , q) j:pj >qj (pj qj ).Set TLmin = inf{TL(CS , q) | CS CS , I(CS ), q = p(CS , y)}. First, proveexists coalition structure CS CS imputation I(CS ) achieve totalloss TLmin .Lemma 1. theorems conditions, exists CS CS , imputation I(CS )payoff vector q = p(CS , y) s.t. TL(CS , q) = TLmin .(t)Proof. definition TLmin , exists infinite sequence coalition structures CS , =1, . . . , , respective imputations (t) , = 1, . . . , ,lim TL(CS (t) , p(CS (t) , (t) )) = TLmin(t)CS CS = 1, . . . , . game U -finite, coalition structureseen list U vectors [0, 1]n . adding all-zero partial coalitions necessary,assume coalition structure list exactly U vectors [0, 1]n , orderedlexicographically. v monotone bounded, exists B > 0 value(t)partial coalition CS 0 B. Consequently, (t) corresponds193fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGS(t)vector [0, B]nU . Hence, sequence (CS , (t) ), = 1, . . . , viewed subset[0, B]K (for sufficiently large finite value K) hence limit point, denote(CS , ). easy see limit sequence coalition structures coalitionP structure,i.e., r CS r [0, 1]n , j = 1, . . . , n holds Ui=1 rj 1.Moreover, continuity v, value partial coalition CS limit values(t)respective partial coalitions CS , = 1, . . . , . this, easy see(t)I(CS ). Also, CS CS , CS . Finally, p(, ) TL(, ) continuousfunctions arguments, conclude TL(CS , p(CS , )) = TLmin .Continuing proof Theorem, let (CS , y) outcome satisfies v(CS ), TL(CS , p(CS , y)) = TLmin , whose existence guaranteed Lemma 1. Setq = p(CS , y). Let us construct directed graph whose vertices agentsedge j exists coalition CS containing j y,agent j gets non-zero payoff coalition, i.e., r k CS rjk , rik > 0yjk > 0. Observe edge (j, i) , change k increasingpayoff small enough decreasing payoff j value withoutviolating constraints, i.e., z = (z 1 , . . . , z ) I(CS ), z l = l l 6= kz k = (y1k , . . . , yjk , . . . , yik + , . . . , ynk ). Now, color vertices follows: vertex j redagent j underpaid Py, i.e., qj < pj , white j isPindifferent, i.e., qj = pj , greenoverpaid, i.e., qj > pj . jS pj < v (S) jS qj = v(CS ) v (S) ,graph contains least one green vertex. argued above, path green vertex jred vertex i, transfer small amount payoff j hence decrease totalloss, contradiction choice (CS , y). Hence, given arbitrary green vertexj, set vertices reachable j graph, denote R(j), containgreen white vertices.would like argue agents R(j) successfully deviate (CS , x).Indeed, let CS coalition structure consists coalitions agents R(j) formamong CS . Clearly, value CS equal total value coalitionsformed agents CS . Note also (CS , y), agents R(j) getpayoffs coalitions involve agents R(j). Indeed, suppose R(j) getsnon-zero payoff coalition involves agent k 6 R(j). edgek, contradiction R(j) constructed. words, CS , payoffsagents R(j) get come coalitions form among themselves, yetagents green white, i.e., worse CS ,(in particular, agent j) strictly better. finish proof, let agentsR(j) distribute payoffs way (CS , y), except player j transfers smallfraction payoffs white players R(j) (this possible construction).last step ensures agent R(j) strictly better (CS , x). demonstrates(CS , x) core, required.v (S)Remark 2. Note make use additional restrictions imposed vprove direction theorem (these used proof Lemma 1). Hence,implication holds arbitrary G.easily verifiable Theorem 1 holds non-overlapping case coalition structureswell. result trivial prove setting, agents payoffs come one194fiC OOPERATIVE G AMES OVERLAPPING C OALITIONScoalition; contrast, use involved combinatorial arguments transferring payoffsamong agents. also get following interesting result corollary:Corollary 1. setting = N statement Theorem 1, conclude outcomec-core maximizes social welfare.turn attention characterizing set coalition structures CS admit payoffallocations x corresponding tuple (CS , x) belongs core. is,Theorem 1 saw necessary sufficient condition tuple (CS , x) belong core,suppose given structure CS = (r 1 , . . . , r k ) want check whetherexists payoff allocation x (CS , x) belongs core. characterizationseen generalization notion balancedness context overlapping coalitionformation. classic setting, analogous question grand coalition admitpayoff allocation core, answered Bondareva (1963) Shapley (1967).proceed result, define balancedness respect coalition structure.Definition 11. Fix coalition structure CS = (r 1 , . . . , r k ), k N, let K = {1, ..., k}.collection numbers {S }SN , {P}iK called balanced w.r.t. given coalition structure CS0 S, S:jS + = 1 K, j supp(r ).Definition 12. game called balanced w.r.t. coalition structure CS = (r 1 , ...,Pr k )every collection {S }SN , {i }iK balanced w.r.t. CS holds v (S) +Pki=1 v(r ) v (N ).proof following theorem based LP-duality, relies characterizationresult Theorem 1; furthermore, proof illustrates condition balancedness introducedarises rather naturally.Theorem 2. Let (N, v) OCF-game, v monotone, continuous, bounded, U -finiteU N consider coalition structure CS = (r 1 , ..., r k ), k N. existsimputation x s.t. (CS , x) belongs c-core game balanced w.r.t. CS .Proof. Suppose exists payoff allocation x (CS , x) belongs core, letK = {1, . . . , k}. following linear program (denoted LP) optimal solution:PxminPiK,jNP ijNs.t.r ) xij v (S)PjS i:jsupp(x=v(r)Kj ijfirst constraint expresses condition Theorem 1, second fact payoffpartial coalition needs distributed exactly. Note variables xijj 6 supp(r )recall Definition 4. precisely conditions need satisfied(CS , x) core clearly optimal value LP v (N ) (using first constraintCorollary 1). LP-duality theorem, means dual program also optimalsolution value v (N ). dual given by:PPmax PS v (S) + ki=1 v(r )K, j supp(r )s.t.S:jS + = 10N195fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGSHence feasible solution dual, value objective function Pv (N ),implies balanced collection {S }SN , {i }iK , holds v (S) +Pki=1 v(r ) v (N ).direction, suppose balanced collection, holds. meansfeasible solution, value dual v (N ). Therefore dualbounded feasible (setting = 1 rest 0 feasible), impliesoptimal solution. primal program also optimal solution x meansTheorem 1 (CS , x) belongs core.Remark 3. traditional superadditive setting, condition balancedness somewhatsimpler intuitive. setting, characterization leads slightly complicatedexpression, essentially due fact linear program describes core allocationscoalition structure requires larger set constraints.7. Convex OCF-Games Non-Empty Coresection, first generalize notion convexity OCF-games proceed showprovides sufficient condition non-emptiness c-core.Recall classical TU-games convexity means R N N \ Rholds v(S R) v(S) v(T R) v(T ). Thus, convexity classic TU-games settingmeans useful coalition R join larger coalition smaller one.apply intuition setting (recall F(S) denotes set feasible agreements S):Definition 13. OCF-game G = (N, v) convex R N N \ Rfollowing condition holds: (CS , xS ) F(S), (CS , xT ) F(T ),(CS SR , xSR ) F(S R) satisfies pj (CS SR , xSR ) pj (CS , xS ) j S, existsoutcome (CS R , xT R ) F(T R) s.t.pj (CS R , xT R ) pj (CS , xT )pj (CSR,xR) pj (CSSRj ,SR,x) j R.definition similar flavour provided Suijs Borm (1999), generalization convexity defined context stochastic cooperative games. intuition behinddefinition follows: Consider two fixed agreements, one one respectively.time feasible agreement R members object compared agreement (i.e., members weakly better previousagreement), feasible agreement R (i) members object agreement, compared previous agreement (ii) members R weaklyprefer agreement agreement R.note different notion convexity defined fuzzy games Branzei,Dimitrov, & Tijs (2003). definition deals marginal contribution partial coalitionjoining another existing partial coalition, result join new partial coalition.We, hand, quantify marginal contribution adding set players R, setplayers , w.r.t. best overlapping coalition structure set R form. Secondly,definition Branzei et al., well classic definition convexity, simply enforce propertyfunction v(), concerning marginal contribution v(R ) v(T ). case, games196fiC OOPERATIVE G AMES OVERLAPPING C OALITIONSfully transferable hence cannot simply talk difference values. Instead,definition enforce existence coalition structure R individuallyevery player least well-off coalition structure R S, .show convexity sufficient condition non-emptiness core,analogy classic result convex TU-games (Shapley, 1971).Theorem 3. OCF-game G = (N, v) convex v continuous, bounded, monotoneU -finite U N, c-core game empty.Proof. Let G = (N, v) convex OCF-game. N , let GS restrictionG S. prove theorem, explicitly construct outcome (CS , x), x I(CS ),show belongs core G: Fix arbitrary ordering players 1, 2, . . . , n 1, n.construction takes place rounds. First, let p1 = v ({1}), p2 = v ({2}); assumptionstheorem using arguments similar proof Lemma 1, exist coalitionstructures CS {1} , CS {2} achieve payoffs. Let CS 1 structure achievesplayer 1 G{1} , let x1 corresponding imputation. know exists least onecoalition structure CS 2 CS {1,2} corresponding imputation x2 p1 (CS 2 , x2 ) p1 ,p2 (CS 2 , x2 ) p2 (e.g., take union payoff-maximizing structures G{1} G{2} ,combine corresponding imputations). exist one feasible agreement,pick one preferred player 2. formally, choose feasible agreement (CS 2 , x2 )maximizes payoff p2 (CS 2 , x2 ) (which least p2 ) feasible agreements{1, 2} subject p1 (CS 2 , x2 ) p1 (CS 1 , x1 ) (by assumptions v(), maximum exists).Now, let p3 maximum payoff agent 3 get G{3} . Again, exists least onecoalition structure CS 3 CS {1,2,3} corresponding imputation x3 agents 1, 2(weakly) better (CS 2 , x2 ), 3 also weakly better own.exist one feasible agreement, pick one maximizes 3s payoff, i.e., pickagreement (CS 3 , x3 ) p3 (CS 3 , x3 ) maximized agreements {1, 2, 3} subjectconstraints p1 (CS 3 , x3 ) p1 (CS 2 , x2 ), p2 (CS 3 , x3 ) p2 (CS 2 , x2 ).Continuing manner, every round k pick outcome (CS k , xk ) maximizespk (CS k , xk ) subject constraints pi (CS k , xk ) pi (CS k1 , xk1 ) {1, ..., k 1};assumptions v() ensure maxima exist. end, obtain feasible agreement(CS n , xn ) N agents weakly better own, well weaklybetter compared agreements previous rounds.show (CS n , xn ) belongs core G. suffices prove followingstronger claim.Claim 1. k = 1, . . . , n, feasible agreement (CS k , xk ) belongs core gameG{1,...,k} .Proof. prove induction. k = 1, obvious (CS 1 , x1 ) belongs coreG{1} .Now, suppose m, 2 n, (CS k , xk ) core(G{1,...,k} )k < m. prove (CS , xm ) core G{1,...,m} .Suppose, sake contradiction, case. subset{1, ..., m} (CS , x ) F(S)pi (CS , x ) > pi (CS , xm ) S.197(2)fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGSconsider three different cases members S:Case 1: 6 S. case know construction {1, . . . , 1}pi (CS , xm ) pi (CS m1 , xm1 ), implies pi (CS , x ) > pi (CS m1 , xm1 )S. Hence, tuple (CS , x ) deviation makes members strictly betteragreement (CS m1 , xm1 ). contradiction since induction (CS m1 , xm1 )core(G{1,...,m1} ).Case 2: = {1, . . . , m}. get contradiction constructed (CS , xm ).Indeed, chose (CS , xm ) maximize pm (CS , xm ) subject constraints pi (CS , xm )pi (CS m1 , xm1 ) = 1, . . . , 1. However, (2), outcome (CS , x ) alsosatisfies constraints provides higher payoff (CS , xm ) does, contradiction.Case 3: = {m}, strict subset {1, . . . , 1}. case utilizeconvexity. Let CS coalition structure consists singleton coalitions agents, let x corresponding imputation. construction, (CS , x ) feasible agreement{m} pi (CS , x ) pi (CS , x ) . Let = {1, . . . , 1}.Since (CS m1 , xm1 ) F(T ), applying Def. 13 R = {m}, getexists feasible agreement (CS , x) {m} = {1, . . . , m} pi (CS , x)pi (CS m1 , xm1 ) = 1, . . . , 1, pm (CS , x) pm (CS , x ). (2)get pm (CS , x) > pm (CS , xm ), contradiction chose (CS , xm ).Applying Claim 1 k = n, get core G non-empty.traditional setting, game represented using oracle access v(S), trivialalgorithm computing element core convex games. Indeed, one set payoffvector vector marginal contributions agents arbitrary permutationset agents. setting, proof yield procedure constructing elementcore, though polynomial-time one. procedure requires solving series optimizationquestions, arbitrary convex games NP-hard. future, would like findclasses convex games proof yields polynomial-time algorithm. particular, lookingproof, would true games solve polynomial time followingproblem: Given set agents N , feasible agreement S, outcome (CS , x),agent k 6 S, find feasible agreement (CS , y) {k} maximizes pk (CS , y) subjectconstraints pj (CS , y) pj (CS , x).8. Properties Three CoresFollowing detailed study c-core stability concept previous two sections,section explore properties three notions OCF-core. particular,investigate relationships among notions, study effects allowing overlappingcoalition formation stability underlying game. also compare OCF modelnotions core fuzzy games setting notion fuzzy core (Aubin, 1981).start exploring connection stability social welfare maximizationTTGs. demonstrated earlier paper, OCF-games two properties closely related. Indeed, Theorem 1 Corollary 1 show outcome c-core OCF-gamemaximizes social welfare long characteristic function game satisfies numbertechnical conditions; Theorem 5 holds r-core o-core. However,one conditions continuity, result directly apply TTGs. proof198fiC OOPERATIVE G AMES OVERLAPPING C OALITIONSTheorem 1 adapted work TTG setting, also exists direct prooffollowing theorem.Theorem 4. TTG G = (N ; w; t) outcome (CS , x) c-core(G),v(CS ) v(CS ) coalition structure CS CS N .Proof. Fix outcome (CS , x) c-core(G), let p payoff vector corresponds(CS , x). Suppose exists coalition structure CS CS N v(CS ) > v(CS ).Let CS = (r 1 , . . . , r k ). j = 1, . . . , k, let z j total weight partial coalition r j , i.e.,set z j = r1j w1 + + rnj wn .Now, consider coalition structure CS = (q 1 , . . . , q k ) given qij = z j /w(N ) N ,Pj = 1, . . . , k; note kj=1 qij 1. total weight partial coalition q jPcomputed qij wi = z j . Therefore, q j CS accomplish task r j CS ,hence v(CS ) = v(CS ) > v(CS ). Now, observe since CS players contributepartial coalitions, restrictions value CS distributed among)players. particular, set = v(CS )v(CS, construct imputation I(CS )nPkPv(r j )jjjsetting yij = v(CS) (pi + ). Indeed,yi = v(r ),j=1 yi = pi + . Now,clear entire set agents N deviate (CS , x) (CS , y); deviatesimultaneously, c-profitable deviation, contradiction (CS , x) c-coreG.discussion Section 5.2 suggests natural relationship three notionssuccessful deviation, and, consequently, three cores. (In follows, referoutcomes c-core, r-core o-core c-stable, r-stable o-stable, respectively.)Theorem 5. OCF-game G, o-core(G) r-core(G) c-core(G). Moreover,containments strict, i.e., exists OCF-game G o-core(G) r-core(G)c-core(G).Proof. Observe c-profitable deviation viewed r-profitable deviationplayers abandon coalitions contributed to. Similarly, r-profitable deviation correspondso-profitable deviation whenever deviator changes contribution coalition,withdraws resources it; note that, illustrated Example 5, deviators payoffo-profitable deviation strictly higher original r-profitable deviation.follows outcome r-stable also c-stable, outcome o-stable alsor-stable, thus proving first part theorem.prove second part theorem, consider game G described Examples 2, 4, 56. demonstrated outcome (CS , x) c-core(G) \ r-core(G)outcome (CS , x ) r-core(G) \ o-core(G).Theorem 5 shows three notions stability substantially different respectindividual outcomes. However, exclude possibility equivalent seennotions stability entire game, i.e., OCF-game G c-core(G) 6= iffr-core(G) 6= iff o-core(G) 6= . show case. games usedproofs following two propositions threshold task games. However, they, too,described terms agents weights tasks.199fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGSProposition 1. exists OCF-game G c-core(G) 6= r-core(G) = .Proof. Consider OCF-game G = (N, v) seven agents N = {1, . . . , 7} whose weightsgiven w = (1, 1, 1, 1, 3, 3, 3), two task types t1 t2 values 100 2, respectively.first task completed following four ways:1 unit player 1s weight 2 units player 5s weight;1 unit player 2s weight 2 units player 6s weight;1 unit player 3s weight 2 units player 7s weight;1 unit player 4s weight 2 units weight either players 5, 6, 7.is, v(r) = 100 wi ri 1 wj rj 2,(i, j) {(1, 5), (2, 6), (3, 7), (4, 5), (4, 6), (4, 7)}.second task t2 requires 2 units weight total players 5, 6 7.Consider coalition structure CS = (r 1 , r 2 , r 3 , r 4 ), given2r 1 = (1, 0, 0, 0, , 0, 0),323r = (0, 0, 1, 0, 0, 0, ),32r 2 = (0, 1, 0, 0, 0, , 0),31 14r = (0, 0, 0, 0, , , 0).3 3is, partial coalitions r 1 , r 2 r 3 successfully complete t1 , r 4 successfully completes t2 . Consider also imputation x I(CS ) givenx1 = (0, 0, 0, 0, 100, 0, 0),x2 = (0, 0, 0, 0, 0, 100, 0),x3 = (0, 0, 0, 0, 0, 0, 100),x4 = (0, 0, 0, 0, 1, 1, 0).Let p payoff vector corresponds x: p1 = p2 = p3 = p4 = 0, p5 =p6 = 101, p7 = 100. hard see (CS , x) c-core(G). Indeed, suppose sakecontradiction set players J c-profitably deviate (CS , x). Since(CS , x) maximizes social welfare, deviation cannot simultaneously profitableplayers N , |J| < 7. Moreover, J cannot contain 2 players set = {5, 6, 7}:indeed, one players deviates, loses 100 units payoff, replacedforms coalition 4. However, since 4 cannot form two distinct coalitions value 100each, possible. Therefore, J cannot contain players set S:players already gets maximum payoff t1 , and, since two playersJ, set deviators enough resources t2 . Finally, c-profitabledeviation players N \ S, task completed agents N \ only.show r-core G empty. Suppose otherwise, let (CS , y)outcome r-core G. Let p payoff vector corresponds y. hardshow outcome r-core G maximizes social welfare; proof similarTheorem 4. Hence, assume without loss generality CS = (q 1 , q 2 , q 3 , q 4 )v(q 1 ) = v(q 2 ) = v(q 3 ) = 100 v(q 4 ) = 2, and, moreover, q51 23 , q62 23 , q73 32 . follows200fiC OOPERATIVE G AMES OVERLAPPING C OALITIONSeither (a) q11 = q22 = q33 = 1 (b) q4j = 1 j {1, 2, 3} qii = 1 {1, 2, 3},6= j. say player useful coalition r v(r ) < v(r), r given ri = 0,rj = rj j 6= i. Observe r-stable outcome player get payoffpartial coalition useful: otherwise members coalition,complete corresponding task own, r-profitably deviate. showp1 = . . . = p4 = 0 case (a) case (b). Observe argument player1 get payoff q 1 only, player 2 get payoff q 2 only, player 3 get payoffq 3 only, player 4 get payoff exactly one coalitions q 1 , q 2 , q 3 .case (a), clearly p4 = 0, player 4 useful coalition CS . Now, if,e.g., y11 > 0, y51 < 100, players 4 5 r-profitably deviate forming coalitionperforms t1 . Hence y11 = y22 = y33 = 0, therefore p1 = p2 = p3 = 0. case (b), assumewithout loss generality q41 = 1. p1 = 0, player 1 useful coalitionCS , y41 = 0, since otherwise players 1 5 r-profitably deviate, and, consequently,p4 = 0. implies also y22 = y33 = 0: if, e.g., y22 > 0, y62 < 100, players 46 r-profitably deviate forming coalition performs t1 . Hence, casesp1 = = p4 = 0.Now, v(q 4 ) = 2, y54 + y64 + y74 = 2, least one payoffs y54 , y64 y74strictly positive. Assume without loss generality y54 = > 0. players 6, 7partners q 2 q 3 (i.e., players , qi2 = 1, qi3 = 1) r-profitably deviate(CS , y) forming coalition structure CS = (s1 , s2 , s3 ), s1 givens1i = 1,2s16 = ,3s1 = 0 6= , 6,s2i = 1,2s27 = ,3s2 = 0 6= , 7,s2 givens3 = (0, 0, 0, 0, 0, 13 , 13 ). construct imputation z CS setting zi1 =zi2 = 4 , z61 = z72 = 100 4 , z63 = y64 + 2 , z73 = y74 + 2 , zij = 0 (i, j) 6=(i , 1), (6, 1), (i , 2), (7, 2), (6, 3), (7, 3). hard see z I(CS ), and, moreover,deviation (CS , z) r-profitable 6, 7, . Hence, (CS , y) r-coreG.Proposition 2. exists OCF-game G r-core(G) 6= o-core(G) = .Proof. Consider OCF-game G = (N, v) 3 agents N = {1, 2, 3} whose weights givenw = (8, 8, 8), 2 task types t1 t2 . first task needs 6 units weight player,value 300, i.e. v(r1 , r2 , r3 ) = 300 wi ri 6 = 1, 2, 3. second task needs 4 unitsweight total players7 7and6 has2value12. 1 2121Let CS = (r , r ), r = 8 , 8 , 8 , r = 8 , 8 , 8 . Clearly, v(r 1 ) = 300, v(r 2 ) = 2.Consider also imputation x I(CS ) given x1 = (100, 100, 100), x2 = (0.5, 0.5, 1).hard see (CS , x) r-core(G). Indeed, CS maximizes social welfare,deviation simultaneously profitable agents. Furthermore, agent withdrawscontribution r 1 , lose associated payoff 100 deviation compensateloss. Moreover, clear withdrawing contribution r 2 cannot profitable either,way earn 2 = v(r 2 ) amount weight.201fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGSshow G empty o-core. Suppose sake contradictionexists outcome (CS , y) o-core(G). hard show outcome o-coreG maximizes social welfare; proof similar Theorem 4. Hence, assumeCS = (q 1 , q 2 ), v(q 1 ) = 300, v(q 2 ) = 2, and, moreover, qi1 68 = 1, 2, 3.y12 + y22 + y32 = 2, assume without loss generality y12 = > 0. meansplayers 2 3 o-profitably deviate (CS , y) follows: players 2 3 withdrawq21 w2 6 q31 w3 6 units weight q 1 , respectively (as argued above, q21 w2 6,q31 w3 6), well entire contribution q 2 , use resources complete t2 .divide resulting payoff allocating y22 + 2 player 2 y32 + 2 player 3, constituteso-profitable deviation them. Thus, (CS , y) o-core G.Thus, far section investigated relationships among notions overlapping core; also insightful compare non-overlapping fuzzy one.proceed so.8.1 Comparison Non-Overlapping CoreGiven OCF-game G = (N, v), define non-overlapping game Gno = (N, v )setting v (C) = v(r C ), partial coalition r C given riC = 1 C riC = 0otherwise C N . Observe threshold task game G applying transformationoverlapping version G gives us exactly non-overlapping version G. comparecore game Gno overlapping cores original game G. particular, naturalask whether core Gno empty o-core G (and hence Theorem 5 alsor-core c-core G) not, vice versa, i.e., whether c-core (the largestoverlapping cores) G empty core Gno not. Interestingly, turnsanswer questions positive. demonstrate via examples based thresholdtask games; argued above, game G Gno = G.Proposition 3. exists TTG G core(G) = , o-core(G) 6= .Proof. Consider threshold task game G = (N ; w; t), N = {1, 2, 3}, w = (2, 2, 2),= t1 = (3, 1). G, coalition structure CS contains one coalition C v(C) = 1.Let p = (p1 , p2 , p3 ) imputation CS . v(CS ) = 1, exists N pi > 0.coalition C = N \ {i} successfully deviate (CS , p), w(C ) = 4,p(C ) = 1 pi < 1. Hence, outcome G stable.G, players form two successful partial coalitions. Now, consider outcome (CS , x),CS = (r 1 , r 2 ) r 1 = (1, 12 , 0), r 2 = (0, 21 , 1), x1 = ( 23 , 31 , 0), x2 = (0, 31 , 23 ).claim (CS , x) o-core G. Indeed, suppose sake contradictiongroup players J o-profitable deviation (CS , x). |J| {1, 2, 3}.easy see |J| =6 1: player enough weight complete t1 own. Also, |J| =6 2:44pair players earns 3 (CS , x), make 1 < 3 . Finally, |J| =6 3,(CS , x) maximizes social welfare. contradiction completes proof.Intuitively, Proposition 3 holds G feasible outcomes G,additional outcomes turn stable. flip side, G allows wider rangedeviations, outcome stable respect G may unstable respect G.next proposition illustrates this.202fiC OOPERATIVE G AMES OVERLAPPING C OALITIONSProposition 4. exists TTG G c-core(G) = , core(G) 6= .Proof. Consider threshold task game G = (N ; w; t), N = {1, 2, 3}, w = (9, 1, 1),= (t1 , t2 ) t1 = (8, 100), t2 = (2, 1).G, player 1 work task t1 , players 2 3 cooperate task t2 , sharingprofits equally. Clearly, resulting outcome stable.hand, G c-stable outcomes. Indeed, suppose outcome(CS , x) c-core G, let p corresponding payoff vector. Theorem 4, CSconsists two partial coalitions: r 1 , completes t1 , r 2 , completes t2 . Hence,v(CS ) = 101. p1 > 100, p2 + p3 < 1, hence players 2 3 deviate formingcoalition r = (0, 1, 1) complete t2 value 1. p1 < 100, player 1 deviateforming coalition r = (1, 0, 0) complete t1 value 100. Hence, p1 = 100,p2 + p3 = 1, therefore assume without loss generality p2 21 . Now, players1 2 deviate forming coalition structure CS = ( 98 , 0, 0), ( 19 , 1, 0) distributingpayoffs ((100, 0, 0), ( 13 , 23 , 0)). conclude (CS , x) c-stable, contradiction.8.2 Comparison Fuzzy Gamesmentioned earlier paper, Aubin (1981) introduces notion fuzzy game,player participate coalition various levels, value coalition dependsparticipation levels members. Thus, first glance, definition fuzzy game identicaldefinition OCF-game, given characteristic functions defined [0, 1]n .However, several crucial differences fuzzy OCF-games.First, fuzzy games OCF-games differ definition outcome. Indeed,OCF-games outcome (overlapping) coalition structure together list payoff vectors,fuzzy games allowable outcome formation grand coalition. Furthermore,outcome OCF-core needs stable deviation set (possibly overlapping) coalition structure. Aubin core, outcomes need stable deviationpartial (fuzzy) coalition, necessarily deviations coalition structure. Indeed,formation coalition structures (overlapping not) addressed fuzzy games literature.One could try represent games overlapping coalition structures using fuzzy gamesformalism. Indeed, given OCF-game, construct fuzzy game whose characteristicfunction simulates behaviour characteristic function original OCF-game coalition structures. Specifically, given OCF-game G = (N, v), define related fuzzy gameG = (N, v ) follows. r [0, 1]n , define1kCS r = {(q , . . . , q ) | k1, qij0 = 1, . . . , n, j = 1, . . . , k,kXqij = ri },j=1set v (r) = supCS CS r v(CS ). is, partial coalition r, v identifies bestcoalition structure CS obtained splitting r subcoalitions, returns valuev(CS ). resulting fuzzy game G similar original OCF-game G. example,TTGs, transformation would enable members grand coalition work several taskssimultaneously. generally, given TTG G, outcome (G) (i.e., payoff vectorgrand coalition) corresponds social-welfare maximizing outcome (CS , x) G vice versa.203fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGSfact, relationship holds OCF-game G corresponding fuzzy game Glong set {v(CS ) | CS CS (1,...,1) } compact (and thus contains least upper bound).However, approach fails capture several delicate aspects overlapping coalition formation. main reason fuzzy game formulation, actual set tasks executedpartial coalition implicit definition characteristic function. Indeed, outcomefuzzy game simply payoff vector, guaranteed set tasksprovides corresponding total payoff, set tasks cannot read descriptionoutcome. leads number difficulties.First, fuzzy games formalism would allow us reason partial coalition structuressuboptimal social welfare. Theorem 4 coalition structures unlikelyfinal outcomes game, dynamic coalition formation protocol may produce partial coalitionstructures intermediate steps. Thus, using language fuzzy coalitions impairs abilitystudy processes lead formation partial coalition structures. processesgreat interest practical perspective, important disadvantage fuzzy model.Further, OCF representation, one-to-one correspondence partialcoalitions tasks. makes OCF approach intuitively appealing, suggests provides right level granularity reasoning partial coalition formation. Indeed, considerproblem computational perspective context TTGs. OCF representation finding socially optimal coalition structure difficult (see Appendix A), computingvalue given partial coalition r straightforward: simply pick valuable taskcompleted using resources posessed r. contrast, fuzzy game framework,two issues intertwined, even computing partial coalitions worth hard problem.Even importantly, definition fuzzy core given Aubin (1981) appropriatemany natural scenarios, and, particular, TTGs. Specifically, fuzzy core fuzzy gameG = (N, v) defined setPoutcomes (N, p) p(N ) = v(1, . . . , 1)partial coalition r holds ni=1 pi ri v(r). Essentially, means groupplayers deviates grand coalition via partial coalition r, deviating player receivespayoff r, original payoff grand coalition, scaled factor(1 ri ). Thus, fuzzy core even optimistic deviators perspective ocore. Indeed, deviators worry grand coalition able leave.simply assume withdraw, say, 40% resources, get 60%used get. However, many gamesand, particular, TTGsif players abandongrand coalition, latter may sufficient resources complete task. Clearly,case deviators could possibly get payoff remains grand coalition. Thus,fuzzy core may empty, even practice game stable. example proofProposition 5 illustrates this.Proposition 5. exists TTG G o-core(G) 6= , fuzzy core corresponding fuzzy game (G) empty.Proof. Consider TTG G given N = {1, 2}, w = (10, 10), = ((20, 20), (7, 9)),induced OCF-game G. corresponding fuzzy game (G) = (N, v ) given204fiC OOPERATIVE G AMES OVERLAPPING C OALITIONS2018v (r) =90r1 + r2 = 21.4 r1 + r2 < 20.7 r1 + r2 < 1.4r1 + r2 < 0.7hard see outcome (CS , x) G, CS = r = (1, 1) x = (10, 10)o-stable. Moreover, intuitively, clear rational agent coalition agents would wantdeviate outcome. hand, definition fuzzy core outcome(10, 10) (G) stable: indeed, q = (.7, .7) p1 q1 + p2 q2 = 14 < 18 = v (q).prove outcome (G) fuzzy core. Observe since v (1, 1) =20, outcome (G) form (z1 , z2 ), z1 + z2 = 20. Clearly, outcomez1 < 9 z2 < 9 unstable, partial coalition (1, 0) (respectively, (0, 1)) profitablydeviate it. Thus assume z1 9, z2 9, or, equivalently, z2 11, z1 11. Thus,partial coalition q considered above, z1 q1 + z2 q2 11 1.4 = 15.4 < 18 = v(q),means (z1 , z2 ) fuzzy core.Remark 4. remedy difficulties illustrated above, devise notion stabilitydefined within framework fuzzy games, yet essentially equivalentP c-core. Letnus say outcome p G f-stable r [0, 1] v (r) isupp(r ) pi ,define f-core G set f-stable outcomes G . Note definitiondifferent standard definition fuzzy core. TTGs, one show outcomep G f-core G corresponding outcome (CS , x) G ccore G. proof makes use fact TTGs one distribute profit v (r)deviating partial coalition r among members supp(r) arbitrarily. (In detail, oneconstruct partial coalition structure CS involving agents supp(r) performs tasks totalvalue v (r) agent supp(r) participates partial coalition CS .) Moreover,equivalence true general OCF games whose characteristic functions satisfy naturalregularity conditions; proof similar proof Theorem 1. Unfortunately, f-coreprovides analogue c-core fuzzy game setup, clear devise analoguer-core o-core setting. Indeed, define concepts, would reasonpartial coalitions hurt deviation. However, description outcomefuzzy game indicate partial coalitions given player belongs to, cannotdetermine tasks affected deviation.conclude natural settings OCF-games provide realisticnuanced model fuzzy games; threshold task games appear one example.9. Computational Aspects Stability Threshold Task Gamessection, investigate computational complexity core-related questions TTGs.goal twofold. First, TTGs provide natural model agent collaboration, thereforeimportant understand allocate resources games stable manner. Second,analysis highlights important differences three definitions core gamesoverlapping coalitions. particular, results presented section provide complexitytheoretic separation c-core, one hand, r-core o-core,205fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGShand. believe results type useful building better understanding stabilitycontext general OCF games.Unless explicitly stated otherwise, make usual assumption parametersgamei.e., weights, thresholds task utilitiesare integers given binary. assumptionmade without loss generality, necessary formal complexity-theoretic analysis.9.1 Games Non-Overlapping Coalitionsstart analyzing complexity TTGs non-overlapping setting. mentionedSection 5.1, games seen generalization weighted voting games coalitionstructures. Elkind, Chalkiadakis & Jennings (2008) show several stability-related questionsgames computationally hard weights integers given binary. Hence,formulate following proposition, whose proof follows immediately results.Proposition 6. Given TTG G = (N ; w; t), coNP-hard decide whether correspondinggame G empty core. Also, given outcome (CS , p) G, coNP-complete decidewhether (CS , p) core G. results hold even one task type,utility task 1.hand, Elkind et al. (2008) provide polynomial-time algorithm checkingoutcome weighted voting game core weights given unary. algorithmbased dynamic programming: given weighted voting game G described set players N ,list weights w threshold , weight 1, . . . , w(N ) identifies minimum payoffPw coalition weight w, checks Pw < 1 w .hard see similar approach works threshold task games well.complication weight w, addition computing minimum payoff coalitionweight given imputation, compute maximum utility availablecoalition weight, i.e., max{uj | w j }, compare two quantities. However,additional steps easy (in particular, performed efficiently even task utilitieslarge). gives us following result.Proposition 7. exists algorithm that, given TTG G = (N ; w; t) outcome (CS , p)G, checks whether (CS , p) core G runs time poly(w(N ), |p|), |p|number bits binary representation p.weighted voting games unary weights, Elkind et al. (2008) also show that, constructing linear program uses algorithm Proposition 7 oracle, checkpolynomial time whether given coalition structure CS stabilized, i.e., whether existspayoff vector p I(CS ) (CS , p) core. algorithm easily adaptedwork TTGs unary weights. Hence, question whether given coalition structurestabilized poly-time solvable games, too.9.2 Games Overlapping Coalitionsshow that, similarly non-overlapping case, weights, thresholds utilitiesTTG integers given binary, computationally hard check given outcomecorresponding OCF game stable. Moreover, hardness result holds three definitions stabilty, i.e., c-core, r-core, o-core. results perhaps206fiC OOPERATIVE G AMES OVERLAPPING C OALITIONSsurprising given similar result non-overlapping setting (i.e., Proposition 6 above),reason behind computational hardness quite different. Indeed, reduction used proofProposition 6 based PARTITION, classic NP-hard problem asks whether, givenset weights, split two sets weight. Essentially, proof proceedsconstructing outcome stable certain subset agents cannot splittwo groups weight. proof technique unlikely work overlappingscenario, one always form two partial coalitions weight allowing agentssplit weight equally two coalitions. Hence, proof following theorem usessomewhat different approach.Theorem 6. Given TTG G = (N ; w; t) outcome (CS , x) corresponding OCF gameG, coNP-complete decide whether (CS , x) c-core G.Proof. reduction based U NBOUNDED K NAPSACK, well-known NP-hard problem.instance U NBOUNDED K NAPSACK (Martello & Toth, 1990) given set items,item size si value zi , knapsack size B target value Z. yesinstance fill knapsack using unlimited number copies itemtotal size resulting set items B,PZ, i.e.,P total value leastvector non-negative integers (1 , . . . , ) i=1 si B i=1 zi Z.Otherwise, no-instance.Consider instance = ((s1 , . . . , ); (z1 , . . . , z ); B; Z) U NBOUNDED K NAPSACK.assume without loss generality sj < B, zj < Z j = 1, . . . , . Moreover,assume monotone, i.e., si sj implies zi zj . Indeed, pair itemssi sj , zi > zj , simply delete jth item, used optimal solution.construct instance problem follows. Set N = {1} let w1 = B.Set = (t1 , t2 , . . . , t+1 ), j = sj , uj = zj j = 1, . . . , +1 = B, u+1 = Z 1.Due restrictions I, game G = (N ; w; t) threshold task game.Consider outcome (CS , p) CS consists single partial coalition r r1 = 1p I(CS ). B > sj j = 1, . . . , , coalition executes task t+1 receivesutility Z 1. Hence, player 1 c-profitably deviate (CS , p) findcollection tasks whose total resource requirement weight B whose total utilityleast Z, i.e., started yes-instance U NBOUNDED K NAPSACK.proof Theorem 6 outcome (CS , x) consists single partial coalition. Thus,r-profitable deviation (CS , x) c-profitable. implies following corollary.Corollary 2. Given TTG G outcome (CS , x) corresponding OCF game G,coNP-complete decide (CS , x) r-core G.o-core, situation somewhat complicated. However, careful examinationproof Theorem 6 allows us obtain following corollary.Corollary 3. Given TTG G = (N ; w; t) outcome (CS , x) corresponding OCFgame G, coNP-complete decide (CS , x) o-core G.Proof. proof Theorem 6, construct OCF game 1 player outcome (r, x).Consider o-profitable deviation (CS, y) (r, x). deviation necessarilyc-profitable deviation (r, x): (CS , y), agent 1 may withdraw some,207fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGSresources (r, x) therefore continue derive benefit it. However, singleagent, allocating resources original partial coalition r equivalent formingnew partial coalition using amount resources, i.e., given (CS, y), one constructdeviation (r, x) c-profitable agent 1. hand, c-profitabledeviation (r, x) also o-profitable. Hence, (r, x) o-stable c-stable, i.e.,started no-instance U NBOUNDED K NAPSACK.rest section, focus case parameters game (i.e.,players weights, thresholds task utilities) integers given unary, or,equivalently, polynomial numberGiven game G = (N ; w; t),Pplayers.j + uj ).tj = (T j , uj ) j = 1, . . . , m, let |G| = w(N ) +(Tj=1turns setting checking whether outcome c-core becomes easy.Intuitively, reason group players decides deviate, agentsgroup easily decide proceed: need pool weights find profitableset tasks completed using amount resources.Theorem 7. exists algorithm that, given TTG G = (N ; w; t) outcome (CS , x)corresponding OCF game G, checks whether (CS , x) c-core G runs timepoly(|G|, |x|), |x| size binary representation imputation x.Proof. algorithm based dynamic programming. First, w = 1, . . . , w(N ), let Uwmaximum profit coalition weight w make, i.e.,XXUw = maxj uj |j j w, (1 , . . . , ) Nm .j=1j=1w = 1, . . . , w(N ), quantity Uw computed using dynamic programmingalgorithm U NBOUNDED K NAPSACK. running time procedure polynomial |G|.Now, let p payoff vector corresponds imputation x. = 1, . . . , nw = 1, . . . , w(N ), set Pi,w = min{p(S) | {1, . . . , i}, w(S) = w}. quantities Pi,weasily computed using dynamic programming. Indeed, P1,w = p1 w = w1P1,w = + otherwise (we use convention min = +). Furthermore, computePi+1,w given values (Pi,w )w =1,...,w setting Pi+1,w = min{Pi,w , pi + Pi,wwi }. runningtime procedure poly(|G|, |p|).Suppose computed Pn,w w = 1, . . . , w(N ). Observe value Pn,wleast amount received coalition weight w p. Now, w = 1, . . . , w(N ),compare quantities Pn,w Uw . value w latter exceeds former,coalition N could increase collective earnings deviating (CS , x), i.e.,(CS , x) c-core G. hard see converse also true: Pn,w Uww = 1, . . . , w(N ), coalition c-profitable deviation (CS , x), hence(CS , x) c-core G.Clearly, algorithm runs time poly(|G|, |x|).contrast, corresponding problems r-core o-core computationally hard.Intuitively, reason decisions players make longer binary: insteadsimply deciding whether deviate, decide coalitions208fiC OOPERATIVE G AMES OVERLAPPING C OALITIONSnon-deviators abandon. case o-core, also possibility reducing onescontribution partial coalition rather abandoning altogether.Theorem 8. Given TTG G = (N ; w; t) outcome (CS , x) corresponding OCF gameG, strongly coNP-complete decide whether (CS , x) r-core G.Proof. hard see problem coNP: show outcome (CS , x)r-core G, guess set deviators J deviation (CS , y), check (CS , y)r-profitable J computing payoffs players J x y.show coNP-hardness, reduce AXIMUM E DGE B ICLIQUE (Peeters, 2003).instance AXIMUM E DGE B ICLIQUE given bipartite graph B = (L, R, E) setvertices L R set edges E L R, parameter K. yes-instance Bcontains biclique size least K, i.e., sets L L, R R |L | |R | K,L R (, ) E. Otherwise, no-instance.Suppose given instance (B, K) AXIMUM E DGE B ICLIQUE B =(L, R, E), L = {1 , . . . , |L| }, R = {1 , . . . , |R| }. create instance problemfollows. Assume without loss generality |L| |R|, set n = |R|+1, k = |L|, = k 2 n2 ,V = k 2 nM , create n players weights w1 = = wn1 = k, wn = k(kn n + 1)2 task types t1 = (kn; V ) t2 = (K; (n 1)k + 1). Also, create coalition structureCS = (r 1 , . . . , r k ) given rij = 1/k = 1, . . . , n j = 1, . . . , k. Observetotal weight rj CS kn, partial coalition performs t1 . Finally, constructimputation x = (x1 , . . . , xk ), j = 1, . . . , k = 1, . . . , n 1, set xji = 1Pn1 jxi j = 1, . . . , k.(i, j) E xji = otherwise. Also, set xjn = V i=1Suppose started yes-instance AXIMUM E DGE B ICLIQUE, let (L , R )corresponding subgraph B. subset players J = {i | R } r-profitablydeviate (CS , x) abandoning partial coalitions set = {r j | j L }, usingfreed-up resources embark t2 . Indeed, x players J collectively earn(n 1)k partial coalitions S, devote least K units weight coalitions.Conversely, consider r-profitable deviation (CS , y), let J corresponding setdeviators. Suppose k1 coalitions CS work t1 , k2 coalitions work t2 . First, supposen J. Observe (CS , y) profitable player n k1 = k, k2 = 0: indeed,(CS , x) player n earns least k(V (n 1)M ), whereas outcome completes less2k copies t1 earns (k 1)V + kKn ((n 1)k + 1) < k(V (n 1)M ). However,deviation results executing k copies t1 must involve resources players, i.e.,J = {1, . . . , n}, deviation cannot simultaneously profitable membersdeviating set. Hence, n 6 J, therefore w(J) k(n 1). Consequently, k1 = 0deviators total profit w(J)K ((n 1)k + 1) < . means (CS , y)r-profitable deviation player J abandons coalition r j CS xji = .hand, successfully execute even one copy t2 , members J must collectivelywithdraw least K units weight. Let R = {i | J}, let L correspond setpartial coalitions CS affected deviation; (L , R ) biclique size least K.hard check proof Theorem 8 player withdraw part resources partial coalition CS still claim profit coalition. implieschecking whether given outcome o-core computationally hard, too.209fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGSCorollary 4. Given TTG G outcome (CS , x) corresponding OCF game G,strongly coNP-complete decide whether (CS , x) o-core G.hand, combining techniques Theorem 7 Theorem 4 leads pseudopolynomial algorithm checking whether c-core TTG non-empty.Theorem 9. Given TTG G = (N ; w; t), one check time poly(|G|) whether corresponding OCF game G non-empty c-core.Proof. show c-core game G non-empty, social welfaremaximizing set tasks construct coalition structure CS executes set tasksimputation x I(CS ) (CS , x) c-core G; moreover, CS agentcontributes coalition. Hence, algorithm first selects social welfare-maximizing settasks, constructs coalition structure perform set tasks, finally solveslinear program check coalition structure stabilized. details follow.Assume simplicity contains task type = 1; caseadd task type t0 = (1, 0) t. allows us assume coalition structureagents resources committed tasks. Fix social welfare-maximizing multi-set tasks{1 t1 , . . . , tm }. Supposelet (CS , y) outcome c-core G.Pmc-core(j G) 6= ,Theorem 4, j=1 j u = v(CS ). Consider coalition structure CS contains1 + + coalitions: first 1 coalitions weight 1 each, next 2 coalitionsweight 2 each, etc., agent distributes resources evenly coalitions, i.e.,T1contributes wi w(N) units weight first 1 coalitions, etc. CS agentscontribute partial coalitions, v(CS ) = v(CS ), I(CS ). Moreover,clear outcome (CS , y) c-core(G): c-profitable deviation (CS , y) alsoc-profitable deviation (CS , y).Proposition 9 weights given unary, find social welfare-maximizingcoalition structure CS = (r 1 , . . . , r k ) polynomial time. Consider following linear program:pi 0 = 1, . . . , nXpi = v(CS )Xpi Uw(J) J N,iJUw defined proof Theorem 7. linear program exponentiallymany constraints, solved linear time ellipsoid method (Schrijver, 1986), sincepolynomial-time separation oracle. Indeed, decide whether given candidate solutionfeasible using algorithm described proof Theorem 7.Clearly, linear program feasible solution p, imputation x given xji =jp v(r ) N j = 1, . . . , |CS | satisfies x I(CS ), and, moreover, (CS , x)v(CS )c-core(G). Conversely, feasible solution, CS cannot stabilized,hence argument c-core G empty.210fiC OOPERATIVE G AMES OVERLAPPING C OALITIONS10. Conclusions, Extensions, Future Workpaper introduced model cooperative games allows overlapping coalitionstakes account need resource allocation. so, generalized usual modelseither grand coalition desirable outcome outcomes requiredpartitions set agents. Given model, defined studied depth notioncore (the c-core) generalization core traditional models cooperative gametheory. quite general conditions, provided characterization outcomethatis, (coalition structure, imputation) pairto belong core. also showed outcomecore maximizes social welfare. Further, introduced notion balancedness OCFgames, showed coalition structure CS admits imputation x (CS , x)core game balanced. Moreover, extended notion convexitysetting showed convex games non-empty core.addition, considered two notions core-stability OCF-games, differ(as well first one) deviators expect obtain collaboration non-deviators. Together, three notions core span wide range beliefsdeviators may hold regarding payoffs coalitions non-deviators, substantiallydifferent respect sets outcomes characterize, respectcomputational complexity. also compared OCF-games non-overlappinganalogues, showed social welfare maximization perspective, OCF-games mayprovide higher total utility, easier work classic counterparts.also argued OCF-games provide appropriate modelling framework fuzzy gamesmany scenarios; particular, certainly case threshold task games. summarize,paper one first attempts provide theoretical treatment overlapping coalitionformation, study stability setting thorough manner.10.1 Extensionsmany environments, coalition formed, may choice actions execute.deterministic setting one considered paper, coalition simplychoose action results highest possible payoff, probabilistic environmentchoice difficult: coalition may want strike balance expected payoffvariance. address issue, incorporate coalitional actions model follows.coalition allowed select action (usually finite) action space A. Without lossgenerality, assume coalition undertake action A.3 value coalitiondetermined resource contribution levels members action selected. Therefore, characteristic function setting defined (r, a) pairs, r = (r1 , . . . , rn )vector resources, action. definitions results generalize readilysituation coalition choice actions (simply put, presentation farcorresponds situation coalition exactly one action available it).Another extension examined modelling available resources.ease presentation assumed throughout paper exists one type (continuous) resource. Nevertheless, results still hold assume multiple types resources(e.g., agents distribute time money among coalitions). Moreover,3. situation case modeled setting value respective (coalition, action) pair0.211fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGSalso studied discrete OCF setting, agent contribution levels taking values finite set(i.e., agent may able contribute 20%, 21% resources given coalition).setting obviously interest many applications involving countable resources (asdiscretization effectively kind resources common practice). discrete resources,number possible coalition structures finite (as coalition setting collectionresourcessee Section 4). definitions theorems carry settingminor differences arguments used proofs.10.2 Future Workexist many exciting open questions future work. First all, important research direction develop better understanding scenarios overlapping coalitions naturally arise, identify appropriate stability concepts scenarios. believetechniques developed paper prove useful purpose. Moreover, one firstpriorities investigate alternative notions stability (i.e., o-core r-core)proposed above, obtain relevant characterization results, c-core. Extendingsolution concepts coalitional gamessuch as, e.g., Shapley valueto OCF settingsimportant research direction well.also plan study computational complexity core-related questionssetting. First, initiated study complexity-theoretic aspects stability OCFgames, paper focused complexity checking whether given outcomestable. Another natural problem domain studying complexity checking whethergame stable solutioni.e., whether c-core (r-core, o-core) non-empty. Theorem 9 makesfirst steps direction, suggesting problem may easier overlapping settingclassic setting: indeed, Elkind et al. (2008) conjecture WVGs coalitionstructures checking non-emptiness core hard unary weights.Now, hardness results computing allocation core checking core nonempty traditional settingas work Chvatal (1978), Tamir (1991), DengPapadimitriou (1994), Sandholm et al. (1999), Conitzer Sandholm (2006)and hardnessresults paper suggest one hope identify special classes gamesefficient algorithms computing core allocations. noted earlier, element coreconvex games computed traditional setting simply taking vector marginalcontributions agents arbitrary permutation set agents. setting, eventhough proof yields procedure constructing element c-core, requires solvingseries optimization questions, arbitrary convex games NP-hard. Naturally, woulddesirable find classes convex games proof yields polynomial time algorithm.also interested finding processes lead core necessarily convex games;though randomized algorithms ones Dieckmann Schwalbe (1998) Chalkiadakis Boutilier (2004) trivially extend overlapping setting, would little practical value due huge space potential overlapping configurations. Therefore,interested finding ways exploit known game structure prune search space potentialstable configurations. Another subject future research extending model allow infinitecoalition structures. Furthermore, would interesting establish links outcomescore outcomes bargaining equilibria overlapping coalitional bargaining games.212fiC OOPERATIVE G AMES OVERLAPPING C OALITIONSFinally, incorporation actions model allows investigation action stochasticity and, generally, uncertainty OCF setting. instance, coalitional actionassociated distribution possible payoff outcomes resulting execution.poses challenges study models theoretical practical standpoint, sinceintroduction uncertainty leads several intricacies readily resolved use deterministic concepts models, work Suijs Borm (1999), Suijs, Borm, Wagenaere, Tijs(1999), Blankenburg, Klusch, Shehory (2003), Chalkiadakis Boutilier (2004) Chalkiadakis, Markakis, Boutilier (2007) demonstrates. related note, enriching model description capture type uncertainty (Chalkiadakis & Boutilier, 2004; Chalkiadakis et al.,2007) would allow ready translation uncertainty regarding types (capabilities) players coalitional value uncertainty, still capturing potential stochasticity coalitionalaction outcomes time.11. Acknowledgmentswould like thank anonymous reviewers constructive comments. researchsupported ALADDIN (Autonomous Learning Agents Decentralised Data InformationNetworks) project, jointly funded BAE Systems EPSRC strategic partnership(EP/C548051/1); well EPSRC (GR/T10664/01), ESRC (ES/F035845/1), SingaporeNRF Research Fellowship 2009-08.Appendix A. Algorithmic Aspects Social Welfare Maximization TTGsappendix, study complexity finding social welfare-maximizing outcome TTGs,overlapping non-overlapping scenario. Unless explicitly mentioned otherwise,make standard assumption parameters description TTG (i.e., agentsweights, thresholds task utilities), integers given binary.hard see finding non-overlapping coalition structure maximizes socialwelfare NP-hard problem.Proposition 8. Given TTG G = (N ; w; t) parameter K, NP-complete decide Goutcome (CS , p) v(CS ) K. holds even one task type, i.e., = t1 ,weights, thresholds utilities given unary.Proof. easy see problem NP. show NP-hardness, give reduction 3PARTITION (Garey & Johnson, 1990) problem. instance 3-PARTITION givenP3 listnon-negative integers = (a1 , . . . , a3 ) integer parameter B satisfies i=1 = BB/4 < ai < B/2 = 1, . . . , 3. yes-instance elementspartitioned sets S1 , . . . , a(S1 ) = = a(S ) = B no-instanceotherwise.Given instance 3-PARTITION, consider TTG G N = {1, . . . , 3}, wi = ai= 1, . . . , 3 single task type = (T, u) = B u = 1. Clearly, deciding whethermaximum social welfare achievable G least equivalent checking whether giveninstance 3-PARTITION yes-instance. Moreover, since 3-PARTITION known remainNP-hard input given unary, true problem.213fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGScontrast, finding social welfare-maximizing coalition structure OCF game corresponds TTG somewhat easier problem. Indeed, simply add together agentsweights, find optimal set tasks execute given amount resource. latterproblem equivalent U NBOUNDED K NAPSACK, known NP-hard inputsgiven binary, polynomial-time solvable elements input given unary2 items; details, see (Martello & Toth, 1990), Section 3.6. Consequently,similar conclusion holds problem.Proposition 9. Given TTG G = (N ; w; t) parameter K, NP-complete decideG outcome (CS , x) v(CS) K. However, problem becomes polynomial-timesolvable weights, thresholds utilities given unary 2 task types.ReferencesAlbizuri, M., Aurrecoechea, J., & Zarzuelo, J. (2006). Configuration values: Extensionscoalitional Owen value. Games Economic Behavior, 57, 117.Apt, K., & Radzik, T. (2006). Stable partitions coalitional games.. Working Paper, availablehttp://arxiv.org/abs/cs.GT/0605132.Apt, K., & Witzel, A. (2009). generic approach coalition formation. International GameTheory Review (IGTR), 11, 347367.Aubin, J.-P. (1981). Cooperative fuzzy games. Mathematics Operations Research, 6(1), 113.Aumann, R., & Dreze, J. (1974). Cooperative games coalition structures. International JournalGame Theory, 3(4), 217237.Bachrach, Y., & Rosenschein, J. (2007). Computing Banzhaf power index network flowgames. Proc. 6th International Conference Autonomous Agents MultiagentSystems (AAMAS-07), pp. 335341.Bachrach, Y., & Rosenschein, J. (2008). Coalitional skill games. Proc. 7th InternationalConference Autonomous Agents Multiagent Systems (AAMAS-08), pp. 10231030.Blankenburg, B., Klusch, M., & Shehory, O. (2003). Fuzzy kernel-stable coalitions rationalagents. Proc. 2nd International Conference Autonomous Agents MultiagentSystems (AAMAS-03), pp. 916.Bondareva, O. N. (1963). applications linear programming methods theory cooperative games (in russian). Problemy Kibernetiki, 10, 119139.Branzei, R., Dimitrov, D., & Tijs, S. (2005). Models cooperative game theory. Springer.Branzei, R., Dimitrov, D., & Tijs, S. (2003). Convex fuzzy games participation monotonicallocation schemes. Fuzzy Sets Systems, 139(2), 267281.Chalkiadakis, G., & Boutilier, C. (2004). Bayesian reinforcement learning coalition formationuncertainty. Proc. 3rd International Conference Autonomous AgentsMultiagent Systems (AAMAS-04), pp. 10901097.Chalkiadakis, G., Elkind, E., Markakis, E., & Jennings, N. R. (2008). Overlapping coalition formation. Proc. 4th International Workshop Internet Network Economics(WINE-08), pp. 307 321.214fiC OOPERATIVE G AMES OVERLAPPING C OALITIONSChalkiadakis, G., Markakis, E., & Boutilier, C. (2007). Coalition formation uncertainty:Bargaining equilibria Bayesian core stability concept. Proc. 6th InternationalConference Autonomous Agents Multiagent Systems (AAMAS-07), pp. 400407.Chvatal, V. (1978). Rational behavior computational complexity.. Technical Report SOCS-78.9,School Computer Science, McGill University, Montreal.Conconi, P., & Perroni, C. (2001). Issue linkage issue tie-in multilateral negotiations.. CESifoWorking Paper No. 601.Conitzer, V., & Sandholm, T. (2006). Complexity constructing solutions core basedsynergies among coalitions. Artificial Intelligence, 170(6-7), 607619.Dang, V. D., Dash, R. K., Rogers, A., & Jennings, N. R. (2006). Overlapping coalition formationefficient data fusion multi-sensor networks. Proc. 21st National ConferenceAI (AAAI-06), pp. 635640.Deng, X., & Papadimitriou, C. (1994). complexity cooperative solution concepts. Mathematics Operation Research, 19, 257266.Dieckmann, T., & Schwalbe, U. (1998). Dynamic coalition formation core.. EconomicsDepartment Working Paper Series, Department Economics, National University Ireland- Maynooth.Elkind, E., Chalkiadakis, G., & Jennings, N. R. (2008). Coalition structures weighted votinggames. Proc. 18th European Conference Artificial Intelligence (ECAI-2008), pp.393 397.Elkind, E., Goldberg, L. A., Goldberg, P. W., & Wooldridge, M. (2009). Computational complexityweighted voting games. Annals Mathematics Artificial Intelligence, 2(56), 109131.Garey, M. R., & Johnson, D. S. (1990). Computers Intractability; Guide TheoryNP-Completeness. W. H. Freeman & Co.Gillies, D. (1953). Theorems n-Person Games. Ph.D. thesis, Department Mathematics,Princeton University, Princeton.Greco, G., Malizia, E., Palopoli, L., & Scarcello, F. (2009). complexity compact coalitional games. Proc. 21st International Joint Conference Artificial Intelligence(IJCAI-09), pp. 147152.Ieong, S., & Shoham, Y. (2005). Marginal contribution nets: compact representation schemecoalitional games. Proc. Sixth ACM Conference Electronic Commerce (ACMEC05), pp. 193202.Manisterski, E., Sarne, D., & Kraus, S. (2008). Cooperative search concurrent interactions.Journal Artificial Intelligence Research (JAIR), 32(136).Martello, S., & Toth, P. (1990). Knapsack Problems: Algorithms Computer Implementations.John Wiley & Sons.Myerson, R. (1991). Game Theory: Analysis Conflict. Harvard University Press.Osborne, M., & Rubinstein, A. (1994). course game theory. MIT Press.Owen, G. (1977). Values games priori unions. Henn, R., & Moeschlin, O. (Eds.),Mathematical Economics Game Theory, pp. 7687. Springer-Verlag.215fiC HALKIADAKIS , E LKIND , ARKAKIS , P OLUKAROV & J ENNINGSPatel, J., Teacy, W., Jennings, N. R., Luck, M., Chalmers, S., Oren, N., Norman, T., Preece, A., Gray,P., Shercliff, G., Stockreisser, P., Shao, J., Gray, W., Fiddian, N., & Thompson, S. (2005).Agent-based virtual organisations Grid. Multiagent Grid Systems, 1(4), 237249.Peeters, R. (2003). maximum edge biclique problem NP-complete. Discrete Applied Mathematics, 131(3), 651654.Rahwan, T., Ramchurn, S., Jennings, N. R., & Giovannucci, A. (2009). anytime algorithmoptimal coalition structure generation. Journal Artificial Intelligence Research (JAIR),34(521567).Sandholm, T., Larson, K., Andersson, M., Shehory, O., & Tohme, F. (1999). Coalition structuregeneration worst case guarantees. Artificial Intelligence, 111(12), 209238.Sandholm, T., & Lesser, V. (1997). Coalitions among computationally bounded agents. ArtificialIntelligence, 94(1), 99137.Schrijver, A. (1986). Theory Linear Integer Programming. John Wiley & Sons.Shapley, L. S. (1967). balanced sets cores. Naval Research Logistics Quarterly, 14, 453460.Shapley, L. (1953). value n-person games. Kuhn, H., & Tucker, A. (Eds.), ContributionsTheory Games II, pp. 307317. Princeton University Press, Princeton.Shapley, L. (1971). Cores convex games. International Journal Game Theory, 1, 1126.Shehory, O., & Kraus, S. (1996). Formation overlapping coalitions precedence-ordered taskexecution among autonomous agents. Proc. 2nd International Conference MultiAgent Systems (ICMAS-96), pp. 330337.Shehory, O., & Kraus, S. (1998). Methods task allocation via agent coalition formation. ArtificialIntelligence, 101(12), 165200.Suijs, J., & Borm, P. (1999). Stochastic cooperative games: superadditivity, convexity certaintyequivalents. Journal Games Economic Behavior, 27, 331345.Suijs, J., Borm, P., Wagenaere, A. D., & Tijs, S. (1999). Cooperative games stochastic payoffs.European Journal Operational Research, 113, 193205.Tamir, A. (1991). core network synthesis games. Mathematical Programming, 50, 123135.von Neumann, J., & Morgenstern, O. (1944). Theory Games Economic Behavior. PrincetonUniversity Press, Princeton.216fiJournal Artificial Intelligence Research 39 (2010) 51-126Submitted 4/10; published 9/10Implicit Abstraction HeuristicsMichael KatzCarmel Domshlakdugi@tx.technion.ac.ildcarmel@ie.technion.ac.ilFaculty Industrial Engineering & Management,Technion, IsraelAbstractState-space search explicit abstraction heuristics state art costoptimal planning. heuristics inherently limited, nonetheless, sizeabstract space must bounded some, even large, constant. Targetingshortcoming, introduce notion (additive) implicit abstractions,planning task abstracted instances tractable fragments optimal planning.introduce concrete setting framework, called fork-decomposition,based two novel fragments tractable cost-optimal planning. induced admissibleheuristics studied formally empirically. study testifies accuracyfork decomposition heuristics, yet empirical evaluation also stresses tradeoffaccuracy runtime complexity computing them. Indeed,power explicit abstraction heuristics comes precomputing heuristicfunction offline determining h(s) evaluated state fast lookupdatabase. contrast, fork-decomposition heuristics calculatedpolynomial time, computing far fast. address problem,show time-per-node complexity bottleneck fork-decomposition heuristicssuccessfully overcome. demonstrate equivalent explicit abstractionnotion database exists fork-decomposition abstractions well, despiteexponential-size abstract spaces. verify empirically heuristic searchdatabased fork-decomposition heuristics favorably competes state artcost-optimal planning.1. IntroductionHeuristic search, either progression space world states regression space subgoals, common successful approach classical planning.probably popular approach cost-optimal planning, is, finding planminimal total cost actions. difference various heuristic-searchalgorithms optimal planning mainly admissible heuristic functions employ.state-space search, heuristic estimates cost achieving goal givenstate guarantees overestimate cost.useful heuristic function must accurate well efficiently computable. Improvingaccuracy heuristic function without substantially worsening time complexitycomputing usually translates faster search optimal solutions. lastdecade, numerous computational ideas evolved new admissible heuristics classicalplanning; include delete-relaxing max heuristic hmax (Bonet & Geffner, 2001), critical path heuristics hm (Haslum & Geffner, 2000), landmark heuristics hL , hLA (Karpas &Domshlak, 2009) hLM-cut (Helmert & Domshlak, 2009), abstraction heuristicsc2010AI Access Foundation. rights reserved.fiKatz & Domshlakpattern database heuristics (Edelkamp, 2001) merge-and-shrink heuristics (Helmert,Haslum, & Hoffmann, 2007). focus work abstraction heuristics.Generally speaking, abstraction planning task given mapping :states planning tasks transition system states abstracttransition system that, states s, s0 S, cost (s) (s0 ) upperbounded cost s0 . abstraction heuristic value h (s) cost(s) closest goal state abstract transition system. Perhaps well-knownabstraction heuristics pattern database (PDB) heuristics, based projectingplanning task onto subset state variables explicitly searching optimalplans abstract space. years, PDB heuristics showneffective several hard search problems, including cost-optimal planning (Culberson &Schaeffer, 1998; Edelkamp, 2001; Felner, Korf, & Hanan, 2004; Haslum, Botea, Helmert,Bonet, & Koenig, 2007). conceptual limitation heuristics, however,size abstract space dimensionality must fixed.1 recent merge-andshrink abstractions generalize PDB heuristics overcome latter limitation (Helmertet al., 2007). Instead perfectly reflecting state variables, merge-and-shrinkabstractions allow imperfectly reflecting variables. demonstrated formalempirical analysis Helmert et al., flexibility often makes merge-and-shrinkabstractions much effective PDBs. However, merge-and-shrink abstractspaces still searched explicitly, thus still fixed size. qualityheuristics estimates still obtained many problems, limitation criticalobstacle many others.goal paper push envelope abstraction heuristics beyond explicitabstractions. introduce principled way obtain abstraction heuristics limit neither dimensionality size abstract spaces. basic idea behindcall implicit abstractions simple intuitive: instead relying abstract problemseasy solve small, rely abstract problems belongingprovably tractable fragments optimal planning. key point that, least theoretically, moving implicit abstractions removes requirement abstractions sizesmall. contribution, however, showing implicit abstractions fartheoretical interest only. Specifically,1. specify acyclic causal-graph decompositions, general framework additive implicit abstractions based decomposing problem hand along causalgraph. introduce concrete family abstractions, called fork decompositions, based two novel fragments tractable cost-optimal planning.Following type analysis suggested Helmert Mattmuller (2008), formally analyze asymptotic performance ratio fork-decomposition heuristicsprove worst-case accuracy selected domains comparable(even parametric) state-of-the-art admissible heuristics. empirically evaluate accuracy fork-decomposition heuristics large set domainsrecent planning competitions show accuracy competitivestate art.1. necessarily apply symbolic PDBs which, tasks, may exponentially reducePDBs representation (Edelkamp, 2002).52fiImplicit Abstraction Heuristics2. key attraction explicit abstractions state-to-goal costs abstractspace precomputed stored memory preprocessing phaseheuristic evaluation search done simple lookup. necessary condition would seem small size abstract space. However,show equivalent PDB merge-and-shrinks notion databaseexists fork-decomposition abstractions well, despite exponential-size abstract spaces latter. databased implicit abstractions based properpartitioning heuristic computation parts shared searchstates parts must computed online per state. empirical evaluationshows equipped databased fork-decomposition heuristics favorablycompetes state art cost-optimal planning.work revision extension formulation results presented KatzDomshlak (2008, 2009), turn based ideas first sketched also KatzDomshlak (2007a).2. Preliminariesconsider classical planning tasks corresponding state models single initial statedeterministic actions. Specifically, consider state models captured sas+formalism (Backstrom & Nebel, 1995) nonnegative action costs. planning taskgiven quintuple = hV, A, I, G, costi, where:V set state variables, v V associated finite domainD(v). subset variables V 0 V , denote set assignments V 0D(V 0 ) = vV 0 D(v). complete assignment V called state, = D(V )state space . initial state. goal G partial assignment V ;state goal state iff G s.finite set actions. action pair hpre(a), eff(a)i partial assignmentsV called preconditions effects, respectively. Av denote actionsaffecting value v. cost : R0+ real-valued, nonnegative action costfunction.variable v value D(v), instantiation v denoted v : .partial assignment p, V(p) V denotes subset state variables instantiated p.turn, V 0 V(p), p[V 0 ] denote value V 0 p; V 0 = {v} singleton,use p[v] p[V 0 ]. sequence actions variable v V , v denoterestriction actions changing value v; is, v maximal subsequenceconsisting actions Av .action applicable state iff s[v] = pre(a)[v] v V(pre(a)). Applyingchanges value v V(eff(a)) eff(a)[v]. resulting state denoted sJaK;sJha1 , . . . , ak iK denote state obtained sequential application (respectivelyapplicable) actions a1 , . . . , ak starting state s. action sequence s-planG sJha1 , . . . , ak iK, cost-optimal (or, follows, optimal) s-plansum action costs minimal among s-plans. purpose (optimal) planningfinding (optimal) I-plan. pair states s1 , s2 S, cost(s1 , s2 ) refer53fiKatz & Domshlakp2Bc2Fcc1ccEpc3CpGp1(a)(b)cBFECEBCEFGGc(c)c(d)Figure 1: Logistics-style example adapted Helmert (2006) illustrated (a).goal deliver p1 C G p2 F E using cars c1 , c2 , c3truck t, making sure c3 ends F . cars may use city roads (thinedges); truck may use highway (thick edge). Figures (b), (c),(d) depict, respectively, causal graph problem, domain transitiongraphs (labels omitted) c1 c2 (left), (center), c3 (right),identical domain transition graphs p1 p2 .cost cost-optimal plan s1 s2 ; h (s) = mins0 G cost(s, s0 ) custom notationcost optimal s-plan . Finally, important roles follows playedpair standard graphical structures induced planning tasks.causal graph CG() digraph nodes V . arc (v, v 0 ) CG()iff v 6= v 0 exists action (v, v 0 ) V(eff(a)) V(pre(a))V(eff(a)). case, say (v, v 0 ) induced a. succ(v) pred(v)respectively denote sets immediate successors predecessors v CG().domain transition graph DTG(v, ) variable v V arc-labeled digraphnodes D(v) arc (, 0 ) labeled pre(a)[V \ {v}] cost(a)exists graph iff eff(a)[v] = 0 , either pre(a)[v] = v 6 V(pre(a)).illustrate various constructs, use slight variation Logistics-style exampleHelmert (2006). example depicted Figure 1a, sas+54fiImplicit Abstraction HeuristicsV= {p1 , p2 , c1 , c2 , c3 , t}D(p1 ) = D(p2 ) = {A, B, C, D, E, F, G, c1 , c2 , c3 , t}D(c1 ) = D(c2 ) = {A, B, C, D}D(c3 ) = {E, F, G}D(t) = {D, E}= {p1 : C, p2 : F, : E, c1 : A, c2 : B, c3 : G}G = {p1 : G, p2 : E, c3 : F },actions corresponding possible loads unloads, well single-segment movements vehicles. instance, action captures loading p1 c1 C,pre(a) = {p1 : C, c1 : C}, eff(a) = {p1 : c1 }. actions example unit cost.causal graph example, well domain transition graphs statevariables, depicted Figures 1b-1d.Heuristic functions used informed-search procedures estimate cost (ofcheapest path) search node nearest goal node. focus statedependent, admissible abstraction heuristics. heuristic function h state-dependentestimate search node depends problem state associated node,is, h : R0+ {}. heuristics use days state-dependent (thoughsee, e.g., Richter, Helmert, & Westphal, 2008 Karpas & Domshlak, 2009 differentcase). heuristic h admissible h(s) h (s) states s. h1 h2 twoadmissible heuristics, h2 (s) h1 (s) states s, say h1 dominates h2 .set admissible heuristics h1 , . . . , hm , pointwise maximum alwaysadmissible heuristic, dominating individual heuristic set. sets admissible heuristics, pointwise sum also admissible dominates pointwisemaximum. Many recent works cost-optimal planning based additive ensembles admissible heuristics, includes critical-path heuristics (Haslum, Bonet, &Geffner, 2005; Coles, Fox, Long, & Smith, 2008), pattern database heuristics (Edelkamp,2001; Haslum et al., 2007), landmark heuristics (Karpas & Domshlak, 2009; Helmert &Domshlak, 2009). particular, Katz Domshlak (2007a, 2008) Yang et al. (2007,2008) independently introduced general criterion admissible additive ensemblesheuristics, called former work action cost partitioning. criterion formalized follows. Let = hV, A, I, G,planning task {costi : R0+ }mi=1Pcostifamily cost functions i=1 costi (a) cost(a) actions A. {hi }mi=1setarbitraryadmissibleheuristicfunctions=hV,A,I,G,costi,respectively,Pi=1 hi also admissible heuristic . set cost functions {costi }i=1seen partition action costs cost.3. Abstractions Abstraction Heuristicssemantics planning task given induced state-transition model, oftencalled transition graph .55fiKatz & DomshlakDefinition 1 transition graph tuple = (S, L, Tr, s0 , ? , $) finiteset states, L finite set transition labels, Tr L set (labeled)transitions, s0 initial state, ? set goal states, $ : L R0+transition cost function.state subset states 0 T, cost(s, 0 ) cost (ofcheapest respect $ path) state 0 along transitions T;state 0 reachable s, cost(s, 0 ) = .path s0 ? plan T, cheapest plans called optimal.states transition graph T() induced planning task = hV, A, I, G, costistates . transition labels T() actions A; transition(s, a, sJaK) Tr iff applicable s; initial state s0 = I; set goal states? = {s | G}; transition cost function $ = cost.proceedformally specifying notion abstraction. definition abstraction resemblesPrieditis (1993), right beginning specify general notionadditive abstraction. Informally, additive abstraction refer set abstractionsinterconstrained requirement jointly overestimate transition-path costsabstracted transition graph.Definition 2 additive abstraction transition graph = (S, L, Tr, s0 , ? , $)set pairs {hTi , i}mi=1 where, 1 m,Ti = (Si , Li , Tri , s0i , Si? , $i ) transition graph,: Si function, called abstraction mapping,(s0 ) = s0i , (s) Si? ? , and,pairs states s, s0 holdsXi=1cost(i (s), (s0 )) cost(s, s0 ).(1)words use particular notion abstraction. term abstractionusually associated simplifying original system, reducing factoring detailsless crucial given context. details reduced betterpreserved depends, course, context. instance, context formalverification, abstract transition graphs required decrease reachabilitystates; is, path s0 original transition graph,path (s) (s0 ) abstract transition graph (Clarke,Grumberg, & Peled, 1999). addition, reachability also increased littlepossible. Beyond that, precise relationship path costs originalabstract transition graphs secondary importance. contrast, abstractionsdesigned induce admissible heuristic functions heuristic search, relationshippath costs captured Eq. 1 must obeyed. However, requirementsbeyond general requirement Eq. 1 overestimate distances56fiImplicit Abstraction Heuristicsstates unnecessary. Hence, particular, Definition 2 generalizes notionabstraction Helmert et al. (2007) replacing condition preserving individualtransitions labels, is, ((s), l, (s0 )) (s, l, s0 ), weaker condition statedEq. 1. reader, course, may well ask whether generality conditionEq. 1 beyond condition Helmert et al. (2007) really delivers practical gain,later show answer question affirmative. now, proceedadding requirements essential making abstraction usable basis heuristicfunctions.Definition 3 Let planning task states S, let {hTi , i}mi=1 additiveabstraction transition graph T(). = O(poly(||||)) and, states1Pm, cost cost(i (s), Si? ) Ti computable time O(poly(||||)),?hA (s) =i=1 cost(i (s), Si ) abstraction heuristic function .Note admissibility hA implied cost conservation condition Eq. 1. illustrate connection abstractions admissible heuristics, consider threewell-known mechanisms devising admissible planning heuristics: delete relaxation (Bonet& Geffner, 2001), critical-path relaxation (Haslum & Geffner, 2000),2 pattern databaseheuristics (Edelkamp, 2001).First, typically considered way, delete relaxation planning task? , $ ),= hV, A, I, G, costi correspond abstraction hT+ = (S+ , L+ , Tr+ , s0+ , S+++transitiongraphT().AssuminguniquenamingvariablevaluesdeSnoting D+ = vV D(v), abstract states S+ power-set D+ ,labels L+ = {a, a+ | A}. transitions come two sources: abstract states+ S+ original action applicable s+ , (s+ , a, s+ JaK) Tr+(s+ , a+ , s+ eff(a)) Tr+ . minor abuse notation, initial state? = {s | G}, abstractiongoal states abstraction s0+ = S++++mapping + simply identity function. easy show that, state? ) = h+ (s), h+ (s) delete-relaxationplanning task , cost(+ (s), S+estimate cost goal. aside, note delete-relaxationabstraction hT+ , + particular exemplifies nothing Definition 2 requiressize abstract state space limited size original state space.event, however, abstraction hT+ , + induce heuristic terms Definition 3computing h+ (s) known NP-hard (Bylander, 1994).situation critical-path relaxation exactly opposite. computingcorresponding family admissible estimates hm polynomial-time fixed m,computation based computing shortest paths abstractionplanning task. state graph hm computed AND/OR-graph (andOR-graph transition graphs), actual computation hm correspondscomputing critical tree (and shortest path) goal. bestknowledge, precise relation critical path abstraction heuristics currentlyopen question (Helmert & Domshlak, 2009).Overall, abstraction heuristics toolbox planning days appearexplicit homomorphism abstractions, whose best-known representative probably2. assume reader familiar two relaxations. not, discussion safelyskipped.57fiKatz & Domshlakpattern database (PDB) heuristics. Given planning task state variables V ,PDB heuristic based projecting onto subset variables V V .homomorphism abstraction maps two states s1 , s2 abstract state iffs1 [V ] = s2 [V ]. Inspired (similarly named) domain-specific heuristics searchproblems (n2 1)-puzzles Rubiks Cube (Culberson & Schaeffer, 1998; Hernadvolgyi & Holte, 1999; Felner et al., 2004), PDB heuristics successfully exploited domain-independent planning well (Edelkamp, 2001, 2002; Haslum et al.,2007). key decision constructing PDBs sets variables problemprojected (Edelkamp, 2006; Haslum et al., 2007). However, apart needautomatically select good projections, two limitations PDB heuristics sizeabstract space dimensionality. First, number abstract statessmall enough allow reachability analysis exhaustive search. Moreover,O(1) bound |S | typically set explicitly fit time memory limitationssystem. Second, since PDB abstractions projections, explicit constraint |S |implies fixed-dimensionality constraint |V | = O(1). planning tasks with, informally,many alternative resources, limitation pitfall. instance, suppose {i }i=1sequence Logistics problems growing size |Vi | = i. packagetransported (i) vehicles, starting i, h accountmovements vehicles essential solving (Helmert & Mattmuller, 2008).Aiming preserving attractiveness PDB heuristic eliminating bottleneck fixed dimensionality, Helmert et al. (2007) generalized methodologyDrager, Finkbeiner, Podelski (2006) introduced called merge-and-shrink(MS) abstractions planning. MS abstractions homomorphisms generalize PDBabstractions allowing flexibility selection pairs states contracted.problems state space viewed synchronized product projections ontosingle state variables. Starting atomic abstractions, productcomputed iteratively composing two abstract spaces, replacing product.PDB size abstract space controlled limiting numberproduct compositions, MS abstractions controlled interleaving iterative composition projections abstraction partial composites. Helmert et al. (2007)proposed concrete strategy interleaved abstraction/refinement scheme empirically demonstrated power merge-and-shrink abstraction heuristics. Like PDBs,however, MS abstractions explicit abstractions, thus computing heuristic values also based explicitly searching optimal plans abstract spaces. Hence,merge-and-shrink abstractions escape fixed-dimensionality constraint PDBs,constraint abstract space fixed size still holds.4. Implicit AbstractionsFocusing O(1) bound posted explicit abstractions size abstractspace, first observation explicit abstractions necessarily wayproceed abstraction heuristics. Given planning task states S, supposetransform different planning task1. transformation induces abstraction mapping : statespace ,58fiImplicit Abstraction Heuristics2. transformation , well computing state S,done time polynomial ||||.planning-task-to-planning-task transformations mind, definecall (additive) implicit abstractions.Definition 4 additive implicit abstraction planning task set pairs= {hi , i}mi=1 {i }i=1 planning tasks {hT(i ), i}i=1additive abstraction T().Let us examine notion implicit abstractions closely. First, implicitabstractions allow natural additive combination admissible heuristics abstracttasks. composition formulated Theorem 1, extending original criterionadmissibility additive heuristics described Section 2. Second, formulatedTheorem 2, implicit abstractions composed via functional compositionabstraction mappings. two easy-to-prove properties implicit abstractions allow ustake desired step implicit abstractions implicit abstraction heuristics.Theorem 1 (Admissibility) Let planning task = {hi , i}mi=1 additive implicit abstraction.If,1m,hadmissibleheuristic,Pmfunction h(s) = i=1 hi (i (s)) admissible heuristic .Proof: proof straightforward. Let = (S, L, Tr, s0 , ? , $) transition graph, let state S. 1 m, let Ti = (Si , Li , Tri , s0i , Si? , $i )transition graph .First, hi admissible heuristic , si Si? ,hi (i (s)) cost(i (s), si ).Now, state s0 ? , Definition 2 (s0 ) Si? , Eq. 1Xi=1thush(s) =Xi=1cost(i (s), (s0 )) cost(s, s0 ),hi (i (s))giving us admissible estimateXi=1h (s).cost(i (s), (s0 )) cost(s, s0 ),Theorem 2 (Composition) Let planning task = {hi , i}mi=1 addimitive implicit abstraction . If,i,j , i,j i}j=1 additive1 m, Ai = m{himplicit abstraction , A0 ={h,i}additive implicit abi,ji,jj=1i=1straction .Proof: Let = (S, L, Tr, s0 , ? , $) transition graph . 1 m,let Ti = (Si , Li , Tri , s0i , Si? , $i ) transition graph , 1 j mi , let? , $ ) transition graph . need showTi,j = (Si,j , Li,j , Tri,j , s0i,j , Si,ji,ji,ji,j abstraction mapping Definition 2. i,j abstractionmappings,59fiKatz & Domshlaks0i,j = i,j (s0i ) = i,j (i (s0 )) = i,j (s0 ),? ,? (s) Si? thus i,j (i (s)) = i,j (s) Si,jP00si , s0i Si , cost(si , s0i )j=1 cost(i,j (si ), i,j (si )), thus s, S,cost(s, s0 )Xi=1cost(i (s), (s0 ))=miXXi=1 j=1miXXi=1 j=1cost(i,j (i (s)), i,j (i (s0 )))cost(i,j (s), i,j (s0 )).Together, Theorems 1 2 suggest following scheme deriving abstraction heuristics. Given additive implicit abstraction = {hi , i}mi=1 , individual abstracttasks belong tractable fragments optimal planning, use practice(sum the) true costs admissible estimates costs . Otherwise, optimal planning abstract tasks cannot proven polynomial-timesolvable, abstract tasks, obtaining admissible estimatestrue costs .Definition 5 Let planning task states S, let = {hi , i}mi=1additive implicit abstraction . = O(poly(||||)), and, allPstates1 m, h (i (s)) polynomial-time computable, hA (s) =i=1 h (i (s))implicit abstraction heuristic function .Compared explicit abstraction heuristics PDB heuristics merge-andshrink heuristics, direction implicit abstraction heuristics is, least principle,appealing neither dimensionality even size state spaces inducedimplicit abstractions required bounded something restrictive, all.pitfall, however, implicit abstraction heuristics correspond tractable fragmentsoptimal planning, palette known fragments extremely limited (Backstrom& Nebel, 1995; Bylander, 1994; Jonsson & Backstrom, 1998; Jonsson, 2007; Katz & Domshlak, 2007b). fact, none far appeared us convenient automatically devising useful problem transformations above. Fortunately, show next boundariestractability expanded right way, allowing us successfully materializeidea implicit abstraction heuristics.following, key role played causal graphs induced planningtasks. Informally, basic idea behind call causal-graph decompositionsabstract given planning task along subgraph causal graph, goalobtaining abstract problems specific structure. Naturally, numerous possibilitiesobtaining structure-oriented abstractions. present one decompositiontailored abstractions around acyclic subgraphs. Informally, decompositionseen sequential application two kinds task transformations: droppingpreconditions (Pearl, 1984) (certain form of) breaking actions conjunctive effectssingle-effect actions.60fiImplicit Abstraction HeuristicsDefinition 6 Let = hV, A, I, G, costi planning task, let G = (VG , EG )acyclic subgraph causal graph CG(). planning task G = hVG , AG , IG , GG , costGacyclic causal-graph decomposition respect G1. IG = I[VG ], GG = G[VG ],2. AG = aA AG (a) AG (a) = {a1 , . . . , al(a) } set actions VGthat, topological respect G ordering variables {v1 , . . . , vl(a) } =V(eff(a)) VG , 1 l(a),(eff(a)[v],v = vieff(a )[v] =unspecified, otherwise(2)(v, vi ) EG v 6 V(eff(a)) v = vipre(a)[v],pre(ai )[v] = eff(a)[v],(v, vi ) EG v V(eff(a))unspecified, otherwise3. action A,Xa0 AG (a)costG (a0 ) cost(a).(3)hard verify Definition 6 planning task acycliccausal-graph decomposition G , causal graph CG(G ) exactly subgraph G underlying decomposition. illustrate notion acyclic causal-graph decomposition,consider planning task = hV, A, I, G, costi five state variables V = {u, v, x, y, z},two unit-cost actions = {a1 , a2 } Figure 2a, initial state = {u : 0, v : 0, x : 0, : 0, z : 0},goal G = {u : 1, v : 1, x : 0, : 1, z : 1}. causal graph CG() depicted Figure 2a.Figures 2b-c show two subgraphs G1 G2 CG(), respectively, well action sets AG1 (a1 ) = {a11 , a21 , a31 } AG1 (a2 ) = {a12 , a22 , a32 } Figure 2(b), actionsets AG2 (a1 ) = {a11 , a21 , a31 } AG2 (a2 ) = {a12 , a22 , a32 } Figure 2(c). {1, 2}, let= hV, Ai , I, G, costi planning task Ai = AGi (a1 )AGi (a2 ) costi (a) = 1/3Ai . two planning tasks (individually) satisfy conditions Definition 6 respect Gi , thus acyclic causal-graph decompositionsrespect Gi .proceed specifying implicit abstractions defined via acyclic causal-graphdecompositions.Definition 7 Let = hV, A, I, G, costi planning task states S, let G = {Gi =(VGi , EGi )}mi=1 set acyclic subgraphs causal graph CG(). = {hGi , i}i=1acyclic causal-graph abstraction G if, set cost functions{costi : R0+ }mi=1 satisfying:Xi=1costi (a) cost(a),have, 1 m,61(4)fiKatz & Domshlaka1 = h{x : 0, : 0, z : 0}, {x : 1, : 1, z : 1}ia11 = h{x : 0}, {x : 1}ia21 = h{x : 1, : 0}, {y : 1}ia31 = h{x : 1, z : 0}, {z : 1}ia11 = h{y : 0}, {y : 1}ia21 = h{z : 0}, {z : 1}ia31 = h{y : 1, z : 1, x : 0}, {x : 1}ia2 = h{u : 0, v : 0, x : 1}, {u : 1, v : 1, x : 0}ia12 = h{x : 1}, {x : 0}ia22 = h{x : 0, u : 0}, {u : 1}ia32 = h{x : 0, v : 0}, {v : 1}ia12 = h{u : 0}, {u : 1}ia22 = h{v : 0}, {v : 1}ia32 = h{u : 1, v : 1, x : 1}, {x : 0}iua1a2xa2a2xa1a22a1vzua31a32 a21v(a)u(b)a32zva32a31za31x(c)Figure 2: (a) actions causal graph CG() planning graph exampleillustrating Definition 2. (b) Subgraph G1 CG() induced action setsAG1 (a1 ) AG1 (a2 ). (c) Subgraph G2 CG() induced action setsAG2 (a1 ) AG2 (a2 ). arcs CG() subgraphs G1 G2labeled actions inducing arcs.Gi = hVGi , AGi , IGi , GGi , costGi acyclic causal-graph decomposition =hV, A, I, G, costi respect Gi ,abstraction mapping : Si projection mapping (s) = s[VGi ].Theorem 3 Acyclic causal-graph abstractions planning tasks additive implicitabstractions tasks.Proof: Let = hV, A, I, G, costi planning task, let = {hGi , i}mi=1acyclic causal-graph abstraction set subgraphs G = {Gi = (VGi , EGi )}mi=1 .Let = (S, L, Tr, s0 , ? , $) transition graph , and, 1 m, Ti =(Si , Li , Tri , s0i , Si? , $i ) transition graph Gi . need show abstraction mapping Definition 2.First, Definitions 6 7,s0i = IGi = I[VGi ] = s0 [VGi ] = (s0 ),? G thus (s) = s[VGi ] G[VGi ] = GGi , providing us(s) Si? .Now, state action pre(a) s, (s) state Gipre(a)[VGi ] (s). Let action sequence = ha1 , a2 , . . . , al(a) constructedEq. 2. inductively prove applicable (s). First, v VGi ,either pre(a1 )[v] = pre(a)[v], pre(a1 )[v] unspecified, thus 1 = ha1 applicable(s). inductive hypothesis j = ha1 , a2 , . . . , aj applicable (s),0let s0 = (s)Jj K. Eq. 2, 1 j 0 j, aj changes value vj 0 eff(a)[vj 0 ],62fiImplicit Abstraction Heuristicschange vj 0 along j . Likewise, since actions constructedEq. 2 unary-effect, {v1 , . . . , vj } variables VGi affected along j . Hence,v VGi , v = vj 0 , 1 j 0 j, s0 [v] = eff(a)[v] = pre(aj+1 )[v], otherwise,s0 [v] = (s)[v], pre(aj+1 )[v] specified, pre(aj+1 )[v] = pre(a)[v] = (s)[v].implies aj+1 applicable s0 and, result, j+1 = ha1 , a2 , . . . , aj+1 applicable(s), finalizing inductive proof. Likewise, exactly arguments affectl(a){aj }j=1 (s) immediately imply that, = ha1 , a2 , . . . , al(a) i, (sJaK) = (s)JK.Next, A, Eqs. 3 4XXi=1 a0 AGi (a)costGi (a0 )Xi=1costi (a) cost(a).(5)Now, let s, s0 pair original states cost(s, s0 ) < , let % =0ha1 , . . . , ak sequencePk labels along cheapest path T. that,0cost(s, ) = cost(%) = j=1 cost(aj ). decomposition path sequencesactions Eq. 2 aP(not Pneccesarily cheapest) path (s) (s0 ) Ti ,k0thus cost(i (s), (s )) j=1 a0 AG (aj ) costGi (a0 ), providing usXi=10cost(i (s), (s ))(5)XkXX0costGi (a ) =i=1 j=1 a0 AGi (aj )kXk XXXcostGi (a0 )j=1 i=1 a0 AGi (aj )cost(aj ) = cost(s, s0 ).j=1Thus, decompose given task set tractable acyclic causalgraph decompositions = {G1 , . . . , Gm }, solve tasks polynomialtime, derive additive admissible heuristic . proceed consideringconcrete acyclic causal-graph decomposition, note Definition 2 leaves decisionactual partition action costs rather open. follows adoptstraightforward, uniform action cost partition theScost action equallysplit among non-redundant representativesi=1 AGi (a). However, betterchoice action cost partition sometimes made. fact, sometimes evenoptimized (Katz & Domshlak, 2010)5. Fork Decompositionsproceed introducing two concrete acyclic causal-graph decompositions that,combined certain variable domain abstractions, provide us implicit abstraction heuristics. called fork-decomposition heuristics based two novelfragments tractable cost-optimal planning tasks fork inverted-fork structuredcausal graphs.Definition 8 planning task variables V , variable v V ,63fiKatz & Domshlak(1) v-fork subgraph Gvf CG() nodes VGvf = {v} succ(v) edgesEGvf = {(v, u) | u succ(v)},(2) v-ifork (short inverted fork) subgraph Gvi CG() nodes VGvi ={v} pred(v) edges EGvi = {(u, v) | u pred(v)}.sets v-forks v-iforks denoted GF = {Gvf }vV GI ={Gvi }vV , respectively.planning task state variables v, v-fork v-iforkacyclic digraphs, allowing us define three implicit abstractions follows.Definition 9 planning task = hV, A, I, G, costi,(1) acyclic causal-graph abstraction AF = {hfv , vf i}vV GF calledF-abstraction, set abstract planning tasks F = {fv }vV calledF-decomposition ;(2) acyclic causal-graph abstraction AI = {hiv , vi i}vV GI calledI-abstraction, set abstract planning tasks = {iv }vV calledI-decomposition ;(3) acyclic causal-graph abstraction AFI = {hfv , vf i, hiv , vi i}vVGFI = GF GI called FI-abstraction, set abstract planning tasksFI = {fv , iv }vV called FI-decomposition .Definition 9 better understood considering FI-abstraction problemLogistics example; Figure 3 schematically illustrates process. simplifyexample, eliminate GFI single-node subgraphs, obtainingAFI = {hfc1 , cf 1 i, {hfc2 , cf 2 i, {hfc3 , cf 3 i, {hft , tf i, {hip1 , pi 1 i, {hip2 , pi 2 i}.Considering action sets problems FI = {fc1 , fc2 , fc3 , ft , ip1 , ip2 }, seeoriginal driving action one nonredundant (that is, changing variable)representative three abstract planning tasks, load/unload actionone nonredundant representative five tasks. instance, action drive-c1 from-A-to-D one nonredundant representative tasks {fc1 , ip1 , ip2 },action load-p1 -into-c1 -at-A one nonredundant representative tasks{fc1 , fc2 , fc3 , ft , ip1 }. Since assume uniform partition action costs, costdriving load/unload action relevant abstract planning task thus set1/3 1/5, respectively. Theorem 3 AFI additive implicitabstraction , Theorem 1XhFI =hf + hi ,(6)vvvVadmissible estimate h . question good estimate is.optimal cost solving running example 19. Taking reference well-knownadmissible heuristics hmax (Bonet & Geffner, 2001) h2 (Haslum & Geffner, 2000),hmax (I) = 8 h2 (I) = 13. Considering FI-abstraction, optimal planstasks FI follows.64fiImplicit Abstraction Heuristicsfc1 : load-p1 -into-c2 -at-C, unload-p1 -from-c2 -at-D, load-p1 -into-t-at-D,unload-p1 -from-t-at-E, load-p1 -into-c3 -at-E, unload-p1 -from-c3 -at-G,load-p2 -into-c3 -at-F, unload-p2 -from-c3 -at-E.fc2 : load-p1 -into-c1 -at-C, unload-p1 -from-c1 -at-D, load-p1 -into-t-at-D,unload-p1 -from-t-at-E, load-p1 -into-c3 -at-E, unload-p1 -from-c3 -at-G,load-p2 -into-c3 -at-F, unload-p2 -from-c3 -at-E.fc3 : load-p1 -into-c1 -at-C, unload-p1 -from-c1 -at-D, load-p1 -into-t-at-D,unload-p1 -from-t-at-E, drive-c3 -from-G-to-E, load-p1 -into-c3 -at-E,drive-c3 -from-E-to-G, unload-p1 -from-c3 -at-G, drive-c3 -from-G-to-E,drive-c3 -from-E-to-F, load-p2 -into-c3 -at-F, drive-c3 -from-F-to-E,unload-p2 -from-c3 -at-E, drive-c3 -from-E-to-F.ft : load-p1 -into-c1 -at-C, unload-p1 -from-c1 -at-D, drive-t-from-E-to-D,load-p1 -into-t-at-D, drive-t-from-D-to-E, unload-p1 -from-t-at-E,load-p1 -into-c3 -at-E, unload-p1 -from-c3 -at-G, load-p2 -into-c3 -at-F,unload-p2 -from-c3 -at-E.ip1 : drive-c1 -from-A-to-D, drive-c1 -from-D-to-C, load-p1 -into-c1 -at-C,drive-c1 -from-C-to-D, unload-p1 -from-c1 -at-D, drive-t-from-E-to-D,load-p1 -into-t-at-D, drive-t-from-D-to-E, unload-p1 -from-t-at-E,drive-c3 -from-G-to-E, load-p1 -into-c3 -at-E, drive-c3 -from-E-to-G,unload-p1 -from-c3 -at-G, drive-c3 -from-G-to-E, drive-c3 -from-E-to-F.ip2 : drive-c3 -from-G-to-E, drive-c3 -from-E-to-F, load-p2 -into-c3 -at-F,drive-c3 -from-F-to-E, unload-p2 -from-c3 -at-E, drive-c3 -from-E-to-F.Hence,hFI = hfc1=85+ hf+85+c2+hf85c3+63hf++85+23+hi+65p1+93+hf+25p2+43= 15,(7)hFI appears least promising.Unfortunately, despite seeming simplicity planning tasks FI , turnsimplicit fork-decomposition abstractions Definitions 9 fit requirementsimplicit abstraction heuristics Definition 5. causal graphs planningtasks F form directed forks directed inverted forks, respectively, and,general, number variables planning task large (|V |).problem even satisficing planning sas+ fragments fork invertedfork causal graphs NP-complete (Domshlak & Dinitz, 2001). fact, recent resultsChen Gimenez (2008) show planning sas+ fragment characterizednontrivial form causal graph NP-hard. Moreover, even domain transition graphsstate variables strongly connected (as example), optimal planningfork inverted fork structured problems remain NP-hard (see Helmert 2003, 2004respective results). Next, however, show end storyfork decompositions.65fiKatz & DomshlakBc1p2c2CG()Fc!p!Gp1c#Ec3Cc"p"{fv , iv }vVfc1c!p!c!p"c"c#ip1p!CG(CG(p1ip1))CG(fcfc11))CG(Figure 3: Schematic illustration FI-decomposition running Logistics examplehardness optimal planning problems fork inverted fork causalgraphs casts shadow relevance fork decompositions, closer look proofscorresponding hardness results Domshlak Dinitz (2001) Helmert (2003, 2004)reveals particular rely root variables large domains. Exploitingobservation, show reliance incidental characterize two substantialislands tractability within structural fragments sas+ .Theorem 4 (Tractable Forks) Given planning task = hV, A, I, G, costi forkcausal graph rooted r V , |D(r)| = 2, time complexity cost-optimal planningpolynomial ||||.Proof: Observe that, planning task theorem, fork structurecausal graph CG() implies actions unary-effect, leaf variablev succ(r) preconditions actions affecting v itself. algorithm basedfollowing three properties satisfied optimal plans .(i) leaf variable v succ(r), path v I[v] G[v] inducedDTG(v, ) either cycle-free contains zero-cost cycles. caseotherwise nonzero-cost cycles eliminated v preservingvalidity, violating assumed optimality . Without loss generality,follows assume path v DTG(v, ) cycle-free; case forkcausal graphs, always select optimal satisfies requirementv succ(r). Thus, |v | |D(v)| 1.(ii) fixed sequence value changes r, forks leaves become mutuallyindependent; is, ability change value one affectability change value others.66fiImplicit Abstraction Heuristics(iii) r binary-valued, v V \ {r} demanding leaf variableterms number value changes required r action preconditionsalong v , value changes r along , except for, possibly,final value change G[r]. Thus, particular, |r | maxvsucc(r) |D(v)|.begin introducing auxiliary notations. |D(r)| = 2, let D(r) = {0, 1}I[r] = 0. Let (r) alternating 0/1 sequence starting 0, 0odd 1 even positions. sequence (r) |(r)| = 1 actionchange rs value 1, |(r)| = 2 action change rs value 1action restore value 0, otherwise, |(r)| = 1 + maxvsucc(r) |D(v)|. Let[(r)] set nonempty prefixes (r) G[r] unspecified; otherwise, letset nonempty prefixes (r) ending G[r]. Note that, [(r)] = ,problem trivially unsolvable; follows assume case.v succ(r), let DT G0v DT G1v subgraphs domain transition graphsDTG(v, ), obtained removing DTG(v, ) arcs labeled r : 1 r : 0,respectively.algorithm incrementally constructs set R valid plans , startingR = .(1) v succ(r), pair vs values x, D(v), compute cheapest(that is, cost-minimal) paths v0 (x, y) v1 (x, y) x DT G0v DT G1v ,respectively. pairs values x, y, one even paths may, course,exist.(2) sequence [(r)], v succ(r), construct layered digraph Lv ()|| + 1 node layers L0 , . . . , L|| , L0 consists I[v], 1 ||,[i]Li consists nodes D(v) path v (x, y) node x Li1constructed step (1). x Li1 , Li , Lv () contains arc[i](x, y) weighted cost(v (x, y)).(3) [(r)], let k = ||. candidate plan constructed follows.(a) v succ(r), find cost-minimal path I[v] G[v] Lv ().path exists, proceed next prefix [(r)]. Otherwise, notei-th edge path (taking us x Li1 Li ) corresponds[i]cost-minimal path v (x, y) x y. Let us denote path xSvi .(b) Set R = R{ }, = 1 a[2] 2 . . .a[k] k , sequence obtainedarbitrary merge sequences {Svi }vsucc(r) , cheapest actionchanging value r value .(4) R = , fail, otherwise return = argmin R cost( ).straightforward verify complexity procedure polynomialdescription size . prove correctness, show procedure returnsplan solvable task , returned plan 0 satisfies cost(0 ) cost()optimal plan .67fiKatz & DomshlakGiven solvable task , let optimal plan v leaf variablesv cycle-free. Let r = ha2 . . . , ak i; numbering actions along r startsa2 simplify indexing later on. v succ(r), actions r divide vsubsequences v-changing actions v = 1v . . . kv , separated value changesrequired r. is, 1 k, actions iv preconditionedvalue r, any, two actions iv a0 i+1preconditioned r,vpre(a)[r] 6= pre(a0 )[r]. Let [(r)] value sequence || = k = |r | + 1.v succ(r), v path I[v] G[v] Lv (), therefore addedR algorithm, meaning algorithm finds solution. Now, R,then, v succ(r), let Sv1 Sv2 . . . Svk cost-minimal path I[v] G[v]Lv () Svi sequence actions changing value v preconditionedeither r : 0 nothing odd i, r : 1 nothing even i. Thus,cost(Sv1 Sv2 . . . Svk ) =kXi=1cost(Svi ) cost(v ).sequence obtained arbitrary merge sequences {Svi }vsucc(r) ,cheapest action changing value r , = 1 a[2] 2 . . . a[k] kapplicable sequence actions achieves goal values v succ(r)well r,cost( ) = cost(S 1 a[2] 2 . . . a[k] k ) =kXcost(a[i] ) +i=2cost(r ) +kXi=1Xcost(S )cost(v ) = cost().vsucc(r)Hence, solvable, algorithm returns plan , plan mustoptimal. Finally, solvable, R necessarily remains empty, thusalgorithm fails.Theorem 4 concerns tractability tasks fork-structured causal graphsroots binary domains, earlier work also reported additional tractabilityresult fork-structured causal graphs domains variables fixedsize, though necessarily binary-valued (Katz & Domshlak, 2008). discussresult detail because, least far, found helpfulcontext devising effective abstraction heuristics.Theorem 5 (Tractable Inverted Forks) Given planning task = hV, A, I, G, costiinverted fork causal graph sink r V , |D(r)| = O(1), time complexitycost-optimal planning polynomial ||||.Proof: Let |D(r)| = d. Observe inverted-fork structure causal graph CG()implies actions unary-effect, sink r preconditionsactions affecting r itself. Hence, follows assume G[r] specified; otherwise68fiImplicit Abstraction HeuristicsGiven path ha1 , . . . , I[r] G[r] DTG(r, )::= hiam+1 := hG[pred(r)],foreach v pred(r) xv := I[v]:= 1 + 1foreach v pred(r)pre(ai )[v] specified pre(ai )[v] 6= xvpre(ai )[v] reachable xv DTG(v, ) failappend actions induced cost-minimal pathpre(ai )[v] xv DTG(v, )xv := pre(ai )[v]< + 1 append action aireturnFigure 4: Detailed outline step (3) planning algorithm inverted-fork structuredtask.breaks set trivial planning problems single variable each. Likewise,properties follows that, optimal plan , pathr I[r] G[r] induced DTG(r, ) either cycle-free contains zerocost cycles. latter safely eliminated , thus assume rcycle-free. Given that, simple algorithm finds cost-optimal plan time(||||d + ||||3 ) follows.(1) Create (|Ar |d1 ) cycle-free paths I[r] G[r] DTG(r, ).(2) variable v pred(r), pair vs values x, D(v), computecost-minimal path x DTG(v, ). whole set cost-minimal pathscomputed using (d|V |) applications Floyd-Warshall algorithmdomain transition graphs sinks parents pred(r).(3) I[r]-to-G[r] path DTG(r, ) generated step (1), construct planbased path r, cheapest paths computed (2). simpleconstruction, depicted Figure 4, possible values parent variablechanged independently values variables inverted fork.(4) Take cheapest plan among constructed (3). plan constructedstep (3), unsolvable.already observed that, cost-optimal plan , r one I[r]-to-G[r]paths generated step (1). v pred(r), let Sv denote sequence valuesD(v) required preconditions actions along r . v pred(r),v corresponding (possibly cyclic) path I[v] G[v] DTG(v, ), traversingvalues (= nodes) Sv order required Sv . turn, plan generated(3) consists cost-minimal paths v pred(r). Therefore, least one69fiKatz & Domshlakplans generated (3) must cost-optimal , minimization step (4) selectone them.Theorems 4 5 clarify gap fork decompositions implicit abstractionheuristics, bridge gap abstracting task given forkdecomposition . abstracting domains fork roots inverted-forksinks meet requirements tractable fragments. note that, itself, ideadomain decomposition new general (Hernadvolgyi & Holte, 1999)domain-independent planning particular (Domshlak, Hoffmann, & Sabharwal, 2009).fact, shrinking step algorithm building merge-and-shrink abstractionsprecisely variable domain abstraction meta-variables constructed mergingsteps (Helmert et al., 2007).Definition 10 Let = hV, A, I, G, costi planning task states S, v V statevariable, = {1 , . . . , } set mappings D(v) sets 1 , . . . , ,respectively. = {hi , i}mi=1 domain abstraction if, setcost functions {costi : R0+ }mi=1 satisfying:Xi=1costi (a) cost(a),(8)have, 1 m,abstraction mapping statesu V :((s[u]),(s)[u] =s[u],u=v,u 6= vand, extending partial assignments V 0 V (s[V 0 ]) = (s)[V 0 ],= hV, Ai , Ii , Gi , costi planning task1. Ii = (I), Gi = (G),2. Ai = {ai = hi (pre(a)), (eff(a))i | A},3. action A,costi (ai ) = costi (a).(9)say domain decomposition = hV, A, I, G, costi respect .Theorem 6 Domain abstractions planning tasks additive implicit abstractionstasks.Proof: Let = hV, A, I, G, costi planning task = {hi , i}mi=1 domainabstraction = {1 , . . . , }. Let = (S, L, Tr, s0 , ? , $) transitiongraph . 1 m, let Ti = (Si , Li , Tri , s0i , Si? , $i ) transition graph. need show abstraction mapping Definition 2.First, Definition 1070fiImplicit Abstraction Heuristicss0i = Ii = (I) = (s0 ),? G thus (s) (G) = Gi , providing us(s) Si? .Now, state action pre(a) s, (s) statepre(ai ) = (pre(a)) (s). Thus, ai applicable (s), showapplying ai (s) results (s)Jai K = (sJaK).1. effect variables v V(eff(a)) = V(eff(ai )), eff(ai ) (s)Jai Keff(ai ) = (eff(a)) (sJaK).2. variables v 6 V(eff(a)), sJaK[v] = s[v] (s)Jai K[v] =(s)[v], thus(s)Jai K[v] = (s)[v] = (s[v]) = (sJaK[v]) = (sJaK)[v].Next, A, Eqs. 8 9Xcosti (ai ) =i=1Xi=1costi (a) cost(a).(10)Now, let s, s0 pair states cost(s, s0 ) , let % = ha1 , . . . , alsequencelabels along cheapest path s0 T. that, cost(s, s0 ) = cost(%) =Pljj=1 cost(a ). decomposition path actions Definition 10(notcheapest) path (s) (s0 ) Ti , thus cost(i (s), (s0 ))Pl neccesarilyjj=1 costi (a ), providing usXi=1cost(i (s), (s0 ))XlXi=1 j=1costi (aji ) =l XXj=1 i=1(10)costi (aji )lXcost(aj ) = cost(s, s0 ).j=1put notion domain abstraction framework implicit abstractions,ready connect fork decompositions implicit abstraction heuristics. GivenFI-abstraction AFI = {hfv , vf i, hiv , vi i}vV planning task = hV, A, I, G, costi,fv FI , associate root v CG(fv ) mappings fv = {fv,1 , . . . , fv,kv }kv = O(poly(||||)) fv,i : D(v) {0, 1}, abstract fvf i}kv ,Afv = {hfv,i , v,ii=1iv FI , associate sink v CG(iv ) mappings iv = {iv,1 , . . . , iv,kv0 }kv0 = O(poly(||||)) iv,i : D(v) {0, 1, . . . , bv,i }, bv,i = O(1),k0i} v .abstract iv Aiv = {hiv,i , v,ii=171fiKatz & DomshlakTheorem 3, Theorem 6, composition Theorem 2, immediatelykv0kv[ [[f{hfv,i , v,iAFI =vf i} {hiv,i , v,ivi i}(11)vVi=1i=1additive implicit abstraction . Hence, Theorem 1,kv0kvX XXhFI =hihf +vVv,ii=1i=1v,i(12)admissible estimate h , and, Theorems 4 5, hFI also computabletime O(poly(||||)).finalizes construction concrete family implicit abstraction heuristics.illustrate mixture acyclic causal-graph domain abstractions above,use running Logistics example. One bothersome question extentabstracting fork decompositions using domain abstractions affects informativenessheuristic estimate. Though generally degradation unavoidable, showanswer question sometimes somewhat surprising.begin extreme setting, let domain abstractions roots forkssinks inverted forks binary-valued domains. Among multiple options choosing mapping sets {fv } {iv }, use simple choice distinguishing different values variable v basis cost I[v] DTG(v, ).Specifically, v V , set fv = iv , and, value D(v)1 max0 D(v) d(I[v], 0 ),(0, d(I[v], ) <fv,i () = iv,i () =(13)1, otherwiseexample, problem fc1 decomposed (see domain transition graph c1left Figure 1c) two problems, fc1 ,1 fc1 ,2 , binary abstractdomains c1 corresponding partitions {{A}, {B, C, D}} {{A, D}, {B, C}}D(c1 ), respectively. yet another example, problem ip1 decomposed (seedomain transition graph p1 Figure 1d) six problems ip1 ,1 , . . . , ip1 ,6 alongabstractions D(p1 ) depicted Figure 5a. Now, given FI-decompositionmappings {fv , iv }vV above, consider problem ip1 ,1 , obtained abstractingalong inverted fork p1 abstracting D(p1 ) using(0, {C}ip1 ,1 () =.1, {A, B, D, E, F, G, c1 , c2 , c3 , t}hard verify that, original actions affecting p1 , left ip1 ,1actions conditioned c1 c2 . so, information lost3 removeip1 ,1 variables c3 t, well actions changing (only) variables,3. information lost still keep either fork inverted fork variable .72fiImplicit Abstraction HeuristicscBCEcFGc(a)cBCcEcFGcBCEcD(p1 ) fp1 ,1cFGBCEccD(p1 ) fp1 ,2FGcD(p1 ) fp1 ,3(b)Figure 5: Domain abstractions D(p1 ). (a) Binary-valued domain abstractions: values inside outside dashed contour mapped 0 1, respectively.(b) Ternary-valued domain abstractions: values mappedabstract value shown nodes color borderline.redistribute cost removed actions representativesoriginals . latter revision action cost partition obtained directlyreplacing cost-partitioning steps corresponding Eqs. 3-4 8-9 single, jointaction cost partitioning applied final additive implicit abstraction AFI Eq. 11satisfyingkvX Xcost(a)vV0Xcostfv,i (fv,i (a0 )) +i=1 a0 f (a)GkvXXcostiv,i (iv,i (a0 )) .(14)i=1 a0 (a)Gvvfollows, uniform action cost partition refer partition costaction equally split among nonredundant representatives final additiveimplicit abstraction.Overall, computing hFI Eq. 12 binary-valued domain abstractions7uniform action cost partition provides us hFI (I) = 12 15, knowingFIoriginal costs integers safely adjust h (I) = 13. Hence, evensevere domain abstractions above, estimate hFI example tasklower h2 .Let us slightly refine domain abstractions sinks inverted forksternary range {0, 1, 2}. mappings {fv } remain unchanged, {iv } set73fiKatz & Domshlak0, d(I[v], ) < 2i 1D(v) : v,i () = 1, d(I[v], ) = 2i 12, d(I[v], ) > 2i 1.(15)example, problem ip1 decomposed ip1 ,1 , . . . , ip1 ,3 along abstractionsD(p1 ) depicted Figure 5b. Applying computation hFI Eq. 12new set domain abstractions gives hFI (I) = 15 12 , which, again, safelyadjusted hFI (I) = 16. Note value higher hFI = 15 obtained using(generally intractable) pure fork-decomposition abstractions Eq. 6. first view,outcome may seem counterintuitive domain abstractions applied forkdecomposition, one would expect coarser abstraction provide less precise estimates.This, however, necessarily case employed action cost partition ad hoc.instance, domain abstraction sink inverted fork may create independencesink parent variables, exploiting domain-abstraction specificindependence relations leads targeted action cost partition via Eq. 14.see surprising estimate improvement obtained, notedomain abstraction Eq. 15 applied example, truck-moving actionsdrive-t-from-D-to-E drive-t-from-E-to-D appear three abstractions ft , ip1 ip2 ,domain abstraction appear five abstractions ft,1 , ip1 ,1 , ip1 ,2 , ip1 ,3ip2 ,1 . However, closer look action sets five abstractions revealsdependencies p1 CG(ip1 ,1 ) CG(ip1 ,3 ), p2 CG(ip2 ,1 ) redundant,thus keeping representatives move-D-E move-E-D corresponding abstracttasks entirely unnecessary. Hence, all, two truck-moving actions appeartwo post-domain-abstraction tasks. Moreover, abstractions truck-movingactions fully counted, contrast predomain-abstraction tasks portioncost actions allocated ip2 simply gets lost.6. Experimental Evaluation: Takeevaluate practical attractiveness fork-decomposition heuristics, conducted empirical study wide sample planning domains InternationalPlanning Competitions (IPC) 1998-2006, plus non-IPC Schedule-STRIPS domain.4domains selected allow comparative evaluation other, baselinestate-of-the-art, approaches/planners, supported PDDL featurestime evaluation.Later formally prove that, ad hoc action cost partitions uniformpartition, none three fork decompositions Definition 9 dominatedtwo. Hence, implemented three additive fork-decomposition heuristics, hF ,hI , hFI , within standard heuristic forward search framework Fast Downwardplanner (Helmert, 2006) using algorithm full duplicate elimination. hFheuristic corresponds ensemble (not clearly redundant) fork subgraphs4. Schedule-STRIPS appears domains distribution IPC-2000. Later became awarefact domain excluded competition encoding generated problemsvarious planners.74fiImplicit Abstraction Heuristicsdomainairport-ipc4blocks-ipc2depots-ipc3driverlog-ipc3freecell-ipc3grid-ipc1gripper-ipc1logistics-ipc1logistics-ipc2miconic-strips-ipc2mprime-ipc1mystery-ipc1openstacks-ipc5pathways-ipc5pipes-notank-ipc4pipes-tank-ipc4psr-small-ipc4rovers-ipc5satellite-ipc4schedule-stripstpp-ipc5trucks-ipc5zenotravel-ipc3213071252206228524217421145076436911total433hF1117293153214517167496475642558%S5257297560502550955371761001004343947110098835673294hI141521021521542171574116486635559%S6750298340502533684971711001005243968610081835682282hFI1115292152144017167486476539558%S525029754050253364477176100100384394868391835673MS -104MS -10519187125274165421177320135066226611172041212752155121374127507616511274%S9060100100100100356773648881100759593100861005110067100332%S816757100201003583956550621001005750100100100210056100285HSPF1530495063164581174137506511598%S711005775100030507353335210010062501008683268310073277Gamer11304112220620859874116475635310%S52100579240100100100911003838100100524394711007833391315blind181847417210501918741410485429557%S866057588050353345597986100100677196716767835664296hmax201848527210502418741710496531678%S9560576710010035334559100861001008171988683721007873318Table 1: summary experimental results. Per domain, denotes numbertasks solved planner. Per planner/domain, number tasks solvedplanner given absolute number (s) percentagesolved planners (%S). last row summarize number solvedinstances.causal graph, domains roots abstracted using leave-one-value-outbinary-valued domain decompositions follows:(0, =D(v) : fv,i () =.(16)1, otherwisehI heuristic inverted fork subgraphs, domainssinks abstracted using distance-to-goal-value ternary-valued domain decompositions5 Eq. 17.0, d(, G[v]) < 2i 1D(v) : v,i () = 1, d(, G[v]) = 2i 1 .(17)2, d(, G[v]) > 2i 1ensemble hFI heuristic union hF hI . action costpartition three heuristics call uniform.make comparison two baseline approaches, namely blind heuristicvalue 0 goal states 1 otherwise, hmax heuristic (Bonet & Geffner,2001), well state-of-the-art abstraction heuristics, represented mergeand-shrink abstractions Helmert et al. (2007). latter constructed5. distance-from-initial-value reasonable evaluation initial state, leave-onevalue-out fork roots distance-to-goal-value inverted-fork sinks typically muchattractive evaluation states examined .75fiKatz & Domshlaklinear, f -preserving abstraction strategy proposed authors, twofixed bounds size abstract state spaces, notably |S | < 104 |S | < 105 .four (baseline merge-and-shrink) heuristics implemented Helmert et al.(2007) within planning system fork-decomposition heuristics, allowingfairly unbiased comparison. also compare Gamer (Edelkamp & Kissmann,2009) HSPF (Haslum, 2008) planners, winner runner-up sequentialoptimization track IPC-2008. algorithmic side, Gamer based bidirectionalblind search using sophisticated symbolic-search techniques, HSPF usesadditive critical-path heuristic. experiments conducted 3GHz Intel E8400CPU 2 GB memory, using 1.5 GB memory limit 30 minute timeout.exception Gamer, used similar machines 4 GB memory 2GB memory limit; done provide Gamer environmentconfigured.Table 1 summarizes experimental results terms number tasks solvedplanner. impression fork-decomposition heuristics Table 1 somewhatmixed. one hand, performance three fork-decomposition based plannerscomparable one settings merge-and-shrink heuristic, clearlytestifies framework implicit abstractions theoretical interest only.hand, planners, except merge-and-shrink heuristic|S | < 104 , failed outperform baseline hmax heuristic. importantus that, unfortunately, three fork-decomposition based planners failed outperformeven basic blind search.This, however, end story fork-decomposition heuristics.hope found detailed results Tables 9-14 appendix. appearsTable 10, on, e.g., Logistics-ipc2 domain, hF almost consistently leads expandingfewer search nodes (better two merge-and-shrink heuristicsdomain) MS -105 , difference hitting four orders magnitude. However, timecomplexity hF per search node substantially higher MS -105 ,two expanding rate approximately 40 100000 nodes per second, respectively.outcome simple: time limits (and memory limit 1.5 GB) hFsolves tasks Logistics-ipc2 MS -105 (task 12-1 solved hF 2519.01seconds), standard time limit half hour used Table 10.follows examine possibility exploiting informativeness fork-decompositionheuristics falling trap costly per-node heuristic evaluation.7. Back Theory: h-Partitions Databased Implicit AbstractionAccuracy low time complexity desired yet competing properties heuristicfunctions. many powerful heuristics, abstraction heuristics particular, computingh(s) state isolation impractical: computing h(s) polynomialdescription size , often efficient enough performed search node.However, costly heuristics obstacle largely overcome sharingcomputation evaluations h different states. possible,shared parts computing h problem states precomputed memorizedsearch, reused search evaluations h different76fiImplicit Abstraction Heuristicsstates. mixed offline/online heuristic computation henceforth called h-partition,define time complexity h-partition complexity computing hset states. Given subset k problem states 0 S, h-partitions timecomplexity computing {h(s) | 0 } expressed O(X + kY ), O(X) O(Y )are, respectively, complexity (offline) pre-search (online) per-node partscomputing h(s).days h-partitions adopted various optimal planners using criticalpath heuristics hm > 1 (Haslum et al., 2005), landmark heuristics hL hLA (Karpas& Domshlak, 2009), PDB merge-and-shrink abstraction heuristics (Edelkamp,2001; Helmert et al., 2007). Without effective h-partitions, optimal searchheuristics would scale well, h-partitions constitutes stateart cost-optimal planning. instance, attractive property PDB abstractionscomplexity natural h -partition. Instead computing h (s) = h ((s))scratch evaluated state (impractical tiny projections), practiceprecompute store h (s0 ) abstract states s0 , per-nodecomputation h (s) boils hash-table lookup h ((s)) perfect hashfunction. terms, time space complexity PDB h -partition setk states O(|S |(log(|S |) + |A|) + k) O(|S |), respectively. preciselymakes PDB heuristics attractive practice. respect, picture mergeand-shrink abstractions much similar. order compositesformed choice abstract states contract crucial complexitynatural h -partitions, time space complexity concrete linear abstractionstrategy Helmert et al. respectively O(|V ||S |(log(|S |) + |A|) + k |V |) O(|S |).Similarly PDB abstractions, per-node computation h (s) merge-and-shrinkabstraction lookup data structure storing h ((s)) abstract states(s) . Hence, pre-search computation MS abstractionscostly PDBs, online part computing heuristic values still extremelyefficient. per-node efficiency provides merge-and-shrink heuristics impressivepractical effectiveness numerous IPC domains (Helmert et al., 2007).sum up, say fixed size abstract spaces induced explicit abstractions PDBs merge-and-shrink limitation also key obtainingeffective h-partitions. contrast, escaping limitation implicit abstractions mighttrap us pay high price search-node evaluation. show, however, time-per-node complexity bottleneck fork-decomposition heuristicssuccessfully overcome. Specifically, show equivalent PDBs mergeand-shrink notion database exists fork-decomposition abstractions well, despiteexponential-size abstract spaces. course, unlike PDB merge-and-shrinkabstractions, databased fork-decomposition heuristics (and cannot) provide uspurely lookup online computation h (s). online part h -partitionnontrivial sense complexity cannot O(1). comes nextprove existence effective h-partitions fork inverted fork abstractions.Section 8 empirically show h-partitions lead fast pre-searchper-node computations, allowing informativeness fork-decomposition heuristicssuccessfully exploited practice.77fiKatz & DomshlakTheorem 7 Let = hV, A, I, G, costi planning task fork causal graph rootedbinary-valued variable r. exists h -partition that, set k states,time space complexity h -partition is, respectively, O(d3 |V | + |Ar | + kd|V |)O(d2 |V |), = maxv D(v).Proof: proof modification polynomial-time algorithm computingh (s) state task used proof Theorem 4 (Tractable Forks). Givenstate s, let D(r) = {0, 1}, s[r] = 0. follows, two rootsvalues D(r), denotes opposite value 1 ; (r), [(r)], DTG 0v DTG 1vdefined exactly proof Theorem 4.(1) two values r D(r) root variable, leaf variable v V \ {r},pair values , 0 D(v), let p,0 ;r cost cheapest sequenceactions changing v 0 provided r : r . whole set {p,0 ;r } leavesv V \{r} computed straightforward variant all-pairs-shortest-paths,Floyd-Warshall algorithm DTG v r time O(d3 |V |).(2) leaf variable v V \ {r}, 1 + 1, D(v), let g;i costcheapest sequence actions changing s[v] provided sequence [(r)],|| = i, value changes r. values {p,0 ;r } step (1), set {g;i }given solution recursive equationps[v],;s[r] ,i=1min g0 ;i1 + p0 ,;s[r] ,1 < , odd0g;i =,0 ;i1 + p0 ,;s[r] ,ming1<,even0g< + 1;i1 ,= |D(v)| + 1. Given that,h (s) =mincost() +[(r)]XgG[v];|| ,vV \{r}P||cost() = i=2 cost(a[i] ), a[i] cheapest action changingvalue r [i 1] [i].Note step (1) already state-independent, heavy step (2) not. However,state dependence step (2) mostly overcome follows. v V \ {r},D(v), 1 + 1, r D(r), let g;i (r ) cost cheapest sequenceactions changing G[v] provided value changes r induce 0/1 sequence lengthstarting r . set {g;i (r )} given solution recursive equation,i=1p,G[v];rg0 ;i1 (r ) + p,0 ;r , 1 <,g;i (r ) = min0g< + 1;i1 (r ),78(18)fiImplicit Abstraction Heuristics2401r ||24011110100101 115012301003001010000211 115015011412345671234567cost()v :0v :1 v :2 v :3u:0u:1 u:2 u:3 u:4 u:502448729612014402448729612014410010010010033310033333222222222222012015353555101101535355200 101 100200 101 100102 32102 3243243243252 51252 512432432432432111111111111100000000000000(a)111111111111100000000000000(b)Figure 6: database fork-structured problem binary-valued root variable rtwo children v u, G[r] = 0, G[v] = 3, G[u] = 5. (a) depictsdomain transition graphs r (top), v (middle), u (bottom); numbersedge precondition r cost respectiveaction. (b) depicts database created algorithm. instance, entryrow r : 0 || = 5 column v : 0 captures value gv:0;5 (r : 0) computedEq. 18. shaded entries examined online computationh (r : 0, v : 0, u : 0).solved time O(d3 |V |). Note equation independentevaluated state s, yet {g;i (r )} allow computing h (s) given state viah (s) =mincost() +[(r|s[r])]Xgs[v];|| (s[r])(19)vV \{r}(r|r ) defined similarly (r) respect initial value r r.new formulation, computation performed online, persearch node, final minimization [(r|s[r])] Eq. 19, lightestpart whole algorithm anyway. major computations, notably {p,0 ;r }{g;i (r )}, performed offline shared evaluated states.space required store information O(d2 |V |) contains fixed amountinformation per pair values variable. time complexity offline computation O(d3 |V | + |Ar |); |Ar | component stems precomputing costs cost().time complexity online computation per state O(d|V |); |V | comesinternal summation comes size [(r|s[r])].Figure 6b shows database created fork-structured problem binary-valuedroot r, two children v u, G[r] = 0, G[v] = 3, G[u] = 5; domain transition79fiKatz & Domshlakgraphs v u depicted Figure 6(a). Online computation h (s) Eq. 19= (r : 0, v : 0, u : 0) sums shaded entries four rowsentries, minimizes resulting four sums, minimum obtainedrow r : 0 || = 5.Theorem 8 Let = hV, A, I, G, costi planning task inverted fork causal graphsink r |D(r)| = b = O(1). exists h -partition that, setk states, time space complexity h -partition O(b|V ||Ar |b1 + d3 |V | +k|V ||Ar |b1 ) O(|V ||Ar |b1 + d2 |V |), respectively, = maxv D(v).Proof: Like proof Theorem 7, proof Theorem 8 based modificationpolynomial-time algorithm computing h (s) used proof Theorem 5(Tractable Inverted Forks).(1) parent variable v V \ {r}, pair values , 0 D(v), let p,0cost cheapest sequence actions changing 0 . whole set {p,0 }computed using Floyd-Warshall algorithm domain transition graphv time O(d3 |V |).(2) Given state s, cycle-free path = ha1 , . . . , s[r] G[r] DTG(v, ),let g cost cheapest plan based , cheapest paths{p,0 } computed step (1). g computedg =Xi=1cost(ai ) +XXpprei [v],prei+1 [v] ,i=0 vV \{r}pre0 , . . . , prem+1 values required parents r along path .is, v V \ {r}, 0 + 1,s[v],i=0G[v],= + 1, G[v] specifiedprei [v] =.pre(a)[v],1m,pre(a)[v]specifiedpre [v]otherwisei1that, h (s) = min g .Note step (1) state-independent, step (2) not. However, dependencestep (2) evaluated state substantially relaxed. O(1)different values r, possible consider cycle-free paths G[r] values r.path , parent variable v V \ {r}, know first valuev required would be. Given that, precompute cost-optimal plans inducedassuming parents start first required values. remaindercomputation h (s) delegated online, modified step (2) follows.r D(r) cycle-free path = ha1 , . . . , r G[r]DTG(r, ), let proxy statev=rr ,[v] = G[v],1 : pre(ai )[v] unspecified ,pre(ai )[v], = argminj {pre(aj )[v] specified}80fiImplicit Abstraction Heuristicsis, nontrivial part captures first values V \ {r} required along .6 Giventhat, let g cost cheapest plan based , cheapestpaths {p,0 } computed (1). g computedg =Xcost(ai ) +i=1Xpprei [v],prei+1 [v] ,vV \{r}where, v V \ {r}, 1 + 1,[v],i=1G[v],= + 1, G[v] specifiedprei [v] =.pre(ai )[v], 2 m, pre(ai )[v] specifiedpre [v], otherwisei1Storing pairs (g , ) accomplishes offline part computation. Now, givensearch state s, computeh (s) =mins.t.[r]=s[r]g +Xps[v],s [v] .(20)vV \{r}number cycle-free paths G[r] DTG(r, ) (|Ar |b1 ), gpath computed time O(b|V |). Hence, overall offline time complexityO(b|V ||Ar |b1 + d3 |V |), space complexity (including storage proxy states) O(|V ||Ar |b1 + d2 |V |). time complexity online computation per state viaEq. 20 O(|V ||Ar |b1 ); |V | comes internal summation |Ar |b1 upperbound number cycle-free paths s[r] G[r].Figure 7(b) shows database created inverted fork structured problemternary-valued sink variable r, two parents u v, G[r] = 2, G[u] = 0, G[v] = 2.domain transition graphs u v depicted top Figure 7(a); actualidentities actions affecting two parents important here. actions affectingsink ra1 = h{u : 1, r : 0}, {r : 1}ia2 = h{v : 1, r : 0}, {r : 1}ia3 = h{u : 2, r : 1}, {r : 2}ia4 = h{v : 1, r : 1}, {r : 2}i.domain transition graph r depicted bottom Figure 7(a). Online computation h (s) Eq. 20 = (r : 0, v : 0, u : 0) sums shaded entriesfour rows entries, minimizes resulting four sums,minimum obtained lowest row.81fiKatz & Domshlak02500505021111001u:2u:111012v:1v:150100rha1 , a30 ha1 , a4ha2 , a3ha2 a4ha31ha4(a)gu:0u:1 u:2v :0u : 1, v : 2u : 1, v : 1u : 2, v : 1u : 0, v : 1u : 2, v : 2u : 0, v : 1202153153152101102100100500500050050100 050 100100 050 10011011011011101v :1 v :220002001001001000100(b)Figure 7: database inverted fork-structured problem O(1) bounded sinkvariable r two parents u v, G[r] = 2, G[u] = 0, G[v] = 2.(a) depicts domain transition graphs u (top left), v (top right), r(bottom); numbers edge preconditionscost respective action, respectively. (b) depicts database createdalgorithm. shaded entries examined online computationh (r : 0, u : 0, v : 0).8. Experimental Evaluation: Take IIevaluate practical attractiveness databased fork-decomposition heuristics,repeated empirical evaluation Section 6, databased versionsheuristics. detailed results evaluation relegated Tables 15-20appendix, summarized Table 2. domain, columncaptures number tasks domain solved least one plannersuite. Per planner/domain, number tasks solved planner givenabsolute number (s) percentage solved planners(%S). Boldfaced results indicate best performance within corresponding domain.last three rows summarize performance planners via three measures.first number tasks solved 23 domains; basically performanceevaluation measure used optimization track IPC-2008. domains equallychallenging equally discriminate planners performance, seconddomain-normalized performance measures(p) =Xdomain#tasks solved planner p.#tasks solved plannersFinally, third measure corresponds number domains w plannerquestion solved least many tasks planner.Overall, Table 2 clearly suggests heuristic search databased fork-decompositionheuristics favorably competes state art optimal planning. particular,6. ease presentation, omit case v required neither along , goal;variables simply ignored accounting cost .82fiImplicit Abstraction Heuristicsdomainairport-ipc4blocks-ipc2depots-ipc3driverlog-ipc3freecell-ipc3grid-ipc1gripper-ipc1logistics-ipc2logistics-ipc1miconic-strips-ipc2mprime-ipc1mystery-ipc1openstacks-ipc5pathways-ipc5pipes-notank-ipc4pipes-tank-ipc4psr-small-ipc4rovers-ipc5satellite-ipc4schedule-stripstpp-ipc5trucks-ipc5zenotravel-ipc3223071252202278524217421145076466911totalw438hF22217125272265123217417114966466611%S1007010010010010035100866096100100100817998861001001006710036820.5614hI2018412417164502218741594976406711%S9160571008050357357599286100100716498100100871007810033718.387hFI2118712417165502121741694966466711%S956010010080503573715988100100100766498861001001007810035019.139MS -104MS -10519187125271645421177320135066226611172041212721555121374127507616511%S866010010010010035735764888110075959310086100481006710033219.0711%S77675710020100359571655062100100575010010010021005610028516.649HSPF1530495061634581174137506511598%S68100577510003073435333521001006250100868324831007327715.456Gamer11304112220206859874116475635310%S501005792401001009186100383810010052439471100783339131516.668blind181847417102501918741410485429557%S82605758805035452959798610010067719671676383566429615.582hmax201848527102502418741710496531678%S916057671001003545295910086100100817198868367100787331817.666Table 2: summary experimental results databased versions forkdecomposition heuristics. Per domain, denotes number tasks solvedplanner. Per planner/domain, number tasks solved plannergiven absolute number (s) percentage solvedplanners (%S). Boldfaced results indicate best performance withincorresponding domain. last three rows summarize number solved instances, domain-normalized measure solved instances (s), numberdomains planners achieved superior performance (w).forks heuristic hF exhibited best overall performance accordingthree measures. terms absolute number solved instances, threefork-decomposition heuristics outperformed planners suite. contributiondatabasing success fork-decomposition heuristics dramatic. Lookingback results fully online heuristic computation depicted Table 1, notetotal number solved instances fork-decomposition heuristics hF , hI , hFIincreased 74, 55, 76, respectively, made whole difference.also performed comparative evaluation planning domainsrecent IPC-2008. IPC-2008 domains differ previous domains actionsvarious costs, and, importantly, many actions zero cost. latterissue heuristic-search planners heuristic functions cannot differentiatesubplans cost zero, differ length. case, comparativeside evaluation IPC-2008 domains differ several points previousone. First, neither merge-and-shrink hmax heuristics, implementationsupporting arbitrary action costs. Hence, comparison Gamer, HSPF ,blind search. Second, ensure admissibility blind search, lattermodified return non-goal states cost cheapest applicable action. Finally,planners run 3GHz Intel E8400 CPU 4 GB memory, using 2 GB memory83fiKatz & Domshlakdomainelevators-strips-ipc6openstacks-strips-ipc6parcprinter-strips-ipc6pegsol-strips-ipc6scanalyzer-strips-ipc6sokoban-strips-ipc6transport-strips-ipc6woodworking-strips-ipc62221162712281114totalw152hF181914271225118%S82908810010089100571347.063hI14191327626118%S6490811005093100571246.352hFI15191327627118%S6890811005096100571266.433HSPF721162761399%S32100100100504682641085.743Gamer221992411201114%S10090568992711001001306.993blind111910271220117%S50906310010071100501176.243Table 3: summary experimental results. Per domain, denotes numbertasks solved planner. Per planner/domain, number tasks solvedplanner given absolute number (s) percentagesolved planners (%S). Boldfaced results indicate best performancewithin corresponding domain. last three rows summarize numbersolved instances, domain-normalized measure solved instances (s),number domains planners achieved superior performance (w).limit 30 minute timeout. results evaluation summarized Table 3;detailed results refer reader Tables 21-22 appendix. Overall,results show fork-decomposition heuristics much competitiveIPC-2008 domains well.9. Formal Analysis: Asymptotic Performance RatiosEmpirical evaluation concrete set benchmark tasks standard importantmethodology assessing effectiveness heuristic estimates: allows us studytradeoff accuracy heuristics complexity computing them.However, rightfully noted Helmert Mattmuller (2008), evaluations almostnever lead absolute statements type Heuristic h well-suited solving problems benchmark suite X, relative statements type Heuristic hexpands fewer nodes heuristic h0 benchmark suite X. Moreover, one would probably like obtain formal evidence effectiveness heuristic proceedingimplementation, especially complicated heuristic procedures underlying proofs Theorems 7 8. formal analysis effectivenessfork-decomposition heuristics using methodology suggested exploited HelmertMattmuller motivated primarily desire formal evidence.Given planning domain heuristic h, Helmert Mattmuller (2008) considerasymptotic performance ratio h D. goal find value (h, D) [0, 1](1) states problems D, h(s) (h, D) h (s) + o(h (s)),(2) family problems {n }nN solvable, non-goal states {sn }nNsn n , limn h (sn ) = , h(sn ) (h, D) h (sn ) + o(h (sn )).84fiImplicit Abstraction HeuristicsDomainh+hkhPDBhPDBaddhFhIhFIGripperLogisticsBlocksworldMiconic-StripsSatellite2/33/41/46/71/200000000002/31/201/21/62/31/205/61/601/201/21/64/91/201/21/6Table 4: Performance ratios multiple heuristics selected planning domains; ratiosh+ , hk , hPDB , hPDBadd Helmert Mattmuller (2008).words, h never worse (, domain, )h (plus sublinear term),become bad (h, D) h (plus sublinear term) arbitrarily large inputs; noteexistence uniqueness (h, D) guaranteed h D.Helmert Mattmuller (2008) study asymptotic performance ratio standard admissible heuristics set well-known benchmark domains first fourIPCs. results Gripper, Logistics, Blocksworld, Miconic, Satelliteshown first four columns Table 4.h+ estimate corresponds optimal cost solving well-known deleterelaxation original planning task, generally NP-hard compute (Bylander, 1994).hk , k N+ , family heuristics based relaxation costachieving partial assignment approximated highest cost achievingsub-assignment size k (Haslum & Geffner, 2000); computing hk exponentialk.hPDB hPDBadd heuristics regular (maximized over) additive patterndatabase heuristics size pattern assumed O(log(n))n = |V |, and, importantly, choice patterns assumed optimal.results provide us baseline evaluating fork-decomposition heuristicshI , hFI . First, however, Theorem 9 shows three heuristics worthanalyzing alone strictly informative two, dependingplanning task and/or state evaluated.7hF ,Theorem 9 (Undominance) uniform action cost partition, none heuristicfunctions hF , hI , hFI dominates another.Proof: proof example two tasks, 1 2 , illustrate followingtwo cases: hF (I) > hFI (I) > hI (I) hF (I) < hFI (I) < hI (I). two tasksdefined set binary-valued variables V = {v1 , v2 , v3 , u1 , u2 , u3 },initial state = {v1 : 0, v2 : 0, v3 : 0, u1 : 0, u2 : 0, u3 : 0}, goal7. Theorem 9 formulated proven uniform action cost partition use throughoutpaper, including experiments. per-step optimal action cost partitions (Katz & Domshlak, 2010),trivial show hFI dominates hF hI planning tasks.85fiKatz & DomshlakA1u1u2u3v1v2v3a1a2a3a4a5a6a7a8a9h{v1 : 0, u1 : 0, u2 : 0, u3 : 0}, {v1 : 1}ih{v2 : 0, u1 : 1, u2 : 0, u3 : 1}, {v2 : 1}ih{v3 : 0, u1 : 1, u2 : 1, u3 : 0}, {v3 1}ih{u1 : 0}, {u1 : 1}ih{u1 : 1}, {u1 : 0}ih{u2 : 0}, {u2 : 1}ih{u2 : 1}, {u2 : 0}ih{u3 : 0}, {u3 : 1}ih{u3 : 1}, {u3 : 0}i(a)1F11FI1/31/31/31111111111/31/31/31/31/31/31/41/41/41/41/41/41/41/41/4(c)u1u2u3v1 v2 v3v1 v2 v3v1 v2 v3Guf 1Guf 2Guf 3u1 u2 u3u1 u2 u3u1 u2 u3v1v2v3Gvi 1Gvi 2Gvi 3A2a1a2a3a4a5a6a7a8a9a10a11a12(b)h{v1 : 0, u1 : 1}, {v1 : 1}ih{v1 : 0, u2 : 1}, {v1 : 1}ih{v1 : 0, u3 : 1}, {v1 : 1}ih{v2 : 0, u1 : 1}, {v2 : 1}ih{v2 : 0, u2 : 1}, {v2 : 1}ih{v2 : 0, u3 : 1}, {v2 : 1}ih{v3 : 0, u1 : 1}, {v3 : 1}ih{v3 : 0, u2 : 1}, {v3 : 1}ih{v3 : 0, u3 : 1}, {v3 : 1}ih{u1 : 0}, {u1 : 1}ih{u2 : 0}, {u2 : 1}ih{u3 : 0}, {u3 : 1}i2F22FI1/31/31/31/31/31/31/31/31/31111111111111/31/31/31/41/41/41/41/41/41/41/41/41/41/41/4(d)Figure 8: Illustrations proof Theorem 9: (a) causal graphs 1 2 , (b) forkinverted fork subgraphs (same) causal graph 1 2 ,action sets (c) 1 (d) 2 , well costs action representativesabstract problem along subgraphs. Considering examplefirst row table (c), action a1 1 single representativethree fork abstractions, well representative inverted-fork abstraction1G . Hence, cost representatives F-decomposition 1/3,v1cost sole representative I-decomposition 1.G = {v1 : 1, v2 : 1, v3 : 1}. difference 1 2 action sets, listedFigure 8c-d, actions unit-cost actions. two tasks induce identicalcausal graphs, depicted Figure 8a. Hence, collections v-forks v-iforkstasks also identical; depicted Figure 8b. fractional costs tasksaction representatives corresponding abstract problems given Figure 8c-d.Figure 9 shows optimal plans abstract problems F-decompositions 1F ={1G f , 1G f , 1G f } 2F = {2G f , 2G f , 2G f }, I-decompositions 1I = {1G , 1G , 1G }u1u2u3u1u2u3v1v2v32I = {2G , 2G , 2G }, FI-decompositions 1FI = 1F 1I 2FI = 2F 2I .v1v2v3last column tables captures estimates three heuristics initialstates 1 2 , respectively. Together, two cases show none forkdecomposition heuristic functions hF , hI , hFI dominates other, and, since86fiImplicit Abstraction HeuristicshhFhIhFItask1G fu11G fu21G fu31Gv11Gv21Gv31G fu11G fu21G fu31Gv11Gv21Gvoptimal plancostha1 , a4 , a2 , a32ha1 , a2 , a6 , a32ha1 , a3 , a8 , a22ha11ha4 , a8 , a25/3ha4 , a6 , a35/3ha1 , a4 , a2 , a31ha1 , a2 , a6 , a31ha1 , a3 , a8 , a21ha11/4ha4 , a8 , a23/4ha4 , a6 , a33/4h(I)hhF6hI4 314 43h3FItaskoptimal plan2G fu12G fu22G fu32Gv12Gv22Gv32G fu12G fu22G fu32Gv12Gv22Gvha2 , a5 , a81ha1 , a4 , a71ha1 , a4 , a7costh(I)31ha10 , a14/3ha10 , a44/3ha10 , a74/3ha2 , a5 , a83/4ha1 , a4 , a73/4ha1 , a4 , a73/4ha10 , a11/2ha10 , a41/2ha10 , a71/2415/43(a)(b)Figure 9: Illustrations proof Theorem 9: Optimal plans abstract problems (a) 1 , hF (I) > hFI (I) > hI (I), (b) 2 ,hF (I) < hFI (I) < hI (I).variables binary-valued, claim holds conjunction arbitrary variabledomain abstractions.One conclusion Theorem 9 worth studying asymptotic performanceratios three heuristics. last three columns Table 4 present resultshF , hI , hFI Gripper, Logistics, Blocksworld, Miconic, Satellitedomains. also studied performance ratios max{hF , hI , hFI }, fivedomains appear identical hF . (Note ratio maxnecessarily identical max ratios, thus analysis worthwhile.) Takingconservative position, performance ratios fork-decomposition heuristicsTable 4 worst-case sense(i) neither optimize action cost partition (setting uniform restpaper) eliminate clearly redundant abstractions,(ii) use domain abstractions (up to) ternary-valued abstract domains only.domains fork roots abstracted using leave-one-out binary-valueddomain decompositions Eq. 16 domains inverted-fork sinksabstracted using distance-from-initial-value ternary-valued domain decompositionsEq. 15.Overall, results fork-decomposition heuristics Table 4 gratifying. First,note performance ratios hk hPDB 0. every subgoalset size k (for hk ) size log(n) (for hPDB ) reached number stepsdepends k (respectively, log(n)), n, h (sn ) grows linearly nfive domains. leaves us hPDBadd state-of-the-art (tractable87fiKatz & Domshlakand) admissible heuristic compare with. Table 4 shows asymptotic performanceFratio hF heuristic least good hPDBadd five domains, h+PDBsuperior hPDBadd Miconic, getting quite close h . comparing haddfork-decomposition heuristics, crucial recall ratios devised HelmertMattmuller hPDBadd respect optimal, manually-selected set patterns.contrast, selection variable subsets fork-decomposition heuristics completelynonparametric, thus requires tuning abstraction-selection process.rest section prove asymptotic performance ratios hF , hI ,FIh Table 4 five domains. begin brief outline resultsobtained. familiarity domains assumed. Next, domain addresseddetail: provide informal domain description well sas+ representation,prove lower upper bounds ratios three heuristics.Gripper Assuming n > 0 balls moved one room another, threeheuristics hF , hI , hFI account required pickup drop actions,O(1)-portion move actions. However, former actions responsible 2/3optimal-plan length (= cost). Now, basic uniform action-cost partition,hF , hI , hFI account whole, O(1/n), 2/3 total pickup/dropactions cost, respectively, providing ratios Table 4.8Logistics optimal plan contains least many load/unload actions move actions,three heuristics hF , hI , hFI fully account former, providing lower bound1/2. instance three heuristics achieve exactly 1/2 consists twotrucks t1 , t2 , airplanes, one city, n packages initial goallocations packages trucks pair-wise different.Blocksworld Arguments similar Helmert Mattmuller (2008) hPDBadd .Miconic three heuristics fully account loads/unload actions. addition, hFaccounts full cost move actions passengers initial locations,half cost move actions. provides us lowerbounds 1/2 5/6, respectively. Tightness 1/2 hI hFI showntask consisting n passengers, 2n + 1 floors, initial goal locationspair-wise different. Tightness 5/6 hF shown task consisting npassengers, n + 1 floors, elevator passengers initially floor n + 1,passenger wishes get floor i.Satellite length optimal plan problem n images taken ksatellites moved end-positions 6n + k. three heuristics fullyaccount image-taking actions one satellite-moving action per satelliteabove, providing lower bound 61 . Tightness 1/6 three heuristicsshown task follows: Two satellites instruments {i}li=1 {i}2li=l+1 ,respectively, l = n n. pair instruments {i, l + i} take imagesmodes {m0 , mi }. set directions {dj }nj=0 set image objectives8. note slight modification uniform action-cost partition results ratio 2/3three heuristics. optimizations, however, outside scope here.88fiImplicit Abstraction Heuristicsrightlefrobotrightb1b1bn...fGrightlefbn...b1rightrobotbnb1fGlef(a)...robotbnfGrobotlefbGbi , b Balls(b)Figure 10: Grippers (a) causal graph (b) corresponding collection v-forksv-iforks{oi }ni=1 that, 1 l, oi = (d0 , mi ) and, l < n, oi = (di , m0 ).Finally, calibration direction pair instruments {i, l + i} di .9.1 Gripperdomain consists one robot robot two arms Arms = {right, lef t}, two roomsRooms = {r1, r2}, set Balls n balls. robot pick ball armarm Arms arm empty, release ball b Balls arm arm arm currentlyholds b, move one room another. balls robot initially roomr1, arms empty, goal move balls room r2. naturaldescription planning task sas+ follows.Variables V = {robot} Arms Balls domainsD(robot) = RoomsD(lef t) = D(right) = Balls {empty}b Balls : D(b) = Rooms {robot}.Initial state = {b : r1 | b Balls} {robot : r1, right : empty, lef : empty}.Goal G = {b : r2 | b Balls}.Actions={M ove(r, r0 ) | {r, r0 } Rooms}[{P ickup(b, arm, r), Drop(b, arm, r) | b Balls, arm Arms, r Rooms},move robot: ove(r, r0 ) = h{robot : r}, {robot : r0 }i,pickup ball:P ickup(b, arm, r) = h{b : r, arm : empty, robot : r}, {b : robot, arm : b}i,drop ball: Drop(b, arm, r) = h{b : robot, arm : b, robot : r}, {b : r, arm : empty}i.(parametric n) causal graph task depicted Figure 10a.89fiKatz & DomshlakfrobotAction0ove(r, r )P ickup(b, arm, r)Drop(b, arm, r)farm,empty111022farm,bfarm,b0022011farm0 ,011ib122ib0111FFI11n1n+11n+11n+113n+613n+612n+512n+5Table 5: Number representatives original Gripper action abstract task,well partition action costs representativesfrobotfright,emptyfright,bfright,b0flef t,ibib0P ickup(b, right, r1) = h{robot : r1, b : r1}, {b : robot}iP ickup(b, right, r1)1 = h{right : empty}, {right : b}i,P ickup(b, right, r1)2 = h{right : b, b : r1}, {b : robot}iP ickup(b, right, r1)1 = h{right : empty}, {right : b}i,P ickup(b, right, r1)2 = h{right : b, b : r1}, {b : robot}iP ickup(b, right, r1) = h{right : b, b : r1}, {b : robot}iP ickup(b, right, r1) = h{right : b, b : r1}, {b : robot}iP ickup(b, right, r1)1 = h{right : empty}, {right : b}i,P ickup(b, right, r1)2 = h{right : b, robot : r1, b : r1}, {b : robot}iP ickup(b, right, r1) = h{right : empty}, {right : b}iTable 6: sets representatives original action P ickup(b, right, r1) abstracttasks9.1.1 Fork DecompositionSince variables robot, right, lef goal value, collection v-forksv-iforks Figure 10b. domains inverted fork sinks ternary valued.domains fork roots abstracted Eq. 16 (leave one out), thusF = {frobot } {fright, , flef t, | {empty} Balls},= {ib | b Balls},FI = {frobot } {fright, , flef t, | {empty} Balls} {ib | b Balls}.original action, number representatives abstract task, wellcost assigned representative, listed Table 5. Table 6 illustrates derivation numbers via decomposition example action P ickup(b, right, r1)fork decomposition abstractions. action one nonredundant representativefrobot , two representatives fright,empty fright,b , one representativefright,b0 b0 Balls \ {b}, one representative flef t, Balls {empty},two representatives ib , one representative ib0 b0 Balls \ {b}.11results cost 2n+5representative F , n+1representative ,13n+6 representative FI .Given that, optimal plans abstract tasks follows.90fiImplicit Abstraction HeuristicshtaskfrobothFfright,flef t,hIibfrobothFIfright,flef t,iboptimal planhP ickup(b1 , right, r1), . . . , P ickup(bn , right, r1),, ove(r1, r2), Drop(b1 , right, r2), . . . , Drop(bn , right, r2)ihP ickup(b1 , lef t, r1), . . . , P ickup(bn , lef t, r1),, Drop(b1 , lef t, r2), . . . , Drop(bn , lef t, r2)ihP ickup(b1 , right, r1), . . . , P ickup(bn , right, r1),, Drop(b1 , right, r2), . . . , Drop(bn , right, r2)ihP ickup(b, right, r1)1 , P ickup(b, right, r1)2 , ove(r1, r2), Drop(b, lef t, r2)2hP ickup(b1 , right, r1), . . . , P ickup(bn , right, r1), ove(r1, r2),, Drop(b1 , right, r2), . . . , Drop(bn , right, r2)ihP ickup(b1 , lef t, r1), . . . , P ickup(bn , lef t, r1),, Drop(b1 , lef t, r2), . . . , Drop(bn , lef t, r2)ihP ickup(b1 , right, r1), . . . , P ickup(bn , right, r1),, Drop(b1 , right, r2), . . . , Drop(bn , right, r2)ihP ickup(b, right, r1)1 , P ickup(b, right, r1)2 , ove(r1, r2), Drop(b, lef t, r2)2cost#4n+52n+512n2n+5n+12n2n+5n+131+ nn+112n +3n+6n+1n2n3n+6n+12n3n+6n+133n+61+ n+1h(I)2n 2n52n+54n+1n+114n3+ 4n+63n+6nAssuming n > 0 balls moved one room another, cost optimalplan original task 3n 1 n even, 3n n odd. Therefore,asymptotic performance ratios heuristics hF , hI , hFI Gripper 2/3, 0, 4/9,respectively.9.2 LogisticsLogistics task consists k cities, x airplanes, trucks n packages.city associated set Li = {li1 . . . , lii } locations within city; unionlocations cities denoted L = ki=1 Li . addition, precisely one locationcity airport, set airports LA = {l11 . . . , lk1 } L. truckmove within city located, airplanes fly airports.airplanes denoted U = {u1 , . . . , ux }, trucks = {t1 , . . . , ty },packages P = {p1 , . . . , pn }. Let Ti = {t | I[t] Li } denote trucks city i,P = P1 P2 P3 P4 P5 denote partition packages follows:package P1 = {p P | I[p], G[p] LA } initially airportneeds moved another airport,package P2 = {p P | I[p] LA Li , G[p] Lj \ LA , 6= j} initiallyairport needs moved non-airport location another city,package P3 = {p P | I[p] Li , G[p] Li } needs moved within onecity,package P4 = {p P | I[p] Li \ LA , G[p] LA \ Li } needs movednon-airport location one city airport city,package P5 = {p P | I[p] Li \ LA , G[p] Lj \ LA , 6= j} needs movednon-airport location one city non-airport location another city.natural Logistics task description sas+ follows.Variables V = U P domainsu U : D(u) = LA ,1 k, Ti : D(t) = Li ,p P : D(p) = L U T.91fiKatz & Domshlaku1 uxt1tyup1 . . .p1pi pn(a)u1 . . . uxpnGuf , u Up1 . . .pnGtf ,(b)t1 . . . typGpi , p PFigure 11: Logisticss (a) causal graph (b) corresponding collection v-forksv-iforksInitial state (LA )x L1 Lk (L)n .Goal G = {p1 : l1 , . . . , pn : ln } (L)n .ActionsA=k [ [[i=1 lLi tTi[ [lLA uU{Lt(p, t, l), U t(p, t, l) | p P } {M t(t, l, l0 ) |, l0 Li \ {l}}{La(p, u, l), U a(p, u, l) | p P } {M a(u, l, l0 ) | l0 LA \ {l}} ,load package p onto truck location l: Lt(p, t, l) = h{p : l, : l}, {p : t}i,unload package p truck location l: U t(p, t, l) = h{p : t, : l}, {p : l}i,move truck location l location l0 : t(t, l, l0 ) = h{t : l}, {t : l0 }i,load package p onto airplane u l: La(p, u, l) = h{p : l, u : l}, {p : u}i,unload package p airplane u l: U a(p, u, l) = h{p : u, u : l}, {p : l}i,move airplane u location l l0 : a(u, l, l0 ) = h{u : l}, {u : l0 }i.(parametrized n, x, y) causal graph Logistics tasks depicted Figure 11a.9.2.1 Fork DecompositionSince variables u U goal value, collection v-forks viforks Figure 11b. domains inverted-fork sinks abstractedEq. 15 (distance-from-initial-value), domains fork roots abstracted92fiImplicit Abstraction Heuristicsfu,l fu,l0 fu,l00 fu0 ,l ft,l ft,l0 ft,l00 ft0 ,l ip,m F FIAction0t(t, l, l )a(u, l, l0 )010100001010000012121111ni 2+ni11ni 2+ni(a)I[p] LA LiI[p] Li \ LAp P1 p P2 p P3 p P3 p P4p P5fu,l ft,l ip0 ,m ip,1 ip,1 ip,2 ip,1 ip,1 ip,1 ip,2 ip,1 ip,2 ip,3 F FIActionl Lil LjLa(p, u, l), U a(p, u, l)Lt(p, t, l), U t(p, t, l)1111110001011010101011001000011000010101nf1nf1nf1111nf +11nf +11nf +1(b)Figure 12: Number representatives original Logistics action abstracttask, well partition action costs representatives;tables (a) (b) capture move load/unload actions, respectivelyEq. 16 (leave-one-out). Thus,F =[ [uU lLA=FI ={fu,l }[[k [ [[i=1 tTi lLi{ip,1 }{ip,2 }pPpP2 P4 P5[ [uU lLA{fu,l }{ft,l },[pP5k [ [[i=1 tTi lLi{ip,3 },{ft,l }[pP{ip,1 }[{ip,2 }pP2 P4 P5[pP5{ip,3 }.Ptotal number forks nf = |F | = |U | |LA | + ki=1 |Ti | |Li |, total numberinverted forks ni = |I | = |P1 | + 2 |P2 | + |P3 | + 2 |P4 | + 3 |P5 |. actionA, number representatives abstract task, well cost assignedrepresentative, given Figure 12. row tables Figure 12corresponds certain Logistics action, column (except last three) representsabstract task, entry captures number representatives actioncorresponding task. last three columns show portion total costgiven action representative task, three heuristics question.9.2.2 Lower BoundNote optimal plan Logistics task contains least many load/unloadactions move actions. Thus, following lemma provides us lower bound1/2 three heuristics question.93fiKatz & DomshlakLemma 1 Logistics task, hF , hI , hFI account full cost load/unloadactions required optimal plan task.Proof: Logistics task, optimal plans task contain amountload/unload actions package p P follows.p P1 :2 actions one load onto airplane, one unload airplane,p P2 : 4 actions one load onto airplane, one unload airplane, one loadonto truck, one unload truck,p P3 :2 actions one load onto truck, one unload truck,p P4 : 4 actions one load onto truck, one unload truck, one load ontoairplane, one unload airplane,p P5 : 6 actions two loads onto trucks, two unloads trucks, one loadonto airplane, one unload airplane.Consider fork-decomposition F . optimal plan abstract taskscontain number load/unload actions exactly (the effects actionsremain unchanged tasks). cost representative load/unloadaction n1f , nf abstract tasks. Therefore, heuristic hF fully accountscost required load/unload actions.consider fork-decomposition . domain-decompositionindex abstraction, optimal plan abstract task ip,m include one loadone unload actions follows.p P1 :one load onto airplane one unload airplane,p P2 , = 1:one load onto airplane one unload airplane,p P2 , = 2:one load onto truck one unload truck,p P3 :one load onto truck one unload truck,p P4 , = 1:one load onto truck one unload truck,p P4 , = 2:one load onto airplane, one unload airplane,p P5 , = 1:one load onto truck one unload truck,p P5 , = 2:one load onto airplane one unload airplane,p P5 , = 3:one load onto truck one unload truck.cost representative load/unload actions 1, thus heuristic hI fullyaccounts cost required load/unload actions.Finally, consider fork-decomposition FI . optimal plan forkstructured abstract tasks contain number load/unload actions F .cost representative load/unload actions nf1+1 nf abstracttasks. addition, load/unload actions also appear exactly one invertedfork-structured abstract task. Therefore heuristic hFI also fully accounts costrequired load/unload actions.94fiImplicit Abstraction Heuristicst1p1t2...pnp1Gtf1t1...t2pnpGpi , p PGtf2Figure 13: Collection v-forks v-iforks Logistics task used proofupper bound 1/29.2.3 Upper Boundinstance three heuristics achieve exactly 1/2 consists two trucks t1 , t2 ,airplanes, one city, n packages initial goal locations packagespairwise different, trucks initially located yet another location.+formally, L = {li }2ni=0 , = {t1 , t2 }, sas encoding Logistics taskfollows.Variables V = {t1 , t2 , p1 , . . . , pn } domains: D(t) = L,p P : D(p) = L T.Initial state = {t1 : l0 , t2 : l0 , p1 : l1 , . . . , pn : ln }.Goal G = {p1 : ln+1 , . . . , pn : l2n }.Actions = {Lt(p, t, l), U t(p, t, l) | l L, T, p P } {M t(t, l, l0 ) | T, {l, l0 }L}.collection v-forks v-iforks task depicted Figure 13. domainsinverted-fork sinks abstracted Eq. 15 (distance-from-initial-value),domains fork roots abstracted Eq. 16 (leave-one-out), thereforeF = {ft1 ,l ft2 ,l | l L},= {ip,1 | p P },FI = {ft1 ,l ft2 ,l | l L} {ip,1 | p P }.total number forks thus nf = 4n + 2 total number inverted forksni = n. partition action costs Logistics tasks described Figure 12.P = P3 thus action cost partition follows.ft,lAction0t(t, l, l )Lt(p, t, l)U t(p, t, l)111ft,l0111ft,l00011ft0 ,l01195ip,1111ip0 ,1FFI0001214n+214n+21n1n+214n+314n+311fiKatz & DomshlakGiven that, optimal plans abstract taskhtaskhFft1 ,lft2 ,lipi ,1ft1 ,lft2 ,lipi ,1hIhFIoptimal planhLt(p1 , t2 , l1 ), . . . , Lt(pn , t2 , ln ), U t(p1 , t2 , ln+1 ), . . . , U t(pn , t2 , l2n )ihLt(p1 , t1 , l1 ), . . . , Lt(pn , t1 , ln ), U t(p1 , t1 , ln+1 ), . . . , U t(pn , t1 , l2n )ihM t(t1 , l0 , li ), Lt(pi , t1 , li ), t(t1 , li , ln+i ), U t(pi , t1 , ln+i )ihLt(p1 , t2 , l1 ), . . . , Lt(pn , t2 , ln ), U t(p1 , t2 , ln+1 ), . . . , U t(pn , t2 , l2n )ihLt(p1 , t1 , l1 ), . . . , Lt(pn , t1 , ln ), U t(p1 , t1 , ln+1 ), . . . , U t(pn , t1 , l2n )ihM t(t1 , l0 , li ), Lt(pi , t1 , li ), t(t1 , li , ln+i ), U t(pi , t1 , ln+i )icost#2n4n+22n4n+22+2n2n4n+32n4n+32n + 12n + 1n2n + 12n + 1n2n+2+24n+3h(I)2n2n + 22n +2nn+2optimal plan original task, e.g., hM t(t1 , l0 , l1 ), Lt(p1 , t1 , l1 ), t(t1 , l1 , l2 ), Lt(p2 , t1 , l2 ),t(t1 , l2 , l3 ), . . . , Lt(pn , t1 , ln ), t(t1 , ln , ln+1 ), U t(p1 , t1 , ln+1 ), t(t1 , ln+1 , ln+2 ), U t(p2 , t1 , ln+2 ),t(t1 , ln+2 , ln+3 ), . . . , U t(pn , t1 , l2n )i,cost 4n, providing us upper bound1/2 three heuristics. Putting lower upper bounds together, asymptoticratio three heuristics question 1/2.9.3 BlocksworldBlocksworld task consists table table, crane c, n + 1 blocks B ={b1 , . . . , bn+1 }. block either table, top block,held crane. crane pick block currently holds nothing,block block top it. crane drop held block tabletop block.Consider Blocksworld task follows. blocks initially form towerb1 , . . . , bn , bn+1 bn+1 table, goal move formtower b1 , . . . , bn1 , bn+1 , bn bn table. is, goal swaplowest two blocks tower. natural description task sas+ follows.Variables V = {b, clearb | b B} {c} domainsD(c) = {empty} B,b B : D(b) = {table, c} B \ {b},D(clearb ) = {yes, no}.Initial state= {c : empty, bn+1 : table, clearb1 : yes}[{bi : bi+1 | 1 n}[{clearb : | b B \ {b1 }} .Goal G = {bn : table, bn+1 : bn , bn1 : bn+1 } {bi : bi+1 | 1 n 2}.Actions = {PT (b), DT (b) | b B} {P (b, b0 ), D(b, b0 ) | {b, b0 } B}pick block b table: PT (b) = h{c : empty, b : table, clearb : yes}, {cb, b : c}i,pick block b block b0 :P (b, b0 ) = h{c : empty, b : b0 , clearb : yes, clearb0 : no}, {c : b, b : c, clearb0 : yes}i,96fiImplicit Abstraction Heuristicscclearb1 . . . clearbn+1cbGbi , b {bn1 , bn , bn+1 }clearb0clearbcb0bbn1bnclearbbn+1bn1Gcf(a)bnbn+1fGclear,b Bb(b)Figure 14: (a) Causal graph (b) corresponding collection v-forks v-iforksBlocksworld task used proofdrop block b table: DT (b) = h{c : b, b : c}, {c : empty, b : table}i,drop block b block b0 :D(b, b0 ) = h{c : b, b : c, clearb0 : yes}, {c : empty, b : b0 , clearb0 : no}i.schematic version causal graph task depicted Figure 14a. Sincevariables bn1 , bn , bn+1 goal values different values initialstate, collection v-forks v-iforks Figure 14b. (leave-one-out,Eq. 16) domain abstraction variable c, c-fork Gcf breaks n + 2 abstracttasks. sinks v-iforks Gbi n1 , Gbi n , Gbi n+1 also go process domaindecomposition (distance-from-initial-value, Eq. 15). However, due structuredomain transition graphs block variables, domain decomposition resultssingle abstract task v-iforks. ThusF ={fc,empty } {fc,b | b B} {fclearb | b B},={ibn1 ,1 , ibn ,1 , ibn+1 ,1 },FI ={fc,empty } {fc,b | b B} {fclearb | b B} ibn1 ,1 , ibn ,1 , ibn+1 ,1 }.technically straightforward verify that, abstract task F , , FI ,exists plan (i) involves representatives actions{P (bn1 , bn ), DT (bn1 ), P (bn , bn+1 ), DT (bn ), PT (bn+1 ), D(bn+1 , bn ), PT (bn1 ), D(bn1 , bn+1 )} ,(21)(ii) involves representative original action once. Even togetherplans account total cost eight actions Eq. 21, total costplans (and thus estimates three heuristics) upper-bounded 8,optimal plan original task, e.g., hP (b1 , b2 ), DT (b1 ), P (b2 , b3 ), DT (b2 ), . . . , P (bn , bn+1 ), DT (bn ),PT (bn+1 ), D(bn+1 , bn ), PT (bn1 ), D(bn1 , bn+1 ), PT (bn2 ), D(bn2 , bn1 ), . . . , PT (b1 ), D(b1 , b2 )i, cost97fiKatz & Domshlakep1ep1pnGef(a)epn(b)pGpi , p PFigure 15: Miconics (a) causal graph (b) corresponding collection v-forksv-iforks4n. Hence, asymptotic performance ratio three heuristics Blocksworlddomain 0.9.4 MiconicMiconic task consists one elevator e, set floors F , passengers P .elevator move |F | floors floor load and/or unload passengers.natural sas+ description Miconic task follows.Variables V = {e} P domainsD(e) = F,p P : D(p) = F {e}.Initial state = {e : fe } {p : fp | p P } (F )|P |+1 .Goal G = {p : fp0 | p P } (F )|P | .Actions = {In(p, f ), Out(p, f ) | f F, p P } {M ove(f, f 0 ) | {f, f 0 } F },load passenger p e floor f : In(p, f ) = h{e : f, p : f }, {p : e}i,unload passenger p e floor f : Out(p, f ) = h{e : f, p : e}, {p : f }i,move elevator floor f floor f 0 : ove(f, f 0 ) = h{e : f }, {e : f 0 }i.(parametrized n) causal graph Miconic tasks depicted Figure 15a,Figure 15b depicts corresponding collection v-forks v-iforks. domainsinverted-fork sinks abstracted Eq. 15 (distance-from-initial-value),domains fork roots abstracted Eq. 16 (leave-one-out). Thus,F = {fe,f | f F },= {ip,1 | p P },FI = {fe,f | f F } {ip,1 | p P }.total number fork-structured abstract tasks thus nf = |F | = |F |total number inverted fork structured abstract tasks ni = |I | = |P |.action A, number representatives abstract task, well costassigned representative, given Table 7.98fiImplicit Abstraction HeuristicsActionove(f, f 0 )In(p, f )In(p0 , f )Out(p, f )Out(p0 , f )fe,f fe,f 0 fe,f 00 ip,1 ip0 ,1 F FI1111111111011111101010101121nf1nf1nf1nf11ni 2+ni1 nf1+11 nf1+11 nf1+11 nf1+1Table 7: Number representatives original Miconic action abstract task,well partition action costs among representatives9.4.1 Lower BoundsFirst, Miconic special case Logistics domain, Lemma 1 applies analogously, package P3 corresponding passenger. Thus, p P ,three heuristics account full cost load/unload actions required optimalplan task.Let us focus abstract tasks F = {fe,f | f F }. Recall task fe,finduced e-fork and, terms domain decomposition, distinguishesfloor f somewhere else. Without loss generality, set floors Frestricted initial goal values variables, optimalplan move elevator floor f neither initial goal locationpassenger elevator. Let FI = {I[p] | p P } FG = {G[p] | p P }. costsoptimal plans abstract task fe,f follows.f FI FG : Let p, p0 P pair passengers initial goal locations f ,respectively; is, I[p] = G[p0 ] = f . f = I[e], plan fe,f moveelevator f order load passenger p0 , move elevator backf order unload passenger p0 . Therefore cost plan fe,f|least 2|P|F | + 1, (see last three columns Table 7) first componentsummation comes summing costs representatives load/unloadactions passengers, second component sum costsrepresentatives two respective move actions. Similarly, f 6= I[e],plan fe,f move elevator f order load passenger p,move elevator f order unload p. Therefore, well, cost|plan fe,f least 2|P|F | + 1.f FI \ FG : Let p P passenger initially f , is, I[p] = f . f = I[e],plan fe,f move elevator f order unload p, thuscost plan fe,f least2|P ||F |+ 12 . Otherwise, f 6= I[e], planfe,f move elevator f order load p, move elevatorf order unload p. Hence, case, cost plan fe,fleast2|P ||F |+ 1.99fiKatz & Domshlakf FG \ FI : Let p P passenger must arrive floor f , is, G[p] = f .f = I[e], plan fe,f move elevator f order load p,move elevator back f order unload p. Hence, well,|cost plan fe,f least 2|P|F | + 1. Otherwise, f 6= I[e], planfe,f move elevator f order unload p, thus cost planfe,f least2|P ||F |+ 12 .f 6 FG FI : f = I[e], plan fe,f include move f order|1load/unload passengers, thus cost plan fe,f least 2|P|F | + 2 .Otherwise, f 6= I[e], elevator initially set locations,|thus cost plan fe,f least 2|P|F | .Putting case-by-case analysis together,|FG \FI |,I[e] FI FG2|P | + |FI FG | + |FI \ FG | +22|P | + |F F | + |F \ F | 1 + 1 + |FG \FI | , I[e] F \ FGGG22.hF (I)|FG \FI |12|P|+|FF|+|F\F|+1+,I[e]F\FGGG22|P | + |F F | + |F \ F | + |FG \FI |1 + 1 ,I[e] 6 FG FIGG22Note value second case lowest. gives us lower bound hFestimate Eq. 22.|FG \ FI |1+ |FI FG | .(22)22Now, let us provide upper bound length (= cost) optimal planMiconic task. First, let P 0 P denote set passengers initial goallocations FI FG . Let m(P 0 , FI FG ) denote length optimal traversalfloors FI FG that, passenger p P 0 , visit I[p] comes visitG[p]. Given that, case-by-case basis, (not necessarily optimal) plan Miconictask hand follows.hF (I) 2|P | + |FI \ FG | +I[e] FI FG : Collect passengers I[e] any, traverse floorsFI \ FG collect passengers floors, move elevator firstfloor f optimal path traversing floors FI FG , drop passengerswhose destination f , collect new passengers any, keep moving alongcollecting dropping passengers initial target floors,traverse FG \ FI , dropping remaining passengers destinations.cost plan (and thus optimal plan) upper-bounded Eq. 23below.h (I) 2|P | + |FI \ FG | + m(P 0 , FI FG ) + |FG \ FI |.(23)I[e] FI \ FG : Collect passengers I[e] any, traverse floorsFI \ FG collect passengers floors making sure traversalends first floor f optimal path traversing floors FI FG ,follow collecting dropping passengers initial target floors,traverse FG \ FI , dropping remaining passengers destinations.first case, cost plan upper-bounded Eq. 23.100fiImplicit Abstraction HeuristicsI[e] 6 FI : Traverse floors FI \ FG collect passengers floors,move along optimal path traversing floors FI FG collectingdropping passengers initial target floors, traverse floorsFG \ FI , dropping remaining passengers destinations. well,cost plan upper-bounded expression Eq. 23.Lemma 2 Miconic task passengers P ,hF (I)h (I)5|P |16|P | .Proof: Recall P 0 P set passengers initial goal locationsFI FG . First give two upper bounds length optimal traversalfloors FI FG that, passenger p P 0 , visit I[p] comes visitG[p]. Theorem 5.3.3 Helmert (2008)m(P 0 , FI FG ) = |FI FG | + (G 0 ),(24)(G 0 ) size minimum feedback vertex set directed graph G 0 =(V 0 , E 0 ), V 0 = FI FG E 0 containing arc f f 0 passengerp P 0 initially floor f arrive floor f 0 .Note (G 0 ) trivially bounded number graph nodes V 0 . addition,observe that, order nodes V 0 , arcs E 0 partitioned forward0backward arcs, one subsets must contain |E2 | arcs. RemovingG 0 nodes origins arcs smaller subset E 0 resultsdirected acyclic graph. Hence, set removed nodes (not necessarily minimum)0feedback vertex set G 0 , size set larger |E2 | . Putting twobounds (G 0 ) together Eq. 24 obtain|P 0 |0m(P , FI FG ) min 2|FI FG |, |FI FG | +.(25)2disjointness FG \ FI FI FG , fact goalpassengers P 0 FI , |FG \ FI | |P | |P 0 |. Eqs. 22 232|P | + |FI \ FG | + |FG2\FI | + |FI FG | 12hF.h2|P | + |FI \ FG | + |FG \ FI | + m(P 0 , FI FG )(26)Finterested lower bound ratio hh , right-hand sideinequality minimized, thus safely set |FI \ FG | = 0 |FG \ FI | =|P | |P 0 |, obtaining0|2|P | + |P ||P+ |FI FG | 12hF5|P | |P 0 | + 2|FI FG | 12=.h2|P | + |P | |P 0 | + m(P 0 , FI FG )6|P | 2|P 0 | + 2m(P 0 , FI FG )(27)Let us examine right-most expression Eq. 27 respect two upper boundsm(P 0 , FI FG ) Eq. 25.minimum obtained 2|FI FG |, m(P 0 , FI FG ) 2|FI FG |0|FI FG | + |P2 | , last inequality reformulated2|FI FG | |P 0 | 0.101fiKatz & Domshlakallows us provide lower bound right-most expression Eq. 27,Fthus hhhF5|P | |P 0 | + 2|FI FG | 15|P | + (2|FI FG | |P 0 |) 15|P | 1.h6|P | 2|P 0 | + 2m(P 0 , FI FG )6|P | + 2(2|FI FG | |P 0 |)6|P |(28)00minimum obtained |FI FG |+ |P2 | , m(P 0 , FI FG ) |FI FG |+ |P2 | <2|FI FG |, last inequality reformulated2|FI FG | |P 0 | > 0.allows us provide lower boundhFhvia Eq. 275|P | |P 0 | + 2|FI FG | 15|P | + (2|FI FG | |P 0 |) 15|P | 1hF.000h6|P | 2|P | + 2m(P , FI FG )6|P | + (2|FI FG | |P |)6|P |(29)Note lower boundslemma.hFhEq. 28 Eq. 29 required claim9.4.2 Upper BoundsMiconic task heuristic hF achieves performance ratio exactly 5/6consists elevator e, floors F = {fi }ni=0 , passengers P = {pi }ni=1 , passengerselevator initially f0 , target floors passengers pairwisedisjoint. sas+ encoding Miconic task follows.Variables V = {e} P domains D(e) = F p P : D(p) = F {e}.Initial state = {e : f0 , p1 : f0 , . . . , pn : f0 }.Goal G = {p1 : f1 , . . . , pn : fn }.Actions = {In(p, f ), Out(p, f ) | f F, p P } {M ove(f, f 0 ) | {f, f 0 } F }.causal graph task corresponding collection v-forks (consistingone e-fork) depicted Figure 15. domain e abstracted Eq. 16(leave-one-out), providing usF = {fe,f0 , fe,f1 , . . . , fe,fn }.costs action representatives abstract tasks given Table 7nf = n + 1. optimal plans abstract tasks Ftask optimal planfe,f0fe,f1fe,fncosthIn(p1 , f0 ), . . . , In(pn , f0 ), ove(f0 , f1 ), Out(p1 , f1 ), . . . , Out(pn , fn )ihIn(p1 , f0 ), . . . , In(pn , f0 ), Out(p2 , f2 ), . . . , Out(pn , fn ), ove(f0 , f1 ), Out(p1 , f1 )ihIn(p1 , f0 ), . . . , In(pn , f0 ), Out(p1 , f1 ), . . . , Out(pn1 , fn1 ), ove(f0 , fn ), Out(pn , fn )i102121212+++2nn+12nn+12nn+1#hF (I)n+15n+12fiImplicit Abstraction Heuristicsoptimal plan original task, hIn(p1 , f0 ), . . . , In(pn , f0 ), ove(f0 , f1 ), Out(p1 , f1 ),cost 3n, providing usFupper bound 5/6 h heuristic Miconic. Putting upper bound togetherpreviously obtained lower bound 5/6, conclude asymptotic performanceratio hF Miconic 5/6.Miconic task heuristics hI hFI achieve exactly 1/2 consistsnelevator e, floors F = {fi }2ni=0 , passengers P = {pi }i=1 , initial target floorspassengers elevator pairwise disjoint. task description sas+follows.ove(f1 , f2 ), Out(p2 , f2 ), ove(f2 , f3 ), . . . , Out(pn , fn )i,Variables V = {e} P domains D(e) = F p P : D(p) = F {e}.Initial state = {e : f0 , p1 : f1 , . . . , pn : fn }.Goal G = {p1 : fn+1 , . . . , pn : f2n }.Actions = {In(p, f ), Out(p, f ) | f F, p P } {M ove(f, f 0 ) | {f, f 0 } F }.causal graph task corresponding collection v-forks v-iforksdepicted Figure 15. domains inverted-fork sinks abstracted Eq. 15(distance-from-initial-value), domains fork roots abstractedEq. 16 (leave-one-out). provides us= {ip1 ,1 , . . . , ipn ,1 },FI = {fe,f0 , fe,f1 , . . . , fe,fn , fe,fn+1 , . . . , fe,f2n , ip1 ,1 , . . . , ipn ,1 }.costs action representatives abstract tasks given Table 7nf = 2n + 1 ni = n. optimal plans abstract tasks FIhtaskoptimal planhIipi ,1fe,f0hM ove(f0 , fi ), In(pi , fi ), ove(fi , fn+i ), Out(pi , fn+i )ihM ove(f0 , f1 ), In(p1 , f1 ), . . . , In(pn , fn ),Out(p1 , fn+1 ), . . . , Out(pn , f2n )ihM ove(f0 , f1 ), In(p1 , f1 ), ove(f1 , f2 ), In(p2 , f2 ), . . . , In(pn , fn ),Out(p1 , fn+1 ), . . . , Out(pn , f2n )ihM ove(f0 , fn ), In(pn , fn ), ove(fn , f1 ),In(p1 , f1 ), . . . , In(pn1 , fn1 ), Out(p1 , fn+1 ), . . . , Out(pn , f2n )ihIn(p1 , f1 ), . . . , In(pn , fn ), Out(p2 , fn+2 ), . . . , Out(pn , f2n ),ove(f0 , fn+1 ), Out(p1 , fn+1 )ihIn(p1 , f1 ), . . . , In(pn , fn ), Out(p1 , fn+1 ), . . . , Out(pn1 , f2n1 ),ove(f0 , f2n ), Out(pn , f2n )ihM ove(f0 , fi ), In(pi , fi ), ove(fi , fn+i ), Out(pi , fn+i )ihFIfe,f1fe,fnfe,fn+1fe,f2nipi ,1cost#h(I)n12n + 21n+2+22n+ 2n+22n+2+2n2n+2n2n+2+2n2n+21n+2+2n2n+21n+2+2n2n+22n+2+22n+22n2n +5n+1n+2nnoptimal plan original task, hM ove(f0 , f1 ), In(p1 , f1 ), ove(f1 , f2 ), In(p2 , f2 ),ove(f2 , f3 ), . . . , In(pn , fn ), ove(fn , fn+1 ), Out(p1 , fn+1 ), ove(fn+1 , fn+2 ), Out(p2 , fn+2 ),ove(fn+2 , fn+3 ), . . . , Out(pn , f2n )i, cost 4n, providing us upper bound1/2 hI hFI heuristics Miconic. Putting upper bound togetherpreviously obtained lower bound 1/2, conclude asymptotic performance ratiohI hFI Miconic 1/2.103fiKatz & Domshlak9.5 SatelliteSatellite domain quite complex. Satellite tasksconsists satellites S,finite set instruments onboard, = sS . set imagemodes M, mode M, set Im instruments supportingmode m. Likewise, set directions L, image objectives LM, functionscal : 7 L, p0 : 7 L, p : S0 7 L S0 S, cal calibration targetdirection function, p0 initial direction function, p goal pointing directionfunction.Let us denote Oi = {o = (d,Sm) | Im } subset imagestaken instrument i, Os = iIs Oi subset images takeninstruments satellite s, Sm = {s | Im 6= } subset satellitestake images mode m. problem description sas+ follows.Variables V = {Oni , Ci | I} domains: D(s) = L,: D(Oni ) = D(Ci ) = {0, 1},: D(o) = {0, 1}.Initial state = {s : p0 (s) | S} {Oni : 0, Ci : 0 | I} {o : 0 | O}.Goal G = {s : p (s) | S0 } {o : 1 | O}.Actions[A={T urn(s, d, d0 ) | {d, d0 } L} {SwOn(i, s), Cal(i, s), SwOf f (i) | }sS{T akeIm(o, d, s, i) | = (d, m) O, Sm , Im },turn satellite: urn(s, d, d0 ) = h{s : d}, {s : d0 }i,power instrument: SwOn(i, s) = h{Oni0 : 0 | i0 }, {Oni : 1}i,power instrument: SwOf f (i) = h{Oni : 1}, {Oni : 0, Ci : 0}i,calibrate instrument: Cal(i, s) = h{Ci : 0, Oni : 1, : cal(i)}, {Ci : 1}i,take image: akeIm(o, d, s, i) = h{o : 0, Ci : 1, : d}, {o : 1}i.9.5.1 Fork Decompositioncausal graph example Satellite task representative subset collectionv-forks v-iforks depicted Figure 16. Since variables {Oni , Ci | I}S \S0goal value, collection v-forks v-iforks follows generalcase.satellite S, s-fork leaves Os .104fiImplicit Abstraction Heuristicso1o2o3o4s1C3s2s2C1C2C4On1On2On3On4C5C7o1C6o3C5o4Gsf 2s1o3C6o1fGC5s2C2C7o3fGC6C4o4fGC7C7On7o4On5On6(a)Goi 4(b)Figure 16: Satellite example task (a) causal graph (b) representative subsetcollection v-forks v-iforksinstrument I, Ci -fork leaves Oi .image objective = (d, m) O, o-ifork parents {Ci | Im }Sm .root domains forks rooted instruments inverted-fork sinksbinary first place, root domains forks rooted satellitesabstracted Eq. 16 (leave-one-out). provides usF = {fs,d | S, L} {fCi | I},= {io | O},FI = {fs,d | S, L} {fCi | I} {io | O}.total number forks thus nf = |S| |L| + |I| total number invertedforks ni = |O|. action A, number representatives abstracttask, well cost assigned representative, given Figure 17.9.5.2 Lower BoundsFirst, note optimal plan Satellite task contains 6 actions per imageobjective one action per satellite S0 I[s] 6= G[s]. showthree heuristics fully account cost least one action per imageobjective one action per satellite. provide us lowerbound 1/6 asymptotic performance ratios three heuristics.Lemma 3 Satellite task, hF , hI , hFI fully account cost leastone Take Image action akeIm(o, d, s, i) image objective O.Proof: image objective = (d, m) O, actions akeIm(o, d, s, i) = h{o :0, Ci : 1, : d}, {o : 1}i appear optimal plans |Sm | |L| fork abstract tasks rooted105fiKatz & Domshlakfs,dAction0urn(s, d, )SwOn(i, s)Cal(i, s)SwOf f (i)1000fs,d01000fs,d00fs0 ,d00000000fCi0011fCi00000Oi Os \ Oi 6 OsioioioF101110001200000111|O |FI1|O |+2001|Oi |1|Oi |1|Oi |+11|Oi |+1(a)ActionakeIm(o, d, s, i),= (d, m)s0 Sm s0 6 Sm i0 Im i0 6 Imfs0 ,d0fs0 ,d0fCi0fCi0io io0101010FFI1|Sm ||L|+|Im |11|Sm ||L|+|Im |+1(b)Figure 17: Number representatives original Satellite action abstracttask, well partition action costs representatives;table (a) shows Turn, Switch On, Switch Off, Calibrate actions,table (b) shows Take Image actionssatellites, |Im | fork abstract tasks rooted instrument calibration status variables Ci ,one inverted-fork abstract task sink o. Together costs actionrepresentatives abstract problems (see Figure 17),hF : cost representativetasks,1|Sm ||L|+|Im ||Sm | |L| + |Im | fork abstracthI : cost representative 1 one inverted fork abstract task,hFI : cost representativetasks.1|Sm ||L|+|Im |+1|Sm | |L| + |Im | + 1 abstractTherefore, O, cost one akeIm(o, d, s, i) action fully accountedthree heuristics.Lemma 4 Satellite task, hF , hI , hFI fully account cost leastone Turn action urn(s, d, d0 ) S0 I[s] 6= G[s].Proof: S0 satellite I[s] 6= G[s], action urn(s, I[s], d0 ) appearoptimal plan fs,I[s] , action urn(s, d, G[s]) appear optimal planfs,G[s] , Os , action urn(s, d, G[s]) appear optimal planio . Together costs action representatives abstract problems (seeFigure 17)hF : cost representative122 fork abstract tasks,106fiImplicit Abstraction HeuristicshI : cost representativehFI : cost representative1|Os ||Os | inverted fork abstract tasks,1|Os |+2|Os | + 2 abstract tasks.Therefore, S0 I[s] 6= G[s], cost one urn(s, d, d0 ) actionfully accounted three heuristics.hhTogether, Lemmas 3 4 imply that, h {hF , hI , hFI }, Satellite1/6.9.5.3 Upper BoundSatellite task three heuristics achieve ratio exactly 1/6 consiststwo identical satellites = {s, s0 } l instruments each, = Is0 = {1, . . . , l} {l +1, . . . , 2l}, instruments {i, l+i} two modes each: m0 mi . setn + 1 directions L = {dI , d1 , . . . , dn } set n image objectives = {o1 , . . . , }, oi =(dI , mi ) 1 l oi = (di , m0 ) l < n. calibration directioninstruments {i, l + i} di . sas+ encoding planning task follows.Variables V = {Oni , Ci | I}.Initial state = {s : dI | S} {Oni : 0, Ci : 0 | I} {o : 0 | O}.Goal G = {o : 1 | O}.Actions[A={T urn(s, d, d0 ) | {d, d0 } L} {SwOn(i, s), Cal(i, s), SwOf f (i) | }sS[sS{T akeIm((dI , mi ), dI , s, i) | }n[{T akeIm((dj , m0 ), dj , s, i) | } .j=l+1causal graph task depicted Figure 18a. state variables {Oni , Ci |I} goal value, thus collection v-forks v-iforks taskFigure 18b. domains inverted-fork sinks binary, domainsfork roots abstracted Eq. 16 (leave-one-out). provides usF = {fs,d , fs0 ,d | L} {fCi | I},= {io | O},FI = {fs,d , fs0 ,d | L} {fCi | I} {io | O}.total number forks task nf = 2n + 2l + 2 total number invertedforks ni = n. costs action representatives abstract task given0Figure 17, |Os | = |Os | = |O| = n, |Oi | = n l + 1, |Sm | = 2, |Im0 | = 2l, |Imi | = 2,|L| = n + 1.optimal plans per abstract task depicted Table 8, optimal planoriginal problem, hSwOn(1, s), urn(s, dI , d1 ), Cal(1, s), urn(s, d1 , dI ), akeIm(o1 , dI , s, 1),107fiKatz & Domshlaks0o1C1okoiCl+1ClCiol+1s0o1 . . .o1 . . .GsfGsf 0Cl+iC2lOniOn1Cis0Cioiol+1 . . .fGC,iCl+is0C1 . . . C2lOnl+iOnlOnl+1On2loioiGoi , 1 lGoi , l < n(a)(b)Figure 18: (a) Causal graph (b) corresponding collection v-forks v-iforksSatellite task used proof upper bound 1/6hhFhIhFItaskoptimal plancosthT akeIm(o1 , dI , s0 , l+1), . . . , akeIm(ol , dI , s0 , 2l),fs,dakeIm(ol+1 , dl+1 , s0 , 2l), . . . , akeIm(on , dn , s0 , 2l)ihT akeIm(o1 , dI , s, 1), . . . , akeIm(ol , dI , s, l),fs0 ,dakeIm(ol+1 , dl+1 , s, l), . . . , akeIm(on , dn , s, l)ihT akeIm(oi , dI , s0 , l + i),fCi ,akeIm(ol+1 , dl+1 , s0 , 2l), . . . , akeIm(on , dn , s0 , 2l)ihT akeIm(oi , dI , s, i),fCi , Is0akeIm(ol+1 , dl+1 , s, l), . . . , akeIm(on , dn , s, l)iioj , 1 j l hT urn(s, dI , dj ), Cal(j, s), urn(s, dj , dI ), akeIm(oj , dI , s, j)iioj , l < j n hT urn(s, dI , d1 ), Cal(1, s), urn(s, d1 , dj ), akeIm(oj , dI , s, 1)ihT akeIm(o1 , dI , s0 , l + 1), . . . , akeIm(ol , dI , s0 , 2l),fs,dakeIm(ol+1 , dl+1 , s0 , 2l), . . . , akeIm(on , dn , s0 , 2l)ihT akeIm(o1 , dI , s, 1), . . . , akeIm(ol , dI , s, l),fs0 ,dakeIm(ol+1 , dl+1 , s, l), . . . , akeIm(on , dn , s, l)ihT akeIm(oi , dI , s0 , l + i),fCi ,akeIm(ol+1 , dl+1 , s0 , 2l), . . . , akeIm(on , dn , s0 , 2l)ihT akeIm(oi , dI , s, i),fCi , Is0akeIm(ol+1 , dl+1 , s, l), . . . , akeIm(on , dn , s, l)iioj , 1 j l hT urn(s, dI , dj ), Cal(j, s), urn(s, dj , dI ), akeIm(oj , dI , s, j)iioj , l < j n hT urn(s, dI , d1 ), Cal(1, s), urn(s, d1 , dj ), akeIm(oj , dI , s, 1)i#l2n+4+nl2n+2l+2n+1l2n+4+nl2n+2l+2n+112n+4+nl2n+2l+2lnl1+ 2n+2l+22n+421+ nl+1+1n21++1nnl+1llnlh(I)nl2n+5+nl2n+2l+3n+1l2n+5+nl2n+2l+3n+112n+5+nl2n+2l+3lnl1+ 2n+2l+32n+521+ nl+2 +n+212n+521+ nl+2+n+212n+2l+3ln + 2+nnl+1n+l2nn+2+nnl+2nlTable 8: Optimal plans abstract tasks overall heuristic estimatesSatellite task used proof upper bound 1/6SwOf f (1), . . . SwOn(l 1, s), urn(s, dI , dl1 ), Cal(l 1, s), urn(s, dl1 , dI ), akeIm(ol1 , dI , s, l 1),SwOf f (l 1), SwOn(l, s), urn(s, dI , dl ), Cal(l, s), urn(s, dl , dI ), akeIm(ol , dI , s, l), urn(s, dI , dl+1 ),akeIm(ol+1 , dl+1 , s, l), . . . , urn(s, dn1 , dn ), akeIm(on , dn , s, l)i,108cost 4l + 2n 1.fiImplicit Abstraction Heuristicsl = n n, provides us asymptotic performance ratio 1/6 threeheuristics.10. Summaryconsidered heuristic search cost-optimal planning introduced domain-independentframework devising admissible heuristics using additive implicit abstractions.implicit abstraction corresponds abstracting planning task hand instancetractable fragment optimal planning. key motivation investigation escape restriction explicit abstractions, pattern-database merge-and-shrinkabstractions, abstract spaces fixed size. presented concrete scheme additiveimplicit abstractions decomposing planning task along causal graph suggestedconcrete realization idea, called fork-decomposition, based two novel fragments tractable cost-optimal planning. studied induced admissible heuristicsformally empirically, showed favorably compete informativenessstate-of-the-art admissible heuristics theory practice. empiricalevaluation stressed tradeoff accuracy heuristics runtime complexity computing them. alleviate problem expensive per-search-node runtimecomplexity fork-decomposition heuristics, showed equivalent explicitabstractions notion database exists also fork-decomposition abstractions,despite exponential-size abstract spaces. subsequent empirical evaluationheuristic search databases fork-decomposition heuristics showedfavorably competes state art cost-optimal planning.basic principles implicit abstraction framework motivate researchnumerous directions, importantly (i) discovering new islands tractabilityoptimal planning, (ii) abstracting general planning tasks islands. Likewise, promise combining implicit abstractions techniques deriving admissible heuristic estimates. first step towards combining implicit abstractionspolynomial-time discoverable landmarks planning tasks recently takenDomshlak, Katz, Lefler (2010). believe various combinations techniques might well improve informativeness heuristics, without substantially increasing runtime complexity.Acknowledgmentswork authors partly supported Israel Science Foundation grants 670/071101/07.109fiKatz & DomshlakAppendix A. Detailed Results Empirical EvaluationhFtaskhIh nodes time nodeshFItime nodestimeMS-104MS-105nodesnodestimeHSPFtimenodes90.00100.00180.03210.01220.01420.17420.1796231549.1389525 466.14190.01220.01400.21380.218968 238.168931 267.813053401077.90910292122424220312956192240386259timeblindnodes timehmaxnodes timeairport-ipc4010203040506070809101112131415161719212236891720214141627118213937605879889010114810910 0.0112 0.0386 0.2522 0.0223 1.2951336.7251437.009 0.0015 0.01133 0.0721 0.0230 0.06639 1.54632 1.5321544166.519 0.0015 0.0393 0.3121 0.0227 1.43567 45.25550 44.1519 0.0223 1.9047554.1843447.4819 0.0230 0.08728 2.76663 2.6025110334.7223317307.6019 0.0327 2.13568 71.23479 59.829 0.0010 0.0018 0.0421 0.0222 0.0142 0.1642 0.1724372 25.42152408 64.9219 0.0222 0.0240 0.2138 0.2030637 51.2328798 46.201031524200.957326372.921119943762.0234365853.7010210.280.7211 0.009 0.001.2313 0.0010 0.005.10164 0.0057 0.001.3223 0.0021 0.0046.5427 0.0022 0.00123.13738 0.01418 0.02117.56742 0.01405 0.02602.09 27032 0.289687 0.90993.07 175717 2.47 56484 7.622.4521 0.0019 0.0065.3627 0.0022 0.01169.02873 0.01392 0.03134.87822 0.01342 0.03714.76 35384 0.399196 1.11647.05 33798 0.388200 1.01124746719.72 221993 49.031043661310.89831632253.2118809 0.423184 1.12159967105.2963061 1.44blocks-ipc204-004-104-205-005-105-206-006-106-207-007-107-208-008-108-209-009-109-210-010-110-211-011-111-212-012-113-013-114-014-1615 0.0146 0.0117 0.017 0.0370.0370.3693 0.0025 0.001014 0.0131 0.0015 0.0011 0.04110.03110.3966 0.0023 0.0067 0.0126 0.0010 0.007 0.0470.0370.3863 0.0018 0.001232 0.03302 0.06113 0.0813 0.30130.96131.32467 0.00145 0.001037 0.03280 0.0698 0.0711 0.29110.96111.36567 0.00135 0.0016152 0.09596 0.10348 0.1817 0.29170.95171.49792 0.00297 0.001233 0.04766 0.27207 0.2513 0.95138.56134.101826 0.00276 0.001041 0.07 2395 0.74578 0.7811 0.90118.34114.174887 0.01755 0.0120855 0.80 5444 1.23 3352 2.88733 0.87858.84314.296385 0.022556 0.0320278 0.56 20183 8.26 4022 8.18577 1.93144 23.3222 11.47 37157 0.145943 0.1122 691011.22 59207 17.37 38539 49.7110071 1.701835 21.05174 11.25 63376 0.21 33194 0.4620 1458 2.85 46009 15.05 18854 29.611855 1.59782 20.3790 10.99 55218 0.19 18293 0.2918 1533 4.79344157179.42 69830208.075557 3.67678 36.8025 26.00 519107 2.28 94671 2.0720 1004027.97517514236.64191352475.3345711 3.8811827 33.49151 26.57 636498 2.60 199901 3.8516479 1.79237140136.18 32567110.76277 3.6354 32.5317 25.85 433144 1.93 52717 1.30301233374 16.00 971409 77.74464 56.76798464936.763840589 85.0028 343518.1795068 7.3558873 63.1582 56.98591457229.731200345 32.0626 637935.22161719 13.5420050 82.4581 57.02596316030.021211463 32.15341800 114.263212063665 228.761835 115.19343685 116.75327046739 141.442678 213.32301510 203.79343984 213.97341184 370.0634614 382.344283996 860.45441634381104.273827791063.023671541087.40depots-ipc30102030407101310152730212425114 0.24113410.82279 0.119344 12.40161 0.322638 22.6811 0.00110.00450.77329 0.00136 0.00738 3.24161.14898 11.56 15404 0.113771 0.17348288 20.69 239313 222.35 103089 247.13293039827.201204646 97.621284048 52.05 1273762 529.34211820 37.5441328 324.19650110071.581331701166.763241083157.521427824116.06grid-ipc10102142657160.2811179.49472 55.87660 8.63467 121.103392724 50.35 3244132 241.946446 0.08190 0.10664016231.26Table 9: Runtimes cost-optimal heuristic-search planners Airport,Blocksworld, Depots, Grid domains. description planners given Section 6; fork-decomposition heuristics computedfully online. Column task denotes problem instance, column h denotes optimalsolution length. columns capture run time number expandednodes.110fiImplicit Abstraction HeuristicshFtaskhnodeshIhFItimenodestime nodestime0.0518.270.2519.1545.025.219.563718452190107781140079517300.013710.29 157940.1316317.14 766518.91 109843.604927.71 10060.0423.800.3129.8846.166.0513.80HSPFMS-104MS-105nodestimenodestimenodes8 0.0420 0.1313 0.1617 0.492614 0.60291 1.3514 1.42287823 7.3415504 1.7018 1.6434137 1.991298884 19.52820131719121429522318107908708750.030.260.252.414.589.7215.3520.3110.4318.5417.0135.3344159988632293324877380425801blindtimenodestimehmaxnodestimedriverlog-ipc30102030405060708091011137191216181113222217192649157131646161136406088644304 199.81433951421.90198651 849.0416099 85.74 4037 200.5241445 186.53 390691395.510.47182 0.00204.5568927 0.36542831.2516031 0.09249812.20 999991 8.12 39367318.77 6290803 61.57 172461110.08 681757 7.645445141.34 6349767 81.53 49348018234 68.225596231193.000.000.520.036.5634.731.7117.316141130 330.22freecell-ipc3010203040582341.5414 30960 107.0718 197647 877.1626309744.882743.2575150 230.54 37131 224.6287 3.1231487 40.4095805140.96943074 86.785950977243.749 38.749 13.013437 0.0310430.15466 70.29 130883 1.4641864 10.771589 169.39 944843 11.45 210503 75.6215848 341.02 3021326 38.80 600525 247.7040642 916.4414080351062.25gripper-ipc101020304050607112140.042400.022140.0512 0.0012 0.00330.11236 0.002080.001717680.5418320.36 18030.7518 0.1118 0.086800.371826 0.0117600.0123 116265.38 117364.05 116898.1111514 0.472094 1.7573701.5211736 0.04116160.0829 68380 43.58 68558 35.24 68479 70.7268380 1.2468190 8.0555568 10.2968558 0.27683680.5635 376510 328.10 376784 296.59376653 560.93376510 3.52 376510 19.46 344386 79.96 376772 1.59 3764963.51411982032 13.42 1982032 42.16 1911592 577.49 1982394 9.59 1982016 21.574710091986 61.6610091986106.8410092464 51.1010091968 119.64logistics-ipc1010531323326221320273293 945.354369.673922.57198127042.532.24128496221.845.53210.021930.0665200.035700.13293160.021170.0379280.0525500.98 1171180.036750.1942790.02240.0113260.0642491.85 2461150.031810.0999260.0527521.22 1394250.0423950.94 1428370.42 251287 203.64 980531689 10.08320.42 82476 78.73 35805450.6611836081306.92370.54 351538 407.06167038310.50 59336 80.88 25359462.26432.10697 26.7821959 696.23432.780.060.160.051.090.310.022.540.131.511.34386.801918881 41.03768161 18.69494 0.4221 0.16949586 34.82609393 35.2714 2.1121 0.72529338 32.552119551700.266.587.081556452453251.662.0732282811560.571.0021 0.0520 0.0416 0.0528 0.3818 0.389 0.3826 1.2315 1.2626 1.2625 1.2237 4.8749 4.9432 6.9045 7.2137 9.4631 9.43668834 29.731457130 43.00701106 37.42210.34200.37160.36280.58180.7290.78261.03151.16261.03251.0224317 35.46362179 453.0614890 33.50114155 198.8432017 83.166720 26.481124692494955109525223071031490207248814766614225570.050.040.020.640.130.003.400.163.322.9548844185120574694619928020222936042000121335210.030.030.010.590.050.001.920.031.981.2936360.074819598logistics-ipc204-004-104-205-005-105-206-006-106-206-907-007-108-008-109-009-110-010-111-011-112-012-12019152717825142524364431443630454248604268161.33883.68168.73212016281892615262552566632410421670820950310.030.030.040.100.100.090.180.180.190.180.658.830.961.151.561.27775996 43.562222340 87.47mprime-ipc101020304050708091112151617192125262728293132343557481156876664664657447451960.1911604 422.83427 35.0938366.62331414.91100.03440451620.6870.5017751.17470.1519838 454.91 1001881798.6990.162190.5416320 192.108118 46.69252 171.97240.072565 242.83113.1510933.443463.075227 284.1380.165243 95.01448 447.496 2.003317 88.5836 33.649 6.091705009127.531667 46.721469752403.4521993 36.258 4.6934763 11.456 20.455463.859 82.7110849.5919076 781.749868 0.67599590 23.58187448 62.6842055143.2722 394.2625665 724.12473 81.420.562197646 71.6973260 2.21108652 3.50425144 32.17172736 42.48453 671.03123039313.25750.1030542.2880.031824.53248 52.8631759 133.33234 11.653923.091772403564612436462900.04290.0833.8290.23371.11327.831934.94 118392.13232.54841.310.081.7911.7995.523.081.895 0.48172432 46.336 11.598 1.885 14.92419 99.8719429 21.61450151.69359 3.635 2.75189154454.696154.438 22.555201.407269292.376 43.431503293103.23383 0.00819590 61.0184079 3.50128 146.8017333 0.253187 0.173584 0.19110731701.00 115479 2.753618 0.19706 96.552476 0.05858.71680.0412606 36.6550.072000.2414881571638.78110.047650 84.3319023 30.269150.5415201.781039 178.557962 35.6551.0636013 533.7515250 101.7560.004402.698312.082110.0670.10110.1730961.74110.18440.03Table 10: Similar Table 9 Driverlog, Freecell, Gripper, Logistics-ipc1,Logistics-ipc2, Mprime domains.111fiKatz & DomshlakhFtaskhnodeshItimenodeshFItime nodestimeMS-104MS-105nodesnodestimetimeHSPFnodesblindtimenodestimehmaxnodes timemiconic-strips-ipc201-001-101-201-301-402-002-102-202-302-403-003-103-203-303-404-004-104-204-304-405-005-105-205-305-406-006-106-206-306-407-007-107-207-307-408-008-108-208-308-409-009-109-209-309-410-010-110-210-310-411-011-111-211-311-443444777771011101010141315151517171517181919202021232422222527272628273130303228333232343337343838355 0.0050.005 0.005 0.0050.005 0.005 0.0050.005 0.005 0.0050.005 0.005 0.0050.005 0.0019 0.00220.0019 0.0021 0.00230.0021 0.0021 0.00230.0021 0.0024 0.01240.0024 0.0019 0.00220.0019 0.0086 0.011290.0198 0.01120 0.011680.01147 0.01137 0.011430.01137 0.0196 0.011530.01117 0.01103 0.011490.01115 0.01524 0.068430.08686 0.12505 0.068170.08663 0.12685 0.089420.09802 0.13681 0.079420.09798 0.13685 0.079420.09802 0.132468 0.3740090.66 3307 0.932807 0.4243450.71 3677 1.011596 0.2929810.55 2275 0.732256 0.3637990.62 3104 0.873210 0.4647320.78 4267 1.119379 1.98 176654.74 13531 5.909106 1.93 181344.75 14052 5.9410900 2.19 190844.90 15111 6.2812127 2.43 217085.69 17807 7.1913784 2.62 232555.93 19536 7.6653662 13.29 96092 37.56 79449 46.7656328 13.86 99109 38.56 83677 47.4948141 12.52 96139 38.02 78471 46.1746867 12.11 93117 36.63 75424 44.4384250 18.24 126595 46.11111984 61.34272580 81.51 485051 267.27408114317.78284415 86.93 527216 288.07446837347.43207931 66.37 414294 235.89330993271.03369479104.29 598031 320.33527216392.87297516 87.65 507910 278.64431432333.911461729497.721207894438.6923351661787.131294691460.1123404111791.161840936589.091252484467.945 0.005 0.004 0.004 0.005 0.005 0.005 0.005 0.005 0.005 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.0011 0.0011 0.0012 0.0012 0.0011 0.0011 0.0011 0.0011 0.0011 0.0011 0.0015 0.0115 0.0114 0.0114 0.0116 0.0116 0.0116 0.0116 0.0116 0.0116 0.0118 0.0618 0.0518 0.0618 0.0516 0.0616 0.0518 0.0618 0.0519 0.0619 0.0520 0.1820 0.3220 0.1820 0.3221 0.1821 0.3221 0.1721 0.3222 0.1722 0.3224 0.3224 1.757001 0.3825 1.751646 0.3323 1.711861 0.3323 1.7423159 0.5226 1.7141629 0.9128 4.1842679 0.9028 4.2537744 0.8627 4.25140453 1.9429 4.2162933 1.1628 4.12684737 9.07 126918 8.89406041 5.61 100937 8.73442547 6.06 82946 8.63765455 10.00 277302 11.14317692 4.6529 7.032436164 35.24 863244 23.762340169 34.09 335745 15.681735477 25.29 486286 17.723952148 55.86 940556 24.242715866 39.44 625559 19.9111473359183.604724980 93.567535468124.801934943 47.9114645785233.686330198120.715809711110.105853546 95.561082086 32.2250.0140.0050.0150.0050.01260.01260.01270.00200.01230.011000.031400.021220.021310.021140.026690.106340.118220.128200.128210.1228290.4432600.4915940.3225680.4239530.5593121.76102521.96112472.11142162.56168803.0456686 14.3163035 16.3355751 13.9853121 13.2796327 24.76290649 104.18339177 123.10204614 73.39435617 160.49315339 111.841555286 794.931344815 683.051357681 692.1120831681051.951231554 605.015 0.005 0.005 0.004 0.005 0.005 0.005 0.005 0.005 0.005 0.0030 0.0020 0.0030 0.0022 0.0030 0.0022 0.0026 0.0017 0.0031 0.0020 0.00193 0.00105 0.00218 0.00150 0.00164 0.0092 0.00197 0.00130 0.00190 0.00114 0.001182 0.00866 0.001176 0.00860 0.001277 0.00969 0.001319 0.00970 0.001334 0.00969 0.006350 0.034387 0.036602 0.034664 0.035565 0.033524 0.035944 0.034140 0.036949 0.045268 0.0430786 0.2021194 0.2030093 0.2021255 0.2032390 0.2121694 0.2132574 0.2124552 0.2333793 0.2226167 0.24155466 1.22 116685 1.32164470 1.29 118494 1.33161342 1.27 119688 1.36155176 1.23 114649 1.30168219 1.33 140128 1.58755255 7.16 594032 7.95794365 7.56 636587 8.66731622 6.92 534711 7.37833421 7.97 690267 9.29771608 7.33 613253 8.433685552 41.04 3006991 49.123649801 40.32 2893803 47.543576134 39.61 2895182 47.263796035 42.13 3304570 53.293589382 39.29 2956995 48.8415804498200.9013267920250.5816472633208.3913720664256.8915867374201.0112497087236.8916309701208.4213801989262.5316472551209.1313925654262.57mystery-ipc10102030407091112151617181920242526272829305748764674657497 0.012404 64.9473 1.920 0.010 0.003049 47.689 0.020 0.14354200.980 0.000 0.139 0.021807 50.4014 0.278 0.0131 0.2660.008012 234.1070.1200.0010764 137.61330.032093419 938.0585 26.3100.004968 183.2410183515947140.0125.341.610.020.106 0.01722 47.5011 0.590 0.000 0.001215 40.758 0.020 0.1983 90.170 0.000 0.309 0.021344 60.206 0.2215 0.0210 0.176 0.201672 82.705 16.4661.79105.385193.7565 811.870 0.000 0.003165 29.348 1.518 16.592102777 14.612102729 27.8400.003868 670.0834 41.20198445.850 0.000 0.0012478 96.38285069 59.22 547246578.395 0.102526 5.946 4.808 0.635 8.9442112 28.075 0.10346 70.786 80.488 6.775107.1044893357.0700.00141.223107 291.367 243.7831 16.6727 536.3030 0.00770852 21.85507 0.020.004.470.030 0.000 0.00138289 2.181458 1.44426 0.0019 0.002102777 15.09 1177842 21.87279973 13.21135 2.625400 0.410 0.00133871 3.65686125 23.2831 0.008455 0.102174 0.03843 0.00153 0.011977063 38.26Table 11: Similar Table 9 Miconic Mystery domains.1128236855015167180.350.005.443.766 0.0037 0.0573 0.0432 0.007 0.0226686 28.27fiImplicit Abstraction HeuristicshFtaskhhIhFIMS-104MS-105timenodesnodes22640.4938951.1930701.3626170.5644851.3235611.5722640.4938951.1530701.3622640.4938951.1530701.3622640.4838951.1530701.35366768 255.00 7797101599.86 5874821498.20410728 277.99 7606681546.44 6067821515.462424242424621008594758nodestimenodestimenodestimetimeHSPFnodesblindhmaxnodestimetimenodestime0.0620001.020.0623781.070.0620001.020.0620001.020.0520001.027.86 379735 217.377.34 405564 226.32482255014822482248228828748366470.010.020.010.020.014.914.62401645944016401640168225147871630.030.040.030.030.0318.7117.8116242984871894561430.000.021.068.223634843461040680.000.010.162.61openstacks-ipc501020304050607232323232345460.05240.06240.06240.06240.06244.85 2796144.69 264535pathways-ipc501020304612181716242755449281269500.030.082.5911.451299230720416337880.020.061.062.971299243729106587380.030.092.147.0771946216711.142.566.437 0.7913 42.1114901129.2398484288.39140599014772342060.280.296.9927.00pipesworld-notankage-ipc4010203040506070809101112131415171921232441512811810810131820241630262224141824121210.1514132.0517425.267007 24.714093 27.4512401 105.374370 71.7518851 406.671090.0515420.8630013.318911 12.436805 19.7427377 103.759168 68.1056189 483.281210.1814132.4217426.437007 30.794093 35.4012401 140.534370 105.5320584 600.944729501577.22117475 899.72238331663.4649035 495.536 0.046 0.0462.79121 0.00130.00169 0.3013 0.174353.071808 0.017920.029 1.159 0.691283.843293 0.022620.02651 1.9512 7.058128.8416088 0.1129250.1377 5.639 21.15155 16.5311128 0.1211210.151299 5.2661 39.311151 23.4149905 0.4871020.72233 19.789 59.70185 29.8846502 0.5726310.48561 12.42497 94.691673 48.84 273585 3.39228743.58104875 25.4810478 74.26 5513309 80.62 321861 68.992982520 66.896898321439.64111212451579.7790598 9.20 52159 43.24 108503 625.52 710123 3.86 107061 14.51594661 12.41 416184109.43 4332961117.57 2467804 13.83 464982 56.8212835 34.28242241019.65 481045 3.14334176.3813255718119.54648132 65.434921698 34.90 555619 105.493200672 90.078767431150.883992 18.13948159.63157782 1.3189662.42296506 49.11 104750256.13481859 229.007315150142.82114257 250.18pipesworld-tankage-ipc40102030405060708111315172131512811810811221630441439770.131260.071050.209601.2010050.609601.5520803 155.53 52139 158.91 20803 207.571102841004.10 157722 668.67 1102841408.506531 73.63 13148 79.046531 112.6120171 329.40 43583 310.24 20171 460.456 3.54110 3.04244 22.643892 16.68376 15.461794328.186 0.1313 0.209 36.8912155.039120.0611201.4463.88128 0.001796.041012 0.01818 24.4752983 0.778116 64.68 221429 3.06313 59.9912764 0.213102 97.3158487 0.872695 339.76 5404036198.08130.016590.0218021.3341540 14.4928341.61157466.61104531 420.474116344 30.67752867 334.424423951 65.441726598 13.56126845 222.23919764 381.6696043191.77660104 28.60 660102162.93188517122.112546587141.1212850247352.4613241 69.801357801124.64tpp-ipc501020304050658111419256912156230.000.000.000.010.52611277851100.000.000.000.011.3669164714550.000.000.000.011.216 0.009 0.0012 0.0015 0.0120 0.36947059 14.226 0.009 0.0012 0.0015 0.0020 0.7774798 23.976912156240.010.010.030.070.48726116494246980.000.000.000.000.1260.00160.00830.004300.00173980.159267024 216.69trucks-ipc50102030405060708091316910.4110270.2210390.4014 0.0314 0.022850.565774 0.024020.011796242.6828980.5729571.354192 0.2218 0.1714131.0428348 0.149390.032080693 71.37 20752 19.93 22236 31.25199405 2.89 173790 6.8840494.43 379582 2.9794650.4023 17538661237.601205793 850.3413156721394.88 2591561 29.172568634 56.9688177.75 2990366 26.65 2091409.432523444940392.9914744 23.121248571 90.7830308920 343.4723 21347281313.60 719751 408.75 755608 820.55 7575415 88.918080496117.13 43270 27.6212410588117.92 223011 19.342549663 47.613106944 403.3628233577 248.21Table 12: Similar Table 9 Openstacks, Pathways, Pipesworld-NoTankage,Pipesworld-Tankage, TPP, Trucks domains.113fiKatz & DomshlakhFtaskhnodeshItimenodeshFItimenodestimeMS-104MS-105nodes timenodestimeHSPFnodesblindtimehmaxnodes timenodestime0.0090.01110.00200.08710.00200.04330.00120.343320.00230.111540.0090.01110.00260.091220.0090.121280.0090.06490.04181.0413580.00960.191530.00400.171530.00590.16950.00130.06272.58356 18.9935620.1222871.3427420.00130.03160.00290.211580.7763384.4690090.00520.18840.00210.12420.87223158.16 1895160.01300.432000.00210.124237.9328 780.3889130.00520.281820.011790.857730.00490.29951.4333377.12 2444990.023931.3522956.557530 32.97 539110.003520.744350.639472.2922910.001580.502276.3674488.27 16517014.07 188564 111.9916697880.012772.1015320.01330.745620.071461.78410312.8623371 87.9110369920.00210.16540.1817731.2919080.002560.503330.054072.1841420.001210.744344.05198656.91 807850.045152.32507511.08 200559 101.2123.32 27728751408.640.023901.406900.000.000.000.000.000.000.000.000.000.000.000.000.000.000.020.010.000.000.040.000.000.670.000.000.120.000.000.001.270.010.250.000.010.000.639.440.000.000.016.740.000.010.000.010.000.250.019 0.0047 0.0028 0.00102 0.0069 0.009 0.0062 0.0052 0.0020 0.00376 0.01142 0.00113 0.0086 0.0018 0.00324 0.021876 0.0114 0.0091 0.006925 0.0875 0.0031 0.00177138 1.43116 0.0031 0.00854 0.18142 0.00616 0.0079 0.00192459 2.321834 0.0116766 0.36424 0.001073 0.01216 0.0061548 1.06717884 18.271342 0.01357 0.002597 0.02229210 9.5135 0.001636 0.01315 0.003235 0.02358 0.0065984 0.634406 0.0219020089286.020.00642psr-small-ipc40102030405060708091011121314151617181920212223242526272829303132333435363738394041424344454647484950811111011811887191615910259122517103312109172114212219242121222223132320103020192034273747231052316675106124181311491209019120023281585802580281632997728485144616791427721791112784311480223659655717661307301248631185532829903476088841046370.00100.00100.000.01550.00520.010.01310.00310.000.04910.03730.060.01790.01750.020.00100.00100.000.01610.00610.010.01290.00250.010.01190.00180.000.201830.181550.320.031490.021490.040.031230.021200.040.02900.01900.020.00190.00190.006.557086.257699.910.6521580.3421760.850.00150.00150.000.03900.01850.034.3178562.1978765.800.02800.01800.020.01280.00280.01405.65 176058 245.42 168685 617.450.04930.03770.060.01280.00280.0184.24463 145.38482 213.420.051500.031460.060.336750.216500.490.02790.01790.02436.34 187319 307.77 159325 709.891.2519820.8018831.9025.936810 38.668297 53.430.174310.104310.250.8414360.3013911.000.072230.042230.09160.36 63186 39.55 68281 199.30392.49 371834 786.06 4584021094.611.2914170.9513632.100.203720.153260.322.4929421.6426823.911826081384.900.01340.00310.010.5017470.1717390.590.093280.053280.123.2534302.3031215.240.163760.113590.2551.77 61842 21.14 61563 68.335.2745223.9342848.700.396590.266459 0.00912 0.001212 0.001211 0.001112 0.00129 0.00912 0.00129 0.0099 0.0098 0.04820 0.002017 0.001716 0.001610 0.001011 0.4611975 0.112610 0.001013 0.00132910 0.272618 0.001811 0.001134 0.283413 0.001311 0.001110 5.421018 0.001822 0.012215 0.001522 0.392223 0.01232647 0.8972325 0.0025446 0.262222 0.002224021 0.83 1111348350 2.98278324 0.022414 0.011424 0.082438837 1.88776711 0.00111117 0.183121 0.002120 0.052021 0.012136941 0.67 3258228 0.0428129627 2.372500204836815.84 5943990.6024 0.02240.00rovers-ipc5010203040507121081182218191470.011470.011470.0211 0.0311 0.03480.071104 0.00283 0.00440.01440.01440.019 0.009 0.00160.03254 0.00129 0.006720.114190.054480.1012 0.1112 0.128040.163543 0.02757 0.00470.02200.00240.019 0.049 0.04580.08897 0.00223 0.00808084 237.13 410712 123.64 522937 231.28 61726711.48 375808 18.46 298400 101.658559690126.19 4318309 81.53741649 517.1816822451780.27 328088451.022212903 59.20 1459792 866.939618062199.915187273166.77satellite-ipc40102030405069240.00320.0013860.023370.101122491.246560.53179817 10.65 14860 24.9015 2795691251.83 46453 515.8020 1496577 968.2415723271721.87290.002410.137280.8211250 26.1861692 877.2610 0.0010 0.0014 0.0114 0.0112 0.5612 0.644152 0.9918 4.4381972 7.26 148667 69.28276922974.73 307962 32.52460.06896460.21172819450.93 15185158909.50 345663267513 565.182 0.002 0.007 0.007 0.007 0.217 0.909 0.209 0.8912 0.2512 1.9012 0.3812 3.5416 0.3816 3.4814354 2.0012 14.48251703551.18 611457 30.47132287134.84 137872 25.4431003011.28 110726 26.6520.45290.4658403.4251602153.4452564227.70 822891957 11.81 59653134890 30.36 40562683533 292.050.000.010.174.705994068221808150.000.000.113.3710751017371.43zenotravel-ipc3010203040506070809101116681111151121221421728991772287508832680.010.020.080.150.325.519.6343.9621818882201144423410260.000.020.120.260.222.005.568.92769041090.672171281136504419916550.010.020.110.300.362.4010.5830.060.000.000.040.030.635.903.562 0.0022 0.00492 0.02665 0.0112466 0.3385931 2.47115348 2.60687846 50.76Table 13: Similar Table 9 PSR, Rovers, Satellite, Zenotravel domains.114fiImplicit Abstraction HeuristicshFtaskh nodeshItimenodeshFItimenodesMS-104time nodesMS-105timenodesHSPFtime nodesblindhmaxtime nodes time nodestimeschedule-strips02-002-102-202-302-402-502-602-702-802-903-003-103-203-303-403-503-603-703-803-904-004-104-204-304-404-504-604-704-804-905-005-105-305-405-505-605-705-805-906-206-407-007-9350.1550.1450.22230.1640.1130.18230.3230.1730.403260.50370.76260.613681.34 1882.24 2207.20230.3330.1430.38230.1450.1230.17230.3030.1330.34230.3230.1430.38350.1550.1450.224402.72 407 12.16 140 14.55230.5130.3530.724271.16501.83332.334150.79912.39150.96341.11162.0841.524736.13 471 16.71748.324721.27751.80691.334281.05501.83281.434273 11.53 266 11.46 273 17.48480.96311.77142.135373 13.91 1498 74.46 167 24.606 175591373.8010707 626.5452099.88 406 20.85665.305142 10.47 674 33.29 251 29.285921 64.48 450 46.95 574 116.656483 47.25 4544 268.77 850 187.466779 27.0911610 361.74 1834 102.68599 18.48 424 38.04 163 40.045102 16.01 573 31.87 111 23.354 1043 80.06 996 76.64 1050 143.485163 41.61 483 63.23 167 62.536 2701 213.921257 286.287136221693.686989 100.02 3433 229.05 582 100.056198 21.67 9550 767.94 347 68.647 6033 743.61103251508.566944 131.19175621446.20 2107 379.707 1190 172.592709 730.546 1537 140.49158291248.19 2717 547.566888 243.141709 730.368 115351776.877 2489 786.768 68291559.864 511.103 104.983 231.994 56.5133334363.11121.84323.77316.53251.465 191.035 259.135 682.305 121.585 195.725 235.4871115.766 267.2977665837.68459.19936.68711.65316.2241743.325334433335577.39754.26495.56658.90484.62667.32697.42604.06668.79577.1676 0.0250.096 0.0230.075 0.0230.07529 0.03950.45543 0.031080.443 0.0330.076 0.0230.0613 0.0230.078 0.0230.0776 0.0350.0911915 0.60 11278.9831 0.04250.373617 0.23 12289.563379 0.231701.8541223.90301 0.06220.2712217 0.64 1175 12.432663 0.19 1542 11.7312859 0.68 1323 13.4712616 0.65 1590 11.134339 0.279137.6931219326.88 22993 273.3855206949.7947696 4.97 9703 131.6989272 8.74 12941 163.8462013 6.03 13614 168.071079781399.991071151001.4061327 5.97 8683 103.5034046729.56 15122 181.9841673 4.27 5480 83.6914335022.71 43336 751.35120602 989.42Table 14: Similar Table 9 (non-IPC) Schedule-STRIPS domain.115fiKatz & DomshlakhFtaskhnodeshItimenodeshFItimenodestimeMS-104MS-105nodesnodestimeHSPFtimenodes90.00100.00180.03210.01220.01420.17420.1796231549.1389525 466.14190.01220.01400.21380.218968 238.168931 267.813053401077.90910292122424220312956192240386259timeblindnodes timehmaxnodes timeairport-ipc4010203040506070809101112131415161719212236378100.019 0.0090.009 0.009120.0115 0.00150.0110 0.0017860.02133 0.01930.0218 0.0420220.0121 0.00210.0121 0.0221230.0830 0.02270.0922 0.01415130.16639 0.065670.1942 0.16415140.15632 0.055500.1942 0.1762127331.89 21544 1.36 143984.0224372 25.427188670 16.58 136717 9.60 90412 38.78 152408 64.9218190.0119 0.01190.0119 0.0221230.1030 0.03270.1222 0.02394750.20728 0.075680.2540 0.21374340.20663 0.074790.2438 0.2060120402.90 25110 1.86 159484.6430637 51.2358114772.74 23317 1.71 145574.2528798 46.2079 267277 77.39 824491 97.12 353592 114.58 1031524200.9588 2460667 708.8226786891235.7990 1354353 592.533400142492.061462739 660.171015156 48.29 11259 3.724773 51.137326372.92148 6066481110.091063668318.90 4778361082.91 1119943762.021099504 129.73 34986 14.419436 140.7534365853.7014237873 820.3310210.280.7211 0.009 0.001.2313 0.0010 0.005.10164 0.0057 0.001.3223 0.0021 0.0046.5427 0.0022 0.00123.13738 0.01418 0.02117.56742 0.01405 0.02602.09 27032 0.289687 0.90993.07 175717 2.47 56484 7.622.4521 0.0019 0.0065.3627 0.0022 0.01169.02873 0.01392 0.03134.87822 0.01342 0.03714.76 35384 0.399196 1.11647.05 33798 0.388200 1.01124746719.72 221993 49.031043661310.89831632253.2118809 0.423184 1.12159967105.2963061 1.44blocks-ipc204-004-104-205-005-105-206-006-106-207-007-107-208-008-108-209-009-109-210-010-110-211-011-111-212-012-113-013-114-014-1615101467123210371615212331041208552027822691020145818153320100401647930 13418528343526637934 152459932 61020634 15160873230343434424438360.0046 0.00170.007 0.0370.030.0031 0.00150.0011 0.04110.030.0026 0.00100.007 0.0470.030.00302 0.011130.0013 0.30130.960.00280 0.00980.0011 0.29110.960.00596 0.003480.0117 0.29170.950.00766 0.012070.0113 0.95138.560.002395 0.035780.0211 0.90118.340.015444 0.0533520.06733 0.87858.840.01 20183 0.2840220.12577 1.93144 23.320.10 59207 0.60 385390.6710071 1.701835 21.050.02 46009 0.52 188540.391855 1.59782 20.370.03 344157 5.46 698302.095557 3.67678 36.800.17 517514 7.22 1913524.9145711 3.8811827 33.490.02 237140 4.08 325671.09277 3.6354 32.533.107405904117.144346535 118.23 1233374 16.00 971409 77.740.094145371 77.54 917197 33.3295068 7.3558873 63.150.174145278 78.21 923365 33.79 161719 13.5420050 82.4536.5215.7912063665 228.7637.717046739 141.4470.3693 0.0025 0.00110.3966 0.0023 0.0070.3863 0.0018 0.00131.32467 0.00145 0.00111.36567 0.00135 0.00171.49792 0.00297 0.00134.101826 0.00276 0.00114.174887 0.01755 0.01314.296385 0.022556 0.0322 11.47 37157 0.145943 0.11174 11.25 63376 0.21 33194 0.4690 10.99 55218 0.19 18293 0.2925 26.00 519107 2.28 94671 2.07151 26.57 636498 2.60 199901 3.8517 25.85 433144 1.93 52717 1.30464 56.76798464936.763840589 85.0082 56.98591457229.731200345 32.0681 57.02596316030.021211463 32.151800 114.261835 115.193685 116.752678 213.321510 203.793984 213.971184 370.06614 382.3483996 860.451634381104.2727791063.0271541087.40depots-ipc301020304071013101140.01279 0.011610.0211 0.00110.00450.77329 0.00136 0.001511340.089344 0.3126380.22738 3.24161.14898 11.56 15404 0.113771 0.1727 1344288.592520703159.84 581726 66.43 348288 20.69 239313 222.35 103089 247.13293039827.201204646 97.6230 1254545 101.185835295 923.87 1284048 52.05 1273762 529.3421 1097659.174271196336.59 487961 76.02 211820 37.5441328 324.19650110071.581331701166.7624 2964635 283.5560814781187.66 3241083157.5225 1003709 152.3081618721559.21 1427824116.06driverlog-ipc30102030405060708091011137490.0037 0.00370.008 0.0419157130.42 18452 0.27 157940.5520 0.13121640.00190 0.001630.0113 0.161661610.42 10778 0.3076650.6217 0.4918136401.01 11400 0.36 109841.072614 0.60116080.09795 0.064920.11291 1.35138640.141730 0.1110060.2114 1.4222 669994 75.741181268 61.32 694996 104.59 287823 7.3422 150255 14.72 198651 11.44 164109 23.0615504 1.701743040.44 16099 1.2140370.6918 1.6419433954.99 41445 2.22 390695.9034137 1.9926 1303099 325.711014865144.641098694 422.20 1298884 19.52820131719121429522318107908708750.03440.47182 0.0020 0.000.26 159984.55 68927 0.36 54283 0.520.258631.25 16031 0.092498 0.032.41 22933 12.20 999991 8.12 393673 6.564.58 24877 18.77629080361.571724611 34.739.723804 10.08 681757 7.64 54451 1.7115.35 25801 41.34634976781.53 493480 17.3120.3110.4318.54 18234 68.2217.01 5596231193.006141130330.2235.33Table 15: Runtimes cost-optimal heuristic-search planners Airport,Blocksworld, Depots, Driverlog domains.descriptionplanners given Section 6; fork-decomposition heuristics viastructural-pattern databases. Column task denotes problem instance, columnh denotes optimal solution length. columns capture run timenumber expanded nodes.116fiImplicit Abstraction HeuristicshFtaskhnodeshItimenodeshFItimenodestimeMS-104MS-105nodesnodestimetimeHSPFnodesblindtimenodestimehmaxnodestimefreecell-ipc301020304058141826302340.109740.15274 0.17309601.95751505.5337131 4.79197647 14.41 533995 78.27 240161 51.24997836 60.67 1921470 232.95 1218329213.026510089 448.2287 3.1231487 40.4095805140.96943074 86.785950977243.749 38.749 13.013437 0.0310430.15466 70.29 130883 1.4641864 10.771589 169.39 944843 11.45 210503 75.6215848 341.02 3021326 38.80 600525 247.7040642 916.4414080351062.25grid-ipc1010214265710.6033302741078.5511170.344720.78660 8.63467121.103392724 50.35 3244132241.9464460.081900.10664016 231.26gripper-ipc101020304050607112140.002400.00214 0.0012 0.0012 0.00330.11236 0.002080.001717680.0218320.011803 0.0318 0.1118 0.086800.371826 0.0117600.0123116260.19117360.0811689 0.2211514 0.472094 1.7573701.5211736 0.04116160.0829683801.46685580.5168479 1.6368380 1.2468190 8.0555568 10.2968558 0.27683680.5635376510 10.07 3767843.20 376653 11.11376510 3.52 376510 19.46 344386 79.96 376772 1.59 3764963.5141 1982032 70.91 1982408 19.08 1982227 77.81 1982032 13.42 1982032 42.16 1911592 577.49 1982394 9.59 1982016 21.5747 10091986 438.4110092464 105.6710092241478.67 10091986 61.6610091986106.8410092464 51.1010091968 119.64logistics-ipc1010531323335262213202730777637.14 146961032930.46 8503124360.0319813920.012704312180 27.19477883 183.0895.4942.430.070.07830292 98.59173477 18.191284 0.09962 0.053617185427.521918881 41.03768161 18.69494 0.4221 0.16949586 34.82609393 35.2714 2.1121 0.72529338 32.552119551700.266.587.081556452453251.662.0732282811560.571.0021 0.0520 0.0416 0.0528 0.3818 0.389 0.3826 1.2315 1.2626 1.2625 1.2237 4.8749 4.9432 6.9045 7.2137 9.4631 9.43668834 29.731457130 43.00701106 37.42210.34200.37160.36280.58180.7290.78261.03151.16261.03251.0224317 35.46362179 453.0614890 33.50114155 198.8432017 83.166720 26.481124692494955109525223071031490207248814766614225570.050.040.020.640.130.003.400.163.322.9548844185120574694619928020222936042000121335210.030.030.010.590.050.001.920.031.981.2936360.074819598logistics-ipc204-0 2004-1 1904-2 1505-0 2705-1 1705-2 806-0 2506-1 1406-2 2506-9 2407-0 3607-1 4408-0 3108-1 4409-0 3609-1 3010-0 4510-1 4211-0 4811-1 6012-0 4212-1 68212016281892615262537168932453731464369721959431065340.001930.005700.001170.0025500.006750.00240.0042490.001810.0027520.0023950.00 2512870.07 35322130.00824760.01 11836080.00 3515380.00593360.010.010.092.220.0211.640.0065 0.000.01293 0.000.0079 0.000.051171 0.030.01427 0.010.0013 0.000.092461 0.070.0099 0.000.061394 0.040.041428 0.047.5298053 4.5999.33 1705009 72.352.6935805 1.7845.72 462244 25.3613.75 167038 9.762.4825359 1.73212016281892615262552566632410421670820950310.030.030.040.100.100.090.180.180.190.180.658.830.961.151.561.27775996 43.562222340 87.47mprime-ipc101020304050708091112151617192125262728293132343557481156876664664657447451960.02100.01116042.7244045 80.684270.2770.0838360.2217750.101745027 195.0833140.25470.03485381 491.53 13767801426.21198382.92 100188 74.8590.022190.03163201.8981180.732520.762746 10.47727401 521.78174221 55.09750.0177622 24.69540.1680.011820.122480.51317591.732340.263920.0751590 135.00453 18.7895361 485.7934022 47.43300.01147854 48.2517721.504030.02560.08460.68124361.46460.162900.0624 0.012565 4.2011 0.161093 0.09604756592.60346 0.085227852436.310.031.13448 2.76451 21.406 2.003317 88.5836 33.649 6.091705009127.531667 46.721469752403.4521993 36.258 4.6934763 11.456 20.455463.859 82.7110849.5919076 781.749868 0.67599590 23.58187448 62.6842055143.270.562197646 71.6922 394.2673260 2.2125665 724.12 108652 3.50473 81.42425144 32.17172736 42.48123039313.25169400392.3029 0.0168239106.359 0.1837 0.0232 0.1119 1.0011839 1.9323 0.2884 0.085 0.48172432 46.336 11.598 1.885 14.92419 99.8719429 21.61450151.69359 3.635 2.75189154454.696154.438 22.555201.407269292.376 43.431503293103.23383 0.00819590 61.0184079 3.50128 146.8017333 0.253187 0.173584 0.19110731701.00 115479 2.753618 0.19706 96.552476 0.05858.71680.0412606 36.6550.072000.2414881571638.78110.047650 84.3319023 30.269150.5415201.781039 178.557962 35.6551.0636013 533.7515250 101.7560.004402.698312.082110.0670.10110.1730961.74110.18440.03Table 16: Similar Table 15 Freecell, Grid, Gripper, Logistics-ipc1,Logistics-ipc2, Mprime domains.117fiKatz & DomshlakhFtaskhnodeshItimenodeshFItimenodestimeMS-104MS-105nodesnodestimetimeHSPFnodesblindtimenodestimehmaxnodes timemiconic-strips-ipc201-001-101-201-301-402-002-102-202-302-403-003-103-203-303-404-004-104-204-304-405-005-105-205-305-406-006-106-206-306-407-007-107-207-307-408-008-108-208-308-409-009-109-209-309-410-010-110-210-310-411-011-111-211-311-445 0.005 0.005 0.005 0.005 0.0035 0.005 0.005 0.004 0.004 0.0045 0.005 0.005 0.005 0.005 0.0045 0.005 0.005 0.005 0.005 0.0045 0.005 0.005 0.005 0.005 0.00719 0.0022 0.0019 0.008 0.008 0.00721 0.0023 0.0021 0.008 0.008 0.00721 0.0023 0.0021 0.008 0.008 0.00724 0.0024 0.0024 0.008 0.008 0.00719 0.0022 0.0019 0.008 0.008 0.001086 0.00129 0.0098 0.0011 0.0011 0.0011120 0.00168 0.00147 0.0012 0.0012 0.0010137 0.00143 0.00137 0.0011 0.0011 0.001096 0.00153 0.00117 0.0011 0.0011 0.0010103 0.00149 0.00115 0.0011 0.0011 0.0014524 0.00843 0.00686 0.0115 0.0115 0.0113505 0.00817 0.00663 0.0114 0.0114 0.0115685 0.00942 0.00802 0.0116 0.0116 0.0115681 0.00942 0.00798 0.0116 0.0116 0.0115685 0.00942 0.00802 0.0116 0.0116 0.01172468 0.034009 0.033307 0.0518 0.0618 0.05172807 0.044345 0.033677 0.0618 0.0618 0.05151596 0.022981 0.022275 0.0416 0.0616 0.05172256 0.033799 0.033104 0.0518 0.0618 0.05183210 0.044732 0.034267 0.0619 0.0619 0.05199379 0.1817665 0.15 13531 0.2620 0.1820 0.32199106 0.1718134 0.15 14052 0.2720 0.1820 0.322010900 0.2019084 0.16 15111 0.2821 0.1821 0.322012127 0.2321708 0.18 17807 0.3321 0.1721 0.322113784 0.2423255 0.19 19536 0.3522 0.1722 0.322353662 1.1996092 0.97 79449 1.7624 0.3224 1.752456328 1.2499109 0.96 83677 1.837001 0.3825 1.752248141 1.1096139 0.94 78471 1.771646 0.3323 1.712246867 1.0893117 0.92 75424 1.691861 0.3323 1.742584250 1.70 126595 1.22 111984 2.3623159 0.5226 1.7127272580 7.05 485051 5.51 408114 10.5341629 0.9128 4.1827284415 7.56 527216 6.01 446837 11.5842679 0.9028 4.2526207931 5.60 414294 4.79 330993 8.9037744 0.8627 4.2528369479 9.25 598031 6.74 527216 13.30140453 1.9429 4.2127297516 7.74 507910 5.79 431432 11.0462933 1.1628 4.1231 1461729 43.82 2491975 32.672138656 63.58684737 9.07 126918 8.8930 1207894 37.47 2335166 30.761952916 59.39406041 5.61 100937 8.7330 1294691 40.03 2340411 30.971972234 59.25442547 6.06 82946 8.6332 1840936 52.68 2889342 38.122571844 74.47765455 10.00 277302 11.1428 1252484 40.34 2352633 31.351944297 59.37317692 4.6529 7.0333 5716041202.3710316603153.808774563300.08 2436164 35.24 863244 23.7632 5601282201.4310789013162.699144153315.23 2340169 34.09 335745 15.6832 4153191155.86 9148616138.697466572265.86 1735477 25.29 486286 17.7234 6108094214.6810960203167.109400386320.13 3952148 55.86 940556 24.2433 5920127211.4011075136170.829448049322.74 2715866 39.44 625559 19.913711473359183.604724980 93.5634 15349953668.777535468124.801934943 47.913814645785233.686330198120.71385809711110.10355853546 95.561082086 32.2250.0140.0050.0150.0050.01260.01260.01270.00200.01230.011000.031400.021220.021310.021140.026690.106340.118220.128200.128210.1228290.4432600.4915940.3225680.4239530.5593121.76102521.96112472.11142162.56168803.0456686 14.3163035 16.3355751 13.9853121 13.2796327 24.76290649 104.18339177 123.10204614 73.39435617 160.49315339 111.841555286 794.931344815 683.051357681 692.1120831681051.951231554 605.015 0.005 0.005 0.004 0.005 0.005 0.005 0.005 0.005 0.005 0.0030 0.0020 0.0030 0.0022 0.0030 0.0022 0.0026 0.0017 0.0031 0.0020 0.00193 0.00105 0.00218 0.00150 0.00164 0.0092 0.00197 0.00130 0.00190 0.00114 0.001182 0.00866 0.001176 0.00860 0.001277 0.00969 0.001319 0.00970 0.001334 0.00969 0.006350 0.034387 0.036602 0.034664 0.035565 0.033524 0.035944 0.034140 0.036949 0.045268 0.0430786 0.2021194 0.2030093 0.2021255 0.2032390 0.2121694 0.2132574 0.2124552 0.2333793 0.2226167 0.24155466 1.22 116685 1.32164470 1.29 118494 1.33161342 1.27 119688 1.36155176 1.23 114649 1.30168219 1.33 140128 1.58755255 7.16 594032 7.95794365 7.56 636587 8.66731622 6.92 534711 7.37833421 7.97 690267 9.29771608 7.33 613253 8.433685552 41.04 3006991 49.123649801 40.32 2893803 47.543576134 39.61 2895182 47.263796035 42.13 3304570 53.293589382 39.29 2956995 48.8415804498200.9013267920250.5816472633208.3913720664256.8915867374201.0112497087236.8916309701208.4213801989262.5316472551209.1313925654262.57mystery-ipc10102030407091112151617181920242526272829305748764674657497 0.006 0.006 0.002404 0.508012 11.19722 1.0173 0.087 0.0411 0.100 0.000 0.000 0.000 0.000 0.003049 0.3710764 5.661215 1.019 0.0133 0.018 0.012102777 33.84 2093419 55.582093419 76.8028271 20.2121572 41.225079 44.420 0.150 0.27354 1.3285 2.7483 3.590 0.000 0.000 0.0021717 4.874968 5.26 16276 29.2889887 46.3284572153.53 53114173.340 0.130 0.309 0.0010 0.009 0.011807 0.271835 0.301344 0.6914 0.05159 0.096 0.078 0.0047 0.0015 0.0031 0.0414 0.0310 0.0623175 5.1676480169.867232 13.306 0.201672 82.705 16.4661.79105.385193.7565 811.870 0.000 0.003165 29.348 1.518 16.592102777 14.612102729 27.8400.003868 670.0834 41.20198445.850 0.000 0.0012478 96.38285069 59.22 547246578.395 0.102526 5.946 4.808 0.635 8.9442112 28.075 0.10346 70.786 80.488 6.775107.1044893357.0700.00141.223107 291.367 243.7831 16.6727 536.3030 0.00770852 21.85507 0.020.004.470.030 0.000 0.00138289 2.181458 1.44426 0.0019 0.002102777 15.09 1177842 21.87279973 13.21135 2.625400 0.410 0.00133871 3.65686125 23.2831 0.008455 0.102174 0.03843 0.00153 0.011977063 38.26Table 17: Similar Table 15 Miconic Mystery domains.1188236855015167180.350.005.443.766 0.0037 0.0573 0.0432 0.007 0.0226686 28.27fiImplicit Abstraction HeuristicshFtask hnodeshItimenodeshFIMS-104MS-105nodestimenodesnodestime0.0330700.0435610.0330700.0330700.03307018.93 58748218.33 6067820.050.050.050.050.0522.2022.5324242424246210085947580.05240.06240.06240.06240.06244.85 2796144.69 2645350.060.060.060.060.057.867.340.000.020.431.317194621671timetimeHSPFnodesblindtimehmaxnodestimenodestime20001.02482223781.07550120001.02482220001.02482220001.024822379735 217.37 882874405564 226.32 8366470.010.020.010.020.014.914.62401645944016401640168225147871630.030.040.030.030.0318.7117.810.000.021.068.223634843461040680.000.010.162.61openstacks-ipc50102030405060723232323234546226426172264226422643667684107280.0238950.0344850.0238950.0238950.0238957.52 7797108.23 760668pathways-ipc501020304612181716242755449281269500.000.020.622.661299230720416337880.000.010.250.591299243729106587381.142.566.437 0.7913 42.1114901129.2398484288.39140599014772342060.2816240.2929846.99 8718927.00 456143pipesworld-notankage-ipc4010203040506070809101112131415171921232441512811810810131820241630262224141824121210.021090.011210.0214130.0615420.0214130.0817420.1430010.0717420.1870070.4589110.2270070.5940930.4968050.2640930.65124011.44 273771.34 124012.0343700.9791680.7743701.34188513.84 561896.21 205846.421092472 160.712419903 151.991092472 219.753139526842343999827.68 472950 29.55 313952 43.9075.721319980 133.58 686186 145.416.02 117475 18.08 40226 12.691594863 254.432588849 192.901594863 353.4054373931588.68238334.02 490357.76 238337.872285790 568.937047138 871.032282678 843.28502308 370.686 0.046 0.04169 0.3013 0.179 1.159 0.69651 1.9512 7.0577 5.639 21.151299 5.2661 39.31233 19.789 59.70561 12.42497 94.69104875 25.482982520 66.8990598 9.20 52159 43.24594661 12.41 416184109.4312835 34.2813255718119.54648132 65.433200672 90.078767431150.883992 18.13948159.63296506 49.11 104750256.137315150142.8262.79121 0.00130.004353.071808 0.017920.021283.843293 0.022620.028128.84 16088 0.1129250.13155 16.53 11128 0.1211210.151151 23.41 49905 0.4871020.72185 29.88 46502 0.5726310.481673 48.84 273585 3.39228743.5810478 74.265513309 80.62 321861 68.996898321439.64111212451579.77108503 625.52 710123 3.86 107061 14.514332961117.572467804 13.83 464982 56.82242241019.65 481045 3.14334176.384921698 34.901577821.315023081092.50555619 105.4989662.42481859 229.00114257 250.18pipesworld-tankage-ipc401020304050607081113151721315770.021260.011050.026 3.546 0.13129600.0510050.029600.06110 3.0413 0.208208031.89 521392.46 208032.82244 22.649 36.8911 1102848.06 1577229.60 110284 14.053892 16.6812155.03865310.86 131481.0365311.32376 15.469120.0610201712.41 435834.32 201714.411794328.1811201.448 202706 73.8326437521379.11 202706 208.811196043191.7722 2345399 296.872629204 662.942365735 838.85660104 28.60 660102162.9316188517122.1130 96520911721.672546587141.124412850247352.4614 839847 250.3913241 69.8039 1501847 240.381568963 661.881504072 850.16 1357801124.6463.88128 0.001796.041012 0.01818 24.47 52983 0.778116 64.68 221429 3.06313 59.99 12764 0.213102 97.31 58487 0.872695 339.765404036198.08130.016590.0218021.3341540 14.4928341.61157466.61104531 420.474116344 30.67752867 334.424423951 65.441726598 13.56126845 222.23919764 381.66rovers-ipc501020304050712101470.001478440.0044116720.014198470.002022 808084 22.61 41071218 4546797 191.34 7416491915295510.001470.000.00440.000.004480.010.00240.009.23 522937 18.2921.011682245 102.7776.4611 0.0311 0.03480.071104 0.002830.009 0.009 0.00160.03254 0.001290.0012 0.1112 0.128040.163543 0.027570.009 0.049 0.04580.08897 0.002230.00617267 11.48 375808 18.46 298400 101.658559690126.19 4318309 81.533280884 51.022212903 59.20 1459792 866.939618062 199.915187273166.770.00290.000.002410.010.017280.040.38 112500.764.92 61692 18.8551.681518261 105.6510 0.0010 0.0014 0.0114 0.0112 0.5612 0.644152 0.9918 4.4381972 7.26 148667 69.282769229 74.73 307962 32.52satellite-ipc4010203040506924138611224917981715 27956920 14965770.00320.003370.086560.57 1486049.47 4645392.221572327460.06896460.21172819450.93 15185158909.50 345663267513 565.180.000.010.174.705994068221808150.000.000.113.3710751017 371.43Table 18: Similar Table 15 Openstacks, Pathways, PipesworldNoTankage, Pipesworld-Tankage, Rovers, Satellite domains.119fiKatz & DomshlakhFtask hnodeshItimenodeshFItimenodestimeMS-104MS-105nodesnodestimetimeHSPFnodesblindtimehmaxnodes timenodestime0.0090.01110.00200.08710.00200.04330.00120.343320.00230.111540.0090.01110.00260.091220.0090.121280.0090.06490.04181.0413580.00960.191530.00400.171530.00590.16950.00130.06272.58356 18.9935620.1222871.3427420.00130.03160.00290.211580.7763384.4690090.00520.18840.00210.12420.87223158.16 1895160.01300.432000.00210.124237.9328 780.3889130.00520.281820.011790.857730.00490.29951.4333377.12 2444990.023931.3522956.557530 32.97539110.003520.744350.639472.2922910.001580.502276.3674488.27 16517014.07 188564 111.99 16697880.012772.1015320.01330.745620.071461.78410312.8623371 87.91 10369920.00210.16540.1817731.2919080.002560.503330.054072.1841420.001210.744344.05198656.91807850.045152.32507511.08 200559 101.2123.32 27728751408.640.023901.406900.000.000.000.000.000.000.000.000.000.000.000.000.000.000.020.010.000.000.040.000.000.670.000.000.120.000.000.001.270.010.250.000.010.000.639.440.000.000.016.740.000.010.000.010.000.250.019 0.0047 0.0028 0.00102 0.0069 0.009 0.0062 0.0052 0.0020 0.00376 0.01142 0.00113 0.0086 0.0018 0.00324 0.021876 0.0114 0.0091 0.006925 0.0875 0.0031 0.00177138 1.43116 0.0031 0.00854 0.18142 0.00616 0.0079 0.00192459 2.321834 0.0116766 0.36424 0.001073 0.01216 0.0061548 1.06717884 18.271342 0.01357 0.002597 0.02229210 9.5135 0.001636 0.01315 0.003235 0.02358 0.0065984 0.634406 0.0219020089286.020.00642psr-small-ipc40102030405060708091011121314151617181920212223242526272829303132333435363738394041424344454647484950810 0.0010 0.0010 0.001152 0.0055 0.0052 0.001131 0.0031 0.0031 0.001066 0.0091 0.0073 0.001175 0.0079 0.0075 0.00810 0.0010 0.0010 0.001161 0.0061 0.0061 0.00824 0.0029 0.0025 0.00818 0.0019 0.0018 0.007131 0.01183 0.00155 0.0119149 0.00149 0.00149 0.0016120 0.00123 0.00120 0.001590 0.0090 0.0090 0.00919 0.0019 0.0019 0.00101200 0.08708 0.03769 0.09252328 0.022158 0.012176 0.03915 0.0015 0.0015 0.001285 0.0090 0.0085 0.00258025 0.117856 0.057876 0.121780 0.0080 0.0080 0.001028 0.0028 0.0028 0.0033163299 4.17 176058 1.56 168685 5.011277 0.0093 0.0077 0.001028 0.0028 0.0028 0.009485 3.06463 0.58482 3.2817144 0.00150 0.00146 0.0021616 0.01675 0.00650 0.011479 0.0079 0.0079 0.0021142772 4.55 187319 2.12 159325 5.80221791 0.031982 0.011883 0.041911278 0.256810 0.088297 0.2424431 0.01431 0.00431 0.01211480 0.021436 0.011391 0.0321223 0.00223 0.00223 0.002265965 1.4363186 0.4668281 1.7022571766 12.62 371834 3.41 458402 11.77231307 0.031417 0.011363 0.0313301 0.01372 0.00326 0.01232486 0.052942 0.022682 0.0720259683 8.59 182608 2.70 270195 11.731031 0.0034 0.0031 0.00301855 0.021747 0.011739 0.0220328 0.00328 0.00328 0.00192990 0.073430 0.033121 0.0820347 0.00376 0.00359 0.013460888 0.8661842 0.3161563 0.99274104 0.094522 0.034284 0.1137 12080249604.4317435137247.2013514084784.804723637 0.01659 0.01645 0.029 0.00912 0.001212 0.001211 0.001112 0.00129 0.00912 0.00129 0.0099 0.0098 0.04820 0.002017 0.001716 0.001610 0.001011 0.4611975 0.112610 0.001013 0.00132910 0.272618 0.001811 0.001134 0.283413 0.001311 0.001110 5.421018 0.001822 0.012215 0.001522 0.392223 0.01232647 0.8972325 0.0025446 0.262222 0.002224021 0.83 1111348350 2.98278324 0.022414 0.011424 0.082438837 1.88776711 0.00111117 0.183121 0.002120 0.052021 0.012136941 0.67 3258228 0.0428129627 2.3725002048368 15.84 59439924 0.02240.00tpp-ipc501020304050658111419256 0.006 0.006 0.009 0.0011 0.009 0.0012 0.0027 0.0016 0.0015 0.0078 0.0047 0.00623 0.025110 0.081455 0.055843306179.03 6916518 95.86 6153923222.356 0.009 0.0012 0.0015 0.0120 0.36947059 14.226 0.009 0.0012 0.0015 0.0020 0.7774798 23.976912156240.010.010.030.070.48726116494246980.000.000.000.000.126 0.0016 0.0083 0.00430 0.0017398 0.159267024216.69trucks-ipc5010203040506070809131691 0.031027 0.011039 0.0314 0.0314 0.02179624 0.232898 0.042957 0.114192 0.2218 0.172080693 2.9920752 0.4422236 1.14199405 2.89 173790 6.8823 1753866 48.55 1205793 23.48 1315672 50.35 2591561 29.172568634 56.9625 12472562515.50 8007189242.98 9483222512.55 23444940392.993023 2134728 96.15 719751 16.91 755608 50.72 7575415 88.918080496117.13255199440221.76 6630689687.95282850.565774 0.02402 0.0114131.0428348 0.14939 0.0340494.43 379582 2.979465 0.4088177.75 2990366 26.65 209140 9.4314744 23.121248571 90.78308920 343.4743270 27.6212410588117.92 223011 19.3449663 47.613106944403.36233577 248.21zenotravel-ipc301020304050607080910111668111115112122142 0.002 0.002 0.0017 0.0018 0.0017 0.0028 0.0118 0.0112 0.0199 0.0188 0.0181 0.01177 0.01220 0.01136 0.022287 0.101144 0.05504 0.055088 0.164234 0.094199 0.193268 0.351026 0.121655 0.322844771177.70 2842546176.05 2433822262.842283679295.65 1921903196.38 1832871383.99139687 18.6376904 8.2093782 19.512 0.002 0.007 0.007 0.007 0.217 0.909 0.209 0.8912 0.2512 1.9012 0.3812 3.5416 0.3816 3.4814354 2.0012 14.482517035 51.18 611457 30.471322871 34.84 137872 25.44310030 11.28 110726 26.6520.4590.46403.422153.444227.701957 11.8134890 30.3683533 292.0525851605256822895965314056260.000.000.040.030.635.903.562 0.0022 0.00492 0.02665 0.0112466 0.3385931 2.47115348 2.60687846 50.76Table 19: Similar Table 15 PSR, TPP, Trucks, Zenotravel domains.120fiImplicit Abstraction HeuristicshFtaskhhIhFInodes timenodes time nodesMS-104time nodesMS-105timenodesHSPFtime nodesblindhmaxtime nodes time nodestimeschedule-strips02-002-102-202-302-402-502-602-702-802-903-003-103-203-303-403-503-603-703-803-904-004-104-204-304-404-504-604-704-804-905-005-105-205-305-405-505-605-705-805-906-206-406-607-007-707-935 0.075 0.045 0.0823 0.084 0.053 0.1023 0.173 0.063 0.19326 0.1737 0.0626 0.18368 0.17 188 0.07220 0.2623 0.173 0.053 0.1923 0.075 0.043 0.0923 0.153 0.053 0.1723 0.173 0.053 0.1935 0.075 0.045 0.08440 0.31 407 0.16140 0.4523 0.223 0.083 0.25427 0.2150 0.0933 0.25415 0.1391 0.0915 0.1534 0.3916 0.104 0.44473 0.38 471 0.1474 0.43472 0.1275 0.0869 0.13428 0.2350 0.0928 0.254273 0.43 266 0.14273 0.4848 0.2331 0.0914 0.275373 0.45 1498 0.50167 0.546 1755915.4510707 3.48 17686 17.585209 0.40 406 0.1966 0.345142 0.40 674 0.25251 0.585921 1.14 450 0.31574 1.396483 0.95 4544 1.11850 2.116779 0.5611610 2.44 1834 1.43599 0.58 424 0.31163 0.785102 0.52 573 0.24111 0.6041043 1.27 996 0.67 1050 1.665163 0.86 483 0.51167 1.0562701 2.951887811.36 1257 3.107 11885586.65158640178.667 2715924.884144713.08 13622 16.726989 1.63 3433 1.29582 1.366198 0.61 9550 4.61347 1.057603311.164987316.17 10325 16.636944 1.9217562 9.03 2107 4.1071190 2.436153920.22 2709 7.2461537 2.2415829 6.85 2717 5.456888 3.292698622.47 1709 6.918 1153520.8156273131.698 1558946.6841764133.7672489 9.106995 25.498 1072641.0138251154.498682919.2030148109.494 511.103 104.983 231.994 56.5133334363.11121.84323.77316.53251.465 191.035 259.135 682.305 121.585 195.725 235.4871115.766 267.2977665837.68459.19936.68711.65316.2241743.325334433335577.39754.26495.56658.90484.62667.32697.42604.06668.79577.1676 0.0250.096 0.0230.075 0.0230.07529 0.03950.45543 0.031080.443 0.0330.076 0.0230.0613 0.0230.078 0.0230.0776 0.0350.0911915 0.60 11278.9831 0.04250.373617 0.23 12289.563379 0.231701.8541223.90301 0.06220.2712217 0.64 1175 12.432663 0.19 1542 11.7312859 0.68 1323 13.4712616 0.65 1590 11.134339 0.279137.6931219326.88 22993 273.3855206949.7947696 4.97 9703 131.6989272 8.74 12941 163.8462013 6.03 13614 168.071079781399.991071151001.4061327 5.97 8683 103.5034046729.56 15122 181.9841673 4.27 5480 83.6914335022.71 43336 751.35120602 989.42Table 20: Similar Table 15 (non-IPC) Schedule-STRIPS domain.121fiKatz & DomshlakhFtaskhnodeshIhFIHSPFblindtimenodestimenodestimenodestimenodestime0.390.454.0010.5968.19125.831.343.3918.4343.8031.37327.825.99112.11335.39291.88203.57249.28105075184219439294029326985438697755073478362432280132551728230190.841.1213.4374.29290.071167.784.6423.8466.00337.57570.438333404413976014639621130171965371315454638629714768742012554791.031.4615.6262.26317.53965.395.0021.3668.80290.86425.2712935481027644127808730.5542.63469.96885.942667016162650316102532995671690.400.4911.3229.51174.387210974663190.25325.43145170152021142646162387432.534.4732.06199.6379574859710109351879.93349.901208.0566582757718754214613.62395.631319.93123510443.9919466916332954.2857.1944305371578.0449144317220842209986125370808492052619878310580398023157304711526411732421646347548124514735531739290.370.731.322.634.875.6640.7457.1218.2623.40105.4443.05443.57222.141034.92671.53745.34186.401731.491018.62651.9319376916658113171513288201137234328114281726735632613411692547985123311511926297492879380651139530490.000.000.010.060.160.022.312.921.320.767.174.1135.0717.19184.5775.73128.8014.32153676427.6212193349936922196131015383484225719222602281682931218970.201.440.7211.2135.00115.360.553.3918.14792.780.090.512.036.38145.47404.982013754903123025180.000.010.03126.4623513811308100.000.0512.721624852858230.000.023.324404745529458821017565710310817103214655454541017098010254740102940230.680.540.49314.87242.27222.660.010.010.01113.2995.9188.03elevators-strips-ipc60102030405061112131415182122232425264226554055535654596366614854695663487483289861649600399098227162381831321812186526248709201777105732771003890048408907114305591384406699757openstacks-strips-ipc6010203040506070809101112131415161718192122222342553343444443434209769172982091670536581951092288471164257768157567735491325965931260363119952255064737819306510209050.000.020.040.170.410.115.857.775.033.5728.7519.85150.8681.43867.27379.45673.9188.15209769172982091670536581951092288471164257768157567735491325965931260363119952255064737819306510209050.000.000.010.070.180.042.453.231.611.109.115.6346.3023.36245.32104.37179.0022.24209769172982091670536581951092288471164257768157567735491325965931260363119952255064737819306510209050.000.020.040.200.480.136.859.065.774.1432.9722.85172.1393.01987.24432.44765.1599.671805050204.83180505048.731805050233.980.010.020.0413.85219.49613.020.010.075.83463.930.000.010.288.49151838217752089200235293272412431440840.000.010.012.2831.78148.950.000.044.2715179668681168224423443221241135976830.000.020.037.56115.96557.750.010.089.2513303158256945030.000.010.4724.621328287783168390.000.020.6331.371.681.881.90687.38870.50869.520.140.150.14834.36720.23643.412201237569432985.204.364.021980937524432986.396.075.7121259292533775413.6913.9214.055151510.080.080.084646460.200.190.196660.050.050.05parcprinter-strips-ipc60102030405061112131421222324252616900943804780711487609411451321514200182808510256693064102051214341137582151923275164212158401216460192408801423141780073411348725118374201449126513225437696748scanalyzer-strips-ipc601020304050622232425262718222624303613131326303419788371824311539477969193480101409094646468974317993683210202674Table 21: Runtimes cost-optimal heuristic-search planners Elevators,Openstacks-strips-08, Parcprinter, Scanalyzer domains. description planners given Section 6; fork-decomposition heuristics via structural-pattern databases. Column task denotes problem instance,column h denotes optimal solution length. columns capture run timenumber expanded nodes.122fiImplicit Abstraction HeuristicshFtaskhhInodeshFIHSPFblindtimenodestimenodestimenodestimenodestime0.020.070.070.070.030.160.082.560.362.451.082.982.514.825.840.8322.384.9320.7127.3641.785.6697.46106.0068.95553.11523.1210832091812519011102525339512824112881373583337455127737331059830097250222257988293860494477481909545931219589899323694312421219360.020.120.120.120.020.140.120.710.200.770.380.860.761.291.670.336.381.375.628.5611.491.4325.1631.8325.33177.0682.6110832091812519011102525339512824112881373583337455127737331059830097250222257988293860494477481909545931219589899323694312421219360.030.180.190.190.040.270.182.890.533.211.363.633.095.637.091.1027.005.5524.4936.4350.515.95108.53136.27107.61719.81339.83620501543247267898757752259792113325897171443781079392828101035890950836931419061312318183027115720193220311561327010.165.176.911.825.6225.6811.6728.5023.0228.2520.6032.7333.2932.2038.7227.70124.3929.8161.7763.9987.8930.94114.89157.50122.271024.04118.201166174192242126521530776353829658134303856132370620477615010090294396627262759693285835458966946512587671324907830182717880260918640.000.010.000.010.010.010.010.150.030.140.060.180.150.290.350.051.440.291.291.632.640.336.176.694.3337.7834.53372551394130524505264752221144432308369797271598155166169436207377943562335238804592109516523895764833785258667003565151145046100.030.020.015.570.320.042.81135.121.473.1715.6310.988.931.05602.9920.204.17156.88354.840.1474.21473.77222.481151.55287497177450482032025344219512042122618921291282061606552947106984774269824277840425119938355880964845002740534133613835224415623044275121381010.010.010.000.287.280.010.3811.270.260.182.090.703.630.0784.751.660.290.9733.600.6914.6445.1850.3130.10275.91152.952695091734419830735262816310803371601320741271598468651694366952745650524091236889119784345931464876647386866325631591759660178321561047320487384570.020.020.012.070.960.041.8474.551.121.0716.873.6910.260.41622.8915.142.059.18251.380.7916.85335.31181.66154.331612.04996.251131.2610797006212828956.174.572.63177.076815756696.83174.92459188620685440869400.45315.43586.911631677178574994.61121.96852948239522859.44220.861762134811653204469607487105263154051332953881869385215053130547057422363177255203215983539355613179847219504232551336490.010.000.001.4381.840.041.4977.704.094.072.7125.2112.601.17120.254.741.4339.20130.460.012074534679.611287422531014620631119976224986674455568972920040.000.1048.69714.490.011.4174.090.000.3713.82120.9816998257608166087410311130246069625408705793825880.010.1559.28856.870.021.7089.040.010.5419.32196.826015673809820.486.36274.86135148743731336275441003470.9419.85454.550.507.7192.93642093408643420437216414796408449112761010654816638560.000.013.6950.690.000.124.360.000.061.0719.2911940980794501166511338616193146730.853.03136.950.9318.49273.760.915.969.059086210760.090.30348718624760.0537.912271779429626980.003.9723.76pegsol-strips-ipc60102030405060708091011121314151617181920212223242526272544443656789788107878688897128420819326613432173168137432975613832393403337963096779321049129967663247279822329570548254699221262645132651783063771968366092258sokoban-strips-ipc6010203040506070809101112131415161718192021222324252627301191029891531193035322029765037494721044315039332314transport-strips-ipc601020304111213212223245413125031845659455047863263061460155838037535262041351487337284562754410026915878210.010.0610.47164.350.020.3715.070.010.183.6577.96woodworking-strips-ipc601020311121321222317018527513022521595185195431355500.230.34371650540.100.14415754080.280.4186032822944137265431189446410.1041.44954.340.024.668.39987328728412578854675281554260.0516.57455.350.023.269.7189732893044041045338912648400.1352.031297.060.036.8314.42Table 22: Similar Table 21 Pegsol, Sokoban, Transport, Woodworking domains.123fiKatz & DomshlakReferencesBackstrom, C., & Nebel, B. (1995). Complexity results SAS+ planning. ComputationalIntelligence, 11 (4), 625655.Bonet, B., & Geffner, H. (2001). Planning heuristic search. Artificial Intelligence, 129 (12), 533.Bylander, T. (1994). computational complexity propositional STRIPS planning.Artificial Intelligence, 69 (1-2), 165204.Chen, H., & Gimenez, O. (2008). Causal graphs structurally restricted planning. Proceedings 18th International Conference Automated Planning Scheduling(ICAPS), pp. 3643, Sydney, Australia.Clarke, E., Grumberg, O., & Peled, D. (1999). Model Checking. MIT Press.Coles, A. I., Fox, M., Long, D., & Smith, A. J. (2008). Additive-disjunctive heuristicsoptimal planning. Proceedings 18th International Conference AutomatedPlanning Scheduling (ICAPS), pp. 4451.Culberson, J., & Schaeffer, J. (1998). Pattern databases. Computational Intelligence, 14 (4),318334.Domshlak, C., & Dinitz, Y. (2001). Multi-agent off-line coordination: Structure complexity. Proceedings Sixth European Conference Planning (ECP), pp. 277288.Domshlak, C., Hoffmann, J., & Sabharwal, A. (2009). Friends foes? planningsatisfiability abstract CNF encodings. Journal Artificial Intelligence Research,36, 415469.Domshlak, C., Katz, M., & Lefler, S. (2010). abstractions met landmarks. Proceedings 20th International Conference Automated Planning Scheduling(ICAPS), pp. 5056, Toronto, Canada.Drager, K., Finkbeiner, B., & Podelski, A. (2006). Directed model checking distancepreserving abstractions. Valmari, A. (Ed.), Proceedings 13th InternationalSPIN Workshop Model Checking Software, Vol. 3925 Lecture Notes ComputerScience, pp. 1936, Berlin Heidelberg. Springer-Verlag.Edelkamp, S. (2001). Planning pattern databases. Proceedings EuropeanConference Planning (ECP), pp. 1334.Edelkamp, S. (2002). Symbolic pattern databases heuristic search planning. Proceedings International Conference AI Planning Scheduling (AIPS), pp.274293.Edelkamp, S. (2006). Automated creation pattern database search heuristics. Proceedings 4th Workshop Model Checking Artificial Intelligence (MoChArt).Edelkamp, S., & Kissmann, P. (2009). Optimal symbolic planning action costspreferences. Proceedings 21st International Joint Conference ArtificialIntelligence (IJCAI), pp. 16901695, Pasadena, CA, US.Felner, A., Korf, R. E., & Hanan, S. (2004). Additive pattern database heuristics. JournalArtificial Intelligence Research, 22, 279318.124fiImplicit Abstraction HeuristicsHaslum, P. (2008). Additive reversed relaxed reachability heuristics revisited. Proceedings 6th International Planning Competition.Haslum, P., Bonet, B., & Geffner, H. (2005). New admissible heuristics domainindependent planning. Proceedings Twentieth National Conference Artificial Intelligence (AAAI), pp. 11631168.Haslum, P., Botea, A., Helmert, M., Bonet, B., & Koenig, S. (2007). Domain-independentconstruction pattern database heuristics cost-optimal planning. Proceedings19th National Conference Artificial Intelligence (AAAI), pp. 10071012.Haslum, P., & Geffner, H. (2000). Admissible heuristics optimal planning. Proceedings Fifth International Conference Artificial Intelligence Planning Systems(ICAPS), pp. 140149.Helmert, M. (2003). Complexity results standard benchmark domains planning.Artificial Intelligence, 146 (2), 219262.Helmert, M. (2004). planning heuristic based causal graph analysis. Proceedings14th International Conference Automated Planning Scheduling (ICAPS),pp. 161170, Whistler, Canada.Helmert, M. (2006). Fast Downward planning system. Journal Artificial IntelligenceResearch, 26, 191246.Helmert, M., & Domshlak, C. (2009). Landmarks, critical paths abstractions: Whatsdifference anyway?. Proceedings 19th International Conference Automated Planning Scheduling (ICAPS), pp. 162169, Thessaloniki, Greece.Helmert, M., Haslum, P., & Hoffmann, J. (2007). Flexible abstraction heuristics optimalsequential planning. Proceedings 17th International Conference AutomatedPlanning Scheduling (ICAPS), pp. 176183, Providence, RI, USA.Helmert, M., & Mattmuller, R. (2008). Accuracy admissible heuristic functions selected planning domains. Proceedings 23rd AAAI Conference ArtificialIntelligence, pp. 938943, Chicago, USA.Helmert, M. (2008). Understanding Planning Tasks: Domain Complexity HeuristicDecomposition, Vol. 4929 Lecture Notes Computer Science. Springer.Hernadvolgyi, I., & Holte, R. (1999). PSVN: vector representation production systems.Tech. rep. 1999-07, University Ottawa.Jonsson, A. (2007). role macros tractable planning causal graphs. Proceedings International Joint Conference Artificial Intelligence (IJCAI-07),pp. 19361941.Jonsson, P., & Backstrom, C. (1998). State-variable planning structural restrictions:Algorithms complexity. Artificial Intelligence, 100 (12), 125176.Karpas, E., & Domshlak, C. (2009). Cost-optimal planning landmarks. ProceedingsInternational Joint Conference Artificial Intelligence (IJCAI-09), pp. 17281733, Pasadena, CA, USA.125fiKatz & DomshlakKatz, M., & Domshlak, C. (2007a). Structural patterns heuristics. ICAPS-07 Workshop Heuristics Domain-independent Planning: Progress, Ideas, Limitations,Challenges, Providence, RI, USA.Katz, M., & Domshlak, C. (2007b). Structural patterns tractable sequentially-optimalplanning. Proceedings 17th International Conference Automated PlanningScheduling (ICAPS), pp. 200207, Providence, RI, USA.Katz, M., & Domshlak, C. (2008). Structural patterns heuristics via fork decomposition.Proceedings 18th International Conference Automated Planning Scheduling (ICAPS), pp. 182189, Sydney, Australia.Katz, M., & Domshlak, C. (2009). Structural-pattern databases. Proceedings19th International Conference Automated Planning Scheduling (ICAPS), pp.186193, Thessaloniki, Greece.Katz, M., & Domshlak, C. (2010). Optimal admissible composition abstraction heuristics.Artificial Intelligence, 174, 767798.Pearl, J. (1984). Heuristics - Intelligent Search Strategies Computer Problem Solving.Addison-Wesley.Prieditis, A. (1993). Machine discovery effective admissible heuristics. Machine Learning,12, 117141.Richter, S., Helmert, M., & Westphal, M. (2008). Landmarks revisited. ProceedingsTwenty-Third National Conference Artificial Intelligence (AAAI), pp. 975982,Chicago, IL, USA.Yang, F., Culberson, J., & Holte, R. (2007). general additive search abstraction. Tech.rep. TR07-06, University Alberta.Yang, F., Culberson, J., Holte, R., Zahavi, U., & Felner, A. (2008). general theoryadditive state space abstractions. Journal Artificial Intelligence Research, 32,631662.126fi