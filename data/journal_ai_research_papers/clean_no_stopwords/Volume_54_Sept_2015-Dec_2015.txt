Journal Artificial Intelligence Research 54 (2015) 535-592Submitted 07/15; published 12/15Pay-As-You-Go Description Logic ReasoningCoupling Tableau Saturation ProceduresAndreas SteigmillerBirte Glimmandreas.steigmiller@uni-ulm.debirte.glimm@uni-ulm.deInstitute Artificial Intelligence, University Ulm, GermanyAbstractNowadays, saturation-based reasoners OWL EL profile Web OntologyLanguage able handle large ontologies SNOMED efficiently. However,currently unclear saturation-based reasoning procedures extendedexpressive Description Logics SROIQthe logical underpinning currentsecond iteration Web Ontology Language. Tableau-based procedures,hand, limited specific Description Logic languages OWL profiles,even highly optimised tableau-based reasoners might efficient enough handle largeontologies SNOMED. paper, present approach tightly couplingtableau- saturation-based procedures implement OWL DL reasonerKonclude. detailed evaluation shows combination significantly improvesreasoning performance wide range ontologies.1. Introductioncurrent version Web Ontology Language (OWL 2) (W3C OWL Working Group,2009) based expressive Description Logic (DL) SROIQ (Horrocks, Kutz,& Sattler, 2006). Sound complete tableau algorithms, easily extensibleadaptable, typically used handle (standard) reasoning tasks. Moreover, usewide range optimisation techniques allows handling many expressive, real-worldontologies. Since standard reasoning tasks SROIQ N2EXPTIME-complete worstcase complexity (Kazakov, 2008), is, however, surprising larger ontologies easilybecome impractical existing systems.contrast, OWL 2 profiles define language fragments SROIQstandard reasoning tasks tractable specialised reasoning procedures available.example, OWL 2 EL profile based DL EL++ , efficientlyhandled completion- consequence-based reasoning procedures (Baader, Brandt, &Lutz, 2005; Kazakov, 2009). saturation algorithms also extended handleexpressive DLs Horn-SHIQ (Kazakov, 2009) often ableoutperform general tableau algorithms. Even saturation procedures DLsnon-deterministic language features, ALCI (Simanck, Kazakov, & Horrocks, 2011),ALCH (Simanck, Motik, & Horrocks, 2014), SHIQ (Bate, Motik, Cuenca Grau, Simanck,& Horrocks, 2015), developed implementations reasoningsystems show remarkable performance. particular, allow one-pass handlingseveral reasoning tasks classification (i.e., task arranging classesontology hierarchy), whereas idea tableau procedures based pairwisetesting individual class subsumptions. Although optimised classification algorithmsc2015AI Access Foundation. rights reserved.fiSteigmiller & Glimmdeveloped tableau-based reasoning systems (Baader, Hollunder, Nebel, Profitlich,& Franconi, 1994; Glimm, Horrocks, Motik, Shearer, & Stoilos, 2012), still usemultitude separate consistency tests order decide subsumption relations. Sincecomplete handling DLs providing disjunctions, cardinality restrictions, inverseroles causes several difficulties, saturation procedures yet extendedexpressive DLs SROIQ. Hence, less efficient tableau-based reasoningsystems currently used handle ontologies expressive languagefeatures.Unfortunately, combination tableau algorithms saturation proceduresstraightforward since techniques work quite differently. Hence, ontology engineersdecide whether use restricted features certain language fragmentsontologies handled specialised reasoners saturation-basedprocedures face possible performance losses using general reasoningsystems based tableau algorithms. especially unfavourable languagefeatures required axioms ontology. case, completenesslonger ensured specialised procedures, fully-fledged, tableau-basedreasoners possibly efficient enough. Ideally, reasoning systems better pay-asyou-go behaviour could used, part ontology affectedaxioms outside tractable fragment still handled efficiently. led recentdevelopment approaches combine saturation procedures fully-fledged reasonersblack box manner (Armas Romero, Cuenca Grau, & Horrocks, 2012; Song, Spencer,& Du, 2012; Zhou, Nenov, Cuenca Grau, & Horrocks, 2014; Zhou, Cuenca Grau, Nenov,Kaminski, & Horrocks, 2015). approaches try delegate much work possiblespecialised efficient reasoner, allows reducing workloadfully-fledged tableau algorithm, still guaranteeing completeness.paper, present much tighter coupling saturation tableau algorithms, whereby performance improvements achieved. introducingpreliminaries (Section 2), present saturation procedure adapted datastructures tableau algorithm (Section 3). allows easily passing informationsaturation tableau algorithm within reasoning system. Moreover, saturation partially handles features expressive DLs order efficientlyderive many consequences possible (Section 3.1). show partsontology identified saturation procedure possibly incompletenecessary fall-back tableau procedure (Section 3.2). Subsequently,present several optimisations based passing information saturationtableau algorithm (Section 4) back (Section 5). Finally, discuss related work(Section 6) present results detailed evaluation including comparisonsapproaches state-of-the-art reasoners (Section 7) conclude (Section 8).paper based previous conference publication (Steigmiller, Glimm, & Liebig,2014a), contains significantly extended explanations, additional examples, proofscorrectness integrated saturation procedure incompleteness detection.Due space limitations conference publication, information passingtableau algorithm saturation procedure could sketched, whereasdescribed detail paper. Moreover, coupling saturation procedureextended paper consider handle language features DL536fiPay-As-You-Go Description Logic ReasoningSROIQ. Furthermore, show new detailed evaluation basedupdated implementation compare results approaches fullyfledged specialised reasoners combined.2. Preliminariesorder describe techniques detail, first give, based original presentation Horrocks et al. (2006), brief introduction DL SROIQ section.detailed introduction DLs, refer Description Logic Handbook (Baader,Calvanese, McGuinness, Nardi, & Patel-Schneider, 2007). Subsequently, describe tableau algorithm typically used reasoning systems also refer workHorrocks et al. (2006) details.2.1 Description Logic SROIQfirst define syntax roles, concepts (also called classes), individuals,go axioms ontologies/knowledge bases. Additionally, sketch typicallyused restrictions combination different axioms, necessary ensuredecidability many inference problems SROIQ. Note describedetails restrictions since well-known DL literature (Horrocks et al.,2006) particularly relevant proposed optimisation techniques. Subsequently,define semantics components.Definition 1 (Syntax Individuals, Concepts, Roles). Let NC , NR , NI countable, infinite, pairwise disjoint sets concept names, role names, individualnames, respectively. call = (NC , NR , NI ) signature. set Rols() SROIQroles (or roles short) NR {r | r NR }, role form rcalled inverse role r. Since inverse relation roles symmetric, definefunction inv, returns inverse role and, therefore, considerroles r . r NR , let inv(r) = r inv(r ) = r.set SROIQ-concepts (or concepts short) smallest set builtinductively symbols using following grammar, NI , n IN0 ,NC , r Rols():C ::= > | | | {a} | C | C1 u C2 | C1 C2 | r.C | r.C | r.Self | > n r.C | 6 n r.C.roles, concepts, individuals used build ontology axioms follows:Definition 2 (Syntax Axioms Ontologies). C, concepts, general conceptinclusion (GCI) axiom expression C v D. finite set GCIs called TBox.role inclusion (RI) axiom expression form u v r, r role ucomposition roles, i.e., u = s1 . . . sn roles s1 , . . . , sn n 1. r,roles, role assertion (RA) axiom form Disj(r, s). RBox finite set RIsRAs. Given RBox R, use v transitive-reflexive closure r vinv(r) v inv(s) axioms R. call role r sub-role super-role rr v s.(ABox) assertion expression form C(a) r(a, b), C concept,r role, a, b NI individual names. ABox finite set assertions.537fiSteigmiller & Glimmknowledge base ontology K tuple (T , R, A) TBox, R RBox,ABox.Note, also possible allow types RAs RBox, e.g., axiomsspecify roles asymmetric, irreflexive, transitive, reflexive, symmetric. However,axioms expressed indirectly ways and, therefore, omit presentationhere. example, axiom form Refl(r), role r interpretedreflexive, encoded axioms r0 v r > v r0 .Self.1 Analogously,allow frequently used ABox assertions since, presence nominals,ABox assertion also expressed GCIs (which also utilise eliminateABox assertions simplify presentation algorithms). Furthermore, SROIQ usuallyallows usage universal role u, u also simulated fresh transitive,reflexive, symmetric super role, i.e., role implied roles.following, use K also abbreviation collection axioms knowledgebase. example, write C v K instead C v K.order ensure decidability (Horrocks, Sattler, & Tobies, 1999; Horrocks & Sattler,2004), simple roles allowed concepts form > n r.C, 6 n r.C, r.Selfaxioms form Disj(r, s), where, roughly speaking, role simpleimplied RI uses role composition. Furthermore, RBox regular,i.e., RI axioms allowed limited form (Horrocks & Sattler, 2004), restrictscyclic dependencies RIs.Next, define semantics concepts go semantics axiomsontologies/knowledge bases.Definition 3 (Semantics Individuals, Concepts, Roles). interpretation =(I , ) consists non-empty set , domain I, function , mapsevery concept name NC subset AI , every role name r NR binaryrelation rI , every individual name NI element aI .role name r NR , interpretation inverse role (r ) consists pairsh, 0 h 0 , rI .interpretation I, semantics SROIQ-concepts signature defined function follows:>I(C)I(r.Self)I(r.C)I(r.C)I(6 n r.C)I(> n r.C)I=======\ C{{{{{=({a})I =(C u D) = C(C D)I =| h, r }| h, 0 rI , 0 C }| h, 0 rI 0 C }| ]{ 0 | h, 0 rI 0 C } n}| ]{ 0 | h, 0 rI 0 C } n},{aI }C DI]M denotes cardinality set .Finally, define semantics ontologies/knowledge bases.1. Note use fresh sub-role r0 r axiom > v r0 .Self since r might complex,r.Self expressions allowed simple roles.538fiPay-As-You-Go Description Logic ReasoningDefinition 4 (Semantics Axioms Ontologies). Let = (I , ) interpretation,satisfies TBox/RBox axiom ABox assertion , written |=1. GCI C v C DI ,2. RI s1 . . . sn v r sI1 . . . sIn rI , denotes compositionbinary relations sI1 . . . sIn ,3. RA form Disj(r, s) rI sI = ,4. ABox assertion C(a) aI C ,5. ABox assertion r(a, b) haI , bI rI .satisfies TBox (RBox R, ABox A) satisfies GCI (each RI/RA axiomR, assertion A). say satisfies K = (T , R, A) satisfies , R,A. case, say model K write |= K. say Kconsistent K model.2.2 Normalisation Preprocessingremainder assume knowledge base normalised following form:1. TBox contains axioms form A1 u A2 v C H v C H = A,H = {a}, H = >, C negation normal form A, A1 , A2 denote conceptnames.2. RBox contains RAs simple role inclusion axioms form r1 v r2 .3. ABox empty.assumption without loss generality. Item 1: concept transformedequivalent one negation normal form (NNF) pushing negation inwards, makinguse de Morgans laws duality existential universal restrictions,at-most at-least cardinality restrictions (Horrocks, Sattler, & Tobies, 2000).use nnf(C) denote equivalent concept C NNF. Furthermore, GCI C vcorrespond normal form equivalently written > vnnf(C tD). rewriting GCIs creates (possibly many) disjunctions, potentiallycauses lot non-determinism reasoning procedure and, therefore, easily decreasesreasoning performance. counteract this, preprocessing step called absorptionoften used (Horrocks & Tobies, 2000; Hudek & Weddell, 2006; Steigmiller, Glimm, & Liebig,2013, 2014b; Tsarkov & Horrocks, 2004), tries rewrite axioms possiblyseveral simpler concept inclusion axioms. example, instead treating u r.B v C> v r.(B) C, sophisticated absorption algorithm avoid non-determinismrewriting axiom B v r .F u F v C, F fresh atomicconcept used preserve semantics original axiom. Item 2: RIsuse compositions eliminated using encoding based automata (Horrocks &Sattler, 2004) regular expressions (Simanck, 2012). Note explicit encodingspropagations complex roles might blow knowledge base exponentially,539fiSteigmiller & Glimmcannot avoided worst-case, i.e., could try delay actualreasoning process (Kazakov, 2008) indeed utilised many reasoners (althoughblow seems hardly caused real-world ontologies). Item 3, C(a) (r(a, b))equivalently expressed {a} v C ({a} v r.{b}).2.3 Tableau Algorithm SROIQModel construction calculi, tableaux, decide consistency knowledge base Ktrying construct abstraction model K, so-called completion graph.following, describe, based original presentation SROIQ tableau algorithm (Horrocks et al., 2006), model construction process used data structures,beginning completion graphs.Definition 5 (Completion Graph). concept C, use sub(C) denote setsub-concepts C (including C). Let K normalised SROIQ knowledge baselet Cons(K) set concepts occurring TBox K, i.e., Cons(K) = {C, |C v K}. define closure clos(K) K as:clos(K) = {C sub(D) | Cons(K)} {nnf(C) | C sub(D), Cons(K)}.). node v Vcompletion graph K directed graph G = (V, E, L, 6=labelled set L(v) fclos(K),fclos(K) = clos(K) {6 r.C |6 n r.C clos(K) n}.edge hv, v 0 E labelled set L(hv, v 0 i) Rols(K), Rols(K)used keep track inequalitiesroles occurring K. symmetric binary relation 6=nodes V .following, often use r L(hv1 , v2 i) abbreviation hv1 , v2 Er L(hv1 , v2 i).Definition 6 (Successor, Predecessor, Neighbour). hv1 , v2 E, v2 calledsuccessor v1 v1 called predecessor v2 . Ancestor transitive closurepredecessor, descendant transitive closure successor. node v2 called ssuccessor node v1 r L(hv1 , v2 i) r sub-role s; v2 called s-predecessorv1 v1 s-successor v2 . node v2 called neighbour (s-neighbour) nodev1 v2 successor (s-successor) v1 v1 successor (inv(s)-successor) v2 .role r node v V , define set vs r-neighbours concept Clabel, written mneighbs(v, r, C), {v 0 V | v 0 r-neighbour v C L(v 0 )}.Note, many inference problems DL SROIQ easily reduced consistencychecking and, therefore, indirectly handled although often consistencychecking reasoning task specified tableau algorithm. example, ordertest satisfiability concept C, introduce fresh individual assertconcept C axiom form {a} v C. nodes represent (fresh)individuals typically called root nodes.order test consistency knowledge base, completion graph initialisedcreating one node individual/nominal input knowledge base. particular,540fiPay-As-You-Go Description Logic Reasoningv1 , . . . , v` nodes individuals a1 , . . . , a` K, create initialcompletion graph G = ({v1 , . . . , v` }, , L, ) add individual ai nominal {ai }concept > label vi , i.e., L(vi ) = {{ai }, >} 1 `.tableau algorithm works decomposing/unfolding concepts completiongraph set expansion rules (see Table 1). rule application add newconcepts node labels and/or new nodes edges completion graph, therebyexplicating structure model input knowledge base. rules repeatedlyapplied either graph fully expanded (no rules applicable), casegraph used construct model witness consistency K,obvious contradiction (called clash) discovered (e.g., C C node label),proving completion graph correspond model. input knowledgebase K consistent rules (some non-deterministic) appliedbuild fully expanded clash-free completion graph.) knowledge base K containsDefinition 7 (Clash). completion graph G = (V, E, L, 6=clash nodes v w1. L(v),2. {C, nnf(C)} L(v) concept C,3. v r-neighbour v r.Self L(v),4. Disj(r, s) K w r- s-neighbour v,5. concept 6 n r.C L(v) {w1 , . . . , wn+1 } mneighbs(v, r, C)wj 1 < j n + 1,wi 6=w.6. {a} L(v) L(w) v 6=Unrestricted application -rule >-rule lead introduction infinitelymany new tableau nodes and, thus, prevent calculus terminating. counteractthat, cycle detection technique called (pairwise) blocking (Horrocks & Sattler, 1999)used restricts application rules. apply blocking, distinguish blockablenodes nominal nodes, either original nominal knowledge basenew nominal introduced calculus label.Definition 8 (Pairwise Blocking). node blocked either directly indirectlyblocked. node v indirectly blocked ancestor v blocked; v predecessorv 0 directly blocked exists ancestor node w v predecessor w01. v, v 0 , w, w0 blockable,2. w, w0 blocked,3. L(v) = L(w) L(v 0 ) = L(w0 ),4. L(hv 0 , vi) = L(hw0 , wi).case, say w directly blocks v w blocker v.541fiSteigmiller & Glimmv1 -rulev2 -ruleu-rulet-rule-ruleSelf-rule-rulech-rule>-rule1.2.6-rule1.2.o-ruleNN-rule 1.2.H L(v), H v C K H = A, H = {a}, H = >, C/ L(v),v indirectly blockedL(v) = L(v) {C}{A1 , A2 } L(v), A1 u A2 v C K, C/ L(v),v indirectly blockedL(v) = L(v) {C}C1 u C2 L(v), v indirectly blocked, {C1 , C2 } 6 L(v)L(v) = L(v) {C1 , C2 }C1 C2 L(v), v indirectly blocked, {C1 , C2 } L(v) =L(v 0 ) = L(v 0 ) {H} H {C1 , C2 }r.C L(v), v blocked,v r-neighbour v 0 C L(v 0 )create new node v 0 edge hv, v 0L(v 0 ) = {>, C} L(hv, v 0 i) = {r}r.Self L(v), v blocked, v r-neighbour vcreate new edge hv, vi L(hv, vi) = {r}r.C L(v), v indirectly blocked,r-neighbour v 0 v C/ L(v 0 )00L(v ) = L(v ) {C}6 n r.C L(v), v indirectly blocked,r-neighbour v 0 v {C, nnf(C)} L(v 0 ) =L(v 0 ) = L(v 0 ) {H} H {C, nnf(C)}> n r.C L(v), v blocked,vjn r-neighbours v1 , . . . , vn v C L(vi ) vi 6=1 < j n, v1 , . . . , vn blocked v nominal nodecreate n new nodes v1 , . . . , vn L(hv, vi )i = {r}, L(vi ) = {>, C}vj 1 < j n.vi 6=6 n r.C L(v), v indirectly blocked,]mneighbs(v, r, C) > n two r-neighbours v1 , v2 vv2C (L(v1 ) L(v2 )) v1 6=a. v1 nominal node, merge(v2 , v1 )b. else v2 nominal node ancestor v1 , merge(v1 , v2 )c. else merge(v2 , v1 )v0two nodes v, v 0 {a} (L(v) L(v 0 )) v 6=merge(v, v 0 )6 n r.C L(v), v nominal node, blockabler-neighbour v 0 v C L(v 0 ) v successor v 0 ,1 n, (6 r.C) L(v),exist nominal r-neighbours v1 , . . . , vm vvj 1 < jC L(vi ) vi 6=1. guess 1 n L(v) = L(v) {6 r.C}0 L(hv, v 0 i) = {r},2. create new nodes v10 , . . . , vm0L(vi ) = {>, C, {ai }} ai NI new G K,v 0 1 < j m.vi0 6=jTable 1: Tableau expansion rules normalised SROIQ knowledge bases542fiPay-As-You-Go Description Logic Reasoningexpansion sometimes necessary merge two nodes delete (prune)part completion graph (Horrocks & Sattler, 2007). Roughly speaking, nodew merged node v, e.g., application 6-rule, written merge(w, v),add L(w) L(v), move edges leading w lead v moveedges leading w nominal nodes lead v nominalnodes; remove w (and blockable sub-trees w) completion graph,written prune(w), prevent rule application nodes.Note, order ensure termination tableau algorithm, principle necessaryapply certain crucial rules higher priority. example, o-rule appliedhighest priority NN-rule applied 6-rule. priorityrules relevant long applied lower prioritycrucial rules.3. Saturation Compatible Tableau Algorithmssection, describe saturation method adaptation completionbased procedure (Baader et al., 2005) generates data structures compatible usage within fully-fledged tableau algorithm. Roughly speaking,saturation approximates completion graphs compressed form and, therefore, directlyallows extraction transfer results saturation tableau algorithm.precise, ensure saturation generates nodes are, similarlynodes completion graphs, labelled sets concepts. saturated labelsused initialise labels new nodes completion graphs block processingsuccessors. Moreover, cases, directly possible build model datastructures saturation, makes construction completion graphstableau algorithm unnecessary.Note, adapted saturation method designed cover certain OWL 2 profile specific DL language. contrast, saturate parts knowledge baseseasily supported efficient algorithm (see Section 3.1), i.e., simplyignore unsupported concept constructors process partially, afterwards(see Section 3.2), dynamically detect parts completely handledsaturation. Hence, results saturation possibly incomplete, sinceknow incomplete, use results saturationappropriately.easy integration highly optimised tableau procedure, (usually simpler)saturation procedure adapted work (normalised preprocessed) knowledge base data structures tableau algorithm (but, principle, also oppositedirection would possible). enables, example, direct use node labelssaturation tableau algorithm. coupling technique, use goodabsorption algorithm crucial since saturation handles deterministic partsknowledge base.3.1 Saturation Based Tableau Rulesadapted saturation method generates so-called saturation graphs, approximatecompletion graphs compressed form, e.g., reusing nodes.543fiSteigmiller & GlimmDefinition 9 (Saturation Graph). saturation graph knowledge base K directedgraph = (V, E, L) nodes V {vC | C fclos(K)}. node vC V labelledset L(v) fclos(K) L(vC ) {>, C}. call vC representative nodeconcept C. edge hv, v 0 E labelled set L(hv, v 0 i) Rols(K).Obviously, saturation graph data structure similar completion-relation, omitted sincegraph. major difference is, however, missing 6=saturation designed completely handle cardinality restrictions. Furthermore,node saturation graph representative node specific concept,allows reusing nodes successors. example, instead creating new successorsexistential restrictions, reuse representative node existentially restrictedconcept successor.Since nodes, edges, labels used completion graphs, use terms(r-)neighbour, (r-)successor, (r-)predecessor, ancestor, descendant analogously. Pleasenote, however, nodes saturation graph several predecessors duereuse nodes, whereas completion graphs, nominal nodes severalpredecessors.initialise saturation graph representative nodes conceptssaturated. example, satisfiability concept C tested,add node vC label L(vC ) = {>, C} saturation graph.later also interested saturation concept D, simply extend existingsaturation graph vD . knowledge bases contain nominals, initialisesaturation graph node v{a} L(v{a} ) = {>, {a}} nominal {a} occurringknowledge base. saturation simply applies rules depicted Table 2saturation graph.Definition 10 (Saturation). Let = (V, E, L) saturation graph knowledge baseK, saturation exhaustively applies rules Table 2 S. saturationgraph called fully saturated rules applicable. use functionsaturate denote saturation saturation graph S, i.e., saturate(S) returns 0 ,0 fully saturated extension S.Note saturation rule refers representative node concept Cnode vC yet exist, assume saturation graph automaticallyextended node. Although saturation rules similar correspondingexpansion rules tableau algorithm, differences. example,number nodes limited number (sub-)concepts occurring knowledgebase due reuse nodes satisfying existentially restricted concepts. Consequently,saturation terminates since rules applied add new conceptsroles node edge labels. Moreover, cycle detection blocking required,makes rule application fast. Note also -rule propagates conceptspredecessors node. restriction necessary order allow reusenodes existentially restricted concepts.efficiently derive many sound inferences possible, saturation rulesTable 2 partially support expressive features SROIQ. full saturation,check saturation graph possibly incomplete. Although often544fiPay-As-You-Go Description Logic Reasoningv1 -rule:v2 -rule:u-rule:-rule:-rule:t-rule:>-rule:Self-rule:o-rule:-rule:H L(v), H v C K H = A, H = {a}, H = >, C/ L(v)L(v) = L(v) {C}{A1 , A2 } L(v), A1 u A2 v C K, C/ L(v)L(v) = L(v) {C}C1 u C2 L(v) {C1 , C2 } 6 L(v)L(v) = L(v) {C1 , C2 }r.C L(v) r/ L(hv, vC i)L(hv, vC i) = L(hv, vC i) {r}r.C L(v), inv(r)-predecessor v 0 v, C/ L(v 0 )L(v 0 ) = L(v 0 ) {C}/ L(v)C1 C2 L(v), L(vC1 ) L(vC2 ),L(v) = L(v) {D}> n r.C L(v) n 1 r/ L(hv, vC i)L(hv, vC i) = L(hv, vC i) {r}r.Self L(v) v r-successor vL(hv, vi) = L(hv, vi) {r}{a} L(v),/ L(v),L(v{a} ) descendant v 0 v {{a}, D} L(v 0 )L(v) = L(v) {D}/ L(v),1. {C, nnf(C)} L(v),2. v r-successor {r.Self, r .Self} L(v) 6= ,3. v 0 r-successor v {a} L(v) L(v 0 )r.Self L(v) r .Self L(v),4. {> n r.C, 6 s.D} L(v) n > m, r v s, L(vC ),5. > n r.C L(v) n > 1 {a} L(vC ),6. v 0 r-successor v, r v s, Disj(r, s) K,7. v 0 r-successor v v 00 s-successor v{a} L(v 0 ) L(v 00 ) Disj(r, s) K,8. exists successor node v 0 v L(v 0 ),9. exists node v{a} L(v{a} )L(v) = L(v) {}Table 2: Saturation rules (partially) handling SROIQ knowledge basesseveral ways integrate support expressive concept constructors, chosesimple one allows partial saturation, implementedefficiently. instance, t-rule adds concepts implieddisjuncts. Hence, addition concepts rule obviously sound, handlingdisjunctions often incomplete. at-least cardinality restrictions, build edges(possibly reused) successor nodes similarly -rule. Thereby, actual cardinalityignored, possibly causes incompleteness also at-most cardinality restrictionsrelated super-roles label. order (partially) handle nominal {a}label node v, use o-rule adds concepts derived v{a}545fiSteigmiller & Glimmdescendant nodes also {a} label (instead merging nodestableau procedures). consequence, unsatisfiability concepts formr.(Au{a})ur.(Au{a}) cannot discovered. simple implementation does, however,require repeated saturation concepts extended small influencesnominals. tractable complete saturation algorithms nominalspossible (Kazakov, Krotzsch, & Simanck, 2012), many ontologies use nominalssimple way o-rule already sufficient (e.g., using nominals conceptsform r.{a}).need explicit -rule uses similar conditions ones clashescompletion graphs SROIQ (cf. Definition 7). -rule used handle severalindependent concepts one-pass manner within saturation graph distinguish nodes unsatisfiable concepts nodes (possibly) still satisfiable.-rule detects trivial reasons unsatisfiability C C labelnode (Condition 1), also involved cases. Violations regarding conceptsform r.Self r .Self handled Conditions 2 3. former handlesstraightforward self-loops, latter handles cases would lead loopsaturation merge neighbouring nodes nominal label. Conditions 4 5 handle problematic cases cardinality restrictions. actual cardinalitiesignored saturation, clear clash would occur completion graphpresence conflicting at-least at-most cardinalities (Condition 4) at-leastnumber restrictions form > n r.C n > 1, node representing C containsnominal. latter case, one instance C, nominal, exist modelknowledge base. Conditions 6 7 handle problems Disj(r, s) axioms.former condition treats trivial case, r-successor also s-successordue super-role r. latter condition considers saturationmerge nodes nominal label, would merge labelsedges nodes. Note node vC r- s-successordue node reuse saturation concepts r.C s.C labelnode. is, however, problem even presence Disj(r, s) axioms sincerequired models knowledge base. -rule also propagates ancestornodes (Condition 8) and, case occurs label nominal node, propagatedevery node since knowledge base inconsistent (Condition 9).principle possible detect also several kinds clashes incompletelyhandled parts saturation (e.g., concept C propagated successornode v C L(v)), presented conditions -rule, combinationdetection incompleteness (see Section 3.2), already sufficient identify potentialcauses unsatisfiability. Hence, omit clash conditions ease presentation.Example 1. Let us assume TBox T1a contains following axioms:v .BB v s.{a}interested satisfiability concept A, saturation graph initialisedrepresentative node A, say vA , L(vA ) = {>, A} v{a} L(v{a} ) ={>, {a}} representation individual a. v1 -rule (cf. Table 2) applicablefirst axiom vA , results addition .B L(vA )546fiPay-As-You-Go Description Logic ReasoningvA vBvA vBv{a}L(vA ) = {>, A, .B}L(vB ) = {>, B, s.{a}}L(v{a} ) = {>, {a}}v{a}rL(vA ) = {>, A, .B, B {a}, C}L(vB ) = {>, B, s.{a}, C, 6 1 s.C}L(v{a} ) = {>, {a}, C, > 2 r.B}Figure 1: Generated saturation graphs testing satisfiability w.r.t. T1a (left)T1c (right) Example 1application -rule generates node vB L(vB ) = {>, B} -labelled edgevA vB . Now, v1 -rule applied unfold B label vB s.{a}-rule applicable. Hence, obtain fully saturated saturation graphdepicted left-hand side Figure 1. Note saturation procedure starts ruleapplication nodes vA v{a} ; nodes, e.g., vB , created demand.let T1b = T1a plus axioms:v B {a}BvC{a} v Cv1 -rule extends L(vA ) B {a} L(vB ) well L(v{a} ) C.t-rule applicable adds concept C label vA C labelrepresentative nodes disjuncts disjunction B {a}. Note althoughconcept C added node labels, node C created since C usedway requires this.Finally, let T1c = T1b plus axioms:B v 6 1 s.C{a} v > 2 r.Bv1 -rule extends L(vB ) 6 1 s.C L(v{a} ) > 2 r.B. latter additiontriggers >-rule, adds r-edge v{a} vB saturation graphdepicted right-hand side Figure 1 obtained. Note saturation inherentlyincomplete. example, saturation rule handles concept 6 1 s.C.tableau rules would merge vA v{a} since vB one s-successor Clabel, possibly leads conclusions saturation misses. coverincomplete handling nodes detected next section.suitable absorption technique, saturation usually able derive addmajority concepts would added tableau algorithm equivalentnode. especially case ontologies primarily use features DL EL++saturation-based procedures particularly well-suited. Since EL++ covers manyimportant often used constructors (e.g., u, ), saturation already majoritywork many ontologies confirmed evaluation Section 7.3.2 Saturation Status DetectionSimilarly saturation procedures, presented method Section 3.1 easily becomesincomplete expressive DLs. order nevertheless gain much information547fiSteigmiller & Glimmpossible saturation, identify nodes saturation possibly incomplete. call nodes critical. principle, nodes detected testingwhether actual tableau rule still applicable. However, since saturate expressive concept constructors partially, approach often conservative. example,at-least cardinality restrictions form > n r.C n > 1, saturation alreadycreates reuses successor node concept C and, therefore, consequencespropagated back successor node already considered. Nevertheless,tableau expansion rule at-least cardinality restriction still applicable, sincecreated n successors stated pairwise different. is, however,relevant restrictions limit number allowed r-successorsconcept C label. DL SROIQ, limitations possiblenominals at-most cardinality restrictions. Therefore, sufficient checklimitations instead testing whether tableau expansion rules applicable. Similarrelaxations also possible concept constructors.use rules Table 3 4 detect saturation status saturation graph,incompletely handled nodes identified information relevantsupporting tableau algorithm extracted. precise, rules appliedsaturation graph gather nodes sets , , S! , represents nodesdepend nominals, represents nodes tight at-most restrictions, S!represents critical nodes potentially completely handled saturation.order specify saturation status detail, first define number mergingcandidates facilitate treatment possibly incompletely handled at-most cardinalityrestrictions.Definition 11 (Merging Candidates). Let = (V, E, L) saturation graph. roleconcept D, number merging candidatesPfor node v V w.r.t. D,written function ]mcands(v, s, D), defined >n r.CL nL ={> n r.C L(v) | r v L(vC )}{> 1 r.C | r.C L(v), r v s, L(vC )}.at-most cardinality restriction 6 s.D label node v, mergingcandidates s-successors concept label. usedC -rule (see Table 3) identify nodes tight at-most restrictions, casenode v at-most cardinality restriction 6 s.D label numbermerging candidates v w.r.t. m, i.e., = ]mcands(v, s, D). nodes,still necessary merge merging candidates, every additional candidatemight require merging and, therefore, nodes cannot used arbitrarily.Co -rule adds set nodes directly indirectly depend nominals,i.e., identifies nodes directly nominal label descendantnode nominal label.rules Table 4 used identify critical nodes saturation proceduremight incomplete, i.e., nodes added set S! follows:C - Ct -rule identify nodes critical - t-ruletableau algorithm applicable. Note, C -rule necessary check548fiPay-As-You-Go Description Logic ReasoningC -rule:Co -rule:v/ , 6 s.D L(v), ]mcands(v, s, D) == {v}v/ either {a} L(v) v successor node v 0 v 0= {v}Table 3: Rules detecting nodes tight at-most restrictions nodes nominaldependency saturation graphwhether concepts propagated successor nodes since propagationpredecessors ensured saturation procedure.C6-rule checks every node v whether potentially unsatisfied at-mostcardinality restriction form 6 s.D label v, i.e., ]mcands(v, s, D) > m.Analogously ch-rule tableau algorithm, Cch -rule identifies nodesincompletely handled s-successor nodes neither nnf(D)label. addition, consider successors maymerged predecessor. Note checked perspectivepredecessors due reuse nodes. Therefore, check C6and Cch -rule node v whether exists inv(s)-successor node v 0tight at-most restriction s, i.e., 6 s.D L(v 0 ) ]mcands(v, s, D) = m.v merging candidate, i.e., L(v), would necessary applych-rule v, consider v critical. example, v -successor v 0{> 3 s.D, 6 3 s.D} L(v 0 ), C6-rule (Cch -rule) identifies v criticalL(v) ({D, nnf(D)} L(v) 6= ).also need several rules detection incompleteness related nominals.First, check Coo -rule whether two nodes saturation graphnominal different concepts label. case,handling nominal possibly incomplete since merging nodes would alsomerge labels. Note saturate several independent conceptssaturation graph, merging nodes nominal labelalways necessary. However, detecting merge really required would involveexpensive test. Since many ontologies less expressive DLs use nominalssimple ways, opt simple efficient solution. addition, node vnominal dependent, i.e., descendant node nominal label, arbitrary consequences could propagated via individuals/nominals. Hence,Co! -rule adds v set S! critical nodes representative node individual completely handled since cannot guarantee saturationderived consequences v. contrast, Co6-rule checks possible interactions nominals at-most cardinality restrictions. interactionhandled NN-rule tableau algorithm, cannot easily handledsaturation rather identify nodes critical.Finally, C -rule marks predecessors critical nodes critical.549fiSteigmiller & GlimmC -rule:Ct -rule:C6-rule:Cch -rule:C6-rule:Cch -rule:Coo -rule:Co! -rule:Co6-rule:C -rule:v/ S! , r.C L(v), r-successor v 0 v, C/ L(v 0 )S! = S! {v}v/ S! , C L(v), {C, D} L(v) =S! = S! {v}v/ S! , 6 s.D L(v), ]mcands(v, s, D) >S! = S! {v}v/ S! , 6 s.D L(v), s-successor v 0 v,L(v 0 ) {D, nnf(D)} =S! = S! {v}v/ S! , L(v), v 0 inv(s)-successor v, 6 s.D L(v 0 ),]mcands(v 0 , s, D) =S! = S! {v}v/ S! , v 0 inv(s)-successor v, 6 s.D L(v 0 ),L(v) {D, nnf(D)} =S! = S! {v}v/ S! , {a} L(v), {a} L(v 0 ), L(v) 6 L(v 0 )S! = S! {v}v/ S! , v , exist node v{a} S!S! = S! {v}v/ S! , v 0 inv(s)-successor v, {a} L(v 0 ), 6 s.D L(v 0 ),nnf(D)/ L(v)S! = S! {v}v/ S! , successor v 0 v, v 0 S!S! = S! {v}Table 4: Rules detecting incompleteness saturation graphsets , , S! used define saturation status saturationgraph follows:Definition 12 (Saturation Status). saturation status saturation graph =(V, E, L) defined tuple (So , , S! ). use status function createsexhaustive application rules Table 3 4. node v V criticalv S! , v nominal dependent v , v tight at-most restrictions v .call v clashed L(v).Note concept C unsatisfiable representative node vC clashed.satisfiability C can, however, guaranteed vC critical knowledgebase consistent. Consistency required, concept satisfiableknowledge base consistent, determined saturation nominalnode critical.course, satisfiability/completeness saturated concepts consideredcontext arbitrary concepts handled saturation (e.g., completion graph constructed tableau algorithm), nominal dependency becomesrelevant. particular, new consequences propagated nominal nodes,550fiPay-As-You-Go Description Logic Reasoningnominal dependent nodes saturation graph could affectedconsidered incompletely handled. Hence, also satisfiability hinges statusnominal nodes node depends on.problem practice critical node nominal also makes nominaldependent nodes critical. Hence, easily get many critical nodes ontologiesuse nominals saturation cannot completely handle individuals. However,improve saturation graph initial consistency check tableau algorithm(see Section 5 details) replacing node labels critical nominal nodessaturation graph ones obtained completion graph. Althoughdistinguish deterministically non-deterministically derived concepts labels,know correspond clash-free fully expanded completion graph and,therefore, consider critical.Example 2. Consider TBoxes Example 1. start fully saturatedsaturation graph T1a (left-hand side Figure 1). Co -rule Table 3applicable, identifies nodes nominal dependent adds (iteratively), nodes completely handled saturation node criticaltight at-most restrictions.situation changes extension T1b T1a . Since B {a} L(vA ), neitherdisjunct is, vA identified critical (vA S! ) Ct -rule Table 4.nodes are, however, still completely handled saturation.Finally, consider extension T1c T1b (right-hand side Figure 1). C -ruleTable 3 adds vB since number merging candidates vB w.r.t.C 1, i.e., ]mcands(vB , s, C) = 1. used identify nodes critical use vB-successor merging s-successor vB potentially required.particular, concept .B L(vA ) problematic connects vB vAvia role s, 6 1 s.C L(vB ), ]mcands(vB , s, C) = 1. Hence, vA alreadyidentified critical due incompletely handled disjunction, C6-rule would add vAS! . Note, however, vB v{a} still completely handled saturation.3.3 Correctnessstraightforward see saturation rules Table 2 produce sound inferences.particular, saturation rules add concepts label nodealso added tableau algorithm equivalently labelled node completiongraph. termination saturation rules ensured since number nodesedges well size labels bounded number concepts, roles, sizeclosure concepts knowledge base. Furthermore, rules appliedadd new facts saturation graph. Analogously, application rulesTable 3 4 generation saturation status terminating, ruleapplication adds node corresponding set (either , , S! ) rulesapplicable node already belong corresponding set.remains show completeness, i.e., show node vD nodesrepresenting individuals neither critical clashed, build model knowledge base extension non-empty. Note direct transformationsaturation graph completion graph possible since reuse nodes551fiSteigmiller & Glimmsaturation graph possibly causes problems certain features SROIQ. example,two roles r stated disjoint super role r, saturation graphcontain node r- s-successor another node. However, principle,would possible rebuild completion graph recursively creating correspondingsuccessor nodes used nodes saturation graph would reach nominalnodes nodes would blocked.Given fully saturated saturation graph, nodes representing individualsneither critical clashed, show completeness non-critical node vD providinginterpretation = (I , ) model knowledge base non-emptyextension D, i.e., DI 6= interpretation witnesses satisfiability D.ease presentation, assume existentially quantified concepts form r.Cequivalently expressed > 1 r.C. w.l.o.g., since normalised knowledge bases containsimple roles.Since occurrence nominal {a} label node vC means node vCrepresents element v{a} , need one representative element,ensure defining suitable equivalence relation nodes saturation graph.Definition 13 (Canonical Saturation Model). saturation graph = (V, E, L), letfollowing relation: {(vC , vC ) | vC V } {(vC , v{a} ) | vC V, {a} L(vC ), L(v{a} ) =*L(vC )} lettransitive, reflexive, symmetric closure . Since relation*equivalence relation nodes V , use v[C] , vC V , denote**equivalence class vC. use relation(recursively) define elements. first define set Nom(S) = {v[{a}] | NI } nodes nominalslabels. non-nominal elements obtained unravelling partssaturation graph paths usual (Horrocks & Sattler, 2007). setPathsS (D) = {v[D] } Nom(S){p v[C]| p PathsS (D), > n r.C L(v), v tail(p), v[C]/ Nom(S), 1 n},)=v .denotes concatenation tail(v[C] ) = tail(p v[C][C]define interpretation = (I , ) follows:= PathsS (D),and, NI , setaI = v[{a}] ,NCAI = {p | v tail(p) L(v)},552fiPay-As-You-Go Description Logic Reasoningr NR> n s.C L(v)rI = {hp, qi PathsS (D) PathsS (D) | q = p v[C]v tail(p) n v r}{hq, pi PathsS (D) PathsS (D) | q = p v[C]> n inv(s).C L(v)v tail(p) n v r}{hp, xi PathsS (D) Nom(S) | v x v 0 tail(p)v r-successor v 0 }{hx, pi Nom(S) PathsS (D) | v x v 0 tail(p)v inv(r)-successor v 0 }{hp, pi PathsS (D) PathsS (D) | v tail(p)v r-neighbour }Note domain elements (paths of) equivalent classes ensureextension role r correctly contains edges derived saturation, use nodesequivalent class construction rI .order show |= K, first show that, every p , holds p CC L(v) v tail(p).Lemma 1. Let = (V, E, L) fully saturated saturation graph concept w.r.t.K vD well nodes representing individuals neither critical clashed.Furthermore, let = (I , ) denote interpretation constructed described Definition 13. p holds p C C L(v) v tail(p).Proof 1. observe nodes involved construction interpretationneither critical clashed. particular, node v tail(p) p clashed,v would descendant node v[D] node representing individual and, hence,would identified clashed -rule, contradicts assumptionnodes clashed. Analogously, v critical, v[D] node representingindividual would identified critical C -rule (which also contradictoryassumption). Hence, considering different types concepts provinglemma following, safe assume nodes used constructioninterpretation neither clashed critical and, hence, = .base case C = L(v) v tail(p) trivially holds pdefinition , i.e., p AI L(v) v tail(p). Also note = >Idue definition saturation algorithm (in particular due initialisationnodes) due fact never remove concepts labels saturation graph.base cases hold elements p v tail(p) C L(v) follows:C = {a}, observe p = v[{a}] due use equivalence classes,*definition, , , fact Coo -rule cannot identify v criticalassumption. Hence, p C .553fiSteigmiller & GlimmC = B, observe p/ B due definition factused nodes clashed saturation graph. Hence, p C .C = r.Self, observe node v r-successor dueapplication Self-rule. definition , hp, pi rI . Hence,p CI .C = r.Self, observe nodes saturation graph clashed.Hence, exclude loops caused last part definition sincenode would clashed due Condition 2 -rule. nominal nodesobserve nodes V nominal label representedone element . possibly introduces loops neighbouring nominal nodessaturation graph. is, however, excluded Condition 3 -rule. Hence,hp, pi/ rI and, therefore, p C .complex cases hold elements p v tail(p) C L(v)induction follows:C = C1 u C2 , application u-rule ensures L(v) {C1 , C2 }.induction, p C1I p C2I . Hence, p C .C = C1 C2 , observe must concept C 0 L(v) C 0{C1 , C2 } since Ct -rule would otherwise identified node v tail(p)critical, contradicts assumption. Hence, induction, p C 0Iand, consequence, p C .C = > n r.C 0 , observe saturation algorithm creates saturatesnode vC 0 r-successor v n 1 consider two cases: First,v[C 0 ] Nom(S), n = 1 since v would clashed n > 1 dueCondition 5 -rule, contradicts assumption. definitionPathsS (D), , , exists element q q Nom(S) hp, qirI . Furthermore, induction, q C 0I and, consequently, p C . Second,1 , . . . , p vnv[C/ Nom(S), construction PathsS (D), p v[C0]0][C 0 ] PathsS (D)and, definition , elements n r-successors p. Finally, induction,1 , . . . , p vn0I and, consequently, p C .p v[C0][C 0 ] CC = r.C 0 , observe application -rule guarantees inv(r)predecessors C 0 label. Furthermore, also r-successors C 0label, otherwise C -rule would identified v critical, contradictoryassumption. Hence, definition PathsS (D), , , induction,holds every r-neighbour element q q C 0I and, consequently, p C .C = 6 n r.C 0 , C6-rule guarantees every node v p n mergingcandidates, i.e., n r-successor nodes C 0 labels, otherwisenode would critical, contradicts assumption. Analogously, Cch -ruleguarantees every r-successor v either C 0 nnf(C 0 ) label.p = v[D] p 6 Nom(S), observe p predecessors and,554fiPay-As-You-Go Description Logic Reasoningdefinition PathsS (D), , , induction, n rneighbour elements q1 , . . . , qn q1 , . . . , qn C 0I since every r-neighbourelement q holds q nnf(C 0 )I and, therefore, q/ C 0I . Hence, p Cp = v[D] . p Nom(S), holds, every inv(r)-predecessor element q p,q/ C 0I due induction, definition PathsS (D), , , Co6-rule(otherwise node would identified critical). Hence, p C p Nom(S).. Moreover, Cp/ {v[D] } Nom(S), p = q v[D0]ch -rule guarantees00w tail(q) either C nnf(C ) label. induction definitionPathsS (D), , , either q C 0I q nnf(C 0 )I . considercases: First, q/ C 0I w tail(q) nnf(C 0 ) L(w),argue analogously case p = v[D] . Second, q C 0I w tail(q)C 0 L(w), guaranteed C6-rule v n 1 rsuccessors C labels and, definition PathsS (D), , ,n r-neighbour elements q1 , . . . , qn p holds inductionq1 , . . . , qn C 0I . Consequently, p C .using Lemma 1, show completeness, i.e., showconstructed interpretation satisfies axioms knowledge base:Lemma 2 (Completeness). Let = (V, E, L) fully saturated saturation graphconcept w.r.t. K vD well nodes representing individuals neither criticalclashed, exists interpretation = (I , ) |= K DI 6= .Proof 2. assume interpretation = (I , ) built Definition 13.Note due definition saturation algorithm, node vD VL(vD ), definition , v[D] and, definition tail , v[D]DI . Hence, DI 6= . observe satisfies every axiom normalisedknowledge base K (cf. Section 2.2) follows:= H v C H = {a}, H = A, H = >, observe that, every p*v tail(p), H H L(v) due definition, PathsS (D),, . Due applications v1 -rule, C L(v) H L(v),and, Lemma 1, p C p H . Hence, |= .= A1 u A2 v C, analogously observe that, every p v tail(p),*(A1 uA2 )I {A1 , A2 } L(v) due definition, PathsS (D), ,. Due applications v2 -rule, C L(v) {A1 , A2 } L(v),and, Lemma 1, p C p H . Hence, |= .= r v s, observe |= due definition successors/predecessorsdefinition PathsS (D), , .= Disj(r, s), assume contradiction elements p, qhp, qi rI sI . definition saturation graph edgesS, either q Nom(S) r v s. However, cases v tail(p) clashed dueCondition 6 Condition 7 -rule, respectively. Since contradictoryassumption v clashed, |= .555fiSteigmiller & GlimmSince satisfies, elements , every axiom K, |= K.language features completely supported presented saturationalgorithm fact r.C concepts left-hand side GCIstransformed universal restrictions right-hand side (with propagationspredecessors inverse roles used), one observe completeness presentedsaturation algorithm guaranteed least ELH knowledge bases.4. Supporting Tableau Algorithmssection, present range optimisations directly indirectly support reasoning tableau algorithms DL SROIQ. already mentioned, reasoning systemsexpressive DLs usually complex integrate many sophisticatedoptimisations necessary make reasoning many real-world ontologies practicable. consequence, important development new optimisationsconsider interaction already existing techniques. example, importantwell-known optimisation technique dependency directed backtracking allowsevaluating relevant non-deterministic alternatives tableau algorithm.typical realisation dependency directed backtracking backjumping every factadded completion graph labelled non-deterministic branchesfact depends (Baader et al., 2007; Tsarkov, Horrocks, & Patel-Schneider, 2007).clash discovered, jump back last non-deterministic decisionreferenced clashed facts completion graph and, consequently,evaluate non-deterministic alternatives clear would result clashes. Hence, new optimisation techniques manipulate completiongraphs must obviously also add dependencies correctly, otherwise dependency directedbacktracking cannot completely supported presence optimisations.optimisation techniques present section fully compatibledependency directed backtracking and, best knowledge, alsonegatively influence well-known optimisations. Moreover, since saturation optimisations allow lot reasoning work efficiently, often reduceeffort optimisation techniques. example, optimisations directly performmany simple expansions completion graph and, therefore, effort conventionalcaching methods often reduced. particular, tableau-based reasoning systems oftencache satisfiable node labels order block expansion successors identicallylabelled nodes subsequent completion graphs. reuse labels non-criticalnon-clashed nodes saturation graph, directly knowprocessing completion graph required them, even without checking whethercorresponding node labels satisfiability cache.4.1 Transfer Saturation Results Completion GraphsSince presented saturation method uses compatible data structures, directlytransfer saturation results completion graphs. improves tableau algorithmfaster clash detection optimises construction completion graph.example, directly use unsatisfiability information detected -rule556fiPay-As-You-Go Description Logic Reasoningsaturation. particular, application tableau expansion rule adds conceptC completion graph, check saturation status vC and, caseclashed, immediately initiate backtracking dependenciesunsatisfiable concept C completion graph. Analogously, utilise derivedconsequences form saturation. instance, expansion rule adds concept Clabel node completion graph, add concepts L(vC )label. course, order support dependency directed backtracking,also add correct dependencies. However, since concepts L(vC )deterministic consequences C, simply use deterministically depends Cevery additionally added concept L(vC ).nice side effect, addition derived concepts saturation improvesbacktracking processing disjunctions. Basically, t-rule saturationextracts shared (super-)concepts disjuncts disjunction. example,disjunction A1 A2 axioms A1 v B A2 v B, derive saturationL(vA1 A2 ) {A1 A2 , B}, i.e., B super-concept disjuncts adddeterministic consequence disjunction A1 A2 . Although still processdisjunction, add consequences (e.g., B) deterministically. Hence,backtracking identify processing alternatives disjunction relevantdeterministic consequences involved clash.transfer derived consequences directly add many consequences possiblehelpful several ways. First, application expansion rules tableau algorithmsmight become unnecessary. example, disjunct disjunction alreadyadded, necessary apply t-rule. Second, specific conceptslabel node, then, least expansion rules tableau algorithm, optimisedrule applications possible. instance, concepts r.C, r.D, 6 1 r.>label node, second application -rule tableaualgorithm directly add existentially restricted concept already present rsuccessor instead creating new one merged afterwards. Third, conceptspropagated back ancestor nodes, necessary check whether onemodified ancestor nodes blocked rules descendant nodes applied.Due transfer derived consequences, many concepts propagatedback successors already added and, therefore, amount blocking testssignificantly reduced. Last least, transfer derived consequences allowsblocking much earlier. Blocking node v usually possible node couldreplaced another non-blocked node completion graph influenceancestor v. simple blocking condition guarantees completenessexpressive DLs pairwise blocking. However, pairwise blocking refined achieveprecise blocking conditions possibly allow blocking earlier (Horrocks & Sattler,2001). Since many concepts propagated back successors addedtransfer derived consequences saturation, likely creationprocessing new successor nodes influence ancestor nodes. result, mightpossible block nodes even without creation processing many successors.Besides transfer derived consequences, cases also possible directlyblock processing successor nodes completion graph. this, nodecompletion graph, say v, labelled concepts node v 0557fiSteigmiller & Glimmsaturation graph v 0 must neither clashed, critical, nominal dependent.exists v 0 , processing successors v blocked since v couldexpanded way v 0 saturation graph. Obviously, enforcev 0 nominal dependent, dependent nominal could influencedcompletion graph new consequences propagated back v wouldconsidered processing successor nodes blocked. Furthermore, indeednecessary create successors blocking processing, maymerged ancestor node. However, saturation node v 0tight at-most restriction, i.e., at-most cardinality restriction 6 r.C L(v 0 ), v 01 r-successors nnf(C) label, also creationsuccessor nodes blocked, every at-most cardinality restriction labelnode allows least one additional neighbour nodesmerged. Since nodes easily large number successors (e.g., due at-leastcardinality restrictions big cardinalities), blocking creation new successorssignificant improvement terms memory consumption building timecompletion graph. course, new concepts propagated v label vdiffers v 0 , blocking becomes invalid processing successorsreactivated find another compatible blocker node.4.2 Subsumer Extractiontableau-based reasoning systems, many higher level reasoning task often reducedconsistency checking. example, naive classification algorithm tests satisfiability classes checks pairwise subsumption relationsclasses (which also reduced satisfiability/consistency tests) order buildclass hierarchy ontology. practice, number required satisfiability testssignificantly reduced optimised classification approaches enhanced traversal(Baader et al., 1994) known/possible set classification (Glimm et al., 2012). optimised classification algorithms use specific testing orders exploit informationextracted constructed models. optimise testing order, algorithmsusually initialised told subsumptions, i.e., subsumption relationssyntactically extracted ontology axioms, and, typically, told subsumersextracted, larger benefit classification algorithms. However,detailed extraction told subsumers ontology axioms usually less efficientsimple one. instance, ontology axioms A1 v r.C u r.C v A2 implyA2 subsumer A1 , detected, parts axioms comparedother.saturation, significantly improve told subsumers initialisation tableau-based classification algorithm since also (some) semantic consequencesconsidered. new accurate told subsumers, simply use,concept classified, (atomic) concepts L(vA ). Moreover, vAclashed, know unsatisfiable without performing satisfiability test.Analogously, vA neither clashed critical knowledge base consistent,know satisfiable L(vA ) contains subsumers. Note vA nominaldependent representative node nominal critical, also vA identified558fiPay-As-You-Go Description Logic Reasoningcritical. Hence, extraction subsumers, consider criticalitystatus considered node, whereas nominal dependency matter. nodeontology critical, already get subsumers saturation and, therefore,transitive reduction (i.e., elimination subsumptions indirectlyimplied transitivity property subsumption relation) necessary buildclass hierarchy. Thus, preceding saturation automatically get one-passclassification simple ontologies.Note completeness proof Section 3.3 principally covers satisfiabilityconcepts. However, quite obvious presented saturation approach also computes subsumers nodes neither critical clashed. particular, assumesubsumption v B derived saturation follows knowledgebase K, obtain contradiction considering saturation knowledge baseK0 extends K axiom B v . Since B v added v1 -ruleB node label K0 differs K axiom B v , saturationwould derive consequences and, hence, would incomplete w.r.t. testingsatisfiability A, contradictory w.r.t. assumption completeness proof.4.3 Model MergingMany ontologies contain axioms form C D, seen abbreviationC v v C. described Section 2.2, utilise get normalisedknowledge base consider axioms. Treating axiomsform atomic concept v v can, however, downgradeperformance tableau algorithms since absorption might apply v A, i.e.,axiom internalised > v nnf(D A). avoid this, many implementedtableau algorithms explicitly support axioms additional unfolding rule,concept label node unfolded nnf(D) (exploitingv equivalent v nnf(D)) (Horrocks & Tobies, 2000).2 Unfortunately, usingunfolding rule also comes price since tableau algorithm longer forcedadd either nnf(D) node completion graph, i.e., might knownodes whether represent instances A. means cannotexclude possible subsumer (atomic) concepts nodes completion graphscontain (and also A), important optimisation classificationprocedures (Glimm et al., 2012).compensate this, create candidate concept A+ A, examplepartially absorbing (Steigmiller et al., 2014b), automatically addednode label completion graph node possibly instance A, i.e., candidateconcepts indicate completely defined concepts possibly satisfied. Hence, A+added node label, know (possible) subsumerconcepts label node (even allow knowledge base contain conceptequivalence axioms form D). Formally, define requirementscandidate concepts follows:2. Note works long axioms form v D0 , u A0 v D0 ,A0 u v D0 , D0 D0 6= knowledge base.559fiSteigmiller & GlimmDefinition 14 (Candidate Concept). Let K knowledge base containing completedefinition form D. say A+ candidate concept every fully) (fully saturated saturation graphexpanded clash-free completion graph G = (V, E, L, 6=+= (V, E, L)), holds L(v) K |= C1 u. . .uCn v A, {C1 , . . . , Cn } = L(v)({C1 , . . . , Cn } = L(v) v well nodes representing individuals neither criticalclashed).course, axioms form > v A+ , enforce A+ added nodelabels and, hence, represents valid candidate concept A. useful practice,is, however, desired concepts added node labels possible (withoutintroducing additional overhead) and, therefore, reasoners usually employ sophisticatedabsorption techniques generate better candidate concepts (Steigmiller et al., 2014b).consequence, handy identification non-subsumptions illustratedfollowing example.Example 3. Let us assume TBox T2 consists axiomsA1 v r.BA2 v s.B u (r. B)A3 s.B u r.B,interested classification T2 . order get (automatic) indicationconcepts could subsumed completely defined concept A3 , create candidateconcept A3 (partially) absorbing negation A3 definition. Hence, partiallyabsorbing s.B r.B B v .A+3 (the part r.B cannot absorbed trivially),+obtain candidate concept A3 A3 . Note absorption adds B v .A+3labelindicatesT2 without removing rewriting axioms. Now, absence A+3A3 subsumer concepts label, used classification.particular, saturate A1 , A2 , A3 , B, .A+3 added labelpropagatedrepresentativenodes A2 A3 .representative node B A+3particular, since label representative node A1 contain A+3 , knowA1 v A3 hold without special consideration axiom A3 s.B ur.B.However, still determine whether A2 satisfiable conceptssubsumers A2 complete classification T2 . this, (have to) fall backtableau algorithm and, principle, perform satisfiability test A2subsumption test possible subsumer A2 , i.e., (atomic) concepts(possibly non-deterministically) added root node satisfiability test,checks whether actual subsumers models.Although candidate concepts already allow significant pruning subsumptiontests, still ontologies candidate concepts added many nodelabels, especially limited absorption axiom formpossible. Hence, still possible subsumer many concepts.saturation graph can, however, used improve identification (moreless obvious) non-subsumptions. Basically, candidate concept A+label node v completion graph, test whether merging vsaturated node vnnf(D) possible. Since often conjunction, also try mergev representative node disjunct nnf(D). models mergeddefined below, v obviously instance A.560fiPay-As-You-Go Description Logic ReasoningDefinition 15 (Model Merging). Let = (V, E, L) fully saturated saturation graph) fully expanded clash-free completion graph knowledgeG = (V 0 , E 0 , L0 , 6=base K. node v V mergeable node v 0 V 0v critical, nominal dependent, clashed;L(v) L0 (v 0 ) contain {C, nnf(C)} concept C;L(v) L0 (v 0 ) contain concepts A1 A2 A1 u A2 v C KC/ (L(v) L0 (v 0 ));v 0 r-neighbour v 0 concept r.Self L(v);v r-neighbour v concept r.Self L0 (v 0 );C L0 (w0 ) every r-neighbour w0 v 0 r.C L(v);C L(w) every r-successor w v r.C L0 (v 0 );nnf(C) L0 (w0 ) every r-neighbour w0 v 0 6 r.C L(v);nnf(C) L(w) every r-successor w v 6 r.C L0 (v 0 ).Note conditions designed checked efficientlyclear conditions relaxed further. instance, necessaryenforce v nominal dependent. principle, ensureinteraction generated completion graph, can, example, alsoguaranteed concept tested satisfiability use nominals completiongraph. addition, model merging fails due concepts completion graphinteraction tested node saturation graph, simply extendsaturation graph new node, also problematic concepts considered,retest model merging node. instance, node v 0 completiongraph mergeable node v saturation graph due axiom A1 u A2 v Cknowledge base A1 L0 (v 0 ), A2 L(v), C/ (L0 (v 0 ) L(v)),saturate new node w L(w) L(v) {C} check whether w mergeable.contrast, concepts tested node saturation graph interactcompletion graph, often easily possible extend model merging approachnon-subsumption guaranteed. particular, interestedmodifying completion graph since also used model merging tests.addition, recursive model merging test, check whether neighboursnode completion graph mergeable propagated concepts saturationgraph, non-trivial since exclude interactions already tested nodes.example, node v 0 completion graph mergeable node vsaturation graph due r-neighbour w0 v 0 concept r.C label vC/ L(w0 ), recursive model merging could test whether w0 mergeablevC . However, would also necessary guarantee merging w0 vCcause new consequences propagated back v 0 , especially non-trivialseveral universal restrictions label v would affect w0 .561fiSteigmiller & GlimmExample 4. continue classification TBox T2 Example 3, (have to)build completion graph A2 tableau algorithm, straightforward.particular, directly see A2 satisfiable A3 possible subsumerA2 (since candidate concept A+3 propagated root node A2 existentially restricted s-successor B label). apply model merging, saturationdifferent alternatives/disjuncts correspond A3 required, i.e., assumeconcepts s.B r.B also saturated, trivial since newconsequences implied created referred nodes completely handledsaturation. tableau algorithm added disjunct r. satisfy r. B,model merging fails since vs.B interaction r-successorcompletion graph constructed satisfy s.B vr.B interactionr. obviously excluded. Hence, would required test whether A3subsumer A2 checking satisfiability A2 u A3 . contrast, Badded, none model merging conditions satisfied vr.B and, therefore,directly conclude A3 subsumer A2 .Note, although proposed (pseudo) model merging techniques (Haarslev, Moller,& Turhan, 2001) work, principle, similar way, also significantdifferences. example, presented merging test applied corresponding candidate concepts label nodes, already reduces number tests.addition, test merging nodes saturation graph and, therefore,significant overhead creating appropriate (pseudo) models. contrast,approaches often necessary build separate completion graphsconcepts model merging applied. Moreover, presented approachalso applicable expressive DLs SROIQ, whereas approaches oftendeactivate model merging certain language features used (e.g., nominals). course,expressive DLs may produce critical nodes and, therefore, potentially reducemodel merging possibilities, necessary completely deactivate it,results good pay-as-you-go behaviour.5. Saturation ImprovementsObviously, support tableau algorithm saturation works betternodes possible marked critical. However, since saturation procedurecompletely support language features, easily get critical nodes evenunsupported language features rarely used knowledge base.especially problematic critical nodes referenced many nodes, wherebyalso considered critical. following, present different approachessaturation improved number critical nodesreduced. result, better support tableau algorithm possible.5.1 Supporting Expressive Language Featuresknown literature, saturation procedures extended expressiveHorn DLs, e.g., Horn-SHIQ (Kazakov, 2009) even Horn-SROIQ (Ortiz, Rudolph, &Simkus, 2010). Although shown extensions efficient562fiPay-As-You-Go Description Logic Reasoningontologies fragments, completely clear perform ontologiesuse language features outside fragments, example, usedpartially saturate ontologies approach. particular, worst-case complexityprocedures polynomial and, therefore, easily cause constructionlarge saturation graphs corresponding large memory requirements. However,practical implementations, simply limit number nodes processedsaturation directly marking remaining nodes critical. Hence, easilysupport features Horn-languages without risking memory consumptionincreased much without gaining benefits.particular, interesting relax restriction concepts propagated predecessor nodes universal restrictions form r.C. requiredsaturation procedure presented Section 3 enable reuse nodes,extended full support universal restrictions possible. course,allowed directly modify existing r-successors, easily create saturate copiesexisting r-successors extend propagated concept C. addition,remove edges previous r-successors incompleteness detection ruleC concept r.C mark node critical, obviously casenewly connected r-successors include concept C completely handled.Note copies extensions nodes realised efficiently. Basically,first apply default saturation rules and, afterwards, extend successorssaturation already added concept C. addition, use,successor node extended, mapping concepts, nodeextended, copied extended nodes, whereby reuse already creatednode extensions. Thus, several predecessors propagate conceptssuccessors, create node corresponding extension once.seen (efficient) implementation so-called node contexts, serve basismany saturation procedures fully handle universal restrictions (Simanck et al.,2011, 2014; Bate et al., 2015). particular, extension mapping, i.e., mappingnodes copies nodes extended additional concepts, seenrepresentation node contexts. example, node vA r-successorv r.B L(v), create copy node vA , say vA,B , B addedused r-successor v instead vA . extension mapping,also store extension vA B found node vA,Breuse it. Note, however, create copy B already labelvA . Moreover, directly copying nodes (with derived consequences), repetitionmany rule applications necessary.Support at-most restrictions form 6 1r.> achieved analogously.labels corresponding r-successors easily merged new node,used replace r-successors. Again, use mapping mergingcertain successors always results (possibly new) node. remainingr-successor v 0 also merged predecessor v 00 node v, addconcepts label v 0 label v 00 make v also inv(r)-successorv 00 . Thus, Horn-SHIF (almost) completely supported rather small extensionspresented saturation procedure.563fiSteigmiller & Glimmdifficult support nominals. Already complete nominal supportDL EL++ would potentially introduce significant overhead. particular, wouldnecessary store, every node v every nominal {a}, descendants v usingnominal {a}, i.e., descendant v nominal {a} label, wouldstore v nominal {a} used descendant. would find node v,stored nominal {a} used several descendant nodes, say v 1 , . . . , v n ,would create new node u labels v 1 , . . . , v n merged,would reproduce paths predecessors merged nodes vpotentially new consequences also propagated v. However, sincemajority EL ontologies use nominals much simpler ways (e.g., conceptsform r.{a}) presented saturation procedure already sufficient,sophisticated nominal handling currently seem required.Saturation procedures extended non-Horn DLs, instance, saturation procedures proposed DLs ALCH (Simanck et al., 2011), ALCI(Simanck et al., 2014), even SHIQ (Bate et al., 2015). this, alsohandle non-determinism is, example, caused disjunctions, typicallyrealised simply considering/saturating non-deterministic alternatives.concepts derived alternatives, interpreted actual consequencesknowledge base. number alternatives large, (naive)saturation approach might become impractical. Although also tableau algorithmconsider alternatives worst-case, successively, i.e., tradingmemory requirements potentially increased runtime. Moreover, tableau algorithms usually implement large amount optimisations reduce non-deterministicalternatives considered. notably, dependency directed backtrackingallows evaluating alternatives non-deterministic decisions indeedrelevant, i.e., involved creation clashes. Since saturation algorithmstrack dependencies derived facts, ability determine alternativesnon-deterministic decisions considered (since would resultclashes) limited. Unfortunately, tracking dependency information makessimple reuse nodes (which foundation saturation procedures) impossible or,least, much involved.Although shown saturation procedures extended non-deterministiclanguage features work well range ontologies (Simanck et al., 2011),investigations required order understand whether (or cases)better tableau algorithms expressive DLs. However, developmentimplementation saturation-based reasoning systems expressive DLs seemschallenging and, best knowledge, saturation-based procedure/reasonerexpressive DLs SROIQ yet exist. Hence, interesting compromise, presented paper, keep (basic) saturation algorithm deterministicprocess remaining parts tableau algorithm, typically coupledseveral well-established optimisations (e.g., semantic branching, Boolean constraintpropagation, dependency directed backtracking, unsatisfiability caching) handle nondeterminism. Alternatively, one process non-deterministic language featuressaturation procedure long certain limits reached (e.g., memory limit564fiPay-As-You-Go Description Logic ReasoningL(vA2 ) =L(vA1 ) =>, A1 , s.A2vA1vA2rvA3L(v{a} ) =>, {a}, B, .Bv{a}L(v{b} ) =>, A2 , s.{b}, r.A3 , A1 A3rv{b}L(vA3 ) =>, A3 , s.{c}rv{c}L(v{c} ) =>, {b}, r.{a}, r.{c}, 6 1r.>>, {c}Figure 2: Incompletely handled saturation graph testing satisfiability conceptA1 Example 5upper bound number saturated, non-deterministic alternatives), simplymark remaining nodes critical processed tableau algorithm.5.2 Improving Saturation Results Completion Graphsalready mentioned, even one node individual critical,presented saturation procedure also marks nominal dependent nodes critical.easily limits improvement saturation ontologies intensively usenominals. Analogously, nodes incompletely handled concepts (e.g.,disjunctions) nodes referenced many nodes,nodes also critical although necessarily concepts labelcannot handled completely. issues also illustrated following example:Example 5. Let us assume TBox T3 contains following axioms:A1 v s.A2A3 v s.{c}{a} v BA2 v s.{b}A2 v r.A3A2 v A1 A3{b} v r.{c}{b} v 6 1r.>B v .B{b} v r.{a}testing satisfiability concept A1 w.r.t. TBox T3 , generate saturationgraph depicted Figure 2. Note, node v{b} individual b cannotcompletely handled saturation due concept 6 1r.> label v{b} ,would require v{a} v{c} merged. Therefore, v{b} critical alsoconsider nodes critical refer critical nodes, is, example,case node vA2 . Moreover, since one node individual critical, cannotexclude consequences propagated individuals and, therefore, possiblyalso nominal dependent nodes. instance, merging v{a} v{c} wouldpropagate concept B label vA3 . Thus, also vA3 critical althoughdirectly contain concept cannot handled saturation. Analogously,label vA2 contains disjunction A1 A3 , also completely processed565fiSteigmiller & Glimmsaturation and, therefore, mark ancestor nodes vA2 critical (ifalready case), even contain problematic concepts. consequence,obtain saturation status = (So , , S! ), v{b} tight at-most restriction,i.e., = {v{b} }, nodes nominal dependent well critical, i.e., = S! ={v{a} , v{b} , v{c} , vA1 , vA2 , vA3 }.course, saturation extended several ways better support featuresexpressive DLs (see Section 5.1), but, best knowledge, existssaturation algorithm completely covers features expressive DLsSROIQ. Hence, knowledge base uses unsupported features, easilyrun problem saturation becomes incomplete possibly get manycritical nodes.approach overcome issues critical nodes patch, i.e., update,saturation graph results fully expanded clash-free completion graphsgenerated consistency satisfiability checks. Roughly speaking, ideareplace labels critical nodes saturation graph corresponding labelscompletion graphs, know completely handled tableaualgorithm. call nodes patched nodes. Then, apply saturation rulesupdate saturation status, hopefully results improved saturation graphfewer critical nodes. Note, however, simply adding non-deterministically derivedconcepts labels completion graphs saturation easily leads unsound results.Hence, distinguish deterministically non-deterministically derived conceptsupdating saturation simultaneously managing two saturation graphs: onedeterministically derived concepts added, i.e., deterministic saturation graph,second one, also non-deterministically derived concepts consequencesconsidered, i.e., non-deterministic saturation graph. non-deterministicconsequences locally limited influence, i.e., non-deterministically addedconcepts propagate new consequences limited number ancestor nodes, then,comparing saturation graphs, possibly identify ancestor nodesinfluenced, considered non-critical. reducingnumber critical nodes saturation, approach allows improvingconstruction new completion graphs transferring new resultsupdated saturation.order describe approach detail, first define saturation patch,constitutes data structure managing information necessaryupdating saturation graph.Definition 16 (Saturation Patch). Let fclos(K) (Rols(K)) denote concepts (roles)possibly occur completion graphs knowledge base K defined Definition 5.saturation patch P saturation graph = (V, E, L) w.r.t. K tuple P = (Vp , Ld , Ln ,Mc , Vo ),Vp V denotes set patched nodes saturation graph,Ld : Vp 2fclos(K) mapping patched nodes set deterministically derivedconcepts,566fiPay-As-You-Go Description Logic ReasoningLn : Vp 2fclos(K) analogously mapping patched nodes set nondeterministically derived concepts,Mc : Vp Rols(K) fclos(K) IN0 mapping at-most cardinality restrictionsform 6 r.C patched nodes (represented tuple node v, roler, qualification concept C) number merging candidates,Vo Vp denotes patched nodes nominal dependent.saturation patch obviously identify nodes patched/updated,realised set Vp . node Vp , mappings Ld Ln containconcepts nodes label completion graph derived deterministicallynon-deterministically, respectively. Hence, mappings determine nodeslabel saturation graph extended longer critical. alsostore number merging candidates (Mc ) patched nodesnominal dependent (Vo ) information required generation updatedsaturation status. Note consider number merging candidates nominaldependencies non-deterministic information since often possible correctlyextract corresponding deterministic information completion graphs. example,state-of-the-art reasoners usually searching blocker nodes checking detailedconditions defined pairwise blocking, whereby node possibly also blockedlabel subset label blocker node (Horrocks & Sattler, 2001).blocker node directly indirectly using nominals, i.e., nominal dependent, alsoblocked node considered nominal dependent. Hence, considernominal dependency non-deterministic information since nominal dependencycould caused concept label blocker node labelblocked one.Especially root nodes completion graphs constructed satisfiability consistency tests suitable extraction patches. instance, fully expandedclash-free completion graph testing satisfiability concept C, root nodeC label used patch node vC saturation graph.completion graph consistency check used patch representative nodes nominals. course, patching nominal dependent nodes, ensure kindconsistency, i.e., dependent nominals compatible representativenodes nominals saturation graph already applied patchesnodes. simple form compatibility defined follows:Definition 17 (Saturation Patch Compatibility). Let P 1 = (Vp1 , L1d , L1n , Mc1 , Vo1 ), . . . , P n =(Vpn , Lnd , Lnn , Mcn , Von ) saturation patches saturation graph w.r.t. knowledge base} 1 n. say P 1 , . . . , P n compatibleK, Vpi = {v1i , . . . , vm) built Kfully expanded clash-free completion graph G = (V, E, L, 6=11nncontains nodes w1 , . . . wm1 , . . . , w1 , . . . wmn L(wji ) = Lid (vji ) Lin (vji )1 j mi 1 n.principle, limited root nominal nodes extractionpatches, detailed analysis completion graph required nodes.example, tableau algorithm apply -rule concept r.C567fiSteigmiller & Glimmlabel node v v already r -predecessor v 0 C label. Hence,predecessor v 0 directly indirectly uses nominals, also v considerednominal dependent. Moreover, nodes completion graph, oftenclear concepts considered non-deterministically derived consequences.instance, create, concepts r.C r.D label node v,r-successor v 0 extract patch vC v 0 , identifiednon-deterministically derived concept. this, principle necessary trackanalyse dependencies facts causes completion graph.efficiently supported reasoning system, extraction patches alsoextended nodes completion graph. Otherwise, patch creation simplyrestricted appropriate.saturation patches applied saturation graph follows:Definition 18 (Saturation Patch Application). Let = (V, E, L) saturation graphP = (Vp , Ld , Ln , Mc , Vo ) saturation patch S. deterministic (non-deterministic)application P yields deterministically (non-deterministically) extended saturationgraph Sd (Sn ) obtained saturating saturation graph (V, E, L0 ),L0 = {v 7 L(v) | v V \ Vp } {v 7 Ld (v) | v Vp } (L0 = {v 7 L(v) | v V \ Vp } {v 7Ld (v) Ln (v) | v Vp }).Since interested deterministic non-deterministic saturation graph,create copy saturation graph soon patch non-deterministicallyderived concepts and, then, use non-deterministic application patchescopy. Although also fully saturate non-deterministic saturation graph simplyusing presented saturate function, potentially derives unwanted consequences sinceapplication saturation rules nodes possibly propagates new consequencespatched nodes. unfavourable patched consequences derivedprocessing different non-deterministic alternatives. particular, node vancestor v patched, saturation rules might propagate new consequencesobtained patching v ancestors. ancestor is, however, patchedconcepts another completion graph, different non-deterministic alternativesprocessed, possibly mix consequences different alternatives saturationgraph, easily limits effectiveness approach. example, v containsdisjunction r.A r.A, patch v non-deterministic extension r.A,patching r -predecessor v 0 v non-deterministic extension allowsapplication -rule concept r.A label node vconcept propagated v 0 . consequence, would infer saturationv 0 (possibly) clashed since label. Since (new) consequencesnon-deterministic saturation graph considered non-deterministic,produce incorrect results. order to, nevertheless, avoid derivation unwantedconsequences, saturate non-deterministic saturation graph containspatched nodes V modified saturate\V (S) function, -rule appliednodes V -rule modified propagate conceptsnode v V . (and precise detection saturation status), gatherpatches one combined patch keep patch addition deterministic568fiPay-As-You-Go Description Logic Reasoningnon-deterministic saturation graph. patches straightforwardly combinedusing -operator defined follows:Definition 19 (Saturation Patch Composition). Given two saturation patches P P 0P = (Vp , Ld , Ln , Mc , Vo ) P 0 = (Vp0 , Ld 0 , Ln 0 , Mc0 , Vo0 ), saturation patch P P 0defined tuple consistingVp Vp0 ,Ld {v 7 C | v 7 C Ld 0 v/ Vp },/ Vp },Ln {v 7 C | v 7 C Ln 0 vMc {hv, s, Ci 7 n | hv, s, Ci 7 n Mc0 v/ Vp },Vo (Vo0 \ Vp ).Note patches contain information node, keepinformation node one (the new) patch instead mixing information.Thus, information patch gets lost common nodes, is,however, problematic since patches describe valid extensions.addition modified saturation function, reprocess ancestorspatched nodes non-deterministic saturation graph patching removes previouslyadded non-deterministic consequences order avoid mixing consequencesdifferent non-deterministic alternatives. example, non-deterministically derivedconcept r.C added propagated node label removed patchingnode, r -predecessor also rebuilt deterministic saturationgraph unnecessary non-deterministic consequences (e.g., C) also removed.practical implementations, obviously limit number ancestor nodesupdated processed new non-deterministic consequences non-deterministicsaturation graph order limit overhead patch application. limitreached, remaining ancestors simply marked critical. Also notereuse data deterministic saturation graph non-deterministic onenodes influenced patch non-deterministic consequences.order able use patched saturation graphs support tableaualgorithm, e.g., transfer results completion graphs, updatesaturation statuses application patches. Similarly rule applicationnon-deterministic saturation graph, want propagate status patchednode successors. Therefore, analogously use modified status\V functioninstead status, rules Table 3 4 applied nodesV . also requires use modified ]mcands0 function status\V since,patched nodes, use correct information given patch.precise, Mc denotes mapping number merging candidatesconsidered patch, ]mcands0 (v, s, D) return Mc (hv, s, Di) v patched node,]mcands(v, s, D) otherwise. addition, correctly initialise sets ,, S! patched nodes information applied patches.non-deterministic saturation graph, patched nodes obviously non-critical sincelabels extracted fully expanded clash-free completion graphs. Hence,569fiSteigmiller & Glimminitialise (combined) patch P = (Vp , Ld , Ln , Mc , Vo ),realised setting = {v | v Vo },= {v | v Vp 6 r.C (Ld (v) Ln (v)) Mc (hv, r, Ci) = m}.deterministic saturation graph, additionally set S! {v | Ln (v) 6= }order mark patched nodes directly critical could depend non-deterministicconsequences. initialisation, call function status\Vp obtain fullstatus corresponding saturation graph, used improvesupport tableau algorithm.Analogously deterministic non-deterministic saturation graphs, every newsaturation status incrementally updated last generated status lastsaturation graphs sequentially updating ancestors newly patched nodes.Hence, also generation new saturation statuses causing significant overheadpractice.patching saturation graphs enables sophisticated support tableau algorithms. one hand, patching reduces number critical nodes and, therefore,optimisations described Section 4, blocking expansion successors nodescompletion graph extraction subsumers, better applicable.hand, also use non-deterministic saturation graph support,e.g., classification process. node vA non-deterministic saturation graphcritical, label vA non-deterministic saturation graph describespossible subsumers A. Thus, vA critical non-deterministic saturationgraph, label used prune possible subsumers. Moreover, usenon-deterministic saturation graph find identical labels used blockingprocessing/expansion successors nodes completion graph. course, stillrequire corresponding nodes (non-deterministic) saturation graphcritical. contrast, restriction nodes saturation graph allowednominal dependent blocking relaxed works sufficiently wellmany real world ontologies. Basically, patch nodes represent individualssaturation graph consistency check corresponding nodesobtained fully expanded clash-free completion graph. Furthermore, ensure,one hand, subsequent saturation patch compatible initial patch, i.e.,create patches nominal dependent nodes labels nodesindividuals completion graph identical subsets corresponding labelsinitial completion graph consistency check. hand, createpatches nodes depend new nominals, i.e., nominals introducedNN-rule. ensures nodes saturation graphs used blockinglong expand nodes individuals way initial completion graph. Thus, nominal dependent nodes used blocking, collect blockednodes queue reactive nodes becomes necessary expand nodesindividuals another way completion graph initial consistencycheck. course, exact tracking dependent nominals, e.g., exactlysaving nominals node possibly depends, refine improve technique significantly. Obviously, use node blocking exactly knownnominals depends, reactivate processing node570fiPay-As-You-Go Description Logic Reasoningnodes corresponding individuals expanded differently. Although approachkeeps patching saturation graphs consistent, i.e., compatibility patchesautomatically ensured, restrictive required Definition 17. However,allows identifying potential incompatibilities techniques tableau-basedreasoning systems, e.g., variants completion graph caching techniques (Steigmiller,Glimm, & Liebig, 2015).Due non-deterministic decisions tableau algorithm, critical nodesaturation graph patched several ways. Moreover, patch alreadypatched node (hopefully) improve non-deterministic saturation graph, i.e., tryreduce number nodes influenced non-deterministic consequencesand/or marked critical. Thus, need strategy decides nodesextract patches fully expanded clash-free completion graphnon-deterministic saturation graph improved. already described,extract patches nodes information safely extractedmake non-deterministic saturation graph inconsistent. addition, strategykeep number patches small possible since update datastructures every patch.simple example strategy create patches reducenumber non-deterministic propagation concepts patched nodes. strategywould prefer patch adds non-deterministic set concepts {r.C, A1 , A2 }comparison patch non-deterministic extension {s.D, t.D}.strategy ensures, least, create arbitrary patches, avoids oscillationdifferent possibilities, clearly favour creation patchesinfluence nodes. However, cannot guarantee non-deterministic saturationgraph actually improved. example, concept r.C could propagate C severalpredecessors also processing C could influence many ancestors, whereaspatch {s.D, t.D} might influence predecessors. Therefore, nodealready patched {s.D, t.D} create new patch {r.C, A1 , A2 } duefewer propagation concepts, even worsen non-deterministic saturation graph.order counteract this, also extract patches saturation graphdetect critical node deterministic saturation graph labelledconcepts non-deterministic saturation graph node non-deterministicsaturation graph critical. kind internal patch ensuresaturation identified node neither critical influenced non-deterministicconsequences, remember solved state node overwritestate integrating patches non-deterministic saturation graph. course,strategy creation extraction patches optimally also considers nominaldependency tight at-most restrictions trying reduce number nodes.Example 6. mentioned, nodes saturation graph Figure 2, generatedtesting satisfiability concept A1 w.r.t. TBox T3 (p. 564), critical.consequence, check satisfiability A1 tableau algorithm detail.this, first check consistency individuals a, b, c, results simplecompletion graph, nodes c merged. completion graph,extract initial saturation patch P 1 individuals, i.e., P 1 = (Vp1 , Ld 1 , Ln 1 , Mc1 , Vo1 )571fiSteigmiller & GlimmVp1 = {v{a} , v{b} , v{c} }, Ld 1 = {v{a} 7 {>, {a}, {c}, B, .B}, v{c} 7 {>, {a}, {c}, B,.B}, v{b} 7 {>, {b}, r.{a}, r.{c}, 6 1 r.>}}, Ln 1 = , Mc1 = {hv{b} , r, >i 7 1},Vo1 = {v{a} , v{b} , v{c} }. Note, although nodes individuals c mergedcompletion graph, patch v{a} v{c} separately since saturationsupport merging nodes. Also note completion graph consistencycheck deterministic and, therefore, mapping nodes non-deterministically derivedconcepts required, i.e., node mapped Ln 1 . However, easepresentation, omit uninteresting patch data simply use Ln 1 .deterministically applying P 1 initial saturation graph, obtain new deterministic saturation graph, nodes extended data applied patch.particular, v{c} extended concepts {a}, B, .B deterministic saturation graph, whereby concept B also propagated vA3 and, consequence,label vA3 extended set {>, A3 , s.{c}, B, .B}. saturation statusnew deterministic saturation graph reveals nodes v{a} , v{b} , v{c} , vA3critical. Thus, have, principle, already shown satisfiability concept A3 .contrast, vA1 still indirectly critical due incompletely handled disjunction A1 A3label vA2 .order test satisfiability A1 tableau algorithm, initialisenew completion graph node v concept A1 asserted. Sincedisjunction A1 A3 added completion graph s-successor v 0 v,tableau algorithm choose disjuncts A1 A3 . Independentlydecision, obtain fully expanded clash-free completion graph showssatisfiability A1 , non-deterministic decision influences patchingsaturation graph. example, non-deterministically adding A3 v 0 , tableau algorithm add s-edge node representing c due A3 v s.{c} T3B propagated label v 0 and, subsequently, also label v dueB v .B T3 since node c B label. Thus, extractpatch P 2 = ({vA1 }, {vA1 7 {>, A1 , s.A2 }}, {vA1 7 {B, .B}}, , {vA1 }). Since P 2 contains non-deterministically derived consequences, apply patch deterministicallynon-deterministically. Although node vA1 considered fully handled nondeterministic saturation graph, remains critical deterministic saturation graph and,therefore, usage supporting (e.g., blocking expansion successor nodes newcompletion graphs, identification (possible) subsumers) tableau algorithm limited.contrast, disjunct A1 non-deterministically added v 0 , could extractsaturation patch P 3 = ({vA1 }, {vA1 7 {>, A1 , s.A2 }}, , , {vA1 }) applying P 3 ,could also consider node vA1 non-critical deterministic saturation graph.Hence, prefer saturation patch P 3 would also extract apply P 3 , evenextracted applied P 2 earlier constructed completion graph.now, considered patching fully expanded clash-free completiongraphs. course, also possible integrate unsatisfiability results completiongraphs saturation graphs. particular, tableau algorithm cannot findfully expanded clash-free completion graph concept C, create patchdeterministically extend vC concept . management unsatisfiable572fiPay-As-You-Go Description Logic Reasoningconcepts saturation graph benefit also propagated nodesimmediately identify many unsatisfiable concepts.also worth pointing that, especially extraction applicationpatches, support tableau algorithm information providedsaturation graphs seen intelligent caching technique. Although corresponds limited caching certain nodes influenced predecessors,also works, extent, nominals inverse roles. Moreover, fastautomatically propagate unsatisfiability satisfiability statuses concepts.6. Related Workalready approaches combine reasoning techniques fully-fledgedDL reasoners specialised procedures specific fragments. instance, reasoningsystem (Armas Romero et al., 2012) uses module extraction identify partontology completely handled efficient reasoning systemfully-fledged reasoner used remaining parts ontology. Note,approach works opposite direction: apply saturation simplyignore (or partially process) unsupported features and, then, detect partscompletely handled. Since uses reasoners black-boxes, is, principle,possible combine arbitrary reasoning procedures adapting module extraction.However, now, fully-fledged OWL 2 reasoners based variants tableaucalculi efficient reasoning systems interesting fragments usually using variantssaturation procedures (e.g., completion- consequence-based reasoning), wherebycombination tableau saturation algorithms currently seems interestingone.Due black-box approach, technique realised flexible.example, easily possible exchange fully-fledged reasoner reasoning systemknown works best certain kinds ontologies. approach,hand, implemented one single reasoning system requiressupport certain techniques, binary absorption, work well. Moreover, compatibledata structures used kinds procedures, usually meansappropriate saturation algorithm integrated tableau-based reasoning system.approach, however, also various advantages. example, saturation usesrepresentation ontologies tableau algorithms and, therefore, ontologyloaded once. contrast, reasoners used separately loadontology (or parts thereof) since used black-boxes and, usually, alsocompatible data structures. Furthermore, approach much tolerantusage features outside efficiently supported fragment. optimisationsalso used saturated nodes critical, could, example, caseontology contains non-absorbable GCIs. addition, presented extensionallows fixing critical parts saturation, whereby unsupported featuresproblematic rarely used ontology. contrast,reduce module efficient reasoner long module contains unsupportedfeatures. Thus, approach promises better pay-as-you-go behaviour. Moreover,use intermediate results saturation, whereas technique relies573fiSteigmiller & Glimmexternally provided interfaces reasoners, usually provides basic informationsatisfiability concepts subsumers classes. Therefore, integrationsaturation procedure obviously allows sophisticated optimisation techniquestransfer inferred consequences blocking processingtableau algorithm.Although approaches principle applicable different reasoning tasks,technique automatically improves reasoning long reasoning task reducedconsistency checking tableau algorithm. example, order supportsatisfiability testing complex concepts, approach need adaptations.MORe, however, would necessary check whether complex conceptmodule handled efficient reasoner order achieve improvement.Last least, need module extraction technique approach,also take significant amount time. especially advantage ontologiesalmost completely efficiently supported fragment since approachsimilar overhead module extraction ontologies.Another reasoning system combines different reasoning techniques WSReasoner(Song et al., 2012), uses weakening strengthening approach classification ontologies. precise, ontology first rewritten simpler one(the weakening ontology), supported language features (partially) expressed fragment handled efficient reasoner. Then, strengthenedversion weakened ontology created, axioms added leastalso consequences original ontology implied. weakened strengthened ontologies classified specialised reasoner possible differencesobtained subsumtion relations verified fully-fledged reasoner. Also WSReasoner, fragment specific reasoner (usually based saturation procedure)fully-fledged reasoner (usually based tableau calculus) used black-boxes,makes them, principle, exchangeable. However, weakening strengthening alsoadapted language fragment efficient reasoner.Although technique WSReasoner different one MORe, advantagesdisadvantages comparison approach principle same. However,approach WSReasoner easily extendible language features and,now, presented DL ALCHIO (with elimination/encodingtransitive roles also SHIO). Moreover, since nominals simplified fresh atomicconcepts, approach cannot straightforwardly used reasoning tasks.simplification is, however, applicable, often improves reasoning performancecorresponding ontologies.Similarly WSReasoner, PAGOdA (Zhou et al., 2014, 2015) also uses weakeningstrengthening approach, however, different reasoning tasks delegatingdifferent fragment ontology specialised reasoner. particular, PAGOdAdesigned ABox reasoning (e.g., conjunctive query answering) delegates majoritycomputational workload efficient datalog reasoner. lower bounddatalog reasoner match upper bound, PAGOdA delegatesquery relevant parts ABox fully-fledged reasoner. order keeprelevant parts small possible, PAGOdA uses additional optimisations relevantsubset extraction, summarisation, dependency analysis. However, additional574fiPay-As-You-Go Description Logic Reasoningoptimisations also carry risk every use fully-fledged reasoner introducesadditional overhead, could problematic ontologies lot work stilldone fully-fledged reasoner. Moreover, maintaining several naive representationsentire ABox easily multiply memory requirements.7. Implementation Evaluationextended Konclude3 (Steigmiller, Liebig, & Glimm, 2014) saturation procedureshown Section 3 optimisations presented Section 4 5. Koncludetableau-based reasoner SROIQ (Horrocks et al., 2006) extensions handlingnominal schemas (Steigmiller et al., 2013). Konclude integrates many state-of-the-art optimisations lazy unfolding, dependency directed backtracking, caching, etc. Moreover,Konclude uses partial absorption (Steigmiller et al., 2014b) order significantly reducenon-determinism ontologies and, therefore, Konclude well-suited proposedcoupling saturation procedures.integration saturation Konclude completely covers language featuresDL Horn-SHIF using saturation extensions described Section 5.1,universal restrictions propagate concepts successors merging successors/predecessors due functional at-most restrictions handled. number nodesadditionally processed handling saturation extensions mainlylimited number concepts occurring knowledge base. However, Koncludessaturation procedure supports limited handling ABox data. duedesign decision try avoid several representations individuals (andderived consequences these) reasoning system. Since saturation could easilyincomplete ABox (e.g., since disjunctions asserted individuals duedatatypes), ABox often also handled tableau algorithm severalrepresentations ABox multiply memory requirements. Hence, Konclude primarily handles ABox individuals tableau algorithm uses patches completiongraphs (as presented Section 5.2) improve parts saturation graphdepend nominals.addition, Konclude saturates concepts might required certain reasoning task upfront batch processing mode, whereby switches tableausaturation algorithm reduced significantly. Moreover, sort conceptsoccur knowledge base saturate specific order maximise amountdata shared saturated nodes. example, knowledge basecontains axiom v B, first saturate B use data vB initiatevA . particular, copying node labels, many rule applications skipped,significantly improves performance saturation procedure. Furthermore, alsoreduces effort saturation status detection. instance, vB satisfyat-most restriction, at-most restriction also satisfied vA .following, present detailed evaluation shows effects Koncludesintegrated saturation procedure presented optimisations support fullyfledged tableau algorithm. addition, compare reasoning times Koncludeones state-of-the-art reasoners support TBox reasoning (almost) features3. Konclude freely available http://www.konclude.com/575fiSteigmiller & GlimmRepository#AxiomsOntologiesQ0.5Gardiner2925, 84296NCBO BioPortal403 27, 1801, 116NCIt185 178, 818 167, 667OBO Foundry502 37, 3491, 292Oxford394 73, 9213, 433TONES2037, 707352Google crawl4146, 869255OntoCrawler5482, 574136OntoJCrawl1, 6966, 281311Swoogle crawl1, 6382, 778132ORE2014 dataset16, 555 16, 01759422, 830 16, 647594ClassesQ0.51, 788147, 51833969, 720 68, 8626, 7535098, 5435002, 864961, 12739124171, 77250416213, 846874, 02074PropertiesQ0.54474813116 12324453114051024493206293610101539750IndividualsQ0.58521, 76600020, 905618, 273565082416330838087901, 801 502, 271 29Table 5: Statistics ontology metrics evaluated ontology repositories ( standsaverage Q0.5 median)DLs SROIQ, namely FaCT++ 1.6.3 (Tsarkov & Horrocks, 2006), HermiT 1.3.8(Glimm, Horrocks, Motik, Stoilos, & Wang, 2014), 0.1.6 (Armas Romero et al., 2012),Pellet 2.3.1 (Sirin, Parsia, Cuenca Grau, Kalyanpur, & Katz, 2007). evaluation useslarge test corpus ontologies,4 obtained collecting downloadableparsable ontologiesGardiner ontology suite (Gardiner, Horrocks, & Tsarkov, 2006),NCBO BioPortal (Whetzel et al., 2011),National Cancer Institute thesaurus (NCIt) archive (National Cancer Institute,2003),Open Biological Ontologies (OBO) Foundry (Smith et al., 2007),Oxford ontology library (Information Systems Group, 2012),5TONES repository (Information Management Group, 2008),subsets OWLCorpus (Matentzoglu, Bail, & Parsia, 2013) gatheredcrawlers Google, OntoCrawler, OntoJCrawl, Swoogle,6ORE2014 dataset (Matentzoglu & Parsia, 2014).4. test corpus evaluated version(s) Konclude v0.6.1 found online http://www.derivo.de/en/products/konclude/paper-support-pages/tableau-saturation-coupling.html5. Note Oxford ontology library also contains repositories (e.g., Gardiner ontology suite),ignored order avoid much redundancy.6. order avoid many redundant ontologies, used subsets OWLCorpusgathered crawlers OntoCrawler, OntoJCrawl, Swoogle, Google.576fiPay-As-You-Go Description Logic ReasoningOntologyGazetteerEL-GALENFull-GALENBiomodelsCell Cycle v2.01NCI v06.12dNCI v12.11dSCT-SEPFMA v2.0-CNSOBIExpressivenessALE+ALEH+ALEHIF+SRIFSRIALCHSHSHALCOIFSHOINAxioms1, 170, 57360, 63361, 782847, 794731, 482141, 957229, 713109, 959165, 00032, 157Classes518, 19623, 13623, 136187, 520106, 39858, 77195, 70154, 97441, 6483, 533Properties1695095070469124110914884Individuals100220, 948000085160Table 6: Ontology metrics selected benchmark ontologiesNote ORE2014 dataset collection ontologies several sourcesredundantly contains many ontologies also contained repositories. However, many ontologies ORE2014 dataset adapted approximated fit requirements certain OWL 2 profiles (e.g., removing datatypesOWL 2 datatype map, enforcing regular role hierarchy, addingdeclarations undeclared entities). used OWL API parsing convertedontologies self-contained OWL/XML files, created, 1,380ontologies imports, version resolved imports another version,import directives simply removed (which allows testing reasoning performancemain ontology content without imports, frequently shared many ontologies). Table 5 shows overview obtained test corpus overall 22,830 ontologiesincluding statistics ontology metrics source repositories.addition test corpus, present results explicitly selected ontologies (shownTable 6) frequently used many evaluations. allows directly showingeffects approach well-known benchmark ontologies enables concretecomparison. Note Table 6 separated EL (upper part) non-EL ontolgies(lower part). EL ontologies, chose well-known Gazetteer EL-GALEN,latter one obtained removing functionality inverses Full-GALENontology, also selected benchmarking. addition, evaluated BiomodelsCell Cycle v2.01, large mainly deterministic ontologies NCBOBioPortal, NCI v06.12d NCI v12.11d, different versions NCI-Thesaurusontology NCIt archive, SCT-SEP, denotes SNOMED CT anatomicalmodel ontology (Kazakov, 2010), FMA v2.0-CNS, version FoundationalModel Anatomy (Golbreich, Zhang, & Bodenreider, 2006), OBI, representsrecent version Ontology Biomedical Investigations (Brinkman et al., 2010).evaluation carried Dell PowerEdge R420 server running two IntelXeon E5-2440 hexa core processors 2.4 GHz Hyper-Threading 144 GB RAM64bit Ubuntu 12.04.2 LTS. evaluation focuses classification, central reasoning task supported many reasoners and, thus, ideal comparing results.principle, measured classification time, i.e., time spent parsingloading ontologies well writing classification output files included pre577fiSteigmiller & Glimmsented results. advantage reasoners already perform preprocessingloading, is, however, case Konclude since Konclude uses lazy processing approach also preprocessing triggered classification request.also seems confirmed accumulated loading times ontologiesevaluated repositories, 6, 304 Konclude, 10, 877 MORe, 13, 210FaCT++, 22, 458 Pellet, 61, 293 HermiT. Note HermiT directlyclausifies ontologies loading (i.e., converts axioms HermiTs internalrepresentation based DL-clauses), easily take lot time ontologies intensively use cardinality restrictions. also ignored errors reported (other)reasoners, i.e., reasoner stopped processing ontology (e.g., due unsupportedaxioms program crashes), measured actual processing time. alsodisadvantage Konclude since Konclude processed ontologies (however, Koncludealso ignored parts role inclusion axioms regular specified OWL 2DL). contrast, reported errors 803, FaCT++ 944, Pellet 1, 285,HermiT 1, 483 ontologies corpus. reasoners often cancelled processingdue unsupported malformed datatypes. Another frequently reported error consisteddifferent individual axioms one individual specified. addition, HermiT completely refused processing ontologies irregular role inclusion axioms (whichare, however, rarely present test corpus).evaluation ontology repositories, used time limit 5 minutes.selected benchmark ontologies, cancelled classification task 15 minutessince ontologies relatively large. Moreover, averaged results selectedbenchmark ontologies 3 separate runs, necessary evaluated repositories since large amount ontologies automatically compensates non-deterministicbehaviours reasoners, i.e., accumulated (classification) times separate runsmany ontologies almost identical. Although reasoners support parallelisation,configured reasoners use one worker thread, allows comparison independently number CPU cores facilitates presentation improvementssaturation.7.1 Evaluation Saturation Optimisationspresented optimisations integrated Konclude way separately activated deactivated. Hence, evaluate compare performanceimprovements different optimisations. Please note deactivating optimisationsKonclude cause disproportionate performance losses since appropriate replacementoptimisations, could compensate deactivated techniques extent, often integrated Konclude. example, many reasoning systems use completelydefined concepts optimisation (Tsarkov & Horrocks, 2005) identify classesontology subsumption relations directly extracted ontologyaxioms and, thus, satisfiability subsumption tests necessary correctly insertclasses class hierarchy. Clearly, optimisation necessary Konclude, extract subsumers class saturation saturatedrepresentative node critical. Hence, performance deactivated optimisations578fiPay-As-You-Go Description Logic Reasoningmight worse be. Nevertheless, evaluated versions Konclude,saturation optimisations activated (denoted ALL),none saturation optimisations activated (denoted NONE),combination activation/deactivation (denoted +/) following modifications:RT (standing result transfer), transfer (possibly intermediate) results saturation completion graphs (as presented Section 4.1) activated/deactivated. precisely, initialise new nodes completion graphconsequences available saturation graph block processing(successor) nodes long identically labelled non-critical nodes(deterministic non-deterministic) saturation graph. described Section 5.2,nominal dependent nodes handled reactivating processing nodesdependent nominals become modified completion graph. this, implemented exact tracking nominal dependent nodes completion graphwell saturation graph.SE (standing subsumer extraction), extraction subsumerssaturation (as presented Section 4.2) activated/deactivated. representative nodes atomic concepts critical, Konclude use extractsubsumers (besides completely defined concepts) and, otherwise, derived atomicconcepts used told subsumers. Note that, completely defined conceptsnode label, candidate concepts interpreted corresponding completely defined concepts non-deterministically derived, i.e., possible subsumers. SE optimisation deactivated, Konclude extractssimple told subsumers axioms knowledge base order initialiseclassification algorithm, also Konclude based known possiblesets classification (Glimm et al., 2012).MM (standing model merging), model merging saturationgraph (as presented Section 4.3) activated/deactivated. candidate conceptsobtained Konclude partial absorption technique (Steigmiller et al.,2014b) model merging applied first initialisation knownpossible subsumers atomic concept. particular, avoid repeatedmodel merging possible subsumption relation different nodes (inpossibly different completion graphs) since could result significant overheadpossibly new non-subsumptions identified.ES (standing extended saturation), handling universal restrictionsfunctional at-most restrictions successors saturation (as presentedSection 5.1) activated/deactivated. Note integrated saturation procedurebecomes complete Horn-SHIF knowledge bases optimisation activated,whereas completeness guaranteed ELH knowledge bases deactivated.579fiSteigmiller & GlimmPS (standing patched saturation), patching saturation graphdata completion graphs (as presented Section 5.2) activated/deactivated.ensure patch compatibility nominal dependent nodes, use completiongraph caching technique integrated Konclude (Steigmiller et al., 2015)nominal nodes identified possibly different consequencesderived initial completion graph. Since Konclude supports exact trackingnominal dependency completion graph, save dependent nominalspatches propagate saturation graphs processingnode reactivated node dependent nominal becomes modified.Konclude incorporates exact tracking facts causesderived facts (Steigmiller, Liebig, & Glimm, 2012) used also extractpatches non-root nodes (as also sketched Section 5.2). Moreover,discovered satisfiability test concept result fully expandedclash-free completion graph, i.e., concept unsatisfiable, Konclude patchessaturation graphs -concept unsatisfiable conceptsalso revealed.example, NONE+MM denotes version Konclude, saturation optimisations except model merging saturation graph deactivated.Based version NONE, Table 7 shows performance improvements activation saturation optimisations RT, SE, MM. addition, resultsshown, optimisations activated simultaneously. Please note ESPS optimisations improve saturation procedure and, therefore, evaluation makes sense combination saturation optimisations.significant improvements achieved transfer saturation results completiongraphs (RT), often reduces effort tableau algorithm significantly.model merging optimisation (MM) primarily improves classification performanceNCI-Thesaurus ontologies NCIt archive, similar significantimpact repositories. Since many NCI-Thesaurus ontologies contain completedefinitions form r.B1 u s.B2 , model merging candidate concepts(as demonstrated Section 4.3) allows pruning many subsumptions performingsatisfiability tests atomic concepts. also improvements extraction subsumers saturation (SE), but, compared improvementsoptimisations, significantly better NCBO BioPortal. particular,NCBO BioPortal contains many large relatively simple ontologies almostcompletely handled saturation and, therefore, necessary perform satisfiability tests every class tableau algorithm SE optimisation activatedorder determine (possible) subsumers. Nevertheless, saturation optimisationsactivated, often able achieve much larger performance improvementsalmost repositories. one hand, caused additionally activated ESPS optimisations, hand, reasoning system utilise several synergyeffects saturation (obviously, concepts saturatedoptimisations).Table 8 analogously shows performance improvements activating saturationoptimisations RT, SE, MM selected benchmark ontologies. saturation optimisations significantly improve classification performance several ontologies.580fiPay-As-You-Go Description Logic ReasoningRepositoryGardinerNCBO BioPortalNCItOBO FoundryOxfordTONESGoogle crawlOntoCrawlerOntoJCrawlSwoogle crawlORE2014 datasetNONE5262, 25928, 6033, 0207, 9761, 734798273, 4053, 477115, 494167, 320NONE+RT5082, 03928, 4348124, 6391, 481463291, 1662, 67080, 673122, 914NONE+SE41458027, 9408775, 8661, 568670302, 2322, 82098, 630141, 628NONE+MM4902, 3263, 1632, 8298, 013756794312, 5042, 283115, 232138, 4211082601, 9427482, 484250112277151, 18729, 84137, 674Table 7: Accumulated classification times (in seconds) separately activated saturationoptimisations evaluated ontology repositoriesOntologyGazetteerEL-GALENFull-GALENBiomodelsCell Cycle v2.01NCI v06.12dNCI v12.11dSCT-SEPFMA v2.0-CNSOBINONENONE+RTNONE+SENONE+MM34.8761.0900.0241.5900.0900.017.7900.0900.01.330.15.5900.050.6900.0900.014.6339.8900.00.814.01.6900.018.27.6900.08.8279.4900.00.737.9762.6900.0148.7900.017.916.0383.1900.02.113.31.412.016.27.213.98.2173.172.70.6Table 8: Classification times (in seconds) separately activated saturation optimisationsevaluated benchmark ontologiesparticular, optimisations, Konclude handle ontologies reasonableamount time, whereas Konclude timed five ontologies saturation optimisations used. difficult ontologies Full-GALEN FMA v2.0-CNShandled sophisticated saturation optimisations used (e.g., SE, PS).also observed that, many ontologies, specific optimisations crucial,is, however, also surprising. example, clear MM optimisation cannot improve performance deterministic ontologies sincepossible subsumers model merging could applied.Table 9 shows performance changes separate deactivation saturation optimisations based configuration. evaluation optimisations alsointeresting perspective, saturation many concepts easily requiresignificant amount reasoning time and, separately deactivating single optimisations,overhead saturation associated separately activated optimisa581fiSteigmiller & GlimmRepositoryGardinerNCBO BioPortalNCItOBO FoundryOxfordTONESGoogle crawlOntoCrawlerOntoJCrawlSwoogle crawlORE2014 dataset1082601, 9427482, 484250112277151, 18729, 84137, 674ALLRT1346242, 0411, 0523, 987143790302, 0171, 42756, 12868, 374ALLSE2011, 9802, 5804533, 701366731621, 4451, 20956, 46969, 286ALLMM9061827, 9524732, 3981, 377706307022, 45637, 76071, 562ALLES3965822, 0007743, 658226412307641, 34851, 40061, 590ALLPS1067091, 9604532, 537633733358791, 20161, 03670, 281Table 9: Accumulated classification times (in seconds) separately deactivated saturation optimisations evaluated ontology repositoriesOntologyGazetteerEL-GALENFull-GALENBiomodelsCell Cycle v2.01NCI v06.12dNCI v12.11dSCT-SEPFMA v2.0-CNSOBI13.31.412.016.27.213.98.2173.172.70.6ALLRT13.61.512.717.27.515.08.7280.460.30.8ALLSE27.94.825.147.1900.015.713.0337.128.20.8ALLMM13.21.411.815.67.1900.07.6161.9180.30.7ALLES13.71.5900.016.27.313.87.4167.566.60.7ALLPS13.51.512.716.66.913.27.7168.7900.00.7Table 10: Classification times (in seconds) separately deactivated saturation optimisations selected benchmark ontologiestion. Furthermore, allows evaluating whether optimisations superfluouseffects caused saturation improvements ES PS, useful combination saturation optimisations. Table 9 reveals saturationoptimisations completely irrelevant repositories. Moreover, deactivationoptimisations also improve performance several repositories, e.g., deactivation RT results better reasoning times ontologies TONES repositorydeactivation MM causes minor performance improvements OntoJCrawlontologies. However, considering repositories, optimisation indeed justified.particular, presented saturation optimisations deactivated, reasoning times increase least 55 %. also caused several difficult ontologiesORE2014 dataset, variants KB Bio 101 ontology (Chaudhri, Wessel, &Heymans, 2013), handled Konclude almost saturation optimisations used. patching saturation graph (PS) data initial582fiPay-As-You-Go Description Logic Reasoningconsistency test often required complete/sufficient handling nominals withinsaturation procedure, saturation extensions (ES) enable primitive handling(qualified) cardinality restrictions even big cardinalities (due reuse nodessaturation graph), result transfer (RT) well subsumer extraction(SE) reduce avoid work tableau algorithm, particularly usefulbig highly cyclic ontologies. Although MM optimisation similar importantORE2014 dataset, optimisation significantly reduces effortKonclude NCI-Thesaurus ontologies NCIt archive.performance changes separate deactivation saturation optimisationsevaluated benchmark ontologies depicted Table 10. Again, observedoften specific optimisations important ontologies. example,deactivation SE optimisations significantly decreases performancesBiomodels Cell Cycle v2.01 ontologies. Since Full-GALEN highly cyclicmany consequences caused functional cardinality restrictions well inverseroles, tableau algorithm difficulties find appropriate blocker nodes completion graph and, therefore, handled saturation extendedlanguage features (as realised ES optimisation). contrast, FMA v2.0-CNSmany unsatisfiable classes and, soon tableau algorithm find unsatisfiable class, saturation graph patched (realised PS optimisation)-concept directly propagated many classes, whereby many satisfiabilitytests tableau algorithm become unnecessary.7.2 Evaluation Saturation EffortTable 11 shows distribution processing times w.r.t. Koncludes processing stagesclassification evaluated repositories version ALL. Unsurprisingly,majority processing time (61.5 %) spent classification process itself. contrast, saturation concepts potentially required classificationrequires 12.1 % together detection saturation status. latter onecan, however, usually neglected terms processing time since implementationefficient. example, node detected critical, criticality statusimmediately propagated dependent nodes and, consequence,tested. Moreover, use criticality testing queue filled saturationconcepts added node labels potentially influence criticality status. Hence,status detection iterate node labels. Althoughprinciple possible design ontologies saturation relatively inefficient (inparticular w.r.t. memory requirements), ontologies hardly occur practice.particular, data sharing node labels realised Konclude, saturationcause significant problems evaluated repositories, also reflectedshort processing time saturation stage. Consistency checking usuallyalso performed efficiently, several evaluated repositories (e.g., Swoogle crawl)also contain difficult ontologies tableau algorithm cannot find fullyexpanded clash-free completion graph within time limit. Building internal representation well preprocessing also realised efficiently Koncludecause problems evaluated repositories.583fiSteigmiller & GlimmRepositoryGardinerNCBO BioPortalNCItOBO FoundryOxfordTONESGoogle crawlOntoCrawlerOntoJCrawlSwoogle crawlORE2014 datasetBuilding Preprocessing10.830.627.417.17.511.016.35.05.610.62.63.311.67.938.310.78.24.62.21.04.85.85.46.3Saturation32.523.611.26.712.25.619.417.54.41.812.512.1Consistency1.83.11.946.620.30.68.321.148.126.713.414.6Classification24.328.868.425.451.387.952.912.534.768.263.461.5Table 11: Distribution processing time w.r.t. different processing stages (in %)7.3 Comparison Approachesmentioned Section 6, exist approaches also use saturation-basedreasoning techniques improve fully-fledged tableau algorithms. example,uses module extraction delegate much work possible efficient reasonerspecialised specific fragment order classify ontologies. Since early developmentversion available, evaluated test corpus compareresults approach following. used combination ELK 0.4.1(Kazakov, Krotzsch, & Simanck, 2014) HermiT 1.3.8, combinations alsopossible since reasoners used black-boxes.left-hand side Table 12 shows accumulated classification times (in seconds)versions Konclude saturation optimisations deactivated (version NONEColumn 2) saturation optimisations activated (version Column 3)different repositories. Furthermore, improvement version NONEversion given percent (Column 4 Table 12). example, using saturationoptimisations presented here, accumulated reasoning time repositories reduced77.5 % Konclude. right-hand side Table 12, analogously depictedaccumulated reasoning times HermiT (Column 5) (Column 6), alsopercentage HermiTs reasoning time reduced (Column 7).Note, accumulated loading times repositories 61, 293 HermiT10, 877 MORe, difference 50, 416 explained additionalpreprocessing directly performed HermiTs loading stage, whereas startsprocessing ontologies classification request. course, alsouses HermiT internally process parts ontologies cannot handled OWL2 EL reasoner ELK, required time loading parts HermiTcounted reasoning/classification time MORe. Hence, made comparison fairadding additional preprocessing time loading stage HermiTs classificationtime, i.e., shown classification times HermiT extended differenceloading times HermiT MORe.584fiPay-As-You-Go Description Logic ReasoningRepositoryGardinerNCBO BioPortalNCItOBO FoundryOxfordTONESGoogle crawlOntoCrawlerOntoJCrawlSwoogle crawlORE2014 datasetNONE [s]5262, 25928, 6033, 0207, 9761, 734798273, 4053, 477115, 494167, 320[%]79.588.593.275.268.985.686.00.079.065.974.277.5[s]1082601, 9427482, 484250112277151, 18729, 84137, 674HermiT [s]1, 7735, 90126, 4356, 65412, 8652, 3421, 9171, 8638, 5554, 857294, 124367, 283[s]1, 5374, 18726, 6004, 4748, 0832, 1841, 6298934, 5464, 270166, 589224, 982[%]13.329.00.632.837.26.715.052.146.912.143.938.7Table 12: Comparison improvements saturation approaches realisedKonclude accumulated classification times evaluatedontology repositories (in seconds %)OntologyGazetteerEL-GALENFull-GALENBiomodelsCell Cycle v2.01NCI v06.12dNCI v12.11dSCT-SEPFMA v2.0-CNSOBINONE [s]34.8761.0900.0241.5900.0900.017.7900.0900.01.3[%]51.298.098.793.399.298.553.880.175.953.8[s]13.31.412.016.27.213.98.2173.172.70.6HermiT [s]900.0900.0900.0788.8900.0211.992.7900.0900.032.5[s]18.22.6900.0648.8900.0208.083.3900.0900.02.37[%]98.099.717.71.910.193.0Table 13: Improvements saturation approaches Koncludeclassification times selected benchmark ontologies (in seconds%)Table 12 reveals significantly improve reasoning time HermiTalmost repositories. particular, saves 52.1 % HermiTs classification timeontologies OntoCrawler. Nevertheless, still many ontologiesrepositories, able reduce effort HermiTclassified within time limit (HermiT timed 786 590 ontologies,respectively). contrast, Konclude integrates sophisticated interactiontableau algorithm saturation procedure and, therefore, improvementssaturation optimisations significantly better many repositories. result,7. class hierarchy computed OBI coincide results HermiTKonclude.585fiSteigmiller & Glimmversion Konclude reached time limit 69 ontologies. Note, alreadyversion NONE Konclude, saturation optimisations deactivated, outperformsHermiT many ontologies, probably due difference integrated optimisations. example, Konclude uses several caching techniques savereuse intermediate results, usually improves reasoning performance lot. Moreover, partial absorption (Steigmiller et al., 2014b) integrated Konclude significantlyreduces non-determinism also expressive ontologies. Also noteyet completely support language features SROIQ and, therefore, always output correct class hierarchy (for evaluated ontology repositories, 1, 441 classhierarchies computed coincide results HermiT Konclude).Table 13 analogously shows performance improvements selected benchmarkontologies. Again, observed improvements saturationoften better Konclude MORe, especially ontologies consideredversion NONE Konclude still requires lot reasoning time.7.4 Comparison State-of-the-Art Reasonersalso evaluated classification times state-of-the-art reasoners FaCT++Pellet, compared reasoners HermiT, Konclude,Table 14. Note, Table 14 shows accumulated classification times actuallyreported reasoners, i.e., compensate differences loading times.observed Konclude outperforms reasoners evaluatedrepositories, mainly due integrated saturation optimisations. FaCT++reasoner efficiently handle majority NCI-Thesaurus ontologiesNCIt archive also without saturation optimisations. Nevertheless, model mergingsaturation graph allows pruning many possible subsumers Konclude, wherebyclassification performance improved and, therefore, Konclude ableoutperform FaCT++ also NCIt archive. Considering repositories, Koncludeproduced fewest timeouts (69), followed (590), HermiT (786), FaCT++ (822),Pellet (1, 470).Nevertheless, ontologies Koncludes performance optimalreasoners sometimes able outperform Konclude. example,Konclude requires 54.6 classification atom-complex-proton-2.0 ontologyTONES repository, whereas Pellet requires 11.4 (FaCT++ HermiT timedout). particular, handling (large) cardinalities easily cause problems since,worst-case, tableau algorithm used create merge correspondingnumbers successor nodes. Although saturation limited handling at-least cardinality restrictions using one representative node successor, easily becomesincomplete also at-most cardinality restrictions used ontologies. remedy, onecould try extend saturation procedure better handle cardinality restrictionscombine tableau algorithm algebraic methods, cardinality restrictionshandled system linear (in)equations (Haarslev, Sebastiani, & Vescovi, 2011).Moreover, much non-determinism, e.g., caused non-absorbable GCIs, still causeserious issues tableau-based systems. Examples ontologies variants enzyoSwoogle crawl, cannot classified evaluated reasoners except586fiPay-As-You-Go Description Logic ReasoningRepositoryGardinerNCBO BioPortalNCItOBO FoundryOxfordTONESGoogle crawlOntoCrawlerOntoJCrawlSwoogle crawlORE2014 datasetFaCT++1, 1085, 4134, 3937, 22520, 7611, 6842, 17896411, 5802, 864241, 402299, 573HermiT1, 6885, 57025, 2036, 25812, 2551, 9431, 7611, 7236, 7574, 073249, 637316, 867Konclude1082601, 9427482, 484250112277151, 18729, 84137, 6741, 5374, 18726, 6004, 4748, 0832, 1841, 6298934, 5464, 270166, 589224, 982Pellet4, 0069, 87717, 64712, 03127, 4611, 7557, 4969, 99931, 7769, 212397, 794528, 891Table 14: Comparison accumulated classification times state-of-the-art reasoners(in seconds) evaluated ontology repositoriesOntologyGazetteerEL-GALENFull-GALENBiomodelsCell Cycle v2.01NCI v06.12dNCI v12.11dSCT-SEPFMA v2.0-CNSOBIFaCT++900.0900.0900.02.78900.013.957.8900.0900.0900.0HermiT900.0900.0900.0788.8900.0206.178.8900.0900.031.5Konclude13.31.412.016.27.213.98.2173.128.30.618.22.6900.0648.8900.0208.083.3900.0900.02.39Pellet480.2135.1900.0900.0900.069.6306.9900.0900.0900.0Table 15: Comparison classification times state-of-the-art reasoners (in seconds)selected benchmark ontologiesFaCT++ (but also FaCT++ needs significant amount time even reachestime limit 5 minutes variants) although less 20, 000 axiomsexpressiveness ranging ALIN ALCOIN . Also large SROIQontologies Oxford ontology library, Mus musculus consisting 221, 484axioms, seem currently reach existing reasoning systems. Duesize complexity, even difficult analyse kinds problems reasonersrunning, intensive use nominals often limits applicability optimisationtechniques and, hence, often results poor performance.Analogously, Table 15 shows comparison classification times evaluated reasoners selected benchmark ontologies seconds. Again, activated8. FaCT++ 1.6.3 crashed classification Biomodels 2.7 seconds.9. class hierarchy computed OBI coincide resultsreasoners.587fiSteigmiller & Glimmsaturation optimisations, Konclude outperform reasoners almost ontologies able classify benchmark ontologies within time limit. Comparedreasoners, also achieve good results several ontologies.particular, timed 4 ontologies, whereas HermiT Pellet couldclassify 6 ontologies time, FaCT++ failed classification 7 ontologies.Hence, support saturation seems pay off.8. Conclusionspaper, presented technique tightly coupling saturation- tableaubased procedures. Unlike standard completion- consequence-based saturation procedures, approach applicable arbitrary OWL 2 DL ontologies. Furthermore,good pay-as-you-go behaviour, i.e., axioms use features problematic saturation-based procedures (e.g., disjunction), tableau procedure stillbenefit significantly saturation.good pay-as-you-go behaviour seems confirmed evaluationseveral thousand ontologies, integration presented saturation optimisationsreasoning system Konclude significantly improves classification performance.particular, optimisations, Konclude able outperform many state-ofthe-art reasoners wide range ontologies often one order magnitude.Acknowledgmentsfirst author acknowledges support doctoral scholarship Postgraduate Scholarships Act Land Baden-Wuerttemberg (LGFG). work donewithin Transregional Collaborative Research Centre SFB/TRR 62 CompanionTechnology Cognitive Technical Systems funded German Research Foundation (DFG).ReferencesArmas Romero, A., Cuenca Grau, B., & Horrocks, I. (2012). MORe: Modular combinationOWL reasoners ontology classification. Proc. 11th Int. Semantic Web Conf.(ISWC12), Vol. 7649 LNCS, pp. 116. Springer.Baader, F., Brandt, S., & Lutz, C. (2005). Pushing EL envelope. Proc. 19th Int. JointConf. Artificial Intelligence (IJCAI05), pp. 364369. Professional Book Center.Baader, F., Calvanese, D., McGuinness, D., Nardi, D., & Patel-Schneider, P. (Eds.). (2007).Description Logic Handbook: Theory, Implementation, Applications (Secondedition). Cambridge University Press.Baader, F., Hollunder, B., Nebel, B., Profitlich, H.-J., & Franconi, E. (1994). empiricalanalysis optimization techniques terminological representation systems. J.Applied Intelligence, 4 (2), 109132.588fiPay-As-You-Go Description Logic ReasoningBate, A., Motik, B., Cuenca Grau, B., Simanck, F., & Horrocks, I. (2015). Extendingconsequence-based reasoning SHIQ. Proc. 28th Int. Workshop DescriptionLogics (DL15).Brinkman, R. R., Courtot, M., Derom, D., Fostel, J., He, Y., Lord, P. W., Malone, J.,Parkinson, H. E., Peters, B., Rocca-Serra, P., Ruttenberg, A., Sansone, S., Soldatova,L. N., Jr., C. J. S., Turner, J. A., Zheng, J., & OBI consortium (2010). Modelingbiomedical experimental processes OBI. J. Biomedical Semantics, 1 (S-1), S7.Chaudhri, V. K., Wessel, M. A., & Heymans, S. (2013). KB Bio 101: challenge OWLreasoners. Proc. 2nd Int. Workshop OWL Reasoner Evaluation (ORE13).CEUR.Gardiner, T., Horrocks, I., & Tsarkov, D. (2006). Automated benchmarking descriptionlogic reasoners. Proc. 19th Int. Workshop Description Logics (DL06), Vol. 198.CEUR.Glimm, B., Horrocks, I., Motik, B., Shearer, R., & Stoilos, G. (2012). novel approachontology classification. J. Web Semantics, 14, 84101.Glimm, B., Horrocks, I., Motik, B., Stoilos, G., & Wang, Z. (2014). HermiT: OWL 2reasoner. J. Automated Reasoning, 53 (3), 125.Golbreich, C., Zhang, S., & Bodenreider, O. (2006). foundational model anatomyOWL: Experience perspectives. J. Web Semantics, 4 (3), 181195.Haarslev, V., Moller, R., & Turhan, A.-Y. (2001). Exploiting pseudo models TBoxABox reasoning expressive description logics. Proc. 1st Int. Joint Conf.Automated Reasoning (IJCAR01), Vol. 2083 LNCS, pp. 6175. Springer.Haarslev, V., Sebastiani, R., & Vescovi, M. (2011). Automated reasoning ALCQ viaSMT. Proc. 23rd Int. Conf. Automated Deduction (CADE11), pp. 283298.Springer.Horrocks, I., Kutz, O., & Sattler, U. (2006). even irresistible SROIQ. Proc.10th Int. Conf. Principles Knowledge Representation Reasoning (KR06),pp. 5767. AAAI Press.Horrocks, I., & Sattler, U. (1999). description logic transitive inverse rolesrole hierarchies. J. Logic Computation, 9 (3), 385410.Horrocks, I., & Sattler, U. (2001). Optimised reasoning SHIQ. Proc. 15th EuropeanConf. Artificial Intelligence (ECAI02), pp. 277281. IOS Press.Horrocks, I., & Sattler, U. (2004). Decidability SHIQ complex role inclusion axioms.Artificial Intelligence, 160 (1), 79104.Horrocks, I., & Sattler, U. (2007). tableau decision procedure SHOIQ. J. Automated Resoning, 39 (3), 249276.Horrocks, I., Sattler, U., & Tobies, S. (1999). Practical reasoning expressive description logics. Proc. 6th Int. Conf. Logic Programming Automated Reasoning(LPAR99), Vol. 1705 LNCS, pp. 161180. Springer.589fiSteigmiller & GlimmHorrocks, I., Sattler, U., & Tobies, S. (2000). Reasoning individuals descriptionlogic SHIQ. Proc. 17th Int. Conf. Automated Deduction (CADE00), Vol. 1831LNCS, pp. 482496. Springer.Horrocks, I., & Tobies, S. (2000). Reasoning axioms: Theory practice.. Proc.7th Int. Conf. Principles Knowledge Representation Reasoning (KR00),pp. 285296. Morgan Kaufmann.Hudek, A. K., & Weddell, G. E. (2006). Binary absorption tableaux-based reasoningdescription logics. Proc. 19th Int. Workshop Description Logics (DL06), Vol.189. CEUR.Information Management Group (2008). TONES ontology repository. University Manchester. Available http://owl.cs.manchester.ac.uk/repository/. Accessed: July2012; Mirrored http://ontohub.org/repositories/tones.Information Systems Group (2012). Oxford ontology library. University Oxford. Availablehttp://www.cs.ox.ac.uk/isg/ontologies/. Accessed: August 2012;.Kazakov, Y. (2008). RIQ SROIQ harder SHOIQ. Proc. 11th Int.Conf. Principles Knowledge Representation Reasoning (KR08), pp. 274284. AAAI Press.Kazakov, Y. (2009). Consequence-driven reasoning Horn-SHIQ ontologies. Proc.21st Int. Conf. Artificial Intelligence (IJCAI09), pp. 20402045. IJCAI.Kazakov, Y. (2010).ConDOR project site.condor-reasoner/. Accessed: July 2013;.https://code.google.com/p/Kazakov, Y., Krotzsch, M., & Simanck, F. (2012). Practical reasoning nominalsEL family description logics. Proc. 13th Int. Conf. Principles KnowledgeRepresentation Reasoning (KR12). AAAI Press.Kazakov, Y., Krotzsch, M., & Simanck, F. (2014). incredible ELK - polynomialprocedures efficient reasoning EL ontologies. J. Automated Reasoning, 53,161.Matentzoglu, N., Bail, S., & Parsia, B. (2013). corpus OWL DL ontologies. Proc.26th Int. Workshop Description Logics (DL13), Vol. 1014. CEUR.Matentzoglu, N., & Parsia, B. (2014). ORE 2014 reasoner competition dataset. Zenodo.Available http://dx.doi.org/10.5281/zenodo.10791.National Cancer Institute (2003). Nci thesaurus archive. Available http://ncit.nci.nih.gov/. Accessed: December 2012;.Ortiz, M., Rudolph, S., & Simkus, M. (2010). Worst-case optimal reasoning HornDL fragments OWL 1 2. Proc. 12th Int. Conf. Principles KnowledgeRepresentation Reasoning (KR10), pp. 269279. AAAI Press.Simanck, F. (2012). Elimination complex RIAs without automata. Proc. 25th Int.Workshop Description Logics (DL12), Vol. 846. CEUR.Simanck, F., Kazakov, Y., & Horrocks, I. (2011). Consequence-based reasoning beyondhorn ontologies. Proc. 22nd Int. Joint Conf. Artificial Intelligence (IJCAI11),pp. 10931098. IJCAI/AAAI.590fiPay-As-You-Go Description Logic ReasoningSimanck, F., Motik, B., & Horrocks, I. (2014). Consequence-based fixed-parametertractable reasoning description logics. J. Artificial Intelligence, 209, 2977.Sirin, E., Parsia, B., Cuenca Grau, B., Kalyanpur, A., & Katz, Y. (2007). Pellet: practicalOWL-DL reasoner. J. Web Semantics, 5 (2), 5153.Smith, B., Ashburner, M., Rosse, C., Bard, J., Bug, W., Ceusters, W., Goldberg, L. J.,Eilbeck, K., Ireland, A., Mungall, C. J., Consortium, T. O., Leontis, N., Rocca-Serra,P., Ruttenberg, A., Sansone, S.-A., Scheuermann, R. H., Shah, N., Whetzeland, P. L.,& Lewis, S. (2007). OBO Foundry: coordinated evolution ontologies supportbiomedical data integration. J. Nature Biotechnology, 25, 12511255.Song, W., Spencer, B., & Du, W. (2012). WSReasoner: prototype hybrid reasonerALCHOI ontology classification using weakening strengthening approach.Proc. 1st Int. Workshop OWL Reasoner Evaluation (ORE12), Vol. 858. CEUR.Steigmiller, A., Glimm, B., & Liebig, T. (2013). Nominal schema absorption. Proc. 23rdInt. Joint Conf. Artificial Intelligence (IJCAI13), pp. 11041110. AAAI Press.Steigmiller, A., Glimm, B., & Liebig, T. (2014a). Coupling tableau algorithms expressivedescription logics completion-based saturation procedures. Proc. 7th Int.Joint Conf. Automated Reasoning (IJCAR14), Vol. 8562 LNCS, pp. 449463.Springer.Steigmiller, A., Glimm, B., & Liebig, T. (2014b). Optimised absorption expressivedescription logics. Proc. 27th Int. Workshop Description Logics (DL14), Vol.1193. CEUR.Steigmiller, A., Glimm, B., & Liebig, T. (2015). Completion graph caching expressivedescription logics. Proc. 28th Int. Workshop Description Logics (DL15).Steigmiller, A., Liebig, T., & Glimm, B. (2012). Extended caching, backjumping merging expressive description logics. Proc. 6th Int. Joint Conf. AutomatedReasoning (IJCAR12), Vol. 7364 LNCS, pp. 514529. Springer.Steigmiller, A., Liebig, T., & Glimm, B. (2014). Konclude: system description. J. WebSemantics, 27 (1).Tsarkov, D., & Horrocks, I. (2004). Efficient reasoning range domain constraints.Proc. 17th Int. Workshop Description Logics (DL04), Vol. 104. CEUR.Tsarkov, D., & Horrocks, I. (2005). Optimised classification taxonomic knowledge bases.Proc. 18th Int. Workshop Description Logics (DL05), Vol. 147. CEUR.Tsarkov, D., & Horrocks, I. (2006). FaCT++ description logic reasoner: System description.Proc. 3rd Int. Joint Conf. Automated Reasoning (IJCAR06), Vol. 4130LNCS, pp. 292297. Springer.Tsarkov, D., Horrocks, I., & Patel-Schneider, P. F. (2007). Optimizing terminological reasoning expressive description logics. J. Automated Reasoning, 39, 277316.W3C OWL Working Group (27 October 2009). OWL 2 Web Ontology Language: Document Overview. W3C Recommendation. Available http://www.w3.org/TR/owl2-overview/.591fiSteigmiller & GlimmWhetzel, P. L., Noy, N. F., Shah, N. H., Alexander, P. R., Nyulas, C., Tudorache, T., &Musen, M. A. (2011). BioPortal: enhanced functionality via new web servicesnational center biomedical ontology access use ontologies softwareapplications. Nucleic Acids Research, 39 (Web-Server-Issue), 541545.Zhou, Y., Cuenca Grau, B., Nenov, Y., Kaminski, M., & Horrocks, I. (2015). PAGOdA:Pay-as-you-go ontology query answering using datalog reasoner. J. ArtificialIntelligence Research, 54, 309367.Zhou, Y., Nenov, Y., Cuenca Grau, B., & Horrocks, I. (2014). Pay-as-you-go OWL queryanswering using triple store. Proc. 28th AAAI Conf. Artificial Intelligence(AAAI14), pp. 11421148.592fiJournal Artificial Intelligence Research 54 (2015) 159-192Submitted 02/15; published 09/15Leveraging Online User Feedback ImproveStatistical Machine TranslationLlus Formigalformiga@verbio.comVerbio Technologies, S.L.,Loreto, 44, 08029 BarcelonaAlberto Barron-CedenoLlus Marquezalbarron@qf.org.qalmarquez@qf.org.qaQatar Computing Research InstituteHamad Bin Khalifa University,Tornado Tower, Floor 10, P.O. Box 5825, Doha, QatarCarlos A. HenrquezJose B. Marinocarlos.henriquez@upc.edujose.marino@upc.eduTALP Research Center - Universitat Politecnica de Catalunya,Jordi Girona, 1-3, 08034 BarcelonaAbstractarticle present three-step methodology dynamically improving statistical machine translation (SMT) system incorporating human feedback formfree edits system translations. target feedback provided casual users,typically error-prone. Thus, first propose filtering step automatically identifybetter user-edited translations discard useless ones. second step producespivot-based alignment source user-edited sentences, focusing errorsmade system. Finally, third step produces new translation model combineslinearly one original system. perform thorough evaluationreal-world dataset collected Reverso.net translation service show every step methodology contributes significantly improve general purpose SMTsystem. Interestingly, quality improvement due increase lexicalcoverage, better lexical selection, reordering, morphology. Finally, showrobustness methodology applying different scenario, newexamples come automatically Web-crawled parallel corpus. Using exactlyarchitecture models provides significant improvement translation qualitygeneral purpose baseline SMT system.1. IntroductionStatistical machine translation (SMT) become widespread technology, used millions people satisfy multiplicity needs daily interactions informationseeking. contrast business-oriented translation services, on-line machine translationservices (e.g., Google Translate, see Google Inc., 2015; Bing, see Microsoft Inc., 2015; Reverso, see Reverso-Softissimo, 2015) offer free general-purpose translations fairly acc2015AI Access Foundation. rights reserved.fiFormiga, Barron-Cedeno, Marquez, Henrquez & Marinoceptable levels quality large number language pairs. facteasily accessible computer, tablet smartphone connected Internetcontributed create huge community heterogeneous users.However, SMT systems significant limitations produce translation errorsdifferent levels (e.g., morphology agreement, phrase structure reordering, lexicalselection, fluency). due inherent complexity task alsolimitations currently available translation models training corpora,might fully representative domain, genre style texts translated.behavior may cause frustration fatigue users; usersright position spot mistakes. response machine translation (MT)systems developers allow users provide feedback proposing correctionssystem-generated translations. Gathering new improved information usersedits shown valuable resource improve translation systems online cost-free services (Simard, Goutte, & Isabelle, 2007; Ambati, Vogel, & Carbonell, 2010;Potet, Esperanca-Rodier, Blanchon, & Besacier, 2011) professional computer-assistedtranslation frameworks (Bertoldi, Cettolo, & Federico, 2013; Mathur, Mauro, & Federico,2013). raising interest topic MT community emerged alsoform research projects (e.g., MateCat, FAUST, Casmacat, see European Comission- 7th Framework Program, 2010) specialized workshops (e.g., Workshop Post-editingTechnology Practice MT Summit XIV) special issues (such MachineTranslation Journal Special Issue Machine Translation MT Post-editing).article explore use real translation feedback non-professionalusers. aim automatically improve general translation quality underlying MT system. approach differs significantly common settingprofessional post-editors used produce high-quality translations imperfectautomatic output. setting users casual, limited skills, sometimeslow command languages translated. perform free editsmachine-translated text produce supposedly better alternative translation. translation sometimes proper post-edition, frequently partial, contains errors,simply piece unrelated text. challenge particularly noisy settingable filter part noise select potentially useful translation edits.One advantage crowd-sourcing approach MT enrichment potentialreach vast community contributors. scenario conveys mutual-interest framework:one side, active user wills correct translations long system respondsbetter needs future; side, system requires inputintelligent agent, able provide information improve translation models.high level engagement achieved, committed live community constantlycontribute improve free on-line translators. Another fundamental aspect necessaryreach circle mechanism efficiently accurately incorporates user feedbacktranslation engine. Accurately, want MT system repeatmistakes and, time, worsen overall translation quality; efficientlyengage users, need system react quickly (if instantaneously) feedback.Even though exploitation user edits (UE) widespread practice increasinginterest, methods aim improving existing MT models. work highly focused translation dictionaries centered minimizing out-of-vocabulary (OOV)160fiLeveraging Online User Feedback Improve SMTratio translations (Cettolo, Federico, Servan, & Bertoldi, 2013). Studying performance enriched translation models variety aspects translation quality(e.g., morphology, word ordering, lexical selection, etc.) issue deservesattention MT community.work explore extent use translation edits collectednon-professional users commercial on-line translation portal improve translationquality general purpose SMT system. main contribution twofold. First,address noisy crowd-sourcing scenario training supervised classifiers identify usefulUE instances. Second, devise SimTer, pivot-based method aligning user-editedtranslations source text original automatic translations, aimdetect specific corrected errors build enriched translation models accordingly.aspects, UE filtering pivot-based selection phrase pairs, novel showcontribute significantly better translation quality. support claimextensive experimentation analysis. improvement achieved remarkable comparedsimple corpus-concatenation strategy, since work relatively low quantityUEs. Additionally, conduct manual evaluation output enriched system.study reveals strengths weaknesses enriched system sourceimproved results, achieved means reduction OOVratio. Interestingly, linguistically-founded aspects translation quality alsoimproved. Finally, show generality approach successfully applyingarchitecture models noisy domain-adaptation scenario, new examplescome automatically-crawled bilingual corpora filtering noisy exampleskey aspect adaptation.rest article organized follows. Section 2 puts current article contextoverviewing related work. Section 3 describes locally evaluates classificationapproach identifying useful UE instances. Section 4 discusses proposal improvingmachine translation models UEs. Section 5 presents experiments real datasetsshowcasing proposed methodology. Finally, conclusions presented Section 6.2. Related Worksection overview relevant work related two main contributionsarticle: automatically identifying useful user edits (UEs) improving existingtranslation models (TMs) basis UEs.Identifying useful UE instances necessary many ones collectednon-professional users may represent better translations compared onesproduced system itself. best knowledge, researchparticular topic exists. analog tasks found either obtaining quality materialfiltering automatically gathered corpora domain adaptation. Usually, subsampling selection method (Foster, Goutte, & Kuhn, 2010; Axelrod, He, & Gao, 2011)used dealing corpus selection problems. consists simple rationale:language model (LM) created reliable in-domain data and, subsequently,parts corpus lower perplexity respect model selected.scenario, select best UE instead.161fiFormiga, Barron-Cedeno, Marquez, Henrquez & Marinoprevious research topic (Pighin, Marquez, & May, 2012; Barron-Cedenoet al., 2013) defined basic set features perform identification. aimcapturing different aspects, as: (i) whether UE text adequate translationsource sentence automatic translation (computed simple surfacesimilarity features), (ii) whether UE includes mistakes typos, (iii) whethersource contains mistakes typos prevent obtaining sensible translations.identification cast supervised classification problem using mentionedfeatures. work extends approach, explained evaluated Section 3.Assuming set good edited translations (revised expert), enrichmenttranslation system involves two separate steps. First, alignment sourcesentences edited translation computed (alignment). Second, improved translationmodels learned using alignments (adaptation). Regarding alignment step,widely accepted best possible alignment obtained adding training corpus, new sentence pairs edited sentence treated target-side modelsestimated schratch (Hardt & Elming, 2010). However, large amount trainingdata makes approach computationally expensive; obstacle goal reactingquickly user feedback. overcome problem, several incremental alignmentmodels proposed literature(Levenberg, Callison-Burch, & Osborne, 2010).exception stream-based translation approach, adds updatesoriginal TM scores according new material (Ortiz-Martnez, Garca-Varea, & Casacuberta, 2010; Martnez-Gomez, Sanchis-Trilles, & Casacuberta, 2012; Mathur et al., 2013),adaptation step usually carried creating specific translation tablesedited translations (using standard phrase-extraction phrase-scoring algorithms)combining original translation tables. important notework incremental adaptation tested scenarios references used instead UEs. Hence, related work mainly addresses simulated artificialscenarios conclusions might totally representative. models usehuman-edited translations. Mathur et al. (2013) along Bertoldi et al.(2013) relybusiness-oriented specific corpus computer-assisted translation. Simard et al. (2007)introduced so-called automatic post-editors (i.e., monolingual SMT systems designedimprove translation errors). Potet et al. (2011) considered small corpus UEsnon-professional users, incremental methodology. basis previousaspects describe next selected papers.Hardt Elming (2010) proposed approach produce approximate alignments.defined approximate alignment one allows extend phrase table,even perfect exact. Given hsource, user-editi pair baseline alignment(Och & Ney, 2003), explored available links selecting ones producinghighest probability according IBM model 4. Moreover, improved alignmentsapplying two heuristics: first non-aligned word source aligned firstnon-aligned word UE unlinked fragment pairs surrounded correspondingalignments linked. One drawback method alignments producednoise-sensitive, built upon heuristics. makes methodology unpredictableunstable deal words seen baseline alignment model.adaptation step, built separate phrase table UEs decodedphrase tables. used approximate exact GIZA++ alignments showed162fiLeveraging Online User Feedback Improve SMTperformance approximate alignment yields half improvement obtainedGIZA++ alignment. However, simulated data, using references instead actualhuman UEs, considered work.Ortiz-Martnez et al. (2010) Martnez-Gomez et al. (2012) applied incremental version Expectation Maximization (EM) algorithm (Neal & Hinton, 1998)minimizes error function small sequences mini-batched data. paradigmcommonly known stream-based translation, small portions data processedtime. specifically, incrementally adapted seven models including language models, length penalty, phrase translation models, distortion. strategy reportedperform reasonably well non-stationary environments fast adaptation required,interactive machine translation (Ortiz-Martnez, Sanchis-Trilles, Gonzalez-Rubio, &Casacuberta, 2013). general-purpose web-based scenario, resulting modelssensitive lately integrated data. approach normalization carrieddue computational cost. Mathur Federico (2013) opted leaving originalfeatures unaltered added extra (normalized) feature reflects impact UEsadaptation system.Simultaneously Ortiz-Martnez et al. (2010), Levenberg et al. (2010) proposedon-line strategy phrase-based model enrichment using stepwise EM alignment algorithm (Cappe & Moulines, 2009). incorporation new knowledge approachbased re-estimation scores phrase table re-computing countsthroughout computationally efficient dynamic suffix array (Callison-Burch, Bannard, &Schroeder, 2005; Lopez, 2008). suffix array contains starting index suffixstring containing phrases lexicographical order, allowing easy computation on-the-fly translation probabilities given source phrase. dynamic variantsuffix array supports deletions insertions, making suitable stream-basedapproach. Moses uses algorithm provide incremental training strategy (Haddow& Germann, 2011).mGIZA++ parallel implementation IBM HMM models (Gao & Vogel, 2008).byproduct, performs forced alignment,1 alternative step-wiseincremental EM approaches. mGIZA++ builds multiple alignment models parallel,allowing filtering merging afterwards produce exact alignmentaggregation. Consequently, one obtain forcedly-aligned material improvedalignment models quality concatenated dataset usedbeginning. tool efficient terms processing time storage requirements,making suitable exact incremental alignment.contrast alignment methods described above, pivot-based approach triesidentify specific edits performed user original translation projectsource (Henrquez, Marino, & Banchs, 2011). precisely, uses originaltranslation pivot obtain alignments source UE translation,enrich existing translation models. advantage approachallows spot incorrect fragments translation, potential source errorsMT system. Therefore, new alignments obtained edited fragmentsones promoted within TMs enriched translator. Formiga et al. (2012)1. term forced alignment refers coercively aligning unseen parallel text selecting maximumprobability given model, even value low.163fiFormiga, Barron-Cedeno, Marquez, Henrquez & MarinoBlain, Schwenk, Senellart Systran (2012) studied idea perform adaptationgood results. recently developed MateCat tool (Matecat, 2015), Web-based CATtool, good example category. approach three advantages: fast,rely baseline alignment models, low memory requirements.previous pivot-based alignment implementations, edit distance computedtranslation-error-rate (TER) alignment algorithm, takes account reordering operations paraphrasing. strategy basis methodology presentedarticle, explain detail Section 4.1. Concerning adaptation strategy,Formiga et al. (2012) combined UE-specific translation models baseline models using Foster Kuhns (2007) interpolation empirically-set weights. Blain et al. (2012)studied two decoding strategies considering baseline UE phrase-tables separately:back-off, phrase found baseline translation model, phrase table considered multiple decoding, phrase found translation models,translations scores used. found multiple decoding best strategyrestricting TER alignment substitution operations (i.e., neglecting addition,deletion, shifting edits). refined combination methods presented recently. Sennrich (2012) used L-BFGS algorithm (Byrd, Lu, Nocedal, & Zhu, 1995)find optimal interpolation values feature function TMs. Bisazza, RuizFederico (2011) defined fill-up strategy complement missing informationoriginal TMs. Nevertheless, methods challenged incrementalscenario.3. Learning Classify User Editssection describes strategy identify useful user-edits improving machinetranslation system. approach task binary classification problem identifyingcases edited translation adequate system-produced translationpositive. so, follow previous work human feedback filtering(cf. Section 2).3.1 Training Corpustraining material used EnglishSpanish Faust Feedback Filtering (FFF+ ) 2 corpus, developed within FAUST EU project.It contains 550 examples real translationrequests user-edits Reverso.net translation Web service. example contains seven fields:SRC source sentence English (users translation request system);TGT automatic translation SRC Spanish;UE potentially improved user-edit TGT provided user;BTGT automatic translation TGT back English;BUE automatic translation UE back English;LANG language set translators interface;2. Available ftp://mi.eng.cam.ac.uk/data/faust/UPC-Mar2013-FAUST-feedback-annotation.tgz.164fiLeveraging Online User Feedback Improve SMTCL class label, i.e., whether UE adequate translation SRC TGT.Observe language set translators interface likely indicatorusers native language; factor may indicate user edits languagereliable. 550 examples FFF+ independently labeled acceptableunnaceptable edits two human annotators native Spanish speakershigh command English. cases disagreement (100) discussed consensusreached. main criterion decide whether user-edit acceptable basedtranslation adequacy (i.e., degree meaning source sentenceconveyed translation). Concretely, UE considered acceptable strictlyadequate TGT, even still imperfect. believed lax criterion acceptabilitycould work well proxy usefulness, thinking enriching MT system.detailed description annotation guidelines, including examples, one may referwork FAUST (2013, Section 3.2). levels inter-annotator agreement achieved(Cohens kappa 0.50.6) considered moderately high. fact evincesinherent difficulty task, even humans. positivenegative distributioncorpus almost balanced: 50.5% versus 49.5%, indicating edits provided casualusers noisy.3.2 Learning Featuresconsidered five sets features characterize examples fields relationshipsthem: surface comparison, back-translation, noise-based, similarity-based, quality estimation. first four sets require external resources MT systemtarget back source language (having system hand likely,necessary resources build practically original-directionsystem). fact makes particularly appealing under-resourced languages.fifth set composed combination well-known MT quality estimation measures.cases, features extracted text pre-processing, including case-folding diacriticselimination original texts incorporated translation system. Following,provide short description main principles guiding family features.full list, comprising 90 individual features, described detail FAUST (2013,Section 3.2).3.2.1 Surface Featuresconsider text strings SRC, TGT UE, compute surface similarities amonglevel word tokens characters (length, length ratios, Levehnstein distance,vocabulary containment, etc.). also binary feature account languageinterface (LANG).165fiFormiga, Barron-Cedeno, Marquez, Henrquez & Marino3.2.2 Back-Translation Featuresfeatures account also surface properties, considered back-translationsTGT (BTGT) UE (BUE). Levenshtein distances token character levelwell vocabulary intersections included.33.2.3 Noise-Based Featuresbinary features intended determine likelihood text fragments include noisy sections. consider instances SRC UE include characters repetitions(longer three characters) tokens whose length high regular word (>10chars). try determine length-based translation difficulty asuminglonger sentences harder translate (we consider features ranges [1 5],[6 10], [11, ) words).3.2.4 Similarity-Based Featuresset includes different similarity measures SRC, TGT, UE back-translations.Borrowing concepts cross-language information retrieval estimate cosine similaritiesacross languages using character 3-grams (Mcnamee & Mayfield, 2004). machinetranslation consider models parallel corpora alignment based pseudocognates lengths (Simard, Foster, & Isabelle, 1992; Gale & Church, 1993; Pouliquen,Steinberger, & Ignat, 2003). features intend alternative Levenshtein-basedfeatures surface back-translation sets.3.2.5 Quality-Estimation-Based Featuresapplied 26 system-independent quality estimation (QE) measures providedAsiya (Gimenez & Marquez, 2010) SRCTGT SRCUE pairs. measures intend estimate translation quality without human references, making appealingcurrent framework. QE measures quite shallow, incorporate linguisticinformation level part speech, syntactic phrases, named entities. bilingualexternal dictionary also used. Consequently, say set features containslinguistically-oriented generalizations previous ones. Perplexity, numberout-of-vocabulary words translation sentence, well bilingual-dictionary-basedsimilarity SRC UE (or TGT) included among 26 measures.3.3 Classifier Learning Intrinsic Evaluationtrained support vector machines (SVM) previously described features learnclassifiers. used SVMlight (Joachims, 1999) linear, polynomial, RBF kernelstuned classifiers 90% FFF+ corpus. remaining 10% leftaside testing purposes. Feature values clipped fit range 3 2decrease impact outliers. Normalization applied means z-score:x = (x )/. Later on, mean standard deviation tuning dataset usednormalize remaining test set instances.3. back-translations produced Spanish-to-English MT engines using Reverso.nettechnology.166fiLeveraging Online User Feedback Improve SMTTable 1: Cross-validation results linear SVMs trained incremental sets features,without application feature selection. Best results italic faced.feature setssurface + bt+ noise+ similarity+ QEF164.670.169.372.0featuresPR Acc63.5 65.7 63.063.7 78.0 65.964.3 75.2 65.967.2 77.6 69.1feature selectionF1PR Acc67.8 65.7 70.1 65.973.5 67.0 81.5 69.973.6 68.1 79.9 70.576.1 71.0 81.9 73.5evaluated basis standard measures: classification accuracy, precision (ratio predicted useful instances instances classified useful), recall (ratiopredicted useful instances useful instances dataset), F1 (harmonicmean precision recall). training strategy aimed optimizing F1 consistedtwo iterative steps: (a) parameter tuning: grid search appropriate SVMparameters (Hsu, Chang, & Lin, 2003), (b) feature selection: wrapper strategy, implementing backward elimination discard redundant irrelevant features (Witten & Frank,2005, p. 294). short, process performs iterative search remove worst featuredataset time, according performance obtained classifierneglects feature. See details work Barron-Cedeno et al. (2013).present incremental evaluation see contribution every featurefamily effect feature selection. base feature set composed surfaceback-translation (bt) features. Then, incrementally add noise-based, similarity-basedquality estimation (QE) features. Table 1 presents results. Figure 1 displayscorresponding precisionrecall curves. learning setting restricted linear SVMsexperiment. first observation feature selection procedure consistentlyprovides better accuracy F1 scores; i.e., allows discard irrelevant features alsoharming ones. Results show feature families contribute positively finalperformance classifiers, gains accumulative. improvement especiallynoticeable quality estimation features come play feature filtering applied.numerical results backed shape precision-recall curves: includingfeature sets leads better results, precision levels clearly 70% recall levels6070%.complementary study using non-linear kernels task (not includedbrevity), revealed even though slightly better accuracy F1 results obtainedusing non-linear kernels, shape precisionrecall curve better linearclassifier high-precision zone.4 Avoiding false positives important propertythinking selecting useful user edits MT improvement. Therefore, used linearclassifiers translation experiments Section 5. extended study, includingkernel variants, available description report FAUST (2013, Section 3.4).report also includes detailed experiments relevance individual features4. values 0.6 precision, curve linear classifier smoother contains much largerarea it.167fiFormiga, Barron-Cedeno, Marquez, Henrquez & Marinosurface+bt+noise+similarity+QE1Recall0.80.60.40.200.50.60.70.8Precision0.91Figure 1: Precision-Recall curves different learning settings feature setsdevelopment partition. Black dots represent optimal F1 values.comparison example rankings produced different classifier variantsset examples.Finally, evaluated different classifiers 10% test partition FFF+corpus. Absolute resuts slightly lower: linear SVM feature sets obtains F1accuracy values 73.2 69.9, respectively,5 results observed.is, precisionrecall curves linear SVMs including feature sets better rest,allowing obtain higher precision scores similar levels recall.3.4 Discussionclassifiers analyzed section showed modest levels precision, slightly70% acceptable levels recall. Significantly higher precision values reachedprice lowering recall 10%. behavior reflects difficulty confidentlycharacterizing positive examples type features used train classifiers.worth noting task also difficult humans. agreement achievedannotators (Cohens kappa 0.6) considered moderately high, certainlyfully satisfactory, evincing inherent difficulty task. Translation qualitymulti-faceted concept, encompasses adequacy (i.e., whether translation conveysmeaning source), fluency (i.e., whether translation fluent utterancetarget language) many aspects; defined application basis(e.g., vocabulary usage, language register, post-editing effort, etc.). result, humanperception translation quality highly subjective matter, depending small details,difficult capture delimit set simple annotation guidelines. effectamplified corpus noisy nature input text, input sentences5. FFF+ test set small susceptible statistical unstability computing performancescores.168fiLeveraging Online User Feedback Improve SMToften lack necessary context make fully reliable decisions. Fortunately, classifyinggood user edits end task. ultimate goal UE classifiers performselection, i.e., rank UE instances acceptability set appropriate thresholdselect useful UEs improve SMT engine. following sections empiricallyshow that, regardless limited performance local classifiers, proper inclusionselected highest-ranked user-edited translations general purpose SMTsignificantly improve quality. Finally, one might argue rather training classifiersoptimize accuracy local task, would better define joint UE-selectionMT-enrichment learning setting, classifiers optimized directlytranslation quality enriched SMT system. Although attractive theory,would extremely inefficient practically infeasible pipeline.4. Method Incorporating User-Edits SMT Systemsection describe method incorporating user-edits machine translationmodel. approach developed assumption translation modeluser-edited materials data disposal improve translation system.approach divided two steps: (i) using original automatic translationpivot align source text edited translation extracting new phrase pairs(Section 4.1), (ii) interpolation new phrase pairs original translationmodel (Section 4.2). validation experiments discussed Section 4.3.4.1 Pivot-Based Word Alignmentorder detect correct translation errors, consider three pieces information:source input text SRC, target output translation given translation systemTGT, user-edited version UE. monolingual alignment TGT UE allowspredicting translation errors, identifying parts edited. projectionalignment SRC allows extraction new translation pairs, representingcorrections provided UE.propose three-step alignment procedure. First, compute TER path (Snover,Madnani, Dorr, & Schwartz, 2009) TGT UE, aligning identical wordssides. Second, estimate best alignment among possible combinationsunaligned TGT UE words maximizing similarity function pairs wordsTGT UE sim(wt , wu ). Finally, monolingual alignment made, pivotalignment towards SRC: taking advantage decoder-provided word alignmentSRC TGT, link words SRC UE word TGTconnects them. alignment process, call SimTer described Algorithm 1.comparison translated edited sentences based translationedit rate, TER (Snover et al., 2009).6 addition minimum number edits, TERobtains alignment edit path: required sequence edits change outputtranslation reference user-edited sentence case. Figure 2 shows6. TER error metric estimates number edits required convert translation outputone references. Although based Levenshtein distance, TER additionally allows wordmovements considering usual addition, deletion, substitution operations order reducenumber changes.169fiFormiga, Barron-Cedeno, Marquez, Henrquez & MarinoAlgorithm 1SimTer. pivot-based algorithm align SRC UE TGT1: Translate SRC TGT decoder obtain corresponding word alignmentsalign(ws , wt ) every ws SRC wt TGT;2: Compute TER path TGT UE align identical words (cf. Section 4.1);3: Align every non-aligned word wt TGT words wu UE summationsimilarities new pairs, Sim(wt , wu ), maximized;4: every pair alignments al(ws , wt ) al(wt , wu ), create new alignment al(ws , wu );easy find right mixright mix easy findeeeeeee ddFinding right mix easyeasy find right mixFinding right mix easyFigure 2: TER-path computed monolingual sentence pair. d, e stand deletion,exact (no change), substitution. minimum number edits three: two deletionsone substitution.example. First, upper part figure, TER allows word movements, rightmix moved next first word. minimum number edits computed,resulting one substitution two deletions. Finally, lower part figure,word movements roll back original positions obtain word alignmenttwo sentences.Although TER able align words correctly, may fail circumstances words affected edit actually aligned accordingposition sentence, rather semantic similarity. example Figure 2,finding find aligned. counter measure issue, proposeconsider similarity wt wu linear combination simple similarityfeatures:8Xsim(wt , wu ) =hi (wt , wu ) ,(1)i=1hi (wt , wu ) similarity features corresponding contributionweights. hi models different relationship wt wu follows:h1 - binary feature indicates wt wu identical.h2,3 - Two binary features accounting existence links wt1 wu1 (h2 )wt+1 wu+1 (h3 ).170fiLeveraging Online User Feedback Improve SMTh4 - feature penalize multiple links (onetomany). considers possibilitylink(wt0 , wu ) aligning user-edited word wu TGT word wt linkwt0 wu already set. feature penalizes new link proportionallydistance wt wt0 :kpos(wt ) pos(wt0 )kh4 (wt , wu ) = max,(2)|TGT|tlink(wt0 ,wu )pos() position TGT |TGT|t number tokens TGT.h5,6 - Two lexical features designed evaluate strength semantic relationshipwt wu according proximity ws . done consideringbidirectional conditional probabilities (ws , wt ) (ws , wu )translation table. Feature h5 (wt , wu ) approximated normalized conditionalprobability based bilingual dictionaries:h5 (wt , wu ) =Xs:link(ws ,wt )=p(wt | ws )p(ws | wu )00 UE p(wt | ws )p(ws | wu )wu(3)p(ws | wu ),00 UE p(ws | wu )wu(4)PXPs:link(ws ,wt )normalization factor included order consider contribution p(ws |wu ) context sentence UE. Feature h6 analogous h5 , consideringp(ws | wt ) p(wu | ws ) instead. ws unknown word (i.e., replicatedSRC TGT without mapping bilingual dictionaries), take h5 = h6 = 0.h7 - feature applied wt unknown word duplicatedtranslation system input sentence output. wu wtsame, force linked giving h7 arbitrarily large value. Otherwise,feature takes real value function Levenshtein distance (LD) characterlevel unknown wt wu :h7 (wt , wu ) = 1LD(wt , wu ),|wu |(5)|wu | represents length wu characters. feature becomes penaltyLevensthein distance exceeds length wu , preventing linkinglonger unrelated words.h8 - penalty feature prevent alignments unknown word wt stopwordwu . takes large negative value wu stopword; zero otherwise. takestopwords determiners, articles, pronouns, prepositions, auxilary verbs.weights relative hi feature obtained downhill simplexalgorithm (Nelder & Mead, 1965). give details Section 4.3.2.171fiFormiga, Barron-Cedeno, Marquez, Henrquez & MarinoFigure 3: Process compute interpolation weight () re-tune TM featurecoefficients ().4.2 Incorporation Aligned Phrase Pairscomputing SimTer word alignment source edited translations,use new parallel corpus (SRC,UE) enrich retrain translator.deal two types newly extracted phrase pairs (translation units): (i) previouslyseenphrase pairs already included original translation model; relativelyup-weighted within translation models, favoring selection facing similarsituation, (ii) new phrase pairs missing original translation modelrepresent principal resource improve translator. New phrase pairs mustadded final translation model order provide decoder new translationoptions facing similar source sentences.include new phrase pairs original model using Foster Kuhns (2007)interpolation method, initially designed address domain adaptation problems. relatively small translation models extracted user edits estimated meanssymmetrization phrase-extraction standard algorithms grow-diag-final-and heuristic. Then, original new translation models linearly interpolated accordingto:TM(phrasei ) = TMoriginal (phrasei ) + (1 ) TMpe (phrasei )(6)TM, TMoriginal TMpe final, original, UE-based translation modelscores phrasei pair. setting interpolation parameter strongly coupledre-tuning classical set weights () used combine SMT features.applied iterative two-step process outlined Figure 3. process starts setweights 1 original translation system iterates updatesweight yield BLEU improvements. two-step iterative process. First, best172fiLeveraging Online User Feedback Improve SMTTable 2: Statistics EnglishSpanish corpora used obtain SimTer similarityfunction weights .CorpusEPPSEPPS UESent.EngSpaEngSpa1.90100Words49.4052.662,8623,022Vocab.124.03 k154.67 k1,0171,089avg.len.26.0527.2828.630.2weighting computed using best i1 available. case = 1 interpolationtaken account (0 = 0). Afterwards, optimum interpolation parametercomputed using best set translation feature weights obtained.combination procedure simpler reordering models. follows fill-upstrategy preserves every entry score original model adds new entriesscores new phrases (Bisazza et al., 2011). Units appearoriginal model one obtained user-edits preserve reordering scoreoriginal model.4.3 Validation Experimentsobjective experiments described section twofold: (i) tuning metaparameters algorithms (ii) validating proposed methodology well established domain-adaptation task. consider experiments preliminary, translationreferences used instead proper user edits.4.3.1 Datasetsselected different datasets experiments. order optimize parameterssimilarity function Equation (1), used Europarl v6 corpus, EPPS (Koehn,2005), build base phrase-based SMT system. evaluate alignments, smallmanually-aligned corpus, EPPS UE (Lambert, de Gispert, Banchs, & Marino, 2005),used perform pivot-translations subsequent SimTer alignments. small corpusbelongs domain EPPS intersection them. Table 2shows statistics.order tune parameters, validate proposed methodology,used corpora WMT12 campaign (Callison-Burch, Koehn, Monz, Post, Soricut,& Specia, 2012). contains parallel sentences EPPS corpus already mentioned,News Commentary (NC), United Nations (UN). also includes monolingual versionEuroparl monolingual corpora based News (broken years: 2007-2011).Tables 3 4 provide descriptive statistics datasets, computed cleaningpre-processing. Additionally, used WMT08-11 test material tuningTMs (dev), WMT12/13 tests testing methodology (test12 test13).Table 5 shows statistics tuning/test material.173fiFormiga, Barron-Cedeno, Marquez, Henrquez & MarinoTable 3: Statistics additional WMT12 EnglishSpanish parallel corpora trainingtranslation models (used tuning validation purposes).CorpusNCUNEngSpaEngSpaSent.Words Vocab.Preliminary Experiments3.7362.70 k0.154.3373.97 k205.68 575.04 k8.38239.40 598.54 kavg.len.24.2028.0924.5428.56Table 4: Statistics Spanish monolingual corpora used build language models.CorpusEPPSNCUNNews.07News.08News.09News.10News.11Sent.2.120.1811.200.051.711.070.695.11Words61.975.24372.211.3349.9730.5719.58151.06Vocab.174.92 k81.56 k725.73 k64.10 k377.56 k287.81 k226.76 k668.63 kavg.len.29.1828.5533.2428.9119.1928.6328.5429.55Table 5: Statistics development test corpora used tune test translationsystem.Corpusdevtest12test13EngSpaEngSpaEngSpaSent.Words Vocab.WMT based dev/test189.01 k 18.61 k7,567202.80 k 21.75 k63.78 k 14.34 k3,00369.45 k 16.47 k56.09 k 13.34 k3,00062.05 k 15.16 kavg.len.25.026.821.223.118.720.74.3.2 Tuning Parameters Similarity Functionbuilt baseline SMT system following standard pipeline Moses trainingEPPS (Koehn & Hoang, 2007). applied resulting system translate sourceside manually-aligned corpus (EPPS UE). Then, carried downhill simplexprocess adjust weights (Nelder & Mead, 1965), except 8 fixed1. Recall h8 assigns large costs prevent alignments unknown wordsfunction words. activated, works hard constraint, pruning hypothesesspace, value 8 chosen arbitrarily positive number differentzero. SimTer applied three completed iterations. final goalproduce alignment source sentence edited translation. Therefore,evaluated using Alignment Error Rate (AER) respect manual sourcereference174fiLeveraging Online User Feedback Improve SMTTable 6: Contribution weights similarity function features.123456780.08 0.75 0.91 3.08 0.47 2.02 1.50 1.00Table 7: Translation quality different values .BLEU0.127.860.228.180.328.330.428.490.528.680.628.750.728.690.828.620.928.45alignment (Och & Ney, 2003). AER reduced 20.12% 17.57% (13% relative errorreduction), reaching performance equivalent mGIZA++ corpora.Table 6 includes resulting s. 4 value shows, penalization distant links(h4 ) important feature. lexical features, h6 significantlyrelevant h5 . Interestingly, feature h1 (same word) considered relevantcompared others.4.3.3 Tuning Validating Combination Methodlast step fully testing strategy compute parameter equation (6). mentioned before, used corpus WMT12 campaign (CallisonBurch et al., 2012). trained baseline English Spanish system factored Mosesphrase-based system (Koehn & Hoang, 2007) words words POS tags (Formigaet al., 2012).7 base system considered EPPS UN concatenated whole corpus.Regarding monolingual data, language model (LM) built corpusinterpolated minimizing perplexity development set (Schwenk & Koehn,2008). experiment translated English sentences NC parallel corpustook Spanish references simulate user edited translations (UE). performedSimTer word alignment build UE-specific translation reordering models. Finally,applied optimization method depicted Section 4.2.Table 7 shows BLEU scores obtained different values . combiningtranslation models, BLEU improved 27.86 28.75, achieving highest value= 0.6 (i.e., 6040% distribution weight base edited translationmodels, respectively). setting , validated adaptation methodobtained hyper-parameters. also compared combination method (referredLinear Interpolation ( = 0.6)) methods available Moses, namely:Concatenation NC, EPPS, UN aggregated single training corpus.Multiple Tables Either Two parallel decodings corresponding TM launchedseparately, selecting one best score.Multiple Tables One decoding launched considering options availablephrase tables, doubling number translation features log-linearmodel.7. text POS-tagged Freeling suite NLP analyzers (Padro, Collado, Reese, Lloberes, &Castellon, 2010).175fiFormiga, Barron-Cedeno, Marquez, Henrquez & MarinoMoses Incremental training base phrase-table updated approximate alignments (see Levenberg et al., 2010 Section 2) . alignments computedMoses incremental inc-giza-pp algorithm instead SimTer algorithm.Table 8: Results different combinations base SimTer-specific translation models.BLEU NIST columns, indicate significant differencesConcatenation system 0.95 0.90 confidence levels, respectively. Bestabsolute results depicted bold face. Moses incremental training showncomparison purposes although use SimTer alignmenttest12BaseConcatenationLinear Interpolation ( = 0.6)Multiple tables eitherMultiple tablesMoses Incremental trainingtest13BaseConcatenationLinear Interpolation ( = 0.6)Multiple tables eitherMultiple tablesMoses Incremental trainingBLEUNISTTERMETEORULC32.7733.0333.2533.2031.7232.588.638.668.708.708.518.6148.6548.4848.2448.1949.4248.8655.4855.6455.8455.7654.8855.4070.7871.1671.6671.6169.2171.0428.7428.9629.1529.1328.0228.578.018.078.078.077.917.9751.6051.2951.2851.2952.4052.0152.8253.1153.1553.0352.2652.6770.9471.5671.7371.6669.5270.74used BLEU, NIST, TER METEOR (Papineni, Roukos, Ward, & Zhu, 2002;NIST, 2002; Snover et al., 2009; Denkowski & Lavie, 2011) automatic translationquality measures. Additionally, considered linear combination former ones:ULC (Gimenez & Marquez, 2010). Table 8 presents obtained results. adaptationstrategy outperforms Baseline Concatenation configurations practically every testcorpora quality measure. precisely, found significant differences BLEU(test12 test13) NIST (test12) metrics.8 performance either combination close linear interpolation method. However, either combinationcomputationally expensive, almost doubling time required linear interpolationmethod. Table 9 includes translation times reference.9 incremental approachfastest one, yields improvement baseline.summary, alignment combination methods proposed work offer significantly better results without sacrificing computational efficiency, comparedalternative methods provided Moses. Therefore, consider multiple decodingincremental strategies remaining experiments paper.8. work, significances computed paired bootstrap resampling (Riezler & Maxwell, 2005)9. figures computed Linux server 96 GB RAM 24-core CPU Xeon processors1.6 GHz (134064 Bogomips total). Multi-threading used compute decoding times.176fiLeveraging Online User Feedback Improve SMTTable 9: Translation times seconds (Collecting+Decoding) combination method.CombinationmethodMoses Incremental trainingLinear Interpolation ( = 0.6)Multiple tablesMultiple tables eitherNum.sent.3,003Total timetest12test137,502.526,553.458,284.797,684.6513,353.80 12,291.7013,097.40 11,364.80Time per Sentencetest12test132.502.182.762.564.104.454.363.79Table 10: Statistics EnglishSpanish parallel corpora used FAUST scenario.CorpusFAUST UEFAUST dev CleanFAUST test RawFAUST test CleanFAUST MonolingualSent.EngSpaEngSpa ref0Spa ref1EngSpa ref0Spa ref1EngSpa ref0Spa ref1Spa6,6101,9989981,99698,199Words43,31047,80024,58824,58825,2709,94110,13510,33319,77320,27020,6661.15Vocab.8,25010,4303,7583,7583,7434,1844,4844,4994,7374,4844,49989,378avg. length6.67.212.312.312.610.010.210.49.910.210.411.675. Experiments Real Datasection present experiments using methodology improve already existingMT systems real data. describe two experiments. first scenario, newmaterial comes collection user-edited translations submitted Reverso.netMT Web service (cf. Section 5.1). second scenario, new material selected (cf.Section 5.2) CommonCrawl (Smith et al., 2013)5.1 User-Provided Edited Translations (FAUST)FAUST project (cf. Section 3) goal improve quality on-line MTservices leveraging users feedback, mainly form suggested improved translations.experiments, take advantage parallel monolingual data supplied setuser translation queries edits. users belong on-line communitymotivated edit response translation queries.FAUST parallel corpora composed two non-overlapping collections translation requests gathered Reverso.net website: FAUST UE FAUST dev/test.10FAUST UE includes triplets composed input source, MT output, user edit.use corpus training purposes. FAUST dev/test corpus includes target refer10. sample FAUST UE available ftp://mi.eng.cam.ac.uk/data/faust/FaustFeedbackSample.xls.gz FAUST User-edited corpus. FAUST dev/test available ftp://mi.eng.cam.ac.uk/data/faust/FAUST-1.0.tgz.177fiFormiga, Barron-Cedeno, Marquez, Henrquez & Marinoences provided two professional translators. Moreover, translators processedsource inputs reduce noise (e.g., removing slang words, misspellings, smileys, etc.).process resulted two versions dev/test corpus: Raw, source inputsoriginal ones, Clean. experiments considered FAUST dev Clean version tuning (less error prone), real FAUST test Raw testing. FAUSTmonolingual corpus composed 98,199 translation requests Reverso.net websiteSpanish source language. selection respect target languagemade. Table 10 shows statistics FAUST corpora.first experiment took Concatenation MT system Section 4.3.3adapted target language model FAUST scenario follows: (i) builtspecific web-domain language model FAUST Monolingual corpus, (ii) obtainedlanguage model means new interpolation language models accordingperplexity minimization FAUST dev Clean corpus, (iii) tuned weightstranslation features using MERT maximize BLEU FAUST dev Cleancorpus. goal set strong baseline system experimental comparisondatset. refer Base FAUST.order select suitable feedback material improve Base FAUSTsystem, ranked FAUST UE collection 6,610 user-edited instances accordingSVM classifier scores (cf. Section 3). SVM labeled 61% data useful feedback(we call point TH0, decision threshold=0). However, guaranteelevel selection maximizes translation quality adapted system. Therefore,carried analysis quality function percentage selected user-editedinstances.5.1.1 ResultsFigure 4 depicts performance obtained FAUST test Raw corpus differentpercentages selected user-edited data. figure focuses two evaluation metrics:NIST, based classical n-gram matching approach improved brevitypenalty providing robustness noise BLEU TER, tries mimicediting effort would addressed humans order obtain high-qualitytranslation. similar curves observed using FAUST test Clean (not shownbrevity). Table 11 presents complete comparative results FAUST Raw corpus,set extended evaluation metrics Section 4.3.3: BLEU, NIST, METEOR,TER, ULC. Different adaptation filtering strategies also presentedtable, including: (i) different filtering methods (FFF+ Subsampling), (ii) adaptationmethods (Concatenation vs. SimTer), (iii) different percentages included user-edits:50%, 61%(TH0), 100%. Significances computed way describedSection 4.3.3. performed subsampling computing perplexityexisting models UE part, wanted select best user edits.analyzing results, worth noting already strong baseline,tuned in-domain using domain specific monolingual data. Several observationsdrawn. first block (SimTer 0.6 & Subsamp.) shows adding new materialsubsampling filtering provides none little improvement baseline dependingevaluation metric analysis. precisely n-gram based metrics BLEU NIST178fiLeveraging Online User Feedback Improve SMT8.38.258.228.2451.551.2551.151.08.1150.58.18.0950.64TERNIST8.28.150.0250.049.949.6749.5RAW80255075RAW1000255075% best PE selected100Figure 4: NIST TER scores function percentage best ranked user-editsused.Table 11: Results obtained considering feedback instances dependingamount user-edits used different filtering adaptation methods.indicate significant differences Baseline system 0.990.95 confidence levels. Best absolute results highlighted.Translation systemAdaptationFilteringBaselineSubsamp.SimTer 0.6FFF+ConcatenationFFF+% editsBLEUNISTTERMETEORULC0%+25%+50%+75%+50%+TH0-61%100%+50%+TH0-61%33.3433.2633.4132.9534.0133.6833.1832.8933.138.118.118.168.138.258.228.108.158.0851.2551.2750.4850.5849.6750.0250.6450.2950.6355.1055.0655.5555.3256.0656.1455.5455.7955.4671.0570.9671.8571.3973.2372.7871.6871.8371.44capture improvement TER METEOR slightly do. importantevidence provided second block (SimTer 0.6 & FFF+), strategypropose paper. results evince appropriateness FFF+ filteringyields significantly better results metrics compared Subsampling. However,remarkable FFF+ Subsampling learning curves obtain best results50% total user-edits considered. filtering strategy results crucialobtaining final improvement. regarding method, also usingedits filtering (+100%) impact n-gram-based metrics (BLEUNIST), marginally improves metrics (TER METEOR).last block (Concatenation & FFF+) confirms important contribution SimTer 0.6adaptation strategy compared straightforward approach adding new materialconcatenation. case, using exactly filtered material, SimTer 0.6 yieldsbetter results compared concatenation strategy.179fiFormiga, Barron-Cedeno, Marquez, Henrquez & MarinoAlignment / Interpolation MethodAlignment / Interpolation Method51.58.3051.08.2050.5NISTTER8.258.1550.08.1049.58.05SimTer 0.6RAW8.25mGIZA++ 0.68.24SimTer PPL8.13mGIZA++ PPL8.12SimTer 0.6RAW49.67mGIZA++ 0.649.94SimTer PPL51.09mGIZA++ PPL51.17Figure 5: NIST TER translation performance FAUST Raw Clean testsachieved different alignment/phrase-table interpolation methods.short, UE-enriched translation models following SimTer 0.6 & FFF+ yieldsignificant final improvement (+0.67) BLEU points (-1.57) TER points testset. Introducing user edits without pre-selection boosting scheme allowMT system achieve consistent improvements.Additionally, compared alignment/phrase-table interpolation approachcompetitive variants present literature. Concerning alignment, consideredforced alignment capability mGIZA++ defined Gao Vogel (2008): malignments obtained re-trained IBM 4 model iterated dataoriginal training edited material. Regarding weight-interpolation strategy,considered perplexity minimization method (PPL) Sennrich (2012), especiallysuited domain adaptation. approach, development translation model (TM)(i.e., phrase-table) built small development set. development TM usedminimize perplexity combining different TMs case base UE-basedmodels. strength approach granularity weights: instead givingdifferent weight phrase-table, assigns different weights feature functionwithin phrase-table, trying lower perplexity much possible. usedoptimization method L-BFGS numerically approximated gradients (Byrd et al., 1995).Figure 5 presents results obtained four alignment/interpolation combinedscenarios. Concerning comparison alignment methods, NIST shows significantdifferences SimTer pivot-based mGIZA++ approaches. However, TERreflects bigger difference favor SimTer. behavior coherent alignmentstrategy, focused finding particular edits given user. terms computationaltime, big differences: alignments computed less minute6,610 sentences. One advantages using SimTer requiredepend previous alignment models (mGIZA++ alike). 11 Comparing termsalignment error rate beyond scope paper. SimTer specifically tailoredfind differences original edited translations order extract11. claiming SimTer work well general purpose alignment algorithm, competitive mGIZA++ state-of-the-art aligners.180fiLeveraging Online User Feedback Improve SMTTable 12: Real examples translations changed (but necessarily improved)SimTer 0.6 & FFF+ (50%) system categorization accordinglinguistic phenomena studiedFunctionWordsAdditions/Omissions(worse)LexicalReorder.Bad FeedbackMorphol.CombinedSourceBaselineApplicantsauthorizedrepresentativeinformation:Tell Im supposedbreathe air.El representante autorizado solicitante informacion:DIME como se supone quetengo para respirar sin aire.SimTer 0.6& FFF+ (50%)Representante autorizadodel solicitante de la informacion:DIME como suponepara respirar sin aire.use lettersEnglish alphabetwrite Persian?measures updated developed2005 strategy review.utilizar todas las letras delalfabeto persa para escribiren espanol?Estas medidas fueron actualizados la revision de laestrategia desarrollada enel 2005.verdad?Si un extranjero llega (. . . ),dejan por el?Informamos que vamosdarle garanta de 5 anossobre los materiales lamano de obra.utilizar todas las letrasdel alfabeto ingles para escribir en persa?Estas medidas se han actualizado desarrolladoen la revision de la estrategia de 2005.Hiza intentoHazlo?Si un extranjero llega (. . . ),vas dejarme por el?Informamos que vamosproporcionarle 5 anos degaranta sobre materialesmano de obra.it?alien comes (. . . ),leave him?Please informedprovide 5 yearswarranty materialworkmanship.new phrase pairs, useful improve translation models. Thus, two tools servedifferent purpose.12 Finally, regarding interpolation strategy, setting interpolationweights perplexity minimization method Sennrich (2012) provideenough boosting UE-based models. issue particularly observed lookingweights set L-BFGS algorithm: order 0.99 baselinemodel 1 103 UE-based model. contrary, optimization basedquality provided translation addresses point directly.5.1.2 Qualitative Output Analysisresults presented far based automatic evaluation metrics. complement study set human assessments order verify improvementalso perceived humans identify characteristics make new translationsbetter. Five expert annotators analyzed 414 instances FAUST test Clean corpus.annotators observed triplets composed source sentence, translation producedBaseline, translation better performing SimTer 0.6 & FFF+ (50%)system. determine two translations better or, instead,quality. additional option cannot tell possible well. Annotators12. sake completeness, mention experiments conducted evaluate performance SimTer general aligner showed AER results significantly lower mGIZA++(Henriquez, 2014)181fiFormiga, Barron-Cedeno, Marquez, Henrquez & MarinoTable 13: Results comparative analysis carried five human annotatorstranslation 414 sentences FAUST test Clean corpus BaselineSimTer 0.6 & FFF+ (50%) systems. criterion (row), Better indicates user-adapted models provide better translation comparednon-adapted system, Worse indicates conversely Changed indicatestranslations different.AdequacyFluencyFunction WordsAdditions / OmissionsLexicalReorderingBad FeedbackMorphologyBetter34.54%32.61%Better50.00%31.54%47.59%57.50%35.77%40.58%49.76%18.56%20.53%31.99%18.37%40.73%Worse15.70%17.63%Worse31.52%47.93%20.40%24.13%100.00%23.45%Cannot Tell9.18%Changed13.04%17.63%60.39%21.01%5.31%19.57%Table 14: Progression OOV ratio BLEU FAUST test Clean corpus alongdifferent acceptance levels user-edited instances.SelectionRatio0% (no-feedback)25%50%61%75%100% (all-feedback)OOVWords563559557554550550TotalWords22,898OOVRatio2.46%2.44%2.43%2.42%2.40%2.40%BLEU37.8537.8638.6538.3238.4737.79know system produced translation, order presentationtwo options randomized. overall quality assessment based translation adequacy fluency, annotators also asked provide detailed informationlinguistic aspects made one translation better one; e.g., changes functionwords, addition omission spurious words, lexical coverage, reordering, morphology,presence harmful elements (bad feedback, i.e., mistranslations clearly introducederroneous user edits). Table 12 includes real samples studied phenomena. Cohenskappa agreement annotators selection 10 common phrases = 0.57.Table 13 presents overall results. percentage sentences translation changes significantly terms adequacy fluency around 50%-60%. numbertranslations adequacy fluency improved SimTer 0.6 & FFF+ (50%)system doubled number cases lowered quality. fact confirmsresults obtained automatic evaluation measures. Table 13 shows that,60% sentences underwent lexical modification. aspects received less bussignificant impact: reordering (21.01% sentences affected), morphology (19.57%), addi182fiLeveraging Online User Feedback Improve SMTTable 15: Statistics EnglishSpanish parallel CommonCrawl corpus.CorpusCommonCrawlSent.EngSpa1.84Words46.5450.33Vocab.750.01 K775.75 Kavg. length25.2227.30tions/omissions (17.63%), function words (13.04%) and, least frequent, bad feedback(5.31%). aspects improved, except additions/omissions and, bad feedback.worth mentioning frequent changes (lexical reordering) alsochanges whose benefit doubles cases quality decrease. Contrary couldthought, lexical correction addresses mistranslations greater deal Out-ofVocabulary words (OOV), OOVs reduced 0.03% best performance(cf. Table 14 detailed analysis).5.2 Using Web-Crawled Parallel Corpusapplication scenario, use CommonCrawl corpus, collection parallel textsautomatically mined Web (Smith et al., 2013). corpus offers two interestingcharacteristics experiments: (i) vocabulary expressions go far beyondcontrolled scenario EPPS acts formality News UN corpora (ii)noisy corpus. large vocabulary size Table 15 gives intuition naturecontent, high presence noise spurious words. addition, size allows settrade-off quantity (amount new material selected) quality (the thresholdselection algorithm). Moreover, selection method FAUST corpus alsoapplicable due analogy scenarios: CommonCrawl, compareautomatic translation source sentences references automatically obtainedcrawler select cases latter better. perform selectionuse classifiers FAUST scenario without retraining adaptationwant study generalization ability specific training materialCommonCrawl corpus available selection task. experiment representsdouble challenge: (i) determining presented proposal also suitable crawledparallel corpora, (ii) studying whether trained selection models generalize wellacross corpora domain. CommonCrawl experimental setting seenartificial post-editing scenario: references represent edits, ideallyprovide adequate translations.experiment, consider baseline best obtained system far translationnews texts (cf. Section 4.3.3). call baseline Base News SimTer 0.6. baselinesystem might considered already strong, since 0.25 BLEU points better purebaseline system (trained data). order assess trade-offquantity quality using parallel text, enrich baseline adaptingoriginal models different portions CommonCrawl corpus filtered eithersubsampling FFF+ strategies. FAUST scenario, analyzed translationperformance depending several factors: (i) ratio CommonCrawl data selected,(ii) data selection strategy (FFF+ vs Subsampling), (iii) adaptation strategy.Table 16 Figure 6 show evaluation results test12 test13 datasetsSection 4.3.1. curves Figure 6 show consistent pattern observed183fiFormiga, Barron-Cedeno, Marquez, Henrquez & MarinoFigure 4 FAUST scenario, reinforcing evidences: FFF+ selectionSimTer 0.6 adaptation important order obtain final gain. Using CommonCrawlwithout selection result performance gain, worsens results slightly.Subsampling improves metrics 75% point cost worsening others.Moreover, concatening 25% best ranked CommonCrawl training data Concat.FFF+(25%) provides slight improvement. However, improvements obtainedConcat. FFF+(25%) SimTer 0.6 Subsampling(75%) significant.Table 16: Results obtained base CommonCrawl-enriched SMT systems depending different filtering adaptation methods. BLEU NIST, ,indicate significant differences News SimTer 0.6 system (experiment baseline) 0.99, 0.95 0.90 confidence levels, respectively.best results corpus boldfaced.Translation systemAdaptationFilteringtest12News SimTer 0.6SubSamp.SimTer 0.6FFF+Concat.FFF+test13News SimTer 0.6SubSamp.SimTer 0.6FFF+Concat.FFF+% editsBLEUNISTTERMETEORULC0%+25%+50%+75%+25%+TH0-60%+100%+25%+TH0-60%33.2533.2133.3833.4733.7333.7433.1933.4133.208.708.678.688.708.788.758.688.718.6848.2448.3848.2548.2747.8447.8748.4648.0948.1855.8455.4855.5455.8156.2156.0555.5055.8855.7271.6671.8672.0472.3272.5272.4271.2072.4472.150%+25%+50%+75%+25%+TH0-60%+100%+25%+TH0-60%29.1529.1729.2229.2929.6129.5729.3229.2729.008.078.058.038.058.138.108.078.078.0451.2851.4951.4351.3650.9951.1251.3651.1151.1453.1552.8752.7152.8853.3953.1352.8753.1453.0171.7371.7171.6371.8572.4172.0771.5372.2671.94Results also show selecting 25%-best CommonCrawl data producesbest improvement. approximately +0.50 BLEU 0.40 TER test sets.important recall Base News SimTer 0.6 strong baseline. remarkableselection models trained data FAUST scenario generalize wellCommonCrawl domain adaptation scenario. optimal 25% selection thresholdrepresents much stricter selection required FAUST scenario (50%). However, FAUST selecting around 3,000 sentences among 6,000, caseselecting around 460 thousand sentences 1.84 million. Hence, final selectionthreshold compromise aggressiveness method minimumamount new material necessary cause real impact. also analyzed effect184fiLeveraging Online User Feedback Improve SMT8.9NIST8.74 8.758.748.748.46TER8.848.949.08.7848.58.688.747.8448.047.5test_128.60255075% best CommonCrawl corpus used47.9 47.87100test_1208.248.04255075% best CommonCrawl corpus used10052.552.068.18.0752.08.088.18.09TERNIST8.1351.58.0750.9951.19 51.1251.2951.3651.080255075% best CommonCrawl corpus usedtest_1350.5test_131000255075% best CommonCrawl corpus used100Figure 6: NIST TER scores test12 test13 corpora functionpercentage best ranked CommonCrawl segments used.selecting 25% CommonCrawl data randomly (averaged 10 times) selecting 25% data selection classifiers considered worst. analysisallows assess good selection algorithm ranking parallel examplesCommonCrawl corpus. Figure 7(a) shows results, indicate classifiersable generate sensible rankings detect best worst examples. allowsproperly enrich translation models, avoiding negative effect using really badinstances. results obtained 25% examples selected randomresults obtained selecting best 25% according classifier.Lastly, repeated comparison alignment/adaptation strategy methods considered FAUST scenario experiment. Figure 7(b) shows obtained results.Similar Figure 5, differences small favor SimTer. However, SimTer 60-40%performs significantly better alignment/adaptation strategies testsets (p < 0.01).185fiFormiga, Barron-Cedeno, Marquez, Henrquez & Marinotest_12test_13Selection Method52.752.151.550.950.449.849.248.64847.4TERNISTSelection Method8.88.68.58.48.38.28.187.97.825%_bestbaseline8.78*8.13*8.78.078.688.0725%_rand 25%_worst8.658.038.447.83test_12test_1325%_bestbaseline50.9947.8451.2848.2451.3648.4625%_rand 25%_worst51.5748.5552.8149.72(a) Achieved using different selection criteria: baseline (0%), (100%), best 25%, random 25%worst 25%.Alignment / Interpolation MethodTERNISTAlignment / Interpolation Method8.88.78.68.58.48.38.28.1851.350.950.55049.649.148.748.247.847.4SimTer 0.6 mGIZA++ PPL SimTer PPL mGIZA++ 0.6test_12test_138.78*8.13*8.728.088.728.078.748.08SimTer 0.6 mGIZA++ PPL SimTer PPL mGIZA++ 0.6test_12test_1350.9947.8451.1848.0751.1948.0851.2648.08(b) Achieved applying different alignment/adaptation methods.Figure 7: NIST TER scores test12 test13 corpora. indicates significantdifferences Baseline system 0.99 confidence level.6. Conclusionsarticle proposed new automatic strategy incrementally train machine translation (MT) models edited translations coming casual unreliable users.strategy builds upon three main blocks, namely: (i) automatic identification useful useredited instances (UE); (ii) alignment UEs source text, focusingerrors made original MT system; (iii) incorporation new parallel segments specific translation models trained UEs. proposal novelapplication techniques information retrieval, quality estimation domainadaptation problem MT system enrichment. datasets explored alsointeresting challenging properties.selection useful UEs important filter noisy feedback users.accomplish training classifier supervised data using features derivedsimilarity metrics used information retrieval MT quality estimation. Although186fiLeveraging Online User Feedback Improve SMTclassification results achieved moderate, classification scores allow approximatelyrank UEs quality tune different selection thresholds. Experiments showuseful strategy select examples which, combined two steps, yieldssignificant improvements original MT system.Regarding sourcetranslationUE alignment, proposed SimTer, simple incremental approach based pivoting, uses TER alignment augmented similarityfeatures. approach two advantages: depend previous softwarespecific alignment models (e.g., GIZA++, mGIZA++ Berkeley Aligner) monolingual nature alignment implicitly allows algorithm focus correcting translation errors, rather achieving optimal alignment words. experimentingtwo real datasets, showed positive contribution SimTer MT enrichment pipeline. particular application, using SimTer better using existinggeneral-purpose aligners, mGIZA++, especially CommonCrawl scenario.experiments also confirmed validity proposal, terms computational efficiency.third step deals building UE-specific translation models using standard phraseextraction scoring tools. experimentally analyzing different ways combiningUE-based original translation models, concluded simple linear interpolation good efficient strategy. properly tuning parameters, combinationreal impact final translation models, something that, instance, perplexityminimization able achieve.complete architecture thoroughly tested real UEs collected nonprofessional users commercial on-line translation portal (the called FAUSTscenario). experimented different thresholds select examples alternativeways perform alignment integration new aligned sentences. Resultsshowed approach significantly improves translation quality basic, generalpurpose SMT system, generally superior alternative methods. Apart evaluating several automatic quality measures, also conducted manual analysis orderverify quality improvements gain insight cases enriched MT system performs better worse. improvements come mainlyreduction out-of-vocabulary words, actually reduced marginally.major improvements translation quality came much better lexical selection,reordering, morphology. side, enriched system introduces timetime incorrect words expressions learned wrongly selected aligned examples.also performed poorly terms adding omitting spurious words, slightly worseningquality baseline system.approach general enough applied different scenarios. finally usedCommonCrawl, collection parallel texts automatically extracted Web,enrich general purpose baseline SMT system. three steps applied;selection also necessary case corpus noisy, due automaticextraction. Exactly classifiers trained FAUST corpus used identifyexamples automatically extracted target sentence better automatictranslation source provided baseline translation system. classifiers showedrobustness even noisy references used instead UEs evincing capacitydeal human automatically-generated noise.The conclusions drawn187fiFormiga, Barron-Cedeno, Marquez, Henrquez & Marinoadaptation experiment, shows methodology works well across differentcorpora sources types noise.Acknowledgmentsmajor part work carried authors worked TALP ResearchCenter - Universitat Politecnica de Catalunya. would like thank Nadir Durraniproofreading paper also anonymous reviewers valuable feedback.work partially funded Spanish Ministerio de Economa Competitividad,contracts TEC2012-38939-C03-02 TIN2012-38523-C02-02, wellEuropean Regional Development Fund (ERDF/FEDER) European CommunitysFP7 (2007-2013) program following grants: 247762 (FAUST, FP7-ICT-2009-4247762) 246016 (ERCIM Alain Bensoussan Fellowship).ReferencesAmbati, V., Vogel, S., & Carbonell, J. (2010). Active Learning Crowd-SourcingMachine Translation. Proceedings LREC, pp. 21692174.Axelrod, A., He, X., & Gao, J. (2011). Domain adaptation via pseudo in-domain dataselection. Proceedings 2011 Conference Empirical Methods NaturalLanguage Processing, pp. 355362, Edinburgh, Scotland, UK. Association Computational Linguistics.Barron-Cedeno, A., Marquez, L., Henrquez, Q. C. A., Formiga, L., Romero, E., & May,J. (2013). Identifying useful human correction feedback on-line machinetranslation service. Proceedings Twenty-Third International Joint ConferenceArtificial Intelligence, IJCAI 13, pp. 20572063. AAAI Press.Bertoldi, N., Cettolo, M., & Federico, M. (2013). Cache-based online adaptation machinetranslation enhanced computer assisted translation. Proc. MT Summit, pp. 3542.Bisazza, A., Ruiz, N., & Federico, M. (2011). Fill-up versus Interpolation MethodsPhrase-based SMT Adaptation. Proceedings IWSLT, pp. 136143.Blain, F., Schwenk, H., Senellart, J., & Systran, S. (2012). Incremental adaptation usingtranslation information post-editing analysis. Proceedings IWSLT 2012, pp.229236.Byrd, R. H., Lu, P., Nocedal, J., & Zhu, C. (1995). Limited Memory Algorithm BoundConstrained Optimization. SIAM Journal Scientific Computing, 16 (5), 11901208.Callison-Burch, C., Bannard, C., & Schroeder, J. (2005). Scaling phrase-based statisticalmachine translation larger corpora longer phrases. Proceedings 43rdAnnual Meeting Association Computational Linguistics, ACL 05, pp. 255262,Stroudsburg, PA, USA. Association Computational Linguistics.Callison-Burch, C., Koehn, P., Monz, C., Post, M., Soricut, R., & Specia, L. (2012). Findings 2012 Workshop Statistical Machine Translation. Proceedings188fiLeveraging Online User Feedback Improve SMTSeventh Workshop Statistical Machine Translation, pp. 1051, Montreal, Canada.Association Computational Linguistics.Cappe, O., & Moulines, E. (2009). On-line expectation-maximization algorithm latentdata models. Journal Royal Statistical Society: Series B (Statistical Methodology), 71 (3), 593613.Cettolo, M., Federico, M., Servan, C., & Bertoldi, N. (2013). Issues Incremental Adaptation Statistical MT Human Post-edits. Proceedings MT Summit XIVWorkshop Post-editing Technology Practice, pp. 111118.Denkowski, M., & Lavie, A. (2011). Meteor 1.3: Automatic Metric Reliable OptimizationEvaluation Machine Translation Systems. Proceedings 6th WorkshopStatistical Machine Translation, pp. 8591, Edinburgh, Scotland.European Comission - 7th Framework Program (2010). Matecat, FAUST Casmacat Projects. http://www.matecat.com http://www.faust-fp7.eu http://www.casmacat.eu. Accessed: 2015-02-01.FAUST (2013). Final report methods evaluation translation requests, system outputs, modelling user feedback.Tech. rep. D4.6,FAUST Feedback Analysis User-Adaptive Statistical Translation. ftp://svrftp.eng.cam.ac.uk/pub/pub/faust-pub/Deliverables/FAUSTD4.6.pdf.Formiga, L., Henrquez Q., C., Hernandez, A., Marino, J., Monte, E., & Fonollosa, J. (2012).talp-upc phrase-based translation systems wmt12: Morphology simplificationdomain adaptation. Proceedings Seventh Workshop Statistical Machine Translation, pp. 275282, Montreal, Canada. Association ComputationalLinguistics.Foster, G., Goutte, C., & Kuhn, R. (2010). Discriminative instance weighting domainadaptation statistical machine translation. Proceedings 2010 ConferenceEmpirical Methods Natural Language Processing, pp. 451459, Cambridge, MA.Association Computational Linguistics.Foster, G., & Kuhn, R. (2007). Mixture-Model Adaptation SMT. ProceedingsSecond Workshop Statistical Machine Translation, pp. 128135.Gale, W., & Church, K. (1993). Program Aligning Sentences Bilingual Corpora.Computational Linguistics, 19, 75102.Gao, Q., & Vogel, S. (2008). Parallel implementations word alignment tool. SoftwareEngineering, Testing, Quality Assurance Natural Language Processing, pp.4957, Columbus, Ohio. Association Computational Linguistics.Gimenez, J., & Marquez, L. (2010). Asiya: Open Toolkit Automatic Machine Translation (Meta-)Evaluation. Prague Bulletin Mathematical Linguistics, pp. 7786.Google Inc. (2015). Google Translate. http://translate.google.com. Accessed: 201502-01.Haddow, B., & Germann, U. (2011).Moses Incremental Training.http://www.statmt.org/moses/?n=Advanced.Incremental. Accessed: 2015-08-11.189fiFormiga, Barron-Cedeno, Marquez, Henrquez & MarinoHardt, D., & Elming, J. (2010). Incremental re-training post-editing smt. proc.AMTA 2010: Ninth conference Association Machine TranslationAmericas, Denver, CO. USA.Henriquez, C. (2014). Improving statistical machine translation adaptationlearning. Ph.D. thesis, Universitat Politecnica de Catalunya.Henrquez, C., Marino, J., & Banchs, R. (2011). Deriving translation units using smalladditional corpora. Proceedings 15th Conference European AssociationMachine Translation, pp. 121128.Hsu, C.-W., Chang, C.-C., & Lin, C.-J. (2003). practical guide support vector classification. Tech. rep., Department Computer Science, National Taiwan University.http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf.Joachims, T. (1999). Making large-scale support vector machine learning practical.Scholkopf, B., Burges, C. J. C., & Smola, A. J. (Eds.), Advances Kernel Methods,pp. 169184. MIT Press, Cambridge, MA, USA.Koehn, P. (2005). Europarl: Parallel Corpus Statistical Machine Translation.Machine Translation Summit X, pp. 7986, Phuket, Thailand.Koehn, P., & Hoang, H. (2007). Factored Translation Models. Proceedings 2007Joint Conference Empirical Methods Natural Language Processing Computational Natural Language Learning (EMNLP-CoNLL), pp. 868876, Prague, CzechRepublic.Lambert, P., de Gispert, A., Banchs, R., & Marino, J. B. (2005). Guidelines wordalignment evaluation manual alignment. Language Resources Evaluation,39 (4), 267285.Levenberg, A., Callison-Burch, C., & Osborne, M. (2010). Stream-based translation modelsstatistical machine translation. Human Language Technologies: 2010 Annual Conference North American Chapter Association ComputationalLinguistics, pp. 394402, Los Angeles, California. Association Computational Linguistics.Lopez, A. (2008). Tera-scale translation models via pattern matching. Proceedings22Nd International Conference Computational Linguistics - Volume 1, COLING08, pp. 505512, Stroudsburg, PA, USA. Association Computational Linguistics.Martnez-Gomez, P., Sanchis-Trilles, G., & Casacuberta, F. (2012). Online adaptationstrategies statistical machine translation post-editing scenarios. Pattern Recognition, 45 (9), 3193 3203. Best Papers Iberian Conference Pattern RecognitionImage Analysis (IbPRIA2011).Matecat (2015). Matecat official repository. https://github.com/matecat/MateCat. Accessed: 2015-07-24.Mathur, P., Mauro, C., & Federico, M. (2013). Online learning approaches computerassisted translation. Proceedings Eighth Workshop Statistical MachineTranslation, pp. 301308, Sofia, Bulgaria. Association Computational Linguistics.190fiLeveraging Online User Feedback Improve SMTMcnamee, P., & Mayfield, J. (2004). Character N-Gram Tokenization European Language Text Retrieval. Information Retrieval, 7 (1-2), 7397.Microsoft Inc. (2015). Bing Translator. http://www.bing.com/translator. Accessed:2015-02-01.Neal, R. M., & Hinton, G. E. (1998). view em algorithm justifies incremental,sparse, variants. Learning graphical models, pp. 355368. Springer.Nelder, J. A., & Mead, R. (1965). Simplex Method Function Minimization.Computer Journal, 7, 308313.NIST (2002). Automatic Evaluation Machine Translation Quality Using N-gram CoOccurrence Statistics. Tech. rep., National Institute Standards Technology.http://www.itl.nist.gov/iad/mig/tests/mt/doc/ngram-study.pdf.Och, F. J., & Ney, H. (2003). Systematic Comparison Various Statistical AlignmentModels. Computational Linguistics, 29, 1951.Ortiz-Martnez, D., Garca-Varea, I., & Casacuberta, F. (2010). Online learning interactive statistical machine translation. Human Language Technologies: 2010 Annual Conference North American Chapter Association ComputationalLinguistics, pp. 546554, Los Angeles, California. Association Computational Linguistics. http://www.aclweb.org/anthology/N10-1079.Ortiz-Martnez, D., Sanchis-Trilles, G., Gonzalez-Rubio, J., & Casacuberta, F. (2013).Progress report adaptive translation models. Tech. rep. D4.2, Casmacat: Cognitive Analysis Statistical Methods Advanced Computer Aided Translation.Padro, L., Collado, M., Reese, S., Lloberes, M., & Castellon, I. (2010). FreeLing 2.1: FiveYears Open-Source Language Processing Tools. Proceedings 7th LanguageResources Evaluation Conference (LREC 2010), La Valletta, MALTA.Papineni, K., Roukos, S., Ward, T., & Zhu, W.-J. (2002). BLEU: Method AutomaticEvaluation Machine Translation. Proceedings Annual MeetingAssociation Computational Linguistics (ACL).Pighin, D., Marquez, L., & May, J. (2012). Analysis (and Annotated Corpus) UserResponses Machine Translation Output. Proceedings Eight InternationalConference Language Resources Evaluation (LREC12), Istanbul, Turkey.Potet, M., Esperanca-Rodier, E., Blanchon, H., & Besacier, L. (2011). Preliminary experiments using users post-editions enhance smt system. Proceedings15th Conference European Association Machine Translation, pp. 161168.Pouliquen, B., Steinberger, R., & Ignat, C. (2003). Automatic Identification DocumentTranslations Large Multilingual Document Collections. Proceedings International Conference Recent Advances Natural Language Processing (RANLP2003), pp. 401408, Borovets, Bulgaria.Reverso-Softissimo (2015). Reverso Free online translator dictionary based SDLtechnology. http://www.reverso.net. Accessed: 2015-02-01.Riezler, S., & Maxwell, J. (2005). pitfalls automatic evaluation significance testing MT. ACL-05 Workshop Intrinsic Extrinsic Evaluation191fiFormiga, Barron-Cedeno, Marquez, Henrquez & MarinoMeasures Machine Tranlsation and/or Summarization (MTSE05) 43rd Annual Meeting Association Computational Linguistics, Ann Arbor, Michigan,USA.Schwenk, H., & Koehn, P. (2008). Large diverse language models statistical machinetranslation.. Proceedings IJCNLP, pp. 661666, Hyderabad, India.Sennrich, R. (2012). Mixture-Modeling Unsupervised Clusters Domain AdaptationStatistical Machine Translation. Proceedings 16th EAMT Conference.Simard, M., Foster, G. F., & Isabelle, P. (1992). Using cognates align sentences bilingual corpora. Proceedings Fourth International Conference TheoreticalMethodological Issues Machine Translation, pp. 6781.Simard, M., Goutte, C., & Isabelle, P. (2007). Statistical phrase-based post-editing.Human Language Technologies 2007: Conference North American ChapterAssociation Computational Linguistics; Proceedings Main Conference,pp. 508515, Rochester, New York. Association Computational Linguistics.Smith, J., Saint-Amand, H., Plamada, M., Koehn, P., Callison-Burch, C., & Lopez, A.(2013). Dirt cheap web-scale parallel text Common Crawl. Proceedings2013 Conference Association Computational Linguistics (ACL 2013),Sofia, Bulgaria. Association Computational Linguistics.Snover, M., Madnani, N., Dorr, B., & Schwartz, R. (2009). TER-Plus: Paraphrase, Semantic,Alignment Enhancements Translation Edit Rate. Machine Translation, 23 (2),117127.Witten, I., & Frank, E. (2005). Data Mining: Practical Machine Learning Tools Techniques (2 edition). Morgan Kaufmann, San Francisco, CA.192fiJournal Artificial Intelligence Research 54 (2015) 437-469Submitted 11/14; published 11/15Constraining Information Sharing ImproveCooperative Information GatheringIgor RochlinIGOR . ROCHLIN @ GMAIL . COMSchool Computer Science,College Management, Rishon LeZion, Israel.David SarneDAVID . SARNE @ GMAIL . COMDepartment Computer Science,Bar-Ilan University, Ramat-Gan, Israel.Abstractpaper considers problem cooperation self-interested agents acquiringbetter information regarding nature different options opportunities available them.sharing individual findings others, agents potentially achieve substantial improvement overall individual expected benefits. Unfortunately, well knownself-interested agents equilibrium considerations often dictate solutions far fullycooperative ones, hence agents manage fully exploit potential benefits encapsulated cooperation. paper introduce, analyze demonstrate benefit fivemethods aiming improve cooperative information gathering. Common five constrain limit information sharing process. Nevertheless, decrease benefit duelimited sharing outweighed resulting substantial improvement equilibrium individual information gathering strategies. equilibrium analysis given paper, which,important contribution study cooperation self-interested agents, enablesdemonstrating wide range settings improved individual expected benefit achievedagents applying five methods.1. Introductionmany settings agents benefit cooperating information gathering (Rochlin, Aumann,Sarne, & Golosman, 2014; Kephart & Greenwald, 2002; Rochlin, Sarne, & Mash, 2014; Hazon,Aumann, Kraus, & Sarne, 2013). example, consider two travel agents, city,plan participate international tourism conference, taking place highly traveleddestination. many airlines offering flights nearby destinations, setting priceaccording various external factors seat availability agreements airlinespartners. Similarly, depending airport arrival, one get conference train, bus,ferry, taxi combination different segments trip. meanstransportation may characterized different availability fare, depending, example,time day required. Checking feasibility cost different alternativestraveling conference, thus, potentially involves several time consuming activities,checking locations map checking companies web-sites routes, timetables,fares availability, thus incurs opportunity cost. Since agents benefitinformation gathers regarding different options getting conference,strong incentive share findings, i.e., execute information gathering process(hereafter denoted IGP) cooperatively.c2015AI Access Foundation. rights reserved.fiROCHLIN & ARNECooperative information gathering used many real-life applications different domains.example, consider two friends, interested buying big TV screen. friends visitshopping mall, together, checks offers different stores, eventuallymeet share findings. Alternatively, consider oil drilling company sending multipleagents explore possible drilling sites, order develop best site discovered. Similarlyposition needs filled, HR personnel interview candidates parallel recruitbest candidate found. Students jointly look references assignment receiveeventually use best source found them.benefits multi-agent cooperative information gathering twofold. First, sincealternative (hereafter termed opportunity) reviewed benefit many agents, relative costinformation gathering reduced, overall welfare increases. Secondly, taskpotentially divided according expertise different agents, expertise exists.1Cooperative information gathering seen type public goods game,agents contribute individual IGP collective result influences welfarethem. Like public goods games, costs IGP cooperative information gathering,basically born individual agents although benefits (better information case) societal.public goods games, general, inefficiencies private giving commonly occur wheneveragents self-interested (de Jong, Tuyls, & Verbeeck, 2008; de Jong & Tuyls, 2011). Similarly,shown prior work cooperative information gathering, carried self-interestedagents, result amount cooperation optimal fully cooperative case (Rochlinet al., 2014). particular demonstrated methods instruments (termed enhancers)easily proved beneficial fully cooperative case, actually negativeimpact, individual overall performance, self-interested case. enhancersincluded increase size group agents gather information jointly, increasenumber opportunities agent time potentially gather information on, improvement agents information gathering competence, increase levelheterogeneity individual information gathering competence group membersability communicate throughout process. Alas, prior work mostly descriptivesense outlined potential problems may arise cooperative information gatheringself-interested agent. research reported current paper aims provide solutionsproblems, form five somehow non-intuitive methods essentially constrain limitISP individual benefit participating agents substantially increase.five cooperative information gathering methods reported paper differ constraints put information sharing process (henceforth denoted ISP). first, denotedEnforced probabilistic information sharing prevents individual agents taking part ISPaccording probabilistic function. second, denoted Threshold restricted informationsharing, prevents agents found highly favorable values along individual IGPtaking part ISP. third, denoted Cost filtered information sharing, introducescost taking part ISP (where proceeds wasted returned agents)allows agents choose whether take part ISP not. fourth, denoted Random findingsharing, allows agents take part ISP, however restricts disclosingone values set known each, random. Finally, fifth, denoted Subgroup restricted information sharing, initially divides agents subgroups allows local ISPs,1. buyers cooperation, agents also benefit volume discount cooperation; howeverproperty holds specific domain.438fiC ONSTRAINING NFORMATION HARING MPROVE C OOPERATIVE NFORMATION G ATHERINGi.e., information sharing subgroup level. methods may seem counter intuitive,absence agents ISP restriction amount informationshared could harmful agents. Yet, many settings, use methodshighly beneficial. paradox embedded ISP option - sharinginformation benefits agents, fact information gathered going shared,discourages agents investing much resources individual IGP (Rochlin et al., 2014).Therefore, use methods individual benefit agent taking partISP decreases, however IGP carried agent individually becomes efficient.Therefore, intelligently managing tradeoff two, beneficial equilibriumachieved, improves overall individual benefits.paper provides comprehensive analysis individual information gathering strategiesused agents, given strategy others, different methods. Enforced probabilistic information sharing, Random finding sharing Subgroup information sharing methodsagents individual strategy proven similar structure one used standardcooperative information gathering method agent resume information gathering longbest value obtained far lower reservation value (a threshold), regardlessmuch information potentially gathered. Threshold restricted informationsharing method agents individual strategy proven threshold-based, however threshold changes function amount information potentially still gathered.Cost filtered information sharing method, individual strategies proven basedsingle reservation value determining benefit additional information gathering setintervals deciding whether take part ISP. allow characterization resulting equilibria. Using synthetic environments, numerically demonstrate five methodsresult substantial improvement agents individual expected benefit wide rangesettings.results contribute advancement theories cooperation MAS. discussed laterpaper, methods easily applied use benefit individuals planningengage cooperative information gathering designers multi-agent systems (MAS)cooperative information gathering likely take place.following section formally introduce cooperative information gathering model.Section 3 detail model analysis, equilibrium strategies different model variantsconsidered supply numerical examples benefit achieved using them.Related work reviewed Section 4, emphasizing uniqueness analysis providedpaper. Finally, conclude discuss directions future research Section 5.2. Modelmodel considers set K = {A1 , ..., Ak } fully-rational self-interested agents.agents needs gather information pertaining value (e.g., benefit) different opportunitiesaccess eventually choose one. values different opportunities prioriunknown information gathered one opportunity time. individual informationgathering problem, defined above, standard follows assumptions commonly usedliterature (Chhabra & Das, 2011; Kephart & Greenwald, 2002; Hazon et al., 2013; Rothschild, 1974;McMillan & Rothschild, 1994; Morgan & Manning, 1985). uncertainty associatedvalue opportunities available agent Ai modeled, costly information gathering439fiROCHLIN & ARNEliterature (McMillan & Rothschild, 1994; Burdett & Malueg, 1981; Carlson & McAfee, 1984;Lippman & McCall, 1976; Morgan, 1983), probability distribution function (p.d.f.) fi (x)(i.e., value opportunity individual IGP Ai drawn fi (x)),agents familiar (Tang, Smith, & Montgomery, 2010; Waldeck, 2008; Janssen, Moraga-Gonzalez,& Wildenbeest, 2005). Due resource consuming nature process considered costlysense revealing value opportunity incurs fixed cost, denoted ci . modelassumes agent Ai constrained number opportunities accessible agent,denoted ni . cost ci , distribution fi (x) number opportunities ni , definedagents level support settings different agents different skills capabilities.agent thus needs gather information, i.e., explore value opportunitieseventually pick one values revealed (i.e., recall permitted) (Carlson & McAfee, 1984;McMillan & Rothschild, 1994).settings opportunities applicable agents agents incentivecooperate information gathering sense individual findings eventually sharedothers. many ways share information, focus paper setupsISP takes place pre-specified time, agents completed individualIGPs needs decide opportunity choose. choice sharing findingsend individual IGPs mostly natural customary real life. importantly,alternative sharing information throughout process major setback senseindividual agent finds information sharing beneficial receiving end,i.e., one informed favorable opportunity found;reporting end, agent loses communication since report potentially encourageagents terminate individual information gathering. hand sharinginformation concluding individual IGPs always beneficial agent gainsinformation, time information discloses affect behavior othersthereafter since also already concluded IGPs.prior models cooperative information gathering, also assume that: (a) agentstruthful sense always report true values obtain;2 (b) agent Aifall-back value v0i , i.e., even becoming acquainted opportunity values (in casegathering information individually receiving others findings) agentpresumably benefit v0i ;3 (c) either opportunities agent check uniqueagents priori divide opportunities among assigned differentset. assumed information gathering costs opportunity values additive agentAi interested maximizing expected benefit, denoted EBi . benefit agent thereforebest value obtained group minus costs accumulated individually along agentsindividual IGP. Finally, assumed engaging cooperative information gatheringprocess agents priori acquainted probability distribution functions informationgathering costs agents, i.e., possible difference information availabledifferent agents throughout cooperative IGP findings findings others.cooperative information gathering model detailed found fullvariations prior literature (Hazon et al., 2013; Rochlin et al., 2014; Gatti, 1999; Carlson &2. truthfulness assumption commonly justified substantial potential reputation loss, easily enforceableusing fines.3. similarly, taking part ISP necessarily disclosing value absence better one.440fiC ONSTRAINING NFORMATION HARING MPROVE C OOPERATIVE NFORMATION G ATHERINGApplicationIndividual goalOpportunityValueProduct acquisitionMinimize individual expenseComplex service/productCost purchaseChoosingoildrillingsiteMaximizeoil revenuesminus costexploratorydrillsMinimizecost production R&DexpensesMaximize individual utility(grade minusindividualeffort)Potentialdrilling sitesAmountoil foundProductiontechnologyCost productionspecifictechnologyExpectedgradesourceusedR&DInformationSearch(studentsassignment)Informationsource (e.g.,online, textbook, libraryresource)Information gathering costTime spent findingoptions evaluatingTime resourcesspent exploratory drillsSource uncertaintyR&D cost specific technologyUncertainty concerning implementation aspectsdesired technologyTime spent evaluatingdifferentsourcesDifferences coveragetopic, relevance, accuracy, level detailsSellers competition, seasonal effects, service constraintsUncertainty regardingamount oildrilling siteTable 1: mapping different applications cooperative information gathering problem.McAfee, 1984).4 Taking travel agents example, given previous section, opportunitiesrepresent different alternatives reaching conference location value total cost.information gathering cost agents cost time needed explore alternatives.goal agent minimize expected expense, defined cost best alternativefound two plus cost time spent individually review different alternatives.Similarly, model mapped applications mentioned introduction (e.g.,see Table 1).3. Analysisdivide analysis according five cooperative information gathering enhancing methods.method, first determine individual optimal information gathering strategyagent taking part process, best response agents strategies. Then, showcollective behavior derived extract equilibrium set strategies.appropriate equilibrium concept depends define type space.define agents type specific vector values would encounter fully exhaustingIGP, appropriate concept would ex-ante Bayesian Nash equilibrium, since agentspriori unaware types information revealed (individually) alongIGP. However, prove paper definition, agents type would affectstrategy (strategies turn based thresholds set prior conducting IGP).Therefore, outcomes stochastic, one could theory build direct stochastic mappingindividual strategies global outcome therefore need gotype so. Therefore added value Bayesian Nash equilibriumcharacterization. equilibrium concept would subgame-perfection Stackelberg (wheresystem designer sets rules participation ISP, agents respond choosingoptimal strategies). result similar equilibrium characterization case.4. model variants consider task executed representative agent, acting behalf group,essence gathering costly information trading-off costs benefit same.441fiROCHLIN & ARNEFinally, demonstrate expected individual benefit agents improves,method used, compared standard cooperative IGP. order illustrate performanceachieved different methods, use setting agents homogeneous termsinformation gathering environment. Meaning agent samples opportunitiesprobability distribution function f (y) (i.e., f1 (y) = .. = fk (y) = f (y)), agentsconstrained number opportunities n sample overall (i.e., n1 = .. = nk = n)share information gathering cost c (i.e., c1 = .. = ck = c) fallbackv0 (i.e., v01 = .. = v0k = v0 ). setting quite common real-life often (and especiallyInternet age) people potentially access opportunities similar effort (e.g., timespent navigating web-site). example, travel agents running example, likelyagents access web-sites resources need used identifyinggathering information different options available getting conference,none them, trained experienced travel agent, specific advantageso. simplicity ease exposition figures, use f (y) uniform distributionfunction (between 0 1). stress even though homogeneous setting standardcostly information gathering literature (McMillan & Rothschild, 1994; Lippman & McCall, 1976),common real-life ISP argued above, use case merely illustration purposesresults concerning individual strategies equilibrium structures givenpaper based formal theoretical proofs.3.1 Enforced Probabilistic Information Sharingmethod agent Ai priori assigned probability PiIS which, completedindividual IGP, used determine whether allowed take part ISP. assumedagents priori acquainted probabilities PiIS used enabling information sharingagent. determination whether agent take part ISP must made proximitytime information actually shared requires enforcing mechanism sinceindividual IGP completed, agents obviously benefit taking part ISP,incur cost time improve best finding. Furthermore,since process takes place individual IGPs terminated, informationagent discloses influence individual IGP strategies used agents.enforcement easy achieve simple means. example, travel agents runningexample equivalent agents send findings designated secured server.server select eligible information sharing, according pre-defined probabilities,remove database information coming not. Then,server allow eligible information sharing access data stores.agents state throughout individual IGP represented subset opportunitiesalready gathered information, associated values, consequently remaining opportunities values still unknown. agents strategy thus mappingworld state choice {resume, terminate} resume suggests agent needsgather information additional opportunity (a random one, since opportunities available given agent priori alike) terminate means agent needs proceedISP. Theorem 1 proves state representation case compacted best valuefound far (including fallback v0i ), v, optimal strategy represented termssingle reservation value, independent number remaining opportunities.442fiC ONSTRAINING NFORMATION HARING MPROVE C OOPERATIVE NFORMATION G ATHERINGTheorem 1. Given probability distribution function maximal value obtainedagents take part ISP, denoted fi (x), agent Ai optimal individual information gatheringstrategy set reservation value ri v0i , ri solution to:5ci = PiISfi (y)(max(y, x) max(ri , x))fi (x)dxdy(1)y=rix=+ (1 Pi )(y ri )fi (y)dyy=riagent always choose gather information additional opportunity (if one available) best value obtained far ri otherwise proceed ISP.Proof. See appendix A.Theorem 1 specifies optimal strategy agent given strategy others. solutionset k equations similar (1), one agent Ai , provide set pure equilibriaform {ri |1 k} exist. mixed equilibrium case defined probabilitypi (v, j) assigned state (v, j), defining whether agent resume terminate information gathering state. may seem infeasible extract, based infinite numberstates (as value distributions continuous). Nevertheless, order solution hold,agents expected benefit actions (resume terminate information gatheringstate) must equal. Based optimality reservation-value rule, holdstates value v equals ri calculated according (1). However, due continuousnature v, probability actually reaching states satisfy condition zero, thusassigning probabilities effect agents. exceptionagents strategy beginning individual IGP. Here, state priori known(v0i , 0) hence adding probability actually gathering information one opportunitycontinuing according ri (or otherwise going straight ISP due indifference resuming terminating information gathering) actual effect others. Consequently,mixed equilibrium problem form:{(pi , ri )|1 k}pi probability agent Ai initiate individual IGP (0 pi 1) rireservation value used agent. solution considered stable (i.e., equilibrium),none agents find beneficial deviate individually. equilibrium purestrategies problem would require pi {0, 1} i. solution mixed equilibriumstrategy.individual strategy equilibrium defined complete form (i.e.,including probabilistic aspect), formulate fi (x) (the probability distribution functionmaximal value obtained along IGP agents take part ISP).purpose make use probability maximum value foundagents take part ISP, except Ai , smaller equal x, denoted Fi (x).5. Notice equation solution necessarily form v0i ri . case solutionequation (e.g., case substantial ci ), onwards, simply set ri = v0 information gatheringtake place.443fiROCHLIN & ARNEcalculation Fi (x) makes use probability maximum value obtained along IGPagent Aj (that chooses engage IGP uses rj ), less x, denoted Fjreturn (x), calculatedaccording to:60njreturnF(x)Fj(x) =jF (r )nj +j jx < v0jv0j x rjnj1Fj (rj )1Fj (rj ) (Fj (x) Fj (rj )) x > rj(2)case x < v0j trivial, v0j lower bound best value agent ends with.case v0j x rj , value nj opportunities must result valuex. x > rj two possible scenarios. first nj opportunities resultvalue reservation value rj , i.e., Fj (rj )nj probability. second,information gathering terminates right revealing value lth opportunityrj < < x (otherwise, < rj information gathering resume) former l 1values obtained smaller rj (otherwise lth opportunity reached). probabilitylatter case occurring (summing values l nj ) calculated using geometricnj1F (r )njseries l=1(Fj (x) Fj (rj ))Fj (rj )l1 = 1Fj j (rj j ) (Fj (x) Fj (rj )).probability distribution function maximum value obtained throughout agent Ai IGP,denoted fireturn (x), definition, first derivative Fireturn (x):fireturn (x) =d(Fireturn (x))dxThus, formulate probability maximum value foundagents taking part ISP, except Ai , smaller equal x, Fi (x):Fi (x) =(PjIS (pj Fjreturn (x) + (1 pj )) + (1 PjIS ))(3)Aj Kj=icalculation based probability given agent either: (a) take partISP (hence contribute value) or, (b) take part ISP best value obtainedindividual IGP x. probability (a) (1 PiIS ). calculate probability(b) first need calculate probability agents best value x.happen either agent initiated IGP best value obtain lower (orequal to) x, i.e., probability pj Fjreturn (x), agent opted IGP, i.e.,probability 1 pj . Therefore probability b given PjIS (pj Fjreturn (x) + (1 pj )).Consequently, probability distribution function fi (x) derivative Fi (x):dFi (x)fi (x) =dxenable us calculate expected benefit agent Ai agents use setstrategies {(pi , ri ) |1 k}. agent Ai chooses engage IGP expected benefit,6. maximum value found includes also fallback v0j . degenerate case Fj (v0i ) = 0 useFjreturn (x) = 0 v0i x rj .444fiC ONSTRAINING NFORMATION HARING MPROVE C OOPERATIVE NFORMATION G ATHERINGdenoted EBi (IGP ), given by:7EBi (IGP ) = PiISfireturn (y)max(v0i , y, x)fi (x)dxdy+y=x=1 Fi (ri )ni(1 PiIS )max(v0i , y)fireturn (y)dy ci1 Fi (ri )y=(4)first term right hand side expected maximum best value foundagent (i.e., associated distribution fireturn (y)) best value returnedagents (associated distribution fi (x)) agent Ai participates ISP (i.e., PiISprobability). second term expected best (i.e., maximum) opportunity-value foundagent along information gathering agent allowed take part ISP (i.e.,1 PiIS probability). last term expected cost incurred throughout IGP carriedn(ri )Ai , calculated as: ci nj=1(Fi (ri ))j1 = ci 1F1Fi (ri ) , number opportunitiesinformation gathered geometric random variable bounded ni , 1 Fi (ri ) successprobability IGP terminates upon receiving value greater ri (or ni opportunitiesexplored) probability value greater ri 1 Fi (ri ).agent opts execute individual IGP all, expected benefit, denoted EBi (IGP ), simply expected value maximum value returned agents, takingpart ISP, takes part process, otherwise v0i , i.e.:EBi (IGP ) = Pimax(v0i , x)fi (x)dx + (1 PiIS )v0i(5)x=point, everything needed formulate equilibrium stability conditions.set strategies {(pi , ri )|1 k} equilibrium following conditions hold:(a) every agent Ai pi = 0, EBi (IGP ) EBi ( IGP ).(b) every agent Ai pi = 1, EBi (IGP ) EBi ( IGP ).(c) every agent Ai 0 < pi < 1, EBi (IGP ) = EBi (IGP ).Therefore, order find equilibrium, stability 3k possible solutions type {(pi , ri )|1 k} differing value pi obtains (pi = 0, pi = 1 0 < pi < 1) needschecked. every combination, reservation values different agents probabilitypi agent uses non-pure mixed strategy (i.e., 0 < pi < 1) calculatedsolving set equations type (1) (one agent characterized pi = 0) EBi (IGP ) =EBi (IGP ) (one every agent Ai 0 < pi < 1). appropriate reservationvalues probabilities obtained given set, stability conditions need validated.note guarantee equilibrium actually exist (either pure mixed,since infinite number strategies). Also, guarantee one existsequilibria (i.e., multiple equilibria may exist). latter case, one7. none agents engage IGP (i.e., pj = 0 Aj = Ai ) fi (x) = 0 therefore expectedn(ri )benefit EBi (IGP ) calculated EBi (IGP ) = y= max(v0i , y)fireturn (y)dy ci 1F,1Fi (ri )ri solution ci = y=r (y ri )fi (y)dy (according single agents optimal IGP (Rochlin et al., 2014)),EBi (IGP ) = v0i .445fiROCHLIN & ARNEFigure 1: Enforced probabilistic information sharing - effect P individual expectedbenefit, different: (a) numbers agents, k, setting: c = 0.35 n = 5; (b)information gathering costs, c setting: k = 15 n = 4.equilibrium dominates others terms individual expected benefit everyagent obtains likely one used. Otherwise, way decidingequilibria one use, question included scope current paper.emphasize analysis generalizes analysis standard cooperative information gathering model (Hazon et al., 2013; Rochlin et al., 2014) sense latterspecific case first, probability agent allowed take part ISPone (i.e., PiIS = 1 1 k). Furthermore, probability agent allowedtake part ISP zero, solution obtained one known single-agentinformation gathering problem (McMillan & Rothschild, 1994) (since agent relies solelyvalues obtains throughout individual IGP).Figure 1 depicts agents individual expected benefit function probability PiISused, different group sizes (k) information gathering costs (c). setting usedhomogeneous setting described beginning section value PiISagents (i.e., PiIS = P i). model parameters set to: c = 0.35 n = 5(Figure 1(a)) k = 15 n = 4 (Figure 1(b)). depicted figure, maximum expectedbenefit (agent-wise, agents alike case) obtained participationagents ISP certain rather determined probabilistically (i.e., 0 < P < 1).typical pattern exhibited figure increase decrease expected individualbenefit probability P increases. explained follows. P = 0 agentactually executes individual IGP without information sharing others. P increases,agent relies agents findings. Thus, pi ri become lower, badgroup since everybody gains less participation agent ISP. However,time probability agent actually take part ISP increases, thus, overall,individual expected benefit increases. Nevertheless, value P , loss dueresulting decrease pi ri becomes dominant benefit due increasevalue P .446fiC ONSTRAINING NFORMATION HARING MPROVE C OOPERATIVE NFORMATION G ATHERINGAnother interesting behavior observed Figure 1 increase information gatheringcosts, c, increase number agents, k, results decrease value Pmaximizes expected benefit. may seem non-intuitive since greater informationgathering cost greater potential benefit achieved information sharingsimilarly, greater number agents greater chances obtaining favorable valuesISP. Therefore limiting information sharing settings high k c values mayseem unnatural. phenomena explained fact positive effect increaseP participation probabilities pi reservation value ri used agentequilibrium case, substantially poor begin with, greater loss dueuncertain information sharing.method requires agent either completely avoid fully participateISP, many variants considered, e.g., partially limiting information sharing.example, agent requested, probability, contribute informationgathered, without receiving group members information. Alternatively, agentallowed receive information however share gathered data. variants can,settings, result substantially superior performance illustrate Appendix B.3.2 Threshold Restricted Information Sharingmethod agents found highly favorable values along individual IGPprevented taking part ISP. implemented setting threshold ViIS ,agent Ai , requires agent opt-out ISP obtained value greater ViISindividual IGP. assumed agents priori acquainted thresholdsagents. travel agents running example take form Enforced probabilistic information sharing, slight modifications, e.g., agents send findingsdesignated secured server. server select eligible information sharing, accordingpre-set thresholds, remove database information comingnot. Then, server allow eligible information sharing access datastores.choice excluding agents findings greater threshold may seemcounter intuitive. Seemingly favorable findings, i.e., actually performed wellcontribute others punished. One may argue suitable choicewould set threshold agents found good values would excludedISP, thereby encouraging try harder. Nonetheless, also suggests discouragement agents IGPs greater expectations high valuesreported ISP. Obviously, time ISP ought take place, opting dominatedtaking part ISP, individually globally. agents benefit participationagents ISP. Moreover, fact require agents favorable valuestake part ISP seems intensify potential negative effect method discussedabove. Nevertheless, since agents may find situation requestedtake part information sharing, due decrease potential improvementencapsulated information sharing agents eventually take part it, likelyagent individually motivated towards efficient IGP.Overall, Threshold restricted information sharing method bit complicated enforce since agents may choose declare value different best found, effort447fiROCHLIN & ARNEFigure 2: schematic illustration optimal strategy Threshold restricted information sharing.take part information sharing. Nevertheless, whenever true value validated (e.g.,travel agents example, agent requested post receipt indicating way gotconference amount paid, ISP) method easily enforced usingfines.case, prove following paragraphs, agents strategy needs takeconsideration best value obtained thus far, also number opportunitiesinformation already gathered. whenever value v > ViIS encountered,whereby agent excluded ISP, agent still benefit resuming individualIGP, benefit additional information gathering depends number remainingopportunities.structure agents optimal strategy, given strategy others, given Theorem2.Theorem 2. Given probability distribution function maximal value obtainedagents take part ISP, fi (x), number opportunities informationalready gathered, j ni , agent Ai optimal individual information gathering strategydescribed pair (ri (j), riresume ), v0i ri (j) ViIS riresume (see Figure 2),where:)(resume(y r)fi (y)dy(6)ri= max Vi , r|ci =y=rri (j) solution to:fi (y)(max(y, x) max(ri (j), x))fi (x)dxdyy=ri (j)x=+fi (y)(EB j+1(y) max(ri (j), x))fi (x)dxdyViISci =y=ViIS(7)x=EB ji (y) given by:{vjEBi (v) =ci + y=EB j+1(max(v0i , y, v))fi (y)dyriresume v j > niv < riresume j ni(8)Given best value obtained far, v, Agent Ai resume IGP v < ri (j) ViIS <v riresume otherwise terminate (and proceed ISP v ViIS ).448fiC ONSTRAINING NFORMATION HARING MPROVE C OOPERATIVE NFORMATION G ATHERINGProof. See appendix C.Intuitively, reservation value riresume used determine IGP resumedcases favorable value v > ViIS found agent own.reservation value ri (j) used determine IGP resumed v ViIS , i.e.,agent still potentially take part ISP. Resuming IGP latter case leadbetter values, however time also lead exclusion ISP, caseagent end own. Since fallback case finding v > ViIS dependsnumber remaining opportunities j, use different reservation value ri (j) j value.case riresume = ViIS , benefit agent resume IGP value v > ViISfound. case ri (j) = r j.again, solution set equations consisting (6-8) provide set pureequilibria form {(ri (1), .., ri (ni )), riresume |1 k}, exist. Similarly,considerations given Section 3.1, mixed equilibrium case form:{(pi , (ri (1), .., ri (ni )), riresume )|1 k}.equilibrium analysis case generally resembles one given 3.1, calculation Fireturn (x), probability maximum value obtained agent Aiindividual IGP (including v0j ) less x substantially complicated. orderformulate Fireturn (x) use Fireturn (x, v, j) denote probability agent Ai obtainmaximum value x below, given current state (v, j), v best value obtainedfar IGP (including v0i ) j number opportunities informationgathered. function Fireturn (x, v, j) calculated recursively according to:v>x )0(resumereturn1v x ri (j) < v Vi riv j = niFi(x, v, j) =return (x, max(v , y, v), j + 1)f (y)dyFotherwise0y=(9)case x < v trivial since maximum value agent obtain leastv. Therefore, probability obtaining x zero. Similarly, ri (j) < v ViISriresume v additional opportunities (j = ni ) agent inevitablyterminate IGP (according Theorem 2) maximum value obtainedv. case, v x function obtains 1. cases, IGP resumes, henceprobability given recursively based new state (x, max(v, y), j + 1) agentgathering information one additional opportunity. Using Fireturn (x, v, j) calculateprobability maximum value obtained agent Ai individual IGPless (or equal to) x, as: Fireturn (x) = Fireturn (x, , 0).Thus, formulate probability maximum value provided agent AiISP less x, denoted Fireturn (x):0x < v0ireturnreturnreturnF(x) + (1 Fi(Vi )) v0i x ViISFi(x) =(10)1otherwisecase x < v0i trivial, v0i lower bound best value agent ends with.case x ViIS satisfied either Ai best value less x (in case take449fiROCHLIN & ARNEpart ISP since x ViIS ), i.e., probability Fireturn (x), agent take partISP, i.e., probability 1Fireturn (ViIS ). case x > ViIS straightforwardsince agent Ai take part ISP best value lower ViIS , probabilityobtaining value v (where x > ViIS ) 1.Using Fireturn (x), calculate function Fi (x) (a modification (3)):Fi (x) =(pj Fjreturn (x) + (1 pj ))(11)Aj Kj=iprobability distribution function fi (x) first derivative Fi (x) before. Similarly,probability distribution function fireturn (x) first derivative Fireturn (x).turn calculating expected cost incurred throughout IGP carried agentAi , denoted ECi . order calculate ECi use ECi (v, j) denote expected costagent Ai , state (v, j), v best value obtained gathering information jopportunities. value ECi (v, j) calculated recursively according to:{ECi (v, j) =0ri (j) v < ViIS riresume v j = nici + y= ECi (max(v0 , y, v), j + 1)fi (y)dyotherwise(12)first case agent unavoidably terminates IGP (according Theorem 2).second case where, IGP resumes, hence expected cost given recursively basednew state (max(v, y), j + 1) agent gathering information one additionalopportunity. allows us calculate ECi (x), as: ECi (x) = ECic (, 0).enable us calculate expected benefit agent Ai agents use setstrategies {(pi , (ri (1), .., ri (ni )), riresume )|1 k = j}. agent Ai choose engageIGP expected benefit, EBi (IGP ), given by:max(v0i , y)fireturn (y)dy(13)EBi (IGP ) = ECi ++ViISfireturn (y)y=y=ViISmax(v0i , y, x)fi (x)dxdyx=similar (4), except differentiation second third termsright according ViIS rather PiIS .agent opts gather information all, expected benefit, EBi (IGP ),simply expected value maximum value returned agents taking part ISP:EBi (IGP ) =max(y, v0i )fi (y)dy(14)y=equilibrium stability conditions remain Section 3.1, replacing calculation EBi (IGP ) EBi (IGP ) (13) (14). former method, guaranteeequilibrium actually exist (either pure mixed) one existsequilibria. Also, method presented above, analysis Threshold restrictedmethod generalizes analysis standard cooperative information gathering model450fiC ONSTRAINING NFORMATION HARING MPROVE C OOPERATIVE NFORMATION G ATHERINGFigure 3: Threshold restricted information sharing - effect V individual expected benefit, different information gathering costs, c, setting: k = 2 n = 1.sense latter specific case threshold set taking part ISP ViISi. Similarly, ViIS i, solution obtained one knownsingle-agent information gathering problem (McMillan & Rothschild, 1994).Figure 3 illustrates agents individual expected benefit function thresholds ViISused, different information gathering costs (c). setting used homogeneous settingdescribed beginning section, parameters c = 0.4 n = 1. values ViISsimilar agents (i.e., ViIS = V i). depicted figure, maximum expectedindividual benefit obtained value threshold excluding agents ISPis, cases, substantially small, leaving many favorable findings outside ISP. typicalpattern exhibited figure similar one depicted Figure 1: increasedecrease expected individual benefit threshold V increases. explainedfact V = 0 agent actually executes individual IGP without sharing informationothers. V increases, agent relies information gathered agentsconsiderations explained 3.1 regarding tradeoff negative effectpi ri positive effect chance actually taking part ISP hold.3.3 Cost Filtered Information Sharingmethod introduces cost cIS agent incurs chooses take part ISP. example,travel agents running example equivalent agents interestedtaking part ISP present evidence donating fixed amount money charity,prerequisite accessing designated secured server used sharing. Unlike twoprior methods, agents get decide whether opt-out information sharing; hencerequire enforcement whatsoever. require, however, means introducing costISP, e.g., donation setting meeting place sharing informationparticipant need spend time money getting there.451fiROCHLIN & ARNEassumed agents priori acquainted ISP participation costs agents.introduction cost (that eventually returned agents) requires appropriatebalance form compensation agents taking part ISP. Withoutcompensation, agent willing take part ISP, proven following proposition.Proposition 1. agents incur cost taking part ISP, absencecompensation taking part ISP, none agents take part ISP.Proof. Consider highest value v known agents, completing individual IGP, warrants participation agent ISP. show absenceappropriate compensation agent, value v cannot hold since none agentscontribute value greater v ISP, agent found v gain anythingISP however incur cost; consequently choose take part ISP.One option compensate agents taking part ISP offer agent bestvalue takes part ISP compensation B. amount B collected agents(e.g., equal shares) prior IGP, collected considered sunk costagents strategies become affected chance receiving bonus B. structurebest response strategy individual agent case, given strategy others, givenTheorem 3.Theorem 3. Given probability distribution function maximal value obtainedagents take part ISP, fi (x), agent Ai optimal individual information gathering strategydescribed pair (ri , RiIS ), RiIS set intervals xRiIS x v0i :xfi (y)dy(15)(y x)fi (y)dy + Bcy=y=xset value ri v0i , ri solution to:ci = (EBi (y) EBi (ri ))fi (y)dy(16)y=riEBi (v) given by:vvEBi (v) = cIS + B y= fi (y)dy+ y= max(v0i , y, v)fi (y)dyv/ RiISotherwise(17)agent resume individual IGP long value found far ri ,otherwise terminate IGP. Upon terminating IGP (or obtaining valueopportunities) agent participate ISP best value found individualIGP one intervals set RiIS otherwise opt taking part ISP.Proof. set RiIS defined (15) contains values v( expected benefit)fromtaking part ISP - calculated potential value improvement,(y x)fi (y)dy plusy=x452fiC ONSTRAINING NFORMATION HARING MPROVE C OOPERATIVE NFORMATION G ATHERINGxexpected compensation B y= fi (y)dy, independent reservation value ri usedagent - greater cost cIS incurred. remainder proof, concerningoptimality reservation-value-based strategy correctness (16) oneprovided Theorem 1, differing way expected benefit information gatheringresumed calculated.solution set equations consisting (16)-(17) agent provide setpure equilibria form {(ri , RiIS )|1 k}, exist. considerations givenSection 3.1, mixed equilibrium case form {(pi , ri , RiIS )|1 k}.equilibrium analysis Cost filtered information sharing follows analysis givenprevious methods, therefore provide differences. calculation Fireturn (x)remains (2). probability distribution function fireturn (x) first order derivativeFireturn (x). function Fireturn (x), calculated modification (10):Fireturn (x) = Fireturn (x) +fireturn (y)dyyxy R/ iISconsequently function Fi (x) given by:Fi (x) =(pj Fjreturn (x) + (1 pj ))Aj Kj=iprobability distribution function fi (x) first order derivative Fi (x) before.enable us calculate expected benefit agent Ai agents use setstrategies {(pj , rj , RjIS )|1 j k = j}. agent Ai choose engage IGPexpected benefit, EBi (IGP ), given by:1 Fi (ri )ni+ EBi (max(y, v0i ))fireturn (y)dy(18)EBi (IGP )=ci1 Fi (ri )y=first term expected cost incurred throughout IGP carried Ai , calculated as:n(ri )ci nj=1(Fi (ri ))j1 = ci 1F1Fi (ri ) , number opportunities information gathered geometric random variable bounded ni , 1 Fi (ri ) success probability.second term expected benefit executing IGP. agent opts gather information all, expected benefit, EBi (IGP ), simply maximum expectedvalue maximum value returned agents v0i , agent choose takepart ISP:EBi (IGP ) = EBi (v0i )(19)equilibrium stability conditions remain Section 3.1, replacing calculation EBi (IGP ) EBi (IGP ) (18) (19). former methods, guaranteeequilibrium actually exist (either pure mixed) one existsequilibria. Also, methods presented above, analysis cost filtered methodgeneralizes analysis standard cooperative information gathering model senselatter specific case cIS = B = 0. Similarly, B = 0 solution obtained453fiROCHLIN & ARNEFigure 4: Cost filtered information sharing - effect cIS individual expected benefit,different information gathering costs, c setting: k = 2, n = 3 B = 0.04.one known single-agent information gathering problem (regardless valuecIS , based Proposition 1).Figure 4 illustrates agents individual expected benefit function cost cIS used,different information gathering costs (c). setting used homogeneous setting describedbeginning section, using parameters k = 2, n = 3 B = 0.04. illustratedfigure, maximum expected individual benefit obtained substantial cost incurredtaking part ISP. typical pattern exhibited figure similar one depictedFigures 1 3, explained similar considerations.3.4 Random Finding Sharingmethod agent Ai , completed individual IGP, allowed take partISP, however restricted disclose one values come across IGP,randomly selected. downside restriction obvious - cases agentsbenefit best individual findings rather become exposed small, necessarilyoptimal, subset information gathered. Still, demonstrate following paragraphs,settings individual performance improves. travel agents running exampleimplementation method quite straight forward relies, before, agentssend findings designated secured server used sharing. difference, however,server pick single random finding agent discard restfindings. Here, again, enforcement necessary since individual agent benefitdisclosing information required disclose.structure best response strategy individual agent case, given strategyothers, given Theorem 4.Theorem 4. Given probability distribution function maximal value obtained ISPbased reports agents, denoted fi (x), agent Ai optimal individual information454fiC ONSTRAINING NFORMATION HARING MPROVE C OOPERATIVE NFORMATION G ATHERINGgathering strategy follow reservation value ri v0i , ri solution to:ci =fi (y)(max(y, x) max(ri , x))fi (x)dxdyy=ri(20)x=agent always choose gather information additional opportunity (if one stillavailable) best value obtained far ri otherwise proceed ISP.Proof. proof similar one given Theorem 1, differing way expectedbenefit gathering information additional opportunity calculated.solution set k equations type (20), one agent, provide set pureequilibria form {ri |1 k} exist. considerations given Section 3.1,mixed equilibrium case form {(pi , ri )|1 k}.equilibrium analysis method follows one given 3.1, except Fireturn (x)used 3.2. function Fireturn (x) given (2). probability distribution functionfireturn (x) first order derivative Fireturn (x). order formulate Fireturn (x) usedifferent state definition Fireturn (x, v, j, l). state (v, j, l) defined accordingnumber values x obtained agent Ai gathering information j opportunities, denoted l, best value obtained far (including v0i ), v. function Fireturn (x, v, j, l)calculated recursively according to:0x < v0ilv ri ni = jjxFireturn (x, v, j, l) =(21)returnF(x,max(y,v),j+1,l+1)f(y)dyotherwisey=+ F return (x, max(y, v), j+1, l)f (y)dyy=xcase x < v0i trivial, v0i lower bound best value agent ends with.second case (21) straightforward best value obtained far v ri ,additional opportunities (ni = j), agent necessarily terminates IGP (accordingTheorem 4). cases, l values total j values x, probabilityAi return value x jl . cases, IGP resume; hence probabilitygiven recursively based new state (x, max(y, v), j + 1, l + 1) case new value obtainedx (x, max(y, v), j + 1, l) otherwise.Thus, formulate Fireturn (x):Fireturn (x) = Fireturn (x, , 0, 0)(22)consequently Fi (x) given (11) probability distribution function fi (x) firstorder derivative Fi (x) before.enable us calculate expected benefit agent Ai agents use setstrategies {(pj , rj )|1 j k = j}. agent Ai choose engage IGP expectedbenefit, EBi (IGP ), given by:1 Fi (ri )niEBi (IGP ) = ci+fireturn (y)max(v0i , y, x)fi (x)dxdy(23)1 Fi (ri )y=x=455fiROCHLIN & ARNEFigure 5: Random finding sharing Standard information sharing (according Rochlin et al.,2014) function of: (a) information gathering costs, c, setting: k = 5 n = 3;(b) number agents, k, setting: c = 0.1 n = 3.agent opts gather information all, expected benefit, EBi (IGP ),simply expected value maximum value returned agents:EBi (IGP ) =max(v0i , x)fi (x)dx(24)x=equilibrium stability conditions remain Section 3.1, replacing calculation EBi (IGP ) EBi (IGP ) (23) (24). former method, guaranteeequilibrium actually exist (either pure mixed) one existsequilibria.Figure 5 depicts agents individual expected benefit function information gatheringcosts c (left graph) number agents k (right graph). setting used homogeneoussetting described beginning section, parameters k = 5 n = 3 (Figure 5(a))c = 0.1 n = 3 (Figure 5(b)). graph depicts performance Random findingsharing standard non-restricted sharing method (according Rochlin et al., 2014).figure shows random finding sharing strategy dominates standard information sharingstrategy, far expected individual benefit concerned.3.5 Subgroup Restricted Information Sharingmethod agents divided sub groups share findings separately, i.e.,agent executes individual IGP separately end subgroup carry separateISP.Formally, considerwthe case |K| agents divided w subgroups {K1 , , Kw }( wK=jj=1j=1 Kj = K). travel agents running example doneproviding sub-group designated server serve subgroup members or,physical environments, setting different meeting places sharing information grouppartitioned sub-groups.456fiC ONSTRAINING NFORMATION HARING MPROVE C OOPERATIVE NFORMATION G ATHERINGFigure 6: Subgroup restricted information sharing - individual expected benefit functionnumber subgroups, w, setting: c = 0.45, k = 20 n = 10.best response strategy individual agent Aji subgroup Kj = {Aj1 , . . . Aj|kj | } Kwell equilibrium analysis within subgroup level given (Rochlinet al., 2014), agents within subgroup fully share findings. optimal strategythus obtained checking expected benefit possible divisions K subgroupsselecting partition associated highest expected benefit. computational complexityevaluating subgroups combinatorial number agents. Although focuspaper computational aspects rather analyzing structure equilibriumcooperative strategies, note ISP settings computational complexity becomesnon-issue since number agents taking part ISP relatively small.note method results similar performance (Rochlin et al., 2014)number subgroups w = 1 (i.e., k agents take part ISP one group). Similarly,number subgroups w = |K| (i.e., subgroup contains one agent) solution obtained one known single-agent information gathering problem(McMillan & Rothschild, 1994).Figure 6 illustrates agents individual expected benefit function number subgroups used (w). setting used homogeneous setting described beginningsection, using parameters k = 20, n = 10 c = 0.45. graph uses partitioning equalsize subgroups, i.e., w obtains values {1, 2, 4, 5, 10}. depicted figure, maximumexpected individual benefit obtained example number subgroups w = 2.4. Related Workmodel analyzed paper based two important concepts: multi-agent cooperationcostly information gathering. Multi-agent cooperation shown widely effectivebetter achieving agents individual goals (Stone & Kraus, 2010) improve performance measures (Kraus, Shehory, & Taase, 2003; Dutta & Sen, 2003), especially differencesagents capabilities, knowledge resources agent incapable completing457fiROCHLIN & ARNEtask (Stone & Kraus, 2010; Saad, Han, Debbah, & Hjorungnes, 2009; Conitzer, 2012;Breban & Vassileva, 2001). also main driving force behind many coalition formation models area cooperative game theory MAS (Shehory & Kraus, 1998). Yet, majoritycooperation coalition formation MAS-related research tends focus way coalitionsformed consequently concerns issues optimal division agents disjointexhaustive coalitions, division coalition payoffs enforcement methods interaction protocols. coalition formation coordination models widely found electronicmarket domain, work domain emphasizes mechanisms forming cooperationpurpose aggregating demands order obtain volume discounts (Tsvetovat, Sycara, Chen, &Ying, 2000; Yamamoto & Sycara, 2001; Sarne & Kraus, 2003). Several authors consideredproblem determining strategy group formed (Ito, Ochi, & Shintani, 2002; Sarne,Manisterski, & Kraus, 2010; Rochlin, Sarne, & Zussman, 2011; Mash, Rochlin, & Sarne, 2012),however focus mostly fully-cooperative agents. None works considered cooperation problem group self-interested agents costly exploration settings findingsbenefit agents.Group-based cooperation self-interested agents also found public goods gamesallocation games general (Aumann, 1998; Nagel & Tang, 1998; McKelvey & Palfrey, 1992;de Jong et al., 2008; de Jong & Tuyls, 2011). Common games accordingequilibrium agent individually opt cooperation soon possible investminimum allowed. Therefore research cooperation domain mostly studiedrepeated games (Selten & Stoecker, 1986) settings bounded-rational participants (e.g., people) cooperation extent commonly exhibited. Much effort placeddeveloping reciprocity-based mechanisms, e.g., tit-for-tat (Axelrod, 1984) facilitate cooperationeven agents find momentarily beneficial act selfishly. way, long-term considerationsoverride short-term greedy behavior. Many extended basic mechanism support variousvariants model, asymmetric costs, heterogeneously repeating instances factors (Sen, 1996). works dealt inducing cooperation non-repeated settings showingrewards somewhat less effective sanctions enforcing cooperation (Walker & Halloran, 2004). main difference public goods games work casepublic goods fact information lead better economic decisions. Obtaininginformation requires carrying active sequential information gathering process. Therefore,settings much room individual information gathering, extent, evenothers free riders. Moreover, simplistic settings used public goods gamesissue information sharing ways carried (when considering self-interested agents)becomes irrelevant.second concept upon paper relies, i.e., costly information gathering, greatimportance central source supply agent full immediate reliable information environment state agents (Sarne & Aumann, 2014). general,introduction information gathering costs MAS models leads realistic descriptionenvironments. agents typically required invest/consumeresources order obtain information concerning opportunities available environment(Bakos, 1997; Sarne & Kraus, 2008; Kephart & Greenwald, 2002; Rochlin & Sarne, 2013; Rochlin,Sarne, & Zussman, 2013; Manisterski, Sarne, & Kraus, 2008).Optimal strategies settings individuals need search applicable opportunityinformation gathering costly widely studied (Grosfeld-Nir, Sarne, & Spiegler,458fiC ONSTRAINING NFORMATION HARING MPROVE C OOPERATIVE NFORMATION G ATHERING2009; Elmalech, Sarne, & Grosz, 2015; Elmalech & Sarne, 2012), prompting several literature reviews (Smith, 2011; McMillan & Rothschild, 1994; Morgan & Manning, 1985). models,often termed costly search models economic search models developedpoint total contribution referred search theory. years, manyinformation gathering model variants considered, focusing different aspectsmodel, decision horizon (finite versus infinite) (Lippman & McCall, 1976), presence recall option (McMillan & Rothschild, 1994), option disambiguate noisy signals(Chhabra, Das, & Sarne, 2014a; Alkoby, Sarne, & Das, 2015; Chhabra, Das, & Sarne, 2014b),distribution values extent findings remain valid along process (Landsberger& Peled, 1977). particular, models integrated study strategic information platforms (Hajaj, Hazon, Sarne, & Elmalech, 2013; Sarne, 2013; Hajaj & Sarne, 2014).Another strand search-based models two-sided search (Sarne & Arponen, 2007; Hendrix &Sarne, 2007) deals distributed (search-based) formation pairwise (or general size)partnerships (Nahum, Sarne, Das, & Shehory, 2015). analysis models deriveequilibrium considerations, different model reflectcooperative aspect.Many cooperative information gathering models studied, extending theoriesmulti-agent (or multi-goal) environments (Sarne & Kraus, 2005). Examples include, among others,attempt purchase several commodities facing imperfect information concerning pricesoperating several robots order evaluate opportunities different locations. worksdiffer either consider fully cooperative agents attempt maximizeoverall utility (Sarne et al., 2010; Gatti, 1999; Burdett & Malueg, 1981; Carlson & McAfee, 1984),thus lack equilibrium considerations, assume agents IGP constrainedfindings agents, rather augmented/improved findingscase (Rochlin, Sarne, & Laifenfeld, 2012; Rochlin & Sarne, 2014b). Consequently constitute substantially different equilibrium strategies. Models consider cooperative informationgathering, rely assumptions similar (e.g., Rochlin et al., 2014; Hazon et al., 2013),focus primarily extraction equilibrium strategies investigate influencedifferent model parameters agents performance equilibrium. None works, however, suggested methods improving cooperative information gathering settings,kind suggest analyze paper.broadly, problem seen part field planning uncertainty, hencerelated Markov decision processes (MDP) (Bellman, 1957; Puterman, 1994) decentralizedMarkov decision processes (Bernstein, Givan, Immerman, & Zilberstein, 2002). modelsgoal maximize expected cumulative reward, also objective case. Alas,use MDPs case complicated continuous nature value probability distributionfunctions. importantly, analysis proofs result threshold-based (or interval-based)solutions simpler terms strategy state representation derivedsubstantially lesser complexity compared solving via MDPs.Finally, note non-intuitive findings whereby methods essentially limit information sharing cooperation actually positive impact self-interested case follows,spirit, earlier results settings. particular, ones shown socalled inefficiencies increase market performance, certain circumstances. example,Masters (1999) shows increase minimum wage, often considered inefficiencyeconomics, positive employment effects. transportation economics (e.g., congestion459fiROCHLIN & ARNEgames) equilibrium frequently overall optimum. cases, shown taxation change equilibrium desirable one (Penn, Polukarov, & Tennenholtz, 2009b,2009a; Fotakis, Karakostas, & Kolliopoulos, 2010). Similarly, taxes facilitate desirableequilibria Boolean games (Endriss, Kraus, Lang, & Wooldridge, 2011) centralized matching schemes (Anshelevich, Das, & Naamad, 2013). work show somewhat similarphenomenon also occurs context cooperative information gathering, though modelanalysis are, course, totally different mentioned.5. Discussion Conclusionsdemonstrated Section 3, five methods proposed analyzed papersubstantially increase benefit self-interested agents achieve information sharinggathering information cooperatively. five methods based different restrictionmade agents ability willingness take part ISP. Intuitively restrictions mayseem negative effect performance. Yet, since agent gains less informationsharing itself, greater incentive invest resources individual information gathering,hence overall performance improves.results suggest important inputs designers markets systems cooperativeinformation gathering applicable, enabling predict strategies usedresulting system performance. primarily facilitate proper design systemdetermination elements included systems orderachieve specific goals promote certain behavior. particular, introductionseemingly non-beneficial elements may actually productive. note paper generallyattempt find optimal parameter values method (e.g., probability, grouppartitioning, threshold cost taking part information sharing, payment receivedagent associated best value), since concept optimality senseproperly defined. Indeed settings equilibrium solution preferredagents (e.g., examples given former sections, agents homogeneous)choice parameter values clear. Nevertheless general, possible certain valuepreferred one agents whereas others prefer another. latter case rolesystem designer decide parameters based goals.numerous extensions model considered. straightforward require minor changes analysis. example, agents buyersinterested single unit product searching for, changerequired individual strategy equations multiplication expense purchasing itemnumber items agent interested. Another example compositionseveral methods. example, case Subgroup restricted information sharing,subgroups adopt four methods subgroup level. extensions,much interest, complex analyze. example, consider model agentscontinuously share findings along individual IGPs. case, discussed Section 1, essential first define method provide incentive agents sharefindings despite negative influence terms discouraging othersinformation gathering.460fiC ONSTRAINING NFORMATION HARING MPROVE C OOPERATIVE NFORMATION G ATHERINGAcknowledgmentsPreliminary results work appeared Proceedings Thirteenth International Conference Autonomous Agents Multiagent Systems (Rochlin & Sarne, 2014a). authors wouldlike thank Barbara Grosz insightful comments helped improve paper substantially.first coauthor student Bar-Ilan University research reported papercarried out. research partially supported ISRAEL SCIENCE FOUNDATION (grantNo. 1083/13) ISF-NSFC joint research program (grant No. 2240/15).Appendix A. Proof Theorem 1Proof. first prove reservation-value nature optimal strategy. continueinductive proof, show reservation value used agent remain stationary alongIGP calculated according Equation 1.absence new information along IGP, agents strategymapping S(x, j) {terminate, resume}, x set values obtained far (including v0i ) j number opportunities information already gathered. Sinceagent interested merely maximum opportunity value, strategy affectedmaximum value x, hence strategy defined S(v, j) {terminate, resume},v maximum value x. Obviously, according optimal strategy agent needsresume IGP upon reaching state (v, j) true state (v , j)v < v. Similarly, according optimal strategy exploration terminate state (v, j)hold state (v , j) v > v. Therefore, given numberopportunities information gathered, j, optimal individual IGP strategyagent Ai characterized reservation value rij agent resume IGPbest value obtained far rij otherwise terminate IGP.begin case j = ni 1. best value obtained thus far agent Ai vgathering information one last opportunity, according strategy, incur cost ciexpected value agents obtain be:PiISfi (y)y=+ (1 PiIS )(max(y, v, z)fi (z))dzdyz=max(y, v)fi (y)dyy=first term relates case agent Ai participate ISP, probabilityPiIS , whereas second term relates case required opt ISP,i.e., probability 1 PiIS (where new value obtained agentz best value obtained agents IGP).hand, terminating IGP point result benefit:PiISmax(v, z)fi (z)dz + (1 PiIS ) vz=461fiROCHLIN & ARNETherefore, agent gather information last opportunity if:Pimax(v, z)fi (z)dz + (1 PiIS ) v <z=PiISfi (y)(max(y, v, z)fi (z))dzdyy=z=+ (1 Pi )max(y, v)fi (y)dy ci(25)y=left hand side equation captures expected benefit individual IGP terminatedright hand side captures expected benefit information gathered last opportunity. terms distinguish case agent Ai participates ISP i.e.,probability PiIS , allowed to. Using simple mathematical manipulationsobtains:0 < Pifi (y)(max(y, z) max(v, z)fi (z))dzdy(26)y=vz=+ (1 PiIS )(y v)fi (y)dy ciy=vvalue v (26) becomes equality fact value ri according (1). Therefore, since right hand side (26) decreasing function v, agents gatherinformation last opportunity whenever value v less value r according(1). establishes first part proof.assume ri (according (1)) holds j > j, j, consideragents decision regarding gathering information one opportunity, best valueobtained thus far v number opportunities values already obtainedj. v > ri v0i agent gathers information one additional opportunity, regardlessvalue obtained next definitely terminate individual IGP thereafter (as alreadyvalue greater ri according induction assumption optimal strategy thereafterreservation value ri ). Therefore benefit obtained information gathering givenby:Pifi (y)(max(y, z) max(v, z)fi (z))dzdyy=z=+ (1 PiIS )(y v)fi (y)dy ciy=Alas, since latter term decreases v increases, obtains zero v = ri (according (1)),since v > ri v0i term obtains negative value, hence additional information gatheringcannot preferred choice.Similarly, consider case v0i v < ri j agent chooses gather additional information. expected benefit resuming information gathering necessarilygreater resuming state (v, j > j). However, according induction assumptionagent resume information gathering state (v, j > j), leading contradiction. Therefore, optimal strategy j also reservation value strategy optimal reservation valuecalculated, again, according (1).462fiC ONSTRAINING NFORMATION HARING MPROVE C OOPERATIVE NFORMATION G ATHERINGFigure 7: Enforced probabilistic information sharing - effect P H individual expectedbenefit, different: (a) numbers agents, k, setting: c = 0.35 n = 5; (b)information gathering costs, c, setting: k = 15 n = 4.Appendix B. Partially Limiting Information SharingConsider case agent Ai , completed individual IGP, sharesfindings however obtain information others probability PiH ,priori assigned. structure best response strategy individual agent case,given strategy others, identical one given Theorem 1, replacing PiIS PiH .Similarly rest analysis given hold case, except calculation Fi (x),given by:Fi (x) =(pj Fjreturn (x) + (1 pj ))(27)Aj Kj=iFigure 7 depicts agents individual expected benefit function probability PiHused, different group sizes (k) information gathering costs (c) using setting usedFigure 1. comparison Figures 1 7 reveals case partial limitationinformation sharing dominates enforced probabilistic information sharing strategy, farexpected individual benefit concerned. Nonetheless, certainly general result.Appendix C. Proof Theorem 2Proof. proof generally resembles one given Theorem 1. best value agent Aifound far (including v0i ) v > ViIS allowed takepart ISP. j = ni 1resuming IGP result expected benefit ci + y= max(y, v)fi (y)dy whereasterminating IGP guarantee v. agent explore v first463fiROCHLIN & ARNEterm greater latter, represented, mathematical manipulations, as:ci <(y v)fi (y)dyy=vequivalent value v greater riresume according 6.8remainder proof deals showing reservation-value nature optimalstrategy v > ViIS reservation value used agent remains stationary alongIGP Theorem 1.consider case best value agent Ai found far v0i v ViISnumber opportunities information already gathered j. Resuming IGPresult in:ci +ViISfi (y)y=(max(y, v, z)fi (z))dzdy +z=y=ViISEB j+1(y)fi (y)dyEB j+1(y) expected benefit agent Ai , given best value obtained thus far,(including v0i ), number opportunities information already gathered, j.term EBij (v) calculated recursively according (8). remaining opportunities(j > n) best value found v riresume expected benefit simply v. Otherwise,IGP resumes (incurring cost ci ) revised best value (max(y, v)), however j + 1opportunities information already gathered, i.e., expected benefitEBij+1 (max(y, v)). hand, terminating IGP point result expectedbenefit:max(v, z)fi (z)dzz=Therefore, agent explore v first term greatersecond, mathematical manipulations becomes:ci <+ViISy=vy=ViIS(max(y, z) max(v, z))fi (z)dzdyfi (y)z=fi (y)(EBij+1 (y) max(v, z))fi (z)dzdyz=equivalent value greater ri (j) according 7. reason different thresholdused different j values calculation threshold depends among othersexpected benefit case value obtained v > ViIS , case expected benefitdepends number remaining opportunities.8. value riresume resulting ci = y=v (yv)fi (y)dy lower ViIS , agent inevitably terminateIGP (as v > riresume ) hence value riresume ViIS used, particular riresume = ViIStheorem.464fiC ONSTRAINING NFORMATION HARING MPROVE C OOPERATIVE NFORMATION G ATHERINGReferencesAlkoby, S., Sarne, D., & Das, S. (2015). Strategic free information disclosure search-basedinformation platforms. Proceedings 2015 International Conference AutonomousAgents Multiagent Systems (AAMAS 2015), pp. 635643.Anshelevich, E., Das, S., & Naamad, Y. (2013). Anarchy, stability, utopia: creating bettermatchings. Autonomous Agents Multi-Agent Systems, 26(1), 120140.Aumann, R. (1998). centipede game. Games Economic Behavior, 23(1), 97105.Axelrod, R. (1984). evolution cooperation. Basic Books.Bakos, Y. (1997). Reducing buyer search costs: Implications electronic marketplaces. Management Science, 42, 16761692.Bellman, R. (1957). Markovian decision process. Indiana University Mathematics Journal, 6(4),679684.Bernstein, D., Givan, D., Immerman, N., & Zilberstein, S. (2002). complexity decentralizedcontrol Markov decision processes. Mathematics Operations Research, 27(4), 819840.Breban, S., & Vassileva, J. (2001). Long-term coalitions electronic marketplace. Proceedings E-Commerce Applications Workshop, Canadian AI Conference.Burdett, K., & Malueg, D. A. (1981). theory search several goods. Journal EconomicTheory, 24(3), 362376.Carlson, J. A., & McAfee, R. P. (1984). Joint search several goods. Journal Economic Theory,32(2), 337345.Chhabra, M., Das, S., & Sarne, D. (2014a). Competitive information provision sequential searchmarkets. Proceedings International conference Autonomous Agents MultiAgent Systems (AAMAS 2014), pp. 565572.Chhabra, M., Das, S., & Sarne, D. (2014b). Expert-mediated sequential search. European JournalOperational Research, 234(3), 861873.Chhabra, M., & Das, S. (2011). Learning demand curve posted-price digital goods auctions.Proceedings 10th International Conference Autonomous Agents MultiagentSystems (AAMAS 2011), pp. 6370.Conitzer, V. (2012). Computing game-theoretic solutions applications security. Proceedings Twenty-Sixth AAAI Conference Artificial Intelligence, pp. 21062112.de Jong, S., & Tuyls, K. (2011). Human-inspired computational fairness. Autonomous AgentsMulti-Agent Systems, 22(1), 103126.de Jong, S., Tuyls, K., & Verbeeck, K. (2008). Fairness multi-agent systems. Knowledge Engineering Review, 23(2), 153180.Dutta, P., & Sen, S. (2003). Forming stable partnerships. Cognitive Systems Research, 4(3), 211221.Elmalech, A., Sarne, D., & Grosz, B. J. (2015). Problem restructuring better decision makingrecurring decision situations. Autonomous Agents Multi-Agent Systems, 29(1), 139.465fiROCHLIN & ARNEElmalech, A., & Sarne, D. (2012). Evaluating applicability peer-designed agents mechanisms evaluation. Proceedings 2012 IEEE/WIC/ACM International Joint Conferences Web Intelligence Intelligent Agent Technology-Volume 02, pp. 374381.Endriss, U., Kraus, S., Lang, J., & Wooldridge, M. (2011). Designing incentives boolean games.Proceedings 10th International Joint Conference Autonomous Agents Multiagent Systems (AAMAS 2011), pp. 7986.Fotakis, D., Karakostas, G., & Kolliopoulos, S. G. (2010). existence optimal taxes network congestion games heterogeneous users. Proceedings Third internationalconference Algorithmic game theory (SAGT10), pp. 162173.Gatti, J. (1999). Multi-commodity consumer search. Journal Economic Theory, 86(2), 219244.Grosfeld-Nir, A., Sarne, D., & Spiegler, I. (2009). Modeling search least costly opportunity. European Journal Operational Research, 197(2), 667674.Hajaj, C., Hazon, N., Sarne, D., & Elmalech, A. (2013). Search more, disclose less. ProceedingsTwenty-Seventh AAAI Conference Artificial Intelligence (AAAI 2013).Hajaj, C., & Sarne, D. (2014). Strategic information platforms: selective disclosure price"free". ACM Conference Economics Computation (EC14), pp. 839856.Hazon, N., Aumann, Y., Kraus, S., & Sarne, D. (2013). Physical search problems probabilisticknowledge. Artificial Intelligence, 196, 2652.Hendrix, P., & Sarne, D. (2007). effect mediated partnerships two-sided economic search.Klusch, M., Hindriks, K., Papazoglou, M., & Sterling, L. (Eds.), Cooperative Information Agents XI (CIA 2007), Vol. 4676 Lecture Notes Computer Science, pp. 224240.Springer Berlin Heidelberg.Ito, T., Ochi, H., & Shintani, T. (2002). group-buy protocol based coalition formationagent-mediated e-commerce. International Journal Computing Information Sciences,3(1), 1120.Janssen, M. C. W., Moraga-Gonzalez, J. L., & Wildenbeest, M. R. (2005). Truly costly sequentialsearch oligopolistic pricing. International Journal Industrial Organization, 23(5-6),451466.Kephart, J., & Greenwald, A. (2002). Shopbot economics. Journal Autonomous AgentsMulti-Agent Systems, 5(3), 255287.Kraus, S., Shehory, O., & Taase, G. (2003). Coalition formation uncertain heterogeneousinformation. Proceedings Second International Conference Autonomous AgentsMulti-agent Systems (AAMAS 2003), pp. 18.Landsberger, M., & Peled, D. (1977). Duration offers, price structure, gain search.Journal Economic Theory, 16(1), 1737.Lippman, S., & McCall, J. (1976). economics job search: survey. Economic Inquiry,14(3), 347368.Manisterski, E., Sarne, D., & Kraus, S. (2008). Enhancing cooperative search concurrentinteractions. Journal Artificial Intelligence Research (JAIR), 32(1), 136.466fiC ONSTRAINING NFORMATION HARING MPROVE C OOPERATIVE NFORMATION G ATHERINGMash, M., Rochlin, I., & Sarne, D. (2012). Join weakest partner, please. Proceedings2012 IEEE/WIC/ACM International Conference Intelligent Agent Technology (IAT2012), pp. 1724.Masters, A. M. (1999). Wage posting two-sided search minimum wage. InternationalEconomic Review, 40(4), 809826.McKelvey, R., & Palfrey, T. (1992). experimental study centipede game. Econometrica,60(4), 803836.McMillan, J., & Rothschild, M. (1994). Search. Proceedings Handbook Game TheoryEconomic Applications, pp. 905927.Morgan, P. (1983). Search optimal sample sizes. Review Economic Studies, 50(4), 659675.Morgan, P., & Manning, R. (1985). Optimal search. Econometrica, 53(4), 923944.Nagel, R., & Tang, F. (1998). Experimental results centipede game normal form:investigation learning. Journal Mathematical Psychology, 42(2-3), 356384.Nahum, Y., Sarne, D., Das, S., & Shehory, O. (2015). Two-sided search experts. AutonomousAgents Multi-Agent Systems, 29(3), 364401.Penn, M., Polukarov, M., & Tennenholtz, M. (2009a). Random order congestion games. Mathematics Operations Research, 34(3), 706725.Penn, M., Polukarov, M., & Tennenholtz, M. (2009b). Taxed congestion games failures. AnnalsMathematics Artificial Intelligence, 56(2), 133151.Puterman, M. L. (1994). Markov Decision Processes: Discrete Stochastic Dynamic Programming.Wiley-Interscience.Rochlin, I., Aumann, Y., Sarne, D., & Golosman, L. (2014). Efficiency fairness team searchself-interested agents. Proceedings International conference AutonomousAgents Multi-Agent Systems (AAMAS 2014), pp. 365372.Rochlin, I., & Sarne, D. (2014a). Constraining information sharing improve cooperative information gathering. Proceedings 13th International Joint Conference AutonomousAgents Multiagent Systems (AAMAS 2014), pp. 237244.Rochlin, I., & Sarne, D. (2014b). Utilizing costly coordination multi-agent joint exploration.Multiagent Grid Systems, 10(1), 2349.Rochlin, I., Sarne, D., & Laifenfeld, M. (2012). Coordinated exploration shared goal costlyenvironments. Proceedings ECAI 2012 - 20th European Conference ArtificialIntelligence. Including Prestigious Applications Artificial Intelligence (PAIS-2012) SystemDemonstrations Track, pp. 690695.Rochlin, I., Sarne, D., & Mash, M. (2014). Joint search self-interested agents failurecooperation enhancers. Artificial Intelligence, 214, 4565.Rochlin, I., Sarne, D., & Zussman, G. (2011). Sequential multilateral search common goal.Proceedings 2011 IEEE/WIC/ACM International Conference Intelligent AgentTechnology (IAT 2011), pp. 349356.Rochlin, I., Sarne, D., & Zussman, G. (2013). Sequential multi-agent exploration commongoal. Web Intelligence Agent Systems, 11(3), 221244.467fiROCHLIN & ARNERochlin, I., & Sarne, D. (2013). Information sharing costly communication joint exploration. Proceedings Twenty-Seventh AAAI Conference Artificial Intelligence, pp.847853.Rothschild, M. (1974). Searching lowest price distribution prices unknown.Journal Political Economy, 82(4), 689711.Saad, W., Han, Z., Debbah, M., & Hjorungnes, A. (2009). Coalitional games distributed collaborative spectrum sensing cognitive radio networks. Proceedings IEEE INFOCOM,pp. 21142122.Sarne, D. (2013). Competitive shopbots-mediated markets. ACM Transactions EconomicsComputation, 1(3), 17.Sarne, D., & Arponen, T. (2007). Sequential decision making parallel two-sided economic search.Proceedings Sixth International Joint Conference Autonomous Agents Multiagent Systems (AAMAS 2007), p. 69.Sarne, D., & Aumann, Y. (2014). Exploration costs means improving performancemultiagent systems. Annals Mathematics Artificial Intelligence, 72(3-4), 297329.Sarne, D., & Kraus, S. (2005). Cooperative exploration electronic marketplace. Proceedings Twentieth National Conference Artificial Intelligence SeventeenthInnovative Applications Artificial Intelligence Conference (AAAI 2005), pp. 158163.Sarne, D., Manisterski, E., & Kraus, S. (2010). Multi-goal economic search using dynamic searchstructures. Autonomous Agents Multi-Agent Systems, 21(1-2), 204236.Sarne, D., & Kraus, S. (2003). search coalition formation costly environments.Proceedings Cooperative Information Agents VII, 7th International Workshop, CIA,pp. 117136.Sarne, D., & Kraus, S. (2008). Managing parallel inquiries agents two-sided search. ArtificialIntelligence, 172(4-5), 541569.Selten, R., & Stoecker, R. (1986). End behavior sequences finite prisoners dilemma supergames learning theory approach. Journal Economic Behavior & Organization, 7(1),4770.Sen, S. (1996). Reciprocity: foundational principle promoting cooperative behavior amongself-interested agents. Proceedings Second International Conference Multi-AgentSystems, pp. 322329.Shehory, O., & Kraus, S. (1998). Methods task allocation via agent coalition formation. ArtificialIntelligence, 101(1-2), 165200.Smith, L. (2011). Frictional matching models. Annual Reviews Economics, 3(1), 319338.Stone, P., & Kraus, S. (2010). teach teach? decision making uncertainty adhoc teams. Proceedings Ninth International Conference Autonomous AgentsMultiagent Systems (AAMAS 2010), pp. 117124.Tang, Z., Smith, M. D., & Montgomery, A. (2010). impact shopbot use pricesprice dispersion: Evidence online book retailing. International Journal IndustrialOrganization, 28(6), 579590.468fiC ONSTRAINING NFORMATION HARING MPROVE C OOPERATIVE NFORMATION G ATHERINGTsvetovat, M., Sycara, K., Chen, Y., & Ying, J. (2000). Customer coalitions electronic markets.Proceedings Agent-Mediated Electronic Commerce III, Current Issues Agent-BasedElectronic Commerce Systems (includes revised papers AMEC 2000 Workshop), pp.121138.Waldeck, R. (2008). Search price competition. Journal Economic Behavior Organization, 66(2), 347357.Walker, J., & Halloran, M. (2004). Rewards sanctions provision public goodsone-shot settings. Experimental Economics, 7(3), 235247.Yamamoto, J., & Sycara, K. (2001). stable efficient buyer coalition formation schemee-marketplaces. Proceedings 5th international conference Autonomous agents(AGENTS 01), pp. 576583.469fiJournal Artificial Intelligence Research 54 (2015) 593-629Submitted 07/15; published 12/15Compressing Optimal Paths Run Length EncodingBen StrasserSTRASSER @ KIT. EDUKarlsruhe Institute TechnologyKarlsruhe, GermanyAdi BoteaADIBOTEA @ IE . IBM . COMIBM ResearchDublin, IrelandDaniel HaraborDANIEL . HARABOR @ NICTA . COM . AUNICTASydney, AustraliaAbstractintroduce novel approach Compressed Path Databases, space efficient oracles usedquickly identify first edge shortest path. algorithm achieves query running times100 nanosecond scale, significantly faster state-of-the-art first-move oraclesliterature. Space consumption competitive, due compression approach rearrangesrows columns first-move matrix performs run length encoding (RLE)contents matrix. One variant implemented system was, convincing margin,fastest entry 2014 Grid-Based Path Planning Competition.give first tractability analysis compression scheme used algorithm.study complexity computing database minimum size general directed undirectedgraphs. find cases problem NP-complete. also show that, graphsdecomposed along articulation points, problem decomposed independentparts, corresponding reduction level difficulty. particular, leads simpletractable algorithms linear running time yield optimal compression results trees.1. IntroductionCompressed Path Database (CPD) index-based data-structure graphs usedquickly answer first-move queries. query takes input pair nodes, namely source nodetarget node t, asks first edge shortest st-path (i.e., path t). CPDssuccessfully applied number contexts important AI. instance, Copa (Botea,2012), CPD-based pathfinding algorithm, one joint winners 2012 editionGrid-Based Path Planning Competition, shorter GPPC (Sturtevant, 2012b). related algorithm,MtsCopa, fast method moving target search known partially known terrain (Botea,Baier, Harabor, & Hernandez, 2013; Baier, Botea, Harabor, & Hernandez, 2014).Given graph G = (V, E), trivial CPD consists square matrix dimensions|V | |V |. matrix m, constructed precomputation step, stores cell m[s, t]identity first edge shortest st-path. call first-move matrix. conventionsay rows correspond fixed source nodes columns fixed target nodes.optimal terms query time O(|V |2 ) space consumption quickly becomes prohibitivelarger graphs. challenge design compact representation trades small increasequery times large decrease space consumption.c2015AI Access Foundation. rights reserved.fiS TRASSER , B OTEA , & H ARABORnumber different techniques compress first-move matrix suggestedpurpose (Sankaranarayanan, Alborzi, & Samet, 2005; Botea, 2011; Botea & Harabor, 2013a).case objective conserve space grouping together entries sharecommon source node store first-edge information.work present Single-Row-Compression (SRC) Multi-Row-Compression(MRC) indexing algorithms compressing all-pairs shortest paths. 2014s GPPC, SRC outperformed competitors terms query running time. contributions presented articlego three main directions: new approach compressing first-move matrix; experimentsdemonstrate advancing state-of-the-art terms response time memory consumption;thorough theoretical analysis, discussing NP-hardness results islands tractability.introduce new matrix compression technique based run-length encoding (RLE).main idea algorithm simple: compute order nodes input graphassign numeric IDs nodes (e.g., 1 |V |) order. purpose orderingnodes located close proximity graph small ID difference. orderingused order rows columns first-move matrix, also computedpreprocessing. Then, apply run-length encoding (RLE) row first-move matrix.study three types heuristic orderings: graph-cut order, depth-first order input-graph order.also study two types run-length encoding. first involves straightforward applicationalgorithm row. second type sophisticated multi-row scheme eliminatesredundancies adjacent RLE-compressed rows. answer first-move queries employbinary search fragment compressed result.undertake detailed empirical analysis including comparisons techniques stateof-the-art variants CPDs (Botea, 2012), Hub-Labeling (Delling, Goldberg, Pajor, & Werneck,2014). Copa recent fast CPD oracle among joint winners 2012International Grid-Based Path Planning Competition (GPPC). Using variety benchmarkscompetition show techniques improve Copa, terms storage querytime. Hub-Labeling technique initially developed speedup queries roads, alsowork graphs, gridmaps. Hub-Labeling best knowledge fastesttechnique known roads. experiments, show approach leads better query timesHub-Labeling graphs reasonably compute m.technique relies all-pairs-shortest-path pre-computation, plays tradeoffquery-response speed, preprocessing time memory required store compressedpath database. Thus, algorithm faster, also requires larger preprocessing timememory techniques literature. words, memorypreprocessing time available, technique provide state-of-the-art speed performance. hand, larger larger graphs create memory preprocessing timebottleneck, techniques considered. See detailed comparison experimentssection.theoretical analysis, formally define study optimal RLE-compression first-movematrices produced input graphs. consider case directed input graphs caseundirected weighted input graphs. show versions NP-complete. Focusingdistinct types graphs, result brings something new compared other. Related (Kou,1977; Oswald & Reinelt, 2009) weaker, less specific (Mohapatra, 2009) results RLE-basedmatrix compression available literature. However, known, NP-hardness classproblems necessarily imply NP-hardness subset class. Thus, despite594fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODINGprevious related results (Mohapatra, 2009), open question whether optimal RLEcompression first-move matrix computed input graph tractable.also show that, graphs decomposed along articulation points, problemdecomposed independent subproblems. optimal orderings available subproblems, global optimal ordering easily obtained. particular, depth-first preorderoptimal trees, general ordering problem fixed-parameter tractable sizelargest 2-connected component.approach part evaluation previously reported shorter conferencepaper (Strasser, Harabor, & Botea, 2014). theoretical analysis topic another conference paper (Botea, Strasser, & Harabor, 2015). Putting together current submissionprovides unique source describes method, performance theoretical properties.Compared previous conference papers, provide complete proofs theoreticalresults. included details examples presentation, better clarity.report additional results, performance pathfinding competition GPPC 2014,originally published paper competition (Sturtevant, Traish, Tulip, Uras,Koenig, Strasser, Botea, Harabor, & Rabin, 2015).2. Related WorkMany techniques literature employed order quickly answer first-move queries.Standard examples include optimal graph search techniques Dijkstras algorithm (Dijkstra,1959) A* (Hart, Nilsson, & Raphael, 1968). Significant improvements methodsachieved preprocessing input graph, done CPDs, instance. shortest pathsnumerous applications various fields, plethora different preprocessing-based algorithmsproposed. overview, refer interested reader recent survey article (Bast,Delling, Goldberg, MullerHannemann, Pajor, Sanders, Wagner, & Werneck, 2015). commonapproach consists adding online pruning rules Dijkstras algorithm, rely data computed preprocessing phase, significantly reducing explored graphs size. approachsignificantly differs technique described paper, omit details referinterested reader aforementioned survey article.SILC (Sankaranarayanan et al., 2005) Copa (Botea & Harabor, 2013a) CPD-based techniques fast first-move computation. SILC employs recursive quad-tree mechanism compression Copa uses simpler effective (Botea, 2011) decomposition rectangles.Hub Labels (HL) initially introduced 2-Hop Labels (Cohen, Halperin, Kaplan, & Zwick,2002). nearly decade much research topic, Abraham, Delling,Goldberg, Werneck (2011) showed technique practical huge road networks,coined term Hub Labels. realization drastically increased interest HL thusspawned numerous follow works, (Abraham, Delling, Goldberg, & Werneck, 2012;Delling, Goldberg, & Werneck, 2013; Abraham, Delling, Fiat, Goldberg, & Werneck, 2012; Akiba,Iwata, & Yoshida, 2013). context, relevant one probably RXL (Delling et al.,2014), HL variant. authors show algorithm works well roadgraphs variety graphs different sources including graphs derived maps usedGPPC. compare algorithm RXL.HL index consists forward backward label node, contains list hubnodes exact distances them. st-pair must exist meeting hub h595fiS TRASSER , B OTEA , & H ARABORforward hub backward hub shortest st-path. shortest distance querynode node answered enumerating common hubs t. labelinggood labels contain hubs. Computing labeling minimizing index sizeNP-hard (Babenko, Goldberg, Kaplan, Savchenko, & Weller, 2015).works consider HL general form, consider restrictive variantcalled Hierarchical Hub Labels (HHL). term introduced Abraham et al. (2012)labels used previous work (Abraham et al., 2011) already hierarchical. labeling calledhierarchical ordering vertices exists, every hub h vertex v comes vorder. Given fixed node order, optimal labeling computed efficiently (Abrahamet al., 2012). difficult task HHL consists computing node order. Computing nodeorder minimizing index size also NP-hard task (Babenko et al., 2015).HHL deeply coupled different popular speedup technique shortest path computations called Contraction Hierarchies (CH) (Geisberger, Sanders, Schultes, & Delling, 2008). CHachieve query speeds HHL significantly smaller index sizes. However,applications even CH query times already faster necessary, makes CHstrong competitor. CH iteratively contracts nodes inserting shortcuts maintain shortestpath distances remaining graph. following inserted shortcuts small fractiongraph needs explored every node. node order good CH searchspaces every node small. Again, computing optimal order NP-hard (Bauer, Columbus,Katz, Krug, & Wagner, 2010). first HL paper road graphs (Abraham et al., 2011) computedlabel v explicitly storing nodes reachable v CH search space applying pruning rules. Later papers refined rules, every hierarchical labelviewed explicitly stored pruned CH search space. consequence node ordersgood CH also good HHL vice versa, even though formal optimizationcriteria differ therefore optimal order one respect criterionslightly suboptimal other.node orders used HHL original CH depend weights input graph.Substantial changes weights requires recomputing node ordering. recent work(Bauer, Columbus, Rutter, & Wagner, 2013; Dibbelt, Strasser, & Wagner, 2014) introducedCustomizable Contraction Hierarchies (CCH) shown node orders exist work welldepend structure input graph. node orders exploit input graphsmall balanced node-separators comparative small treewidth.paper also consider two types node orders. first depth first search preordersecond based small balanced edge-cuts. thus also independent inputgraphs weights. However, confuse orders CCH node orders.interchangeable. Using CCH ordering result bad performance technique,using one node orders CCH work well. fact, using preorder CCHmaximizes maximum search space terms vertices instead minimizing it. is,order works well technique CCH worst case node order. Further, ordersalso interchanged weight-dependent orders needed HHL CH.described literature, HL answers distance queries. However, hinted Abrahamet al. (2012), easy extend hub labels first move queries. achieve this, entriesforward backward labels extended third component: first move edge ID. hforward hub corresponding entry extended using first edge ID shortestsh-path. h backward hub entry extended first edge shortest ht-path.596fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODINGst-query first corresponding meeting hub h determined. 6= h first moveedge ID stored forward label otherwise first move contained backwardlabel t. slightly increases memory consumption negligible impactperformance. Note distance values needed even one wishes compute first-movesneed distances determine right hub several hubs common.context program analysis sometimes desirable construct oracle determines particular section code ever reached. PWAH (van Schaik & de Moor, 2011)one example. Similarly work, authors precompute quadratic matrix employcompression scheme based run-length encoding. main difference reachabilityoracles return yes-no answer every query rather identity first-edge.Another speedup technique low average query times Transit Node Routing (TNR) (Bast,Funke, & Matijevic, 2009; Bast, Funke, Matijevic, Sanders, & Schultes, 2007; Antsfeld, Harabor,Kilby, & Walsh, 2012). However, two independent studies (Abraham et al., 2011; Arz, Luxen, &Sanders, 2013) come conclusion (at least roads) TNR dominated HLterms query time. Further, TNR optimize short range queries. scenario oftenarises unit chases another unit. situations units tend close,results many short range queries. TNR rather ineffective scenario.Bulitko, Bjornsson, Lawrence (2010) present subgoal-based approach pathfinding. Similarities work include preprocessing stage paths map precomputed,results compressed stored database. database used speedresponse time path query posed system. substantial differencestwo approaches well. method precomputes all-pairs shortest paths, eliminating graphsearch entirely production mode (i.e., stage system queried provide fullshortest paths fragments shortest paths). contrast, Bulitko et al. restrict precomputeddatabase subset nodes, turn requires additional search production mode.compression method different case. system provides optimal paths,guaranteed case Bulitko et al.s method. Besides Bulitko et al. (2010) work, pathfindingsub-goals turned popular successful idea recent work (Hernandez &Baier, 2011; Bulitko, Rayner, & Lawrence, 2012; Lawrence & Bulitko, 2013; Uras, Koenig, &Hernandez, 2013).Pattern databases (PDBs) (Culberson & Schaeffer, 1998) lookup tables provide heuristicestimations true distance search node goal state. obtained abstractingoriginal search space smaller space. Optimal distances abstracted space, everystate pre-established goal, precomputed stored pattern database estimationsdistances original space. such, techniques memory-based enhancementsproblems solution represented path graph. several keydistinctions PDBs CPDs. PDBs lossy abstractions, specific goalsubset goals. CPDs lossless compressions, encode shortest paths every starttargetpair. Given lossy nature, PDBs need used heuristic within search algorithm,example A*, opposed complete optimal method own. PDBs commonlyused large graphs, implicitly defined search spaces, exploring entire graphpreprocessing impractical. PDBs, coarseness abstraction impacts accurracyheuristic estimations. finer abstraction better quality, also result larger PDB.Work addressing bottleneck include compressing pattern databases (Felner, Korf, Meshulam,597fiS TRASSER , B OTEA , & H ARABOR& Holte, 2007; Samadi, Siabani, Felner, & Holte, 2008). contrast, CPDs compress all-pairsshortest paths.3. Preliminariesdenote G = (V, E) graph node set V edge1 set E V V . denotedeg(u) number outgoing edges u.2 maximum out-degree denoted . nodeorder : V [1, |V |] assigns every node v unique node ID o(v). out-going edges everynode ordered arbitrary fixed order position (index ordering) referredout-edge ID.Further, weight function w : E R>0 3 . st-path sequence edges a1 . . . aka1 starts ak ends tPevery edge ai ends node ai+1starts. weight (or cost) path w(ai ). st-path shortest st-path existsstrictly smaller weight. distance two nodes weight shortestst-path, one exists. st-path exists, distance . Notice may multipleshortest st-paths weight.Without loss generality assume duplicate edges (multi-edges) existgraphs, were, could drop shortest edge, edges usedshortest path. Further, using similar argument, assume without loss generalityreflexive loops exist.6= t, st-first-move first edge shortest st-path. multiple shortestst-paths, may also multiple st-first-moves. st-path exists, st-first-move exists.formal problem consider following: Given pair nodes t, find st-first-move.several valid first-moves, algorithm freely choose return.Given oracle answers first move queries, easily extract shortest paths. Computest-first move a. words, first edge shortest path. Next, set end a.long 6= t, apply procedure iteratively. Notice, works edge weightsguaranteed non-zero. allowed zero-weights, could run infinite-loop problem,following example illustrates: Consider graph G two nodes x connected edgesxy yx weights zero. Denote node G. valid xt-first-move using xy.valid yt-first-move using yx. oracle always returned two first-moves,path extraction algorithm would oscillate x would terminate.depth first search (DFS) way traversing graph constructing special sortspanning tree using backtracking. depth-first preorder node order orders nodesway DFS first sees them. search parameterized root node orderneighbors node visited. work regularly refer depthfirst preorders without stating parameters. always implicitly assume rootarbitrary node neighbors visited arbitrary order.1. term arc also used literature. Sometimes, distinction made whether graph directed (incase authors prefer say arcs) undirected. paper, stick term edge cases.2. directed graph, every ordered pair (u, v) E outgoing edge u. undirected graph, every edgeincident u outgoing edge u.3. assume function E R>0 able apply Dijkstras algorithm preprocessing phase.However, one could consider arbitrary weights without negative cycles replace every occurrence Dijkstrasalgorithm algorithm Bellman Ford (Bellman, 1958; Ford, 1956).598fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODINGRun length encoding (RLE) compresses string symbols representing compactlysubstrings, called runs, consisting repetitions symbol. instance, string aabbbaaathree runs, namely aa, bbb, aaa. run replaced pair contains startvalue run. start index first element substring, whereas valuesymbol contained substring. example, first run aa start 1 value a.Run bbb start 3 value b, whereas last run start 6 value a.4first last run value, need encode both. firstrun easily reconstructed constant time case. First, decide whether first runremoved not, done checking first run among preserved onesstart equal 1. Secondly, needed, reconstruct first run, using 1 start position valueequal value last encoded run. Another way looking that, firstlast run value, allow merge, wrapped around stringform cycle. allow this, say using cyclic runs. Otherwise (never considermerging ends string), say use sequential runs. See Example 1 below.Given ordered sequence elements (string), say two positions are: adjacentnext other; cyclic-adjacent adjacent one first lastposition ordering; separated otherwise.Let ordered sequence elements (symbols) dictionary (or alphabet) . Givensymbol , let -run RLE run containing symbol . every string , denoteN () total number occurrences symbol . Further, number sequential -runsdenoted Rs () number cyclic Rc (). Notice 0 Rs ()Rc () 1.words, number sequential runs number cyclic runs never differ1. Finally, denote Rs () total number sequential runs Rc () total numbercyclic runs. paper, assume first-move compression uses cyclic runs, unlessexplicitly say otherwise.Example 1. Consider string = aabbbaaa. Compressing yields 1, a; 3, b; 6, a.means position 1 string consists as. Similarily position 3 bsfinally position 6 elements string ends. Na () = 5 Nb () = 3.three sequential runs, namely aa, bbb aaa. first third ones a-runs,whereas middle one b-run. Thus, Ras () = 2, Rbs () = 1, Rs () = 2 + 1 = 3.time, one cyclic a-run. Indeed, put next two endsstring, string cyclic, occurrences string become one solid block (i.e.,one cyclic a-run). Thus, Rac () = 1, Rbc () = 1, Rc () = 1 + 1 = 2.4. Basic Ideamentioned introduction, algorithm starts building |V | |V | all-pairs first-movematrix m. entry position m[i, j] ij-first-move. central idea algorithmcompress row using RLE. compression performed gradually, matrixrows computed, uncompressed matrix kept memory.answer st-first-move query, run binary search row s. However, achievegood compression ratio, first reorder columns decrease total number runs.columns correspond nodes, regard problem reordering columns problem4. Alternative encodings exist, value followed run length. E.g., a, 2; b, 3; a, 3 example.599fiS TRASSER , B OTEA , & H ARABOR1b,5a,2e,33c,35d,6(a) Input2f ,44123451a2 ae f e3 e ed c4 f f dd5 c c c c(b) First-Move Matrix123451/a1/a 3/e 4/f 5/e1/e 4/d 5/c1/f 3/d1/c(c) Compressed Path DatabaseFigure 1: toy example algorithmcomputing good node order. Computing optimal node order minimizes numberruns NP-hard, show theoretical analysis. Fortunately, simple depth-first preorderworks well practice.Sometimes, formal analysis, technical details annoying sensemake presentation somewhat complicated. question symboluse m[i, i] example. practical implementation, say caresymbol, never query it. reduce number runs therefore assign eithervalue m[i 1, i] m[i + 1, i]. theoretical analysis, make similar assumption (i.e.,dont care symbol) Sections 5 6. state Section 7, assumptionm[i, i] symbol different edge symbol. every case, assumptionspurpose keeping analysis simple possible.Example 2. Figure 1a shows toy weighted undirected graph, 5 nodes 6 edges.edge, show weight (cost), number, unique label, letter. first-movematrix graph, corresponding node ordering 1, 2, 3, 4, 5, shown Figure 1b.Recall entry m[r, c], r row c column, id first moveshortest path node r node c. example, m[3, 1] = e e first step ea,optimal path node 3 node 1. Another optimal path would single-step path b,ea b optimal weight (cost) 5. Thus, free choose m[3, 1] = em[3, 1] = b. prefer e leads better compression row 3 m, sincefirst two symbols third row, identical, part RLE run. showSection 9 breaking ties optimal way feasible computationally easy.compression given node ordering (or equivalently, matrix column ordering) shownFigure 1c.Notice ordering nodes impacts size compressed matrix. Example 2,swapping nodes 3 4, illustrated Figure 2, would reduce number RLE runsrow 2, two e symbols become adjacent. total number runs decreases 11runs 10 runs. Thus, challenge find optimal least good enough node ordering,objective function size compressed first-move matrix.compression strategy RLE illustrated Example 2 key component approach. study theoretically next three sections, showing computing optimalnode ordering NP-hard general, identifying tractability islands. present numbereffective heuristic node orderings Section 8. variant implemented method, called SRC,600fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODING1b,5a,2e,34c,35d,6(a) Input2f ,43123451a2 af e e3 f f4 e e dc5 c c c c(b) First-Move Matrix123451/a1/a 3/f 4/e1/f 3/d1/e 3/d 4/c1/c(c) Compressed Path DatabaseFigure 2: toy example Figure 1 different node ordering (i.e., nodes 34 swapped).performs compression illustrated example. Another version program, calledMRC, goes beyond idea compressing row independently, implementing multi-rowcompression strategy. discussed Section 9 evaluated empirically Section 12.5. First-Move Compression Directed GraphsRecall ordering columns first-move matrix affects number RLE runsmatrix. section show obtaining optimal ordering intractable generalinput graph directed. construction works uniform edge weights. simplicitlytherefore omit weights section.Definition 1. FMComp-d (First Move CompressionDirected) problem:Input: directed graph G = (V, E); matrix size |V | |V | cell m[i, j] encodesfirst move optimal path node node j; integer k.Question: ordering columns that, apply RLE row,total number cyclic RLE runs summed rows k?Theorem 1. FMComp-d problem NP-complete.Proof. easy see problem belongs NP, solution guessed verifiedpolynomial time.NP-hardness shown reduction Hamiltonian Path Problem (HPP)undirected graph. Let GH = (VH , EH ) arbitrary undirected graph, define n = |VH |e = |EH |. Starting GH , build instance FMComp-d problem. AccordingDefinition 1, instance includes directed graph, call GF , first-move matrixGF , number.GF = (VF , EF ) defined follows. node u VH , define node VF . callnodes VF type-n nodes, indicate created original nodes VH .edge (u, v) EH , define new node nuv VF (type-e nodes). new node nuv , definetwo edges EF , one nuv u one nuv v. edges EF . SeeFigure 3 example.Table 1 shows first-move matrix running example. Given type-n node u,nodes unreachable u graph GF . Thus, matrix row corresponding u601fiS TRASSER , B OTEA , & H ARABORnxyxxwznxwwznwzFigure 3: Left: sample graph GH . Right: GF built GH . GF , x, y, w, z type-n nodes.Nodes nij type e.xwznxynxwnwzx222002222122w222210z222221nxy222222nxw222222nwz222222-Nr. cyclic runs1111343Table 1: First-move matrix running example. rows columns follow nodeordering x, y, w, z, nxy , nxw , nwz .one non-trivial symbol,5 chose symbol 2, denotes nodereachable. rows one RLE run each, regardless node ordering.matrix row corresponding type-e node nuv three distinct (non-trivial) symbols total:one symbol edge node u, another symbol edge node v, non-reachablesymbol 2 every node. Without generality loss, use symbol 0 edge u,symbol 1 edge v. easy see that, nodes u v cyclic-adjacent givenordering, nuv row 3 RLE runs. u v separated, row 4 RLE runs.See Table 1 sample orderings.claim HPP solution iff FMComp-d solution 4e + 1 RLE runs. Letvi1 , vi2 . . . , vin solution HPP (i.e., Hamiltonian path GH ), let P EH setedges included solution. show node ordering VF starting vi1 , . . . , vin ,followed type-e nodes arbitrary order, result 4e+1 = 3(n1)+4(en+1)+nruns, 3n 3 runs total type-e rows6 corresponding edges P ; 4(e n + 1) runstotal remaining type-e rows; n runs total type-n rows.5. trivial symbol mean dont care symbol . Recall impact number runs.simplicity, safely ignore symbol discussion.6. say row type-n (or type-e) iff associated node type.602fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODINGIndeed, edge (u, v) P , type-e row corresponding node nuv VF3 RLE runs, since u v adjacent ordering. n 1 edges Hamiltonianpath, total number RLE runs 3(n 1) rows.edge (u, v)/ P , two nodes separated therefore corresponding matrix row4 runs. sums 4(e n + 1) RLE runs rows corresponding edgesincluded Hamiltonian path.Conversely, consider node ordering creates 4e + 1 = 3(n 1) + 4(e n + 1) + n RLEruns total. show ordering type-n nodes contiguous block,7ordering Hamiltonian path GH . equivalent saying exist n 1 pairstype-n nodes u v u v cyclic-adjacent ordering, (u, v) EH .proof contradiction. Assume p < n 1 pairs type-n nodes u vu v cyclic-adjacent ordering, (u, v) edge EH .p pairs, row corresponding type-e node nuv 3 RLE runs. remaining e ptype-e rows 4 RLE runs each. mentioned earlier, type-n rows n runs total,regardless ordering. Thus, total number RLE runs 3p + 4(e p) + n = 4e p + n >4e (n 1) + n = 4e + 1. Contradiction.6. Compression Undirected Weighted Graphsturn attention undirected weighted graphs, showing computing optimal orderingNP-complete.Definition 2. FMComp-uw problem (First Move CompressionUndirected, Weighted) defined follows.Input: undirected weighted graph G = (V, E); matrix size |V | |V | cell m[i, j]stores first move optimal path node node j; integer k.Question: ordering ms columns that, apply run length encoding (RLE)row, total number cyclic RLE runs matrix k?stepping stone proving NP-hardness FMComp-uw, introduce problemcall SimMini1Runs (Definition 3), prove NP-completeness. SimMini1Runs inspiredwork Oswald Reinelt (2009), studied complexity problem involvingso-called k-augmented simultaneous consecutive ones property (C1Sk ) 0/1 matrix (i.e.,matrix two symbols, 0 1). definition, 0/1 matrix C1Sk property if,replacing k 1s 0s, columns rows matrix ordered that,row column, 1s row column come one contiguous block.Oswald Reinelt (2009) proven checking whether 0/1 matrix C1Sk propertyNP-complete. proof SimMini1Runs related, point later proof.Given 0/1 matrix o, ordering columns, ordering rows, let globalsequential 1-runs count Gs1 (o) number sequential 1-runs summed rowscolumns. is,XGs1 (o) =R1s (),7. Here, notion contiguous block allows case part block end sequence,part beginning, sequence cyclic.603fiS TRASSER , B OTEA , & H ARABORo=r1r2c1c2c3011011Figure 4: Running example 0/1 matrix o. Rows labelled ri , whereas cj represent columnlabels.iterated os rows columns. instance, Gs1 (o) = 6 matrix shownFigure 4.Definition 3. Simultaneous Mini 1-Runs (SimMini1Runs) problem defined follows.Input: 0/1 matrix every row column contain least one value 1; integer k.Question: ordering columns, ordering rows, Gs1 (o) k?Theorem 2. SimMini1Runs NP-complete.proof available Appendix A.Lemma 1. Let 0/1 string starts 0, ends 0, both.R1s () = R0c ().Proof. Case (i): starts 0 ends 1. two end symbols different, sequentialruns cyclic runs identical. 0-runs 1-runs alternate, numbers identical. Case(ii), starts 1 ends 0, similar previous one.Case (iii): 0 ends. 0-runs 1-runs alternate, 0-runsends, follows R1s () = R0s () 1 = R0c ().Theorem 3. FMComp-uw NP-complete.Proof. NP-hardness shown reduction SimMini1Runs. Consider arbitrarySimMini1Runs instance rows n columns. Figure 4 shows running example.build undirected weighted graph G = (V, E) follows. V 3 types nodes, total+ n + 1 nodes. column generates one node V . call c-nodes. rowgenerates one node well (r-nodes). extra node p called hub node.One r-node ri one c-node cj connected unit-cost edge iff o[ri , cj ] = 1.addition, edge weight 0.75 p every node. edgesexist graph G. See Figure 5 example.Let first-move matrix G. row p fixed number runs, namely + n,8regardless ordering ms columns. Let v c-node r-node. Apart vs adjacentnodes, nodes reached shortest path cost 1.5 whose first move edge(v, p). matrix running example shown Figure 6.Let T1 total number occurrences symbol 1 matrix o. claimordering os rows columns results k sequential 1-runs (summed rowscolumns) iff ordering columns resulting k + 2T1 + + n8. Recall ignore dont care symbol m[p, p] = , impact number RLE runs.604fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODINGpc1c2c3r1r2Figure 5: Graph running example. Dashed edges weight .75, whereas solid linesunit-cost edges.r1m=r1r2c1c2c3pr2c1c2c3p0 0 1 2 00 1 0 2 00 1 0 0 01 0 0 0 01 2 0 0 01 2 3 4 5Figure 6: first-move matrix running example. Without generality loss, 0 movetowards p. incident edges given node counted starting 1.cyclic RLE runs total (summed rows). Thus rows m, except ps row,k + 2T1 runs total.Let ri1 , . . . rim cj1 , . . . cjn row column orderings result ksequential RLE runs rows columns. show ordering ri1 , . . . rim , cj1 , . . . cjn , pms columns generates k + 2T1 + + n cyclic runs. Clearly, every row columno, corresponding row 0 (see Figures 4 6 example). Accordingsteps explained earlier illustrated Figures 4 6, 0 obtained follows.original 0s preserved. original 1s replaced distinct consecutive integers starting1. addition, 0 padded 0s one ends. Since 0 0s oneends, follows R1s () = R0c ( 0 ).9 follows Rc ( 0 ) = R0c ( 0 )+N1 () = R1s ()+N1 ().Summing Rc ( 0 ) rows 0 m, except ps row, obtainX0 (m)\{p}Rc ( 0 ) =XR1s () +(o)X(o)N1 () k + 2T1 ,denotes set rows matrix, set columns, = . followsms rows k + 2T1 + + n cyclic RLE runs total (that is, summed rows).Conversely, assume ordering ms columns k + 2T1 + + n cyclic RLE runstotal (for rows). means summing runs rows m, except node psrow, results k + 2T1 runs. exactly 2T1 distinct runs different 0-runs,9. R1s () = R0c () Lemma 1, R0c () = R0c ( 0 ) construction.605fiS TRASSER , B OTEA , & H ARABORfollows k 0-runs total:X0 (m)\{p}R0c ( 0 ) k.Let ri1 , . . . rim , cj1 , . . . cjn , p re-arragement ms columns that: r-nodes comeone contiguous block, relative ordering preserved; c-nodes one contiguous block,relative ordering preserved.Since G restricted c-nodes r-nodes bi-partite, rearrangement cannot possibly increase number RLE runs. (If anything, could eliminate 0-runs). hardprove. example, current matrix row corresponds r-node source node,m[a, b] = 0 every r-node b, since a, p, b optimal path b. Also,m[a, p] = 0. rearrangement moves nodes b block cyclic-adjacent p,create new run. case c-node source similar.order os columns cj1 , . . . cjn , os rows ri1 , . . . rim . orderings,relation row column corresponding row 0 follows.non-zero values 0 converted 1s . 0 0s one ends cutaway . Since 0 contains 0s one ends, R1s () = R0c ( 0 ), according Lemma 1.followsXXR1s () =R0c ( 0 ) k.(o)(o)0 (m)\{p}7. Fighting Complexity Decompositionfar results negative. shown computing optimal order largeclass graphs NP-hard. section identify tractability islands. show problemdecomposed along articulation points (which related cuts size 1). particular,implies (as shown section) depth-first preorder optimal node ordering trees.able construct optimal orders efficiently broader class graphs trees:show problem fixed-parameter tractable size largest componentgraph articulation points.Definition 4. say node x graph G articulation point removing x adjacent edges G would split graph two disjoint connected subgraphs G1 . . . Gn .Figure 7 shows example. rest section focus graphs G articulationpoints x. consider cyclic runs. previous sections, treated m[s, s] dont care symbol,impact number runs. section, make different assumption. Every cellm[s, s] gets distinct symbol, called s-singleton, always creates run,merged adjacent symbols common run. makes proofs easierclearly significant impact number runs.Definition 5. call x-block ordering node ordering x comes first, nodes G1come next contiguous block, way block Gn .606fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODINGFigure 7: graph articulation point x. Removing x would decompose graph fourdisjoint components, depicted G1 G4 .example shown Figure 7, ordering = x, a, b, c, d, e, f, g examplex-block ordering.use o|G0 denote projection node ordering subset nodes correspondingsubgraph G0 G. use denote subgraph induced nodes Gi {x}.10say order rotation another order o0 obtained o0 taking blocko0 elements beginning appending end. instance, d, e, f, g, x, a, b, crotation x, a, b, c, d, e, f, g. formally, rotation o0 two sub-ordersexist o0 = , = , .Lemma 2. Let x articulation point graph G. Every node order rearrangedx-block ordering o0 without increasing number runs row.Given graph G, node ordering row subset S, let N (o, G, S) number runsrestricted subset S. Clearly, N (o, G, G) total number runs.Lemma 3. Given x-block ordering o, that:1. N (o, G, Gi ) = N (o|i , , Gi );P2. N (o, G, {x}) = 1 n + N (o|i , , {x});P3. N (o, G, G) = 1 n + N (o|i , , ).proofs Lemmas 2 3 available Appendix B.Theorem 4. Given optimal order oi every subgraph induced , constructoptimal global ordering G following. Obtain new orderings o0i rotating oi xcomes first, removing x. Then, = x, o01 , . . . , o0n optimal.Proof. show, contradiction, global ordering optimal. Notice o|i optimal. Assume strictly better ordering o0 . According Lemma 2, exists x-block10. subgraph induced subset nodes contains nodes edges whose ends belong S.607fiS TRASSER , B OTEA , & H ARABORordering o00 least good o0 .N (o, G, G) = 1 n +X1n+XN (o|i , , )N (o00 |i , , )= N (o00 , G, G) N (o0 , G, G)contradiction o0 strictly better (i.e., N (o0 , G, G) < N (o, G, G)).Lemma 4. G tree depth-first preorder G (with arbitrary root) rotatedx-block order every node x.Proof. Every preorder induces rooted tree. respect root every node x (except root)parent p possibly empty sequence direct children c1 . . . cn ordered waydepth-first search visited them. removing x, G decomposed subgraphs Gp ,Gc1 . . . Gcn . x root Gp empty graph. order following structure:nodes Gp , x, nodes Gc1 . . . nodes Gcn , remaining nodes Gp . Clearlyrotated x-block ordering.Theorem 5. G = (V, E) tree depth-first preorder G N (o, G, G) = 3|V | 2.Proof. direct consequence Lemma 4 every node v many runs d(v) + 1,d(v) degree node. +1 comes v-singleton. thusN (o, G, G) =XvV(d(v) + 1) = 2|E| + |V | = 3|V | 2.Theorem 6. Computing optimal order graph G fixed-parameter tractable sizelargest two-connected component G (i.e., largest component articulation points).Proof. Recursively decompose G articulation points two-connected parts left.size parts depend size G enumerate orders pickbest one. Given optimal orders every part use Theorem 4 construct optimal globalorder.able decompose graphs along articulation points useful real-world road networks.graphs tend large two-connected component many small trees attached. example Europe graph made available 9th DIMACS challenge (Demetrescu, Goldberg,& Johnson, 2009) 18M nodes total 11.8M within largest twoconnected component. result allows us position 6.2M nodes order fast optimallyusing local information.608fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODING8. Heuristic Node OrderingsSections 5 6 shown computing optimal order NP-hard theory. Fortunately, NP-hardness rule existence good heuristic orderingscomputed quickly. Indeed, simple depth-first preorder works well practice. observation partially explained fact that, shown Section 7, depth-first preorderoptimal trees. However, also explain using informal intuitive terms.ordering good neighboring nodes graph assigned neighboring IDs.consistent previous observation (Sankaranarayanan et al., 2005; Botea, 2011) that, twotarget nodes close other, chances first move current node towardstargets same. depth-first preorder achieves goal assigning close IDsneighboring nodes low degree graphs. node either interior node, root, leafDFS tree. nodes graph tend interior nodes. these, depth-first preorderassign two neighboring nodes adjacent IDs. Denote v internal node, p parentc first child v. ID p ID v minus 1, whereas ID c IDv plus one. guarantee nothing children. However, average node degreelow, case example road graphs, many children.Besides using depth-first preorders, also propose another heuristic based intuition assigning close IDs close nodes. based cuts. formulated intuitiveoptimization criterion also formulated following: every edge, endpointsclose ID. Obviously fulfilled edges once. reason proposed ordering tries identify small set edges property may violated.using balanced edge cuts. Given graph n nodes want assign IDs range [1, n]using recursive bisection. first step algorithm bisects graph two parts nearlyequal node counts small edge cut size. divides ID range middle assignslower IDs one part upper IDs part. continues recursively bisectingparts dividing associated ID ranges parts constant size left.described far algorithm free decide part assigns lowerupper ID ranges. reason augment tracking every node v two counters h(v)`(v) representing number neighbors guaranteed higher lower IDs. Initiallycounters zero. every bisection ranges assigned algorithm iteratesedge cut increasing counters border nodes. deciding two parts p qgets ranges uses counters estimate ID distance parts nodes aroundthem. evaluatesXXXXh(v)`(v) <h(v)`(v)vqvqvpvpassigns higher IDs p condition holds. algorithm encounters partsmall bisected assigns IDs ordered `(v) h(v).9. CompressionLet a1 . . . denote uncompressed row first-move matrix. stated previously, SRCcompresses list runs ordered start. compressed rows vary size, needadditional index array maps source node onto memory offset first run609fiS TRASSER , B OTEA , & H ARABORrow corresponding s. arrange rows consecutively memory therefore end ssrow also start + 1s row. therefore need store row ends.9.1 Memory Consumptionrequired node IDs encodable 28 bits out-edge IDs 4 bits. encode runsstart upper 28 bits 32-bit machine word value lower 4 bits. total memoryconsumption therefore 4 (|V | + 1 + r) bytes r total number runs rows|V | + 1 number offsets index array. Notice that, implementation, assume4 bytes per index entry sufficient, equivalent saying r < 232 . formulaeasily adapted sizes (i.e., number bits) node IDs, edge IDs, index entries.instance, sum one node ID one edge ID K bytes, J bytes sufficientencode index run (in words, number r fits J bytes), formula becomesJ (|V | + 1) + K r bytes.9.2 Computing RowsRows computed individually running variant Dijkstras one-to-all algorithm everysource node compressed described detail Section 9.3. However, dependinggraph possible shortest paths unique may differ first edge. thereforepossible multiple valid uncompressed rows exist tie-break paths differently. rowsmay also differ number runs therefore different compressed sizes. minimizecompressed size row, instead using Dijkstras algorithm compute one specific rowa1 . . . modify compute sets A1 . . . valid first move edges. requireshortest st-path must exist uses first edge. algorithm maintains alongsidetentative distance array d(t) node set valid first move edges . algorithmrelaxes edge (u, v) decreasing d(v) performs Av Au . d(u) + w(u, v) = d(v)performs Av Av Au . restricted out-degree node 15 storesets 16-bit bitfields. Set union performed using bitwise-or operation.9.3 Compressing Rows Run Length Encodingevery target compression method given set valid first move edges may pick oneminimizes compressed size. formalize subproblem following: Given sequencesets A1 . . . find sequence a1 . . . ai Ai minimizes number runs.show subproblem solved optimally using greedy algorithm. algorithm beginsdetermining longest runincludes a1 .done scanning A1 . . . Ai Ai+1intersection empty: j[1,i] Aj 6= j[1,i+1] Aj = . algorithm choosesvalue intersection (it matter which) assigns a1 . . . ai . continuesdetermining longest run starts contains ai+1 way. procedureiterated rows end reached. approach optimal showoptimal solution longest first run exists. valid solution longer first run.optimal solution shorter first run transformed increasing first runs lengthdecreasing second ones without modifying values. subsequences exchangedwithout affecting surroundings conclude greedy strategy optimal.610fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODING1b,5a,2e,34c,35d,62f ,43123451/a1/a 3/f 4/e1/f 3/d1/e 3/d 4/c1/c(a) Input(b) SRC12345XX 3/f 4/e1/f1/e 4/cZ(c) MRC per row info.X 1/a3/dZ 1/c(d) MRC per group info.Figure 8: MRC applied toy graph Figure 2, reproduced convenience, left.Part (b) illustrates SRC input full runs Rs every row. Part (c) show groups (X,, Z) row row-specific runs R0 . Finally, part (d) depicts runs R0 g sharedrows group.9.4 Merging Rows using Groupscompress individual rows exploited shortest paths t1 t2 oftenfirst move t1 t2 close. similar observation made close source nodess1 s2 . compressed rows tend resemble other. want compressdata exploiting redundancy. call technique multi-row compression (MRC)illustrate Figure 8. partition nodes groups store group informationshared nodes group. row store information unique it. Denoteg(s) unique group node s. Two runs different rows start value32-bit pattern. Denote Rs set runs row s. Instead storingrowwhole set Rs store group h intersection rows. is,0store R h = ih Ri . row store R0 = Rs \ Rg(s) . Recall query targetconsists finding max{x Rs | x < t0 } (where t0 = 15t + 16). Notice formularewritten using basic set logic max{max{x R0 | x < t0 }, max{x R0 g(s) | x < t0 }}implemented using two binary searches R0 stored ordered arrays. Noteneed second index array lookup R0 g groups g.9.5 Computing Row Groupsdesign close source nodes close node IDs thus neighbouring rows. motivatesrestricting row-run groupings. is, group h rows jrows [i, j] belong group. optimal row-run grouping computed usingdynamic programming. Denote S(n) maximum number runs saved compared usinggroup-compression restricted first n rows. Notice S(1) = 0. Given S(1) . . . S(n)want compute S(n + 1). Obviously n + 1s row must part theTlast group. Supposelast group length ` save total S(n + 1 `) + (` 1) | i[n+1`,n+1] Ri | runs.n different values ` enumerate, brute force, possible values,resulting algorithm running time (n2 ). observe intersection largegroups often seems nearly empty therefore test values ` 100 resulting(n) heuristic.611fiS TRASSER , B OTEA , & H ARABOR10. QueriesGiven source node target node (with 6= t) algorithm determines first edgeshortest st-path. first determining start end compressed rowusing index array. runs binary search determine run containingcorresponding out-edge ID. precisely algorithm searches run largest startstill smaller equal t. Recall encode run single 32-bit machine wordhigher 28 bits runs start. reinterpret 32-bits unsigned integers.algorithm consists binary search ordered 32-bit integer largest elementlarger 16t + 15 (i.e., higher 28 bits 4 lower bits set).Extracting path using CPDs extremely simple recursive procedure: beginning startnode extract first move toward target. follow resultant edge neighbouringnode repeat process target reached.11. Experimental Setupevaluate work consider two types graphs: road graphs grid-based graphs.cases assume node IDs encoded within 28-bit integers. assume15, use distinct value (15) indicate invalid edge. allows us encodeout-edge IDs within 4 bits. Note concatenation node ID out-edge ID fitssingle 32-bit machine word.experiments performed quad core i7-3770 CPU @ 3.40GHz 8MB combined cache, 8GB RAM running Ubuntu 13.10. algorithms compiled using g++ 4.8.1-O3. reported query times use single core.11.1 Grid Graphschosen three benchmark problem sets drawn real computer games. first two setsbenchmark instances appeared 2012 Grid-Based Path Planning Competition. thirdbenchmark set consists two worst case maps terms size. two maps available partNathan Sturtevants extended problem repository http://movingai.com/benchmarks/part 2012 competition set.first benchmark set features 27 maps come game Dragon Age Origins.maps 16K nodes 119K edges, average.second benchmark set features 11 maps come game StarCraft.maps 288K nodes 2.24M edges, average.third benchmark set comprises two large grids evaluate separately.largest maps available two games. extended Dragon Age Originsproblem set choose map called ost100d. 137K nodes 1.1M edges.extended StarCraft problem set choose map called TheFrozenSea.754K nodes 5.8M edges. Note ost100d, largest Dragon AgeOrigins map, smaller average StarCraft map.grid maps evaluation undirected feature two typesedges: straight edgesweight 1.0 diagonal edges weight 2.612fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODING11.2 Road Graphscase road graphs chosen several smaller benchmarks made available9th DIMACS challenge (Demetrescu et al., 2009).New York City map (henceforth, NY) 264K nodes 730K edges.San Francisco Bay Area (henceforth, BAY) 321K nodes 800K edges.Finally, State Colorado (henceforth, COL) 436K nodes 1M edges.three graphs travel time weights (denoted using -t suffix) geographic distance weights(denoted using -d) available.11.3 Comparisonsimplemented algorithm two variants: single-row-compression (SRC) using rowmerging optimization, multi-row-compression (MRC), using optimization. compareapproaches two recent state-of-the-art methods: Copa (Botea & Harabor, 2013b)RXL (Delling et al., 2014). evaluate two variants Copa. first variant,denote Copa-G, appeared 2012 GPPC optimised grid-graphs. use originalC++ implementation available competition repository (Sturtevant, 2012a).second variant, denote Copa-R, optimised road graphs. algorithm described(Botea & Harabor, 2013a); used original C++ implementation program versionwell.RXL newest version Hub-Labeling algorithm. asked original authorsrun experiments us presented below. experiments carried Xeon E52690 @ 2.90 GHz. compensate lower clock speed, compared test machine,scale query times RXL factor 2.90/3.40 = 85%. important noteimplementation RXL computes path distances instead first-moves. discussed Section 2make significant difference query times. However unclear us whetherpossible incorporate additional data needed first-move computation compressionschemes presented Delling et al. (2014). reported RXL database sizes thereforeregarded lower bounds.12. Resultsevaluate two algorithms (SRC MRC) terms preprocessing time, compressionperformance query performance. also study impact range heuristic node orderingsusing metrics. three variants, distinguished suffix. suffix +cutindicates node ordering based balanced edge-separators graph cutting technique describedSection 8. suffix +dfs indicates node ordering based depth-first search traversal,described Section 8. suffix +input (or shorter +inp) indicates order nodes takenassociated input file. case grid graphs ordered nodes lexicographically, firsty- x-coordinates. applicable compare work state-of-the-artfirst-move algorithms Copa-R Copa-G. also compare recent hub labelingtechnique known RXL space efficient (but fast) variant called CRXL.613fiS TRASSER , B OTEA , & H ARABORBenchmarkDIMACSDragon Age OriginsStarCraftost100dTheFrozenSeaAverage Preprocessing Time (seconds)Compute OrderSingle Row CompressionMulti Row Compression+cut+dfs+input+cut+dfs+input+cut+dfs+input16<101950198221111953198521252<1032353833364018<1019792181253919932195257419<1n/m101100n/m104105n/m110<1n/m30383605n/m31333690n/mTable 2: Preprocessing time road grid graphs. give results (i) average time requiredcompute node ordering; (ii) total time required compute entire database SRCMRC. Values given nearest second. ost100d TheFrozenSea preprocessing experimentsrun AMD Opteron 6172 48 cores @ 2.1 GHz accelerate APSP computation.experiments smaller graphs clearly show input order fully dominated. therefore omitnumbers two larger test graphs. n/m stands measured.Graph|V ||E||V |CopaG+cutMin < 1K7Q12K 7.2Med5K 7.4Avg 31K 7.4Q352K 7.6Max 100K 7.7<1<11121875<1<1<15631MinQ1MedAvgQ3Max60128183351510934202869148189549105K173K274K288K396K494K7.77.77.87.87.87.8DB Size (MB)Query Time (nano seconds)MRCSRCMRCSRCUM CopaG+dfs +inp +cut +dfs +inp+cut +dfs +inp +cut +dfsDragon Age: Origins (27 maps)<1 <1 <1 <1 <1<13419 26 2614 19<1 <1 <1 <1 <126322 31 3516 2211<1 1212.58130 44 5420 317236853480.515634 50 7225 36102971265135226636 62 106 28 4539 106 35 44 349 500031695 116 176 67 78StarCraft (11 maps)358925 42 187 5512.5 30463 93 130 47 6361 144 33 71 281 1496432470 103 142 51 69111 393 83 126 956 3753833495 121 187 66 77203 444 172 222 983 41472358105 130 195 66 82282 621 222 308 1318 78408396126 146 226 72 90626 1245 630 660 2947 122018 436197 195 311 108 118+inp182638548213888102133132156208Table 3: Performance SRC MRC grid graphs. use two problem sets taken 2012GPPC compare Copa-G, one winners competition. measure (i) sizecompressed database (in MB) and; (ii) time needed extract first query (in nanos). valuesrounded nearest whole number (either MB nano, respectively). baseline, column UM showssize naive, non-compressed first-move matrix.12.1 Preprocessing TimeTable 2 gives average preprocessing time SRC MRC 6 road graphs twocompetition sets. time case dominated need compute full APSP table.previously commented, APSP compression central point work;APSP-computation. preprocessing approach involves executing Dijkstras algorithm repeatedlyresulting total running time O(n2 log n) sparse graphs non-negative weights; usingmodern APSP techniques (e.g., Delling, Goldberg, Nowatzyk, Werneck 2013) succeededsignificantly reducing hidden constants behind big-O able exploit specificgraphs structures (e.g., road graphs) get running time down. However, techniquesgive benefit repeatedly running Dijkstras algorithm asymptotic worst-case.614fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODINGGraphName|V ||E||V |BAY-dBAY-tCOL-dCOL-tNY-dNY-t321K321K436K436K264K264K2.52.52.42.42.82.8DB Size (MB)Query Time (nano seconds)Copa Hub LabelsMRCSRCCopa Hub LabelsMRCSRCUM-R RXL CRXL +cut +dfs +cut +dfs-R RXL CRXL +cut +dfs +cut +dfs317 9019141 129 160 144 51521 527 488 3133 89 100 62 69248 6517102 95 117 107 51521 469 371 1873 74 87 52 60586 138 24228 206 268 240 95048 677 564 3867 125 111 68 85503 9022162 150 192 175 95048 571 390 2131 88 97 58 65363 9921226 207 252 229 34848 617 621 4498 112 122 75 83342 6618192 177 217 198 34848 528 425 2529 98 111 67 75Table 4: Comparative performance SRC, MRC, Copa-R two recent Hub Labeling algorithms.also report size UM uncompressed matrix. test one six graphs 9th DIMACSchallenge. measure (i) database sizes (in MB); (ii) time needed extract first query (in nanos).Values rounded nearest whole number. Graph sizes rounded nearest thousand nodes.Creating node order fast; +dfs requires fractions second. Even +cut orderrequires 18 seconds average using METIS (Karypis & Kumar, 1998). Meanwhile,difference running times SRC MRC indicate multi-row compressionadd small overhead total time. test instancesrecorded preprocessing overhead order seconds.12.2 Compression Query PerformanceTable 3 give overview compression query time performance Copa-Grange SRC MRC variants competition benchmark sets. measure queryperformance run 108 random queries source target nodes picked uniformly randomaverage running times.MRC outperforms SRC terms compression expense query time. Node orderssignificantly impact performance SRC MRC. cases +cut yields smaller databasefaster queries. SRC MRC using +cut +dfs convincingly outperform Copa-Gmajority test maps, terms space consumption query time.naive, non-compressed first-move matrix impractical due large memory requirements. size uncompressed matrix would 4 |V |2 bits, reflecting assumptionoutgoing edge stored 4 bits. Tables 3, 4, 5 specify column UM memory consumption uncompressed matrix. example, ost100d game graph 137K,non-compressed matrix requires bit 9GB memory, two orders magnitude higher 49MB, respectively 39MB SRC+cut respectively MRC+cutneed. larger graphs, difference striking. example TheFrozenSea, largestgame graph, 754K nodes leads 576MB MRC+cut database compared 284GB noncompressed matrix. hand, smaller graphs matrix would fit memory,fetching moves would extremely fast, one table lookup per move. comparison,fetch one move, method performs binary search compressed string whose lengthlarger, usually much smaller |V |.Table 4 look performance 6 road graphs compare Copa-R, SRC, MRC,RXL CRXL. main observations road graphs +dfs leads smaller CPDs+cut. Surprisingly, lower average row lengths yield faster query times. Copa-R dominated RXL, SRC, MRC. SRC+cut outperforms competitors several factors terms615fiS TRASSER , B OTEA , & H ARABORGraphNameost100dFrozenSea|V ||E||V |137K754K7.77.7DB Size (MB)MRCSRCUMRXL CRXL +cut +dfs +cut +dfs6224395049579436429 135576 634 753 740 284405Hub LabelsQuery Time (nano seconds)Hub LabelsMRCSRCRXL CRXL +cut +dfs +cut +dfs598 550189 1105871814 9411 176 192 104 109Table 5: Performance SRC MRC large grid graphs Nathan Sturtevants extended repository.compare Hub Labeling methods RXL, CRXL. also report size UM uncompressed matrix. run tests TheFrozenSea, drawn game StarCraft, ost100d, comesgame Dragon Age Origins. measure (i) database sizes (in MB); (ii) time needed extractfirst query (in nanos). Values rounded nearest whole number. RXL & CRXL exploit graphsundirected SRC & MRC not. directed graphs space consumption RXL would double.GraphBAY-dBAY-tCOL-dCOL-tNY-dNY-tFrozenSeaost100dAverage Row LabelLengthSpace (Bytes)SRCSamPGSRCSamPG+cut +dfs + Plain +cut +dfs51129 108816516 432349479544376 31659160 131944640 5243511496560456 38470248 2031120992 81244214 175704856 70092260 25614721040 102480911081280364 432Table 6: report average number hubs per label (length), number runs per row (length),average space usage per node SamPG+Plain SRC.speed. RXL wins terms database size. However factor gained space smallerfactor lost query time compared SRC. CRXL clearly wins terms space twoorders magnitude slower competition. road graphs distance weights hardertravel time weights. already known algorithms exploit similar graph featuresRXL. However, interesting seemingly unrelated first-move compression based algorithmsincur penalties.Table 5 evaluate performance SRC, MRC, RXL CRXL larger gamemaps. dropped Copa-R experiments smaller graphs clearfully dominated. road graphs, space consumption SRC MRC lower+cut order +dfs. result +cut order clearly superior +dfs game maps.ost100d SRC MRC beat RXL terms query time space consumption.TheFrozenSea RXL needs less space SRC MRC. However, note game maps RXLgains factor 2 exploiting graphs undirected SRC MRC not.CRXL employs powerful compression techniques specific shortest paths. RXL useuncompressed uses basic encoding techniques delta encoding.basic HL variant stores nodes distances explicitly needs memory. referbasic variant SamPG+Plain. SamPG ordering algorithm used RXL11 Plain refers11. RXL-paper describes several node orders. However, SamPG order suggest using. RXLCRXL numbers paper use SamPG.616fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODING1b,5a,2e,32f ,44c,35d,63(a) Input Graph(b) Computing rectangles(c) List rectanglesFigure 9: Copas rectangle decomposition toy example Figures 2 8 firstmoves source node 2. Similar decompositions needed every source node.elementary HL encoding 4 bytes per hub ID 4 bytes per distance value. wantcomparse SRC SamPG+Plain. therefore report Table 6 average number hubsper label average number runs per row using SRC. reported number hubs perlabel. Note directed graphs every node needs two labels: forward backward label.undirected graphs two labels coincide one stored. contrastsSRC cannot exploit input graph undirected. numbers table thereforeassume two HL-labels needed per node better comparability. HL need store32-bit distance value, 28-bit node ID 4-bit out-edge ID times 2two labels per node. total space consumption thus 16h bytes h averagenumber hubs per label. SRC need store 28-bit node ID 4-bit out-edge ID perrun. results 4r bytes r average number runs per row. Table 6seen SamPG+Plain consistently occupies space SRC, even though experimentsthus far suggest RXL compact. basic compression techniques RXL thereforeimportant enough make performance ordering algorithms tip respectspace consumption.RXL advantages visible tables. example require computingAPSP preprocessing step significantly reducing preprocessing time. computesbesides first move also shortest path distance.12.3 Discussioncompared SRC MRC Copa RXL. Copa recent successful technique creating compressed path databases. one joint winners 2012 Grid-Based Path PlanningCompetition (GPPC-12) regard Copa current state-of-the-art range pathfindingproblems including efficient storage extraction optimal first-moves. RXL newestversion Hub-Labeling algorithm knowledge state-of-the-art terms minimizing query times road graphs.617fiS TRASSER , B OTEA , & H ARABORSRC MRC illustrated Figures 1, 2 8. Figure 9 illustrates Copaworks preprocessing, better understanding section, without intention fullydetailed description. Copa assumes every node graph labelled x, coordinates.toy example 3 rows 3 columns, shown Figure 9 (a). Copa iteratesnodes graph. Let n current node (source node) given iteration. Copa splitsmap rectangles, labels rectangle id outgoing edge n.target belongs given rectangle, optimal move n towards precisely labelrectangle. Figure 9 (a) shows map decomposition source node 2, rectangles depicteddashed line. three rectangles constructed figure: one bottom left,size 2 2 label e; one top left, size 1 1 label a; one bottom right,size 1 1 label f . part (b), rectangle represented 5 symbols each: upperrow, left column, width, height, label. show rectangles source node 2,concatenated lists nodes. rectangles safely removed (listtrimming) skip example. Then, 5 columns Figure 9 (a) treatedseparate string, compressed sliding window compression run-lengthencoding.performed experiments large number realistic grid-graphs used GPPC-12 findSRC MRC significantly improve query time compression powerCopa. large number experiments broad range input maps able extractfirst move tens hundreds nano-seconds (a factor 3 5 faster Copa).two main reasons SRC MRC performant vs. Copa: approach uses less memoryquery running time logarithmic (cf. linear) label size.approach requires less memory Copa. Part explanation stems differences sizes building blocks approach. SRC MRC, buildingblock RLE run represented two numbers: start run, node idthus requires log2 (|V |) bits, value run, out-edge id requires log2 ()bits. Copa, building block rectangle requires 2 log2 (|V |) + log2 () bits. actualimplementations, SRC MRC store single 32-bit machine word per run, allows graphs 228 nodes. Copa code used 2012 Grid-Based Path PlanningCompetition stores rectangle 48 bits, corresponding max node count 222 .Clearly, size building blocks reason different compressionresults. number RLE runs SRC MRC differ total number rectanglesCopa. one optimal out-edge exists, SRC MRC select edgeimprove compression, whereas Copa sticks one arbitrary optimal out-edge.hand, besides rectangle decomposition, Copa implements additional compression methods,list trimming, run length encoding sliding window compression, performed toporiginal rectangle decomposition (Botea & Harabor, 2013a).approach asymptotic query time O(log2 (k)) k number compressedlabels must searched. comparison, given source node, Copa stores correspondinglist rectangles decreasing order size. Rectangles checked order. While,worst-case, total number rectangle checks linear size list, average numbermuch improved due ordering mentioned (Botea, 2011; Botea & Harabor, 2013a).reason CPD faster RXL due basic query algorithm. algorithmunderlying RXL consists merge-sort like merge two integer arrays formed forwardlabel backward label t. fast cache friendly operation needs look618fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODINGentry resulting inherently linear time operation. SRC hand builds uponbinary search slightly less cache friendly memory accesses sequentiallogarithmic running time.One regard compressed SRC rows one-sided labels. st-pair first movedetermined using label s. HL hand needs forward labelbackward label t. HL-labels tend less entries SRC labels. However,HL-entry needs space need store distance values addition node-IDs.13. Results 2014 Grid-Based Path Planning Competitionrecently submitted algorithms SRC+cut SRC+dfs 2014 edition GridBased Path Planning Competition GPPC (Sturtevant, 2014). section give brief overviewcompetition short summary results. full description methodology employedorganisers, well full account results, given (Sturtevant et al., 2015).13.1 Competition SetupGrid-Based Path Planning Competition features one hundred grid mapsthree hundred thousand distinct problem instances drawn. Individual maps differ size,ranging several thousand several million nodes. topography maps also variedmany maps originating computer games StarCraft, Dragon Age: Origins DragonAge 2. maps appearing part competition synthetically generated grids; mazes,rooms randomly placed obstacles varying density. 2014 edition competitiontotal 14 different entries, submitted 6 different teams. Several entries variantsalgorithm submitted team.6 entries employ symmetry breaking speed search. entries BLJPS, BLJPS2, JPS+JPS+Bucket roughly described extensions Jump Point Search (Harabor &Grastien, 2011) JPS+ (Harabor & Grastien, 2014). entry NSubgoal makes usemulti-level Subgoal Graphs (Uras & Koenig, 2014). Finally entry named BLJPS Subhybrid algorithm makes use Jump Point Search Subgoal Graphs.1 entry (CH) employs variation Contraction Hierarchies (Dibbelt et al., 2014).3 entries directly improve performance A* algorithm; either use fasterpriority queues (A* Bucket) trading optimality speed (RA* RA*-Subgoal).4 entries use Compressed Path Databases. Two (SRC+dfs-i SRC+cut-i)incremental algorithms return optimal path one segment time; is, mustcalled repeatedly target location returned. two algorithms (SRC+dfsSRC+cut) non-incremental queried return complete path.Unfortunately, 3 entries contained bugs therefore finish instances.SRC+cut one them. therefore omit tables discussion.13.2 Resultssummary results competition given Table 7. observe following:619fiS TRASSER , B OTEA , & H ARABOREntryRA*BLJPSJPS+BLJPS2RA*-SubgoalJPS+ BucketBLJPS2 SubNSubgoalCHSRC-dfsSRC-dfs-iAveraged Query Time Test Paths (s)Slowest MoveFirst 20 MovesFull PathPathpathExtraction282 995282 995282 99514 45314 45314 4537 7327 7327 7327 4447 4447 4441 6881 6881 6881 6161 6161 6161 5711 5711 57177377377336236236214514514514189Preprocessing RequirementsDB SizeTime(MB)(Minutes)00.0200.29471.0470.22640.29471.05240.22932.62 400968.828 00011649.528 00011649.5Table 7: Results 2014 Grid-Based Path Planning Competition. Figures summarisedofficial competition results, appear (Sturtevant et al., 2015). Entries denotedindicate approximate algorithms guaranteed always find shortest path.measurments bold indicate entry performed best regard single criterion.entries whose name bold fully Pareto-dominated respect everycriterion. preprocessing running times time needed process 132 test maps.1. CPD-based entries fastest methods competition across query time metrics. includes fastest (average) time required extract complete optimal path,fastest (average) time extract first 20 steps optimal path fastest (average)time required extract single step optimal path.2. Performing first move query algorithm faster resolution competitions microsecond timer. Even iteratively extracting 20 edges path barelymeasurable without finer timer resolution. testing observed significantamount query running time spent within benchmarking code providedcompetition. therefore opted submit two variants. SRC+dfs extracts pathwhole. benchmarking code thus run per path. hand SRC+dfs-iextracts path one edge time. allows measuring time needed individualfirst move query. Unfortunately, also requires executing benchmarking code peredge. difference path extraction running times SRC-dfs SRC-dfs-i (i.e.,44s) time spent benchmarking code.3. algorithm competitor able answer first-move queries fasterfull path extraction.4. entries database driven require generous amounts preprocessing timestorage space. SRC+dfs therefore largest total preprocessing time largesttotal storage cost entries competition.14. Conclusion Future Workstudy problem creating efficient compressed path database (CPD): shortest pathoracle which, given two nodes weighted directed graph, always returns first-move620fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODINGoptimal path connecting them. Starting all-pairs first-move matrix, assumegiven, create oracles compact answer arbitrary first-move queriesoptimally many orders faster otherwise possible using conventional online graph searchtechniques. employ run-length encoding (RLE) compression scheme throughout analyseproblem theoretical perspective empirical one. main idea simple:look re-order nodes (i.e., columns) input first-move matrix good wayRLE-compressed size subsequently reduced.theoretical side show problem finding optimal node ordering,general case directed directed graphs, NP-complete. specific cases,graphs decomposed along articulation points, problem efficiently tackledsolving series independent sub-problems. particular show depth-first traversaltree provides optimal node ordering. results give first theoretical underpinningproblem creating space-efficient CPDs using RLE. work also extends theoretical resultsareas information processing databases (Oswald & Reinelt, 2009; Mohapatra, 2009).empirical side study efficacy three heuristic node orderings: (i) depth-firstordering; (ii) graph-cut ordering based balanced edge separators; (iii) naive baseline givenordering specified input graph. Given ordering first-move matrix, describetwo novel approaches creating CPDs. first these, SRC, uses simple run-length encodingcompress individual rows matrix. second approach, MRC, sophisticatedidentifies commonalities sets labels compressed SRC.range experiments show SRC MRC compress APSP matrix graphshundreds thousands nodes little 1-200MB. Associated query times regularlyrequire less 100 nanoseconds. also compare approaches Copa (Botea, 2012;Botea & Harabor, 2013a), RXL (Delling et al., 2014). range experiments gridroad graphs show SRC MRC competitive Copa often severalfactors better, terms compression query times. also show SRC MRCoutperform RXL terms query time. also summarise results 2014 Grid-BasedPath Planning Competition. particular report SRC fastest methodcompetition across query-time metrics SRC performed better resolutioncompetitions microsecond timer.appear several promising directions current work could extended. Oneimmediate possibility harness available results efficient appproximate TSP algorithmsorder compute better space-efficient node orderings. Another immediate possibilityimprove current MRC compression scheme devising algorithm optimizesassignment first-move IDs.Looking broadly, strength CPDs have, addition fast move extraction,compress kind path network-distance optimal.12multi-agent pathfinding example sometimes useful guarantee properties like mustalways local detour available (Wang & Botea, 2011). Another example turn-costs roadgraphs. Thus one possible possible direction future work create CPDs storepaths satisfying constraints.weakness approach preprocessing APSP-computation required.Delling et al. (2013) shown APSP sometimes computed reasonably fast12. Suboptimal paths, however, introduce additional challenge avoiding infinite loops extracting pathCPD.621fiS TRASSER , B OTEA , & H ARABORgraphs many nodes, APSP remains inherently quadratic number nodesgraph class output size quadratic. approach would therefore hugely profitalgorithm directly compute compressed CPD without first computing first-movematrix intermediate step.15. Acknowledgmentsthank Patrik Haslum, Akihiro Kishimoto, Jakub Marecek, Anika Schumman Jussi Rintanenfeedback earlier versions parts work. would like thank Daniel Delling &Thomas Pajor running Hub-Labeling experiments us.Appendix A. Proof Theorem 2Theorem 2. SimMini1Runs NP-complete.Proof. membership NP straightforward. hardness proof uses reductionHamiltonian Path Problem (HPP) undirected graph. Let G = (V, E) arbitrary undirectedgraph, without duplicate edges, define n = |V | e = |E|. Figure 10 shows toy graph usedrunning example.Starting G, build SimMini1Runs instance follows. define 0/1 matrixe rows n columns. Let r row corresponding edge (u, v), let cu cvcolumns associated nodes u v. m[r, cv ] = m[r, cu ] = 1 m[r, c] = 0columns. Notice least value 1 every row column. Figure 11 showsmatrix running example.xwzFigure 10: Sample graph G.Let r matrix row corresponding edge (u, v). easy see that, givenordering columns (nodes) makes two nodes u v adjacent, number sequential(x, y)(x, w)(x, z)(w, z)x11101000w0101z0011Figure 11: Matrix built G.622fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODING(x, z)(w, z)(x, w)(x, y)0001x0011w0110z1100Figure 12: matrix after: i) converting 1s 0s (shown bold); ii) re-ordering columnsHamiltonian path; iii) re-ordering rows lexicographically.(x, z)(w, z)(x, w)(x, y)0001x1011w0110z1100Figure 13: Matrix restoring back previously replaced 1s (shown bold).RLE 1-runs13 row r 1. nodes adjacent, number sequential RLE 1-runsrow r 2.claim HPP solution iff SimMini1Runs solution = 3e n + 2 RLE1-runs. Let vi1 , . . . , vin solution HPP (i.e., Hamiltonian path), let P setedges included solution. running example, let P contain (y, x), (x, w) (w, z).every row corresponding edge contained P , switch one two 1-entries0. Then, order columns respect sequence nodes Hamiltonian pathrearrange rows lexicographical order. Figure 12 illustrates changes.construction matrix, trick converting 1s 0s, orderingrows columns reused Oswald Reinelts proof hardness decidingwhether 0/1 matrix C1Sk property (Oswald & Reinelt, 2009). rest proof,coming below, significantly different.Now, restore previously replaced 1s, shown Figure 13. e n + 1 1sreplaced restored adjacent 1s matrix.14 such, counts two1-runs, one horizontal one vertical. sums total 2(e n + 1) 1-runs corresponding1s replaced restored. addition, row column one 1-run. followsmatrix 3e n + 2 1-runs.Conversely, consider row column ordering creates 3e n + 2 RLE 1-runs total.show matrix least e + 1 vertical 1-runs, regardless row ordering. Considerrows, order, starting top. first row introduces exactly 2 vertical 1-runs, onecolumn contains value 1. subsequent row introduces least one vertical1-run. Otherwise, new row would identical previous one, contradicts factgraph duplicate edges.13. runs used proof sequential.14. adjacent 1 column, would imply two identical rows, would meanG duplicate edges. adjacent 1 row, would mean edge hand belongsHamiltonian path, contradicts fact 1s replaced restored complementary set edges.623fiS TRASSER , B OTEA , & H ARABORleast e + 1 vertical 1-runs, number horizontal 1-runs(3e n + 2) (e + 1) = 2e n + 1. show column ordering Hamiltonian path.Assuming contrary, p < n 1 edges nodes adjacentordering. follows number horizontal 1-runs p + 2(e p) = 2e p > 2e n + 1.Contradiction.Appendix B. Proofs Lemma 2 Lemma 3start pointing two simple important properties stemming notion articulation point:Remark 1. Given graph G, let x articulation point, let G1 . . . Gn correspondingconnected components obtained removing x.1. Given source node Gi , first optimal move towards anywhere outside Gisame.152. Given two distinct components Gi Gj , first optimal move x towards anywhereGi different first optimal move x towards anywhere Gj .Remark 1 follows easily obvious observation way going onesubgraph Gi another subgraph Gj passing x. See Figure 7 illustration.Lemma 2. Let x articulation point graph G. Every node order rearrangedx-block ordering o0 without increasing number runs row.Proof. construct desired ordering o0 applying following steps:1. Rotate x comes first.2. every {1 . . . n} project resulting order onto Gi , obtaining suborder o0i .3. Define o0 as: o0 = x, o01 , . . . , o0n .clear construction nodes every subgraph Gi consecutive o0 . remainsshow number runs per row grow.Denote source node. distinguish two cases:Case Gi i. rotation,step 1 impact numbercyclic runs. Steps 2 3 take nodes k6=i Gk put one two blockscyclicadjacent x. know Remark 1, point 1 m[s, x] = m[s, n]nodes n k6=i Gk . Thus, re-arrangement brings next x nodes nfirst-move symbol x. Clearly, increase number runs.Case = x. previous case, rotation performed step 1 increasenumber cyclic runs. step 1, cyclic runs sequential runs equivalent, sincefirst position contains distinct symbol, namely x-singleton. Steps 2 3 separate15. Assuming split ties among optimal paths consistent manner, easy ensure.624fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODINGGi contiguous block. increase number sequential runs since,according Remark 1, point 2, every two blocks corresponding Gi Gj , 6= j,common symbol. follows number cyclic runs increase either.Lemma 3. Given x-block ordering o, that:1. N (o, G, Gi ) = N (o|i , , Gi );P2. N (o, G, {x}) = 1 n + N (o|i , , {x});P3. N (o, G, G) = 1 n + N (o|i , , ).Proof. prove point follows.1. x-block ordering, nodes come order x, G1 , . . . Gi , . . . Gn . Considernode Gi corresponding row first-move matrix. pointed Remark 1,every path node outside Gi pass x, therefore first moveanywhere outside Gi same. follows nodes sequence x, G1 , . . . Gi1 ,together nodes sequence Gi+1S, . . . Gn , form one cyclic run. effect, removingconsideration nodes contained k6=i Gk leaves number runs unchanged,completes proof case.2. case focused x start node. According Remark 1, Gi 6= Gj ,first move x towards anywhere Gi different first move x towardsanywhere Gj . follows two runs two adjacent subsets Gi Gi+1 never mergeone run. Thus,XN (o, G, {x}) = 1 +(N (o|i , , {x}) 1)= 1n+XN (o|i , , {x}).3. case follows previous two, standard arithmetic manipulation.XN (o, G, G) = N (o, G, {x}) +N (o, G, Gi )= 1n+X= 1n+X(N (o|i , , {x}) + N (o|i , , Gi ))N (o|i , , {x}) +XX= 1n+(N (o|i , , {x} Gi )= 1n+XN (o|i , , ).625N (o|i , , Gi )fiS TRASSER , B OTEA , & H ARABORReferencesAbraham, I., Delling, D., Fiat, A., Goldberg, A. V., & Werneck, R. F. (2012). HLDB: Locationbased services databases. Proceedings 20th ACM SIGSPATIAL InternationalSymposium Advances Geographic Information Systems (GIS12), pp. 339348. ACMPress. Best Paper Award.Abraham, I., Delling, D., Goldberg, A. V., & Werneck, R. F. (2011). hub-based labeling algorithmshortest paths road networks. Proceedings 10th International SymposiumExperimental Algorithms (SEA11), Vol. 6630 Lecture Notes Computer Science, pp.230241. Springer.Abraham, I., Delling, D., Goldberg, A. V., & Werneck, R. F. (2012). Hierarchical hub labelingsshortest paths. Proceedings 20th Annual European Symposium Algorithms(ESA12), Vol. 7501 Lecture Notes Computer Science, pp. 2435. Springer.Akiba, T., Iwata, Y., & Yoshida, Y. (2013). Fast exact shortest-path distance queries large networks pruned landmark labeling.. Proceedings 2013 ACM SIGMOD InternationalConference Management Data (SIGMOD13), pp. 349360. ACM Press.Antsfeld, L., Harabor, D., Kilby, P., & Walsh, T. (2012). Transit routing video game maps..AIIDE.Arz, J., Luxen, D., & Sanders, P. (2013). Transit node routing reconsidered. Proceedings12th International Symposium Experimental Algorithms (SEA13), Vol. 7933 LectureNotes Computer Science, pp. 5566. Springer.Babenko, M., Goldberg, A. V., Kaplan, H., Savchenko, R., & Weller, M. (2015). complexity hub labeling. Proceedings 40th International Symposium MathematicalFoundations Computer Science (MFCS15), Lecture Notes Computer Science. Springer.Baier, J., Botea, A., Harabor, D., & Hernandez, C. (2014). fast algorithm catching preyquickly known partially known game maps. Computational Intelligence AIGames, IEEE Transactions on, PP(99).Bast, H., Delling, D., Goldberg, A. V., MullerHannemann, M., Pajor, T., Sanders, P., Wagner, D., &Werneck, R. F. (2015). Route planning transportation networks. Tech. rep. abs/1504.05140,ArXiv e-prints.Bast, H., Funke, S., & Matijevic, D. (2009). Ultrafast shortest-path queries via transit nodes.Shortest Path Problem: Ninth DIMACS Implementation Challenge, Vol. 74 DIMACSBook, pp. 175192. American Mathematical Society.Bast, H., Funke, S., Matijevic, D., Sanders, P., & Schultes, D. (2007). transit constant shortestpath queries road networks. Proceedings 9th Workshop Algorithm EngineeringExperiments (ALENEX07), pp. 4659. SIAM.Bauer, R., Columbus, T., Katz, B., Krug, M., & Wagner, D. (2010). Preprocessing speed-uptechniques hard. Proceedings 7th Conference Algorithms Complexity(CIAC10), Vol. 6078 Lecture Notes Computer Science, pp. 359370. Springer.Bauer, R., Columbus, T., Rutter, I., & Wagner, D. (2013). Search-space size contraction hierarchies. Proceedings 40th International Colloquium Automata, Languages,626fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODINGProgramming (ICALP13), Vol. 7965 Lecture Notes Computer Science, pp. 93104.Springer.Bellman, R. (1958). routing problem. Quarterly Applied Mathematics, 16, 8790.Botea, A. (2011). Ultra-fast optimal pathfinding without runtime search. Proceedings Seventh AAAI Conference Artificial Intelligence Interactive Digital Entertainment (AIIDE11), pp. 122127. AAAI Press.Botea, A. (2012). Fast, optimal pathfinding compressed path databases. ProceedingsSymposium Combinatorial Search (SoCS12).Botea, A., Baier, J. A., Harabor, D., & Hernandez, C. (2013). Moving target search compressedpath databases. Proceedings International Conference Automated PlanningScheduling ICAPS.Botea, A., & Harabor, D. (2013a). Path planning compressed all-pairs shortest paths data.Proceedings 23rd International Conference Automated Planning Scheduling.AAAI Press.Botea, A., & Harabor, D. (2013b). Path planning compressed all-pairs shortest paths data.Proceedings International Conference Automated Planning Scheduling ICAPS.Botea, A., Strasser, B., & Harabor, D. (2015). Complexity Results Compressing Optimal Paths.Proceedings National Conference AI (AAAI15).Bulitko, V., Bjornsson, Y., & Lawrence, R. (2010). Case-based subgoaling real-time heuristicsearch video game pathfinding. J. Artif. Intell. Res. (JAIR), 39, 269300.Bulitko, V., Rayner, D. C., & Lawrence, R. (2012). case base formation real-time heuristicsearch. Proceedings Eighth AAAI Conference Artificial Intelligence Interactive Digital Entertainment, AIIDE-12, Stanford, California, October 8-12, 2012.Cohen, E., Halperin, E., Kaplan, H., & Zwick, U. (2002). Reachability distance queries via2-hop labels. Proceedings Thirteenth Annual ACM-SIAM Symposium DiscreteAlgorithms, SODA 02, pp. 937946, Philadelphia, PA, USA. Society Industrial Applied Mathematics.Culberson, J. C., & Schaeffer, J. (1998). Pattern databases. Computational Intelligence, 14(3),318334.Delling, D., Goldberg, A. V., Nowatzyk, A., & Werneck, R. F. (2013). PHAST: Hardwareaccelerated shortest path trees. Journal Parallel Distributed Computing, 73(7), 940952.Delling, D., Goldberg, A. V., Pajor, T., & Werneck, R. F. (2014). Robust distance queries massivenetworks. Proceedings 22nd Annual European Symposium Algorithms (ESA14),Vol. 8737 Lecture Notes Computer Science, pp. 321333. Springer.Delling, D., Goldberg, A. V., & Werneck, R. F. (2013). Hub label compression. Proceedings12th International Symposium Experimental Algorithms (SEA13), Vol. 7933Lecture Notes Computer Science, pp. 1829. Springer.Demetrescu, C., Goldberg, A. V., & Johnson, D. S. (Eds.). (2009). Shortest Path Problem: NinthDIMACS Implementation Challenge, Vol. 74 DIMACS Book. American MathematicalSociety.627fiS TRASSER , B OTEA , & H ARABORDibbelt, J., Strasser, B., & Wagner, D. (2014). Customizable contraction hierarchies. Proceedings13th International Symposium Experimental Algorithms (SEA14), Vol. 8504Lecture Notes Computer Science, pp. 271282. Springer.Dijkstra, E. W. (1959). note two problems connexion graphs. Numerische Mathematik,1, 269271.Felner, A., Korf, R. E., Meshulam, R., & Holte, R. C. (2007). Compressed pattern databases.. J.Artif. Intell. Res. (JAIR), 30, 213247.Ford, Jr., L. R. (1956). Network flow theory. Tech. rep. P-923, Rand Corporation, Santa Monica,California.Geisberger, R., Sanders, P., Schultes, D., & Delling, D. (2008). Contraction hierarchies: Fastersimpler hierarchical routing road networks. Proceedings 7th InternationalConference Experimental Algorithms (WEA08), pp. 319333.Harabor, D. D., & Grastien, A. (2011). Online graph pruning pathfinding grid maps. Burgard, W., & Roth, D. (Eds.), Proceedings Twenty-Fifth AAAI Conference ArtificialIntelligence, AAAI 2011, San Francisco, California, USA, August 7-11, 2011. AAAI Press.Harabor, D. D., & Grastien, A. (2014). Improving jump point search. Chien, S., Do, M. B.,Fern, A., & Ruml, W. (Eds.), Proceedings Twenty-Fourth International ConferenceAutomated Planning Scheduling, ICAPS 2014, Portsmouth, New Hampshire, USA, June21-26, 2014. AAAI.Hart, P. E., Nilsson, N., & Raphael, B. (1968). formal basis heuristic determinationminimum cost paths. IEEE Transactions Systems Science Cybernetics, 4, 100107.Hernandez, C., & Baier, J. A. (2011). Fast subgoaling pathfinding via real-time search..Proceedings International Conference Automated Planning Scheduling ICAPS11.Karypis, G., & Kumar, V. (1998). Metis, software package partitioning unstructured graphs,partitioning meshes, computing fill-reducing orderings sparse matrices, version 4.0..Kou, L. T. (1977). Polynomial complete consecutive information retrieval problems. SIAM JournalComputing, 6(1), 6775.Lawrence, R., & Bulitko, V. (2013). Database-driven real-time heuristic search video-gamepathfinding. Computational Intelligence AI Games, IEEE Transactions on, 5(3), 227241.Mohapatra, A. (2009). Optimal Sort Ordering Column Stores NP-Complete. Tech. rep., Stanford University.Oswald, M., & Reinelt, G. (2009). simultaneous consecutive ones problem. Theoretical Computer Science, 410(21-23), 19861992.Samadi, M., Siabani, M., Felner, A., & Holte, R. (2008). Compressing pattern databaseslearning. Proceedings 2008 Conference ECAI 2008: 18th European ConferenceArtificial Intelligence, pp. 495499, Amsterdam, Netherlands, Netherlands. IOSPress.628fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODINGSankaranarayanan, J., Alborzi, H., & Samet, H. (2005). Efficient query processing spatial networks. Proceedings 13th Annual ACM International Workshop Geographic Information Systems (GIS05), pp. 200209.Strasser, B., Harabor, D., & Botea, A. (2014). Fast First-Move Queries Run Length Encoding. Proceedings Symposium Combinatorial Search (SoCS14).Sturtevant, N. (2012a). 2012 Grid-Based Path Planning Competition. https://code.google.com/p/gppc-2012/.Sturtevant, N. (2012b). Website Grid-Based Path Planning Competition 2012. http://movingai.com/GPPC/.Sturtevant, N. (2014). Website Grid-Based Path Planning Competition 2014. http://movingai.com/GPPC/.Sturtevant, N., Traish, J., Tulip, J., Uras, T., Koenig, S., Strasser, B., Botea, A., Harabor, D., &Rabin, S. (2015). grid-based path planning competition: 2014 entries results.Proceedings 6th International Symposium Combinatorial Search (SoCS15). AAAIPress.Uras, T., & Koenig, S. (2014). Identifying hierarchies fast optimal search. Brodley, C. E., &Stone, P. (Eds.), Proceedings Twenty-Eighth AAAI Conference Artificial Intelligence,July 27 -31, 2014, Quebec City, Quebec, Canada., pp. 878884. AAAI Press.Uras, T., Koenig, S., & Hernandez, C. (2013). Subgoal graphs optimal pathfinding eightneighbor grids.. Proceedings International Conference Automated PlanningScheduling ICAPS-13.van Schaik, S. J., & de Moor, O. (2011). memory efficient reachability data structure bitvector compression. Proceedings 2011 ACM SIGMOD International ConferenceManagement Data, SIGMOD 11, pp. 913924, New York, NY, USA. ACM.Wang, K.-H. C., & Botea, A. (2011). MAPP: Scalable Multi-Agent Path Planning AlgorithmTractability Completeness Guarantees. Journal Artificial Intelligence Research (JAIR),42, 5590.629fiJournal Artificial Intelligence Research 54 (2015) 369435Submitted 9/15; published 11/15Continuing Plan Quality OptimisationFazlul Hasan SiddiquiPatrik Haslumfazlul.siddiqui@anu.edu.aupatrik.haslum@anu.edu.auAustralian National University &NICTA Optimisation Research GroupCanberra, AustraliaAbstractFinding high quality plans large planning problems hard. Although currentanytime planners often able improve plans quickly, tend reach limitplans produced still far best possible, planners failfind improvement, even given several hours runtime.present approach continuing plan quality optimisation larger time scales,implementation system called BDPO2. Key approach decompositionsubproblems improving parts current best plan. decomposition basedblock deordering, form plan deordering identifies hierarchical plan structure.BDPO2 seen application large neighbourhood search (LNS) local searchstrategy planning, neighbourhood plan defined replacing onesubplans improved subplans. On-line learning also used adapt strategyselecting subplans subplanners course plan optimisation.Even starting best plans found means, BDPO2 able continueimproving plan quality, often producing better plans anytime plannersgiven enough runtime. best results, however, achieved combinationdifferent techniques working together.1. Introductionclassical AI planning problem involves representing models world (initialgoal states) available actions formal modelling language, reasoningpreconditions effects actions. Given planning problem, planning system(or planner, short) generates sequence actions, whose application transformsworld initial state desired goal state. Thus, planning makes intelligentsystem autonomous construction plans action achieve goals.key concern automated planning producing high quality plans. Planners usingoptimal bounded suboptimal (heuristic) search methods offer guarantees plan quality,unable solve large problems. Fast planners, using greedy heuristic searchtechniques, hand, solve large problems often find poor quality plans.gap capabilities two kinds planners means producing highquality plans large problems still challenge. example gap shownFigure 1. seek address gap proposing new approach continuing planimprovement, able tackle large problems works varying time scales.Anytime search tries strike balance optimal (or bounded suboptimal)greedy heuristic search methods. Anytime search algorithms finding initialsolution, possibly poor quality, quickly continuing search better solutionsc2015AI Access Foundation. rights reserved.fi20010Plan cost30Siddiqui & Haslum******************050100150Problem (sorted)Figure 1: Illustration plan quality gap. dashed line represents best (lowestcost) plan 156 problems Genome Edit Distance (GED) domain (Haslum, 2011)found different non-optimal planners, including anytime planners. solid line represents corresponding highest known lower bound. difference twooptimality gap. ? points represent plans found optimal planners,vertical bars show optimality gap obtained problem-specific algorithm (GRIMM).time given. Anytime search algorithms as, example, RWA*(Richter, Thayer, & Ruml, 2010) AEES (Thayer, Benton, & Helmert, 2012b)successfully used anytime planners. However, planners often effectivemaking use increasing runtime beyond first minutes. Xie, Valenzano, & Muller(2010) define unproductive time planner amount time remainingfinds best plan, total time given. show four IPC-2011 domains(Barman, Elevators, Parcprinter, Woodworking), unproductive time LAMAplanner (which uses RWA*), given 30 minutes per problem, 90%.observed similar results, shown Figure 2. figure shows averageIPC quality score function time several anytime planners plan optimisationmethods, including LAMA planner. (A full description experiment setup,results even anytime planners, presented Section 3, page 392.) LAMAfinds first solution quickly: 92.3% problems solves (within maximum 7hours CPU time per problem), first plan found less 10 minutes. qualityLAMAs plans improve rapidly early on, later trend one flattening out, i.e.,decreasing increase. (The drop beginning due figure showing averageplan quality solved problems: initial, low-quality, plans problems foundaverage drops, increasing better plans found.) 1 7hours CPU time, LAMA improves plans 21.3% solved problems. Yet51.6% problems better plans exist, found methods. timeinterval, LAMAs average plan quality score increases 2.7%, increase370fiContinuing Plan Quality Optimisation0.960.95Average Quality Score (Relative IPC Quality Score / Coverage)0.940.930.920.910.90.890.880.870.860.850.840.83BDPO2 PNGS base plansBDPO2 base plansPNGS base plansIBCS base plansBSS base plansLAMA scratchIBaCoP2 scratch0.8276.565.554.543.532.521.510.500.81Time (hours)Figure 2: Average IPC quality score function time per problem, set 182large-scale planning problems. quality score plan cref/c, c costplan cref reference cost (least cost plans problem); hencehigher score represents better plan quality. Anytime planners (LAMA, IBaCoP2) startscratch, post-processing (PNGS, BDPO) bounded-cost search (IBCS, BeamStack Search) methods start set base plans. curves delayed 1 houraccount maximum time given generating base plan. experiment setupresults additional planners described Section 3.1 (page 392).371fiSiddiqui & HaslumFigure 3: General framework BDPO2least 14.6% possible. Memory-limited branch-and-bound algorithms, like Beam StackSearch (Zhou & Hansen, 2005) may run indefinitely, find improvements slowly.increase average plan quality made BSS entire time depicted Figure2 1.8%.Plan optimisation approaches based post-processing start valid plan seekimprove it. Figure 2 shows results Plan Neighbourhood Graph Search (Nakhost& Muller, 2010). PNGS searches shortcuts subgraph state spaceproblem, constructed around current plan. (The PNGS implementation usedexperiment also applies Nakhosts Mullers action elimination technique.) ApplyingPNGS results substantial plan quality improvements quickly 94.8% improved plansfound less 10 minutes stops, runs memory.summary, experiment shows current anytime plan optimisation methodsbecome unproductive runtime increases, suffer slow rate plan qualityimprovement.present post-processing approach plan optimisation, implementationsystem called BDPO2. (The source code BDPO2 provided on-line appendixarticle.) post-processor, BDPO2 work own: dependsmethods providing initial plan. experiment, set input plans (referredbase plans) best plans found LAMA 1 hour, plan found IBaCoP22014 IPC. Figure 2 shows switching approach timeovercome limitation current anytime planning techniques, continue improveplan quality allotted time increases. best result, shown, obtained chainingseveral techniques together, applying first PNGS base plans, BDPO2best result produced PNGS. result could achieved previous anytimeplanning approaches alone.BDPO2 uses Large Neighborhood Search (LNS), local search technique. localsearch explores neighbourhood around current solution plan better quality validplan. LNS, neighbourhood solution defined destroy repair methods,together replace part current solution, keeping rest unchanged.BDPO2, destroy step selects subsequence linearisation deorderingcurrent plan (we call window) repair step applies bounded-costplanner subproblem finding better replacement subplan. focussolving smaller subproblems makes local search, LNS particular, scale betterlarge problems. size structure neighborhood, however, plays crucial372fiContinuing Plan Quality Optimisationrole performance local search (Hoffmann, 2001). setting, neighbourhood determined strategies used select windows subplanners. destroymethods used LNS algorithms often contain element randomness, localsearch may accept moves lower-quality solutions (Ropke & Pisinger, 2006; Schrimpf,Schneider, Stamm-Wilbrandt, & Dueck, 2000). contrast, explore neighbourhoodsystematically, examining candidate windows generated ordered several heuristics,accept moves strictly better plans. also introduce LNS ideadelayed restarting, meaning search combine multiple local improvementsrestarting next iteration new best plan. found delayedrestarts allow better exploration subplans different parts current plan,helps avoid local minima otherwise occur system attempts re-optimisepart plan successive iterations.BDPO2 framework, shown Figure 3, broadly consists four components: plandecomposition, LNS (i.e., repeated destroy repair steps), windowing, on-lineadaptation. first step, decomposition, uses deordering produce partially orderedplan. Deordering enables windowing strategies find subplans easierimprove on, leading much better anytime performance. use block deordering (Siddiqui& Haslum, 2012), simultaneously decomposes given plan coherent subplans,called blocks, relaxes ordering constraints blocks. Block deordering removesinherent limitations existing, step-wise deordering techniques, abledeorder sequential plans cases step-wise deordering possible.windowing component collection strategies extracting windows blockdeordered plan, ranking policies order windows system attemptsoptimise promising windows first.BDPO2 extends earlier system, BDPO (Siddiqui & Haslum, 2013b), mainly usingvariety alternatives task: BDPO used single windowing strategy (withranking) single subplanner, BDPO2 uses portfolios window generationranking strategies several subplanners. improves capability robustnesssystem, since single alternative (windowing strategy, subplanner, etc.) dominatesothers across problems. Furthermore, take advantage fact systemsolves many subproblems course local search learn on-linebest alternatives current problem. particular, use UCB1 multi-armedbandit learning policy (Auer, Cesa-Bianchi, & Fischer, 2002) subplanner selection,sequential portfolio window ranking policies.remainder article structured follows: Section 2 describes block deordering. theory block deordering presented slightly different earlieraccount (Siddiqui & Haslum, 2012), allowing deordering cases better contrasting traditional partially ordered plan semantics. Section 3 presentsoverview BDPO2 system main empirical results, Sections 4 5 givedetails windowing on-line adaptation components, respectively, includingempirical analysis impact performance system whole. Section 6reviews related work, Section 7 presents conclusions outlines ideas future work.373fiSiddiqui & Haslum2. Plan Decompositionapproach continuing plan quality improvement based optimising planparts, one time. Every subplan consider local optimisation subsequencelinearisation partially ordered plan. Therefore, key step removing unnecessary ordering constraints the, typically sequential, input plan. process calledplan deordering. importance deordering demonstrated one experiments(presented Section 3.6, page 402), apply BDPO2 input plansalready high quality: total plan quality improvement (measured increaseaverage IPC plan quality score) achieved BDPO2 without deordering 28.7%less achieved BDPO2 using plan deordering technique.standard notion valid partially ordered plan requires unordered stepsplan non-interfering (i.e., two subsequences plan unordered, everyinterleaving steps two must form valid execution). limits amountdeordering done, cases extent deordering sequentialplan possible. (An example situation shown Figure 6 page 381.)remedy this, introduced block deordering (Siddiqui & Haslum, 2012), createshierarchical decomposition plan non-interleaving blocks deordersblocks. makes possible deorder plans further, including casesconventional, step-wise, deordering possible. (Again, example foundFigure 6 page 381.) section, present new, slightly different accounttheory practice block deordering. First, relaxes restriction block deorderedplans, thereby allowing deordering plans. Second, contrasts semanticsblock decomposed partially ordered plans traditional partially ordered plansemantics clearer way.Sections 2.12.3 describe necessary background, Sections 2.42.6 introduce blockdecomposed partially ordered plans block deordering algorithm.2.1 Planning Problem, Sequential Plan Validityconsider standard STRIPS representation classical planning problems actioncosts. planning problem tuple = hM, A, C, I, Gi, set atoms(alternatively called fluents propositions), set actions, C : R0+ costfunction actions, assigns action non-negative cost, initialstate, G goal.action characterised triple hpre(a), add(a), del(a)i, pre(a), add(a),del(a) preconditions, add delete effects respectively. also sayaction consumer atom pre(a), producer add(a),deleter del(a). action applicable state pre(a) S,applied S, results state apply(a, S) = (S \ del(a)) add(a). sequenceactions = hai , ai+1 , ..., aj applicable state Si (1) pre(ak ) Sk k j,(2) Si+1 = apply(ai , Si ), Si+2 = apply(ai+1 , Si+1 ), on; resulting stateapply(, Si ) = Si+j+1 .valid sequential plan (also totally ordered plan) seq = ha1 , ..., planningproblem sequence actions applicable G apply(seq , I).actions seq must executed specified order.374fiContinuing Plan Quality Optimisation2.2 Partially Ordered Plan ValidityPlans partially ordered, case actions unordered respectother. partially ordered plan (p.o. plan) tuple, pop = hS, i,set steps (each labelled action A) represents strict (i.e.,irreflexive) partial order S. unordered steps pop executed order.+ denotes transitive closure . element hsi , sj (also si sj ) basicordering constraint iff transitively implied constraints . planstep s, use pre(s), add(s) del(s) denote preconditions, add delete effectsaction associated s. also use terms producer, consumer, deleter,cost plan steps, referring associated actions. include two steps,sI sG . sI ordered steps, consumes nothing produces initiallytrue atoms, sG ordered steps, consumes goal atoms producesnothing.linearisation pop total ordering steps respects . p.o. planpop valid (for planning problem ) iff every linearisation pop valid sequentialplan (for ). words, p.o. plan viewed compact representationset totally ordered plans, namely linearisations.Every basic ordering constraint, si sj , pop set associated reasons, denotedRe(si sj ). reasons explain ordering necessary planvalid: Re(si sj ) non-empty, step precondition may unsatisfiedexecution linearisations pop violate si sj . reasons threetypes:PC(m) (producerconsumer atom m): first step, si , produces precondition second step, sj . Thus, order changed, sj executed si ,precondition sj may established required.CD(m) (consumerdeleter m): second step, sj deletes m, preconditionsi . Thus, order changed, may deleted required.DP(m) (deleterproducer m): first step, si deletes m, producedsecond step, sj . order changed, add effect producer step mayundone deleter, causing later step fail. is, however, necessaryorder producer deleter step may occur producer plandepends added atom.Note ordering constraint several associated reasons, including severalreasons type referring different atoms. producerconsumer relationPC(m) Re(si sj ) usually called causal link si sj (McAllester &Rosenblitt, 1991), denoted triple hsi , m, sj i. causal link hsi , m, sj threateneddeleter may ordered last producer sjsj , since implies possibility false required executionsj . formal definition follows.Definition 1. Let pop = hS, p.o. plan, hsp , m, sc causal link pop .hsp , m, sc threatened step sd deletes neither (1) sc + sd(2) s0p : add(s0p ) sd + s0p + sc true.375fiSiddiqui & Haslummentioned above, p.o. plan, pop = hS, planning problem valid iffevery linearisation pop valid sequential plan . However, following theoremgives alternative, equivalent, condition p.o. plan validity.Theorem 1 (e.g., Nebel & Backstrom, 1994). p.o. plan valid iff every step preconditionsupported causal link threat causal link.condition Chapmans (1987) modal truth criterion,sc S, pre(sc ) :sp : (PC(m) Re(sp sc )st : del(st ) sc + sd s0p : add(s0p ) sd + s0p + sc.2.3 Deorderingprocess deordering converts sequential plan p.o. plan removing orderingconstraints steps, steps plan successfully executedorder consistent partial order still achieve goal (Backstrom, 1998).refer step-wise deordering, distinguish block decompositiondeordering introduce later section. Since current state space search plannersproduce sequential plans efficiently, deordering plays important role efficientgeneration p.o. plans.Let pop = hS, valid p.o. plan. (step-wise) deordering pop valid plan00pop= hS, 0 (0 )+ + . is, popresult removing basicordering constraints without invalidating plan. sequential plan seq = ha1 , ...,represented p.o. plan one step si action ai seq orderingsi sj whenever < j, two steps unordered. Thus, deorderingsequential plan different (further) deordering p.o. plan.Computing (step-wise) deordering minimum number ordering constraintsNP-hard (Backstrom, 1998), several non-optimal algorithms (e.g., Pednault,1986; Veloso, Perez, & Carbonell, 1990; Regnier & Fade, 1991). used variantexplanation-based generalisation algorithm Kambhampati Kedar (1994).algorithm works two phases: first phase constructs validation structure,exactly one causal link hsp , m, sc precondition step sc . sp chosenearliest producer preceding sc input plan, intervening threateningstep (i.e., deletes m) sp sc . (The algorithm Veloso, Perez Carbonellsimilar, selects latest producer instead.) second phase, algorithm buildspartial ordering, keeping orderings original plan either correspondcausal links validation structure required prevent threatening stepbecoming unordered w.r.t. steps causal link.Kambhampati Kedars deordering algorithm, due greedy strategy,guarantee optimality. example fails transform totally ordered planleast-constrained plan shown Figure 4. However, recent study foundalgorithm produce optimal step-wise plan deorderings planstested (Muise, McIlraith, & Beck, 2012).However, motivation plan deordering find deordering adequategenerating useful candidate subplans local optimisation. important achieving376fiContinuing Plan Quality OptimisationFigure 4: example Kambhampati Kedars (1994) algorithm fails findleast constrained plan. (Derived Figure 14 Backstroms 1998 article plandeordering.) Figure (a) sequential input plan, (b) plan produced algorithmchoosing earliest producer (for validation structure) preconditions pq D, (c) minimally ordered version (a). simplicity, goal atomsproduced steps A, B, C shown figure.optimal step-wise deordering overcoming inherent limitation step-wise deordering, allows plan steps unordered non-interfering. Blockdeordering, described next two sections, remove orderings inputplans forming blocks, helps generate decomposed plan suitableextracting subplans local optimisation.2.4 Block Decompositionconventional p.o. plan, whenever two subplans unordered every interleaving stepstwo forms valid execution. limits deordering cases individual stepsnon-interfering. remove restriction, proposed block decomposed partialordering, restricts interleaving steps dividing plan steps blocks,steps block must interleaved steps block. However,steps within block still partially ordered. illustrated exampleFigure 5. figure shows difference linearisations p.o. plan blockdecomposed p.o. plan. b, a, c, valid linearisation standard partial orderingblock decomposed p.o. plan. formal definition block follows.Definition 2. Let pop = hS, p.o. plan. block w.r.t. , subset b stepstwo steps s, s0 b, exists step s00 (S \b) + s00 + s0 .decomposition plan blocks recursive, i.e., block whollycontained another. However, blocks cannot partially overlapping. Two blocksordered bi bj exist steps si bi sj bj si sj neither blockcontained (i.e., bi 6 bj bj 6 bi ).Definition 3. Let pop = hS, p.o. plan. set B subsets blockdecomposition pop iff (1) b B block w.r.t. (2) every bi , bj B,either bi bj , bj bi , bi bj disjoint. block decomposed plan denotedbdp = hS, B, i.377fiSiddiqui & HaslumFigure 5: normal p.o. plan (left) represents set sequential plans linearisations plan steps, example ha, b, c, di, hb, a, c, di, hb, c, a, di, hb, c, d, ai.block decomposed p.o. plan (shown right dashed outlines blocks) allowsunordered blocks executed order, steps different blocksinterleaved. Thus, ha, b, c, di, hb, c, a, di, hb, c, d, ai possible linearisationsplan.semantics block decomposed plan defined restricting linearisations (formust valid) respect block decomposition, i.e.,interleave steps disjoint blocks. bi bj , steps bi must precede steps bjlinearisation block decomposed plan.Definition 4. Let bdp = hS, B, block decomposed p.o. plan planning problem. linearisation bdp total order lin (1) lin (2) everyb B block w.r.t. lin . bdp valid iff every linearisation bdp plan .Blocks behave much like (non-sequential) macro steps, preconditions, adddelete effects subset union constituent steps.enables blocks encapsulate plan effects preconditions, reducing interferencethus allowing deordering. following definition captures preconditionseffects visible outside block, i.e., give rise dependenciesinterference parts plan. need considerdeciding two blocks unordered. (Note responsible step step blockcauses produce, consume threaten atom.)Definition 5. Let bdp = hS, B, block decomposed p.o. plan, b B block.block semantics defined as:b adds iff b precondition m, responsible step badd(s), s0 b, s0 deletes s0 s.b precondition iff responsible step b pre(s),step s0 b causal link hs0 , m, si without active threat.b deletes iff responsible step b del(s), steps0 b s0 adds m.Note block consumes proposition, cannot also produce proposition.reason taking black box view block execution, propositionsimply persists: true execution block begins remains truefinished. steps within block totally ordered, preconditions effectsblock according Definition 5 nearly cumulative preconditions378fiContinuing Plan Quality Optimisationeffects action sequence defined Haslum Jonsson (2000), differenceconsumer block cannot also producer proposition.conventional p.o. plan, valid, must contain threat causal link.contrast, block decomposed p.o. plan allows threat causal link exist plan,long causal link protected threat block structure. causallink protected threat iff either (i) causal link contained blockcontain threat, (ii) threat contained block containcausal link delete threatened atom (i.e., encapsulates delete effect).threat causal link active link protected it, otherwise inactive.formal definition follows.Definition 6. Let bdp = hS, B, block decomposed p.o. plan, st threatcausal link hsp , m, sc bdp . hsp , m, sc protected st iff exist blockb B either following true: (1) sp , sc b; st/ b; (2) st b, sp , sc/ b,/ del(b).example block decomposition protects causal link seen Figure7(i) page 382.following theorem provides alternative criterion validity block decomposed p.o. plan, analogy condition conventional p.o. plan giventheorem cited above. difference block decomposed p.o. plan allowsthreats causal links, long threats inactive. Let bdp = hS, B, blockdecomposed p.o. plan. Analogously Chapmans modal truth criterion, conditionstated follows:sc S, pre(sc )sp : (m add(sp )st : (m del(st ) st 6+ sp sc 6+ st hsp , m, sc protected st )).Theorem 2. block decomposed p.o. plan valid iff every step precondition supportedcausal link active threat.Proof. Let bdp = hS, B, block decomposed p.o. plan planning problem . Letus first prove part, i.e., every step precondition supported causallink active threat every linearisation bdp valid plan . Letseq = h. . . , sc , . . .i arbitrary linearisation bdp total order seq S,pre(sc ). Then, according validity criteria sequential plan, showmust satisfied execution sc seq . Since every step preconditionsupported causal link bdp active threat, must supportedcausal link hsp , m, sc active threat. Moreover, since seq sp seq sc .Let st threat hsp , m, sc bdp . Clearly, sp seq st seq sc possibilitymay cause unsatisfied execution sc . Since hsp , m, sc activethreat, hsp , m, sc protected st , therefore, according Definition 6, either (1)sp , sc b st/ b, (2) st b, sp , sc/ b,/ del(b), must hold. (1) true,sp seq st seq sc occur valid linearisation bdp , since interleavessteps sp , sc b st/ b, thus b block w.r.t. seq . second case, since379fiSiddiqui & Haslum/ del(b) must producer m, s0p b, st seq s0p . Moreover,since sp , sc/ b, sp seq st seq sc true sp seq st seq s0p seq sc . alsomakes true execution sc seq .Let us prove part, i.e., bdp valid every step preconditionsupported causal link active threat. Let sc S, pre(sc ),seq = h. . . , sc , . . .i linearisation bdp total order seq S. consider twopossible situations: (1) producer s0 causal link hs0 , m, sc bdpconstructed, (2) least one producer construct causallink sc atom causal link active threat bdp . shownone situations happen long bdp valid. According situation(1), s0 seq well s0 seq sc . causes unsatisfiedexecution sc seq , i.e., seq become invalid. Consequently, bdp become invalid(since one linearisation invalid), contradicts assumption. Therefore,must exist least one producer s0 construct causal link hs0 , m, sc bdp .Now, situation (2), assume sp last producer execution scseq , i.e., s0p \ sp : add(s0p ) (s0p seq sp sc seq s0p ). Let sp producercausal link hsp , m, sc bdp (which possible, since sp ordered scbdp ). Assume hsp , m, sc active threat st bdp . Since hsp , m, sc activethreat st (i.e., hsp , m, sc protected st ), neither (i) sp , sc b; st/ b,(ii) st b; sp , sc/ b,/ del(b), true. Therefore, sp seq st seq sc possiblelinearisation bdp . Moreover, since producer sp sc ,must unsatisfied execution sc , i.e., seq becomes invalid. Consequently,bdp invalid since one linearisations invalid. Therefore, hsp , m, sc mustactive threat.2.5 Block DeorderingBlock deordering (Siddiqui & Haslum, 2012) process removing orderingsplan steps adding blocks block decomposed p.o. plan. may also add plannew ordering constraints, transitively implied orderingconstraints. Block deordering often remove ordering constraints step-wise deordering not. no-interleaving restriction among blocks affordsus simplified, black box, view blocks localises interactions,preconditions effects executing block whole important. Thus, allows deordering able ignore dependencies effects matterinternally within block. addition providing linearisations, improvingdeordering, blocks formed block deordering often correspond coherent, selfcontained subplans, form basis windowing strategies (described detailSection 4) use generate candidate subplans local optimisation.subsection presents conditions adding blocks block decomposition allows removal basic ordering constraints. complete block deorderingalgorithm presented next subsection.simple example block deordering, Figure 6(i) shows sequential plan smallLogistics problem. plan deordered conventional p.o. plan,plan step reason ordered previous. Block deordering, however,380fiContinuing Plan Quality OptimisationFigure 6: sequential plan block deordering plan two unordered blocksb1 b2. Ordering constraints labelled reasons: producerconsumer (PC),i.e., causal link, deleterproducer (DP), consumerdeleter (CD). Note orderingconstraint sequential plan removed without invalidating it. Thus, step-wisedeordering plan possible.able break ordering s3 s4 removing reason PC(at P1 A) basedformation two blocks b1 b2 shown Figure 6(ii). Neither two blocksdelete add atom P1 (although precondition both). removesinterference them, allows two blocks executed orderwithout interleaving. Therefore, possible linearisations block decomposedp.o. plan hs1, s2, s3, s4i hs4, s1, s2, s3i. Note b2 ordered b1,b1 optimised removing step s3.Besides necessary orderings pair steps plan due reasons PC,CD, DP (stated Section 2.2), valid block decomposed p.o. plan must maintain onetype necessary ordering, called threat protection ordering. removing orderingsx + sy causes block containing steps delete effect,ordering, delete effect causes causal link outside block becomeunprotected (not satisfying either two conditions Definition 6), sx + sythreat protection ordering, may removed. threat protection orderingintroduced block deordering process, introduced removed.demonstrated Figure 7, removing kind ordering leads invalidblock decomposed p.o. plan. threat protection ordering defined formally follows.Definition 7. Let bdp = hS, B, block decomposed p.o. plan, hsp , m, sccausal link protected st bdp . Let b B; st , s0 b; sp , sc/ b; add(s0 );/ del(b); st + s0 . st + s0 threat protection ordering breaking orderingcauses del(b) causes hsp , m, sc become unprotected st .381fiSiddiqui & HaslumFigure 7: Two block decompositions plan containing five steps: s1, s2, s3, s4, s5.decomposition (i), three (transitively reduced) necessary orderings: s1 s2,s2 s3, s4 s5, Re(s1 s2) = {DP(m), DP(n)}, Re(s2 s3) = {PC(m)},Re(s4 s5) = {PC(n)}. decomposition valid since every step preconditionsatisfied causal link without active threats. threat s1 causal link hs4, n,s5i inactive, since link protected block bx = {s1, s2, s3} contains s1delete m, disjoint causal link. forming two blocks, = {s1}bz = {s2, s3} would possible remove s1 s2, shown (ii), since hs2, m, s3iprotected s1 bz . However, decomposition delete effect block bxbecomes del(bx ) = {m, n}, block therefore longer protects hs4, n, s5i. Therefore,decomposition deordering invalid. ordering s1 s2 threat protectionordering, must broken. Note (i) s2 consumers producedatom n, yet acts white knight hs4, n, s5i protect n deleter s1.notion threat protection ordering missing earlier block deorderingprocedure (Siddiqui & Haslum, 2012), relied (implicitly) stronger restrictiondelete effects block change due subsequent deordering inside block.Explicitly checking necessary threat protection orderings allows deorderinginside created blocks take place.remove basic ordering, si sj , block decomposed p.o. plan bdp = hS, B, i,create two blocks, bi bj , si bi , sj bj , bi bj = . Note onetwo blocks consist single step. blocks must consistent existingdecomposition, i.e., B {bi , bj } must still valid block decomposition, senseDefinition 2. remainder subsection, define four rules state conditionsblocks bi bj allow different reasons ordering si sj eliminated.Since ordering si sj exist several reasons (including several reasonstype, referring different atoms), blocks bi bj foundallow us remove every reason Re(si sj ) ordering stepsremoved.Rule 1. Let bdp = hS, B, valid block decomposed p.o. plan, si sj basicordering whose removal cause threat protection ordering removed,PC(m) Re(si sj ). Let bi block, si bi , sj/ bi , s0 bi : si s0 . PC(m)removed Re(si sj ) pre(bi ) sp/ bi sp establishcausal link bi sj .382fiContinuing Plan Quality OptimisationFigure 8: Formation block {s,p} addition causal link hr,m,qi (ii) orderremove reason PC(m) behind basic ordering constraint p q (i). Differentsituations, (iii iv), threat, t, may active hr,m,qi.explanation Rule 1, PC(m) Re(si sj ), bi must produce m. Sincesi produces followed deleter within bi (because si sj basicordering sj/ bi ) way happen bi consumes m. Since planvalid, must producer, sp/ bi , necessarily precedes step (in bi )+consumes m. Note sp sj . adding causal link PC(m) Re(sp sj ) (i.e.,adding hsp , sj already present) allows PC(m) removed Re(si sj ).Theorem 3. Deordering according Rule 1 preserves plan validity.Proof. Let bdp = hS, B, valid block decomposed p.o. plan. Therefore, accordingTheorem 2, every step precondition bdp supported causal link activethreat. Let p q basic ordering constraint (where p, q S), bp , bq B blocksmeet conditions removing PC(m) Re(p q), bp , bq orderedordering constraints. show removing PC(m) Re(p q) results0new plan, bdp= hS, B 0 , 0 i, meets condition Theorem 2, thereforeremains valid.Assume PC(m) Re(p q) removed, precondition q suppliedstep r based newly established causal link hr,m,qi deordering formulating0bp = {s,...,p}, bq = {q} bdp, shown Figure 8 (ii). show hr,m,qi00active threat bdp , therefore, bdpvalid. Assume, active threat,0+t, hr,m,qi bdp . Then, course, r q + t. examine everysituation, active threat hr,m,qi.Situation (1): assume + t, shown Figure 8 (iii). Since active threathr,m,si bdp , according Theorem 2, either contained block383fiSiddiqui & HaslumFigure 9: Formation blocks removing reason CD(m) behind basic orderingp q.delete threatened atom contain hr,m,si, hr,m,si contained0block b0 = {r, s, ...} contain t. first case, also holds true bdp,0therefore, active threat hr,m,qi. second case, b partiallyoverlap bp = {s,...,p}, therefore, either bp b0 b0 bp . bp b0 , bp must contain r,happen according PC removing criteria (i.e., r/ bp must hold) statedRule 1. b0 bp , b0 must contain least r, s, p, b0 partiallyoverlap bp = {s,...,p}. Since also active threat hp,m,qi bdp , hp,m,qimust contained block b00 = {p, q, ...} contain t. Now, since b0b00 partially overlap, b0 b00 (whichever bigger) must contain least r, s, p,q, b0 b00 (whichever bigger) protects hr,m,qi t.Situation (2): assume + p, also shown Figure 8 (iii). Since also activethreat hp,m,qi bdp , like before, show either contained blockencapsulates threatened atom (i.e., delete m) contain hp,m,qi,hp,m,qi contained block b0 = {r, s, p, q, ...} contain t. cases,hr,m,qi protected t.Situation (3): assume + + p shown Figure 8 (iv). possible bp ,since interleave steps bp/ bp . Therefore, bp , causeshr,m,qi protected t. bp contain hr,m,qidelete (since add(p) + p).Therefore, conclude never active threat hr,m,qisituation.Rule 2. Let bdp = hS, B, valid block decomposed p.o. plan, si sj basic orderingwhose removal cause threat protection ordering removed, CD(m)384fiContinuing Plan Quality OptimisationRe(si sj ). Let bi bj two blocks, si bi , sj bj , bi bj = .CD(m) removed Re(si sj ) bi consume m.Theorem 4. Deordering according Rule 2 preserves plan validity.Proof. Let bdp = hS, B, valid block decomposed p.o. plan, p q basicordering constraint, p, q CD(m) Re(p q). order meetcondition Rule 2, let us assume bp block includes r p hr,m,picausal link every consumer bp (if exist) ordered r bdp (asshown Figure 9 (i)). Therefore meets condition bp must consume m. Also,assume bq block contains {q} bp , bq ordered orderingconstraints. Therefore, CD(m) Re(p q) well p q removed, results00new plan bdp= hS, B 0 , 0 i. show bdpvalid according Theorem 2.Since bdp valid, active threat causal link bdp accordingTheorem 2, due deordering p q, deleter q becomes new threat0. However, hr,m,pi contained bp containcausal link hr,m,pi bdpq, therefore, according Definition 6, hr,m,pi protected q, i.e., q becomes0remains valid.inactive threat. result, bdpRule 3. Let bdp = hS, B, valid block decomposed p.o. plan, si sj basic orderingwhose removal cause threat protection ordering removed, CD(m)Re(si sj ). Let bi bj two blocks, si bi , sj bj , bi bj = .CD(m) removed Re(si sj ) bj delete m.Theorem 5. Deordering according Rule 3 preserves plan validity.Proof. Let bdp = hS, B, valid block decomposed p.o. plan, p q basicordering constraint, p, q CD(m) Re(p q). order meet conditionRule 3, let us assume bq block includes q DP(m) Re(q s)every deleter bq (if exist) ordered bdp (as shownFigure 9 (ii)). Therefore meets condition bq must delete m. Also, assume bpblock contains {p}, bp , bq ordered ordering constraints.Therefore, CD(m) Re(p q) well p q removed, results new plan00valid according Theorem 2.= hS, B 0 , 0 i. show bdpbdpSince bdp valid, active threat causal link bdp accordingTheorem 2, due deordering p q, deleter q becomes new threat0causal link hr,m,pi bdp. However, q contained bq contain hr,m,pi,delete m; therefore, according Definition 6, hr,m,pi protected q, i.e.,0q becomes inactive threat. result, bdpsatisfies condition Theorem 2therefore remains valid.Rule 4. Let bdp = hS, B, valid block decomposed p.o. plan, si sj basic orderingwhose removal cause threat protection ordering removed, DP(m)Re(si sj ). Let bj block, sj bj si/ bj . DP(m) removedRe(si sj ) bj includes every step s0 PC(m) Re(sj s0 ).Theorem 6. Deordering according Rule 4 preserves plan validity.385fiSiddiqui & HaslumFigure 10: Formation blocks removing reason DP(m) behind basic orderingp q.Proof. Let bdp = hS, B, valid block decomposed p.o. plan, let p q basicordering constraint (where p, q S). Let bq block includes steps rhq,m,ri, hq,m,si causal links bdp (as shown Figure 9 (ii)). Hence,meets condition Rule 4. Also, assume bp block contains {p} bp , bqordered ordering constraints. result, DP(m) Re(p q) well00= hS, B 0 , 0 i. show bdpp q removed, results new plan bdpsatisfies condition Theorem 2 therefore remains valid.Since bdp valid, active threat causal link bdp accordingTheorem 2, due deordering p q, deleter p becomes new threat0. However, causal links containedcausal links hq,m,ri hq,m,si bdpbq contain p, therefore, according Definition 6, protected p,0i.e., p becomes inactive threat. result, bdpremains valid.Even when, applying four rules above, find blocks bi bj removereasons ordering si sj , thus permitting ordering removed,guaranteed two blocks bi bj unordered. may orderedbi contains step si ordered step bj (whether sjanother). Even not, block b B contains bi (or bj both),b still ordered bj (resp. bi ) due constraint +hsi , sj i, blocks bi bj still ordered, sense bi appear bjlinearisation consistent block decomposition.386fiContinuing Plan Quality Optimisation2.6 Block Deordering Algorithmprevious subsection described four conditions (Rules 14) adding blocksdecomposition allows reasons ordering constraints, thus ultimately orderingconstraints themselves, removed preserving plan validity. Next, describealgorithm uses rules perform block deordering, i.e., convert sequentialplan seq block decomposed p.o. plan bdp .algorithm divided two phases. First, apply step-wise deordering procedure convert seq p.o. plan pop = (S, 0 ). used KambhampatiKedars (1994) algorithm this, simple shown producegood results (Muise et al., 2012), even though optimality guarantee.step-wise plan deordering, extend ordering blocks: two blocks orderedbi bj exist steps si bi sj bj si sj neither block contained(i.e., bi 6 bj bj 6 bi ). case, steps bi must precede steps bjlinearisation block decomposed plan. also extend reasons ordering(PC, CD DP) ordering constraints blocks, set propositionsproduced, consumed deleted block given Definition 5. Recall responsiblestep step block causes produce, consume delete proposition.example, b produces p, must step b produces p, stepblock ordered deletes p; say step responsible b producing p.next phase block deordering, converts p.o. plan pop = (S, )block decomposed p.o. plan bdp = (S, B, 0 ). done greedy procedure,examines basic ordering constraint bi bj turn attempts create blocksconsistent decomposition built far allow orderingremoved. core algorithm Resolve procedure (Algorithm 1). takesinput two blocks, bi bj , ordered (one blocks may consist single step),tries break ordering extending larger blocks, b0i b0j . procedureexamines reason ordering constraint extends one blocks removereason, following rules given previous subsection. this, setspropositions produced, consumed deleted new blocks (b0i b0j ) recomputed(following Definition 5) new reasons ordering constraint arisensteps included added Re(b0i b0j ). repeatedeither reason ordering remains, case new blocks returnedprocedure safely unordered, reason cannot removed, casedeordering possible (signalled returning null). function Intermediate(bi , bj )returns set steps ordered bi bj , i.e., {s | bi + + bj }. Algorithm1 refers nearest step s0 preceding following another step s, means stepsmallest number basic ordering constraints s0 s.applied Resolve procedure basic ordering constraint would obtaincollection blocks break orderings. collectionnecessarily valid decomposition, since blocks may partial overlap.find valid decomposition, use greedy procedure. repeatedly examine basicordering constraint bi bj call Resolve find two extended blocks b0i bi b0j bjallow ordering removed. iteration, constraints checked orderbeginning plan. block, added bdp , removed387fiSiddiqui & HaslumAlgorithm 1 Resolve ordering constraints pair blocks.1: procedure Resolve(bi , bj )2:Initialise b0i = bi , b0j = bj .3:Re(b0i b0j ) 6=4:r Re(b0i b0j )5:r = PC(p)// try Rule 16:Find responsible step b0i nearest s0 6 b0i consumesp s0 + s.7:s0 exists8:Set b0i = b0i {s0 } Intermediate(s0 , b0i ).9:else return null10:else r = DP(p)// try Rule 411:Find responsible step b0j s0 6 b0jhs, p, s0 causal link.12:s0 exists13:Set b0j = b0j {s0 } Intermediate(b0j , s0 ).14:else return null15:else r = CD(p)// try Rule 316:Find responsible step b0j nearest s0 6 b0j produces p,+ s0 .17:s0 exists18:Set b0j = b0j {s0 } Intermediate(b0j , s0 ).19:else// try Rule 220:Find responsible step b0i nearest s0 6 b0i producesp, s0 + s.21:s0 exists22:Set b0i = b0i {s0 } Intermediate(s0 , b0i ).23:else return null.24:Recompute Re(b0i b0j ).25:return (b0i , b0j ).accommodate another block partially overlaps existing block throughoutprocedure, even later (rejected) block could produce deordering onecreated earlier. Since choice deordering apply greedy, result guaranteedoptimal. b0i b0j cannot added decomposition (because onepartially overlaps existing block), consider blocks ordered immediatelybi , check orderings broken simultaneously, using unionblocks returned Resolve ordering constraint. (Symmetrically, also checkset blocks immediately bj , though rarely useful.) additional388fiContinuing Plan Quality Optimisationheuristic, discard two blocks basic ordering constraint stepinternal one blocks (i.e., preceding following steps withinblock) step outside block.ordering removed, inner loop exits ordering relation updatednew constraints b0i blocks ordered bj b0j blocksordered bi . done checking three reasons (PC, CD DP) basedsets propositions produced, consumed deleted b0i b0j . inner looprestarted, ordering constraints previously could broken checkedagain. done removing ordering constraints make possible resolutionconstraints, since removal orderings change set steps intermediatetwo steps.main loop repeats deordering consistent current decomposition found. iteration runs polynomial time, know upperbound number iterations. Note, however, procedure anytime,sense interrupted running completion, result end last completed iteration still block deordering plan. BDPO2, use time-limit 5minutes whole deordering procedure. However, almost every problem consideredexperiments (described Section 3.1), block deordering finishes seconds(except problems Visitall domain, takes couple minutes).summary, deordering makes structure plan explicit, showing us partsnecessarily sequential (because dependency interference) independent non-interfering. Block deordering improves creating on-the-flyhierarchical decomposition plan, encapsulating dependencies interferenceswithin block. Considering blocks, instead primitive actions, units partialordering thus enables deordering plans greater extent, including cases deordering possible using standard, step-wise, partial order plan notion. impactblock decomposition anytime performance plan quality optimisation systemdiscussed Section 3.6.3. System OverviewBDPO2 post-processing-based plan quality optimisation system. Starting initialplan, seeks optimise parts plan, i.e. subplans, replacing lower-costsubplans. refer subplans candidates replacement windows.better plan found certain conditions met, starts newplan. viewed local search, using large neighborhood search (LNS)strategy, neighborhood plan defined set plansreached replacing window new subplan. local search plain hill-climbing:move strictly better neighbouring plan. LNS algorithms, searchingbetter plan neighbourhood done formulating local optimisation problems,solved using bounded-cost subplanners.Block deordering, described previous section, helps identify candidate windowsproviding large set possible plan linearisations; block decomposition also usedwindowing strategies. window subsequence linearisationblock deordered input plan. However, represent window slightly different389fiSiddiqui & Haslumway, partitioning blocks part replaced (w), ordered(p) (q) part.Definition 8. Let bdp = (S, B, ) block decomposed p.o. plan. window bdppartitioning B sets p, w, q, bdp linearisation consistent{bp bw bq | bp p, bw w, bq q}.window defines subproblem, problem finding planfill gap left removing steps w linearisation bdp consistentwindow. problem formally defined follows.Definition 9. Let bdp = (S, B, ) block decomposed p.o. plan planning problem, hp, w, qi window bdp , s1 , . . . , s|p| , s|p|+1 , . . . , s|p|+|w| , s|p|+|w|+1 , . . . , sn linearisation bdp consistent window. subproblem corresponding hp, w, qi,sub , atoms actions . initial state sub , Isub , resultprogressing initial state s1 , . . . , s|p| (i.e., applying s1 , . . . , s|p| I),goal sub , Gsub , result regressing goal sn , . . . , s|p|+|w|+1 .Theorem 7. Let bdp = (S, B, ) block decomposed p.o. plan planning problem , hp, w, qi window bdp , sub subproblem corresponding window,s1 , . . . , s|p| , s|p|+1 , . . . , s|p|+|w| , s|p|+|w|+1 , . . . , sn linearisation sub constructed000 = s0 , . . . , s0 planfrom. Let wsub . s1 , . . . , s|p| , s1 , . . . , sk , s|p|+|w|+1 , . . . , sn1kvalid sequential plan .Proof. proof straightforward. subsequence s1 , . . . , s|p| applicable initialstate , I, and, construction sub , results initial state sub , Isub . Hences1 , . . . , s|p| , s01 , . . . , s0k applicable I, and, construction sub , results statesG satisfies goal sub , Gsub . Since Gsub result regressing goal ,G, s|p|+|w|+1 , . . . , sn reverse, follows subsequence applicable sG ,applying results state satisfying G. (For relevant properties regression,see, example, Ghallab, Nau, & Traverso, 2004, Section 2.2.2.)subproblem corresponding window hp, w, qi always solution, formlinearisation steps w. improve plan quality, however, replacementsubplan must cost strictly lower cost w, C(w). amountssolving bounded-cost subproblems. subplanners used BDPO2described Section 3.3. return question multiple windowswithin plan simultaneously replaced Section 3.5.Algorithm 2 describes BDPO2 performs one step local search, exploringneighbourhood current plan. first step block deorder current plan(line 3). Next, optimisation using bounded-cost subplanner tried systematicallycandidate windows (lines 419), restart condition met (line 18),local improvements possible, time limit reached. point differenceLNS algorithms used delayed restart, meaning explorationneighbourhood continue better plan found. helps avoidlocal minima, driving exploration different parts current plan. restartconditions, impact local search, described Section 3.4.390fiContinuing Plan Quality OptimisationAlgorithm 2 neighbourhood exploration procedure BPDO2.1: procedure BDPO2(in , tlimit , banditPolicy, rankPolicy, optSubprob)2:Initialize: telapsed = 0, last = , trialLimit[1...n] = 1, windowDB =3:bdp = BlockDeorder(in )4:telapse < tlimit last locally optimal5:windows needed6:ExtractMoreWindows(bdp , windowDB, optSubprob)7:8:9:10:11:12:13:14:15:16:17:18:19:20:p = SelectPlanner(banditPolicy)w = SelectWindow(p, rankPolicy, trialLimit, windowDB)w = null windows extract trialLimit[p] += 1w = null continuewnew , searchResult = OptimiseWindow(p, w)UpdateWindowDB(p, w, wnew , optSubprob, searchResult, windowDB)C(wnew ) < C(w)new = Merge(bdp , windowDB)C(new ) < C(last ) last = newUpdateBanditPolicy(p, w, wnew , searchResult, banditPolicy)UpdateRankPolicy(p, searchResult, rankPolicy)C(last ) < C(in ) restart condition truereturn BDPO2 (last , tlimt telapsed , banditPolicy, rankPolicy, optSubprob)return lastkey design goal procedure avoid unproductive time, meaning spendingmuch time one step trying optimise one window options couldlead improvement left waiting. Therefore, steps done incrementally,time limit step could take unbounded time.database (windowDB) stores unique window extracted block deorderedplan, records status (how many times optimisation window triedsubplanner result), structural summary information window. window database populated incrementally (lines 56), applying differentwindowing strategies limit time spent number windows added.limits used 120 seconds 20 windows, respectively. balances timewindow extraction optimisation, prevent procedure spending unproductive time. windowing strategies described Section 4. also compute lowerbound cost replacement plan window, using admissible LM-Cutheuristic (Helmert & Domshlak, 2009). window proven optimal current subplan cost equals bound, previous attempt optimise window exhaustedbounded-cost search space. Already optimal windows are, course, excludedoptimisation. windows added database number windows eligible selected optimisation one subplanner (defined next paragraph)drops threshold. used 75% current window database sizethreshold.391fiSiddiqui & Haslumsubplanner use selected using UCB1 multi-armed bandit policy (Auer et al.,2002), learns repeated trials select often subplanner succeedsoften finding improvements. next window try chosen, among eligibleones database, according ranking policy. Windows eligible optimisationchosen subplanner (1) already proven optimal; (2)tried chosen subplanner current trial limit; (3) overlapimproved window already found. ranking policy heuristic aimed selectingwindows likely improved chosen subplanner. use several rankingpolicies switch one next subplanner fails find improvementnumber consecutive tries, since indicates current ranking policy mayrecommending right windows current problem. threshold usedswitching ranking policy 13. (This 2/3 maximum number windows addedwindow database call ExtractMoreWindows.) ranking policiesdescribed Section 4.6. subplanner given time limit, increased timeretried window. used limit 15 seconds, increasing another15 seconds retry. limit number times retriedwindow kept subplanner. Initially set 1, limit increasedsubplanner tried every window database (excluding windowsalready proven optimal overlap windows better replacementfound) strategy generate new windows (line 9). lower-costreplacement subplan window found, together improvements alreadyfound current neighbourhood fed Merge procedure, triescombine several replacements achieve greater overall plan cost reduction. Mergeprocedure described Section 3.5.procedure restarts new best plan, learned bandit policy subplanner selection current ranking policy (for subplanner) carriednext iteration. also keep database subproblems (defined initialstate goal) whose plan cost proven optimal, avoid trying fruitlessly optimise further. window database, contains information specificcurrent input plan, reset.remainder section organised follows: next two sections describesettings used experiments overview main results, respectively.describe subplanners used BDPO2 (Section 3.3), restart conditions(Section 3.4) Merge procedure (Section 3.5). Section 3.6 discusses impactblock deordering performance system. windowing strategies rankingpolicies described Section 4, details on-line adaptation methodsused presented Section 5.3.1 Experiment Setuppresenting overview results, outline three different experimentalsetups used. experiment setup 2 3 used 182 large-scale instances21 IPC domains. selection domains instances described below.experiment 1, included additional medium-sized instances total 219 instances21 domains. used domains sequential satisficing track392fiContinuing Plan Quality Optimisation2008, 2011, 2014 IPC, except CyberSec, CaveDiving CityCar domains.(The CyberSec domain slow system parse. two conditionaleffects, implementation handle.) also used Alarm ProcessingPower Networks (APPN) domain (Haslum & Grastien, 2011). plans used inputBDPO2 plan produced IBaCoP2 (Cenamor, de la Rosa, & Fernandez, 2014)2014 IPC problems competition, best plan found LAMA(Richter & Westphal, 2010, IPC 2011 version) 1 hour CPU time problems.refer base plans. experiments 2 3, selected domain10 last instances base plan exists. (In domains less 10 instancessolved LAMA/IBaCoP2, total 182 rather 210.) domainsappeared one competition, used instances IPC 2011 set.experiments run 6-Core, 3.1GHz AMD CPUs 6M L2 cache, 8GB memory limit every system. comparing anytime performance BDPO2systems require input plan, count time generate base plan1 hour CPU time. maximum time allocated generating base plan;found much quickly.first experiment, use BDPO2 system. Instead, ran twosubplanners, PNGS IBCS, 30 seconds every subproblem correspondingwindow extracted (by six windowing strategies) base plans, excludingsubproblems window proven optimal lower bound obtainedadmissible LM-Cut heuristic (Helmert & Domshlak, 2009). experiment providedinformation inform design combined window extraction procedure, windowranking policies, aspects system. present results here,refer later discuss system components detail.experiment 2, compare BDPO2 eight anytime planners plan optimisation systems: LAMA (Richter & Westphal, 2010, IPC 2011 version); AEES (implementedFast Downward code base; cf. Thayer et al., 2012b); IBCS (as described Section3.3); Beam-Stack Search (BSS) (Zhou & Hansen, 2005); PNGS, including Action Elimination (Nakhost & Muller, 2010); IBaCoP2 (Cenamor et al., 2014); LPG (Gerevini &Serina, 2002); Arvand (Nakhost & Muller, 2009). BDPO2 uses PNGS IBCSsubplanners, configured described above. AEES uses LM-Cut (Helmert & Domshlak, 2009) admissible heuristic, FF heuristic, without action costsinadmissible estimates. BSS uses LM-Cut heuristic. implementation BSSuse divide-and-conquer solution reconstruction, run beam width500. systems described Section 6.system run 7 hours CPU time per problem. BDPO2 PNGSuse base plans input, IBCS Beam-Stack Search use baseplan cost initial cost bound. mentioned above, allocated 1 hour CPU timegenerating base plan. Therefore, comparing systems plannersstarting scratch (LAMA, AEES, IBaCoP2, LPG Arvand), add 1 hour startdelay runtime. Beam-Stack Search much slower planners usedexperiment. Therefore, ran 24 hours CPU time, reportingresults divide runtime 4. words, results shown hypotheticalimplementation Beam-Stack Search amount search, fasterconstant factor 4.393fiSiddiqui & HaslumExperiment 3 uses setup experiment 2, except input BDPO2best plan found running PNGS 1 hour CPU time, 8 GB memorylimit, base plans. (As mentioned previously, vast majority cases PNGS runsmemory much less time that, cases run 1 hourlimit.) use setup primarily run different configurations BDPO2 analyseimpact different designs (e.g., planner selection window ranking policies,immediate vs. delayed restart, on) setting input plans already goodquality. comparing anytime result BDPO2 experimentsystems, add 2 hours runtime.3.2 Overview ResultsFigure 11 shows headline result, form average plan quality achievedBDPO2 systems time-per-problem increases. IPC quality score plancalculated cref /c, c cost plan cref cost best planproblem instance found runs systems used experiments. Thus,higher score reflects lower-cost plan. results Figure 11 experiment 23, described previous section. shown Figure 2 (on page 371),including results compared anytime planning systems. None plannersstarting scratch find solution 182 problems: LAMA solves 155 problems,IBaCoP2 144, Arvand 134, AEES 87 LPG 49. planners, average qualityscore shown Figure 11 average problems have,time, found least one plan. (As previously mentioned, also reasonaverage quality sometimes falls: first plan, low quality, previously unsolvedproblem found, average decrease.) words, metric unaffecteddifferences coverage. Likewise, none post-processing bounded cost searchmethods improve base plans: BDPO2 finds plan lower cost base plan147 problems, PNGS 133, IBCS 66 Beam-Stack Search 14.systems, average quality shown Figure 11 taken 182 problems, usingbase plan quality score problems system improved on.majority compared systems show trend similar LAMA, i.e.,improving quickly early flattening ultimately stagnating. reasonsvary: Memory limiting factor algorithms, notably PNGS, exhausts8 GB available memory reaching 7 hour CPU time limit 93.7% problems,LAMA, 67% problems. AEES runs memory50% problems. hand, planners use limited-memory algorithms,Beam-Stack Search, LPG Arvand (both use local search), never runmemory thus could conceivably run indefinitely. However, ratefind plan quality improvements small: 4 7 hours, average quality producedLPG Arvand increases 0.0049 0.0094, respectively. (The latter excludes threeproblems solved Arvand first time 4 7 hours; includingbrings average down, making increase less 0.002.) increase averagequality achieved BDPO2, starting high-quality plans generated PNGSbase plans, time interval 0.0115.394fiContinuing Plan Quality Optimisation0.960.940.92Average Quality Score (Relative IPC Quality Score / Coverage)0.90.880.860.840.820.80.780.760.740.720.70.680.660.640.62BDPO2 PNGS base plansBDPO2 base plansPNGS base plansIBCS base plansBSS base plansLAMA scratchAEES scratchIBaCoP2 scratchArvand scratchLPG scratch0.60.580.560.5476.565.554.543.532.521.50.500.510.52Time (hours)Figure 11: Average IPC quality score function time per problem, set 182large-scale planning problems. quality score plan cref/c, c costplan cref least cost plans problem; hence higher score representsbetter plan quality. LAMA, AEES, LPG, Arvand IBaCoP2 planners startscratch, whereas post-processing (PNGS, BDPO2) bounded cost search (IBCS,Beam-Stack Search) methods start set base plans; curves delayed 1hour, maximum time allocated generating base plan. experimentalsetup described detail Section 3.1.395fiSiddiqui & HaslumBDPO2BDPO2PNGS= < ? = < ?Appn5020 4010Barman100 9010Childsnack100 3070Elevators60 6010 10Floortile6778 22GED3020Hiking5070 20Maintenance 100100Nomystery100100 100100OpenstacksParcprinter10022 100224343 14ParkingScanalyzer75 1238 12Sokoban100100Tetris80 4060 20Thoughtful80 3050 20Tidybot4329Transport60 6040 40Visitall60 6030 30Woodworking 70 3050 20Overall66 24 4 47 12 3DomainsLAMAAEESArvandLPGIBCSBSSPNGSIBaCoP2= < ? = < ? = < ? = < ? = < ? = < ? = < ? = <40104010 70 20 20?1010101180 7040 3020 2011 1110331050295050 503311505050 505022 33672288 8811 3343 432071 293333434312 1267112975 126729 1410121410 1018 1481112181 12 2 3 13 120 108 21Table 1: plan improvement method, percentage instances foundplan cost matching best plan (=); found plan strictly better method(<); found plan known optimal, i.e., matched highest lower bound(?). percentage instances domain shown Figure 12. (Zerosomitted improve readability.) BDPO2 PNGS result BDPO2 experiment3; results experiment 2 (see Section 3.1).draw two main conclusions: First, BDPO2 achieves aim continuing qualityimprovement even time limit grows. fact, continues find better plans, thoughdecreasing rate, even beyond 7 hour time limit used experiment. Second,combination PNGS BDPO2 achieves better result either alone. Partlywork well different sets problems figure showingaverage, BDPO2 sometimes produces better result started best planfound PNGS also domains BDPO2 already outperforms PNGS startbase plans (e.g., Elevators Transport). However, also seenopposite domains (e.g., Floortile Hiking), starting BDPO2 worseinput plan often yields better final plan. seen Figure 12, providesdetailed view. shows problem cost best plan foundsystem 7 hour total time limit, scaled interval base plan costhighest known lower bound (HLB) plan problem. (Lower boundsobtained variety methods, including several optimal planners; cf. Haslum,2012.) 18 182 problems excluded Figure 12: 3 cases, base plan costalready matches lower bound, improvement possible; another 15 problems,method improves base plans within stipulated time. (The Pegsol domainappear graph, base plans one optimal, methodimproves cost last one.)396fiContinuing Plan Quality OptimisationBase PlansBest cost achieved (normalised)NomysteryMaintenanceGedFloortileBarmanHikingElevatorsChildsnackAppnHLBLAMA scratchAEES scratchArvand scratchLPG scratchIBaCoP2 scratchPNGS base plansIBCS base plansBSS base plansBDPO2 base plansBDPO2 PNGS base plansBase PlansBest cost achieved (normalised)HLBLAMA scratchAEES scratchArvand scratchLPG scratchIBaCoP2 scratchPNGS base plansIBCS base plansBSS base plansBDPO2 base plansBDPO2 PNGS base plansWoodworkingVisitallTransportTidybotThoughtfulTetrisSokobanScanalyzerParkingParcprinterOpenstacksFigure 12: Best plan cost, normalised interval cost base plancorresponding highest known lower bound, achieved different anytime planoptimisation methods experiment 2, BDPO2 experiments 2 & 3 (see Section3.1).397fiSiddiqui & HaslumTable 1 provides different summary information Figure 12, showingdomain system percentage instances found plan cost (1)matching best plan instance; (2) strictly better method;(3) matching lower bound, i.e., known optimal. aggregate, combinationBDPO2 PNGS base plans achieves best result three measures.However, 5 domains (GED, Hiking, Openstacks, Parking, Tidybot), LAMA findsplans strictly better method. tried using LAMAone subplanners BDPO2, lead better results overall.domains, OpenStacks GED, smallest improvable subplan often whole,almost whole, plan, LAMA finds improvement plan searchinglonger time. Although BDPO2 increases time limit given subplannersretry, average time limit, across local optimisation attempts experiment,18.48 seconds. Thus, strategy searching quick improvements plan partswork well domains.3.3 Subplanners Used Window Optimisationsubplanners used BDPO2 used find plan window subproblem,stated Definition 9, cost less cost current window, C(w).considered three subplanners:(1) Iterated bounded-cost search (IBCS), using greedy search admissible heuristic pruning.(2) Plan neighbourhood graph search (PNGS), including action elimination technique (Nakhost & Muller, 2010).(3) Restarting weighted A? (Richter et al., 2010), implemented LAMA planner.However, experimental setups described previous section, BDPO2 usestwo subplanners, IBCS PNGS. two reasons choosing two: First,show good complementarity across domains. example, IBCS significantly better PNGS APPN, Barman, Floortile, Hiking, Maintenance, Parking, Sokoban,Thoughtful Woodworking domains, PNGS better Elevators, Scanalyzer,Tetris, Transport Visitall domains. Second, learning policy use subplanner selection learns faster smaller number options. Therefore, adding thirdsubplanner improve overall performance BPDO2, given limited time perproblem, subplanner complements two well, i.e., performs wellsignificant fraction instances two not. set benchmarkproblems used experiment, case. (A different set benchmarkscould course yield different outcome.) experiment comparing effectivenessthree subplanners, individually well combination IBCS PNGSlearning policy, BDPO2 presented Section 5.2 page 420.solve bounded-cost problem, IBCS uses greedy best-first search guidedunit-cost FF heuristic, pruning states cannot lead plan within cost boundusing f-value based admissible LM-Cut heuristic (Helmert & Domshlak, 2009).implemented Fast Downward planner. search complete: plan398fiContinuing Plan Quality Optimisationwithin cost bound, prove exhausting search space, given sufficienttime memory. bounded-cost search return plan within costbound. get best subplan possible within given time limit, iterate it: wheneverplan found, long time remains, search restarted bound setstrictly less cost new plan.PNGS (Nakhost & Muller, 2010) plan improvement technique. searches subgraph state space around input plan, limited bound number states,lower cost plan. better plan found exploration limit increased (usuallydoubled); continues time memory limit reached. Like IBCS,iterate PNGS get best subplan possible within given time limit. improvescurrent subplan, process repeated around new best plan.LAMA (Richter & Westphal, 2010) finds first solution using greedy best-first search.switches RWA? (Richter et al., 2010) search better quality solutions.3.4 Restartrestart condition determines trade-off exploring neighbourhoodcurrent solution continuing local search different parts solution space.obvious choice, one used LNS algorithms, restartnew best solution soon one found. call immediate restart. However,found continuing explore neighbourhood current plan even betterplan found, merging together several subplan improvements, describedSection 3.5 below, often produces better results. call delayed restart.Setting right conditions make delayed restart critical successapproach. used disjunction two conditions: First, unionimproved windows found neighbourhood covers 50% steps input plan.Recall continue exploration loop (Algorithm 2) improvementfound, windows overlap already improved window excludedoptimisation. drives procedure search improvements differentparts current plan, helps avoid certain myopic behaviour occurimmediate restarts: restarting new best plan, get new blockdecomposition new set windows; lead attempting re-optimisepart plan improved, even several restarts, may leadlocal optimum time-consuming escape. second condition 39 consecutivesubplanner calls failed find improvement. threshold 39 threetimes threshold switching ranking policy (cf. description Algorithm 2beginning section). means 39 attempts tried optimise13 promising windows, among remaining eligible ones, recommendedranking policies, without success. suggests improvable windowsfound, none ranking policies good current neighbourhood.Making restart point allows exploration return parts planintersect already improved windows, thus increasing set eligible windows.average plan quality, function time-per-problem, achieved BDPO2 usingimmediate restart delayed restart based conditions shown toptwo lines Figure 13 (page 403). experiment, configurations run using399fiSiddiqui & HaslumAlgorithm 3 Merge Improved Windows1: procedure Merge(bdp , windowDB)2:Initialise bdp = bdp3:W = improved windows windowDB sorted cost reduction (C(w) C(wnew ))4:W 6=5:(hp, w, qi, wnew ) = pop window highest C(w) C(wnew ) W6:bdp = ReplaceIfPossible(bdp , hp, w, qi, wnew )7:W = RemoveConflictingWindows(W, bdp )8:return bdpsetup experiment 3, described Section 3.1 page 392. seen,delayed restart yields better results overall. Compared BDPO2 immediate restart,achieves total improvement 12% higher. However, found immediate restartwork better instances, especially Visitall Woodworking domains,BDPO2 immediate restart found better final plan nearly 20% instances.average number iterations (i.e., steps LNS) done BDPO2 usingdelayed restart condition 3.48 per problems across domains consideredexperiment; highest average single domain 8.7, Thoughtful solitaire.immediate restart average domains increases 4.87. words,configurations BDPO2 spend significant time exploring neighbourhood plan.anytime performance curve Figure 13 shows additional time spentneighbourhood using delayed restarts pays off.3.5 Merging Improved WindowsDelayed restarting would benefit without ability simultaneously replaceseveral improved windows current plan. improved windows always nonoverlapping (because better subplan window found, windows overlaplonger considered optimisation) corresponding subproblems maygenerated different linearisations block deordered plan.this, replacement subplans may additional preconditions delete effectsreplaced windows not, lack add effects. Thus, maylinearisation permits two windows simultaneously replaced.Merge procedure shown Algorithm 3 greedy procedure. maintainstimes valid block deordered plan (bdp ), meaning precondition blocksupported causal link active threat. (Recall block contextblock consists single step.) Initially, input plan (bdp ),causal links, ordering constraints, computed block deordering.procedure gets improved windows (W ) window database, tries replacecurrent plan bdp order contribution decreasing plan cost, i.e.,cost replaced window (C(w)) minus cost new subplan (C(wnew )).first replacement always succeeds, since, construction subproblem,linearisation input plan wnew valid (cf. Theorem 7). Subsequentreplacements may fail, case Merge proceeds next improved window W .400fiContinuing Plan Quality OptimisationSince replacing window different subplan may impose new ordering constraints,remaining improved windows conflict partial order current planremoved W .ReplaceIfPossible function takes current plan (bdp ), returns updated plan (which becomes current plan), plan replacementpossible. replacement subplan (wnew ) made single block whose steps totally ordered. preconditions effects block, replaced window(w), computed according Definition 5 (page 378). atom pre(wnew )also w, existing causal link kept; likewise, causal links effect add(w)also add(wnew ) kept. links unthreatened consistentorder, since plan valid replacement. additional preconditionnew subplan, pre(wnew ) \ pre(wi ), causal link hbp , m, bc bdpproducer replaced window (bp w), consumer (bc 6 w),atom link produced replacement subplan (m 6 add(wnew )), newcausal link must found. Given consumer (bc ) atom requires (m pre(bc )),procedure tries following two ways creating unthreatened causal link:(C1) block b0 + bc add(b0 ), every threatening block (i.e.,b00 del(b00 )), either b00 b0 bc b00 added existing plan orderingwithout contradiction, b0 chosen, ordering constraints necessary resolvethreats (if any) added.(C2) Otherwise, block b0 add(b0 ) unordered w.r.t. bc ,every threatening block either b00 b0 bc b00 enforced, b0 chosen,causal link (implying new ordering b0 bc ) threat resolution ordering constraints(if any) added plan.two tried order, C1 first C2 C1 fails. neither rule findrequired causal link, replacement fails. wnew may also threaten existing causallinks bdp w not. threatened link, hbp , m, bc i, procedure triesresolve threat three ways:(T1) consumer bc ordered w linearisation correspondingsubproblem (bc p), bc wnew consistent, threat removed addingordering.(T2) producer bp ordered w linearisation corresponding subproblem (bp q), wnew bp consistent, threat removed adding ordering.(T3) new, unthreatened causal link supplying bc found one tworules C1 C2 above, threatened link replaced new causal link.rules tried order, none resolve threat, replacementfails.non-basic ordering constraints blocks w may disappear wreplaced wnew ; likewise, ordering constraints w restplan may become unnecessary, wnew may delete every atom w deletesmay preconditions w, thus removed. may make pairsblocks b, b0 plan ordered replacement unordered, thus createnew threats. new threats checked ReplaceIfPossible, foundresolved restoring ordering constraint lost.401fiSiddiqui & HaslumLemma 8. current plan bdp valid, wnew solves subproblem correspondingwindow hp, w, qi, plan returned ReplaceIfPossible valid.Proof. procedure ensures every precondition every step supported causallink active threat: link either existed plan replacement (andnew threats created replacement resolved ordering constraints),added procedure. Thus, replacement succeeds, resulting plan validaccording Theorem 2. replacement fails, plan returned current plan,bdp , unchanged, valid assumption.Theorem 9. input plan, bdp valid, plan returned Merge.Proof. Immediate Lemma 8 induction sequence accepted replacements.3.6 Impact Plan Decompositionneighbourhood explored step LNS BDPO2 defined substitutingimproved subplans current plan. subplan considered local optimisationsubsequence linearisation block deordering current plan. Obviously,also restrict windows consecutive subsequences totally ordered inputplan; fact, similar approaches plan optimisation adopted restriction (Ratner& Pohl, 1986; Estrem & Krebsbach, 2012; Balyo, Bartak, & Surynek, 2012). section,address question much block deordering contributes performanceBDPO2.preliminary experiment (setup 1, described Section 3.1 page 392)observed 75% subproblems improved subplan foundcorrespond non-consecutive part sequential input plan. However, prove optimising 25% subplans found withoutdeordering would lead equally good end result.Therefore, conducted another experiment, using setup experiment 3 (described Section 3.1). experiment, ran BDPO2 separately different degreesplan decomposition: (1) block deordering (as default BDPO2 configuration,one used experiments 2 3 presented Section 3.2 page 394). (2) standard, i.e., step-wise, plan deordering only. configuration, used KambhampatiKedars (1994) algorithm (described Section 2.3) plan deordering. (3) Withoutdeordering, i.e., passing totally ordered input plan directly LNS process.addition, configurations run immediate restartingdelayed restarting, described Section 3.4.Figure 13 shows average IPC plan quality score function time-per-problemachieved configurations BDPO2. shows simple clear picture:immediate restart, LNS applied block deordered plans outperforms LNS appliedstep-wise deordered plans, turn outperforms use totally ordered plans.total improvement, measured increase average IPC plan quality score,achieved BDPO2 without deordering 28.7% less achieved bestconfiguration. also see deordering enabler delayed restarting:block step-wise deordering, delayed restarting boosts performance LNS402fiContinuing Plan Quality Optimisation0.9620.9580.9540.950.9460.9420.9380.9340.9365.554.510.500.92243.530.926BDPO2 delayed restart block deordered plansBDPO2 immediate restart block deordered plansBDPO2 delayed restart standard partially ordered plansBDPO2 immediate restart standard partially ordered plansBDPO2 delayed restart totally ordered plansBDPO2 immediate restart totally ordered plans2.521.5Average Quality Score (Relative IPC Quality Score / Coverage)Time (hours)Figure 13: Average IPC quality score function time per problem BDPO2 appliedtotally ordered input plan; standard (step-wise) deordering plan;block deordering plan. plan type, system run two configurations: delayed restarting immediate restarting (cf. Section 3.4page 399). experiment run setup 3, described Section 3.1 page 392.time shown runtime BDPO2 (i.e., without 2 hour delaygenerating input plans, shown Figure 11). Note also y-axis truncated:curves start average quality input plans, 0.907.403fiSiddiqui & Haslumplan optimisation 12% 14.7%, respectively, totally ordered planssignificant effect.Deordering increases number linearisations therefore enables manydistinct candidate windows created. However, recall BDPO2s neighbourhoodexploration procedure (Algorithm 2) interleaves incremental window generation optimisation attempts; many windows could generated current plan maynever generated restart occurs. Thus, average number windows generatediteration reflect difference performance. (With block deordering,average number windows generated 277.23, 183.19 remain filtering,totally ordered plans 376.8, 149.94 filtering; using immediaterestart.) deordering helps windowing strategies generate windowseasily optimised. Recall neighbourhood exploration retry subplannerwindow (with higher time limit) windows triedsubplanner. average number optimisation attempts, using either subplanner,window selected optimisation least once, around 1.7 either block deorderingstandard deordering used input plan. Without deordering, however,average number attempts higher, high domains: leavinghighest 5% neighbourhoods encountered, average slightly 2;10% plan neighbourhoods average number attempts 5,cases 10. words, generating windows totally ordered plancauses procedure spend, average, time window improvingplan found.hand, noted Section 3.2, domains subplanners needruntime find better plans improvable windows, BDPO2 configuration withoutdeordering find better plan default configuration 26 182 problems.current BDPO2 system, subplanner time limit increased windowretried. procedure either attempts candidate windows likely improved(for example, indicated window ranking policies described Section 4.6)frequently, varies amount time given optimise window may perform better.optimal amount deordering plan may well different problem problem. averaged across set benchmark problems, deorderingunarguably better none.4. Windowing Strategies Ranking Windowswindow subplan linearisation block deordered plan, extracted orderattempt local optimisation. section describes strategies use generaterank windows, experimental evaluation impact systems performance.Recall Definition 8 (page 390) window represented triple hp, w, qi,w set blocks replaced, p q sets blocks orderedw, respectively, linearisation. block decomposed p.o. planmany linearisations, producing many possible windows typically far manyattempt optimise all. windowing heuristic procedure extracts reducedset windows, hopefully including promising ones, systematic way.404fiContinuing Plan Quality OptimisationFigure 14: block deordered plan transformation extended blocks: blocks b1b3 merged single block, blocks b5 b6.Windowing heuristicsRule-basedCyclic threadCausal followersGeneratedBasicExt.1083559477245filteredBasicExt.592245314120ImprovedBasicExt.23915.51115.57Impr./Gen.BasicExt.0.210.260.260.230.220.16Table 2: total number (in thousands) windows generated, filtered out,finally improved, using different windowing heuristics different block types (basicextended). number possible windows sequential input plans,even considering deordering, 1.47 million. rightmost pair columns showsrate success, meaning fraction improved windows generated windows.numbers results experiment 1 (described Section 3.1 page 392).present three windowing heuristics, called rule-based, cyclic thread, causal followersheuristics. described detail following subsections.heuristic applied two types block basic extended one time.Basic blocks blocks generated block deordering. (For purpose windowing,step included block created block deordering consideredblock own.) Extended blocks created merging basic blocks blockdeordered plan form complete non-branching subsequences. block biimmediate predecessor block bj , bj immediate successor bi ,merged one extended block. Algorithm 4 shows procedure extended blockformation. (IP(b) denotes set bs immediate predecessors, IS(b) bs immediatesuccessors.)Algorithm 4 Computing extended blocks.1: Bext Bbasic2: bi , bj Bext : IP(bj ) = {bi }, IS(bi ) = {bj }3:Bext Bext {bi bj } \ {bi , bj }process illustrated example Figure 14. Note blocks b5b2 merged one extended block. although b5immediate successor b2, b2 immediate predecessor b5. Extended blocksuseful allow windowing heuristics capture larger windows.experiment results show windows different sizes useful different domains:405fiSiddiqui & HaslumAlgorithm 5 Extract Candidate windows/* global array strategy[1..6] stores state windowing strategy */1: procedure ExtractMoreWindows(bdp , windowDB, optSubprob)2:W =3:tlimit = initial time limit Tincrement4:telapsed < tlimit |W | < nWindowsLimit5:= NextWindowingStrategy()6:= null break /* windowing strategies exhausted */7:W = strategy[i].GetWindows(bdp , windowDB, optSubprob,nWindowsLimit |W |, tlimit telapsed )8:telapsed tlimit W = tlimit += Tincrement9:windowDB.Insert(W )example, larger windows likely improved Pegsol, OpenstacksParcprinter domains, optimising smaller windows better Elevators, Transport,Scanalyzer Woodworking domains.windowing strategy windowing heuristic applied block type. Thus, usetotal six different strategies. strategies contributes improvablewindows generated strategies (cf. Section 4.4,particular Table 3 page 411). Thus, are, sense, useful.hand, size set windows generates fraction improvablewindows set varies strategies, sense usefulothers.Table 2 shows results first experiment, systematically tried twosubplanners (PNGS IBCS) every window generated (and filtered out)windowing strategy 219 input plans. table shows total number (in thousands)windows generated, remain filtering, finally improvedleast one two subplanners. experiment, windows filteredwindow cost matched lower bound given admissible LM-Cut heuristic(Helmert & Domshlak, 2009). experiment setup described Section 3.1 (onpage 392). first observation strategies selective. numberwindows could potentially generated, even without considering deordering, i.e.,taking subsequences totally ordered input plans, 1.47 million. Thus,even prolific strategy generates less tenth possible windows. Second,used rate success, meaning fraction windows generated improvedsubplanners used experiment, order strategies. orderfollows:1. Rule-based heuristic extended blocks.2. Cyclic thread heuristic basic blocks.3. Cyclic thread heuristic extended blocks.4. Causal followers heuristic basic blocks.5. Rule-based heuristic basic blocks.6. Causal followers heuristic extended blocks.406fiContinuing Plan Quality Optimisationneighbourhood exploration procedure (Algorithm 2 page 391) adds windowsdatabase incrementally, calling ExtractMoreWindows procedure shownAlgorithm 5. procedure selects next strategy try, cyclingorder above, asks strategy generate specified number windows,limited time. strategy keeps state (what part heuristicapplied part plan), next time queried resumegenerating new windows. windows possible given strategygenerated, say strategy exhausted. windowing strategies discard (1)windows known optimal, either cost matches lower boundgiven admissible LM-Cut heuristic (Helmert & Domshlak, 2009),stored set optimally solved subproblems, (2) windows overlapalready improved window. windows eligible optimisation (cf. Section 3),generating redundant. selected strategy finishes without generating enoughwindows time remains, next not-yet-exhausted strategy order queried,on, either |W | = nWindowsLimit time up. windows generated,strategies still exhausted, time limit increased.4.1 Rule-Based Windowing Heuristicfirst version BDPO (Siddiqui & Haslum, 2013b) used single windowing strategy,based applying fixed set rules extended blocks. strategy complements new windowing heuristics well, kept BDPO2.rule applied block b block deordered plan bdp selects setblocks go replaced part (w) based relation b. ensurewindow consistent block deordering (i.e., consistent linearisation,stated Definition 8 page 390), blocks constrained orderedblocks window must also included. call intermediate blocks, formallydefined follows.Definition 10. Let bdp = hS, B, block decomposed p.o. plan. intermediateblocks B B IB(B) = {b | b0 , b00 B : b0 b b00 }.Let b block bdp , let Un(b) set blocks ordered w.r.t. b,IP(b) immediate predecessors b, IS(b) immediate successors. rules usedwindowing heuristic are:1. w0 {b}.2. w0 {b} IP(b).3. w0 {b} IS(b).4. w0 {b} Un(b).5. w0 {b} Un(b) IP(b).6. w0 {b} Un(b) IS(b).7. w0 {b} Un(b) IP(b) IS(b).8. w0 {b} Un(b) IP({b} Un(b)).9. w0 {b} Un(b) IS({b} Un(b)).407fiSiddiqui & HaslumFigure 15: Window formation applying 1st rule rule-based windowing heuristicblock b1, i.e., w {b1}, p Un(b1). unordered block b2 placedpredecessor set. Note window optimised removing s3 stepcausal link successors.10. w0 {b} Un(b) IP({b} Un(b)) IS({b} Un(b)).Given blocks selected one rules above, partitioning blocks hp, w, qimade setting w = w0 IB (w0 ) assigning p block orderedunordered w, q block ordered w. Figure 15 shows examplerule-based windowing, 1st rule applied block b1. Applied blocks,rules produce duplicates; course, unique windows kept.first rules, include fewer blocks, generally produce smaller windows,later rules tend produce larger window (though exact relation, sincenumber actions block varies). heuristic applies rules blockblock deordered plan bdp turn. Rules applied order 1,10,2,9,3,8,4,7,5,6, i.e.,starting first, last, second, second last, on. blocksordered size (descending), ties broken order input plan (in oppositedirection extended blocks).Recall ExtractMoreWindows repeatedly asks windowing strategy generate limited number windows. ordering blocks rules described helpsensure heuristic generates varied set windows, including smalllarge, covering different parts current plan, time queried.4.2 Cyclic Thread Windowing Heuristicdiscover new windowing heuristics, noted key changes decomposed planstructure frequently occur plan improved. One significant observationmultiple steps input plan add effects, steps togethersteps necessarily ordered form subplan often im408fiContinuing Plan Quality Optimisationproved. call cyclic behavior. one experiment, found cycles typeeither removed plan replaced different cycles 87%improvements across domains. definition cyclic behavior basedindividual atom. Intuitively, atom cyclic behavior multiple producers (asdefined below).Definition 11. Let bdp = hS, B, block decomposed p.o. plan, Pmset producers atom m, i.e., sPm add(s). cyclic behavior iff |Pm | > 1.Note Pm contains init step sI iff I. However, since window never containsinitial step sI , candidate windows formed extended producers instead. step/ {sI , sG } extended producer atom iff produces m, consumess0 6= sI produces ordered block deordered plan.formal definition follows.Definition 12. Let bdp = hS, B, block decomposed p.o. plan. stepextended producer atom iff/ {sI , sG } and:1. add(s)2. pre(s) kS\sI add(k) + k.order form candidate windows respect atom cyclic behavior,first extract blocks contain least one extended producer atom m.cyclic thread (cf. Definition 14) formed taking linearisation blocks,consistent input plan.Definition 13. Let bdp = hS, B, block deordering sequential plan seq ,bx , B two blocks bx = . Let hbx , linearisation {bx , }.hbx , consistent seq least one step bx appears step seq .way linearise blocks consistent input plan clarifiedfollowing example. Assume bx : {sa , sc } : {sb , sd } two blockslinearise, orderings constituent steps input plansa sb sc sd . linearisation starts block contains firstelement , i.e., bx case (since contains sa ); updated \bx ,linearisation continues fashion empty. resulting linearisationexample blocks hbx , i. multiple (nested) blocks contain first element, innermost one picked. formal definitions thread cyclic threadfollows.Definition 14. Let bdp = hS, B, block deordering sequential plan seq , EPmset extended producers atom m, Bm B set blocks,element Bm contains least one element EPm . thread m, Tm ,linearisation blocks Bm linearisation consistent seq . threadcalled cyclic iff cyclic behavior.example, plan shown Figure 15(i), atom (at t1 A) cyclic behaviour,since holds initial state added step s3. extended producers s1, s3s4, cyclic thread T(at t1 A) = hb1, b2i.409fiSiddiqui & HaslumFinally, candidate windows formed taking consecutive subsequence blocks(and intermediate blocks, necessary) cyclic thread. Like rule-based windowing,blocks unordered respect window assigned set blocksprecede window.Definition 15. Let Tm = b1 , ..., bk cyclic thread atom m. cyclic thread-basedwindows cyclic thread Tm Wl,m = {B IB(B) | B = bi , ..., bi+l consecutivesubsequence Tm }, unordered blocks always placed predecessor set.Also like rule-based windowing heuristic, cyclic thread heuristic generates windows order aims ensure returns varied set windows timecalled. first identifies cyclic threads block deordered plan generatesstream candidate windows one cyclic thread another. mentioned,candidate window formed taking consecutive subsequence blocks (and intermediate blocks required form consistent window) cyclic thread. Giventhread |Tm | blocks, subsequences generated according following order sizes:1, |Tm |, 2, |Tm | 1, . . . , |Tm |/2. words, subsequence lengths orderedsmallest, biggest, second smallest, second biggest, on. sizeorder, windows generated moving beginning end thread.4.3 Causal Followers Windowing Heuristicthird strategy use obtain broader range potentially improvablewindows similar cyclic thread heuristic creates windows subsequences linearisation blocks connected particular atom, differentconnections via causal links.Definition 16. Let bdp = hS, B, block decomposed p.o. plan, c setcausal links . causal followers atom producer p CFhm,pi ={p, sj , ..., sk |{hp, m, sj i, ..., hp, m, sk i} c } \ {sI , sG }. causal followers (forproducers), CFm , sequence hCFhm,p1 , ..., CFhm,pn i, p1 , ..., pn linearisationproducers m.words, causal followers atom list sets steps.set steps, one producer others consumers sj m,causal link every sj m, i.e., PC(m) Re(s sj ). example, atom (at t1 B)block deordered plan Figure 15(i) appears two causal links,producer: hs1, (at t1 B), s2i hs1, (at t1 B), s3i. Thus, causal followersCF(at t1 B) = h{s1, s2, s3}i.block deordered plan extract sequence sets blocks correspondingcausal follower steps, according definition below. example, sequencecausal follower blocks CF(at t1 B) plan Figure 15(i) CFB(at t1 B) = h{b1}i,since steps CF(at t1 B) contained block b1.Definition 17. Let bdp = hS, B, block decomposed p.o. plan, CFhm,picausal followers atom respect producer p S. causal followerblocks respect producer p atom m, CFBhm,pi , set blocks,block contains least one element CFhm,pi . causal follower blocks410fiContinuing Plan Quality OptimisationExclusiveBasic block66.52%91.86%Ext. block8.14%33.48%Rule-based24.50%63.22%Cyclic thread6.09%34.01%Causal followers17.78%66.34%Table 3: Percentage improvable windows found using two block types threewindowing heuristics, total number improvable windows found using blockstypes windowing heuristics. first row gives percentage improvable windowsfound one block type (or one windowing heuristicothers), second row gives percentage improvable windows found oneblock type (or windowing heuristic). results first experiment, describedSection 3.1.(for producers), CFBm , sequence hCFBhm,p1 , ..., CFBhm,pn i, p1 , ..., pnlinearisation producers bdp .Candidate windows formed taking consecutive subsequences sequencecausal follower blocks (with intermediate blocks, necessary). formal definitiongiven below. Like windowing heuristics, blocks unordered respectwindow assigned set blocks precede window.Definition 18. Let bdp = hS, B, block decomposed p.o. plan, CFBm =hCFBhm,p1 , ..., CFBhm,pn causal follower blocks m. causal followers-basedwindows CFBm Wl,m = {B IB(B) | B = CFBhm,pi ... CFBhm,pi+lconsecutive subsequence CFBm length l}, unordered blocks always placedpredecessor list.order windows generated causal followers heuristic basedprinciple cyclic thread heuristic. generates stream candidatewindows causal follower blocks CFBm associated atom turn.windows consecutive subsequences sets blocks CFBm , lengths chosenaccording pattern 1, l, 2, l 1, ..., (l/2), l length CFBm .4.4 Impact Windowing Heuristicsone single windowing heuristic block type, combination them, guaranteedfind improvable windows. first row Table 3 shows percentage improvablewindows found using one block type (or one windowing heuristicothers), total number improvable windows found using blocks typeswindowing heuristics. (The results first experiment, described Section3.1). shows every windowing heuristic block type contributes improvablewindows found strategies. example, 24.5% improvable windowsfound rule-based windowing heuristic (using basic extended blocks).hand, 36.78% improvable windows found heuristic.windowing heuristics strengths limitations. rule-based heuristic,example, generate windows contain sequences extended blocksfixed length, cyclic thread causal followers heuristics make windowsblocks connected single atom.411fiSiddiqui & Haslum0.9630.9550.9510.9470.9430.9390.9350.9310.92732.521.510.5060.9195.550.923BDPO2 (combined windowing heuristics)BDPO2 (random windowing)BDPO2 (rulebased windowing only)BDPO2 (causal followers windowing only)BDPO2 (cyclic thread windowing only)4.543.5Average Quality Score (Relative IPC Quality Score / Coverage)0.959Time (hours)Figure 16: Average IPC quality score function time separate runs BDPO2 usingthree windowing heuristics alone, three heuristics combined, randomwindow generation. run done using setup experiment 3, describedSection 3.1 (on page 392). x-axis shows runtime BDPO2 (i.e., without2 hour delay generating input plans, shown Figure 11). Note alsoy-axis truncated: average quality input plans 0.907.412fiContinuing Plan Quality OptimisationFigure 16 shows impact different windowing heuristics anytime performanceBDPO2, measured average IPC plan quality score achieved function timeper-problem. experiment, ran BDPO2 three windowing heuristicsalone, three combined sequential portfolio, described beginningsection. (The combined portfolio windowing heuristic configurationBDPO2 presented experimental results Section 3.2, page 394.) alsocompare non-heuristic, random windowing strategy, windowformed taking random subsequence blocks random linearisationblock deordered plan. Subsequences chosen distribution window sizes(measured number actions window) roughly producedcombined heuristics. experiment uses setup 3 (described Section 3.1 page392), i.e., input plans BDPO2 already high quality. (Their average IPC planquality score 0.907.)predicted data Table 3, using three windowing heuristicsresults much worse system performance, since fails find substantialfraction improvable windows. fact, random window generation betterheuristics own. However, combined portfolio heuristics outperformsrandom windowing good margin: total quality improvement achievedrandom windowing strategy 17.1% less best BDPO2 configuration.demonstrates heuristics capture information useful guide selectionwindows.4.5 Possible Extensions Windowing StrategiesSince window formed partitioning plan steps three disjoint sets blocks,number possible windows exponential. challenge good windowing heuristicextract reduced set contains windows likely improved. Every windowingstrategy limitations. Hence, always scope developing new windowingheuristics extending existing ones; one extension discussed section.combination strategies use may miss improvable windows. example,long sequence blocks form part cyclic thread causal followers sequencerespect single atom captured heuristics. exampleshown Figure 17, three candidate windows, W1, W2 W3, found causalfollowers windowing heuristic improvable separately. situation, formingwindow union separate windows, found one several strategies, overcomelimitations strategies. example, union W1 W2 improvable.type composite windows could formed later stages plan improvementprocess, individual windowing heuristics exhausted. However,number composite windows created large set candidate windowscombinatorial thus optimising take long time.4.6 Window RankingAlthough windowing strategies generate fraction possible windows,number candidate windows still often large (cf. Table 2). order speed413fiSiddiqui & HaslumFigure 17: Three candidate windows, W1, W2, W3, found causal followerswindowing heuristic atoms (at t1 B), (in p1 t2), (in p2 t3) respectively. Noneimprovable. However, composite window formed merging W1 W2improvable substituting delivery package p1 (from location B C) providedtruck t2 truck t1. atom (at t2 C) requiredsuccessors (i.e., goal example).plan improvement process, helpful order windows likelyimproved optimised first. role window ranking.Ranking windows made difficult fact properties improvable windowsvary one another, lot domain domain. example, mentionedbeginning section, larger windows likely improved Pegsol,Openstacks Parcprinter domains, smaller windows better Elevators,Transport, Scanalyzer, Woodworking domains. Sokoban domain,hand, medium-sized windows better. Moreover, improvable window mayimproved particular subplanner within given time bound. noteddomains, e.g., Pegsol Scanalyzer, subplanners require, average, timefind lower-cost plan.developed set window ranking policies examining structural propertiesgenerated candidate windows generated results first experiment (cf.Section 3.1) ran two subplanners (IBCS PNGS) generated window30 second time limit, excluding windows whose cost already shownoptimal admissible LM-Cut heuristic (Helmert & Domshlak, 2009). Investigatingproperties improved unimproved windows, identified four metrics workrelatively well across domains:414fiContinuing Plan Quality Optimisation0.74Random rankingOutgoing causal links per length (min max)Incoming causal links per length (min max)Pairwise ordering disagreement (min max)Gap cost & admissible heuristic (max min)Fraction improvable windows selected windows0.720.70.680.660.640.624003753503253002752502252001751501251007550250.6Number selected (top ranked) windowsFigure 18: Fraction improvable windows, across domains, selected topwindows ranked orders generated ranking policies (see text).(1) total number causal links whose producers reside window whose consumers outside window, divided length window lowervalue higher rank. call property outgoing causal links per length.(2) total number causal links whose consumers reside window whose producers outside window, divided length window lowervalue higher rank. call property incoming causal links per length.(3) gap cost window lower bound cost plancorresponding subproblem given admissible heuristic higher valuehigher rank.(4) number pairwise ordering (of steps) disagreements window hp, w, qisequential input plan lower value higher rank. calculatefirst take linearisation hp, w, qi used generate correspondingsubproblem. Then, every pair plan steps, orderinglinearisation input plan call pairwise orderingdisagreement. lower total number disagreements window,higher rank. words, ordering steps window differentinput plan less likely improved.415fiSiddiqui & Haslum0.64Fraction improvable windows selected windowsRandom rankingOutgoing causal links per length (min max)Incoming causal links per length (min max)Pairwise ordering disagreement (min max)Gap cost & admissible heuristic (max min)0.620.60.580.560.540.520.50.480.460.440.420.40.380.360.340.324003753503253002752502252001751501251007550250.3Number selected (top ranked) windowsFigure 19: Fraction improvable windows Parking domain, selected topwindows ranked orders generated ranking policies (see text).infer first two ranking policies disconnected windowblocks decomposed plan likely improved. Figure 18compares ranking policies performance random ordering windows.average across domains, four ranking policies good picking improvablewindows. example, take top 25 windows order generatedincoming causal links per length policy, nearly 74% windows improvable (byleast one subplanner), top 25 windows random order contain61% improvable windows. random ranking Figure 18 best result threeseparate random rankings values x-axis. expected, exhibitsroughly ratio improvable windows ranges (from 25 400). Nearly 61%selected windows, across domains, improvable. However, performanceindividual ranking policies varies domain, policy find domaingood. example, Figure 19 shows ranking results instancesParking domain only: Here, outgoing causal links per length policy workwell. Considering top 90 windows ranked order, even worse random.However, ranking policies quite beneficial domain.BDPO2 uses first three ranking policies sequential portfolio (as explainedSection 3). subplanner, BDPO2 uses current ranking policy select next416fiContinuing Plan Quality Optimisation0.963Average Quality Score (Relative IPC Quality Score / Coverage)0.9610.9590.9570.9550.9530.9510.9490.9470.9450.9430.9410.9390.9370.9350.9330.931BDPO2 (rankbased)BDPO2 (randomranked)65.554.543.532.521.510.50Time (hours)Figure 20: Average IPC plan quality score function time two separate runs:without window ranking. second case, order candidate windowsrandomised. run done using experimental setup 3, described Section 3.1page 392. time shown runtime BDPO2 (excluding 2 hour delaygenerating input plans, shown Figure 11). Also, y-axis truncated:curves start average quality score input plans, 0.907.window chosen subplanner (from eligible optimisation subplanner).improvement found subplanner certain number attempts (13,current configuration), system switches different ranking policy, produce differentordering candidate windows subplanner.use window ranking beneficial effect anytime performanceplan improvement process, shown Figure 20. achieve higher quality scores,particular, achieve faster, using window ranking compared random ranking.experiment, ran BDPO2 portfolio ranking policies, described417fiSiddiqui & Haslumabove, windows chosen optimisation random order. experimentused setup experiment 3 (described Section 3.1 page 392).tried many alternative methods combining ordered lists generated differentranking policies, order achieve ranking stable performance across domains.problem combining rankings, often called rank aggregation, studied manydisciplines, social choice theory, sports competitions, machine learning, information retrieval, database middleware, on. Rank aggregation techniques rangequite simple (based rank average number pairwise wins) complex proceduresrequire solving optimisation problem. tried five simple popular rank aggregation techniques, namely Bordas (1781) method, Kemenys (1978) optimalordering, Copelands (1951) majority graph, MC4 (Dwork, Kumar, Naor, & Sivakumar,2001), multivariate Spearmans rho (Bedo & Ong, 2014). result experiments, however, rank aggregation produce better, stable, windowrankings, especially cases one individual policy relatively bad. Hence choiceusing ranking policies cyclic portfolio instead.5. On-line AdaptationLNS approach optimisation repeatedly solving local subproblems gives usopportunity adapting process on-line current problem. noteddifferent subplanners, windowing strategies, ranking policies work better differentdomains. example, Figure 21 shows fraction local improvements foundthree subplanners different domains. seen, IBCS subplannerproductive, compared PNGS LAMA, APPN, Barman, Maintenance, Parking,Sokoban, Woodworking domains. PNGS, hand, better ScanalyzerVisitall domains, LAMA Elevators Openstacks domains. Therefore,learn course local search relative success rate different subplannerscurrent problem, system perform better. similar fashion, windowgeneration strategies ranking policies may also adapted current problem,system likely select subplans optimisation improvable.use on-line machine learning technique multi-armed bandit (MAB) model,specific select subplanner local optimisation attempt. technique, impact anytime performance BPO2 described followingsubsections.window selection, on-line adaptation limited switching alternativeranking policies. window selected optimisation subplanner top oneorder given current ranking policy subplanner (cf. Section 4.6).long improvements found among windows, consider currentpolicy useful. subplanner reaches certain number attemptsimprovements found, switch using next policy subplanner. numberwindows neighbourhood optimised typically small comparednumber candidate windows generated. average across problems experiment 3(cf. Section 3.1 page 392) optimisation least one subplanner tried 24.8%generated windows. this, adapting ranking policy influence418fiContinuing Plan Quality OptimisationFigure 21: percentage improved windows found subplanners (PNGS,IBCS, LAMA), total number improved windows found subplanners. experiment, BDPO2 run three times, time one subplanner.setup experiment 3 (described Section 3.1 page 392).windows tried adapting windowing strategies. effect adaptivewindow ranking anytime performance BDPO2 shown Figure 20 (page 417).5.1 Bandit Learningmulti-armed bandit (MAB) model popular machine learning formulation dealingexploration versus exploitation dilemma. MAB problem, algorithmpresented sequence trials. round, algorithm chooses one setalternatives (often called arms) based past history, receives rewardchoice. goal maximise total reward time. bandit learning algorithmbalances exploiting arms highest observed average reward exploring poorlyunderstood arms discover yield better reward.MAB found numerous applications diverse fields (e.g., control, economics, statistics, learning theory) influential paper Robbins (1952). Many policiesproposed MAB problem different assumptions, example, independent (Auer et al., 2002) dependent arms (Pandey, Chakrabarti, & Agarwal, 2007),exponentially infinitely many arms (Wang, Audibert, & Munos, 2008), finite infinitetime horizon (Jones & Gittins, 1974), without contextual information (Slivkins,2014), on.cast problem selecting subplanner local optimisation attemptmulti-armed bandit problem. goal maximise total number improvedwindows time. use learning algorithm based optimistic exploration strategy, chooses arm favorable environments high probabilitybest, given observed far. strategy often called optimismface uncertainty. trial t, arm k, strategy use pastobservations probabilistic argument define high-probability confidence intervalsexpected reward k . favorable environment arm k thus upper419fiSiddiqui & Haslumconfidence bound (UCB) k . simple policy based strategy play armhighest UCB.number algorithms developed optimistic exploration bandit arms,UCB1, UCB2 UCB1-NORMAL Auer et al. (2002), UCB-V Audibert,Munos Szepesvari (2009), KL-UCB Garivier Cappe (2011). useUCB1 algorithm planner selection. UCB1 algorithmselects trial armq2 lnhighest upper confidence bound Bk,t =bk,t +nk , sum exploitation termexploration term, respectively.bk,t empirical mean rewards receivedarm ktrialt,nnumbertimes arm k tried far.kq2 lnsecond term,nk , confidence interval average reward, within trueexpected reward falls almost certain probability. Hence, Bk,t upper confidencebound. UCB1 algorithm achieve logarithmic regret uniformly numbertrials without preliminary knowledge reward distributions (Auer et al.,2002).Applied subplanner selection BDPO2, algorithm works follows: First,select subplanner p once, initialise average rewardbp . optimisationattempt, give reward 1 chosen subplanner found improvementreward 0 otherwise. could use scheme assigning rewards rathersimply 0 1, example, making reward proportional amount improvement(or time taken find it). However, observed assigning varying rewardssubplanners makes bandit learning system complicated, helpachieving better overall result. Next, selectq attempt subplanner pmaximises upper confidence bound p, Bp,t =bp + 2nlnp , explained above. Here,np number times p tried far, total number optimisationattempts (by subplanners) done far. see Bp,t grows shrinksnp increase uniformly. ensures alternative tried infinitely oftenstill balances exploration exploitation. words, try p,smaller size confidence interval closer gets mean valuebp .p cannot tried becomes smaller p , p planner bestaverage reward.5.2 Impact Bandit Learningresponse bandit policy subplanner selection shown Figure 22. figureshows fraction total number optimisation attempts one subplanner, IBCS,selected, fraction total number window improvements foundsubplanner. Since BDPO2 experiment uses two subplanners, IBCS PNGS,corresponding fraction PNGS 1 y. example, third problem (fromleft) APPN domain, 100% window improvements found IBCS,bandit policy selects subplanner 84% total number optimisation attempts.PNGS chosen 16%, finds improvement. see banditpolicy selects promising subplanner often across problems. However,bandit policy somewhat conservative, ensures rulesubplanners fare poorly early on. Moreover, current plan improved420fiContinuing Plan Quality Optimisation1improvement ratioexploitation ratio0.9Exploitation improvement ratio IBCS0.80.70.60.50.40.30.20.1WoodworkingVisitallTransportThoughtfulTetrisSokobanParkingScanalyzerParcprinterNomysteryMaintenanceHikingGedFloortileElevatorsChildsnackBarmanAppn0Figure 22: response bandit policy subplanner success rates. exploitationratio fraction total number optimisation attempts IBCSsubplanner chosen, total number attempts subplanners.improvement ratio fraction total number improved windows found IBCS,total number improved windows found subplanners. Since IBCSPNGS two subplanners used experiment, corresponding ratiosPNGS opposite (i.e., 1 y). experiment run setupexperiment 2, described Section 3.1 page 392.becomes harder find improvements (within given time bound), averagereward subplanners decreases. forces bandit policy switchsubplanners often.Figure 23 shows impact combining subplanners using UCB1 bandit policy,compared simply alternating subplanners using subplanner alone,anytime performance BDPO2. experiment ran BDPO2 IBCS,PNGS LAMA subplanner, combining two (IBCS PNGS)using simple alternation policy, selects two turn, combiningtwo using bandit policy. run done experiment setup 3 (as describedSection 3.1 page 392), i.e., input plans high quality. (The IPC plan qualityscore plan calculated before; see page 394). average score inputplans 0.907.) expected, combining IBCS PNGS subplanners fashionleads quality improvement across entire time scale achieved runningBDPO2 individual subplanner. figure also shows combining multiplesubplanners using bandit policy better strategy simply alternating421fiSiddiqui & Haslum0.963Average Quality Score (Relative IPC Quality Score / Coverage)0.9590.9550.9510.9470.9430.9390.9350.9310.9270.923BDPO2 (PNGS+IBCS: Bandit)BDPO2 (PNGS+IBCS: Alternating)BDPO2 (PNGS only)BDPO2 (IBCS only)BDPO2 (LAMA only)0.91965.554.543.532.521.510.500.915Time (hours)Figure 23: Average IPC quality score function time per problem five differentruns BDPO2: using one three subplanners, using two (IBCSPNGS) combined UCB1 bandit policy, without (using simple alternationinstead). experiment run setup 3 described Section 3.1 (on page 392).Note y-axis truncated: curves start average quality input plans,0.907. time shown runtime BDPO2 only, excluding 2 hourdelay generating input plans shown Figure 11).422fiContinuing Plan Quality Optimisationthem. total quality improvement achieved BDPO2 using alternation policy6.8% less BDPO2 using bandit policy.6. Related Worksurvey four areas related work: Anytime search algorithms post-processing approaches, common approach aim continuing plan qualityimprovement; uses local search planning; finally, uses algorithm portfoliosplanning.6.1 Anytime SearchLarge state-space search problems, kind frequently arise planning problems,often cannot solved optimally optimal search algorithms exhaust memoryfinding solution. Anytime search algorithms try deal problems findingfirst solution quickly, possibly using greedy suboptimal heuristic search, continue(or restart) searching better quality solution. Anytime algorithms attractive allow users stop computation time, i.e., good enough solutionfound, long wait. contrasts algorithms requireuser decide advance deadline, suboptimality bound, parameterfixes trade-off time solution qualty.Bounded suboptimal search problem finding solution cost lessequal user specified factor w optimal. Weighted A* (WA*) search (Pohl, 1970)Explicit Estimation Search (EES) (Thayer & Ruml, 2011) two algorithmskind used planning. Iteratively applying bounded suboptimalsearch algorithm lower value w whenever new best solution found providesanytime improvement plan quality. Restarting WA* (Richter et al., 2010) this, usingschedule decreasing weights. RWA* used LAMA planner (Richter & Westphal,2010) LAMA finds first plan using greedy best-first search (Bonet & Geffner, 2001).also uses several search enhancements, like preferred operators deferred evaluation(Richter & Helmert, 2009). EES conducts bounded suboptimal best-first search restrictedexpanding nodes may lead solution cost given factor wtimes optimal. Among open nodes set, expands one estimatedfewest remaining actions goal. uses admissible heuristic plancost informative inadmissible estimates guide search. AEES (Thayeret al., 2012b) anytime version EES. achieve anytime behavior, AEES lowersvalue w whenever new best solution found.bounded-cost search (Stern, Puzis, & Felner, 2011) problem, subproblems solved approach example, requires finding solution cost lessequal user-specified cost bound C. aim bounded-cost search algorithm find solution quickly possible. Iteratively applying bounded-costsearch algorithm bound less cost best solution found far providesanytime quality improvement. IBCS algorithm, used one subplanners BDPO2, does. BEES BEEPS algorithms (Thayer, Stern, Felner, &Ruml, 2012a) adapt EES setting bounded cost search. algorithms expand423fiSiddiqui & Haslumbest open node among whose inadmissible cost estimate C, falling backexpanding node best admissible estimate set empty.Branch-and-bound algorithms explore search space systematic fashion, usingadmissible heuristic (lower bound cost) prune nodes cannot lead solutionbetter best found far. Branch-and-bound implemented linearmemory, depth-first search strategy well top strategies. experimentreported Section 3.2 (page 394) used Beam-Stack Search (BSS) (Zhou & Hansen,2005) bounded-cost search algorithm providing initial upper bound costbase plan problem. BSS combines backtracking branch-and-bound beamsearch, behaves like breadth-first search limits size open listlayer user-specified parameter, known beam width. forced backtrack,BSS reconstructs nodes pruned open list search complete. beamwidth parameter used control memory consumption BSS neverexceeds available memory. planning problems, however, whose state spaces oftendense transpositions accurate admissible heuristics expensive compute,repeatedly reconstructing paths unexplored nodes becomes time-consuming.Anytime search planners aim provide continuing improvement plan quality giventime, often succeed early stages search. However,observed results experiments, algorithms often stagnate, reachingpoint find better plans even several hours CPU time. (cf.Figure 11 page 395 Section 3.2 page 394.) example, experiment LAMAAEES found better plans 8.7% 6.1%, respectively, total numberproblems 3 hours 6 hours CPU time, BDPO2 found better plans30.4% problems time interval. Memory one limiting factor,one. almost half problems, AEES ran full 7 hours CPU timewithout running memory, yet found improved plans. BSS found planscost less initial upper bound (the cost base plans) 14 182problems even 24 hours CPU time per problem.6.2 Local SearchLocal search explores space searching small neighbourhood current elementsearch space one is, way, better, moving neighbourrepeating process. Compared systematic search algorithms, advantage localsearch needs much less memory. Therefore, local search algorithms widelyused solve hard optimisation problems. However, local search algorithms cannot offerguarantees global optimality, bounded suboptimality. planning, local searchused mainly find plans quickly, rarely improve plan quality, thoughpost-processing methods discussed next section viewed local searches.FF (Hoffmann & Nebel, 2001) forward-chaining heuristic state space search planner.heuristic used FF estimates distance state nearest goal state. FFuses local search strategy, called enforced hill-climbing, state uses breadthfirst search find neighbour state (which may several steps away currentstate) strictly better heuristic value, i.e., believed closer goal.commits state starts new search neighbour better yet424fiContinuing Plan Quality Optimisationheuristic value. local search fails, due getting trapped dead end, FF falls backcomplete best-first search algorithm. RW-LS planning algorithm (Xie, Nakhost,& Muller, 2012) similar FFs hill-climbing approach, uses combination greedybest-first search exploration random walks find better next state localsearch step. Nakhost Muller (2009) developed planning system, called Arvand,uses random walk-based local exploration conjunction FF search heuristic.showed Arvand outperforms FF hard problems many domains. executionArvand consists series search episodes. episode starts set randomwalks initial state. endpoint random walk evaluated usingheuristic function choose next state. search episode continues setrandom walks state. process repeats either goal reached,enough transitions made without heuristic progress, case processrestarted. IPC 2011 2014 versions Arvand apply post-processing improvequality generated plan. post-processing techniques Action EliminationPlan Neighborhood Graph Search (Nakhost & Muller, 2010); discussed nextsubsection. Arvands search randomised, system continue generatingalternative plans, optmised, indefinitely, storing times best plangenerated far. provides certain anytime capability. mannerused experiment reported Section 3.2 page 394.LPG planner (Gerevini & Serina, 2002) based local search spaceaction graphs, represent partial plans. neighbourhood defined operatorsmodify action graph, inserting removing actions. functionevaluates nodes neighbourhood combines terms estimate far actiongraph becoming valid plan, termed search cost, expected qualityplan may become. choice neighbour move also involves elementrandomness. LPG also performs continuing search better plans; this, similaranytime search algorithms discussed last subsection. Whenever finds plan,local search restarts partial plan obtained removing randomly selectedactions current plan. numerical constraint forcing cost next planlower also added. provides guidance towards better quality next plan.close relationship local search approaches planning plan repairadaptation methods (Garrido, Guzman, & Onaindia, 2010). LPG planner originatedmethod plan repair (Gerevini & Serina, 2000), iterative repair methods alsoused plan generation (Chien, Knight, Stechert, Sherwood, & Rabideau, 2000).key difference use local search previous uses planningcarry local search space valid plans. permits neighbourhoodevaluation focus exclusively plan quality. Searching space partial plans (represented states) done FF, incomplete (invalid) plans, done LPG, requiresneighbourhood evaluation consider close element becoming valid plan,balancing quality.large neighbourhood search (LNS) strategy formulates problem findinggood neighbor optimisation problem, rather simply enumerating evaluatingneighbours. allows much larger neighbourhood considered. LNS usedsuccessfully solve hard combinatorial optimisation problems like vehicle routingtime windows (Shaw, 1998) scheduling (Godard, Laborie, & Nuijten, 2005). Theoretical425fiSiddiqui & Haslumexperimental studies shown increased neighborhood size may improveeffectiveness (quality solutions) local search algorithms (Ahuja, Goodstein, Mukherjee,Orlin, & Sharma, 2007). neighbourhood current solution smalldifficult escape local minima. case, additional meta-heuristic techniques,Simulated Annealing Tabu Search, may needed escape local minimum.LNS, size neighborhood may sufficient allow search processavoid escape local minima.LNS literature, neighborhood solution usually defined setsolutions reached applying destroy heuristic repair method.destroy heuristic selects part current solution removed (unassigned),repair method rebuilds destroyed part, keeping rest current solutionfixed. destroy heuristic often includes element randomness, enabling searchexplore modifications different parts current solution. role destroyheuristic system played windowing strategies, select candidate windows (subplans) re-optimisation. explore windows systematically. LNSalgorithms (e.g., Ropke & Pisinger, 2006; Schrimpf et al., 2000) allow local searchmove neighbouring solution lower quality (e.g., using simulated annealing).consider strictly improving moves. However, difference previous LNS algorithms,immediately move better plan restart neighbourhood explorationlocal improvement found. Instead, use delayed restarting, allows bettersolution found one local search step destroying repairing multiple partscurrent plan. Experimentally, found delayed restarting produces better qualityplans, produces faster, immediate restarts (cf. Section 3.4 page 399).6.3 Plan Post-Processingpost-processing method, mean one takes valid plan input attemptsimprove it, making modifications. also related plan repair adaptation(Chien et al., 2000; Fox, Gerevini, Long, & Serina, 2006; Garrido et al., 2010),key difference plan repair adaptation starts plan validcurrent situation focuses making work; discrepancy currentstate goals plan originally built provide guidance repairsneeded. contrast, post-processing plan optimisation may require modificationsanywhere current plan.Nakhost Muller (2010) proposed two post-processing techniques Action Elimination (AE) Plan Neighborhood Graph Search (PNGS). Action elimination identifiesremoves unnecessary actions given plan. PNGS constructs plan neighborhood graph, subgraph state space problem, built aroundpath state space induced current plan expanding limited numberstates state path. searches least-cost plan subgraph.finds plan better current, process repeated around new bestplan; otherwise, exploration limit increased, time memory limit exceeded.Furcys (2006) Iterative Tunneling Search A* (ITSA*) similar PNGS. ITSA*explores area, called tunnel, state space using A* search, restricted fixeddistance current plan. methods seen creating neighborhood426fiContinuing Plan Quality Optimisationincludes small deviations current plan, anywhere along plan.contrast, BDPO2 focuses one section decomposed plan time, often groupingtogether different parts input plan, puts restriction much sectionchanges; hence, creates different neighbourhood. experiments show bestresults obtained exploring neighbourhoods. example, PNGS often findsplan improvements quickly, running additional 6 hours improves averageIPC plan quality score, best plans finds first hour, 0.01%.Running instead BDPO2, using PNGS subplanner taking best plansfound PNGS 1 hour input, improves average plan quality score 3% 6hours.Ratner Pohl (1986) used local optimisation shortening solutions sequentialsearch problems. select subpath optimise, used sliding window predefined size dmax consecutive segments current path. Estrem Krebsbach(2012) instead used form windowing heuristic: select local optimisation pairsstates current path maximise estimate redundancy, based ratioestimated distances two states, given state space heuristic,cost current path. Balyo, Bartak Surynek (2012) used sliding windowapproach minimise parallel plan length (that is, makespan, assuming actionsunit duration). Rather take segments single path state space, use blockdeordering input plan create candidate windows local optimisation. shownexperimental results, important success BDPO2: totalimprovement average plan quality achieved without deordering 28.7% lessachieved BDPO2 using block deordering input plans (cf. Section 3.6 page 402).planning-by-rewriting approach (Ambite & Knoblock, 2001) also uses local modifications partially ordered plans improve quality. Plan modifications defineddomain-specific rewrite rules, provided domain designer learnedmany examples good bad plans. Hence, technique effectivesolving many problem instances domain. Using planner solve subproblems may time-consuming applying pre-defined rules, makes processautomatic. However, consider solving many problems domain maypossible reduce average planning time learning (generalised) rules subplanimprovements discover using applicable avoid invoking subplanner.6.4 Portfolio Planning Automatic Parameter Tuningportfolio planning system runs several subplanners sequence (or parallel) shorttimeouts, hope least one component planners find solutiontime allotted it. Portfolio planning systems motivated observationssingle planner dominates others domains, planner solveplanning task quickly, often solve all. Therefore, many todayssuccessful planners run sequential portfolio planners (Coles, Coles, Olaya, Celorrio,Linares Lopez, Sanner, & Yoon, 2012).Gerevini, Saetti Vallati (2009) introduced PbP planner, learns portfoliogiven set planners specific domain, well domain-specific macro-actions.Fast Downward Stone Soup (FDSS, Helmert, Roger, Seipp, Karpas, Hoffmann, Keyder,427fiSiddiqui & HaslumNissim, Richter, & Westphal, 2011) uses fixed portfolio, computed optimise performancelarge sample training domains, domains. IBaCoP2 (Cenamor et al., 2014)dynamically configures portfolio using predictive model planner success.Another recent trend use automatic algorithm configuration tools, likeParamILS framework (Hutter, Hoos, Leyton-Brown, & Stutzle, 2009), enhance plannerperformance specific domain. ParamILS local search space configurations, using suite training problems evaluate performance different parametersettings. combinatorial explosion caused many parameters many different values managed varying one parameter time. ParamILS used configureLPG planner (Vallati, Fawcett, Gerevini, Hoos, & Saetti, 2011) Fast Downward planner (Fawcett, Helmert, Hoos, Karpas, Roger, & Seipp, 2011). PbP2 portfolioplanner (Gerevini, Saetti, & Vallati, 2011), successor PbP, includes version LPGcustomised domain ParamILS learned portfolio.BDPO2, course, uses portfolio subplanners, and, shown, selectingright subplanner current problem important (cf. Section 5). Much important,however, focus subproblems approach brings: comparing Figures 11 (page395) 23 (page 422), clear using even single subplanner within BDPO2effective using subplanners own. multiple window rankingpolicies used BDPO2 (cf. Section 4.6) also viewed simple sequential portfolio.Compared previous portfolio planners, iterated use subplanners, windowing strategies components approach offers possibility learn best portfolioconfiguration on-line; is, rather spend time configuring system usingtraining problems, learn experience solving several subproblems,actually working optimising current plan.Finally, although explored great depth, results suggest combining different anytime search post-processing methods, effectively kindsequential portfolio (such running BDPO2 result running PNGS resultLAMA IBaCoP2, results experiment 3, shown Figure 2 page 371),often achieves better quality final plans investing available time singlemethod.7. Conclusions Future WorkPlan quality optimisation, particularly large problems, central concern automatedplanning. Anytime planning, aims deliver continuing stream better plansgiven time, attractive idea, offering flexibility stop processpoint, best plan found good enough wait next planbecomes long. presented approach anytime plan improvement,realisation BDPO2 system. approach based large neighbourhood localsearch strategy (Shaw, 1998), using windowing heuristics select candidate windowsblock deordering current plan, local optimisation using off-the-shelf bounded-costplanning techniques.Experiments demonstrate BDPO2 achieves continuing plan quality improvementeven large time scales (several hours CPU time), anytime planners stagnate.Key achieving focus optimising subproblems, corresponding windows.428fiContinuing Plan Quality Optimisationmentioned Section 4.5, extending windowing heuristics improving on-linelearning effective window rankings one way improve approach. Also, complementing window ranking, estimates promising window is,estimate difficult windows optimise, using inform time allocated subplanners, currently uniform windows, may contribute betterperformance. best result, however, achieved chaining several techniques together(for example, applying BDPO2 best plan found PNGS applied best planfound LAMA IBaCoP2). result cannot achieved previous anytime planning approaches alone. Thus, another area future work examine greaterdepth best way combine different plan improvement methods,learned on-line optimising plan. example, conducted studyoptimal time switch base plan generation, using LAMA, post-processingusing PNGS BDPO, function total runtime (Siddiqui & Haslum, 2013a).demonstrated experimentally, block deordering step essentialgood performance BDPO2 (cf. Section 3.6 page 402). Block deordering createsdecomposition plan non-interleaving blocks removing ordering constraintsblocks. lifts limitation conventional, step-wise, deordering,requires unordered steps plan non-interfering. shown, validitycondition block decomposed partially ordered plans stated almostChapmans (1987) modal truth criterion, allowing threats causal linkremain unordered long link protected block structure (Theorem 2page 379). Therefore, block deordering yield less order-constrained plans, includingcases conventional deordering possible.plan structure uncovered block decomposition also uses. Recently used planner independent macro generation system BloMa (Chrpa &Siddiqui, 2015) find longer macros capture compound activities order improveplanners coverage efficiency. domains (e.g., Barman, ChildSnack, Scanalyzer,Parcprinter, Gripper, Woodworking, etc.), block deordering often identifies structurally similar subplans, also symmetric improvement patterns. could potentiallyexploited learning plan rewrite rules (Ambite, Knoblock, & Minton, 2000). structureblock deordered plans, often comprises nested, hierarchical decompositionmeaningful subplans, reminiscent Hierarchical Task Network (HTN) representations.Hence, block deordering technique could potentially applied generating (or helpinggenerate) HTN structures domain independent way, reducing knowledge-engineeringeffort. Recent work Scala Torasso (2015) extends deordering plans planningdomains numeric state variables, identifying numeric dependencies captureadditional reasons necessary orderings. Defining conditions blocks sufficientencapsulate dependencies would allow block deordering also numeric plans.may synergy block deordering numeric planning, since numeric dependencies often involve groups plan steps, rather single producerconsumer pair.Acknowledgmentwork partially supported Australian Research Council discovery projectDP140104219 Robust AI Planning Hybrid Systems. NICTA funded Aus429fiSiddiqui & Haslumtralian Government Department Communications Australian Research Council ICT Centre Excellence Program.ReferencesAhuja, R. K., Goodstein, J., Mukherjee, A., Orlin, J. B., & Sharma, D. (2007).large-scale neighborhood search algorithm combined through-fleet-assignmentmodel. INFORMS Journal Computing, 19 (3), 416428.Ambite, J. L., & Knoblock, C. A. (2001). Planning rewriting. Journal ArtificialIntelligence Research (JAIR), 15 (1), 207261.Ambite, J. L., Knoblock, C. A., & Minton, S. (2000). Learning plan rewriting rules.Proc. 5th International Conference Artificial Intelligence Planning Systems,AIPS 2000, Breckenridge, CO, USA, April 14-17, 2000, pp. 312. AAAI Press.Audibert, J.-Y., Munos, R., & Szepesvari, C. (2009). Explorationexploitation tradeoff usingvariance estimates multi-armed bandits. Theoretical Computer Science, 410 (19),18761902.Auer, P., Cesa-Bianchi, N., & Fischer, P. (2002). Finite-time analysis multiarmedbandit problem. Machine Learning, 47 (2-3), 235256.Backstrom, C. (1998). Computational aspects reordering plans. Journal ArtificialIntelligence Research (JAIR), 9, 99137.Balyo, T., Bartak, R., & Surynek, P. (2012). improving plan quality via local enhancements. Proc. 5th International Symposium Combinatorial Search, SOCS2012, Niagara Falls, Canada, July 19-21, 2012. AAAI Press.Bedo, J., & Ong, C. S. (2014). Multivariate Spearmans rho aggregating ranks usingcopulas. CoRR, abs/1410.4391.Bonet, B., & Geffner, H. (2001). Planning heuristic search. Artificial Intelligence, 129 (12), 533.Cenamor, I., de la Rosa, T., & Fernandez, F. (2014). IBaCoP IBaCoP2 planners.Proc. 8th International Planning Competition, IPC 2014, Deterministic Part,pp. 3538.Chapman, D. (1987). Planning conjunctive goals. Artificial Intelligence, 32 (3), 333377.Chien, S., Knight, R., Stechert, A., Sherwood, R., & Rabideau, G. (2000). Using iterativerepair improve responsiveness planning scheduling. Proc.5th International Conference Artificial Intelligence Planning Systems, AIPS 2000,Breckenridge, CO, USA, April 14-17, 2000, pp. 300307. AAAI Press.Chrpa, L., & Siddiqui, F. H. (2015). Exploiting block deordering improving planners efficiency. Proc. 24th International Joint Conference Artificial Intelligence,IJCAI 2015, Buenos Aires, Argentina, July 25-31, 2015, pp. 15371543. AAAI Press.Coles, A. J., Coles, A., Olaya, A. G., Celorrio, S. J., Linares Lopez, C., Sanner, S., & Yoon,S. (2012). survey seventh international planning competition. AI Magazine,33 (1), 8388.430fiContinuing Plan Quality OptimisationCopeland, A. H. (1951). reasonable social welfare function. University MichiganSeminar Applications Mathematics social sciences.de Borda, J. C. (1781). Memory election ballot. History Royal AcademySciences, Paris, 657664.Dwork, C., Kumar, R., Naor, M., & Sivakumar, D. (2001). Rank aggregation methodsweb. Proc. 10th International Conference World Wide Web, WWW2001, Hong Kong, May 1-5, 2001, pp. 613622, New York, NY, USA. ACM.Estrem, S. J., & Krebsbach, K. D. (2012). AIRS: Anytime iterative refinement solution. Proc. 25th International Florida Artificial Intelligence Research SocietyConference, Marco Island, Florida. May 23-25, 2012.Fawcett, C., Helmert, M., Hoos, H., Karpas, E., Roger, G., & Seipp, J. (2011). FD-Autotune:Domain-specific configuration using Fast Downward. Proc. 2011 ICAPSWorkshop Planning Learning, PAL 2011, Freiburg, Germany, June 11-16,2011, pp. 1320. AAAI Press.Fox, M., Gerevini, A., Long, D., & Serina, I. (2006). Plan stability: Replanning versus planrepair. Proc. 16th International Conference Automated PlanningScheduling, ICAPS 2006, Cumbria, UK, June 6-10, 2006., pp. 212221. AAAI Press.Furcy, D. (2006). ITSA*: Iterative tunneling search A*. Proc. 2006 AAAIWorkshop Heuristic Search, Memory-Based Heuristics Applications,July 1620, 2006, Boston, Massachusetts, pp. 2126. AAAI Press.Garivier, A., & Cappe, O. (2011). KL-UCB algorithm bounded stochastic banditsbeyond. CoRR, abs/1102.2490.Garrido, A., Guzman, C., & Onaindia, E. (2010). Anytime plan-adaptation continuousplanning. Proc. joint 28th Workshop UK Special Interest GroupPlanning Scheduling 4th Italian Workshop Planning Scheduling, pp.4754.Gerevini, A., Saetti, A., & Vallati, M. (2009). automatically configurable portfolio-basedplanner macro-actions: PbP. Proc. 19th International ConferenceAutomated Planning Scheduling, ICAPS 2009, Thessaloniki, Greece, September19-23, 2009, pp. 350353. AAAI Press.Gerevini, A., Saetti, A., & Vallati, M. (2011). PbP2: Automatic configuration portfoliobased multi-planner. 7th International Planning Competition (IPC 2011), LearningTrack. http://www.plg.inf.uc3m.es/ipc2011-learning.Gerevini, A., & Serina, I. (2002). LPG: planner based local search planning graphsaction costs. Proc. 6th International Conference Artificial IntelligencePlanning Scheduling, AIPS 2002, April 23-27, 2002, Toulouse, France, pp. 281290. AAAI Press.Gerevini, A. E., & Serina, I. (2000). Fast plan adaptation planning graphs: Localsystematic search techniques. Proc. 5th International ConferenceArtificial Intelligence Planning Systems, AIPS 2000, Breckenridge, CO, USA, April14-17, 2000, pp. 112121. AAAI Press.431fiSiddiqui & HaslumGhallab, M., Nau, D. S., & Traverso, P. (2004). Automated Planning: Theory & Practice.Morgan Kaufmann Publishers Inc., San Francisco, CA, USA.Godard, D., Laborie, P., & Nuijten, W. (2005). Randomized large neighborhood searchcumulative scheduling. Proc. 15th International Conference AutomatedPlanning Scheduling, ICAPS 2005, Monterey, California, USA, June 5-10 2005,pp. 8189. AAAI Press.Haslum, P. (2011). Computing genome edit distances using domain-independent planning.Proc. 2011 ICAPS Workshop Scheduling Planning Applications,SPARK 2011, Freiburg, Germany, June 11-16, 2011. AAAI Press.Haslum, P. (2012). Incremental lower bounds additive cost planning problems. Proc.22nd International Conference Automated Planning Scheduling, ICAPS2012, Atibaia, Sao Paulo, Brazil, June 25-19, 2012, pp. 7482. AAAI Press.Haslum, P., & Grastien, A. (2011). Diagnosis planning: Two case studies. Proc.2011 ICAPS Workshop Scheduling Planning Applications, SPARK 2011,Freiburg, Germany, June 11-16, 2011. AAAI Press.Haslum, P., & Jonsson, P. (2000). Planning reduced operator sets. Proc.5th International Conference Artificial Intelligence Planning Systems, AIPS 2000,Breckenridge, CO, USA, April 14-17, 2000, pp. 150158. AAAI Press.Helmert, M., Roger, G., Seipp, J., Karpas, E., Hoffmann, J., Keyder, E., Nissim, R., Richter,S., & Westphal, M. (2011). Fast Downward Stone Soup (planner abstract).Proc. 7th International Planning Competition, IPC 2011, Deterministic Part.http://www.plg.inf.uc3m.es/ipc2011-deterministic.Helmert, M., & Domshlak, C. (2009). Landmarks, critical paths abstractions: Whatsdifference anyway?. Proc. 19th International Conference AutomatedPlanning Scheduling, ICAPS 2009, Thessaloniki, Greece, September 19-23, 2009,pp. 162169. AAAI Press.Hoffmann, J. (2001). Local search topology planning benchmarks: empirical analysis.Proc. 17th International Joint Conference Artificial Intelligence, IJCAI2001, Seattle, Washington, USA, August 4-10, 2001, pp. 453458, San Francisco, CA,USA. Morgan Kaufmann Publishers Inc.Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generationheuristic search. Journal Artificial Intelligence Research (JAIR), 14, 253302.Hutter, F., Hoos, H. H., Leyton-Brown, K., & Stutzle, T. (2009). ParamILS: automaticalgorithm configuration framework. Journal Artificial Intelligence Research (JAIR),36 (1), 267306.Jones, D. M., & Gittins, J. (1974). dynamic allocation index sequential designexperiments. University Cambridge, Department Engineering.Kambhampati, S., & Kedar, S. (1994). unified framework explanation-based generalization partially ordered partially instantiated plans. Artificial Intelligence,67 (1), 2970.432fiContinuing Plan Quality OptimisationMcAllester, D., & Rosenblitt, D. (1991). Systematic nonlinear planning. Proc. 9thNational Conference Artificial Intelligence, AAAI 1991, Anaheim, CA, USA, July14-19, 1991, Volume 2., pp. 634639. AAAI Press / MIT Press.Muise, C. J., McIlraith, S. A., & Beck, J. C. (2012). Optimally relaxing partial-order plansmaxsat. Proc. 22nd International Conference Automated PlanningScheduling, ICAPS 2012, Atibaia, Sao Paulo, Brazil, June 25-19, 2012, pp. 358362. AAAI Press.Nakhost, H., & Muller, M. (2009). Monte-carlo exploration deterministic planning.Proc. 21st International Joint Conference Artificial Intelligence, IJCAI2009, Pasadena, California, USA, July 11-17, 2009, Vol. 9, pp. 17661771.Nakhost, H., & Muller, M. (2010). Action elimination plan neighborhood graph search:Two algorithms plan improvement. Proc. 20th International ConferenceAutomated Planning Scheduling, ICAPS 2010, Toronto, Canada, May 12-16,2010, pp. 121128. AAAI Press.Nebel, B., & Backstrom, C. (1994). computational complexity temporal projection, planning, plan validation. Artificial Intelligence, 66 (1), 125160.Pandey, S., Chakrabarti, D., & Agarwal, D. (2007). Multi-armed bandit problemsdependent arms. Proc. 24th International Conference Machine Learning,ICML 2007, Corvallis, Oregon, USA, June 20-24, 2007, Vol. 227, pp. 721728. ACM.Pednault, E. P. D. (1986). Formulating multiagent, dynamic-world problems classicalplanning framework. Reasoning actions plans, 4782.Pohl, I. (1970). Heuristic search viewed path finding graph. Artificial Intelligence,1 (3), 193204.Ratner, D., & Pohl, I. (1986). Joint LPA*: Combination approximation search.Proc. 5th National Conference Artificial Intelligence, AAAI 1986, Philadelphia, PA, August 11-15, 1986. Volume 1: Science., pp. 173177. Morgan Kaufmann.Regnier, P., & Fade, B. (1991). Complete determination parallel actions temporaloptimization linear plans action. Proc. European Workshop Planning,EWSP 1991, Sankt Augustin, FRG, March 18-19, 1991, Vol. 522 Lecture NotesComputer Science, pp. 100111. Springer.Richter, S., & Helmert, M. (2009). Preferred operators deferred evaluation satisficingplanning. Proc. 19th International Conference Automated PlanningScheduling, ICAPS 2009, Thessaloniki, Greece, September 19-23, 2009, pp. 273280.AAAI Press.Richter, S., Thayer, J. T., & Ruml, W. (2010). joy forgetting: Faster anytime searchvia restarting. Proc. 20th International Conference Automated PlanningScheduling, ICAPS 2010, Toronto, Canada, May 12-16, 2010, pp. 137144. AAAIPress.Richter, S., & Westphal, M. (2010). LAMA planner: Guiding cost-based anytimeplanning landmarks. Journal Artificial Intelligence Research (JAIR), 39, 127177.433fiSiddiqui & HaslumRobbins, H. (1952). aspects sequential design experiments. HerbertRobbins Selected Papers, Vol. 58, pp. 527535. Springer.Ropke, S., & Pisinger, D. (2006). adaptive large neighborhood search heuristicpickup delivery problem time windows. Transportation Science, 40 (4),455472.Scala, E., & Torasso, P. (2015). Deordering numeric macro actions plan repair.Proc. 24th International Joint Conference Artificial Intelligence, IJCAI2015, Buenos Aires, Argentina, July 25-31, 2015, pp. 16731681. AAAI Press.Schrimpf, G., Schneider, J., Stamm-Wilbrandt, H., & Dueck, G. (2000). Record breakingoptimization results using ruin recreate principle. Journal ComputationalPhysics, 159 (2), 139171.Shaw, P. (1998). Using constraint programming local search methods solve vehiclerouting problems. Proc. 4th International Conference PrinciplesPractice Constraint Programming, CP 1998, , Pisa, Italy, October 26-30, 1998,Vol. 1520 Lecture Notes Computer Science, pp. 417431. Springer.Siddiqui, F. H., & Haslum, P. (2012). Block-structured plan deordering. Proc. 25thAustralasian Joint Conference Advances Artificial Intelligence, AI 2012, Sydney,Australia, December 4-7, 2012, Vol. 7691 Lecture Notes Computer Science, pp.803814, Berlin, Heidelberg. Springer.Siddiqui, F. H., & Haslum, P. (2013a). Local search space valid plans. Proc.2013 ICAPS Workshop Evolutionary Techniques Planning Scheduling, EVOPS 2013, Rome, Italy, June 10-14, 2013, pp. 2231. http://icaps13.icapsconference.org/wp-content/uploads/2013/05/evops13-proceedings.pdf.Siddiqui, F. H., & Haslum, P. (2013b). Plan quality optimisation via block decomposition.Proc. 23rd International Joint Conference Artificial Intelligence, IJCAI2013, Beijing, China, August 3-9, 2013, pp. 23872393. AAAI Press.Slivkins, A. (2014). Contextual bandits similarity information. Journal MachineLearning Research, 15 (1), 25332568.Stern, R. T., Puzis, R., & Felner, A. (2011). Potential search: bounded-cost searchalgorithm. Proc. 21st International Conference Automated PlanningScheduling, ICAPS 2011, Freiburg, Germany June 11-16, 2011, pp. 234241. AAAIPress.Thayer, J., Stern, R., Felner, A., & Ruml, W. (2012a). Faster bounded-cost search usinginadmissible heuristics. Proc. 22nd International Conference AutomatedPlanning Scheduling, ICAPS 2012, Atibaia, Sao Paulo, Brazil, June 25-19, 2012,pp. 270278. AAAI Press.Thayer, J. T., Benton, J., & Helmert, M. (2012b). Better parameter-free anytime searchminimizing time solutions. Proc. 5th International SymposiumCombinatorial Search, SOCS 2012, Niagara Falls, Canada, July 19-21, 2012, pp.120128. AAAI Press.434fiContinuing Plan Quality OptimisationThayer, J. T., & Ruml, W. (2011). Bounded suboptimal search: direct approach usinginadmissible estimates. Proc. 22nd International Joint Conference Artificial Intelligence, IJCAI 2011, Barcelona, Catalonia, Spain, July 16-22, 2011, pp.674679. AAAI Press.Vallati, M., Fawcett, C., Gerevini, A., Hoos, H., & Saetti, A. (2011). ParLPG: Generating domain-specific planners automatic parameter configuration LPG.Proc. 7th International Planning Competition, IPC 2011, Deterministic Part.http://www.plg.inf.uc3m.es/ipc2011-deterministic.Veloso, M. M., Perez, A., & Carbonell, J. G. (1990). Nonlinear planning parallelresource allocation. Proc. DARPA Workshop Innovative ApproachesPlanning, Scheduling Control, San Diego, California, November 5-8, 1990, pp.207212. Morgan Kaufmann.Wang, Y., Audibert, J., & Munos, R. (2008). Algorithms infinitely many-armed bandits.Proc. 22nd Annual Conference Neural Information Processing Systems,NIPS 2008, Vancouver, British Columbia, Canada, December 8-11, 2008, pp. 17291736. Curran Associates, Inc.Xie, F., Nakhost, H., & Muller, M. (2012). Planning via random walk-driven local search.Proc. 22nd International Conference Automated Planning Scheduling,ICAPS 2012, Atibaia, Sao Paulo, Brazil, June 25-19, 2012, pp. 315322. AAAI Press.Xie, F., Valenzano, R. A., & Muller, M. (2010). Better time constrained search via randomization postprocessing. Proc. 23rd International ConferenceAutomated Planning Scheduling, ICAPS 2013, Rome, Italy, June 10-14, 2013,pp. 269277. AAAI Press.Young, H. P., & Levenglick, A. (1978). consistent extension condorcets election principle. SIAM Journal Applied Mathematics, 35 (2), 285300.Zhou, R., & Hansen, E. A. (2005). Beam-stack search: Integrating backtracking beamsearch. Proc. 15th International Conference Automated PlanningScheduling, ICAPS 2005, Monterey, California, USA, June 5-10, 2005, pp. 9098.AAAI Press.435fiJournal Artificial Intelligence Research 54 (2015) 233275Submitted 06/15; published 10/15Decision Making Dynamic Uncertain EventsMeir KalechKALECH @ BGU . AC . ILDepartment Information Systems Engineering,Ben-Gurion University Negev, Beer-Sheva, IsraelShulamit RechesSHULAMIT. RECHES @ GMAIL . COMDepartment Applied Mathematics,Jerusalem College Technology, IsraelAbstractmake decision key question decision making problems characterizeduncertainty. paper deal decision making environments information arrives dynamically. address tradeoff waiting stopping strategies. onehand, waiting obtain information reduces uncertainty, comes cost. Stoppingmaking decision based expected utility reduces cost waiting, decisionbased uncertain information. propose optimal algorithm two approximation algorithms. prove one approximation optimistic - waits least long optimalalgorithm, pessimistic - stops later optimal algorithm. evaluatealgorithms theoretically empirically show quality decision approximations near-optimal much faster optimal algorithm. Also, concludeexperiments cost function key factor chose effective algorithm.1. Introductionmany real-world domains agent choose alternative among multiplecandidates, based utility. problem becomes complicated utility dependsevents occur dynamically therefore decision based dynamically changinguncertain information. domains, question whether stop particular pointmake best decision given information available, wait information arrivesenable making better decision. problem trivial cost associatedwaiting.example, consider problem finding best stock buy stock market.values stocks may change time due future events, publication companyssales report change interest rate, etc. longer wait, information becomesavailable and, result, decision made certainty. many real-world domains,cost waiting. instance, example, cost stock reflects losscaused investing money one candidate stocks. Thus, tradeoffwaiting strategy enables one acquire information decreases uncertaintystopping strategy, reduces cost.Another example relates scheduling systems meetings. Determining best timemeeting could depend many factors, times meetings, location,schedule attendees. Typically, factors may change dynamically influence decisionbest time meeting; obviously, longer one waits, information becomesc2015AI Access Foundation. rights reserved.fiK ALECH & R ECHESavailable probability choosing best time meeting higher. However, waitingincurs cost possibility chosen time slot might longer available. goalpaper determine best time make decision maximizes expected gainconsiders cost waiting.question, whether wait get information not, also raised contextreal estate investment. many unknown factors may influence decisionreal estate property buy. example, infrastructure development area (like railwaystation), raising/reducting municipal taxes area, construction polluting factory area,etc. question whether choose real estate property based expected gainwait get information next factor taking risk properties prices mayincrease.tradeoff uncertainty cost related optimal stopping problem (Ferguson,1989; Peskir & Shiryaev, 2006), problem decision making bounded-resource (Horvitz,2001, 2013), problem decision making multiple informative expensive observations(Krause & Guestrin, 2009; Tolpin & Shimoni, 2010), Max K-Armed Bandit problem (Cicirello& Smith, 2005) ranking selection problem (Powell & Ryzhov, 2012). work copeschallenge stopping problem multiple alternatives affected uncertaininformation arrives dynamically. decision whether stop wait, problem, dependsutility affected result certain events occur next time stamps. Sincealternative affected different events consider combination possibleevents, makes problem hard different others.paper, we:1. Develop model representing arrival dynamic information influenceutilities candidates.2. Present optimal exponential algorithm (OP IM AL) guarantees best decisiontradeoff certainty waiting costs.3. Propose two polynomial approximation algorithms solve problem provide boundserror. prove algorithms evaluate expected utility stopping optimally. However, one approximation algorithm optimistic (OP IM IST IC)sense waiting evaluation overestimated. algorithm pessimistic(P ESSIM IST IC), namely waiting evaluation underestimated.4. Empirically evaluate optimal two approximation algorithms illustrateadvantages one them.empirically evaluate three algorithms simulating stock market scenario. compare optimal approximation algorithms four baseline algorithms; one algorithmmakes decision beginning decision process, second algorithm decidesinformation obtained, third algorithm makes decision random time fourthone makes decision half time steps. examine algorithms termsquality decision (utility) runtime.empirical evaluation shows cost function much influences qualitydecision. cost function increases moderately (i.e. root function), pessimisticalgorithm becomes less effective optimistic algorithm improves quality decision234fiD ECISION AKING DYNAMIC U NCERTAIN E VENTSeven slightly better pessimistic one. However, cost functions grow linearlypolynomially time pessimistic approach much better optimistic one,cases even significant difference quality decision madepessimistic approximation algorithm optimal algorithm. quality approximations much better baseline algorithms. runtime approximation algorithmspolynomial rather exponential runtime optimal algorithm.work extension previous work (Kalech & Pfeffer, 2010; Reches, Kalech, &Stern, 2011). work expand theoretical empirical parts research.particular, theoretical aspect find prove approximation error expectedgain expected wait algorithms, prove complexity propertiespessimistic optimistic algorithms. greatly expanded evaluation presentinginfluence different parameters, cost waiting, distribution variables.Furthermore, empirically show pessimistic optimistic behaviour algorithms.paper organized follows. next section present basic fundamentalsproblem formally define it. Section 3 present optimal algorithm. optimistic approach illustrated Section 4 pessimistic approach Section 5. empirical evaluationalgorithms provided Section 6. Section 7 discuss related work conclusionpresented Section 8.2. Model Descriptiondescribe model clearly use example inspired stock market. Assume decisionmaker wishes choose one stock purchase among three stocks (c1 , c2 , c3 ). valuestocks influenced future events, consumer price index (CPI), interest rates, etc.decision maker cannot evaluate influence future events stocks certaintydegree probability. Obviously, sooner decision taken, lesserloss investing money. hand, longer waiting time,information gathered knowing outcome expected events consequentlydecision greater degree certainty made.model, decision designated candidate; throughout paper refercandidate set C = {c1 , c2 , ..., cm }. agent desires choose alternative setC. candidates utility influenced information arrives dynamically. representdynamic information random variables. random variable event occurs specifictime. different outcomes event may influence utility candidate differentways. described extensively later, candidate may influenced multiple events. Let usdefine formally timed variable.Definition 1 (timed variable) timed variable pair Xi , t, Xi discrete, finite random variable taking values xi1 , ..., xik represents time stamp, discretetime horizon = {0, ..., h} horizon h.Given timed variable Xi , t, time stamp random variable Xi assignedone possible values xi1 , ..., xik .example, timed variables stock market future events influence utilitystocks. X1 , 1 may represent expected decrease percentage interest rate time1, time 1 represents one month now. X1 takes discrete values {x11 = 0.1, x12 =235fiK ALECH & R ECHES0}. Another timed variable, X2 , 2, represents expected prospectus specific companytwo months now, takes values {x21 = positive, x22 = negative}. One timedvariable X3 , 3, represents expected change percentage CPI three months. X3 takesvalues {x31 = 0.1, x32 = 0.2}. example, X1 , 1 X3 , 3 influence candidate c1X2 , 2 influences candidate c2 . timed variable may affect two candidates.Definition 2 (assignment) assignment timed variable X, outcome xi X.global assignment time t, denoted , assignment values timed variables whosetime stamp less equal t.example, global assignment time 3 ( 3 ) may X1 = 0, X2 = positive,X3 = 0.1, i.e., time 1 (after month) interest change, time 2 (after two months)prospectus company positive, time 3 (after three months) CPI increased0.1%.candidates utility depends set timed variables, different sets lead differentutilities. use tree represent effect timed variables utility.Definition 3 (candidate tree) candidate tree cti candidate ci tree. nj,i node cti ,stands index candidate j index tree. internal nodesassociated timed variables. random variable corresponding node n denoted X(n)time denoted (n). nj,i descendant nk,i (nk,i ) < (nj,i ). edges goingnode n represent possible assignments X(n). edge X = x labeledprobability outcome denoted p(X = x). leaf n labeled utility U(n), representingutility candidate affected assignments root leaf. CT represents setcandidate trees.call assignments path starts root candidate tree cti endsnode nj,i time = (ni,j ) local assignment candidate ci denoted . Notecandidate tree represents estimate effect timed variables utilitycandidates. Obviously, estimate may change time, due addition removal timesvariables re-estimation probabilities utilities. case candidate treesupdated.X3,t=3 0.4n1,1X1,t=1n0,10.60.80.20.9n2,1n3,1n5,18055X4,t=3 0.3n1,2X5,t=4n4,10.80.1Figure 1: Candidate tree ct1 .X6,t=4n4,20.6n5,2n3,275650.70.40.2n2,2n6,160X2,t=2n0,240n6,27045Figure 2: Candidate tree ct2 .Figures 1 2 present two candidate trees built time stamp = 0. extensionthree timed variables demonstrated above. n0,1 root candidate tree ct1 . time stamp= 1, represents fact random variable X1 obtain outcomes time 1.236fiD ECISION AKING DYNAMIC U NCERTAIN E VENTSnode n1,1 ct1 represents timed variable X3 , = 3. One possible outcome changeCPI (X3 ) 0.1% (left edge). probability outcome 0.8. alternative outcomechange CPI 0.2% (right edge) probability outcome 0.2. value80 left leaf ct1 represents utility candidate c1 local assignment time 3(13 ) is: interest decreased 0.1% (X1 = 0.1) CPI increased 0.1% (X3 = 0.1).probability utility 0.4 0.8 = 0.32.utility candidate known certainly leaves. However, expected utilitycandidate calculated beforehand time (depth candidate tree) considersubtree depth. expected utility trivially computed recursive function.expected utility leaf utility internal node expected utilitieschildren. Formally:Definition 4 (expected utility) Given node n cti , function EU(cti , n) returns expectedutility n:{U(n)n leafEU(cti , n) =j p(X(n) = xj )EU(cti , nj ) otherwisenj represents successor node n via assignment X(n) = xj .instance, expected utility root Figure 1 is: EU(ct1 , n0,1 ) = 0.4 (0.8 80 +0.2 55) + 0.6 (0.9 60 + 0.1 65) = 66.3.expected utility estimate real utility based information knowncurrent time. Waiting next time reduces uncertainty candidates utilitieshence increases probability making good decision. However, waiting incurs cost. costeither function assignments function time. sake simplicity,paper represent cost function time. reality, cost waiting specifictime stamp usually higher utility gained time. Thus, enforce realistic cost,bound cost maximum utility.Definition 5 (cost) Given time stamp , CST (t) increasing function returnsapproximated cost waiting time t.expected gain node difference expected utility nodecost waiting node.Definition 6 (expected gain) Given node ncti , GN (cti , n)=EU (cti , n)CST ((parent(n))).1 n root candidate tree then: GN (cti , n) = EU(cti , n).reason reduce cost parent n, rather n EU(cti , n) representsexpected gain subtree rooted n without waiting outcomes X(n).tradeoff first component GN , expected utility, secondcomponent, waiting cost. objective paper present algorithm find1. Since utility cost necessarily given scale normalized reduction.normalization domain dependent.237fiK ALECH & R ECHEStime maximizes gain2 . Unfortunately, unable separate computationoptimal time make decision selection best candidate, since utilitiescandidates depend future events. Therefore, define policy determinesituations decision maker might face.Beside outcomes timed variables, cost function also influences decisionwhether stop wait. cost function returns much smaller values differenceexpected utilities time eventually lead wait decision.hand, cost function returns values high eventually lead stop decision. examples paper use cost function CST (t) = t. function ensuresproportional cost values (0,1,2,3,4) relation utility values (4580). instance, accordingestimate time stamp = 0, given global assignment: X1 = 0.1, X2 = positive,expected gain candidate c1 GN (ct1 , n1,1 ) = 75 1 = 74 expected gain c2GN (c2 , n1,2 ) = 68 2 = 66. result, decision maker decides stop choose c1 ,otherwise wait next time stamp. policy dictates decision whether stopwait.Definition 7 (policy) policy function : {stop, wait}, set globalassignments.policy specifies stop, decision maker chooses candidate current highestexpected gain.Finally, define expected gain decision maker using policy , referred globalexpected gain. understand definition first introduce another definition nodescorresponding certain time.Definition 8 (N ODEStj ) set N ODEStj represents following nodes ctj : (1) leaveswhose parents time less equal t: {n ctj |(parent(n)) t, n leaf}. (2)internal nodes whose parents time less equal time greater {nctj |(parent(n)) (n) > t, n internal node}.example, Figure 1 N ODES31={n2,1 , n3,1 , n4,1 }, N ODES41={n2,1 , n3,1 , n5,1 , n6,1 }.global expected gain function obtains candidate trees, global assignment,policy. policy specifies stop, global expected gain maximum expected gainamong candidates. Otherwise, recursively computes expectation global expectedgain different combinations roots children next time stamp. Formally:Definition 9 (global expected gain) global expected gain function returns expectedgain choosing policy :GEG(CT, , ) =GN (ctj , nj )( ) = stopmaxjGEG(CT , ty , )P r(y) ( ) = waity{N ODES 1 ,...,N ODES }t+1t+12. Although decision making theory common maximize expected utility, use term expectedgain, incorporates cost order distinguish expected utility.238fiD ECISION AKING DYNAMIC U NCERTAIN E VENTS1. nj root ctj .2. CT set candidate trees rooted nodes y.3. P r(y) probability nodes given assignment .4. ty represents union assignments X(nj ) represented y.running example, global assignment t=2 policy ( t=2 ) = stop= (n1,1 , n1,2 ), GEG(CT , , ) = max(73, 66) = 73. case policy ( ) = wait,sum GEG possible assignments next time. set N ODES rootednodes n1,1 n1,2 time = 3 N ODES31 = {n2,1 , n3,1 } N ODES32 = {n2,2 , n3,2 },correspondingly, {n2,1 , n3,1 } {n2,2 , n3,2 }. Therefore:GEG(CT {n1,1 ,n1,2 } , , ) =GEG(CT {n2,1 ,n2,2 } , , ) 0.8 0.8+GEG(CT {n2,1 ,n3,2 } , , ) 0.8 0.2+GEG(CT {n3,1 ,n2,2 } , , ) 0.2 0.8+GEG(CT {n3,1 ,n3,2 } , , ) 0.2 0.2Based definitions, define timed decision making problem (TDM):Definition 10 (Timed Decision Making (TDM) problem) Given set candidate trees CT ,TDM problem find policy maximizes GEG(CT, 0 , ).Table 1 summarizes notation use describing model.hardness TDM problem due computation expected gain waiting next time stamp. computation needs take consideration utilitycandidate possible assignment time stamp. Specifically, time t0 , decision maker decide whether stop choose best candidate wait nexttime stamp comparing expected gain stopping expected gain waiting.expected gain stopping time stamp t0 computed immediately taking maximumexpected gain candidate trees (maxGN (ctj , nj ), n1 , ..., nm rootsjcandidate trees). hand, computation expected gain waiting nexttime stamp hard. expected wait considers combination possible assignmentscandidate trees time t1 . combination, need take considerationutility stopping time t1 utility waiting time stamp t2 include additionalcombinations assignments on. problem hard number combinationsexponential number candidates. Specifically, certain time stamp, k possibleassignments different variables different candidate trees, number combinations k .order prove TDM NP-hard, present timed decision making problemdecision problem . Given CT, 0 non-negative integer K. Answer yes existpolicy global expected gain GEG(CT, 0 , ) K.Theorem 1: TDM problem NP-hard. (The proof appears Appendix A).One option representing problem would use Markov Decision Processes (MDP).model, states time would global assignments time ( ) actions wouldeither select best candidate time (stop) wait one time step. transition239fiK ALECH & R ECHESParameterC = {c1 , ..., cm }Xi ,ctiCTnj,iX(n)(n)= (0, ..., h)U (nij )EU(cti , n)CST (t)GN (cti , n)policyN ODEStjGEGEW( , )ES( , )PT H(cti , n)P rPT H(cti , n)Descriptionset candidates.timed variable, Xi discrete, finite random variabletime stamp.candidate tree ci .set candidate trees.assignment values timed variables whose time stamp lessequal t.local assignment. assignments path stats rootcandidate cti end node whose time t.node candidate tree cti candidate ci .random variable corresponding node n.time random variable corresponding node n.time horizon.utility candidate cti affected assignments rootleaf nij .expected utility candidate tree cti node n.approximated cost waiting time t.expected gain node n candidate tree cti differenceexpected utility node cost waiting node.function : {stop, wait}.set nodes whose parents time less equalleaves, time greater t.Global expected gain.expected gain waiting next time stamp (t+1), using policy.expected gain stopping time stamp t, using policy .path, set local assignments root cti node n.probability path.Local policy candidate ci .Table 1: notation used description model.240fiD ECISION AKING DYNAMIC U NCERTAIN E VENTSfunction time state time + 1 state wait action would given productprobabilities time + 1 assignments. stop action leads terminal state rewardreceived equal gain winning candidate.usual advantage MDP formulation possibility using dynamic programmingmethods, value policy iteration. However, problem, dynamic programmingprovides benefits state cannot reached different paths numberstates exponential total number timed variables trees.One methods addresses large MDPs means factored MDPs (Boutilier,Dearden, & Goldszmidt, 2000; Guestrin, Koller, Parr, & Venkataraman, 2003). approachviable domain utility stopping maximization utilitiestrees depends timed variables. show Section 4, special structureproblem readily apparent MDP factored MDP formulation.3. Optimal Algorithmoptimal gain calculated straightforwardly decision tree approach. optimaldecision tree merges candidate trees single decision tree whose depth maximal timetimed variables candidate trees. decision tree, define three kinds nodes:Decision nodes, decision maker must decide whether stop wait; decisionstop, candidate choose.Stop nodes, decision maker stopped chosen one candidates.Wait nodes, decision maker decided wait.node marked time stamp. Edges leading wait nodes labeled conjunctions assignments. Every node tree marked set assignments,assignments path leading node.tree constructed offline time follows:Procedure 1 Optimal:1. root decision node time stamp 0.2. time stamp, children decision nodes time stamp wait nodestime stamp t; candidate stop node child. final time stamp, waitnode child included.3. Stop nodes leaves tree. stop node corresponds node n cti time t,value node GN (cti , n) (Definition 6).4. children wait node time stamp given global assignment determinedfollows:(a) local assignment passes path assignments ending node. Let usdenote node ni candidate tree cti .(b) Let Xn = X(ni ).241fiK ALECH & R ECHESDecision Time Horizon66.84066.8466.358.90.40.673.857.773.8859.373.260.365.66 0.6476.476.4 71.44476.4 36.44475.275.270.275.22170.275.275.235.251.4 36.44450.270.250.22150.250.235.20.70.872.36660.258.168.565.660.856.275.2 75.265.250.256.971.4 70.2420.9 0.170.270.252.6658.159.510.271.476.4 51.4 75.2 51.4 51.4 56.22442440.4 0.60.4 0.6259.568.576.451.451.4 71.4 70.2442152.660.0471.476.475.2210.1672.6662.240.372.674.60.1657.70.774.672.66162.256.956.936.4 55.740.9 0.155.259.557.960.252.44359.50.36 0.54 0.04 0.0665.255.265.2 60.2440.275.2 65.2 75.2 40.2 50.2 65.2 50.2 40.2 55.2 70.2 60.2 70.2 55.2 35.2 60.2 35.2 55.2 65.2 55.2 40.2 60.2 65.2 60.2Figure 3: Optimal decision tree ct1 ct2 candidate trees.(c) possible joint outcome timed variables Xn , wait node child,labeled joint probability. child decision node time stamp + 1.tree constructed, evaluated using simple bottom-up process.gains leaves, i.e., stop nodes, already calculated. gain wait nodeexpectation utilities children. gain decision node maximum gainchildren optimal decision one leads maximal gain. decision treegenerated evaluated advance assignments undertaken. solutionrepresents policy (Definition 7).Figure 3 presents optimal decision tree decision problem candidate trees ct1(Figure 1) ct2 (Figure 2). time line right graph represents time horizondecision. rectangular nodes represent decision nodes; shaded ellipse nodes representwait nodes empty ellipse nodes represent stop nodes3 . stop nodes come pairs, onecandidate; node c1 left. numbers nodes represent expectedgains computed using bottom-up algorithm. example, used cost functionlinearly grows time: CST (t) = 1.2t, cost reaching leaf 4.8 (since fourtime stamps).example, consider dashed triangle right-hand side figure. rootsubtree shown triangle wait node time stamp 3. determining childrennode, consider timed variables candidate trees time stamp 4. twotimed variables, X5 , 4 candidate c1 X6 , 4 candidate c2 . need splitjoint outcomes two candidates wait node four children.children decision node time stamp 4. Since last time stamp, decision nodesstop nodes children.One particular course events shown bold figure. Since expected gain waiting(66.84) higher expected gain stopping, expected utility choosing3. stop nodes final time ellipses readability. also omitted assignment labelsedges.242fiD ECISION AKING DYNAMIC U NCERTAIN E VENTSbest stop node (66.3), agent wait. Accordingly, assignment X1 = 0 (left)occur. next decision node child, expected gain stopping choosing candidatec1 (73.88) higher expected gain waiting (73.26), agent may stop = 1choose c1 . Assume sequence assignments occurred depicted bold figure.eventually lead leaf node gain 75.2 shown. Note, however, gainincorporates cost waiting 4 time stamps. Thus, agent omniscient knownoutcomes timed variables advance, would obtained gain 80, since wouldwait all. rational agent stops time 1, gain choosing c180 1.2 = 78.8.Denote optimal policy. Given global assignment , use EW( , ) representexpected gain waiting next time stamp executing optimal algorithm. equalswait node given . Similarly, use ES( , ) represent expected gain stoppingtime stamp executing optimal algorithm; equals maximal stop node given .example, Figure 3, EW( 0 , ) = 66.84 ES( 0 , ) = 66.3.optimal decision tree explicitly represents state space MDP model, describedSection 2. Since state space represented tree (rather graph), intelligent valueiteration process equivalent backward induction algorithm use optimal decisiontree.3.1 Analysistime complexity optimal algorithm affected fact optimal decision treeconsiders different combinations paths candidate trees. Let maximum sizecandidate tree number candidates m. Notice size candidate treeexponential depth local candidate tree. Specifically, given depth candidatetree, h (the horizon), number outcomes timed variable, k (the branching factor)= k h . total number timed variables size depth optimaldecision tree bounded log(M ). worst-case time complexity computing optimaltree O(M ).mentioned above, backward induction optimal decision tree equivalentvalue iteration MDPs. Since state space represented tree, value iteration simplyscans state space. Thus, complexity value iteration size state space.complexity state space, described Section 2, sum global assignment alternatives time. worst case, every candidate depends different timed variablestime, k alternatives time 1, (k 2 ) alternatives time 2, (k h ) alternativestime h. complexity identical complexity optimal decision tree O(M ) (sinceO(k h )).best-case complexity archived candidates affected timed variable, since consider combinations timed variables. casetrees candidates identical except utilities leaves complexitythus mM .Beyond exponential complexity optimal algorithm, another disadvantage algorithm stems fact every change candidate trees demands rebuilding decisiontree. Unfortunately, due exponential complexity rebuilding feasible. copeexponential complexity optimal algorithm fact feasible rebuild de243fiK ALECH & R ECHEScision tree timed variables change, propose two approximation algorithms followingsections.Beyond exponential complexity optimal algorithm, another disadvantage algorithm stems fact every change candidate trees demands rebuilding decisiontree. optimal algorithm computes whole combinations future events advanceresult, makes optimal solution long initial evaluation probabilitiesutilities event valid. Since complexity optimal algorithm exponential, mayinfeasible rebuild new decision tree time stamp. However, realistic scenariosevaluation events utilities may change time. cope exponentialcomplexity optimal algorithm fact feasible rebuild decision treetimed variables change, following sections propose two approximation polynomialalgorithms.4. Optimistic Approachoptimal algorithm presented Section 3 considers candidates simultaneously thusgrows exponentially number candidates. section, present alternative algorithmic framework considers candidates separately dynamically. alternative viewpointlead efficient approximation algorithm.4.1 OPTIMISTIC Algorithmmain idea behind alternative framework calculating utility candidate treeseparately combining utilities together obtain evaluation global gain.way avoid complexity comparing assignment assignmentscandidates; candidate contributes separately overall utility. Specifically, candidatecontributes overall utility actually prevails candidates. Thusestimate utility node candidate tree product expected gainprobability candidate win, given node reached. Then, order estimateoverall gain, sum utility candidates. formally describe algorithmpresent following definitions:Definition 11 (path) Given node n cti , function PT H(cti , n) returns set local assignments root n {Xi1 = xi1 , Xi2 = xi2 , ...} candidate tree cti .Definition12 (probability path) GivenjPT H(cti ,n) P r(j).nodencti ,P rPT H(cti , n)=probability ci prevail specific candidate cj time sum probabilities prevail cj possible assignment, i.e., node N ODEStj .probability candidate ci prevail candidates, given specific node nx,i ctispecific time stamp, = (nx,i ), sum probabilities prevailcandidate current time t. Formally4 :4. mathematical calculations probabilities approximation algorithms, assume candidatesdisjointed sets timed variables probabilistically independent; means two candidatesaffected time variable. Nevertheless, shown results experiments, algorithmsperform well even common variables.244fiD ECISION AKING DYNAMIC U NCERTAIN E VENTSDefinition 13 (probability winning) Given node nx,i cti , probability ci win is5 :P r(ciwins|nx,i ) =IsW in(EU(cti , nx,i ), EU (ctj , ny,j ))P rPT H(ctj , ny,j )j{1,...,m},i=j ny,j N ODES j1. = (parent(nx,i )).2. IsW in(EU (cti , nx,i ), EU(ctj , ny,j )) ={1 EU(cti , nx,i ) > EU(ctj , ny,j )0 elseexample, using Figures 1 2 above, recall N ODES31 = {n2,1 , n3,1 , n4,1 }.P r(c2 wins|n2,2 ) =IsW in(EU (ct2 , n2,2 ), EU(ct1 , n2,1 )) 0.4 0.8+IsW in(EU (ct2 , n2,2 ), EU(ct1 , n3,1 )) 0.4 0.2+IsW in(EU (ct2 , n2,2 ), EU(ct1 , n4,1 )) 0.6 =0 0.32 + 1 0.08 + 1 0.6 = 0.68define relative expected gain candidate contribution global expected gain given specific node.Definition 14 (relative expected gain) Given node nx,i cti , relative expected gain candidate ci GN (cti , nx,i ) P r(ci wins|nx,i ).Notice probability candidate ci win time stamp is:P r(ci wins) =P r(ci wins|nx,i ) P r(nx,i )nx,i N ODEStithus according law total probability:P r(ci wins|nx,i ) P r(nx,i ) = 1nx,i N ODESticomputation relative expected gain nx,i presented Algorithm 1. line 3go candidate trees except candidate tree cti . line 5 go candidatetrees nodes time nx,i time. sum probabilitiesnodes whose expected utility less nx,i (lines 68). sum representsprobability ci win cj , given node nx,i . Finally, line 10 multiply probability ciprevail candidates (given node nx,i ), since winning candidate prevailcandidates. return product probability expected gain node5. Ties candidates broken consistent manner.245fiK ALECH & R ECHESAlgorithm 1 RELATIVE EXPECTED GAIN(input: candidate trees CT = {ct1 , ..., ctm }input: node nx,ioutput: relative expected gain nx,i )1:2:3:4:5:6:7:8:9:10:11:12:(nx,i )prob 1ctj CT (i = j)temp 0ny,j N ODEStjEU (cti , nx,i ) > EU (ctj , ny,j )temp temp + P rPT H(ctj , ny,j )endendprob prob tempendreturn prob GN (cti , nx,i )nx,i . instance, relative expected gain choosing candidate c2 given node n2,2 time3 (with cost function CST (t) = 1.2t) (75 3.6) 0.68 = 48.552.optimistic approach determines policy (Definition 7) constructing separate decisiontree candidate. policy determined based local assignment time.mentioned earlier local assignment certain candidate tree derived globalassignment. estimate global expected gain stopping waiting dependspolicy expected gain candidate separately. call policy local policy.Obviously, may possible certain time local policies candidatesdifferent.Definition 15 (local policy) local policyi candidate ci rule dictates either stoppingwaiting local assignment .assignment time t, optimistic decision maker decides policy buildingindividual decision trees based relative expected gain candidate. expected gainstopping time sum relative expected gain candidates. optimisticprocedure invoked first time 0:Procedure 2 Optimistic:1. Generate individual candidate decision tree candidate ci based cti mannersimilar optimal decision tree except relative expected gain used insteadexpected gain.2. Denote stop node current time stamp candidate tree cti ES ( , )wait node current time stamp candidate tree cti EW ( , ).Denote also:ES( , ) =ES ( , )i{1,...,m}EW( , ) =EW ( , ).i{1,...,m}246fiD ECISION AKING DYNAMIC U NCERTAIN E VENTS3. ES( , ) EW( , )= stop, return argmax ES ( , )i{1,...,m}else = wait.4. Prune candidate tree according global assignment tree rootednode reached local assignment. Invoke Procedure 2 next time stamp + 1.consider stop values root, exactly one candidate probability winning 1 others probability 0. Therefore, expected gain winningcandidate equals sum values stop nodes root decision trees. Intuitively, value wait node candidate estimate candidates contributionbenefit waiting. Therefore, algorithm evaluates expected utility waiting summing expected wait candidates. summation value greater maximumimmediate expected gain, total expected gain waiting greater expected gainstopping. case decision wait. Otherwise, decision stopchoose candidate highest expected gain.agent decides wait decision trees must updated according new assignments obtained waiting. new assignments prune parts candidate trees.instance, consider candidate tree ct1 Figure 1. Assume agent decided waitoutcome variables time 1. Assume assignment timed variable X1 time 1left, right subtree ct1 pruned since longer influences utility ct1 .N ODESt1 set, associated specific time, changes result pruningwell computation relative expected gain. Therefore rebuilding decision treesnecessary.Figures 4 5 present decision tree ct1 ct2 , respectively (Figures 1 2). leavescontain two numbers; first represents expected utility second (in bold) representsrelative expected gain.example, let us compute relative expected gain rightmost bottom-level node n6,1Figure 1. cost function CST (t) = 1.2 t. node, utility 65, greatertwo nodes ct2 n3,2 utility 40 n6,2 utility 45. total probabilitytwo nodes ct2 defeated n6,1 0.3 0.2 + 0.7 0.6 = 0.48. probabilityc1 defeat c2 given utility 65. compute relative expected gain node(see Definition 14), multiply gain, 65 4.8 = 60.2, probability winning,resulting 28.9 (see rightmost bottom-level node Figure 4).Based decision trees Figures 4 5 find Optimistic algorithm decisiontime 0 wait, since sum wait nodes = 0 (89.3) greater sumstop nodes (66). Suppose timed variables X1 , 1 assigned left outcome.(asexample optimal algorithm). decision trees updated. Candidate c1 treepruned includes subtree rooted n1,1 result relatives expectedgain candidate trees c1 c2 updated. Figures 6 7 present obtained treesOptimistic algorithm case. According trees, algorithm time stamp = 0, decideswait, since sum wait nodes (84), higher sum stop nodes(73.8).next decision node child, expected gain stopping choosing candidate c1 (73.88)higher expected gain waiting (73.2), agent may stop = 1 choose c1 .247fiK ALECH & R ECHESDecision Time Horizon024.224.2(58.9) 01124.2(58.9) 00.324.20.739.438.8(68) 39.40.8(55) 01047.7 (40) 0047.70.4044.3(40) 0(70) 44.30.604(45) 0Figure 5: Candidate decision tree ct2 (built= 0).Decision Time Horizon111.4(58.9) 00.311.40.713.410.511.6(68) 13.40.8(75) 14.5(55) 01010.514.3 (40) 0114.3(75) 57.1210.50.214.5Figure 6: Candidate decision tree ct1 (rebuilt= 1).17.7(55) 4.11(75) 47.7317.71Figure 4: Candidate decision tree ct1 (built= 0).17.70.248.5(75) 48.5217.70135.3(55) 10.50.4013.3(40) 0(70) 13.30.604(45) 0Figure 7: Candidate decision tree ct2 (rebuilt= 1).4.2 Analysistime complexity optimistic approximation polynomial number candidatessince build decision tree every candidate separately.248fiD ECISION AKING DYNAMIC U NCERTAIN E VENTSTheorem 1 time complexity building decision trees optimistic approximationO(M 2 m2 ), number candidates maximal size among candidatetrees.Proof: evaluating candidate tree, must compute probability winningO(M ) nodes. node, perform summation O(M ) nodescandidate trees cost O(M 2 m). perform candidate trees. Thus,total cost algorithm O(M 2 m2 ). 2result compares favorably O(M ) optimal algorithm number candidateslarge. addition, due polynomial complexity due fact optimistic algorithm rebuilds decision trees update probabilities, easily update decision treenew dynamic events updated probabilities utilities. instance, assume time= 0 prediction interest rate increase time = 2 0.1% probability0.8 0.2% probability 0.2. time = 1 prediction may change, instance,0.15% probability 0.6 0.2% probability 0.4. Since optimistic algorithmrebuilds polynomial time decision trees easily consider updated probabilitiesvalues.show Procedure 2 returns stopping policy, optimal algorithm woulddecide same. algorithm waits, implies expected gain waiting greaterexpected gain stopping. case, optimal waiting expectation could lower.Theorem 2 Given global assignment , policy obtained Procedure 2optimal policy, ES( , ) = ES( , ) EW( , ) EW( , ).Proof: First prove ES( , ) = ES( , ). Procedure 2 calculates ES( , ) timestampstop nodes nx,i candidate trees cti time: ES( , ) =summingES ( , ). nodes relative expected gain stopping time and,i{1,...,m}according definition 14, GN (cti , nx,i )P r(ci wins|nx,i ). Since global assignmenttime known, exactly one candidate ci (the candidate highest expected gain time t)confirms P r(ci wins|nx,i ) = 1 others confirm P r(cj wins|nx,j ctj ) = 0. result,ES( , ) = GN (cti , nx,i ), ci candidate highest expected gain time t. Thus,ES( , ) = ES( , )., ). optimistic approach estimates expectedprove EW( , )EW(waiting EW( , ) sum EW ( , ). Since every decision tree ctiglobal assignment optimistic approach chooses policy maximizes EW ( , )(looks optimal time stop local assignment takes combinationutilities) independently candidate trees, possibility sum EW ( , )includes relative expected gain one candidate stopping specific time stamprelative expected gain another candidate waiting till time stamp + 1 globalassignment. Since relative expected gain optimal, EW( , ) EW( , ).2Corollary 1 Based last theorem, given policy obtained Procedure 2, ( ) = stop,optimal policy would decide same. optimistic policy decidesstop, ES( , ) > EW( , ). Then, based last theorem, EW( , ) EW( , )ES( , ) = ES( , ), thus ES( , ) > EW( , ), namely optimal policy declare249fiK ALECH & R ECHESstopping policy too. Therefore, optimistic approach guarantees optimal expected gainstopping.prove approximation error expected wait. Notice following theoremdiscuss error optimistic algorithm focuses worst case errorestimating waiting gain optimistic algorithm.Theorem 3 Given time horizon = (0, ..., h), policy obtained Procedure 2f 1policy obtained optimal algorithm, EW( 0 , ) EW( 0 , ) i=1EU(cti , ni ) +CST (h), ni root candidate tree cti , EU (cti , ni ) expected utility nodenij candidate tree cti f = in(m, h) (m number candidates).Proof: According optimistic approach, EW( , ) = EW ( , ). Since expectedwait candidate EW ( , ) computed independently, global expected wait EW( , )may include, specific assignment, stopping gain one candidate waiting gainanother candidate simultaneously (even though combination impossible).worst case scenario, whereby EW( , ) highest value occurs timestamp, exactly one local policy ( ) = stop. situation, expected wait sumexpected stop different time stamps f candidates, f = in(m, h). Thus, (1)EW( , ) fi=1 EU(cti , ni ), ni root candidate tree cti . Now, EW( , )EU(ctj , nj ) CST (h) EU (ctj , nj ) highest expected utility among rootscandidate trees. Thus, (2) EW( , ) EU(cti , nj ) + CST (h) result, summing1(1) (2), EW( , ) EW( , ) fi=1EU(cti , ni ) + CST (h). particular, = 0:1EW( 0 , ) EW( 0 , ) fi=1EU (cti , ni ) + CST (h). 2Finally, prove approximation error global expected gain. actually costwaiting till level lh1 , lh last level.Theorem 4 Given time horizon = (0, ..., h), policy obtained Procedure 2,a cost functionCST (t), set candidate trees CT , global assignment optimal policy , globalexpected gain GEG holds: GEG(CT, 0 , ) GEG(CT, 0 , ) CST (h 1).Proof: According Corollary 1, Procedure 2 guarantees optimal policy ( ) = stop.result, error obtained ( ) = wait ( ) = stop. Sincewaiting next time stamp decreases uncertainty, error cost waiting.worst case scenario, Procedure 2 may wait last time stamp optimal policywould stop immediately. However, policy obtained Procedure 2 time h 1 optimal,GEG(CT, h1 , ) = GEG(CT, h1 , ). reason behind valueEW( h1 , ) considers local policies ( h1 ) = wait, estimated expected waitpolicy, sum local expected wait, optimal, since includerelative gain waiting stopping assignment.result, absolute approximation error GEG(CT, 0 , ) GEG(CT s, 0 , ) <CST (h 1).25. Pessimistic Approachsection present alternative approximation algorithm which, contrast former,presents pessimistic approach. algorithm considers expected utility time stamp250fiD ECISION AKING DYNAMIC U NCERTAIN E VENTSseparately. result, avoid exponential complexity optimal algorithm considers possible combinations waiting stopping time stamp.5.1 PESSIMISTIC Algorithmapproximation gain calculated united decision tree. approach mergecandidate utility functions single decision tree, level tree represents timestamp associated timed variable, i.e., level li tree represents time point tidecide whether stop wait. decision tree two nodes level:Stop node, decision maker stops chooses one candidates. stop node, ES ,expected utility stopping level li .Wait node, decision maker decides wait. wait node, EW , expected utilitywaiting next time level. maximum stop node waitnode level li+1 .approximate solution time stamp compute expected utility stopping(ES ) level. stopping, optimal choice candidate highest expectedutility. compute expected utility stopping (ES ) optimally, compute expectedutility winning candidate possible assignment multiply probabilityassignment. brute force approach consider combinations assignmentstimed variables one return product winners expected utilityprobability assignment. approach obviously exponential number candidatessince size assignment combinations exponentially affected number candidates.Alternatively, relax time complexity sorting expected utilities candidate. way easily find winner multiply expected utility probabilitiesassignments candidates lower expected utility. Since expected utilitiessorted, computation linear number candidates. Theorem 5 analyzetime complexity detail.describe calculation Algorithm 2, use definition N ODES (see Definition8). algorithm obtains time set candidate trees CT returns expected utilitystopping time. one candidate trees, lines 811 sort nodes timesless equal (N ODEStj ) according expected utility. sorting done inverseorder ordered nodes inserted array sj []. arrays added set S. orderiterate arrays, initiate pointers arrays; indx[] contains pointers arrays,indx[j] contains pointer array sj []. pointers initiated point first nodecorresponding array (lines 1214). main loop (lines 1519), find nodehighest expected utility among nodes pointed at. compute probability winning,multiply probability lower probabilities nodes candidates.Namely, one candidate trees, sum probabilities nodeslower expected utility winner (line 17) multiply summation probabilitynode currently wins. sum probabilities array candidate ci (si [])lower cj actually probability cj greater ci thus probabilitybeat it. Since arrays sorted, summation actually done current pointerend arrays. follows law total probability. Finally, line 18, increment251fiK ALECH & R ECHESAlgorithm 2 EXPECTED STOPPING(input: time t)(input: candidate trees CT = {ct1 , ..., ctm })output: expected stopping ES( , )1:2:3:4:5:6:7:8:9:10:11:12:13:14:15:16:17:Internal variables:indx[m]i1j1exp 0bestctj CTjsj [] sortN ODESt inverse ordersj []endjindx[j] 1endj m, indx[j] reach end sj []best k, k confirmssk [indx[k]] si [indx[i]] {1, ..., m}expexp+EU (ctbest , sbest [indx[best]])|si []|PrPTH(ct,[k])i=bestk=indx[i]18:indx[best] indx[best] + 119: end20: return exp CST (t)s0=66.3P rPT H(ctbest , sbest [indx[best]])w1=65.904s1=65.1w1=65.904s2=65.255w2=65.904s3=65.17w3=65.904s4=65.904Figure 8: Pessimistic approach: decision tree based ct1 ct2 .pointer local winner next node find winner next iteration. continueloop one candidate nodes scanned. case, unscanned utilitiesarrays less last utility array completely scanned. line20 function subtracts cost waiting exp. algorithm demonstratednet page.next procedure describes pessimistic decision tree time stamp t. tree rebuilttime stamp. invoked first time 0:Procedure 3 Pessimistic:252fiD ECISION AKING DYNAMIC U NCERTAIN E VENTS1. Generate decision tree bottom-up manner:ES {0, ..., h} computed basedAlgorithm 2. Then, EW h1 equal ES h EW {0, ..., h 2} maximumES i+1 EW i+1 . building iterates root time stamp t. Denote ESEW ES( , ) EW( , ) respectively.2. ES( , ) EW( , )then, = stop, return argmax ES ( , )i{1,...,m}else = wait.3. Prune candidate tree according global assignment tree rootednode reached local assignment invoke Procedure 3 time stamp + 1.Let us demonstrate approximate decision tree (Figure 8). Figure 1 Figure 2 representtwo candidate trees CST (t) = 1.2 t. generate decision tree bottom-up mannersince waiting node actually maximum nodes next level. last level l4 ,one node, ES 4 . order calculate expected utility stopping, use Algorithm2. N ODES41 = {n2,1 , n3,1 , n5,1 , n6,1 }, N ODES42 = {n2,2 , n3,2 , n5,2 , n6,2 }. Algorithm 2 sortssets s1 s2 : s1 = [80, 65, 60, 55], s2 = [75, 70, 45, 40]. first iteration (lines1519), pointer winner best = 1 since s1 [1] = 80 > s2 [1] = 75. Thus,exp = s1 [1] P rPT H(ct1 , n2,1 )(P rPT H(ct2 , n2,2 ) + P rPT H(ct2 , n3,2 )+P rPT H(ct2 , n5,2 ) + P rPT H(ct2 , n6,2 )) =80 (0.4 0.8) (0.3 0.8 + 0.7 0.4 + 0.7 0.6 + 0.3 0.2) = 25.6pointer s1 incremented point s1 [2]. next iteration, best = 2 since s2 [1] =75 > s1 [2] = 65. Thus,exp = exp + s2 [1] P rPT H(ct2 , n2,2 )(P rPT H(ct1 , n6,1 ) + P rPT H(ct1 , n5,1 ) + P rPT H(ct1 , n3,1 )) =exp + 75 (0.8 0.3) (0.6 0.1 + 0.6 0.9 + 0.4 0.2) =exp + 12.24 = 37.84Lastly, exp = 70.704 expected utility stopping ES 4 = 70.704 4.8 = 65.904.EW 3 = ES 4 , since wait node time t4 . Similarly, according Algorithm 2,calculate ES 3 based N ODES31 = {n2,1 , n3,1 , n4,1 }, N ODES32 = {n2,2 , n3,2 , n4,2 }: ES 3 =65.172. EW 2 = max(ES 3 , EW 3 ) = 65.904. complete decision tree presented Figure 8.runtime, decision maker decides wait stop according ES 0 EW 0 (in firstiteration = 0). agent decides stop ES 0 > EW 0 chooses candidatehighest expected utility. agent decides wait, several assignments occur.point decision tree needs recomputed several nodes become irrelevant.presented example agent decide stop time stamp = 0 since expected stop, ES 0 (66.3)higher expected wait EW 0 (65.904).5.2 AnalysisFirst, show time complexity pessimistic approach.253fiK ALECH & R ECHESTheorem 5 Given time horizon = (0, ..., h), time complexity building decision treepessimistic approximation O(h (m2 + mM log )), number candidatesmaximal size among candidate trees.Proof: time stamp ti , algorithm sorts nodes set N ODEStji candidate treectj . Since maximum number nodes N ODEStji , worst case complexity sortlog . Since perform sort candidate tree, complexity O(mM log ).compare sorted sets set S, algorithm goes candidates finds maximumamong pointed nodes candidates. computation m2 . algorithm stopsreaches end one candidates array (line 15). worst case . Finding P rPT Hnode calculated loop complexity mM log . Thus, worst casetime complexity Algorithm 2 O(m2 + mM log ). perform Algorithm 2 timestamp result time complexity O(h (m2 + mM log )).2Similar optimistic algorithm, pessimistic algorithm rebuilds decision treetime stamp polynomial time thus address changed additional timed variables.show Procedure 3 decides wait optimal algorithm would operate similarly.expected gain stopping greater expected gain waiting, Procedure 3returns stopping policy. case optimal policy could return waiting policy.Theorem 6 Given cost function CST (t), set candidate trees CT , global assignmentoptimal policy , policy taken Procedure 3 optimal policy , global expectedgain GEG holds: ES( , ) = ES( , ) EW( , ) EW( , ).Proof: time t, Algorithm 2 calculates expected gain stopping, ES( , ),summing possible assignment expected utility candidate highest value(the winner candidate) times probability assignment. Since time stamp sumprobabilities possible assignments 1, according law total probability (Beaver& Mendenhall, 1983), ES( , ) = ES( , ). waiting node maximumwait node stop node next time level. Therefore, algorithm takeconsideration combination waiting stopping different assignments. contrast,optimal policy algorithm considers combinations takes maximal valueassignment. Thus, value expected wait may higher result wait nodes valueless equal optimal expected gain waiting, EW( , ) EW( , ).2Corollary 2 Based last theorem, ( ) = wait, optimal policy would resultdecision. due fact policy obtained Procedure 3 ( ) =wait, EW( , ) > ES( , ). Based last theorem EW( , ) EW( , )ES( , ) = ES( , ), thus EW( , ) > ES( , ) therefore, policy decides wait.Consequently, pessimistic approach guarantees optimal expected gain waiting.prove approximation error expected wait.Theorem 7 Given time horizon = (0, ..., h), cost function CST (t), set candidate treesCT , global assignment global assignment , policy obtained Procedure3 policy obtained optimal algorithm, EW( , ) EW( , ) CST (h)CST (t + 1).254fiD ECISION AKING DYNAMIC U NCERTAIN E VENTSProof: optimal expected gain obtained stopping waiting specific timestamp expected gain waiting last time stamp h (where uncertainty) without considering cost waiting, ES( h , ) + [CST (h) CST (t)]. Thus,expected gain waiting time holds, (1) EW( , ) ES( h , )+[CST (h)CST (t+1)](since expected wait EW( , ) already includes cost waiting time time stamp+ 1). hand, wait nodes calculated maximum amongchildren since last level lh stop node, ES( h , ) EW( , ) thus,(2) EW( , ) ES( h , ). result, (by summing two inequalities (1) (2)),EW( , ) EW( , ) CST (h) CST (t + 1). 2Finally, prove approximation error global expected gain.Theorem 8 Given time horizon = (0, ..., h), policy taken Procedure 3 optimalpolicy , cost function CST (t), set candidate trees CT , global assignment holds:GEG(CT, 0 , ) GEG(CT, 0 , ) < CST (h) CST (1).Proof:According Corollary 2 , pessimistic policy optimal except assignment , ( ) = stop optimal policy holds ( ) = wait. case,GEG(CT, , ) = EW( , ) GEG(CT, , ) = ES( , ). ( ) = stop timestamp t, ES( , ) > EW( , ) according Theorem 7, EW( , ) EW( , )CST (h) CST (t + 1). Thus, EW( , ) ES( , ) CST (h) CST (t + 1).result, GEG(CT, , ) GEG(CT, , ) < CST (h) CST (t + 1). particular, t=0,GEG(CT, 0 , ) GEG(CT s, 0 , ) < CST (h) CST (1).26. Evaluationpresenting empirical evaluation, summarize theoretical analysis algorithmsTable 2.PolicyOPTIMALOPTIMISTICPESSIMISTIC#trees Complexitym-#candidates,M-size candidatetree1O(M )O(M 2 m2 )1O(m2 + mM log )Approximationerror GEG(h-max time horizon)0CST (h 1)CST (h) CST (1)Expected waitApproximation error EWoptimaloverestimateunderestimate0fi=1 EU (cti , ni ) + CST (h)CST (h) CST (t + 1)Table 2: Summary theoretical evaluation algorithms.three algorithms, OPTIMAL, OPTIMISTIC, PESSIMISTIC, based decisiontree approach. However, optimal pessimistic algorithms use single decisiontree merges candidates, optimistic algorithm implements decision trees, onecandidate tree. time complexity approximation error global expected gainpresented columns three four, respectively. fifth column presents evaluationexpected wait. Obviously, optimal algorithm computes expected wait optimally.optimistic algorithm overestimates expected wait thus waiting decision optimalsince real expected wait may less stop. pessimistic algorithm underestimatesexpected wait although waiting decision optimal, stopping decision sincereal expected wait may higher consequently optimal decision would wait. lastcolumn presents approximation error expected wait.255fiK ALECH & R ECHESshown table 2, error expected wait estimated optimistic algorithmmuch higher pessimistic algorithm. result estimate pessimisticperformances closer optimal algorithm situations. However, sinceexpected wait optimistic algorithm overestimated, may frequently choose waitobtain information thus case cost function increases moderately time,performance optimistic algorithm increase.6.1 Experimental Settingsexperimentally validated algorithm within systematic artificial framework inspiredstock market. varied number candidate stocks (230) time horizoneconomic events (15) (i.e., timed variables). ran combination 25 times. test,possible profits stocks (the utility) randomly selected uniform distributionrange [$10K . . . $100K]. Later present experiments additional distributions.ran scenario (of 25 tests) 25 random assignments timed variables. data pointgraphs average 625 tests (25 random utilities 25 random assignments).compared three algorithms (OPTIMAL, OPTIMISTIC PESSIMISTIC) four baseline algorithms:1. trivial stopping strategy; determining winning candidate beginning basedexpected utility (STOP).2. trivial waiting strategy; determining winning candidate end based full information (WAIT).3. algorithm stops middle (horizon/2) chooses best candidate basedexpected gain (MIDDLE).4. algorithm stops random time (RANDOM).compared algorithms using two metrics: (1) runtime, (2) outcome utility.runtime OPTIMAL runtime building decision tree; runtime approximations average runtime building decision trees level. normalize utility,divided utility gained omniscient decision maker cost. followingexperiments presented next sections apart presented Section 6.4 deal disjoint timed variables, namely, two candidate trees share timed variable. Notice that,using disjoint time variables, worst case scenario OPTIMAL since finding optimaltime stop requires taking consideration combinations timed variablescandidate trees. timed variables disjoint number comparisons exponentialnumber candidates (see Table 2).6.2 Effect Costcost function key factor selecting affective algorithm. examine factor,set simple cost function grows linearly time CST (t) = varied coefficienttime stamp (a) 0.01K 2.91K, jumps 0.15K. fixed numbercandidates horizon 5. STOP strategy, presented Figure 9, affected costsince stops time = 0 case. hand, utility WAIT, MIDDLE256fiD ECISION AKING DYNAMIC U NCERTAIN E VENTSOPTIMALOPTIMISTICPESSIMISTICWAITMIDDLERANDOMSTOPOPTIMISTICPESSIMISTICWAITMIDDLERANDOMSTOP1Depth percents1Normalized utilityOPTIMAL0.950.90.850.80.80.60.40.200.010.160.310.460.610.760.911.041.161.311.461.611.761.912.042.162.312.462.612.762.910.010.160.310.460.610.760.911.041.161.311.461.611.761.912.042.162.312.462.612.762.910.75Cost per time stamp (in thousands)Cost per time stamp (in thousands)Figure 9: Normalized utility cost Figure 10:time step, CST (t) = xK t. Time horizon 5 levelsnumber candidates 5.Depth decision costtime step, CST (t) = xK t. Time horizon 5 levelsnumber candidates 5.RANDOM, linearly decreases cost increases. Figure 10 shows OPTIMALapproximations make decision earlier cost increases since becomes less worthwhilewait. However, depth decision decreases faster OPTIMAL PESSIMISTICOPTIMISTIC. depth decision influences utility algorithms. interestingsee gap utility OPTIMISTIC PESSIMISTIC grows cost increases,similarly gap depth. explained fact OPTIMISTIC overestimatesexpected wait thus makes decision later loss cost significant.Nevertheless, cost = 2 approximations optimal algorithm stop time stamp 0achieve utility.OPTIMALOPTIMISTICPESSIMISTICWAITMIDDLERANDOMSTOPOPTIMISTICPESSIMISTICWAITMIDDLERANDOMSTOP0.96Normalized utilityNormalized utility1OPTIMAL0.950.90.850.80.950.940.930.920.752234#candidates56Figure 11: Normalizedutilitynumber candidates,CST (t) = 0.28K 3 timehorizon 5 levels.34#candidates56Figure 12: Normalized utility number candidates,CST (t) =0.28K 3 time horizon 5 levels: zoom utility range 0.920.96.ran experiments additional cost functions. Figures 11 13 presentnon3linear cost functions. cost Figure 11 increases moderately (CST (t) = 0.28K t)cost Figure 13 increases fast (CST (t) = 0.28K t2 ). show that, cost function257fiK ALECH & R ECHESOPTIMALOPTIMISTICPESSIMISTICWAITMIDDLERANDOMSTOPOPTIMISTICPESSIMISTICWAITMIDDLERANDOMSTOP0.97Normalized utility1Normalized utilityOPTIMAL0.950.90.850.80.750.960.950.940.930.920.91234#candidates561/7Figure 13: Normalized utility num- Figure 14:ber candidates, CST (t) =0.28K t2 time horizon 5 levels.1/61/51/41/31/2cost function: cost(t)=0.28k*t^x12Normalized utility cost function: cost(t) = 0.28K tx ,time horizon 5 levels numbercandidates 5.increases moderately (a root function), pessimistic algorithm becomes less effectiveOPTIMISTIC becomes better PESSIMISTIC. shown Figure 11 zoom-in viewFigure 12, functions OPTIMAL significantly better PESSIMISTICsituations better OPTIMISTIC (tested 95% confidence value).examine influence cost function algorithms, varied consistentlycost function. choose cost function cost(t) = 0.28K tx changing x range{ 17 , 16 , 15 , 14 , 13 , 21 , 1, 2}. Obviously, decreasing x function increases moderately. Figure14 presents results. clear shown OPTIMISTIC better PESSIMISTIC rootfunctions smaller square root. Then, cost function increases faster gapOPTIMISTIC PESSIMISTIC increases favor PESSIMISTIC.expected utility0.28K*t0.28K*t^(1/3)Averaged expected utility9.598.587.57012345TimeFigure 15: Averaged expected utility time, time horizon 5 levels number candidates 5.258fiD ECISION AKING DYNAMIC U NCERTAIN E VENTSexamine reason behavior approximations dependent cost function,observed growth averaged expected utility function time (Figure 15).x-axis time horizon y-axis averaged expected utility. Obviously, expectedutility increase time increases since events discovered uncertainty decreases.seems averaged expected utility grows moderately, approximately logarithmically,function time. addition averaged expected utility, present Figure 15 twocost functions. first linear cost function CST (t) = 0.28K t, pessimisticapproximation better, second root cost function CST (t) = 0.28K 3 t,optimistic approximation better. set cost functions start valueexpected utility y-axis. Figure 15 compares growth behavior twocost functions expected utility. comparison may explain fact costfunction grows linearly pessimistic algorithm, usually stops earlier, betteroptimistic algorithm, since cost function grows faster utility function. However,cost function grows moderately (a root function), meaning, cost function utilityfunction similar trend, optimistic algorithm, usually stops later, becomes better.rest experiments examine factors influence performancealgorithms. showed, difference algorithms root cost functionsmall thus might hard examine impact factors. Therefore, restexperiments use linear cost function fixing waiting cost events constantvalue $2.8K time stamp (CST (t) = 2.8K t).6.3 Effect Number Candidatespresent subset results time horizon 5 levels. Figure 16 presents utilitytest setting six candidates. Due memory limitations, optimal algorithm failed deallarger candidate sets. utility gained PESSIMISTIC close OPTIMALdifference significant. result much better results baselinealgorithms even better OPTIMISTIC.OPTIMALOPTIMISTICPESSIMISTICWAITMIDDLERANDOMSTOPRuntime (ms)Normalized utility10.950.90.850.80.75234#candidates56OPTIMALOPTIMISTICPESSIMISTICWAITMIDDLERANDOMSTOP1000010001001010.10.010.001234#candidates56Figure 16: Normalized utility 6 candidates Figure 17: Runtime 6 candidatestime horizon 5 levels.time horizon 5 levels.runtime presented logarithmic scale Figure 17. runtime algorithmspolynomial, except OPTIMAL, exponential. instance, average runtimeOPTIMAL six candidates 5836 milliseconds, algorithms lesstwo milliseconds.259fiK ALECH & R ECHEScompared algorithms, excluding optimal algorithm, larger sets 30candidates. utility PESSIMISTIC always significantly better others, shownFigure 18. may explained approximation error expected wait. comparingapproximation error two algorithms (see Table 2), clear approximation errorexpected wait OPTIMISTIC much greater PESSIMISTIC thus OPTIMISTIC expected make decision later PESSIMISTIC. Note statisticallysignificant difference OPTIMISTIC MIDDLE. Later present experimentslarger cost values horizon OPTIMISTIC much better MIDDLE.Although complexity PESSIMISTIC OPTIMISTIC polynomial, PESSIMISTIC better OPTIMISTIC terms runtime, shown Figure 19.justified complexity analysis algorithms, shown Table 2. OPTIMISTICsquare m, PESSIMISTIC square .illustrate significance results, consider instance stock market fivecandidate stocks. Based experiments, average utility optimal algorithm $92.8K,97.6% utility obtained omniscient decision maker. PESSIMISTICs utility is,average, less optimal amount $300, OPTIMISTIC reduces utilityamount $2, 800. Obviously, baseline algorithms reduce utility drastically. waitstrategy, instance, produces profit $80.5K.OPTIMISTICPESSIMISTICSTOPOPTIMISTICPESSIMISTICSTOPWAITMIDDLERANDOMWAITMIDDLERANDOM100.95Runtime (ms)Normalized utility10.90.850.810.10.010.0010.752468210 12 14 16 18 20 22 24 26 28 30#candidates46810 12 14 16 18 20 22 24 26 28 30#candidatesFigure 18: Normalized utility 30 candi- Figure 19: Runtime 30 candidatesdates time horizon 5 levels.time horizon 5 levels.6.4 Shared Timed Variablesprevious experiments run settings different candidates affectedtimed variable. next experiment show that, even different candidates affectedtimed variables, approximations achieve similar utility previously. generated candidate trees horizon 5 time stamps. set 50% variables affect multiplecandidates. Figures 20 21 present normalized utility 6 30 candidates.comparing results results without shared variables (Figures 16 18) seebaseline algorithms MIDDLE RANDOM significantly improve utility.statistically significant difference one algorithms without sharedvariables (tested 95% confidence value). reason improvement MIDDLERANDOM shared variables less uncertainty thus expected utilitiescandidates accurate. hand computation expected stopping260fiD ECISION AKING DYNAMIC U NCERTAIN E VENTSOPTIMALOPTIMISTICPESSIMISTICWAITMIDDLERANDOMSTOPPESSIMISTICSTOPWAITMIDDLERANDOM1Normalized utilityNormalized utility1OPTIMISTIC0.950.90.850.80.750.950.90.850.80.75234#candidates56246810 12 14 16 18 20 22 24 26 28 30#candidatesFigure 20: 50% Shared timed variables: Nor- Figure 21: 50% Shared timed variables: Normalized utility 6 candidatesmalized utility 30 candidatestime horizon 5 levels.time horizon 5 levels.approximation algorithms relies independence variables thus decreaseuncertainty improve results.also checked difference algorithms found statisticallysignificant difference OPTIMAL PESSIMISTIC. algorithms better OPTIMISTIC statistically significant difference OPTIMISTIC MIDDLE.results approximation algorithms significantly better baseline algorithms (tested 95% confidence value).analyzed Section 3, optimal algorithm addresses shared timed variables efficientlyfact reduces computational complexity. Figure 22 show runtime 50%shared timed variables. Compared Figure 17 see OPTIMAL runs two ordersmagnitude faster experiments shared timed variables.OPTIMALOPTIMISTICPESSIMISTICWAITMIDDLERANDOMSTOPOPTIMISTICPESSIMISTICWAITMIDDLERANDOMSTOP1Depth percents10Runtime (ms)OPTIMAL10.10.010.80.60.40.200.001234#candidates52634#candidates56Figure 22: 50% Shared timed variables: runtime Figure 23: Normalized depth 6 candidates6 candidates time horizontime horizon 5 levels.5 levels.6.5 Depth DecisionFigure 23 illustrates attributes PESSIMISTIC OPTIMISTIC algorithms runcandidate trees time horizon 5 levels. y-axis represents depth (in percentage261fiK ALECH & R ECHESrelative maximal horizon) algorithms stop decide. Figure 23 presentsresults candidate trees time horizon 5 levels. analyzed, PESSIMISTIC always stopsoptimal algorithm, since expected wait underestimated. OPTIMISTIC always stopsoptimal algorithm since overestimating expected wait continues wait, althoughoptimal algorithm decides stop.6.6 Effect HorizonOPTIMALOPTIMISTICPESSIMISTICWAITMIDDLERANDOMSTOPPESSIMISTICSTOPWAITMIDDLERANDOM1Normalized utilityNormalized Utility1OPTIMISTIC0.950.90.850.80.750.950.90.850.80.75123456Horizon789101357911 13 15 17 19 21 23 25 27 29HorizonFigure 24: Normalized utility horizon (1- Figure 25: Normalized utility horizon (130) number candidates 5.10) number candidates 5.Next examine influence horizon candidate trees utility. growcandidate trees large horizon, generated chain; tree every left branch leadsleaf every right branch leads another internal node. Thus, size candidate treegrows linearly horizon. experimental setting experiments includes 5 candidates. Figures 24, 26, 28 present results horizon 110 comparing algorithms.Since feasible run OPTIMAL larger horizon, ran rest algorithmshorizon 130 (see Figures 25, 27 29). shown Figures 24 25, utility dramatically affected horizon optimal, approximations stop algorithms. differentWAIT, MIDDLE RANDOM, lose constant cost every time stamp sinceintelligently compute stop. stop strategy affected horizon sincealways makes decision first time, thus see low horizon levels wait strategybetter, high levels stop strategy outperforms wait strategy well MIDDLERANDOM.Although chain topology candidate trees grows linearly horizon, runtimeOPTIMAL increases exponentially horizon, since level splits possible assignments candidates timed variables (Figure 26, runtime presented logarithmic scale).shown Figure 27, OPTIMISTIC PESSIMISTIC grow polynomially OPTIMISTICgrows faster. Naturally, relative depth decision OPTIMAL approximationsdecrease horizon, since cost function grows horizon thus less worthwhilewait information (Figure 28 29). Nevertheless, decision time converge0 since cost high, cost waiting time stamps may lessexpected utility. Obviously, discussed above, higher cost less wait. Note262fiOPTIMALOPTIMISTICPESSIMISTICWAITMIDDLERANDOMSTOPOPTIMISTICPESSIMISTICSTOPWAITMIDDLERANDOM1001000010001001010.10.010.001Runtime (ms)Runtime (ms)ECISION AKING DYNAMIC U NCERTAIN E VENTS1010.10.010.001123456Horizon789101357911 13 15 17 19 21 23 25 27 29HorizonFigure 26: Runtime horizon (1-10) Figure 27: Runtime horizon (1-30)number candidates 5.number candidates 5.OPTIMALOPTIMISTICPESSIMISTICWAITMIDDLERANDOMSTOPPESSIMISTICSTOPWAITMIDDLERANDOM1Depth percentsDepth percents1OPTIMISTIC0.80.60.40.200.80.60.40.20123456Horizon789101357911 13 15 17 19 21 23 25 27 29HorizonFigure 28: Depth decision horizon (1- Figure 29: Depth decision horizon (130) number candidates 5.10) number candidates 5.decrease OPTIMISTIC compared PESSIMISTIC moderate (Figure 29) sinceapproximation error expected wait OPTIMISTIC greater PESSIMISTIC.6.7 Effect Utility Distributionexperiments, simulated utilities taking uniform distribution.simulate varied range domains present additional results utilities takenBeta distribution symmetric asymmetric cases. Beta distribution = providessymmetric distribution. = 2 Beta distribution similar normal distribution definedinterval [0, 1] thus reflects distribution many real-world domains. largervalue = lower variance. Running experiments Beta distribution allows usexamine: (1) influence variance - controlling value = , (2) influenceskewness - setting fixed value varying .first experiment set = = 2 number candidates horizon 5.comparing results (Figure 31) results experiments uniform distribution (Figure16), see algorithms except WAIT, improve utility. explainedfact variance candidates utilities Beta distribution smallervariance uniform distribution, thus choosing non-optimal candidate, utility263fiK ALECH & R ECHESOPTIMALOPTIMISTICPESSIMISTICWAITMIDDLERANDOMSTOPNormalized utility10.950.90.850.80.752345#candidatesFigure 31: Utilities taken Beta distribution = 2 = 2Figure 30: Beta distribution = 2skewness=0. Normalized utility= 2.candidates time horizon 5levels 5 candidates.closer optimal candidate. Therefore, algorithm stops selects non-optimalcandidate, utility selection closer optimal (and higher) Beta distributionuniform distribution. also explains Beta distribution utility STOPhigher OPTIMISTIC, uniform distribution lower. also supporteddepth decision. decision made earlier Beta distribution uniformdistribution. utility WAIT strategy distributionsdecision made end optimal thus cost reduced,distributions.OPTIMALOPTIMISTICPESSIMISTICWAITMIDDLERANDOMSTOPNormalized utility10.950.90.850.80.75234value =56Figure 32: Utilities taken Beta distribution varied = . Normalized utilitycandidates time horizon 5 levels 5 candidates.examine insight run experiments varied range = 26. increasing variance decreased. Figure 32 presents average utility264fiD ECISION AKING DYNAMIC U NCERTAIN E VENTSexperiment. seems utility algorithms significantly influencedvariance. possible explanation tradeoff two trends. one hand, smallervariance utilities candidates, less difference utilities chosencandidate best candidate. hand, difference expected utilitycandidates, decreases variance, thus possibility selecting wrong candidateincreases. Consequently, probability error choosing best candidate increasespayoff error decreased thus utility significantly influenced variance.exception WAIT algorithm decreases variance. reason makesdecision end thus always chooses best candidate. However, since Betadistribution = symmetric distribution variance increases best utilitydecreases (close middle), hand, pays full cost waiting last timestamp.OPTIMALOPTIMISTICPESSIMISTICWAITMIDDLERANDOMSTOPNormalized utility10.950.90.850.80.752345#candidatesFigure 34: Utilities taken Beta distribution = 2 = 6Figure 33: Beta distribution = 2skewness=0.69. Normalized utility= 6.candidates time horizon5 levels 5 candidates.repeated experiments Beta distribution changing parametersdistribution first candidate = 6 = 2. difference influences skewnessdistribution (-0.69) gives high probability gaining higher values (Figure 33). Sinceparameters candidates remain ( = 2 = 2), skewness 0thus first candidate likely chosen. shown Figure 34, low skewness firstcandidate significantly increases utility algorithms. reason independentlystopping time, cases, expected utility first candidate highest thusselected algorithms. cost waiting reduces utility. insightsignificantly shown high utility STOP algorithm.experimented influence skewness algorithms. Figure 35presents normalized utility changing skewness first candidate. lowerskewness, likely first candidate chosen. increase utility algorithms clear since likely first candidate chosen, fewer errorschoosing best candidate.265fiK ALECH & R ECHESOPTIMALOPTIMISTICPESSIMISTICWAITMIDDLERANDOMSTOPNormalized utility10.950.90.850.80.750.00-0.29-0.47Skewness-0.60-0.69Figure 35: Utilities taken Beta distribution = 2 varied skewness.Normalized utility candidates time horizon 5 levels 5 candidates.6.8 Conclusionssummarize, conclusions experiments are:1. cost function increases moderately (a root function), PESSIMISTIC algorithm becomes less effective OPTIMISTIC becomes better PESSIMISTIC.2. utility PESSIMISTIC close OPTIMAL cases (for functionsgrow polynomially) statistically significant difference them.3. runtime OPTIMAL exponential actually feasible candidatessmall candidate trees.4. runtime approximations polynomial PESSIMISTIC runs much fasterOPTIMISTIC.5. statistically significant difference experiments include sharedtimed variable experiments include disjoint timed variables (except MIDDLE RANDOM).6. OPTIMAL runs much faster experiments include candidates shared timed variable.7. PESSIMISTIC strategy makes decision slightly earlier OPTIMAL.8. OPTIMISTIC strategy makes decision much later OPTIMAL. gap increasedincreasing horizon candidate trees cost waiting. largehorizon cost depth close time=0.9. cases (low horizon, high number agents, cost functions grow polynomiallyshared timed variables) MIDDLE better OPTIMISTIC algorithm.266fiD ECISION AKING DYNAMIC U NCERTAIN E VENTS10. greater expected utility one candidate higher others, greaterutility achieved different algorithms.11. normalized utilities achieved algorithms almost affected variancecandidates utilities. However, significant improvement achieved Beta distribution ( = 2) relation uniform distribution.7. Related Worksection discuss relation work research related optimalstoping problem explorationexploitation problems.7.1 Optimal Stopping Problemproblem related Optimal Stopping Problem (OSP). OSP goal choosetime take particular action order maximize expected reward (Ferguson, 1989; Gilboa& Schmeidler, 1989; Peskir & Shiryaev, 2006). classical stopping problem defined twoobjects: (i) sequence independent random variables, X1 , X2 , ... , known joint distribution, (ii) sequence real-valued reward functions, y0 , y1 (x1 ), y2 (x1 , x2 ), ...,.n = 1, 2, ..., observing X1 = x1 , X2 = x2 , ..., Xn = xn , agent may stop receiveknown reward, yn (x1 , ..., xn ), may continue observe Xn+1 . agent choosesmake observation, receive constant amount, y0 . Take example house-sellingproblem agent wishes sell house. day receives offer Xi . agentdecide either accept offer wait next offer. Waiting associated costliving. Offers assumed independent. goal get highest offer (Lippman &McCall, 1976).class problems seems similar problem, since address problem finding best time stop. However, deeper perspective, three significantdifferences problems:(1) Stopping reward: OSP, agent decide whether stop obtain knownreward, based prior random variables wait next time stamp observenext random variable. agent chooses stop, make observation, receiveconstant reward dependent random variables. contrast OSP,model, utility (which considering waiting cost) candidate dependdecision stop wait, future events. Even gain solely dependentstopping time, since different future events influence gain differently. waiting decision enablesdecision maker acquire information reward candidate, althoughreward affected waiting decision. example house-selling problem, agentwishes sell house. day receives offer Xi . agent decide either acceptoffer wait next offer. decides stop accept offer obtains rewardoffer. reward affected future offers. model, hand,reward stopping depends future random variables. difference reward obviouslyaffects way approach maximizes reward. example, assume omniscient agentknows outcomes variables advance; certainly stop time stamphighest value OSP. Contrastingly, problem, best time stop first time267fiK ALECH & R ECHESstamp since time agent knows exact utility candidates rather expectedutility.second aspect related independency stopping rewards. OSP, stoppingrewards time stamp assumed independent. example, house-sellingproblem, offers independent. problem, although variables independent,rewards stopping dependent. difference significant since, independencyassumption, stopping rule OSP depends probability agent stopcurrent time stamp multiplied probability stop now. model,hand, rewards stopping depend future random variables calculated takingexpected rewards candidates therefore dependent. result, ableuse OSP model solve problem vice versa.(2) Multiple candidates: OSP one reward observing X1 , X2 , ..., Xn .problem, hand, considers multiple candidates. result, candidate differentreward observing variables. two different challenges face: (1) findingbest time stop, (2) choosing candidate highest expected utility time.Although two different challenges, cannot treated two steps: finding besttime stop advance, time reached choosing candidate highestexpected utility time. approach would made challenge much simplerthus fact multiple candidates would insignificant. Nevertheless, problemcannot solved two separate steps since decision whether stop wait dependsassignments occur next time. Since candidate may affected differentassignments, consider combination assignments makes problemhard.(3) Joint distribution: classical stopping problem random variables knownjoint distribution. previous example, offers assumed knowndistribution thus case infinity convergence. problem different sinceconsiders random variables different distributions.last years several researchers generalized classical stopping problem orderdeal cases multiple distributions, i.e., multiple optimal stopping problems. Riedel (2009)presents unified general theory optimal stopping multiple priors discrete timeextends theory continuous time (da Rocha & Riedel, 2010; Cheng & Riedel, 2010).developed theory optimal stopping one joint distribution unknown distribution variables using extending suitable results martingale theory (Williams,1991). Still two differences (Stopping reward, Multiple candidates) specified above, maintain. addition, Riedel presents specific constraints random variables consideringMartingale theory assuming set stopping rewards time-consistent (Cheridito& Stadje, 2009). contrast, work distribution variables known advancerequire specific constraints random variables.three differences demonstrate spite similarity problem OSP,two models comparable cannot reduced other.7.2 ExplorationExploitation Problemsaddition classical stopping problem, also consider subset familyexplorationexploitation problems kind stopping problem. problems agent268fiD ECISION AKING DYNAMIC U NCERTAIN E VENTSdecide stop acquiring information (exploration) specific issue makedecision (exploitation). Sequential hypothesis testing method based statisticaltests. method enables stopping rule defined soon significant results observed.method based mainly uncertain information, using multiple observations samples.instance, Wald Woldforwitz (1948) present problem chance variable, Xs distribution, either p0 (X) p1 (X). required decision choose twooptions based acquired observations variable. research goal obviously, makedecision minimal number observations.multi-armed bandit problem (Katehakis & Veinott, 1987) agent allocates trialsslot machines machine provides random reward distribution specificmachine. objective allocate trials slot machines order maximize expectedreward using machines. One version multi armed bandit relevantresearch Max K-Armed Bandit. Max K-Armed Bandit problem (Cicirello &Smith, 2005; Streeter & Smith, 2006) objective allocate trials K arms orderidentify best arm. Cicirello Smith (2005) extend problem agent runs trialsrepeatedly, trial tries improve reward achieved thus far.Similarly, ranking selection problem agent supposed select alternativeamong several options. demonstrate problem, Powell Ryzhov present following example (Powell & Ryzhov, 2012): physician choose type drug among several medicinesreduces cholesterol patient,. order decide best drug might requiremaking physical experiments might need run number medical laboratory simulations. Testing alternative might involve running time-consuming computer simulation,require physical experiment. Obviously, experimental process costly thus challengeallocate experiments efficiently accurately make selection. Usuallylimited budget evaluating alternatives budget exhausted, agentchoose alternative appears best, according obtained knowledge (Swisher,Jacobson, & Yucesan, 2003). Frazier Powell (2008) present version problemprior information units new obtained information units alternative sampledspecific distribution unknown mean variance. model provides new heuristicsampling stopping rule relies distribution samples.additional problem statistical analysis change detection tries identify changeparameters stochastic system. changes probability distributionstochastic process time series (Basseville & Nikiforov, 1993). general, problem concernsdetecting whether change occurred (several changes also might occur), identifying time change. model decide stop obtaining observationsfind closest time stamp distribution changed. problem worksdetect disorder time quickly possible happens minimize rate false alarmstime (Dayanik, Poor, & Sezer, 2007).Another problem decision making concerning multiple observations informativeexpensive. challenge decision making problems decide variables observe order maximize expected utility. Krause Guestrin studied problemdomain sensor placement consider sensor network utility sensor determined certainty measured quantity. task efficiently select informative subsets observations. Specifically, propose optimal nonmyopic value informationchain graphical models (Krause & Guestrin, 2009). Bilgic Getoor (2011) address similar269fiK ALECH & R ECHESproblem efficiently acquiring classification features domains costs associatedacquisition. objective minimize sum information acquisition cost.propose data structure known value information lattice (VOILA). VOILA exploits dependencies missing features, making possible share information value computationsdifferent feature subsets.Similarly, another work (Tolpin & Shimoni, 2010; Radovilsky & Shimoni, 2010) dealsselection uncertainty develops algorithms based value information (VOI)semi-myopic approximation scheme problems real-valued utilities. particular, TolpinShimoni (2010) interpret VOI expected difference expected utility meta-levelaction expected utility current base-level action. Radovilsky Shimoni (2010) dealoptimizing selection set observations. aim bring objective functionoptimum taking consideration cost observation remaining uncertaintyexecuting observation.Recently, Chen et al. (2014) proposed use computation Same-decision Probability(SDP) order compute whether additional information gathered. particular,compute stopping criterion computing SDP, SDP probability decisionmade even observations. information gathered proposepieces information gather next.work also related, aspects, Horvitzs work (2001, 2013) decision makingbounded resources. execution task associated utility cost, dependingresources. resources bounded, question stopping point bestwill, part, satisfy task. Horvitz presents use expected value computationdetermine best time stop. Similarly, monitoring anytime algorithms (Boddy & Dean,1994; Zilberstein, 1996; Zhang, 2001) search best possible answer constraintlimited time and/or resources. major question arises utilizing class algorithmsoptimally decide stop. instance, Finkelstein Markovitch (2001) developedalgorithms design optimal query schedule detect given goal fulfilled.aim minimize number queries (which time consuming) reach goal.joint objective works maximize goal function considering costobservations/acquisition/actions extent uncertainty. also attempt maximizeutility choosing best candidate consider cost uncertainty timedvariables. However, work differs works two significant aspects:1. Time variables: previous studies change detection problemK-Armed bandit problem consider set observations without considering order.works consider time observations. work variables associatedtime selection dynamically determined according time progress outcomesprevious variables. point important due fact candidates may influenced disjoint variables. cannot order variables according time select subsetvariables since available variables time depend assignment time 1. Thus,decision whether stop wait depends assignments occur next time period.Since candidate may affected different assignments consider combinationassignments complicates problem makes dissimilar previous work.2. Finite small horizon: model utility candidate affected finitesmall set discrete random variables. result, decision maker actually achieve absoluteinformation optimal choice waiting last time stamp. last time stamp,270fiD ECISION AKING DYNAMIC U NCERTAIN E VENTScomplete knowledge assignments random variables exploreexact value utility. Due cost information research problem modeldetermine optimal time make decision reaching end. related research,hand, basic assumption partial information obtained thusimpossible compute exact utility candidate. obtained information containsobservations samples different alternatives help decision makerstatistically approximate utility distribution different alternatives. potential populationobservations may infinite large thus impossible practice obtaininformation necessary compute exact utility. research problem modelsthus use statistical methods decide required information different alternatives.8. Summary Future Workpaper presented problem decision making among multiple candidatesinformation arrives dynamically. focused question stop make decisionmaximizes utility taking consideration cost waiting. presented threealgorithms; optimal algorithm exponential number candidates two alternativepolynomial approximation algorithms. proved one approximation algorithm optimistic.Namely computation expected utility waiting equal to, higher than, expectedutility computed optimal algorithm, algorithm pessimistic thus stopsearlier. empirical evaluation algorithms showed cost function much influencesresults. cost function increases moderately (a root function), PESSIMISTICalgorithm becomes less effective OPTIMISTIC becomes better PESSIMISTIC.polynomial cost functions significant difference outcome utilityoptimal algorithm pessimistic algorithm. also illustrated exponential growthoptimal algorithm polynomial growth optimistic pessimistic algorithms.future plan continue two directions: 1) work assumed discrete variables, however practice, variables may continuous. One option solving problemdiscretize variables, however, lose optimality. plan find optimal way address question, 2) plan investigate problem presentedpaper domains involving multi-agent decision making. domains multiple agentsshare decision based different variables utilities. multi-agent versionapproximation grows exponentially number agents thus plan reducecomplexity.Appendix A. TDM problem NP-hardProof: present reduction 3-SAT problem (Cook, 1971). instance 3-SATgiven propositional logic formula (z1 , ..., zn ) = 1 ... k , clausedisjunction exactly three literals. aim answer yes assignmentBoolean variables z1 , ..., zn satisfies formula. construct instance DMfollows.1. Boolean variable zi create timed variable Xi .271fiK ALECH & R ECHESFigure 36: Structure candidate trees accordance next 3-SAT formula:(z1 , z2 , z3 , z4 ) = (z1 z2 z3 ) (z1 z3 z4 ) (z1 z2 z4 ).2. every clause j j {1, ..., k} create candidate tree ctj three timedvariables:Xj1 , Xj2 Xj3 , corresponding variables clause. example,clause j = (z1 z4 z5 ) create candidate tree ctj variables: X1 , X4X5 .3. root candidate tree ctj includes additional timed variable Yj , time stamp(Yj ) = 1 three possible assignments. probability assignment 13one assignments leads one timed variables:Xj1 , Xj2 Xj3 .4. Every timed variable Xi corresponds literal zi two possible assignmentsXi = 1 utility > 0 Xi = 0 utility 2a, probability 0.5(Xi ) = 2. timed variable corresponding literal zi also two possibleassignments Xi = 1 utility 2a > 0 Xi = 0 utility a, oneprobability 0.5 (Xi ) = 2.Figure 36 presents example structure candidate trees accordance 3SAT formula. left outgoing edge random variable Xi represents assignment Xi = 1right outgoing edge represents assignment Xi = 0.5. set time horizon = [0, 2].6. set cost function be: CST (t) = 0.1 t.7. set constant C C = 1.8a.prove exists policy global expected gain GEG(CT, 0 , )C, (x1 , ..., xn ) satisfiable.expected utility stopping time = 0 well = 1 exactly 3a2 lessC. highest expected utility 2a obtained waiting time stamp 2.expected gain less equal 1.8a (after considering cost waiting). Therefore,rest proof consider waiting policy waits time stamp 2.1. guarantee GEG(CT, 0 , ) C time stamp 2, must confirm assignmentcombination trees branches, least one candidate tree utility2a.272fiD ECISION AKING DYNAMIC U NCERTAIN E VENTS2. construction, may happens assignments least onecandidate tree utilities 2a.3. construction, candidate trees assignment guarantees utility 2a entailsleast one false clause, meaning literals clause obtain 0 result (z1 , ..., zn )satisfiable.result obtain Timed Decision Making (TDM) NP-hard.2ReferencesBasseville, M., & Nikiforov, I. V. (1993). Detection abrupt changes: theory application.Prentice-Hall, Inc., Upper Saddle River, NJ, USA.Beaver, B. M., & Mendenhall, W. (1983). Introduction probability statistics, sixth edition,William Mendenhall, study guide. Statistics Series. Duxbury Press.Bilgic, M., & Getoor, L. (2011). Value information lattice: Exploiting probabilistic independenceeffective feature subset acquisition. Journal Artificial Intelligence Research (JAIR), 41,6995.Boddy, M., & Dean, T. L. (1994). Deliberation scheduling problem solving time-constrainedenvironments. Artificial Intelligence, 67(2), 245285.Boutilier, C., Dearden, R., & Goldszmidt, M. (2000). Stochastic dynamic programming factored representations. Artificial Intelligence, 121, 49107.Chen, S. J., Choi, A., & Darwiche, A. (2014). Algorithms applications same-decisionprobability. Journal Artificial Intelligence Research (JAIR), 49, 601633.Cheng, X., & Riedel, F. (2010). Optimal stopping ambiguity continuous time. Workingpapers 429, Bielefeld University, Institute Mathematical Economics.Cheridito, P., & Stadje, M. (2009). Time-inconsistency var time-consistent alternatives.Finance Research Letters, 6(1), 4046.Cicirello, V. A., & Smith, S. F. (2005). max k-armed bandit: new model explorationapplied search heuristic selection. Veloso, M. M., & Kambhampati, S. (Eds.), AAAI, pp.13551361.Cook, S. A. (1971). complexity theorem-proving procedures. STOC 71: Proceedingsthird annual ACM symposium Theory computing, pp. 151158, New York, NY,USA. ACM.da Rocha, V. F. M., & Riedel, F. (2010). equilibrium prices continuous time. JournalEconomic Theory, 145(3), 10861112.Dayanik, S., Poor, H. V., & Sezer, S. O. (2007). Multisource bayesian sequential change detection.CoRR, abs/0708.0224.Ferguson, T. S. (1989). solved secretary problem?. Statistical Science, 4(3), 282289.Finkelstein, L., & Markovitch, S. (2001). Optimal schedules monitoring anytime algorithms.Artificial Intelligence, 126, 63108.273fiK ALECH & R ECHESFrazier, P., & Powell, W. (2008). knowledge-gradient stopping rule ranking selection.Simulation Conference, 2008. WSC 2008. Winter, pp. 305312.Gilboa, I., & Schmeidler, D. (1989). Maxmin expected utility non-unique prior. JournalMathematical Economics, 18(2), 141153.Guestrin, C., Koller, D., Parr, R., & Venkataraman, S. (2003). Efficient solution algorithmsfactored MDPs. Journal Artificial Intelligence Research (JAIR), 19, 399468.Horvitz, E. (2001). Principles applications continual computation. Artificial Intelligence,126, 1261.Horvitz, E. (2013). Reasoning beliefs actions computational resource constraints.CoRR, abs/1304.2759.Kalech, M., & Pfeffer, A. (2010). Decision making dynamically arriving information.van der Hoek, W., Kaminka, G. A., Lesperance, Y., Luck, M., & Sen, S. (Eds.), AAMAS, pp.267274.Katehakis, M., & Veinott, J. A. (1987). multi-armed bandit problem: decomposition computation. Mathematics Operations Research, 12(2), 262268.Krause, A., & Guestrin, C. (2009). Optimal value information graphical models. JournalArtificial Intelligence Research (JAIR), 35, 557591.Lippman, S. A., & McCall, J. J. (1976). economics job search: survey. Economic Inquiry,14(3), 155189.Peskir, G., & Shiryaev, A. (2006). Optimal Stopping Free-Boundary Problems. BirkhauserBasel.Powell, W., & Ryzhov, I. (2012). Optimal Learning. Wiley Series Probability Statistics.Wiley.Radovilsky, Y., & Shimoni, S. E. (2010). Observation subset selection optimization uncertainty. Tech. rep., Lynne William Frankel Center Computer Science Ben GurionUniversity Negev.Reches, S., Kalech, M., & Stern, R. (2011). stop? question. Burgard, W., &Roth, D. (Eds.), AAAI. AAAI Press.Riedel, F. (2009). Optimal stopping multiple priors. Econometrica, 77(3), 857908.Streeter, M. J., & Smith, S. F. (2006). asymptotically optimal algorithm max k-armedbandit problem. AAAI, pp. 135142. AAAI Press.Swisher, J. R., Jacobson, S. H., & Yucesan, E. (2003). Discrete-event simulation optimizationusing ranking, selection, multiple comparison procedures: survey. ACM Trans. Model.Comput. Simul., 13(2), 134154.Tolpin, D., & Shimoni, S. E. (2010). Semi-myopic observation selection optimizationuncertainty. Tech. rep. 10-01, Lynne William Frankel Center Computer ScienceBen Gurion University Negev.Wald, A., & Wolfowitz, J. (1948). Optimum Character Sequential Probability Ratio Test.Annals Mathematical Statistics, 19(3), 326339.274fiD ECISION AKING DYNAMIC U NCERTAIN E VENTSWilliams, D. (1991). Probability Martingales. Cambridge mathematical textbooks. CambridgeUniversity Press.Zhang, W. (2001). Iterative state-space reduction flexible computation. Artificial Intelligence,126(1-2), 109138.Zilberstein, S. (1996). Using anytime algorithms intelligent systems. AI Magazine, 17(3), 7383.275fiJournal Artificial Intelligence Research 54 (2015) 493-534Submitted 05/15; published 12/15Possible Necessary Winners Partial TournamentsHaris Azizharis.aziz@nicta.com.auData61 University New South WalesAustraliaMarkus Brillbrill@cs.duke.eduComputer Science DepartmentDuke University, USAFelix Fischerfischerf@math.tu-berlin.deInstitut fur MathematikTechnische Universitat Berlin, GermanyPaul Harrensteinpaul.harrenstein@cs.ox.ac.ukComputer Science DepartmentUniversity Oxford, UKJerome Langlang@lamsade.dauphine.frLAMSADEUniversite Paris-Dauphine, FranceHans Georg Seedigseedigh@in.tum.deInstitut fur InformatikTechnische Universitat Munchen, GermanyAbstractstudy problem computing possible necessary winners partially specified weighted unweighted tournaments. problem arises naturally electionsincompletely specified votes, partially completed sports competitions, generallyscenario outcome pairwise comparisons yet fully known.specifically consider number well-known solution conceptsincluding uncovered set, Borda, ranked pairs, maximinand show them, possiblenecessary winners identified polynomial time. positive algorithmic resultsstand sharp contrast earlier results concerning possible necessary winners givenpartially specified preference profiles.1. IntroductionMany multi-agent situations modeled analyzed using weighted unweightedtournaments. Prime examples voting scenarios pairwise comparisonsalternatives decided majority rule sports competitions organizedround-robin tournaments. application areas include webpage journal ranking,biology, psychology, AI. generally, tournaments solution concepts tournaments used mathematical tool analysis kinds situationschoice among set alternatives made exclusively basis pairwisecomparisons.choosing tournament, relevant information may partly available.could preferences yet elicited, matches yet played,c2015AI Access Foundation. rights reserved.fiAziz, Brill, Fischer, Harrenstein, Lang, & Seedigcertain comparisons yet made. cases, natural speculatepotential inevitable outcomes basis information already hand.tournaments, number attractive solution concepts proposed (Brandt,Brill, & Harrenstein, 2016; Laslier, 1997). Given solution concept S, definepossible winners partial tournament G alternatives selectedcompletion G, necessary winners alternatives selected completions.completion understand (complete) tournament extending G.article address computational complexity identifying possiblenecessary winners number solution concepts whose winner determination problem tournaments tractable. consider five common solution conceptstournamentsnamely, Condorcet winners (COND), Condorcet non-losers (CNL),Copeland set (CO), top cycle (TC ), uncovered set (UC )and three commonsolutions weighted tournamentsBorda (BO), maximin (MM ), ranked pairs (RP ).solution concepts, consider computational complexity following problems: deciding whether given alternative possible winner (PW), decidingwhether given alternative necessary winner (NW), well deciding whethergiven subset alternatives equals set winners (the winning set) completion (PWS). problems challenging, even unweighted partial tournamentsmay allow exponential number completions. results encouraging,sense problems solved polynomial time. Table 1 summarizesfindings.Similar problems considered before. Condorcet winners, voting treestop cycle, shown possible necessary winners computablepolynomial time (Konczak & Lang, 2005; Lang et al., 2012). holdscomputation possible Copeland winners, problem consideredcontext sports tournaments (Cook, Cunningham, Pulleyblank, & Schrijver, 1998).Another specific setting also frequently considered within area computational social choice differs setting subtle important wayworth pointed out. There, tournaments assumed arise pairwise majoritycomparisons basis profile individual voters preferences.1Since partial preference profile R need conclusively settle every majority comparison, may give rise partial tournament only. two natural ways definepossible necessary winners partial preference profile R solution conceptillustrated Figure 1. first consider completions R winnerscorresponding tournaments. secondcovered general settingisconsider completions partial tournament G(R) corresponding Rwinners these. Since every tournament corresponding completion Ralso completion G(R) necessarily way round, second definition1. See, e.g., work Baumeister Rothe (2010), Betzler Dorn (2010), Konczak Lang (2005),Walsh (2007), Xia Conitzer (2011) basic setting, Betzler, Hemmann, Niedermeier(2009) parameterized complexity results, Bachrach, Betzler, Faliszewski (2010), Hazon, Aumann,Kraus, Wooldridge (2012), Kalech, Kraus, Kaminka, Goldman (2011) probabilisticsettings, Chevaleyre, Lang, Maudet, Monnot (2011) Chevaleyre, Lang, Maudet, Monnot,Xia (2012) settings variable set alternatives, Baumeister, Faliszewski, Lang, Rothe(2012), Kalech et al. (2011), Lu Boutilier (2011), Oren, Filmus, Boutilier (2013), FilmusOren (2014) settings truncated ballots Lu Boutilier (2013) multiwinner rules.494fiPossible Necessary Winners Partial TournamentsPWSCONDCNLCOTCUCBOMMRPP (Thm. 8)aP (Thm. 11)aNP-C (Thm. 14)PPPPPNWS(Konczak & Lang, 2005)(Thm. 2)(Cook et al., 1998)a(Lang et al., 2012)a(Thm. 5)PPPPPPWSS(Konczak & Lang, 2005) P(Thm. 2)P(Thm. 3)aP(Lang et al., 2012)P(Thm. 6)NP-CP(Thm. 10)P(Thm. 13)coNP-C (Thm. 15)(Thm.(Thm.(Thm.(Thm.(Thm.1)2)3)4)7)P (Thm. 9)P (Thm. 12)NP-C (Cor. 2)P-time result contrasts intractability problem partial preferenceprofiles (Lang et al., 2012; Xia & Conitzer, 2011).Table 1: Complexity computing possible winners (PW) necessary winners (NW)checking whether given subset alternatives possible winning set (PWS)following solution concepts: Condorcet winners (COND), Condorcet non-losers (CNL),Copeland (CO), top cycle (TC ), uncovered set (UC ), Borda (BO), maximin (MM ),ranked pairs (RP ).gives rise stronger notion possible winner weaker notion necessary winner. Interestingly, sharp contrast results, determining stronger possibleweaker necessary winners computationally hard many voting rules (Lang et al.,2012; Xia & Conitzer, 2011). contrast foreshadowed work Lang etal. (2012) Pini, Rossi, Venable, Walsh (2011), compared two waysdefining possible necessary winners (both theoretically experimentally) threesolution concepts: Condorcet winners, voting trees, top cycle.context article, assume tournaments arise majoritycomparisons voting specific procedure. approach numberadvantages. Firstly, matches diversity settings solution conceptstournaments applicable, goes well beyond social choice voting. instance,results also apply question commonly encountered sports competitions, namely,teams still win cup future results depends (Cook et al.,1998; Kern & Paulusma, 2004; B. L. Schwartz, 1966). Secondly, (partial) tournamentsprovide informationally sustainable way representing relevant aspects manysituations maintaining workable level abstraction conciseness. instance,social choice setting described above, partial tournament induced partialpreference profile much succinct piece information, discloses less information, preference profile itself. generally, gives canonical way extendingtournament solutions incomplete tournaments (a line pursued Brandt,Brill, & Harrenstein, 2014). Finally, specific settings may impose restrictions feasibleextensions partial tournaments. positive algorithmic results articleused efficiently approximate sets possible necessary winners settings,corresponding problems may intractable. voting setting discussedserves illustrate point.also point computing possible outcomes considered domains social choice example matching allocations (Aziz, Walsh, & Xia, 2015;495fiAziz, Brill, Fischer, Harrenstein, Lang, & Seedig1 1 1cb bbccompletionscompletions1 1 1cb b bc c1 1 11 1 1cb b cc bcbbc cb bc bbcbcbccFigure 1: non-commutative diagram illustrates two approaches possiblenecessary winners partial preference profiles majoritarian social choice functions.First, completions partial profile full preference profiles shownbottom left. corresponding majority tournaments dashed box bottomright. work, start partial majority tournament top rightinduced partial preference profile. Then, consider possible completionstournaments depicted solid box bottom right.Rastegari, Condon, Immorlica, & Leyton-Brown, 2013) knockout tournaments (Azizet al., 2014; Vu, Altman, & Shoham, 2009).2. Preliminariespartial tournament pair G = (V, E) V nonempty finite set alternativesE V V asymmetric relation V , i.e., (y, x)/ E whenever (x, y) E.(x, y) E say x dominates y. tournament partial tournament (V, E)E also complete, i.e., either (x, y) E (y, x) E distinct x, V .denote set tournaments .Let G = (V, E) partial tournament. Another partial tournament G0 = (V 0 , E 0 )called extension G, denoted G G0 , V = V 0 E E 0 . E 0 complete, G0called completion G. write [G] set completions G, i.e.,[G] = {T : G }.496fiPossible Necessary Winners Partial Tournamentssay alternative x V dominated (y, x) E V , undominated+otherwise. define dominion x G DG(x) = {y V : (x, y) E},+dominators x G DGS(x) = {y V : (y, x) E}. X V , let DG(X) =+(x)(X)=(x).nonemptysubsetXValternativesxXxXGGGpartial complete tournament (V, E) dominant every alternative X dominatesevery alternative outside X. given G = (V, E) X V , write E Xset edges obtained E adding missing edges alternatives Xalternatives X, i.e.,E X = E {(x, y) X V :/ X (y, x)/ E}.use E X abbreviation E V \X , write E x , E x , GX , GXE {x} , E {x} , (V, E X ), (V, E X ), respectively. G = (V, E) X V ,use E|X G|X denote restriction E(XX) E X restriction (X, E|X )G X, respectively.Let n positive integer. partial n-weighted tournament pair G = (V, w)consisting finite set V alternatives weight function w : V V {0, . . . , n}pair (x, y) V V x 6= y, w(x, y) + w(y, x) n. say= (V, w) n-weighted tournament x, V x 6= y, w(x, y) + w(y, x) = n.call (partial) weighted tournament (partial) n-weighted tournamentn N. class n-weighted tournaments denoted Tn . Observepartial 1-weighted tournament (V, w) associate partial tournament (V, E)setting E = {(x, y) V : w(x, y) = 1}. Thus, (partial) n-weighted tournaments seengeneralize (partial) tournaments, may identify T1 .notations G G0 [G] extended naturally partial n-weighted tournaments G = (V, w) G0 = (V 0 , w0 ) letting (V, w) (V 0 , w0 ) V = V 0w(x, y) w0 (x, y) x, V , [G] = {T Tn : G }.given G = (V, w) X V , define wX x, V ,wX(n w(y, x) x X/ X,(x, y) =w(x, y)otherwise,set wX = wV \X . Moreover, wx , wx , GX , GX defined obviousway.use term solution concept functions associate tournament = (V, E), weighted tournament = (V, w), choice set S(T ) V .2solution concept called resolute |S(T )| = 1 tournament . articleconsider following solution concepts: Condorcet winners (COND), Condorcet nonlosers (CNL), Copeland (CO), top cycle (TC ), uncovered set (UC ) tournaments,maximin (MM ), Borda (BO), ranked pairs (RP ) weighted tournaments.ranked pairs resolute. Formal definitions provided later article.2. avoid otherwise natural term tournament solution common definition requireschoice set nonempty (Laslier, 1997). would exclude COND.497fiAziz, Brill, Fischer, Harrenstein, Lang, & Seedig3. Possible Necessary Winnerssolution concept selects unique set alternatives complete tournament.holds particular completions partial tournament. However,completion partial tournament, solution concept may select another set alternatives. similar remark concerns weighted tournaments completions. givensolution concept S, thus define set possible winners partial (weighted)tournament G set alternatives selected completion G, i.e.,[S(T ).PWS (G) =[G]Analogously, set necessary winners G set alternatives selectedevery completion G, i.e.,\NWS (G) =S(T ).[G]furthermore writePWSS (G) = {S(T ) : [G]}possible winning sets, i.e., set sets alternatives selectsdifferent completions G. sake completeness, also mention necessary winningsets. set X necessary winning set partial tournament G X = S(T )[T ]. Accordingly, conditions set necessary winning setstrong satisfied relatively seldom. Necessary winning sets also straightforwardlycharacterized means sets possible necessary winners: X necessarywinning set X = PW (G) = NW (G). implies solutionconcepts addressed article, computational results surrounding necessary winningsets follow easy corollaries.3 consider necessary winning sets.Note NWS (G) may empty even selects nonempty set alternativestournament [G], number |PWSS (G)| possible winning sets mayexponential number alternatives G.following lemmas, relate useful structural propertiessets possible necessary winners. proofs straightforward thereforeomitted.Lemma 1. Let solution concept G G0 partial tournaments. Then,(i) G G0 implies PWS (G0 ) PWS (G),(ii) G G0 implies NWS (G) NWS (G0 ).say solution concept refines another solution concept 0 , denoted 0 ,S(G) 0 (G) G. find following monotonicity properties hold.3. Given results Table 1, fact X necessary winning set X = PW (G) =NW (G) immediately implies concepts apart ranked pairs deciding whether setnecessary winning set achieved polynomial time. Since ranked pairs resolute, every setNWSRP singleton {x} {x} PWSRP x NWRP . Consequently,problem deciding whether set X contained NWSRP coNP-complete.498fiPossible Necessary Winners Partial TournamentsLemma 2. Let 0 solution concepts G G0 partial tournaments. Then,(i) 0 implies PWS (G) PWS 0 (G),(ii) 0 implies NWS (G) NWS 0 (G).next lemma concerns way sets possible necessary winnersdefined terms one another.Lemma 3. Let solution concept G partial tournament. Then,(i) PWS (G) = GG0 NWS (G0 ),(ii) NWS (G) = GG0 PWS (G0 ).Observe that, 0 generally imply PWSS (G) PWSS 0 (G), followinghold:0 X PWSS (G) exists X 0 PWSS 0 (G) X X 0 .Deciding membership sets PWS (G), NWS (G), PWSS (G) given solutionconcept partial (weighted) tournament G natural computational problems.Overloading notation, refer problems PWS , NWS , PWSS , respectively.PWS (Possible Winners)Input:partial tournament G = (V, E) n-weighted partial tournamentG = (V, w) along positive integer n; alternative x V .Output: Yes, exists completion [G] x S(T ).No, otherwise.NWS (Necessary Winners)Input:partial tournament G = (V, E) n-weighted partial tournamentG = (V, w) along positive integer n; alternative x V .Output: Yes, x S(T ) completions [G].No, otherwise.PWSS (Possible Winning Set)Input:partial tournament G = (V, E) n-weighted partial tournamentG = (V, w) along positive integer n; subset alternativesX V.Output: Yes, exists completion [G] X = S(T ).No, otherwise.Note PWSS decided polynomial time, meanspolynomial-time algorithm decides whether given subset alternatives possible499fiAziz, Brill, Fischer, Harrenstein, Lang, & Seedigwinning set. Outputting set PWSS possible winning sets may much difficult,PWSS may exponential size.4irresolute solution concepts, PWSS may appear complex problemPWS . are, however, aware generic polynomial-time reduction PWSPWSS . relationship problems may also interestclassic possible winner setting partial preference profiles.complete tournaments [T ] = {T } thus PWS (T ) = NWS (T ) = S(T )PWSS (T ) = {S(T )}. consequence, solution concepts NP-hardwinner determination problemlike Banks, Slater, tournament equilibrium setproblems PWS , NWS , PWSS NP-hard well.5 therefore restrictattention solution concepts winners computed polynomial time.4. Unweighted Tournament Solutionssection, consider following well-known solution concepts unweighted tournaments: Condorcet winners, Condorcet non-losers, Copeland set, top cycle,uncovered set. use partial tournament depicted Figure 2(i ) runningexample.bbbccc(i ) Partial tournament G(ii ) Completion T1(iii ) Completion T2Figure 2: Example partial unweighted tournament G possible completions T1T2 . Initially, (dotted) edges pairs {a, b}, {b, c}, {c, d} yetspecified.4.1 Condorcet Winners Condorcet Non-losersCondorcet winners Condorcet non-losers fundamental solution conceptsprovide nice warm-up. alternative x V Condorcet winner complete tournament = (V, E) dominates alternatives, i.e., (x, y) E V \ {x}.set Condorcet winners tournament denoted COND(T ); obviouslyset always either singleton empty. alternative x Condorcet loserdominated every alternative, i.e., (y, x) E V \ {x}. Consequently,x Condorcet non-loser = (V, E) x Condorcet loser V = {x}.set Condorcet non-losers tournament denoted CNL(T ); obviouslyset always cardinality |V | |V | 1.4. instance, G = (V, ) PWS TC (G ) = {X V : |X| 6= 2}, even though PWSTC P(Theorem 4).5. exclude possibility computing (arbitrary) possible winner possible winningset solution concepts could done polynomial time.500fiPossible Necessary Winners Partial TournamentsLet G = (V, E) partial tournament. alternative x dominant G, xobviously Condorcet winner completions G. hand,V \ {x} case (x, y) E, completion G xCondorcet winner. Hence,x NWCOND (G) (x, y) E V \ {x}x PWCOND (G) (y, x) E V \ {x}.Obviously, criteria right-hand side equivalences checked polynomial time.turn problem PWSCOND . sets PWSCOND (G) eithersingleton empty set, determining membership singleton obviouslytractable. Checking whether PWSCOND (G) quite simple. followingresult gives exact characterization PWSCOND (G), interestingright.Lemma 4. Let U set undominated alternatives partial tournament G = (V, E).Then,every alternative x V , {x} PWSCOND (G) x U ;6 PWSCOND (G) 1 |U | 2 U dominant.Proof. Since complete tournament either one Condorcet winner none, setPWSCOND (G) cardinality 0 1. Clearly, {x} PWSCOND (G) x U .remains shown PWSCOND (G) contains U = , |U | 3,1 |U | 2 U dominant.U = , COND(T ) = every [G]. follows PWSCOND (G).|U | 3, consider directed cycle C U U visits every alternative U .6 Then,set undominated alternatives G0 = (V, E C) empty. followsPWSCOND (G).U = {x} x dominant, x Condorcet winner every [G]. Therefore,/ PWSCOND (G).U = {x} {x} dominant, (x, y)/ E 6= x. Considercompletion G containing (y, x). completion, set undominated alternativesempty. follows PWSCOND (G).U = {x, y} {x, y} dominant, every [G], either (x, y) xCondorcet winner , (y, x) Condorcet winner . follows/ PWSCOND (G).Finally, U = {x, y} {x, y} dominant, z 6= x,(x, z)/ E (y, z)/ E. Without loss generality, assume (x, z)/ E. Considercompletion G containing (z, x) (x, y). completion exists, (x, z)/ E,(y, x)/ E (since x U ). completion, set undominated alternativesempty. follows PWSCOND (G).6. cycle C subgraph G. fact, G|U contain edges.501fiAziz, Brill, Fischer, Harrenstein, Lang, & Seedigposition prove following theorem.Theorem 1. PWCOND , NWCOND , PWSCOND solved polynomial time.results PWCOND NWCOND also follow Corollary 2 KonczakLang (2005).note Theorem 1 corollary corresponding results maximinSection 5.2. reason Condorcet winner maximin winner 1weighted tournament, tournament admit Condorcet winneralternatives maximin winners.conclude section observing problems PWCNL , NWCNL ,PWSCNL reducible NWCOND , PWCOND , PWSCOND , respectively.straightforwardly checked partial tournaments G = (V, E) |V | > 1X V ,X PWSCNL (G) V \ X PWSCOND (G1 ),G1 = (V, E 1 ) G set edges inverted, i.e., E 1 = {(x, y) : (y, x) E}.also follows that,PWCNL (G) = V \ NWCOND (G1 ),NWCNL (G) = V \ PWCOND (G1 ).Since complement set computed polynomial time edgesreversed polynomial time well, obtain following result corollaryTheorem 1.Theorem 2. PWCNL , NWCNL , PWSCNL solved polynomial time.example, consider partial tournament G depicted Figure 2(i )dominating alternative set undominated alternatives G U = {a, b}.Therefore,PWCOND (G) = {a, b}NWCOND (G) = .PWSCOND (G), note set U dominant (b, c)/ E. Lemma 4,givesPWSCOND (G) = {{a}, {b}, }.Condorcet non-losers, observe G1 = (V, E 1 ) E 1 = {(c, a), (d, a), (d, b)}.Now, PWCOND (G1 ) = {c, d}, NWCOND (G1 ) = , (from Lemma 4)PWSCOND (G1 ) = {{c}, {d}, }. Therefore,PWCNL (G) = {a, b, c, d},NWCNL (G) = {a, b},PWSCNL (G) = {{a, b, d}, {a, b, c}, {a, b, c, d}}.502fiPossible Necessary Winners Partial Tournaments4.2 CopelandCopelands solution selects alternatives based number alternativesdominate. Define Copeland score alternative x tournament = (V, E)sCO (x, ) = |DT+ (x)|.set CO(T ) consists alternatives maximal Copeland score.illustrative example, consider partial tournament G shown Figure 2(i ). completions G (respectively b) Condorcet winner, (respectively b) sole Copeland winner completion shown Figure 2(ii ).two completions neither b Condorcet winner{(a, c), (a, d), (b, a), (b, d), (c, b), (c, d)},set Copeland winners {a, b, c},{(a, c), (a, d), (b, a), (b, d), (c, b), (d, c)},also depicted Figure 2(iii ), set Copeland winners {a, b}. Therefore,PWCO (G) = {a, b, c},NWCO (G) = ,PWSCO (G) = {{a}, {b}, {a, b}, {a, b, c}}.Since Copeland scores coincide Borda scores case 1-weighted tournaments,following direct corollary results Section 5.1.7Theorem 3. PWCO , NWCO , PWSCO solved polynomial time.PWSCO solvable polynomial time, get following corollary,may independent interest graph theorists.Corollary 1. exists polynomial-time algorithm check whether partial tournament admits regular completion, i.e., completion every alternativeout-degree.see this, merely observe completion = (V, E) partial tournamentregular CO(T ) = V .4.3 Top Cycletop cycle tournament = (V, E), denoted TC (T ), unique minimaldominant subset V .Lang et al. shown possible necessary winners TC computedefficiently greedy algorithms (Lang et al., 2012, Corollaries 1 2). Still, givefollowing characterization prove useful come consider possible7. PWCO alternatively solved via polynomial-time reduction maximum network flow (Cook etal., 1998, p. 51).503fiAziz, Brill, Fischer, Harrenstein, Lang, & Seedigwinning sets TC . alternative possible TC -winnerreach every alternative via existing unspecified edges. Formally, given partialtournament G = (V, E), alternative x V PWTC (G) everyalternative V , exists path x0 , x1 , x2 , . . . , xk x = x0 , = xk ,(xi+1 , xi )/ E {0, . . . , k 1}. call path possible path. possiblepath x exists, denote xy.Observe pair b alternatives partial tournament G = (V, E),possible path b, (b, a) E. set alternativesreach every alternative via possible path partial tournament G = (V, E) alsoknown Good set (Good, 1971) denoted GO(G).8 followsGO(G) polynomial-time computable. Moreover, following lemma.Lemma 5. Let G = (V, E) partial tournament |V | 3, GO(G) = V , xalternatives (x, y), (y, x)/ E. Let Gxy = (V, E {(x, y)})Gyx = (V, E {(y, x)}). Then, GO(Gxy ) = V GO(Gyx ) = V .Proof. Assume contradiction GO(Gxy ) GO(Gyx ) strict subsetsV . Clearly, x GO(Gxy ) GO(Gyx ). Moreover, claim x/GO(Gyx )/ GO(Gxy ). see x/ GO(Gyx ) holds, assume contradictionx GO(Gyx ). Then, possible path x Gyx . pathused replace edge (x, y) (which available possible paths G,Gyx ). Therefore, possible path two alternatives Gyx wheneverone G. Since GO(G) = V , GO(Gyx ) = V well, contradictingassumption. analogous argument shows/ GO(Gxy ).established x GO(Gxy ) \ GO(Gyx ) GO(Gyx ) \ GO(Gxy ),know possible path x Gyx , neither possiblepath x Gxy . consider z V \ {x, y}. either(i) (x, z) E (y, z) E,(ii) (z, x) E (z, y) E,otherwise would either possible path x Gyx possible pathx Gxy .(i), recall assumed GO(G) = V . Hence, G possiblepaths zx zy. Observe may assume either possible path zx contain (y, x), possible path z contain (x, y).former case, y, zx possible path Gxy . latter case, x, zpossibleyxpath G. Thus, either case yields contradiction.(ii), GO(G) = V implies possible paths xzz G,may assume either possible path x z contain (y, x)possible path z contain (x, y). former case, possiblepath xz, Gxy . latter case, possible pathz, x Gyx . Again,either case leads contradiction. concludes proof.8. Equivalently, Good set partial tournament G = (V, E) unique minimal dominant subsetV . Good set also known Smith set (Smith, 1973) GETCHA (T. Schwartz, 1986).504fiPossible Necessary Winners Partial Tournamentsready show PWSTC solved efficiently. Notecheck exists completion set question dominating,also smaller dominating set.Theorem 4. PWSTC solved polynomial time.Proof. Let set consideration X. set X cannot empty C(T ) 6=every [G]. |X| = 1, problem PWSTC equivalent PWCOND .|X| = 2, answer already top cycle never size two. maytherefore assume |X| 3.Consider graph GX . X dominate V \ X GX , X/ PWSTC (G)alternative V \ X beats alternative X. Therefore, need checkwhether X PWSTC (G|X ), i.e., whether X possible top cycle set partialtournament G restricted X. essence, problem PWSTC reduced restrictedproblem PWSTC set alternatives.prove V PWSTC (G) GO(G) = V . Obviously, V 6= GO(G)V/ PWSTC (G). direction, start partial tournament G =(V, E) GO(G) = V . iteratively applying Lemma 5, new edges successivelyadded G maintaining GO(G) = V G tournament.example, consider partial tournament G depicted Figure 2(i ),showPWTC (G) = {a, b, c, d},NWTC (G) = ,PWSTC (G) = {{a}, {b}, {a, b, c}, {a, b, c, d}}.result PWTC (G) witnessed completion shown Figure 2(iii ) everyalternative top cycle. NWTC (G), statement follows observation every alternative, exists completion another alternativeCondorcet winner. Regarding PWSTC (G), consider subset separately. SincePWSCOND PWSTC , get {a} {b} PWSTC (G). {a, b, c}, applyresult shown second paragraph proof Theorem 4: a, b, c undominatedd, Good set G|{a,b,c} {a, b, c}. Likewise, Good set G {a, b, c, d}.remains shown subsets size three PWSTC (G).end, note Good set G|{a,b,d} {a, b} neither {a, c, d} {b, c, d}undominated G.4.4 Uncovered SetGiven tournament = (V, E), alternative x V said cover another alternativeV DT+ (y) DT+ (x), i.e., every alternative dominated also dominated x.uncovered set , denoted UC (T ), set alternatives coveredalternative. useful alternative characterization uncovered set viatwo-step principle: alternative uncovered set reachevery alternative two steps.9 Formally, x UC (T )9. graph theory, vertices satisfying property often called kings.505fiAziz, Brill, Fischer, Harrenstein, Lang, & SeedigV \ {x}, either (x, y) E z V (x, z), (z, y) E. denote++++two-step dominion DE(DE(x)) alternative x DE(x).first consider PWUC , check alternative whetherreinforced reach every alternative two steps.Theorem 5. PWUC solved polynomial time.Proof. given partial tournament G = (V, E) alternative x V , checkwhether x UC (T ) completion [G].Consider graph G0 = (V, E 00 ) E 00 derived E follows. First,let D+ (x) grow much possible letting E 0 = E x . Then,+two-step dominion defining E 00 E 0DE0 (x) . claim x PWUC (G)+++V = {x} DE00 (x) DE 00 (x).() First, let x PWUC (G). definition, completion (V, E )+++00V \ {x} DE(x) DE (x). definition E , follows+++++++++DE (x) DE 00 (c) DE (x) DE 00 (x). Consequently, also DE 00 (x) DE00 (x).+++() direction, let V \ {x}, DE 00 (x) DE 00 (x). completionG0 , x trivially UC (T ), implying x PWUC (G).similar argument yields following.Theorem 6. NWUC solved polynomial time.Proof. given partial tournament G = (V, E) alternative x V , checkwhether x UC (T ) completions [G].Consider graph G0 = (V, E 00 ) E 00 defined follows. First, let E 0 = E x . Then,expand E 00 = E 0DE0 (x) . Intuitively, makes hard possible x beatalternatives outside dominion two steps. claim x NWUC (G)+++V = {x} DE00 (x) DE 00 (x) equivalently, 6= x pathlength one two x G.() First, let x NWUC (G). Assume contradiction exists V \ {x}+++0/ DE00 (x) DE 00 (x). Then, completion (V, E ) G , x cannot reachtwo steps consequently x/ UC (V, E ), contradiction.+++completion (V, E ) G,() Now, let V \ {x} = DE00 (x) DE 00 (x).++++++DE 00 (x) DE (x) DE 00 (x) DE (x). Consequently, x UC (V, E )x NWUC (G).+++checked polynomial time whether V = {x} DE00 (x) DE 00 (x),completes proof.Consider partial tournament G Figure 3(i ) example.checked NWUC (G) = .10 PWUC , consider alternative separately.a, E 0 = E = {(a, b), (a, c), (a, d), (b, d)}, E 00 = E 0 , therefore+DELikewise, b PWUC (G). Now, c,00 (a) = {b, c, d} PWUC (G).E 0 = {(a, c), (a, d), (b, d), (c, b), (c, d)} E 00 = {(a, c), (a, d), (b, d), (c, b), (c, d), (b, a)},+++see also Figure 3(ii ). gives us DE00 (c) = {b, d} DE 00 (c) = {a}, there0fore, c PWUC (G). Lastly, d, E = {(a, c), (a, d), (b, d), (d, c)} E 00 =10. also consequence NWTC (G) = (Section 4.3) NWUC NWTC (Lemma 2).506fiPossible Necessary Winners Partial Tournamentsbbbccc(i )(ii )(iii )Figure 3: partial unweighted tournament G possible extensions. center,alternative c dominion maximally reinforced resulting c reaching everyalternative two steps. Therefore, c PWUC (G). right,done alternative cannot reach two steps therefore containedPWUC (G).+{(a, c), (a, d), (b, d), (d, c), (c, b)} depicted Figure 3(iii ). gives us DE00 (d) = {c}++/ PWUC (G). summary,DE 00 (d) = {b}, implyingPWUC [G] = {a, b, c},NWUC (G) = ,PWSUC (G) = {{a}, {b}, {a, b, c}},PWSUC (G) obtained ad hoc argument.solution concepts considered farCondorcet winners, Condorcet non-losers,Copeland, top cyclePW PWS complexity. One might wonderwhether result like holds generally, whether could polynomialtime reduction PWS PW. following find case, unlessP=NP, show PWSUC , problem deciding whether subset alternativespartial tournament G uncovered set completion G, NP-complete.proof result proceeds reduction Sat involves construction partialtournaments basis formulas conjunctive normal form. propositionalvariable p every clause c, gadget based partial tournament Gpdepicted Figure 4(i ).hard see exactly two completions Gp {p , p+ , 1}uncovered set. first, + positive completion, depicted Figure 4(ii )other, negative completion, Figure 4(iii ). verifyones, consider arbitrary completion (V, E 0 ) Gp . Then, either (p , p+ ) E 0(p+ , p ) E 0 . former case, observe p must covered 1. Hence,(1, p ) E 0 (c, p ) E 0 . follows c covered p+ . Therefore, also(p+ , 1) E 0 (p+ , c) E 0 . entails p covers p+ and, (p+ , p+ ) E 0finally obtain (p , p+ ) E 0 . resulting tournament + . analogous argumentseen results assume (p , p+ ) E 0 . construction below,positive completion + correspond setting propositional variable p truenegative completion setting p false.Besides c, construction also involves alternative c clause. c relatedalternatives Gp depends whether respective clause contains p pliteral. may assume clause contains p p, three cases remain,507fiAziz, Brill, Fischer, Harrenstein, Lang, & Seedigpp+1pp+1pp+1pp+cpp+cpp+c(i ) variable gadget variable p(ii ) completion + p set true(iii ) completion p set falseFigure 4: partial tournament Gp two completions, + ,uncovered set given {p , p+ , 1}. Dotted edges missing omitted edges pointdownwards.pp+1pp+cpp+(i ) c contains p p1pp+ccpp+(ii ) c contains p p1ccpp+c(iii ) c contains neither p pFigure 5: Gp -gadget alternative c added. Figure 4, dotted edges missingomitted edges point downwards.depicted Figure 5. reflection reveals clause contains p positiveliteral, c covered p+ partial tournament completed positively,p completed negatively. Similarly, clause contains p negative literal, ccovered p Gp completed negatively, p+ Gp completedpositively. c contains neither p p literal, c covered either p+ pirrespective whether Gp completed positively negatively.construction below, every clause, alternative c coveredclause contains literal p Gp -gadget completed positively literal qGq -gadget completed negatively.Theorem 7. PWSUC NP-complete.Proof. Given partial tournament G = (V, E), set X V , completion [G],checked polynomial time whether X = UC (T ). Hence, PWSUC obviouslyNP.NP-hardness shown reduction Sat. Let formula conjunctivenormal form. Without loss generality may assume clause contains508fiPossible Necessary Winners Partial Tournamentsliteral negation, least two clauses, every literal occursleast one clause. construct partial tournament G = (V , E ) follows.propositional variable p introduce five alternatives denoted p, p , p+ , p , p+ .clause c, introduce two alternatives denoted c c. also two auxiliaryalternatives denoted 1 0. Thus,V = {p, p , p+ , p , p+ : p variable} {c, c : c clause} {1, 0}.give description edge set E . every propositional variable pevery clause c alternatives p , p+ , p , p+ , 1, c, c organized Figure 5.remaining edges set way make construction work properly. Formally,define edge set E every propositional variable p every clause c:p dominates every clause well q , q + , q , q + every q 6= p;p+ dominates 0, p, p along q , q + , q 6= p clauses d.Moreover, every clause d, alternative p+ dominates alternative poccurs literal clause d;p dominates 0, p, p+ along q , q + , q 6= p clauses d.Moreover, every clause d, alternative p dominates alternative poccurs literal clause d;p+ dominates 0, p, p+ ;p dominates 0, p, p ;c dominates 0, q , q + every variable q, every clause 6= c. Moreover,variable q, alternative c dominates q + whenever c contain q literal,q c contain q literal;cdominates 0, c, 1;1 dominates 0 well q, q , q + variables q, clauses d;0 dominates alternative q every variable q, otherwise 0 dominatedalternatives.Moreover, every variable p, edges among p , p+ , 1 missing wellp , p+ , every clause d. Finally, edges specifieddescription set arbitrarily. example construction reader referredFigure 6.letX = {p, p , p+ : p propositional variable} {c : c clause} {1}.Table 2 summarizes alternatives reach alternatives twosteps G . thus find that, every completion G , set X containedUC (T ) 0 covered 1. propositional variables p clauses c, alternatives p , p+ , c covered alternatives {p , p+ , 1}, i.e., whether509fiAziz, Brill, Fischer, Harrenstein, Lang, & Seedigpppqp+p+1pqprpqprqq+qq+0Figure 6: Part dominance relation partial tournament G associatedCNF formula = (p q) (p r). alternatives pq pr represent two clauses .part involving variable r, i.e., alternatives r, r , r+ , r , r+ , omitted.dashed edges dependent clauses . Omitted edges point downwards or,level, arbitrary direction. Dotted edges missing.covered depends subtournament {p , p+ , 1, p , p+ , c} completed. saw discussion preceding theorem, done positivelynegatively, positive completion corresponds setting variable p truenegative completion setting p false. complete proof showingX = UC (T ) [G ]satisfiable.() First assume satisfiable let v satisfying assignment .propositional variable p v sets true clause c, complete subtournament {p , p+ , 1, p , p+ , c} positively, i.e., add edges (p , p+ ), (p+ , 1), (1, p )well (p , p+ ), (p+ , c), (c, p ). Thus, p covered 1, p+ p , and, providedp occurs literal c, c also p+ . Similarly, propositional variable q vsets false clause c, complete subtournament {p , p+ , 1, p , p+ , c} negatively, i.e., add edges (1, q + ), (q + , q ), (q , 1) well (c, q + ), (q + , q ),(q , c). Accordingly, q covered q + , q + 1, and, provided q occurs literalc, c also q . Observe procedure induces well-defined completion G ,denote Tv . v satisfies , every clause contains literal p v sets ptrue literal q v sets q false. follows every clause c, alternative ccovered Tv . Observe p p+ covered Tv irrespective whether v sets p510fiPossible Necessary Winners Partial Tournamentsp qpp+1q q+ cpp+cq q+ 0ppp+1c[p]c[p]00q0000c[p]pppc[p]p+p+p+cccccppp p c[p]ppp pc[p]q q+pppp+pp+c[p]c[p]0000000cqcqppccpppccppp11ppp11pp+11qp11qpppppccpcpp11ppp11pTable 2: Table summarizing types alternatives reach types alternatives one two steps (all completions of) partial tournament G . assume pq distinct variables neither q q occurs literal c. Furthermore, cassumed distinct clauses, c[p] denotes clause c understandingp occurs literal c. Similarly, c[p] denotes clause c understanding poccurs literal c. alternative x entry row r column c means rreach c via x. entry dot (), r reach c directly, i.e., one zerosteps. box () signifies depends G completed whethervia alternative r reach c. minus () entry 0 1 means 0cannot reach 1 two steps, matter G completed. Thus, 0 covered1 every completion G . may assume clause contains literalnegation, least two clauses, every literal occurs least oneclause.true false. Hence, c, p+ , p/ UC (Tv ). Recalling 1 covers 0 X UC (T )completions G , may conclude UC (Tv ) = X, desired.() opposite direction, assume completion Gevery propositional variable p every clause c, alternatives p , p+ , ccovered , i.e., UC (T ) = X. Define assignment vT setspropositional variable p true clause c containing p literalp+ covers c sets p false, otherwise. Observe vT well-definedassignment.show vT satisfies every clause hence well. endconsider arbitrary clause c. assumption, c covered alternative x. Recallc reaches alternatives two steps except alternatives p+ p occursliteral c alternatives q q occurs literal c (also see Table 2).Hence, either x = p+ variable p occurring literal c x = qvariable q q occurs literal c.former, vT sets p true consequently also satisfies clause c. latter,demonstrate vT sets q false way satisfies clause c. suffices511fiAziz, Brill, Fischer, Harrenstein, Lang, & Seedig24qq+61531qq+cFigure 7: Illustration concluding argument proof Theorem 7. doubleedge alternative x alternative indicates x covers y. numbersedges labelled correspond order existence demonstratedproof Theorem 7.show clause q + covers . end, consider arbitraryclause d. prove q + cover refer Figure 7 illustrationreasoning. Let ET denote edge set . extends G , obviously E ET . Firstrecall assumed q covers c . (c, 1) E , also (q , 1) ET .Since (q , q ) E , therefore case 1 covers q . Reaching everyalternative two steps G , alternative q must therefore covered q +. (q , q ) E , follows (q + , q ) ET . Since, moreover, (q + , q + ) E ,also q cover q + . Rather, q + reaches every alternative except 1two steps . follows q + covered 1. Moreover, since (q + , q + ) E ,also (1, q + ) ET . consider alternative observe that, construction, (d, 1) E .Thus, reach q + two steps may conclude q + cover .follows vT sets q false thus satisfies c, desired.5. Weighted Tournament Solutionsturn weighted tournaments, particular consider solution conceptsBorda, maximin, ranked pairs.5.1 BordaBorda solution (BO) typically used voting context set N n voters,voter equipped linear ranking individual preference. Then,alternative receives |V | 1 points time ranked first voter, |V | 2points time ranked second, forth. total number pointsalternative x constitute Borda score sBO (x, (i )iN ) writtensBO (x, (i )iN ) =X512|{y V : x y}|.fiPossible Necessary Winners Partial Tournamentsgenerally, Borda solution extended n-weighted tournamentsBorda scores definedXsBO (x, (V, w)) =w(x, y)yV \{x}BO(V, w) chooses alternatives maximum Borda score. subsumesvoting settingXsBO (x, (i )iN ) =|{i N : x y}| = sBO (x, (V, w))yVweight edge x defined number voters rank xhigher y, i.e.,w(x, y) = |{i N : x y}|.proceed, define notion b-matching, used proofsseveral results section. Let H = (VH , EH ) undirected graphvertex capacities b : VH N0 . Then, b-matching H function : EH N0v VH ,Xm(e) b(v).e{e0 EH :ve0 }Psize b-matching definedeEH m(e). easy see b(v) = 1v VH , maximum-size b-matching equivalent maximum-cardinalitymatching. b-matching problem upper lower bounds, function: VH N0 . feasible b-matching function : EH N0Xa(v)m(e) b(v).e{e0 EH :ve0 }H bipartite, problem computing maximum-size feasible b-matchinglower upper bounds solved strongly polynomial time (Schrijver, 2003,ch. 21). use result show PWBO PWSBO solvedpolynomial time. following result PWBO also shown using Theorem 6.1Kern Paulusma (2004), still give direct proof extendedPWSBO .Theorem 8. PWBO solved polynomial time.Proof. Observe BO satisfies following (weak) monotonicity property: makingwinner x stronger increasing weight edge another alternative, cannot make xlosing alternative.Let G = (V, w) partial n-weighted tournament, x V . previous observation,x PWBO (G) x PWBO (Gx ). Therefore, assume w.l.o.gG = Gx , i.e., edges incident x completely specified already. Moreover,exists V \ {x} sBO (y, Gx ) > sBO (x, Gx ), already knowx/ PWBO (G). thus assume sBO (y, Gx ) sBO (x, Gx ) V \ {x}.513fiAziz, Brill, Fischer, Harrenstein, Lang, & Seediggive polynomial-time algorithm checking whether x PWBO (Gx ) viareduction problem computing maximum-size b-matching bipartite graph.Let = sBO (x, Gx ) Borda score x Gx . construct bipartite graphH = (VH , EH ) verticesVH = V \ {x} E x ,E x = {{i, j} V \ {x} : 6= j}edgesEH = {{i, {i, j}} : {i, j} V \ {x}, 6= j}.define vertex capacities b : VH N0b({i, j}) = n w(i, j) w(j, i) {i, j} E xb(v) = sBO (v, Gx ) v V \ {x}.observe completion = (V, w0 ) [Gx ], w0 (i, j) + w0 (j, i) = ni, j V 6= j. sum Borda scores therefore n|V |(|V | 1)/2.weight already used Gx ; weight yet usedequalX= n|V |(|V | 1)/2sBO (v, Gx ).vV(Gx )claim x PWBOH b-matching size least .0x() Let = (V, w ) [G ] completion x BO(T ). Consider bmatching m(i, {i, j}) = w0 (i, j) w(i, j). verify feasible b-matching.Let v VH . v V \ {x},Xm(e) = sBO (v, ) sBO (v, Gx ) sBO (v, Gx ) = b(v).e{e0 EH :ve0 }Otherwise, v = {i, j} E xXm(e) = m({i, {i, j}}) + m({j, {i, j}}) = n w(i, j) w(j, i) = b({i, j}).e{e0 EH :{i,j}e0 }sizeXXX XXm(e) =w0 (i, j) + w0 (j, i) w(i, j) w(j, i) =nw(i, j) = ,eEHi6=ji6=jiV jV \{i}statement shown.() direction, assume feasible b-matching size least exists.construct completion = (V, w0 ) [Gx ] x BO(T ). Letw0 (i, j) = m(i, {i, j}) + w(i, j)0{i, j} V \ {x},0w (x, i) = w(x, i), w (i, x) = w(i, x)514V \ {x}.fiPossible Necessary Winners Partial Tournamentsw(i, j) w0 (i, j) w0 (i, j)+w0 (j, i) w(i, j)+w(j, i)+b({i, j}) = n {i, j} V ,extension Gx .XXXb({i, j})m(e) =,={i,j}E xeEHi6=jknow upper capacities b({i, j}) {i, j} E x exactly met (andcannot matching size ). impliesw0 (i, j) + w0 (j, i) = w(i, j) + w(j, i) + b({i, j}) = n,showing indeed completion Gx .Since H constructed efficiently, since maximum-size b-matchingcomputed strongly polynomial time, algorithm runs polynomial time.1111b15155442c222cap.32ccap.3{a, b}143b521{a, d}25{b, d}1cb533(ii ) partial tournament Gc .(i ) partial 5-weighted tournament G.0b1 42(iii )constructedbipartitegraph H target Borda score= sBO (c, Gc ) = 8. Capacitiesgiven next vertices. Thickedges weights indicate uniquemaximum b-matching.32(iv ) completion G corresponds maximum b-matching.case, BO(T ) = {a, b, c}.Figure 8: Illustration algorithm checking whether alternative c containedPWBO (G) partial 5-weighted tournament G.Figure 8 illustrates described steps determining whether alternative contained PWBO (G).idea extended polynomial-time algorithm PWSBO usesimilar construction given G = (V, w), candidate set X V target Bordascore . Binary search used efficiently search interval possible target scores.515fiAziz, Brill, Fischer, Harrenstein, Lang, & SeedigTheorem 9. PWSBO solved polynomial time.Proof. Let G = (V, w) partial n-weighted tournament, X V . givepolynomial-time algorithm checking whether X PWSBO (G), via bisection methodreduction problem computing maximum b-matching graph lowerupper bounds.Assume target Borda score completion [G] XPWSBO (T ) sBO (x, ) = x X. Then, maximum possible Borda scorealternative X 1.given target Borda score , construct bipartite graph H = (VH , EH )vertices VH = V E x ,E x = {{i, j} V : 6= j},edgesEH = {{i, {i, j}} : {i, j} V, 6= j, w(i, j) + w(j, i) < n}.lower bounds : VH N0 upper bounds bs : VH N0 dependdefined follows. vertices x X, lower upper bounds coincide given(x) = bs (x) = sBO (x, G).vertices v VH \ X lower bound (v) = 0. Upper boundsvertices definedbs (v) = sBO (v, G) 1v V \ X,bs ({i, j}) = n w(i, j) w(j, i){i, j} E x .proof Theorem 8, holds feasible b-matching H correspondsextension G. extension completion [G] b-matchingsizeX= n|V |(|V | 1)/2sBO (v, G),vVequals weight yet used G. Then, satisfies X PWSBO (T )sBO (x, ) = x X. If, hand, gives rise graphb-matching size , X 6 PWSBO (G).order obtain polynomial-time algorithm, need check whether existstarget score corresponding graph H upper lower bounds admitsb-matching size . easily verified contained integer interval= [ max sBO (x, G), n(|V | 1) ].xXObserve |I| depends n thus polynomially bounded size G.Checking every integer therefore feasible polynomial time. However,show perform binary search order find efficiently. need following516fiPossible Necessary Winners Partial Tournamentstwo observations interval I. I, say admits feasible b-matchingcorresponding graph H feasible b-matching.First, s0 admits feasible b-matching, every s00 s00 s0 alsoadmits feasible b-matching. removing weight edges exceeds(reduced) upper bounds gives feasible b-matching s00 .Second, s0 0 size corresponding maximum feasible bmatching m0 , cannot s00 s00 s0 size 00 maximumfeasible b-matching m00 s00 smaller 0 . either (i ) m00 existssince lower bounds met, (ii ) m00 exists size least 0 .see latter, note decrease size maximum feasible matching cannotcaused upper bounds bs00 (v) bs0 (v) v VH . remains shownincrease as00 (v) v X result smaller maximum b-matching. Sinceweight edges incident vertex X b-matching completely determinedbounds increases m0 m00 , total decrease size due edges{j, {i, j}} V \ X, j V whose weight bounded bs00 ({i, j}) m00 (i, {i, j}).then,m00 (i, {i, j}) + m00 (j, {i, j}) = bs00 ({i, j}) bs0 ({i, j}) m0 (i, {i, j}) + m0 (j, {i, j})therefore 00 0 .two observations show partitioned two non-overlapping integerintervals I1 I2 . Here, I1 admits feasible b-matching whose size increasesgrows, whereas I2 admit feasible b-matchings. Therefore, eitherI1 empty desired exist, = max(I1 ).check existence following binary search algorithm. Let[Imin , Imax ] interval initialized = [maxxX sBO (x, G), n(|V | 1)]. Considermedian value interval. corresponding graph H feasible b-matching,continue interval [Imin , 1]. Otherwise, maximum feasible b-matchingsize least , return yes. size less , continue [s+1, Imax ]. [Imin , Imax ]empty, return no.number queries algorithm bounded dlog2 |I|e dlog2 n|V |e and,therefore, polynomial size G.conclude section, show NWBO solved polynomial time well.worth noting result follow directly polynomial-time resultNWBO case preference profiles (Xia & Conitzer, 2011).Theorem 10. NWBO solved polynomial time.Proof. Let G = (V, w) partial weighted tournament, x V . give polynomial-timealgorithm checking whether x NWBO (G).Let G = Gx . want check whether alternative V \ {x}achieve Borda score = sBO (x, G). done separatelyV \ {x} reinforcing much possible G. y, sBO (y, Gy ) > ,x/ NWBO (G). If, hand, sBO (y, Gy ) V \ {x},x NWBO (G).517fiAziz, Brill, Fischer, Harrenstein, Lang, & Seedigexample, consider partial 5-weighted tournament G Figure 8(i ). fact{a, b, c} PWBO (G) follows already completion shown Figure 8(iv ). Alsonote completion c chosen. Alternative possibleBorda winner since sBO (d, Gd ) = 7 < 8 = sBO (a, G). determine PWSBO (G), stillcheck subsets {a, b, c} possible winning sets. singletons, easysee {a} {b} PWSBO (G). {a, b}, could employ binarysearch method described Theorem 9. Here, argue moving one unit weight(c, d) (d, c) completion shown Figure 8(iv ) gives completion{a, b} winning set. NWBO (G), straightforward check alternativenecessary Borda winner. Altogether,PWBO (G) = {a, b, c},NWBO (G) = ,PWSBO (G) = {{a}, {b}, {a, b}, {a, b, c}}.5.2 Maximinmaximin score sMM (x, ) alternative x weighted tournament = (V, w),given worst pairwise comparison, i.e., sMM (x, ) = minyV \{x} w(x, y). maximin solution, also known Simpsons method denoted MM , returns setalternatives highest maximin score.example, consider partial 5-weighted tournament depicted Figure 9(i ).easy see (or b) unique maximin winners completions Ga (or Gb ).Also, c cannot possible maximin winner always maximin score 0whereas always least 1. Similarly, alternative never higher maximinscore a. Figure 9(iii ) shows completion {a, d} set maximin winners.one unit weight shifted (c, b) (b, c), resulting completion {a, b, d}maximin winners. also straightforward find completion G{a,b} {a, b}set maximin winners. easy verify alternative necessary maximinwinner.Together, givesPWMM (G) = {a, b, d},NWMM (G) = ,PWSMM (G) = {{a}, {b}, {a, b}, {a, d}, {a, b, d}}.first show PWMM polynomial-time solvable reducing problemfinding maximum-cardinality matching graph.Theorem 11. PWMM solved polynomial time.Proof. show check whether x PWMM (G) partial n-weighted tournamentG = (V, w). Consider graph Gx = (V, wx ). Then, sMM (x, Gx ) best possiblemaximin score x get among completions G. sMM (x, Gx ) n2 ,sMM (y, ) wx (y, x) n2 every V \ {x} every completion [Gx ],therefore x PWMM (G).518fiPossible Necessary Winners Partial Tournaments11b154c222c(i ) partial 5-weighted tournament G.14{a, b}{a, c}{a, d}{b, c}{b, d}{c, d}b(ii )constructedbipartitegraph H = 1 X = {a, d}proof Theorem 12.maximum-cardinality matching giventhick edges.b14553532b32c321425c(iii ) completion G couldobtained matching. Indeed,MM (T ) = {a, d} sMM (T ) = 1.32(iv ) completion G witness{a, b} PWSMM (G).Figure 9: Example 5-weighted partial tournament completions relevant possiblemaximin winners.consider sMM (x, Gx ) < n2 . reduce problem checking whether xPWMM (G) finding maximum-cardinality matching undirected unweightedgraph, known solvable polynomial time (Edmonds, 1965). wantfind completion [Gx ] sMM (x, ) sMM (y, ) V \ {x}.words, want complete weights edges alternatives V \ {x}balanced way x still winner. exists V \ {x}sMM (y, Gx ) > sMM (x, Gx ), already know x/ PWMM (G). Otherwise,V \ {x} derives maximin score least one particular edge (y, z)z V \ {x, y} w(y, z) sMM (x, Gx ). Moreover, clear completion,z cannot achieve maximin score less sMM (x, Gx ) edges (y, z)(z, y) time. Let H = (VH , EH ) undirected unweighted graphverticesVH = V \ {x} {{i, j} V : 6= j}edgesEH = {{i, {i, j}} : V \ {x}, j V \ {i}, wx (i, j) sMM (x, Gx )}.way, matched {i, j} H, derives maximin score lessequal sMM (x, Gx ) comparison j. Clearly, size H polynomial519fiAziz, Brill, Fischer, Harrenstein, Lang, & Seedigsize G. show x PWMM (G) exists matchingcardinality |V | 1 H.() First, assume x PWMM (G). exists completion = (V, w0 )Gx maximin score V \ {x} sMM (x, Gx ) < n2 .alternative derives maximin score comparison j 6= V \ {x}, i.e.,sMM (i, ) = w0 (i, j), j cannot derive maximin score comparisonw0 (j, i) n sMM (x, Gx ) implies w0 (j, i) > n2 . Therefore, H, VH Vmatched vertex {i, j} VH {i, j} matched vertexVH . resulting matching H cardinality |V | 1.() Now, assume exists matching cardinality |V | 1 H. Then,V \ {x} matched {i, j} w(i, j) sMM (x, Gx ). Considercompletion = (V, w0 ) [Gx ] (i, j) V V {i, {i, j}} ,set w0 (i, j) = w(i, j) w0 (j, i) = n w(i, j). Moreover, weights edgesset arbitrary completion edges Gx . Clearly, proper completionGx therefore G. , maximin score V \ {x} less equalmaximin score x. Therefore x MM (T ) implies x PWMM (G).Next, show PWSMM solved polynomial time. proof proceedsidentifying maximin values could potentially achieved simultaneouslyelements set question, solving problem values usingsimilar techniques proof Theorem 11. polynomially bounded numberproblems need considered.Theorem 12. PWSMM solved polynomial time.Proof. Let G = (V, w) partial n-weighted tournament X V . givepolynomial-time algorithm checking whether X PWSMM (G).X PWSMM (G) must completion [G] {0, . . . , n}sMM (x, ) = x X sMM (i, ) < V \ X.First, note > n w(j, i) X, j V w(i, j)/ X, j V , X 6 PWSMM (G). Therefore, assumen w(j, i) X, j Vw(i, j) </ X, j V.treat cases > n2 , = n2 , <n2separately.Case 1: > n2 . Then, X PWSMM X singleton, x V ,whether {x} PWSMM maximin score checked easily.Case 2: = n2 . assumptions above, define G0 = (V, w0 ) extensionGX w0 (i, j) = w0 (j, i) = n2 = i, j X. Note every completionG0 , sMM (i, ) = X X PWSMM (G) maximin score n2corresponding completion X PWSMM (G0 ) maximin scorerespective completion.520fiPossible Necessary Winners Partial Tournamentsaddition, need check whether alternatives X forcedstrictly smaller maximin score n2 . end, construct unweighted undirectedbipartite graph H = (VH , EH ) verticesVH = V {{i, j} V : 6= j}edgesEH = {{i, {i, j}} : V \ X, j V \ {i}, w(i, j) < }.claim X PWSMM (G0 ) maximin score = n2 correspondingcompletion maximum-cardinality matching size |V \ X| H.() Let = (V, w00 ) completion G0 (and thereby G) X setmaximin winners sMM (i, ) = = n2 X./ X, needsj 6= w00 (i, j) < . Collecting {i, {i, j}} pair gives matchingsize |V \ X| H maximum since vertex one side bipartite graphcontained it.() direction, assume maximum matching size |V \ X|.construct completion = (V, w00 ) G0 X set maximin winners.Note every (VH V ) \ X contained edge {i, {i, j}} matching.edge, let w00 (i, j) = w0 (i, j) < w00 (j, i) = n w00 (i, j), implyingsMM (i, ) < . Otherwise, arbitrary completion G.Together, sMM (i, ) = X sMM (i, ) </ X.Figure 10 illustrates procedure 2-weighted tournament set X = {a}.Case 3: < n2 . given , construct undirected unweighted bipartite). Let Vgraph H = (VH , EHH[[EH={{i, {i, j}} : w(i, j) n w(j, i)}{{i, {i, j}} : w(i, j) 1}.iXj6=iiVj6=iclaim X PWSMM (G) maximin score correspondingcompletion maximum-cardinality matching size |V | H .() Let = (V, w0 ) completion G X set maximin winnersmaximum maximin score . every vertex V , j 6=w0 (i, j) accounts maximin score i. Also, since < n2 , cannot case jalso derives maximin score w0 (j, i). Therefore, set pairs {i, {i, j}}valid matching size |V |. obviously maximal.() direction, assume maximum matching size |V |. Noteevery (VH V ) matched define j(i) V edge {i, {i, j(i)}contained matching. construct completion = (V, w0 ) X setmaximin winners. end, definew0 (i, j(i)) = w0 (j(i), i) = n X,w0 (i, j(i)) = 1 w0 (j(i), i) = n (s 1) V \ X.long unspecified edges (i, j) completion, definew0 (i, j) = max{w(i, j), } w0 (j, i) = n w(i, j) X, j V ,w0 (i, j) = max{w(i, j), 1} w0 (j, i) = n w(i, j) otherwise.521fiAziz, Brill, Fischer, Harrenstein, Lang, & SeedigNote proper completion G. Now, sMM (i, ) = XsMM (i, ) </ X. completes Case 3.remains shown limited number possible (and thereby H )considered. contrast proof Theorem 9, cannot employ binary searchmethod since clear cut feasible infeasible integer interval.However, see gradually incremented 0 n2 1, whetherchanges twice due definitionedge {i, {i, j}} contained EH. partitions integer interval = [0, n 1] possible finite numberEH2subintervals Ik within single Ik induce H . Therefore,sufficient consider one per Ik choose minimum. setpossibly relevant target scores given[[[=min Ik{w(i, j), n w(j, i) + 1}{w(i, j) + 1}.iXj6=ikiVj6=isize obviously bounded 3n2 .cases handled polynomial time.b11111b211111c1c(ii ) extension G0 reinforcing {a}.(i ) partial 2-weighted tournament G.bc{a, b}{a, c}{a, d}{b, c}{b, d}{c, d}b21111211c2(iv ) completion G0 GMM (G0 ) = {a}(iii ) constructed undirected bipartite graph H. Thick edges indicatemaximum-cardinality matching.Figure 10: Illustration algorithm checking whether singleton {a} containedPWSMM (G) partial 2-weighted tournament G. obvious cannotmaximin score 2 completion sole maximin winner maximin score0. Therefore, check case = n2 = 1.Lastly, consider NWMM , apply similar technique NWBO :see whether x NWMM (G), start graph Gx check whetheralternative achieve higher maximin score x completion Gx .522fiPossible Necessary Winners Partial TournamentsTheorem 13. NWMM solved polynomial time.Proof. show check whether x NWMM (G) partial n-weighted tournamentG = (V, w). maximin score x Gx worst case maximin score x amongproper completions G.V \ {x}, maximin score Gy best possible maximin scoreamong completions G. maximin score correspondingGy maximin score x Gx , x NWMM (G), otherwisex/ NWMM (G).5.3 Ranked Pairsmethod ranked pairs (RP ) resolute solution concept consideredarticle. Given weighted tournament = (V, w), returns unique undominatedalternative transitive tournament 0 V constructed following manner. Firstorder (directed) edges decreasing order weight, breaking ties accordingexogenously given tie-breaking rule. start empty graph 0 consideredges one one according ordering. current edge added 0without creating cycle, so; otherwise discard edge.11example, consider partial 5-weighted tournament depicted Figure 11(i ),slightly modified version tournament considered Figures 8 9.easy see ranked pairs winner completions Ga , likewise branked pairs winner completions Gb . hand, completionc ranked pairs winner. Whether possible ranked pairs winner dependstie-breaking rule used, particular tie-breaking rule ranksedges (d, c) (b, d): alternative possible ranked pairs winner (d, c)considered (b, d) (see Figure 11(iv )). Since RP resolute, (assumingtie-breaking rule ranks (d, c) (b, d))PWRP (G) = {a, b, d}NWRP (G) =PWSRP (G) = {{a}, {b}, {d}}.readily appreciated winner determination problem RP computationally tractable. possible winner problem, hand, turns NP-hard.also shows tractability winner determination problem, necessarytractability PW, generally sufficient.Theorem 14. PWRP NP-complete.Proof. work alternative characterization ranked pairs winnersintroduced Zavist Tideman (1989). given weighted tournament = (V, w)11. variant ranked pairs originally proposed Tideman (1987), also used XiaConitzer (2011), instead chooses set alternatives, containing alternative selectedprocedure way breaking ties among edges equal weight. considerirresolute version ranked pairs winner determination variant NP-hard (Brill& Fischer, 2012). mentioned Section 3, immediately implies problems concerningpossible necessary winners NP-hard well.523fiAziz, Brill, Fischer, Harrenstein, Lang, & Seedig1141b1515545212c414b554114432b535(ii ) completion G ranked pairswinner a.15c32c(i ) partial 5-weighted tournament G.b2c(iii ) completion G rankedpairs winner b.14(iv ) completion G ranked pairswinner d. Here, assume edge(d, c) considered edge (b, d).Figure 11: Example 5-weighted partial tournament completions relevant possibleranked pairs winners. completion, transitive tournament constructedranked pairs procedure indicated thick edges.given tie-breaking rule, let denote order edges consideredranked pairs procedure. is, (x, y) (u, v) either w(x, y) > w(u, v)w(x, y) = w(u, v) tie-breaking rule ranks (x, y) higher (u, v). Given rankingL V , two alternatives b, say attains b L existssequence distinct alternatives a1 , a2 , . . . , , 2, a1 = a, = b,ai L ai+1 ,(ai , ai+1 ) (b, a) 1 < t.case, say attains b via (a1 , a2 , . . . , ). ranking L called stackpair alternatives b holds L b implies attains b L.Zavist Tideman (1989) shown alternative ranked pairs winnertop element stack.12 Intuitively, defining properties stack Lensure pairs (a, b) alternatives L b, point time edge (b, a)considered, discarded would create cycle.Membership PWRP NP obvious, given completion given tiebreaking rule, ranked pairs winner found efficiently.12. characterization Zavist Tideman (1989) addresses irresolute version ranked pairsdiscussed previous footnote. adaptation resolute version ranked pairs straightforward corollary.524fiPossible Necessary Winners Partial Tournamentsp01p02p1p1p2p2p01p02c1c2c3Figure 12: partial 8-weighted tournament G Boolean formula = {p1 , p2 }{p1 , p2 } {p1 , p2 }. Double-shafted arrows represent heavy edges, standard arrows representmedium edges, dashed arrows represent light edges, dotted lines represent partial edges.pairs (a, b) connected arrow, w (x, y) = w (y, x) = 4.NP-hardness shown reduction Sat. construction basedproof Theorem 1 Brill Fischer (2012). Boolean formula conjunctivenormal-form set C clauses set P propositional variables, constructpartial 8-weighted tournament G = (V , w ) follows. variable p P , Vcontains two literal alternatives p p two auxiliary alternatives p0 p0 .clause c C, alternative c. Finally, alternativemembership PWRP (G ) decided.order conveniently describe weight function w , let us introduce followingterminology. two alternatives x, V , say heavy edge xw (x, y) = 8 (and therefore w (y, x) = 0). medium edge x means w (x, y) = 6w (y, x) = 2, light edge x means w (x, y) = 5 w (y, x) = 3.Finally, partial edge x means w (x, y) = w (y, x) = 1.ready define w . variable p P , heavy edgesp p0 p p0 , partial edges p p0 p p0 .clause c C, medium edge c heavy edge literalalternative ` (with ` = p ` = p p P ) c corresponding literal ` appearsclause c. Finally, heavy edges auxiliary alternatives light edgesliteral alternatives. pairs x, edge specified,define w (x, y) = w (y, x) = 4. example shown Figure 12. Observepairs alternatives w fully specified pairs connectedpartial edge.525fiAziz, Brill, Fischer, Harrenstein, Lang, & Seedig`0`0`````0`0cc0(ii ) Sc = (d, `0 , `, c)(i ) Sc = (d, ` , `, `0 , `, c)Figure 13: Two possibilities sequence Sc .show alternative possible ranked pairs winner Gsatisfiable. Intuitively, choosing completion (p0 , p) (p0 , p) correspondssetting variable p true.() First assume PWRP let [G ] completion GRP (T ) = {d}. Consider stack L top element alternative c correspondingclause . Since L stack L c, attains c though L via sequence Sc . (Ifattains c via several sequences, fix one arbitrarily.) Since w (c, d) = 6, edgessequence Sc must heavy, medium, appropriate completions partial edges.Therefore, Sc must one following two forms (depicted Figure 13):0Sc = (d, ` , `, `0 , `, c)Sc = (d, `0 , `, c),0` literal. former fact possible w (`, ` ) = 8 implies0` attain ` L. Therefore, Sc form Sc = (d, `0 , `, c)literal `.define assignment setting true literals contained onesequences Sc , c C. claim satisfying assignment .order show well-defined, suppose exists literal ` `` set true . implies exist c1 c2 attains c100via Sc1 = (d, `0 , `, c1 ) attains c2 via Sc2 = (d, ` , `, c2 ). particular, `0 L ` ` L `.00However, easily verified stack ranks ` higher ` (because w (`, ` ) = 8)0` higher `0 (because w (`, `0 ) = 8). Thus, L-cycle ` L ` L ` L `0 L `,contradicting assumption L stack.order show satisfies , consider arbitrary clause c. attains c viaSc = (d, `0 , `, c) w (c, d) = 6, w (`, yj ) 6. definition w (, ),implies literal ` appears clause c. Furthermore, ` set true `contained Sc .() direction, assume satisfiable let satisfyingassignment. use construct completion = (V , w ) [G ] RP (T ) = {d}.526fiPossible Necessary Winners Partial Tournamentspartial edges, weight function w defined follows. literal ` set true, let w (`0 , `) = 7 w (`, `0 ) = 1. Otherwise, let w (`0 , `) = 1 w (`, `0 ) = 7.show RP (T ) = {d} going procedure constructstransitive tournament 0 , starting empty tournament V .13 First, setedges weight 7 added, cycles amongedges. set consists heavy edges (previously) partial edges. Next,medium edges considered. edges form (c, d) c alternativecorresponding clause. Since satisfying assignment, 0 already contains pathsevery clause alternative c. Therefore, edges (c, d) c C discarded.next step, light edges (i.e., edges weight 5) considered. edgesform (d, `) literal `. Therefore, edges added 0 withoutcreating cycle (d ingoing edges 0 ). adding light edges,outgoing edge literal alternatives ` auxiliary alternatives `0 . Furthermore,edges clause candidate c already discarded. Thus, uniqueundominated alternative 0 , i.e., RP (T ) = {d}.Since ranked pairs method resolute, hardness PWSRP follows immediately.Corollary 2. PWSRP NP-complete.Computing necessary ranked pairs winners turns coNP-complete.somewhat surprising, computing necessary winners often considerably easier computing possible winners, partial tournaments partial preference profiles (Xia& Conitzer, 2011).Theorem 15. NWRP coNP-complete.Proof. Membership coNP obvious. hardness, give reductionUnSat slight variation reduction proof Theorem 14. Let G0partial 8-weighted tournament results form G adding new alternativeheavy edges alternatives V except d. Furthermore, light edge. show necessary ranked pairs winner G0unsatisfiable.() Assume contradiction NWRP (G0 ) = {d } satisfiable. Letsatisfying assignment define tournament = (V {d }, w0 ) [G0 ]w0 coincides w (as defined proof Theorem 14) partial edges.arguments proof Theorem 14, follows ingoingedges tournament 0 constructed ranked pairs procedure. pointtime edge (d, ) considered, added 0 . yields RP (T ) = {d},contradicting assumption NWRP (G0 ) = {d }.() Assume contradiction unsatisfiable exists completion[G0 ] RP (T ) = {x} 6= {d }. follows x = d. (All alternatives V \ {d}incoming heavy edge (from ), heavy edges addedcycle among them.) argument proof Theorem 14, followssatisfiable, contradicting assumption.13. following arguments independent choice particular tie-breaking rule.527fiAziz, Brill, Fischer, Harrenstein, Lang, & Seedig6. Possible Winning Subsetsconsidered problem whether subset alternatives possible winning set (PWS).addition, may interest whether subset alternatives among winnerscompletion, i.e., whether completion alternativessubset (and possibly alternatives) choice set. refer latterproblem PWSS (possible winning subset). note oracle solve PWSSused solve PW. want check whether PW (G), simply check whether{i} PWSS (G). aware direct algorithmic relation problemsPWS PWSS.examined computational complexity PWSSS solution conceptsconsidered article. Since arguments often similar proofs already given,briefly summarize findings here.COND never one Condorcet winner, every X PWSSCOND (G)singleton problem reduces computing PWCOND (G).CNL PWSSCNL , note nonempty set X V , X/ PWSSCNL (G)1|V | > 1 every completion GCondorcet winnerfurthermore located X. Therefore,|V | = 11X PWSSCNL (G)PWSCOND (G )1PWCOND (G ) \ X 6= .CO problems, polynomial computability PWSSCO followscorresponding result PWSSBO .TC problem PWSSTC solved polynomial time. fact, shownpartial tournament G set alternatives X, sufficient checkwhether X PWTC (G) (with additional argument |X| = 2) orderdetermine whether X PWSSTC (G).BO argument algorithm checking whether X PWSSBO (G) almostargument PWSBO Theorem 9. differencesBO (v, ) may instead 1 v V \ X [G].Consequently, need redefine bs (v) sBO (v, G) v V \ X.MM proof efficient computability checking whether X PWSMM (G)modified accommodate PWSSMM . precisely, second basic assumptionw(i, j)/ X, j V . = n2 , sufficient check whether G0extension G. < n2 , edges {i, {i, j}} X containedw(i, j) . rest argument adjusted appropriately.EH> n2 , nothing changes.RP Since PWRP NP-complete (Theorem 14), get NP-hardness PWSSRPoracle argument above. Since membership NP obvious, problemNP-complete.528fiPossible Necessary Winners Partial Tournamentscomplexity PWSSUC left open. Minor modification hardness construction PWSUC trick. argument, crucial question whethercompletion excludes certain alternatives choice set.help PWSSUC .7. Discussionproblem computing possible necessary winners partial preference profilesrecently received lot attention. article, investigated problemsetting partially specified (weighted unweighted) tournaments instead profilesgiven input. summarized findings Table 1.key conclusion computational problems partial tournaments significantly easier counterparts partial profiles. example, possible Bordamaximin winners found efficiently partial tournaments, whereas corresponding problems partial profiles NP-complete (Xia & Conitzer, 2011). Furthermore,computing possible necessary Copeland winners NP-hard coNP-hard respectively partial preference profiles (Xia & Conitzer, 2011). contrast, showedeven PWSCO solved polynomial time partial tournaments. negative(hardness) results, tempered fact parametersproblem bounded constant, hard problems may solved polynomial time. particular, Yang Guo (2013) shown PWSUC polynomial-timesolvable size given subset X bounded constant.14tractability winner determination problem necessary tractabilitypossible necessary winners problems, results ranked pairs Section 5.3 showsufficient. considered problem deciding whether givensubset alternatives equals winning set completion partial tournament.results uncovered set Section 4.4 imply problem cannot reducedpolynomial time computation possible necessary winners; whether reductionexists opposite direction remains open problem.Partial tournaments also studied right, independentpossible completions. instance, Peris Subiza (1999) Dutta Laslier (1999)generalized several solution concepts tournaments partial tournaments.common point approach follow nature input, namely, partial tournaments. However, Peris Subiza (1999) Dutta Laslier (1999) definesolution concepts partial tournaments directly generalizing usual definitiontournaments. contrast definitions, based completionsinput partial tournament. notion possible winners suggests canonical waygeneralize solution concept defined tournaments partial tournaments. wayextending tournament solutions partial tournaments referred conservativeextension inherits various axiomatic properties original tournament solutions satisfies tournaments (Brandt et al., 2014). positive computational resultsarticle indication may promising approach.14. Yang Guo (2013) also give hardness fixed-parameter tractability results generalizationBanks set partial tournaments.529fiAziz, Brill, Fischer, Harrenstein, Lang, & Seedigalso highlight another way viewing algorithmic results concerning possiblenecessary winners. burgeoning literature computational social choicedeals problem manipulation control voting (Bartholdi, III, Tovey, & Trick,1989, 1992; Faliszewski & Procaccia, 2010). given alternative already necessary winner, need invest effort influencing remaining comparisons votesmake winning. Moreover, results also implications partial tournamentversion coalitional manipulation problem: coalitional tournament manipulation,constructive version, defined follows. Given partial tournament (V, E), subset X V , distinguished alternative x, way complete missing edgesX X x winner? Informally, players X way fixingwinners matches among make x win?Constructive coalitional tournament manipulation polynomial-time solvable wheneverPW is. Likewise, destructive version coalitional tournament manipulation (isway complete edges within X candidate x winning?) polynomialwhenever NW is.Regarding future work, yet examined complexity computing possiblenecessary winners attractive tournament solutions minimal coveringset weighted versions top cycle uncovered set (De Donder, Le Breton, &Truchon, 2000).15interesting related question goes beyond computation possible necessary winners following: winners yet fully determined, unknowncomparisons need learned, pairs candidates compare,matches played? problem seen tournament-based versionpreference elicitation problem (Conitzer & Sandholm, 2002; Ding & Lin, 2013; Walsh,2008). standard version problem looks minimal sets queries voterspairwise preferences candidates, tournament version query bearspair candidates output edge two candidates, one directionother. Procaccia (2008) considers similar question COND. constructionpolicy tree defining optimal protocol minimizing number questions askednumber matches played, worst case average, evenchallenging issue leave future research.AcknowledgmentsPrevious versions paper presented 11th International ConferenceAutonomous Agents Multi-Agent Systems (AAMAS 2012) 4th International Workshop Computational Social Choice (COMSOC 2012). grateful FelixBrandt extensive discussions useful advice. also thank Gerhard Woegingerhints towards improving previous pseudo-polynomial time algorithms PWSBOPWSMM various anonymous reviewers, whose comments greatly helped us improvepaper. material based work supported Deutsche Forschungsgemeinschaft grants BR 2312/9-1, BR 2312/10-1, FI 1664/1-1. Haris Aziz supportedAustralian Government represented Department Broadband, Commu15. Brill, Freeman, Conitzer (2016) recently shown computing possible necessary winnersbipartisan set (Laffond, Laslier, & Le Breton, 1993) intractable.530fiPossible Necessary Winners Partial Tournamentsnications Digital Economy Australian Research Council ICTCentre Excellence program. Markus Brill supported Feodor Lynen researchfellowship Alexander von Humboldt Foundation ERC Starting Grant639945 (ACCORD). Jerome Lang supported ANR project CoCoRICoCoDec. Paul Harrenstein supported ERC Advanced Grant 291528(RACE).ReferencesAziz, H., Gaspers, S., Mackenzie, S., Mattei, N., Stursberg, P., & Walsh, T. (2014). Fixingbalanced knockout tournament. Proceedings 28th AAAI ConferenceArtificial Intelligence (pp. 552558). AAAI Press.Aziz, H., Walsh, T., & Xia, L. (2015). Possible necessary allocations via sequentialmechanisms. Proceedings 23rd International Joint Conference ArtificialIntelligence (pp. 468474).Bachrach, Y., Betzler, N., & Faliszewski, P. (2010). Probabilistic possible winner determination. Proceedings 24th AAAI Conference Artificial Intelligence (pp.697702). AAAI Press.Bartholdi, III, J., Tovey, C. A., & Trick, M. A. (1989). computational difficultymanipulating election. Social Choice Welfare, 6 (3), 227241.Bartholdi, III, J., Tovey, C. A., & Trick, M. A. (1992). hard control election?Mathematical Computer Modelling, 16 (89), 2740.Baumeister, D., Faliszewski, P., Lang, J., & Rothe, J. (2012). Campaigns lazy voters:truncated ballots. Proceedings 11th International Conference AutonomousAgents Multi-Agent Systems (pp. 577584). IFAAMAS.Baumeister, D., & Rothe, J. (2010). Taking final step full dichotomy possiblewinner problem pure scoring rules. Proceedings 19th European ConferenceArtificial Intelligence (pp. 10191020).Betzler, N., & Dorn, B. (2010). Towards dichotomy possible winner problemelections based scoring rules. Journal Computer System Sciences, 76 (8),812836.Betzler, N., Hemmann, S., & Niedermeier, R. (2009). multivariate complexity analysisdetermining possible winners given incomplete votes. Proceedings 21stInternational Joint Conference Artificial Intelligence (pp. 5358). AAAI Press.Brandt, F., Brill, M., & Harrenstein, P. (2014). Extending tournament solutions.Proceedings 28th AAAI Conference Artificial Intelligence (pp. 580586).AAAI Press.Brandt, F., Brill, M., & Harrenstein, P. (2016). Tournament solutions. F. Brandt,V. Conitzer, U. Endriss, J. Lang, & A. D. Procaccia (Eds.), Handbook Computational Social Choice (chap. 3). Cambridge University Press. (Forthcoming)531fiAziz, Brill, Fischer, Harrenstein, Lang, & SeedigBrill, M., & Fischer, F. (2012). price neutrality ranked pairs method.Proceedings 26th AAAI Conference Artificial Intelligence (pp. 12991305).AAAI Press.Brill, M., Freeman, R., & Conitzer, V. (2016). Computing possible necessary equilibrium actions (and bipartisan set winners). Proceedings 30th AAAI ConferenceArtificial Intelligence. AAAI Press. (Forthcoming)Chevaleyre, Y., Lang, J., Maudet, N., & Monnot, J. (2011). Compilation communication protocols voting rules dynamic set candidates. Proceedings13h Conference Theoretical Aspects Rationality Knowledge (pp. 153160).Chevaleyre, Y., Lang, J., Maudet, N., Monnot, J., & Xia, L. (2012). New candidates welcome! Possible winners respect addition new candidates. MathematicalSocial Sciences, 64 (1), 7488.Conitzer, V., & Sandholm, T. (2002). Vote elicitation: Complexity strategy-proofness.Proceedings 18th National Conference Artificial Intelligence (pp. 392397). AAAI Press.Cook, W. J., Cunningham, W. H., Pulleyblank, W. R., & Schrijver, A. (1998). Combinatorial optimization. Wiley Sons.De Donder, P., Le Breton, M., & Truchon, M. (2000). Choosing weighted tournament. Mathematical Social Sciences, 40 (1), 85109.Ding, N., & Lin, F. (2013). Voting partial information: questions ask?Proceedings 12th International Conference Autonomous Agents MultiAgent Systems (pp. 12371238). IFAAMAS.Dutta, B., & Laslier, J.-F. (1999). Comparison functions choice correspondences. SocialChoice Welfare, 16 (4), 513532.Edmonds, J. (1965). Paths, trees flowers. Canadian Journal Mathematics, 17 ,449467.Faliszewski, P., & Procaccia, A. D. (2010). AIs war manipulation: winning? AIMagazine, 31 (4), 5364.Filmus, Y., & Oren, J. (2014). Efficient voting via top-k elicitation scheme: probabilistic approach. Proceedings 15th ACM Conference EconomicsComputation (pp. 295312). ACM Press.Good, I. J. (1971). note Condorcet sets. Public Choice, 10 (1), 97101.Hazon, N., Aumann, Y., Kraus, S., & Wooldridge, M. (2012). evaluation electionoutcomes uncertainty. Artificial Intelligence, 189 , 118.Kalech, M., Kraus, S., Kaminka, G. A., & Goldman, C. V. (2011). Practical voting rulespartial information. Journal Autonomous Agents Multi-Agent Systems,22 (1), 151182.532fiPossible Necessary Winners Partial TournamentsKern, W., & Paulusma, D. (2004). computational complexity eliminationproblem generalized sports competitions. Discrete Optimization, 1 (2), 205214.Konczak, K., & Lang, J. (2005). Voting procedures incomplete preferences.Proceedings Multidisciplinary Workshop Advances Preference Handling(pp. 124129).Laffond, G., Laslier, J.-F., & Le Breton, M. (1993). bipartisan set tournamentgame. Games Economic Behavior , 5 (1), 182201.Lang, J., Pini, M. S., Rossi, F., Salvagnin, D., Venable, K. B., & Walsh, T. (2012). Winnerdetermination voting trees incomplete preferences weighted votes. JournalAutonomous Agents Multi-Agent Systems, 25 (1), 130157.Laslier, J.-F. (1997). Tournament solutions majority voting. Springer-Verlag.Lu, T., & Boutilier, C. (2011). Vote elicitation probabilistic preference models: Empirical estimation cost tradeoffs. Proceedings 2nd International ConferenceAlgorithmic Decision Theory (pp. 135149). Springer-Verlag.Lu, T., & Boutilier, C. (2013). Multiwinner social choice incomplete preferences.Proceedings 23rd International Joint Conference Artificial Intelligence (pp.263270). AAAI Press.Oren, J., Filmus, Y., & Boutilier, C. (2013). Efficient vote elicitation candidateuncertainty. Proceedings 23rd International Joint Conference ArtificialIntelligence (pp. 309316). AAAI Press.Peris, J. E., & Subiza, B. (1999). Condorcet choice correspondences weak tournaments.Social Choice Welfare, 16 (2), 217231.Pini, M. S., Rossi, F., Venable, K. B., & Walsh, T. (2011). Possible necessary winnersvoting trees: Majority graphs vs. profiles. Proceedings 10th InternationalConference Autonomous Agents Multi-Agent Systems (pp. 311318). IFAAMAS.Procaccia, A. (2008). note query complexity Condorcet winner. InformationProcessing Letters, 108 (6), 390393.Rastegari, B., Condon, A., Immorlica, N., & Leyton-Brown, K. (2013). Two-sided matchingpartial information. Proceedings 14th ACM Conference ElectronicCommerce (pp. 733750). ACM Press.Schrijver, A. (2003). Combinatorial optimizationpolyhedra efficiency. Springer.Schwartz, B. L. (1966). Possible winners partially completed tournaments. SIAM Review ,8 (3), 302308.Schwartz, T. (1986). logic collective choice. Columbia University Press.Smith, J. H. (1973). Aggregation preferences variable electorate. Econometrica,41 (6), 10271041.533fiAziz, Brill, Fischer, Harrenstein, Lang, & SeedigTideman, T. N. (1987). Independence clones criterion voting rules. Social ChoiceWelfare, 4 (3), 185206.Vu, T., Altman, A., & Shoham, Y. (2009). complexity schedule control problemsknockout tournaments. Proceedings 8th International ConferenceAutonomous Agents Multi-Agent Systems (pp. 225232). IFAAMAS.Walsh, T. (2007). Uncertainty preference elicitation aggregation. Proceedings22nd AAAI Conference Artificial Intelligence (pp. 38). AAAI Press.Walsh, T. (2008). Complexity terminating preference elicitation. Proceedings7th International Conference Autonomous Agents Multi-Agent Systems (pp.967974). IFAAMAS.Xia, L., & Conitzer, V. (2011). Determining possible necessary winners commonvoting rules given partial orders. Journal Artificial Intelligence Research, 41 , 2567.Yang, Y., & Guo, J. (2013). Possible winner problems partial tournaments: parameterized study. Proceedings 3rd International Conference AlgorithmicDecision Theory (Vol. 8176, pp. 425439). Springer-Verlag.Zavist, T. M., & Tideman, T. N. (1989). Complete independence clones rankedpairs rule. Social Choice Welfare, 6 (2), 167173.534fiJournal Artificial Intelligence Research 54 (2015) 1-57Submitted 09/14; published 09/15Knowledge-Based Textual Inference viaParse-Tree TransformationsRoy Bar-Haimbarhair@gmail.comIdo Dagandagan@cs.biu.ac.ilComputer Science Department, Bar-Ilan UniversityRamat-Gan 52900, IsraelJonathan Berantyonatan@cs.stanford.eduComputer Science Department, Stanford UniversityAbstractTextual inference important component many applications understandingnatural language. Classical approaches textual inference rely logical representationsmeaning, may regarded external natural language itself. However,practical applications usually adopt shallower lexical lexical-syntactic representations,correspond closely language structure. many cases, approaches lack principled meaning representation inference framework. describe inference formalismoperates directly language-based structures, particularly syntactic parse trees. Newtrees generated applying inference rules, provide unified representationvarying types inferences. use manual automatic methods generate rules,cover generic linguistic structures well specific lexical-based inferences. alsopresent novel packed data-structure corresponding inference algorithm allowsefficient implementation formalism. proved correctness new algorithmestablished efficiency analytically empirically. utility approachillustrated two tasks: unsupervised relation extraction large corpus,Recognizing Textual Entailment (RTE) benchmarks.1. IntroductionTextual inference Natural Language Processing (NLP) concerned deriving targetmeanings texts. textual entailment framework (Dagan, Roth, Sammons, &Zanzotto, 2013), reduced inferring textual statement (the hypothesis h)source text (t). Traditional approaches formal semantics perform inferenceslogical forms derived text. contrast, practical NLP applications avoidcomplexities logical interpretation. Instead, operate shallower representationsparse trees, possibly supplemented limited semantic information namedentities, semantic roles, forth. clearly demonstrated recent PASCALRecognizing Textual Entailment (RTE) Challenges (Dagan, Glickman, & Magnini, 2006b;Bar-Haim, Dagan, Dolan, Ferro, Giampiccolo, Magnini, & Szpektor, 2006; Giampiccolo,Magnini, Dagan, & Dolan, 2007; Giampiccolo, Trang Dang, Magnini, Dagan, & Dolan,2008; Bentivogli, Dagan, Dang, Giampiccolo, & Magnini, 2009; Bentivogli, Clark, Dagan,c2015AI Access Foundation. rights reserved.fiBar-Haim, Dagan & BerantDang, & Giampiccolo, 2010), popular framework evaluating application-independentsemantic inference.1Inference representations commonly made applying transformationssubstitutions tree graph representing text. transformations basedavailable knowledge paraphrases, lexical relations synonyms hyponyms,syntactic variations, (de Salvo Braz, Girju, Punyakanok, Roth, & Sammons,2005; Haghighi, Ng, & Manning, 2005; Kouylekov & Magnini, 2005; Harmeling, 2009).transformations may generally viewed inference rules. available semantic knowledge bases composed manually, either experts, example WordNet(Fellbaum, 1998), large community contributors, Wikipedia-basedDBPedia resource (Lehmann et al., 2009). knowledge bases learned automatically distributional pattern-based methods, using aligned monolingualbilingual parallel texts (Lin & Pantel, 2001; Shinyama, Sekine, Sudo, & Grishman,2002; Szpektor, Tanev, Dagan, & Coppola, 2004; Chklovski & Pantel, 2004; Bhagat &Ravichandran, 2008; Ganitkevitch, Van Durme, & Callison-Burch, 2013). Overall, appliedknowledge-based inference prominent line research gained much interest. Recent examples include series workshops Knowledge Reasoning AnsweringQuestions (Saint-Dizier & Mehta-Melkar, 2011) evaluation knowledge resourcesrecent Recognizing Textual Entailment challenges (Bentivogli et al., 2010).many applied systems use semantic knowledge inference rules,use typically limited, application-specific, somewhat heuristic. Formalizingpractices important textual inference research, analogous role well-formalizedmodels parsing machine translation. take step direction introducinggeneric inference formalism parse trees. formalism uses inference rules capturewide variety inference knowledge simple uniform manner, specifies smallset operations suffice broadly utilize knowledge.formalism, applying inference rule clear, intuitive interpretation generating new sentence parse (a consequent), semantically entailed source sentence.inferred consequent may subject rule applications, on. Rule applications may independent other, modifying disjoint parts source tree,may specify mutually-exclusive alternatives (e.g., different synonyms sourceword). Deriving hypothesis text analogous proof search logic,propositions parse trees deduction steps correspond rule applications.nave implementation formalism would generate consequent explicitlyseparate tree. However, discuss Section 5, implementation raisessevere efficiency issues, since number consequents may grow exponentiallynumber possible rule applications. Previous work proposed partial solutionsproblem (cf. Section 8). work present novel data-structure, termed compactforest, packed representation entailed consequents, corresponding inferencealgorithm. prove new algorithm valid implementation formalism,establish efficiency analytically, showing typical exponential-to-linear reduction,empirically, showing improvement orders magnitude. Together, formalism1. See, instance, listing techniques per submission provided organizers firstthree challenges (Dagan et al., 2006b; Bar-Haim et al., 2006; Giampiccolo et al., 2007).2fiKnowledge-Based Textual Inference via Parse-Tree Transformationsnovel efficient inference algorithm open way large-scale rule application withinwell-formalized framework.Based formalism inference algorithm, built inference engineincorporates variety semantic syntactic knowledge bases (cf. Section 6).evaluated inference engine following tasks:1. Unsupervised relation extraction large corpus. setting allows evaluationknowledge-based inferences real-world distribution texts.2. Recognizing textual entailment (RTE). cope complex RTE examples, complemented knowledge-based inference engine machine-learningbased entailment classifier, provides necessary approximate matching capabilities.inference engine shown substantial contribution tasks, illustratingutility approach.Bar-Haim, Dagan, Greental, Shnarch (2007) Bar-Haim, Berant, Dagan(2009) described earlier versions inference framework algorithm efficient implementation, respectively. current article includes major enhancementscontributions. formalism presented detail, includingexamples pseudo-code algorithms. present several extensions formalism, including treatment co-reference, traces long-range dependencies, enhancedmodeling polarity. efficient inference algorithm also presented detail,including pseudo-code. addition, provide complete proofs theorems,establish correctness algorithm. Finally, article contains extended analysisinference component RTE system, terms applicability, coverage,correctness rule applications.2. Backgroundsection, provide background textual entailment. survey variousapproaches applied task Recognizing Textual Entailment (RTE). particular,focus use semantic knowledge within current RTE systems.2.1 Textual EntailmentMany semantic applications need identify meaning expressed by,inferred from, various language expressions. example, Question-Answering systemsneed verify retrieved passage text entails selected answer. Given questionJohn Lennons widow?, text Yoko Ono unveiled bronze statue latehusband, John Lennon, complete official renaming Englands Liverpool AirportLiverpool John Lennon Airport. entails expected answer Yoko Ono John Lennonswidow 2 . Similarly, Information Extraction systems need validate given textindeed entails semantic relation expected hold extracted slot fillers(e.g., X works ). Information Retrieval queries Alzheimers drug treatment32. example taken RTE-2 dataset (Bar-Haim et al., 2006).3. one topics TREC-6 IR benchmark (Voorhees & Harman, 1997).3fiBar-Haim, Dagan & Berantrephrased propositions (e.g., Alzheimers disease treated using drugs),expected entailed relevant documents. selecting sentencesincluded summary, multi-document summarization systems verifymeaning candidate sentence entailed sentences already summary,avoid redundancy.observation led Dagan Glickman propose unifying framework modelinglanguage variability, termed Textual Entailment (TE) (Dagan & Glickman, 2004). Daganet al. (2006b) define TE follows:say entails h if, typically, human reading would infer hlikely true. somewhat informal definition based (and assumes) common human understanding language well common background knowledge.Dagan et al. (2013) discuss TE definition relation classical semanticentailment linguistics literature. Recognizing Textual Entailment Challenges (RTE),held annually since 2004 (Dagan et al., 2006b; Bar-Haim et al., 2006;Giampiccolo et al., 2007, 2008; Bentivogli et al., 2009, 2010), formed growing researchcommunity around task.holy grail TE research development entailment engines, usedgeneric modules within different semantic applications, similar current usesyntactic parsers morphological analyzers. Since textual entailment definedrelation surface texts, bound particular semantic representation.allows black-box view entailment engine, input/output interfaceindependent internal implementation, may employ different typessemantic representations inference methods.2.2 Determining EntailmentConsider following (t,h) pair4 :hoddest thing UAE 500,000 2 millionpeople living country UAE citizens.population United Arab Emirates 2 million.Understanding h involves several inference steps. First, inferreduced relative clause 2 million people living country proposition:(1) 2 million people live country.Next, observe country refers UAE, rewrite (1)(2) 2 million people live UAE.Knowing UAE acronym United Arab Emirates, obtain:(3) 2 million people live United Arab Emirates.4. Taken RTE1 test set (Dagan et al., 2006b).4fiKnowledge-Based Textual Inference via Parse-Tree Transformationsfinally paraphrase obtain h:(4) population United Arab Emirates 2 million.general, textual inference involves diverse linguistic world knowledge, includingknowledge relevant syntactic phenomena (e.g., relative clauses), paraphrasing (X peoplelive population X ), lexical knowledge (UAE United Arab Emirates),on. may also require co-reference resolution, example, substituting country UAE. may think types knowledge representing inferencerules define derivation new entailed propositions consequents. workintroduce formal inference framework based inference rule application. currentdiscussion, however, informal notion inference rules would suffice.example illustrates derivation h sequence inferencerule applications, procedure generally known forward chaining. Finding sequencerule applications would get us h (or close possible) thus searchproblem, defined space possible rule application chains.Ideally, would like base entailment engine solely trusted knowledge-basedinferences. practice, however, available knowledge incomplete, full derivation hoften feasible. Therefore, requiring strict knowledge-based proofs likelyyield limited recall. Alternatively, may back heuristic approximateentailment classification.next two sections survey two complementary inference types: knowledgebased inference, focus research, approximate entailment matchingclassification.2.3 Knowledge-Based Inferencesection, describe common resources inference rules (2.3.1),use textual entailment systems (2.3.2).2.3.1 Semantic Knowledge ResourcesLexical Knowledge Lexical-semantic relations words phrases play important role textual inference. prominent lexical resource WordNet (Fellbaum,1998), manually composed wide-coverage lexical-semantic database. following WordNet relations typically used inference: synonyms (buy purchase), antonyms (winlose), hypernyms/hyponyms (is-a relations, violin musical instrument), meronyms(part-of relations, Provence France) derivations meeting meet.Many researchers aimed deriving lexical relations automatically, using diverse methods sources. Much automatically-extracted knowledge complementaryWordNet, however, typically less accurate. Snow, Jurafsky, Ng (2006a) presentedmethod automatically expanding WordNet new synsets, achieving high precision.Lins thesaurus (Lin, 1998) based distributional similarity. Recently, several worksaimed extract lexical-semantic knowledge Wikipedia, using metadata, welltextual definitions (Kazama & Torisawa, 2007; Ponzetto & Strube, 2007; Shnarch, Barak,& Dagan, 2009; Lehmann et al., 2009, others). recent empirical study5fiBar-Haim, Dagan & Berantinferential utility common lexical resources, see work Mirkin, Dagan, Shnarch(2009).Paraphrases Lexical-Syntactic Inference Rules rules typically represententailment equivalence predicates, including correct mappingarguments (e.g., acquisition X X purchase ). Much work dedicatedunsupervised learning relations comparable corpora (Barzilay & McKeown, 2001; Barzilay & Lee, 2003; Pang, Knight, & Marcu, 2003), querying Web(Ravichandran & Hovy, 2002; Szpektor et al., 2004), local corpus (Lin & Pantel,2001; Glickman & Dagan, 2003; Bhagat & Ravichandran, 2008; Szpektor & Dagan, 2008;Yates & Etzioni, 2009). particular, textual entailment systems widely usedDIRT resource Lin Pantel. common idea underlying algorithms,predicates sharing argument instantiations likely semantically related.NomLex-Plus (Meyers, Reeves, Macleod, Szekeley, Zielinska, & Young, 2004) lexicon containing mostly nominalizations verbs, allowed argument structures (e.g.,Xs acquisition Y/Ys acquisition X etc.). Argument-mapped WordNet (AmWN)(Szpektor & Dagan, 2009) resource inference rules verbal nominal predicates, including argument mapping. based WordNet NomLex-Plus,verified statistically intersection unary-DIRT algorithm (Szpektor &Dagan, 2008).Syntactic Transformations Textual entailment often involves inference genericsyntactic phenomena passive/active transformations, appositions, conjunctions, etc.,illustrated following examples:John smiled laughed John laughed (conjunction)neighbor, John, came John neighbor (apposition)paper Im reading interesting Im reading paper (relative clause).Syntactic transformations addressed extent de Salvo Braz et al.(2005) Romano, Kouylekov, Szpektor, Dagan, Lavelli (2006). describe novelsyntactic rule base entailment, based survey relevant linguistic literature, wellextensive data analysis (Sections 6.16.2).2.3.2 Use Semantic Knowledge Textual Entailment SystemsFollowing description common knowledge sources textual inference, discussuse knowledge textual entailment systems.Textual entailment systems usually represent h trees graphs, basedsyntactic parse, predicate-argument structure, various semantic relations. Entailmentdetermined measuring well h matched (or embedded ) t, estimatingdistance h, commonly defined cost transforming h.next section, briefly cover various methods proposed approximatematching heuristic transformations graphs trees. role semantic knowledgegeneral scheme bridge gaps h stem languagevariability. example, applying lexical-semantic rule purchase buy allowsmatching word buy appearing h word purchase appearing t.6fiKnowledge-Based Textual Inference via Parse-Tree TransformationsRTE systems restrict type allowed inference rules search space.Systems based lexical (word-based phrase-based) matching h (Haghighi et al.,2005; MacCartney, Galley, & Manning, 2008) heuristic transformation h(Kouylekov & Magnini, 2005; Harmeling, 2009) typically apply lexical rules (withoutvariables), sides rule matched directly h.Hickl (2008) derived given (t, h) pair small set consequents termsdiscourse commitments. commitments generated several different toolstechniques, based syntax (conjunctions, appositions, relative clauses, etc.), co-reference,predicate-argument structure, extraction certain relations, paraphrase acquisitionWeb. Pairs commitments derived h fed next stagesRTE system lexical alignment entailment classification. Prior commitmentgeneration, several linguistic preprocessing modules applied text, includingsyntactic dependency parsing, semantic dependency parsing, named entity recognition,co-reference resolution. Hickl employed probabilistic finite-state transducer (FST)-basedextraction framework commitment generation, extraction rules modeledseries weighted regular expressions. commitments textual form fedback system, additional commitments generated.De Salvo Braz et al. (2005) first incorporate syntactic semantic inferencerules comprehensive entailment system. system, inference rules appliedhybrid syntactic-semantic structures called concept graphs. left hand side (LHS)rule matched concept graph, graph augmented instantiationright hand side (RHS) rule. several iterations rule application,system attempts embed hypothesis augmented graph. types semanticknowledge, verb normalization lexical substitutions, applied eitherrule application (at preprocessing time) rule application, part hypothesissubsumption (embedding).Several entailment systems based logical inference. Bos Markert (2005, 2006)represented h DRS structures used Discourse Representation Theory (Kamp &Reyle, 1993), translated first-order logic. Background knowledge(BK) encoded axioms, comprised lexical relations WordNet, geographicalknowledge, small set manually composed axioms encoding generic knowledge.Bos Markert used logic theorem prover find proof entails h (alonetogether background knowledge BK), h inconsistent(implying non-entailment) background knowledge. logic provercomplemented model builder aimed find counter-examples (e.g., modelh holds). logical inference system suffered low coverage, due limitedbackground knowledge available, able find proofs small fractionRTE2 dataset. Therefore, RTE system Bos Markert combined logical inferenceshallow approximate matching method, based mainly word overlap.LCCs logic-based entailment system (Tatu & Moldovan, 2006) one top performers RTE2 RTE3 (Tatu, Iles, Slavick, Novischi, & Moldovan, 2006; Tatu &Moldovan, 2007). based proprietary tools deriving rich semantic representations, extensive knowledge engineering. syntactic parses htransformed logic forms (Moldovan & Rus, 2001), representation enrichedvariety relations extracted semantic parser, well named entities7fiBar-Haim, Dagan & Beranttemporal relations. Inference knowledge included on-demand axioms based extendedWordNet lexical chains, WordNet glosses, NLP rewrite rules. Additional knowledgetypes included several hundreds world knowledge axioms, temporal axioms, semantic composition axioms (e.g., encoding transitivity kinship relation). Basedrich semantic representation extensive set axioms, theorem prover aimedprove refutation entails h. proof failed, h repeatedly simplifiedproof found, reducing proof score simplification.2.4 Approximate Entailment ClassificationSemantic knowledge always incomplete. Therefore, cases, knowledge-based inference must complemented approximate, heuristic methods determining entailment. RTE systems employ limited amount semantic knowledge,focus methods approximate entailment classification. common architectureRTE systems (Hickl, Bensley, Williams, Roberts, Rink, & Shi, 2006; Snow, Vanderwende,& Menezes, 2006b; MacCartney, Grenager, de Marneffe, Cer, & Manning, 2006) comprisesfollowing stages:1. Linguistic processing: Includes syntactic (and possibly semantic) parsing, namedentity recognition, co-reference resolution, etc. Often, h represented treesgraphs, nodes correspond words edges represent relationswords.2. Alignment: Find best mapping h nodes nodes, taking accountnode edge matching.3. Entailment classification: Based alignment found, set features extractedpassed classifier determining entailment. features measurealignment quality, also try detect cues false entailment. example,node h negated aligned node negated, may indicate falseentailment.alternative approach aims transform text hypothesis, ratheraligning them. Kouylekov Magnini (2005) applied tree edit distance algorithmtextual entailment. edit operation (node insertion/deletion/substitution) assignedcost. algorithm aims find minimum-cost sequence operations transformh. Mehdad Magnini (2009b) proposed method estimating costedit operation based Particle Swarm Optimization. Wang Manning (2010)presented probabilistic tree-edit approach models edit operations using structuredlatent variables. Tree edits represented state transitions Finite-State Machine(FSM), model parameterized Conditional Random Field (CRF). Harmeling(2009) developed probabilistic transformation-based approach. defined fixed setoperations, including syntactic transformations, WordNet-based substitutions,heuristic transformations adding/removing verb noun. probabilitytransformation estimated development set. Similarly, Heilman Smith(2010) classify entailment based sequence edits transforming h. employgeneric edit operations greedy search heuristic, guided cost functionmeasures remaining distance h using tree kernel.8fiKnowledge-Based Textual Inference via Parse-Tree TransformationsZanzotto, Pennacchiotti, Moschitti (2009) aimed classify given (t, h) pairanalogy similar pairs training set. method based finding intra-pairalignment (i.e., h) capturing transformation h, interpair alignment, capturing analogy new pair (t, h) previously seenpair (t0 , h0 ). cross-pair similarity kernel computed, based tree kernel similarityapplied aligned texts aligned hypotheses. Another cross-pair similarity kernelproposed Wang Neumann (2007). extracted tree skeletons h,consisting left right spines, defined unlexicalized paths starting root.found sections h spines differ compared sections across pairsusing subsequence kernel.3. Research Goalgoal textual entailment research develop entailment engines usedgeneric inference components within various text-understanding applications. Logic-basedentailment systems provide formalized expressive framework textual inference.However, deriving logic representations text complex task, available toolsmatch accuracy robustness current syntactic parsers (which often basissemantic parsing). Furthermore, interpretation logic forms often unnecessary,many common inferences modeled shallower representations.follows textual entailment systems (and text-understanding applicationsgeneral) operate lexical-syntactic representations, possibly supplementedpartial semantic annotation. However, unlike logic-based approaches, systemslack clear, unified formalism knowledge representation inference; insteademploy multiple representations inference mechanisms. notable exceptionnatural logic framework MacCartney Manning (2009), rather differentfocus current work. discuss Section 8.work, develop well-formalized entailment approach lexical-syntacticlevel. formalism models wide variety inference rules composition, basedunified representation small set inference operations. Moreover, presentefficient implementation formalism using novel data structure algorithmallow compact representation proof search space.see contribution work practical theoretical. practical(or engineering) perspective, formalism may simplify development entailmentsystems, number representations inference mechanisms need dealtminimal. Furthermore, efficient implementation may allow entailment enginesexplore much larger search spaces. theoretical perspective, concise, formal modelingleads better insight phenomenon investigation. particular,formal model entailment engine makes possible apply formal methods investigating properties. enabled us prove correctness efficient implementationformalism (cf. Appendix A). next present inference formalism.9fiBar-Haim, Dagan & BerantRuleTypeSyntacticSourcesExamplesManually-composedLexicalLearned unsupervised algorithms (DIRT, TEASE),derived automatically integrating information WordNetNomlex, verified using corpusstatistics (AmWN)WordNet, WikipediaPassive/active, apposition, relativeclause, conjunctionsXs wife, X marriedSyntacticLexicalX bought sold XX maker X producessteal take, AlbanianAlbaniaJanis JoplinsingerAmazonSouth AmericaTable 1: Representing diverse knowledge types inference rules4. Inference Formalism Parse Treesprevious sections highlighted need principled, well-formalized approachtextual inference lexical-syntactic level. section, propose step towardsfilling gap, defining formalism textual inference parse-based representations. semantic knowledge required inference represented inference rules,encode parse tree transformations. rule application generates new consequent sentence (represented parse tree) source tree. Figure 1b shows sample inferencerule, representing passive-to-active transformation.knowledge representation usage perspective, inference rules provide simpleunifying formalism representing applying broad range inference knowledge.examples breadth illustrated Table 1. knowledge acquisitionperspective, representing inference rules lexical-syntactic level allows easy incorporation rules learned unsupervised methods, important scaling inferencesystems. Interpretation stipulated semantic representations, often difficultinherently supervised semantic task learning, circumvented altogether.historical machine translation perspective, approach similar transfer-based translation, contrasted semantic interpretation Interlingua. overall research goalexplore reach inference approach, identify scopesemantic interpretation may needed.Given syntactically parsed source text set inference rules, formalismdefines set consequents derivable text using rules. consequentobtained sequence rule applications, generating intermediate parsetree, similar proof process logic. addition, new consequents may inferred basedco-reference relations identified traces. formalism also includes annotation rulesadd features existing trees. According formalism, text entails hypothesish h consequent t.rest section, define illustrate formalism components:sentence representation (Section 4.1), inference rules application (Sections 4.24.3), inference based co-reference relations traces (Section 4.4), annotation10fiKnowledge-Based Textual Inference via Parse-Tree TransformationsInput: source tree ; rule E : L ROutput: set derived treesset matches Lfl subtree matched L according match f// R instantiationr copy Rvariable v rInstantiate v f (v)aligned pair nodes uL l uR rdaughter uL/ lCopy subtree rooted uR r, dependency relation// Derived tree generationsubstitution rulecopy l (and descendants nodes) replaced relse // introduction ruledraddAlgorithm 1: Applying rule treerules (Section 4.5). components form inference process specifies setinferable consequents given text set rules (Section 4.6). Section 4.7 extendshypothesis definition, allowing h template rather proposition. Finally,Section 4.8 discusses limitations possible extensions formalism.4.1 Sentence Representationassume sentences represented form parse trees. work, focusdependency tree representation, often preferred directly capture predicateargument relations. Two dependency trees shown Figure 1a. Nodes represent wordshold set features values. features include word lemmapart-of-speech, additional features may added inference process.Edges annotated dependency relations.4.2 Inference Rulesentailment (or inference) rule L R primarily composed two templates, lefthand-side (LHS) L right-hand-side (RHS) R. Templates dependency subtrees,may contain POS-tagged variables, matching lemma. Figure 1 shows passiveto-active transformation rule, illustrates application.rule application procedure given Algorithm 1. Rule application generates setderived trees (consequents) source tree steps described below.11fiBar-Haim, Dagan & Berantrootrain VERBexpletiverwha,ADJrMary NOUNmodsee VERBobjqmodbysubjVERBPREP,yesterday NOUNpcompnlittle ADJJohn NOUNSource: rained little Mary seen John yesterday.rootrain VERBrexpletivewha,ADJsubjrJohn NOUNsee VERBobjmod,Mary NOUN yesterday NOUNmodlittle ADJDerived: rained John saw little Mary yesterday.(a) Passive-to-active tree transformationV VERBobjLuN1 NOUNV VERBbysubjsubjobj)u)VERBPREPN2 NOUNN1 NOUNpcompnRN2 NOUN(b) Passive active substitution rule.Figure 1: Application inference rule. POS relation labels based Minipar(Lin, 1998). N 1, N 2 V variables, whose instances L R implicitly aligned.by-subj dependency relation indicates passive sentence.12fiKnowledge-Based Textual Inference via Parse-Tree TransformationsrootrootV1 VERB V2 VERBLwhaRADJV2 VERBFigure 2: Temporal clausal modifier extraction (introduction rule)4.2.1 L MatchingFirst, matches L source tree sought. L matched existsone-to-one node mapping function f L s, that:1. node u L, f (u) features feature values u. Variablesmatch lemma value f (u).2. edge u v L, edge f (u) f (v) s, dependencyrelation.matching fails, rule applicable s. example, variable V matchedverb see, N 1 matched Mary N 2 matched John. matching succeeds,following performed match found.4.2.2 R Instantiationcopy R generated variables instantiated according matching nodeL. addition, rule may specify alignments, defined partial function L nodesR nodes. alignment indicates modifier source nodepart rule structure, subtree rooted also copied modifiertarget node. addition explicitly defining alignments, variable L implicitlyaligned counterpart R. example, alignment V nodes impliesyesterday (modifying see) copied generated sentence, similarlylittle (modifying Mary) copied N 1.4.2.3 Derived Tree GenerationLet r instantiated R, along descendants copied L alignment,l subtree matched L. formalism two methods generatingderived tree d: substitution introduction, specified rule type. Substitutionrules specify modification subtree s, leaving rest unchanged. Thus,formed copying replacing l (and descendants ls nodes) r.case passive rule, well lexical rules buy purchase.contrast, introduction rules used make inferences subtree s,parts ignored affect d. typical example inferring propositionembedded relative clause s. case, derived tree simply taken13fiBar-Haim, Dagan & Berantrootrootbuy VERBsubjpurchase VERBobjsubjobjv(v(John NOUNbooks NOUNJohn NOUNbooks NOUNJohn bought books.Lbuy VERBJohn purchased books.purchase VERBRFigure 3: Application lexical substitution rule. dotted arc represents explicitalignment.r. Figure 2 presents rule, enables deriving propositions embeddedwithin temporal modifiers. Note derived tree depend main clause.Applying rule right part Figure 1a yields proposition John saw littleMary yesterday.4.3 Examples Rule Applicationsection illustrate rule representation application additionalexamples.4.3.1 Lexical Substitution Rule Explicit AlignmentFigure 3 shows derivation consequent John purchased books sentenceJohn bought books using lexical substitution rule buy purchase. exampleillustrates role explicit alignment: since buy purchase variables,implicitly aligned. However, need aligned explicitly, otherwise daughtersbuy would copied purchase.4.3.2 Lexical-Syntactic Introduction RuleFigure 4 illustrates application lexical-syntactic rule, derives sentencehusband died knew late husband. defined introduction rule, sinceresulting tree derived based solely phrase late husband, ignoringrest source tree. example illustrates leaf variable L (variableleaf node) may become non-leaf R vice versa. alignmentinstances variable N (matched husband ) allows copying modifier, (recallalignments defined implicitly formalism). note correctnessrule application may depend context applied. instance,rule example correct late meaning longer alive givencontext. discuss context-sensitivity rule application Section 4.8.14fiKnowledge-Based Textual Inference via Parse-Tree Transformationsrootrootknow VERBsubjdie VERBobjsubjv(NOUNhusband NOUNgenhusband NOUNmodv(NOUNlate ADJgenNOUNknew late husband.husband died.rootLN NOUNdie VERBsubjmodlate ADJRN NOUNFigure 4: Application lexical-syntactic introduction rule4.4 Co-Reference Trace-Based InferenceAside primary inference mechanism rule application, formalism also allowsinference based co-reference relations long-distance dependencies. view coreference equivalence relation complete subtrees, either within treedifferent trees, linked co-reference chain. practice, relationsobtained external co-reference resolution tool, part text pre-processing.co-reference substitution operation similar application substitution rule.Given pair co-referring subtrees, t1 t2 , derived tree generated copyingtree containing t1 , replacing t1 t2 ; operation symmetricallyapplicable t2 .5 example, given sentences [My brother] musician. [He] playsdrums, infer brother plays drums.Long-distance dependencies another type useful relation inference, illustrated following examples:(1) Relative clause: boyi [I saw ti ] went home.( saw boy.)(2) Control verbs: Johni managed [ti open door].( John opened door.)5. view co-referring expressions substitutional also found seminal paper vanDeemter Kibble (2000), noun phrases shown non-substitutable evidenceco-referring.15fiBar-Haim, Dagan & Berant(3) Verbal conjunction: [Johni sang] [ti danced].( John danced.)parsers including Minipar, use current work, recognize annotatelong distance dependencies. instance, Minipar generates node representingtrace (ti examples), holds pointer antecedent (e.g., Johni (2)).shown examples, inference sentences may involve resolving long- distancedependencies, traces substituted antecedent. Thus, generalizeco-reference substitution operate trace-antecedent pairs, well. mechanismworks together inference rule application. instance, substituting traceantecedent (2) obtain John managed [John opened door].apply introduction rule N managed extract embedded clause Johnopened door.4.5 Polarity Annotation Rulesaddition inference rules, formalism implementation includes mechanismadding semantic features parse tree nodes. However, many cases naturalway define semantic features classes. Hence, often difficult agree rightset semantic annotations (a common example definition word senses).approach, aim keep semantic annotation minimum, sticking lexicalsyntactic representation, widely-agreed schemes exist.Consequently, semantic annotation employ predicate polarity. featuremarks truth predicate, may take one following values: positive(+),negative(-) unknown(?). examples polarity annotation shown below:(4) John called[+] Mary.(5) John hasnt called[] Mary yet.(6) John forgot call[] Mary.(7) John might called[?] Mary.(8) John wanted call[?] Mary.Sentences (5) (6) entail John didnt call Mary, hence negative annotationcall. contrast, truth John called Mary cannot determined (7) (8),therefore predicate call marked unknown. general, polarity predicatesmay affected existence modals, negation, conditionals, certain verbs, etc.Technically, annotation rules right-hand-side R, rather node Lmay contain annotation features. L matched tree, annotations containscopied matched nodes. Figure 5 shows example annotation rule application.Predicates assumed positive polarity default. polarity rules usedmark negative unknown polarity. one rule applies predicate(as sentence John forgot call Mary), may applied order,following simple calculus employed combine current polarity new polarity:16fiKnowledge-Based Textual Inference via Parse-Tree TransformationsrootV[]Llisten[]subjVERBVERBv(VERBJohn NOUNVERBnegnegADJADJJohn listening[] .(a) Annotation rule(b) Annotated sentenceFigure 5: Application annotation rule (a), marking predicate listen negativepolarity (b)Current polarity+?+/ /?New polarity?Result+??Annotation rules used detecting polarity mismatches text hypothesis. Incompatible polarity would block hypothesis matched text.case approximate entailment classification, polarity mismatches detectedannotation rules used features classifier, discuss Section 7.3.addition, existence polarity annotation features may prevent inappropriate inferencerule applications, blocking L matching. discuss Section 6.1.4.6 Inference ProcessLet set dependency trees representing text, along co-referencetrace information. Let h dependency tree representing hypothesis, let Rcollection inference rules (including inference polarity rules). Basedpreviously defined components inference framework, next give proceduraldefinition set trees inferable using R, denoted I(T, R). inferenceprocess comprises following steps:1. Initialize I(T, R) .2. Apply matching polarity rules R trees I(T, R) (cf. Section 4.5).3. Replace trace nodes copy antecedent subtree (cf. Section 4.4).4. Add I(T, R) trees derivable co-reference substitution (cf. Section 4.4).17fiBar-Haim, Dagan & Berant5. Apply matching inference rules R trees I(T, R) (cf. Section 4.2),add derived trees I(T, R). Repeat step iteratively newly addedtrees, new trees added.Steps 2 3 performed h well.6 h inferable using R h I(T, R).Since I(T, R) may infinite large, practical implementation process mustlimit search space, example restricting number iterations appliedrules iteration.inference rule applied, polarity annotation propagated sourcetree derived tree follows. First, nodes copied retain originalpolarity. Second, node gets polarity aligned node s.4.7 Template Hypothesesmany applications useful allow hypothesis h template ratherproposition, is, contain variables. variables case existentially quantified: entails h exists proposition h0 , obtained h variable instantiation,entails h0 . variable X instantiated (replaced) subtree SX . Xmodifiers h (i.e., X leaf), become modifiers SX root. obtainedvariable instantiations may stand answers sought questions slots filled relation extraction. example, applying framework question-answering setting,question killed Kennedy? may transformed hypothesis X killed Kennedy.successful proof h sentence assassination Kennedy Oswald shooknation would instantiate X Oswald, providing sought answer.4.8 Limitations Possible Extensionsconclude section discussing limitations presented inference formalism,well possible extensions address limitations. First, inference rules matchsingle subtree, therefore less expressive logic axioms used BosMarkert (2005) Tatu Moldovan (2006), may combine several predicatesoriginating text representation well background knowledge.allows logic-based systems make inferences combine multiple pieces information.instance, text says person X lives city , background knowledgetells us city country Z, infer X lives country Z, usingrule person(X) location(Y) location(Z) live(X,Y) in(Y,Z) live(X,Z) .Schoenmackers, Etzioni, Weld, Davis (2010) describe system acquires rules(first-order horn clauses) Web text. Allowing rules match multiple subtreest, well information background knowledge, seems plausible future extensionformalism.Another limitation formalism lack context disambiguation. Word sensemismatch potential cause incorrect rule applications. example, rule hitscore applied correctly (9) (10):6. Step 4 applied h since hypothesis typically short, simple sentence usuallyinclude co-referring NPs. Moreover, presented formalism h single tree. Applying co-referencebased inference would resulted additional trees inferred h, thus would requiredextending formalism accordingly.18fiKnowledge-Based Textual Inference via Parse-Tree Transformations(9) team hit home run. team scored home run.(10) car hit tree. ; car scored tree.Several works past years addressed problem context-dependent rule application (Dagan, Glickman, Gliozzo, Marmorshtein, & Strapparava, 2006a; Pantel, Bhagat,Coppola, Chklovski, & Hovy, 2007; Connor & Roth, 2007; Szpektor, Dagan, Bar-Haim, &Goldberger, 2008; Dinu & Lapata, 2010; Ritter, Mausam, & Etzioni, 2010; Berant, Dagan,& Goldberger, 2011; Melamud, Berant, Dagan, Goldberger, & Szpektor, 2013). Szpektoret al. (2008) proposed comprehensive framework modeling context matching, termedContextual Preferences (CP). Given text t, hypothesis h (possibly template hypothesis) inference rule r bridging h, objects annotatedtwo context components: (a) global (topical) context, (b) preferences constraints instantiation objects variables (for r template h). CP requiresh r matched t, h matched r7 , context componentmatched counterpart. Szpektor et al. also proposed concrete implementationscomponents. example, could model global contextr sets content words, compute semantic relatednesstwo sets, using methods Latent Semantic Analysis (LSA) (Deerwester, Dumais,Furnas, Landauer, & Harshman, 1990), Explicit Semantic Analysis (ESA) (Gabrilovich& Markovitch, 2007). would expect semantic relatedness {score}{team, home run} much higher {score} {car, tree}, wouldpermit inference (9) (10).RTE systems (including system RTE experiments, describedSection 7.3) lexicalized rules bridge h directly, rules LHSRHS matched h, respectively. Since RTE benchmarks h tendsemantic context, setting alleviates context matching problemsextent. However, analysis, presented later work (Subsection 7.5.2), showscontext matching remains issue even setting, expected become evenimportant chaining lexicalized rules attempted. Adding contextual preferencesformalism important direction future work.validity rule application also depends monotonicity properties application site. instance, hypernym rule poodle dog applicable upwardmonotone contexts. Monotonicity may affected presence quantifiers, negation, certain verbs implicatives counterfactives (Nairn, Condoravdi, &Karttunen, 2006). common textual entailment systems, assume upward monotonicity anywhere. assumption usually holds true, cases may leadincorrect inferences. following examples show correct applications ruleupward monotone contexts ((11),(14)), incorrect applications downward monotonecontexts ((12),(13),(15)):(11) bought poodle. bought dog.(12) didnt buy poodle ; didnt buy dog(13) Poodles smart. ; Dogs smart.7. Context matching, like textual entailment, directional relation.19fiBar-Haim, Dagan & Berant(14) failed avoid buying poodle failed avoid buying dog.(15) fail avoid buying poodle ; fail avoid buying dog.MacCartney Manning (2009) address monotonicity well semantic relationsexclusion, Natural Logic framework based syntactic representation.discuss work detail Section 8.Finally, since polarity annotation rules applied locally, may fail complexcases, computing polarity buying sentences (14) (15), polarityinformation need propagated along syntactic structure sentence.TruthTeller system (Lotan, Stern, & Dagan, 2013), computes predicate polarity (truthvalue) combination annotation rules global polarity propagation algorithm,extending previous work Nairn et al. (2006) MacCartney Manning (2009).4.9 Summarysection, presented well-formalized approach textual inference parsebased representations, core paper. framework, semantic knowledgerepresented uniformly inference rules specifying tree transformations. provideddetailed definitions representation rules well inference mechanismsapply them. formalism also models inferences based co-reference relationstraces. addition, includes annotation rules used detect contexts affectingpolarity predicates. next section present efficient implementationformalism.5. Compact Forest Scalable InferenceAccording formalism, rule application generates new sentence parse (a consequent), semantically entailed source sentence. inferred consequent maysubject rule applications, on. straightforward implementationformalism would generate consequent separate tree. Unfortunately, naveapproach raises severe efficiency issues, since number consequents may grow exponentially number rule applications. Consider, example, sentence Childrenfond candies, following rules: childrenkids, candiessweets, Xfond YX likes Y. number derivable sentences, including source sentence,would 23 (the power set size), rule either applied not, independently.found exponential explosion leads poor scalability nave implementationapproach practice.Intuitively, would like rule application add entailed part rule(e.g., kids) packed sentence representation. Yet, still want resulting structurerepresent set entailed sentences, rather mixture sentence fragmentsunclear semantics. discussed Section 8, previous work proposed partial solutionsproblem.section, introduce novel data structure, termed compact forest, corresponding inference algorithm, efficiently generate represent consequentspreserving identity individual one. data structure allows compact representation large set inferred trees. rule application generates explicitly20fiKnowledge-Based Textual Inference via Parse-Tree Transformationsnodes rules right-hand-side. rest consequent tree shared sourcesentence, also reduces number redundant rule applications, explained latersection. show representation based primarily disjunction edges,extension dependency edges specify set alternative edges multiple trees.Since follow well-defined inference formalism, able prove inferenceoperations formalism equivalently applied compact forest. compareinference cost compact forests explicit consequent generation theoretically,illustrating exponential-to-linear complexity ratio, empirically, showing improvementorders magnitude (empirical results reported Section 7.2).5.1 Compact Forest Data Structurecompact forest F represents set dependency trees. Figure 6d shows examplecompact forest containing trees sentences Little Mary seen John yesterdayJohn saw little Mary yesterday. first define general data structuredirected graphs, narrow definition case trees.Compact Directed Graph (cDG) pair G = (V, E) V set nodes Eset disjunction edges (d-edges). Let set dependency relations. d-edgetriple (Sd , reld , Td ), Sd Td disjoint sets source nodes targetnodes; reld : Sd function specifying dependency relation correspondssource node. Graphically, d-edges shown point nodes, incoming edgessource nodes outgoing edges target nodes. instance, let bottommostd-edge Figure 7. Sd = {of, like}, Td = {candy, sweet}, rel(of ) = pcomp-n,rel(like) = obj .d-edge represents, si Sd , set alternative directed edges {(si , tj ) : tjTd }, labeled relation given reld (si ). edges,termed embedded edge (e-edge), would correspond different graph represented G.objobjpcompnprevious example, e-edges likecandy, likesweet, ofcandypcompnofsweet (the definition implies source nodes Sd setalternative target nodes Td ). d-edge called outgoing d-edge node v v Sdincoming d-edge v v Td . Compact Directed Acyclic Graph (cDAG)cDG contains cycles e-edges.DAG G rooted node v V cDAG G embedded G derivedfollows: initialize G v alone; then, expand v choosing exactly one targetnode Td outgoing d-edge v, adding corresponding e-edge(v, t) G. expansion process repeated recursively new node added G.set choices results different DAG v root. Figure 6d,may choose connect root either left see, resulting source passivesentence, right see, resulting derived active sentence.Compact Forest F cDAG single root r (i.e., r incoming d-edges)embedded DAGs rooted r trees. set trees, termed embeddedtrees, denoted (F) comprise set trees represented F.Figure 7 shows another example compact forest efficiently representing 23 sentences resulting three independently applied rules presented beginningsection.21fiBar-Haim, Dagan & BerantROOTROOTseeVby-subj objMarypcomp-nJohnseemodby-subj objyesterdaymodpcomp-nlittlemodyesterdaylittle(b) Variable instantiationROOTROOTseeobjmodJohn(a) Right-hand-side generationby-subjMaryseeseeseeby-subjmod modseemodmodobjobjsubjpcomp-nJohnMaryyesterdaymodyesterdaypcomp-nlittleJohn(c) Alignment sharingMarymodlittle(d) Dual-leaf variable sharingFigure 6: Step-by-step construction compact forest containing source sentence Little Mary seen John yesterday sentence John saw little Maryyesterday derived via application passive rule Figure 1b. Partsspeech omitted.5.2 Inference Processnext describe algorithm implementing inference process described Section 4.6compact forest (henceforth, compact inference), illustrated Figures 1b (thepassive-to-active rule) 6.22fiKnowledge-Based Textual Inference via Parse-Tree TransformationsROOTpredfondlikemod subjsubjobjchildkidpcomp-ncandysweetFigure 7: compact forest representing 23 sentences derivable sentence Children fond candies using following three rules: childrenkids, candiessweets,X fond YX likes Y.5.2.1 Forest InitializationF initialized set dependency trees representing text sentences,roots connected forest root target nodes single d-edge. Dependencyedges transformed trivially d-edges single source target. Annotationrules applied stage initial F. Figure 6a, without node labeled Vincoming edge, corresponds initial forest (containing single sentenceexample).5.2.2 Inference Rule ApplicationInference rule application comprises steps described below, summarizedAlgorithm 2.L Matching first find matches rules LHS L forest F (line 1).sake brevity, omitted technical details L matching implementationpseudocode Algorithm 2. following high-level description matchingprocedure, focusing key algorithmic points.L matched F exists embedded tree F L matchedt, Section 4.2. denote l subtree L matched (line 3).23fiBar-Haim, Dagan & BerantInput: compact forest F ; inference rule E : L ROutput: modified F, denoted F 0 , (F 0 ) = (F) D, set trees derivedapplying E subset Ls matches trees (F)1: set matches L F2: match f3:l subtree F L matched according f4:5:6:7:8:9:10:11:12:13:14:// Right-hand-side generationSR copy R excluding dual leaf variable nodesAdd SR FSL l excluding dual leaf variable nodesrR root(SR )rL root(l)E substitution ruleincoming d-edge rL // set SR alternative SLelse // introduction ruleoutgoing d-edge root(F) // set SR alternative trees (F)Add rR Td15:16:17:18:19:// Variable instantiationvariable X held node xR SR // Rs variables excluding dual leavesX leaf LxL f (X) // node SL matched X(xR .lemma, xR .polarity) (xL .lemma, xL .polarity)20:21:22:23:24:25:26:else // X leaf L matched whole target node set(xR .lemma, xR .polarity) (n.lemma, n.polarity) node n f (X)n0 f (X); n0 6= ngenerate substitution rule n n0 n n0 aligned, apply xRx0R instantiation n0u SL u aligned xRadd alignment u x0R27:28:29:30:31:32:// Alignment sharingaligned pair nodes nL SL nR SRnR .polarity nL .polarityoutgoing d-edge nL whose e-edges part SLAdd nR Sdreld (nR ) reld (nL )33:34:35:36:// Dual leaf variable sharingdual-leaf variable X matched node v lincoming d-edge vp parent node X SR37:38:39:40:41:// go p alternatives p generated variable instantiationP set target nodes ps incoming d-edgep0 PAdd p0 Sdreld (p0 ) relation X pAlgorithm 2: Applying inference rule compact forest24fiKnowledge-Based Textual Inference via Parse-Tree Transformationssubtree may shared multiple trees represented F, case ruleapplied simultaneously trees. Section 4.2, match example(V, N 1, N 2)=(see, Mary, John). definition allow l scatteredmultiple embedded trees. Matches constructed incrementally, aiming add Ls nodesone one partial matches constructed far, verifying candidate nodeF node content corresponding edge labels match. also verifiedmatch contain one e-edge d-edge. nodes Findexed using hash table enable fast lookup.target nodes d-edge specify alternatives position tree,parts-of-speech expected substitutable. assume target nodesd-edge part-of-speech8 polarity. Consequently, variablesleaves L may match certain target node d-edge mapped wholeset target nodes Td rather single node. yields compact representationmultiple matches, prevents redundant rule applications. instance, given compactrepresentation {Children/kids} fond {candies/sweets} (cf. Figure 7), rule Xfond YX likes matched applied once, rather four times (forcombination matching X ).Right-Hand-Side Generation Given inference rule L R, define dual-leafvariable variable leaf L R. example, N 1 N 2dual-leaf variables passive-to-active rule Figure 1b. Variablesnode R (and hence root leaf), variables additionalalignments (other implicit alignment occurrences L R)considered dual-leaves. explained below, instantiations dual leaf variablesshared source target trees.right-hand-side generation step, template SR (line 5), consisting Rexcluding dual-leaf variables, generated inserted F (line 6). example,SR includes node V passive rules RHS. Similarly, define SL lexcluding dual-leaf variables (line 7).case substitution rule (as example), SR set alternative SLadding SR root Td , incoming d-edge SL root (line 11). caseintroduction rule, set alternative trees forest addingSR root target node set forest roots outgoing d-edge (line 13). Figure 6aillustrates results step example. SR gray node labeledvariable V , becomes additional target node d-edge entering original(left) see.Variable Instantiation variable SR (i.e., non dual-leaf) instantiated (lines16-26) according match L (as Section 4.2). example, V instantiatedsee (Figure 6b, lines 17-19). specified above, variable SR leaf L (whichcase example) matched set nodes,instantiated SR (lines 20-26). decomposed sequence simpleroperations: first, SR instantiated representative set (line 21).apply ad-hoc lexical substitution rules creating new node additional node8. case current implementation, based coarse tag-set Minipar.25fiBar-Haim, Dagan & Berantset (line 22-26). nodes, addition usual alignment source nodesSL (lines 25-26), share daughters SR (due alignment nn0 , defined line 23).Alignment Sharing Modifiers aligned nodes shared (rather copied) follows.Given node nL SL aligned node nR SR , outgoing d-edge nLpart l, share nL nR adding nR Sd settingreld (nR ) = reld (nL ) (lines 28-32). example (Figure 6c), aligned nodes nLnR left right see nodes, respectively, shared modifier yesterday.dependency relation mod copied right see node. also copy polarity annotationnL nR (line 29).note point instantiation variables dual leaves cannotshared typically different modifiers two sides rule. Yet,modifiers, part rule, shared alignment operation(recall common variables always considered aligned). Dual leaf variables,hand, might shared, described next, since rule doesnt specify modifiersthem.Dual Leaf Variable Sharing final step (lines 34-41) performed similarlyalignment sharing. Suppose dual leaf variable X matched node v l whoseincoming d-edge d. simply add parent p X SR Sd set reld (p)relation p X (in R). Since v shared, modifiers become sharedwell, implicitly implementing alignment operation. subtrees little Mary Johnshared way variables N 1 N 2 (Figure 6d). ad-hoc substitution rulesapplied p variable instantiation phase, generated nodes serve alternativeparents X, thus sharing procedure applied p repeated them.Applying rule example added single node linked four d-edges,compared duplicating whole tree explicit inference.5.2.3 Co-reference SubstitutionSection 4.4 defined co-reference substitution, inference operation allows replacing subtree t1 co-referring subtree t2 . operation implemented generatingon-the-fly substitution rule t1 t2 applying t1 . implementation,initial compact forest annotated co-reference relations obtained externalco-reference resolution tool, substitutions performed prior rule applications.Substitutions t2 pronoun ignored, usually useful.5.3 Correctnesssection, present two theorems proving inference process presentedvalid implementation inference formalism. provide full proofs Appendix A.Theorem 1, argue applying rule compact forest results compactforest. Since begin valid compact forest created initialization step, followsinduction sequence rule applications result inference processcompact forest. fact embedded DAGs generated inferenceprocess indeed trees trivial, since nodes generally many incoming e-edges26fiKnowledge-Based Textual Inference via Parse-Tree Transformationsmany nodes. However, show pair parent nodes cannot partembedded DAG. example, Figure 7, node candy incominge-edge node like node . However, nodes likepart embedded DAG. d-edge emanating rootforces us choose node like node be. Thus, see reasoncorrectness local: two incoming e-edges leaf node candies cannotembedded DAG rule applied root tree. turntheorem proof scheme:Theorem 1 Applying rule compact forest results compact forest.Proof scheme prove applying rule compact forest creates cycleembedded DAG tree, cycle non-tree DAG already existedprior rule application. contradicts assumption original structurecompact forest. crucial observation proof directed pathnode u node v passes SR , u v outside SR , alsoanalogous path u v passes SL instead.next theorem main result. argue inference process compactforest complete sound, is, generates exactly set consequents derivabletext according inference formalism.Theorem 2 Given rule base R set initial trees , tree representedcompact forest derivable inference process consequent accordinginference formalism.Proof scheme first show completeness induction number explicit ruleapplications. Let tn+1 tree derived tree tn using rule rn accordinginference formalism. inductive assumption determines tn embeddedderivable compact forest F. easy verify applying rn F yield compactforest F 0 tn+1 embedded.Next, show soundness induction number rule applicationscompact forest. Let tn+1 tree represented derived compact forest Fn+1 (tn+1(F n+1 )). Fn+1 derived compact forest Fn , using rule rn . inductiveassertion states trees (F n ) consequents according formalism.Hence, tn+1 already (F n ) consequent . Otherwise, shownexists tree tn (F n ) applying rn tn yield tn+1 accordingformalism. tn consequent according inductive assertion thereforetn+1 consequent well.two theorems guarantee compact inference process valid, is,yields compact forest represents exactly set consequents derivable giventext given rule set.27fiBar-Haim, Dagan & Berant5.4 Complexitysection, explain compact inference exponentially reduces time spacecomplexity typical scenarios.consider set rule matches tree independent matched left-handsides (excluding dual-leaf variables) overlap , applicationchained order. example, three rule matches presented Figure 7independent.Let us consider explicit inference first. Assume start single tree kindependent rules matched. Applying k rules yield 2k trees, since subsetrules might applied . Therefore, time space complexity applying kindependent rule matches (2k ). Applying rules newly derived consequentsbehaves similar manner.Next, examine compact inference. Applying rule using compact inference addsright-hand-side rule shares existing d-edges. Since sizeright-hand-side number outgoing d-edges per node practically boundedlow constants, applying k rules tree yields linear increase size forest.Thus, resulting size O(|T | + k), see Figure 7.time complexity rule application composed matching rule forestapplying matched rule. Applying matched rule linear size. Matchingrule size r forest F takes O(|F|r ) time even performing exhaustivesearch matches forest. Since r tends quite small boundedlow constant9 , already gives polynomial time complexity. Furthermore, matchesconstructed incrementally, step aim extend partial matches found.Due typical low connectivity forest, well various constraints imposedrule (lemma, POS, dependency relation), number candidates extendingmatches step << |F|, candidates retrieved efficiently usingproper indexing. Thus, matching procedure fast practice, illustratedempirical evaluation described Section 7.2.5.5 Related Work Packed RepresentationsPacked representations various NLP tasks share common principles, also underliecompact forest: factoring common substructures representing choice localdisjunctions. Applying general scheme individual problems typically requires specific representations algorithms, depending type alternativesrepresented specified operations creating them. create alternatives ruleapplication, newly derived subtree set alternative existing subtrees.Alternatives specified locally using d-edges.Packed chart representations parse forests introduced classical parsing algorithms CYK Earley (Jurafsky & Martin, 2008), extended laterwork various purposes (Maxwell III & Kaplan, 1991; Kay, 1996). Alternativesparse chart stem syntactic ambiguities, specified locally possible decompositions phrase sub-phrases.9. RTE system, average rule LHS size found 2 nodes, maximal size 7nodes, experimental setting described Section 7.2.2, applied RTE3 test set.28fiKnowledge-Based Textual Inference via Parse-Tree TransformationsPacked representations also utilized transfer-based machine translation.Emele Dorna (1998) translated packed source language representation packed targetlanguage representation avoiding unnecessary unpacking transfer. Unlikerule application, work transfer rules preserve ambiguity stemming sourcelanguage, rather generating new alternatives. Mi et al. (2008) applied statisticalmachine translation source language parse forest, rather 1-best parse.transfer rules tree-to-string, contrary tree-to-tree rules, chainingattempted (rules applied single top-down pass source forest). Thus,representation algorithms quite different ours.6. Incorporated Knowledge Basessection, describe various knowledge bases used inference engine.first describe novel rule base addressing generic linguistic structures. rule basecomposed manually, based formalism, includes inference rules (Section 6.1)polarity annotation rules (Section 6.2). addition, derived inference rulesseveral large scale semantic resources (Section 6.3). Overall, variety illustratessuitability formalism representing diverse types inference knowledge.6.1 Inference Rules Generic Linguistic Phenomenarules capture inferences associated common syntactic structures,summarized Table 2. rules three major functions:1. Simplification canonization source tree (categories 6 7 Table 2).2. Extracting embedded propositions (categories 1, 2, 3).3. Inferring propositions non-propositional subtrees source tree (category 4).Inference rules merely extract subtree source tree without changingstructure (such relative clause rule) useful exact inference aims generatehypothesis, used evaluation inferences (cf. Section 7.1). However, currently implemented approximate classification features focused matchingsubstructures hypothesis forest (as described Section 7.3), hencetake advantage extractions. Therefore, rules excluded restexperiments, reported Sections 7.27.3.rules categories 1-7 depend solely syntactic structure closed-class words,referred generic rules. contrast, verb complement extraction rules (category8) considered lexicalized rules, since specific certain verbs: replace forcedadvised example, entailment would hold. extracted PARCpolarity lexicon (Nairn et al., 2006) list verbs allow inference appearingpositive polarity contexts, generated inference rules verbs. listcomplemented reporting verbs, say announce, since informationnews domain, rules applied experiments (cf. Section 7.1)often given reported speech, speaker usually considered reliable.sidestep issue polarity propagation applying rules mainclause, implemented including tree root node rule LHS.29fiBar-Haim, Dagan & Berant#1CategoryConjunctions2Clausal extractionconnectivesRelativeclauses34Appositives5DeterminerCanonization6Passive7Genitivemodifier8Verb complement clauseextractionExample: sourceHelenas experiencedplayed long timetour.celebrations mutedmany Iranians observedShiite mourning month.assailants fired six bullets car, carriedVladimir Skobtsov.Frank Robinson, onetime manager Indians, distinctionNL.plaintiffs filed lawsuit last year U.S. DistrictCourt Miami.approachedinvestment banker.Malaysias crude palm oiloutput estimatedrisen six percent.Yadav forced resign.Example: derivedHelena played longtime tour.Many Iranians observedShiite mourning month.car carried VladimirSkobtsov.Frank Robinson onetime manager Indians.plaintiffs filed lawsuit last year U.S. DistrictCourt Miami.investment banker approached us.crude palm oil output Malaysia estimatedrisen six percent.Yadav resigned.Table 2: Inference rules generic linguistic structuresembedded clause extracted, becomes main clause derived tree, rulesextract embedded clauses. polarity verb detected applyingannotation rules, described next. verb annotated negative unknownpolarity, matching complement extraction rules fails. example, last sentenceTable 2 Yadav forced resign, forced would annotated negativepolarity, consequently matching corresponding complement extraction rulewould fail, Yadav resigned would entailed. Hence, annotation rules may blockerroneous inference rule applications. polarity important correct applicationrules, case rule types, passive-to-active transformation.therefore checked polarity matching rule application exact inferenceexperiment (Section 7.1), verb complement extraction rules used. leaveanalysis polarity-dependence rules future work.6.2 Polarity Annotation Rulesuse annotation rules mark negative unknown polarity predicates (cf. Section 4.5). Table 3 summarizes polarity-inducing contexts address. Like inference rules, annotation rules also comprise generic rules (categories 1-4) lexicalized30fiKnowledge-Based Textual Inference via Parse-Tree Transformations#1CategoryExplicit Negation234Implied NegationModal AuxiliariesOvert Conditionals567Verb complementsAdjectivesAdverbsExampleweve never seen[] actual costs comedown.one stayed[] last lecture.could eat[?] whale now!Venus wins[?] game, meet[?] Sarenafinals.pretend know[] calculus.impossible survived[] fall.probably danced[?] night.Table 3: Polarity annotation rulesrules (categories 5-7). verb complement embedded clause negative unknownpolarity, extracted, however, polarity annotated (category 5; comparecategory 8 Table 2). list verbs imply negative/unknown polarityclausal complements taken PARC lexicon, well VerbNet (Kipper,2005).6.3 Lexical Lexical-Syntactic Rulesaddition manually-composed generic rules, system integrates inference knowledge variety large-scale semantic resources, introduced Section 2.3. information derived resources represented uniformly inference rulesformalism. examples rules shown Table 1. following resourcesused:WordNet: extracted WordNet (Fellbaum, 1998) lexical rules based synonym, hyponym (a word entailed hyponym, e.g., dog animal ), instancehyponym 10 derivation relations.Wikipedia: used lexical rulebase Shnarch et al. (2009), extracted rulesJanis Joplin singer Wikipedia based metadata (e.g.,links redirects) text definitions, using patterns X .11DIRT: DIRT algorithm (Lin & Pantel, 2001) learns corpus inference rulesbinary predicates, example, X fond YX likes Y. usedversion learns canonical rule forms (Szpektor & Dagan, 2007).Argument-Mapped WordNet (AmWN): resource inference rules predicates, covering verbal nominal forms (Szpektor & Dagan, 2009), includ10. According WordNet glossary, instance proper noun refers particular, uniquereferent (as distinguished nouns refer classes). specific form hyponym.example, Ganges instance river.11. addition extraction methods described Shnarch et al. (2009), employed two additionalmethods. First, extraction entailments among terms redirected page. Second,generalization rules RHS common LHS head, different modifiers. instance,rules Ferrari F430 car Ferrari Ascari car generalized Ferrari car .31fiBar-Haim, Dagan & Beranting argument mapping. based WordNet NomLex-plus (Meyerset al., 2004), verified statistically intersection unary-DIRT algorithm (Szpektor & Dagan, 2008). AmWN rules defined unary templates,example, kill XX dieautomatically-extracted inference rules lack two attributes defined formalism: rule type (substitution/introduction) explicit alignments (beyond alignmentsRs variables L counterparts, defined default). attributes added automatically using following heuristics:1. roots L R part-of-speech, substitution rule(e.g., X buy sold X ). Otherwise (e.g., Ys acquisition Xsold X ), introduction rule.2. roots L R assumed aligned.Note application rules, (e.g., WordNet derivationsrules learned DIRT), result valid parse tree. rulesused aiming exact derivation h t. However, may usefulinference engine used together approximate matching component,RTE system. approximate matcher (described Section 7.3) employs featurescoverage words subtrees h F, therefore benefitinferences. rules preferably applied last step inferenceprocess, avoid cascading errors.7. Evaluationsection, present empirical evaluation entailment system whole,well evaluation individual components. evaluate quality systemsoutput (in terms accuracy, precision, recall) computational efficiency (in termsrunning time space, using various application settings.first evaluate knowledge-based inference engine. Section 7.1, describeexperiment engine aims prove simple template hypotheses, representingbinary predicates, texts sampled large corpus. Next, Section 7.2 evaluateefficiency engine implementation using compact forest data structure.evaluate complete entailment system, including approximate entailment classifier(Section 7.3). Finally, Sections 7.47.5 provide in-depth analysis performanceinference component RTE data.7.1 Proof System Evaluationexperiment, evaluate inference engine finding strict proofs. is,inference process must derive precisely target hypothesis (or instantiationit, case template hypotheses, contain variables defined Section 4.7).Thus, evaluate precision text-hypothesis pairs complete proofchain found, using available rules. note PASCAL RTE datasetssuitable purpose. rather small datasets include many text-hypothesis pairs32fiKnowledge-Based Textual Inference via Parse-Tree Transformationsavailable inference rules would suffice deriving complete proofs. Furthermore,since focus research applied textual inference, inference engineevaluated NLP application setting texts represent realistic distributionlinguistic phenomena. Manually-composed benchmarks FraCas test suite(Cooper et al., 1996), contains synthetic examples specific semantic phenomena,clearly suitable evaluation.alternative, chose Relation Extraction (RE) setting, completeproofs achieved large number corpus sentences. setting, systemneeds identify pairs arguments sentences target semantic relation (e.g., X buy).7.1.1 System Configurationexperiment, first reported Bar-Haim et al. (2007), used earlierversion engine rule bases. engine experiment make usecompact forest, rather generates consequent explicitly. Polarity annotationspropagated source derived trees. Instead, polarity annotation rulesapplied original text t, inferred consequent, prior applicationinference rule. following rule bases used experiment:Generic Linguistic Rules used generic rule base presented Section 6, including inference polarity annotation rules. early version includelexicalized polarity rules derived VerbNet PARC lexicon (category 5Table 3).Lexical-Syntactic Rules Nominalization rules: inference rules Xs acquisitionX acquired capture relations verbs nominalizations.rules derived automatically (Ron, 2006) Nomlex, hand-coded databaseEnglish nominalizations (Macleod, Grishman, Meyers, Barrett, & Reeves, 1998),WordNet.Automatically Learned Rules: used DIRT paraphrase collection, welloutput TEASE (Szpektor et al., 2004), another unsupervised algorithm learninglexical-syntactic rules. TEASE acquires entailment relations Web giveninput template identifying characteristic variable instantiations sharedtemplates. algorithms provide ranked list output templates given inputtemplate. learned rules linguistic paraphrases, (e.g., X confirm Xapprove ), others capture world knowledge, (e.g., X buy X ).algorithms learn entailment direction rule, reduces accuracyapplied given direction. system, considered top 15 bi-directionalrules learned template.Generic Default Rules rules used define default behavior, situationscase-by-case rules available. used one default rule allows removalmodifiers nodes. Ideally, rule would replaced future workspecific rules removing modifiers.33fiBar-Haim, Dagan & Berant7.1.2 Evaluation Processuse sample test template hypotheses correspond typical relations,X approve Y. identify large test corpus, sentences instantiationtest hypothesis proved. example, sentence budget approvedparliament found prove instantiated hypothesis parliament approve budget(via passive-to-active inference rule). Finally, sample candidate sentenceshypothesis pairs judged manually true entailment. repeated process comparedifferent system configurations.Since publicly available sample output TEASE much smallerresources12 randomly selected resource 9 transitive verbs may correspondtypical predicates13 . formed test templates adding subject object varisubjable nodes. example, verb accuse constructed template XNOUNobjaccuse VERB YNOUN .test template h identify sentences corpus templateproved system. efficiently find proof chains generate h corpussentences combine forward backward (Breadth-First) searches availablerules. First, use backward search lexical-syntactic rules, starting ruleswhose right-hand-side identical test template. process backward chainingDIRT/TEASE nominalization rules generates set templates ti ,proving (deriving) h. example, hypothesis X approve may generatetemplate X confirm Y, backward application DIRT/TEASE rule,generate template confirmation X, nominalization rule.Since templates ti generated lexical-syntactic rules, modify open-classlexical items, may considered lexical expansions h.Next, specific ti generate search engine query composed open-classwords ti . query fetches candidate sentences corpus, ti mightproven using generic linguistic rules (recall rules modify openclass words). end, use forward search applies generic rules, startingcandidate sentence trying derive ti sequence rule applications.successful, variables ti instantiated (cf. Section 4.7). Consequently, knowvariable instantiations, h proven (since derives ti turnderives h).performed search sentences prove test templateReuters RCV1 corpus, CD#2, applying Minipar parsing. random sampling,obtained 30 sentences prove (according tested system configuration)9 test templates, yielding total 270 pairs sentence, instantiated hypothesis, four tested configurations, described (1080 pairs overall).pairs split entailment judgment two human annotators (graduate studentsBar-Ilan NLP group). annotators achieved, sample 100 shared exam12. output TEASE DIRT, well many knowledge resources, available RTEknowledge resources page:http://aclweb.org/aclwiki/index.php?title=RTE_Knowledge_Resources13. verbs approach, approve, consult, lead, observe, play, seek, sign, strike.34fiKnowledge-Based Textual Inference via Parse-Tree Transformations#1234ConfigurationBaseline (embed h anywhere s)Proof (embed h root s)Proof + GenericProof + Generic + Lexical-SyntacticPrecision67.0%78.5%74.8%23.6%Yield2,4141,4262,96718,809Table 4: Proof system evaluationples, agreement level 87%, Kappa value 0.71 (corresponding substantialagreement).7.1.3 Resultstested four configurations proof system:1. Baseline: baseline configuration follows prominent approach graph-basedentailment systems: system tries embed given hypothesis anywherecandidate sentence tree s, negative unknown polarity (detectedannotation rules) may block embedding.2. Proof: configuration h strictly generated candidate sentence s. inference rule available default rule removing modifiers(polarity annotation rules active Baseline). configuration equivalentembedding h root h matched root s, since modifierspart match removed default rule. However,h embedded elsewhere extracted, opposed Baselineconfiguration.3. Proof + Generic: Proof, plus generic linguistic rules.4. Proof + Generic + Lexical-Syntactic: previous configuration, pluslexical-syntactic rules.system configuration measure precision, percentage examples judgedcorrect (entailing), average extrapolated yield, expected numbertruly entailing sentences corpus would proven system.extrapolated yield specific template calculated number sample sentencesjudged entailing, multiplied sampling proportion. average calculatedtest templates. note that, similar IR evaluations, possible computetrue recall setting since total number entailing sentences corpusknown (recall equal yield divided total). However, straightforwardmeasure relative recall differences among different configurations based yield. Thus,using two measures estimated large corpus possible conduct robustcomparison different configurations, reliably estimate impact differentrule types. analysis possible RTE datasets, rather small,hand-picked examples represent actual distribution linguistic phenomena.35fiBar-Haim, Dagan & Berantresults reported Table 4. First, comparing results Proofresults Baseline, observe requirement matching h root (i.e.,main clause s), rather allowing matched anywhere s, improvesprecision considerably baseline (by 11.5%), reducing yield nearly 40%.Proof configuration avoids errors resulting improper extraction embeddedclauses.Remarkably, using generic inference rules, system able gain back lostyield Proof surpass yield baseline configuration. addition,obtain higher precision baseline (a 7.8% difference), statisticallysignificant p < 0.05 level, using z test proportions. demonstratesprincipled proof approach appears superior heuristic baseline embeddingapproach, exemplifies contribution generic rule base. Overall, generic rulesused 46% proofs.Adding lexical-syntactic rules increased yield factor six. showsimportance acquiring lexical-syntactic variability patterns. However, precisionDIRT TEASE currently quite low, causing overall low precision. Manual filteringrules learned systems currently required obtain reasonable precision.Error analysis revealed third configuration Proof + Generic rules,significant 65% errors due parsing errors, notably incorrect dependencyrelation assignment, incorrect POS assignment, incorrect argument selection, incorrect analysis complex verbs (e.g., play text vs. play hypothesis) ungrammatical sentence fragments. Another 30% errors represent conditionals, negation,modality phenomena, could handled additional rules, making use elaborate syntactic information verb tense. remaining,rather small, 5% errors represent truly ambiguous sentences would requireconsiderable world knowledge successful analysis.7.2 Compact Forest Efficiency EvaluationNext, evaluate efficiency compact inference (cf. Section 5) setting recognizing textual entailment, using RTE-3 RTE-4 datasets (Giampiccolo et al., 2007,2008). datasets consist (text, hypothesis) pairs, need classifiedentailing/non entailing. first experiment, using generic inference rule set, showscompact inference outperforms explicit inference (efficiency-wise) orders magnitude (Section 7.2.1). second experiment shows compact inference scales wellfull-blown RTE setting several large-scale rule bases, hundreds rulesapplied per text (Section 7.2.2).7.2.1 Compact vs. Explicit Inferencecompare explicit compact inference randomly sampled 100 pairs RTE-3development set, parsed text pair using Minipar (Lin, 1998). avoidmemory overflow explicit inference, applied sentences subsetgeneric inference rules described Section 6.1. fair comparison, aimed makeexplicit inference implementation reasonably efficient, example preventing multiplegenerations tree different permutations rule applications.36fiKnowledge-Based Textual Inference via Parse-Tree TransformationsTime (msec)Rule applicationsNode countEdge endpointsCompact611269141Explicit24,1841235,90111,552Ratio396108682Table 5: Compact vs. explicit inference, using generic rules. Results averaged pertext-hypothesis pair.configurations perform rule application iteratively, new matches found.iteration, first find rule matches apply matching rules. compare runtime, number rule applications, overall generated size nodes edges,edge size represented sum endpoints (2 regular edge, |Sd | + |Td |d-edge).results summarized Table 5. expected, results show compactinference orders magnitude efficient explicit inference. avoid memoryoverflow, inference terminated reaching 100,000 nodes. Three 100 testtexts reached limit explicit inference, maximal node count compactinference 268. number rule applications reduced due sharingcommon subtrees compact forest, single rule application operatessimultaneously large number embedded trees. results suggest scalinglarger rule bases longer inference chains would feasible compact inference,prohibitive explicit inference.7.2.2 Application RTE Systemgoal second experiment test compact inference scales well broadinference rule bases. experiment used Bar-Ilan RTE system (Bar-Haim et al.,2008). system operates two primary stages:Inference: inference rules first applied initial compact forest F, aiming bringcloser hypothesis h. experiment, use knowledge basesdescribed Section 6. Overall, rule bases contain millions rules.current system implemented simple search strategy, spirit(de Salvo Braz et al., 2005): first, applied three exhaustive iterations genericrules. Since rules low fan-out (few possible right-hand-sides givenleft-hand-side), affordable apply chain freely. iterationfirst find rule matches, apply matched rules. avoid repeatedidentical rule applications, mark newly added nodes iteration,next iteration consider matches containing new nodes. perform singleiteration lexical lexical-syntactic rules, applying Lpart matched F R part matched h. investigationeffective search heuristics representation left future research.Classification: Following inference, set features extracted resulting Fh fed SVM classifier, determines entailment. describe37fiBar-Haim, Dagan & BerantRule applicationsNode countEdge endpointsRTE3-DevAvg. Max.1427571606155 1,741RTE4Avg. Max.1511080357173 1,062Table 6: Application compact inference RTE-3 Dev. RTE-4 datasets, usingrule typesclassification stage detail next section, discusses performanceRTE system.Table 6 provides statistics rule applications using rule bases, RTE-3development set RTE-4 dataset14 . Overall, primary result compactforest indeed accommodates well extensive rule applications large-scale rule bases.resulting forest size kept small, even maximal cases causing memoryoverflow explicit inference.7.3 Complete RTE System Evaluationprevious sections, evaluated knowledge-based inference engine (the proof system) respect quality output (precision, recall) well computationalefficiency (time, space). evaluate complete RTE system, combinesinference engine approximate classification module.classification setting features quite typical RTE literature. Features broadly categorized two subsets: (a) lexical features solely dependlexical items F h, (b) lexical-syntactic features also take accountsyntactic structures dependency relations F h. brief descriptionfeatures. complete description appears RTE system report (Bar-Haim et al.,2008).Lexical features: Coverage features check words h present (covered) F.assume high degree lexical coverage correlates entailment.features measure proportion uncovered content words, verbs, nouns, adjectivesadverbs, named entities numbers. Polarity mismatch features detect casesnouns verbs h matched F incompatible polarity.features assumed indicate non-entailment.Edge coverage features: say edge h matched F edgeF matching relation, source node target node. say edge hloosely-matched path F matching source node matchingtarget node. Based definitions extract two features: proportion hedges matched/loosely matched F.1514. Running time included since dedicated rule fetching, rather slowavailable implementation resources. elapsed time seconds per (t, h) pair.15. look subset edges labeled relevant dependency relations.38fiKnowledge-Based Textual Inference via Parse-Tree TransformationsPredicate-argument features: F entails h, predicates h matchedF along arguments. Predicates include verbs (except verb be)subject complements copular sentences, example, smart Joseph smart.Arguments daughters predicate node h.16 Four features computedF, h pair. categorize every predicate h match F onefour possible categories:1. complete match - matching predicate exists F matching argumentsdependency relations.2. partial match - matching predicate exists F matching argumentsdependency relations.3. opposite match - matching predicate exists F matching argumentsincorrect dependency relations.4. match - matching predicate F matching arguments.predicate categorized complete match category.Finally, compute four features F, h pair: proportion predicatesh complete match F, three binary features, checkingpredicate h categorized partial match/opposite match/no match. Sincesubject object arguments crucial textual entailment, compute foursimilar features subset predicates arguments (ignoringarguments).global lexical-syntactic feature: feature measures well subtrees hcovered F, weighted according proximity root h. featuresomewhat similar dependency tree kernel Collins Duffy (2001),measures similarity two dependency trees counting commonsubtrees. However, measure several distinct properties makes suitableneeds: (a) directional measure, estimating coverage h F,vice versa (b) operates compact forest tree, rather pairtrees. (c) takes account distance root h, assuming nodescloser root important.system trained RTE-3 development set, tested RTE3RTE-4 test sets (no development set released RTE-4). Co-reference substitutiondisabled due insufficient accuracy co-reference resolution tool used.first report overall performance, provide analysis inference module,focus work.accuracies obtained experiment shown Table 7 (under inferencecolumn). results RTE-3 quite competitive: compared 66.4%, 3 teams26 participated RTE-3 scored higher 67%, three systemsscored 66% 67%. results RTE4 rank 9-10 26, 6 teamsscoring higher 1%. Overall, results show system well-situatedstate art RTE task.Table 8 provides detailed view systems performance. Precision, recall,F1 results given entailing non-entailing pairs, well overall accuracy.16. dependent preposition clause take complement preposition headclause respectively dependent.39fiBar-Haim, Dagan & Beranttable also shows results per task (IE, IR, QA SUM). Overall, system tendspredict entailment often non-entailment. recall entailing pairs muchhigher recall non-entailing pairs, precision non-entailing pairsmuch higher entailing pairs. Performance varies considerably among different tasks.RTE3 accuracy results QA IR considerably higher average resultsachieved RTE3 submissions, reported organizers (Giampiccolo et al., 2007)(0.71 0.66, respectively), IE SUM, results bit average(0.52 0.58). RTE4 results better IR SUM, seem easiertasks RTE4 (Giampiccolo et al., 2008).177.4 Usage Contribution Knowledge Basesevaluate accuracy gain knowledge-based inference, ran systeminference module disabled, entailment classification applied directly initialparse tree text. results shown inference column Table 7.Comparing results full system accuracy (inference), see applyinginference module resulted higher accuracy test sets. contributionprominent RTE-4 dataset. results illustrate typical contribution currentknowledge sources current RTE systems. contribution likely increasecurrent near future research, topics extending improving knowledgeresources, applying semantically suitable contexts, improved classificationfeatures, broader search strategies.Tables 9 10 illustrate usage contribution individual rule bases. Table 9shows distribution rule applications various rule bases. Table 10 presentsablation study showing marginal accuracy gain rule base. results showrule bases applicable large portion pairs, contributesoverall accuracy. note results highly dependent searchstrategy. instance, chaining lexical rules expected increase number lexicalrule applications, reduce accuracy. provide detailed analysis ruleapplications system next section.7.5 Manual Analysisconclude evaluation two manual analyses inference component withinRTE system. first analysis (Subsection 7.5.1) assesses applicability inferenceframework RTE task well actual coverage current system. alsocategorizes cases formalism falls short. (Subsection 7.5.2) assesscorrectness applied rules, analyze various causes incorrect applications.analyses done one authors randomly sampled subsets RTE-3test set.17. According RTE4 organizers, IE task appeared difficult task, SUMIR seemed easier tasks. However, report average accuracy per task.40fiKnowledge-Based Textual Inference via Parse-Tree TransformationsTest setRTE3RTE4Accuracyinference Inference64.6%66.4%57.5%60.6%1.8 %*3.1%LexicalOverlap62.4%56.6%Best RTEResult80.0%74.6%Table 7: Inference contribution RTE performance. system trained RTE3 development set. * indicates statistically significant difference (at level p < 0.02, usingMcNemars test). best results achieved RTE3 RTE4 challenges (Hickl &Bensley, 2007; Bensley & Hickl, 2008), well lexical overlap baseline results (Mehdad& Magnini, 2009a), also given reference. Mehdad Magnini tested eightconfigurations lexical overlap baselines, chose one performs best averageRTE1-4 test sets.RTE3RTE4TaskIEIRQASUMIEIRQASUMNon-Entailing PairsPrecision RecallF10.5000.095 0.1590.7640.743 0.7530.8220.787 0.8040.5450.341 0.4200.7220.505 0.5940.5960.187 0.2840.7210.587 0.6470.6360.210 0.3160.6850.630 0.6560.6800.400 0.504Entailing PairsPrecision RecallF10.5270.914 0.6690.6780.701 0.6890.8180.849 0.8330.6000.777 0.6770.6340.815 0.7130.5180.873 0.6500.6520.773 0.7070.5270.880 0.6590.6570.710 0.6830.5750.812 0.673Accuracy0.5250.7250.8200.5850.6640.5300.6800.5450.6700.606Table 8: RTE results breakdown task pair typeRule baseWordNetAmWNWikipediaDIRTGenericPolarityRTE3-DevRules App0.61.20.30.40.61.70.50.74.7 10.40.20.2RTE4Rules App0.61.10.30.40.61.30.51.05.4 11.50.20.2Table 9: Average number rule applications per (t, h) pair, rule base. App countsrule application, Rules ignores multiple matches ruleiteration.7.5.1 Applicability Coverageanalysis assesses ability inference framework derive complete proofsRTE (t,h) pairs idealized setting perfect knowledge bases co-referenceresolution available. provides upper bound coverage inference41fiBar-Haim, Dagan & BerantRule baseWordNetAmWNWikipediaDIRTGenericPolarityAccuracy (RTE4)0.8%0.7%1.0%0.9%0.4%0.9%Table 10: Contribution various rule bases. Results show accuracy loss RTE-4, obtainedremoving rule base (ablation tests).engine. similar analysis previously done Bar-Haim, Szpektor, Glickman(2005) subset RTE-1 dataset. However, go (a) assessactual coverage required inferences implemented RTE system, (b) presentclassification uncovered cases different categories.carried analysis follows: 80 positive (entailing) pairs randomlysampled RTE-3 test set. pair aimed manually derive proofcomprising inference steps expressible formalism, similar exampleSection 2.2. complete proof could derived, pair classified inferable.Otherwise, classified one following categories:Discourse references: Complete proof requires incorporating pieces informationdiscourse, including event co-reference bridging (Mirkin et al., 2010). Nominal co-reference substitution included, covered formalism.instance, text Titanics sinking hitting iceberg April 14,1912. . . , year 1912 explicitly specified time Titanics sinking,relation derived discourse order infer hypothesisTitanic sank 1912.Non-decomposable: inference cannot reasonably decomposed sequencelocal rewrites. case, example, text black plague lastedfour years killed one-third population Europe, approximately 20million people hypothesis Black plague swept Europe.Other: cases fall categories.distribution categories shown Table 11. found 60%pairs could proven formalism given appropriate inference rules co-referenceinformation, demonstrates utility approach. results somewhathigher 50% reported Bar-Haim et al. (2005), may attributedfact RTE1 considered difficult dataset, entailment systems consistentlyperform better RTE3.remaining 40% pairs, analysis highlights significance discoursereferences, occur 16.3% pairs. previous analysis discourse referencestextual entailment applied RTE-5 search task, text sentencesinterpreted context full discourse (Mirkin et al., 2010), analysis shows42fiKnowledge-Based Textual Inference via Parse-Tree TransformationsCategoryInferableNon-decomposableDiscourse referencesCount4814135%60.0%17.5%16.3%6.3%Table 11: Applicability inference framework RTE task. 80 randomly selectedentailing pairs RTE-3 test set analyzed.significance discourse references even short, self-contained texts, RTE3 composed. Mirkin et al. show framework, similar methods basedtree transformations, extended utilize discourse references. Several workslast years targeted implied predicate-argument relationships, notableSemEval-2010 Task Linking Events Participants Discourse(Ruppenhofer, Sporleder, Morante, Baker, & Palmer, 2009). particular, Stern Dagan(2014) recently showed identifying relations improves performanceRTE system. Finally, entailment 17.5% pairs could establishedsequence local rewrites, thus cases likely require deeper methods semanticanalysis inference.manually-derived proofs 48 inferable pairs included total 79 rule applications, average 1.65 rule applications per pair.18 maximal number rules perpair 3. 28 rules (35.4%) applied system. 21% proofsinferable pairs fully derived RTE system. Partial proofs derivedadditional 25% pairs. remaining 54% pairs, system applyrules manual proof. results demonstrate utility inferencemechanisms rule bases system, hand suggest stillmuch room improvement coverage existing rule bases.7.5.2 Correctness Applied Rulesnext assess correctness rules applied inference engine. focusfour lexical lexical-syntactic rule bases described Section 6.3: WordNet, Wikipedia,DIRT, Argument-Mapped WordNet (AmWN). Except WordNet, rule basesgenerated automatically, therefore accuracy issue accuracymanually-composed generic inference rules polarity annotation rules. Furthermore, lexicalized rules often context sensitive, additional potential sourceincorrect rule applications.evaluation randomly sampled 75 pairs RTE-3 test set, analyzedlexical lexical-syntactic rule applications performed system pairs,total 201 rule applications. define two levels rule application correctness:18. previously mentioned, RTE system apply rules merely extract subtreegiven source tree. Accordingly, rules ignored analysis well.43fiBar-Haim, Dagan & BerantPropositional: derived tree resulting rule application grammaticalentailed source tree. level correctness assumedformalism.Referential: case propositional correctness hold, turn weaker criterion Referential Correctness, following notion Lexical Reference (Glickman,Shnarch, & Dagan, 2006; Shnarch et al., 2009), extend casetemplate-based rules variables. Let rule E : L R inference rule matchedsource tree s. Let l r instantiations L R respectively, accordingvariable matching L s. say referential correctness holds l generates reference possible meaning r. examples rules foundanalyzed sample are: popepapal, TurkishTurkey fishermenfishing.rule applications result valid entailed tree, still usefulcontext RTE system applies approximate matching (as previouslydiscussed end Section 6).Incorrect rule applications classified one following categories:1. Bad rule: rule a-priori incorrect (e.g., Walesyear ).2. Bad context: rule incorrect context source sentence. example,WordNet rule strikecreate corresponds rare sense strike definedproduce ignition blow (as strike fire flint stone).3. Bad match: rule applied due incorrect matching left-hand-side,resulting incorrect parse source tree.results summarized Table 12. Overall, 52.7% rule applications correct.Interestingly, referential (29.4%) propositional (23.4%) rule applications. Unsurprisingly, accurate knowledge resource manually composedWordNet (75.9% correct applications), followed AmWN (57.9%) Wikipedia(57.4%) rule bases, derived automatically human-generated resources.least accurate resource DIRT (21.4%), makes use human knowledge engineering, rather learned automatically based corpus statistics. accuracy DIRTconsiderably lower accuracy resources, substantially decreasingoverall accuracy well. errors DIRT Wikipedia due bad rules.also overall dominant cause incorrect applications, WordNetAmWN a-priori rule quality high errors due bad context. Wikipedia rules suffer bad context, explained factleft-hand-side often unambiguous named entity (Madrid, Antelope ValleyFreeway, Microsoft Office). analysis highlights need improving accuracyautomatically-generated rule bases, whose quality still far human generated resources. analysis also shows context-sensitivity lexicalized rules still issueeven rules applied conservatively experiment (no chaining, LR matched F h). addressed future research.44fiKnowledge-Based Textual Inference via Parse-Tree Transformations% rule applicationsPropositionalReferentialCorrectBad ruleBad contextBad matchingIncorrectDIRT27.9%17.9%3.6%21.4%58.9%7.1%12.5%78.6%AmWN9.5%21.1%36.8%57.9%5.3%31.6%5.3%42.1%Wikipedia33.8%19.1%38.2%57.4%42.6%0.0%0.0%42.6%WordNet28.9%34.5%41.4%75.9%0.0%17.2%6.9%24.1%100.0%23.4%29.4%52.7%31.3%10.0%6.0%47.3%Table 12: Analysis lexical lexical-syntactic rule applications8. Discussion: Comparison Related Approachessection, compare work several closely-related inference methods,described Section 2.3.2.discourse commitments derived Hickl (2008) quite similar kind consequents generate applying syntactic, lexical-syntactic, co-reference substitution rules. However, work differs Hickls several respects. First foremost,Hickls work fully describe knowledge representation inference framework,main focus work. Hickl briefly mentions commitmentsgenerated using probabilistic FST-based extraction framework, explanations examples given paper. Second, framework allows unified modelingvariety inference types addressed various tools components Hicklssystem (FST, relation extraction, paraphrase acquisition, etc.). addition, systemoperates lexical-syntactic representations, rely semantic parsing. Finally, consequents generated formalism packed efficient data structure,whereas Hickls commitments generated explicitly discuss commitmentgeneration efficiency. noted, however, explicit generation commitments restricts search space, may simplify approximate matching (e.g., findingalignment h given consequent vs. aligning h whole compact forest).De Salvo Braz et al. (2005) presented semantic inference framework augmentstext representation right-hand-side applied rule, respectsimilar ours. However, work, rule application semanticsresulting augmented structure fully specified. particular, distinctionindividual consequents lost augmented graph. contrast, compactinference fully formalized proved equivalent expressive, well-definedformalism operating individual trees, inferred consequent recoveredcompact forest.MacCartney Manning (2009) proposed model natural language inference which,similar framework, operates directly parse-based representations. work extends previous work natural logic (Valencia, 1991), focused semantic containment monotonicity, incorporating semantic exclusion implicativity. modelinference h sequence atomic edits; thought generatingintermediate premise. calculus computes semantic relation source45fiBar-Haim, Dagan & Berantderived premise propagating semantic relation local edit upwardparse tree according properties intermediate nodes. example,correctly infer first-year students arrived students arrived ,Every first-year student arrived Every student arrived . composition semantic relations along inference chain yields semantic relation holdingh. contribution complementary ours. approaches, inferenceh modeled sequence atomic steps (rule applications edits). focusframework representation application diverse types transformationsneeded textual inference, well efficient representation possible inference chains.Application inference rule assumed always generate entailed consequent,polarity rules may used detect situations assumption holdblock rule application. comparison, formalism MacCartney Manning assumesrather simple edit operations, focused precise predication semantic relationh given sequence edits transform h. Thus, combiningtwo complementary approaches natural direction future research.9. Conclusionsubject work representation use semantic knowledge textualinference lexical-syntactic level. defined novel inference framework parsetrees, represents diverse semantic knowledge inference rules. proof processaims transform source text target hypothesis sequence ruleapplications, generating intermediate parse tree. complementary contributionwork novel data structure associated rule application algorithm,proved valid implementation inference formalism. illustrated inferenceefficiency analytically empirically.approach several advantageous properties. First, ability representapply wide variety inferences combine rule chaining makes framework expressive previous RTE architectures. Second, expressivepower obtained well-formalized compact framework, based unified knowledgerepresentation inference mechanisms. Finally, shown RTE experiments,compact forest data structure allows approach scale well practical settingsinvolve large rule bases hundreds rule applications per text-hypothesis pair.demonstrated utility approach two different semantic tasks. Experiments unsupervised relation extraction showed exact proofs outperformheuristic common practice hypothesis embedding. also achieved competitiveresults RTE benchmarks, adding simple approximate matching moduleinference engine. contribution semantic knowledge illustrated tasks.Limitations possible extensions formalism discussed Section 4.8.Manual analysis inference engines performance relation extraction RTEtasks suggested promising directions future research, discussed Subsections7.1.3 7.5. Two additional major areas research approximate matchingheuristics proof search strategy. Stern Dagan (2011) Stern, Stern, Dagan,Felner (2012) extended work address two aspects, respectively.46fiKnowledge-Based Textual Inference via Parse-Tree TransformationsAcknowledgmentsarticle based doctoral dissertation first author, completedguidance second author Bar-Ilan University (Bar-Haim, 2010).work partially supported Israel Science Foundation grants 1095/05 1112/08,IST Programme European Community PASCAL Network Excellence IST-2002-506778, PASCAL-2 Network Excellence European CommunityFP7-ICT-2007-1-216886, Israel Internet Association (ISOC-IL), grant 9022,FBK-irst/Bar-Ilan University collaboration. third author grateful AzrieliFoundation award Azrieli Fellowship. authors wish thank Cleo Condoravdi making polarity lexicon developed PARC available research.grateful Eyal Shnarch help implementing experimental setup describedSection 7.1. also thank Iddo Greental collaboration developing generic rulebase. Finally, would like thank Dan Roth, Idan Szpektor, Yonatan Aumann, MarcoPennacchiotti, Marc Dymetman anonymous reviewers valuable feedbackwork.Appendix A: Compact Forest Complete Proofssection, provide complete proofs correctness compact inferencealgorithm presented Section 5. start definitions.Definition Let L R rule matched applied compact forest F. Section 5.2, let l subtree represented tree (F), L matched. RecallSL defined l excluding nodes matched dual-leaf variables, similarly SRdefined copy R without dual-leaf variables generated insertedF part rule application. roots SL SR denoted rL rR respectively.say node SR tied node s0 SL , set source node oneoutgoing d-edges s0 , due alignment sharing dual leaf variable sharing.graph operations performed applying rule L R compact forest Fsummarized follows:1. Adding subtree SR F.2. Setting rR target node d-edge F.3. Setting nodes SR tied nodes SL source nodes d-edges F,according rules variable sharing dual leaf variable sharing. Recalld-edges part SL .First, show simple property cDGs generated inference process:Lemma 1 Every node cDG generated inference process one incoming d-edge.47fiBar-Haim, Dagan & BerantProof construction, initial forest node one incoming d-edge.rule application adds subtree SR , whose nodes one incoming d-edge.Last, root rR , initially incoming edges, set target singled-edge rule application (the incoming d-edge rL ). Therefore, lemma followsinduction number rule applications.Using following theorem show inference process generates compactforest:Theorem 1 Applying rule compact forest results compact forest.Proof Let F 0 cDG generated applying rule L R compact forest F.show F 0 compact forest, is, cDAG single root rembedded DAGs rooted r trees. First, show F 0 cDAG, (i.e.,contain cycle e-edges).Assume contradiction F 0 contains simple cycle e-edges C. Applyingrule L R add e-edges nodes F. Therefore, C must passrR , root SR contain e-edge (p, rR ). Since SR tree, C must also leave SRe-edge (u, v) (u SR v/ SR ). cycle written p rR ...u v ... p. Notice path v p fully contained F since cycleC simple entering SR possible rR .L R must substitution rule, otherwise p would root F.impossible, since root incoming d-edges. Therefore, rR rLsingle incoming d-edge, e-edge (p, rL ) exists F. addition, u addedsource node d-edge F since tied u0 SL , also source node d.Therefore, path rL ... u0 v exists F. Finally, know path vp fully contained F, therefore construct cycle p rL ... u0 v ... pF, contradiction assumption F compact forest.shown F 0 cDAG. Next, define generalization embedded DAGs,help us show embedded DAGs F 0 rooted r trees.Definition embedded partial DAG G = (V, E) cDAG G rooted node v Vsimilar embedded DAG generated using following process:1. Initialize G v alone2. Repeat number iterations:(a) choose node V(b) choose outgoing d-edge already chosen previousiteration. d-edges chosen - halt.(c) choose target node Td add e-edge (s, t)d G.show embedded partial DAGs F 0 rooted node trees. Sinceembedded DAG also embedded partial DAG, proves embedded DAGsF 0 rooted r trees. Assume contradiction applying L R48fiKnowledge-Based Textual Inference via Parse-Tree Transformationsembedded partial DAG 0 rooted node n tree. assume nSR , otherwise, extend 0 adding path p rR ... n, pnode outside SR source node incoming edge rR .Since 0 tree, two simple paths P1 P2 n reachnode z two different e-edges. z cannot SR , since two paths meetsubtree SR , must first meet root rR entering incoming d-edge. However, couldconstruct F two paths, selecting rL instead rR , contradictionassumption F compact forest. Clearly, either P1 P2 must passnew subtree SR , otherwise two paths already existed F.first handle case where, without loss generality, P1 passes SRP2 not. P1 passes SR contains e-edge (p, rR ). Since z/ SR ,also contains e-edge (u, v) u SR v/ SR . P1 writtenn ... p rR ... u v ... z. paths n p v zF, way enter SR rR P1 simple.incrementally construct F following embedded partial DAG : First, constructP2 section P1 n p 0 . Next, expand p e-edge (p, rL )instead (p, rR ). would like expand rL reach z possible.previously explained, u tied node u0 SL therefore e-edge (u0 , v) existsF. Therefore, path P 0 SL , rL (u0 , v) z. However,guaranteed whole P 0 added . try expand incrementallyP 0 , step adding next e-edge path. succeed, embeddedgraph F two paths z, contradiction. fail, due e-edge(z 0 , t) P 0 cannot add. Thus, z 0 must already P2 , nodetwo distinct paths embedded graph , contradiction. path constructedindeed different P2 since contains e-edge (p, rL ) cannot part P2 , sinceP1 contains disjoint edge (p, rR ).remaining case, P1 P2 pass SR reach node z/ SR . P1written n ... u1 v1 ... z P2 n ... u2 v2 ... z,u1 , u2 SR , v1 , v2/ SR . Assume first e-edges (u1 , v1 ) (u2 , v2 )originate d-edge d. u1 6= u2 , otherwise (u1 , v1 ) (u2 , v2 ) couldembedded partial DAG. u1 ,u2 tied nodes u01 , u02 SL .show u01 6= u02 : Assume contradiction u01 = u02 = u0 . u0 tied u1u2 due alignment sharing dual leaf variable sharing. u0 cannot tied u1u2 due alignment sharing since alignment function nodes SL nodesSR . cannot tied due dual leaf variable sharing, since variable appearsR. Finally, u0 tied u1 (without loss generality) due dual leafvariable sharing, d-edge part l. Therefore, u2 includealigned modifier, thus u2 tied u0 due alignment.construct embedded graph rooted rL F: SL partmatch L F, construct embedded graph rooted rL pathnode SL , particular paths u01 u02 . Since u01 6= u02 , u01u02 source nodes d, part SL , expand two pathse-edges (u01 , v1 ) (u02 , v1 ) get embedded graph Gn tree,contradiction.49fiBar-Haim, Dagan & BerantSuppose e-edges (u1 , v1 ) (u2 , v2 ) originate different d-edges d1d2 respectively. u1 u2 tied u01 u02 . Therefore, v1 6= v2 constructfollowing embedded graph rooted rL : previous case, expandpaths SL rL u01 u02 . Next, add e-edges (u01 , v1 ) d1 (u02 , v2 )d2 . Recall d1 d2 SL therefore used expansion. tryexpand embedded graph include paths v1 v2 z. succeed,two paths leading z. fail two paths Tn meetingnode z 0 , explained above. Last, v1 = v2 = v, v node F twoincoming d-edges, contradicting Lemma 1.case introduction rule quite similar simpler. P1 passes SRP2 not, n must root compact forest (the node pathrR ). However, case n single outgoing d-edge, therefore outgoinge-edges disjoint (i.e. cannot part embedded DAG). Thus, P2 must alsopass rR - contradiction. P1 P2 pass SR , proof identicalcase substitution rule.shown F 0 cDAG whose embedded DAGs rooted r trees. F 0also single root new nodes added applying L R incomingedge. Hence, F 0 compact forest.Corollary 1 inference process generates compact forest.Proof easy verify initialization generates compact forest. Since applyingrule compact forest results compact forest, inference process generatescompact forest induction number rule applications.Theorem 2 Given rule base R set initial trees , tree representedcompact forest derivable inference process consequent accordinginference formalism.Proof () first show completeness induction number rule applications n.n = 0 one initial trees represented initial compact forest.Let tn+1 tree derived formalism applying sequence n + 1 rules. showtn+1 represented derivable compact forest. tn+1 derived applyingrule L R tree tn . According inductive assumption, tn representedcompact forest F derivable inference process. Therefore, rule L Rmatched applied F. assume L R substitution rule since caseintroduction rule similar. tn+1 almost identical tn except contains subtreeR instead L instantiated variables aligned modifiers. easy verifyapplication L R F resulting F 0 , F 0 contain embedded treealmost identical tn , except root SR , rR , chosen instead rootSL , rL , rest SR also chosen appropriate instantiated variablesmodifiers. Therefore, tn+1 = contained F 0 required. guaranteedtree according Corollary 1.() Next, prove soundness induction number rule applicationsforest. initialization, initial trees consequents. Let Fn+1 compactforest derived n + 1 rule applications (Corollary 1 guarantees Fn+1 indeed50fiKnowledge-Based Textual Inference via Parse-Tree Transformationscompact forest). Given tree tn+1 represented Fn+1 , show tn+1 consequentformalism.tn+1 already represented compact forest n rule applications,according assumption induction consequent formalism. not,tn+1 new embedded tree created application rule L R. Therefore,tn+1 contains entire subtree SR . incrementally construct embedded tree tnrepresented Fn tn+1 result applying L R tn .substitution rule, first construct part tn+1 includesubtree rooted rR . introduction rule, take path forests rootrL . Next, construct SL rL instead SR rR . possible sinceaccording Corollary 1 embedded graphs trees, therefore nodes SLalready tn . look set e-edges (s, t) tn+1 SR/ SR .Let (s, z) edge originating d-edge Sz subtree rooted ztn+1 . Notice Sz already part Fn . tied s0 SL therefore s0 sourcenode d. expand tn include edge (s0 , z) Sz s0 already usedd-edge tn . guaranteed part SL (only d-edgespart SL shared). Finally, complete construction tn arbitrarilyexpanding unused outgoing d-edge tn nodes, obtain complete embeddedtree.constructed embedded tree tn Fn . Therefore, according inductiveassumption, tn consequent formalism. tn contains SL instantiationdual leaf variables. Therefore, matched L rule L R applied.easy verify application rule tn yield tn+1 , required. Thus, tn+1also consequent formalism.sake simplicity, proofs ignored case one leafvariables L match multiple target nodes l appear R non-leaves. describedSection 5.2, case matched target nodes inserted SR alternatives (withproper sharing modifiers). Consequently, SR becomes compact forest containingmultiple trees. Similarly, SL compact forest, whose represented trees correspondpossible choices matching leaf variables. mapping nodes matchedleaf variables SL nodes generated SR defines one-to-onemapping trees SL SR .proofs easily adapted handle case, follows. First, proofLemma 1 need change. Theorem 1, proof rule application createcycles still holds underlying graph SR DAG rather tree. proveembedded partial DAG 0 tree, observe exactly one trees embeddedSR part 0 . Thus, consider tree SR corresponding treeSL , ignoring rest SR SL , proceed original proof. Similarly,prove completeness Theorem 2, refer tree represented SL , parttn , corresponding tree SR . prove soundness, consider subtreesSR corresponding tree SL .51fiBar-Haim, Dagan & BerantReferencesBar-Haim, R. (2010). Semantic Inference Lexical-Syntactic Level. Ph.D. thesis,Department Computer Science, Bar-Ilan University, Ramat-Gan, Israel.Bar-Haim, R., Berant, J., & Dagan, I. (2009). compact forest scalable inferenceentailment paraphrase rules. Proceedings EMNLP.Bar-Haim, R., Berant, J., Dagan, I., Greental, I., Mirkin, S., Shnarch, E., & Szpektor, I.(2008). Efficient semantic deduction approximate matching compact parseforests. Proceedings TAC 2008 Workshop.Bar-Haim, R., Dagan, I., Dolan, B., Ferro, L., Giampiccolo, D., Magnini, B., & Szpektor,I. (2006). Second PASCAL Recognising Textual Entailment Challenge.Second PASCAL Challenges Workshop Recognizing Textual Entailment.Bar-Haim, R., Dagan, I., Greental, I., & Shnarch, E. (2007). Semantic inferencelexical-syntactic level. Proceedings AAAI.Bar-Haim, R., Szpektor, I., & Glickman, O. (2005). Definition analysis intermediateentailment levels. Proceedings ACL Workshop Empirical ModelingSemantic Equivalence Entailment.Barzilay, R., & Lee, L. (2003). Learning paraphrase: unsupervised approach usingmultiple-sequence alignment. Proceedings HLT-NAACL.Barzilay, R., & McKeown, K. R. (2001). Extracting paraphrases parallel corpus.Proceedings ACL.Bensley, J., & Hickl, A. (2008). Workshop: Application LCCs GROUNDHOG systemRTE-4. Proceedings TAC 2008 Workshop.Bentivogli, L., Clark, P., Dagan, I., Dang, H. T., & Giampiccolo, D. (2010). SixthPASCAL Recognizing Textual Entailment Challenge. Proceedings TAC 2010Workshop.Bentivogli, L., Dagan, I., Dang, H. T., Giampiccolo, D., & Magnini, B. (2009). FifthPASCAL Recognizing Textual Entailment Challenge. Proceedings TAC 2009Workshop.Berant, J., Dagan, I., & Goldberger, J. (2011). Global learning typed entailment rules.Proceedings ACL.Bhagat, R., & Ravichandran, D. (2008). Large scale acquisition paraphrases learningsurface patterns. Proceedings ACL-08: HLT.Bos, J., & Markert, K. (2005). Recognising textual entailment logical inference techniques. Proceedings EMNLP.Bos, J., & Markert, K. (2006). logical inference helps determining textual entailment(and doesnt). Proceedings Second PASCAL Recognising TextualEntailment Challenge.Chklovski, T., & Pantel, P. (2004). VerbOcean: Mining web fine-grained semanticverb relations. Proceedings EMNLP.52fiKnowledge-Based Textual Inference via Parse-Tree TransformationsCollins, M., & Duffy, N. (2001). Convolution kernels natural language. AdvancesNeural Information Processing Systems 14.Connor, M., & Roth, D. (2007). Context sensitive paraphrasing single unsupervisedclassifier. ECML.Cooper, R., Crouch, R., van Eijck, J., Fox, C., van Genabith, J., Jaspars, J., Kamp, H.,Pinkal, M., Milward, D., Poesio, M., Pulman, S., Briscoe, T., Maier, H., & Konrad, K.(1996). Using framework. Tech. rep., FraCaS: Framework ComputationalSemantics.Dagan, I., & Glickman, O. (2004). Probabilistic textual entailment: Generic applied modeling language variability. PASCAL workshop Text Understanding Mining.Dagan, I., Glickman, O., Gliozzo, A., Marmorshtein, E., & Strapparava, C. (2006a). Directword sense matching lexical substitution. Proceedings COLING-ACL.Dagan, I., Glickman, O., & Magnini, B. (2006b). PASCAL Recognising Textual Entailment Challenge. Quinonero-Candela, J., Dagan, I., Magnini, B., & dAlche Buc, F.(Eds.), Machine Learning Challenges. Lecture Notes Computer Science, Vol. 3944,pp. 177190. Springer.Dagan, I., Roth, D., Sammons, M., & Zanzotto, F. M. (2013). Recognizing Textual Entailment: Models Applications. Synthesis Lectures Human Language Technologies.Morgan & Claypool Publishers.de Salvo Braz, R., Girju, R., Punyakanok, V., Roth, D., & Sammons, M. (2005). inferencemodel semantic entailment natural language.. Proceedings AAAI.Deerwester, S., Dumais, S. T., Furnas, G. W., Landauer, T. K., & Harshman, R. (1990).Indexing latent semantic analysis. Journal American Society InformationScience, 41 (6), 391407.Dinu, G., & Lapata, M. (2010). Topic models meaning similarity context. Proceedings Coling 2010: Posters.Emele, M. C., & Dorna, M. (1998). Ambiguity preserving machine translation using packedrepresentations. Proceedings COLING-ACL.Fellbaum, C. (Ed.). (1998). WordNet: Electronic Lexical Database. Language, SpeechCommunication. MIT Press.Gabrilovich, E., & Markovitch, S. (2007). Computing semantic relatedness using Wikipediabased Explicit Semantic Analysis. Proceedings IJCAI.Ganitkevitch, J., Van Durme, B., & Callison-Burch, C. (2013). PPDB: paraphrasedatabase. Proceedings HLT-NAACL.Giampiccolo, D., Magnini, B., Dagan, I., & Dolan, B. (2007). Third PASCAL Recognizing Textual Entailment Challenge. Proceedings ACL-PASCAL WorkshopTextual Entailment Paraphrasing.Giampiccolo, D., Trang Dang, H., Magnini, B., Dagan, I., & Dolan, B. (2008). FourthPASCAL Recognizing Textual Entailment Challenge. Proceedings TAC 2008Workshop.53fiBar-Haim, Dagan & BerantGlickman, O., & Dagan, I. (2003). Identifying lexical paraphrases single corpus:case study verbs. Proceedings RANLP.Glickman, O., Shnarch, E., & Dagan, I. (2006). Lexical reference: semantic matchingsubtask. Proceedings EMNLP.Haghighi, A. D., Ng, A. Y., & Manning, C. D. (2005). Robust textual inference via graphmatching. Proceedings EMNLP.Harmeling, S. (2009). Inferring textual entailment probabilistically sound calculus.Natural Language Engineering, 15 (4), 459477.Heilman, M., & Smith, N. A. (2010). Tree edit models recognizing textual entailments,paraphrases, answers questions. Proceedings HLT-NAACL.Hickl, A. (2008). Using discourse commitments recognize textual entailment. Proceedings COLING.Hickl, A., & Bensley, J. (2007). discourse commitment-based framework recognizing textual entailment. Proceedings ACL-PASCAL Workshop TextualEntailment Paraphrasing.Hickl, A., Bensley, J., Williams, J., Roberts, K., Rink, B., & Shi, Y. (2006). Recognizing textual entailment LCCs GROUNDHOG system. Second PASCALChallenges Workshop Recognizing Textual Entailment.Jurafsky, D., & Martin, J. H. (2008). Speech Language Processing: IntroductionNatural Language Processing, Computational Linguistics Speech Recognition(Second edition). Prentice Hall.Kamp, H., & Reyle, U. (1993). Discourse Logic. Introduction ModeltheoreticSemantics Natural Language, Formal Logic Discourse Representation Theory.Kluwer Academic Publishers, Dordrecht.Kay, M. (1996). Chart generation. Proceedings ACL.Kazama, J., & Torisawa, K. (2007). Exploiting Wikipedia external knowledge namedentity recognition. Proceedings EMNLP-CoNLL.Kipper, K. (2005). VerbNet: broad-coverage, comprehensive verb lexicon. Ph.D. thesis,University Pennsylvania.Kouylekov, M., & Magnini, B. (2005). Tree edit distance textual entailment. Proceedings RANLP.Lehmann, J., Bizer, C., Kobilarov, G., Auer, S., Becker, C., Cyganiak, R., & Hellmann,S. (2009). DBpedia - crystallization point web data. Journal WebSemantics.Lin, D. (1998). Dependency-based evaluation minipar. Proceedings WorkshopEvaluation Parsing Systems LREC.Lin, D., & Pantel, P. (2001). Discovery inference rules question answering. NaturalLanguage Engineering, 7 (4), 343360.Lotan, A., Stern, A., & Dagan, I. (2013). TruthTeller: Annotating predicate truth.Proceedings HLT-NAACL.54fiKnowledge-Based Textual Inference via Parse-Tree TransformationsMacCartney, B., Galley, M., & Manning, C. D. (2008). phrase-based alignment modelnatural language inference. Proceedings EMNLP.MacCartney, B., Grenager, T., de Marneffe, M.-C., Cer, D., & Manning, C. D. (2006).Learning recognize features valid textual entailments. Proceedings HLTNAACL.MacCartney, B., & Manning, C. D. (2009). extended model natural logic. Proceedings IWCS-8.Macleod, C., Grishman, R., Meyers, A., Barrett, L., & Reeves, R. (1998). Nomlex: lexiconnominalizations. Proceedings Euralex98.Maxwell III, J. T., & Kaplan, R. M. (1991). method disjunctive constraint satisfaction. Tomita, M. (Ed.), Current Issues Parsing Technology. Kluwer AcademicPublishers.Mehdad, Y., & Magnini, B. (2009a). word overlap baseline recognizing textualentailment task. Unpublished manuscript.Mehdad, Y., & Magnini, B. (2009b). Optimizing textual entailment recognition using particle swarm optimization. Proceedings 2009 Workshop Applied TextualInference.Melamud, O., Berant, J., Dagan, I., Goldberger, J., & Szpektor, I. (2013). two levelmodel context sensitive inference rules. Proceedings ACL.Meyers, A., Reeves, R., Macleod, C., Szekeley, R., Zielinska, V., & Young, B. (2004).cross-breeding dictionaries. Proceedings LREC.Mi, H., Huang, L., & Liu, Q. (2008). Forest-based translation. Proceedings ACL-08:HLT.Mirkin, S., Dagan, I., & Pado, S. (2010). Assessing role discourse referencesentailment inference. Proceedings ACL.Mirkin, S., Dagan, I., & Shnarch, E. (2009). Evaluating inferential utility lexicalsemantic resources. Proceedings EACL.Moldovan, D. I., & Rus, V. (2001). Logic form transformation WordNet applicability question answering. Proceedings ACL.Nairn, R., Condoravdi, C., & Karttunen, L. (2006). Computing relative polarity textualinference. Proceedings International workshop Inference ComputationalSemantics (ICoS-5).Pang, B., Knight, K., & Marcu, D. (2003). Syntax-based alignment multiple translations:Extracting paraphrases generating new sentences. Proceedings HLT-NAACL.Pantel, P., Bhagat, R., Coppola, B., Chklovski, T., & Hovy, E. (2007). ISP: Learninginferential selectional preferences. Proceedings HLT-NAACL.Ponzetto, S. P., & Strube, M. (2007). Deriving large-scale taxonomy wikipedia.Proceedings AAAI.Ravichandran, D., & Hovy, E. (2002). Learning surface text patterns question answering system. Proceedings ACL.55fiBar-Haim, Dagan & BerantRitter, A., Mausam, & Etzioni, O. (2010). latent dirichlet allocation method selectionalpreferences. Proceedings ACL.Romano, L., Kouylekov, M., Szpektor, I., Dagan, I., & Lavelli, A. (2006). Investigatinggeneric paraphrase-based approach relation extraction. Proceedings EACL.Ron, T. (2006). Generating entailment rules based online lexical resources. Mastersthesis, Computer Science Department, Bar-Ilan University.Ruppenhofer, J., Sporleder, C., Morante, R., Baker, C., & Palmer, M. (2009). Semeval2010 task 10: Linking events participants discourse. ProceedingsWorkshop Semantic Evaluations: Recent Achievements Future Directions(SEW-2009).Saint-Dizier, P., & Mehta-Melkar, R. (Eds.). (2011). Proceedings Joint Workshop FAM-LbR/KRAQ11. Learning Reading Applications IntelligentQuestion-Answering.Schoenmackers, S., Etzioni, O., Weld, D. S., & Davis, J. (2010). Learning first-order hornclauses web text. Proceedings EMNLP.Shinyama, Y., Sekine, S., Sudo, K., & Grishman, R. (2002). Automatic paraphrase acquisition news articles. Proceedings HLT.Shnarch, E., Barak, L., & Dagan, I. (2009). Extracting lexical reference rulesWikipedia. Proceedings ACL-IJCNLP.Snow, R., Jurafsky, D., & Ng, A. Y. (2006a). Semantic taxonomy induction heterogenous evidence. Proceedings COLING-ACL.Snow, R., Vanderwende, L., & Menezes, A. (2006b). Effectively using syntax recognizingfalse entailment. Proceedings HLT-NAACL.Stern, A., & Dagan, I. (2011). confidence model syntactically-motivated entailmentproofs. Proceedings RANLP.Stern, A., & Dagan, I. (2014). Recognizing implied predicate-argument relationshipstextual inference. Proceedings ACL.Stern, A., Stern, R., Dagan, I., & Felner, A. (2012). Efficient search transformation-basedinference. Proceedings ACL.Szpektor, I., & Dagan, I. (2007). Learning canonical forms entailment rules. ProceedingsRANLP.Szpektor, I., & Dagan, I. (2008). Learning entailment rules unary templates. Proceedings COLING.Szpektor, I., & Dagan, I. (2009). Augmenting WordNet-based inference argumentmapping. Proceedings ACL-IJCNLP Workshop Applied Textual Inference(TextInfer).Szpektor, I., Dagan, I., Bar-Haim, R., & Goldberger, J. (2008). Contextual preferences.Proceedings ACL-08: HLT.Szpektor, I., Tanev, H., Dagan, I., & Coppola, B. (2004). Scaling web based acquisitionentailment patterns. Proceedings EMNLP.56fiKnowledge-Based Textual Inference via Parse-Tree TransformationsTatu, M., Iles, B., Slavick, J., Novischi, A., & Moldovan, D. (2006). COGEX Second Recognizing Textual Entailment Challenge. Second PASCAL ChallengesWorkshop Recognizing Textual Entailment.Tatu, M., & Moldovan, D. (2006). logic-based semantic approach recognizing textualentailment. Proceedings COLING-ACL.Tatu, M., & Moldovan, D. (2007). COGEX RTE3. Proceedings ACL-PASCALWorkshop Textual Entailment Paraphrasing.Valencia, V. S. (1991). Studies Natural Logic Categorial Grammar. Ph.D. thesis,University Amsterdam.van Deemter, K., & Kibble, R. (2000). coreferring: Coreference MUC relatedannotation schemes. Computational Linguistics, 26 (4), 629637.Voorhees, E. M., & Harman, D. (1997). Overview sixth Text REtrieval Conference(TREC-6). Proceedings TREC.Wang, M., & Manning, C. (2010). Probabilistic tree-edit models structured latentvariables textual entailment question answering. Proceedings COLING.Wang, R., & Neumann, G. (2007). Recognizing textual entailment using subsequencekernel method. Proceedings AAAI.Yates, A., & Etzioni, O. (2009). Unsupervised methods determining object relationsynonyms web. Journal Artificial Intelligence Research (JAIR), 34, 255296.Zanzotto, F. m., Pennacchiotti, M., & Moschitti, A. (2009). machine learning approachtextual entailment recognition. Natural Language Engineering, 15 (4), 551582.57fiJournal Artificial Intelligence Research 54 (2015) 631-677Submitted 7/15; published 12/15Practical, Integer-Linear Programming Model Delete-FreeTasks Use Heuristic Cost-Optimal PlanningTatsuya ImaiTATSUYA . IMAI .30100041@ GMAIL . COMGraduate School Information Science EngineeringTokyo Institute TechnologyTokyo, JapanAlex FukunagaFUKUNAGA @ IDEA . C . U - TOKYO . AC . JPGraduate School Arts SciencesUniversity TokyoTokyo, JapanAbstractpropose new integer-linear programming model delete relaxation cost-optimalplanning. straightforward IP delete relaxation impractical, enhanced modelincorporates variable reduction techniques based landmarks, relevance-based constraints, dominated action elimination, immediate action application, inverse action constraints, resultingIP used directly solve delete-free planning problems. show IP modelcompetitive previous state-of-the-art solvers delete-free problems. LP-relaxationIP model often good approximation IP, providing approach approximating optimal value delete-free task complementary well-known LM-cutheuristic. also show constraints partially consider delete effects addedIP/LP models. embed new IP/LP models forward-search based planner, showperformance resulting planner standard IPC benchmarks comparablestate-of-the-art cost-optimal planning.1. Introductiondelete relaxation classical planning problem relaxation planning problemdelete effects eliminated operators. delete relaxation, every propositionbecomes true remains true never becomes false again. delete relaxationstudied extensively classical planning literature used estimate costoptimal plan original planning problem therefore useful basis heuristicfunctions search-based domain-independent planning algorithms. solution originalplanning problem solution delete relaxation, cost optimal solutiondelete-relaxed problem lower cost original problem relaxation,every proposition needs established once. Thus, optimal cost delete relaxationplanning problem (denoted h+ ) lower bound optimal cost original planningproblem. Despite fact computing h+ easier solving original planning problem,computing h+ NP-equivalent (Bylander, 1994) poses challenging problem.addition importance basis heuristic functions standard classical planning,delete relaxation also interesting right, problemsnaturally modeled delete-free problems (i.e., problems actions deleteeffects). example, minimal seed set problem, problem systems biology seeksc2015AI Access Foundation. rights reserved.fiI MAI & F UKUNAGAminimal set nutrients necessary organism fully express metabolism,mapped delete-free planning problem (Gefen & Brafman, 2011). Another applicationrelational database query plan generation (Robinson, McIlraith, & Toman, 2014),problem determining join orders modeled delete-free problem.paper, propose new, integer programming (IP) approach computing h+ .1 showmodel allows fast computation h+ , linear programming (LP) relaxationmodel used successfully heuristic function A* -based planner. restpaper structured follows: begin review previous work delete relaxationwell applications LP planning. introduce IP(T + ), basic integer programmingmodel delete-free planning problem (Section 3) show correctly computes h+ . Sincestraightforward IP(T + ) model often intractable useful practice computingh+ , develop enhanced model, IPe (T + ), reduces number variables IPusing techniques landmark-based constraints, relevance analysis (Section 4). evaluateperformance basic IP(T + ) enhanced IPe (T + ) models Section 5, showIPe (T + ) competitive state-of-the-art methods computing h+ .objective use IP models basis heuristic forward state-spacesearch based planning, solving IP every node search algorithm computationally daunting, Section 6, propose evaluate two relaxations IP(T + )-based IP models.consider LP(T + ) LPe (T + ), LP-relaxation IP(T + ) IPe (T + ), showLP-relaxations usually closely approximate h+ . also introduce time-relaxation IPLP models (IPetr (T + ) LPetr (T + ), respectively) reduces number variables,cost sometimes underestimating h+ , show time-relaxations usually closelyapproximate h+ . experimentally compare closely relaxed, delete-free models approximate h+ LM-cut heuristic (Helmert & Domshlak, 2009) show approachescomplementary.Next, Section 7, evaluate utility IP LP models heuristics forwardsearch based planning embedding A* -based planner. results show althoughLPetr (T + ) competitive LM-cut heuristic overall, domainsLPetr (T + ) yields state-of-the-art performance, outperforming LM-cut.turn strengthening IP LP models partially considering delete effects(Section 8). add constraints enforce lower bounds number times action mustused. correspond net change constraints recently proposed Pommereninget al. (2014), well action order relaxation van den Briel et al. (2007). tightenedbound IPc (T ) dominates IP(T + ). Counting constraints also added LP-relaxationLPec (T ), well time-relaxed LP-relaxation LPectr (T ). However, additional countingconstraints makes IP LP difficult, A* -based planner uses bounds,tradeoff tighter bound (fewer nodes searched A* ) time spent per node.result, find although counting constraints result enhanced performance domains,significantly degrades performance domains. experimentally compare countingconstraint enhanced models LMC-SEQ LP model Pommerening et al. (2014)combines landmark net-change constraints, show that, like LM-cut vs delete-free LPs,models complementary.1. paper revises extends work originally reported authors paper presented ECAI2014 (Imai &Fukunaga, 2014). Formal results proofs ECAI paper included, paper containsmuch thorough experimental evaluation models (all experimental data new).632fiO N P RACTICAL , NTEGER -L INEAR P ROGRAMMING ODELTable 1 provides overview IP/LP models discussed Sections 3-8, alsoserves roadmap paper . model, indicate section textmodel introduced, constraints used model, variable elimination optimizationsused model. Figure 1 directed graph showing dominance relationships amongoptimal costs IP/LP models.Finally, clear dominance relationship among LP models (with respectperformance A* -based planners use LP models heuristic function),propose evaluate simple automatic configuration heuristic selects LP useheuristic A* (Section 9). simple automated bound selection significantly boosts performance, resulting ensemble-based LP-heuristic competitive state-of-the-art heuristics. Section 10 concludes paper summary discussion results directions future work.2. Background Related Worksection first introduces notation planning tasks used rest paper, surveys related work solving delete-free planning tasks well previous applicationsIP/LP domain-independent planning.2.1 Preliminary DefinitionsSTRIPS planning task defined 4-tuple = hP, A, I, Gi. P set propositions.set actions. state represented subset P , applying action state addspropositions removes propositions state. action composedthree subsets P , hpre(a), add(a), del(a)i called preconditions, add effects,delete effects. action applicable state iff satisfies pre(a) S. applyingS, propositions change S(a) = ((S \ del(a)) add(a)). sequence actions= (a0 , , ), use S() denote ((((S \ del(a0 )) add(a0 )) \ del(a1 )) ) add(an ).Let P initial state G P goal. solution planning task sequenceactions transform state satisfies G S. Formally, feasible solution, i.e.,plan, sequence actions = (a0 , , ) satisfies (i) i, pre(ai ) I((a0 , , ai1 )),(ii) G I().basic STRIPS planning task extended STRIPS planning action costs,action associated (non-negative) cost c(a). objective cost-optimal planning STRIPSmodel action costs find plan minimizes sum costsPactions i=nc(a).i=0delete relaxation task , denoted + , task hP, A+ , I, Gi A+ setdelete-free actions defined A+ = {hpre(a), add(a), | A}. also use + denotetask delete-free beginning without relaxed.2.2 Previous Work Computing h+ Relaxationsdelete relaxation used basis planning heuristics since beginningrecent era interest forward-state space search based planning (Bonet & Geffner, 2001). Unfortunately, computing h+ known NP-equivalent reduction vertex cover (Bylander,633fiI MAI & F UKUNAGAModelIP(T + ) (Sec. 3)IPe (T + ) (Sec. 4)ConstraintsC1, C2, C3, C4,C5, C6,C1, C2a C3, C4,C5, C6Variable EliminationsNoneLandmarks (4.1), relevance (4.2), dominatedaction elimination (4.3),immediate action application (4.4)NoneIPe (T + )IPe (T + )LP(T + ) (Sec. 6.1)LPe (T + ) (Sec. 6.1)LPetr (T + ) (Sec. 6.2)IP(T + )IPe (T + )C1, C2a C3, C4,IPc (T ) (Sec. 8)C1, C2, C3, C4,C5, C6, C7 C8NoneIPec (T + ) (Sec. 8)C1, C2a C3, C4,C5, C6 C7 C8LPc (T ) (Sec. 8)LPec (T ) (Sec. 8)LPectr (T ) (Sec. 8)IPc (T )IPec (T )C1, C2a C3, C4,C7 C8Landmarks (4.1), relevance(4.2), modified dominatedaction elimination (Definition 2)NoneIPec (T )IPec (T )A* /autoconf (Sec. 9)Selects among LPe (T + ), LPetr (T + ), LPec (T ),LPectr (T ).Basic delete-free task IPmodel (computes h+ )Enhanced IP model (computes h+ )LP relaxation IP(T + )LP relaxation IPe (T + )LP-relaxation timerelaxation IPe (T + )Basic delete-free taskIP model enhancedcounting constraintsEnhanced IP modelcounting constraintsLP relaxation IPc (T )LP relaxation IPec (T )LP-relaxation timerelaxation IPec (T )Automatic LP Model SelectionTable 1: Overview delete-relaxation based IP/LP models paperLP(T+)LPtr(T+)LPe(T+)IP(T+) = IPe(T+) =aaah+IPcec(T)LPecc(T)LPtre(T+)IPtre(T+)ec(T)IPctre (T)cLPctrIPtr(T+)Figure 1: Dominance relationships among IP/LP models. Edge modeli modelj indicatesoptimal cost modeli optimal cost modelj . 4 highlighted LPs componentsA* /autoconf model.634fiO N P RACTICAL , NTEGER -L INEAR P ROGRAMMING ODEL1994), therefore, beginning, researchers avoided direct computation h+ , insteadsought approximations h+ .satisficing planning, optimal solutions required, successful approach deriving heuristics approximate delete relaxation. additive heuristic (hadd ) assumessubgoals independent computes sum achieving subgoal delete-relaxedmodel (Bonet & Geffner, 2001). FF heuristic (Hoffmann & Nebel, 2001) constructs planninggraph (Blum & Furst, 1997) delete-relaxed problem, extracts relaxed plan, computesnumber actions relaxed plan, upper bound h+ .case cost-optimal planning, action assigned cost objectivefind minimal cost plan, lower bounds h+ basis several admissible heuristic functionsused literature. Bonet Geffner (2001) proposed hmax heuristic,computes highest cost associated achieving costly, single proposition.hmax admissible, often informative (i.e, gap hmax h+ large)considers single costly goal proposition. admissible landmark cut(LM-cut) heuristic (Helmert & Domshlak, 2009), approximates h+ follows. state s, LMcut heuristic first computes hmax (s), zero infinite, h+ zero infinite,hLM cut (s) = hmax (s). Otherwise, disjunctive action landmark L (a set actions least onemust included relaxed plan) computed, cost actions L reducedc(m), cost minimal-cost action L, hLM cut increased c(m). processrepeated hmax (s) (for remaining, reduced problem) becomes 0. approximationsh+ informative hmax include set-additive heuristic (Keyder & Geffner, 2008)cost-sharing approximations hmax (Mirkis & Domshlak, 2007).Previous planners avoided direct computation h+ extra search efficiencygained using h+ offset high cost computing h+ . far aware, firstactual use h+ inside cost-optimal planner Betz Helmert (2009), implementeddomain-specific implementations h+ several domains. recently, Haslum et al. evaluateduse domain-independent algorithm h+ (Haslum, Slaney, & Thiebaux, 2012)heuristic function A* -based cost-optimal planning, found performance relativelypoor (Haslum, 2012).recent years, several advances computation h+ . Since, describedabove, LM-cut heuristic (Helmert & Domshlak, 2009) lower bound h+ , cost-optimalplanner using A* search algorithm LM-cut heuristic directly applied deleterelaxation classical planning problem order compute h+ . possible improve upondeveloping methods exploit delete-free property specifically tailoredsolving delete relaxation. Pommerening Helmert (2012) developed approach usesIDA* branch-and-bound incrementally computed LM-cut heuristic. Gefen Brafman(2012) proposed action pruning delete-free problems.different approach computing h+ based observation h+ could formulatedproblem finding minimal hitting set sets disjunctive action landmarks (Bonet &Helmert, 2010). led methods computing h+ searching minimum-cost hitting setcomplete set action landmarks delete-relaxed planning problem (Bonet & Castillo,2011; Haslum et al., 2012). original implementation Haslum et al.s hitting-set basedh+ solver used problem-specific branch-and-bound algorithm (Haslum et al., 2012), improvedimplementation (which use experimental evaluation Section 5) uses integer programming solve hitting set problem (Haslum, 2014a).635fiI MAI & F UKUNAGA2.3 Integer/Linear Programming Classical PlanningAnother related line research modeling classical planning integer/linear programs(ILP). use high-performance, general problem solvers solve planning problemspioneered Kautz Selman, solved planning problems encoding propositionalsatisfiability (SAT) applied state-of-the-art SAT solvers. basic approach instantiateSAT formula satisfying assignment implies t-step plan. SATPLAN starts smallvalue (e.g., trivially, 1, lower bound), instantiates propositional formula F (t)satisfiable plan parallel steps less exists. F (t) satisfiable,minimal parallel makespan plan found. Otherwise, incremented, processrepeated plan found. initial encodings modestly successful (Kautz &Selman, 1992), advances SAT solver technology well improvements encodingintegration planning graphs (Blum & Furst, 1997) led dramatic performance improvements (Kautz & Selman, 1996, 1999). Recent work SAT-based planning includes improvedencodings well execution strategies SAT strategies improve upon simply incrementing(Rintanen, Heljanko, & Niemela, 2006). addition, improvements SAT solversspecifically target domain-independent planning investigated (Rintanen, 2012)Since expressiveness integer programming (IP) subsumes SAT, SAT encodingsstraightforwardly translated IP. However, direct translation SAT encodings IP resultedpoor performance, state-change formulation replaces original fluents SATencoding set variables directly expresses addition, deletion, persistencefluents shown successful basis IP model planning (Vossen, Ball,Lotem, & Nau, 1999). formulation strengthened additional mutual exclusion constraints (Dimopoulos, 2001). Optiplan model (van den Briel & Kambhampati, 2005) combinedstate-change IP formulation planning-graph based model refinement strategies improvements Dimopoulous (2001). SAT-based approaches described above, IP modelsfeasible plan steps exists constructed. However, unlikeSAT formulation, easy directly encode action costs objective function IPmodel, IP models used directly solve cost-optimal planning problems. Anotherapproach decomposes planning instance set network flow problems, subproblem corresponds state variable original planning problem (van den Briel, Vossen, &Kambhampati, 2008).Instead modeling directly solving classical planning problem IP, another approach, adopt paper, uses ILP models provide heuristic function guidesstate-space search planning algorithms A* . early instance approach (which,knowledge, also earliest application LP classical planning) LPlan,LP encoding classical planning problem used heuristic function partial orderplanner (Bylander, 1997). Van den Briel et al. (2007) developed admissible heuristic basedLP model represents planning problem order actions executedrelaxed, variable represents number times action executed. Delete effectsconsidered, constraints number actions delete valuesincremented actions add value. Although LP-based heuristicintegrated planning system, compared relaxed problem cost found modelBylanders LPlan LP model, well LP model h+ .636fiO N P RACTICAL , NTEGER -L INEAR P ROGRAMMING ODELknowledge, h+ implementation van den Briel et al. (2007) first implementation IP model h+ . First, relaxed planning graph (Blum & Furst, 1997) expandedquiescence, results instantiation actions relevant optimaldelete-free task well upper bound number steps optimal delete-free task.Then, h+ computed using delete-relaxed, step-based encoding planning problemOptiplan (van den Briel, 2015).Cooper et al. (2011) showed optimal solution dual LP model relaxes action ordering corresponds best lower bound obtained applyingtransformations original planning problem shift costs among actions affectfluents.Bonet proposed hSEQ , admissible, flow-based LP heuristic based Petri Net state equations (Bonet, 2013) used heuristic A* -based planner. Bonet van denBriel (2014) enhanced Bonets flow-based LP model adding action landmark constraint implementing variable merging strategies, resulting competitive, admissible heuristic. KarpasDomshlak (2009) proposed LP formulation compute optimal partitioning landmarks. Pommerening et al. (2014) proposed operator counting framework enabled unificationnumber ideas, including state equation formulation (Bonet, 2013), post-hoc optimization constraints (Pommerening, Roger, & Helmert, 2013), well landmarks (the formulation Bonet& Helmert, 2010, dual formulation Karpas & Domshlak, 2009) stateabstraction heuristics (Katz & Domshlak, 2010). showed combinations constraints resulted strong heuristics significantly outperformed LM-cut heuristic. recent surveyRoger Pommerening (2015) presents survey LP-based heuristics planningincludes earlier conference version paper (Imai & Fukunaga, 2014) suggestsdelete-relaxation model could incorporated operator counting framework associatingoperator-counting variable action variable (see below) delete-relaxed problem.3. IP(T + ): Basic IP Formulation Delete-Free Taskdefine integer program IP(T + ), IP formulation delete free task+ = hP, A+ , I, Gi. Note feasible solution IP(T + ) (not optimal solution),derive corresponding, feasible non-redundant (i.e., action appears once)plan + cost IP(T + ) solution.First, define variables IP(T + ). addition able derive plan IP(T + ),always exists injective mapping feasible non-redundant plan IP(T + ) solution.Thus, also show feasible assignments variables derived feasible plan+ , well meanings roles variables. use = (a0 , , ) denoteplan + corresponding solution IP(T + ). say first achiever p planp 6 I, first action achieves (establishes) p.proposition: p P, U (p) {0, 1}. U (p) = 1 iff p I(). U (p) indicates whether proposition pachieved relaxed plan + .action: A, U (a) {0, 1}. U (a) = 1 iff holds. U (a) indicates whether actionused relaxed plan.add effect: A, p add(a), E(a, p) {0, 1}. E(a, p) = 1 iff holds firstachiever p. E(a, p) = 0 p true I, p achieved.637fiI MAI & F UKUNAGAtime (proposition): p P, (p) {0, , |A|}. (p) = p I() p addedat1 first. (p) = 0 p member I. (p) indicates time step p firstachieved first achiever.time (action): A, (a) {0, , |A|}. (a) = = . (a) = |A| 6 .(a) indicates time step first used.initial proposition: p P, I(p) {0, 1}. I(p) = 1 iff p I.p P achieved once, i.e., p appears add effects multiple actions ,assign (p) index first action . p achieved, i.e., p 6 I() holds,assign arbitrary value {0, , |A|} (p). Given delete-free task + feasiblenon-redundant plan , call assignment solution derived .usePthe following fact later proofs: solution derived feasible solution satisfies (a) s.t.padd(a ) E(a , p) 1 proposition p U (p) = 1, (b)Ps.t.padd(a ) E(a , p) = 0 proposition p U (p) = 0.Variables I(p) auxiliary variables computing h+ . Although redundantsolving delete-free task one time, useful avoid reconstructing constraintsstate IP(T + ) LP(T + ) embedded heuristic function forward-search plannercalled state.objective function defined follows:Xminimize:c(a)U (a).(1)aAobjective function, cost solution IP(T + ) equal costcorresponding (delete-free) plan.Finally define following six constraints.(C1) p G, U (p) = 1. (The goals must achieved).(C2) A, p pre(a), U (p) U (a). (Actions require preconditions).(C3) A, p add(a), U (a) E(a, p). (An action first achiever used).P(C4) p P, I(p) + s.t.padd(a ) E(a , p) = U (p). (If proposition achieved, musttrue initial state effect action).(C5) A, p pre(a), (p) (a). (Actions must preceded satisfactionpreconditions).(C6) A, p add(a), (a) + 1 (p) + (|A| + 1)(1 E(a, p)). (If first achieverp, must precede p).show solution IP(T + ) derived feasible non-redundant planfeasible. variable V IP(T + ), VF describes assignment V solution FIP(T + ).T+Proposition 1. Given delete-free task + feasible, non-redundant plan + ,solution F IP(T + ) derived feasible solution IP(T + ).638fiO N P RACTICAL , NTEGER -L INEAR P ROGRAMMING ODELProof. F clearly satisfies constraint C1 since satisfies G I().Constraint C2 satisfied exists action proposition p pre(a)U (a)F = 1 U (p)F = 0. However, U (a)F = 1, U (p)F = 1delete-free feasible plan p established point. show F satisfiesconstraints C3 C4 similar arguments. exists action propositionp add(a) E(a, p)F = 1, U (a)F = 1 must hold according definition F .addition, exists proposition p U (p)F = 1, exists first achiever pE(a, p)F = 1, p member initial state I.action member , propositions precondition must achievedused. Hence, according definition F , (p)F (a)F actionplan . action member , (a)F = |A|. Thus, constraintC5 satisfied action plan , regardless values (p)F .Finally F satisfies constraint C6 action proposition preconditionp pre(a). first achiever p, i.e., E(a, p) = 0, constraint C6 satisfiedregardless values (p)F (a)F . first achiever p, then, accordingdefinition F , (p)F = (a)F + 1 , satisfies constraint C6.addition, exists feasible plan IP(T + ) feasible solution. IP(T + )solved optimally, optimal plan + obtained according following proposition.Proposition 2. Given feasible solution F IP(T + ), action sequence = (a0 , , )obtained ordering actions set {a | U (a)F = 1} ascending order (a)F feasibleplan + .Proof. First show satisfies condition (ii) plan (i.e., G I()) using proofcontradiction. Assume exists proposition g G satisfies g 6 I(). Then,exists action achieving g . Since F solution IP(T + ), U (g)F = 1 due constraintC1. Since g 6 I() implies g 6 I, I(g)F = 0. Therefore, satisfy constraint C4, mustexist action g add(a) E(a, g)F = 1. However, satisfy constraint C3,U (a)F = 1 hold. means , contradicts assumption.Next show satisfies condition (i) (i.e., i, pre(ai ) I((a0 , , ai1 ))). basecase inductive proof, assume exists proposition p P satisfying p pre(a0 )p 6 I. Since a0 , U (a0 )F = 1 hold, U (p)F = 1 hold accordingconstraint U (p)F U (a0 )F . Then, similar proof condition (ii), must exist actionp add(a), U (a)F = 1, E(a, p)F = 1. However, satisfy constraint C5,(p) (a0 ) must true, (a) + 1 (p) hold satisfy constraint C6. ThereforeU (a)F = 1 (a) < (a0 ), a0 first action , contradiction.Similar case = 0, > 0, pre(ai ) I((a0 , , ai1 )) true, mustexist action 6 (a0 , , ai1 ) U (a)F = 1 (a) < (ai ), contradicting factai i-th action sequence .Corollary 1. Given optimal solution F IP(T + ), sequence actions built orderingactions set {a | U (a)F = 1} ascending order (a)F optimal plan + .P+ ) 3|P | + 2|A| +number variablesIP(T|add(a)|. number constraintsPPPless 2|PP| + 2 aA |pre(a)| + 2 aA |add(a)|. number terms also O(|P | +|pre(a)| + |add(a)|).639fiI MAI & F UKUNAGA4. Enhanced IP ModelIP(T + ) provides IP model exactly computing h+ , shall see Section 5IP(T + ) competitive previous methods computing h+ . Thus, section,introduce variable elimination techniques modifications constraints orderspeed computation h+ . show experimental results, IPe (T + ),incorporates enhancements, computes h+ significantly faster IP(T + ). enhancements adopted IP framework previous work planning research.particular, landmark-based variable reduction method plays key role.Note enhancements introduce constraints render solutions IP(T + )mapped feasible plans + infeasible. However, show cases, least oneoptimal plan always remain valid enhanced model, optimal cost enhancedmodel still corresponds h+ .4.1 Landmark-Based IP Model Reductionlandmark element needs used every feasible solution (Hoffmann, Porteous,& Sebastia, 2004). use two kinds landmarks, called fact landmarks action landmarkswork Gefen Brafman (2012). fact landmark planning task propositionbecomes true state every feasible plan, action landmark planning taskaction included every feasible plan. also say fact action landmarkl landmark proposition p l landmark task hP, A, I, {p}i. Similarly saylandmark l landmark action l landmark task hP, A, I, pre(a)i.IP model delete-free task + , proposition p fact landmark propositiongoal G, substitute U (p) = 1. Similarly, action action landmark,substitute U (a) = 1. Landmark extraction substitution clearly prune feasiblesolutions IP(T + ).actually extract set landmarks satisfy intensional definitions, landmarkextraction algorithm necessary. easy see givenfeasible delete-free task,ff propositionaddp P fact landmark p holds P, \ Ap , \ {p}, G infeasible,= {a | p add(a)}. Similarly action action landmarkAaddphP, \ {a}, I, Gi infeasible. Hence, landmark candidate, test whetherlandmark checking feasibility delete-free task excludes candidate.feasibility delete-free task checked using following, straightforward algorithm baseddelete-relaxed planning graph method Hoffmann Nebel (2001): fluent, lete(p) {0, 1} represent whether p achievable not. action, let e(a) {0, 1} representwhether preconditions satisfied not. Initially, e(p) = 1 p , e(p) = 0fluents. e(a) = 0 a. step algorithm, actionse(a) = 0 whose preconditions satisfied; (1) set e(a) = 1, (2) set e(p) = 1e add(a). algorithm terminates reaches quiescence, i.e., actionse(a) = 0 whose preconditions satisfied found. takes |A| steps.repeating feasibility check facts actions, algorithm collects factlandmarks action landmarks satisfying definitions O(|T + |2 )-time.interested computing h+ once, straightforward method onedescribed would sufficient. However, since intend use h+ -based modelsheuristic functions forward state-space search planning, landmark extraction needs640fiO N P RACTICAL , NTEGER -L INEAR P ROGRAMMING ODELperformed repeatedly search, efficiency extraction procedure important.experimented several methods, describe effective method below.method extracting landmarks based method Zhu Givan (2003),proposed planning based propagation method collecting causal landmarks. methodlater generalized Keyder et al. AND-OR graph based landmark extraction method (Keyder,Richter, & Helmert, 2010).Zhu Givan (2003) define proposition p causal landmark hP, \ Aprep , \ {p}, Gipreinfeasible, Ap = {a | p pre(a)}. focus causal landmarks, ignoring(non-causal) landmarks nonessential (even misleading) point viewguiding search algorithm uses landmark-based heuristic. contrast, use landmarksorder reduce number variables IP model delete relaxation. Thus, insteadfocusing causal landmarks using Zhu Givans criteria, seek larger set landmarksslightly modifyingcriterion landmarkdetection. hP, \ Aprep , \ {p}, Giffsolution, P, \ Aadd,\{p},Gmustalsoinfeasible,furthermore, usingppreaddAp instead Ap extract larger set fact landmarks. addition, Zhu Givanused forward propagation algorithm based layered planning graph delete-free task+ , use following, open-list based propagation algorithm.proposition p, compute set fact landmarks p, using iterative methodbased following update equations characterizing fact landmarks:p member initial state I, {p} set fact landmarks achieve p.p member I, set fact landmarks p {p} aA s.t.padd(a) (add(a)p pre(a) (fact landmarks p )).pseudocode open list based propagation algorithm shown Algorithm 1.initialization phase, candidate set proposition p 6 set P , fact landmarksp set {p} (Lines 1-3). addition, action inserted FIFO queue Qsatisfies pre(a) (Lines 4-7). main loop iterative method similar straightforward method described above. iteration, action retrieved Q, candidateset fact landmarks updated p add(a) based second equation (Lines 12-14).Moreover, method memorizes achievability p (Line 11), action inserted Qmembers pre(a ) achievable candidate set p pre(a ) changed (Lines15-17). process continues Q becomes empty. clarity simplicity, implementation details/optimizations omitted Algorithm 1, e.g., instead literally inserting everymember P L[p] Line 3, use single flag represent L[p] = P Updating candidate set always reduces number elements, method always terminates. Unlikesimpler O|T + |2 algorithm described above, algorithm complete (not landmarksextracted). However, soundness method guaranteed following proposition.Proposition 3. Given delete-free STRIPS planning task hP, A+ , I, Gi, assume propositionsP achieved. Let L(p) set fact landmark candidates p computedlandmark extracting method.(i) L(p) = {p} p I,(ii) L(p) = {p} aA s.t.padd(a) (add(a) p pre(a) L(p )) p 6641fiI MAI & F UKUNAGAAlgorithm 1 landmark extracting method1:2:3:4:5:6:7:8:9:10:11:12:13:14:15:16:17:18:19:20:21:// L[p] sets candidates fact landmarks p P .L[p] P p 6 I;L[p] {p} p I;I;insert FIFO queue Q pre(a) S;endQ emptyretrieve action Q.p add(a){p}.X L[p] (add(a) p pre(a) L[p ]);L[p] 6= XL[p] X.Aprepinsert Q pre(a ) 6 Q;endendendend// point, L[p] contain sets fact landmarks p P .satisfied, elements L(p) fact landmarks p.Proof. Assume proposition q satisfies q L(p) q fact landmark p.p 6= q since proposition fact landmark itself. Then, L(p) oneproposition, condition (i) (ii), p 6 holds. Since q landmark, existsnon-empty feasible plan delete-free task hP, A+ , I, {p}i achieve q.Let = (a0 , , ) plan, let ai action achieves p first.p 6= q stated above, andSq 6 add(ai ) since achieve q. Hence, accordingcondition (ii), q p pre(ai ) L(p ). Let p member pre(ai ) satisfies q L(p ).Since feasible plan achieve q, p achieved , thus p 6= q holds. Then,L(p ) one proposition, again, p 6 holds. Hence, = (a0 , , ai1 )non-empty feasible plan delete-free task hP, A+ , I, {p }i achieve q.argument extended ad infinitum, length clearly finite,contradiction. Thus, members L(p) fact landmarks p proposition p P .addition fact landmarks extracted using procedure, algorithmextracts action landmarks using criterion: proposition p fact landmark G,one action achieve p, used action landmark G.642fiO N P RACTICAL , NTEGER -L INEAR P ROGRAMMING ODEL4.2 Relevance AnalysisBackchaining relevance analysis widely used eliminate propositions actions irrelevant task. action relevant (i) add(a) G 6= , (ii) exists relevant actionsatisfying add(a) pre(a ) 6= . proposition p relevant (i) p G, (ii) existsrelevant action p pre(a) holds.addition, noted Haslum et al. (2012), sufficient consider relevance respect subset first achievers add effect. Although defined first achieverachievability proposition, equivalent following definition: action firstachiever proposition p p add(a) p fact landmark a. Let fadd(a) denote{p add(a) | first achiever p}. sufficient use fadd instead adddefinition relevance.p P relevant, eliminate variable U (a) = 0 U (p) = 0.addition this, p add(a) first achiever p, eliminate variableE(a, p) = 0. possible fact landmark fact irrelevant, case set U (p) = 1.variable elimination prunes feasible solutions, clearly prune optimalsolutions.4.3 Dominated Action Eliminationdelete-free task, two actions add effects, clearly sufficient useone two actions. idea generalized following reduction,eliminates useless (dominated) actions.Proposition 4. Given feasible delete-free task + , exists optimal plancontain exists action satisfying following: (i) fadd(a) fadd(a ), (ii)p pre(a ), p fact landmark p I, (iii) c(a) c(a ).Proof. plan = (a0 , , ai1 , a, ai+1 , , ) + , show sequence actions= (a0 , , ai1 , , ai+1 , , ) also feasible plan. proposition pre(a ) factlandmark a, hence, pre(a) I((a0 , , ai1 )), pre(a ) I((a0 , , ai1 )) alsoholds. definition first achievers, add(a) \ fadd(a) I((a0 , , ai1 )), alsoI((a0 , , ai1 , a)) I((a0 , , ai1 , ). Therefore G I( ) ( feasible plan).Finally, c() c( ) c(a) c(a ). Therefore, plan contains a, optimal,exists another optimal plan contain a.exists dominated action a, eliminate variable setting U (a) = 0.variable elimination prunes feasible solutions IP(T + ). Moreover, sometimes prunesoptimal solutions c(a) = c(a ) holds condition (iii). However, shown proofabove, least one optimal solution remains.slight generalization similar set constraints Robinson (2012)[Definition5.3.4, p. 108] MaxSAT-based planner. Robinsons dominance condition checks whether (R1)add(a) \ add(a ) \ I, (R2) pre(a ) \ pre(a) \ I, (R3) c(a) c(a ).condition (iii) (R3) equivalent, condition (i) less strict condition (R1)instead checking add effects, condition (i) tests whether propositionsfirst achiever subsumed . Furthermore, condition (ii) subsumes (R2)proposition pre(a ) fact landmark a, pre(a) I((a0 , , ai1 )), pre(a )I((a0 , , ai1 )) also holds, satisfying (R2).643fiI MAI & F UKUNAGA4.4 Immediate Action Applicationdelete-free task + , actions immediately applied initial state withoutaffecting optimality relaxed plan. adopt immediate application zero-cost actions(Gefen & Brafman, 2011) well immediate application action landmarks (Gefen & Brafman,2012). delete-free task + , action satisfies c(a) = 0 pre(a) I,sequence made placing optimal plan hP, \ {a}, add(a), Gi optimalplan + . Similarly, action action landmark + applicable I,applied immediately.IP(T + ) model, variables (p) p eliminated substituting zerovalues. Given sequence immediately applicable actions (a0 , , ak ) (it must correctapplicable sequence), eliminate variables follows: (i) U (ai ) = 1, (ii) (ai ) = i,(iii) p pre(ai ), U (p) = 1, (iv) p add(ai ) \ I((a0 , , ai1 )), U (p) = 1, (p) =E(ai , p) = 1, (v) p add(ai ) \ I((a0 , , ai1 )), \ {a0 , , ai }, E(a, p) = 0.4.5 Iterative Application Variable Eliminationsvariable elimination techniques described interact synergisticallyresulting cascade eliminations. Therefore, used iterative variable elimination algorithmapplies eliminations quiescence. order elimination applied shownAlgorithm 2. full landmark extraction pass variable elimination would extremelyexpensive. Therefore, perform landmark extraction iterative applicationeliminations.Algorithm 2 Iterative Variable Eliminationrelevance analysis;landmark extraction;variable eliminatedimmediate action application;dominated actions elimination;relevance analysis;4.6 Inverse Action Constraintsdefine following inverse relationship pair actions delete-free task + .Definition 1 (inverse action). two actions a1 , a2 A, a1 inverse action a2 if: (i)add(a1 ) pre(a2 ), (ii) add(a2 ) pre(a1 ).definition, clear a1 inverse action a2 , a2 inverse action a1 .Inverse actions satisfy following fact.Proposition 5. Given delete-free task + , let = (a0 , , ) feasible plan. aiinverse action aj , < j holds, = (a0 , , aj1 , aj+1 , , ) alsofeasible plan.Proof. Since feasible plan + , pre(ai ) I((a0 , , ai1 )) I((a0 , , aj1 )).definition inverse actions, add(aj ) pre(ai ) holds, add(aj ) pre(ai ) I((a0 , , aj1 )) =644fiO N P RACTICAL , NTEGER -L INEAR P ROGRAMMING ODELI((a0 , , aj )). Hence (aj+1 , , ) applicable I((a0 , , aj1 )), G I( ) =I().Corollary 2. delete-free task + , feasible solution = (a0 , , ) optimalai inverse action aj ai aj non-zero cost.several possible ways use proposition (e.g., U (a) + U (a ) 1,inv(a), inv(a) set inverse actions a). order avoid adding large numberconstraints IP(T + ) model (|A/2|2 worst case half actions inversesother), modify constraint C2 follows:P(C2a) A, p pre(a), U (p) inv(a,p) E(a , p) U (a), inv(a, p) denotes setinverse actions p add effect.Proposition 6. Given delete-free task + , IP(T + ) constraint C2 feasible solution,optimal solution IP(T + ) constraint C2 also feasible IP(T + ) constraintC2a.Proof. Let F optimal solution IP(T + ) constraint C2 derived optimal plan+ . Since F satisfies constraints IP(T + ) constraint C2, suffices showF satisfies constraint C2a action proposition p pre(a).PRecall feasible solution derived feasible plan satisfies s.t.padd(a ) E(a , p)P1 proposition p U (p) = 1, also satisfies s.t.padd(a ) E(a , p) = 0PPproposition p U (p) = 0. Since s.t.padd(a ) E(a , p) inv(a,p) E(a , p)action proposition p pre(a), F clearly satisfies constraint C2a U (p)F = 1U (a)F = 0,Pif U (p)F = 0 U (a)F = 0 hold.show inv(a,p) E(a , p)F = 0 holds U (a)F = U (p)F = 1, assumeexists action inv(a, p) E(a , p)F = 1. According constraint C3, U (a )F = 1.However, since F derived optimal plan + , must exist optimal plan +contains . contradicts Corollary 2.Since F feasible solution, exist action proposition p pre(a)U (a)F = 1 U (p)F = 0. Hence F satisfies constraint C2ap pre(a).4.7 IPe (T + ): Enhanced IP Model h+define IPe (T + ) integer programming model result first adding inverseaction constraints described Section 4.6 basic IP(T + ) model applying iterative reduction algorithm Algorithm 2 (which applies reductions Sections 4.1-4.4)quiescence. previously noted, IPe (T + ) computes h+ . shall see below, cumulativeeffects enhancements quite significant, resulting much practical IP modelcomputing h+ . See Table 1 summary relationship IPe (T + ) IP(T + ).5. Experimental Evaluation IP Models Delete-Free Planning (ExactComputation h+ )section, evaluate effectiveness integer programming model delete relaxation method solving delete-free tasks computing h+ exactly. evaluate followingmodels:645fiI MAI & F UKUNAGAIP(T + ): basic IP model (Section 3).IP(T + )+LM: IP(T + ) landmark-based variable reduction method (Section 4.1).IPe (T + ): enhanced model includes enhancements described Sections4.1-4.6 designed speed computation h+ (landmark-based reduction,relevance analysis, dominated action elimination, immediate action application, inverse action constraints).emphasize (unlike models evaluated later sections)IP models compute h+ exactly.Following previous work solvers delete-free problems, main results basedevaluation using delete-free versions standard IPC benchmark problems (Section 5.1).addition, Section 5.2, also present results much smaller scale study set natural,delete-free problems systems biology (Gefen & Brafman, 2011).5.1 Evaluation Delete-Free Versions IPC Benchmark InstancesFollowing methodology evaluating delete-free planning previous work (Haslum et al.,2012; Pommerening & Helmert, 2012; Gefen & Brafman, 2012), evaluate IP modelssolving International Planning Contest (IPC) benchmark instances delete effectsactions ignored. Below, experiments used CPLEX 12.61 solver solve integerlinear programs. experiments single-threaded executed Xeon E5-2680, 2.8GHz.previous work computing h+ evaluated using several different setsexperimental settings (different CPU limits different problem instances), present results4 sets comparisons. first 3 sets comparisons, compare benchmark results reportedprevious publications results obtained running solvers problem instances,fourth set results compares models improved implementation minimalhitting set based approach (Haslum et al., 2012) one original authors.Comparison results Pommerening Helmert (2012) (experimental setup described Section 5.1.1, results shown Table 2).Comparison results Gefen Brafman (2012) (experimental setup describedSection 5.1.2, results shown Table 3).Comparison results Haslum et al. (2012) (experimental setup described Section5.1.2, results shown Table 4).Comparison HST/CPLEX, improved implementation algorithm (Haslumet al., 2012) (experimental setup described Section 5.1.3, results shown Table 5Figures 2-3).results copied previous work (Pommerening & Helmert, 2012; Haslum et al., 2012;Gefen & Brafman, 2012) Tables 2-4 obtained using hardware available several years agooriginal papers written, results IP(T + ), IPe (T + ), HST/CPLEXobtained slightly recent hardware. Since coverage coarse metric based binary results (solved/unsolved), significantly impacted differences machine speed,646fiO N P RACTICAL , NTEGER -L INEAR P ROGRAMMING ODELe.g., many problems threshold slightly faster machine (equivalent runningslightly longer) results many instances solved. order eliminate possibilityimprovements hardware since 2010 (when first results comparedpublished) explain improvements obtained using approach, also include results running best IP model (IPe (T + )) significantly shorter CPU time limit previousexperiments, addition results use CPU time limit previous experiments.5.1.1 C OMPARISON R ESULTS P OMMERENINGELETE -F REE V ERSIONS IPC B ENCHMARKSH ELMERT (2012)first comparison results Pommerening Helmert (2012). Table 2 showsresults running IP(T + ), IP(T + )+LM, IPe (T + ) 5 minute time limit 2GB memorylimitation. Coverage (# problem instances solved) domain shown. columnssolver name contains PH12 Table 2 copied paper Pommerening Helmert(2012). FD/PH12 Fast Downward using A* LM-cut heuristic applied deleterelaxed problems, BC/PH12 hitting set based approach Bonet Castillo (2011),BnB/PH12 IDA*/PH12 best performing strategies using incremental LM-cutheuristic delete-free problems proposed Pommerening Helmert (2012). PommereningHelmert obtained results using AMD Opteron 2356 processor 2GB memory limit5 minute time limit.Table 2 includes column IPe (T + )/1min, shows results 1-minute runsIPe (T + ). columns Table 4 5 minute runs.5.1.2 C OMPARISONS R ESULTS G EFEN B RAFMAN (2012) H ASLUM ET AL .(2012) ELETE -F REE V ERSIONS IPC B ENCHMARKSNext, evaluated h+ solvers previous results obtained 30-minute timelimit 2GB memory limit. Table 3 compares IP(T + ), IP(T + )+LM, IPe (T + )results (Gefen & Brafman, 2012, p. 62, Table 2). LM-cut/GB12 column A*LM-cut heuristic (Helmert & Domshlak, 2009) applied directly delete-free instances ordercompute h+ . LM-cut+Pruning/GB12 column A* LM-cut using pruning techniquesdelete-free instances proposed Gefen Brafman (2012). Table 4 compares IP(T + )IPe (T + ) results Haslum et al. (2012, p. 356, Table 1). BC/HST12 columnmethod Bonet Castillo (2011). ML/HST12 column minimal landmark methodproposed Haslum et al.. original work Haslum et al. (2012), minimum-cost hittingset problem solved using specialized branch-and-bound algorithm, ML/HST12 column reflects performance original algorithm. However, Minimal Landmark methodlater significantly improved replacing hitting set solver CPLEX-based solver(Haslum, 2014b), Table 4 also includes HST/CPLEX column, shows resultsMinimal Landmark method using CPLEX hitting set solver. obtained HST/CPLEXresults running HST/CPLEX code machine used run IP models.Table 4 includes column IPe (T + )/5min, shows results 5-minute runsIPe (T + ) (all columns Table 4 30 minute runs).Note Table 4, instances IPC2008 IPC2011 sequential satisfying track (i.e., -sat08 -sat11 domain names), accordance original paper(Haslum et al., 2012).647fiI MAI & F UKUNAGA5.1.3 C OMPARISONHST/CPLEXELETE -F REE V ERSIONS IPC B ENCHMARKSdetailed comparison improved implementation hitting-set based methodHaslum et al. (2012). Although original version algorithm used problem-specificbranch-and-bound method solve hitting set problems, used recent versionHaslums h+ solver (source dated 2014-1-17), configured use CPLEX 12.61 solve hitting set subproblem. configuration abbreviated HST/CPLEX. shown Table4, HST/CPLEX significantly outperforms original HST implementation described (Haslumet al., 2012), compares favorably vs. previous methods.Tables 5-6 Figures 2-3 compare IP(T + ), IPe (T + ), IP(T + )+LM, HST/CPLEX 1376IPC benchmark instances. algorithms run 2GB memory limit. Table 5 shows results30 minute time limit, Table 6 shows results 5 minute time limit. Tables 56 compares coverage runtimes per domain, Figure 2 compares cumulative numberinstances solved function time, Figure 3 compares runtimes individualinstances.contrast previous set experiments described Section 5.1.2, used optimal trackinstances (-opt08 -opt11 domain names) satisficing optimal trackinstances available benchmark sets. subsequent sections,focus applying models basis heuristics forward-search, cost-optimal planning.5.1.4 ISCUSSION R ESULTS ELETE -F REE V ERSIONS IPC B ENCHMARKSsurprisingly, basic IP(T + ) model competitive previous state-of-the-art methods specifically developed computing h+ (Haslum et al., 2012; Pommerening &Helmert, 2012). However, Table 3 shows basic IP(T + ) model least competitiveA* LM-cut enhanced Gefen Brafmans pruning methods delete-free instances(Prune/GB12). IP(T + ) also significantly outperforms standard A* LM-cut (Table 3, LMcut/GB12 Table 2, FD/PH12).hand, enhancing IP(T + ) landmark-based model reduction method resultssignificant improvement, IP(T + )+LM competitive previous methods exceptHST/CPLEX.IPe (T + ) model, includes enhancement described Section 4 reducingmodel order compute h+ faster, performs well overall, competitiveprevious methods. example, Table 4, IPe (T + ) highest coverage (or tied highest)19/28 domains. Table 5, Figure 2, Figure 3 show IPe (T + ) HST/CPLEXsimilar coverage 30-minute time limit, IPe (T + ) tends somewhat faster overall.However, clear dominance relationship IPe (T + ) HST/CPLEX, sincedomains IPe (T + ) clearly performs better (e.g., rovers, satellite, freecell) ,domains HST/CPLEX performs better (e.g., airport, pegsol, scanalyzer, transport). Thus,IP-based approach minimal landmark approaches seem complementary strengthsrespect solving delete-free problems.Aside coverage, Figure 3 shows many delete-free instances solved much fasterIPe (T + ) HST/CPLEX. difference solving easy delete-free instance 0.1vs. 0.5 seconds may seem important need solve instance once. However,speed difference IPe (T + ) HST/CPLEX easy delete-free instancessignificant implication consider using h+ solvers heuristic functions A* -based648fiO N P RACTICAL , NTEGER -L INEAR P ROGRAMMING ODELplanners, may need solve delete-free problems many thousands times coursesingle A* search. result, see Section 7, A* using IPe (T + ) heuristicsignificantly outperforms A* using HST/CPLEX heuristic.order eliminate possibility CPU speed differences account qualitative improvements coverage obtained IP models compared previously published results, Table2 includes column IPe (T + )/1min, result 1-minute runs IPe (T + ), Table4 includes column IPe (T + )/5min, result 5-minute runs IPe (T + ) effect,simulate machines run 1/5 1/6 (respectively) speed machine usedexperiments Tables 2 4. offsets improvements single-core CPUperformance 2010-2015. coverage achieved IPe (T + )/1min (753) Table 2higher solvers Table 2 given 5 minutes. Similarly, coverageachieved IPe (T + )/5min (847) Table 4 higher solvers Table 4given 30 minutes.Therefore, overall, IPe (T + ) competitive previous state-of-the-art delete-free solvers,results indicate direct computation h+ using integer programming viable approach,least computing delete-free task once.5.2 Comparison HST/CPLEX Minimal Seed Set Problemassess performance best IP model, IPe (T + ) natural, delete-free task, alsocompared IPe (T + ) HST/CPLEX set minimal seed set problem instances systemsbiology (Gefen & Brafman, 2011). consist 22 instances originally evaluated GefenBrafman, well three additional versions 22 instances also providedoriginal authors, version uses different set action costs (Gefen & Brafman, 2011, p.322), total 22 4 = 88 instances. solvers run 1 hour CPU time limit perinstance 2GB RAM limit.Figure 4 shows scatter plot comparing runtimes problem instance. coverageIPe (T + ) 87 instances, coverage HST/CPLEX 88 instances. one hand,Figure 4 shows majority instances solved significantly faster IPe (T + ),IPe (T + ) solves 22 instances 10 times faster HST/CPLEX. hand,one instance HST/CPLEX 10 times faster IPe (T + ),one instance solved 40.7 seconds HST/CPLEX solved withintime limit IPe (T + ) (The dre instance type 2 preprocessing Gefen & Brafman,2011, p. 322).6. Relaxations h+ ModelsAlthough delete-free planning problems interesting right, main motivationdeveloping efficient IP model delete-free problems able use basisheuristic function forward-state space search based domain-independent planner. far,presented IP(T + ), basic IP model computes h+ , proposed IPe (T + ),incorporates number enhancements which, shown experimental results Section5, significantly increase scalability model provide new approach computing h+competitive previous state-of-the-art methods. possible simply use IPe (T + )heuristic function forward search based planner. However, shown Section 5,computing h+ remains relatively expensive even using IPe (T + ), surprising, given649fiI MAI & F UKUNAGA(Pommerening & Helmert, 2012, Table 2)Domain (# problems)airport(50)blocks(35)depot(22)driverlog(20)freecell(80)grid(5)gripper(20)logistics00(28)logistics98(35)miconic(150)no-mprime(35)no-mystery(30)openstacks-opt08(30)pathways-noneg(30)pipes-notankage(50)pipes-tankage(50)psr-small(50)rovers(40)satellite(36)tpp(30)trucks(30)zenotravel(20)Total coverage (876)# Best DomainsIP(T + )IP(T + )+LMIPe (T + )IPe (T + )/1minFD/PH12BC/PH12BnB/PH12IDA*/PH12solved2235614110202481501515230855040311130145417solved36351914174202821150202130301395040302430146559solved363521158052028271503130303011950403430302076219solved353521148052028241503028303010950403430302075315solved34357146120239150272655171050136137134915solved5035521120267150141604325012612384275solved503514152220281615027285518950198239135467solved5035141532202815150262845191050199249135489Table 2: Coverage (# instances solved) delete-free problems (exact computation h+ ).5-minute time limit (except IPe (T + )/1min run 1-minute time limit), 2GBRAM. Comparison data Table 2 paper Pommerening Helmert (2012). #Best domains number domains solver achieves highest coverage(including ties).(Gefen & Brafman, 2012, Table 2)Domain (# problems)blocks(35)depot(22)driverlog(20)freecell(80)gripper(20)logistics00(28)logistics98(35)miconic(150)no-mystery(30)pipesworld-notankage(50)pipesworld-tankage(50)rovers(40)Total coverage (560)# Best DomainsIP(T + )IP(T + )+LMIPe (T + )LM-cut/GB12Prune/GB12solved35814122024815021117403504solved3519142020282315023179403986solved35211580202828150301794047311solved357146202310150261710133315solved35121522028161502699233455Table 3: Coverage (# instances solved) delete-free problems (exact computation h+ ).30-minute time limit, 2GB RAM. Comparison data Table 2 paper GefenBrafman (2012).650fiO N P RACTICAL , NTEGER -L INEAR P ROGRAMMING ODEL(Haslum et al, 2012,Table 2)IP(T + )Domain (# problems)airport(50)barman-sat11(20)blocks(35)depot(22)driverlog(20)elevators-sat08(30)floortile-sat11(20)freecell(80)gripper(20)logistics98(35)logistics00(28)miconic(150)no-mprime(35)nomystery-sat11(20)parcprinter-08(30)pegsol-08(30)pipesworld-notankage(50)pipesworld-tankage(50)psr-small(50)rovers(40)satellite(36)scanalyzer-08(30)sokoban-sat08(30)transport-sat08(30)trucks(30)visitall-sat11(20)woodworking-sat08(30)zenotravel(20)Total coverage (1041)# Best Domainssolved227358141191220824150201130251175040311025230829156647IP(T + )+LMsolved408351914520202023281502313302417950403110293307301574310IPe (T + )solved3993521153020802028281503419302617950403410297308302086819HST/CPLEXsolved5020352014301276202028150317303024105032142130153016291485816IPe (T + )HST/CPLEX5min5minsolved366352115301980202728150311930251195040349296307302084716solved5020352014301248201828150264303017105031111630123010291279312ML/HST12BC/HST12solved5018351813271217201527150285303020155018815306302191372110solved50535128119020627991743030965019543063009105418Table 4: Coverage (# instances solved) delete-free problems (exact computation h+ ).30-minute time limit (except IPe (T + )/5min HST/CPLEX/5min run 5minute time limit), 2GB RAM. Comparison data Table 2 paper Haslum et al.(2012).651fiI MAI & F UKUNAGAIP(T + )/30minDomain (# problems)airport(50)barman-opt11(20)blocks(35)depot(22)driverlog(20)elevators-opt08(30)elevators-opt11(20)floortile-opt11(20)freecell(80)grid(5)gripper(20)logistics98(35)logistics00(28)miconic(150)no-mprime(35)no-mystery(30)nomystery-opt11(20)openstacks(30)openstacks-opt08(30)openstacks-opt11(20)parcprinter-08(30)parcprinter-opt11(20)parking-opt11(20)pathways-noneg(30)pegsol-08(30)pegsol-opt11(20)pipesworld-notankage(50)pipesworld-tankage(50)psr-small(50)rovers(40)satellite(36)scanalyzer-08(30)scanalyzer-opt11(20)sokoban-opt08(30)sokoban-opt11(20)tpp(30)transport-opt08(30)transport-opt11(20)trucks(30)visitall-opt11(20)woodworking-opt08(30)woodworking-opt11(20)zenotravel(20)Total coverage (1376)# Best Domainssolved2283581421201202082415020211353030202302513117504031107292013403020302015time253.971616.970.08151.0719.05294.94525.764.67130.8200.02194.0112.210.08202.01187.66180.88114.55506.6300.080.06529.751.50229.13360.87370.96154.580.0311.7735.88306.24442.4434.1239.14256.03289.6301.943.972.042.4035.5484314IP(T + )+LM/30minsolved408351914201320204202328150232317253020302018302414179504031107292024403020302015time173.581522.410.0012.7515.77201.74179.161.76259.965.590.0289.770.030.09221.48129.89224.4082.480.080.040.040.03172.211.1339.01105.91198.5122.870.020.3438.40292.41439.540.610.4755.7145.0000.701.760.520.4736.69104417IPe (T + )/30minsolved392035211530202080520282815034302030302030202030261517950403410730203015163020302020time sd134.68 452.9914.29 40.800.00 0.000.92 1.905.47 18.320.38 0.460.32 0.421.08 3.020.32 0.216.50 11.290.00 0.0039.07 132.250.01 0.020.01 0.0153.06 132.8712.84 44.490.11 0.110.39 1.090.01 0.010.01 0.010.02 0.010.01 0.010.30 0.230.05 0.0340.72 126.7986.91 183.21221.80 306.9018.39 44.420.01 0.050.13 0.220.96 1.6486.52 173.64129.49 213.4156.97 305.420.23 0.284.58 9.54151.31 421.56203.80 424.600.03 0.021.07 2.930.02 0.010.02 0.013.21 9.13121434HST/CPLEX/30minsolved5020352014302015765202028150313082730203020203030202410503214211330202827203020302014time sd9.99 36.340.04 0.080.00 0.003.50 8.7017.30 56.930.09 0.070.07 0.0454.56 193.72320.71 433.351.41 1.610.01 0.01146.85 339.480.03 0.060.04 0.05106.60 242.3712.43 29.270.36 0.4981.80 258.730.04 0.040.03 0.020.07 0.120.04 0.0515.97 30.892.55 3.080.01 0.010.01 0.01223.55 358.144.32 11.940.01 0.0534.36 123.88205.10 384.71242.91 460.55338.77 536.070.07 0.120.07 0.13142.13 272.08100.16 146.5718.30 35.031.32 2.100.21 0.380.15 0.270.09 0.07179.65 453.63120231Table 5: Detailed comparison IP(T + ), IP(T + )+LM, IPe (T + ), HST/CPLEX 1376 deletefree tasks (exact computation h+ ). 30-minute time limit, 2GB RAM. Coverage meanstandard deviation runtimes (average successful runs only, excludes unsuccessful runs).652fiO N P RACTICAL , NTEGER -L INEAR P ROGRAMMING ODELIP(T + )/5minDomain (# problems)airport(50)barman-opt11(20)blocks(35)depot(22)driverlog(20)elevators-opt08(30)elevators-opt11(20)floortile-opt11(20)freecell(80)grid(5)gripper(20)logistics98(35)logistics00(28)miconic(150)no-mprime(35)no-mystery(30)nomystery-opt11(20)openstacks(30)openstacks-opt08(30)openstacks-opt11(20)parcprinter-08(30)parcprinter-opt11(20)parking-opt11(20)pathways-noneg(30)pegsol-08(30)pegsol-opt11(20)pipesworld-notankage(50)pipesworld-tankage(50)psr-small(50)rovers(40)satellite(36)scanalyzer-08(30)scanalyzer-opt11(20)sokoban-opt08(30)sokoban-opt11(20)tpp(30)transport-opt08(30)transport-opt11(20)trucks(30)visitall-opt11(20)woodworking-opt08(30)woodworking-opt11(20)zenotravel(20)Total coverage (1376)# Best Domainssolved2203561410201102082415015151152030200302298550403174281911303020302014time sd0.8200.0829.3517.3325.4004.7473.0700.0220.4511.640.0828.019.3537.8566.3916.8900.070.0501.5374.55131.785.5331.710.0310.2629.8757.2634.2027.2722.2212.428.6401.603.801.982.174.0279013IP(T + )+LM/5mintime0.3300.0012.8517.0441.0930.131.6443.145.390.0219.560.030.0830.0227.7442.1531.370.080.040.030.0369.501.1416.6036.0937.5821.570.020.3328.8148.9915.280.580.4649.3143.1600.671.830.490.461.04solved3603519141611201742021281502021142430203020153023121395040307429202440302030201499417IPe (T + )/5minsolved36203521153020208052027281503130203030203020203025131195040349629203013133020302020time sd4.10 23.8313.60 38.230.00 0.000.93 1.955.86 19.830.39 0.470.31 0.411.05 2.930.30 0.206.35 11.050.00 0.0013.94 36.730.01 0.020.01 0.0114.91 51.5212.04 41.800.10 0.100.37 1.000.01 0.010.01 0.010.01 0.010.01 0.010.29 0.220.04 0.0316.24 37.0116.65 20.1716.55 52.1814.65 34.930.01 0.040.13 0.231.03 1.7941.39 56.9852.22 66.890.25 0.330.23 0.284.60 9.6611.60 24.2528.55 42.330.03 0.021.11 3.080.02 0.010.02 0.013.38 9.70119033HST/CPLEX/5minsolved502035201430201448520182815026308243020302020303020171050311116930202424203020302012time sd9.44 34.940.04 0.080.00 0.003.47 8.5717.03 56.020.08 0.070.07 0.042.80 4.2160.87 80.811.37 1.540.01 0.0034.28 67.680.03 0.060.04 0.0511.27 23.4212.88 30.690.34 0.4612.20 35.900.04 0.040.03 0.020.07 0.110.04 0.0515.07 28.612.47 2.920.01 0.010.01 0.0121.71 35.684.31 11.930.01 0.0512.55 28.7616.92 40.9921.91 45.0723.20 54.450.07 0.120.07 0.1346.47 81.7056.58 87.0817.45 32.841.74 3.160.21 0.380.14 0.260.08 0.0720.86 65.51113431Table 6: Detailed comparison IP(T + ), IP(T + )+LM, IPe (T + ), HST/CPLEX 1376 deletefree tasks (exact computation h+ ). 5-minute time limit, 2GB RAM. Coverage meanstandard deviation runtimes (average successful runs only, excludes unsuccessful runs).653fiI MAI & F UKUNAGA14001200Instances solved1000800600400IPe(T+)HST/CPLEX20000.0001IP(T+)+LMIP(T+)0.0010.010.11101001000Time (seconds)Figure 2: Comparison IP(T + ), IP(T + )+LM, IPe (T + ), HST/CPLEX delete-free tasks(exact computation h+ ). 30-minute time limit, 2GB RAM. cumulative number instances(out 1376 instances Table 5) solved within ime seconds shown.computing h+ NP-equivalent (Bylander, 1994). Haslum (2012) reported previous, baselineresults using direct computation h+ using hitting-set method proposed earlier work(Haslum et al., 2012) heuristic A* , reported poor results. Although show Section7 A* using IPe (T + ) performs well domains, using h+ directly heuristic A*continues pose significant challenge. Thus, turn next relaxations IP(T + ) IPe (T + )lower bounds h+ computed faster, making suitable admissibleheuristics forward-search planner IP models.6.1 LP(T + ) LPe (T + ): LP Relaxations Delete-Relaxation (h+ ) Modelslinear programming (LP) relaxations IP models obvious candidates tractablealternatives computing h+ using IP(T + ) IPe (T + ). LP-relaxations trivially derivedIP models eliminating integer constraints variables, optimal costLP-relaxation lower bound optimal cost IP. denote LP relaxationIP(T + ) LP(T + ) LP relaxation IPe (T + ) LPe (T + ) (see Table 1). caseproblem domains integer action costs, ceiling LP costs used.Although LPe (T + ) solved quickly, tight theoretical bounds gap IP(T + )LP(T + ) gap IPe (T + ) LPe (T + ) difficult obtain provenBetz Helmert (2009) exists constant c > 0 polynomial-time algorithmcomputing lower bound h states s, h(s) ch+ , unless P = N P (i.e.,h+ polynomial-time approximable constant factor c). Fortunately, worst-case654fiO N P RACTICAL , NTEGER -L INEAR P ROGRAMMING ODEL100*x10*xxx/100x/101101001000100IPe(T+)1010.10.010.0010.0010.010.11000HST/CPLEXFigure 3: Comparison runtimes IPe (T + ) HST/CPLEX 1376 delete-free instances (exact computation h+ , instances Table 5). 30-minute time limit, 2GB RAM. point represents problem instance. x-axis represents runtime HST/CPLEX, y-axis represents runtimeIPe (T + ). example, point diagonal (y = x) indicates IPe (T + ) solved problem represented point faster HST/CPLEX, point = x/10 line indicates IPe (T + )solved problem represented point least 10 times faster HST/CPLEX. algorithm failedsolve instance within 30-minute time limit, runtime shown 1800 seconds.theoretical approximation results necessarily apply real-world problem instances. fact,experimental results show LP-relaxations often provide fast, accurate, lowerbounds h+ standard planning benchmark problems.6.2 Time-Relaxation h+ Modelsmotivation embed computation h+ (or approximation thereof) admissibleheuristic A* , necessarily interested actual optimal delete-free plan + ,cost plan (or approximation). particular, exact order actionsexecuted delete-relaxed plan matter, necessity time-related variablesbrought question.time-relaxation IP(T + ), IP(T + ) without constraints C5 C6, denotedIPtr (T + ). LP relaxation IPtr (T + ) denoted LPtr (T + ). Table 1 summarizes relationships among models.propositions actions task satisfy conditions, eliminating time-relatedvariables affect cost optimal solution IP(T + ). example, relaxedcausal AND/OR graph (Gefen & Brafman, 2012) task cycle,decide values (p) (a) constraints C5 C6 IP(T + ) satisfied in655fiI MAI & F UKUNAGA1000IPe(T+)1001010.10.010.0010.001x10*xx/100.010.11101001000HST/CPLEXFigure 4: Runtime comparisons IPe (T + ) HST/CPLEX minimal seed set problem (88 natural,delete-free instances Gefen & Brafman, 2011). 60-minute time limit, 2GB RAM. point representsproblem instance. algorithm failed solve instance within 60-minute time limit, runtimeshown 3600 seconds. coverage IPe (T + ) 87 instances, coverage HST/CPLEX88 instances.dependently values variables, case optimal costs IP(T + )LP(T + ) optimal costs IPtr (T + ) LPtr (T + ), respectively.Indeed, shall show experimentally Section 6.3 relaxation quite tight, i.e.,IP(T + ) IPtr (T + ) often cost, IPtr (T + ) computed significantly faster IP(T + ). Similarly, LPtr (T + ), LPetr (T + ), IPetr (T + ), time-relaxationsLP(T + ), LPe (T + ), IPe (T + ), computed much faster non-time-relaxedcounterparts.6.3 Experimental Evaluation LP Time Relaxation Gapsevaluated quality LP(T + ), LPe (T + ), LPetr (T + ) linear programming bounds described comparing optimal costs computed bounds exact h+ values (computedusing IPe (T + )). used set 1376 instances Table 5. Table 7 shows mean ratiooptimal cost LP model h+ , instances h+ could computed usingIPe (T + ). perfect columns indicate fraction instances optimal costLP model equal h+ . Note used ceiling LP cost, since IPC benchmarkinstances integer costs. stacked histogram representation data (aggregateddomains) classifies ratios optimal costs LP relaxations value h+shown Figure 5.expect variable-fixing constraints enhanced LPe (T + ) model wouldtend increase value optimal solution LPe (T + ) compared optimal valuebase LP relaxation, LP(T + ). addition, would also expect optimal value LPe (T + )would tend greater optimal value time relaxation, LPetr (T + ). Table 7 shows656fiO N P RACTICAL , NTEGER -L INEAR P ROGRAMMING ODELgeneral, LPe (T + ) LPetr (T + ) LP(T + ). 10/43 domains, LPe (T + ) matches h+ perfectly,i.e., LPe (T + )/h+ = 1. 20/43 domains, LPe (T + )/h+ 0.95. almost every single domain,optimal LP value enhanced model LPe (T + ) significantly better (higher) basicformulation LP(T + ), confirming variable elimination additional constraints servetighten LP bound. Thus, enhancements basic model described Section 4 providesignificant benefit beyond speedups demonstrated Section 5. time-relaxationLPetr (T + ) usually close LPe (T + ), indicating time relaxation potentiallyachieve good tradeoff computation cost accuracy (and fact, see laterSection 7, LPetr (T + ) performs quite well used heuristic A* ).comparison, also evaluated ratio value LM-cut heuristic (Helmert &Domshlak, 2009) h+ . Comparing average ratios lower bound h+ , see that:LP(T + ) less informative LM-cut 31 domains, informative LM-cut 5domains, equivalent 6 domains.LPe (T + ) less informative LM-cut 16 domains, informative LM-cut19 domains, equivalent 8 domains.LPetr (T + ) less informative LM-cut 17 domains, informative LM-cut17 domains, equivalent 9 domains.Thus, LM-cut better approximation h+ basic LP-relaxation, LP(T + ),LPetr (T + ) roughly equivalent LM-cut. Interestingly, LP-relaxation approach appears highly complementary cost-partitioning approach LM-cut,LP-relaxation LM-cut informative roughly half casescompared other.LPe (T + )11.0[0.8-1.0)[0.6-0.8)[0.4-0.6)[0.2-0.4)[0.0-0.2)0.9Fraction Instances0.80.70.60.50.40.30.20.10LPLPeLPetrFigure 5: Ratio optimal LP costs h+ , categorized buckets. [x:y) = fractioninstances ratio LP/h+ range [x:y). example, fraction instancesratio optimal value LPetr (T + ) h+ range [0.8,1,0) approximately0.24 (this stacked histogram based data Table 6.3).657fiI MAI & F UKUNAGALM-cutperfect1.00.74.740.99.97.640.89.20.77.06.80.10.94.05.290.67.401.001.00.98.40.99.921.001.00.76.20.79.28.93.50.6101.001.001.001.00.99.70.99.65.870.87.13.60.26.55.05.68.02.7501.001.00.87.12.95.23.95.32.97.26.94.53.96.60.98.55.87.03.84.05.920.69.10.89.13.88.10.95.50LM-cut/h+airportbarman-opt11blocksdepotdriverlogelevators-opt08elevators-opt11floortile-opt11freecellgridgripperlogistics98logistics00miconicno-mprimeno-mysterynomystery-opt11openstacksopenstacks-opt08openstacks-opt11parcprinter-08parcprinter-opt11parking-opt11pathways-nonegpegsol-08pegsol-opt11pipesworld-notankagepipesworld-tankagepsr-smallroverssatellitescanalyzer-08scanalyzer-opt11sokoban-opt08sokoban-opt11tpptransport-opt08transport-opt11trucksvisitall-opt11woodworking-opt08woodworking-opt11zenotravelLP(T + )perfect.46.02.170.92.20.500.85.10.210.200.95.10.120.31.201.001.00.39.02.46.031.001.00.420.390.96.60.23.031.001.001.001.00.99.66.99.70.880.90.13.26.03.200.520.580.87.82.480.82.13.94.30.96.25.33.13.28.15.28.13.080.090.400.98.65.810.800.91.25LP(T + )/h+LPe (T + )perfect.98.94.3801.001.00.92.22.87.21.650.640.95.10.94.35.81.201.001.00.89.11.99.851.001.00.71.33.77.331.00.951.00.961.001.001.001.00.99.66.99.70.92.10.98.60.64.03.650.83.38.93.551.001.00.65.35.82.21.94.75.96.71.95.73.97.80.85.26.35.08.4101.001.00.98.651.001.001.001.00.92.31LPe (T + )/h+LPetr (T + )+LPe(T)/h+perfecttr.98.381.00.91.83.64.62.95.92.791.00.88.991.00.63.721.00.881.001.00.99.99.87.98.64.65.79.911.00.65.82.94.96.94.97.85.35.411.00.971.001.00.89.7001.00.18.0500.10.23.201.00.05.781.00.17.30.951.001.001.00.66.700.60.030.08.361.00.30.20.34.29.66.75.26.0301.00.651.001.00.30Table 7: Gaps LP models h+ : mean ratio LP model h+ (on 1228instances solved using IPe (T + ) shown. perfect columns indicate fraction instancesoptimal cost LP model equal h+ .658fiO N P RACTICAL , NTEGER -L INEAR P ROGRAMMING ODELFigure 6 compares runtimes CPLEX LP solver relaxed h+ models. LPe (T + )significantly faster LP(T + ), solving many instances 2-10 times faster (and solving instances 10 times faster), demonstrating benefits enhanced model. comparison LPetr (T + ) LPe (T + ) shows using time relaxation results addition speedupfactor 2. additional speedup may seem significant solvingsingle LP instance takes fraction second, cumulative effects using LP models heuristic forward-search based planning significant, show Section 7,results increased coverage using LPetr (T + ) heuristic A* , compared LPe (T + ).1001001010LPetr(T+)1000LPe(T+)100010.10.1x10*x2*xx/2x/100.010.0010.00110.010.11LP(T+)10100x10*x2*xx/2x/100.0110000.0010.0010.010.11LPe(T+)101001000Figure 6: Runtime comparisons relaxed h+ models. 1376 delete-free instances (exact computationh+ , instances Table 5). 30-minute time limit, 2GB RAM. point represents problem instance.left subfigure compare LP(T + ) vs LPe (T + ), showing impact enhancements basic LPmodel, right subfigure compares LPe (T + ) vs LPetr (T + ), showing impact time relaxation.algorithm failed solve instance within 30-minute time limit, runtime shown 1800seconds.7. Cost-Optimal Planners Using h+ -Based Heuristicsembedded IP LP models introduced far A* -based, cost-optimalforward search planner (our planner implementation, uses propositional representationinternally) evaluated performance. Note particular experiment limited admissible heuristics whose value bounded h+ . later results Section 8 9 includeheuristics necessarily bounded h+ . Specifically, evaluated followingsolver configurations:A* /IP(T + ) : A* basic delete-free IP model IP(T + ) heuristic.A* /IPe (T + ) : A* enhanced delete-free IP model IPe (T + ) heuristic.A* /LPe (T + ) : A* LP relaxation enhanced delete-free IP model IPe (T + )heuristic.A* /LPetr (T + ) : A* LP relaxation time-relaxed, enhanced delete-free IP modelIPe (T + ) heuristic.659fiI MAI & F UKUNAGAhsp/HST/CPLEX : A* heuristic hitting-set based h+ solver HST/CPLEX(Haslum et al., 2012) using CPLEX solve hitting set instances (hsp planner providedPatrik Haslum).FD/hmax : Fast Downward using hmax heuristic (Bonet & Geffner, 2001).FD/LM-cut : Fast Downward using landmark cut heuristic (Helmert & Domshlak, 2009)(the standard seq-opt-lmcut configuration)per standard IPC sequential optimal track settings, solver configurations run30 minute time limit per problem 2GB RAM limit. set 1376 instances IPC1998IPC-2011 used. planner currently handles STRIPS subset PDDL action costs.Table 8 compares coverage heuristics. Figure 7a shows cumulative coverage(out 1376) solved function time solver configurations compared Table 8,Figure 7b shows cumulative coverage function number node evaluations (callsheuristic function A* ).compare IP/LP-based A* -heuristics planners, note significant implementation-level differences heuristic function affect executionspeed. example, Fast Downward uses multi-valued SAS+ representation (Backstrom & Nebel,1995) internally represent states, planner uses STRIPS propositional representation,significant differences internal data structures implementation details. Thus,results used qualitative comparisons.Table 8 shows A* /IP(T + ), uses basic IP(T + ) model, worst coverageamong IP models (403), comparable A* /HST/CPLEX(398). noted Haslum(2012), straightforward use h+ heuristic unsuccessful (even worse FD usinghmax , coverage 540) cost computing h+ search node high.However, shown Section 5, solving IPe (T + ) IP model significantly fasterIP(T + ) A* /HST/CPLEX. makes much viable heuristic function A* ,result, A* /IPe (T + ) coverage 635, significantly outperforming A* /HST/CPLEXwell FD/hmax.shown Section 6.3, LP relaxations IP models provide relatively tight lowerbounds h+ . Since LP models solved much faster IP, quite effectiveused heuristics A* . Thus, A* /LPe (T + ), uses LP-relaxation enhancedIPe (T + ) model, coverage 696, A* /LPetr (T + ), uses LP-relaxationtime-relaxed, enhanced IP model, coverage 705.Section 6.3, showed LPe (T + ) LPetr (T + ) models complementary LMcut respect informativeness, suggests least respect search efficiency,LP models competitive LM-cut. Figure 7b shows fact, A* /LPe (T + )A* /LPetr (T + ) tend search quite efficiently, seen linesLM-cut line (i.e., problems solved using given number evaluations) 105 106 node evaluations, point overtaken LM-cut line.informativeness comparison Section 6.3 showed LP models comparable complementary LM-cut respect informativeness, FD/LM-cut outperforms A* /LPetr (T + )A* /LPetr (T + ) domains. LM-cut implementation Fast Downwardoften significantly faster current implementation LP-based heuristics. Nevertheless, several domains (freecell, parcprinter-08, parcprinter-opt11, satellite, trucks, visitall),660fiO N P RACTICAL , NTEGER -L INEAR P ROGRAMMING ODELDomain (# problems)airport(50)barman-opt11(20)blocks(35)depot(22)driverlog(20)elevators-opt08(30)elevators-opt11(20)floortile-opt11(20)freecell(80)grid(5)gripper(20)logistics98(35)logistics00(28)miconic(150)no-mprime(35)no-mystery(30)nomystery-opt11(20)openstacks(30)openstacks-opt08(30)openstacks-opt11(20)parcprinter-08(30)parcprinter-opt11(20)parking-opt11(20)pathways-noneg(30)pegsol-08(30)pegsol-opt11(20)pipesworld-notankage(50)pipesworld-tankage(50)psr-small(50)rovers(40)satellite(36)scanalyzer-08(30)scanalyzer-opt11(20)sokoban-opt08(30)sokoban-opt11(20)tpp(30)transport-opt08(30)transport-opt11(20)trucks(30)visitall-opt11(20)woodworking-opt08(30)woodworking-opt11(20)zenotravel(20)Total coverage (1376)# Best domainsFD/hmaxFD/LM-cuthsp/HST/CPLEXA* /IP(T + )A* /IPe (T + )A* /LPe (T + )solved21418491513415272105023178719141410042717167496696272061167994854015solved284287142218715276201412316147191419143527171784977151230206116101117121374836solved240171731119123107915158572191404174961945526357231514873980solved140192900280431613710580201914051032437852315207912794030solved24027710974542551914020151471052116251021084871052171367213101711963513solved250287111310644266201401813147116201615261612748710852319694151616101069614+A* /LPetr (T )solved2502871313107432662014117121471162016152616137487108525196105151617111170517Table 8: Comparison forward search (A* ) planners, part 1: Number problems solved 30minute, 2GB RAM limit using A* IP/LP models bounded h+ (Sections3-7) heuristic functions. Comparison Fast Downward hmax , Fast DownwardLandmark Cut, hsp planner using HST/CPLEX (Haslum et al., 2012) compute h+ ,heuristic function.A* /LPetr (T + ) achieves higher coverage FD/LM-cut. Thus, A* /LPetr (T + ), bestmodel among bounded h+ , considered fairly powerful, admissible heuristic function forward-state search based planning.661fiI MAI & F UKUNAGA800700Instances solved600500400300FD/LMcutA*/LPetr(T+)A*/LPe(T+)A*/IPe(T+)FD/hmax20010000.11101001000Time (seconds)(a) Cumulative number problems solved (out 1376) vs time (30 minute time limit).800700Instances solved600500400300FD/LMcutA*/LPetr(T+)A*/LPe(T+)A*/IPe(T+)FD/hmax2001000110100100010000 100000 1e+061e+071e+08Evaluations(b) Cumulative number problems solved (out 1376) vs number search nodes evaluated (30 minutetime limit).Figure 7: Comparison forward search (A* ) planners, part 1 ( heuristics boundedh+ ).662fiO N P RACTICAL , NTEGER -L INEAR P ROGRAMMING ODEL8. Incorporating Counting Constraintsfar, concentrated efficient computation h+ well relaxations h+ ,models far bounded h+ . However, IP model extendedconstraints consider delete effects. adding variables constraints related delete effectsactions, model also calculate lower bounds number times action mustapplied. New variables defined follows:A, N (a) {0, 1, } : N (a) = n iff used n times.p P, G(p) {0, 1} : G(p) = 1 iff p G.G(p) auxiliary variable similar I(p). Furthermore, extended model, meaningU (a) {0, 1} slightly modified mean action used least optimalsolution (in basic model proposed Section 3, pure delete-free model, U (a)denoted whether used exactly optimal solution).New constraints defined follows:(C7) A, N (a) U (a).PP(C8) p P, G(p) + as.t.ppredel(a) N (a) I(p) + as.t.padd(a) N (a),predel(a) = pre(a) del(a). Finally, objective function modified minimizePaA c(a)N (a). Given planning task , use IPc (T ) denote IP problem addsnew variables constraints IP(T + )idea types constraints previously proposed several times (for SAS+formulation), correspond action order relaxation van den Briel et al. (2007), stateequation heuristic Bonet (2013), net change constraints Pommerening et al. (2014).Intuitively, final constraint states number uses actions adding p must greaterequal number uses actions requiring deleting p time feasibleplan . feasible plan STRIPS planning task always satisfies condition. Hence,task feasible plan , clearly derive feasible solution IPc (T )cost . addition this, stronger proposition proved modificationsmodels enhancements Section 4.Proposition 7. Given task , feasible plan = (a0 , , ) , exists feasiblesolution IPc (T ) cost cost . addition this, exists feasible solution IPc (T ) combination landmark extraction substitution, relevanceanalysis, inverse action constraints cost cost .Proof. Let + delete relaxation subsequence plan extracted Algorithm 3.First show subsequence + feasible delete-free plan + , showassignment derived + satisfies constraints.++++use (a+0 , , ) denote elements . show feasible , assume++a+first infeasible action . Let p proposition p pre(ai ) p 6++I((a0 , , ai1 )). Since valid feasible plan , delete-relaxation entire sequencevalid feasible plan + . Hence, a+feasible, Algorithm 3+skipped actions add p ai applied. Since line 5 Algorithm 3 equal+I((a+0 , , ai1 )) i, skipped actions add p satisfy add(ai ) \ 6= , thus663fiI MAI & F UKUNAGAAlgorithm 3 Extracting subsequence = (a0 , , ) (for proof Proposition 7)1:2:3:4:5:6:7:8:9:10:+ (); // emptyI;= a0 , ,Let delete-relaxation a.relevant + add(a ) \ 6=append end + ;add(a );endendreturn + ;irrelevant + . However contradicts definition relevance analysis++fact a+relevant. Similar argument, G I( ). Hence valid feasibleplan + .Define assignment F IPc (T ) as:VF := VF + variable V defined IP(T + ), F + assignmentderived + IP(T + ),N (a)F := (the number occurrences ) A.assignment F clearly satisfies constraints C1 C6. assignment F also satisfiesconstraint C8 since valid plan , F satisfies constraint C7 since U (a)F = 0included . Hence F feasible solution IPc (T ) cost .addition, F also feasible solution IPc (T ) combination landmark extractionsubstitution, relevance analysis, inverse action constraints. see checkingfeasibility F type modified constraints independently. F satisfiesmodified constraints, satisfies combination constraints.F satisfies constraints added landmark extraction substitution (i.e. substituting 1 variables corresponding landmarks) since + valid feasible plan + . F alsosatisfies constraints added relevance analysis (i.e. substituting 0 irrelevant actionspropositions) since + contains relevant actions. Finally, showP F satisfies inverseaction constraints similarly proof Proposition 6. inv(a,p) E(a , p)F = 0PU (a)F = 0 U (p)F = 0 hold, also inv(a,p) E(a , p)F 1PU (a)F = 0 U (p)F = 1 hold. addition, show inv(a,p) E(a , p)F = 0U (a)F = U (p)F = 1. Assume exists inv(a, p) E(a , p)F = 1. Then,constraint C3, U (a )F = 1, means also member + . Without loss generality,assume applied applied + . Since add(a ) pre(a) definition inverseactions, nothing new added state applying . line 5 Algorithm 3 equalI((a+0 , , )), contradicts add(ai ) \ 6= .Unfortunately, counting constraints conflict dominated action elimination (Section 4.3)zero cost immediate action application (Section 4.4). counting constraints used,necessary disable zero cost immediate action application modify conditiondominated actions follows:664fiO N P RACTICAL , NTEGER -L INEAR P ROGRAMMING ODELDefinition 2 (modified dominated action definition). Given feasible task , action dominated action (i) add(a) add(a ), (ii) p pre(a ), p fact landmarkp I, (iii) c(a) c(a ), (iv) pre(a ) del(a ) pre(a) del(a).longer use modified dominated actions make feasible plan , since factlandmarks sometimes deleted achieved. However following fact proved.Proposition 8. Given task , let = (a0 , , ) feasible solution . existsfeasible solution IPc (T ) combination landmark extraction substitution, relevanceanalysis, inverse action constraints, modified dominated action elimination costequal less cost .Proof. Recall dominated action elimination constraints substitute 0s U (a) dominated action a. contain modified dominated actions, proposition holdsdue Proposition 7.Otherwise, derive feasible solution using sequence actions made replacingmodified dominated actions corresponding dominating actions. Letsequence. Note sum costs actions clearly less equal .Let + relaxation subsequence extracted Algorithm 3. Sinceprove delete-relaxation feasible plan + argument similar proofProposition 4, prove + also feasible plan + argument similarproof Proposition 7.+ feasible plan, derive feasible solution IPc (T ) constraintsproof Proposition 7. solution satisfies constraints C1 C6combination landmark extraction substitution, relevance analysis, inverse actionconstraints. satisfies constraint C7 U (a) = 0 included , satisfiesconstraint C8 replacing dominated actions invalidate constraint C8 feasibleplan . also satisfies dominated action elimination constraints (i.e. U (a) = 0dominated action a) since contain modified dominated action.IPec (T ) LPec (T ) denote models constructed applying valid reductionsIPc (T ) LPc (T ) respectively. LP time relaxations IP(T + ) described Section 6applied IPc (T ) well, LPectr (T ) time-relaxed, LP-relaxation enhancedIPec (T ) model. Table 1 summarizes relationships among models.8.1 Experimental Results Models Enhanced Counting Constraintssee impact adding counting constraints, evaluated informativeness LPec (T ),LPectr (T ), LPe (T + ), LPetr (T + ) comparing values LM-cut heuristic values(Helmert & Domshlak, 2009). Table 9 shows values LPec (T ), LPectr (T ), LPe (T + ),LPetr (T + ) multiple LM-cut values (means domain shown). Notecontrast Table 7, limited 1228 instances h+ could computedexactly, Table 9 includes 1376 instances (because LM-cut values could computed1376 instances).majority domains, counting constraints result informative heuristic,compared models without counting constraints, cases, LPe (T + ) LPec (T )LPetr (T + ) LPectr (T ). sometimes possible optimal value LPe (T + ) larger665fiI MAI & F UKUNAGAoptimal value LPec (T ) LPetr (T + ) larger optimal value LPectr (T )explained Section 8, additional constraints part IPe (T + )incompatible IPc (T ) excluded IPec (T ), resulting different LP polytopesLP-relaxations.Next, see impact adding counting constraints forward-search planning usingdelete-relaxation LP models, compare A* /LPec (T ) A* /LPe (T + ), A* /LPectr (T )A* /LPetr (T + ). Coverage instances previous experiment shown Table 10.tradeoff improved search efficiency due additional informativenessheuristic provided counting constraints, additional time required solve LPs(because additional constraints make LP difficult solve). Table 10 showsoverall effects enhancing delete-relaxation model mixed. A* /LPec (T ) attains coverage672 instances, lower coverage A* /LPe (T + ), A* /LPectr (T ) solves 716problems compared 705 problems solved A* /LPetr (T + ). domainsadding counting constraints significantly improved coverage, including parcprinter, pathwaysnoneg, rovers, woodworking. hand, coverage dropped significantly elevators, freecell, openstacks result adding counting constraints. time relaxation seemsadvantageous overall, resulting increase 672 instances A* /LPe (T + ) 716 problemsA* /LPetr (T + ).Table 9 also shows value LMC-SEQ LP value (Pommerening et al., 2014). combination landmark constraints net change constraints operator-counting framework analogous combination delete-free model counting constraints,interesting compare optimal LP values. LPec (T ) LPectr (T ) higher average valueLMC-SEQ 16 15 domains, respectively, LMC-SEQ higher valueLPec (T ) LPectr (T ) 17 domains. Thus, previous comparison LM-cutLPe (T + ) LPetr (T + ) Section 6.2, delete-relaxation approach seems complementaryLMC-SEQ combination operator-counting framework. hand, comparingresults forward search based optimal planning using LP models, see FD/LMCSEQ significantly higher coverage A* /LPec (T ) A* /LPectr (T ), well A* /LPec (T )A* /LPectr (T ).9. Automatic LP Model Selectiondefinitions models, know STRIPS planning task actioncosts, relationships among IP models follows: IPtr (T + ) IPetr (T + ) IP(T + ) =IPe (T + ) = h+ IPc (T ) = IPec (T ). LP relaxations, know LP(T + )LPe (T + ), LPetr (T + ) LPe (T + ), LPectr (T ) LPec (T ), LPectr (T ) LPec (T ). NoteLPec (T ) always dominate LPe (T + ), dominated action elimination immediate action application eliminate different sets variables two LP models. Figure 1illustrates dominance relationships among bounds.time-relaxed LPetr (T + ) LPectr (T ) dominated non-time-relaxed modelsLPe (T + ) LPec (T ), respectively, time-relaxed LPs significantly cheaper computenon-relaxed counterparts.Similarly, although IPec (T ) dominates IPe (T + ), possible LPe (T + ) largerLPec (T ). Furthermore, two LPs optimal value, one solved fasterclearly preferable LPs must solved node A* search. Thus, set666fiO N P RACTICAL , NTEGER -L INEAR P ROGRAMMING ODELairportbarman-opt11blocksdepotdriverlogelevators-opt08elevators-opt11floortile-opt11freecellgridgripperlogistics98logistics00miconicno-mprimeno-mysterynomystery-opt11openstacksopenstacks-opt08openstacks-opt11parcprinter-08parcprinter-opt11parking-opt11pathways-nonegpegsol-08pegsol-opt11pipesworld-notankagepipesworld-tankagepsr-smallroverssatellitescanalyzer-08scanalyzer-opt11sokoban-opt08sokoban-opt11tpptransport-opt08transport-opt11trucksvisitall-opt11woodworking-opt08woodworking-opt11zenotravelLMC-SEQLPe (T + )1.002.231.071.101.041.021.011.052.641.091.001.001.001.001.001.011.031.361.001.001.081.051.001.531.341.331.451.322.601.231.001.001.011.151.111.431.111.081.001.501.041.051.00.85.511.001.431.01.84.801.013.141.201.00.91.991.00.89.981.071.611.001.001.001.001.041.131.091.101.181.271.00.72.83.98.981.011.01.89.49.491.081.421.121.13.96+LPetr (T ).85.511.001.42.99.82.771.013.071.191.00.90.991.00.78.901.071.431.001.001.001.00.991.131.051.101.161.261.00.72.75.94.981.001.01.89.49.491.081.411.121.13.94LPec (T )LPectr (T ).983.591.071.541.12.71.671.083.081.551.001.011.001.00.82.841.101.611.001.001.081.051.061.721.251.221.731.352.61.81.85.97.971.131.121.42.18.181.081.481.181.19.94.983.591.071.541.12.71.671.083.071.551.001.011.001.00.82.811.101.431.001.001.081.051.001.721.231.221.701.202.61.81.75.93.971.131.121.42.18.181.081.471.181.19.93Table 9: Optimal values LP models relative LM-cut value 1376 IPC instances. Meansdomain shown. E.g., barman-opt11, mean LMC-SEQ value 2.23 times LMcut value, LPe (T + ) LPetr (T + ) values 0.51 times LM-cut value, LPec (T )LPectr (T ) values 3.59 times LM-cut value.667fiI MAI & F UKUNAGA800700Instances solved600500400300FD/LMC-SEQA*/AutoconfFD/LMCA*/LPectr(T)A*/LPetr(T+)FD/SEQ20010000.11101001000Time (seconds)(a) Cumulative number problems solved (out 1376) vs time (30 minute time limit).800700Instances solved600500400300FD/LMC-SEQA*/Autoconf200FD/LMCA*/LPectr(T)100A*/LPetr(T+)FD/SEQ0110100100010000 100000 1e+061e+071e+08Evaluations(b) Cumulative number problems solved (out 1376) vs number search nodes evaluated (30 minutetime limit).Figure 8: Comparison forward search (A* ) planners, part 2.668fiO N P RACTICAL , NTEGER -L INEAR P ROGRAMMING ODEL4 viable LP heuristics, none dominate others considering accuracytime. best choice optimize tradeoff heuristic accuracy node expansionrate depends problem instance. difficult choose best heuristic priorigeneral, know (1) whether worthwhile use counting constraints not, (2)whether time-relaxation tight particular problem instance.Thus, implemented simple mechanism automatically selecting LP usedproblem works follows: First, compute LPe (T + ), LPec (T ), LPetr (T + ),LPectr (T ) problem instance (i.e., root node A* search). select onebased following rule: Choose heuristic highest value, break ties choosing heuristic cheapest compute. Although cheapest heuristic could identifiedaccording CPU time required compute heuristic, many problems, computations fast robust timing measurements, simply break ties order LPetr (T + ),LPectr (T ), LPe (T + ), LPec (T ), ordering usually accurately reflects timing order.mechanism makes simplistic assumption ranking behavior LP boundsroot node similar ranking LP bounds throughout search graph. sophisticated method heuristic selection may result better performance (c.f. Domshlak, Karpas,& Markovitch, 2012), avenue future work.9.1 Experimental Results Automated Model Selection ComparisonState-of-the-Artcompared A* using LP-based heuristics, including A* /autoconf, state-of-the-art heuristics. Specifically, compared:FD/LM-cut : Fast Downward using landmark cut heuristic (Helmert & Domshlak, 2009)(the standard seq-opt-lmcut configuration)FD/LMC : Fast Downward using LP-model optimal cost partitioning landmarkcut constraints (Pommerening et al., 2014)FD/SEQ : Fast Downward using lower-bound net change constraints (Pommerening et al.,2014), corresponding state-equation heuristic Bonet (2013).FD/OPT-SYS1, FD/PHO-SYS1, FD/PHO-SYS2 : Fast Downward using optimal cost partitioning constraints projections goal variables (OPT-SYS1), post-hoc optimizationconstraints (PHO-SYS1, PHO-SYS2) (Pommerening et al., 2014).FD/LMC-SEQ : Fast Downward using landmark cut net change constraints.A* /LPe (T + ) : A* LP relaxation enhanced delete-free IP model IPe (T + )(Section 4) heuristic.A* /LPetr (T + ) : A* LP relaxation time-relaxed, enhanced delete-free IP modelIPe (T + ) heuristic.A* /LPec (T ) : A* LP relaxation enhanced delete-free IP model countingconstraints IPec (T ) heuristic.A* /LPectr (T ) : A* LP relaxation time-relaxed, enhanced delete-free IP modelcounting constraints IPec (T ) heuristic.669fiI MAI & F UKUNAGA9.1.1 C OVERAGE R ESULTScoverage results (number problems solved) shown Tables 10. time spentroot node A* /autoconf LP model selection included runtimes, also counts30-minute runtime limit. Figures 8a-8b show cumulative number instances solvedfunction number time number node evaluations, respectively (for legibility,subset algorithms included Figures 8a-8b). Table 11 shows summary total coverageresults forward-search configurations included Tables 8 10.results indicate automatic LP model selection significantly boosts performanceA* -based planner compared relying single LP model. A* /autoconf achieved coverage 761 1376 instances, significantly better 4 individual components.Furthermore, A* /autoconf attained higher coverage solver configurations Table10 except FD/LMC-SEQ (Pommerening et al., 2014), solved 781 instances. NoteA* /autoconf higher coverage FD/LMC-SEQ 11/43 domains (floortile-opt11, freecell,grid, logistics98, nomystery-opt11, pathways-noneg, rovers, satellite, trucks, woodworking-opt08,woodworking-opt11).9.1.2 ACCURACY A* / AUTOCONF ODEL ELECTIONanalyzed accuracy model selection evaluating performance A* /autoconfproblem instance vs performance four component models. coverageconsidered, 96.4% instances, A* /autoconf made correct decision respectcoverage, model selection A* /autoconf deemed correct either A* /autoconfsolved problem instance, none 4 components solved problem instance.hand, runtimes considered well coverage, 83.0% instances, A* /autoconfmade correct decision, selection deemed correct A* /autoconf selectedmodel best runtime (including ties), none 4 components solved probleminstance. baseline, LPectr (T ), best coverage among component models,correct choice according criterion 49.9% time. Mistakes selections madeA* /autoconf seen Table 10 coverage results example, woodworking-opt11domain, A* /autoconf solved 18 instances compared 20 instances solved LPectr (T ). Thus,significant room improvement runtimes considered addition coverage,improving model selection using machine learning techniques direction future work.10. Discussion Conclusionpaper proposed new, integer-linear programming formulation delete relaxation h+cost-optimal, domain-independent planning. started basic IP model IP(T + ),showed enhanced model IPe (T + ), incorporates landmark-based variable reduction,relevance analysis, action elimination, competitive previous methods solving deletefree versions standard IPC planning benchmarks tasks (i.e., exact computation h+ ).results embedding IP model heuristic function A* -based forward searchplanner confirmed plain IP(T + ) model practical (coverage 403/1367 instancesvs. 540 Fast Downward using hmax ). However, showed IPe (T + ) model,uses variable reduction methods reduce size IP models exactly computes h+ ,performed much better, coverage 635 instances. According summary results670fiFD/SEQA* /LPe (T + )+A* /LPetr (T )22428712119215174165021151271914151154271714849661292419611661610595711028427713191621527521542115167191417131427171684966742920611671616111162012224287121084391741652201510717122820442818158506614112017811691714996271225028711131064426620140181314711620161526161274871085231969415161610106965250287131310743266201411712147116201615261613748710852519610515161711117056A* /autoconfFD/PHO-SYS22042641086281621445191387116117142212137486510718156943158384622FD/PHO-SYS1304297131916633266201412216127161129202528181485077141129208116101921161278118A* /LPectr (T )FD/OPT-SYS1284287132016615266201412316147191418132527171784977141128206116101016111273013FD/LMC-SEQ28428714221871527620141231614719141914352717178497715123020611610111712137482225029712646172672013915118762292011422121275011974221986112173020106721225329713867213672014016111171052920114261613750119852619861151730201071615252297131310744367201411812147116292011426161375011108525198105151728181176116A* /LPec (T )FD/LMCDomainairport(50)barman-opt11(20)blocks(35)depot(22)driverlog(20)elevators-opt08(30)elevators-opt11(20)floortile-opt11(20)freecell(80)grid(5)gripper(20)logistics98(35)logistics00(28)miconic(150)no-mprime(35)no-mystery(30)nomystery-opt11(20)openstacks(30)openstacks-opt08(30)openstacks-opt11(20)parcprinter-08(30)parcprinter-opt11(20)parking-opt11(20)pathways-noneg(30)pegsol-08(30)pegsol-opt11(20)pipesworld-notankage(50)pipesworld-tankage(50)psr-small(50)rovers(40)satellite(36)scanalyzer-08(30)scanalyzer-opt11(20)sokoban-opt08(30)sokoban-opt11(20)tpp(30)transport-opt08(30)transport-opt11(20)trucks(30)visitall-opt11(20)woodworking-opt08(30)woodworking-opt11(20)zenotravel(20)Total coverage (1376)# Best domainsFD/LM-cutN P RACTICAL , NTEGER -L INEAR P ROGRAMMING ODELTable 10: Comparison forward search (A* ) planners, part 2: Number problems solved30 minute, 2GB RAM limit using A* IP/LP models heuristic functions. Includes LPmodels incorporate counting constraints (LPec (T ), LPectr (T ), Section 8), well A* /autoconf(Section 9). Comparison Fast Downward using operator-counting LP models (Pommereninget al., 2014).671fiI MAI & F UKUNAGAConfigurationFD/LM-cut# solved748FD/hmaxFD/SEQFD/PHO-SYS1FD/PHO-SYS2FD/LMC540627571620730FD/OPT-SYS1FD/LMC-SEQA* /HST/CPLEX462781398A* /IP(T + )A* /IPe (T + )A* /LPe (T + )A* /LPetr (T + )A* /LPec (T )*e/LPctr (T )A* /autoconf403635696705672716761DescriptionFast Downward (FD) using standard Landmark Cut heuristic(seq-opt-lmcut)FD using hmax heuristicFD using SEQ LP heuristic (Pommerening et al., 2014)FD using PHO-SYS1 LP heuristic (Pommerening et al., 2014)FD using PHO-SYS2 LP heuristic (Pommerening et al., 2014)FD using LP model optimal cost partitioning landmark constraints (Pommerening et al., 2014)FD using OPT-SYS1 LP heuristic (Pommerening et al., 2014)FD using LMC+SEQ LP heuristic (Pommerening et al., 2014)hsp planner using A* h+ heuristic (Haslum et al., 2012; Haslum,2012)basic IP formulation h+IP(T + ) enhancements Sections 4.1-4.6LP relaxation IPe (T + )LP relaxation time-relaxed model IPetr (T + )LP relaxation IPec (T )LP relaxation time-relaxed model IPectr (T )Automated selection LP root node(Section 9)Table 11: Summary coverage (# solved) 1376 IPC benchmark problems instances 30minute time limit 2GB RAM (see Tables 8-10 detailed results)Table 11, aggregate coverage IPe (T + ) comparable coverage obtained LPbased SEQ, OPT-SYS1, PHO-SYS1, PHO-SYS2 heuristics recently implemented usingoperator-counting framework Pommerening et al. (2014). However, aggregate coverageIPC benchmarks skewed miconic domain, SEQ, OPT-SYS1, PHO-SYS1,PHO-SYS2 perform particularly poorly compared heuristics. miconic domainincluded, IPe (T + ) competitive LP-based models. Note freecelldomain, A* IPe (T + ) heuristic solved 54/80 instances, significantly highermethods, least 1 domain exact h+ computation using IPe (T + ) modelperforms extremely well compared state-of-the-art heuristics.showed gap optimal value LP relaxations IP modelsh+ tended quite small (the gap often zero), suggesting LP relaxations,computed much faster IP models, could used heuristic A* -based planning.time-relaxation eliminates time-related constraints also proposed another wayreduce model order solvable faster. comparison LP-relaxed delete relaxationmodels LM-cut (Helmert & Domshlak, 2009) heuristic values showed approachescomplementary respect closely approximate h+ . Thus, LP-relaxationdelete-free models provides novel, practical alternative approximating h+ . showedA* search using LPe (T + ) (LP-relaxation delete-free task) LPetr (T + ) (time relaxed,LP-relaxation delete-free task) significantly improves upon IP models, solving 696 705instances, respectively, making usable practical heuristics.major advantage LP-based heuristics relative ease additional constraintsadded order obtain improved heuristics. showed counting constraints,corresponding net change constraints proposed previous work (van den Briel et al., 2007;Pommerening et al., 2014), could added LP model. resulting heuristic, LPectr (T )mixed results, improving performance domains, degrading performancedomains, i.e., LPetr (T + ) LPectr (T ) complementary heuristics.672fiO N P RACTICAL , NTEGER -L INEAR P ROGRAMMING ODELSince dominance relationship among A* /LPe (T + ), A* /LPetr (T + ), A* /LPec (T )*/LPectr (T ), proposed A* /autoconf , simple method automatically selects among4 heuristics computing 4 heuristic values root node using accurate heuristic(breaking ties according speed). showed overall, A* /autoconf significantly improves upon4 components, competitive landmark-cut heuristic, solving 761/1367 instancesachieving state-of-the-art performance several domains.A* /autoconf lower total coverage compared Fast Downward using LMC-SEQLP-based heuristic (Pommerening et al., 2014), LP(T + )-based approach outperforms LMCSEQ several domains including freecell, pathways-noneg, rovers, satellite, trucks, woodworking. Although A* /autoconf includes LP models counting constraints considerdelete effects, note A* /LPetr (T + ), uses pure delete-free LP, performs quite well, obtaining higher coverage operator-count based heuristics Pommerening et al. (2014)floortile, freecell, nomystery-opt11, satellite, trucks domains, counting constraintsrequired order A* using delete-relaxation based LPs achieve state-of-the-artperformance domains.comparison optimal values counting-constraint enhanced delete-relaxation LPmodels LPec (T ) LPectr (T ) optimal LP values LMC-SEQ model showedcomplementary, class models outperforming roughlynumber domains (Section 8.1). Thus, integrating two approaches single LP modelpromising direction future work. recent survey LP-based heuristics planning,Roger Pommerening (2015) noted delete-relaxation model incorporatedoperator counting framework Pommerening et al. (2014) adding operator-counting variablesoperator delete-relaxed problem promising direction future work. NotePommerening et al. (2014) approach use landmarks, useddifferent purposes. landmark constraints used Pommerening et al. (2014) used directlyoperator counting constraints. contrast, approach uses landmarks order decreasesize IP/LP models delete-free task used purpose speedingcomputation IP/LP models, i.e., landmark based reduction change optimal valueIP(T + ).showed adding counting constraints consider delete effects (i.e., LPec (T )LPectr (T )) improve performance domains, domains, coverage droppedsignificantly. additional constraints make LP difficult solve,increased search efficiency due tighter bound enough overcome increased costsolving LP search node. A* /autoconf attempts address selecting modelscounting constraints return higher value model without counting constraints root node, otherwise uses model include counting constraints(i.e., LPe (T + ) LPetr (T + )). hand, strengthening delete-relaxation consideringdelete effects active area research, recently, two frameworks allow flexible interpolation delete relaxation original model proposed.Keyder, Hoffmann, Haslum (2014) propose approach adds new fluents representconjunctions fluents original planning task. Red-black planning (Domshlak, Hoffmann, &Katz, 2015) framework separates state variables two groups red variablesrelaxed, black variables relaxed. Combining flexible relaxation frameworksIP approach developing principled approach deciding use countingconstraints avenue future work.673fiI MAI & F UKUNAGAcurrent implementation uses CPLEX solver naively, relying entirely default controlparameters. Systematically tuning improving implementation IP/LP models ordermake better use incremental IP/LP solving capabilities promising direction future work.Although shown LP models often compute h+ exactly, domainssignificant gaps h+ optimal cost LP models. Improvedmodeling techniques may allow tighter LP bounds. example, Constraint C6 uses straightforwardbig-M encoding, may possible obtain tighter bounds using methods.Furthermore, although solving IP node forward-search based planner previously considered impractical, shown IPe (T + ) model, computes h+exactly, almost useful practical heuristic, improving techniques used solve IPIPe (T + ) may result balance accuracy speed necessary practical generalpurpose heuristic. example, significant performance improvements might obtainable improving use IP solver. example, contrast LP solvers, parallel speedupsoften difficult obtain, IP solvers often sped significantly parallelization, currentIP solvers already provide parallel search algorithms (which use paperlimited experiments single threads). number cores per processor continues increase, possible cases, IP-based heuristics may become useful LP-basedheuristics.AcknowledgmentsThanks Patrik Haslum assistance code computing h+ hsp f planner.Thanks Florian Pommerening assistance code LP heuristic-based Fast Downward (Pommerening et al., 2014). Thanks anonymous reviewers numerous helpful suggestions significantly improved paper. research supported JSPS Grant-in-AidJSPS Fellows JSPS KAKENHI grant.ReferencesBackstrom, C., & Nebel, B. (1995). Complexity Results SAS+ Planning. Computational Intelligence, 11(4), 625655.Betz, C., & Helmert, M. (2009). Planning h+ theory practice. KI 2009, pp. 916.Springer.Blum, A., & Furst, M. (1997). Fast Planning Planning Graph Analysis. Artificial Intelligence, 90(1-2), 281300.Bonet, B. (2013). admissible heuristic SAS+ planning obtained state equation.Proceedings International Joint Conference Artificial Intelligence (IJCAI), pp.22682274.Bonet, B., & Castillo, J. (2011). complete algorithm generating landmarks. ProceedingsInternational Conference Automated Planning Scheduling (ICAPS).Bonet, B., & Geffner, H. (2001). Planning heuristic search. Artificial Intelligence, 129(1-2),533.Bonet, B., & Helmert, M. (2010). Strengthening landmark heuristics via hitting sets. ProceedingsEuropean Conference Artificial Intelligence (ECAI), pp. 329334.674fiO N P RACTICAL , NTEGER -L INEAR P ROGRAMMING ODELBonet, B., & van den Briel, M. (2014). Flow-based heuristics optimal planning: Landmarksmerges. Proceedings International Conference Automated PlanningScheduling (ICAPS).Bylander, T. (1994). Computational Complexity Propositional STRIPS Planning. ArtificialIntelligence, 69(12), 165204.Bylander, T. (1997). linear programming heuristic optimal planning. ProceedingsNational Conference Artificial Intelligence (AAAI), pp. 694699.Cooper, M. C., de Roquemaurel, M., & Regnier, P. (2011). Transformation optimal planningproblems. Journal Experimental & Theoretical Artificial Intelligence, 23(2), 181199.Dimopoulos, Y. (2001). Improved integer programming models heuristic search ai planning.Proceedings 6th European Conference Planning (ECP), pp. 5057.Domshlak, C., Karpas, E., & Markovitch, S. (2012). Online speedup learning optimal planning.Journal Artificial Intelligence Research, 44, 709755.Domshlak, C., Hoffmann, J., & Katz, M. (2015). Red-black planning: new systematic approachpartial delete relaxation. Artificial Intelligence, 221, 73114.Gefen, A., & Brafman, R. (2011). minimal seed set problem. Proceedings International Conference Automated Planning Scheduling (ICAPS), pp. 319322.Gefen, A., & Brafman, R. (2012). Pruning methods optimal delete-free planning. ProceedingsInternational Conference Automated Planning Scheduling (ICAPS), pp. 5664.Haslum, P. (2012). Incremental lower bounds additive cost planning problems. ProceedingsInternational Conference Automated Planning Scheduling (ICAPS), pp. 7482.Haslum, P. (2014a) Personal communication.Haslum, P. (2014b). Hsp* code documentatoin http://users.cecs.anu.edu.au/patrik/un-hsps.html..Haslum, P., Slaney, J., & Thiebaux, S. (2012). Minimal landmarks optimal delete-free planning. Proceedings International Conference Automated Planning Scheduling(ICAPS), pp. 353357.Helmert, M., & Domshlak, C. (2009). Landmarks, critical paths abstractions: Whats difference anyway?. Proceedings International Conference Automated PlanningScheduling (ICAPS), pp. 162169.Hoffmann, J., & Nebel, B. (2001). FF Planning System: Fast Plan Generation Heuristic Search. Journal Artificial Intelligence Research, 14, 253302.Hoffmann, J., Porteous, J., & Sebastia, L. (2004). Ordered landmarks planning. JournalArtificial Intelligence Research, 22, 215278.Imai, T., & Fukunaga, A. (2014). practical, integer-linear programming model deleterelaxation cost-optimal planning. Proceedings European Conference ArtificialIntelligence (ECAI).Karpas, E., & Domshlak, C. (2009). Cost-optimal planning landmarks. ProceedingsInternational Joint Conference Artificial Intelligence (IJCAI), pp. 17281733.675fiI MAI & F UKUNAGAKatz, M., & Domshlak, C. (2010). Optimal admissible composition abstraction heuristics. Artificial Intelligence, 174(12-13), 767798.Kautz, H., & Selman, B. (1992). Planning Satisfiability. Proceedings European Conference Artificial Intelligence (ECAI), pp. 359363.Kautz, H. A., & Selman, B. (1996). Pushing envelope: Planning, propositional logic stochastic search. Proceedings National Conference Artificial Intelligence (AAAI), pp.11941201.Kautz, H. A., & Selman, B. (1999). Unifying sat-based graph-based planning. ProceedingsInternational Joint Conference Artificial Intelligence (IJCAI), pp. 318325.Keyder, E., Richter, S., & Helmert, M. (2010). Sound complete landmarks and/or graphs.Proceedings European Conference Artificial Intelligence (ECAI), pp. 335340.Keyder, E., & Geffner, H. (2008). Heuristics planning action costs revisited. ProceedingsEuropean Conference Artificial Intelligence (ECAI), pp. 588592.Keyder, E. R., Hoffmann, J., & Haslum, P. (2014). Improving delete relaxation heuristicsexplicitly represented conjunctions. Journal Artificial Intelligence Research, 50, 487533.Mirkis, V., & Domshlak, C. (2007). Cost-sharing approximations h+. ProceedingsInternational Conference Automated Planning Scheduling (ICAPS), pp. 240247.Pommerening, F., & Helmert, M. (2012). Optimal planning delete-free tasks incremental LM-cut. Proceedings International Conference Automated PlanningScheduling (ICAPS), pp. 363367.Pommerening, F., Roger, G., Helmert, M., & Bonet, B. (2014). LP-based heuristics costoptimal planning. Proceedings International Conference Automated PlanningScheduling (ICAPS).Pommerening, F., Roger, G., & Helmert, M. (2013). Getting pattern databasesclassical planning. Proceedings International Joint Conference ArtificialIntelligence (IJCAI).Rintanen, J. (2012). Planning satisfiability: Heuristics. Artificial Intelligence, 193, 4586.Rintanen, J., Heljanko, K., & Niemela, I. (2006). Planning satisfiability: parallel plans algorithms plan search. Artificial Intelligence, 170(12-13), 10311080.Robinson, N. (2012). Advancing Planning-as-Satisfiability. Ph.D. thesis, Griffith University.Robinson, N., McIlraith, S. A., & Toman, D. (2014). Cost-based query optimization via AI planning.Proceedings Twenty-Eighth AAAI Conference Artificial Intelligence, July 27 -31,2014, Quebec City, Quebec, Canada., pp. 23442351.Roger, G., & Pommerening, F. (2015). Linear programming heuristics optimal planning.AAAI2015 Workshop Planning, Search, Optimization.van den Briel, M. (2015) Personal communication.van den Briel, M., Benton, J., Kambhampati, S., & Vossen, T. (2007). LP-based heuristicoptimal planning. Proceedings International Conference Principles PracticeConstraint Programming (CP).676fiO N P RACTICAL , NTEGER -L INEAR P ROGRAMMING ODELvan den Briel, M., & Kambhampati, S. (2005). Optiplan: planner based integer programming.Journal Artificial Intelligence Research, 24, 919931.van den Briel, M., Vossen, T., & Kambhampati, S. (2008). Loosely coupled formulation automated planning: integer programming perspective. Journal Artificial IntelligenceResearch, 31, 217257.Vossen, T., Ball, M. O., Lotem, A., & Nau, D. S. (1999). use integer programming modelsAI planning. Proceedings International Joint Conference Artificial Intelligence(IJCAI), pp. 304309.Zhu, L., & Givan, R. (2003). Landmark extraction via planning graph propagation. ProceedingsICAPS Doctoral Consortium, pp. 156160.677fiJournal Artificial Intelligence Research 54 (2015) 309-367Submitted 03/15; published 11/15PAGOdA: Pay-As-You-Go Ontology Query AnsweringUsing Datalog ReasonerYujiao ZhouBernardo Cuenca GrauYavor NenovMark KaminskiIan Horrocksyujiao.zhou@cs.ox.ac.ukbernardo.cuenca.grau@cs.ox.ac.ukyavor.nenov@cs.ox.ac.ukmark.kaminski@cs.ox.ac.ukian.horrocks@cs.ox.ac.ukDepartment Computer Science, University OxfordParks Road, Oxford OX1 3QD, United KingdomAbstractAnswering conjunctive queries ontology-enriched datasets core reasoning taskmany applications. Query answering is, however, computationally expensive,led development query answering procedures sacrifice either expressivepower ontology language, completeness query answers order improvescalability. paper, describe hybrid approach query answering OWL 2ontologies combines datalog reasoner fully-fledged OWL 2 reasoner orderprovide scalable pay-as-you-go performance. key feature approachdelegates bulk computation datalog reasoner resorts expensiveOWL 2 reasoning necessary fully answer query. Furthermore, althoughmain goal efficiently answer queries OWL 2 ontologies data, technicalresults general approach applicable first-order knowledge representation languages captured rules allowing existential quantificationdisjunction head; assumption availability datalog reasonerfully-fledged reasoner language interest, used black boxes.implemented techniques PAGOdA system, combines datalogreasoner RDFox OWL 2 reasoner HermiT. extensive evaluation showsPAGOdA succeeds providing scalable pay-as-you-go query answering wide rangeOWL 2 ontologies, datasets queries.1. IntroductionOntologies increasingly used rich conceptual schemas wide range applicationdomains (Staab & Studer, 2004). One widely used ontology languages OWL,description logic based language standardised World Wide Web Consortium(W3C) 2004 revised (as OWL 2) 2009 (Baader, Calvanese, McGuinness, Nardi,& Patel-Schneider, 2003; Horrocks, Patel-Schneider, & van Harmelen, 2003; Cuenca Grau,Horrocks, Motik, Parsia, Patel-Schneider, & Sattler, 2008). OWL ontology consistsset axioms, correspond first-order sentences containing unary binarypredicates (called classes properties OWL), structure axioms/sentencesrestricted ensure decidability basic reasoning problems.applications, main focus conceptual model itself, class subsumption key reasoning problem. increasing number applications, however,main focus using conceptual model access data, often form RDFc 2015 AI Access Foundation. rights reserved.fiZhou, Cuenca Grau, Nenov, Kaminski, & Horrocksgraph (Manola & Miller, 2004). data-centric applications key reasoning problemanswer conjunctive queries (CQs)sentences constructed function-free atoms usingconjunction existential quantification (Abiteboul, Hull, & Vianu, 1995)whichconstitute core component standard query languages SQL SPARQL(W3C SPARQL Working Group, 2013).Conjunctive query answering ontology-enriched datasets is, however, high worstcase complexity (Glimm, Lutz, Horrocks, & Sattler, 2008; Eiter, Ortiz, & Simkus, 2012),even measured respect size data (so called data complexity).Although heavily optimised, existing systems query answering respect (RDF)data unrestricted OWL 2 ontology process small medium size datasets(Sirin, Parsia, Cuenca Grau, Kalyanpur, & Katz, 2007; Moller, Neuenstadt, Ozcep, &Wandelt, 2013; Wandelt, Moller, & Wessel, 2010; Kollia & Glimm, 2013). leddevelopment query answering procedures sacrifice expressive powerontology language completeness query answers order improve scalability.former case (sacrificing expressive power), query answering proceduresdeveloped various fragments OWL 2 conjunctive query answering tractablerespect data complexity, three fragments standardised so-calledprofiles OWL 2 (Motik, Cuenca Grau, Horrocks, Wu, Fokoue, & Lutz, 2012). OWL 2QL OWL 2 EL profiles based DL-Lite (Calvanese, De Giacomo, Lembo,Lenzerini, & Rosati, 2007) EL (Baader, Brandt, & Lutz, 2005) families descriptionlogics; OWL 2 RL profile corresponds fragment rule-based language datalog(Grosof, Horrocks, Volz, & Decker, 2003; Dantsin, Eiter, Gottlob, & Voronkov, 2001).Conjunctive query answering systems profiles shown highly scalablepractice (Bishop, Kiryakov, Ognyano, Peikov, Tashev, & Velkov, 2011; Wu, Eadon, Das,Chong, Kolovski, Annamalai, & Srinivasan, 2008; Motik, Nenov, Piro, Horrocks, & Olteanu,2014; Erling & Mikhailov, 2009; Rodriguez-Muro & Calvanese, 2012; Lutz, Seylan, Toman,& Wolter, 2013; Stefanoni, Motik, & Horrocks, 2013). favourable computationalproperties fragments make natural choice data-intensive applications,also come expense loss expressive power, many ontologies usedapplications captured profiles.latter case (sacrificing completeness), query answering proceduresdeveloped exploit scalable reasoning techniques, expense computingapproximate query answers (Thomas, Pan, & Ren, 2010; Tserendorj, Rudolph, Krotzsch,& Hitzler, 2008; Wandelt et al., 2010; Bishop et al., 2011). cases, computedanswers sound (only correct answer tuples identified) incomplete (some correctanswer tuples may identified). One way realise procedure weakenontology falls within one OWL 2 profiles, use scalableprocedure relevant fragment. required weakening trivially achievedsimply discarding (parts of) out-of-profile axioms, sophisticated techniques maytry reduce even minimise information loss (Console, Mora, Rosati, Santarelli, & Savo,2014). approach clearly sound (if answer tuple entailed weakenedontology, entailed original ontology), incomplete general,ontologies outside relevant profile, answer returned systems thereforeunderstood providing lower-bound correct answer; however, procedures310fiPAGOdA: Pay-As-You-Go Query Answering Using Datalog Reasonercannot general provide complementary upper bound even indicationcomplete computed answer (Cuenca Grau, Motik, Stoilos, & Horrocks, 2012).paper, describe novel hybrid approach query answering combinesscalable datalog (or OWL 2 RL) reasoner fully-fledged OWL 2 reasoner providescalable performance still guaranteeing sound complete answers cases.procedure uses datalog reasoner efficiently compute lower bound (soundpossibly incomplete) upper bound (complete possibly unsound) answers input query. lower upper bound answers coincide, obviously provide soundcomplete answer. Otherwise, relevant subsets ontology data computedguaranteed sufficient test correctness tuples gaplower upper bounds. subsets computed using datalog reasoner,typically much smaller input ontology data. Finally, fully-fledgedreasoner used check gap tuples w.r.t. relevant subset. still computationally expensive, load fully-fledged reasoner reduced exploitingsummarisation techniques inspired SHER system quickly identify spurious gaptuples (Dolby, Fokoue, Kalyanpur, Kershenbaum, Schonberg, Srinivas, & Ma, 2007; Dolby,Fokoue, Kalyanpur, Schonberg, & Srinivas, 2009), analysing dependenciesremaining gap tuples reduce number checks need performed.key feature approach pay-as-you-go behaviour: bulk computational workload delegated datalog reasoner, extentfully-fledged reasoner needed depend solely ontology, interactionsontology, dataset query. Thus, even using expressiveontology, queries often fully answered using datalog reasoner, evenfully-fledged reasoner required, relevant subset extraction, summarisationdependency analysis greatly reduce number size reasoning problems. Moreover,approach additional advantage lower bound answer tuples quicklyreturned, even cases completion answer requires time consuming computations. Finally, although main goal efficiently answer queries OWL 2ontologies datasets, technical results general approachrestricted ontology languages based description logics. precisely, given KRlanguage L captured first-order rules allowing existential quantificationdisjunction head, want answer conjunctive queries,assumption availability fully-fledged reasoner L datalog reasoner,used black box.implemented techniques PAGOdA system1 using RDFox datalogreasoner (Motik et al., 2014) HermiT fully-fledged OWL 2 reasoner (Glimm,Horrocks, Motik, Stoilos, & Wang, 2014),2 conducted extensive evaluation usingwide range realistic benchmark datasets queries. evaluation suggeststechniques eective providing scalable pay-as-you-go query answering: tests4,000 queries 8 ontologies, none contained withinOWL profiles, 99% queries fully answered without resorting fullyfledged reasoner. Moreover, even fully-fledged reasoner used, relevant subset1. http://www.cs.ox.ac.uk/isg/tools/PAGOdA/2. Although techniques proved correct general conjunctive queries, practice limitedcurrent query capabilities OWL 2 reasoners.311fiZhou, Cuenca Grau, Nenov, Kaminski, & Horrocksextraction, summarisation dependency analysis greatly reduced number sizereasoning problems: tests, size dataset typically reduced ordermagnitude, often several orders magnitude, seldom requiredsingle test resolve status gap tuples. Taken together, experiments showPAGOdA provide efficient conjunctive query answering service scenarios requiringexpressive ontologies datasets containing hundreds millions facts, somethingfar beyond capabilities pre-existing state-of-the-art ontology reasoners.remainder paper organised follows. Section 2 introduce keyconcepts definitions. Section 3 present high-level overview approach.Section 4 describe lower bound answers computed provesound, Section 5 describe upper bound answers computed provecomplete. Section 6 present technique reducing sizeontology dataset processed fully-fledged reasoner provepreserves completeness. Section 7 present summarisation dependency analysisoptimisations prove preserve completeness. Section 8 describeimplementation techniques PAGOdA system discuss additionaloptimisations. Finally, positioning work within state-of-the-art Section 9,present extensive evaluation Section 10, draw conclusions Section 11.2. Preliminariessection briefly introduce rule-based first-order languages description logics(DLs)a family knowledge representation formalisms underpinning OWL OWL 2ontology languages (Baader et al., 2003).use standard notions first-order logic constant, predicate, function,term, substitution, atom, formula, sentence. also adopt standard definitions(Herbrand) interpretation model, well (un)satisfiability entailment (written|=) sets first-order sentences. denote ? nullary predicate falseinterpretations. Formulas may also contain special equality predicate . assumefirst-order knowledge base F function-free signature uses axiomatisessemantics usual way; is, F must contain following first-order sentences,(EQ1) (EQ4) instantiated n-ary predicate P F 1 n:8x1 , . . . , xn (P (x1 , . . . , xi , . . . , xn ) ! xi xi )(EQ1)8x, y(x ! x)8x, y, z(x ^ z ! x z)8x1 , . . . , xn , y(P (x1 , . . . , xi , . . . , xn ) ^ xi ! P (x1 , . . . , xi(EQ2)(EQ3)1 , y, xi+1 , . . . , xn ))(EQ4)Finally, also exploit following notion homomorphism applicable setsatoms, formulas substitutions. Given sets ground atoms , definehomomorphism mapping ground terms ground terms s.t.(c) = c constant c S, P (t1 , . . . , tn ) 2 atom P (t1 , . . . , tn ) 2 S.application homomorphism naturally extended ground atoms, groundformulas ground substitutions, e.g. atom = P (t1 , . . . , tn ), = P (t1 , . . . , tn )ground substitution , substitution {x 7! x | x 2 dom( )}.312fiPAGOdA: Pay-As-You-Go Query Answering Using Datalog Reasoner2.1 Rule-Based Knowledge RepresentationRule languages well-known knowledge representation formalisms strongly connected ontology languages (Dantsin et al., 2001; Cal, Gottlob, Lukasiewicz, Marnette,& Pieris, 2010; Bry, Eisinger, Eiter, Furche, Gottlob, Ley, Linse, Pichler, & Wei, 2007).define fact function-free ground atom dataset finite set facts.rule r function-free first-order sentence form8~x, ~y (x, ~y )(~x, ~y )1 (~^ ^x, ~y )n (~!_i=19~zi 'i (~x, ~zi ))(1)atom dierent ? free variables ~x [ ~y , either= 1 '1 (~x, ~z1 ) = ?,1, 1 formula 'i (~x, ~zj ) conjunction atoms dierent? free variables ~x [ ~zj .conjunctionatoms 1 (~x, ~y ) ^ ^ n (~x, ~y ) body r, denoted body(r).Wformula9~z'x, ~zi ) head r, denoted head(r). assume rules(~i=1safe; is, every variable ~x mentioned body(r). brevity, universal quantifiersomitted rules.Rules form general able capture first-order rule languagesknowledge representation, including datalog (Abiteboul et al., 1995), existential rulesdatalog (Cal et al., 2010), well datalog,_ (Alviano, Faber, Leone, & Manna,2012b; Bourhis, Morak, & Pieris, 2013).say rule rdisjunctive datalog head(r) contains existential quantifiers conjunction;existential = 1;datalog disjunctive datalog = 1.knowledge base K = K [ DK consists finite set rules K dataset DKpredicate DK assumed occur K .order simplify presentation technical results, sometimes restrictknowledge bases particular normal form, specify next. sayrule r normalised one following forms,1x, ~zi ) single atom dierent ?:(~x, ~y )1 (~x, ~y )1 (~x, ~y )1 (~^ ^x, ~y )n (~^ ^x, ~y )n (~^ ^x, ~y )n (~!?(2)! 9~z1 1 (~x, ~z1 )!x)1 (~_ _(3)x)(~(4)knowledge base K [ DK normalised rules K normalised. restrictionnormalised knowledge bases w.l.o.g. since every set rules form (1)transformed polynomial time set normalised rules norm() conservativeextension given next. rule r 2 1 m, let ~xi tuple313fiZhou, Cuenca Grau, Nenov, Kaminski, & Horrocksfree variables subformulas 9~zi 'i (~x, ~zi ) head(r), ~xi ~x. Furthermore,let E'i fresh predicates arity |~xi | let C'i fresh predicates arity |~xi | + |~zi |uniquely associated r i. Then, norm() consists following rules:3x, ~y )1 (~^ ^x, ~y )n (~!_E'i (~xi ),(5)i=1E'i (~xi ) ! 9~zi C'i (~xi , ~zi ) 1 m,C'i (~xi , ~zi ) !1 atom'i (~x, ~zi ) ! E'i (~xi ) 1 m,'i (~x, ~zi ) ! C'i (~xi , ~zi ) 1 m.(6)'i (~x, ~zi ),(7)(8)(9)frequently use Skolemisation interpret rules Herbrand interpretations.rule r form (1) existentially quantified variable zij , let fijr functionsymbol globally unique r zij arity ~x. Furthermore, let sk substitutionsk (zij ) = fijr (~x) zij 2 ~zi . Skolemisation sk(r) r followingfirst-order sentence, slight abuse notation refer Skolemised rule:x, ~y )1 (~^ ^x, ~y )n (~!_'i (~x, ~zi )ski=1Skolemisation sk() set rules obtained Skolemising individual rule. extend definitions head body rules Skolemised rules naturally.well-known Skolemisation entailment-preserving transformation.2.2 Description Logics Ontology Languagesnext present brief overview DLs underpinning W3C standard ontologylanguage OWL 2 (Horrocks, Kutz, & Sattler, 2006; Cuenca Grau et al., 2008). Typically,predicates DL signatures restricted unary binary; former called atomicconcepts, whereas latter typically referred atomic roles. DLs typically providetwo special concepts ? (the bottom concept) > (the top concept), mappedevery interpretation empty set interpretation domain, respectively.Every OWL 2 DL ontology normalised set axioms form givenleft-hand-side Table 1 (Motik, Shearer, & Horrocks, 2009).4 Thus, w.l.o.g.,define OWL 2 DL ontology finite set axioms form (O1)(O13) Table 1.Every OWL 2 DL ontology must satisfy certain additional requirements order ensuredecidability reasoning (Horrocks et al., 2006). restrictions, however, immaterialtechnical results.normalised axiom corresponds single rule, given right-hand-sideTable 1. Concept ? translated special nullary predicate ?, whereas > translated3. Although rules (5)(7) sufficient express normal form, also introduce rules (8)(9) orderfacilitate computation upper bound query answers (see Sections 5.2 5.3).4. convenience, omit axioms form v n R.B simulated v 9R.Bi ,Bi v B Bi u Bj v ? 1 < j n Bi fresh concept.314fiPAGOdA: Pay-As-You-Go Query Answering Using Datalog ReasonerAxiomsdnAi v F?di=1nvi=1j=1 Bj9R.A v Bv Self(R)Self(R) vR vSR vSR vTRuS v?v 9R.Bv R.Bv {a}> v 8R.ARulesVnAi (x) ! W?Vi=1n(x)!i=1j=1 Bj (x)R(x, y) ^ A(y) ! B(x)A(x) ! R(x, x)R(x, x) ! A(x)R(x, y) ! S(x, y)R(x, y) ! S(y, x)R(x, z) ^ S(z, y) ! (x, y)R(x, y) ^ S(x, y) ! ?A(x) ! 9y(R(x, y) ^ B(y))VWA(x) ^ m+1i=1 [R(x, yi ) ^ B(yi )] !1i<jm+1 yi yjA(x) ! xR(x, y) ! A(y)(O1)(O2)(O3)(O4)(O5)(O6)(O7)(O8)(O9)(O10)(O11)(O12)(O13)Table 1: Normalised DL axioms translation rules n, > 0, Batomic concepts >, R, S, atomic roles.ordinary unary predicate, meaning axiomatised. Let functionmaps OWL 2 axiom corresponding rule Table 1, letontology. Then, (O) smallest knowledge base containing:() 2 O;rule A(x) ! >(x) atomic concept O;rules R(x, y) ! >(x) R(x, y) ! >(y) atomic role R O.Note since (O) knowledge base, must contain axioms equalitysignature whenever required translate axiom O.recent years, growing interest ontology languages favourablecomputational properties, led standardisation RL, QL, ELprofiles OWL 2 (Motik et al., 2012). say ontology Horn = 1axioms (O2) (O11). Additionally, say Horn ontologyRL contain axioms (O4), (O5), (O10).QL contain axioms (O4), (O5), (O8), (O9), (O11), (O12); furthermore, axioms (O1) (O2) satisfy n 2 axioms (O3) satisfy = >.EL contain axioms (O7), (O9) (O11). Additionally, sayEL ontology ELHOr? contain axioms (O4), (O5) (O8).2.3 Conjunctive Queriesconjunctive query (CQ) formula q(~x) form 9~y '(~x, ~y ), '(~x, ~y )conjunction function-free atoms. query Boolean |~x| = 0, atomic '(~x, ~y )315fiZhou, Cuenca Grau, Nenov, Kaminski, & Horrocksconsists single atom |~y | = 0. simplicity, sometimes omit free variableswrite q instead q(~x).Let K knowledge base. tuple ~a constants possible answer q(~x) w.r.t. Karity ~x constant ~a occurs K. Furthermore, saypossible answer ~a certain answer K |= q(~a); set certain answers denotedcert(q, K). Note that, '(~x, ~y ) Boolean, set certain answers either emptyconsists tuple length zero. treat unsatisfiability Boolean query'(~x, ~y ) nullary falsehood symbol ?; query holds w.r.t. K K unsatisfiable.CQs alternatively represented using datalog rules. end, query q(~x)uniquely associated predicate Pq arity |~x| (where take P? = ?) setRq rules defined follows:;q=?Rq =(10){'(~x, ~y ) ! Pq (~x)} otherwiseThen, ~a 2 cert(q, K) K [ Rq |= Pq (~a). way, certain answers characterisedmeans entailment single facts.Answering CQs w.r.t. knowledge bases computationally hard, decidability knowledge bases stemming OWL 2 DL ontologies remains open. Decidabilityobtained ensuring ontology stays within one standardised profilesOWL 2. restriction also ensures tractability respect data complexity,makes profiles natural choice ontology language data-intensive applications.standard language SPARQL 1.1 (W3C SPARQL Working Group, 2013) allows usersformulate CQs OWL 2 ontologies; however, ensure decidability reducecomplexity query answering, CQs interpreted SPARQL 1.1 ground semantics.say possible answer ~a q(~x) = 9~y '(~x, ~y ) ground answer w.r.t. satisfiableknowledge base K exists tuple ~e constants K K |= '(~a, ~e). Clearly,every ground answer certain answer vice versa. denote ground(q, K)set ground answers q w.r.t. K.Many reasoning systems currently support SPARQL 1.1 hence compute ground(q, K)given CQ q OWL 2 DL ontology K input. Additionally, systemsable compute certain answers q suitably restricted. precisely, say qinternalisable Kq = K [ Rq corresponds OWL 2 DL knowledge base. Internalisationamounts transforming query ontology axiom typically referredrolling-up DL literature (Horrocks & Tessaris, 2000).paper, focus general problem computing certain answers CQw.r.t. knowledge base K, theoretical results generally applicable regardlessrule-based language K expressed.2.4 HyperresolutionReasoning knowledge bases realised means hyperresolution calculus(Robinson & Voronkov, 2001), briefly discuss next. treatment hyperresolution consider standard basic notions theorem proving (ground) clausegeneral unifier (MGU). Furthermore, treat disjunctions ground atomssets hence allow duplicated atoms disjunction. assume ?316fiPAGOdA: Pay-As-You-Go Query Answering Using Datalog Reasoneroccur clauses denote empty clause. Skolemisation sk(r)normalised rule r logically equivalent clause containing atom dierent? head(sk(r)) negation atom body(sk(r)), sometimes abusenotation use sk(r) refer Skolemised rule corresponding clause.Let C = 1 _ _ n _ 1 _ _ clause, j atoms(possibly containing functional terms). Furthermore 1 n, let = _positive ground clause. Finally, let MGU pairs , , 1 n. Then,positive ground clause 1 _ _ _ 1 _ _ n hyperresolvent C 1 , . . . , n .inference called hyperresolution step, clause C main premise.Let K = K [ DK normalised knowledge base let C positive ground clause.derivation C K pair = (T, ) tree, labeling functionmaps node ground clause, v :(1)(v) = C v root;(2)(v) 2 DK v leaf;(3) v children w1 , . . . , wn , (v) hyperresolvent sk(r) (w1 ), . . . , (wn )rule r 2 K .support , written support(), set facts rules participating hyperresolution steps . write K ` C denote hyperresolution derivationC K. Hyperresolution sound complete: K unsatisfiable K ` ;furthermore, K satisfiable K ` K |= ground atom .2.5 Skolem ChaseAnswering CQs knowledge base K = K [ DK K consists existentialrules realised using chase technique (Abiteboul et al., 1995; Cal, Gottlob, &Kifer, 2013). paper, use Skolem chase variant (Marnette, 2009; Cuenca Grau,Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang, 2013).Skolem chase sequence K sequence sets ground atoms {B }i 0 ,0B = DK , B i+1 inductively defined follows:B i+1 = B [ {head(sk(r)) | r 2 K ,substitution, B |= body(r) }.Skolem chase K, written ChaseK , defined 0 B .key property Skolem chase computes universal Herbrand modelK, used database answering CQs. Formally, K satisfiable?2/ ChaseK ; furthermore, K satisfiable, ChaseK homomorphically embeddableevery Herbrand model K (seen set atoms). follows K satisfiableq Boolean CQ K |= q ChaseK |= q.Note ChaseK might contain infinitely many atoms. K datalog, however,ChaseK guaranteed finite contains precisely facts logically entailed K.case, often refer ChaseK materialisation K.317fiZhou, Cuenca Grau, Nenov, Kaminski, & Horrocks3. Overviewsection provide high-level overview approach conjunctive query answering. assume availability two reasoners:datalog reasoner sound complete answering conjunctive queriesdatalog knowledge bases;fully-fledged reasoner sound complete answering given classconjunctive queries Q (which includes unsatisfiability query) w.r.t. knowledgebases given ontology language L.describe approach general form, make assumptionstwo reasoners, treating black-box query answering procedures.kind queries knowledge bases dealt using approachultimately depends capabilities fully-fledged reasoner. instance, OWL2 DL reasoners typically process arbitrary OWL 2 DL knowledge bases; however,query language limited internalisable queries. turn, scalability approachultimately depends much reasoning workload delegated datalogreasoner; goal delegate bulk computation datalog reasonerrestrict (expensive) use fully-fledged reasoner bare minimum.Here, rest paper, fix arbitrary normalised knowledge baseK = K [ DK . Given arbitrary query q (which may special unsatisfiability query)containing symbols K, core approach relies exploiting datalogreasoner accomplishing following tasks:Lower Upper Bound Computation, exploit datalog reasonercompute lower bound Lq upper bound U q certain answersq w.r.t. K. bounds match (i.e. Lq = U q ), query fullyanswered datalog reasoner; otherwise, dierence Gq = U q \ Lq providesset gap answers need verified using fully-fledged reasoner.relevant techniques computing bounds described Sections 4 5.Knowledge Base Subset Computation, exploit datalog reasonercompute (hopefully small) subset Kq K sufficient check answers Gqcert(q, K); is, ~a 2 cert(q, K) ~a 2 cert(q, Kq ) ~a 2 Gq . detailscompute Kq given Section 6.proceed according following steps given query q:Step 1. Check satisfiability K.(a) Compute bounds L? U ? unsatisfiability query ?. L? 6= ;,terminate report K unsatisfiable. U ? = ;, proceed Step 2(K satisfiable).(b) Compute subset K? K.(c) Use fully-fledged reasoner check satisfiability K? . minimisecomputational workload fully-fledged reasoner, proceed follows:318fiPAGOdA: Pay-As-You-Go Query Answering Using Datalog Reasoneri. Construct summary K? (See Section 7), use fully-fledged reasoner check satisfiable; is, proceed Step 2 (K satisfiable).ii. Use fully-fledged reasoner check satisfiability K? ; unsatisfiable, terminate report K unsatisfiable. Otherwise,proceed Step 2 (K satisfiable).Step 2. Compute bounds Lq U q . Gq = ;, terminate return Lq . Otherwise,proceed Step 3.Step 3. Compute subset Kq K.Step 4. ~a 2 Gq , use fully-fledged reasoner check whether Kq |= q(~a).minimise computational workload, step carried follows:(a) Construct summary Kq Kq (see Section 7). ~a 2 Gq , usefully-fledged reasoner check whether ~a certain answer q w.r.t.summary Kq , remove ~a Gq case.(b) Compute dependency relation remaining answers Gq s.t. ~bdepends ~a ~a spurious answer, ~b. (See Section 7).(c) Remove remaining spurious answers Gq , answer spuriousentailed Kq depends spurious answer; use fullyfledged reasoner check relevant entailments, arranging checks heuristicsw.r.t. dependency relation.Step 5. Return Lq [ Gq .following sections, describe steps formally. also introducenumber improvements optimisations, rely additional assumptiondatalog reasoner materialisation-basedthat is, datalog knowledge base K0query q 0 , computes query answers cert(q 0 , K0 ) first computing materialisationChaseK0 evaluating q 0 resulting materialisation. reasonableassumption practice since datalog reasoners Semantic Web applications (e.g.,OWLim, RDFox, Oracles native inference engine) materialisation-based. cases,assume direct access materialisation. PAGOdA systemcombines HermiT materialisation-based reasoner RDFox, hence ableexploit improvements optimisations described below; realisationapproach PAGOdA discussed detail Section 8.illustrate techniques using running example consisting knowledgebase Kex = Kex [ DKex query qex (x) given Table 2. Note rules (R6)(R8) Kex normalised; however, easily brought normal formintroducing fresh binary predicates eatsH eatsL follows:MeatEater(x) ! 9y eatsH (x, y) (R6a)eats(x, y) ^ Herbivore(y) ! eatsH (x, y)eatsH (x, y) ! eats(x, y)eatsH (x, y) ! Herbivore(y)(R6b)(R6c)(R6d)319Folivore(x) ! 9y eatsL (x, y) (R8a)eats(x, y) ^ Leaf(y) ! eatsL (x, y)eatsL (x, y) ! eats(x, y)eatsL (x, y) ! Leaf(y)(R8b)(R8c)(R8d)fiZhou, Cuenca Grau, Nenov, Kaminski, & HorrocksMammal(tiger)(D1)Mammal(wolf )(D6)Mammal(howler)(D11)Mammal(lion)(D2)MeatEater(wolf )(D7)MeatEater(python)eats(python, rabbit)(D3)(D4)eats(wolf , sheep)Herbivore(sheep)(D8)(D9)Folivore(howler)Mammal(a hare)(D12)(D13)Folivore(a hare)(D14)Herbivore(rabbit)(D5)eats(sheep, grass)(D10)eats(a hare, willow)(D15)Carnivore(x) ! Mammal(x)Herbivore(x) ! Mammal(x)Folivore(x) ^ MeatEater(x) ! ?Herbivore(x) ^ eats(x, y) ! Plant(y)(R1)(R2)(R3)(R4)Mammal(x) ! Herbivore(x) _ MeatEater(x)(R5)Mammal(x) ! 9y eats(x, y)(R7)MeatEater(x) ! 9y[eats(x, y) ^ Herbivore(y)]Folivore(x) ! 9y[eats(x, y) ^ Leaf(y)]Leaf(x) ! Plant(x)(R6)(R8)(R9)qex (x) = 9y[eats(x, y) ^ Plant(y)]Table 2: Running example knowledge base Kex query qex (x). set Kex consistsrules (R1)(R9), dataset DKex consists facts (D1)(D15).core techniques described Sections 4-6 applicable knowledge basequery. order simplify presentation definitions technical resultssections fix, addition knowledge base K = K [ DK , arbitrary queryq(~x) = 9~y '(~x, ~y ) (which may unsatisfiability query ?).4. Lower Bound Computationstraightforward way compute lower bound answers using datalog reasonerevaluate q w.r.t. datalog subset K consisting facts DK datalog rulesK . case OWL 2 ontologies, amounts considering subset OWL 2RL axioms ontology. monotonicity property first-order logic certainanswers w.r.t. subset also certain answers w.r.t. K. Furthermore, subsetunsatisfiable, K.Example 4.1. datalog subset example Kex consists rules (R1)(R4)(R9), together facts (D1)(D15). materialisation datalog subsetKex results following dataset: Dex [ {Mammal(rabbit), Mammal(sheep), Plant(grass)}evaluating qex (x) materialisation obtain sheep answer.}basic lower bound rather imprecise practice since rules featuring disjunction existential quantification typically abound OWL 2 DL ontologies. improve320fiPAGOdA: Pay-As-You-Go Query Answering Using Datalog Reasonerbound, exploit techniques allow us deterministically derive (also via datalogreasoning) additional consequences K follow datalog subset.4.1 Dealing Disjunctive Rules: Program Shiftingdeal disjunctive rules, adopt variant shiftinga polynomial program transformation commonly used Answer Set Programming (Eiter, Fink, Tompits, & Woltran,2004). next illustrate intuition behind transformation example.Example 4.2. Let us consider information Kex Arctic hares (a hare).(R3) (D14), one deduce hare MeatEater, followsrule (R5) fact (D13) hare Herbivore. Since hare eats willow,deduce Plant(willow) (R4) hence hare answer qex . Although (R5)disjunctive rule, reasoning process fully deterministic captureddatalog. end, introduce predicate MeatEater intuitively standscomplement MeatEater. extend datalog subset Kex rules encodingintended meaning fresh predicate. particular, (R3) (R5) two rules,obtained (R3) (R5), respectively.Folivore(x) ! MeatEater(x)(R3)Mammal(x) ^ MeatEater(x) ! Herbivore(x)(R5)exploit rules derive MeatEater(a hare) Herbivore(a hare).}define shifting transformation formally.Definition 4.3. Let r normalised disjunctive datalog rule. predicate P rlet P fresh predicate arity. Furthermore, given atom = P (~t) letP (~t). shifting r, written shift(r), following set rules:r form (2), shift(r) = {r}[{ 1 ^ ^1 ^ i+1 ^ ^ n!| 1 n};r form (4), shift(r) consists following rules: (i) rule (S1);(ii) rules (S2) 1 j m; (iii) rules (S3) 1 n s.t.variable also occurs atom rule.111^ ^^ ^^ ^nn^^111^^ ^^ ^i+1!?j 1^ ^^n(S1)j+1^1^ ^^ ^!!j(S2)(S3)Let set normalised disjunctive datalog rules. Then, shifting definedfollowing set datalog rules:[shift() =shift(r)}r2Note shifting polynomial transformation. r disjunctive datalog rulen atoms body atoms head, shift(r) contains + n + 1 datalogrules. Furthermore, shown following theorem, also sound.321fiZhou, Cuenca Grau, Nenov, Kaminski, & HorrocksTheorem 4.4. Let DDsubset disjunctive datalog rules K ; furthermore, letKK0 = shift(DD)[.Then,cert(q, K0 ) cert(q, K).KK0Proof. Let ChaseK0 = {B }Li=1 L non-negative integer (recall K datalogknowledge base hence Skolem chase finite). show inductionfollowing properties hold 0 L 2 B :(a) = ?, K unsatisfiable;(b) = P (~a), K |= P (~a);(c) = P (~a), K |= P (~a).Base case: Clearly, B 0 = DK properties trivially follow fact DK K.Inductive step: Assume properties (a)(c) hold every 2 B . showalso hold every 2 B i+1 \ B . must exist rule r0 2 K0 substitutionB |= body(r0 ) = head(r0 ) . Since every atom body(r0 ) B ,properties (a)-(c) hold atoms induction hypothesis. Furthermore,must exist rule r 2 K form 1 ^ ^ n ! 1 _ _ r0 2 shift(r).(a) = ?, distinguish two cases. (i) head(r) = ?, case r = r0induction hypothesis, K |= { 1 , . . . , n } hence K |= ?; (ii) head(r) 6= ?,case r0 form (S1) 1 , . . . , n 1 , . . . , B .induction hypothesis, K entails 1 , . . . , n 1 , . . . , . then, rule rcannot satisfied model K since r 2 K, obtain K unsatisfiable.(b) = P (~a), r0 form (S2) = P (~a). Hence, B contains atomsi+1 , . . . , . induction hypothesis, K entails1 ,..., n , 1 ,... 1,...,,,...,a)1n11 , i+1 , . . . , . Since r 2 K = P (~must case K |= P (~a).(c) = P (~a), following cases. (i) head(r) = ?, case inductionK |= { 1 , . . . , 1 , i+1 , . . . , n }; then, since 1 ^ ^ n ! ? alsorule K, obtain K |= , required. (ii) head(r) 6= ?, caser0 form (S3) = P (~a); then, B contains atoms 1 , . . . , 1 ,induction hypothesis K entails atomsi+1 , . . . , n , 1 , . . . ,,...,,,...,a).11i+1n1 , . . . , . Since r 2 K obtain K |= P (~Vq = ?, theorem follows property (a). Otherwise, let q(~x) = 9~y ( ni=1 (~x, ~y ))let ~a possible answer K0 |= q(~a). Since K0 datalog, exists tuple~e constants K0 non-negative integer L (~a, ~e) 2 B L 0 n.then, (b) K |= (~a, ~e), hence K |= q(~a).Shifting captures consequences disjunctive datalog rules K.Furthermore, note refinement shifting ensures preservationconsequences; indeed, well-known disjunctive datalog express queries (e.g.,non-3-colorabilility) cannot captured means datalog program (Afrati, Cosmadakis, & Yannakakis, 1995).322fiPAGOdA: Pay-As-You-Go Query Answering Using Datalog ReasonerExample 4.5. Consider disjunctive datalog knowledge base consisting factGreenSeaTurtle(turtle), rules (R1), (R2)GreenSeaTurtle(x) ! Herbivore(x) _ Carnivore(x).Clearly, Mammal(turtle) follows knowledge base. shifting consists factGreenSeaTurtle(turtle) following rules, predicates Carnivore, GreenSeaTurtle,Herbivore Mammal abbreviated as, respectively, C, G, H M:C(x) ^ M(x) ! ?C(x) ! M(x)M(x) ! C(x)G(x) ^ H(x) ^ C(x) ! ?G(x) ^ H(x) ! C(x)G(x) ^ C(x) ! H(x)H(x) ^ M(x) ! ?H(x) ! M(x)H(x) ^ C(x) ! G(x)M(x) ! H(x)}checked fact Mammal(turtle) follow shifting.4.2 Dealing Existential Rules: Combined Approach OWL 2 ELExistentially quantified rules ubiquitous large-scale complex ontologies, especiallylife sciences applications. EL profile OWL 2 specifically designedapplications, many large ontologies used practice seen consisting largeEL backbone extended small number axioms outside profile.Given prevalence EL axioms realistic ontologies, natural considerOWL 2 EL subset K computing lower bound answers. CQ answering OWL2 EL is, however, PSpace-complete (Stefanoni, Motik, Krotzsch, & Rudolph, 2014)system currently supports CQ answering whole OWL 2 EL. Complexity,however, drops NP case ELHOr? (Stefanoni et al., 2014). setting,restriction ELHOr? ontologies added practical benefit exploit socalled combined approach delegate computational work associated CQanswering datalog reasoner (Stefanoni et al., 2013; Lutz, Toman, & Wolter, 2009)atechnique currently supported systems KARMA.5 Although datalog-based CQanswering techniques also available richer languages, extension ELHOr?inverse roles (i.e., axioms (O7) Table 1), resulting datalog programs hardcompute exponential size worst case (Perez-Urbina, Motik, & Horrocks,2010). contrast combined approach ELHOr? , relevant datalogprograms straightforwardly constructed without need reasoning,linear size (see Related Work section details).Thus, compute query answers depend existentially quantified rules considerrsubset ELK ELHO ? rules K, syntactically characterised follows.Definition 4.6. rule ELHOr? one following forms, '(x) either?, form A(x), x c, 9yR(x, y):p^i=1Ai (x) ^q^j=1[Rj (x, yj ) ^lj^k=15. http://www.cs.ox.ac.uk/isg/tools/KARMA/323Bjk (yj )] ! '(x),(EL1)fiZhou, Cuenca Grau, Nenov, Kaminski, & HorrocksR1 (x, y) ! R2 (x, y),R(x, y) ! A(y).(EL2)(EL3)combined approach exploit CQ answering conceptualisedthree-step process.1. first step compute materialisation datalog program obtainedELK respect DK . contains ?, knowledge base unsatisfiable. Otherwise model knowledge base. model, however,universal cannot homomorphically embedded every model. Thus,evaluation CQs may lead unsound answers.2. second step evaluate query q . step intractable querysize, well-known database techniques exploited.3. third step, unsound answers obtained second step discarded usingpolynomial time filtration algorithm.next specify transformation knowledge bases datalog used firststep, transformation also exploited later Section 5 computing upperbound query answers. computation datalog program knowledge baseStep 1 relies form Skolemisation existentially quantified variables mappedfresh constants (instead functional terms).Definition 4.7. rule r form (1) existentially quantified variablezij , let crij constant globally unique r zij , let c-sk substitutionc-sk (zij ) = crij zij 2 ~zi . c-Skolemisation c-sk(r) r given follows:x, ~y )1 (~^ ^x, ~y )n (~!_'i (~x, ~zi )c-sk .i=1Then, define c-sk(K) = {c-sk(r) | r 2 K } [ DK .}Note application c-Skolemisation ELHOr? rule always resultsdatalog rule. Note also that, contrast standard Skolemisation, c-Skolemisationsatisfiability entailment preserving transformation, may query answersw.r.t. c-sk(K) unsound w.r.t. K. shown, however, c-Skolemisationsatisfiability-preserving ELHOr? knowledge bases; thus, c-sk(ELK ) [ DK satisfiableEL[satisfiable(Stefanonietal.,2013).nextsketchfiltration step,KKrefer interested reader work Stefanoni et al. details.main source spurious answers evaluating query materialisationobtained Step 1 presence forksconfluent chains binary atoms involvingSkolem constantsin image query materialisation. duefact ELHOr? so-called forest-model property, forks cannot manifestforest-shaped models. say constant c ELK [DK auxiliarydierent constant b exists c-sk(EL)[|=cb;is,auxiliary constantsKKintroduced c-Skolemisation entailed equal324fiPAGOdA: Pay-As-You-Go Query Answering Using Datalog Reasonerconstant present original ELHOr? knowledge base. Let substitutionmapping free variables ~x q constants ~a K |= q . Then, relationq ~a smallest reflexive-transitive binary relation terms q satisfyingfollowing fork rule(fork)0 t0stR(s, s0 ) P (t, t0 ) occur q,(s0 ) auxiliary constant.Clearly equivalence relation, computed polynomial time sizeq. term q, let [t] equivalence class w.r.t. , let mappingterm q arbitrary fixed representative [t]. auxiliary graphq ~a directed graph G = hV, EiV contains vertex (t) term q (t) auxiliary;E contains directed edge h (s), (t)i atom form R(s, t) q{ (s), (t)} V .Now, ready define filtration. say ~a spurious answer eitherauxiliary graph q contains cycle, terms occurring q existc-sk(ELK ) [ DK 6|= (s) (t). Clearly, filtration candidate answer ~done polynomial time size q.assume availability procedure soundAnswers solves Steps 2 3;is, given q model computed Step 1, returns answers q w.r.t.input ELHOr? knowledge base. Consequently, given K q, obtain lower boundquery answers follows:rextract subset ELK ELHO ? rules K;compute materialisation c-sk(ELK ) [ DK ;q = ? return unsatisfiable ? 2 ; otherwise, return soundAnswers(q, ).Example 4.8. Consider running example. ELHOr? subset Kex consistsfacts (D1)(D15) together rules except (R4) (R5). fact (D12)rule (R8) deduce howler eats leaf, must plant rule (R9). Hencehowler answer qex . answer identified using aforementioned steps.c-Skolemisation (R8a) leads datalog ruleFolivore(x) ! eatsL (x, c3 )(R8aU)materialisation datalog program consisting facts rule (R8aU) containsfact Plant(c3 ) hence tuple (howler, c3 ) matches qex materialisation.match deemed sound filtration procedure.}4.3 Aggregated Lower Boundtechniques section seamlessly combined obtain lower bound Lqhopefully close actual set certain answers. Given K q, proceed follows:325fiZhou, Cuenca Grau, Nenov, Kaminski, & HorrocksDD subset1. Construct datalog knowledge base shift(DDK ) [ DK , KLdisjunctive datalog rules K . Compute materialisation M1 .LL2. Construct datalog program c-sk(ELK ) [ M1 compute materialisation M2 .3. q = ?, Lq = cert(q, M2L ). Otherwise, Lq = soundAnswers(q, M2L ).Theorem 4.4 ensures K |= 2 M1L signature K, hence M1Lused initial dataset second step. properties c-Skolemisationfiltration discussed Section 4.2 ensure every answer Lq indeed certainanswer q w.r.t. K. Furthermore, ? 2 M2L , K indeed unsatisfiable. Finally, notematerialisation M1L obtained first step pipelined second step;result, Lq (sometimes strict) superset answers would obtain simplyELcomputing answers q w.r.t. shift(DDK ) [ DK c-sk(K ) [ DK independentlyunion results.Example 4.9. running example Kex , aggregated lower bound Lex consistssheep (which follows datalog subset Kex ), hare (which follows shift(Kex )),howler (which follows ELHOr? fragment Kex ).}5. Upper Bound Computationmany practical cases lower bound Lq described Section 4.3 constitutes ratherprecise approximation actual set certain answers. Furthermore, alsocomputed efficiently resorting datalog reasoner. lower boundcomputation, however, gives indication accuracy answers: withoutcorresponding upper bound, every possible answer remains candidate answer,needs either confirmed discarded.section, describe approach efficiently computing upper boundset certain answers. lower upper bounds coincide, fully answeredquery; otherwise, gap lower upper bounds provides marginerror lower bound, also narrows set candidate answers whoseverification may require powerful computational techniques.5.1 Strengthening Knowledge Basefirst step towards computing upper bound construct (polynomial size)datalog knowledge base K0 K unsatisfiable, K0 entails nullary predicate?s , cert(q, K) cert(q, K0 ) otherwise. Roughly speaking, K0 , referdatalog strengthening K, obtained K1. replacing ? fresh nullary predicate ?s predefined meaning;2. splitting disjuncts occurring head position dierent datalog rules;3. Skolemising existentially quantified variables constants Definition 4.7.convenient subsequent definitions proofs explicitly define splittingK, written split(K), intermediate knowledge base resulting Steps 1 2 above,326fiPAGOdA: Pay-As-You-Go Query Answering Using Datalog Reasonersatisfiable disjunction-free. datalog strengthening K definedresult applying Step 3 replacing existentially quantified rulesplit(K) c-Skolemisation.Definition 5.1. splitting rule r form (1) following set rules:head(r) = ?, split(r) = { 1 ^ ^predicate predefined meaning;otherwise, split(r) = {! ?s }, ?s fresh nullary! 9~zj 'j (~x, ~zj ) | 1 j }.splitting K = K [ DK defined split(K) = r2K split(r) [ DK . Finally,datalog strengthening K defined str(K) = c-sk(split(K)).}1^ ^nnExample 5.2. Consider example knowledge base Kex . splitting Kex obtainedreplacing rule (R5) rules (R5Ua) (R5Ub), rule (R3) (R3U).Mammal(x) ! Herbivore(x)Mammal(x) ! MeatEater(x)Folivore(x) ^ MeatEater(x) ! ?s(R5Ua)(R5Ub)(R3U)Finally, str(K) obtained replacing existentially quantified rules (R6a), (R7)following rules (R6aU), (R7U)MeatEater(x) ! eatsH (x, c1 )Mammal(x) ! eats(x, c2 )well rule (R8a) rule (R8aU) given Example 4.8.(R6aU)(R7U)}Note K contain rules ? head, str(K) logically entailsK: splitting amounts turning disjunctions head rules conjunctions,c-Skolemisation restricts possible values existentially quantified variables fixedconstants. Thus, cert(q, str(K)) constitutes upper bound cert(q, K). is, however,longer case ? replaced ordinary predicate ?s without predefinedmeaning. rationale behind replacement provide meaningful upper boundeven cases splitting disjunctions c-Skolemising existentially quantified variableswould make strengthened knowledge base unsatisfiable.0 = str(K ) example knowledge base.Example 5.3. Consider strengthening KexexSince howler Mammal, Rule (R5Ub) also MeatEater. then,since Folivore(howler) fact Kex derive ?s using Rule (R3U). Note that,replaced falsehood predicate ? ?s , strengthening Kex wouldunsatisfiable, case meaningful upper bound could obtained query. }next show str(K) exploited compute meaningful upper boundinput query, despite fact ? stripped built-in semantics first-orderlogic. following lemma establishes key property splitting transformationDefinition 5.1: ground clause ' = 1 _ _ n derivable K via hyperresolution,Skolem chase split(K) contains every atom 1 n.327fiZhou, Cuenca Grau, Nenov, Kaminski, & HorrocksLemma 5.4. Let = (T, ) hyperresolution derivation K let H = split(K).Then, every node v 2 ground atom occurring (v), 2 ChaseH .Proof. prove claim structural induction .Base case: v leaf , (v) 2 DK . Since DK H 2 ChaseH .Inductive step: Assume induction hypothesis holds children w1 , . . . , wnnode v 2 . exists rule r 2 K substitution , sk(r) form1 _ _ n _ disjunction atoms, (v) =_ 1 _ _ nhyperresolvent sk(r) (wi ) = _ 1 n. inductionhypothesis, disjuncts ChaseH , need show claimdisjunct. distinguish following cases depending formnormalised rule rr form (2),empty. claim holds vacuously.r form (3), = 1 sk . induction hypothesis,ChaseH , since split(r) = r hence r 2 H, obtain 1 sk 2 ChaseH .r form (4), = 1 _ _ . induction hypothesis,ChaseH , 1 m, since rule 1 ^ ^ n ! H, obtainatom also ChaseH , required.exploit completeness hyperresolution show split(K) satisfiesrequired properties. Furthermore, fact str(K) |= split(K) immediately impliesstr(K) satisfies properties well hence may exploited compute upperbound query answers.Theorem 5.5. following properties hold H = split(K) well H = str(K):(i) cert(?, K) cert(?s , H), i.e. K unsatisfiable, H |= ?s ; (ii) Ksatisfiable cert(q, K) cert(q, H).Proof. first show Properties (i) (ii) hold H = split(K). K unsatisfiable,hyperresolution derivation empty clause K. Thus, mustexist rule r form (2) K substitutionatom1 n also derivable K. then, Lemma 5.4 2 ChaseH .Since H contains rule 1 ^ ^ n ! ?s ?s 2 ChaseH H |= ?s , required.Assume K satisfiable. cert(q, K) = ;, cert(q, K) cert(q, H) holds trivially;otherwise let ~a certain answer q w.r.t. K. K |= q(~a) hence K [ Rq |= Pq (~a).Since cert(?, K) = ;, q 6= ?. Using completeness hyperresolutionLemma 5.4 obtain Pq (~a) chase K [ Rq . then, aforementionedsplitting also entails Pq (~a) since split(K [ Rq ) = H [ Rq ~a 2 cert(q, H),required. Finally, Properties (i) (ii) hold str(K) direct consequence factstr(K) |= split(K).Example 5.6. Figure 1 depicts materialisation str(Kex ), edges predicatesintroduced normalisation ignored edges figure representbinary predicate eats. Explicit facts Kex depicted black; implicit facts depicted328fiPAGOdA: Pay-As-You-Go Query Answering Using Datalog Reasonerc1tigerMammalHerbivoreMeatEaterMeatEaterMammalHerbivorePlantlionMammalHerbivoreMeatEaterc2pythonMeatEaterPlantgrass PlantwolfrabbitHerbivoreMammalMeatEaterMammalMeatEaterHerbivorec3sheepHerbivoreMammalMeatEaterPlantLeafPlantwillow PlanthowlerhareMammalFolivoreHerbivoreMeatEaterMammalFolivoreHerbivoreMeatEaterFigure 1: Materialisation Datalog strengthening Kexusing dierent colours facilitate subsequent illustration refinementsmaterialisation allow us tighten upper bound. obtain followingupper bound cert(qex , Kex ) evaluating qex materialisation:cert(qex , str(Kex )) = {tiger, lion, python, rabbit, wolf , sheep, howler, hare, c1 }already mentioned, str(Kex ) |= ?s ; however, obtained upper bound still meaningfulsince contain possible answers Kex , grass willow. Please notec1 certain answer qex w.r.t. str(Kex ); however, constant c1 signatureKex hence possible answer qex w.r.t. K.}5.2 Tightening Upper Bound: Existential Rulesupper bound obtained str(K) rather coarse-grained practice: discussedExample 5.6, python, tiger, lion wolf contained upper bound, nonecertain answer qex . section, show refine upper boundrestricting application c-Skolemisation existential rules. Instead computingupper bound q constructing strengthened knowledge base str(K)evaluating q (the materialisation of) str(K), proceed follows.1. Apply K variant Skolem chase, refer c-chase firstsplitting disjuncts occurring head position dierent rules applyingSkolem chasing split(K) following modifications: (i) similarlyrestricted chase (Cal et al., 2013), existential rules applied rulehead already satisfied; (ii) rather Skolemising head atom (usingfunctional term) whenever existential rule applied, resort c-Skolemisationinstead. Due latter modification, c-chase compute leastHerbrand Model split(K), rather model split(K).2. Evaluate q result aforementioned chase, thus obtaining upper boundcertain answers q w.r.t. split(K), thus also w.r.t. K.following example motivates practical advantages approach.Example 5.7. Consider materialisation str(Kex ) Figure 1. alreadymentioned, python returned upper bound answer since qex matches facts329fiZhou, Cuenca Grau, Nenov, Kaminski, & Horrockseats(python, c1 ) Plant(c1 ) materialisation. fact eats(python, c1 ) obtainedeatsH (python, c1 ), included materialisation satisfy c-Skolemisedrule (R6aU) str(Kex ), also existentially quantified rule (R6a) Kex . casepython, however, rule (R6a) Kex already satisfied fact eatsH (python, rabbit),derived eats(python, rabbit) Herbivore(rabbit) dataset, rule(R6b). Please note rule (R6b) form (9) normalisation (R6).Rule (R6b) ensures (R6) satisfied substitution, (R6a) also satisfied substitution. obtain upper bound suffices construct modelKex (rather model str(Kex )); thus, prevent application rule (R6aU)python chase, dispense eats(python, c1 ) materialisation. }ready define c-chase formally.Definition 5.8. Let H = split(K), let dH subset datalog rules H ,eH = H \ dH . c-chase sequence K sequence sets ground atoms {B }i 0 ,B 0 = DH (i.e. B 0 = DK ), B i+1 inductively defined given next. Let Sdi+1Sei+1 defined follows:Sdi+1 = {head(r) | r 2 dH ,Sei+1 = {head(c-sk(r)) | r 2 eH ,substitution, B |= body(r) B 6|= head(r)}substitution, B |= body(r) B 6|= head(r)}Then, B i+1 = B [ Sdi+1 Sdi+16 ;, B i+1 = B [ Sei+1 otherwise. Finally, define=c-chase K c-ChaseK = 0 B .}Note c-chase K finite set since terms occurconstants c-sk(split(K)).Example 5.9. c-chase Kex depicted Figure 2. materialisation strictsubset Figure 1, orange-coloured binary facts longer derived.Consequently, python longer derived answer qex .}relevant properties c-chase summarised following lemma.Theorem 5.10. following properties hold: (i) cert(?, K) cert(?s , c-ChaseK ), i.e.K unsatisfiable, ?s 2 c-ChaseK ; (ii) K satisfiable, cert(q, K) cert(q, c-ChaseK ).Proof. first prove c-ChaseK model split(K). Since DK c-ChaseK clearsatisfies facts split(K). Let r 2 split(K); distinguish two cases:rule r datalog. c-ChaseK |= body(r) substitution definitionc-chase ensures head(r) 2 c-ChaseK hence rule satisfied.Otherwise, r form (3). c-ChaseK |= body(r) substitutiondefinition c-ChaseH ensures head(c-sk(r)) 2 c-ChaseK ; thus, c-ChaseK |=head(r) hence rule satisfied.show contrapositive first property. Assume ?s 62 c-ChaseK .c-ChaseK model split(K), split(K) 6|= ?s hence K satisfiableTheorem 5.5. Finally, assume K satisfiable. cert(q, K) = ;, cert(q, K) cert(q, H)holds trivially; otherwise let ~a certain answer q w.r.t. K. Theorem 5.5, obtain~a 2 cert(q, split(K)). c-ChaseK |= split(K), ~a 2 cert(q, c-ChaseK ).330fiPAGOdA: Pay-As-You-Go Query Answering Using Datalog Reasonerc1tigerMammalHerbivoreMeatEaterMeatEaterMammalHerbivorePlantlionMammalHerbivoreMeatEaterc2pythonPlantgrass PlantwolfrabbitMeatEaterHerbivoreMammalMeatEaterMammalMeatEaterHerbivorec3sheepHerbivoreMammalMeatEaterPlantLeafPlantwillow PlanthowlerhareMammalFolivoreHerbivoreMeatEaterMammalFolivoreHerbivoreMeatEaterFigure 2: c-chase Kex5.3 Tightening Upper Bound: Disjunctive RulesAlthough technique described previous section quite eective practice,main limitation split(K) disjunctions heads rules K eectively turned conjunctions. section, show refine upper boundexploiting extension c-chase uses similar approach deal disjunctiverules well existential rules.Specifically, extend c-chase deal disjunctive rules r form (4)(i) r applied none disjuncts head rule alreadysatisfied; (ii) r applied, one disjuncts included chase (ratherthem). order avoid non-determinism chase expansion reducecomputational cost, disjuncts selected deterministically means (efficientlyimplementable) choice function.Example 5.11. Consider running example. First observe wolf answerqex w.r.t. c-chase Kex shown Figure 2. Indeed, Herbivore(wolf ) derivedMammal(wolf ) rules split (R5); thus, Plant(sheep) also derived usingrule (R4). Note, however, wolf spurious answer: given MeatEater(wolf )explicit fact Kex , rule (R5) already satisfied wolf hence dispensefact Herbivore(wolf ) materialisation.Finally, since goal construct model Kex reasonable pick disjunctswhose predicate unrelated ? Kex . Since ? depends MeatEater Folivore(by rule (R3)), makes sense include fact Herbivore(b) materialisation wheneverdisjunctive rule (R5) applied constant b.}details refer reader Section 8, specific choice functionimplemented PAGOdA described.define extended notion c-chase, efficiently implementablechoice function given additional parameter.Definition 5.12. Let H knowledge base obtained K replacing ?nullary predicate ?s , let dH set datalog rules H , let nH = H \ dH .Furthermore, let f polynomially computable choice function given ground clauseset ground atoms returns disjunct . c-chase sequence K w.r.t. f331fiZhou, Cuenca Grau, Nenov, Kaminski, & Horrocksc2tigerMammalHerbivorelionMammalHerbivorepythonMeatEaterPlantgrass PlantwolfrabbitHerbivoreMammalMammalMeatEaterc3sheepHerbivoreMammalLeafPlantwillow PlanthowlerhareMammalFolivoreHerbivoreMammalFolivoreHerbivoreFigure 3: c-chasef Kexsequence sets ground atoms {B }i 0 , B 0 = DH (i.e., B 0 = DK ), B i+1defined given next. Let Sdi+1 Sni+1 follows:Sdi+1 = {head(r) | r 2 dH ,Sni+1 = {f (head(c-sk(r)) , B ) | r 2 nH ,substitution, B |= body(r) B 6|= head(r)}substitution , B |= body(r) B 6|= head(r)}Then, B i+1 = B [ Sdi+1 Sdi+1 6= ;, B i+1 = B [ Sni+1 otherwise. Finally, definec-chase K w.r.t. f c-ChasefK = 0 B .}Example 5.13. Consider aforementioned choice function f picks Herbivore(b)whenever rule (R5) applied fact Mammal(b). Figure 3 depicts facts c-ChasefKex .observed c-ChasefKex strict subset materialisation Figure 2,brown-colored facts longer derived. see wolf answerqex w.r.t. c-ChasefKex hence identified spurious. Furthermore, nullarypredicate ?s derived hence determine Kex satisfiable. }relevant properties variant c-chase follows.Theorem 5.14. Let f choice function Definition 5.12. ?s 62 c-ChasefK ,c-ChasefK model K cert(q, K) cert(q, c-ChasefK ).Proof. dataset DK contained c-ChasefK , suffices show c-ChasefK satisfiesrule r 2 K. distinguish following cases:r form (2). Since ?s 2/ c-ChasefK , cannot exist substitutionc-ChasefK |= body(r) hence c-ChasefK satisfies r vacuously.r form (3). Pick c-ChasefK |= body(r) . definition c-ChasefKensures head(c-sk(r)) 2 c-ChasefK hence c-ChasefK satisfies r.r form (4). Pick c-ChasefK |= body(r) . definitionc-ChasefK , f (head(c-sk(r)), Sni ) 2 c-ChasefK set atoms Snichase sequence, c-ChasefK satisfies r.q = ?, cert(q, K) = ; cert(q, K) cert(q, c-ChasefK ) holds trivially; otherwise,cert(q, K) cert(q, c-ChasefK ) follows fact c-ChasefK model K.332fiPAGOdA: Pay-As-You-Go Query Answering Using Datalog Reasoner5.4 Combined Upper Boundintroduced three dierent techniques computing upper bound cert(q, K).1. Compute materialisation M1U str(K), evaluate q w.r.t. M1U obtain setpossible answers U1q q w.r.t. K (c.f. Section 5.1).2. Compute c-chase K, denoted M2U , evaluate q w.r.t. M2U obtain setpossible answers U2q q w.r.t. K (c.f. Section 5.2).3. Fix choice function f , compute c-chase K w.r.t. f , denoted M3U , evaluate q w.r.t. M3U obtain set possible answers U3q q w.r.t. K (c.f. Section 5.3).trivially seen U2q U3q precise U1q , i.e. U2q U1q U3q U1q .shown following example, U2q U3q are, however, incomparable.Example 5.15. Consider knowledge base H consisting facts A(a1 ), R(a1 , b1 ), B(b1 ),A(a2 ), R(a2 , b2 ), B(b2 ) rules B(x) ! C(x) _ D(x), R(x, y) ^ C(y) ! S(x, y)A(x) ! 9yS(x, y). Let c freshly introduced constant A(x) ! 9yS(x, y), letf choice function picks disjunct D(bi ) every clause C(bi ) _ D(bi ). Then,c-ChaseH = DH [ {C(b1 ), D(b1 ), S(a1 , b1 ), C(b2 ), D(b2 ), S(a2 , b2 )},c-ChasefH = DH [ {D(b1 ), S(a1 , c), D(b2 ), S(a2 , c)}.q1 (x) = 9y(S(x, y) ^ C(y) ^ D(y)), upper bound computed using c-ChaseHcontains two additional answers a1 a2 compared computed using c-ChasefH .q2 (x1 , x2 ) = 9y(S(x1 , y) ^ S(x2 , y)), upper bound computed using c-ChasefHadditional answers (a1 , a2 ) (a2 , a1 ) compared computed using c-ChaseH . }are, however, tradeos considered. Clearly, upper bound U1qconvenient ease implementation point view: str(K) constructed,bound directly computed using o-the-shelf datalog reasoner without modification. Furthermore, upper bound U3q important shortcoming: usewhenever ?s derived, show following example.Example 5.16. Consider choice function g picks MeatEater(a) disjunction form Herbivore(a) _ MeatEater(a). c-chase Kex w.r.t. g deriveMeatEater(howler) fact Mammal(howler) disjunctive rule (R5). Usingfact Folivore(howler) rule (R3U) derive ?s . Thus see that, althoughhowler cert(qex , Kex ), Herbivore(howler) c-chase Kex w.r.t. g, hencehowler upper bound computed using it; contrast twoupper bounds, Herbivore(howler) materialisation str(Kex ) c-chaseKex , hence howler upper bound computed w.r.t. them.}Therefore, ?s 62 c-ChasefK , combine U2q U3q compute hopefullyprecise upper bound; otherwise, use U2q . combined upper bound query answerU q q K formally defined follows:8 ?s?< U2 \ U3 q = ?;qqqU =(13)U \ U3q 6= ? ?s 62 c-ChasefK ;: 2qU2otherwise.333fiZhou, Cuenca Grau, Nenov, Kaminski, & HorrocksExample 5.17. combined upper bound qex Kex gives:Uex = {tiger, lion, rabbit, sheep, howler, hare}.compare upper bound aggregated lower bound Lex given Example 4.9identify gap Gex = {tiger, lion, rabbit}.}6. Reducing Size Knowledge BaseWhenever non-empty gap Gq lower upper bound (e.g., runningexample) need verify whether answer Gq spurious not. Accomplishingtask using fully-fledged reasoner computationally expensive: verifyinganswer Gq typically involves satisfiability test, infeasible practicelarge-scale knowledge bases.section propose technique identifying (typically small) subset Kqknowledge base K sufficient verifying answers Gq (i.e. ~a 2 cert(q, K)~a 2 cert(q, Kq ) ~a 2 Gq ). essential subsets be, one hand,small possible and, hand, efficiently computable. requirementsconflict: computing minimal-sized subsets hard answering query, whereassubsets easily computed may almost large initial knowledge base.main idea behind approach construct datalog knowledge base whosematerialisation identifies rules facts Kq . knowledge base size polynomialsizes K q include predicates arity higher Kq. way, subset computation fully delegated scalable datalog reasoner,hence addressing efficiency requirement. key property Kq , ensurescontains relevant information K, following: rule fact 2/ Kqshow occur hyperresolution proof (resp. gap answerGq ) K [ Rq q = ? (resp. q 6= ?). completeness hyperresolutionguarantees excluded facts rules indeed irrelevant.6.1 Overview ApproachLet us motivate main ideas behind approach using running example. Since ?sderived M2U \ M3U , know cert(?, Kex ) = ;, hence Kexsatisfiable (see Example 5.13). However, still need determine whether answersGex = {tiger, lion, rabbit} combined upper bound cert(qex , Kex ), i.e.,certain answers qex .sketch construction datalog knowledge base track(Kex , qex , Gex )subset Kex relevant answers Gex derived. key propertyknowledge base materialisation tracks rules facts mayparticipate hyperresolution proof gap answer thus encodes contentssubset Kqex . relevant information recorded using fresh predicates constants:fresh predicate P R predicate P Kex , extensionmaterialisation track(Kex , qex , Gex ) give us facts subset.334fiPAGOdA: Pay-As-You-Go Query Answering Using Datalog Reasonerfresh constant dr rule r Kex special unary predicate Rel,extension materialisation track(Kex , qex , Gex ) give us rulessubset.key step construction knowledge base invert rule r 2 Kexset datalog rules (r) (i) moving head atoms r bodyreplacing predicates corresponding fresh ones (e.g., replace P P R );(ii) copying atoms originally body r (now empty) headreplacing predicates corresponding fresh ones adding special atomRel(dr ) additional conjunct; (iii) eliminating conjunction head rsplitting r multiple rules, one head conjunct.Consider first example datalog rule (R4) Kex , invertedfollowing rules:PlantR (y) ^ Herbivore(x) ^ eats(x, y) ! HerbivoreR (x)RRPlant (y) ^ Herbivore(x) ^ eats(x, y) ! eats (x, y)RPlant (y) ^ Herbivore(x) ^ eats(x, y) ! Rel(dR4 )(14)(15)(16)head Plant(y) (R4) moved body predicate Plant replacedPlantR ; body Herbivore(x) ^ eats(x, y) copied head conjunctionHerbivoreR (x) ^ eatsR (x, y), conjoined special atom Rel(dR4 ); finallyhead conjunction eliminated splitting rule three separate rules.rules reflect intuitive meaning freshly introduced predicates. factPlantR (c) holds constant c, means fact Plant(c) may participatehyperresolution proof Kex answer gap. Additionally, Herbivore(b)eats(b, c) also hold b, facts rule (R4) could also participateone proof since Plant(c) hyperresolvent facts Herbivore(b) eats(b, c)rule (R4), recorded facts HerbivoreR (b), eatsR (b, c), Rel(dR4 ). Thus, rules(14)(16) faithfully invert hyperresolution steps involving rule (R4).Similarly, disjunctive rule (R5) inverted following two rules:HerbivoreR (x) ^ MeatEaterR (x) ^ Mammal(x) ! MammalR (x)RRHerbivore (x) ^ MeatEater (x) ^ Mammal(x) ! Rel(dR5 )(17)(18)case, disjunctive head Herbivore(x)_MeatEater(x) (R5) movedbody conjunction HerbivoreR (x) ^ MeatEaterR (x) fresh predicates HerbivoreRMeatEaterR . facts HerbivoreR (c) MeatEaterR (c) hold c (which meansfacts Herbivore(c) MeatEater(c) may participate relevant proof Kex )Mammal(c) holds, also deem fact Mammal(c) rule (R5) relevant.situation dierent comes inverting existentially quantified rules,case longer capture relevant hyperresolution steps Kex faithfully. Considerrule (R7), inverted follows:eatsR (x, y) ^ Mammal(x) ! MammalR (x)Reats (x, y) ^ Mammal(x) ! Rel(dR7 )335(19)(20)fiZhou, Cuenca Grau, Nenov, Kaminski, & Horrockscase, existentially quantified head 9y eats(x, y) moved body atomeatsR (x, y). eatsR (b, c) holds b c (and hence fact may participaterelevant proof), Mammal(b) also holds, record (R7) Mammal(b)relevant (the latter means fact MammalR (b)). hyperresolvent Mammal(b)(R7) atom eats(b, t), functional term, may unrelated eats(b, c)hence irrelevant proving answer gap.addition inverting rules Kex , construction track(Kex , qex , Gex ) alsoneeds take query gap answers account. this, encode queryeats(x, y) ^ Plant(y) ! Pqex (~x) rulesPqRex (x) ^ eats(x, y) ^ Plant(y) ! eatsR (x, y)(21a)PqRex (x) ^ eats(x, y) ^ Plant(y) ! PlantR (y)(21b)add fact PqRex (c) c 2 Gex . query-dependent rules used initialise extension fresh predicates, subsequently makes rulestrack(Kex , qex , Gex ) applicable.query answers gap stem upper bound; consequently, orderrules (21a) (21b) applicable data track(Kex , qex , Gex ) obtainedupper bound materialisation Kex . following section show sufficesinclude facts c-chase Kex order ensure computed subsetcontain necessary facts rules.6.2 Subset Definition Propertiesready formally define datalog knowledge base used subset computationwell corresponding relevant subset.Definition 6.1. Let G set possible answers q, let Rel fresh unary predicatelet dr fresh constant unique r K [ Rq . Furthermore, predicateP K [ Rq , let P R fresh predicate arity P and, atom = P (~t),let R denote P R (~t). normalised rule r 2 K [ Rq , let move(r) followingconjunction atoms:P?R r form (2);R x, ~z1 )1 (~R x)1 (~Then,r form (3);^ ^R x)(~r form (4).(r) following set rules:(r) = {move(r) ^ body(r) ! Rel(dr )} [ {move(r) ^ body(r) !Rk|kbody(r)}.tracking knowledge base track(K, q, G) smallest knowledge base containing(i) facts c-chase K;(ii) rules r2K[Rq (r);336fiPAGOdA: Pay-As-You-Go Query Answering Using Datalog Reasoner(iii) fact PqR (~a) ~a 2 G;(iv) fact P?R q 6= ?.subset K relevant q G, denoted Kq,G , smallest knowledge basecontainingrule r 2 K track(K, q, G) |= Rel(dr );fact 2 DK track(K, q, G) |= R .brevity, write Kq particular case G set gap answers Uq \ Lqdefined Sections 4.3 5.4.}Note K? subset Kq since track(K, ?, G? ) subset track(K, q, Gq ):Definition 6.1, point (i) track(K, ?, G? ) track(K, q, Gq ); furthermore,set rules (ii) track(K, ?, G? ) subset track(K, q, Gq ) sinceK [ R? K [ Rq ; finally, fact P?R , included track(K, ?, G? ) point (iii),also belongs track(K, q, Gq ) point (iv).Example 6.2. Consider running example, Gex = {tiger, lion, rabbit}.subset Kex relevant qex Gex consists rules R2, R4, R5, R6, R7 factsD1, D2, D3, D5, D7, D9, D11.}key properties computed subsets established following theorem.Theorem 6.3. following properties hold:(1) Assume L? = ;. Then, K unsatisfiable K? unsatisfiable.(2) Let q dierent ? let G non-empty set possible answers q w.r.t.K. K satisfiable, ~a 2 cert(q, K) ~a 2 cert(q, Kq,G ) every ~a 2 G.Proof. direction (1) (2) follows directly monotonicity firstorder logic. direction (1) (2) follows completenesshyperresolution following claim, establishes q non-emptyG, Kq,G contains support hyperresolution derivations clause (q, G)K [ Rq{}q = ?;(q, G) ={Pq (~a) | ~a 2 G} otherwise.Claim (|) = ( , ) derivation 2 (q, G) K [ Rq , support() Kq,G .show direction (1), assume K unsatisfiable. Theorem 5.10,Theorem 5.14 (13), U ? 6= ; thus G? 6= ;. exists hyperresolutionderivation 1 K. Since (?, G? ) = {}, know support(1 ) K?(|). K? unsatisfiable. show direction (2), assume ~a 2 G~a 2 cert(q, K). exists hyperresolution 2 Pq (~a) K [ Rq . Similarly,(|), know support(2 ) Kq,G hence ~a 2 cert(q, Kq,G ).337fiZhou, Cuenca Grau, Nenov, Kaminski, & Horrocksnext show inductively statement (|) follow. Let = ( , )derivation clause (q, G) K [ Rq , let H = split(K). alreadyestablished (see proof Theorem 5.10) c-ChaseK model H. Since ChaseHuniversal model H exists homomorphism ChaseH c-ChaseK . showfollowing properties inductively every node v .a. track(K, q, G) |= R , atom (v);b. track(K, q, G) |= Rel(dr ), sk(r) main premise used obtain parent u v.proceed induction distance v root .Base case: base case v root . Property (b) follows vacuouslysince v parent .q = ?, derivation empty clause (v) empty disjunctionand. property (a) also follows vacuously.Otherwise, (v) = Pq (~a) ~a 2 G. definition track(K, q, G) (point(iii)) ( (v))R 2 track(K, q, G) hence property (a) also holds.Inductive step: Assuming properties (a) (b) hold node u, showalso hold children v1 , . . . , vn u. Let r rule K sk(r)main premise relevant hyperresolution step MGU , i.e., (u) = 1 _ __ 1 _ _ n hyperresolvent sk(r) = 1 _ _ n _ 1 _ _(vi ) = _ 1 n, using . easy observation compositionsubstitution homomorphism used later rest proof.() = ( ) arbitrary function-free atom .(22)Lemma 5.4 Section 5.1 2 ChaseH 1 n. Sincehomomorphism ChaseH c-ChaseK ( ) 2 c-ChaseK(22), ( ) 2 c-ChaseK 1 n. next show track(K, q, G) |= move(r) .= 0, move(r) = P?R . distinguish two cases.q 6= ?, P?R 2 track(K, q, G) point (iv);q = ?, ?s 2 c-ChaseK hence PqR 2 track(K, q, G) point (iii).Otherwise, induction hypothesis, also track(K, q, G) |= ((22), track(K, q, G) |= jR ( ) 1 j m.j)RTherefore track(K, q, G) |= move(r) . body rules (r) satisfiedsubstitution hence track(K, q, G) |= Rel(dr ), track(K, q, G) |= iR ( )1 n. (22), track(K, q, G) |= ( iR ) 1 n. addition,induction hypothesis, track(K, q, G) |= R, 1 n. Hence, shown(a), (b) hold child vi u.remains shown (a) (b) imply (|). Indeed, take 2 support().338fiPAGOdA: Pay-As-You-Go Query Answering Using Datalog Reasonerfact K, leaf node ; hence, property (a)track(K, q, G) |= R . then, since fact DK definition homomorphism ensures R = R . definition Kq,G implies 2 Kq,G .rule K, Property (b) track(K, q, G) |= Rel(d ). Again,definition Kq,G ensures 2 Kq,G .completes proof theorem.Note Claim (|) proof theorem also establishes important propertycomputed subsets, namely proof-preserving; is, support everyhyperresolution proof relevant gap answer original knowledge base K alsocontained computed subset. two key implications. First, every justification(i.e., minimal subset K entailing gap answer) contained also subset;way, subsets preserve formulas K relevant gap answers,formulas disregarded seen irrelevant. Second, fully-fledged reasonerwhose underpinning calculus cast framework resolution ablecompute subset derivations gap answers K. Consequently,practice reasonable expect fully-fledged reasoner uniformly displaybetter performance computed subsets Kan expectation borneexperiments.conclude section example illustrating dataset track(K, q, G)(point 1 Definition 6.1) obtained c-ChaseK materialisation underpinningupper bound Section 5.2rather c-ChasefK Section 5.3.Example 6.4. Consider query q(x) = E(x) knowledge base K consistingfollowing rules facts.A(x) ! B(x) _ D(x)D(x) ! E(x)B(x) ! E(x)A(a)Let f function always choosing B(a) D(a), c-ChasefK = {A(a), B(a), E(a)}constant answer q(x) gap lower upper bound. Supposedefine track(K, q, G) Definition 6.1 replacing facts point (i)c-ChasefK . Since D(a) hold c-ChasefK corresponding subsetcontain rule D(x) ! E(x), essential derive E(a).}6.3 Optimisations Datalog Encodingconclude section, present two optimisations datalog encoding Definition6.1 exploit system PAGOdA.first optimisation aims reducing size computed subsets. Recallkey step construction tracking knowledge base track(K, q, G) invertrules K capture hyperresolution proofs backwards fashion. Considerinversion (17) rule (R5) running example. eect inversion capture applicability hyperresolution: facts Mammal(rabbit), HerbivoreR (rabbit)MeatEaterR (rabbit) hold, include rule (R5) subset since may proof339fiZhou, Cuenca Grau, Nenov, Kaminski, & HorrocksK involving step ground clause Herbivore(rabbit) _ MeatEater(rabbit) _obtained resolving (R5) Mammal(rabbit) _ .Note, however, step redundant Herbivore(rabbit) already contained K, case (R5) may needed relevant subset. captureobservation distinguishing tracking knowledge base facts c-chaseK already present original dataset DK . encode impliedfacts instantiating fresh predicates P predicate P K. running example,fact MeatEaterI (rabbit) tracking knowledge base establishes MeatEater(rabbit)present original data. use atoms predicates guardsinverted rules, e.g. rule (17) would written follows:HerbivoreI (x) ^ MeatEaterI (x) ^ HerbivoreR (x)^ MeatEaterR (x) ^ Mammal(x) ! MammalR (x)Formally, Definition 6.1 optimised given next.Definition 6.5. Let K, q, G predicates P R Definition 6.1. predicateP , let P fresh predicate arity P . redefine move(r)rule r following conjunction atoms:P?R r form (2);x, ~z1 )1 (~x)1 (~^R x, ~z1 )1 (~^ ^x)(~r form (3);^R x)1 (~^ ^R x)(~r form (4).Then, (r) Definition 6.1, track(K, q, G) also Definition 6.1, extendedaddition fact P (~a) fact P (~a) c-ChaseK DK . }easy see optimisation aect correctness Theorem 6.3:disjunction atoms derived via hyperresolution, one atoms alreadypresent data, disjunction subsumed dispensed with.second optimisation used obtain succinct encoding datalogreasoners support equality reasoning natively (such RDFox). already mentioned,built-in semantics equality predicate axiomatised within datalog. However,axiomatisation lead performance issues, scalability improved nativetreatment equality equal objects merged single representativewhole equivalence class.axiomatisation equality significant eect tracking encoding.example, replacement rules r form (EQ4) inverted following rules(r) predicate P :P R (x1 , . . . , xi1 , y, xi+1 , . . . , xn )P R (x1 , . . . , xi1 , y, xi+1 , . . . , xn )^ P (x1 , . . . , xn ) ^ xi ! P R (x1 , . . . , xn )^ P (x1 , . . . , xn ) ^ xi ! R (xi , y)(23)(24)(23) tautology dispensed with, rule (24) required.datalog reasoner native support equality, need include340fiPAGOdA: Pay-As-You-Go Query Answering Using Datalog Reasonertracking knowledge base inversion equality axioms (EQ1), (EQ2) (EQ3),need include rules (24) order ensure computed subset requiredproperties. result succinct encoding materialised efficiently.Example 6.6. Consider knowledge base K consists facts {R(a1 , b), R(a2 , b), A(a1 )}following rules.A(x) ! B(x) _ C(x)R(x1 , y) ^ R(x2 , y) ! x1 x2(25)(26)B(x) ! D(x)C(x) ! D(x)(27)(28)Let q = D(x), gap G lower upper bounds q {a1 , a2 }. easysee rule (26) essential derive q(a2 ). ensure rule fragmentKq,G , track a1 a2 using instance rule (24).}6.4 Comparison Magic Setsidea inverting rules recording relevant information heavily exploitedLogic Programming. particular, magic set transformation (Bancilhon, Maier, Sagiv,& Ullman, 1986) technique that, given program query, optimises materialisation process derive facts relevant query. Similarlytracking encoding, magic sets technique uses auxiliary predicates, called magic predicates, identify relevant facts. technique originally developed datalog,subsequently extended handle also negation failure (Beeri, Naqvi, Ramakrishnan, Shmueli, & Tsur, 1987; Kemp, Srivastava, & Stuckey, 1995) disjunctions (Alviano,Faber, Greco, & Leone, 2012a).contrast magic sets, goal transformation reduce sizematerialisation, rather compute relevant fragment knowledge base potentiallygiven expressive (even undecidable) language, reduce computationdatalog reasoning. sense, technique orthogonal magic sets. Indeed,benefits technique relevant knowledge bases containing existentiallyquantified and/or disjunctive rules (if K datalog, query would fullyanswered lower bound).Furthermore, worth noticing way invert (datalog) rules also dierentmagic sets yields precise tracking. assumptiontracking starts already computed materialisation (see Point (i) Definition6.1). instance, given already adorned rule A(x) ^ B(x) ! C(x), magic sets wouldproduce following rules deriving magic predicates B B:C (x) ! (x)C (x) ^ A(x) ! B (x)rules used derive fact (a) C (a), even A(a) cannot usedderive C(a) aforementioned rule applicable (e.g., B(a) holdC(a) derived using rules). transformation, contrast, would yieldrestrictive rulesC R (x) ^ A(x) ^ B(x) ! AR (x)C R (x) ^ A(x) ^ B(x) ! B R (x)applicable A(a) B(a) hold materialisation.341fiZhou, Cuenca Grau, Nenov, Kaminski, & Horrocks7. Summarisation Analysis Answer Dependenciessection, let q input query dierent unsatisfiability query ?.K? Kq computed, still need check, using fully-fledged reasoner,satisfiability K? well whether Kq entails candidate answer Gq .computationally expensive subsets large complex, manycandidate answers verify. therefore exploit summarisation techniques (Dolby et al.,2007) eort reduce number candidate answers.idea behind summarisation shrink data knowledge base mergingconstants instantiate unary predicates. Since summarisation equivalentextending knowledge base equality assertions constants, summaryknowledge base entails original one monotonicity first-order logic. Consequently, exploit summarisation follows:1. satisfiability K remains undetermined, construct summary K?check satisfiability. satisfiable, K? (and thus also K) also satisfiable.2. Construct summary Kq use fully-fledged reasoner check whethersummary ~a entailed certain answer q summary Kq ,discarding answers entailed.Formally, summarisation defined follows.Definition 7.1. type set unary predicates; given constant c K, say= {A | A(c) 2 K} type c. type , let fresh constantuniquely associated . summary function K substitution mappingconstant c K , type c. Finally, summary K K . }following proposition shows summarisation exploited detect spuriousanswers setting. Since summarisation significantly reduce data size practice,relevant subsets K? Kq already significantly smaller K, checkingsatisfiability K? gap answer Kq becomes feasible many cases, eventhough implies resorting fully-fledged reasoner.Proposition 7.2. Let summary function K. Satisfiability K? impliesfollowing: (i) K satisfiable; (ii) cert(q, K) cert(q , Kq ) every CQ q.Example 7.3. case running example, constants tiger liontype {Mammal}, therefore mapped fresh constant, say tMammal , uniquelyassociated {Mammal}. Since tMammal certain answer qex w.r.t. summaryKex , determine tiger lion spurious answers.}summarisation succeed pruning candidate answers G, trylast step reduce calls fully-fledged reasoner exploiting dependenciesremaining candidate answers that, answer ~a depends answer ~c,~a spurious, ~c.Consider two tuples ~c d~ constants Gq . Suppose find endomor~ determine (by calling fully-fledgedphism dataset DK ~c = d.~reasoner) spurious answer, must ~c; result, longer needcall fully-fledged reasoner verify ~c. endomorphisms defined next.342fiPAGOdA: Pay-As-You-Go Query Answering Using Datalog ReasonerDefinition 7.4. Let ~c = (c1 , . . . , cn ) d~ = (d1 , . . . , dn ) n-tuples constants K.endomorphism ~c d~ K mapping constants constants(i) ci = di 1 n; (ii) P (t1 , . . . , tm ) 2 DK fact P (t1 , . . . , tm ) 2 DK ;(iii) r 2 K r 2 K .}relevant property endomorphisms given following proposition.Proposition 7.5. Let ~c, d~ possible answers q let endomorphism ~cd~ K. Then, ~c 2 cert(q, K) implies d~ 2 cert(q, K).Proof. Since ~c 2 cert(q, K), know K |= q(~c). hyperresolution derivation= (T, ) Pq (~c) K [ Rq . easy check (T,) hyperresolution~ K [ Rq . Then, K |= q(d)~ hence d~ 2 cert(q, K).derivation Pq (d)exploit idea compute dependency graph candidate answer tuples~ whenever endomorphism DK exists mapping ~c d.~ Sincenodes edge (~c, d)computing endomorphisms hard resort practice sound greedy algorithmapproximate dependency graph, describe Section 8.8. Implementation: PAGOdA Systemimplemented approach system called PAGOdA, written Javaavailable academic license. system integrates datalog reasonerRDFox (Motik et al., 2014) fully-fledged OWL 2 reasoner HermiT (Glimm et al.,2014) black-boxes, also exploit combined approach ELHOr? (see Section4.2) implemented KARMA (Stefanoni et al., 2014).PAGOdA accepts input arbitrary OWL 2 DL ontologies, datasets turtle format(PrudHommeaux & Carothers, 2014) CQs SPARQL. Queries interpretedground certain answer semantics. former case, PAGOdA soundcomplete. latter case, however, PAGOdA limited capabilities HermiT,check entailment ground DL concept queries; hence, PAGOdAguarantee completeness lower upper bounds match, querytransformed DL concept query via internalisation (see Section 2.3). Otherwise,PAGOdA returns sound (but possibly incomplete) set answers, along boundincompleteness computed answer set.architecture PAGOdA depicted Figure 4. box Figure 4 representscomponent PAGOdA, indicates external systems exploited withincomponent. could, principle, use materialisation-based datalog reasonersupports CQ evaluation incremental addition facts, fully-fledged OWL2 DL reasoner supports fact entailment.PAGOdA uses four instances RDFox (one lower bound, c-chase, cchasef subset extractor components) two instances HermiT (onesummary filter dependency graph components).process fully answering query divided several steps. Here, distinguish query independent steps query dependent ones. see Figure4, loading ontology materialisation steps query independent. Therefore,343fiZhou, Cuenca Grau, Nenov, Kaminski, & Horrockscert(q, [ D)heuristic plannerG0 GqHermiTq, Gqsummary filterHermiTq, GqendomorphismcheckerFull reasoningKqLqsubset extractortracking encoderExtracting subsetsRDFoxtrack(, q, Gq ), q, GqGqLqFComputing query boundssoundAnswers(q, [ D)certU3 (q, [ D)M2Lqlower storeKARMARDFoxcertU2 (q, [ D)M3UM2Uqqc-chasef*c-chaseRDFoxRDFoxMaterialisationshiftLoading ontology & dataprofile checkernormaliserHermiT clausifierFigure 4: architecture PAGOdAcounted pre-processing steps. Computing query bounds, extracting subsetfull reasoning query dependent, called query processing steps.next describe component, following process flow PAGOdA.8.1 Loading Ontology DataPAGOdA uses OWL API parse input ontology O. dataset givenseparately turtle format. normaliser computes set rules correspondingaxioms ontology. PAGOdAs normaliser extension HermiTs clausificationcomponent (Glimm et al., 2014), transforms axioms so-called DL-clauses (Motiket al., 2009). dataset loaded directly (the four instances of) RDFox.normalisation, ontology checked determine inside OWL 2 RLELHOr? . input ontology OWL 2 RL (resp. ELHOr? ), RDFox (resp.KARMA) already sound complete, cases PAGOdA simply processes344fiPAGOdA: Pay-As-You-Go Query Answering Using Datalog Reasonerontology, dataset queries using relevant component. Otherwise, PAGOdA usesdedicated program shifting component enrich deterministic part ontologyadditional information disjunctive rules (see Section 4.1), resulting set rules .8.2 Materialisationthree components involved step, namely lower bound, c-chase cchasef . takes input D, computes materialisation (shownFigure 4 ellipses). lower bound component performs Steps 1 2 Section 4.3order compute aggregated lower bound M2L . c-chase c-chasef componentscompute M2U M3U upper bound materialisations described Section 5.4 usingdedicated implementation c-chase algorithm. chase sequence stored RDFox,applicability existential disjunctive rules determined posing SPARQLqueries RDFox. applying disjunctive rule (while computing M3U ), PAGOdAuses choice function select one disjuncts. discussed Section 5.4, choicefunction try select disjuncts (eventually) lead contradiction.end, PAGOdA implements following heuristics.construct standard dependency graph containing edge predicate PQ rule P occurs body Q head. Then, computepreference ordering predicates occurring disjunction accordingdistance ? dependency graph, preferring furthest ?.exploit result materialising using shifting enriched rules (seeSection 4.1). fact form P (~a) obtained materialisation, P (~a)follows knowledge base. Hence, obtained P (~a), tryavoid choosing P (~a) disjunct P (~a) _ chase computation.M2L contains contradiction, input ontology dataset unsatisfiable,PAGOdA reports terminates. ?s derived M3U , computationaborted M3U longer used. M2U contains ?s , PAGOdA checkssatisfiability [ D; eect, computes cert(?, [ D). answer querynon-empty, input ontology dataset unsatisfiable, PAGOdA reportsterminates; otherwise input ontology dataset satisfiable, PAGOdAable answer queries.8.3 Computing Query BoundsGiven query q, PAGOdA uses M2L lower bound materialisation compute lowerbound answer Lq . order exploits KARMAs implementation filtrationprocedure (algorithm soundAnswers Section 4.2), clarity step shown separately (as circle F it) Figure 4. ?s derived computingM3U materialisation, U q = cert(q, M2U ) \ cert(q, M3U ); otherwise U q = cert(q, M2U ). eithercase U q computed directly using RDFox answer q w.r.t. relevant materialisation.Extracting Subsets tracking encoder component implements datalog encodingbased Definition 6.1 optimisations described Section 6.3. resultingdatalog knowledge base added rules data c-chase component,345fiZhou, Cuenca Grau, Nenov, Kaminski, & HorrocksRDFox used extend c-chase materialisation accordingly. freshly derived facts(over tracking predicates introduced tracking encoder) passedsubset extractor component, uses facts identify facts rulesrelevant checking gap answers, computes intersection relevant factsinput dataset querying instance RDFox containing only.8.4 Full ReasoningPAGOdA uses HermiT verify gap answers Gq = U q \ Lq . HermiT acceptsqueries given either facts DL concepts, implemented standard rolling-uptechnique transform internalisable CQs. summary filter component, PAGOdA usesHermiT filter gap answers entailed summary Kq (see Section 7).remaining gap answers G0 Gq passed endomorphism checker,exploits greedy algorithm compute incomplete dependency graph answersG0 . graph used heuristic planner optimise order answersG0 checked using HermiT (see Section 7). Verified answers G0 combinedlower bound Lq give cert(q, [ D).implementation summarisation straightforward: PAGOdA essentially mergesconstants (explicit) types data.12345678910123456789101112Input: knowledge base K = K [ DK , two tuples (a1 , . . . , ), (b1 , . . . , bn ).Output: return true endomorphism (a1 , . . . , ) (b1 , . . . , bn ) K found,otherwise, false.= ;;foreach 2 [1..n]ai locally embeddable bi K return false;else (ai ) = bi ;endforeach 2 [1..n]check(ai , bi ) return false;endK 6= K return false;else return true;Subroutine check(a, b)Oa := {c | P (ai , c) 2 DK }, Ia := {c | P (c, ai ) 2 DK };Ob := {d | P (bi , d) 2 DK }, Ib := {d | P (d, bi ) 2 DK };foreach 2 {O, I} c 2 Sa:= {d 2 Sb | c locally embedded d};empty return false;defined c(c) := similar constant c D;check(c, d) return false;endelse (c) 62 return false;endAlgorithm 1: Greedy endomorphism checker.346fiPAGOdA: Pay-As-You-Go Query Answering Using Datalog Reasonernext describe greedy algorithm implemented PAGOdA checking answerdependencies (see Algorithm 1). Given tuples (a1 , . . . , ) (b1 , . . . , bn ), algorithmreturns True able find endomorphism, False otherwise. algorithmconsiders constant ai tries map bi locally, senseimmediate neighbourhoods ai bi considered stage. Formally,captured following notion local embedding.Definition 8.1. Given K constant c let Mc multiset containing occurrencefact A(c) 2 DK , occurrence P binary fact P (c, c0 ) 2 DK ,occurrence P binary fact P (c0 , c) 2 DK .Given constants c K, say c locally embeddable predicateMc occurs (with cardinality) Md .}check(a, b) subroutine implements greedy search looking immediate neighbours b. Specifically, subroutine considers neighbour c picksneighbour b c locally embedded d. several choicesavailable, algorithm heuristically chooses one according Jaccard similaritymultisets Mc Md .6 algorithm terminates success managescompute mapping defined constants reachable {a1 , . . . , }K. immediate see computed endomorphism ~a ~b K; thus,algorithm sound. algorithm works polynomial time choices madeconstruction never revisited local embeddability checked efficiently.9. Related WorkConjunctive query answering ontology-enriched datasets received great dealattention recent years. computational complexity thoroughly investigatedwide range KR languages number practicable algorithms proposedliterature implemented reasoning systems.9.1 Computational Complexity CQ Answeringdecision problem associated CQ answering conjunctive query entailment (CQE),namely decide whether K |= q(~a) given input CQ q, possible answer ~a,knowledge base K expressed (fixed) language L. problem well-knownundecidable general, even q restricted atomic L languageexistential rules (Dantsin et al., 2001).CQE knowledge bases stemming OWL DL ontologies decidableassumption query mention transitive relations (Rudolph & Glimm, 2010).Decidability CQE unrestricted OWL DL OWL 2 DL ontologies CQs remainsopen problem. Even cases CQE decidable, typically highcomputational complexity. CQE 2-ExpTime-complete expressive DLs SHIQSHOQ (Glimm et al., 2008; Eiter, Lutz, Ortiz, & Simkus, 2009). Hardness results6. Jaccard similarity multisets 0 defined |M \ 0 |/|M [ 0 |, |M \ 0 | countsminimum number occurrences common element 0 , whereas |M [ 0 | countssum occurrences elements 0 .347fiZhou, Cuenca Grau, Nenov, Kaminski, & Horrocks2-ExpTime obtained already ALCI (Lutz, 2008) well Horn-SROIQ,underpins Horn fragment OWL 2 DL (Ortiz, Rudolph, & Simkus, 2011). CQEALC SHQ, involve inverse roles, ExpTime-complete (Lutz, 2008).Single exponential time results also obtained Horn DLs disallowing complex roleinclusion axioms: CQE ExpTime-complete Horn-SHOIQ, underpins Hornfragment OWL DL (Ortiz et al., 2011).Given high complexity CQE, recently increasing interestlightweight DLs CQE computationally easier. lightweight DLsincorporated OWL 2 standard profiles (Motik et al., 2012). CQE OWL2 EL profile PSpace-complete (Stefanoni et al., 2014). Furthermore, complexityCQE drops NP complex role inclusions (with exception transitivityreflexivity) disallowed OWL 2 EL (Stefanoni & Motik, 2015). latter complexityrather benign since CQE databases already NP-hard. Finally, CQE OWL2 QL profile also NP-complete (Calvanese et al., 2007). Regarding data complexity,CQE coNP-complete non-Horn DLs, ALE (Schaerf, 1993). contrast,data complexity PTime-complete Horn DLs encode recursion, HornSROIQ OWL 2 EL (Ortiz et al., 2011; Stefanoni et al., 2014). Finally, data complexityknown AC0 OWL 2 QL profile (Calvanese et al., 2007).complexity CQE also well understood rule-based KR languages. plaindatalog, ExpTime-complete combined complexity PTime-complete w.r.t. datacomplexity. disjunctive datalog, coNExpTime-complete combined complexitycoNP-complete w.r.t. data complexity. Datalog refers family decidable KRlanguages based existential rules (Cal, Gottlob, & Lukasiewicz, 2012). includesguarded (Cal et al., 2013), sticky (Cal, Gottlob, & Pieris, 2011), acyclic (Cuenca Grauet al., 2013) datalog . extension datalog languages disjunctive rulesrecently studied (Alviano et al., 2012b; Bourhis et al., 2013).Finally, refer ground query entailment (GCQE) problem checking whethertuple ~a ground answer q(~x) = 9~y '(~x, ~y ) w.r.t. K. KR languages allowexistentially quantified rules, restriction ground answers typically makes CQE easier:definition ground answers means GCQE trivially reduced satisfiabilitychecking. Consequently, GCQE decidable OWL 2 DL.9.2 Practical Query Answering Approacheso-the-shelf DL reasoners, Pellet (Sirin et al., 2007) HermiT (Glimmet al., 2014) provide support query answering. Pellet supports SPARQL conjunctivequeries also implements rolling-up technique. contrast, HermiT provideSPARQL API supports CQs form (complex) DL concepts. Raceramong first DL reasoners implement optimise CQ answering groundsemantics (Haarslev, Hidde, Moller, & Wessel, 2012). Finally, also intensivework optimising query answering DL systems, including filter-and-refine techniques(Wandelt et al., 2010), ordering strategies query atoms (Kollia & Glimm, 2013), datasummarisation (Dolby et al., 2009). Optimising CQ answering DL reasoners complementary approach, use optimised DL reasoner could significantlyimprove performance PAGOdA queries require full reasoning.348fiPAGOdA: Pay-As-You-Go Query Answering Using Datalog ReasonerRDF triple stores typically implement materialisation-based (a.k.a. forward chaining)reasoning algorithms, answer queries evaluating resulting materialisation. Jena (McBride, 2001) Sesame (Broekstra, Kampman, & van Harmelen, 2002)among first systems provide support RDF-Schema. Modern triple storesOWLim (Bishop et al., 2011), Oracles native inference engine (Wu et al., 2008),provide extended suppport ontologies RL profile. Additionally, RDFox (Motiket al., 2014) supports arbitrary datalog unary binary predicates. Finally, ASPengines DLV (Leone, Pfeifer, Faber, Eiter, Gottlob, Perri, & Scarcello, 2006) implement sound complete reasoning (extensions of) disjunctive datalog. Although triplestores exhibit appealing scalability, support restricted ontology languages;however, DL reasoners, improving scalability triple stores complementaryapproach, advances area directly exploited PAGOdA.technique CQ answering lightweight DLs receiving increasing attentionso-called combined approach (Lutz et al., 2009; Stefanoni et al., 2013; Kontchakov,Lutz, Toman, Wolter, & Zakharyaschev, 2011). combined approach datasetfirst augmented new facts query-independent way build (in polynomial time)model ontology. model exploited query answering two equivalentways. approach Lutz et al. (2009) Kontchakov et al. (2011) query firstrewritten evaluated constructed model. Alternatively, workStefanoni et al. (2013) Lutz et al. (2013) query first evaluated modelunsound answers eliminated means polynomial time filtration process.Combined approaches applied logics EL family (Lutz et al., 2009;Stefanoni et al., 2013) well DL-Lite (Kontchakov et al., 2011), PAGOdA,use implementation (Stefanoni et al., 2013) compute aggregated lower bound.CQ answering Horn ontologies often realised means query rewriting techniques. rewriting query q w.r.t. ontology another query q 0 capturesinformation necessary answer q arbitrary dataset. Unions CQsdatalog common target languages query rewriting. Query rewriting enables reuseoptimised data management system: UCQs answered using standard relationaldatabases, whereas datalog queries evaluated using triple store. Query rewritingsuccessfully applied OWL 2 QL ontologies, rewritability UCQsguaranteed. Example systems include QuOnto (Acciarri, Calvanese, De Giacomo, Lembo,Lenzerini, Palmieri, & Rosati, 2005), Mastro (Calvanese, De Giacomo, Lembo, Lenzerini,Poggi, Rodriguez-Muro, Rosati, Ruzzi, & Savo, 2011), Rapid (Chortaras, Trivela, & Stamou, 2011), Prexto (Rosati, 2012), Ontop (Bagosi, Calvanese, Hardi, Komla-Ebri,Lanti, Rezk, Rodriguez-Muro, Slusnys, & Xiao, 2014). systemssuccessful large scale applications; however, applicable OWL 2 QLsize rewriting exponential size ontology. Datalog-based queryrewriting implemented systems REQUIEM (Perez-Urbina et al., 2010),supports extension ELHOr? inverse roles. introduction inverseroles, however, leads significant jump complexity: query answering ELHOr?NP-complete (and tractable atomic queries), whereas becomes ExpTime-completeinverse roles introduced (furthermore, ExpTime-hardness holds already unsatisfiability checking atomic queries). practice, restricting ELHOr?allows us compute datalog program linear size straightforward way Skolemis349fiZhou, Cuenca Grau, Nenov, Kaminski, & Horrocksing existentially quantified variables constants. Furthermore, datalog materialisationquery independent queries without existentially quantified variables answereddirectly materialisation, complex queries answered using filtration.Finally, similarly PAGOdA, system Hydrowl (Stoilos, 2014a) combines OWL2 RL reasoner query rewriting system fully-fledged DL reasoner orderanswer conjunctive queries OWL 2 knowledge base. techniques Hydrowl are,however, rather dierent PAGOdA. Hydrowl uses two dierent query answeringstrategies. first one based repairing (Stoilos, 2014b) query rewriting,applicable ontologies suitable repair exists. second strategy exploitsquery base: set atomic queries Hydrowl computes pre-processing phase,fully answered using triple store given ontology arbitrarydataset. answering query q, Hydrowl checks q covered query base (Stoilos& Stamou, 2014); is, q completely evaluated using OWL 2 RL reasoner;otherwise, fully-fledged reasoner used answer q. However, computationquery base appear correct general,7 believe accountsapparent incompleteness Hydrowl tests (see Section 10.3.1).9.3 Approximate Reasoningidea transforming ontology, data and/or query obtain lower upper boundanswers already explored previous work. Screech system (Tserendorj et al.,2008) uses KAON2 (Hustadt, Motik, & Sattler, 2007) transform SHIQ ontology(exponential size) disjunctive datalog program way ground answersqueries preserved. Subsequently, Screech exploit (unsound incomplete) techniquestransform disjunctive datalog plain datalog. way, Screech computesapproximation answer. TrOWL (Thomas et al., 2010) exploits approximationtechniques transform OWL 2 ontology ontology QL profile (Pan &Thomas, 2007). approximation first computes closure input ontologyentailment OWL 2 QL axioms, disregards axioms outside OWL 2 QL.Related approximations OWL 2 QL also proposed, e.g., Wandelt et al.(2010) Console et al. (2014). Efficient approximation strategies OWL 2 ontologiescomplementary approach, exploited PAGOdA orderrefine lower upper bound query answers.10. Evaluationevaluated query answering system PAGOdA range realistic benchmark ontologies, datasets queries, compared performance stateof-the-art query answering systems. test data systems used comparisonintroduced Sections 10.1 10.2, respectively. results discussed Section10.3. Experiments conducted 32 core 2.60GHz Intel Xeon E5-2670 250GBRAM, running Fedora 20. test ontologies, queries, results available online.87. Stoilos (2014a) mentions limitation automatically extracting [the atomic queries].8. http://www.cs.ox.ac.uk/isg/tools/PAGOdA/2015/jair/350fiPAGOdA: Pay-As-You-Go Query Answering Using Datalog ReasonerLUBM(n)UOBM(n)FLYNPDDBPedia+ChEMBLReactomeUniprot]axioms9318614,4477711,7162,593559442]rules13323418,0137781,7442,960575459]9-rules15238396128114261320]_-rules060145732343]factsn 1052.6n 1058 1033.8 1062.9 1072.9 1081.2 1071.2 108Table 3: Statistics test datasets10.1 Test Ontologies QueriesTable 3 summarises test data. first two columns table indicate totalnumber DL axioms test ontology well total number rulesnormalisation. interested ontologies captured OWL 2 RLhence cannot fully processed RDFox; thus, number rules containing existentialquantification disjunction especially relevant given third fourthcolumns table, respectively. Finally, rightmost column lists number datafacts dataset.LUBM UOBM widely-used reasoning benchmarks (Guo, Pan, & Heflin, 2005;Ma, Yang, Qiu, Xie, Pan, & Liu, 2006). ontology axioms benchmarksmanually created considered fixed, whereas data synthetically generatedaccording parameter n determines size. LUBM UOBM come 14 15standard queries, respectively. make tests LUBM challenging, extendedbenchmark 10 additional queries datalog lower-bound answersguaranteed complete (as case standard queries).FLY realistic ontology describes anatomy Drosophilacurrently integrated Virtual Fly Brain tool.9 Although data rather smallcompared test cases (about 8, 000 facts), ontology rich existentiallyquantified rules, makes query answering especially challenging. tested 6 realisticqueries provided developers ontology.NPD FactPages ontology describing petroleum activities Norwegiancontinental shelf. ontology comes realistic dataset containing 3.8 million facts.Unfortunately, NPD realistic queries tested atomic queriessignature ontology.DBPedia contains information Wikipedia entries. Although dataset ratherlarge, ontology axioms simple captured OWL 2 RL. providechallenging test, used ontology matching system LogMap (JimenezRuiz & Cuenca Grau, 2011) extend DBPedia tourism ontology containing9. http://www.virtualflybrain.org/site/vfb site/overview.htm351fiZhou, Cuenca Grau, Nenov, Kaminski, & Horrocksexistential disjunctive rules. case NPD example test queries,focused evaluation atomic queries.ChEMBL, Reactome, Uniprot realistic ontologies made publicly available European Bioinformatics Institute (EBI) linked data platform.10ontologies especially interesting testing purposes. one hand,ontology axioms data realistic used number applications;hand, ontologies rich existentially quantified disjunctive rules,datasets extremely large. Furthermore, EBI website provides numberexample queries ontologies. order test scalability datasetswell compare PAGOdA systems implemented data sampling algorithmbased random walks (Leskovec & Faloutsos, 2006) computed subsets dataincreasing size. used evaluation example queries correspond CQswell atomic queries relevant signature.10.2 Comparison Systemscompared PAGOdA four ontology reasoners: HermiT (v.1.3.8), Pellet (v.2.3.1),TrOWL-BGP (v.1.2), Hydrowl (v.0.2). single exception TrOWL,systems implement sound complete algorithms standard reasoning tasks OWL2 DL ontologies, including ontology consistency checking concept instance retrieval.Additionally, HermiT provide support SPARQL queries.pointed Section 9, many systems answer queriesontologies. However, systems generally designed specific fragmentsOWL 2, incomplete ontologies outside fragments. Although TrOWLalso incomplete OWL 2, included evaluation is,one hand, widely-used system Semantic Web applications and, hand,similar PAGOdA exploits ontology approximation techniques. follows,describe capabilities systems detail.HermiT fully-fledged OWL 2 reasoner based hypertableau calculus (Motiket al., 2009; Glimm et al., 2014). HermiT focuses standard reasoning tasks DLs.provide SPARQL conjunctive query answering API, capableanswering atomic queries unary predicates checking fact entailment.Pellet tableau-based OWL 2 DL reasoner support CQ answering (Sirin et al.,2007). Pellet provides SPARQL API, hence compute set groundanswers arbitrary conjunctive queries expressed SPARQL. Pellet also capablecomputing certain answers internalisable conjunctive queries using rolling-uptechnique (see Section 2.3).TrOWL system based approximated reasoning. accepts input arbitraryOWL 2 DL ontology CQ SPARQL, aims computing ground answersgiven query (Thomas et al., 2010). TrOWL exploits technique approximatesinput ontology OWL 2 QL profile, provide completeness guarantees.10. http://www.ebi.ac.uk/rdf/platform352fiPAGOdA: Pay-As-You-Go Query Answering Using Datalog Reasonercorrect#incomplete#unsound#error#Kmeout#cannot#handle#100%#90%#80%#70%#60%#50%#TrTrPe HyPe HyTrPe HyTrTrPe HyPe HyTrPe HyTrPe HyTrPe HyTrPe HyTrPe Hy40%#30%#20%#10%##1%#ProtUnEMace#10%#BL#1%##DBPeiaChNPD#FactPages#ledUp#rolY_FL1_rolledUp#1#UOBMUOBMledUp#1_rolLUBMLUBM1#0%#Figure 5: Quality answers computed system. four bars ontologyrepresent Trowl, Pellet, HermiT Hydrowl respectively.Hydrowl (Stoilos, 2014a) hybrid reasoning system similar spirit PAGOdA(see Section 9.2 detailed comparison). Hydrowl integrates triple store OWLimHermiT. accepts input arbitrary OWL 2 ontology conjunctive queries rules,computes ground answers query.10.3 Experiments Resultsperformed three dierent experiments. first experiment, comparedPAGOdA mentioned systems, respect qualityanswers (i.e., number correctly answered queries) performance relativePAGOdA. second experiment, evaluated scalability considering datasetsincreasing size. Finally, third experiment, evaluated eectivenessdierent reasoning techniques implemented PAGOdA.10.3.1 Comparison Systemscompared PAGOdA systems test ontologies. usedLUBM(1) UOBM(1) since already rather hard systems. Similarly, used relatively small samples EBI platform ontologies (1% dataChEMBL UniProt, 10% Reactome) processed majoritysystems. test ontology computed ground answers correspondingtest queries, whenever possible used internalisation (see Section 2.3) additionallycompute certain answers. case FLY, test queries yield empty setground answers, case computed certain answers (all FLY queriesinternalised). set timeouts 20 minutes answering individual query, 5hours answering queries given ontology.Figure 5 summarises quality answers computed reasoner. barfigure represents performance particular reasoner w.r.t. given ontology353fiPellet"HermiT"Hydrowl"DBPeTrOWL"ctPages"Zhou, Cuenca Grau, Nenov, Kaminski, & Horrocks1000"100"10""1%"ProtUnEMace"10%"BL"1%""iaChFaNPD"ledUp"rolY_FL1_rolledUp"1"UOBMledUp"1_rolUOBM0"LUBMLUBM1"1"Figure 6: Performance comparison systems. bar depicts total timeanswer test queries relevant ontology comparison PAGOdA.set test queries. use green indicate percentage queries reasonercomputed correct answers, correctness determined majority voting,blue (resp. purple) indicate percentage queries reasonerincomplete (resp. unsound). Red, orange grey indicate, respectively, percentagequeries reasoner reported exception execution, acceptinput query, exceeded timeout. criterion correctness, PAGOdAable correctly compute answers every query test ontology within giventimeouts. Consequently, performance PAGOdA represented figure.Figure 6 summarises performance system relative PAGOdA,case considered queries relevant system yields answer (evencomputed answer unsound and/or incomplete). ideal, choseconsider queries (rather queries relevant systemyields correct answer) (i) resulting time measurement obviously closertime would required correctly answer queries; (ii) correctnessrelative gold standard query answers. ontologyreasoner, corresponding bar shows t2 /t1 (on logarithmic scale), t1 (resp. t2 )total time required PAGOdA (resp. compared system) compute answersqueries consideration; missing bar indicates comparison system failedanswer queries within given timeout. Please note two dierent barsontology comparable may refer dierent sets queries, barneeds considered isolation.draw following conclusions results experiments.TrOWL faster PAGOdA LUBM rolling up, UOBM rollingFLY rolling up, incomplete 7 14 LUBM queries 34 UOBM queries. ChEMBL, TrOWL exceeds timeout performingsatisfiability check. remaining ontologies, PAGOdA efficient spitefact TrOWL incomplete queries, even unsound severalUniProt queries.354fiPAGOdA: Pay-As-You-Go Query Answering Using Datalog ReasonerPellet one robust systems evaluation. Although timesFLY ontology, succeeds computing answers remaining cases.observe, however, cases Pellet significantly slower PAGOdA,sometimes two orders magnitude.HermiT answer queries one distinguished variable, couldevaluate atomic binary queries. see HermiT exceeds timeout manycases. tests HermiT succeeds, significantly slower PAGOdA.Although Hydrowl based theoretically sound complete algorithm,found incomplete tests. also exceeded timeout queriesthree ontologies, ran memory queries another twoontologies, reported exception ChEMBL 1%. remaining cases,significantly slower PAGOdA.10.3.2 Scalability Teststested scalability PAGOdA LUBM, UOBM ontologies EBIlinked data platform. LUBM used datasets increasing size step n =100. UOBM also used increasingly large datasets step n = 100 alsoconsidered smaller step n = 5 hard queries. Finally, case EBIs datasets,implemented data sampling algorithm based random walks computed subsetsdata increasing sizes 1% original dataset 100% steps10%. used test queries described Section 10.1 ontologies;Section 10.3.1, computed ground answers and, whenever possible, used internalisationadditionally compute certain answers. test ontology measured following:Pre-processing time. includes pre-processing steps Section 8 wellsatisfiability checking (i.e., query processing Boolean unsatisfiability query).Query processing time. time perform query processing stepsquery given ontology. organise test queries following threegroups depending techniques exploited PAGOdA compute answers:G1: queries lower upper bounds coincide;G2: queries non-empty gap, summarisation able filterremaining candidate answers;G3: queries fully-fledged reasoner called ontology subsetleast one test datasets.scalability test, set timeout 5 hours answering queries 2.5 hoursindividual query. LUBM UOBM, increased size datasetPAGOdA exceeded timeout; ontologies, PAGOdA able answerqueries within timeout, even largest dataset.Pellet compared system found sound complete testontologies queries, also conducted scalability tests it. scalabilityPellet is, however, limited: already failed LUBM(100), UOBM(5), well ChEMBL355fi3.0#G1(18)"2.5#Thousands)seconds)Thousands)seconds)Zhou, Cuenca Grau, Nenov, Kaminski, & Horrocks2.0#1.5#1.0#Q32"Q34"9"8"7"6"5"4"3"2"0.5#1"0.0#0"1#100#200#300#400#500#600#700#800#1"200"300"400"500"600"700"800"(b) LUBM query processing14"G1(18)"12"Thousands)seconds)Thousands)seconds)(a) LUBM pre-processing100"10"8"6"G2(1)"Q18"2.5"2"1.5"1"4"0.5"2"0"1"100"200"300"400"0"500"0"(c) UOBM pre-processing100"200"300"400"500"(d) UOBM query processingFigure 7: Scalability tests benchmarks10% Uniprot 10%. dataset Pellet managed process least two datasamples Reactome, succeeded samples smaller 40%. caseReactome discussed detail later on.results summarised Figures 7 8. ontology, plot timesize input dataset, query processing distinguish dierent groupsqueries discussed above. PAGOdA behaves relatively uniformly queries G1G2, plot average time per query groups. contrast, PAGOdAsbehaviour queries G3 quite variable, plot time individual query.LUBM(n) shown Figure 7a, pre-processing fast, times appear scale linearly increasing dataset size. LUBM queries belong either G1 G3latter group containing two queries. Figure 7b illustrates average query processingtime queries G1, never exceeds 13 seconds, well timetwo queries G3 (Q32 Q34), reaches 8,000 seconds LUBM(800),accounted HermiT.UOBM(n) shown Figure 7c, pre-processing times significantly higherLUBM, reflecting increased complexity ontology, still appear scale linearlydataset size. LUBM, test queries contained G1,processing times never exceeds 8 seconds UOBM(1) UOBM(500). found onequery G2. Processing times query somewhat longer G1reached 569s UOBM(500). Finally, found one query (Q18) that, due UOBMs356fi12"G1(1896)#10"Seconds(Thousands))seconds)PAGOdA: Pay-As-You-Go Query Answering Using Datalog Reasoner8"6"4"2"0"1%"10%" 20%" 30%" 40%" 50%" 60%" 70%" 80%" 90%" 100%"0.50#0.45#0.40#0.35#0.30#0.25#0.20#0.15#0.10#0.05#0.00#1%# 10%# 20%# 30%# 40%# 50%# 60%# 70%# 80%# 90%# 100%#(a) ChEMBL pre-processingPellet"G1(128)"14"Seconds(Hundreds(seconds(PAGOdA"(b) ChEMBL query processing12"G2(1)"Q65"Pellet_Q65"1000"800"10"8"600"6"400"4"200"2"0"0"10%" 20%"30%"40%"50%" 60%"70%"80%"90%" 100%"10%" 20%" 30%" 40%" 50%" 60%" 70%" 80%" 90%" 100%"(c) Reactome pre-processingUnsa9sable#G1(236)"2.0#Seconds(Thousands)seconds)Satsiable#(d) Reactome query processing1.5#G2(4)"25"20"15"1.0#10"0.5#5"0.0#0"1%# 10%# 20%# 30%# 40%# 50%# 60%# 70%# 80%# 90%# 100%#1%"(e) Uniprot pre-processing10%"20%"30%"40%"(f) Uniprot query processingFigure 8: Scalability tests EBI linked data platformrandomised data generation, dierent groups dierent datasets: UOBM(1),UOBM(10) UOBM(50) G3, HermiT called relevant subsetsfully answer query; UOBM(40) G2, HermiT calledsummary relevant subset; remaining cases shown Figure 7dG1, lower upper bounds coincided. query timed UOBM(50),due time taken HermiT reason relevant subset, showntimes remaining G1 G2 queries UOBM(500).ChEMBL shown Figure 8a, pre-processing times significant manageable,appear scale linearly dataset size. test queries contained G1.357fiZhou, Cuenca Grau, Nenov, Kaminski, & HorrocksTotalL1 + U 1L2 + U 1L2 + U 2L2 + U2|3LUBM(100)3526333333UOBM(1)20441216FLYNPDDBPedia6055547844244244247312471240124112411246ChEMBL1%18961883188318831896Reactome10%130828298128Uniprot1%240204204204236Table 4: ]Queries answered dierent boundsFigure 8b illustrates average processing times queries, less 0.5sdatasets increases smoothly dataset size.Reactome shown Figure 8c, pre-processing times appear scale quitesmoothly. Groups G2 G3 contained one query, remaining queriesbelonging G1. Query processing times shown Figure 8d. Average query processing time queries G1 never exceeded 10 seconds. Average processing times G2queries appeared grow linearly size datasets, average time never exceeded10 seconds. Finally, seen G3 query (Q65) much challenging,could still answered less 900 seconds, even largest dataset.already mentioned, also tested scalability Pellet Reactome, Pelletable process samples size 10%, 20% 30%. pre-processing time Pelletdatasets comparable PAGOdA shown Figure 8c. Average queryprocessing times queries G1 G2 slightly higher PAGOdA.contrast, times query Q65 significantly higher: 445s, 518s 2, 626s Reactome10%, 20% 30%, respectively (see Figure 8d). Processing times Q65 PAGOdA,however, grow smoothly thanks eectiveness subset extraction technique,able keep input fully-fledged reasoner small, even largest datasets.Uniprot contrast cases, Uniprot whole unsatisfiable; samplingtechnique can, however, produce satisfiable subset. Figure 8e illustrates pre-processingtimes. seen, drop abruptly unsatisfiable samples (50% larger);unsatisfiability efficiently detected lower bound. figure showstime detect inconsistency 100% even less 90%;time dominated loading time, I/O performance varies run run. Queryprocessing times considered satisfiable samples (see Figure 8f).queries G3, four G2. observe average times queriesappear scale linearly data size groups.10.3.3 Effectiveness Implemented Techniquesevaluated eectiveness various reasoning techniques implementedPAGOdA comparing numbers test queries fully answered usingrelevant technique.Query bounds Sections 4 5 described dierent techniques computing lowerupper bound query answers. Table 4 illustrates eectiveness bounds358fiPAGOdA: Pay-As-You-Go Query Answering Using Datalog ReasonerFactsRulesLUBM0.5%3.7%UOBM10.4%10.9%Fly7.3%0.9%NPD16.5%18.4%DBPedia9 10 5 %2.4%Reactome5.2%5.3%Uniprot4 10 4 %1.1%Table 5: Size largest subsets given percentage input rules facts.terms number queries bounds coincided test ontologies.table, refer lower bound described Section 4.1 L1 aggregatedlower bound described Section 4.3 L2 . Similarly, refer three upper boundcomputation techniques discussed Section 5.4 U1 , U2 , U3 combined upperbound U2|3 . observe following experiments:basic lower upper bounds suffice answer queries manytest ontologies. particular, L1 U1 matched 26 35 queriesLUBM(100), 442 478 NPD, 240 1247 DBPedia, 1883 1896ChEMBL, 204 240 Uniprot.aggregated lower bound L2 eective case FLY, basicbounds match query. also useful LUBM, yielding matchingbounds 7 queries.refined treatment existential rules described Section 5.2, yieldsupper bound U2 , especially eective UOBM(1) Reactome, manyexistentially quantified rules already satisfied lower bound materialisation.Finally, refined treatment disjunctive rules Section 5.3, yields combined upper bound U2|3 , instrumental obtaining additional matching boundsnon-Horn ontologies. could answer additional 4 queries UOBM(1), 31NPD, 5 DBPedia, 13 ChEMBL, 30 Reactome, 32 Uniprot.Overall, obtained matching bounds queries test ontologies:could answer queries ChEMBL, 1 FLY DBPedia, 2Reactome LUBM(100), 4 UOBM(1) Uniprot, 5 NPD.Subset extraction Table 5 shows, dataset, maximum percentage factsrules included relevant subset test queries non-matchingbounds. observe subset extraction eective cases terms factsrules. Uniprot DBPedia, reduction data size especially dramatic.also interesting observe large reduction number rules FLY,rather complex ontology. Finally, subset extraction least eective NPDUOBM, even cases reduction almost one order magnitudesize ontology dataset.turn attention summarisation dependency analysis. eectivenesstechniques measured number hard calls HermiT requiredfully answer query, call HermiT considered hard knowledge basepassed HermiT summary. first row Table 6 shows number gap359fiZhou, Cuenca Grau, Nenov, Kaminski, & HorrocksL2 + U2|3+ Sum+ DepLUBM26 1426 14112642641UOBM112 14700 1444012642641FLY3443447DBPedia1000NPD32600Reactome1852052037UniProt16800Table 6: number hard calls HermiT fully answer queryanswers query L2 U2|3 bounds match. Without optimisation,would call HermiT number times fully answer query. Row 2(resp. row 3) shows number hard calls HermiT applying summarisation (resp.summarisation plus dependency analysis). mentioned above, respectively 54 queries non-matching bounds NPD UniProt. However,groups, summarisation dependency analysis identical eects queriesgroup, present one representative query ontology.Summarisation already discussed, summarisation enables PAGOdA fully answernumber test queries non-empty gaps. instrumental fully answering onequery UOBM(1), DBPedia Reactome, well 5 queries NPD, 4queries Uniprot. Even cases summarisation suffice fully answerquery, eective reducing size gap. instance, one queriesUOBM(1) obtained 1,470 gap answers, 26 ruled summarisation.Dependency analysis LUBM(100) two queries gap 26 answers14 answers, respectively; cases, answers merged single group,hence single call HermiT sufficed complete computation. Similarly, UOBM(1)single call HermiT sufficient, even though three queries gapinvolved large number candidate answers. FLY, 344 answers remainingverified summarisation, 7 hard calls HermiT required. Finally,case Reactome one query 52 gap answers, dependency analysis reducednumber calls HermiT 37.11. Conclusionspaper, investigated novel pay-as-you-go approach conjunctive queryanswering combines datalog reasoner fully-fledged reasoner. key featureapproach delegates bulk computation datalog reasonerresorts fully-fledged reasoner necessary fully answer query.reasoning techniques proposed general applicablewide range knowledge representation languages. main goal practice, however,realise approach highly scalable robust query answering systemOWL 2 DL ontologies, called PAGOdA. extensive evaluationconfirmed feasibility approach practice, also system PAGOdAsignificantly ourperforms state-of-the art reasoning systems terms robustnessscalability. particular, experiments using ontologies EBI linked dataplatform shown PAGOdA capable fully answering queries highly complexexpressive ontologies realistic datasets containing hundreds millions facts.360fiPAGOdA: Pay-As-You-Go Query Answering Using Datalog ReasonerAcknowledgmentsextended version conference publications (Zhou, Nenov, Cuenca Grau, &Horrocks, 2014; Zhou, Nenov, Grau, & Horrocks, 2013). work supportedRoyal Society Royal Society Research Fellowship, EPSRC projectsScore!, MaSI3 , DBOnto, well EU FP7 project Optique.ReferencesAbiteboul, S., Hull, R., & Vianu, V. (Eds.). (1995). Foundations Databases: LogicalLevel. Addison-Wesley Longman Publishing Co., Inc., Boston, MA, USA.Acciarri, A., Calvanese, D., De Giacomo, G., Lembo, D., Lenzerini, M., Palmieri, M., &Rosati, R. (2005). QuOnto: Querying ontologies. Veloso, M. M., & Kambhampati,S. (Eds.), AAAI 2005, Proceedings Twentieth National Conference Artificial Intelligence Seventeenth Innovative Applications Artificial IntelligenceConference, July 9-13, 2005, Pittsburgh, Pennsylvania, USA, pp. 16701671. AAAIPress / MIT Press.Afrati, F. N., Cosmadakis, S. S., & Yannakakis, M. (1995). datalog vs. polynomial time.J. Comput. Syst. Sci., 51 (2), 177196.Alviano, M., Faber, W., Greco, G., & Leone, N. (2012a). Magic sets disjunctive datalogprograms. Artificial Intelligence, 187188, 156192.Alviano, M., Faber, W., Leone, N., & Manna, M. (2012b). Disjunctive datalog existential quantifiers: Semantics, decidability, complexity issues. Theory PracticeLogic Programming, 12 (4-5), 701718.Baader, F., Brandt, S., & Lutz, C. (2005). Pushing EL envelope. IJCAI 2015,Proceedings Nineteenth International Joint Conference Artificial Intelligence,Edinburgh, Scotland, UK, July 30-August 5, 2005, pp. 364369.Baader, F., Calvanese, D., McGuinness, D. L., Nardi, D., & Patel-Schneider, P. F. (2003).Description Logic Handbook: Theory, Implementation, Applications. Cambridge Univ. Press.Bagosi, T., Calvanese, D., Hardi, J., Komla-Ebri, S., Lanti, D., Rezk, M., Rodriguez-Muro,M., Slusnys, M., & Xiao, G. (2014). Ontop framework ontology based data access. Zhao, D., Du, J., Wang, H., Wang, P., Ji, D., & Pan, J. Z. (Eds.), CSWS 2014,Proceedings Semantic Web Web Science - 8th Chinese Conference, Wuhan,China, August 8-12, 2014, Revised Selected Papers, Vol. 480 CommunicationsComputer Information Science, pp. 6777. Springer.Bancilhon, F., Maier, D., Sagiv, Y., & Ullman, J. D. (1986). Magic sets strangeways implement logic programs. Silberschatz, A. (Ed.), Proceedings FifthACM SIGACT-SIGMOD Symposium Principles Database Systems, March 2426, 1986, Cambridge, Massachusetts, USA, pp. 115. ACM.Beeri, C., Naqvi, S. A., Ramakrishnan, R., Shmueli, O., & Tsur, S. (1987). Sets negationlogic database language (LDL1). Vardi, M. Y. (Ed.), Proceedings Sixth361fiZhou, Cuenca Grau, Nenov, Kaminski, & HorrocksACM SIGACT-SIGMOD-SIGART Symposium Principles Database Systems,March 23-25, 1987, San Diego, California, USA, pp. 2137. ACM.Bishop, B., Kiryakov, A., Ognyano, D., Peikov, I., Tashev, Z., & Velkov, R. (2011).OWLIM: family scalable semantic repositories. Semantic Web, 2 (1), 3342.Bourhis, P., Morak, M., & Pieris, A. (2013). impact disjunction query answering guarded-based existential rules. IJCAI 2013, Proceedings 23rdInternational Joint Conference Artificial Intelligence, Beijing, China, August 3-9,2013, pp. 796802. AAAI Press.Broekstra, J., Kampman, A., & van Harmelen, F. (2002). Sesame: generic architecturestoring querying RDF RDF schema. Horrocks, I., & Hendler, J. A.(Eds.), ISWC 2002, Proceedings Semantic Web - First International SemanticWeb Conference, Sardinia, Italy, June 9-12, 2002, Proceedings, Vol. 2342 LectureNotes Computer Science, pp. 5468. Springer.Bry, F., Eisinger, N., Eiter, T., Furche, T., Gottlob, G., Ley, C., Linse, B., Pichler, R., & Wei,F. (2007). Foundations rule-based query answering. Antoniou, G., Amann, U.,Baroglio, C., Decker, S., Henze, N., Patranjan, P., & Tolksdorf, R. (Eds.), ReasoningWeb 2007, Vol. 4636 Lecture Notes Computer Science, pp. 1153. Springer.Cal, A., Gottlob, G., & Kifer, M. (2013). Taming infinite chase: Query answeringexpressive relational constraints. Journal Artificial Intelligence Research, 48,115174.Cal, A., Gottlob, G., & Lukasiewicz, T. (2012). general datalog-based frameworktractable query answering ontologies. J. Web Sem., 14, 5783.Cal, A., Gottlob, G., Lukasiewicz, T., Marnette, B., & Pieris, A. (2010). Datalog+/-:family logical knowledge representation query languages new applications.LICS 2010, Proceedings 25th Annual IEEE Symposium Logic ComputerScience, 11-14 July 2010, Edinburgh, United Kingdom, pp. 228242. IEEE ComputerSociety.Cal, A., Gottlob, G., & Pieris, A. (2011). New expressive languages ontological queryanswering. Burgard, W., & Roth, D. (Eds.), AAAI 2011, Proceedings TwentyFifth AAAI Conference Artificial Intelligence, San Francisco, California, USA,August 7-11, 2011, Vol. 2, pp. 15411546. AAAI Press.Calvanese, D., De Giacomo, G., Lembo, D., Lenzerini, M., Poggi, A., Rodriguez-Muro, M.,Rosati, R., Ruzzi, M., & Savo, D. F. (2011). MASTRO system ontology-baseddata access. Semantic Web, 2 (1), 4353.Calvanese, D., De Giacomo, G., Lembo, D., Lenzerini, M., & Rosati, R. (2007). Tractablereasoning efficient query answering description logics: DL-Lite family.Journal Automated Reasoning, 39 (3), 385429.Chortaras, A., Trivela, D., & Stamou, G. B. (2011). Optimized query rewriting OWL2 QL. Bjrner, N., & Sofronie-Stokkermans, V. (Eds.), CADE 23, Proceedings23rd International Conference Automated Deduction, Wroclaw, Poland, July31 - August 5, 2011, Vol. 6803 Lecture Notes Computer Science, pp. 192206.Springer.362fiPAGOdA: Pay-As-You-Go Query Answering Using Datalog ReasonerConsole, M., Mora, J., Rosati, R., Santarelli, V., & Savo, D. F. (2014). Eective computationmaximal sound approximations description logic ontologies. ISWC 2014,Proceedings Semantic Web - 13th International Semantic Web Conference,Riva del Garda, Italy, October 19-23, 2014. Proceedings, Part II, pp. 164179.Cuenca Grau, B., Horrocks, I., Krotzsch, M., Kupke, C., Magka, D., Motik, B., & Wang, Z.(2013). Acyclicity notions existential rules application query answeringontologies. Journal Artificial Intelligence Research, 47, 741808.Cuenca Grau, B., Horrocks, I., Motik, B., Parsia, B., Patel-Schneider, P. F., & Sattler, U.(2008). OWL 2: next step OWL. Journal Web Semantics, 6 (4), 309322.Cuenca Grau, B., Motik, B., Stoilos, G., & Horrocks, I. (2012). Completeness guaranteesincomplete ontology reasoners: Theory practice. Journal Artificial IntelligenceResearch, 43, 419476.Dantsin, E., Eiter, T., Gottlob, G., & Voronkov, A. (2001). Complexity expressivepower logic programming. ACM Computing Surveys, 33 (3), 374425.Dolby, J., Fokoue, A., Kalyanpur, A., Kershenbaum, A., Schonberg, E., Srinivas, K., &Ma, L. (2007). Scalable semantic retrieval summarization refinement.AAAI 2007, Proceedings Twenty-Second AAAI Conference Artificial Intelligence, July 22-26, 2007, Vancouver, British Columbia, Canada, pp. 299304. AAAIPress.Dolby, J., Fokoue, A., Kalyanpur, A., Schonberg, E., & Srinivas, K. (2009). Scalable highlyexpressive reasoner (SHER). Journal Web Semantics, 7 (4), 357361.Eiter, T., Fink, M., Tompits, H., & Woltran, S. (2004). Simplifying logic programsuniform strong equivalence. LPNMR 2004, Proceedings Logic ProgrammingNonmonotonic Reasoning - 7th International Conference, Fort Lauderdale, FL,USA, January 6-8, 2004, Proceedings, pp. 8799.Eiter, T., Lutz, C., Ortiz, M., & Simkus, M. (2009). Query answering description logicstransitive roles. Boutilier, C. (Ed.), IJCAI 2009, Proceedings 21stInternational Joint Conference Artificial Intelligence, Pasadena, California, USA,July 11-17, 2009, pp. 759764.Eiter, T., Ortiz, M., & Simkus, M. (2012). Conjunctive query answering descriptionlogic SH using knots. Journal Computer System Sciences, 78 (1), 4785.Erling, O., & Mikhailov, I. (2009). Virtuoso: RDF support native RDBMS. Virgilio,R. D., Giunchiglia, F., & Tanca, L. (Eds.), Semantic Web Information Management- Model-Based Perspective, pp. 501519. Springer.Glimm, B., Horrocks, I., Motik, B., Stoilos, G., & Wang, Z. (2014). HermiT: OWL 2reasoner. Journal Automated Reasoning, 53 (3), 245269.Glimm, B., Lutz, C., Horrocks, I., & Sattler, U. (2008). Conjunctive query answeringdescription logic SHIQ. Journal Artificial Intelligence Research, 31, 157204.Grosof, B. N., Horrocks, I., Volz, R., & Decker, S. (2003). Description logic programs:combining logic programs description logic. Hencsey, G., White, B., Chen,Y. R., Kovacs, L., & Lawrence, S. (Eds.), WWW 2003, Proceedings Twelfth363fiZhou, Cuenca Grau, Nenov, Kaminski, & HorrocksInternational World Wide Web Conference, Budapest, Hungary, May 20-24, 2003,pp. 4857. ACM.Guo, Y., Pan, Z., & Heflin, J. (2005). LUBM: benchmark OWL knowledge basesystems. Journal Web Semantics, 3 (2-3), 158182.Haarslev, V., Hidde, K., Moller, R., & Wessel, M. (2012). RacerPro knowledge representation reasoning system. Semantic Web, 3 (3), 267277.Horrocks, I., Kutz, O., & Sattler, U. (2006). even irresistible SROIQ. KR2006, Proceedings Tenth International Conference Principles KnowledgeRepresentation Reasoning, Lake District United Kingdom, June 2-5, 2006,pp. 5767.Horrocks, I., Patel-Schneider, P. F., & van Harmelen, F. (2003). SHIQ RDFOWL: making web ontology language. Journal Web Semantics, 1 (1),726.Horrocks, I., & Tessaris, S. (2000). conjunctive query language description logicaboxes. Kautz, H. A., & Porter, B. W. (Eds.), AAAI/IAAI 2000, ProceedingsSeventeenth National Conference Artificial Intelligence Twelfth ConferenceInnovative Applications Artificial Intelligence, July 30 - August 3, 2000, Austin,Texas, USA., pp. 399404. AAAI Press / MIT Press.Hustadt, U., Motik, B., & Sattler, U. (2007). Reasoning description logics reductiondisjunctive datalog. Journal Automated Reasoning, 39 (3), 351384.Jimenez-Ruiz, E., & Cuenca Grau, B. (2011). LogMap: Logic-based scalable ontologymatching. Aroyo, L., Welty, C., Alani, H., Taylor, J., Bernstein, A., Kagal, L., Noy,N. F., & Blomqvist, E. (Eds.), ISWC 2011, Semantic Web - 10th InternationalSemantic Web Conference, Bonn, Germany, October 23-27, 2011, Proceedings, PartI, Vol. 7031 Lecture Notes Computer Science, pp. 273288. Springer.Kemp, D. B., Srivastava, D., & Stuckey, P. J. (1995). Bottom-up evaluation queryoptimization well-founded models. Theoretical Computer Science, 146 (12), 145184.Kollia, I., & Glimm, B. (2013). Optimizing SPARQL query answering OWL ontologies.Journal Artificial Intelligence Research, 48, 253303.Kontchakov, R., Lutz, C., Toman, D., Wolter, F., & Zakharyaschev, M. (2011). combined approach ontology-based data access. Walsh, T. (Ed.), IJCAI 2011,Proceedings 22nd International Joint Conference Artificial Intelligence,Barcelona, Catalonia, Spain, July 16-22, 2011, pp. 26562661. IJCAI/AAAI.Leone, N., Pfeifer, G., Faber, W., Eiter, T., Gottlob, G., Perri, S., & Scarcello, F. (2006).DLV system knowledge representation reasoning. ACM TransactionsComputational Logic, 7 (3), 499562.Leskovec, J., & Faloutsos, C. (2006). Sampling large graphs. KDD 2006, ProceedingsTwelfth ACM SIGKDD International Conference Knowledge DiscoveryData Mining, Philadelphia, PA, USA, August 20-23, 2006, pp. 631636.364fiPAGOdA: Pay-As-You-Go Query Answering Using Datalog ReasonerLutz, C. (2008). complexity conjunctive query answering expressive description logics. Armando, A., Baumgartner, P., & Dowek, G. (Eds.), IJCAR 2008,Proceedings 4th International Joint Conference Automated Reasoning, Sydney,Australia, August 12-15, 2008, Vol. 5195 Lecture Notes Computer Science, pp.179193. Springer.Lutz, C., Seylan, I., Toman, D., & Wolter, F. (2013). combined approach OBDA:Taming role hierarchies using filters. Alani, H., Kagal, L., Fokoue, A., Groth, P. T.,Biemann, C., Parreira, J. X., Aroyo, L., Noy, N. F., Welty, C., & Janowicz, K. (Eds.),ISWC 2013, Proceedings Semantic Web - 12th International Semantic WebConference, Sydney, NSW, Australia, October 21-25, 2013, Proceedings, Part I, Vol.8218 Lecture Notes Computer Science, pp. 314330. Springer.Lutz, C., Toman, D., & Wolter, F. (2009). Conjunctive query answering description logic EL using relational database system. Boutilier, C. (Ed.), IJCAI2009, Proceedings 21st International Joint Conference Artificial Intelligence,Pasadena, California, USA, July 11-17, 2009, pp. 20702075.Ma, L., Yang, Y., Qiu, Z., Xie, G. T., Pan, Y., & Liu, S. (2006). Towards complete OWLontology benchmark. Sure, Y., & Domingue, J. (Eds.), ESWC 2006, SemanticWeb: Research Applications, 3rd European Semantic Web Conference, Budva,Montenegro, June 11-14, 2006, Proceedings, Vol. 4011 Lecture Notes ComputerScience, pp. 125139. Springer.Manola, F., & Miller, E. (2004). RDF primer. W3C Recommendation. Availablehttp://www.w3.org/TR/rdf-primer/.Marnette, B. (2009). Generalized schema-mappings: termination tractability.PODS 2009, Proceedings Twenty-Eigth ACM SIGMOD-SIGACT-SIGARTSymposium Principles Database Systems, June 19 - July 1, 2009, Providence,Rhode Island, USA, pp. 1322.McBride, B. (2001). Jena: Implementing RDF model syntax specification.SemWeb 2001, Proceedings Second International Workshop SemanticWeb.Moller, R., Neuenstadt, C., Ozcep, O. L., & Wandelt, S. (2013). Advances accessingbig data expressive ontologies. Timm, I. J., & Thimm, M. (Eds.), KI 2013,Proceedings Advances Artificial Intelligence - 36th Annual German ConferenceAI, Koblenz, Germany, September 16-20, 2013, Vol. 8077 Lecture NotesComputer Science, pp. 118129. Springer.Motik, B., Cuenca Grau, B., Horrocks, I., Wu, Z., Fokoue, A., & Lutz, C. (2012). OWL 2Web Ontology Language Profiles (second edition). W3C Recommendation. Availablehttp://www.w3.org/TR/owl2-profiles/.Motik, B., Nenov, Y., Piro, R., Horrocks, I., & Olteanu, D. (2014). Parallel materialisationdatalog programs centralised, main-memory RDF systems. Brodley, C. E., &Stone, P. (Eds.), AAAI 2014, Proceedings Twenty-Eighth AAAI ConferenceArtificial Intelligence, July 27 -31, 2014, Quebec City, Quebec, Canada., pp. 129137.AAAI Press.365fiZhou, Cuenca Grau, Nenov, Kaminski, & HorrocksMotik, B., Shearer, R., & Horrocks, I. (2009). Hypertableau reasoning description logics.Journal Artificial Intelligence Research, 36, 165228.Ortiz, M., Rudolph, S., & Simkus, M. (2011). Query answering horn fragmentsdescription logics SHOIQ SROIQ. IJCAI 2011, Proceedings 22ndInternational Joint Conference Artificial Intelligence, Barcelona, Catalonia, Spain,July 16-22, 2011, pp. 10391044.Pan, J. Z., & Thomas, E. (2007). Approximating OWL-DL ontologies. AAAI 2007,Proceedings Twenty-Second AAAI Conference Artificial Intelligence, July22-26, 2007, Vancouver, British Columbia, Canada, pp. 14341439.Perez-Urbina, H., Motik, B., & Horrocks, I. (2010). Tractable query answering rewritingdescription logic constraints. Journal Applied Logic, 8 (2), 186209.PrudHommeaux, E., & Carothers, G. (2014). RDF 1.1 Turtle. W3C Recommendation.Available http://www.w3.org/TR/turtle/.Robinson, J. A., & Voronkov, A. (Eds.). (2001). Handbook Automated Reasoning (in 2volumes). Elsevier MIT Press.Rodriguez-Muro, M., & Calvanese, D. (2012). High performance query answeringDL-Lite ontologies. Brewka, G., Eiter, T., & McIlraith, S. A. (Eds.), KR 2012,Proceedings Principles Knowledge Representation Reasoning, ThirteenthInternational Conference, Rome, Italy, June 10-14, 2012, pp. 308318. AAAI Press.Rosati, R. (2012). Prexto: Query rewriting extensional constraints DL - lite.Simperl, E., Cimiano, P., Polleres, A., Corcho, O., & Presutti, V. (Eds.), ESWC2012, Proceedings Semantic Web: Research Applications - 9th ExtendedSemantic Web Conference, Heraklion, Crete, Greece, May 27-31, 2012, Vol. 7295Lecture Notes Computer Science, pp. 360374. Springer.Rudolph, S., & Glimm, B. (2010). Nominals, inverses, counting, conjunctive queries or:infinity friend!. Journal Artificial Intelligence Research, 39, 429481.Schaerf, A. (1993). complexity instance checking problem concept languagesexistential quantification. Komorowski, H. J., & Ras, Z. W. (Eds.), ISMIS1993, Proceedings Methodologies Intelligent Systems, 7th International Symposium, Trondheim, Norway, June 15-18, 1993, Vol. 689 Lecture Notes ComputerScience, pp. 508517. Springer.Sirin, E., Parsia, B., Cuenca Grau, B., Kalyanpur, A., & Katz, Y. (2007). Pellet: practicalOWL-DL reasoner. Journal Web Semantics, 5 (2), 5153.Staab, S., & Studer, R. (Eds.). (2004). Handbook Ontologies. International HandbooksInformation Systems. Springer.Stefanoni, G., & Motik, B. (2015). Answering conjunctive queries EL knowledge basestransitive reflexive roles. Bonet, B., & Koenig, S. (Eds.), AAAI 2015,Proceedings 29th AAAI Conference Artificial Intelligence, Austin, TX, USA.AAAI Press. appear.Stefanoni, G., Motik, B., & Horrocks, I. (2013). Introducing nominals combinedquery answering approaches EL. AAAI 2013, Proceedings Twenty-SeventhAAAI Conference Artificial Intelligence, pp. 11771183.366fiPAGOdA: Pay-As-You-Go Query Answering Using Datalog ReasonerStefanoni, G., Motik, B., Krotzsch, M., & Rudolph, S. (2014). complexity answeringconjunctive navigational queries OWL 2 EL knowledge bases. JournalArtificial Intelligence Research, 51, 645705.Stoilos, G. (2014a). Hydrowl: hybrid query answering system OWL 2 DL ontologies.RR 2014, Proceedings Web Reasoning Rule Systems - 8th InternationalConference, Athens, Greece, September 15-17, 2014, pp. 230238.Stoilos, G. (2014b). Ontology-based data access using rewriting, OWL 2 RL systemsrepairing. Presutti, V., dAmato, C., Gandon, F., dAquin, M., Staab, S., & Tordai,A. (Eds.), Semantic Web: Trends Challenges - 11th International Conference,ESWC 2014, Anissaras, Crete, Greece, May 25-29, 2014. Proceedings, Vol. 8465Lecture Notes Computer Science, pp. 317332. Springer.Stoilos, G., & Stamou, G. B. (2014). Hybrid query answering OWL ontologies.Schaub, T., Friedrich, G., & OSullivan, B. (Eds.), ECAI 2014 - 21st European Conference Artificial Intelligence, 18-22 August 2014, Prague, Czech Republic - Including Prestigious Applications Intelligent Systems (PAIS 2014), Vol. 263 FrontiersArtificial Intelligence Applications, pp. 855860. IOS Press.Thomas, E., Pan, J. Z., & Ren, Y. (2010). Trowl: Tractable OWL 2 reasoning infrastructure.ESWC 2010, Proceedings Semantic Web: Research Applications, 7thExtended Semantic Web Conference, Heraklion, Crete, Greece, May 30 - June 3, 2010,Part II, pp. 431435.Tserendorj, T., Rudolph, S., Krotzsch, M., & Hitzler, P. (2008). Approximate OWLreasoning screech. Calvanese, D., & Lausen, G. (Eds.), RR 2008, ProceedingsWeb Reasoning Rule Systems, Second International Conference, Karlsruhe,Germany, October 31-November 1, 2008, Vol. 5341 Lecture Notes ComputerScience, pp. 165180. Springer.W3C SPARQL Working Group (2013). SPARQL 1.1 Overview. W3C Recommendation.Available http://www.w3.org/TR/sparql11-overview/.Wandelt, S., Moller, R., & Wessel, M. (2010). Towards scalable instance retrievalontologies. International Journal Software Informatics, 4 (3), 201218.Wu, Z., Eadon, G., Das, S., Chong, E. I., Kolovski, V., Annamalai, M., & Srinivasan, J.(2008). Implementing inference engine RDFS/OWL constructs user-definedrules oracle. Alonso, G., Blakeley, J. A., & Chen, A. L. P. (Eds.), ICDE 2008,Proceedings 24th International Conference Data Engineering, April 7-12,2008, Cancun, Mexico, pp. 12391248. IEEE.Zhou, Y., Nenov, Y., Cuenca Grau, B., & Horrocks, I. (2014). Pay-as-you-go OWL queryanswering using triple store. Proceedings Twenty-Eighth AAAI ConferenceArtificial Intelligence.Zhou, Y., Nenov, Y., Grau, B. C., & Horrocks, I. (2013). Complete query answeringhorn ontologies using triple store. Semantic Web - ISWC 2013 - 12thInternational Semantic Web Conference, Sydney, NSW, Australia, October 21-25,2013, Proceedings, Part I, pp. 720736.367fiJournal Artificial Intelligence Research 54 (2015) 83-122Submitted 02/15; published 09/15Word vs. Class-Based Word Sense DisambiguationRuben IzquierdoRUBEN . IZQUIERDOBEVIA @ VU . NLVU University AmsterdamAmsterdam. NetherlandsArmando SuarezARMANDO @ DLSI . UA . ESUniversity AlicanteAlicante. SpainGerman RigauGERMAN . RIGAU @ EHU . ESUniversity Basque CountrySan Sebastian. SpainAbstractempirically demonstrated Word Sense Disambiguation (WSD) tasks last SensEval/SemEval exercises, assigning appropriate meaning words context resistedattempts successfully addressed. Many authors argue one possible reason coulduse inappropriate sets word meanings. particular, WordNet used de-factostandard repository word meanings tasks. Thus, instead using wordsenses defined WordNet, approaches derived semantic classes representing groupsword senses. However, meanings represented WordNet used WSDfine-grained sense level coarse-grained semantic class level (also called SuperSenses). suspect appropriate level abstraction could levels.contributions paper manifold. First, propose simple method automaticallyderive semantic classes intermediate levels abstraction covering nominal verbal WordNet meanings. Second, empirically demonstrate automatically derived semantic classesoutperform classical approaches based word senses coarse-grained sense groupings.Third, also demonstrate supervised WSD system benefits using new semantic classes additional semantic features reducing amount training examples.Finally, also demonstrate robustness supervised semantic class-based WSD systemtested domain corpus.1. IntroductionWord Sense Disambiguation (WSD) intermediate Natural Language Processing (NLP) taskconsists assigning correct lexical interpretation ambiguous words depending surrounding context (Agirre & Edmonds, 2007; Navigli, 2009). One successful approacheslast years supervised learning examples, Machine Learning classificationmodels induced semantically annotated corpora (Marquez, Escudero, Martnez, & Rigau,2006). Quite often, machine learning systems obtained better results knowledge-basedones, shown experimental work international evaluation exercises Senseval SemEval1 . Nevertheless, lately weakly supervised knowledgebased approaches reachingperformance close supervised techniques specific tasks. tasks,1. information competitions found http://www.senseval.org.c2015AI Access Foundation. rights reserved.fiI ZQUIERDO , U AREZ & R IGAUcorpora usually manually annotated experts word senses taken particular lexicalsemantic resource, commonly WordNet (Fellbaum, 1998).However, WordNet widely criticized sense repository often providesfinegrained sense distinctions higher level applications like Machine Translation (MT)Question & Answering (AQ). fact, WSD low level semantic granularity resistedattempts inferring robust broad-coverage models. seems many wordsense distinctionssubtle captured automatic systems current small volumes wordsenseannotated examples. Using WordNet sense repository, organizers English all-wordstask SensEval-3 reported inter-annotation agreement 72.5% (Snyder & Palmer, 2004). Interestingly, result difficult outperform state-of-the-art sense-based WSD systems.Moreover, supervised sensebased approaches biased towards frequent sensepredominant sense training data. Therefore, performance supervised sensebasedsystems strongly punished applied domain specific texts sense distribution differs considerably respect sense distribution training corpora (Escudero, Marquez,& Rigau., 2000).paper try overcome problems facing task WSD SemanticClass point view instead traditional word sense based approach. semantic classseen abstract concept groups subconcepts word senses sharing semantic properties features. Examples semantic classes VEHICLE, FOOD ANIMAL. hypothesisusing appropriate set semantic classes instead word-senses could help WSD severalaspects:higher level abstraction could ease integration WSD systems higherlevel NLP applications Machine Translation Question & AnsweringGrouping together semantically coherent sets training examples could also increaserobustness supervised WSD systemssocalled bottleneck acquisition problem could also alleviatedpoints explained along paper. Following hypothesis proposecreate classifiers based semantic classes instead word sense experts. One semantic classifiertrained semantic class final system assign proper semantic classambiguous word (instead sense traditional approaches). example, usingautomatically derived semantic classes (that introduced later), three senses churchWordNet 1.6 subsumed semantic classes R ELIGIOUS RGANIZATION, B UILDINGR ELIGIOUS C EREMONY. Also note semantic classes still discriminate among threedifferent senses word church. instance, assign semantic class B UILDINGoccurrence church context, still know refers second sense. Additionally,semantic class B UILDING covers six times training examplescovered second sense church.example text senseval2 automatically annotated semantic classes seenFigure 1. shows automatic annotations classbased classifiers different semantic classes. BLC stands Basic Level Concepts2 (Izquierdo, Suarez, & Rigau, 2007), SS2. use following format throughout paper refer particular sense: wordnumpos , pospart-of-speech: n nouns, v verbs, adjectives r adverbs, num stands sense number.84fiW ORD VS . C LASS -BASED W ORD ENSE ISAMBIGUATIONSuperSenses (Ciaramita & Johnson, 2003), WND WordNet Domains (Magnini & Cavaglia,2000; L. Bentivogli & Pianta, 2004) SUMO Suggested Upper Merged Ontology (Niles &Pease, 2001). Incorrect assignments marked italics. correct tags includedbrackets next automatic ones. Obviously, semantic resources relate senses differentlevel abstraction using diverse semantic criteria properties could interest subsequent semantic processing. Moreover, combination could improve overall results sinceoffer different semantic perspectives text.Id1234678WordancientstonechurchamidfieldsBLCSSWNDSUMOartifact1nbuilding1nnoun.artifactnoun.artifactbuildingbuildingMineralBuildinggeographic area1n[physical object1n ]noun.location[noun.object]factotum [geography]LandArea91011,soundproperty2nnoun.attributefactotum [acoustics]RadiatingSound[SoundAttribute]1213bellsdevice1nnoun.artifactMusicalInstrument1415161718cascadingtowercallingmove2vverb.motionfactotum [acoustics]factotumconstruction3ndesignate2v[request2v ]noun.artifactfactotumverb.stativefactotum[verb.communication]BuildingCommunication[Requesting]1920faithful[sogroup1ncial group1n ]noun.groupperson [religion]Group2122evensongtime day1n[writing2n ]noun.communicationreligionTimeInterval[Text]MotionTable 1: Example automatic annotation text several semantic class labelsmain goal research investigate performance alternative Semantic Classesderived WordNet supervised WSD. First, propose system automatically extract setssemantically coherent groupings nominal verbal senses WordNet. systemallows generate arbitrary sets semantic classes distinct levels abstraction. Second,also analyze impact respect alternative Semantic Classes performing classbasedWSD. empirical results show automatically generated classes performs bettercreated manually (WNDomains, SUMO, SuperSenses, etc.) capturing preciseinformation. Third, also demonstrate supervised WSD system benefits usingnew semantic classes additional semantic features reducing amount training85fiI ZQUIERDO , U AREZ & R IGAUexamples. Finally, show supervised class-based system adapted particulardomain. Traditional word sense based systems also included comparison purposes.Summarizing, research empirically investigates:performance alternative semantic groupings used supervised class-basedWSD systemimpact class-based semantic features supervised WSD frameworkrequired amount training examples needed class-based WSD order obtaincompetitive resultsrelative performance class-based WSD systems respect WSD based wordexpertsrobustness class-based WSD system specific domainsMoreover, tested domain dataset, supervised class-based WSD system obtains slightly better results state-of-the-art word sense based WSD system, ItMakesSensesystem presented Zhong Ng (2010).introduction, present work directly related research supervisedWSD based semantic classes. Then, Section 3 presents sense-groupings semantic classesused study. Section 4 explains method automatically derive semantic classesWordNet different levels abstraction. Moreover analysis different semantic groupingsincluded. Section 5, presents system developed perform supervised class-basedWSD. performance system shown Section 6, system tested severalWSD datasets provided international evaluations. comparison participantscompetitions introduced sections 7 8. experiments system appliedspecific domain analyzed Section 9. Finally, conclusions future work presentedsection 10.2. Related Workfield WSD broad. large amount publications WSDlast 50 years. section revises relevant WSD approaches dealing appropriatesets meanings word have.research focused deriving different word-sense groupings overcomefinegrained distinctions WordNet (Hearst & Schutze, 1993; Peters, Peters, & Vossen, 1998;Mihalcea & Moldovan, 2001; Agirre & de Lacalle, 2003; Navigli, 2006; Snow, S., D., & A., 2007).is, provide methods grouping senses word, thus producing coarser wordsense groupings. example, word church three senses WordNet 1.6, sensegrouping presented Snow et al. (2007) produces unique grouping. is, accordingapproach church monosemous.OntoNotes project (Hovy, Marcus, Palmer, Ramshaw, & Weischedel, 2006), differentmeanings word considered kind tree, ranging coarse concepts rootfinegrained meanings leaves. merging increased fine coarse grainedobtaining inter annotator agreement around 90%. coarse-grained repository used86fiW ORD VS . C LASS -BASED W ORD ENSE ISAMBIGUATIONWSD lexical sample task SemEval-2007 (Pradhan, Dligach, & Palmer, 2007),systems scored 88.7% Fscore. Note merging created word followingmanual costly process.Similarly previous approach, another task organized within SemEval-2007consisted traditional WSD word task using another coarsegrained sense repository derivedWordNet (Navigli, Litkowski, & Hargraves, 2007). case WordNet synsetsautomatically linked Oxford Dictionary English (ODE) using graph algorithm.meanings word linked ODE entry merged coarse sense. systemsachieving top scores followed supervised approaches taking advantage different corporatraining, reaching top Fscore 82.50%.previous cases aimed solving granularity problem word sensedefinitions WordNet. However, approaches still word experts (one classifier trainedword). Obviously, decreasing average polysemy word using coarsersensesmakes easier classification choice. result, performance systems increasecost reducing discriminative power.Conversely, instead word experts, approach creates semantic class experts.semantic classifiers exploit diverse information extracted meanings differentwords belong class.Wikipedia (Wikipedia, 2015) also recently used overcome problems supervised learning methods: excessively finegrained definition meanings, lack annotated datastrong domain dependence existing annotated corpora. way, Wikipedia providesnew source annotated data, large constantly expansion (Mihalcea, 2007; Gangemi,Nuzzolese, Presutti, Draicchio, Musetti, & Ciancarini, 2012).contrast, research focused using predefined sets sense-groupingslearning classbased classifiers WSD (Segond, Schiller, Greffenstette, & Chanod, 1997; Ciaramita & Johnson, 2003; Villarejo, Marquez, & Rigau, 2005; Curran, 2005; Ciaramita & Altun,2006; Izquierdo, Suarez, & Rigau, 2009). is, grouping senses different wordsexplicit comprehensive semantic class. Also work presented Mihalcea, Csomai,Ciaramita (2007) makes use three different sets semantic classes (WordNet classes twoNamed Entity annotated corpora) train sequential classifiers. classifiers trained usingbasic features, collocations semantic features, reach performance around 60%14th position SemEval-2007 allwords task.semantic classes WordNet (also called SuperSenses) widely used differentworks. instance, Paa Reichartz (2009a) apply Conditional Random Fields modelsequential context words relation SuperSenses. also extend model includepotential SuperSenses word training data. F1 score 82.8% reported (bothnouns verbs) potential labels used (no training data all) 1% worseusing training data right labels. Although interesting, evaluatesystem applying 5-fold cross validation SemCor.3. Semantic Classes Levels Abstractionmeanings represented WordNet used WSD fine-grained senselevel coarse-grained semantic class level (also called SuperSenses). suspectappropriate level abstraction could found levels. section propose87fiI ZQUIERDO , U AREZ & R IGAUsimple method automatically derive semantic classes intermediate levels abstraction covering nominal verbal WordNet meanings. First, introduce WordNet, semantic resourcesense repository used WSD systems. Also note semantic classes usedwork also linked WordNet.WordNet (Fellbaum, 1998) online lexical database English contains conceptsrepresented synsets, sets synonyms content words (nouns, verbs, adjectivesadverbs). One synset groups together several senses different words synonyms.WordNet different types lexical semantic relations interlink different synsets, creatingway large structured lexical semantic network. important relationencoded WordNet subclass relation (for nouns called hyponymy relation verbstroponymy relation). Table 2 shows basic figures different WordNet versions includingtotal number words, polysemous words, synsets, senses (all possible senses words)average polysemy.VersionWN 1.6WN 1.7WN 1.7.1WN 2.0WN 2.1WN 3.0Words121,962144,684146,350152,059155,327155,287Polysemous23,25524,73525,94426,27527,00626,896Synsets99,642109,377111,223115,424117,597120,982Senses173,941192,460195,817203,145207,016206,941Avg. Polysemy2.912.932.862.942.892.89Table 2: Statistics WordNet versions.3.1 SuperSensesSuperSenses name WordNet Lexicographer Files within framework WSD3 .detail, WordNet synsets organized forty five SuperSenses, based syntactic categories(nouns, verbs, adjectives adverbs) logical groupings PERSON, PHENOMENON,FEELING , LOCATION , etc. 26 basic categories nouns, 15 verbs, 3 adjectives1 adverbs. cases, different senses word grouped high levelSuperSense, reducing polysemy word. often case similarsenses word. classes adjectives adverbs, SuperSense taggersusually developed nouns verbs. (Tsvetkov, Schneider, Hovy, Bhatia, Faruqui, &Dyer, 2014) presents interesting study tagging adjectives SuperSenses acquiredGermaNet (Hamp, Feldweg, et al., 1997).3.2 WordNet DomainsWordNet Domains4 (WND) (Magnini & Cavaglia, 2000; L. Bentivogli & Pianta, 2004) hierarchy 165 domains used label semi-automatically WordNet synsets.set labels organized taxonomy following Dewey Decimal Classification System5 .3. information SuperSenses found http://wordnet.princeton.edu/wordnet/man/lexnames.5WN.html.4. http://wndomains.itc.it5. http://www.oclc.org/dewey88fiW ORD VS . C LASS -BASED W ORD ENSE ISAMBIGUATIONbuilding WND, many labels assigned high levels WordNet hierarchyautomatically inherited across hypernym troponym hierarchy. Thus, semi-automaticmethod6 used develop resource free errors inconsistencies (Castillo, Real, &Rigau, 2004; Gonzalez, Rigau, & Castillo, 2012).Information brought domain labels complementary already WordNet. WNDpresent characteristics interesting WSD. First all, domain label may containsenses different WordNet subhierarchies (derived different SuperSenses). instance,domain RELIGION contains senses priest, deriving NOUN . PERSON church,deriving NOUN . ARTIFACT. Second, domain label may also include synsets differentsyntactic categories. instance, domain RELIGION also contains verb pray adjectiveholy.Furthermore, single WND label subsume different senses word, reducingway polysemy. instance, first third senses church WordNet 1.6domain label RELIGION.3.3 SUMO ConceptsSUMO7 (Niles & Pease, 2001) created part IEEE Standard Upper Ontology WorkingGroup. goal develop standard upper ontology promote data interoperability, information search retrieval, automated inference, natural language processing. UMO consistsset concepts, relations, axioms formalize upper ontology. experiments,used complete WordNet 1.6 mapping 1,019 UMO labels (Niles & Pease, 2003).case, three noun senses church WordNet 1.6 classified R ELIGIOUS RGANIZATION,B UILDING R ELIGIOUS C EREMONY according SUMO ontology.3.4 Example Semantic Classesexample, table 3 presents three senses glosses word church WordNet 1.6.Sense123WordNet 1.6gloss1Christian churchn group Christians; group professingChristian doctrine belief: church biblical term assemblychurch2n church building1npublic (especially Christian) worship:church emptychurch service1n church3nservice conducted church: dont latechurchword senseschurch1nChristianity2nTable 3: Glosses examples senses churchnTable 4 show classes assigned sense according semantic resources introduced previously. instance, considering WordNet Domains, observed sensesnumber 1 (group Christians) 3 (service conducted church) belong domain6. based several cycles manual checking automatically labeled data.7. http://www.ontologyportal.org89fiI ZQUIERDO , U AREZ & R IGAURELIGION . contrary, SuperSenses SUMO represent three senses church usingdifferent semantic classes. Also note resulting assignment semantic classes identifiesword sense individually.Sense123SuperSenseNOUN . GROUPNOUN . ARTIFACTNOUN . ACTSemantic ClassWNDSUMOR ELIGION R ELIGIOUS RGANIZATIONB UILDINGSB UILDINGR ELIGIONR ELIGIOUS C EREMONYTable 4: Semantic Classes noun churchn3.5 Levels AbstractionBasic Level Concepts (Rosch, 1977) (hereinafter BLC) result compromise twoconflicting principles characterization (general vs. specific):Represent many concepts possibleRepresent many features possibleresult conflicting characterization, BLC typically occur middle levelssemantic hierarchies.notion Base Concepts (hereinafter BC) introduced EuroWordNet (Vossen, 1998).BC supposed important concepts several language specific wordnets.importance measured terms two main criteria:high position semantic hierarchymany relations conceptsEuroWordNet set 1,024 concepts selected called Common Base Concepts.Common BC concepts act BC least two languages. local wordnets English,Dutch Spanish used select set Common BC. later initiatives, similar setsderived harmonize construction multilingual wordnets.Considering definitions, next section present method automatically generatedifferent sets Basic Level Concepts WordNet different levels abstraction.4. Automatic Selection Basic Level ConceptsSeveral approaches developed trying alleviate fine granularity problem WordNetsenses obtaining word sense groupings (Hearst & Schutze, 1993; Peters et al., 1998; Mihalcea& Moldovan, 2001; Agirre & de Lacalle, 2003; Navigli, 2006; Snow et al., 2007; Bhagwani, Satapathy, & Karnick, 2013). cases approach consists grouping different sensesword, resulting decrease polysemy. Obviously, polysemy reducedWSD task classification problem becomes easier, system using coarse sensesobtain better results systems using word senses. works used predefined setssemantic classes, mainly SuperSenses (Segond et al., 1997; Ciaramita & Johnson, 2003; Curran,90fiW ORD VS . C LASS -BASED W ORD ENSE ISAMBIGUATION2005; Villarejo et al., 2005; Ciaramita & Altun, 2006; Picca, Gliozzo, & Ciaramita, 2008; Paa &Reichartz, 2009b; Tsvetkov et al., 2014).section, describe simple method automatically create different sets Basic LevelConcepts WordNet. method exploits nominal verbal structure WordNet.basic idea synsets WordNet high number relations important, couldcandidates BLC. capture relevance synset WordNet considered twooptions:1. All: total number relations encoded WordNet synset2. Hypo: total number hyponymy relations synsetmethod follows bottomup approach exploiting hypernymy chains WordNet.synset, process starts visiting synsets hyperonymy chain selecting (andstopping walk synset) BLC ancestor first local maximum consideringtotal number relations (either Hypo)8 . synsets one hyperonym,method chooses one higher number relations continue process. processends preliminary set candidate synsets selected potential BLC.Additionally, synset selected potential BLC candidate must subsume (or represent)least certain number descendant synsets. Thus, minimum number synsets BLC mustsubsume another parameter algorithm, represented symbol . CandidateBLCs reach threshold discarded, subsumed synsets reassignedBLC candidate appearing higher levels abstraction.Algorithm 1 presents pseudocode algorithm. parameters algorithm are:WordNet resource, type relations considered (All Hypo), minimum numberconcepts must subsumed BLC (). algorithm two phases. firstone selects candidate BLC, following bottomup approach. second phase discardscandidate BLC satisfy threshold.Figure 1 shows schema illustrate selection process. node represents synset,edges represent hyperonymy relations (for instance, hyperonym D,hyperonym F). number synset indicates number hyponymy relations.schema illustrates selection process BLC candidates synset J using criterion Hypo.process starts checking hyperonym J, F. F two hyperonyms, B D.next synset visited hyperonymy chain J since higher number hyponymyrelations (three). algorithm compares number relations hyperonym synset (Dthree relations), previous synset (F two). number increasingprocess continues. Now, next node visit A. number relations twonumber three, process stops synset selected BLC candidate J D.Table 5 shows real example selection process noun church WordNet 1.6.hyperonym chain number relations encoded WordNet (All criterion) shownsynset. local maximum chain marked bold.8. algorithm starts checking first hyperonym synset, synset itself.91fiI ZQUIERDO , U AREZ & R IGAUFigure 1: Example BLC selection#rel.18193710125#rel.14293963791119#rel.206951171synsetgroup 1,grouping 1social group 1organisation 2,organization 1establishment 2,institution 1faith 3,religion 2Christianity 2,church 1,Christian church 1synsetentity 1,something 1object 1,physical object 1artifact 1,artefact 1construction 3,structure 1building 1,edifice 1place worship 1, ...church 2,church building 1synsetact 2,human action 1,human activity 1activity 1ceremony 3religious ceremony 1,religious ritual 1service 3,religious service 1,divine service 1church 3,church service 1Table 5: BLC selection noun church WordNet 1.692fiW ORD VS . C LASS -BASED W ORD ENSE ISAMBIGUATIONAlgorithm 1 BLC ExtractionRequire: WordNet (WN) , typeOfRelation (T), threshold ()BlcCandidates ={synset W N }cur :={Obtaining hypernym chains current synset cur}H := Hypernyms(W N, cur)new := SynsetW ithM oreRelations(W N, H, ){Iterating number relations increased}N umOf Rels(W N, T, cur) < N umOf Rels(W N, T, new)cur := newH := Hypernyms(W N, cur)new := SynsetW ithM oreRelations(W N, H, )end while{Store cur candidate BLC}BlcCandidates := BlcCandidates {cur}end{Filtering BLC candidates}BlcF inal ={blc BlcCandidates}< N umberOf Descendants(W N, blc)BlcF inal := BlcF inal {blc}endendreturn BlcF inalFigure 2: Example BLC selection sense 2 church93fiI ZQUIERDO , U AREZ & R IGAUfigure 2 see diagram showing partial view selection process candidateBLC sense number 2 noun church. synset dotted synsetprocessed (church2n ). synsets bold visited algorithm, onegray (building1n ) one selected BLC church2n . process stops checking synsetstructure1n number relations 63, lower number relationsprevious synset (79 relations edifice1n ).Obviously, combining different values threshold (for example 0, 10, 20 50)criterion considered algorithm (All Hypo), process ends different sets BLCextracted automatically WordNet version.Furthermore, instead number relations consider frequency synsetscorpus measure importance. Synset frequency calculated sumfrequencies word senses contained synset, obtained SemCor (Miller,Leacock, Tengi, & Bunker, 1993), WordNet.sum up, algorithm two main parameters, parameter, representing minimum number synsets BLC must represent, criterion used characterizingrelevance synsets. values parameters be:parameter: integer value greater equal 0Synset relevance parameter: value considered measure importance synset.Four possibilities:Number relations synsetAll: relations encoded synsetHypo: hyponymy relationsFrequency synsetFreqWN: frequency obtained using WordNetFreqSC: frequency obtained using SemCorimplementation algorithm different sets BLC used paper severalWordNet versions freely available9 .4.1 Analysis Basic Level Conceptsselected WordNet 1.6 generate several sets BLC, combining four types synsetrelevance criteria values 0, 10, 20 50 . values selected sincerepresent different levels abstraction, ranging = 0 (no filtering) = 50 (each BLCmust subsume least 50 synsets). Table 6 shows, combinations synset relevanceparameters, number concepts set BLC contains, average depthWordNet hierarchy group. gray highlight two sets BLC (BLC-20 BLC-50relations parameter) use experiments described paper.expected, increasing threshold direct effect number BLCaverage depth WordNet hierarchy. particular, values decreased, indicatingthreshold increased, concepts selected abstract general. instance,9. http://adimen.si.ehu.es/web/BLC94fiW ORD VS . C LASS -BASED W ORD ENSE ISAMBIGUATIONThresholdSynset Relevance0102050HypoFreqSCFreqWNHypoFreqSCFreqWNHypoFreqSCFreqWNHypoFreqSCFreqWN# BLCNouns Verbs3,094 1,2562,490 1,04134,865 3,07034,183 2,6159717199937186907316917385586735586723396593406672536332486339463099631DepthNouns Verbs7.093.327.093.317.443.417.443.306.201.396.231.365.741.385.771.405.811.255.801.215.431.225.471.235.211.135.211.104.351.124.411.12Table 6: Automatic Base Level Concepts WN1.6using (All) nominal part WordNet, number concepts selected range 3,094filtering ( = 0) 253 ( = 50). However, average, depth reduction acute sincevaries 7.09 5.21. fact shows robustness method selecting synsetsintermediate level abstraction.Also expected, verbal part WordNet behave differently. case, since verbalhierarchies less deep, average depth synsets selected ranges 3.32 1.13using relations, 3.31 1.10 using Hypo relations.general, using frequency criteria, observe similar behaviorusing relation criteria. However, effect threshold dramatic, speciallynouns. Again, expected, verbs behave differently nouns. number BLC (forSemCor WordNet frequencies) reaches plateau around 600. fact, numberclose verbal top beginners WordNet.Summing up, devised simple automatic procedure deriving different sets BLCrepresenting different level abstraction whole set nominal verbal synsets WordNet. following section show explain supervised framework developed WSDorder exploit semantic classes described section previous one.5. Supervised Class-Based WSDfollow supervised machine learning approach develop set semantic class based WSDclassifiers. systems use implementation Support Vector Machine algorithm trainclassifiers, one per semantic class, semantic annotated corpora acquiring positivenegative examples class. classifiers built basis set features definedrepresenting examples. class-based, training data must collected treatedpretty different way usual word-based approach.95fiI ZQUIERDO , U AREZ & R IGAUFirst, word-based class-based approaches selects training examples differently.word-based approach, instances word used training examples. Figure3 shows distribution training examples used generate word sense classifier nounhouse. Following binary definition SVM, one classifier generated word sense.classifiers, occurrences word sense associated classifierused positive examples, rest word sense occurrences used negative examples.Classifier HOUSEClassifiersense#1... house.n#1 ...Classifiersense#2... house.n#2...... house.n#1 ...Classifiersense#3... house.n#2 ...... house.n#3 ...Figure 3: Distribution examples using word-based approachclass-based approach, use examples words belongparticular semantic class. Figure 4 shows distribution examples class-based approach.case, one classifier created semantic class. occurrences words belongingsemantic class associated classifier used positive examples, restoccurrences word senses associated different semantic class selected negativeexamples.Obviously, class-based approach number examples training increased. Table7 shows example sense church2n . Following word-based approach 58 examplesfound Semcor church2n . Conversely, 371 positive training examples usedbuilding classifier semantic class building, edifice.think approach several advantages. First, semantic classes reduce averagepolysemy degree words (some word senses might grouped together within semanticclass). Moreover, acquisition bottleneck problem supervised machine learning algorithmsattenuated increase number training examples. However, mixingone classifier examples different words. instance, building classgrouping together examples hotel, hospital church, could introduce noiselearning process grouping unrelated word senses.5.1 Learning Algorithm: SVMSupport Vector Machines (SVM) proven robust competitive many NLPtasks, WSD particular (Marquez et al., 2006). experiments, used SVM-Light96fiW ORD VS . C LASS -BASED W ORD ENSE ISAMBIGUATIONClassifier ANIMALClassifier BUILDING...hospital..(BUILDING)...house..(BUILDING)...dog...(ANIMAL)...cat...(ANIMAL)...star..(PERSON)Figure 4: Distribution examples using class-based approachchurch2nClassifier(word-based approach)building, edifice(class approach)Exampleschurch2nchurch2nbuilding1nhotel1nhospital1nbarn1n.......# positive examples585848392017......371 examplesTable 7: Number examples Semcor: word vs. class-based approaches97fiI ZQUIERDO , U AREZ & R IGAUimplementation (Joachims, 1998). SVM used induce hyperplane separates positivenegative examples maximum margin. means hyperplane locatedintermediate position positive negative examples, trying keep maximum distanceclosest positive example, closest negative example. cases, possibleget hyperplane divides space linearly, better allow errors obtainefficient hyperplane. known soft-margin SVM, requires estimation parameter(C), represents trade-off allowed training errors margin. setvalue 0.01, demonstrated good value SVM WSD tasks.classifying example, obtain value output function SVM classifiercorresponding semantic class word example, system simply selects classgreatest value.5.2 CorporaThree semantic annotated corpora used training testing. Semcor training,SensEval-2 SensEval-3 English all-words tasks, testing.SemCor (Miller et al., 1993) subset Brown Corpus plus novel Red BadgeCourage, developed group created WordNet. contains 253texts around 700,000 running words, 200,000 also lemmatized sensetagged according Princeton WordNet 1.6. sense annotations SemCor alsoautomatically ported WordNet versions10 .SensEval-211 English all-words corpus (hereinafter SE2) (Palmer, Fellbaum, Cotton, Delfs, &Dang, 2001) consists 5,000 words text three Wall Street Journal (WSJ) articles representing different domains Penn TreeBank II. sense inventory used taggingWordNet 1.7.SensEval-312 English all-words corpus (hereinafter SE3) (Snyder & Palmer, 2004), made5,000 words, extracted two WSJ articles one excerpt Brown Corpus. Senserepository WordNet 1.7.1 used tag 2,041 words proper senses.also considered alternative evaluation datasets. instance, SemEval-2007 coarsegrained task corpus13 . However, dataset discarded corpus annotatedparticular set word sense clusters. Additionally, provide clear simple waycompare orthogonal sets clusterings. Although recent SensEval/SemEvaltasks WSD, think purpose evaluation (different level abstractionWSD), SensEval-2 SensEval-3 still datasets best fit purposes. recentSemEval competitions designed address specific topics, multilinguality jointWSD Named Entity Recognition. However, also make additional experimentsdomain adaptation dataset provided SemEval-10 task 17 All-words Word SenseDisambiguation Specific Domain (WSD-domain)14 (Agirre, Lopez de Lacalle, Fellbaum,Hsieh, Tesconi, Monachini, Vossen, & Segers, 2010).10.11.12.13.14.http://web.eecs.umich.edu/mihalcea/downloads.html#semcorhttp://www.sle.sharp.co.uk/senseval2http://www.senseval.org/senseval3Indeed participated task preliminary version systemhttp://semeval2.fbk.eu/semeval2.php?location=tasks#T2598fiW ORD VS . C LASS -BASED W ORD ENSE ISAMBIGUATION5.3 Feature TypesFollowing previous contributions supervised WSD, selected set basic featuresrepresent training testing examples. also include additional features based semanticclasses.Basic featuresWord-forms lemmas window 10 words around target word.PoS, concatenation preceding/following three five PoS tags.Bigrams trigrams formed lemmas word-forms window 5 wordsaround target word; use tokens regardless PoS build bi/trigrams.replace target word character X features increase generalization.Semantic featuresfrequent semantic class target word, calculated SemCor.Monosemous semantic class monosemous words window size five wordsaround target word.Basic features widely used literature, work presented Yarowsky (1994).features pieces information occur context target word: local featuresincluding bigrams trigrams (including target word) lemmas, word-forms partofspeech labels (PoS). addition, wordforms lemmas larger window around targetword considered features representing topic discourse.set features extended semantic information. Several types semantic classesconsidered create features. particular, two different sets BLC (BLC20BLC5015 ), SuperSenses, WordNet Domains (WND) SUMO.order increase generalization capabilities class-based classifiers filterirrelevant features. measure relevance feature16 f class c terms frequencyf. class c, feature f class, calculate frequency featurewithin class (the number times occurs examples class), also obtaintotal frequency feature classes. get relative frequency dividingvalues (classFreq / totalFreq) result lower certain threshold t, featureremoved feature list class c17 . way, make sure features selectedclass frequently related class others. set threshold0.25, obtained empirically preliminary versions classifiers applying crossvalidation setting SemCor.15. selected set since represent different levels abstraction. said section 4, 20 50 referthreshold minimum number synsets possible BLC must subsume considered proper BLC.sets BLC built using criterion.16. is, value feature, example feature type word-form, feature typehouses.17. Depending experiment, around 30% original features removed filter.99fiI ZQUIERDO , U AREZ & R IGAU6. Semantic ClassBased WSD Experimentssection present performance semantic class-based WSD systemwords WSD SensEval-2 (SE2) SensEval3 (SE3) datasets. want analyze behaviorclass-based WSD system working different levels abstraction. saidbefore, level abstraction defined semantic class used build classifiers.experiment defined two different parameters one involving particular setsemantic classes.1. Target class: semantic classes used train classifiers (determining abstractionlevel system). case, tested: word-sense18 , BLC20, BLC50, WordNet Domains (WND), SUMO SuperSenses (SS).2. Semantic features class: semantic classes used building semantic features.case, tested: BLC20, BLC50, WND, SUMO SuperSenses (SS).target class type classes classifier assigns given ambiguous word.instance, target class traditional word expert classifiers word senses. Semanticfeature class one used building semantic features, independent targetclass. instance, use WordNet Domains extract monosemous words contexttarget word use WND labels words semantic features buildingclassifier.Combining different semantic classes target features, generated set experiments described next sections. way, evaluate independently impactselecting one semantic class another target class semantic feature class.TestSE2SE3PoSNVNVSense4.029.824.9310.95BLC203.457.114.088.64BLC503.346.943.928.46SUMO3.335.943.947.60SS2.734.063.064.08WND2.662.693.052.49Table 8: Average polysemy SE2 SE3Table 8 shows average polysemy (AP) measured SE2 SE3 respect different semantic classes used evaluation target classes. expected, every corpus behavesdifferently average polysemy verbs higher nouns. Also could assumeadvance, relevant reductions polysemy degree obtained increasing levelabstraction. fact acute also verbs. Note large reduction polysemy verbsusing SuperSenses also WND. Also note priori SE3 seems difficultdisambiguate SE2, independently abstraction level.6.1 Baselinesbaselines evaluations define frequent classes (MFC) word calculatedSemCor. Ties classes specific word solved obtaining global frequency18. included word-based evaluation comparison purposes since current system designedclass-based evaluation.100fiW ORD VS . C LASS -BASED W ORD ENSE ISAMBIGUATIONSemCor tied classes, selecting frequent class whole trainingcorpus. Semcor occurrences particular word (that is, able calculatefrequent class word), compute global frequency possiblesemantic classes (obtained WordNet) SemCor, select frequent one. Table9 shows baseline semantic class testing corpora.ClassSenseBLC20BLC50SUMOSuperSenseWNDPosNVNVNVNVNVNVSE2MFC AP70.02 4.0244.75 9.8275.71 3.4555.13 7.1176.65 3.3454.93 6.9476.09 3.3360.35 5.9480.41 2.7368.47 4.0686.11 2.6690.33 2.69SE3MFCAP72.304.9352.88 10.9576.294.0858.828.6476.643.9260.058.4679.553.9464.717.6081.503.0679.074.0883.823.0592.202.49Table 9: Frequent Class baselines average polysemy (AP) SE2 SE3expected, performances MFC baselines high. particular, corresponding nouns (ranging 70% 80%). nominal baselines seem perform similarlySE2 SE3, verbal baselines appear consistently much lower SE2 SE3.SE2, verbal baselines range 44% 68% SE3 verbal baselines range 52%79%. results WND high due low polysemy degree nouns verbs.Obviously, increasing level abstraction (from senses WND) results also increase.6.2 Results Basic Systemsection present performance supervised semantic classbased WSD system.Table 10 shows results system trained varying target classes usingbasic feature set. values correspond F1 measures (harmonic mean recallprecision) training systems SemCor testing SE2 SE3 test sets. resultsimprove baselines shown italics. Additionally, results showing statisticallysignificant positive difference compared corresponding baseline using McNemarstest marked bold.Interestingly, basic system word-sense level outperforms baselines SE2SE3 nouns verbs. addition, systems obtain cases significantly betterresults verbs. Also interesting verbs word-sense level baselines resultsdifferent, class-level differences datasets much smaller.expected, results systems increase augmenting level abstraction (fromsenses WND), cases, baseline results reached outperformed. evenrelevant consider baseline results already quite high. However, highlevel abstraction (SuperSenses WND) basic systems seem unable outperformbaselines.101fiI ZQUIERDO , U AREZ & R IGAUClassSenseBLC20BLC50SUMOSuperSenseWNDPosNVNVNVNVNVNVSE271.2045.5375.5257.0674.5758.0377.6062.0979.9471.9580.8190.14SE373.1557.0273.8261.1075.8461.9776.7466.2179.4878.3977.6488.92Table 10: Results basic system trained SemCor basic set features evaluatedSE2 SE3general, results obtained BLC20 different BLC50. instance,consider number classes within BLC20 (558 classes), BLC50 (253 classes) SuperSense (24 classes), BLC classifiers obtain high performance rates maintaining much higherexpressive power SuperSenses (they able classify among much larger number classes).fact, using SuperSenses (40 classes nouns verbs) obtain accurate semantic tagger performance close 80%. Even interesting, could use BLC20 taggingnouns (558 semantic classes F1 around 75%) SuperSenses verbs (14 semantic classesF1 around 75%).6.3 Results Exploiting Semantic FeaturesOne main goals prove simple semantic features added training processcapable producing significant improvements basic systems. results experiments considering also different types semantic features presented Tables 11 12,respectively nouns verbs.tables, column labeled Class refers called target class,column labeled SF indicates type semantic features included represent exampleswithin machine learning approach.Again, values tables correspond F1 measures (harmonic mean recallprecision) training systems SemCor testing SE2 SE3 test sets. resultsimproving baselines appear italics. Additionally, results showing statistically significant positive difference compared corresponding baseline using McNemars testmarked bold.Regarding nouns (see Table 11), different behavior observed SE2 SE3. Addingsemantic features mainly improves results SE2. SE3 none systems presentsignificant improvement baselines, SE2 improvement obtained usingseveral types semantic features (in particular, using WND features SE2). usesemantic class-based features seems improve systems using target classes intermediatelevels abstraction (specially BLC20 BLC50). Interestingly, SE3 BLC20 BLC50102fiW ORD VS . C LASS -BASED W ORD ENSE ISAMBIGUATIONClassSFbaselinebasicFeatBLC20BLC50SUMOSSWNDbaselinebasicFeatBLC20BLC50SUMOSSWNDbaselinebasicFeatBLC20BLC50SUMOSSWNDSenseBLC20BLC50SE270.0271.2071.7971.6971.5971.1071.2075.7575.5277.6977.7977.6075.1477.8876.6574.5778.4576.6579.5875.5278.92SE372.3073.1573.1573.0473.1572.7073.1576.2973.8276.5275.7373.7173.8274.2476.7475.8476.8576.7475.5174.6174.83ClassSUMOSSWNDSFbaselinebasicFeatBLC20BLC50SUMOSSWNDbaselinebasicFeatBLC20BLC50SUMOSSWNDbaselinebasicFeatBLC20BLC50SUMOSSWNDSE276.0977.6075.5275.5277.8877.5077.8880.4179.9481.0780.2280.5180.3282.4786.1180.8181.8582.3383.5583.0886.01SE379.5576.7476.7477.1978.7676.9777.4281.5079.4881.3981.7381.0576.4679.8283.8277.6480.7980.1181.2478.3183.71Table 11: Results nouns using extended systemseem provide improvements baselines target classes (for instance,BLC20, BLC50 SS), although significant.Regarding verbs (see Table 12), also different behavior observed SE2 SE3.case, observe almost opposite effect nouns. SE3 semanticclass features improve results obtained baselines. SE2 systemspresent significant improvement baselines, SE3 improvement obtainedusing several types semantic features. However, case also obtain significantly betterresults several semantic features SE2. use semantic class-based features seemsbenefit lower levels abstraction (specially word-sense, BLC20, BLC50 also SUMO).general, results show using semantic features addition basic features helpsreach better performance class-based WSD systems. Additionally, also seems usingsemantic features able obtain competitive classifiers sense level.6.4 Learning Curvesalso investigate behavior class-based WSD system respect number trainingexamples. Although experiments carried nouns verbs,include results nouns since cases, trend similar.experiment, Semcor files randomly selected added trainingcorpus order generate subsets 5%, 10%, 15%, etc. training corpus19 . Then, train19. portion contains also files previous portion. example, files 25% portion alsocontained 30% portion.103fiI ZQUIERDO , U AREZ & R IGAUClassSenseBLC20BLC50SFbaselinebasicFeatBLC20BLC50SUMOSSWNDbaselinebasicFeatBLC20BLC50SUMOSSWNDbaselinebasicFeatBLC20BLC50SUMOSSWNDSE244.7545.5345.1445.5345.7345.3445.5355.1357.0656.8755.9057.0656.2958.6154.9358.0357.4556.6757.0657.4559.77SE352.8857.0256.6156.4757.0256.7556.7558.8261.1059.9260.6061.1561.2960.8860.0561.9761.2961.0161.8361.8362.38ClassSUMOSSWNDSFbaselinebasicFeatBLC20BLC50SUMOSSWNDbaselinebasicFeatBLC20BLC50SUMOSSWNDbaselinebasicFeatBLC20BLC50SUMOSSWNDSE260.3562.0961.1262.0960.7459.9661.5168.4771.9569.2569.2570.2169.2571.7690.3390.1490.1490.1490.5289.7590.52SE364.7166.2166.0766.4864.9864.7166.3579.0778.3977.7077.7077.7077.8479.7592.2088.9290.4290.1589.8888.7892.20Table 12: Results verbs using extended systemsystem training portions test system SE2 SE3. Finally, alsocompare resulting system baseline computed training portion.Figures 5 6 present learning curves SE2 SE3, respectively. case,selected BLC20 class-based WSD system using WordNet Domains semantic features20 .Surprisingly, SE2 system improves F1 measure around 2% increasingtraining corpus 25% 100% SemCor. SE3, system improves F1measure around 3% increasing training corpus 30% 100% SemCor. is,knowledge required class-based WSD system seems already presentsmall part SemCor.Figures 7 8 present learning curves SE2 SE3, respectively, class-basedWSD system based SuperSenses using semantic features built WordNet Domains.SE2 system improves F1 measure around 2% increasing training corpus25% 100% SemCor. SE3, system improves F1 measure around 2%increasing training corpus 30% 100% SemCor. is, 25%whole corpus, class-based WSD system reaches F1 close performance using corpus.SE2 ans SE3, using BLC20 (Figures 5 6) SuperSenses (Figures 7 8)semantic classes WSD, behavior system similar MFC baseline.interesting since MFC obtains high results due way defined: MFCtotal corpus assigned occurrences word training corpus. Withoutdefinition, would large number words test set occurrences using20. shown previous experiments, combination obtains good performance.104fiW ORD VS . C LASS -BASED W ORD ENSE ISAMBIGUATION80System SV2MFC SV278767472F170686664625101520253035404550556065707580859095 100% corpusFigure 5: Learning curve BLC20 classifier SE278System SV3MFC SV3767472F170686664625101520253035404550 55% corpus60657075808590Figure 6: Learning curve BLC20 classifier SE310595 100fiI ZQUIERDO , U AREZ & R IGAU84System SV2MFC SV2828078F176747270685101520253035404550556065707580859095 100% corpusFigure 7: Learning curve SuperSense classifier SE282System SV3MFC SV38078F1767472705101520253035404550 55% corpus6065707580859095 100Figure 8: Learning curve SuperSense classifier SE3106fiW ORD VS . C LASS -BASED W ORD ENSE ISAMBIGUATIONsmall training portions. cases, recall baselines (and turn F1) would muchlower.evaluation seems indicate class-based approach WSD reduces considerablyrequired amount training examples.7. Comparison SensEval Systems: Sense Levelmain goal experiments included section verify whether abstraction levelclass-based systems maintains discriminative power evaluated sense level. Additionally, compare results results top participant systems SE2 SE3provided best senselevel outputs. Thus, class-based systems adapted following simple protocol. output based semantic classes converted sense identifiers:instead semantic class produced systems particular instance, select firstsense word according WordNet sense ranking belonging predicted semantic class.So, first obtain semantic class means classifiers, obtain restricted setsenses word match semantic class obtained, choose frequentsense restricted subset.results first experiment SE2 data shown Table 13. systemsprefix SVM- suffix denotes type semantic class used generate classifier21 .cases experiments, WND selected target semantic class generatesemantic features. Two baselines marked Italics also included. first sense WordNet (base-WordNet) frequent sense SemCor (base-SemCor). fact, developersWordNet ranked word senses using SemCor sense-annotated corpora. Thus,frequencies ranks appearing SemCor WordNet similar, equal. alsoinclude results system working word level (SVM-sense).cases, nouns verbs, systems outperform frequent baselines.frequent sense word, according WordNet sense ranking competitiveWSD tasks, extremely hard improve upon even slightly (McCarthy, Koeling, Weeds,& Carroll, 2004). expected, behavior different semantic features produces slightlydifferent results. However, independently semantic features used, SE2 sense level,class-based systems rank third position.Table 14 shows experiment using SE3 dataset. case, class-based systemsclearly outperform baselines, achieving best results nouns second place verbs.Interestingly, nouns, best system SE3 achieve SemCor baseline. Also recallSE3 seems difficult SE2.worth mention class-based systems use features nounsverbs. instance, take profit complex feature sets encoding syntactic informationseems important verbs.experiments show class-based classifiers seem quite competitive evaluated word sense level. perform frequent sense according WordNetSemCor, achieve higher position nouns second verbs SE3, thirdposition nouns verbs SE2. Obviously, indicates class-based WSD maintainshigh discriminative power word sense level.21. instance, SVM-BLC20 stands experiment creates classifier considering BLC20 semantic classes.107fiI ZQUIERDO , U AREZ & R IGAUClass Sense SE2NounsVerbsSystemF1SystemSMUam73.80 SMUawAVe-Antwerp74.40 AVe-antwerpSVM-semBLC20 71.80 SVM-semSUMOSVM-semBLC50 71.70 SVM-senseSVM-semSUMO 71.60 SVM-semWNDSVM-semWND71.20 SVM-semBLC50SVM-sense71.20 SVM-semSSSVM-semSS71.10 SVM-semBLC20base-WordNet70.10 LIA-Sinequabase-SemCor70.00 base-SemCorLIA-Sinequa70.00 base-WordNetF152.7047.9045.7045.5345.5045.5045.3045.1044.8044.8043.80Table 13: Class Sense results SE2. Class word sense transformation.Class Sense SE3NounsSystemSVM-semWNDSVM-semBLC20SVM-semSUMOSVM.senseSVM-semBLC50SVM-semSSbase-SemCorGAMBL-AWbase-WordNetkuawUNTawMeaning-allwordsLCCawF173.2073.2073.2073.1573.0072.7072.3070.8070.7070.6069.6069.4069.30VerbsSystemGAMBL-AWSVM-semSUMOSVM-semWNDSVM-semSSSVM-senseSVM-semBLC20SVM-semBLC50UNTawMeaning-allwordskuawR2D2base-SemCorbase-WordNetF159.3057.0056.8056.8056.7556.6056.5056.4055.2054.5054.4052.9052.80Table 14: Class Sense results SE3. Class word sense transformation.108fiW ORD VS . C LASS -BASED W ORD ENSE ISAMBIGUATION8. Comparison SensEval Systems: Class Levelexperiments presented section explore performance word-based classifiersparticipating SE2 SE3 evaluated class level. perform kind evaluation,word sense output participant systems mapped corresponding semanticclasses. class-based systems modified. Obviously, expect different performancessystems depending semantic class level. Considering results presented tables11 12, order perform comparison, selected experiments use WNDbuild semantic features22 . Thus, system results using different target semantic classesrepresented SVM-semWND.Table 15 presents ordered F1-measure results best performing systems SE2 dataevaluated different levels abstraction. previously, italics includefrequent senses according WordNet base-WordNet SemCor base-SemCor.SE2, independently abstraction level PoS, system (SVM-semWND) scoresfirst positions ranking. one case system reaches best position, twicesecond one. baselines outperformed experiments, except nouns using WND,baseSemCor high.Table 16 presents ordered F1-measure results best performing systems SE3 dataevaluated different levels abstraction. italics include frequent sensesaccording WordNet base-WordNet SemCor base-SemCor. systems representedSVM-semWND.SE3, see system performs better baselines cases, exceptSemCorbased baseline nouns, obtains high result. particular, systemobtains good results verbs, reaching first second best positions cases,outperforming baselines cases.sum up, classbased approach outperforms SensEval participants (both SE2SE3), sense level semantic class level. suggests good performancesemantic classifiers due polysemy reduction. Actually, confirmsclassbased semantic classifiers learning semantic class training examples differentabstraction levels.9. Domain Evaluationsection describe system SemEval-2 Allwords Word Sense DisambiguationSpecific Domain task (Izquierdo, Suarez, & Rigau, 2010). aim evaluationshow robust semantic class approach tested specific domain, differentdomain training material.Traditionally, SensEval competitions focused general domain texts. Thus, domainspecific texts present fresh challenges WSD. example, specific domains reduce possible meaning word given context. Moreover, distribution word senses dataexamples changes compared general domains. problems affect supervisedknowledgebased systems. fact, supervised word-based WSD systems sensitivecorpora used training testing system (Escudero et al., 2000).22. Remind semantic features frequent class target word, semantic class monosemous words context around target word.109fiI ZQUIERDO , U AREZ & R IGAUNounsVerbsF1SystemSense BLC20SMUaw78.72 SMUawSVM-semWND 77.88 SVM-semWNDAVe-antwerp76.71 LIA-Sinequabase-SemCor75.71 AVe-antwerpbase-WordNet74.29 base-SemCorLIA-Sinequa73.39 base-WordNetSense BLC50SMUaw79.01 SMUawSVM-semWND 78.92 SVM-semWNDAVe-antwerp77.57 LIA-Sinequabase-SemCor76.65 AVe-Antwerpbase-WordNet75.24 base-SemCorLIA-Sinequa74.53 base-WordNetSense SUMOSMUaw79.30 SMUawSVM-semWND 77.88 LIA-Sinequabase-SemCor76.09 AVe-AntwerpAVe-Antwerp75.94 SVM-semWNDLIA-Sinequa74.92 base-SemCorbase-WordNet71.74 base-WordNetSense SuperSenseSVM-semWND 82.47 SMUawSMUaw81.21 LIA-SinequaAVe-Antwerp80.75 SVM-semWNDbase-SemCor80.41 AVe-AntwerpLIA-Sinequa79.58 base-WordNetbase-WordNet78.16base-SemCorSense WNDSMUaw88.80 SMUawbase-SemCor86.11 SVM-semWNDSVM-semWND 86.01 base-SemCorAVe-Antwerp87.30 LIA-Sinequabase-WordNet85.82 base-WordNetLIA-Sinequa84.85 AVe-AntwerpSystemF161.2258.6157.4257.2855.1354.1661.6159.7757.8157.6754.9354.5568.2264.7962.5661.5161.3360.3573.4772.7471.7669.3169.0568.4791.1690.5290.3389.8289.7589.74Table 15: Results sense BLC20, BLC50, SUMO, SuperSense WND semantic classesSE2110fiW ORD VS . C LASS -BASED W ORD ENSE ISAMBIGUATIONNounsVerbsF1SystemSense BLC20base-SemCor76.29 GAMBL-AWGAMBL-AW74.77 SVM-semWNDkuaw74.69 kuawLCCaw74.44 R2D2UNTaw74.40 UNTawSVM-semWND74.24 Meaning-allwordsbase-WordNet74.16base-SemCorMeaning-allwords 73.11 base-WordNetSense BLC50base-SemCor76.74 GAMBL-AWGAMBL-AW75.56 SVM-semWNDkuaw75.25 kuawSVM-semWND74.83 R2D2LCCaw74.78 UNTawUNTaw74.73 Meaning-allwordsbase-WordNet74.49 base-SemCorR2D273.93 base-WordNetSense SUMObase-SemCor79.55 GAMBL-AWkuaw78.18 SVM-semWNDLCCaw77.54 UNTawSVM-semWND77.42 kuawUNTaw77.32 Meaning-allwordsGAMBL-AW77.14 upv-eaw2base-WordNet76.97base-SemCorMeaning-allwords 76.75 base-WordNetSense SuperSensebase-SemCor81.50 SVM-semWNDkuaw79.89 GAMBL-AWSVM-semWND79.82 base-SemCorUNTaw79.71 base-WordNetGAMBL-AW79.62 Meaning-allwordsupv-eaw279.27 Meaning-simpleupv-eaw78.42 kuawbase-WordNet78.25 upv-eaw2Sense WNDbase-SemCor83.80 SVM-semWNDSVM-semWND83.71 base-SemCorUNTaw83.62 UNTawkuaw81.78 GAMBL-AWGAMBL-AW81.53 base-WordNetbase-WordNet81.46R2D2LCCaw80.64 Meaning-simpleMeaning-allwords 80.50 kuawSystemF163.5660.8860.6659.7959.7359.3758.8258.2864.3862.3861.2260.3560.2760.1960.0658.8268.7766.3566.0365.9365.4364.9264.7164.0279.7579.4079.0778.2578.1477.7277.5377.2192.2092.2091.3791.0190.8390.5290.5090.44Table 16: Results sense BLC20, BLC50, SUMO, SuperSense WND semantic classesSE3111fiI ZQUIERDO , U AREZ & R IGAUTherefore, main challenge develop specific domain WSD systems adaptgeneral system particular domain. Following research line, task proposed withinSemEval2 competition: Allwords Word Sense Disambiguation Specific Domain (Agirreet al., 2010). restricted domain selected task environmental domain. testcorpora consist three texts compiled European Center Nature Conservation23 (ECNC)World Wildlife Forum24 (WWF). task proposed several languages: Chinese, Dutch,English Italian, although participation limited English. detail,total 1,032 noun tokens 366 verb tokens tagged. Moreover, set backgrounddocuments related environmental domain provided. texts sense tagged,plain text, also provided ECNC WWF. could usedsystems help adaptation specific domain. English, total 113background documents, containing 2,737,202 words.apply kind specific domain adaptation technique supervised classbasedsystem. order adapt supervised system environmental domain increase automatically training data new training examples domain. acquire examples,use 113 background documents environmental domain provided organizers.use TreeTagger (Schmid, 1994) preprocess documents, performing PoStagging lemmatization. Since background documents semantically annotated, supervised systemneeds labeled data, selected monosemous instances occurring documentsaccording BLC20 semantic classes25 . Note approach exploited classbased WSD systems. way, obtained automatically large set examples annotatedBLC20. semantic class selected provided good results previousexperiments. order analyze approach system would work levelabstraction, performed evaluation posteriori using BLC50, WordNet DomainsSuperSenses besides BLC20, official participation SemEval-2. Nevertheless,section focused BLC20.Regarding BLC20, Table 17 presents total number training examples extracted SemCor (SC) background documents (BG). expected, method large numbermonosemous examples obtained nouns verbs, although, verbs much less productive nouns. However, background examples correspond reduced set 7,646monosemous words.SCBGTotalNouns87,978193,536281,514Verbs48,26710,82159,088N+V136,245204,357340,602Table 17: Number training examples BLC20Table 18 lists ten frequent monosemous nouns verbs occurring backgrounddocuments. Remember examples monosemous according BLC20 semanticclasses.23. http://www.ecnc.org24. http://wwf.org25. BLC20 (see section 4) stands Basic Level Concepts obtained relations criterion minimum thresholdsubconcepts subsumed equal 20.112fiW ORD VS . C LASS -BASED W ORD ENSE ISAMBIGUATION12345678910NounsLemmabiodiversityhabitatspecieclimateeuropeanecosystemrivergrasslanddatumdirective# ex.7,4767,2067,0673,5392,8182,6692,4202,3032,2762,197VerbsLemma # ex.monitor788achieve784target484select345enable334seem287pine281evaluate 246explore200believe172Table 18: frequent monosemous words background documentsSCBGTotalNouns87,978116,912204,890Verbs48,2677,01955,286N+V136,245123,931260,176Table 19: Number training examples word sensesapproach applies semantic class architecture shown previous sections,using examples extracted background documents. case, semantic class usedextract examples generate classifiers BLC2026 . select simple feature set widelyused many WSD systems. particular, use window five tokens around target wordextract word forms, lemmas; bigrams trigrams word forms lemmas; trigrams PoStags, also frequent BLC20 semantic class target word training corpus.analyze contribution monosemous examples performance system threeexperiments defined:BLC20SC: training examples extracted SemCorBLC20BG: monosemous examples extracted background dataBLC20SCBG: training examples extracted SemCor monosemous background datafirst run (BLC20SC) aims show behavior supervised system trained generalcorpus, tested specific domain. second one (BLC20BG) analyzes contributionmonosemous examples extracted background data. Finally, third run (BLC20SCBG) studies robustness approach combining training examples SemCorautomatic ones obtained background documents.Table 20 summarizes ordered recall official results participants EnglishWSD domain specific task SemEval2. table, Type refers approach followedcorresponding system: Weakly Supervised (WS), Supervised (S) KB (Knowledge Based,unsupervised). participate system using BLC20 semantic class (the BLC20SC/BG/SCBG runs). wordbased classifiers (labeled SenseBG, Sense-SC SenseSCBG)26. case use set BLCs WordNet3.0, also version WN one usedannotation.113fiI ZQUIERDO , U AREZ & R IGAUincluded evaluation campaign. Finally, mentioned introduction,also included performance ItMakesSense system, one best performing WSD systems, task comparison purposes (it row table calledItMakesSense Italics).Rank1234567891011...25...32System IDCFILT2CFILT1IIITH1-d.1.ppr.05IIITH2-d.2.ppr.05BLC20SCBGItMakesSenseBLC20SCFrequent SenseCFILT3TreematchTreematch2SenseSCBGSenseSC...BLC20BG...Random baselineSenseBGTypeWSWSWSWSKBKBKB......P0.5700.5540.5340.5220.5130.5100.5050.5050.5120.5060.5040.4980.498...0.380...0.2320.045R0.5550.5400.5280.5160.5130.5100.5050.5050.4950.4930.4910.4840.484...0.380...0.2320.001Table 20: Precision Recall SemEval2 participants. ItMakesSense results includedcomparison purposegeneral, results reported SemEval task quite low. best systemachieved precision 0.570, frequent baseline reached precision 0.505.fact shows domain adaptation WSD systems difficult task.Analyzing results three runs SemEval, worst result obtained systemusing monosemous background examples (BLC20BG). system ranks 23rd27Precision Recall 0.380 (0.385 nouns 0.366 verbs). system using SemCor(BLC20SC) ranks 6th Precision Recall 0.505 (0.527 nouns 0.443 verbs).also performance first sense baseline. expected, best result threeruns obtained combining examples SemCor background (BLC20SCBG).supervised system obtains 5th position Precision Recall 0.513 (0.534nouns, 0.454 verbs) slightly baseline. Actually, version systemobtains slightly better results best performing supervised system (ItMakesSense). Also notecould include automatically monosemous examples background test thanksclass-based nature WSD system.Moreover, system one completely supervised participating task. organizers calculated recall confidence interval 95% using bootstrap re-sampling procedure(Noreen, 1989). method estimation might strict pairwise methods.reveals differences four first systems system (BLC20SCBG)27. table appears 25th position due included wordbased classifier results.114fiW ORD VS . C LASS -BASED W ORD ENSE ISAMBIGUATIONstatistically significant. seen Figure 9, overlapping recall confidence interval four first systems system (ranking 5th), provesdifferences statistically significant28 .Figure 9: Recall confidence intervals.Possibly, reason low performance BCL20BG system high correlation features target word semantic class. case, features correspondmonosemous word later evaluated polysemous words, kind features. However, also seems class-based systems robust enough incorporate large setsmonosemous examples domain text. fact, knowledge, first timesupervised WSD algorithm successfully adapted specific domain. Furthermore,system trained SemCor also achieves good performance, reaching frequentbaseline, showing robustness class-based WSD approaches domain variations.Comparing wordbased classifiers, seems BLC20 classes contribute two mainaspects. First, using set features, classbased classifiers obtain better resultswordbased ones. classifiers built BLC20 robust domain adaptablewordbased approaches. Second, experiment uses examples extracted background data considering word senses (Sense-BG) obtain accuracy close zero,experiment using BLC20 semantic classes (BLC20BG) reaches accuracy 0.380.fact indicates BLCs useful extract good training examples unlabeled data.mentioned previously, order obtain better insight, evaluation campaign performedevaluation system using semantic classes represent different levelsabstractions: BLC50, WordNet Domains SuperSenses. Table 21 shows precision (P)recall (R)29 evaluation considering different training datasets (SemCor only, Backgrounddocuments SemCor Background documents: SC, BG SC+BG respectively)different semantic classes.seen Table 21, BLC20 leads better performance using three differentcorpora training (BG, SC SCBG). training monosemous examples extractedbackground documents, BLC20 obtains best result, may indicate levelabstraction adequate other, including WND SS, sets much smallermuch lower polysemy. effect drawn results trainingSemCor monosemous examples background (SCBG). best resultsobtained BLC20, together SuperSenses two semantic classes seem28. figure taken directly overview paper task.29. figures obtained using official scorer script official gold key, without modification.115fiI ZQUIERDO , U AREZ & R IGAUSystem IDBLC20SCBGItMakesSenseBLC20SCFrequent SenseWNDSCSenseSCBGSenseSCSS-SCBGBLC50SCBGBLC50SCSSSCWNSCBGBLC20BGWNDBGSSBGBLC50BGRandom baselineType-P0.5130.5100.5050.5050.4950.4980.4980.4840.4810.4810.4720.4710.3800.3620.3480.2770.232R0.5130.5100.5050.5050.4950.4840.4840.4840.4810.4810.4570.4710.3800.3620.3480.2770.232Table 21: Results experiments according different semantic classesbenefit background monosemous examples. results seem confirm potentialcapabilities BLC20 provide adequate level abstraction perform class-based WSD.Finally, proved system performs level one state-of-the-art sys30tem , ItMakesSense system (Zhong & Ng, 2010). Considering set featuressystem quite simple, apply machine learning optimization featureengineering, results show use Semantic Classes provides robust behaviorspecific domains, reaching state-of-the-art results.10. Concluding RemarksWord sense disambiguation difficult task empirically demonstrated SensEval/SemEval exercises. One reason difficulties could use inappropriate setsword meanings. WordNet de-facto standard repository meanings, several attemptsmade grouping senses order achieve higher levels accuracy. Moreover,approach tries ease hard task creating large enough sets annotated data per domainlanguage train supervised systems. possible solution would use manual annotation semantic class labels instead fine-grained word senses (Schneider, Mohit, Oflazer, & Smith, 2012;Schneider, Mohit, Dyer, Oflazer, & Smith, 2013).Several attempts made obtain word sense groupings alleviate problemfine granularity word senses, widely using WordNet senses. cases approachconsists grouping different senses word, resulting decrease polysemy,reducing discriminative capacity. works use predefined sets semantic classesintegrated directly WSD system, mainly SuperSenses.30. tested offline, ItMakesSense system participate task. downloaded lastversion software http://www.comp.nus.edu.sg/nlp/software.html.116fiW ORD VS . C LASS -BASED W ORD ENSE ISAMBIGUATIONwork describe simple method automatically select Basic Level ConceptsWordNet. Based simple structural properties WordNet, method automatically selectsdifferent sets BLC representing different levels abstraction.aim work explore several allwords WSD tasks performance differentlevels abstraction provided Basic Level Concepts, WordNet Domains, SUMO SuperSenselabels. Furthermore, study empirically demonstrates that:a) word sense groupings cluster senses coherent level abstraction orderperform supervised classbased WSD harming performance,b) semantic classes successfully used semantic features boost performanceclassifiers,c) classbased approach WSD reduces dramatically required amount training examples obtain competitive classifiers,d) classbased approach obtains competitive performances compared word-based systems,e) classbased approach outperforms wordbased systems evaluated class level,f) robustness class-based WSD system performing domain evaluation,g) system reaches results comparable state-of-the-art system (ItMakesSense)tested specific domain.general, classbased disambiguation nouns verbs achieves better resultswordbased systems presented SensEval2 SensEval3. also showed classbased approach reduces considerably required amount training examples. order provetype disambiguation possible accurate ranked class-based systemstogether SensEval2 Senseval3 official results. order establish fair comparisonmapped necessary word senses semantic classes viceversa.experiments designed use classbased classifiers perform wordsensedisambiguation. shown simple approach selecting first sense WordNet corresponds class selected classifiers performs well top systemsSensEval2 SensEval3.Additional experiments carried compare wordbased systems performclassbased disambiguation. case translated official system outputs corresponding semantic classes.Different experiments performed using different levels abstraction, rangingSuperSenses (a small set) SUMO (which 1,000 labels linked WordNet1.6 senses),WordNet Domains (with 163 labels), Basic Level Concepts (with arbitrary number classesdepending abstraction level selected).expected differences SensEval2 SensEval3 results, classbased systems outperform baselines nouns verbs. Specially nouns, class-basedsystems outperforms SensEval2 SensEval3 systems. general, results obtainedSVM-semBLC20 different results SVM-semBLC50. Thus, select117fiI ZQUIERDO , U AREZ & R IGAUmedium level abstraction, without significant decrease performance. Considering number classes, BLC classifiers obtain high performance rates maintaining muchhigher expressiveness SuperSenses. However, using SuperSenses (40 classes) obtainaccurate semantic tagger performances around 80%. Even better, use BLC20tagging nouns (558 semantic classes F1 75%) SuperSenses verbs (14 semanticclasses F1 around 75%).systems SemEval2 All-words Word Sense Disambiguation Specific Domain taskproved simple features exploiting BLC perform well sophisticated methods.Comparing wordbased classifiers, see BLC20 classes contribute two mainaspects: classbased classifiers obtain better results wordbased ones semantic classescontribute effectively results. fact indicates that, particular, BLC20 usefulextract monosemous training examples unlabeled domain data.next goal exploit inconsistencies different labeling provided differentclass-based classifiers order obtain robust accurate class-based WSD system.main idea study several classifiers, one based different degree abstraction (e.g.BLC20, BLC50, WordNet Domains, etc.) label concrete context example incompatibletags. manner, would able predict apply best classifier dependingcontext.Acknowledgementswork partially supported NewsReader project31 (ICT-2011-316404), Spanish project SKaTer32 (TIN2012-38584-C06-02).ReferencesAgirre, E., & de Lacalle, O. L. (2003). Clustering wordnet word senses. ProceedingsRANLP03, Borovets, Bulgaria.Agirre, E., & Edmonds, P. (2007). Word Sense Disambiguation: Algorithms Applications.Springer.Agirre, E., Lopez de Lacalle, O., Fellbaum, C., Hsieh, S.-K., Tesconi, M., Monachini, M., Vossen,P., & Segers, R. (2010). Semeval-2010 task 17: All-words word sense disambiguationspecific domain. Proceedings 5th International Workshop Semantic Evaluation,pp. 7580, Uppsala, Sweden. Association Computational Linguistics.Bhagwani, S., Satapathy, S., & Karnick, H. (2013). Merging word senses. Proceedings Workshop Graph-based Methods Natural Language Processing (TextGraphs-8), pp. 1119.Castillo, M., Real, F., & Rigau, G. (2004). Automatic assignment domain labels wordnet.Proceeding 2nd International WordNet Conference, pp. 7582.Ciaramita, M., & Altun, Y. (2006). Broad-coverage sense disambiguation information extraction supersense sequence tagger. Proceedings Conference Empirical Methods Natural Language Processing (EMNLP06), pp. 594602, Sydney, Australia. ACL.31. http://www.newsreader-project.eu32. http://nlp.lsi.upc.edu/skater118fiW ORD VS . C LASS -BASED W ORD ENSE ISAMBIGUATIONCiaramita, M., & Johnson, M. (2003). Supersense tagging unknown nouns wordnet.Proceedings Conference Empirical methods natural language processing(EMNLP03), pp. 168175. ACL.Curran, J. (2005). Supersense tagging unknown nouns using semantic similarity. Proceedings43rd Annual Meeting Association Computational Linguistics (ACL05), pp. 2633. ACL.Escudero, G., Marquez, L., & Rigau., G. (2000). Empirical Study Domain DependenceSupervised Word Sense Disambiguation Systems. Proceedings joint SIGDATConference Empirical Methods Natural Language Processing Large Corpora,EMNLP/VLC, Hong Kong, China.Fellbaum, C. (Ed.). (1998). WordNet. Electronic Lexical Database. MIT Press.Gangemi, A., Nuzzolese, A. G., Presutti, V., Draicchio, F., Musetti, A., & Ciancarini, P. (2012).Automatic typing dbpedia entities. Proceedings 11th International ConferenceSemantic Web - Volume Part I, ISWC12, pp. 6581, Berlin, Heidelberg. Springer-Verlag.Gonzalez, A., Rigau, G., & Castillo, M. (2012). graph-based method improve wordnet domains.Computational Linguistics Intelligent Text Processing, pp. 1728. Springer.Hamp, B., Feldweg, H., et al. (1997). Germanet-a lexical-semantic net german. ProceedingsACL workshop Automatic Information Extraction Building Lexical Semantic ResourcesNLP Applications, pp. 915. Citeseer.Hearst, M., & Schutze, H. (1993). Customizing lexicon better suit computational task.Proceedingns ACL SIGLEX Workshop Lexical Acquisition, Stuttgart, Germany.Hovy, E., Marcus, M., Palmer, M., Ramshaw, L., & Weischedel, R. (2006). Ontonotes: 90Proceedings Human Language Technology Conference NAACL, CompanionVolume: Short Papers, NAACL-Short 06, pp. 5760, Stroudsburg, PA, USA. AssociationComputational Linguistics.Izquierdo, R., Suarez, A., & Rigau, G. (2007). Exploring automatic selection basic level concepts. et al., G. A. (Ed.), International Conference Recent Advances Natural LanguageProcessing, pp. 298302, Borovets, Bulgaria.Izquierdo, R., Suarez, A., & Rigau, G. (2009). empirical study class-based word sense disambiguation. Proceedings 12th Conference European Chapter AssociationComputational Linguistics, EACL 09, pp. 389397, Stroudsburg, PA, USA. AssociationComputational Linguistics.Izquierdo, R., Suarez, A., & Rigau, G. (2010). Gplsi-ixa: Using semantic classes acquire monosemous training examples domain texts. Proceedings 5th International WorkshopSemantic Evaluation, pp. 402406. Association Computational Linguistics.Joachims, T. (1998). Text categorization support vector machines: learning many relevantfeatures. Nedellec, C., & Rouveirol, C. (Eds.), Proceedings ECML-98, 10th EuropeanConference Machine Learning, No. 1398, pp. 137142, Chemnitz, DE. Springer Verlag,Heidelberg, DE.L. Bentivogli, P. Forner, B. M., & Pianta, E. (2004). Revising wordnet domains hierarchy: Semantics, coverage, balancing. COLING 2004 Workshop Multilingual LinguisticResources, Geneva, Switzerland.119fiI ZQUIERDO , U AREZ & R IGAUMagnini, B., & Cavaglia, G. (2000). Integrating subject field codes wordnet. ProceedingsLREC, Athens. Greece.Marquez, L., Escudero, G., Martnez, D., & Rigau, G. (2006). Supervised corpus-based methodswsd. E. Agirre P. Edmonds (Eds.) Word Sense Disambiguation: Algorithmsapplications., Vol. 33 Text, Speech Language Technology. Springer.McCarthy, D., Koeling, R., Weeds, J., & Carroll, J. (2004). Finding predominant word sensesuntagged text. 42nd Annual Meeting Association Computational Linguistics,Barcelona, Spain.Mihalcea, R. (2007). Using wikipedia automatic word sense disambiguation. ProceedingsNAACL HLT 2007.Mihalcea, R., Csomai, A., & Ciaramita, M. (2007). Unt-yahoo: Supersenselearner: Combiningsenselearner supersense coarse semantic features. Proceedings 4thInternational Workshop Semantic Evaluations, SemEval 07, pp. 406409, Stroudsburg,PA, USA. Association Computational Linguistics.Mihalcea, R., & Moldovan, D. (2001). Automatic generation coarse grained wordnet. Proceding NAACL workshop WordNet Lexical Resources: Applications, Extensions Customizations, Pittsburg, USA.Miller, G., Leacock, C., Tengi, R., & Bunker, R. (1993). Semantic Concordance. ProceedingsARPA Workshop Human Language Technology.Navigli, R. (2006). Meaningful clustering senses helps boost word sense disambiguation performance. ACL-44: Proceedings 21st International Conference ComputationalLinguistics 44th annual meeting Association Computational Linguistics,pp. 105112, Morristown, NJ, USA. Association Computational Linguistics.Navigli, R. (2009). Word Sense Disambiguation: survey. ACM Computing Surveys, 41(2), 169.Navigli, R., Litkowski, K., & Hargraves, O. (2007). Semeval-2007 task 07: Coarse-grained englishall-words task. Proceedings Fourth International Workshop Semantic Evaluations (SemEval-2007), pp. 3035, Prague, Czech Republic. Association ComputationalLinguistics.Niles, I., & Pease, A. (2001). Towards standard upper ontology. Proceedings 2ndInternational Conference Formal Ontology Information Systems (FOIS-2001), pp. 1719. Chris Welty Barry Smith, eds.Niles, I., & Pease, A. (2003). Linking lexicons ontologies: Mapping WordNet SuggestedUpper Merged Ontology. Arabnia, H. R. (Ed.), Proc. IEEE Int. Conf. Inf.Knowledge Engin. (IKE 2003), Vol. 2, pp. 412416. CSREA Press.Noreen, E. (1989). Computer-intensive methods testing hypotheses: introduction. WileyInterscience publication. Wiley.Paa, G., & Reichartz, F. (2009a). Exploiting semantic constraints estimating supersensescrfs.. SDM, pp. 485496. SIAM.Paa, G., & Reichartz, F. (2009b). Exploiting semantic constraints estimating supersensescrfs.. SDM, pp. 485496. SIAM.120fiW ORD VS . C LASS -BASED W ORD ENSE ISAMBIGUATIONPalmer, M., Fellbaum, C., Cotton, S., Delfs, L., & Dang, H. T. (2001). English tasks: All-wordsverb lexical sample. Proceedings SENSEVAL-2 Workshop. conjunctionACL2001/EACL2001, Toulouse, France.Peters, W., Peters, I., & Vossen, P. (1998). Automatic sense clustering eurowordnet. First International Conference Language Resources Evaluation (LREC98), Granada, Spain.Picca, D., Gliozzo, A. M., & Ciaramita, M. (2008). Supersense tagger italian.. LREC. Citeseer.Pradhan, S., Dligach, E. L. D., & Palmer, M. (2007). Semeval-2007 task 17: English lexical sample,srl words. SemEval 07: Proceedings 4th International Workshop SemanticEvaluations, pp. 8792, Morristown, NJ, USA. Association Computational Linguistics.Rosch, E. (1977). Human categorisation. Studies Cross-Cultural Psychology, I(1), 149.Schmid, H. (1994). Probabilistic Part-of-Speech Tagging Using Decision Trees. ProceedingsInternational Conference New Methods Language Processing, pp. 4449.Schneider, N., Mohit, B., Dyer, C., Oflazer, K., & Smith, N. A. (2013). Supersense taggingarabic: mt-in-the-middle attack.. HLT-NAACL, pp. 661667. Citeseer.Schneider, N., Mohit, B., Oflazer, K., & Smith, N. A. (2012). Coarse lexical semantic annotationsupersenses: arabic case study. Proceedings 50th Annual MeetingAssociation Computational Linguistics: Short Papers-Volume 2, pp. 253258. AssociationComputational Linguistics.Segond, F., Schiller, A., Greffenstette, G., & Chanod, J. (1997). experiment semantic taggingusing hidden markov model tagging. ACL Workshop Automatic Information ExtractionBuilding Lexical Semantic Resources NLP Applications, pp. 7881. ACL, NewBrunswick, New Jersey.Snow, R., S., P., D., J., & A., N. (2007). Learning merge word senses. Proceedings JointConference Empirical Methods Natural Language Processing Computational Natural Language Learning (EMNLP-CoNLL), pp. 10051014.Snyder, B., & Palmer, M. (2004). english all-words task. Mihalcea, R., & Edmonds, P.(Eds.), Senseval-3: Third International Workshop Evaluation Systems Semantic Analysis Text, pp. 4143, Barcelona, Spain. Association Computational Linguistics.Tsvetkov, Y., Schneider, N., Hovy, D., Bhatia, A., Faruqui, M., & Dyer, C. (2014). Augmentingenglish adjective senses supersenses. Proc. LREC, pp. 43594365.Villarejo, L., Marquez, L., & Rigau, G. (2005). Exploring construction semantic class classifiers wsd. Proceedings 21th Annual Meeting Sociedad Espaola para elProcesamiento del Lenguaje Natural SEPLN05, pp. 195202, Granada, Spain. ISSN 11365948.Vossen, P. (Ed.). (1998). EuroWordNet: Multilingual Database Lexical Semantic Networks. Kluwer Academic Publishers .Wikipedia (2015). Wikipedia, free encyclopedia. https://en.wikipedia.org.. [Online;accessed 21-August-2015].Yarowsky, D. (1994). Decision lists lexical ambiguity resolution: Application accent restoration spanish french. Proceedings 32nd Annual Meeting AssociationComputational Linguistics (ACL94).121fiI ZQUIERDO , U AREZ & R IGAUZhong, Z., & Ng, H. T. (2010). makes sense: wide-coverage word sense disambiguation systemfree text. Proceedings ACL 2010 System Demonstrations, ACLDemos 10, pp.7883, Stroudsburg, PA, USA. Association Computational Linguistics.122fiJournal Artificial Intelligence Research 54 (2015) 193231Submitted 6/15; published 10/15Expressiveness Two-Valued SemanticsAbstract Dialectical FrameworksHannes Strassstrass@informatik.uni-leipzig.deComputer Science Institute, Leipzig UniversityAugustusplatz 10, 04109 Leipzig, GermanyAbstractanalyse expressiveness Brewka Woltrans abstract dialectical frameworkstwo-valued semantics. expressiveness mean ability encode desired settwo-valued interpretations given propositional vocabulary using atomsA. also compare ADFs expressiveness (the two-valued semantics of)abstract argumentation frameworks, normal logic programs propositional logic.computational complexity two-valued model existence problemlanguages (almost) same, show languages form neat hierarchyrespect expressiveness. demonstrate hierarchy collapsesallow introduce linear number new vocabulary elements. finally also analysecompare representational succinctness ADFs (for two-valued model semantics),is, capability represent two-valued interpretation sets space-efficient manner.1. Introductionoften not, different knowledge representation languages conceptually similar partially overlapping intended application areas. facedapplication choice several possible knowledge representation languagescould used application? One first axes along compare differentformalisms comes mind computational complexity: language computationally expensive considering problem sizes typically encountered practice,clear criterion exclusion. available language candidatescomputational complexity? expressiveness computationalcomplexity sense kinds problems formalism solve? same,need fine-grained notion expressiveness. paper, use notionstudy expressiveness abstract dialectical frameworks (ADFs) (Brewka & Woltran,2010; Brewka, Ellmauthaler, Strass, Wallner, & Woltran, 2013), recent generalisationabstract argumentation frameworks (AFs) (Dung, 1995).Argumentation frameworks de-facto standard formalism abstract argumentation, field studies (abstract) arguments relate terms directedconflicts (attacks), conflicts resolved without lookingarguments. AFs popular well-studied, noted many timesliterature expressive capabilities somewhat limited. recentlymade technically precise Dunne, Dvorak, Linsbichler, Woltran (2014, 2015),basically showed introducing new, purely technical arguments sometimes inevitable using AFs representation purposes. However, due nature,dialectical meaning technical arguments might ironically debatable.c2015AI Access Foundation. rights reserved.fiStrasssurprisingly, quite number generalisations AFs proposed (foroverview refer Brewka, Polberg, & Woltran, 2014). one general AFalternatives, aforementioned abstract dialectical frameworks (ADFs) emerged.formalism, arguments (called statements there) abstract, also linksarguments. AFs links necessarily attacks, ADFs statementassociated acceptance condition Boolean function parent statementsspecifies exactly statement accepted. way, acceptanceconditions ultimately express meaning links ADF. Even restricted subclassbipolar ADFs intuitively links supporting attacking propergeneralisation AFs, quite expressive one shall see paper.ADFs could called lovechild AFs logic programs, since combineintuitions semantics Dung-style abstract argumentation well logic programming (Brewka et al., 2013; Strass, 2013; Alviano & Faber, 2015). abstractlevel, ADFs intended function argumentation middleware sufficiently expressive target formalism translations concrete (application) formalisms.part ADF success story, mention reconstruction Carneades modelargument (Brewka & Gordon, 2010), instantiation simple defeasible theoriesADFs (Strass, 2015a), recent applications ADFs legal reasoning reasoningcases Al-Abdulkarim, Atkinson, Bench-Capon (2014, 2015).paper, approach abstract dialectical frameworks knowledge representationformalisms, since used represent knowledge arguments relationshipsarguments. employ view analyse representational capabilitiesADFs. Due roots AFs logic programs, also compare representational capabilities formalisms setting. initial study restrictlooking two-valued semantics, specifically ADF (stable) model semantics, corresponds AF stable extension semantics, supported stablemodel semantics logic programs. add propositional logic well-known reference point. Analysing precise formalisms additionally makes sense uscomputational complexity respective model existence problems (withone exception):AFs, deciding stable extension existence NP-complete (Dimopoulos, Nebel, &Toni, 2002);normal logic programs, deciding existence supported/stable models NPcomplete (Bidoit & Froidevaux, 1991; Marek & Truszczynski, 1991);ADFs, deciding existence (supported) models NP-complete (Brewkaet al., 2013), deciding existence stable models P2 -complete generalADFs (Brewka et al., 2013) NP-complete subclass bipolar ADFs (Strass& Wallner, 2015);propositional satisfiability problem NP-complete.view almost identical complexities, use alternative measureexpressiveness knowledge representation formalism F: Given set two-valuedinterpretations, knowledge base F exact model set? notion194fiExpressiveness Two-Valued Semantics ADFslends straightforwardly compare different formalisms (Gogic, Kautz, Papadimitriou,& Selman, 1995):Formalism F2 least expressive formalism F1 everyknowledge base F1 equivalent knowledge base F2 .expressiveness understood terms realisability, kinds model setsformalism express? (In model theory, known definability.)easy see propositional logic express set two-valued interpretations,universally expressive. easy (but less easy) see normal logic programssupported model semantics. normal logic programs stable model semantics,clear model sets expressed, since two different stable modelsalways incomparable respect subset relation.1 paper, studyexpressiveness properties mentioned formalisms different semantics.turns languages form less strict expressiveness hierarchy, AFsbottom, ADFs LPs stable semantics higher ADFs LPssupported model semantics top together propositional logic.show language F2 least expressive language F1 mainlyuse two different techniques. best case, use syntactic compact faithfultranslation knowledge bases F1 F2 . Compact means translationchange vocabulary, is, introduce new atoms. Faithful meanstranslation exactly preserves models knowledge base respective semanticstwo languages. second best case, assume knowledge base F1given form set X desired models construct semantic realisation XF2 , is, knowledge base F2 model set precisely X. show languageF2 strictly expressive F1 , additionally present knowledge base kbF2 prove F1 cannot express model set kb.Analysing expressiveness argumentation formalisms quite recent strandwork. ascent attributed Dunne et al. (2014, 2015), studied realisabilityargumentation frameworks (allowing introduce new arguments longnever accepted). Likewise, Dyrkolbotn (2014) analysed AF realisability projection(allowing introduce new arguments) three-valued semantics. Baumann, Dvorak, Linsbichler, Strass, Woltran (2014) studied expressiveness subclass compactAFs, argument accepted least once. Finally, recently, Puhrer(2015) analysed realisability three-valued semantics ADFs. Previous preliminary works include Brewka, Dunne, Woltran (2011), translated ADFsAFs ADF model AF stable extension semantics, however translationintroduces additional arguments therefore compact; (Strass, 2013),studied syntactic intertranslatability ADFs LPs, lookexpressiveness realisability.gain achieved analysis paper increasedclarity fundamental properties knowledge representation languagesformalisms express, actually? several applications. Dunneet al. (2015) remarked, major application constructing knowledge bases aim1. However, stable model semantics becomes universally expressive allow nested expressionsform p rule bodies (Lifschitz, Tang, & Turner, 1999; Lifschitz & Razborov, 2006).195fiStrassencoding certain model set. necessary prerequisite this, must knownintended model set realisable first place. example, recent approachrevising argumentation frameworks (Coste-Marquis, Konieczny, Mailly, & Marquis, 2014),authors avoid problem assuming produce collection AFs whose model setsunion produce desired model set. work Dunne et al. (2015) showedindeed necessary case AFs stable extension semantics, work showsADFs model semantics, single knowledge base (ADF) always enoughrealise given model set. more, assume intended model setgiven form propositional formula, size realising ADFlinear size formula. one example several occasionsalso consider sizes realisations, uncommon logic-based AI (Darwiche &Marquis, 2002; Lifschitz & Razborov, 2006; French, van der Hoek, Iliev, & Kooi, 2013; Shen& Zhao, 2014). Indeed, representation size fundamental practical aspect knowledgerepresentation languages: universal expressiveness little use model sets expressrequire exponential-size knowledge bases even best case!course, fact languages study computational complexitymeans principle exist polynomial intertranslations respective decisionproblems. intertranslations may involve introduction polynomial numbernew atoms. theory, increase n atoms nk atoms k > 1consequence. practice, profound impact: number n atoms directlyinfluences search space implementation potentially cover. There, step2nk1 nkk12n = 2n n = 2namounts exponential increase search space size. able realise model setcompactly, without new atoms, therefore attests formalism F certain basickind efficiency property, sense F-realisation model setunnecessarily enlarge search space algorithms operating it.might seem restricting assumption view formalisms sets F knowledge bases kb F associated two-valued semantics. However, languagerepresentation model universal sense another way expressing languages sets words {0, 1}. Using n-element vocabulary = {a1 , . . . , }, binary word w = x1 x2 xn length n encoded set Mw = {ai | xi = 1} .example, using vocabulary A3 = {a1 , a2 , a3 }, binary word 101 length 3 corresponds set M101 = {a1 , a3 }. Consequently, set Ln words length nrepresented set XLn 2An subsets : XLn = {Mw | w Ln }.example vocabulary, word set L3 = {101, 110, 011} represented modelset XL3 = {{a1 , a3 } , {a1 , a2 } , {a2 , a3 }}. Conversely, sequence (Xn )n0 setsXn 2An uniquely determines language L = n0 Ln {0, 1}: n N,Ln = {wM | Xn } wM = x1 x2 xn {1, . . . , n}, xi = 1ai xi = 0 ai/ . paper use language refer object-levellanguages formalism refers meta-level languages, propositional logic,argumentation frameworks, abstract dialectical frameworks, logic programs.Formally, syntax ADFs defined via Boolean functions. However, interested representations ADFs. fix representation ADFs via fixing196fiExpressiveness Two-Valued Semantics ADFsrepresentation Boolean functions. choose use (unrestricted) propositional formulas, customary literature (Brewka & Woltran, 2010; Brewka et al.,2013; Polberg et al., 2013; Polberg, 2014; Gaggl & Strass, 2014; Linsbichler, 2014; Strass &Wallner, 2015; Puhrer, 2015; Gaggl, Rudolph, & Strass, 2015). Exceptions customworks Brewka et al. (2011), use Boolean circuits, one (Strass,2013) used characteristic models (that is, used representation equivalentrepresenting formulas disjunctive normal form). subclass bipolar ADFs,yet uniform representation exists, another question address paper.propositional formulas vocabulary mean formulas Booleanbasis {, , }, is, trees whose leaves (sinks) atoms logical constantstrue > false , internal nodes either unary () binary (,). also makeoccasional use Boolean circuits, trees replaced directed acyclicgraphs; particular, allow unbounded fan-in, is, reusing sub-circuits. usual,depth formula (circuit) length longest path root leaf(sink). Figure 1 shows formula circuit examples depth 3.pqpqpqFigure 1: Representing (p q) (q p) formula tree (left) circuit (right).Analysing expressive power representation size Boolean circuits established sub-field computational complexity (Arora & Barak, 2009). lednumber language classes whose members recognised Boolean circuits satisfyingcertain restrictions. need class AC0 , contains languages L = n0 Lnexist d, k N n N, exists Boolean circuit Cndepth size nk models Cn exactly express Ln .2words, every language L AC0 recognised family polynomial-size Booleancircuits fixed maximal depth independent word length.paper proceeds follows. first define notion expressiveness (and succinctness) formally introduce formalisms study. reviewing severalintertranslatability results languages, step-wise obtain results leadexpressiveness hierarchy, times also looking representational efficiency.finally show allowing linearly expand vocabulary leads collapsehierarchy. paper concludes discussion possible future work.2. precise, n N, models Cn exactly XLn , turn expresses Ln .197fiStrass2. Backgroundpresume finite set atoms (statements, arguments), vocabulary. knowledgerepresentation formalism interpreted set F; (two-valued) semanticsF mapping : F 22 assigns sets two-valued models knowledge baseskb F. (So implicit .) Strictly speaking, two-valued interpretation mappingset atoms two truth values true false, technical easerepresent two-valued interpretations sets containing atoms true. Below,write (F) = {(kb) | kb F}; intuitively, (F) set interpretation setsformalism F express, knowledge base whatsoever. example, F = PLpropositional logic = mod usual model semantics, (PL) = 22 sinceobviously set models realisable propositional logic.3 leads us comparedifferent pairs languages semantics respect semantics range models.concept formalism concentrates semantics decidedly remains abstract.first define expressiveness relation among formalisms.Definition 1. Let finite vocabulary, F1 , F2 formalisms interpreted1 : F1 22 2 : F2 22 two-valued semantics. defineF11 e F22iff1 (F1 ) 2 (F2 )Intuitively, formalism F2 semantics 2 least expressive formalism F1semantics 1 , model sets F1 express 1 also containedF2 produce 2 . (If semantics clear contextomit them; holds particular argumentation frameworks propositional logic,look single semantics.) usual,F1 <e F2 iff F1 e F2 F2 6e F1 ;F1=e F2 iff F1 e F2 F2 e F1 .relation e reflexive transitive definition, necessarily antisymmetric.is, might different formalisms F1 6= F2 equally expressive: F1=e F2 .next introduce succinctness relation defined Gogic et al. (1995).Definition 2. Let finite vocabulary; let F1 F2 formalisms interpreted A, size measures kk1 kk2 , two-valued semantics 1 2 ,respectively. Define F11 F22 k N kb1 F11 (kb1 ) 1 (F1 ) 2 (F2 ), kb2 F2 1 (kb1 ) = 2 (kb2 ) kkb2 k2 kkb1 kk1 .Intuitively, F11 F22 means F2 2 least succinct F1 1 .Put another way, F11 F22 hold, knowledge base F1 equivalentcounterpart F2 must equivalent counterpart polynomially larger.Note succinctness talks model sets express,meaningful comparing languages equally expressive, is, whenever3. set X 2A simply define X =mod (X ) = X.WX198=VVaA\MclearlyfiExpressiveness Two-Valued Semantics ADFs1 (F1 ) = 2 (F2 ). usual, define F1 <s F2 iff F1 F2 F2 6s F1 , F1=s F2iff F1 F2 F2 F1 . relation reflexive, necessarily antisymmetrictransitive.final general definition formalisms polynomially expressing languages.Here, already make use previously introduced bijection interpretationsbinary words use term languages synonymously refer both.Definition 3. formalism F polynomially express language L = n0 Lnsemantics : F 22 k N positive n Nknowledge base kbn F formalism (kbn ) = Ln kkbn k O(nk ).next introduce specific object-level languages use. First all,language Parity contains odd-element subsets vocabulary. Formally,= {a1 , . . . , } n 1Parityn = {M | N : |M | = 2m + 1}explained before, Parity = nN,n1 Parityn . textbook result Parityexpressible polynomial-size propositional formulas (Jukna, 2012); example,define Parity(a1 ) = a1 n 2 set1Parity(a1 , . . . , ) = (Parity(a1 , . . . , ) Parity(an +1 , . . . , ))nnn(Parity(a1 , . . . , ) Parity(an +1 , . . . , ))nnn = n2 n = n2 . (This construction yields formula logarithmic depththerefore polynomial size.) also textbook result (although nearly easysee) Parity cannot expressed depth-bounded polynomial-size circuits, is,Parity/ AC0 (Jukna, 2012).another important class, threshold languages defined n, k N n 1k n:Thresholdn,k = {M | k |M |}is, Thresholdn,k containsinterpretations n atoms least k atomstrue. special case k = n2 leads majority languages,Majorityn = Thresholdn,d n e2contain interpretations least half atoms vocabulary true.next introduce particular knowledge representation languages studypaper. make use vocabulary A; results paper consideredparametric given vocabulary.2.1 Logic Programsvocabulary define = {not | A} accordingly set literals= A. normal logic program rule form BB . set B called body rule, abbreviate B + = B199fiStrassB = {a | B}. logic program (LP) P set logic program rulesA. interpretation satisfies body B rule B P iff B +B = . supported model P iff = {a | B P, satisfies B}.logic program P denote set supported models su(P ). intuitionbehind semantics atoms true modelkind support.However, support might cyclic self-support. instance, logic program{a {a}} two supported models, {a}, latter undesired manyapplication domains. alternative, Gelfond Lifschitz (1988) proposed stablemodel semantics, allow self-support: set stable model P iff-least supported model P , P obtained P (1) eliminatingrule whose body contains literal , (2) deleting literalsform bodies remaining rules (Gelfond & Lifschitz, 1988).write st(P ) set stable models P . follows definition st(P )-antichain: M1 6= M2 st(PP) M1 6 M2 . size measure defineka Bk = |B| + 1 rules kP k = rP krk programs.example, consider vocabulary = {a, b, c} logic programP = {a {b} , b {a} , c {not a}}. find su(P ) = {{c} , {a, b}} st(P ) = {{c}}.2.2 Argumentation FrameworksDung (1995) introduced argumentation frameworks pairs F = (A, R) set(abstract) arguments R relation attack arguments.purpose semantics argumentation frameworks determine sets arguments (calledextensions) acceptable according various standards. given extensionA, arguments considered accepted, attackedargument considered rejected, others neither, statusundecided. interested so-called stable extensions, sets argumentsattack attack arguments set. stable extensions,argument either accepted rejected definition, thus semantics two-valued.formally, set arguments conflict-free iff a, b (a, b) R.set stable extension (A, R) iff conflict-free \argument b (b, a) R. AF F , denote set stable extensionsst(F ). Again, follows definition stable extension set st(F ) always-antichain. size argumentation framework F = (A, R) kF k = |A| + |R|.example, AF F = ({a, b, c} , {(a, b), (b, a), (b, c)}) visualised usingc set stable extensions st(F ) = {{a, c} , {b}}.bdirected graph2.3 Abstract Dialectical Frameworksabstract dialectical framework tuple = (A, L, C) set statements(representing positions one take take debate), L set links(representing dependencies positions), C = {Ca }aA collection totalfunctions Ca : 2par (a) {t, f }, one statement A. function Ca calledacceptance condition expresses whether accepted, given acceptance200fiExpressiveness Two-Valued Semantics ADFsstatus parents par (a). paper, represent Ca propositional formulapar (a). mentioned earlier, propositional formulas built using negation ,conjunction disjunction ; connectives material implication , logical equivalenceexclusive disjunction = regarded abbreviations. specify acceptancecondition, then, take Ca (M par (a)) = hold iff model , |= .Brewka Woltran (2010) introduced useful subclass ADFs: ADF = (A, L, C)bipolar iff links L supporting attacking (or both). link (b, a) L supporting iff par (a), Ca (M ) = implies Ca (M {b}) = t.Symmetrically, link (b, a) L attacking iff par (a),Ca (M {b}) = implies Ca (M ) = t. link (b, a) supporting attackingb influence a, link redundant (but violate bipolarity).sometimes use circumstance searching ADFs; simply assumeL = A, links actually needed expressed acceptance conditions make redundant.numerous semantics ADFs; interested two them,(supported) models stable models. set model ifffind iff Ca (M ) = t. definition stable models inspired logicprogramming slightly complicated (Brewka et al., 2013). Define operator by4(X, ) = (ac(X, ), re(X, )) X, A,ac(X, ) = {a | Z : X Z \ Ca (Z) = t}re(X, ) = {a | Z : X Z \ Ca (Z) = f }intuition behind operator follows: pair (X, ) represents partial interpretation set statements X accepted (true), rejected(false), \ (X ) neither. operator checks statementwhether total interpretations possibly arise (X, ) agree truthvalue acceptance condition a. is, accepted matterstatements \ (X ) interpreted, acc(X, ). set rej (X, ) definedsymmetrically, pair (acc(X, ), rej (X, )) constitutes refinement (X, ).A, reduced ADF DM = (M, LM , C ) defined LM = Lsetting/ ], is, replacing b/ false= [b/ : bacceptance formula a. model stable model iff least fixpointoperator DM given (M, ). usual, su(D) st(D) denote respective modelsets; ADF modelsP-related, ADF stable models cannot. size ADFgiven kDk = aA ka k; size kk formula numbernodes.example ADF D, consider vocabulary = {a, b, c} acceptance formulas= c, b = c, c = b. single supported model, su(D) = {{a, b, c}},find st(D) = since atoms model support circularly.2.4 Translations Formalismsreview known translations mentioned formalisms.4. operator closely related ultimate approximation operators Denecker, Marek,Truszczynski (2004), observed earlier (Strass, 2013).201fiStrass2.4.1 AFs BADFsBrewka Woltran (2010) showed translate AFs ADFs: AF FV= (A, R),define ADF associated F DF = (A, R, C) C = {a }aA = (b,a)R bA. Clearly, resulting ADF bipolar: parents always attacking. BrewkaWoltran proved translation faithful AF stable extension ADFmodel semantics (Proposition 1). Brewka et al. (2013) later proved AFstable extension ADF stable model semantics (Theorem 4). easy seetranslation computed polynomial time induces linear blowup.2.4.2 ADFs PLBrewka Woltran (2010) also showed ADFs supported model semanticsfaithfully translated propositional logic: acceptance conditions statements represented propositional formulas , supported modelsADF given classical propositional models formula set= {a | A}.2.4.3 AFs PLcombination, previous two translations yieldn polynomialVfifaithfulotranslationfichain AFs propositional logic: (A,R) =(b,a)R b fi .2.4.4 ADFs LPsearlier work (Strass, 2013), showed ADFs faithfully translated normallogic programs. ADF = (A, L, C), standard LPPD = {a (M (par (a) \ )) | A, Ca (M ) = t}follows Lemma 3.14 Strass (2013) translation preserves supportedmodel semantics. translation size-preserving acceptance condition representation Strass (2013) via characteristic models; representing acceptance conditionsvia propositional formulas, cannot guaranteed show later.52.4.5 AFs LPstranslation chain AFs ADFs LPs compact, faithful AF stablesemantics LP stable semantics (Osorio, Zepeda, Nieves, & Cortes, 2005), AF stablesemantics LP supported semantics (Strass, 2013). size-preserving since singlerule atom contains attackers once: P(A,R) = {a {not b | (b, a) R} | A}.5. Already complexity reasons, cannot expect translation also faithful stablesemantics. indeed, ADF = ({a} , {(a, a)} , {a = a}) stable model {a}standard logic program P (D) = {a {a} , {not a}} stable model. However, holdsst(P (D)) st(D) (Denecker et al., 2004; Strass, 2013).202fiExpressiveness Two-Valued Semantics ADFs2.4.6 LPs PLwell-known logic programs supported model semantics translatedpropositional logic (Clark, 1978). logic program P becomes propositional theory P ,_^^P = {a | A} =bb A.aBPbB +bBstable model semantics, additional formulas added, extendedtranslation works (Lin & Zhao, 2004).2.4.7 LPs ADFsClark completion normal logic program directly yields equivalent ADFsignature (Brewka & Woltran, 2010). Clearly translation computablepolynomial time blowup (with respect original logic program)linear. resulting translation faithful supported model semantics, followsLemma 3.16 Strass (2013).2.5 Representing Bipolar Boolean Functionsbipolarity hitherto predominantly defined used contextADFs (Brewka & Woltran, 2010), easy define concept Boolean functionsgeneral. Let set atoms f : 2A {t, f } Boolean function. atomsupporting iff A, f (M ) = implies f (M {a}) = t; write sup(f ).atom attacking iff A, f (M ) = f implies f (M {a}) = f ;write att(f ). Boolean function f : 2A {t, f } semantically bipolar iffsupporting attacking both. Throughout paper, sometimes take Booleanfunction given interpretation set say set bipolar.define bipolar propositional formulas representing bipolar ADFs.important study, also since (for three-valued semantics), bipolaritykey BADFs low complexity comparison general ADFs (Strass & Wallner, 2015).now, usually assumed specify bipolar ADF, addition statements,links acceptance conditions, user specifies link whether supportingattacking (Strass & Wallner, 2015). introduce arguably simpler way,support attack represented syntax propositional formula encodingacceptance function.Formally, polarity atom formula determined numbernegations path root formula tree atom. polarity positivenumber even negative number odd.Definition 4. propositional formula syntactically bipolaratom occurs positively negatively .Recall use formulas basis {, , } thus hiddennegations, e.g. material implication. formulas negation normal form (that is,negation applied atomic formulas), polarities atoms readformula directly.203fiStrassaddress question represent bipolar Boolean functions. ClearlyBoolean functions represented propositional formulas; modify constructionlater thus reproduce here: Boolean function f : 2A {t, f }, associatedformula^^_(1)=f =A,f (M )=taA\Mis, exactly one model , f enumerates models.particular, bipolar Boolean functions represented propositional formulas well. However, guarantees us existence representationsgives us way actually obtain them. first fundamental result showsconstruct syntactically bipolar propositional formula given semantically bipolarBoolean function. converse straightforward, thus two notions bipolarityclosely related. formula , associated Boolean function f returnsgets input model .Theorem 1. Let set atoms.1. syntactically bipolar formula A, Boolean function f semanticallybipolar.2. semantically bipolar Boolean function f : 2A {t, f }, syntactically bipolarformula f ff = f givenf =_=A,f (M )=t^aM,aatt(f/)^(2)aA\M,asup(f/)Proof.1. Obvious: every atom occurring positively supporting, every atom occurring negatively attacking.2. Let f : 2A {t, f } semantically bipolar. Note first (2),|= . easy see f syntactically bipolar: Since fsemantically bipolar, is: (1) attacking supporting,occurs negatively f ; (2) supporting attacking, occurspositively f ; (3) supporting attacking, occur f .remains show ff = f ; show |= f f .|= f f : Let v : {t, f } v(f ) = t.f (M ) = v(M ) = t. (Clearly v = vM .) |= get v(M ) =thus v(f ) = t.|= f f : model v f , f (M ) =v(M ) = t. show model f model f , showf (M ) = t, model v model f . Let |A| = n.contains exactly n literals. correspondingk N 0 k n contains exactly n k literals. two204fiExpressiveness Two-Valued Semantics ADFsinterpretations v1 : {t, f } v2 : {t, f }, define difference(v1 , v2 ) = {a | v1 (a) 6= v2 (a)}. (Note |A| = n always|(v1 , v2 )| n.) use induction k show following:f (M ) = t, v : {t, f } v(M ) = |(v, vM )| = kfind v(f ) = t. covers models v f (since |(v, vM )| |A|)thus establishes claim.k = 0: (v, vM ) = implies v = vM whence v(f ) = vM (f ) = vM (M ) =definition f .kk + 1: Let f (M ) = t, v : {t, f } v(M ) =|(v, vM )| = k + 1. Since k + 1 > 0, (v, vM ), is,v(a) 6= vM (a).(a) supporting attacking. necessarily v(a) = t. (If v(a) = f ,vM (a) 6= v(a) implies vM (a) = t, is, whence {M } |=v(M ) = f , contradiction.) Define interpretation w : {t, f }w(a) = f w(c) = v(c) c \ {a}. Clearly (v, w) = {a}|(w, vM )| = k. Hence induction hypothesis applies ww(f ) = t. w(a) = f , v(a) = w(f ) = t. Since supporting, also v(f ) = t.(b) attacking supporting. Symmetric opposite case above.(c) supporting attacking. Define interpretation w : {t, f }w(a) = vM (a) w(c) = v(c) c \ {a}. follows|(w, vM )| = k, whence induction hypothesis applies ww(f ) = t. Since supporting attacking (thus redundant),get v(f ) = w(f ) = t.result paves way analysing succinctness bipolar ADFs, sincequite natural way representing them.3. Relative Expressivenessanalyse compare relative expressiveness argumentation frameworks(AFs), (bipolar) abstract dialectical frameworks ((B)ADFs), normal logic programs (LPs)propositional logic (PL). first look different families semantics supportedstable models isolation afterwards combine results two semantics.formalisms F {ADF, LP} supported stable semantics,indicate semantics via superscript Definition 1. AFs considerstable semantics, (to date) semantics AFs interpretationsguaranteed map arguments either true (accepted) false (rejected, i.e. attackedaccepted argument). propositional logic PL consider usual model semantics.syntactic translations reviewed previous section, currentlyfollowing expressiveness relationships. supported semantics,AF e BADFsu e ADFsu=e LPsu e PLstable semantics,205fiStrassAF e LPst <e PL AF e BADFst e ADFst <e PLNote LPst <e PL ADFst <e PL hold since sets stable models antichainproperty, contrast model sets propositional logic.succinctness relation,AF BADFsu ADFsu PL LPsu ADFsu3.1 Supported Semanticsdepicted above, know expressiveness AFs propositional logicdecrease. However, yet clear relationships strict. followsshow two strict, working way top-down leastexpressive.3.1.1 ADF vs. PLfirst show ADFs realise set models showing given propositionalformula used construct equivalent ADF linear size.6Theorem 2. PL e ADFsu PL ADFsu .Proof. Let propositional formula vocabulary A. Define ADFsetting, A,= = (a ) (a )Thus ka k O(kk), whence kD k O(|A| kk). remains toVshow su(D ) = mod ().Recall ADF A, su(D) = mod (D ) = aA (a ). Applyingdefinition yieldsV= aA (a (a ))A, formula (a (a ))Vis equivalent . (The proof casedistinction a.) Thus equivalent aA , is, , followssu(D ) = mod (D ) = mod ().example, consider vocabulary = {a, b} propositional formula = b.canonical construction yields ADF acceptance formulas = (a b)b = b (a b). have:= (a b) = (a (a b)) ((a b) a) (a b) bIntuitively, = b expresses cannot false, true b true.symmetrical argument, acceptance formula b equivalent b a. readilychecked su(D ) = {{a, b}} desired. Since know Section 2.4.2converse translation also possible (ADFsu PL), get following.Corollary 3. PL=s ADFsu6. consider vocabulary part input, size increase quadratic.206fiExpressiveness Two-Valued Semantics ADFsacceptance conditions written propositional formulas, constructionrealise X 2A proof Theorem 2 defines space-efficient equivalent__=X,aMA,M X,a//acceptance formula a, Footnote 3.3.1.2 ADF vs. LPSince ADFs supported semantics faithfully translated logic programs,likewise translated propositional logic, following.Corollary 4. ADFsu=e LPsu=e PLHowever, extend succinctness relation, logic programs stipulateparticular syntactic form essentially fixed-depth circuit. specifically,easy see language polynomially expressible normal logic programssupported semantics AC0 . stable semantics so-called canonical logicprograms, recently shown Shen Zhao (2014) (Proposition 2.1).case interested (supported semantics) works similarly, still presentproof completeness. main technical result towards proving lemma showingturn logic program equivalent Boolean circuit fixed depth.Lemma 5. every normal logic program P , exists circuit CP basis{, , } that:1. CP accepts supported models P ,2. size CP linear size P ,3. CP depth 4.Proof. Let = {a1 , . . . , } vocabulary P , Clark completion P ={ai | ai A}V DNFs literals A. Clearly circuit Pmust compute CP = ai (ai ) ai replaced (ai )(ai )CNF literals A. construction depicted follows,inner layers shown one only, dotted lines represent potential edges.ai......a1a1...ai...aiai207......fiStrass(1) follows since su(P ) = mod (P ) CP accepts models P .(2), P contains = |P | rules, kP k total number inner gatesbounded n(2m + 3) n(2 kP k + 3). (3) clear.statement Lemma 5 actually much stronger gives constant upperbound resulting circuit depth arbitrarily-sized logic programs, readily followsset polynomially logic-program expressible languages subset languagesexpressible alternating Boolean circuits unbounded fan-in constant depth.Proposition 6. L polynomially expressible normal logic programs supportedsemantics, L AC0 .follows immediately normal logic programs cannot polynomially expresslanguage Parity.7 supported-semantics counterpart Theorem 3.1 (Shen& Zhao, 2014).Corollary 7. Parity polynomial size normal logic program representation.Proof. Proposition 6 Parity/ AC0 (Jukna, 2012).follows propositional logic strictly succinct normal logic programssupported semantics.Corollary 8. PL 6s LPsu thus LPsu <s PL.considerations since Theorem 2, follows small conjunctivenormal form (a conjunction clauses) disjunctive normal form (disjunction monomials) representation, also small normal logic program representationmod ().3.1.3 ADF vs. BADFquite obvious canonical ADF constructed Theorem 2 bipolar, sincewell every atom mentioned occurs positively negatively .raises question whether construction adapted bipolar ADFs.turns subclass bipolar ADFs strictly less expressive. Towardsproof result start new concept: conjugate model setrespect atom. concept used characterise ADF realisabilityprecisely captures if-and-only-if part ADFs supported model semantics:translation ADF propositional logic V(cf. Section 2.4.2) see resultbasically conjunction equivalences: = aA (a ). conjunction partcaptured set intersection, conjugate capture equivalence part.Definition 5. Let vocabulary, X 2A A. a-conjugate X sethai(X) = {M | X, } {M |/ X,/ M}7. Logic programs supported models universally expressive, express Parity,polynomial size.208fiExpressiveness Two-Valued Semantics ADFsAlternatively, could write hai(X) = {M | X }. Intuitively, hai(X)contains interpretations containment coincides exactly containment X. Formulated terms propositional formulas, X model setformula A, hai(X) model set formula . Note vocabularyimplicit conjugate function.Example 1. Consider vocabulary A2 = {a, b}. functions hai() hbi() operateset 22 2 interpretation sets A2 shown Table 1.bbbabbba=bababbabba>hai()bbbab>aba=bbbbabababhbi()bbbbbaab>a=babbababbTable 1: Conjugation functions A2 = {a, b}. Interpretation sets represented usingformulas A2 , connective = denotes exclusive disjunction XOR.two-valued ADF semantics, conjugation function plays essential semanticalrole, since provides bridge models acceptance functions modelsADF. also interesting itself: first show properties conjugationfunction associated atom, since used proof later on. Firstall, involution, is, inverse (and thus particular bijection). Next,compatible complement operation (logical negation formula level).Finally, also preserves evenness cardinality input set.Proposition 9. Let vocabulary, X 2A A.1. hai(hai(X)) = X.(involution)2. 2A \ hai(X) = hai 2A \ X .(compatible negation)3. |X| even iff |hai(X)| even.(preserves evenness)Proof. Let |A| = n, X 2A A.209fiStrass1. Let A.hai(hai(X)) iff hai(X)iff (M X )iff X (a )iff X2. DenoteS, = {M | X, }S,/ = {M | X,/ M}S,= {M |/ X, }/S,/ X,/ M}// = {M |observe2A = S, ] S,/ ] S,/ ] S,//X = S, ] S,/hai(X) = S, ] S,//] denotes disjoint union.2A \ hai(X) = 2A \ S, ] S,//= S,/ ] S,/= {M | X,/ } ] {M |/ X, }fifi= AfiM/ 2 \ X,/ ] fi 2A \ X,= hai 2A \ X3. show |X| + |hai(X)| even. Firstly,S,/ ] S,/ } = 2A\{a}// = {M |fifi fifin1 . Thusfiwhence fiS,/ fi + fiS,// =2fififififi|X| + |hai(X)| = |S, | + fiS,/ fi + |S, | + fiS,//fifi fififi= 2 |S, | + fiS,/ fi + fiS,//= 2 |S, | + 2n1even.current purpose characterising expressiveness bipolar ADFs,use concept conjugation make ADF realisability model semantics slightlyaccessible. show ADF realisation model set X n-elementvocabulary equivalently characterised n-tuple (Y1 , . . . , Yn ) supersets Xwhose intersection exactly X. crux proof result acceptanceconditions realising ADF Yi related conjugation function.210fiExpressiveness Two-Valued Semantics ADFsProposition 10. Let = {a1 , . . . , } vocabulary X 2A set interpretations. Denote ADF sequence (1 , . . . , n ) acceptance formulas (for{1, . . . , n}, formula acceptance formula ai ), defineCX = {(mod (1 ), . . . , mod (n )) | su(1 , . . . , n ) = X}fi(!)nfi\fiYX = (Y1 , . . . , Yn ) fi Y1 , . . . , Yn 2A ,Yi = Xfii=1sets CX YX one-to-one correspondence; particular |CX | = |YX |.Proof. provide bijection CX YX . Consider functionnn(B1 , . . . , Bn ) 7 (ha1 i(B1 ) , . . . , han i(Bn ))22f : 22involution Proposition 9. Using results Section 2.4.2, get(mod (1 ), . . . , mod (n )) CX iff su(1 , . . . , n ) = X^iff mod(ai ) = X1iniff\mod (ai ) = X1iniff\hai i(mod (i )) = X1iniff (ha1 i(mod (1 )) , . . . , han i(mod (n ))) YXiff f (mod (1 ), . . . , mod (n )) YXThus f (CX ) = YX whence f (YX ) = f (f (CX )) = CX f |CX : CX YX bijective.one-to-one correspondence important since later analyse precisenumber realisations given model sets. Furthermore, result shows roleconjugation function characterising two-valued model realisability general ADFs.adapt characterisation result case bipolar ADFs. precisely,give several necessary sufficient conditions given model set bipolarly realisable.characterisation hand, later show specific interpretation set failsnecessary conditions thus cannot model set BADF.Below, fiwe denoteset supersets set X interpretation sets X = 2A fi X .Proposition 11. Let = {a1 , . . . , } vocabulary X 2A set interpretations. following equivalent:1. X bipolarly realisable.2. exist Y1 , . . . , Yn X that:(a) ( ni=1 Yi ) = X,211fiStrass(b) 1 n, set hai i(Yi ) bipolar.3. exist Y1 , . . . , Yn X(a) ( ni=1 Yi ) = X,(b) 1 i, j n, least one :A, (M Yi ai ) (M {aj } Yi ai {aj });N A, (N Yi = ai N ) (N {aj } Yi = ai N {aj }).Proof. (1) (2): X bipolarly realisable, exists bipolar ADF = (A, L, C)su(D) = X. particular, exist bipolar Boolean functions C1 , . . . , CnX 1 n find ai iff Ci (M ) = t.1 n define YT= hai i(Ci ). assumption, hai i(Yi ) = hai i(hai i(Ci )) = Ci bipolar; furthermore ( ni=1 Yi ) = X follows above.(2) (3): Let {1, . . . , n} assume hai i(Yi ) bipolar. meansaj A, find aj supporting attacking (or both) hai i(Yi ). ajsupporting haj i(Yi ) iff find:hai i(Yi ) {aj } hai i(Yi ) , is,(M Yi ai ) (M {aj } Yi ai {aj })Similarly, aj attacking hai i(Yi ) iff N find:N/ hai i(Yi ) N {aj }/ hai i(Yi ) , is,(N Yi ai N ) (N {aj } Yi ai N {aj })Thus aj A, find least one following:A, (M Yi ai ) (M {aj } Yi ai {aj });N A, (N Yi = ai N ) (N {aj } Yi = ai N {aj }).(3) (1): construct ADF = (A, L, C) follows: {1, . . . , n} define Ci = hai i(Yi ) finally set L = A. Ci bipolar equivalencesestablished previous proof item, su(D)= X follows facthai i(Ci ) = hai i(hai i(Yi )) = Yi presumption ( ni=1 Yi ) = X.apply characterisation result show interpretation setthree atoms cannot realised bipolar ADFs model semantics.smallest example terms number atoms (actually, one two smallestexamples) interpretation sets binary vocabulary bipolarly realisable.Proposition 12. vocabulary A3 = {1, 2, 3}, bipolar ADF realisesX = Even3 = {, {1, 2} , {1, 3} , {2, 3}}.212fiExpressiveness Two-Valued Semantics ADFsProof. Assume contrary X bipolarly realisable. exist Y1 , Y2 , Y3 XProposition 11. 2|2 ||X| = 284 = 24 = 16 candidates Yi , is,every Yi must form X ] ZZ {{1} , {2} , {3} , {1, 2, 3}} = 2A \ Xeleven sixteen model set candidates Yi , set hii(Yi )bipolar. show model set hii(Yi ) bipolar, provide statement j A3neither supporting attacking; say statement dependent.1. Y1 = X, get h1i(Y1 ) = {{1, 2} , {1, 3} , {2} , {3}}, bipolar sincestatement 2 dependent: 2 supporting, {3} h1i(Y1 ) would imply{2, 3} h1i(Y1 ); 2 attacking,/ h1i(Y1 ) would imply {2}/ h1i(Y1 ).remaining cases, justifications specific statement dependentequally easy read model set; brevity indicate statements.2. Y1 = X {{1}}, get h1i(Y1 ) = {{1, 2} , {1, 3} , {1} , {2} , {3}},bipolar since statement 2 dependent.3. Y1 = X {{2}}, get h1i(Y1 ) = {{1, 2} , {1, 3} , {3}}, bipolar sincestatement 2 dependent.4. case Y1 = X {{3}} symmetric previous one: get model seth1i(Y1 ) = {{1, 2} , {1, 3} , {2}}, bipolar since statement 3 dependent.5. Y1 = X {{1, 2, 3}}, get h1i(Y1 ) = {{1, 2, 3} , {1, 2} , {1, 3} , {2} , {3}},bipolar since statement 2 dependent.6. Y1 = X {{1} , {2}}, get h1i(Y1 ) = {{1, 2} , {1, 3} , {1} , {3}},bipolar since statement 3 dependent.7. case Y1 = X {{1} , {3}} symmetric previous one.8. Y1 = X {{2} , {3}}, get h1i(Y1 ) = {{1, 2} , {1, 3}}, bipolar sincestatement 2 dependent.9. Y1 = X {{1} , {1, 2, 3}}, get h1i(Y1 ) = {{1, 2, 3} , {1, 2} , {1, 3} , {1} , {2} , {3}},bipolar since statement 2 dependent.10. Y1 = X {{2} , {1, 2, 3}}, get h1i(Y1 ) = {{1, 2, 3} , {1, 2} , {1, 3} , {3}},bipolar since statement 2 dependent.11. Y1 = X {{3} , {1, 2, 3}} symmetric previous case.remains set C five candidates (due symmetry i):C = {X ] {{1} , {2} , {3}} ,X ] {{1} , {2} , {1, 2, 3}} ,X ] {{1} , {3} , {1, 2, 3}} ,X ] {{2} , {3} , {1, 2, 3}} ,X ] {{1} , {2} , {3} , {1, 2, 3}}}213fiStrassBasically, candidates least three four interpretations= {{1} , {2} , {3} , {1, 2, 3}} contained addition already X. clearlyassumption Yi realise X1 , Y2 , Y3C.T3Yi 1 3 thusi=1 Yi = X. However, X = .Contradiction. Thus Yi exist X bipolarly realisable.interpretation set A3 bipolarly realisable, foundcomplement Even3 above, Parity language three atoms.Proposition 13. vocabulary A3 = {1, 2, 3}, bipolar ADF realisesParity3 = {{1} , {2} , {3} , {1, 2, 3}}.Together straightforward statement fact Even3 realisednon-bipolar ADF, Proposition 12 leads next result.Theorem 14. BADFsu <e ADFsuProof. Model set Even3 Proposition 12 realisable model semantics ADFDEven3 acceptance conditions1 = (2 = 3),2 = (1 = 3),3 = (1 = 2)However, bipolar ADF realising Even3 , witnessed Proposition 12.Another consequence characterisation two-valued model realisability Proposition 10 get precise number distinct realisations given model set.significant illustrates rather intricate difficulty underlying bipolar non-realisability: cannot necessarily use model set Even3 determinesingle reason bipolar non-realisability, is, single link (b, a) neither supporting attacking realisations. Rather, culprit(s) might differentrealisation, show bipolar non-realisability, prove realisations,necessarily exists reason non-bipolarity. number different ADFrealisations given model set X considerable.8Propositionfifi 15. Let vocabulary |A| = n, X 2 interpretation setfi2 \ X fi = m. number distinct ADFs su(D) = Xr(n, m) = (2n 1)mProof. According Proposition10,T realisationtufifi X characterisednn tuples.ple (Y1 , . . . , Yn ) X X = ni=1 Yi . Since fiX fi = 2m , (2m )THowever,Ttowards r(n, m), wrongly counts tuples (Y1 , . . . , Yn ) ( ni=1 Yi ) ) X,is, |( ni=1 Yi ) \ X| > 0 (at least once); remains subtract{1, . . . , n},n them.overestimate number tuples (Y1 , . . . , Yn ) X |( ni=1 Yi ) \ X|expressionnq(n, m, i) =2mi(3)8. counting ADFs A, take account different link relations, take L =count different acceptance functions, redundant links modelled.214fiExpressiveness Two-Valued Semantics ADFsseen follows: Let 2A \ X fixed i-element set. (Intuitively, interpretation-set X containsinterpretations many.)mi sets.fi exactlyfinI, fiI fi = 2mi . Thus 2mi possible ways choose nelements (the Y1 , . . . , Yn ) . matter Yj chosen, intersectioncontains thus least elements many. However, sets least+ 1 elements many counted twice subtracted. subtractq(n, m, + 1), counted sets least + 2 elements manyadd q(n, m, + 2),inclusion-exclusion principle, numbern etc. Hencetuples (Y1 , . . . , Yn ) X ni=1 Yi = X givenr(n, m) = q(n, m, 0) q(n, m, 1) + q(n, m, 2) . . . q(n, m, m)X=(1)i q(n, m, i)i=0Xn=(1)2mii=0X=(2n )mi (1)i(by (3) above)(reordering factors)i=0n= (2 1)m(binomial theorem)main contributing factor number interpretations excludeddesired model set X. Proposition 12, instance, (23 1)4 = 74 = 2401ADFs model set Even3 . According Theorem 14, none bipolar. Obvinously, maximal number realisations achieved X = whence r(n, 2n ) = (2n 1)2 .hand, model set X = 2A exactly one realisation, r(n, 0) = 1. Notenumber (syntactically distinct) realisations universally expressiveformalisms, logic programs propositional logic, unbounded general sinceadd arbitrary number tautologies.finally show reduction problem bipolar realisability propositionalsatisfiability. approaches problem another angle (a possible implementationdeciding bipolar realisability using SAT solver), provides proof Theorem 3Strass (2015b), contained work.given vocabulary set X 2A set interpretations, aimconstruct propositional formula X satisfiable X bipolarlyrealisable. propositional signature use following: A,propositional variable pMexpresses whether Ca (M ) = t. allowsencode possible acceptance conditions statements A. enforce bipolarity,use additional variables model supporting attacking links: a, b A,a,bvariable pa,bsup saying supports b, variable patt saying attacks b.vocabulary X givenfina,b fia,bP = pM,p,pA,A,bfisup attguarantee desired set models, constrain acceptance conditions dictatedX: desired set statement a, containment must correspond215fiStrassexactly whether Ca (M ) = t; encodedX . Conversely, undesired set/statement a, must correspondence,X expresses.enforce bipolarity, state link must supporting attacking. modelmeaning support attack, encode ground instances definitions.Definition 6. Let vocabulary X 2A set interpretations. Definefollowing propositional formulas:/BADF=XX X bipolar^^^pMpMX =XaA\M^/X =_A,M X/bipolar =^_pMpMaA\Ma,ba,ba,bpa,bsup patt sup atta,bAa,bsup= pa,bsupa,battpa,batt^(a, b A)(a, b A){a}pMb pb=^{a}pbpMbcorresponding result shows reduction correct.Theorem 16. Let vocabulary X 2A set interpretations. X bipolarlyrealisable BADFsatisfiable.XProof. if: Let P model X . A, define acceptance condition follows: A, set Ca (M ) = iff pMI. easy see bipolarguarantees acceptance conditions bipolar. ADF givensu = (A, A, C). remains show model suDXXX.su . Consider A.if: Let X. show model DX1. . Since modelX , pa thus definitionCa (M ) = t./ thus definition2. \ . Since modelX , paCa (M ) = f ./if: Let/ X. Since modelX ,Ca (M ) = f/ Ca (M ) = t. case, modelsu .DXif: Let bipolar ADF su(D) = X. use define model X .First, A, set pMiff Ca (M ) = t. Since bipolar, linksupporting attacking a, b find valuation pa,bsuppa,b.remainsshowmodel.Xatt216fiExpressiveness Two-Valued Semantics ADFs1. modelX : Since realises X, X model thusCa (M ) = iff ./2. model/ X modelX : Since realises X,D. Thus , witnessing modelD: (1) Ca (M ) = f , (2)/ Ca (M ) = t.3. model bipolar : straightforward since bipolar assumption.Remarkably, decision procedure give answer, casepositive answer read BADF realisation satisfying evaluationconstructed formula. illustrate construction example seen earlier.Example 2. Consider A3 = {1, 2, 3} model set Even3 = {, {1, 2} , {1, 3} , {2, 3}}.construction Theorem 16 yields formulas:{1}Even3 = p1 p2 p3{1,2}p2{1,3}p2p1p1{1,2}{2,3}p1/Even3 = (p1{1,2}(p1{1,3}(p1p3{1,3}p3{2,3}p3p2{2,3}{1}p3 ){2}p2{1}{2}p2p3 ){3}p2{3}p3 ){1,2,3}(p1{2}{3}{1,2,3}p2{1,2,3}p3)remaining formulas bipolarity independent Even3 , showhere. implemented translation proof Theorem 16 used solverclasp (Gebser, Kaminski, Kaufmann, Ostrowski, Schaub, & Schneider, 2011) verifyEven3 unsatisfiable.3.1.4 BADF vs. LPEarlier, used language Parity show propositional logic (and thusPL=s ADFsu general ADFs are) exponentially succinct normal logic programs(under supported models). However, bipolar ADFs, Proposition 13 BADFA3 = {1, 2, 3} model set su(D) = Parity3 = {{1} , {2} , {3} , {1, 2, 3}}, is,BADFs cannot even express Parity. Fortunately, Majority language trickcase.Theorem 17. BADFsu 6s LPsuProof. show language Majority polynomially expressed BADFsu ,LPsu . latter fact follows Majority/ AC0 (Jukna, 2012) Proposition 6. show first part constructing series BADFs Dn = {a1 , . . . , }(n N, n 1) su(Dn ) = Majorityn . use results (Friedman, 1986; Boppana, 1986), show positive n N k n, language Thresholdn,knegation-free propositional formulas Thresholdpolynomial size s, usen,k4.27bound Boppana, k n log n . Define D1 a1 = >, n 2 set k = n21 n,ai = ai Threshold(a1 , . . . , ai1 , ai+1 , . . . , )n1,k217fiStrassIntuitively, formula ai checks whether remaining variables could achieve majoritywithout ai . so, ai set arbitrarily; otherwise, ai must set true. ClearlyBoolean function computed ai bipolar, since ai supporting parentsattacking. size Dn , observekDn k n Thresholdn1,kwhence overall size polynomial. remains show su(Dn ) = Majorityn .: Let Majorityn . show su(Dn ), is, iff |=. , immediate |= , let aj/j {1, .. . ,n}. show 6|= aj . Since Majorityn , |M | =k = n2 n 1 Thresholdn1,k , is,|= Threshold(a1 , . . . , aj1 , aj+1 , . . . , )n1,kTogether 6|= aj , follows 6|= aj .: Let/ Majorityn . |M | = 0 < n2 = k. particular,aj \ . < k implies N Thresholdn1,k(a1 , . . . , aj1 , aj+1 , . . . , ) whence follows|N | = = |M |. Thus 6|= Thresholdn1,k|= aj . Together 6|= aj conclude/ su(Dn ).Since every BADF ADF size, get:Corollary 18. ADFsu 6s LPsucombination translation logic programs ADFs (implying relationLPsu ADFsu ), means also ADFs strictly succinct logic programs.Corollary 19. LPsu <s ADFsu3.1.5 BADF vs. AFcomparably easy show BADF models strictly expressive AFs,since sets supported models bipolar ADFs antichain property.Proposition 20. AF <e BADFsuProof. Consider vocabulary = {a} BADF = (A, {(a, a)} , {a }) = a.straightforward check model set su(D) = {, {a}}. Since model sets AFsstable extension semantics satisfy antichain property, equivalent AFA.yields following overall relationships:AF <e BADFsu <e ADFsu=e LPsu=e PLconcise overview relative succinctness, present results open problemsglance Table 2 below.99. remark three open problems Table 2 really two: easy show ADFspropositional logic behave equivalently relation bipolar ADFs, since equally expressiveequally succinct; is, holds ADFsu BADFsu PL BADFsu .218fiExpressiveness Two-Valued Semantics ADFssuBADFADFsuLPsuPLBADFsu=???ADFsu=<s=sLPsu6s6s=6sPL=s<s=Table 2: Relative succinctness results (bipolar) ADFs model semantics, normallogic programs supported semantics, classical propositional logic. entryrow F1 column F2 means F1 F2 .3.2 Stable Semanticsbefore, recall current state knowledge:AF e BADFst e ADFst <e PL AF e LPst <e PLfirst show BADFs strictly expressive AFs.Proposition 21. AF <e BADFstProof. Consider set X2 = {{a, b} , {a, c} , {b, c}} desired models. Dunne et al. (2015)proved X2 realisable stable AF semantics. However, model set X2realisable BADF DX2 stable semantics:= b c,b = c,c = bLet us exemplarily show = {a, b} stable model (the cases completelysymmetric): reduct DM characterised two acceptance formulas = bb = . easily find DM (, ) = (M, ) = DM (M, ).Intuitively, argument AF non-realisability X2 follows: Since b occurextension together, attack them. holdspairs a, c b, c. set {a, b, c} conflict-free thus must stableextension containing three arguments, allowed X2 . reason AFsrestriction individual attack, set attack (also called joint collective attack) sufficesrealise X2 seen above.construction used proof realize X2 comes workEiter, Fink, Puhrer, Tompits, Woltran (2013) logic programming,generalised realise non-empty model set satisfying antichain property.st = (A, L, C) CDefinition 7. Let X 2A . Define following BADF DXgiven_^=bX,aMbA\Mthus L = {(b, a) | X, M, b \ }.219fiStrassnext result shows construction indeed works.st ) = X.Theorem 22. Let X =6 X 2A -antichain. find st(DXProof. Let A.st ) st(D st ); use case distinction.: Let/ X. show/ su(DXX1. N X ( N . N \ . ConsideracceptanceV formula . Since N N X, formula disjuncta,N = bA\N b. N implies \ N \ modelst ).a,N . Thus model although/ , hence/ su(DX2. N X, 6 N . X 6= implies 6= , let .V N X N , acceptance formula contains disjuncta,N = bA\N b. assumption, N X bN \ N .Clearly bN \ N bN evaluated true . Hence N XN , disjunct a,N evaluated false . Thus falsest )./ su(DXst ), is: A, find: Let X. first show su(DXiff model .st1. Let .V construction, DX contains disjunctform a,M = bA\M b. According interpretation , b \false thus a,M true whence true.2. Let \ consider acceptance formula . Assume contrarymodel V. N X Nmodel a,N = bA\N b, is, \ N \ . Hence N ; and,since N \ , even ( N , whence X -antichain. Contradiction.Thus model .st respect . There, containsconsider reduct DM DXdisjunct a,M = a,M [b/ : b/ ] b \ replaced false,= . . . equivalent true. Thus truewhence a,Mst ).least fixpoint DM thus st(DXrestriction non-empty model sets immaterial relative expressiveness, sinceuse construction Theorem 2 fact st(D) su(D) ADFrealize empty model set. stable model semantics ADFs logic programsantichain property, get:Corollary 23. ADFst e BADFst LPst e BADFstleads following overall relationships:AF <e BADFst=e ADFst=e LPst <e PLremark antichain property provides characterisation realisabilitystable semantics; is, model set stable-realisable iff -antichain.220fiExpressiveness Two-Valued Semantics ADFs3.3 Supported vs. Stable Semanticsput supported stable pictures together. proof Theorem 22,st antichain X, supportedread canonical realisation DXst ) = st(D st ) = X. observation, alsostable semantics coincide, is, su(DXXbipolar ADFs supported semantics realize antichain, this:Proposition 24. BADFst e BADFsuseen Proposition 20, bipolar ADFs supported-model setsantichains. get:Corollary 25. BADFst <e BADFsuresult allows us close last gap put together big picture relativeexpressiveness Figure 2 below.ADFsu=e PL=e LPsuBADFsuBADFst=e LPst=e ADFstAFFigure 2: expressiveness hierarchy. Expressiveness strictly increases bottomtop. F denotes formalism F semantics , su supported ststable model semantics; formalisms among AFs (argumentation frameworks), ADFs(abstract dialectical frameworks), BADFs (bipolar ADFs), LPs (normal logic programs)PL (propositional logic).4. Allowing Vocabulary Expansionhere, considered compact realisations, introduce new vocabulary elements. section, allow introduction small number newatoms/arguments/statements. precisely, small means number linearsize source knowledge base (representing model set wish realizetarget language). purpose realisability, new vocabulary elements projectedresulting models.turns out, adding additional arguments already makes AFs universally expressive(under projection). technically, show propositional formulavocabulary A, exists AF F expanded vocabularymodels stable extensions F correspond one-to-one. Roughly,possible since AFs regarded syntactic variant classical propositionallogic connective logical (Gabbay, 2011; Brewka et al.,2011). Using connective, negation expressed = disjunction221fiStrass= ( ) = ( ) ( ). equivalences used translate arbitrary propositional formulas (over , , ) syntactical -fragment; guaranteesize increase linear, introduce names subformulas (Tseitin,1968). next definition combines ideas.Definition 8. Let formula using , , vocabulary A. Define setsR inductively follows:A> = {a> }R> == {a }R = {(a , )}Ap = {p, ap } pRp = {(p, ap ), (ap , p)} p= {a }R = {(a , )} R= {a , , } R = {(a , ), (a , )} R R= {a , }R = {(a , ), (a , ), (a , )} R RAF associated given F = (A , R {(a , )} R ).argument a> unattacked thus part every stable extension (is true everyinterpretation); argument attacks thus cannot part stable extension (is false every interpretation). mutually attacking arguments p app serve guess valuation A, guarantee (and all)valuations models lead stable extensions F : intuitively, mustattacked, candidate . arguments attacks Booleanconnectives express usual truth-theoretic semantics, first technical resulttranslation shows.Lemma 26. Let formula vocabulary F associated AF.stable extension F , , have:iff/ M;iff ;iff one ;iff neither .Proof.definition, attacker argument form argument. Thus iff/ M.attackers arguments . case above,iff/ , iff/ . Consequently, iff// iff .attacker argument . Similarly previous cases,show iff// , iff/ .combination, iff .222fiExpressiveness Two-Valued Semantics ADFsattackers arguments . directly followsiff neither .correspondences used show induction newly introducedarguments capture semantics formulas encode (for subformulas ).Lemma 27. Let formula F associated AF. stable extensionF , iff model .Proof. Let stable extension F . use structural induction .= >: Trivial: a> since attackers.= : Trivial:/ since set {a } conflict-free.= p A: Trivial: p iff |= p definition.= : iff iff/ iff 6|= iff |= iff |= .= : iff iff iff |= |= iff |=iff |= .= : iff iff iff |= |= iff |=iff |= .= : iff iff// iff 6|= 6|= iff |=iff |= .lets us show main result section, namely AF stable extensionsemantics universally expressive projection.Theorem 28. Let formula vocabulary F associated AF.1. model , exists stable extension E F = E A.2. stable extension E F , set E model .Proof.1. Let model . Define setE = {a | , |= }Observe = E A. presumption, E. remains show Estable extension, is, E conflict-free attacks arguments b/ E.E conflict-free: Assume contrary attack r = (a, b) Ra, b E. definition, cases:arbitrary b = . definition E get |= ,contradiction.r = (p, ap ) r = (ap , p) p A. definition E get|= p |= p, contradiction.223fiStrassr = (a , ). definition E get |= |= ,contradiction.r = (a , ) r = (a , ). |= , |= |= ,contradiction.r = (a , ). |= , whence |= ( ). also |= ,contradiction.r = (a , ) r = (a , ). |= , |= |= .also |= , contradiction.E attacks arguments E: Let b (A {a }) \ E argument.definition, formula b = 6|= . use structuralinduction.= E attacks definition.= , |= whence E attacks definition.= , |= |= whence E E.case, E attacks definition.= , |= whence E attacks definition.= , |= whence E E.case, E attacks definition.2. Let E stable extension F . Since E conflict-free,/ E. Since E stable,E attacks , yields E. Lemma 27, E model .particular, F stable extension iff unsatisfiable. showsconstruction Definition 8 works intended, remains show number newarguments linear formula size. even show total increasesize linear, thus also number new arguments linear.Proposition 29. formula , find kF k O(kk).Proof. first notekF k = k(A , R {(a , )} R )k= |A | + |R {(a , )} R |= |A | + 1 + |R | + 2= |A | + |R | + 3use structural induction show formulas , find |A | 5 kk|R | 4 kk. follows kF k (5 + 4) kk + 3 = 9 kk + 3 O(kk).= >:|A> | = |{a> }| = 1 5 = 5 k>k|R> | = || = 0 4 = 4 k>k224fiExpressiveness Two-Valued Semantics ADFs= :|A | = |{a }| = 1 5 = 5 kk|R | = |{(a , )}| = 1 4 = 4 kk= A:|Aa | = |{a, aa }| = 2 5 = 5 kak|Ra | = |{(a, aa ), (aa , a)}| = 2 4 = 4 kak= :|A | = |A {a }| |A | + 1 (5 kk) + 1 5 (kk + 1) = 5 kk|R | = |R {(a , )}| |R | + 1 (4 kk) + 1 4 (kk + 1) = 4 kk= :|A | |A | + |A | + 3 (|A | + 1) + (|A | + 1) + 3(5 kk + 1) + (5 kk + 1) + 3 = 5 kk + 5 kk + 5= 5 (kk + kk + 1) = 5 k k|R | |R | + |R | + 2 (|R | + 1) + (|R | + 1) + 2(4 kk + 1) + (4 kk + 1) + 2 = 4 kk + 4 kk + 4= 4 (kk + kk + 1) = 4 kk= :|A | |A | + |A | + 2 5 kk + 5 kk + 25 kk + 5 kk + 5 = 5 (kk + kk + 1) = 5 kk|R | |R | + |R | + 3 (4 kk) + (4 kk) + 34 kk + 4 kk + 4 = 4 (kk + kk + 1) = 4 kkHence projection, AF stable extension semantics realise much propositional logic can. results previous section (AF e PL), meansallowing introduce linear number new vocabulary elements (that later projectedout), languages considered paper equally (universally) expressive.However, must note equal expressiveness mean equal efficiency:assume knowledge base size n leads search space size O(2n ),linear increase knowledge base size (that is, n c n constant c) leadspolynomial increase search space size (that is, O(2n ) O(2cn ) = O((2n )c ).225fiStrass5. Discussioncompared expressiveness abstract argumentation frameworks, abstract dialecticalframeworks, normal logic programs propositional logic. showed expressivenessdifferent semantics varies formalisms obtained neat expressiveness hierarchy. results inform us capabilities languages encode setstwo-valued interpretations, help us decide languages use specific applications. Furthermore, seen results sensitive vocabulary onepermitted use, hierarchy collapses allow introduce even linearnumber new atoms.Concerning succinctness, shown ADFs (under model semantics) exponentially succinct normal logic programs (under supported model semantics),even bipolar ADFs (under model semantics) although less expressivesuccinctly express model sets equivalent normal logic programs (under supported model semantics) vocabulary must necessarily blow exponentiallysize. open whether converse direction also holds, is, whether BADFsexponentially succinct logic programs (if LPsu BADFsu ) twomutually incomparable terms succinctness (if LPsu 6s BADFsu ). stable semantics, relative succinctness logic programs BADFs completely open, partly duetechnical aspect two stable semantics conceptually different, ADFsfact employ ultimate stable models (Denecker et al., 2004; Brewka et al., 2013; Strass& Wallner, 2015). Furthermore, general ADFs, computational complexitymodel existence problem stable semantics higher normal logic programs,10succinctness comparison regard stable models would limited significance.easy see AFs somewhat special role representationallysuccinct case: vocabulary , syntactically possibility specify knowledge base (an AF) exponential size, since largest AF sizek(An , )k = n + n2 thus polynomially large. anything expressed AF expressed reasonable space definition. However,strength AFs taken grain salt, since comparably inexpressive. (in addition results presented) already seen simplecounting argument: even syntactically different AFs semantically differ2ent (which not), could express 2n different model sets,nincreasing n negligible relation 22 possible model sets .original paper, Gogic et al. (1995) also used relaxed version succinctness,allowed introduce linear number new variables. follows resultsSection 4 formalisms consider equally succinct relaxednotion.Parts expressiveness results normal logic programs carry LPclasses. example, canonical logic programs provide limited form nesting allowingliterals form rule bodies (Lifschitz et al., 1999). makes quite easysee normal logic programs supported semantics translated equivalentcanonical logic programs, namely replacing positive body atom10. P2 -hard ADFs (Strass & Wallner, 2015) opposed NP normal LPs (Bidoit & Froidevaux,1991; Marek & Truszczynski, 1991).226fiExpressiveness Two-Valued Semantics ADFsrule bodies. Recently, Shen Zhao (2014) showed canonical logic programspropositional logic programs succinctly incomparable (under assumption11 ), alsoprovide interesting avenues succinctness studies. also add succinctnessquestions own: firstly comparing disjunctive logic programs stablemodels general ADFs stable models, since two equally complex(P2 -complete) model existence problem (Eiter & Gottlob, 1995; Brewka et al., 2013).more, alternative proposals stable model semantics ADFs:(Strass, 2013) (Definition 3.2, later called approximate stable models Strass& Wallner, 2015), model existence NP-complete (Strass & Wallner, 2015)thus potentially easier stable models Brewka et al. (2013)(called ultimate stable models Strass & Wallner, 2015);grounded model semantics Bogaerts, Vennekens, Denecker (2015) (Definition 6.8), whose model existence problem also P2 -complete (Bogaerts et al.,2015);F-stable model semantics Alviano Faber (2015) (Definition 10).follows Theorem 5.9 Bogaerts et al. (2015) grounded models F-stablemodels coincide. Still, demonstrably different approximate ultimate stable models ADFs (Alviano & Faber, 2015),12 relative succinctnesscomparison normal/disjunctive logic programs unanalysed.potential work. First all, nice characterisation bipolarADF realisability still missing; unsure whether much improvement Proposition 11 possible. Incidentally, AFs exact characterisation compact stable extension realisability constitutes major open problem (Dunne et al., 2015; Baumann et al.,2014). Second, semantics abstract dialectical frameworks whose expressiveness could studied; Dunne et al. (2015) Dyrkolbotn (2014) already analyse manyargumentation frameworks. work thus startdone remaining semantics. example admissible, complete preferredsemantics defined AFs, (B)ADFs LPs (Strass, 2013; Brewka et al., 2013),Puhrer (2015) already made huge step direction characterising realisability. Third, formalisms abstract argumentation (Brewka et al., 2014)whose expressiveness large unexplored best knowledge. Finally,representational succinctness subclass bipolar ADFs (using bipolar propositionalformulas represent them) supported model semantics mostly open (cf. Table 2),evidence pointing toward meaningful capabilities.Acknowledgementspaper combines, extends improves results previous work (Strass, 2014,2015b, 2015c). wish thank Stefan Woltran providing useful pointer related111. P 6 NC/poly, Boolean circuit equivalent assumption NP 6 P.12. terminology Alviano Faber (2015), approximate stable models (Strass, 2013) calledS-stable models ultimate stable models (Brewka et al., 2013) called B-stable models.shown different F-stable models.227fiStrasswork realisability logic programming, Bart Bogaerts pointing groundedmodels F-stable models same, Jorg Puhrer several suggestions improvement manuscript, Frank Loebe helpful discussions. research partiallysupported Deutsche Forschungsgemeinschaft (DFG, project BR 1817/7-1).ReferencesAl-Abdulkarim, L., Atkinson, K., & Bench-Capon, T. J. M. (2014). Abstract dialecticalframeworks legal reasoning. Hoekstra, R. (Ed.), Proceedings TwentySeventh Annual Conference Legal Knowledge Information Systems (JURIX),Vol. 271 Frontiers Artificial Intelligence Applications, pp. 6170. IOS Press.Al-Abdulkarim, L., Atkinson, K., & Bench-Capon, T. J. M. (2015). Evaluating approachreasoning cases using abstract dialectical frameworks. ProceedingsFifteenth International Conference Artificial Intelligence Law (ICAIL).Alviano, M., & Faber, W. (2015). Stable model semantics abstract dialectical frameworks revisited: logic programming perspective. Yang, Q., & Wooldridge, M.(Eds.), Proceedings Twenty-Fourth International Joint Conference ArtificialIntelligence (IJCAI), pp. 26842690, Buenos Aires, Argentina. IJCAI/AAAI.Arora, S., & Barak, B. (2009). Computational Complexity: Modern Approach. CambridgeUniversity Press.Baumann, R., Dvorak, W., Linsbichler, T., Strass, H., & Woltran, S. (2014). Compactargumentation frameworks. Proceedings Twenty-First European ConferenceArtificial Intelligence (ECAI), pp. 6974, Prague, Czech Republic.Bidoit, N., & Froidevaux, C. (1991). Negation default unstratifiable logic programs.Theoretical Computer Science, 78 (1), 85112.Bogaerts, B., Vennekens, J., & Denecker, M. (2015). Grounded fixpoints applications knowledge representation. Artificial Intelligence, 224, 5171.Boppana, R. B. (1986). Threshold functions bounded depth monotone circuits. JournalComputer System Sciences, 32 (2), 222229.Brewka, G., Dunne, P. E., & Woltran, S. (2011). Relating semantics abstract dialectical frameworks standard AFs. Proceedings Twenty-Second InternationalJoint Conference Artificial Intelligence (IJCAI), pp. 780785. IJCAI/AAAI.Brewka, G., Ellmauthaler, S., Strass, H., Wallner, J. P., & Woltran, S. (2013). Abstractdialectical frameworks revisited. Proceedings Twenty-Third InternationalJoint Conference Artificial Intelligence (IJCAI), pp. 803809. IJCAI/AAAI.Brewka, G., & Gordon, T. F. (2010). Carneades abstract dialectical frameworks: reconstruction. Proceedings Third International Conference ComputationalModels Argument (COMMA), Vol. 216 FAIA, pp. 312. IOS Press.Brewka, G., Polberg, S., & Woltran, S. (2014). Generalizations Dung frameworksrole formal argumentation. IEEE Intelligent Systems, 29 (1), 3038. SpecialIssue Representation Reasoning.228fiExpressiveness Two-Valued Semantics ADFsBrewka, G., & Woltran, S. (2010). Abstract dialectical frameworks. ProceedingsTwelfth International Conference Principles Knowledge RepresentationReasoning (KR), pp. 102111.Clark, K. L. (1978). Negation failure. Gallaire, H., & Minker, J. (Eds.), LogicData Bases, pp. 293322. Plenum Press.Coste-Marquis, S., Konieczny, S., Mailly, J.-G., & Marquis, P. (2014). revisionargumentation systems: Minimal change arguments statuses. ProceedingsFourteenth International Conference Principles Knowledge RepresentationReasoning (KR), pp. 5261.Darwiche, A., & Marquis, P. (2002). knowledge compilation map. Journal ArtificialIntelligence Research, 17, 229264.Denecker, M., Marek, V. W., & Truszczynski, M. (2004). Ultimate approximationapplication nonmonotonic knowledge representation systems. InformationComputation, 192 (1), 84121.Dimopoulos, Y., Nebel, B., & Toni, F. (2002). computational complexityassumption-based argumentation default reasoning. Artificial Intelligence,141 (1/2), 5778.Dung, P. M. (1995). Acceptability Arguments Fundamental RoleNonmonotonic Reasoning, Logic Programming n-Person Games. Artificial Intelligence, 77, 321358.Dunne, P. E., Dvorak, W., Linsbichler, T., & Woltran, S. (2014). Characteristics multipleviewpoints abstract argumentation. Proceedings Fourteenth InternationalConference Principles Knowledge Representation Reasoning (KR), pp.7281, Vienna, Austria.Dunne, P. E., Dvorak, W., Linsbichler, T., & Woltran, S. (2015). Characteristics multipleviewpoints abstract argumentation. Artificial Intelligence, 228, 153178.Dyrkolbotn, S. K. (2014). argue anything: Enforcing arbitrary sets labellingsusing AFs. Proceedings Fourteenth International Conference PrinciplesKnowledge Representation Reasoning (KR), pp. 626629, Vienna, Austria.Eiter, T., Fink, M., Puhrer, J., Tompits, H., & Woltran, S. (2013). Model-based recastinganswer-set programming. Journal Applied Non-Classical Logics, 23 (12), 75104.Eiter, T., & Gottlob, G. (1995). computational cost disjunctive logic programming:Propositional case. Annals Mathematics Artificial Intelligence, 15 (34), 289323.French, T., van der Hoek, W., Iliev, P., & Kooi, B. (2013). succinctnessmodal logics. Artificial Intelligence, 197, 5685.Friedman, J. (1986). Constructing O(n log n) size monotone formulae k-th elementary symmetric polynomial n Boolean variables. SIAM Journal Computing, 15,641654.Gabbay, D. M. (2011). Dungs argumentation essentially equivalent classical propositional logic Peirce-Quine dagger. Logica Universalis, 5 (2), 255318.229fiStrassGaggl, S. A., & Strass, H. (2014). Decomposing Abstract Dialectical Frameworks. Parsons, S., Oren, N., & Reed, C. (Eds.), Proceedings Fifth International ConferenceComputational Models Argument (COMMA), Vol. 266 FAIA, pp. 281292.IOS Press.Gaggl, S. A., Rudolph, S., & Strass, H. (2015). computational complexity naivebased semantics abstract dialectical frameworks. Yang, Q., & Wooldridge, M.(Eds.), Proceedings Twenty-Fourth International Joint Conference ArtificialIntelligence (IJCAI), pp. 29852991, Buenos Aires, Argentina. IJCAI/AAAI.Gebser, M., Kaminski, R., Kaufmann, B., Ostrowski, M., Schaub, T., & Schneider, M.(2011). Potassco: Potsdam Answer Set Solving Collection. AI Communications,24 (2), 105124. Available http://potassco.sourceforge.net.Gelfond, M., & Lifschitz, V. (1988). stable model semantics logic programming.Proceedings International Conference Logic Programming (ICLP), pp.10701080. MIT Press.Gogic, G., Kautz, H., Papadimitriou, C., & Selman, B. (1995). comparative linguisticsknowledge representation. Proceedings Fourteenth International JointConference Artificial Intelligence (IJCAI), pp. 862869. Morgan Kaufmann.Jukna, S. (2012). Boolean Function Complexity: Advances Frontiers, Vol. 27 Algorithms Combinatorics. Springer.Lifschitz, V., & Razborov, A. (2006). many loop formulas?. ACM Transactions Computational Logic, 7 (2), 261268.Lifschitz, V., Tang, L. R., & Turner, H. (1999). Nested expressions logic programs. AnnalsMathematics Artificial Intelligence, 25 (34), 369389.Lin, F., & Zhao, Y. (2004). ASSAT: Computing answer sets logic program SATsolvers. Artificial Intelligence, 157 (1-2), 115137.Linsbichler, T. (2014). Splitting abstract dialectical frameworks. Parsons, S., Oren, N., &Reed, C. (Eds.), Proceedings Fifth International Conference ComputationalModels Argument (COMMA), Vol. 266 FAIA, pp. 357368. IOS Press.Marek, V. W., & Truszczynski, M. (1991). Autoepistemic logic. Journal ACM, 38 (3),587618.Osorio, M., Zepeda, C., Nieves, J. C., & Cortes, U. (2005). Inferring acceptable argumentsanswer set programming. Proceedings Sixth Mexican InternationalConference Computer Science (ENC), pp. 198205.Polberg, S. (2014). Extension-based semantics abstract dialectical frameworks. Endriss,U., & Leite, J. (Eds.), Proceedings Seventh European Starting AI ResearcherSymposium (STAIRS), Vol. 264 FAIA, pp. 240249. IOS Press.Polberg, S., Wallner, J. P., & Woltran, S. (2013). Admissibility abstract dialecticalframework. Leite, J., Son, T. C., Torroni, P., van der Torre, L., & Woltran, S.(Eds.), Proceedings Fourteenth International Workshop Computational LogicMulti-Agent Systems (CLIMA XIV), Vol. 8143 LNAI, pp. 102118. Springer.230fiExpressiveness Two-Valued Semantics ADFsPuhrer, J. (2015). Realizability three-valued semantics abstract dialectical frameworks. Yang, Q., & Wooldridge, M. (Eds.), Proceedings Twenty-FourthInternational Joint Conference Artificial Intelligence (IJCAI), pp. 31713177. IJCAI/AAAI, Buenos Aires, Argentina.Shen, Y., & Zhao, X. (2014). Canonical logic programs succinctly incomparablepropositional formulas. Proceedings Fourteenth International ConferencePrinciples Knowledge Representation Reasoning (KR), pp. 665668,Vienna, Austria.Strass, H. (2013). Approximating operators semantics abstract dialectical frameworks. Artificial Intelligence, 205, 3970.Strass, H. (2014). relative expressiveness argumentation frameworks, normallogic programs abstract dialectical frameworks. Konieczny, S., & Tompits,H. (Eds.), Proceedings Fifteenth International Workshop Non-MonotonicReasoning (NMR).Strass, H. (2015a). Instantiating rule-based defeasible theories abstract dialectical frameworks beyond. Journal Logic Computation, Advance Access published 11February 2015, http://dx.doi.org/10.1093/logcom/exv004.Strass, H. (2015b). relative expressiveness abstract argumentation logic programming. Proceedings Twenty-Ninth AAAI Conference Artificial Intelligence(AAAI), pp. 16251631, Austin, TX, USA.Strass, H. (2015c). Representational succinctness abstract dialectical frameworks.Black, E., Modgil, S., & Oren, N. (Eds.), Proceedings Third International Workshop Theory Applications Formal Argumentation (TAFA).Strass, H., & Wallner, J. P. (2015). Analyzing computational complexity abstractdialectical frameworks via approximation fixpoint theory. Artificial Intelligence, 226,3474.Tseitin, G. S. (1968). complexity derivations propositional calculus. Structures Constructive Mathematics Mathematical Logic, Part II, SeminarsMathematics (translated Russian), 115125.231fiJournal Artificial Intelligence Research 54 (2015) 471492Submitted 05/15; published 11/15Weighted Regret-Based Likelihood: New ApproachDescribing UncertaintyJoseph Y. Halpernhalpern@cs.cornell.eduComputer Science DepartmentCornell UniversityIthaca, NY 14853, USAAbstractRecently, Halpern Leung suggested representing uncertainty set weightedprobability measures, suggested way making decisions based representationuncertainty: maximizing weighted regret. paper answer apparentlysimpler question: means, according representation uncertainty,event E likely event E 0 . paper, notion comparativelikelihood uncertainty represented set weighted probability measuresdefined. generalizes ordering defined probability (and lower probability)natural way; generalization upper probability also defined. completeaxiomatic characterization notion regret-based likelihood given.1. IntroductionRecently, Samantha Leung (Halpern & Leung, 2012) suggested representing uncertainty set weighted probability measures, suggested way making decisionsbased representation uncertainty: maximizing weighted regret. However,answer apparently simpler question: given representation uncertainty,mean event E likely event E 0 ?paper. explain issues, start reviewing Halpern-Leung approach.frequently observed many situations agents uncertainty adequately described single probability measure. Specifically, singlemeasure may adequate representing agents ignorance. example,seems big difference coin known fair coin whose bias agentknow, yet agent use single measure represent uncertainty,cases would seem measure assigns heads probability 1/2would used.One approach suggested representing ignorance use set Pprobability measures. idea old one, apparently going back work Boole(1854, ch. 1621) Ostrogradsky (1838); authors (e.g., Campos & Moral, 1995;Couso, Moral, & Walley, 1999; Gilboa & Schmeidler, 1993; Levi, 1985; Walley, 1991)additionally required set P convex (so 1 2 P,a1 + b2 , a, b [0, 1] + b = 1). approach benefit representinguncertainty general, single number, range numbers. allows usdistinguish certainty coin fair (in case uncertainty headsrepresented single number, 1/2) knowing probability heads couldanywhere between, say, 1/3 2/3.c2015AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiHalpernapproach also problems. example, consider agent believescoin may slight bias. Thus, although unlikely completely fair,close fair. represent set probability measures? Supposeagent quite sure bias 1/3 2/3. could, course, takeP consist measures give heads probability 1/3 2/3.agent know possible biases exactly 1/3 2/3.consider 2/3 + possible small ? even confident bias1/3 2/3, representation cannot take account possibilityviews biases closer 1/2 likely biases 1/2.also second well-known concern: learning. Suppose agent initiallyconsiders possible measures gives heads probability 1/3 2/3.starts tossing coin, sees that, first 20 tosses, 12 heads. seemsagent consider bias greater 1/2 likely bias less1/2. use standard approach updating sets probability measures(Halpern, 2003), condition measures observation, since cointosses viewed independent, agent continue believe probabilitynext coin toss 1/3 2/3. observation impact far learningpredict better. set P stays same, matter observation made.well-known solution problems: putting measure uncertaintyprobability measures P. idea long history. One special case putsecond-order probability probability measures; see (Good, 1980) discussionapproach references. example, agent express factbias coin likely close 1/2 far 1/2. addition,problem learning dealt straightforward conditioning. approachleads problems. Essentially, seems ambiguity agent might feeloutcome coin toss seems disappeared. example, supposeagent idea bias is. obvious second-order probability useuniform probability possible biases. cannot talk probabilitycoin heads (there set probabilities, all, single probability), expectedprobability heads 1/2. agent idea bias coinknow believe expected probability heads 1/2? course, one usesingle probability measure describe uncertainty, symmetry considerations dictateone ascribes equal likelihood heads tails; similarly, oneput single second-order probability set possible biases, uniform probabilityseems like obvious choice. Moreover, interest making decisions,maximizing expected utility using expected probability takeagents ignorance account. Kyburg (1988) Pearl (1987) even arguedneed second-order probability probabilities; whatever donesecond-order probability already done basic probability.Nevertheless, comes decision-making, seem useful use approachrepresents ambiguity, still maintaining features secondorder probability probabilities. idea goes back least Gardenfors Sahlin(1982, 1983). Walley (1997) suggested putting possibility measure (Dubois & Prade, 1998;Zadeh, 1978) probability measures; also essentially done Cattaneo (2007),Chateauneuf Faro (2009), de Cooman (2005). authors others,472fiWeighted Regret-Based LikelihoodKlibanoff et al. (2005), Maccheroni et al. (2006), Nau (1992), proposed approachesdecision making using representations uncertainty.Leung similarly suggested putting weights probability measure P. Sinceassumed weights normalized supremum weights 1,weights also viewed possibility measure. set P finite, alsonormalize view weights second-order probabilities. secondorder probabilities, weights vary time, information acquired.example, start state complete ignorance (modeled assumingprobability measures weight 1), update weights making observationob, take weight measure Pr relative likelihood ob Prtrue measure. (See Section 2 details.) approach, called likelihood updatingHalpern Leung (2012), true underlying measure generating data,time, weight true measure approaches 1, weight measuresapproaches 0. Thus, approach allows learning natural way. If, example,actual bias coin 5/8 example above, matter initial weights,long 5/8 positive weight, weight would almost surely converge 1observations made, weight measures would approach 0. This,course, exactly would happen second-order probability P.weights also used represent fact probabilities set Plikely others.Like essentially others considered representation uncertainty based setprobability weights, Leung also suggested way using representationmake decisions. However, approach different suggested earlier.based approach regret, standard approach decision-making introduced(independently) Niehans (1948) Savage (1951). uncertainty representedset P probability measures, regret works follows: actmeasure Pr P, compute expected regret respect Pr;difference expected utility expected utility actgives highest expected utility respect Pr. associate actworst-case expected regret a, measures Pr P, compare actsrespect worst-case expected regret. weights picture, modifyprocedure multiplying expected regret associated measure Pr weightPr, compare acts according worst-case weighted expected regret. approachmaking decisions different others mentioned incorporatelikelihood probabilities. Moreover, using weights way means cannotsimply replace set weighted probability measures single probability measure;objections Kyburg (1988) Pearl (1987) apply.Leung (Halpern & Leung, 2012) show approach seems reasonablethings number examples interest, provide axiomatization decision-makingapproach. Since sets weighted probabilities certainly intended wayrepresenting uncertainty, seems natural ask whether used representrelative likelihood direct way. Surprisingly, something largely consideredearlier papers using sets weighted probabilities, since focus decision-making(although work Nau discussed Section 3 exception).473fiHalpernRepresenting relative likelihood straightforward uncertainty representedsingle probability measure: E likely E 0 exactly probability E greaterprobability E 0 . using sets probability measures, various approachesconsidered literature. common takes E likelyE 0 lower probability E greater lower probability E 0 , lowerprobability E worst-case probability, taken measures P (see Section 3).could also compare E E 0 respect upper probabilities (the best-caseprobability respect measures P). Another possibility take Elikely E 0 Pr(E) Pr(E 0 ) measures Pr P; gives partial orderlikelihood.1 uncertainty represented set weightedprobability measures?paper, define notion relative likelihood uncertainty representedset weighted probability measures generalizes ordering defined lowerprobability natural way; also define generalization upper probability.associate event E two numbers analogues lower upper probability.uncertainty represented single measure, two numbers coincide; general,not. interval thought representing degree ambiguitylikelihood E. Indeed, special case weights 1, numbersessentially lower upper probability (technically, 1 minus lowerupper probability, respectively). Interestingly, approach assigning likelihoodbased approach decision-making. Essentially, analoguedefining probability terms expected utility, rather way around.approach viewed generalizing probability lower probability,time allowing natural approach updating.interested representation? ever probability use make decisions, arguably wouldnt much interest;work Leung already shows sets weighted probabilities used decisionmaking. results paper add nothing question. However, oftentalk likelihood events quite independent use decision-making.clearly many examples physics. issue arises AI applications well: typicalexplanation rather B thought event Elikely F . computations expectation, clearly involve representationuncertainty, arise many AI applications. Thus, analogue probability seemsimportant useful right.rest paper organized follows. reviewing relevant material(Halpern & Leung, 2012) Section 2, define regret-based likelihood Section 3,compare lower probability. provide axiomatic characterization regret-basedlikelihood Section 4, show relates axiomatic characterization lowerprobability. conclude Section 5.1. long tradition considering partially ordered notions likelihood; see (Halpern, 1997)references therein, work Walley (1991).474fiWeighted Regret-Based Likelihood2. Weighted Expected Regret: ReviewConsider standard setup decision theory. state space outcomespace O. act function O; describes outcome state. Supposeutility function u outcomes set P + weighted probability measures.is, P + consists pairs (Pr, Pr ), Pr weight [0, 1] Pr probabilityS. Let P = {Pr : ((Pr, ) P + )}. Pr P assumedexactly one , denoted Pr , (Pr, ) P + . assumed weightsnormalized least one measure Pr P Pr = 1.Finally, P + assumed weakly closed, (Prn , n ) Pr+ n = 1, 2, 3, . . .,(Prn , n ) (Pr, Pr ), Pr > 0, (Pr, Pr ) P + . (I discuss requireP + weakly closed, rather closed.)assumption least one probability measure weight 1 convenientcomparison approaches; see below. However, making assumptionimpact results paper; long restrict sets weight bounded,results hold without change. assumption is, course, incompatibleweights probabilities. Note assumption weights probabilitiesruns difficulties infinite number measures P; example, Pincludes measures heads 1/3 2/3, discussed Introduction, usinguniform probability, would forced assign individual probability measureweight 0, would work well later definitions.weights P + coming from? general, viewed subjective,like probability measures. However, Leung (Halpern & Leung, 2012)observed, important special case weights given naturalinterpretation. Suppose that, case biased coin Introduction, makeobservations situation probability making given observation determinedobjective source. start giving probability measures weight 1.Given observation ob (e.g., sequence coin tosses example Introduction),compute Pr(ob) measure Pr P; update weight PrPr(ob)/ supPr0 P Pr0 (ob). Thus, likely observation according Pr,higher updated weight Pr relative probability measures P.2 (Thedenominator normalization ensure measure weight 1.)approach updating, true underlying measure generating data,agent makes observations, almost surely, weight true measure approaches1, weight measures approaches 0.3 addition, approach givesagent natural way determining weights probability measure P. While,general, means agent may need carry around lot information (not2. idea putting possibility probabilities P determined likelihood also appearswork Moral (1992), although consider general approach dealing sets weightedprobability measures.3. almost surely due fact that, probability approaching 0, observations made, possible agent make misleading observations representativetrue measure. also depends set possible observations rich enough allowagent ultimately discover true measure generating observations; example, agentnever learn distributions outcomes die never gets observe die lands 5 6.Since learning focus paper, make notion rich enough precise here.475fiHalpernpossibly infinite set probabilities, weight associated one),set P reasonable parametric representation, weight often evaluatedterms parameters, admit compact representation (see Example 3.2).weight associated probability Pr viewed upper boundagents confidence Pr actually describes situation. agentidea going modeled starting placing weight 1 probabilitymeasures. believe weights allow agents express nuancesconsider important, weights hard elicit. Whethercase really empirical question, one believe deserves exploration,beyond scope paper.review definition weighted regret, introduce notion absolute(weighted) regret. start regret. regret act statedifference utility best act state utility s. Typically,act compared acts, acts set , called menu. Thus,regret state relative menu , denoted reg (a, s), supa0 u(a0 (s)) u(a(s)).4typically constraints put ensure supa0 u(a0 (s)) finitethiscertainly case finite, convex closure finite set acts,best possible outcome outcome space O. latter assumption holds paper,assume throughout supa0 u(a0 (s)) finite.simplicity, assume state space finite. Given probability measurePr S, expected regret act respect Pr relative menuPregsS reg (a, s) Pr(s). (expected) regret respect P menuPr (a) =worst-case regret, is,regP (a) = sup reg Pr (a).PrPSimilarly, weighted (expected) regret respect P + menuworst-case weighted regret, is,wrP + (a) = sup Pr reg Pr (a).PrPThus, regret special case weighted regret, weights 1.Note that, far weighted regret goes, hurt augment set P + weightedprobability measures adding pairs form (Pr, 0) Pr/ P. start set+P unweighted probability measures, set P = {(Pr, 1) : Pr P}{(Pr, 0) : Pr/ P}closed general, although weakly closed. may well sequence Prn Pr,Prn/ P n, Pr P. would (Prn , 0) P + converging+(Pr, 0)/ P . exactly required weak closedness. Note future referencethat, since P + assumed weakly closed, wrP + (a) > 0, element+(Pr, Pr ) P wr P + (a) = Pr reg Pr (a).Weighted regret induces obvious preference order acts: act least good00a0 respect P + , written regP + ,M , wr P + (a) wr P + (a ). usual,4. Recall X set real numbers, sup X, supremum X, smallest real numbersgreater equal elements X. X finite, sup max.X is, say, interval (0, 1), sup X = 1. Similarly, inf X largest real numberless equal elements X.476fiWeighted Regret-Based Likelihoodregreg000write regP + ,M P + ,M case P + ,M a. standard notionregret special case weighted regret weights 1. sometimes write0+regP,M denote unweighted case (i.e., weights P 1).setting, using weighted regret gives approach allows agent transitionsmoothly regret expected utility. well known regret generalizes expected0utility sense P singleton {Pr}, wrP (a) wr P (a ) iff EUPr (a)0EUPr (a ) (where EUPr (a) denotes expected utility act respect probabilityPr); follows observation that, given menu , constant cMthat, acts , wr{Pr} (a) = cM EUPr (a). (In particular, means Psingleton, regret menu independent.) start weights 1, then,observed above, weighted regret standard notion regret. agentmakes observations, measure Pr generating uncertainty, weightsget closer closer situation Pr gets weight 1, weightsmeasures dropping quickly 0, ordering acts converge orderinggiven expected utility respect Pr.another approach similar properties, starts uncertainty represented set P (unweighted) probability measures. Define wc P (a) =inf PrP EUPr (a). Thus wc P (a) worst-case expected utility a, taken Pr P.define mma0 wc P (a) wc P (a0 ). maxmin expected utility rule, quitePoften used economics (Gilboa & Schmeidler, 1989). difficulties gettingweighted version maxmin expected utility (Halpern & Leung, 2012) (discussedSection 3); however, Epstein Schneider (2007) propose another approachcombined maxmin expected utility. fix parameter (0, 1), update Pobservation ob retaining measures Pr Pr(ob) .choice < 1, end converging almost surely single measure,approach converges almost surely expected utility.conclude section discussion menu dependence. Maxmin expected utilitymenu dependent; preference ordering acts induced regret be,following example illustrates.Example 2.1: Take outcome space {0, 1}, utility functionidentity, u(1) = 1 u(0) = 0. usual, E S, 1E denotes indicatorfunction E, where, state S, 1E (s) = 1 E, 1E (s) = 0/ E. Let = {s1 , s2 , s3 , s4 }, E1 = {s1 }, E2 = {s2 }, E3 = {s2 , s3 }, M1 = {1E1 , 1E2 },M2 = {1E1 , 1E2 , 1E3 }, P = {Pr1 , Pr2 }, Pr1 (s1 ) = Pr1 (s3 ) = Pr1 (s4 ) = 1/3,1Pr2 (s2 ) = 1/4, Pr2 (s3 ) = 3/4. straightforward calculation shows regPr1 (1E1 ) =M1M1M1M2M20, reg Pr1 (1E2 ) = 1/3, reg Pr2 (1E1 ) = 1/4, reg Pr2 (1E2 ) = 0, reg Pr1 (1E1 ) = 1/3, reg Pr1 (1E2 ) =M1M1M222/3, regPr2 (1E1 ) = 1, reg Pr2 (1E2 ) = 3/4. Thus, 1/4 = reg P (1E1 ) < reg P (1E2 ) = 1/3,M221 = regP (1E1 ) > reg P (1E2 ) = 3/4. preference 1E1 1E2 dependswhether consider menu M1 menu M2 .Suppose outcome gives maximum utility; is,u(o) O. constant act gives outcomes states,clearly best act states. best act, absolute,menu-independent notion weighted expected regret defined always comparingu(o )477fiHalpern. is, definereg(s, a) = u(o ) u(a(s));Preg Pr (a) = sS (u(o ) u(a(s)) Pr(s) = u(o ) EUPr (a);Preg P (a) = supPrP sS (u(o ) u(a(s)) Pr(s) = u(o ) inf PrP (EUPr (a);Pwr P + (a) = supPrP Pr sS (u(o ) u(a(s)) Pr(s) = supPrP Pr (u(o ) EUPr (a)).best act, write P + a0 wr P + (a) wr P + (a0 ); similarlyunweighted case, write P a0 wr P (a) wr P (a0 ).Conceptually, think agent always aware best outcome ,comparing actual utility u(o ). Equivalently, absolute notion regretequivalent menu-based notion respect menu includes (sincemenu includes , best act every state). shall see, setting,always reduce menu-dependent regret absolute, menu-independent notion, sincefact best act: 1S .3. Relative Ordering Events Using Weighted Regretsection, consider notion comparative likelihood defined using setsweighted probability measures.Example 2.1, take outcome space {0, 1}, utility functionidentity, consider indicator functions. easy see EUPr (1E ) = Pr(E),setup, recover probability expected utility. Thus, uncertaintyrepresented single probability measure Pr make decisions preferringacts maximize expected utility, 1E 1E 0 iff Pr(E) Pr(E 0 ).Consider happens apply approach maxmin expected utility.1E mm1E 0 iff inf PrP Pr(E) inf PrP Pr(E 0 ). literature, inf PrP Pr(E),Pdenoted P (E), called lower probability E, standard approach describing likelihood. dual upper probability, supPrP Pr(E), denoted P (E). easycalculation showsP (E) = 1 P (E),where, usual, E denotes complement E. interval [P (E), P (E)]thought describing uncertainty E; larger interval, greater ambiguity.happens apply approach regret? First consider unweighted regret.restrict acts form 1E , best act clearly 1S ,constant function 1. Thus, (and do) use absolute notion regret here,remainder paper. get 1E regP 1E 0 iff supPrP (1 Pr(E))00supPrP (1 Pr(E )) iff supPrP Pr(E) supPrP Pr(E ); is,01E regP 1E 0 iff P (E) P (E ).478fiWeighted Regret-Based LikelihoodMoreover, easy manipulation shows supPrP (1 Pr(E)) = 1 inf PrP Pr(E) = 1P (E). follows1E regP 1E 0iff (1 P (E)) (1 P (E 0 ))iff P (E) P (E 0 )iff 1E mm1E 0 .Pis, regret maxmin expected utility put ordering events.+ (E), (weighted) regret-basedextension weighted regret immediate. Let Preglikelihood E, defined taking+Preg(E) = sup Pr Pr(E).PrPP + unweighted, weights 1, write Preg (E) denote supPrP Pr(E).Note Preg (E) = 1 P (E),Preg (E) Preg (E 0 ) iff P (E) P (E 0 ).is, ordering induced Preg opposite induced P . So, example,Preg () = 1 Preg (S) = 0; smaller sets larger regret-based likelihood. However, sinceact smaller regret viewed better, ordering acts form 1E inducedregret induced maxmin expected utility.Regret-based likelihood provides way associating number event,probability lower probability do. Moreover, lower probability gives lower+ (E) giving upper bound uncertainty.bound uncertainty, think Preg(It upper bound rather lower bound larger regret means less likely,smaller lower probability does.) naive corresponding lower bound giveninf PrP Pr Pr(E). lower bound terribly interesting; probabilitymeasures Pr0 P Pr0 close 0, lower bound close 0,independent agents actual feeling likelihood E. reasonable+lower bound given expression P +reg (E) = 1 Preg (E) (recall analogousexpression relates upper probability lower probability). intuition choicefollowing. nature conspiring us, would try prove us wrongmaking Pr Pr(E) large possiblethat is, make weighted probabilitywrong large possible. hand, nature conspiring us, wouldtry make Pr Pr(E) large possible, or, equivalently, make 1 Pr Pr(E) smallpossible. Note different making Pr Pr(E) large possible, unlessPr = 1 Pr P. easy calculation shows+ (E) = 1 sup1 PregPrP Pr Pr(E)= inf PrP (1 Pr Pr(E)).motivates definition P +reg .following lemma clarifies relationship expressions, shows+[P +reg (E), Preg (E)] really give interval ambiguity.+ (E) P + (E).Lemma 3.1: inf PrP Pr Pr(E) 1 Pregreg479fiHalpernProof: Clearlyinf Pr Pr(E) = inf Pr (1 Pr(E)).PrPPrPSince, observed above,+1 Preg(E) = inf (1 Pr Pr(E)),PrPPr P,1 Pr Pr(E) Pr (1 Pr(E)),+ (E).follows inf PrP Pr Pr(E) 1 PregSince, assumption, probability measure Pr0 P Pr0 = 1,follows+ (E) = 1 sup1 PregPrP Pr Pr(E)1 Pr0 (E)= Pr0 (E)supPrP Pr Pr(E)+ (E).Preggeneral, equality hold Lemma 3.1, shown following example.example also illustrates ambiguity interval decrease weighted regret,weights updated Leung (Halpern & Leung, 2012) suggested.Example 3.2: Suppose state space consists {h, t} (for heads tails); let Prmeasure puts probability h. Let P0+ = {(Pr , 1) : 1/3 2/3}. is,initially consider measures put probability 1/3 2/3 heads.toss coin observe lands heads. Intuitively, consider likelyprobability heads greater 1/2. Indeed, applying likelihood updating,get set P1+ = {(Pr , 3/2) : 1/3 2/3}; probability measures give h higherprobability get higher weight. particular, weight Pr2/3 still 1, weightPr1/3 1/2. (The weight Pr likelihood observing heads according Pr ,, normalized likelihood observing heads according measuregives heads highest probability, namely 2/3.) coin tossedtime tails observed, update get P2+ = {(Pr , 4(1 )) : 1/3 2/3}.going on, worth noting simple parametric form P0+ leadssimple parametric forms P1+ P2+ .+++easy calculation shows [P +0,reg (h), P0,reg (h)] = [1/3, 2/3], [P 1,regret (h), P1,reg (h)] =++[1/3, 3/8], [P 2,reg (h), P2,reg (h)] = [11/27, 16/27]. detail, since Pr (h) =Pr (t) = 1 , following:0P0,reg(h) = sup[1/3,2/3] (1 ) = 2/3.P 00,reg (h) = inf [1/3, 2/3](1 ) = 1/3.0P1,reg(h) = sup[1/3,2/3] (3/2)(1). Taking derivative shows (3/2)(1)0maximized = 1/2, P1,reg(h) = 3/8.480fiWeighted Regret-Based LikelihoodP 01,reg (h) = inf [1/3,2/3] (1 (3/2)). 1 (3/2) minimized, (3/2)maximized; [1/3, 2/3], happens = 2/3, P 01,reg (h) = 1/3.0P2,reg(h) = sup[1/3,2/3] 4(1)(1). Taking derivative shows 4(1)2maximized = 1/3, case 16/27.P 02,reg (h) = inf [1/3,2/3] (1 4(1 )). 1 4 2 (1 ) minimized4 2 (1) maximized; [1/3, 2/3], happens = 2/3, P 01,reg (h) =11/27.also easy see inf Pr 4(1 ) Pr (t) = inf [1/3,2/3] 4(1 )2 = 8/27,++inf 4(1 )Pr (t) < 1 P2,reg(t) < P2,reg(h).PrP2Thus, P2+ , get strict inequalities expressions Lemma 3.1.+width interval [P +reg (E), Preg (E)] viewed measure ambiguityagent feels E, interval [P (E), P (E)]. Indeed, weights 1,+ (E) P (E) = 1 P + (E)two intervals width, since P (E) = 1 Pregregcase.However, weighted regret significant advantage upper lower probability.true bias coin is, say 5/8, set Pk+ represents uncertainty+k steps, k increases, almost surely, [P +k,reg (h), Pk,reg (h)] smaller smallerinterval containing 1 5/8 = 3/8. generally, using likelihood updated combinedweighted regret provides natural way model reduction ambiguity via learning.worth point comparing approach representing likelihood takenwork Nau (1992). Nau starts preference order lotteries (functionsfinite state space reals) satisfying certain axioms, derivescalls confidence-weighted (lower upper) probabilities. Roughly speaking, ratherassociating event lower upper probability, Nau associateprobabilitiesevent E, confidence c [0, 1], probability p [0, 1] set Pc,pgive event E lower probability p confidence least c. c0 c, Pc0 ,p Pc,p(every probability measures gives E lower probability p higher confidencec0 also give lower probability p confidence c, converse may hold).Similarly, consider probability measures give E upper probability pconfidence c. set P unweighted probabilities, agents uncertainty regardingevent E characterized single interval [P (E), P (E)]. Naus framework,agents uncertainty regarding E characterized family intervals [Pc (E), P c (E)],indexed confidence c, Pc (E) largest p E lower probabilityconfidence c, P c (E) defined similarly. Clearly intervals nested;0c0 > c, [Pc0 (E), P c (E)] contains [Pc (E), P c (E)]. Thus, Naus approach providesfine-grained representation uncertainty single intervals [P (E), P (E)]+[P +reg (E), Preg (E)]. extent, distinction due fact Naus preferenceorder lotteries partial order; preference order induced max=min expected+ , P + pututility regret total. However, note even though P , P , Pregreg+ , P + together,total order events, considering P P Pregreg481fiHalpernalso obtain partial order events; particular, approaches expressambiguity.One benefit regret-based approach provides natural way updating.Nau consider updating; would interesting see analogue likelihoodupdating could defined axiomatically Naus framework, perhaps spiritcharacterization Leung (Halpern & Leung, 2012) gave likelihood updatingcontext regret.One concern use regret dependence regret menu;Naus approach, approaches decision-making based regret,require menu. evidence psychology literature suggestingpeople quite sensitive menus, also worth noting dealing likelihood,sense work absolute notion weighted regret withoutloss generality: restrict indicator functions, preference relative menualways reduced absolute preference. Given menu consisting indicatorfunctions, let EM = {E : 1E }; is, EM union eventscorresponding indicator function . following property shows that, restrictindicator functions, regret satisfies satisfies axiom similar spirit Naus (1992)cancellation axiom.Proposition 3.3: menu consisting indicator functions, 1E1 , 1E2 ,reg1E1 regP + ,M 1E2 iff 1E1 + 1E P + 1E2 + 1E .Proof: Let 0 menu consisting indicator functions includes 1E1 + 1E ,reg1E2 + 1E , 1S . Recall 1E1 + 1E regP + 1E2 + 1E iff 1E1 + 1E 0 ,P + 1E2 + 1E ;absolute notion regret equivalent menu-based notion, long menuincludes best act, case 1S . clearly suffices show that, statesacts 1E ,0reg (1E , s) = reg (1E + 1E , s).straightforward. two cases, depending whether EM .EM , then, definition, act 1E 0 E 0 ,supaM u(a(s)) = u(1). Clearly supaM 0 u(a(s)) = u(1), since 1S 0 . Moreover,1E (s) = 0, (1E + 1E )(s) = 1E (s). Thus, EM ,reg (1E , s) = supaM u(a(s)) u(1E (s))= supaM 0 u(a(s)) u((1E + 1E )(s))0= reg (1E + 1E , s)./ E , a(s) = 0 1E (s) = 0, supaM u(a(s)) u(1E (s)) =0. hand, supaM 0 u(a(s)) = u(1), u((1E + 1E )(s)) = u(1),0supaM 0 u(a(s)) u((1E + 1E )(s)) = 0. Thus, reg (1E , s) = reg (1E +1E , s).482fiWeighted Regret-Based Likelihood4. Characterizing Weighted Regret-Based Likelihoodgoal section characterize weighted regret-based likelihood axiomatically.order so, helpful review characterizations probability lowerprobability. ease exposition discussion, assume sample spacefinite sets measurable.probability measure finite set maps subsets [0, 1] way satisfiesfollowing three properties:Pr1. Pr(S) = 1.Pr2. Pr() = 0.5Pr3. Pr(E E 0 ) = Pr(E) + Pr(E 0 ) E E 0 = .three properties characterize probability sense function f : 2S [0, 1]satisfies properties probability measure.Lower probabilities satisfy analogues properties:LP1. P (S) = 1.LP2. P () = 0.LP30 . P (E E 0 ) P (E) + P (E 0 ) E E 0 = .However, properties characterize lower probability. functionssatisfy LP1, LP2, LP30 lower probability corresponding setprobability measures. (See (Halpern & Pucella, 2002, Proposition 2.2) exampleshowing analogous properties characterize P ; example also showscharacterize P .)Various characterizations P (and P ) proposed literature (Anger &Lembcke, 1985; Giles, 1982; Huber, 1976, 1981; Lorentz, 1952; Williams, 1976; Wolf, 1977),similar spirit. discuss one due Anger Lembcke (1985) here, since makescontrast lower probability regret particularly clear. characterizationbased notion set cover: set E said covered n times multisetevery element E appears least n times . important notemultiset, set; elements necessarily distinct. (Of course, setspecial case multiset.) Let denote multiset union; thus, M1 M2 multisets,M1 M2 consists elements M1 M2 , appear multiplicitysum multiplicities M1 M2 . example, using {{. . .}} notationdenote multiset, {{1, 1, 2}} {{1, 2, 3}} = {{1, 1, 1, 2, 2, 3}}.E S, (n, k)-cover (E, S) multiset covers k timescovers E n + k times. Multiset n-cover E covers E n times. example,= {1, 2, 3}, {{1, 1, 1, 2, 2, 3}} (2, 1)-cover ({1}, S), (1, 1)-cover ({1, 2}, S),3-cover {1}.interested whether multiset form E 1 . . . E (n, k)-cover(E, S). perhaps best thought terms indicator functions. E 1 . . . E5. property actually follows two, using observation Pr(S ) = Pr(S) + Pr();include ease comparison approaches.483fiHalpern(n, k)-cover (E, S) 1E1 + + 1Em n1E + k1S . use equalities inequalities involving sums indicator functions axiomatic characterizationsuncertainty long history; example, used Scott (1964) characterizequalitative probability. Set covers special case inequalities. Typically,axioms make possible apply results linear programming prove characterizationresults. shall see, case too.Consider following property:LP3. integers m, n, k subsets E1 , . . . , Em S, E1 . . . Em (n, k)P6cover (E, S), k + nP (E)i=1 P (Ei ).analogous property upper probability, replaced . easysee LP3 implies LP30 (since E E 0 (1, 0) cover (E E 0 , S)). followsstraightforward induction LP30 E1 , . . . , Em pairwise disjoint,P (E1 . . . Em ) P (E1 ) + + P (E1 ). LP3 generalizes property allow setsnecessarily disjoint. soundness LP3 lower probability follows usingtechniques given soundness property REG3. AngerLembcke (1985) show, LP3 property needed characterize lowerprobability.Theorem 4.1: (Anger & Lembcke, 1985) f : 2S [0, 1], exists set Pprobability measures f = P f satisfies LP1, LP2, LP3.Moving regret-based likelihood, clearly+ (S) = 0.REG1. Preg+ () = 1.REG2. Pregwhole space least regret; empty set greatest regret. Again, seeregret-based likelihood inverts standard ordering probability; larger regret-basedlikelihood corresponds probability.unweighted case, since Preg (E) = P (E), REG1, REG2, following analogue LP3 (appropriately modified P ) clearly characterize Preg :REG30 . integers m, n, k subsets E1 , . . . , Em S, E 1 . . . EP(n, k)-cover (E, S), k + nPreg (E)i=1 Preg (Ei ).Note complements sets (E 1 , . . . , E , E) used here, since regret minimizedprobability complement maximized. need work complementmakes statement properties (and proofs theorems) slightly less elegant,seems necessary.hard see REG30 hold weighted regret-based likelihood.example, suppose = {a, b, c} P + = ((Pr1 , 2/3), (Pr2 , 2/3), (Pr3 , 1)), where,identifying probability Pr tuple (Pr(a), Pr(b), Pr(c)),Pr1 = (2/3, 0, 1/3);6. Note LP3 implies LP2, using fact (1,0)-cover (, S).484fiWeighted Regret-Based LikelihoodPr2 = (1/3, 0, 2/3);Pr3 = (1/3, 1/3, 1/3).+ ({a, b}) = P + ({b, c}) = 4/9, P + ({b}) = 2/3. Since {a, b} {b, c}Pregregreg(1,1)-cover ({b}, {a, b, c}), REG30 would require+++Preg({a, b}) + Preg({b, c}) 1 + Preg({b}),clearly case.must thus weaken REG30 capture weighted regret-based likelihood. turnsappropriate weakening following:REG3. integers m, n subsets E1 , . . . , Em S, E 1 . . . E n-cover+ (E) Pm P + (E ).E, nPregi=1 regAlthough REG3 weaker REG30 , still nontrivial consequences.+ anti-monotonic. E E 0 , E 1-coverexample, follows REG3 Preg0+ (E) P + (E 0 ). Since E E 0 trivially 1-coverE , REG3, must Pregreg+ (E) + P + (E 0 ) P + (E E 0 ). REG3 also implies REG1,E E 0 , also follows Pregregregsince (= S) n-cover n.state representation theorem. says representation uncertaintysatisfies REG1, REG2, REG3 iff weighted regret-based likelihood determinedset P + . set P + unique, taken maximal,sense weighted regret-based likelihood respect set (P 0 )+ givesrepresentation, pairs (Pr, 0 ) (P 0 )+ , exists 0(Pr, ) P + . (unique) maximal set P + viewed canonical representationuncertainty.Theorem 4.2: f : 2S [0, 1], exists weakly closed set P + weighted+ f satisfies REG1, REG2, REG3;probability measures f = Pregmoreover, P + taken maximal.Proof: Clearly, given weakly closed set P + weighted probability measures, function+ satisfies REG1 REG2. see satisfies REG3, suppose E . . . EPreg1+ (E) = 0, REG3 trivially holds. P + (E) > 0, since P +n-cover E. Pregreg+ (E) = Pr(E).weakly closed, must probability Pr P PregPrSince E 1 t. . .tE n-cover E, easy see Pr(E 1 )+ +Pr(E ) = n Pr(E),+ (E), construction,Pr Pr(E 1 ) + + Pr Pr(E ) = nPr Pr(E). Pr Pr(E) = PregP+ (E ), = 1, . . . , n. Thus, nP + (E)+Pr Pr(E ) Pregregi=1 Preg (Ei ).opposite direction, suppose f : 2 [0, 1] satisfies REG1, REG2,REG3. Let P = (S), set probability measures S, Pr P, definePr = sup{ : Pr(E) f (E) E S}.Note that, Pr P, 0 Pr(E) f (E) E S, since f (E) [0, 1],1 Pr() = f () = 1. follows Pr [0, 1] Pr P. Let P + = {(Pr, Pr ) :485fiHalpernPr (S)}. easy see P + weakly closed. Moreover, show P ++ ), immediate P + maximal among sets weightedrepresents f (i.e., f = Pregprobability measures represent f . Thus, suffices show exists Pr (S)(1) Pr = 1 (since one conditions sets weighted measures)+ (E) E S.(2) f (E) = Pregproof result makes critical use following variant Farkas Lemma(Farkas, 1902) (see also Schrijver, 1986, pg. 89) linear programming,matrix, b column vector, x column vector distinct variables:Lemma 4.3: Ax b unsatisfiable, exists row vector1. 02. = 03. b > 0.Intuitively, witness fact Ax b unsatisfiable.vector x satisfying Ax b, 0 = (A)x = (Ax) b > 0, contradiction.prove first claim, suppose = {s1 , . . . , sN }. construct set linearequations variables x1 , . . . , xN solution equations guaranteesexistence probability measure Pr (S) Pr = 1. Intuitively, wantxi Pr(si ). Since must Pr(E) f (E) E S,7 E S,Pinequality {i:si E}xi f (E). Note since f () = 1, equation/E = x1 + + xN 1. addition, require xi 0 = 1, . . . , N ,x1 + +xN = 1. suffices require x1 + +xn 1, since, observed earlier,equation corresponding E = already says x1 + + xn 1. apply Farkas Lemmainequalities need involve , collection inequalities must rewritten as:{i:si E}xi f (E), E/xi 0, = 1, . . . , Nx1 + + xN 1.Psystem inequalities expressed form Ax b. Note matrixwhose entries either 1, 0, 1, and, first 2N 1 rows (the lines correspondingequations E S), entries either 0 1, final N + 1rows, entries either 0 1.solution system inequalities provides desired Pr. systemssolution, Farkas Lemma, exists nonnegative vector = 0b > 0. Since entries either 1, 0, 1, follows standardobservations (cf., Fagin, Halpern, & Megiddo, 1990, Lemma 2.7) take vectorwhose entries rational.8 Since multiply term product7. use denote strict subset.8. slight subtlety since also satisfy b > 0, b may involve irrational numbers(since f (E) may irrational sets E). However, nonnegative satisfies = 0b > 0, nonnegative satisfies = 0 b0 > 0, b0 consistsrational entries b0 b. Thus, vector rational entries = 0 b0 > 0,b > 0.486fiWeighted Regret-Based Likelihooddenominators entries , assume without loss generalityentries natural numbers.Since 2N + N rows, vector form (1 , . . . , 2N +N ). Let A1 , . . . , A2N +Nrows A; vector length N . Since = 0, means1 A1 + + 2N +N A2N +N = 0. Suppose 2N , . . . , 2N +N 1 (the coefficientsrows corresponding inequalities xi 0 = 1, . . . , N ) 0; showbelow, assumption made without loss generality.assumption, rewrite equations 1 A1 +. . . 2N 1 A2N 1 = 2N +N A2N +N .E1 , . . . , E2N 1 subsets correspond equations A1 , . . . , A2N 1 ,respectively, equation says 1 copies E 1 , 2 copies E 2 , . . . , 2N 1 copiesE 2N 1 form 2N +N -cover S. (Recall A2N +N row 1s, A2N +N corresponds S.) Thus, REG3, 1 f (E1 ) + + 2N 1 f (E2N 1 ) 2N +N f () = 2N +N .Farkas Lemma requires b > 0, where, construction, bi = f (Ei ) =1, . . . , 2N 1, bi = 0 = 2N , . . . , 2N + N 1, b2N +N = 1. Thus, must(1 f (E1 )+ +2N 1 f (E2N 1 )) > 2N +N . Clearly, gives contradiction. Thus,conclude, desired, equations solvable, exists probabilitymeasure Pr Pr = 1.NNremains show assume without loss generality 2 , . . . , 2 +N 10. Note since 0, must nonnegative. prove induction2N + + 2N +N 1 vector 0 = 0 b > 0,vector 2N + + 2N +N 1 = 0.suppose solution 2N + + 2N +N 1 > 0. Suppose withoutloss generality 2N > 0. Recall A2N corresponds inequality x1 0.Choose j {0, . . . , 2N 1} j > 0 s1/ Ej . must j,otherwise would = 0. Let j 0 Ej 0 = Ej {s1 }. Define vector/ {j, j 0 , 2N }.0 20 N = 2N 1, j0 = j 1, j0 0 = j + 1, i0 =000easy check = 0 2N + + 2N +N 1 < 2N + + 2N +N 1 .remains show 0 b > 0. Since Ej Ej 0 , must f (Ej ) f (Ej 0 ),0 b = b + f (Ej ) f (Ej 0 ) b > 0. completes inductive step argument.+ (E)must show second required property holds, namely, f (E) = PregE S. construction, Pr Pr(E) f (E) E S, suffices showPr P Pr Pr(E) = f (E). this, suffices show existsmeasure Pr Pr(E) = 1, E 0 S, f (E) Pr(E 0 ) f (E 0 ), sincePr = f (E), Pr Pr(E) = f (E), desired.show measure exists, construct set linear inequalitiesmuch above, apply Farkas Lemma. Using notation above, supposesimplicity E = {s1 , . . . , sM }, N . required inequalities involvevariables x1 , . . . , xM :0{i:s EE 0 } xi f (E 0 )/f (E), E 0 E E 6=xi 0, = 1, . . . ,x1 + + xM 1.PAgain, requirement x1 + + xM 1 follows equation E.system inequalities satisfiable, required probability measure,suppose satisfiable. Again, writing system equations Ax b,487fiHalpernFarkas Lemma, exists nonnegative vector = 0 b > 0.proceed much before. Again, assume vector natural numbers.assume 2 , . . . , 2 +M 1 (the coefficients rows correspondinginequalities xi 0 = 1, . . . , N ) 0, fact = 0 means2M +M cover E. get contradiction REG3 almost identical wayabove. completes argument.said earlier, set P + guaranteed exist Theorem 4.2 unique, althoughcanonical, sense unique maximal set weighted probability measuresrepresents f . might wonder actually get uniqueness imposingextra requirements, particularly since Leung able representationtheorem. answer seems no. explain why, helpful review material(Halpern & Leung, 2012).Define sub-probability measure p like probability measure (i.e., functionmapping measurable subsets [0, 1] p(T 0 ) = p(T ) + p(T 0 ) disjointsets 0 ), without requirement p(S) = 1. identify weightedprobability distribution (Pr, ) sub-probability measure Pr. Conversely, givensub-probability measure p, unique pair (, Pr) P = Pr: simplytake = p(S) Pr = p/. Thus, sequel, identify set sub-probabilitymeasures set weighted probability measures.set B sub-probability measures downward-closed if, whenever p B q p,q B.One advantage considering sub-probability measures clearwould mean set weighted probabilities convex (indeed, obviouscount convex combination (Pr, ) (Pr0 , 0 )), quite clear countsconvex combination sub-probability measures. Moreover, convex combinationsub-probability measures sub-probability measure.Call set subprobability measures regular convex, downward-closed, closed,contains least one proper probability measure. (The latter requirement correspondsPr = 1 Pr P + .) Leung provide set axioms preferenceorders, show family preference orders indexed menus satisfiesaxioms iff unique regular set weighted probability measures P + that,b iff wrP + (a) wr P + (b). Thus, might hope get uniquenessimposing regularity requirement. easy see canonical maximal set P +constructed proof Theorem 4.2 regular, lends credence hope.Unfortunately, following example shows, regularity suffice uniqueness.Example 4.4: Let = {s1 , s2 }, let f defined 2S taking f ({s1 }) = 1/4f ({s2 }) = 1 (and f (S) = 0 f () = 1). sub-probability measure pidentified pair (p(s1 ), p(s2 )), makes easy think sub-probabilitymeasures geometrically. set sub-probability measures region IR2contained triangle bounded lines x = 0, = 0, = 1 x. set P +subprobability measures downward closed if, whenever contains point (x, y),contains (x0 , 0 ) rectangle defined points (0, 0), (x, 0), (0, y), (x, y).intuition, let P0+ set subprobabilities quadrilateral boundedx = 0, = 0, = 1 x, = 1/4 (the region marked vertical lines Figure 1).488fiWeighted Regret-Based Likelihoodhard show P0+ maximal set weighted probabilities representing f .+clearly regular. Since contains subprobability (1, 0), follows P0,reg({s2 }) = 1.++also easy see that, since (0, 1/4) P0 p(s2 ) 1/4 p P0 ,+P0,reg({s1 }) = 1/4.let P1+ consist sub-probabilities triangle bounded x = 0, = 0,+= 1x4 (the region marked horizontal lines Figure 1). Clearly P1 strict+subset P0 , clear figure also regular. Moreover, sincecontains points ( 41 , 0) (0, 1), also represents f . Indeed, easily followsgeometry situation uncountably many regular sets weightedprobabilities representing f ; z [0, 34 ], regular set bounded lines x = 0,= 0, = 14 , line (z, 41 ) (1, 0).1( 34 , 14 )140341xFigure 1: Regular sets weighted probability measures represent f .Intuitively, problem function contain enough informationuniquely determine regular set weighted probability measures. clear whethernatural conditions imposed lead uniqueness.seems closest come uniqueness consider maximal set.5. Conclusiondefined approach associating event E numerical representationlikelihood uncertainty represented set weighted probability measures.representation consists pair numbers, thought upperlower bounds uncertainty. difference numbers viewedmeasure ambiguity. two numbers coincide uncertainty representedsingle probability. Moreover, probability measure gets weight 1,two numbers essentially viewed lower upper probabilities E (moreprecisely, 1 P (E) 1 P (E)). Thus, approach viewed generalizationlower upper probability case weighted probability measures, regretbased likelihood corresponding upper probability. definitions show489fiHalperninteresting connection regret-based approaches minimization/maximizationapproaches comes defining likelihood; connection breaks comesgeneral utility calculations (Halpern & Leung, 2012).main technical result paper complete characterization likelihoodcase state space finite. notion likelihood easily extendedcase infinite state space (of course, integral used instead sumcalculate expected utility). conjecture characterization theorem still holdessentially change, although checked details carefully.course, would useful get better understanding numerical representation, see really captures agents feelings ambiguity riskassociated event, understand technical properties. leave futurework.Acknowledgmentsthank Samantha Leung, reviewers ECSQARU, JAIR referees many usefulcomments paper. work supported part NSF grants IIS-0812045, IIS0911036, CCF-1214844, AFOSR grants FA9550-08-1-0438, FA9550-09-1-0266,FA9550-12-1-0040, ARO grant W911NF-09-1-0281.ReferencesAnger, B., & Lembcke, J. (1985). Infinitely subadditive capacities upper envelopesmeasures. Zeitschrift fur Wahrscheinlichkeitstheorie und Verwandte Gebiete, 68, 403414.Boole, G. (1854). Investigation Laws Thought FoundedMathematical Theories Logic Probabilities. Macmillan, London.Campos, L. M. d., & Moral, S. (1995). Independence concepts sets probabilities.Proc. Eleventh Conference Uncertainty Artificial Intelligence (UAI 95), pp.108115.Cattaneo, M. E. G. V. (2007). Statistical decisions based directly likeihood function.Ph.D. thesis, ETH.Chateauneuf, A., & Faro, J. (2009). Ambiguity confidence functions. JournalMathematical Economics, 45, 535 558.Couso, I., Moral, S., & Walley, P. (1999). Examples independence imprecise probabilities. Proc. First International Symposium Imprecise ProbabilitiesApplications (ISIPTA 99).de Cooman, G. (2005). behavioral model vague probability assessments. Fuzzy SetsSystems, 154 (3), 305358.Dubois, D., & Prade, H. (1998). Possibility measures: qualitative quantitative aspects.Gabbay, D. M., & Smets, P. (Eds.), Quantified Representation Uncertainty490fiWeighted Regret-Based LikelihoodImprecision, Vol. 1 Handbook Defeasible Reasoning Uncertainty ManagementSystems, pp. 169226. Kluwer, Dordrecht, Netherlands.Epstein, L., & Schneider, M. (2007). Learning ambiguity. Review EconomicStudies, 74 (4), 12751303.Fagin, R., Halpern, J. Y., & Megiddo, N. (1990). logic reasoning probabilities.Information Computation, 87 (1/2), 78128.Farkas, J. (1902). Theorie der enfachen ungleichungen. J. Reine und Angewandte Math.,124, 127.Gardenfors, P., & Sahlin, N. (1982). Unreliable probabilities, risk taking, decisionmaking. Synthese, 53, 361386.Gardenfors, P., & Sahlin, N. (1983). Decision making unreliable probabilities. BritishJournal Mathematical Statistical Psychology, 36, 240251.Gilboa, I., & Schmeidler, D. (1989). Maxmin expected utility non-unique prior.Journal Mathematical Economics, 18, 141153.Gilboa, I., & Schmeidler, D. (1993). Updating ambiguous beliefs. Journal EconomicTheory, 59, 3349.Giles, R. (1982). Foundations theory possibility. Gupta, M. M., & Sanchez, E.(Eds.), Fuzzy Information Decision Processes, pp. 183195. North-Holland.Good, I. J. (1980). history hierarchical Bayesian methodology. Bernardo,J. M., DeGroot, M. H., Lindley, D., & Smith, A. (Eds.), Bayesian Statistic I, pp.489504. University Press: Valencia.Halpern, J. Y. (1997). Defining relative likelihood partially-ordered preferential structures. Journal A.I. Research, 7, 124.Halpern, J. Y. (2003). Reasoning Uncertainty. MIT Press, Cambridge, Mass.Halpern, J. Y., & Leung, S. (2012). Weighted sets probabilities minimax weightedexpected regret: new approaches representing uncertainty making decisions.Proc. Twenty-Ninth Conference Uncertainty Artificial Intelligence (UAI 2012),pp. 336345. appear, Theory Decision.Halpern, J. Y., & Pucella, R. (2002). logic reasoning upper probabilities.Journal A.I. Research, 17, 5781.Huber, P. J. (1976). Kapazitaten statt Wahrscheinlichkeiten? Gedanken zur Grundlegungder Statistik. Jahresbericht der Deutschen Mathematiker-Vereinigung, 78, 8192.Huber, P. J. (1981). Robust Statistics. Wiley, New York.Klibanoff, P., Marinacci, M., & Mukerji, S. (2005). smooth model decision makingambiguity. Econometrica, 73 (6), 18491892.491fiHalpernKyburg, Jr., H. E. (1988). Higher order probabilities intervals. International JournalApproximate Reasoning, 2, 195209.Levi, I. (1985). Imprecision uncertainty probability judgment. Philosophy Science,52, 390406.Lorentz, G. G. (1952). Multiply subadditive functions. Canadian Journal Mathematics,4 (4), 455462.Maccheroni, F., Marinacci, M., & Rustichini, A. (2006). Ambiguity aversion, robustness,variational representation preferences. Econometrica, 74 (6), 14471498.Moral, S. (1992). Calculating uncertainty intervals conditional convex sets probabilities. Proc. Eighth Conference Uncertainty Artificial Intelligence (UAI95), pp. 199206.Nau, R. F. (1992). Indeterminate probabilities finite sets. Annals Statistics, 40 (4),17371767.Niehans, J. (1948). Zur preisbildung bei ungewissen erwartungen. Schweizerische Zeitschriftfur Volkswirtschaft und Statistik, 84 (5), 433456.Ostrogradsky, M. V. (1838). Extrait dun memoire sur la probabilite des erreurs des tribuneaux. Memoires dAcademie St. Petersbourg, Series 6, 3, xixxxv.Pearl, J. (1987). need higher-order probabilities and, so, mean?.Proc. Third Workshop Uncertainty Artificial Intelligence (UAI 87), pp. 4760.Savage, L. J. (1951). theory statistical decision. Journal American StatisticalAssociation, 46, 5567.Schrijver, A. (1986). Theory Linear Integer Programming. Wiley, New York.Scott, D. (1964). Measurement structures linear inequalities. Journal MathematicalPsychology, 1, 233247.Walley, P. (1991). Statistical Reasoning Imprecise Probabilities, Vol. 42 MonographsStatistics Applied Probability. Chapman Hall, London.Walley, P. (1997). Statistical inferences based second-order possibility distribution.International Journal General Systems, 26 (4), 337383.Williams, P. M. (1976). Indeterminate probabilities. Przelecki, M., Szaniawski, K., &Wojcicki, R. (Eds.), Formal Methods Methodology Empirical Sciences, pp.229246. Reidel, Dordrecht, Netherlands.Wolf, G. (1977). Obere und untere Wahrscheinlichkeiten. Ph.D. thesis, ETH, Zurich.Zadeh, L. A. (1978). Fuzzy sets basis theory possibility. Fuzzy Sets Systems,1, 328.492fiJournal Artificial Intelligence Research 54 (2015) 277-308Submitted 12/14; published 10/15Relations Spatial CalculiDirections OrientationsTill Mossakowskitill@iws.cs.uni-magdeburg.deOtto-von-Guericke-University Magdeburg,Faculty Computer ScienceUniversittsplatz 239106 MagdeburgReinhard Moratzreinhard.moratz@maine.eduUniversity Maine,National Center Geographic Information Analysis,School Computing Information Science,348 Boardman Hall, Orono, 04469 Maine, USA.AbstractQualitative spatial descriptions characterize essential properties spatial objectsconfigurations relying relative comparisons rather measuring. Typically,qualitative approaches relatively coarse distinctions configurations made.Qualitative spatial knowledge used represent incomplete underdeterminedknowledge systematic way. especially useful task describe featuresclasses configurations rather individual configurations.Although reasoning generally NP-hard (even IR-complete), relative directions important play key role human spatial descriptionsseveral approaches represent using qualitative methods. approachesdirections spatial locations expressed constraints infinite domains,e.g. Euclidean plane. theory relation algebras successfully appliedfield. Viewing relation algebras universal algebras applying modifyingstandard tools universal algebra work, (re)define notions qualitative constraint calculus, homomorphism calculi, quotient calculi.Basedmethod derive important properties spatial calculi corresponding propertiesrelated calculi. conceptual point view formal mappings calculimeans translate different granularities.1. Introductionqualitative representation space and/or time provides mechanisms characterizeessential properties objects configurations. advantages quantitative representations be: (1) better match human concepts related natural language,(2) better efficiency reasoning. two main trends qualitative spatial constraintreasoning (Ligozat, 2011) topological reasoning regions (Randell & Cohn, 1989;Randell, Cui, & Cohn, 1992; Egenhofer & Franzosa, 1991; Renz & Nebel, 1999; Worboys& Clementini, 2001) reasoning directions points straight linesorientations straight lines configurations derived points (Frank, 1991; Ligozat,1998; Renz & Mitra, 2004; Freksa, 1992; Clementini, Felice, & Hernandez, 1997; Scivos &c2015AI Access Foundation. rights reserved.fiMossakowski & MoratzNebel, 2004; Moratz, Lcke, & Mossakowski, 2011; Mossakowski & Moratz, 2012; Dubba,Bhatt, Dylla, Cohn, & Hogg, 2015).constraint-based reasoning spatial configurations, typically partial initialknowledge scene represented terms qualitative constraints spatial objects. Implicit knowledge spatial relations derived constraint propagation.Previous research found mathematical notion relation algebra relatednotions well-suited kind reasoning. particular, arbitrary relation algebra, well-known path consistency algorithm (Montanari, 1974) computes algebraicclosure given constraint network, approximates, many cases also decides,consistency network polynomial time. Intelligent backtracking techniquesstudy maximal tractable subclasses also allow efficiently deciding networks involvingdisjunctions. Starting Allens temporal interval algebra, approach successfully applied several qualitative constraint calculi, supported freelyavailable toolboxes (Gantner, Westphal, & Wlfl, 2008; Wallgrn, Frommberger, Wolter,Dylla, & Freksa, 2006). Moreover, people started develop benchmark problem libraries (Nebel & Wlfl, 2009) shown method performs quite well alsocompared constraint reasoning techniques (Westphal & Wlfl, 2009).work, apply universal algebraic tools qualitative calculi. connectionprevious investigated literature (Li, Kowalski, Renz, & Li, 2008; Bodirsky, 2008;Huang, 2012). However, paper deviate standard universal algebra using laxoplax homomorphisms, weaker properties standard homomorphisms(and order-theoretic algebraic flavor), better suited transferofalgebraic structure qualitative calculi DRAfp , OPRA1 CYC b .work, focus calculi binary relations only.2. Relation Algebras Spatial ReasoningStandard methods developed finite domains generally apply constraint reasoning infinite domains. theory relation algebras (Ladkin & Maddux, 1994;Maddux, 2006) allows purely symbolic treatment constraint satisfaction problemsinvolving relations infinite domains. corresponding constraint reasoning techniquesoriginally introduced Montanari (1974), applied temporal reasoning (Allen, 1983)later proved valuable spatial reasoning (Renz & Nebel, 1999; Isli & Cohn, 2000).central data binary calculus given by:list (symbolic names for) base-relations, interpreted relationsdomain, crucial JEPD properties joint exhaustiveness pairwise disjointness (a general relation simply union base-relations).table computation converses relations.table computation compositions relations.Then, path consistency algorithm (Montanari, 1974) backtracking techniques (vanBeek & Manchak, 1996) tools used tackle problem consistency constraintnetworks related problems. algorithms implemented genericreasoning toolboxes GQR (Gantner, Westphal, & Wlfl, 2008) SparQ (Wallgrn et al.,278fiRelations Spatial Calculi2006). integrate new calculus tools, list base-relations tablescompositions converses (plus compositional identity, however reallyused) need provided. Thereby, qualitative reasoning facilities tools becomeavailable calculus.1 Since compositions converses general relationsreduced compositions converses base-relations, tables need givenbase-relations. Based tables, tools provide means approximateconsistency constraint networks, list atomic refinements, (see Section 4details).Let b base-relation. converse b` = {(x, y)|(y, x) b} often baserelation. Since base-relations generally closed composition, operationapproximated weak composition:[b1 b2 = {b base-relation | (b1 b2 ) b 6= }b1 b2 usual set theoretic compositionb1 b2 = {(x, z)|y . (x, y) b1 , (y, z) b2 }Composition said strong b1 b2 = b1 b2 base-relations b1 , b2 . Generally,b1 b2 over-approximates set-theoretic composition, strong composition capturesexactly.mathematical background composition table-based reasoning giventheory relation algebras (Maddux, 2006; Renz & Nebel, 2007). many calculi, includingdipole calculus (see Ex. 9 below), slightly weaker notion needed, namelynon-associative algebra (Maddux, 2006; Ligozat & Renz, 2004), associativitydropped. algebras treat spatial relations abstract entities (independentlydomain) combined certain operations governed certain equations.Definition 1 (Maddux 2006; Ligozat & Renz 2004). non-associative algebra tuple= (A, , , , 0, 1, ,` , ) that:1. (A, , , , 0, 1) Boolean algebra. called join, meet, 0 bottom, 1 top,relative complement. Note Boolean algebra carries partial order definedb iff b = b;2. constant (called identity relation), ` unary operation (called converse)binary operation (called weak composition) that, a, b, c A:(a) (a` )` =(b) = =(c) (b c) = b c(d) (a b)` = a` b` (e) (a b)` = a` b` (f ) (a b)` = b` a`(g) (a b) c` = 0 (b c) a` = 0non-associative algebra called relation algebra, weak composition associative.21. information calculus, tools provide functionality goes beyondsimple qualitative reasoning constraint calculi.2. terminology bit misleading, since relation algebras associative non-associative algebras.precise name non-associative algebras would relation algebras without associativity requirement. Nevertheless, stick terminology established literature.279fiMossakowski & Moratzelements algebra called (abstract) relations. mainlyinterested finite non-associative algebras complete atomic, meansset pairwise disjoint minimal relations, atoms, also called base-relations,relations obtained joins these. Then, following fact well-knowneasy prove:Proposition 2 (Dntsch, 2005). complete atomic non-associative algebra uniquelydetermined set base-relations, together converses compositions baserelations. (Note composition two base-relations general base-relation.)providing examples, easier start partition schemes:Definition 3 (Ligozat & Renz, 2004; Mossakowski et al., 2006). Let U non-empty set.partition scheme U defined finite (index) set distinguished elementi0 I, unary operation ` I, family binary relations (Ri )iI U1. (Ri )iI partition U U sense Ri pairwise disjoint jointlyexhaustive.2. Ri0 diagonal relation {(x, x) | x U }.3. Ri` (set-theoretical) converse relation Ri , I.relations Ri referred basic relations. following often writeU U =[RiiIdenote partition schemes.Proposition 4 (Ligozat & Renz, 2004; Mossakowski et al., 2006). Given partition schemeU U =[RiiIobtain non-associative algebra follows: Boolean algebra component P(I),powerset I. converse given pointwise application ` ; diagonal i0 .Composition given weak composition defined above.introduce several qualitative calculi giving domain U setbasic relations; diagonal converse clear.Example 5. prominent temporal calculus Allens interval algebra IA (Allen,1983), describes possible relations intervals linear flows time3 .interval pair (s, t) real numbers < t. 13 basic relationsintervals depicted Fig. 1.3. also spatial interpretation Allen calculus intervals interpretedone-dimensional spatial entities280fiRelations Spatial CalculiFigure 1: Allens interval relationsFigure 2: CYC b relations. r B means B right A.Example 6. CYC b calculus (Isli & Cohn, 2000) based domain CYC = { |< } cyclic orientations. Equivalently, angles representedoriented straight lines containing origin 2D Euclidian plane associatedreference system. Using latter representation, Fig. 2 depicts four base-relations r, l,o, e (e.g. right, left, opposite, equal) CYC b .converse composition tables follows:belrb`erlelrelell {l, o, r}rr {e, l, r}281rrr {e, l, r}ell {l, o, r}fiMossakowski & MoratzExample 7. OPRAn calculus (Moratz, 2006; Mossakowski & Moratz, 2012) baseddomain OP = {(p, ) | p R2 , < } oriented points Euclidean plane.oriented point consists point angle serving orientation. full angledivided using n axes, leading 4n regions, see Fig. 3. points B differ,0 15 141 01312112345133B61097 8 9 107 8Figure 3: Two o-points relation 4313 Brelation mji B (i, j Z4m 4 ) reads like this: given granularity m, relative positionB respect described relative position respect Bdescribed j. points B coincide, relation mi B expressesdifference Bs orientations (angles) region i.special case OPRAn calculus n = 1 (e.g. OPRA1 ) cognitively motivated symbolic notation addition general notation OPRAn baserelations introduced above. Fig. 4 depicts oriented point corresponding divisionplane regions Front, Left, Right Back (the latter standspoint itself). naming schema OPRA1 base-relations concatenates namerelative position second oriented point w.r.t. first relative positionfirst oriented point w.r.t. second. Using capitalization first part relation symbol, cognitively motivated schema relation names leads names16 base-relations OPRA1 : FRONTfront, FRONTleft, FRONTright, FRONTback, LEFTfront, LEFTleft, LEFTright, LEFTback, RIGHTfront, RIGHTleft, RIGHTright,RIGHTback, BACKfront, BACKleft, BACKright, BACKback. Again, pointscoincide, compare orientations. leads relations SAMEfront, SAMEleft,SAMEright SAMEback.SAMEfront identity relation. SAMEback analogous opposite relationCYC b (see Fig. 2). Also SAMEleft SAMEright analogous corresponding CYC brelations.Example 8. OPRAm calculus (Dylla, 2008) similar OPRAm . Here, concentrate OPRA1 . important extension refinement applied relationsRIGHTright, RIGHTleft, LEFTleft, LEFTright. relations refined markingletters + , P A, according whether two orientationsoriented points positive, negative, parallel anti-parallel, similar Fig. 6:LEFTleft refined LEFTleftA, LEFTleft+ LEFTleft-.4. Z4m residue ring; simplicity, set Z4m = {0, . . . , 4m 1}.282fiRelations Spatial CalculiFigure 4: OPRA1 base frameLEFT right refined LEFTrightP, LEFTright+ LEFTright-.RIGHTright refined RIGHTrightA, RIGHTright+ RIGHTright-.RIGHT left refined RIGHTleftP, RIGHTleft+ RIGHTleft-.remaining four options LEFTleftP, LEFTrightA, RIGHTrightP RIGHTleftAgeometrically impossible. Altogether, obtain set 28 base-relations.Example 9. dipole pair distinct points Euclidean plane. explainingdipole-dipole relations, first study dipole-point relations. distinguish whetherpoint lies left, right, one five qualitatively different locationsstraight line passes corresponding dipole (Ligozat, 1993; Scivos & Nebel,2004). corresponding regions shown right side Fig. 5.Using seven possible relations dipole point, relationstwo dipoles may specified according following conjunction four relationships:R1 sB R2 eB B R3 sA B R4 eA , 5Ri {l, r, b, s, i, e, f} 1 4. formal combination gives us 2401 relations,72 relations geometrically possible. constitute DRAf calculus(Moratz, Renz, & Wolter, 2000; Moratz, Lcke, & Mossakowski, 2011). example,Fig. 5, relation lrrr B holds.BsBfeAeBerlsAbl r rr BFigure 5: Orientation two dipoles based four dipole-point relationsFig. 6 shows refinement DRAf , called DRAfp , additional distinguishing features due parallelism. relations different rrrr, llrr rrll llll, +,, P already determined original base-relationmentioned explicitly. base-relations relation symbol DRAf .leads set 80 DRAfp base-relations. relation sese identity relation.denote resulting non-associative algebra DRAfp .5. Note e.g. r sB reads sB right A.283fiMossakowski & Moratzrrrr BrrrrArrrrrrrr+rrll BrrllPrrllrrll+llll BllllAllllllll+llrr BllrrPllrrllrr+Figure 6: Refined base-relations DRAfp . solid arrow denotes A, dashed arrowdenotes B.3. Homomorphisms Weak Representationspresented calculi offer possibility describe scenes different levels granularity.granularity description context-dependent selection adequate leveldetail description (Hobbs, 1985). Granularity plays key role human strategiesdeal complexity spatial features real world. demonstratednicely example Hobbs (1985). example points humans conceptualize streets one-dimensional entities plan trip, use two-dimensionalconception cross street. contexts pavement dugstreet becomes three-dimensional volume. key importance mechanismsflexibly switch translate granularities successful reasoning worldhighlighted following quote Hobbs (1985, p. 432):ability conceptualize world different granularities switchamong granularities fundamental intelligence flexibility.enables us map complexities world around us simple theoriescomputationally tractable reason in.Imagine scenario involving ships relative positions open sea (see Fig. 7).Ships modelled elongated, directed entities neglecting widthshape property. resulting DRAfp representation uses single dipole ship284fiRelations Spatial Calculirepresented (see left part Fig. 7). OPRA1 representation addition evenlengths ships neglected (see middle part Fig. 7). CYC b representation abstracts away different locations ships focuses relative orientation(see right part Fig. 7).abstraction shapeabstraction lengthabstraction locationFigure 7: Modelling relative ship directions different levels granularity DRAfp ,OPRA1 , CYC b .another example ships represented DRAfp way start pointcorresponds position ship end point represents current speed.specifically, end point denotes future position one minute travel (if speedheading constant). longer arrows represent faster ships diagram.alternative representation OPRA1 , representation might focuslocation heading ships abstract away speed. severalDRAfp relations one representation map onto single OPRA1 relation alternativerepresentation. example three relations {flll, ells, illr} mapped FRONTleft(see Fig. 8).Figure 8: quotient homomorphism DRAfp OPRA1 three relations{flll, ells, illr} mapped FRONTleft.different spatial calculi used represent given spatial situation differentlevels granularity, relation calculi typically formalized quotienthomomorphism. Figure 8 exemplifies action quotient homomorphism. Homomorphisms also arise contexts, e.g. embeddings smaller calculus larger285fiMossakowski & Moratzone (for example, Allens interval algebra embedded DRAfp , see Proposition 25below).study homomorphisms general. means examinationrelationships among calculi. Often, conceptual relations different calculidomains formalised homomorphism, vice versa, one found homomorphism, often also conceptual relation behind it.Homomorphisms also used transfer properties (like strength composition,algebraic closure deciding consistency) one calculus another one, see Propositions16, 19, 23, 39, 40, 44, 46, 47 48 below. Using homomorphisms, also possible finderrors composition tables (we discovered errors 197 entries composition tableOPRA1 , see Example 38 below).Homomorphisms studied Ligozat Renz (2004) Ligozat (2005, 2011)(mainly name representations). introduce systematic treatmenthomomorphisms. non-associative algebras, recall refine weaker notionlax homomorphisms, allow embedding calculus domain,well relating several calculi other.Definition 10 (Lax homomorphism, Moratz et al., 2009; Lcke, 2012). Given non-associativealgebras B, lax homomorphism homomorphism h : B underlyingBoolean algebras that:h(A ) Bh(a` ) = h(a)`h(a b) h(a) h(b) a, blax homomorphism complete atomic non-associative algebras called semistrong (Mossakowski, Schrder, & Wlfl, 2006) atoms a, bab=_{c | (h(a) h(b)) h(c) 6= 0}notion inspired definition weak composition usedrepresentation homomorphisms qualitative calculi.Dually lax homomorphisms, define oplax homomorphisms6 , enable usdefine projections one calculus another.Definition 11 (Oplax homomorphism, Moratz et al., 2009; Lcke, 2012). Given nonassociative algebras B, oplax homomorphism homomorphism h : Bunderlying Boolean algebras that:h(A ) Bh(a` ) = h(a)`h(a b) h(a) h(b) a, b6. terminology motivated monoidal functors.286fiRelations Spatial Calculiquotients, introduce strengthening notion oplax homomorphism.full 7 homomorphism oplax homomorphism even_h(c d)h(a) h(b) =h(a)=h(c),h(b)=h(d)proper homomorphism (sometimes called homomorphism) non-associativealgebras homomorphism lax oplax time; inequalitiesturn equations. proper homomorphism also full. proper injectivehomomorphism also semi-strong.homomorphism complete atomic non-associative algebras givenaction base-relations; extended general relations__h( bi ) =h(bi ),iIiIWarbitrary (possibly infinite) join. sequel, always define homomorphisms way.semi-strong lax homomorphisms used transfer compositiontarget source algebra, surjective full oplax homomorphisms used transferopposite direction. study latter, former treated Def. 20.Definition 12. Given complete atomic non-associative algebra equivalencerelation atoms congruence _` , define quotient algebraA/A equivalence classes A-atoms atoms. General relations setsatoms. define atoms a, b:A/ = {[a] | }[a]` = [a` ][a] [b] = {[c] | c a0 b0 , a0 a, b0 b}usual treat general relations sets atoms; hence general relations A/Asets equivalence classes A-atoms.Unfortunately, general, A/A non-associative algebra again:Example 13. Consider relation algebra CYC b calculus (Example 6)equivalence relation generated e. quotient algebra fails satisfy identitylaws (laws (b) Def. 1). seen quotient composition table:{e, o}{l}{r}{e, o}{l}{r}{e, o}{{l}, {r}}{{l}, {r}}{{l}, {r}} {{e, o}, {l}, {r}} {{e, o}, {l}, {r}}{{l}, {r}} {{e, o}, {l}, {r}} {{e, o}, {l}, {r}}7. terminology borrowed theory partial algebras (Burmeister, 1986). Burmeister (2002,p. 101) puts follows: f full iff f fully induces structure direct image f (A).exactly want here, too.287fiMossakowski & Moratzstudy method prove A/A non-associative algebra lateradditional conditions. now, straightforward prove:Proposition 14. algebra A/A defined Def. 12 non-associative algebra,homomorphism q : A/A given 7 [a] surjective full.naturally leads to:Definition 15. oplax homomorphism non-associative algebras said quotienthomomorphism full surjective.easy standard result universal algebra (Grtzer, 1979) gives us:Proposition 16. Proper quotient homomorphisms preserve holding equations,particular, associativity.However, non-proper quotient homomorphisms general preserve holdingequations. See Example 35: DRAfp associative, quotient DRAf not.raises question use standard constructions resultsuniversal algebra (Grtzer, 1979; Maddux, 2006), homomorphisms always properhence quotients preserve equations (Prop. 16) thus quotient non-associativealgebra non-associative algebra again. reason following:Example 17. Consider point algebra induced three base-relations <, = >,converse composition tables:<=>a`>=<<=><<<{<, =, >}=>< {<, =, >}=>>>Let standard algebraic congruence relation generated <>. < equal< <, congruent < >, {<, =, >}. Similarly, > congruent{<, =, >}. Since congruence respects meet, obtain < >, , congruent{<, =, >}. means congruence trivial standard algebraic quotienttrivial one-point relation algebra.contrast, notion quotient, obtain following relation algebra,expected one (we denote equivalence class {<, >} 6=):6==a`6==6==6=={6=, =} 6=6==corresponding quotient homomorphism proper: q(<) q(<) 6= =6 ,{6=, =}, q(< <) = q(<), 6=. However, Prop. 14, surjective full.Proposition 18. context Prop. 14, q proper, A/A non-associativealgebra.288fiRelations Spatial CalculiProof. Prop. 16, know equations preserved q. axiom Def. 1equational form (g). Tarski shown (Maddux, 2006) (g) equivalent(a` (1 (a b))) (1 b) = 1 bimportant application quotients quotient homomorphisms lies followingfact:Proposition 19. Given quotient homomorphism q : B, Bs converse composition tables computed A, using q.Proof. Use formulas converse resp. composition definition full homomorphism. Since q surjective, formulas work elements B.Another important application homomorphisms use definitionqualitative calculus. Ligozat Renz (2004) define qualitative calculus termsso-called weak representation (Ligozat, 2005, 2011):Definition 20 (Weak representation). weak representation : P(U U)8identity-preserving (i.e. (A ) = B ) converse-preserving lax homomorphismcomplete atomic non-associative algebra relation algebra domain U.latter given canonical relation algebra powerset P(U U), identity,converse composition (as well Boolean algebra operations) givenset-theoretic interpretations. weak representation semi-strong semi-strong.strong, strong.Example 21. Let = {(s, e) | s, e R2 , 6= e} set dipoles R2 .weak representation DRAfp lax homomorphism f : DRAfp P(D D) givenf (b) = b.Here, b left hand-side equation element abstract relationalgebra, b right hand-side set-theoretic extension relation. Sincechosen use set-theoretic relations elements relation algebra,same.generalized follows:Proposition 22. Semi-strong representations partition schemes one-one correspondence.Proof. Given partition scheme, bySProp. 4, obtain non-associative algebra. Letmap general relation R P(I) iR Ri . definition weak composition ensuressemi-strong lax homomorphism. Conversely, given semi-strong representation: P(U U), define partition scheme atoms putting Ra := (a).8. Note domain codomain part weak representation.289fiMossakowski & MoratzPreservation top, bottom meet ensure JEPD property. Moreover, semistrength, composition weak composition according partition scheme.clear constructions inverses other.following propositions straightforward.Proposition 23 (Moratz et al., 2009; Lcke, 2012). calculus strong compositionweak representation proper homomorphism.Proposition 24 (Ligozat, 2005). weak representation injective (b) 6=base-relation b.first sample use homomorphism embedding Allens interval relations (Allen,1983) DRAfp via homomorphism.Proposition 25 (Moratz et al., 2011). proper homomorphism Allens interval algebraDRAfp exists given following mapping base-relations.equalsmeetsoverlapsstartsfinishes7777777seseffbbefbsifbibfiisfsibeie`meets `overlaps ``starts `finishes `777777bbffbsefbiifiibfsisfiebestudying quotients calculi, natural consider homomorphisms weakrepresentations. refine notion Moratz et al. (2009) Lcke (2012) orderfit better examples:Definition 26. Given weak representations : P(U U) : B P(V V),{lax, oplax, full, proper} b {lax, oplax, proper}, (a,b)-homomorphism weakrepresentations (h, i) : givena-homomorphism non-associative algebras h : B,map : U V, diagramP(U U)P(i i)hBP(V V)290fiRelations Spatial Calculicommutes according b. Here, lax commutation means R A, (h(R))P(ii)((R)), oplax commutation means , proper commutation =.Note P(ii) obvious extension function relation algebras;note (unless bijective) even homomorphism Boolean algebras (itmay fail preserve top, intersections complements), although satisfies oplaxnessproperty (and laxness property injective)9 .Ligozat (2005) defines special notion morphism weak representations;corresponds notion (proper,oplax) homomorphism weak representationscomponent h identity.Example 27. homomorphism Prop. 25 extended (proper, proper)homomorphism weak representations letting embedding time intervalsdipoles x-axis.Definition 28. quotient homomorphism weak representations (full,oplax) homomorphism weak representations surjective components.also refine construction weak representation equivalence relationdomain introduced Moratz et al. (2009) Lcke (2012), whose constructionstypical cases produce trivial one-point quotient, cf. Example 17.Definition 29. Given weak representation : P(U U) equivalence relationU congruence _` , obtain quotient representation / follows:P(U U)qAA/AP(q q)P(U/ U/)/Let q : U U/ set-theoretic factorization U ;q extends relations: P(q q) : P(U U) P(U/ U/);let equivalence relation atoms generatedP(q q)((b1 )) P(q q)((b2 )) 6= b1 b2base-relations b1 , b2 A;let qA : A/A quotient sense Def. 12;9. reader background category theory may notice categorically natural formulation would use contravariant powerset functor, yields homomorphisms Boolean algebras(Mossakowski et al., 2006). However, present formulation fits better examples.291fiMossakowski & Moratzfinally, function / defined1/(R) = P(q q)((qA(R))).called regular w.r.t. kernel P(q q) (i.e. set pairsmade equal P(q q) ). case, base-relation b already generates (viaP(q q) ) full relation equivalence class [b] A/A .Proposition 30. Let strong representation : P(U U) complete atomic nonassociative algebra equivalence relation U given,1. identity-regular, ((a) ) 6= implies (a)2. congruence converse,3. enjoys following fill-in property: u(a)x u y, exist a0z xu(a)x(a0 )zA/A defined Def. 29 non-associative algebra, qA : A/A quotienthomomorphism, / semi-strong lax homomorphism non-associative algebras.Proof. use atoms A/A define partition scheme b At(A/A ) 7 /(b).Note know A/A Boolean algebra (although know yetnon-associative algebra). straightforward show / preserves bottomjoins; since q surjective, also top preserved. Concerning meets, since general relationsA/A considered sets base-relations, suffices show b1 b2 = 011(b2 ))) = . Assume contrary P(q(b1 ))) P(q q)((qAimplies P(q q)((qA11q)((qA (b1 )))P(qq)((qA (b2 ))) 6= . already P(qq)((b01 ))P(qq)((b02 )) 6=1base-relations b0i qA(bi ), = 1, 2. b01 b02 , hence qA (b01 ) = qA (b02 ) b1 b2 ,contradicting b1 b2 = 0. preservation properties, JEPD property follows.identity-regularity converse congruence, condition partition schemeidentity converse fulfilled.Prop. 22, obtain semi-strong representation / : B P(U/ U/).order show A/A non-associative algebra, show A/A = B. alreadyknow atoms thus agree complete atomic Boolean algebras.show agreement remaining operations:Identity: Since identity-preserving, atomic. identity-regularity, B = [A ] =A/A .Converse: Since congruence converse, atomic relation A, [a]`B =[a`A ] = [a]`A/A .292fiRelations Spatial CalculiComposition: Given atomic relations a, b A, [c] [a] B [b] iff (by definitionweak composition) exist x, y, z [x] /(a) [y] /(b) [z] [x] /(c) [z]iff (by definition /) exist x1 , x2 , y1 , x2 , z1 , z2 a0 a, b0 b, c0 cx1 (a0 ) y1y2 (b0 ) z1(c0 )x2z2fill-in property, equivalent (implicitly quantifying variables existentially omitting a0 a, b0 b, c0 c):x1 (a0 )(b0 ) z1(c0 )x2z2strength , equivalentx1 (a0 b0 ) z1x2(c0 )z2turn equivalent c0 c00 (a0 b0 ) (for c00 a0 a, b0 b, c0 c).equivalent [c] [a] A/A [b].completes proof A/A non-associative algebra. Prop. 14, qA :A/A quotient homomorphism, Prop. 22, / semi-strong lax homomorphism.interesting open question whether Prop. 30 also holds semi-strong representations. conjecture answer positive. Note / fail strong even(consider quotient DRAf DRAfp introduced Example 35).Example 31. CYC b quotient OPRA1 . level domains, acts follows:oriented point (p, ) mapped orientation (the point p forgotten).level non-associative algebras, quotient given table Fig. 9.Proposition 32. conditions Prop. 30, (qA , q) : / (full, oplax)quotient homomorphism semi-strong representations. regular w.r.t. , (qA , q)(full,proper) satisfies following universal property: (qB : B, : UV) : another (full,proper) homomorphism weak representations injectiveker (i), unique (full,proper) homomorphism weak representations(h, k) : / (qB , i) = (h, k) (qA , q).293fiMossakowski & Moratz{LEFTleftA, FRONTfront, BACKback, RIGHTrightA, SAMEback} 7{LEFTleft+, LEFTback, LEFTright+, RIGHTright+, RIGHTleft+,RIGHTfront, FRONTleft, BACKright, SAMEleft} 7 l{LEFTleft, LEFTfront, LEFTright, RIGHTright, RIGHTleft,RIGHTback, FRONTright, BACKleft, SAMEright} 7 r{LEFTrightP, RIGHTleftP, FRONTback, BACKfront, SAMEfront} 7 eFigure 9: Mapping OPRA1 CYC b relationsProof. (full,_) property10 follows Prop. 14. (_,oplax) property (qA , q)P(q q) / qA , definition / amounts1qA ,P(q q) P(q q) qAfollows surjectivity q. Regularity w.r.t. means kernel P(q q) , turns inequation equality; hence obtain(_,properness). Concerning universal property, let (qB , i) : mentionedproperties given. Since ker (i), unique function k : U/ V = k q.homomorphism h looking determined uniquely h(qA (b)) = qB (b);also ensures (full,proper) homomorphism property. remains shownwell-definedness. Suppose b1 b2 . regularity, P(q q)((b1 )) = P(q q)((b2 )).Hence also P(i i)((b1 )) = P(i i)((b2 )) (qB (b1 )) = (qB (b2 )). injectivity, get qB (b1 ) = qB (b2 ).Example 33. equivalence relation quotient Ex. 31 regular, consequently,quotient weak representations (full,proper), cf. Fig. 10 illustratingrelation RIGHTright+.far, studied quotients arising quotienting domain. alsoquotients leaving domain intact identifying certain base-relations.Proposition 34. Let : P(U U) semi-strong representation complete atomicnon-associative algebra 11 equivalence relation atoms (base-relations)relate relation congruence _` .leads (full, oplax) quotient weak representation follows:10. write _ placeholder dont care, i.e. (full,_) refers fullness first component.11. Note contrast Def. 29, constructed, parameter chosen.294fiRelations Spatial CalculiFigure 10: OPRA1 relation RIGHTright+ generates possible angles CYC brelation r.P(U U)qAA/AP(id id)P(U U)/Proof. Let qA : A/A defined Def. 12. / defined similarlyDef. 29 (where q = id). this, get semi-strong representation / : BP(U U) Prop. 30. proof A/A = B parallels Prop. 30Boolean algebra structure converse. identity, use assumption ,implies A/A = {A }. Concerning composition, need semi-strength only:[c] [a] B [b] iff exist x, y, z x /(a) /(b) z x/(c)z iff existx, y, z a0 a, b0 b, c0 c x a0 b0 z x c0 z iff (by semi-strength) exista0 a, b0 b, c0 c c0 a0 b0 iff [c] [a] A/A [b].(full, oplax)-property follows Prop. 14 Prop. 32.Example 35. DRAf (as semi-strong representation) quotient DRAfp . obtained forgetting labels +, -, P A.Example 36. OPRAn quotient OPRAnm , identity domainlevel. level non-associative algebras, qA maps region OPRAnm regionOPRAn (for even i), regions (i 1) + 1 (i + 1) 1 OPRAnmregion OPRAn (for odd i), see Fig. 11. canonically extended OPRArelations. equivalence relation kernel qA , i.e. relatesitself, elements (i 1) + 1 (i + 1) 1 related other.295fiMossakowski & MoratzNote yields oplax homomorphism non-associative algebra lax.counterexample laxness OPRA2 OPRA1 following: h(200 212 ) = {113 },h(200 ) h(212 ) = {113 , 123 , 133 }.(i-1)mi-1(i-1)m+1...(i+1)m-1(i+1)mi+1Figure 11: OPRAn quotient OPRAmn(Dylla, Mossakowski, Schneider, & Wolter, 2013), show OPRA1 OPRA8associative. Prop. 16 Ex. 36, carries OPRAn .Example 37. OPRA1 quotient OPRA1 . identity domain level.level non-associative algebras, forgets labels +, -, P A.296fiRelations Spatial Calculi{llllA} 7 LEFTleftA{llll+, lllr, lllb} 7 LEFTleft+{llll, lrll, lbll} 7 LEFTleft{ffff, eses, fefe, fifi, ibib, fbii, fsei, ebis, iifb, eifs, iseb} 7 FRONTfront{bbbb} 7 BACKback{llbr} 7 LEFTback{llfl, lril, lsel} 7 LEFTfront{llrrP} 7 LEFTrightP{llrr+} 7 LEFTright+{llrf, llrl, llrr, lfrr, lrrr, lere, lirl, lrri, lrrl} 7 LEFTright{rrrrA} 7 RIGHTrightA{rrrr+, rbrr, rlrr} 7 RIGHTright+{rrrr, rrrl, rrrb} 7 RIGHTright{rrllP} 7 RIGHTleftP{rrll+, rrlr, rrlf, rlll, rfll, rllr, rele, rlli, rilr} 7 RIGHTleft+{rrll} 7 RIGHTleft{rrbl} 7 RIGHTback{rrfr, rser, rlir} 7 RIGHTfront{ffbb, efbs, ifbi, iibf, iebe} 7 FRONTback{frrr, errs, irrl} 7 FRONTright{flll, ells, illr} 7 FRONTleft{blrr} 7 BACKright{brll} 7 BACKleft{bbff, bfii, beie, bsef, biif} 7 BACKfront{slsr} 7 SAMEleft{sese, sfsi, sisf} 7 SAMEfront{sbsb} 7 SAMEback{srsl} 7 SAMErightFigure 12: Mapping DRAfp OPRA1 relationsExample 38 (refined Moratz et al. 2009; Lcke 2012). OPRA1 quotient DRAfp .level non-associative algebras, quotient given table Fig. 12.level domains, acts follows: Given dipoles d1 , d2 D, relation d1 d2expresses d1 d2 start point point direction. (Thisregular w.r.t. f .) D/ domain OP oriented points R2 . See Fig. 14.297fiMossakowski & Moratzequivalence relation quotient indeed regular: given base-relation b DRAfp ,(b) already generates (via quotient) whole /([b]): pair orientedpoints /([b]), suitable choice dipole end points leads relation (b) (also cf.Fig. 8). Consequently, quotient weak representations (full,proper).Prop. 19, construction OPRA1 quotient allows us computationconverse composition tables applying congruence relations tablesDRAfp . Actually, compared result procedure compositiontable OPRA1 published Dylla (2008) provided tool SparQ (Wallgrn,Frommberger, Dylla, & Wolter, 2009). course checking full oplaxness propertyquotient homomorphism DRAfp OPRA1 , discovered errors 197 entriescomposition table OPRA1 shipped qualitative reasoner SparQ.12table corrected accordingly meantime.13example, composition SAMEright= q(srsl) RIGHTright+= q(rrrr+, rbrr,rlrr) computed q({blrr, lere, lfrr, lirl, llrf, llrl, llrr+, llrr-, llrrp, lrri,lrrl, lrrr, rbrr, rlrr, rrrr+}) = {LEFTright-, LEFTright+, LEFTrightP, BACKright,RIGHTright+}. old table additionally contained RIGHTright-. However,configuration SAMEright b, b RIGHTright+ c RIGHTright- c geometricallypossible. Consider three oriented points oA , oB oC oA SAMEright oBCBFigure 13: OPRA1 configurationoB RIGHTright+ oC , depicted Fig. 13. picture, oA RIGHTright+ oC .relation oA RIGHTright- oC hold, oC would need turned counter-clockwise.turn would lead first oB RIGHTrightA oC oB RIGHTright- oC , evenoA RIGHTright- oC reached.next result shows also use quotients transfer important propertycalculi.Proposition 39 (refined Moratz et al. 2009; Lcke 2012). Quotient homomorphismsweak representations bijective second component preserve strength composition.12. already reported (Moratz et al., 2009; Lcke, 2012). actual computationtable done congruence relation here, quotient construction wrong, resultingone-point algebra, stated above.13. See https://github.com/dwolter/SparQ/commit/89bebfc60a https://github.com/dwolter/SparQ/commit/dad260edd9.298fiRelations Spatial CalculiDRAfpOPRA?1fpopra 1P(D D)P(OP OP)Figure 14: Quotient homomorphism weak representations DRAfp OPRA1Proof.Let (h, i) : : P(U U) : B P(V V) quotienthomomorphism weak representations bijective. According Prop. 23,strength composition equivalent (respectively ) proper homomorphism. assume proper homomorphism need show properwell. also know h P(i i) proper. Let R2 , S2 two abstract relationsB. surjectivity h, abstract relations R1 , S1 h(R1 ) = R2h(S1 ) = S2 . (R2 S2 ) = (h(R1 ) h(S1 )) = (h(R1 S1 )) = P(i i)((R1 S1 )) =P(i i)((R1 )) P(i i)((S1 )) = (h(R1 )) (h(S1 )) = (R2 ) (S2 ), henceproper.Corollary 40 (Moratz et al. 2009; Lcke 2012). Composition OPRA1 strong.Proof.Composition DRAfp known strong (Moratz, Lcke, & Mossakowski,2011). Example 38 Prop. 39, strength composition carries OPRA1 .Corollary 41. Composition CYC b strong.Example 42. quotient homomorphism Example 31 one-sided inverse, namelyembedding (i.e. proper injective homomorphism) CYC b OPRA1 levelnon-associative algebras, quotient given table Fig. 15. leveldomains, acts follows: orientation mapped oriented point (0, 0)orientation.Altogether, get diagram calculi (semi-strong representations) homomorphisms Fig. 16.4. Constraint ReasoningLet us apply relation-algebraic method constraint reasoning. Given nonassociative algebra A, constraint network map : N N A, N setnodes (or variables) (Ligozat & Renz, 2004). Individual constraints (X, ) = R writtenX R , X, variables N R relation A. constraint network: N N atomic scenario, (X, ) base-relation.299fiMossakowski & Moratz7 SAMEbackl 7 SAMEleftr 7 SAMErighte 7 SAMEfrontFigure 15: Mapping CYC b OPRA1 relationsIA(proper,proper)DRAfp(full,proper)(proper,proper)OPRA?1CYC b(proper, oplax)(full,oplax)DRAf(full,oplax)(full,proper)OPRA1(full,oplax)OPRAnm(full,oplax)OPRAnFigure 16: Homomorphisms among various calculi.constraint network consistent assignment variableselements domain constraints satisfied (a solution). problemConstraint Satisfaction Problem (CSP) (Mackworth, 1977). rely relation algebraicmethods check consistency, namely mentioned path consistency algorithm.non-associative algebras, abstract composition relations need coincide(associative) set-theoretic composition. Hence, case, standard path-consistencyalgorithm necessarily lead path consistent networks, algebraic closure(Renz & Ligozat, 2005):Definition 43 (Algebraic Closure). constraint network binary relations calledalgebraically closed variables X1 , X2 , X3 relations R1 , R2 , R3 constraint300fiRelations Spatial CalculirelationsX1 R1 X2 ,X2 R2 X3 ,X1 R3 X3implyR 3 R1 R2 .Algebraic closure enforced successively applyingR3 := R3 (R1 R2 )X1 R1 X2 , X2 R2 X3 , X1 R3 X3 fixed point reached. Note procedureleaves set solutions constraint network invariant. meansalgebraic closure contains empty relation, original network inconsistent.14However, general, algebraic closure one-sided approximation consistency:algebraic closure detects inconsistency, sure constraint networkinconsistent; however, algebraic closure may fail detect inconsistencies: algebraically closed network necessarily consistent. calculi, like Allens intervalalgebra, algebraic closure known exactly decide consistency scenarios, others(Renz & Ligozat, 2005). also shown question completely orthogonalquestion whether composition strong.Constraint networks translated along homomorphisms non-associative algebrasfollows: Given h : B : N N A, let h() composition h .turns oplax homomorphisms preserve algebraic closure.Proposition 44 (refined Moratz et al. 2009; Lcke 2012). Given non-associative algebras B, oplax homomorphism h : B preserves algebraic closure. injectivelax homomorphism reflects algebraic closure.Proof. Since oplax homomorphism homomorphism Boolean algebras,preserves order. three relations X1 R1 X2 , X2 R2 X3 , X1 R3 X3algebraically closed constraint network A,R3 R1 R2preservation order implies:h(R3 ) h(R1 R2 ).Applying oplaxness property yields:h(R3 ) h(R1 ) h(R2 ).hence image constraint network h also algebraically closed. hinjective lax, reflects equations inequalities, converse implication followssimilar way.14. scenarios, suffices check whether scenario algebraically closed, proper refinement must contain empty relation.301fiMossakowski & MoratzGiven scenario : N N A, following Renz Ligozat (2005), reorganizefunction : P(N N ) defining (b) = {(X, ) N N | (X, ) = b}base-relations b extending relations using joins usual. Noteweak representation iff scenario algebraically closed normalised. Here, constraintnetwork normalised (X, X) = (Y, X) = (X, )` .atomic homomorphisms (i.e. mapping atoms atoms), translationconstraint networks lifted scenarios represented : P(N N ) usingcorrespondence, obtain h() : B P(N N ).Definition 45. Given scenario : P(N N ), solution weak representation: P(U U) function j : N U R A, P(j j)((R)) (R),P(j j) short:P(j j)P(N N )P(U U)Proposition 46 (refined Moratz et al. 2009; Lcke 2012). (_,oplax) homomorphismsweak representations preserve solutions scenarios.Proof.Let weak representations : P(U U) : B P(V V)(_,oplax) homomorphism weak representations (h, i) : given.given solution j : N U defined P(j j) .oplax commutation property P(i i) h infer P(i j j) h,implies j solution h().important question calculus (= weak representation) whether algebraic closuredecides consistency scenarios (Renz & Ligozat, 2005). (Note general, consistentscenario algebraically closed, vice versa.) prove propertypreserved certain homomorphisms.Proposition 47 (refined Moratz et al. 2009; Lcke 2012). Atomic (lax,oplax) homomorphisms (h, i) weak representations injective h preserve following propertyimage h:Algebraic closure decides scenario-consistency.Proof. Let weak representations : P(U U) : B P(V V) atomicoplax homomorphism weak representations (h, i) : given. assume, algebraic closure decides consistency scenarios.302fiRelations Spatial Calculiscenario image h written h() : B P(N N ). h()algebraically closed, Prop. 44, . Hence, assumption, consistent,i.e. solution. Prop. 46, h() consistent well.general scenario consistency problem DRAfp calculus NP-hard evenIR-complete (Wolter & Lee, 2010; Lee, 2014). However, specific scenarios,better: apply Prop. 47 homomorphism interval algebra DRAfp (seeExample 27) obtain:Proposition 48 (Moratz et al. 2009; Lcke 2012). Algebraic closure decides consistencyDRAfp scenarios involve interval algebra relations only.Hence, consistency scenarios decided polynomial time (in spiteNP-hardness general scenario consistency problem). similar remark holdsCYC b relations embedded OPRA1 .calculi RCC8, interval algebra etc., (maximal) tractable subsetsdetermined, i.e. sets relations algebraic closure decides consistency alsonon-atomic constraint networks involving relations. follows algebraicclosure DRAfp decides consistency constraint network involving (the homomorphicimage of) maximal tractable subset interval algebra only.5. Conclusionstudy investigated calculi application side represent modalitydifferent levels granularity. modality case relative direction. demonstrated model relative directions different levels granularity DRAfp ,OPRA1 , CYC b . turned case study relative directionoriented objects formal relation calculi could expressed quotient homomorphisms.result step application universal algebraic methods qualitativeconstraint reasoning. Since explosion qualitative constraint calculirecent years becomes important study relations calculimake automatic mappings calculi. contributepresented work. also contributed new notion quotient (based so-calledoplax homomorphisms) relation algebras captures existing natural quotientsspatial calculi. published Haskell tools used finding checkinghomomorphisms calculi public repository.15concrete results study demonstrated answer questions whether composition strong algebraic closure decides consistency calculiexamined yet. purely algebraic methods, lift properties strengthcomposition algebraic closure deciding consistency along homomorphisms qualitative calculi. latter particularly important, algebraic closure polynomialtime method, whereas qualitative constraint problems cases turn NP-hard,even scenarios base-relations.15. See https://github.com/spatial-reasoning/homer303fiMossakowski & Moratzderived chain calculi homomorphisms DRAfp , OPRA1 , CYC b .Thereby combined dipole opra calculi cycord approach. Basednew approach could automatically derive composition table OPRA1 basedformally verified composition table DRAfp . compared tablecomposition table OPRA1 described previous work authors (Dylla, 2008).turned old composition table shipped qualitative reasonerSparQ contained errors 197 entries. emphasizes point importantdevelop sound mathematical theory basis computation composition tablesstay close possible implementation theory.Acknowledgementsauthors would like thank Dominik Lcke, Andr van Delden, Torsten Hahmann, JayLee, Thomas Schneider Diedrich Wolter fruitful discussions Thomas Schneidervaluable comments draft. Also anonymous referees provided valuable hints.work supported DFG Transregional Collaborative Research Center SFB/TR 8Spatial Cognition, projects I4-[SPIN] R4-[LogoSpace] (TM), National ScienceFoundation Grant No. CDI-1028895 (RM).ReferencesAllen, J. F. (1983). Maintaining knowledge temporal intervals. CommunicationsACM, pages 832843, 1983.Bodirsky, M. (2008). Constraint satisfaction problems infinite templates. Creignou,N., Kolaitis, P. G., & Vollmer, H., editors, Complexity Constraints - OverviewCurrent Research Themes [Result Dagstuhl Seminar]., volume 5250 Lecture NotesComputer Science, pages 196228. Springer, 2008. ISBN 978-3-540-92799-0. doi: 10.1007/978-3-540-92800-3_8. URL http://dx.doi.org/10.1007/978-3-540-92800-3_8.Burmeister, P. (1986). model theoretic approach partial algebras. Akademie Verlag,Berlin, 1986.Burmeister, P. (2002). Lecture notes universal algebra many-sorted partial algebraspreliminary version.see http://www.mathematik.tu-darmstadt.de/Math-Net/Lehrveranstaltungen/Lehrmaterial/SS2002/AllgemeineAlgebra/download/LNPartAlg.pdf, 2002.Clementini, E., Felice, P. D., & Hernandez, D. (1997). Qualitative Represenation Positional Information. Artificial Intelligence, 95:317356, 1997.Dubba, K. S. R., Bhatt, M., Dylla, F., Cohn, A. G., & Hogg, D. C. (2015). Learningrelational event models video. J. Artif. Intell. Res. (JAIR), 52, 2015. acceptedpublication.Dntsch, I. (2005). Relation algebras application temporal spatial reasoning.Artif. Intell. Rev., 23(4):315357, 2005.304fiRelations Spatial CalculiDylla, F. (2008). Agent Control Perspective Qualitative Spatial Reasoning TowardsIntuitive Spatial Agent Development. PhD thesis, University Bremen, 2008. Published Akademische Verlagsgesellschaft Aka GmbH.Dylla, F., Mossakowski, T., Schneider, T., & Wolter, D. (2013). Algebraic propertiesqualitative spatio-temporal calculi. Tenbrink, T., Stell, J. G., Galton, A., & Wood,Z., editors, COSIT, volume 8116 Lecture Notes Computer Science, pages 516536.Springer, 2013. ISBN 978-3-319-01789-1. doi: 10.1007/978-3-319-01790-7. URL http://dx.doi.org/10.1007/978-3-319-01790-7.Egenhofer, M. & Franzosa, R. (1991). Point-Set Topological Spatial Relations. InternationalJournal Geographical Information Systems, 5(2):161174, 1991.Frank, A. (1991). Qualitative Spatial Reasoning Cardinal Directions. Kaindl, H., editor, Proc. 7th sterreichische Artificial-Intelligence-Tagung, pages 157167. Springer,1991.Freksa, C. (1992). Using orientation information qualitative spatial reasoning. Frank,A. U., Campari, I., & Formentini, U., editors, Theories methods spatio-temporalreasoning geographic space, volume 639 Lecture Notes Comput. Sci., pages 162178. Springer, 1992.Gantner, Z., Westphal, M., & Wlfl, S. (2008). GQR - Fast Reasoner Binary Qualitative Constraint Calculi. Proc. AAAI-08 Workshop Spatial TemporalReasoning, 2008.Grtzer, G. (1979). Universal Algebra. Springer-Verlag, New York, NY, second edition,1979.Hobbs, J. R. (1985). Granularity. Proceedings Ninth International Joint Conference Artificial Intelligence, 1985.Huang, J. (2012). Compactness implications qualitative spatial temporalreasoning. Brewka, G., Eiter, T., & McIlraith, S. A., editors, Principles KnowledgeRepresentation Reasoning: Proceedings Thirteenth International Conference,KR 2012, Rome, Italy, June 10-14, 2012. AAAI Press, 2012. ISBN 978-1-57735-560-1.URL http://www.aaai.org/ocs/index.php/KR/KR12/paper/view/4494.Isli, A. & Cohn, A. G. (2000). new approach cyclic ordering 2D orientations usingternary relation algebras. Artificial Intelligence, 122(1-2):137187, 2000.Ladkin, P. & Maddux, R. (1994). Binary Constraint Problems. J. ACM, 41(3):435469,1994.Lee, J. H. (2014). complexity reasoning relative directions. Schaub, T.,Friedrich, G., & OSullivan, B., editors, ECAI 2014 - 21st European Conference305fiMossakowski & MoratzArtificial Intelligence, 18-22 August 2014, Prague, Czech Republic - Including Prestigious Applications Intelligent Systems (PAIS 2014), volume 263 Frontiers Artificial Intelligence Applications, pages 507512. IOS Press, 2014. ISBN 978-161499-418-3. doi: 10.3233/978-1-61499-419-0-507. URL http://dx.doi.org/10.3233/978-1-61499-419-0-507.Li, J. J., Kowalski, T., Renz, J., & Li, S. (2008). Combining binary constraint networksqualitative reasoning. Ghallab, M., Spyropoulos, C. D., Fakotakis, N., & Avouris,N. M., editors, ECAI 2008 - 18th European Conference Artificial Intelligence, Patras,Greece, July 21-25, 2008, Proceedings, volume 178 Frontiers Artificial IntelligenceApplications, pages 515519. IOS Press, 2008. ISBN 978-1-58603-891-5. doi: 10.3233/978-1-58603-891-5-515. URL http://dx.doi.org/10.3233/978-1-58603-891-5-515.Ligozat, G. (1993). Qualitative triangulation spatial reasoning. Frank, A. U. & Campari, I., editors, Proc. International Conference Spatial Information Theory., volume716 Lecture Notes Comput. Sci., pages 5468. Springer, 1993.Ligozat, G. (1998). Reasoning Cardinal Directions. J. Vis. Lang. Comput., 9(1):2344, 1998.Ligozat, G. (2005). Categorical Methods Qualitative Reasoning: Case WeakRepresentations. Cohn, A. G. & Mark, D. M., editors, Proc. COSIT, volume 3693Lecture Notes Comput. Sci., pages 265282. Springer, 2005.Ligozat, G. & Renz, J. (2004). Qualitative Calculus? General Framework.Zhang, C., Guesgen, H. W., & Yeap, W.-K., editors, Proc. PRICAI-04, pages 5364,2004.Ligozat, G. (2011). Qualitative Spatial Temporal Reasoning.9781848212527,9781118601457.Wiley, 2011.ISBNLcke, D. (2012). Qualitative Spatial Reasoning Relative Orientation: QuestionConsistency. PhD thesis, University Bremen, 2012. http://elib.suub.uni-bremen.de/edocs/00102632-1.pdf.Mackworth, A. K. (1977). Consistency Networks Relations. Artif. Intell., 8:99118,1977.Maddux, R. (2006). Relation Algebras. Stud. Logic Found. Math. Elsevier Science, 2006.Montanari, U. (1974). Networks constraints: Fundamental properties applicationspicture processing. Inf. Sci., 7:95132, 1974.Moratz, R. (2006). Representing Relative Direction Binary Relation Oriented Points.Brewka, G., Coradeschi, S., Perini, A., & Traverso, P., editors, Proc. ECAI-06,volume 141 Frontiers Artificial Intelligence Applications, pages 407411. IOSPress, 2006.Moratz, R., Renz, J., & Wolter, D. (2000). Qualitative Spatial Reasoning LineSegments. Proc. ECAI 2000, pages 234238, 2000.306fiRelations Spatial CalculiMoratz, R., Lcke, D., & Mossakowski, T. (2009). Oriented straight line segment algebra:Qualitative spatial reasoning oriented objects. CoRR, abs/0912.5533, 2009. URLhttp://arxiv.org/abs/0912.5533.Moratz, R., Lcke, D., & Mossakowski, T. (2011). condensed semantics qualitativespatial reasoning oriented straight line segments. Artif. Intell., 175(16-17):20992127, 2011.Mossakowski, T., Schrder, L., & Wlfl, S. (2006). categorical perspective qualitativeconstraint calculi. Wlfl, S. & Mossakowski, T., editors, Qualitative Constraint Calculi- Application Integration. Workshop KI 2006, pages 2839, 2006.Mossakowski, T. & Moratz, R. (2012). Qualitative reasoning relative directionoriented points. Artificial Intelligence, 180-181(0):34 45, 2012.Nebel, B. & Wlfl, S., editors (2009). AAAI Spring Symposium Benchmarking Qualitative Spatial Temporal Reasoning Systems. AAAI Technical Report SS-09-02, 2009.Randell, D. A. & Cohn, A. G. (1989). Modelling topological metrical propertiesphysical processes. Brachman, R. J., Levesque, H. J., & Reiter, R., editors, Proc.KR-89, pages 357368. Morgan Kaufmann, 1989.Randell, D. A., Cui, Z., & Cohn, A. G. (1992). spatial logic based regionsconnection. Nebel, B., Rich, C., & Swartout, W., editors, Proc. KR-92, pages165176. Morgan Kaufmann, 1992.Renz, J. & Ligozat, G. (2005). Weak Composition Qualitative Spatial TemporalReasoning. van Beek, P., editor, Proc. CP-05, volume 3709 Lecture NotesComput. Sci., pages 534548. Springer, 2005.Renz, J. & Mitra, D. (2004). Qualitative Direction Calculi Arbitrary Granularity.Zhang, C., Guesgen, H. W., & Yeap, W.-K., editors, Proc. PRICAI-04, volume 3157Lecture Notes Comput. Sci., pages 6574. Springer, September 2004.Renz, J. & Nebel, B. (1999). Complexity Qualitative Spatial Reasoning:Maximal Tractable Fragment Region Connection Calculus. Artificial Intelligence,108(1-2):69123, 1999.Renz, J. & Nebel, B. (2007). Qualitative Spatial Reasoning Using Constraint Calculi.Aiello, M., Pratt-Hartmann, I., & van Benthem, J., editors, Handbook Spatial Logics,pages 161215. Springer, 2007.Scivos, A. & Nebel, B. (2004). finest class: natural point-based ternarycalculus qualitative spatial reasoning. Freksa, C., Knauff, M., Brckner, B. K.,Nebel, B., & T.Barkowski, editors, Spatial Cognition, volume 3343 Lecture NotesComput. Sci., pages 283303. Springer, 2004.van Beek, P. & Manchak, D. W. (1996). design experimental analysis algorithmstemporal reasoning. J. Artif. Intell. Res., 4:118, 1996.307fiMossakowski & MoratzWallgrn, J. O., Frommberger, L., Wolter, D., Dylla, F., & Freksa, C. (2006). QualitativeSpatial Representation Reasoning SparQ-Toolbox. Barkowsky, T., Knauff,M., Ligozat, G., & Montello, D. R., editors, Spatial Cognition, volume 4387 LectureNotes Comput. Sci., pages 3958. Springer, 2006.Wallgrn, J. O., Frommberger, L., Dylla, F., & Wolter, D. (2009). SparQ User ManualV0.7. User manual, University Bremen, January 2009.Westphal, M. & Wlfl, S. (2009). Qualitative CSP, finite CSP, SAT: Comparing methodsqualitative constraint-based reasoning. Boutilier, C., editor, IJCAI, pages 628633,2009.Wolter, D. & Lee, J. H. (2010). Qualitative reasoning directional relations. ArtificialIntelligence, 174(18):14981507, 2010. doi: 10.1016/j.artint.2010.09.004.Worboys, M. F. & Clementini, E. (2001). Integration Imperfect Spatial Information.Journal Visual Languages Computing, 12:6180, 2001.308fiJournal Artificial Intelligence Research 54 (2015) 123158Submitted 04/15; published 09/15Achieving Goals Quickly Using Real-time Search:Experimental Results Video GamesScott KieselEthan BurnsWheeler Rumlskiesel cs.unh.edueaburns cs.unh.eduruml cs.unh.eduDepartment Computer ScienceUniversity New HampshireDurham, NH 03824 USAAbstractreal-time domains video games, planning happens concurrently execution planning algorithm strictly bounded amount time mustreturn next action agent execute. explore use real-time heuristicsearch two benchmark domains inspired video games. Unlike classic benchmarksgrid pathfinding sliding tile puzzle, new domains feature exogenous changedirected state space graphs. consider setting planning actingconcurrent use natural objective minimizing goal achievement time. Usingclassic benchmarks new domains, investigate several enhancementsleading real-time search algorithm, LSS-LRTA*. show experimentally 1)better plan action use dynamically sized lookahead, 2) A*-basedlookahead cause undesirable actions selected, 3) on-line de-biasingheuristic lead improved performance. hope work encourages future researchapplying real-time search dynamic domains.1. Introductionmany applications, desirable agent achieve assigned task quicklypossible. Consider common example navigation video game. userselects destination character move to, expect character begin movingimmediately arrive destination soon possible. suggests planning strategy featuring concurrent planning execution. area real-time heuristicsearch developed address problem. Algorithms class perform shortplanning episodes limited provided real-time bound, finding partial solutionsbeginning execution complete plan goal found. solutionquality search time traditional heuristic search metrics, real-time heuristic searchalgorithms usually compared length trajectories execute.recent work real-time heuristic search focused grid pathfinding problemssimplicity. important, grid pathfinding characteristicsexist search problems: search space undirected small enougheasily fit memory. explore use real-time heuristic search two additionaldomains closely reflect features dynamic application domains, robotics.One platform-based pathfinding domain proposed Burns, Ruml, (2013b),novel domain call traffic problem, featuring navigationc2015AI Access Foundation. rights reserved.fiKiesel, Burns, & Rumlfield moving obstacles. Unlike traditional grid pathfinding problem used evaluatereal-time search, benchmarks dynamics large state spaces formdirected graphs.addition evaluating real-time heuristic search new domains, introduce threemodifications LSS-LRTA* (Koenig & Sun, 2008), among state-of-the-artreal-time heuristic search algorithms. First, show LSS-LRTA*, executesmultiple actions per planning episode, improved executing single actiontime. Second, become standard practice construct local search spacereal-time search using partial A* search. show that, care takencompare search nodes correctly, agent may execute unnecessary actions. Third, showapplying on-line de-biasing heuristic used search significantly reduceoverall goal achievement time. Together, modifications easily appliedimprove overall performance agent controlled real-time heuristic searchalgorithm. Videos illustrating new domains discussed algorithms providedon-line (Kiesel, Burns, & Ruml, 2015b) well described Appendix B.Instead comparing techniques based solely solution length convergence time,evaluate new methods comparing goal achievement timesthe timeproblem issued goal achieved. metric follows naturallybenchmark domains allows us easily compare real-time search algorithms offline planning techniques A*. results show A*, performs optimallyrespect number expansions required produce optimal solution,easily outperformed one cares goal achievement time. hopework methodology encourage future research applying real-time searchdynamic domains.2. Previous Workmuch work area real-time search since initially proposedKorf (1990). section review real-time search algorithms relevantstudy. (Additional related algorithms reviewed Section 7.)2.1 LRTA*Many real-time search algorithms considered agent-centered agent performsbounded amount lookahead search rooted current state acting. Sincesize lookahead search bounded, agent respect real-time constraintsrestricting lookahead completed time real-time limitreached. seminal paper, Korf (1990) presents Learning Real-time A* (LRTA*),complete, agent-centered, real-time search algorithm. select next action perform,LRTA* uses action costs estimate cost-to-goal, heuristic value,states resulting applying current applicable actions; chooses executeaction lowest estimated cost-to-goal.LRTA* estimates heuristic value states two different ways. First, statenever visited before, uses depth-bounded, depth-first lookahead search.estimated cost state minimum f value among leaves lookaheadsearch, f cost-so-far (notated g) plus estimated cost-to-goal (notated124fiAchieving Goals Quickly Using Real-time SearchLSS-LRTA*(s, expansion limit)1. goal reached2.perform expansion limit expansions best-first search f3.update heuristic values nodes CLOSED4.state OP EN lowest f5.start executing path6.OP EN {s}; clear CLOSEDFigure 1: Pseudocode LSS-LRTA*.h). second way estimates cost learning. time LRTA* performssearch, learns updated heuristic value current state. state encounteredagain, learned estimate used instead searching again. Korf (1990) provedlong states heuristic estimate increased move amount bounded, agent never get infinite cycle, algorithmcomplete. original algorithm, second best actions heuristic value usedupdate cost estimate current state agent moves.2.2 LSS-LRTA*Local Search Space Learning Real-time A* (LSS-LRTA*, Koenig & Sun, 2008) currentlyone popular real-time search algorithms. LSS-LRTA* two big advantagesoriginal LRTA*: much less variance lookahead times significantly learning. LRTA* large variance lookahead times because,even depth limit, different searches expand different numbersnodes due pruning. Instead using bounded depth-first search beneath successor state, LSS-LRTA* uses single A* search rooted agents current state.A* search limited exact number nodes expand, significantlyless variance lookahead times. second advantage original LRTA*learns updated heuristics states agent visited; LSS-LRTA* learns updatedheuristics every state expanded lookahead search. accomplished usingDijkstras algorithm propagate accurate heuristic values fringelookahead search back interior agent moves. Koenig Sun showedLSS-LRTA* find much cheaper solutions LRTA* even competitivestate-of-the-art incremental search, D*Lite (Koenig & Likhachev, 2002).Another major difference LRTA* LSS-LRTA* agent moves.LRTA*, lookahead, agent moves performing single action; LSS-LRTA*agent moves way node fringe current lookahead searchlowest f value. result, agent performs many fewer lookahead searchesreaching goal. one concerned minimizing total number expansions,may advantageous. However, see below, search execution allowedhappen parallel, movement method LSS-LRTA* actually detrimentalperformance. Pseudocode LSS-LRTA* presented Figure 1.125fiKiesel, Burns, & Ruml3. Evaluating Real-time Search AlgorithmsTraditionally, real-time heuristic search algorithms evaluated using two criteria:convergence time solution length. Convergence time measures number repeatedstart-to-goal plans algorithm must execute learns optimal pathgiven start goal pair. useful comparing rate differentalgorithms learn accurate heuristic values, seem useful practice;agents rarely need repeatedly plan exactly start goal states. Oftenone solution needed, algorithm finds better first solution preferredeven takes long time converge.Solution length number actions executed achieve goal. real-timesearch, planning action execution happen parallel, solution lengthgood proxy amount time real-time agent given problemgoal actually achieved. downside simply using solution length,however, makes comparison offline techniques unfair. example,comparing algorithms solely solution length, technique perform betteroptimal search like A*. But, practice, A* may best method solveproblem. agent using A* could spend long time planning finally beginsexecuting optimal path, agent using real-time algorithm may start executinglong path right away, consequently arrive goal first.3.1 Goal Achievement TimeRecently, Hernandez, Baier, Uras, Koenig (2012) introduced game time modelevaluating real-time heuristic search algorithms. game time model, time divideduniform intervals. interval, agent three choices: search,execute action, search execute parallel. objective gametime model agent move initial state goal state using fewesttime intervals. advantage game time model allows comparisonsreal-time algorithms search execute time step off-linealgorithms, like A*, search first execute search completed.experiments, compare algorithms directly goal achievement time. Goalachievement time (GAT) slight generalization game time model allowsreal-valued times, fixed-size discrete time intervals. computed planningtime plus execution time minus time spent planning executing parallel:goal achievement time = time planning + time executing timeSince benchmark domains used experiments natural definitionexecution time (e.g., 15-puzzle, exactly much time needed slide tile?),present results using variety different execution times. define execution timenumber seconds required execute unit-cost action. call value unitaction duration; effectively converts action costs unitstime. example,8-way grid pathfinding problem diagonal edges cost 2, simply multiplyedge costs unit action duration convert seconds execution. largeunit action duration models agent moves slowly small unit action durationmodels agent moves quickly, relative planning speed.126fiAchieving Goals Quickly Using Real-time Searchtwo following sections, present modifications LSS-LRTA* algorithm.benefit modification evaluated using goal achievement time.4. Lookahead Commitmentimportant step real-time search algorithm selecting far move agentnext phase planning begins. mentioned above, original LRTA*algorithm agent moves single step, LSS-LRTA* agent movesway frontier node local search space. Lustrek Bulitko (2006) reportedsolution length increased switching single-step multi-step policy usingoriginal LRTA* algorithm. unclear behavior would carry givenincreased learning performed LSS-LRTA* use new goal achievement metric.4.1 Single-step Dynamic Lookaheadimplemented standard LSS-LRTA* well version executes single actionslike LRTA*. also implemented LSS-LRTA* using dynamic lookahead strategyexecutes multiple actions leading current state selected state fringerecent local search. dynamic lookahead, agent selects amountlookahead search perform based duration currently-executing trajectory.agent commits executing multiple actions, simply adjusts lookaheadfill entire execution time.learning step, algorithm based LSS-LRTA* cannot simply searchreal-time bound expires must leave time learning. accountuse offline training determine speed agent searches.fixed lookahead algorithms, necessary know maximum lookahead sizeagent search minimum action execution time. found simplyrunning search algorithm different fixed lookahead settings representativeset training instances recording per-step search times. case dynamiclookahead, agent must learn function mapping durations lookahead sizes.agent commits trajectory requires time execute, must usefunction find l(t), maximum lookahead size agent search time t. Notethat, data structures used search often non-linear-time operations,function may linear. possible create conservative approximation l(t)running algorithm representative set training instances large varietyfixed lookahead sizes. approximation l(t) selects largest lookahead sizealways completed within time t.4.2 Experimental Evaluationcompare different techniques platform pathfinding benchmark Burns et al.(2013b). domain inspired popular platform-based video games like Super MarioBros. agent must find path, jumping platform platform, maze.screenshot domain example instance shown Figure 2. Videos alsoavailable on-line (Kiesel et al., 2015b) described Appendix B.127fiKiesel, Burns, & RumlFigure 2: screenshot problem instance platform path-finding domain (left),zoomed-out image entire instance (right). knight must findpath starting location, maze, door (on right sideleft image, center right image).available actions different combinations controller keys may pressedsingle iteration games main loop: left, right, jump. Left right moveknight respective directions (holding time never consideredsearch domain, movements would cancel out, leaving knightplace), jump button makes knight jump, applicable. knight jumpdifferent heights holding jump button across multiple actions rowmaximum 8. actions unit cost.state state space contains x, position knight using doubleprecision floating point values, velocity direction (x velocity storeddetermined solely left right actions), number remaining actionspressing jump button add additional height jump, boolean statingwhether knight currently falling. knight moves speed 3.25 units perframe horizontal direction, jumps speed 7 units per frame, simulategravity falling, 0.5 units per frame added knights downward velocitymaximum 12 units per frame.benchmark natural fit real-time search algorithms, since agent mustdecide action execute forced move due gravity. state spaceplatform domain directed, air agents actionsreversible. heuristic based visibility navigation (see Burns et al. details)quite accurate except account players limited jumpingheight. C++ source code available GitHub (Kiesel, Burns, & Ruml, 2015a).128fiAchieving Goals Quickly Using Real-time Searchfactor optimal GAT (log10)platform3multi-step (LSS-LRTA*)single-stepdynamic210-4-3-2-1unit action duration (log10)0Figure 3: LSS-LRTA*: multi-step, single-step, dynamic lookahead.experiments run Core2 duo E8500 3.16 GHz 8GB RAM running Ubuntu10.04.experiments used 25 test instances created using level generator describedBurns et al. (2013b), maze instance unique randomstart goal location. used offline training techniques described learnamount time required perform different amounts lookahead search.offline training, generated additional 25 training instances. lookahead valuesused 1, 5, 10, 20, 50, 100, 200, 400, 800, 1000, 1500, 2000, 3000, 4000, 8000 10000,16000, 32000, 48000, 64000, 128000, 196000, 256000, 512000. algorithms usefixed-size lookahead, lookahead value selected choosing largest lookahead sizemean step time training instances within single action duration.none lookahead values fast enough fit within single action time givenaction duration, data reported. implementation used mean step timeinstead maximum step time, latter usually large due rare, slowsteps. attribute outliers occasional, unpredictable overhead system-relatedsubroutine calls memory allocation. suspect issue would go awaytrue real-time operating system used, operations perform predictablecomputations, domain-specific optimized implementation used. (Unfortunately,developing optimized implementations would made much difficultperform thorough scientific comparisons.)Figure 3 shows comparison different techniques LSS-LRTA* algorithm.axis shows goal achievement time factor optimal goal achievementtime instance. optimal goal achievement time computed GAToptimal solution planning time taken account. One could imagine oracleable instantly provide optimal set actions execute. plot,129fiKiesel, Burns, & Rumlh3322110g=2f=5g=1f=4g=2f=4g=3f=5g=4f=5g=5f=6g=6f=6g=1f=4g=1f=3g=2f=4g=3f=4g=4f=5g=2f=5g=1f=4g=2f=4g=3f=5g=4f=5g=5f=6g=6f=6Figure 4: Example heuristic error f layers.axis shown log10 scale. consider variety action durations, shownx axis, also log10 scale. Smaller action durations represent agent moverelatively quickly, spending lot time planning make small decreases solutioncost may worth time. larger values, agent moves slowly,may worth planning execute cheaper paths. unit action duration usedlimit number expansions performed iteration.point plot shows mean goal achievement time 25 test instancessolved algorithms given factor optimal goal achievement timeaction duration. value log10 (0) = 1 indicates given algorithm optimaltime. Error bars show 95% confidence intervals means.plot, clear multi-step approach (standard LSS-LRTA*) performedworse single-step dynamic lookahead variants. likelymulti-step technique commits many actions little bit planningtheamount planning single-step variant uses commit one action.unit action duration increased 1 second, algorithms started performsimilarly. However, single-step dynamic lookahead still appear perform slightlybetter. Note 0.02 seconds per frame game platformdomain derived, values greater log10 (0.02) 1.7 represent agentmoves unusually slow pace.also important note small unit action durations, one algorithm may perform better another, unit action duration increases,relationship inverts. small unit action durations, much timesearch performed.5. A*-based Lookaheadstandard LSS-LRTA*, lookahead search A*-based, nodes expanded forder. searching, agent moves node open list lowest fvalue. may seem intuitively reasonable, show choiceproblematic, see remedied.130fiAchieving Goals Quickly Using Real-time SearchFigure 5: f -layered lookahead.5.1 Heuristic Errorcrux problem f -based lookahead doesnt account heuristic error.admissible heuristic used compute f is, definition, low-biased, f typicallyoptimistically underestimate true solution cost node.heuristic error, nodes f value actually lead toward goal node.Figure 4 shows example using simple grid pathfinding problem. figure, agentlocated cell labeled goal node denoted star. admissibleh values column grid; listed across topcolumns. g f values shown cell. Cells f = 4 bold, restlight gray. see nodes equivalent f values form elliptical rings aroundstart node. heuristic search literature, referred f layers.nodes f layer closer goal node, many nodes layernotsome nodes f layer even exactly away goal.simple problem, optimal solution move agent right goal reached,however, 7 nodes f = 4, 2 nodes along optimal path;nodes not, f value heuristic error. agentmove random node f = 4, chances following optimalpath goal.One way alleviate problem use second criterion breaking ties amongnodes f value. common tie breaker favor nodes lower h valuesas, according heuristic, nodes closer goal. see, Figure 4among nodes f = 4 layer, one lowest h value (h = 1) actuallyalong optimal path. LSS-LRTA* tie breaking insufficient, LSSLRTA* stops lookahead, may generated nodes largest f layer.node h = 1 generated, even tie breaking, agentled astray.5.2 Incomplete f Layersincomplete f layers cause problems too. Recall LSS-LRTA*, agentmoves node front open list. low-h tie breaking used orderexpansions local search space, best nodes first f layer open listactually expanded first open list comes timeagent move. Figure 5 shows problem diagrammatically. before, agentnode labeled goal denoted star. ellipse represents differentf layer, shaded portions show closed nodes, darker shading denotes nodes larger131fiKiesel, Burns, & Rumlh(s){heuristic error(a)g()h(){h(s) g() + h()heuristic error(b)g(){^h(s) g() + h() + d()h()heuristic error d()(c)Figure 6: (a) standard heuristic error. (b) updated heuristic error.(c) Using updated heuristic accounting heuristic error.f values, dotted lines surround nodes open list. see, closednodes largest f values cap tip second-largest f layer. causedlow-h tie breaking first open nodes expanded added closedlist lowest h. nodes portion f layernearest goal. agent moves node open list lowestf value, tie breaking low h, select node take best routetoward goal.5.3 Improving Lookahead Searchdemonstrated two problems: 1) heuristic error, f layers containlarge number nodes, many lead toward goal, 2) even goodtie breaking, LSS-LRTA* may miss good nodes considers partial f layersdeciding move. Next present two possible solutions problems.first quite simple. choosing move, select node lowesth value completely expanded f layer largest f value, next nodeopen. Figure 5, corresponds node labeled . call completetechnique, considers completely expanded f layers instead partially expanded,incomplete layers.second technique explicitly accounts heuristic errorit orders searchagents action selection f , less-biased estimate solution cost.Ideally, would prefer use unbiased (and hence inadmissible) estimate accountsattempts correct heuristic error. inadmissible heuristic could used,note Thayer, Dionne, Ruml (2011) investigated use inadmissible heuristics132fiAchieving Goals Quickly Using Real-time Searchoffline search adopt simple heuristic correction technique real-timesearch. call estimate f. Like f , f attempts estimate solution costnode search space. Unlike f , f explicitly biasedit lower bound. fcomputed similarly f , however, attempts correct heuristic error addingadditional term:ferrorz}|{ z }| {f (n) = g(n) + h(n) + d(n)average single-step error heuristic, additional term d(n)corrects error adding back cost estimate d(n) steps estimatedremain n goal. Following Thayer et al. (2011), make simplifyingassumption error heuristic distributed evenly among actionspath node goal.Distance estimates readily available many domains; tendeasy compute heuristic estimates (Thayer & Ruml, 2009). estimate single-stepheuristic error, use average difference f values expandednode best child. difference accounts amount heuristic error duesingle step parent node child. perfect heuristic, oneerror, f values parent node best child would equalsome fsimply moved h g:f (parent ) = f (child ), ideal case,h(parent ) = h(child ) + c(parent , child ),g(parent ) = g(child ) c(parent , child )Since g known exactly, cost edge c(parent , child ), imperfectheuristic difference f (child ) f (parent ) must caused errorheuristic step. Averaging differences gives us estimate .Adapting technique real-time search requires subtlety. real-time searchalgorithms like LSS-LRTA*, heuristic values nodes expanded lookahead search updated time agent moves. Figure 6a schematically depictserror default heuristic value node S. error accrued distancegoal. lookahead (Figure 6b), updated heuristics accurateoriginals based heuristic values nodes closergoal, thus less heuristic error. Here, see node fringestart state inherits updated heuristic value. Since g(), cost, known exactly, error backed heuristic comes entirelysteps goal. Since closer goal, error less errororiginal heuristic value S.computing f(S) real-time search, necessary account facterror updated heuristic comes node . this, track value calledderr , distance heuristic error accrued, node, usecompute f. Initially, nodes without updated heuristic values derr (n) = d(n).performing lookahead search, h updated backed-up h values before. h(n)receives backed value originated node , set derr (n) = d(), sinceerror updated heuristic comes instance fringe node133fiKiesel, Burns, & RumlplatformGAT difference LSS-LRTA*factor optimal GAT (log10)platformcompleteincomplete (LSS-LRTA*)3210-4-3-2-1unit action duration (log10)(a)00-40unit action duration (log10)(b)0Figure 7: LSS-LRTA*: f-based lookahead f-based lookahead.goal, distance n goal. updated heuristic, accountingheuristic error, h(s) = g() + h() + derr (n) , g() + h() standardheuristic backup derr (n) error correction (cf Figure 6b, derr (n) = d() dueupdate). demonstrated Figure 6c. new technique uses f orderexpansions lookahead search LSS-LRTA*, moves agent towardnode open list lowest f value.Figure 7 shows comparison three node selection techniques: standard incomplete f layer method LSS-LRTA*, complete f -layer method, approachuses f (denoted fhat). better demonstrate problem standard approach,plot shows results multi-step movement model commits entire pathcurrent state fringe local search space lookahead. styleplot panel (a) Figure 3.figure, see complete performed worse standard LSS-LRTA*algorithm small action durations agent may time expand manynodes thus ignoring expansions large effect. longer action durations,however, performance improves complete becomes best performer rightside plot cheaper solutions preferred. clarify improvementright side plot Figure 7 (a), included Figure 7 (b). plotdifferent y-axis highlights improvement comparing algorithm directlyincomplete version LSS-LRTA*. indicates using completed f layerlead fewer extraneous actions gives cheaper solutions. Using f sort openlist lookahead searches performs much better two algorithms leftside plot, although begins perform slightly worse unit action durationincreased. likely inadmissibility f hinders ability find solutionscheap found complete f layer variant.134fiAchieving Goals Quickly Using Real-time Searchfactor optimal GAT (log10)platform3LSS-LRTA*single-step f210-4-3-2-1unit action duration (log10)0Figure 8: Comparison four new real-time techniques.Dynamic-f(s, expansion limit)1. goal reached2.perform expansion limit expansions best-first search f3.update heuristic values nodes CLOSED4.state OP EN lowest f5.6.7.8.start executing pathexecution time execution time reachexpansion limit number expansions possible within execution timeOP EN {s}; clear CLOSEDFigure 9: Pseudocode LSS-LRTA* dynamic lookahead using f.Figure 8 shows results comparison four combinations single-stepversus dynamic lookahead f -based versus f-based node ordering. domain, fdynamic lookahead tended give best goal achievement times portionsplot algorithms significant overlap (i.e., everywhere exceptright-half plot).Figure 7 Figure 8, ordering lookahead search f commonlink best performance considered algorithms. Figure 7 demonstratesinitial intuition heuristic correction used real-time search. Figure 8 buildsidea adding dynamic look ahead proposed previous section yieldstrongest algorithm seen far. present pseudocode Figure 9dynamic-f method.135fiKiesel, Burns, & Rumlfactor optimal GAT (log10)platform3LSS-LRTA*210-4-3-2-1unit action duration (log10)0Figure 10: Comparison four new real-time techniques weak heuristic.5.3.1 Heuristic Accuracycould argued effects dynamic lookahead heuristic correction distorted strong heuristic visibility graph. short experiment, replacevisibility graph heuristic platform domain much weaker euclidean distanceheuristic. solve instances using heuristic, decrease overall sizeinstances 50x50 25x25.Even decreased instance size, dynamic algorithms able solve25 instances unit action durations. algorithms, unit actiondurations, solved 13 full 25 instances. Figure 10 shows resultsexperiment, data point represents mean instances solvedalgorithms unit action duration (between 13 17 instances).see ranking algorithms remains algorithmsregardless weakening heuristic. note unit action duration 0.001seconds rise data. attributed solving larger subset25 instances containing difficult instances, thus increasing GAT.5.3.2 CPU Usagepaper focus minimizing CPU time assumes timeallocated search may utilized, still instructive compare CPU usagenew techniques. one might imagine, tradeoff CPU usage GAT.inverse relationship seen examining algorithm utilizes searchtime. Single step policies execute search every action goal reached.behavior increase overall demand CPU. However, using single steppolicy, goal achieved quickly using multi-step policy. Dynamic136fiAchieving Goals Quickly Using Real-time Searchplatformplatformsingle-step fLSS-LRTA*dynamic fhat10050-4-3-2-1unit action duration (log10)(a)single-step fdynamic fhatLSS-LRTA*0.9fraction search time usedtotal raw cpu time (seconds)1500.60.3-40-3-2-1unit action duration (log10)(b)0Figure 11: Comparison LSS-LRTA*, single-step LSS-LRTA* dynamic f termscpu usage.lookahead greedily use search time becomes available, arrivegoal quickly.Figure 11, search time plotted. Figure 11 (a) shows raw cpu time usedalgorithm platform domain. axis raw cpu time secondsx axis log10 unit action duration. seen plot, dynamic f usessmall amount planning time. attributed dynamic f findinggoal quickly. single-step policy able find goal quicklyLSS-LRTA*(see Figure 3), requires cpu time unit action durationincreases.Figure 11 (b) plots raw cpu time divided goal achievement time. providesidea active CPU execution algorithms. importantkeep mind quick goal achievement times small denominator, causingutilization appear higher raw cpu time longer goal achievementtime. reduced utilization longer action durations likely dynamic f ablefind goals quickly using small number iterations remainder executionoverlapping planning time.5.3.3 Implementation Detailsf technique requires information standard LSS-LRTA*, slightlygreater storage requirements. note, however, experimentsrun memory issues, optimize implementation reducememory requirements.137fiKiesel, Burns, & Rumlimplementation uses two different types nodes: persistent transient. Persistent nodes form agents memory states encountered past lookaheadsearches: connectivity, learned heuristic values, distance estimatesheuristic error accrued. Transient nodes exist single round lookahead searchh-cost learning; akin traditional search nodes used in, example, A*search, however include information required order search f.persistent node, store information connectivity search graph.includes set predecessors successors node costs associated edges. store predecessors assume undirected search graphpredecessor function easily computable. predecessors successorscomputed lazily. predecessor added first expanded, entire set successors populated first time node expanded. successor nodes,also store cost reversing edge (which matters case edge costssymmetric) operator used generate successor. Persistent nodes alsostore learned heuristic estimate cached values original h estimatesnode, would otherwise need computed time needed.Transient nodes hold additional information needed perform best first search orderedf. First, transient node pointer corresponding persistent node.addition, transient node g-cost, f -cost, f-cost computedsingle lookahead search node persists. information containedtransient nodes are: pointer best parent current lookahead search;nodes index open list (which implemented array-based binary heap), neededupdating nodes position heap encountered via better path; twobooleans used h-cost learning easily determine node alreadyh value updated determine closed list. detail, referreader source code freely available GitHub (Kiesel et al., 2015a).differences information stored f normal LSS-LRTA*implementation latter store estimates persistent node set,store f values transient nodes. information exactly same.5.3.4 Theoretical Evaluationprove that, certain conditions, modifications LSS-LRTA* retaincompleteness property algorithm. learning cause f convergef . begin, assume heuristic admissible state space finite.Proposition 1. Following spirit Korf completeness proof LRTA*, note that,search algorithm incomplete finite state space, must exist nodesvisited infinite number times. 1goal show nodes cannot exist.Lemma 1. dynamic f searches within finite set nodes D, h valuesnodes interior reach fixed point (remain static unchanging)finite time T1 , least long search remains within D.1. note that, contrary assumptions previous work, algorithm need actually enterloop, trajectory may vary non-repeating way, digits conjectured to.138fiAchieving Goals Quickly Using Real-time SearchProof.1. h updated using update rule LSS-LRTA*, hvalues state space non-decreasing via Koenig Suns (2008) Theorem 1regarding LSS-LRTA*.2. Note h values nodes fringe remain statich-value learning updates heuristic nodes interior LSS. Everyupdate learning step obeys h(p) = max(h(p), c(p, bc) + h(bc)), bcbest child p one lowest f value. Thus every h(p) valuesum numbers drawn set C contains: edge costs, setfringe h values, set initial h(p) values. finitenumber costs C, update h(p) must larger minimum positivedifference two possible sums costs drawn C. Thus increasesbounded constant.3. Similarly step 1, h values remain admissible via Theorem 2 Koenig Sunregarding LSS-LRTA*, cannot rise true cost go.4. steps 1, 2, 3, must time T1 , h values changelong search remains within set D.Lemma 2. search visits finite set nodes infinite number times,exists time search visits nodes D.Proof. Consider LSSes formed iteration learning stepparents inherit h values child lowest f . Considering pairsnodes, two cases: a) two nodes LSS infinite numbertimes number search iterations approaches infinity, b) nodesLSS finite number times. pairs case (b), notemust exist time, , never LSS, otherwise twonodes would covered case (a) instead.Lemma 3. dynamic f searches within set D, one-step heuristic errorgoes 0 time T2 stays least long search remains withinD.Proof.1. Consider pairs nodes LSS . Lemma 1,exists T1 h values converged. T1 , knowh(p) = c(p, bc) + h(bc).2. Note average, across internal nodes LSS associatedbest children, differences f values parents best children.step 1, f (p) = f (bc), = 0 holds time T2 T1 .Lemma 4. cannot exist set nodes dynamic f visits infinitely often.Proof.1. sake contradiction, let set nodes part LSSinfinite number times.2. Lemma 3, become 0 time T2 .139fiKiesel, Burns, & Ruml3. time T2 = 0, h = h, f = h, dynamic f behave like LSS-LRTA*(dynamic-sized lookahead makes difference LSS-LRTA*s theoretical propertieshold without regard lookahead size).4. LSS-LRTA* complete (Koenig & Sun, 2008, Thm. 3), search eventuallyreach goal. contradicts 1, dynamic f visit set states infinitelyoften.Note that, dynamic f escape potential set D, described step 1proof Lemma 4, circulate within another set nodes infinite time,would equaled instead. Also, oscillate twosets, would defined union sets.Theorem 1. finite search space admissible h, dynamic f eventually reachgoal.Proof. Proof contradiction:1. Assume search never reaches goal. dynamic f goes goalLSS, means goal never LSS.2. finite space, search never sees goal, must visit statesinfinite number times.3. Lemma 4, dynamic f exhibit behavior.4. Thus, using dynamic f retains completeness LSS-LRTA*.6. Comparison Off-line Techniquesprevious sections, explored modifications LSS-LRTA* algorithm improveability achieve goals quickly. LSS-LRTA*s performance improved applyingheuristic correction either using single-step movement policy using dynamicallysized lookahead searches. section evaluate performance algorithmsstandard offline techniques. included three extra domains finalcomparison, 15-puzzle, grid pathfinding, novel domain call trafficdomain. 15-puzzle, used 94 instances Korfs 100 instances (Korf, 1985)implementation A* able solve using 6GB memory limit. gridpathfinding, ran orz100d grid map video game Dragon Age: Origins(Sturtevant, 2012). map, shown Figure 12, includes mix open space mazelike areas narrow corridors. used 25 start end locations longestoptimal path lengths scenarios Sturtevant (2012). completeness, resultsbest performing algorithms random selection 10 additional maps presentedAppendix A.140fiAchieving Goals Quickly Using Real-time SearchFigure 12: Grid path-finding video game map.6.1 Traffic Domaintraffic domain new domain inspired part video games Frogger2 .goal traffic domain navigate grid given goal locationavoiding obstacles, many motion. state includes x, locationagent x, location obstacle (In implementation, locationsobstacles stored state; instead, store states current time,obstacle locations computed based initial location, velocity, time).Time divided discrete intervals called ticks, agent move one fourcardinal directions remain still tick. Obstacles horizontalvertical velocities either -1, 0, 1 cell per-tick respective direction.Obstacle locations known agent time future. obstaclehits edge grid bounces off, reversing velocity direction hit.Obstacles simply pass other. search space directed, timeticking forward and, obstacles move, agent cannot perform action moveobstacles back previous locations. domain especially well-suitedreal-time techniques agent must action ready execute tickworld transitions obstacles move.eliminate dead end states (real-time algorithms incomplete presencedead ends), result executing action agent intersectionobstacle, agent teleported back start state location (at time t=0).especially important offline algorithms expect begin execution initial2. domain similar 2011 ICAPS International Probabilistic Planning Competition domaincalled crossing traffic constructed MDP also POMDP. versiondomain deterministic fully observable.141fiKiesel, Burns, & Ruml15-puzzlefactor optimal GAT (log10)factor optimal GAT (log10)platform2.41.60.80-4-3-2-1unit action duration (log10)0-4-3-2orz100d0traffic3factor optimal GAT (log10)factor optimal GAT (log10)-1unit action duration (log10)2103210-4-3-2-1unit action duration (log10)0-3-2-1unit action duration (log10)Figure 13: Comparison off-line techniques.state despite passage time planning. experiments, generated 25random solvable instances consisting 100x100 grids 5,000 obstacles placed randomlyrandom velocities. start location upper-left corner gridgoal location lower-right corner. average solution length 211.24 moves.Videos showing traffic domain available on-line (Kiesel et al., 2015b) discussedAppendix B.1420fiAchieving Goals Quickly Using Real-time Search6.2 Resultsallowing planning execution take place simultaneously, possibleimprove offline techniques delay execution planning finished. assessthis, compared best-performing variants LSS-LRTA* A* algorithmcalled Speedy (Thayer & Ruml, 2009). Speedy best-first greedy search d(n),estimated number actions remaining goal. tends find poor plans quickly,providing informative contrast A*. Figure 13 shows results comparison,log10 factor optimal goal achievement time axis unitaction duration, log10 scale, x axis.f-based search dynamic lookahead gave best goal achievement timesplatform, 15-puzzle, traffic domains. Speedy strong performer gridpathfinding domain traffic domain. surprising domainsbased grid navigation. traffic domain Speedy able quickly find collision freepath (avoiding additional cost overhead). grid pathfinding A* actually lowestgoal achievement times unit action durations, f dynamic lookaheadtied A* except fastest unit action duration. results gridpathfinding consistent results presented Hernandez et al. (2012),best performer good A*. (In study, best performerTBA*, dont compare work directed graphs.)likely A* solve grid pathfinding problems quickly, thus shortplanning times, still finds optimal solutions.Even though A* performs well, applicable real-time constraint presentaction needs returned within bound. A*-based real-time algorithms givesimilar results infinite lookahead, although would waste time learning.7. Related Worklarge body work relating real-time search. section reviewwork discuss relation techniques presented previoussections.7.1 Pruning Dead Statesf -LRTA* (Sturtevant & Bulitko, 2011) extension LSS-LRTA* RIBS (Sturtevant,Bulitko, & Bjornsson, 2010), combining h-cost learning g-cost learning. g-costlearning enables algorithm label states dead-ends redundant. Determiningtypes states using basic algorithm relies underlying undirected graph.arises requirement compute cost successor parent. undirectedgraph simply reverse operator, case directed graph, wouldrequire call either heuristic call additional search determine costedge. consultation Sturtevant, created small modification includereverse edge costs easily computable. However, practiceperform well directed graph domains. conclude work neededadapt ideas behind f -LRTA* directed graphs.143fiKiesel, Burns, & RumlSharon, Sturtevant, Felner (2013) introduce technique pruning dead statesreal-time agent-centered search. work detects two types dead states: expendableswamp. determined considering reachability shortest pathslocal neighborhood state. dead state pruning shown lead speedups 8-way grid pathfinding, applicable certain domains. Let us first considerundirected domains considered paper. sliding tile puzzle, example,expendable swamp states exist locally. neighbors state reachanother neighbor without passing considering local neighborhood.Without reachability, shortest paths exist, locally expendable swamp stateswould pruned. also note grid navigation problem considersmovement four cardinal directions, pruning could occur either reason.directed graph, predecessors must also considered local neighborhood. case, expendable state would state whose predecessors reachss successors without traversing s. Similarly, swamp state would statewhose predecessors shortest paths successors pass s.traffic domain, example, state contains time, predecessors statetime t, would time 1 successors time + 1.way traverse state 1 state time + 1 without traversingstate time t. state state local neighborhood time t,paths exist predecessors successors pass s.expendable swamp states would pruned domain.7.2 Minimizing Search EffortGAT model assumes search occur action execution, appropriate situations separate processor cores responsible planning versusmanaging execution. processor resources scarce shared among many tasks,one may want minimize search effort even execution. Bulitko, Lustrek, Schaeffer,Bjornsson, Sigmundarson discuss methods dynamically adjusting real-time searchlookahead order minimize search effort still selecting good actions. contrast,discussed section 5.3.2, dynamic f attempts use available execution timeperform much search possible.7.3 Time-bounded A*Time-bounded A* (TBA*, Bjornsson, Bulitko, & Sturtevant, 2009) non-agent-centeredreal-time search algorithm. Instead performing bounded amount lookahead searchagents current state, TBA* maintains single A* search agents initialstarting state goal state. iteration, fixed number expansions donesingle search agent attempts move toward promising nodesearch frontier. Since agent may already moved away initial stateprevious iterations, A* vacillates many different paths, agentscurrent state may along current best path. occurs, agent backtrackstoward initial state current best path. experiments, Bjornssonet al. showed that, grid pathfinding benchmarks, TBA* requires fewer iterations findquality paths real-time algorithms LRTA*.144fiAchieving Goals Quickly Using Real-time Searchmentioned briefly above, Hernandez et al. (2012) found TBA* besttechnique optimizing goal achievement time grid pathfinding problems fully-knowngrids. state performance A*. experiments, compare TBA*, consider domains form directed graphs,TBA* works undirected graphs, due agents need backtrack.suspect, however, dynamic lookahead f technique would quite competitiveTBA*, also matched performance A* grid pathfinding problemsable greatly outperform A* domains.7.4 Avoiding Depressions Real-time Heuristic SearchReal-time search algorithms become temporarily stuck heuristic local minimumextended period search execution time (Sturtevant & Bulitko, 2014). agenttypically wander around heuristic minimum learns heuristicarea inaccurate corrects it. behavior results long solutionsaesthetically undesirable.daLSS-LRTA* daRTAA* (Hernandez & Baier, 2012) attempt actively avoidescape heuristic depressions. Instead selecting node lowest f value, daLSSLRTA* selects node along frontier whose heuristic value changed least.daRTAA* similar uses simpler learning phase borrowed Real-Time AdaptiveA* (Koenig & Likhachev, 2006). RTAA* daRTAA* update entire interiorlocal search f value node open list best f value.implemented daLSS-LRTA* daRTAA* compared standardLSS-LRTA* well multi-step dynamic lookahead variants LSS-LRTA* usingf. results comparison shown Figure 14. results grid pathfindingproblem (orz100d) agree results Hernandez Baier (2012) show usingdepression avoidance techniques help improve performance (for example, compare LSSLRTA* daLSS-LRTA*). Also, daLSS-LRTA* daRTAA* outperform standardmulti-step variant LSS-LRTA* using f. Dynamic lookahead f clearly gives bestperformance fastest unit action duration 0.0001. platformtraffic domains, however, daLSS-LRTA* appears slightly worse LSS-LRTA*,15-puzzle depression avoidance appears little effect. Overall, found dynamicf dominate techniques.Similar Figure 10, see spike 0.001 unit action duration platformdomain. attributed jump number instances solvedalgorithms 0.0001 0.001. larger set contains difficult instancesincreases factor optimal GAT.may interesting future work combine depression avoidance dynamic lookahead, especially grid pathfinding domains.7.5 Weighted Real-time Heuristic SearchWeighted A* (wA*, Pohl, 1970) popular heuristic search algorithm proceeds likeA*, orders nodes open list using f (n) = g(n) + w h(n), w 1.w increases, search becomes greedy often find solutions faster A*.solutions may optimal, guaranteed within factor w145fiKiesel, Burns, & Ruml15-puzzlefactor optimal GAT (log10)factor optimal GAT (log10)platform1.81.20.60-4-3-2-1unit action duration (log10)0-4-3-2orz100d0traffic3factor optimal GAT (log10)factor optimal GAT (log10)-1unit action duration (log10)211.81.20.600-4-3-2-1unit action duration (log10)0-3-2-1unit action duration (log10)Figure 14: Depression avoidance real-time heuristic search.optimal solution cost. Rivera, Baier, Hernandez (2012) recently showed variant wA*real-time search called wLSS-LRTA*. One obvious way implement real-time variantwA* would simply multiply heuristic value w 1 lookahead searchLSS-LRTA*, however, wLSS-LRTA* this. Instead, wLSS-LRTA* multipliesedge weights w learning phase LSS-LRTA*. update rule becomes:h(n) minmopen w g(n, m) + h(m), g(n, m) cost node nupdated node open list lookahead search.1460fiAchieving Goals Quickly Using Real-time Search15-puzzle2.4factor optimal GAT (log10)factor optimal GAT (log10)platform1.60.80-4-3-2-1unit action duration (log10)0-4-3-20trafficfactor optimal GAT (log10)factor optimal GAT (log10)orz100d3w=16 LSS-LRTA*w=1 LSS-LRTA*dynamic fhatw=2 LSS-LRTA*2-1unit action duration (log10)12.41.60.800-4-3-2-1unit action duration (log10)0-3-2-1unit action duration (log10)Figure 15: Weighted real-time heuristic search.Rivera et al. (2012) show using increased weight wLSS-LRTA* leadlower-cost solutions. point that, admissible heuristics lower bounds,inflating heuristic factor w may make heuristic accurate.reasoning behind f technique. difference wLSS-LRTA* uses weightinflate g portion updated heuristic whereas f technique adds correctionbased h portion updated heuristic. would argue f approachmakes sense error causing heuristic underestimate comeperfectly-known g portion update, estimated h portion.1470fiKiesel, Burns, & Rumlimplemented wLSS-LRTA* compared standard multi-step dynamiclookahead variants LSS-LRTA* using f. results comparison shownFigure 15. results grid pathfinding problem (orz100d) tend agreeRivera et al. (2012): using larger weights wLSS-LRTA* increase performance.trend seems depend, however, unit action duration; noticeableactions fast. Also, grid pathfinding, wLSS-LRTA* outperforms standardmulti-step variant LSS-LRTA* using f, dynamic lookahead f clearly givesbest performance fastest unit action duration 0.0001. However,platform, 15-puzzle, traffic domains found almost opposite true! Dynamicf still bestit nearly dominates techniques. fairest comparisonLSS-LRTA* using f (with statically sized lookahead) provides better performancewLSS-LRTA*, dominating wLSS-LRTA* weight greater 1 15-puzzletraffic problems, increasing weight wLSS-LRTA* either effectmakes performance worse. traffic domain weights greater 1, wLSSLRTA* unable solve problems lookahead 1, greater lookaheadvalues tried (including lookahead 2) slow meet real-time deadlineunit action duration 0.0001, thus data point x=0.0001 eitheralgorithms. Based results, conclude using parameter-free ftechnique explicitly attempt account heuristic error recommended approachweighting edge costs learning user-specified parameter.7.6 FRITFollow Reconnect Ideal Tree, FRIT (Rivera, Illanes, Baier, & Hernandez,2013), takes another approach dealing heuristic minima real-time search. Ratherapplying heuristic learning updating escape local minimum, FRIT insteadtries follow ideal tree state space. ideal tree represents family pathsconnect states search space goal state. also thoughtimplicitly represented heuristic.ideal tree explored following heuristic greedily operatorsapplicable states, heuristic suggests operator inapplicable. simpleexample following Manhattan distance heuristic grid pathfinding domainencountering obstacle. inapplicable operator suggested, tree becomesdisconnected agent must reconnect tree. done performinglocal search around agents current state state believed Ideal Treefound. agent moves state continues on. resulting behaviorgrid pathfinding domains appear similar wall following.modifications required make FRIT real-time algorithm. localsearch find state Ideal Tree bounded size state space,rather time bound expansion limit. authors suggest techniquesbounding local search experiments, allowed FRIT thoughtoffline allowed much time needed looking reconnect IdealTree. also used breadth first search local search algorithm.implemented FRIT compared standard LSS-LRTA* multistep dynamic versions LSS-LRTA* using f. results shown Figure 16.148fiAchieving Goals Quickly Using Real-time Searchfactor optimal GAT (log10)orz100d3LSS-LRTA*dynamic fhat210-4-3-2-1unit action duration (log10)0Figure 16: Comparison offline FRIT using breadth first search.present results grid pathfinding problem (orz100d). FRIT ablesolve easier instances platform traffic domains within five minutetimeout. sliding tile puzzle domain, unclear adapt algorithmdomain. naive approach results branching factor 44 poor results.grid pathfinding, even treating FRIT offline algorithm penalizingsearch time final goal achievement time, performs worse three variantsLSS-LRTA* presented. exception unit action duration small,point FRIT competitive algorithms (ignoring search time).7.7 FALCONSFurcy Koenig (2000) present two modifications LRTA* speed convergencetime. noticed breaking ties favor successors smaller f -values LRTA*would converge quickly. also point also use tie-breaking criteria select successor move to, convergence occurs even faster. two modifications yield two new algorithms: Tie Breaking LRTA* (TB-LRA*) FAst LearningCONverging Search (FALCONS).Figure 17 compare original LRTA*, TB-LRTA* FALCONS.domains three algorithms perform worse newer LSS-LRTA* modifiedversions LSS-LRTA*.7.8 RTA*Korf (1990) proposed LRTA* seminal paper also another algorithmsimply called Real Time A* (RTA*). RTA*, unlike counterpart LRTA*, focusedsolving problem getting start state goal state once. LRTA*149fiKiesel, Burns, & Ruml15-puzzlefactor optimal GAT (log10)factor optimal GAT (log10)platform2.41.60.803210-4-3-2-1unit action duration (log10)0-4-3-20trafficfactor optimal GAT (log10)orz100dfactor optimal GAT (log10)-1unit action duration (log10)432143LSS-LRTA*dynamic fhat2100-4-3-2-1unit action duration (log10)0-3-2-1unit action duration (log10)Figure 17: Comparison LRTA*, TBLRTA* FALCONS.proven converge optimal heuristic values successive trials. RTA*s learning policyguarantee convergence heuristic values practice find solutionsquickly LRTA*.Figure 18 compare RTA*. include LRTA* plots well showtradeoff convergence initial goal achievement time RTA* makes. RTA*slookahead based bounded depth first search, run time difficult predict.experiments ran RTA* lookahead depths {1, 5, 10, 20, 50, 100, 200, 400,800, 1000, 1500, 2000, 3000, 4000, 8000, 10000, 16000} chose largest depth1500fiAchieving Goals Quickly Using Real-time Search15-puzzlefactor optimal GAT (log10)factor optimal GAT (log10)platform321432100-4-3-2-1unit action duration (log10)0-4-3-20trafficfactor optimal GAT (log10)factor optimal GAT (log10)orz100d54LSS-LRTA*dynamic fhat3-1unit action duration (log10)2103LSS-LRTA*dynamic fhat210-4-3-2-1unit action duration (log10)0-3-2-1unit action duration (log10)Figure 18: Comparison RTA*.instances solved within timeout. interesting note 15-puzzledepth 1500 able used, platform traffic lookahead 10could used. attribute platform traffic graphy domains,tiles fewer cycles. extreme case grid pathfinding orz100d mapmaximum lookahead 5 could solve instances within timeout. supplementarycomparison, also provide line RTA* using A* lookahead instead depth firstsearch grid pathfinding domain. expansion limit 4000 largest lookahead1510fiKiesel, Burns, & Rumlsize solved instances. four plots Figure 18, see neweralgorithms outperform RTA* domains.7.9 BugsyBugsy (Burns et al., 2013b) real-time search, off-line algorithmexplicitly attempts optimize utility function given linear combination searchtime solution cost. solution cost specified units time, Bugsyexplicitly attempt minimize goal achievement time appropriately weighting searchexecution times given units. off-line algorithmoptimize goal achievement time objective, interesting see Bugsycompares real-time algorithms. Since performs global search, may better ableoptimize cost, inherently less efficient, cannot plan execute parallel.Figure 19 shows results. Bugsy tended lowest goal achievement timesdomains except traffic domain, dynamic lookahead f method nearlydominated approaches. However, domains except 15-puzzle, advantage Bugsy small. conclude that, full solution found upfront,off-line methods like Bugsy often given best results. agent mustrespect real-time constraints, however, dynamic lookahead f technique algorithmchoice.may possible create new algorithm incorporates ideas Bugsyreal-time search. Bugsy proceeds like A*, orders open list utility estimateu(n) = wf f (n) + wt time(n), time(n) estimate time searchtake reach best solution beneath node n (for details, see Burns et al., 2013b).difficulty incorporating ideas Bugsy real-time search Bugsys utilityestimate assumes none planning time, time(n), occur parallelexecution time f (n) (recall cost units time optimizing goal achievementtime). real-time search, true. solution cost units timeplanning happens execution, optimizing cost seems appropriate.8. Conclusionpaper considered real-time search context minimizing goal achievementtime concurrent planning execution possible. optimizing goal achievement time, important consider tradeoff searching executing.presented three modifications LSS-LRTA*: 1) taking single steps instead movingway fringe lookahead search, 2) use multiple steps, dynamically increaselookahead size match execution time trajectory, 3) using f correctbias heuristic. evaluated techniques plain LSS-LRTA*, A*,Speedy, daRTAA*, daLSS-LRTA*, wLSS-LRTA*, FRIT, TBLRTA*, FALCONS, LRTA*,RTA*, Bugsy four domains. addition 15-puzzle grid pathfindingdomains, classic heuristic search benchmarks, used two video-game-inspireddomains: platform domain new traffic domain.showed committing single actions time give better performanceusing traditional multiple action approach. demonstrated usingmultiple action technique even better performing single steps amount152fiAchieving Goals Quickly Using Real-time Search15-puzzlefactor optimal GAT (log10)factor optimal GAT (log10)platform2.41.60.80-4-3-2-1unit action duration (log10)0-4-3-2orz100d0traffic3factor optimal GAT (log10)factor optimal GAT (log10)-1unit action duration (log10)211.81.20.600-4-3-2-1unit action duration (log10)0-3-2-1unit action duration (log10)Figure 19: Comparison Bugsy.lookahead search dynamically adjusted use time available executioncurrently-executing multi-step trajectory. pointed possible reasonsusing A*-based lookahead search may lead poor performance showed f couldused fix issues. Overall, combination dynamically sized lookaheadf gave best performance compared previous real-time techniques. hopework spur research applying real-time heuristic search dynamicdomains.1530fiKiesel, Burns, & Ruml9. Acknowledgmentswork supported part NSF (grants 0812141 1150068), DARPACSSG program (grant D11AP00242), University New Hampshire DissertationYear Fellowship. preliminary version work published Burns, Kiesel,Ruml (2013a).Appendix A. Grid Pathfinding Results Additional Mapsfollowing random sample 10 maps Sturtevants repository topperforming algorithms plotted. plots similar included paperlog10 factor optimal goal achievement time y-axis log10 unit actionduration x-axis.0.4factor optimal GAT (log10)factor optimal GAT (log10)arena20.6single-step f0.20.24single-step f0.160.0800-3-4-2-1unit action duration (log10)0-4-3-2-1unit action duration (log10)0factor optimal GAT (log10)factor optimal GAT (log10)orz201d0.024single-step fdaRTAA*0.0160.00800.12single-step f0.080.040-4-3-2-1unit action duration (log10)0-4154-3-2-1unit action duration (log10)0fi1.2factor optimal GAT (log10)factor optimal GAT (log10)Achieving Goals Quickly Using Real-time Searchsingle-step fdaRTAA*daLSS-LRTA*0.80.40.024single-step f0.0160.00800-4-3-2-1unit action duration (log10)0-4factor optimal GAT (log10)factor optimal GAT (log10)isound1daLSS-LRTA*LSS-LRTA*single-step f-3-2-1unit action duration (log10)00.15single-step f0.10.050-4-32.4-10-4w=2 LSS-LRTA*LSS-LRTA*dynamic fhat1.6-3daRTAA*daLSS-LRTA*0.8-2-1unit action duration (log10)0rmtst01LSS-LRTA*daRTAA*factor optimal GAT (log10)factor optimal GAT (log10)-2unit action duration (log10)dynamic fhat0-4-3-2-1unit action duration (log10)0-4155-3-2-1unit action duration (log10)0fiKiesel, Burns, & RumlAppendix B. Video Descriptionsdescribe videos available on-line (Kiesel et al., 2015b).B.1 Platform Videosvideos numbered 1-10 playlist show algorithms solving Platform domain.B.1.1 Random InstanceVideos 1-7 provide example random instance Platform platform domainsolved various algorithm configurations.Video 1 LSS-LRTA* 1,000 node lookahead using multi-step policy.video see algorithm get stuck local heuristic minima actively tryingupdate heuristic estimates states minimum.Video 2 LSS-LRTA* 1,000 node lookahead using single-step policy.video see algorithm traverse smaller sized local minima much quicklystill become stuck short larger local minimum around 9 seconds.Video 3 LSS-LRTA* using dynamically sized lookahead. Initially, gets stuckinside local minimum, similar LSS-LRTA* static lookahead, soon ableescape learning increasing lookahead sizes.Video 4 LSS-LRTA* using dynamically sized lookahead heuristic correction.quickly able escape various heuristic minima way goal.Video 5 Speedy. video see algorithm able find solutionquickly starts moving almost instantly. next 2 minutes video spentexecuting highly suboptimal solution.Video 6 A*. visualize planning time complete solution foundA* begins moving (roughly 1 minute 15 seconds, see video 7). solutionoptimal quickly gets agent initial position goal.Video 7 comparison LSS-LRTA* 1,000 node lookahead, LSS-LRTA*dynamically sized lookahead heuristic correction, A* Speedy. video,planning time visualized.B.1.2 Ladder InstanceVideos 8-10 demonstrate extreme example heuristic minimum. visibility graphheuristic assumes agent able jump infinitely high, creating large local minimumagent must learn way of.Video 8 shows LSS-LRTA* 1,000 node lookahead multi-step policy struggling climb platform ladder.Video 9 shows LSS-LRTA* 1,000 node lookahead single-step lookaheadpolicy quickly climbing ladder struggling end.Video 10 shows optimal example climb ladder using A*.156fiAchieving Goals Quickly Using Real-time SearchB.2 Traffic Videosremaining videos illustrate traffic domain, highly dynamic domain manymoving obstacles agent must avoid. videos provided visualization domain algorithms trying solve.Video 11 shows example optimal solution found A* never collidesobstacle.Video 12 shows LSS-LRTA* 1,000 node lookahead solving problem.video around 20 seconds, agent wanders situation collision occurstransported back start state.ReferencesBjornsson, Y., Bulitko, V., & Sturtevant, N. (2009). TBA*: time-bounded A*. ProceedingsTwenty-first International Joint Conference Artificial Intelligence (IJCAI),pp. 431436.Bulitko, V., Lustrek, M., Schaeffer, J., Bjornsson, Y., & Sigmundarson, S. (2008). Dynamiccontrol real-time heuristic search. Journal Artificial Intelligence Research, 32,419452.Burns, E., Kiesel, S., & Ruml, W. (2013a). Experimental real-time heuristic search resultsvideo game. Proceedings Sixth Annual Symposium CombinatorialSearch (SoCS).Burns, E., Ruml, W., & Do, M. B. (2013b). Heuristic search time matters. JournalArtificial Intelligence Research (JAIR), 47, 697740.Furcy, D., & Koenig, S. (2000). Speeding convergence real-time search.Proceedings National Conference Artificial Intelligence (AAAI), pp. 891897.Hernandez, C., & Baier, J. (2012). Avoiding escaping depressions real-time heuristicsearch. Journal Artificial Intelligence Research (JAIR), 43, 523570.Hernandez, C., Baier, J., Uras, T., & Koenig, S. (2012). Time-bounded adaptive A*.Proceedings Eleventh International Joint Conference Autonomous AgentsMultiagent Systems (AAMAS).Kiesel, S., Burns, E., & Ruml, W. (2015a).Research code heuristic search.https://github.com/eaburns/search. Accessed September 2, 2015.Kiesel, S., Burns, E., & Ruml, W. (2015b). Videos achieving goals quickly using realtime search. http://bit.ly/1bW3Ey8. Accessed September 2, 2015.Koenig, S., & Likhachev, M. (2002). lite. Proceedings Eighteenth NationalConference Artificial Intelligence (AAAI), pp. 476483.Koenig, S., & Likhachev, M. (2006). Real-time adaptive A*. Proceedings International Joint Conference Autonomous Agents Multiagent Systems (AAMAS).Koenig, S., & Sun, X. (2008). Comparing real-time incremental heuristic searchreal-time situated agents. Journal Autonomous Agents Multi-Agent Systems,pp. 18(3):313341.157fiKiesel, Burns, & RumlKorf, R. E. (1985). Depth-first iterative-deepening: optimal admissible tree search.Artificial Intelligence, 27 (1), 97109.Korf, R. E. (1990). Real-time heuristic search. Artificial intelligence, 42 (2-3), 189211.Lustrek, M., & Bulitko, V. (2006). Lookahead pathology real-time path-finding.Proceedings National Conference Artificial Intelligence (AAAI), WorkshopLearning Search, pp. 108114.Pohl, I. (1970). Heuristic search viewed path finding graph. Artificial Intelligence,1, 193204.Rivera, N., Illanes, L., Baier, J. A., & Hernandez, C. (2013). Reconnecting idealtree: alternative heuristic learning real-time search. ProceedingsSixth International Symposium Combinatorial Search (SoCS).Rivera, N., Baier, J. A., & Hernandez, C. (2012). Weighted real-time heuristic search.Proceedings Twelfth International Conference Autonomous AgentsMultiagent Systems (AAMAS).Sharon, G., Sturtevant, N. R., & Felner, A. (2013). Online detection dead statesreal-time agent-centered search. Proceedings Sixth Annual SymposiumCombinatorial Search (SoCS).Sturtevant, N. (2012). Benchmarks grid-based pathfinding. Transactions Computational Intelligence AI Games (TCIAIG), 4 (2), 144 148.Sturtevant, N., & Bulitko, V. (2014). Reaching goal real-time heuristic search: Scrubbing behavior unavoidable. Proceedings Seventh Annual SymposiumCombinatorial Search (SoCS).Sturtevant, N. R., & Bulitko, V. (2011). Learning going whencecame: h-and g-cost learning real-time heuristic search. ProceedingsTwenty-Second International Joint Conference Artificial Intelligence (IJCAI), pp.365370.Sturtevant, N. R., Bulitko, V., & Bjornsson, Y. (2010). learning agent-centered search.Proceedings Ninth International Conference Autonomous Agents Multiagent Systems (AAMAS), pp. 333340. International Foundation AutonomousAgents Multiagent Systems.Thayer, J. T., Dionne, A., & Ruml, W. (2011). Learning inadmissible heuristicssearch. Proceedings Twenty-first International Conference AutomatedPlanning Scheduling (ICAPS).Thayer, J. T., & Ruml, W. (2009). Using distance estimates heuristic search. Proceedings Nineteenth International Conference Automated Planning Scheduling (ICAPS).158fiJournal Artificial Intelligence Research 59 (2015) 59-82Submitted 05/15; published 09/15Solving #SAT MaxSAT Dynamic ProgrammingSigve Hortemo StherJan Arne TelleMartin Vatshellesigve.sether@ii.uib.notelle@ii.uib.nomartin.vatshelle@ii.uib.noDepartment Informatics, University BergenBergen, NorwayAbstractlook dynamic programming algorithms propositional model counting, alsocalled #SAT, MaxSAT. Tools graph structure theory, particular treewidth,used successfully identify tractable cases many subfields AI, includingSAT, Constraint Satisfaction Problems (CSP), Bayesian reasoning, planning.paper attack #SAT MaxSAT using similar, modern, graph structuretools. tractable cases include formulas whose class incidence graphsunbounded treewidth also unbounded clique-width. show algorithms extendprevious results MaxSAT #SAT achieved dynamic programming alongstructural decompositions incidence graph input formula. presentlimited experimental results, comparing implementations algorithms state-of-the-art#SAT MaxSAT solvers, proof concept warrants research.1. Introductionpropositional satisfiability problem (SAT) fundamental problem computer scienceAI. Many real-world applications planning, scheduling, formal verificationencoded SAT SAT solver used decide exists solution.decide many solutions are, propositional model counting problem (#SAT),finds number satisfying assignments, could useful. solutions,may interesting know close get solution. propositionalformula encoded Conjunctive Normal Form (CNF) may solved maximumsatisfiability problem (MaxSAT), finds maximum number clausessatisfied assignment. paper investigate classes CNF formulastwo problems, #SAT MaxSAT, solved polynomial time. Toolsgraph structure theory, particular treewidth, used successfully identifytractable cases many subfields AI, including SAT, Constraint Satisfaction Problems(CSP), Bayesian reasoning, planning (Bacchus, Dalmao, & Pitassi, 2003; Darwiche,2001; Fischer, Makowsky, & Ravve, 2008; Samer & Szeider, 2010). paperattack #SAT MaxSAT using similar, modern, graph structure tools.tractable cases include formulas whose class incidence graphs unboundedtreewidth also unbounded clique-width.#SAT MaxSAT significantly harder simply deciding satisfyingassignment exists. #SAT #P-hard (Garey & Johnson, 1979) even restrictedHorn 2-CNF formulas, monotone 2-CNF formulas (Roth, 1996). MaxSATNP-hard even restricted Horn 2-CNF formulas (Jaumard & Simeone, 1987),c2015AI Access Foundation. rights reserved.fiSther, Telle & Vatshelle2-CNF formulas variable appears 3 times (Raman, Ravikumar, & Rao,1998). problems become tractable certain structural restrictions obtainedbounding width parameters graphs associated formulas (Fischer, Makowsky, & Ravve,2008; Ganian, Hlineny, & Obdrzalek, 2013; Samer & Szeider, 2010; Szeider, 2003).work present inspired recent results work Paulusma, Slivovsky,Szeider (2013) also work Slivovsky Szeider (2013) showing #SATsolvable polynomial time incidence graph1 I(F ) input formula Fbounded modular treewidth, strongly, bounded symmetric clique-width.tractability results work dynamic programming along decomposition I(F ).two steps involved: (1) find good decomposition, (2) perform dynamicprogramming along decomposition. goal fast runtime, usuallyexpressed function known graph width parameter incidence graph I(F )formula F , like tree-width. Step (1) solved known graph algorithmcomputing decomposition low (tree-)width, step (2) solves #SAT MaxSATdynamic programming runtime expressed terms (tree-)width kdecomposition.algorithms give paper also work dynamic programming alongdecomposition, slightly different framework. Since solving graphtheoretic problem, expressing runtime graph theoretic parameter may limitation.Therefore, strategy develop framework based following strategy(A) consider, #SAT MaxSAT, amount information needed combinesolutions subproblems global solutions,(B) define notion good decompositions based parameter minimizesinformation,(C) design dynamic programming algorithm along decomposition runtimeexpressed parameterwork Paulusma et al. (2013) Slivovsky Szeider (2013)two assignments considered equivalent satisfy set clauses.carrying (A) #SAT MaxSAT led us concept ps-valueCNF formula. Let us define give intuitive explanation. subset C clausesCNF formula F called projection satisfiable complete assignmentsatisfying every clause C satisfying clause C. ps-value Fnumber projection satisfiable subsets clauses. Let us consider connectiondynamic programming, general applies optimal solution foundcombining optimal solutions certain subproblems. #SAT MaxSATsubproblems, least cases consider, take form subformula F inducedsubset clauses variables, i.e. first remove F variablesremove clauses S. Consider simplicity two subproblems FS FSdefined complement S. combining solutions FS FS , order1. I(F ) bipartite incidence graph clauses F one hand variables Fhand. Information positive negative occurrences variables encoded I(F )sometimes signed directed version used includes also information.60fiSolving #SAT MaxSAT Dynamic Programmingfind solutions F , seems clear must consider number cases leastbig ps-values two disjoint subformulas crossing S, i.e.subformulas obtained removing clauses variables S, removingclauses variables S. See Figure 2 example.find literature study ps-value CNF formulas, startasking characterization formulas low ps-value. led conceptmim-value I(F ), size maximum induced matching I(F ),induced matching subset edges property edge graphincident one edge . Note value much lowersize maximum matching, e.g. complete bipartite graph mim-value 1. showps-value F upper bounded number clauses F raised powermim-value I(F ), plus 1. CNF formula F I(F ) mim-value 1interpretation result straightforward: clauses totally orderedtwo clauses C < C 0 variables occurring C subset variables occurringC 0 , implication number subsets clausescomplete assignment satisfies exactly subset number clauses plus 1.Families CNF formulas small ps-value algorithmic interest,paper continue part (B) strategy, focusdecompose CNF formula F based concept ps-value. common way decomposemathematical object recursively partition ground set two parts, givingbinary tree whose root represents ground set whose leaves bijectively mappedelements ground set. Taking ground set F set containingclauses variables, decompose F , words binary treewhose leaves 1-1 correspondence variables clauses. node binarytree represents subset X variables clauses leaves subtree.decomposition trees good efficiently solving #SAT MaxSAT? accordancediscussion part (A) answer good decomposition treessubformulas crossing X X, X defined nodetree, low ps-value. See Figure 2 example. define informal notionprecisely use concept branch decomposition ground set formulacut function ps-value formulas crossing cut. Branch decompositionsstandard notion graph matroid theory, originating work RobertsonSeymour graph minors (Robertson & Seymour, 1991). way arrivedefinition ps-width CNF formula F , decompositions F achieveps-width. important note formula ps-value exponentialformula size ps-width polynomial, general class formulas lowps-width much larger class formulas low ps-value.finish strategy, must carry part (C) show solve #SATMaxSAT dynamic programming along branch decomposition formula,express runtime function ps-width. complicated, dynamicprogramming everything defined properly simply becomes exercisebrute-force computation sufficient necessary information, technicalquite tedious. leads following theorem.Theorem 2. Given formula F n variables clauses, decomposition Fps-width k, solve #SAT weighted MaxSAT time O(k 3 m(m + n)).61fiSther, Telle & VatshelleThus, given decomposition ps-width k polynomially-boundednumber variables n clauses formula, get polynomial-time algorithms.Let us compare result strongest previous result direction, namelywork Slivovsky Szeider (2013) #SAT. algorithm takes input branchdecomposition vertex set I(F ), ground set F ,evaluates runtime cut function call index. show cut functionclosely related symmetric clique-width scw given decomposition, giving runtime(n + m)O(scw) . Considering clique-width cw given decomposition runtimecwwork Slivovsky Szeider (2013) becomes (n + m)O(2 ) since symmetric clique-widthclique-width related essentially tight inequalities 0.5cw scw 2cw (Courcelle,2004). algorithm thus polynomial-time algorithm given decompositionconstantly bounded scw. result Theorem 2 encompasses this, since Corollary 1ties ps-width mim-width work Vatshelle (2012) shows mim-width upperbounded clique-width, see also work Rao (2008) symmetric clique-width,decomposition I(F ) constantly bounded (symmetric) clique-width alsopolynomially bounded ps-width. way, given decomposition assumed inputwork Slivovsky Szeider (2013), algorithm Theorem 2 runtimeO(m3cw s), cw clique-width given decomposition.work Brault-Baron, Capelli, Mengel (2014), appearing preliminarypresentation results (Sther, Telle, & Vatshelle, 2014), argued frameworkbehind Theorem 2 gives uniform explanation tractability results #SATliterature, particular using dynamic programming based structural decompositionsincidence graph. work Brault-Baron et al. (2014) also goes beyond this, givingpolynomial-time algorithm, dynamic programming, solve #SAT -acyclicCNF formulas, exactly formulas whose incidence graphs chordal bipartite.show formulas bounded ps-width incidencegraphs bounded mim-width. See Figure 1 gives overview resultspaper papers.Using concept mim-width graphs, introduced thesis Vatshelle (2012),connection ps-value mim-value alluded earlier, show rich classformulas, including classes unbounded clique-width, polynomially bounded ps-widththus covered Theorem 2. Firstly, holds classes formulas incidencegraphs represented intersection graphs certain objects, like interval graphs(Belmonte & Vatshelle, 2013). Secondly, holds also much larger class bipartitegraphs achieved taking bigraph bipartizations intersection graphs, obtainedimposing bipartition vertex set keeping edges partition classes.bigraph bipartizations studied previously, particular intervalbigraphs. interval bigraphs contain bipartite permutation graphs, lattergraphs shown unbounded clique-width (Brandstadt & Lozin, 2003). SeeFigure 1.Let us discuss step (1), finding good decomposition. Note Theorem 2 assumesinput formula given along decomposition ps-width k. value kneed optimal, heuristic finding reasonable branch decomposition couldused practice. Computing decompositions optimal ps-width probably doable62fiSolving #SAT MaxSAT Dynamic ProgrammingidenincFh Fce grapps-width mk#SAT poly. Paper A.#SAT poly. Paper B.chordalbipartite#SAT MaxSAT poly.paper.-acyclicps-width m2MIM-width kclique-width ksymmetricclique-width k/2modulartreewidth k/2ps-widthk-trapezoidbigraphcircular arcbigraphinterval bigraphbipartitepermutationFigure 1: believe, argued work Brault-Baron et al. (2014), dynamicprogramming approach working along structural decomposition solve #SAT(or MaxSAT) polynomial time cannot go beyond green box. PaperBrault-Baron et al. (2014) Paper B Slivovsky Szeider (2013).left two dashed lines 4 classes graphs bound k/2 kstructural graph width parameter, 5 classes bipartite graphs.right -acyclic CNF formulas 3 classes CNF formulas ps-widthvarying linear number clauses m, m2 mk . arcP Q formula F incidence graph I(F ) property P alsoproperty Q. Hasse diagram, lack arc transitive closuremeans relation provably hold.polynomial-time, complexity question adressed paper. However,able efficiently decide CNF formula certain linear structure guaranteeinglow ps-width. combining alternative definition interval bigraphs (Hell & Huang,2004) fast recognition algorithm (Muller, 1997; Rafiey, 2012) arrivefollowing. Say CNF formula F interval ordering exists total orderingvariables clauses variable x occurring clause C, x appearsC variable also occurs C, C appears x xoccurs also clause them.Theorem 6. Given formula F n variables clauses literals.time O((m + n)mn) decide F interval ordering (yes iff I(F )interval bigraph), yes solve #SAT weighted MaxSAT additionalruntime O(min{m2 , 4t }(m + n)m).Formulas interval ordering precisely whose incidence graphs intervalbigraphs, Theorem 6 encompasses classes formulas whose incidence graphsunbounded clique-width.Could parts algorithms interest practical applications? Answeringquestion beyond scope present paper. However, performed limitedtesting, particular formulas linear structure, simple proof concept.code found online (Sther, Telle, & Vatshelle, 2015). designedimplemented heuristic step (1) finding good decomposition, case linear63fiSther, Telle & Vatshelleone binary tree describing decomposition path attached leaves.also implemented step (2) dynamic programming solving #SAT MaxSAT alongdecompositions. run (1) followed (2) compare onebest MaxSAT solvers Max-SAT-2014 event SAT-2014 conferencelatest version #SAT solver called sharpSAT (Thurley, 2006). solvers beatimplementation inputs, suprising since code includetechniques beyond algorithm. Nevertheless, able generate classesCNF formulas interval orderings implementation far better.lends support belief methods related ps-value warrants researchinvestigate could useful practice.paper organized follows. Section 2 give formal definitions ps-valueps-width CNF formula show central combinatorial lemma linking ps-valueformula size maximum induced matching incidence graphformula. Section 3 present dynamic programming algorithms given formuladecomposition solves #SAT weighted MaxSAT, proving Theorem 2. Section 4investigate classes formulas decompositions low ps-width, basically provingcorrectness hierarchy presented Figure 1. Section 5 consider formulasinterval ordering prove Theorem 6. Section 6 present resultsimplementations testing. end Section 7 open problems.2. Frameworkconsider propositional formulas Conjunctive Normal Form (CNF). literalpropositional variable negated variable, x x, clause set literals,formula multiset clauses. formula F , cla(F ) denotes clauses F .incidence graph formula F bipartite graph I(F ) vertex clausevariable, variable x adjacent clause C occurs. considerinput formulas I(F ) connected, otherwise would solve problemsseparate components I(F ). clause C, lit(C) denotes set literalsC var(C) denotesvariables literals lit(C). formula F , var(F )denotes union Ccla(F ) var(C). set X variables, assignment Xfunction : X {0, 1}. literal `, define (`) 1 (var(`)) ` negatedvariable (` = x variable x) (var) otherwise (` = x variablex). clause C said satisfied assignment exists least one literal` lit(C) (`) = 1. clause assignment satisfy saidfalsified . notice means empty clause falsified assignments.formula satisfied assignment satisfies clauses cla(F ).problem #SAT, given formula F , asks many distinct assignments var(F )satisfy F . optimization problem weighted MaxSAT, given formulaP F weightfunction w : cla(F ) N, asks assignment var(F ) maximizes C w(C)C cla(F ) satisfied . problem MaxSAT asks maximum number satisfiedclauses achieved, equivalent weighted MaxSAT clauses weightone. weighted MaxSAT, assume sum weights 2O(cla(F )) ,thus summation weights time linear cla(F ).64fiSolving #SAT MaxSAT Dynamic Programmingset A, elements universe U denote elements U \ A,universe usually given context.2.1 Cut Formulapaper, solve MaxSAT #SAT use dynamic programming.using divide conquer technique solve problem smallersubformulas original formula F combine solutions smallerformulas form solution entire formula F . Note however, solutions foundsubformula depend interaction subformula remainderformula. use following notation subformulas.clause C set X variables, C|X denote clause {` C : var(`) X}.say C|X clause C induced X. Unless otherwise specified, clauses mentionedpaper set cla(F ) (e.g., write C|X cla(F 0 ), still assume Ccla(F )). formula F subsets C cla(F ) X var(F ), say subformulaFC,X F induced C X formula consisting clauses {Ci |X : Ci C}.is, FC,X formula get removing clauses C followed removingliteral variable X. set C clauses, denote C|X set {C|X : C C}.clause, assignment set X variables, say assignmentinduced X 0 X assignment |X 0 domain restricted X 0 .formula F sets C cla(F ), X var(F ), = C X, call cut Fnote breaks F four subformulas FC,X , FC,X , FC,X , FC,X . See Figure 2.One important fact may observe definition clause C F satisfiedassignment var(F ), C (induced X X) satisfiedleast one formulas cut F .2.2 Projection Satisfiable Sets ps-value Formulaformula F assignment variables var(F ), denote sat(F, )inclusion maximal set C cla(F ) clause C satisfied .set C cla(F ) sat(F, ) = C variables var(F ), Cknown projection (Kaski, Koivisto, & Nederlof, 2012; Slivovsky & Szeider, 2013)say C projection satisfiable F . denote PS(F ) family projectionsatisfiable sets F . is,PS(F ) = {sat(F, ) : assignment entire set var(F )}.cardinality set, |PS(F )|, referred ps-value F .get grasp structure formulas low ps-value consider inducedmatchings incidence graph formula. incidence graph formula Fbipartite graph I(F ) vertex clause variable, variable x adjacentclause C occurs. induced matching graph subset edgesproperty edge graph incident one edge .words, 3 vertices a, b, c, ab edge bc edgeexist edge cd . number edges called size induced matching.following result provides upper bound ps-value formula termsmaximum size induced matching incidence graph.65fiSther, Telle & VatshelleLemma 1. Let F CNF formula clause containing literals,let k maximum size induced matching I(F ). |PS(F )|min{|cla(F )|k + 1, 2tk }.Proof. first argue |PS(F )| |cla(F )|k + 1. Let C PS(F ) Cf = cla(F ) \ C.Thus, exists complete assignment clauses satisfiedCf = cla(F ) \ sat(F, ). Since every variable var(F ) appears clause Fmeans |var(Cf ) unique assignment variables var(Cf ) satisfy00clause Cf . Let Cf Cf inclusion minimal set var(Cf ) = var(Cf ),hence |var(Cf ) also unique assignment variables var(Cf ) satisfy00clause Cf . upper bound number different minimal Cf ,0C PS(F ), give upper bound |PS(F )|. every C Cf variable vC00appearing C clause Cf , otherwise Cf would minimal. Noteinduced matching I(F ) containing edges vC , C. assumption,0induced matching k edges hence |Cf | k. easy showinduction k |cla(F )|k + 1 sets k clauses lemmafollows.argue |PS(F )| 2tk . maximum induced matching size kset C k clauses var(C) = var(F ). clause C C |var(C)| t,|var(F )| = |var(C)| tk. 2|var(F )| assignments F ,PS-value F upper bounded 2tk .2.3 ps-width Formuladefine branch decomposition formula F pair (T, ) rootedbinary tree bijective function leaves clauses variablesF . non-leaf nodes (also referred internal nodes) induce path,say (T, ) linear branch decomposition. non-leaf node v , denote(v) set {(l) : l leaf subtree rooted v}. Based this, saydecomposition (T, ) formula F induces certain cuts F , namely cuts defined (v)node v .formula F branch decomposition (T, ), node v , Fv denoteformula induced clauses cla(F ) \ (v) variables (v), Fvdenote formula complement sets; i.e. clauses (v) variablesvar(F ) \ (v). words, (v) = C X C cla(F ) X var(F )Fv = FC,X Fv = FC,X . simplify notation, node v branchdecomposition set C clauses denote C|v set C|var(Fv ) . define ps-valuecut (v)ps((v)) = max{|P S(Fv )|, |P S(Fv )|}define ps-width branch decompositionpsw(T, ) = max{ps((v)) : v node }define ps-width formula Fpsw(F ) = min{psw(T, ) : (T, ) branch decomposition F }66fiSolving #SAT MaxSAT Dynamic Programmingvx4x3 c4 x5 c2x1x2c1Cc1 = {x1 , x2 }c3 = {x2 , x4 , x5 }c3FC,X = FvXFC,XFC,Xx1 x2x3 x4x5FC,X = Fvc2 = {x1 , x2 , x3 }c4 = {x2 , x3 , x5 }XCFigure 2: top branch decomposition formula F var(F ) = {x1 , x2 , x3 , x4 , x5 }4 clauses cla(F ) = {c1 , c2 , c3 , c4 } given boxes. nodev tree defines cut (v) = C X C = {c1 , c3 } X ={x1 , x2 }. 4 subformulas defined cut: FC,X , FC,X , FC,X , FC,X .example, FC,X = {{x1 , x2 }, {x2 }} FC,X = {, {x4 , x5 }}.Fv = FC,X Fv = FC,X projection satisfiable sets clauses PS(Fv ) ={{c2 |v }, {c4 |v }, {c2 |v , c4 |v }} PS(Fv ) = {, {c3 |v }} ps-value cutps((v)) = max{|P S(Fv )|, |P S(Fv )|} = 3.Note ps-value cut symmetric function. is, ps-value cutequals ps-value cut S. See Figure 2 example.3. Dynamic Programming MaxSAT #SATGiven branch decomposition (T, ) CNF formula F n variables clausestotal size s, give algorithms solve MaxSAT #SAT F timeO(psw(T, )3 m(m + n)). algorithms strongly inspired work SlivovskySzeider (2013), order achieve runtime polynomial ps-width, also solveMAXSAT, must make crucial changes. particular, must index dynamicprogranming tables PS-sets rather shapes used work SlivovskySzeider (2013).Let us discuss special terminology used section. dynamicprogramming section, combine partial solutions subformulas solutionsinput formula F . improve readability introduce notation P 0 sat0allows us refer directly clauses F , also working subformulas.67fiSther, Telle & VatshelleThus, formula F branch decomposition (T, ), node v , inducedsubformula Fv F , PS0 (Fv ) denote subsets clauses C cla(F ) \ (v)PS(Fv ) = C|var(Fv ) . Similarly, assignment var(Fv ), sat0 (Fv , )denote set clauses C cla(F ) \ (v) sat(Fv , ) = C|var(Fv ) . Note|PS0 (Fv )| = |PS(Fv )| |sat0 (Fv , )| = |sat(Fv , )|. take liberty call alsosets projection satisfiable refer PS-sets text, clearcontext mean clauses cla(F ) cla(Fv ).Let us discuss implementation details. regard PS-sets boolean vectorslength |cla(F )|, assume identify clauses variables integer numbers. So,checking clause PS-set done constant time, checking two PS-setsequal done O(|cla(F )|) time. manage PS-sets, use binary triedatastructure (Fredkin, 1960). add retrieve PS-set trieO(|cla(F )|) time. Trying add PS-set trie already containing equivalent PS-setalter content trie, tries contain distinct PS-sets.retrieval element trie takes O(|cla(F )|) time, assigning distinct integerPS-set time added trie, O(|cla(F )|)-time mappingPS-sets distinct integers. used implicitly algorithmssay index PS-sets; implementing algorithm instead indexcorresponding integer PS-set mapped to.pre-processing step need following which, node v computessets projection satisfiable subsets clauses PS0 (Fv ) PS0 (Fv ) two crossingsubformulas Fv Fv .Theorem 1. Given CNF formula F branch decomposition (T, ) ps-width k,time O(k 2 m(m + n)) compute sets PS0 (Fv ) PS0 (Fv ) v .Proof. notice node v children c1 c2 , express PS0 (Fv )C1 PS0 (Fc1 ),0PS (Fv ) = (C1 C2 ) cla(Fv ) :.C2 PS0 (Fc2 )Similarly, sibling parent p v , set PS0 (Fv ) expressedCp PS0 (Fp ),0PS (Fv ) = (Cp Cs ) cla(Fv ) :.Cs PS0 (Fs )transforming recursive expressions dynamic programming algorithm,done Procedure 1 Procedure 2 below, able calculate desired setslong compute sets base cases PS0 (Fl ) l leaf , PS0 (Fr )root r . However, formulas contain one variable, thuseasily construct set projection satisfiable clauses linear amount timeformulas. rest formulas, construct formulas using Procedure 1Procedure 2. twice many nodes clausesvariables F , procedures run O(|cla(F )| + |var(F )|) times. runalgorithms, iterate k 2 pairs projection satisfiable sets,constant number set operations might take O(|cla(F )|) time each. resultstotal runtime O(k 2 |cla(F )|(|cla(F )| + |var(F )|)) = O(k 2 m(m + n)) nodescombined.68fiSolving #SAT MaxSAT Dynamic ProgrammingProcedure 1: Generating PS0 (Fv )input: PS0 (Fc1 ) PS0 (Fc2 ) children c1 c2 vbranch decompositionoutput: PS0 (Fv )L empty trie projection satisfiable clause-sets(C1 , C2 ) PS0 (Fc1 ) PS0 (Fc2 )add (C1 C2 ) cla(Fv ) Lreturn LProcedure 2: Generating PS0 (Fv )input: PS0 (Fs ) PS0 (Fp ) sibling parent p vbranch decompositionoutput: PS0 (Fv )L empty trie projection satisfiable clause-sets(Cs , Cp ) PS0 (Fs ) PS0 (Fp )add (Cs Cp ) cla(Fv ) Lreturn Lmove dynamic programming proper. first give algorithmMaxSAT briefly describe changes necessary solving weighted MaxSAT#SAT.algorithm uses technique expectation introduced work Bui-Xuan,Telle, Vatshelle (2010, 2011). partial solutions might good combinedcertain partial solutions, bad combined others. techniqueexpectation categorize partial solutions interact, optimize selectionpartial solutions based expectation interaction occurs. dynamicprogramming algorithm MaxSAT, apply technique making expectationscut regarding set clauses satisfied variables opposide sidecut.node v decomposition F PS-sets C PS0 (Fv ) C 0 PS0 (Fv ),say assignment var(F ) meets expectation C C 0 sat0 (Fv , |v ) = Csat0 (Fv , |v ) = C 0 . node v branch decomposition, algorithm usestable Tabv pair (C, C 0 ) PS0 (Fv ) PS0 (Fv ) stores Tabv (C, C 0 ) maximumnumber clauses (v) satisfied, assignments meeting expectationC C 0 . variables var(F ) \ (v) satisfy exactly C 0 , assignmentmeets expectation, equivalent formulation content Tabv (C, C 0 )must satisfy following constraint:assignments var(F ) (v) sat0 (Fv , ) = C ,fifiTabv (C, C 0 ) = max fi sat0 (F, 0 ) (v) C 0 fi(1)bottom-up dynamic programming along tree compute tablesnode . leaf l , generating Tabl done easily linear time sinceformula Fv contains one variable. internal node v , children c1 , c2 ,69fiSther, Telle & Vatshellecompute Tabv algorithm described Procedure 3. 3 tables involvedupdate, one child one parent. pair entries, one childtable, may lead update entry parent table. table entry indexedpair, thus 6 indices involved single potential update. trick first introducedwork Bui-Xuan et al. (2011) allows us loop triples indicestriple compute remaining 3 indices forming 6-tuple involved update, therebyreducing runtime.Procedure 3: Computing Tabv inner node v children c1 , c2input: Tabc1 , Tabc2output: Tabv1. initialize Tabv : PS0 (Fv ) PS0 (Fv ) {1}2. (Cc1 , Cc2 , Cv0 ) PS0 (Fc1 ) PS0 (Fc2 ) PS0 (Fv )3.Cc0 1 (Cc2 Cv0 ) (c1 )4.Cc0 2 (Cc1 Cv0 ) (c2 )5.Cv (Cc1 Cc2 ) \ (v)6.Tabc1 (Cc1 , Cc0 1 ) + Tabc2 (Cc2 , Cc0 2 )7.Tabv (Cv , Cv0 ) < Tabv (Cv , Cv0 )8. return TabvLemma 2. CNF formula F clauses inner node v, branch decomposition (T, ) ps-width k, Procedure 3 computes Tabv satisfying Constraint (1) timeO(k 3 m).Proof. assume Tabc1 Tabc2 satisfy Constraint (1). Procedure 3 loops triplesPS0 (Fc1 ) PS0 (Fc2 ) PS0 (Fv ). definition ps-width (T, )k 3 triples. operation inside iteration loop take O(m) timeconstant number operations. Thus runtime O(k 3 m).show correctness output, let us look bit workingsProcedure 3. assignment var(F ), cut, assignment meetexpectation single pair PS-sets. Let (X1 , X10 ), (X2 , X20 ) (Xv , Xv0 ) pairsassignment meets expectation respect cuts induced c1 , c2 , v,respectively. noticeXv = sat0 (Fv , |v )= sat0 (Fv , |c1 ] |c2 )= sat0 (Fv , |c1 ) sat0 (Fv , |c2 )= (sat0 (Fc1 , |c1 ) \ (v)) (sat0 (Fc2 , |c2 ) \ (v))(2)= (X1 \ (v)) (X2 \ (v))= (X1 X2 ) \ (v).also seen Figure 3. symmetry, find similar values X10 X20 ;namely X10 = (X2 Xv0 ) (c1 ) X20 = (X1 Xv0 ) (c2 ). So, latter three setsimplicit based three former sets respect cuts induced v, c1c2 . therefore, convenience proof, say assignment meets70fiSolving #SAT MaxSAT Dynamic Programming= X1 = sat (Fc1 , |c1 )clauses cla(F ) \ (v)= X2 = sat (Fc2 , |c2 )= Xv = sat (Fv , |v )clauses (c2 )clauses (c1 )Figure 3: shown chain equalities (2) proof Lemma 2, clausessat0 (Fv , |v ) precisely clauses (sat0 (Fc1 , |c1 ) sat0 (Fc2 , |c2 )) \ (v).expectation triple (C1 , C2 , C 0 ) PS-sets, meets expectation implicitthree pairs respective cuts. notice choice triplesPS-sets (Cc1 , Cc2 , Cv0 ) Procedure 3 computes implicit three sets namesCc0 1 , Cc0 2 Cv accordingly.show pairs (C, C 0 ) PS0 (Fv ) PS0 (Fv ) value Tabv (C, C 0 )correct. Let 0 assignment var(F ) satisfies maximum numberclauses, meeting expectation C C 0 . Thus, value Tabv (C, C 0 ) correctstores exactly number clauses (v) 0 satisfies.Let (C1 , C10 ) (C2 , C20 ) pairs PS-sets 0 meet expectationcut ((c1 ), (c1 )) ((c2 ), (c2 )), respectively. 0 meets expectations, valueTabc1 (C1 , C10 ) Tabc2 (C2 , C20 ) must least large number clauses 0satisfies (c1 ) (c2 ), respectively. Thus, number clauses 0 satisfies(c1 ) (c2 ) large sum two entries. Since Procedure 3,iteration Cv0 = C 0 , Cc1 = C1 Cc2 = C2 , ensures Tabv (C, C 0 ) leastsum Tabc1 (C1 , C10 ) Tabc2 (C2 , C20 ), know Tabv (C, C 0 ) least largecorrect value.assume contradiction value cell Tabv (C, C 0 ) large.means iteration Procedure 3 assigned value Tabc1 (Cc1 , Cc0 1 ) +Tabc2 (Cc2 , Cc0 2 ) sum large. Let 1 2 assignments var(F )meeting expectation Cc1 Cc0 1 meeting expectation Cc2 , Cc0 2 , respectively,number clauses (c1 ) (c2 ), respectively, equals according tableentries Tabc1 Tabc2 . take assignment x = 1 |c1 ] 2 |c2 ] 0 |v ,assignment meets expectation C C 0 , satisfies clauses(v) 0 , contradicting choice 0 . Tabv (C, C 0 ) neither smaller largernumber clauses (v) 0 satisfies, exactly same.Theorem 2. Given formula F n variables clauses, branch decomposition(T, ) F ps-width k, solve MaxSAT, #SAT, weighted MaxSAT timeO(k 3 m(m + n)).Proof. solve MaxSAT, first compute Tabr root node r . requiresfirst compute PS0 (Fv ) PS0 (Fv ) nodes v , then, bottommanner, compute Tabv O(m + n) nodes . former part71fiSther, Telle & VatshelleO(k 2 m(m + n)) time Theorem 1, latter part O(k 3 m(m + n)) timeLemma 2.root r (r) = var(F ) cla(F ). Thus Fr = Frvariables, P S(Fr ) P S(Fr ) contains (, ). assignments var(F )meet expectation cut ((r), (r)), cla(F ) (r) = cla(F ),Constraint (1) value Tabr (, ) maximal number clauses F assignmentvar(F ) satisfies. hence, number solution MaxSAT.weight function w : cla(F ) N, redefining Constraint (1) Tabv maximizew(sat0 (F, ) (v)) instead |sat0 (F, ))(v)|, able solve generalproblem weighted MaxSAT way.problem #SAT, care assignments satisfying clausesF , want decide number distinct assignments so. requiresalterations. Firstly, alter definition contents Tabv (C, C 0 ) Constraint(1) number assignments var(F ) (v) sat0 (Fv , ) = Cclauses (v) either C 0 satisfied . Secondly, computing Tablleaves l , set entries Tabl either zero, one, two, accordingdefinition. Thirdly, alter algorithm compute Tabv (Procedure 3) inner nodes.initialize Tabv (C, C 0 ) zero start algorithm, substitute lines 67 Procedure 3 following line increases table value producttable values childrenTabv (Cv , Cv ) Tabv (Cv , Cv ) + Tabc1 (Cc1 , Cc1 ) Tabc2 (Cc2 , Cc2 )satisfy new constraint Tabv internal nodes v . value Tabr (, )root r exactly number distinct assignments satisfying clausesF.bottleneck giving cubic factor k 3 runtime Theorem 2 numbertriples PS0 (Fv ) PS0 (Fc1 ) PS0 (Fc2 ) node v children c1 c2 . (T, )linear branch decomposition, always case either c1 c2 leaf .case either |PS0 (Fc1 )| |PS0 (Fc2 )| constant. Therefore, linear branch decompositionsPS0 (Fv ) PS0 (Fc1 ) PS0 (Fc2 ) contain O(k 2 ) triples. Thus reduceruntime algorithm factor k.Theorem 3. Given formula F n variables clauses, linear branchdecomposition (T, ) F ps-width k, solve #SAT, MaxSAT, weighted MaxSATtime O(k 2 m(m + n)).4. CNF Formulas Polynomial ps-widthsection investigate classes CNF formulas decompositions ps-widthpolynomially bounded total size formula. particular, showholds whenever incidence graph formula constant mim-width (maximuminduced matching-width, introduced Vatshelle, 2012). also show large classbipartite graphs, using call bigraph bipartizations, constant mim-width.72fiSolving #SAT MaxSAT Dynamic Programmingorder lift upper bound Lemma 1 ps-value F , i.e |PS(F )|,ps-width F , use mim-width incidence graph I(F ), defined using branchdecompositions graphs. branch decomposition formula F , defined Section2, also seen branch decomposition incidence graph I(F ). Nevertheless,completeness, formally define branch decompositions graphs mim-width.branch decomposition graph G pair (T, ) rooted binary treebijection leaf set vertex set G. node wlet subset V (G) bijection leaves subtree rooted wdenoted Vw . say decomposition defines cut (Vw , Vw ). mim-value cut(Vw , Vw ) size maximum induced matching G[Vw , Vw ]. mim-width (T, )maximum mim-value cuts (Vw , Vw ) defined node w . mim-widthgraph G, denoted mimw(G), minimum mim-width branch decompositions(T, ) G. linear branch decomposition branch decomposition innernodes underlying tree induces path.Since decomposition I(F ) seen also decomposition F , immediatelyget Lemma 1 following corollary.Corollary 1. CNF formula F clauses, clause containingliterals, ps-width F min{mk + 1, 2tk } k = mimw(I(F )).Many classes graphs intersection models, meaning representedintersection graphs certain objects, i.e. vertex associated objecttwo vertices adjacent iff objects intersect. objects used define intersectiongraphs usually consist geometrical objects lines, circles polygons. Many wellknown classes intersection graphs constant mim-width, followinglists subset classes proven bounds (Belmonte & Vatshelle, 2013;Vatshelle, 2012).Theorem 4. (Belmonte & Vatshelle, 2013; Vatshelle, 2012) Let G graph. G a:interval graph mimw(G) 1.circular arc graph mimw(G) 2.k-trapezoid graph mimw(G) k.Moreover exist linear decompositions satisfying bound, found polynomial time (for k-trapezoid assume intersection model given).Let us briefly mention definition graph classes. graph interval graphintersection model consisting intervals real line. graph circular arcgraph intersection model consisting arcs circle. build k-trapezoidstart k parallel line segments (s1 , e1 ), (s2 , e2 ), ..., (sk , ek ) add two non-intersectingpaths e joining si si+1 ei ei+1 respectively straight lines{1, ..., k 1}. polygon defined e two line segments (s1 , e1 ), (sk , ek )forms k-trapezoid. graph k-trapezoid graph intersection model consistingk-trapezoids. See work Brandstadt, Le, Spinrad (1999) informationgraph classes containment relations.Combining Corollary 1 Theorem 4 get followingCorollary 2. Let F CNF formula containing clauses maximum clause-size t.I(F ) a:73fiSther, Telle & Vatshelleinterval graph psw(F ) min{m + 1, 2t }.circular arc graph psw(F ) min{m2 + 1, 4t }.k-trapezoid graph psw(F ) min{mk + 1, 2tk }.Moreover exist linear decompositions satisfying bound, found polynomial time (for k-trapezoid assume intersection model given).incidence graphs formulas bipartite graphs, casemajority graphs above-mentioned graph classes. following showextend results Corollary 2 large classes bipartite graphs. graph Gsubset vertices V (G) bipartite graph G[A, A] subgraph G containingedges G exactly one endpoint A. graph G V (G) call G[A, A]bigraph bipartization G, note G bigraph bipartization subsetvertices. graph class X define class X bigraphs bipartite graphs Hexists G X H isomorphic bigraph bipartization G.example, bipartite graph H interval bigraph interval graph GV (G) H isomorphic G[A, A].following result allow us lift results Corollary 2 given graphsbigraph bipartizations graphs.Theorem 5. Assume given CNF formula F clauses maximumclause-size t, graph G, subset V (G), (T, G ) (linear) branch decompositionG mim-width k. I(F ) connected isomorphic G[A, A] (thus I(F ) bigraphbipartization G) linear time produce (linear) branch decomposition (T, F )F ps-width min{mk + 1, 2tk }Proof. Since variable clause F corresponding node I(F ), nodeI(F ) corresponding node G, defining F function mapping leafl variable clause F corresponding node G (l), get (T, F )branch decomposition F . Consider cut (B, B) induced node (T, F ). Notemim-value G[B, B] k. I(F ) connected meanseither corresponding set variables F . Assume wlog former. ThusC = B cla(F ) clauses B, C = cla(F ) \ C X = B var(F )variables B, X = var(F ) \ X. mim-values G[C, X] G[C, X]k, since induced subgraphs G[B, B], taking induced subgraphscannot increase size maximum induced matching. Hence Lemma 1,|PS(FC,X )| |cla(F )|k + 1, likewise |PS(FC,X )| |cla(F )|k + 1,maximum two ps-value cut. Since ps-width decompositionmaximum ps-value cut theorem follows.Combining Theorems 5 4 immediately get following.Corollary 3. Let F CNF formula containing clauses maximum clause-size t.I(F ) a:interval bigraph psw(F ) min{m + 1, 2t }.circular arc bigraph psw(F ) min{m2 + 1, 4t }.k-trapezoid bigraph psw(F ) min{mk + 1, 2tk }.Moreover exist linear decompositions satisfying bound.74fiSolving #SAT MaxSAT Dynamic Programmingnext section address question finding linear decompositionspolynomial time. succeed case interval bigraphs, circular arc bigraphsk-trapezoid bigraphs must leave open problem.5. Interval Bigraphs Formulas Interval Orderssection show formulas whose incidence graph interval bigraphpolynomial time find linear branch decompositions small ps-width. Letus recall definition interval ordering. CNF formula F interval orderingexists linear ordering variables clauses variable x occurringclause C, x appears C variable also occurs C,C appears x x occurs also clause them. See Figure 4example.Order:x1 c 1 x2 x3 c 2 c 3 x4 x5Clauses:Bipartized interval rep.Incidence graphx1c1x2x3c2c3x4x5c1 = {x1 , x2 }c2 = {x2 , x3 , x5 }c3 = {x3 , x4 , x5 }c1x1c2 c3x2 x3x4 x5Figure 4: CNF formula interval ordering. incidence graph intervalbigraph, since isomorphic bigraph bipartization, defined blueintervals, interval graph intersection model left.work Hell Huang (2004) follows formula F interval orderingI(F ) interval bigraph.Theorem 6. Given CNF formula F n variables clausesliterals. time O((m + n)mn) decide F interval ordering (yes iff I(F )interval bigraph), yes solve #SAT weighted MaxSAT additionalruntime O(min{m2 , 4t }(m + n)m).Proof. Using characterization work Hell Huang (2004) algorithmRafiey (2012) time O((m + n)mn) decide F interval orderingyes, find it. interval ordering build interval graph G I(F )bigraph bipartization G, construct linear branch decomposition Gmim-width 1 (Belmonte & Vatshelle, 2013). linear branch decomposition75fiSther, Telle & Vatshelleget Theorem 5 construct another linear branch decomposition Fps-width O(m). run algorithm Theorem 3.6. Experimental Resultspresent simple experimental results, intended proof concept. beliefideas behind algorithms, like notion ps-value, usefulpractice, require thorough investigation confirm belief. resultsindicate worst-case runtime bounds dynamic programming, Theorems 23, probably higher would commonly seen practice.past decade, SAT solvers become powerful, currently ablehandle large practical instances. Techniques SAT solversapplied develop relatively powerful MaxSAT #SAT solvers (Biere, Heule, & vanMaaren, 2009). experiments compare implementations algorithmsstate-of-the-art MaxSAT #SAT solvers. enhance implementationstechniques, even simple pre-processing, vast majority instancesimplementations fall far behind comparison. However, focusing formulascertain linear order implementations compare favorably.explained Section 1, two steps involved: (1) find good decompositioninput CNF formula F , (2) perform DP (dynamic programming) alongdecomposition. Let us start describing simple heuristic step (1). takesinput bipartite graph I(F ) vertex set cla(F ) var(F ), outputs linearorder vertex set. heuristic GreedyOrder greedy algorithmincreasing values chooses (i) vertex highest number alreadychosen neighbors, among choosing one fewest non-chosen neighbors.defines linear branch decomposition (T, ) CNF formula F , non-leaf nodesbinary tree inducing path, rooted one end path,mapping ith leaf encountered breadth-first search starting rootclause variable (i), 1 |cla(F ) var(F )|.Algorithm GreedyOrderinput: G = (V, E), (bipartite) graphoutput: , linear ordering VL = , R = V , = 1v V set Ldegree(v) = 0R emptychoose v: vertices R max Ldegree take one smallest degreeset (i) = v, increment i, add v L remove v Rw R vw E increment Ldegree(w)76fiSolving #SAT MaxSAT Dynamic Programmingimplementations found online (Sther, Telle, & Vatshelle, 2015).implemented GreedyOrder Java, together straight-forward implementationDP algorithm Theorem 3.Given CNF formula, allows us solve MaxSAT #SAT first runningGreedyOrder DP. compare implementation best solvers couldfind online, respectively CCLS-to-akmaxsat (Luo, Cai, Wu, Jie, & Su, 2014)among best solvers Ninth Max-SAT Evaluation (2014), latest version#SAT solver called sharpSAT (Thurley, n.d., 2006). solvers handily beatimplementation inputs. therefore generated CNF formulasinterval orderings, Theorem 6, check least instances better.Note step (1) implemented polynomial-time algorithm recognizingformulas interval orders, relying instead GreedyOrder heuristic.6.1 Generation Instancespresenting results, let us describe generation set instances,three types. start type 1. generation formulas baseddefinition interval orderings given interval bigraph definition, see e.g. left sideFigure 4. generate formula type 1 n variables clauses, generaten + intervals real line iterating points 1 2(n + m) leftright endpoints intervals:step i, check 4 cases legal (e.g. 3 legal existslive variable, i.e. left endpoint < right endpoint) randomly makeone legal choices:1. start interval new variable left endpoint2. start interval new clause left endpoint3. end interval randomly chosen live variable right endpoint4. end interval randomly chosen live clause right endpointTowards end process boundary conditions enforced reach exactlyclauses, n expected slightly smaller m. clause interval randomlychoose variable overlapping interval either positive negativeclause. resulting CNF formula interval ordering given rightmostendpoints intervals. hide ordering clauses variables randomly permutedmake final CNF formula.formulas type 2 generated similar fashion type 1, exceptguarantee clauses size t, Lemma 1 could big help.change case 4 instead choice becomes enforced liveclause step accumulated exactly overlapping variable intervals. also letclause interval represent 4 clauses variable set randomly chosenliterals, aim increasing probability instance satisfiable.formulas type 3 CNF-representation conjunction XOR functionsXOR fixed number literals variables XOR functions77fiSther, Telle & Vatshelleoverlap way incidence graph bipartization circular arcgraph.formula type 3 generated three input parameters n, t, s. n variablesrepresented successive points 1 n circle. first XOR function interval1 thus containing variables points 1 t, second interval + 1 + t,general ith interval + 1 + t, appropriate modulo additionboundary condition end ensure n/s XOR functions. Variables chosenrandomly appear positive negative XOR. XOR transformedstandard way CNF formula 2t1 clauses give us resulting CNF formulan/s 2t1 clauses. Again, variables clauses randomly permuted hideordering giving circular arc bigraph representation.Note resulting formulas quite simple structure, state-ofthe-art SAT solver, like lingeling (Biere, 2014), handles generated instances withinseconds.6.2 Resultsready present results. ran solvers Dell Optiplex 780running Ubuntu 12.04 64-Bit. machine 8GB memory Intel Core 2 QuadQ9650 processor OpenJDK java 6 (IcedTea6 1.13.5).instances type 1 GreedyOrder heuristic fails terribly becomes hugebottleneck. greedy choice based degrees vertices I(F ) simple. However,given correct interval order solver(s) performed better.Instances type 2 generated similar type 1 clauses small size,Lemma 1 could help. case number clauses approximatelyRuntime seconds600400CCLSsharpSATMaxSAT#SAT(practically equal)2000010002000Number variables3000Figure 5: Runtimes instances type 2. MaxSAT solver clearly fasterCCLS akmaxsat. vertical axis represents time seconds. Runs taking600 seconds stopped completion drawndotted line.78fiSolving #SAT MaxSAT Dynamic Programmingfour times number variables, consequence great number instancessatisfiable, making work #SAT-solvers easier MaxSATsolvers. generated instances type 2 solved within seconds sharpSAT, seeFigure 5. size instances grow, see clear tendency runtimesCCLS akmaxsat increase much rapidly solvers. runtimestwo solvers almost identical. GreedyOrder heuristic instances seemsproduce decompositions/orders low PS-width.type 3 instances shown Figure 6 generated k = 5 = 3.instances satisfiable, may explain CCLS akmaxsat fast. Choosingk = 3 = 2 satisfiable instances CCLS akmaxsat wouldoften spend 600 seconds time out. size instances grow,see clear tendency runtimes sharpSAT increase much rapidlysolvers. runtimes two solvers almost identical.Runtime seconds600400CCLSsharpSATMaxSAT#SAT(practically equal)20006080100120Number variables140Figure 6: Runtimes instances type 3. #SAT solver clearly fastersharpSAT. vertical axis represents time seconds. Runs taking600 seconds stopped completion drawn dotted line.7. Conclusionpaper proposed structural parameter CNF formulas, called ps-widthprojection-satisfiable-width. showed weighted MaxSAT #SATsolved polynomial time given decomposition formula polynomially boundedps-width. Using concept interval bigraphs also showed polynomial time algorithmactually finds decomposition, formulas interval ordering. Couldone devise algorithm also larger class circular arc bigraphs, maybeeven even larger class k-trapezoid bigraphs? words, problemrecognizing bipartite input graph circular arc bigraph, k-trapezoid bigraph,polynomial-time solvable?79fiSther, Telle & Vatshellecould practical interest design heuristic algorithm given formula findsdecomposition relatively low ps-width, done boolean-width (Hvidevold,Sharmin, Telle, & Vatshelle, 2011). One could check benchmarks covering real-worldSAT instances low ps-width, perform study correlation lowps-width practical hardness MaxSAT #SAT solvers, donetreewidth SAT solvers (Mateescu, 2011). presented simple experimentalresults, require thorough investigation check ideas algorithmscould useful practice. Finally, hope essential combinatorial result enablingimprovements paper, Lemma 1, may uses well.ReferencesBacchus, F., Dalmao, S., & Pitassi, T. (2003). Algorithms complexity results for#SATbayesian inference. Foundations computer science, 2003. proceedings. 44thannual ieee symposium (pp. 340351).Belmonte, R., & Vatshelle, M. (2013). Graph classes structured neighborhoodsalgorithmic applications. Theor. Comput. Sci., 511 , 54-65.Biere, A. (2014). Yet another local search solver lingeling friends entering SATcompetition 2014. SAT Competition 2014 , 39.Biere, A., Heule, M., & van Maaren, H. (2009). Handbook satisfiability. (Vol. 185,chap. 20). IOS Press.Brandstadt, A., Le, V. B., & Spinrad, J. P. (1999). Graph classes: survey (Vol. 3).Philadelphia: SIAM Society Industrial Applied Mathematics.Brandstadt, A., & Lozin, V. V. (2003). linear structure clique-width bipartitepermutation graphs. Ars Comb., 67 .Brault-Baron, J., Capelli, F., & Mengel, S. (2014). Understanding model counting-acyclic CNF-formulas. CoRR, abs/1405.6043 . Retrieved http://arxiv.org/abs/1405.6043Bui-Xuan, B.-M., Telle, J. A., & Vatshelle, M. (2010). H-join decomposable graphsalgorithms runtime single exponential rankwidth. Discrete Applied Mathematics,158 (7), 809-819.Bui-Xuan, B.-M., Telle, J. A., & Vatshelle, M. (2011). Boolean-width graphs. TheoreticalComputer Science, 412 (39), 51875204.Courcelle, B. (2004). Clique-width countable graphs: compactness property. DiscreteMathematics, 276 (1-3), 127148. Retrieved http://dx.doi.org/10.1016/S0012-365X(03)00303-0 doi: 10.1016/S0012-365X(03)00303-0Darwiche, A. (2001). Recursive conditioning. Artificial Intelligence, 126 (1), 541.Fischer, E., Makowsky, J. A., & Ravve, E. V. (2008). Counting truth assignmentsformulas bounded tree-width clique-width. Discrete Applied Mathematics, 156 (4),511-529.80fiSolving #SAT MaxSAT Dynamic ProgrammingFredkin, E. (1960). Trie memory. Communications ACM , 3 (9), 490499.Ganian, R., Hlineny, P., & Obdrzalek, J. (2013). Better algorithms satisfiability problemsformulas bounded rank-width. Fundam. Inform., 123 (1), 59-76.Garey, M. R., & Johnson, D. S. (1979). Computers intractability: guide theoryNP-completeness. W. H. Freeman.Hell, P., & Huang, J. (2004). Interval bigraphs circular arc graphs. Journal GraphTheory, 46 (4), 313-327.Hvidevold, E. M., Sharmin, S., Telle, J. A., & Vatshelle, M. (2011). Finding gooddecompositions dynamic programming dense graphs. D. Marx & P. Rossmanith(Eds.), Ipec (Vol. 7112, p. 219-231). Springer.Jaumard, B., & Simeone, B. (1987). complexity maximum satisfiabilityproblem Horn formulas. Inf. Process. Lett., 26 (1), 1-4.Kaski, P., Koivisto, M., & Nederlof, J. (2012). Homomorphic hashing sparse coefficientextraction. Proceedings 7th international conference parameterizedexact computation (pp. 147158).Luo, C., Cai, S., Wu, W., Jie, Z., & Su, K. (2014). CCLS: efficient local searchalgorithm weighted maximum satisfiability. IEEE Transactions Computers. doi:10.1109/TC.2014.2346195Mateescu, R. (2011). Treewidth industrial SAT benchmarks (Tech. Rep.). Tech. rep.Cambridge, UK: Microsoft Research. Retrieved http://research.microsoft.com/pubs/145390/MSR-TR-2011-22.pdfMuller, H. (1997). Recognizing interval digraphs interval bigraphs polynomial time.Discrete Applied Mathematics, 78 (1-3), 189-205.Ninth Max-SAT Evaluation. (2014). Retrieved http://www.maxsat.udl.cat/14/(accessed 16-January-2015)Paulusma, D., Slivovsky, F., & Szeider, S. (2013). Model counting CNF formulasbounded modular treewidth. N. Portier & T. Wilke (Eds.), Stacs (Vol. 20, p. 55-66).Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik.Rafiey, A. (2012).abs/1211.2662 .Recognizing interval bigraphs forbidden patterns.CoRR,Raman, V., Ravikumar, B., & Rao, S. S. (1998). simplified NP-complete MAXSATproblem. Inf. Process. Lett., 65 (1), 1-6.Rao, M. (2008). Clique-width graphs defined one-vertex extensions. DiscreteMathematics, 308 (24), 61576165.Robertson, N., & Seymour, P. D. (1991). Graph minors X. obstructions tree-decomposition.J. COMBIN. THEORY SER. B , 52 (2), 153190.Roth, D. (1996). connectionist framework reasoning: Reasoning examples.81fiSther, Telle & VatshelleW. J. Clancey & D. S. Weld (Eds.), Aaai/iaai, vol. 2 (p. 1256-1261). AAAI Press /MIT Press.Sther, S. H., Telle, J. A., & Vatshelle, M. (2014). Solving MaxSAT #SATstructured CNF formulas. C. Sinz & U. Egly (Eds.), SAT 2014 (Vol. 8561, pp. 1631). Springer. Retrieved http://dx.doi.org/10.1007/978-3-319-09284-3 3doi: 10.1007/978-3-319-09284-3 3Sther, S. H., Telle, J. A., & Vatshelle, M. (2015). online implementations. Retrievedhttp://people.uib.no/ssa032/pswidth/Samer, M., & Szeider, S. (2010). Algorithms propositional model counting. J. DiscreteAlgorithms, 8 (1), 50-64.Slivovsky, F., & Szeider, S. (2013). Model counting formulas bounded clique-width.L. Cai, S.-W. Cheng, & T. W. Lam (Eds.), Isaac (Vol. 8283, p. 677-687). Springer.Szeider, S. (2003). fixed-parameter tractable parameterizations SAT. E. Giunchiglia& A. Tacchella (Eds.), Sat 2003 (Vol. 2919, p. 188-202). Springer.Thurley, M. (n.d.). sharpSAT. Retrieved https://sites.google.com/site/marcthurley/sharpsat (accessed 16-January-2015)Thurley, M. (2006). sharpSATcounting models advanced component cachingimplicit BCP. Theory applications satisfiability testing-sat 2006 (pp. 424429).Springer.Vatshelle, M. (2012). New width parameters graphs. Unpublished doctoral dissertation,University Bergen.82fi