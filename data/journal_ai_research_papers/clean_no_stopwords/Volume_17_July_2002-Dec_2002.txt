Journal Artificial Intelligence Research 17 (2002) 451-499

Submitted 12/00; published 12/02

Policy Recognition Abstract Hidden Markov Model
buihh@cs.curtin.edu.au
svetha@cs.curtin.edu.au
geoff@cs.curtin.edu.au

Hung H. Bui
Svetha Venkatesh
Geoff West
Department Computer Science
Curtin University Technology
PO Box U1987, Perth, WA 6001, Australia

Abstract

paper, present method recognising agent's behaviour dynamic,
noisy, uncertain domains, across multiple levels abstraction. term problem
view generally probabilistic inference
stochastic process representing execution agent's plan. contributions
paper twofold. terms probabilistic inference, introduce Abstract Hidden
Markov Model (AHMM), novel type stochastic processes, provide dynamic Bayesian
network (DBN) structure analyse properties network. describe
application Rao-Blackwellised Particle Filter AHMM allows us
construct ecient, hybrid inference method model. terms plan recognition,
propose novel plan recognition framework based AHMM plan execution
model. Rao-Blackwellised hybrid inference AHMM take advantage
independence properties inherent model plan execution, leading algorithm
online probabilistic plan recognition scales well number levels plan
hierarchy. illustrates stochastic models plan execution complex,
exhibit special structures which, exploited, lead ecient plan recognition
algorithms. demonstrate usefulness AHMM framework via behaviour
recognition system complex spatial environment using distributed video surveillance
data.
on-line plan recognition uncertainty

1. Introduction

Plan recognition problem inferring actor's plan watching actor's actions
effects. Often, actor's behaviour follows hierarchical plan structure. Thus,
plan recognition, observer needs infer actor's plans sub-plans
different levels abstraction plan hierarchy. problem complicated two
sources uncertainty inherent actor's planning process: (1) stochastic aspect
plan refinement (a plan non-deterministically refined different sub-plans),
(2) stochastic outcomes actions (the action non-deterministically result
different outcomes). Furthermore, observer deal third source uncertainty
arising noise inaccuracy observation actor's plan.
addition, would like observer able perform plan recognition task \online" observations actor's plan streaming in. refer general
problem on-line plan recognition uncertainty.
c 2002 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiBui, Venkatesh & West
seminal work plan recognition (Kautz & Allen, 1986) considers plan hierarchy,
deal uncertainty aspects problem. result, approach
postulate set possible plans actor, unable determine
plan probable. Since then, important role uncertainty reasoning plan
recognition recognised (Charniak & Goldman, 1993; Bauer, 1994; van Beek, 1996),
Bayesian probability argued appropriate model (Charniak & Goldman,
1993; van Beek, 1996). dynamic, \on-line" aspect plan recognition
recently considered (Pynadath & Wellman, 1995, 2000; Goldman, Geib, & Miller, 1999;
Huber, Durfee, & Wellman, 1994; Albrecht, Zukerman, & Nicholson, 1998).
recent work shares view online plan recognition largely problem probabilistic
inference stochastic process models execution actor's plan.
view offers general coherent framework modelling different sources uncertainty,
stochastic process need deal become quite complex, especially
consider large plan hierarchy. Thus, main issue computational complexity
dealing type stochastic processes, whether complexity scalable
complex plan hierarchies.
1.1 Aim Significance

paper, demonstrate type plan recognition problems described
scales reasonably well respect number levels abstraction plan hierarchy. contrast common-sense analysis levels plan
hierarchy would introduce variables stochastic process, turn, results
exponential complexity w.r.t number levels hierarchy.
order achieve this, first assume general stochastic model plan execution
model three sources uncertainty involved. model planning
hierarchy abstraction uncertainty developed recently abstract
probabilistic planning community (Sutton, Precup, & Singh, 1999; Parr & Russell, 1997;
Forestier & Varaiya, 1978; Hauskrecht, Meuleau, Kaelbling, Dean, & Boutilier, 1998; Dean
& Lin, 1995). advantage, adopt basic model, known abstract Markov
policies (AMP) 1 model plan execution. AMP extension policy
Markov Decision Processes (MDP) enables abstract policy invoke
refined policies policy hierarchy. Thus, AMP similar contingent plan prescribes sub-plan invoked applicable state
world achieve intended goal, except represent uncertainty
plan refinement outcomes actions. Since AMP described simply
terms state space Markov policy selects among set AMP's, using
AMP model plan execution also helps us focus structure policy
hierarchy.
execution AMP leads special stochastic process called
Abstract Markov Model (AMM). noisy observation environment state (e.g.,
effects action) modelled making state \hidden", similar
hidden state Hidden Markov Models (Rabiner, 1989). result interesting
novel stochastic process term Abstract Hidden Markov Model. Intuitively,
1. Also known options, policies

, supervisor's

Abstract Markov Decision Processes

452

policies

.

fiPolicy recognition Abstract Hidden Markov Model
AHMM models AMP causes adoption policies actions different
levels abstraction, turn generate sequence states observations.
plan recognition task, observer given AHMM corresponding actor's plan
hierarchy, asked infer current policy executed actor
levels hierarchy, taking account sequence observations currently available.
amounts reversing direction causality AHMM, i.e. determine set
policies explain sequence observations hand. shall refer
problem policy recognition.
Viewing AHMM type dynamic Bayesian network (Dean & Kanazawa, 1989;
Nicholson & Brady, 1992), known complexity kind inferencing
DBN depends size representation so-called belief state, conditional
joint distribution variables DBN time given observation sequence
(Boyen & Koller, 1998). Thus ask following question: policy
hierarchy affect size belief state representation corresponding AHMM?
Generally, policy hierarchy K levels, belief state would least
K variables thus size joint distribution would O(exp(K )). However,
AHMM specific network structure exhibits certain conditional independence
properties among variables exploited eciency. first identify
useful independence properties AHMM show compact representation special belief state case state sequence correctly observed
(full observability assumption) starting ending time policy known.
Consequently, policy recognition case performed eciently updating
AHMM compact belief state. partial result, although restricted useful
itself, leads important observation general belief state: although cannot
represented compactly, approximated eciently collection compact special belief states. makes inference problem AHMM particularly amenable
technique called Rao-Blackwellisation (Casella & Robert, 1996) allows us
construct hybrid inference methods combine exact inference approximate
sampling-based inference greater eciency. application Rao-Blackwellisation
AHMM structure reduces sampling space need approximate space
fixed dimension depend K , ensuring hybrid inference algorithm scales well w.r.t K .
contributions paper thus twofold. terms stochastic processes
dynamic Bayesian networks, introduce AHMM, novel type stochastic processes,
provide DBN structure analyse properties network. present application Rao-Blackwellised Particle Filter AHMM results ecient
hybrid inference method stochastic model. terms plan recognition, propose
novel plan recognition framework based probabilistic inference using AHMM
plan execution model. complexity inference problem addressed applying
range recently developed techniques probabilistic reasoning plan recognition
problem. work illustrates stochastic models plan execution
complex, exhibit certain special structures exploited construct ecient
plan recognition algorithms.

453

fiBui, Venkatesh & West
1.2 Structure Paper

main body paper organised follows. Section 2 introduces background
material dynamic Bayesian networks probabilistic inference. Section 3 formally defines abstract Markov policy policy hierarchy. Section 4 presents AHMM,
DBN representation conditional independence properties. algorithms policy recognition discussed Section 5, first special tractable case
general case. Section 6 presents experimental results AHMM framework,
including real-time system recognising people behaviour complex spatial environment using distributed video surveillance data. Section 7 provides comparative review
related work probabilistic plan recognition. Finally, conclude discuss directions
research Section 8.
2. Background Probabilistic Inference

aim section familiarise readers concepts probabilistic inference
used later paper. subsections 2.1 2.2, discuss Bayesian
Networks (BN) Dynamic Bayesian Networks (DBN) general. subsection 2.3,
discuss Sequential Importance Sampling (SIS) algorithm, general approximate
sampling-based inference method dynamic models. Subsections 2.4 2.5 introduce
Rao-Blackwellisation, technique improving sampling-based methods utilising certain
special structures dynamic model. Later on, Rao-Blackwellisation used
key computational technique performing policy recognition.
2.1 Bayesian Networks

Bayesian network (BN) (Pearl, 1988; Jensen, 1996; Castillo, Gutierrez, & Hadi, 1997)
(also known probabilistic network belief network) well-established framework
dealing uncertainty. provides graphical compact representation joint
probability distribution set domain variables X1; : : : Xn form directed
acyclic graph (DAG) whose nodes correspond domain variables. node
Xi , links parent nodes P a(Xi ) parameterised conditional probability node given parents Pr(Xi j P a(Xi )). network structure together
parameters
encode factorisation joint probability distribution (JPD)
Q
n
Pr(X1 ; : : : Xn) = i=1 Pr(Xi j P ai). Given Bayesian network, conditional independence
statements form X ? j Z (X independent given Z, X; Y; Z variables sets variables) asserted X d-separated Z network
structure, d-separation graph separation concept DAGs (Pearl, 1988).
network structure BN thus captures certain conditional independence properties among
domain variables exploited ecient inference.
main inference task Bayesian network calculate conditional probability
set variables given values another set variables (the evidence).
two types computation techniques this. Exact inference algorithms (Lauritzen
& Spiegelhalter, 1988; Jensen, Lauritzen, & Olesen, 1990; D'Ambrosio, 1993) compute
exact value conditional probability required based analytical transformation
exploits conditional independence relationships variables network.

454

fiPolicy recognition Abstract Hidden Markov Model
Approximative inference algorithms (Pearl, 1987; York, 1992; Henrion, 1988; Fung & Chang,
1989; Shachter & Peot, 1989) compute approximation required probability,
usually obtained either \forward" sampling (Henrion, 1988; Fung & Chang, 1989;
Shachter & Peot, 1989) (a variance Bayesian Importance Sampling (Geweke, 1989)),
Gibbs (Monte-Carlo Markov-Chain) sampling (Pearl, 1987; York, 1992).
algorithms advantages simple implementation, applied types
network, trade accuracy estimates computation resources.
known exact inference BN NP-hard respect network size (Cooper,
1990), approximate inference, although scales well network size, NP-hard
respect hard-bound accuracy estimates (Dagum & Luby, 1993).
light theoretical results, approximate inference useful large networks
exact computation intractable, certain degree error probability estimate
tolerated application.
2.2 Dynamic Bayesian Networks

model temporal dynamics environment, Dynamic Bayesian Network
(DBN) (Dean & Kanazawa, 1989; Nicholson & Brady, 1992; Dagum, Galper, & Horvitz,
1992) special Bayesian network architecture representing evolution domain variables time. DBN consists sequence time-slices time-slice
contains set variables representing state environment current time.
time-slice Bayesian network, network structure replicated
time-slice. temporal dynamics environment encoded via network links
one time-slice next. addition, time-slice contain observation nodes
model (possibly noisy) observation current state environment.
Given DBN sequence observations, might want draw predictions
future state variables (predicting), unobserved variables
past (smoothing) (Kjaerulff, 1992). problem solved using inference algorithm Bayesian networks described above. However, want revise prediction
observations arrive time, reapplying inference algorithm time observation sequence changes could costly, especially sequence grows. avoid this,
need keep joint distribution variables current time-slice, given
observation sequence date. probability distribution termed belief state
(also known filtering distribution) plays important role inferencing
DBN. existing inference schemes DBN involve maintaining updating
belief state (i.e., filtering). new observation received, current belief state
rolled one time-slice ahead following evolution model, conditioned new
observation obtain updated belief state.
obvious problem approach size belief state need
maintain. noted interaction variables DBN
localised, variables belief state highly connected (Boyen & Koller, 1998).
marginalisation past time-slices usually destroys conditional
independence current time-slice. size belief state large, exact
inference methods like (Kjrulff, 1995) intractable, becomes necessary maintain
approximation actual belief state, either form approximate

455

fiBui, Venkatesh & West
distribution represented compactly (Boyen & Koller, 1998), form
set weighted samples Sequential Monte-Carlo Sampling methods (Doucet,
Godsill, & Andrieu, 2000b; Kanazawa, Koller, & Russell, 1995; Liu & Chen, 1998).
simple case DBN where, time-slice, single state
variable observation node, well-known Hidden Markov Model (HMM) (Rabiner, 1989). Filtering simple structure solved using dynamic programming discrete HMM (Rabiner, 1989), Kalman filtering linear Gaussian
model (Kalman, 1960). recently, extensions HMM multiple hidden interacting chains Coupled Hidden Markov Models (CHMM) Factorial
Hidden Markov Models (FHMM) proposed (Brand, 1997; Ghahramani & Jordan,
1997; Jordan, Ghahramani, & Saul, 1997). models, size belief state
exponential number hidden chains. Therefore, inference parameter estimation problems become intractable number hidden chains large. reason,
approximate techniques required. CHMM (Brand, 1997) employs deterministic approximation approximates full dynamic programming keeping fixed number
\heads" highest probabilities. \heads" thus chosen deterministically rather
randomly sampling-based methods. FHMM (Ghahramani & Jordan, 1997; Jordan et al., 1997) uses variational approximation (Jordan, Ghahramani, Jaakkola, & Saul,
1999) approximates full FHMM structure sparsified tractable structure.
idea similar structured approximation method (Boyen & Koller, 1998).
AHMM viewed type Coupled/Factorial HMM since AHMM
also consists number interacting chains. However type interaction
AHMM different types interaction considered (Brand,
1997; Jordan et al., 1997; Ghahramani & Jordan, 1997). main focus
AHMM dynamics temporal abstraction among chains, rather
correlation time interval. addition, node AHMM
specific meaning (policy, state, policy termination status), links
clear causal interpretation based policy selection persistence model.
contrast Coupled/Factorial HMM nodes links usually
clear semantic/causal interpretation. advantage prior knowledge
temporal decomposition abstract process incorporated AHMM
naturally.
2.3 Sequential Importance Sampling (SIS)

Sequential Importance Sampling (SIS) (Doucet et al., 2000b; Liu & Chen, 1998), also
known Particle Filter (PF), general Monte-Carlo approximation scheme dynamic
stochastic models. principle, SIS method so-called Bayesian
Importance Sampling (BIS) estimator
R static case (Geweke, 1989). Suppose
want estimate quantity f = f (x)p(x)dx, i.e., mean f (x) x random
variable density p. Note f taken identity function event
f simply Pr(A). Let q(x) arbitrary2 density function, termed importance
distribution. Usually, importance distribution q chosen easy obtain
2. weight properly defined, support q subset support p.

456

fiPolicy recognition Abstract Hidden Markov Model
random samples it. expectation estimation rewritten as:
R [f (x)p(x)=q(x)]q(x)dx Eq f (x)p(x)=q(x)
f = R
[p(x)=q(x)]q(x)dx = Eq p(x)=q(x)
expression, BIS estimator w.r.t q obtained:
f f^BIS =

1

N

PNi=1 f (x(i))w_ (x(i) ) X
N
= f (x(i))w~(x(i) )
1 PN w_ (x(i) )
i=1
i=1

N

fx(i) g N i.i.d samplesPtaken q(x), w_ (x) = p(x)=q(x) w~
normalised weight w~(x(i) ) = w_ (x(i) )= w_ (x(i) ). Note normalised weight
computed weight function w(x) / w_ (x), i.e., weight function need
computed normalising constant factor. R
dynamic case, want estimate f = x~t f (~xt)p(~xt jo~t ) x~t = (x0 ; : : : ; xt )
o~t = (o0; : : : ; ot ) two sequences random variables; ot represents observation
available us time t. Often, (~xt ) Markov sequence ot observation xt
HMM. DBN, xt corresponds set state variables ot corresponds
set observations time-slice t. SIS method presented however applies
general case (~xt ) non-Markov, ot depends xt.
introduce importance distribution q(~xt jo~t ) obtain estimator:
f f^SIS

=

N
X
f (~
x(i) )w~ (~x(i) )
i=1





(1)

ensure obtain sample q(~xtjo~t ) \online", i.e., sample new value
xt sequence x~t current observation ot arrives, q must restricted
form:
q(~xt jo~t ) = q(~
xt 1 jo~t 1 )q(xt jx~t 1 ; o~t )
restriction q, use weight function w(~xt ) = p(~xt ; o~t )=q(~xt jo~t )
weight also updated \online" using:
w(~xt ) = w(~
xt 1 )p(xt ; ot jx~t 1 ; o~t 1 )=q(xt jx~t 1 ; o~t )
(2)
Let wt = w(~xt )=w(~xt 1 ) weight updating factor time t, qt = q(xt jx~t 1 ; o~t )
sampling distribution used time t. (2)
wt qt = p(xt ; ot jx~t 1 ; o~t 1 )
(3)
means p(xt ; ot jx~t 1 ; o~t 1 ) factorised two parts: wt qt . choosing different factorisations, obtain different forms qt thus different important
distributions q. example, (~xt ; o~t ) HMM, qt chosen p(xt jxt 1 )
wt = p(ot jxt ) likelihood weighting (LW) method, qt chosen
p(xt jxt 1 ; ot ) wt = p(ot jxt 1 ) likelihood weighting evidence reversal (LW-ER) (Kanazawa et al., 1995). general, \forward" qt chosen
p(xt jx~t 1 ; o~t 1 ) corresponding weight wt = p(ot jx~t ; o~t 1 ). \optimal" qt ,

457

fiBui, Venkatesh & West
sense discussed (Doucet et al., 2000b), chosen qt = p(xtjx~t 1 ; o~t )
associating wt = p(ot jx~t 1 ; o~t 1 ).
general SIS approximation scheme thus follows. time 1, maintain N
sample sequences fx~(ti)1 g N corresponding weight values fw(i) g. current
observation ot arrives, sequence x~(ti)1 lengthened new value x(ti) sampled
distribution q(xt jx~(ti)1 ; o~t ). weight value x~(ti) updated using (2).
new samples new weights obtained, expectation functional f
estimated using (1). procedure furthered enhanced re-sampling step
Markov-chain sampling step (see Doucet et al. (2000b), Doucet, de Freitas, Murphy,
Russell (2000a)). describe important improvements SIS here.3
2.4 Rao-Blackwellisation

Rao-Blackwellisation general technique improving accuracy sampling methods
analytically marginalising variables sampling remainder (Casella &
Robert, 1996). simplest form, consider problem estimating expectation
E f (x), x joint product two
P variables r; z. Using direct Monte-Carlo sampling, obtain estimator: f^ = N1 N1 f (r(i); z(i) ). Alternatively, Rao-Blackwellised
estimator derived sampling variable r, variable z
integrated analytically:
N
X
E f (r; z) = Er h(r) f^RB = N1 h(r(i) )

1

h(r) = Ez [f (r; z)jr]. convenience, r referred Rao-Blackwellising
variable.
Rao-Blackwellised estimator f^RB generally accurate f^
number samples N . direct consequence Rao-Blackwell theorem
gives relationship unconditional conditional variance:
VAR X = VAR[E[X jY ]] + E[VAR[X jY ]]
applying problem estimating E f (r; z), have:
VAR f (r; z) = VAR[E[f (r; z)jr]] + E[VAR[f (r; z)jr]]
thus VAR f (r; z) VAR[E[f (r; z)jr]] = VAR h(r). suggests direct MonteCarlo sampling, error RB-sampling (sample r marginalise z) always
smaller error sampling r z number samples, except
degenerated case. Bayesian Importance Sampling, using variance convergence
result (Geweke, 1989), one also easily prove number samples tend
infinity, RB-BIS would generally better BIS number samples.
3. Note improvements used orthogonal Rao-Blackwellisation procedure discussed
subsequently. implementation policy recognition algorithm later sections include
re-sampling step, crucial keeping error SIS time control.

458

fiPolicy recognition Abstract Hidden Markov Model
2.5 SIS Rao-Blackwellisation (RB-SIS)

Since SIS form BIS, Rao-Blackwellisation also used improve performance (Liu & Chen, 1998; Doucet
et al., 2000b). Let us consider problem
R

estimating expectation f = f (~xt)p(~xt jo~t ), variable xt joint product
two variables (zt ; rt ). shall restrict case x~t Markov
ot observation xt , i.e., (~
xt ; o~t ) represented DBN. addition,
consider f depends current variable xt , i.e., f expectation
filtering distribution p(xt jo~t ). example, \future" event, i.e., event
Rdepends fxt0 jt0 tg, estimate p(Ajo~t ) letting f (xt) = p(Ajxt )
f = xt p(Ajxt )p(xt jo~t ) = p(Ajo~t ).
R f (zt; rt)p(ztjr~t; o~t),
Applying Rao-Blackwellisation


setting,


let
h
(~
r
)
=

zt
R
f = h = r~t h(~rt )p(~rt jo~t ). Thus, use SIS estimate h , also obtain
estimator f:
N
f f^RBSIS = h^ SIS = X h(~rt(i) )w~(~rt(i) )
(4)
i=1

benefit increase accuracy estimator,
need sample variables r~t . side sample r~t , need
compute h(~rt ) using exact inference method. Furthermore, SIS procedure
estimate h might require additional complexity since sequence r~t generally nonMarkov, ot longer depends rt . Overall, comparison normal SIS
estimator f^SIS (Eq. 1), number samples N , f^RBSIS accurate
also computationally demanding compute.
see clearly involved implementing RB-SIS method, let us look
Rao-Blackwellised belief state, i.e., belief state dynamic process
Rao-Blackwellising variables observed: Rt = p(zt ; rt ; ot jr~t 1 ; o~t 1 ) posterior
Rt+ = p(zt jr~t ; o~t ). entities needed RB-SIS procedure computed
two distributions. Indeed, functional h rewritten terms Rt+ as:
h(~rt ) =

Z

zt

f (zt ; rt )p(zt jr~t ; o~t ) =

Z

zt

f (zt ; rt )Rt+ (zt )

addition, performing SIS estimate h , Eq. (3), weight
sampling distribution qt computed Rt :
wt qt = p(rt ; ot jr~t 1 ; o~t 1 ) = Rt (rt ; ot ) =

Z

zt

Rt (zt ; rt ; ot )

(5)
wt


(6)

Thus, computing RB belief state Rt posterior Rt+ essential step
RB-SIS method. Since maintain RB belief state sample
RB variables r~t, crucial done eciently using exact inference
method. xt composed many variables, case DBN, choice
Rao-Blackwellising variables Rao-Blackwellised belief state
maintained tractable way. Hence, Rao-Blackwellisation especially useful
set variables DBN split two parts conditioning first part
makes structure second part tractable amenable exact inference.

459

fiBui, Venkatesh & West
Begin
= 0; 1; : : :
sample = 1; : : : ; N
Sample rti Rti (rt jot )
Update weight w = w Rti (ot)
Compute posterior RB bel state Rti = Rti (ztjrti ; ot)
Compute new RB belief state Rti Rti
Compute h Rti
Compute estimator f^RBSIS = PNi h w~
End
( )

( )

( )

( )

( )

( )
+

( )

( )

( )
+1

( )
+

=1

( )

( )

( )
+

( )

Figure 1: RB-SIS general DBN
general RB-SIS algorithm given Fig. 1. illustrating purpose, assume
\optimal" qt corresponding wt used (qt = Rt (rt jot ) wt =
Rt (ot )). time point, need maintain N samples r~t(i) , = 1; : : : ; N .
sample, addition sample weight w(i) , also need store representation
RB belief state corresponding sample sequence: R(ti) = p(rt; zt ; ot jr~t(i)1 ; o~t 1 )
R(t+i) = p(zt jr~t(i) ; o~t ).
number applications RB-SIS method (also known Rao-Blackwellised
Particle Filter (RBPF)) discussed literature. general framework
using RB-SIS inference DBNs presented Doucet et al. (2000a), Murphy
(2000), Murphy Russell (2001). However, authors mainly focused
case sequence Rao-Blackwellising variables (~rt ) Markov (for example,
RB variables root nodes time slice). assumption simplifies
sampling step RB procedure since obtaining sample RB variable
time + 1 straightforward. previous work (Bui, Venkatesh, & West, 2000),
introduced hybrid-inference method AHMM special case statespace decomposition policy hierarchy, essentially RB-SIS method. Note
applied AHMMs, sequence Rao-Blackwellising variables use
satisfy Markov property. case, care must taken design ecient sampling
step, especially sampling distribution next RB variable
tractable form. use non-Markov RB variables also appears special models
Bayesian missing data model (Liu & Chen, 1998), partially observed
Gaussian state space model (Andrieu & Doucet, 2000) RB belief state
maintained Kalman filter.
Since make Rao-Blackwellised belief state tractable, context variables framework context-specific independence (Boutilier, Friedman, Goldszmidt,
& Koller, 1996) used conveniently Rao-Blackwellising variables (Murphy, 2000).
Indeed, since context variable acts mixing gate different Bayesian network structures, conditioning variables would simplify structure remaining vari-

460

fiPolicy recognition Abstract Hidden Markov Model
ables. property context variables, Boutilier et al. (1996) suggested
use cut-set variables cut-set conditioning inference method (Pearl,
1988). cut-set variables play similar role Rao-Blackwellising variables
help simplify structure remaining network. Rao-Blackwellised sampling, instead summing possible values cut-set variables
intractable, number representative sampled values used.
idea combining exact approximate inference RB sampling also
similar hybrid inference scheme described Dawid, Kjrulff, Lauritzen (1995),
however it's unclear RB sampling described using model communicating
belief universe. Also, Dawid et al. use hybrid inference mainly inference networks
mixture continuous discrete variables, opposed RB whose goal
improve sampling performance.
3. Abstract Markov Policies

section, formally introduce AMP concept originating literature
abstract probabilistic planning MDPs (Sutton et al., 1999; Parr & Russell, 1997;
Forestier & Varaiya, 1978; Hauskrecht et al., 1998; Dean & Lin, 1995). main motivation
abstract probabilistic planning scale MDP-based planning problems large
state space. noted hierarchical organisation policies help reduce
complexity MDP-based planning, similar role played plan hierarchy
classical planning (Sacerdoti, 1974). comparison classical plan hierarchy,
policy hierarchy model different sources uncertainty planning process
stochastic actions, uncertain action outcomes, stochastic environment dynamics.
work planning concerned finding optimal policy given
reward function, work focuses policy recognition inverse problem, i.e.,
infer agent's policies watching effects agent's actions. two problems
however share common element model stochastic plan hierarchy. policy
recognition, although possible derive information reward function
observing agent's behaviour, choose this, thus omitting model
reward function also optimality notion. leaves model open tracking
arbitrary agent's behaviours, regardless whether optimal not.
3.1 General Model
3.1.1 Actions Policies

MDP, world modelled set possible states , termed state space.
state s, agent set actions available, action a, employed,
cause world evolve next state s0 via transition probability (s; s0). agent's
plan actions modelled policy prescribes agent would choose action
state. policy , modelled selection function : ! [0; 1]
state s, (s; a) probability agent choose action a.
easy see that, given fixed policy P
, resulting state sequence Markov chain
0
transition probabilities Pr(s j s) = (s; a)a (s; s0). Thus, policy also
viewed Markov chain state space.

461

fiBui, Venkatesh & West
3.1.2 Local Policies

original MDP, behaviours modelled two levels: primitive action
level, plan level (policy). would like consider policies select
refined policies on, number abstraction levels. idea form
intermediate-level abstract policies policies defined local region state space,
certain terminating condition, invoked executed like primitive
actions (Forestier & Varaiya, 1978; Sutton et al., 1999).
Definition 1 (Local policy). local policy tuple = hS; D; fi; where:
set applicable states.
set destination states. fi : ! (0; 1] stopping probabilities
fi (d) = 1; 8 2 n .
: ! [0; 1] selection function. Given current state s, (s; a)
probability action selected policy state s.
set models local region policy applicable. called
set applicable states, since policy start state . shall assume
discrete, thus shall concerned technical details generalising
AHMM formulation continuous state space case. stopping condition
policy modelled set possible destination states set positive stopping
probabilities fi (d); 2 fi (d) probability policy terminate
current state d. possible allow policy stop state outside
, however, 2 n enforce condition fi (d) = 1, i.e., terminal
destination state. Sometimes, might want consider policies deterministic
stopping condition. case, every destination terminal destination: 8d 2 D,
fi (d) = 1. Thus, deterministically terminating policy, ignore redundant
parameter fi , need specify set destinations D.
Given starting state 2 , local policy defined generates Markov sequence states according transition model. time destination state 2
reached, process stops probability fi (d). Since process starts within ,
terminates one states D, destination states play role
possible exits local region state space.
want make clear policy currently referred to, shall use
subscripted notations , , fi , denote elements policy .
Fig. 2 illustrates local policy visualised. Fig. 2(a) shows set
applicable states , set destinations D, chain starting within terminating
D. Bayesian network Fig. 2(b) provides detailed view chain start
finish. Bayesian network Fig. 2(c) abstract view chain
interested starting stopping states.
3.1.3 Abstract Policies

local policy defined selects among set primitive actions. Similarly,
generally, define higher level policies select among set policies.

462

fiPolicy recognition Abstract Hidden Markov Model










0

1

2









(a)

(b)

(c)

Figure 2: Visualisation policy
Definition 2 (Abstract Policy).
Let set abstract policies. abstract
policy policies tuple hS ; ; fi ; where:
[2S set applicable states.
[2D set destination states. fi : ! (0; 1] set stopping
probabilities.
: ! [0; 1] selection function (s; ) probability
selects policy state s.
Note recursiveness definition 2 allows abstract policy select among set
abstract policies. base level, primitive actions viewed abstract policies
themselves. Since primitive actions always stop one time-step, Da Sa fi (d) =
1 8d 2 Da (Sutton et al., 1999). idea policies suitable stopping condition
viewed primitive actions first made explicit (Sutton, 1995),
also introduces fi model representing stopping probabilities. subsequent
work (Sutton et al., 1999) introduces abstract policy concept name options.
execution abstract policy follows. Starting state s,
selects policy 2 according distribution (s; :). selected policy
executed terminated state 2 . also destination state
(d 2 ), policy stops probability fi (d). still continues, new policy
0 2 selected d, executed termination (Fig. 3).
remarks representation abstract policy needed here. Let
2 [2 , denote subset policies applicable (s) =
f 2 j 2 g. abstract policy well-defined, make sure
state s, selects among policies applicable s. Thus,
selection function (s; ) > 0 2 (s). helps keep
specification selection function manageable size, even set
policies chosen large. addition, specification selection
function stopping probabilities make use factored representations (Boutilier,
Dearden, & Goldszmidt, 2000) case state space composite set
relatively independent variables. ensures still compact specification

463

fiBui, Venkatesh & West













Figure 3: chain generated abstract policy
probabilities conditioned state variable, even though state space
high dimension.
3.1.4 Policy Hierarchy

Using abstract policies building blocks, construct hierarchy abstract
policies follows:
Definition 3 (Policy hierarchy). policy hierarchy sequence H = (0 ; 1 ; : : : ; K )
K number levels hierarchy, 0 set primitive actions,
k = 1; : : : ; K , k set abstract policies policies k 1 .
top-level policy K executed, invokes sequence level-(K-1) policies,
invokes sequence level-(K-2) policies on. level-1 policy invoke
sequence primitive actions leads sequence states. Thus, execution
K generates overall state sequence (s0; s1 ; : : : ; st ; : : :) terminates one
destination states DK . K = 1 sequence simply Markov chain (with
suitable stopping conditions). However, K 2, generally non-Markovian,
despite fact policies Markov, i.e., select lower level policies
based solely current state (Sutton et al., 1999). knowing current
state st alone provide information current intermediate-level policies,
affect selection next state st+1. Intuitively, means agent's
behaviour achieve given goal usually non-Markovian, since choice actions
depends current state, also current intermediate intentions
agent.
term dynamical process executing top-level abstract policy K Abstract
Markov Model (AMM). states partially observable, observation
modelled usual observation model Pr(ot j st ) = !(st; ot ). resulting process
termed Abstract Hidden Markov Model (AHMM) since states hidden
Hidden Markov Model (Rabiner, 1989).
idea higher level policy controlling lower level ones MDP
traced back work Forestier Varaiya (1978), investigated two
layer structure similar 2-level policy hierarchy deterministic stopping condition.
Forestier Varaiya showed sub-process, obtained sub-sampling state

464

fiPolicy recognition Abstract Hidden Markov Model

(a)

(b)

Figure 4: environment partition
sequence time level-1 policy terminates, also Markov, thus policies
level 1 simply play role \extended" action. framework, given policy
hierarchy, one consider \lifted" model policies level k
observations time points policy level k ends considered. level-k
policies considered primitive actions, lifted model treated
like normal model.
3.2 State-Space Region-Based Decomposition

cases, state space dimensions already exhibit natural hierarchical
structure. example, spatial domain, set ground positions divided
small local spaces rooms, corridors, etc. set local spaces
grouped together form larger space higher level ( oors, buildings, etc).
intuitive often-used method constructing policy hierarchy case via
so-called region-based decomposition state space (Dean & Lin, 1995; Hauskrecht
et al., 1998). Here, state space successively partitioned sequence partitions
PK ; PK 1; :::P1 corresponding K levels abstraction, PK = fS g coarsest
partition, P1 finest. region Ri Pi, periphery Ri , P er(Ri)
defined set states Ri, connected state Ri. Let P eri
set peripheral states level i: P eri = [Ri2Pi P er(Ri ). Fig. 4(b) shows example
state space representing building partitioned 4 regions corresponding
4 rooms. peripheral states region shown Fig 4(a), Fig 4(b) shows
peripheral states.
construct policy hierarchy, first define region R1 2 P1 set abstract
policies applicable R1 , P er(R1) destination states. example,
room Fig 4, define set policies model agent's different behaviours
inside room, e.g., getting particular door. policies
initiated inside room, terminate agent steps room
(not necessarily target door since policy might fail achieve intended

465

fiBui, Venkatesh & West
target). Note since P er(R1 ) \ R1 = ;, policies defined manner
deterministic stopping conditions.
Let set policies defined 1. higher level P2 , region R2 ,
define set policies model agent's behaviours inside region
applicable state space R2 , destination set P er(R2 ), constraint policies
must use policies previously defined level-1 achieve goals. example
policy navigate room-doors get one building gate another. Let
set policies defined level 2. Continuing higher levels,
obtain policy hierarchy H = (0 ; 1 ; 2 ; : : : ; K ). policy hierarchy constructed
State-space Region-based Decomposition termed SRD policy hierarchy.
SRD policy hierarchy property set applicable states
policies given abstraction level forms partition state space. Thus, state
sequence (s0 ; : : : ; st ; : : :) resulting execution top level policy, infer
exact starting terminating times intermediate-level policies. example,
level k, starting/stopping times policies level time indices t's
state sequence crosses region boundary: st 1 2 Rk st 62 Rk
region Rk partition Pk . Later section 5.1, show property helps
simplify complexity policy recognition problem.
3.3 Policy Hierarchy Example

example, consider task monitor predict movement agent
building shown Fig. 5(a). room represented 5 5 grid, two adjacent
rooms connected via door center common edge. four entrances
building labeled north (N), west (W), south (S) east (E). addition, door
center building (C) acts like entrance building's north wing
south wing. state (cell), agent move 4 possible directions except
blocked wall.
policy hierarchy model agent's behaviour environment constructed based region-based decomposition three levels abstraction. Firstly, region
hierarchy constructed. partition environment consists 8 rooms level 1,
two wings (north south) level 2, entire building level 3. behaviours
agent level 1 (within room) represented set level 1 policies.
example, room, use 4 level-1 policies model agent's behaviours exiting
room via 4 different doors. essentially four Markov chains within room
terminate outside room. One way represent policies specify
movement action agent take given current position current heading.
higher level, agent's behaviours within wing specified. example,
use 3 level-2 policies wing model agent's behaviours exiting wing
via 3 wing exits. policies built top set level-1 policies already
defined. specify level-1 policies agent take leave wing
intended exit. Finally, top level, agent's behaviours within entire building
specified. example, use 4 top-level policies model agent's behaviours
leaving building via four building exits N, W, S, E. sample policies
parameters given Fig. 5(b).

466

fiPolicy recognition Abstract Hidden Markov Model
N
Level 1 Policy. (Destination right)

Level 2 Policy (current state: W, destination : C)
0.8

W


0.3

Go rightdoor (level 1 policy)

0.2

0.1
0.5

Right

E

Go backdoor (level 1 policy)
0.1


C
W

Rightdoor
Backdoor

Level 3 (current state: W, destination: E)



0.9

Prior toplevel policy

Go C (level 2 policy)
N: 0.25, S: 0.25, E: 0.25, W: 0.25

W
0.1

Go (level 2 policy)
(a) environment
(b) Parameters AHMM

Figure 5: example policy hierarchy
3.4 AMM Plan Execution Model

now, presented AMM formal plan execution model used later
plan recognition process. subsection, discuss expressiveness
AMM formal plan specification language, also suitability using AMM
encode plans context plan recognition. Note discussion focuses
representational aspect AMM alone. discussion computational aspects
AMM/AHMM comparison works probabilistic plan recognition
presented Section 7.
AMM particularly well-suited representing goal-directed behaviours different levels abstraction. policy AMM viewed plan trying
achieve particular goal. However, unlike classical plan, policy specifies course
actions applicable states, similar contingent plan. ending
policy could either means goal achieved, attempt achieve
goal using current policy failed. interpretation persistence policy
fits persistence model intentions (Cohen & Levesque, 1990): intention
ends, guarantee intended goal achieved. Thus, conceptually,
two types destination states: one corresponds intended goal states,
corresponds unintended failure states resulting stochastic nature
execution plan. Due generality, AMM need distinguish two types; successful termination states unsuccessful ones
treated possible destination states, albeit different reaching probabilities.4
4. One would expect agent would likely reach intended destination state rather
random failure state.

467

fiBui, Venkatesh & West
Using AMM model plan execution thus allows us blur difference
planning re-planning. time, moves recognition
classical plan towards recognition agent's intention. existing
framework probabilistic plan recognition explicitly represent current state,
thus, relationship states adoption termination current plans
ignored (Goldman et al., 1999).5 Thus, would impossible tell current plan
failed new plan attempt recover failure, current plan
succeeded new plan part new higher level goal.
expressive language describing abstract probabilistic plan Hierarchical
Abstract Machines (HAM) proposed (Parr & Russell, 1997; Parr, 1998). HAM,
abstract policy replaced stochastic finite automaton, call machines
lower level. abstract policies written machines type.
machine would choose one machines correspond policies lower level
go back start state called machines terminated. HAM
framework allows machines arbitrary finite number machine states transition
probabilities,6 thus readily represent complex plans concatenation
policies, alternative policy paths, etc. possible represent machine HAM
policy AMM, however cost augmenting state space include
machine states machines current call stack. Thus, size
AMM's new state space would exponential respect number nested levels
HAM's call stack. shows theory expressiveness HAM
policy hierarchy same, performing policy recognition HAM-equivalent policy
hierarchy probably unwise since state space becomes exponentially large
conversion. better idea would represent internal state machine
variable DBN perform inference DBN structure directly.
AMM also closely related model probabilistic plan recognition called
Probabilistic State-Dependent Grammar (PSDG), independently proposed (Pynadath,
1999; Pynadath & Wellman, 2000). PSDG described Probabilistic
Context Free Grammar (PCFG) (Jelinek, Lafferty, & Mercer, 1992), augmented
state space, state transition probability table terminal symbol PCFG.
addition, probability production rule made state dependent. result,
terminal symbol acts like primitive actions non-terminal symbol chooses
expansion depending current state. Interestingly, PSDG directly related
HAM language described above, similar way production-rule grammars related
finite automata. Given PSDG, convert equivalent HAM constructing
machine non-terminating symbol, modelling production rules
non-terminating symbol automaton.
policy hierarchy equivalent special class PSDG production
rules form X ! X X ! ; allowed. former rule models adoption
lower level policy higher level policy X , latter models termination
policy X . PSDG model considered (Pynadath, 1999; Pynadath & Wellman,
2000) allows general rules form X ! Y1 : : : YmX , i.e., recursion symbol
5. exceptions (Goldman et al., 1999; Pynadath & Wellman, 2000) discussed
detail Section 7.
6. constraint recursion calling stack keep stack finite.

468

fiPolicy recognition Abstract Hidden Markov Model
must located end expansion. Thus PSDG, policy might expanded
sequence policies lower level executed one another
control returned higher level policy. implicit assumption
policy sequence terminates, always state next policy
sequence applicable. Given assumption, language AHMM define
compound policy k policy simply orderly executes sequence policies
k 1 ; : : : ; k 1 , independent current state. PSDG equivalent
lower level (1)
(m)
AHMM compound policies form allowed.
Since AMM closely follows models used abstract probabilistic planning,
used model recognise behaviours autonomous agent whose decision
making process equivalent abstract MDP. also useful formal language
specifying contingent plans whose execution monitored using policy
recognition algorithm. language also rich enough specify range useful human
behaviours, especially domains natural hierarchical decomposition
state space. Section 6 presents application AHMM framework problem
recognising people behaviours complex spatial environment. Here, policy
AHMM represents evolution possible trajectories people movement
person performs certain task environment heading towards door, using
computer certain location, etc. policies different levels would represent
evolution trajectories different levels abstraction. Due existing hierarchy
domain, policies constructed using region-based decomposition
state space. environment populated multiple cameras divided different
zones provide current location tracking target, albeit noisy one.
noisy observations readily handled observation model AHMM.
policy recognition algorithm applied infer person's current policy
different levels hierarchy.
One main restriction current AHMM model consider one toplevel policy time, thus unable model inter-leaving concurrent plans.
Another subtle restriction assumption high level policy selects lower
level policies depending current state. state space interpreted
states external environment, assumption implies actor either full
observation current state, least refines intentions based actor's
observation current state (and entire observation history). Note
restrictions AHMM also apply case PSDG model.
4. Dynamic Bayesian Network Representation

section, describe Dynamic Bayesian Network (DBN) representation
AHMM. network serves two purposes: (1) tool derive probabilistic independence property stochastic model, (2) computational framework
policy recognition algorithms Section 5.
4.1 Network Construction

time t, let st represent current state, tk represent current policy level k
(k = 0; : : : ; K ), ekt represent ending status tk , i.e., boolean variable indicating

469

fiBui, Venkatesh & West
k

k

k

ek

ek

ek =F

e k-1

e k-1 =T

ek-1 =F




(a)


(b)

(c)

Figure 6: Sub-network policy termination
whether policy tk terminates current time. variables would make
current time-slice full DBN. convenience, notation tall refers set
current policies ftK ; : : : ; t0 g. presenting full network, first describe
two sub-structures model policies terminated selected. full DBN
easily constructed sub-structures.
4.1.1 Policy Termination

definition abstract policies, level-k policy tk terminates lower level
policy tk 1 terminates, so, tk terminates probability fitk (st). Bayesian
network representation, terminating status ekt therefore three parent nodes: tk , st ,
etk 1 (Fig. 6(a)).
parent variable ekt 1 however plays special role. ekt 1 = , meaning lower
level policy terminates current time, Pr(ekt = j tk ; st) = fitk (st) gives
conditional probability ekt given two parent variables (Fig. 6(b)). However,
ekt 1 = F , tk terminate ekt = F . Therefore, given ekt 1 = F , ekt
deterministically determined independent two parent variables tk
st . Using notion context-specific independence (CSI) (Boutilier et al., 1996),
safely remove links two parents ekt context ekt 1
false (Fig. 6(c)).
bottom level, since primitive action always terminates immediately, e0t =
t. Since modelling execution single top-level policy K , assume
top-level policy terminate remains unchanged: eKt = F tK = K
t. Also, note elt = ) ekt = k l, elt = F ) ekt = F k l.
Thus, time t, exists 0 lt < K ekt = k lt , ekt = F
k > lt . variable lt termed highest level termination time t. Knowing
value lt equivalent knowing terminating status current policies.
4.1.2 Policy Selection

current policy tk general dependent higher level policy tk+1, previous
state st 1 , previous policy level tk 1 ending status ekt 1 .
Bayesian network, tk thus four variables parents (Fig. 7(a)). depen-

470

fiPolicy recognition Abstract Hidden Markov Model
k+1
k

prev

k

k

eprev

k+1
k

prev

k

(a)

k
prev

ek = F

ek =T

sprev

sprev

prev

sprev

k+1


k

prev

(b)

(c)

Figure 7: Sub-network policy selection
dency broken two cases, depending value parent
node ekt 1 .
previous policy terminated (ekt 1 = F ), current policy
previous one: tk = tk 1 , variable tk thus independent tk+1 st 1 .
Therefore, context ekt 1 = F , two links tk+1 st 1 current policy
removed, two nodes tk tk 1 merged together (Fig. 7(b)).
previous policy terminated (ekt 1 = ), current policy selected
higher level policy probability Pr(tk j tk+1; st 1 ) = tk+1 (st 1 ; tk ). context, tk
independent tk 1 corresponding link Bayesian network removed
(Fig. 7(c)).
4.1.3 Full DBN

full dynamic Bayesian network constructed policy, ending status,
state variables putting sub-networks policy termination selection together
(Fig. 8). top level, since eKt = F , remove ending status nodes merge
tK single node K . base level, since e0t = , remove ending
status nodes also links t0 t0+1. model observation hidden
states, observation layer attached state layer shown Fig. 8.
Suppose given context variable ekt known.
modify full DBN using corresponding link removal node merging rules.
result intuitive tree-shaped network Fig. 9, policy nodes
corresponding policy entire duration grouped one. grouping
done since knowing value ekt equivalent knowing exact duration
policy hierarchy. One would expect performing probabilistic inference
structure simple full DBN Fig. 8. particular,
state sequence known, remainder network Fig. 9 becomes singly-connected,
i.e., directed graph undirected cycles, allowing inference performed
complexity linear size network (Pearl, 1988). policy recognition algorithms
follow later exploit extensively particular tractable case AHMM.

471

fiBui, Venkatesh & West

K

Level K

Policy

2

Stop status

e2

Policy

1

Stop status

e1

Action

0

State

Observation

Figure 8: DBN representation Abstract Hidden Markov Model

4

3

...

2

...

1


...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

Figure 9: Simplified network duration policy known (action nodes
omitted clarity)

472

fiPolicy recognition Abstract Hidden Markov Model
4.2 Conditional Independence Current Time-Slice

discussion identifies tractable case AHMM, requires knowledge
entire history state policy ending status variables. subsection,
focus conditional independence property nodes current time-slice:
st ; t0 ; : : : ; tK . Since nodes make belief state future inference
algorithm AHMM, independence properties among variables, exploited,
provide compact representation belief state reduce inference
complexity.
Due way policies invoked AMM, make intuitive remark
higher level policies uence happens lower level
current level. precisely, level k policy tk , know starting state, course
execution fully determined, determined means without uence
happening higher levels. Furthermore, also know long
policy executed, equivalently starting time, current state execution
also determined. Thus, higher level policies uence current state
execution tk either starting state starting time. words, know
tk together starting time starting state, current higher level policies
completely independent current lower level policies current state.
theorem 1 formally states precise form. Note condition obtained
strictest: one three conditional variables unknown, examples
AMMs higher level policies uence lower level ones.
Theorem 1. Let tk bkt two random variables representing starting time

starting state, respectively, current level-k policy tk : tk = maxft0 < j ekt0 = g
bkt = stk . Let t>k = ftk+1 ; : : : ; tK g denote set current policies level k + 1
K, t<k = fst ; t0 ; : : : ; tk 1 g denote set current policies level k 1
0 together current state. have:
t>k ? t<k j tk ; bkt ; tk

(7)

Proof. sketch intuitive proof theorem use Bayesian
network manipulation rules context-specific independence discussed
4.1.1 4.1.2. alternative proof use CSI found (Bui et al.,
2000).
first note theorem obvious looking full DBN Fig. 8.
Therefore, shall proceed modifying network structure context
know tk .
time tk , policies level k must terminate: eltk = l k.
Thus remove links policies new policies time tk + 1.
hand, time tk + 1 current time t, policies level k
must terminate: elt0 = F l k, tk + 1 t0 < t. Thus group
policies level l k time tk + 1 one node representing current
policy level l.
two network manipulation steps result network structure shown
Fig. 10. modified network structure obtained, observe t>k

473

fiBui, Venkatesh & West

k+1



k



k-1


...

...

k

...

State

bt

st

Time

k




...

Figure 10: Network structure conditioned tk
d-separated tk bkt new structure. Thus t>k t<k independent
given tk , bkt tk .
t<k

5. Policy Recognition

section begin address problem policy recognition framework
AHMM. assume policy hierarchy given modelled AHMM,
however top level policy details execution unknown. problem
determine top level policy current policies lower levels given
current sequence observations. concrete terms, interested
conditional probability:
Pr(tK ; : : : ; t0 j o~t 1 )
especially, marginals:
Pr(tk j o~t 1 ); levels k
Computing probabilities gives us information current policies
levels abstraction, current action (k = 0), top-level policy (k = K ),
taking account observations date.
typical monitoring situations, probabilities need computed \online",
new observation becomes available. this, required update belief
state (filtering distribution) AHMM time point t. problem generally
intractable unless belief state ecient representation affords closed form
update procedure. case, belief state joint distribution K + 3 discrete
variables: Pr(tK ; : : : ; t0 ; st ; lt j o~t ). Without structure imposed belief
state, complexity updating exponential K .
cope complexity, one generally resort form approximation
trade accuracy computational resources. hand, analysis

474

fiPolicy recognition Abstract Hidden Markov Model
AHMM network previous section suggests problem inference AHMM
tractable special case history state terminating status
variables known. Motivated property AHMM, main aim section
derive hybrid inference scheme combines approximation tractable
exact inference eciency. first treat special case policy recognition
belief state AHMM tractable structure 5.1. present hybrid
inference scheme general case using Rao-Blackwellised Sequential Importance
Sampling (RB-SIS) method 5.2.
5.1 Policy Recognition: Tractable Case

Here, address policy recognition problem two assumptions: (1) state
sequence observed certainty, (2) exact time policy starts
ends known. precisely, observation time includes state history
s~t = (s0 ; : : : ; st ) policy termination history ~lt = (l0 ; : : : ; lt ). belief state
need compute case Bt = Pr(tall ; st ; lt j s~t 1 ; ~lt 1 ) posterior
absorbing observation time t: Bt+ = Pr(tall j s~t ; ~lt ).
first assumption means observer always knows true current state
often referred \full observability". states fully observable, ignore
observation layer fot g AHMM thus deal AMM instead.
second assumption means observer fully aware current policy
ends new policy begins. policy hierarchy constructed region-based
decomposition state space (subsection 3.2), termination status inferred
directly state sequence. Thus SRD policy hierarchies, full observability
condition needed since second assumption subsumed first left
out. Except SRD policy hierarchies, two assumptions usually restrictive
policy recognition algorithm presented useful itself. However,
algorithm special case form exact step hybrid algorithm presented
subsection 5.2 general case.
5.1.1 Representation belief state

first look conditional joint distribution Pr(tall ; st j s~t 1; ~lt 1 ). termination history ~lt 1 , derive precisely starting time current level-k policy:
tk

= maxf0g [ ft0 < tj ekt0 = g = maxf0g [ ft0 < tj lt0 kg

hand, knowing starting time together state history also gives
us starting state bkt . Thus, starting time starting state tk
derived s~t 1 ~lt 1 . Theorem 1, obtain level k:
t>k ? t<k j tk ; s~t 1 ; ~lt 1
words, given s~t 1 ~lt 1 , conditional joint distribution ftK ; : : : ; t0 ; st g
represented Bayesian network simple chain structure. denote
chain network Ct Pr(tall ; st j s~t 1 ; ~lt 1 ) term belief chain role plays
representation belief state (Fig. 11(a)). chain drawn links

475

fiBui, Venkatesh & West

K

Bt

Ct



k+1
root

K

e

K

e

k+1

k+1



k



k



k-1

ek
k-1

e k-1
1



1



0

e1

0




(a)

(b)

Figure 11: Representation belief state
point away level-k node, say chain root level k. root
chain moved k another level k0 simply reversing links lying
k k0 using standard link-reversal operation Bayesian networks (Shachter, 1986).
node belief chain also manageable size. principle, domain
tk k , set policies level k, domain st , set possible
states. K large, basically want model larger state space, set
policies cover state space also large. sizes domains would
likely grow exponential w.r.t. K . However, given particular state, number policies
applicable state would remain relatively constant independent K .
policy tk , know starting state bkt , implies tk 2 k (bkt ), set
level-k policies applicable bkt . Thus k (bkt ) used \local" domain tk
avoid exponential dependency K . Similarly, domain st taken
set neighbouring states st 1 (reachable st 1 performing one primitive
action). given state, term maximum number relevant objects (applicable
policies/actions, neighbouring states) single level degree connectivity N
domain modelled. size conditional probability table link
belief chain O(N 2), overall size belief chain O(K N 2 ).
construct belief state Bt Ct. Since current terminating status
solely determined current policies current state, belief state Bt
factorised into:
Pr(tall ; st ; lt j s~t 1 ; ~lt 1 ) = Pr(lt j tall ; st ) Pr(tall ; st j s~t 1 ; ~lt 1 ) = Pr(lt j tall ; st)Ct
Note variable lt equivalent set variables feKt ; : : : ; e1t g. Thus, full
belief state Bt realised adding Ct links current policies
current state terminating status variables ekt (Fig. 11(b)). size belief state

476

fiPolicy recognition Abstract Hidden Markov Model


K


e

K

k+1

K

e

k+1


e

k+1

k



k



k-1

ek


e
k+1




K

ek

k-1

e k-1


1



0

e1
(a)

(b)

Figure 12: Belief state updating: Bt Bt+
would still O(K N 2 ). state composite many orthogonal variables, factored
representation used size belief state representation depend
exponentially dimensionality state space. discuss factored representations
subsection 5.2.2.
5.1.2 Updating belief state

Since belief state Bt represented simple belief network Fig. 11(b),
expect general exact inference method updating belief state (Kjrulff,
1995) work eciently. However, general method works undirected network
representation belief state distribution inconvenient us later
want sample distribution. Here, describe algorithm updates
belief state closed form given directed network Fig. 11(b).
Assuming complete specification belief state Bt , i.e., parameters Bayesian network representation, need compute parameters
new network Bt+1 . done two steps, standard \roll-over" belief
state DBN: (1) absorbing new evidence st , lt (2) projecting belief state
next time step.
first step corresponds instantiation variables st , e1t ; : : : ; eKt
Bayesian network Bt obtain Bt+ conditional joint distribution tK ; : : : ; t0 .
checking conditional independence relationships Fig. 11(b), easy see
Bt+ simple chain network structure. Thus, conceptually, problem
update parameters chain Ct absorb given evidence form new
chain Bt+. done number link-reversal steps follows.
instantiate st, first move root chain Ct st. variable st
parents instantiated deleted network (Fig. 12(a)).
instantiate lt equivalent value assignment (eKt = F; : : : ; eltt +1 = F; eltt =
T; : : : e1t = ), starting k = 1, iteratively reverse links tk 1 tk
tk ekt (Fig. 12(b)). algebraic forms, first link reversal operation corresponds

477

fiBui, Venkatesh & West
computing following probabilities:
Pr(tk j st; e1t ; : : : ; ekt 1 ) =
Pr(tk 1 j tk ; st; e1t ; : : : ; ekt 1 ) /

X Pr(k j k 1) Pr(k 1 j ; e1; : : : ; ek 1)










tk 1
Pr(tk j tk 1) Pr(tk 1 j st ; e1t ; : : : ; ekt 1)



(8)
(9)

second link reversal corresponds to:
Pr(tk j st ; e1t ; : : : ; ekt ) / Pr(ekt j tk ; st; ekt 1 ) Pr(tk j st ; e1t ; : : : ; ekt 1)
(10)
Effectively, k-th link reversal step positions root chain Ct tk absorbs
evidence ekt . repeating link reversal operations k = 1; : : : ; lt + 1, obtain
new chain Bt+ root level lt +1. Note need incorporate
instantiations ekt = F k > lt + 1 since direct consequences
instantiation eltt+1 = F . parameters chain Bt+ given below. upward
links remain Ct , marginal level lt + 1 downward
links obtained results link reversal operations above:
Pr(tk+1 j tk ; st ; lt ) = Pr(tk+1 j tk ); k lt + 1
Pr(tk j st ; lt ) = Pr(tk j st; e1t ; : : : ; ekt ); k = lt + 1
Pr(tk 1 j tk ; st ; lt ) = Pr(tk 1 j tk ; st ; e1t ; : : : ; ekt 1 ); k lt
second step, continue compute Ct+1 Bt+. Since policies
levels higher lt terminate, t>l+1t = t>lt , retain upper sub-chain
Bt+ Ct+1 . lower part, k lt, new policy tk+1 created policy
+1 state st , thus new sub-chain formed among variables <lt
tk+1
t+1
+1 ; st ) = k+1 (st ; k ). Note domain newly-created
parameters Pr(tk+1 j tk+1
t+1
t+1
k
k
node t+1 (st ). new chain Ct+1 combination two sub-chains,
chain root level lt + 1 (see Fig. 13). chain Ct+1 ,
new belief state Bt+1 obtained simply adding terminating status variables
fekt+1 g Ct+1 .
completes procedure updating belief state Bt Bt+1 , thus allowing
us compute belief state Bt time step. Although belief state joint
distribution current variables, due simple structure, marginal distribution
single variable computed easily. example, interested
current level-k policy tk , marginal probability Pr(tk j s~t 1 ; ~lt 1 ) simply marginal
level-k node chain Ct, readily obtained chain parameters.
complexity belief state updating procedure time proportional lt
since needs modify bottom lt levels belief state. hand,
probability current policy level l terminates assumed exponentially
P
small w.r.t. l. Thus, average updating complexity time-step O( l l=exp(l))
constant-bounded, thus depend number levels policy
hierarchy. terms number policies states, updating complexity linear
size policy node belief chain, thus linear degree connectivity
domain.

478

fiPolicy recognition Abstract Hidden Markov Model

Kt

l +1


Ct+1
l

l

t+1



Bt+
1t
0

0

t+1





st

t+1

Figure 13: Belief state updating: Bt+ Ct+1
5.2 Policy Recognition: General Case

return general case policy recognition, i.e., without two assumptions
previous subsection. makes inference tasks AHMM much dicult.
Since neither starting times starting states current policies known
certainty, theorem 1 cannot used. Thus, set current policies longer forms
chain structure Ct since conditional independence properties current
time-slice longer hold. therefore cannot hope represent belief state simple
structure previously. exact method updating belief state thus
operate structure size exponential K , bound intractable
K large.
cope complexity, approximation scheme sequential importance
sampling (SIS) (Doucet et al., 2000b; Liu & Chen, 1998; Kanazawa et al., 1995)
employed. previous work (Bui, Venkatesh, & West, 1999), applied SIS
method known likelihood weighting evidence reversal (LW-ER) (Kanazawa et al.,
1995) AHMM-like network structure. However SIS method needs sample
product space layers AHMM thus becomes less accurate inecient
large K . key get around ineciency utilise special structure
AHMM, particularly, special tractable case, keep set variables need
sampled minimum.
improvement SIS method achieve presented subsection 2.5 name Rao-Blackwellised SIS (RB-SIS) method. Rao-Blackwellisation
specifically allows marginalisation variables analytically samples
remaining variables. result, reduces averaged error, measured variance
estimator (Casella & Robert, 1996).

479

fiBui, Venkatesh & West
order apply RB-SIS AHMM, main problem identify variables used Rao-Blackwellising variables still sampled,
remaining variables marginalised analytically. key choosing RaoBlackwellising variables, shown 2.5, variables observed,
Rao-Blackwellised belief state becomes tractable. subsection 5.1, demonstrated state history s~t terminating status history ~lt observed
belief state simple network structure updated constant average complexity. Thus, (st ; lt ) used conveniently Rao-Blackwellising variable
rt . Note variables ~lt context variables help simplify network
structure AHMM, state variables s~t help make remaining network
singly-connected exact inference operate eciently (see subsection 4.1.3).
5.2.1 RB-SIS AHMM

discuss specific application RB-SIS problem belief state updating
policy recognition AHMM. main objective use RB-SIS estimate
conditional probability policy currently executed level-k given current
sequence observations Pr(tk+1 j o~t ).
Mapping RB-SIS general framework subsection 2.5 AHMM structure,
set current variables xt set current policies, terminating status nodes,
current state: xt = (tall ; st; lt ). probability estimation Pr(tk+1 j o~t )
viewed expectation letting f (tall ; st; lt ) = Pr(tk+1 jtall ; st ; lt ) that:
X Pr(k jall ; ; l ) Pr(all ; ; l jo~ ) = Pr(k j o~ )
f =


t+1

t+1
tall ;st ;lt

Using RB-SIS estimate expectation, shall split xt two sets variables:
set RB variables rt = (st; lt ), set remaining variables zt = tall
set current policies. functional h, depends RB variables
obtained f integrating remaining variables (Eq. (5)),
form:
X Pr(k j ; ; l ) Pr(all j s~ ; ~l ; o~ ) = Pr(k j s~ ; ~l ) (11)
h(~rt ) = h(~st ; ~lt ) =


t+1

t+1
tall

marginal Ct+1 (tk+1 ) belief chain time + 1.
RB belief state, belief state AHMM RB variables
known, becomes:
Rt = Pr(tall ; st; lt ; ot j s~t 1 ; ~lt 1 ; o~t 1 ) = Pr(tall ; st ; lt ; ot j s~t 1 ; ~lt 1 )
(12)
identical special belief state Bt discussed subsection 5.1, except minor
modification attach observation variable ot .
(11) (12), h function RB belief state computed
eciently using exact inference techniques described 5.1. Thus RB-SIS
implemented eciently minimal overhead exact inference.
main RB-SIS algorithm AHMM given Fig. 14. Note need
sample RB variables s~t ~lt . sample i, addition weights w(i) ,

480

fiPolicy recognition Abstract Hidden Markov Model
Begin
= 0; 1; : : :
sample = 1; : : : ; N
Sample sti ; lti Bti (st; ltj ot )
Update weight w = w Bti (ot )
Compute posterior RB bel state Bti = Bti (tall jsti ; lti ; ot)
Compute belief chain Ct Bti
Compute new belief state Bti Ct
Compute h = Ct (tk )
Compute estimator Pr(tk j o~t) f^RBSIS = PNi h w~
End
( )

( )

( )

( )

( )

( )

( )
+1

( )

( )
+1

( )
+1

( )
+
( )
+

( )

( )

( )

( )
+1

+1

+1

=1

( )

( )

Figure 14: RB-SIS policy recognition
B er



K

e

K

e

k+1

k+1




k



k1

ek = F
e k1 =


1



0

highest level
termination lt

e1




Figure 15: Sampling Rao-Blackwellising variables AHMM
also maintain parametric representation Rao-Blackwellised belief state Bt(i),
value h function sample h(i) . weights samples, together
values h function combined yield approximation f.
details obtain new samples time step worth noting
here. Since using optimal sampling distribution qt = Bt(st ; lt j ot ) sample

481

fiBui, Venkatesh & West
RB variables st lt , need perform evidence reversal step.7 done
positioning root belief chain Ct st reverse link st ot .
gives us network structure Bter = Bt (st; lt ; tall j ot ) exactly Bt
(see Fig. 15), except evidence ot absorbed marginal distribution
st. weight wt = Bt(ot ) also obtained by-product evidence reversal
step. order sample st lt Bter without need compute marginal
distribution two variables, use forward sampling sample every variable
Bter , starting root node st proceeding upward. Since lt definition
highest level policy termination, sampling stop first level k ekt = F .
assign lt value k 1. unnecessary samples policy nodes along
way discarded. new samples st lt , updating
RB belief state Bt Bt+1 identical belief state updating procedure described
5.1. h function obtained computing corresponding marginal
new belief chain Ct+1.
time step, complexity maintaining sample (sampling new RB
variables updating RB belief state) O(lt ), thus, average, bounded
constant. overall complexity maintaining every sample thus O(N ) average.
prediction needed, sample, compute h manipulating chain
Ct+1 complexity O(K ). Thus complexity time step prediction
needs made O(NK ).
comparison use SIS method LW-ER, RB-SIS
order computational complexity (the SIS also complexity O(NK )). However,
SIS method needs sample every layers AHMM, RB-SIS method
needs sample two sequences variables s~t, ~lt , avoids sample K policy
sequences f~tk g. Rao-Blackwellisation, dimension sample space becomes
much smaller, importantly, grow K . result, accuracy
approximation RB-SIS method depend height hierarchy
K . contrast, due problems sampling high dimensional space, accuracy
SIS methods tends degrade, especially K large.
5.2.2 Performing Evidence Reversal Factored State Space

many cases, state space Cartesian product many state variables representing relatively independent properties state: st = (s1t ; s2t ; : : : ; sM
). Since overall
state space large, specifying action usual transition probability matrix
problematic. advantageous case represent state information factored
form, i.e., representing state variable smt separate node rather lumping
single node st. shown using factored representations, specify
transition probability action compact form since action likely affect
small number state variables specification effects actions
many regularities (Boutilier et al., 2000).
7. term evidence reversal used paper refer general procedure link
observation node reversed prior sampling (Kanazawa et al., 1995), thus allowing us sample
according optimal sampling distribution qt .

482

fiPolicy recognition Abstract Hidden Markov Model
representation belief chain Ct also RB belief state Bt take direct
advantage factored representation actions. Indeed, chain parameter Ct(st jt0 )
link t0 st precisely transition probability action t0
previous state st 1 (note st 1 known due Rao-Blackwellisation). conditional
distribution extracted compact factored representation t0 general
form Bayesian network variables fs1t ; s2t ; : : : ; sM
g. convenience, let us
denote Bayesian network F (:jt0 ). network usually sparse enough exact inference operate eciently. example, special case fs1t ; s2t ; : : : ; sMt g
independent given t0 st 1 , F factored completely product
marginals smt .
Although factored representations used part RB belief state, care must
taken performing evidence reversal, i.e. reverse link state variable
observation node. procedure evidence reversal discussed previously (see
Fig. 15), first position root Ct node st, thus need compute represent
distribution Pr(st). factored state space case, becomes joint distribution
0
state variables fs1t ; s2t ; : : : ; sM
g. Without conditioning current action ,

factored representation state variables fst g cannot utilised, thus resulting
complexity exponential .
key get around diculty always keep specification distribution
current state conditioned current action, vice versa. Thus, computing
Bter = Bt (:jot ), first position root chain Ct t0, reverse evidence
ot t0 st . algebraic form, use following factorisation joint
distribution current action state given current observation:
Pr(t0 ; st jot ) = Pr(stjt0 ; ot ) Pr(t0 jot )
(13)
Fig. 16 illustrates evidence reversal procedure. model depicted here, F
arbitrary Bayesian network. observation model specified attaching
observation nodes fo1t ; o2t ; : : :g state variables. overall network representing
distribution Pr(st ; ot j t0 ) denoted F obs(:jt0 ).
first look first term RHS (13). Let F er (:jt0 ; ot ) represent
distribution Pr(st j t0 ; ot ). Note F er obtained conditioning F obs(:jt0 )
observation ot . achieved applying exact inference method
clustering algorithm (Lauritzen & Spiegelhalter, 1988) network F obs(:jt0 ).
second term RHS (13), note that:
Pr(ot j t0 ) =

X Pr(s ; j 0) = X F obs(s ; j0)
st







st







integration readily obtained by-product performing clustering algorithm F obs(:jt0 ). Pr(ot j t0 ) known, compute Pr(t0 j ot ) by:
Pr(t0 j ot ) / Pr(ot j t0 ) Pr(t0 )
shows belief state evidence reversal Bter = Bt (:j ot ) still simple
structure exploits independence relationships state variables fsmt g
given current action t0. Sampling RB variables structure proceed

483

fiBui, Venkatesh & West



0



F
3t . .
.

2

st

F

0

obs

3t

2

st

1

F er
.
. .

1

st

st

2

1

o3t

...
4t
2

ot

1

ot

o3t

.. .
4t

ot

ot

Belief state evidence reversal

Belief state evidence reversal

Figure 16: Evidence reversal factored state space
follows: Pr(t0 j ot ) first used sample t0; F er (stjt0 ; ot ) used sample st.
obtained sample t0 st , proceed sample remaining nodes
network Bter obtain sample lt usual. Finally, note weight
wt = Pr(ot ) also computed eciently by:
Pr(ot ) =

X Pr(o j 0) Pr(0)


t0





evidence reversal procedure, value t0 , need perform exact
inference structure F obs (st; ot jt0 ). Thus complexity procedure heavily
depends complexity network structure F . However, noted,
due nature factored representation, F usually sparse structure
exact inference performed eciently. example, special case F
completely factored product independent state variables
independently observed, complexity becomes linear w.r.t. .
6. Experimental Results

section, present experimental results policy recognition algorithm.
subsection 6.1, demonstrate effectiveness Rao-Blackwellised sampling method
policy recognition comparing performance Rao-Blackwellised procedure
likelihood weighting sampling synthetic tracking task. subsection 6.2,
present application AHMM framework problem tracking human behaviours complex spatial environment using distributed video surveillance data.

484

fiPolicy recognition Abstract Hidden Markov Model
N
Rm 6

Rm 5

North Wing
25
Rm 4

36
50

Rm 7

62 E

16
Rm 0

W

7
Rm 3
Rm 1

Rm 2

South Wing



Figure 17: environment sample trajectory
Destination probabilities
1
west
south
east
north

Probability

0.8

0.6

0.4

0.2

0
0

5

10

15

20

25

30 35
Time

40

45

50

55

60

Figure 18: Probabilities top-level destinations time
6.1 Effectiveness Rao-Blackwellisation

demonstrate effectiveness Rao-Blackwellised inference method AHMM,
consider synthetic tracking task required monitor predict
movement agent building environment previously discussed subsection 3.3. structure AHMM used one shown Fig. 5.
parameters policies chosen manually, used simulate movement
agent building. simulate observation noise, assume observation agent's true position anywhere among 8 neighbouring cells
probabilities given predefined observation model.

485

fiBui, Venkatesh & West

0.3
SIS
0.26/sqrt(x)
RB-SIS
0.055/sqrt(x)

std. deviation

0.25
0.2
0.15
0.1
0.05
0
10

20
30
40
Sample size (in 1000)

50

CPU Time (in second)

(a) Sample size average error
7
6.5
6
5.5
5
4.5
4
3.5
3
2.5
2
1.5
1
0.5
0

SIS
0.035*x
RB-SIS
0.08*x

10

20
30
40
Sample size (in 1000)

50

(b) Sample size CPU time
0.25
SIS
RB-SIS

std. deviation

0.2

0.15

0.1

0.05

0
0

0.2

0.4

0.6
0.8
1
1.2
CPU time (in second)

1.4

1.6

(c) CPU time average error
Figure 19: Performance profiles SIS vs. RB-SIS

486

fiPolicy recognition Abstract Hidden Markov Model

0.003
SIS
0.00179375
RB-SIS
0.000235286

Efficiency coefficient

0.0025
0.002
0.0015
0.001
0.0005
0
0

5

10

15 20 25 30 35
Sample size (in 1000)

40

45

50

Figure 20: Eciency coecients SIS RB-SIS
implement RB-SIS method (with re-sampling) use policy hierarchy
specification simulated observation sequence input algorithm. typical
run, algorithm return probability main building exit, next wing exit,
next room-door agent currently heading to. example track shown
Fig. 17. observations track arrive time, prediction probability
distribution main building exit track heading shown Fig. 18.
illustrate advantage RB-SIS, also implement SIS method without RaoBlackwellisation (LW ER re-sampling (Kanazawa et al., 1995)) compare
performance two algorithms. run two algorithms using different sample population sizes obtain performance profiles. given sample size N , standard
deviation ((N )) 50 runs estimated probabilities top-level policies used
measure expected error probability estimates. also record average
time taken update iteration.
Fig. 19(a) plots standard deviation two algorithms different
p sample sizes.
behaviour error follows closely theoretical curve (N ) = c= N , 2(N ) =
c2 =N , cSIS 0:26 cRB SIS 0:055. expected, number samples,
RB-SIS algorithm delivers much better accuracy.
Fig. 19(b) plots average CPU time (T ) taken iteration versus sample
size. expected, (N ) linear N , RB-SIS taking twice longer due
overhead updating RB belief state processing sample.
Fig. 19(c) plots actual CPU time taken versus expected error two algorithms. shows CPU time spent, RB-SIS method still significantly
reduces error probability estimates.
Note algorithm, quantity = 2 (N )T (N ) approximately constant
since dependency N cancels one another out. Thus, constant used
eciency coecient measure performance sampling algorithm independent
number samples. example, algorithm twice smaller coecient,
deliver accuracy half CPU time, half variance CPU time.
Fig. 20 plots eciency coecients SIS RB-SIS, SIS 0:0018

487

fiBui, Venkatesh & West
RB SIS 0:000235. indicates performance gain almost order magnitude
(8 folds) RB-SIS.

6.2 Application Tracking Human Behaviours

Using policy recognition algorithm, implemented real-time surveillance system
tracks behaviour people complex indoor environment using surveillance video
data. environment consists corridor, Vision lab two oces (see Fig. 21).
People enter/exit scene via left right entrance corridor. system
six static cameras overlapping field views cover ground plane
scene.
entire environment divided grid cells, current cell position
tracked object acts like current state AHMM. cameras calibrated
return current position tracked object ground, however
returned coordinates unreliable cameras deal noisy video frames
occlusion objects scene. information low-level tracking done
multiple cameras, readers referred (Nguyen, Venkatesh, West, & Bui, 2002).
assume observation state area surrounding it, thus
observation model matrix specifying observation likelihood cell within
neighbourhood current state.
policy hierarchy behaviours environment constructed follows. First,
construct region hierarchy three levels. bottom level, identify 7
regions special interest: corridor, two oces, areas surrounding Linux
server, NT server, printer, remaining free space Vision lab (Fig. 21).
higher level, regions Vision lab grouped together. top level consists
entire environment. policy hierarchy representing people's behaviors three levels
corresponding three levels region hierarchy (see Fig. 23). bottom level,
interested behaviours take place within 7 regions interest.
example, near Linux server, person might using Linux machine, simply
passing region, leading two different policies. Similar policies defined
NT server region, printer region, two small oces. corridor
inside Vision lab (region 1 5), construct different policies corresponding
different destinations person heading to. Region 5 also special policy
representing \walk-around" behaviour. middle level, three policies defined
corridor oce space representing person's plan exiting space
left/right entrance door Vision lab. define one policy Vision
lab represent typical behaviour lab user (e.g., go Linux server, followed
go printer).8 Finally, top level region (the whole environment), define two
policies representing person's leaving scene via left/right entrance.
Fig. 21 22 show two concurrent trajectories two different people environment. sample video frames captured different cameras system shown
Fig. 24.
AHMM model defined above, sequence observations returned
cameras, first determine performance profiles RB-SIS SIS real
8. consider different groups lab users, group might give rise different policy level.

488

fiPolicy recognition Abstract Hidden Markov Model

Camera 2

Camera 5

Table

Book shelf

Table

Office 1

Office 2
Region 7

Region 2

Book shelf

Camera 3

Camera 4
Region 1

left entrance

right entrance

Corridor
Camera 0

Linux server

time slice 300
Region 3

time slice 150 > 180

time slice 50

time slice 60

Printer

1111
0000
0000
1111

Vision Lab

Table

Table

Region 5

Region 6
Region 4

NT server

Camera 1

Figure 21: environment trajectory person 1

489

fiBui, Venkatesh & West

Camera 2

Camera 5

Table

Table

Office 1

Book shelf

Office 2
Book shelf

Camera 3

Camera 4

Corridor

left entrance

right entrance

time slice 180

Camera 0
Linux region

time slice 260

Linux server

Table

Vision Lab
Table

(Region 5)

Printer

1111
0000
0000
1111

NT region
Printer region

NT server

Camera 1

Figure 22: trajectory person 2

Top level

environment
2 policies

Middle level

Bottom level

Corridor & offices
3 policies

Corridor
5 policies

Office 1
2 policies

Vision lab
1 policy

Office 2
2 policies

Linux region Printer region Empty space
2 policies
2 policies
4 policies

Figure 23: region policy hierarchy

490

NT region
2 policies

fiPolicy recognition Abstract Hidden Markov Model

(a)
(b)
Figure 24: (a) Person 1 enters scene (b) Person 2 enters scene.

0.6

0.2

std. deviation

0.5

Efficiency coefficient

RB-SIS
SIS

0.4
0.3
0.2
0.1
0

SIS
0.06
RB-SIS
0.011

0.15

0.1

0.05

0
0

0.2

0.4 0.6 0.8 1 1.2
CPU time (in second)

1.4

1.6

0

(a) Error vs. CPU time

0.2 0.4 0.6 0.8 1 1.2 1.4 1.6
CPU time (in second)

(b) Eciency coecients

Figure 25: Performance RB-SIS SIS real tracking data

491

fiBui, Venkatesh & West
1.4
p(left_e)
p(right_ e)

1.2
Probability

1
0.8
0.6
0.4
0.2
0
0

50

100 150 200 250 300 350 400
Time

Figure 26: probabilities person 1 leaving scene via entrances (top level
policies)
environment. two algorithms behave similar way previous experiment
simulated data. Fig. 25 shows error curve CPU time two
algorithms. eciency co-ecient RB-SIS case RB SIS 0:011,
SIS SIS 0:06. shows RB-SIS still performs 5 times better
SIS domain.
surveillance system, low level tracking module returns observations
rate approximately two per second. observation passed RB-SIS
algorithm produces probability estimate current policy different levels
hierarchy. moment, surveillance system run real time using two
AMD 1G machines. Examples output returned system two trajectories
Fig. 21 Fig. 22 given below.
Fig. 26 shows probabilities person 1 exiting environment left
right entrance (denoted pleft e pright e respectively). beginning, pleft e
increases person 1 heading left entrance (see trajectory Fig. 21). Then,
pleft e approximately constant time slice 50 person 1 inside Vision lab.
one middle level policy defined Vision lab movement
inside lab independent final exit/entrance. time slice 310, pleft e decreases
person 1 leaving lab, turning right, entering oce 2. Then, increases
approaches 1 leaving oce 2, turning left, going towards left entrance.
contrast, pright e falls quickly zero time.
look results querying bottom level policies. Fig. 27 shows
distribution possible destinations person 2 time slice 180 time slice 260,
region 5 (see trajectory Fig 22). probabilities obtained show
system able correctly detect \walk-around" behaviour.
final result (Fig. 28) shows inferred behaviours person 1
Linux server region. Initially, probabilities \using Linux server" \passing
through" same. person stays position extended period
time, system able identify correct behaviour person 1 \using Linux
server".

492

fiPolicy recognition Abstract Hidden Markov Model

1.4
p(v_Linux)
p(v_printer)
p(v_NT)
p(w_ around)

1.2
Probability

1
0.8
0.6
0.4
0.2

0
180 190 200 210 220 230 240 250 260
Time

Figure 27: Behaviours person 2 inside Vision lab

1.4
p(u_Linux)
p(pass)

1.2
Probability

1
0.8
0.6
0.4
0.2
0
50

100

150
200
Time

250

300

Figure 28: Behaviour person 1 inside Linux server region

493

fiBui, Venkatesh & West
7. Related Work Probabilistic Plan Recognition

case using probabilistic inference plan recognition argued convincingly
Charniak Goldman (1993). However, plan recognition Bayesian network used
Charniak Goldman static network. Thus approach would run problems process on-line stream evidence plan. recent
approaches (Pynadath & Wellman, 1995, 2000; Goldman et al., 1999; Huber et al., 1994;
Albrecht et al., 1998) used dynamic stochastic models plan recognition thus
suitable on-line plan recognition uncertainty.
Among these, closely related model AHMM Probabilistic StateDependent Grammar (PSDG) (Pynadath, 1999; Pynadath & Wellman, 2000). comparison representational aspect two models discussed subsection 3.4.
terms algorithms plan recognition, Pynadath Wellman offer exact
method deal case states fully observable. states
partially observable, brute-force approach suggested amounts summing
possible states. note even fully observable case, belief state need
deal still large since policy starting/ending times unknown.9 Since
exact method used Pynadath Wellman, complexity maintaining
belief state would likely exponential number levels PSDG expansion
hierarchy (i.e., height policy hierarchy). hand, RB-SIS policy
recognition algorithm handle partially observable states Rao-Blackwellisation
procedure ensures sampling algorithm scales well number levels
policy hierarchy. Furthermore, noted subsection 3.4, consider compound
policies, PSDG converted AHMM. framework, compound policy
k 1 ; : : : ; k 1 represented normal policy, slight modification
k = (1)
(m)
let variable ek take values 1 + 1, value + 1 indicates
compound policy terminated. policy recognition algorithm
modified also work model.
Similar AHMM PSDG, recent work Goldman et al. (1999) also
makes use detailed model plan execution process. Using rich language
probabilistic Horn abduction, able model sophisticated plan structures
interleaved/concurrent plans, partially-ordered plans. However work serves
mainly representational framework, provides analysis complexity plan
recognition setting.
work probabilistic plan recognition date employed much coarser
models plan execution. ignored important uence state
world agent's planning decision (Goldman et al., 1999). best knowledge,
none work date addressed problem partial noisy observation
state. Most, except PSDG, look observation outcomes
actions, assume action observed directly accurately. note
kind simplifying assumptions needed previous work computational
complexity performing probabilistic plan recognition remains manageable. contrary,
work illustrates although plan recognition dynamic stochastic model
9. course, SRD policy hierarchy considered full observability alone enough.

494

fiPolicy recognition Abstract Hidden Markov Model
complex, exhibit special types conditional independence which, exploited,
lead ecient plan recognition algorithms.
8. Conclusion Future Work

summary, presented approach on-line plan recognition uncertainty
using AHMM model execution stochastic plan hierarchy noisy
observation. AHMM novel type stochastic processes, capable representing
rich class plans associating uncertainty planning plan observation
process. first analyse AHMM structure conditional independence properties. leads proposed hybrid Rao-Blackwellised Sequential Importance Sampling
(RB-SIS) algorithm performing belief state updating (filtering) AHMM
exploits structure AHMM greater eciency scalability. show
complexity RB-SIS applied AHMM depends linearly number
levels K policy hierarchy, sampling error depend K .
terms plan recognition, results show stochastic process
representing execution plan hierarchy complex, exhibit certain conditional independence properties inherent dynamics planning acting
process. independence properties, exploited, help reduce complexity
performing inference plan execution stochastic model, leading feasible scalable
algorithms on-line plan recognition noisy uncertain domains. scalability
algorithm policy recognition provides possibility consider complex plan
hierarchies detailed models plan execution process. key achieve
eciency, shown paper, combination recently developed techniques
probabilistic inference: compact representations Bayesian networks (context-sensitive
independence, factored representations), hybrid DBN inference take advantage compact representations (Rao-Blackwellisation).
Several future research directions possible. investigate AHMM,
would like consider problem learning parameters AHMM database
observation sequences, e.g., learn plan execution model observing multiple
episodes agent executing plan. structure AHMM suggests
try learn model abstract policy separately. Indeed, observe
execution abstract policy separately, learning problem reduced HMM
parameter re-estimation level-1 policies, simple frequency counting higher-level
policies. observation sequence long episode clear cut temporal boundary
policies, problem becomes type parameter estimation DBN
hidden variables, techniques dealing hidden variables EM (Dempster,
Laird, & Rubin, 1977) applied.
Extensions made AHMM make model expressive suitable
representing complex agents' plans. example, expressive plan execution
model HAM model (Parr, 1998) considered state-independent
sequences policies represented. current model also enriched consider
set top-level policies interleaved execution. expect
new models would exhibit context-specific independence properties similar

495

fiBui, Venkatesh & West
AHMM, Rao-Blackwellised sampling methods policy recognition models
derived.
Acknowledgement

would like thank anonymous reviewers insightful comments
helped improve presentation contents paper. Many thanks Nam
Nguyen implementation distributed tracking system used paper.
References

Albrecht, D. W., Zukerman, I., & Nicholson, A. E. (1998). Bayesian models keyhole
plan recognition adventure game. User Modelling User-adapted Interaction,
8 (1{2), 5{47.
Andrieu, C., & Doucet, A. (2000). Particle filtering partially observed Gaussian state
space models. Tech. rep. CUED-F-INFENG/TR. 393, Signal Processing Group, University Cambridge, Cambridge, UK.
Bauer, M. (1994). Integrating probabilistic reasoning plan recognition. Proceedings
Eleventh European Conference Artificial Intelligence.
Boutilier, C., Dearden, R., & Goldszmidt, M. (2000). Stochastic dynamic programming
factored representations. Artificial Intelligence, 121, 49{107.
Boutilier, C., Friedman, N., Goldszmidt, M., & Koller, D. (1996). Context-specific independence Bayesian networks. Proceedings Twelveth Annual Conference
Uncertainty Artificial Intelligence.
Boyen, X., & Koller, D. (1998). Tractable inference complex stochastic processes.
Proceedings Fourteenth Annual Conference Uncertainty Artificial Intelligence.

Brand, M. (1997). Coupled hidden Markov models modeling interacting processes. Tech.
rep. 405, MIT Media Lab.
Bui, H. H., Venkatesh, S., & West, G. (1999). Layered dynamic Bayesian networks
spatio-temporal modelling. Intelligent Data Analysis, 3 (5), 339{361.
Bui, H. H., Venkatesh, S., & West, G. (2000). recognition abstract Markov policies.
Proceedings National Conference Artificial Intelligence (AAAI-2000), pp.
524{530.
Casella, G., & Robert, C. P. (1996). Rao-Blackwellisation sampling schemes. Biometrika,
83, 81{94.
Castillo, E., Gutierrez, J. M., & Hadi, A. S. (1997). Expert systems probabilistic network
models. Springer.
Charniak, E., & Goldman, R. (1993). Bayesian model plan recognition. Artificial
Intelligence, 64, 53{79.
Cohen, P. R., & Levesque, H. J. (1990). Intention choice commitment. Artificial
Intelligence, 42, 213{261.

496

fiPolicy recognition Abstract Hidden Markov Model
Cooper, G. F. (1990). computational complexity probabilistic inference using Baysian
belief networks. Artificial Intelligence, 42, 393{405.
Dagum, P., & Luby, M. (1993). Approximating probabilistic inference Bayesian belief
networks NP-hard. Artificial Intelligence, 60, 141{153.
Dagum, P., Galper, A., & Horvitz, E. (1992). Dynamic network models forecasting.
Proceedings Eighth Annual Conference Uncertainty Artificial Intelligence,
pp. 41{48.
D'Ambrosio, B. (1993). Incremental probabilistic inference. Proceedings Ninth
Annual Conference Uncertainty Artificial Intelligence, pp. 301{308.
Dawid, A. P., Kjrulff, U., & Lauritzen, S. (1995). Hybrid propagation junction trees.
Zadeh, L. A. (Ed.), Advances Intelligent Computing, Lecture Notes Computer
Science, pp. 87{97.
Dean, T., & Kanazawa, K. (1989). model reasoning persistence causation.
Computational Intelligence, 5 (3), 142{150.
Dean, T., & Lin, S.-H. (1995). Decomposition techniques planning stochastic domains. Proceedings Fourteenth International Joint Conference Artificial
Intelligence (IJCAI-95).
Dempster, A., Laird, N., & Rubin, D. (1977). Maximum likelihood incomplete data
via EM algorithm. Journal Royal Statistical Society B, 39, 1{38.
Doucet, A., de Freitas, N., Murphy, K., & Russell, S. (2000a). Rao-Blackwellised particle filtering dynamic Bayesian networks. Proceedings Sixteenth Annual
Conference Uncertainty Artificial Intelligence.
Doucet, A., Godsill, S., & Andrieu, C. (2000b). sequential Monte Carlo sampling methods Bayesian filtering. Statistics Computing, 10 (3), 197{208.
Forestier, J.-P., & Varaiya, P. (1978). Multilayer control large Markov chains. IEEE
Transactions Automatic Control, 23 (2), 298{305.
Fung, R., & Chang, K. C. (1989). Weighting integrating evidence stochastic simulation bayesian networks. Proceedings Fifth Conference Uncertainty
Artificial Intelligence.
Geweke, J. (1989). Bayesian inference econometric models using Monte Carlo integration.
Econometrica, 57 (6), 1317{1339.
Ghahramani, Z., & Jordan, M. I. (1997). Factorial hidden Markov models. Machine Learning, 29, 245{273.
Goldman, R., Geib, C., & Miller, C. (1999). new model plan recognition. Proceedings
Fifteenth Annual Conference Uncertainty Artificial Intelligence.
Hauskrecht, M., Meuleau, N., Kaelbling, L. P., Dean, T., & Boutilier, C. (1998). Hierarchical
solution Markov decision processes using macro-actions. Proceedings
Fourteenth Annual Conference Uncertainty Artificial Intelligence.
Henrion, M. (1988). Propagating uncertainty Bayesian networks probabilistic logic
sampling. Lemmer, J., & Kanal, L. (Eds.), Uncertainty Artificial Intelligence 2,
Amsterdam. North-Holland.

497

fiBui, Venkatesh & West
Huber, M. J., Durfee, E. H., & Wellman, M. P. (1994). automated mapping plans
plan recognition. Proceedings Tenth Annual Conference Uncertainty
Artificial Intelligence.
Jelinek, F., Lafferty, J. D., & Mercer, R. L. (1992). Basic methods probabilistic context free grammar. Laface, P., & Mori, R. D. (Eds.), Recent Advances Speech
Recognition Understanding, pp. 345{360. Springer-Verlag.
Jensen, F. (1996). Introduction Bayesian Networks. Springer.
Jensen, F., Lauritzen, S., & Olesen, K. (1990). Bayesian updating recursive graphical
models local computations. Computational Statistics Quarterly, 4, 269{282.
Jordan, M. I., Ghahramani, Z., Jaakkola, T. S., & Saul, L. K. (1999). introduction
variational methods graphical models. Machine learning, 37 (2), 183{233.
Jordan, M. I., Ghahramani, Z., & Saul, L. K. (1997). Hidden Markov decision trees.
Mozer, M. C., Jordan, M. I., & Petsche, T. (Eds.), Advances Neural Information
Processing Systems 9, Cambridge, MA. MIT Press.
Kalman, R. E. (1960). new approach linear filtering prediction problems. Transactions American Society Mechanical Engineering, Series D, Journal Basic
Engineering, 82, 35{45.

Kanazawa, K., Koller, D., & Russell, S. (1995). Stochastic simulation algorithms dynamic probabilistic networks. Proceedings Eleventh Annual Conference
Uncertainty Artificial Intelligence, pp. 346{351.
Kautz, H., & Allen, J. F. (1986). Generalized plan recognition. Proceedings Fifth
National Conference Artificial Intelligence, pp. 32{38.
Kjaerulff, U. (1992). computational scheme reasoning dynamic probabilistic networks. Proceedings Eighth Annual Conference Uncertainty Artificial
Intelligence, pp. 121{129.
Kjrulff, U. (1995). dHugin: computational system dynamic time-sliced Bayesian
networks. International Journal Forecasting, 11, 89{111.
Lauritzen, S., & Spiegelhalter, D. (1988). Local computations probabilities graphical
structures application expert systems. Journal Royal Statistical
Society B, 50, 157{224.
Liu, J. S., & Chen, R. (1998). Sequential Monte Carlo methods dynamic systems.
Journal American Statistical Association, 93, 1032{1044.
Murphy, K., & Russell, S. (2001). Rao-blackwellised particle filtering dynamic Bayesian
networks. Doucet, A., de Freitas, N., & Gordon, N. J. (Eds.), Sequential Monte
Carlo Methods Practice. Springer-Verlag.
Murphy, K. P. (2000). Bayesian map learning dynamic environments. Advances
Neural Information Processing Systems 12, pp. 1015{1021. MIT Press.
Nguyen, N. T., Venkatesh, S., West, G., & Bui, H. H. (2002). Coordination multiple
cameras track multiple people. Proceedings Asian Conference Computer
Vision (ACCV-2002), pp. 302{307.

498

fiPolicy recognition Abstract Hidden Markov Model
Nicholson, A. E., & Brady, J. M. (1992). data association problem monitoring
robot vehicles using dynamic belief networks. Proceedings Tenth European
Conference Artificial Intelligence, pp. 689{693.
Parr, R. (1998). Hierarchical control learning Markov Decision Processes. Ph.D.
thesis, University California, Berkeley.
Parr, R., & Russell, S. (1997). Reinforcement learning hierarchies machines.
Advances Neural Information Processing Sytems (NIPS-97).
Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks Plausible Inference. Morgan Kaufmann, San Mateo, CA.
Pearl, J. (1987). Evidential reasoning using stochastic simulation causal models. Artificial
Intelligence, 32, 245{257.
Pynadath, D. V. (1999). Probabilistic grammars plan recognition. Ph.D. thesis, Computer Science Engineering, University Michigan.
Pynadath, D. V., & Wellman, M. P. (1995). Accounting context plan recognition,
application trac monitoring. Proceedings Eleventh Annual Conference
Uncertainty Artificial Intelligence.
Pynadath, D. V., & Wellman, M. P. (2000). Probabilistic state-dependent grammars
plan recognition. Proceedings Sixteenth Annual Conference Uncertainty
Artificial Intelligence.
Rabiner, L. R. (1989). tutorial Hidden Markov Models selected applications
speech recognition. Proceedings IEEE, 77 (2), 257{286.
Sacerdoti, E. (1974). Planning hierarchy abstraction spaces. Artificial Intelligence,
5, 115{135.
Shachter, R. (1986). Evaluating uence diagrams. Operations Research, 34, 871{882.
Shachter, R. D., & Peot, M. A. (1989). Simulation approaches general probabilistic
inference belief networks. Proceedings Fifth Conference Uncertainty
Artificial Intelligence.
Sutton, R. S. (1995). Td models: Modelling world mixture time scales.
Proceedings Internation Conference Machine Learning (ICML-95).
Sutton, R. S., Precup, D., & Singh, S. (1999). MDP semi-MDPs: framework
temporal abstraction reinforcement learning. Artificial Intelligence, 112, 181{
211.
van Beek, P. (1996). investigation probabilistic interpretations heuristics plan
recognition. Proceedings Fifth International Conference User Modeling,
pp. 113{120.
York, J. (1992). Use Gibbs sampler expert systems. Artificial Intelligence, 56, 115{130.

499

fi
ff
fi
! #"$ %
'&)(+*-,/.00.213( 42*+5'(+*
0

6789: ;)( .2<
0!(=?>8 %&;A@2<
0.

B$CEDGFEHJI7CEKLB$CNMO-PRQEP3OSMTVUXWOZY\[VM]I7CEK_^`WTbaca]IdGO-P3afegI
M3hE[iFjMlkmP3TbDGI7CEK
n

H:HJFEP3TbHSoqpr[)PtsjIuvQXWIHJI
Mwoyx`kzhEO-[)P3OSM3I2H:TVW|{}OJaFXWMaS~
n

n

QXQEP3[JEIuLTM3I2[NC

WK)[iPRI
M]hXua~yTVCEDEQyO-PRIuLOCNMa

ff#$`|3

cRiJ$c$$$$$ $#ff

c

2r?
-$$ ' w2 2'2r+
-ffEc
'?+rVw
!22
:Sff?
77

2]


r3
J727#rr2!]- +i?rr+b2/r 7+r?r++]rSrR7/?
j+7r2+/r$7+
J27r++:N+)2E:r]7+)V++
'
r
7 ff+ r+7 +? +X+7?

mr-2/r ?+r X7+|r
G?r++ Nr+? 77 X77m+ r? +7++?E2/r 77
S2r


!X?R:+7-rVrAj/+7 ):G+rjGr
7:+ff

r7
++| +r+
?/ ! +:ffi7 ?
E!?y

X?
fi
++?/b?b/+G +G?+ ++/?G? 7?
r7

]ffN7+b7+VffG+i+G+j?
!+br:+
+/2
r72
r +
r
yrr?2/r 77
SXVffi?X
7ff
+
:
r
E+rm/
!"crr7yrt+!27V7+)r+#!


7r+?iff
?r
#
'3/Ar

ff:!r+
3? ]+Nr?
++A )r)/+i7

E!?
?r
%$+Nr):/
Srff&
r+7S72/++2+r(
'??S +ri7r+)rN7#)

$rV rR)
2/r
b:+ ff + '*
rr
7+ ' ,i !)E& .
ff:
2+r
Effr+ 2!+ :?++7rAr+! 7
/
+ff


ff!r+ + ? rr+
01+! r++77+!2 r +!
rr ?rV?++/2/?V7r+7Arff +2

ff: br yff +G?
?3

ffE+
ff +5
476
?:7+
Nr|+ 8
'rX ?/
# r:/
+!r r/?

)/ i+?N?9
1+!+V+-+r: ffr
+
r+r7+
r++!

;7<2=8> 3?@BA-3CD? >
E"FGHFI(JLKM#N8KIOGHFPRQSI2JT9FUPVJW9M#X-YZ7NYJQSI#[ffG]\SKPPQ_^`G]KaJQ_Y3IK\_[Yb/QSJT9cPdT9KNF eObY3W#[3T(JdFc2fOQ_bQSG]K\#KI9M
JT#F]YbF]JQgG]K\bFPW9\SJPhG]\SFKab/\_XiP/T#YjUQgI#[kJT#FM9QSPGHbQScQSI9KaJQSY3IlfmYjnF]boYZBFIOPVFc!e`\_F2G]\SKPPQ_^OF]b/P2p.qnKW9F]b
rts Y3TOKNuQwv`xyyy{z#qnbFQScKIvOxyy|{z#}hQSF]JVJVF]b/QSG/Tv{~auzOhfOQ_JV r KG]\SQgI7vOxyyy{zOuG/TOKafOQ_bF r #QSI#[F]bv
xyy3k"T#FPVFcF]JT#Y{MOPoeOKPQSG]K\g\_XbF\SXY3INYJQgI#[lJT#FM#FG]QgPQ_Y3IYZLQSI9M9QSN{QSMOW9K\G]\SKP/PQ_^9F]b/PoQgI9PQSM#F
KI%FI9PVFcffeO\_FJnQgPBj QSM#F\_X2KG]GHF]f9JVFM7v`KI9M%ZYb/cK\S\_Xf9bYNFIQSIGHF]b/JKQSIG]KPVFPpDuGT9KafOQ_bFvu#bFWOI9M7v
qLKabJ\_F]JVJ]v r F]Fvhxyy{zfiuG/T9Kaf`Q_bF r uQSI#[F]bvUxyy3vLJT9KaJ2JT#FQ_b2fmYjnF]bKGHJW9K\g\_XbF\gQ_FP-Y3IJT#F
KaeOQS\gQ_JX%JVYeOW9Qg\SMkfmYJVFIJQSK\g\_XHk\gKab[F!G]\SKPP/Q_^9F]b/P]R)JUTOKP"F]NFIieF]FIYeOPVF]bNFMFH{fmF]b/Qgc2FIJK\g\_X
JT9KaJPW9GTKI1FIOPVFc!e`\_FiG]KItPVY3cF]JQSc2FP%emFiKP\SKab[F5KPp:Ybl\SKab[F]b%JT9KI`JT#F5M9KaJKW9PVFM1JVY
eOW9Qg\SMJT#FFI9PFc!eO\SFp Kab/[3QSI#FKI(JW r }hQSF]JVJVF]b/QSG/Tvxyy3lt"T9FI7vnKPQSc2f`\_Fl(W9FPVJQ_Y3IKab/QgPVFP]v
I9Kc2F\SX2jUT9KaJBQgPRJT#FfiQSI(JVF]bFPVJnKffG]W9PJVY3c2F]bG]KI%TOKNFoQSIWOPQSI#[!P/W9G/TkK!G]\gKPPQ_^9F]bv(QSI9PJVFKMYZP/QSc2fO\_F


.00. %%`!;V
;LA2
n3
!fi9J
R8! %&% r&2%%g2 ;

fi

\_Y{Y{W9fOPdQSIJT#F M9KaJKuv#KI9MW9PQSI9[!K\_[Yb/Q_JTOcPRPWOG/T%KPBI#FKab/FPVJBI#FQS[3TemYbBG]\gKPPQ_^9F]bPUp Kab/[3QSI#FKI(JW
r }fiQ_F]JVJVF]b/QgG/T7vxyy3
ZJVF]b%PVY3c2FYZfiJT#Flc2Y3PJbFcKab aKaeO\_FkbFGHFI(JPVJWOM9Q_FP2QSINYJQSI9[G]\SKPPQS^OG]KaJQ_Y3IK\_[Yb/QSJT9cP]v
PVY3c2F"KW9JT#Yb/PdT9KNF"fmY3QSI(JVFMffY3W9JJT#F"QSI(JVF]bFPVJJVYe9bQSI#[hJT9QSP G]\SKPPQS^OG]KaJQ_Y3IfmYjnF]bdJVY!M9KaJKocQSI9QSI#[#v
KI9MlcYbFof9bFG]QSPF\_XJVYcK FffQSI(JVF]bf9bF]JKae`QS\SQ_J)XKG]\_FKabUQgPPW#FoQSIkNYJQSI9[G]\SKPPQS^OG]KaJQ_Y3IK\_[Yb/QSJT9cP
p.qLKW#F]b r Y3T9KN{Qwv0xyyy{zE QSM#[F]jLKXv KM9Q_[3KIvOEUQSGT9Kab/M9PY3I7v r
KI9Fvxyy3U{Y3c2F!KW#JT9Yb/P
[YF]NFIZ.W#bJT#F]bv0KI9MKab[3W9FJT9KaJ!JT9FQSc2fmYbJKI9GHF2YZ"QgIJVF]bfObF]JKaeOQS\SQSJXiTOKPoemF]FIcKab[3QgI9K\SQ_]FM
QSIkJT#FM9FPQ_[3IkYZ JT#FPVFK\_[YbQ_JT9cP]v#KI9MlfOW#JLemFT9QSI9M%JT#FI#F]FMlJVYM#F]NuQSPVFoG]\SKPPQS^9F]b/PLjUQ_JTPJVbY3I#[
G]\SKPP/Q_^OG]KaJQ_Y3IfYjBF]bop.EUQgM#[F]jnKX2F]JnK\D_vxyy3RqLW#JnQSI(JVF]bf9bF]JKaeOQg\SQ_JXK\SPVYff[YNF]b/IOPBJT9F {W9K\SQ_J)X-YZ
K-c2Y{M9F\Oe{Xf9bYN{QgM9QSI#[KI9PjBF]b/PnJVY2T#YjQSJBQSPBjBY
b {QSI9[#v{KI9Mv{c2Y3PJnQScfYb/JKIJ\_Xv(jUT(X G]GHYb/MOQSI#[
JVYqLKW#F]b rs Y3T9KN{Qp+xyyy3vLPVJVb/QSN{QSI9[iZ:YbGHY3c2f9bFT9FI9PQ_eOQg\SQ_JX5QSINYJQSI#[c2YuM#F\SPQSP-Y3I#FYZ JT#F
f9b/QgI9G]Q_fOK\f9bYeO\SFcPmbF{W9Q_b/QSI9[RZ.W#JW#bFdQSI(NFPVJQ_[3KaJQSY3I9P]0UT#F]XhK\gPVYbFcKab hJT9Kafi
J ff+NYJQgI#["JVFG/TOI9QS{W#FP
W9PWOK\S\_XbFP/W9\_JQSIQSI9GHY3cf9bFT#FI9P/Q_eO\_FhG]\SKPPQ_^OF]b/PLJT9KaJUG]KI9I9YJ"FKPQS\_X%emFoPT#Yj IJVYW9PVF]bP u
Y3cf9bFT#FI9P/Q_eOQS\SQSJXQgP]vY3IJT#FiYJT9F]blT9KI9M7v"KT9Kab/McQSI9QgI#[QSPP/W#Fp.qLW K r F]Fvh~a#x

Q_J!M9F]fFIOM9PfiY3IfOKab/KcF]JVF]b/PffP/W9G/TKPffJT#FJ)X(fmFYZG]\SKP/PQ_^9F]b/PoWOPVFM7vJT9FK\_[Yb/Q_JTOc QSI9M9WOG]QSI#[kJT#F
G]\SKPP/Q_^9F]b/P]v{JT#FoW9PVF]bcQgI9QSI#[ffJT#FfiY3W#JVfOW#JP]vuF]JGa"dUT#Y3W#[3T%JT#F{W9KIJQS^OG]KaJQ_Y3I%YZ0QSI(JVF]bf9b/F]JKaeOQS\SQ_J)X
QSPPJQS\S\YfmFI#FMQgIJT#F[FI9F]b/K\RG]KPVFp.qLW K r F]Fv ~a#xvJT9F]bFKabF%PVY3c2F%G]\SW#FPGHY3cQgI#[lZ:bY3c
JT#F]YbX-KI9M-f9b/KGHJQSGHFLYZcKG/T9QgI#F\_FKab/I9QSI9[ 8M9KaJK cQSI9QSI#[ QSI9M9QSG]KaJQgI#[ PVY3cFnfmYJVFI(JQSK\S\_XffQSIJVF]b/FPVJQSI#[
bF{W9Q_bFcFIJPKI9MGHY3c2f9bY3cQgPVFPJVYM#F]NuQSPVFKIlF G]Q_FI(JU\_FKab/I9QgI#[ 8cQSI9QgI#[ffK\_[YbQ_JT9c
^9bPVJobF{W9Q_bFc2FI(JZ:Yb!JT#F%K\_[Yb/Q_JTOc QSPoYe{NuQ_Y3W9P\_X5Q_JP![FI#F]b/K\SQ_KaJQSY3IKaeOQS\gQ_JQ_FP j Q_JT#Y3W#J
G]\SKPP/Q_^OG]KaJQ_Y3IkPVJVbFI9[JT7v9Q_JLQSPnfY3QgIJ\_FP/PBJVYPFKab/G/TkZ:Yb"QSI(JVF]bFPVJQSI#[c2YuM#F\SPnYZJT9FM9KaJKu PFGHY3I9M
r KPG]W#F\wvnxyy {z
bF{W9Q_bFcFIJ]vcYbFbF\SKaJVFMJVYcQSIOQSI#[#vQSPoJT9FPQ_]FYZLJT#FG]\SKP/PQ_^9F]b/Pp YuG
r Kaf9f{Xvxyy3)Z"KG]G]W#bKaJVFvRKiG]\gKPPQ_^9F]bffjUQ_JTbFPVJVb/QSGHJVFMPQ_]F%G]KI\_FKMJVY5Z.KPVJVF]b2KI9M
Y{
G
M#F]F]fmF]bLW9I9M#F]b/PJKI9M9QSI#[# "T9QSPBQSPBYe(NuQ_Y3W9P\SXI#YJnKIkKaeOPY3\SW#JVFUbW9\_Fv{b/KaJT#F]bLKI%KafOf9bY#QScKaJVFhf9bY{X
Z:YbQSIJVF]b/f9bF]JKaeOQS\gQ_J
X hfOKaJT#Y3\_Y[3QSG-G]KPVFPoFH#QSPVJoQSIijUT9QgG/T7vmZ:YbhFH#Kc2fO\SFvK%\gKab[F2KI9M5W9Ie`K\SKI9GHFM
JVbF]FG]KI emFNF]bXPQSc2fO\SF%JVYW9I9M#F]b/PJKI9M p.qLW VK r F]Fv"~a#x
UYJVFiJT9KaJQSIJTOQSPFHuKcfO\_Fv
JT#FoKW#JT#YbPLFH{fO\gKQSIJTOKaJJT#FfiJVbF]FQSPLPQSc2f`\_FUemFG]KW9PVFoK\S\mQ_JPI9Y{M#FPLG]KIkemFoM#FPGHb/QSeFM%W9PQgI#[!Z:F]j
!#"$&% % "T#F]b/F]ZYbFv3P/QSc2fO\SQgG]Q_JXoQSP K\SPVYoKPPVYuG]QSKaJVFMJVYoKfiPT#YbJ M#FPGHbQ_f9JQ_Y3I7vaeOW9J W9P/QSI#[ KhfOKab/JQSG]W9\SKab
G]\SKPP"YZ GHY3IOGHF]f9J"bF]f9b/FPVFIJKaJQSY3I7
JT9Q_bMfff`Kab/Kc2F]JVF]bBQg(
'OW#FI9G]QgI#[hGHY3cf9bFT#FI9P/Q_eOQS\SQSJXQSP JT#F I9KaJW#bFYZmJT#F"K\_[YbQ_JT9)
c PY3W9JVfOW#J]
+I9PQSM#FRJT#FLe9bY3KM-PGHYfmFBYZOPX{cffemY3\SQSGRG]\gKPPQ_^9F]bP]v8PY3c2FnG]\gKPPVFP YZ`GHY3I9GHF]fOJ b/F]f9bFPVFI(JKaJQ_Y3I9P Kaf9fmFKab
JVY5Y *F]b2Ki[bFKaJVF]bGHY3c2Z:YbJ-ZYb2QSI(JVF]bf9bF]JKaJQSY3I7i}hFG]QSPQSY3IJVbF]FPemF\_Y3I9[JVYJT9QSP-PVF]Jkp.qnbFQgcKI7v
#bFQgM9cKI7vo\SPT#FI7v r {JVY3I#Fv0xy +(vJT#Y3W#[3TJT#F]XK\SPVYbKQSPVF!PVY3cF!QSI(JVF]bf9bF]JKaeOQg\SQ_JXf9bYeO\SFc,
P
Y3T9KN{Q r {Y3cc2F]b/^9F\SMp+xyy3{W#YJVFJTOKaJ
ff+JT9FLG]\gQ_FIJP.- eOW9P/QSI#FPP0W9PVF]b/P0/uZ:Y3W9I9M-PVY3c2FLQSIJVF]b/FPVJQSI#[ fOKaJVJVF]b/I9P

SQ IffJT#FLM#FG]QSPQ_Y3IffJVbF]FP]v
e`W#JBJT9F]XM9QSMI#YJLZF]F\JT#FoPVJVbW9GHJW#bF jnKPI9KaJW9b/K\ZYbLJT#FcdUT#F]XjnF]bFo\_Y(YuQSI#[ffZYb
JT9Y3PVF!J)jBYYb JT#b/F]F!KaJVJVb/Q_eOW9JVFPUKI9MNaK\SW#FP-p214351LKGHY3c!eOQgI9KaJQ_Y3IYZ[F]Y[b/Kaf`T9QSGKI9M
QgI9M9W9PVJVbQ_FP0jUT#F]b/F PVY3c2F]JTOQSI#[ffVQgIJVF]bFPJQSI#[6 jLKPLT9Kaf9fmFI9QSI9[#+IKM9MOQ_JQ_Y3I7v3JT9F]XZF\SJ
QSJdjnKPBJVY{Y-\SQgcQ_JQSI#[fiJT9KaJBJT#F I9Y{M#FPRQSIKffM#FG]QSPQ_Y3IJVbF]FUbF]fObFPVFI(JRb/W9\SFPJT9KaJLK\S\9PVJKabJ
j Q_JTkJT#F!PKcF!KaJVJVb/Q_eOW9JVFP]7
\_JT#Y3W#[3TI9YJ\SQScQ_JQgI#[Z:bY3c KG]\SKPP/Q_^OG]KaJQ_Y3INuQ_F]j"fmY3QSI(J]vdJT#FYb/M9F]b/QSI#[YZhI9Y{M#FPfOb/Q_YbJVY
]G \SKPP/Q_^OG]KaJQ_Y3IG]KIJT9F]bF]ZYb/FcKF!Q_JW9I9GHY3cZYbJKae`\_FoJVYcQSI#FoK2M#FG]QgPQ_Y3IkJVbF]F8 YJQSGHFJTOKaJJT9QSP
f9bYe`\_Fc cQS[3TJT#Y3\SMZYb2KI(XG]\SKPPffYZUGHY3I9GHF]f9JbF]fObFPVFI(JKaJQ_Y3IQSIJVF][bKaJQSI#[iKIYb/M9F]b/QSI#[if9b/Q_Yb
JVYkG]\SKPPQ_^`G]KaJQ_Y39I BM9FG]QSPQ_Y3Ii\SQSPVJP!p.E Q_NFPVJ]v xy3vK\_JVF]b/I9KaJQgI#[M#FG]QSP/Q_Y3IlJVbF]FPp.#bFWOI9M r KPY3I7v
:<;>=

fi

iwc


ffff

xyyy3v7e9b/KIOG/T9QSI9[2f9bY[b/KcPp KI9PVY3W#b r G \g\_FPVJVF]bv7~av7F]JGaU"T9F]bFFH#QSPVJP]vmT#YjnF]NF]bv7K
JX{fmFLYZ`G]\SKPP/Q_^9F]b/P Y3IjUT9QgG/T-bF\SKaJVFMfOKafmF]b/P Kaf9fmFKabJVYoemFB[FI9F]b/K\S\_X!WOI9KI9QSc2Y3WOPY3IJT#FQSb cQSI9QSI#[
KaeOQS\gQ_JQ_FP M9QgP VWOI9GHJQ_NFBI9Yb/cK\{ZYbc ZYb/c-W9\SKP"p.} h P]v(KI9M-JT#FQSbdI(W9cF]bY3W9P FH{JVFIOPQ_Y3I9PvJT9KaJdQSP]v
M9QSP VW9IOGHJQ_Y3I9P"YZBGHY3I VWOI9GHJQ_Y3I9P]o+I(JVF]bFPVJQSI#[3\SXFI#Y3W#[3T7v7JT9QgP QSPhJT#F2G]\SKP/P j T9QSG/Tc2YJQ_NaKaJVFM5FKab/\_X
jnYb {Pop.KI9MkK-[bFKaJKc2Y3W9I(JLYZjnYb {PLKaZ:JVF]bjLKab/M9PRY3I%JT#FhjBF\S \ fi {I#YjU
JT9F]YbXYZ0\SFKab/I9QSI#[
p dK\SQSKI(J]vUxy +#vUxy 3vBfOKabJ\_XeFG]KWOPVFYZUJT#FkJVFI9M#FI9GHXT{W9cKIOP-PF]Fc JVYT9KNFJVY5bF]f9bFPVFI(J
uI#YjU\SFM#[FW9PQgI#[PQScQS\gKab/\_XlPT9KafmFM5b/WO\_FPp dK\SQSKI(J]vnxy 3"TOQSPfiG]\SKPP!QgPoK\SPVYlJT#FM9W9K\ YZLJT#F
Y3I#FQScfO\SQSG]Q_J\SX%W9PFM5e(XqnW VK r F]Fpw~a#xoJVYlG]KPVJoJT#FQ_bP/Q_]F2c2FKPW#bFZ:YbM#FG]QSPQSY3IiJVb/F]FPp:JVY
PVJKaJVFffjUT#F]JT#F]bJT#FffGHY3I9GHF]f9J"bF]fObFPVFI(JVFMQSPPQgc2fO\_FhYb I#YJ
JUQSPLY3W#b KQSc QSIJTOQSPLfOKafmF]bJVYf9b/YfY3PFhJT9F]YbF]JQSG]K\b/FPW9\_JP"KIOMlKaf9f9bYuQgcKaJQ_Y3IK\_[Yb/QSJT9cP
bF\SKaJVFMiJVY%JT#F-QgI9M9W9GHJQ_Y3IkYZRNF]bXfOKabJQSG]WO\SKabUNYJQSI9[%G]\SKP/PQ_^9F]b/PvOM#b/KjUQSI#[JT9FQ_bUbY{YJPhY3IiP/QSc2fO\_F
b/W9\SFUPVF]JPp.\S#Q Fh} dvujUQ_JTJT#FhYe +FGHJQSNFhJV
F]F]flKffJVb/KM#F]Y *emF]JjnF]FIPQScfO\SQSG]Q_J)X-KIOMKG]G]W#bKGHX
fiW#bkKQSc QSP%K\SPVYJVYf9bYNFJT9KaJ]vfiQSI JT9F5I{W9c2F]b/Y3W9PkQSI9M9W9GHJQSY3I K\_[Yb/QSJT9cPkK\_bFKM#X f9bYfmY3PVFM
JT#bY3W9[3T#Y3W#JhJT#F-cKG/T9QSI9Fff\_FKab/IOQSI#[KIOMiM9KaJKkcQgI9QSI#[GHY3cc-W9I9QSJQ_FP]vmPVY3c2F-YZdJT#Fcvmf9bF]NuQ_Y3W9P/\_X
W9PVFMiQSIM9FG]QSPQ_Y3IJVb/F]FP KI9MM#FG]QSP/Q_Y3Il\SQSPJP"QSI9M9WOGHJQ_Y3I7vOG]KIiemFFKPQS\_XKM9KafOJVFMJVY%GHYfFffjUQ_JTJT9QSP
Ye VFGHJQ_NFvaJT#F]bF]e{X\_FKM9QSI9[JVY"FKPVX fiDJVY fiQSc2fO\_FcFIJLp.KI9M!GHY3c2f`KabF7K\_[YbQ_JT9cP] "T#FdI#FHuJ0PFGHJQ_Y3I
f9bFPFIJP"KPVX{I(JT#FPQgPLYZ Y3W9bUGHY3IJVbQ_eOW#JQ_Y3Iv{j T9QSG/TQgPM#F]JKQS\_FMlQgIkJT#FbFPVJYZ JT#Fof`KafF]b
< AJ? >

C BA:3C?

>

T9QgPBf`KafF]b"QgPBfOb/QSI9G]Q_f`K\S\_X2GHY3I9GHF]b/I#FMljUQ_JT%JT#FoJT#F]YbF]JQgG]K\KI9MkFHufF]bQSc2FI(JK\7PVJW9M#XYZ0KPVF]JYZ
"
NYJQSI#[G]\SKP/PQ_^9F]b/P jUT9QgG/TjBFJT9QgI(QSPh\SQ#F\_XJVY%fObYNuQSM#FKIKG]G]W#b/KaJVFKI9PjBF]boJVYkJT#F2PQScfO\SQSG]Q_J)Xfi
KG]G]W#b/KGHXJVb/KM#F]Y * M9FG]QSPQ_Y3IGHY3ccQ_JVJVF]FPfip.} "p Y{
G r KP/G]W#F\wvmxyy 3R} QSPRQSI#Z:Yb/cK\S\_XffJT#F
qnY(Y3\SFKIcffWO\_JQSG]\SKPPhFHuJVFI9PQ_Y3I5YZBfmY3\_X{I9Y3cQSK\ M9QSPGHb/QgcQSI9KI(JUZ.W9I9GHJQ_Y3IOP] M#FG]QSPQ_Y3I5GHY3ccQ_JVJVF]F
GHY3I(JKQSI9PdbW9\_FP]v3FKGT%YZJT9FPVFUemFQSI#[KfOKQ_bhp.cY3I#Y3cQSK\wvNFGHJVYb
RKGTcY3I#Y3cQSK\9QgPRKGHY3I9MOQ_JQ_Y3I
JT9KaJ]v jUT#FI^ObFM7vbF]JW#bI9PQ_JPNFGHJVYb ZJVF]bkFKG/TtcY3I#Y3cQSK\ T9KP%eF]FI1JVFPVJVFM7vUJT#FP/W9c YZ
JT#FbF]JW9b/I#FMNFGHJVYb/PQgP%WOPVFMJVYJK FJT#FM#FG]QSP/Q_Y3I7 "TOQSPkKM9M9Q_JQ_NFZ.KPT9Q_Y3IZ:YblGHY3c!eOQgI9QSI#[
b/W9\SFP!QSPffKaeOPVFI(JffZ:bY3c G]\SKPPQSG]K\BqnY(Y3\_FKIG]\SKP/PQ_^9F]b/P!PW9G/TKP}hFG]QSPQ_Y3Ib/F]FP%p.}fi Yb-}hFG]QSP/Q_Y3I
QgPVJP"p.} 9W9bJT#F]b/c2Yb/FvW9I9\SQ FBJT#FPFJjnY!\SKaJVJVF]bRG]\SKP/PVFP]v3JT#F"G]\gKPPQ_^9F]bGHY3I(JKQSI9PdKae`PVY3\SW#JVF\_X-I#Y
Yb/M#F]bQSI#[#vI#FQ_JT#F]b Y3I-NaKab/QSKaeO\_FPp.W9IO\S#Q FB}fi v3I9Yb Y3Ic2Y3I9Y3cQSK\SPp.W9I9\g#Q FB} T#FIP(W G]Q_FIJ\SX
PcK\g\} PKabFeOWOQS\_JfiKI9MKM#F{W9KaJVFb/FPVJVb/QSGHJQ_Y3IOPoKabFJK FI7v KI#F]j M9Qgc2FI9PQ_Y3I5QSIQgIJVF]bfObF]JQSI#[
JT#FG]\SKPP/Q_^9F]b2QSP-Ye9JKQSI#FMvjUT9QSGTM9Y(FP2I#YJFH#QSPVJZ:Yb}h Yb2} hKc2F\_XvnKIXFHuKcfO\_FG]KI
PKaJQSPZXcYbFfiJT9KI%Y3I#Ffib/W9\_FvuKI9MK} G]KIkJT9F]bF]ZYb/FhemFoQSI(JVF]bf9bF]JVFM%e{Xc2FKI9PLYZ0N8KabQ_Y3W9PBb/W9\_F
%<$ % % p.QSIK2IOKQ_NFoGHY3INF]b/P/Q_Y3IYZ K2}h YbUK2} QSI(JVY2b/W9\_FfiPVF]JP]vOKI(X%FHuKc2f`\_FoPKaJQSPV^9FPLFH#KGHJ\_X
Y3I#FlbW9\_F }hFG]QSPQSY3IGHY3ccQ_JVJVF]FPbFPVFcffeO\_FYb[FI#F]b/K\SQS]FlYJT#F]bbW9\_FPVF]JPip Y3T#FI r #QSI#[F]bv
xyyy3 +I1JT9QSPfOKafmF]bv"JT#FKW#JT#YbP%GHY3IOPQSM#F]bk} fiPT9KafmFMZ:Yb/cffWO\SKP]vUQSI1jUT9QgG/T1JT#FiY3W9JVfOW#J
YZKcY3I#Y3cQSK\"QgPI#YJKG]\SKPPp.G]K\S\_FM ff+fmY3PQSJQ_N2F veOW#JKp.I#Y3!I fiI#F][3KaJQSNFGHY3I#^`M#FI9GHFiQgIJT#F
G]\SKPP/Q_^OG]KaJQ_Y3I2KPRfY3P/Q_JQ_NF M9F]Z:KW9\SJ G]\gKPPf9bFMOQSGHJPJT#FYJT#F]bnG]\SKPP]v(G]K\S\_FM ffVI#F][3KaJQSN2F p:JT9QSPRQSPdK
PVF]JVJQSI9[ojUQ_JT-JjnY!G]\SKPPFP Y3c2fOW#JQgI#[ JT9F"G]\SKPP YZmKI2YeOPVF]bNaKaJQ_Y3IemY3QS\SP M#YjUIJVYPW9ccQSI#[hJT#F
GHY3I#^OM9FI9GHFPRYZ7JT9FUb/W9\SFPdQ_JBP/KaJQSPV^9FP]v{KI9MJT9FIM#FG]QgM9QSI#[oJT#F fmY3PQ_JQ_NFUG]\gKPPBQSZJT9F PW9c QSPd[b/FKaJVF]b
JT9KI]F]bY#vdKI9MJT#FkI#F][3KaJQ_NFkG]\SKPP-YJT#F]bjUQgPVF}hFG]QSPQ_Y3IGHY3ccQSJVJVF]FP-Kab/F%Ki[FI#F]b/K\SQSKaJQ_Y3IYZ
JT#FPVFoZ:Yb/c-W9\SKP]vuQSI%jUT9QgG/T%jBFfibFcYNFJT#FoPVF]JVJQgI#([ P"GHY3I9PVJVbKQSIJp:J)jBYG]\gKPPVFPBKI9MKW#JT9Yb/Q_]FfiJT#F
c2FcffemF]b/PT9Q_ff9bFM9QSGHJQSY3IJVY2KabeOQ_JVbKabX2G]\SKPPVFP]vuJT#F]b/F]e(X\SFKM9QSI#[JVY2KffJVb/W#F NYJQSI#[G]\SKPPQ_^OF]b"T9QSP
NYJQSI#[kZ.KPT9Q_Y3I5QSPfiK%Z:FKaJW#bFJT9KaJM#FG]QSP/Q_Y3IiGHY3ccQ_JVJVF]FPPTOKabFjUQ_JTM#FG]QSPQ_Y3IJKaeO\SFPp Y3T9KNuQ r
{Y3ccF]b^9F\SM7v`xyy3#
" YjnF]NF]bv#M#FG]QSPQ_Y3IJKaeO\_FPnG]\SKPPQS^9F]b/PdKabF eOKPVFMY3IcK VYb/Q_J)X2NYJQSI#[-YZ7JT#F
:<;%$

fi

FH#Kc2fO\_FP-p.KI9MI#YJUYZb/W9\_FPv#YNF]boK2bFPVJVb/QgGHJVFM ff+jUQSIOM#Yjfi YZ JT9F!M#FPGHb/QSf9JQ_Y3INaKab/QSKaeO\SFP]R"T#F]X
I#FGHFPP/Q_JKaJVFJT#F2PVJVYb/QSI#[%YZRcKI(XlFH#Kc2fO\_FPvmKIOMiJT9F-QSI(JVF]bf9b/F]JKaJQ_Y3I9PhYZdJT#F2M9KaJKkG]KIY3I9\_XlemF
cKM#FJT#bY3W#[3TJT9QSP!jUQSI9M9Yjv KG]GHYb/M9QSI9[JVYJT9QSPfmYJVFI(JQSK\S\_X\SKab/[FPVF]J-YZ"FH#Kc2fO\_FP]l}hFG]QSP/Q_Y3I
GHY3ccQSJVJVF]FPb/KaJT#F]bbF]fObFPVFI(J KIF G]Q_FIJjLKX-JVYoFI9GHYuM#FKfiNYJQSI#[oc2F]JT#YuM2QSI(JVYoKoPcK\S\{I(WOc!emF]b
YZb/W9\_FP]v3KIOMJT#FjnKX-KoG]\gKPPdQSP [3Q_NFI2G]KIeFLe9b/Y3W#[3TJe`KG -JVYFKab/\_XffjBYb uPdQSIcKGT9QSI#F"\SFKab/I9QSI#[
p \SKa
b r qnY3PVjnF\S\wvxyyux YbFZ:Yb/cK\7M#F]JKQS\gP"KabFf9b/YNuQSM#FMQSIkJT#FI9FH{JUPFGHJQ_Y3I7
c2Y3I#[lY3W9boJT#F]YbF]JQSG]K\RbFPW9\_JPv7JT9KaJKabFf9b/FPVFIJVFMQSI5JT#F2Z:Y3\S\_Yj QSI#[PVFGHJQ_Y3I7vjBFfObYNuQSM#F
Z:Yb/cK\9fObY(YZ.PJT9KaJBJT#F P/QSc2fO\SQgG]Q_JX fiKG]G]W#b/KGHX-JVb/KM#F]Y *QSPRK\SPVYffTOKab/M2JVYffKGT9Q_F]NFhZYbn} v(KPRjBF\S\`KP
Z:Yb0JT#FnGHY3I9PVJVb/WOGHJQ_Y3I!YZ`GHY3c2fO\_FHoNYJVFPQSI(NY3\_NuQSI#[U}fio8"T9QSP0\SKPVJb/FPW9\_JP/T#YjUP0JT9KaJ]vjUTOQS\_FdcQ #QSI#[
+# jUQ_JTemY{Y3PVJQSI#[f9bYNuQSM#FPUY3I#F!YZJT9Fffc2Y3PVJ fmYjnF]bZ:WO\G]\SKPP/Q_^OG]KaJQ_Y3IlK\S[Yb/Q_JT9cP-p.#b/Q_FMOcKI7v
"hKPVJQ_Fv r "Q_eOPTOQ_b/KI9Qwv~avOf9b/W9I9QgI#[oemY(Y3PVJQgI#[ffQSPnFPPFIJQSK\g\_XT#FW#b/QgPVJQSG!p Kab[3QSI#FKI(JW r }fiQ_F]J fi
JVF]b/QSGT7vxyy3
"T9FK\_[YbQ_JT9c jBF5f9bYfmY3PVFZ:Yb%JT9F5QgI9M9W9GHJQ_Y3I YZ!}
v p:Z:Yb FK 1+I9M9WOGHJQ_Y3I YZ
}hFG]QSPQ_Y3I Y3ccQ_JVJVF]FPvdT9KPffJT#F%ZY3\S\SYjUQSI9[ F]XZ:FKaJW#bFP]i)JW9PVFPffbFGHFI(J-b/FPW9\_JP!Y3IfOKab/JQ_JQ_Y3I
emY(Y3PJQSI#[#v3b/KI {QSI9[!\_Y3PPReY{Y3PVJQSI9[pDuG/T9Kaf`Q_bF r uQSI#[F]bvxyy3dKIOMPVY3c2FhKaemY3W#JRf9bW9I9QSI#[oqnY{Y3\_FKI
Z:Yb/cffWO\SKP-p FKab/I9P r KIOPVY3W#bvxyy3

ZY3\g\_YjUPhKkPG/T9Fc2F2G]\_Y3PVFJVY +# & PfiZYboM#FG]QgPQ_Y3I
JVbF]FPfip fffiWOQSI9\SKI7v`xyy +(v9Yb } PnZYbM#FG]QSP/Q_Y3I\gQSPVJPfip UYuG r Kaf9f{Xv7xyy3 zuKPP/W9G/T7vuQ_JLM9Q *mF]b/P
Z:bY3c f9b/F]N{Q_Y3WOPUPVJW9MOQ_FP"QSINYJQSI#[G]\gKPPQ_^9F]bPffp:emY(Y3PJQSI#[#v9eOKa[[3QgI#[p.qnbFQScKI7v0xyy|3V e{XZFKaJW9bFP
PW9GTffKP0JT#FnZ:KGHJ JT9KaJ I#Y c2YuM9Q_^`G]KaJQ_Y3I!QSP0cKM#FBY3I!JT#FnFH#Kc2fO\_F P M9QSPVJVbQ_eOW#JQ_Y3IfiM9W9b/QSI#["QSIOM9W9GHJQ_Y3I7
JBQSPBK\SPVY-Y3I#F Q_Z7Q_JPnM9Q *mF]bFI9GHFPRjUQ_JTJT#Ffi #BE b/WO\_FUQSI9MOW9GHJQ_Y3IKaf9fObY3KG/T5p Y3T#FI r #QSI#[F]bv
xyyy3
fiIcffWO\_JQSG]\SKPPKIOMc-W9\_JQS\SKaemF\{f9bYe`\_FcP] v f9bYfmY3PVFPdK!NF]bX2Z:KPJRKI9MP/QSc2fO\_FPVY3\gW#JQ_Y3I
JVYob/K(I uQSI#[o\_Y3P/P0emY{Y3PVJQSI#[#vYfOJQScK\#QSI-Z.KQ_b/\_X[FI9F]b/K\#G]KPVFP]v{KI9M2KPVXuc2f9JVYJQSG]K\S\SX!Yf9JQScK\{QgI2c2Y3PVJ
YZ7JT#FhbFcKQSIOQSI#[oY3I#FP]dUT#FU[FI#F]bK\Of9b/YeO\_Fc YZ7bK(I {QgI#[!\_Y3PPBemY(Y3PJQSI#[jLKPnf9bF]NuQ_Y3W9P\_XGHY3I VF
G fi
JW#bF
fi "hKab/MpDuG/T9Kaf`Q_bF r uQgI#[F]bvxyy3"T#Y3W#[3TlY3W#b"b/K(I uQSI#[2\_Y3P/P"emY(Y3PJQSI#[2K\_[Yb/Q_JTOc QSP
I#YJLK\_jLKXuPLYf9JQScK\wv{jnFfiK\gPVY-P/T#YjJT9KaJLJT#Fh[FI#F]b/K\b/K(I uQSI#[-\_Y3PPnemY(Y3PJQSI#[!fObYeO\_Fc bF\SKaJVFM%JVY
uGT9KafOQ_bF r uQSI9[F]bffp+xyy3"QgPUKGHJW9K\S\SXkI9Y
J fi " KabM7v`KI9MG]KIemF!PVY3\SNFMQSIfmY3\_XuI#Y3cQgK\mJQSc2Fv
JT#Y3W#[3TQ_JRPVF]FcPdJVY!b/F(W9QSbFJT#FUW9PF"YZGHY3c2fO\_FH2KI9MJQSc2F fiDFHufFIOPQ_NFUK\_[YbQ_JT9cP]vbF\SKaJVFMJVYffJT#F
cQSIOQScQ_KaJQ_Y3IlYZ p.PVXucc2F]JVb/QSGUPW#e`c2Y{MOW9\SKab"Z.W9I9GHJQ_Y3IOP]U"T9QgPUK\SPVY%fOKabJQgK\S\_X VWOPVJQ_^9FPUJT#F-WOPVFffYZ
Y3W#bUP/QSc2fO\_FfiKI9MZ.KPVJUKafOf9bY#QScKaJQSY3IK\_[Yb/Q_JT9cl
"T9F\SKPVJ-PVFGHJQ_Y3IYZJT9QSPfffOKafmF]b!fObFPVFI(JP!FHufmF]b/QSc2FI(JK\dbFP/W9\_JPffYe9JKQSI#FMjUQ_J
Y3I
JT9Q_b/JX fiDY3I#FM#Y3cKQSIOP]v c2Y3PJlYZffj T9QSG/TKabFbFKM9QS\_X1KNaKQS\SKaeO\_FKI9MtG]KIemFZ:Y3W9I9MY3ItJT9
F
bF]fmY3PQ_JVYb/XYZcKG/TOQSI#F\_FKab/IOQSI#[2M9KaJKaeOKPVF%p.qn\gK Fv F]Y[3T7v r F]b/vxyy3
+IYb/M9F]b!JVY F]F]fJT#FfOKafmF]b!PVF\_Z fiGHY3IJKQgI#FMKI9MKPffGHY3IOG]QSPVFKI9MbFKM9KaeO\SFKP!fmY3PP/Q_eO\_Fv7jnF
T9KNFfiGT#Y3PVFI%JVYfOW#JnKIKaf9fmFI9MOQ KaJBJT#FhFI9MYZJT#FhfOKafmF]bnGHY3I(JKQSI9QgI#[ffK\S\`f9bY{YZ.PRYZY3W9bBbFP/W9\_JP]

Cff
< #C aCD? > ?
F]J"
! eF2JT9FI(W9cffemF]boYZG]\SKPPVFP]# I9\SFPPfiYJT#F]bjUQgPVFPVfmFG]Q_^9FM7v0KIFHuKcfO\_F$QSPoKlGHY3W#fO\SF$%
p'&)(*!,]+ UjUT9F]bF"
& QSP KIYeOPF]bN8KaJQSY3IiM#FP/GHb/Q_emFMlYNF]b.
- NaKab/QSKaeO\SFP]v`KI9M/!,
+ Q_JPhGHYbbFPfY3IOM9QSI#[G]\gKPP
Kc2Y3I#[10 2( x3(5464646(*!8
7 x:
9 z3JVYFKGTFH#Kc2fO\_Fp'&)(*!,+ QSPKPPVYuG]QSKaJVFMKfijnFQ_[3T(J<; pVp'&)(*!,+ Vvb/F]f9bFPVFI(JQSI#[
Q_JPfiKaf9fmFKab/KI9GHF-f9bYe`KaeOQS\SQ_J)XkjUQ_JTibFPVfmFGHJfiJVYkK%\_FKab/IOQSI#[P/Kc2fO\_F1=?> jUT9QgG/TijBF2M9QSPfY3PFYZ)@=A>
QSPhQ_JPVF\_ZK%PW#eOPF]JUYZRKjUT#Y3\_F-M#Y3cKQSIijUT9QSGTljnF-M9FI#YJVFCl
B fifie(NuQ_Y3W9P\SXvOjnF-M#Y%I#YJfiT9KNFFI(JQ_bF
KG]GHFPPnJVY1B p'=A>EDF%
B QSI2[FI#F]bK\wvjnFUF]NFI%T9KNFG =?>HGJIKGLB#G p*GM4N3G M9FI#YJVFPRJT9FUG]Kab/M9QSIOK\SQ_JXz3jnF
PW#fOfY3PFhQSIkK\S\JT9KaJLZ:Y3\S\_YjUPLJT9KaJHB QgPnMOQSPGHbF]JVFfijUQ_JT^OI9QSJVFfiG]KabM9QSI9K\SQSJX9 +I%JT#FfifOKabJQSG]WO\SKabG]KPVF
:PORQ

fi

iwc


ffff

jUT#F]b/FA! %t~{v(JT#FLJjnY!G]\SKPPFPKabF"I#YJVFM ff fi p'!,+ % KI9M ff p'!,+ % xvKIOM2G]K\S\_FMbFPVfmFGHJQ_NF\SX
JT#FkI#F][3KaJQ_NFKI9MfmY3PQ_JQ_NF%G]\SKPP]5"T#F%\_FKab/I9QSI9[iPKc2f`\_FQSPffJT#FkW9I9Q_Y3IYZ"JjnYPKc2fO\SFP]vI#YJVFM
=?>KI9
=A>Bv(GHY3I(JKQSI9QSI#[!bFPVfmFGHJQ_NF\_XJT#FhI#F][3KaJQ_NF KIOMfmY3PQ_JQ_NFFH#Kc2fO\SFP] )JnQSPjnYbJTj T9QS\_F
JVY-JT9QS(I -JT#FUfmY3PQSJQ_NF"FH#Kc2fO\_FPBKPRemF\_Y3I#[3QgI#[oJVY-KffPW#eOPF]JdYZ B GHY3IJKQgI9QSI#[-K\S\9fmY3PPQSeO\_FLfmY3PQ_JQ_NF
FH#Kc2fO\_FP]v9WOPW9K\S\_XG]K\S\_FMJT#F " 3{ ff
.
PfifOKabJoYZBY3W#bo[Y3K\dQSI5cKGT9QSI#F2\_FKab/IOQSI#[#v7QSPhJT#FI#F]FM5JVYeOWOQS\SMKkb/F\SQSKaeO\_F-Kaf9f9bYuQgcKaJQ_Y3I
JVYJT#F!JVb/W#FG]\SKPP/Q_^OG]KaJQ_Y3IkYZ JT#FFH#Kc2fO\SFP"QS
Blv9JT9KaJUQSPv9K[Y(YuMKaf9fObY#QScKaJQ_Y3IkYZ JT#FoJKab/[F]J
GHY3I9GHF]f9J]ve{X!W9P/QSI#["Y3I9\SXoJT#FBFH#Kc2fO\SFP0QS"
=?>n Y{Y{M-Kaf9f9b/Y#QScKaJQ_Y3I9P PT9K\g\T9KNFLKhT9Q_[3TffKG]G]W#b/KGHX
YNF]b Blv{K\_JT9Y3W#[3T2jnF M#Y!I9YJRT9KNFfiKG]GHFPPBJVY!JT9QgPd(WOKIJQ_J)Xv(e`W#Jdb/KaJT#F]bBJVYffQ_JPdFPVJQScKaJVY2b Kffc2YbF
Yb\_FPPb/F\SQSKaeO\_F%KG]G]W#b/KGHXGHY3c2fOW9JKaeO\_FkYNF]b =?>n FlbF]Z:F]b2JT#FkbFKM#F]bJVYPVJKIOM9Kab/McKG/TOQSI#F
\_FKab/IOQSI#[emY(Y uPffp Q_JG/T9F\S\wvxyy3"ZYb Z:W9bJT#F]bUGHY3I9P/QSM#F]b/KaJQ_Y3IOP"KaemY3W#J"JT9QSPUQSPPW#F } GHY3IJKQgI9P
JjnYf`KabJP

fi

0(p ff ( P9 ( . j T#F]bF"FKGT 7QSPdK!cY3I#Y3cQSK\p.KffGHY3I!fi
( . (5464646( ( 9 p -emFQSI9[ JT#F"I{W9cffemF]b YZmM#FPGHbQ_f9JQ_Y3I
NaKab/QSKae`\_FP]v7FKG/T!#"QSPoKfmY3PQ_JQ_NF2\SQSJVF]b/K\ KI9MFKG/T #"QSPoKI#F][3KaJQ_NF%\SQ_JVF]b/K\vKIOM5FKG/T$
QgPffKiNFGHJVYbQSI!% &(H' 5#YbJT#F%P/KF%YZUbFKM9KaeOQS\gQ_JXv JT9QSPffNFGHJVYb/QSK\LI#YJKaJQSY3IP/T9K\S\demF F]f9J

PVF]JBYZ7W9I#Yb/M#F]b/FM2fOKQ_b/P p:YbRb/W9\SFP
W9I9GHJQSY3IYZ`\SQ_JVF]bK\SPYNF]bH0 ( ( ( ( .

JT9bY3W#[3T#Y3W#JK\S\JT#FfifOKafmF]bvuF]NFIZ:Ybf9bYe`\_FcPBjUQ_JT%Y3I9\_XJ)jBYG]\SKPPVFP]BoI#FocQ_[3T(JLGT#Y{Y3PVF
JVYKM9MlKPQgI#[3\_FfibFK\7b/KaJT9F]b"JT9KIlK~ fiGHY3cfY3I9FIJ"NFGHJVYbfiQSIJTOKaJ"G]KPVF

}hF]Z:KW9\SJ FGHJVYb ) QSI - 2(x / ' [3KQSI7v7QSIiJT#FJjnYfiG]\SKPPG]KPFvQ_JfiQSPfiPW(G]Q_FI(JhJVY%b/F]fO\SKGHF
) e{XkK2M9F]Z:KW9\SJ"G]\SKPP"QSI0 ( 7 93
#YbffKIXiYeOPVF]bNaKaJQ_Y3I%
& KI9M5KIX5c2Y3I#Y3cQgK\* v7JT#Ff9bYfmY3PQ_JQ_Y3I ff &kPKaJQSPV^9FP+ QgPhM9FI#YJVFM
e{X&-,. "T#F2YfOfY3P/Q_JVFfffObYfmY3PQ_JQ_Y3Iff k
& M#Y{FPoI#YJPKaJQSPVZ:X/ QSPfiM#FI#YJVFMe{Xff &1,2
0 u2"T#F
G]\SKPP/Q_^OG]KaJQ_Y3IkYZKI(X%Ye`PVF]bNaKaJQ_Y3I
& QSPcKM#FffQSIkJT#FoZ:Y3\S\_Yj QSI#[jnKX nM#F]^OI#F 3 h
+ KP"Z:Y3\S\_Yj P
3 + %
4
4
p (
&5,6

fi



"T9FG]\SKPP"KPP/Q_[3I#FMJVY&QSP"JT#FI9

fi Kab/[BcK8 " 3 + Q_ZAGKab[ncK8 " 3 + G % xavOKI9M
fi Kab/[BcK8 "87
9J9:<;>A=? @ ) YJT#F]b/jUQSPVF

+ IYJT#F]bBjBYbM9P]v(QSZJT9FUcK8#QScK\9GHY3c2fmY3I#FI(JRYZ 3 + QSPRWOI9QS{W#FvJT#FIJT9F QSI9M9FH-[3Q_NFPBJT#FUG]\gKPP
KPPQS[3I#FMJVYC&{BhJT#F]b/jUQSPVFv{jBFhJKFoJT#FfiQSI9M#FHYZJT#FocK8uQgcK\OGHY3c2fmY3I#FI(JLYZ ) GHYbb/FPVfmY3I9M9QSI#[
JVYkJT#F2cK8#QScK\ GHY3c2fmY3I#FIJfiYZ 3 +%p:JQ_FPfiKabF2PVY3\_NFM5e{XK%b/KI9M#Y3cG/T9Y3QSGHF2Kc2Y3I#[kJT#F2cK8#QScK\
GHY3c2fmY3I#FI(JP
} GHY3IJKQSIOP-KPW#e7G]\SKP/PojUT9QSGTQSP-Kc2Y3I#[iJT#Fk\SKab[FPVJG]\SKPPVFPffYZ"qnY(Y3\SFKIZ:Yb/c-W9\SKPffJVYiemF
r KPG]W#F\wv9xyy 3v{T#YjnF]NF]bJT9QSP G]\SKPP QSP \_FPP QSI(JVF]bFPVJQSI9[UZ:bY3c KUf9bKGHJQSG]K\
fi\_FKab/IOKaeO\_Fop UYuG
NuQ_F]j"fmY3QSI(JfiP/QSI9GHFb/W9\_FPoG]KIemFI(W9cF]bY3W9PoKI9MTOKab/MJVYQSI(JVF]bf9b/F]J] UF]NF]bJT9F\_FPP]v KlPW#e7G]\SKPPfiYZ
} p UYuG r KP/G]W#F\wvRxyy 3hfObFPVFI(JPoKIQSI(JVF]bFPVJQSI#[kGHY3c2f9b/Y3cQSPVFemF]JjnF]FIbF]f9b/FPVFIJKaJQSY3I9K\
fmYjnF]bKI9M QgIJVF]bfObF]JKaeOQS\SQSJXfmYjnF]b +ItJT9QSPG]\SKP/P]vfijUT9QSGTQgPlW9PVFMe{X !vFKGT YZJT#F
NFGHJVYbLGHY3c2fmY3I#FIJPRKabF"bFPVJVbQSGHJVFM2JVC
0 73x (2 ( :x 9fiKI9MFKG/TcY3I#Y3cQSK\#QSPdf9bFPVFI(JdKaJRc2Y3PVJRY3I9GHF
:PO5:

fi

"T#FkNaK\SW#FP 7xavnuv xK\g\_Yj I9KaJW#bK\QSIJVF]b/f9bF]JKaJQ_Y3I9PYZ JT#Fb/W9\SFP]vemFQSI#[FQ_JT#F]bQSIZ.KNYbYZ
JT#FGHYbbFPfY3IOM9QSI#[G]\SKPPlp xvnI#FW#JVb/K\njUQ_JTbFPVfmFGHJJVYJT#FG]\SKPPlp.vBYbQSIM9QSPVZ.KNYb2YZ JT#F
GHYbbFPfY3IOM9QSI#[%G]\SKPP2p 7x!"TOQSP P/W#e7G]\SKPP]vJVYkjUT9QSGTjnFbF\SKaJVF2KPo} ( 0 ( v7QSP]v7KPfijBF2I#Yj
f9bYNFvnP/W *F]bQSI#[JT#FPKc2FlK\_[Yb/QSJT9cQSG%M#b/Kj"eOKG uPKP2}fi p " X3Ka^O\ r EUQSNFPVJ]v xy3a|3KI9M}
p Y{
G r Kaf9f{Xv7xyy3< RF]NFI%jUQ_JT9Y3W#JRbFPJVb/QSGHJQSI#[ffJT#FoGHY3c2fmY3I#FI(JPBYZJT#F NFGHJVYbP]v9YbLjUQ_JT%KIX
bFPVJVbQSGHJQ_Y3IJVY5KPVF]J2GHY3I(JKQSI9QSI#[KaJ2\_FKPVJ-Y3I#Fb/FK\BNaK\SW#FvJT9F%GHY3I9PJVb/W9GHJQ_Y3IYZUPcK\g\RZ:Yb/c-W9\SKP
jUQ_JTP(W G]QSFIJ\_XT9QS[3TKG]G]W#b/KGHXQSP!TOKab/M7"TOQSP!QSPffKiG]\SFKabcYJQ_N8KaJQSY3IZ:Yb-WOPQSI#[T9FW#b/QSPVJQgG]PQSI
M#FG]QSP/Q_Y3IGHY3ccQ_JVJVF]F P QSI9M9WOGHJQ_Y3I7
?Cff > @}C C
d< ABC@BC >
fiff z N#AJ # C aC? > %

(@

F I9YjPT#Yj1JT9KaJRe`W9QS\SM9QgI#[ M#FG]QgPQ_Y3IGHY3ccQ_JVJVF]FPBQgPdK!T9KabMK\_[Yb/Q_JTOcQSGLJKP 2jUT9FI2Y3I#FUPVJVbQ_NFP

JVYYe9JKQgIkeYJTP/cK\S\mKI9MlKG]G]W#bKaJVFZYbcffW9\gKP]d"T#F]bFoKabFoJ)jBY%W9PW9K\mI#YJQSY3I9PLYZ P/Q_]FojUT9QSGTG]KI
I9KaJW#bK\S\_X%eFffW9PVFMlZ:YbfiM#FG]QSPQ_Y3IGHY3ccQ_JVJVF]FP] "T#F!^Ob/PVJ"Y3I#F-QSP"JT9F!jUT#Y3\SF!I(WOc!emF]bUYZd\gQ_JVF]b/K\SPYZ
r KPG]W9F\wvxyy {z
JT#FZYb/c-W9\SKp.Q_ZK\SQ_JVF]bK\dQSPfObFPVFI(
J hJQSc2FP]v Q_J!QSPffGHY3W9I(JVF
hJQSc2FPp UYuG
r Kaf9f{Xvxyy3vRJT#FkPVFGHY3I9MY3I#FkQSPJT#FkI{W9c!emF]bffYZ"b/W9\_FP!YZ"JT#F%ZYbcffW9\gKp FKab/I9Pv Qwv
Y{
G
RQSJVJ]v r dK\SQSKI(J]v0xy3fiW#bUb/FPW9\_JP"Qgc2fO\_X%JT9KaJhbF][3Kab/M9\_FP/P"YZJT#FffbFPVJVb/QSGHJQSY3IlYNF]bfiJT#F-NaK\SW#FP
YZJT#FffNFGHJVYb/P2p.KP \_Y3I9[KP JT#F]XKabFffF\SFc2FIJP YZdKPF]JUjUQ_JTG]Kab/M9QSI9K\gQ_J
X t~3vKI9MiK\_bFKM#XkZ:Yb
JjnY fiG]\SKPPFPfif9bYeO\_FcP]vOcQSIOQScQ_QSI9[-JT9FffPQ_]FffYZdKM9FG]QSPQ_Y3IiGHY3ccQ_JVJVF]F-ZYbhemYJTPQS]FffM#F]^OIOQ_JQ_Y3I9P
QSPoKPTOKab/MKPPVY3\_NuQSI#[%jnF\S\ fi uI#YjU
fi "hKab/M5f9bYe`\_FcP]"T#F]bF]Z:YbFvJT9F-JKP 5QgPoK\SPVYT9Kab/M5Z:Yb
} ( 0 ( jUQ_JTkJT9FfOKabJQSG]WO\SKabLN8K\SW9F@
P 7xavOuv xfiZYb"JT9FNFGHJVYb/P]

! #"%$3'&("*))%+-, '.0/1"2.43#5" 6.874.:9 <;8" =3?>@A"*)CBAD75"6;'.
#
" E"F> HGI %KJML ":PRQSJ %UT "%<$ WV "%J %YX ! $ZT ] [N !\J ] "! %K]^J J % _
` " [V ba V %KT "! ! % cV dJ %eJ fTgTgJ (%KJ % XhJ " % [N ji "fT
! % =?> 1
k36)jl {F]FoJT#F f9fmFI9M9Q_

F%G]KIFKPQg\_XKMOKaf9J!"T#F]Yb/Fc x2JVYiJT#FG]KPVFjUT#F]bFJT9Fb/W9\_FP!KabFbF]fO\gKGHFMe{XjnFQ_[3T(JVFM
}fi KPKM#NYuG]KaJVFMQSIeY{Y3PVJVFM +# pDuG/TOKafOQ_bF r uQgI#[F]bvUxyy3 "UF]bFvnFKG/T JVbF]FlbF]JW9b/I9P2K
G]\SKPPm 0 x3( 7x:93vKI9MFKG/T JVbF]FlQSP[3Q_NFIK5b/FK\LjBFQ_[3T(J2JVY\_F]NF]bKa[FlQ_JPNYJVF"T#FPQ_[3IYZ
JT#F\gQSI#FKab!GHY3cffeOQSI9KaJQSY3I[3Q_NFPJT9FG]\SKPPYZ"KIFHuKcfO\_Fk"T#F2Z:Y3\S\_Yj QSI#[JT#F]YbFc T#Y3\SM9P!Ka[3KQSI
jUQ_JTkKI(X\SQgcQ_JKaJQ_Y3I9PBY3IJT#Fo\_F]NF]bKa[3QSI#[2GHY(F G]Q_FIJPffp.KP"\_Y3I#[2KPKaJ"\_FKPVJY3I9FfiI9Y3!I fiD]F]bY2NaK\SW#FoQSP
KW#JT#YbQ_]FM`v{YbRjUQ_JT9Y3W#JR\SQScQ_JKaJQ_Y3I2Y3IJT#F GHY{F G]Q_FI(JP]dqnX2JT9QSPvjnF c2FKIJT9KaJRZ:YbnFKG/T%YZ7JT#F
Kaf9fO\gQSG]KaeO\_F!\gQScQ_JKaJQ_Y3IOPffp:YbfijUQ_JT#Y3W9JvJT9Ffff9b/YeO\_Fc Qg
P fi "hKab/M7o"T#FPQ_]FI#YJQ_Y3IQSP JT#F2PW9cv
YNF]bfiK\S\mJVbF]FPv9YZ JT#FQ_b"I{W9c!emF]bYZI#YuM#FP]

#" E"F>onqp
J % :_` " OV V %KT "! ! %
%KJ % XhJ " % [N Wi "fT
! % =?> ]vXhJ $ !wJ'TgJ "
"
%<%KJ ! !wJ'TgJ " J 2]."% ! 3 "% " ! "%

X J 3 jV !\J " fT rJ " J (%-ONsPut _
! ] aH " 3 J 3 yx dJ %j]+ N8
_ L H "!4$ J % "$ JML jV61
T9QS\_FffQ_JUQSPUjBF\S\ {I9YjUIJT9KaJ emY{Y3PVJQSI#[2b/FPW9\_JP QSIlKb/KafOQSMlM9FGHbFKPQSI#[YZJT#FffF]b/bYbUYNF]b =A>



J

jUT9QgG/TG]KI%FKPQg\_X2KI9MbKafOQSM9\_XM#bYf%M#Yj IJVY-]F]bYp.KPn\SY3I#[ffKPnQ_JBQgPdfmY3PPQ_e`\_Fv"T#F]Yb/Fc ~!PT#YjUP
JT9KaJoKaJVJVFc2f9JPfiJVYkF G]QSFIJ\_XbFM9W9GHFJT#FPQ_]F-YZRJT#F-NYJVF2jUT#FIemY{Y3PVJQSI#[%}h QSP fi "hKab/M7fi)Z
JT#F f9bYeO\_Fc QSPdPQScfO\SQ_^9FM-JVYffJT#FUJVY-f9b/W9IOQSI#[hYZK!\SKab[FhGHY3I9PQSPJVFIJBNYJVF YZ}fi p Kab[3QSI9FKIJW r
}fiQ_F]JVJVF]b/QSGT7v7xyy3v9JVYYe9JKQSI%KPcK\S\_F]bnGHY3I9PQSPJVFIJp:YbLjUQ_JT%\SQScQSJVFMF]bbYbHNYJVFfijUQ_JTbFPVJVbQSGHJVFM
PQ_]Fv#Q_JQSPLKa[3KQSIkfmY3PP/Q_eO\_Fp.W9PQSI#[-JT#FoPKc2Fob/FM9W9GHJQ_Y3I`dJVYPT#YjtJT9KaJJT9QSPne9bQSI#[3?
P fi "hKab/M9I9FPP]
:POEz

fi

n

iwc


ffff

#"%$3'&("*))%+-, ' .0/1"2.43#5" 6 .874.G=3?>@A"*)) 3 ;'"F.


FffI9YjPVJKaJVF-KI9Mkf9bYNF!JT#FoF{W9Q_NaK\_FI(JYZ"T#F]YbFc

xfij Q_JTkJT9QSP"I9F]jPQ_]FI#YJQSY3I7

#" E"F> GI %KJML [N "-PuQ J %uT "%<$ WV "%J % $ZT ] [N $ ! %j] J J % _` " OV
= > 1 % %<$ !
V %KT "! ! % UV( J %KJ fTgTgJ (%KJ % XhJ "% [N Wi "fT
! %
! V % H %X
!#" !\J 3 %Wi "fT
! %:J % "T r_ P N8
$ !#"E] " J %j]fi"
V J % $ J [N $# J
'Pff fi5] "6 XhJ $ 3 " J !\J H "! % 1
k36)jl {F]FoJT#F f9fmFI9M9Q_




fObF]N{QSY3W9PjnYb 1p FKabI9P-F]JK\D_vLxy3fffObYNFP2KPQScQg\SKabJT#F]YbFc GHY3IOGHF]b/I9QSI#[iJT#FkcQSI9Q fi
cQ_KaJQSY3IkYZJT#FPQS]FhYZ K2} nO"T9F]YbFc-G]KIemFfiP/T#YjUI%JVYemFfic2YbFo[FI#F]bK\wv9KPLJT#FG]\SKPPLYZ
} ( 0 ( jUQ_JTkJ)jBYb/W9\_FPPJVb/QSGHJ\_X%GHY3IJKQSIOP"JT9KaJ"YZ } j Q_JTkJjnYc2Y3I9Y3cQSK\SP]
"T9F-PVJKaJVFcFIJfiYZBUT#F]YbFcP-xav~{v KPhYf9JQScQ_KaJQ_Y3Iif9bYeO\_FcPUjLKPfiG/T#Y3PVFI5Z:YbhfOW#bF-GHY3I!fi
NFI9Q_FIOGHFffzubF]fO\gKG]QSI#[JT#Fc e{XJT#FQ_bLKPPVYuG]QSKaJVFMkM#FG]QSP/Q_Y3If9b/YeO\_FcPhp.M#FG]QSM#FhjUT#F]JT#F]bnJT#F]bFhFH#QSPVJ
KGHY3I9PQSPJVFIJnZYbcffW9\gK!jUT9Y3PVFhP/Q_]FhQgPnI9Y-c2Yb/FhJTOKI%PY3c2F ^9{FM%JT#bFP/T#Y3\SM`jBY3W9\gMJVb/QSN{QSK\g\_X2cK F
JT#FfObYeO\_FcPLI#YJUY3I9\_#
X fi "hKab/M7v9e`W#J"K\SPV
fi Y3c2f`\_F]JVF

< C ?
IlK\_[Yb/Q_JTOcv#} vOjnKPUf9bF]NuQ_Y3W9P\_Xf9bYfmY3PVFMp Y{
G r KPG]W9F\wvxyy 3"ZYb eOW9QS\SMOQSI#[!M#FG]QgPQ_Y3I
HG Y3ccQSJVJVF]FP])Jf9bYuGHF]FM9P2QSIJ)jBYPJKa[FP]"T#Fk^9b/PVJPVJKa[Fle`W9QS\SM9PffK5fmYJVFIJQSK\g\_X\SKab[FlP/W#eOPVF]J
YZLM9Q *mF]bFIJfib/WO\_FP]vmFKG/TYZRjUT9QgG/T5QSPoKGHJW9K\S\SXiK} ( 0 ( jUQ_JTY3I9\_XiY3I#F2b/W9\SFIKPFGHY3I9M
PVJKa[Fv Q_Jo[b/KM9WOK\S\_XiG]\gW9PVJVF]b/PoJT9FM#FG]QSPQ_Y3IGHY3ccQ_JVJVF]FP]v W9PQSI9[%JT9Ff9bYfmF]bJ)XiJT9KaJ!JT#FW9I9Q_Y3I5YZ
JjnY!} ( 0 ( Pj Q_JT2M9Q *mF]bFI(J bW9\_FPQSPPVJQg\S\uKo} ( 0 ( JRJT#FFI9MYZmJT9QSP f9b/Y{GHFM9W9bFvJT#F
W9PVF]bnYe9JKQSIOPRK-PVF]JBYZ} Pv{KI9MJT#Fhc2Y3PVJLKG]G]W#b/KaJVFfiY3I#F QgPBGT#Y3PVFI%KI9Mb/F]JW#b/I#FM7 d{fmF]b/QScFIJK\
bFPWO\_JPM9QgPVfO\SKXhJT9FnKaeOQg\SQ_JXoYZ#+} JVY eOWOQS\SMPcK\S\} P] +I!JT9KaJ fOKafmF]bv8jnFBf9b/YNuQSM#FBKIK\_[YbQ_JT9c
Z:YbR\_FKab/I9QgI#[oM#FG]QSPQ_Y3I2GHY3ccQ_JVJVF]FPBjUT9QSGT2T9KPRKMOQ *F]b/FIJdPVJVbW9GHJW#bF"PQgI9GHF"Q_JeOW9Qg\SM9P0Y3I9\_X-Y3I#FU}
YbFof9bFG]QSPF\_Xv QSPLKJT#b/F]FfiPJKa[F!K\_[Yb/Q_JTOc )JL^9b/PJne`W9QS\SM9PBKPVF]JYZb/WO\_FPLM#F]b/Q_NFM%Z:bY3c
bFPWO\_JPY3IlemY{Y3PVJQSI#[2M#FG]QgPQ_Y3IJVbF]FPpDuGT9KafOQ_bF r uQSI#[F]bvxyy3nJ"JT#FIiG]K\SG]W9\SKaJVFPUJT#FNFGHJVYb/P
W9PQgI#[KP/G/T#Fc2FkM#F]b/QSNFMZ:bY3c EUK(I uQSI#[\SY3PP!emY{Y3PVJQSI#[pDuG/T9Kaf`Q_bF r uQSI#[F]bvnxyy35J!^OI9K\g\_X
f9b/WOI#FPhJT#F^OI9K\ } ( 0 ( W9PQSI#[%JjnYlfmY3PPQSeO\_FffP/G/T#Fc2F2P fiKIOKaJW#b/K\ f9b/W9IOQSI#[j T9QSG/TjnFG]K\S\
ff+fmFPPQScQSPVJQSG%f9b/WOI9QSI#6
[ uvRKIOMf9b/WOI9QSI#[5W9PQSI9[\_Y{G]K\UGHY3INF]b[FIOGHFb/FPW9\_JPlp FKabI9P r KI9PY3W#bv
xyy3v jUT9QSGT5jBFG]K\g\ ff+Yf9JQScQgPVJQSG-f9b/W9IOQSI#6[ uffUT#FM#F]Z.KW9\_JfiNFGHJVYb-QgPoK\_jnKX{PffG/T#Y3PFIJVYlemF2JT#F
YeOPVF]b/NFMlM9QSPVJVbQ_eOW#JQ_Y3IYZKc!e`Q_[3W#Y3W9P\SXG]\SKPPQS^9FMkFHuKcfO\_FP]


B&$*"=+"'.r'" ,j<> > 8 7d74"F" 3#.r#"($ kN$5787'"
! 3';S#"%$

6. 7#"($

3

u W#fOfY3PFUJT9KaJJT#FT(X{fYJT9FPQSPop.I#YJI#FGHFPPKabQS\_XKM#FG]QgPQ_Y3IkGHY3ccQ_JVJVF]Fv`Q_JcQ_[3T(JBemF214351BKM#FG]Q fi
PQ_Y3IJVbF]F jnFUe`W9QS\SMbFK\gQ_]FPRK!fOKabJQ_JQ_Y3IYZ7JT#FUM#Y3cKQgI B QSI(JVYffM9QSP+Y3QSI(JdPW#e`PVF]JP*) ( (+) . (5464646(+)-,ff
Q KP - - . / /0JT#FoZ.W9I9GHJQ_Y3IlbF]JW#b/I9QgI#[ffJT9FJVb/W#JTkNaK\SW#FoYZKf9bFMOQSG]KaJV/
F . d}hF]^OI#F

0 " 1 %
0 " 1 %

4
; pVp'&)(*!,+V - -_p'&)(*!,+vm)5"76 ,! +A%98 / / (
+, ' @ 1 73254
4
; pVp'&)(*!,+V - -_'p &)(*!,+vm)5"76 ,! + %9
0 8 / / 4
+, ' 2@ 1 37 254
:PO ;

fi

"

+IkYJT#F]b"jnYb/M9P]v 0 1 bF]f9bFPVFI(JPJT#FfiZ:b/KGHJQ_Y3IYZ FH#Kc2fO\_FPLYZ G]\SKPP 80f9bFPVFI(J"QSIkPW#e`PVF]J )5"v
"
KI9M 0 1 bF]fObFPVFI(JPBJT9FhZ:b/KGHJQ_Y3I%YZ0FHuKc2f`\_FPnYZ0G]\SKPPFP %9
0 8f9b/FPVFIJLQSI%PW#eOPF]J )5"3 G]GHYb/MOQSI#[

JVY%uGT9KafOQ_b/F r uQSI#[F]b!p+xyy3vmKjnFK l\_FKab/I#F]b"PT9Y3W9\SMcQSIOQScQ_]F JT#F!GHb/Q_JVF]bQ_Y3I9

%

~ 4

0 " 1 0 " 1 4

" 1
4

p+x

+IJT#F%G]KPVF%YZLKM#FG]QSP/Q_Y3IJVbF]Fv JT#FfOKabJQ_JQ_Y3IQSPJT9KaJffjUT9QSGTQSPeOW9QS\_JKaJffJT#F\SFKNFP-YZJT#F
JVbF]FpfifffiWOQSI9\SKI7v xyy+(z0QSIJT#FG]KPVFYZnKM#FG]QSPQ_Y3I5\SQgPVJ]vmJT#F2fOKabJQ_JQSY3IQgP JTOKaJojUT9QSGTQSPheOW9QS\_JhKaJ
FKG/TkbW9\_FvJVY-jUT9QgG/TjnFfiKM9MJT9F PW#e`PVF]JBKPPY{G]QSKaJVFM%JVY-JT#FfiM#F]Z:KWO\_JRG]\SKPPop Y{G
r Kaf9f{Xv7xyy3
uW#fOfY3PFJT9KaJhjBF-FI9GHYuM#F!JT#FM#FG]QSP/Q_Y3IlJVbF]FQSIJT#FffZ:Yb/c YZdKP/W#eOPVF]J YZRc2Y3I#Y3cQgK\SP]vOe{XJK uQSI#[
Z:Yb"FKG/T\_FKaZ JT#F!\_Y[3QgG]K\ fi 6YZK\S\7KaJVJVb/Q_e`W#JVFP"Z:bY3c JT#F!bY(YJUJVYJT#F!\_FKaZ FKPW#bQSI#
[ YNF]bhJT#F
JVbF]F P\_FKNFPQSPnF(WOQ_N8K\SFIJBJVYcFKPW#b
F YNF]bJT#F f`KabJQ_JQ_Y3IbFK\SQ_]FM%e{XJT#FfiPVF]JLYZc2Y3I#Y3cQSK\SP]
" YjnF]NF]bvdJT#Fkc2Y3I#Y3cQgK\SP!KabF%M9QSP VY3QSI(JZ:bY3c FKGTYJT#F]bkp:FKGTFHuKcfO\_FP/KaJQSPV^9FPffFHuKGHJ\SXY3I#F
c2Y3I#Y3cQSK\ }hW9FiJVYJT9QSPf9bYfmF]bJ)Xv"Y3I9\_X PW#eOPVF]JP%G]KIemFbFK\gQ_]FM j Q_JT c2Y3I#Y3cQSK\gP]vYb
F{W9Q_NaK\_FIJ\SXjUQ_JTKJVbF]F!T9KN{QSI9[ n\_FKNFP]
uW9f9fmY3PVF"JT9KaJBjBFh[FI#F]b/K\SQS]FUJT9QSPRYeOPVF]bNaKaJQ_Y3Ie(X2b/Fc2YNuQSI#[ffJT#FhMOQSP VY3QSIJI9FPPdGHY3I9M9QSJQ_Y3IYNF]b
JT#Fc2Y3I#Y3cQSK\SP] "T#FIKI(W9cffemF]bkYZ-PW9eOPVF]JP%YZffYbM#F]
b kpw~ )QSPI#Yj fmY3PP/Q_eO\_FijUQ_JTY3I9\_X
c2Y3I#Y3cQSK\SP]v"KI9MQ_JkKaf9fmFKab/PJT9KaJkJT#FI(WOc!emF]b%YZbFK\SQ_]FMfOKab/JQ_JQ_Y3I9PG]KIeFFHufY3I9FIJQSK\g\_X
\SKab[F]bfiW9PQgI#[M#FG]QSP/Q_Y3IGHY3ccQ_JVJVF]FPfiJT9KIM#FG]QSPQ_Y3IJVbF]FP] "UYjBF]NF]bv7JT#FffFHufmFGHJVFMbW9I9I9QSI9[2JQSc2F
QSP%I#YJe`Q_[[F]bkjUT#FI WOPQSI#[M9FG]QSPQ_Y3I1GHY3ccQ_JVJVF]FP]vhPQSI9GHFiJT#F5I(W9cffemF]bYZf`KabJQ_JQ_Y3I9PQSP%QSIZ.KGHJ
emY3W9I9M#FMe{XJT#F I{W9cffemF]bdYZ7FHuKcfO\_FP]v G =?> G"T{W9P]v(jBFhcKXFHufFGHJnPVY3c2F bFM9W9GHJQ_Y3IQSIJT#F PQ_]F
YZJT#F ZYbcffW9\gKjnF eOWOQS\SMjUT#FIW9PQSI9[!M#FG]QSPQSY3IGHY3ccQSJVJVF]Fv{j T9QSG/TQSPBYZQSIJVF]b/FPVJBJVYQSI(JVF]bf9bF]JBJT#F
G]\SKPP/Q_^9F]bYe9JKQSI9FM7
f9fO\SQgG]KaJQ_Y3IYZJT9QSPBf9b/QSI9G]QSfO\_F"QSI QgPBPVJVbKQ_[3TJVZ:YbjLKab/9
K\SKab[FoM#FG]QSP/Q_Y3IGHY3ccQ_JVJVF]FQSP
eOW9Qg\_JBe{X%[bYjUQgI#[2Q_JVF]b/KaJQ_NF\_Xv`QSIkKJVYf fiM#Yj IlZ.KPT9Q_Y3I7v#K2G]W#b/bFIJc2Y3I9Y3cQSK\w+IkJT9QSPc2Y3I9Y3cQSK\wv
JT#F"\SQSJVF]b/K\uKM9M#FM2KaJdJT#F"G]W9bbFI(J PJVF]fQSP JT#FY3I#Fj T9QSG/T2cQSI9QScQS]FPJT#F"G]W9bbFI(
J 1GHb/QSJVF]b/Q_Y3I7vYNF]b
K\S\mfmY3PPQSeO\_F KMOM9Q_JQ_Y3I%YZ\SQ_JVF]b/K\gP]v{KIOMk[3Q_NFIJT9KaJ"JT9FI#F]j c2Y3I#Y3cQgK\7M#Y(FPUI#YJFHuQgPVJ"K\_bFKM#X%QSI
JT#FnG]W#bbFI(J0M#FG]QgPQ_Y3IGHY3ccQ_JVJVF]Ffip.QgIYb/M#F]b JVYUfObF]NFIJ c-W9\_JQ_fO\SFdKM9M9Q_JQ_Y3IOP7YZ9KUPQgI#[3\_FRc2Y3I9Y3cQSK\
"T#

F GHb/Q_JVF]b/Q_Y3I QSPGHY3c2fOW9JVFM1W9P/QSI#[JT#Flf`KabJQ_JQ_Y3IQgI9M9W9GHFMYNF]b =A> e{XJT#FiG]W9bbFI(JPVF]JYZ
c2Y3I#Y3cQSK\SPeOW9Qg\_Jlp.Q_Z J)jBYFHuKcfO\_FPPKaJQgPVZXJT#FP/Kc2Fc2Y3I#Y3cQSK\SP]vnJT#F]XeF\SY3I#[JVYJT#FiPKc2F
PW#e`PVF]JYZ JT#FkfOKab/JQ_JQ_Y3I` T#FII9YZ:W#b/JT#F]b2KM9M9Q_JQ_Y3IYZhK\SQ_JVF]b/K\LM#FGHbFKPFP2JT#
F N8K\SW9FvBK
I#F]j c2Y3I#Y3cQgK\0QSPhGHbFKaJVFMKI9M5QSIOQ_JQSK\SQ_]FMKa
J ff{v7KI9MiJT#FI5QSP [bYjUI5W9P/QSI#[JT9F-PKcFfff9bQSI9G]Q_fO\SF
T#FII9YZ.W#bJT#F]b!GHb/FKaJQ_Y3IYZ"Kc2Y3I#Y3cQSK\RM#FGHb/FKPVFP-JT#fi
F NaK\SW#Fv JT#FkK\_[Yb/Q_JT9c PVJVYfOP-KI9M
bF]JW#bI9P JT#F"G]W#bbFI(J]v\SKab/[FLM9FG]QSPQ_Y3I2GHY3ccQ_JVJVF]FjUQ_JTPVJQS\g\(Fcf9JX-NFGHJVYb/P]+IJT#FZ:Y3\S\_Yj QSI#[fiPVJVF]fv

G]K\SG]WO\SKaJVFPhJT#FPVF-NFGHJVYb/P]U+IKf9bF]NuQ_Y3W9P Kaf9f9bY3KGTJVYeOWOQS\SM9QSI9[ffb/WO\_F!PVF]JPhZ:Yb f9b/YeO\_FcP
jUQ_JT-J)jBYG]\SKP/PVFP"p Y3T#FI r uQgI#[F]bv#xyyy3v{KI2QSJVF]b/KaJQ_NFL[bYj QSI#[ fiDf9b/WOI9QSI#[hK\_[Yb/Q_JT9c QSP M#FP/Q_[3I#FM
pD #REfi3"T#Fb/WO\_F fiD[bYj QSI#[oKaf9f9bY3KGTYZ #REQgPGHF]bJKQSI9\_XG]\_Y3PVFJVYffjUT9Ka<
J
1M#Y{FP
Z:Yb[bYj QSI#[lKl} PQgI9GHFQ_JoYf9JQScQ_]FPo
K GHb/Q_JVF]b/QSY3I7v7XF]JffKI#YJKae`\_FM9Q *mF]bFI9GHFQSPJT9KaJQ_JM#Y{FP
I#YJhGHY3c2fOW#JV
F YNF]boKfOKabJQ_JQ_Y3IQSI9M9W9GHFMle(XlK%PVF]JUYZbW9\_FP]EUKaJT9F]bv`JT9FffG/T9Y3QSGHFffYZB
QSPffJVY5[bYj KaJFKG/TPJVF]fK %eJ 3 ! lc2Y3I#Y3cQgK\wv f9b/W9I#FQ_J]vdKI9MJT#FI[bYj K5PVFGHY3I9Mc2Y3I9Y3cQSK\wv
f9b/WOI#FQ_J]vBKI9MPVY5Y3IW9I(JQS\BK5^`I9K\B} h fiPT9KafmFMZYbcffW9\gKQgP-GHY3cfO\_F]JVFKI9MbF]JW#b/I9FM7 YJQSGHF
JT9KaJ #RE K\SPYc2YuM9Q_^9FPJT#FjBFQ_[3T(JYZfiJT#FFHuKc2f`\_FP]vQSIKG]GHYb/M9KIOGHFijUQSJTqnY(Y3PVJQgI#([ P
PVJKI9MOKab/M9PpDuGT9KafOQ_bF r uQSI#[F]bv7xyy3
:PO



fi

n ,j*; 3 ; 7#"($


iwc

3 ;'"U"(7rE.R3 .r#"%$


ffff

'" #"($ B6.d.

R

*. 7#"($

3

uGT9KafOQ_bF r uQgI#[F]blp+xyy3T9KNFQSI(NFPVJQ_[3KaJVFMG]\gKPPQ_^OG]KaJQSY3If9bYeO\_FcPffj T#F]bFkJT#FlKQSc YZhJT#F
f9bYuGHFM9W#b/F!QSPhI#YJUJVYkf9bYN{QgM#F!KIKG]G]W#b/KaJVF2G]\SKPP ZYboPVY3cF!YeOPVF]b/N8KaJQ_Y3I EUKaJT9F]bv`JT9F-K\_[YbQ_JT9c
Y3W#JVfOW9JPKlPVF]JYZLNaK\SW#FPp:Y3I9FZYb!FKG/TG]\SKPPhKI9MjBFFHufmFGHJJT#FG]\gKPPYZnJT#FYeOPF]bN8KaJQSY3IJVY
bFGHFQ_NF-JT#F\SKab[FPVJ N8K\gW#F!YZdK\S\DvOJT{W9PUemFQSI9[b/K(I FMT9Q_[3T#F]b JT9KIK\S\YJT#F]bP] "TOQSP"Kaf9f9b/Y3KG/T5QSP
fOKabJQgG]W9\SKab/\_XWOPVF]Z:WO\Bj T#FIK5[3Q_NFIFHuKcfO\_FlG]KIemF\_Y3I#[5JVYc2YbFJTOKIY3I#FG]\SKPPp.c-W9\_JQS\gKaeF\
f9bYe`\_FcPvfiKG]KPVFjUT#F]bFjnFFHufFGHJFKG/T YZffJT#FPFG]\SKPPVFPJVYbFGHFQ_NFJT#F[bFKaJVFPVJNaK\SW#FP
GHY3c2fOKab/FMJVYJT#FG]\gKPPVFPJT#F!FHuKc2f`\_FP"M#Y{FP"I#YJ"emF\_Y3I9[-JVY#
"T9F- " EJ 3 ! %<% b/F]f9bFPVFI(JPQSI#Z:Yb/cK\S\SX-JT9FfiI{W9cffemF]bnYZ0JQSc2FPLJT#FoT(X(fmYJT#FP/QSPRZ.KQS\SPnJVYb/K(I
JT#FLG]\SKPP YZ`KI-FH#Kc2fO\_FLT9Q_[3T9F]b0JT9KIKhG]\SKPP JVYfijUT9QSGTffQSJ M#Y{FP I#YJ eF\SY3I#[# qnF]Z:YbFL[Y3QSI#[hZ:W9bJT#F]bv
jnFh^Ob/PVJn[FI#F]b/K\SQ_]FhY3W#bG]\SKPP/Q_^OG]KaJQ_Y3I%PVF]JVJQSI#[#v9KIOMbF]f`\SKGHFfiJT#FhGHY3cc2Y3II#YJKaJQ_Y3I'p &)(*!,+dZ:YbKI
FH#Kc2fO\_F e(XJT#Fhc2YbFh[FI#F]b/K\9Y3I9F'p &)( !, + "UF]bF*
v !, + m/02 (:x 9 ' QSPRK!NFGHJVYbn[3QSN{QSI9[#vZ:YbBFKGT%G]\gKPP]v
JT#F!cFc!emF]b/PTOQ_fJVYJT#FffG]\SKPPffp ffV %QSP"I9YKI9M ff]x QSP"XFPLYZ JT#FffGHYb/bFPVfmY3I9M9QSI9[-Ye`PVF]bNaKaJQ_Y3
&{
J!QSPQScfYb/JKIJoJVYI9YJVFJT9KaJJTOQSPPVF]JVJQSI9[QSPc2Yb/F[FI#F]b/K\RJT9KIJT#FWOPW9K\dqLKXFP/QSKIPF]JVJQSI#[#v
QSIjUT9QSGTJT#F]bFkG]KIFHuQgPVJ!FH#Kc2fO\_FPk'p &)(*!,+]!KI9M'p &N(*! + ; p.W9PQSI9[JT#F%I#Y3!I fiDNFGHJVYbI#YJKaJQ_Y3IoZ:Yb
jUT9QgG/
&1% & eOW#H
J !,+% 0 ! + ; UE K(I uQSI#[\_Y3P/PU[FI#F]bK\SQ_]FPhqnKXFPfiJVYJT9Fffc-W9\_JQS\SKaemF\mf9b/YeO\_FcP]vKI9M
fmY3PVJW9\SKaJVFPnJT9KaJJT9F]bFoG]KIkeFfiPVY3c2FfiFH#Kc2fO\_FPnZ:YbjUT9QSGTjnFG]KI9I#YJLf9b/YNuQSM#FfiK-P/QSI#[3\_FhG]\SKPPKaJ"K
JQSc2FvuF]NFIQ_ZL2 14351dKI(XYZJT#FoG]\SKPPVFPLJVYjUT9QgG/TJT#FfiFHuKc2f`\_F emF\_Y3I9[3PnKab/FhPWOPGHF]f9JQ_eO\SFUJVYKaf9fmFKab
QSI9M9F]fFIOM#FIJ\SX\SKaJVF]bUjUQSJTkJT#FPKc2FYe`PVF]bNaKaJQ_Y3I7
E K(I {QgI#[ff\_Y3P/PBqnY{Y3PVJQSI#[-bF]fO\SKGHFPnFKGTkFHuKc2f`\_F-'p &)( !, +e{XKPVF]JnYZRx ' = @ 'p ! 7x ' = @ dFHuKc2f`\_FP]v
jUT#F]b/Fx ' = @ M#FI#YJVFP%JT#F " KccQSI#[jnFQ_[3T(JkYZ !
+p J 1.2 1 JT9FI{W9cffeF]b%YZ!G]\SKP/PVFP%JVYjUTOQSG/T1JT#F
FH#Kc2fO\_FffeF\SY3I#[3P RKGTYZJT#FPF-I#F]j FHuKcfO\_FPUQgPUM#FI#YJVFM'p &)( 8(ff
(v7jUT9F]bfi
F
kKI9
lPVfOKIiK\S\
NaK\SW#FPQSE
02 (3x (5464646(*!@7t:x 9 . %UT#FM9QSPVJVbQ_eOW#JQ_Y3IiYZLJT#FI#F]j FHuKcfO\_FPQSPbFI#Yb/cK\gQ_]FM7vPVYJT9KaJ
;-pV'p &)( 8(ff
{V? % ( @ ,, , + ' ' = @ ( 11 @ 1 j T#FI#F]NF]b !, +-
/ % xKI9M !, +-/8%uvOKI9M2YJT#F]bjUQgPVF
Y3I9Y3 c QSK\ LYe9JKQSI9FMlZ:bY3c JT#F-\SKab[F-} v`KI9MlK\g\FH#Kc2fO\_FP PKaJQSPVZ:X{QgI#[Q_J] F
K F-PY3c2Fffc2
I#YjjBYb !jUQ_JTffJT9QSP bFPVJVb/QgGHJVFM-P/W#eOPVF]J YZ9FH#Kc2fO\_FP]vj T9QS\_FRG]K\gG]W9\SKaJQSI#[hJT#FGHYbbFPfY3IOM9QSI#["NFGHJVYb
YZ d#G/T9KafOQSbF r uQSI#[F]bfip+xyy3Bf9bYfmY3PVFUK-GHY3PVJnZ:W9IOGHJQ_Y3IjUTOQSG/TjBFfiPT#Y3W9\gMcQSI9QgcQ_]F"QSI2YbM#F]b
JVYcQgI9QScQ_]FhJT#FbK(I {QgI#[2\_Y3PP]d"TOQSPnZ:W9IOGHJQ_Y3IQSP

%



4

+ "

;-pVp'&)( 8(ff
(V

"
$ , = = 1

4

pw~3

" F]bFv QSPKfiJWOI9KaeO\_FfOKabKc2F]JVF]bdjUT9QgG/T7v3QSI(JW9Q_JQSNF\_XvbF]f9bFPFIJPJT9FUGHY3I#^OM#FIOGHF"QSIJT#F"G/T9Y3QSGHF

YZ( v`KI9M\_F]NF]bKa[FP Q_JP (WOK\SQ_JXL"T#F!eF]JVJVF]b- QgPUKaJUG]\SKP/PQ_Z:X{QSI9[2FHuKc2f`\_FP]v9JT#Fff\SKab[F]b QgP"G ?G+I
Y3W#boG]KPVF2T#YjBF]NF]bv0KW#JT#Yb/Q_QgI#[! % 0 xQSPhF{W9Q_NaK\_FIJhJVYKW#JT#Yb/QSQSI#[GHY3cfY3I9FIJPhZ:Yb QSI5PVF]JP
0 7 (2 ( 9ffZ:Yb"KabeOQSJVb/Kab
X 0dY2b/FK\S\_XGHY3IOPVJVb/KQSIkJT#FGHY3cfY3I9FIJPYZ Qg
0 73x (2 ( :x 93vOjnF!T9KNF
G/T9Y3PVFIlJVYYfOJQScQ_]FoJT#FGHbQ_JVF]b/Q_Y3I

%

4

+ "

;-pVp'&)( 8(ff
(V

"
$ , = = 1

p 3

p:JT#F]b/F]ZYbFoZ:Yb/G]QSI9["% xLuG/T9Kaf`Q_bF r uQSI#[F]bp+xyy3GHY3I+FGHJW#b/FoJT9KaJ^OI9M9QgI#[!JT#FoYfOJQScK\
NFGHJVYbcQSIOQScQ_QSI9[ QgIF`pw~3%p:jUT9QSGTQSP-PQScQS\SKaboJVY5KI !\J J $&% TX{fmYJT#FPQSPffKG]GHYb/M9QSI#[iJVY
JT#FQ_bhM#F]^OI9QSJQ_Y3I9Pv9Yb [3Q_NFIKf`KabJQSG]W9\SKabUN8K\SW9F!YZ#RvQSP fi " Kab/MijUT#FI!QSP I#YJ ^9{FM7vKI9M
jUT#FIJT#FhGHY3c2fmY3I#FIJPnYZ Kab/FhQSIJT#FfiPVF]H
J 0 7!3x ( :x 93R"T#F ZY3\g\_YjUQgI#[!PVFGHJQ_Y3IkKM9M9bFPPVFPnM9Q_bFGHJ\SX
JT#F-PVF]JVJQSI#[YZB#G/T9KafOQSbF r #QSI#[F]bffp+xyy3v7KI9Mf9bFPVFI(JPUGHY3c2f`\_FHuQSJX fiDJT#F]YbF]JQSGffbFPW9\SJP"PT#YjUQSI#[

$

:PO

fi

JT9KaJJT9FcQSI9QScQ_KaJQ_Y3IYZ QSPoKGHJWOK\S\_XfY3\SX{I#Y3cQSK\wvmeOW#JT9QS[3T9\_XGHY3c2f`\SQSG]KaJVFMJVYKGT9Q_F]NFv K\S\
JT#F5c2YbFZYb%jUT9KaJkQ_J%QSPP/W#f9fmY3PVFMJVYe9bQSI#[JVYJT#F5cQSI9QScQ_KaJQ_Y3IYZ QSI Y3W9b%PVF]JVJQgI#[#
PVJVb/Q {QSI9[bFP/W9\_JojnFK\SPVYl[3Q_NFv I#YJobF\SKaJVFMJVYlJT#FfOW9bfmY3PVFYZBJT#F2f`KafF]bvQSPfiJT9KaJ!QSJQSPoKGHJW9K\S\_X
JT#F!cK8uQScQ_KaJQ_Y3IkY
Z j T9QSG/TQgP fi " Kab/M
"T9FI7vujBFfObFPVFI(JJT#FKaf9f9bYuQgcKaJQ_Y3IK\_[Yb/QSJT9c jBFffT9KNFe`W9QS\_JLKI9MQSc2f`\_Fc2FI(JVFMJVYYf9JQ fi
cQ_]FBJT#FLGHY3c2fOW#JKaJQ_Y3IffYZ QSI!Y3W#b0PVF]JVJQgI#[p.GHY3cfY3I9FIJP YZ QSI!JT#FBPVF]J 0 73x (2 ( :x 98v{K\_Y3I#[ jUQ_JT
Q_JPBf9bYfmF]bJQ_FP T9QS\_F jBFhZ:F]F\`JTOKaJBJT#FfiQSM#FKPnW9PVFMJVY2cQSI9QgcQ_]F QSIJT#FfiPVF]JVJQSI#[-YZ0uGT9KafOQ_bF r
uQSI9[F]b p+xyy3nG]KIemFUKMOKaf9JVFMJVYffY3W#bLPVF]JVJQSI#[JVY-f9bYN{QgM#FUKIK\S[Yb/Q_JT9c JT9KaJnQgPdK\_jLKXuPBYfOJQScK\wv
Y3W#bK\_[YbQ_JT9c T9KPoJT9FKM#N8KI(JKa[FJVYemFPQgc2fO\_FvmZ.KPVJ]vKI9MK\gPVYkYf9JQScK\ Z:Yb!I{W9c2F]bY3W9PoG]KPFP]
+IlcKI(XYJT#F]bhG]KPVFP]v9jnF!PT9Yj JT9KaJ Q_J"QSP"PVJQg\S\mKPVX{cf9JVYJQSG]K\S\_X%Yf9JQScK\7KP !oQSI9GHbFKPFP]

fiff



fffiffff !"#$&% fi '& r

fi')(*,+-+-.0/

+IkJT#FoG]KPVFjUT#F]b/F FKGTGHY3c2fmY3I#FI(JYZ QSPnbFPVJVb/QSGHJVFMkJVY2JT9FPVF]J 0 7x3( :x 93v#G/T9KafOQSbF r #QSI#[F]b
p+xyy3[3Q_NFLK"jLKXJVYfiG/T#Y{Y3PV
F kJVY cQSI9QScQS]F ZYb KIX!fY3P/PQ_eO\_FGT#Y3QSGHFnYZ .p W9PQSI#[UY3W#b0I#YJKaJQSY3I`<


%

~

x

\SY[21

0

0 43 (

p +(

jUQSJT9

0
%

0
%

4
+
4
+

"
"

;-pVp'&)( 8(ff
{V - -

- /




7


-/

;-pVp'&)( 8(ff
{V - -

- /




7

- /

%t~ / /"(

p 3

% 7U~ / / 4

pw|3

EUF]fO\SKG]QSI#[2JTOQSPLN8K\gW#FoYZ
QSIkF` pw~3v`[3Q_NFP"JT#FoZ:Y3\S\_YjUQSI#[2I#F]jFH{f9b/FPPQ_Y3IkZ:Yb

% 0

0

~,5 0 0 (




pD

jUQSJT 0 0 %76 + " ;-pVp'&)( 8(ff
(V - - -
/87 -/ %t/ /n#G/T9KafOQSbF r uQSI#[F]bp+xyy3"b/KQSPVFfiJT#F!f9bYefi
\_Fc ZmcQSI9QScQ_QSI#[ K PM#F]^OI#FMQSI-F{W9KaJQ_Y3I9P"pw~3 KIOMlpD F I#YjPT9YjJT9KaJdQ_J QSP fmY3\_XuI#Y3cQSK\w

#" E"F> 98 J 6J8TgJMLrJ 3 "% V( j V2 J H J ;: $ " J (%/ =<fi4] ?> fi5 ;@+fi J %
! fTgJ"!6X
fT
% [N " Vff % . J jV % < 0 7!x3( x:9 1
k36)jl {F]FoJT#F f9fmFI9M9Q_




/b KaJT9F]b-PVJVbQ#{QgI#[bFPW9\SJ[3Q_NFIJT#FGHY3IVFGHJW#bF%YZ uGT9KafOQ_bF r uQgI#[F]bp+xyy3-QSP!JT9KaJffQ_J-QSP
JT#FcK8#QScQ_KaJQSY3IYZ !vRKI9MI#YJ2Q_JPcQSI9QgcQ_KaJQ_Y3I7v jUTOQSG/TQSP1 fi " Kab/M TOQS\_F%JT9QSPQSPI#YJ
JT#Ff`W#bfmY3PVFYZLJT#Ff9bFPFIJofOKafmF]bp:jnFKab/FQSI(JVF]bFPVJVFMQSIcQSI9QScQ_QSI#[ hv0jBFT9KNF%G/T#Y3PVFIJVY
[3Q_NFoT#F]bFoK-e9b/QSF]Zf9bY{YZP F]JGTYZJT#FfibFP/W9\_J]v{jUT9QSGT%WOPVFPLG]\SKPPQSG]K\bFMOW9GHJQ_Y3I9PnZ:bY3c jBF\S \ fi {I#YjUI
fi " KabMf9bYeO\SFcP]


#" E"F> A8 " 'J TgJ L J 3 "% V WV J H J ;: $ " J (% =<fi5] ?> fi B @ fisJ % :_` " V X
fT
% [N " Vff % . J jV % <0 7!x3( x:9 1
k36) ?. 6" 7rffAl uF]
F JT#F f9fmFI9M9Q


:PODC

fi


fiff



!



iwc


ffff

' fiffff

P f9bF]NuQ_Y3W9P\_XKab/[3W#FM2QSI"T#F]YbFc +#v{cQSI9QgcQ_QSI#[ QSI-JT#FPVF]JVJQSI9[oYZmuGT9KafOQ_bF r uQgI#[F]bLp+xyy3
G]KIieF-M#Y3I#FffYf9JQScK\S\SXv9eOW#JUKaJhJT#FffFH{fmFI9PVFffYZdGHY3c2fO\_FHlYfOJQScQ_KaJQ_Y3If9bYuGHFM9W#bFPv9jUQ_JTi\SKab[F
GHY3c2fO\SFHuQ_JQSFP]BfiI#FoG]KIljnY3I9M#F]bUjUT#F]JT#F]b"PWOG/Tf9b/Y{GHFM9W9bFP]v#JVYYf9JQgcQ_]FfiY3I9\_X%JT#FGHY3c2fOW9JKaJQ_Y3I
YZ p.KP/cK\S\mfOKabJYZ
fivOKabFb/FK\S\_XjnF\S\7jnYbJTJT9FKM9Kaf9JKaJQ_Y3IJVYY3W#bUPVF]JVJQgI#[#v9QSIkjUT9QgG/T
c2YbF!N8K\SW9FPUKabF!KW9JT#Yb/Q_]FM7#
F-Kab/F!I#Yj [Y3QSI#[JVY%PT#YjJT9KaJhKcffWOG/TP/QSc2fO\_F]b"GHY3cffeOQSIOKaJVYb/QSK\
f9bYuGHFM9W#b/Fv jUQSJTtGHY3c2fOKab/KaJQ_NF\SXNF]b/X\SYj GHY3c2f`\_FHuQSJXvG]KIte9bQSI#[Yf9JQScK\fib/FPW9\_JPlQgIZ:KQ_b\_X
[FI#F]b/K\PQ_JWOKaJQ_Y3I9P]"T#Fhc2Y3PVJnPQSc2fO\SFjnKXJVYM#FPGHb/Q_emF"c2Y3PJBYZ7JT#FPFhPQSJW9KaJQ_Y3I9PBQSPdJVYcK FfiJT#F
Z:Y3\S\_Yj QSI#[2KPPW9cf9JQ_Y3IkY3IJT#FoFH#Kc2fO\SFP


p2BKG/TFHuKc2f`\_FW9PVFMJVYGHY3c2fOW#JVF T9KPY3I9\SXY3I#Fff]x QSIQ_JP"G]\gKPPNFGHJVYb
]G Kab/F]Z:W9\ bFKMOQSI#[YZBKPPW9c2fOJQ_Y3IpUbF]NFK\SPhJT9KaJoQ_J Qgc2fO\SQ_FP"JT9KaJfiFKG/T5FH#Kc2fO\_F-emF\_Y3I#[3P
JVYFHuKGHJ\SXY3I#FoG]\SKPPv $ RQ_JLM#Y{FPnI9YJnfObF]NFIJKI%YeOPVF]b/N8KaJQ_Y3I%JVYemF F\SFc2FIJLYZ c2YbFhJT9KIkY3I#F
G]\SKPPvuKPU\_Y3I#[2KPM9Q *mF]bFI(JnFH#Kc2fO\SFPnP/T9Kab/QSI#[-JT#FPKcFhYe`PVF]bNaKaJQ_Y3IT9KNFffM9Q *mF]bFIJLG]\SKPPFPp:JT#F
ff]x YZmJT#F G]\SKPPdNFGHJVYbPBQSPRQSI2M9Q *mF]bFI(JdfmY3PQ_JQ_Y3I9PKcY3I#[JT#FPVFUFHuKc2f`\_FP"T#F]bF]Z:YbFv(F]NFIQ_ZQ_J
M#Y{FPRI#YJBQSIJVF][bKaJVFUJT#FUcY3PVJR[FI#F]bK\9Z:FKaJW#bFPdYZmJT#F b/K(I uQSI#[o\_Y3PPBPVF]JVJQSI#[#v(Y3W#bBKP/PW9c2f9JQSY3I2PVJQS\S\
KW#JT#YbQ_]FPdJVY-GHY3I9PQSM#F]bRf9bYeO\_FcP jUQ_JTI#Y3I]F]bYffqLKXFPBYfOJQScffWOc UT9QSPdQSPdbFK\S\_XQSI(JVF]bFPVJQSI#[#v{KP
cKI(X!GHY3cc2Y3IO\_XW9PVFM-M9KaJKPVF]JPZ.K\S\(QSIJVYhJT#FLG]KaJVF][YbX-YZ9Y3W#b KPPW9c2fOJQ_Y3I7vaKP ZYb FHuKcfO\_FLcKIX
M9KaJKPVF]JP YZ JT#
F LbF]fmY3PQ_JVYbXYZ KGT9QSI#F FKab/I9QgI#[2M9KaJKaeOKPVFkp.qn\gK F!F]J K\D_vxyy3 QgI9K\S\_Xv
F]NFIQSZJT#FKPP/W9c2f9JQ_Y3IM9Y(FPI#YJ T#Y3\SM7vujnFPT#YjJT9KaJUQSIcKI(X%YZ0JT#F!bFcKQSI9QgI#[kp.QgIJVF]bFPJQSI#[(
G]KPVFP]vuY3W#bLKaf9f9b/Y#QScKaJQ_Y3IK\_[Yb/Q_JT9c QSPnKPVX{cf9JVYJQSG]K\S\_XYf9JQgcK\wv{JT9KaJBQSPv(^OIOM9PdPVY3\SW9JQ_Y3I9PRG]\SY3PVF]b
JVYJT#FffcQSI9QScK\ONaK\SW#FoYZ KH
P !oQSI9GHb/FKPVFP]
uW9f9fmY3PVFkZYbI#Yj JT9KaJp T#Y3\gM9P] fiW#b2Ye VFGHJQ_NFQgPJVYG]K\SG]W9\SKaJVFJT#FNFGHJVYb YZoPVY3c2F
c2Y3I#Y3cQSK
\ FW9PF%JT9FlPT#YbJT9KIOM9P 0 0 ( 0 ( (5464646( 0 ( JVYM#FI9YJVFJT#FlPW9c YZhjBFQS[3TJP2YZ
JT#FFH#Kc2fO\SFP!PKaJQSPZXuQSI#[ oKI9MeF\SY3I#[3QSI#[kbFPVfmFGHJQ_NF\SX' JV YG]\SKPPVFPff2 (3x (5464646(*!@7txa FjLKIJffJVY
cQSIOQScQ_]
F KPf9bYfmY3PVFMQSIlFO p 3LuW#f9fmY3PVFfijUQ_JT9Y3W#J\_Y3PPYZ [FI#F]b/K\gQ_JX%JT9KaJ


0 (
0 0


46464


0 ' ( (

YJT#F]bj QSPVFvmbF]Yb/M#F]bfiJT#FG]\SKPPFPhPY%JTOKaJhJT9F]XlNF]b/Q_Z:XlJT9QSPhKPPVF]b/JQ_Y3I7 Q_NFIY3I9\_XJT#bF]F-fY3P/PQ_eO\_F
NaK\SW#FPoZ:Yb!FKGTGHY3c2fmY3I#FI(JYZ v0JT#FJVFPVJQgI#[lYZK\S\ ' fmY3PP/Q_eOQS\SQSJQ_FP"Z:Yb QSPoFHufmY3I#FIJQgK\dKI9M
JQSc2F fiGHY3IOPW9cQSI9[# qLW#JUjBF!G]KIlf9bYfmY3PVFK2NF]bXkZ.KPVJ"Kaf9f9b/Y3KG/T7 F-T9KNF-QSI9M#F]FM

B "F> >
x
k36)jl {]F FoJT#F










!:(




- /






- / 1

f9fmFI9M9Q_
"T{W9P]v(JT#F"Yf9JQgcK\ M#Y{FPRI#YJBemF\_Y3I#[oJVYffKffPVF]JRYZG]KabM9QSI9K\SQSJX ' v(eOW9JdJVYffKffPVF]JRYZG]Kab/MOQSI9K\SQ_J)X
kp'! . oW#bK\_[Yb/Q_JTOc QSPoJT#FIPVJVb/KQ_[3T(JVZ:YbjnKabM9ffPQgc2fO\_XlFHufO\_Yb/FJT9QSPoPVF]JffYZ kp'! . fiF\_Fc2FI(JP]v
KI9
F]F]fJT#F-NFGHJVYbT9KNuQSI#[%JT#F\_YjnFPVJfiN8K\gW#F!YZ ! UYJVFJT9KaJhJT9QSPhGHY3cffeOQSI9KaJVYb/QgK\0K\_[YbQ_JT9c
T9KPnJT#FoKM#NaKIJKa[F!JVY-emFfiKM9Kaf9JKaeO\SFhJVY2c2Yb/Fh[FI9F]b/K\7PVF]JVJQSI#[3PLQSI%jUTOQSG/T 8f`KabJQSG]W9\SKabnNaK\SW#FPLKabF
KW#JT#YbQ_]FMkZYbJT9FfiGHY3cfY3I9FIJPY+
Z vuZ:Yb"KIX%^#uF
80I9YJLI9FGHFPPKab/QS\SXF{W9K\JVY {dIkJTOKaJ"G]KPVFv
JT#F!GHY3cfO\_FH#Q_JXkQSP\SKab[F]bv#eOW#J"\SQScQ_JVFM%JVY k'p ! 1 (
"T9F]bFKabFP\SQ_[3T(J\_XcYbF[FI#F]bK\UPVF]JVJQSI9[3PQSIjUT9QSGTY3W#bK\_[YbQ_JT9c b/FcKQSI9P2YfOJQScK\wvLQSI

0 fi p % 0
( 0 "
0 V pVp 0 "
fOKabJQgG]W9\SKabUj T#FIljnFffG]KI5GHF]bJQ_Z:X
( v pVp 0 "ff
0 fi p % 0
J( 0 "
0 V " F]bF(v 0 M9FI#YJVFPfiJT#F2PW9c YZRjnFQ_[3T(JP YZBJT#F-FHuKc2f`\_FP
emF\_Y3I#[3QSI9[ KaJd\_FKPVJJVYoG]\SKP/P vKI9M 0 M9FI#YJVFP JT#F"PW9c YZ`jBFQ_[3T(JP YZJT#FLFHuKc2f`\_FP emF\_Y3I#[3QSI#[
:PO

fi

KaJff\SFKPVJJVYiG]\gKPP 0v KI9M fiemF\_Y3I#[3QgI#[lKaJff\_FKPJJVYiG]\SKP/
P %"TOQSPPT#YjUPJTOKaJ!F]NFIZYb-PVY3c2F
fOKabJQgG]W9\SKabc-W9\_JQg\SKaemF\G]KPVFP]vUY3W9b%Kaf9fObY#QScKaJQ_Y3I1K\_[Yb/Q_JTOc G]KI1bFcKQSI1Yf9JQScK\w fiI#FG]KI
jnY3I9M#F]b2Q_ZJT#FkYf9JQScK\SQ_JXQgPfffObFPVF]bNFMQSIJT#FkW9I#bFPVJVbQSGHJVFMc-W9\_JQg\SKaemF\dZ:b/Kc2F]jnYb` FlI#Yj
PT#YjtJT9KaJ]v#Q_ZYf9JQgcK\SQ_J)XQSPnI#YJLf9bFPVF]bNFMv{jnFoG]KIPVJQS\S\`f9bYNFfiJT#Fo(W9K\gQ_JXYZY3W#b"K\_[Yb/Q_JTOc Z:Yb
[FI#F]b/K\cffW9\SJQS\SKaemF\mG]KPVFP]vOPT9YjUQSI9[KPVX{cf9JVYJQSGfiYf9JQScK\SQ_JXkKP !oQSIOGHbFKPVFP]
fiW9b KafOf9bY#QScKaJQSY3I-K\S[Yb/Q_JT9c QSP b/W9IQSI-JT#Fc-W9\_JQS\gKaeF\(G]KPVFe{X!JVb/KI9PZYb/cQSI#[hJT#FLFHuKc2f`\_FP
KP"Z:Y3\S\_YjUP dFKGTFH#Kc2fO\SF'p &)( !
+ZYb"j T9QSG/Tx ' = @
xffQSPJVb/KI9PZYb/cFMlQSI(JVYx ' = @ FHuKcfO\_FP]vOTOKNuQSI#[
JT#FPKcFM#FPGHb/Q_fOJQ_Y3
&{vKIOM5Y3I9\_XY3I9F ff]x lQSIJT#FQ_boNFGHJVYbv QSIPW9GTKkjnKX5JT9KaJojBFPfOKI5JT#F
x ' = @
x ff]x !YZ`JT9F"Yb/Q_[3QSIOK\uFHuKc2f`\_F UT#FQ_bjnFQ_[3TJBQSPJT#FY3I#FUYZJT9F"Yb/Q_[3QSIOK\(FH#Kc2fO\SFv(M9Q_NuQSM#FM
e{Xx ' = @ F!JT#FIb/W9IkY3W9bUK\_[Yb/Q_JTOc Y3IJT9QSPI9F]jPVF]J"YZ FHuKcfO\_FP"PKaJQgPVZXuQSI#[2KPP/W9c2f9JQ_Y3Ip
YjvmPW#fOfY3PFJT9KaJhZYbhKIXlFH#Kc2fO\SF'p &)( ! + vjnFffT9KNF%x @ Z:YbhPVY3cF U"T9F]bF!KabF-JjnY
'=
QSI(JVF]bFPVJQSI9[NFGHJVYb/P-jBFWOPVF"T9F2^9b/PVJoY3I#F%QSP v JT#FYfOJQScK\NFGHJVYbp:YbffKIYf9JQScK\NFGHJVYbH
cQSIOQScQ_QSI9

[ YNF]b%JT#FYb/Q_[3QSIOK\PVF]JYZhFHuKc2f`\_FP]vnJT#FlPVFGHY3I9MY3I9FQSP vRJT#FlNFGHJVYb%jnF^OI9M
cQSIOQScQ_QSI9[ YNF]bJT#FJVb/KI9PVZ:Yb/c2FM1PVF]J%YZFHuKcfO\_FP] T9KaJ%jnFijLKIJQSPJVYFPJQScKaJVF5JT#F
{W9K\SQ_J)XY+
Z jUQ_JT%bFPfFGHJJVY2JT9FoYf9JQScK\mNaK\SW#FfiYZ YNF]bUJT#FfiYb/Q_[3QgI9K\mPVF]J"YZFH#Kc2fO\SFP]v -p
W9PQgI#[ffY3W9bLI9YJKaJQ_Y3I7R"T9F Z:Y3\S\_YjUQSI#[ffJT#F]YbFc [3Q_NFPKIKIOPVjBF]bJVY2JTOQSPnf9bYeO\_Fclv(e{X{W9KI(JQ_ZXuQSI#[
Q_JP"GHY3I(NF]b[FI9GHF-JVYjLKab/M9P -p

#" E"F> p


k36)jl {F]FoJT#F



-p 8x ' ff
fi

1

f9fmFI9M9Q_
"T9F]bF]ZYb/Fv"QSIJT#FPVF]JYZK\S\Uf9bYeO\SFcP2Z:YbjUTOQSG/TZ:YbkPVY3c2F xav !vjnFYeOJKQSI
-p < % p+x &#p+xV ffAp v{KI9MY3W#bdemY3W9I9M2GHY3I(NF]b[FPBJVYJT#FYf9JQgcffW9c KP<!QSI9GHbFKPFPdQSIJT9QSPG]\gKPP
YZf9bYe`\_FcP]"qnXc2FKIOPUYZjnYb/M9P]vY3W#bfiPQSc2f`\_FKaf9f9bYuQgcKaJQ_Y3IK\S[Yb/Q_JT9c QSP {W9Q_JVF!FG]Q_FI(J Z:Yb
f9bYe`\_FcPjUQSJTl\SKab[F-I(W9cffemF]bUYZdG]\SKP/PVFP] YJVFffJT9KaJhW9PQSI9[KP\SQS[3TJ\_Xc2Yb/F!QSI(NY3\_NFMfObY(YZv9jnF
GHY3W9\SMT9KNF bFM9W9GHFMJT#FUGHY3I9PVJKI(J ff*$> !Z.KGHJVYbLQSI2"T#F]YbFc |oJVYJT9F P\SQS[3TJ\_X-PcK\S\SF]b ff*$ 7p+x 3$8 u
Yjv JVYl^#5JT#FQSM9FKP]vJT#FZY3\S\SYjUQSI9[kP/W#eOPVFGHJQ_Y3IMOQSPVfO\SKX{PfiJT9FFH{f`\SQSG]Q_Jp.KI9MP/QSc2fO\_F PVY3\gW#JQ_Y3I
jUT#FIkJT9F]bF!KabFY3IO\_XJ)jBY%G]\SKPPVFP]

, $ ff ff !ff

% %
0 0 % 0
KI9M 0 ( % 0 bF]f9bFPFIJQSI9[JT#F-ZbKGHJQ_Y3IYZ

#YbfiJT#FPK F-YZRPQSc2f`\SQSG]Q_J)Xv9bFI9Kc2F
FH#Kc2fO\_FPZ:bY3c JT#FffI#F][3KaJQ_NF!KI9MkfmY3PQSJQ_NFoG]\SKPPbFPfFGHJQSNF\_XvOPKaJQSPZXuQSI#[ B"T#Ffib/W9\_FfiJVYGT#Y{Y3PVF
QSPLJT#FZ:Y3\S\_YjUQSI#[(

B "F> > %n ! ! fXhJ 3 "! 3 J % ff $&! % "
!
pN
X %
#%$ ($ '
% p 7x3( x
#& # $
5 $ # & $ '
% p 7!x3( % p.2( x
*
#
$
) ( ##*&$ 5 $ % p 7!x3( 7 x % p.2( % p x3( x
(
(

% p.2( 7!x % p x3(
' #% $ #+ & ( )
% p x3( 7x
#& '
k36)jl {F]FoJT#F f9fmFI9M9Q_
:PO =

fi

iwc


ffff

+-,
kf3 "##"($

"T#FK\S[Yb/Q_JT9c QSPKP/QSI#[3\_F fiDfOKP/PK\_[Yb/Q_JT9c FKGT b/WO\_FQSPkJVFPVJVFM Y3IO\_X Y3I9GHFvoZ:bY3c JT#F^9b/PVJ
b/W9\SFffJVYlJT9F\gKPVJoY3I#F#Yb!FKGTfmY3PPQ_e`\_F!b/WO\_Fv7KGHb/Q_JVF]b/Q_Y3I

ff fipbF]JW#bI9P ffV"EA Yb
ffV !
8 -M#F]fmFI9M9QgI#[oY3Ij T#F]JT#F]bRJT9F b/WO\_FUPT#Y3WO\SM2emFUbFcYNFM%YbnI9YJ]d"T#F]bFhKabF J)jBYNF]b/P/Q_Y3I9P
YZJT9QSP GHb/Q_JVF]b/QSY3I7""T#Fff^9b/PVJ"Y3I9Fv`jUTOQSG/TjBFG]K\Sfi
\ ff+fmFPP/QScQSPVJQgG uvOQSP"e`KPVFMY3IGHY3I(NFIJQ_Y3IOK\0F]b/bYb
cQSIOQScQ_KaJQ_Y3I1"T#FiPVFGHY3I9MY3I9Fv"G]K\S\_FM ff+YfOJQScQSPVJQgG uvLQgPM#F]b/QSNFMZb/Y3c KfObF]N{QSY3W9P2jnYb Y3I
f9b/WOI9QSI#[M#FG]QSPQSY3!I fiDJVbF]FP!p FKabI9P r KI9PVY3W#bvxyy3





ff $ '


&

FPPQScQSPVJQSGhf9b/WOI9QSI#[-eOW9QS\gM9PBKPVF(W9FI9GHFYZ} Zb/Y3c

J T#F!QSIOQ_JQSK\Y3I#F J FKG/TPVJVF]fv#jnFbFc2YNF
Y3I#F-b/W9\_FvmPW9GTJT9KaJoQ_JPUb/Fc2YNaK\ e9b/QSI#[3P JT#F\_YjnFPVJfiF]bbYboKc2Y3I9[%K\S\0fmY3PPQ_e`\_FbFc2YN8K\gP YZRb/W9\_F
QSIJT9FG]W#bb/FIJ!} RKGTJQScFJT#FF]b/bYb!YZLJT#F%G]W#bbFI(J!} QSPffI#YJ![b/FKaJVF]bffJT9KIJT#F\SYjnFPVJ
F]bbYbRZY3W9IOMK\_bFKM#Xv

fffipobF]JW#b/I9PdJVb/W#F"Z:YbRK\S\#bW9\_FPdK\_b/FKM#XffJVFPJVFMZ:YbdbFc2YN8K\Dd"T9QSP
f9b/WOI9QSI#[b/F]JW#b/I9P JT#F2PcK\S\SFPVJ } T9KN{QSI9[JT#F2\_YjBFPJhF]b/bYbfiYZRJT#F2PVF{W#FI9GHF"TOQSPUfOb/W9I9QSI9[QSP
b/KaJT#F]bhI9KaJW#b/K\Bp.KI9MPQgc2fO\_Fv9KI9Mc2YJQ_NaKaJVFMe{XkJT#FZ.KGHJUJT9KaJ JT#F!QSI9MOW9GHJQ_Y3IkYZ JT#Fff\gKab[F!}
emF]ZYb/FBf9bW9I9QSI#[ M#Y(FP I#YJ \_FKM-JVYKhGHY3INFI(JQ_Y3I9K\#F]b/bYbcQSI9QScQ_KaJQ_Y3I70uWOG/TKhf9bYfmF]bJXffQSPbKaJT#F]b
PVF\SM9Y3c QSI ff+JVYffiM#YjUIkKI9Mf9bW9I#2F !QgI9M9W9GHJQ_Y3IK\_[Yb/Q_JT9cP] 9YbFHuKc2f`\_Fv{GHY3cc2Y3IM9FG]QSPQ_Y3IJVbF]F
QSI9MOW9GHJQ_Y3IK\S[Yb/Q_JT9cPBQSIJT9QSPnPG/T#FcFfiQgI9GHYbfmYb/KaJVFUNF]b/XPVYfOT9QgPVJQSG]KaJVFMf9b/W9I9QgI#[!GHb/Q_JVF]bQSKp E
p.qnbFQScKIlF]JUK\w_vxy +(v +# lfip fffiW9QgI9\SKI7v7xyy +(V




fiff ff $ '


&

FKab/IOP r KI9PVY3W#blp+xyy3fff9bFPFIJKiI9YNF\K\_[Yb/QSJT9c JVYf9b/WOI#FM#FG]QgPQ_Y3IJVb/F]FP]vdeOKPVFMY3IK
VJ FPVJYNF]bk\_Y{G]K\g\_XYeOPF]bNFMF]bb/Yb/P]JPf9bQSI9G]Q_fO\SFQSPP/QSc2fO\_FFKGT QSI(JVF]b/I9K\UI#Y{M9FYZfiK}h QSP
JVFPVJVFMiY3I9\_XkY3I9GHF-QSIlKemYJVJVY3c fiW9fZ.KPT9Q_Y3I7v`KI9MljnF!FPVJQgcKaJVF!JT#Fff\_Y{G]K\F]bbYb YNF]bfiJT#Fff\SFKab/I9QSI#[
FH#Kc2fO\_FPob/FKG/T9QSI9[lJT9QSPI9Y{M#Fv0emF]ZYbFKIOMKaZ:JVF]b!JT#Fb/Fc2YNaK\dYZLJT#FI9Y{M#F)ZnJT#F\SY{G]K\F]b/bYb
KaZ:JVF]bRbFc2YN8K\`QSPI#YJd[b/FKaJVF]bRJT9KI2JT9FU\_YuG]K\#F]bbYbdemF]Z:YbFv3fO\gW9P KofmFI9K\_JX-JVF]b/cv(JT#FI2jnFbFc2YNF
JT#F-I#Y{M9FKI9MQ_JP PW#e9JVb/F]Fn"T9FfmFI9K\_JXkJVF]b/c cK FP JT#F!f9bW9I9QSI#[FPPFIJQSK\g\_XYfOJQScQSPVJQgGav#JT9KaJ
QSP]v7jnF2JVFI9M5JVYYNF]bf9b/W9I9F2JT#F2M#FG]QSPQ_Y3IJVbF]F " YjnF]NF]bv JT9K(I uPfiJVYl\_Y{G]K\WOI9Q_Z:Yb/cGHY3INF]b[FIOGHF
bFPWO\_JP]vmKI9M5M9W#F-JVYJT#FffZ.KGHJoJT9KaJoGHF]bJKQSIP/W#e fiG]\SKPPFPUYZnM#FG]QSPQ_Y3IiJVbF]FPKab/F-b/FKPVY3I9KaeO\_Xi\SKab[Fv
FKab/IOP r KI9PVY3W9bp+xyy3KabFKaeO\_F%JVYf9bYNFJT9KaJjUQ_JTT9Q_[3Tf9bYeOKae`QS\SQ_J)Xv JT9F%YNF]bf9b/WOI9QSI#[
jUQS\g\0I#YJoemFJVY{YlPVF]NF]bF2jUQ_JT5b/FPVfmFGHJhJVYJT9F2Yf9JQScK\PW9e9JVbF]FYZRJT#FQgI9Q_JQSK\ }fio F2bF]Z:F]bJT#F
bFKM#F]bhJVYJT9FQ_bUfOKafmF]b"Z:YbhZ:W#b/JT#F]b"JT#F]YbF]JQgG]K\bFP/W9\_JP]vOI9YJ I#F]FM#FMT#F]bF"T9FfmY3QSIJ QSP"JT9KaJ e(X
W9PQgI#[JT#F%bFPWO\_JP!YZ FKab/I9P r KIOPVY3W#blp+xyy3vRjnFG]KIYe9JKQSIKP/QScQS\SKab!JVFPVJZYb2} F
Fc2fOTOKPQ_]F-JT9KaJfiY3W#b emY3W9IOMicQS[3TJfiI#YJhFI +YXJT#F2PKcFffJT#F]Yb/F]JQSG]K\ f9bYfmF]bJQ_FPhKPhZYboM#FG]QgPQ_Y3I
JVbF]FP]vBemFG]KW9PVFkYZUJT#FG]Kab/MOQSI9K\SQ_J)XbFKPVY3I9PeOb/Q_F '9XY3W9J\SQSI#FMemF]ZYbF "UYjBF]NF]bvLPW9GTKJVFPVJQSP
QSI(JVF]bFPVJQSI9[!PQSI9GHF Q_JBcKX\_FKMFPfFG]QgK\S\_X-JVYffNF]bXP/cK\S\9KI9M%QSI(JVF]bf9bF]JKae`\_F"M#FG]QSPQSY3IGHY3ccQSJVJVF]FP]v
jUQ_JTJT#FYe{N{Q_Y3WOP!T#YfmF2JT9KaJffJT#FQ_b!KG]G]W#bKGHXjUQS\S\ I#YJ-M#FGHbFKPVFJVY(YcffWOG/T7k9W#bJT9F]b/c2YbFv JT#F
fOKafmF]bYZ FKabI9P r KI9PVY3W9b%p+xyy3ffM#Y{FP!I#YJ!GHY3I(JKQSIFH{fmF]b/Qgc2FIJK\dbFPW9\_JP F%JT9QS(I iY3W#b
GHb/Q_JVF]bQ_Y3IKP"K2jLKXkJVYJVFPVJ T#FW#b/QSPJQSG]K\S\_X2JT#FoFHufmF]b/QSc2FI(JK\mZ:FKPQ_eOQS\gQ_JXYZPVY3cFoYZ0JT#F!bFPW9\_JPLYZ
FKab/IOP r KI9PY3W#bhp+xyy3n"T#FUfOb/QSI9G]Q_f`\_FBYZ7Y3W9bBGHb/Q_JVF]bQ_Y3IQSPRFHuKGHJ\SX2JT#F PKcFhKPBJT#FUYbQ_[3QSI9K\
JVFPVJ2YZ FKab/I9P r KIOPVY3W#blp+xyy3 ffVG]KIjBFGHY3c2fOKab/FvRjUT#FIJVFPVJQSI9[5PY3c2Fkb/W9\_Fp ( ffKI9M
W9PQgI#[lJT#FFHuKc2f`\_FP!JTOKaJ-PKaJQgPVZXJT9Fb/W9\SFv0JT#FF]bbYb/PffemF]ZYb/FKI9MKaZJVF]b-bFc2YN{QgI#[JT#F%b/W9\SF2 5
F]
J , = 1 bF]f9b/FPVFIJnJT#FhF]bbYbnemF]ZYbF bFc2YN{QSI9[ffJT#F b/W9\_Fv(Y3I%JT#Fh\SY{G]K\PKc2fO\SH
F =?> , = 1 PKaJQSPZXuQSI#[
c2Y3I#Y3cQSK#\ }hFI#YJV
F nKP JT#FLF]bbYb emF]ZYb/FBbFcYNuQSI#[p ( vPVJQg\S\c2FKP/W#bFM-Y3IJT#F\_YuG]K\{P/Kc2fO\_F
:PO $

fi

=?> , = 1 ff"T#FIjnF2M#F]^OI#F-JT#F2T#FW#b/QgPVJQSG ff+fmFI9K\SJX p:f9bY{YZdY3cQ_JVJVFM9fiQ_JfiQSPfiKkbY3W#[3T5W#f9fmF]bemY3W9IOM
YZ FKab/I9P r KI9PY3W#bffp+xyy3v FccKx

, = 1

pD{F]JpVp
( V ~3{\_Y[7p -0 \_Y[hx
4

%

pw3

G =A> , = 1 G

{F]JpVp
( VM#FI9YJVFP JT9FffcK8#QSc-W9c I{W9cffeF]b YZd\SQ_JVF]b/K\gPYZdK\S\bW9\_FP"FH#GHF]f9J2p ( QgIlJT#F-G]W#b fi
bFI(Jn} v(JT9KaJLKIKabe`Q_JVb/KabX2FH#Kc2fO\_FhGHY3W9\SMPKaJQSPVZ:Xd"T#F Z:KPVJnG]K\SG]W9\SKae`QS\SQ_J)XffYZ , 1 QSPRYeOJKQSI#FM
KaJhJT#F!FHufmFI9PVF!YZBK[bFKaJVF]bob/QgP kYZYNF]bf9bW9I9QSI#[#v`jUT#Y3PVFffF *FGHJPhY3I5PVY3c2F-PcK\S\0 M9 = KaJKPVF]JPhjnF]bF
FHufF]bQSc2FI(JK\S\_XM#b/KcKaJQgGZ:YbJT#F%KG]G]W9b/KGHX+IY3W#b-FHufF]bQSc2FI(JP]vjUT9QSGTGHY3I(JKQSINF]bXP/cK\S\
M9KaJKPVF]JPvOjnF!T9KNFffG/T#Y3PVFIJVYJW9I9FKfOKab/Kc2F]JVF]bh\SQScQ_JQgI#[ffJT9FoF *FGHJP YZ JT9QSPGHY3cffeOQSI9KaJVYb/QgK\W#f fi
fmF]bemY3W9I9M7 Yb/F2f9bFG]QSPVF\SX v FT9KNFG/T#Y3PFI5JVYkWOI9Q_Z:Yb/c\_XkbFPKcfO\_"
F =A>QSI(JVY%Kk\SKab[F]bP/W#eOPVF]J
YZ aFH#Kc2fO\SFP]vLjUT#FIJT#FiQSI9Q_JQSK
\ =A> GHY3I(JKQSI#FM1\_FPPJTOKI aFH#Kc2fO\SFP]qnXJT9QSPvBjnF
KabJQ_^`G]QSK\S\_X%QSI9GHbFKPV#
F G =A> , = 1 GuKIOMcQScQSGhZYb JT#F!PcK\g\M#Y3cKQSIOPI#F]j M#Y3cKQSI9PLjUQ_JTKIQSM#FI(JQ fi
G]K\d\SKab/[F]bPQ_]FvjUQSJTiJT9FKM9M9Q_JQ_Y3IOK\emFI#F]^9JPfiJTOKaJobFKPVY3I9KaeO\SFGHY3c2fOKab/QSPY3I9PficKXemFcKM#F2Y3I
f9b/WOI9QSI#[#
"T9FoN8K\SW9FoYZ
fffipVp ( VQSPJT#F]bF]Z:YbF ffV"A
E 8 Q * , = 1 , 1

=


<

C

`>



#Y3\S\SYjUQSI9[iKabF%JT#bF]F%FH{fmF]b/Qgc2FIJK\BPVFGHJQ_Y3I9PvdKQSc2FMKaJffJVFPVJQgI#
[ Y3IJT9bF]F%QgPPW#FP]i"T#F
^9b/PJBf9b/FPVFIJPLFHuJVFI9PQSNFhb/FPW9\_JPnY3I%JT#FfiJVb/KM#F]Y*PQSc2f`\SQSG]Q_J)XfiKG]G]W#bKGHX2Ye9JKQSI#FMke{X
!v9KI9M
GHY3c2fOKab/FP JT9FffbFP/W9\_JP jUQ_JTlJT9Y3PVFYe9JKQSI#FMiZYbfiPVJKaJVF fiDYZ fiDJT#F fiKabJ!K\S[Yb/Q_JT9cP "T#F-PVFGHY3I9M[Y{FP
Y3I%QSIM9F]f9JTKI9K\SX(]FPnZ:YbBJT#FficQSIOQSI#[ 8QSI(JVF]bf9bF]JKae`QS\SQ_J)XffQSPP/W#Fv(KI9MJT#FhJT9Q_b/Mf9bFPVFI(JPnbFPW9\_JPRY3I
I#Y3QSPFoJVY3\_F]b/KI9GHF

!

" !$3y> fi?;'87

$ ff


3

$

ufmF]b/QSc2FI(JPijBF]bFG]Kabb/QSFM Y3W9JW9P/QSI#[ JT9bF]FN8Kab/QgKIJPYZ
fijUQ_JT Yf9JQScQgPVJQSGfOb/W9I9QSI9[

:p Y(vhjUQ_JT1fFP/PQScQSPJQSGkf9b/W9IOQSI#[1p:fvhKI9M1jUQ_JT#Y3W#Jf9b/W9IOQSI#[1p ff3 KaeO\_Fxf9bFPVFI(JPkPVY3c2F5bF fi
PW9\SJPY3IN8Kab/QSY3W9P!M9KaJKPF]JP]vRc2Y3PVJffYZ"jUT9QgG/TjnF]bFJKFIZbY3c JT#F ob/F]fY3P/Q_JVYbX5YZ"cKG/TOQSI#F
\_FKab/IOQSI#[M9KaJKae`KPVFp.qn\gK FF]JK\w_vffxyy3 #YbFKG/TtM9KaJKPF]J]vUJT#FF]NFIJWOK\oM9QSPGHbF]JQSKaJQ_Y3I YZ
KaJVJVb/Q_e`W#JVFPjLKPifF]b/ZYb/cFM Z:Y3\S\_Yj QSI#[f9bF]NuQ_Y3W9PbFGHY3cc2FIOM9KaJQ_Y3I9PiKI9MFHufmF]b/QSc2FI(JK\!PF]JW#fOP
p.M#F KabN8K\gT#Y Y3c2FP r KP/G]W#F\wv0xyy +("UT#FbFPWO\_JPjnF]bF!GHY3c2fOW9JVFMW9PQgI#[K2JVF!I fiDZ:Y3\SMPJVb/KaJQ fi
^9FMkGHbY3PP"N8K\SQgM9KaJQ_Y3If9bYuGHFM9W#bF2fip fffiW9QSIO\SKI7v`xyy|3n"T#Fo\_FKPVJLF]bb/Yb/PLZYb KabFW9IOM#F]b/\SQSI9FM
Z:Yb FKGTM9Y3cKQSI7#YbhJT#FffP/K FffYZdGHY3c2f`Kab/QSPVY3I9Pv`GHY3\SW9cI ff/hJT#F]b/
P fmY3QSI(JPY3W#J N8Kab/QSY3W9P"bFP/W9\_JP
Z:Yb-YJT9F]bK\_[Yb/Q_JT9cP]vdQSI(JVFI9M#FMJVYT#F\_f[F]JVJQSI#[K[FI#F]b/K\LfOQSGHJW9bFYZUjUT9KaJ2G]KIemFJT#FkfmF]b fi
Z:Yb/cKI9GHFP!YZBF G]QSFIJ-Kaf9f9bY3KGT#FPjUQSJTM9Q *mF]bFIJoY3W9JVfOW#JPp.M#FG]QgPQ_Y3I\SQSPJP]vJVbF]FP]v GHY3ccQSJVJVF]FP]v
F]JGavOQSIJVF]b/cPnYZF]b/bYb/Pop.KI9M7vujUT#FI%Kaf9fO\gQSG]KaeO\_Fv{PQ_]FPB{Y3cF YZJT9FficY3PVJLbF\_F]NaKIJnbFPW9\SJPRZ:Yb

KabFPWOccKab/Q_]FMQgIkJT#F!PG]KaJVJVF]bf`\_YJP"YZ 0Kae`\_F!~{
"T9FiQSI(JVF]bf9bF]JKaJQSY3I YZ KaeO\_FxW9P/QSI#[Y3I9\SXF]bbYb/P[3Q_NFP%JT#FiKM9N8KI(JKa[F5JVY jUQ_JT
fmFPPQScQSPVJQSGf9b/W9I9QgI#[#vUK\S\hJT#Fc2Yb/FKP p:f%T9KPkJT#FKM#NaKI(JKa[FYZ-f9bYNuQSM9QgI#[PQgc2fO\_F]b
Z:Yb/cffWO\SKPhJT9K/
-p ff3v0KI9M5T9KPoKkcffW9GT5PQSc2fO\SF]b f9bW9I9QSI#[PJKa[FJT9K/
p:Y(ffE"FP/W9\_JP
K\SPVY5GHY3c2fOKab/FZ.KNYb/Kae`\_XJVY5JT#F ff/fiJT#F]
b lb/FPW9\_JP]v eOWOQS\SM9QSI9[%FQSJT#F]b-} P]v}hUP]vYb-} Pi"T#F]X
KabF!K\g\7JT#F!c2Yb/FffQSI(JVF]bFPVJQSI9[Q_Z0jnF!GHY3c2f`KabF!JT#F!F]bbYb/P"QgIJT#F!\SQS[3TJYZ JT#F-PQ_]FPYe9JKQgI#FM7B9Yb
JT#F ff RGT#6Y lM#Y3cKQSI7v jUQ_JTifFP/PQScQSPJQSGf9bW9I9QSI#[eFKaJPoQgc2f9bYNFM h~e{XJ)jBYlfmY3QSI(JP]v
:

$Q

fi

}hY3cKQSI
W9PVJVb/K\gQSKI
qLK\SKI9GHF
qnbFKPVJ fi
qLW#fOK
BG/T#Y
\gKPP/~
" FKabJ fi
" FKabJ fi
" FKabJ fi "
" F]fOKaJQ_JQSP
" Yb/PVF
b/QSP
KaeYb
R}
R}hF]NFI
R}hF]NFIO~
W9I#[
Y3(I mx
Y3(I #~
Y3I(
BQScK
Y3\_F
uT{W#JVJ\_F
"QgG]0KG]0Y(F
FT9QgG]\_F~
YJVF
YJVF3x
KNF]ZYb/c
QSI#F
fi}o|

F]bb
x2)4 3
~)~ 4
4 +|
)| 4 3
)~ 4Sx +
~u3x 4a|
~+ 4
~)~ 4&ya
~)~ 4&|3
~a2 4
2x )4&~|
)4



-p:Y(

2x )4
ux34 3y
x )4Sx
a2 4
+)
~ 4
2x )4
~+ 4 +
)4 +
~)y 4&|ux
)| 4&|3
)4&~3
~)~ 4 +(
~)| 4 +(
)| 4&ux
x]2 4&ya
a2 4 +y
x]2 4
x)| 43



x34Sx
S4 x
x34Sx
)4&~
3x 4&
x34
)4Sx
~)4&y
)4&y

+

)4 +

x34
x34&y
~)4&y
|)4&y
~)4
+ 4Sx
x34
+ 4Sx
)y 4
)4&|
)~ 4&~
x34
3x 4
)4
)~ 4&
3x 4&y
)~ 4
+ 4&
)4
)4&~

iwc

8

3x 4&
x]24
+ 4
x~)4 +

)4&y

4
)4&y
y)4Sx
x]24&y
) 4
)4&|
+ 4&|
)4
)4 +
)| 4Sx
x)| 4 +
)4&
y)4
) 4 +
+ 4&
)4&y
+ 4Sx
)~ 4
x + 4+
4&
)4
+

)4
)4&~
|)4&~

x + 4+


-p:f

]F b/b
x|)4
x + 4a|
+ 4 3
3 4Sx +
~3 4&|
~u3x 4Sx
x)y 4 +
~u3x 4&
~a2 4 +5
x)y 4&~ +
2x )4 3
)4



x2)4
~+ 4&~
x~)4 +
~ )4S2x
+)
~ 4
2x )4
~u3x 4 +
)y 4&y
~)| 4Sx
)4 ~
)4&~3
~a2 4Sx]
~)| 48
) 4 +3
)y 4&y
~ )4 +(
)y 4 +(
x 4



+

3x 4&|
y)4&y
)4
4

4
x34
)4
|)4
)4 +
4
)&4
~)&4
)4
x|)&4 ~
)&4
S4 x
~)&4 |
)&4 ~
x)&4 ~
+ 4
)4
+ &4 ~
x34
|)4
+ 4
+ 4
4
4
)4
|)&4 ~
+


ffff

8

+ 4Sx
~3 4
u~ x34
x)| 4&|
x3x 4Sx
)4 +

ux34 +

~3 4 +
~+ 4&~
x 4
x]24 +
S4 x
)| 4&|
~u3x 4
)y 4&~
~)| 4Sx
S4 x
x )4
|u3x 4
) 4&y
~)y 4 +
x)~ 4
)~ 4
x 4&|
x3x 4&~
)4
x + 4&y
x 4
) 4Sx
x S4 x

-p ff3

]F bb
x)4Sx +
x + 4&~y
)| 4&ya
3 4Sx +
u3x 4 +~
~)| 4 +(
~u3x 4&
~)4 +
~a2 4
2x )4&~y
~a2 4&~|
~a2 4&|3
x)| 4&|3
~+ 43
~+ 4&|
~u3x 48
+)
~ 4
2x )4
u3x 4&a
x)~ 4
)~ 4&yy
3 4&| +
+ 4 ux
~ )4
)4Sx
x]2 4
x)~ 4
~a2 4&~ +
4&y
~)~ 4&|y

8



+ 4&
x)4
4
4
~+ 4&|
+

x 4
&4
~)y 4
~) 4 +
) 4&
x~)4
+32
4&
+)
| 4&~

4

++

x~)4
x)4

x + 4
x x34 +
x)~ 4
)4
)4&
x)y 4
)y 4&y

~+ 4 +
)~ 4
y)4 +
~+ 4&
y)4
~)~ 4&~
~+ 4
)~ 4
2x )4&y
x|)4 +
y)4
x )4&|
+32
4Sx
+ 4&~
x)y 4&

)4

+

~|)4
u3x 4
&4
)| 4

~)4 +
~u3x 4&y
)4&
&4 ~
x 4&y
)~ 4Sx
x~)4
|) 4&y
|)4&
+ 4
+ )4
+)
| 4
x) 4&y
~)y 4
| )4
) 4&y
)
~ 4

hJT#F]b
2x )4Sx 4ff
0 )
~a2 4Sx @fffi 0 )
+ 4&y .!( @ )
3 4 42* 0 )
)~ 4 4ff
~|)4 @ 0 )
~ux34 G
~~)4 . 0
~u3x 4& fi0 4
x)y 4&~ 4A 0
2x )4 ( 4 )
)4 G
x)| 4 ux fi @
~ )43 ( . .
x )4 (
. )
~ )4Sx .ff )
+)
| 4&
| "
x)| 4&|| 0
~)y 4 ( @ 0
)~ 4&|3 . 0
~ )4&G


)4 @!( fi )
x34 .ff
@ )
x)4 ( 40
)
~)4&| 24 0 )
+ 4
fi
x]24&y fi

)4 .!( @ @
~~)4&"



~ux34&~ @ 0 )

0Kae`\_Fx ufmF]b/QSc2FI(JK\mbFPWO\_JPW9PQSI9[1!
3Y I(NFIJQSY3I9P 8 QSP"JT#FffjUT#Y3\_FffI(W9cffemF]bUYZd\SQSJVF]b/K\SP"YZdK%} v QSPUQSJP I{W9cffeF]bUYZdb/W9\_FPL9Yb
ff/hJT#F]bP uv#I(W9cffemF]b/PRKab/F [3Q_NFI%Y3IJT#FhZYb/c F]bbYb PQ_]F v(j T#F]bFikQSPBQSc2f9b/YNFM h~%p fi~ fi n L
,
1
eOW9Qg\SM9QSI#[l} P]vdPQ_]FQSPffJT#FI(WOc!emF]b-YZU\SQ_JVF]b/K\gP%p.}hY3cQSI9[Y3P]vUxyy3 @ QSPff } eOWOQS\SM9QSI9[l} P]v
r Kaf9f(Xvxyy3 QgP +# p.#b/KI9
G r Q_JVJVFI7v"xyy3 tQSP+}
I#YJKaJQ_Y3IOP!Z:Y3\S\_Yj p UYuG
eOW9Qg\SM9QSI#[o} P]vuI#YJKaJQ_Y3IOPRZ:Y3\S\_Y`
j 5p Y{
G r KPG]W#F\wv7xyy 3 "2QSPU
x fi FKabFPVJ FQ_[3T(eYbBb/W9\_FhKI9M
)!QgP +# lp:f9b/WOI#FM7v#M#F]Z.KW9\_JLfOKab/Kc2F]JVF]bPneOW9Qg\SM9QSI#[ff}hUP]z9JT#FPQS]FoYZ KJVb/F]F!QSPQ_JPj T#Y3\_FoI(WOc!emF]b
YZI#YuM#FP]


eOW#J JT#Fff} Ye9JKQSI9FMiGHY3I(JKQSI9P bY3W#[3T9\SX%FQS[3TJhJQSc2FP ZF]jnF]bo\SQ_JVF]b/K\gP"JT9KI fi~ fi n fi
P M#FG]QgPQ_Y3I
\SQSPJ] Z-jBFFH#GHF]f9J ff YJVF uv-Y3I K\S\fiYJT9F]bf9bYe`\_FcPkY3ItjUTOQSG/TjnFM9QSPfY3PFiYZ fi~ fi n fi P

$

: :

fi50

50

45

45

45

40

40

40

35

35

35

30
25
20
15

30
25
20
15

30
25
20
15

10

10

10

5

5

5

0

0
0

5

10

15

20 25 30 35
WIDC(p) err. (%)

40

45

50

0
0

5

10

15

20 25 30 35
WIDC(p) err. (%)

40

45

50

0

100

100

80

80

80

60
40
20

WIDC() #litterals

100

WIDC() #litterals

WIDC(o) #litterals

WIDC() err. (%)

50

WIDC() err. (%)

WIDC(o) err. (%)



60
40
20

0
20

40
60
WIDC(p) #litterals

80

100

10

15

20 25 30 35
WIDC(o) err. (%)

40

40
60
WIDC(o) #litterals

80

45

50

60
40
20

0
0

5

0
0

20

40
60
WIDC(p) #litterals

80

100

0

20

100

KaeO\_F!~&huG]KaJVJVF]b/fO\_YJPPW9ccKab/Q_QSI9[ PVY3c2FLbFP/W9\_JP0YZ` KaeO\_FfixBZ:Yb JT#FLJT#bF]F.'OKNYb/P YZ
!vQSI
JVF]b/cPLYZF]bbYbp:^9bPVJLbYjhBKI9MkPQS]F2#p 8nv#PVFGHY3I9MkbYjhv#Y3IkJT#FfiJT9Q_bJ)XM9KaJKPVF]JPRKGT
fmY3QSI(JoKaeYNF2JT#F % \SQSI#FM#F]fOQSGHJPoKkM9KaJKPF]JZYboj T9QSG/TJT#FK\S[Yb/Q_JT9cQSI5KaeOPG]QgPPK
fmF]bZ:Yb/cPLemF]JVJVF]b
bFPWO\_JP]v3jnF"Y3W#JVfmF]bZ:Yb/c fi~ fi n Y3I2emYJTKG]G]W#bKGHXKI9MPQ_]F QSI9K\g\_Xv3Y3I ff YJVF uv9I#YJVFUJT9KaJ

jUQ_JT5YfOJQScQSPVJQgGf9b/W9I9QgI#[%QgPoP\SQ_[3T(J\_XY3W9JVfF]b/ZYb/cFMe(X fi~ fi n e{X~)4 ux kv e`W#JoJT#F
} Ye9JKQSI9FMlQSP a2N / JQScFP"PcK\S\SF]bJT9KIkJT#F!M#FG]QgPQ_Y3Ik\SQSPVJLYZ fi~ fi n U9)Z jnFM#jBF\g\mY3IJT#F
bFPWO\_JPUYZ +# {vPQScQS\SKabUGHY3I9G]\gW9PQ_Y3I9PhG]KIemFffe9b/Y3W#[3TJ UY3Ix~Y3W9J YZhxMOKaJKPVF]JPfiY3IjUT9QSGTjnF
b/KI +# {v p:f ^OI9M9PfiPcK\S\_F]bfiZYbcffW9\gKP]vKI9MPVJQS\g\emFKaJP +# & PffKG]G]W#b/KGHXY3Iy%YZnJT#Fc
{W9KI(JQ_JKaJQ_NFGHY3c2f`Kab/QSPVY3IYZ 8 Ka[3KQgI9PVJoJT#F2I{W9c!emF]bfiYZBI9Y{M#FPhYZBJT#F}fi"PoPT#YjUPhJT9KaJoY3I
+M9KaJKPVF]JPfiY3W#JhYZRJT9F%x 5p Y3\_Fv0uT{W#JVJ\_Fvm"QSG] KG]Y{Fv W9PVJVb/K\SQgKI`vOJT#F2} PfiKabFc2YbFJT9KI|
JQSc2FP PcK\S\SF]bv9jUT9Qg\_FoJT#F]XY3I9\_XQSIOG]W#bUK\SY3PPUQSIKG]G]W#b/KGHXlZ:Ybfi~YZJT#FcvKI9M\SQgcQ_JVFMkJVY5xa& %
#Yb JT9QSP0\SKaJVJVF]b f9bYeO\_Fc p."QSG] KG]Y{Fv3K [3\SQSc2fOPFdKaJ KaeO\_FhxRPT#YjUP0JT9KaJ0JT9FB} P]vajUQ_JTff\_FPPJT9KI
b/W9\_FP Y3I5KNF]b/Ka[Fv F]F]fOPoGHY3c2fOKabKaJQ_NF\_XicY3PVJ YZBJT#F2QSI#Z:Yb/cKaJQ_Y3IiGHY3IJKQgI#FMQSI}hUPhTOKNuQSI#[
c2YbFUJT9KIKT{W9I9M#b/FM-\SFKNFP]BfiIcKIXf9b/YeO\_FcP jUT#F]b/F"cQSI9QSI9[fiQgPPW#FPKabF GHb/W9G]QSK\wv3P/W9G/TK!PQ_]F
bFM9WOGHJQ_Y3I%jBY3W9\gMemFfijBF\g\`jnYbJT%JT#Fp.GHY3c2fOKabKaJQ_NF\_XkP\SQ_[3T(Jd\SY3PPLQSIkKG]G]W#b/KGHXv9emFG]KW9PVFfijnF F]F]f
K!P/Q_[3I9Q_^OG]KI(JfOKabJRYZ7JT#FUQSI#Z:Yb/cKaJQSY3I2Y3INF]bXP/cK\S\#G]\SKPP/Q_^9F]b/P]vJT(W9PB\S#Q F\_X-JVY!emFUQgIJVF]bfObF]JKaeO\_F

n"<74" fi#E" 72@y;'87 .d.53#"F.

+I5JT#F h}o|M#Y3cKQSI7v7FKG/TFHuKc2f`\_F2T9KPx]keOQSIOKabXlNaKab/QSKaeO\_FP!"T#FJVFI(JTQSPoQ_bb/F\_F]N8KI(JoQSIJT#F
PVJVbY3I9[FPVJPVFI9PVFp Y3TOI7v Y3T9KN{QDv r 8'9F][F]bvffxyy+( "T#FJKab[F]JlGHY3I9GHF]f9J
QSP%K fi} h p.K
:



$4z

fi

iwc

7

0 6 ( 6
4 6 6-
fi 6 * 6-
( 6
0 6 .



ffff



fi/x
.

fi/x


x

fi/x
@



M#F]Z.KW9\_J )

x

fi/x

x

x
u&y|

(

x

fi/x
fi/x



u 3

Q_[3W#bFx } Ye9JKQSI#FMY3IJT9F fi}fi|!M#Y3cKQSIjUQ_JT-p:fdUT#F"^9b/PJdJT#bF]F b/W9\_FPFH#KGHJ\_X
FI9GHY{M9FJT#FoJKab[F]JhGHY3I9GHF]f9J]v`KIOMkJT#F!Q_bb/F\_F]N8KI(JLN8KabQSKaeO\_FQSPKae`PVFIJUZbY3c JT#F}






4

0

fi
*



@



@






*




@

(

fi




*





0





(



.






(






4




fi



(



.





@









fi





Q_[3W#bF!~& aK b/JUYZK}fiYeOJKQSI#FMY3IJT#F fi}fi|M#Y3cKQSIljUQ_JT +# { Y3PQ_JQSNF!\SQ_JVF]b/K\gP\SKaemF\7JT#F
QSIJVF]bI9K\uI#Y{M9FP] 0YoG]\SKPPQSZX!KIYe`PVF]bNaKaJQ_Y3I7vJT#F\_F]Z:J FM#[FLYZKfiI#YuM#FLQSP ZY3\S\SYjnFMjUT#FI
KI2YeOPVF]bNaKaJQ_Y3IGHY3I(JKQSI9P p fffiff` % JT9FfY3P/Q_JQ_NF"\SQ_JVF]bK\wv3KI9MJT#Fb/QS[3TJFM#[F QSP ZY3\g\_YjnFM
YJT#F]bjUQSPFffp J 1.2 1dJT#F \gQ_JVF]b/K\OQgPRI#F][3KaJQ_NFfiQSI2JT9FUYeOPVF]b/N8KaJQ_Y3Id"T#F"emY3\SMP/(W9Kab/F QSPBW9PVFM
JVY%M9QgPVfO\SKXJT#Ffff9bFPVFIOGHF!YZJT#F-Q_bbF\_F]NaKI(J"N8KabQSKaeO\_FQSIJT#F!JVb/F]F I9KQ_NF-GHY3INF]b/P/Q_Y3I
YZ JTOQSPLJVbF]F!QSIkbW9\_FPLZ:Yb"emYJTlG]\SKPPVFP"[FI#F]b/KaJVF
P a2b/W9\_FPv{Z:YbUK2JVYJK\YZxay2\SQ_JVF]b/K\gP]

$

: 2;

fi

}
jUQ_JTFKG/Tc2Y3I#Y3cQSK\RGHY3I(JKQSI9QSI9[iKaJc2Y3PVJ-JT#bF]Fk\SQ_JVF]b/K\SPhYNF]b2JT#F^9b/PVJ-I9QSI#FN8Kab/QgKaeO\_FP
p 0 6 ( 6 . p 4 6 6 p fi 6 * 6 @ uW9G/TK2ZYbcffW9\gK-QgPJX{fOQSG]K\S\SX%T9KabMkJVYFI9GHYuM#F
W9PQgI#[K5PcK\S\BM#FG]QSPQSY3IJVbF]F5+IY3W9bffFHufmF]b/QSc2FI(JP!j Q_JT
-p:Y(-KI9
p:fvjBFT9KNF
bFcKa
b FM5JT9KaJoJT#FJKab[F]JoZ:Yb/cffWO\SKQSJPVF\_ZRQSPfiK\ScY3PVJoK\_jnKX{P!KI5F\_Fc2FI(JhYZBJT#F2G]\SKPPQS^9F]bfieOW9QS\_J]v
KI9MkJT#FffQ_bbF\_F]NaKI(JLKaJVJVbQ_eOW#JVFQSPK\SjnKX{P"Kae`PVFIJ]B QS[3W#bFxoPT#YjUP"KIFH#Kc2fO\SFoYZ } jUTOQSG/TkjLKP
Ye9JKQSI9FMkY3IlKb/W9I%YZ ! YJVFJT9KaJJT9FGHY3I9GHF]f9JbF]JW#bI#FMQSPK fi} 9 Q_[3W#bF!~M9F]fOQSGHJPK
fOKabJYZ K2JVbF]FoYe9JKQgI#FMkY3IJT9QSPLM#Y3cKQSIkjUQ_JT +# { T9QS\SFhJT9FoJVbF]FKaf9fmFKab/PLJVYemFo(WOQ_JVFo\SKab[F
Z:YbnJT9FhM#Y3cKQSI7v(I9YJVFhJT9F f9b/FPVFI9GHFhYZJT#FfiQ_bbF\_F]NaKI(JRNaKab/QSKaeO\_F QSIJT9F JVbF]FvujUTOQSG/T%Q_JBGHY3I(JVb/Q_e`W#JVFP
JVY-FI9\SKab[F jUT9QS\_F"cK {QSI9[!Q_JRT9KabM#F]bRJVYcQSI#FdfiI%cKI(X2YJT#F]bnM9Y3cKQSI9P]vjBFhYeOPVF]bNFMfmF]b/PQSPJVFIJ
b/W9\SFPYbhP/W#e7GHY3I9GHF]f9JP"JT9bY3W#[3TlJT9Fx]GHb/Y3PP fiDNaK\SQSM9KaJQ_Y3Ilb/W9I9P]"uQScQS\SKab/\_XJVY fi}o|{v`jUT9FI#F]NF]bUjnF
GHY3W9\SMkcQgI#FUJT#FfibFP/W9\_JPBjUQ_JTkKP(W G]Q_FI(J\_XKG]G]W#bKaJV,
F {I#YjU\_FM#[FfiYZ0JT#FoM#Y3cKQSI7v{JT#FPVFfifOKaJVJVF]bI9P
jnF]bF-cY3PVJ QSI(JVF]bFPVJQgI#[#U#YbfiFH#Kc2fO\_Fv`JT#F-} P Ye9JKQSI9FMlY3IiJT#F R}hF]NFI5M#Y3cKQSIiGHY3IJKQgI#FM
c2Y3PVJLYZJT9FhJQgc2FhKGHY3cffeOQSI9KaJQSY3IYZ0JjnY2b/W9\_FPBjUQ_JTY3I#Ffi\SQ_JVF]b/K\`FKG/T7v#j T9QSG/TbF]f9b/FPVFIJVFMK-NF]bX
KG]G]W#b/KaJVF!jnKX%JVYG]\gKPPQ_Z:Xy-Y3W#JYZ JT#F2x]2fmY3PPQ_e`\_F G]\SKP/PVFP]BfiIkJT#F YJVFKI9M YJVF3x!M#Y3cKQSI9P]v
jnFK\SPVYYeOPVF]b/NFMGHY3I9PVJKI(JfOKaJVJVF]b/IOP]v0PVY3cF2YZBjUTOQSG/TKabF2jnF\S\ uI#Yj Ip.qn\gK FF]J!K\w_vRxyy3oJVY
f9bYN{QgM#FhKNF]b/X%KG]G]W#bKaJVFG]\SKPPQ_^`G]KaJQ_Y3IkZYb"K-JQSI(XP/Q_]F dNFIZ:Yb YJVF3xojUT9F]bFoG]\SKPPQSG]K\mPVJWOM9Q_FP
YZ:JVFIbF]fmYbJF]b/bYb/P2YNF]bx~ %vKI9M1K\Sc2Y3PVJI#F]NF]bKabY3WOI9M x] p " Y3\_JVFvxyy 3vjnFYeOPF]bNFM
Y3IcY3PVJ!YZJT#Fb/W9I9P!K} GHY3I(JKQSI9QgI#[KIKG]G]W9b/KaJVFbW9\_FjUQSJTJjnY\gQ_JVF]b/K\SPoY3IO\_Xv0j Q_JTjUT9QgG/T

-p:fnf9b/YNuQSM#FMkY3IlKNF]b/Ka[F-KIlF]bbYbUW9IOM#F]bx] %

jnKPfiK\SPVY%GHY3c2fOKabFMJVY +# Y3IKbFK\0jBYb\SMM#Y3cKQSIY3IijUT9QgG/TcQSI9QSI#[QgPPW#FPhKabF
KP%GHb/W9G]QSK\"KPG]\SKPPQS^OG]KaJQ_Y3IPVJVb/FI#[J9T 5Ka[b/QSG]W9\_JW9bF IFHufmF]b/QSc2FI(JQSP2emFQSI#[G]Kab/b/Q_FMY3W9JQSI
KabJQSI9QS{W#F-e(XJT#F2}fi} p.}hF]fOKabJc2FI(JK\R}fiQ_bFGHJQSY3I5YZ [b/QSG]W9\SJW#bFKI9M#YbFPVJv0JVYKG/TOQ_F]NF
emF]JVJVF]b-WOI9M#F]b/PVJKIOM9QSI#[kYZJT#FeFTOKNuQ_Yb!YZZ.Kab/c2F]b/Pv QSIfOKabJQSG]WO\SKabbF][3Kab/MOQSI#[lJT#FQSb!jUQS\g\SQSI#[3I#FP/P
JVY2GHY3IJVbKGHJ"K p.OKab/cQSI#[0F]bb/Q_JVYb/QgK\ Y3I(JVb/KGHJ hPW9K\`Z.Kab/cQSI#[-GHY3IJVbKGHJPjUQ_JTFQ_JT#F]bLJT#F
PVJKaJVFp.#b/KIOGHFBYb BW#bYfmFUM9QgMI#YJLGHY3IJKQgIGHY3ccQ_Jc2FI(JPnZYbnJT#FhZ:Kabc2F]bLJVY-PKaJQgPVZX+I%K "v
FKG/TZ.Kab/c2F]b2GHY3ccQ_JP-JVY5KMOKaf9J-KIOM YbG/T9KI9[FkTOQSPffKa[bQSG]W9\_JW#bK\dJVFG/TOI9QS{W#FP-Yb-fObY{MOW9GHJQ_Y3I9P]v
JVYFIOPW#bFP/W9PVJKQSI9Kae`\_FM#F]NF\_YfOcFIJffZYb-\_Y{G]K\BKa[b/QSG]W9\SJW#bF%IFHuGT9KI#[F%ZYb-JT9QSP]v T#FbFGHFQSNFP
JT#F[3W9Kab/KI(JVF]F2JVYYe9JKQSI^OIOKI9G]QSK\ T#F\_f5ZYbfiJT9QgPhGHY3I(JVb/KGHJ]v KI9MJVYeF-JVb/KQSI9FMiJVYI#F]j Ka[bQSG]W9\ fi
JW#b/K\ JVFGT9I9QS{W#FP]uWOG/TKM#Y3cKQgIQSPfiK[Y(YuM5JVFPVJemFM5JVYF]NaK\SW9KaJVFKcF]JT#Y{M5Y3IJT#F2eOKPQSPfiYZ
f9bFMOQSGHJKaeOQS\SQSJXKI9MQSI(JVF]bf9bF]JKaeOQg\SQ_JXv7emFG]KW9PFYZLJT#FfO\SKGHFYZLWOI9GHF]bJKQSI(JXQSIKa[b/QgG]W9\_JW#bFv KI9M
JT#FkZ.KGHJ2JT9KaJYe9JKQSI9QSI9[iM9KaJKG]KIemFkKTOKab/MKI9M\_Y3I#[JKP JT#F}fi} TOKPffJVYemFkKP2K
G fi
G]W#b/KaJVFKPfifmY3PP/Q_eO\_F-QSIiQSJPfif9bFM9QSGHJQSY3I9P KIOMQgIJVF]bfObF]JKaJQ_Y3I9P]v7JVYlcKI9Ka[FKPfiemFPVJoKPfifY3P/PQ_eO\_F-Q_JP
bF\SKaJQSY3I9PT9Q_f`PjUQ_JTZ:Kabc2F]b/P]v#KI9M%QSIJT#FoG]KPVFfiYZ BP]v(JVY2cK FfiJT#FfiemFPVJnf9bY3c2YJQSY3IG]Kc2f`KQ_[3I
Z:YbUJT#FPVFffI#F]j GHY3I(JVb/KGHJP] [b/QSG]W9\SJW#bFoQSP"K\SPYNF]bXlPVFI9P/Q_JQ_NFoJVYK ffVPT#YjLG]KPVF-F *FGHJ Lf9b/YNuQSM#FM
F]NFIlZ:F]j bF]fObFPVFI(JKaJQ_NFZ.Kab/c2F]b/PLjUQg\S\mT9KNF!P/W#eOPGHb/QSeFMJVYJT#FGHY3I(JVb/KGHJP]vGHY3c2fOKab/KaJQSNF\_XcKIX
YJT#F]b/PUKabF!\S#Q F\SXJVYZ:Y3\S\_Yj
+I5JT9QSPoPVJWOM#XvZ:bY3cJT#FM#FPGHbQ_f9JQ_Y3IYZ ~kN8KabQSKaeO\_FPfiZ:YbKaemY3W#J!|abF]f9b/FPVFIJKaJQSNFZ:Kabc2F]b/P
PKaJQSPZXuQSI#[JT#FGHb/Q_JVF]b/QgK5JVYKM9T#F]b/FJVYK "vRJT#FiKQSc QSPJVYM#F]NF\_Yf1cY{M#F\gP2ZYb%JT#Y3PVFjUT#Y
KabFKGHJW9K\g\_XjUQg\S\SQSI#[JVYlKM9T#F]bFv7JT#Y3PFI#YJojUQS\S\gQSI#[JVYlKM9T9F]bFvKI9MJT#Y3PVFG]W9bbFI(J\_XiW9IOGHF]bJKQSI7
dKab/QSKae`\_FP2KabFM9KaJKY3IFKG/T1Ka[b/QSG]W9\_JW9b/K\nFH{fO\SY3Q_JKaJQ_Y3Ip.PQS]FvBJVF]bbKQSII9KaJW#bFvn^OI9KIOG]QSK\LM9KaJKuv
JX{fmFYZ f9bYuM9W9GHJQ_Y3Iv{F]JGvOKP"jnF\S\KP c2YbFfmF]b/PY3I9K\7M9KaJKY3IlJT#FZ.Kab/c2F]b/P!p:FMOW9G]KaJQ_Y3I7v`Z:KcQg\_X
PVJKaJW9PvYe VFGHJQ_NFP]v(fF]bPVY3I9K\#KI9PVjnF]bdJVY!Ko{W#FPVJQSY3I9I9KQ_bFvF]JGaB"T9QSP bF]f9b/FPVFIJPRKPcK\S\#MOKaJKPVF]J
JVYcQSI#Fv{eOW#J]vuQSI(JVF]bFPVJQSI#[3\SXvJT#FhbFPW9\SJPRYe9JKQgI#FMjnF]bFfiM9Q *mF]bFI(JRjUT#FIf9bYuGHFPPQgI#[!Q_JnjUQ_JT +#
YH
b
-p:f
:

$5O

fi

iwc


ffff

p'& &:- &Efi- J&
$ ! V6p'& $8! &:-0
p'& &:- &Efi- J&
$ ! V6p'= $5- ff
( J&3!] 6p'& fi
0
&38'$ 58 $
M#F]Z.KW9\_J )

KMOT#F]bF
fi/x
x
u ~



fi/x

fi/x
u&|

KM9T9F]bF
x
x


Q_[3W#bF/& "T#F!} Ye9JKQSI#FMY3IiJT#F-Ka[b/QSG]W9\_JW9b/K\7M9KaJKip.PF]FffJVFHuJUZ:YbUJT#F-QSI(JVF]bf9bF]JKaJQ_Y3IYZJT#F
N8Kab/QgKaeO\_FP
FbKI5eYJTK\S[Yb/Q_JT9cPfiQSI5Kx] fiDZ:Y3\SMPVJVbKaJQ_^9FMGHbY3PP fiDN8K\SQgM9KaJQ_Y3IFH{fmF]b/Qgc2FIJ]1
-p:f
Ye9JKQSI9FMffKfi~)4& KNF]b/Ka[FF]b/bYb I|"Y3W9J0YZx]hb/WOI9P]v8JT#FnP/Kc2Fn} jLKP QgI9M9W9GHFM7)J QSP0f9bFPVFI(JVFM
QSI- Q_[3W#bF {qnKP/QSG]K\S\_XvaJT9QSP } f9bYNFP JT9KaJ f9bFM9QSGHJQgI#[UJT#F ff KM9T9F]bF2 fiG]\SKPP QSP JT#FnFKPQ_FPVJ JKP v
Z:Y3\S\_YjnFMle{XJT#FfObFM9QSGHJQ_Y3IlYZJT#
F ffVKM9T9F]b2F G]\SKP/P]"T#F ff
> p.W9I9GHF]bJKQgIlZ.Kab/c2F]b/PQSP"f9b/FM9QSGHJVFM
Y3I9\_Xe(XJT9FfiM9F]Z:KW9\SJBNFGHJVYbn"T9QSPnPVF]FcPnb/KaJT9F]b"I9KaJW#b/K\ jUT9F]bFKPnJT#FfiFH{JVbFcFoeFTOKNuQ_Yb/PBJVFI9M
JVYemFG]\_FKab"JVYM#F]JVF]b/cQSI9Fv#JT#F!W9I9GHF]b/JKQSIJ)X%QgPJT#FT9Kab/M9FPVJJVYf9bFMOQSGHJ]
+# p.M#F]Z.KW9\_JfffOKab/Kc2F]JVF]b/PoQSI9MOW9GHFMKi}h jUT9QgG/TjLKPK\Sc2Y3PVJffJT#FFH#KGHJJVb/KI9PGHbQ_f9JQ_Y3IYZ
b/W9\SF-xav9K-b/W9\SF jUTOQSG/T%PKXuPJT9KaJLZ.Kab/c2F]b/PLj Q_JTkI#YffFMOW9G]KaJQ_Y3Ip:jUQ_JT9Y3W#JnKI(XkKa[b/QSG]W9\_JW9b/K\`MOQ_fO\_Y3cK
YbkJVb/KQSI#F]FP/T9Q_fOPKI9MI#YY3I#[Y3QSI#[f9bY VFGHJKabFI#YJj QS\S\SQSI9[JVYKMOT#F]bF "T9QSPb/W9\SFiQSP%c2Y3PVJ\_X
QSI(JVF]bFPVJQSI9[%emFG]KW9PFQ_Jfif9bYNFPJT9KaJoFM9W9G]KaJQ_Y3IQgPoKPVJVbY3I#[Z.KGHJVYb!M#F]JVF]b/cQSI9QSI#[%JT#F ff KMOT#F]b2F
KI9PVjnF]b"T#Fff}hUPUQSI9MOW9GHFMlK\SPVYGHY3IJKQSI9FMY3I#FffYbUJ)jBYkc2YbF!\gQ_JVF]b/K\SP"PF]fOKab/KaJQSI#[JT#F ffVKM9T9F]b2F
KI9M ff
2 1G]\SKPPVFPp.KNF]bKa[FF]bbY2b ")| 4 vmeOW9JUY3I9\_XkZ:F]j YJT9F]bhJTOQSI#[3PUGHY3WO\SMlemFffcQSI#FMlZ:bY3c JT#F
JVbF]FPUYZ +# {vQSIkJT#F\SQS[3TJYZ JT#Fof9b/YeO\_Fc KM9M#b/FPPVFM7
E W9\_F~QgI1 Q_[3W#b/F M9QSMI#YJT9KNFJT#F5F(W9QSN8K\_FI(JkQSI JT9F5}fi"PkQSIOM9W9GHFM7 T9KaJQ_J%P/KXuP
QSP-QSI(JVF]bFPVJQSI#[iZYb-JT#Fk}fi} nvemFG]KW9PVF%Q_J!eOb/QSI#[3P!JT#FZ:Y3\S\_YjUQSI#[iGHY3I9G]\SW9PQSY39I Z:Kab/cF]b/P!j Q_JT#Y3W#J
Y3I#[Y3QSI9[2f9bY VFGHJP]vOKI9MI#YJ"PF\S\SQSI#[-JT#FQ_bfObY{MOW9GHJPnY3I9\_XJVYKjUT#Y3\_FPK\SF]bv#KabFY3IkJT#,
F uI9Q_Z:FfiFM#[F
Z:Yb2JT#FQ_b2c2FcffeF]bPT9Q_fp:FQ_JT#F]bQSI ffVKM9T#F]b/2F uvRYbQSI ff KM9T#F]b/2F Q_JT#Y3W#J-[Y3QSI#[5Z.W#bJT#F]b2QSI(JVY
\_YuG]K\`Ka[bQSG]W9\_JW#bK\OGHY3I9PQgM#F]b/KaJQ_Y3I9PvJT9QSPBb/W9\SFvZ:YbnJT9Fh}fi} RI#[3QSI9F]F]b/P]vb/F]f9bFPVFI(JPLKIKG]G]W#bKaJVF
NuQ_F]j YZ JT#FZ.Kab/c2F]b/P"KGHJWOK\S\_XkGHY3IJVbY3\g\SQSI#[JT#FQ_bFHufO\_Y3QSJKaJQ_Y3IlGHY3PVJP]vOeFQgI#[FQ_JT#F]b"Z:Yb"Yb Ka[3KQgI9PVJ
BP]v#KI9MJT9KaJFMOW9G]KaJQ_Y3IfOWOPT#FPnJVYjLKab/M9PUJT#Fc2FcffeF]bPT9Q_fp.GHY3c!e`QSI9KaJQ_Y3IYZ b/W9\SFPhx!KI9Ml~3v
f9bYe`KaeO\_XemFG]KW9PFQ_J"K\S\_YjUPJT#Fc JVYPVF]FJT#FZ.W#JW#b/FofYJVFI(JQSK\7emFI#F]^OJPLYZ JT9FGHY3IJVb/KGHJ]vemF]JVJVF]b
JT9KIlQSJP"G]W#bbFI(J"GHY3I9PVJVbKQSIJP



'.d"m "#?;'#"($

|c

p.qLKW#F]b r Y3T9KNuQwvoxyyy{z!hfOQ_JV r KG]\SQSI7v
x yyy3v3F]NFIGHY3I9PQgM#F]bFMkp.qnKW9F]b r1s Y3T9KN{QDvuxyyy30KP Q_JP0fmYJVFIJQSK\{cKQSI!f9bYeO\SFc d{fmF]b/QScFIJK\
PVJW9MOQ_FPUPT9Yj JT9KaJfiPW#eOPVJKI(JQSK\0I#Y3QSPVF-\_F]NF\SPhG]KIK\SJVF]b JT#F-NYJVFJVYJT9FfffmY3QSI(JUJT9KaJfiQ_JPhKG]G]W#b/KGHX
QSP\_YjnF]bJTOKI JT9KaJ%YZKP/QSI#[3\_FlYZQSJPG]\SKP/PQ_^9F]bipDfifOQ_JV r KG]\SQSI7voxyyy3 hfOQ_JV r KG]\SQSI
p+xyyy3fifmY3QSI(JhY3W#JfiJT#FbF]jBFQS[3TJQSI9[kP/G/T#Fc2F2YZBJT#F2FH#Kc2fO\_FPfiQSIemY(Y3PJQSI#[kKPfieFQgI#[%K%fmYJVFI(JQSK\
bFKPVY3IZYbBJT9QSPemFT9KN{QSYb"T#Y3W#[3T2jnFUM#YffI#YJBW9PF"KIX2bF]jnFQ_[3T(JQSI#[!P/G/T#Fc2Fv{jnFUT9KNFfiG/T9Y3PVFIZ:Yb
JT#F-PK F!YZdGHY3c2f`\_F]JVFI#FPP JVYKM9M9bFPP"JT9F!emFT9KNuQ_Yb"Y<
Z -p:f"Ka[3KQSI9PVJhI#Y3QSPVFv`KI9MGHY3c2f`KabF
Q_JPb/FPW9\_JP%jUQ_JTfmF]b/TOKafOPkJT#FcK VYbQSI9MOW9GHJQ_Y3IK\_[Yb/Q_JTOc jUQ_JTjUT9QgG/TjnFPT9KabFJT9F ff+JVYf fi
M#YjUIKI9M5f9b/WOI#2F kQSI9M9W9GHJQSY3IiPGT#Fc2F +# fip ffoW9QSI9\SKIv xyy +(UT9QSPfiPVJW9M#XbF\SQ_FPfiY3I5JT#F fi}o|
M#Y3cKQgI7vnQgIjUT9QSGTjnFbF]fO\gKGHFJT#FlYbQ_[3QSI9K\x] G]\SKPPI#Y3QSPVFp.qnWOIJQSI9F r hQ_eO\_F]JVJ]voxyy~3e(X
NaKab/Q_Y3W9PQSIOGHbFKPQSI#[KcY3W9IJPdYZmG]\gKPPdI#Y3QSPFb/KI#[3QSI#[oZ:bY3c JVY +3 e{X2PVJVF]fOPYZ~ %v3YbBN8KabQ_Y3W9P
Y3QSPVFiTOKI9M9\SQSI9[5QgPKGHb/WOG]QSK\UQSP/PW#FZ:YbemY{Y3PVJQSI#[

:

$$

fi

0.5

0.35

WIDC
C4.5
Bayes

0.45
0.4

0.25

0.35
0.3

error (%)

error (%)

WIDC
C4.5
Bayes

0.3

0.25
0.2
0.15

0.2
0.15
0.1

0.1
0.05

0.05
0

0
0

0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4

0

0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4

class noise (%)
100

attribute noise (%)
110

WIDC
C4.5
Bayes (DC)
Bayes (DT)

90
80

90
80

70

70
size

60
size

WIDC
C4.5
Bayes (DC)
Bayes (DT)

100

50
40

60
50
40

30

30

20

20

10

10

0

0
0

0.05

0.1

0.15

0.2

0.25

0.3

0.35

0.4

0

class noise (%)

0.05

0.1

0.15

0.2

0.25

0.3

0.35

0.4

attribute noise (%)

Q_[3W#bF,+( R\_YJPkYZffJT#F5F]bbYb/Pp.W#fmKIOMP/Q_]FPp.M#Yj I`YZ
-p:fv +# KI9MqLKXFPb/W9\_F
Ka[3KQSI9PVJ"NaKab/Q_Y3WOPG]\SKPP"I#Y3QgPVF\_F]NF\SP!p.\SF]ZJLKIOMKaJVJVb/Q_eOW#JVFffI#Y3QSPVFo\_F]NF\SPffp:b/Q_[3T(J
SQ I9GHb/FKPQSI#["Kc2Y3WOIJPYZ9KaJVJVb/Q_eOW#JVFBI#Y3QSPVFdQSIJT#FBPKcFdb/KI#[F "T#F fi}o|"M#Y3cKQSI!T9KPJT#FRKM#NaKI(JKa[F
JT9KaJ2JT#FkJKab[F]JGHY3IOGHF]f9JQSP {I9YjUI7vBKI9MQ_JT9KPemF]FIKMOM#bFPPVFMQSIKPW9eOPVJKI(JQSK\BKcY3W9IJ2YZ
f9bF]NuQ_Y3W9PhFHufmF]b/QSc2FI(JK\ jBY
b {P] FT9KNFPQSc-W9\SKaJVFMGHYb/bFPVfmY3I9M9QSI9[%M9KaJKPF]JPoY.
Z ux~FHuKc2f`\_FP
FKG/Tv#ZYbnFKG/TI#Y3QgPVFh\SF]NF\w RKG/TP/W9G/T%M9KaJKPVF]JLjLKPBfObY{GHFP/PVFM%e(
X
-p:fBKI9M +# {v#W9PQSI9[ffK
x] fiDZ:Y3\S!M fiGHbY3PP fiDN8K\SQgM9KaJQ_Y3If9b/Y{GHFM9W9bFR Q_[3W#b,
F +M#F]fOQSGHJPJT9FbFPW9\SJPYe9JKQSI#FMlZYb"JT9FF]bbYb/P KI9M
Z:YbUJT#F!P/Q_]FP"YZ JT#F!G]\gKPPQ_^9F]bP]B"T9FPQ_]FYZK} QSP"Q_JPj T#Y3\_F!I{W9cffeF]bUYZ \gQ_JVF]b/K\SP]v9KIOMJT9KaJUYZ
K}fi QSPUQ_JPI(WOc!emF]bYZQSI(JVF]b/I9K\7I#YuM#FP]
T9QS\_F JT#FRbFPQSPVJKIOGHFdKa[3KQSI9PVJI#Y3QgPVFdPVF]FcPJVY"emF b/F\SKaJQ_NF\_XhjBF\g\M9QSPVJVb/QSeOW#JVFMhKc2Y3I#H
[
-p:f
KI9M +# 'p
-p:fUPVF]FcP JVYfmF]bZ:Yb/c emF]JVJVF]bhZYbhG]\SKPPhI#Y3QSPVFv9j T9QS\_F +# PVF]FcP JVYfmF]bZ:Yb/c
emF]JVJVF]b"Z:Yb"KaJVJVb/Q_eOW#JVFoI#Y3QgPVFv9KfOT#FI#Y3cFI#Y3Ic2YbFQSI(JVF]bFPVJQgI#[2GHY3c2FPZ:bY3c JT#FPQ_]FPLYZ JT#FoZ:Yb fi
c-W9\SKPQSI9MOW9GHFM7 QSb/PVJ]vuJT#F} P"T9KNFoNF]bXkPcK\S\mPQ_],
F '`W9GHJW9KaJQ_Y3I9PLGHY3c2f`KabFMJVY2JT#F}fi"P Z:Yb
G]\SKPP!I#Y3QSPVFPo[b/FKaJVF]bffJT9KI~a %v0JT9F}fi"PT9KNFPQ_]FQgI9GHbFKPQSI9[%e{XKZ.KGHJVYb!YZoxa fi)~{uFGHY3I9M7v
I#YJVFLJT9KaJ JT#Fnb/KaJQ_YheF]J)jBF]FIJT9FnI{W9cffeF]b YZOI#YuM#FP0YZ9JT#FnJKab[F]Jd}fiovaKI9M-JT#FnI{W9cffemF]bYZ`\gQ_JVF]b/K\SP

$

: C

fi

iwc


ffff

YZnJT#FJKab[F]J!} QgP{#YbffKcK +Yb/QSJXYZLG]\gKPPfiYb!KaJVJVb/Q_e`W#JVFI#Y3QSPVF\SF]NF\SP]vJT#F2bKaJQ_YemF]JjnF]FI
JT#Fo}fi"PLeOW9Qg\SMKI9M%JT#Fo} PLeOW9Qg\_JBQSP
{v#jUQSJTKfOKaJT9Y3\_Y[3QSGhG]KPVFoZYbx] KaJVJVbQ_eOW#JVFfiI#Y3QSPVFvuZ:Yb
jUT9QgG/TJT#Fffb/KaJQ_YQgP
|{"T9FPVFbFcKab
{P]v`K\_Y3I#[j Q_JTJT#FZ.KGHJhJT9KaJ"JT#F-} P"eOW9Qg\_JT9KNFKNF]bX
bFKPVY3IOKaeO\_FPQ_]FLjUT#FIGHY3c2f`KabFM2JVYoJT9KaJ YZJT#FLJKab[F]JR} ZYbdKI(X-JX{fFKI9M2\SF]NF\uYZ`I#Y3QSPFvJVFI9M
JVYiP/T#Yj Kl[Y{Y{MI#Y3QSPVFT9KI9M9\SQgI#[kZY1
b p:f f`KabJZ:bY3c JT#FPFGHY3I9PQgM#F]b/KaJQ_Y3I9Pv0[3\SQgc2fOPVFP
KaJoJT#F2} PfiY3W#JVfOW9Jhe{
X -p:fhP/T#Yj JT9KaJfiF]NFIZ:Yb\SKab[F2I#Y3QgPVF2\_F]NF\SP]vQ_JocKIOKa[FPoJVYk^OI9M
GHY3I9GHF]f9JPhPVXuIJKGHJQgG]K\S\_XG]\_Y3PVFJVYJT#FJKab[F]Jfi} O#YbhFH#Kc2fO\_Fv9Y3I9FYZJT#F!} PUY3W#JVfOW#JUKaff
J
G]\SKPPffI#Y3QSPVFQSPFH#KGHJ\_XJT#FJKab[F]J-} z K\SPVY#v Q_J!QSP!Y3I9\_X5Z:YbffG]\SKPPffI#Y3QSPV=
F x~ p.KI9MKaJVJVb/QSeOW#JVF
I#Y3QSP
F x| nJT9KaJ PVY3c2F!} PZ:Y3W9I9MM9YI#YJUPVXuIJKGHJQgG]K\S\_XkQSI9G]\SW9M9F JT#F!JKab[F]J } KI(X{cYbF
< ? >


AaCD? >

E FGHFI(JLKM#N8KIOGHFPRQSI2JT9FUPVJW9M#X-YZ7NYJQSI#[ffG]\SKPPQ_^`G]KaJQ_Y3IK\_[Yb/QSJT9cPdT9KNF eObY3W#[3T(JdFc2fOQ_bQSG]K\#KI9M
"
JT#F]YbF]JQgG]K\LbFPW9\_JPG]\_FKab\_XPT#YjUQSI#[JT#FM9QSP/GHb/QScQSIOKaJQ_Y3IfmYjnF]b2YZUFI9PFc!eO\SF%G]\SKP/PQ_^9F]b/P"T9QSP
fOKafmF]bKM9M#bFP/PVFPnZbY3c K-JT#F]YbF]JQgG]K\7KI9M%Fc2fOQ_b/QgG]K\9fmY3QSI(JBYZNuQ_F]jJT#Fo{W#FPVJQ_Y3I%YZj T#F]JT#F]bLY3I#F
cQ_[3T(JT9KNFJVYM9QSPVfmFI9PVFkjUQSJTQSIJVF]b/f9bF]JKaeOQS\gQ_JXQSIYb/M#F]bJVY F]F]fG]\SKPPQ_^`G]KaJQ_Y3IPVJVbFI9[JT71+I
Yb/M#F]bnJVYGHYfFhjUQ_JTJT9QSPRf9bYeO\_FclvjnFhT9KNFhGT#Y3PVFI%JVYPVJW9M#XK-G]\SKPPBYZGHY3I9GHF]f9JnbF]f9b/FPVFIJKaJQSY3I9P
bFPVFcffeO\SQgI#[c-W9\_JQS\gQSI#FKabUM9QgPGHb/QScQgI9KIJUfY3\SX{I#Y3cQSK\SP]vOKM9F(W9KaJVF2Z:YbocQSI9QgI#[QSPP/W#FPUj T#FIiM9FK\SQSI#[
jUQ_JT5NYJQgI#[lf9bYuGHFM9W#b/FP]v7jUT9QSGT5jBFM#F]^OI#F2KP}hFG]QSPQSY3I Y3ccQSJVJVF]FP]%fiW#boJT9F]YbF]JQSG]K\bFP/W9\_JP
PT#Yj1JTOKaJnPVJVbQ_N{QgI#[oZYbLPQScfO\SQSG]Q_J)X-QgP]v(\SQ FUZ:YbncKI(X2YJT#F]bG]\SKPPFPRYZGHY3I9GHF]fOJBbF]fObFPVFI(JKaJQ_Y3I9P]v#K
T9Kab/MffGHY3c2fOW#JKaJQSY3I9K\3f9b/YeO\_FctjUT9FI!M#FK\SQgI#[jUQ_JT} Yb0YJT9F]b GHY3c2f`\_FHoNYJQSI#[UfObY{GHFMOW#bFP]vaKI9M
f9bYNFPhJT#F-T9FW#b/QSPVJQgGoI9KaJW#bFffYZdYJT#F]bhbFPW9\_JPUJVbXuQSI#[JVY%f9b/WOI#FKM9Kaf9JQ_NF-emY(Y3PJQSI#[#""T9QgP"fOKafmF]b
f9bYfmY3PVFP!JVYKMOKaf9J-Kif9bF]NuQ_Y3W9PffPG/T9Fc2FJVYeOW9Qg\SM5jBFK \_FKab/I#F]b/Pv P/W9G]GHFPPVZ.W9\dZ:Yb-JT#FQSIOM9W9GHJQ_Y3I
YZ"M#FG]QSP/Q_Y3IJVbF]FP-KI9MM#FG]QSPQSY3I\SQSPVJPv0JVYiJT#F%G]KPFYZ"} "T9QSPQgP!KIYb/Q_[3QSI9K\RKaf9f9bY3KGTQSZBjnF
bF]Z:F]bJVYJT#FoPVJKaJVF fiDYZ fiDJT#F fiKabJfiK\_[Yb/Q_JTOcPLeOW9QS\gM9QSI#[GHY3c2f`\_FH%NYJVFPUf9bYuGHFM9W#bFPv{W9P/W9K\S\_XjnYb uQSI#[
QSIiJT#FPVJVbY3I#[k\_FKab/I9QgI#[Z:b/Kc2F]jnYb `fiW#bfiK\_[Yb/QSJT9cv !vbF\SQSFP"Y3IbFGHFI(JPfiYbfiI9F]j bFP/W9\_JP
KaemY3W#J fOKabJQ_JQSY3I!emY{Y3PVJQSI#[#vb/KI {QSI9[ \_Y3PP emY{Y3PVJQSI#[#v3KI9M-f9bW9I9QSI#[#)JGHY3c2FPj Q_JT!J)jB,
'`KNYb/P]v(Y3I#F
jUQ_JT5YfOJQScQSPVJQgGfffOb/W9I9QSI9[%KI9M5Y3I9FjUQ_JT5fmFPPQgcQSPVJQSGfff9b/WOI9QSI#[#qnYJTYe9JKQSI9FMFH{fmF]b/Qgc2FIJK\g\_X
[Y{Y{M1bFPW9\SJPY3IJT9FPQgc2fO\SQSG]QSJX fiKG]G]W#b/KGHXJVb/KM#F]Y * v"eOW#Jj T#F]bFKPYf9JQScQSPJQSGkf9b/W9IOQSI#[G]\_FKab/\SX
Y3W#JVfmF]bZ:Yb/cP YJT#F]bK\_[Yb/QSJT9cPhQSIJT9F\gQ_[3TJ YZRJT#FPQ_]F-YZRJT9F-Z:Yb/c-W9\SKP Ye9JKQSI#FMvfmFPP/QScQSPVJQgG
f9b/WOI9QSI#[hJVFI9M9P JVY!KGT9Q_F]NFhKc2YbFbFKPY3I9KaeO\_FJVb/KM9F]Y * v{jUQ_JT2T9QS[3T2KG]G]W#b/KG]Q_FPRYe9JKQSI#FMY3IP/cK\S\
Z:Yb/cffWO\SKP]L"T9QSP"QgP"K\S\7JT#F-c2YbF-QSIJVF]b/FPVJQSI#[KP fmFPPQScQgPVJQSGhf9b/W9IOQSI#[QSP"eOKPFMlY3IKI9KaJW#b/K\0KI9M
PQScfO\_Fhf9b/W9I9QgI#[fffObY{GHFMOW#bF

<



> ? @ O>



"T9KI {PhKabFM9W#F!JVYk}fi} KabJQSIOQS(W9Fv 8 n } p dJKaeO\SQgPPVFc2FI(JhKaJQ_Y3I9K\ M9 RIOPVFQ_[3I#Fc2FI(J
uW#
f F] bQ_FW#b [bY3I9Y3cQS{W#FhM9Fh}fiQ VY3I`RKI9M QSPVF FKI!fi Y3W9QSPnZ:YbLTOKNuQSI#[-f9bYNuQSM#FMJT#FoKa[b/QSG]WO\_JW#b/K\
M9KaJKuv0ZYb!PJQScffWO\SKaJQSI#[kM9QSPG]WOPPQ_Y3I9PhKabY3W9IOM5Y3W#bbFPWO\_JP]vKI9M5Z:Yb!T9KN{QSI9[kKW9JT#Yb/Q_]FMJT9F2fOW#eO\SQ fi
G]KaJQ_Y3IYZ PVY3c2F!YZ0JT#Fob/FPW9\_JPLYe9JKQgI#FM7"T9K(I uPLJVY T9c2FM QSI#Y3W9GT#FoZ:Yb"T9KNuQSI#[2fmY3QSI(JVFMkY3W#J
JT#FUQgIJVF]bFPJBQSI2cQgI9QScQ_QgI#[hP/W#eOc2YuM9W9\SKab Z.W9I9GHJQ_Y3IOP] QSIOK\S\_XvJT#FhKW#JT#YbdjUQgPT#FPJVYffJT9K(I FM#bY
}hY3cQSI#[Y3PUKI9MJT#Fb/F]N{Q_F]jnF]b/PZ:Yb"JT#FQSbN8K\SWOKaeO\_FoPW#[[FPVJQSY3I9P]

:

$


fi



`>

@RC

k36)N6)



" 5"Z>

c

uQSIOGHF JT#FoT9KabM9I#FPPBbFPW9\SJPBYZ "T#F]YbFcPhxfiKI9M-KabFoPVJKaJVFMZ:YbJT#FfiJjnYfiG]\SKPPFP"G]KPVFv#jnFPT9K\S\
9W PVFfiJT#FoI#YJKaJQSY3I , 1 % , 1 - x / 7 , 1 - /mZ:Yb"PVY3c2FoKabe`Q_JVb/KabXbW9\_F-p , 1 ( , 1 v#jUT9F]bF , 1 - /QSPnJT#F
NaK\SW#FZ:Yb-G]\gKPPff fi KI9M , 1 - x /QSPoJT#F%N8K\gW#FZ:YbffG]\SKPP ff u fmY3PQSJQ_NFNaK\SW#FZ:Yb , 1 cFKI9P
JT9Ka(
J , 1 QSPfiQSIZ.KNYbYZnG]\SKPP)ff kjUT9F]bFKPfiKI#F][3KaJQ_NF2NaK\SW#F-[3Q_NFPK , 1 QSIZ:KNYbYZBG]\gKPP)ff fi u
dK\SW#FhZ:Y
b , 1 [3Q_NFPB5
K , 1 I9FW#JVb/K\9j Q_JT2bFPVfmFGHJBJVYffJT#FhG]\SKPPVFP FhW9PFUK!b/FM9W9GHJQ_Y3I2Z:bY3c JT#F
fi " KabMf9bYeO\SFc ff QSIOQScffWOc YNF]
b ip KabF]X r Y3T9I9PVY3I7v7xy3ay3<

6> " ff QSI9QSc-W9c YNF]b
u
fi " . 7r'"(" GHY3\S\_FGHJQ_Y3IYZ0PW9eOPVF]JPBYZK!^`I9Q_JVF PF]J>n fY3P/Q_JQ_NF QgIJVF][F]bv
fi
3 " .d7 '" R}hY(FPff GHY3I(JKQSIKGHYNF]b YZPQS]FKaJUc2Y3PVJfiv#JT9KaJhQSP]v#KPW9eOPVF]J
G G v9PW9G/TlJT9KaJUKI(X%F\SFc2FIJUYZ >emF\_Y3I9[3PJVYKaJU\_FKPJ"Y3I#Fc2FcffemF]b"YZ
fi

|





GG
jUQ_JT

"T9Fhb/FM9W9GHJQ_Y3IQSPLGHY3I9PJVb/W9GHJVFMlKPZ:Y3\S\_YjUP Zb/Y3c K ff QSIOQScffWOc YNF]b
QgI9PVJKI9GHFfijnFoeOW9QS\SM%K
\_FKab/IOQSI#[ffP/Kc2fO\_F.=?>P/W9G/T%JT9KaJ"Q_ZJT#F]bFfiFHuQgPVJPKGHYNF]bUYZ PQ_]FG G YZ >Lv{JT9FIkJT#F]bFfiFHuQgPVJP
KM#FG]QgPQ_Y3IGHY3ccQSJVJVF]FjUQ_JT G Gu\gQ_JVF]b/K\SPLGHY3I9PQgPVJVFIJUjUQ_JT =?>Lv9KI9M7v#bFG]Q_fObY{G]K\g\_Xv#Q_Z0JT9F]bFoFHuQgPVJP
KM9FG]QSPQ_Y3IGHY3ccQ_JVJVF]Fffj Q_JT \SQSJVF]b/K\SP"GHY3I9P/QSPVJVFI(J"jUQ_JT =A>nvOJT9FIJT#F]bFffFHuQSPJPUKGHYNF]bhYZdP/Q_]F
YH
Z >n "UFIOGHFv ^`I9M9QSI#[kJT#FPcK\S\_FPJM#FG]QSPQ_Y3IGHY3ccQ_JVJVF]FkGHY3I9PQSPJVFIJj Q_J
=?> QSPoF{W9Q_NaK\_FI(JJVY
^OI9MOQSI#[JT9FP/cK\S\_FPVff
J ZYbojUTOQSG/TJT#F]bFFH#QSPVJPoKPVY3\gW#JQ_Y3IiJVY ff QSIOQScffWOc YNF]
b uvKIOM5JT9QSPfiQSP
QSI(JVb/KGHJKaeO\_FQSZ % 0 2
F]J !"M9FI#YJVF5JT#F
F\_Fc2FI(JkY
Z 2v KI9M "JT#F
F\_Fc2FI(JkY1
Z >n FM#F]^OI#F5KPVF]J

Z GG"qnY(Y3\_FKI NaKab/QSKaeO\_FPiQSI Y3I9FJVYY3I#FGHYbb/FPVfmY3I9M#FI9GHFj Q_JT JT#FF\_Fc2FI(JPY
Z 2vjUT9QgG/T
jnFWOPVFJVYtM#FP/GHb/Q_emFJT#FFH#Kc2fO\_FPiY#
Z =A>n "T#FGHYbbFPVfmY3I9M9QgI#[ PVF]J5YZ\SQSJVF]b/K\SPQSPiM9FI#YJVFM
0 ( ( ( ( . ( . (5464646( ( M93R"T9FfiP/Kc2fO\_F =?>GHY3I(JKQSI9P"JjnYM9QSP VY3QSI(JnPW9eOPVF]JP JT#FPVF]JYZ fmY3PQ fi
JQ_NFhFHuKcfO\_F?
P =?> v#KI9MJT#FhPF]JBYZI9F][3KaJQ_NFfiY3I#FA
P =?> <
=?> GHY3IJKQgI9@
P GL> GFH#Kc2fO\SFP]v{M9FI#YJVFM



e{
X $ ( (P$ . (5464646(P$ 4 FGHY3I9PVJVb/W9GHJoFKGTfmY3PQ_JQ_NF-FH#Kc2fO\_FPVYkJT9KaJQ_JhFI9GHYuM#FPfiJT#F2c2FcffeF]bPT9Q_f
YZ JT#FGHYbbFPfY3IOM9QSI#[-F\_Fc2FI(J"YZ >QSIkJT#F!F\_Fc2FI(JPY
Z YbFf9bFG]QgPVF\_Xv


x





GL> GM(P$
%



"#"$ 6
"#"$ 4
" !7 ' :
"% !'&7 ' :

=A> GHY3IJKQSIOPUKPQgI#[3\_FoI#F][3KaJQ_NFFH#Kc2fO\SFvOM#F]^OI#FMke{X
"
$ %
" 4
" (

fi uW#f9fmY3PVF JT#F]bFhFHuQgPVJPKGHYNF]b( Z >PKaJQSPZXuQSI#[ G G

pwy3



p+x]



FGHbFKaJVFKM#FG]QSPQSY3IGHY3ccQ_JVJVF]F
GHY3I9PQgPVJQSI#[ffYZ
cY3I#Y3cQSK\SPvFKG/TljUQ_JTY3I#Fo\SQ_JVF]b/K\OY3I9\_XKI9MkKPPY{G]QSKaJVFM%JVY2K-fmY3PQ_JQ_NF k R
KGT
c2Y3I#Y3cQSK\dGHYuM#FP!Y3I9FYZJT#FPF]JP!QSI
"T9FM#F]Z.KW9\_J!G]\SKP/P!QSP ff fi ulUT9QSPM#FG]QgPQ_Y3IGHY3ccQ_JVJVF]F



*



)

QSP GHY3I9PQSPVJVFI(JUj Q_JTlJT#FffFHuKcfO\_FP"YZ<=A>+ =A> vOYJT#F]b/jUQSPVF!PY3c2FffF\SFc2FIJ YZ >jnY3W9\SMI#YJ emF
GHYNF]b/FM7dZJT9F]bF KabF Y3I9\_XJjnY-N8K\SW9FPRKW#JT#YbQ_]FMZ:YbRJT#F NFGHJVYb/PLKI9MJT9F]XKab/F uv{jBFhPQSc2f`\_X
GHbFKaJVFK} GHY3I9PQSPVJQgI#[YZnY3I#Fc2Y3I9Y3cQSK\ jUQ_JTI9F][3KaJQ_NF\SQ_JVF]bK\SPfiKPPVYuG]QSKaJVFMJVYKI#F][3KaJQSNF

$

: 2=

fi

iwc


ffff

c2Y3I9Y3cQSK\>









/





























h




Q_[3W#bF &n"T#FoPQ kfmY3PPQ_eO\SFhG]KPVFPUYZ b/W9\_FP]
p:JT#F2NaK\SW#F-ZYboJT9FI#F][3KaJQ_NFG]\SKPPoQgP [b/FKaJVF]bJT9KI5JT#F2Y3I#FYZBJT#F2fmY3PQ_JQ_NFG]\SKPPzFKG/TYZnJT#F
I#F][3KaJQ_NF-\SQ_JVF]b/K\gPnGHYuM#FPUY3I#FoYZ JT#F!PVF]JP"QgI R"T#FM#F]Z.KW9\_JG]\SKP/P"QSP ff u
fi uW#f9fmY3PVF!I9Yj JT9KaJhJT#F]bF-FHuQSPJPhK%M#FG]QSP/Q_Y3IGHY3ccQ_JVJVF]F jUQ_JTKaJfic2Y3PVJ \SQSJVF]b/K\SPhGHY3I9PQSPVJVFI(J
jUQ_JT =A>nd}hFI#YJV5
F ( ( . (5464646( # uFKG/Tic2Y3I#Y3cQSK\YZ v#QSIkI#YPVfmFG]Q_^OG Yb/M#F]bv#KI9
( ( . (5464646(
JT#FQ_bhKPPVYuG]QSKaJVFMN8K\gW#FPUZ:Y)
b kU"T#F-c2Y3I#Y3cQgK\SP"YZ G]KIiemF\_Y3I9[JVY%JT#bF]F!J)X(fmFPhYZdPW#e`PVF]JPUYZ
c2Y3I#Y3cQSK\SP







fi cY3I#YJVY3I#Y3W9P c2Y3I#Y3cQSK\gPp:jUQ_JT#Y3W#J"I9F][3KaJQ_NF!\SQ_JVF]bK\SPv
fi cY3I#Y3cQSK\SPGHY3I(JKQSI9QgI#[2Y3I9\_XkI#F][3KaJQ_NF!\gQ_JVF]b/K\SP]v
fi cY3I#Y3cQSK\SPGHY3I(JKQSI9QgI#[2fmY3PQ_JQ_NFKI9MI9F][3KaJQ_NFff\SQSJVF]b/K\SP]
F]JW9PoG]K\S\ bFPVfmFGHJQ_NF\_X v
v JT9FPVFJT#bF]FG]\SKPPFP]

_Q NFI5JT9KaJoFKG/Tc2Y3I#Y3cQgK\0YZ
G]KI5eF2KPPY{G]QSKaJVFM5JVYlK%fmY3PQ_JQSNFffYbKI#F][3KaJQSNF kv7JT#F]bFFH#QSPVJPfiY3IJT#F2jUT#Y3\SF-PQ_iG]\SKPPVFPfiYZ
b/W9\SFP]vuf9bFPVFI(JVFMQSI Q_[3W9bF {
IXc2Y3I#Y3cQgK\ YZ GHY3I(JKQSI9QgI#[KaJk\SFKPVJY3I#F5fmY3PQ_JQ_NF5\SQ_JVF]b/K\hG]KItY3I9\SXemFPKaJQgPV^9FMe(X
fmY3PQ_JQ_NFLFH#Kc2fO\_FP UT#F]bF]Z:YbFv(Q_Z`JT#F]bF"FH#QSPVJPdb/W9\_FP emF\_Y3I#[3QgI#[fiJVY!G]\SKPP/0Yb hv3jBF G]KI2bFc2YNF
JT#Fc jUQSJT#Y3W#J \_Y3PQSI#[fiGHY3I9PQgPVJVFI9GHX9W#bJT9F]b/c2YbFvP/QSI9GHF $ GHY3IJKQgI9P Y3I9\_X-I#F][3KaJQ_NF"\SQ_JVF]bK\SP]vQ_Z9jnF
bFc2YNFffJT9FQ_b I#F][3KaJQSNFff\SQ_JVF]bK\SPZ:bY3c K\S\b/W9\_FP"eF\SY3I#[3QSI#[2JVY%G]\SKPP p.cK {QSI9[JT#Fc [YJVYG]\gKPP
v{jnFoM#Y2I#YJ\_Y3PVFfiGHY3I9PQSPJVFI9GHX PK-GHY3IOPVF(W9FI9GHFv#jBFoG]KIPW9f9fmY3PVFUjUQSJT#Y3W#JL\_Y3PPnYZ[FI#F]bK\SQ_JX
JT9KaJUK\g\mb/W9\_FPLYZ KabF!QSIG]\gKPPv9vuYb" -
FI#Yj JVbFKaJoQSI9M#F]fmFI9M#FI(J\_X%JjnYlG]KPVFP]vM#F]fmFI9MOQSI#[Y3IjUT#F]JT9F]b JT#F2M#F]Z.KW9\_JhG]\SKPPhYZ QSP
ff 2Yb ff fi u













xaUUT#FM#F]Z.KW9\_J-G]\SKPP-QSP ff fi u IXfmY3PQ_JQSNFFH#Kc2fO\_F%PKaJQSPV^9FPffJT#F]bF]Z:YbF%Kic2Y3I9Y3cQSK\RQgI
UT#F]bF2G]KIFH#QSPVJfiJjnYlJX{fmFPfiYZBfmY3PQSJQ_NFffFH#Kc2fO\SFP JT9Y3PVFPKaJQSPVZ:XuQSI#[kKaJ\_FKPVJoY3I#F2b/WO\_FffYZ
G]\gKPPv9KI9MJT#Y3PVFI9YJUPKaJQSPVZ:XuQSI#[KIXG]\SKPP"Rb/W9\SF2p:JT9F]bF]ZYb/F!PKaJQSPVZ:XuQSI#[2KaJU\_FKPVJY3I9Fob/W9\_F
YZG]\SKP/P $ PKaJQSP^9FP"K\S\7G]\SKP/PnKI9M b/WO\_FP]d"T#F]b/F]ZYbFv
,



= 1 7

,

4

G]\gKPPG]\SKP/P




E4

p+xx

1

UT9QSPRP/T#YjUPBJT9KaJ]vuQ_Z7K!fmY3PQSJQ_NF"FH#Kc2fO\_FhI#YJBPKaJQgPVZXuQSI#[ffKIXG]\gKPPRbW9\_FPjnY3W9\SMPKaJQSPVZ:XK\S\
G]\gKPPh b/WO\_FP]vOJT9FIQSJUjnY3W9\SMlemF-cQSPG]\SKP/PQ_^9FM7vOjUT9QSGTiQSP QSc2fmY3PPQSeO\_Foe{XJT#F-GHY3IOPQSPVJVFI9GHX
T(X{fYJT9FPQSP]RUT9QSPL[3Q_NFP KIQSc2fmYbJKI(Jf9bYfmF]bJ)XvOI9Kc2F\SXJT9KaJ KIXkfmY3PQ_JQ_NFoFH#Kc2fO\SF!I#YJ

$

: $

fi

P/KaJQSPVZ:X{QSI9[ffKI(XG]\SKPPndb/WO\_F G]KI9I9YJLP/KaJQSPVZ:XK\S\`G]\gKPPn bW9\_FP] F]JLW9PLG]K\S\<k JT9QSPBf9bYfmF]bJ)X
QgIjUTOKaJ!Z:Y3\S\_Yj P] FkI#Yj PT9Yj T#Yj JVY5eOW9QS\gMKNaK\SQSMPVY3\SW#JQ_Y3IJVY ff QSIOQScffWOc YNF]b<
j Q_JTKaJUc2Y3PVJ kF\_Fc2FI(JP]R#YbhKIXkfmY3PQ_JQSNFhFH#Kc2fO\S
F $ v



fi QSZ $ PKaJQSPV^9FPfiKaJo\_FKPVJfiY3I#F2G]\SKP/P Ub/W9\_FvmG/T#Y{Y3PVFQSI

K PW#eOPVF]JhYZA>1GHYbb/FPVfmY3I9M9QSI#[
k
JVYK2fmY3PQ_JQ_NF\SQSJVF]b/K\YZ PY3c2F!PKaJQSP^9FMG]\SKPPnb/W9\SFd"T9QSPLPW#e`PVF]J"GHY3IJKQgI9P$
fi QSZH$ M#Y(FPI#YJPKaJQSPZXKI(XG]\gKPP-b/W9\_Fv JT#F]b/FFH#QSPVJP-Z:bY3c k PY3c2FG]\SKPP- b/W9\_F
j T9QSG/TkQSPI9YJ"PKaJQSPV^9FM c2Y3I#[K\g\I9F][3KaJQ_NF!\SQ_JVF]bK\SPnYZ0K2G]\SKPPL b/W9\_FhjUT9QSGTkQSPI#YJ
P/KaJQSPV^9FMie(X$ vGT#Y(Y3PFffY3I#FffjUT9QSGTQSPUfmY3PQ_JQ_NF!Qg
$ p.G]KW9PQSI#[%Q_J I9YJUJVYkPKaJQSPVZ:XJT#F
bW9\_FvKI9MJT9FI2G/T#Y{Y3PVF"JT#F"GHYb/bFPVfmY3I9M9QSI9[ F\_FcFIJYZ "T9QgP P/W#eOPVF]J YZ >5GHY3IJKQgI9P
$
JVF]b/KaJQSI9[%JT9FKaeYNF2f9bYuGHFM9W#bF-Z:YbK\S\fmY3PQSJQ_NFffFH#Kc2fO\SFP]v7jBF2YeOJKQSI5K%GHYNF]b!YZ>GHY3I!fi
P/QSPVJQSI#[YZKaJUc2Y3PJ PW#eOPF]JPYZ >L
~{UUT#FM#F]Z.KW9\_J"G]\SKPPUQSP ff u?$ PKaJQSPV^9FPUK\S\7G]\SKPP/BKI9Ml b/W9\_FPd"T#F]bF]Z:YbFv
,



= 1 7

,

4

G]\gKPPG]\SKP/P




E4

p+x~3

1

RNFI5Q_ZJT#F2QSI#F{W9K\SQ_J)XQSP I9Yj

PVJVb/QSGHJ]v7Q_J [3Q_NFPfiJT#FPKc2F-f9bYuGHFM9W#bFffZYbfiFG]QSFIJ\_XeOW9QS\SMfi
QgI#[JT#FkPVY3\SW9JQ_Y3IJVY ff QSI9QSc-W9c YNF]b
jUQSJTKaJc2Y3PVJ F\_Fc2FI(JP]ve(XW9PQSI#[JT#FPKc2F
Kab/[3W9c2FI(JUKPUQSIkJT9Fof9bFGHF]FM9QSI9[G]KPVF
"TOQSPLFI9M9PLJT#F!f9bY{YZYZ"T#F]YbFc xa

k36)N6)

" 5"Z>

c

FoW9PVFfiK-bFM9W9GHJQ_Y3IZ:bY3c

JT9F fi "hKab/M%f9bYeO\SFc

ff~ fi

fi Y3\SYb/KaeOQS\SQSJX kp FKab/I9PnF]JK\w_v7xy3<

6> " ff~ fi fi Y3\_Yb/KaeOQS\gQ_JX u
fi " . 7r'"(" ^OI9Q_JVF%PVF]J> % 0 ( ( . (5464646( 4 9kKIOMKGHY3\S\_FGHJQ_Y3IYZUGHY3I9PJVb/KQSI(JPffYNF]b#>nv
% 0 ! ( (*! . (5464646(*! 93vOPW9GTJT9KaJ ^m/0x3(/~)(5464646(RGG 9 (*! >n
fi
3 " .d7 '" R}hY(FPJT9F]bFFH#QSPVJ"K~ fi fi Y3\SYb/KaJQ_Y3IlYZ JT#FoF\SFc2FIJP"YZ<>Lv J 1.21BKZ:WOI9GHJQ_Y3I
)
> 0 x3/( ~ 2
9 PW9GTJT9KaJ
fi

|

p
m/0x3(/~)(5464646(RGG 98(p ( 1 m! p

%0

p 1

"T9F"bFM9W9GHJQSY3IQSPRGHY3IOPVJVb/W9GHJVFM%KPdZ:Y3\S\_YjUP Zb/Y3c K ff~ fi fi Y3\_Yb/KaeOQg\SQ_JX !QgI9PVJKI9GHFv(jBF eOW9QS\SM
K \SFKab/I9QSI#[P/Kc2fO\_F =A>PWOG/TJTOKaJBQ_ZJT#F]bF FHuQSPJPRKff~ fi fi Y3\_Yb/KaJQ_Y3IYZ7JT#F"F\SFc2FIJPBYZ >nv(JT#FI
!
JT#F]bFFHuQgPVJP!KiM#FG]QSPQ_Y3IGHY3ccQ_JVJVF]FjUQ_JTJ)jBYib/W9\_FP!GHY3I9PQSPVJVFI(J!j Q_JT=?>Lv KIOM7vbFG]QSf9bYuG]K\S\_Xv0QSZ
JT#F]bF!FHuQSPJP"KM#FG]QSP/Q_Y3IlGHY3ccQSJVJVF]FjUQ_JTJ)jBYb/W9\_FPGHY3IOPQSPVJVFI(J"jUQ_J
=?>nv#JT#FIJT#F]bFFH#QSPVJPUK~ fi
fi Y3\SYb/KaJQ_Y3IYZ JT#FoF\_Fc2FI(JPY<
Z >nR9W9bJT#F]b/c2Yb/Fv#JT#F]bFI#F]NF]b"FH#QSPVJPK2M9FG]QSPQ_Y3IGHY3ccQ_JVJVF]F
jUQ_JTY3I9\_XfiY3I#Fdb/WO\_FdGHY3I9PQSPJVFIJ0jUQ_J@
=A>n " FI9GHFv^OI9MOQSI#[LJT#FRM#FG]QgPQ_Y3IGHY3ccQ_JVJVF]FBj Q_JToJT#FRP/cK\S\ fi
FPVJhI(W9cffemF]bUYZb/WO\_FPUGHY3I9P/QSPVJVFI(JUjUQ_J
=?>QSPUKaJfi\_FKPVJhKPhTOKab/MlKPfiPVY3\_NuQSI#[ ff~ fi fi Y3\_Yb/KaeOQS\gQ_JX uv
KI9MJTOQSPQSPQSI(JVb/KGHJKaeO\_FffQ_Z % 0 2
:BC

Q

fi

iwc


ffff

F]J !"M9FI#YJVF5JT#F
F\_Fc2FI(JkYZ2v KI9M "JT#F
F\_Fc2FI(JkYZ1>n FM#F]^OI#F5KPVF]J
YZ/GL>HG"qnY{Y3\_FKI N8KabQSKaeO\_FPQSI Y3I#FJVYY3I9FGHYb/bFPVfmY3I9M#FI9GHFjUQ_JT JT#FF\_Fc2FI(JPYZ >nv-jUT9QgG/T
jnFWOPVFJVYtM#FP/GHb/Q_emFJT#FFH#Kc2fO\_FPiYZ#=A>n "T#FGHYbbFPVfmY3I9M9QgI#[ PVF]J5YZ\SQSJVF]b/K\SPQSPiM9FI#YJVFM
0 ( ( ( ( . ( . (5464646( 4 ( 4 93 oW#bbFM9W9GHJQSY3ItQSPcKM#FQSIJT#FJ)jBYfiG]\gKPPVFPlZ:b/Kc2F]jnYb "T#F
PKc2f`\_.
F =?>GHY3I(JKQSI9PJ)jBY%M9QSP VY3QSI(JnP/W#eOPVF]JP dJT9FPVF]J"YZ fY3P/Q_JQ_NFfiFHuKcfO\_F
P =?> Rv`KI9MkJT#FPVF]J"YZ
I#F][3KaJQ_NFY3I#F@
P =?>
=A>1GHY3IJKQSIOP GL> G`FH#Kc2fO\_FPvM#FI#YJVFMe{
X $ ( (P$ . (5464646(P$ 4 FGHY3I9PJVb/W9GHJ
FKG/TifmY3PQ_JQ_NFfiFH#Kc2fO\_FPYJT9KaJUQ_JLbF]fObFPVFI(JPUKIF\_FcFIJ"Y<
Z >n YbFfObFG]QSPVF\_Xv



" 4
p+x3
" ( " &
A= > GHY3I(JKQSI9PGGdFH#Kc2fO\_FP]v M#FI#YJVFMe{XF$ ( (P$ . (5464646(P$ F5GHY3IOPVJVb/W9GHJ%FKG/T I9F][3KaJQ_NF
x









GL> GM(P$

%

6

" 4

FH#Kc2fO\_FPVYJT9KaJUQ_JFI9GHYuM#FPFKGTlYZ JT#F!GHY3IOPVJVb/KQSI(JPYZ
YbFf9b/FG]QSPVF\_X


x





GGM(P$
%



#"%"$ 6
#""$ 4
" : 7 '
"% : 7& '

p+x +(

Q_JT#Y3W#J\SY3PP7YZ{[FI#F]b/K\SQ_J)XvjnFRcKFRZY3W#b0KPPW9c2fOJQ_Y3I9PY3IJT#FdQgI9PVJKI9GHFYZ ff~ fi fi Y3\_YbKaeOQS\SQ_J)X&

M9W#FoJVYJT#FoZ:KGHJ JT9KaJUQ_J"QgPI#YJ"JVb/Q_NuQSK\
xaUUT#F]bF M9Y(FPnI#YJnFHuQSPJBPVY3c2F F\_Fc2FI(JBYZ >f9b/FPVFIJnQSIK\g\OGHY3I9PVJVbKQSIJPIJT9QSPBG]KPVFhQgI9M#F]FM7v
JT9FJVb/Q_NuQSK\LGHY3\_Yb/KaJQ_Y3IGHY3IOPQSPVJP2QSI[3QSN{QSI9[JVYY3I9FYZhPWOG/TF\_FcFIJP2Y3I9FlGHY3\_YbvLKI9MJT#F
YJT9F]b GHY3\_Yb"JVYK\S\7YJT#F]b"F\SFc2FIJPUYZ >n
~{


p'*(ff
J( 8( D8 Cm/0x3(/~)(5464646(RGL> G 9 jUQ_JT % 0
KI9M % 0 8v
& m0x3(/~)(5464646(RGG 9 (,0 ( "390 !,+ 6 0 ( 1 9-0 !,+4
p+x23
fiJT#F]bjUQSPFQgI9M#F]FM7vJT9F]bF2jBY3WO\SM5FHuQgPVJp'*(ff
( 8( 8w:m 0x3(/~)(5464646(RGL>HG 9 j Q_JT % 0
KI9M % 0 8
P/W9G/TJTOKaJ
x (/)~ (5464646(RGG 9 (,0 ( "39 !,+ 0 ( 1 9 !,+(
p+x|3
& m03
KIOMlQSIJT9KaJ G]KPVFv`K2JVbQ_N{QgK\7PVY3\SW#JQ_Y3IkJVY ff~ fi fi Y3\_YbKaeOQS\SQ_J)X& jBY3W9\gMGHY3I9PQSPVJ"QgI[3Q_NuQSI#[JVY
Y3I#F!GHY3\_YbhKI9MkJVY " JT#FoYJT#F]b Y3I#FvOKI9MlJVY Y3I#F!GHY3\_YbhKI9MkJVY 1 JT#FYJT9F]bUY3I#F

{ B KG/TF\_FcFIJ%YZ"> eF\SY3I#[3PJVYKaJk\_FKPVJ%Y3I#FGHY3IOPVJVb/KQSI(J%QgI hJT#F]bj QSPVFv"Q_J%G]KI1emF
b/Fc2YNFM7

+# BKG/TlGHY3IOPVJVb/KQSI(J"GHY3IJKQgI9PKaJ"\_FKPVJJ)jBY2F\_FcFIJPZ:bY3c

>nBfiJT#F]bjUQSPFhQ_JG]KIkemFfibFc2YNFM7

fi uW9f9fmY3PVFJT9F]bFFHuQgPVJPKPVY3\gW#JQ_Y3IJVY ff~ fi fi Y3\_Yb/KaeOQS\gQ_JX u FeOWOQS\SMJT#F} j Q_JTJjnY
c Y3I#Y3cQSK\SPnYZLp FKab/I9PF]J"K\w_vxy3"GHY3I9PQSPJVFIJjUQSJTJT9FoFHuKc2f`\_FP]d"T#FIv{jnFoeOW9Qg\SMJ)jBYbW9\_FP
2
e{XiKPPVYuG]QSKaJQSI9[%JT9F-J)jBYic2Y3I#Y3cQSK\gP JVYlPY3c2Flp.KabeOQ_JVb/Kab/X#UfmY3PQ_JQ_NF-NaK\SW#FffUT#F2M#F]Z:KWO\_JhG]\gKPPoQSP
ff fi uBUT9QSPL\_FKM9PJVYKM#FG]QSPQSY3IGHY3ccQ_JVJVF]Fj Q_JTJjnYb/WO\_FPGHY3I9PQSPJVFIJ"j Q_JT =?>n
fi uW9f9fmY3PVFfiJT9KaJUJT#F]b/FFHuQgPVJPUKM9FG]QSPQ_Y3IGHY3ccQ_JVJVF]F 5j Q_JTKaJ c2Y3PJ"JjnYb/WO\_FP"GHY3I9PQgPVJVFIJUjUQ_JT
=?>L
FI#Yj PT#Yj JT9KaJ2JT#F]bFkFH#QSPVJP2K5NaK\SQSM~ fi fi Y3\_Yb/KaJQSY3IYZUJT9F%F\SFc2FIJPYZ >n F
^9b/PJP/T#Yj JT#b/F]Fl\_FccKPjUTOQSG/TPT9K\g\BemFW9PVFM\gKaJVF]bY3I7"T#FI7vdjnFlPT#Yj JT9KaJJT#FM#FG]QgPQ_Y3I
GHY3ccQSJVJVF]F%QSP!KGHJW9K\S\_XF{W9Q_NaK\_FI(JJVYiKi} h j Q_JTJjnY5c2Y3I#Y3cQSK\gPGHY3I9PQSPJVFIJffjUQ_J
=A>n F
GHY3I9G]\SWOM#FUe{XW9PQSI9[!f9bF]NuQ_Y3W9PRbFPW9\SJP p FKab/IOPRF]JK\w_vmxy3BY3IT9YjJVYffJVbKI9PVZ:Yb/c JTOQSPR} hQSI(JVY
K2NaK\SQSM~ fi fi Y3\SYb/KaJQ_Y3IiYZ0JT#F!F\_Fc2FI(JP"Y<
Z >n



:BC6:

fi

p N "RT fTgJ"! J %( % " J %8a WV " (
%KJ J Wi f"
! ]
fi J H J "fJ(% " ! "% X 3 " J !wJ H "! %j]
fi J J % J "! "fJ 6J 3 "! !
%KJ J !\J ] "! % !
" 4

B "F> >



"

"4

(

p RbY(YZ PVJVb/KQS[3TJVZ:YbjLKab/M`

B "F> >

jV "! !
%KJ J aji "fT
! %K]
J J %
.61
p:+I9M#F]FM7v Z:Yb-KI(XN8KabQSKaeO\_Fv JT#F]bFFHuQSPJJjnYifmY3PQSJQ_NFFH#Kc2fO\_FP-T9KNuQSI#[JT#FGHYbb/FPVfmY3I9M9QSI#[
fmY3PQ_JQ_NFo\SQSJVF]b/K\wv#KI9MJT#FffGHYbbFPVfmY3I9M9QgI#[-I9F][3KaJQ_NFff\SQSJVF]b/K\


pN R
" fTgJ"! J %

% " J 8%

B "F> > "fJ(% Wi "6 ! X $ ! % 1
k36)jl uW#f9fmY3PVF%JT9KaJ GHY3IJKQgI9PY3I#Fb/W9\SFvjUT#Y3PVFc2Y3I#Y3cQSK\LQSP2G]K\S\_FM ( Z"JT#FlM#F]Z.KW9\_J
G]\SKPPnQSP ff fi uvuK\g\#fmY3PQ_JQ_NF"FH#Kc2fO\SFPBPKaJQgPVZX ( v(jUTOQSG/TQSPdQSc2fmY3PP/Q_eO\_FLe{X FccK +( JT#F c2Y3I9Y3cQSK\
jnY3W9\SMemFFc2fOJXv KI9M GHY3WO\SMI#YJemFGHY3IOPQSPVJVFI(J]k)ZLJT#FM9F]Z:KW9\SJG]\SKPP!QgP ff uv JT#FI9F][3KaJQ_NF
FH#Kc2fO\_FPhKabFffG]\gKPPQ_^9FMe(X ( KIOMlJT#F]bF]Z:YbF ( uh"T{W9P]vOI#Y%fmY3PQ_JQ_NF!FHuKc2f`\_FffPKaJQgPV^9FP (
" 4
#bY3c FccK {vFQSJT#F]b ( % " ( #"-KI9MI#YkI#F][3KaJQ_NFFH#Kc2fO\_F-G]KIP/KaJQSPVZ:XlQ_J-p.QScfY3P/PQ_eO\_Fv
Yb ( GHY3IJKQSIOP-KaJ\_FKPVJ-JjnY5I#F][3KaJQ_NF\SQ_JVF]b/K\gP]v KIOMJT#F%GHY3I9PVJVb/KQgIJPK\S\BT9KNFQSIGHY3cc2Y3IJjnY
F\_Fc2FI(JP-YZn
> iUT(W9Pv JT9F%QSIOPVJKI9GHFYZ ff~ fi fi Y3\_Yb/KaeOQg\SQ_JX QSP!JVbQ_N{QgK\wvjUTOQSG/TQSP!Qgc2fmY3PPQ_eO\SF
"T9QgPLFI9M9PLJT#FfObY(YZ0YZ FccK {
F-I#YjP/T#Yj JT9KaJ"JT#F!M9F]Z:KW9\SJLG]\gKPP"YZ 5QSP ff fi un#YbUJT#FffPKF!YZ PQSc2f`\SQSG]Q_J)Xv{jnFj"bQ_JVFoJT#F
JjnY5c2Y3I#Y3cQSK\gPoYZ e{/
X ( KI91
. l"T9FM#F]Z.KW9\_J!G]\SKP/P!QSPffM#FI#YJVFM 1m 0 ff fi uv ff )93 KuQSI#[
JT#FKPP/W9c2f9JQ_Y3I5JTOKa
J % ff lQScfO\SQ_FP JT9KaJ!K\S\I9F][3KaJQ_NFFH#Kc2fO\_FPc-W9PVJP/KaJQSPVZ:XiKaJ!\_FKPJY3I#F
c2Y3I#Y3cQSK\7QSI







fi #W#f9fmY3PVF2JT9KaJ ( KI9M . u%"T9FI7v0I#YfY3P/Q_JQ_NF2FH#Kc2fO\_FG]KIPKaJQSPZXFQ_" J T#F]4 b (
Yb . 9bY3c JT#F%JjnYfmY3PP/Q_eOQS\SQSJQ_FPfiYZ FccK {vY3IO\_XJT#F%^9b/PVJffY3I#FkQSP!NaK\SQSMp " ( "
G]KIOI#YJoemFP/KaJQSPV^9FMe{XiKI(XI#F][3KaJQSNF2FHuKc2f`\_Fff"T{W9P]v ( KI9M/ . GHY3I(JKQSI5FKG/TKaJ\_FKPVJ
J)jBY%I#F][3KaJQ_NF-\SQ_JVF]b/K\SP2

0 ( ":9
0 ( 19




( (

p+x
p+x3

. 4

FKabF2QSIJT#FPVFGHY3I9MG]KPVFYZRJVb/Q_NuQSK\SQSJXYZnJT#F2QSI9PVJKI9GHFYZ ff~ fi fi Y3\_YbKaeOQS\SQ_J)X& uv0PQSI9GHF



cK{QSI9[2JT#F!KPPWOc2f9JQ_Y3I%JT9KaJ 5QgPGHY3I9PQSPVJVFI(JUQScfO\SQ_FP

&

fi #W#f9fmY3PVFfiJT9KaJ

m0x3(/~)(5464646(RGG 9 (,0 ( "39 0 !,+ 6

0 ( 1 9- 0 !,+4

p+xy3

KI9M .
u \S\I#F][3KaJQ_NFFH#Kc2fO\_FPUcffW9PJUPKaJQSPVZ:X ( ( QSPZ:Yb/GHFM

JVYkemFc2Y3I#YJVY3I#Y3W9PoP/QSI9GHF-YJT#F]bjUQSPFkp:[3Q_NFIJT9KaJ E% ff K\S\ I#F][3KaJQ_NF2FH#Kc2fO\_FPhjnY3W9\SM
P/T9KabF!KGHY3cc2Y3II9F][3KaJQ_NF-\gQ_JVF]b/K\wv#JT{W9PUK\g\GHY3I9PVJVb/KQgIJPUjBY3W9\gMlPT9KabFffKGHY3cc2Y3IF\_Fc2FI(J
YZ >nvKI9M JT#FQSIOPVJKI9GHFlY)
Z ff~ fi fi Y3\SYb/KaeOQS\SQSJX jBY3WO\SMemFJVb/Q_NuQSK\w . emFQSI#[PKaJQgPV^9FM
(

:BC5z

fi

iwc


ffff



e{XKaJ2\_FKPVJ-Y3I#FkfmY3PQ_JQ_NFFHuKcfO\_Fp:YJT9F]bjUQSPVFv jBY3WO\SMemF%F(WOQ_N8K\SFIJffJVY5KPQSI9[3\_F fiDb/W9\_F
M9FG]QSPQ_Y3IGHY3ccQSJVJVF]FvfiKIOM1jnFZ.K\S\fiQSIJT#FGHY3IJVb/KMOQSGHJQ_Y3IYZ FccK 3vfiQ_JGHY3IJKQgI9PKaJ
cY3PVJ Y3I9F-I#F][3KaJQSNF\gQ_JVF]b/K\wZdQ_J GHY3I(JKQSI9PhFH#KGHJ\_XlY3I#FI#F][3KaJQ_NF\SQ_JVF]bK\wv`Q_JhQSPUP/KaJQSPV^9FMie(X
FH#KGHJ\_XffY3I#FLfY3P/Q_JQ_NFRFH#Kc2fO\SFv3KI9M-jBFLG]KIbF]fO\SKGHFLQ_J e(X!JT#Fc2Y3I#YJVY3I#Y3W9P c2Y3I9Y3cQSK\(jUQ_JT
GL>HG)7 xfmY3PQ_JQSNF\SQ_JVF]bK\SPp:jnF%\_FKNFFcf9JXJT9FfmY3PQ_JQ_Y3IYZ"JT#FQgI9Q_JQSK\I#F][3KaJQSNFk\gQ_JVF]b/K\
Y3I9PVF{W#FIJ\SXv9PQScQS\gKab/\_X-ZYb ( v#jBFG]KIPW9f9fmY3PVF JTOKa
J . QSPLc2Y3I#YJVY3I#Y3WOP] F!M9QSPJQSI#[3W9QSP/T
J)jBY%G]KPVFP]

" 4



Z G ( G
G . GvOI#Y2fmY3PQSJQ_NFfiFHuKc2f`\_FG]KIPKaJQgPVZX- ( dqnXkZ.KGHJ{v ( % " ( #"vOKI9M
I9YI#F][3KaJQ_NFFH#Kc2fO\SFG]KIPKaJQSPZXkQ_J]v9KGHY3I(JVb/KM9QSGHJQSY3Ip 5G]KI9I#YJ"emFGHY3I9P/QSPVJVFI(J
Z G ( G G . G . G]KI9I9YJeFFc2f9J)X`z!JT#F]bF]Z:YbFQ_JkGHY3IJKQSIOPKGHF]b/JKQSItI(WOc!emF]b
YZ-fmY3PQ_JQ_NF5\SQ_JVF]bK\SP] BKG/TtfmY3PQSJQ_NF5FHuKc2f`\_FPKaJQSPVZ:X{QgI#!
[ . cffWOPVJK\SPVYPKaJQSPZX ( v
P/QSI9GHF5YJT#F]bjUQgPVF
QSPI#YJlGHY3I9PQgPVJVFIJ]z2uQSI9GHF ( KI9M . KabFc2Y3I#YJVY3I#Y3W9P+
v . QSPK
[FI9F]b/K\SQ_KaJQ_Y3IYZ ( v KI9MKI(XFHuKc2f`\_FPKaJQgPVZXuQSI#[ ( p.QgIfOKabJQgG]W9\SKabv0JT#F%I9F][3KaJQ_NF
FH#Kc2fO\SFPLc-W9PVJ"PKaJQSPZX . v9KGHY3I(JVb/KM9QgGHJQ_Y3I7





"T9F]bF]ZYb/F %)ff fi un"TOQSPZ:Yb/GHFPUK\S\fY3P/Q_JQ_NFoFH#Kc2fO\_FPUJVYPKaJQSPZXkKaJ \_FKPJ"Y3I#FffcY3I#Y3cQSK\7YZ
. uJffGHY3cFP
(
iKI9*
( % ffp FccK +( \S\I#F][3KaJQ_NFFHuKcfO\_FPc-W9PVJPKaJQgPVZ/
X . v KI9M5jnFK\SPVYlT9KN/
F G ( G G . G


"
4

YfY3P/Q_JQ_NFFHuKcfO\_FG]KIPKaJQgPVZX . vKIOM FccK %[3QSNFPFQ_JT#F](
b ( % " ( "lp.PKaJQSP^9FM5e(X
I#YkFH#Kc2fO\_Fv7QSc2fmY3PP/Q_eO\_FnY(
b . GHY3IJKQSIOPoKaJ\_FKPVJfiJjnYlI#F][3KaJQ_NF\SQSJVF]b/K\SP]vjUT#Y3PVF2GHYbb/FPVfmY3I9M9QSI#[
F\_Fc2FI(JPYH
Z >Kab/FPT9KabFMe(X5K\S\dGHY3I9PJVb/KQSI(JP]v0KI9MjBFYeOJKQSIKa[3KQSIJTOKaJJT#FQSIOPVJKI9GHF2YZ ff~ fi
fi Y3\SYb/KaeOQS\SQSJX 2QSPLJVb/Q_NuQSK\w
"T9F]bF]ZYb/Fv (
KI9M .
uvKIOMlFKG/T5c2Y3I9Y3cQSK\QgPUPKaJQSP^9FMle{XlKaJh\SFKPVJUY3I#FfffmY3PQ_JQ_NF
FH#Kc2fO\_F
QgP!JT{W9PffF(W9QSN8K\_FI(J-JVYK5} jUQ_JTJT#FPKc2F%JjnYc2Y3I#Y3cQSK\gP]vKI9MjnFG]KIW9PVF
Kkf9bF]NuQ_Y3W9PfiPVY3\gW#JQ_Y3Ip FKab/I9PF]JK\w_vRxy3fiJVYe`W9QS\SMKkN8K\gQSM~ fi fi Y3\_Yb/KaJQSY3I72 QSb/PVJ]vjnFG]KI
PW#fOfY3PFdJT9KaJ 2QSP Ka[3KQSIffcY3I#YJVY3I#Y3W9PLp FKab/I9P F]J K\w_v#xy3d"T#FI7vaPQSIOGHFRFKG/T-fmY3PQ_JQSNFdFHuKcfO\_F
PKaJQSP^9FP KaJd\_FKPVJ Y3I#Fc2Y3I#Y3cQSK\7p % ff fi v3JT#FIZ:YbK\S\NaKab/QSKae`\_FvJT#F]bFnFHuQgPVJPKfic2Y3I#Y3cQSK\(jUT9QgG/T
M#Y{FP"I#YJUGHY3I(JKQSIJT9F!GHYbbFPVfmY3I9MOQSI#[-fY3P/Q_JQ_NF\SQ_JVF]bK\w"T#F!~ fi Y3\_YbKaJQ_Y3IlQSPJT9FI

EUFG]K\S\RJTOKaJ GHY3I(JKQSI9P-J)jBYc2Y3I#Y3cQSK\SP]iuW9f9fmY3PVFJT9KaJ







"87 c(QSI .j 0
0 "J9 4


m0x3(/~)(5464646(RGL> G 9 ( p %


pw~a

Y3WO\SMJT9QgP!emFQgINaK\SQSM "T9KaJ-jBY3W9\gMc2FKIJT9KaJ-JT#F]bF%FHuQgPVJPKiGHY3I9PJVb/KQSI(J !UPWOG/TJT9KaJ
"m ! ( p "#% % ! UT9QSPjnY3W9\SMc2FKI JT9KaJJT#FlGHYbb/FPVfmY3I9M9QSI#[I#F][3KaJQSNFlFHuKcfO\_F
PKaJQSP^9FP vOK2GHY3I(JVb/KM9QgGHJQ_Y3Ip FKabI9PF]JUK\w_vxy3L"T9QgPLFI9M9PLJT#FfObY(YZ YZ "T#F]YbFc {

k36)N6)

" 5"Z>

c

}hF]^OI#FJT9FoZ:W9IOGHJQ_Y3I





~

' (
0 (



% & P/W9G/TJTOKaJ

02(x3(5464646(*!7x:9 (

- /

%

4 ; pVp'&)( 8(ff
(V"p
( 9 (
+ "

pw~ux

jUQSJT
np
J( 9

% $ - -
um 6



m0 / / $


m0
--/


6
:BC>;

/ / - -_p
Rm

6

p
m0


6 m0

/ /.4

fi


>
>

(

>

(

>

(

>
(

>

.

>
4

>


(

>
>

.

>

.

>

4

>

4

.

>

.

>

4

>

4

>
>



>

(

>

>



-

8?m


.

>
4

>


>

(

>
.

>
4

>


>

(

>


>

.

>
>


4



GHY(FG]QSFIJ"YZ
; pVp'& ( 8(ff
{V QSI
+ / -
- /
- /
/
~
~
$ x
$ x
$ x
$ x
~J$
J~ $
$ x
$ x
~
~
~
$ $
x $
x $
$ x
$ x
~
$ $
~
~
x $
x $
~J$
~J$
x $
x $
x $
x $
~
~







KaeO\_F/& 3Y PPQSeO\_FiGHY{FG]Q_FI(JPkYZ@;pVp'& ( 8(ff
{V
FT9KNF^#uFM Z:YbPT#YbJ >
:x 9up +v > . % %v8> 4 % v8> % %
(

% 02(x3(5464646(*!7

[FI#F]b/K\SQ_]FPJT#FJT#bF]FFH{f9b/FPPQ_Y3I9PfiYZ QSI5F{W9KaJQ_Y3I9Ppw~3vLp 3vKI9M
KM#F{W9KaJVFNaK\SW#FPZ:YbfiR8 Yjv`jBF!GT#FGkJT9KaJ 5
PKaJQSPV^9FP"JT#FPW#eOcY{M9WO\SKabQSI#F{W9K\SQ_J)X
- + / - / - / - /@(
YJVFJT9KaJ



pDfijUQ_JT
pw~~3

Z:YbK\S\LPW#eOPF]JP
( 0 2( x3(5464646(*!1
7 x:39 "T#F F]XQSPJVYFH#KcQSI#FkJT#FGHY{FG]Q_FI(J2YZ FKGT
;-pVp'&)( 8(ff
{VvRZ:Yb!FKG/TPVF]J02(x3(5464646(*! 7tx:9up +ffv %vfi v JVYjUT9QSGT
iYb G]KI
emF\_Y3I#[#d KaeO\_F/fObFPVFI(JPJT#FPVF!GHY{FG]Q_FI(JP] Fff[F]J"Z:bY3c KaeO\_F/

-

+ / - / 7 p - / - /: %
~@7 $ 7 $ 4 ; pVp'& ( 8(ff
{V - -_p
=m 6 5p
um 6 / / 4
+ "
"TOQSPd\SKPVJn(WOKIJQ_J)XQSP !ZYbLKI(X2fY3P/PQ_eO\_FGT#Y3QSGHFhYZ
d"T9F]bF]ZYb/Fv(cQSIOQScQ_QSI9[ QSIKIX2YZ
Q_JP JT#bF]FLZ:Yb/cP YZOF`"pw~3v`p 3vKI9MpD0emY3QS\SP0M#Yj IJVYficQSI9QScQSQSI#[ Y3IffJT9FLP/W#eOc2YuM9W9\SKab PVXuPVJVFc
p 02(x3(5464646(*! 7 x:9 ( op:jUQSJTJT#F!KM#F{W9KaJVFNaK\SW#FP"YZ L"T9QSPLf9b/YeO\_Fc KM9cQSJPfmY3\_X{I9Y3cQSK\ fiDJQScF
PVY3\_NuQSI#[-K\_[Yb/Q_JTOcPhp JPG/T9F\wv YNK PVv r uGT#b/Q VNF]bv`xyuxaz fffiW#F]X{b/KI9I#Fvmxyy3T9KaJQSPncffW9GT
QSI(JVF]bFPVJQSI9[QSPJT9KaJdJT9FUK\_[Yb/Q_JTOcP {I9YjUIKab/FUT9Q_[3T9\SXffGHY3c2fO\gQSG]KaJVFMKI9M2JQgc2F"GHY3I9PW9cQSI#[fiZYbBJT#F
[FI#F]b/K\ncQSIOQScQ_KaJQ_Y3I5YZ pfiffoW#F]X(bKI9I#FvLxyy3 " YjnF]NF]bvjUT#FIW9PQSI#[JT9FNaK\SW#FYZ
KP-QSI
F`!p +("KI9M KPhQSIF`ffpDv`JT9FffGHYbbFPfY3IOM9QSI#[2Z.W9I9GHJQ_Y3I 5emFGHY3c2FPhPW#eOc2YuM9W9\gKab"PVX{cc2F]JVb/QSG
p - / % -M02(x3(5464646(*!"7 x:9 /: P2P/W9G/T7vBc2YbFkFG]Q_FI(Jlp.KI9MPQSc2f`\_F]boK\S[Yb/Q_JT9cP-FH#QSPVJ-JVY
cQSIOQScQ_]F #YbnFHuKc2f`\_FvJT#F]b/FUFH#QSPVJPRK!fmYjnF]bZ:WO\9GHY3c!e`QSI9KaJVYb/QSK\OK\_[Yb/Q_JT9c jBYb
{QSI9[QSI k
p'!




pfifffiW#F]X{b/KI9I9Fvxyy3 YJVF!JT9KaJJTOQSP"QSPPVJQg\S\mK2NF]bX\SKab[FGHY3c2f`\_FHuQSJX
:BC



fi

iwc


ffff

" 5"Z>

k36) .?6" 7rff * )

c

"T#FRbFM9W9GHJQ_Y3IffQSPcKM9FRZ:bY3c JT#F? fi " Kab/Mfff9bYe`\_Fc 3 fiffp.#FQ_[Fv9xyy|3d"TOQSPQSPJT#FBG]\SKP/PQSG]K\
3 f9bYeO\SFc p KabF]X r Y3TOI9PVY3I7vLxy3ay3vdeOW#JffFKG/TNaKab/QSKaeO\_FKaf9fmFKab/P!QSIFHuKGHJ\SX lG]\SKWOPVFP]
hPQSI#[!K!jBF\g\ fi {I9YjUIbFM9W9GHJQ_Y3Ip KabF]X r Y3TOI9PVY3I7vOxy3ay3v#f`Ka[F {vujUQ_JTKIKM9MOQ_JQ_Y3I9K\9P/QSc2fO\_F
[3KM#[F]J]vfijnF5G]KItcK FKb/FM9W9GHJQ_Y3IZ:bY3c 3 fiJVYNF]bJVFHtGHYNF]bp:JT{W9P]vhQSI9M#F]fmFI9M9FIJ%PVF]Jv
Ye9JKQSIOQSI#[ Kh[b/Kaf`
QgI!jUTOQSG/T-K\S\{NF]bJQSGHFPT9KNF"M#F][bF]FLFQ_JT#F]b {vYbduv3KI9M-Z:YbjUT9QSGT!JT9FL\gKab[FPVJ
QSI9M9F]fFIOM#FIJdPF]Jhp:Z:YbnPKaJQgPV^OKaeO\_F QSI9PVJKI9GHFPRY%
Z 3 fi
3RT9KPRP/Q_]1
F G3 G a~{v{jUT#F]bC
F G3#G3QSPdJT#FhI(WOc!emF]b
YZNF]b/JQSGHFPY
Z d#bY3c JT9QgPBf`KabJQSG]W9\SKabn[b/KafOTv{jnFfieOW9QS\gMK2PQScfO\_F"bFMOW9GHJQ_Y3I%JVY2Y3W#bLf9bYeO\SFc YZ
cK8#QScQ_QgI#[ YJVFRJT9KaJ PQSI9GHFdjnFBKab/FRPVFKab/GT9QSI#[ ZYb KIYeO\SQSN{Q_Y3WOP7TX{fmYJT#FPQSP]vJT#FdYeOPF]bN8KaJQSY3I9P
KabFI#YJ Qgc2fmYbJKIJ-p:jBFG]KI5PW#f9fmY3PVFoJT9KaJfiK\S\FHuKc2f`\_FP TOKNF-JT#FffPKcFffYeOPF]bN8KaJQSY3I`U"T9KaJhQSP
jUT(XfiJT#FBb/FM9W9GHJQ_Y3IoY3IO\_XfieOW9QS\SMOP7G]\SKPP0NFGHJVYb/Pp:YNF]
b G3 GG]\SKP/PVFPvaFI9GHYuM9QSI#["JT9FBG]\SKPP0c2FcffeF]bPT9Q_f
YZ`KI(X-YZOJT#FPVFQSM9FIJQSG]K\{YeOPF]bN8KaJQSY3I9P] "T#FQSM#FKhQSP JT9KaJJT#FG]\SKPPFPKabF"QSIffY3I#F fiDJVY fiDY3I#F cKaf9fOQSI#[
jUQ_JTkJT9FNF]bJQSGHFP]v`KI9MJT#F]bFKab/FJjnYPVF]JPUYZ G]\gKPPNFGHJVYb/P eOW9QS\SJBZ:bY3
c
G3#GNFGHJVYb/P]v{FI9GHYuM9QSI#[oJT#F NF]bJQSGHFPRYZ RKG/TY3I#FUQgPdK!G]\SKP/PNFGHJVYbLjUQ_JT2Y3I9\SX
fi KffPVF]JdjUQSJ
Y3I9F ff]x GHYbb/FPVfmY3I9M9QSI#[!JVY-JT9F NF]bJVFHmv9KI9M%JT#FhbFcKQSIOQSI#[!GHY3c2fmY3I#FI(JPLKabFfi]F]bY{FP] RKGT
YZ JT#FGHYb/bFPVfmY3I9M9QSI9[-FH#Kc2fO\SFP"T9KNF!jBFQ_[3T(ff
J 0

fi KkPVF]JfijUQSJTG GONFGHJVYb/PvjUT#F]bF G GOQSPhJT#FI(WOc!emF]bhYZdFM#[FPfiYZ- B KG/TY3I#FFI9GHYuM#FPfiKI

FM9[Fv9KI9MJT9F]bF]ZYb/FhGHY3I(JKQSI9PnJjnY ff]x lp.KI9MJT#F b/FcKQSI9QSI9[!KabFfi]F]bY{FPdGHYb/bFPVfmY3I9M9QSI9[JVY
JT9FJjnYNF]bJQgGHFP"YZ JT#FFM#[F
BKG/TYZ JT9FGHYbbFPVfmY3I9M9QgI#[FHuKc2f`\_FPT9KNFffjBFQS[3TJff0
Y3IOPQSM#F]bhZYbcffW9\gKPpw~3vBp 3 ZYboFH#Kc2fO\SFff"T#F]XiKabF2JT#F2PW9c YZRJT9FGHY3IJVb/QSeOW#JQ_Y3IiJVY YZ
JT#FFH#Kc2fO\SFPT9KNuQSI#[jBFQ_[3T(J 0 v0KI9MJT#FFH#Kc2fO\_FPTOKNuQSI#[jnFQ_[3TJ 0 IJT#FPVFG]KPVFPv0jnF
G]KIlb/F]j"b/Q_JVF W9PQSI9[-JT9F[FI#F]b/QSGfiFHuf9bFP/PQ_Y39I

% (
pw~ 3
% 0 $ 7p*G3 G:7 9 7p 7x p*G3 G37 9Hp*G3 G37 17 x $ 7p*G3 G:7 9 (Lpw~+(
% 0 $ p*G3 G:7 9Hpw~ $ 7pw~ 4
pw~3
" F]bFv QSPdJT#FfiI{W9c!emF]bBYZFM#[FPLT9KNuQSI#[ffJT#FQ_bBJjnY-NF]b/JQSGHFPLQSIJT#FfiPVF]JLGHYbbFPVfmY3I9MOQSI#[JVY-JT#F

xNaK\SW#FPRQSI v SQ PJT#FUI{W9cffemF]bdYZmFM#[FPRT9KN{QgI#[JT#FQ_bRJjnY!NF]bJQSGHFPnQSIJT#F PVF]JBGHYbb/FPVfmY3I9M9QSI#[
JVYJT#FC
7 xfiNaK\SW#FPQgI v9KI9M QSPLJT#FI{W9c!emF]bLYZ FM#[FPUT9KN{QgI#[Y3I#FoYZ0JT9FQ_bNF]bJQSGHFP"QgIkJT#F x
PVF]J]vOKIOMJT#FYJT#F]bUY3I#F!QSIkJT#F!
7 xPVF]J] QgPLJT#F!I{W9c!emF]bYZ xoNaK\SW#FPQSI
uW9f9fmY3PVF JTOKaJff0 ff
0 p214351 0
G3#G 4 0 R"T#FIkJT9FcK8uQgcQ_KaJQ_Y3IkYZ QSPLJT#FcK8#Q fi
cQ_KaJQSY3IYZ v`ZY3\S\SYjnFMe(XkJT#FffcK8uQgcQ_KaJQ_Y3IYZ KMOcQ_JP"KcK8uQSc-W9c Z:Yb #%G3 G a~{v

KI9MjUQSJTJTOQSP-N8K\SW9F%Z:Yb vBQSJG]KIeFkPT#YjUIJT9KaJcK8#QScQSQSI#[
emY3QS\SP-M#YjUIJVYcK8#QScQ_]F
~
fi vhJT9KaJlQSP]v JT#F p:jBFQS[3TJVFM`%I{W9cffemF]b%YZ-FM#[FPI#YJZ.K\S\SQgI#[FI(JQ_bF\_XQSI(JVYJT9F5PF]JlGHYb fi
bFPVfmY3I9MOQSI#[JVYJT#F xkNaK\SW#FP]zLjUT9FI#F]NF]bJT#F 3 fi5QSI9PVJKIOGHFlQSP2PKaJQSPV^`KaeO\_Fp.KI9MW9P/QSI#[5JT#F
fOKabJQgG]W9\SKabLM#F][bF]FPLYZJT9F NF]bJQgGHFPv9JT9QSPnPVF]JGHYbbFPfY3IOM9PRJVY2JT9Fh\SKab/[FPVJQSI9M#F]fmFI9M#FI(JRPVF]JY
Z -

k36)N6)bB^"Z> >





T#F f9bY{YZ7YZ7JT9QSPn\_FccKffQSPn(W9QSJVF PVJVb/KQS[3TJVZ:YbjLKab/M7v{eOW#JdjnF [3QSNFhQ_JnZ:YbnGHY3c2f`\_F]JVFI#FPP]
"
G]KIemF
bF]j"bQ_JVJVFIKP

%

4
" &

$

:BC



" (

pw~|3

fi

jUQSJT

0 , " 1 0 , " 1
% 0 8 ( " % !7" x $
(
pw~3
!7 x $
jUT9F]bF p
J( 9% -
/?7 -/D uW9f9fmY3PVFZ:YblGHY3IJVbKM9QSGHJQ_Y3IJT9KaJkZ:YblPVY3c2F
vff %
lp
( 9
u FPQgc2fO\_XfmF]b/c-W#JVFJT#F2JjnYlNaK\SW#FP -
/BKIOM -/Dv0KIOM5jBFPT9Yj JT9KaJoJT9FI#F]j
NaK\SW#F!YZ KaZJVF]bv vQSP I#YJh[bFKaJVF]bfiJT9KI eF]Z:YbFfffF]bcffW#JQgI#[#v @ UT#F!M9Q *mF]bFI9GHFffemF]JjnF]FI
KIOM @ G]KIemFLFKPQS\_XM#FGHY3c2fmY3PVFM2W9P/QSI#[fiJT#FUI#YJKaJQSY3I , " 1 @ p'*ff(
um/0 2( x3(5464646(*! l
7 x:9 (O5% 0
{
KPhJT#F-N8K\SW9F!YZ k
" p:F`pw~3VhQSI
@ vmKIOM
, " 1 p'*ff(
=m 0 2( x3(5464646(*!.7 x:9 (O % 0
{ KP JT9F!NaK\SW#F
YZ
" p:F` pw~3VUQSI F-K\SPVYM#F]^OI9F
(
( m/0 2( x3(5464646(*!
7 x:9 (O % 0
% 0 8( , " 1 % , 1 , 1 , " 1 , " 1 4 pw~3
*ff
F-M#F]^OI#FoQSIkJT#FffPKc2FjLKX , " 1 @ F!YeOJKQSI
7 @ % , " 1 7 , " 1 @
4 ' , " 1 7 , " 1 @
4
pw~y3
( 7& "
RbYNuQSI#[2JT9KaJ 7 @ 2G]KIemFoYe9JKQSI#FMlKP"ZY3\S\SYjUP]d Q_bPVJ]v
0 7 0 "
$
, " 1 7 , " 1 @ %
xH7 $
E4
!A
7 x
F-K\SPVYT9KNF
m0 x3/( ~)(5464646(*! 9 0
( 69
~ 0
" $
: 7 ~ 0 " $ : 7 ~ 0 $
, " 1 7 , " 1 @ % ~!A0
$




7 x
!A
7 x
!A
7 x
!
7 x
~0 7 0 "

%
,$ : 7 $

!7x
~0 7 0 "
$ :
%
8x 7 $
E4
!
7 x
" F]bFUjnF TOKNFfiW9PVFUJT9F"Z:KGHJnJT9KaJ %
" k"T9QSPP/T#YjUPBJT9KaJ 7 @ uvuKI9MFI9M9P





JT#FfObY(YZ0YZ FccKxa

k36)N6)

" 5"Z>

c

0YhKNY3QSMffGHY3I9Z:W9P/Q_Y3I7v8jBFLG]K\S\ JT#FnNaK\SW#FdYZ GHY3c2fOW#JVFMffYNF]b JT#FnJVb/KI9PVZ:Yb/c2FMffPVF]J YZ#FHuKc2f`\_FP]v
KI9M p Z:Yb m0 ( 9KI9M
m0 ( 9KPhJT#FffNaK\SW#FffYZRGHb/Q_JVF]bQ_Y3I WOPQSI#[NFGHJVYb/ h)JfiQSP
PQScfO\_FhJVYYe9JKQSIlK ffVP(W G]Q_FI(J 2emY3W9I9M%JVYGT#FGJT9FJT#F]YbFcF!T9KNF

-p % p 7
p % - p

4

> 3
LG > G
x
4

> 3
GL> G
x

0 4 4 $ = 4 $ = " "$ (
GL>HG 734 "734

p

0 4 4 $ = 4 $ = " "$ 4
"87 4

GL> G 734


p ux

:BC C

fi
" F]bFv0 l
4 QSP"JT#FffPWOc

iwc


ffff

YZjBFQS[3TJP YZ JT#F!FH#Kc2fO\_FP QSIJT#F!Yb/Q_[3QSI9K\PVF]J]v`j T#Y3PVFNFGHJVYb/PfiT9KNF
wp .p v`PQSIOGHFoY3W#bUK\_[Yb/QSJT9c QSPYfOJQScK\wv

ff]x cKaJG/T9QSI9[JT#FF\_FcFIJPUYZ<>L YJVF!JT9KaJ

KI9MjnFYe9JKQgI

-p


-p

4

> 3
GL> G
x

0 4 4
GL> G



734

$ =

"87 4
4



$ = " 7 $ =

"734 4


$ = "





"$ 4

qnXkJK{QgI#[2Y3I9\_X%JT#FofmY3PQ_JQ_NFof`KabJYZ0JT9Fb/Q_[3T(J fiT9KI9MPQgM#Fv9KI9MkbFcKab
{QSI9[2JT9KaJ

fi

> 3 (RGL> G
3x ( bm >nv&6 "734
$ = " $* ' 4 4 (
6 " 7 ? +4 $ = " :p JT#Fb/QS[3TJhPW9c
QgPUp'!7 GL> G $ K I9MJT#Fff\_F]ZJY3I9FQSP *p GL> JG 7x 5 $av
"

fi JT9F!GHY(FG]Q_FIJUYZ*04QSI QSP 54% 6 734 $ = 6 "7 ? +4 $ = v




jnF[F]J

-p

-p

$ GL> *p GGL>p'! G37 7GLx> G 0 4 4

4



> 3
LG > G
x
-p $ 7p p'C!7 7 x9







-p

Ox



!7


$

4



> 3
GL>HG
x
ff
fi


04 54


(

KP G]\SKQSc2FM7

k36)N6)bB^"Z> > %
n

emFGHY3c2FP"QSIJTOKaJUG]KPVF




jUT9F]bF % - x /

% 0 $ 0 $ (
p ~3
7 - /DB"T#F]bFfiKabFo^9NFoM9Q *mF]bFI(JLN8K\SW9FPBZ:Ybfikv#[3Q_NuQSI#[-b/QSPF JVYI9QgI#F M9Q#*F]bFI(J

%
%
%
%
%

,
x ,
,
7 x ,

7 ~ ,
U
~

% p 7x3( x
% p
7 x3(
% p
7 x3(
7 x
% p.2(
7 x
% p x3(
7 x

(

%

%
4
:BC


p.2( x (
% p.2( % p 3x ( x (
p 3x ( (

fi

Q
% 5jUT#F]bF 0 7U~)( 7x3(2(x3(/~ 93 0 7x3(2(x3(/~ 93vJT9FN8K\gW#F % 5
PT#Y3W9\SM5emF
f9bF]Z:F]bbFMkJVYJT#FNaK\SW#F % 17 xQ *iJT9F!GHYbbFPVfmY3I9MOQSI#[ QgPPcK\S\_F]bv#JT9KaJUQSP

0 $ 0 $
EUFKabb/KI#[3QSI9[2JVF]b/cP[3Q_NFP0 0 (&


>

0 $ & 0 $ & 4



p 3

R"TOQSP\_FKM9PLJVYJT9Fb/W9\_FfiYZ JT#F\_FccKu



qLKW#F]bv"_v rs Y3T9KNuQwvaEup+xyyy3 IffFc2fOQSb/QSG]K\GHY3cfOKab/QSPVY3IffYZ9NYJQSI9[hG]\SKP/PQ_^OG]KaJQ_Y3I-K\_[Yb/QSJT9cP
qLKa[[3QSI9[#vOemY(Y3PJQSI#[#v#KI9MNaKab/QSKI(JP] 8 "5 J " 2J 3v > vx]6`xy{
qL\SK Fv _v F]Y[3T7v "_v r F]bv p+xyy3 bF]fmY3PQ_JVYb/X-YZcKG/T9QSI9F \_FKab/IOQSI#[M9KaJKaeOKPFP]_
ff
fifi fi "!
fifi$#"% & $ ff' ff( $ #
qnbFQScKIv p+xyy|3LqnKa[[3QgI#[f9b/FM9QSGHJVYb/P] 8 "6 J
0 " 2J 3v <) vx~ `x +3u
qnbFQScKIv _vR#b/FQSM9cKI7v
"ff_vnfi\SPT9FI7vE _v r {JVY3I9Fv Up+xy +( Q !#"%<%KJ
" J " V
*U 3 %<%KJ V % KM9PVjnYbJT7
qLW Kuv _v r F]F"v + fipw~a#xd}hKaJK2cQSI9QSI#[-GHb/Q_JVF]b/QgK!Z:YbLJVbF]F fiDeOKPVFMkbF][b/FPPQ_Y3IkKI9MkG]\SKPP/Q_^OG]K fi
JQSY3I7oI , 2 /j V J 3 %-[N @ p H " J "!bQ dN ]V /. fX ! W V23{ PJ % a] J

P " ""% % v`f9fO~30 5|{
qLW9I(JQSI#Fv _v r hQ_eO\_F]JVJ]vo`p+xyy~3 Z.W#bJT#F]bdGHY3c2f`Kab/QSPVY3IYZmPVfO\SQSJVJQSI#[hb/W9\_FP Z:YbR}hFG]QSPQ_Y3I fibF]F
QgI9M9W9GHJQ_Y3I 8 "6 J 1
0 " 2J 33
v 2v { {
\SKa
b `v 0_v r qBY3PjBF\S\Dv`Ep+xyyuxoEUW9\SF!QSI9M9WOGHJQ_Y3IjUQ_JT fi&
~ PVY3cFffbFGHFI(JoQSc2f9b/YNFc2FI(JP]U+I
, > /j V J 3 % [N 54 $
# " G EJ 376 %<%KJ J " 2J 3vOfOf72x `x|uxa
Y3T#FIv _v r uQSI#[F]b
v +Rp+xyyy3 uQSc2f`\_Fv`9KPJ!KI9M *mFGHJQ_NFE W9\_F FKabI#F]b-8
, _
/j V J 3 % [N :
9 " J "! Q 4N ]V <;
J J "! p ! !wJ 3( ]v#f9f 5+~{
M#F Kab/N8K\ST9Y Y3c2FP]vOn _v r KPG]W#F\Dv-p+xyy +(L#} v9K2PVJVYuG/T9KPVJQgGK\_[Yb/Q_JTOc ZYbU\SFKab/I9QSI#[
M9FG]QSPQ_Y3I\SQgPVJPhjUQ_JT\SQScQ_JVFM5GHY3c2fO\_FH#Q_JX ; "! %[N 8 " " J % " V ; J J "! p ! !\J _
3{ H=
v 9>8v`~u?x 5a3~{
}fiQ_F]JVJVF]b/QSGT7v0 npw~a IFH{fmF]b/QScFIJK\dGHY3cfOKab/QSPVY3IYZLJT#bF]FcF]JT#Y{MOPoZYb-GHY3I9PVJVb/WOGHJQSI#[
FIOPVFc!e`\_FP YZ`M#FG]QSP/Q_Y3IJVbF]F2P 3qnKa[[3QgI#[#vaeY{Y3PVJQSI9[#v8KI9Mffb/KI9M9Y3cQ_KaJQ_Y3I7 8 "5 J @
" 2J 33v
>) 8v0x `2x 3(
}hY3cQSI#[Y3Pv 0Rp+xyy3 RbY{GHFP/P fiDYb/Q_FI(JVFM "UFW9b/QSPVJQSG-Z:Yb YuM#F\PVF\SFGHJQ_Y3I7-8
, 2 /j V J 3 % [N
:
9 p H " J "!cQ dN H 8 "6 J
" 6J 33v9f9fx~30 `x {
#FQ_[Fv ffLp+xyy|3 JT#bFPT9Y3\SMYZ"\SI -ZYbKaf9f9b/Y#QScKaJQSI#[iPVF]J-GHYNF]b+B
, > /j V J 3 % [N
2< ;:Q 8 69
%eJ $ZT [NRQ
$ J 33v9f9f ux +C5ux{
#b/KIOG v U_v r Q_JVJVFI7v(p+xyy3 hPQSI#["K dF]b/c-W#JKaJQ_Y3IffFPVJZ:Yb JVJVb/QSeOW#JVFdPVF\_FGHJQSY3I!QSI}hFG]QSP/Q_Y3I
"bF]FP]m7
,L 2 W V J 3 % [N
9 p ] " J "!AQ dN H 8 "5 J ff
0 " 2J 3v{f9f
2x ~ `x|au
#bFWOI9M7D
v +-_v r KPY3I7v p+xyyy3 "T9FK\_JVF]bI9KaJQSI#[M#FG]QSPQSY3I JVbF]F\_FKabI9QSI#[K\_[Yb/Q_JT9cl +I
, > /j V J 3 % [N E
9 p ] " J "!^Q dN H 8 "6 J F
" 2J 33v{fOfx~ +C`x {
:BC>=

fi

iwc


ffff

#b/QSFM9cKI7v _v "hKPVJQ_Fvao_v r "QSeOPT9Q_bKI9QwvHE{pw~a M9M9QSJQ_NF Y[3QgPVJQSGREUF][bFPPQSY3I 8Kfi{JKaJQgPVJQSG]K\
fiQ_F]j YZqnY{Y3PVJQSI#[# ;+ "! % [N 6 " J % J % v < 23v' 3053 +#
KabF]Xv _v r Y3T9I9PVY3I7v}-Lp+xy3ay3 Q
$ ] %)" Vp . "6 "rJ !wJ . ]," 3 $ZJ V [N
,v_ QfT
! %<% RqnF\S\0F\_F]fOT9Y3I#F KaemYb/KaJVYb/QSFP]
b JP/G/T#F\wv _v
N K PVv _v r uG/T9b/Q VNF]bv up+xyux`"T#FnF\S\SQ_fOPY3QSMoc2F]JT#YuMKI9MffQSJP0GHY3I9PF(W#FIOGHFP
QgIGHY3c!eOQgI9KaJVYb/QSK\7YfOJQScQ_KaJQ_Y3I Q J " J<" v 9avx|y `xy3(
" Y3\_JVFvBE! p+xyy 3 F]bXPQScfO\_FG]\SKPPQS^OG]KaJQ_Y3Ib/WO\_FP2fmF]bZ:Yb/c jnF\S\Y3I cY3PVJGHY3cc2Y3IO\_XW9PVFM
MOKaJKPVF]JP] 8 "6 J
0 " 2J 33
v 9 9av| {yuxa
" X3Ka^O\wv _v r EUQSNFPVJ]v#Ep+xy3a|3 Y3I9PJVb/W9GHJQSI#[-Yf9JQScK\M9FG]QSPQ_Y3I%JVbF]FPQS.
P fiGHY3c2f`\_F]JVF^
p dN8 K _


,


3






H


v




v
x
2


`


x
(


" J 2 %<%KJ
%
Y3TOI7v

r
"ff_v Y3TOKNuQwvOE_v 'OF][F]bv p+xyy +(bbF\SF]N8KI(J"Z:FKaJW#bFPUKIOMlJT#F!P/W#eOPVF]J"PVF\SFGHJQ_Y3I
fObYeO\_FcRI , > /j V J 3 % [N :
9 9 p ] " J "!vQ dN ]V 8 "6 J 1
" 2J 33v
fOfx~u?x `x~y{
FKab/IOP]v _v r KI9PVY3W#b
v +Up+xyy3 KPVJ]vRqnYJVJVY3c fiW#f}hFG]QSPQ_Y3I"bF]F db/W9IOQSI#[5K\_[Y fi
bQ_JT9c jUQSJT UFKab fifif9JQScK\[FI9F]b/K\SQ_KaJQ_Y3I +I ,L 2 /W V J 3 %/[N 9 p ] " J "!
Q dN ]V 8 "6 J 0 " 2J 3v`f9fO~|y {~3(
FKab/IOP]v _v Qwv _v BQ_JVJ]v _v r dK\SQSKI(J]v up+xy3OfiI!JT9FB\_FKab/IOKaeOQS\SQ_J)XUYZ#emY{Y3\_FKIZ:Yb/c-W9\SKaF+I
, > /j V J 3 % 9 ;Q 8 69
%eJ $ZT ONRQfT
$ J 3v9f9f#~ {~y {
Y3T9KN{QDvL}-_v r {Y3cc2F]b^9F\SMvn}-!p+xyy3 0Kab/[F]JVJQSI#[qLW9PQSI9FPPkW9PVF]b/P%jUQ_JT}hFG]QSPQSY3It"KaeO\_F
\SKPPQ_^OF]b/P]a:
,L 2 W V J 3 % ) p ] " J "!#Q dN H . fX ! W V23{ PJ % a]
J P " ""% % vOf9f#~ +y {~ {
KI9PVY3W#bv +_v r G \S\_FPVJVF]bvu}-pw~adqBY{Y3PVJQSI9[WOPQSI#[ffe9b/KI9GT9QSI#[fff9bY[b/KcP+5
, > /j V J 3 %
9 > %p H " J "!Q dN ]V qQfT
$ " J "! " 2J 3 av f9f ~~a
~~ +#
Kab[3QSI#FKI(JW7v#}-_v r }fiQ_F]JVJVF]b/QgG/T7v#o p+xyy3 db/WOI9QSI#[!KMOKaf9JQ_NFfiemY(Y3PVJQgI#[#+5
, > /j V J 3 % [N
:
9 ) p H " J "!cQ dN H 8 "6 J
" 6J 33v9f9fO~ux?x {~ux{
Q_JG/T#F\g\wv9op+xyy3 8 "6 J
" 2J 33 G b/Kj fi "hQS\S\D
Y{
G `vaE_v r KP/G]W#F\wva{p+xy
3OfiI!\SFKab/I9QSI#["M9FG]QSPQ_Y3IGHY3ccQ_JVJVF]FP]{:
,L 2 W V J 3 % 9 <
p H " J "!cQ dN H 8 "5 J 1
" 6J 33vOf9f( +9x 5+~au Yb[3KI KW#Z.cKI9I7
Y{
G `vE!_v r Kaf9f{Xv Rp+xyy3fiI5JT#F2fmYjnF]boYZLM#FG]QSPQ_Y3I5\SQgPVJP]+8
,L 2 W V J 3 % [N 7
9
p H " J "!cQ dN H 8 "5 J 1
" 6J 33vOf9f( +9x 5+~au Yb[3KI KW#Z.cKI9I7
hfOQSJVv9}ff_v r KG]\gQSI7v9Ep+xyyy3 YfOW9\SKabUFI9PVFcffeO\_Fc2F]JT#YuM9P 9K2P/W#bNF]X
$ "! [N1;
J dJ"!
p ! !wJ 3(
*" % " v 9 9avx|y `xy{
fffiW#F]X{b/KI9I9Fv np+xyy3 QgI9QScQ_QgI#[PVX{cc2F]JVb/QSG2PW9eOc2YuM9W9\SKabfiZ.W9I9GHJQ_Y3I9P 8 " " J
"! , _
33 " TgJ 33
v 2 < v `x~{
fffiW9QgI9\SKI7v 9E!p+xyy +( Q) 1 !
` 3 "fT %vNA "6 J ! " 2J 3 Yb/[3KI KW#Z.cKI9I
fffiW9QgI9\SKI7v ELp+xyy|3qLKa[[3QSI#[#v qnY(Y3PJQSI#[iKIOM +# {l+B
, > /j V J 3 % [N 5
9 > " J "!
]

V







p



(
3

]

#
v
9
f

f
`



~



u


3


u


Q dN ; J dJ"! ! !wJ

:BC%$

fi

EUQgM#[F]jnKXv _v KM9Q_[3KI7v }-_v E QSG/T9KabM9PVY3I7v_v r KI#Fv np+xyy3I(JVF]bf9b/F]JKaeO\_FemY{Y3PVJVFM
IOKQ_NFe`KXFP5G]\SKPPQS^OG]KaJQ_Y3I7 +I ,L 2 WV J 3 % [N ) p H " J "! Q 4N ]V
. fX ! j V23( PUJ % a] J P " "
"% % vOfOfx]#x?`x]+#
EUQSNFPVJ]vOEp+xy3 FKabI9QSI#[M#FG]QgPQ_Y3I\SQSPJP] 8 "6 J 0 " 2J 3v < v`~~y{~+|{
uGT9KafOQ_bFv E "_v #bFW9IOM7v +_v qLKabJ\SF]JVJ]v _v r F]Fv dnp+xyy3qnY{Y3PVJQSI#[JT#F Kab/[3QSI K
I9F]j FHufO\SKI9KaJQ_Y3I ZYb%JT#FlF *mFGHJQ_NFI#FP/PYZ hYJQSI#[c2F]JT#YuM9P] ;+ "! %/ON)% " J % J % v <" v
x| u?x `x||{
uGT9KafOQ_bFv#E!! U_v r uQSI#[F]bv +p+xyy3R+c2f9bYNFMkemY(Y3PVJQgI#[-K\S[Yb/Q_JT9cPLW9P/QSI#[GHY3I#^OM#FI9GHF fiDbKaJVFM
fObFM9QSGHJQ_Y3IOP]8
, 2 /j V J 3 % [N 7
9 9 -p ] " J "! Q dN ]V Q
$ " J "!
0 " 2J 3 8v`f9fOa {yuxa
dK\SQSKI(J]v p+xy +( JT#F]Yb/XYZdJT#Fff\SFKab/I9KaeO\_F QfTgT $ 2J
" J % [N ;:Q 8 v <@ vxx +C
xx +~{
dK\SQSKI(J]v Up+xy 3 FKab/I9QgI#[M9QSP W9I9GHJQ_Y3IOPYZfiGHY3I VWOI9GHJQ_Y3I9P]I , > /j V J 3 % [N
p H " J "! J Q dN H ; J J "! p ! !\J 3{ Hv9fOf |a &||{

:

5Q


fiJournal Artificial Intelligence Research 17 (2002) 333-361

Submitted 2/2002; published 11/2002

New Technique Combining Multiple Classifiers using
Dempster-Shafer Theory Evidence
Ahmed Al-Ani
Mohamed Deriche

a.alani@qut.edu.au
m.deriche@qut.edu.au

Signal Processing Research Centre
Queensland University Technology
GPO Box 2434, Brisbane, Q 4001, Australia

Abstract
paper presents new classifier combination technique based DempsterShafer theory evidence. Dempster-Shafer theory evidence powerful method
combining measures evidence different classifiers. However, since
available methods estimates evidence classifiers limitations,
propose new implementation adapts training data overall mean
square error minimized. proposed technique shown outperform available
classifier combination methods tested three different classification problems.

1. Introduction
field pattern recognition, main objective achieve highest possible classification accuracy. attain objective, researchers, throughout past decades,
developed numerous systems working different features depending upon application interest. features extracted data different types
like continuous variables, binary values, etc. such, classification algorithm used
specific set features may appropriate different set features. addition,
classification algorithms different theories, hence achieve different degrees
success different applications. Even though, specific feature set used specific
classifier might achieve better results obtained using another feature set and/or
classification scheme, conclude set classification scheme achieve
best possible classification results (Kittler, Hatef, Duin, & Matas, 1998). different
classifiers may offer complementary information patterns classified, combining classifiers, efficient way, achieve better classification results single
classifier (even best one).
explained Xu et al. (1992), problem combining multiple classifiers consists
two parts. first part, closely dependent specific applications, includes problems
many type classifiers used specific application?,
classifier type features use?, well problems
related construction individual complementary classifiers. second
part, common various applications, includes problems related question
combine results different existing classifiers better result
obtained?. work, concentrating problems related second issue.

c
2002
AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiAl-Ani & Deriche

output information various classification algorithms categorized
three levels: abstract, rank, measurement levels. abstract level,
classifier outputs unique label, case syntactic classifiers.
rank level, classifier ranks labels subset labels queue label
top first choice. type discussed Ho et al. (1994).
measurement level, classifier attributes class measurement value reflects
degree confidence specific input belongs given class. Among three levels,
measurement level contains highest amount information abstract level
contains lowest. reason, adopted, work, measurement level.
Kittler et al. (1998) differentiated two classifier combination scenarios.
first scenario, classifiers use representation input pattern.
hand, classifier uses representation input pattern second
scenario. illustrated first case, classifier considered produce estimate posteriori class probability. However, second case
longer possible consider computed posteriori probabilities estimates
functional value, classification systems operate different measurement systems. Kittler et al. (1998) focused second scenario, conducted
comparative study performance several combination schemes namely; product,
sum, min, max, median. assuming joint probability distributions conditionally independent, found sum rule gave best results. well known
approach used combining results different classifiers weighted
sum, weights determined Bayesian decision rule (Lam & Suen,
1995). alternative method presented Hashem & Schmeiser (1995), cost
function used minimize mean square error (MSE) order calculate linear
combination corresponding outputs number trained artificial neural networks (ANNs). expectation maximization algorithm used Chen & Chi (1998)
perform linear combination. fuzzy integral used Cho & Kim (1995a,
1995b) combine multiple ANNs, (Rogova, 1994; Mandler & Schurmann, 1988)
used Dempster-Shafer theory evidence combine result several ANNs. Many
combination methods also used combine classifiers, bagging
boosting (Dietterich, 1999), powerful methods diversifying combining
classification results obtained using single classification algorithm specific feature
set. bagging, get family classifiers training different portions training
set. method works follows. first create N training bags. single training bag
obtained taking training set size sampling training set times
replacement. training instances occur multiple times bag, others may
appear all. Next, bag used train classifier. classifiers
combined. Boosting, hand, based multiple learning iterations.
iteration, instances incorrectly classified given greater weight next iteration. so, iteration, classifier forced concentrate instances
unable correctly classify earlier iterations. end, trained classifiers
combined.
paper, focus combining classification results obtained using N different
feature sets, f 1 , , f N . feature set used train classifier, hence
N different classifiers, c1 , , cN . specific input x, classifier cn produces
334

fiA New Technique Combining Multiple Classifiers

Feature
Extraction
1

f

1

Classifier



1

c1

Combination

x

Feature
Extraction
N

f

N

Classifier

z

yN

cN

Figure 1: multi-classifier recognition system

real vector yn = [y n (1), n (k), n (K)]T , K number class labels
n (k) corresponds degree cn considers x label k. degree could
probability, Bayesian classifier, scoring system. Fig. 1 shows
block diagram multi-classifier recognition system.
Unlike statistical-based combination techniques, Dempster-Shafer theory evidence
ability represent uncertainties lack knowledge. quite important
problem classifier combination, usually certain level uncertainty
associated performance classifiers. Since available classifier combination methods based theory accurately estimate evidence classifiers,
paper attempts solve issue proposing new technique based gradient
descent learning algorithm, aims minimizing MSE combined output target output given training set. Aha (1995) gave following definition
learning:
Learning denotes changes system adaptive sense
enable system task tasks drawn population
effectively next time.
Based above, show instead attempting find analytical formula
accurately measures evidence, one obtain good estimate evidence using
appropriate learning procedures, discussed later.
basic concepts Dempster-Shafer theory evidence presented
next section. Section three discusses existing methods computing evidence.
proposed combination technique presented section four. Section five compares
proposed algorithm conventional methods used Kittler et al. (1998), fuzzy
integral, previous implementation Dempster-Shafer theory. Section six provides
conclusion paper.

2. Dempster-Shafer Theory Evidence
Dempster-Shafer (D-S) theory evidence (Shafer, 1976) powerful tool representing uncertain knowledge. theory inspired many researchers investigate
335

fiAl-Ani & Deriche

different aspects related uncertainty lack knowledge applications real
life problem. Today, D-S theory covers several different models, theory
hints (Kohlas & Monney, 1995) transferable belief model (TBM) (Smets, 1998).
latter adopted paper represents powerful tool combining
measures evidence.
Let = {1 , ....., K } finite set possible hypotheses. set referred
frame discernment, powerset denoted 2 . Following basic concepts
theory:
Basic belief assignment (BBA). basic belief assignment function assigns
value [0, 1] every subset satisfies following:
X
m() = 0,
m(A) = 1
(1)


worth mentioning m() could positive considering unnormalized combination rule explained later. probability theory measure probability
assigned atomic hypotheses , m(A) part belief supports A,
support anything specific, i.e., strict subsets A. 6= , m(A) reflects ignorance belief cannot subdivide finer subsets. m(A) measure
support willing assign composite hypothesis expense support
m(i ) atomic hypotheses . subset m(A) > 0 called focal element.
partial ignorant associated leads following inequality: m(A) + m(A) 1,
compliment A. words, D-S theory evidence allows us
represent actual knowledge without forced overcommit
ignorant.
Belief function. belief function, bel(.), associated BBA m(.) function
assigns value [0, 1] every nonempty subset B . called degree belief
B defined
X
bel(B) =
m(A)
(2)
AB

consider basic belief assignment generalization probability density function whereas belief function generalization probability function.
Combination rule. Consider two BBAs m1 (.) m2 (.) belief functions bel1 (.)
bel2 (.) respectively. Let Aj Bk focal elements bel1 bel2 respectively.
m1 (.) m2 (.) combined obtain belief mass committed C according
following combination orthogonal sum formula (Shafer, 1976),
X
m1 (Aj )m2 (Bk )
m(C) = m1 m2 (C) =

j,k,Aj Bk =C

1

X
j,k,Aj Bk =

336

,
m1 (Aj )m2 (Bk )

C=
6

(3)

fiA New Technique Combining Multiple Classifiers

denominator normalizing factor, intuitively measures much m1 (.)
m2 (.) conflicting. Smets (1990) proposed unnormalized combination rule:
X

m1 (Aj )m2 (Bk ), C
(4)
m1
2 (C) =
Aj Bk =C

rule implies m() could positive, case reflects kind contradiction belief state. work consider m() = 0 use
normalized combination rule. comparison normalized unnormalized combination rules problem combining classifiers considered future.
Combining several belief functions. combination rule easily extended
several belief functions repeating rule new belief functions. Thus pairwise
orthogonal sum n belief functions bel1 , bel2 , , beln , formed
((bel1 bel2 ) bel3 ) beln =

n


beli

(5)

i=1

Notation. According Smets (2000), full notation bel related functions is:
<
belY,t
[ECY,t ](w0 A) = x

represents agent, time, frame discernment, < boolean algebra
subsets , w0 actual world, subset , ECY,t agent knows
t. Thus, expression denotes degree belief held w0
belongs set worlds equal x. belief based evidential corpus
ECY,t held t.
practice, many indices omitted simplicity sake. Usually < power set
, 2 . bel defined 2 , < explicitly stated. w0 denoted
A. and/or omitted values missing elements clearly defined
context. Furthermore, EC usually conditioning event. So, bel(A) one
often used notations (Smets, 2000). proposed method, adopt
following notation: beln (k ), agent classifier, subsets concern
class labels.
important mention combination rule given Eq. 3 assumes
belief functions combined independent. Consider certain information
would like measure belief, think process mapping
original information level belief level. Liu & Bundy (1992) explained
independence original information level would lead independence belief level.
But, two independent belief functions rooted original information level,
original information may may independent. problem combining
multiple classifiers, original information level consists outputs classifiers
combined, belief level consists evidence classifiers (or BBAs).
assumption BBAs independent, whether obtained independent
dependent original information, hence justify use D-S theory. fact, many

337

fiAl-Ani & Deriche

existing classifier combination methods assume classification results different classifiers independent (Mandler & Schurmann, 1988; Hansen & Salamon, 1990; Xu et al.,
1992). Since classifiers evidence plays crucial role combination performance,
increased interest proper estimation evidence. next section,
discuss number existing classifier combination methods estimate evidence
classifiers, section 4 present proposed method.

3. Existing Methods Computing Evidence
Mandler & Schurmann (1988) proposed method transforms distance measures
different classifiers evidence. achieved first calculating distance
learning data sets number reference points order estimate statistical distributions intra- interclass distances. both, posteriori probability function
estimated, indicating degree input pattern belongs certain reference
point. Then, class label, class conditional probabilities combined
evidence value ranging 0 1, considered BBA class.
Finally, Dempsters combination rule used combine BBAs different classifiers give final result. explained Rogova (1994), method brought forward
questions choice reference vectors distance measure. Moreover, approximations associated estimation parameters statistical models intra-
interclass distances lead inaccurate measure evidence.
Xu et al. (1992) used K + 1 classes perform classification task,
(K + 1)th class denotes classifier idea class input comes
from. classifier cn , n = 1..N , recognition, substitution, rejection rates (nr , ns ,
1 nr ns ) used measure BBA, mn , follows:
1. maximum output specific classifier belongs K + 1, mn
focal element mn () = 1.
2. maximum output belongs one K classes, mn two focal elements
k k mn (k ) = nr , mn (k ) = ns . classifier says nothing
propositions, mn () = 1 mn (k ) mn (k ).
drawback method way evidence measured. two problems
associated method. Firstly, many classifiers produce binary outputs,
rather probability like outputs. So, first case, inaccurate assign 0
mn (k ) mn (k ). Secondly, way measuring evidence ignores fact classifiers
normally performance different classes. clear impact
performance combination method compared conventional
methods especially Bayesian (Xu et al., 1992).
Rogova (1994) used several proximity measures reference vector classifiers output vector. proximity measure gives highest classification accuracy
later transformed evidences. reference vector used mean vector, nk ,
output set classifier cn class label k. number proximity measures,
dnk , nk yn considered. classifier, proximity measure class

338

fiA New Technique Combining Multiple Classifiers

transformed following BBAs:
mk (k ) = dnk ,

mk () = 1 dnk


mk (k ) = 1 (1 dnl ), mk () =
(1 dnl )
l6=k

l6=k

evidence classifier cn class k obtained combining knowledge
k , thus mk mk . Finally, Dempsters combination rule used combine evidences
classifiers obtain measure confidence class label. Note first
combination performed respect class label (Rogova used notations k
k), second one agent n. idea promising one. However,
major drawback way reference vectors calculated, mean output
vectors may best choice. Also, trying several proximity measures choosing
one gives highest classification accuracy questionable.

4. Proposed Combination Technique
section estimate value mn (k ), represents belief class label
k produced classifier cn . addition, also estimate mn (), reflects
ignorance associated classifier cn . Since ultimate objective minimize
MSE combined classification results target output, mn (k ) mn ()
estimated using iterative procedure aims attaining objective.
first compare yn , output classification vector produced classifier cn ,
reference vector, wkn , obtained distance used estimate BBAs.
BBAs combined obtain new output vector, z, represents combined
confidence class label. wkn measured MSE z
target vector, t, training dataset minimized. Note two indices wkn .
Thus, class label k, dont consider value assigned classifier cn ,
rather whole output vector (values assigned class label).
Let frame discernment = {1 , k , , K }, k hypothesis
P
input x class k. Considering BBA, mn , mn (k ) 0, mn () =
1 K
k=1 mn (k ), mn 0 elsewhere. Let dn (k ) distance measure gn
unnormalized ignorance classifier cn , mn (k ) mn () estimated according
following formulas:
(6)
dn (k ) = exp(kwkn yn k2 )
mn (k ) =

dn (k )
K
X

(7)

dn (k ) + gn

k=1

mn () =

gn
K
X

(8)

dn (k ) + gn

k=1

mn (k ) mn () normalized values dn (k ) gn respectively. Similar
wkn , minimized MSE used estimate gn .
339

fiAl-Ani & Deriche

Evidences classifiers combined according normalized combination rule
obtain measure confidence class label. k th element new combined
vector given by:

z(k) = m(k ) = m1 (k ) mN (k ) =
mn (k )
(9)
nN

L
given classifier cn , let = {1 N } \ {n}, mI = iI mi , Eq. 9 written
as:
z(k) = mI (k ) mn (k )
(10)
according Eq. 3, combination two BBAs is:
mj (k ) ml (k ) =

mj (k )ml (k ) + mj (k )ml () + mj ()ml (k )
XX
1
mj (p )ml (q )
p

(11)

q
q6=p

wkn gn initialized randomly, values adjusted according
training dataset MSE z minimized.
Err = kz tk2

(12)

values wkn gn adjusted according formulas:
Err
wkn [old]
Err
gn [new] = gn [old]
gn [old]

wkn [new] = wkn [old]

(13)
(14)

learning rates. terms Err/wkn Err/gn derived
follows:
Err
wkn
Err
gn

=
=

Err z(k) mn (k )
z(k) mn (k ) wkn
Err z(k) mn (k )
z(k) mn (k ) gn

340

(15)
(16)

fiA New Technique Combining Multiple Classifiers

where,
Err
= 2[z(k) t(k)]
(17)
z(k)
("
#
XX
z(k)
=
1
mn (p )mI (q ) [mI (k ) + mI ()] + [mn (k )mI (k ) +
mn (k )
p
q
q6=p

"
mn (k )mI () + mn ()mI (k )]

#),
X

mI (p )

p
p6=k

#2

"
1

XX
p

mn (p )mI (q )

(18)

q
q6=p

X
2 exp(kwkn yn k2 )[wkn yn ][
dn (p ) + gn ]
p

mn (k )
=
wkn

p6=k

X
[
dn (p ) + gn ]2

(19)

p

mn (k )
dn (k )
=X
gn
[
dn (p ) + gn ]2

(20)

p

Fig. 2 shows flow chart learning procedures. found adjusting
values gn achieved first iterations. continuing training
fine-tune values wkn improvement training set,
reach pre-defined maximum number epochs1 , result could enhanced.
Note weight values adjusted pattern (not batch training). fix
value = 106 , first initialized 5 104 , changed according
value MSE, described flow chart.
Although computational cost involved implementing technique higher
combination methods2 , need perform training once,
done off-line. Then, optimal values wkn gn , perform on-line
combination, comparable combination methods.
hand, indicated beginning section, consider reference
vector, wkn , class. leads increase training time number classes
and/or classifiers increases. alternative consider using reference value
class, wkn . save 50% training time case several
classifiers classes. Note learning formulas applicable replacing wkn
wkn yn ykn . refer two alternative approaches DS1 DS2,
respectively. following section, compare DS1 DS2 well-known
combination methods.
1. maximum number epochs set 50 experiments described paper
2. Training time experiments conducted section 5 required less 3 minutes
conventional PC

341

fiAl-Ani & Deriche

Start
Th
=
Errnew =
Errold =
It_no =
It_nomax=

Randomly initialize
wkn g n
n =1: N, k =1: K
Initialize learning
rates
-4
-6
=510 , =10

error threshold
current MSE
previous MSE
current no. iterations
max. no. iterations

pattern

It_no=It_no+1
Errold = Errnew

Compute
mn(k ) mn()

Adjust
wkn g n

Compute
z Errnew

Yes
Errold -Errnew>Th
= 1.03


= 0.7

Yes


It_no<It_nomax
-4
> 10

End

Figure 2: Training procedure proposed technique

worth mentioning although training procedures proposed
method backpropagation algorithm ANN based minimizing MSE using
iterative approaches, proposed method ANN similar. backpropagation
training operates passing weighted sum input activation function,
usually multi-layer architecture known multi-layer perceptron (MLP). Extracting
rules trained MLP challenging problem. hand, training
proposed method operates measuring distance classification vector
reference vector. distance would later used measure belief class
label classifiers. final confidence class label obtained combining
beliefs classifiers. Unlike MLP, belief given class label classifier
indicates contribution towards final confidence. reader may refer (Denoeux,
2000) description ANN classifier based D-S theory.

342

fiA New Technique Combining Multiple Classifiers

5. Performance Analysis Different Combination Methods
following three classification problems considered: texture classification,
classification speech segments according manner articulation, speaker
identification. ANNs used perform classification three problems.
case, classifiers sorted according performance, best classifier
referred c1 , 2nd best c2 , worst one cN .
problem, consider different number classes, combine results
different number classifiers, combining results best, worst mixtures
best worst classifiers investigated. example, five classifiers
would like combine two these, consider combining best two,
{c1 , c2 }, best one worst one, {c1 , c5 }, worst two classifiers, {c4 , c5 }. following
combination methods tested: weighted sum (WS)3 , average (Av), median (Md),
maximum (Mx), majority voting (MV), fuzzy integral (FI) (Cho & Kim, 1995a) 4 , Rogovas
D-S method (DS0) (Rogova, 1994), proposed method two alternatives (DS1
& DS2). training set used train ANNs used estimate confusion
matrix WS FI, well estimate evidence DS0, DS1, DS2.
Two measures used compare performance different combination
methods, namely: overall performance error reduction rate (ERR). overall performance mean classification accuracy obtained combining considered subsets
2, , N classifiers. ERR percentage error reduction obtained combining
classifiers reference best single classifier:
ERR =

ERBSC ERCC
100
ERBSC

(21)

ERBSC error rate best single classifier ERCC error rate obtained combining considered classifiers. Unlike classification accuracy, ERR clearly
shows performance combined classifiers improves deteriorates compared
best single classifier. words, shows merit performing combination. specifically concentrate maximum ERR obtained combining
considered subsets 2, , N classifiers. addition, also investigate
value ERR gets affected increasing number combined classifiers.
5.1 Texture Classification
Several experiments carried classification texture images.
textures considered are: bark, brick, bubbles, leather, raffia, water, weave, wood
wool (USC, 1981). order obtain better comparison different combination
methods, considered classifying first two textures, first three, first five
finally nine textures. Additive Gaussian noise, different signal-to-noise ratio,
added (1024 1024) pixels image texture class form training
testing sets. 961 patterns obtained image using (64 64) windows
overlap 32 pixels.
3. weights classifier determined according classification accuracy class label
using training dataset
4. reader may refer Appendix brief description method

343

fiAl-Ani & Deriche

No. classes
2
3
5
9

SDH1
86.96
84.58
85.10
80.97

SDH2
85.73
84.52
84.62
77.44

SDH3
84.44
83.91
84.34
77.51

SDH4
85.45
86.24
83.46
75.72

En
91.14
89.72
88.84
83.65

Table 1: Texture classification accuracy five original classifiers different number
class labels

Four nine-feature vectors calculated using statistics sum difference histogram
(SDH) co-occurrence matrix different directions, vertical (SDH1 ), horizontal
(SDH2 ), two diagonals (SDH3 SDH4 ) . direction, features used
were: mean, variance, energy, correlation, entropy, contrast, homogeneity, cluster shade,
cluster prominence. fractal dimension (FD) also used form tenth
feature vector. energy contents texture images (En) used form
another feature vector using 9 different masks. tenth feature FD.
five feature vectors used input ANN. numbers
training testing patterns depend upon number classes considered, i.e. case
two classes, 15376 patterns used train networks 5766 test them.
results obtained shown Table 1. Note number classes increases
overall accuracy decreases. addition, performance En classifiers found
better four.
No. classes
2
3
5
9

WS
89.16
88.52
89.60
84.96

Av
89.04
88.39
89.41
84.55

Md
87.66
87.41
87.99
83.37

Mx
90.12
88.86
89.23
82.90

MV
88.09
87.30
87.83
83.23

FI
90.08
88.71
90.28
86.76

DS0
88.70
88.40
89.52
84.87

DS1
90.66
90.21
92.69
89.83

DS2
90.72
90.08
91.50
86.79

Table 2: Overall performance various combination methods different number
class labels (texture classification)

overall performance tested combination methods different number class
labels shown Table 2. case 2 classes, clear overall performances
DS1 DS2 better combination methods. mixtures
good bad classifiers considered, performance combination methods, except
DS1 DS2, closer worse best single classifier. shown
Table 3 combination {c1 , c3 , c4 , c5 }, {c1 , c4 , c5 }, {c1 , c5 }, etc5 . 3 5
classes considered, DS1 performs slightly better DS2, outperform
methods. gap DS1 methods gets wider 9 classes
considered. superiority DS1 reflects advantage using whole output vector
measuring evidences classifiers.
5. reader may refer Appendix B detailed results cases

344

fiA New Technique Combining Multiple Classifiers

Classifiers
c1 , c2
c1 , c5
c4 , c5
c1 , c2 , c3
c1 , c2 , c5
c1 , c4 , c5
c3 , c4 , c5
c1 , c2 , c3 , c4
c1 , c2 , c3 , c5
c1 , c2 , c4 , c5
c1 , c3 , c4 , c5
c2 , c3 , c4 , c5
c1 , c2 , c3 , c4 , c5

WS
92.56
91.16
85.07
91.21
91.03
89.80
85.38
89.94
89.70
89.72
88.57
86.07
88.81

Av
92.59
91.12
85.07
91.21
90.81
89.59
85.38
89.70
89.42
89.49
88.45
86.11
88.54

Md
92.59
91.12
85.07
88.92
88.68
86.21
85.47
87.84
87.53
87.37
86.30
85.87
86.63

Mx
92.51
91.09
85.22
91.62
91.48
91.21
85.40
91.47
91.42
91.48
91.09
86.25
91.33

MV
92.51
91.09
85.22
88.92
88.71
86.21
85.48
89.13
89.04
88.94
87.03
86.26
86.59

FI
92.61
91.00
85.07
91.69
91.48
91.24
85.33
91.59
91.29
91.40
90.98
86.13
91.21

DS0
92.40
91.33
85.15
90.81
90.43
88.88
85.22
89.13
88.92
89.00
87.81
85.93
88.10

DS1
92.46
91.62
85.10
92.40
92.47
91.68
85.43
92.21
92.32
92.25
91.78
86.66
92.21

DS2
92.46
91.61
85.12
92.53
92.39
91.78
85.40
92.33
92.42
92.26
91.87
86.80
92.33

Table 3: Classification accuracy texture images using different combination methods (2
textures)

best ERR values WS, FI, DS0, DS1 DS2 determined according Eq.
21. Since WS widely used literature, outperforms conventional
methods (Av, Md, Mx, MV), observed Table 2, use representative conventional methods performing comparison FI, DS0, DS1
DS2. Figure 3a shows ERR values 2 classes considered. clear
maximum ERR values five combination methods close, ranging
14% 16%. obtained combining best two classifiers WS, FI DS0,
DS1 DS2 use three classifiers obtain maximum ERR. mentioned
earlier, performance first four individual classifiers weaker
En. Notice that, DS1 DS2, significant degradation ERR
number combined classifiers increases.
case 3 classes, DS1 DS2 outperform combination methods
terms maximum ERR. achieve values 17.3% 19.6% respectively,
compared 11.4% less methods shown Figure 3b. addition, ERR
DS1 DS2 affected number combined classifiers increases.
case 5 classes, maximum ERR values sorted descending order are:
DS1 50.7%, DS2 40.2%, FI 31.6%, WS 28.1%, DS0 23.8%, shown Figure 3c.
addition, ERR values DS1 improve number combined classifiers increases, DS2
second best, ERR values methods degrade number combined
classifiers increases. case 9 classes, superiority DS1 becomes clearer,
shown Figure 3d, maximum ERR value DS1 54% compared 37.5% less
methods. worth mentioning even though maximum ERR values
methods degrade, still perform better best single classifier. leads
us conclude number classes increases, performance classifier
combination methods gets better overall.

345

fiAl-Ani & Deriche

20

30

10

20

0

10

10

0

20

10

(a) 2 classes

(b) 3 classes

20

WS
FI
DS0
DS1
DS2

ERR

30

50
50
40
40
30
30
20
20
10
10

(c) 5 classes
0

2

2.5

3

3.5

4

4.5

5

(d) 9 classes
2

2.5

3

3.5

4

4.5

5

No. combined classifiers

Figure 3: ERR different classifier combination methods obtained considering different
number classifiers cases: (a) 2 classes, (b) 3 classes, (c) 5 classes,
(d) 9 classes

Taking facts consideration, sort methods descending order
follows: DS1, DS2, FI, WS, DS0, conventional methods. Thus, summary,
problem texture classification, proposed technique two alternatives
(DS1 DS2) clearly outperforms standard combination methods increase
classification accuracy 2 7%. cases 2 3 classes, little
difference performance DS1 DS2. using reference vectors
small size, 2 1 3 1, make big impact upon estimation evidence
compared obtained using single reference value. size reference vector
increases, 5 1 9 1 two cases, impact estimating evidence
becomes clearer, leads better results, cost increasing computational
load.
5.2 Speech Segment Classification
Six different input feature sets used classify speech segments according
manner articulation, were: 13 mel-frequency cepstral coefficients (MFC), 16 log
mel-filter bank (MFB), 12 linear predictive cepstral coefficients (LPC), 12 linear predictive

346

fiA New Technique Combining Multiple Classifiers

No. classes
3
6
9

MFC
88.21
83.16
78.48

MFB
90.98
85.50
83.24

LPC
81.64
74.77
71.64

LPR
80.69
74.06
70.03

WVT
90.64
84.33
81.33

ARP
70.87
62.90
56.66

Table 4: Speech segment classification accuracy six original classifiers different
number class labels

reflection coefficients (LPR), 10 wavelet energy bands (WVT), 12 autoregressive model
parameters (ARP). experiment, speech obtained TIMIT database
(MIT, SRI, & TI, 1990). Segments 152 speakers (56456 segments) used train
ANNs, 52 speakers (19228 segments) test them. Three cases considered:
3 classes (vowel, consonant, silence), 6 classes (vowel, nasal, fricative, stop, glide,
silence), finally 9 classes (vowel, semi-vowel, nasal, fricative, stop, closure, lateral,
rhotic, silence). classification results three cases summarized Table
4.
No. classes
3
6
9

WS
90.80
85.54
83.05

Av
90.41
84.91
82.31

Md
90.20
84.62
81.93

Mx
86.15
81.16
75.63

MV
89.51
84.03
81.00

FI
90.65
85.29
82.73

DS0
90.90
85.18
82.86

DS1
91.57
87.18
85.20

DS2
91.31
86.37
84.22

Table 5: Overall performance various combination methods different number
class labels (speech segment classification)

two best individual classifiers MFB WVT three cases, followed
MFC methods. Unlike texture classifiers one good classifier four,
relatively, weak classifiers, three good classifiers (MFB, MFC WVT)
three weak classifiers (LPC, LPR ARP).
overall performance values various combination methods displayed
Table 5. case 3 classes, seen overall performance DS1
better DS2 outperform methods. becomes even
clearer number classes increases (with 2% increase accuracy).
ERR values case 3 classes shown Figure 4a. maximum ERR
value DS1 23.4%, achieved combining six classifiers, compared 20.3%
DS2 19.6% less methods. gap DS1
methods gets wider consider 6 9 classes shown Figures 4b 4c.
good classifiers experiment compared texture
experiment, variations ERR values number classifiers increases
found smaller. addition, see number classes increases DS1 keeps
steady superior performance terms ERR 10% increase.
summary, DS1 outperforms methods terms overall performance
ERR measurements. followed DS2, WS, rest methods.

347

fiAl-Ani & Deriche

25
25
20
20
15
15
10
10

(b) 6 classes

(a) 3 classes

5
2

3

4

5

6

2

3

4

5

6

25

ERR

20

WS
FI
DS0
DS1
DS2

15

10

(c) 9 classes

5
2

3

4

5

6

No. combined classifiers

Figure 4: ERR different classifier combination methods obtained considering different
number classifiers cases: (a) 3 classes, (b) 6 classes, (c) 9 classes

5.3 Speaker Identification
Three limited-scope experiments carried perform speaker identification using 2,
3, 4 speakers. Speech data TIMIT database also used (MIT et al., 1990).
number training patterns 3232, 4481 5931 respectively, number
testing patterns 1358, 1921 2542 respectively. features used classify
speech segments according manner articulation used identify speakers.
Classification results six classifiers shown Table 6. performance
individual classifiers quite similar speech segment problem, three
good classifiers are: MFB, MFC LPC three weak classifiers are: LPR, WVT
ARP.
overall performance various combination methods shown Table 7.
case 2 classes, clear overall performance combination methods
comparable. superiority DS1, lesser degree DS2, becomes clear
number classes increases (more patterns included estimate evidence).
Note that, high performance individual classifiers case 2
classes, small difference performance combination methods great impact
ERR, explains graphs fluctuations, shown Figure 5a. seen

348

fiA New Technique Combining Multiple Classifiers

No. classes
2
3
4

MFC
94.58
85.84
85.01

MFB
96.17
87.25
85.96

LPC
92.49
82.20
80.84

LPR
89.60
81.00
77.97

WVT
87.80
74.39
70.93

ARP
84.55
73.03
64.59

Table 6: Speaker identification accuracy six original classifiers different number
speakers
No. classes
2
3
4

WS
95.53
90.80
83.05

Av
95.50
90.41
82.31

Md
95.26
90.20
81.93

Mx
95.36
86.15
75.63

MV
95.21
89.51
81.00

FI
95.25
90.65
82.73

DS0
95.46
90.90
82.86

DS1
95.48
91.57
85.20

DS2
95.45
91.31
84.22

Table 7: Overall performance various combination methods different number
class labels (speaker identification)

maximum ERR overall performance combination methods close.
results favor DS1 DS2, additional computational
cost. Lets consider case 3 classes, Figure 5b shows maximum ERR
DS2 highest followed DS1, outperform methods.
case 4 classes, maximum ERR DS1 30%, compared 27% less
methods, shown Figure 5c. figure also shows ERR values DS2 WS
close. However, overall performance DS2 better WS, DS2
considered second best method followed WS, DS0 finally FI.
results clearly show performance DS1 DS2 get affected
number training patterns, crucial achieving good estimation evidence
classifier. clear case 2 speakers. performance, however, get
better number speakers training patterns increase. words, DS1
DS2 require larger number patterns work properly. Failing provide number
patterns, conventional methods, WS, achieve similar performance.
experiments textures, speech segments speaker classification show
proposed technique clearly outperforms methods terms overall performance
ERR, providing sufficient number patterns estimate evidence classifiers
exists. Also, among different combination methods, DS1 DS2 least effected
inclusion weak classifiers. experiments also show BBAs could
better estimated using reference vectors rather reference values, especially large
number classes.
worth mentioning one combination methods merit.
example, MV useful combination method dealing classifiers
produce results abstract level. working measurement level, combination methods could better performance.
Mx method provide good results performance combined classifiers close. case, classifier higher confidence provide better results
349

fiAl-Ani & Deriche

40
20
35
15
30
10
25
5
20
0

(a) 2 classes

(b) 3 classes

15

5
2

3

4

5

6

2

3

4

5

6

30

ERR

25

WS
FI
DS0
DS1
DS2

20
15
10

(c) 4 classes

5
2

3

4

5

6

No. combined classifiers

Figure 5: ERR different classifier combination methods obtained considering different
number classifiers cases: (a) 2 classes, (b) 3 classes, (c) 4 classes

individual classifier. shown Tables 11-13 (refer Appendix B),
good results achieved combining best two three classifiers speech
segment experiment compared best individual classifier. However, clear
difference performance classifiers, case considering mixtures good
bad classifiers, using Mx combine classification results good
choice. case dont information performance classifiers, i.e.,
training dataset, Av Md methods could provide attractive choice.
Similar findings (Kittler et al., 1998; Alkoot & Kittler, 1999), performance
two methods found close slight favor Av method. classification accuracy different classifiers available, WS method represents
good choice, outperforms Av almost conducted experiments.
expected, associating classifier weight reflects performance, would
make better classifier contributes towards final decision. performance
combined classifiers close, combining results using Av
WS methods would lead similar performance, shown Tables 11-13
cases combining best two three speech segment classifiers.
FI DS0 represent two non-linear combination methods. According (Cho &
Kim, 1995a), performance FI slightly better WS tested using
350

fiA New Technique Combining Multiple Classifiers

optical character recognition database, similar results obtained
texture experiments. However, speech segment classification speaker identification
experiments, performance FI good WS. hand,
experiments conducted show WS slightly outperforms DS0. Note Rogova
(1994) compared DS0 original classifiers. main problem FI
DS0 appropriate estimation parameters. example, desired sum
fuzzy densities affects combination results FI, choice proximity
measure reference vector plays important role performance DS0.
DS1 DS2 differ DS0 appropriate measure reference vectors,
hence accurate estimation evidence classifier. exploit
complementary information provided different classifiers. words,
accurate estimation evidence classifier lead minimizing MSE
combined results, hence resolving conflicts classifiers.

6. Conclusion
developed work new powerful classifier combination technique based
D-S theory evidence. technique, based adjusting evidence different
classifiers minimizing MSE training data, gave good results terms overall
performance error reduction rate. test algorithm, three experiments carried
out: texture classification, speech segments classification, speaker identification.
experiments showed superiority proposed technique compared
conventional methods, fuzzy integral, another D-S implementation uses different
measure evidence. shown accurate estimation evidence different
classifiers based whole output vectors (DS1) gives best performance, especially
higher number class labels. drawback algorithm training
computationally expensive (this used accurately estimate evidence
classifier). However, executed off-line, such, major effect
performance algorithm. also shown proposed algorithm easily
achieve increase classification accuracy order 2% 7% compared
combination methods. believe work enhancing technique,
scheme form new framework pattern classification future.

Acknowledgment
authors wish thank Dr. J. Chebil Dr. M. Mesbah valuable comments
paper. authors also acknowledge support Queensland University
Technology work presented paper. Dr. Deriche acknowledges support
King Fahd University, Saudi Arabia, currently leave.

Appendix A. Classifier Combination Based Fuzzy Integral
Fuzzy integral non-linear combination method defined respect fuzzy measure.
Detailed explanation classifier combination based g fuzzy measure found
work Cho & Kim (1995a, 1995b).

351

fiAl-Ani & Deriche

finite set elements, Z, g fuzzy measure (Sugeno, 1977) defined set
function g: 2Z [0, 1] satisfies following conditions:
1. g() = 0, g(Z) = 1,
2. g(A) g(B) B,
3. {Ai }
i=1 increasing sequence measurable sets, limi g(Ai ) = g(limi Ai ),
4. g(A B) = g(A) + g(B) + g(A)g(B)
A, B Z B = , > 1. Let h : Z [0, 1] fuzzy
subset Z. fuzzy integral Z function h respect fuzzy measure g
defined



h(z) g(.) = max min min h(z).g(E)
EZ

=

zE

max [min(, g(F ))],



[0,1]

F = {z|h(z) }
Let Z = {z1 , zn }, suppose h(z1 ) h(z2 ) h(zn ), (if not, Z rearranged
relation holds). fuzzy integral e, respect fuzzy measure g
Z computed
n

e = max[min(h(zi ), g(Ai ))],
i=1



Ai = {z1 , zi }
g(A1 ) = g({z1 }) = g 1
g(Ai ) = g + g(Ai1 ) + g g(Ai1 ), 1 < n
Q
given solving: + 1 = ni=1 (1 + g ), (1, ) 6= 0.
calculated solving (n 1)st degree polynomial finding unique root greater
1.
problem combining classifiers, Z represents set classifiers, object
consideration classification, hk (zi ) partial evaluation object
class k . Corresponding classifier zi , degree importance, g , reflects
good zi classification class k must given. densities induced
training dataset.

352

fiA New Technique Combining Multiple Classifiers

Appendix B. Tables Classification Accuracy Different Combination
Methods
Classifiers
c1 , c2
c1 , c5
c4 , c5
c1 , c2 , c3
c1 , c2 , c5
c1 , c4 , c5
c3 , c4 , c5
c1 , c2 , c3 , c4
c1 , c2 , c3 , c5
c1 , c2 , c4 , c5
c1 , c3 , c4 , c5
c2 , c3 , c4 , c5
c1 , c2 , c3 , c4 , c5

WS
90.89
89.69
85.05
89.92
89.55
89.05
85.76
89.29
89.07
88.87
88.60
86.45
88.54

Av
90.79
89.57
85.05
89.83
89.39
88.80
85.73
89.07
88.83
88.78
88.38
86.44
88.47

Md
90.79
89.57
85.05
88.04
87.54
86.95
85.49
87.98
87.24
87.34
87.05
86.18
87.06

Mx
90.83
89.68
84.67
90.48
90.23
89.62
84.81
90.17
90.01
90.02
89.39
85.52
89.73

MV
90.17
89.10
84.81
87.77
87.09
86.62
85.49
87.91
87.50
87.61
87.52
86.31
87.03

FI
90.22
88.99
85.13
89.88
89.56
89.26
85.67
89.85
89.58
89.64
89.44
86.36
89.65

DS0
90.81
89.92
85.51
89.59
89.18
88.80
85.91
88.82
88.81
88.66
88.39
86.46
88.29

DS1
91.09
90.45
85.49
91.26
91.12
90.77
87.27
91.44
91.48
91.16
91.31
88.37
91.50

DS2
90.81
90.29
85.44
91.73
91.10
90.73
86.88
91.51
91.53
91.26
91.00
87.20
91.61

Table 8: Classification accuracy texture images using different combination methods (3
textures)

Classifiers
c1 , c2
c1 , c5
c4 , c5
c1 , c2 , c3
c1 , c2 , c5
c1 , c4 , c5
c3 , c4 , c5
c1 , c2 , c3 , c4
c1 , c2 , c3 , c5
c1 , c2 , c4 , c5
c1 , c3 , c4 , c5
c2 , c3 , c5 , c6
c1 , c2 , c3 , c4 , c5

WS
91.98
91.95
85.14
91.49
90.77
90.61
86.29
90.26
90.14
89.73
90.32
86.41
89.65

Av
91.87
91.74
85.19
91.29
90.50
90.35
86.22
90.03
89.91
89.43
90.06
86.38
89.39

Md
91.87
91.74
85.19
88.78
87.92
87.67
85.40
88.37
88.17
87.62
87.91
85.99
87.27

Mx
90.28
90.72
84.77
90.39
90.34
90.29
85.99
90.12
90.25
90.19
90.50
85.98
90.11

MV
89.89
89.58
84.50
88.60
87.74
87.43
85.64
88.90
89.00
88.45
88.51
85.79
87.81

FI
92.21
91.30
84.94
92.35
91.54
91.41
85.91
91.86
91.83
91.11
91.83
86.15
91.22

DS0
91.45
91.55
85.82
91.08
90.32
90.25
86.98
89.93
90.09
89.41
90.20
87.21
89.51

DS1
93.40
93.27
86.28
94.37
93.66
93.69
89.16
94.48
94.41
93.82
94.50
89.47
94.46

DS2
92.81
92.72
85.36
93.19
92.96
92.90
87.29
93.19
93.26
92.56
93.33
86.97
93.01

Table 9: Classification accuracy texture images using different combination methods (5
textures)

353

fiAl-Ani & Deriche

Classifiers
c1 , c2
c1 , c5
c4 , c5
c1 , c2 , c3
c1 , c2 , c5
c1 , c4 , c5
c3 , c4 , c5
c1 , c2 , c3 , c4
c1 , c2 , c3 , c5
c1 , c2 , c4 , c5
c1 , c3 , c4 , c5
c2 , c3 , c4 , c5
c1 , c2 , c3 , c4 , c5

WS
88.45
86.39
79.55
87.10
86.48
85.92
80.27
86.42
85.70
85.79
85.42
81.60
85.33

Av
88.13
85.97
79.40
86.53
85.85
85.32
80.21
85.95
85.11
85.39
84.92
81.44
84.88

Md
88.13
85.97
79.40
84.20
83.66
83.22
79.63
84.56
83.37
84.29
83.06
81.15
83.19

Mx
85.44
82.27
78.74
84.65
84.08
82.97
79.54
84.33
83.91
83.83
83.47
80.75
83.74

MV
85.91
83.00
78.53
84.60
84.17
83.67
79.38
85.16
84.26
84.91
84.08
81.03
83.35

FI
89.78
88.18
79.37
89.51
88.72
88.25
79.97
89.18
88.52
88.52
88.34
81.54
88.02

DS0
89.26
87.10
79.28
87.06
86.92
85.98
79.80
85.96
85.41
85.94
84.81
81.02
84.83

DS1
91.42
90.07
81.22
92.00
92.13
92.01
82.48
92.45
92.02
92.48
92.35
84.70
92.43

DS2
89.20
88.08
79.91
88.59
88.53
88.30
80.89
88.70
88.30
88.66
88.35
82.17
88.65

Table 10: Classification accuracy texture images using different combination methods (9
textures)

Classifiers
c1 , c2
c1 , c6
c5 , c6
c1 , c2 , c3
c1 , c2 , c6
c1 , c5 , c6
c4 , c5 , c6
c1 , c2 , c3 , c4
c1 , c2 , c3 , c6
c1 , c2 , c5 , c6
c1 , c4 , c5 , c6
c3 , c4 , c5 , c6
c1 , c2 , c3 , c4 ,
c1 , c2 , c3 , c4 ,
c1 , c2 , c3 , c5 ,
c1 , c2 , c4 , c5 ,
c1 , c3 , c4 , c5 ,
c2 , c3 , c4 , c5 ,
c1 , c2 , c3 , c4 ,

c5
c6
c6
c6
c6
c6
c5 , c6

WS
92.34
89.99
81.09
92.63
92.17
89.85
84.98
92.59
92.62
92.25
90.15
88.79
92.75
92.57
92.73
92.14
91.41
91.51
92.62

Av
92.34
88.11
80.65
92.61
91.79
88.79
84.96
92.57
92.47
91.93
89.51
88.42
92.64
92.48
92.50
91.70
91.04
90.98
92.36

Md
92.34
88.11
80.65
92.37
91.83
88.20
84.76
92.42
92.50
91.82
89.34
88.30
92.23
92.30
92.20
91.07
90.63
90.52
92.24

Mx
92.34
83.95
76.19
92.34
85.97
84.17
79.36
91.64
86.94
86.01
84.64
83.25
91.42
86.96
86.93
86.19
85.79
85.73
86.95

MV
92.22
82.64
76.10
92.27
91.60
87.50
84.08
92.04
92.02
91.96
89.84
88.46
92.13
91.92
91.91
90.97
90.41
90.60
91.97

FI
91.84
91.06
82.03
92.36
92.03
89.66
84.89
92.38
92.49
92.14
89.48
88.46
92.49
92.25
92.53
91.71
90.98
91.15
92.38

DS0
92.38
90.92
81.54
92.63
92.27
90.34
84.62
92.61
92.73
92.37
90.12
88.76
92.74
92.56
92.76
92.23
91.46
91.50
92.61

DS1
92.45
91.48
82.29
92.79
92.53
91.92
85.65
92.77
92.78
92.77
91.92
90.51
93.07
92.77
93.03
92.78
92.48
92.67
93.09

Table 11: Classification accuracy speech segments using different combination methods
(3 classes)

354

DS2
92.29
91.42
82.01
92.67
92.23
91.79
85.36
92.64
92.54
92.49
91.84
89.94
92.81
92.56
92.72
92.46
92.14
92.40
92.64

fiA New Technique Combining Multiple Classifiers

Classifiers
c1 , c2
c1 , c6
c5 , c6
c1 , c2 , c3
c1 , c2 , c6
c1 , c5 , c6
c4 , c5 , c6
c1 , c2 , c3 , c4
c1 , c2 , c3 , c6
c1 , c2 , c5 , c6
c1 , c4 , c5 , c6
c3 , c4 , c5 , c6
c1 , c2 , c3 , c4 ,
c1 , c2 , c3 , c4 ,
c1 , c2 , c3 , c5 ,
c1 , c2 , c4 , c5 ,
c1 , c3 , c4 , c5 ,
c2 , c3 , c4 , c5 ,
c1 , c2 , c3 , c4 ,

c5
c6
c6
c6
c6
c6
c5 , c6

WS
86.97
84.30
74.60
88.09
86.48
84.33
79.27
88.03
87.64
86.51
84.61
83.84
87.90
87.57
87.69
86.71
86.36
86.70
87.67

Av
86.95
81.98
73.91
88.08
85.76
82.80
78.73
87.91
87.17
85.84
83.64
83.12
87.87
87.24
87.17
86.00
85.85
85.95
87.33

Md
86.95
81.98
73.91
87.77
86.01
81.88
77.84
87.81
87.26
85.90
83.28
82.84
87.44
86.98
86.91
85.54
85.26
85.18
87.02

Mx
86.46
77.97
70.38
87.11
80.38
78.64
74.07
86.58
82.59
80.54
79.47
79.28
86.01
82.76
82.64
81.21
81.50
81.63
82.76

MV
86.30
76.66
70.20
87.76
85.31
81.24
77.26
87.29
86.95
86.10
83.85
83.05
87.35
86.85
86.96
85.63
85.57
85.23
86.95

FI
86.67
85.01
75.00
87.51
86.49
83.88
78.46
87.67
87.37
86.69
83.97
83.22
87.72
87.36
87.52
86.46
86.10
86.06
87.35

DS0
86.64
84.52
74.20
87.49
86.45
84.56
78.51
87.48
87.25
86.59
84.29
83.56
87.34
87.08
87.32
86.39
85.95
85.81
86.98

DS1
88.12
86.71
76.47
88.73
88.19
87.16
80.17
88.98
88.61
88.47
87.38
86.00
89.15
88.95
88.93
88.64
88.26
88.37
89.14

Table 12: Classification accuracy speech segments using different combination methods
(6 classes)

355

DS2
87.59
86.39
75.68
88.10
87.50
86.45
79.39
88.09
88.08
87.57
86.68
84.95
88.15
88.11
88.12
87.56
87.38
87.28
88.01

fiAl-Ani & Deriche

Classifiers
c1 , c2
c1 , c6
c5 , c6
c1 , c2 , c3
c1 , c2 , c6
c1 , c5 , c6
c4 , c5 , c6
c1 , c2 , c3 , c4
c1 , c2 , c3 , c6
c1 , c2 , c5 , c6
c1 , c4 , c5 , c6
c3 , c4 , c5 , c6
c1 , c2 , c3 , c4 ,
c1 , c2 , c3 , c4 ,
c1 , c2 , c3 , c5 ,
c1 , c2 , c4 , c5 ,
c1 , c3 , c4 , c5 ,
c2 , c3 , c4 , c5 ,
c1 , c2 , c3 , c4 ,

c5
c6
c6
c6
c6
c6
c5 , c6

WS
84.58
81.85
70.48
85.41
84.20
82.18
75.94
85.44
85.34
84.48
82.41
81.02
85.52
85.53
85.54
84.60
83.97
84.14
85.32

Av
84.61
78.59
69.04
85.42
83.44
80.26
75.23
85.30
84.97
83.77
81.44
80.51
85.43
85.01
85.16
84.03
83.32
83.48
84.93

Md
84.61
78.59
69.04
85.00
83.53
79.19
74.43
85.20
84.99
83.77
81.03
80.15
84.94
84.41
84.76
83.34
82.74
82.32
84.70

Mx
83.77
71.48
62.87
83.81
74.18
72.32
67.23
83.41
76.49
74.61
73.61
72.74
82.93
77.04
76.62
75.51
75.80
75.40
77.08

MV
83.66
70.50
62.65
85.02
82.70
77.86
73.46
84.96
84.82
83.98
81.49
79.83
84.77
84.53
84.66
83.69
83.16
82.66
84.51

FI
84.06
82.53
71.22
85.00
84.11
81.20
75.30
85.11
85.19
84.58
81.61
80.06
85.45
84.96
85.38
84.17
83.67
83.29
85.07

DS0
84.15
82.51
69.97
85.34
84.01
82.53
75.54
85.15
85.14
84.53
82.44
80.41
85.42
85.00
85.25
84.42
83.91
83.44
85.19

DS1
86.11
84.41
73.24
86.85
86.05
85.10
78.21
87.05
86.79
86.67
85.65
83.86
87.32
87.09
87.11
86.82
86.59
86.55
87.26

Table 13: Classification accuracy speech segments using different combination methods
(9 classes)

356

DS2
85.60
83.72
71.94
86.15
85.44
84.56
76.92
86.13
86.16
85.86
84.76
82.25
86.32
86.09
86.22
85.78
85.45
85.56
85.23

fiA New Technique Combining Multiple Classifiers

Classifiers
c1 , c2
c1 , c6
c5 , c6
c1 , c2 , c3
c1 , c2 , c6
c1 , c5 , c6
c4 , c5 , c6
c1 , c2 , c3 , c4
c1 , c2 , c3 , c6
c1 , c2 , c5 , c6
c1 , c4 , c5 , c6
c3 , c4 , c5 , c6
c1 , c2 , c3 , c4 ,
c1 , c2 , c3 , c4 ,
c1 , c2 , c3 , c5 ,
c1 , c2 , c4 , c5 ,
c1 , c3 , c4 , c5 ,
c2 , c3 , c4 , c5 ,
c1 , c2 , c3 , c4 ,

c5
c6
c6
c6
c6
c6
c5 , c6

WS
96.10
95.38
90.25
96.68
95.81
94.66
92.20
96.90
97.04
95.88
95.88
95.02
96.82
96.10
96.53
95.74
96.39
95.16
96.53

Av
96.10
94.95
90.69
96.68
95.74
94.73
92.13
96.90
96.82
95.88
95.81
94.95
96.75
96.10
96.46
95.67
96.32
95.23
96.61

Md
96.10
94.95
90.69
96.90
95.23
94.37
91.77
96.97
96.97
95.74
95.52
94.30
96.25
95.45
96.17
95.38
95.60
95.02
96.53

Mx
96.10
94.95
90.83
96.97
95.38
95.09
92.64
96.68
96.10
95.16
95.52
94.01
96.53
96.32
95.88
95.60
96.39
95.45
96.17

MV
96.10
94.95
90.83
96.90
95.23
94.51
91.70
96.61
96.53
95.96
95.45
94.30
96.25
95.45
96.10
95.31
95.52
94.95
96.25

FI
95.16
96.25
87.51
96.61
96.17
94.95
91.48
96.61
96.97
96.17
94.95
94.30
96.82
96.25
96.75
95.81
95.96
95.16
95.96

DS0
96.02
95.36
89.32
96.98
95.73
94.62
91.75
97.05
96.91
95.95
95.95
95.14
96.69
96.02
96.47
95.88
96.24
95.14
96.54

DS1
95.51
96.17
88.59
96.91
95.51
96.24
91.16
96.69
96.76
95.80
95.88
94.55
96.76
96.24
96.76
96.02
96.39
95.58
96.54

Table 14: Speaker identification accuracy using different combination methods (2 speakers)

357

DS2
95.80
96.17
88.66
96.54
95.88
96.17
91.16
96.69
96.69
95.80
96.24
94.40
96.61
96.10
96.54
95.95
96.24
95.58
96.39

fiAl-Ani & Deriche

Classifiers
c1 , c2
c1 , c6
c5 , c6
c1 , c2 , c3
c1 , c2 , c6
c1 , c5 , c6
c4 , c5 , c6
c1 , c2 , c3 , c4
c1 , c2 , c3 , c6
c1 , c2 , c5 , c6
c1 , c4 , c5 , c6
c3 , c4 , c5 , c6
c1 , c2 , c3 , c4 ,
c1 , c2 , c3 , c4 ,
c1 , c2 , c3 , c5 ,
c1 , c2 , c4 , c5 ,
c1 , c3 , c4 , c5 ,
c2 , c3 , c4 , c5 ,
c1 , c2 , c3 , c4 ,

c5
c6
c6
c6
c6
c6
c5 , c6

WS
89.22
88.91
80.37
90.53
90.37
88.70
84.54
91.10
91.25
90.63
90.37
86.88
91.20
91.36
90.99
91.41
91.05
90.37
91.51

Av
89.17
88.55
80.90
90.47
90.58
88.60
84.17
91.10
91.51
90.47
90.32
86.78
91.20
91.31
91.15
91.67
90.99
90.27
91.36

Md
89.17
88.55
80.90
90.32
89.90
87.35
83.60
90.58
91.36
90.47
89.48
85.94
90.58
91.25
90.58
90.99
89.69
89.22
91.78

Mx
88.70
87.61
79.44
89.28
88.65
87.25
83.24
89.59
88.70
88.81
87.87
84.64
89.59
88.96
88.81
88.86
88.34
88.24
88.91

MV
88.91
85.58
77.93
90.06
90.06
86.93
83.34
90.32
90.06
88.39
88.55
84.54
89.59
90.32
90.06
90.47
89.59
88.81
90.89

FI
87.82
89.38
75.90
89.80
89.43
88.29
83.08
90.94
90.89
90.16
89.54
85.79
90.84
90.89
90.73
90.89
89.85
88.96
91.46

DS0
89.22
88.86
79.44
90.47
90.58
88.96
83.86
91.31
91.62
90.58
90.47
86.15
91.72
91.36
91.20
91.46
91.04
89.38
91.46

DS1
89.33
89.90
80.37
90.58
90.32
90.11
84.64
91.78
91.62
90.94
91.57
87.40
91.93
91.93
91.62
91.83
91.83
90.42
91.93

Table 15: Speaker identification accuracy using different combination methods (3 speakers)

358

DS2
89.17
89.95
79.85
91.20
90.21
90.58
85.06
91.51
92.04
90.21
91.46
87.35
91.78
92.40
91.88
92.09
91.41
90.32
91.98

fiA New Technique Combining Multiple Classifiers

Classifiers
c1 , c2
c1 , c6
c5 , c6
c1 , c2 , c3
c1 , c2 , c6
c1 , c5 , c6
c4 , c5 , c6
c1 , c2 , c3 , c4
c1 , c2 , c3 , c6
c1 , c2 , c5 , c6
c1 , c4 , c5 , c6
c3 , c4 , c5 , c6
c1 , c2 , c3 , c4 ,
c1 , c2 , c3 , c4 ,
c1 , c2 , c3 , c5 ,
c1 , c2 , c4 , c5 ,
c1 , c3 , c4 , c5 ,
c2 , c3 , c4 , c5 ,
c1 , c2 , c3 , c4 ,

c5
c6
c6
c6
c6
c6
c5 , c6

WS
87.45
84.78
74.00
89.18
87.96
85.60
80.84
89.77
89.26
87.84
87.06
84.74
89.61
89.77
89.26
89.10
88.00
88.99
89.42

Av
87.53
83.79
74.47
89.18
88.08
85.41
80.68
89.85
89.22
87.33
86.74
84.38
89.61
89.73
89.14
89.06
87.88
88.87
89.26

Md
87.53
83.79
74.47
88.24
87.53
83.32
79.58
89.65
88.71
86.90
86.23
84.30
89.02
88.83
88.36
88.20
86.98
87.21
88.91

Mx
87.29
83.40
72.03
88.16
86.35
83.52
77.18
88.04
87.29
86.35
83.99
80.72
88.00
87.45
87.29
86.74
85.21
85.80
87.37

MV
86.98
81.55
71.28
87.92
87.33
83.12
78.76
88.59
88.20
87.10
85.44
83.01
88.47
88.87
88.04
88.36
87.45
87.06
88.24

FI
86.55
85.48
69.83
88.32
87.25
84.66
80.29
89.65
88.75
87.37
86.82
84.07
89.18
89.06
88.55
88.36
87.92
88.00
89.22

DS0
87.69
83.87
71.99
89.10
87.65
84.62
78.80
89.61
88.91
87.65
86.66
83.83
89.61
89.61
89.18
88.95
87.88
87.92
89.54

DS1
87.73
85.37
73.29
89.38
88.08
86.15
81.51
90.17
89.50
88.32
88.16
85.68
90.01
89.93
89.73
89.65
89.38
89.26
89.89

Table 16: Speaker identification accuracy using different combination methods (4 speakers)

359

DS2
87.41
84.78
73.13
88.87
87.41
85.13
80.68
89.61
88.71
87.69
87.14
84.66
89.73
89.50
88.59
88.95
89.02
88.75
89.73

fiAl-Ani & Deriche

References
Aha, D. (1995). Machine learning. Tutorial presented 1995 Artificial Intelligence
Statistics Workshop.
Alkoot, F., & Kittler, J. (1999). Experimental evaluation expert fusion strategies. Pattern
Recognition Letters, 20, 13611369.
Chen, K., & Chi, H. (1998). method combining multiple classifiers soft competition different feature sets. Neurocomputing, 20, 227252.
Cho, S., & Kim, J. (1995a). Combining multiple neural networks fuzzy integral robust
classification. IEEE Transactions Systems, Man Cybernetics, 25, 380384.
Cho, S., & Kim, J. (1995b). Multiple networks fusion using fuzzy logic. IEEE Transactions
Neural Networks, 6, 497501.
Denoeux, T. (2000). neural network classifier based DempsterShafer theory. IEEE
Transactions Systems, Man Cybernetics, 30, 131150.
Dietterich, T. (1999). experimental comparison three methods constructing ensembles decision trees: Bagging boosting randomization. Machine Learning,
40, 139158.
Hansen, L., & Salamon, P. (1990). Neural network ensembles. IEEE Transactions
Pattern Analysis Machine Intelligence, 12, 9931001.
Hashem, S., & Schmeiser, B. (1995). Improving model accuracy using optimal linear combinations trained neural networks. IEEE Transactions Neural Networks, 6,
792794.
Ho, T., Hull, J., & Srihari, S. (1994). Decision combination multiple classifier system.
IEEE Transactions Pattern Analysis Machine Intelligence, 16, 6675.
Kittler, J., Hatef, M., Duin, R., & Matas, J. (1998). combining classifiers. IEEE
Transactions Pattern Analysis Machine Intelligence, 20, 226239.
Kohlas, J., & Monney, P. (1995). mathematical theory hints. approach
Dempster-Shafer theory evidence. Berlin: SpringerVerlag.
Lam, L., & Suen, C. (1995). Optimal combinations pattern classifiers. Pattern Recognition
Letters, 16, 945954.
Liu, W., & Bundy, A. (1992). combination different pieces evidence using incidence
calculus. Tech. rep. RP 599, Dept. Artificial Intelligence, Univ. Edinburgh.
Mandler, E., & Schurmann, J. (1988). Combining classification results independent
classifiers based dempstershafer theory evidence. Gelsema, E., & Kanal,
L. (Eds.), Pattern recognition artificial intelligence, pp. 381393. North-Holland.
MIT, SRI, & TI (1990). DARPA TIMIT acoustic-phonetic continuous speech corpus..
http://www.ldc.upenn.edu/doc/TIMIT.html.
Rogova, G. (1994). Combining results several neural network classifiers. Neural
Networks, 7, 777781.
Shafer, G. (1976). mathematical theory evidence. Princeton University Press.
360

fiA New Technique Combining Multiple Classifiers

Smets, P. (1990). combination evidence transferable belief model. IEEE
Transactions Pattern Analysis Machine Intelligence, 12, 447458.
Smets, P. (1998). transferable belief model quantified belief representation.
Gabbay, D., & Smets, P. (Eds.), Handbook defeasible reasoning uncertainty,
pp. 267301. Kluwer.
Smets, P. (2000). Data fusion transferable belief model. 3rd Intl. Conf. Information
Fusion, pp. 2133.
Sugeno, M. (1977). Fuzzy measures fuzzy integrals: survey. Gupta, M., Saridis, G.,
& Gaines, B. (Eds.), Fuzzy automata decision processes, pp. 89102. Amsterdam:
North-Holland.
USC (1981). USC-SIPI image database.. http://sipi.usc.edu/services/database/.
Xu, L., Krzyzak, A., & Suen, C. (1992). Methods combining multiple classifiers
applications handwriting recognition. IEEE Transactions Systems, Man
Cybernetics, 22, 418435.

361

fi ff
fiff ff


!ff#"%$'&)(+*,,*-/.,0$213.*&

45678 9;:<ff,*0=?>6
"9%$!*<ff,*

@BADCFE)GHIJLKNMONE)OQPRKNSDT%GVUWKNCYXLMZ[8U]\WE)G_^F`


EbHVcDUdONUWeU%Tf^hgfiDOkjlCNCNe5M[8gmHVMUWi

npoqr/q/sutvq/wyx)z{or/z{o
]25m]' 0fi
8 5 0
ff
5 '0]_'

|/}~~/ ~/]{}/}/W} }

qqmqoq


{

~/|~ ~}~W 5


ymV{
b+8?{5)'0!5ff)?N?'ffd'{5!!#+0D!'D+' 5'bf? N'5
?';!'+' 5'W'0'5'm ' R?!'d0'' ' 5fi+{5!3'0fi
5'+'+{0?!0?ffff? ' 'D_! v 5?ff?'' 50 ' ?)' D?
+ffd+?? fi50 ff? Vb]?'5 {!ff?b'5?'m'{!0!'d+' 5'
'0'%?''R'0' ?]ff '+'+5? v! {5?%'{5!' 0f?]!5 0'0!'f?
!'Ffi+!? 0 ' ff '+'+5? F! {5?'{5!' 0?'!0'N5'+ffF'd0''
' 8?_ 0D!'5 ;'fi+!? 0 ' D! 8!'R'{5!' 0b R';3'
?+'' ' 8?_'ffi%{5ff8?V? 08 D'%!'5b%?'ffR+8 'ff '0
fi''0! ffbff? 03)W0+5?' 5?_0?' '0' R?_ ' 58'+!d'5
VN 8]]{
f3/fi_ D??v ff
fi W3 %5 _ff
$ 3%#& f#3%

_ '& (F#3)mFfiF* ?+ff

$ 3%#/)%fiD+%3+ #&.

!"#ff

-,-


/+* ?+0#,1 1#,fiD23fiD%$#
?_ff;+<

_ '= f* ?+"68>7'
? +ff-,A@ffBBC5DFE_ffG,H@ffBBI*,KJ%LL@9M14NO P

Q* 5# #B
3d3
!

N!R# $SRR?T ]U_ WVX
ff

&3
1;{
_ff Z #,

*R=ffm/fi5
N!5#[ ff##<f
]\5
3 #'<
ff ff
53+ ;_
?
?fiM5
#5#
4,M/!)ffff##
5#

$
5%

U N

(m
?#
* !,* ^! ff #S
+%3+ ##Z *)_
?F
ff ff ffv

/!{
, F
ff_


]
3
3 #?[ % #

N!R-1`_T RV'
#
37 ( F
$
ff\5
3 #'<N

?
v3d
ff
ffG
1 f
$ffS
N!R#N
F_
ff
fi 3 ff;+P ^N

ff
ff
-! ff R
S? 5#/

/%ff*)

/A%
# p#
v53+b] : Wfi
! c

fip
?fi^3?]6XdAeTf79M1 $
fd/fi_ ^


#?[ % # 3%^ :#%
!1(_T#
5#

( :
W

`! ff #y
ff ff #-,
%5 fi; /


ffff* ^ g R
U _ WVX
ffy

=3
=N

! R#
, fi
?
5#_
ffp={
ff #`J51){
ff #=D
h ?ff* !gP

fi
?fi^3?53+b"

`! ff #
ff
4,(
<3 ff /% ff*v
53+bi

/!,) ?p+ % 3+ 25 fi5 5#?[ % #-,T
3
3 #?[ jV
#-,kN

ff )
* ! % #
!fi
% #-
, !F
33!
#`Q N
U _ !0


ff34
/+/5m+%3+ 7683+5# #:925fi5 53+ ;%#

lnmokp qnrMsXt uXvjw(xyZrMsRxGzj{jqMsXrnzj|F}~OuX~WOuXt rnFM%}xG~Wp ~WOuXt rnFv%+~{~W~WKt w(|jp ~Ww(~W!uX~+}kt uXvj~rnp j~Ku'kTt jt jqff~OsX~Os
MwH{~OsXqn~OsFff wHzjn5Mnffl'R|jzj{jp Wp P+nMt p M{jp ~(uK!n 8M5Gn !7vjt 'v+MP{~HuX~Wx8uX~+}7t }rnw)Mt jx
uXv;zj|PuXr7nM2~OjMw(|jp ~WxWm^ow(rMsX~(xGrn|jvjt x8uXt +uX~+}t w(|jp ~Ww(~W!u'uXt rnrMy$uXvj~)Mp qnrMsXt uXvjw(xFt xgjrMug+nMt p M{jp ~(yZrMs
|jzj{jp zjxG~nm


*,,* 9 ' fff9A;ffHVff0 7)ffg{6
"'

"/9j

fi~}~

~/]{}/}



v3 R?!1<Y{ff#
?R RV' #37 (F$ff
\5
3 #'`N

?
:
&3 !yU_ 5
Nff*
N/fi53+`%#y
ff ff
ff`
+WVX/
ff`\5
3 #'N

?
1 b
#,{
ff # R
?)3
b H+S dff3 % ff4H
b1




b )
B!fi

fiff

]]{



/{


f3mff
#4? 5#_
?F 2'HS

v
+ /H k
5V


3

R ?!)nV
#DNffff# * ?+/!1f?A'Hd+ /!,mffA%A?5#

#F
R ?fN

#
U _ f
*#
ffN

ff*!1

!#"$&% z $ (q '*),+-/.1032)z{o5476 t98;:z{=<38xr/o>+?82 @n :A' +{z{o5B

DC

f;+b& mU_ WVXffy<3 ?ff=32Hb& _ 53#*#3


33 +b4ffp`Y{ff#@dp$ff5Q68>7'? +ff-,@ffBBC5DE_ffG,
@ffBBI9M1FNW
+ ?;
W
;

N

?
:
)+

% ff

D?fiM5 Nff ff #-,
c
7

3A+
k
U _ f
p
_ :


/
U # p _ff #
R?fiM5 38
;


5
= 7

W
+ #
!1 W
_ v
ff\5
ff ,^ &ff 3# 7%
5

/S%
)_

ff ff
ff3+/ :
2
V
+ #v
3) ! :A+S
U _ !]
1 f2 +b

33

#
5#
3+
ff
% H (! ff #//
?? 5#/
f
$ ff* 3#7





/!,j%
5
fi^5
fi5 5# [ ff]5; f _ ' %F !N
fi^
ffg :
H

*; fi
!H!3 g ?T6 /% ff*
%#
fiB
?fi3?8
, <
U N

"


ff Q 37H
b
9
ffP :
G,-
P
/
+c O,kRVX fi !P!3 7 ?"#6 ?# *y
ff n9MN
1 fi
!P!3 c ?!ff *+
N

fi7 ff
A%
cRVX fi
!^!3 ) ?%
ff#F
!ffF*+



fi7 ff
n1
fN/fi
!3 fi
U _ WVX
ff

Q3
& +
b ?ff& 3cH

b N

?
&3 %$ 5% # P
U _ v
<%
#
+v
_?% ff#
B



3
p
# 5#
%
# p/
kR
?(? 5#/
R
$
3 % #v


/A%
5 -

9EGF5HIHKJMLON

QP

OC

SR

TNULGFVWHKJ>EGXUNUXAYVGE
Z7[M\ E*VHKJ>EGXUNUXAYVGE

S^" ff*#"3fi7 5%,

]
]

ffR

S^" ff*#43fiPM

ffN$##P/3)+;fiMTfi!c!3T ; 5%`6#ffNF

>_ #3$##5%#59

$##

S^" ff*#"# 5c :^!ff]
/+) 7fi!%$ 3%#-,
] 8Zj U_ !0SR ff#g
N?? ! %/3#'k 5+%/3#',
N 3 #'
]

fi

#%/3#'1

NW ?5 # 5% #-,A ` +b 2

3
#
5# h

3S+
?+"
`

/R$ff*3#4
+#!1cY{ff#&J51 J?5#_?%Fff53+d?fiM5#5#
YRf,
%5 _
=
ff +
+ M"

* ?S %F
fi=


)%
# ?_ff"+
U _
ff ff
ffiff
53 #?[ % # /fi5N

! ff1


* p ff ? i_



3 fiff,
$ y=

2 g ?c 5% F&Nff ff ff< ?%
?!,- 2Y
#
5#
? 5#_
ff
ff #PJ51 h( 7_
{
F
ff2+%
ff ff
f

5
P_
- R3+ _
?$ %
fiF _ ff7+) 8
U _
$
ff* 3#

%
+ #
!1 _T#
% #
ff#
,

3
_
N

ffN

ff* ff
%# `.
?#
* ff-0 5
# 5#
f <Y
, 3T = 3 !#p
fffi 3 % ;
f %

"{
S6
P_

YR
%,-J%LL@9M,-%
5 3
ff
5% ?c
`+" P_
?+W


/f
!
p
# 5% #-1



`

c

edgf

ba

h*i>j

MC

fi }


fiff

|/|

! $&% z 3< 8xr/o>+?82 @n :A' +{z{o5Br+/oM: 4 %



/}





30 {}

w



f(
$ %S3 N#5#
YRf,3ffN b#7@%,3K+?fiM5] :)M?
%2
jU
#[
, % $#&%lfiM$##?!,'$% fiP #3$##?!,)(3%
.- /+
/0 "! n14W
e #
Q\5
3 #' ?7
;

*& fi!!3dU
N ?dB3#
* ,+
5
P_
H kRVX fi !;

U N

?!8
1 f25
P_
g + 5% ff4RVX fi
!(!3 ?!
, ff3 % #
T+
75
P_
( ff`fi !^!3 ) ?!/
, 3(!


ff5F
/fi5N

! 1( 1
^#2
(<36 (4@9M,

ffvM ?A%
V
ff R#
p_ff Z #'<68## 3 3 fiM
5% j
9 P
5S8
!
p

RVX fi
!!3
U N

]3k

]ff3 % #
ff#2
/.
U _ff
#
0#6
1 527 g 8-,5d
ff ff
p#
7(3fi
336 (98 @!L :




n9M,
/
;
ff
5b
?T%
k_

ff
5% ff-,
5
3 +SRVX
fi !T!3 f
+ ?!1

V !VOL [M\ X *[NUX#J HK[ML [ V7N VOL



:;3<=?>@.ACBDFEHGJI"EHKLM<?>=KNfiGO@3PCQ=/RS>,T
UWV NMKAIYX[Zfi\^]O_a`3X 'ff? !0b X b'ff? !]! 5
\ {! ' ` ff?')+'dc ? 05 _ 5 ' ` ff?'8+'dc? 0dc
e !)?_? 030 ''0 ` !'' ' ? 0dc?fghe

ij > j DkSACS>/Il` 55ff? 0 ' d?ff?'50 inm oqp l ? ) ? c
rOsut vxwyyz,{,| ` ?/!{!838' 55ff?,c
}~, r s| ` ?fi%{58?' 0b h ~, r ? _~ ~, r c
KAxNMKAI)ZC { l~ | f v,vqz,tHn ` !)?' 03'0R? }~, r s| {0] ' qz,tH c
` c =?> ? ' 0b h ~, r ? _~ ~, r ` Z ' }~, r s| c6 =

'+? 5 ' D?!8?';' ;'{5 qz,tH ` c
'+? 5;' f? nW ` c
` j c B@3;3S '5'?'; ' 55ff h ~, r =
`3 c
=?> ? ' 0b h ~, r ` Z ' }~, r s| c6 =
`. c
=?> ? fge9 =
`h c
3' W ' ;fid3' ' N8 ' R?'
' R3' ~, r ?30 ''1f qz,tH ` c qz,tH ` cHOf
`3 c
';'f? d?_W ' 6W Z

`u c
@ " rOsut vxwyyz,{,| jnV @ Wf+b+?'5'?HN ?fiW ` c _~ ~, r
jnV @ B
' ' ;+8'5 5 ? =
`3 c
'5+m' ffb' _~ ~, r 'R' ' f?
'5ff5'' 0b _~ ~, r 'D'0!{0b''5 )?
`3 c
V9 =?> 30 ''0
` Go c
V^ =?> ' 03' ~, r
` oo c
~, r _~ ~, r
` Oo j c V^ B@3;3S

b#S@%ge%ff53+T_?
?fiM5Mc+M##5#



:%43 1

( ff % ?2 NU _ 2+3 N <3
&#&%&'$%
6 #+ff]S3V!jU3n9K ffF+P_^

#[ ff-,h#&% 6 #+ff]S
V!jU3n92 ffc+3_S
jU
#[ ff-1Nf#&%&'$% /3
3fi2+3 57d 6 fff?# h5WV
5%d;fi5 53+

9 / "u6 )
+
ffA
!+!,kJ%LL@9M;
1 fPN

/fi53+ 57du
#&%&'$% /WS1(ff 53+ ;
fiW
#5 [ ffS!
"{
ff #
HJ51 {
, ?_ff #
ff#1
fi4/fi;

'$%

/,/%5

`





h*i

U`



Q`

fi~}~

~/]{}/}




ff
fififi

fififi
#%$ & '(' ) # *
-, #%. /

_T#5#
YRf %b?v# /`
N !35B!
i` ?%! ),
% ?%
?
fi2# $##H+Mff"
L%+5# Tfi?A?5#/7
UN

?R S1 /3!&68 %!5 :9R%+5# ?!, ?%?Dff"" :M


c

, :)5
N 5 _%+5# ?A!vff7c :M

8


1 k" :

3 # [ P ?%
;
+ #-,$ !Tfi
?
6 9 @
9)ff

_ ff*Tfi

?Tm
%+ 5#
%

fi_?fi` D$
# #
R
U N

?
6 k
@
9(
_ ff*^fi

?)
fi_?fi5
4 ;
!
% #
R
U N

?!1^_ !^ F ?%
?
3)
+ ff) :#%
!


fi

fififi

fififi"!
+) # * DC
'(' ) #%0 ") #%0 DC


"
#
1
#

, #%. fi7ff 5%ff-1
] T3!d%+5# ?2
# , ?%?) c :M
3
# #%$
# 4
] )*5m%+5# ?
# ,
3fig+ ff5]N'56W@ffBBJ9M, ?%?H :M



#
4 6 #%$65 , %# . 9%Jfi;?%ff= :Wk?#*$5/fi/5P6 #%$87 , #%. 9M,_` ?%?

# 8 6 #%$ 5 , #%. 9%J; :W-?#*$5R/576, #%.97#%$ 9M1
] N*! ;fiff %+5# ?:
# ,K ?%?Rfi"ff 5%ff R# 2
# ]$3!
*5!,%?# ?%? P :4DC_ ff*" :M
!
# 4
6 #%$+5 , #%. 9%J5,

# 8 6 #%$ 5 , #%. 9%J5,;
# #%$ ,/<
# 4
, #%. 1
(N/fi5
N! ff,R ;52

f 3H!! $_ gfi^ :A2 +Vff

fi N+,

?+ff_ P3
#QRU ff"5
P_ (5U
N ?!1

<Y{ NfipF5_!'m ffLR1@p @!LLR,g :
ff%LU
N ?!1]f75P (v_d>R+ff$4+]
#[ c 7%!%4+Sd$#" b$##U
N ?f!!1
_T#5#
YRf7'Hy##b/fi5
N! 5P%5Bfi]'{/ #<R>R+ff<5<
(Qfi?R4f%

?+ff

#/%!) 3+"J

=<?> @ACBCB;DEfi

"F E

ff1Ff//5+d3

;68! ##7fi3
%O S,% J% 3c]5
P_ 7 Afi!
!3U
N ?f ;9H%5vff#]?(7

5
P_ ( fi!^!3U
N ?
%5 4

+(_
7 ff`5F! p18fdff3
68! ##(fi3^J%L*9
5 `
%
?) 5
P_
))
+ #
)
b W

?5 y# 5% #-f
1 f7 ^ K R#
5#

3d!

_ ff*
?2%
# B#
?+$
/fi
?!
1 fNM ?ff
] :


#
?%
?(
)1
5
ffN

'
H# #
!1
f;#
5#

# 33 # [ ?5 ;M ?
L
f?\5
3 #'2fi
? 6 W
9 fim!+T [ /#6 + 4@9M1 ^
# 33 #?[ % #
3 :#m
ffP5d
R
R
#
#5 4#6 + /KJ @ffJ9k %8
++ /%
ff-,% :
b
?P H_
?
4
, #b
3T#
b$
# F+T 8

N

/ ?c\5
3 #'1 ^ ?2 <_
N


ff&#35& #
ff# " ?%
?c

)14_^ : //
5+
# 5% #-b
, S# #Q
3+ 7f
?%
b
, % : Fff
#
5% #Q
Q+3'H` ?%
?!b
, B+3 :
-
1 f?fiM5 3d+
+ ff

%
& ff
%7 :

?f4 P_
?
#6 + <h
9 ?%
?^
a#6 + 5f
9 fiP ?+ ff
?5 y# 5% #-1
!
"
!u
,R
+ ff5] #
ff#
R
?%
2+N
^$R`#6 + 9H\5
3 #'
37N

ff #6 + C9M1"NO H
$
2 ]
! 32
?%

#
# ]\5
3 #'
3/ ?% " `\5
3 #'
*
<,( 3H
5+

3m 3
ff"5S c
! 8
1 fWM ?mfiW!
ffv
!
M+
?P\5

3 #'^
%1"_AP NffQm
?5 # 5% #-,
37
/ffB*+
#6 +
@@9M1
E ff4 # 5#



% ?!, 2/
5+

3A
dM 2%
# 4

j
U


1
_
ff ?fi"# #<#6 F
+ =I9g :
RM T+;_
!ff
3g
%f
#A

+

_
/+ 8m
1 fc
!u
3ff !fi *
# k
U 3+ DM

5
4 %(

$
# # ?k (
! ;fi;/
!
m$
# #
?k
#3 m$
# #
?k
!

<

>R

"K 2G = , IHCfiJ DC
AP



2G = , IHCfiJ

3

"L =



`

"MNO, G =

`

>R

>R

Q



fiff

R=<?> A@ CBCB;DEfi
SMNO, G =
TMNO, G =
UMNO, G =
VL =
<L =
MNO, G =
6W TMNO, G =
;W

MNO, G =

L VO\ VOYM[ N

h*i



fi }


fiff

|/|

W;1K_



/}





30 {}

f

ff{5 %,

P_ ff,M!46W@ffBB9M,3KF $^
N_) $3b/fi_ ff1K_^ : F^! 3
!ffN
#H
fffi_ff/%;+
N^ -%U3+dM?)
_ffN


ff!fi*(%#p?_ff^+S3^!M1(YR5M?ffidff3
%ff4

fi5
#!M 5Q6#+ 9M1f;?+3 mff!fiNff?2%
*
c#
_ ff*fpff!fi*M ?!1
fiR_ 5!g #3%$##?g

c

!ffF#3F ff!fi,?ff*ff"5

MNO, G =

MNO, G =
3MNO, G =
MNO, G =

DC

YRf,fiM(\53#'P
N?1 ?K'Hd $?!-/5+!,Mm!fi%#-,
#
-%
# #
$ ff* 3 :
k H
+ #
D# \53#' ?v /
ff\5
ff*p
# 5% #
!L
1 f
#
3 P 34\5
3 #' N

?

Y{ff#
%4
%3 : 3 &/
5+v

$

,

?
B#
_ ff*4
+ 3+ # 3
$##?; #3 c
!
% # ?)v_ :
Ml

ff\5
#]m
ffG,5 :
(
$

P
?fiM537N

?
d3fi* % !
!1
NW/_T#5#


>R

ff-,fi!fi%#7 ?%?7?

=

DC

! 8 zT<38x;'?z 49<Vzz 4>:A+s
f3ff#?5#_?

+ ff]5
P_ P )ff 5%ff M?7+yff3%#ff#

5
P_ P ^# 5FM?!1 fff `FM!N3?5% S_ff U_ff U_ P+
!fi%D]3fiR!^ 8M?f3^ ?#
, ff-,/
U _ 5N

ff* ^ff
/
+ 5% P%T
fif/! R
3fiM ?%
5 ;

/
+ fN

f%+ 5# Afi
?bNff
%

3 fi
ff#v_ ?!1

fi`

c

fcm
?#
* ff` 5
fi
5
$
ff :
^R/M
%#pM/!fffff#6
;V
ff{5 %,-J%LLL*9)?)# 5dM?)P%^ c# 5d!^ fi!T!3
_

U N

?!1bfmfi5-,
N ff
Nff*ff_T#5#
2YY23ff b#AJ5, ;fi+V
*
+ % 3+ /
_ffff - %ff ff ffM ?!, ]#)ff?KT# 5#' -ff 5%ff
/
! !1

1d

f

`

Q

:;3<=?>@.ACBD
EE Iff K;3SEHKLMPCSAEHS/;3S/Q AC@3= V
UWV NMKAI !)?' 03b';ff?')+'
\ ff?')+'b? 0
ij > j DkSACS>/I wr }~ { ` '0 '0fi%{5)?_!5 0'0R' 0b R'm! " c
KAxNMKAI" !8?_'5+ ' 5 5{55]' 03b';ff?')+'
` c @ V @.AC@ j ;3 @ fiS$" ` 5!)?V!5 0'0' 0dc
` j c =?> 55' ~ g \
= `3~ c
`3 c >SNS j wr }~ { ' 0
`. c
PCS/;3S/Q 3' '' 'R' 0 5 `3~ c 5'! ' D+
\ ^\ ?ff?'8+'b? 08 5'0dfi''
5'f!
`h c
\ 5'0dfi'f!5 0'0'
=?> 55' ~ g
= `3~ c `3~ c

`3 c
S/;3@3Dk@ Vj ACS 'f!5 0'0' m3'
`u c
jnv
'f!5 0'0' '! "
`3 c V >SNS j

b#PJ5ge%ff53+WM/!fffff##5#
41
h*i>h

fi~}~

~/]{}/}

`

WN ^+_T#5#
2YYpfi;D!T ]kfi!c!3WU
N ?&%L`D!T )M?
H1KNO g m3mffff!A VM? H,
H18fT ; +% %/fi5
N!
!



?

*
?-%
j_
]ff ffffP :!#c ! H1 ! U
N
% 3d4* 6 j9M1]NW # 3#,$
!c
ff ff ffBM ?3ffN

' #6 + @9
H* ;fi

?Rfiv!;+@&#6 + J9M1 %UR!]
, B
?5 # 5% # ) #5
#6 + //h
+ 9M,
DM D3ff&+ /
!]#6 + I9M1
! H, DM %
# ` #
?+
( Hfi W3mff ff ff-1 ;?5 vM , ( ;3HN

ffF+ %c@ 6 j9gfi
?mfiff
: H fi !]!3
U N

?/ ff 5 3RM <#6 + 59M1_^ : NM vff ff #-,g vM
3ff3


% ff&
!
#6 + C
9 6 j92fi
?c :
R fi
!;!3
U N

?P
ff5
ff ff ffBM Dfi ffN

ff* ff&5@`#6 + 9M
1 f332 ff* 5)
/fi2 #
5#

%5 Fff

?H %
" T/
5+;
# 5% #v
fi
!)!3 ;
U N

?A* 5# 2 N

2fi

@ 6 j9 @)+P ( n,R%
/ ^ :#%

# 5% #
F T* 5# #
V

U N

?]fi
*
5 $ #
5+c ?F 5%
25
!
#
#
ff ff ffM ?!1kNW; 3;
ff;
U N

?
?&
ffQ5=
/ P
/ ff ff ffM ?cff ?S ?
( ]%
RM ?c
5

*S !A ff"fi !(!3

U N

?g%

^m
?#
* ;ff
2H_
ff"ff ?ff"%
ff
/
?% T5 P+S_
dff ff ff c :#%
N
# 5% #
!1
NW3 R 3 !#
fffi 3 % P
f %

"{

ff, 2Yp
3%N

ffN

ff* ff
` 2#5
` :
YRf1 b#
ch7
# ?A W/ffR2
#
5#
f <Y1RNWF
# ;
H#5
,Rf <Y] 3 )YRf
ff ff
(
# (_
?
T_
?+
T+/_
d!ffF*+; c f
! H)
1 kN
ff
%
YRf +D
fP _ ff*]
+ #
%]
?5 v# 5% #-
,
U N

)m
?#
* 6 j)
9 fiW* R ff
ff 7\5

3 #'N

?
c%
5 p3)
ffp( :#%
!

K



K K K K K







,6O 8J fi

,6O 8J fi


"K



>R



> =VGO

K

K K ;



,

ff

,6O 8J fi

,6O 8J fi@





!`
ba



DC

&
f383F%
N^\53#'/
N?%]"YRf




'$%

KK

ff
'
5 (
$
( ff-

U g%g)m?#*g $Mf$##U
N ?
$ ,-5]

# 5%#`+
( ff-

ff


fi;2+*ff\5k+<@P ^ff`5pU?#
# 5%#-1

ba

fc
v?+4 :(7?5#_ffF
N ff
Nff*%#p3H+ff2c# 5#'] bff

/m!ff3-,_ff c dUff!#4
N73
#H4 3!#fffi3%

G = , IHCfiJ

/fi5N

! 4fi
_T#
5#
YRf +_
y!Q6:<! ##

ffW
, #
fi3(J%L*9M1gfW?/#c2 #ff5% 7# 5#'S M?;5!ff4_T#5#
f <Y,
fi
5 Nb3 +
+N

A5ff)/

b !8
1 fg/
5+5ff)/
R
b 3k % N

mM H ;_A!ffff
P _ ff*b
# 5% #
k _T# 5#
f <Y,%?/# g A5
?87 6 j9fi
?!b
1 fH
/
N

$ *P5ff)/
B
b 37 %D
ff
53+ N
?fiM5 %
#


fi
"

ff
!
ff*
/! ff #&m
+N

;5R&\5
3 #'


/!
1 f ! :
/5

U #
5%+

fi 3 % #
!,
fi #
p
"YRL
f
U ff! #%
# B`3 fi

:#m
ffQ5
NM< 2YY
fi_?fi5(+S_
/_
!+ Wfi
5 -1

DC

ba

fi

ba

1G = , IHCfiJ

`

G = , IHCfiJ

! <38xr/o>+?82 <Vz{qo %

q/s

.WqU8qK4>:A+s :#s,4 % z

q/s

`

$ < 2q

z

57d / ;%
5 y3T

#
ff= :!fi%4!3Z/ _ :M
,V&O#&%&'$%/;%5y32_?F?fiM5ff

5"dff53+W;YRf #5#
41

fi
% #Q%
ffB
/dQ 57d / <6 57dT fff ?#
J5W_ 5% =;
fi+V

53+ %, )
+
ffA
!+!,HJ%LL@d
9 %
7 ?d_ :


<

7 #&% fi'$% R,
f g3ff#y3T+3!3fi5# :4Dff3%#=_!'m ff&





`

h*i

U`

`





fi }


fiff

|/|



/}





30 {}

:;3<=?>@.ACBD
G E IMG j j [@ V @ V <)EHS>,RS>OPCKLM<?>=KN9Q= V PxAx>KQ AC@3= V
X Zfi\^]O_ `3X 'ff? !0b X b'ff? !)! 5
[
UWV NMKAI
\ {! ' ` ff?')+'dc? 05
_ 5 ' ` ff?')+'dc ? 0dc
e !)?_? 030 ''0 ` !'' ' ? 0dc ?fghe

ij > j DkSACS>/I wr }~ { ` '0 '0fi%{5)?_!5 0'0R' 0
D']! " c
l` 55ff? 0 ' d?ff?'50 inm oqp l pGo i5i ? ) ? c
rOsut vxwyyz,{,| ` ?/!{!838' 55ff?,c
}~, r s| ` fi%{5)?' 0b R'{0?$c
KAxNMKAI" !8?_'5+ ' 5 5{55]' 03b';ff?')+'
` c @ V @.AC@ j ;3 @ fiS$" ` 5!)?V!5 0'0' 0dc
` j c =?> 55' ~ g \
= `3~ c
`3 c >SNS j wr }~ { ' 0
`. c
5? :;3<=?>@.ACBDFEHG 'd'')W' 'N ?

? W Z

ff
fi
`h c
=?> 55' ~ g \ H5 '0dfi'f'''0'
= `3~ c `3~ c

`3 c
jnv
'f'''0' ; 'd! "
`u c V >SNS j

b#Ph5FNO 5%#3+M#7f%
E*V KEGXUNUXAY5XUN



]Y{ ff1

% #&% 3/ ,+
4 Q!3Z/ ]
N?5&3 5#i $##3 ?S%
fi;!3 Z/
ffW$##,_ '$% 3^
C0
N?5] 5#` ]ff#
1g_$*"
!3 Z/
ff!
% # 7 ?!#&% $
,)'$%
57d / N%
c!3 Z/
W_ :


"! D=

2 g# 3 D3 fi
! 5% h'$% <6 #+ ff&&
3!V jU 3n9K %
S_WA# m$
#
, vff
# #
#'O
#&% "6 #+ ff"] !V j
U 3n9K %
"_d%#
p$
# /#6 b#
N`{
ff #`h51 J9M1
f 57d /
F3dfi 53% :
N

?
54 ! ?P


3
8
,


/K%

1#&% ?'$% c 5! 3F!#
^+P T3%
]_
^3 fiMffg
* ?+WV
1FdH*
5ff#
, * ?+ W
?

/fiA
f " ff*#P3+ *
(3%
G1
f
RM ?)%
5 fi;
/
+c3+ *T
;3%

P R$
* W3 57
/


5 4* U 5
%
3c
+ ff-1fNfi?3 2 57d !

]
ff=5y
V


/c%
# & S_
?+

#&% ?'$% " 5!
<_


ffB4\5
3 #'&N

?
/ :
N

/fi5
v! ? _ ff* ?fiM

5P N




5!1`NW


+ #-,K %

#
+2 = 3+p
5 ! ; ;?ff)#&% ?'$% ] 5! 53

?T
] _ ff*
%
P



# 5#

!,5/ _ ff*8
/fi5N

! ;!+
FV
dff ff ff"% 7



#
5#

^5v

fi #
N

+W!V ff
# # P%


N
#
5#
%^ %
b ?W*+/ !*T _ ff*

3!3 Z % #

+ !1
f(N

?
f; TYRf # 5#
%g
ffK+c_
)

j
U

# [ ff-, 5?+cN

/
%

fic# fi$
#
S3%
57d / & Sff #= H ! :
_ 7

46:%
# ^#&% pff\5
F+@!LL
'$% pff\5
F+=L S9M1 ^ )
,
!
ff,K %P

RN

% #-
, bN

ffN

ff* ff_T#
5#
YRffi, 3
_ :
MN

ffP

#&% %





`

`



&
MC
G_





DC









eff






S^

`

`

MC





DC



1Z7[M\ E*V [M\ [ML

MC







h*i

`

DC
DC







fi~}~

~/]{}/}

' % R,%
Nffe`57du#3!,R 5% %
( #&% k'$% +%V' ff
$
#&%&'$% /1FfN?+ 3c
NffQ
N %#8O^" ff& (
N J
fi)%53Fffm?fiM5vff53+A :H
N/fi57T\53#'; VM?K :;7#ff-,*Uff


-1 R
U ff<

-, #&%&'$%/ 3fi
53% N7 57d / 7
57u
/ R3)
N

ff#F
ff\5
#fi ff*)+] P


3 # [ ff#&%&'$%l/ P%
$% R
,(pfi


3 #?[ % #`
+ * : 7 j
U ?!_
, ?_ff #
ff#%
1 f#&%&'$%L/ R` 57d
/
fi
+ 5% ffv`{
ff #`h51 J/5 b#
? 5
, ?_ff #
ff#1



`

`



/fi)#

b



]]{

W

D@

VMN

&`

fiff



8 /fi

fR# ]/!, ?5#_ff=Y{ff#&J51 J5,_ ?ff*^
+ & K%V

$ff=?5##R?!1Wf3%+ &?$)+;%"
+ & F

+
fiMRR ? bR^ ffA3

% %/
?^68>7f2f79M
1 fA
5?5#;nV
#vR?!,$ffp3m/fi_ ff,3(
N/fi5% 2+Sd+fiM4>7f2f R?76 ff5-,
]3% ! +b5*VWY fi/, YR
P5 -,@ffBBC9M,k%
# +N

R/fi !3 fi5# ?) g +b` ]&3WV
1
f
$
ffv
U _ WVX
ffp

33
v
R ?(
3+ ( c :#%
N
+ /!

U



@%1f ff


5+

J51^%S 5+Dp /fi5%#
h51%3!ff#

1%/!fffff#
ff51%+%3+ 5fi5 5#[?%#` 8/
C51%433#[?%#
I*1%* !%#
51%p!fi%#
Y{ff#`h51@%,+5%R+ /7@d`J5,?ff*fS
Nff _ ff
ffp%/ R+
:fi #
= p $
ff? 5 #
p #N

! R#1 k53 ; :$ V

=! ff # ff ff #

+ /T
h Sm
? 5#_
ffp3!
={
ff #
TJ51 J
J51 h5,R%
( %?# F

U _ WVX
ff

"! ff #F
Fff ff #F
fi^3
ff"{
ffnV
#3h51 J51 ! Rv?# Hb
+ /
:
) 3A

v
fic3
ffF3{
ff #
)h51 h Rh51 C5,
?_ff
#
ff#1
fD
$
ff<? 5 # #
R ?d3# 5% #
* 5 #
1/NOd
3# 5% # ,

c

*F
+ /(

ff
ff+/_
_?% ff_! :
N% 3+# +
v
+ #v
3H :-1NOf
3;3 +
*
5 # {
,

W

U _ !0 )*#
ffN

ff*)
/
/
+K ;/?K
$
ff;? 5 #

# R ?!1 fy
U _ !0 p B B/% ff*p
53+b

! ff # fi 3 % # 3
?
5#_
ffv`{
ff #=h51 I*1

@



ffAP

AP

h*i

fi }


#"$&% z >o +/x




zw

fiff



|/|

+- Kq 4>:zs?4 A: '*)

/}

>+?82

tvo





30 {}

4 4>:A+s

npz z

fiM#3! ff
#&]
fi
! ;fi?fi23?46XdAeTf79%3Wy
N$*=# V
!#^
Nff ff
41^dAeTf 53+b #+5W!dfi ! R%+5# ?!,3#%/#!,
ff
/
+ % "# + 5!,F #5R ?,8
N!%$3] #+536
!NG1#,)@ffBBC9M1 f?

ff

3;_ : MN

ffp ff
5V
5 75% ff #
4 7 _ ff*f
+ %
?!1

c



DC

dHff
S?+d :M
%#p/* VU
%#p?#!,!R53+b" #nV
+ 573 #b N%
, $
# # ;#

#
3++
,-m
?#
*!
, ?#
*!,k #
fi!+
/
b
,
KRV
N

#-,R #5Rv?

, p!
#
;?fi%
4fi!3 fi^3??!1
dHffN?#) K3%$5%+4?+!,!N :M
%#p%$%53+b" #+5T3#bP3/
% ,
c+ 5
,
P$
ff
c# +
5!1

c



dHff

%p?+4?+p?#!,W!
N?ff
Nff* D?fip5%,c! :ffRV
5!3 fiv*{_ /*,cY !
Nff*3 ?#-,) fiM3yfi5*5
3v #

3+
/
?!1

52^;T++M%c?+^Rff!fi*

d?+( cHb, :f?5

* ?+F, ff

+%,_P,T,/=dT,?_ff#ff#1

/%+

_ % %/
S%
# <Jhv
/% ff* ?ff* '{/ K
Nff b5QdAeTf 3%3!,
ffffR%HNW+#F :Fd;fiM#fi!3fi )!ff*#R f?%/3#%#-,_%!,*dm%3R,
;]
ffi : F
3 1 f`% %/3 ?_ff<5R /ff
##
dAeTfa% %/
/ff

dAeTf R!!
ff
/
ff
5
$
3 % #-
, %$ %L
2
% ff /% ff*
ff ?ff*dAeTf /% ff* !1 %!
ff ?!,( `% %/
3S

fi
% R D#
!?fff MT H _ ff*T'{
_?2 g /3?1 `
!
ff,k N!ff
!

% # & ?<6 /% ff* ]%
F
ff
QdAeTf7
9 fi=
5
S# ff ff ff _ 5+

#
3 A%
# y+N

N ff # ff

^
c
/
ff=5`
ff
5b
5 # #
5
$
ff* 3^dAeTf /% ff* !m
, ff ff*; :
/ 8
N*
?+ #
% #
;+< NW
+ # 1 f3
/3ff % B!F
3fi 53% : 4dAeTf 53+b

3
,A
#
3
fi
53% " :

?
N
5] N! ?2 (dAeTl
f 53+b`! ff #
= :


_ :


R?+

% #y

ff
5N

ff V
5 1

&`

OP

/ff



DC

ea

SR






z

'58 54 ' +-/.1032)z{o5476 t98;:z{ <38xr/o>+?82

4 4>:A+s

npz z

q/s

<Vzz 4>:A+s

fR?A U_ WVXffp43 ";_ :M
Nffv( :#%!1




%!
%
%M3 :Tfi?1(35;LR1 S+&@!LLR,V
;
Uff"5
P_ g ffffff" ]M?)ff\5
+/h51)f%M?]ffS3m# 5%#%R?
^S+%U_ g :;ffff#FF* ! % #-8
1 fW
_ff #/ F@ RJ%R
L ?F :
?5&%+%5# ff3 8 %U_ 5N

ff* !1)dH ! R
?+ #
) K N

ff V

U _
*#ff 3D+m 4+3

#P 35
P_
; ?%
? pM $R +<
+ff&;ff 5%#<]
?T%

?%
?cHy*#

U _ff
#

7
ff3 3%
3%$5%+?+!1gdH
ff\5
ff*#,*m
fff
%_ :
MN

ff) 8
b
U _ 5N

ff* 5N
* ff* #
#
3
#) ?%
f/ f(5
P_

# 5% #
8 (

;#5
; ^YRf #
5#

#6 +
/TJVM@ffJ/ _T# 5#
YRf79M1
NW7 3# 5% # )R ?!,j )
U _
ff ff ff7
]* ?+ 2dAeTf 53+bT

/!
1 % ^@
%
7 F ffB
/!,+ ! ;%
# < ]fi
?7q
(QM #
Z 1"NW
N

<3 =

#

$
ffy= 3W/fi_ ff,- ; ?%
?dfi_?fi5v
=
+%/_P,

ba<Y#5#


&dT, f

ff

*ffAP

?_

h*i

fi~}~

~/]{}/}

1H?LGX 7X HK[M\IZ7[ *NJML E

##H M?A?5#/Pd/mfi7 ff
+
n1mfc?5#_ff
#
5% # ]R ?k;
! ?+ 8 : % W%
+ %
? B/dT,ff #Mff7k%
S?+
%
3 # 7^ #6 + % 4_ % *
9 3PR
:


% #
ff
Q :
R p


/!
, G1 1#b
, #
# ff/+P 8Z5 %
U _ !0 g 5# 532
* ?+
?!
1 52#D
% : ]ff

5c

-,5
/fi5%
7

%/ ff

/% ff* !,*m
%* ?+


/K3
ff-1H{
T{
ff #"h51
: ^
/ P! 3 A4
U _ !0 f*#
ffN

ff*%
3

33
v
R ?!1




j















j













NS>,AEHS/;3S/Q ACS EHKLM<?>=KNMP
ff G
{! ' m? +'' :fih








5
?
0?
{'b 5
?m 5
0?ff
'?ff?ff 0'5' 5

?m 5
0?ff fiff
{'b {5

'?ff?ff 0'5' 5

' 5 5

fiff
{'b {5

)5''++?bfifi{5!''fi



h

j5h

l r fi
: ffhG
rOrz f3e :fiffhG
: hG
l r
h rOrz f3e fi: ffhG
1l e : hG
l
r

l


h





oGi



oOj



oGi



`

{

% S@%)NWffp/;7 :M


>R


?!1 ^ 7# #
fi7 #
Ab
5RV
/- #+5!1)YR3_@d3( :T
d/%ff*!,/`_2J; :^ ff
d/%ff*!,
% W
/ 2@%
, (J5
, 3d2
@ fi2 :
(

" ff

/% ff* !)
1 f

/
fi
ff7
_ ff*b
%+ 5# ;/
! k%
#
?$1
(d/fi5N

! Kfi
?
# ffD


( 8
1 fA3 +

* *
b :


% #
%$ ;#
Z
?(N

ff45 * ?+!1

DC

X

/fi5% ff#" : %?5`%+%, mffR*?+#%ff3%5 dffvM?fi7
{
_?+]/
F $ 57d /,G1 1#,*%5/ $ff
fi^ffS+P) 57di*UF5G1
_A
+ % T, :
+,!ffBM?fiS<S*UB5b^ b#? " :
#&%&'$%& 57d /
, ?_ff #
ff#N
1 (H4 g ?NM ?!,
@ ^&J5
, % ff
`
P
?!_
, fi;3 3+ ff % /J51 ^ ; %2 R
U _ W!V ff ff ffy

/ 2D
@ (J
fi#
Z *!, f
fi%

/S
#
;3 P*
U 5G]
1 f?+3 :
Wff ff

U #&
]'H
?%
+ % fiS ?N

3 #'68
3+ 4 H ?%
?7#9M,
?F ff
53 #'368 5
ff3 % # ff#;

*D
$
# #
) ?n)
9 /)# g %F
ff/ ?%
?
fi,

7N

ff V
$
*A
!7
,

U _ff
#
23 %$
5%+
" ?+ !1

/`



`



<!4qK4>:A'74>: q %

f&URp+ u

/`

b

Tff



4 M:qK4>:A+s +- <38xr/o>+?82;'

qoq z{o

y$ff

?5#y#

DC

R?v+fi


<3 ff

/!1NW<3+ ,+%3+ F _ ff?<3+5# #WfiS
N ff< :7'H$V

3%#!,kSfi!DQ! ff$ 3%#-1fSfi!R$ 3%#Q3+7
/%
ff* !ff*+3 F
#5 [ ff

$9M,k%
?7 ! ff
$
3 % #v
fiV
fffi 3 % 7RVX fi
!T!3
U N

?P#6 $ ?# *v
ff n9M1
$##S <6XdAeTf

SR

hoGi

fi }





j











fiff



|/|

/}





30 {}

S/PxA UWV K QS EHKLM<?>=KNMP

: hG
h rOrz f3e :fiffhG
j5h rOrz 3f e
j5h : hG
: ffhG
j5h rOrz f3e fi
rOrz f3e fi
: ffhG
rOrz f3e : hG
1l e

l

; 5
?
0?ff fiff
''fi +5'+0{5

N5! {'?'5 D{5
fiff
{'b R 5
N5! {'?'5 D{5
'++{5

!;{5
fiff
' 5R 5



% PJ5%(H c`_?+ff

#&%&'$%lQ`57d

/ffi :v+%







T1mf?$##

9 b#?fiff5,?_ff#ff#1

/fiP
fibff

b# %f7#&%&'$%

/
?ff*
*U 5 v/yff
\53#'
N?
#&%&Ru6 '$% (9%%2%v+% T1 jV
ff3 2@ (Jff $##
_
W

/Dffffffi54
NffRV



U _ !v
, ;@ cJ'H
! ff

/H :


/
#&%&'$% *
U 5G1

b#Qff5%fy
N/Fv b#%V

W
^c ` 57d/mRV
$#&%&'$%l/1f

+?`

5



{



ff\5#fiff= P?='H

_ ?# ff-1 NW
57dy/](73Kff
$
* 268LR, L*]
9 <6W@!LLR,@!LL*m
9 V
ff*
RM $
# #
c%
# #
ZV
dff\5

- [ 1

`



DC

/?

Y5 % 3+ _ ff ?W`3+ 5# #A :k?5+5;6#%+5# ?n9A_!'m ff=?
'HF$ 3%#3)?+ff&/fi * ?+^%#=B
RffR+%46 L L 9M1 T3

$
/5N

5 b
%+ 5# ?dff ]_
ffy/fi##ff<<+=h%L* fi3d+4%y!
*
fi fi%S ?+
+ ?!1_T
/& %+ 5# ?;%
# #
Z *#Q _ ff*
3+
5# #
^ fiF#;
ff
7
%P :

?%
?? 5#/
"

/S6:
5
/# + 5n9M,% k

#) ]fi]3 +) %+ 5# ?-%
# #
Z *#T _ ff*-fi

3+
5# #
!)
1 f?R%+ 5# ?%fi ff
+*
n_
, 3P ?%
?^ :
MN

ff3
?kfi
?- %b
fiH5 fi5 53+ F : k H3
ffR

/VfiH ff
+ * n1

ff

ff

B

8' Iff 1

DC

EGF5HIHKJMLONUX [N#NULGXOFKN VGE
hoo

DC
EGF5HIHKJMLONUX Z7[ *NJML E

fi~}~

~/]{}/}

$/ #+5fi
N$*)+p5!D/%+ M&?5#(%fiR?+RV
R
% #Q
N !v ! % :/
Nff ]5,);
Nff ]U_ 33#bM?
p! ?!R
^
5
$
#
!
ff df$
# /68>c
ffb,k@ffBBh9M1
NW` 3^H b,$ R ]
+ % 3+ b

#
3W3^+! ff7N

?
8

$
S# +
5!,
% ?K ^ff 3#;%
! F !%
5_
)
ff/+

$

ff0 FRff %; %


?
5 #y
3c ! :c+3 N
U _ !1/NW& dAeTL
f fi 3 % #& N
U _
7ff ff&%!
W $
ff] #+ 5fi ffF* ?+
, ff3 3% ) !F
fiT
?#S !] _


?
N
ff
5 1^NW % ;h5
,
U _ W
ff ff ffy
$
/# +
5fi;3 3+ ff`URT+"
#
$dAeTf 53+b]
/!
, ?5 =? 5#_
ff"5v
S3 3+Ab
5 / # +
5!1



j





j


EHKNN=?>,AC@ V < j Q AC=?>P

>@ V Q@.N j ; j Q AC=?>P
{! ' m? +''
?; 5
0?

!ff!+?''0'
?'!';!fi
fifi{5!'5!
5 5
{! ' m? +''
fifi{5!'5!
! ' '0!0

pff 0'5'
'?]0'0!0
pff 0'5'
'0!0'' 5'+0 ?



{'b
R 5
?; 5
0
?ff



j5h l r






r rz f3e
l r

h rOrz f3e
rOrz f3e
l r

'?ff?/ff 0'5'{ 5

?; 5
0?ff
{'b R{5

'?ff?/ff 0'5'{ 5

' 5R 5


{'b R{5

)5''++?bfifi{5!''fi

h



{! ' m? +''

{! ' m? +''
fifi{5!'5!
+?{'0b5 '

% Ph5)NWff`?5#P65 /- #+5n9f`?W+%3+ 5fi5 5ZV

[?%#6#$ #+5n9M1



<38 >+?82@:A'58 U: K4>:A+
xr/o

q

q



_

ff 33#[?%#/
N!R] ]_)ffS+P33#[ A^ F V*]3
%3 <

4 < :

R
?%
# u fi
!`!3 ?
ff\5
ff*!1gNO)
3 +/_
7
ffp%SN

! R :
^
3
3 #?[ R
+ fiM3!3 Z % #v
?!1
YR
4
3
3 #?[ % #-
, ^? 5#_
ffp4 3fff #-/
, #%
)
)+]N

/fi3+ 5# #

2 _ ff*N

/!1 fpfi
5 N

?; p
U 3+ ff 3
%S ?+S
35N

5<6:
ffS3 ! jb
9 %+ 5# )_

U _ !0 )* ?+F :



#
3!b
1 ffff ff ff%+ 5#
3% #+
ff=& O3!V j
U 32 F ;3%
5
4
1 f !V j
U 3W ?ff* !3 !,$
c
/
Dff 3ff#,
S5
P_
2m

+ ?2m

# ff<!3 !1 H Qff #
^ H !V j
U 3]6 ! W
9 fi
ff=+p

% P /5
P_
T]

+ ?!12NW b#
/C5,- :

+ ,$ O3!V j
U 3 ?ff*
( , ! !V jU 3Kff ?K!3 fiR
?fiK3?76XdAeTf7
9 ff ?K!3 H. ?# *0
#5#
4,Wff

DC

8



hoOj

fi }


fiff

|/|



/}





30 {}







86 RVWdAeTf79M152H :A5fi/m%A ! ,* ?ff*;ff/26 @%, 2J
/@9k -dAeTf /%ff*!,A :D%%^3+5# #c ;ff*;$ 3%#
FdAeTf #6 kdAeTf7m
9 /% ff* !)
1 fc 5fi/f%( 73+ 5# #] RVWdAeTf
#6 b
?# *f
9 /% ff* ` ; 5
F
!d
=/3+ 5# #4m
?# *
ff !ff
*+/

3_2J368ff43
j9M1



SR

b#PC5^f3+5# #c )5
P_ 5P 2dAeTf/%ff*46#)dAeTf79d ?#* SRff
6#]?#*9Q
7 f%<6#Q?fi5n9M1 W
c 5fi/
@%,
2J5,8/@ ?ff*P
3+5# #c 7dAeTf
/%ff*;_ff#`+<4?$ /!1Bf
ff33W ?ff*%?#*vS
R fff!ffF<
2J51

b#I*^f3+5# #c )5
P_ 5P 2dAeTf/%ff*46#)dAeTf79d

SR

?#
* ff
6#V?#*9M,Amff_(c3+5# #F /%ff*( :f/ @ /JR


^]
% 3#6 3 ?fi5n9M
1 fff`3
?ff* W?# *
ffW!ffp


@%1

SR

L

L








<L

52B

$
, ] 5fi/7 f/ @ /@ b#C #<" 5%
f$##" ?36XdAeTf /%ff*n9M,] b#
3I45fi/ % /J%#



ho

L

fi~}~

~/]{}/}

b#

5^f3+5# #K -dAeTf/%ff*m"2?5#_ff/5/%+ MA_@W (J5,
ffb

db
?# * ff &
!ff*+p
/%+ (J<68ff<3j9f
$
1


( + k5 ?+ fi


SR

T=<=D

2






L

" 5%4 ;$##] ?!,% ?P]5fi/7 2J b#"C @ b#4I

% %2 ;? 5 #
^]


/T
d$
## ?]6XdAeTfl/%ff*n9%Tmffb
+N

^
!
% # 2 ?2#6 ?# *N
#
3 n9M1 U F :
g ^
ffH
3
3 #?[ % #;V


/
2
J
@ 3 ff* /dAeTf `RVWdAeTf 3+ 5# #-, b#
?T
C N
ff
_
ff
N

3 Z/
ff +
ff
% 2_
!+ F 5+ ^
3
3 #?[ % #N

! R-,5R
%


+( 7 5% ;
$
# # 7 ?!1
NWN

ff g


cm
]'{
/ #<
! S+
?ff*P "5
P_
7
$
# #
?46XdAeT

f /% ff* !)
, Q 3/fi_
9
P+y
!
?m

_ ?7f
ffB/%+
P :


/ $ ?f/% ff* !
1 52/ ) m-, f38?
ffS+d
!
?/

_ ?
F ?DN

R/%+
/6: 2 /%+
n9( :
2 ;
!
% #
/ ?/6 /% ff* T%
# cdAeTf79M1
52 ffi* % ?F ! 8 $ ffD%$ f3 %8 / fiP!3 Z % #
ff

^ ;N

/fi53+= F Nfi? ;
5fi/=]
v

y=
5fi/= g
ff*
$ 3 % #;
3
3 # [ ? ) 5 #
K

%F ! P#6 ff # # #'$
#&% *9M,



"

!
1% f
,(D+ ; : K


%K c6:# 3 3 fiM
5% '$% *9M,%
! # # 4! % # P ?% ff* $ 3 % #-{, ?_ff # ff#1 W + ,
5
P_
5H
$
3

3
3 #?[ % #4]

R
@ b#
/I; Dfi?" ^ ;ff`3
7`
% ?ff*
g 25
P_
5F k

3!3 Z/
ff/5


+ ?g


@%1KNW] 3F;
ff,
Fff

# #
#'y
Q #3 3 fiM
5% _
?+

% ff :
/%+ 2@S
b#
4I*p
1 f
N

:

% #4 : W/%+ (J] =_
7 : b#
5V
, %



/^_
@ (J



(8
%+ 5# ;. + k5 ?+ fi
0#1
f%
$
ff]3
3 #?[ % #SN

! R" "_
Wfi ff"+
3
3 # [ %

/]3 +D



Tfi
33+ 5# #
P 23 ! j



%+ 5# ?!1 _T fi
5 i+ 5
3
3 #?[ % #
3?ff* ffB b#
SB51]e^m
! ff,/+4/
fiP5 fid
?ff* % #-
, #d
3c
/
"!#T+
N

/fi! 5

/;
7
3
3 #?[ % #-1
NW= ff
5G
, #
32c
ff ?fi` % ! ff /'H4
$
# ;!3 ?!1PNO]
fi%V
53%
, !3

ff`ff D*3'H!3 ?!,
!
ffy
*4'H4 _ ff*W
%+ 5# Pfi
?!, %
5


U _ (H43#b 2+"N

/fi1






VL



R












VL



D@

fi

L

fi



"MN

>_








D^

DC

ho

fi }


fiff

|/|



/}

b#PB5^f3+5# #4 AdAeTf





30 {}

SR

/%
ff* y?# *
ff T%
# ?_ffT+p
+ ?Tfi
?
68#7,#-,; N#9- :Fff*$ 3%#R/A fffR/%+ M!1

b#S@!LR^f3+5# #P dAeTf

SR

/%ff*)D?#*D ff%#R?_ffK+U 3

dc

u!N


ff*^ ?#p


3 N

! 526W@!


?$A+SLR1@7
9M1 fi
7# V
ffT_!'m ff"+_?#*F$ 3%#F "_^ff-,5 H _ ff?

/
/%+
fi4

G
1 b%+
S_p
@ d2p
@ fiff ff ff NUR ffN


?!1 f"ff3

?ff* R?# *y
_ 5+

ff#<? 5#_
ff<5
/%WV
M&d2@

DC



<38xr/o>+?82 ?s?4z{o>2oz 4qK4>:A+s 4 % >o +?8r % @ :A'58qU:qK4>:A+s




YR333#[?%#p3) 4fi% 7 :%U_ W* !%#3 )`3 pV


b#
?7v
C IF#c <_
N ff< %c 32
#
Z *2 _ ff ;_
!'m
ff

& g

DC

#!1

hoOh

fi~}~

~/]{}/}

SR

dAeTfl/%ff*y?#* ffW!fiM"?%, T%2 NfiN#Z *2# V
ff ?F
/ =! ffff /%+ M!1 b# B+5%?
3fiN _ff :]`+
?+ $fi
5
?;#
p#;
3HbR^%A+5?+ V3;p
N$*m53+b/ #+) :
^dAeTf 3?b
1 f3k/
fi % #D
%
% ; ff
-dAeTf 53+bc

/! ff #S
'{
/ #/g_
%+# ff]5/
5d
) ?%
?m]ff
/
+ 5% ?g Wfi
53% ff
?
?+ ffvfi
5 "%
5 5?g+;
ff
5%

"? 5 #
K%
5 fi#

#8
/ ! ff3 % ff3 ?%
?!1
b#
=@!L 33 + * ?+ 8
, F#
3P
Q _ ff*P
fi P
?!1 ^ " %

U 3
fi
!N

ff*" ?#;
]]
ff %+ 5# 3 5
<%
6:%
5 S*
ff]#D
%+ 5# ?F %m
fi%fffi 3 % %%m
+ %
?H_P, d)9M

U 3

!N

ff*^ ?#-,#;


ff
MN
pff5 R5 fiM#
5fi/*v
fiPf
fffi 3 % 2 :
?fiM#
53+b/
4! ff #p
^ !" _
ff ff jN

?
ff#
F
_ff 33 # [ ff"
Nff

+ # #
!1 b#
@!L! ?fiM#Sff
/
+ 5% ?;#
Z *g _ ff ?g_
!'m
ffv
-dAeT
f F
?#
* ff

;f

U 3

!N


ff*S ?#fi
?!,Fff
/
+ 5%
%g 3KN

?
ffN

ff*!
, #_
fffi 3 %
, 3)
U ff ff*g3?% %+
ff1 A]
#]
3 +d
%
F %!,
#

#f
3(bR^3 %f
/%+
^_d
@ =d2@7
c _ ff*)3?d
$
3 % #
!,5 !
_?ff 7 p


3 fiM#


(
U 3

u!N


ff*T ?#v

_ '1

>R





OC



DC

c

c

;
SR

?_

c



DC

DC

c



c

<38xr/o>+?82 .WqU8qK4>:A+s

NW3M T+F!fi%3 ff 53+b"/!, ;
Nff U_ W^?+ff=Rff


/%+
)

_ffff*!^ gIjL_! ]6 %L4dAeTf /%ff*%=J%L]RVWdAeTf
?(
N



/# :9M)
1 fW?# H :
?/% ff*!,

fi5#[ ffFv% ,
%7 N/%+
fi! ?+ 88
<! ff &dAeTL
f /% ff* !1S_^$PB%L
)dAeTL
f /% ff*
R!ff*+F
%T ?+^
K 7
/%+
!%
1 fP! ff ffyff
# #
#'fi
?36 #&% *9
: /%+
c_@%, (J5
, Qd2N
@ fiN#
Z *#
#
2 & ;fi
?cN

ff&& N!

/% ff* (
ff" : f
3 1
( 2 ('HN
/%+
2fi
?A/( _
#
Z *#1 ^ ; %2 D!!
5`fi
?WfiDff3 % #
ff#
#
-,$?/# P Rff3 % #
ff#
#

#3 d$
# # 5% u6 '$% *9M;]#m
&'$% Sff
P_
ff
5 !
ff`5p
ff ff ]#m
Tfi
?
F ff
53 #?[ % # /fi5N

! &( V
, %
"
+2 g! ff v


/)%
# =#m
c
5%

$
# # c ?!1

#ff









#&%

_@
_2J
2@
(J
d2@
%

5I*1 ff
51
J51
hJ51
Jh51

1



DC





5D!

'$%

JC51
C51
B51
@ffJ51 C
51







ff ff



7FSL [ #&%
ffB51
>1
R@%1 J
@%1 J

I%J51
hC51 L
CB51 J
J51 L
*
51





J51 L

?+%!

'$%

I*1

JI*1 h
J%LR1 L
@ 51 L
LR1 L





*ff






7FSL [

2YR

fi W?#;ffii45!i
IjL _ 5+=6#%ff LidAeTf /%ff*F J%LRVWdAeTf ?"


N?ff
( #&% R,H'$% N
7FSL [ %1


ho




ff


%LR1 L
IjLR1 L
R@%1
I*1
h51

_ffff*D!S

Ny/#:9M,

fi }






fiff

|/|



/}





30 {}

$&% fiz .1032)z{o54 ' + z :#s <38xr/o>+?82 @n :A' +{z{o5B


f)dAeTf

++5%?%bU_ WVXffR#3bD# 5%#;R?bP%5

U_ ) 35Pff\5?+ff4ff 53#'" dffv/d/!(
%+5# ?26: ?%
?n9K %m
fi2

Wfffi 3 % ) :
mM ^
+ #-1NW] 3F;
ff
#]
3)$
#
+W K _ ff*V
/%+
H#6
/n9
]N

g% %!!b
1 f)ff ff #7 R
F

/



/) ?ff* P ^
/
+ #F
3g ! :H+ W
U _ !DR 2ff 3#] _ffF$ ]
Nff
#
_ ?]683 #b "5
P_
P
$
# #
?dQ]+ 5% ff5
P_
P
#3 $
# # ?n9M
, ^m
ff
ff #
_ ?)3 #
b P 5+ %/
3 #',

U _ff ff?

#
%/
3 #'3]
ff
&? 5 #
6X
#_
55 %+[
?
[ 3 -,k@ffBB 9M,k%
5
_ff/S
^ ?%
?g
ff/ T# #
KV
ffNM ?!1NWS %fi 3 % #S? 5#_
ff
`
3W/fi_ ff,$ /


ff # D! %/
3 #'= 5# 53]m
5+ %/
3 #'
, N

3 #'

#
%/
3 #'1

DC

SR



ff

SR

P

bfi # # 4 dAeTf 53+b` ff
*+3 ]% + % ?_ da;P
N !ff#
/ff&<NU_ !0 7 5+] H/'{/ K3%+RR?!1

5
?fiM
$
*;
! 3N _ff ] ff ff #
/
! ;
%+ 5# ?;%fi3ff
_ ff*

U _ 5N

ff* !1 ` ! ff8
, %P% + %
"_ /fi # #
" N
U N

!

_ ff`
ff^m
ffG1A_AT 3)% + %
RfiP#v
! %+ 5# ?) %Tff
_
ff
ffS : ]M % #-

1 ff
U _ !0 g 5+ 2 -



?+ ff"%g cdAeTf
$
3 % #_
d/fi # #
ff*+]'Hv

$
3 % #
H/
ff3` RU48
/% ff* !,

%
b
#
#
Z *#
? +
* ?+


/!
1 f3/fi # #
v
?# ff
/%+

_d
@ 3_2J51

DC





>C

_T#
% # ff#,//fi##S 3_d_ :M
Nff3+F4/7 8_ :M
N+%3+
5fi5 5#[?%# P3 ff /!,A5i 8 3#+<&!ffff /
!
5
/fi /6 1 1#, _ ff*3%]_!'m ff<
R= ff
/%ff*T%fiMR$##
?P : P
$%
9 QffQN

/fi5
%+ 5# /fi
]3+ 5# #
^ :
P ?/fi !1
_T*
#
Z *^ _ ff R3 3^3+ 5# #

ff3_
$ ff* 3#v
* ?+ F
%/fi^ F


P? 5 #-1kW
_ ^/
3 : b

d/fi # #
(
H

ffP
]?# +N

A! ff ff

$
53+b"# + W*4 W%+ 5# 7
W%+ 5# P
P/

% #3%
5 3$ ff* 3#
*
?+ //
ff44
U 3+

U _ (bR^ ff1

DC

DC

OC$7!ff3+"+p+
%DR?T )/fi##U5V
_c 3AHbQ6 YR
f
%,?c
P_ ff,?da>5+ f %,-J%LL@9M1

7
N!R# $*A k!#3;* ?+;+Sc%(U_ fiV

f DT_ ffy+
NR


N !c54
N!R< (_ 3ff`?fiM,- d#?ff*%#B327



3%ff<ffy/2 5`
*&fi!P!37 ?"6:%#<MN$##D5%S
%c ?+7J%L S%
9 =%# `# 3 R$
# #
5% Nc# W$
# , %
# ` N* ff* #`+
b B#
_ff# @!L "1 Af
p
ff ff N
NM
, # ff #\5
3 #'F
((_
ff4 7
/
+f
N

$
*
#+ ff8
1 fA
ff ?fiP# #P : 8ff ff
WM g;
%
U _ ;
8% g+
ff
# [

ff #
W
/" ?%
?T
RM 7 %
fi;N

ff #F
?+
% 1^NW3 3Wff
,

R
?Rfip#
Z *#Q
/ p*
# #
]
#; _
ff
% &@" %N
]
?
ff ff
ff=53
U _
ff D%c
/
+T P ?%
?2
R5 /_
53+b# +
5!
1 f
#g %F f
U _ g/]
ff ff]


/%
# NS



#&%&'$%5% #
3)
+ 5% ff5
b#
?A@ffC @
S{
ff # 1 J5,%
5 Ri m$
# #
k ;/%+
_@ d2
@ P #&%&'$%
/
<h#&%&'$% * U 53 ff& :
% + %
?_ dT,k
ff
$
* 2%
#







AP

&

P

ho

P

fi~}~

~/]{}/}

^
5%_ ?!1NOg ]_^ffS%H) -%U_ ]ffffff/%+
3(#
;4 #&%&'$% *
U 5$ ff ff ff/%+
ffiP!#
7+S 7*

U 5G1
)





#)fi!vd 3>/ ) !2* Vfi)IB>/

_






`

/)!!

NOv3]mff^bR^
57d #3!,(%p + 5!&=_?+F?#!,(
3
ffM ?);_%g!#W)$# A+P^+V'! :gM g - 57d /1)f3

?
N
K %)
q#&% ?'$% 5! n
, #&% _F3 fi
fb$
#
, h'$% )

f$
# 1g


3 fiM#{
, 4
#&%&'$%l/ H
, #&% "_d^3 fi
f$
#
, k'$%l


V
$
# 1
NW 3H b 3\5
3 #'N

?
) a#&%&Ru6 '$%
(9 = ff 53 #?[ % # /fi5N

!
(y7_ ffQ ff-1f3ff #B

U 3
2%
*& 37\5
3 #'&N

?
7_
ffB
ff ff ff-,b
N

/fi53+%
# F
/ f*
# #
A\5
3 #'PN

?
(3 #
b ;c
+WVX/
ffS
N?
1 *#

.
+!/
0 /fi5N

! j1



MC



/`





5





3#" + 2 M:A'*+ ,+- 4 %
w

qo





z

q/s

S8 M:A'74>: '

fi
ff

z

52U_ 5ff]7DC_ ff*
Nff fi 3 %#V %?-%*##-3#b U_ff#
3! fi'$%
ff#<
7 ## #&%
ff#7
S5Mpfi"! 8
:2 5+; ff
FffSR?fiM5y4#&%&'$% /12YR$c%





^##; -+m/fi5
N! f3K/ffSS) :#%dfi
Nff*! m! ##
'$%/,H p
/ 3 p###&% U
N ?M S+Q_4_!+ ff1
;ff<
5 y?+

, #
3$
# 7+3N\53#'=
N?h ,"; :#%
#&%&'$% 5!

MC

3#'
N?$





#&%
'$%



'

j1gNO

3?++]7_ff c *##* !%#4 b/fi5
N!

;3+N;W_ 'S%ffff" :3 K5"5;

^ 2
j1

mc

fi


/R
#&%&'$%l/ffff)c
V$*A/ff4p/fi5
N!
NWi_T# 5#
YRf,K `\5
3 #'N

?
k%,A

< _ ff*O
#&%&'$% 5! u3/ff& #&%&Ru6 '$% (9M,%

(v3A 7
ff
53 #?[ % #p
/fi5N

! ff1
NOd

3 # 5#
ffN

#

U
+ #
?fiM5 a6:
v#d
f
$
*
#&%&'$% / vfi"bR^ fi j9c ff "'H&N

?
?OF fiFff\5
#fi ff*
pff

" %D
!


+ ##
` 4*
U 5g _
! ff ffi5

*
7'H
ff
53+ !DR#] 7fi
?( %^

+(_
dff ff ff4 :
%/fi5N

! 5q(v fi
_ ff*!1KNW4
3(
,

#
*(_
!
ff3_
!+ ^_
ff
d# f* ! % #
3(
/
*
# # 1
e^m
! ff
, &_T# 5#
YRf 3v ff
53+ 4_
?
?fiM5 u#
5#
4,) #
% # 3
_ ff*!1 YR

3 3 # 5% #
R ?!m
, _ :


&
3
"
/
# 5% #

6:'{
/ #`J 9^* -5RM ?%fi;
+ ff=54 :


] #
) F ?%
?3
`$R1NW
3R ?!f
, `\5
3 #' N

?
y3"
ff :
vM ff ff #a6: :
%
5
c'H]N


?
?1d) fidff\5
#fi ff*n]
9 (m
ff_
( :
) dff ff # ?%
?f?
#
%b
ff ;#
d$ ff* 3 :
H
+ #P
#
P\5
3 #'
?
/
ff\5
ff*

#
5% #
!D : ) 3(

, c\5
3 #'"N

?
d3A_
!+ ^ k
1 !^
;
U 3 %
*1
YR
$
7 %Tm
Dff N$
*;#6 j9 l` #&%&'$% / ,$%
#&% '$%Lfi
#
2
& #3 N$
# # ?!V
, ?_ff #
ff#1
pff ff ff9(`fi

, / <_
S!


ff= :

DC

5

MC



DC
DC



APSff

>R

>R







W

ho



fi }


fiff



|/|

/}





30 {}

W

3M ;1ANO^ `_^3%W$*(%WffR
N\53#'%M
S3
2ff45"c :#%; 8#-

W

3c

#&%( &
# %*69B 5 ( 9 '
9B
fi B) &#$' %
5
% 5 ( $
' % 5 (
' % 5 (
$

fiB

NW33( 8#-,
?ff*^5
P_ ) KMd$##?) )Mc%#3\53#')7%5
5d
U #
Q!%#U
N ?!1 H ffffp4 _ ff* <fi,-/?$
3fi
2 _
c!


ff]5] 3H 8#-18fc3,R!
ff]5]3H 8#-,?

j
U 3%f
$
* #&% , #&% C( Ru6 '$%
(;
9 4 j
U 3%f
$
*fi
1( ]
1 f3;3^p

b#
2@@%8
1 f;# _H 33
m3ff\5
5+2 (\5
3 #'c/
;,%
5 ff\5
3 #&%&Ru6 '$%
(9M1

fiB



9B

DC

fiB

9B

9B

5

W

5

tp

points
quality
qg=TP/(FP+g)

R

TP
TP0

-g

b#S@@%

fp

FP

)_ ?7 ;M?c%#<F
N
\53#' '

b#S@ffJ5/`^?4%##?+3\53#'
!ff *+&"_?

#&%&Ru6 '$% (9M1

5

RV
:k

WN )#&%&'$% /,$*/%# # ]\53#' fi %$`3S3,;i
ff# c=_ S! :"M ff1 ^=%vik#&%&'$%
/=`+V'! :F3S
! ff /fi4 B/ $*p %p/fip ?ff*pM?"%# &_?+#&%&'$%
5! F
1 f3W?+

% ?c %d$*2%7%_!ffy&S_?

+d
3 D%$
S3
]
ff\5

?#
* $ ff
%
5 y3c
ff=5= /3 +
D= /_?
41PNO
?ff* ffS5fi/
#,%/
5+
"5
P_
K_
?!, :; 1#&%&'$% / )%
ff

% 2 (3
g
$
*(68L % %
9 P (!#Rb5%
3Aff #-,%%
_
;!ffP A_
?
41
f7
ff* ^b
% #
3;$
*76 1( L*9M;
1 f33
+ 5% ffv b#
S@ffJ51
52P 8-,% : q \5 3 #'7N

?

ffP5
#&% 3'$% ;#
% #R
3


3 fiK F]
ff* G6
1
* F%
# / %N

T\5
3 #';3 (
P3
)
6 fi'$%9 #&%/,
;
# # _3A
+ *f
Fff\5
$+ j
1
* A%
# v#
A\5
3 #'"3 W%$
7 c3
W"
ff
#` F ; ! :2
_
ff
1 fR$
* ^ %T%
_
R!ff*+] ;_
?
fi;
/5+
p$
* mS &#&%&'$% / :]5

R
/
ffN

ff*( k 23
)%
#
#
_ j
, + fi "
$
*/68L % %W
9 ` /ff #`+;
fiM2 /#m
5#
*2

ff
1 f3
3
+ 5% ffp b#
/@ffh51
!
P N

%Pm
Ffi"#5
b 4 :
RQ


)
/%
5 B3c
B
_ff Z%1"NW
3F

, /fi5N

! A%

ff d#
/fi
)%
/fi5N

! (%

ff
7
N


fi
1
fN*
ff* #y
32+`N

;

b
R= #&%&'$% / 1;_Ac ;/
5+
+ %

^
+ #]#
) ?%
?;fi2
ffF"
/
+m
/
% # ?A\5
3 #'
H



MC




1G = , IHCfiJ
7 D@
7



G = , IHCfiJ



9





eHK[ML [M\A\ VO\

7 D@

9

fi

ho

fi B



9B

5

fi~}~

~/]{}/}

b#S@ffh5/`^?

b#S@O

#Q#?+ \53#'kRV
%
!ffv"c_?
: #&%
'$%/1





1

g3ff
Nff*



* ?+

?];q#&%&'$%
c/
5+f
# 5% #-1

?jV
/%% :



+#3)5% ]$5ff1gY{ b#P@ P :m7'{/ / 3ff
Nff*g _$ff*3#N* ?+
?%
?%
#&%&'$%l/ 1
ff5

fi 8 #/ - ?^ ?%?m3K+_)5RS #Rb]+P%g5/ nV
# ff#D

2 F ?%
?!{
, #
;\5
3 #'R
? S_
(
+ ff-1 HD
c #!,
+
#
^ ff
5#=
/ = /ff #` H / ! :2#m
P

ff
1 fD?+
3T %cRV
#
ff /5
P_

'$% ff #
!12e^m
!
ff, !
ff /5
P_

#&%/0 f)m
ffG1AdH
ff\5
ff*#,5 #
ff#v
; ?%
?)+
?A %%
fiP!#
7+]
! :c#m
7
ff,- N# 5#
%
k2_
N% +`?_ff 33 #?[ % #

?fi c+4
! :H
_ H
ff1 52#; WM ?F %;
ff
#
h#&% fi
{
, vfiS 2
_ )/fiH
#&%&'$%l/ /, ff S5 P+S %b /fif
7
+ #48
* ?+
!
?!1
b#
P@
+ 5% ? ^

_ ff )_
!'m
ff"\5
3 #';N

?
?% ) :
MN


ffF+

ff ffH
/ ) ff
5 ?%
?g
%5#
*F
_ 8/fiF - 1#&%&'$% / ;6 $
*

+%V' ff. (R/ 0 9M,*%
g (3 % (. ! 5!
0 _ff Zg ?%
?
( ! :K#m
g


6 $
* b f+%V' ff". ;/ 0 9M1KNW; ?K%
ff m3
;3 fi
O(R3



G,% ; _ff
<_

+
N

$ *2 %
#c

ffy
!
ff*7 #
5#

" /


8
+ #
!
ffS%
# N73 fi (_
?
a%
-1 ^
,
!
ff,5 %g_T#
5#
YRf 38ff
53+
N
# F
%

&p
+ % ffN

ff* fi;
; : ?!D
1 f3TN

?
2 %

+N

,

5fi/ ?!
,
\5
3 #'N

?
c/
ff4p
/fi5N

! c

ffv
?#
p
/_
!+ (
V
+ #-1

>R

>R

R

>R



*ff

DC











3 .1032 M: ?4
. U8 K4>:A+ +- 4 %
)z{o #w



zs q

Wq

q



OC

z

ff

S8 M:A'74>: '
z



;
$
/ )N

/fi53 F N

?
?!8
, )#&%&'$% *
U 5K :
R?5
P'H4
N??%^_ ff`+Mff-1%fRffc;W _?%ff` :+%?2_ dT1f
#&%&'$%fi* U 53 ; : ] 3N

?
`m
`
+ ff +Q %] :
" _ ff*h
(fi?

*

//m
&
+ ff-1 _T
/ ff

&#
Q &*
U 5f

#&%&'$% / Sm
Fff ff ff-P3?# ffQ*
U 53 ?ff* ffQ5= b<3
?
b#
?T@ffC @ 5m
1 fT ]3
?] ?ff*H #&%&'$% *
p
U 53 K
ffvS N

T;
ff
: %
/ ff"5" N

?
, :
2fi
?(_
!'m
ff`LR1d
@ %LR1
b#
?7@ffCVM@ / : W+ % ?^_ ff
/
+ 5% 7 %)$ 3!

?f%
R P3 fi
?+
/fi)
#&%&'$%L/ ,- ^ %2 :



'$% fi
?T ;N

?
D3W% P+"

/





AP


P

DC



h5j*i

fiff

P

fi }


fiff



|/|

/}





30 {}

b#S@*ff5%f;\53#'7

ff
N #]

/fi5
N! "ff]+



ffff/%WV

6$*n9&%#
h#&%
fi
?!,%A\53#'ff
N #*V
2
(/fi5N

! K%
{
!
3 +i

* /%+
%
# 3 fi
#&% fi ?;6:
R5# *%
/fi
- 1#&%&'$% / j9 %m
ff
5
+ _
Q
ff
RV
P
#
KV
#
S\5
3 #'
?!1

>R

5<
/ F$
# #
U N

?!1<_T!
M=+& v
#
3R F!
#
Rff #-,K 3
;(dU_ffffp?#!1KNWM )+]
%b77 _ ff7
/c5#A#"7! :/fi(
#&%&'$% / 3^
?c
?!1

DC

b#S@ffC5%f

! :

#&%&'$%

/fi =

#&%&'$%

*U 53Q / RV
ff \53 #' N

??
#&%&R6u'$% (9;6: b=3 j9

#&% M'$% 6:
3j9 %% + %
_P1 %_
ff3
_@ d2@7ff $
# #
Hb
V

/ff ff ff5< "N

ff

U _ f
f* ?+ N
53+bS


?
5 #
!1
/

P

b#S@I*%f]! :/fi7 A#&%&'$%

RV
U 53 ?ff*u/
ffp%^%+% T1

h5jo

b#S@ 5%f



?ff*

5



! : /fi =#&%&'$%
*U 53p ?ff* V

/8ffR%F%+%2dT1

fi~}~

~/]{}/}

DC

#&%&'$%



*U53 :
N??K
ffR ff


#Z *!, RB?3#' #R3D
+1yf
+5#'Q %* ?+ /"6:3
!3
3$ffy3+45/%+ M7_@ d2N
@ ff ff ff<5=


U _ n9Wfi/
%#R
#3%$##f5%T%5 ]3 %S W5
S%
5 J^H

b g_
!+ ff1KNW
# #-,
:N/7%#'$% L` "
F$
# #
5% p
R
U N

?;
D%$'H& N

?
3fi H :m/) ff/%# J^ S%
# J 1

/
,5 %H :
m+ %
?A
_
ffi)'HPF % /)68_2
J "d2@9%
5 /3 / (
fi]_
!'m
ffS 1#&%&'$%
*U 53 !1/NO J N

?

+ ?Q1
SN

?
Sm
"
ffB<
U _ 5N

ff* c%
#
dAeTfa

-
, %^ ?+%

3_2J;3f
ff
P_
ff3! ff ff-1
f( _ ff?_!'m ff;

5R

P






b

/

f3ff#R?
N/fi53+3b+Wff3%ffHbR3 ,
N??

8* ?+?!,!fi%#3
N??f433#[?%#-1

!#" <38xr/o>+?82 @n :A' +{z{o5B
fA ff :K b* 5##'RR3 R3?ffP57E_ffY1!8G16W@ffBBC9M,





>R



?
5#/

d+
+ ff
!ff#_ff/^> YH5
_?N??fiM5 ff268>7^ff UR5nV
#i :"Y5%3+ &5 "?n9R ++ff


5 ^_ 68>7'? +ff-,2@ffBBC9N `NWf$57Y
6:
E _
ffG,$@ffBBI*, J%LL@9M1
5 ^_ ?%A2?fiMc+b;Rfff3%# ff
4,{G1 1#,

]% fiN

ff<+3_
fffi 3 % &
% `6 ff3 % #9M,k%
? `NW$
f 57Y UR ff
3^ +b`+4
# ZV ff3 % #`% %/
?!,-%
5 3%ff3 % ff=+p
"5
P_
g c ?fiM
+
b
68W
f %fiff W
f ?_,$@ffBBI*D

3 k
#
ff-,-@ffBBC5D
E _
ff f [
+
b G,-@ffBB 9M,
/
+#
ff{
"
T/
ff" kNW #

)
5


468f [
+
b
5 %,$J%LL@%D ff{
5
f [
+
b G,
@ffBB 59M1
f2
/
+
N

$ *g ?%
?H
5 ^
_ `NW$
f 57Y
, ff3 % ff"+; 3]/fi_ ff,R
c
2
ff
53+ g : f
43
cN

?
?A
* ?+
?;?fiM5
ff
53+ fi`3
ff /fi5% ff #
]_
ff#71 _ ff3 % ff fi
5 +
vfi
5
+
/
!d
ff ff #-
, ?ff* ff {
ff #J51 h5b
, 3 W!/
fiM!0 ]6W@ffBBR@9cH
b&



?#-1
^ P %%
+N

fi
5 ?)+F
+R 3% #p
#
3 +S_
7
ff :
W


ff{
3
1
+ ,) &&
_ )WN 5 )N'VW
#
5#
6 fi
+
b
5 %,7J%LL@9M,T%
5
fi 3 ?+R
3% #N
; #P+7!3 Z % #R
; #-,j K!3 Z % #R
?
%#
fi5* ff
$
/Rff (%
# R?_ff+
fi
!g!3 !1NO
;% 3W/
?83 +
2
+V'
ff#
Z g ?-,fiD
ffP_& )WN 5 )N'VWB
m3D
_ffff*K. 5 5b0
HbR^ ff%$2 / fi !P!3 !,%
5 & <_
;
!m
ffB

<? 5 #`%
#

fi5* ffB#
Z _
,
$ W
&Rff 1;


3 fiM#, /R/


% #
; !,
*
R ff;5
P_
; ff{
5 ;6GJ%LLL*]
9 Sff]c/
3K :
g %

]3

#
5#
3)/fi_ ff,R 3 # [ ?K 2






$
)
ff\5
ffN

ff*]
;N

?
T%
5 ]

+
_d% 3W/
ff5F
! p
)+S_
d!ffF ffR/


% #p
!!1
H %$ 7N

ff* #
ffvfi
5 ?(+N


43


U #
#H :


% #F
%$
!3 cN

ff
P_
5O
1 52
H /

?+
2%
*` ?fi
5 ?dfi;;
* ?+2 :
dV

`3
3A %!,3 #b 2 P!3 !3 Z % #p
#v
#
5#

f5
ff{
2J6XdA3 fib
W# !+!,-@ffBB;
9 _ 6 5 3 +
b G, ` [ ! %,e^,
5 %,@ffBC9M, !"

2 5N
# 5#
41NW"
5N
#
5#

g#/ ^/
5+g !u
ffM ?g

ff

/^

b`
>





b`





Qd





Qa



f

b`

b`



f

!d

f

&f

&c







` b`

ed

` b`

f

c

fi



f

Ua

Sa

h5j5j

f



f

ff

f

fi }


fiff

|/|



/}





30 {}

S^

_c )* ?+%%3?5+5(%# " ff*) 5%12YR/ff\5ff*#FffvM?
fi
ff
/
3ff
U N

/
! !m
, 1 1#,f/!!`# $##pU
N ?
ff=5v
!
#
#v
ffvM ?!;
1 f3(/
3^
+ 5
( $
3%# :
3

N
7;
ff/ %m
3F
%
5R :
g W

S3
N
R ?F%
5 N3!{
, /
ff
5G,
N

ff%^3 5
* ?+

_ ?A8


/H ff* d$
3 % #-1
fff
ff*
fi
5 ?2+v

&3


%2


R ff
F 3W
fiV

53% S/
37 ( F+ fiM 5 #
5#
4p
1 fff ff*#Q!
ff#
_ff

3WV
F
# 5#

Ad 2JVWYRf 6 ff{
5 %, 3 5 -,Rd
> ff !b,
kR
+
b G,J%LLJ]
9 2YRf 6 ff{
5 %,
ff ![ff ,
3 5 -,J%LLJ9c
; +%V' ff<m?#
* ffQ
5
#
5#
4
,

3 fiT+3 /

N

ffN

ff* ffp4_T# 5#
f <Y4? 5#_
ffv 3;/fi_ ff1
NW
+ <m
?#
* p 3 ff
N

$
*v
$5
+ 6 ff
fi/,@ffBBCp

9
#

% ff 3# ?6XYR5 fi/


ff,;@ffBBB9M1 NW
+ <m
?#
* ff
Q_
ff
ff
3 +
4fi fi53* ( 5
# 5#

N

ffN

ff* ffp
c ?fiM

fi
5 ?%5
dN
6XdH
ff-,R@ffBBB9M, 6 , A5
-, i%
_
3!,5@ffBBV
9 7f)_^N 68W
e -,Y5R M3 -,
+?[ #
G,K@ffBB9M1;_ fi fi53*2 g ;m
?#
* ffQ
5p
#
5#
2_
ff&
ffy3 +p
=
ff{
* UR2 FR/


% #
d/
!W
ff ff #6
P_


5 %,kJ%LLL*9M,
ffWS/
3
: ) dM /
!f
ff ff #
# 5#
2YY"? 5#_
ffp 3;/fi_ ff1

`

f

;d

fi

ba

f (d

`

U



`



f

I`

`

>d
c

f



`

ed

f

! z{q('58oz ' +- ?s?4z{oz '74>:#srsz '*'




fi5#%Md!fi%#=
N??Wff53+ %ff_ ff


Nff

%"/3 Q

#[ = da6! ff

+

#/3+5# #g5?6! ff+B/ #+

+ff4 :=3 ,

(i5

] #+

B-9M1

>7'? +ff-,7@ffBBC9S%#

fv_ ? 8#%

B
W
@E@


P/c?7'H] #+5%ff7_ ffpURff#ff#v+ffQ6:+%V' ff V(V!/*9M1



3 fiM#,! Km
?#
* ffdff3 % # ]!!
5d
ff
53+ %,
ff
6

R96
6
R9 56 6

R9 6
%9+;
9 `ff35p
kR
+
b G, 3 5 -
, ff{
5 46GJ%LLL*9M,
5?( < ff

53 #' dM S6 6
R9M/
, G1 1#
, c
5%
j%
9 pff3 % #
d!!
5
6

R9 6
%9M8
1 f3]ff
53+ %
3m! :

3 % #] k
k 2N

?
?A
ffF

5 ^_P1
m??N5 . ff # 0gN

?
?;
* ?+
?!]
, +N

&. ff #
0gN

?

RV
?+

?; 23 ff /%+
i_
" %
b ff *+& !*!;
, 5 #
%/
3 #'
6'. /%+ 3* ?+
# `
+N

! <%
# #/+ 3;
fi* %
0 9


U _ff ff?"6 /%+ 3* ?+ `+=
R#
#R
3R
53"+=
*9
6X
#_
55 %+[
?
[ 3 -,@ffBB 9M1

B

B



DE> H B @E@ ED > H B
MC
@E@ DE> H B E@ @

b`

B

@E@

?

DE> H

SR

f

DE> H

SR

ed
ff
! <38xr/o>+?82 W. qU8qK4>:A+s z{q('58oz '
fi%#4 )ffp/f4Q`57du/6u)+ ffA!+!,kJ%LL@9%%^!3WV
Z/ %_ :M
4
^ K #3R3fiM

Z7[M\ E*V/HKJ>EGXUNUXAYV L [N V&'$% h
! 6 #+ff`

3V!jU3n9%g ffF+7_^

#[ ff-,ff###'1NULGFV HKJ>EGXUNUXAYVbL [N V6#&% $

6 #+ff V!jU3n9c%/ ffP+&_"
jU
#[ ff-1yf
` 57dl/v3Rfi53%"]! :

N?5]D!?T ]=3 ,VD/)%$#&% ?'$% S5!MC 3
!#P+"3%k =_P3 fiMffW#Z *!1(_Tfi53%fi5`+F!fiRV
%R!g ffN/)3F5/cWfi? F1
` 57di*UF5ff/5
/F%#ST_?+#&% ?'$% 75!MC ;\53#'S
N?T :(
N/fi5P!?
KD_
C ff*(?fiM 5!1
h5j

fi~}~

~/]{}/}

`

_ # M%#?+=vfi?& P 57d *U 5g
N %# fi" N+fiM

!fi%#i
N??;ff M?fiM,)5 Dff#v!!5ff,m3 4

N " ffQ
+ 5* P %
ffQ+=_
%
b ff *+`F!*!,K]5!

N??
f _ 68
> ff ff, b% 5+-,
ff,(J%LLL*
9 _T
+ ff %% # %% #
=68_
2936 m5%[ffG,
Y5
fi?!,
?5R, J%LL@9( %^
P/ d!! 5p
4N

c+
?fff3 % #
d_ :


1
5W

# [ ffd!!
5R
3!fi,
! ff, H#

% g
5


P3
1NWR
# #
+/ dfi?S 57d *
U 5$\5
3 #'"N

?
, fN

$
*
! ?)N

?
?
fiM #
Z 768N

?
52 )3+ 5# #
*5


?k_


$9M
, (
5%

68N

?
5
3 fi 3%S3 ff

$9M
, # [ # [ 78
NM d!;68N

?
5
DN

3 #'p
= 5+ %/
3 #'" g3
ff=bR^ ffj9Md
1 f?N

?
?Tm
/
ff
+
!fi
% 7 d?# ;d 2JVWYRf

33
v
#
5#
fi6 ff{
5
!W
G1#, J%LLJ9M1



>_ O^
?d

Wd

>R

`

MC
1`/`

b`

e`

fi

f

! <38xr/o>+?82@:A'58qU:qK4>:A+s

f % 7

3
3 #?[ % #/N

! R)ff ^_
ffN
/fiF_
+ % 3+ ]S%
#
3b??fiM5 :
H

*
?fi5!1]f3;??fiM5`ff*5%ff5
fi5#/p #+/cT
/d _ffff*Hfifi53% ?
%

+
Q _ffff*;fi fi53% p
$
;W

U #
5%+
% B
#
34#6
b !,c@ffBII*D ,
52, !b,@ffBB 5D T*%
-,J%LLL*9M1
fP
3
3 #?[ % #3]

#
3f?# W!_
,
!
ff,-

ff=#p
ff ff*#
+N

D%+ ff* #
%# F3 # 5% #Q ^% &


6X;
fiM-,

b 3 ff,


?

-,H@ffBBB5D ff5
-,
W5
+ ?-,
E 5,J%LLJ5D
> ?

> 5!
ffG,$@ffBBC5D

/ , ^
5
SN

V 5#
,
H{ ? ff-,
J%LL@9Mm
1 fT
3
3 #?[ % #S

#
3]?# ]5

fi5#D

?A :
;
$
?!k_!+ f
+ 5%
/%+ M/+7 ffS ff, ff
% ( )N

/fi53+;
/%+
!{
, ?;/%+
! ,
ff
% /%+ ff#
$
/ :
W%
%W!V # 7\5
?+ #
R1 fff ff*p
* ?+F

]
3
3 #?[ % #&f

#
3?# 7;
R/ff^
ffQ5& ] : ff
%
ff

`5
P_
R
N


U #'" K%


R
?# !1
f? 5* ?+ ffy`N

/fi5"
3
3 #?[ % #3N

! R
$
ff` 3f/fi_ T%
#
]
/
3
3 #?[ % #;N

! RK ;;(
3
3 #?[ % #_


/K_@ d2f
@ ;
+
*(H b5
P_
ff, ff{
5 %_
, E!+ 5 ffb6GJ%LLJ9M1



ff

c










MC



`

R

@c

b

Sd



P

f

K

!]fi

f3/fi_ d?ff*3ffmQ3 B#5#


*!5%ff

*+3ffQ+ff

bR^ff(3 RR?!1bf(3!#RDff
N/5 ?#$*f
N$

_ff # %
U _ WVX
ffN
S3

; q#&%&'$% / 1NO F


fi* %
?mfi
$
#/
3 #';+
TbR^ ff%^ _ ff*( !
ff3 k
ff
53 #?[ % #Q#6 5 !
ff35]

k( /fi5N

! " c
3
#
5#
"9;
ff `\5
3 #'iN

?

%N
ff

?; #
#
\5
3 #' ?D3 +B
ff
53+ F


i3

R
?!%
1 f/fi_ fi
?^ %W

U _ !0 W*#
ffN

ff*
` R #p
R ?W3T
ff ?fi
: %! ?+ 8V
#
% 7bR^ ffc
ff
5% #-1
f
$
ffv
U _ WVX
ffp

33
v
R ?)
3+ ( 7 :#%
N
+ /!
ff
5+
,%% c 5+ W
/fi5% #-
,

/3
{
,


/
!%
ff ff #-_
, + % 3+ 5 fi5 5#?[ % #=)


/!/
,

3
3
3 #?[ % #-, ?WRV
! % #
N!fi
% #-b
1 f)

N
+ /!,*? 5#_
ffD/!
; 3b/fi_ ff
, fi%


3
N
/fff ff #S_
d/
!K -#
5f

/!, :#m
ff/5 %+ % 3+ 5 fi+V

5#?[ % #

/ %b

$
(# +
5+T ffd

? 5 #
!1

OC

DC

h5j

fi }


fiff

|/|



/}





30 {}

YR$; #+5W ?ff*fff*% :M
%#%$W/!, !,3^/#-,
?A 8 #v
3mUR ffN

ff#F
N

$ *;

/%+ M4? 5 #-,5_
ff
2 !F
ff "
U _
+]

/ PN

! P5 fi5 5#?[ % # 3_!+ 5+ 8


/!1 `
V
ff, !
?7
U _ !0 TRff 7 %^ /%+
3ffi
53% 7 :
^ ff

%d
32
+
+# 1;NW
# #-
,

&
3
3 #?[ % #y
ff /< 5+ ]
ff3 %
#
/]
/D
/%+
"#
?A
3


#
* m*+; ?ff
# #
#'
" #3 3 fiM

5%
1
fD?ff* ffBfi
5 <+`? 5 #
#&
?
U _ cbR^ ff%
!

+ 1
52 * ff* #=;
c2+4
v+
+ ff
%c%

3
U _ W
5% c+p



! R#& %P%
N
8
ff B
U _ d< ]bR^ ff]3

R ?!1"NWQ
P
!7,k
$
#/
3 #'/
; #F
R ?f3f
fi* %
P 3fi
5 -1











/



&a

f3$Hbc;$ffc5cF(dm%3


3+^ YR ffmff5#,5YR#ff3
%#-,HYR ffv Y{$!,8
8ffB ff/f%

fWff 3#YR$ K : A?HdH
N_!##ff?!_
_? * 53P6:NYAVM@ffBBBV
@@ *B 9M1 E fi& 5% ! 82+ 5
> 5+ B
uk
33ff YR
= :4?43%$5%#
QFU_ 5N

ff*
fi ?fi;3?53+b&

! ff #-,K+^
! 3 5 :
D3
3%$ 5% #

#
3K k _ ff*H\5
3 #'/N

?
?!
, ]+;
f ! 55
E !+ 5 ffb :

R
$
* 5(+S ff3 % ff4H
p
b
3
3 #?[ % #-1



3+&



ff

c

DC

f





f

>R







S/

Sd ?5R, `716GJ%LL@9M1;`fff 5bK -!3Z/ 5K5Nff3
%
ff*2!3Z/ 5!17NWWL J * L VGE E X + 1LONUX 7X#[M\x+N VO\A\ X * V,+GV
ffWL J GV V fiMX + * EJ Z NKV?V,+N
JMLONUF * FVGE*V J/+*Z*VOL V,+GV J/+ 1LONUX 7X#[M\x+N VO\A\ X * V,+GV1Y{5 ff1
d;fiM-,Y15>/1#,Ka b3ff, 1Rf1#,(a
Y?
-, T16W@ffBBB9M1 V [fiMX + * E X +fiX +*Z7JMLC0 [NUX#J/+Y5X EGF([M\
X.-*[NUX#/J +1 `a `>d 8
-1
dA3fib,q1#,/d W# !+!,c176W@ffBB9M1 fdfi2J # #5#
41T
[ X +!V V [MCL +(X + * ,,

m5%[ffG,n1#,Y5fi?!,RdT1#,





P

JCR@ RJh51


N , #+!,O_
C ff#RMP?fiM ff1ANWWL J GV V fiMX + * E J Z &+H+(F([M\
VOLGX [/+ E7J 7X#[NUX#J/+ Z7JML 1LONUX 7X#[M\ x+N VO\A\ X * V,+GV1
fWQ`%fiff!, 1#,?dafW?_, 1k6W@ffBBI9M1)dA3-3 1!T
[ X +!"V V [MCL +(X + * ,#%$j,BBAP@O*C51
f [ f +bG,-Y1#,d ff{5 %f , P16GJ%LL@9M1& VO\ [NUX#/J +?[M(
\ '&[N)[ X +(X + * 1HY{5 ff1
ff5-, P1;a1#, cW5+?-,c 1 c 1#, E 5,_P1H6GJ%LLJ9M1x+*Z7JMCL 0 [NUX#/J +,Y5X EGF([M\ .X -*[NUX#/J +,X +*fiI[N[
0 X +(X + * [/+ fi,++?.J -\ V fi * /
V fiMX E JMYVOL %1 `a `>d 8
-1
ff5-, P1!
1#,3d N'5G, >/1 T1F6W@ffBBJ9M1O52`D3S g*5WVXfiff %+5# ?W
ff 3# 7ff 5%#-1!T
[ X +!"V V [MCL +(X + * ,0, IOP@!LJ51
ff5-, P1
1#,]3%!+b5*VWYfi/,Sc 1#,Sd YR
P5-,?1$6W@ffBBC9M1
%P
2+PbR^ff
3 _T !71NW 1fiMYM/
[ +GVGEX +32+?.J -\ V fi * !V 'eX E JMYVOL &/[ + fi4'&[N4[ X +(X + * 1_T_T_^N

dHff-, E

1 E

1K6W@ffBBB9M12_

/J +*Z*VOL ,V +GVJ Z &0

)?!1









h5j5h

fi~}~

~/]{}/}

ff-, ;1#,d Yfi/,
`71 126W@ffBBC9M1 U_ 5
Nff*S%# ! $5+ #5#
41 NW
W L J GV V fiMX + * E/J Z NKV ( XALON V V,+Nx+N VOLC+?[NUX#J/+?[M\ J/+*Z*VOL V,+GV J/+/T[ X +!V V [MLC+(X + * 1Ma 5


?fiM1

c
P_ ff,Pf1#,&d ff{5 %f ,P1]6GJ%LLL*9M1 dHR/M
%# !!1 NW WL J GV V fiMX + * E J Z NKV
JMFSLON WFSL J H(V [/+ J/+*Z*VOL V,+GVfiJ/+*WLGX +7X H?\ VGE@J Z,'&[N[ X +(X + * [/+ fi 2+?J.-\ V fi * V 'eX E JMY
VOL %1$Y{5 ff1
c
P_ ff, f1#, ff{5 %f , P1#,d E!+5 ffb,-f1k6GJ%LLJ9M1(YR33#[?%#-R_
N!R
Dfi 3 %#R$ 3%#R ff1RNW)WL J GV
V fiMX + * EbJ Z N KV x+N VOCL +?[NUX#/J +?[M\fiJML +5E SJ H
/J + x+N VO\A\ X * ,V +ffN '&[N[ &+?[M\ >EGX EeX + V fiMX 7X +!V&/[ + fi3 S[MCL 0 [ JM\ J * ' ! #
#1
c
P_ ff,f1#,Id YRf
%,fic16GJ%LL@9M1qff + \ X +!V '&[N4[ X +(X + * VOLGYVOnL 1K^` >R H +f b )NW+#,
*+ _j
_
!1 1 ff1
cW!/fiM!,3H 1g6W@ffBBR@9M1d;5p
/3
N_!4ff 53#[?%#!132+?.J -\ V fi * V fi7FSX EGXUNUX#/J +
JMFSCL +?[M\ ,,hCR@PRh%LR1
cT
-, 1#,3c fi_ ff,_P1!
1#,Wc ff,kY1_P1#, eT3%+b5,!
1$_P1K6W@ffBBC9M1dH+WVO_C ff#ff?c
?
Nff*]/
%ff
Nff*F 53+bP #+5!1 JMFSC
L +?[M\?J Z &0 VOLGX /[ + JM\A\ V * /V [ML fiMX#JM\ J * %,
#! ,@!LJ%L P@!Lh%LR1
eW-,Af1#,^Y5R M3-,AY1#,d +[?#G,5126W@ffBB9M1 _ ff*" 5 #5#
Yfi 3ff
+3UR7!3Z %#-1PNWWL J GV V fiMX + * EJ Z N KV
fiJML +5E SJ H /J + V [MCL +(X + * ZGL /J 0 ?VIN
[N V * JMLG.X -*[NUX#/J +1
fi+bG, 1#,/d ff{5 %f , P1P6GJ%LL@9M1 dA3Z %# M&?fiM%# _&)` NW5b)` N'VWdT1 NW
WL J * L VGE EbX + 1LONUX 7X#[M\ x+N VO\A\ X * ,V +GV
WL J GV V fiMX + * EeJ Z1N K,
V ?,V +N / JMLONUF * FVGE*)V /J +*Z*VOL ,V +GV /J +
1LONUX 7X#[M\ x+N VO\A\ X * ,V +GV1Y{5 ff1
>?
4,f1 _P1#,a
>5!ffG,eP11k6W@ffBBC9M1 33#[?%#ff5\5?( :^
;3fi7%%/?!

N/fi53+-1 KL /
[ +KE7[ *NUX#/J +KE /J + 2+?.J -\ V fi * V /[ + fi3'&[N[q + * X +!V VOLGX + * ,(0,BJhAPRBh51
>ff ff,1#,?b% 5+-,*Nn1#, ff,eP16GJ%LLL*9M1k_T*!5%ff] g :g
#5# 53%5b
7%
#5#
!1 NW
( #

fiJML +5E SJ H /J + V7N.[ V [MCL +(X + * FSXA\ fiMX + *
1FKN/J 0 [NUX 1fiMY5X GV ?NUL [N V * XVGEZ7JM4L
J fi VO\ VO\ V *NUX#/J +/[ + fi)V7N
J fi /J 0 OX +?[NUX#/J +1


























>7'? +ff-,KE

1T6W@ffBBC9M1



U #5RF_

1fiMYM[/+GVGEQX + 2+?J.-\ V fi *
V 'eX E



#/%+




#3+5%!3
+ + * 1 `ffN )?!1

JMYVOL [/+ fi)'&[N[3 X (X Ka



>cffb,Nn1k6W@ffBBh9M1HNW#d ;ff?3=?fiMN4
Nff -3%3!1

x+
* ,+ , !,hR@I RhhI*1

3+*!1

HIH?\ XV fi 1LONUX

7X#[M\ N VO\A\ X V GV OP
ff{5 %
f [ f +bG,Y16W@ffBB>59M14x+ fiMF*NUXAYV"3J * X WL J * L [/00 X + * "?V ?+(Xfi7FVGE [/+ fi HIH?\ X [.
f , P1#,!a
NUX#/J +KnE 1 33He^H5R-1
ff{5 %
f , P1#,
35-,1#,F>dff f !b, T1#,d kR+bG, 1)6GJ%LLJ9M1i_Tfi&!3Z %#
#+d/3 1 NW,WL J GV V fiMX + * EbJ Z NKV x+N VOLC+?[NUX#J/+?[M\ff J/+*Z*VOL V,+GV
/J + '&[N3
[ X +(X + * 1
ff{5 %
f , P1#, c
P_ ff, f1#,!d M!,H16W@ffBB9M1)_ ff!fi"# ) :^+M#RnV
#-1 x+N VO\A\ X * ,V +N >EON ,V 0&E (KVOXAL HIH?\ X [NUX#/J +KnE , ,!%ff L PS
ff C51
ff{5 %
f , P1#,/f ff![ff ,3H 1#,3d 35-, 1F6GJ%LLJ9M1 2` YRf f` ff3%#b&3 `
/5+WVXM c ?%S+M#-1NWWL J GV V fiMX + * E J ZN KV - VO\ ZON x+N VOCL +?[NUX#/J +?[M4
\ /J +*Z*VOL
,V +GVGE&/J + x+ fiMF *NUXAY4
V 3J * X WL J * L /[ 00 X + * 1Y{5 ff1














NW



h5j

fi }


fiff



|/|



/}



30 {}

!b, 1eP1g6W@ffBBff9M1 U ##"33#[?%# =bR^ffS3WV
WL J GV V MX + * E J ZeNKV XAL EON x+N VOLC+?[NUX#J/+?[M\! J/+*Z*VOL V,+GV&J/+ 2+?J.-\ V fi * V"'eX E JMYVOL
[ &[N[ X (X
, ;1#, A5-, T1S
c 1#,Sd _%3!,1 a16W@ffBB9M1>7^ffVX/ffS?fiMDU #5%+
ff ?fiMRM?H+NffmRff*( fiM ff #'1T[ X +!V V [MLC+(X + * , j, JR@IOP
J>
LR1
3R,eP1#,!d k#ff-,eP16W@ffBBC9M1&52#5#
:)D* ?+ff*ff?!1
NWWL J GV V fiMX + * EJ ,
Z VOCL +!V7NUX OE&/[ + fi >EON ,V 0&E $j1
53+bG,(7` 1-Y1#,`a [ ! %f ,-Nn1#, e^, 1#,?d ff{5 %f , P16W@ffBC9M1%fP
#ZV $ff
NffRV
H?fiM++ff
_ @*
ff #7?+ fi 3 %#<Q "
Nff g
!1"NW
WL J GV V fiMX + * E&J Z N KV X ZON Q[NUX#/J +?[M
\ /J +*Z*VOL ,V +GV&/J + 1LONUX 7X#[M\ x+N VO\A\ X * ,V +GV1S`a 4>d V
;1#, 52,-eP1 1#,
1FNW
fi
/+ fi3' ) + + * 1



,eP1




-1

)+!,> H1#,Md
V [MLC(+ X + *

ffA!+!,c156GJ%LL@9M1 `) +!3Z %#2 :
Nff 3bff*
Nff*!1 T[ X +!V
#,$J%LhAPRJhR@%1


,

K`

YR5fi/, 71 1#,
ff, ;1k6W@ffBBB9M1gNW
Nff$5+D#5#
A;RffV5%ff
ff#!1 + "
C+ + * , !,$JBI RhhC51





T[ X !V V [ML (X

OP

ff
SR
WL J GV V MX EfiJ Z N KV XAL EON N VOL ?[NUX#J ?[M\ J *Z*VOL V GV@J ?J \ V V
eX E JMYVOL [ &[N[ X (X

/MC,*Y1 1#, ^5

NV 5#,
1#, H{?ff-,a1*eP1 6GJ%LL@9M1WL J GV V fiMX + * E J Z/NKV 2"'4'
#
fiJML +5E SJ H /J +3X EGF([M
\ '&[N)[ X +(X + * 1
kR+bG, 1#,S 35-, 1#,Kd ff{5 %
f , P1-6GJ%LLL*9M16)ff#%_ :M
^ m?#*ffFff3%#
!!51&NW WL J GV
V fiMX + * EfiJ ZN KV JMFSLON WFSL J H(V /[ + /J +*Z*VOL ,V +GV@/J + WLGX +7X H?\ VGE9J )Z '&[N[
X +(X + * /[ + fi32+?.J -\ V fi * "
V 'eX E JMYVOL %1$Y{5 ff1
b!, 1E 16W@ffBII9M1 GH?\ JML [NJML '&[N[ &+?[M\ >EGX n
E 1g_T3+"E?!1
T*%-,fi_P1 6GJ%LLL*9M1
3X EGF([M\ .X -*[NUX#/J + Z7JML fiI[N[ 0 X +(X + * 1
*+ _
_ ))P@%1
%-1 ZV
+ 1 >

_ j*%?j_ _T*+*R_%G_ 3 fiff>c?fWffffJ%LLLR1 - O1
YRf
%,c1#,?
c
P_ ff, f1#,?d >5+ f %,3c 1k6GJ%LL@9M1)dH
P/;_ #[ ffFp_ #[ ff

5;?fiMF #3^ F]dAeTf /%ff*c%%/1cNW WL J GV V fiMX + * E J Z WX * N
/J +*Z*VOL ,V +GV/J + 1LONUX 7X#[M
\ x+N VO\A\ X * ,V +GVeX + V fiMX 7X +!VQX + WFSL J H(V 1-Y{5 ff1
E_ffG,Y1g6W@ffBBI9M13_TB#5#
:
#ZVff3%#K3 & /!1/NW WL J GV V fi.
X + * E J Z&N KV XAL EON WFSL J H(V /[ + /0/HKJ>EGXAF 0 /J + WLGX +7X H?\ VGE J "Z '&[N,[ X +(X + * /[ + fi,2+?.J -\ V fi * V
'eX E JMYVOL %1$Y{5 ff1
Y#_ 55%+[,_P1#, [?3-,%_P16W@ffBB 9M1 52 ff#^
N??F V* ?+?);bR^ZV
ff43 1=NW*
fi + *

1x+ C+
/+ /+ ,+ /+ 2+ .- fi *
'
/+ fi3' ) + + * 1_T_T_^N1)?!1







E_ffG,Y1K6GJ%LL@9M1NW#;#5

] :2bR^ff/3 =%%/?!17NW

/+ (' 3 + + * 1 {Y 5 ff1

VO\ [NUX#J ?[M\ &[N[ X (X
E_ffG,Y1#, f [ f +bG,kY1K6W@ffBBff9M1fN ?5#`?fiM ff
4/k;fiM]ffRV
5
/RffZV'!ffk##4 g%"
3N )1^NWWL J GV V fiMX + * E [ * LGF5HIH(V,+NUL VfiffbV,+
T[>E X +!VO\A\ VG4
E VOCL +!,V +1 T#1fT
-1
E_ff Y1#,E!+5 ffb,Rf1#, bfi
/,*_P1Nn1#,5Y!_?!,%_P1#,Ia 3R,eP1#,>c;%b5bffG,IH
1#, >7#{?WV
ff-,E 16W@ffBBC9M1 W * 5##'4 33fiR %]
1HNW WL J GV V fiMX + * E J Z
N K
V /VOCL 0 /[ + fiJML +5E SJ H /J + T[ X +!4V V [MCL +(X + * 1 T#1d;ff
S#+[1
h5j

fiJournal Artificial Intelligence Research 17 (2002) 309-332

Submitted 06/02; published 10/02

Analysis Phase Transition NK Landscapes
Yong Gao
Joseph Culberson

ygao@cs.ualberta.ca
joe@cs.ualberta.ca

Department Computing Science
University Alberta
Edmonton, Alberta, Canada, T6G 2H1

Abstract
paper, analyze decision version NK landscape model
perspective threshold phenomena phase transitions two random distributions,
uniform probability model fixed ratio model. uniform probability
model, prove phase transition easy sense polynomial
algorithm solve random instance problem probability asymptotic
1 problem size tends infinity. fixed ratio model, establish several
upper bounds solubility threshold, prove random instances parameters
upper bounds solved polynomially. This, together empirical
study random instances generated phase transition region, suggests
phase transition fixed ratio model also easy.

1. Introduction
NK landscape fitness landscape model devised Kauffman (1989). appealing
property NK landscape ruggedness landscape tuned
changing parameters. years, NK landscape model
studied perspectives statistics computational complexity (Weinberger, 1996;
Wright, Thompson, & Zhang, 2000). study genetic algorithms, NK landscape
models used prototype benchmark analysis performance
different genetic operators effects different encoding methods algorithms
performance (Altenberg, 1997; Hordijk, 1997; Jones, 1995).
field combinatorial search optimization, one interesting discoveries
threshold phenomena phase transitions. Roughly speaking, phase transition
combinatorial search refers phenomenon probability random instance
problem solution drops abruptly 1 0 order parameter
random model crosses critical value called threshold. Closely related phase
transition solubility hardness solving problems. strong empirical evidence theoretical arguments showing hardest instances problems
usually occur around threshold instances generated parameters far away
threshold relatively easy. Since seminal work Cheeseman et al. (Cheeseman, Kanefsky, & Taylor, 1991), many NP-complete combinatorial search problems
shown phase transition associated easy-hard-easy pattern (Cook
& Mitchell, 1997; Culberson & Gent, 2001; Freeman, 1996; Gent, MacIntyre, Prosser, &

c
2002
AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiGao & Culberson

Walsh, 1998; Kirkpatrick & Selman, 1994; Mitchell, Selman, & Levesque, 1992; Vandegriend
& Culberson, 1998).
paper, analyze NK landscape model perspective threshold
phenomena phase transitions. establish two random models decision problem
NK landscapes study threshold phenomena associated hardness
phase transitions two models.
rest paper organized follows. Section 2, introduce NK fitness
landscape probabilistic models, uniform probability model fixed ratio
model. Section 3 Section 4, threshold phenomena phase transitions
NK landscapes analyzed. uniform probability model, prove phase
transition uniform probability model easy sense polynomial
algorithm solve random instance problem probability asymptotic
1 problem size tends infinity. fixed ratio model, establish two upper
bounds solubility threshold, prove random instances parameters
upper bounds solved polynomially. This, together empirical study
random instances generated phase transition region, suggests
phase transition fixed ratio model also easy. Section 5, report
experimental results typical hardness fixed ratio model. Section 6, conclude
investigation discuss implications results.

2. NK Landscapes Probabilistic Models
NK landscape f (x) =

n
P

fi (xi , (xi )), real-valued function defined binary strings

i=1

fixed length, n > 0 positive integer x = (x1 , , xn ) {0, 1}n . sum
n local fitness functions fi , 1 n. local fitness function fi (xi , (xi )) depends
main variable xi neighborhood (xi ) Pk ({x1 , , xn }\{xi }) Pk (X)
denotes set subsets size k X. important parameters NK
landscape number variables n, size neighborhood k = |(xi )|.
NK landscape, neighborhood (xi ) chosen two ways: random
neighborhood, k variables randomly chosen set {x1 , , xn }\{xi },
adjacent neighborhood, k variables indices nearest (modulo n)
chosen. example, even integer k, k variables (xi ) defined
x((n+i k ) mod n) , , x((n+i+ k ) mod n) . variables neighborhood deter2
2
mined, local fitness function fi determined fitness lookup table specifies
function value fi 2k+1 possible assignments variables xi (xi ).
Throughout paper, consider NK landscapes random neighborhoods.
simplify discussion, assume local fitness functions take binary
values. Given NK landscape f , corresponding decision problem stated follows:
maximum f (x) equal n? NK landscape decision problem insoluble
solution it.
proved NK landscape model NP complete k 2 (e.g.,
Weinberger, 1996; Wright et al., 2000). proofs based reduction SAT
decision problem NK landscapes. study typical hardness NK landscape
decision problems framework thresholds phase transitions, introduce two

310

fiPhase Transition NK Landscapes

random models. models defined below, neighborhood set (xi )
variable xi selected randomly choosing without replacement k = |(xi )| variables
x\{xi }.
Definition 2.1. Uniform Probability Model N (n, k, p): model, fitness value
local fitness function fi (xi , (xi )) determined follows: assignment
Dom(fi ) = {0, 1}k+1 , let fi (y) = 0 probability p fi (y) = 1
probability 1 p, done possible assignment local fitness
function independently.
Definition 2.2. Fixed Ratio Model N (n, k, z): model, parameter z takes
values [0, 2k+1 ]. z integer, specify local fitness function fi (xi , (xi ))
randomly choosing without replacement z tuples possible assignments = (y1 , , yz )
Dom(fi ) = {0, 1}k+1 , defining local fitness function follows:

0, ;
fi (y) =
1, else.
non-integer z = (1 )[z] + [z + 1] [z] integer part z, choose
randomly without replacement [(1 )n] local fitness functions determine fitness
values according N (n, k, [z]). rest local fitness functions determined according N (n, k, [z] + 1).
theory random graphs, two related random models G(n, p)
n(n1)
possible edges included graph independently probability
2
p, G(n, m) exactly edges chosen randomly without replacement
set n(n1)
possible edges. well known monotone graph
2
properties, results proved G(n, p) (or G(n, m)) also hold asymptotically G(n, N p)

(correspondingly, G(n, N
)) N = n(n1)
. However, cannot expect similar
2
relations exist two random models NK landscapes defined unless
parameter k tends infinity. result, asymptotic behaviors two NK landscape
models significantly different fixed k.
conclude section establishing relation decision problem NK
landscapes SAT problem. decision problem NK landscape
f (x) =

n
X

fi (xi , (xi )),

i=1

maximum f (x) equal greater n?, reduced (k+1)-SAT problem
follows:
z
V
(1) local fitness function fi (xi , (xi )), construct conjunction Ci =
Cij
j=1

clauses exactly k + 1 variable-distinct literals set variables {xi , (xi )},
z number zero values fi takes Cij assignment
yj {0, 1}k+1 falsifies Cij , fi (yj ) = 0.
n
V
(2) (k+1)-SAT conjunction =
Ci .
i=1

311

fiGao & Culberson

x
0
0
0
0
1
1
1
1


0
0
1
1
0
0
1
1

z
0
1
0
1
0
1
0
1

fi
0
1
1
0
1
0
0
1

Clauses
xyz

x z
x z
x z

Table 1: local fitness function equivalent 3-clauses.

Table 1 shows example fitness assignment local fitness function fi = fi (x, y, z)
associated equivalent 3-SAT clauses. easy see assignment
variables x, y, z, fi (s) = 1 assignment satisfies formula
x z, x z, x z, x z.

3. Analysis Uniform Probability Model
uniform probability model N (n, k, p), parameter p determines many zero
values local fitness function take. interested solubility hardness
NK landscape decision problem change parameter p increases 0 1.
turns fixed p > 0, decision problem asymptotically trivially insoluble.
quite similar phenomena random models constraint satisfaction
problem observed Achlioptas et al. (1997).
gain insight problem, consider case p = p(n)
function problem size n lim p(n) = 0. analysis shows solubility
n

problem depends fast p(n) decreases:
(1)
1

lim p(n)n 2k+1 = +,

(3.1)

n

problem still asymptotically trivially insoluble probability asymptotic 1, least one local fitness function always fitness value 0;
(2) hand p(n) decreases fast enough, i.e.,
1

lim p(n)n 2k+1 < +,

(3.2)

n

problem decomposed set independent sub-problems. either case
problem solved polynomial time. case (3.1) difficult prove,
prove case (3.2), need make use following concepts results.
Definition 3.1. connection graph NK landscape instance f (x) =

n
P
i=1

graph G = G(V, E) satisfying
312

fi (xi , (xi ))

fiPhase Transition NK Landscapes

(1) vertex v V corresponds local fitness function;
(2)There edge vi , vj corresponding local fitness functions
fi , fj share variables, i.e., neighborhoods (xi ) (xj ) xi xj non-empty
intersection, least one zero value.
Definition 3.2. Let f (x) =

n
P

fi (xi , (xi )) NK landscape instance con-

i=1

nection graph G = G(V, E). Let G1 , , Gl connected components G. Since
vertices G correspond local fitness functions, regard Gi set local fitness
functions. 1 l, let Ui x = (x1 , , xn ) set variables appear
definition local fitness functions Gi .
easy see (U1 , Ul ) excluding independent vertices forms disjoint partition
(a subset of) variables x = (x1 , , xn ), local fitness functions Gi
depend variables Ui . Furthermore, NK decision problem soluble
1 l, assignment si {0, 1}|Ui | variables Ui
local fitness function g Gi , g(s) = 1.
Theorem 3.1 summarizes result uniform probability model.
1

Theorem 3.1. p(n) lim p(n)n 2k+1 exists, k fixed,there polynon

mial time algorithm successfully solves random instance N (n, k, p) probability
asymptotic 1 n tends infinity.
1

1

Proof: consider two cases: lim p(n)n 2k+1 = + lim p(n)n 2k+1 < +.
n

(1) case lim p(n)n
n

1
2k+1

n

= +.

Let Ai event fi (y) = 0 possible assignment {0, 1}k+1 let
n

A=
Ai event least one Ai occurs.
i=1

lim P r{A} = 1 lim P r{

n

n

n
\

Aci }

i=1

= 1 lim (1 p(n)2
n

k+1

)n .

1

shown k fixed lim p(n)n 2k+1 = +, lim P r{A} = 1. follows
n
n
probability asymptotic one, least one local fitness function
takes values 0 possible assignments. therefore show case,
NK decision problem insoluble checking local fitness functions one one.
takes linear time.
1
(2) case lim p(n)n 2k+1 < +.
n
Consider algorithm first finds connected components Gi , 1 l
connection graph G NK model, uses brute force find assignment
si {0, 1}|Ui | variables Ui local fitness function g Gi ,
g(s) = 1. time complexity algorithm O(n2 + n 2M(n,k,p) ) M(n, k, p) =
max(|Ui |, 1 l) maximum size subsets (Ui , 1 l) associated
313

fiGao & Culberson

connected components connection graph. prove theorem, need show
1
M(n, k, p) O(log n). following, show lim p(n)n 2k+1 < +,
n

lim P r{M(n, k, p) 2k + 2} = 1
n

Consider connection graph G = G(V, E) NK model. random graph
edge two nodes two corresponding local fitness functions
share variables local fitness functions take least one zero fitness
value. However, definition edge probabilities independent. vx E
know fx least one zero probability xw E greater
edge x.
deal resort following proof construction. Let Cm = {v1 , . . . , vm }
subset V size m. Let ordering (permutation) v1 . . . vm . say
Cm variable connected respect ordering , denoted C(Cm , ),
i, 2 either
1. j < f(j) f(i) share variable;
2. j, 1 j variable xj one k random variables fi .
Lemma induced subgraph G[Cm ] connected exists least one ordering
v1 . . . vm C(Cm , ).
proof, consider ordering vertices depth first search connected
subgraph. case, connections case 1.
expected number permutations C(Cm , )
Ec = E[|{ : C(Cm , )}|] = m!Pr{C(Cm , )}
observe
expected number connected induced graphs vertices
n
less pm
0 Ec , p0 probability fi takes least one value zero.
show value goes zero limit 2k + 2. Finally, since connected
subgraph vertices must one < m, follows largest
connected component size 2k + 1.
randomly generated permutation Cm , let Ci set first vertices
permutation. 2 define Pi probability f(i) shares least one
variable f(j) j < given C(Ci1 , /1, , 1). Let P1 = 1. (A one
vertex subgraph always connected.)
> 1 Pi = Pr{j < i, f(i) f(j) share variables, given C(Ci1 , )
one k random variables f(i) {x1 . . . xm } {xi }}.
Pr{C(Cm , )} =




Pi .

i=2

Finally, > 1 note Ci1 (i 1)k distinct variables. Ci1
connected number variables may less this. Thus,
nk(i1)m
k

n1
k

Pi 1
314

.

fiPhase Transition NK Landscapes

combinatorial part reduces
(n k(i 1) m) . . . (n k(i 1) k + 1)
(n 1) . . . (n k)


n ki + 1 k

.
n1
So, Pr{C(Cm , )}






1

i=2

n ki + 1
n1

k !

!m1
km + 2 k

1 1
n1
m1 !
1

, m, k fixed.
n



Noting pm


n 2k +1 , see expected number connected subgraphs
0
size bounded

m1 !

1
n
2k +1
p0
Ec n n

n
goes zero = 2k +2. follows M(n, k, p) less 2k +2 probability
asymptotic 1. completes proof.

4. Analysis Fixed Ratio Model
discussed previous section, uniform probability model N (n, k, p)
NK landscapes asymptotically trivial. Part cause asymptotic triviality lies
fact parameter p decrease quickly n, asymptotically
least one local fitness function takes value 0 possible
assignments, making whole decision problem insoluble. section, study
fixed ratio model N (n, k, z). model, require local fitness function
fixed number zero values trivially insoluble situation uniform probability
model avoided. note idea used study flawless
CSP (Gent et al., 1998).
Recall fixed ratio model, choose neighborhood structure local
fitness way uniform probability model N (n, k, p). determine
fitness value local fitness function fi , randomly without replacement select exactly
z tuples {s1 , , sz } {0, 1}k+1 , let fi (sj ) = 0 1 j z fi (s) = 1
every {0, 1}k+1 .
fixed ratio model, interested probability instance
N (n, k, z) soluble changes parameter z increases 0 2k+1 . easy
n
P
see property exists assignment x f (x) =
fi (xi , (xi )) = n
i=1

315

fiGao & Culberson

monotone parameter z number tuples local fitness function takes
zero. Actually, following Lemma property solubility probability
fixed ratio model:
Lemma 4.1. fixed ratio model, z1 > z2 ,
P r{N (n, k, z1 )is soluble} P r{N (n, k, z2 )is soluble}.
Furthermore,

P r{N (n, k, z)is soluble} =

1, z 1;
0, z = 2k+1 .

Based Lemma parallel study threshold phenomena
random combinatorial structures 3-Coloring random graphs random
3-SAT, suggest following conjecture:
Conjecture 4.1. exists threshold zc

1, z < zc ;
lim P r{N (n, k, z)is soluble} =
n
0, z > zc .
Conjectures like starting point study phase transition many
random combinatorial structures 3-coloring random graphs random SAT,
existence thresholds still open question (Achlioptas, 1999; Cook &
Mitchell, 1997). However, bounding thresholds important topic
study phase transition (Achlioptas, 1999, 2001; Dubois, 2001; Franco & Gelder, 1998;
Franco & Paul, 1983; Frieze & Suen, 1996; Kirousis, P.Kranakis, D.Krizanc, & Y.Stamation,
1994). section, establish two upper bounds threshold parameter
zc , theoretically prove random instances generated parameter z
upper bounds solved probability asymptotic 1 polynomial (even
linear) algorithms.
Characterizing sharpness thresholds also great interest study
phase transition. proving every monotone graph property threshold
behavior (Friedgut & Kalai, 1996), Friedgut (1999) established necessary sufficient
condition monotone graph property sharp threshold, used
prove sharpness thresholds 3-colorability 3-SAT problems (Friedgut, 1999;
Achlioptas, 1999). fixed ratio model discussed paper, suspect
exhibit coarse threshold behavior, would like leave detailed investigation
problem future research direction.
4.1 Upper Bound z = 3.0
derivation upper bound based concept conflicting pair local
fitness functions. say two local fitness functions fi fj conflict

1. fi fj share least one variable x;
316

fiPhase Transition NK Landscapes

2. assignment {0, 1}n , fi (s)fj (s) = 0.
obvious instance NK decision problem insoluble exists pair
conflicting local fitness functions.
Based second moment method theory probability (Alon & Spencer,
1992), prove following upper bound result. takes linear time check
pair conflicting local fitness functions, see fixed ratio model
N (n, 2, z) linearly solvable z > 3.0.
Theorem 4.1. Define event conflicting pair local fitness
functions N (n, 2, z). fixed ratio model N (n, 2, z) z = 3.0 + ,
lim P r{A} = 1
n

thus problem insoluble probability asymptotic 1.
Proof: Without loss generality, may write f fi 4 zeroes fitness
value assignment 1 n, 3 zeroes n + 1 n. Let Iij indicator
function event fi fj conflicts other, i.e.,

1, fi fj conflicts other;
Iij =
0, else.
P
Iij . claim lim P r{S = 0} = 0.
=
1i,jn

n

Chebyschevs inequality,
P r{S = 0} P r{|S E(S)| E(S)}
V ar(S)

.
(E(S)2 )

(4.3)

Since 1 n, fi exactly 4 zeros fitness value assignment, know
two local fitness function fi , fj , 1 i, j n, conflict
exactly one common variable x one following true: (1)fi (s) =
0(or 1), fj (s) = 1(or 0) assignments x = 1(respectively x = 0);
(2)fi (s) = 1(or 0), fj (s) = 0(or 1) assignments x = 1(respectively x =
0);
Since probability two local fitness functions share least one variable equal



n2 n4
1

2
2
n1 n1 ,
2
2




P r{Iij = 1} =

1

1
= ( ),
n

!

n2 n4
2
2
n1 n1
2
2

2

1

8

!2

4

> 0, 1 i, j n,

317

(4.4)

fiGao & Culberson

hence,
X

E(S) =

X

E(Iij ) =

1i,jn

P r{Iij = 1} (n).

1i,jn

P

consider variance S. Since =

Iij ,

1i,jn

P
V ar(S) =

P

V ar(Iij ) + 2

i,j

[E{Iij Ilm } E{Iij }E{Ilm }]

(i,j)6=(l,m)

.

(E(S))2

Let

P
A1 =



P

2
A2 =

V ar(Iij )

i,j

(E(S))2

[E{Iij Ilm } E{Iij }E{Ilm }]

(i,j)6=(l,m)

(E(S))2

.

easy see lim A1 = 0. prove lim A2 = 0, consider two cases:
n
n
Case 1: 6= j 6= 6= l. case, two random variables Iij Ilm actually
independent. follows E{Iij Ilm } E{Iij }E{Ilm } = 0.
Case 2: (i, j) 6= (l, m), one common, say j = l. case,
2 !
1
E{Iij Ilm } E{Iij }E{Ilm } = P r{Iij = 1}P r{Ijm = 1|Iij = 1}
n

2 !
1
1
=
P r{Ijm = 1|Iij = 1}
n
n
Given fi fj conflict other, conditional probability fj fm
conflict still ( n1 ).
3 pairs
SincePthere Cn
ij
jm satisfying condition Case 2, know

[E{Iij Ilm } E{Iij }E{Ilm }] (n). therefore, lim A2 = 0. follows
n

(i,j)6=(l,m)



V ar(S)
= 0.
n (E(S)2 )

lim P r{S = 0} lim

n

Since event {S > 0} implies exists conflicting pair local fitness functions,
theorem follows.
4.2 2-SAT Sub-problems N (n, 2, z) Tighter Upper Bound
subsection, establish tighter upper bound z > 2.837 threshold fixed
ratio model N (n, 2, z) showing asymptotically N (n, 2, z) contains unsatisfiable
2-SAT sub-problem probability 1 value z greater 2.873. also
gives us polynomial time algorithm determines N (n, 2, z) insoluble
probability asymptotic 1 z > 2.837.
318

fiPhase Transition NK Landscapes

Recall Section 2 instance N (n, 2, z) equivalent 3-SAT instance.
idea show probability asymptotic 1, instance N (n, 2, z)
contain set specially structured 3-clauses, called t-3-module (Definition 10.3, Franco
& Gelder, 1998):
= {M1 , . . . , M3p+2 }, = 3p + 2,

M1 = (u1 u2 z1 , u1 u2 z1 );

Mp1 = (up1 zp1 , up1 zp1 );
Mp = (up u0 zp , u0 zp );
Mp+1 = (up+1 up+2 zp+1 , up+1 up+2 zp+1 );

M3p1 = (u3p1 u3p z3p1 , u3p1 u3p z3p1 );
M3p = (u3p u0 z3p , u3p u0 z3p )
M3p+1 = (u0 u1 z3p+1 , u0 u1 z3p+1 );
M3p+2 = (u0 up+1 z3p+2 , u0 up+1 z3p+2 );
u1 , , u3p+1 , z1 , , z3p+1 binary variables. Notice t-3-module reduced 2-SAT problem containing two contradictory cycles hence unsatisfiable.
result proved two steps. first step, shown z > 2.837
average number t-3-modules contained N (n, 2, z) tends infinity n increases.
second step, use result established Alon Spencer (1992) second
moment method prove z > 2.837 probability N (n, 2, z) contains least
one t-3-module tends 1.
Let us start first step show average number t-3-modules contained
N (n, 2, z) tends infinity n increases.
Definition 4.1. Given t-3-module NK landscape instance f =

n
P

fi , k = 2,

i=1

sequence local fitness functions
g = (g1 , , gt ) (f1 , , fn )
said possible match(PM) 1 t, main variable gm one
three variables occur 3-module Mm . subsequence (h1 , , hl ) possible
match g legal 1 < j l, hm 6= hj .
Lemma 4.2. Let f (x) =

n
P

fi (xi , (xi )) instance N (n, 2, z) t-3-

i=1


module. number possible matches
t-3-module 3 . Further,

number legal possible matches ( 3+2 5 )t .

319

fiGao & Culberson

Proof: 1 t, exactly 3 possible choices gm :
fi1 (xi1 , (xi1 )), fi2 (xi2 , (xi2 )), fi3 (xi3 , (xi3 )),
xi1 , xi2 , xi3 correspond three variables occur 3-module Mm .
Therefore, 3t possible matches t-3-module.
prove second conclusion, divide t-3-module 3 parts = (M1 , M2 , M3 ),
M1 = (Mm , 1 p), M2 = (Mm , p + 1 3p 1), M3 =
(M3p , M3p+1 , M3p+2 ). Letting L1 , L2 , L3 number legal possible matches
M1 , M2 , M3 respectively. Since literals M1 variable-distinct literals
M2 , number legal possible matches, L, t-3-module satisfies
L1 L2 L 27L1 L2 .
estimate order L1 . end, consider probability space (, P ),
set sequences (g1 , , gp ) local fitness functions possibly match M1
P uniform probability distribution. Then, number legal possible matches

L1 = || P r{a random sample legal}
(4.5)
Let g = (g1 , , gp ) random sample xgm denote main variable
local fitness function gm ,
1
P r{xgm = |um |} = P r{xgm = |um+1 |} = P r{xgm = |zm |} = ,
3
|u| denotes variable corresponding literal u.
Let Bm , 0 < p event first local fitness functions g1 , , gm
possible match g = (g1 , , gp ) mutually distinct. Since M1 consecutive
3-modules share variables,
Bm = {(g1 , , gm ) : gi 6= gi+1 , 1 1}.
Let bm = P r{gm 6= gm1 | Bm1 }, 2, b1 = 1. Notice B1 = . Then,
P r{g = (g1 , , gp )is legal} = P r{Bp }
= P r{g1 6= g2 , g2 6= g3 , , gp1 6= gp }
= P r{B1 }P r{g2 6= g1 | B1 } P r{g3 6= g2 | B2 } P r{gp 6= gp1 | Bp1 }

(4.6)

= b1 b2 bp
Recalling xgm denotes main variable local fitness function gm ,
bp = P r{gp1 6= gp , xgp1 = |up | | Bp1 } + P r{gp1 6= gp , xgp1 6= |up | | Bp1 }
= P r{gp1 6= gp | Bp1 , xgp1 = |up |} P r{xgp1 = |up | | Bp1 } +
P r{gp1 6= gp | Bp1 , xgp1 6= |up |} P r{xgp1 6= |up | | Bp1 }
2
ap + (1 ap )
=
3
1
= 1 ap ,
3
320

(4.7)

fiPhase Transition NK Landscapes

ap = P r{xgp1 = |up | | Bp1 }. ap ,
P r{Bp1 , xgp1 = |up |}
P r{Bp1 }
1
=
(P r{Bp1 , xgp1 = |up |, xgp2 = |up1 |}
P r{Bp1 }

ap =

+ P r{Bp1 , xgp1 = |up |, xgp2 6= |up1 |})
(4.8)
1
=
(P r{xgp1 = |up | | Bp1 , xgp2 = |up1 |} P r{Bp1 , xgp2 = |up1 |}
P r{Bp1 }
+ P r{xgp1 = |up | | Bp1 , xgp2 6= |up1 |} P r{Bp1 , xgp2 6= |up1 |})


1
1
1
=
P r{Bp1 , xgp2 = |up1 |} + P r{Bp1 , xgp2 6= |up1 |}
P r{Bp1 } 2
3
last equation formula given Bp1 xgp2 = |up1 |
(or xgp2 6= |up1 |), two (three, respectively) choices selecting local fitness
function gp1 . Consider two terms P r{Bp1 , xgp2 = |up1 |} P r{Bp1 , xgp2 6=
|up1 |} (4.8),
P r{Bp1 , xgp2 = |up1 |}
= P r{gp2 6= gp1 | Bp2 , xgp2 = |up1 |} P r{Bp2 , xgp2 = |up1 |}
2
= Pr{xgp2 = |up1 | | Bp2 } P r{Bp2 }
3
2
= ap1 P r{Bp2 }
3

(4.9)


P r{Bp1 , xgp2 6= |up1 |}
= P r{gp2 6= gp1 | Bp2 , xgp2 6= |up1 |} P r{Bp2 , xgp2 6= |up1 |}
= P r{xgp2 6= |up1 | | Bp2 } P r{Bp2 }

(4.10)

= (1 ap1 ) P r{Bp2 }
plugging (4.9) (4.10) (4.8), get


P r{Bp2 } 1
1
1
ap =
ap1 + (1 ap1 ) =
.
P r{Bp1 } 3
3
3bp1
This, together (4.7), gives us
bp = 1

1
.
9bp1

(4.11)

difficult show sequence {bp } decreasing lower bounded 0.
Letting lim bp = b taking limit sides, get
p

b=1
321

1
,
9b

(4.12)

fiGao & Culberson

thus, b =
thus,


3 5
6 .

case, b =


3+ 5
6

b 1 bp

since b1 = 1. follows bp b =

prove expected number legal possible matches L1 M1

3+ 5
6



!p
3+ 5
.
6

(4.5), know number legal possible matches greater
!p
!p
3
+
5
3
+
5
3p
=
.
6
2

let p = bp


3+ 5
6



(4.13)
p
3+ 5
,
2

= bp b. (4.11) (4.12),
p = bp b =

means series

p
P

bp1 b
dp1 , 0 < < 1,
9bbp1

convergent. follows

m=1

(1 +

p
1
) (1 +
)
b
b

converges finite positive constant c. Therefore,
b1 bp = (b + 1 ) (b + p )


p
1
= bp 1 +
1 +
b
b
!p
3+ 5
c
6

(4.14)

sufficient large p constant c.
show number legal possible matches L2 M2
Similarly,
2p+2
3+ 5

. Recalling number legal possible matches L t-3-module
2
satisfies L1 L2 L 27L1 L2 , second conclusion follows.
following Lemma calculates probability matching local fitness function
implies matched 3-module.
Lemma 4.3. Given 3-module x w, x w, local fitness function g
main variable xg g one three Boolean variables |x|, |y|, |w|, let z =
2 + , 0 1 parameter fixed ratio model N (n, 2, z). probability
g contains 3-module
!

1
1
6

p0 =
(1 ) +
(4.15)
n1
28
56
2

322

fiPhase Transition NK Landscapes

Proof: Since xg already one variables 3-module, probability
1
two variables also 3-module n1
.
( 2 )
Now, assume variables local fitness function g
variables 3-module. definition fixed ratio model, g two zeros
fitness value assignment probability (1 ), three zeros fitness
assignment probability . Note local fitness function g implies 3-module
x w, x w
g(x, y, w) = 0

g(x, y, w) = 0.

definition fixed ratio model, happens probability
1
6


8 (1 ) + 8
2

3

Lemma follows.
preparation, prove average number t-3-modules
contained N (n, 2, z) tends infinity.
Theorem 4.2. Let number t-3-modules contained N (n, 2, z) =
(ln2 n). Then, z = 2 + > 2.837,
lim E{At } = .

n

(4.16)



Proof: Lemma 4.2, ( 3+2 5 )t legal possible matches fixed
t-3-module. Lemma 4.3, know possible legal match g = {g1 , , gt }
implies t-3-module probability pt0 . proof Theorem 10.1 (Franco &
Gelder, 1998),
2t2 nt1 (n + 1)t
(4.17)

n!
1
6
possible t-3-modules, nt1 = (nt+1)!
. Let r = 28
(1 ) + 56
, write p0 =
1
r.
(n1
2 )
E{At } =

=

=

=
=

!t

3+ 5
p0 2t2 nt1 (n + 1)t
2
!t
1
3+ 5
r 2t2 nt1 (n + 1)t

n1
2
2
!t
!t
n
2 n (n + 1)t
1
3+ 5
2

r

n1
n
2
4(n + 1)
2
2
!t


3+ 5
4 n (n + 1)t
n
1
r
4(n + 1)
2
(n(n 1))t
n2
2

1

(2(3 + 5)r)t (1
),
4n
n
323

(4.18)

fiGao & Culberson

fourth equation (4.18) due fact positive integer n q
2
q < n2 , nq eq /2n nq nq . follows lim E{At } =
n

2(3 +



5)r > 1.

(4.19)

Solving inequality (4.19) gives us > 0.837, is, z = 2 + > 2.837. proves
Theorem 4.2.
Based Chebychevs inequality, prove N (n, 2, z) contains t-3-modules
probability 1, need show variance , number contained t-3-modules,
o(E{At }). purpose, follow Franco Gelders approach (Lemma 4.1, Franco
& Gelder, 1998) apply second moment method (Alon & Spencer, 1992):
Lemma 4.4. (Alon & Spencer, 1992, Ch. 4.3 Cor 3.5) Given random structure(e.g.,
random CNF formula), let W set substructures consideration, A(w)
set substructures sharing clauses w W . Let Iw = 1 w random
structure 0 otherwise.
(1) elementsP
W symmetric;
(2) = E{
Iw } ;
wW
P
(3)
P r(w | w) = o(), w W ,
wA(w)

n , probability random structure contains substructure tends
1.
use Lemma study 2-SAT sub-problem NK landscapes, view
random structure random instance N (n, 2, z), W set
t-3-modules symmetric definitions(Sections 5 10, Franco & Gelder,
1998).
Theorem 4.3. z = 2 + > 2.837, N (n, 2, z) asymptotically insoluble
probability 1.
Proof:
Let number t-3-modules implied N (n, 2, z) = O(ln2 n).
Theorem 4.2 shows lim E{At } = . Lemma 4.4, enough show
n
w W ,
X
P r(w | w) = o(E{At }),
(4.20)
wA(w)

P r(w | w) conditional probability N (n, 2, z) implies t-3-module w
given implies w, A(w) set t-3-modules sharing clauses w.
Suppose w shares Q, 1 Q 2t clauses w, Q clauses
distributed among q 3-modules. Further, let q1 number 3-modules whose two
clauses shared q2 = q q1 number 3-modules one clause
shared.
Let T1 3-module w shares exactly one clause 3-module T2 w.
claim conditional probability T1 implied N (n, 2, z) given w
implied N (n, 2, z),
1
1
+ O( ).
(4.21)
6
n
324

fiPhase Transition NK Landscapes

Without loss generality, assume T2 = {xyu, xy u} T1 = {xyu, xy u}.
Since w implied N (n, 2, z), local fitness function g = g(|x|, |y|, |u|) implies
T2 . conditional probability T1 implied, less equal P1 + P2
P1 conditional probability g also implies clause x u given g implies
T2 , P2 conditional probability clause x u implied local
fitness functions. definition N (n, 2, z), P1 = 61 . Since local fitness
function implies x u variables g = g(|x|, |y|, |u|),
P2 = O( n1 ). claim proved. follows that, sufficiently large n,
!tq

q 2
3+ 5
1
q1
P r{w | w} c
p0
1

(4.22)
2
6
p0 defined Lemma 4.3 c fixed constant.
Let AQ,q,q2 (w) set t-3-modules share Q clauses w Q
clauses distributed q different 3-modules. before, q1 number 3-modules
whose two clauses shared q2 = q q1 number 3-modules
one clause shared. claim
|AQ,q,q2 (w)| = |A2q,q,0 (w)|6q2 .

(4.23)

A2q,q,0 (w) set t-3-modules share 2q clauses q 3-modules
w. Let = {M1 , , Mt } t-3-module clauses Mi , 1 q
shared w. Let = {M1 , , Mt } t-3-module clauses
Mi , 1 q1 shared 3-modules Mi , q1 + 1 q1 + q2 one
clause shared. Since q2 3-modules, 6 ways choose non-shared
clauses, 6q2 t-3-modules AQ,q,q2 (w) correspond one t-3-module
A2q,q,0 . claims follow. formula (55) (56) (Franco & Gelder, 1998)
(4.23), follows
(
O(t) tq 2(tq) q2
2 n
6
, q p + 1,
n2
|AQ,q,q2 (w)| < O(1)
(4.24)
tq
2(tq)
q
2
n
6
, q > p + 1.
n 2

6
1
1
Let r = 28
(1 ) + 56
, write p0 = n1
r. Then,
( 2 )
|AQ,q,q2 (w)|P r{w | w}


O(t) tq 2(tq) q2 3 + 5 tq 1 q2
2 2 n
6 (
p0 ) ( )
n
2
6
!tq
O(t)
1
3+ 5
2 2tq n2(tq)
r

n1 tq
n
2

(4.25)

2


O(t) 1
(2(3 + 5)r))tq
n 4n

O(t)

E{At }(2(3 + 5)r))q , q p + 3
n




|AQ,q,q2 (w)|P r{w | w} O(1)E{At }(2(3 +
325



5)r))q , q > p + 3.

(4.26)

fiGao & Culberson

Therefore,
X
X
P r(w | w) =
|AQ,q,q2 (w)|P r{w | w}
Q,q,q2

wA(w)

=


X


X
X X
X X O(t)


q
E{At }(2(3 + 5)r)) +
O(1)E{At }(2(3 + 5)r))q .
n
q
q

Q=1 qp+3

Q=1 q>p+3

2

2

(4.27)
Since 2(3 +



5)r) > 1 z > 2.837,
X
wA(w)

P r(w | w)

O(t4 )
E{At } + t3 E{At }(4r)(p+3)
n

(4.28)

= o(E{At }).
completes proof Theorem 4.3.

5. Experiments
study threshold phenomena NK landscapes started experimental
investigation. Many theoretical results previous section motivated
observations made experiments. section, describe approach
methods used experimental study, report results observations
made.
experiments, instance NK landscape decision problem converted
equivalent 3-SAT problem, 3-SAT problem solved using Robertos relsatan
enhanced version famous Davis-Putnam algorithm SAT problems implemented
C ++ . source code relsat found http://www.cs.ubc.ca/ hoos/SATLIB/.
experiments, generated random instances NK landscape decision problem random model N (n, 2, z). result, equivalent SAT problem
random NK landscape instance 3-SAT problem n variables (on average) zn
clauses. definition, parameter z 0 8. z 1, 3-SAT instance
solved easily setting literals correspond main variables
local fitness function true. z increases, get clauses 3-SAT
problem becomes constrained. aims experiments threefold:(1)Investigating exists threshold phenomenon random NK landscape
model; (2) Locating threshold parameter z; (3)Determining
hard instances around threshold.
5.1 Experiments Fixed Ratio Model
part experiments, generate 100 random instances N (n, 2, z)
parameters n = 29 216 z = 2.71, 2.72, , 3.00. instances
converted 3-SAT instances solved relsat. Figure 1 shows fraction insoluble
instances function parameter z. seen exists threshold
phenomenon threshold around 2.83. shows upper bound z = 2.837
tight.
326

fiPhase Transition NK Landscapes

1

0.9

0.8

0.7

n=512
n=1024
n=2048
n=4096
n=8192
n=16384
n=32768
n=65536
z=2.84

0.6

0.5

0.4

0.3

0.2

0.1

0
2.7

2.75

2.8

2.85

2.9

2.95

3

Figure 1: Fractions insoluble instances(Y-axis) function z (X-axis).

Figure 2, plot square root average search cost function
parameter n. figure indicates average search O(n2 ) parameter
z. also observed 99 percent insoluble instances solved
quickly preprocessing stage relsat. indicates must small
structures make instances insoluble. detailed experimental results
found Gaos thesis (Gao, 2001).
5.2 Experiments 2-SAT sub-Problem
part experiments motivated theoretical analyses Section 4.2.
idea explained follows. Let
f (x) =

n
X

fi (xi , (xi ))

i=1

instance decision problem NK landscape
^
^
= C1 C2 Cn
equivalent 3-SAT problem Ci set 3-clauses equivalent local fitness
function fi . i, set 2-clauses Di (possibly empty) implied Ci .
example, Ci three 3-clauses ((x, y, z), (x, y, z), (x, y, z)), set 2-clauses Di
would ((x, z), (x, y)). conjunction Di , denoted , 2-SAT problem.
obvious original 3-SAT problem satisfiable 2-SAT sub-problem
satisfiable. experiment, generate instances NK landscape N (n, 2, z), convert
327

fiGao & Culberson

35
z=2.71
z=2.80
z=2.84
z=2.86
z=2.90

30

25

20

15

10

5

0

0

1

2

3

4

5

6

7
4

x 10

Figure 2: Square root average search cost (Y-axis, seconds) function n
(X-axis).

1

0.9

0.8

0.7

n=512
n=1024
n=2048
n=4096
n=8192
n=16384
n=32768
n=65536
z=2.84

0.6

0.5

0.4

0.3

0.2

0.1

0
2.7

2.75

2.8

2.85

2.9

2.95

3

Figure 3: Fractions insoluble instances(Y-axis) function z (X-axis) 2-SAT
sub-problems.

equivalent 3-SAT problems, extract 2-SAT sub-problems. 2-SAT

328

fiPhase Transition NK Landscapes

40
z=2.71
z=2.80
z=2.84
z=2.86
z=2.90

35

30

25

20

15

10

5

0

0

1

2

3

4

5

6

7
4

x 10

Figure 4: Square root average search cost (Y-axis, seconds) function n
(X-axis) 2-SAT sub-problems.

problems solved relsat solver. 2-SAT problem unsatisfiable,
original NK landscape instance also insoluble.
experimental settings experiment original
problem. results shown Figures 3-4, parallel Figures 1-2 results
original 3-SAT problems Section 5.1. see patterns insoluble fractions
search cost similar found original 3-SAT problems.
soluble-insoluble phase transition occurring around 2.83, fraction unsatisfiable
instances lower fraction original 3-SAT problems.
also observed average search cost 2-SAT sub-problems remains
original 3-SAT problems. tells us difficulty solving
soluble instance NK landscape almost solving 2-SAT problem,
hence easy. Therefore, average NK landscape N (n, 2, z) also easy parameters
threshold almost instances soluble.

6. Implications Conclusions
One questions arises work implications design analysis genetic algorithms. NK landscapes initially conceived simplified models
evolutionary landscapes could tuned respect ruggedness epistatic
interactions (Kauffman, 1989). study genetic algorithms, NK landscape models
used prototype benchmark analysis performance different genetic operators effects different encoding methods algorithms

329

fiGao & Culberson

performance (Altenberg, 1997; Hordijk, 1997; Jones, 1995). Kauffman (1993) points
parameters primarily affect number ruggedness measures n k.
Nevertheless, fact k 2 discrete NK landscape NP-complete (Wright
et al., 2000) neighbors arbitrarily chosen could construed implying
random landscapes fixed k practice hard.
results paper serve cautionary note may
case. analyses show fixed k uniform probability model trivially solvable
problem size tends infinity. fixed ratio model, derived two upper
bounds threshold solubility phase transition, proved problem
control parameter upper bounds solved polynomial time
probability asymptotic 1 due existence easy sub-problems 2-SAT.
series experiments also conducted investigate hardness problem
control parameters around threshold. experiments,
observed problem also easy around threshold.
proofs hold decision version problem component functions discrete {0, 1}. proofs obtained noticing clustering
functions, clauses, selected subsets variables implies overall problem
decomposable independent subproblems, problem contains small substructures identify solution. subproblems components connection
graph defined Section 3 2-SAT sub-problems studied Section 4.2. currently unclear us extent analysis extended optimization version
NK model, would like study problem future.
response question implications GAs? suggest following
speculative line enquiry. discrete model use, soluble instances readily
solved standard algorithmic approach based recognizing components
connection graph. (This surprise us pointed
Heckendorn, Rana, Whitley (1999) Even relatively old algorithms DavisPutnam deterministic exact orders magnitude faster GAs.) 1
similar connectivity developed real valued distributions, example capping
minimum value allow sub-function take. speculate
clustering imposed fixed values k would also generate localized structures real
values applied considering optimization instead decision, perhaps
fuzzy boundaries. fact, observation flip side limited epistasis. Genetic
algorithms, variants probabilistic model-building algorithms (Larranaga
& Lozano, 2001), designed mimic natural evolution, supposed take advantage
situation. So, extent NK landscapes accurate reflection
features exploited evolutionary algorithms, pose following question. possible
identify fuzzy components exist, design algorithm
exploits landscape features evolutionary algorithms do, far
efficiently, done uniform discrete decision problem?
landscapes designed intent studying limited interactions,
results also seen confirmation indeed limited epistasis leads easier problems. another domain, traditional research search optimization,
1. thanks anonymous referee pointing us work Heckendorn, et al. (Heckendorn
et al., 1999)

330

fiPhase Transition NK Landscapes

need test bed problems real world connections tunable
respect difficulty. NK landscapes might domain generating 3-SAT
instances. disappointing restricted k instances generated easy
high probability.

Acknowledgments
research supported part Natural Sciences Engineering Research Council
Grant No. OGP8053. thank anonymous reviewers comments.

References
Achlioptas, D. (1999). Threshold Phenomena Random Graph Colouring Satisfiability. Ph.D. thesis, Department Computer Science, University Toronto, Toronton,
Canada.
Achlioptas, D. (2001). survey lower bounds random 3-sat via differential equations.
Theoretical Computer Science, 265, 159185.
Achlioptas, D., Kirousis, L., Kranakis, E., Krizanc, D., & Molloy, M. (1997). Random
constraint satisfaction: accurate picture. Proceedings CP97, pp. 107
120. Springer.
Alon, N., & Spencer, J. (1992). Probabilistic Method. Wiley, New York.
Altenberg, L. (1997). Nk fitness landscapes. Back, T., Fogel, D., & Michalewicz, Z.
(Eds.), Handbook Evolutionary Computation. Oxford University Press, New York.
Cheeseman, P., Kanefsky, B., & Taylor, W. (1991). really hard problems are.
Proceedings 12th International Joint Conference Artificial Intelligence, pp.
331337. Morgan Kaufmann.
Cook, S., & Mitchell, D. (1997). Finding hard instances satisfiability problem:
survey. Du, Gu, & Pardalos (Eds.), Satisfiability Problem: Theory Applications,
Vol. 35 DIMACS Series Discrete Mathematics Theoretical Computer Science.
American Mathematical Society.
Culberson, J., & Gent, I. (2001). Frozen development graph coloring. Theoretical Computer Science, 265 (1-2), 227264.
Dubois, O. (2001). Upper bounds satisfiability threshold. Theoretical Computer
Science, 265 (1-2), 187197.
Franco, J., & Gelder, A. (1998). perspective certain polynomial time solvable classes
satisfiability. Discrete Applied Mathematics, appear.
Franco, J., & Paul, M. (1983). Probabilistic analysis davis-putnam procedure
solving satisfiability. Discrete Applied Mathematics, 5, 7787.
Freeman, J. (1996). Hard random 3-sat problems davis-putman procedure. Artificial
Intelligence, 81, 183198.

331

fiGao & Culberson

Friedgut, E. (1999). Sharp thresholds graph properties k-sat problem. J. Amer.
Math. Soc., 10171054.
Friedgut, E., & Kalai, G. (1996). Every monotone graph property sharp threshold.
Proc. Amer. Math. Soc., 29933002.
Frieze, A., & Suen, S. (1996). Analysis two simple heuristics random instance
k-sat. J. Algorithm, 20 (2), 312355.
Gao, Y. (2001). Threshold phenomena NK landscapes. Masters thesis, Department
Computing Science, University Alberta, Edmonton, Alberta, Canada.
Gent, I., MacIntyre, I., Prosser, P.and Smith, B., & Walsh, T. (1998). Random constraint
satisfaction: Flaws structure. Tech. rep. APES-08-1998, APES Research Group.
Heckendorn, R., Rana, S., & Whitley, D. (1999). Polynomial time summary statistics
generalization maxsat. GECCO99: Proceedings Genetic Evolutinary
Computation Conference, pp. 281288. Morgan Kaufmann.
Hordijk, W. (1997). measure landscapes. Evolutionary Computation, 4 (4), 335360.
Jones, T. (1995). Evolutionary Algorithms, Fitness Landscapes Search. Ph.D. thesis,
University New Mexico, Albuquerque, NM.
Kauffman, S. (1989). Adaptation rugged fitness landscapes. Stein, D. (Ed.), Lectures
Sciences Complexity, Santa Fe Institute Studies Sciences Complexity,
pp. 527618. Addison Wesley.
Kauffman, S. (1993). Origins Order: Self-organization Selection Evolution.
Oxford University Press, Inc.
Kirkpatrick, S., & Selman, B. (1994). Critical behavior satisfiability random
boolean expressions. Science, 264, 12971301.
Kirousis, L., P.Kranakis, D.Krizanc, & Y.Stamation (1994). Approximating unsatisfiability threshold random formulas. Random Structures Algorithms, 12 (3),
253269.
Larranaga, P., & Lozano, J. (2001). Estimation Distribution Algorithms: New Tool
Evolutinary Computation. Kluwer Academic Publishers, New York.
Mitchell, D., Selman, B., & Levesque, H. (1992). Hard easy distributions sat problems.
Proceedings 10th Natl. Conf Artificial Intelligence, pp. 459465. AAAI
Press.
Vandegriend, B., & Culberson, J. (1998). Gn,m phase transition hard
Hamiltonian Cycle problem. Journal Artificial Intelligence Research, 9, 219245.
Weinberger, E. D. (1996). Np completeness kauffmans NK model, tunable rugged
fitness landscape. Tech. rep. 96-02-003, Santa Fe Institute, Santa Fe.
Wright, A. H., Thompson, R. K., & Zhang, J. (2000). computational complexity NK
fitness functions. IEEE Transactions Evolutionary Computation, 4 (4), 373379.

332

fiJournal Artificial Intelligence Research 17 (2002) 229-264

Submitted 12/01; published 9/02

Knowledge Compilation Map
Adnan Darwiche

darwiche@cs.ucla.edu

Computer Science Department
University California, Los Angeles
Los Angeles, CA 90095, USA

Pierre Marquis

marquis@cril.univ-artois.fr

Universite dArtois
F-62307, Lens Cedex, France

Abstract
propose perspective knowledge compilation calls analyzing different compilation approaches according two key dimensions: succinctness target compilation
language, class queries transformations language supports polytime.
provide knowledge compilation map, analyzes large number existing target compilation languages according succinctness polytime transformations
queries. argue analysis necessary placing new compilation approaches within
context existing ones. also go beyond classical, flat target compilation languages based
CNF DNF, consider richer, nested class based directed acyclic graphs (such
OBDDs), show include relatively large number target compilation languages.

1. Introduction
Knowledge compilation emerged recently key direction research dealing
computational intractability general propositional reasoning (Darwiche, 1999; Cadoli & Donini,
1997; Boufkhad, Gregoire, Marquis, Mazure, & Sas, 1997; Khardon & Roth, 1997; Selman &
Kautz, 1996; Schrag, 1996; Marquis, 1995; del Val, 1994; Dechter & Rish, 1994; Reiter & de
Kleer, 1987). According direction, propositional theory compiled off-line target
language, used on-line answer large number queries polytime. key
motivation behind knowledge compilation push much computational overhead
off-line phase, amortized on-line queries. knowledge compilation serve
important purposes well. example, target compilation languages associated
algorithms simple, allowing one develop on-line reasoning systems simple software
hardware platforms. Moreover, simplicity algorithms operate compiled languages
help streamlining effort algorithmic design single task: generating smallest
compiled representations possible, turns main computational bottleneck
compilation approaches.
three key aspects knowledge compilation approach: succinctness
target language propositional theory compiled; class queries
answered polytime based compiled representation; class transformations
applied representation polytime. AI literature thus far focused mostly
target compilation languages variations DNF CNF formulas, Horn theories
prime implicates. Moreover, focused mostly clausal entailment queries, little
discussion tractable transformations compiled theories.
goal paper provide broad perspective knowledge compilation considering
relatively large number target compilation languages analyzing according
succinctness class queries/transformations admit polytime.

c
2002
AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiDarwiche & Marquis

Instead focusing classical, flat target compilation languages based CNF DNF,
consider richer, nested class based representing propositional sentences using directed acyclic
graphs, refer NNF. identify number target compilation languages
presented AI, formal verification, computer science literature show
special cases NNF. class, list extra conditions need imposed
NNF obtain specific class, identify set queries transformations
class supports polytime. also provide cross-rankings different subsets NNF, according
succinctness polytime operations support.
main contribution paper map deciding target compilation language
suitable particular application. Specifically, propose one starts identifying set queries transformations needed given application, choosing
succinct language supports operations polytime.
paper structured follows. start formally defining NNF language Section 2,
list number conditions NNF give rise variety target compilation languages.
study succinctness languages Section 3 provide cross-ranking
compares according measure. consider number queries applications
Section 4 compare different target compilation languages according tractability
respect queries. Section 5 dedicated class transformations, applications,
tractability respect different target compilation languages. finally close
Section 6 concluding remarks. Proofs theorems delegated Appendix A.

2. NNF Language
consider dozen languages paper, subsets NNF language,
defined formally follows (Darwiche, 1999, 2001a).
Definition 2.1 Let PS denumerable set propositional variables. sentence NNFP
rooted, directed acyclic graph (DAG) leaf node labeled true, false, X X,
X P S; internal node labeled arbitrarily many children.
size sentence NNFP , denoted | |, number DAG edges. height
maximum number edges root leaf DAG.
Figure 1 depicts sentence NNF, represents odd parity function (we omit reference
variables PS confusion anticipated). propositional sentence represented
sentence NNF, NNF language complete.
important distinguish representation language target compilation
language. representation language one expect humans read write
ease. language CNF popular representation language, language Horn
clauses (especially expressed rules form). hand, target compilation language
need suitable human specification interpretation, tractable enough
permit non-trivial number polytime queries and/or transformations. consider
number target compilation languages qualify representation languages
perspective, suitable humans construct interpret. also consider
number representation languages qualify target compilation languages.1
formal characterization representation languages outside scope paper.
language qualify target compilation language, require permits polytime
clausal entailment test. Note polytime consistency test sufficient here, one
consistency test given theory justify compilation. Given definition, NNF
1. appears proposing target compilation languages AI literature, usually implicit
requirement proposed language also representation language. shall see later, however,
powerful target compilation languages suitable humans specify interpret directly.

230

fiA Knowledge Compilation Map

Decomposability

(a)

(b)








A,B

Smoothness

(c)

Determinism






C,D



























A,B
A,B



















































B

B



C





C



B

B



C





C



B

B



C





C

Figure 1: sentence NNF. size 30 height 4.
qualify target compilation language unless P=NP (Papadimitriou, 1994), many
subsets do. define number subsets below, obtained imposing
conditions NNF.
distinguish two key subsets NNF: flat nested subsets. first consider
flat subsets, result imposing combinations following properties:
Flatness: height sentence 2. sentence Figure 3 flat,
one Figure 1 not.
Simple-disjunction: children or-node leaves share variables (the
node clause).
Simple-conjunction: children and-node leaves share variables (the
node term). sentence Figure 3 satisfies property.
Definition 2.2 language f-NNF subset NNF satisfying flatness. language CNF
subset f-NNF satisfying simpledisjunction. language DNF subset f-NNF satisfying
simpleconjunction.
CNF permit polytime clausal entailment test (unless P=NP) and, hence, qualify
target compilation language. dual DNF does.
following subset CNF, prime implicates, quite influential computer science:
Definition 2.3 language PI subset CNF clause entailed sentence
subsumed clause appears sentence; clause sentence subsumed
another.
dual PI, prime implicants IP, also defined.
Definition 2.4 language IP subset DNF term entailing sentence
subsumes term appears sentence; term sentence subsumed
another term.
work representing set prime implicates propositional theory
compact way, allowing exponential number prime implicates represented polynomial
space certain casessee example TRIE representation (de Kleer, 1992), ZBDD
representation used (Simon & del Val, 2001), implicit representation based metaproducts, proposed (Madre & Coudert, 1992). representations different
language PI sense necessarily support queries transformations
231

fiDarwiche & Marquis

report Tables 5 7. also exhibit different succinctness relationships
ones report Table 3.
Horn theories (and renamable Horn theories) represent another target compilation subset CNF,
consider since restrict attention complete languages L only, i.e.,
require every propositional sentence logically equivalent element L.
consider nested subsets NNF language, impose restriction
height sentence. Instead, subsets result imposing one following
conditions: decomposability, determinism, smoothness, decision, ordering. start defining
first three properties. on, C node NNF, Vars(C) denotes set
variables label descendants node C. Moreover, NNF sentence rooted C,
Vars() defined Vars(C).
Decomposability (Darwiche, 1999, 2001a). NNF satisfies property conjunction C NNF, conjuncts C share variables. is, C1 , . . . , Cn
children and-node C, Vars(Ci ) Vars(Cj ) = 6= j. Consider and-node
marked Figure 1(a). node two children, first contains variables A, B
second contains variables C, D. and-node decomposable since two children
share variables. and-node Figure 1(a) also decomposable and, hence,
NNF figure decomposable.
Determinism (Darwiche, 2001b): NNF satisfies property disjunction C
NNF, two disjuncts C logically contradictory. is, C1 , . . . , Cn
children or-node C, Ci Cj |= false 6= j. Consider or-node marked
Figure 1(b), two children corresponding sub-sentences B B A.
conjunction two sub-sentences logically contradictory. or-node
deterministic or-nodes Figure 1(b). Hence, NNF figure
deterministic.
Smoothness (Darwiche, 2001b): NNF satisfies property disjunction C
NNF, disjunct C mentions variables. is, C1 , . . . , Cn children
or-node C, Vars(Ci ) = Vars(Cj ) 6= j. Consider marked or-node Figure 1(c).
node two children, mentions variables A, B. or-node
smooth or-nodes Figure 1(c). Hence, NNF figure smooth.
hard ensure decomposability. also hard ensure determinism preserving decomposability. Yet sentence NNF smoothed polytime, preserving decomposability
determinism. Preserving flatness, however, may blow-up size given NNF. Hence, smoothness important complexity viewpoint unless flatness.
properties decomposability, determinism smoothness lead number interesting
subsets NNF.
Definition 2.5 language DNNF subset NNF satisfying decomposability; d-NNF subset satisfying determinism; s-NNF subset satisfying smoothness; d-DNNF subset satisfying
decomposability determinism; sd-DNNF subset satisfying decomposability, determinism
smoothness.
Note DNF strict subset DNNF (Darwiche, 1999, 2001a). following decision property
comes literature binary decision diagrams (Bryant, 1986).
Definition 2.6 (Decision) decision node N NNF sentence one labeled true,
false, or-node form (X ) (X ), X variable,
decision nodes. latter case, dVar (N ) denotes variable X.
Definition 2.7 language BDD set NNF sentences, root sentence
decision node.
232

fiA Knowledge Compilation Map



X1




X1 X1


X2



X2



X3


X3

true





X2

X2

X2

X2

X3

X3

1

0





X3

X3

false

Figure 2: left, sentence BDD language. right, corresponding binary decision
diagram.

NNF sentence Figure 2 belongs BDD subset.
BDD language corresponds binary decision diagrams (BDDs), known formal
verification literature (Bryant, 1986). Binary decision diagrams depicted using compact
notation though: labels true false denoted 1 0, respectively; decision





X

. BDD sentence left Figure 2 corresponds
node X X denoted
binary decision diagram right Figure 2. Obviously enough, every NNF sentence satisfies
decision property also deterministic. Therefore, BDD subset d-NNF.
show later, BDD qualify target compilation language (unless P=NP),
following subset does.

Definition 2.8 FBDD intersection DNNF BDD.
is, sentence FBDD decomposable satisfies decision property. FBDD language
corresponds free binary decision diagrams (FBDDs), known formal verification (Gergov &
Meinel, 1994a). FBDD usually defined BDD satisfies read-once property:
path root leaf, variable appear once. FBDDs also known
read-once branching programs theory literature. Imposing read-once property BDD
equivalent imposing decomposability property corresponding BDD sentence.
influential subset BDD language obtained imposing ordering property:
Definition 2.9 (Ordering) Let < total ordering variables PS. language OBDD<
subset FBDD satisfying following property: N or-nodes, N
ancestor node , dVar (N ) < dVar (M ).
Definition 2.10 language OBDD union OBDD< languages.
OBDD language corresponds wellknown ordered binary decision diagrams (OBDDs)
(Bryant, 1986).
final language definition follows:
Definition 2.11 MODS subset DNF every sentence satisfies determinism smoothness.
233

fiDarwiche & Marquis




X





Z





X Z

Figure 3: sentence language MODS.

NNF
CO,

d-NNF

s-NNF

CE,

DNNF

f-NNF

VA, IM, CT

BDD

d-DNNF

EQ?

VA, IM

FBDD

EQ?

DNF

sd-DNNF

CNF

EQ

OBDD
SE

OBDD<

EQ, SE

VA, IM, EQ, SE

MODS

IP

CO , CE, EQ, SE,

PI

Figure 4: set DAG-based languages considered paper. edge L1 L2 means
L1 proper subset L2 . Next subset, list polytime queries supported
subset ancestors (see Section 4).

Figure 3 depicts sentence MODS. show later, MODS tractable NNF subset
shall consider (together OBDD< ). surprising since syntax sentence
MODS, one immediately recover sentence models.
languages discussed far depicted Figure 4, arrows denote set inclusion.
Table 1 lists acronyms languages, together descriptions. Table 2 lists
key language properties discussed section, together short description each.

3. Succinctness Compiled Theories
discussed dozen subsets NNF language. subsets well
known studied extensively computer science literature. Others, DNNF
(Darwiche, 2001a, 1999) d-DNNF (Darwiche, 2001b), relatively new. question is:
subset one adopt particular application? argue paper, depends

234

fiA Knowledge Compilation Map

Acronym
NNF
DNNF
d-NNF
s-NNF
f-NNF
d-DNNF
sd-DNNF
BDD
FBDD
OBDD
OBDD<
DNF
CNF
PI
IP
MODS

Description
Negation Normal Form
Decomposable Negation Normal Form
Deterministic Negation Normal Form
Smooth Negation Normal Form
Flat Negation Normal Form
Deterministic Decomposable Negation Normal Form
Smooth Deterministic Decomposable Negation Normal Form
Binary Decision Diagram
Free Binary Decision Diagram
Ordered Binary Decision Diagram
Ordered Binary Decision Diagram (using order <)
Disjunctive Normal Form
Conjunctive Normal Form
Prime Implicates
Prime Implicants
Models

Table 1: Language acronyms.

Property
Flatness
Simple Disjunction
Simple Conjunction
Decomposability
Determinism
Smoothness
Decision
Ordering

Short Description
height NNF 2
Every disjunction clause, literals share variables
Every conjunction term, literals share variables
Conjuncts share variables
Disjuncts logically disjoint
Disjuncts mention set variables
node form true, false, (X X ),
X variable , decision nodes
Decision variables appear order path NNF

Table 2: Language properties.

235

fiDarwiche & Marquis

three key properties language: succinctness, class tractable queries supports,
class tractable transformations admits.
goal following sections construct map place different
subsets NNF language according criteria. map serve guide
system designers choosing target compilation language suitable application.
also provides example paradigm studying evaluating target compilation languages.
start study succinctness2 section (Gogic, Kautz, Papadimitriou, & Selman, 1995).
Definition 3.1 (Succinctness) Let L1 L2 two subsets NNF. L1 least succinct
L2 , denoted L1 L2 , iff exists polynomial p every sentence L2 ,
exists equivalent sentence L1 || p(||). Here, || || sizes ,
respectively.
stress require exists function computes given
polytime; require polysize exists. Yet, proofs Appendix contain specific
algorithms computing certain cases. relation clearly reflexive transitive,
hence, pre-ordering. One also define relation <, L1 < L2 iff L1 L2 L2 6 L1 .
Proposition 3.1 results Table 3 hold.
occurrence cell row r column c Table 3 means fragment Lr
given row r least succinct fragment Lc given column c. occurrence 6 (or
6 ) means Lr least succinct Lc (provided polynomial hierarchy
collapse case 6 ). Finally, presence question mark reflects ignorance
whether Lr least succinct Lc . Figure 5 summarizes results Proposition 3.1 terms
directed acyclic graph.
classical result knowledge compilation states possible compile propositional formula polysize data structure that: entail set clauses,
clausal entailment decided time polynomial size, unless NP P/poly
(Selman & Kautz, 1996; Cadoli & Donini, 1997). last assumption implies collapse
polynomial hierarchy second level (Karp & Lipton, 1980), considered unlikely.
use classical result knowledge compilation proofs Proposition 3.1,
explains parts conditioned polynomial hierarchy collapsing.
excluded subsets BDD, s-NNF, d-NNF f-NNF Table 3 since
qualify target compilation languages (see Section 4). kept NNF CNF though given
importance. Consider Figure 5 depicts Table 3 graphically. exception NNF
CNF, languages depicted Figure 5 qualify target compilation languages. Moreover,
exception language PI, DNNF succinct among target compilation languageswe
know PI succinct DNNF, know whether DNNF succinct
PI.
DNNF MODS, succinctness ordering target compilation languages:
DNNF <

d-DNNF <

FBDD <

OBDD <

OBDD<

< MODS.

DNNF obtained imposing decomposability NNF; d-DNNF adding determinism; FBDD
adding decision; OBDD OBDD< adding ordering (w.r.t. total ordering PS
first case specific one second case). Adding properties reduces language
succinctness (assuming polynomial hierarchy collapse).
One important fact stress adding smoothness d-DNNF affect succinctness: sd-DNNF d-DNNF languages equally succinct. also interesting compare
2. general notion space efficiency (model preservation polysize reductions) exists (Cadoli, Donini,
Liberatore, & Schaerf, 1996), need full generality here.

236

fiA Knowledge Compilation Map

L
NNF
DNNF
d-DNNF
sd-DNNF
FBDD
OBDD
OBDD<
DNF
CNF
PI
IP
MODS

NNF

6
6
6
6
6
6
6
6
6
6
6

DNNF


6
6
6
6
6
6
6
6
6
6

d-DNNF




6
6
6
6
6
6
6
6

sd-DNNF




6
6
6
6
6
6
6
6

FBDD





6
6
6
6
6
6
6

OBDD






6
6
6
6
6
6

OBDD<







6
6
6
6
6

DNF


6
6
6
6
6

6
6
6
6

CNF

6
6
6
6
6
6
6

6
6
6

PI

?
?
?
6
6
6
6


6
6

IP


?
?
6
6
6

6
6

6

MODS









?



Table 3: Succinctness target compilation languages. means result holds unless
polynomial hierarchy collapses.

NNF
DNNF
sd-DNNF

=

CNF

d-DNNF
DNF

FBDD

PI
OBDD
IP
OBDD<
MODS

Figure 5: edge L1 L2 indicates L1 strictly succinct L2 : L1 < L2 ,
L1 = L2 indicates L1 L2 equally succinct: L1 L2 L2 L1 . Dotted
arrows indicate unknown relationships; instance, dotted arrow DNNF PI
means know whether DNNF least succinct PI. edges
conditioned polynomial hierarchy collapsingsee Table 3.

sd-DNNF (which succinct influential FBDD, OBDD OBDD< languages) MODS,
tractable language. sd-DNNF MODS smooth, deterministic decomposable. MODS, however, flat obtains decomposability stronger condition
simple-conjunction. Therefore, sd-DNNF viewed result relaxing MODS
flatness simple-conjunction conditions, maintaining decomposability, determinism
smoothness. Relaxing conditions moves language three levels succinctness hierarchy, although compromises polytime test sentential entailment possibly one
equivalence show Section 4.

237

fiDarwiche & Marquis

4. Querying Compiled Theory
evaluating suitability target compilation language particular application, succinctness language must balanced set queries transformations
supports polytime. consider section number queries, returns valuable information propositional theory, identify target compilation languages
provide polytime algorithms answering queries. restrict attention paper
existence polytime algorithms answering queries, present algorithms
themselves. interested reader referred (Darwiche, 2001a, 2001b, 1999; Bryant, 1986)
algorithms proofs theorems Appendix others.
queries consider tests consistency, validity, implicates (clausal entailment), implicants, equivalence, sentential entailment. also consider counting enumerating theory
models; see Table 4. One also consider computing probability propositional sentence,
assuming variables probabilistically independent. subsets consider, however,
done polytime whenever models counted polytime.
on, L denotes subset language NNF.
Definition 4.1 (CO, VA) L satisfies CO (VA) iff exists polytime algorithm maps
every formula L 1 consistent (valid), 0 otherwise.
One main applications compiling theory enhance efficiency answering
clausal entailment queries:
Definition 4.2 (CE) L satisfies CE iff exists polytime algorithm maps every formula
L every clause NNF 1 |= holds, 0 otherwise.
key application clausal entailmentVis testing equivalence. Specifically, suppose
designVexpressed set clauses = specification expressed also set clauses
= j j , want test whether design specification equivalent. compiling
targets support polytime clausal entailment test, test
equivalence polytime. is, equivalent iff |= j j
|= i.
number target compilation languages shall consider support direct polytime equivalent test:
Definition 4.3 (EQ, SE) L satisfies EQ (SE) iff exists polytime algorithm maps every
pair formulas , L 1 ( |= ) holds, 0 otherwise.
Note sentential entailment (SE) stronger clausal entailment equivalence. Therefore,
language L satisfies SE, also satisfies CE EQ.
completeness, consider following dual CE:
Definition 4.4 (IM) L satisfies IM iff exists polytime algorithm maps every formula
L every term NNF 1 |= holds, 0 otherwise.
Finally, consider counting enumerating models:
Definition 4.5 (CT) L satisfies CT iff exists polytime algorithm maps every formula
L nonnegative integer represents number models (in binary notation).
Definition 4.6 (ME) L satisfies iff exists polynomial p(., .) algorithm
outputs models arbitrary formula L time p(n, m), n size
number models (over variables occurring ).

238

fiA Knowledge Compilation Map

Notation
CO
VA
CE
IM
EQ
SE
CT


Query
polytime consistency check
polytime validity check
polytime clausal entailment check
polytime implicant check
polytime equivalence check
polytime sentential entailment check
polytime model counting
polytime model enumeration

Table 4: Notations queries.

L
NNF
DNNF
d-NNF
s-NNF
f-NNF
d-DNNF
sd-DNNF
BDD
FBDD
OBDD
OBDD<
DNF
CNF
PI
IP
MODS

CO

















VA








CE































IM








SE












CT

















EQ





?
?

?

















































Table 5: Subsets NNF language corresponding polytime queries.
means satisfy unless P = NP.



means satisfies

Table 4 summarizes queries interested acronyms.
following proposition states know availability polytime algorithms
answering queries, respect languages introduced Section 2.
Proposition 4.1 results Table 5 hold.
results Proposition 4.1 summarized Figure 4. One draw number conclusions
based results figure. First, NNF, s-NNF, d-NNF, f-NNF, BDD fall one equivalence
class support polytime queries CNF satisfies VA IM; hence, none
qualifies target compilation language case. remaining languages
support polytime tests consistency clausal entailment. Therefore, simply imposing either
smoothness (s-NNF), determinism (d-NNF), flatness (f-NNF), decision (BDD) NNF language lead tractability respect queries considerneither
properties seem significant isolation. Decomposability (DNNF), however, exception
leads immediately polytime tests consistency clausal entailment, polytime
algorithm model enumeration.
239

fiDarwiche & Marquis

Recall succinctness ordering DNNF < d-DNNF < FBDD < OBDD < OBDD< < MODS
Figure 5. adding decomposability (DNNF), obtain polytime tests consistency
clausal entailment, addition polytime model enumeration algorithm. adding determinism
decomposability (d-DNNF), obtain polytime tests validity, implicant model counting,
quite significant. clear, however, whether combination decomposability
determinism leads polytime test equivalence. Moreover, adding decision property top
decomposability determinism (FBDD) appear increase tractability respect
given queries3 , although lead reducing language succinctness shown Figure 5.
hand, adding ordering property top decomposability, determinism decision,
leads polytime tests equivalence (OBDD OBDD< ) well sentential entailment provided
ordering < fixed (OBDD< ).
succinctness ordering NNF < DNNF < DNF < IP < MODS Figure 5, note
DNNF obtained imposing decomposability NNF, DNF obtained imposing flatness
simple-conjunction (which stronger decomposability). interesting DNF
less succinct DNNF, yet support polytime queries; see Figure 4. However,
addition smoothness (and determinism) top flatness simple-conjunction (MODS) leads
five additional polytime queries, including equivalence entailment tests.4
close section noting determinism appears necessary (but sufficient)
polytime model counting: deterministic languages, d-DNNF, sd-DNNF, FBDD, OBDD, OBDD<
MODS, support polytime counting. Moreover, polytime counting implies polytime test validity,
opposite true.

5. Transforming Compiled Theory
query operation returns information theory without changing it. transformation, hand, operation returns modified theory, operated
using queries. Many applications require combination transformations queries.
Definition 5.1 (C, C) Let L subset NNF. L satisfies C (C) iff exists polytime
algorithm maps every finite set formulas 1 , . . . , n L formula L logically
equivalent 1 . . . n (1 . . . n ).
Definition 5.2 (C) Let L subset NNF. L satisfies C iff exists polytime algorithm
maps every formula L formula L logically equivalent .
language satisfies one properties, say closed corresponding operator. Closure logical connectives important two key reasons. First,
implications compilers constructed given target language. example, clause
easily compiled language L, closure conjunction implies compiling
CNF sentence L easy. Second, implications class polytime queries supported
target language: language L satisfies CO closed negation conjunction,
must satisfy SE (to test whether |= , do, Refutation Theorem,
test whether inconsistent). Similarly, language satisfies VA closed
negation disjunction, must satisfy SE Deduction Theorem.
3. Deciding equivalence two sentences FBDD, d-DNNF, sd-DNNF, easily shown coNP.
However, proof coNP-hardness, deterministic polytime algorithms deciding
problems. Actually, latter case quite unlikely equivalence problem FBDD intensively
studied, algorithm sight. Note, however, equivalence two sentences FBDD
decided probabilistically polytime (Blum, Chandra, & Wegman, 1980), similarly sentences d-DNNF
(Darwiche & Huang, 2002).
4. Given flatness, simple-conjunction smoothness, obtain determinism simply removing duplicated
terms.

240

fiA Knowledge Compilation Map

important stress languages closed logical operator,
number operands bounded constant. refer bounded closure.
Definition 5.3 (BC, BC) Let L subset NNF. L satisfies BC (BC) iff exists
polytime algorithm maps every pair formulas L formula L
logically equivalent ( ).
turn another important transformation:
Definition 5.4 (Conditioning) (Darwiche, 1999) Let propositional formula, let
consistent term. conditioning , noted | , formula obtained replacing
variable X true (resp. false) X (resp. X) positive (resp. negative) literal .
Definition 5.5 (CD) Let L subset NNF. L satisfies CD iff exists polytime algorithm
maps every formula L every consistent term formula L logically
equivalent | .
Conditioning number applications, corresponds restriction literature
Boolean functions. main application conditioning due theorem, says
consistent iff | consistent (Darwiche, 2001a, 1999). Therefore, language satisfies CO
CD, must also satisfy CE. Conditioning also plays key role building compilers
enforce decomposability. two sentences 1 2 decomposable (belong DNNF),
conjunction 1 2 necessarily decomposable since sentences may share variables.
Conditioning
used ensure decomposability case since 1 2 equivalent
W
(
|
)

(
1
2 | ) , term covering variables shared 1 2 . Note
W
(
|
)

(
1
2 | ) must decomposable since 1 | 2 | mention variables

. previous proposition indeed generalization multiple variables well-known
Shannon expansion literature Boolean functions. also basis compiling CNF
DNNF (Darwiche, 1999, 2001a).
Another critical transformation shall consider forgetting (also referred marginalization, elimination middle terms (Boole, 1854)):
Definition 5.6 (Forgetting) Let propositional formula, let X subset variables
PS. forgetting X , denoted X., formula mention variable
X every formula mention variable X, |= precisely
X. |= .
Therefore, forget variables X remove reference X , maintaining
information captures complement X. Note X. unique logical
equivalence.
Definition 5.7 (FO, SFO) Let L subset NNF. L satisfies FO iff exists polytime
algorithm maps every formula L every subset X variables PS formula
L equivalent X.. property holds singleton X, say L satisfies SFO.
Forgetting important transformation allows us focus/project theory set
variables. example, know variables X never appear entailment queries,
forget variables compiled theory maintaining ability answer
queries correctly. Another application forgetting counting/enumerating instantiations variables Y, consistent theory . query answered
counting/enumerating models X., X complement Y. Forgetting also
applications planning, diagnosis belief revision. instance, SATPLAN framework,

241

fiDarwiche & Marquis

Notation
CD
FO
SFO
C
BC
C
BC
C

Transformation
polytime conditioning
polytime forgetting
polytime singleton forgetting
polytime conjunction
polytime bounded conjunction
polytime disjunction
polytime bounded disjunction
polytime negation

Table 6: Notations transformations.

L
NNF
DNNF
d-NNF
s-NNF
f-NNF
d-DNNF
sd-DNNF
BDD
FBDD
OBDD
OBDD<
DNF
CNF
PI
IP
MODS

CD

















FO













SFO

























C


BC





C





BC




































































C





?
?











Table 7: Subsets NNF language polytime transformations.
means satisfies,
means satisfy, means satisfy unless P=NP.

compiling away fluents actions amounts forgetting variables. model-based diagnosis, compiling away every variable except abnormality ones remove piece information
required compute conflicts diagnoses system (Darwiche, 2001a). Forgetting
also used design update operators valuable properties (Herzig & Rifi, 1999).
Table 6 summarizes transformations interested acronyms. following
proposition states know tractability transformations respect
identified target compilation languages.
Proposition 5.1 results Table 7 hold.
One draw number observations regarding Table 7. First, languages consider satisfy
CD and, hence, lend efficient application conditioning transformation.
forgetting multiple variables, DNNF, DNF, PI MODS permit polytime. important
stress none FBDD, OBDD OBDD< permits polytime forgetting multiple variables.
noticeable since recent applications OBDD< planningwithin so-called
symbolic model checking approach planning (A. Cimmati & Traverso, 1997)depend crucially
242

fiA Knowledge Compilation Map

operation forgetting may suitable use language satisfies FO
case. Note, however, OBDD OBDD< allow forgetting single variable polytime,
FBDD allow even that. d-DNNF similar FBDD satisfies neither FO SFO.
also interesting observe none target compilation languages closed
conjunction. number them, however, closed bounded conjunction, including OBDD< ,
DNF, IP MODS.
disjunction, target compilation languages closed disjunction
DNNF DNF. OBDD< PI languages, however, closed bounded disjunction. Again,
d-DNNF, FBDD OBDD languages closed neither.
target compilation languages closed negation FBDD, OBDD OBDD< ,
known whether d-DNNF sd-DNNF closed operation. Note d-DNNF
FBDD support set polytime queries (equivalence checking unknown both)
indistinguishable viewpoint. Moreover, difference two
languages Table 7 closure FBDD negation, seem significant
light closure either conjunction disjunction. Note, however, d-DNNF
succinct FBDD given Figure 5.
Finally, OBDD< target compilation language closed negation, bounded
conjunction, bounded disjunction. closure actually plays important role compiling
propositional theories OBDD< basis state-of-the-art compilers purpose
(Bryant, 1986).

6. Conclusion
main contribution paper methodology analyzing propositional compilation approaches according two key dimensions: succinctness target compilation language,
class queries transformations supports polytime. second main contribution
paper comprehensive analysis, according proposed methodology,
dozen languages produced knowledge compilation map, cross-ranks
languages according succinctness, polytime queries transformations
support. map allows system designers make informed decisions target compilation
language use: class queries/transformations decided based application interest, designer chooses succinct target compilation language supports
operations polytime. Another key contribution paper uniform treatment
applied diverse target compilation languages, showing subsets NNF
language. Specifically, identified number simple, yet meaningful, properties, including
decomposability, determinism, decision flatness, showed combinations properties give rise different target compilation languages. studied subsets include well known
languages PI, influential AI; OBDD< , influential formal
verification; CNF DNF, quite influential computer science. subsets
also include relatively new languages DNNF d-DNNF, appear represent
interesting, new balances language succinctness query/transformation tractability.

Acknowledgments
revised extended version paper Perspective Knowledge Compilation,
Proceedings 17th International Joint Conference Artificial Intelligence (IJCAI01), pp.
175-182, 2001. wish thank Alvaro del Val, Mark Hopkins, Jerome Lang anonymous
reviewers suggestions comments, well Ingo Wegener help
issues discussed paper. work done second author visiting
researcher Computer Science Department UCLA. first author partly
243

fiDarwiche & Marquis

supported NSF grant IIS-9988543 MURI grant N00014-00-1-0617. second author
partly supported IUT de Lens, Universite dArtois, Nord/Pas-de-Calais Region
TACT-TIC project, European Community FEDER Program.

Appendix A. Proofs
simplify proofs main propositions later on, identified number lemmas
list below. proofs lemmas direct, include completeness.
Lemma A.1 Every sentence d-DNNF translated equivalent sentence sd-DNNF
polytime.
Proof: Let = 1 . . . n or-node d-DNNF sentence . Suppose smooth
andWlet V = V
Vars(). Consider sentence obtained replacing node
n
i=1 vV \Vars(i ) (v v). equivalent smooth. Moreover,
computed time polynomial size satisfies decomposability determinism. 2
Lemma A.2 Every sentence FBDD translated equivalent sentence FBDD s-NNF
polytime.
Proof: Let sentence FBDD let node . always replace (Y )
(Y ), variable , preserving equivalence decision property. Moreover,
long variable appear ancestor , decomposability
also preserved (that is, resulting sentence FBDD). Note ancestor respect
binary decision diagram notation see left Figure 2.
Now, suppose (X ) (X ) or-node . Suppose or-node
smooth. Hence, appears Vars() Vars() (or
way around). Since decomposable, cannot ancestor (since case
would also ancestor , impossible decomposability ). Hence, replace (Y ) (Y ), preserving equivalence, decision decomposability.
repeating process, smooth preserving necessary properties. Finally,
note every or-node (X ) (X ) , need repeat process
| Vars() Vars() | + | Vars() Vars() | times. Hence, smoothing operation performed polytime.
2
Lemma A.3 subset L NNF satisfies CO CD, also satisfies ME.
Proof: Let sentence L. First, test inconsistent (can done polytime).
is, return empty set models. Otherwise, construct decision-tree representation
models . Given ordering variables x1 , . . . , xn Vars(), start tree
consisting single root node. = 1 n, repeat following leaf node
(corresponds consistent term) :
a. | xi consistent, add xi child ;
b. | xi consistent, add xi child .
key points are:
Test (a) Test (b) performed time polynomial size (since L satisfies
CO CD).

244

fiA Knowledge Compilation Map

Either Test (a) Test (b) must succeed (since consistent).
Hence, number tests performed O(mn), number leaf nodes final
decision tree (bounded number models ) n number variables .
2
Lemma A.4 subset NNF satisfies CO CD, also satisfies CE.
Proof: test whether sentence entails non-valid clause , |= , suffices test whether
| inconsistent (Darwiche, 2001a).
2
Lemma A.5 Let two sentences share variables. valid iff valid
valid.
Proof: valid iff inconsistent. Since share variables,
inconsistent iff inconsistent is. true iff valid valid.
2
Lemma A.6 Let sentence d-DNNF let clause. sentence d-DNNF
equivalent constructed polytime size .
Wn
Vi1
Proof: Let l1 , . . . , ln literals appear clause . = i=1 (li j=1 lj )
equivalent clause , d-DNNF, constructed polytime size . let
term equivalent . equivalent (( | ) ) . last sentence
d-DNNF constructed polytime size .
2
Lemma A.7 subset NNF satisfies VA CD, also satisfies IM.
Proof: test whether consistent term entails sentence , |= , suffices test whether
valid. sentence equivalent ( ), ( ( | )), ( | ).
Since | share variables, disjunction valid iff valid | valid (by
Lemma A.5). cannot valid since consistent. | constructed polytime since
language satisfies CD validity tested polytime since language satisfies VA. 2
Lemma A.8 Every CNF DNF formula translated equivalent sentence BDD
polytime.
Proof: straightforward convert clause term equivalent sentence BDD. order
generate BDD sentence corresponding conjunction (resp. disjunction) BDD sentences
, sufficient replace 1-sink (resp. 0-sink) root .
2
Lemma A.9 subset NNF satisfies EQ, satisfies CO VA.
Proof: true false belong every NNF subset. inconsistent iff equivalent false.
valid iff equivalent true.
2
Lemma A.10 subset NNF satisfies SE, satisfies EQ, CO VA.
Proof: Sentences 1 2 equivalent iff 1 |= 2 2 |= 1 . EQ implies CO VA
(Lemma A.9).
2

245

fiDarwiche & Marquis

Lemma A.11 Let sentence d-DNNF let clause. validity
tested time polynomial size .
Proof: Construct polytime given Lemma A.6 check validity,
done polytime too.
2
Lemma A.12 every propositional formula every consistent term , |
equivalent
Vars().( ).
Proof: Without loss generality, assume given disjunctively-interpreted set
models (over Vars()). Conditioning leads (1) removing every model ,
(2) projecting remaining models every variable removed. Conjoining
leads exactly (1), forgetting every variable resulting formula leads exactly (2)
(Lang, Liberatore, & Marquis, 2000).
2
Lemma A.13 sentence f-NNF converted equivalent sentence polynomial time, CNF DNF.
Proof: consider three cases sentence :
1. root node and-node. case, turned CNF sentence
polynomial time simply ensuring or-node clause (that is, disjunction
literals share variables). Let C or-node . Since flat root
and-node, C must child root children C must leaves. Hence,
easily ensure C clause follows:
one edge C leaf X another edge C X (C valid),
replace edge root C edge root true.
one edge C leaf node X, keep one
edges delete rest.
2. root or-node. turned DNF sentence dual way.5
3. root leaf node. already CNF sentence.
2
Lemma A.14 prime implicant (resp. essential prime implicant) sentence iff
prime implicate (resp. essential prime implicate) . 6
Proof: folklore result, immediate definitions.

2

Proof Proposition 3.1
proof proposition broken eight steps. step, prove number
succinctness relationships different languages, apply transitivity succinctness
relation infer even relationships. Associated step proof table

246

fiA Knowledge Compilation Map

L

NNF

DNNF

d-DNNF

FBDD

OBDD

OBDD<

DNF

CNF

PI

IP

MODS

sd-DNNF

NNF
DNNF
d-DNNF
FBDD
OBDD
OBDD<
DNF
CNF
PI
IP
MODS
sd-DNNF































































Table 8:
L

NNF

DNNF

d-DNNF

FBDD

OBDD

OBDD<

DNF

CNF

PI

IP

MODS

sd-DNNF

NNF
DNNF
d-DNNF
FBDD
OBDD
OBDD<














































DNF

6



6

6





CNF

6

6

6





6

PI

6

6

6

6



6

IP
MODS
sd-DNNF

6

6

6

6

6







Table 9:
mark relationships proved stepwe dont show marks first
table though.
Table 8: Follows immediately language inclusions reported Figure 4.
Table 9: prove DNF 6 PI CNF 6 IP (this slightly generalizes results
DNF 6 CNF CNF 6 DNF given (Gogic et al., 1995)).
Vn1
Let us consider CNF formula n = i=0 (x2i x2i+1 ). formula prime implicates
form7 (and clause n essential prime implicate it). Hence negation n
prime implicants form (as easy consequence Lemma A.14).
Since Quines early work (Quine, 1959), know number essential prime implicants
(resp. prime implicates) formula lower bound number terms (resp. clauses)
found DNF (resp. CNF) representation (indeed, representation must
include essential prime). n 2n essential prime implicants. Indeed, easily shown
induction n given (i) every literal occurring n occurs once, (ii) set prime
implicants nontautological clause set literals occurring (up logical equivalence),
(iii) distribution property prime implicants (see e.g., (dual of) Proposition 40 (Marquis,
2000)) states IP ( ) = max({PI PI | PI IP (), PI IP ()}, |=) (up logical
equivalence). Subsequently, n 2n essential prime implicates (cf. Lemma A.14). Accordingly,
obtain DNF 6 PI CNF 6 IP. also obtain PI 6 IP IP 6 PI. Now,
wellknown DNF formulas exponentially many prime implicants (see proof
Proposition 5.1 show IP satisfy SFO). Hence, negations CNF
5. Note f-NNF satisfies C negation CNF sentence (resp. DNF sentence) turned
DNF (resp. CNF) linear time.
6. prime implicant (resp. prime implicate) essential iff disjunction (resp. conjunction) prime
implicants (resp. prime implicates) except equivalent .
7. correctness (the dual of) Quines consensus algorithm computing prime implicants (Quine, 1955)
ensures it, since clause n subsumed another clause consensi performed since
negated variables.

247

fiDarwiche & Marquis

L

NNF

DNNF

d-DNNF

FBDD

OBDD

OBDD<

DNF

CNF

PI

IP

MODS

sd-DNNF

NNF
DNNF
d-DNNF
FBDD
OBDD
OBDD<














































DNF

6

6

6

6

6

6



6

6





CNF

6

6

6

6

6

6

6





6

PI

6

6

6

6

6

6

6

6



6

IP
MODS
sd-DNNF

6

6

6

6

6

6

6

6

6







Table 10:
L

NNF

DNNF

d-DNNF

FBDD

OBDD

NNF
DNNF
d-DNNF


















OBDD<




FBDD

6

6

6







OBDD

6

6

6

6





OBDD<
DNF
CNF
PI
IP
MODS
sd-DNNF

6
6

6

6

6


6
6

6

6

6


6
6

6

6

6


6
6

6

6

6


6
6

6

6

6



6

6

6

6


DNF

CNF

PI

IP

MODS

sd-DNNF




















6

6

6


6

6

6


6


6



6

6










Table 11:
formulas exponentially many prime implicates. Subsequently IP 6 DNF PI 6 CNF.
remaining results table follow fromL
transitivity .
n1
Table 10: parity function = i=0 xi linear size OBDD< representations (Bryant,
1986) exponential size CNF DNF representations. reason 2n
essential prime implicants (resp. essential prime implicates) number essential prime
implicants (resp. essential prime implicates) formula lower bound size
DNF (resp. CNF) representation. easily shows CNF 6 OBDD DNF 6 OBDD.
remaining results table follow language inclusions reported Figure 4.
Table 11: shown (Darwiche, 2001b) sentence d-DNNF
exponential FBDD representations. Accordingly, FBDD 6 d-DNNF. (Gergov & Meinel,
1994a), shownVthat OBDD 6 FBDD. Finally, easy show OBDD< 6 OBDD (for instance,
n
formula n = i=1 (xi yi ) OBDD< representation size polynomial n whenever <
satisfies x1 < y1 < x2 < . . . < xn < yn , OBDD< representation size exponential
n provided < s.t. x1 < x2 < . . . < xn < y1 < y2 < . . . < yn ). remaining results
table follow language inclusions reported Figure 4.
Table 12: L 6 L means L 6 L unless polynomial hierarchy PH collapses.
results table follow since existence polysize knowledge compilation functions clausal
entailment implies collapse polynomial hierarchy PH (Selman & Kautz, 1996; Cadoli &
Donini, 1997). Now, DNNF CNF, sentence CNF exists polysize equivalent
sentence DNNF. Therefore, test whether clause entailed polytime testing
whether clause entailed . proves existence polysize knowledge compilation
functions clausal entailment, leading collapse polynomial hierarchy PH.
true d-DNNF sd-DNNF since languages support polytime clausal entailment test
(see Proposition 4.1).
Table 13: (Wegener, 1987) (Theorem 6.2 pp. 436), family n2 -variable boolean functions
pointed out. Provided every interpretation n2 variables represents n-vertices
digraph (for every 1 i, j n, I(xi,j ) = 1 iff (i, j) arc digraph), (I) = 1 iff
248

fiA Knowledge Compilation Map

L

NNF

DNNF

d-DNNF

FBDD

OBDD

OBDD<

DNF

CNF

PI

IP

MODS

sd-DNNF

NNF


6



































6












DNNF
d-DNNF
FBDD
OBDD
OBDD<
DNF
CNF
PI
IP
MODS

6


sd-DNNF

6

6
6

6

6

6

6

6



6

6

6

6

6

6

6


6
6

6

6

6

6

6




6

6

6

6

6

6





6

6

6

6

6


6






6

6

6

6



6

6

6


6

6

6


6


6



6

6






6





Table 12:
L

NNF

DNNF

d-DNNF

FBDD

OBDD

CNF

PI

IP

MODS

sd-DNNF


6
6
















OBDD<




DNF

NNF
DNNF
d-DNNF





6
6














FBDD

6

6

6







6

6

6

6

OBDD

6

6

6

6





6

6

6

6

OBDD<
DNF
CNF
PI
IP
MODS
sd-DNNF

6
6

6

6

6


6
6

6

6

6


6
6

6

6

6


6
6

6

6

6


6
6

6

6

6



6

6

6

6


6

6

6

6


6
6


6

6


6
6



6


6

6

6



6






6



Table 13:
digraph represented contains k-clique special kind (k parameter family).
shown certain values k (depending n), every FBDD representation exponential
size. Moreover, shown cubic number prime implicants. shows
FBDD 6 IP, hence FBDD 6 DNF. FBDD satisfies C (see Proposition 5.1),8 cannot
case polynomial size FBDD. Since cubic number prime implicates,
obtain FBDD 6 PI, hence FBDD 6 CNF. remaining results table follow since FBDD
OBDD OBDD< .
Table 14: Assume d-DNNF DNF holds. consequence, every sentence DNF
compiled equivalent d-DNNF sentence polynomial size. Now, checking whether clause
entailed CNF sentence equivalent checking whether DNF sentence
valid. Checking whether () validwhen () d-DNNF sentence clausecan
achieved polynomial time Lemma A.11. Therefore, () polysize compilation
8. is, sentence FBDD negated polytime yield sentence FBDD too.

L

NNF

DNNF

d-DNNF

FBDD

OBDD

NNF
DNNF



6











OBDD<



d-DNNF


6

6

DNF

CNF

PI

IP

MODS

sd-DNNF


6

6
















6








FBDD

6

6

6











6

6

6

6

OBDD

6

6

6

6

6





6

6

6

6

OBDD<
DNF

6

6

6

6

6

6



6

6

6

6

6

6

6

6

6

6



6

6



CNF

6

6

6

6

6

6

6





6

PI

6

6

6

6

6

6

6

6



6

IP
MODS

6

6

6

6

6

6

6

6

6



sd-DNNF

6

6


6
6
6
6


6









Table 14:

249

6

6





fiDarwiche & Marquis

L

NNF

DNNF

d-DNNF

FBDD

OBDD

OBDD<

DNF

CNF

PI

IP

MODS

sd-DNNF

NNF
DNNF
d-DNNF


6

6



6



















6


6

6














FBDD

6

6

6







6

6

6

6



6

OBDD

6

6

6

6





6

6

6

6



6

OBDD<
DNF

6
6


6
6


6
6


6
6


6
6



6


6


6
6


6
6


6





6
6


CNF
PI

6
6


6
6


6
6


6
6


6
6


6
6


6
6



6





6
6




6
6


IP

6

6

6

6

6

6

6

6

6





6

MODS
sd-DNNF

6

6

6

6

6


6


6


6


6

6

6

6

6

6




6


Table 15:
CNF sentence , allowing clausal entailment achieved polynomial time. existence
() every CNF sentence implies collapse polynomial hierarchy (Selman &
Kautz, 1996; Cadoli & Donini, 1997). Hence, obtain d-DNNF 6 DNF. consequence,
also d-DNNF 6 DNNF. Finally, since every d-DNNF sentence turned polynomial time
equivalent sd-DNNF sentence Lemma A.1, sd-DNNF d-DNNF. Moreover, since
d-DNNF sd-DNNF, obtain sd-DNNF 6 DNF, sd-DNNF 6 DNNF, sd-DNNF FBDD, sd-DNNF
OBDD, sd-DNNF OBDD< , FBDD 6 sd-DNNF, OBDD< 6 sd-DNNF, DNF 6 sd-DNNF, CNF 6 sd-DNNF, PI
6 sd-DNNF IP 6 sd-DNNF.
Table 15: Let us show WMODS less succinct PI, IP, sd-DNNF OBDD.
n
First, let us consider formula = i=1 xi . represented PI, IP, sd-DNNF OBDD
formulas size polynomial n. Contrastingly, cannot represented MODS formula
size polynomial n since 2n 1 models Vars(). Now, well-known old
good Quine-McCluskeys algorithm generating prime implicants MODS representation
propositional formula runs time polynomial number models (Wegener, 1987).
shows IP MODS. CNF OBDD< , obvious decision tree (or Shannon tree)
respects given total ordering Vars() generated polynomial time
MODS representation . decision tree 1-leaves number models
Vars(). Accordingly, n 0-leaves n = |Vars()|. Since set
paths root tree 0-leaf read CNF representation , obtain
CNF MODS. hand, since reducing decision tree derive corresponding OBDD<
done polynomial time, follows OBDD< representation also generated
MODS representation it. Hence, OBDD< MODS. remaining results table follow
language inclusions reported Figure 4. 2
Proof Proposition 4.1
proof proposition broken twelve steps. step, prove number
results. Associated step proof table mark results
proved step. table last step includes results declared proposition.
Table 16: Every classical CNF DNF formula translated straightforward way
equivalent f-NNF sentence (with tree structure) polytime. Moreover, every NNF sentence
translated equivalent s-NNF sentence polytime (Lemma A.1). Given CO
NP-hard (resp. VA coNP-hard) classical CNF (resp. DNF) sentences, inclusion
various NNF subsets reported Figure 4, obtain table.
Table 17: SE implies CO VA (Lemma A.10). Moreover, since CT implies CO
VA, IM implies VA (valid term), CE implies CO (inconsistent clause), obtain
table.

250

fiA Knowledge Compilation Map

L

CO

VA

NNF





DNNF
d-NNF
d-DNNF
BDD
FBDD
OBDD
OBDD<

CE

IM

EQ

CT

SE

EQ





DNF



CNF
PI
IP
MODS



s-NNF





f-NNF
sd-DNNF





Table 16:

L

CO

VA

CE

IM

CT

SE

NNF





























DNNF
d-NNF
d-DNNF
BDD
FBDD
OBDD
OBDD<



DNF



CNF
PI
IP
MODS





s-NNF













f-NNF
sd-DNNF















Table 17:

L

CO

VA

CE

IM

CT

SE

NNF
DNNF
d-NNF
d-DNNF
BDD
FBDD
OBDD
OBDD<
DNF
CNF
PI
IP

























MODS
s-NNF
f-NNF
sd-DNNF
















EQ








Table 18:

251









fiDarwiche & Marquis

L

CO

VA

CE

IM

CT

SE

NNF





























DNNF
d-NNF
d-DNNF
BDD
FBDD
OBDD
OBDD<
DNF
CNF
PI
IP
MODS
s-NNF
f-NNF
sd-DNNF







EQ












































Table 19:
L

CO

VA

CE

IM

CT

SE



NNF
























DNNF
d-NNF
d-DNNF
BDD
FBDD
OBDD
OBDD<
DNF
CNF
PI
IP





EQ















































































s-NNF















f-NNF


















MODS

sd-DNNF





Table 20:
Table 18: sentence consistent (resp. valid) iff model (resp. 2n models,
n = |Vars()|). Moreover, number models given number edges outgoing
or-node MODS representation . Accordingly, CO, VA CT achieved
polynomial time given MODS formula gives us table.
Table 19:Because DNNF satisfies CE (Darwiche, 2001a), CE implies CO MODS DNF
DNNF, IP DNF
sd-DNNF d-DNNF DNNF, obtain table.
Table 20: use following results:
CD CO imply CE (Lemma A.4).
CD VA imply IM (Lemma A.7).
CD CO imply (Lemma A.3).
considered NNF subsets satify CD (cf. Proposition 5.1).
NNF subset satisfy CO cannot satisfy ME.
well-known FBDD satisfies CO, VA CT, OBDD< satisfies (in addition)
EQ (Gergov & Meinel, 1994a; Bryant, 1992).
Since |= holds iff inconsistent since OBDD< satisfies CO, C BC (cf.
Proposition 5.1), OBDD< also satisfies SE.
252

fiA Knowledge Compilation Map

L

CO

VA

CE

IM

CT

SE



NNF
DNNF
d-NNF
d-DNNF
BDD
FBDD
OBDD
OBDD<
DNF





































CNF







PI
IP
MODS
s-NNF
f-NNF
sd-DNNF













EQ
























































Table 21:
L

CO

VA

CE

IM

CT

SE



NNF
DNNF






















d-NNF
d-DNNF


















BDD
FBDD
OBDD
OBDD<
DNF
CNF
PI
IP
MODS
s-NNF
f-NNF
sd-DNNF






































































EQ





















Table 22:
Obviously enough, query concerning OBDD equivalent corresponding query concerning OBDD< provided one DAG brought play. Together
results, conclude OBDD satisfies CO, VA CT. Since fragment satisfies CD
well, satisfies CE, IM addition. also satisfies EQ (see Theorem 8.11
(Meinel & Theobald, 1998)) satisfy SE (unless P = NP). Indeed, known
checking consistency two OBDD< formulas (based two different variable orderings <) NP-complete (Lemma 8.14 (Meinel & Theobald, 1998)). Since OBDD
satisfies C since consistent iff 6|= , checking sentential entailment OBDD
formulas coNP-complete.
results lead table.
Table 21: known IM satisfied classical CNF formulas (hence, PI) (in order
check whether non-valid clause implied consistent term, sufficient test
share literal). CNF (hence, PI) also known satisfy VA. obtain table.
Table 22: Every sentence CNF DNF turned equivalent sentence BDD
polytime (Lemma A.8). Hence, CNF DNF cell implies corresponding BDD cell.
Similarly, since BDD d-NNF, BDD cell implies corresponding d-NNF cell.
leads table.
Table 23: Since EQ implies CO VA (Lemma A.9), CO VA cell implies
corresponding EQ cell. leads table.
Table 24: definition, PI satisfies CE IP satisfies IM. Since PI CNF IP DNF,
implies PI IP satisfy SE. Now, SE implies EQ, hence PI IP satisfy EQ
(actually, two equivalent formulas share prime implicates prime implicants
(both forms canonical ones, provided one representative per equivalence class considered,
253

fiDarwiche & Marquis

L

CO

VA

CE

IM

EQ

CT

SE



NNF




























d-NNF
d-DNNF




















BDD
FBDD
OBDD
OBDD<





















































DNNF

DNF
CNF
PI
IP
MODS































s-NNF

















f-NNF
sd-DNNF






















Table 23:

L

CO

VA

CE

IM

EQ

CT

SE



NNF
DNNF
d-NNF
d-DNNF
BDD
FBDD
OBDD
OBDD<
DNF
CNF





























































PI
IP
MODS
s-NNF
f-NNF
sd-DNNF
































































Table 24:

254

































fiA Knowledge Compilation Map

L

CO

VA

CE

IM

EQ

CT

SE



NNF
DNNF
d-NNF
d-DNNF
BDD
FBDD
OBDD
OBDD<
DNF
CNF
PI
IP














































































MODS
s-NNF
f-NNF
sd-DNNF


















































































Table 25:
L

CO

VA

CE

IM

EQ

CT

SE



NNF
DNNF
d-NNF





















































































































d-DNNF
BDD
FBDD
OBDD
OBDD<
DNF
CNF
PI
IP
MODS
s-NNF
f-NNF
sd-DNNF









































Table 26:
only)). Since PI satisfies CE, also satisfies CO. Since satisfies CD well (cf. Proposition 5.1),
also satisfies (Lemma A.3). Contrastingly, models counting problem monotone Krom
formulas (i.e. conjunctions clauses containing two literals positive literals)
#P-complete (Roth, 1996). formulas easily turned prime implicates form
polynomial time (Marquis, 2000), hence PI satisfy CT. Now, since negation
formula prime implicates form formula prime implicants form (cf. Lemma A.14),
since number models Vars() 2|Vars()| minus number models
Vars(), necessarily IP satisfy CT. also imply IP satisfies VA,
leading table.
Table 25: proof Proposition 3.1, shown prime implicants
computed polytime MODS representation . immediate consequence, since IP
satisfies IM, EQ SE, obtain MODS satisfies IM, EQ SE, leading table.
Table 26: Since d-DNNF satisfies CT (Darwiche, 2001b), also satisfies VA. Since satisfies
CD (Proposition 5.1), also satisfies IM well (Lemma A.7). Since sd-DNNF d-DNNF,
results follow sd-DNNF. Hence, obtain table.
Table 27: known determining whether conjunction two FBDD formulas 1 2
consistent NP-complete (Gergov & Meinel, 1994b) Moreover, FBDD satisfies C. Since 1 2
inconsistent iff 1 |= 2 , reduce consistency test entailment test. Hence, FBDD
satisfy SE. Since FBDD d-DNNF, d-DNNF satisfy SE either. Finally, since every
d-DNNF translated equivalent sd-DNNF sentence polytime (Lemma A.1), sd-DNNF
satisfy SE either. leads final table above. 2

255

fiDarwiche & Marquis

L

CO

VA

CE

IM

EQ

CT

SE



NNF
DNNF
d-NNF












































d-DNNF
BDD
FBDD
OBDD
OBDD<
DNF
CNF
PI
IP
MODS
s-NNF
f-NNF
sd-DNNF



















































































































Table 27:
Proof Proposition 5.1
proof proposition broken eight steps. step corresponds one
transformations, prove results pertaining transformation.
CD. show language L satisfies CD, want show sentence L
consistent term , construct polytime sentence belongs L
equivalent | .
NNF, f-NNF, CNF DNF. property trivially satisfied languages:
belongs languages, replacing literals Boolean constant
results sentence language. case DNF (resp. CNF),
inconsistent terms (valid clauses) may result conditioning,
removed easily polynomial time.
DNNF. sufficient prove conditioning preserves decomposability. every
propositional sentences , every consistent term , share variables,
| | share variables either since Vars(|) Vars() Vars(|)
Vars().
d-NNF d-DNNF. Since NNF DNNF satisfy CD, sufficient prove conditioning preserves determinism, i.e. every propositional formulas , every consistent
term , |= false, (|) (|) |= false. |= false, every term
, ( ) |= false. Since ( ) (( )|) , implies
(( )|) |= false. Since consistent share variable ( )|, must
case ( )| inconsistent. equivalent state (|) (|) |=
false.
s-NNF sd-DNNF. Since NNF satisfies CD, since conditioning preserves decomposability determinism, show conditioning also preserves smoothness. follows immediately since two propositional sentences , consistent
term , Vars() = Vars() Vars( | ) = Vars( | ).
BDD, FBDD, OBDD OBDD< . wellknown BDD satisfies CDthe conditioning
operation binary decision diagrams known restrict operation (Bryant, 1986).
condition sentence BDD consistent term , replace every node labeled
variable one two children, according sign variable .
resulting sentence also BDD equivalent | . applies FBDD,
OBDD OBDD< .
PI. prime implicates computed polytime prime
implicates form term (see Proposition 36 (Marquis, 2000)). Moreover, since
256

fiA Knowledge Compilation Map

PI satisfies FO (see below), prime implicates Vars().( ) computed
polytime. exactly prime implicates | according Lemma A.12.
Wn
IP.
WnLet = i=1 formula prime implicants form. clear formula
( i=1 ) | DNF formula equivalent | . Now, claim
Wnthat formula
obtained keeping logically weakest terms | among ( i=1 ) | prime
implicants formula equivalent | . Removing terms clearly truth-preserving.
Since generating requires O(n2 ) entailment tests among terms, since
tests easily achieved polynomial time, obtain IP satisfies CD. Now,
prove prime implicants form? Since pair different terms
cannot compared w.r.t. logical entailment, correctness Quines consensus
algorithm generating prime implicants shows sufficient prove every
consensus among two terms inconsistent entails another term . Lets
recall consensus DNF formulas resolution CNF formulas. Since
prime implicants form, every consensus among two terms inconsistent
entails another term . happens terms (here, prime implicants)
conditioned ? containing negation literal removed
remaining ones shortened removing every literal . Hence,
every pair terms 1 , 2 , consensus 1 2 ,
consensus 1 | 2 |: conditioning cannot create new consensus.
Now, remains prove unproductive consensus terms
rendered productive conditioning. Formally, let 1 = 10 l 2 = 20 l
two prime implicates s.t. l (resp. l) appear 10 (resp. 20 ).
consensus 10 20 1 2 . Let us assume 1 2 survived
conditioning: means 1 | 2 | consistent. Especially, l belongs
1 | l belongs 2 |. Accordingly, consensus 1 | 2 |.
construction, consensus equivalent (10 |)(20 |), hence equivalent (10 20 )|.
Now, 10 20 inconsistent, (10 20 )| inconsistent well done.
Otherwise, let us assume exists prime implicant 3 s.t. 10 20 |= 3
holds. Necessarily, 3 preserved conditioning . Otherwise, 3 would
contain negation literal , since every literal 3 literal 1
literal 2 , 2 3 would survived conditioning. Since 10 20 |= 3
holds, necessarily (10 20 )| |= 3 |. completes proof.
MODS. Direct consequence Lemma A.12 fact MODS satisfies BC FO
(see below).
FO.
DNNF DNF. known DNNF satisfies FO (Darwiche, 2001a). also known
DNF satisfies FO (Lang et al., 2000).
NNF, s-NNF, f-NNF, d-NNF, BDD CNF. Let sentence CNF. show
previous languages satisfies FO, test consistency
polytime. Since CNF satisfy CO (see Proposition 4.1), follows none
previous languages satisfy FO unless P = NP. First, note must also
belong NNF f-NNF. Moreover, turned sentence BDD polytime
(Lemma A.8) sentence s-NNF polytime (see proof Lemma A.1).
also turned sentence d-NNF polytime since BDD d-NNF.
Suppose one previous languages, call L, satisfy FO. test
consistency polytime follows:
Convert sentence L polytime (as shown above).
Compute Vars()., done polytime assumption.

257

fiDarwiche & Marquis

Test validity Vars()., done polytime since sentence
contains variablesall check whether sentence evaluates
true.
Finally, note definition forgetting implies sentence consistent iff
Vars(). valid, completes proof.
d-DNNF sd-DNNF. Follows immediately since none languages satisfies SFO
unless P = NP (see below).
IP. Follows immediately since IP satisfy SFO.
FBDD, OBDD OBDD< . show FBDD (resp. OBDD, OBDD< ) satisfies FO,
every sentence DNF, must exist equivalent sentence FBDD (resp.
OBDD, OBDD< ), size polynomial size . contradicts fact
FBDD (resp. OBDD, OBDD< ) 6 DNFsee Table 3.
Given DNF consisting terms 1 , ..., n , convert terms equivalent FBDD (resp. OBDD, OBDD< ) sentences 1 , . . . , n polytime. Let {v1 , . . . , vn1 }
set variables belong P S. Construct new set variables
P 0 = P {v1 , . . . , vn1 }. case OBDD OBDD< , also assume
new variables earlier variables P ordering. Consider sentence
= {v1 , . . . , vn1 }.1 , respect variables P 0 , inductively defined
by:
= , = n,
= (i vi ) (i+1 vi ), = 1, . . . , n 1.
Clearly enough, FBDD (resp. OBDD, OBDD< ) sentence equivalentWto 1 W
computed
n
n
time polynomial input size. Moreover, i=1 i=1 .
Hence, FBDD (resp. OBDD, OBDD< ) satisfies FO, convert DNF sentence
equivalent FBDD (resp. OBDD, OBDD< ) size polynomial size
given DNF. impossible general.
PI. known prime implicates X. exactly prime implicates
contain variable X (see Proposition 55 (Marquis, 2000)). Hence,
prime implicates computed time polynomial input size
prime implicates form.
MODS. Given MODS formula subset X P S, formula obtained removing
every leaf node (and corresponding incoming edges) labeled literal x x
s.t. x X MODS representation X.this easy consequence Propositions
18 20 (Lang et al., 2000). See also polytime operation forgetting DNNF,
defined (Darwiche, 2001a), applies MODS, since
MODS DNNF, easily modified guarantees output
MODS input also MODS.
SFO.
DNNF, DNF, PI MODS. Immediate fact languages satisfies
FO (see above).
NNF, d-NNF, s-NNF, f-NNF, BDD, OBDD< CNF. Direct fact x. (|x)
(|x) holds fact fragments satisfies CD BC.
OBDD. Direct fact one OBDD sentence considered transformation
OBDD< satisfies SFO.
d-DNNF, sd-DNNF FBDD. Let 1 2 two FBDD formulas. Let x variable
included Vars(1 ) Vars(2 ). formula = (x 1 ) (x 2 ) FBDD
258

fiA Knowledge Compilation Map

formula since decomposability decision preserved construction. Since x.
equivalent 1 2 , FBDD would satisfy SFO, would satisfy BC well,
case unless P = NP (see below). conclusion drawn
d-DNNF. Hence, FBDD d-DNNF satisfy SFO unless P = NP. Since every d-DNNF
formula turned polynomial time equivalent sd-DNNF formula, obtain
sd-DNNF satisfy SFO unless P = NP.
IP. Let us show number prime implicants x. exponentially greater
number prime implicants . Let 0 following DNF formula:

0 =

k _

_


(pi qi,j )

i=1 j=1

k
^

pi .

i=1

0 (m + 1)k + mk primes implicants (Chandra & Markowsky, 1978). Now, let
formula:

=

k _

_


(x pi qi,j ) (x

i=1 j=1

k
^

pi ).

i=1

Since 0 obtained removing every term every occurrence x
x, 0 equivalent {x}. (see (Lang et al., 2000)). Now, mk + 1
prime implicants; indeed, every term prime implicant, converse holds
since every term maximal w.r.t. logical entailment every consensus two terms
inconsistent. completes proof.
C.
NNF, s-NNF, d-NNF, CNF. property trivially satisfied languages since determinism smoothness concerned or-nodes. Hence, 1 , . . . , n belong
one languages, 1 . . . n .
BDD. wellknown conjunction two BDDs easily computed
connecting 1-sink root (see proof Lemma A.8). size
resulting BDD sum sizes respective BDDs . Accordingly,
repeat operation n times time polynomial input size.
f-NNF. Direct fact f-NNF satisfy BC.
FBDD, OBDD, OBDD< , DNF, PI IP. straightforward convert clause
equivalent formula languages polynomial time. proof Proposition 3.1, show specific CNF formulas cannot turned equivalent FBDD
(resp. OBDD, OBDD< , DNF, PI IP) formulas polynomial space (see Tables 9 10).
Hence, conversion cannot accomplished polynomial time either. implies
none FBDD, OBDD, OBDD< , DNF, PI IP satisfies C.
DNNF, d-DNNF sd-DNNF. Direct fact none languages satisfy
BC unless
P = NP.
Vn
MODS. Let = i=1 , = (xi,1 xi,2 ), 1..n. 3 models
Vars(i ). Since 3n models, MODS representation size polynomial
input size.
BC.

259

fiDarwiche & Marquis

NNF, s-NNF, d-NNF, BDD CNF. Immediate since languages satisfy C (see
above).
DNNF, d-DNNF, sd-DNNF, FBDD OBDD. Checking whether conjunction two OBDD<
formulas 1 2 (w.r.t. two different variable orderings <) consistent NP-complete
(see Lemma 8.14 (Meinel & Theobald, 1998)). Since OBDD satisfies CO, cannot satisfy
BC unless P = NP. Since OBDD FBDD d-DNNF DNNF, d-DNNF DNNF satisfy
CO, none satisfy BC unless P = NP. Finally, since every d-DNNF formula
turned polynomial time equivalent smoothed d-DNNF formula since
sd-DNNF satisfies CO, cannot case sd-DNNF satisfy BC unless P = NP.
OBDD< . Well-known fact (Bryant, 1986).
Vn1
Wn1
f-NNF. Let 1 = i=0 (x2i x2i+1 ) CNF formula 2 = i=0 (x02i x02i+1 ) DNF
formula. 1 2n essential prime implicants n essential prime implicates (see
proof Proposition 3.1, Table 9). duality, 2 n essential prime implicants 2n
essential prime implicates. Now, 1 2 two f-NNF formulas. Lemma A.13,
know every f-NNF formula turned polynomial time CNF formula
DNF formula. f-NNF would satisfy BC, f-NNF formula s.t. 1 2 could
computed time polynomial input size. Hence, either CNF formula equivalent
1 2 DNF formula equivalent 1 2 could computed polytime.
impossible since 1 2 n + 2n essential prime implicates n 2n essential
prime implicants. Hence every CNF (resp. DNF ) formula equivalent 1 2 size
exponential |1 | + |2 |.
Note case two f-NNF formulas 1 2 consideration
turned polynomial time either two CNF formulas two DNF formulas,
f-NNF formula equivalent 1 2 computed time polynomial input
size (this obvious two CNF formulas considered next item proof
shows achieved two DNF formulas considered).
DNF MODS. 1 2 sentences one languages L, construct
sentence L equivalent 1 2 simply taking conjunctions one
term 1 one term 2 , removing redundant literals resulting
terms removing inconsistent terms result. disjunction
resulting terms sentence L equivalent 1 2 computed
polynomial time.
Vk Vm
Wk
PI. Let 1 = i=1 pi 2 = i=1 j=1 (pi qi,j ). Sentence 1 one prime implicate
2 k prime implicates. 1 2 (m + 1)k + k prime implicates
(Chandra & Markowsky, 1978).
IP. Let IP () set prime implicants . IP (1 2 ) = max({1
2 | 1 IP (1 ), 2 IP (2 )}, |=) (up logical equivalence). See e.g., (dual of) Proposition 40 (Marquis, 2000).

260

fiA Knowledge Compilation Map

C.
NNF, s-NNF, DNNF DNF. property trivially satisfied languages since
decomposability concerned and-nodes, since every NNF formula
turned polynomial time equivalent smoothed NNF formula.
d-NNF BDD. Direct consequence fact d-NNF BDD satisfies C
C. Especially, well-known disjunction two BDDs
easily computed connecting 0-sink root (see proof
Lemma A.8). size resulting BDD sum sizes respective
BDDs . Accordingly, repeat operation n times time polynomial
input size.
f-NNF. Since f-NNF satisfy C satisfies C, cannot satisfy C (due
De Morgans laws).
FBDD, OBDD, OBDD< , CNF, PI, IP MODS. straightforward convert term
equivalent formula previous languages polynomial time.
proof Proposition 3.1, show specific DNF formulas cannot turned
equivalent FBDD (resp. OBDD, OBDD< , CNF , PI, IP MODS) formulas polynomial space
(see Tables 9, 10 15). Hence, conversion cannot accomplished polynomial
time either. implies none FBDD, OBDD, OBDD< , CNF, PI, IP MODS satisfies
C.
d-DNNF sd-DNNF. Immediate form fact none classes satisfies BC
unless P = NP (see below).
BC.
NNF, d-NNF, DNNF, s-NNF, BDD DNF. Immediate since languages satisfies
C.
OBDD< . Well-known fact (Bryant, 1986).
OBDD, FBDD, d-DNNF sd-DNNF. Checking whether conjunction two OBDD< formulas 1 2 (w.r.t. two different variable orderings <) consistent NP-complete (see
Lemma 8.14 (Meinel & Theobald, 1998)). Now, 1 2 inconsistent iff 1 2
valid. Since OBDD satisfies C, OBDD formula equivalent 1 (resp. 2 )
computed time polynomial |1 | (resp. |2 |). Since OBDD FBDD d-DNNF,
resulting formulas also FBDD d-DNNF formulas. OBDD (resp. FBDD, d-DNNF)
would satisfy BC, OBDD (resp. FBDD, d-DNNF) formula equivalent 1 2
could computed time polynomial |1 | + |2 |. since d-DNNF satisfies VA,
impossible unless P = NP. Finally, since every d-DNNF formula turned
polynomial time equivalent sd-DNNF formula, sd-DNNF cannot satisfy BC unless
P = NP.
f-NNF. Since f-NNF satisfy BC satisfies C, cannot satisfy BC (due
De Morgans laws).
CNF. 1 2 two CNF sentences, construct CNF sentence
equivalent 1 2 simply taking disjunctions one clause 1
one clause 2 , removing redundant literals inside resulting clauses
removing valid clause result. conjunction resulting clauses
CNF sentence equivalent 1 2 , computed polynomial time.
PI. Let PI () set prime implicates sentence . PI (1 2 ) =
min({1 2 | 1 PI (1 ), 2 PI (2 )}, |=). See Proposition 40 (Marquis, 2000).

261

fiDarwiche & Marquis

Vk
Wk Wm
IP. Let 1 = i=1 pi 2 = i=1 j=1 (pi qi,j ). Sentence 1 one prime implicant
2 k prime implicants. 1 2 (m + 1)k + k prime implicants
(Chandra & Markowsky, 1978).
Vn
MODS. Let 1 = i=1 xi 2 = y. Sentence 1 1 model Vars(1 ) 2
1 model Vars(2 ). 1 2 2n + 1 models Vars(1 ) Vars(2 ).
C.
NNF, s-NNF, f-NNF, BDD, FBDD, OBDD OBDD< . property obviously satisfied
NNF. s-NNF also satisfies C since every NNF formula turned polynomial time
equivalent s-NNF formula. f-NNF satisfies C since applying De Morgans laws
f-NNF formula results f-NNF formula. Finally, forms BDDs,
sufficient switch labels sinks achieve negation (Bryant, 1986).
CNF. negation DNF formula CNF formula computed
polynomial time, CNF would satisfy C, would possible turn DNF
formula equivalent CNF formula polynomial time (by involution negation).
know possible polynomial space since CNF 6 DNF(see proof
Proposition 3.1). Hence, CNF satisfy C.
DNF. Dual proof (just replace CNF DNF vice-versa).
Vn1
PI. formula n = i=0 (x2i x2i+1 ) prime implicates form (see proof
Proposition 3.1, Table 9). formula exponentially many prime implicants,
negations prime implicates n . Since n exponentially many
prime implicates, cannot case PI satisfies C.
IP. take dual proof (prime implicates case). formula
Wn1
n = i=0 (x2i x2i+1 ) prime implicants form. formula exponentially many
prime implicates, negations prime implicants n . Since n
exponentially many prime implicants, cannot case IP satisfies C.
DNNF. negation CNF formula computed polynomial time DNF
formula, hence DNNF formula. DNNF would satisfy C, would possible
turn CNF formula equivalent DNNF one (by involution negation).
DNNF satisfies CO, would P = NP.
d-NNF. Following procedure negating d-NNF sentence :9
Traverse nodes DAG , visiting children node visit
node itself. visiting node, construct negation follows:
true negation false.
false negation true.
(N10 , . . . , Nk0 ) negation (N1 , . . . , Nk ). Here, Ni0 node representing
negation Ni .
((N10 , M1 ), . . . , (Nk0 , Mk )) negation (N1 , . . . , Nk ). Here, Ni0
node representing negation Ni , Mi node representing conjunction N1 . . . Ni1 .
Return negation root d-NNF .
implement four steps visit node k children,
construct O(k) nodes O(k) edges.10 Hence, procedure complexity
9. Mark Hopkins pointed us procedure.
10. assume or-node (resp. and-node) less two children removed replaced unique
child f alse (resp. true) children. simplification process equivalence-preserving
achieved time linear size input DAG.

262

fiA Knowledge Compilation Map

linear size original d-NNF. easy check result equivalent
negation given d-NNF sentence also d-NNF.
sd-DNNF d-DNNF. Unknown.
Vn
Sn
MODS. = Si=1 xi one model i=1 {xi } negation 2n 1
n
models i=1 {xi }. Hence MODS cannot satisfy C. 2

References
A. Cimmati, E. Giunchiglia, F. G., & Traverso, P. (1997). Planning via model checking: decision
procedure AR. Proceedings 4th European Conference Planning (ECP97), pp.
130142.
Blum, M., Chandra, A. K., & Wegman, M. N. (1980). Equivalence free Boolean graphs
decided probabilistically polynomial time. Information Processing Letters, 10 (2), 8082.
Boole, G. (1854). investigation laws thought. Walton Maberley, London.
Boufkhad, Y., Gregoire, E., Marquis, P., Mazure, B., & Sas, L. (1997). Tractable cover compilations.
Proc. 15th International Joint Conference Artificial Intelligence (IJCAI97), pp.
122127, Nagoya.
Bryant, R. E. (1986). Graph-based algorithms Boolean function manipulation. IEEE Transactions Computers, C-35, 677691.
Bryant, R. E. (1992). Symbolic Boolean manipulation ordered binary decision diagrams. ACM
Computing Surveys, 24 (3), 293318.
Cadoli, M., & Donini, F. (1997). survey knowledge compilation. AI Communications, 10,
137150. (printed 1998).
Cadoli, M., Donini, F., Liberatore, P., & Schaerf, M. (1996). Comparing space efficiency propositional knowledge representation formalisms. Proc. 5rd International Conference
Knowledge Representation Reasoning (KR96), pp. 364373.
Chandra, A., & Markowsky, G. (1978). number prime implicants. Discrete Mathematics,
24, 711.
Darwiche, A. (1999). Compiling knowledge decomposable negation normal form. Proceedings
International Joint Conference Artificial Intelligence (IJCAI99), pp. 284289. Morgan
Kaufmann, California.
Darwiche, A. (2001a). Decomposable negation normal form. Journal ACM, 48 (4), 608647.
Darwiche, A. (2001b). tractability counting theory models application belief
revision truth maintenance. Journal Applied Non-Classical Logics, 11 (1-2), 1134.
Darwiche, A., & Huang, J. (2002). Testing equivalence probabilistically. Tech. rep. D123, Computer
Science Department, UCLA, Los Angeles, Ca 90095.
de Kleer, J. (1992). improved incremental algorithm generating prime implicates. Proc.
10th National Conference Artificial Intelligence (AAAI92), pp. 780785, San Jose,
California.
Dechter, R., & Rish, I. (1994). Directional resolution: Davis-Putnam procedure, revisited.
Proceedings Fourth International Conference Principles Knowledge Representation
Reasoning (KR94), pp. 134145, Bonn.
del Val, A. (1994). Tractable databases: make propositional unit resolution complete
compilation. Proceedings International Conference Principles Knowledge Representation Reasoning (KR94), pp. 551561. Morgan Kaufmann Publishers, Inc., San
Mateo, California.
263

fiDarwiche & Marquis

Gergov, J., & Meinel, C. (1994a). Efficient analysis manipulation obdds extended
fbdds. IEEE Transactions Computers, 43 (10), 11971209.
Gergov, J., & Meinel, C. (1994b). complexity analysis manipulation Boolean
functions terms decision diagrams. Information Processing Letters, 50, 317322.
Gogic, G., Kautz, H., Papadimitriou, C., & Selman, B. (1995). comparative linguistics
knowledge representation. Proc. 14th International Joint Conference Artificial
Intelligence (IJCAI95), pp. 862869, Montreal.
Herzig, A., & Rifi, O. (1999). Propositional belief base update minimal change. Artificial
Intelligence, 115 (1), 107138.
Karp, R., & Lipton, R. (1980). connections non-uniform uniform complexity
classes. Proc. 12th ACM Symposium Theory Computing (STOC80), pp. 302
309.
Khardon, R., & Roth, D. (1997). Learning reason. Journal ACM, 44 (5), 697725.
Lang, J., Liberatore, P., & Marquis, P. (2000). Propositional independencePart I: formulavariable
independence forgetting. Submitted.
Madre, J. C., & Coudert, O. (1992). new method compute prime essential prime implicants
boolean functions. Advanced research VLSI parallel systems, Proceedings
Brown/MIT conference, pp. 113128.
Marquis, P. (2000). Consequence finding algorithms, Vol. 5 Handbook Defeasible Reasoning
Uncertainty Management Systems: Algorithms Uncertain Defeasible Reasoning.
Kluwer Academic Publishers.
Marquis, P. (1995). Knowledge compilation using theory prime implicates. Proc. International
Joint Conference Artificial Intelligence (IJCAI95), pp. 837843. Morgan Kaufmann Publishers, Inc., San Mateo, California.
Meinel, C., & Theobald, T. (1998). Algorithms Data Structures VLSI Design: OBDD Foundations Applications. Springer.
Papadimitriou, C. (1994). Computational complexity. AddisonWesley.
Quine, W. (1955). way simplify truth functions. American Mathematical Monthly, 52, 627631.
Quine, W. (1959). cores prime implicants truth functions. American Mathematical
Monthly, 66, 755760.
Reiter, R., & de Kleer, J. (1987). Foundations assumption-based truth maintenance systems:
Preliminary report. Proceedings Fifth National Conference Artificial Intelligence
(AAAI), pp. 183188.
Roth, D. (1996). hardness approximate reasoning. Artificial Intelligence, 82 (1-2), 273302.
Schrag, R. (1996). Compilation critically constrained knowledge bases. Proc. 13th
National Conference Artificial Intelligence (AAAI96), pp. 510515, Portland, Oregan.
Selman, B., & Kautz, H. (1996). Knowledge compilation theory approximation. Journal
Association Computing Machinery, 43, 193224.
Simon, L., & del Val, A. (2001). Efficient consequence finding. Proc. 17th International
Joint Conference Artificial Intelligence (IJCAI01), pp. 359365, Seattle (WA).
Wegener, I. (1987). complexity boolean functions. Wiley-Teubner, Stuttgart.

264

fiJournal Artificial Intelligence Research 17 (2002) 379-449

Submitted 4/02; published 12/02

Specific-to-General Learning Temporal Events
Application Learning Event Definitions Video
Alan Fern
Robert Givan
Jeffrey Mark Siskind

AFERN @ PURDUE . EDU
GIVAN @ PURDUE . EDU
QOBI @ PURDUE . EDU

School Electrical Computer Engineering
Purdue University, West Lafayette, 47907 USA

Abstract
develop, analyze, evaluate novel, supervised, specific-to-general learner simple temporal logic use resulting algorithm learn visual event definitions video
sequences. First, introduce simple, propositional, temporal, event-description language called
AMA sufficiently expressive represent many events yet sufficiently restrictive support
learning. give algorithms, along lower upper complexity bounds, subsumption generalization problems AMA formulas. present positive-examplesonly
specific-to-general learning method based algorithms. also present polynomialtimecomputable syntactic subsumption test implies semantic subsumption without
equivalent it. generalization algorithm based syntactic subsumption used place
semantic generalization improve asymptotic complexity resulting learning algorithm.
Finally, apply algorithm task learning relational event definitions video
show yields definitions competitive hand-coded ones.

1. Introduction
Humans conceptualize world terms objects events. reflected fact
talk world using nouns verbs. perceive events taking place objects,
interact world performing events objects, reason effects
actual hypothetical events performed us others objects. also learn new
object event types novel experience. paper, present evaluate novel implemented techniques allow computer learn new event types examples. show results
application techniques learning new event types automatically constructed
relational, force-dynamic descriptions video sequences.
wish acquired knowledge event types support multiple modalities. Humans
observe someone faxing letter first time quickly able recognize future occurrences
faxing, perform faxing, reason faxing. thus appears likely humans use
learn event representations sufficiently general support fast efficient use multiple
modalities. long-term goal research allow similar cross-modal learning use
event representations. intend learned representations used vision (as described
paper), planning (something beginning investigate), robotics (something
left future).
crucial requirement event representations capture invariants event
type. Humans classify picking cup table picking dumbbell floor
picking up. suggests human event representations relational. abstract

c 2002 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiF ERN , G IVAN , & ISKIND

relational notion picking parameterized participant objects rather distinct
propositional notions instantiated specific objects. Humans also classify event picking
matter whether hand moving slowly quickly, horizontally vertically, leftward
rightward, along straight path circuitous one. appears characteristics
participant-object motion distinguish picking event types. Rather, fact
object picked changes supported resting initial location
supported grasped agent. suggests primitive relations used
build event representations force dynamic (Talmy, 1988).
Another desirable property event representations perspicuous. Humans
introspect describe defining characteristics event types. introspection allows us create dictionaries. support introspection, prefer representation language
allows characteristics explicitly manifest event definitions emergent consequences distributed parameters neural networks hidden Markov models.
develop supervised learner event representation possessing desired characteristics follows. First, present simple, propositional, temporal logic called AMA
sublanguage variety familiar temporal languages (e.g. linear temporal logic, LTL Bacchus & Kabanza, 2000, event logic Siskind, 2001). logic expressive enough describe
variety interesting temporal events, restrictive enough support effective learner,
demonstrate below. proceed develop specific-to-general learner AMA logic giving algorithms complexity bounds subsumption generalization problems involving
AMA formulas. show semantic subsumption intractable, provide weaker syntactic notion subsumption implies semantic subsumption checked polynomial
time. implemented learner based upon syntactic subsumption.
next show means adapt (propositional) AMA learner learn relational concepts.
evaluate resulting relational learner complete system learning force-dynamic event
definitions positive-only training examples given real video sequences. first
system perform visual-event recognition video. review prior work compare
current work later paper. fact, two prior systems built one
authors. H OWARD (Siskind & Morris, 1996) learns classify events video using temporal,
relational representations. representations force dynamic. L EONARD (Siskind,
2001) classifies events video using temporal, relational, force-dynamic representations
learn representations. uses library hand-code representations. work adds
learning component L EONARD , essentially duplicating performance hand-coded
definitions automatically.
demonstrated utility learner visual-eventlearning domain,
note many domains interesting concepts take form structured temporal sequences events. machine planning, macro-actions represent useful temporal patterns
action. computer security, typical application behavior, represented perhaps temporal patterns system calls, must differentiated compromised application behavior (and likewise
authorized-user behavior intrusive behavior).
follows, Section 2 introduces application domain recognizing visual events
provides informal description system learning event definitions video. Section 3
introduces AMA language, syntax semantics, several concepts needed analysis
language. Section 4 develops analyzes algorithms subsumption generalization
problems language, introduces practical notion syntactic subsumption. Sec380

fiL EARNING EMPORAL E VENTS

tion 5 extends basic propositional learner handle relational data negation, control
exponential run-time growth. Section 6 presents results visual-event learning. Sections 7
8 compare related work conclude.

2. System Overview
section provides overview system learning recognize visual events video.
aim provide intuitive picture system providing technical details. formal
presentation event-description language, algorithms, theoretical empirical results appears Sections 36. first introduce application domain visual-event recognition
L EONARD system, event recognizer upon learner built. Second, describe
positive-only learner fits overall system. Third, informally introduce AMA
event-description language used learner. Finally, give informal presentation
learning algorithm.
2.1 Recognizing Visual Events
L EONARD (Siskind, 2001) system recognizing visual events video camera input
example simple visual event hand picking block. research originally
motivated problem adding learning component L EONARDallowing L EONARD
learn recognize event viewing example events type. Below, give high-level
description L EONARD system.
L EONARD three-stage pipeline depicted Figure 1. raw input consists video-frame
image sequence depicting events. First, segmentation-and-tracking component transforms
input polygon movie: sequence frames, frame set convex polygons placed
around tracked objects video. Figure 2a shows partial video sequence pick event
overlaid corresponding polygon movie. Next, model-reconstruction component
transforms polygon movie force-dynamic model. model describes changing
support, contact, attachment relations tracked objects time. Constructing
model somewhat involved process described Siskind (2000). Figure 2b shows
visual depiction force-dynamic model corresponding pick event. Finally, eventrecognition component armed library event definitions determines events occurred
model and, accordingly, video. Figure 2c shows text output input
event-recognizer pick event. first line corresponds output indicates
interval(s) pick occurred. remaining lines text encoding
event-recognizer input (model-reconstruction output), indicating time intervals various
force-dynamic relations true video.
event-recognition component L EONARD represents event types event-logic formulas like following simplified example, representing x picking z .

4

P ICK U P (x; y; z ) = (S UPPORTS (z; ) ^ C ONTACTS (z; )); (S UPPORTS (x; ) ^ ATTACHED (x; ))

formula asserts event x picking z defined sequence two states
z supports way contact first state x supports way attachment
second state. UPPORTS , C ONTACTS , ATTACHED primitive force-dynamic relations.
formula specific example general class AMA formulas use
learning.
381

fiF ERN , G IVAN , & ISKIND

image
sequence

Segmentation
Tracking

polygonscene
sequence

Model
Reconstruction

training
models
event
labels

model
sequence

Event
Learner

Event
Classification

event
labels

learned event
definitions

Figure 1: upper boxes represent three primary components L EONARDs pipeline.
lower box depicts event-learning component described paper. input
learning component consists training models target events (e.g., movies pick
events) along event labels (e.g., P ICK U P (hand; red; green)) output
event definition (e.g., temporal logic formula defining P ICK U P (x; y; z )).
2.2 Adding Learning Component
Prior work reported paper, definitions L EONARD event-recognition library
hand coded. Here, add learning component L EONARD learn recognize
events. Figure 1 shows event learner fits overall system. input event
learner consists force-dynamic models model-reconstruction stage, along event
labels, output consists event definitions used event recognizer. take
supervised-learning approach force-dynamic model-reconstruction process applied
training videos target event type. resulting force-dynamic models along labels
indicating target event type given learner induces candidate definition
event type.
example, input learner might consist two models corresponding two videos,
one hand picking red block green block label P ICK U P (hand; red; green)
one hand picking green block red block label P ICK U P (hand; green; red)the
output would candidate definition P ICK U P (x; y; z ) applicable previously unseen
pick events. Note learning component positive-only sense learning
target event type uses positive training examples (where target event occurs)
use negative examples (where target event occur). positive-only setting
interest appears humans able learn many event definitions given primarily
positive examples. practical standpoint, positive-only learner removes often difficult
task collecting negative examples representative event learned
(e.g., typical non-pickup event?).
construction learner involves two primary design choices. First, must choose
event representation language serve learners hypothesis space (i.e., space event definitions may output). Second, must design algorithm selecting good event definition
hypothesis space given set training examples event type.
2.3 AMA Hypothesis Space
full event logic supported L EONARD quite expressive, allowing specification
wide variety temporal patterns (formulas). help support successful learning, use
382

fiL EARNING EMPORAL E VENTS

(a)

Frame 0

Frame 1

Frame 2

Frame 13

Frame 14

Frame 20

Frame 0

Frame 1

Frame 2

Frame 13

Frame 14

Frame 20

(b)

(PICK-UP HAND RED GREEN)@{[[0,1],[14,22])}

(c)

(SUPPORTED? RED)@{[[0:22])}
(SUPPORTED? HAND)@{[[1:13]), [[24:26])}
(SUPPORTS? RED HAND)@{[[1:13]), [[24:26])}
(SUPPORTS? HAND RED)@{[[13:22])}
(SUPPORTS? GREEN RED)@{[[0:14])}
(SUPPORTS? GREEN HAND)@{[[1:13])}
(CONTACTS? RED GREEN)@{[[0:2]), [[6:14])}
(ATTACHED? RED HAND)@{[[1:26])}
(ATTACHED? RED GREEN)@{[[1:6])}

Figure 2: L EONARD recognizes pick event. (a) Frames raw video input automatically generated polygon movie overlaid. (b) frames visual depiction
automatically generated force-dynamic properties. (c) text input/output
event classifier corresponding depicted movie. top line output
remaining lines make input encodes changing force-dynamic properties.
GREEN represents block table RED represents block picked up.

383

fiF ERN , G IVAN , & ISKIND

restrictive subset event logic, called AMA, learners hypothesis space. subset excludes
many practically useless formulas may confuse learner, still retaining substantial
expressiveness, thus allowing us represent learn many useful event types. restriction
AMA formulas form syntactic learning bias.
basic AMA formulas called states express constant properties time intervals arbitrary duration. example, UPPORTS (z; ) ^ C ONTACTS (z; ) state tells us
z must support contact . general, state conjunction number
primitive propositions (in case force-dynamic relations). Using AMA also describe
sequences states. example, (S UPPORTS (z; ) ^ C ONTACTS (z; )) ; (S UPPORTS (x; ) ^
ATTACHED (x; )) sequence two states, first state given second
state indicating x must support attached . formula true whenever first
state true time interval, followed immediately second state true
time interval meeting first time interval. sequences called timelines since
Meets Ands. general, timelines contain number states. Finally,
conjoin timelines get AMA formulas (Ands MAs). example, AMA formula

[(S UPPORTS (z; y) ^ C ONTACTS (z; y)) ; (S UPPORTS (x; y) ^ ATTACHED (x; y))] ^
[(S UPPORTS (u; v) ^ ATTACHED (u; v)) ; (S UPPORTS (w; v) ^ C ONTACTS (w; v))]
defines event two timelines must true simultaneously time interval.
Using AMA formulas represent events listing various property sequences (MA timelines),
must occur parallel event unfolds. important note, however,
transitions states different timelines AMA formula occur relation one
another. example, AMA formula, transition two states first
timeline occur before, after, exactly transition states second timeline.
important assumption leveraged learner primitive propositions used construct states describe liquid properties (Shoham, 1987). purposes, say property
liquid holds time-interval holds subintervals. force-dynamic
properties produced L EONARD liquide.g., hand UPPORTS block interval
clearly hand supports block subintervals. primitive propositions
liquid, properties described states (conjunctions primitives) also liquid. However, properties described AMA formulas not, general, liquid.
2.4 Specific-to-General Learning Positive Data
Recall examples wish classify learn force-dynamic models,
thought (and derived from) movies depicting temporal events. Also recall
learner outputs definitions AMA hypothesis space. Given AMA formula, say
covers example model true model. particular target event type (such
P ICK U P ), ultimate goal learner output AMA formula covers example
model model depicts instance target event type. understand
learner, useful define generality relationship AMA formulas. say AMA
formula 1 general (less specific) AMA formula 2 2 covers every
example 1 covers (and possibly more).1
1. formal analysis, use two different notions generality (semantic syntactic). section,
ignore distinctions. note, however, algorithm informally describe later section based
syntactic notion generality.

384

fiL EARNING EMPORAL E VENTS

learning goal find AMA formula consistent set positiveonly training data, one result trivial solution returning formula covers
examples. Rather fix problem adding negative training examples (which rule
trivial solution), instead change learning goal finding least-general
formula covers positive examples.2 learning approach pursued
variety different languages within machine-learning literature, including clausal first-order
logic (Plotkin, 1971), definite clauses (Muggleton & Feng, 1992), description logic (Cohen &
Hirsh, 1994). important choose appropriate hypothesis space bias learning
approach hypothesis returned may simply (or resemble) one two extremes, either
disjunction training examples universal hypothesis covers examples.
experiments, found that, enough training data, least-general AMA formula often
converges usefully.
take standard specific-to-general machine-learning approach finding least-general
AMA formula covers set positive examples. approach relies computation two
functions: least-general covering formula (LGCF) example model least-general
generalization (LGG) set AMA formulas. LGCF example model least general
AMA formula covers example. Intuitively, LGCF AMA formula captures
information model. LGG set AMA formulas least-general AMA
formula general formula set. Intuitively, LGG formula set
AMA formula captures largest amount common information among formulas.
Viewed differently, LGG formula set covers examples covered formulas,
covers examples possible (while remaining AMA).3
resulting specific-to-general learning approach proceeds follows. First, use LGCF
function transform positive training model AMA formula. Second, return LGG
resulting formulas. result represents least-general AMA formula covers
positive training examples. Thus, specify learner, remains provide algorithms computing LGCF LGG AMA language. informally describe
algorithms computing functions, formally derived analyzed Sections 3.4 4.
2.5 Computing AMA LGCF
increase readability presentation, follows, dispense presenting examples primitive properties meaningfully named force-dynamic relations. Rather,
examples utilize abstract propositions b. current application, propositions correspond exclusively force-dynamic properties, may applications.
demonstrate system computes LGCF example model.
Consider following example model: fa@[1; 4]; b@[3; 6]; c@[6; 6]; d@[1; 3]; d@[5; 6]g . Here,
take number (1, . . . , 6) represent time interval arbitrary (possibly varying
number) duration nothing changes, fact p@[i; j ] indicates proposition p continuously true throughout time intervals numbered j . model
depicted graphically, shown Figure 3. top four lines figure indicate time
2. avoids need negative examples corresponds finding specific boundary version space
(Mitchell, 1982).
3. existence uniqueness LGCF LGG defined formal property hypothesis space
proven AMA Sections 3.4 4, respectively.

385

fiF ERN , G IVAN , & ISKIND

1

2



3

4





b

b

5

6

b

b
c


a^d







; a^b^d ; a^b ; b^d ; b^c^d

Figure 3: LGCF Computation. top four horizontal lines figure indicate intervals propositions a; b; c true model given
fa@[1; 4]; b@[3; 6]; c@[6; 6]; d@[1; 3]; d@[5; 6]g . bottom line shows model
divided intervals transitions occur. LGCF timeline,
shown bottom figure, state no-transition intervals.
state simply contains true propositions within corresponding interval.
intervals propositions a; b; c, true model. bottom line
figure shows model divided five time intervals propositions
change truth value. division possible assumption propositions
liquid. allows us, example, break time-interval true three consecutive subintervals true. dividing model intervals transitions,
compute LGCF simply treating intervals state timeline,
states contain propositions true corresponding time interval.
resulting five-state timeline shown bottom figure. show later simple
computation returns LGCF model. Thus, see LGCF model always
timeline.
2.6 Computing AMA LGG
describe algorithm computing LGG two AMA formulasthe LGG
formulas computed via sequence 1 pairwise LGG applications, discussed later.
Consider two timelines: 1 = (a ^ b ^ c); (b ^ c ^ d); e 2 = (a ^ b ^ e); a; (e ^ d).
useful consider various ways timelines true simultaneously along
arbitrary time interval. this, look various ways two timelines
aligned along time interval. Figure 4a shows one many possible alignments
timelines. call alignments interdigitationsin general, exponentially many
interdigitations, one ordering state transitions differently. Note interdigitation
allowed constrain two transitions different timelines occur simultaneously (though
depicted figure).4
4. Thus, interdigitation provides ordering relation transitions need anti-symmetric, reflexive,
transitive, total.

386

fiL EARNING EMPORAL E VENTS

(a)

a^b^e
(b)

a^b^c

b^c^d



e^d

e

a^b^c a^b^c a^b^c b^c^d
a^b^e
a^b ;



e^d

e^d



; true ;



e
e^d
;

e

Figure 4: Generalizing timelines (a ^ b ^ c); (b ^ c ^ d); e (a ^ b ^ e); a; (e ^ d). (a)
One exponentially many interdigitations two timelines. (b) Computing
interdigitation generalization corresponding interdigitation part (a). States
formed intersecting aligned states two timelines. state true represents
state propositions.

Given interdigitation two timelines, easy construct new timeline must
true whenever either timelines true (i.e., construct generalization two timelines).
Figure 4b, give construction interdigitation given Figure 4a. top two
horizontal lines figure correspond interdigitation, divided every state
either timeline two identical states, whenever transition occurs state
timeline. resulting pair timelines simultaneous transitions viewed
sequence state pairs, one timeline. bottom horizontal line labeled
timeline one state state pair, state intersection
proposition sets state pair. Here, true represents empty set propositions, state
true anywhere.
call resulting timeline interdigitation generalization (IG) 1 2 .
clear IG true whenever either 1 2 true. particular, 1 holds along
time-interval model, sequence consecutive (meeting) subintervals
sequence states 1 true. construction, IG aligned relative 1 along
interval view states sets, states IG subsets corresponding
aligned state(s) 1 . Thus, IG states true model alignment, showing
IG true model.
general, exponentially many IGs two input timelines, one possible
interdigitation two. Clearly, since IG generalization input timelines,
conjunction IGs. conjunction AMA formula generalizes
input timelines. fact, show later paper AMA formula LGG
two timelines. show conjunction IGs 1 2 serves
LGG.
387

fiF ERN , G IVAN , & ISKIND

[(a ^ b); b; e; true; e] ^
[(a ^ b); b; true; e] ^
[(a ^ b); b; true; true; e] ^
[(a ^ b); b; true; e] ^
[(a ^ b); b; true; d; e] ^
[(a ^ b); true; true; e] ^
[(a ^ b); true; e] ^
[(a ^ b); true; d; e] ^
[(a ^ b); a; true; true; e] ^
[(a ^ b); a; true; e] ^
[(a ^ b); a; true; d; e] ^
[(a ^ b); a; d; e] ^
[(a ^ b); a; true; d; e]
formula LGG, contains redundant timelines pruned. First,
clear different IGs result timelines, remove one copy
timeline LGG. Second, note timeline 0 general timeline
, ^ 0 equivalent thus, prune away timelines generalizations
others. Later paper, show efficiently test whether one timeline general
another. performing pruning steps, left first next last
timelines formulathus, [(a ^ b); a; d; e] ^ [(a ^ b); b; e; true; e] LGG 1
2 .
demonstrated compute LGG pairs timelines. use
procedure compute LGG pairs AMA formulas. Given two AMA formulas compute
LGG simply conjoining LGGs pairs timelines (one AMA formula)
i.e., formula
m^
n
^
LGG(i ; 0j )
j

LGG two AMA formulas 1 ^ ^ 01 ^ ^ 0n , 0j
timelines.
informally described LGCF LGG operations needed carry
specific-to-general learning approach described above. follows, formally develop
operations analyze theoretical properties corresponding problems, discuss
needed extensions bring (exponential, propositional, negation-free) operations
practice.

3. Representing Events AMA
present formal account AMA hypothesis space analytical development
algorithms needed specific-to-general learning AMA. Readers primarily interested
high-level view algorithms empirical evaluation may wish skip Sections 3 4
instead proceed directly Sections 5 6, discuss several practical extensions
basic learner present empirical evaluation.
study subset interval-based logic called event logic (Siskind, 2001) utilized
L EONARD event recognition video sequences. logic interval-based explicitly rep388

fiL EARNING EMPORAL E VENTS

resenting possible interval relationships given originally Allen (1983) calculus
interval relations (e.g., overlaps, meets, during). Event-logic formulas allow definition
event types specify static properties intervals directly dynamic properties
hierarchically relating sub-intervals using Allen relations. paper, formal syntax
semantics full event logic needed Proposition 4 given Appendix A.
restrict attention much simpler subset event logic call AMA, defined
below. believe choice event logic rather first-order logic, well restriction
AMA fragment event logic, provide useful learning bias ruling large number
practically useless concepts maintaining substantial expressive power. practical utility
bias demonstrated via empirical results visual-eventrecognition application.
AMA also seen restriction LTL (Bacchus & Kabanza, 2000) conjunction
Until, similar motivations. present syntax semantics AMA along
key technical properties AMA used throughout paper.
3.1 AMA Syntax Semantics
natural describe temporal events specifying sequence properties must hold
consecutive time intervals. example, hand picking block might become block
supported hand block supported hand. represent
sequences timelines5 , sequences conjunctive state restrictions. Intuitively,
timeline given sequence propositional conjunctions, separated semicolons,
taken represent set events temporally match sequence consecutive conjunctions.
AMA formula conjunction number timelines, representing events
simultaneously viewed satisfying conjoined timelines. Formally, syntax
AMA formulas given by,
state

AMA

::= true j prop j prop ^ state
::= (state) j (state);
// may omit parens
::= j ^ AMA

prop primitive proposition (sometimes called primitive event type). take
grammar formally define terms timeline, formula, AMA formula, state. k formula formula k states, k -AMA formula AMA formula
whose timelines k -MA timelines. often treat states proposition sets
true empty set AMA formulas MA-timeline sets. may also treat formulas
sets statesit important note, however, formulas may contain duplicate states,
duplication significant. reason, treating timelines sets,
formally intend sets state-index pairs (where index gives states position formula).
indicate explicitly avoid encumbering notation, implicit index must
remembered whenever handling duplicate states.
semantics AMA formulas defined terms temporal models. temporal model
= hM; set PROP propositions pair mapping natural numbers
(representing time) truth assignments PROP, closed natural-number interval .
note Siskind (2001) gives continuous-time semantics event logic models
5. stands Meets/And, timeline Meet sequence conjunctively restricted intervals.

389

fiF ERN , G IVAN , & ISKIND

defined terms real-valued time intervals. temporal models defined use discrete
natural-number time-indices. However, results still apply continuous-time semantics. (That semantics bounds number state changes continuous timeline countable number.) important note natural numbers domain representing
time discretely, prescribed unit continuous time represented natural
number. Instead, number represents arbitrarily long period continuous time
nothing changed. Similarly, states timelines represent arbitrarily long periods time
conjunctive restriction given state holds. satisfiability relation AMA
formulas given follows:




state satisfied model hM; iff [x] assigns P true every x 2 P



AMA formula 1 ^ 2 ^ ^ n satisfied iff satisfied M.

2 s.

timeline s1 ; s2 ; : : : ; sn satisfied model hM; [t; t0 ]i iff exists t00
[t; t0 ] hM; [t; t00 ]i satisfies s1 either hM; [t00 ; t0 ]i hM; [t00 + 1; t0 ]i satisfies
s2 ; : : : ; sn .

condition defining satisfaction timelines may appear unintuitive first due
fact two ways s2 ; : : : ; sn satisfied. reason becomes clear recalling using natural numbers represent continuous time intervals. Intuitively,
continuous-time perspective, timeline satisfied consecutive continuous-time
intervals satisfying sequence consecutive states timeline. transition
consecutive states si si+1 occur either within interval constant truth assignment (that
happens satisfy states) exactly boundary two time intervals constant truth
value. definition, cases correspond s2 ; : : : ; sn satisfied time
intervals [t00 ; t0 ] [t00 + 1; t0 ] respectively.
satisfies say model covers M. say AMA 1
subsumes AMA 2 iff every model 2 model 1 , written 2 1 , say 1
properly subsumes 2 , written 2 < 1 , also 1 6 2 . Alternatively, may state
2 1 saying 1 general (or less specific) 2 1 covers 2 . Siskind
(2001) provides method determine whether given model satisfies given AMA formula.
Finally, useful associate distinguished timeline model. projection
model = hM; [i; j ]i written MAP(M) timeline s0 ; s1 ; : : : ; sj state sk
gives true propositions (i + k ) 0 k j i. Intuitively, projection gives
sequence propositional truth assignments beginning end model. Later
show projection model viewed representing model precise
sense.
following two examples illustrate basic behaviors AMA formulas:
Example 1 (Stretchability). S1 ; S2 ; S3 , S1 ; S2 ; S2 ; : : : ; S2 ; S3 , S1 ; S1 ; S1 ; S2 ; S3 ; S3 ; S3
equivalent timelines. general, timelines property duplicating state
results formula equivalent original formula. Recall that, given model hM; i,
view truth assignment [x] representing continuous time-interval. interval
conceptually divided arbitrary number subintervals. Thus state satisfied
hM; [x; x]i, state sequence ; ; : : : ; .
390

fiL EARNING EMPORAL E VENTS

Example 2 (Infinite Descending Chains). Given propositions B , timeline =
subsumed formulas A; B , A; B ; A; B , A; B ; A; B ; A; B , . . . .
intuitively clear semantics viewed continuous-time perspective. interval
B true broken arbitrary number subintervals
B hold. example illustrates infinite descending chains AMA
formulas entire chain subsumes given formula (but member equivalent given
formula). general, AMA formula involving propositions B subsume .

(A ^ B )

3.2 Motivation AMA
timelines natural way capture stretchable sequences state constraints.
consider conjunction sequences, i.e., AMA? several reasons language enrichment. First all, show AMA least-general generalization (LGG)
uniquethis true MA. Second, informally, argue parallel conjunctive constraints important learning efficiency. particular, space formulas
length k grows size exponentially k , making difficult induce long formulas.
However, finding several shorter timelines characterize part long sequence
changes exponentially easier. (At least, space search exponentially smaller.) AMA
conjunction timelines places shorter constraints simultaneously often captures
great deal concept structure. reason, analyze AMA well and,
empirical work, consider k -AMA.
AMA language propositional. intended applications relational, first-order,
including visual-event recognition. Later paper, show propositional AMA learning algorithms develop effectively applied relational domains. approach
first-order learning distinctive automatically constructing object correspondence across examples (cf. Lavrac, Dzeroski, & Grobelnik, 1991; Roth & Yih, 2001). Similarly, though AMA
allow negative state constraints, Section 5.4 discuss extend results
incorporate negation learning algorithms, crucial visual-event recognition.
3.3 Conversion First-Order Clauses
note AMA formulas translated various ways first-order clauses.
straightforward, however, use existing clausal generalization techniques learning.
particular, capture AMA semantics clauses, appears necessary define subsumption
generalization relative background theory restricts us continuous-time first-order
model space.
example, consider AMA formulas 1 = ^ B 2 = A; B B
propositionsfrom Example 2 know 1 2 . Now, consider straightforward clausal
translation formulas giving C1 = A(I ) ^ B (I ) C2 = A(I1 ) ^ B (I2 ) ^ EETS (I1 ; I2 ) ^
= PAN (I1 ; I2 ), Ij variables represent time intervals, EETS indicates
two time intervals meet other, PAN function returns time interval equal
union two time-interval arguments. meaning intend capture satisfying
assignments C1 C2 indicate intervals 1 2 satisfied, respectively.
clear that, contrary want, C1 6 C2 (i.e., 6j= C1 ! C2 ), since easy
find unintended first-order models satisfy C1 , C2 . Thus translation,
similar translations, capture continuous-time nature AMA semantics.
391

fiF ERN , G IVAN , & ISKIND

order capture AMA semantics clausal setting, one might define first-order theory
restricts us continuous-time modelsfor example, allowing derivation property B
holds interval, property also holds sub-intervals. Given theory ,
j= C1 ! C2 , desired. However, well known least-general generalizations relative background theories need exist (Plotkin, 1971), prior work clausal
generalization simply subsume results AMA language.
note particular training set, may possible compile continuous-time background theory finite adequate set ground facts. Relative ground theories,
clausal LGGs known always exist thus could used application. However,
compiling approaches look promising us require exploiting analysis similar one given paperi.e., understanding AMA generalization subsumption
problem separately clausal generalization exploiting understanding compiling
background theory. pursued compilations further.
Even given compilation procedure, problems using existing clausal generalization techniques learning AMA formulas. clausal translations
AMA found, resulting generalizations typically fall outside (clausal translations
formulas the) AMA language, language bias AMA lost. preliminary empirical work video-event recognition domain using clausal inductive-logic-programming (ILP)
systems, found learner appeared lack necessary language bias find effective
event definitions. believe would possible find ways build language bias
ILP systems, chose instead define learn within desired language bias directly,
defining class AMA formulas, studying generalization operation class.
3.4 Basic Concepts Properties AMA
use following convention naming results: propositions theorems key
results work, theorems results technical difficulty, lemmas
technical results needed later proofs propositions theorems. number
results one sequence, regardless type. Proofs theorems propositions provided
main textomitted proofs lemmas provided appendix.
give pseudo-code methods non-deterministic style. non-deterministic language functions return one value non-deterministically, either contain
non-deterministic choice points, call non-deterministic functions. Since nondeterministic function return one possible value, depending choices made
choice points encountered, specifying function natural way specify richly structured set (if function arguments) relation (if function arguments). actually
enumerate values set (or relation, arguments provided) one simply use
standard backtracking search different possible computations corresponding different
choices choice points.
3.4.1 UBSUMPTION



G ENERALIZATION



TATES

basic formulas deal states (conjunctions propositions). propositional
setting computing subsumption generalization state level straightforward. state S1
subsumes S2 (S2 S1 ) iff S1 subset S2 , viewing states sets propositions. this,
derive intersection states least-general subsumer states union
states likewise general subsumee.
392

fiL EARNING EMPORAL E VENTS

3.4.2 NTERDIGITATIONS
Given set timelines, need consider different ways model could simultaneously satisfy timelines set. start model (i.e., first time point),
initial state timeline must satisfied. time point model, one
timelines transition second state timelines must satisfied place
initial state, initial state timelines remains satisfied. sequence
transitions subsets timelines, final state timeline holds. way
choosing transition sequence constitutes different interdigitation timelines.
Viewed differently, model simultaneously satisfying timelines induces co-occurrence
relation tuples timeline states, one timeline, identifying tuples co-occur
point model. represent concept formally set tuples co-occurring states,
i.e., co-occurrence relation. sometimes think set tuples ordered sequence
transitions. Intuitively, tuples interdigitation represent maximal time intervals
timeline transition, tuples giving co-occurring states
time interval.
relation R X1 Xn simultaneously consistent orderings 1 ,. . . ,n, if,
whenever R(x1 ; : : : ; xn ) R(x01 ; : : : ; x0n ), either xi x0i , i, x0i xi , i. say
R piecewise total projection R onto component totali.e., every state Xi
appears R.
Definition 1 (Interdigitation). interdigitation set f1 ; : : : ; n g timelines cooccurrence relation 1 n (viewing timelines sets states6 ) piecewise total
simultaneously consistent state orderings . say two states 2
s0 2 j 6= j co-occur iff tuple contains s0 . sometimes refer
sequence tuples, meaning sequence lexicographically ordered state orderings.
note exponentially many interdigitations even two timelines (relative
total number states timelines). Example 3 page 396 shows interdigitation two
timelines. Pseudo-code non-deterministically generating arbitrary interdigitation set
timelines found Figure 5. Given interdigitation timelines s1 ; s2 ; : : : ; sm
t1 ; t2 ; : : : ; tn (and possibly others), following basic properties interdigitations easily
verifiable:
1. < j , si tk co-occur k 0
2.

< k, sj co-occur tk

0

.

(s1 ; t1 ) (sm ; tn ).

first use interdigitations syntactically characterize subsumption timelines.
Definition 2 (Witnessing Interdigitation). interdigitation two timelines 1 2
witness 1 2 iff every pair co-occurring states s1 2 1 s2 2 2 ,
s2 subset s1 (i.e., s1 s2 ).
following lemma proposition establish equivalence witnessing interdigitations
subsumption.
6. Recall, that, formally, timelines viewed sets state-index pairs, rather sets states. ignore
distinction notation, readability purposes, treating timelines though state duplicated.

393

fiF ERN , G IVAN , & ISKIND

1:

an-interdigitation (f1 ; 2 ; : : : ; n g)

// Input: timelines 1 ; : : : ; n
// Output: interdigitation f1 ; : : : ; n g

2:
3:

S0 := hhead(1 ); : : : ; head(n )i;
1 n; ji j = 1
return hS0 i;
0
:= fi ji j > 1g;
00 := a-non-empty-subset-of (T 0 );

4:
5:
6:
7:
8:

:= 1 n
2 00
0i := rest(i )
else 0i := ;

9:
10:
12:
12:

return extend-tuple (S0 ; an-interdigitation (f01 ; : : : ; 0n g));

13:

Figure 5: Pseudo-code an-interdigitation(), non-deterministically computes interdigitation set f1 ; : : : ; n g timelines. function head() returns first
state timeline . rest() returns first state removed. extend-tuple(x,I )
extends tuple adding new first element x form longer tuple. a-non-emptysubset-of(S ) non-deterministically returns arbitrary non-empty subset .
Lemma 1. timeline model M, satisfies , witnessing
interdigitation MAP(M) .
Proposition 2. timelines 1 2 , 1

1 2 .

2 iff interdigitation witnesses

Proof: show backward direction induction number states n timeline 1 .
n = 1, existence witnessing interdigitation 1 2 implies every state 2
subset single state 1 , thus model 1 model 2 1 2 .
Now, suppose induction backward direction theorem holds whenever 1 n
fewer states. Given arbitrary model n + 1 state 1 interdigitation W
witnesses 1 2 , must show also model 2 conclude 1 2 desired.
Write 1 s1 ; : : : ; sn+1 2 t1 ; : : : ; tm . witnessing interdigitation, W must identify
maximal prefix t1 ; : : : ; tm 2 made states co-occur s1 thus
subsets s1 . Since = hM; [t; t0 ]i satisfies 1 , definition must exist t00 2 [t; t0 ]
hM; [t; t00 ]i satisfies s1 (and thus t1 ; : : : ; tm ) hM; 0 satisfies s2 ; : : : ; sn+1 0 equal
either [t00 ; t0 ] [t00 + 1; t0 ]. either case, straightforward construct, W , witnessing
interdigitation s2 ; : : : ; sn+1 tm +1 ; : : : ; tm use induction hypothesis show
hM; 0 must satisfy tm +1; : : : ; tm . follows satisfies 2 desired.
forward direction, assume 1 2 , let model 1 =
MAP(M). clear exists satisfies 1 . follows satisfies 2 .
Lemma 1 implies witnessing interdigitation MAP(M) 2 thus
1 2 . 2
0

0

0

0

394

fiL EARNING EMPORAL E VENTS

3.4.3 L EAST-G ENERAL C OVERING F ORMULA
logic discriminate two models contains formula satisfies one other.
turns AMA formulas discriminate two models exactly much richer internal positive event logic (IPEL) formulas so. Internal formulas define event occurrence
terms properties within defining interval. is, satisfaction hM; depends
proposition truth values given inside interval . Positive formulas
contain negation. Appendix gives full syntax semantics IPEL (which used
state prove Lemma 3 ). fact AMA discriminate models well IPEL
indicates restriction AMA formulas retains substantial expressive power leads
following result serves least-general covering formula (LGCF) component
specific-to-general learning procedure. Formally, LGCF model within formula language
L (e.g. AMA IPEL) formula L covers covering formula
L strictly less general. Intuitively, LGCF model, unique, representative
formula model. analysis uses concept model embedding. say model
embeds model M0 iff MAP(M) MAP(M0 ).
Lemma 3.

E

2 IP EL, model embeds model satisfies E , satisfies E .

Proposition 4. projection model LGCF internal positive event logic (and
hence AMA), semantic equivalence.
Proof: Consider model M. know MAP(M) covers M, remains show
MAP(M) least general formula so, semantic equivalence.
Let E IPEL formula covers M. Let M0 model covered MAP(M)
want show E also covers M0 . know, Lemma 1, witnessing
interdigitation MAP(M0 ) MAP(M). Thus, Proposition 2, MAP(M0 ) MAP(M)
showing M0 embeds M. Combining facts Lemma 3 follows E also covers
M0 hence MAP(M) E . 2
Proposition 4 tells us that, IPEL, LGCF model exists, unique,
timeline. Given property, AMA formula covers timelines covered
another AMA formula 0 , 0 . Thus, remainder paper, considering
subsumption formulas, abstract away temporal models deal instead
timelines. Proposition 4 also tells us compute LGCF model constructing
projection model. Based definition projection, straightforward
derive LGCF algorithm runs time polynomial size model7 . note
projection may contain repeated states. practice, remove repeated states, since
change meaning resulting formula (as described Example 1).
3.4.4 C OMBINING NTERDIGITATION



G ENERALIZATION



PECIALIZATION

Interdigitations useful analyzing conjunctions disjunctions timelines.
conjoining set timelines, model conjunction induces interdigitation timelines
co-occurring states simultaneously hold model point (viewing states
sets, states resulting unioning co-occurring states must hold). constructing
7. take size model = hM; sum x 2 number true propositions (x).

395

fiF ERN , G IVAN , & ISKIND

interdigitation taking union tuple co-occurring states get sequence states,
get timeline forces conjunction timelines hold. call sequence
interdigitation specialization timelines. Dually, interdigitation generalization involving
intersections states gives timeline holds whenever disjunction set timelines
holds.
Definition 3. interdigitation generalization (specialization) set timelines
timeline s1 ; : : : ; sm , that, interdigitation tuples, sj intersection
(respectively, union) components jth tuple sequence . set interdigitation
generalizations (respectively, specializations) called IG() (respectively, IS()).
Example 3. Suppose s1 ; s2 ; s3 ; t1 ; t2 ; t3 sets propositions (i.e., states). Consider timelines = s1 ; s2 ; s3 = t1 ; t2 ; t3 . relation

f hs1; t1 ; hs2; t1 ; hs3; t2 ; hs3; t3 g
interdigitation states s1 s2 co-occur t1 , s3 co-occurs
t2 t3 . corresponding IG members

s1 \ t1 ; s2 \ t1 ; s3 \ t2 ; s3 \ t3
s1 [ t1 ; s2 [ t1 ; s3 [ t2 ; s3 [ t3

2 IG(fS; g)
2 IS(fS; g):

t1 s1 ; t1 s2 ; t2 s3 ; t3 s3 , interdigitation witnesses

T.

timeline IG() (dually, IS()) subsumes (is subsumed by) timeline
easily verified using Proposition 2. complexity analyses, note number states
member IG() IS() bounded number states
timelines bounded total number states timelines
. number interdigitations , thus members IG() IS(), exponential total number states. algorithms present later computing LGGs
require computation IG () IS(). give pseudo-code compute
quantities. Figure 6 gives pseudo-code function an-IG-member non-deterministically
computes arbitrary member IG() (an-IS-member same, except replace intersection union). Given set timelines compute IG() executing possible
deterministic computation paths function call an-IG-member(), i.e., computing set
results obtainable non-deterministic function possible decisions non-deterministic
choice points.
give useful lemma proposition concerning relationships conjunctions disjunctions concepts (the former AMA concepts). convenience here,
use disjunction concepts, producing formulas outside AMA obvious interpretation.
Lemma 5. Given formula subsumes member set formulas, also
subsumes member 0 IG(). Dually, subsumed member ,
also subsumed member 0 IS(). case, length 0 bounded
size .

396

fiL EARNING EMPORAL E VENTS

an-IG-member (f1 ; 2 ; : : : ; n g)

// Input: timelines 1 ; : : : ; n
// Output: member IG(f1 ; 2 ; : : : ; n g)

return map (intersect-tuple ; an-interdigitation (f1 ; : : : ; n g));
Figure 6: Pseudo-code an-IG-member, non-deterministically computes member
IG(T ) set timelines. function intersect-tuple(I ) takes tuple
sets argument returns intersection. higher-order function map(f; )
takes function f tuple arguments returns tuple length
obtained applying f element making tuple results.
Proposition 6.

following hold:

1. (and-to-or) conjunction set timelines equals disjunction timelines
IS().
2. (or-to-and) disjunction set timelines subsumed conjunction
timelines IG().
Proof: prove or-to-and, recall that, 2 0 2 IG(), 0 .
W
V
immediate ( ) ( IG()). Using dual argument, show
W
V
V
W
( IS()) ( ). remains Vto show ( ) ( ISW()), equivalent showing
timeline subsumed ( ) also subsumed ( IS()) (by Proposition 4). Consider
V
timeline ( )this implies member subsumes . Lemma
W
5 implies 0 2 IS() 0 . get ( IS())
desired. 2
Using and-to-or, reduce AMA subsumption subsumption, exponential increase problem size.
Proposition 7.
2 ; 1 2 .

AMA

1



2 , 1

2 1 2 IS( 1) 2 2

Proof: forward direction show contrapositive. Assume 1 2 IS( 1 )
2 2 2 W1 6 2 . Thus, timeline
1 6 2 .
W
tells us ( IS( 1 )) 6 2 , thus ( IS( 1 )) 6 2 and-to-or get
1 6 2 .
backward direction assume 1 2 IS( 1 ) 2 2 2 1 2 .
W
tells us 1 2 IS( 1 ), 1 2 thus, 1 = ( IS( 1 )) 2 . 2

4. Subsumption Generalization
section study subsumption generalization AMA formulas. First, give
polynomial-time algorithm deciding subsumption formulas show
deciding subsumption AMA formulas coNP-complete. Second give algorithms complexity bounds construction least-general generalization (LGG) formulas based
397

fiF ERN , G IVAN , & ISKIND

MA-subsumes (1 ; 2 )
// Input: 1 = s1 ; : : : ; sm 2
// Output: 1 2

= t1 ; : : : ; tn

1. path v1;1 vm;n SG(1 ; 2 ) return TRUE. example,
(a)
(b)

(c)

Create array Reachable(i,j ) boolean values, FALSE, 0
0 j n.
:= 1 m, Reachable(i; 0) := TRUE;
j := 1 n, Reachable(0; j ) := TRUE;
:= 1
j := 1 n
Reachable(i; j ) := (ti sj ^ ( Reachable(i
Reachable(i; j
Reachable(i

Reachable(m; n) return TRUE;



1; j ) _
1) _
1; j 1));

2. Otherwise, return FALSE;
Figure 7: Pseudo-code subsumption algorithm.
defined main text.

SG(1 ; 2 ) subsumption graph

analysis subsumption, including existence, uniqueness, lower/upper bounds, algorithm
LGG AMA formulas. Third, introduce polynomial-timecomputable syntactic notion
subsumption algorithm computes corresponding syntactic LGG exponentially faster semantic LGG algorithm. Fourth, Section 4.4, give detailed example
showing steps performed LGG algorithms compute semantic syntactic LGGs
two AMA formulas.
4.1 Subsumption
methods rely critically novel algorithm deciding subsumption question 1 2
formulas 1 2 polynomial-time. note merely searching possible
interdigitations 1 2 witnessing interdigitation provides obvious decision procedure
subsumption questionhowever, are, general, exponentially many interdigitations. reduce subsumption problem finding path graph pairs states
1 2 , polynomial-time operation. Pseudo-code resulting subsumption algorithm shown Figure 7. main data structure used subsumption algorithm
subsumption graph.
Definition 4. subsumption graph two timelines 1 = s1 ; ; sm 2 = t1 ; ; tn
(written SG(1 ; 2 )) directed
graph G = hV; E V = fvi;j j 1 m; 1 j ng .

(directed) edge set E equals hvi;j ; vi ;j j si tj ; si tj ; i0 + 1; j j 0 j + 1 .
0

0

0

0

achieve polynomial-time bound one simply use polynomial-time pathfinding algorithm. case special structure subsumption graph exploited determine
398

fiL EARNING EMPORAL E VENTS

desired path exists (mn) time, example method shown pseudo-code illustrates.
following theorem asserts correctness algorithm assuming correct polynomial-time
path-finding method used.
Lemma 8. Given timelines 1 = s1 ; : : : ; sm 2 = t1 ; : : : ; tn , witnessing
interdigitation 1 2 iff path subsumption graph SG(1 ; 2 ) v1;1
vm;n .
Theorem 9.
mial time.

Given timelines 1 2 , MA-subsumes(1 ; 2 ) decides 1

2 polyno-

Proof: algorithm clearly runs polynomial time. Lemma 8 tells us line 2 algorithm
return TRUE iff witnessing interdigitation. Combining Proposition 2 shows
algorithm returns TRUE iff 1 2 . 2
Given polynomial-time algorithm subsumption, Proposition 7 immediately suggests
exponential-time algorithm deciding AMA subsumptionby computing subsumption
exponentially many timelines one formula timelines formula.
next theorem suggests cannot better worst casewe argue
AMA subsumption coNP-complete reduction boolean satisfiability. Readers uninterested
technical details argument may skip directly Section 4.2.
develop correspondence boolean satisfiability problems, include negation,
AMA formulas, lack negation, imagine boolean variable two AMA
propositions, one true one false. particular, given boolean satisfiability problem
n variables p1 ; : : : ; pn , take set PROPn set containing 2n AMA propositions
Truek Falsek k 1 n. represent truth assignment pi
variables AMA state sA given follows:

sA = fTruei j 1 n; A(pi ) = trueg [ fFalsei j 1 n; A(pi ) = falseg
Proposition 7 suggests, checking AMA subsumption critically involves exponentially
many interdigitation specializations timelines one AMA formulas. proof,
design AMA formula whose interdigitation specializations seen correspond truth
assignments8 boolean variables, shown following lemma.
Lemma 10.

Given n, let conjunction timelines
n
[
i=1

f(PROPn; Truei; Falsei; PROPn); (PROPn; Falsei; Truei; PROPn)g:

following facts truth assignments Boolean variables p1 ; : : : ; pn :
1. truth assignment A, PROPn ; sA ; PROPn semantically equivalent member
IS( ).
2. 2 IS( ) truth assignment PROPn ; sA ; PROPn .
8. truth assignment function mapping boolean variables true false.

399

fiF ERN , G IVAN , & ISKIND

lemma hand, tackle complexity AMA subsumption.
Theorem 11.

Deciding AMA subsumption coNP-complete.

Proof: first show deciding AMA-subsumption 1 2 coNP providing
polynomial-length certificate answer. certificate non-subsumption
interdigitation timelines 1 yields member IS( 1 ) subsumed 2 .
certificate checked polynomial time: given interdigitation, corresponding
member IS( 1 ) computed time polynomial size 1 , test
whether resulting timeline subsumed timeline 2 using polynomial-time MAsubsumption algorithm. Proposition 7 guarantees 1 6 2 iff timeline IS( 1 )
subsumed every timeline 2 , certificate exist exactly
answer subsumption query no.
show coNP-hardness reduce problem deciding satisfiability 3-SAT formula
= C1 ^ ^ Cm problem recognizing non-subsumption AMA formulas. Here,
Ci (li;1 _ li;2 _ li;3 ) li;j either proposition p chosen P = fp1 ; : : : ; pn g
negation :p. idea reduction construct AMA formula view
exponentially many members IS( ) representing truth assignments. construct
timeline view representing :S show satisfiable iff 6 .
Let defined Lemma 10. Let formula s1 ; : : : ; sm ,

si =

fFalsej j li;k = pj kg [
fTruej j li;k = :pj kg:

si thought asserting Ci . start showing satisfiable
6 . Assume satisfied via truth assignment Awe know Lemma 10
0 2 IS( ) semantically equivalent PROPn ; sA ; PROPn . show
PROPn ; sA ; PROPn subsumed , conclude 6 using Proposition 7, desired.
Suppose contradiction PROPn ; sA ; PROPn subsumed state sA must
subsumed state si . Consider corresponding clause Ci . Since satisfies
Ci satisfied least one literals li;k must true. Assume li;k = pj (a
dual argument holds li;k = :pj ), si contains Falsej sA contains Truej
Falsej thus, sA 6 si (since si 6 sA ), contradicting choice i.
complete proof, assume unsatisfiable show . Using
Proposition 7, consider arbitrary 0 IS( )we show 0 . Lemma 10
know truth assignment 0 PROPn ; sA ; PROPn . Since unsatisfiable
know Ci satisfied hence :Ci satisfied A. implies
primitive proposition si sA . Let W following interdigitation =
PROPn ; sA ; PROPn = s1 ; : : : ; sm :

fhPROPn; s1 hPROPn; s2 hPROPn; sii hsA; sii hPROPn; sii hPROPn; si+1i hPROPn; smig

see tuple co-occurring states given state subsumed
state . Thus W witnessing interdigitation PROPn ; sA ; PROPn ,
holds Proposition 2combining 0 PROPn ; sA ; PROPn get 0 . 2
Given hardness result later define weaker polynomial-timecomputable subsumption
notion use learning algorithms.
400

fiL EARNING EMPORAL E VENTS

4.2 Least-General Generalization.
AMA LGG set AMA formulas AMA formula general
formula set strictly general formula. existence
AMA LGG nontrivial infinite chains increasingly specific formulas
generalize given formulas. Example 2 demonstrated chains subsumee
extended AMA subsumees. example, member chain P ; Q, P ; Q; P ; Q,
P ; Q; P ; Q; P ; Q; : : : covers 1 = (P ^ Q); Q 2 = P ; (P ^ Q). Despite complications,
AMA LGG exist.
Theorem 12. LGG finite set AMA formulas subsumed
generalizations .
Proof: Let set 2 IS( 0 ). Let conjunction timelines
generalize size larger . Since finite number primitive
propositions, finite number timelines, well defined9 . show
least-general generalization . First, note timeline generalizes thus
(by Proposition 6), must generalize . Now, consider arbitrary generalization 0 .
Proposition 7 implies 0 must generalize formula . Lemma 5 implies
timeline 0 must subsume timeline longer size also subsumes
timelines . must timeline , choice , every timeline
0 subsumes timeline . follows 0 subsumes , LGG subsumed
LGGs , desired. 2


0

Given AMA LGG exists unique show compute it. first step
strengthen or-to-and Proposition 6 get LGG sublanguage.
Theorem 13. set formulas, conjunction timelines IG() AMA
LGG .
Proof: Let specified conjunction. Since timeline IG() subsumes timelines
, subsumes member . show least-general formula, consider
AMA formula 0 also subsumes members . Since timeline 0 must subsume
members , Lemma 5 implies timeline 0 subsumes member IG() thus
timeline 0 subsumes . implies 0 . 2
characterize AMA LGG using IG.
Theorem 14.



IG( 2 IS( )) AMA LGG set AMA formulas.

Proof: Let = f 1 ; : : : ; n g E = 1 _ _ n . know AMA LGG
must subsume E , would fail subsume one . Using and-to-or represent
W
W
E disjunction timelines given E = ( IS( 1 )) _ _ ( IS( n )). AMA
LGG must least-general formula subsumes E i.e., AMA LGG set

timelines fIS( )j 2 g. Theorem 13 tells us LGG timelines given

IG( fIS( )j 2 g). 2
9. must least one timeline, timeline state true

401

fiF ERN , G IVAN , & ISKIND

1:
2:
3:
4:
5:
6:
7:
8:
9:

10:
11:
12:
13:
14:

15:

semantic-LGG(f 1 ; 2 ; : : : ; g)

// Input: AMA formulas 1 ; : : : ;
// Output: LGG f 1 ; : : : ; g

:= fg;
:= 1
all-values(an-IS-member ( ))
(80 2 : 6 0 )
0 := f00 2 j 00 g;
:= (S 0 ) [ fg;
G := fg;
all-values(an-IG-member(S ))
(80 2 G : 0 6 )
G0 := f00 2 G j 00 g;
G := (G G0 ) [ fg;
V

return (

G)

Figure 8: Pseudo-code computing semantic AMA LGG set AMA formulas.
Theorem 14 leads directly algorithm computing AMA LGGFigure 8 gives
pseudo-code computation. Lines 4-9 pseudo-code correspond computation

fIS( )j 2 g, timelines included set subsumed timelines
already set (which checked polynomial time subsumption algorithm).
pruning, accomplished test line 7, often drastically reduces size timeline set perform subsequent IG computationthe final result affected
pruning since subsequent IG computation generalization step. remainder

pseudo-code corresponds computation IG( fIS( )j 2 g) include
timelines final result subsume timeline set. pruning step (the test
line 12) sound since one timeline subsumes another, conjunction timelines
equivalent specific one. Section 4.4.1 traces computations algorithm
example LGG calculation.
Since sizes IS() IG() exponential sizes inputs, code
Figure 8 doubly exponential input size. conjecture cannot better this,
yet proven doubly exponential lower bound AMA case. input
formulas timelines algorithm takes singly exponential time, since IS(fg) =
MA. prove exponential lower bound input formulas MA. Again,
readers uninterested technical details proof safely skip forward Section 4.3.
argument, take available primitive propositions set fpi;j j 1
n; 1 j ng, consider timelines


1 = s1; ; s2; ; : : : ; sn;
2 = s;1 ; s;2 ; : : : ; s;n ;
402



fiL EARNING EMPORAL E VENTS



si; = pi;1 ^ ^ pi;n
s;j = p1;j ^ ^ pn;j :

show AMA LGG 1 2 must contain exponential number timelines.
particular, show AMA LGG equivalent conjunction subset
IG(f1 ; 2 g), certain timelines may omitted subset.
Lemma 15. AMA LGG set
timelines IG() j 0 j j j

timelines equivalent conjunction 0

Proof: Lemma 5 implies timeline must subsume timeline 0 2 IG().
conjunction 0 0 must equivalent , since clearly covers covered
LGG . Since 0 formed taking one timeline IG() timeline ,
j 0 j j j. 2 complete argument showing exponentially many
timelines IG(f1 ; 2 g) cannot omitted conjunction remains LGG.
Notice i; j si; \s;j = pi;j . implies state IG(f1 ; 2 g)
contains exactly one proposition, since state formed intersecting state 1
2 . Furthermore, definition interdigitation, applied here, implies following two facts
timeline q1 ; q2 ; : : : ; qm IG(f1 ; 2 g):
1. q1

= p1;1 qm = pn;n.

2. consecutive states qk
= i0 j

= pi;j qk+1 = pi ;j , i0 either + 1, j 0 either j j + 1,
= j0.
0

0

Together facts imply timeline IG(f1 ; 2 g) sequence propositions starting
p1;1 ending pn;n consecutive propositions pi;j ; pi ;j different
i0 equal + 1 j 0 equal j j + 1. call timeline IG(f1 ; 2 g) square
pair consecutive propositions pi;j pi ;j either i0 = j 0 = j .
following lemma implies square timeline omitted conjunction timelines
IG(1 ; 2 ) remain LGG 1 2 .
0

0

0

0

Lemma 16. Let 1 2 given let = IG(f1 ; 2 g).
timelines subset omits square timeline, < 0 .
V

0 whose

n 2)! hence exponenThe number square timelines IG(f1 ; 2 g) equal (n (21)!(
n 1)!
tial size 1 2 . completed proof following result.

Theorem 17.

smallest LGG two formulas exponentially large.

Proof: Lemma 15, AMA LGG 0 1 2 equivalent conjunction
number timelines chosen IG(f1 ; 2 g). However, Lemma 16, conjunction
n 2)! timelines, must 0 , must exponentially
must least (n (21)!(
n 1)!
large. 2
Conjecture 18.

smallest LGG two AMA formulas doubly-exponentially large.
403

fiF ERN , G IVAN , & ISKIND

show lower-bound AMA LGG complexity merely consequence
existence large AMA LGGs. Even small LGG, expensive compute
due difficulty testing AMA subsumption:
Theorem 19. Determining whether formula AMA LGG two given AMA formulas 1
2 co-NP-hard, co-NEXP, size three formulas together.
Proof: show co-NP-hardness use straightforward reduction AMA subsumption. Given
two AMA formulas 1 2 decide 1 2 asking whether 2 AMA LGG 1
2 . Clearly 1 2 iff 2 LGG two formulas.
show co-NEXP upper bound, note check exponential time whether 1
2 using Proposition 7 polynomial-time subsumption algorithm. remains
show check whether least subsumer. Since Theorem 14 shows
LGG 1 2 IG(IS( 1 ) [ IS( 2 )), LGG 6 IG(IS( 1 ) [ IS( 2 )).
Thus, Proposition 7, least subsumer, must timelines 1 2 IS( )
2 2 IG(IS( 1 ) [ IS( 2 )) 1 6 2 . use exponentially long certificates
answers: certificate pair interdigitation I1 interdigitation I2
IS( 1 ) [ IS( 2 ), corresponding members 1 2 IS( ) 2 2 IG(IS( 1 ) [ IS( 2 ))
1 6 2 . Given pair certificates I1 I2 , 1 computed polynomial time,
2 computed exponential time, subsumption checked
polynomial time (relative size, exponential). LGG
IG(IS( 1 ) [ IS( 2 )), certificates exist. 2
4.3 Syntactic Subsumption Syntactic Least-General Generalization.
Given intractability results semantic AMA subsumption, introduce tractable generality notion, syntactic subsumption, discuss corresponding LGG problem. use
syntactic forms generality efficiency familiar ILP (Muggleton & De Raedt, 1994)
where, example, -subsumption often used place entailment generality relation.
Unlike AMA semantic subsumption, syntactic subsumption requires checking polynomially
many subsumptions, polynomial time (via Theorem 9).
Definition 5. AMA 1 syntactically subsumed AMA 2 (written 1
timeline 2 2 2 , timeline 1 2 1 1 2 .

syn 2) iff

Proposition 20. AMA syntactic subsumption decided polynomial time.
Syntactic subsumption trivially implies semantic subsumptionhowever, converse
hold general. Consider AMA formulas (A; B ) ^ (B ; A), A; B ; B
primitive propositions. (A; B ) ^ (B ; A) A; B ; A; however, neither A; B
A; B ; B ; A; B ; A, A; B ; syntactically subsume (A; B ) ^ (B ; A).
Syntactic subsumption fails recognize constraints derived interaction
timelines within formula.
Syntactic Least-General Generalization. syntactic AMA LGG syntactically least-general
AMA formula syntactically subsumes input AMA formulas. Here, least means
404

fiL EARNING EMPORAL E VENTS

formula properly syntactically subsumed syntactic LGG syntactically subsume input
formulas. Based hardness gap syntactic semantic AMA subsumption, one might
conjecture similar gap exists syntactic semantic LGG problems. Proving
gap exists requires closing gap lower upper bounds AMA LGG shown
Theorem 14 favor upper bound, suggested Conjecture 18. cannot yet
show hardness gap semantic syntactic LGG, give syntactic LGG algorithm
exponentially efficient best semantic LGG algorithm found (that
Theorem 14). First, show syntactic LGGs exist unique mutual syntactic
subsumption (and hence semantic equivalence).
Theorem 21. exists syntactic LGG AMA formula set syntactically subsumed syntactic generalizations .
Proof: Let conjunction timelines syntactically generalize
size larger . proof Theorem 12, well defined. show
syntactic LGG . First, note syntactically generalizes timeline
generalizes timeline every member , choice . consider arbitrary
syntactic generalization 0 . definition syntactic subsumption, timeline
0 must subsume timeline ff member ff . Lemma 5 implies
timeline 0 size larger subsumes ff subsumed .
choice , timeline 0 must timeline . follows 0 syntactically subsumes
, syntactic LGG subsumed syntactic generalizations . 2
general, know semantic syntactic LGGs different, though clearly syntactic
LGG semantic generalization must subsume semantic LGG. example, (A; B ) ^
(B ; A), A; B ; semantic LGG A; B ; A, discussed above; syntactic LGG
(A; B ; true) ^ (true; B ; A), subsumes A; B ; subsumed A; B ; A. Even
so, formulas:
Proposition 22.

AMA , syn

equivalent .

Proof: forward direction immediate since already know syntactic subsumption implies
semantic subsumption. reverse direction, note implies timeline
subsumes thus since single timeline timeline subsumes timeline
definition syntactic subsumption. 2
Proposition 23.

syntactic AMA LGG formula set also semantic LGG .

Proof: Now, consider syntactic LGG . Proposition 22 implies semantic
generalization . Consider semantic LGG 0 . show 0 conclude
semantic LGG . Proposition 22 implies 0 syntactically subsumes . follows
0 ^ syntactically subsumes . But, 0 ^ syntactically subsumed , syntactic
LGG follows 0 ^ syntactically subsumes , would least syntactic
generalization . ( 0 ^ ), implies 0 , desired. 2
note stronger result stating formula syntactic LGG set formulas semantic LGG immediate consequence results above.
405

fiF ERN , G IVAN , & ISKIND

first examination, strengthening appears trivial, given equivalence syn
. However, semantically least necessarily stronger condition syntactically leastwe ruled possibility semantically least generalization may
syntactically subsume another generalization semantically (but syntactically) equivalent.
(This question open, found example phenomenon either.)
Proposition 23 together Theorem 21 nice consequence learning approach
syntactic LGG two AMA formulas semantic LGG formulas, long
original formulas syntactic LGGs sets timelines. learning approach starts training examples converted timelines using LGCF operation,
syntactic LGGs computed (whether combining training examples once, incrementally computing syntactic LGGs parts training data) always syntactic LGGs sets
timelines hence also semantic LGGs, spite fact syntactic subsumption
weaker semantic subsumption. note, however, resulting semantic LGGs may
considerably larger smallest semantic LGG (which may syntactic LGG all).
Using Proposition 23, show cannot hope polynomial-time syntactic LGG
algorithm.
Theorem 24.

smallest syntactic LGG two formulas exponentially large.

Proof: Suppose always syntactic LGG two formulas exponentially large.
Since Proposition 23 formula also semantic LGG, always semantic LGG
two formulas exponentially large. contradicts Theorem 17. 2
discouraging, algorithm syntactic LGG whose time complexity
matches lower-bound, unlike semantic LGG case, best algorithm
doubly exponential worst case. Theorem 14 yields exponential time method computing
semantic LGG set timelines since timeline , IS() = , simply
conjoin timelines IG(). Given set AMA formulas, syntactic LGG algorithm uses
method compute polynomially-many semantic LGGs sets timelines, one chosen
input formula, conjoins results.
Theorem 25.
1 ; : : : ; n .

formula

2 IG(f1 ; : : : ; n g) syntactic LGG AMA formulas

V





Proof: Let 2 IG(f1 ; : : : ; n g). timeline must subsume
output IG set containing timeline thus syntactically subsumes .
show syntactically least formula, consider 0 syntactically subsumes every
. show syn 0 conclude. timeline 0 0 subsumes timeline Ti 2 ,
i, assumption syn 0 . Lemma 5, 0 must subsume member
IG(fT1 ; : : : ; Tn g)and member timeline timeline 0 0 subsumes
timeline . conclude syn 0 , desired. 2
V

theorem yields algorithm computes syntactic AMA LGG exponential time
pseudo-code method given Figure 9. exponential time bound follows fact
exponentially many ways choose 1 ; : : : ; line 5,
exponentially many semantic-LGG members line 6 (since timelines)the
product two exponentials still exponential.
406

fiL EARNING EMPORAL E VENTS

1:
2:
3:
4:
5:
6:

syntactic-LGG(f 1 ; 2 ; : : : ; g)

// Input: AMA formulas f 1 ; : : : ; g
// Output: syntactic LGG f 1 ; : : : ; g

G := fg;

h1 ; : : : ; 2 1

semantic-LGG(f1 ; : : : ; g)

7:
8:
9:
10:

V

return (

(80 2 G : 0 6 )
G0 := f00 2 G j 00 g;
G := (G G0 ) [ fg;

G)

Figure 9: Pseudo-code computes syntactic AMA LGG set AMA formulas.
formula returned algorithm shown actually subset syntactic LGG given
Theorem 25. subset syntactically (and hence semantically) equivalent formula
specified theorem, possibly smaller due pruning achieved statement
lines 79. timeline pruned set (semantically) subsumed timeline
set (one timeline kept semantically equivalent group timelines, random).
pruning timelines sound, since timeline pruned output subsumes
formula outputthis fact allows easy argument pruned formula syntactically equivalent (i.e. mutually syntactically subsumed by) unpruned formula. Section 4.4.2
traces computations algorithm example LGG calculation. note empirical evaluation discussed Section 6, cost terms accuracy using
efficient syntactic vs. semantic LGG. know learned definitions made errors
direction overly specificthus, since semantic-LGG least specific
syntactic-LGG would advantage using semantic algorithm.
method exponential amount work even result small (typically
many timelines pruned output subsume remains). still
open question whether output-efficient algorithm computing syntactic AMA
LGGthis problem coNP conjecture coNP-complete. One route settling
question determine output complexity semantic LGG input formulas.
believe problem also coNP-complete, proven this; problem P,
output-efficient method computing syntactic AMA LGG based Theorem 25.
summary algorithmic complexity results section found Table 3
conclusions section paper.
4.4 Examples: Least-General Generalization Calculations
work details semantic syntactic LGG calculation. consider
AMA formulas = (A; B ) ^ (B ; A) = A; B ; A, semantic LGG A; B ;
syntactic LGG (A; B ; true) ^ (true; B ; A).

407

fiF ERN , G IVAN , & ISKIND

4.4.1 EMANTIC LGG E XAMPLE
first step calculating semantic LGG, according algorithm given Figure 8,
compute interdigitation-specializations input formulas (i.e., IS() IS( )). Trivially,
IS() = = A; B ; A. calculate IS( ), must consider possible interdigitations , three,

f hA; B ; hB; B ; hB; Ai g
f hA; B ; hB; Ai g
f hA; B ; hA; Ai ; hB; Ai g
interdigitation leads corresponding member IS( ) unioning (conjoining) states
tuple, IS( )

f (A ^ B ); B ; (A ^ B );
(A ^ B );
(A ^ B ); A; (A ^ B ) g:
Lines 59 semantic LGG algorithm compute set , equal union
timelines IS( ) IS(), subsumed timelines removed. formulas, see
timeline IS( ) subsumed thus, = = A; B ; A.
computing , algorithm returns conjunction timelines IG(S ), redundant
timelines removed (i.e., subsuming timelines removed). case, IG(S ) = A; B ; A,
trivially, one timeline , thus algorithm correctly computes semantic LGG
A; B ; A.
4.4.2 YNTACTIC LGG E XAMPLE
syntactic LGG algorithm, shown Figure 9, computes series semantic LGGs
timeline sets, returning conjunction results (after pruning). Line 5 algorithm, cycles
timeline tuples cross-product input AMA formulas. case tuples
T1 = hA; B ; A; A; B T2 = hA; B ; A; B ; Aifor tuple, algorithm
computes semantic LGG tuples timelines.
semantic LGG computation tuple uses algorithm given Figure 8,
argument always set timelines rather AMA formulas. reason, lines 4
9 superfluous, timeline 0 , IS(0 ) = 0 . case tuple T1 , lines 49
algorithm compute = fA; B ; A; A; B g. remains compute interdigitationgeneralizations (i.e., IG(S )), returning conjunction timelines pruning (lines
1015 Figure 8). set interdigitations are,

f hA; Ai ; hB; Ai ; hB; B ; hB; Ai g
f hA; Ai ; hB; B ; hB; Ai g
f hA; Ai ; hA; B ; hB; B ; hB; Ai g
f hA; Ai ; hA; B ; hB; Ai g
f hA; Ai ; hA; B ; hA; Ai ; hB; Ai g
intersecting states interdigitation tuples get IG(S ),

f A; true; B ; true; A; B ; true; A; true; B ; true; A; true; true; A; true; A; true g
408

fiL EARNING EMPORAL E VENTS

Since timeline A; B ; true subsumed timelines IG(S ), timelines
pruned. Thus semantic LGG algorithm returns A; B ; true semantic LGG timelines
T1 .
Next syntactic LGG algorithm computes semantic LGG timelines T2 . Following
steps T1 , find semantic LGG timelines T2 true; B ; A. Since
A; B ; true true; B ; subsume one another, set G computed lines 59
syntactic LGG algorithm equal f A; B ; true; true; B ; g. Thus, algorithm computes
syntactic LGG (A; B ; true) ^ (true; B ; A). Note that, case, syntactic
LGG general semantic LGG.

5. Practical Extensions
implemented specific-to-general AMA learning algorithm based LGCF syntactic LGG algorithms presented earlier. implementation includes four practical extensions.
first extension aims controlling exponential complexity limiting length
timelines consider. Second describe often efficient LGG algorithm based
modified algorithm computing pairwise LGGs. third extension deals applying
propositional algorithm relational data, necessary application domain visual event
recognition. Fourth, add negation AMA language show compute corresponding LGCFs LGGs using algorithms AMA (without negation). Adding negation
AMA turns crucial achieving good performance experiments. end
section review overall complexity implemented system.
5.1 k-AMA Least-General Generalization
already indicated syntactic AMA LGG algorithm takes exponential time relative
lengths timelines AMA input formulas. motivates restricting AMA
language k -AMA practice, formulas contain timelines k states.
k increased algorithm able output increasingly specific formulas cost
exponential increase computational time. visual-eventrecognition experiments shown
later, increased k , resulting formulas became overly specific computational bottleneck reachedi.e., application best values k practically computable
ability limit k provided useful language bias.
use k -cover operator order limit syntactic LGG algorithm k -AMA. k -cover
AMA formula syntactically least general k -AMA formula syntactically subsumes
inputit easy show k -cover formula formed conjoining k -MA
timelines syntactically subsume formula (i.e., subsume timeline formula) .
Figure 10 gives pseudo-code computing k -cover AMA formula. shown
algorithm correctly computes k -cover input AMA formula. algorithm calculates
set least general k -MA timelines subsume timeline inputthe resulting k -MA
formulas conjoined redundant timelines pruned using subsumption test. note
k -cover AMA formula may exponentially larger formula; however,
practice, found k -covers exhibit undue size growth.
Given k -cover algorithm restrict learner k -AMA follows: 1) Compute
k-cover AMA input formula. 2) Compute syntactic AMA LGG resulting kAMA formulas. 3) Return k -cover resulting AMA formula. primary bottleneck
409

fiF ERN , G IVAN , & ISKIND

1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:

12:
13:
14:
15:
17:
18:
19:
20:

V

k-cover(k; 1im )
V
// Input: positive natural number k , AMA formula 1im
V
// Output: k -cover 1im
G := fg;
:= 1

:= hP1 ; : : : ; Pn all-values(a-k-partition (k; ))


:= ( P1 ); : : : ; ( Pn );
(80 2 G : 0 6 )
G0 := f00 2 G j 00 g;
G := (G G0 ) [ fg;
V
return ( G)
P

a-k-partition (k; s1 ; : : : ; sj )

// Input: positive natural number k , timeline s1 ; : : : ; sj
// Output: tuple k sets consecutive states partitions s1 ; : : : ; sj

k return hfs1g; : : : ; fsj gi;
k = 1 return hfs1 ; : : : ; sj gi;
l := a-member-of(f1; 2; : : : ; j k + 1g);
P0 = fs1 ; : : : ; sl g;
j

return extend-tuple (P0 ; a-k-partition (k

// pick next block size
// construct next block

1; sl+1 ; : : : ; sj ));

Figure 10: Pseudo-code non-deterministically computing k-cover AMA formula, along
non-deterministic helper function selecting k block partition states
timeline.

original syntactic LGG algorithm computing exponentially large set interdigitationgeneralizationsthe k -limited algorithm limits complexity computes interdigitationgeneralizations involving k -MA timelines.
5.2 Incremental Pairwise LGG Computation
implemented learner computes syntactic k-AMA LGG AMA formula setshowever,
directly use algorithm describe above. Rather compute LGG formula
sets via single call algorithm, typically efficient break computation
sequence pairwise LGG calculations. describe approach potential
efficiency gains.
straightforward show syntactic semantic subsumption
LGG( 1 ; : : : ; ) = LGG( 1 ; LGG( 2 ; : : : ; )) AMA formulas. Thus,
recursively applying transformation incrementally compute LGG AMA formulas via sequence 1 pairwise LGG calculations. Note since LGG operator
410

fiL EARNING EMPORAL E VENTS

commutative associative final result depend order process
formulas. refer incremental pairwise LGG strategy incremental approach
strategy makes single call k-AMA LGG algorithm (passing entire formula
set) direct approach.
simplify discussion consider computing LGG formula set
argument extended easily AMA formulas (and hence k-AMA). Recall syntactic
LGG algorithm Figure 9 computes LGG() conjoining timelines IG() subsume others, eliminating subsuming timelines form pruning. incremental
approach applies pruning step pair input formulas processedin contrast,
direct approach must compute interdigitation-generalization input formulas
pruning happen. resulting savings substantial, typically compensates
extra effort spent checking pruning (i.e. testing subsumption timelines
incremental LGG computed). formal approach describing savings constructed


based observation 2IG(f1 ;2 g) IG(fg[ ) 2LGG(1 ;2 ) IG(fg[ )
seen compute LGG [ f1 ; 2 g, latter possibly much cheaper
compute due pruning. is, LGG(1 ; 2 ) typically contains much smaller number
timelines IG(f1 ; 2 g).
Based observations implemented system uses incremental approach
compute LGG formula set. describe optimization used system speedup
computation pairwise LGGs, compared directly running algorithm Figure 9. Given
pair AMA formulas 1 = 1;1 ^ ^ 1;m 2 = 2;1 ^ ^ 2;n , let syntactic
LGG obtained running algorithm Figure 9. algorithm constructs computing
LGGs timeline pairs (i.e., LGG(1;i ; 2;j ) j ) conjoining results
removing subsuming timelines. turns often avoid computing many
LGGs. see consider case exists j 1;i 2;j , know
LGG(1;i ; 2;j ) = 2;j tells us 2;j considered inclusion (it may
pruned). Furthermore know LGG involving 2;j subsume 2;j thus
pruned . shows need compute LGGs involving 2;j , rather
need consider adding 2;j constructing .
observation leads modified algorithm (used system) computing
syntactic LGG pair AMA formulas. new algorithm computes LGGs
non-subsuming timelines. Given AMA formulas 1 2 , modified algorithm proceeds
follows: 1) Compute subsumer set = f 2 1 j 90 2 2 s:t: 0 g [ f 2 2 j 90 2
1 s:t: 0 g. 2) Let AMA 01 ( 02 ) result removing timelines 1 ( 2 )
. 3) Let 0 syntactic LGG 01 02 computed running algorithm Figure 9
(if either 0i empty 0 empty). 4) Let 0 conjunction timelines
subsume timeline 0 . 5) Return = 0 ^ 0 . method avoids computing LGGs
involving subsuming timelines (an exponential operation) cost performing polynomially
many subsumption tests (a polynomial operation). noticed significant advantage
using procedure experiments. particular, advantage tends grow process
training examples. due fact incrementally process training examples
resulting formulas become generalthus, general formulas likely
subsuming timelines. best case 1 syn 2 (i.e., timelines 2 subsuming), see step 2 produces empty formula thus step 3 (the expensive step) performs
workin case return set = 2 desired.
411

fiF ERN , G IVAN , & ISKIND

5.3 Relational Data
L EONARD produces relational models involve objects (force dynamic) relations
objects. Thus event definitions include variables allow generalization objects.
example, definition P ICK U P (x; y; z ) recognizes P ICK U P (hand; block; table) well
P ICK U P (man; box; floor). Despite fact k -AMA learning algorithm propositional,
still able use learn relational definitions.
take straightforward object-correspondence approach relational learning. view
models output L EONARD containing relations applied constants. Since (currently)
support supervised learning, set distinct training examples event type.
implicit correspondence objects filling role across different training models given type. example, models showing P ICK U P (hand; block; table)
P ICK U P (man; box; floor) implicit correspondences given hhand; mani, hblock; boxi,
htable; floori. outline two relational learning methods differ much objectcorrespondence information require part training data.
5.3.1 C OMPLETE BJECT C ORRESPONDENCE
first approach assumes complete object correspondence given, input, along
training examples. Given information, propositionalize training models
replacing corresponding objects unique constants. propositionalized models given
propositional k -AMA learning algorithm returns propositional k -AMA formula.
lift propositional formula replacing constant distinct variable. Lavrac et al.
(1991) taken similar approach.
5.3.2 PARTIAL BJECT C ORRESPONDENCE
approach assumes complete object-correspondence information. sometimes
possible provide correspondences (for example, color-coding objects fill identical
roles recording training movies), information always available.
partial object correspondence (or even none all) available, automatically complete
correspondence apply technique.
moment, assume evaluation function takes two relational models
candidate object correspondence, input, yields evaluation correspondence quality. Given set training examples missing object correspondences, perform greedy
search best set object-correspondence completions models. method works
storing set P propositionalized training examples (initially empty) set U unpropositionalized training examples (initially entire training set). first step, P empty,
evaluate pairs examples U , possible correspondences, select pair yields
highest score, remove examples involved pair U , propositionalize according best correspondence, add P . subsequent step, use previously
computed values pairs examples, one U one P , possible correspondences. select example U correspondence yields highest average
score relative models P example removed U , propositionalized according
winning correspondence, added P . fixed number objects, effort expended
polynomial size training set; however, number objects b appear
training example allowed grow, number correspondences must considered grows
412

fiL EARNING EMPORAL E VENTS

bb . reason, important events involved manipulate modest number
objects.
evaluation function based intuition object roles visual events (as well
events domains) often inferred considering changes initial
final moments event. Specifically, given two models object correspondence,
first propositionalize models according correspondence. Next, compute ADD
DELETE lists model. ADD list set propositions true final
moment initial moment. DELETE list set propositions true
initial moment final moment. add delete lists motivated STRIPS action
representations (Fikes & Nilsson, 1971). Given ADDi DELETEi lists models 1 2,
evaluation function returns sum cardinalities ADD1 \ ADD2 DELETE1 \
DELETE2 . heuristic measures similarity ADD DELETE lists two
models. intuition behind heuristic similar intuition behind STRIPS actiondescription languagei.e., differences initial final moments
event occurrence related target event, event effects described ADD
DELETE lists. found evaluation function works well visual-event domain.
Note, full object correspondences given learner (rather automatically
extracted learner), training examples interpreted specifying target event
took place well objects filled various event roles (e.g., P ICK U P (a,b,c)). Rather,
object correspondences provided training examples interpreted specifying
existence target event occurrence specify objects fill roles (i.e., training
example labeled P ICK U P rather P ICK U P (a,b,c)). Accordingly, rules learned
correspondences provided allow us infer target event occurred
objects filled event roles. example object correspondences manually provided
learner might produce rule,
"

4 (S UPPORTS (z; y) ^ C ONTACTS (z; y));
P ICK U P (x; y; z ) =
(S UPPORTS (x; y) ^ ATTACHED (x; y))

#

whereas learner automatically extracts correspondences would instead produce rule,
"

4 (S UPPORTS (z; y) ^ C ONTACTS (z; y));
P ICK U P =
(S UPPORTS (x; y) ^ ATTACHED (x; y))

#

worth noting, however, upon producing second rule availability single training
example correspondence information allows learner determine roles variables,
upon output first rule. Thus, assumption learner reliably
extract object correspondences, need label training examples correspondence information order obtain definitions explicitly recognize object roles.
5.4 Negative Information
AMA language allow negated propositions. Negation, however, sometimes necessary adequately define event type. section, consider language AMA ,
superset AMA, addition negated propositions. first give syntax semantics
AMA , extend AMA syntactic subsumption AMA . Next, describe approach
413

fiF ERN , G IVAN , & ISKIND

learning AMA formulas using above-presented algorithms AMA. show approach correctly computes AMA LGCF syntactic AMA LGG. Finally, discuss
alternative, related approach adding negation designed reduce overfitting appears
result full consideration negated propositions.
AMA syntax AMA, new grammar building states negated
propositions:
literal
state

::= true j prop j :3prop
::= literal j literal ^ state

prop primitive proposition. semantics AMA
state satisfaction.

AMA except



positive literal P (negative literal
true (false), every x 2 .10

:3P ) satisfied model hM; iff [x] assigns P



state l1 ^ ^ lm satisfied model hM; iff literal li satisfied hM; i.

Subsumption. important difference AMA AMA Proposition 2, establishing existence witnessing interdigitations subsumption, longer true .
words, two timelines 1 ; 2 2 AMA , 1 2 , need
interdigitation witnesses 1 2 . see this, consider AMA timelines:

1 = (a ^ b ^ c); b; a; b; (a ^ b ^ : c)
2 = b; a; c; a; b; a; : c; a; b
argue:
1. interdigitation witnesses 1 2 . see this, first show that,
witness, second fourth states 1 (each b) must interdigitate align
either first fifth, fifth ninth states 2 (also, b). either
cases, third state 1 interdigitate states 2 subsume it.
2. Even so, still 1 2 . see this, consider model hM; satisfies 1 .
must interval [i1 ; i2 ] within hM; [i1 ; i2 ]i satisfies third state 1 ,
state a. two cases:
(a) proposition c true point hM; [i1 ; i2 ]i. Then, one verify hM;
satisfies 1 2 following alignment:

1
2

=
=

(a ^ b ^ c); b;
b;

a;
a; c; a;

b;
b;

(a ^ b ^ : c)
a; : c; a; b

10. note important use notation :3P rather :P . event-logic, formula :P
satisfied model whenever P false instant model. Rather, event-logic interprets :3P
indicating P never true model (as defined above). Notice first form negation yield
liquid propertyi.e., :P true along interval necessarily subintervals. second form
negation, however, yield liquid property provided P liquid. important learning algorithms,
since assume states built liquid properties.

414

fiL EARNING EMPORAL E VENTS

(b) proposition c false everywhere hM; [i1 ; i2 ]i. Then, one verify hM;
satisfies 1 2 following alignment:

1 =
(a ^ b ^ c);
2 =
b; a; c; a;
follows 1 2 .

b;
b;

a;
a; : c; a;

b; (a ^ b ^ : c)
b

light examples, conjecture computationally hard compute AMA
subsumption even timelines. reason, extend definition syntactic subsumption AMA way provides clearly tractable subsumption test analogous
discussed AMA.
Definition 6. AMA 1 syntactically subsumed AMA 2 (written 1 syn 2 ) iff
timeline 2 2 2 , timeline 1 2 1 witnessing interdigitation
1 2 .
difference definition previous one AMA need
test witnessing interdigitations timelines rather subsumption timelines.
AMA formulas, note new old definition equivalent (due Proposition 2);
however, AMA new definition weaker, result general LGG formulas.
one might expect, AMA syntactic subsumption implies semantic subsumption tested
polynomial-time using subsumption graph described Lemma 8 test witnesses.
Learning. Rather design new LGCF LGG algorithms directly handle AMA ,
instead compute functions indirectly applying algorithms AMA transformed
problem. Intuitively, adding new propositions models (i.e., training examples) represent proposition negations. Assume training-example models
set propositions P = fp1 ; : : : ; pn g. introduce new set P = fp1 ; : : : ; pn g propositions
use construct new training models P [ P assigning true pi time
model iff pi false model time. forming new set training models (each
twice many propositions original models) compute least general AMA formula
covers new models (by computing AMA LGCFs applying syntactic AMA LGG
algorithm), resulting AMA formula propositions P [ P . Finally replace pi
:3pi resulting AMA formula 0 propositions P turns
syntactic subsumption 0 least general AMA formula covers original training
models.
show correctness transformational approach computing AMA
LGCF syntactic LGG. First, introduce notation. Let set models
P . Let set models P [ P , time, i, exactly one pi
pi true. Let following mapping M: hM; 2 M, [hM; i]
unique hM 0 ; 2 j 2 i, 0 (j ) assigns pi true iff (j ) assigns pi
true. Notice inverse functional mapping M. approach handling
negation using purely AMA algorithms begins applying original training models.
follows, consider AMA formulas propositions P , AMA formulas
propositions P [ P .
Let F mapping AMA AMA 2 AMA , F [ ] AMA formula
identical except :3pi replaced pi . Notice inverse F func415

fiF ERN , G IVAN , & ISKIND

tion AMA AMA corresponds final step approach described above.
following lemma shows one-to-one correspondence satisfaction AMA
formulas models satisfaction AMA formulas models M.
Lemma 26. model hM; 2 2 AMA ,
[hM; i].

covers hM;

iff

F [ ] covers

Using lemma, straightforward show transformational approach computes
AMA LGCF semantic subsumption (and hence syntactic subsumption).
Proposition 27.



hM; 2 M, let AMA LGCF model [hM; i].
LGCF hM; i, equivalence.

F 1 [] unique AMA

Then,

Proof: know covers [hM; i], therefore Lemma 26 know F 1 [] covers
hM; i. show F 1[] least-general formula AMA covers hM; i.
sake contradiction assume 0 2 AMA covers hM; 0 < F 1 [].
follows model hM 0 ; 0 covered F 1 [] 0 . Lemma 26
F [0 ] covers [hM; i] since unique AMA LGCF [hM; i],
equivalence, F [0 ]. However, also [hM 0 ; 0 i] covered
F [0 ] gives contradiction. Thus, 0 exist. follows
AMA LGCF. uniqueness AMA LGCF equivalence follows AMA
closed conjunction; two non-equivalent LGCF formulas, could
conjoined get LGCF formula strictly less one them. 2
use fact F operator preserves syntactic subsumption. particular, given
two timelines 1 ; 2 , clear witnessing interdigitation 1 2 trivially
converted witness F [1 ] F [2 ] (and vice versa). Since syntactic subsumption defined
terms witnessing interdigitations, follows 1 ; 2 2 AMA , ( 1 syn 2 ) iff
(F [ 1 ] syn F [ 2 ]). Using property, straightforward show compute syntactic
AMA LGG using syntactic AMA LGG algorithm.
Proposition 28.

AMA

formulas

1 ; : : : ; ,

let



fF [ 1 ]; : : : ; F [ ]g. Then, F 1[ ] unique syntactic AMA

syntactic AMA LGG
LGG f 1 ; : : : ; g.

Proof: know i, F [ ] syn thus, since F 1 preserves syntactic subsumption,
i, syn F 1 [ ]. shows F 1 [ ] generalization inputs.
show F 1 [ ] least formula. sake contradiction assume
F 1 [ ] least. follows must 0 2 AMA 0 <syn F 1 [ ]
i, syn 0 . Combining fact F preserves syntactic subsumption, get
F [ 0 ] <syn i, F [ ] F [ 0 ]. contradicts fact LGG;
must F 1 [ ] syntactic AMA LGG. argued elsewhere, uniqueness
LGG follows fact AMA closed conjunction. 2
propositions ensure correctness transformational approach computing
syntactic LGG within AMA . case semantic subsumption, transformational approach
correctly compute AMA LGG. see this, recall given two timelines 1 ; 2 2 AMA , 1 2 , witnessing interdigitation. Clearly
416

fiL EARNING EMPORAL E VENTS

semantic subsumption, AMA LGG 1 2 2 . However, semantic AMA LGG
F [1 ] F [2 ] F [2 ]. reason since witness F [1 ] F [2 ]
(and F [i ] timelines), know Proposition 2 F [1 ] 6 F [2 ]. Thus, F [2 ]
cannot returned AMA LGG, since subsume input formulasthis shows
transformational approach return 2 = F 1 [F [2 ]]. Here, transformational
approach produce AMA formula general 2 .
computational side, note that, since transformational approach doubles number propositions training data, algorithms specifically designed AMA may
efficient. algorithms might leverage special structure transformed examples
AMA algorithms ignorein particular, exactly one pi pi true time.
Boundary Negation. experiments, actually compare two methods assigning truth
values pi propositions training data models. first method, called full negation,
assigns truth values described above, yielding syntactically least-general AMA formula
covers examples. found, however, using full negation often results learning overly
specific formulas. help alleviate problem, second method places bias use
negation. choice bias inspired idea that, often, much useful information
characterizing event type pre- post-conditions. second method, called boundary
negation, differs full negation allows pi true initial final moments
model (and pi false). pi must false times. is, allow
informative negative information beginnings ends training examples.
found boundary negation provides good trade-off negation (i.e., AMA),
often produces overly general results, full negation (i.e., AMA ), often produces overly
specific much complicated results.
5.5 Overall Complexity Scalability
review overall complexity visual event learning component discuss
scalability issues. Given training set temporal models (i.e., set movies), system
following: 1) Propositionalize training models, translating negation descried Section 5.4.
2) Compute LGCF propositional model. 3) Compute k -AMA LGG LGCFs.
4) Return lifted (variablized) version LGG. Steps two four require little computational
overhead, linear sizes input output respectively. Steps one three
computational bottlenecks systemthey encompass inherent exponential complexity
arising relational temporal problem structure.
Step One. Recall Section 5.3.2 system allows user annotate training examples object correspondence information. technique propositionalizing models
shown exponential number unannotated objects training example. Thus,
system requires number objects relatively small correspondence information
given small number objects. Often event class definitions interested
involve large number objects. true, controlled learning setting
manage relational complexity generating training examples small number (or
zero) irrelevant objects. case domains studied empirically paper.
less controlled setting, number unannotated objects may prohibit use
correspondence techniquethere least three ways one might proceed. First, try
417

fiF ERN , G IVAN , & ISKIND

develop efficient domain-specific techniques filtering objects finding correspondences.
is, particular problem may possible construct simple filter removes irrelevant
objects consideration find correspondences remaining objects. Second,
provide learning algorithm set hand-coded first-order formulas, defining set
domain-specific features (e.g., spirit Roth & Yih, 2001). features used
propositionalize training instances. Third, draw upon ideas relational learning
design truly first-order version k -AMA learning algorithm. example, one could use
existing first-order generalization algorithms generalize relational state descriptions. Effectively
approach pushes object correspondence problem k -AMA learning algorithm rather
treating preprocessing step. Since well known computing first-order LGGs
intractable (Plotkin, 1971), practical generalization algorithms retain tractability constraining
LGGs various ways (e.g., Muggleton & Feng, 1992; Morales, 1997).
Step Three. system uses ideas Section 5.2 speedup k -AMA LGG computation
set training data. Nevertheless, computational complexity still exponential k thus,
practice restricted using relatively small values k . restriction limit
performance visual event experiments, expect limit direct applicability
system complex problems. particular, many event types interest may
adequately represented via k -AMA k small. event types, however, often contain
significant hierarchical structurei.e., decomposed set short sub-event types.
interesting research direction consider using k -AMA learner component
hierarchical learning systemthere could used learn k -AMA sub-event types. note
learner alone cannot applied hierarchically requires liquid primitive events,
learns non-liquid composite event types. work required (and intended) construct
hierarchical learner based perhaps non-liquid AMA learning.
Finally, recall compute LGG examples, system uses sequence 1
pairwise LGG calculations. fixed k , pairwise calculation takes polynomial time. However, since size pairwise LGG grow least constant factor respect
inputs, worst-case time complexity computing sequence 1 pairwise LGGs exponential m. expect worst case primarily occur target event type
compact k -AMA representationin case hierarchical approach described
appropriate. compact representation, empirical experience indicates
growth occurin particular, pairwise LGG tends yield significant pruning. problems, reasonable assumptions amount pruning11 imply time
complexity computing sequence 1 pairwise LGGs polynomial m.

6. Experiments
6.1 Data Set
data set contains examples 7 different event types: pick up, put down, stack, unstack, move,
assemble, disassemble. involve hand two three blocks. detailed
description sample video sequences event types, see Siskind (2001). Key frames
sample video sequences event types shown Figure 11. results segmentation,
11. particular, assume size pairwise k-AMA LGG usually bounded sizes k-covers
inputs.

418

fiL EARNING EMPORAL E VENTS

tracking, model reconstruction overlaid video frames. recorded 30 movies
7 event classes resulting total 210 movies comprising 11946 frames.12
replaced one assemble movie (assemble-left-qobi-04), duplicate copy another (assembleleft-qobi-11) segmentation tracking errors.
event classes hierarchical occurrences events one class contain occurrences events one simpler classes. example, movie depicting
OVE (a; b; c; d) event (i.e. moves b c d) contains subintervals P ICK U P (a; b; c)
P UT (a; b; d) events occur. experiments, learning definition event
class movies event class used training. train movies
event classes may also depict occurrence event class learned subevent.
However, evaluating learned definitions, wish detect events correspond
entire movie well subevents correspond portions movie. example, given
movie depicting OVE (a; b; c; d) event, wish detect OVE(a; b; c; d) event
also P ICK U P (a; b; c) P UT (a; b; d) subevents well. movie type data
set, set intended events subevents detected. definition
detect intended event, deem error false negative. definition detects unintended
event, deem error false positive. example, movie depicts OVE(a; b; c; d) event,
intended events OVE(a; b; c; d), P ICK U P (a; b; c), P UT (a; b; c). definition
pick detects occurrence P ICK U P (c; b; a) P ICK U P (b; a; c), P ICK U P (a; b; c),
charged two false positives well one false negative. evaluate definitions
terms false positive negative rates describe below.
6.2 Experimental Procedure
event type, evaluate k -AMA learning algorithm using leave-one-movie-out crossvalidation technique training-set sampling. parameters learning algorithm k
degree negative information used. value either P, positive propositions
only, BN, boundary negation, N, full negation. parameters evaluation procedure
include target event type E training-set size N . Given information, evaluation
proceeds follows: movie (the held-out movie) 210 movies, apply k AMA learning algorithm randomly drawn training sample N movies 30 movies
event type E (or 29 movies one 30). Use L EONARD detect occurrences
learned event definition . Based E event type , record number false
positives false negatives , detected L EONARD . Let FP FN total number
false positives false negatives observed 210 held-out movies respectively. Repeat
entire process calculating FP FN 10 times record averages FP FN.13
Since event types occur frequently data others simpler events
occur subevents complex events vice versa, report FP FN directly.
Instead, normalize FP dividing total number times L EONARD detected target
event correctly incorrectly within 210 movies normalize FN dividing total
12. source code data used experiments available Online Appendix 1, also
ftp://ftp.ecn.purdue.edu/qobi/ama.tar.Z.
13. record times experiments, system fast enough give live demos N = 29
k = 3 boundary negation, giving best results show (though dont typically record 29 training
videos live demo reasons). less favorable parameter settings (particularly k = 4 full
negation) take (real-time) hour so.

419

fiF ERN , G IVAN , & ISKIND

pick

put

stack

unstack

move

assemble

disassemble

Figure 11: Key frames sample videos 7 event types.

420

fiL EARNING EMPORAL E VENTS

number correct occurrences target event within 210 movies (i.e., human assessment
number occurrences target event). normalized value FP estimates probability target event occur given predicted occur, normalized
value FN estimates probability event predicted occur given
occur.
6.3 Results
evaluate k -AMA learning approach, ran leave-one-movie-out experiments, described
above, varying k , , N . 210 example movies recorded color-coded objects
provide complete object-correspondence information. compared learned event definitions
performance two sets hand-coded definitions. first set HD1 hand-coded definitions
appeared Siskind (2001). response subsequent deeper understanding behavior
L EONARD model-reconstruction methods, manually revised definitions yield another
set HD2 hand-coded definitions gives significantly better FN performance cost
FP performance. Appendix C gives event definitions HD1 HD2 along set
machine-generated definitions, produced k -AMA learning algorithm, given training data
k = 30 = BN.
6.3.1 BJECT C ORRESPONDENCE
evaluate algorithm finding object correspondences, ignored correspondence information provided color coding applied algorithm training models event
type. algorithm selected correct correspondence 210 training models. Thus,
data set, learning results correspondence information given identical
correspondences manually provided, except that, first case, rules
specify particular object roles, discussed section 5.3.2. Since evaluation procedure uses
role information, rest experiments use manual correspondence information, provided
color-coding, rather computing it.
correspondence technique perfect experiments, may suited
event types. Furthermore, likely produce errors noise levels increase. Since
correspondence errors represent form noise learner makes special provisions
handling noise, results likely poor errors common. example,
worst case, possible single extremely noisy example cause LGG trivial (i.e.,
formula true). cases, forced improve noise tolerance learner.
6.3.2 VARYING k

first three rows Table 1 show FP FN values 7 event types k 2 f2; 3; 4g ,
N = 29 (the maximum), = BN. Similar trends found = P = N.
general trend that, k increases, FP decreases remains FN increases remains
same. trend consequence k -cover approach. because, k increases,
k -AMA language contains strictly formulas. Thus k1 > k2 , k1 -cover formula
never general k2 -cover. strongly suggests, prove, FP
non-increasing k FN non-decreasing k .
results show 2-AMA overly general put assemble, i.e. gives high
FP. contrast, 3-AMA achieves FP = 0 event type, pays penalty FN compared
421

fiF ERN , G IVAN , & ISKIND

k
2 BN

pick

put

stack

unstack

move

assemble

disassemble

FP
FN

0
0

0.14
0.19

0
0.12

0
0.03

0
0

0.75
0

0
0

3

BN

FP
FN

0
0

0
0.2

0
0.45

0
0.10

0
0.03

0
0.07

0
0.10

4

BN

FP
FN

0
0

0
0.2

0
0.47

0
0.12

0
0.03

0
0.07

0
0.17

3

P

FP
FN

0.42
0

0.5
0.19

0
0.42

0.02
0.11

0
0.03

0
0.03

0
0.10

3

BN

FP
FN

0
0

0
0.2

0
0.45

0
0.10

0
0.03

0
0.07

0
0.10

3

N

FP
FN

0
0.04

0
0.39

0
0.58

0
0.16

0
0.13

0
0.2

0
0.2

HD1

FP
FN

0.01
0.02

0.01
0.22

0
0.82

0
0.62

0
0.03

0
1.0

0
0.5

HD2

FP
FN

0.13
0.0

0.11
0.19

0
0.42

0
0.02

0
0.0

0
0.77

0
0.0

Table 1: FP FN learned definitions, varying k , hand-coded definitions.
2-AMA. Since 3-AMA achieves FP = 0, likely advantage moving k -AMA
k > 3. is, expected result FN become larger. effect demonstrated
4-AMA table.
6.3.3 VARYING

Rows four six Table 1 show FP FN 7 event types 2 fP; BN; Ng, N = 29,
k = 3. Similar trends observed values k . general trend that,
degree negative information increases, learned event definitions become specific.
words, FP decreases FN increases. makes sense since, negative information
added training models, specific structure found data exploited
k -AMA formulas. see that, = P, definitions pick put
overly general, produce high FP. Alternatively, = N, learned definitions
overly specific, giving FP = 0, cost high FN. experiments, well others,
found = BN yields best worlds: FP = 0 event types lower FN
achieved = N.
Experiments shown demonstrated that, without negation pick put down,
increase k arbitrarily, attempt specialize learned definitions, never significantly reduce FP. indicates negative information plays particularly important role
constructing definitions event types.

422

fiL EARNING EMPORAL E VENTS

6.3.4 C OMPARISON



H -C ODED EFINITIONS

bottom two rows table 1 show results HD1 HD2 . yet attempted
automatically select parameters learning (i.e. k ). Rather, focus comparing
hand-coded definitions parameter set judged best performing across event
types. believe, however, parameters could selected reliably using cross-validation
techniques applied larger data set. case, parameters would selected perevent-type basis would likely result even favorable comparison hand-coded
definitions.
results show learned definitions significantly outperform HD1 current data
set. HD1 definitions found produce large number false negatives current
data set. Notice that, although HD2 produces significantly fewer false negatives event types,
produces false positives pick put down. hand definitions
utilize pick put macros defining events.
performance learned definitions competitive performance HD2 .
main differences performance are: (a) pick put down, learned HD2 definitions
achieve nearly FN learned definitions achieve FP = 0 whereas HD2 significant
FP, (b) unstack disassemble, learned definitions perform moderately worse HD2
respect FN, (c) learned definitions perform significantly better HD2 assemble
events.
conjecture manual revision could improve HD2 perform well (and perhaps better than) learned definitions every event class. Nonetheless, view experiment
promising, demonstrates learning technique able compete with, sometimes
outperform, significant hand-coding efforts one authors.
6.3.5 VARYING N
practical interest know training-set size affects algorithms performance.
application, important method work well fairly small data sets, tedious
collect event data. Table 2 shows FN learning algorithm event type, N
reduced 29 5. experiments, used k = 3 = BN. Note FP = 0
event types N hence shown. expect FN increase N decreased,
since, specific-to-general learning, data yields more-general definitions. Generally, FN
flat N > 20, increases slowly 10 < N < 20, increases abruptly 5 < N < 10.
also see that, several event types, FN decreases slowly, N increased 20 29.
indicates larger data set might yield improved results event types.
6.3.6 P ERSPICUITY



L EARNED EFINITIONS

One motivation using logic-based event representation support perspicuityin respect
results mixed. note perspicuity fuzzy subjective concept. Realizing this,
say event definition perspicuous humans knowledge language
would find definition natural. Here, assume human detailed knowledge model-reconstruction process learner trying fit. Adding assumption
would presumably make definitions qualify perspicuous, many complex features learned definitions appear fact due idiosyncrasies model-reconstruction
process. sense, evaluating perspicuity output entire system,
423

fiF ERN , G IVAN , & ISKIND

learner itself, key route improving perspicuity sense would improve
intuitive properties model-reconstruction output without change learner.
learned hand-coded definitions similar respect accuracy, typically
learned definitions much less perspicuous. simplest event types, however, learned
definitions arguably perspicuous. look issue detail. Appendix C gives
hand-coded definitions HD1 HD2 along set machine-generated definitions.
learned definitions correspond output k -AMA learner run 30 training
movies event type k = 3 = BN (i.e., best performing configuration
respect accuracy).
Perspicuous Definitions. P ICK U P (x; y; z ) P UT (x; y; z ) definitions particular interest since short state sequences appear adequate representing event types
thus, hope perspicuous 3-AMA definitions. fact, hand-coded definitions involve short sequences. Consider hand-coded definitions P ICK U P(x; y; z )the definitions
roughly viewed 3-MA timelines form begin;trans;end.14 State begin asserts facts
indicate z held x end asserts facts indicate held
x z . State trans intended model fact L EONARDs model-reconstruction
process always handle transition begin end smoothly (so definition
begin;end work well). make similar observations P UT OWN(x; y; z ).
Figure 15 gives learned 3-AMA definitions P ICK U P (x; y; z ) P UT (x; y; z )
definitions contain six two 3-MA timelines respectively. Since definitions consists
multiple parallel timelines, may first seem perspicuous. However, closer examination
reveals that, definition, single timeline arguably perspicuouswe
placed perspicuous timelines beginning definition. perspicuous timelines
natural begin;trans;end interpretation. fact, practically equivalent definitions
P ICK U P (x; y; z ) P UT (x; y; z ) HD2 .15
mind, notice HD2 definitions overly general indicated significant
false positive rates. learned definitions, however, yield false positives without significant
increase false negatives. learned definitions improve upon HD2 essentially specializing
HD2 definitions (i.e., perspicuous timelines) conjoining non-perspicuous
timelines. non-perspicuous timelines often intuitive, capture patterns
events help rule non-events. example, learned definition P ICK U P (x; y; z )
non-perspicuous timelines indicate ATTACHED (y; z ) true transition period
event. attachment relationship make intuitive sense. Rather, represents
systematic error made model reconstruction process pick events.
summary, see learned definitions P ICK U P (x; y; z ) P UT (x; y; z )
contain perspicuous timeline one non-perspicuous timelines. perspicuous timelines give intuitive definition events, whereas non-perspicuous timelines capture nonintuitive aspects events model reconstruction process important practice.
note that, experienced users, primary difficulty hand-coding definitions L EONARD
14. Note event-logic definition P ICK U P(x; y; z ) HD2 written compact form 3-MA,
definition converted 3-MA (and hence 3-AMA). Rather, HD1 cannot translated exactly 3-MA
since uses disjunctionit disjunction two 3-MA timelines.
15. primary difference HD2 definitions contain negated propositions. learner considers
proposition negation proposition true point training movies. Many negated
propositions HD2 never appear positively, thus included learned definitions.

424

fiL EARNING EMPORAL E VENTS

determining non-perspicuous properties must included. Typically requires many
iterations trial error. automated technique relieve user task. Alternatively,
could view system providing guidance task.
Large Definitions. TACK (w; x; y; z ) U NSTACK (w; x; y; z ) events nearly identical
put pick respectively. difference picking
putting onto two block (rather single block) tower (i.e., composed blocks z ).
Thus, might expect perspicuous 3-AMA definitions. However, see
learned definitions TACK (w; x; y; z ) U NSTACK (w; x; y; z ) Figures 16 17 involve
many timelines P ICK U P (w; x; ) P UT (w; x; ). Accordingly,
definitions quite overwhelming much less perspicuous.
Despite large number timelines, definitions general structure
pick put down. particular, contain distinguished perspicuous timeline,
placed beginning definition, conjoined many non-perspicuous timelines.
clear that, above, perspicuous timelines natural begin;trans;end interpretation
and, again, similar definitions HD 2 . case, however, definitions
HD2 overly general (committing false positives). Thus, inclusion
non-perspicuous timelines detrimental effect since unnecessarily specialize definition
resulting false negatives.
suspect primary reason large number non-perspicuous timelines relative
definitions pick put stems increased difficulty constructing
force-dynamic models. inclusion two block tower examples causes modelreconstruction process produce unintended results, particularly transition periods
TACK U NSTACK . result often many unintuitive physically incorrect patterns
involving three blocks hand produced transition period. learner
captures patterns roughly via non-perspicuous timelines. likely generalizing
definitions including training examples would filter timelines, making
overall definition perspicuous. Alternatively, interest consider pruning learned
definitions. straightforward way generate negative examples. these,
could remove timelines (generalizing definition) contribute toward rejecting
negative examples. unclear prune definitions without negative examples.
Hierarchical Events. OVE(w; x; y; z ), SSEMBLE (w; x; y; z ), ISASSEMBLE (w; x; y; z )
inherently hierarchical, composed four simpler event types. hand-coded definitions leverage structure utilizing simpler definitions macros. light,
clear that, viewed non-hierarchically, (as learner does) events involve relatively
long state sequences. Thus, 3-AMA adequate writing perspicuous definitions.
spite representational shortcoming, learned 3-AMA definitions perform quite well.
performance supports one arguments using AMA section 3.2. Namely, given
easier find short rather long sequences, practical approach finding definitions long
events conjoin short sequences within events. Examining timelines learned
3-AMA definitions reveals might expect. timeline captures often understandable
property long event sequence, conjunction timelines cannot considered
perspicuous definition. future direction utilize hierarchical learning techniques
improve perspicuity definitions maintaining accuracy.
425

fiF ERN , G IVAN , & ISKIND

N

pick

put

stack

unstack

move

assemble

disassemble

29
25
20
15
10
5

0.0
0.0
0.01
0.01
0.07
0.22

0.20
0.20
0.21
0.22
0.27
0.43

0.45
0.47
0.50
0.53
0.60
0.77

0.10
0.16
0.17
0.26
0.36
0.54

0.03
0.05
0.08
0.14
0.23
0.35

0.07
0.09
0.12
0.20
0.32
0.57

0.10
0.10
0.12
0.16
0.26
0.43

Table 2: FN k

= 3, = BN, various values N .

note, however, that, level, learned definition OVE (w; x; y; z ) given Figure 18 perspicuous. particular, first 3-MA timeline naturally interpreted giving
pre- post-conditions move action. is, initially x supported hand w
empty finally x supported z hand w empty. Thus, care preand post-conditions, might consider timeline perspicuous. remaining timelines
definition capture pieces internal event structure facts indicating x moved
hand. weaker case made assemble disassemble. first timeline
learned definitions Figures 19 20 interpreted giving pre- post-conditions.
However, cases, pre(post)-conditions assemble(disassemble) quite incomplete.
incompleteness due inclusion examples model-reconstruction process
properly handle initial(final) moments.

7. Related Work
discuss two bodies related work. First, present previous work visual event recognition relates experiments here. Second, discuss previous approaches learning
temporal patterns positive data.
7.1 Visual Event Recognition
system unique combines positive-only learning temporal, relational,
force-dynamic representation recognize events real video. Prior work investigated various subsets features systembut, date, system combined pieces
together. Incorporating one pieces system significant endeavor. respect, competing approaches directly compare system against. Given this,
following representative list systems common features ours. meant
comprehensive focuses pointing primary differences systems ours, primary differences actually render systems loosely related
ours.
Borchardt (1985) presents representation temporal, relational, force-dynamic event definitions definitions neither learned applied video. Regier (1992) presents techniques learning temporal event definitions learned definitions neither relational, force
dynamic, applied video. addition learning technique truly positive-onlyrather,
extracts implicit negative examples event type positive examples event types.
426

fiL EARNING EMPORAL E VENTS

Yamoto, Ohya, Ishii (1992), Brand Essa (1995), Siskind Morris (1996), Brand, Oliver,
Pentland (1997), Bobick Ivanov (1998) present techniques learning temporal event
definitions video learned definitions neither relational force dynamic. Pinhanez
Bobick (1995) Brand (1997a) present temporal, relational event definitions recognize
events video definitions neither learned force dynamic. Brand (1997b) Mann
Jepson (1998) present techniques analyzing force dynamics video neither formulate
event definitions apply techniques recognizing events learning event definitions.
7.2 Learning Temporal Patterns
divide body work three main categories: temporal data mining, inductive logic
programming, finite-statemachine induction.
Temporal Data Mining. sequence-mining literature contains many general-to-specific (levelwise) algorithms finding frequent sequences (Agrawal & Srikant, 1995; Mannila, Toivonen,
& Verkamo, 1995; Kam & Fu, 2000; Cohen, 2001; Hoppner, 2001). explore specific-togeneral approach. previous work, researchers studied problem mining temporal
patterns using languages interpreted placing constraints partially totally ordered
sets time points, e.g., sequential patterns (Agrawal & Srikant, 1995) episodes (Mannila et al.,
1995). languages place constraints time points rather time intervals work
here. recently work mining temporal patterns using interval-based pattern
languages (Kam & Fu, 2000; Cohen, 2001; Hoppner, 2001).
Though languages learning frameworks vary among approaches, share two
central features distinguish approach. First, typically goal
finding frequent patterns (formulas) within temporal data setour approach focused
finding patterns frequency one (covering positive examples). first learning
application visual-event recognition yet required us find patterns frequency less
one. However, number ways extend method direction
becomes necessary (e.g., deal noisy training data). Second, approaches
use standard general-to-specific level-wise search techniques, whereas chose take specificto-general approach. One direction future work develop general-to-specific level-wise
algorithm finding frequent formulas compare specific-to-general approach.
Another direction design level-wise version specific-to-general algorithmwhere
example, results obtained k -AMA LGG used efficiently calculate
(k + 1)-AMA LGG. Whereas level-wise approach conceptually straightforward general-tospecific framework clear specific-to-general case. familiar
temporal data-mining systems take specific-to-general approach.
First-Order Learning Section 3.3, pointed difficulties using existing first-order
clausal generalization techniques learning AMA formulas. spite difficulties, still
possible represent temporal events first-order logic (either without capturing AMA
semantics precisely) apply general-purpose relational learning techniques, e.g., inductive
logic programming (ILP) (Muggleton & De Raedt, 1994). ILP systems require positive
negative training examples hence suitable current positive-only framework.
Exceptions include G OLEM (Muggleton & Feng, 1992), P ROGOL (Muggleton, 1995), C LAU DIEN (De Raedt & Dehaspe, 1997), among others. performed full evaluation
427

fiF ERN , G IVAN , & ISKIND

Inputs

AMA

Subsumption
Semantic
Syntactic
P
P
coNP-complete P

Semantic AMA LGG
Lower Upper Size
P
coNP EXP
coNP NEXP 2-EXP?

Syntactic AMA LGG
Lower Upper Size
P
coNP EXP
P
coNP EXP

Table 3: Complexity Results Summary. LGG complexities relative input plus output size.
size column reports worst-case smallest correct output size. ? indicates
conjecture.
systems, early experiments visual-event recognition domain confirmed belief
horn clauses, lacking special handling time, give poor inductive bias. particular, many
learned clauses find patterns simply make sense temporal perspective and,
turn, generalize poorly. believe reasonable alternative approach may incorporate
syntactic biases ILP systems done, example, Cohen (1994), Dehaspe De Raedt
(1996), Klingspor, Morik, Rieger (1996). work, however, chose work directly
temporal logic representation.
Finite-State Machines Finally, note much theoretical empirical research
learning finite-state machines (FSMs) (Angluin, 1987; Lang, Pearlmutter, & Price, 1998).
view FSMs describing properties strings (symbol sequences). case, however,
interested describing sequences propositional models rather sequences symbols.
suggests learning type factored FSM arcs labeled sets propositions
rather single symbols. Factored FSMs may natural direction extend
expressiveness current language, example allowing repetition. aware
work concerned learning factored FSMs; however, likely inspiration drawn
symbol-based FSM-learning algorithms.

8. Conclusion
presented simple logic representing temporal events called AMA shown
theoretical empirical results learning AMA formulas. Empirically, weve given first
system learning temporal, relational, force-dynamic event definitions positive-only input
applied system learn definitions real video input. resulting
performance matches event definitions hand-coded substantial effort human
domain experts. theoretical side, Table 3 summarizes upper lower bounds
shown subsumption generalization problems associated logic.
case, provided provably correct algorithm matching upper bound shown.
table also shows worst-case size smallest LGG could possibly take relative input
size, AMA inputs. key results table polynomial-time
subsumption AMA syntactic subsumption, coNP lower bound AMA subsumption,
exponential size LGGs worst case, apparently lower complexity syntactic AMA
LGG versus semantic LGG. described build learner based results applied
visual-event learning domain. date, however, definitions learn neither crossmodal perspicuous. performance learned definitions matches hand428

fiL EARNING EMPORAL E VENTS

coded ones, wish surpass hand coding. future, intend address cross-modality
applying learning technique planning domain. also believe addressing perspicuity
lead improved performance.

Acknowledgments
authors wish thank anonymous reviewers helping improve paper. work
supported part NSF grants 9977981-IIS 0093100-IIS, NSF Graduate Fellowship
Fern, Center Education Research Information Assurance Security
Purdue University. Part work performed Siskind NEC Research Institute,
Inc.

Appendix A. Internal Positive Event Logic
give syntax semantics event logic called Internal Positive Event Logic
(IPEL). logic used main text motivate choice small subset
logic, AMA, showing, Proposition 4, AMA define set models IPEL
define.
event type (i.e., set models) said internal whenever contains model
= hM; i, also contains model agrees truth assignments [i] 2 .
Full event logic allows definition non-internal events, example, formula = 3< P
satisfied hM; interval 0 entirely preceding P satisfied
hM; 0 i, thus internal. applications considering appear require
non-internal events, thus currently consider events internal.
Call event type positive contains model = hM; [1; 1]i (1) truth
assignment assigning propositions value true. positive event type cannot require proposition false point time.
IPEL fragment full propositional event logic describe positive internal
events. conjecture, yet proven, positive internal events representable
full event logic Siskind (2001) represented IPEL formula. Formally, syntax
IPEL formulas given

E ::= true j prop j E1 _ E2 j 3R E1 j E1 ^R E2 ;
0

Ei IPEL formulas, prop primitive proposition (sometimes called primitive event
type), R subset thirteen Allen interval relations fs,f,d,b,m,o,=,si,fi,di,bi,ai,oi g (Allen,
1983), R0 subset restricted set Allen relations fs,f,d,=g, semantics
Allen relation given Table 4. difference IPEL syntax full propositional
event logic event logic allows negation operator, that, full event logic, R0
subset thirteen Allen relations. operators ^ ; used define AMA formulas
merely abbreviations IPEL operators ^f=g ^fmg respectively, AMA subset
IPEL (though distinguished subset indicated Proposition 4).
thirteen Allen interval relations binary relations set closed naturalnumber intervals. Table 4 gives definitions relations, defining [m1 ; m2 ] r [n1 ; n2 ]
Allen relation r . Satisfiability IPEL formulas defined follows,
429

fiF ERN , G IVAN , & ISKIND

I1
[m1 ; m2 ]
[m1 ; m2 ]
[m1 ; m2 ]
[m1 ; m2 ]
[m1 ; m2 ]
[m1 ; m2 ]
[m1 ; m2 ]

Relation

f

b


=

I2
[n1 ; n2 ]
[n1 ; n2 ]
[n1 ; n2 ]
[n1 ; n2 ]
[n1 ; n2 ]
[n1 ; n2 ]
[n1 ; n2 ]

English
starts
finishes


meets
overlaps
equals

Definition
m1 = n1 m2
m1 n1 m2
m1 n1 m2

n2
= n2
n2

m2 n1
m2 = n1 m2 + 1 = n1
m1 n1 m2 n2
m1 = n1 m2 = n2

Inverse
si
fi
di
bi
mi
oi
=

Table 4: Thirteen Allen Relations (adapted semantics).

true satisfied every model.
prop satisfied model hM; iff [x] assigns prop true every x 2 .
E1 _ E2 satisfied model iff satisfies E1 satisfies E2.
3RE satisfied model hM; iff r 2 R interval 0 0 r
hM; 0 satisfies E .
E1 ^R E2 satisfied model hM; iff r 2 R exist intervals I1 I2
I1 r I2 , PAN (I1 ; I2 ) = hM; I1 satisfies E1 hM; I2 satisfies E2 .
prop primitive proposition, E Ei IPEL formulas, R set Allen relations,
PAN (I1 ; I2 ) minimal interval contains I1 I2 . definition, easy
show, induction number operators connectives formula, IPEL formulas
define internal events. One also verify definition satisfiability given earlier AMA
formulas corresponds one give here.

Appendix B. Omitted Proofs
Lemma 1. timeline model M, satisfies witnessing
interdigitation MAP(M) .
Proof: Assume = hM; satisfies timeline = s1 ; : : : ; sn , let 0 =
MAP(M). straightforward argue, induction length , exists mapping
V 0 states sub-intervals ,

2 V 0 (s), [i] satisfies s,
V 0(s1) includes initial time point ,
V 0(sn) includes final time point ,
2 [1; n 1], V 0(si ) meets V 0(si+1) (see Table 4).
430

fiL EARNING EMPORAL E VENTS

Let V relation states 2 members 2 true 2 V 0 (s). Note
conditions V 0 ensure every 2 every 2 appear tuple V (not
necessarily together). use V construct witnessing interdigitation W .
Let R total, one-to-one, onto function time-points corresponding states 0 ,
noting 0 one state time-point , 0 = MAP(hM; i). Note R preserves
ordering that, j , R(i) later R(j ) 0 . Let W composition V R
relations V R.
show W interdigitation. first show state 0 appears
tuple W , W piecewise total. States must appear, trivially, appears
tuple V , R total. States 0 appear 2 appears tuple V , R
onto states 0 .
suffices show states , W (s; s0 ) W (t; t0 ) implies
s0 later t0 0 , W simultaneously consistent. conditions defining V 0
imply every number 2 V (s) less equal every j 2 V (t). order-preservation
property R, noted above, implies every state s0 2 V R(s) later state
t0 2 V R(t) 0 , desired. W interdigitation.
argue W witnesses 0 . Consider 2 2 0 W (s; t).
construction W , must 2 V 0 (s) ith state 0 . Since 0 = MAP(M),
follows set true propositions [i]. Since 2 V 0 (s), know [i] satisfies
s. follows t, s. 2

2 IPEL, model embeds model satisfies E satisfies E .
Proof: Consider models = hM; M0 = hM 0 ; 0 embeds M0 , let
= MAP(M) 0 = MAP(M0 ). Assume E 2 IPEL satisfied M0 , show
E also satisfied M.
know definition embedding 0 thus witnessing interdigitation W 0 Proposition 2. know one-to-one correspondence
numbers (I 0 ) states (0 ) denote state (0 ) corresponding 2 (i0 2 0 )
Lemma 3. E

si (ti ). correspondence allows us naturally interpret W mapping V subsets
0 subsets follows: I10 0 , V (I10 ) equals set 2 i0 2 I10 ,
si co-occurs ti W . use following properties V ,
0

0

1. I10 sub-interval 0 , V (I10 ) sub-interval .

2. I10 sub-interval 0 , hM; V (I10 )i embeds hM 0 ; I10 i.

3. I10 I20 sub-intervals 0 , r Allen relation, I10 rI20 iff V (I10 )rV (I20 ).
4. I10 I20 sub-intervals 0 , V (S PAN (I10 ; I20 )) = PAN (V (I10 ); V (I20 )).

5.

V (I 0 ) = .

sketch proofs properties. 1) Use induction length I10 ,
definition interdigitation. 2) Since V (I10 ) interval, MAP(hM; V (I10 )i) well defined.
MAP(hM; V (I10 )i) MAP(hM 0 ; I10 i) follows assumption embeds M0 . 3)
Appendix A, see Allen relations defined terms relation natural
431

fiF ERN , G IVAN , & ISKIND

number endpoints intervals. show V preserves (but <) singleton sets
(i.e., every member V (fi0 g) every member V (fj 0 g) i0 j 0 ) V commutes set union. follows V preserves Allen interval relations. 4) Use fact
V preserves sense argued, along fact PAN (I10 ; I20 ) depends
minimum maximum numbers I10 I20 . 5) Follows definition interdigitation
construction V .
use induction number operators connectives E prove that, M0
satisfies E , must M. base case E = prop, prop primitive proposition,
true. Since M0 satisfies E , know prop true 0 [x0 ] x0 2 0 . Since W witnesses
0 , know that, prop true 0 [x], prop true [x], x 2 V (x0 ).
Therefore, since V (I 0 ) = , prop true 0 [x], x 2 , hence M0 satisfies E .
inductive case, assume claim holds IPEL formulas fewer N operators connectiveslet E1 ; E2 two formulas. E = E1 _ E2 , claim trivially
holds. E = 3R E1 , R must subset set relations fs,f,d,=g. Notice E
written disjunction 3r E1 formulas, r single Allen relation R. Thus,
suffices handle case R single Allen relation. Suppose E = 3fsg E1 . Since M0
satisfies E , must sub-interval I10 0 I10 0 hM 0 ; I10 satisfies E1 . Let
I1 = V (I10 ), know properties V V (I 0 ) = , and, hence, I1 . Furthermore, know hM; I1 embeds hM 0 ; I10 i, and, thus, inductive hypothesis, hM; I1
satisfies E1 . Combining facts, get E satisfied M. Similar arguments hold
remaining three Allen relations. Finally, consider case E = E1 ^R E2 , R
set Allen relations. Again, suffices handle case R single Allen relation
r. Since M0 satisfies E = E1 ^r E2 , know sub-intervals I10 I20 0
PAN (I10 ; I20 ) = 0 , I10 r I20 , hM 0 ; I10 satisfies E1 , hM 0 ; I20 satisfies E2 . facts,
properties V , easy verify satisfies E . 2
Lemma 5. Given formula subsumes member set formulas,
also subsumes member 0 IG(). Dually, subsumed member ,
also subsumed member 0 IS(). case, length 0
bounded size .
Proof: prove result IG(). proof IS() follows similar lines. Let

=

f1 ; : : : ; ng, = s1; : : : ; sm, assume 1 n, . Proposition 2, i, witnessing interdigitation Wi . combine Wi

interdigitation , show corresponding member IG() subsumed
. construct interdigitation , first notice that, sj , Wi specifies set
states (possibly single state least one) co-occur sj . Furthermore, since
Wi interdigitation, easy show set states corresponds consecutive subsequence states let j;i timeline corresponding subsequence.
let j = fj;i j 1 ng, ffj interdigitation j . take union
ffj , 1 j m. show interdigitation . Since state appearing
must co-occur least one state sj least one Wi , least one tuple ffj ,
and, hence, tuple piecewise total.
Now, define restriction i;j components j , < j , relation given
taking set pairs formed shortening tuples omitting components except
432

fiL EARNING EMPORAL E VENTS

ith j th. Likewise define ffi;j
k k . show interdigitation, suffices
show i;j simultaneously consistent. Consider states si sj timelines
j , respectively, i;j (si ; sj ). Suppose ti occurs si i, tj 2 j ,
i;j (ti ; tj ) holds. suffices show sj later tj j . Since i;j (si ; sj ) i;j (ti ; tj ),
i;j
0
0
must ffi;j
k (si ; sj ) ffk (ti ; tj ), respectively, k k . know k k
0
si ti Wi simultaneously consistent. k = k , sj later tj j ,
ffk must simultaneously consistent, interdigitation. Otherwise, k < k 0 . sj
later tj j , desired, Wj simultaneously consistent. simultaneously
consistent, interdigitation .
Let 0 member IG() corresponding . show 0 . know
state s0 2 0 intersection states tuple ffj say s0 derives
ffj . Consider interdigitation 0 0 , 0 (sj ; s0 ), sj 2 s0 2 0 ,
s0 derives ffj . 0 piecewise total, every tuple 0 derives ffj , ffj
empty. 0 simultaneously consistent tuples 0 deriving later ffk must later
lexicographic ordering , given simultaneous consistency Wk interdigitations used
construct ffj . Finally, know sj subsumes (i.e., subset of) state tuple
ffj , Wk witnessing interdigitation k , and, hence, subsumes (is subset
of) intersection states. Therefore, sj 2 co-occurs s0 2 0 0
s0 sj . Thus, 0 witnessing interdigitation 0 , Proposition 2 0 .
size bound 0 follows, since, pointed main text, size member
IG() upper-bounded number states . 2
0

Lemma 8. Given timelines 1 = s1 ; : : : ; sm 2 = t1 ; : : : ; tn , witnessing
interdigitation 1 2 iff path subsumption graph SG(1 ; 2 ) v1;1
vm;n .
Proof: Subsumption
graph SG(1 ; 2 ) equal hV; E V = fvi;j j 1 m; 1 j ng

E = hvi;j ; vi ;j j si tj ; si tj ; i0 + 1; j j 0 j + 1 . Note
correspondence vertices state tupleswith vertex vi;j corresponding hsi ; tj i.
forward direction, assume W witnessing interdigitation 1 2 .
know that, states si tj co-occur W , si tj since W witnesses 1 2 .
vertices corresponding tuples W called co-occurrence vertices, satisfy
first condition belonging edge E (that si tj ). follows definition
interdigitation v1;1 vm;n co-occurrence vertices. Consider co-occurrence
vertex vi;j equal vm;n , lexicographically least co-occurrence vertex vi ;j vi;j
(ordering vertices
ordering
pair subscripts). show i, j , i0 , j 0 satisfy
ff
requirements vi;j ; vi ;j 2 E . not, either i0 > + 1 j 0 > j + 1. i0 > + 1,
co-occurrence vertex vi+1;j , contradicting W piecewise total. j 0 > j + 1,
since W piecewise total, must co-occurrence vertex vi ;j +1 : i00 <
i00 > i0 , contradicts simultaneous consistency W , i00 = i, contradicts
lexicographically least choice vi ;j . follows every co-occurrence vertex vm;n
edge another co-occurrence vertex closer Manhattan distance vm;n , thus
path v1;1 vm;n .
reverse direction assume path vertices SG(1 ; 2 ) v1;1 vm;n
given by, vi1 ;j1 ; vi2 ;j2 ; : : : ; vir ;js i1 = j1 = 1, ir = m; js = n. Let W set state
0

0

0

0

0

0

0

00

00

0

0

433

0

fiF ERN , G IVAN , & ISKIND

tuples corresponding vertices along path. W must simultaneously consistent
orderings directed edges non-decreasing orderings. W must
piecewise total edge cross one state transition either 1 2 ,
edge set definition. W interdigitation. Finally, definition edge set E ensures
tuple hsi ; tj W property si tj , W witnessing interdigitation
1 2 , showing 1 2 , desired. 2
Lemma 10. Given n, let conjunction timelines
n
[
i=1

f(PROPn; Truei; Falsei; PROPn); (PROPn; Falsei; Truei; PROPn)g:

following facts truth assignments Boolean variables p1 ; : : : ; pn :
1. truth assignment A, PROPn ; sA ; PROPn semantically equivalent member
IS( ).
2. 2 IS( ) truth assignment PROPn ; sA ; PROPn .
Proof: prove first part lemma, construct interdigitation
corresponding member IS( ) equivalent PROPn ; sA ; PROPn . Intuitively, construct
ensuring tuple consists states form Truek Falsek agree
truth assignmentthe union states tuple, taken IS( ) equal sA . Let
= fT0 ; T1 ; T2 ; T3 ; T4 g interdigitation exactly five state tuples Ti . assign
states timeline tuples follows:
1. k , 1 k




n A(pk ) true,

timeline s1 ; s2 ; s3 ; s4 = Q; ruek ; F alsek ; Q, assign state si tuple Ti ,
assign state s1 T0 well,
timeline s01 ; s02 ; s03 ; s04 = Q; F alsek ; ruek ; Q, assign state s0i tuple Ti 1 ,
state s04 tuple T4 well.

2. k , 1 k n A(pk ) false, assign states tuples item 1
interchanging roles ruek F alsek .

clear piecewise total simultaneously consistent state orderings
, interdigitation. union states T0 , T1 , T3 , T4 equal
PROPn , since PROPn included state tuples. Furthermore, see
union states T2 equal sA . Thus, member IS( ) corresponding equal
PROPn ; PROPn ; sA ; PROPn ; PROPn , semantically equivalent PROPn ; sA ; PROPn ,
desired.
prove second part lemma, let member IS( ). first argue
every state must contain either Truek Falsek 1 k n. k , since contains PROPn ; Truek ; Falsek ; PROPn , every member IS( ) must subsumed PROPn ; Truek ;
Falsek ; PROPn . So, subsumed PROPn ; Truek ; Falsek ; PROPn . every state PROPn ;
Truek ; Falsek ; PROPn contains either Truek Falsek , implying , desired.
434

fiL EARNING EMPORAL E VENTS

Next, claim 1 k n, either Truek Falsek i.e., either states
include Truek , states include Falsek (and possibly both). prove claim, assume,
sake contradiction, that, k , 6 Truek 6 Falsek . Combining assumption first claim, see must states s0 contains ruek
F alsek , s0 contains F alsek ruek , respectively. Consider interdigitation
corresponds member IS( ). know s0 equal union
states tuples 0 , respectively, . 0 must include one state timeline
s1 ; s2 ; s3 ; s4 = PROPn ; Truek ; Falsek ; PROPn s01 ; s02 ; s03 ; s04 = PROPn ; Falsek ; Truek ; PROPn .
Clearly, since include Falsek , includes states s1 s02 , likewise 0 includes
states s2 s01 . follows simultaneously consistent state orderings
s1 ; s2 ; s3 ; s4 s01 ; s02 ; s03 ; s04 , contradicting choice interdigitation. shows
either Truek Falsek .
Define truth assignment 1 k n, A(pk ) Truek .
Since,for k , Truek Falsek , follows state subsumed
sA . Furthermore, since begins ends PROPn , easy give interdigitation
PROPn ; sA ; PROPn witnesses PROPn ; sA ; PROPn . Thus,
PROPn ; sA ; PROPn . 2
Lemma 16. Let 1 2 given page 402, proof Theorem 17, let =
V
IG(f1 ; 2 g). 0 whose timelines subset omits square
timeline, < 0 .
Proof: Since timelines 0 subset timelines , know 0 . remains
show 0 6 . show constructing timeline covered 0 , .
Let = s1 ; s2 ; : : : ; s2n 1 square timeline included 0 . Recall
si single proposition proposition set P = fpi;j j 1 n; 1 j ng, that,
consecutive states si si+1 , si = pi;j , si+1 either pi+1;j pi;j +1 . Define new
timeline = s2 ; s3 ; : : : ; s2n 2 si = (P si ). show 6 (so 6 ),
that, 0 fg, 0 (so 0 ).
sake contradiction, assume must interdigitation W
witnessing . show induction that, 2, W (si ; sj ) implies j > i.
base case, = 2, know s2 6 s2 , since s2 6 s2 , W (s2 ; s2 ) false, since
W witnesses subsumption. inductive case, assume claim holds i0 < i,
W (si ; sj ). know si 6 si , thus 6= j . W piecewise total, must
W (si 1 ; sj ) j 0 , and, induction hypothesis, must j 0 > 1. Since W
simultaneously consistent sk sk state orderings, 1 < i, j 0 j .
follows j > desired. Given claim, see s2n 2 cannot co-occur W
state , contradicting fact W piecewise total. Thus 6 .
Let 0 = s01 ; : : : ; s0m timeline fg, construct interdigitation
witnesses 0 . Note assumed square, 0 need be. Let j smallest
index sj 6= s0j since s1 = s01 = p1;1 , 6= 0 , know j must exist,
range 2 j m. use index j guide construction interdigitation. Let W
interdigitation 0 , exactly following co-occurring states (i.e., state tuples):
0

0

1. 1 j

1, si+1 co-occurs s0i .
435

fiF ERN , G IVAN , & ISKIND

m, sj co-occurs s0i.
j + 1 2n 2, si co-occurs s0m .

2. j
3.

easy check W piecewise total simultaneously consistent state
orderings , interdigitation. show W witnesses 0
showing states subsumed states co-occur W . co-occurring
states si+1 s0i corresponding first item s0i = si implies s0i
contained si+1 , giving si+1 s0i . consider co-occurring states sj s0i
second item above. Since square, choose k l sj 1 = pk;l , sj either
pk+1;l pk;l+1. addition, since sj 1 = s0j 1 s0j either pk+1;l ; pk;l+1 pk+1;l+1
sj 6= s0j . cases, find state 0 s0j equal sj follows
noting proposition indices never decrease across timeline 0 16 . therefore
that, j , sj s0i . Finally, co-occurring states si s0m item three above,
si s0m , since s0m = pn;n, states . Thus, shown co-occurring
states W , state subsumed co-occurring state 0 . Therefore, W witnesses
0 , implies 0 . 2
Lemma 26. model hM; 2 2 AMA ,
[hM; i].

covers hM;

iff

F [ ] covers

Proof: Recall set models propositions set P = fp1 ; : : : ; pn g
assume AMA uses primitive propositions P (possibly negated). also
set propositions P = fp1 ; : : : ; pn g, assume formulas AMA use propositions
P [ P set models P [ P , i, exactly one pi pi
true time. Note F [ ] AMA [hM; i] M. prove lemma via
straightforward induction structure proving result literals, states,
timelines, finally AMA formulas.
prove result literals, consider two cases (the third case true trivial). First,
single proposition pi , 0 = F [pi ] = pi . Consider model hM; 2 let
hM 0 ; = [hM; i]. following relationships yield desired result.

covers hM;

iff
iff
iff

2 , [i] assigns pi true
2 , 0 [i] assigns pi true
0 = pi covers [hM; i]

(by definition satisfiability)
(by definition )
(by definition satisfiability)

second case negated proposition :3pi here, get 0 = pi . Let
hM; 2 hM 0 ; = [hM; i]. following relationships yield desired result.

covers hM;

iff
iff
iff

2 , [i] assigns pi false
2 , 0 [i] assigns pi true
0 = pi covers [hM; i]

(by definition satisfiability)
(by definition )
(by definition satisfiability)

proves lemma literals.
16. Note
pk+1;l+1 .

required square possible +1 equal
0

sj

436

sj

i.e., could equal

fiL EARNING EMPORAL E VENTS

prove result states, use induction number k literals state. base
case k = 1 (the state single literal) proven above. assume lemma
holds states k fewer literals let = l1 ^ ^ lk+1 hM; 2 M.
inductive assumption know = l1 ^ ^ lk covers hM; iff F [] covers [hM; i].
base case also know lk+1 covers hM; iff F [lk+1 ] covers [hM; i]. facts
definition satisfiability states, get covers hM; iff F [] ^ F [lk+1 ] covers
[hM; i]. Clearly F property F [] ^ F [lk+1 ] = F [ ], showing lemma holds
states.
prove result timelines, use induction number k states timeline.
base case k = 1 (the timeline single state) proven above. assume
lemma holds timelines k fewer states. Let = s1 ; : : : ; sk+1 hM; [t; t0 ]i 2
hM 0 ; [t; t0 ]i = [hM; [t; t0 ]i]. following relationships.

covers hM; [t; t0 ]i

iff
iff
iff
iff

exists t00 2 [t; t0 ], s1 covers hM; [t; t00 ]i
= s2 ; : : : ; sk+1 covers either hM; [t00 ; t0 ]i hM; [t00 + 1; t0 ]i
exists t00 2 [t; t0 ], F [s1 ] covers hM 0 ; [t; t00 ]i
F [] covers either hM 0 ; [t00 ; t0 ]i hM 0 ; [t00 + 1; t0 ]i
F [s1 ]; F [] covers hM 0 ; [t; t0 ]i
F [ ] covers hM 0 ; [t; t0 ]i

first iff follows definition satisfiability; second follows inductive
hypothesis, base case, fact [t; t0 ] [hM; i] = hM 0 ; i; third
follows definition satisfiability; fourth follows fact F [s1 ]; F [] =
F [ ].
Finally, prove result AMA formulas, induction number k timelines
formula. base case k = 1 (the formula single timeline) proven
above. assume lemma holds AMA formulas k fewer timelines
let = 1 ^ ^ k+1 hM; 2 M. inductive assumption, know
0 = 1 ^ ^ k covers hM; iff F [ 0 ] covers [hM; i]. base case, also
know k+1 covers hM; iff F [k+1 ] covers [hM; i]. facts definition
satisfiability, get covers hM; iff F [ 0 ] ^ F [k+1 ] covers [hM; i]. Clearly F
property F [ 0 ] ^ F [k+1 ] = F [ ], showing lemma holds AMA formulas.
completes proof. 2

Appendix C. Hand-coded Learned Definitions Used Experiments
give two sets hand-coded definitions, HD1 HD2 , used experimental
evaluation. also give set learned AMA event definitions seven event types.
learned definitions correspond output k -AMA learning algorithm, given available
training examples (30 examples per event type), k = 3 = BN. event definitions
written event logic, :3p denotes negation proposition p.

437

fiF ERN , G IVAN , & ISKIND

1

0

4

P ICK U P (x; y; z )

=

P UT OWN(x; y; z )

=

TACK (w; x; y; z )

=

U NSTACK (w; x; y; z )

=

OVE(w; x; y; z )
SSEMBLE(w; x; y; z )
ISASSEMBLE(w; x; y; z )

4

4

4

4
4
=
4
=
=

:3x = ^ :3z = x ^ :3z = y^
C
B UPPORTED(y ) ^ :3ATTACHED(x; z )^
B 8 2
3 9 C
C
B >
:3ATTACHED(x; y) ^ :3S UPPORTS(x; y)^
>
>
C
B >
>
7
>
C
B >
>
6
UPPORTS (z; )^
>
7
>
C
B >
>
6
>
7
>
C
B >
>
6
:
3
UPPORTED(x) ^ :3ATTACHED(y; z )^ 7 ; >
>
C
B >
>
6
>
>
C
B >
>
5
4
:3S UPPORTS(y; x) ^ :3S UPPORTS(y; z )^
>
>
C
B >
>
>
>
B >
>
:3S UPPORTS(x; z ) ^ :3S UPPORTS(z; x)
= C
C
B <
C
B
B > [2ATTACHED(x; ) _ ATTACHED(y; z )] ;
3 > C
>
C
B >
ATTACHED(x; ) ^ UPPORTS(x; )^
>
>
C
B >
>
>
6
7
>
C
B >
>
:3S UPPORTS(z; y)^
>
6
7
>
C
B >
>
>
6
7
>
C
B >
>
:
3

UPPORTED
(
x
)
^
:
3

TTACHED
(
y;
z
)
^
>
6
7
>
C
B >
>
>
>
>
4
5

@ >
:
3

UPPORTS
(
y;
x
)
^
:
3

UPPORTS
(
y;
z
)
^
>
>
>
>
;
:
:3S UPPORTS(x; z ) ^ :3S UPPORTS(z; x)
1
0
:3x = ^ :3z = x ^ :3z = y^
C
B UPPORTED(y ) ^ :3ATTACHED(x; z )^
B 8 2
3 9 C
C
B >

TTACHED
(
x; ) ^ UPPORTS (x; )^
>
>
C
B >
>
>
C
7
B >
>
6
:
3

UPPORTS
(
z;

)
^
>
>
C
7
B >
>
6
>
>
C
B >
>
6
7
:
3

UPPORTED
(
x
)
^
:
3

TTACHED
(
y;
z
)
^
;
>
>
C
B >
>
6
7
>
>
C
B >
>
4
5
:
3

UPPORTS
(
y;
x
)
^
:
3

UPPORTS
(
y;
z
)
^
>
>
C
B >
>
>
>
B >
>
:
3

UPPORTS
(
x;
z
)
^
:
3

UPPORTS
(
z;
x
)
= C
C
B <
C
B
B > [2ATTACHED(x; ) _ ATTACHED(y; z )] ;
3 > C
>
C
B >

TTACHED
(
x; ) ^ :3 UPPORTS(x; )^
:
3
>
>
> C
B >
7 >
>
C
B >
>
6 UPPORTS (z; )^
>
>
7 > C
B >
6
>
C
B >
>
6 :3S UPPORTED(x) ^ :3ATTACHED(y; z )^ 7 >
>
>
7 > C
B >
6
>
>

@ >
4 :3S UPPORTS(y; x) ^ :3S UPPORTS(y; z )^ 5 >
>
>
>
>
;
:
:3S UPPORTS(x; z ) ^ :3S UPPORTS(z; x)
3
2
:3z = w ^ :3z = x ^ :3z = y^
4 P UT OWN(w; x; ) ^ UPPORTS(z; )^ 5
:ATTACHED(z; y)


:3z = w ^ :3z = x ^ :3z = y^
P ICK U P (w; x; ) ^ UPPORTS(z; ) ^ :ATTACHED(z; )
:3y = z ^ [P ICK U P(w; x; y); P UT OWN(w; x; z )]
P UT OWN(w; y; z ) ^f g TACK (w; x; y; z )
U NSTACK(w; x; y; z ) ^f g P ICK U P (x; y; z )
<

<

Figure 12: HD1 event-logic definitions seven event types.

438

fiL EARNING EMPORAL E VENTS

0

1
:3x = ^ :3z = x ^ :3z = y^
B
C
(y) ^ :3ATTACHED (x; z )^
B UPPORTED
C
3
9 C
B 8 2
B >
C

TTACHED (x; ) ^ :3S UPPORTS (x; )^
:
3
>
>
B >
C
> 6
>
7
>
B >
C
> 6 UPPORTS (z; ) ^ C ONTACTS (z; )^
>
7
>
B >
C
>
>
7
6
>
B >
C
> 6 :3S UPPORTED (x) ^ :3ATTACHED (y; z )^ 7 ^f<;mg >
>
B >
C
>
>
7
6
>
B >
C
>
> 4 :3S UPPORTS (y; x) ^ :3S UPPORTS (y; z )^ 5
>
4
B >
C
>
>
>
P ICK U P (x; y; z ) = B >
= C
<
B
C

UPPORTS (x; z ) ^ :3S UPPORTS (z; x)
:
3
3
B
2
C
B >
C
>

TTACHED
(
x;

)
^

UPPORTS
(
x;

)
^
>
B >
C
>
> 6
>
7
B >
C
>
>
:
3

UPPORTS
(
z;

)
^
>
6
7
B >
C
>
> 6
>
7
B >
C
>
>
>
:
3

UPPORTED
(
x
)
^
:
3

TTACHED
(
y;
z
)
^
6
7
B >
C
> 6
>
>
7
B >
C
>
>
>
4
5
@ >

:
3

UPPORTS
(
y;
x
)
^
:
3

UPPORTS
(
y;
z
)
^
>
>
>
>
;
:
:3S UPPORTS(x; z) ^ :3S UPPORTS(z; x)
0
1
:3x = ^ :3z = x ^ :3z = y^
C
B
(y) ^ :3ATTACHED (x; z )^
C
B UPPORTED
3
9 C
B 8 2
C
B >

TTACHED (x; ) ^ UPPORTS (x; )^
>
>
C
B >
>
> 6
7
>
C
B >
>
>

UPPORTS
(
z;

)
^
:
3
7
6
>
C
B >
>
> 6
7
>
C
B >
>
>
:
3

UPPORTED
(
x
)
^
:
3

TTACHED
(
y;
z
)
^
^
7
6
>
f
<;

g
C
B >
>
>
7
> C
> 6
B >
>
5
4
>
:
3

UPPORTS
(
y;
x
)
^
:
3

UPPORTS
(
y;
z
)
^
4 B>
C
>
>
>
P UT (x; y; z ) = B >
= C
<
C
B
:
3

UPPORTS (x; z ) ^ :3S UPPORTS (z; x)
3
C
B
2
C
B >
>
:
3ATTACHED (x; y) ^ :3S UPPORTS(x; y)^
>
C
B >
>
>
>
6
7
C
B >
>
> 6 UPPORTS (z; ) ^ C ONTACTS (z; )^
>
7
C
B >
>
>
>
6
7
B >
C
>
> 6 :3S UPPORTED (x) ^ :3ATTACHED (y; z )^ 7
>
B >
C
>
>
>
6
7
B >
> C
>
>
4 :3S UPPORTS (y; x) ^ :3S UPPORTS (y; z )^ 5

@ >
>
>
>
>
;
:
:3S UPPORTS(x; z) ^ :3S UPPORTS(z; x)

Figure 13: Part HD2 event-logic definitions.

439

fiF ERN , G IVAN , & ISKIND

0

1

:3w = x ^ :3y = w ^ :3y = x^
B :3z = w ^ :3z = x ^ :3z = ^
C
B
C
B UPPORTED (x) ^ :3ATTACHED(w; )^
C
B 8 2
9 C
3
B >
C
ATTACHED(w; x) ^ UPPORTS (w; x)^
>
B >
>
C
> 6
>
B >
7
>
C
:
3
UPPORTS(y; x)^
>
B >
>
7
>
6
C
> 6
>
B >
7
>
C
UPPORTS(z; ) ^ C ONTACTS(z; )^
>
B >
7
>
6
>
C
> 6
>
B >
7
C
>
:
3
ATTACHED(z; )^
^
f
mg >
B >
7
6
C
>
>
> 6
>
7
B >
C
>
:
3
UPPORTED(w) ^ :3ATTACHED(x; )^ 7
>
B >
6
C
>
>
> 4
>
B >
C
>
5
:3S UPPORTS(x; w) ^ :3S UPPORTS(x; y)^
>
B >
>
>
= C
B <
C
B
C
2 :3S UPPORTS(w; ) ^ :3S UPPORTS(y; w)
3
B >
C
:3ATTACHED(w; x) ^ :3S UPPORTS(w; x)^
>
B >
C
>
>
B >
C
6
7
>
>
UPPORTS(y; x) ^ C ONTACTS (y; x)^
>
B >
C
6
7
>
>
>
B >
C
6
7
>
>
>
B >
C
6 UPPORTS(z; ) ^ C ONTACTS(z; )^
7
>
>
>
>
B >
C
6
7
>
>
B >
C
7
> 6 :3ATTACHED(z; )^
>
>
>
B >
C
6
7
>
>
B >
C
> 6 :3S UPPORTED(w) ^ :3ATTACHED(x; )^ 7
>
>
>
>
@ >

4
5
:3S UPPORTS(x; w) ^ :3S UPPORTS(x; y)^
>
>
>
>
:
;
:3S UPPORTS(w; y) ^ :3S UPPORTS(y; w)
1
0
:3w = x ^ :3y = w ^ :3y = x^
C
B :3z = w ^ :3z = x ^ :3z = ^
C
B
C
B UPPORTED(x) ^ :3ATTACHED(w; )^
9 C
B 8 2
3
C
B >
:3ATTACHED(w; x) ^ :3S UPPORTS(w; x)^
>
C
>
B >
>
C
>
6
B >
7
>
>
C
>
6 UPPORTS (y; x) ^ C ONTACTS (y; x)^
B >
7
>
>
>
C
>
6
B >
7
>
C
>
B >
7
> 6 UPPORTS (z; ) ^ C ONTACTS (z; )^
>
>
C
>
6
B >
7
C
>
6 :3ATTACHED(z; )^
B >
7 ^f mg >
>
>
>
C
>
6
B >
7
>
C
>
B >
> 6 :3S UPPORTED(w) ^ :3ATTACHED(x; )^ 7
>
>
C
>
B >
4
5
:3S UPPORTS(x; w) ^ :3S UPPORTS(x; y)^
>
C
>
B >
>
=
<
C
B
C
B
2 :3S UPPORTS(w; ) ^ :3S UPPORTS(y; w) 3
C
B >
ATTACHED(w; x) ^ UPPORTS(w; x)^
>
C
>
B >
>
>
6
C
7
>
B >
>
C
7
>
B >
> 6 :3S UPPORTS(y; x)^
>
>
6
C
7
>
B >
>
6 UPPORTS (z; ) ^ C ONTACTS (z; )^
C
7
>
B >
>
>
>
6
C
7
>
B >
>
C
7
>
B >
> 6 :3ATTACHED(z; )^
>
>
6
C
7
>
B >
>
C
>
B >
> 6 :3S UPPORTED(w) ^ :3ATTACHED(x; )^ 7
>
>
>
4

5
@ >
:3S UPPORTS(x; w) ^ :3S UPPORTS(x; y)^
>
>
>
>
;
:
:3S UPPORTS(w; y) ^ :3S UPPORTS(y; w)
:3y = z ^ [P ICK U P(w; x; y); P UT OWN(w; x; z )]
P UT OWN(w; y; z ) ^f g TACK (w; x; y; z )
U NSTACK (w; x; y; z ) ^f g P ICK U P (x; y; z )
<;

TACK(w; x; y; z )

4

=

<;

U NSTACK(w; x; y; z )

OVE(w; x; y; z )
SSEMBLE(w; x; y; z )
ISASSEMBLE(w; x; y; z )

4

=

4
4
=
4
=
=

<

<

Figure 14: Part II HD2 event-logic definitions.

440

fiL EARNING EMPORAL E VENTS

3 9
0 8 2
UPPORTED (y ) ^ UPPORTS (z; )^
>
>
>
>
>
B >
> 4 C ONTACTS (y; z ) ^ : UPPORTS(x; )^
5; >
>
>
B >
>
>
>
B >
>
: ATTACHED(x; y) ^ : ATTACHED(y; z )
=
B <
B
UPPORTED(y );
B > 2
3 >^
>
B >
UPPORTED (y ) ^ UPPORTS (x; )^
>
>
>
B >
>
>
B >
>
5
4
ATTACHED(x; ) ^ : UPPORTS(z; )^
>
>
>
B >
;
:
B
: C ONTACTS(y; z ) ^ : ATTACHED(y; z9)
B 8
B > UPPORTED(y );
>
B >

>
=
B <
UPPORTED(y ) ^ ATTACHED(x; )^
B
;
^
B >
ATTACHED(y; z )
>
B >
>
:
;
B
B 8 [S UPPORTED(y ) ^ ATTACHED(x; )] 9
B < [S UPPORTED(y ) ^ C ONTACTS (y; z )] ; =
B
B
B : [S UPPORTED(y ) ^ ATTACHED(y; z )] ; ; ^
B
B 8 [2S UPPORTED(y ) ^ ATTACHED(x; )]
3 9
B >
UPPORTED (y ) ^ UPPORTS (z; )^
>
>
B >
>
> 4 C ONTACTS (y; z ) ^ : UPPORTS(x; )^
B >
5; >
=
B <
B
:

TTACHED
(
x; ) ^ : ATTACHED(y; z )
^
B >
>
>
B >
[

UPPORTED
(

)
^

UPPORTS
(
z;

)]
;
>
>
>
B >
;
B : [S UPPORTED(y ) ^ ATTACHED(x; )]
9
B 8
B > [S UPPORTED(y ) ^ UPPORTS (z; )] ;
>
>
B >
>
>
> [S UPPORTED(y ) ^ ATTACHED(x; )] ;
B >
B < 2
3 =
B

UPPORTED
(
) ^ UPPORTS (x; )^
B >
>
5 >
@ >
>
> 4 ATTACHED(x; ) ^ : UPPORTS(z; )^
>
>
:
;

3

3

3

3

P ICK U P (x; y; z )

4

=

3

3

3

3

3

3

:3C ONTACTS(y; z ) ^ :3ATTACHED(y; z )

P UT OWN(x; y; z )

4

=

1
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C


3 9
0 8 2
UPPORTED(y ) ^ UPPORTS(x; ) ^ ATTACHED(x; )^
>
>
>
>
> 4 : UPPORTS(z; ) ^ : C ONTACTS(y; z )^
>
B >
5; >
>
B >
>
>
=
B <
: ATTACHED(y; z )
B
^
B > UPPORTED (y );
>
>
B >


>
>
>
B >
UPPORTED(y ) ^ UPPORTS (z; ) ^ C ONTACTS(z; )^
>
B >
>
>
;
B :
:

UPPORTS
(
x; ) ^ :

TTACHED
(
x; )
B 8
9

B <
B
UPPORTED (y ) ^ ATTACHED(x; ) ;
=
@
UPPORTED (y ) ^ ATTACHED(x; ) ^ ATTACHED(y; z ) ;
:
;

3
3

3

3

3

UPPORTED (y )

Figure 15: learned 3-AMA definitions P ICK U P (x; y; z ) P UT (x; y; z ).

441

1
C
C
C
C
C
C
C
C
C
C
C
C


fiF ERN , G IVAN , & ISKIND

0 8
>
>
B <
B
B >
B >
B :
B (
B
B
B
B
B (
B
B
B
B
B (
B
B
B
B
B (
B
B
B
B
B (
B
B
B
B
B 8
B <
B
B
B :
B
B (
B
B
B
B
B (
B
B
B
B
B 8
B
B <
B
B
B :
B 8
B
B <
B
B
B :
B
B (
B
B
B
B
B 8
B <
B
B
B :
B
B 8
B >
B >
B <
B
@ >
>
:

h

^

^

^

^

UPPORTED(y ) ATTACHED(w; x) UPPORTS(z; ) C ONTACTS(y; z )
UPPORTS(x; )
UPPORTS(y; x)
C ONTACTS(x; )
ATTACHED(x; )

:3

^ :3

^ :3

^ :3



;

9
>
>
=

1

C
C
>^ C
UPPORTED(y ) ^ UPPORTED(x) ^ UPPORTS(y; x) ^ C ONTACTS(x; ) ^ C ONTACTS(y; z )^
>
; C
C
:3S UPPORTS(x; y) ^ :3ATTACHED(w; x) ^ :3ATTACHED(x; y) ^ :3)ATTACHED(y; z)
C
C
[S UPPORTED(y) ^ ATTACHED(w; x)] ;
C
[S UPPORTED(y) ^ ATTACHED(x; y)] ;
^
C
C
[S UPPORTED(y) ^ UPPORTED(x) ^ UPPORTS(y; x) ^ C ONTACTS(x; y)]
)
C
C
[S UPPORTED(y) ^ ATTACHED(w; x)] ;
[S UPPORTED(y) ^ UPPORTS(x; y) ^ ATTACHED(w; x) ^ ATTACHED(x; y) ^ ATTACHED(y; z)] ; ^ C
C
C
[S UPPORTED(y) ^ UPPORTED(x)S UPPORTS(y; x)]
)
C
C
[S UPPORTED(y) ^ ATTACHED(w; x)] ;
C
[S UPPORTED(y) ^ UPPORTED(x) ^ UPPORTS(x; y) ^ UPPORTS(y; x) ^ ATTACHED(w; x)] ; ^
C
C
[S UPPORTED(y) ^ UPPORTED(x) ^ UPPORTS(y; x)]
)
C
C
[S UPPORTED(y) ^ ATTACHED(w; x) ^ UPPORTS(z; y) ^ C ONTACTS(y; z)] ;
C
[S UPPORTED(y) ^ ATTACHED(y; z)] ;
^
C
C
[S UPPORTED(y) ^ UPPORTED(x) ^ UPPORTS(y; x) ^ C ONTACTS(y; z)] )
C
C
[S UPPORTED(y) ^ ATTACHED(w; x) ^ UPPORTS(z; y) ^ C ONTACTS(y; z)] ;
C
[S UPPORTED(y) ^ ATTACHED(w; x) ^ ATTACHED(y; z)] ;
^
C
C
[hS UPPORTED(y) ^ UPPORTED(x) ^ UPPORTS(y; x)]
9
C
UPPORTED(y ) ^ ATTACHED(w; x) ^ UPPORTS(z; ) ^ C ONTACTS(y; z )^
C
=
;
C
:3S UPPORTS(x; y) ^ :3S UPPORTS(y; x) ^ :3C ONTACTS(x; y) ^ :3ATTACHED(x; y)
C
^
C
[S UPPORTED(y) ^ ATTACHED(w; x)] ;
;
C
[S UPPORTED(y) ^ UPPORTED(x) ^ UPPORTS(y; x)]
C
)
C
[S UPPORTED(y) ^ ATTACHED(w; x)] ;
C
[S UPPORTED(y) ^ ATTACHED(w; x) ^ UPPORTS(z; y) ^ C ONTACTS(y; z)] ; ^
C
C
[S UPPORTED(y) ^ UPPORTED(x)]
C
)
C
[S UPPORTED(y) ^ ATTACHED(w; x)] ;
C
[S UPPORTED(y) ^ ATTACHED(w; x) ^ UPPORTS(z; y) ^ UPPORTED(x)] ; ^
C
C
[S UPPORTED(y) ^ UPPORTED(x)]
C
9
C
[hS UPPORTED(y) ^ ATTACHED(w; x)] ;
=
C
UPPORTED(y ) ^ C ONTACTS(y; z ) ^ UPPORTS(z; ) ^ UPPORTED(x)^
C
;
^
C
:3S UPPORTS(x; y) ^ :3ATTACHED(x; y)
;
C
C
[S UPPORTED(y) ^ UPPORTED(x)]
9
C
UPPORTED(y );
C
h
=
C
UPPORTED(y ) ^ C ONTACTS(y; z ) ^ UPPORTS(z; ) ^ UPPORTED(x)^
^
;
C
:3S UPPORTS(x; y) ^ :3ATTACHED(x; y) ^ :3ATTACHED(y; z)
C
;
C
[S UPPORTED(y) ^ UPPORTED(x) ^ UPPORTS(y; x)] )
C
C
[S UPPORTED(y) ^ ATTACHED(w; x)] ;
C
[S UPPORTED(y) ^ C ONTACTS(y; z) ^ UPPORTED(x)] ; ^
C
C
[S UPPORTED(y) ^ UPPORTED(x) ^ UPPORTED(y)x]
9 C
[S UPPORTED(y) ^ ATTACHED(w; x)] ;
= C
C
[hS UPPORTED(y) ^ UPPORTED(x) ^ UPPORTS(y; x)] ;

^C
UPPORTED(y ) ^ UPPORTED(x) ^ UPPORTS(y; x) ^ C ONTACTS(x; ) ^ C ONTACTS(y; z )^
; C
C
:3S UPPORTS(x; y) ^ :3ATTACHED(w; x) ^ :3ATTACHED(x; y) ^ :3ATTACHED(y; z)
9 C

UPPORTED(y );
> C
h

>
= C
UPPORTED(y ) ^ UPPORTED(x) ^ UPPORTS(y; x) ^ UPPORTS(z; )^
C
;
C
C
ONTACTS(x; ) ^ C ONTACTS(y; z )
h
>
UPPORTED(y ) ^ UPPORTED(x) ^ UPPORTS(y; x) ^ C ONTACTS(x; ) ^ C ONTACTS(y; z )^
>
;

[S UPPORTED(y)] ;
h

:3S UPPORTS(x; y) ^ :3ATTACHED(w; x) ^ :3ATTACHED(x; y) ^ :3ATTACHED(y; z)

Figure 16: learned 3-AMA definition TACK (w; x; y; z ).

442

fiL EARNING EMPORAL E VENTS

0 8
>
>
B >
>
B >
>
B >
>
B <
B
B >
B >
>
B >
B >
>
>
B >
B :
B
B (
B
B
B
B
B (
B
B
B
B
B
B (
B
B
B
B
B (
B
B
B
B
B 8
B
B >
>
B >
>
B >
B <
B
B >
B >
>
B >
:
B >
B 8
B
B >
>
B >
>
B >
B <
B
B >
B >
>
B >
>
B :
B
B (
B
B
B
B
B 8
B
B >
<
B
B
B >
B :
B
B (
B
B
B
B
B (
B
B
B
B
B
B 8
B >
B <
B
@
>
:

"

#

9

UPPORTED(x) ^ UPPORTED(y ) ^ UPPORTS(y; x)^
>
>
>
;
C ONTACTS(x; ) ^ C ONTACTS(y; z ) ^ :3S UPPORTS(w; x)^
>
>
>
>
:3S UPPORTS(x; y) ^ :3ATTACHED(w; x) ^ :3ATTACHED(x; y)
>
=
[2S UPPORTED(x) ^ UPPORTED(y)] ;
3
^
UPPORTED(x) ^ UPPORTED(y ) ^ ATTACHED(w; x) ^ UPPORTS(z; )^
>
>
>
6 C ONTACTS(y; z ) ^ ATTACHED(w; x) ^ :3S UPPORTS(x; )^
7 >
>
4
5 >
>
:3S UPPORTS(y; x) ^ :3C ONTACTS(x; y)^
>
;
:3ATTACHED(x; y) ^ :3ATTACHED(y; z)
)
[S UPPORTED(x) ^ UPPORTED(y) ^ UPPORTS(y; x)] ;
[S UPPORTED(x) ^ UPPORTED(y) ^ ATTACHED(w; x) ^ ATTACHED(y; z)] ; ^
[S UPPORTED(x) ^ UPPORTED(y) ^ ATTACHED(w; x) ^ C ONTACTS(y; z)] )
[S UPPORTED(x) ^ UPPORTED(y) ^ UPPORTS(y; x) ^ C ONTACTS(y; z)] ;
[S UPPORTED(x) ^ UPPORTED(y) ^ ATTACHED(y; z)] ;
^
[S UPPORTED(x) ^ UPPORTED(y) ^ ATTACHED(w; x) ^ C ONTACTS(y; z)] )
[S UPPORTED(x) ^ UPPORTED(y) ^ UPPORTS(y; x) ^ C ONTACTS(x; y)] ;
[S UPPORTED(x) ^ UPPORTED(y) ^ UPPORTS(y; x) ^ ATTACHED(x; y)] ; ^
[S UPPORTED(x) ^ UPPORTED(y) ^ ATTACHED(w; x)] )
[S UPPORTED(x) ^ UPPORTED(y) ^ UPPORTS(y; x)] ;
[S UPPORTED(x) ^ UPPORTED(y) ^ C ONTACTS(y; z)] ; ^
[S UPPORTED(x) ^ UPPORTED(y) ^ ATTACHED(w; x)]
9
[S UPPORTED(x) ^ UPPORTED(y) ^ UPPORTS(y; x)] ;
>
>
>
>
[2S UPPORTED(x) ^ UPPORTED(y) ^ ATTACHED(w; x)] ;
3 >
=
UPPORTED(x) ^ UPPORTED(y ) ^ ATTACHED(w; x) ^ UPPORTS(z; )^
^
7 >
6 C ONTACTS(y; z ) ^ ATTACHED(w; x) ^ :3S UPPORTS(x; )^
5 >
4
>
>
:3S UPPORTS(y; x) ^ :3C ONTACTS(x; y)^
>
;
ATTACHED(x; ) ^ :3ATTACHED(y; z )
:
3
2
3 9
UPPORTED(x) ^ UPPORTED(y ) ^ UPPORTS(y; x)^
>
>
>
6 C ONTACTS(x; ) ^ C ONTACTS(y; z )^
7 >
>
4
5; =
:3S UPPORTS(w; x) ^ :3S UPPORTS(x; y)^
^
:3ATTACHED(w; x) ^ :3ATTACHED(x; y)
>
>
>
>
[S UPPORTED(x) ^ UPPORTED(y) ^ UPPORTS(y; x)] ;
>
;
[S UPPORTED(x) ^ UPPORTED(y) ^ ATTACHED(w; x)]
[S UPPORTED(x) ^ UPPORTED(y) ^ UPPORTS(y; x) ^ C ONTACTS(y; z)] ; )
[S UPPORTED(x) ^ UPPORTED(y) ^ UPPORTS(y; x) ^ ATTACHED(y; z)] ; ^
[S UPPORTED(x) ^ UPPORTED(y) ^ ATTACHED(w; x)]
9
[S UPPORTED(x) ^ UPPORTED(y) ^ UPPORTS(y; x)] ;

>
=
UPPORTED(x) ^ UPPORTED(y ) ^ UPPORTS(y; x) ^ ATTACHED(y; z )^
^
;
UPPORTS(x; ) ^ ATTACHED(w; x) ^ ATTACHED(x; )
>
;
[S UPPORTED(x) ^ UPPORTED(y) ^ ATTACHED(w; x)]
)
[S UPPORTED(x) ^ UPPORTED(y)] ;
[S UPPORTED(x) ^ UPPORTED(y) ^ UPPORTS(y; x) ^ ATTACHED(w; x)] ; ^
[S UPPORTED(x) ^ UPPORTED(y) ^ UPPORTS(w; x) ^ ATTACHED(w; x)] )
[S UPPORTED(x) ^ UPPORTED(y) ^ UPPORTS(y; x)] ;
[S UPPORTED(x) ^ UPPORTED(y) ^ UPPORTS(w; x) ^ ATTACHED(w; x)] ; ^
[S UPPORTED(x) ^ UPPORTED(y) ^ ATTACHED(w; x)]
9
[S UPPORTED(x) ^ UPPORTED(y) ^ UPPORTS(y; x)] ;

>
=
UPPORTED(x) ^ UPPORTED(y ) ^ C ONTACTS(y; z )^
;
:3S UPPORTS(x; y) ^ :3ATTACHED(x; y) ^ :3ATTACHED(y; z)
>
;
[S UPPORTED(x) ^ UPPORTED(y)]

Figure 17: learned 3-AMA definition U NSTACK (w; x; y; z ).

443

1
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C


fiF ERN , G IVAN , & ISKIND

0 8
>
>
>
B >
>
B >
>
B >
>
B >
B <
B
B >
B >
>
B >
>
B >
>
B >
>
B >
B :
B 8
B >
B <
B
B
B >
B :
B 8
B >
B <
B
B
B >
B :
B 8
B >
B <
B
B
B >
B :
B 8
B >
B <
B
B
B >
B :
B 8
B >
B <
B
B
B >
B :
B 8
B >
B <
B
@
>
:

2
6
4

UPPORTED (x) ^ UPPORTS (y; x) ^ C ONTACTS (y; x)^
:3S UPPORTS(w; x) ^ :3S UPPORTS(z; x) ^ :3C ONTACTS(x; z)^
:3ATTACHED(w; x) ^ :3ATTACHED (y; x) ^ :3ATTACHED (x; z)

3
7
5

UPPORTED (x);
UPPORTED (x) ^ UPPORTS (z; x) ^ C ONTACTS (x; z )^
6
:
4 3S UPPORTS (w; x) ^ :3S UPPORTS (y; x) ^ :3C ONTACTS (y; x)^
:3ATTACHED(w; x) ^ :3ATTACHED9(y; x) ^ :3ATTACHED (x; z)
[S UPPORTED (x) ^ UPPORTS (y; x)] ; >
=
[S UPPORTED (x) ^ ATTACHED (w; x)] ; > ^
;
UPPORTED (x)
9
>
UPPORTED (x);
=
[S UPPORTED (x) ^ ATTACHED (w; x) ^ ATTACHED (x; z )] ; > ^
;
UPPORTED (x)
9
>
[S UPPORTED (x)] ;
=
[S UPPORTED (x) ^ ATTACHED (x; z )] ; > ^
[S UPPORTED (x) ^ C ONTACTS (x; z )] ;
9
>
UPPORTED (x);
=
[S UPPORTED (x) ^ ATTACHED (w; x) ^ UPPORTS (w; x)] ; > ^
;
UPPORTED (x)
9
>
UPPORTED (x);
=
[S UPPORTED (x) ^ ATTACHED (w; x) ^ ATTACHED (y; x)] ; > ^
;
UPPORTED (x)
9
[S UPPORTED (x) ^ C ONTACTS (y; x)] ; >
=
[S UPPORTED (x) ^ ATTACHED (y; x)] ; >
;
UPPORTED (x)
2

Figure 18: learned 3-AMA definition OVE (w; x; y; z ).

444

3
7
5

;

9
>
>
>
>
>
>
>
>
>
>
=
>
>
>
>
>
>
>
>
>
>
;

1

^

C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C


fiL EARNING EMPORAL E VENTS

0 8
>
>
>
B >
>
>
B >
B >
>
>
B <
B
B
B >
B >
>
B >
>
B >
>
B >
>
B >
:
B
B 8
B >
B >
B >
>
B >
<
B
B
B >
B >
>
B >
>
B :
B 8
B
B >
B <
B
B >
B :
B 8
B
B >
B <
B
B >
B :
B 8
B
B >
B <
B
B >
B :
B 8
B
B >
B <
@
>
:

2

3

9

:3S UPPORTED (x) ^ :3S UPPORTS(z; y) ^ :3S UPPORTS(y; x)^ 7 >
>
>
6
>
:
4 3C ONTACTS (x; ) ^ :3C ONTACTS (z; )^
5; >
>
>
>
>
>
:3ATTACHED(w; x) ^ :3ATTACHED (z; y)
=

true
;
2
6
4
2
6
4

3

UPPORTED (x) ^ UPPORTED (y ) ^ UPPORTS (z; )^
7
UPPORTS (y; x) ^ C ONTACTS (x; )^
5
C ONTACTS (z; ) ^ :3ATTACHED (w; )
:3S UPPORTED (x) ^ :3S UPPORTS(z; y) ^ :3S UPPORTS(y; x)^
:3C ONTACTS(x; y) ^ :3C ONTACTS(z; y)^
:3ATTACHED(w; x) ^ :3ATTACHED (z; y)

ATTACHED (w; );
UPPORTED (y )

9
>
=

true;

3
7
5

;

>
>
>
>
>
>
>
>
>
>
;
9
>
>
>
>
>
=
>
>
>
>
>
;

[S UPPORTED (y) ^ :3ATTACHED (w; x) ^ :3ATTACHED (z; y)] ; > ^
;
UPPORTED (y )
9
>
true;
=
[S UPPORTED (y) ^ ATTACHED (z; y)] ; > ^
[S UPPORTED (y) ^ C ONTACTS (z; y)] ;
true;
[S UPPORTED (y) ^ UPPORTS (z; y)C ONTACTS (z; y) ^ ATTACHED (w; x)] ;
UPPORTED (y )
9
>
true;
=
[S UPPORTED (y) ^ ATTACHED (w; y)ATTACHED (z; y)] ; >
;
UPPORTED (y )
Figure 19: learned 3-AMA definition SSEMBLE (w; x; y; z ).

445

1

^

^

9
>
=
>
;

^

C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C


fiF ERN , G IVAN , & ISKIND

0 8
>
>
B >
>
B >
>
B >
>
B >
>
B <
B
B >
B >
B >
>
B >
>
B >
>
B >
>
B :
B 8
B >
B >
B <
B
B >
B >
B :
B 8
B >
B >
B <
B
B >
B >
B :
B 8
B >
B >
B <
B
B >
B >
B :
B 8
B >
B >
B <
B
B >
B >
B :
B 8
B <
B
B
B :
B
B 8
B <
B
@
:

3

2

9

UPPORTED (x) ^ UPPORTED(y ) ^ UPPORTS(y; x) ^ UPPORTS (z; )^
>
>
7 >
>
6 C ONTACTS (x; ) ^ C ONTACTS(z; ) ^ : UPPORTS(w; x)^
7; >
>
6
>
5 >
4 : UPPORTS(w; ) ^ : UPPORTS(x; ) ^ : ATTACHED(x; w)^
>
>
=
: ATTACHED(w; y) ^ : ATTACHED(x; y) ^ : ATTACHED(z; y)
^
UPPORTED(y );
>
>
2
3
>
>
UPPORTED (y ) ^ : UPPORTED(x) ^ : UPPORTS(w; x)^
>
>
>
>
4 : UPPORTS(z; ) ^ : UPPORTS(y; x) ^ : C ONTACTS(x; )^ 5 ;
>
>
;
: C ONTACTS(z; y) ^ : ATTACHED(x; w) ^ : ATTACHED9(z; y)
[ UPPORTED (x) ^ UPPORTED (y )] ;
>

>
=
UPPORTED(x) ^ UPPORTED (y ) ^ UPPORTS (w; x)^
^
;
UPPORTS(z; ) ^ C ONTACTS (z; ) ^ ATTACHED(x; w)
>
>
;
UPPORTED(y )
9


UPPORTED(x) ^ UPPORTED (y ) ^ UPPORTS (z; )^
>
>
;
=
UPPORTS(y; x) ^ C ONTACTS (x; ) ^ C ONTACTS(z; )
^
[ UPPORTED (x) ^ UPPORTED (y ) ^ UPPORTS (y; x) ^ ATTACHED (x; )] ; >
>
;
UPPORTED(y )
9
[ UPPORTED (x) ^ UPPORTED (y ) ^ UPPORTS (y; x) ^ C ONTACTS (z; )] ; >
>


=
UPPORTED(x) ^ UPPORTED (y ) ^ UPPORTS (x; )^
;
^
UPPORTS(y; z ) ^ ATTACHED(x; ) ^ ATTACHED(z; )
>
>
;
UPPORTED(y )
9
[ UPPORTED (x) ^ UPPORTED (y ) ^ UPPORTS (y; x)] ;
>
>

=
UPPORTED(x) ^ UPPORTED (y ) ^ UPPORTS (x; )^
;
^
UPPORTS(y; z ) ^ ATTACHED(x; ) ^ ATTACHED(z; ) ^ ATTACHED(x; w)
>
>
;
UPPORTED(y )
9
UPPORTED(y );
=
[ UPPORTED (y ) ^ ATTACHED (w; ) ^ ATTACHED (z; )] ;
^
;
UPPORTED(y )
9
UPPORTED(y );
=
[ UPPORTED (y ) ^ UPPORTS (w; ) ^ ATTACHED (w; )] ;
;
UPPORTED(y )

3
3

3
3

3
3

3

3
3

3

3

3
3

3
3

Figure 20: learned 3-AMA definition ISASSEMBLE (w; x; y; z ).

446

1
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C


fiL EARNING EMPORAL E VENTS

References
Agrawal, R., & Srikant, R. (1995). Mining sequential patterns. Proceedings Eleventh
International Conference Data Engineering, pp. 314.
Allen, J. F. (1983). Maintaining knowledge temporal intervals. Communications ACM,
26(11), 832843.
Angluin, D. (1987). Learning regular sets queries counterexamples. Information
Computation, 75, 87106.
Bacchus, F., & Kabanza, F. (2000). Using temporal logics express search control knowledge
planning. Artificial Intelligence, 16, 123191.
Bobick, A. F., & Ivanov, Y. A. (1998). Action recognition using probabilistic parsing. Proceedings IEEE Computer Society Conference Computer Vision Pattern Recognition,
pp. 196202, Santa Barbara, CA.
Borchardt, G. C. (1985). Event calculus. Proceedings Ninth International Joint Conference
Artificial Intelligence, pp. 524527, Los Angeles, CA.
Brand, M. (1997a). inverse Hollywood problem: video scripts storyboards via
causal analysis. Proceedings Fourteenth National Conference Artificial Intelligence, pp. 132137, Providence, RI.
Brand, M. (1997b). Physics-based visual understanding. Computer Vision Image Understanding, 65(2), 192205.
Brand, M., & Essa, I. (1995). Causal analysis visual gesture understanding. Proceedings
AAAI Fall Symposium Computational Models Integrating Language Vision.
Brand, M., Oliver, N., & Pentland, A. (1997). Coupled hidden Markov models complex action
recognition. Proceedings IEEE Computer Society Conference Computer Vision
Pattern Recognition.
Cohen, P. (2001). Fluent learning: Elucidating structure episodes. Proceedings
Fourth Symposium Intelligent Data Analysis.
Cohen, W. (1994). Grammatically biased learning: Learning logic programs using explicit antecedent description lanugage. Artificial Intelligence, 68, 303366.
Cohen, W., & Hirsh, H. (1994). Learning CLASSIC description logic: Theoretical experimental results. Proceedings Fourth International Conference Principles Knowledge
Representation Reasoning, pp. 121133.
De Raedt, L., & Dehaspe, L. (1997). Clausal discovery. Machine Learning, 26, 99146.
Dehaspe, L., & De Raedt, L. (1996). DLAB: declarative language bias formalism. Proceedings
Ninth International Syposium Methodologies Intelligent Systems, pp. 613622.
Fikes, R., & Nilsson, N. (1971). STRIPS: new approach application theorem proving
problem solving. Artificial Intelligence, 2(3/4).
Hoppner, F. (2001). Discovery temporal patternsLearning rules qualitative behaviour
time series. Proceedings Fifth European Conference Principles Practice
Knowledge Discovery Databases.
447

fiF ERN , G IVAN , & ISKIND

Kam, P., & Fu, A. (2000). Discovering temporal patterns interval-based events. Proceedings
Second International Conference Data Warehousing Knowledge Discovery.
Klingspor, V., Morik, K., & Rieger, A. D. (1996). Learning concepts sensor data mobile
robot. Artificial Intelligence, 23(2/3), 305332.
Lang, K., Pearlmutter, B., & Price, R. (1998). Results Abbadingo one DFA learning competition new evidence-driven state merging algorithm. Proceedings Fourth
International Colloquium Grammatical Inference.
Lavrac, N., Dzeroski, S., & Grobelnik, M. (1991). Learning nonrecursive definitions relations
LINUS. Proceedings Fifth European Working Session Learning, pp. 265
288.
Mann, R., & Jepson, A. D. (1998). Toward computational perception action. Proceedings
IEEE Computer Society Conference Computer Vision Pattern Recognition, pp.
794799, Santa Barbara, CA.
Mannila, H., Toivonen, H., & Verkamo, A. I. (1995). Discovery frequent episodes sequences.
Proceedings First International Conference Knowledge Discovery Data Mining.
Mitchell, T. (1982). Generalization search. Artificial Intelligence, 18(2), 51742.
Morales, E. (1997). Pal: pattern-based first-order inductive system. Machine Learning, 26, 227
252.
Muggleton, S. (1995). Inverting entailment Progol. Machine Intelligence, 14, 133188.
Muggleton, S., & Feng, C. (1992). Efficient induction logic programs. Muggleton, S. (Ed.),
Inductive Logic Programming, pp. 281298. Academic Press.
Muggleton, S., & De Raedt, L. (1994). Inductive logic programming: Theory methods. Journal
Logic Programming, 19/20, 629679.
Pinhanez, C., & Bobick, A. (1995). Scripts machine understanding image sequences.
Proceedings AAAI Fall Symposium Series Computational Models Integrating
Language Vision.
Plotkin, G. D. (1971). Automatic Methods Inductive Inference. Ph.D. thesis, Edinburgh University.
Regier, T. P. (1992). Acquisition Lexical Semantics Spatial Terms: Connectionist Model
Perceptual Categorization. Ph.D. thesis, University California Berkeley.
Roth, D., & Yih, W. (2001). Relational learning via propositional algorithms: information extraction case study. Proeedings Seventeenth International Joint Conference Artificial
Intelligence.
Shoham, Y. (1987). Temporal logics AI: Semantical ontological considerations. Artificial
Intelligence, 33(1), 89104.
Siskind, J. M. (2000). Visual event classification via force dynamics. Proceedings Seventeenth National Conference Artificial Intelligence, pp. 149155, Austin, TX.
Siskind, J. M. (2001). Grounding lexical semantics verbs visual perception using force
dynamics event logic. Journal Artificial Intelligence Research, 15, 3190.
448

fiL EARNING EMPORAL E VENTS

Siskind, J. M., & Morris, Q. (1996). maximum-likelihood approach visual event classification. Proceedings Fourth European Conference Computer Vision, pp. 347360,
Cambridge, UK. Springer-Verlag.
Talmy, L. (1988). Force dynamics language cognition. Cognitive Science, 12, 49100.
Yamoto, J., Ohya, J., & Ishii, K. (1992). Recognizing human action time-sequential images using
hidden Markov model. Proceedings IEEE Conference Computer Vision
Pattern Recognition, pp. 379385.

449

fiJournal Artificial Intelligence Research 17 (2002) 1-33

Submitted 8/01; published 7/02

Critical Assessment
Benchmark Comparison Planning
Adele E. Howe
Eric Dahlman

Computer Science Department
Colorado State University, Fort Collins, CO 80523

howe@cs.colostate.edu
dahlman@cs.colostate.edu

Abstract
Recent trends planning research led empirical comparison becoming commonplace. field started settle methodology comparisons,
obvious practical reasons requires running subset planners subset problems.
paper, characterize methodology examine eight implicit assumptions
problems, planners metrics used many comparisons. problem assumptions are: PR1) performance general purpose planner
penalized/biased executed sampling problems domains, PR2) minor syntactic
differences representation affect performance, PR3) problems solvable STRIPS capable planners unless require ADL. planner assumptions are:
PL1) latest version planner best one use, PL2) default parameter settings
approximate good performance, PL3) time cut-offs unduly bias outcome.
metrics assumptions are: M1) performance degrades similarly planner run
degraded runtime environments (e.g., machine platform) M2) number plan
steps distinguishes performance. find assumptions supported
empirically; particular, planners affected differently assumptions.
conclude call community devote research resources improving state
practice especially enhancing available benchmark problems.

1. Introduction
recent years, comparative evaluation become increasingly common demonstrating
capabilities new planners. Planners directly compared
problems taken set domains. result, recent advances planning
translated dramatic increases size problems solved (Weld,
1999), empirical comparison highlighted improvements.
Comparative evaluation planning significantly uenced expedited
Artificial Intelligence Planning Scheduling (AIPS) conference competitions.
competitions dual effect highlighting progress field providing
relatively unbiased comparison state-of-the-art planners. individual researchers
compare planners others, include fewer planners fewer test problems
time constraints.
support first competition 1998 (McDermott, 2000), Drew McDermott defined,
contributions organizing committee, shared problem/domain definition
language, PDDL (McDermott et al., 1998) (Planning Domain Definition Language). Using

c 2002 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiHowe & Dahlman

common language means planners' performance directly compared, without
entailing hand translation factoring different representational capabilities.
second benefit, lack translation (or least human accomplished translation) meant performance could compared large number problems
domains1. fact, five competition planners given large number problems
(170 problems ADL track 165 STRIPS track) within seven domains,
including one domain planner developers never seen prior competition.
first competition generated large collection benchmarks: seven domains used
competition plus 21 considered use. 28 domains available
ftp://ftp.cs.yale.edu/pub/mcdermott/domains/. second competition added three
novel domains set.
third major benefit competitions appear motivated researchers develop systems others use. number entrants went five
first competition 16 second. Additionally, 1998 competitors six
sixteen 2000 competitors made code available web sites. Thus, others
perform comparisons.
paper, describe current practice comparative evaluation evolved
since AIPS competitions critically examine underlying assumptions
practice. summarize existing evidence assumptions describe
experimental tests others previously considered. assumptions
organized three groups concerning critical decisions experiment design:
problems tested, planners included performance metrics collected.
Comparisons (as part competitions specific researchers) proven enormously useful motivating progress field. goal understand assumptions
readers know far comparative results generalized. contrast
competitions, community cannot legislate fairness individual researcher's comparative evaluations, readers may able identify cases results viewed
either skeptically confidence. Thus, conclude paper observations
call considerably research new problems, metrics methodologies
support planner evaluation.
Also contrast competitions, goal declare winner. goal
also critique individual studies. Consequently, draw attention away
possible interpretation, whenever possible, report results using letter designators
assigned randomly planners.

2. Planning Competitions Direct Comparisons

Recently, AIPS competitions spurred considerable interest comparative evaluation. roots comparative planner evaluation go back considerably further, however.
Although researchers able run side-by-side comparisons planners
1. solve particular planning problem (i.e., construct sequence actions transform initial state
goal state), planners require domain theory problem description. domain theory represents
abstract actions executed environment; typically, domain descriptions include
variables instantiated specific objects values. Multiple problems defined
domain; problem descriptions require initial state description, goal state association
domain.

2

fiA Critical Assessment Benchmark Comparison Planning

others, able demonstrate performance planner well-known problems, could viewed de facto benchmarks. Sussman's anomaly (Sussman, 1973)
Blocksworld premier planning benchmark problem domain many years;
every planner needed \cut teeth" it.
researchers tired Blocksworld, many called additional benchmark problems
environments. Mark Drummond, Leslie Kaelbling Stanley Rosenschein organized
workshop benchmarks metrics (Drummond, Kaelbling, & Rosenschein, 1990).
Testbed environments, Martha Pollack's TileWorld (Pollack & Ringuette, 1990)
Steve Hanks's TruckWorld (Hanks, Nguyen, & Thomas, 1993), used comparing
algorithms within planners. 1992, UCPOP (Penberthy & Weld, 1992) distributed
large set problems (117 problems 21 domains) demonstration purposes.
1995, Barry Fox Mark Ringer set planning scheduling benchmarks web page
(http://www.newosoft.com/~benchmrx/) collect problem definitions, emphasis
manufacturing applications. Recently, PLANET (a coordinating organization European planning scheduling researchers) proposed planning benchmark collection
initiative (http://planet.dfki.de).
Clearly, benchmark problems become well-established means demonstrating
planner performance. However, practice known benefits pitfalls; Hanks, Pollack
Cohen (1994) discuss detail context agent architecture design.
benefits include providing metrics comparison supporting experimental control.
pitfalls include lack generality results potential benchmarks
unduly uence next generation solutions. words, researchers construct
solutions excel benchmarks, regardless whether benchmarks accurately
represent desired real applications.
obtain benefits listed benchmarks, problems often idealized
simplified versions real problems. Cohen (1991) points , research papers
AI, least AAAI conference, exploit benchmark problems; yet relate
benchmarks target tasks. may significant problem; example, study
owshop scheduling2 benchmarks, found performance standard benchmark set generalize performance problems realistic structure (Watson,
Barbulescu, Howe, & Whitley, 1999). study Blocksworld problems found
best known Blocksworld benchmark problems atypical require short
plans solution optimal solutions easy find (Slaney & Thiebaux, 2001).
spite diculties, benchmark problems AIPS competitions considerably uenced comparative planner evaluations. example, AIPS 2000 conference proceedings (Chien, Kambhampati, & Knoblock, 2000), papers improvements classical planning (12 44 papers conference) relied heavily
comparative evaluation using benchmark problems; papers concerned scheduling,
specific applications, theoretical analyses special extensions standard paradigm
(e.g., POMDP, sensing). 12 classical papers, six used problems AIPS98
competition benchmark set, six used problems Kautz Selman's distribution
problems blackbox (Kautz, 2002) three added problems
well. paper showed results subset problems benchmark distributions
2. Scheduling area related planning actions already known, sequence still
needs determined. Flowshop scheduling type manufacturing scheduling problem.

3

fiHowe & Dahlman

(e.g., Drew McDermott's first competition) logistics, blocksworld, rocket
gripper domains popular (used 11, 7, 5 5 papers, respectively). availability planners competition also exploited; eight papers compared
systems AIPS98 planners: blackbox, STAN, IPP HSP (in 5, 3, 3 1
papers, respectively).

3. Assumptions Direct Comparison
canonical planner evaluation experiment follows procedure Table 1. procedure
designed compare performance new planner previous state art
highlight superior performance set cases new planner. exact form
experiment depends purpose, e.g., showing superiority class problem
highlighting effect design decision.
1. Select and/or construct subset planner domains
2. Construct problem set by:
running large set benchmark problems
selecting problems desirable features
varying facet problem increase diculty (e.g., number blocks)
3. Select planners are:
representative state art problems
similar distinct new planner, depending point comparison advance new planner
available able parse problems
4. Run problems planners using default parameters setting upper limit
time allowed
5. Record problems solved, many plan steps/actions solution
much CPU time required either solve problem, fail time
Table 1: Canonical comparative planner evaluation experiment.
protocol depends three selections: problems, planners evaluation metrics.
simply practical even desirable run available planners available
problems. Thus, one needs make informed decisions select. purpose
paper examine assumptions underlying decisions help make
informed. Every planner comparison adopt every one assumptions,
assumptions ones commonly found planner comparisons. example,
comparisons designed specific purpose (e.g., show scale-up certain problems
suitability planner logistics problems) carefully select particular types
problems benchmark sets.
4

fiA Critical Assessment Benchmark Comparison Planning

Problems Many planning systems developed solve particular type planning
problem explore specific type algorithmic variation. Consequently, one would expect
perform better problems developed. Even
designed specific purpose, test set used development may
subtly biased development. community knows planner performance depends
problem features, general, how, why. Researchers tend design
planners general purpose. Consequently, comparisons assume
performance general-purpose planner penalized/biased
executed sampling problems domains (problem assumption 1).

community also knows problem representation uences planner performance.
example, benchmark problem sets include many versions Blocksworld problems, designed different planner developers. versions vary problem representation,
minor apparently syntactic changes (e.g., clauses ordered within operators,
initial conditions goals, whether information extraneous) changes ecting addition domain knowledge (e.g., constraints included whether
variables typed). Consequently, comparisons assume
syntactic representational modifications either matter affect planner equally (problem assumption 2).

PDDL includes field, :requirements, capabilities required planner solve
problem. PDDL1.0 defined 21 values :requirements field; base/default requirement :strips, meaning STRIPS derived add delete sets action effects. :adl
(from Pednault's Action Description Language) requires variable typing, disjunctive preconditions, equality built-in predicate, quantified preconditions conditional effects
addition :strips capability. Yet, many planners either ignore :requirements
field reject problem specifies :adl (ignoring many requirements
could also cause trouble). Thus, comparisons assume
problems benchmark set solvable STRIPS planner unless
require :adl (problem assumption 3).

Planners wonderful trend making planners publicly available led dilemma
determining use configure them. problem compounded
longevity planner projects; projects produced multiple versions.
Consequently, comparisons tend assume
latest version planner best (planner assumption 1).

planners may also include parameters. example, blackbox planner allows
user define strategy applying different solution methods. Researchers expect
parameters affect performance. Consequently, comparisons assume
default parameter settings approximate good performance (planner assumption
2).
5

fiHowe & Dahlman

Experiments invariably use time cut-offs concluding planning yet found
solution declared failure. Many planners would need exhaustively search large space
declare failure. practical reasons, time threshold set determine
halt planner, failure declared time-out reached. Thus, comparisons
assume
one picks suciently high time-out threshold, highly unlikely
solution would found slightly time granted (planner
assumption 3).

Metrics Ideally, performance would measured based well planner

job (i.e., constructing `best' possible plan solve problem) eciently
so. planner shown solve possible problems, basic
metric performance number percentage problems actually solved within
allowed time. metric commonly reported competitions. However, research
papers tend report directly typically test relatively small number
problems.
Eciency clearly function memory effort. Memory size limited
hardware. Effort measured CPU time, preferably always platform
language. problems CPU time well known: programmer skill
varies; research code designed fast prototyping fast execution; numbers
literature cannot compared newer numbers due processor speed improvements.
However, CPU times regenerated experimenter's environment one assumes

performance degrades similarly reductions capabilities runtime
environment (e.g., CPU speed, memory size) (metric assumption 1).

words, experimenter user system expect code
optimized particular compiler/operating system/hardware configuration,
perform similarly moved another compatible environment.
commonly reported comparison metric computation time. second
number steps actions (for planners allow parallel execution) plan. Although
planning seeks solutions achieving goals, goals defined terms states
world, lend well general measures quality. fact, quality likely
problem dependent (e.g., resource cost, amount time execute, robustness),
number plan steps favored. Comparisons assume
number steps resulting plan varies planner solutions approximates quality (metric assumption 2).

comparison, competitions especially, unenviable task determining
trade-off combine three metrics (number solved, time, number steps). Thus,
number steps matter, comparison could simplified.
converted assumption testable question. either summarized
literature question ran experiment test it.
6

fiA Critical Assessment Benchmark Comparison Planning

3.1 Experimental Setup
key issues examined previously, directly indirectly. those,
simply summarize results subsections follow. However, open
questions. those, ran seven well known planners large set 2057 benchmark
problems. planners accept PDDL representation, although built-in
translators PDDL internal representation others rely translators
added. several versions planner available, included (for total
13 planners). basic problem set comprises UCPOP benchmarks, AIPS98
2000 competition test sets additional problem set developed specific application.
exception permuted problems (see section Problem Assumption
2 specifics), problems run 440 MHz Ultrasparc 10s 256 Megabytes
memory running SunOS 2.8. Whenever possible, versions compiled developers
used; source code available, compiled systems according
developers' instructions. planners written Common Lisp run Allegro
Common Lisp version 5.0.1. planners compiled GCC (EGCS version
2.91.66). planner given 30 minute limit wall clock time3 find solution;
however, times reported run times returned operating system.
3.1.1 Planners

planners called primitive-action planners (Wilkins & desJardins,
2001), planners require relatively limited domain knowledge construct plans
simple action descriptions. AIPS98 competition required planners accept
PDDL, majority planners used study competition entrants later
versions thereof 4 . common language facilitated comparison planners without address effects translation step. two exceptions UCPOP
Prodigy; however, representations similar PDDL translated automatically. planners represent five different approaches planning: plan graph analysis,
planning satisfiability, planning heuristic search, state-space planning learning
partial order planning. possible, used multiple versions planner,
necessarily recent. conducted study period time (almost 1.5 years), froze set early on; comparing performance declare
winner think lack recent versions undermined results
testing assumptions.

IPP (Koehler, Nebel, Hoffmann, & Dimopoulos, 1997) extends Graphplan (Blum &

Furst, 1997) algorithm accept richer plan description language. early versions,
language subset ADL extends STRIPS formalism Graphplan
allow conditional universally quantified effects operators. version 4.0,
negation handled via introduction new predicates negated preconditions
3. used actual time lightly loaded machines occasionally system would thrash due
inadequate memory resulting little progress considerable time.
4. used BUS system manager running planners (Howe, Dahlman, Hansen, Scheetz, &
von Mayrhauser, 1999), implemented AIPS98 competition planners. facilitated
running many different planners, somewhat bias included.

7

fiHowe & Dahlman

corresponding mutual exclusion rules; subsequent versions handle directly (Koehler,
1999). used AIPS98 version IPP well later 4.0 version.
SGP (Sensory Graph Plan) (Weld, Anderson, & Smith, 1998) also extends Graphplan
richer domain description language, primarily focusing uncertainty sensing.
IPP, transformation performed using expansion techniques remove
quantification. SGP also directly supports negated preconditions conditional effects.
SGP tends slower (it implemented Common Lisp instead C)
Graphplan based planners. used SGP version 1.0b.
STAN (STate ANalysis) (Fox & Long, 1999) extends Graphplan algorithm part
adding preprocessor (called TIM) infer type information problem domain.
information used within planning algorithm reduce size search
space Graphplan algorithm would search. STAN also incorporated optimized data
structures (bit vectors planning graph) help avoid many redundant calculations performed Graphplan. Additionally, STAN maintains wave front graph
construction track remaining goals limit graph construction. Subsequent versions
incorporated analyses (e.g., symmetry exploitation) additional simpler planning engine. Four versions STAN tested: AIPS98 competition version, version
3.0, version 3.0s development snapshot version 4.0.
blackbox (Kautz & Selman, 1998) converts planning problems Boolean satisfiability
problems, solved using variety different techniques. user indicates
techniques tried order. constructing satisfiability problem,
blackbox uses planning graph constructed Graphplan. blackbox, used
version 2.5 version 3.6b.
HSP (Heuristic Search Planner) (Bonet & Geffner, 1999) based heuristic search.
planner uses variation hill-climbing random restarts solve planning problems.
heuristic based using Graphplan algorithm solve relaxed form
planning problem. study, used version 1.1, algorithmic refinement
version entered AIPS98 competition, version 2.0.
Prodigy 5 (The Prodigy Research Group, 1992) combines state-space planning backward chaining goal state. plan construction consists head-plan
totally ordered actions starting initial state tail-plan partially ordered
actions related goal state. Although ocially entered competition, informal results presented AIPS98 competition suggested Prodigy performed well
comparison entrants. used Prodigy version 4.0.
UCPOP (Barrett, Golden, Penberthy, & Weld, 1993) Partial Order Causal Link
planner. decision include UCPOP based several factors. First,
expand quantifiers negated preconditions; domains, expansion
grounding operators great make problem insolvable. Second, UCPOP
based significantly different algorithm interest recently resurfaced.
used UCPOP version 4.1.
5. thank Eugene Fink code translates PDDL Prodigy.

8

fiA Critical Assessment Benchmark Comparison Planning

Source
# Domains # Problems
Benchmarks
50
293
AIPS 1998
6
202
AIPS 2000
5
892
Developers
1
13
Application
3
72
Table 2: Summary problems testing set: source problems, number
domains problems within domains.
3.1.2 Test Problems

Following standard practice, experiments require planners solve commonly available
benchmark problems AIPS competition problems. addition, test assumptions uence domains (assumption PR1) representations problems
(assumption PR2), also include permuted benchmark problems application problems. section describes set problems domains study,
focusing source composition.
problems require STRIPS capabilities (i.e., add delete lists). chose
least common denominator several reasons. First, capable planners still handle
STRIPS requirements; thus, maximized number planners could included
experiment. Also, surprisingly, problems type available. Second,
examining assumptions evaluation, including effect required capabilities
performance. propose duplicate effort competitions singling
planners distinction, rather, purpose determine factors differentially
affect planners.
bulk problems came AIPS98 AIPS 2000 problem sets
set problems distributed PDDL specification. remaining problems
solicited several sources. source counts problems domains
summarized Table 2.
Benchmark Problems preponderance problems planning test sets \toy
problems": well-known synthetic problems designed test attribute planners.
Blocksworld domain long included evaluation well known,
subgoal interactions supports constructing increasingly complex problems
(e.g., towers blocks). benchmark problems simplified versions realistic
planning problems, e.g., tire, refrigerator repair logistics domains. used
set included UCPOP planner. problems contributed large number
people include multiple encodings problems/domains, especially Blocksworld.
AIPS Competitions: 1998 2000 first AIPS competition, Drew McDermott solicited problems competitors well constructing own,
mystery domain, semantically useless names objects operators.
Problems generated domain automatically. competition included 155
problems six domains: robot movement grid, gripper balls
9

fiHowe & Dahlman

moved rooms robot two grippers, logistics transporting packages, organizing snacks movie watching, two mystery domains, disguised logistics
problems.
format 1998 competition required entrants execute 140 problems
first round. problems, 52 could solved planner. round two,
planners executed 15 new problems three domains, one included
first round.
2000 competition attracted 15 competitors three tracks: STRIPS, ADL
hand-tailored track. required performance problems five domains: logistics,
Blocksworld, parts machining, Freecell (a card game), Miconic-10 elevator control.
domains determined organizing committee, Fahiem Bacchus
chair, represented somewhat broader range. chose problems Untyped
STRIPS track set.
scientific standpoint, one interesting conclusions competitions observed trade-offs performance. Planners appeared excel different
problems, either solving set finding solution faster. 1998, IPP solved
problems found shorter plans round two; STAN solved problems fastest;
HSP solved problems round one; blackbox solved problems fastest
round one. 2000, awards given two groups distinguished planners across
different categories planners (STRIPS, ADL hand tailored), according
judges, \it impossible say one planner best"(Bacchus, 2000);
TalPlanner FF highest distinguished planner group. graphs performance show differences computation time relative planners problem
scale-up. However, planner failed solve problems, makes trends
harder interpret (the computation time graphs gaps).
purpose competitions showcase planner technology
succeeded admirably. planners solved much harder problems could
accomplished years past. trend planners handling increasingly dicult
problems, competition test sets may become historical interest tracking field's
progress.
Problems Solicited Planner Developers also asked planner developers
problems used development. One developer, Maria Fox, sent us domain
(Sodor, logistics application) set problems used. would
included domains problems received others.
Applications Miconic elevator domain AIPS2000 competition
derived actual planning application. domain problems extremely
simplified (e.g., removing arithmetic).
add another realistic problem comparison, included one planning application set test domains: generating cases test software interface.
similarities software interface test cases plans, developed system,
several years ago, automatically generating interface test cases using AI planner.
system designed generate test cases user interface Storage Technology's robot tape library (Howe, von Mayrhauser, & Mraz, 1997). interface (i.e.,
commands interface) coded domain theory. example, mount com10

fiA Critical Assessment Benchmark Comparison Planning

mand/action's description required drive empty effect changing
position tape mounted changing status tape drive. Problems
described initial states tape library (e.g., tapes resident,
status devices software controller) goal states human operator might
wish achieve.
time, found simplest problems could generated using
planners available. included application part knew would
challenge. part test set, include three domain theories (different ways
coding application involving 8-11 operators) twenty-four problems domain.
included 24 wanted include enough problems see effect,
many overly bias results. problems relatively simple, requiring
movement one tape coupled status changes,
still dicult could solved original system.

3.2 Problem Assumptions
General-purpose planners exhibit differential capabilities domains sometimes even
problems within domain. Thus, selection problem set would seem critical
evaluation. example, many problems benchmark sets variants logistics
problems; thus, general-purpose planner actually tailored logistics may appear
better overall current benchmarks. section, empirically examine
possible problem set factors may uence performance results.

Problem Assumption 1: Extent Performance General Purpose
Planners Biased Toward Particular Problems/Domains? Although planners
developed general purpose, competitions previous studies shown
planners excel different domains/problems. Unfortunately, community yet
good understanding planner well particular domain. studied
impact problem selection performance two ways.
First, assessed whether performance might positively biased toward problems
tested development. developer6 asked indicate domains used
development. compared planner's performance development
problems (i.e., development set) problems remaining complete test set
(rest). ran 2x2 2 tests comparing number problems solved versus failed
development test sets. included number solved failed analysis
timed-out problems made difference results7.
results analysis summarized Table 3; Figure 1 graphically displays
ratio successes failures development problems. planners
except C performed significantly better development problems. suggests
planners tailored (intentionally not) particular types problems
tend better test sets biased accordingly. example, one
6. decided studying planners way representations
development problems PDDL.
7. One planner exception rule; one case, planner timed far frequently
non-development problems.

11

fiHowe & Dahlman

Development
Planner Sol. Fail

48
56
B
42
34
C
30
0
G
43
35
H
52
9

113
20
J
114
24
K
37
56
L
63
32

Rest
Sol. Fail
2
P
207 1026 51.70 0.001
226 929 51.27 0.001
549 16
0.13 0.722
233 924 49.56 0.001
234 655 91.41 0.001
328 920 187.72 0.001
388 949 157.62 0.001
203 987 27.82 0.001
358 846 52.13 0.001

Table 3: 2 results comparing outcome development versus problems.
planners set, STAN, designed emphasis logistics problems (Fox &
Long, 1999).

Figure 1: Histogram ratios success/failures development problems
planners.
analysis introduces variety biases. developers tended give us short
lists probably really representative actually used. set used
moving target, rather stationary suggests. set problems included
experimentation publication may different still. Consequently, second
part, broadened question determine effect different subsets problems
12

fiA Critical Assessment Benchmark Comparison Planning

n
5
10
20
30

0
0
0
0
0

1
1
3
0
0

2
2
0
0
0

3
0
0
0
0

Rank Dominance
4 5 6 7
5 7 10 4
4 10 6 7
1 3 8 7
1 1 9 6

8 9 10 Total Pairs
10 18 21
78
5 23 20
78
11 8 40
78
9 8 44
78

Table 4: Rank dominance counts 10 samples domains domain sizes (n) five
30.
performance. 10 trials, randomly selected n domains (and companion
problems) form problem set. counted many problems could
solved planner ranked relative performance planner. Thus,
value n, obtained 10 planner rankings. focused rankings problems
solved two reasons: First, domain includes different number problems, making
count problems variable across trials. Second, relative ranking gets
heart whether one planner might considered improvement another.
tested values 5, 10, 20 30 n (30 half domains disposal).
give sense variability size, n = 5, problems solved trial
varied 11 64. assess changes rankings across trials, computed rank
dominance pairs planners; rank dominance defined number trials
planner x's rank lower planner y's (note: ties would count toward neither
planner). 13 planners study resulted 78 dominance pairings. relative
ranking two planners stable, one would expect one always dominate
other, i.e., rank dominance 10.
Table 4 shows number pairs value (0-10) rank dominance
four values n. given pair, used highest number rank dominance
pair, e.g., one always lower rank, pair's rank dominance 10
five, five. ties, maximum less five.
data suggest even picking half domains, rankings completely
stable: 56% pairings, one always dominates, 22% 0.3 greater chance
switching relative ranking. values degrade n decreases 27% always
dominating n = 5.

Problem Assumption 2: Syntactic Representation Differences Affect
Performance? Although well known planners' performance depends

representation (Joslin & Pollack, 1994; Srinivasan & Howe, 1995), two recent developments
planner research suggest effect needs better understood. First, common
representation, i.e., PDDL, may bias performance. planners rely pre-processing
step convert PDDL native representation, step usually requires making
arbitrary choices ordering coding. Second, advantage planners based
Graphplan supposed less vulnerable minor changes representa13

fiHowe & Dahlman

Planner

B
C

E
F
G
H

J
K
L


None Subset
65 315
30
70 295
45
318 74
18
202 169
39
111 132
167
112 138
160
70 295
45
91 290
29
109 134
167
150 124
136
60 305
45
112 284
14
212 148
50

Table 5: number problems planners able solve all, none
subset permutations.
tion. Although reasoning claim sound, exigencies implementation may
require re-introduction representation sensitivity.
evaluate sensitivity representation, ten permutations problem
AIPS2000 set generated, resulting 4510 permuted problems. permutations
constructed randomly reordering preconditions operator definitions
order definitions operators within domain definition.
limited number problems study ten permutations problems would prohibitive. selected AIPS2000 problems attention
recently developed benchmark set. Even within set, domains
permuted would result different domains transformation used. purposes investigation, limited set modifications
permutations preconditions operators known affect planners practical considerations limited number permutations could
executed. Finally, expediency, ran permutations smaller number faster
platforms expedited throughput computation time factor
study.
analyze data, divided performance permutations problems
three groups based whether planner able solve permutations,
none permutations subset permutations. planner insensitive
minor representational changes, subset count zero. results
Table 5, see planners affected permutation operation.
susceptibility permuting problem strongly planner dependent (2 = 1572:16,
P < 0:0001), demonstrating planners vulnerable others.
examining number Subset column, one assess degree susceptibility. planners sensitive reorderings, even relied Graphplan
14

fiA Critical Assessment Benchmark Comparison Planning

0
0
165
166
152
145
0
0
138
130
0
13
169

35
8
216
196
199
185
8
46
169
160
8
24
212

0
0
163
139
157
150
0
0
138
130
0
16
149

0
0
2
0
0
0
0
0
0
0
0
0
2

255
268
561
279
384
376
276
285
441
502
240
421
372

8
0
197
180
168
165
0
17
139
130
0
13
180

Pre.
8

0
0
169
164
162
157
0
0
138
130
0
19
168

Pre.
Safety
Strips
Typing

0
0
5
3
1
0
0
0
0
0
0
0
0

9


B
C

E
F
G
H

J
K
L


Feature

Axioms
Cond. Eff.
Dis. Pre.
Equality

Planner

0
0
160
139
149
145
0
0
138
130
0
13
151

Table 6: number problems claiming require PDDL feature solved
planner.

methodology. sensitive E, F, J (which included Graphplan based
planners 40% problems mixed results permutations) C
L least sensitive (3-4% affected).

Problem Assumption 3: Performance Depend PDDL Requirements
Features? planners intended handle STRIPS problems.

problems test set claim require features STRIPS; one would expect
planners would able handle problems. addition,
planners claim able handle given feature may well planners.
Table 6 shows effects feature requirements ability solve problems. data
table based features specified :requirements list PDDL
definition domain.
verify requirements accurate necessary; thus, problem
may solvable ignoring part PDDL syntax understood,
problem may mislabeled designer. evident cases planner
support given feature still appears able solve corresponding
problem. planners, e.g., older versions STAN, reject problem requires
STRIPS without trying solve it; ADL problem makes use
STRIPS features would attempted.
guidance planner use when, results must viewed
skepticism. example, would appear based results planner might
15

fiHowe & Dahlman

good choice problems conditional effects able solve many
problems. would mistake, since planner cannot actually handle types
problems. cases, problems claim require ADL, fact, make
use STRIPS subset.
Clearly, certain problems solved specific planners. instance, C
planners able handle safety constraints, based data,
C, E appear handle domain axioms. half planners trouble
typed problems. gaps appear due problems translation
native representation.

3.3 Planners

Publicly available, general-purpose planners tend large programs developed
period years enhanced include additional features time. Thus, several versions
likely available, versions likely features turned
on/off via parameter settings.
authors release later versions planning systems, general assumption
newer versions outperform predecessors. However, may
case practice. instance, planner could better optimized toward specific class
problem turn hurts performance problems. Also, advanced
capabilities, even unused, may incur overhead solution problems.
comparison purposes, one use latest version? First, tested
question study comparing multiple versions four planners. Second,
planner relies parameter settings tune performance. Some, blackbox,
many parameters. Others none. Comparisons tend use default published
parameter settings people usually understand effects parameters
tuning extremely time consuming. practice undermine fair
comparison?
Planner Assumption 1: Latest Version Best? study, compared
performance multiple versions four planners (labeled section W, X,
Z, larger version numbers indicating subsequent versions). considered two criteria
improvement: outcome planning computation time solved problems.
outcome planning one of: solved, failed timed-out. criterion, statistically
analyzed data superior performance one versions. outcome results
planners summarized Table 7. table shows, rarely new version
result problems solved. Z improved number test problems
solved subsequent versions.
check whether differences outcome significant, ran 2x3 2 tests
planner version independent variable outcome dependent. Table 8 summarizes
results 2 analysis. Z, compared version successor only.
differences significant except transition Z 2 3 (this expected
two versions extremely similar).
Another planner performance metric, evaluated, speed solution.
analysis, limited comparison problems solved
versions planner. classified problem whether later version solved
16

fiA Critical Assessment Benchmark Comparison Planning

Planner Version Solved Failed Timeout Solved?
W
1
286
664
533
W
2
255
1082
147
+
X
1
502
973
3
X
2
441
940
103
+

1
387
750
339

2
382
771
329
+
Z
1
240
1043
201
Z
2
276
959
248
*
Z
3
268
963
252
+
Z
4
421
878
184
*
Table 7: Version performance: counts outcome change number solved.
old
new
Planner Version Version 2
P
W
1
2
320.96 .0001
X
1
2
98.84 .0001

1
2
.46
.79
Z
1
2
10.96 .004
Z
2
3
.158 .924
Z
3
4
48.50 .0001
Table 8: 2 results comparing versions planner.
problem faster, slower, time preceding version. results
Table 9, see planners improved average speed solution
subsequent versions, exception Z (transition 1 2 versions). However,
Z increase number problems solved versions.
Planner Old New Faster Slower Total
W
1
2
161
61
30
252
X
1
2
295
126
0
421

1
2
222
82
53
357
Z
1
2
84
121
30
235
Z
2
3
131
84
53
268
Z
3
4
115
92
21
228
Table 9: Improvements execution speed across versions. Faster column counts
number cases new version solved problem faster; Slower specifies
cases new version took longer solve given problem.
17

fiHowe & Dahlman

Planner Assumption 2: Parameter Settings Matter Fair Comparison?

planner set, three obvious, easily manipulable parameters: Blackbox, HSP
UCPOP. blackbox extensive set parameters control everything
much trace information print sequence solver applications. HSP's function
varied include (or not) loop detection, change search heuristic vary
number paths expand. UCPOP, user change strategies governing node
orderings aw selection.
run experiments assumption planners
parameters clear literature parameters matter.
Blackbox relies heavily random restarts trying alternative SAT solvers. Kautz
Selman (1999), authors blackbox carefully study aspects blackbox's design
demonstrate differential performance using different SAT solvers; propose hypotheses
performance differences working better models performance variation.
heart HSP heuristic search. Thus, performance varies depending
heuristics. Experiments HSP FF (a planner builds ideas
HSP) shown importance heuristic selection search space expansion,
computation time problem scale (Haslum & Geffner, 2000; Hoffmann & Nebel,
2001).
HSP, heuristic search critical UCPOP's performance. set studies
explored alternative settings aw selection heuristics employed UCPOP (Joslin &
Pollack, 1994; Srinivasan & Howe, 1995; Genevini & Schubert, 1996), producing dramatic
improvements domains heuristics. Pollack et al. (1997) confirmed,
good default strategy could derived, performance best
circumstances.
Thus, parameters control fundamental aspects algorithms,
search strategies, role parameters comparisons cannot easily dismissed.

Planner Assumption 3: Time Cut-offs Unfair? Planners often admit

failure. Instead, planner stops used allotted time found
solution. setting time threshold requirement planner execution.
comparison, one might always wonder whether enough time allotted fair {
perhaps solution almost found execution terminated.
determine whether cut-off 30 minutes fair, examined distribution
times declared successes failures8. Across planners problem set,
found distributions skewed (approximately log normal long right tails)
planners quick declare success failure, going so.
Table 10 shows max, mean, median standard deviation success failure times
planners. differences mean median indicate distribution
skew, low standard deviations relative observed max times. max time
shows rare occasions planners might make decision within 2 minutes
cut-off.
8. separated two usually observed significant difference distributions time
succeed time fail { half planners quick succeed slow fail, half
reversed relationship.

18

fiA Critical Assessment Benchmark Comparison Planning

Planner

B
C

E
F
G
H

J
K
L


Successes
Max Mean Median
667.9 34.0
1.3
1608.5 38.5
0.5
1455.4 89.9
1.6
481.0 17.8
1.1
1076 26.2
0.1
1282.4 44.4
0.1
1456.2 44.6
0.7
657.7 29.58
1.4
1713.8 115.4
0.2
1596.5 43.6
4.3
1110.5 31.0
0.32
1611.9 54.4
2.0
1675.3 53.4
1.45

Sd
98.7
182.8
244.6
77.4
126.8
126.8
188.5
80.6
303.1
127.4
121.8
180.9
196.5

Failures
Max Mean Median
1116.4 44.9
4.9
1692.0 45.6
17.8
1.4
0.4
0.13
713.6 26.3
1.1
1622.8 286.9
260.6
1188.4 22.3
0.2
1196.5 43.8
16.7
1080.6 93.8
1.4
50.6
5.1
4.9
1796 11.0
11.0
1298.8 27.7
12.1
847.1 124.1
68.4
1.6
0.9
0.8

Sd
128.8
96.8
0.4
122.6
189.1
104.8
78.5
162.1
6.3
57.9
65.2
164.8
0.4

Table 10: Max, mean, median standard deviations (Sd) computation times
success failure planner.

table show, observed distributions show,
values greater half time cut-off. Figures 2 3 display
distributions planner F, means middle set planners
quite typical distributions. Consequently, least problems, cut-off 15
minutes (900 seconds) would significantly change results.

300

200

100

0
0

104 208 312 416 520 624 728 832 936 1040 1144 1248
success.time

Figure 2: Histogram times, seconds, planner F succeed.
19

fiHowe & Dahlman

600

400

200

0
0

96

192 288 384 480 576 672 768 864 960 1056 1152
fail.time

Figure 3: Histogram times, seconds, planner F fail.

3.4 Performance Metrics

comparisons emphasize number problems solved CPU time completion metrics. Often, problems organized increasing diculty show scale-up.
Comparing based metrics leaves lot open interpretation. example,
planners designed find optimal plan, measured number steps either
parallel sequential plan. Consequently, planners may require computation.
Thus, ignoring plan quality, planners may unfairly judged. also hypothesize
hardware software platform tests vary results. planner
developed machine 1GB memory, likely performance degrade
less. key issue whether effect less uniform across set planners.
section, examine two issues: execution platform effect plan
quality.

Metric Assumption 1: Performance Vary Planners Run
Different Hardware Platforms? Often planner run competition

someone else's lab, hardware software platforms differ platform used
development. Clearly, slowing processor speed slow planning,
requiring higher cut-offs. Reduction memory may well change set problems
solved increase processing time due increased swapping. Changing
hardware configuration may change way memory cached organized, favoring
planners' internal representations others. Changing compilers could also affect
amount type optimizations code. exact effects probably unknown.
assumption changes affect planners less equally.
test this, ran planners less powerful, lower memory machine compared
results two platforms: base Sun Ultrasparc 10/440 256mb memory
Ultrasparc 1/170 128mb memory. operating system compilers
versions machines. problems run platforms.
followed much methodology comparison planner versions: comparing
number problems solved time solution. Table 11 shows results
measured problems solved, failed timed-out planner two platforms.
20

fiA Critical Assessment Benchmark Comparison Planning

Planner Platform Solved Failed Timed-Out 2
p % Reduction

Ultra 1
94
383
27
Ultra 10
95
389
20 1.09 .58
1
B
Ultra 1
121
346
37
Ultra 10
121
353
30 0.80 .67
0
C
Ultra 1
354
7
143
Ultra 10
367
7
130 0.85 .65
4

Ultra 1
218
59
227
Ultra 10
217
59
228 0.01 .998
-.4
E
Ultra 1
280
145
79
Ultra 10
284
150
70 0.66 .72
1
F
Ultra 1
277
155
72
Ultra 10
284
154
66 0.35 .84
2
G
Ultra 1
120
347
37
Ultra 10
121
352
31 0.57 .75
1
H
Ultra 1
116
350
38
Ultra 10
122
338
44 0.80 .67
7

Ultra 1
265
201
38
Ultra 10
274
201
29 1.36 .51
3
J
Ultra 1
280
220
4
Ultra 10
285
217
2 0.73 .69
2
K
Ultra 1
108
370
26
Ultra 10
108
368
28 0.08 .96
0
L
Ultra 1
149
339
16
Ultra 10
150
341
13 0.32 .85
1

Ultra 1
250
65
189
Ultra 10
258
66
180 0.35 .84
3
Table 11: Number problems solved, failed timed-out planner two
hardware platforms. Last column percentage reduction number
solved faster slower platforms.

21

fiHowe & Dahlman

Planner

B
C

E
F
G
H

J
K
L


Faster
# Mean
92
5.18
120
4.02
294
31.89
177
11.02
275
2.68
271
14.86
117
5.02
115
6.86
261
25.73
280
42.24
107
15.26
148
16.81
194
32.72

Slower
Sd # Mean
30.76 1
10.01 0
101.71 60
0.29
82.82 39
0.23
12.27 1
72.44 0
17.17 1
25.24 0
119.97 0
138.16 0
75.42 0
98.54 1
139.73 56
0.30

Sd
0.14
0.14

0.18

Total
1
1
0
1
4
6
2
1
4
0
1
0
0

94
121
354
217
280
277
120
116
265
280
108
149
250

Table 12: Improvements execution speed moving slower faster platform. Counts
problems solved platforms. faster slower,
mean standard deviation (Sd) difference also provided.
before, also looked change time solution. Table 12 shows time
solution changes planner. surprisingly, faster processor memory
nearly always lead better performance. Somewhat surprisingly, difference far less
doubling might expected; mean differences much less
mean times faster processor (see Table 10 mean solution times).
Also, effect seems vary planners. Based counts, Lisp-based
planners appear less susceptible trend (the ones sometimes faster
slower platform). However, advantages small, affecting primarily
smaller problems. think effect due need load Lisp image
startup centralized server; thus, computation time small problems
dominated network delay. Older versions planners appear less sensitive
switch platform.
study, platforms make little difference results, despite
doubling processor speed doubling memory. However, two platforms
underpowered compared development platforms planners.
chose platforms differed characteristics (processor speed
memory amount) access 20 identically configured machines.
really observe difference, 1GB9 memory may needed.
Recent trends planning technology exploited cheap memory: translations
propositional representations, compilation problems built-in caching memory
management techniques. Thus, planners designed trade-off memory time;
9. propose figure amount requested participants AIPS 2000
planning competition.

22

fiA Critical Assessment Benchmark Comparison Planning

planners understandably affected memory limitations problems.
Given results study, considered performing careful study memory
artificially limiting memory planners
access enough suciently large machines likely make difference could
devise scheme fairly across planners (which implemented
different languages require different software run-time environments).
Another important factor may memory architecture/management. planners
include memory managers, map better hardware platforms
others (e.g., HSP uses linear organization appears fit well Intel's memory
architecture).

Metric Assumption 2: Number Plan Steps Vary? Several researchers

examined issue measuring plan quality directing planning based it, e.g.,
(Perez, 1995; Estlin & Mooney, 1997; Rabideau, Englehardt, & Chien, 2000). number
steps plan rather weak measure plan quality, far, one
widely used primitive-action planning.
expect planners sacrifice quality (as measured plan length) speed.
Thus, ignoring even measure plan quality may unfair planners.
check whether appears factor problem set, counted plan length
plans returned output compared lengths across planners.
planners construct parallel plans, adopted general definition:
sequential plan length. compared plan lengths returned planner
every successfully solved problem.
found 11% problems solved one planner (not necessarily
one). planners found equal length solutions 62% remained (493
problems). calculated standard deviation (SD) plan length solutions
problem analyzed SDs. found minimum observed SD 0.30,
maximum 63.30, mean 2.43 standard deviation 5.45. Thirteen
cases showed SDs higher 20. Obviously, cases involved fairly long plans (up
165 steps); cases problems logistics gripper domains.
check whether planners favored minimal lengths, counted number
cases planner found shortest length plan (ties attributed
planners) variance plan length. Table 13 lists results.
planners find shortest length plans one third problems. Planner F
designed optimize plan length, shows results. one exception,
older planners rarely find shortest plans.

4. Interpretation Results Recommendations
previous section presented summarization analysis planner runs.
section, ect results mean empirical comparison planners;
summarize results recommend partial solutions. possible guarantee
fairness propose magic formula performing evaluations, state
practice general certainly improved. propose three general recommendations
12 recommendations targeted specific assumptions.
23

fiHowe & Dahlman

Planner Count

178
B
169
C
0

161
E
5
F
319
G
171
H
176

222
J
0
K
159
L
151

283
Table 13: Number plans planner found shortest plan. data
include problems different length plans found.
Many targeted recommendations amount requesting problem planner developers precise requirements expectations contributions.
planners extremely complex time consuming build, documentation may inadequate determine subsequent version differs previous
conditions (e.g., parameter settings, problem types) planner fairly
compared. current positive trend making planners available, behooves
developer include information distribution system.
sweeping recommendation shift research focus away developing
best general-purpose planner. Even competitions, planners identified
superior ones designed specific classes problems, e.g., FF IPP.
competitions done great job exciting interest encouraging development
public availability planners incorporate representation.
However, advance research, informative comparative evaluations
designed specific purpose { test hypothesis prediction
performance planner10. experimental hypothesis focuses analysis often
leads naturally justified design decisions experiment itself. example, Hoffmann Nebel, authors Fast-Forward (FF) system, state introduction
JAIR paper FF's development motivated specific set benchmark
domains; system heuristic, designed heuristics fit expectations/needs domains (Hoffmann & Nebel, 2001). Additionally, part
evaluation, compare specific system system commonalities
point various advantages disadvantages design decisions specific
10. Paul Cohen advocated experimental methodology artificial intelligence based
hypotheses, predictions models considerable detail; see Cohen (1991, 1995).

24

fiA Critical Assessment Benchmark Comparison Planning

problems. Follow-up work researchers comparing systems FF
well-defined starting point comparison.

Recommendation 1: Experiments driven hypotheses. Re-

searchers precisely articulate advance experiments expectations new planner augmentations existing planner add
state art. expectations turn justify selection
problems, planners metrics form core comparative
evaluation.
general issue whether results accurate. reported results
output planners. planner stated output successful,
took face value. However, examining output, determined
claims successful solution erroneous { proposed solution would work.
way ensure output correct solution checker. Drew McDermott
used solution checker AIPS98 competition. However, planners
provide output compatible format checker. Thus, another concern
comparative evaluation output needs cross-checked.
declaring winner (i.e., planner exhibited superior performance), think
lack solution checker casts serious doubt results. part,
concerned factors cause observed success rates change.

Recommendation 2: input standardized PDDL, output
standardized, least format returned plans.

Another general issue whether benchmark sets representative space
interesting planning problems. test directly (in fact, sure
one could so), clustering results observations others planning
community suggest set biased toward logistics problems. Additionally, many
problems getting dated longer distinguish performance. researchers
begun formally analyze problem set, either service building improved
planners (e.g., Hoffmann & Nebel, 2001) better understand planning problems.
example, related area scheduling, group identified distinctive patterns
topology search spaces different types classical scheduling problems
related topology performance algorithms (Watson, Beck, Barbulescu, Whitley, &
Howe, 2001). Within planning, Hoffmann examined topology local search spaces
small problems benchmark collection found simple structure
respect well-known relaxations (Hoffmann, 2001). Additionally, worked
partial taxonomy, based three characteristics, analyzed domains. Helmert
analyzed computational complexity subclass benchmarks, transportation
problems, identified key features affect diculty problems (Helmert,
2001).

Recommendation 3: benchmark problem sets eval-

uated over-hauled. Problems easily solved removed.
Researchers study benchmark problems/domains classify
25

fiHowe & Dahlman

problem types key characteristics. Developers contribute application problems realistic versions evolving set.
remainder section describes recommendations improving state
art planner comparisons.

Problem Assumption 1: General Purpose Planners Biased Toward Particular Problems/Domains? set problems planner developed
strong effect performance planner. either effect
unintentional over-specialization result concerted effort part
developers optimize system solve specific problem. one exception, every
planner fared better tailored subset problems (training set). Consequently,
must conclude choice subset problems may well affect outcome
comparison.
fair planner comparison must account likely biases problem set. Good
performance certain class problems imply good performance general.
large performance differential planners targeted problem domain (i.e., well
focus problems poorly others) may well indicate developers
succeeded optimizing performance planner.
Recommendation 4: Problem sets constructed highlight
designers' expectations superior performance planner,
specific selection criteria.
hand, goal demonstrate across board performance,
results randomly selecting domains suggests biases mitigated.
Recommendation 5: highlighting performance \general" problems
goal, problem set selected randomly benchmark
domains.

Problem Assumption 2: Syntactic Representation Differences Affect
Performance? Many studies, including this, shown planners may sensitive

representational features. representations translated automatically
mean performance unaffected. algorithm
theoretically insensitive factor mean practice is.
planners showed sensitivity permuted problems, degree sensitivity varied.
outcome suggests translators even minor variations problem descriptions
impact outcome used care, especially sensitivity
focus study planner vulnerable effect.
Recommendation 6: Representation translators avoided using
native versions problems testing multiple versions problems necessary.
many planner developers participating AIPS competitions, become
less issue.
importantly, researchers explicitly testing effect alternative phrasings planning problems determine sensitivity performance separate
effects advice/tuning essence problem.
26

fiA Critical Assessment Benchmark Comparison Planning

Recommendation 7: Studies consider role minor syntactic vari-

ations performance include permuted problems (i.e., initial conditions,
goals, preconditions actions) problem sets demonstrate robustness, provide opportunity learning protect developers
accidentally over-fitting algorithm set test problems.

Problem Assumption 3: Performance Depend PDDL Requirements
Features? planners perform quite advertised expected given

problem features. discrepancy could many possible causes: problems incorrectly
specified, planners less sensitivity thought, solutions correct, etc.
example, many problems benchmark set designed competitions
even intended widely used may specified carefully enough.

Recommendation 8: problems contributed benchmark set,
developers verify requirements stated description
problem correctly ect subset features needed. Planner evaluators
use problems match planner's capabilities.

Depending cause, results skewed, e.g., planner may unfairly
maligned unable solve problem specifically designed solve.
recommendation addresses gaps specification problem set,
mismatches capabilities specifiable PDDL planners possess
remain.

Recommendation 9: Planner developers develop vocabulary
planner's capabilities, PDDL ags, specify expected
capabilities planner's distribution.

Planner Assumption 1: Latest Version Best? results suggest

new versions run faster, often solve problems. Thus, newest version may
represent \best" (depending definition) performance class planner.
competitions fields, e.g., automatic theorem proving community, require
previous year's best performer compete well; advantage establishing
baseline performance well allowing comparison focus may shift
time.

Recommendation 10: primary evaluation metric speed, newer

version may best competition. number problems solved one
wishes establish progress made, may worth running
older version well. recommendation 9 followed,
evaluators select version based guidance.

Planner Assumption 2: Effect Parameter Settings? Perfor-

mance planners vary parameter settings. Unfortunately, often
dicult figure set parameters properly, changing settings makes
dicult compare results across experiments. Generally, issue
27

fiHowe & Dahlman

developers users tend rely default parameter settings. Unfortunately,
sometimes developers exploit alternative settings experiments, complicating
later comparison.

Recommendation 11: planner includes parameters, developer
guide users settings. not, default settings
used developers others experiments facilitate comparison.

Planner Assumption 3: Time Cut-offs Unfair? found little benefit
increasing time cut-offs beyond 15 minutes problems.

Recommendation 12: total computation time bottleneck, run

problems separate batches, incrementally increasing time cut-off
runs including unresolved problems subsequent runs.
additional problems solved run, stop.

Metric Assumption 1: Alternative Platforms Lead Different Performance? experiments, performance vary much expected.
result suggests researchers general developing specific hardware/software
configurations, recent trends suggest otherwise, least regards memory. Again,
systems research prototypes, behooves developer clear
his/her expectations anyone subsequently using system accommodate requests studies.

Recommendation 13: factors planner design, researchers

must clearly state hardware/software requirements planners,
design based platform assumptions. Additionally, careful study memory versus time trade-offs undertaken, given recent trends memory exploitation.

Metric Assumption 2: Number Plan Steps Vary? certainly can.

one neglects quality measures, planners penalized efforts declare
best planner.

Recommendation 14: expedite generalizing across studies, reports
describe performance terms solved (how many types),
much time required quality solutions. Tradeoffs reported, possible, e.g., 12% increase computation time
30% decrease plan length. Additionally, design goal find
optimal solution, compare planners design goal.

Good metrics plan quality sorely needed. latest specification PDDL
specification supports definition problem-specific metrics (Fox & Long, 2002);
metrics indicate whether total-time (a new concept supported specification action
durations) specified functions minimized maximized. addition
excellent start, general metrics plan-length total-time also
needed expedite comparisons across problems.
28

fiA Critical Assessment Benchmark Comparison Planning

Recommendation 15: Developing good metrics valuable research contri-

bution. Researchers consider worthwhile project, conference organizers reviewers encourage papers topic, planner developers
implement planners responsive new quality metrics (i.e.,
support tunable heuristics evaluation criteria).

5. Conclusions

Fair evaluation comparison planners hard. Many apparently benign factors exert
significant effects performance. Superior performance one planner another
problem neither intentionally designed solve may explained minor
representational features. However, comparative analysis general problems practical
importance practical create specialized solution every problem.
analyzed effects experiment design decisions empirical comparison
planners made recommendations ameliorating effects decisions.
recommendations common sense suggestions improving current
methodology.
expand beyond current methodology require least two substantive changes.
First, field needs question whether trying show performance
planning problems general. shift general comparisons focused comparisons (on
problem class mechanism hypothesis testing) could produce significant advances
understanding planning.
Second, benchmark problem sets require attention. Many problems
discarded simple show much. domains far removed
real applications. may time revisit testbeds. example, several researchers
robotics constructed interactive testbed comparing motion planning algorithms
(Piccinocchi, Ceccarelli, Piloni, & Bicchi, 1997). testbed consists user interface
defining new problems, collection well-known algorithms simulator testing
algorithms specific problems. Thus, user design his/her problems compare performance various algorithms (including own) via web site.
testbed affords several advantages current paradigm static benchmark problems
developer conducted comparisons, particular, replicability extendability
test set. Alternatively, challenging problem sets developed modifying deployed
applications (Wilkins & desJardins, 2001; Engelhardt, Chien, Barrett, Willis, & Wilklow,
2001).
recent years, planning community significantly improved size planning
problems solved reasonable time advanced state art
empirical comparison systems. interpret results empirical comparisons
understand motivate development planning, community
needs understand effects empirical methodology itself. purpose
paper understanding initiate dialogue methodology
used.

29

fiHowe & Dahlman

Acknowledgments
research partially supported Career award National Science
Foundation IRI-9624058 grant Air Force Oce Scientific Research F4962000-1-0144. U.S. Government authorized reproduce distribute reprints
Governmental purposes notwithstanding copyright notation thereon.
grateful reviewers careful reading well-considered comments
submitted version; hope done justice suggestions.

References

Bacchus,
F.
(2000).
AIPS-2000
planning
competition.
http://www.cs.toronto.edu/aips2000/SelfContainedAIPS-2000.ppt.
Barrett, A., Golden, K., Penberthy, S., & Weld, D. (1993). UCPOP User's Manual. Dept.
Computer Science Engineering, University Washington, Seattle, WA. TR
93-09-06.
Blum, A. L., & Furst, M. L. (1997). Fast planning planning graph analysis. Artificial
Intelligence Journal, 90 (1-2), 225{279.
Bonet, B., & Geffner, H. (1999). Planning heuristic search: New results. Proceedings
Fifth European Conference Planning (ECP-99) Durham, UK.
Chien, S., Kambhampati, S., & Knoblock, C. A. (Eds.)(2000). Proceedings Fifth
International Conference Artificial Intelligence Planning Scheduling (AIPS
2000). AAAI Press, Breckenridge, CO.
Cohen, P. R. (1991). survey eighth national conference artificial intelligence:
Pulling together pulling apart? AI Magazine, 12 (1), 16{41.
Cohen, P. R. (1995). Empirical Methods Artificial Intelligence. MIT Press.
Drummond, M. E., Kaelbling, L. P., & Rosenschein, S. J. (1990). Collected notes
benchmarks metrics workshop. Artificial intelligence branch FIA-91-06, NASA
Ames Research Center.
Engelhardt, B., Chien, S., Barrett, T., Willis, J., & Wilklow, C. (2001). data-chaser
citizen explorer benchmark problem sets. Proceedings Sixth European
Conference Planning (ECP 01) Toledo, Spain.
Estlin, T. A., & Mooney, R. J. (1997). Learning improve ecicency quality
planning. Proceedings Fifteenth International Joint Conference Artificial
Intelligence, pp. 1227{1233, Nagoya, Japan.
Fox, M., & Long, D. (1999). ecient implementation plan-graph STAN.
Journal Artificial Intelligence Research, 10, 87{115.
Fox, M., & Long, D. (2002). PDDL2.1: extension PDDL expressing temporal
planning domains. Available http://www.dur.ac.uk/d.p.long/pddl2.ps.gz.
30

fiA Critical Assessment Benchmark Comparison Planning

Genevini, A., & Schubert, L. (1996). Accelerating partial-order planners: techniques
effective search control pruning. Journal Artificial Intelligence Research, 5,
95{137.
Hanks, S., Nguyen, D., & Thomas, C. (1993). beginner's guide truckworld simulator. Dept. Computer Science Engineering UW-CSE-TR 93-06-09, University
Washington.
Hanks, S., Pollack, M. E., & Cohen, P. R. (1994). Benchmarks, test beds, controlled
experimentation design agent architectures. AI Magazine, 17{42.
Haslum, P., & Geffner, H. (2000). Admissible heuristics optimal planning. Proceedings Fifth International Conference Artificial Intelligence Planning
Scheduling (AIPS 2000), pp. 140{149, Breckenridge, CO. AAAI Press.
Helmert, M. (2001). complexity planning transportation domains. 6th
European Conference Planning (ECP'01), Lecture Notes Artificial Intelligence,
New York, Springer-Verlag.
Hoffmann, J. (2001). Local search topology planning benchmarks: empirical analysis.
Proceedings 17th International Joint Conference Artificial Intelligence
Seattle, WA, USA.
Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generation
heuristic search. Journal Artificial Intelligence Research, 14, 253{302.
Howe, A. E., Dahlman, E., Hansen, C., Scheetz, M., & von Mayrhauser, A. (1999). Exploiting competitive planner performance. Proceedings Fifth European Conference
Planning, Durham, UK.
Howe, A. E., von Mayrhauser, A., & Mraz, R. T. (1997). Test case generation AI
planning problem. Automated Software Engineering, 4 (1), 77{106.
Joslin, D., & Pollack, M. (1994). Least-cost aw repair: plan refinement strategy
partial-order planning. Proceedings Twelfth National Conference Artificial
Intelligence, pp. 1004{1009, Seattle, WA.
Kautz, H., & Selman, B. (1998). BLACKBOX: new approach application
theorem proving problem solving. Working notes AIPS98 Workshop
Planning Combinatorial Search, Pittsburgh, PA.
Kautz,
H.
blackbox:
SAT technology planning system.
http://www.cs.washington.edu/homes/kautz/blackbox/index.html.
Kautz, H., & Selman, B. (1999). Unifying SAT-based graph-based planning. Proceedings Sixteenth International Joint Conference Artificial Intelligence, Stockholm, Sweden.
Koehler, J. (1999). Handling conditional effects negative goals IPP. Tech. rep.
128, Institute Computer Science, Albert Ludwigs University, Freiburg, Germany.
31

fiHowe & Dahlman

Koehler, J., Nebel, B., Hoffmann, J., & Dimopoulos, Y. (1997). Extending planning graphs
ADL subset. Proceedings Fourth European Conference Planning.
McDermott, D., Ghallab, M., Howe, A., Knoblock, C., Ram, A., Veloso, M., Weld, D., &
Wilkins, D. (1998). Planning Domain Definition Language.
McDermott, D. (2000). 1998 AI planning systems competition. AI Magazine, 21 (2),
35{56.
Penberthy, J. S., & Weld, D. S. (1992). UCPOP: sound, complete, partial order planner
adl. Proceedings Third International Conference Knowledge Representation Reasoning, pp. 103{114.
Perez, M. A. (1995). Learning Search Control Knowledge Improve Plan Quality. Ph.D.
thesis, Carnegie-Mellon University.
Piccinocchi, S., Ceccarelli, M., Piloni, F., & Bicchi, A. (1997). Interactive benchmark
planning algorithms web. Proceedings IEEE International Conference
Robotics Automation.
Pollack, M. E., & Ringuette, M. (1990). Introducing Tileworld: Experimentally evaluating agent architectures. Proceedings Eight National Conference Artificial
Intelligence, pp. 183{189, Boston, MA.
Pollack, M., Joslin, D., & Paolucci, M. (1997). Flaw selection strategies partial-order
planning. Journal Artificial Intelligence Research, 6, 223{262.
Rabideau, G., Englehardt, B., & Chien, S. (2000). Using generic prferences incrementally
improve plan quality. Proceedings Fifth International Conference Artificial
Intelligence Planning Scheduling (AIPS 2000), Breckenridge, CO.
Slaney, J., & Thiebaux, S. (2001). Blocks world revisited. Artificial Intelligence Journal,
125 (1-2), 119{153.
Srinivasan, R., & Howe, A. E. (1995). Comparison methods improving search eciency
partial-order planner. Proceedings 14th International Joint Conference
Artificial Intelligence, pp. 1620{1626, Montreal, Canada.
Sussman, G. A. (1973). computational model skill acquisition. Tech. rep. Memo no.
AI-TR-297, MIT AI Lab.
Prodigy Research Group (1992). PRODIGY 4.0; manual tutorial. School
Computer Science 92-150, Carnegie Mellon University.
Watson, J., Barbulescu, L., Howe, A., & Whitley, L. D. (1999). Algorithm performance
problem structure ow-shop scheduling. Proceedings Sixteenth National
Conference Artificial Intelligence (AAAI-99), Orlando, FL.
Watson, J., Beck, J., Barbulescu, L., Whitley, L. D., & Howe, A. (2001). Toward descriptive model local search cost job-shop scheduling. Proceedings Sixth
European Conference Planning (ECP'01), Toledo, Spain.
32

fiA Critical Assessment Benchmark Comparison Planning

Weld, D., Anderson, C., & Smith, D. (1998). Extending graphplan handle uncertainty
sensing actions. Proceedings Fifteenth National Conference Artificial
Intelligence Madison, WI.
Weld, D. S. (1999). Recent advances AI planning. AI Magazine, 20 (2), 93{122.
Wilkins, D. E., & desJardins, M. (2001). call knowledge-based planning. AI Magazine,
22 (1), 99{115.

33

fiJournal Artificial Intelligence Research 17 (2002) 289-308

Submitted 6/02; published 10/02

Unified Model Structural Organization
Language Music
Rens Bod

RENS@ILLC.UVA .NL

Institute Logic, Language Computation
University Amsterdam, Nieuwe Achtergracht 166
1018 WV Amsterdam, NETHERLANDS,
School Computing, University Leeds
LS2 9JT Leeds, UK

Abstract
general model predict perceived phrase structure language
music? usually assumed humans separate faculties language
music, work focuses commonalities rather differences
modalities, aiming finding deeper "faculty". key idea perceptual system
strives simplest structure (the "simplicity principle"), biased
likelihood previous structures (the "likelihood principle"). present series dataoriented parsing (DOP) models combine two principles tested
Penn Treebank Essen Folksong Collection. experiments show (1)
combination two principles outperforms use either them, (2) exactly
model parameter setting achieves maximum accuracy language
music. argue results suggest interesting parallel linguistic
musical structuring.

1. Introduction: Problem Structural Organization
widely accepted human cognitive system tends organize perceptual information
hierarchical descriptions conveniently represented tree structures. Tree
structures used describe linguistic perception (e.g. Wundt, 1901; Chomsky,
1965), musical perception (e.g. Longuet-Higgins, 1976; Lerdahl & Jackendoff, 1983)
visual perception (e.g. Palmer, 1977; Marr, 1982). Yet, little attention paid
commonalities different forms perception question whether
exists general, underlying mechanism governs perceptual organization. paper
studies exactly question: acknowledging differences perceptual
modalities, general model predict perceived tree structure sensory
input? studying question, use empirical methodology: model
might hypothesize tested manually analyzed benchmarks
linguistically annotated Penn Treebank (Marcus et al. 1993) musically annotated
Essen Folksong Collection (Schaffrath, 1995). argue general model
structural organization language, music vision, carry experiments
linguistic musical benchmarks, since benchmark visual tree structures currently
available, best knowledge.
Figure 1 gives three simple examples linguistic, musical visual information
corresponding tree structures printed (these examples resp. taken Martin et al.
1987, Lerdahl & Jackendoff, 1983, Dastani, 1998).

2002 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiBOD

List sales products 1973

NP
NP
NP
V

DT

PP
N

P

PP
N

P

N

List sales products 1973

Figure 1: Examples linguistic, musical visual input tree structures
Thus, tree structure describes parts input combine constituents
constituents combine representation whole input. Note linguistic
tree structure labeled syntactic categories, whereas musical visual tree
structures unlabeled. language syntactic constraints
words combined larger constituents (e.g. English determiner combined
noun precedes noun, expressed rule NP DT N),
music (and lesser extent vision) restrictions: principle note
may combined note.
Apart differences, also fundamental commonality: perceptual input
undergoes process hierarchical structuring found input itself. main
problem thus: derive perceived tree structure given input?
problem trivial may illustrated fact inputs also assigned
following, alternative tree structures:


NP
PP

NP
V

DT

N

P

PP
N

P

N

List sales products 1973

Figure 2: Alternative tree structures inputs Figure 1
alternative structures possible perceived. linguistic tree
structure Figure 1 corresponds meaning different tree Figure 2.
two musical tree structures correspond different groupings motifs. two
visual structures correspond different visual Gestalts. alternative tree
structures possible, plausible: correspond structures
actually perceived human cognitive system.
phenomenon input may assigned different structural organizations
known ambiguity problem. problem one hardest problems modeling
human perception. Even language, phrase-structure grammar may specify
words combined constituents, ambiguity problem notoriously hard (cf.
Manning & Schtze, 1999). Charniak (1997: 37) argues many sentences Wall
Street Journal one million different parse trees. ambiguity problem
290

fiA UNIFIED MODEL STRUCTURAL ORGANIZATION LANGUAGE MUSIC

musical input even harder, since virtually constraints notes may
combined constituents. Talking rhythm perception music, Longuet-Higgins
Lee (1987) note "Any given sequence note values principle infinitely ambiguous,
ambiguity seldom apparent listener.".
following Section, discuss two principles traditionally proposed
solve ambiguity: likelihood principle simplicity principle. Section 3,
argue new integration two principles within data-oriented parsing framework.
hypothesis human cognitive system strives simplest structure generated
shortest derivation, biased frequency previously
perceived structures. Section 4, go computational aspects model.
Section 5, discuss linguistic musical test domains. Section 6 presents empirical
investigation comparison model. Finally, Section 7, give discussion
approach go combinations simplicity likelihood proposed
literature.

2. Two principles: Likelihood Simplicity
predict set possible tree structures tree actually
perceived human cognitive system? field visual perception, two competing
principles traditionally proposed govern structural organization. first, initiated
Helmholtz (1910), advocates likelihood principle: perceptual input organized
probable structure. second, initiated Wertheimer (1923) developed
Gestalt psychologists, advocates simplicity principle: perceptual system
viewed finding simplest rather probable structure (see Chater, 1999,
overview). two principles also used linguistic musical structuring.
following, briefly review principles modality.
2.1 Likelihood
likelihood principle particularly influential field natural language
processing (see Manning Schtze, 1999, review). field, appropriate
tree structure sentence assumed likely structure. likelihood tree
computed probabilities parts (e.g. phrase-structure rules) turn
estimated large manually analyzed language corpus, i.e. treebank. State-of-the-art
probabilistic parsers Collins (2000), Charniak (2000) Bod (2001a) obtain around
90% precision recall Penn Wall Street Journal treebank (Marcus et al. 1993).
likelihood principle also applied musical perception, e.g. Raphael (1999)
Bod (2001b/c). probabilistic natural language processing, probable musical
tree structure computed probabilities rules fragments taken large
annotated musical corpus. musical benchmark used models
Essen Folksong Collection (Schaffrath, 1995).
Also vision science, huge interest probabilistic models (e.g. Hoffman, 1998;
Kersten, 1999). Mumford (1999) even seen fit declare Dawning Stochasticity.
Unfortunately, visual treebanks currently available.
2.2 Simplicity
simplicity principle long tradition field visual perception psychology (e.g.
Restle, 1970; Leeuwenberg, 1971; Simon, 1972; Buffart et al. 1983; van der Helm, 2000).
291

fiBOD

field, visual pattern formalized constituent structure means visual coding
language based primitive elements line segments angles. Perception
described process selecting simplest structure corresponding "shortest
encoding" visual pattern.
notion simplicity also applied music perception. Collard et al. (1981) use
coding language Leeuwenberg (1971) predict metrical structure four preludes
Bach's Well-Tempered Clavier. well-known music perception theory
proposed Lerdahl Jackendoff (1983). theory contains two kinds rules: "wellformedness rules" "preference rules". role well-formedness rules define
kinds formal objects (grouping structures) theory employs. grouping structures
listener actually hears, described preference rules describe Gestaltpreferences kind identified Wertheimer (1923), therefore also seen
embodiment simplicity principle.
Notions simplicity also exist language processing. example, Frazier (1978)
viewed arguing parser prefers simplest structure containing minimal
attachments. Bod (2000a) defines simplest tree structure sentence structure
generated smallest number subtrees given treebank.

3. Combining Likelihood Simplicity
key idea current paper principles play role perceptual organization,
albeit rather different ones: simplicity principle general cognitive preference
economy, likelihood principle probabilistic bias due previous perceptual
experiences. Informally stated, working hypothesis human cognitive system
strives simplest structure generated shortest derivation,
biased frequency previously perceived structures (some combinations
simplicity likelihood discussed Section 7). formally instantiate working
hypothesis, first need model defines set possible structures input.
paper, chosen model defines set phrase-structures input
basis treebank previously analyzed input, known Data-Oriented
Parsing DOP model (see Bod, 1998; Collins & Duffy, 2002). DOP learns grammar
extracting subtrees given treebank combines subtrees analyze fresh input.
chosen DOP (1) uses subtrees arbitrary size, thereby capturing nonlocal dependencies, (2) obtained competitive results various benchmarks
(Bod, 2001a/b; Collins & Duffy, 2002). following, first review DOP model
discuss use likelihood simplicity principles approach. Next, show
two principles combined instantiate working hypothesis.
3.1 Data-Oriented Parsing
Section, illustrate DOP model linguistic example (for rigorous definition
DOP, reader referred Bod, 1998). come back musical examples
Section 5. Suppose given following extremely small linguistic treebank two
trees resp. wanted dress rack saw dog telescope
(actual treebanks contain tens thousands trees, cf. Marcus et al. 1993):

292

fiA UNIFIED MODEL STRUCTURAL ORGANIZATION LANGUAGE MUSIC





NP

VP

V

NP



wanted



PP
NP

saw

NP

dress P

VP
V

PP

NP


VP

NP

NP

P

dog telescope

rack

Figure 3: example treebank
DOP model parse new sentence, e.g. saw dress telescope,
combining subtrees treebank means substitution operation (indicated ):







VP

NP



NP

PP
NP

P

dress



=

telescope



VP



PP
NP

V

VP

NP

VP

PP
NP

V
saw

saw

P

NP

dress telescope

Figure 4: Parsing sentence combining subtrees Figure 3
Thus substitution operation combines two subtrees substituting second subtree
leftmost nonlexical leaf node first subtree (the result may combined
third subtree, etc.). combination subtrees results tree structure
whole sentence called derivation. Since many different subtrees, various
sizes, typically also many different derivations produce, however, tree;
instance:





NP


VP

NP


VP
V
saw

dress

P

VP

NP


PP
NP



=

NP

VP
V

telescope

PP
NP

P

NP

saw dress telescope

Figure 5: different derivation produces parse tree
293

fiBOD

interesting case occurs different derivations produce different
parse trees. happens sentence ambiguous; example, DOP also produces
following alternative parse tree saw dress telescope:




NP

VP

V

V
saw


P



=

PP

NP

NP

telescope

NP

VP

V

NP

saw
NP


PP

PP

NP


dress

dress

P

NP

telescope

Figure 6: different derivation produces different parse tree
3.2 Likelihood-DOP
Bod (1993), DOP enriched likelihood principle predict perceived tree
structure set possible structures. model, call Likelihood-DOP,
computes probable tree input occurrence-frequencies subtrees.
probability subtree t, P(t), computed number occurrences t, | |, divided
total number occurrences treebank-subtrees root label t.
Let r(t) return root label t. may write:
P(t) =

|t|

t': r(t')= r( t)

| t' |

probability derivation t1...tn computed product probabilities
subtrees ti:
P(t1...tn ) =

P(ti)

seen, may different derivations generate parse tree.
probability parse tree thus sum probabilities distinct derivations. Let
tid i-th subtree derivation produces tree T, probability given

P(T) =

P(tid)

294

fiA UNIFIED MODEL STRUCTURAL ORGANIZATION LANGUAGE MUSIC

parsing sentence s, interested trees assigned s,
denote Ts. best parse tree, Tbest, according Likelihood-DOP tree
maximizes probability Ts:
Tbest = arg max P(Ts)
Ts

Thus Likelihood-DOP computes probability tree sum products,
product corresponds probability certain derivation generating tree.
distinguishes Likelihood-DOP statistical parsing models identify exactly
one derivation parse tree thus compute probability tree one
product probabilities (e.g. Charniak, 1997; Collins, 1999; Eisner, 1997). Likelihood-DOP's
probability model allows including counts subtrees wide range sizes: everything
counts single-level rules counts entire trees.
Note subtree probabilities Likelihood-DOP directly estimated
relative frequencies treebank-trees. relative-frequency estimator obtains
competitive results several domains (Bonnema et al. 1997; Bod, 2001a; De Pauw, 2000),
maximize likelihood training data (Johnson, 2002).
may hidden derivations relative-frequency estimator cannot deal with. 1
estimation procedures take account hidden derivations maximize
likelihood training data. example, Bod (2000b) presents Likelihood-DOP model
estimates subtree probabilities maximum likelihood re-estimation procedure
based expectation-maximization algorithm (Dempster et al. 1977). However, since
relative frequency estimator far outperformed estimator (see
Bod et al. 2002b), stick relative frequency estimator current paper.
3.3 Simplicity-DOP
Likelihood-DOP justice preference humans display simplest
structure generated shortest derivation input. Bod (2000a), simplest tree
structure input defined tree constructed smallest number
subtrees treebank. refer model Simplicity-DOP. Instead
producing probable parse tree input, Simplicity-DOP thus produces parse
tree generated shortest derivation consisting fewest treebank-subtrees,
independent probabilities subtrees. define length derivation d,
L(d), number subtrees d; thus = t1...tn L(d) = n. Let derivation
results parse tree T, best parse tree, Tbest, according Simplicity-DOP
tree produced derivation minimal length:
Tbest = arg min L(d Ts )
Ts

Section 3.2, Ts parse tree sentence s. example, given treebank Figure
3, simplest parse tree saw dress telescope given Figure 5, since
1 subtrees restricted depth 1 relative frequency estimator coincide

maximum likelihood estimator. depth-1 DOP model corresponds stochastic context-free
grammar. well-known DOP models allow subtrees greater depth outperform depth-1
DOP models (Bod, 1998; Collins & Duffy, 2002).

295

fiBOD

parse tree generated derivation two treebank-subtrees,
parse tree Figure 6 (and parse tree) needs least three treebank-subtrees
generated. 2
shortest derivation may unique: happen different parse trees
sentence generated minimal number treebank-subtrees (also
probable parse tree may unique, never happens practice). case
back frequency ordering subtrees. is, subtrees root label
assigned rank according frequency treebank: frequent subtree (or
subtrees) root label gets rank 1, second frequent subtree gets rank 2, etc.
Next, rank (shortest) derivation computed sum ranks
subtrees involved. derivation smallest sum, highest rank, taken final
best derivation producing final best parse tree Simplicity-DOP (see Bod, 2000a).
performed one little adjustment rank subtree. adjustment averages
rank subtree ranks sub-subtrees. is, instead simply taking
rank subtree, compute rank subtree (arithmetic) mean ranks
sub-subtrees (including subtree itself). effect technique
redresses low-ranked subtree contains high-ranked sub-subtrees.
Simplicity-DOP Likelihood-DOP obtain rather similar parse accuracy
Wall Street Journal Essen Folksong Collection (in terms precision/recall -- see
Section 6), best trees predicted two models quite match. suggests
combined model, justice simplicity likelihood, may boost accuracy.
3.4 Combining Likelihood-DOP Simplicity-DOP: SL-DOP LS-DOP
underlying idea combining likelihood simplicity human perceptual system
searches simplest tree structure (generated shortest derivation)
biased likelihood tree structure. is, instead selecting simplest tree
per se, combined model selects simplest tree among n likeliest trees, n
free parameter. course ways combine simplicity likelihood
within DOP framework. straightforward alternative would select
probable tree among n simplest trees, suggesting perceptual system
searching probable structure among simplest ones. refer
first combination simplicity likelihood (which selects simplest among n
likeliest trees) Simplicity-Likelihood-DOP SL-DOP, second combination
(which selects likeliest among n simplest trees) Likelihood-Simplicity-DOP LSDOP. Note n=1, Simplicity-Likelihood-DOP equal Likelihood-DOP, since
one probable tree select from, Likelihood-Simplicity-DOP equal
Simplicity-DOP, since one simplest tree select from. Moreover, n gets large,
SL-DOP converges Simplicity-DOP LS-DOP converges Likelihood-DOP.
varying parameter n, able compare Likelihood-DOP, Simplicity-DOP
several instantiations SL-DOP LS-DOP.

2 One might argue straightforward metric simplicity would return parse tree

smallest number nodes (rather smallest number treebank-subtrees). metric
known perform quite badly (see Manning & Schtze, 1999; Bod, 2000a).

296

fiA UNIFIED MODEL STRUCTURAL ORGANIZATION LANGUAGE MUSIC

4. Computational Issues
Bod (1993) showed standard chart parsing techniques applied Likelihood-DOP.
treebank-subtree converted context-free rule r lefthand side r
corresponds root label righthand side r corresponds frontier labels
t. Indices link rules original subtrees maintain subtree's internal
structure probability. rules used create derivation forest sentence
(using chart parser -- see Charniak, 1993), probable parse computed
sampling sufficiently large number random derivations forest ("Monte Carlo
disambiguation", see Bod, 1998). technique successfully applied parsing
ATIS portion Penn Treebank (Marcus et al. 1993), extremely time consuming.
mainly number random derivations sampled reliably
estimate probable parse increases exponentially sentence length (see
Goodman, 2002). therefore questionable whether Bod's sampling technique scaled
larger domains Wall Street Journal (WSJ) portion Penn Treebank.
Goodman (1996) showed Likelihood-DOP reduced compact stochastic
context-free grammar (SCFG) contains exactly eight SCFG rules node
training set trees. Although Goodman's method still allow efficient computation
probable parse (in fact, problem computing probable parse
Likelihood-DOP NP-hard -- see Sima'an, 1996), method allow efficient
computation "maximum constituents parse", i.e. parse tree likely
largest number correct constituents. Unfortunately, Goodman's SCFG reduction method
beneficial indeed subtrees used, maximum parse accuracy usually
obtained restricting subtrees. example, Bod (2001a) shows "optimal"
subtree set achieving highest parse accuracy WSJ obtained restricting
maximum number words subtree 12 restricting maximum depth
unlexicalized subtrees 6. Goodman (2002) shows subtree restrictions,
subtree depth, may incorporated reduction method, found reduction
method optimal subtree set.
paper therefore use Bod's subtree-to-rule conversion method LikelihoodDOP, use Bod's Monte Carlo sampling technique derivation forests,
turned computationally prohibitive. Instead, use well-known Viterbi
optimization algorithm chart parsing (cf. Charniak, 1993; Manning & Schtze, 1999)
allows computing k probable derivations input cubic time. Using
algorithm, estimate probable parse tree input 10,000
probable derivations, summing probabilities derivations generate tree.
Although approach guarantee probable parse tree actually found,
shown Bod (2000a) perform least well estimation probable
parse Monte Carlo techniques ATIS corpus. Moreover, approach known
obtain significantly higher accuracy selecting parse tree generated single
probable derivation (Bod, 1998; Goodman, 2002), therefore consider
paper.
Simplicity-DOP, also first convert treebank-subtrees rewrite rules
Likelihood-DOP. Next, simplest tree, i.e. shortest derivation, efficiently
computed Viterbi optimization way probable derivation, provided
assign rules equal probabilities, case shortest derivation equal
probable derivation. seen follows: rule probability p
probability derivation involving n rules equal p n, since 0<p<1 derivation
297

fiBOD

fewest rules greatest probability. experiments Section 6, give
rule probability mass equal 1/R, R number distinct rules derived Bod's
method. mentioned 3.3, shortest derivation may unique. case
compute shortest derivations input apply ranking scheme
derivations. ranks shortest derivations computed summing ranks
subtrees involve. shortest derivation smallest sum subtree ranks
taken produce best parse tree.
SL-DOP LS-DOP, compute either n likeliest n simplest trees means
Viterbi optimization. Next, either select simplest tree among n likeliest ones (for
SL-DOP) likeliest tree among n simplest ones (for LS-DOP). experiments, n
never larger 1,000.

5. Test Domains
linguistic test domain used Wall Street Journal (WSJ) portion Penn
Treebank (Marcus et al. 1993). portion contains approx. 50,000 sentences
manually annotated perceived linguistic tree structures using predefined set
lexico-syntactic labels. Since WSJ extensively used described
literature (cf. Manning & Schtze, 1999; Charniak, 2000; Collins, 2000; Bod, 2001a),
go here.
musical test domain used European folksongs Essen Folksong
Collection (Schaffrath, 1995; Huron, 1996), correspond approx. 6,200 folksongs
manually enriched perceived musical grouping structures. Essen
Folksong Collection previously used Bod (2001b) Temperley (2001) test
musical parsers. current paper presents first experiments Likelihood-DOP,
Simplicity-DOP, SL-DOP LS-DOP collection. Essen folksongs
represented staff notation encoded Essen Associative Code (ESAC).
pitch encodings ESAC resemble "solfege": scale degree numbers used replace
movable syllables "do", "re", "mi", etc. Thus 1 corresponds "do", 2 corresponds "re", etc.
Chromatic alterations represented adding either "#" "b" number.
plus ("+") minus ("-") signs added number note falls resp.
principle octave (thus -1, 1 +1 refer al "do", different octaves).
Duration represented adding period underscore number. period (".")
increases duration 50% underscore ("_") increases duration 100%;
one underscore may added number. number duration indicator,
duration corresponds smallest value. Thus pitches ESAC encoded integers
1 7 possibly preceded followed symbols octave, chromatic alteration
duration. pitch encoding treated atomic symbol, may simple "1"
complex "+2#_.". pause represented 0, possibly followed duration
indicators, also treated atomic symbol. loudness timbre indicators used
ESAC.
Phrase boundaries indicated hard returns ESAC. phrases unlabeled (cf.
Section 1 paper). Yet make ESAC annotations readable DOP models,
added three basic labels phrase structures: label "S" whole song,
label "P" phrase, label "N" atomic symbol. way, obtained
conventional tree structures could directly employed DOP models parse new
input. use label "N" distinguishes annotations previous work (Bod,
298

fiA UNIFIED MODEL STRUCTURAL ORGANIZATION LANGUAGE MUSIC

2001b/c) used labels song phrase ("S" "P"). addition "N"
enhances productivity robustness musical parsing model, although also leads
much larger number subtrees.
example, assume simple melody consisting two phrases, (1 2) (2 3),
tree structure given Figure 7.

P

P

N

N

N

N

1

2

2

3

Figure 7: Example musical tree structure consisting two phrases
Subtrees extracted tree structure include following:

P
N

P
P

N

N

N

N

2

3

3

1

Figure 8: subtrees extracted tree figure 7
Thus first subtree indicates phrase starting note 1, followed exactly one
(unspecified) note, phrase followed exactly one (unspecified) phrase.
subtrees used parse new musical input way explained
linguistic parsing Section 3.

6. Experimental Evaluation Comparison
evaluate DOP models, used blind testing method randomly divides
treebank training set test set, strings test set parsed
means subtrees training set. applied standard PARSEVAL metrics
precision recall compare proposed parse tree P corresponding correct test
set parse tree follows (cf. Black et al. 1991):
# correct constituents P

# correct constituents P

Precision =

Recall =

# constituents P

# constituents

constituent P "correct" exists constituent label spans
atomic symbols (i.e. words notes).3 Since precision recall obtain rather
3 precision recall scores computed using "evalb" program (available via

http://www.cs.nyu.edu/cs/projects/proteus/evalb/)

299

fiBOD

different results (see Bod, 2001b), often balanced single measure
performance, known F-score (see Manning & Schtze, 1999):
F-score =

2 Precision Recall
Precision + Recall

experiments, divided treebanks (i.e. WSJ Essen Folksong
Collection) 10 training/test set splits: 10% WSJ used test material time
(sentences 40 words), Essen Folksong Collection test sets 1,000 folksongs
used time. words test set unknown training set,
guessed categories using statistics word-endings, hyphenation capitalization
(cf. Bod, 2001a); unknown notes. previous work (Bod, 2001a), limited
maximum size subtrees depth 14, used random samples 400,000 subtrees
depth > 1 14.4 Next, restricted maximum number atomic symbols
subtree 12 maximum depth unlexicalized subtrees 6. subtrees
smoothed technique described Bod (1998: 85-94) based simple Good-Turing
estimation (Good, 1953).
Table 1 shows mean F-scores obtained SL-DOP LS-DOP language
music various values n. Recall n=1, SL-DOP equal Likelihood-DOP
LS-DOP equal Simplicity-DOP.

n
1
5
10
11
12
13
14
15
20
50
100
1,000

SL-DOP

LS-DOP

(simplest among n likeliest)

(likeliest among n simplest)

Language

Music

Language

Music

87.9%
89.3%
90.2%
90.2%
90.2%
90.2%
90.2%
90.2%
90.0%
88.7%
86.8%
85.6%

86.0%
86.8%
87.2%
87.3%
87.3%
87.3%
87.2%
87.2%
86.9%
85.6%
84.3%
84.3%

85.6%
86.1%
87.0%
87.0%
87.0%
87.0%
87.0%
87.0%
87.1%
87.4%
87.9%
87.9%

84.3%
85.5%
85.7%
85.7%
85.7%
85.7%
85.7%
85.7%
85.7%
86.0%
86.0%
86.0%

Table 1: F-scores obtained SL-DOP LS-DOP language music

4 random subtree samples selected first exhaustively computing complete set

subtrees (this computationally prohibitive). Instead, particular depth > 1 sampled
subtrees randomly selecting node random tree training set, selected
random expansions node subtree particular depth obtained. repeated
procedure 400,000 times depth > 1 14.

300

fiA UNIFIED MODEL STRUCTURAL ORGANIZATION LANGUAGE MUSIC

Table shows increase accuracy SL-DOP LS-DOP
value n increases 1 11. accuracy SL-DOP decreases n=13
converges Simplicity-DOP (i.e. LS-DOP n=1), accuracy LS-DOP continues
increase converges Likelihood-DOP (i.e. SL-DOP n=1). highest accuracy
obtained SL-DOP 11 n 13, language music. Thus SL-DOP outperforms
Likelihood-DOP Simplicity-DOP, selection simplest structure
top likeliest ones turns promising model selection likeliest
structure top simplest ones. According paired t-testing, accuracy
improvement SL-DOP n=11 SL-DOP n=1 (when equal Likelihood-DOP)
statistically significant language (p<.0001) music (p<.006).
surprising SL-DOP reaches highest accuracy small value n.
even surprising exactly model (with parameter setting) obtains
maximum accuracy language music. model embodies idea
perceptual system strives simplest structure searches among
probable structures.
compare results language others, also tested SL-DOP n=11
standard division WSJ, uses sections 2 21 training (approx. 40,000
sentences) section 23 testing (2416 sentences 100 words) (see e.g. Manning &
Schtze, 1999; Charniak, 2000; Collins, 2000). division, SL-DOP achieved F-score
90.7% best previous models obtained F-score 89.7% (Collins, 2000; Bod,
2001a). terms error reduction, SL-DOP improves 9.6% models.
common also report accuracy sentences 40 words WSJ, SLDOP obtained F-score 91.8%.
musical results compared Bod (2001b/c), tested three probabilistic
parsing models increasing complexity training/test set splits Essen
Folksong Collection. best results obtained hybrid DOP-Markov parser:
80.7% F-score. significantly worse best result 87.3% obtained SL-DOP
splits Essen folksongs. difference may explained fact
hybrid DOP-Markov parser Bod (2001b/c) takes account context higher
nodes tree sister nodes, DOP models presented
current paper take subtree account (almost) arbitrary width depth, thereby
covering larger amount musical context. Moreover, mentioned Section 5, models
Bod (2001b/c) use label "N" notes; instead, Markov approach used
parse new sequences notes.
would also interesting compare musical results melodic parser
Temperley (2001), uses system preference rules similar Lerdahl Jackendoff
(1983), also evaluated Essen Folksong Collection.
tested several test sets 1,000 randomly selected folksongs, Temperley used one test
set 65 folksongs moreover cleaned eliminating folksongs irregular
meter (Temperley, 2001: 74). therefore difficult compare results Temperley's;
yet, noteworthy Temperley's parser correctly identified 75.5% phrase
boundaries. Although lower 87.3% obtained SL-DOP, Temperley's parser
"trained" previously analyzed examples like model (though note
Temperley's results obtained tuning optimal phrase length parser
average phrase length Essen Folksong Collection).
perhaps mentioned parsing models trained treebanks widely
used natural language processing, still rather uncommon musical processing.
301

fiBOD

musical parsing models, including Temperley's, employ rule-based approach
parsing based combination low-level rules -- "prefer phrase boundaries
large intervals" -- higher-level rules -- "prefer phrase boundaries changes
harmony". low-level rules usually based well-known Gestalt principles
proximity similarity (Wertheimer, 1923), prefer phrase boundaries larger
intervallic distances. However, Bod (2001c) shown Gestalt principles
predict incorrect phrase boundaries number folksongs, higher-level
phenomena cannot alleviate incorrect predictions. folksongs contain phrase
boundary falls large pitch time interval (which called
jump-phrases) rather intervals -- would predicted Gestalt principles.
Moreover, musical factors, melodic parallelism, meter harmony, predict
exactly incorrect phrase boundaries cases (see Bod, 2001b/c details).
conjectured jump-phrases inherently memory-based, reflecting idiomdependent pitch contours (cf. Huron, 1996; Snyder, 2000), best captured
memory-based model tries mimic musical experience listener
certain culture (Bod, 2001c).

7. Discussion Conclusion
seen combination simplicity likelihood quite rewarding linguistic
musical structuring, suggesting interesting parallel two modalities. Yet, one
may question whether model massively memorizes re-uses previously perceived
structures cognitive plausibility. Although question important want
claim cognitive relevance model, appears evidence people store
various kinds previously heard fragments, language (Jurafsky, 2002) music
(Saffran et al. 2000). people store fragments arbitrary size, proposed DOP?
overview article, Jurafsky (2002) reports large body psycholinguistic evidence
showing people store lexical items bigrams, also frequent phrases
even whole sentences. case sentences, people store idiomatic sentences,
also "regular" high-frequency sentences.5 Thus, least language
evidence humans store fragments arbitrary size provided fragments
certain minimal frequency. suggests humans need always parse new input
rules grammar, productively re-use previously analyzed fragments.
Yet, evidence people store fragments hear, suggested DOP.
high-frequency fragments seem memorized. However, human perceptual
faculty needs learn fragments stored, initially need keep track
fragments (with possibility forgetting them) otherwise frequencies never
accumulate. results model continuously incrementally updates fragment
memory given new input -- correspondence DOP approach, also
approaches (cf. Daelemans, 1999; Scha et al. 1999; Spiro, 2002).
acknowledge importance rule-based system acquiring fragment memory,
substantial memory available may efficient construct tree means
already parsed fragments constructing entirely means rules. many cognitive
5 results derived differences reaction times sentence recognition

frequency (whole) test sentences varied, variables, lexical frequency,
bigram frequency, plausibility, syntactic/semantic complexity, etc., kept constant.

302

fiA UNIFIED MODEL STRUCTURAL ORGANIZATION LANGUAGE MUSIC

activities advantageous store results, immediately retrieved
memory, rather computing time scratch. shown,
example, manual reaches (Rosenbaum et al. 1992), arithmetic operations (Rickard et al.
1994), word formation (Baayen et al. 1997), mention few. linguistic musical
parsing may exception this.
stressed experiments reported paper limited least two
respects. First, musical test domain rather restricted. wide variety linguistic
treebanks currently available (see Manning & Schtze, 1999), number musical
treebanks extremely limited. thus need larger richer annotated musical
corpora covering broader domains. development annotated corpora may timeconsuming, experience natural language processing shown worth
effort, since corpus-based parsing systems dramatically outperform grammar-based parsing
systems. second limitation experiments evaluated parse
results rather parse process. is, assessed accurately
models mimic input-output behavior human annotator, without investigating
process annotator arrived perceived structures. unlikely humans
process perceptual input computing 10,000 likely derivations using random samples
400,000 subtrees current paper. Yet, many applications suffices
know perceived structure rather process led structure.
seen combination simplicity likelihood predicts perceived structure
high degree accuracy.
proposals integrating principles simplicity likelihood
human perception (see Chater, 1999 review). Chater notes context
Information Theory (Shannon, 1948), principles simplicity likelihood identical.
context, simplicity principle interpreted minimizing expected length encode
message i, log2 p bits, leads result maximizing
probability i. used information-theoretical definition simplest structure
Simplicity-DOP, would return structure Likelihood-DOP, improved
results would obtained combination two. hand, defining
simplest structure one generated smallest number subtrees, independent
probabilities, created notion simplicity provably different notion
likely structure, which, combined Likelihood-DOP, obtained improved results.
Another integration two principles may provided notion Minimum
Description Length MDL (cf. Rissanen, 1978). MDL principle viewed
preferring statistical model allows shortest encoding training data.
relevant encoding consists two parts: first part encodes model data,
second part encodes data terms model (in bit length). MDL closely related
stochastic complexity (Rissanen, 1989) Kolmogorov complexity (Li Vitanyi, 1997),
used natural language processing estimating parameters stochastic
grammar (e.g. Osborne, 1999). leave open research question whether
MDL successfully used estimating parameters DOP's subtrees. However,
since MDL known give asymptotically results maximum likelihood estimation
(MLE) (Rissanen, 1989), application DOP may lead unproductive model.
maximum likelihood estimator assign training set trees empirical
frequencies, assign 0 weight trees (see Bonnema, 2002 proof).
would result model generate training data strings.
Johnson (2002) argues may overlearning problem rather problem
303

fiBOD

MLE per se, standard methods, cross-validation regularization, would seem
principle ways avoid overlearning. leave issue future
investigation.
idea general underlying model language music uncontroversial.
linguistics usually assumed humans separate language faculty, Lerdahl
Jackendoff (1983) argued separate music faculty. work propose
separate faculties exist, wants focus commonalities rather
differences faculties, aiming finding deeper "faculty" may hold
perception general. hypothesis perceptual system strives simplest
structure searches among likeliest structures.

Acknowledgements
Thanks Aline Honingh, Remko Scha, Neta Spiro, Menno van Zaanen three anonymous
reviewers excellent comments. preliminary version paper presented
keynote talk LCG workshop ("Learning Computational Grammars", Tbingen, 2001).

References
Baayen, R. H., Dijkstra, T. & Schreuder, R. (1997). Singular Plurals Dutch: Evidence
Parallel Dual-Route Model. Journal Memory Language, 37, 94-117.
Black, E., Abney, S., Flickinger, D., Gnadiec, C., Grishman, R., Harrison, P., Hindle, D.,
Ingria, R., Jelinek, F., Klavans, J., Liberman, M., Marcus, M., Roukos, S., Santorini, B.
& Strzalkowski, T. (1991). Procedure Quantitatively Comparing Syntactic
Coverage English, Proceedings DARPA Speech Natural Language
Workshop, Pacific Grove, Morgan Kaufmann.
Bod, R. (1993). Using Annotated Language Corpus Virtual Stochastic Grammar.
Proceedings AAAI-93, Menlo Park, Ca.
Bod, R. (1998). Beyond Grammar: Experience-Based Theory Language. Stanford:
CSLI Publications (Lecture notes number 88).
Bod, R. (2000a). Parsing Shortest Derivation. Proceedings COLING-2000,
Saarbrcken, Germany.
Bod, R. (2000b). Combining Semantic Syntactic Structure Language Modeling.
Proceedings ICSLP-2000, Beijing, China.
Bod, R. (2001a). Minimal Set Fragments Achieves Maximal Parse
Accuracy? Proceedings ACL'2001, Toulouse, France.
Bod, R. (2001b). Memory-Based Model Music Analysis. Proceedings International
Computer Music Conference (ICMC'2001), Havana, Cuba.
Bod, R. (2001c). Memory-Based Models Melodic Analysis: Challenging Gestalt
Principles. Journal New Music Research, 31(1), 26-36. (available
http://staff.science.uva.nl/~rens/jnmr01.pdf)
304

fiA UNIFIED MODEL STRUCTURAL ORGANIZATION LANGUAGE MUSIC

Bod, R., Hay, J. & Jannedy, S. (Eds.) (2002a). Probabilistic Linguistics. Cambridge,
MIT Press. (in press)
Bod, R., Scha, R. & Sima'an, K. (Eds.) (2002b). Data-Oriented Parsing. Stanford, CSLI
Publications. (in press)
Bonnema, R. (2002). Probability Models DOP. Bod et al. (2002b).
Bonnema, R., Bod, R. & Scha, R. (1997). DOP Model Semantic Interpretation,
Proceedings ACL/EACL-97, Madrid, Spain.
Buffart, H., Leeuwenberg, E. & Restle , F. (1983). Analysis Ambiguity Visual Pattern
Completion. Journal Experimental Psychology: Human Perception
Performance. 9, 980-1000.
Charniak, E. (1993). Statistical Language Learning, Cambridge, MIT Press.
Charniak, E. (1997). Statistical Techniques Natural Language Parsing, AI Magazine,
Winter 1997, 32-43.
Charniak, E. (2000). Maximum-Entropy-Inspired Parser. Proceedings ANLPNAACL'2000, Seattle, Washington.
Chater, N. (1999). Search Simplicity: Fundamental Cognitive Principle?
Quarterly Journal Experimental Psychology, 52A(2), 273-302.
Chomsky, N. (1965). Aspects Theory Syntax, Cambridge, MIT Press.
Collard, R., Vos, P. & Leeuwenberg, E. (1981). Melody Tells Metre Music .
Zeitschrift fr Psychologie. 189, 25-33.
Collins, M. (1999). Head-Driven Statistical Models Natural Language Parsing, PhDthesis, University Pennsylvania, PA.
Collins, M. (2000). Discriminative Reranking Natural Language Parsing, Proceedings
ICML-2000, Stanford, Ca.
Collins, M. & Duffy, N. (2002). New Ranking Algorithms Parsing Tagging: Kernels
Discrete Structures, Voted Perceptron. Proceedings ACL'2002,
Philadelphia, PA.
Daelemans, W. (1999). Introduction Special Issue Memory-Based Language
Processing. Journal Experimental Theoretical Artificial Intelligence 11(3),
287-296.
Dastani, M. (1998). Languages Perception. ILLC Dissertation Series 1998-05, University
Amsterdam.
Dempster, A., Laird, N. & Rubin, D. (1977). Maximum Likelihood Incomplete Data via
EM Algorithm, Journal Royal Statistical Society, 39, 1-38.

305

fiBOD

De Pauw, G. (2000). Aspects Pattern-matching Data-Oriented Parsing, Proceedings
COLING-2000, Saarbrcken, Germany.
Eisner, J. (1997). Bilexical Grammars Cubic-Time Probabilistic Parser, Proceedings
Fifth International Workshop Parsing Technologies, Boston, Mass.
Frazier, L. (1978). Comprehending Sentences: Syntactic Parsing Strategies. PhD.
Thesis, University Connecticut.
Good, I. (1953). Population Frequencies Species Estimation Population
Parameters, Biometrika 40, 237-264.
Goodman, J. (1996). Efficient Algorithms Parsing DOP Model, Proceedings
Empirical Methods Natural Language Processing, Philadelphia, PA.
Goodman, J. (2002). Efficient Parsing DOP PCFG-Reductions. Bod et al. 2002b.
von Helmholtz, H. (1910). Treatise Physiological Optics (Vol. 3), Dover, New York.
Hoffman, D. (1998). Visual Intelligence. New York, Norton & Company, Inc.
Huron, D. (1996). Melodic Arch Western Folksongs. Computing Musicology 10, 223.
Johnson, M. (2002). DOP Estimation Method Biased Inconsistent. Computational
Linguistics, 28, 71-76.
Jurafsky, D. (2002). Probabilistic Modeling Psycholinguistics: Comprehension
Production. Bod et al. 2002a. (available http://www.colorado.edu/ling/jurafsky/
prob.ps)
Kersten, D. (1999). High-level vision statistical inference. Gazzaniga , S. (Ed.), New
Cognitive Neurosciences, Cambridge, MIT Press.
Leeuwenberg, E. (1971). Perceptual Coding Language Perceptual Auditory
Patterns. American Journal Psychology. 84, 307-349.
Lerdahl, F. & Jackendoff, R. (1983). Generative Theory Tonal Music. Cambridge,
MIT Press.
Li, M. & Vitanyi, P. (1997). Introduction Kolmogorov Complexity
Applications (2nd ed.). New York, Springer.
Longuet-Higgins, H. (1976). Perception Melodies. Nature 263, 646-653.
Longuet-Higgins, H. Lee, C. (1987). Rhythmic Interpretation Monophonic Music.
Mental Processes: Studies Cognitive Science, Cambridge, MIT Press.
Manning, C. & Schtze, H. (1999). Foundations Statistical Natural Language
Processing. Cambridge, MIT Press.
Marcus, M., Santorini, B., & Marcinkiewicz, M. (1993). Building Large Annotated Corpus
English: Penn Treebank, Computational Linguistics 19(2).
306

fiA UNIFIED MODEL STRUCTURAL ORGANIZATION LANGUAGE MUSIC

Marr, D. (1982). Vision. San Francisco, Freeman.
Martin, W., Church, K. & Patil, R. (1987). Preliminary Analysis Breadth-first Parsing
Algorithm: Theoretical Experimental Results. Bolc, L. (Ed.), Natural Language
Parsing Systems, Springer Verlag, Berlin.
Mumford, D. (1999). dawning age stochasticity. Based lecture
Accademia Nazionale dei Lincei. (available http://www.dam.brown.edu/people/
mumford/Papers/Dawning.ps)
Osborne, M. (1999). Minimal description length-based induction definite clause grammars
noun phrase identification. Proceedings EACL Workshop Computational
Natural Language Learning. Bergen, Norway.
Palmer, S. (1977). Hierarchical Structure Perceptual Representation. Cognitive
Psychology, 9, 441-474.
Raphael, C. (1999). Automatic Segmentation Acoustic Musical Signals Using Hidden
Markov Models. IEEE Transactions Pattern Analysis Machine Intelligence,
21(4), 360-370.
Restle , F. (1970). Theory Serial Pattern Learning: Structural Trees. Psychological
Review, 86, 1-24.
Rickard, T., Healy, A. & Bourne Jr., E. (1994). cognitive structure basic arithmetic
skills: Operation, order symbol transfer effects. Journal Experimental
Psychology: Learning, Memory Cognition, 20, 1139-1153.
Rissanen, J. (1978). Modeling shortest data description. Automatica, 14, 465-471.
Rissanen, J. (1989). Stochastic Complexity Statistical Inquiry. Series Computer
Science - Volume 15. World Scientific, 1989.
Rosenbaum, D., Vaughan, J., Barnes, H. & Jorgensen, M. (1992). Time course movement
planning: Selection handgrips object manipulation. Journal Experimental
Psychology: Learning, Memory Cognition, 18, 1058-1073.
Saffran, J., Loman, M. & Robertson, R. (2000). Infant Memory Musical Experiences.
Cognition, 77, B16-23.
Scha, R., Bod, R. & Sima'an, K. (1999). Memory-Based Syntactic Analysis. Journal
Experimental Theoretical Artificial Intelligence, 11(3), 409-440.
Schaffrath, H. (1995). Essen Folksong Collection Humdrum Kern Format. D.
Huron (ed.). Menlo Park, CA: Center Computer Assisted Research
Humanities.
Shannon, C. (1948). Mathematical Theory Communication. Bell System Technical
Journal. 27, 379-423, 623-656.
Sima'an, K. (1996). Computational Complexity Probabilistic Disambiguation means
Tree Grammars. Proceedings COLING-96, Copenhagen, Denmark.
307

fiBOD

Simon, H. (1972). Complexity Representation Patterned Sequences Symbols.
Psychological Review. 79, 369-382.
Snyder, B. (2000). Music Memory. Cambridge, MIT Press.
Spiro, N. (2002). Combining Grammar-based Memory-based Models Perception
Time Signature Phase. Anagnostopoulou, C., Ferrand, M. & Smaill, A. (Eds.).
Music Artificial Intelligence, Lecture Notes Artificial Intelligence, Vol. 2445,
Springer-Verlag, 186-197.
Temperley, D. (2001). Cognition Basic Musical Structures. Cambridge, MIT
Press.
Wertheimer, M. (1923). Untersuchungen zur Lehre von der Gestalt. Psychologische
Forschung 4, 301-350.
Wundt, W. (1901). Sprachgeschichte und Sprachpsychologie. Engelmann, Leipzig.

308

fiJournal Artificial Intelligence Research 17 (2002) 57-81

Submitted 12/01; published 8/02

Logic Reasoning Upper Probabilities
Joseph Y. Halpern
Riccardo Pucella

halpern@cs.cornell.edu
riccardo@cs.cornell.edu

Department Computer Science
Cornell University
Ithaca, NY 14853
http://www.cs.cornell.edu/home/halpern

Abstract
present propositional logic reason uncertainty events,
uncertainty modeled set probability measures assigning interval probability
event. give sound complete axiomatization logic, show
satisfiability problem NP-complete, harder satisfiability propositional
logic.

1. Introduction
Various measures exist attempt quantify uncertainty. many trained use
probability theory, probability measures obvious choice. However, probability
cannot easiliy capture certain situations interest. Consider simple example: suppose
bag 100 marbles; know 30 red know remaining 70
either blue yellow, although know exact proportion blue yellow.
modeling situation pick ball bag random, need
assign probability three different events: picking red ball (red-event), picking
blue ball (blue-event), picking yellow ball (yellow-event). clearly assign
probability .3 red-event, clear probability assign blue-event
yellow-event.
One way approach problem represent uncertainty using set probability measures, probability measure possible proportion blue yellow
balls. instance, could use set probabilities P = { : [0, .7]},
gives red-event probability .3, blue-event probability , yellow-event probability
.7 . set probabilities P assign pair functions, upper lower
probability measure, event X give supremum (respectively, infimum)
probability X according probability measures P. measures
used deal uncertainty manner described above, lower upper
probability event defines range probability event.1 (This example
viewed giving frequentist interpretation upper probabilities. Upper probabilities
also given subjective interpretation, example, considering odds
someone would willing accept reject bet (Smith, 1961; Walley, 1991).)
1. Note using sets probability measures way model situation. alternative
approach, using inner measures, studied Fagin Halpern (1991).

c
2002
AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiHalpern & Pucella

Given measure uncertainty, one define logic reasoning it. Fagin,
Halpern Megiddo (1990) (FHM on) introduce logic reasoning
probabilities, possible-worlds semantics assigns probability possible
world. provide axiomatization logic, prove sound complete
respect semantics. also show satisfiability problem logic,
somewhat surprisingly, NP-complete, hence harder satisfiability problem
propositional logic. moreover show logic extended notions
uncertainty, inner measures (Fagin & Halpern, 1991) Dempster-Shafer belief
functions (Shafer, 1976).
paper, describe logic reasoning upper probability measures, along
lines FHM logic. logic allows reasoning linear inequalities involving
upper probabilities measures. Like logics considered FHM, logic agnostic
interpretation upper probabilities, whether frequentist subjectivist.
main challenge derive provably complete axiomatization logic; this,
need characterization upper probability measures terms properties
expressed logic. Many semantic characterizations upper probability measures
proposed literature. characterization Anger Lembcke (1985) turns
best suited purposes. Even though reasoning potentially
infinite sets probability measures, satisfiability problem logic remains NPcomplete. Intuitively, need guess small number probability measures satisfy
given formula, polynomially many size formula. Moreover, probability
measures taken defined finite state space, polynomial size
formula. Thus, need basically determine polynomially many valuesa value
probability measure stateto decide satisfiability formula.
rest paper structured follows. Section 2, review required
material probability theory theory upper probabilities. Section 3,
present logic axiomatization. Section 4, prove axiomatization
sound complete respect natural semantic models expressed terms upper
probability spaces. Finally, Section 5, prove decision problem logic
NP-complete. proofs new, technical results given Appendix A.
make paper self-contained, also review Anger Lembckes results Appendix B.

2. Characterizing Upper Probability Measures
start brief review relevant definitions. Recall probability measure
function : [0, 1] algebra subsets (that closed
complements unions), satisfying () = 0, () = 1, (A B) = (A) + (B)
disjoint sets A, B .2 probability space tuple (, , ), set,
algebra subsets (the measurable sets), probability measure defined
. Given set P probability measures, let P upper probability measure defined
2. infinite, could also require -algebra (i.e., closed countable unions)
countably additive. Requiring countable additivity would affect results, since show
take finite. ease exposition, required it.

58

fiA Logic Reasoning Upper Probabilities

P (X) = sup{(X) : P} X .3 Similarly, P (X) = inf{(X) : P}
lower probability X . straightforward derivation shows relationship
P (X) = 1P (X) holds upper lower probabilities, X complement
X . duality, restrict discussion upper probability measures
paper, understanding results lower probabilities similarly
derived. Finally, upper probability space tuple (, , P) P set probability
measures .
would like set properties completely characterizes upper probability measures. words, would like set properties allow us determine
function f : R (for algebra subsets ) upper probability measure,
is, whether exists set P probability measures X ,
P (X) = f (X).4
One approach characterization upper probability measures adapt
characterization Dempster-Shafer belief functions; functions known
lower envelope probability measures dominate them, thus form subclass
class lower probability measures. duality noted earlier, characterization
lower probability measures would yield characterization upper probability measures.
characterization belief functions derived generalization following
inclusion-exclusion principle probabilities (obtained replacing equality
inequality):
(

n
[

n
X
(1)i1 (

Ai ) =

i=1

i=1

X

(

J{1,... ,n}
|J|=i

\

Aj )).

jJ

seems reasonable characterization lower (or upper) probability measures
could derived along similar lines. However, well known, properties derivable
inclusion-exclusion principle (which include properties reported
literature) insufficient characterize upper probability measures. Huber (1981, p. 257)
Walley (1991, p. 85) give examples showing insufficiencies properties.
give sense insufficiency simple properties, consider following inclusionexclusionstyle properties, taken (Walley, 1991). simplify
statement properties, let P 1 = P P +1 = P .
P P

(1) P (A1 ) ni=1 |I|=i (1)i+1 P (1) ( jI Aj ),
(2) P (A1 )

Pn P
i=1

|I|=i (1)

i+1 P (1)i+1 (



jI

Aj ),

(3) P (A B) + P (A B) P (A) + P (B) P (A B) + P (A B),
3. literature, term upper probability sometimes used restricted sense here.
example, Dempster (1967) uses term denote class measures later characterized
Dempster-Shafer belief functions (Shafer, 1976); belief functions fact upper probability measures
sense, converse true (Kyburg, 1987). measure theory literature, call
upper probability measures special case upper envelopes measures, defined
sup sets general measures, probability measures.
4. possible define notion upper probability arbitrary set subsets , necessearily
algebra, simply requiring f coincides P domain, set P probability
measures. See Walley (1991) details.

59

fiHalpern & Pucella

(4) P (A) + P (B) P (A B) + P (A B) P (A) + P (B),
(5) P (A) + P (B) P (A B) + P (A B) P (A) + P (B).
Note without alternation upper probabilities lower probabilities,
(1) (2) would standard notions subadditivity superadditivity, respectively. subadditivity superadditivity hold upper lower probabilities,
respectively, (1) (2) stronger properties. easily verified five properties
hold upper probability measures. question whether completely characterize
class upper probability measures. show inherent incompleteness
properties proving derivable following simple property,
insufficient characterize upper probability measures:
(6) B = , P (A) + P (B) P (A B) P (A) + P (B).
Proposition 2.1: Property (6) implies properties (1)-(5).
Observe property (6) already given Walley (1991, p. 84), properties (d)
(e). following example shows insufficiency Property (6). Let P set
probability measures {1 , 2 , 3 , 4 } = {a, b, c, d} (with containing subsets
) defined singletons
1 (b) =

1
4

1 (c) =

1
4

1 (d) =

1
4

2 (a) = 0 2 (b) =

1
8

2 (c) =

3
8

2 (d) =

1
2

3
8

3 (c) = 0

3 (d) =

1
2

1 (a) =

1
4

3 (a) =

1
8

3 (b) =

4 (a) =

3
8

4 (b) = 0 4 (c) =

1
8

4 (d) = 12 ,

extended additivity . defines upper probability measure P
. Consider function : [0, 1] defined

P (X) + X = {a, b, c}
(X) =
P (X)
otherwise.
claim function , small enough > 0, satisfies property (6), cannot
upper probability measure.
Proposition 2.2: 0 < < 18 , function satisfies property (6),
upper probability measure. is, cannot find set P 0 probability measures
= (P 0 ) .
example clearly illustrates need go beyond inclusion-exclusion principle
find properties characterize upper probability measures. turns out, various
complete characterizations described literature (Lorentz, 1952; Huber,
1976, 1981; Williams, 1976; Wolf, 1977; Giles, 1982; Anger & Lembcke, 1985; Walley, 1991).
characterizations obtained considering upper lower expectations,
rather working directly upper lower probabilities. Anger Lembcke (1985)
60

fiA Logic Reasoning Upper Probabilities

give characterization terms upper lower probabilities. Since characterization
particularly well-suited logic presented next section, review here.
characterization based notion set cover. set said covered
n times multiset {{A1 , . . . , }} sets every element appears least
n sets A1 , . . . , : x A, exists distinct i1 , . . . , {1, . . . , m}
j n, x Aij . important note {{A1 , . . . , }} multiset, set; Ai necessarily distinct. (We use {{ }} notation denote
multisets.) (n, k)-cover (A, ) multiset {{A1 , . . . , }} covers k times
covers n + k times. example, {{1, 2}, {2, 3}, {1, 3}} covers {1, 2, 3} 2 times,
{{{1, 2}, {2, 3}, {1, 3}, {2}, {2}}} (2,2) cover ({2}, {1, 2, 3}).
notion (n, k)-cover key concept Anger Lembckes characterization
upper probability measures.
Theorem 2.3: (Anger & Lembcke, 1985) Suppose set, algebra subsets
, : R. exists set P probability measures = P
satisfies following three properties:
UP1. () = 0,
UP2. () = 1,
UP3. natural numbers m, n, k subsets A1P
, . . . , , {{A1 , . . . , }}
(n, k)-cover (A, ), k + n(A)
i=1 (Ai ).
Proof: reproduce proof result Appendix B.
Note UP1 redundant presence UP2 UP3. Indeed, {{, }}
(0, 1)-cover (, ), applying UP3 yields () + () = 1. Since UP2 states
() = 1, means () = 0. consequence UP3 B,
(A) (B), since {{B}} (1, 0)-cover (A, ). Therefore, , (A) [0, 1].
need strengthen Theorem 2.3 order prove main result paper,
namely, completeness axiomatization logic introduce next section.
show cardinality state space finite, need finitely
many instances property UP3. Notice cannot derive Theorem 2.3
alone: even || finite, UP3 provide bound m, number sets
consider (n, k) cover set A. Indeed, seem priori reason
value m, n, k bounded. Bounding value (and hence n
k, since larger m) one key technical results paper,
necessary foundation work.
Theorem 2.4: exist constants B0 , B1 , . . . finite set,
algebra subsets , : R, exists set P probability measures
= P satisfies following properties:
UPF1. () = 0,
UPF2. () = 1,
UPF3. integers m, n, k B|| sets A1 , P
. . . , , {{A1 , . . . , }}
(n, k)-cover (A, ), k + n(A)
i=1 (Ai ).
61

fiHalpern & Pucella

Property UPF3 significantly weaker UP3. principle, checking UP3
holds given function requires checking holds arbitrarily large collections
sets, even underlying set finite. hand, UPF3 guarantees
finite, fact sufficient look collections size B|| . observation
key completeness result.
Theorem 2.4 prescribe values constants B0 , B1 , . . . . Indeed,
proof found Appendix relies Ramsey-theoretic argument even
provide bound Bi s. could certainly attempt obtain bounds,
obtaining completely unnecessary purposes. get completeness
axiomatization logic introduced next section, sufficient exist
finite constants B0 , B1 , . . . .

3. Logic
syntax logic straightforward, taken FHM. fix set 0 =
{p1 , p2 , . . . } primitive propositions. set propositional formulas closure
0 . assume special propositional formula true, abbreviate
true false. use p represent primitive propositions, represent
propositional formulas. term expression form 1 l(1 ) + + k l(k ),
1 , . . . , k reals k 1. basic likelihood formula statement form ,
term real. likelihood formula Boolean combination basic
likelihood formulas. use f g represent likelihood formulas. use obvious
abbreviations needed, l() l() l() + (1)l() a, l() l()
l() l() 0, l() l() a, l() < (l() a) l() =
(l() a) (l() a). Define length |f | likelihood formula f number
symbols required write f , coefficient counted one symbol. Let LQU
language consisting likelihood formulas. (The QU stands quantitative uncertainty.
name logic taken (Halpern, 2002).)
FHM, operator l interpreted either probability belief (in sense
Dempster-Shafer). first interpretation, formula l() + l() 2/3
would intereted probability plus probability least 2/3.
interpret l upper probaiblity. Thus, logic allows us make statements
inequalities involving upper probabilities.
capture interpretation, assign semantics formulas LQU using upper
probability space, defined Section 2. Formally, upper probability structure
tuple = (, , P, ) (, , P) upper probability space associates
state (or world) truth assignment primitive propositions 0 . Thus,
(s)(p) {true, false} p 0 . Let [[p]]M = {s : (s)(p) = true}.
call measurable p 0 , [[p]]M measurable. measurable
[[]]M measurable propositional formulas . paper, restrict attention
measurable upper probability structures. Extend (s) truth assignment
propositional formulas standard way, associate propositional formula
set [[]]M = {s : (s)() = true}. easy structural induction shows [[]]M

62

fiA Logic Reasoning Upper Probabilities

measurable set. = (, , P, ), let
|= 1 l(1 ) + + k l(k ) iff 1 P ([[1 ]]M ) + + k P ([[k ]]M )
|= f iff 6|= f
|= f g iff |= f |= g.
Note LQU express lower probabilities: follows duality upper
lower probabilities |= l() 1 iff P ([[]]M ) .5
Consider following axiomatization AXup upper probability, prove sound
complete next section. key axioms simply translation LQU
characterization upper probability given Theorem 2.3. FHM, AXup divided
three parts, dealing respectively propositional reasoning, reasoning linear
inequalities, reasoning upper probabilities.
Propositional reasoning
Taut. instances propositional tautologies LQU (see below).
MP. f f = g infer g.
Reasoning linear inequalities
Ineq. instances valid formulas linear inequalities (see below).
Reasoning upper probabilities
L1. l(false) = 0.
L2. l(true) = 1.
L3. l() 0.
W
V
L4. l(1 ) + + l(m ) nl() k J{1,... ,m}, |J|=k+n jJ j
W
V
6
J{1,... ,m}, |J|=k jJ j propositional tautologies.
L5. l() = l() propositional tautology.
difference AXup axiomatization reasoning probability
given FHM axiom l( ) + l( ) = l() FHM, expresses
additivity probability, replaced L4. Although may immediately
obvious, L4 logical analogue SUP3. see this,
first note {{A1 , . . . , }}
covers


times






J{1,... ,m}, |J|=n jJ Aj . Thus, formula
W
V

says


(more
J{1,... ,m}, |J|=k+n jJ j
Wprecisely, setVof worlds true)
covered k +n times {{1 , . . . , n }}, J{1,... ,m}, |J|=k jJ j says whole
space covered k times {{1 , . . . , n }}; roughly speaking, multiset {{1 , . . . , n }}
(n, k)-cover (, true). conclusion L4 thus corresponds conclusion
5. Another approach, keeping FHM, would interpret l lower probability measure.
hand, interpreting l upper probability measure keeping literature
upper probabilities.
6. Note that, according syntax LQU , 1 , . . . , must propositional formulas.

63

fiHalpern & Pucella

UP3. Note way UP1 follows UP2 UP3, axiom L1 (as
well L3) follows L2 L4.
Instances Taut include formulas form f f , f arbitrary
formula LQU . could replace Taut simple collection axioms characterize
propositional reasoning (see, example, (Mendelson, 1964)), chosen focus
aspects reasoning upper probability.
FHM, axiom Ineq includes valid formulas linear inequalities.
inequality formula formula form a1 x1 + + xn c, variables x1 , . . . , xn .
inequality formula said valid true every possible assignment real
numbers variables. get instance Ineq, replace variable xi occurs
valid inequality formula primitive likelihood term form l(i ) (naturally
occurence variable xi must replaced primitive likelihood term l(i )).
Taut, replace Ineq sound complete axiomatization Boolean
combinations linear inequalities. One axiomatization given FHM.

4. Soundness Completeness
formula f provable axiom system AX f proven using axioms
rules inferences AX. AX sound respect class structures every
formula provable AX valid (i.e., valid every structure M); AX complete
respect every formula valid provable AX.
goal prove AXup sound complete axiomatization reasoning
upper probability (i.e., respect upper probability structures). soundness
AXup immediate earlier disscussion. Completeness is, usual, harder. Unfortunately, standard technique proving completeness modal logic, involves
considering maximal consistent sets canonical structures (see, example, (Popkorn,
1994)) work. briefly review approach, point difficulties.
standard approach uses following definitions. formula consistent
axiom system AX provable AX. finite set formulas {1 , . . . , n }
consistent AX formula 1 n consistent AX; infinite set
formulas consistent AX finite subsets consistent AX. F
maximal AX-consistent set F consistent AX strict superset F
consistent AX. AX includes Taut MP, hard show, using
propositional reasoning, every AX-consistent set formulas extended
maximal AX-consistent set.
show AX complete respect class structures, must show
every formula valid provable AX. this, sufficient show
every AX-consistent formula satisfiable structure M. Typically,
done constructing called canonical structure c whose states
maximal AX-consistent sets, showing formula satisfied world w
c iff one formulas canonical set associated world w.
Unfortunately, approach cannot used prove completeness here. see this,
consider set formulas
F 0 = {l()

1
, n = 1, 2, . . . } {l() > 0}.
n
64

fiA Logic Reasoning Upper Probabilities

set clearly AXup consistent according definition, since every finite subset
satisfiable upper probability structure AXup sound respect upper
probability structures. thus extended maximal AXup consistent set F .
However, set F 0 formulas satisfiable: possible assign l() value
satisfy formulas time. Hence, F satisfiable. Thus,
canonical model approach, least applied naively, simply work.
take different approach here, similar one taken FHM. try
construct single canonical model. course, still must show formula f
AXup -consistent satisfiable upper probability structure.
explicit construction, depending f . proceed follows.
simple argument, easily reduce problem case f
conjunction basic likelihood formulas negations basic likelihood formulas. Let
N
p1 , . . . , pN primitive propositions appear f . Observe 22
inequivalent propositional formulas p1 , . . . , pN . argument goes follows. Let
atom p1 , . . . , pN formula form q1 . . . qN , qi either pi pi .
clearly 2N atoms p1 , . . . , pN . Moreover, easy see formula
N
p1 , . . . , pN written unique way disjunction atoms. 22
disjunctions, claim follows.
Continuing construction structure satisfying f , let 1 , . . . , 22N
canonical listing inequivalent formulas p1 , . . . , pN . Without loss generality, assume 1 equivalent true, 22N equivalent false. Since every propositional formula p1 , . . . , pN provably equivalent , follows
f provably equivalent formula f 0 conjunct f 0 form
1 l(1 ) + + 22N l(22N ) . Note negation formula form
1 l(1 ) + + 22N l(22N ) < or, equivalently, (1 )l(1 ) + + (22N )l(22N ) > .
Thus, formula f gives rise natural way system inequalities form:
1,1 l(1 ) + + 1,22N l(22N )
...
r,1 l(1 ) + + r,22N l(22N )
0 l( ) + + 0
1,1
1
N l(22N )
1,22
..
.
0
s,1 l(1 ) + + 0 2N l(22N )
s,2

1
..
..
.
.
r
> 1
..
..
.
.
> .

(1)

express (1) conjunction inequality formulas, replacing occurrence
l(i ) (1) xi . Call inequality formula f .
f satisfiable upper probability structure , take xi
upper probability ; gives solution f . However, f may solution
without f satisfiable. example, f formula l(p) = 1/2 l(p) = 0,
f obvious solution; f , however, satisfiable upper probability structure,
upper probability set corresponding p upper probability
set corresponding p must sum least 1 upper probability structures. Thus,
must add constraints solution force act like upper probability.
UP1UP3 or, equivalently, axioms L1L4, describe exactly additional constraints needed. constraint corresponding L1 (or UP1) x1 = 0, since
65

fiHalpern & Pucella

assumed 1 formula false. Similarly, constraint corresponding L2
N
x22N = 1. constraint corresponding L3 xi 0, = 1, . . . , 22 .
L4? seems require infinite collection constraints, UP3 does.7
UPF3 comes play. turns that, f satisfiable all,
satisfiable structure 2N worlds, one atom p1 , . . . , pN .
Thus, need add instances L4 k, m, n < B2N 1 , . . . , ,
among 1 , . . . , 22N . Although large number formulas (in fact, know
exactly large, since depends B2N , computed), suffices
purposes finite number. instances L4, inequality
form a1 x1 + + a22N x22N k. Let f, inequality formula corresponding f ,
conjunction consisting f , together inequalities corresponding
relevant instances L4, equations inequalities x1 = 0, x22N = 1, xi 0
N
= 1, . . . , 22 , corresponding axioms L1L3.
Proposition 4.1: formula f satisfiable upper probability structure iff
inequality formula f solution. Moreover, f solution, f satisfiable
upper probability structure 2|f | worlds.
Theorem 4.2: axiom system AXup sound complete upper probability structures.
Proof: soundness, easy see every axiom valid upper probability
structures, including L4, represents UP3.
completeness, proceed discussion above. Assume formula f
satisfiable upper probability structure; must show f AXup inconsistent.
first reduce f canonical form. Let g1 gr disjunctive normal form
expression f (where gi conjunction basic likelihood formulas
negations). Using propositional reasoning, show f provably equivalent
disjunction. Since f unsatisfiable, gi must also unsatisfiable. Thus, sufficient
show unsatisfiable conjunction basic likelihood formulas negations
inconsistent. Assume f conjunction. Using propositional reasoning axiom
N
L5, f equivalent likelihood formula f 0 refers 22 propositional formulas, say
1 , . . . , 22N . Since f unsatisfiable, f 0 . Proposition 4.1, inequality formula
f0 corresponding f 0 solution. Thus, Ineq, formula f 00 results
replacing instance xi f0 l(i ) AXup provable. conjuncts f 00
instances axioms L1L4 AXup provable. follows f 0 AXup provable,
hence f .

5. Decision Procedure
settled issue soundness completeness axiom system AXup ,
turn problem complexity deciding satisfiability. Recall problem
7. Although dealing finitely many formulas here, 1 , . . . , 22N , recall formulas
1 , . . . , L4 need distinct, potentially infinitely many instances L4 deal
with.

66

fiA Logic Reasoning Upper Probabilities

satisfiability: given likelihood formula f , want determine exists upper
probability structure |= f . show, satisfiability problem
NP-complete, thus harder satisfiability propositional logic.
decision problem make sense, need restrict language slightly.
allow real numbers coefficients likelihood formulas, carefully discuss
issue representation numbers. avoid complications, restrict
language (in section) allow integer coefficients. Note still express
rational coefficients standard trick clearing denominator. example,
express 32 l() 1 2l() 3 l() 23 3l() 2. Recall defined
|f | length f , is, number symbols required write f ,
coefficient counted one symbol. Define ||f || length longest coefficient
appearing f , written binary. size rational number ab , denoted || ab ||,
b relatively prime, defined ||a|| + ||b||.
preliminary result required analysis decision procedure shows
formula satisfied upper probability structure, satisfied structure
(, , P, ), small terms number states , cardinality
set P probability measures, size coefficients f .
Theorem 5.1: Suppose f likelihood formula satisfied upper probability
structure. f satisfied structure (, , P, ), || |f |2 , = 2 (every
subset measurable), |P| |f |, (w) rational number ||(w)||
O(|f |2 ||f || + |f |2 log(|f |)) every world w P, (w)(p) = false every
world w every primitive proposition p appearing f .
Theorem 5.2: problem deciding whether likelihood formula satisfiable
upper probability structure NP-complete.
Proof: lower bound, clear given propositional formula satisfiable iff
likelihood formula l() > 0 satisfiable, therefore satisfiability problem NP-hard.
upper bound, given likelihood formula f , guess small satisfying structure
= (, , P, ) f form guaranteed exist Theorem 5.1. describe
model size polynomial |f | ||f ||. (The fact (w)(p) = false
every world w every primitive proposition p appearing f means
must describe propositions appear f .) verify |= f follows.
Let l() arbitrary likelihood term f . compute [[]]M checking truth
assignment seeing whether
P truth assignment makes true.
replace occurence l() f maxP { s[[]]M (s)} verify resulting
expression true.

6. Conclusion
considered logic syntax logic reasoning probability, inner measures, belief presented FHM, uncertainty interpreted upper
probability set probability measures. interpretation, provided
sound complete axiomatization logic. showed satisfiability problem NP-complete (as reasoning probability, inner measures,
67

fiHalpern & Pucella

beliefs), despite deal probability structures possibility infinitely many
states infinite sets probability measures. key step axiomatization involves
finding characterization upper probability measures captured logic.
key step complexity result involves showing formula satisfiable all,
satisfiable small structure, size state space, well size
set probability measures size probabilities involved, polynomial
length formula.
Given similarity spirit results various interpretations uncertainty operator (as probability, inner measure, belief function, upper probability),
including fact complexity decision problem NP-complete cases,
conjecture underlying result results follow.
would interesting make precise.
FHM, conditional probabilities well probabilities investigated. not,
paper, discussed conditional upper probabilities. main reason that,
unlike probability, cannot characterize conditional upper probabilities terms (unconditional) upper probabilities. Thus, results really tell us nothing conditional
upper probabilities. might interest consider logic allows conditional upper probabilities primitive likelihood terms (that is, allows likelihood terms form
l( | )). intrinsic difficult giving semantics language, far
clear appropriate axiomatization would be, effect extension
complexity.
Finally, worth noting semantic framework developed FHM
fact rich enough talk gambles (that is, real-valued functions set
states) expectation gambles. Expectation functions defined
different measures uncertainty, including upper probabilities, difficult
extend FHM logic order reason expectation. One advantage working
expectation functions typically easier characterize corresponding
measures; instance, characterization expected upper probabilities much simpler
upper probabilities (Huber, 1981; Walley, 1981, 1991). However, getting
complete axiomatization quite nontrivial. refer reader (Halpern & Pucella,
2002) details subject. remark Wilson Moral (1994) take
starting point Walleys notion lower upper previsions. consider
acceptance one set gambles implies acceptance another gamble. Since acceptance
involves expectation, cannot expressed logic considered paper; however,
expressed easiliy logic (Halpern & Pucella, 2002).

Acknowledgments
preliminary version paper appears Uncertainty Artificial Intelligence, Proceedings Seventeenth Conference, 2001. Thanks Dexter Kozen, Jon Kleinberg,
Hubie Chen discussions concerning set covers. Vicky Weissman read draft paper
provided numerous helpful comments. also thank anonymous UAI JAIR
reviewers useful comments suggestions. work supported part
NSF grants IRI-96-25901 IIS-0090145, ONR grants N00014-00-1-03-

68

fiA Logic Reasoning Upper Probabilities

41, N00014-01-10-511, N00014-01-1-0795. first author also supported part
Guggenheim Fulbright Fellowship sabbatical leave; sabbatical support
CWI Hebrew University Jerusalem also gratefully acknowledged.

Appendix A. Proofs
Proposition 2.1: Property (6) implies properties (1)-(5).
Proof: introduce following auxiliary properties help derive implications:
(7) P (A) + P (B) P (A B) + P (A B).
(8) P (A) + P (B) P (A B) + P (A B).
(9) P (A B) + P (A B) P (A) + P (B).
(10) B = ,
P (A) + P (B) P (A B) P (A) + P (B) P (A B) P (A) + P (B).
Using properties, show following chain implications:

(6) = (10)

(10) = (9) = (3)
(10) = (7) = (4)
(10) = (8) = (5)

(4), (5) = (1), (2).

implication (4), (5) = (1), (2) follows easily mutual induction n.
base case following instances properties (4) (5): P (A B) P (A) + P (B)
P (A B) P (A B) P (A) + P (B) P (A B). details left reader.
prove remaining implications.
(9) = (3): Since (9) already one inequalities (3), remains show
implies inequality (3), is, P (A)+P (B) P (AB)+P (AB).
P (A B) + P (A B) = 1 P (A B) + 1 P (A B)
= 1 P (A B) + 1 P (A B)
= 2 (P (A B) + P (A B))
= 2 (P (B A) + P (B A))
2 (P (B) + P (A))
= 1 P (B) + 1 P (A)
= P (B) + P (A).

69

fiHalpern & Pucella

(7) = (4): Since (7) already one inequalities (4), remains show
implies inequality (4), is, P (AB)+P (AB) P (A)+P (B).
P (A) + P (B) = 1 P (A) + 1 P (B)
= 2 (P (A) + P (B))
2 (P (A B) + P (A B))
= 1 P (A B) + 1 P (A B)
= 1 P (A B) + 1 P (A B)
= P (A B) + P (A B).
(8) = (5): Since (8) already one inequalities (5), remains show
implies inequality (5), is, P (AB)+P (AB) P (A)+P (B).
P (A) + P (B) = 1 P (A) + 1 P (B)
= 2 (P (A) + P (B))
2 (P (A B) + P (A B))
= 1 P (A B) + 1 P (A B)
= 1 P (A B) + 1 P (A B)
= P (A B) + P (A B).
next implications, given A, B, let Z = B.
(10) = (9):
P (A B) = P ((A Z) B)
P (A Z) + P (B)

[since (A Z) B = ]

P ((A Z) Z) P (Z) + P (B)
= P (A) + P (B) P (A B).
(10) = (7):
P (A B) = P ((A Z) B)
P (A Z) + P (B)
P ((A Z) Z) P (Z) + P (B)
= P (A) + P (B) P (A B).
(10) = (8):
P (A B) = P ((A Z) B)
P (A Z) + P (B)
P ((A Z) Z) P (Z) + P (B)
= P (A) + P (B) P (A B).
70

fiA Logic Reasoning Upper Probabilities

(6) = (10): Again, since (6) already comprises two inequalities (10),
remains show implies two, is, B = ,
P (A) + P (B) P (A B) P (A) + P (B).
First, show P (A) + P (B) P (A B). Using (6), know
P (A B) + P (A) P ((A B) A) = P (B).
words, P (A B) P (B) + P (A). this, derive
P (A B) = 1 P (A B)
= 1 P (A B)
1 (P (B) P (A))
= 1 P (B) + P (A)
= P (B) + P (A).
Second, show P (A B) P (A) + P (B). Using (6), know
P (A B) + P (A) P ((A B) A) = P (B).
(The last equality follows fact (A B) = B B = .)
words, P (A B) P (B) P (A). this, derive
P (A B) = 1 P (A B)
= 1 P (A B)
1 (P (B) P (A))
= 1 P (B) + P (A)
= P (B) + P (A).
Proposition 2.2: 0 < < 18 , function satisfies property (6),
upper probability measure. is, cannot find set P 0 probability measures
= (P 0 ) .
Proof: given 0 < < 81 . easy check mechanically satisfies (6).
show set P 0 = (P 0 ) . way contradiction,
assume P 0 . properties sup, means P 0
({a, b, c}) > 43 , since ({a, b, c}) = 34 + > 34 . Consider detail. Since P,
must X , X 6= {a, b, c}, (X) (P 0 ) (X) = P (X). particular,
({a, b}), ({b, c}), ({a, c}) 21 . Therefore,
3
({a, b}) + ({b, c}) + ({a, c}) .
2

(2)

However, standard properties probability, follows
({a, b}) + ({b, c}) + ({a, c}) = 2({a, b, c}) > 2
71

3
3
= ,
4
2

fiHalpern & Pucella

contradicts (2). Therefore, , therefore P 0 cannot exist, upper
probability measure.
Theorem 2.4: exists constants B0 , B1 , . . . algebra subsets
function : R, exists set P probability measures
= P satisfies following properties:
UPF1. () = 0,
UPF2. () = 1,
UPF3. integers m, n, k B|| sets A1 , P
. . . , , {{A1 , . . . , }}
(n, k)-cover (A, ), k + n(A)
i=1 (Ai ).
Proof: view Theorem 2.3, need show exist constant B0 , B1 , . . .
function satisfies UP3 iff satisfies UPF3. Clearly, UP3 always implies
UPF3, sufficient show exists B0 , B1 , . . . UPF3 implies
UP3.
need terminology proceeding. exact (n, k)-cover (A, ) cover
C property every element appears exactly n + k sets C,
every element appears exactly k sets C. Thus, (n, k)-cover (A, )
many extra sets, long sets cover least n + k times k times,
exact cover necessary sets, right total number elements.
exact (n, k)-cover C (A, ) decomposable exists exact (n1 , k1 )-cover C1
exact (n2 , k2 )-cover C2 (A, ) C1 C2 form nontrivial partition C,
n = n1 + n2 k = k1 + k2 . Intuitively, exact cover C decomposable
split two exact covers. follows easily induction exact (n, k)cover, exists (not necessarily unique) finite set nondecomposable exact covers
C1 , . . . , Cm
Pm(ni , ki )-cover, Ci nontrivial partition C
P, mwith Ci exact
n = i=1 ni k = i=1 . (If C nondecomposable, take = 1
C1 = C.) One easily verify C exact (n, k)-cover (A, ) C 0 C
exact (n0 , k 0 )-cover (A, ) n0 + k 0 < n + k, C decomposable.
following lemma highlights important property exact covers
perspective. says set , cannot large nondecomposable
exact cover (A, ).
Lemma A.1: exists sequence B10 , B20 , B30 , . . . , every exact
0
0
(n, k)-cover (A, ) n > B||
k > B||
decomposable.
Proof: clearly sufficient show finite find B||
required properties. Fix . Given , first show exists NA
n > NA k > NA , every exact (n, k)-cover (A, ) decomposable. Suppose
sake contradiction case. means find infinite
sequence C1 , C2 , . . . Ci nondecomposable exact (ni , ki )-cover (A, ),
either n1 < n2 < . . . k1 < k2 < . . . .
derive contradiction, use following lemma, known Dicksons Lemma
(Dickson, 1913).
72

fiA Logic Reasoning Upper Probabilities

Lemma A.2: Every infinite sequence d-dimensional vectors natural
numbers contains monotonically nondecreasing subsequence pointwise
ordering (where x pointwise ordering iff xi yi i).
Proof: straightforward prove induction k k d,
every infinite sequence vectors x1 , x2 , . . . contains subsequence xi1 , xi2 , . . .
xij1 , xij2 , . . . nondecreasing sequence natural numbers
j k. base case immediate observation every infinite
sequence natural numbers contains nondecreasing subsequence.
inductive step, observe xi1 , xi2 , . . . subsequence xij1 , xij2 , . . .
nondecreasing sequence natural numbers j k, sequence
1
2
xik+1
, xik+1
, . . . natural numbers must nondecreasing subsequence.
determines subsequence original sequence appropriate property
j k + 1.
Let S1 , . . . , S2|| arbitrary ordering 2|| subsets . associate
C
C
cover C 2|| -dimensional vector xC = (xC
1 , . . . , x2|| ), xi number
times subset Si appears multiset C. key property association
0
C 0 C multisets, C 0 C iff xC xC pointwise ordering.
Consider sequence vectors xC1 , xC2 , . . . associated sequence C1 , C2 , . . .
nondecomposable exact covers (A, ). Lemma A.2, nondecreasing subsequence vectors, xCi1 xCi2 . means Ci1 Ci2 . Since
n1 < n2 < . . . k1 < k2 < . . . , every cover chain must distinct. pair
exact covers chain Ci Ci+1 , meaning Ci+1 decomposable, contradicting assumption. Therefore, must exist NA exact (n, k)-cover
n > NA k > NA decomposable.
0
= max{NA : {1, . . . , ||}}. easy see choice
define B||
works.
0 , N = 1, 2, . . . , B 0
get constants B1 , B2 , . . . , let BN = 2N BN
N
Lemma A.1. show UPF3 implies UP3 choice B1 , B2 , . . . .
Assume UPF3 holds. Fix . Suppose C = {{A1 , .P
. . , }} (n, k)-cover
(A, ) |C| = m. want show k + n(A)
i=1 (Ai ). proceed
follows.
first step show that, without loss generality, C exact (n, k)-cover
(A, ). Let Bi consist states Ai either appears
n + k sets A1 , . . . , Ai1 appears k sets
A1 , . . . , Ai1 . Let A0i = Ai Bi . Let C 0 = {{A01 , . . . , A0m }}. easy check C 0
exact (n, k)-cover (A, ). A, appears exactly n + k sets C 0 (it
appears A0j iff Aj among first n + k sets C appeared) and, similarly,
A, appears exactly k sets C 0 . Clearly UP3 holds C 0 ,
holds C, since (A0i ) (Ai ) = 1, . . . , m. Thus, assume without loss
generality C exact (n, k)-cover A.
also assume without loss generality set C empty (otherwise,
simply remove empty sets C; resulting set still (n, k)-cover
(A, )). two cases consider. max(m, n, k) B|| , desired result

73

fiHalpern & Pucella

follows UPF3. not, consider decomposition C multisets C1 , . . . , Cp ,
Ch exact (nh , kh )-cover (A, ) decomposable. claim
max(|Ch |, nh , kh ) B|| h = 1, . . . , p. nh > B|| kh > B|| ,
immediate Lemma A.1 Ch decomposed, contradicting
fact
P
Ch decomposable. |Ch | > B|| , observe XCh |X| |Ch |.
0 , must appears least 2B 0
Since |Ch | > B|| = 2||B||
||
0 k > B 0 .
sets Ch . Since Ch exact (nh , kh )-cover, follows either nh > B||
h
||
then, Lemma A.1, Ch decomposable, contradiction.
apply UPF3 C1 , . . . , Ck get
X
(X) nh (A) kh .
XCh

Since Ch form decomposition C,


p
p
X
X
X


kh
(X) nh (X)
XCh

h=1





p
X
h=1




X

p
p
X
X
(Ai ) (
nh )(A)
kh

i=1

Pp

h=1





X

XCh

(X)

p
X

h=1

decomposition, n = h=1 nh k =
showing UP3 holds, desired.

nh (A)

h=1

p
X

kh

h=1

h=1

Pp

h=1 kh ,

therefore

Pm

i=1 (Ai ) n(A)

k,

Proposition 4.1: formula f satisfiable upper probability structure iff
inequality formula f solution. Moreover, f solution, f satisfiable
upper probability structure 2|f | worlds.
Proof: Assume first f satisfiable. Thus upper probability structure
= (, , P, ) |= f . Section 4, let p1 , . . . , pN primitive propositions appear f , let 1 , . . . , 22N canonical listing inequivalent
formulas p1 , . . . , pN . Without loss generality, assume 1 equivalent
true, 22N equivalent false. Define vector x letting xi = P ([[i ]]M ),
N
1 22 . Since |= f , immediate x solution inequality
2N

formula f . Moreover, since 1 = false 2
= true, follows x1 = 0 (since
P ([[false]]M ) = P () = 0) x2N = 1 (since P ([[true]]M ) = P () = 1). Final2
ly, consider conjunct f corresponding instance L4; suppose form
xi1 + xW
Since conjunct appears
f, must case
im nxim+1 k. V
W
V
(im+1 J{1,... ,m}, |J|=k+n J{1,... ,m}, jJ ij ) ( |J|=k jJ ij ) propositional tautology. Thus, follows [[i1 ]]M , . . . , [[im ]]M (n, k)-cover ([[im+1 ]]M , [[true]]M ).
follows UP3
P ([[i1 ]]M ) + + P ([[im ]]M ) nP ([[]]M ) k.
74

fiA Logic Reasoning Upper Probabilities

Thus, x solution inequality formulas corresponding L4. Hence, x solution
f.
converse, assume x solution f. construct upper probability
structure = (S, E, P, ) |= f follows. Let p1 , . . . , pN primitive
propositions appearing f . Let = {1 , . . . , 2N } atoms p1 , . . . , pN . Let E
set subsets S. observed earlier, every propositional formula p1 , . . . , pn
equivalent unique disjunction atoms. Thus, get canonical collection
1 , . . . , 22N inequivalent formulas p1 , . . . , pn identifying formula
different element E, 1 corresponds empty set 22N corresponds
S. Define set function taking ({i1 , . . . , ij }) = xi disjunction
atoms i1 , . . . , ij . Let ()() = true iff .
sufficient show upper probability (of set P probability
measures), since clear (S, E, P, ) |= f (since x solution f, system
inequalities derived formula f ). this, Theorem 2.4, suffices verify
UPF1, UPF2, UPF3, using B2N UPF3, since |S| = 2N .
UPF1: () = x1 = 0.
UPF2: (S) = x2N = 1.
2

UPF3: Suppose A1 , . . . , E satisfy premises property UPF3, k, m, n B2N . Let i1 , . . . , im , im+1 canonical
A1 , . . . , AmW, A, respectively. Clearly,

V
formulas corresponding

iff







m+1
j
J{1,...
J{1,... ,m}, |J|=k+n jJ
,m}, |J|=k+n TjJ j
propositional tautology similarly J{1,... ,m}, |J|=k jJ Aij iff
W
V
Pm
J{1,... ,m}, |J|=k jJ ij propositional tautology. Thus,
j=1 xij

x
k one inequality formulas f . Thus, follows
Pim+1



k, desired. definition , therefore
j=1 xij xiP
m+1
k + n(A)
i=1 (Ai ), UPF3 holds.
Theorem 5.1: Suppose f likelihood formula satisfied upper probability
structure. f satisfied structure (, , P, ), || |f |2 , = 2 (every
subset measurable), |P| |f |, (w) rational number ||(w)||
O(|f |2 ||f || + |f |2 log(|f |)) every world w P, (w)(p) = false every
world w every primitive proposition p appearing f .
Proof: first step proof involves showing P set probability measures
defined algebra finite space , assume without loss generality
set X , probability measure X P X (X) = P (X)
(rather P (X) sup (X) P).
Lemma A.3: Let P set probability measures defined algebra finite set
. exists set P 0 probability measures that, X , P (X) =
(P 0 ) (X); moreover, probability measure X P 0 X (X) = P (X).
addition, interpretation , = (, , P, ) = (, , P 0 , ),
likelihood formulas f , |= f iff 0 |= f .

75

fiHalpern & Pucella

Proof: Since finite, show P 0 exists, clearly suffices show that,
X , probability measure X X (X) = P (X) and, P 0 = P {X },
P (Y ) = (P 0 ) (Y ) .
Given X, exists P (X) = P (X), done. Otherwise,
construct sequence 1 , 2 , . . . probability measures P limi (X) =
P (X) and, , sequence (Y ) converges limit. Let X1 , . . . , Xn
enumeration sets , X1 = X. inductively construct sequence
measures m1 , m2 , . . . P n mi (Xj ) converges limit k
limi mi (X) = P (X). = 1, know must sequence 11 , 12 , . . .
measures P 1i (X) converges P (X). inductive step, < n,
suppose constructed appropriate sequence m1 , m2 , . . . . Consider sequence
real numbers mi (Xm+1 ). Using Bolzano-Weierstrass theorem (Rudin, 1976) (which
says every sequence real numbers convergent subsequence), sequence
convergent subsequence. Let (m+1)1 , (m+1)2 , . . . subsequence m1 , m2 , . . .
generates convergent subsequence. sequence probability measures clearly
required properties. completes inductive step.
Define X (Y ) = limi ni (Y ). easy check X indeed probability
measure, X (X) = P (X), P 0 = P {X }, P (Y ) = (P 0 ) (Y )
. shows appropriate set P 0 exists.
Now, given , let = (, , P, ) 0 = (, , P 0 , ). straightforward induction
structure f shows |= f iff 0 |= f . base case:
(, , P, ) |= a1 l(1 ) + + l(n )
a1 P ([[1 ]]M ) + + P ([[n ]]M )
a1 (P 0 ) ([[1 ]]M 0 ) + + (P 0 ) ([[n ]]M 0 )
(, , P 0 , ) |= a1 l(1 ) + + l(n ) a.
others cases trivial.
FHM, prove Theorem 5.1, make use following lemma
derived Cramers rule (Shores, 1999) simple estimates size
determinant (see also (Chvatal, 1983) simpler variant):
Lemma A.4: system r linear equalities and/or inequalities integer coefficients
length l nonnegative solution, nonnegative solution
r entries positive, size member solution O(rl +r log(r)).
Continuing proof Theorem 5.1, suppose f satisfiable upper
probability structure. Proposition 4.1, system f equality formulas solution,
f satisfied upper probability structure finite state space. Thus, Lemma A.3, f satisfied structure = (, , P, ) X , exists
X P X (X) = P (X).
completeness proof, write f disjunctive normal form. disjunct
g conjunction |f | 1 basic likelihood formulas negations. Since
|= f , must disjunct g |= g. Suppose g conjunction
r basic likelihood formulas negations basic likelihood formulas. Let p1 , . . . , pN
76

fiA Logic Reasoning Upper Probabilities

primitive formulas appearing f . Let 1 , . . . , 2N atoms p1 , . . . , pN .
proof completeness, derive system equalities inequalities g.
slightly complicated system, however. Recall propositional formula
p1 , . . . , pN disjunction atoms. Let 1 , . . . , k propositional formulas
appear g. Notice k < |f | (since symbols f , coefficients,
propositional formulas). system equations inequalities
construct involve variables xij , = 1, . . . , k j = 1, . . . , 2N . Intuitively, xij
represents [[i ]]M ([[ j ]]M ), [[i ]]M P [[i ]]M ([[i ]]M ) = P ([[i ]]M ). Thus,
system includes k < |f | equations following form,
xi1 + + xi2N = 1,
= 1, . . . , k. Since [[i ]]M ([[i ]]M ) ([[i ]]M ) P, Ei subset
W
{1, . . . , 2N } = jEi j , system includes k 2 k inequalities form
X
X
xij
xi 0 j ,
jEi

i0

jEi

i0 .

pair i,
6=
conjunct g form 1 l(1 ) + +
n l(k ) , corresponding inequalityP
where, roughly speaking, replace l(i )
[[i ]]M ([[]]M ).8 Since [[i ]]M corresponds jEi xij , appropriate inequality
k
X



i=1

X

xij .

jEi

Negations formulas correspond negated inequality formula; before,
equivalent formula form
(

k
X
i=1



X

xij ) > .

jEi

Notice |f | inequalities corresponding conjuncts g. Thus,
altogether, k(k 1) + 2|f | < |f |2 equations inequalities
system (since k < |f |). know system nonnegative solution (taking
xij [[i ]]M ([[ j ]]M )). follows Lemma A.4 system solution
x = (x11 , . . . , x12N , . . . , xk1 , . . . , xk2N ) |f |2 entries positive, entry
size O(|f |2 ||f || + |f |2 log(|f |)).
use solution construct small structure satisfying formula f . Let =
{i : xij positive, j}; suppose = {i1 , . . . , it0 }, t0 t. Let
= (S, E, P, ) t0 states, say s1 , . . . , st0 , E consists subsets S. Let
(sh ) truth assignment corresponding formula ih , is, (sh )(p) = true
ih p (and (sh )(p) = false p appear f ). Define
P = {j : 1 k}, j (sh ) = xih j . clear construction |= f .
Since |P| = k < |f |, |S| = t0 |f |2 j (sh ) = xih j , where, construction, size
xih j O(|f |2 ||f || + |f |2 log(|f |)), theorem follows.
8. simplicity here, implicitly assuming formulas appears conjunct
g. without loss generality, since appear, put in, taking = 0.

77

fiHalpern & Pucella

Appendix B. Proof Characterization Upper Probabilities
make paper self-contained, appendix give proof Theorem 2.3.
proof give essentially Anger Lembcke (1985). Walley (1991) gives
alternate proof along somewhat similar lines. Note functional g define
proof corresponds construction Walleys Natural Extension Theorem,
needed version result.
Theorem 2.3: Suppose set, algebra subsets , : R.
exists set P probability measures = P satisfies
following three properties:
UP1. () = 0,
UP2. () = 1,
UP3. integers m, n, k subsets A1 , . . . ,
Pm , {{A1 , . . . , }}
(n, k)-cover (A, ), k + n(A)
i=1 (Ai ).
Proof: direction characterization straightforward. Given P = {i }iI
set probability measures, show P satisfies UP1-UP3.
UP1: P () = sup{i ()} = sup{0} = 0
UP2: P () = sup{i ()} = sup{1} = 1


UP3: GivenSA1 , . . . ,
J{1,... ,m},|J|=k+n jJ Aij
J{1,... ,m},|J|=k jJ Aij , ki () + ni (A)
Pm
P
Pm
(Aj ), kP+ ni (A)
j=1 (Aj ) supi { j=1 (Aj )}
Pj=1


(A ). sup {k+n (A)} = k+n sup { (A)} =
j




j=1 supi {i (Aj )} =
j=1 P P
(A ), required.
k + nP (A), k + nP (A)
P
j
j=1
direction, first prove general lemma relating problem
Hahn-Banach Theorem. general definitions needed. Suppose given
space W algebra F subsets W . Let K vector space generated
indicator functions 1X defined

0 x 6 X
1X (x) =
1 x X,
X F. sublinear functional K mapping c : K R c(h) = c(h)
0 c(h1 + h2 ) c(h1 ) + c(h2 ) h1 , h2 . sublinear functional increasing
h 0 implies c(h + h0 ) c(h0 ) h0 K. following result formulation
well-known Hahn-Banach Theorem (see, example, (Conway, 1990)).
Theorem (Hahn-Banach): Let K vector space R, let g sublinear
functional K. linear subspace K : R linear functional
(x) g(x) x M, linear functional 0 : K R
0 |M = 0 (x) g(x) x K.
Lemma B.1: Let g : F [0, 1] g(W ) = 1 suppose
increasing sublinear functional g K
78

fiA Logic Reasoning Upper Probabilities

1. g(1K ) = g(K) K F;
2. g(h) 0 h 0;
3. g(1) 1 (where g() identified g(1W )).
g upper probability measure.
Proof: show g upper probability exhibiting set {X : X }
probability measures, property X (X) = g(X) X (Y ) g(X) 6= X.
probability measure X constructed application Hahn-Banach
Theorem.
Given X F, define linear functional subspace generated 1X
(1X ) = g(1X ). claim (h) g(h) h subspace. Since elements
subspace form 1X , two cases consider: 0 < 0.
0, (1X ) = g(1X ) = g(1X ), since g sublinear. Moreover, 0 = g(0) =
g(1X + 1X ) g(1X ) + g(1X ), g(1X ) g(1X ). Thus, > 0,
(1X ) = g(1X ) g(1X ) = g(1X ).
Now, Hahn-Banach Theorem, extend linear functional 0
K 0 (h) g(h) h. claim (a) 0 (1Y ) 0 K (b)
0 (1) = 1. (a), note 0 (1Y ) g(1Y ) 0 assumption, 0 (1Y ) 0.
(b), note 0 (1) g(1) = g(W ) = 1 0 (1) = 0 (1) g(1) 1 (since
g(1) 1, assumption).
Define X (Y ) = 0 (1Y ). Since 0 (1W ) = 1, X (W ) = 1. 0 disjoint,
immediate linearity X (Y 0 ) = X (Y ) + X (Y 0 ). construction,
X (Y ) g(1Y ) = g(Y ) 6= X, X (X) = (1X ) = g(1X ) = g(X). Bottom
line: probability measure X dominated g X (X) = g(X).
Take P = {X : X }. Since X X (X) = g(X)
X (Y ) g(X) (if 6= X), P (X) = X (X) = g(X). Therefore, g = P .
main result follows showing construct, function satisfying
properties Theorem 2.3, sublinear functional c K required properties.
Suppose g : R function satisfying UP1-UP3. show discussion
Theorem 2.3 text, UP1-UP3 show range g fact [0, 1].PSince g

satisfies UP3, {{K1 , . . . , Km }} (n, k)-cover
Pm (K, ), k +ng(K) i=1 Ki .
equivalent
saying k + n1K Pi=1 1Ki . Hence, K1 , . . . , Km
P

k + n1K
1
i=1 Ki , k + ng(K)
i=1 g(Ki ), equivalently


k
1X
+
g(Ki ) g(K).
n n

(3)

i=1

observation motivates following definition functional g : K R
{, }:
(
)


k
1X
k
1X
g(h) = inf +
g(Ki ) : m, n, k N, m, n > 0, K1 , . . . , Km F, +
1Ki h .
n n
n n
i=1

i=1

goal show g satisfies conditions Lemma B.1.
79

fiHalpern & Pucella

almost immediate definitions g increasing: h 0 nk +
1 Pm
k
1 Pm
0
0
i=1 1Ki h + h , n + n
i=1 1Ki h .
n
see g sublinear, note easy see using properties inf
g(h1 + h2 ) g(h1 ) + g(h2 ). show g(h) = g(h) 0, first observe
definition g equivalent
(
)


X
X
inf +
g(Ki ) : N, , R+ , K1 , . . . , Km F +
1Ki h .
i=1

i=1

Consider first case > 0.
(
)


X
X
g(h) = inf +
g(Ki ) : +
1Ki h
i=1

= inf

(

+


X
i=1

= inf

(

i=1

)

1X

1Ki h
g(Ki ) : +



1
+


i=1


X
i=1

)


1X
g(Ki ) : +
1Ki h

i=1

= g(h).
= 0, clear definition g g(1 ) g(). (3) follows
g(1 ) g(), hence g(0) = g(1 ) = g() = 0.
immediate definition g g(1K ) g(K) K F; fact
g(1K ) = g(K) follows (3).
immediate definition g(1) 1.
h 0, h 0; since g increasing, g(h) g(h + h) = g(0), since g
sublinear, g(0) = 0.
Since conditions Lemma B.1 satisfied, g upper probability measure.

References
Anger, B., & Lembcke, J. (1985). Infinitely subadditive capacities upper envelopes
measures. Zeitschrift fur Wahrscheinlichkeitstheorie und Verwandte Gebiete, 68, 403
414.
Chvatal, V. (1983). Linear Programming. W. Freeman Co., San Francisco, Calif.
Conway, J. B. (1990). Course Functional Analysis (Second edition). No. 96 Graduate
Texts Mathematics. Springer-Verlag.
Dempster, A. P. (1967). Upper lower probabilities induced multivalued mapping.
Annals Mathematical Statistics, 38 (2), 325339.

80

fiA Logic Reasoning Upper Probabilities

Dickson, L. E. (1913). Finiteness odd perfect primitive abundant numbers
n distinct prime factors. American Journal Mathematics, 35 (4), 413422.
Fagin, R., & Halpern, J. Y. (1991). Uncertainty, belief probability. Computational
Intelligence, 7 (3), 160173.
Fagin, R., Halpern, J. Y., & Megiddo, N. (1990). logic reasoning probabilities.
Information Computation, 87 (1,2), 78128.
Giles, R. (1982). Foundations theory possibility. Gupta, M. M., & Sanchez, E.
(Eds.), Fuzzy Information Decision Processes, pp. 183195. North-Holland.
Halpern, J. Y. (2002). Reasoning uncertainty. Book manuscript.
Halpern, J. Y., & Pucella, R. (2002). Reasoning expectation. Proc. Eighteenth
Conference Uncertainty Artificial Intelligence (UAI 2002).
Huber, P. J. (1976). Kapazitaten statt Wahrscheinlichkeiten? Gedanken zur Grundlegung
der Statistik. Jber. Deutsch. Math.-Verein, 78, 8192.
Huber, P. J. (1981). Robust Statistics. Wiley Interscience.
Kyburg, Jr., H. E. (1987). Bayesian non-Bayesian evidential updating. Artificial Intelligence, 31, 271293.
Lorentz, G. G. (1952). Multiply subadditive functions. Canadian Journal Mathematics,
4 (4), 455462.
Mendelson, E. (1964). Introduction Mathematical Logic. Van Nostrand, New York.
Popkorn, S. (1994). First Steps Modal Logic. Cambridge University Press, Cambridge;
New York.
Rudin, W. (1976). Principles Mathematical Analysis (Third edition). McGraw-Hill.
Shafer, G. (1976). Mathematical Theory Evidence. Princeton University Press, Princeton, NJ.
Shores, T. (1999). Applied Linear Algebra Matrix Analysis (Second edition). McGrawHill.
Smith, C. A. B. (1961). Consistency statistical inference decision. Journal
Royal Statistical Society, Series B, 23, 125.
Walley, P. (1981). Coherent lower (and upper) probabilities. Manuscript, Dept. Statistics,
University Warwick.
Walley, P. (1991). Statistical Reasoning Imprecise Probabilities. Chapman Hall.
Williams, P. M. (1976). Indeterminate probabilities. Przelecki, M., Szaniawski, K., &
Wojciki, E. (Eds.), Formal Methods Methodology Empirical Sciences, pp.
229246.
Wilson, N., & Moral, S. (1994). logical view probability. Proc. 11th European
Conference Artificial Intelligence (ECAI-94), pp. 7195.
Wolf, G. (1977). Obere und Untere Wahrscheinlichkeiten. Doctoral dissertation, Eidgenossischen Technischen Hochschule, Zurich. (Diss. ETH 5884).

81

fiJournal Artificial Intelligence Research 17 (2002) 171-228

Submitted 3/02; published 9/02

Towards Adjustable Autonomy Real World
scerri@isi.edu
pynadath@isi.edu
tambe@usc.edu

Paul Scerri
David V. Pynadath
Milind Tambe
Information Sciences Institute Computer Science Department
University Southern California
4676 Admiralty Way, Marina del Rey, CA 90292 USA

Abstract

Adjustable autonomy refers entities dynamically varying autonomy, transferring decision-making control entities (typically agents transferring control
human users) key situations. Determining whether transfers-of-control
occur arguably fundamental research problem adjustable autonomy. Previous work investigated various approaches addressing problem often
focused individual agent-human interactions. Unfortunately, domains requiring collaboration teams agents humans reveal two key shortcomings previous
approaches. First, approaches use rigid one-shot transfers control result
unacceptable coordination failures multiagent settings. Second, ignore costs (e.g.,
terms time delays effects actions) agent's team due transfers-ofcontrol.
remedy problems, article presents novel approach adjustable autonomy, based notion transfer-of-control strategy. transfer-of-control strategy
consists conditional sequence two types actions: (i) actions transfer decisionmaking control (e.g., agent user vice versa) (ii) actions change
agent's pre-specified coordination constraints team members, aimed minimizing
miscoordination costs. goal high-quality individual decisions made
minimal disruption coordination team. present mathematical model
transfer-of-control strategies. model guides informs operationalization
strategies using Markov Decision Processes, select optimal strategy, given
uncertain environment costs individuals teams. approach
carefully evaluated, including via use real-world, deployed multi-agent system
assists research group daily activities.
1.

Introduction

Exciting, emerging application areas ranging intelligent homes (Lesser et al., 1999),
routine organizational coordination (Pynadath et al., 2000), electronic commerce (Collins
et al., 2000a), long-term space missions (Dorais et al., 1998) utilize decision-making
skills agents humans. new applications brought forth increasing
interest agents' adjustable autonomy (AA), i.e., entities dynamically adjusting
level autonomy based situation (Mulsiner & Pell, 1999). Many exciting
applications deployed unless reliable AA reasoning central component.
AA, entity need make decisions autonomously; rather choose reduce
autonomy transfer decision-making control users agents,
c 2002 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiScerri, Pynadath & Tambe
expected net benefit (Dorais et al., 1998; Barber, Goel, & Martin, 2000a;
Hexmoor & Kortenkamp, 2000).
central problem AA determine whether transfers decision-making
control occur. key challenge balance two potentially con icting goals.
one hand, ensure highest-quality decisions made, agent transfer control human user (or another agent) whenever user superior decision-making
expertise.1 hand, interrupting user high costs user may
unable make communicate decision, thus transfers-of-control minimized. Previous work examined several different techniques attempt balance
two con icting goals thus address transfer-of-control problem. example,
one technique suggests decision-making control transferred expected
utility higher expected utility making autonomous decision
(Horvitz, Jacobs, & Hovel, 1999). second technique uses uncertainty sole rationale
deciding control, forcing agent relinquish control user
whenever uncertainty high (Gunderson & Martin, 1999). Yet techniques transfer
control user erroneous autonomous decision could cause significant harm (Dorais
et al., 1998) agent lacks capability make decision (Ferguson, Allen, &
Miller, 1996).
Unfortunately, previous approaches transfer-of-control reasoning indeed
previous work AA, focused domains involving single agent single
user, isolated interactions entities. applied interacting teams
agents humans, interaction agent human impacts interaction entities, techniques lead dramatic failures. particular,
presence entities team members introduces third goal maintaining coordination (in addition two goals already mentioned above), previous
techniques fail address. Failures occur two reasons. Firstly, previous techniques
ignore team related factors, costs team due incorrect decisions due
delays decisions transfers-of-control. Secondly (and importantly),
techniques use one-shot transfers-of-control, rigidly committing one two choices: (i)
transfer control wait input (choice H ) (ii) act autonomously (choice A). However,
given interacting teams agents humans, either choice lead costly failures
entity control fails make report decision way maintains coordination.
instance, human user might unable provide required input due temporary communication failure; may cause agent fail part joint action,
joint action may dependent user's input. hand, forcing
less capable entity make decision simply avoid miscoordination lead poor
decisions significant consequences. Indeed, seen Section 2.2, applied
rigid transfer-of-control decision-making domain involving teams agents users,
failed dramatically.
Yet, many emerging applications involve multiple agents multiple humans acting
cooperatively towards joint goals. address shortcomings previous AA work
domains, article introduces notion transfer-of-control strategy. transfer-ofcontrol strategy consists pre-defined, conditional sequence two types actions: (i)
1. AA problem general involves transferring control one entity another, paper,
typically focus interactions involving autonomous agents human users.

172

fiTowards Adjustable Autonomy Real World
actions transfer decision-making control (e.g., agent user vice versa);
(ii) actions change agent's pre-specified coordination constraints team members,
rearranging activities needed (e.g., reordering tasks buy time make decision).
agent executes strategy performing actions order, transferring control
specified entity changing coordination required, point time
entity currently control exercises control makes decision. Thus, previous
choices H two many different possibly complex transfer-ofcontrol strategies. instance, ADAH strategy implies agent initially attempts
make autonomous decision. agent makes decision autonomously strategy
execution ends there. However, chance unable make decision
timely manner, perhaps computational resources busy higher
priority tasks. avoid miscoordination agent executes action changes
coordination constraints activity. example, action could inform
agents coordinated action delayed, thus incurring cost inconvenience
others buying time make decision. still cannot make decision,
eventually take action H , transferring decision-making control user waiting
response. general, strategies involve available entities contain many
actions change coordination constraints. strategies may useful singleagent single-human settings, particularly critical general multiagent settings,
discussed below.
Transfer-of-control strategies provide exible approach AA complex systems
many actors. enabling multiple transfers-of-control two (or more) entities,
rather rigidly committing one entity (i.e., H ), strategy attempts provide
highest quality decision, avoiding coordination failures. particular, multiagent
setting often uncertainty whether entity make decision
so, e.g., user may fail respond, agent may able make decision
expected communication channel may fail. strategy addresses uncertainty
planning multiple transfers control cover contingencies. instance,
ADH strategy, agent ultimately transfers control human attempt ensure
response provided case agent unable act. Furthermore, explicit
coordination-change actions, i.e., actions, reduce miscoordination effects, cost,
better decisions made. Finally, since utility transferring control changing
coordination dependent actions taken afterwards, agent must plan strategy
advance find sequence actions maximizes team benefits. example,
reacting current situation repeatedly taking giving control strategy
ADHADH : : : may costly planning ahead, making bigger coordination
change, using shorter ADH strategy. developed decision theoretic model
strategies, allows expected utility strategy calculated and, hence,
strategies compared.
Thus, key AA problem select right strategy, i.e., one provides
benefit high-quality decisions without risking significant costs interrupting user
miscoordination team. Furthermore, agent must select right strategy despite
significant uncertainty. Markov decision processes (MDPs) (Puterman, 1994) natural
choice implementing reasoning explicitly represent costs, benefits
uncertainty well lookahead examine potential consequences sequences
173

fiScerri, Pynadath & Tambe
actions. Section 4, general reward function presented MDP results
agent carefully balancing risks incorrect autonomous decisions, potential miscoordination
costs due changing coordination team members. Detailed experiments
performed MDP, key results follows. relative importance
central factors, cost miscoordination, varied resulting MDP policies
varied desirable way, i.e., agent made decisions autonomously cost
transferring control entities increased. experiments reveal phenomenon
reported literature: agent may act autonomously coordination
change costs either low high, \middle" range, agent tends act
less autonomously.
research conducted context real-world multi-agent system,
called Electric Elves (E-Elves) (Chalupsky, Gil, Knoblock, Lerman, Oh, Pynadath, Russ,
& Tambe, 2001; Pynadath et al., 2000), used six months
University Southern California, Information Sciences Institute. E-Elves assists
group researchers project assistant daily activities, providing exciting
opportunity test AA ideas real environment. Individual user proxy agents called
Friday (from Robinson Crusoe's servant Friday) act team assist rescheduling
meetings, ordering meals, finding presenters day-to-day activities. course
several months, MDP-based AA reasoning used around clock E-Elves,
making many thousands autonomy decisions. Despite unpredictability user's
behavior agent's limited sensing abilities, MDP consistently made sensible
AA decisions. Moreover, many times agent performed several transfers-of-control
cope contingencies user responding. One lesson learned actually
deploying system sometimes users wished uence AA reasoning, e.g.,
ensure control transferred particular circumstances. allow users
uence AA reasoning, safety constraints introduced allow users prevent
agents taking particular actions ensuring take particular actions.
safety constraints provide guarantees behavior AA reasoning, making
basic approach generally applicable and, particular, making applicable
domains mistakes serious consequences.
rest article organized follows. Section 2 gives detailed description
AA problem presents Electric Elves motivating example application. Section
3 presents formal model transfer-of-control strategies AA. (Readers interested
mathematical details may wish skip Section 3.) operationalization
strategies via MDPs described Section 4. Section 5, results detailed
experiments presented. Section 6 looks related work, including earlier AA work
analyzed within strategies framework. Section 7 gives summary article.
Finally, Section 8 outlines areas work could extended make applicable
applications.
2.

Adjustable Autonomy { Problem

general AA problem previously formally defined literature, particularly multiagent context. following, formal definition problem given
clearly define task AA reasoning. team, may consist entirely
174

fiTowards Adjustable Autonomy Real World
agents include humans, joint activity, ff. entity team works
cooperatively joint activity. agent, A, role, , team. Depending
specific task, roles need performed successfully order
joint activity succeed. primary goal agent success ff
pursues performing . Performing requires one non-trivial decisions
made. make decision, d, agent draw upon n entities set
E = fe1 : : : en g, typically includes agent itself. entity E (e.g., human
user) capable making decision d. entities E necessarily part
team performing ff. Different agents users differing abilities make decisions
due available computational resources, access relevant information, etc. Coordination
constraints, , exist roles members team. example,
various roles might need executed simultaneously certain order
combined quality total cost. critical facet successful completion joint task
ff, given jointness, ensure coordination team members maintained,
i.e., violated. Thus, describe AA problem instance tuple:
hA; ff; ; ; d; E i.
AA perspective, agent take two types actions decision, d.
First, transfer control entity E capable making decision. general,
restrictions when, often long decision-making control
transferred particular entity. Typically, agent also transfer decision-making
control itself. general, assume agent transfers control,
guarantee exact time response exact quality decision made
entity control transferred. fact, cases know whether
entity able make decision even whether entity know
decision-making control, e.g., control transferred via email, agent may know
user actually read email.
second type action agent take request changes coordination constraints, , team members. coordination change gives agent
possibility changing requirements surrounding decision made, e.g.,
required timing, cost quality decision, may allow better fulfill responsibilities. coordination change might involve reordering delaying tasks may
involve changing roles, may dramatic change team pursues ff
completely different way. Changing coordination cost, may better
incur cost violate coordination constraints, i.e., incur miscoordination costs.
Miscoordination team members occur many reasons, e.g., constraint
limits total cost joint task might violated one team member incurs higher
expected cost team members reduce costs. article,
primarily concerned constraints related timing roles, e.g., ordering constraints requirements simultaneous execution. turn, usually requires
agent guards delayed decisions although also require decision
made soon.
Thus, AA problem agent, given problem instance, hA; ff; ; ; d; E i,
choose transfer-of-control coordination-change actions maximizes overall
expected utility team. remainder section describe concrete, real175

fiScerri, Pynadath & Tambe
world domain AA (Section 2.1) initial failed approach motivates solution
(Section 2.2).

2.1 Electric Elves
research initiated response issues arose real application
resulting approach extensively tested day-to-day running application.
Electric Elves (E-Elves) project USC/ISI deploy agent organization
support daily activities human organization (Pynadath et al., 2000; Chalupsky
et al., 2001). believe application fairly typical future generation applications involving teams agents humans. operation human organization
requires performance many everyday tasks ensure coherence organizational
activities, e.g., monitoring status activities, gathering information keeping everyone informed changes activities. Teams software agents aid organizations
accomplishing tasks, facilitating coherent functioning rapid, exible response
crises. number underlying AI technologies support E-Elves, e.g., technologies
devoted agent-human interactions, agent coordination, accessing multiple heterogeneous
information sources, dynamic assignment organizational tasks, deriving information
organization members (Chalupsky et al., 2001). technologies useful,
AA fundamental effective integration E-Elves day-to-day running
real organization and, hence, focus paper.
basic design E-Elves shown Figure 1(a). agent proxy called
Friday (after Robinson Crusoes' man-servant Friday) acts behalf user
agent team. design Friday proxies discussed detail (Tambe, Pynadath,
Chauvat, Das, & Kaminka, 2000) (where referred TEAMCORE proxies).
Currently, Friday perform several tasks user. user delayed meeting,
Friday reschedule meeting, informing Fridays, turn inform users.
research presentation slot open, Friday may respond invitation present
behalf user. Friday also order user's meals (see Figure 2(a)) track
user's location, posting Web page. Friday communicates users using wireless
devices, personal digital assistants (PALM VIIs) WAP-enabled mobile phones,
via user workstations. Figure 1(b) shows PALM VII connected Global Positioning
Service (GPS) device, tracking users' locations enabling wireless communication
Friday user. Friday's team behavior based teamwork model,
called STEAM (Tambe, 1997). STEAM encodes enforces constraints roles
required success joint activity, e.g., meeting attendees arrive
meeting simultaneously. role within team needs filled, STEAM requires
team member assigned responsibility role. find best suited person,
team auctions role, allowing consider combination factors assign
best suited user. Friday bid behalf user, indicating whether user
capable and/or willing fill particular role. Figure 2(b) shows tool allows users
view auctions progress intervene desire. auction progress, Jay
Modi's Friday bid Jay capable giving presentation, unwilling
so. Paul Scerri's agent highest bid eventually allocated role.

176

fiTowards Adjustable Autonomy Real World

Friday

Friday

Friday

Friday

(a)

(b)

Figure 1: (a) Overall E-Elves architecture, showing Friday agents interacting users.
(b)Palm VII communicating users GPS device detecting
location.

177

fiScerri, Pynadath & Tambe
AA critical success E-Elves since, despite range sensing devices,
Friday considerable uncertainty user's intentions even location; hence,
Friday always appropriate information make correct decisions.
hand, user required information, Friday cannot continually ask
user input, since interruptions disruptive time-consuming. four
decisions E-Elves AA reasoning applied: (i) whether user attend
meeting time; (ii) whether close auction role; (iii) whether user willing
perform open team role; (iv) order lunch. paper,
focus AA reasoning two decisions: whether user attend meeting
time whether close auction role. decision whether user
attend meeting time often used dicult decisions Friday
faces. brie describe decision close auction later show insight
provided model strategies led significant reduction amount code
required implement AA reasoning decision. decision volunteer user
meeting similar earlier decisions, omitted brevity; decision order
lunch currently implemented simpler fashion (at least yet) illustrative
full set complexities.
central decision Friday, describe terms problem formulation,
hA; ff; ; ; d; E i, whether user attend meeting currently scheduled meeting time. case, Friday agent, A. joint activity, ff, meeting
attendees attend meeting simultaneously. Friday acts proxy user, hence
role, , ensure user arrives currently scheduled meeting time.
coordination constraint, , Friday's role roles Fridays
occur simultaneously, i.e., users must attend currently scheduled time.
attendee arrives late, all, time attendees wasted;
hand, delaying meeting disruptive users' schedules. decision, d, whether
user attend meeting could made either Friday user, i.e.,
E = fuser; Fridayg. Clearly, user often better placed make decision.
However, Friday transfers control user decision, must guard miscoordination, i.e., attendees wait, waiting user response.
decisions potentially costly, e.g., incorrectly telling attendees user
attend, Friday avoid taking autonomously. buy time
user make decision gather information, Friday could change
coordination constraints action. Friday several different actions disposal, including delaying meeting different lengths time, well able
cancel meeting entirely. user also request action, e.g., via dialog box
Figure 5(a), buy time make meeting. user decides required,
Friday conduit Fridays (and hence users) informed.
Friday must select sequence actions, either transferring control user, delaying
cancelling meeting autonomously announcing user attend,
maximize utility team.
second AA decision look decision close auction open
role assign user role.2 case, joint activity, ff, group research
2. also roles submitting bids auction AA decisions simpler, hence
focus here.

178

fiTowards Adjustable Autonomy Real World

(a)

(b)

Figure 2: (a) Friday transferring control user decision whether order lunch.
(b) E-Elves auction monitoring tool.
meeting role, , auctioneer. Users always submit bids
role immediately; fact, bids may spread several days, users might
bid all. specific decision, d, focus whether close auction
assign role continue waiting incoming bids. individual team members
provide bids, auctioneer agent human team leader decides presenter based
input (E = fuser; auctioneer agentg). team expects willing presenter
high-quality research presentation, means presenter need time
prepare. Thus, coordination constraint, capable, willing user must
allocated role enough time prepare presentation. Despite individually
responsible actions, agent team may reach highly undesirable decision, e.g., assigning
user week week, hence advantage getting human team leader's
input. agent faces uncertainty (e.g., better bids come in?), costs (i.e., later
assignment, less time presenter prepare), needs consider
possibility human team leader special preference
presentation particular meeting. transferring control, agent allows
human team leader make assignment. decision, coordination-change action,
D, would reschedule research meeting. However, relative cost cancelling
meeting, cost rescheduling high rescheduling useful action.

2.2 Decision-Tree Approach
One logical avenue attack AA problem E-Elves apply approach
used previously reported, successful meeting scheduling system, particular CAP
(Mitchell, Caruana, Freitag, McDermott, & Zabowski, 1994). Like CAP, Friday learned
user preferences using C4.5 decision-tree learning (Quinlan, 1993). Friday recorded values
dozen carefully selected attributes user's preferred action (identified asking
179

fiScerri, Pynadath & Tambe
user) whenever make decision. Friday used data learn decision
tree encoded autonomous decision making. AA, Friday also asked user
wanted decisions taken autonomously future. responses, Friday
used C4.5 learn second decision tree encoded rules transferring control.
Thus, second decision tree indicated Friday act autonomously, would
take action suggested first decision tree. Initial tests C4.5 approach
promising (Tambe et al., 2000), key problem soon became apparent.
Friday encountered decision learned transfer control user,
would wait indefinitely user make decision, even though inaction caused
miscoordination teammates. particular, team members would arrive
meeting location, waiting response user's Friday, would end
completely wasting time response arrived. address problem, user
respond within fixed time limit (five minutes), Friday took autonomous action.
Although performance improved, resulting system deployed 24/7 led
dramatic failures, including:
1. Example 1: Tambe's (a user) Friday incorrectly cancelled meeting division
director Friday over-generalized training examples.
2. Example 2: Pynadath's (another user) Friday incorrectly cancelled group's weekly
research meeting time-out forced choice (incorrect) autonomous
action.
3. Example 3: Friday delayed meeting almost 50 times, time 5 minutes.
correctly applying learned rule ignoring nuisance rest
meeting participants.
4. Example 4: Tambe's Friday automatically volunteered presentation,
actually unwilling. Friday over-generalized examples
timeout occurred took undesirable autonomous action.
Clearly, team context, rigidly transferring control one agent (user) failed. Furthermore, using time-out rigidly transferred control back agent,
capable making high-quality decision, also failed. particular, agent needed
better avoid taking risky decisions explicitly considering costs (example 1),
take lower cost actions delay meetings buy user time respond (example 2
4). Furthermore, example 3 showed, agent needed plan ahead, avoid taking
costly sequences actions could replaced single less costly action (example
3). theory, using C4.5 Friday might eventually able learn rules would
successfully balance costs deal uncertainty handle special cases
on, large amount training data would required.
3.

Strategies Adjustable Autonomy

avoid rigid one-shot transfers control allow team costs considered,
introduce notion transfer-of-control strategy, defined follows:
180

fiTowards Adjustable Autonomy Real World
Definition 3.1 transfer-of-control strategy pre-defined, conditional sequence two

types actions: (i) actions transfer decision-making control (e.g., agent
user agents, vice versa) (ii) actions change agent's pre-specified
coordination constraints team members, aimed minimizing miscoordination costs.

agent executes transfer-of-control strategy performing specified actions
sequence, transferring control specified entity changing coordination required,
point time entity currently control exercises control
makes decision. Considering multi-step strategies allows agent exploit decisionmaking sources considered risky exploit without possibility retaking control.
example, control could transferred capable always available decision
maker taken back decision made serious miscoordination occurred.
complex strategies, potentially involving several coordination changes, give agent
option try several decision-making sources exible getting input
high-quality decision makers. result, transfer-of-control strategies specifically allow
agent avoid costly errors, enumerated previous section.3
Given AA problem instance, hA; ff; ; ; d; E , agent transfer decision-making
control decision entity ei 2 E , denote transfer-of-control
action symbol representing entity, i.e., transferring control ei denoted
ei . agent transfers decision-making control, may stipulate limit time
wait response entity. capture additional stipulation,
denote transfer-of-control actions time limit, e.g., ei (t) represents ei
decision-making control maximum time t. action two possible outcomes:
either ei responds time makes decision, respond decision
remains unmade time t. addition, agent mechanism
change coordination constraints (denoted D) change expected timing
decision. action changes coordination constraints, , team members.
action associated value, Dvalue , specifies magnitude (i.e., much
alleviated temporal pressure), cost, Dcost , specifies price paid
making change. concatenate actions specify complete transferof-control strategy. instance, strategy H (5)A would specify agent first
relinquishes control asks entity H (denoting H uman user). user responds
decision within five minutes, need go further. not,
agent proceeds next transfer-of-control action sequence. example,
next action, A, specifies agent make decision complete task.
transfers control occur case. define space possible
strategies following regular expression:

= (E R)((E R) + D)

(1)

(E R) possible combinations entity maximum time.
readability, frequently omit time specifications transfer-ofcontrol actions instead write order agent transfers control among
3. domains, may make sense attempt get input one entity once, hence
requiring strategies actions might executed parallel. However, work, first
step, consider strategies. Furthermore, relevant domains hand.

181

fiScerri, Pynadath & Tambe
entities executes Ds (e.g., often write HA instead H (5)A). time
specifications omitted, assume transfers happen optimal times,4 i.e.,
times lead highest expected utility. consider strategies
sequence actions different timings strategy, agent O(jE jk )
possible strategies select from, k maximum length strategy jE j
number entities. Thus, agent wide range options, even practical
considerations lead reasonable upper bound k jE j. agent must select
strategy maximizes overall expected utility ff.
rest section, present mathematical model transfer-of-control strategies AA use model guide search solution. Moreover, model
provides tool predicting performance various strategies, justifying use
explaining observed phenomena use. Section 3.1 presents model AA
strategies detail. Section 3.2 reveals key properties complex strategies, including dominance relationships among strategies. Section 3.3 examines E-Elves application
light model, make specific predictions properties successful
AA approach reasoning application class have. predictions shape
operationalization strategies Section 4.

3.1 Mathematical Model Strategies
transfer-of-control model presented section allows calculation expected
utility (EU) individual strategies, thus allowing strategies compared. calculation strategy's EU considers four elements: likely relative quality different
entities' decisions; probability getting response entity particular time;
cost delaying decision; costs benefits changing coordination constraints. parameters might also modeled similar manner, experience
E-Elves AA work suggests parameters critical ones
across wide range joint activities.
first element model expected quality entity's decision. general,
capture quality entity's decision time functions EQ = fEQde (t) :
R ! Rg. quality decision ects probability entity make
\appropriate" decision costs incurred decision wrong. expected quality
decision calculated decision theoretic way, multiplying probability
outcome, i.e., decision, utility decision, i.e., cost benefit
decision. example, higher probability entity make mistake,
lower quality, even lower mistakes might costly. quality decision
entity make vary time information available changes
time \think". second element model probability entity
make decision control transferred it. functions, P = fP>e (t) : R ! [0; 1]g,
represent continuous probability distributions time
entity e respond.
R t0 ei
is, probability ei respond time t0 0 P> (t)dt.
third element model representation cost inappropriate timing
decision. general, making decision particular point time incurs
4. best time transfer control found, e.g., differentiating expected utility equation
Section 3.1 solving 0.

182

fiTowards Adjustable Autonomy Real World
cost function time, t, coordination constraints, ,
team members. stated earlier, focus cases constraint violations due delays
making decisions. Thus, cost due violation constraints caused
making decision point time. write wait-cost function :
W = f (; t) returns cost making decision particular point time
given coordination constraints, . miscoordination cost fundamental aspect
model given emphasis multiagent domains. called \wait cost" models
miscoordination arises team \waits" entity make ultimate
decision. domains like E-Elves, team incurs wait costs situations (for
example) meeting attendees assembled meeting room time
meeting, kept waiting without input decision Friday (potentially
cannot provide high-quality decision, get input user). Notice
different roles lead different wait cost functions, since delays performance
different roles different effects team. assume
point time, , costs accrue, i.e., f (; t) = f (; ).
deadline, , maximum cost due inappropriate timing decision
incurred. Finally, assume that, general, , wait cost function nondecreasing, ecting idea bigger violations constraints lead higher wait costs.
final element model coordination-change action, D, moves agent
away deadline hence reduces wait costs incurred.
model effect letting W function Dvalue (rather t)
action fixed cost, Dcost , incurred immediately upon execution.
example, E-Elves domain, suppose time meeting, Friday delays
meeting 15 minutes (D action). Then, following time period, incur
relatively low cost making decision 15 minutes meeting (t Dvalue ),
rather relatively high cost making decision time meeting.
Other, possibly complex, models action could also used.
use four elements compute EU arbitrary strategy, s. utility
derived decision made time entity control quality
entity's decision minus costs incurred waiting t, i.e., EUedc (t) = EQdec (t)
W (t). coordination-change action taken also effect utility.
coordination change value Dvalue taken time , incurred wait cost
W (). Then, t, wait cost incurred W (t Dvalue ) W ( Dvalue ).
Thus, action taken time cost Dcost value Dvalue ,
utility decision time (t > ) is: EUedc (t) = EQdec (t) W () W ( Dvalue ) +
W (t Dvalue) Dcost. calculate EU entire strategy, multiply response
probability mass function's value instant EU receiving response
instant, integrate products. Hence, EU strategy given
problem instance, hA; ff; ; ; d; E , is:
Z 1
h
A;ff;;

;d;E

EUs
=
P (t)EUedc (t) :dt
(2)
0 >
strategy involves several actions, need ensure probability response
function wait-cost calculation ect control situation point
strategy. example, user, H , control time t, P> (t) ect H's
183

fiScerri, Pynadath & Tambe

W (0)

EUAd = EQdA (0)
EUed

EUeA

=

=



Z

0
Z

0

EUedDeA =

P>(t) (EQde (t)
P>(t) (EQde (t)

W (t)):dt +
W (t)):dt +

1
P>(t) (EQde (t)


Z

1

Z



R

(3)

W (D)):dt (4)

P>(t):dt (EQda (T )

W (T )) (5)


0
0 P> (t)(EQe (t) W (t)):dt +

P>(t)(EQe (t) W () + W ( Dvalue ) W (t Dvalue ) Dcost ):dt +
R1

P> (t)(EQA (t) W () + W ( Dvalue ) W (T Dvalue ) Dcost ):dt

(6)

RT

Table 1: General AA EU equations sample transfer control strategies.
probability responding t, i.e., P>H (t0 ). end, break integral
Equation 2 separate terms, term representing one segment strategy,
e.g., strategy UA would one term U control another
control.
Using basic technique writing EU calculations, write
specific equations arbitrary transfer-of-control strategies. Equations 3-6 Table 1
show EU equations strategies A, e , eA e DeA respectively. equations
assume agent, A, make decision instantaneously (or least, delay
significant enough affect overall value decision). equations created
writing integral segments strategy, described above.
time agent takes control e , time occurs.
One write equations complex strategies way. Notice
equations make assumptions particular functions.
Given EU strategy calculated, AA problem agent reduces
finding following transfer-of-control strategy maximize EU. Formally,
agent's problem is:

Axiom 3.1 problem hA; ff; ; ; d; E , agent must select 2 8s0 2
S; s0 6= s; EUshA;ff;;;d;E EUsh0A;ff;;;d;E

184

fiTowards Adjustable Autonomy Real World

5
0
-5
0.1

w 0.2

0.3

0.4

1.2
0.8p

Figure 3: Graph comparing EU two strategies, H DA (solid line) H (dashed line)
given particular instantiation model constant expected decisionmaking quality, exponentially rising wait costs, Markovian response probabilities. p parameter P>(t) function, higher p meaning longer
expected response time. w parameter W (t) function higher w
meaning rapidly accruing wait costs.

3.2 Dominance Relationships among Strategies
agent could potentially find strategy highest EU examining
every strategy S, computing EU, selecting strategy highest value.
example, consider problem domains constant expected decision-making quality,
exponentially rising wait costs, Markovian response probabilities. Figure 3 shows
graph EU two strategies (H DA H ) given particular model instantiation.
Notice that, different response probabilities rates wait cost accrual, one strategy
outperforms other, neither strategy dominant entire parameter space.
EU strategy also dependent timing transfers control, turn
depend relative quality entities' decision making. Appendix provides
detailed analysis.
Fortunately, evaluate compare every candidate
exhaustive search find optimal strategy. instead use analytical methods
draw general conclusions relative values different candidate strategies.
particular, present three Lemmas show domain-level conditions
particular strategy types superior others. Lemmas also lead us the, perhaps
surprising, conclusion complex strategies necessarily superior single-shot
strategies, even multi-agent context; fact, particular strategy dominates
strategies across domains.
Let us first consider AA subproblem whether agent ever take back
control another entity. show that, certain conditions, agent
always eventually take back control, strategy selection process ignore
strategies agent (i.e., strategies ending A). agent's
goal strike right balance waiting indefinitely user response
185

fiScerri, Pynadath & Tambe
taking risky autonomous action. Informally, agent reasons eventually
make decision expected cost continued waiting exceeds difference
user's decision quality own. formally, agent eventually take back
decision-making control iff, time t:
Z
P> (t0 )W (t0 ):dt0 W (t) > EQdU (t) EQdA (t)
(7)


left-hand side calculates future expected wait costs right-hand side
calculates extra utility gained getting response user. result
leads following general conclusion strategies end giving control back
agent:
Lemma 1: 2 isRa strategy ending e 2 E , s0 sA, EUsd0 > EUsd iff
8e 2 E; 9t < P>(t0 )W (t0 ):dt0 W (t) > EQde (t) EQdA(t)
Lemma 1 says if, point time, expected cost indefinitely leaving
control hands user exceeds difference quality agent's
user's decisions, strategies ultimately give agent control dominate
not. Thus, rate wait cost accrual increases difference
relative quality decision-making abilities decreases user's probability response
decreases, strategies agent eventually takes back control dominate.
key consequence Lemma (in opposite direction) that, rate costs accrue
accelerate, probability response stays constant (i.e., Markovian),
agent indefinitely leave control user (if user originally
given control), since expected wait cost change time. Hence, even
agent faced situation potentially high total wait costs, optimal strategy
may one-shot strategy handing control waiting indefinitely,
expected future wait costs point time relatively low. Thus, Lemma 1 isolates
condition consider appending transfer-of-control action
strategy.
perform similar analysis identify conditions
include action strategy. agent incentive changing coordination
constraints via action due additional time made available getting highquality response entity. However, overall value action depends
number factors (e.g., cost taking action timing subsequent
transfers control). calculate expected value comparing EU
strategy without D. useful increased expected value
strategy greater cost, Dcost .
Lemma 2: sR2 s0 included EUsd0 > EUsd iff
R
P> (t0 )W (t):dt0
P>(t0 )W (tjD):dt0 > Dcost
illustrate consequences Lemma 2 considering specific problem model
Appendix (i.e., P> (t) = exp , W (t) = ! exp!t , EQde (t) = c, candidate strategies
iff ( ! )! exp ( !) (1 exp !Dvalue ) >
eA e DA). case, EUedDA > EUeA
Dcost. Figure 4 plots value action vary rate wait cost accumulation,
w, parameter Markovian response probability function, p. graph shows
186

fiTowards Adjustable Autonomy Real World

Value
0.16
0.12
0.08
0.04
0
-0.04
0.1 0.2
w0.3 0.4 0.5

1
0.75
0.5 p
0.25

Figure 4: value action particular model (P> (t) = exp
EQde (t) = c).

,

W (t) = ! exp!t ,

benefit highest probability response neither low
high. probability response low, user unlikely respond,
even given extra time; hence, agent incurred Dcost benefit.
also little value probability response high, user likely
respond shortly D, meaning little effect (the effect
wait costs action taken). Overall, according Lemma 2, points
graph goes Dcost , agent include action, and, points,
not. Figure 4 demonstrates value action specific subclass problem
domains, extend conclusion general case well. instance,
specific model exponential wait costs, models wait costs grow
slowly, fewer situations Lemma 2's criterion holds (i.e.,
useful). Thus, Lemma 2 allows us eliminate strategies consideration, based
evaluation criterion particular domain interest.
Given Lemma 2's evaluation adding single action strategy, natural
ask whether second, third, etc. action would increase EU even further. words,
complex strategy better simple one, even complex strategy even
better? answer \not necessarily".

8K 2 N; 9W 2 W; 9P 2 P; 9EQ 2 EQ optimal strategy
actions.
Informally, Lemma 3 says cannot fix single, optimal number actions,
every possible number actions, potential domain (i.e., combination
Lemma 3:

K

wait-cost, response-probability, expected-quality functions) number
actions justified optimal. Consider situation cost
function number Ds date (i.e., cost K th f (K )). example,
E-Elves' meeting case, cost delaying meeting third time much
higher cost first delay, since delay successively annoying
meeting participants. Hence, test usefulness K th strategy,
187

fiScerri, Pynadath & Tambe
given specific model Appendix I, is:

!

exp exp! )
(8)
f (K ) < !(exp Dvalue! 1) ( exp


Depending nature f (K ), Equation 8 hold number Ds, so,
K , conditions strategy K Ds optimal. instance,
Section 5.3, show maximum length optimal strategy random
configuration 25 entities usually less eight actions.
Equation 8 illustrates value additional limited changing Dcost ,
Lemma 3 also shows us factors affect value additional D.
example, even constant Dcost , value additional depends many
actions agent performs. Figure 4 shows value depends
rate wait costs accrue. rate wait cost accrual accelerates time (e.g.,
exponential model), action slows acceleration, rendering second action
less useful (since wait costs accruing slowly). Notice also Ds become
valueless deadline, wait costs stop accruing.
Taken together, Lemmas 1-3 show particular transfer-of-control strategy dominates others across domains. Moreover, different strategies, single-shot
strategies arbitrarily complex strategies, appropriate different situations, although
range situations particular transfer-of-control action provides benefit
quite narrow. Since strategy might low EU set parameters, choosing
wrong strategy lead poor results. hand, understand
parameter configuration intended application domain, Lemmas 1-3 provide useful
tools focusing search optimal transfer-of-control strategy. Lemmas
used off-line substantially reduce space strategies need searched
find optimal strategy. However, general may many strategies finding
optimal strategy may possible feasible.

3.3 Model Predictions E-Elves
section, use model predict properties successful approach AA
E-Elves. Using approximate functions probability response, wait cost,
expected decision quality, calculate EU various strategies determine
types strategies going useful. Armed knowledge, predict
key properties successful implementation.
key feature E-Elves user mobile. moves around environment, probability responding requests decisions changes drastically, e.g.,
likely respond workstation. calculate EU different strategies,
need know P>(t), means need estimate response probabilities
model change user moves around. Friday communicates via
workstation dialog box, user respond, average, five minutes. However,
Friday communicates via Palm pilot average user response time hour. Users
generally take longer decide whether want present research meeting, taking
approximately two days average. So, function P>(t) average value
5 minutes user oce, average one hour user contacted
via Palm pilot average two days decision whether present
188

fiTowards Adjustable Autonomy Real World
research meeting. also necessary estimate relative quality user, EQdU (t),
Friday's decision making, EQdA (t). assume user's decision-making EQdU (t)
high respect Friday's, EQdA (t). uncertainty user intentions makes
hard Friday consistently make correct decisions time user
arrive meetings, although sensors (e.g., GPS device) give indication
user's location. dealing important meetings, cost Friday's errors
higher. Thus, cases, decision-making quality user Friday
similar, i.e., EQUd (t) EQAd (t); cases, order magnitude
difference, i.e., EQUd (t) 10 EQAd (t). wait cost function, W (t), much larger
big meetings small increase rapidly attendees wait longer meeting
room. Finally, cost delays, i.e., Dcost , vary order magnitude.
particular, cost rescheduling meetings varies greatly, e.g., cost rescheduling
small informal meetings colleagues far less rescheduling full lecture room
5 PM Friday.
parameters laid show parameters vary decision decision.
specific decision, use Markovian response probabilities (e.g., user
oce, average response time five minutes), exponentially increasing wait costs,
constant decision-making quality (though changes decision decision) calculate
EU interesting strategies. Calculating EU different strategies using values
different parameters shown allows us draw following conclusions (Table 5
Section 5.3 presents quantitative illustration predictions):

strategy e used, since combinations user location
meeting importance EU strategy low.

Multiple strategies required, since different user locations meeting importance different strategies optimal.

Since quite different strategies required user different locations,
AA reasoning need change strategies user changes location.

strategy reasonable EU possible parameter instantiations, hence always
using strategy occasionally cause dramatic failures.

decisions, strategies end agent taking decision, since strategies
ending user control generally low EU.

predictions provide important guidance successful solution AA
E-Elves. particular, make clear approach must exibly choose
different strategies adjust depending meeting type user location.
Section 2.2 described unsuccessful C4.5 approach AA E-Elves identified
several reasons mistakes occurred. particular, rigidly transferring control
one entity ignoring potential team costs involved agent's decision highlighted
reasons dramatic mistakes Friday's autonomy reasoning. Reviewing C4.5
approach light notion strategies, see Friday learned one strategy
stuck strategy. particular, originally, Friday would wait indefinitely user
response, i.e., would follow strategy e , learned transfer control. shown later
189

fiScerri, Pynadath & Tambe
Table 5, strategy low EU. fixed-length timeout introduced,
Friday would follow strategy e (5)A. strategy high EU EQUd (t) EQAd (t)
low EU EQUd (t) 10 EQAd (t). Thus, model explains phenomenon
observed practice.
hand, use model understand C4.5's failure case
mean never useful AA. Different strategies required
certain parameters (like probability response wait cost) change significantly.
applications parameters change dramatically decision decision,
one particular strategy may always appropriate. applications, C4.5 might learn
right strategy small amount training data perform acceptably well.
4.

Operationalizing Strategies MDPs

formalized problem AA selection transfer-of-control strategy highest EU. need operational mechanism allows agent
perform selection. One major conclusion previous section different
strategies dominate different situations, applications E-Elves require mechanism(s) selecting strategies situation-sensitive fashion. particular,
mechanism must exibly change strategies situation changes. required mechanism must also represent utility function specified expected decision qualities,
EQ, costs violating coordination constraints, W, coordination-change cost,
Dcost. Finally, mechanism must also represent uncertainty entity responses
look ahead possible responses (or lack thereof) may occur future.
MDPs natural means performing decision-theoretic planning required find
best transfer-of-control strategy. MDP policies provide mapping agent's
state optimal transfer control strategy. encoding parameters model
AA strategies MDP, MDP effectively becomes detailed implementation
model and, hence, assumes properties. use standard algorithms (Puterman,
1994) find optimal MDP policy and, hence, optimal strategies follow
state.
simplify exposition, well illustrate generality resulting MDP,
section describes mapping AA strategies MDP four subsections.
particular, Section 4.1 provides direct mapping strategies abstract MDP. Section
4.2 fills state features enable concrete realization reward function,
still maintaining domain-independent view. Thus, section completely defines general
MDP AA potentially reusable across broad class domains. Section 4.3 illustrates
implemented instantiation MDP E-Elves. Section 4.4 addresses practical
issues operationalizing MDPs domains E-Elves.

4.1 Abstract MDP Representation AA Problem
MDP representation's fundamental state features capture state control:

controlling-entity entity currently decision-making control.
ei -response response ei made agent's requests input.
190

fiTowards Adjustable Autonomy Real World
Original State Action
Destination State
ectrl time
ectrl ei -response
time
ej
tk
ei
ei
yes
tk+1
ej
tk
ei
ei

tk+1
ei
tk
wait
ei
yes
tk+1
ei
tk
wait
ei

tk+1
ei
tk

ei

tk Dvalue

Probability
1
1

R tk+1 ei
tkR P> (t)dt
tk+1 ei
tk P> (t)dt
R tk+1
ei
tkR P> (t)dt
tk+1 ei
tk P> (t)dt

1

Table 2: Transition probability function AA MDP. ectrl controlling-entity.



time current time, typically discretized ranging 0 deadline,
| i.e., set ft0 = 0; t1 ; t2 ; : : : ; tn = g.

ei -response null time = , agent terminal state. former
case, decision value ei -response.
specify set actions MDP representation = E [fD; waitg.
set actions subsumes set entities, E , since agent transfer decision-making
control one entities. action coordination-change action
changes coordination constraints, discussed earlier. \wait" action puts transferring control making autonomous decision, without changing coordination
team. agent reason \wait" best action when, time, situation
likely change put agent position improved autonomous decision
transfer-of-control, without significant harm. example, E-Elves domain, times
closer meeting, users generally make accurate determinations whether
arrive time, hence sometimes useful wait meeting long
time off.
transition probabilities (specified Table 2) represent effects actions
distribution effects (i.e., ensuing state world). If, state
time = tk , agent chooses action transfers decision-making control entity,
ei , agent itself, outcome state controlling-entity = ei
time = tk+1 . two possible outcomes ei -response: either entity responds
decision transition (producing terminal state), not,
derive probability distribution two P. \wait" action similar
branch, except controlling-entity remains unchanged. Finally, action occurs
instantaneously, time controlling entity respond, resulting
state effectively moves earlier time (e.g., tk tk Dvalue ).
derive reward function MDP straightforward fashion
strategy model. Table 3 presents complete specification reward function.
transitions take time, i.e., transferring control receiving response
(Table 3, row 1) \wait" (Table 3, row 2), agent incurs wait cost interval.
transitions agent performs D, agent incurs cost action (Table 3,
row 3). terminal states response ei , agent derives expected quality
entity's decision (Table 3, row 4). policy maximizes reward agent
expects receive according AA MDP model correspond exactly optimal
191

fiScerri, Pynadath & Tambe
controlling-entity time ei -response Action
ej
tk

ei
ei
tk

wait
ei
tk


ei
tk
yes

Reward

W (k + 1) W (k)
W (k + 1) W (k)
Dcost
EQdei (tk )

Table 3: Reward function AA MDP.
transfer-of-control strategy. Note reward function described abstract
fashion|for example, specify compute agent's expected quality
decision, EQAd (t).

4.2 MDP Representation AA Problem within Team Context
given high-level description MDP implementing notion
transfer-of-control strategies AA. remainder section provides detailed
look MDP broad class AA domains (including E-Elves) agent
acts behalf user filling role, , within context team activity, ff.
reward function compares EU different strategies, finding optimal one
current state. facilitate calculation, need represent parameters used
model. introduce following state features capture aspects AA
problem team context:

team-orig-expect- team originally expected fulfilling .
team-expect- team's current expectations fulfilling role implies.
agent-expect- agent's (probabilistic) estimation fulfilled.
\other ff attributes" encapsulate aspects joint activity affected
decision.

add specific features generic AA state features already
presented, overall state, within MDP representation decision d, tuple:

hcontrolling-entity; team-orig-expect-; team-expect-; agent-expect-; ff-status;
ei -response; time; ff attributesi
example, meeting scenario, team-orig-expect- could \Meet 3pm", teamexpect- could \Meet 3:15pm" user requested delay, agent-expect- could
\Meet 3:30pm" agent believes user make rescheduled meeting.
transition probability function AA MDP team context includes
underlying AA transition probabilities Table 3, must also include probabilities
new state features. particular, addition temporal effect
action described Section 4.1, additional effect coordination ff.
action changes value team-expect- feature (in domain-dependent
192

fiTowards Adjustable Autonomy Real World
deterministic way). actions affect team's expectations. team-orig-expect-
feature change; include simplify definition reward function.
transition probabilities agent-expect- ff-specific features domain-specific.
provide example transition probabilities Section 4.3.
final part MDP representation reward function. team AA MDP
framework uses reward function breaks function Table 3 follows:

R(s; a) = f (team-orig-expect-(s); team-expect- (s); agent-expect- (s);
ff-status (s); time(s); a)
X
=
EQde (time(s)) e -response

(9)

e 2E nfAg

1 f1 (k team-orig-expect- (s) team-expect- (s) k)
21 f21 (time(s))
22 f22 (k team-expect-(s) agent-expect-(s) k)
+3 f3 (ff-status (s)) + 4 f4 (a)

(10)

first component reward function captures value getting response
decision-making entity agent itself. Notice one entity actually
respond, one e -response non-zero. corresponds EQed (t) function
used model bottom row Table 3. f1 function ects inherent
value performing role team originally expected, hence deterring agent
taking costly coordination changes unless gain indirect value
so. corresponds Dcost mathematical model third row Table 3.
f21 corresponds second row Table 3, represents wait cost function,
W (t), model. component encourages agent keep team members
informed role's status (e.g., making decision taking explicit action),
rather causing wait without information. Functions f22 f3 represent
quality agent's decision, represented QAd (t). standard MDP algorithms
compute expectation agent's reward, expectation quality
produce desired EQAd (t) fourth row Table 3. first quality function, f22 ,
ects value keeping team's understanding role performed
accordance agent expects user actually perform role. agent
receives reward role performed exactly team expects,
uncertainty agent's expectation, errors possible. f22 represents costs
come errors. second quality component, f3 , uences overall reward based
successful completion joint activity, encourages agent take actions
maximize likelihood joint activity succeeds. desire joint
task succeed implicit mathematical model must explicitly represented
MDP. component, f4 , augments first row Table 3 account additional
costs transfer-of-control actions. particular, f4 broken follows:
(

f4 (a) =

q(e ) 2 E
0
otherwise
193

(11)

fiScerri, Pynadath & Tambe
function q(e ) represents cost transferring control particular entity, e.g.,
cost WAP phone message user. Notice, detailed, domain-specific costs
appear directly model.
Given MDP's state space, actions, transition probabilities, reward function,
agent use value iteration generate policy P : ! specifies optimal
action state (Puterman, 1994). agent executes policy taking
action policy dictates every state finds itself. policy
may include several transfers control coordination-change actions. particular
series actions depends activities user. interpret policy
contingent combination many transfer-of-control strategies, strategy follow
chosen depending user's status (i.e., agent-expect-).

4.3 Example: E-Elves MDPs
example AA MDP generic delay MDP, instantiated
meeting Friday may act behalf user. Recall decision, d, whether
let meeting attendees wait user begin meeting. joint activity,
ff, meeting agent role, , ensuring user attends
meeting scheduled time. coordination constraints, , attendees
arrive meeting location simultaneously effect action delay
cancel meeting.
delay MDP's state representation, team-orig-expect- originally-scheduledmeeting-time, since attendance originally scheduled meeting time team
originally expects user best possible outcome. team-expect- timerelative-to-meeting, may increase meeting delayed. ff-status becomes statusof-meeting. agent-expect- represented explicitly; instead, user-location used
observable heuristic user likely attend meeting. example,
user away department shortly meeting begin unlikely
attending time, all. state features, total state space contains
2800 states individual meeting, large number states arising
fine-grained discretization time.
general reward function mapped delay MDP reward function following way.
(

g(N; ff) N < 4
(12)
1
otherwise
N number times meeting rescheduled g function takes
account factors like number meeting attendees, size meeting delay
time originally scheduled meeting time. function effectively forbids
agent ever performing 4 actions.
delay MDP, functions, f21 f22 , correspond cost making
meeting attendees wait, merge single function, f2 . expect
consolidation possible similar domains team's expectations relate
f1 =

194

fiTowards Adjustable Autonomy Real World
temporal aspect role performance.
(

f2 =

h(late; ff) late > 0
0
otherwise

(13)

late difference scheduled meeting time time user
arrives meeting room. late probabilistically calculated MDP based
user's current location model user's behavior.
8
>
<

rff + ruser user attends
f3 = > rff
meeting takes place, user attend
: 0
otherwise

(14)

value, rff , models inherent value ff, value ruser models user's
individual value ff.
f4 given previously Equation 11. cost communicating user
depends medium used communicate. example, higher cost
communicating via WAP phone via workstation dialog box.
users asked input, assumed that, respond, response
\correct", i.e., user says delay meeting 15 minutes, assume
user arrive time re-scheduled meeting. user asked front
his/her workstation, dialog like one shown Figure 5 popped up, allowing user
select action taken. expected quality agent's decision calculated
considering agent's proposed decision possible outcomes decision.
example, agent proposes delaying meeting 15 minutes, calculation
decision quality includes probability benefits user actually arrive
15 minutes originally scheduled meeting time, probability costs
user arrives originally scheduled meeting time, etc.

(a)

(b)

Figure 5: (a) Dialog box delaying meetings. (b) small portion delay MDP.
delay MDP also represents probabilities change user location (e.g.,
oce meeting location) occur given time interval. Figure 5(b) shows portion
195

fiScerri, Pynadath & Tambe
state space, showing user-response, user location features. transition
labeled \delay n" corresponds action \delay n minutes". figure also shows
multiple transitions due \ask" (i.e., transfer control user) \wait" actions,
relative probability outcome represented thickness arrow.
state transitions correspond uncertainty associated user's response (e.g.,
agent performs \ask" action, user may respond specific information may
respond all, leaving agent effectively \wait"). One possible policy produced
delay MDP, subclass meetings, specifies \ask" state S0 Figure 5(b)
(i.e., agent gives autonomy). world reaches state S3, policy specifies
\wait". However, agent reaches state S5, policy chooses \delay 15",
agent executes autonomously. terms strategies, sequence actions
H D.
Earlier, described another AA decision E-Elves, namely whether close
auction open team role. Here, brie describe key aspects mapping
decision MDP. auction must closed time user prepare
meeting, sucient time given interested users submit bids
human team leader choose particular user. team-orig-expect- (s) highquality presenter selected enough time prepare. action, hence
team-expect- (s) = team-orig-expect- (s). agent-expect-(s) whether agent believes
high-quality bid believes bid arrive time user allocated
role. agent's decision quality, EQdA (t), function number bids
submitted quality bids, e.g., team members submitted
bids one user's bid stands out, agent confidently choose user
presentation. Thus, ff-status primarily quality best bid far difference
quality bid second-best bid. critical component
reward function Equation 10 2 component, gives reward agent
fulfills users' expectation willing presenter high-quality presentation.

4.4 User-Specified Constraints
standard MDP algorithms provide agent optimal policies subject encoded probabilities reward function. Thus, agent designer access correct
models entities' (e.g., human users E-Elves) decision qualities probabilities response, agent select best possible transfer-of-control strategy.
However, possible entities accurate information
abilities agent designer. exploit knowledge, entity could
communicate model quality decision probability response directly
agent designer. Unfortunately, typical entity unlikely able express
knowledge form MDP reward function transition probabilities. agent
could potentially learn additional knowledge interactions
entities domain. However, learning may require arbitrarily large number
interactions, take place without benefit entities' inside
knowledge.
alternative, provide language constraints allows entities
directly immediately communicate inside information agent. constraint
196

fiTowards Adjustable Autonomy Real World

Figure 6: Screenshot tool entering constraints. constraint displayed forbids
transferring control (i.e., forces transfer) five minutes meeting
teammates previously given information user's attendance
meeting.
language provides entities simple way inform agent specific properties
needs. entity use constraint forbid agent entering specific states
performing specific actions specific states. constraints directly communicated
user via tool shown Figure 6. instance, figure shown user
forbidding agent autonomous action five minutes meeting. define
forbidden-action constraints set, Cfa , element constraint
boolean function, cfa : !ft; f g. Similarly, define forbidden-state constraints
set, Cfs , elements, cfs : !ft; f g. constraint returns particular domain
element (either state state-action pair, appropriate), constraint applies
given element. example, forbidden-action constraint, cfa , forbids action
performed state cfa (s; a) = t.
provide probabilistic semantics, suitable MDP context, first provide
notation. Denote probability agent ever arrive state sf following
jP ). Then, define semantics
policy, P , initial state si Pr(si !
f
jP ) = 0. semantics given
forbidden-state constraint cfs requiring Pr(si !
f
^P (s )=ajP ) = 0
forbidden-action constraint, cfa , bit complex, requiring Pr(si!
f
f
(i.e., cfa forbids agent entering state sf performing action a).
cases, aggregation constraints may forbid actions state sf . case,
conjunction allows agent still satisfy forbidden-action constraints avoiding sf
(i.e., state sf becomes forbidden). state, sf , becomes indirectly forbidden
fashion, action potentially leads agent ancestor state
sf likewise becomes forbidden. Hence, effect forbidding constraints propagate
backward state space, affecting state/action pairs beyond cause
immediate violations.
197

fiScerri, Pynadath & Tambe
forbidding constraints powerful enough entity communicate wide
range knowledge decision quality probability response agent.
instance, E-Elves users forbidden agents rescheduling meetings
lunch time. so, users provide feature specification states want
forbid, meeting-time =12 PM. specification generates forbidden-state
constraint, cfs , true state, s, meeting-time =12 PM s. constraint
effectively forbids agent performing action would result state
meeting-time =12PM. Similarly, users forbidden autonomous actions certain
states providing specification actions want forbid, e.g., action 6=\ask".
generates forbidden-action constraint, cfa , true state/action pair,
(s; a), 6=\ask". example, user might specify constraint states
oce, time meeting know
always make decisions case. Users easily create complicated constraints
specifying values multiple features, well using comparison functions
= (e.g., 6=, >).
Analogous forbidding constraints, also introduce required-state requiredaction constraints, defined sets, Crs Cra , respectively. interpretation provided
required-state constraint symmetric, opposite forbidden-state
jP ) = 1. Thus, state, agent must eventually reach
constraint: Pr(si !
f
^P (s )=ajP ) = 1.
required state, sf . Similarly, required-action constraint, Pr(si!
f
f
users specify constraints forbidding counterparts (i.e., specifying values relevant state features action, appropriate). addition,
requiring constraints also propagate backward. Informally, forbidden constraints focus
locally specific states actions, required constraints express global properties
states.
resulting language allows agent exploit synergistic interactions
initial model transfer-of-control strategies entity-specified constraints. example,
forbidden-action constraint prevents agent taking autonomous action
particular state equivalent user specifying agent must transfer control
user state. AA terms, user instructs agent consider transferof-control strategies violate constraint. exploit pruning strategy
space user, extended standard value iteration also consider constraint
satisfaction generating optimal strategies. Appendix II provides description
novel algorithm finds optimal policies respecting user constraints. appendix
also includes proof algorithm's correctness.
5. Experimental Results

section presents experimental results aimed validating claims made previous sections. particular, experiments aim show utility complex transfer-ofcontrol strategies effectiveness MDPs technique operationalization.
Section 5.1 details use E-Elves daily activities Section 5.2 discusses
pros cons living working assistance Fridays. Section 5.3 shows
characteristics strategies type domain (in particular, different strategies
198

fiTowards Adjustable Autonomy Real World
used practice). Finally, Section 5.4 describes detailed experiments illustrate
characteristics AA MDP.

5.1 E-Elves Daily Use
E-Elves system heavily used ten users research group ISI, June
2000 December 2000.5 Friday agents ran continuously, around clock, seven
days week. exact number agents running varied period execution,
usually five ten Friday agents individual users, capability matcher (with proxy),
interest matcher (with proxy). Occasionally, temporary Friday agents operated
behalf special guests short-term visitors.
Daily Counts Exchanged Messages
No. Messages

300
250
200
150
100
50
0
Jun Jul Aug Sep Oct Nov Dec
Date

Figure 7: Number daily coordination messages exchanged proxies seven-month
period.
Figure 7 plots number daily messages exchanged Fridays seven months
(June December, 2000). size daily counts ects large amount
coordination necessary manage various activities, high variability illustrates
dynamic nature domain (note low periods vacations final exams).
Figure 8(a) illustrates number meetings monitored user. seven
months, nearly 700 meetings monitored. users fewer 20 meetings,
others 250. users 50% meetings delayed (this includes
regularly scheduled meetings cancelled, instance due travel). Figure 8(b)
shows usually 50% delayed meetings autonomously delayed.
graph, repeated delays single meeting counted once. graphs show
5. user base system greatly reduced period due personnel relocations
student graduations, remains use smaller number users.

199

fiUser Delays vs. Autonomous Delays

Meetings Monitored vs. Meetings Delayed
400
350
300
250
200
150
100
50
0

140

Number Meetings

ito

ramanan

tambe

nair

scerri

modi

pynadath

jungh

Total Delays
Human Delays

120

Monitored
Delayed

kulkarni

Number Meetings

Scerri, Pynadath & Tambe

100
80
60
40
20
0
1

Users

2

3

4

5

6

7

8

Users

(a)

(b)

Figure 8: (a) Monitored vs. delayed meetings per user. (b) Meetings delayed autonomously
vs. hand.
agents acting autonomously large number instances, but, equally importantly,
humans also often intervening, indicating critical importance adjustable autonomy
Friday agents.
seven-month period, presenter USC/ISI's TEAMCORE research group
presentations decided using auctions. Table 4 shows summary auction results.
Column 1 (\Date") shows dates research presentations. Column 2 (\No.
Bids") shows total number bids received decision. key feature
auction decisions made without 9 users entering bids; fact, one case,
4 bids received. Column 3 (\Best bid") shows winning bid. winner typically
bid < 1; 1 >, i.e., indicating user represents capable willing
presentation | high-quality bid. Interestingly, winner July 27 made
bid < 0; 1 >, i.e., capable willing. team able settle winner
despite bid highest possible, illustrating exibility. Finally, columns
4 (\Winner") 5 (\Method") show auction outcome. `H' column 5 indicates
auction decided human, `A' indicates decided autonomously. five
seven auctions, user automatically selected presenter. two manual
assignments due exceptional circumstances group (e.g., first-time visitor),
illustrating need AA.
Date
No. bids Best bid Winner Method
Jul 6, 2001
7
1,1
Scerri
H
Jul 20, 2001
9
1,1
Scerri

Jul 27, 2001
7
0,1
Kulkarni

Aug 3, 2001
8
1,1
Nair

Aug 3, 2001
4
1,1
Tambe

Sept 19, 2001
6
-,Visitor
H
Oct 31, 2001
7
1,1
Tambe

Table 4: Results auctioning research presentation slot.
200

fiTowards Adjustable Autonomy Real World
5.2 Evaluating Pros Cons E-Elves Use
general effectiveness E-Elves shown several observations.
E-Elves' operation, group members exchanged email messages announce
meeting delays. Instead, Fridays autonomously informed users delays, thus reducing
overhead waiting delayed members. Second, overhead sending emails recruit
announce presenter research meetings assumed agent-run auctions. Third,
web page, Friday agents post users' location, commonly used avoid
overhead trying track users manually. Fourth, mobile devices kept users
informed remotely changes schedules, also enabling remotely delay
meetings, volunteer presentations, order meals, etc. Users began relying Friday
heavily order lunch one local \Subway" restaurant owner even suggested: \. . .
computers getting order food. . . might think marketing
them!!". Notice daily use E-Elves number different users occurred
MDP implementation AA replaced unreliable C4.5 implementation.
However, agents ensured users spent less time daily coordination (and
miscoordination), price paid. One issue users felt
less privacy location continually posted web monitored
agent. Another issue security private information credit card numbers
used ordering lunch. users adjusted agents monitor daily activities,
users adjusted behavior around agent. One example
behavior users preferring minute two early meeting lest
agent decide late delay meeting. general, since agents never made
catastrophically bad decisions users felt comfortable using agent frequently
took advantage services.
emphatic evidence success MDP approach that, since replacing
C4.5 implementation, agents never repeated catastrophic mistakes
enumerated Section 2.2. particular, Friday avoids errors error 3 Section
2.2 selecting strategy single, large action, higher EU
strategy many small Ds (e.g., DDDD). Friday avoids error 1, large cost
associated erroneous cancel action significantly penalizes EU cancellation.
Friday instead chooses higher-EU strategy first transfers control user
taking action autonomously. Friday avoids errors errors 2 4 selecting
strategies situation-sensitive manner. instance, agent's decision-making
quality low (i.e., high risk), agent perform coordination-change action
allow time user response agent get information.
words, exibly uses strategies like e DeA, rather always using e (5)A strategy
discussed Section 2.2. indicates reasonably appropriate strategy chosen
situation. Although current agents occasionally make mistakes, errors
typically order transferring control user minutes earlier may
necessary. Thus, agents' decisions reasonable, though always optimal.6
6. inherent subjectivity user feedback makes determination optimality dicult.

201

fiScerri, Pynadath & Tambe
5.3 Strategy Evaluation
previous section looked application MDP approach E-Elves
address strategies particular. section, specifically examine strategies
E-Elves. show Fridays indeed follow strategies strategies followed
ones predicted model. also show model led insight that,
turn, led dramatic simplification one part implementation. Finally, show
use strategies limited E-Elves application showing empirically
that, random configurations entities, optimal strategy one
transfer-of-control action 70% cases.
Figure 9 shows frequency distribution number actions taken per meeting
(this graph omits \wait" actions). number actions taken meeting corresponds
length part strategy followed (the strategy may longer,
decision made actions taken). graph shows MDP
followed complex strategies real world followed different strategies
different times. graph bears model's predictions different strategies would
required good solution AA problem E-Elves domain.
Table 5 shows EU values computed model strategy selected
MDP. Recall MDP explicitly models users' movements locations,
model assumes users move. Hence, order accurate
comparison model MDP's results, focus cases
user's location change (i.e., probability response constant).
EU values calculated using parameter values set Section 3.3. Notice,
MDP often perform Ds transferring control buy time reduce
uncertainty. model abstraction domain, actions, like changes
user location, captured. Except slight discrepancy first case
match MDP's behavior model's predictions exact, provided
ignore actions beginning MDP strategies. Thus, despite model
considerably abstracted domain high correlation MDP
policies model's suggested strategies. Moreover, general properties policies
predicted model borne exactly. particular, recall model
predicted different strategies would required, strategy e would used,
generally strategies ending would best | properties MDP policies.
model predicts parameters vary greatly sucient find
single optimal strategy follow strategy situation. MDP
decision close auction instance E-Elves. pattern
behavior followed every time open role needs filled team. consistency
arises wait cost (since meetings same)
pattern incoming bids reasonably consistent (variations individuals' behavior
cancel look team whole). model predicts
parameters change, find optimal strategy parameters
execute strategy every time. However, since MDP worked effectively
meeting AA, MDP also chosen implementing auction AA.
realized parameters vary greatly, concluded MDP could replaced
simple implementation optimal strategy. verify hypothesis, replaced
202

fiTowards Adjustable Autonomy Real World

No. meetings

No. actions per meeting
200
180
160
140
120
100
80
60
40
20
0
0

2

4
6
8
No. actions

10

12

Figure 9: frequency distribution number steps taken AA strategy
meeting scenario. actions taken meeting, meeting
cancelled Friday started AA reasoning.

Location

e
eA e DA MDP
Small meeting, active participant
oce
14.8 -277 41.9 42.05 DDe DA
@ dept. 14.8 -6E7 31.4 28.0 DDeA
@ meet loc. 14.8 -2E5 39.2 39.1
eA
Large meeting, passive participant
oce
14.6 -7E12 30.74 30.65 DDeA
@ dept. 14.6 -2E17 14.6 7.7
DDeA
@ meet loc. 14.5 -7E14 25.1 23.5
eA
Table 5: EU values simple strategies calculated model. last column
shows strategy actually followed MDP.

203

fiScerri, Pynadath & Tambe
Date No. Bids MDP eA
7/20/00
9
25% 26%
7/27/00
7
14% 20%
8/3/00
8
29% 23%
Table 6: Auction results. \MDP" column shows percentage available auction
time remaining MDP chose close auction. \eA" column
shows percentage available auction time remaining strategy eA,
EQde (t) proportional number bids received (\No. Bids" column),
would closed auction.

general MDP code three simple lines code implementing eA strategy,
determined optimal particular parameters problem. Using log files
recorded actual auctions reported (Scerri, Pynadath, & Tambe, 2001),
experimentally verified MDP eA strategy produced result.
Table 6 shows percentage available auction time remaining (e.g., auction
opened four days role performed, closing auction one day
would correspond 25%) MDP version eA version code closed
auction. number bids used estimate agent's expected decision quality.
timing auction closing close, certainly within hours. result
precisely MDP strategy implementations, MDP
implementation reactive incoming bids strategy implementation.
confirm need strategies phenomenon unique particular
settings E-Elves, experiment run randomly generated configurations
entities. wait cost configuration increased exponentially, rate
accrual varying configuration configuration. configurations contained
3 25 entities, randomly chosen Markovian response probabilities randomly
chosen, constant, decision-making quality. cost value action also
randomly selected. configuration, agent could respond instantly,
lower decision quality entities. configuration,
optimal transfer-of-control strategy found. Figure 10(a) shows percentage optimal
strategies (z-axis) length (y-axis \jOpt. Strat.j"), separated according
rate wait costs accrued (x-axis, \Wait Cost Param"). figure shows
rate wait cost accrues low, optimal strategies length
one, agent handing control entity highest decision-making
quality. rate wait cost accrual high, strategies length two,
agent brie giving best decision maker opportunity make decision
taking back control acting wait costs became high. intermediate
values wait cost parameter, considerably variation length
optimal strategy. Figure 10(b) shows percentage optimal strategies length
wait cost parameter 0.12 (i.e., slice Figure 10(a)). Hence, strategies
often contained several transfers control several coordination changes. Thus,
experiment shows complex transfer-of-control strategies useful, E-Elves,
204

fiTowards Adjustable Autonomy Real World
range domains, especially wait costs neither negligible
accruing fast.
Strategy Lengths w = 0.12
35

% Opt. Strats.

30
25
% Opt. Strats.

100
90
80
70
60
50
40
30
20
10
01

2

20
15
10

3

|Opt. Strat.|

4

5

6

7

8 0

0.35 0.4
0.25 0.3
0.15 0.2
0.1
Wait
Cost
Param
0.05

5
0
1

(a)

2

3

4
5
|Opt. Strat.|

6

7

8

(b)

Figure 10: (a) Percentage optimal strategies certain length, broken according fast wait costs accruing. (b) Percentage optimal strategies
certain length wait cost parameter = 0.12.
Thus, shown MDP produces strategies Friday follows
strategies practice. Moreover, strategies followed ones predicted model.
practical use, followed prediction model, i.e., MDP
required auctions, able substantially reduce complexity one part
system. Finally, showed need strategies specifically phenomenon
E-Elves domain.

5.4 MDP Experiments
Experience using MDP approach AA E-Elves indicates effective
making reasonable AA decisions. However, order determine whether MDPs
generally useful tool AA reasoning, systematic experiments required.
section, present systematic experiments determine important properties
MDPs AA. MDP reward function designed result optimal strategy
followed state.
experiments, vary one parameters weights
different factors Equation 10. MDP instantiated range values
parameter policy produced value. case, total policy
defined 2800 states. policy analyzed determine basic properties
policy. particular, counted number states policy specifies ask,
delay, say user attending say user attending. statistics
show broadly policy changes parameters change, e.g., whether Friday gives
autonomy less cost coordination change increased. first
aim experiments simply confirm policies change desired expected
way parameters reward function changed. instance, Friday's expected
decision quality increased, states makes autonomous
205

fiScerri, Pynadath & Tambe
decision. Secondly, practical perspective critical understand sensitive
MDP policies small variations parameters, sensitivity would mean
small variations parameter values significantly impact MDP performance.
Finally, experiments reveal interesting phenomena.
first experiment looks effect 1 parameter Equation 10, represented delay MDP implementation team repair cost (function g Equation
12), policies produced delay MDP. parameter determines averse Friday changing coordination constraints. Figure 11 shows properties
policy change team repair cost value varied. x-axis gives value
team repair cost, y-axis gives number times action appears
policy. Figure 11(a) shows number times Friday ask user input.
number times transfer control exhibits interesting phenomenon: number
asks maximum intermediate value parameter. low values,
Friday \confidently" (i.e., decision quality high) make decisions autonomously,
since cost errors low, hence less value relinquishing autonomy.
high team repair costs, Friday \confidently" decide autonomously make
coordination change. intermediate region Friday uncertain needs
call user's decision making often. Furthermore, cost delaying
meeting increases, Friday delay meeting less (Figure 11(b)) tell team
user attending often (Figure 11(d)). so, Friday gives user less time
arrive meeting, choosing instead announce user attending.
Essentially, Friday's decision quality become close enough user's decision quality
asking user worth risk respond cost asking
input. Except jump value zero non-zero value,
number times Friday says user attending change (Figure 11(c)).
delay MDP use E-Elves team repair cost parameter set two. Around
value policy changes little, hence slight changes parameter lead
large changes policy.
second experiment, vary 2 parameter Equation 10, implemented
delay MDP variable team wait cost (function h Equation 13).
factor determines heavily Friday weigh differences
team expects user fulfill role user actually fulfill role.
particular, determines cost team members wait meeting room
user. Figure 12 shows changes policy parameter varied (again
x-axis shows value parameter y-axis shows number times
action appears policy). graph number times agent asks
policy (Figure 12(a)), exhibits phenomena 1 parameter varied,
i.e., increasing decreasing parameter increases. graphs show that,
cost teammates' time increases, Friday acts autonomously often (Figure 12(bd)). Friday asks whenever potential costs asking lower potential costs
errors makes { cost time waiting user decision increases, balance
tips towards acting. Notice phenomenon number asks increasing
decreasing occurs way 1 parameter; however, occurs
slightly different reason. case, waiting costs low, Friday's decision-making
quality high acts autonomously. waiting costs high, Friday cannot
206

fiTowards Adjustable Autonomy Real World

Number delays policy

68
66
64
62
60
58
56
54
52
50
48

# delays

# asks

Number asks policy

0

2
4
6
8
"Team repair cost" weight

140
130
120
110
100
90
80
70
60
50
40
30

10

0

(a)

Number Attending messages policy
# Attending

# attending

140
135
130
125
120
115
110
105
100
95
90
2
4
6
8
"Team repair cost" weight

10

(b)

Number Attending messages policy

0

2
4
6
8
"Team repair cost" weight

10

70
60
50
40
30
20
10
0
0

(c)

2
4
6
8
"Team repair cost" weight

(d)

Figure 11: Properties MDP policy team repair cost varied.

207

10

fiScerri, Pynadath & Tambe
afford risk user respond quickly, acts autonomously (despite
decision quality low). Figure 12(b) shows number delay actions taken
Friday increases, states meeting already delayed twice.
indicates normally expensive third delay meeting starts
become worthwhile cost teammates wait meeting room high.
delay MDP, value 1 used 2 . decision transfer control (i.e., ask)
particularly sensitive changes parameter around value|again, slight
changes significant impact.
Number Asks policy

Number Delays policy

70
# delays

# asks

50
40
30

100
80
60
40
20
0

20
0

2

4

6

8

10

0

"Cost teammates time" weight

4

6

8

10

(b)

Number Attending messages policy
30
# Attending

Number Attending messages policy
260
240
220
200
180
160
140
120
100
80
0

2

"Cost teammates time" weight

(a)

# Attending

Total
1st Delay
2nd Delay
3rd Delay

120

60

2
4
6
8
10
"Cost teammates time" weight

25
20
15
10
5
0
0

(c)

2
4
6
8
10
"Cost teammates time" weight

(d)

Figure 12: Properties MDP policy teammate time cost varied. (b) shows
number times meeting delayed states yet
delayed, delayed already, delayed
twice already.
third experiment, value 3 , weight joint task, varied
(Figure 13). E-Elves, value joint task includes value user
meeting value meeting without user. experiment, value
208

fiTowards Adjustable Autonomy Real World
meeting without user varied. Figure 13 shows policy changes value
meeting without user changes (again x-axis shows value parameter
y-axis shows number times action appears policy). graphs
show significantly instability values. large changes
result simultaneous change utility taking key actions expected
quality Friday's decision making, e.g., utility saying user attending much
higher meeting low value without user. current delay MDP,
value set 0.25, part graph insensitive small changes
parameter.
three experiments above, specific E-Elves parameters regions
graph small changes parameter lead significant changes policy.
However, regions graphs policy change dramatically small
changes parameter. indicates domains, parameters different
E-Elves, policies sensitive small changes parameters.

180
160
140
120
100
80
60
40
20
0
-10

Number delays policy
120
100
# delays

# asks

Number asks policy

80
60
40

-8

-6
-4
-2
0
Joint activity weight

20
-10

2

-8

(a)

Number Attending messages policy
20
# attending

# attending

180
160
140
120
-8

-6
-4
-2
0
Joint activity weight

2

(b)

Number Attending messages policy
200

100
-10

-6
-4
-2
0
Joint activity weight

15
10
5
0
-10

2

(c)

-8

-6
-4
-2
Joint activity weight

0

2

(d)

Figure 13: Properties MDP policy importance successful joint task
varied.
209

fiScerri, Pynadath & Tambe
experiments show three important properties MDP approach AA.
First, changing parameters reward function generally lead changes
policy expected desired. Second, value parameters uenced
policy, effect AA reasoning often reasonably small, suggesting small
errors model affect users greatly. Finally, interesting phenomena
number asks reaching peak intermediate values parameters revealed.
three previous experiments examined behavior MDP changes
parameters reward function changed. another experiment, central
domain-level parameter affecting behavior MDP, i.e., probability getting
user response cost getting response (corresponding f4 ), varied. Figure
14 shows number times Friday chooses ask (y-axis) varies
expected time get user response (x-axis) cost (each line
graph represents different cost). MDP performs expected, choosing ask
often cost low and/or likely get prompt response. Notice
that, cost low enough, Friday sometimes choose ask user even
long expected response time. Conversely, expected response time suciently
high, Friday assume complete autonomy. graph also shows distinct
change number asks point (depending cost), outside change
point graphs relatively at. key reason fairly rapid change number
asks often difference quality Friday's user's decision
making fairly small range. mean response time increases, expected wait
costs increase, eventually becoming high enough Friday decide act autonomously
instead asking.

# Asks

Number Asks Policy
70
60
50
40
30
20
10
0
0.01

Cost = 0.0001
Cost = 0.2
Cost = 1.0

0.1
1
10
Mean Response Time

100

Figure 14: Number ask actions policy mean response time (in minutes) varied.
x-axis uses logarithmic scale.
conclude section quantitative illustration impact constraints
strategy selection. experiment, merged user-specified constraints
E-Elves users, resulting set 10 distinct constraints. started unconstrained
210

fiTowards Adjustable Autonomy Real World

Figure 15: (a) Number possible strategies (logarithmic). (b) Time required strategy
generation.
instance delay MDP added constraints one time, counting strategies
satisfied applied constraints. repeated experiments expanded
instances delay MDP, increased initial state space increasing
frequency decisions (i.e., adding values time-relative-to-meeting feature).
expansion results three new delay MDPs, artificial, uenced
real delay MDP. Figure 15a displays results (on logarithmic scale), line
corresponds original delay MDP (2760 states), lines B (3320 states), C (3880
states), (4400 states) correspond expanded instances. data point
mean five different orderings constraint addition. four MDPs, constraints
substantially reduce space possible agent behaviors. instance, original
delay MDP, applying 10 constraints eliminated 1180 2760 original states
consideration, reduced mean number viable actions per acceptable state
3.289 2.476. end result 50% reduction size (log10 ) strategy space.
hand, constraints alone provide complete strategy, since
plots stay well 0, even 10 constraints. Since none individual users
able/willing provide 10 constraints, cannot expect anyone add enough constraints
completely specify entire strategy. Thus, MDP representation associated
policy selection algorithms still far redundant.
constraints' elimination behaviors also decreases time required strategy
selection. Figure 15b plots total time constraint propagation value iteration
four MDPs Figure 15a (averaged five constraint orderings).
data point also mean five separate iterations, total 25 iterations
per data point. values zero-constraint case correspond standard value iteration without constraints. savings value iteration restricted strategy space
dramatically outweigh cost pre-propagating additional constraints. addition,
savings increase size MDP. original delay MDP (A),
28% reduction policy-generation time, largest MDP (D), 53%
reduction. Thus, introduction constraints provide dramatic acceleration
agent's strategy selection.

211

fiScerri, Pynadath & Tambe
6.

Related Work

discussed related work Section 1. section adds discussion.
Section 6.1, examine two representative AA systems { detailed experimental
results presented { explain results via model. illustrates
potential applicability model systems. Section 6.2, examine AA
systems areas related work, meta-reasoning, conditional planning
anytime algorithms.

6.1 Analyzing AA Work Using Strategy Model
Goodrich, Olsen, Crandall, Palmer (2001) report tele-operated teams robots,
user's high-level reasoning robots' low-level skills required
achieve task. Within domain, examined effect user neglect
robot performance. idea user neglect similar idea entities taking time
make decisions; case, user \neglects" robot, joint task takes longer
perform. domain, coordination constraint user input must arrive
robot work low-level actions needs perform. Four control systems
tested robot, giving different amount autonomy robot,
performance measured user neglect varied.
Although quite distinct E-Elves system, mapping Goodrich's team robots
AA problem formulation provides interesting insights. system
interesting feature entity robot call decision, i.e., user, also
part team. Changing autonomy robot effectively changes nature
coordination constraints user robot. Figure 16 shows performance
(y-axis) four control policies amount user neglect increased (x-axis).
experiments showed higher robot autonomy allowed operator \neglect"
robot without serious impact performance.
notion transfer-of-control strategies used qualitatively predict
behavior observed practice, even though Goodrich et al. (2001) use
notion strategies. lowest autonomy control policy used Goodrich et al. (2001)
pure tele-operation one. Since robot cannot resort decision making,
represent control policy strategy U , i.e., control indefinitely hands
user. second control policy allows user specify waypoints on-board
intelligence works details getting waypoints. Since robot highlevel decision-making ability, strategy simply give control user. However,
since coordination robot user abstract, i.e., coordination
constraints looser, wait cost function less severe. Also human giving less
detailed guidance fully tele-operated case (which good according
(Goodrich et al., 2001)), hence use lower value expected quality user
decision. denote approach Uw p distinguish fully tele-operated case.
next control policy allows robot choose waypoints given user
inputs regions interest. robot also accept waypoints user. ability
robot calculate waypoints modeled D, since effectively changes
coordination entities, removing user's need give waypoints. model
control policy strategy U DU . final control policy full autonomy, i.e., A.
212

fiTowards Adjustable Autonomy Real World
Performance



UDU
U wp

U

Neglect

(a)
Goodrich robot operation EU
60
40
EU

20
0
-20
-40
-60
2

1.5

(b)

1
p

0.5

0

Figure 16: Goodrich al's various control strategies plotted neglect. (a) Experimental results. Thinner lines represent control systems intelligence
autonomy. (b) Results theoretically derived model strategies presented article (p parameter probability response function).
Robot decision making inferior user, hence robot's decision quality less
user's. graphs four strategies, plotted probability response
parameter (getting smaller right, match \neglect" Goodrich et al graph)
shown Figure 16. Notice shape graph theoretically derived model,
shown Figure 16(b), qualitatively shape experimentally derived
graph, Figure 16(a). Hence, theory predicted qualitatively performance
found experimentation.
common assumption earlier AA work entity asked
decision make decision promptly, hence strategies handling contingency
213

fiScerri, Pynadath & Tambe
lack response required. example, Horvitz's (1999) work using
decision theory aimed developing general, theoretical models AA reasoning
user workstation. prototype system, called LookOut, helping users manage
calendars implemented test ideas (Horvitz, 1999). Although systems
distinctly different E-Elves, mapping problem formulation allows us
analyze utility approaches across range domains without implement
approach domains.
critical difference Horvitz's work work LookOut
address possibility receiving (timely) response. Thus, complex strategies
required. typical case LookOut, agent three options: take
action, take action, engage dialog. central factor uencing
decision whether user particular goal action would aid, i.e., user
goal, action useful, he/she goal, action
disruptive. Choosing act act corresponds pursuing strategy A.7 Choosing
seek user input corresponds strategy U . Figure 17(a) shows graph different
options plotted probability user goal (corresponds Figure 6
Horvitz (1999)). agent's expected decision quality, EQdA (t) derived Equation
2 Horvitz (1999). (In words, Horvitz's model performs detailed calculations
expected decision quality.) model predicts selection strategies
Horvitz does, i.e., choosing strategy EQdA (t) low, U otherwise (assuming
two strategies available). However, model predicts something
Horvitz consider, i.e., rate wait costs accrue becomes
non-negligible choice simple. Figure 17(b) shows EU two
strategies changes rate wait costs accruing increased. fact optimal
strategy varies wait cost suggests Horvitz's approach would immediately
appropriate domain wait costs non-negligible, e.g., would need
modified many multi-agent settings.

6.2 Approaches AA
Several different approaches taken core problem whether
transfer decision-making control. example, Hexmoor examines much time agent
AA reasoning (Hexmoor, 2000). Similarly, Dynamic Adaptive Autonomy
framework, group agents allocates votes amongst themselves, hence defining amount
uence agent decision thus, definition, autonomy
agent respect decision (Barber, Martin, & Mckay, 2000b). related
application meeting scheduling Cesta, Collia, D'Aloisi (1998) taken approach
providing powerful tools users constrain monitor behavior proxy
agents, agents explicitly reason relinquishing control user.
least work done multiagent context, possibility multiple
transfers control considered.
Complementing work, researchers focused issues architectures
AA. instance, AA interface 3T architecture (Bonasso, Firby, Gat, Kortenkamp,
7. consider choosing act autonomous decision, hence categorize way autonomous action

214

fiTowards Adjustable Autonomy Real World

Horvitzs EU Calculations Wait Cost
1

EU

0
-1
-2
0

0.2
0.4
0.6
0.8
Probability User Goal

1

(a)

Horvitzs EU Calculations Wait Cost
0.4

EU

0.2
0
-0.2
-0.4
-0.6
0

0.05 0.1 0.15 0.2 0.25 0.3

(b)

w

Figure 17: EU different agent options. solid (darkest) line shows EU taking
autonomous action, dashed (medium dark) line shows EU autonomously deciding act dotted line shows EU transferring
control user. (a) Plotted probability user goal,
wait cost. (b) plotted wait cost, fixed probability user goal.
Miller, & Slack, 1997) implemented solve human-machine interaction problems
experienced number NASA projects (Brann, Thurman, & Mitchell, 1996).
experiences showed interaction system required way
deliberative layer detailed control actuators. AA controls layers
encapsulated referred 3T's fourth layer { interaction layer
215

fiScerri, Pynadath & Tambe
(Schreckenghost, 1999). similar area AA technology required safety-critical
intelligent software, controlling nuclear power plants oil refineries (Musliner
& Krebsbach, 1999). work resulted system called AEGIS (Abnormal Event
Guidance Information System) combines human agent capabilities rapid
reaction emergencies petro-chemical refining plant. AEGIS features shared task
representation users intelligent system work (Goldman,
Guerlain, Miller, & Musliner, 1997). key hypothesis work model needs
multiple levels abstraction user interact level see fit.
Interesting work Fong, Thorpe, Baur (2002) extended idea tele-operated
robotics re-defining relationship robot user collaborative one,
rather traditional master-slave configuration. particular, robot treats
human resource perform perceptual cognitive functions robot
determines cannot adequately perform. However, yet work looked
possibility user available provide input required, would require
robot perform complex transfer-of-control reasoning.
previous work AA ignored complex strategies AA, work
research fields potentially relevant. example, research issues addressed fields mixed-initiative decision-making (Collins, Bilot, Gini, & Mobasher,
2000b), anytime algorithms (Zilberstein, 1996), multi-processor scheduling (Stankovic, Ramamritham, & Cheng, 1985), meta-reasoning (Russell & Wefald, 1989), game theory (Fudenberg & Tirole, 1991), contingency plans (Draper, Hanks, & Weld, 1994; Peot &
Smith, 1992) have, least superficial, similarities AA problem. However,
turns core assumptions focus research areas different
enough algorithms developed related fields directly applicable
AA problem.
mixed-initiative decision making human user assumed continually available
(Collins et al., 2000b; Ferguson & Allen, 1998), negating need reasoning
likelihood response. Furthermore, often little time pressure coordination
constraints. Thus, basic problem transferring control human
agent common mixed-initiative decision making AA, assumptions
quite different leading distinct solutions. Likewise, related research fields make
distinctly different assumptions lead distinctly different solutions. instance,
contingency planning (Draper et al., 1994; Peot & Smith, 1992) deals problem
creating plans deal critical developments environment. Strategies related
contingency planning plans deal specific contingency
entity making decision manner maintains coordination. However, contingency planning, key diculty creating plans. contrast, AA, creating
strategies straightforward key diculty choosing strategies.
contribution recognizing need strategies addressing AA problem, instantiating strategies via MDPs, development general, domain-independent
reward function leads MDP choosing optimal strategy particular situation.
Similarly, another related research area meta-reasoning (Russell & Wefald, 1989).
Meta-reasoning work looks online reasoning computation. type meta-reasoning,
closely related AA, chooses sequences computations different ex216

fiTowards Adjustable Autonomy Real World
pected quality running time, subject constraint choosing highest-quality
sequence computations possible (because takes long) (Russell & Wefald,
1989). idea treat computations actions \meta-reason" EU
certain combinations computation (base-level) actions. output metareasoning sequence computations executed sequence. AA parallels metareasoning consider reasoning transferring control entities reasoning
selecting computations, i.e., think entities computations. However, AA,
aim one entity make high-quality decision, meta-reasoning, aim
sequence computations high quality. Moreover, meta-reasoning
assumption computations guaranteed return timely result executed,
apply AA. Finally, meta-reasoning looks sequence computations use
fixed amount time, AA reasons trading extra time better decision
(possibly buying time action). Thus, algorithms developed meta-reasoning
applicable AA.
Another research area conceptual similarity AA field anytime algorithms (Zilberstein, 1996). anytime algorithm quickly finds initial solution
incrementally tries improve solution stopped. AA problem similar
assume agent make immediate decision, problem
property solution always available (an important property anytime
algorithm). However, case general, i.e., agent always
answer. Furthermore, anytime algorithms generally need deal multiple,
distributed entities, opportunity change coordination (i.e., using
action).
Multi-processor scheduling looks assigning tasks nodes order meet certain
time constraints (Stankovic et al., 1985). entities thought \nodes", AA
also assigning tasks nodes. multiprocessor scheduling, quality
computation performed nodes usually assumed equal, i.e., nodes
homogeneous. Thus, reasoning trades quality time required,
AA. Moreover, deadlines externally imposed multi-processor scheduling algorithms,
rather exibly reasoned AA. Multi-processor scheduling algorithms
sometimes deal node rejecting task cannot fulfill time constraints
network failures. However, AA problem focuses failure get response
central issue load balancing auxiliary issue, multi-processor scheduling
opposite focus. difference focus leads algorithms developed
multiprocessor scheduling community well suited AA (and vice versa).
7.

Conclusions

Adjustable autonomy critical success real-world agent systems allows
agent leverage skills, resources decision-making abilities entities,
human agent. Previous work addressed AA context single-agent
single-human scenarios, solutions scale increasingly complex multiagent systems. particular, previous work used rigid, one-shot transfers control
consider team costs and, importantly, consider possibility costly

217

fiScerri, Pynadath & Tambe
miscoordination team members. Indeed, applied rigid transfer-of-control
approach multi-agent context, failed dramatically.
article makes three key contributions enable application AA
complex multiagent domains. First, article introduces notion transfer-of-control
strategy. transfer-of-control strategy consists conditional sequence two types
actions: (i) actions transfer decision-making control (ii) actions change
agent's pre-specified coordination constraints team members, aimed minimizing
miscoordination costs. strategies allow agents plan sequences transfer-of-control
actions. Thus, strategy allows agent transfer control entities best able make
decisions, buy time decisions made still avoid miscoordination | even
entity control transferred fails make decision. Additionally,
introduced idea changing coordination constraints mechanism giving
agent opportunity provide high-quality decisions, showed changes
can, cases, effective way increasing team's expected utility.
second contribution article mathematical model AA strategies
allows us calculate expected utility strategies. model shows
complex strategies indeed better single-shot strategies situations,
always superior. fact, analysis showed particular strategy dominates
whole space AA decisions; instead, different strategies optimal different
situations.
third contribution article operationalization notion transferof-control strategies via Markov Decision Processes general reward function
leads MDP find optimal strategies multiagent context. general, domainindependent reward function allow approach potentially applied
multi-agent domains. implemented, applied, tested MDP approach AA reasoning real-world application supporting researchers daily activities. Daily use
showed MDP approach effective balancing need avoid risky autonomous
decisions potential costly miscoordination. Furthermore, detailed experiments
showed policies produced MDPs desirable properties, transferring control user less often probability getting timely response low.
Finally, practical experience system revealed users require ability manipulate AA reasoning agents. end, introduced constraint language
allows user limit range behavior MDP exhibit. presented
algorithm processing constraints, showed desirable property
reducing time takes find optimal policies.
8.

Future Work

model AA presented article suciently rich model wide variety
interesting applications. However, key factors modeled
current formulation required domains. One key issue allow agent
factor AA reasoning agents AA reasoning. instance,
Elves domain, one agent likely decide delay meeting, another agent may
wait decision avoid asking user. Conversely, agent take
back control decision knows another agent going continue waiting user input,
218

fiTowards Adjustable Autonomy Real World
might also continue wait input. interactions substantially increase
complexity reasoning agent needs perform. article, assumed
agent finding transfer-of-control strategy single, isolated decision.
general, many decisions made agent able
ignore interactions decisions. example, transferring control many
decisions user, reduces probability getting prompt response them.
Reasoning interactions add complexity required reasoning
agent.
Another focus future work generalizing AA decision making allow
types constraints | coordination constraints | taken account.
would turn require generalization concept action include types
stop-gap actions may lead different types strategies agent could pursue.
Additionally, transfer-of-control actions could generalized allow parts decision
transferred, e.g., allow input received user without transferring total
control him/her, allow actions could performed collaboratively. Similarly,
actions reversible, agent could make decision allow user reverse
it. hope generalizations would improve applicability adjustable
autonomy research complex domains.
Acknowledgments

research supported DARPA award no. F30602-98-2-0108. effort
managed Air Force Research Labs/Rome site. article unifies, generalizes, significantly extends approaches described previous conference papers (Scerri et al., 2001;
Scerri, Pynadath, & Tambe, 2002; Pynadath & Tambe, 2001). thank colleagues,
especially, Craig Knoblock, Yolanda Gil, Hans Chalupsky Tom Russ collaborating
Electric Elves project. would also like thank JAIR reviewers
useful comments.

219

fiScerri, Pynadath & Tambe
Appendix A: Example Instantiation Model

Appendix, present detailed look one possible instantiation AA model.
use instantiation calculate EU commonly used strategies show
EU varies parameters rate wait cost accrual time
transfers control performed. instantiation, agent, A, one entity
call decision (i.e., user U ), hence E = fA; U g. W (t), use following
function:
(

!t
W (t) = !! exp
exp! otherwise

(15)

exponential wait cost function ects idea big delay much worse
small one. polynomial similar function could also used exponential
used since makes mathematics cleaner. probability response use:
P>(t) = exp . Markovian response probability ects entity likely
respond next point time previous point. users moving around dynamic environment, turns reasonable approximation.
entities' decision-making quality constant time, particular, EQdA (t) = ff
EQdU (t) = fi . Assuming constant decision-making quality always accurate
dynamic environment since information available entity may change (hence uencing
ability make decision) however, decisions involving static facts preferences
decision-making quality relatively constant. functions coarse approximation range interesting applications, including E-Elves. Table 7 shows resulting
instantiated equations simple strategies (For convenience let = !). Figures
18(a) (b) show graphically EU eA strategy varies along different axes (w
parameter wait cost function, higher w means faster accruing wait costs
p parameter response probability function, higher p means faster response).
Notice EU depends transfer time (T) much fi (the user's
decision quality). Figure 18(d) shows value (as discussed earlier).
Figure 18(c) compares EU e DeA e strategies. complex
transfer-of-control strategy (i.e., transfers control makes), atter
EU graph plotted wait cost (w) response probability (p) parameters.
particular, fall-off wait costs high probability response low
dramatic complex strategy.

Appendix B: Constraint Propagation Algorithm Correctness

Section 4.4, examined need user-specified constraints conjunction
MDP-based approach strategies. must thus extend standard MDP policy
evaluation algorithms support evaluation strategies accounting
standard quantitative reward function new qualitative constraints. appendix
provides novel algorithm developed evaluate strategies accounting
220

fiTowards Adjustable Autonomy Real World

5
4.5
4
3.5
3
0

20
15
10
5
0
-5

1.5
0.1

w 0.2

0.3

0.5

1 p

0

10

(a)

T20

30

40

(b)
Value
0.16
0.12
0.08
0.04
0
-0.04

5
0
-5
0.1

w 0.2

0.3

4

20
16
12
beta
8

0.4

1.2
0.8p

0.1 0.2
w0.3 0.4 0.5

(c)

1
0.75
0.5 p
0.25

(d)

Figure 18: Equation 17, i.e., strategy eA plotted (a) ! (i.e., w, rate
wait costs accrue) (i.e., p likelihood response) (b) (transfer
time)and beta (the user's decision quality). (c) Comparing strategies e DeA
e (dotted line e ). (d) value D.

221

fiScerri, Pynadath & Tambe


EUed = exp !(

= ! exp
EUeA

(

1) + exp



1)

!
+fi


(ff

fi)

(16)

!
+fi


(17)

EUedDeAt =
(18)
!

value
! (exp 1) + fi (1 exp ) + ! exp
(exp exp ) +


(Dcost fi )(exp exp ) + ! exp! (exp !Dvalue 1)(exp exp )
exp (Dcost ff + !(exp! exp!( Dvalue ) + exp!(T Dvalue ) ))
Table 7: Instantiated AA EU equations simple transfer control strategies.
both. also present detailed proof algorithm's output correct strategy
(i.e., strategy highest expected utility, subject user-specified constraints).
standard MDP value iteration algorithm, value strategy particular
state single number, expected utility U . addition two types
constraints, value tuple hF; N; U i. F represents strategy's ability satisfy
forbidding constraints; therefore, boolean indicating whether state forbidden
not. N represents strategy's ability satisfy necessary constraints; therefore,
set requiring constraints satisfied. traditional value iteration,
U expected reward. instance, value state, V (s) = htrue; fcrs g; 0:3i,
executing policy state achieve expected value 0.3 satisfy
required-state constraint crs . However, guaranteed satisfy requiredstate, required-action, constraints. addition, forbidden, nonzero
probability violating forbidden-action forbidden-state constraint. record
forbidding constraints policy violates, since violating one equally
bad. record requiring constraints policy satisfies, since satisfying
constraints preferable satisfying them. Therefore, size
value function grows linearly number requiring constraints, independent
number forbidding constraints.
Following form standard value iteration, initialize value function
states considering immediate value strategy given state, without
lookahead. precisely:

V 0 (s)

*

_

c2Cfs

+

c(s); fc 2 Crs jc(s)g ; RS (s)

(19)

Thus, state forbidden forbidden-state constraints immediately apply,
satisfies required-state constraints immediately apply. standard value
iteration, expected utility value reward function state.
222

fiTowards Adjustable Autonomy Real World
value iteration, must define updated value function V t+1 refinement
previous iteration's value function, V . States become forbidden V t+1
violate constraints directly successors forbidden according V .
States satisfy requirements satisfy directly successors satisfy
requirement. simplify following expressions, define 0 set
successors: fs0 2 jMssa 0 > 0g. following expression provides precise definition
iterative step:
*

_
_
_
max
c(s) _
c(s; a) _
F 0;
a2A c2C

0
0
0
c2Cfa V (s )=hF ;N ;U 0 i;s0 2S 0
fs
\
fc 2 Crsjc(s)g [ fc 2 Cra jc(s; a)g [ N 0;
V (s0 )=hF 0 ;N 0 ;U 0 i;s0 2S 0
+
X
RS (s) + R(s; a) + Mssa 0 U 0
(20)
V (s0 )=hF 0 ;N 0 ;U 0 i;s0 2S 0
standard value iteration, iterative step specifies maximization possible choices action. However, two additional components represent value
strategy respect constraints, longer obvious comparison
function use evaluating candidate actions. Therefore, perform maximization
using following preference ordering, x means preferable x:
ht; N; U

f; N 0; U 0ff ff
hF; N; U
F; N 0 N; Uff0
hF; N; U F; N; U 0 > U

V t+1 (s)

words, satisfying forbidden constraint takes highest priority, satisfying
requiring constraints second, increasing expected value last. define optimal
action, P (s), action, a, final V (s) expression maximized.
Despite various set operations Equation 20, time complexity iteration
step exceeds standard value iteration linear factor, namely number
constraints, jCfs j + jCfa j + jCrsj + jCra j. eciency derives fact
constraints satisfied/violated independently other. determination whether
single constraint satisfied/violated requires time standard value
iteration, hence overall linear increase time complexity.
expected value lowest priority, separate iterative step
Equation 20 two phases: constraint propagation value iteration.
constraint-propagation phase, compute first two components value function, hF; N; i. value-iteration phase computes third component, h; ; U i,
standard value iteration. However, ignore state/action pairs that, according
results constraint propagation, violate forbidding constraint (ht; N; i) requiring constraint (hf; N Crs [ Cra ; i). component-wise independence
Equation 20, two-phase algorithm computes identical value function original,
single-phase version (over state/action pairs satisfy constraints).
rest Appendix provide proof correctness modified value
iteration policy. Given policy, P , constructed according algorithm, must
223

fiScerri, Pynadath & Tambe
show agent following P obey constraints specified user. agent
begins state, 2 , must prove satisfy constraints
V (s) = hf; Cra [ Crs ; U i. prove results forbidding requiring constraints
separately.

Theorem 1 agent following policy, P , value function, V , generated Section 4.4, state 2 violate forbidding constraint probability zero
V (s) = hf; N; U (for U N ).
Proof: prove theorem induction subspaces states, classified

\close" violating forbidding constraint. precisely, partition
state space, , subsets, Sk , defined contain states violate forbidding
constraint minimum k state transitions. words, S0 contains states
violate forbidding constraint directly; S1 contains states violate
forbidding constraints themselves, successor state (following transition
probability function, P ) (i.e., successor state S0 ); S2 contains states
violate forbidding constraints, successors do,
least one successor state successor state (i.e., successor state
S1 ); etc. jS j nonempty subsets mutually exclusive sequence.
make partition exhaustive, special subset, S1 , contains states
agent never violate forbidding constraint following P . first show, induction
k, 8s 2 Sk (0 k jS j), V (s) = ht; N; U i, required theorem.
Basis step (S0): definition, agent violate forbidding constraint 2 S0 .
Therefore, either 9c 2 Cfs c(s) = 9c 2 Cfa c(s; P (s)) = t,
know, Equation 20, V (s) = ht; N; U i.
Inductive step (Sk ; 1 k jS j): Assume, induction hypothesis, 8s0 2
Sk 1 , V (s0 ) = ht; N 0 ; U 0 i. definition Sk , state, 2 Sk , least one
successor state, s0 2 Sk 1 . Then, according Equation 20, V (s) = ht; N; U i,
disjunction 0 must include s0 , F 0 = t.
Therefore, induction, know 2 Sk (0 k jS j), V (s) = ht; N; U i.
show 8s 2 S1 , V (s) = hf; N; U i. prove, induction t, that,
state, 2 S1, V (s) = hf; N; U i.
Basis step (V 0 ): definition, 2
S1 , thereff cannot exist c 2 Cfs
c(s) = t. Then, Equation 19, V 0 (s) = f; N 0 ; U 0 .
Inductive step (V ; > 0): Assume,
inductive
hypothesis, that, s0 2 S1 ,
ff
V 1 (s0 ) = hf; N 0 ; U 0 i. know V (s) = f; N ; U three disjunctions
Equation 20 false. first false, described basis step. second term
similarly false, since, definition S1, cannot exist c 2 Cfa
c(s; P (s)) = t. evaluating third term, first note 0 S1. words,
successor states also S1 (if successor s0 2 Sk finite k,
2 Sk+1). Since successors S1 , know, inductive hypothesis,
disjunction V 1 successors
fffalse. Therefore, three disjunctive


terms Equation 20 false, V (s) = f; N ; U .
Therefore, induction, know 2 S1 , V (s) = hf; N; U i. definition
state partition, two results prove theorem required. 2
224

fiTowards Adjustable Autonomy Real World
Theorem 2 agent following policy, P , value function, V , generated described
Section 4.4, state 2 satisfy every requiring constraint
probability one V (s) = hF; Cra [ Crs ; U (for U F ).
Proof Sketch: proof parallels Theorem 1, state partition, Sk ,
k corresponds maximum number transitions satisfying requiring
constraint. However, here, states S1 violate constraint, rather

satisfy it. cycles state space prevent guarantee satisfying requiring
constraint within fixed number transitions, although probability satisfaction
limit may 1. current constraint semantics, decided
situation fails satisfy constraint, algorithm behaves accordingly. cycles
effect handling forbidding constraints, where, saw Theorem 1,
need consider minimum -length trajectory. 2
proofs two theorems operate independently, policy-specified action
satisfy constraints, action exists. precedence forbidding constraints
requiring ones effect optimal action states. However,
con icting forbidding requiring constraints state, preference ordering
causes agent choose policy satisfies forbidding constraint violates
requiring constraint. agent make opposite choice simply change
preference ordering Section 4.4. Regardless choice, Theorems 1 2,
agent use value function, V , identify existence violation
notify user violation possible constraint con ict.
References

Barber, K., Goel, A., & Martin, C. (2000a). Dynamic adaptive autonomy multi-agent
systems. Journal Experimental Theoretical Artificial Intelligence, 12 (2), 129{
148.
Barber, K. S., Martin, C., & Mckay, R. (2000b). communication protocol supporting
dynamic autonomy agreements. Proceedings PRICAI 2000 Workshop Teams
Adjustable Autonomy, pp. 1{10, Melbourne, Australia.
Bonasso, R., Firby, R., Gat, E., Kortenkamp, D., Miller, D., & Slack, M. (1997). Experiences architecture intelligent reactive agents. Journal Experimental
Theorectical Artificial Intelligence, 9 (1), 237{256.
Brann, D., Thurman, D., & Mitchell, C. (1996). Human interaction lights-out automation: field study. Proceedings 1996 Symposium Human Interaction
Complex Systems, pp. 276{283, Dayton, USA.
Cesta, A., Collia, M., & D'Aloisi, D. (1998). Tailorable interactive agents scheduling
meetings. Lecture Notes AI, Proceedings AIMSA'98, No. 1480, pp. 153{166.
Springer Verlag.
Chalupsky, H., Gil, Y., Knoblock, C., Lerman, K., Oh, J., Pynadath, D., Russ, T., & Tambe,
M. (2001). Electric Elves: Applying agent technology support human organizations.
International Conference Innovative Applications AI, pp. 51{58.
225

fiScerri, Pynadath & Tambe
Collins, J., Bilot, C., Gini, M., & Mobasher, B. (2000a). Mixed-initiative decision-support
agent-based automated contracting. Proceedings International Conference
Autonomous Agents (Agents'2000).
Collins, J., Bilot, C., Gini, M., & Mobasher, B. (2000b). Mixed-initiative decision support
agent-based automated contracting. Proceedings International Conference
Autonomous Agents (Agents'2000), pp. 247{254.
Dorais, G., Bonasso, R., Kortenkamp, D., Pell, B., & Schreckenghost, D. (1998). Adjustable
autonomy human-centered autonomous systems mars. Proceedings
First International Conference Mars Society, pp. 397{420.
Draper, D., Hanks, S., & Weld, D. (1994). Probabilistic planning information gathering
contingent execution. Hammond, K. (Ed.), Proc. Second International Conference Artificial Intelligence Planning Systems, pp. 31{37, University Chicago,
Illinois. AAAI Press.
Ferguson, G., Allen, J., & Miller, B. (1996). TRAINS-95 : Towards mixed-initiative
planning assistant. Proceedings Third Conference Artificial Intelligence
Planning Systems, pp. 70{77.
Ferguson, G., & Allen, J. (1998). TRIPS : intelligent integrated problem-solving assistant. Proceedings Fifteenth National Conference Artificial Intelligence(AAAI98), pp. 567{573, Madison, WI, USA.
Fong, T., Thorpe, C., & Baur, C. (2002). Robot partner: Vehicle teleoperation collaborative control. Workshop Multi-Robot Systems, Naval Research Laboratory,
Washington, D.C.
Fudenberg, D., & Tirole, J. (1991). Game Theory. MIT Press, Cambridge, Massachusetts.
Goldman, R., Guerlain, S., Miller, C., & Musliner, D. (1997). Integrated task representation indirect interaction. Working Notes AAAI Spring Symposium
Computational Models Mixed-Initiative Interaction.
Goodrich, M., Olsen, D., Crandall, J., & Palmer, T. (2001). Experiments adjustable
autonomy. Hexmoor, H., Castelfranchi, C., Falcone, R., & Cox, M. (Eds.), Proceedings IJCAI Workshop Autonomy, Delegation Control: Interacting
Intelligent Agents.
Gunderson, J., & Martin, W. (1999). Effects uncertainty variable autonomy maintainance robots. Agents'99 Workshop Autonomy Control Software, pp. 26{34.
Hexmoor, H. (2000). cognitive model situated autonomy. Proceedings PRICAI2000, Workshop Teams Adjustable Autonomy, pp. 11{20, Melbourne, Australia.
Hexmoor, H., & Kortenkamp, D. (2000). Introduction autonomy control software. Journal
Experiemental Theoretical Artificial Intelligence, 12 (2), 123{128.
Horvitz, E. (1999). Principles mixed-initiative user interfaces. Proceedings ACM
SIGCHI Conference Human Factors Computing Systems (CHI'99), pp. 159{166,
Pittsburgh, PA.
226

fiTowards Adjustable Autonomy Real World
Horvitz, E., Jacobs, A., & Hovel, D. (1999). Attention-sensitive alerting. Proceedings
Conference Uncertainty Artificial Intelligence (UAI'99), pp. 305{313, Stockholm, Sweden.
Lesser, V., Atighetchi, M., Benyo, B., Horling, B., Raja, A., Vincent, R., Wagner, T., Xuan,
P., & Zhang, S. (1999). UMASS intelligent home project. Proceedings
Third Annual Conference Autonomous Agents, pp. 291{298, Seattle, USA.
Mitchell, T., Caruana, R., Freitag, D., McDermott, J., & Zabowski, D. (1994). Experience
learning personal assistant. Communications ACM, 37 (7), 81{91.
Mulsiner, D., & Pell, B. (1999). Call papers: AAAI spring symposium adjustable
autonomy. www.aaai.org.
Musliner, D., & Krebsbach, K. (1999). Adjustable autonomy procedural control
refineries. AAAI Spring Symposium Agents Adjustable Autonomy, pp.
81{87, Stanford, California.
Peot, M. A., & Smith, D. E. (1992). Conditional nonlinear planning. Hendler, J. (Ed.),
Proc. First International Conference Artificial Intelligence Planning Systems, pp.
189{197, College Park, Maryland. Morgan Kaufmann.
Puterman, M. L. (1994). Markov Decision Processes. John Wiley & Sons.
Pynadath, D., Tambe, M., Arens, Y., Chalupsky, H., Gil, Y., Knoblock, C., Lee, H., Lerman,
K., Oh, J., Kamachandran, S., Rosenbloom, P., & Russ, T. (2000). Electric-elves:
Immersing agent organization human organization. Proceedings
AAAI Fall Symposium Socially Intelligent Agents { Human Loop.
Pynadath, D., & Tambe, M. (2001). Revisiting Asimov's first law: response call
arms. Intelligent Agents VIII Proceedings International workshop Agents,
Theories, Architectures Languages (ATAL'01).
Quinlan, J. R. (1993). C4.5: Programs machine learning. Morgan Kaufmann, San
Mateo, CA.
Russell, S. J., & Wefald, E. (1989). Principles metareasoning. Brachman, R. J.,
Levesque, H. J., & Reiter, R. (Eds.), KR'89: Principles Knowledge Representation
Reasoning, pp. 400{411. Morgan Kaufmann, San Mateo, California.
Scerri, P., Pynadath, D., & Tambe, M. (2001). Adjustable autonomy real-world multiagent environments. Proceedings Fifth International Conference Autonomous Agents (Agents'01), pp. 300{307.
Scerri, P., Pynadath, D., & Tambe, M. (2002). elf acted autonomously: Towards
theory adjustable autonomy. First International Joint Conference Autonomous Agents Multi-Agent Systems (AAMAS'02).
Schreckenghost, D. (1999). Human interaction control software supporting adjustable
autonomy. Musliner, D., & Pell, B. (Eds.), Agents Adjustable Autonomy,
AAAI 1999 Spring Symposium Series, pp. 116{119.
Stankovic, J., Ramamritham, K., & Cheng, S. (1985). Evaluation exible task scheduling algorithm distributed hard real-time system. IEEE Transactions Computers, 34 (12), 1130{1143.
227

fiScerri, Pynadath & Tambe
Tambe, M. (1997). Towards exible teamwork. Journal Artificial Intelligence Research
(JAIR), 7, 83{124.
Tambe, M., Pynadath, D. V., Chauvat, N., Das, A., & Kaminka, G. A. (2000). Adaptive
agent integration architectures heterogeneous team members. Proceedings
International Conference MultiAgent Systems, pp. 301{308.
Zilberstein, S. (1996). Using anytime algorithms intelligent systems. AI Magazine, 17 (3),
73{83.

228

fiJournal Artificial Intelligence Research 17 (2002) 363378

Submitted 5/02; published 11/02

Competitive Safety Analysis: Robust Decision-Making
Multi-Agent Systems
moshet@ie.technion.ac.il

Moshe Tennenholtz
Faculty Industrial Engineering Management
Technion Israel Institute Technology
Haifa 32000, Israel

Abstract
Much work AI deals selection proper actions given (known unknown) environment. However, way select proper action facing agents
quite unclear. work AI adopts classical game-theoretic equilibrium analysis
predict agent behavior settings. approach however provide us
guarantee agent. paper introduce competitive safety analysis.
approach bridges gap desired normative AI approach, strategy
selected order guarantee desired payoff, equilibrium analysis. show
safety level strategy able guarantee value obtained Nash equilibrium,
several classical computer science settings. Then, discuss concept competitive
safety strategies, illustrate use decentralized load balancing setting, typical
network problems. particular, show many agents, possible
guarantee expected payoff factor 8/9 payoff obtained Nash
equilibrium. discussion competitive safety analysis decentralized load balancing
developed deal many communication links arbitrary speeds. Finally,
discuss extension concepts Bayesian games, illustrate use
basic auctions setup.

1. Introduction
Deriving solution concepts multi-agent encounters major challenge researchers
various disciplines. famous popular solution concept economics
literature Nash equilibrium. Although Nash equilibrium extensions modifications powerful descriptive tools, widely used AI literature
(Rosenschein & Zlotkin, 1994; Kraus, 1997; Sandholm & Lesser, 1995), appeal
normative AI perspective somewhat less satisfactory.1 wish equip agent
action guarantees desired outcome, expected utility, without relying
agents rationality.2 paper shows that, surprisingly, desire obtaining
guaranteed expected payoff, payoff order value obtained
1. restrict cases exists equilibrium dominant strategies, done
CS literature (Nisan & Ronen, 1999), corresponding equilibrium appealing
normative perspective. However, cases rarely exist.
2. Maximizing expected payoff facing set possible environment behaviors fundamental AI.
particular, discussed context game trees, context planning incomplete
information, need obtain desired goal regardless initial configuration, well
context reinforcement learning, wish maximize expected payoff actual
model (selected set possible models adversarial way) initially unknown. (Russell & Norvig,
1995).
c
2002
AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiTennenholtz

Nash equilibrium, achievable various classical computer science settings. results
inspired several interesting examples counter-intuitive behaviors obtained following Nash equilibria solution concepts (Roth, 1980; Aumann, 1985). One
interesting challenging examples introduced Aumann (Aumann,
1985). Aumann presented 2-person 2-choice (2 2) game g, safety-level (probabilistic maximin) strategy game Nash equilibrium it, yield
expected payoff Nash equilibrium g. observation may significant positive ramifications agents design perspective. safety-level strategy agent
guarantees expected payoff equals expected payoff Nash equilibrium,
serve desirable robust protocol agent! Given above, interested
whether optimal safety level strategy leads expected payoff similar one
obtained Nash equilibrium simple games represent basic variants classical
computer science problems. show, indeed case 2 2 games capturing
simple variants classical load balancing leader election problems. general
question refers general 2 2 games. show safety-level strategy
(strictly) mixed one, expected payoff identical expected payoff obtained
Nash equilibrium generic non-reducible 2 2 game. also show
longer necessarily case pure safety-level strategy. addition, consider
general 2-person set-theoretic games (which naturally extend 2 2 leader election games)
show set-theoretic game g possesses strictly mixed strategy equilibrium
safety level value player game equals expected payoff obtains
equilibrium. Following this, define concept C-competitive safety strategies.
Roughly speaking, strategy called C-competitive safety strategy, guarantees
expected payoff C1 expected payoff obtained Nash equilibrium.
show extended decentralized load balancing setting 9/8-competitive strategy
exists, number players large. also discuss extensions result
general settings. particular, deal cases arbitrary number communication
lines, arbitrary different speeds communication. show ratio 4/3
obtained allow arbitrary speeds two communication lines connecting source
target. also consider notion k-regular network, k ratio
average communication speed lowest speed communication (in given set
communication lines), show k-competitive safety strategy exists general
k-regular networks. Then, discuss C-competitive strategies context Bayesian
games. particular show existence e-competitive safety strategy classical
first-price auctions setup.
Imagine agent designed deal communication user different
targets. Selecting routes messages multi-agent system non-trivial task.
efficiency agent depends actions selected users (and agents)
try also communicate similar targets. cases, game-theoretic analysis
identify Nash equilibria may emerge setting. However, adopting
strategy prescribed Nash equilibrium may quite dangerous agent.
agents may fail choose strategies prescribed equilibrium, result
outcome agent quite poor. would much better agent could
guaranteed similar payoff (to one obtained Nash equilibrium) without relying
agents behavior. computational settings, (machine other) failures
364

fiCompetitive Safety Analysis

possible, rationality assumptions participants behavior minimized,
safety-level strategy special appeal, especially yields value close
expected payoff obtained Nash equilibrium.
Previous work concerned comparing payoffs obtained
optimal centralized (and Pareto-efficient) controller expected payoffs obtained
Nash-equilibria corresponding game (Koutsoupias & Papadimitriou, 1999).3
work spirit competitive analysis, central topic theoretical computer
science (Borodin & El-Yaniv, 1998). work considered suggesting complementary approach, comparing safety-level value agents expected payoff Nash
equilibrium.
rest paper organized follows. Section 2 provide basic
definitions notations. sections 3 4 deal simple variants load
balancing leader election problems. use examples showing
safety-level strategies quite competitive attractive, leading value
Nash equilibrium. generalized section 5 context general 2 2 games.
discussion another extension dealing set-theoretic games discussed section 6.
section 7 deal several settings decentralized load balancing, increasing level
complexity. particular show existence desired competitive safety strategies
settings many agents many possible routes. Section 8 illustrates use
competitive safety analysis games incomplete information.

2. Basic Definitions Notations
game tuple G = hN = {1, . . . , n}, {Si }ni=1 , {Ui }ni=1 i, N set n players,
Si finite set pure strategies available player i, Ui : ni=1 Si < payoff
function player i. Given Si , denote set probability distributions
elements Si (Si ). element (Si ) called mixed strategy player i.
called pure strategy assigns probability 1 element Si , called
strictly mixed strategy assigns positive probability element Si . tuple
= (t1 , . . . , tn ) ni=1 (Si ) called strategy profile. denote Ui (t) expected
payoff player given strategy profile t. strategy profile = (t1 , . . . , tn ) Nash
equilibrium N , Ui (t) Ui (t1 , t2 , . . . , ti1 , t0i , ti+1 , . . . , tn ) every t0i Si . Nash
equilibrium = (t1 , . . . , tn ) called pure strategy Nash equilibrium ti pure strategy
every N . Nash equilibrium = (t1 , . . . , tn ) called strictly mixed strategy
Nash equilibrium every N ti strictly mixed strategy. Given
game g mixed strategy player i, (Si ), safety level value obtained
choosing game g, denoted val(t, i, g), minimal expected payoff player
may obtain employing arbitrary strategy profiles players.
strategy t0 player val(., i, g) maximal called safely-level strategy (or
probabilistic maximin strategy) player i. Hence, safety-level strategy agent i,
ssaf e (Si ) satisfies
ssaf e argmaxs(Si ) min(s1 ,s2 ,...,si1 ,si+1 ,...,sn )j6=i Sj Ui (s1 , s2 , . . . , si1 , s, si+1 , . . . , sn )
3. work extended e.g. (Roughgarden, 2001; Roughgarden & Tardos, 2002).

365

fiTennenholtz

strategy e Si dominates strategy f Si every (s1 , s2 , . . . , si1 , si+1 , . . . , sn )
j6=i (Sj ) Ui (s1 , . . . , sj1 , e, sj+1 , . . . , sn )
Ui (s1 , . . . , sj1 , f, sj+1 , . . . , sn ), strict inequality least one tuple.
game called non-reducible exist e, f Si , N ,
e dominates f . game called generic every N , pair strategies e, f Si ,
(s1 , s2 , . . . , si1 , si+1 , . . . , sn ) j6=i Sj , Ui (s1 , . . . , si1 , e, si+1 , . . . , sn ) =
Ui (s1 , . . . , si1 , f, si+1 , . . . , sn ) e f coincide. generic game different strategies player i, assuming fixed strategy profile rest players, lead
different payoffs. property simply says fixed environment (captured
strategy profile rest players), different strategies player lead
somewhat different payoffs (e.g. result costs, outcomes, etc.) game called
2 2 game n = 2 |S1 | = |S2 | = 2.

3. Decentralized Load Balancing
section consider decentralized load balancing, two rational players need
submit messages simple communication network: network two parallel communication lines e1 , e2 connecting nodes t. player message needs
deliver t, needs decide route taken. communication line
e1 faster one, therefore value transmitting single message along e1 X > 0
value transmitting single message along e2 X 0.5 < < 1.4
player needs decide communication line used sending message
t. players choose communication line value one
drops factor two (a player obtain X2 players choose e1 , player
obtain X
2 players choose e2 ). matrix form, game presented
follows:

!
X/2, X/2
X, X
M=
X, X
X/2, X/2
Proposition 1 optimal safety-level value player decentralized load balancing game equals expected payoff strictly mixed strategy equilibrium game.
Proof: Consider following equations probability choose e1 symmetric
equilibrium, player selects e1 probability p e2 probability 1 p.
equation derived fact Nash equilibrium every strategy
support lead identical expected payoffs. Notice solving equation
also prove existence strictly mixed strategy Nash equilibrium.
p

X
X
+ (1 p)X = pX + (1 p)
2
2

Hence, p X2 + X pX = pX + X2 p X2 , X X2 = p X2 + p X2 . implies
p=

2
1+

4. Notice later paper, X constant. important factor ratio
payoffs.

366

fiCompetitive Safety Analysis

Notice 0 < p < 1 required. safety level mixed strategy satisfies following
equation. equation derived fact expected payoff (mixed)
safety-level strategy identical strategy player.
p

X
X
+ (1 p)X = pX + (1 p)
2
2

Hence, p X2 +X pX = pX + X2 p X2 . implies pX p X2 +pX p X2 =
) = X
therefore p( X+X
2
2 . get:
p=

X
2 ,


1+

Notice Nash equilibrium different safety level strategy. However,
consider expected payoff obtained Nash equilibrium safety level
strategy: Nash value is:
2X
2 1
+
X
1+ 2
1+
safety level value is:
1
X
+
X
1+ 2
1+
show values coincide. enough show that:
2 1

2
+
= 1.5
2(1 + )
1+
1+

however trivially holds since sides equal 1.5 1+
2
Notice proposition shows agent guarantee expected
payoff equals payoff Nash equilibrium decentralized load balancing
game. obtained using strategy differs agents strategies Nash
equilibria game (which provide guarantee). Notice players
could used mediator/correlation devise, play game repeatedly,
mediator could directed use strategies leading payoff higher
one guaranteed safety-level strategy. use mediator/correlation
devise, well discussion repeated games, beyond scope paper.

4. Leader Election: Decentralized Voting
leader election setting, players vote identity player take
lead particular task. failure obtain agreement leader bad
output, modelled leading 0 payoff. Assume players strategies
either vote 1 vote 2, denoted a1 , a2 respectively, Ui (aj , ak ) > 0,
i, j, k {1, 2}, j = k. Notice setting captures various forms leader
election, e.g. player prefers selected, prefers player
selected, etc. matrix form, game presented follows (where a, b, c, > 0):


M=

a, b
0, 0
367

0, 0
c,

!

fiTennenholtz

Proposition 2 optimal safety-level value player leader election game equals
expected payoff strictly mixed strategy equilibrium game.
Proof: strictly mixed Nash equilibrium probability q choosing a1
player 2 satisfy:
qU1 (a1 , a1 ) = (1 q)U1 (a2 , a2 )
equality implied fact pure strategy support
mixed strategy agent, Nash equilibrium, yield expected payoff
(otherwise, deviation rational.) Hence, equality captures fact
strategy player 2 equilibrium selected way utility agent 1
using either a1 a2 same.
Similarly, probability p choosing a1 player 1 satisfy
pU2 (a1 , a1 ) = (1 p)U2 (a2 , a2 )
Hence, strictly mixed strategy Nash equilibrium exists, q =

U1 (a2 ,a2 )
U1 (a1 ,a1 )+U1 (a2 ,a2 )



U2 (a2 ,a2 )
U2 (a1 ,a1 )+U2 (a2 ,a2 )

seen equations strictly mixed strategy
p=
equilibrium exists. Consider w.l.o.g player 1. expected payoff obtains
)U1 (a2 ,a2 )
equilibrium qU1 (a1 , a1 ) = UU11(a(a11,a,a11)+U
Player 1s safety level strategy satisfies
1 (a2 ,a2 )
0
following, p probability choosing a1 :
p0 U1 (a1 , a1 ) = (1 p0 )U1 (a2 , a2 )
Hence, p0 =

U1 (a2 ,a2 )
U1 (a1 ,a1 )+U1 (a2 ,a2 ) Notice
)U1 (a2 ,a2 )
.
p0 U1 (a1 , a1 ) = UU11(a(a11,a,a11)+U
1 (a2 ,a2 )

p0 = q. safety level value there-

get Nash equilibrium safety level
fore:
strategies different, expected payoffs players coincide.
2
Notice proposition shows agent guarantee expected
payoff equals payoff Nash equilibrium leader election game.5
decentralized load balancing game, obtained using strategy differs
agents strategies Nash equilibria game (which provide guarantee).

5. Safety Level General 2 2 Games
results presented previous sections refer 2-person 2-choice variants central problems occurring computational contexts. Given encouraging results
framework basic settings, wish consider two types extensions:
1. Generalize results broader family simple games.
2. Generalize results general CS-related settings, dealing particular
games many players, found load-balancing settings.
5. reader confuse fact p0 = q similarity safety-level Nash equilibrium. Indeed, p0 refers probability choosing a1 player 1, q refers probability
choosing action player 2.

368

fiCompetitive Safety Analysis

section deal first point. Later, particular section 7,
deal second one. interest see whether results sections 3-4
extended forms 2 2 games. Notice load balancing leader
election settings represented non-reducible generic 2 2 games. true
regard game presented Aumann:


M=

2, 6
6, 0

4, 2
0, 4

!

Non-reducible generic games attractive concept. dominated strategies
game add understanding interaction, since strategies safely
ignored. fact game generic also quite appealing: quite natural assume
pair actions lead different outcomes fix rest environment.
show:
Theorem 1 Let G 2 2 non-reducible generic game. Assume optimal safety
level value player obtained strictly mixed strategy, value coincides
expected payoff player Nash equilibrium G.
Proof: Denote strategies available players a1 , a2 . Use following notation: = U1 (a1 , a1 ), b = U1 (a1 , a2 ), c = U1 (a2 , a1 ), = U1 (a2 , a2 ), e = U2 (a1 , a1 ), f =
U2 (a1 , a2 ), g = U2 (a2 , a1 ), h = U2 (a2 , a2 )
matrix form, presented as:


M=

a, e
c, g

b, f
d, h

!

strictly mixed strategy Nash equilibrium exists satisfy that:
qa + (1 q)b = qc + (1 q)d

pe + (1 p)g = pf + (1 p)h
p q probabilities choosing a1 players 1 2, respectively. get
qa + b qb = qc + qd, implies q(a b c + d) = b.
Similarly, get pe + g pg = pf + h ph, implies
p(e g f + h) = h g. Hence, strictly mixed strategy Nash equilibrium
have:
db
q=
abc+d

hg
p=
egf +h
Notice since game generic 6= b. > b q strictly
0 1 c > contradict non-reducibility. < b q strictly
0 1 > c, also contradicts non-reducibility. Similarly, since
game generic h 6= g. h > g p strictly 0 1 f > e
369

fiTennenholtz

contradict non-reducibility. h < g p strictly 0
1 e < f , also contradicts non-reducibility. Given get p q
define strictly mixed strategy equilibrium G. Consider safety level strategy
player 1. player 1 chooses a1 probability p0 satisfies that:
p0 + (1 p0 )c = p0 b + (1 p0 )d
implies need p0 a+cp0 c = p0 b+dp0 d, implies p0 (acb+d) =
c. Hence,
dc
p0 =
acb+d

ab
1 p0 =
acb+d
Compute expected payoff player 1 strictly mixed Nash equilibrium, given
ac
, that:
1 q = abc+d
qa + (1 q)b =

da cb
(d b)a + (a c)b
=
abc+d
abc+d

expected payoff safety level strategy player 1 be:
p0 + (1 p0 )c =

(d c)a + (a b)c
da cb
=
abc+d
abc+d

Hence, get expected payoffs Nash equilibrium safety level strategies player 1 coincide. computation player 2 similar.
2
5.1 Case Pure Safety-Level Strategies
reader may wonder whether previous result also proved case
restrictions structure safety-level strategy game g. several
AI contexts, discussion pure maximin strategies, probabilistic behavior
considered. course, probabilistic maximin strategies powerful, many
cases best safety level obtained mixed strategy pure one.
However, interest consider case safety-level strategy pure
one. show, exists generic non-reducible 2 2 game g, optimal
safety level strategy player pure, expected payoff player lower
expected payoff player Nash equilibria g. Consider game g,
U1 (1, 1) = 100, U1 (1, 2) = 40, U1 (2, 1) = 60, U1 (2, 2) = 50, U2 (1, 1) = 100, U2 (1, 2) =
210, U2 (2, 1) = 200, U2 (2, 2) = 90. matrix form game looks follows:


M=

100, 100
60, 200

40, 210
50, 90

!

easy check g generic non-reducible. particular, dominated
strategies, payoffs obtained player different strategy profiles different
one another. game pure Nash equilibria. strictly mixed strategy
370

fiCompetitive Safety Analysis

equilibrium probability q choosing a1 player 2 satisfy 100q + 40(1 q) =
60q+50(1q), i.e. 60q+40 = 10q+50, q = 0.2. equilibrium probability
player 1 choose a1 p = 0.5, expected payoff player 1 100q+40(1q) = 52.
safety-level strategy player 1 perform a2 , guaranteeing payoff 50, given
(a2 , a2 ) saddle point zero-sum game payoffs player 2 taken
complement 0 player 1s original payoffs. Hence, value safety level
strategy player 1 50 < 52.
2

6. Beyond 2 2 Games
leader election game instance general set games: set-theoretic games.
set theoretic game sets strategies available players identical,
payoff player uniquely determined set strategies selected player.
example, 2-person set-theoretic game U1 (s, t) = U1 (t, s), U2 (s, t) =
U2 (t, s) every s, S1 = S2 . Notice set-theoretic games typical voting
contexts. typical voting context care votes, indentity
voters. prove following:
Proposition 3 Given 2-person set theoretic game g strictly mixed strategy Nash
equilibrium, value optimal safety level strategy player equals expected
payoff equilibrium.
Proof: Let = S1 = S2 = {s1 , s2 , . . . , sl }. Let = (t1 , t2 ) strictly mixed strategy
Nash equilibrium. Denote tuple probabilities associated ti (pi1 , . . . , pil ) (i
{1, 2}, |S1 | = |S2 | = l). strictly mixed Nash equilibrium expected
payoff player 1 is:
lj=1 p2j U1 (se , sj ) ()
every 1 e l. Consider strategy f player 1 assigns probability p2j
strategy sj . Then, every strategy se selected player 2, expected payoff f
given
lj=1 p2j U1 (sj , se ) = lj=1 p2j U1 (se , sj ) = ()
implies safety level strategy player 1 yields expected payoff
identical expected payoff player 1 equilibrium. Similar reasoning
applied player 2.
2

7. Competitive Safety Strategies
Let set strategies. Consider family games (g1 , g2 , . . . , gj , . . .)
player them, set strategies games S, j
players, addition i, gj . example, consider family decentralized load
balancing settings. (n 1)-th game extended load-balancing setting consist
n players, one i. players submit messages along e1 e2 .
payoff player participating n-person decentralized load balancing game
X
X
k (resp. k ) chosen e1 (resp. e2 ) additional k 1 participants chosen
371

fiTennenholtz

communication line. mixed strategy (S) called C-competitive safety
strategy exists constant C > 0,
nash(i, gj )
C
j val(t, i, gj )
lim

nash(i, gj ) lowest expected payoff player might obtain equilibrium
gj , val(t, i, gj ) expected payoff guaranteed choosing game gj .
extended decentralized load balancing setting 6 typical basic network problem.
C small, C-competitive safety strategy context provide useful protocol
behavior. show:
Theorem 2 exists 9/8-competitive safety strategy extended decentralized
load-balancing setting.
Proof: Consider following strategy profile players n-person decentralized
1
load balancing game: players {1, 2, . . . , 1+
ne} choose e1 , rest choose
e2 . W.l.o.g assume = 1 player make computation
expected payoffs. easy verify strategy profile equilibrium
game, expected payoff player bounded
X(1 + )
()
n
Intuitively, equilibrium obtained partitioning players way payoff
using communication lines (almost) equal. Consider following strategy

1
player i: select e1 probability 1+
select e2 probability 1+
. Notice
(if adopted participants) Nash equilibrium. However, show
competitive safety strategy small C > 0 . Consider arbitrary number
participants n, (n 1) (i.e. excluding player i) n 1 participants use
e2 rest use e1 , arbitrary 0 1. expected payoff obtained using
be:
1
X

X
+
1 + (n 1) + 1 1 + (1 )(n 1) + 1
value greater equal to:
1
X

X
+
1 + n + 1 1 + (1 )n + 1
equals



1
1
X
+
1 + n + 1 (1 )n + 1



Simplifying get:
X
n+2
( )
1 + (1 + n)(n n + 1)
6. later term extended load-balancing setting refers family games above.

372

fiCompetitive Safety Analysis

Dividing (**) (***) get ratio is:
(1 + )2 ( 2 )n2 + n + 1

n(n + 2)
n approaches infinity ratio approaches
(1 + )2
( 2 )

Given 0.5 < 1 0 1 get ratio bounded 9/8
desired.
2
7.1 Extensions: Arbitrary Speeds Links
section generalize result obtained context decentralized load balancing case parallel communication lines leading source target.
value obtained agent (w.l.o.g. agent 1) submitting message along line

i, ni agents decided submit messages line given X
ni ,
1 = 1 2 > 0. extension enables us handle general binary
case 0 < < 1, well discuss cases safety level strategy
effective general m-lines situation. Using ideas developed case = 2,
show:




j6=i j
Theorem 3 exists i=1mi2 i=1
competitive safety strategy extended

i=1 j
decentralized load-balancing setting, allow (rather 2) parallel communication lines, arbitrary s.

Proof: Following ideas previous theorem, exists equilibrium agent
1 obtains (X/n)m
i=1 . Intuitively, equilibrium players distributed
way payoff using different communication lines (almost) identical.
particular, agents {1, 2, . . . , m1 ne}, 1 = 1 assigned communication
i=1
line 1, hence agent 1s payoff prescribed.
Consider following strategy agents: choose communication line
probability
j6=i j

i=1 j6=i j
Given above, expected payoff agent minimized (using similar ideas
ones proof Theorem 2), splitting agents equally among
communication lines. Hence, expected payoff agent least:

i=1

Xj6=i j
m2 X
j=1 j
=
n


(1 + )i=1 j6=i j
+ n i=1 j6=i j

Hence, ratio expected payoff Nash equilibrium expected
payoff guaranteed bounded by:

m+n
i=1 j6=i j
(

)
i=1
2
n

j=1 j
373

fiTennenholtz

implies, n large existence



i=1 i=1 j6=i j
competitive
m2
j=1 j

strategy.
2
general binary case, 1 = 1, 2 = , 0 < 1,
implies existence
(1 + )2
4
competitive strategy.
Corollary 1 Given extended load balancing setting, = 2, arbitrary speeds
communication lines (0 < 1), exists 43 -competitive strategy.
2

2

Proof: see notice 1 + < (1+)
< 1/3 (1+)
4
4
decreasing interval (0, 1]. Hence, considering strategy prescribed
theorem 1/3 selecting e1 otherwise, guaranteed ratio
1 + 1/3 = 4/3.
2
Consider general m-links (i.e. parallel communication lines) case.

average network quality (or speed), Q, defined i=1
. network called
Q
k-regular k. Many networks k-regular small k. example, 0.5
before, network 2-regular regardless number edges.
Corollary 2 Given k-regular network, exists k-competitive safety strategy
extended decentralized load-balancing setting, allow (rather 2) parallel
edges.
Proof: show above, observe


Q
i=1 i=1 j6=i j
i=1 j6=i j
=
m2



j=1 j
j=1 j

latter smaller equal
Q
=k

desired.
2
Together, Theorem 3 corollaries 1 2 extend results decentralized load
balancing general case parallel communication lines.

8. Competitive Safety Analysis Bayesian Games
results presented previous sections refer games complete information.
games studied context refer fundamental settings AI game
theory intersection, deal issues congestion. section, show
ideas applied games incomplete information well.
game incomplete information payoff player given behavior
set players private information player. order illustrate competitive safety
analysis games incomplete information, chosen consider basic
mechanism, first-price auction. selection first-price auction accident.
374

fiCompetitive Safety Analysis

Auctions fundamental theory economic mechanism design7 , among
auctions possess dominant strategy, assuming independent private value
model, first-price auctions probably common ones.
consider setting good g put sale, n potential buyers.
buyer valuation (i.e. maximal willingness pay) g drawn
uniform distribution interval real numbers [0, 1]. valuation private
information agent has. exact valuation known agent,
distribution agent valuations commonly known. valuations assumed
independent one another. first price auction, potential buyer asked
submit bid good g. assume bids buyer valuation v
number interval [0, v].8 good allocated bidder submitted
highest bid (with lottery determine winner case tie). auction setup
defined using Bayesian game.9 game players potential bidders,
payoff player valuation v vp wins good pays p, 0
get good. reader see, distinguished feature games
players utility function depends agents private valuation, therefore known
it. equilibrium concept also extended context Bayesian games.
auction setup agents strategy function valuations monetary bids.
strategy profile equilibrium agents strategy best response
agents strategies given distribution agents valuations. particular,
equilibrium game bid player valuation v (1 n1 )v.
n
Given above, expected payoff agent valuation v, vn . before,
question whether guarantee payoff proportional expected payoff
equilibrium.
discussing appropriate strategy, emphasize formal issue
regard competitive safety strategies Bayesian games. Notice definition
competitive safety strategies, assume players competitive action
independent number players. hand, suggested equilibrium
analysis above, behavior first-price auction may heavily depend number players.
order address issue, make use revelation principle, discussed
economic mechanism design literature. revelation principle tells us one replace
above-mentioned first-price auction following auction: bidder asked
reveal valuation, good sold bidder reported highest
valuation; agent reported valuation v 0 turn winner
asked pay (1 n1 )v 0 . mechanism player submit bids 0
n
n1 v. turns reporting true valuation equilibrium auction,
yield (in equilibrium) allocation, payments, expected utility
participants, original auction. convenient consider revelation
mechanism, since facing number participants, bidders strategy equilibrium
always same.
7. general discussion mechanism design see (Mas-Colell, Whinston, & Green, 1995), Chapter 23,
(Fudenberg & Tirole, 1991), Chapter 7).
8. general, buyers may submit bids higher valuations, strategies dominated strategies, existence effect equilibrium discussed paper.
9. formal definition exposition Bayesian games found (Fudenberg & Tirole, 1991).

375

fiTennenholtz

Given above, first-price auction setup identified family (Bayesian)
games (g1 , g2 , . . .) gj Bayesian game associated (the revelation mechanism
of) first-price auction j +1 potential buyers. definition C-competitive strategies
applied context well.
Theorem 4 exists e-competitive strategy first-price auction setup.
Proof: player 1 valuation v submits bid b auction additional
n 1 players, worst case payoff
Z

n1
b
n

v2 =0

Z

dv2

n1
b
n

v3 =0

dv2

Z

n1
b
n

vn =0

(v

n1
b)dvn
n

says order win, player bid higher players
n
bids. players bid revelation mechanism however n1
times
n1
valuation, therefore integrate valuations n times
player bid. agent winner gain v n1
n b bids b
valuation v (given rules revelation mechanism). maximized


n 1 n 1 n1
(v
b)(
b)
=0
db
n
n
n1 , i.e. b = v.
Hence, expected value maximized (n 1)vbn2 = n1
n nb
therefore get safety-level strategy coincides case equilibrium
strategy. expected payoff equilibrium shown v n /n. expected payoff
guaranteed strategy

(

n 1 n1 1
v)
v
n
n

ratio safety level value equilibrium value therefore bounded
n
1
( n1
n ) , greater equal e , approaches number
players approaches infinity.
2
interesting observation theorem, safety-level strategy
identical equilibrium strategy. connection occurs although game
0-sum game. interesting observe since consider revelation mechanisms
safety-level strategy turns independent number participants.
result also obtained consider standard first-price auctions, rather
revelation mechanisms associated them; nevertheless, require us allow
player choose action knowing number potential bidders (as corresponding
equilibrium analysis).

9. Discussion
previous work AI attempted show potential power decision-theoretic
approaches rely classical game-theoretic analysis. particular, work theoretical computer science competitive analysis extended deal rationality
constraints (Tennenholtz, 2001), order become applicable multi-agent systems.
376

fiCompetitive Safety Analysis

introduced competitive safety analysis, bridging gap normative AI/CS approach classical equilibrium analysis. shown observation, due
Aumann, safety-level strategies may yield value Nash equilibrium games
zero-sum, provides powerful normative tool computer scientists AI
researchers interested protocols non-cooperative environments. illustrated
use power competitive safety analysis various contexts. shown general
results 2 2 games, well games many participants, introduced
use competitive safety analysis context decentralized load balancing, leader
election, auctions. Notice work concerned normative approach
decision making multi-agent systems. make claims applicability
approach descriptive purposes, i.e. prediction people behave
corresponding situations. Although exists much literature failure Nash equilibrium, still powerful concept action prediction multi-agent systems.
setting decentralized load balancing discussed part paper central game
theory applications.10 Given importance setting CS perspective,
providing robust agent protocols setting major challenge work multiagent systems. order however build robust protocols, relying standard equilibrium
analysis might satisfactory, safety guarantees required. work suggests
protocols analysis providing guarantees, bridging gap classical
AI/decision-theoretic reasoning equilibrium analysis game theory.

Acknowledgements
work carried author sabbatical leave computer
science department Stanford university. preliminary version paper appears
proceedings AAAI-2002.

References
Aumann, R. (1985). non-transferable utility value: comment Roth-Shaper
examples. Econometrica, 53 (3), 667677.
Borodin, A., & El-Yaniv, R. (1998). On-Line Computation Competitive Analysis. Cambridge
University Press.
Fudenberg, D., & Tirole, J. (1991). Game Theory. MIT Press.
Koutsoupias, E., & Papadimitriou, C. (1999). Worst-Case Equilibria. STACS.
Kraus, S. (1997). Negotiation cooperation multi-agent environments. Artificial Intelligence,
94, 7997.
Mas-Colell, A., Whinston, M., & Green, J. (1995). Microeconomic Theory. Oxford University Press.
Monderer, D., & L.S.Shapley (1996). Potential games. Games Economic Behavior, 14, 124143.
Nisan, N., & Ronen, A. (1999). Algorithmic mechanism design. Proceedings STOC-99.
10. See literature potential congestion games, e.g. (Monderer & L.S.Shapley, 1996; Rosenthal,
1973).

377

fiTennenholtz

Rosenschein, J. S., & Zlotkin, G. (1994). Rules Encounter. MIT Press.
Rosenthal, R. (1973). class games possessing pure-strategy nash equilibria. International
Journal Game Theory, 2, 6567.
Roth, A. E. (1980). Values games without side payments: difficulties current concepts.
Econometrica, 48 (2), 457465.
Roughgarden, T. (2001). price anarchy independent network topology. Proceedings
34th Annual ACM Symposium Theory Computing, pp. 428437.
Roughgarden, T., & Tardos, E. (2002). bad selfish routing?. Journal ACM, 49 (2),
236259.
Russell, S., & Norvig, P. (1995). Artificial Intelligence: Modern Approach. Prentice Hall.
Sandholm, T. W., & Lesser, V. (1995). Equilibrium Analysis Possibilities Unenforced
Exchange Multiagent Syustems. Proc. 14th International Joint Conference Artificial
Intelligence, pp. 694701.
Tennenholtz, M. (2001). Rational Competitive Analysis. Proc. 17th International Joint
Conference Artificial Intelligence, pp. 10671072.

378

fiJournal Artificial Intelligence Research 17 (2002) 265287

Submitted 10/01; published 9/02

Numbers Really Matter?
Hei Chan
Adnan Darwiche

hei@cs.ucla.edu
darwiche@cs.ucla.edu

Computer Science Department
University California, Los Angeles
Los Angeles, CA 90095, USA

Abstract
Common wisdom small distinctions probabilities (parameters) quantifying belief network matter much results probabilistic queries. Yet,
one develop realistic scenarios small variations network parameters
lead significant changes computed queries. pending theoretical question
analytically characterize parameter changes matter. paper,
study sensitivity probabilistic queries changes network parameters prove
tight bounds impact parameters queries. analytic
results pinpoint interesting situations parameter changes
matter. results important knowledge engineers help identify
influential network parameters. also help explain previous experimental
results observations regards network robustness parameter changes.

1. Introduction
belief network compact representation probability distribution (Pearl, 1988;
Jensen, 2001). consists two parts, one qualitative quantitative.
qualitative part belief network (called structure) directed acyclic graph
nodes represent domain variables edges represent direct influences
variables. quantitative part belief network set conditional probability tables
(CPTs) quantify beliefs influences. Figure 1 depicts structure
belief network Figure 2 depicts CPTs.1
Automated reasoning systems based belief networks become quite popular recently enjoyed much success number real-world applications. Central
development systems construction belief network (hence, probability distribution) faithfully represents domain interest. Although automatic
synthesis belief networksbased design information certain applications based
learning techniques othershas drawing lot attention recently, mainstream
methods constructing networks continue based traditional knowledge engineering (KE) sessions involving domain experts. One central issues arise
KE sessions assessment impact changes network parameters may
probabilistic queries interest.
Consider example following common method constructing belief networks
medical diagnosis applications (Coupe, Peek, Ottenkamp, & Habbema, 1999). First,
1. specific network CPTs distributed evaluation version commercial HUGIN
system http://www.hugin.com/.
c
2002
AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiChan & Darwiche

Fire

Smoke

Tampering

Alarm

Leaving

Report

Figure 1: belief network structure.

Fire
true
false

x|u
.01
.99

Fire
true
true
false
false

Smoke
true
false
true
false

x|u
.9
.1
.01
.99

Alarm
true
true
false
false

Leaving
true
false
true
false

x|u
.88
.12
.001
.999

Fire
true
true
true
true
false
false
false
false

Tampering
true
false

x|u
.02
.98

Tampering
true
true
false
false
true
true
false
false

Alarm
true
false
true
false
true
false
true
false

x|u
.5
.5
.99
.01
.85
.15
.0001
.9999

Leaving
true
true
false
false

Report
true
false
true
false

x|u
.75
.25
.01
.99

Figure 2: CPTs belief network shown Figure 1.

network structure developed. Next, parameters estimated non-experts using
combination statistical data qualitative influences available textbook materials.
Finally, medical experts brought evaluate network fine-tune parameters.
One method evaluation pose diagnostic scenarios network, compare
results queries expected experts. example, given set
symptoms e, two potential diagnoses z, network may give us conclusion
Pr (y | e)/Pr (z | e) = 2, domain expert may believe ratio
less 4. Assuming network structure correct, central question
then: network parameters changed give us correct ratio,
much?
automate task identifying parameter changes, recently developed belief network tool, called SamIam (Sensitivity Analysis, Modelling, Inference
266

fiWhen Numbers Really Matter?

Figure 3: screen shot SamIam performing sensitivity analysis belief network
shown Figure 1.

More)2 . One feature sensitivity analysis, allows domain experts fine-tune
network parameters order enforce constraints results certain queries. Users
specify constraint want enforce, SamIam automatically decide whether given parameter relevant constraint, is, compute
minimum amount change parameter needed enforce constraint.
technical details approach sensitivity analysis subject Section 2.
experimented SamIam, ran scenarios found surprising
first glance. Specifically, many occasions queries would quite
sensitive small variations certain network parameters. Consider scenario Figure 3
one example, corresponds network detailed Figures 1 2. Here,
evidence e = report, smoke: people reported evacuating building,
evidence smoke. evidence make tampering likely fire,
given belief network indeed reflect Pr (tampering | e) = .50
Pr (fire | e) = .03. wanted, however, probability tampering less .65.
Hence, asked SamIam identify parameter changes enforce constraint,
made two recommendations:
1. either decrease probability false report, Pr (report | leaving), current
value .01 .0047,
2. SamIam developed UCLA Automated Reasoning Group.
http://reasoning.cs.ucla.edu/.

267

web page

fiChan & Darwiche

2. increase prior probability tampering current value .02 .036.
Therefore, distinctions .02 .036, one .01 .0047,
really matter case induces absolute change .15 probabilistic query
interest. Note also implicit SamIams recommendations parameters
variables Fire, Smoke, Leaving, Alarm irrelevant enforcing constraint, i.e.
matter much change parameters, would able enforce
desired constraint.
example shows absolute change query much larger
absolute change corresponding parameters. Later, show example
infinitesimal change network parameter leads change .5 corresponding
query. also show examples relative change probability query
larger corresponding relative change network parameter. One wonders
whether different method measuring probabilistic change (other absolute
relative), allows one non-trivially bound change probabilistic query
terms corresponding change network parameter.
answer related questions, conduct Section 3 analytic study
partial derivative probabilistic query Pr (y | e) respect network parameter
x|u . study leads us three main results:
1. bound derivative terms Pr (y | e) Pr (x | u) only, independent aspect given belief network;
2. bound sensitivity queries infinitesimal changes network parameters;
3. bound sensitivity queries arbitrary changes network parameters.
last bound particular shows amount change probabilistic query
bounded terms amount change network parameter, long change
understood relative change odds. result number practical implications. First, relieve experts precise specifying certain
parameters subjectively. Next, important approximate inference algorithms
pre-process network parameters eliminate small distinctions parameters,
order increase efficiency inference (Poole, 1998). Finally, used show
automated reasoning systems based belief networks robust and, hence, suitable
real-world applications (Pradhan, Henrion, Provan, Del Favero, & Huang, 1996).
Section 4 indeed dedicated exploring implications bounds,
provide analytic explanation certain parameter changes dont matter.
finally close Section 5 concluding remarks. Proofs theorems given
Appendix A.

2. Tuning Network Parameters
report section tool developing, called SamIam, finetuning network parameters (Laskey, 1995; Castillo, Gutierrez, & Hadi, 1997; Jensen, 1999;
Kjrulff & van der Gaag, 2000; Darwiche, 2000). Given belief network, evidence
e, instantiation variables E belief network, two events z
variables Z respectively, Y, Z 6 E, tool efficiently identify parameter
changes needed enforce following types constraints:
268

fiWhen Numbers Really Matter?

Difference: Pr (y | e) Pr (z | e) ;
Ratio: Pr (y | e)/Pr (z | e) .
two constraints often arise debug belief networks. example,
make event likely event z, given evidence e, specifying constraint,
Pr (y | e) Pr (z | e) 0, make event least twice likely event z, given
evidence e, specifying constraint, Pr (y | e)/Pr (z | e) 2. discuss next
one would enforce two constraints, need settle notational conventions
technical preliminaries first.
Variables denoted upper-case letters (A) values lower-case letters (a).
Sets variables denoted bold-face upper-case letters (A) instantiations
denoted bold-face lower-case letters (a). variable values true false,
use denote = true denote = false. CPT variable X
parents U defines set conditional probabilities form Pr (x | u), x value
variable X, u instantiation parents U, Pr (x | u) probability known
network parameter denoted x|u . finally recall basic fact belief networks.
probability instantiation x network variables X equals product
network parameters consistent instantiation. example,
probability instantiation fire, tampering, smoke, alarm, leaving, report Figure 1 equals
.01 .98 .9 .99 .12 .01, product network parameters (from Figure 2)
consistent instantiation.
2.1 Binary Variables
first consider parameters binary variable X, two values x x and,
hence, two parameters x|u x|u parent instantiation u. assume
variable X parent instantiation u meta parameter x|u ,
x|u = x|u x|u = 1 x|u . Therefore, goal determine amount
change meta parameter x|u would lead simultaneous change x|u
x|u . use meta parameter x|u meaningful change x|u
x|u without changing since x|u + x|u = 1.
First observe probability instantiation e, Pr (e), linear function
network parameter x|u belief network (Russell, Binder, Koller, & Kanazawa,
1995; Castillo et al., 1997). fact, probability linear meta parameter x|u .
Theorem 2.1 derivative Pr (e) respect meta parameter x|u given by:
Pr (e)
Pr (e, x, u) Pr (e, x, u)
=

,
x|u
x|u
x|u

(1)

x|u 6= 0 x|u 6= 0.3 designate derivative constant e .
Theorem 2.1, e = Pr (e, x, u)/x|u Pr (e, x, u)/x|u constant terms
x|u x|u (and consequently, x|u ) since Pr (e, x, u) = Kx x|u Pr (e, x, u) = Kx x|u ,
3. either previous parameters zero, use differential approach Darwiche (2000)
compute derivative directly.

269

fiChan & Darwiche

Kx = Pr (u)Pr (e | x, u) Kx = Pr (u)Pr (e | x, u) constants terms
x|u x|u . substituting y, e z, e e Theorem 2.1, get:
y,e =

Pr (y, e)
x|u

=

Pr (y, e, x, u) Pr (y, e, x, u)

;
x|u
x|u

(2)

z,e =

Pr (z, e)
x|u

=

Pr (z, e, x, u) Pr (z, e, x, u)

.
x|u
x|u

(3)

Now, want enforce Difference constraint, Pr (y | e) Pr (z | e) ,
suffices ensure Pr (y, e) Pr (z, e) Pr (e). Suppose previous constraint
hold, wish establish applying change meta parameter
x|u . change leads change e Pr (e). also changes Pr (y, e) Pr (z, e)
y,e z,e , respectively. Hence, enforce Difference constraint, need
solve following inequality:
[Pr (y, e) + y,e ] [Pr (z, e) + z,e ] [Pr (e) + e ].
Rearranging terms, get following result.
Corollary 2.1 satisfy Difference constraint, need change meta parameter x|u , that:
Pr (y, e) Pr (z, e) Pr (e) [y,e + z,e + e ],
constants defined Equations 1, 2 3.
similarly solve parameter changes enforce Ratio constraint,
Pr (y | e)/Pr (z | e) , following inequality:
[Pr (y, e) + y,e ]/[Pr (z, e) + z,e ] .
Rearranging terms, get following result.
Corollary 2.2 satisfy Ratio constraint, need change meta parameter x|u
, that:
Pr (y, e) Pr (z, e) [y,e + z,e ],
constants defined Equations 2 3.
Difference Ratio constraints, solution , any, always
one two forms:
q, computed q < 0, case new value meta parameter x|u
must interval [0, p + q].
q, computed q > 0, case new value meta parameter x|u
must interval [p + q, 1].
270

fiWhen Numbers Really Matter?

Note p current value meta parameter x|u (before change). many
parameters, intervals empty and, therefore, way change
meta parameters enforce constraint.
question solve inequalities, efficiently, meta parameters. Note may one possible parameter change would enforce
given constraint, need identify changes. either Corollary 2.1
2.2, easily solve amount change needed, , know following
probabilities: Pr (e), Pr (y, e), Pr (z, e), Pr (e, x, u), Pr (e, x, u), Pr (y, e, x, u), Pr (y, e, x, u),
Pr (z, e, x, u), Pr (z, e, x, u). leads following complexity technique.
Corollary 2.3 algorithm compute Pr (i, x, u), given instantiation i, family instantiations x, u every variable X, time O(f ),
solve Corollaries 2.1 2.2 parameters time O(f ). running
algorithm three times, = e, = y, e, finally = z, e.
Recall family variable X set containing X, parents U
belief network.
join-tree algorithm (Jensen, Lauritzen, & Olesen, 1990) differential approach (Darwiche, 2000) compute Pr (i, x, u), given instantiation
family instantiations x, u every variable X O(n exp w) time. Here, n number
variables belief network, w width given elimination order. SamIam
uses differential approach, thus running time identify possible parameter
changes network also O(n exp w). Note also time needed answer
one simplest queries, computing probability evidence e.
2.2 Multi-Valued Variables
results easily extended multi-valued variables, long assume model
changing co-varying parameters one changes (Darwiche, 2000; Kjrulff &
van der Gaag, 2000). parameter x|u changes, need use scheme change
parameters, xi |u xi 6= x, order ensure sum-to-one constraint.
common way use proportional scheme. scheme,
change parameters ratios remain same.
example, suppose three parameters x1 |u = .6, x2 |u = .3 x3 |u = .1.
x1 |u changes .8, two parameter values changed x2 |u = .3(.2/.4) = .15
x3 |u = .1(.2/.4) = .05 accordingly. define meta parameter x|u
simultaneously changes parameters according proportional scheme.
obtain linear relation Pr (e) x|u , partial derivative given by:
Pr (e)
Pr (e, x, u)
=

x|u
x|u

P

xi 6=x Pr (e, xi , u)

P

xi 6=x xi |u

.

similar result Theorem 2.1, way grouped
values xi 6= x value x. use Corollaries 2.1 2.2 solve
Difference Ratio constraints.
present another example illustrate results used practice.

271

fiChan & Darwiche

Example 2.1 Consider network Figure 3. Here, set evidence
smoke, report people evacuating building, i.e. e = smoke, report.
got posteriors Pr (fire | e) = .25 Pr (tampering | e) = .02. thought
case posterior fire less .5 asked SamIam recommend
necessary changes enforce constraint, Pr(fire | e) Pr (fire | e) 0.
five recommendations case, three could ruled based qualitative
considerations:
1. increase prior fire .03 (from .01);
2. increase prior tampering .80 (from .02);
3. decrease Pr (smoke | fire) .003 (from .01);
4. increase Pr (leaving | alarm) .923 (from .001);
5. increase Pr (report | leaving) .776 (from .01).
Clearly, sensible change either increase prior fire, decrease
probability smoke without fire.
example similar ones suggest identifying parameter changes
magnitudes inevitable developing faithful belief network, yet trivial
experts accomplish task visual inspection belief network, often due
size complexity. Sensitivity analysis tools SamIam help facilitate
identifying important parameters need fine-tuned order satisfy certain
constraints. course, given multiple constraints, need cautious
implementing recommendation made SamIam due one constraint, may
result violating constraints. case, parameter changes recommended
SamIam used help experts focusing attention relevant
parameters.
Moreover, previous examples illustrate need develop analytic tools
understand explain sensitivity queries certain parameter changes.
also need reconcile sensitivities exhibited examples previous experimental studies demonstrating robustness probabilistic queries small parameter
changes certain application areas, diagnosis (Pradhan et al., 1996). address
particular questions next two sections.

3. Sensitivity Probabilistic Queries Parameters Changes
starting point understanding sensitivity query Pr (y | e) changes
meta parameter x|u analyze derivative Pr (y | e)/x|u . analysis,
assume X binary, variables network multi-valued.
following theorem provides simple bound derivative, terms Pr (y | e)
Pr (x | u) only. use simple bound study effect changes meta
parameters probabilistic queries.

272

fiWhen Numbers Really Matter?

6
pd bound 4
0.8

2
0

0.6
0.4

0.2
0.4
Pr(x| u)

Pr(y|e)

0.2

0.6
0.8

Figure 4: plot upper bound partial derivative Pr (y | e)/x|u , given
Theorem 3.1, Pr (x | u) Pr (y | e).

Theorem 3.1 X binary variable belief network, then:4


Pr (y | e)
Pr (y | e)(1 Pr (y | e))


.


x|u
Pr (x | u)(1 Pr (x | u))

bound Theorem 3.1 tight, show later example
derivative assumes bound exactly. main point note bound
independent given belief network.5
plot bound Pr (x | u) Pr (y | e) shown Figure 4. number
observations order plot:
extreme values Pr (x | u), bound approaches infinity, thus small
absolute change meta parameter x|u big impact query
Pr (y | e).
hand, bound approaches 0 extreme values query Pr (y | e).
Therefore, small absolute change meta parameter x|u small effect
absolute change query.
One implications result belief network queries
interest Pr (y | e) extreme values, queries robust small
changes network parameters. course assumes robustness understood
4. theorem results follow requires x|u 6= 0 x|u 6= 1, since use
expression Equation 2.1 conditions.
5. Note exact closed form derivative Pr (y | e)/x|u (Darwiche, 2000; Greiner,
Grove, & Schuurmans, 1997), form includes terms specific given belief network.

273

fiChan & Darwiche

X



E

Figure 5: network used Example 3.1.

small change absolute value given query. Interestingly enough,
disease diagnosed finding ethat is, probability Pr (y | e) quite high
surprising queries would robust small perturbations
network parameters. seems explain results Pradhan et al. (1996),
robustness confirmed queries Pr (y | e) .9.
Another implication result one careful changing
parameters extreme. parameters potentially influential one
must handle care.
Therefore, worst situation robustness viewpoint materializes one extreme parameters non-extreme queries. case, queries sensitive
small variations parameters.
Example 3.1 Consider network structure Figure 5. two binary nodes, X
respective parameters x , x , . assume E deterministic
binary node value E e iff X = . dictates following CPT E:
Pr (e | x, y) = 1, Pr (e | x, y) = 1, Pr (e | x, y) = 0 Pr (e | x, y) = 0. conditional
probability Pr (y | e) expressed using root parameters x as:
Pr (y | e) =

x
.
x + x

Since x /x = 1 x /x = 1, derivative Pr (y | e) respect meta
parameter x given by:
Pr (y | e)
x

=
=

(x + x )y x (y )
(x + x )2

.
(x + x )2

equal upper bound given Theorem 3.1:
Pr (y | e)(1 Pr (y | e))
Pr (x)(1 Pr (x))

=
=

(x )(x )
x x (x + x )2

.
(x + x )2

Now, set x = , derivative becomes:
Pr (y | e)
1
=
,
x
4x x
274

fiWhen Numbers Really Matter?

x (or x ) approaches 0, derivative approaches infinity. Finally, set x =
= , Pr (y | e) = .5, keep constant change x
0, get new result Pr (y | e) = 0.
Example 3.1 illustrates three points. First, shows bound Theorem 3.1
tight, i.e. construct belief network assumes bound. Second, gives
example network derivative Pr (y | e)/x|u tends infinity, therefore
cannot bound derivative constant. Finally, shows infinitesimal absolute
change meta parameter (changing x 0) induce non-infinitesimal absolute
change query (Pr (y | e) changes .5 0). following theorem, however,
shows possible consider relative notion change.
Theorem 3.2 Assume x|u .5 without loss generality.6 Suppose x|u
infinitesimal change applied meta parameter x|u , leading change Pr (y | e)
query Pr (y | e). have:





Pr (y | e)
x|u




.
Pr (y | e) 2
x|u

function f (x), quantity:
(f (x) f (x0 ))/f (x0 )
,
(x x0 )/x0
(xx0 )0
lim

typically known sensitivity f x x0 . Therefore, Theorem 3.2 shows
sensitivity Pr (y | e) x|u bounded.
example application Theorem 3.2, consider Example 3.1 again. change
x 0 amounts relative change | /| = 1. corresponding change
Pr (y | e) .5 0 amounts relative change | .5/.5| = 1. Hence, relative
change query great viewpoint.7
relative change Pr (y | e) may greater double relative change x|u
non-infinitesimal changes derivative Pr (y | e)/x|u depends value
x|u (Darwiche, 2000; Jensen, 1999). Going back Example 3.1, set x = .5
= .01, obtain result Pr (y | e) = .01. increase x .6, relative change
20%, get new result Pr (y | e) = 0.0149, relative change 49%,
double relative change x .
question is: Suppose change meta parameter x|u arbitrary
amount (not infinitesimal amount), say corresponding change
query Pr (y | e)? following result.
Theorem 3.3 Let O(x | u) denote odds x given u: O(x | u) = Pr (x | u)/(1 Pr (x |
u)), let O(y | e) denote odds given e: O(y | e) = Pr (y | e)/(1 Pr (y | e)).
Let O0 (x | u) O0 (y | e) denote odds applied arbitrary change
6. binary variable X, x|u > .5, instead choose meta parameter x|u without loss
generality.
7. consider meta parameter x = 1 instead, relative change x amount
/(1 ). Theorem 3.2 applicable case (assuming close 0) since
theorem requires chosen meta parameter greater .5.

275

fiChan & Darwiche

meta parameter x|u X binary variable belief network. change
positive, then:
O(x | u)
O0 (y | e)
O0 (x | u)


;
O0 (x | u)
O(y | e)
O(x | u)
negative, then:
O0 (x | u)
O0 (y | e)
O(x | u)

0
.
O(x | u)
O(y | e)
(x | u)
Combining results, have:
| ln(O0 (y | e)) ln(O(y | e))| | ln(O0 (x | u)) ln(O(x | u))|.
Theorem 3.3 means relative change odds given e bounded
relative change odds x given u, X binary variable.8 Note result
makes assumptions whatsoever structure given belief network.
illustrate theorem, go back Example 2.1. intend increase
posterior Pr (fire | e) .25 .5, e = smoke, report. log-odds change
query thus lo(Pr (y | e)) = | ln(O0 (y | e)) ln(O(y | e))| = 1.1. five
recommendations made SamIam calculate log-odds change, lo(x|u ) =
| ln(O0 (x | u)) ln(O(x | u))| parameter change:
1. increase prior fire .03 (from .01): lo(x|u ) = 1.1;
2. increase prior tampering .80 (from .02): lo(x|u ) = 5.3;
3. decrease Pr (smoke | fire) .003 (from .01): lo(x|u ) = 1.2;
4. increase Pr (leaving | alarm) .923 (from .001): lo(x|u ) = 9.4;
5. increase Pr (report | leaving) .776 (from .01): lo(x|u ) = 5.8.
Therefore, see recommended parameter changes satisfy Theorem 3.3,
i.e. log-odds change query bounded log-odds change parameter.
interesting special case Theorem 3.3 X root node X = .
basic probability theory, have:
O(x | e) = O(x)

Pr (e | x)
.
Pr (e | x)

ratio Pr (e | x)/Pr (e | x) independent Pr (x), ratio O(x | e)/O(x) also
independent prior. Therefore, conclude that:
O0 (x | e)
O0 (x)
=
.
O(x | e)
O(x)

(4)

means find exact amount change needed meta parameter x
order induce particular change query Pr (x | e). need use
expensive technique Section 2 case.
8. recently expanded results multi-valued variables, arbitrarily change parameters
0
x|u new values x|u
, values x. resulting bound is: | ln(O0 (y | e)) ln(O(y | e))|
0
0
ln(maxx x|u /x|u ) ln(minx x|u
/x|u ) (Chan & Darwiche, 2002).

276

fiWhen Numbers Really Matter?

Example 3.2 Consider network Figure 3. Suppose e = report, smoke. Currently, Pr (tampering) = .02 Pr (tampering | e) = .50. wish increase conditional probability .65. compute new prior probability Pr 0 (tampering) using
Equation 4:
.65/.35
Pr 0 (tampering)/(1 Pr 0 (tampering))
=
,
.50/.50
.02/.98
giving us Pr 0 (tampering) = .036, equal result obtained using SamIam
Section 1. changes Pr (tampering) Pr (tampering | e) bring log-odds
difference .616.
Theorem 3.3 number implications. First, given particular query Pr (y | e)
meta parameter x|u , used bound effect change x|u
query Pr (y | e). Going back Example 3.2, may wish know impact
conditional probabilities apply change making Pr 0 (tampering) = .036.
log-odds changes conditional probabilities network bounded
.616. example, currently Pr (fire | e) = .029. Using Theorem 3.3, find range
new conditional probability value Pr 0 (fire | e):

!



.029
Pr 0 (fire | e)

ln
ln
.616,

1 P r0 (fire | e)
.971

giving us range .016 Pr 0 (fire | e) .053. exact value Pr 0 (fire | e), obtained
inference, .021, within computed bounds.
Second, Theorem 3.3 used efficiently approximate solutions Difference
Ratio problems discussed Section 2. is, given desirable change
value query Pr (y | e), use Theorem 3.3 immediately compute lower bound
minimum change meta parameter x|u needed induce change. method
applied constant time serve preliminary recommendation,
method proposed Section 2 much expensive computationally.
Third, suppose SamIam used recommend parameter changes would
induce desirable change given query. Suppose SamIam returned
number changes, capable inducing necessary change.
question is: one changes adopt? main principle applied
situations adopt minimal change. minimal case?
Theorem 3.3 reveals, notion minimality based amount absolute change
misleading. Instead, suggests one adopts change minimizes
relative change odds, queries shown robust
change precise sense.
example, given two parameter changes, one .1 .15, another
.4 .45. changes give us absolute change .05. However, first
change log-odds change .462, second one log-odds change .205.
Therefore, two parameter changes give us absolute change different
amounts log-odds change.
hand, two parameter changes give us relative change
also different amounts log-odds change. example, given two parameter
changes, one .1 .2, another .2 .4. changes double original
277

fiChan & Darwiche

parameter value. However, first change log-odds change .811, second
one log-odds change .981.
Finally, result used obtain better intuitive understanding parameter
changes matter, topic discuss next section.

4. Changes (Dont) Matter
return central question: changes network parameters matter
matter? mentioned earlier, experimental studies
investigating robustness belief networks parameter changes (Pradhan et al.,
1996). also shown simple intuitive examples networks
sensitive small parameter changes. calls better understanding
effect parameter changes queries, one intuitively sort situations
changes matter. goal section develop
understanding looking closely implications Theorem 3.3.
start first highlighting difference theorem previous results
sensitivity analysis.
4.1 Network-Specific Sensitivity Analysis
One main differences results sensitivity analysis approaches
need know belief network, hence, need perform
inference. clarify difference, compare sensitivity function approach
(van der Gaag & Renooij, 2001), computes sensitivity function relates
query, f (x), parameter, x, form:
f (x) =

ax+b
,
cx+d

a, b, c, constants depend given network computed
performing inference suggested van der Gaag Renooij (2001).
Going back Example 2.1, express query Pr (fire | smoke, report)
function parameter x = Pr (smoke | fire). function given by:
f (x) =

0.003165
,
0.9684 x + 0.003165

plot function Figure 6. see current parameter value .01,
query value .25, decrease .003, query value increases .5,
one suggested parameter changes SamIam.
However, find bound relations query parameter
using Theorem 3.3, without inference network (and without knowing
network). example, changing current parameter value .01 .003, new
query value within bounds .09 .53. hand, want
query value increase .5, least decrease parameter value .01
.003, increase .03.
278

fiWhen Numbers Really Matter?

___

___

Pr(fire|smoke, report)

Pr(fire| smoke, report)
1

0.5

0.8

0.4
0.6
0.3
0.4

0.2

0.2

0.1
___

0.2

0.4

0.6

0.8

1

___

Pr(smoke, fire)

0.005

0.01

0.015

0.02

Pr(smoke, fire)

Figure 6: plot query Pr (fire | smoke, report) parameter Pr (smoke |
fire). second graph shows magnification first graph region
Pr (smoke | fire) 0 .02.

4.2 Assuring Query Robustness
One important issues yet settle is: mean parameter
change matter? One think least three definitions. First, absolute
change probability Pr (y | e) small. Second, relative change probability
Pr (y | e) small. Third, relative change odds O(y | e) small. first notion
one prevalent literature, shall adopt rest section.
Suppose belief network diagnostic application suppose concerned robustness query Pr (y | e) respect changes network
parameters. application, particular disease e particular finding
predicts disease, Pr (y | e) = .9. Let us define robustness case
absolute change .05 given query. Now, let X binary variable
network let us ask: kind changes parameters X guaranteed
keep query within desirable range? use Theorem 3.3 easily answer
question. First, changing parameter , want value query
remain .95, must ensure that:
| ln((p + )/(1 p )) ln(p/(1 p))| | ln(.95/.05) ln(.9/.1)| = .7472,
p current value parameter. Similarly, want ensure query
remains .85, want ensure that:
| ln((p + )/(1 p )) ln(p/(1 p))| | ln(.85/.15) ln(.9/.1)| = .4626.
Figure 7 plots permissible change function p, current value
parameter. main point observe amount permissible change
depends current value p, smaller changes allowed extreme values p.
also interesting note easier guarantee query stay .95
guarantee stays .85. general, likely parameter change reduce
279

fiChan & Darwiche



0.15
0.1
0.05

0.2

0.4

0.6

0.8

1

p

0.05
0.1
0.15

Figure 7: amount parameter change would guarantee query Pr (y | e) = .9
stay within interval [.85, .95], function current parameter value
p. outer envelope guarantees query remain .95, inner
envelope guarantees query remain .85.



0.04

0.02

0.2

0.4

0.6

0.8

1

p

0.02

0.04

Figure 8: amount parameter change would guarantee query Pr (y | e) = .6
stay within interval [.55, .65], function current parameter value
p. outer envelope guarantees query remain .65, inner
envelope guarantees query stay .55.

value query close 1 (and increase value query close
0). Finally, increasing parameter, parameter value close .4
allow biggest absolute change. decreasing parameter, value
close .6 allow biggest absolute change.
let us repeat exercise assuming initial value query
Pr (y | e) = .6, yet insisting measure robustness. Figure 8 plots
280

fiWhen Numbers Really Matter?

8
6

lo

4

0.8

2
0

0.6
Pr(x| u)

0.4

0.2
0.4
Pr(x| u)

0.2

0.6
0.8

Figure 9: plot log-odd difference, lo = | ln(O0 (x | u)) ln(O(x | u))|,
Pr (x | u) Pr 0 (x | u).

lo

lo

lo

6

4

6

5

5

3

4
3

4
3

2

2

2

1

1
0.2

0.4

0.6

0.8

1

p

1
0.2

0.4

0.6

0.8

1

p

0.2

0.4

0.6

0.8

1

p

Figure 10: plots log-odd difference, lo = | ln(O0 (x | u)) ln(O(x | u))|,
new parameter value p0 = Pr 0 (x | u). figures correspond different
initial values parameter, p = Pr (x | u) = .1, .5, .9, respectively.

permissible changes function p, current value parameter. Again,
amount permissible change becomes smaller probability p approaches 0 1.
main point emphasize permissible changes much smaller
previous example, since initial value query extreme. Therefore,
query much less robust previous one.
generally, Figure 9 plots log-odds difference, | ln(O0 (x | u)) ln(O(x | u))|,
Pr (x | u) = p Pr 0 (x | u) = p + , Figure 10 shows cross-sections Figure 9
three different values p. Again, plots explain analytically afford
absolute changes non-extreme probabilities (Pradhan et al., 1996; Poole, 1998).
281

fiChan & Darwiche

Figure 10, also notice although plot symmetric p = .5,
p = .1 p = .9, i.e. absolute changes p p give us different amounts
log-odds change. example, changing parameter .1 .05 give us larger
log-odds change changing parameter .1 .15. also notice plots
p = .1 p = .9 mirror images other. Therefore, log-odds change
complementary parameter changes x|u x|u .
close section emphasizing figures identify parameter changes
guarantee keeping queries within certain ranges. However, belief network
specific properties, specific topology, possible query robust
parameter changes outside identified bounds.

5. Conclusion
paper, presented efficient technique fine-tuning parameters belief
network. technique suggests minimal changes network parameters ensure
certain constraints enforced probabilistic queries. Based technique,
experimented belief networks, find networks
sensitive parameter changes previous experimental studies seem suggest.
observation leads us analytic study effect parameter changes,
aim characterizing situations parameter changes matter.
reported number results direction. central result shows belief
networks robust specific sense: relative change query odds bounded
relative change parameter odds. closer look result, meaning,
implications provides interesting characterizations parameter changes
matter, explains analytically previous experimental results
observations matter.

Acknowledgments
shorter version paper appeared Proceedings 17th Conference Uncertainty Artificial Intelligence (UAI-01), pp. 6574. work partially supported
NSF grant IIS-9988543, MURI grant N00014-00-1-0617, DiMI grant 00-10065.

Appendix A. Proofs
Theorem 2.1 derivative Pr (e) respect meta parameter x|u given
by:
Pr (e, x, u) Pr (e, x, u)
Pr (e)
=

,
x|u
x|u
x|u

x|u 6= 0 x|u 6= 0.
282

fiWhen Numbers Really Matter?

Proof Russell et al. (1995), semantics first derivative Pr (e) respect
parameter x|u given by:9
Pr (e)
Pr (e, x, u)
=
,
x|u
x|u
x|u 6= 0, and:
Pr (e, x, u)
Pr (e)
=
,
x|u
x|u
x|u 6= 0. x|u = x|u x|u = 1 x|u , have:
Pr (e)
x|u

=

Pr (e) Pr (e)

x|u
x|u

=

Pr (e, x, u) Pr (e, x, u)
,

x|u
x|u

x|u 6= 0 x|u 6= 0.2
Theorem 3.1 X binary variable belief network, then:


Pr (y | e)
Pr (y | e)(1 Pr (y | e))


.


x|u
Pr (x | u)(1 Pr (x | u))

Proof Darwiche (2000), derivative Pr (y | e)/x|u equal to:
Pr (y | e)
Pr (y, x, u | e) Pr (y | e)Pr (x, u | e)
.
=
x|u
Pr (x | u)
Since:

Pr (y | e)
Pr (y | e) Pr (y | e)
,
=

x|u
x|u
x|u

have:
Pr (y | e)
x|u
=
=

Pr (y, x, u | e) Pr (y | e)Pr (x, u | e) Pr (y, x, u | e) Pr (y | e)Pr (x, u | e)

Pr (x | u)
Pr (x | u)
Pr (y, x, u | e) Pr (y | e)Pr (x, u | e) Pr (x | u)(Pr (y, u | e) Pr (y | e)Pr (u | e))
.
Pr (x | u)(1 Pr (x | u))

order find upper bound derivative, would like bound term
Pr (y, x, u | e)Pr (y | e)Pr (x, u | e). Since, Pr (y, x, u, e) Pr (y, u, e) Pr (y, x, u, e)
Pr (x, u, e), have:
Pr (y, x, u | e) Pr (y | e)Pr (x, u | e) Pr (y, x, u | e) Pr (y | e)Pr (y, x, u | e)
= Pr (y, x, u | e)Pr (y | e)
Pr (y, u | e)Pr (y | e).
9. allow notations Pr (e)/x|u Pr (e)/x|u assuming Pr (e) functions x|u x|u ,
even though allowed belief networks change x|u x|u .

283

fiChan & Darwiche

Therefore, upper bound derivative given by:
Pr (y | e)
Pr (y, u | e)Pr (y | e) Pr (x | u)(Pr (y, u | e) Pr (y | e)Pr (u | e))

,
x|u
Pr (x | u)(1 Pr (x | u))
equal following term:
Pr (y | e)Pr (y, u | e) Pr (y | e)Pr (y, u | e)
+
Pr (x | u)
1 Pr (x | u)
(1 Pr (x | u))Pr (y | e)Pr (y, u | e) + Pr (x | u)Pr (y | e)Pr (y, u | e)
=
Pr (x | u)(1 Pr (x | u))
Pr (y, u | e)Pr (y | e) Pr (x | u)(P r(y, u | e) Pr (y | e)Pr (u | e))
=
.
Pr (x | u)(1 Pr (x | u))
Since Pr (y, u | e) Pr (y | e) Pr (y, u | e) Pr (y | e), upper bound
derivative given by:
Pr (y | e)
x|u



=

Pr (y | e)Pr (y, u | e) Pr (y | e)Pr (y, u | e)
+
Pr (x | u)
1 Pr (x | u)
Pr (y | e)Pr (y | e) Pr (y | e)Pr (y | e)
+
Pr (x | u)
1 Pr (x | u)
Pr (y | e)(1 Pr (y | e))
.
Pr (x | u)(1 Pr (x | u))

order find lower bound derivative, note Pr (y | e) = 1 Pr (y | e),
thus Pr (y | e)/x|u = Pr (y | e)/x|u . Therefore, get lower bound
finding upper bound derivative Pr (y | e)/x|u multiplying 1:
Pr (y | e)
x|u



Pr (y | e)(1 Pr (y | e))
Pr (x | u)(1 Pr (x | u))

=

Pr (y | e)(1 Pr (y | e))
.
Pr (x | u)(1 Pr (x | u))

Combining upper bound lower bound, have:


Pr (y | e)
Pr (y | e)(1 Pr (y | e))


.2


x|u
Pr (x | u)(1 Pr (x | u))

Theorem 3.2 Assume x|u .5 without loss generality. Suppose x|u
infinitesimal change applied meta parameter x|u , leading change Pr (y | e)
query Pr (y | e). have:





Pr (y | e)
x|u




.
Pr (y | e) 2
x|u

284

fiWhen Numbers Really Matter?

Proof x|u infinitesimal, Theorem 3.1:


Pr (y | e)




x|u



Pr (y | e)


'

x|u



Pr (y | e)(1 Pr (y | e))
.
Pr (x | u)(1 Pr (x | u))

Arranging terms, have:


Pr (y | e)


Pr (y | e)







1 Pr (y | e) x|u


1 Pr (x | u) x|u



1 x|u


.5 x|u



=






x|u

2
,
x|u

since Pr (x | u) = x|u .5.2
Theorem 3.3 Let O(x | u) denote odds x given u: O(x | u) = Pr (x | u)/(1Pr (x |
u)), let O(y | e) denote odds given e: O(y | e) = Pr (y | e)/(1 Pr (y | e)).
Let O0 (x | u) O0 (y | e) denote odds applied arbitrary change
meta parameter x|u X binary variable belief network. change
positive, then:
O(x | u)
O0 (y | e)
O0 (x | u)


;
0
(x | u)
O(y | e)
O(x | u)
negative, then:
O0 (x | u)
O0 (y | e)
O(x | u)

0
.
O(x | u)
O(y | e)
(x | u)
Combining results, have:
| ln(O0 (y | e)) ln(O(y | e))| | ln(O0 (x | u)) ln(O(x | u))|.

Proof obtain result integrating bound Theorem 3.1. particular,
0
change x|u x|u
> x|u , consequently Pr (y | e) changes Pr 0 (y | e),
separate variables upper bound derivative Theorem 3.1, integrate
intervals, yield:
Z Pr 0 (y|e)
Pr (y|e)

dPr (y | e)

Pr (y | e)(1 Pr (y | e))

Z 0
x|u
x|u

dx|u
.
x|u (1 x|u )

gives us solution:
ln(Pr 0 (y | e)) ln(Pr (y | e)) ln(1 Pr 0 (y | e)) + ln(1 Pr (y | e))
0
0
ln(x|u
) ln(x|u ) ln(1 x|u
) + ln(1 x|u ),
285

fiChan & Darwiche

taking exponentials, have:
0 /(1 0 )
x|u
Pr 0 (y | e)/(1 Pr 0 (y | e))
x|u

,
Pr (y | e)/(1 Pr (y | e))
x|u /(1 x|u )

equivalent to:

O0 (x | u)
O0 (y | e)

.
O(y | e)
O(x | u)

Similarly, separate variables lower bound derivative Theorem 3.1, integrate intervals, yield:
Z Pr 0 (y|e)
Pr (y|e)

dPr (y | e)

Pr (y | e)(1 Pr (y | e))

Z 0
x|u
x|u

dx|u
.
x|u (1 x|u )

gives us solution:
ln(Pr 0 (y | e)) ln(Pr (y | e)) ln(1 Pr 0 (y | e)) + ln(1 Pr (y | e))
0
0
ln(x|u
) + ln(x|u ) + ln(1 x|u
) ln(1 x|u ),
taking exponentials, have:
x|u /(1 x|u )
Pr 0 (y | e)/(1 Pr 0 (y | e))
0
0 ),
Pr (y | e)/(1 Pr (y | e))
x|u /(1 x|u
equivalent to:

O0 (y | e)
O(x | u)
0
.
O(y | e)
(x | u)

0
Therefore, following inequality x|u
> x|u :

O(x | u)
O0 (y | e)
O0 (x | u)


.
O0 (x | u)
O(y | e)
O(x | u)
0
hand, change x|u x|u
< x|u , instead integrate
x|u . integrals satisfy two inequalities:

0
x|u

Z Pr (y|e)
Pr 0 (y|e)

Z Pr (y|e)
Pr 0 (y|e)

Z x|u

dPr (y | e)
Pr (y | e)(1 Pr (y | e))



dPr (y | e)
Pr (y | e)(1 Pr (y | e))



0
x|u

dx|u
;
x|u (1 x|u )

Z x|u
0
x|u

dx|u
.
x|u (1 x|u )

solve inequalities similarly get result:
O0 (x | u)
O0 (y | e)
O(x | u)

0
.
O(x | u)
O(y | e)
(x | u)
0
0
Combining results x|u
> x|u x|u
< x|u , have:

| ln(O0 (y | e)) ln(O(y | e))| | ln(O0 (x | u)) ln(O(x | u))|.2
286

fiWhen Numbers Really Matter?

References
Castillo, E., Gutierrez, J. M., & Hadi, A. S. (1997). Sensitivity analysis discrete Bayesian
networks. IEEE Transactions Systems, Man, Cybernetics, 27, 412423.
Chan, H., & Darwiche, A. (2002). distance measure bounding probabilistic belief
change. Proceedings Eighteenth National Conference Artificial Intelligence
(AAAI), pp. 539545.
Coupe, V. M. H., Peek, N., Ottenkamp, J., & Habbema, J. D. F. (1999). Using sensitivity analysis efficient quantification belief network. Artificial Intelligence
Medicine, 17, 223247.
Darwiche, A. (2000). differential approach inference Bayesian networks. Proceedings 16th Conference Uncertainty Artificial Intelligence (UAI), pp.
123132.
Greiner, R., Grove, A., & Schuurmans, D. (1997). Learning Bayesian nets perform
well. Proceedings 13th Conference Uncertainty Artificial Intelligence
(UAI), pp. 198207.
Jensen, F. V., Lauritzen, S., & Olesen, K. (1990). Bayesian updating recursive graphical
models local computation. Computational Statistics Quarterly, 4, 269282.
Jensen, F. V. (1999). Gradient descent training bayesian networks. Proceedings
Fifth European Conference Symbolic Quantitative Approaches Reasoning
Uncertainty (ECSQARU), pp. 190200.
Jensen, F. V. (2001). Bayesian Networks Decision Graphs. Springer-Verlag, Inc., New
York.
Kjrulff, U., & van der Gaag, L. C. (2000). Making sensitivity analysis computationally
efficient. Proceedings 16th Conference Uncertainty Artificial Intelligence
(UAI), pp. 317325.
Laskey, K. B. (1995). Sensitivity analysis probability assessments Bayesian networks.
IEEE Transactions Systems, Man, Cybernetics, 25, 901909.
Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks Plausible Inference. Morgan Kaufmann Publishers, Inc., San Mateo, California.
Poole, D. (1998). Context-specific approximation probabilistic inference. Proceedings
14th Conference Uncertainty Artificial Intelligence (UAI), pp. 447454.
Pradhan, M., Henrion, M., Provan, G., Del Favero, B., & Huang, K. (1996). sensitivity
belief networks imprecise probabilities: experimental investigation. Artificial
Intelligence, 85, 363397.
Russell, S., Binder, J., Koller, D., & Kanazawa, K. (1995). Local learning probabilistic
networks hidden variables. Proceedings Fourteenth International Joint
Conference Artificial Intelligence (IJCAI), pp. 11461152.
van der Gaag, L. C., & Renooij, S. (2001). Analysing sensitivity data probabilistic networks. Proceedings 17th Conference Uncertainty Artificial Intelligence
(UAI), pp. 530537.

287

fiJournal Articial Intelligence Research 17 (2002) 83135

Submitted 10/01; published 08/02

Monitoring Teams Overhearing:
Multi-Agent Plan-Recognition Approach

galk@cs.biu.ac.il

Gal A. Kaminka
Computer Science Department
Bar Ilan University
Ramat Gan 52900, Israel

pynadath@isi.edu
tambe@usc.edu

David V. Pynadath
Milind Tambe
Computer Science Department Information Sciences Institute
University Southern California
4676 Admiralty Way
Los Angeles, CA 90292, USA

Abstract

Recent years seeing increasing need on-line monitoring teams cooperating agents, e.g., visualization, performance tracking. However, monitoring
deployed teams, often cannot rely agents always communicate state
monitoring system. paper presents non-intrusive approach monitoring
overhearing, monitored team's state inferred (via plan-recognition) teammembers' routine communications, exchanged part coordinated task execution,
observed (overheard) monitoring system. Key challenges approach include demanding run-time requirements monitoring, scarceness observations
(increasing monitoring uncertainty), need scale-up monitoring address potentially large teams. address these, present set complementary novel techniques,
exploiting knowledge social structures procedures monitored team: (i)
ecient probabilistic plan-recognition algorithm, well-suited processing communications observations; (ii) approach exploiting knowledge team's social behavior predict future observations execution (reducing monitoring uncertainty);
(iii) monitoring algorithms trade expressivity scalability, representing
certain useful monitoring hypotheses, allowing number agents
dierent activities represented single coherent entity. present empirical
evaluation techniques, combination apart, monitoring deployed team
agents, running machines physically distributed across country, engaged
complex, dynamic task execution. also compare performance techniques
human expert novice monitors, show techniques presented capable
monitoring human-expert levels, despite diculty task.
1. Introduction
Recent years seen tremendous growth applications involving distributed multi-agent
teams, formed agents collaborate specic joint task (e.g., Jennings, 1995; Pechoucek, Marik, & Stepankova, 2000, 2001; Kumar & Cohen, 2000; Kumar, Cohen, &
Levesque, 2000; Horling, Benyo, & Lesser, 2001; Lenser, Bruce, & Veloso, 2001; Barber &
Martin, 2001). growth led increasing need monitoring techniques allow

c 2002 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiKaminka, Pynadath, & Tambe
synthetic agent human operator monitor identify state distributed team.
Previous work discussed critical role monitoring visualization (e.g., Ndumu,
Nwana, Lee, & Collis, 1999), identifying failures execution (e.g., Horling et al., 2001),
providing advice improve performance (e.g., Aiello, Busetta, Dona, & Serani, 2001),
facilitating collaboration monitoring agent members team
(e.g., Grosz & Kraus, 1996).
paper focuses monitoring cooperative agent teams overhearing internal communications.

allows human operator synthetic agent monitor

coordinated execution task, listening messages team-members exchange
other.

contrasts previous techniques impractical settings

direct observations team members unavailable (e.g., team-members
physically distributed away observer), large-scale applications composed

already-deployed

agents dynamically integrated jointly execute task.

example, one common technique,

report-based monitoring, requires

monitored

team-member communicate state monitoring agent regular intervals,
least whenever team-member changes state. reporting provides monitoring
agent accurate information state team. Unfortunately, report-based monitoring suers several diculties monitoring large deployed teams interest
real-world (see Section 2 detailed discussion): First, requires intrusive modications
behavior agents, report state needed dierent monitoring applications. However, since agents already deployed, repeated modications
behavior agents dicult implement complex manage.

par-

ticular, legacy proprietary systems notoriously expensive modify (for instance,
consider notorious modications address Year 2000 bug, also known Y2K).
Second, bandwidth requirements report-based monitoring (which relies communication channels) unrealistic (Jennings, 1993, 1995; Grosz & Kraus, 1996; Pechoucek
et

al., 2000, 2001; Vercouter, Beaune, & Sayettat, 2000). addition, network delays

unreliable lossy communication channels key concern report-based monitoring
approaches.
therefore advocate alternative monitoring approach, based multi-agent keyhole
plan-recognition (Tambe, 1996; Huber & Hadley, 1997; Devaney & Ram, 1998; Intille &
Bobick, 1999; Kaminka & Tambe, 2000).

approach, monitoring system infers

unobservable state agents based observable actions, using knowledge
plans give rise actions. approach non-intrusive, requiring changes
agents' behaviors; allows changes requested monitoring information.
assumes access knowledge plans may explain observable actionhowever
knowledge readily available monitoring system assume deployed
collaborative environment. Indeed, cases, monitoring system may deployed
human operator team. additional benet plan-recognition approach
rely inference compensate occasional communication losses,
therefore robust communication failures.
general, observable actions agents distributed team

routine

communications, agents exchange part task execution (Ndumu et al., 1999).
Fortunately, growing popularity agent integration tools (Tambe, Pynadath, Chauvat,
Das, & Kaminka, 2000; Martin, Cheyer, & Moran, 1999) agent communications (Finin,

84

fiMonitoring Teams Overhearing
Labrou, & Mayeld, 1997; Reed, 1998) increases standardization aspects agent communications, provides increasing opportunities observing interpreting inter-agent
communications.

assume monitored agents truthful messages, since

communicating teammates; attempting deceive
monitoring agent prevent overhearing (as deployed human operator team).

Given (possibly stochastic) model plans agents may

executing, monitoring system using plan-recognition infer current state
agents observed routine messages.
However, application plan-recognition techniques overhearing poses signicant
challenges. First, key characteristic overhearing task scarcity observations.
Explanations overheard messages (i.e., observed actions) sometimes fairly easy
disambiguate, uncertainty arises relatively observe:
team members cannot practice continuously communicate among
state (Jennings, 1995; Grosz & Kraus, 1996). Thus team-members change
state keeping quiet. Another key characteristic overhearing observable
actions inherently
agent

listening.

multi-agent actions :

sends messages.

agents communicate, single

others implicitly act role communications

Yet despite scarcity observable communications, multi-agent nature

observed actions, monitoring system must infer state agents team,
times. Previous investigations multi-agent plan-recognition (Tambe, 1996; Devaney
& Ram, 1998; Intille & Bobick, 1999; Kaminka & Tambe, 2000) typically made
assumption changes state agents observable eect: Uncertainty
resulted ambiguity explanations observed actions. Furthermore,
investigations addressed settings observable actions individual (each action
carried single agent).
addition challenges unique overhearing, monitoring system must
address additional challenges stemming use monitoring service visualization.

representation algorithms must support soft real-time response; reasoning

must done quickly useful visualization.

Furthermore, real-world applications

demand techniques scale number agents increases, monitoring large
teams. However, many current representations plan-recognition computationally intense (e.g., Kjrul, 1992), address single-agent recognition tasks (e.g., Pynadath
& Wellman, 2000). Multi-agent plan-recognition investigations typically explicitly
addressed scalability concerns (Devaney & Ram, 1998; Intille & Bobick, 1999).
paper presents Overseer, implemented monitoring system capable monitoring large distributed applications composed previously-deployed agents.

Overseer

builds previous work multi-agent plan-recognition (Tambe, 1996; Intille & Bobick,
1999; Kaminka & Tambe, 2000) utilizing knowledge relationships agents
understand decisions interact. However, previous techniques proved insucient, Overseer includes number novel multi-agent plan-recognition techniques
address scarcity observations, well severe response-time scale-up requirements imposed realistic applications. Key contributions include: (i)

linear time

probabilistic plan-recognition representation associated algorithms, exploit
nature observed communications eciency; (ii) method addressing unavailable
observations exploiting knowledge

social procedures
85

teams eectively predict

fiKaminka, Pynadath, & Tambe
(and hence eectively monitor) future observations normal failed execution, thus
allowing inference lack observations; (iii) YOYO*, algorithm uses

team-hierarchy )

knowledge team organizational structure (

model agent team

(with dierent parallel activities taken individual agents) using single structure,
instead modeling agent individually. YOYO* sacrices expressivity (the ability
accurately monitor team certain coordination failure states) signicant gains
eciency scalability.
present rigorous evaluation Overseer's dierent monitoring techniques one
application domains show techniques presented result signicant boosts
Overseer's monitoring accuracy eciency, beyond techniques explored previous
work. evaluate Overseer's capability address lossy observations, key concern
report-based monitoring. Furthermore, evaluate Overseer's performance comparison
human expert novice monitors, show Overseer's performance comparable human experts, despite diculty task, Overseer's reliance
computationally-simple techniques. One key lessons draw Overseer
combination computationally-cheap multi-agent plan-recognition techniques, exploiting knowledge expected structures interactions among team-members,
competitive approaches focus accurate modeling individual agents (and
may computationally expensive).
paper organized follows.

Section 2 presents motivation design

Overseer, using examples actual distributed application Overseer
applied.

Section 3 presents novel single-agent plan-recognition representation

associated algorithms, particularly suited monitoring agent based observed
communications. Section 4 explores several methods Overseer uses address uncertainty
using representation monitoring team agents. Section 5 presents YOYO*,
allows ecient reasoning using methods previously discussed. Section 6 presents
evaluation dierent techniques incorporated YOYO*. Section 7 contrasts
techniques presented previous related investigations, nally, Section 8 concludes
presents plans future work. addition, several appendices present pseudocode algorithms discussed text, portions data used experiments,
readers may wish replicate experiments.

2. Motivation Illustrative Examples
Several considerations, based experience actual distributed applications,
directed us towards plan-recognition approach advocate paper. present
considerations context illustrative complex distributed application,
also use evaluating Overseer Section 6. application, distributed team
11 20 agents executes simulation evacuation civilians threatened location.
integrated system allows human commander interactively provide locations
stranded civilians, safe areas evacuation key points. Simulated helicopters
coordinated mission evacuate civilians, relying various information agents
dynamically obtain information enemy threats, (re)plan routes avoid threats
obstacles, etc. distributed team composed diverse agents four dierent research groups: Quickset multi-modal command input agent (Cohen, Johnston, McGee,

86

fiMonitoring Teams Overhearing
Oviatt, Pittman, Smith, Chen, & Clow, 1997), Retsina route planner (Payne, Sycara,
Lewis, Lenox, & Hahn, 2000), Ariadne information agent (Knoblock, Minton, Ambite, Ashish, Modi, Muslea, Philpot, & Tejada, 1998) eight synthetic helicopter pilots
(Tambe, Johnson, Jones, Koss, Laird, Rosenbloom, & Schwamb, 1995).
agents designed work together taskthey already built
deployed prior creation team. team integrated using Teamcore
(Tambe et

al., 2000), accomplishes integration wrapping agent

proxy maintains collaboration agents (via proxies). proxies
agents form team, jointly executing distributed application described

oriented program.

team-

program consists of:



team hierarchy, team decomposes subteams, sub-subteams.



plan hierarchy, contains team plans decompose subteam plans



Assignment teams team hierarchy plans plan hierarchy.

example, Figure 1-a shows part team/subteam hierarchy used
evacuation-domain (described below).

Here, instance, TRANSPORT subteam

FLIGHT-TEAM, subteam TASK-FORCE. Figure 1-b shows abbreviated planhierarchy domain.

High-level team plans,

compose team plans,

Process-Orders,

Evacuate,

typically de-

and, ultimately, leaf-level

plans executed individuals. Temporal transitions used constrain order execution plans. teams assigned execute plans, e.g., TASK
FORCE team jointly executes Evacuate, TRANSPORT subteam executes
Transport-Operations (Transport-Ops) step.

team-oriented program

application consists 40 team-plans. plans may get executed repeatedly
though, agent may execute hundreds plan steps part execution
single team-oriented program.
execute team-oriented program, proxy uses domain-independent teamwork
model, called STEAM (Tambe, 1997).

teamwork model automatically generates

communication messages required ensure appropriate coordination among proxies.
instance, STEAM requires agent privately obtains belief

bel

terminates

team plan, agent send message rest team terminate
team plan, along private belief

bel

led termination. avoid jamming

communication channels ood messages every single plan, STEAM
chooses communicate selectively. Thus, whereas communicating initiation
termination every plan would led 2000 messages generated
one run, 100 messages get exchanged one run using STEAM (Tambe
et

al., 2000).
Figure 2 displays messages exchanged among team members evac-

uation application, use STEAM. rst message sent proxy
called teamquickset

members team TEAM-EVAC (another name TASK

FORCE). content message indicates team terminate plan
called

determine-number-of-helos.

second message sent proxy called

87

fiKaminka, Pynadath, & Tambe

TASK FORCE

EVACUATE [TASK FORCE]

.....
GET ORDERS
ROLE

FLIGHT
TEAM

ESCORT

ROUTE
PLANNER

TRANSPORT

ESCORT ESCORT

TRANSPORT ...

LEAD

DIVISION 1

FOLLOW

PROCESS
ORDERS
[TASK FORCE]

EXECUTE
MISSION
[TASK FORCE]

LANDING
ZONE
MANEUVERS
[FLIGHT TEAM]

FLY-FLIGHT
PLAN
GET
ORDERS
[FLIGHT TEAM]
[GET ORDERS]
FLY-CONTROL
ROUTE....
[FLIGHT TEAM]

(a)

.....

....
ESCORT
TRANSPORT
OPERATIONS OPERATIONS
[ESCORT]
[TRANSPORT]

(b)

Figure 1: Portions team-hierarchy (a) plan-hierarchy (b) used domain.
Dotted lines show temporal transitions.

team_auto2 members subteam TEAM-ESCORT-FOLLOW (a subteam ESCORTS). content message indicates subteam establish commitment plan named

prepare-to-execute-mission.

online appendix presents sample

logs overheard messages complete runs, well plan team hierarchies
evacuation application.
discussed Section 1, capability automatically monitoring progress
team critical.

need team monitoring amplied distributed

settings, since human operator one place cannot directly observe agents executing
remote location.

instance, trial runs evacuation simulation application

described above, monitoring sometimes required series frantic phone calls among human
operators dierent states, trying verify successful execution system
operating.

even agent team co-located multiple computers one

room, diversity agents made extremely dicult observer automatically
monitor state team observing dierent agent output screens.
Overseer built provide monitoring tracking routine communica-

tions among agents (Figure 2).

Using plan-recognition, allows humans agents

query present future likely plans entire team, subteams
individualsto monitor progress, compute likelihoods failure, etc. However, given
agent team communicates selectively plans executed, Overseer's planrecognition faces signicant uncertainty. Furthermore, Overseer must able answer
queries on-line, must therefore work eciently.

discussed later, addressing

challenges required several novel team-based plan-recognition techniques developed.
Several considerations led us away report-based monitoring
Teamcore applications. First, report-based monitoring requires agents' code mod-

ied communicate reports needed monitoring; monitoring requirements change

88

fiMonitoring Teams Overhearing

Log Message Received; Fri Sep 17 18:27:54 1999:
Logging Agent: teamquickset
Message==> tell
:content teamquickset terminate-jpg constant determine-number-of-helos
number-of-helos-determined *yes* 4 4 98 kqml_string
:receiver TEAM-EVAC 9 kqml_word
:reply-with nil 3 kqml_word
:team TEAM-EVAC 9 kqml_word
:sender teamquickset 12 kqml_word
:kqml-msg-id 21547+tsevet.isi.edu+7 22 kqml_word
Log Message Received; Fri Sep 17 18:30:35 1999:
Logging Agent: TEAM_auto2
Message==> tell
:content TEAM_auto2 establish-commitment prepare-to-execute-mission
58 kqml_string
:receiver TEAM-ESCORT-FOLLOW 18 kqml_word
:reply-with nil 3 kqml_word
:team TEAM-ESCORT-FOLLOW 18 kqml_word
:sender TEAM_auto2 10 kqml_word
:kqml-msg-id 20752+dui.isi.edu+16 20 kqml_word
Figure 2: Example KQML messages used observations Overseer.

89

fiKaminka, Pynadath, & Tambe
one application next, information needed agent.

Un-

fortunately, agents proxies already deployed several government laboratories universities.

Modifying agents deployed location problematic

intrusivemodications interfere carefully designed timing specications given
tasks, requiring modications agent developers. distributed nature
Teamcore implies centralized server controls behavior

agents, instead changes required dierent proxy types.

Indeed, general,

modifying legacy proprietary applications (including integration architecture)
course known dicult process, solution requires constant modications
agents architecture scale up.
second important consideration computational bandwidth requirements
report-based monitoring. repeatedly noted literature, one cannot expect
agents able communicate continuously fully monitor agents (e.g.,
Jennings, 1993, 1995; Grosz & Kraus, 1996; Pechoucek et al., 2001; Vercouter et al., 2000).
team 11 (used example paper), regularly scheduled state reports
agents required temporal resolution would require approximately 50,000 messages
sent 15-minute run, number nearly doubling reach 20 agents.
instead 11 agents report state changes, announcing plan initiation
termination, approximately 2,000 messages sent.

However, still

order-of-magnitude normal 100 messages exchanged
11 agents part routine execution. Even network could support bandwidth
necessary report-based monitoring, also signicant computational burden
monitoring system process incoming reports.
hand, plan-recognition approach seemed like natural task.
First, doesn't require changes behavior monitored agents, thus
suitable monitoring agents already deployed. Second, doesn't add
computational burdens monitored agents network, since uses
observations already available. Third, main knowledge source plan-recognition systems typically rely ona plan libraryis fact easily available accessible form
monitoring system team-oriented program used integrate agents,
since operator deploying monitoring system assumed one describe
integration team-oriented program rst place. Thus plan-recognition's sometimes
criticized assumption correct plan-library fact satised fully monitoring
application.
Note assumption holds even agents using integration architecture: knowledge rely (possibly stochastic) model
components execution together, communications used integrate
them. Therefore, paper focuses team-oriented programs (described above),
techniques introduced appear generalizable types representation languages
distributed systems, TMS (Decker, 1995), team-oriented programming (Tidhar,
1993a) others. Furthermore, plan-library need contain implemetation details
names key steps. Thus even agents utilizing radically-dierent representations
plan-hierarchy monitored, long execution states corresponding
team-oriented program (which case order coordinate
team-members).

90

fiMonitoring Teams Overhearing
Monitoring overhearing poses unique challenges previously discussed. However,
also oers unique opportunities plan recognition. earlier stated assumption
agents truthful communications, seek deceive teammates
monitoring system, prevent overhearing way (e.g., encryption).



assumption justied monitoring system deployed operator monitored
agents, agent team-member. Failures team coordinate (e.g., due clock
asynchrony unintentional erroneous messages) therefore cause corresponding failures
monitoring. However, make additional assumptions messages beyond
made monitored agents themselves.
assumption allows plan-recognition system treat observations certainty:
message overheard terminating plan
certainty indeed plan
plan recognition ambiguity.

X

X,

monitoring system infer

longer executed. However, eliminate

First, multiple instantiations plan

X

may exist,

message specify one terminated. Second, upon termination plan,
monitored team-member must often choose multiple alternative plan steps
follow

X,

yet choice evident observations.

Indeed, diculty

monitoring overhearing demonstrated human monitoring performance: Novice
human monitors managed achieve approximately 60% accuracy average.

3. Monitoring Team Agents Separate Individuals
section, present representation associated baseline algorithms support
overhearing based plan-hierarchy team-hierarchy.

begin making as-

sumption agent independence, observations beliefs one agent's state
execution bearing beliefs another agent's state. assumption
contrasted another: assume instead team-members successful
coordination, knowing one agent begun executing joint plan would naturally increase likelihood teammates begun well, agents would
considered independent. fact, successful teamwork

requires

interdependency among

agents (Grosz, 1996).
However, initial assumption agent independence provides baseline comparison,
closely follows current approaches multi-agent plan recognition, often
assume observations individual agent continuously available.

Later

sections (Sections 4 5) highlight unique challenges tackled monitoring
overhearing, take agent interdependencies account.
thus begin maintaining separate plan recognizer agent.

recog-

nizer observes messages respective agent sends. basis
observations, recognizer maintains probabilistic estimate state execution
various plans agent may currently executing. Knowledge plans assigned
agents team memberships available application plan-hierarchy
team-hierarchy team-oriented program used constructing monitored application.
Section 3.1 presents language use probabilistic representation teamoriented program.

exploit various independence properties within team-oriented pro-

grams achieve compact representation possible plan states agents. Sec-

91

fiKaminka, Pynadath, & Tambe
tion 3.2 presents algorithm updating recognizer's beliefs agents' plan
states upon observation message.

algorithm performs update

eciency gained exploiting particular semantics communicated messages, namely
message observation indicates initiation/termination par-

certainty.

ticular plan

Section 3.3 presents algorithm updating recognizer's

beliefs agents' plan states



message observed. absence

evidence, algorithm eciently updates recognizer's beliefs using
temporal model agents' plan execution makes strong Markovian assumption.
Finally, Section 3.4 presents overall recognition procedure, well illustration
complexity analysis procedure.

3.1 Plan-State Representation
address uncertainty monitoring probabilistic model supports quantitative evaluation recognized plan hypotheses. Since monitoring agents
duration execution, use time series plan-state variables.



point time, agent's plan state state team-oriented program
currently executing, i.e., path root leaf team-oriented program tree.
represent plans program set boolean random variables,
variable

Xt

represent beliefs agent's actual state time
variables

fXt g.

X

fXt g,

t.
probability distribution

true agent actively executing plan

time

distribution takes account dependencies among dierent

plans team-oriented program (e.g., parent-child relationships), well temporal dependencies plan state times





+ 1.

simplify dependency

done(X; t),
1 execution terminated

structure, useful introduce additional boolean random variables,
true plan
time

t.

X

executed time



number possible representations capturing distribution performing inference variables.

However, generality plan hierarchy,

dynamic nature domain, requirements task eliminate existing approaches consideration. instance, could potentially generate DBNDynamic
Belief Network (Kjrul, 1992)to represent probabilistic distribution plan
variables. so, include nodes representing plan variables,
representing

done(X; t).

Xt ,

well

links among nodes represent structure plan

hierarchy (e.g., parent-child relationships, temporal constraints), conditional probability tables accordingly. also represent temporal progress team
including nodes variables next time slice,
nodes

Xt+1

links.

Xt+1 .

add links

Xt

nodes represent dynamics conditional probability tables

transition node

Xt

node

Yt+1 (X

6= ), would

also add binary nodes indicating observation message along transition. Thus,
plan hierarchy

(4M



plan nodes, corresponding DBN representation

+ 2 ) = O(M 2 ) binary random variables.

standard DBN inference algorithms maintain belief state,
posterior probability distribution variables time slice,

t,

bt ,

representing

conditioned

observations made far (from time 0t). inference algorithms update

92

fiMonitoring Teams Overhearing
belief state incorporate new evidence variables,
next time-tick's belief state,

bt+1 .

Xt ,

also compute

extract desired probability plan-

state variables examining posterior probabilities stored

bt .

Given dependency

structure plan model, space time complexity performing inference using
2
DBN (either incorporating single observation, computing bt+1 )

(2 )

single agent.
DBN method suciently ecient support on-line monitoring real-world
domains, since every time step, recognizer must perform inferential
step exponential computational complexity.

exist

single-agent

plan-recognition

techniques avoid exponential complexity DBNs using representation
inference algorithms aimed particular properties plan-recognition task (e.g.,
Pynadath & Wellman, 2000).

specialized representations avoid full generality

DBNs, still capturing broad class interesting planning agent models.

Given

specialized representation, single-agent plan-recognition algorithms exploit
particular structure plan models achieve ecient online inference.
Drawing inspiration success work single-agent domains, adopt
similar methodology multi-agent domain.

words, developed

novel plan-recognition representation suited capturing team-oriented programs.
structural assumptions make representation support ecient inference
specialized algorithms, well naturally supporting extension represent interagent dependencies (as discussed Section 4).
represent team-oriented plan directed graph, whose vertices plans,
whose edges signify temporal hierarchical decomposition transitions plans:
Children edges denote hierarchical decomposition plan sub-plans.

Sibling edges

denote temporal orderings plans. Following structure plan hierarchy,
variables

fXt g form directed connected graph, node Xt one

hierarchical-decomposition incoming transition parent node (representing parent
plan), number temporal incoming transitions plans precede order

execution. graph may contain multiple nodes single plan, plan potential child multiple parent plans. node may number temporal outgoing
transitions immediate successor sibling nodes (representing plans may follow
order execution), number hierarchical-decomposition outgoing transitions
node's
plan

Xt .

rst

children (i.e., executed rst decomposition

graph forms tree along hierarchical decomposition transitions,

plan descendent. hand, may cycles along temporal
transitions (to siblings). words, plan may outgoing temporal transition
(meaning selected execution upon termination),
node temporal path leading back plan (meaning rst node
temporal sequence plans may executed repeatedly). may also two
alternative temporal paths leading indirectly one node another.
perform inference representation, borrow standard DBN inference
algorithms' notion belief state,

bt .

DBN case, belief state represents

posterior probability distribution variables time slice, t, conditioned
observations made far. addition, plan, distinguish state actual
execution

blocked

state, indicating execution terminated, execution

93

fiKaminka, Pynadath, & Tambe
successor yet begun (perhaps agent process sending
message).

bt (X; block )

Thus,

belief

X

terminated, agent

bt (X; :block ) belief time monitored
X , yet terminated. precisely, dene
Pr(Xt ; done(X; + 1)jE ) bt (X; :block) Pr(Xt ; :done(X; + 1)jE ),

begun execution successor;
agent currently executing


E denotes evidence received far. recognizer observes

bt (X; block )


message agent time

t,

updates previous belief state,

bt+1 ,

evidence new belief state,

bt+1 ,

incorporating

according method described Section

3.2. observe message agent time
new belief state,

bt ,

t,

propagates belief

using method described Section 3.3 simulate plan execution

time.

3.2 Belief Update Observed Message
observing team communications, recognizer expect occasionally receive
evidence form messages (sent individual agent member) identify either
plan initiation termination.

incorporating evidence, exploit assumption

agents truthful messages. words, observe initiation
message plan,

X,

time

t,

termination message plan,



X,

Xt

true certainty.

time

t,



Likewise, observe

done(X; + 1)

true certainty.

precisely, algorithms presented section specialized exploit prop-


, either Pr(Xt j
; E ) = 1
Pr(done(X; t)j
; E ) = 1, possible previously observed evidence, E .
erty observed communications, observation

Though messages assumed truthful, still remains ambiguity.
message uniquely species relevant

First,

plan, uniquely specify relevant node.

words, recognizer still unsure particular
refers to, since graph may contain multiple

Xt

Xt

node message

nodes consistent message. Fur-

thermore, message announces termination plan (even ambiguity
corresponding node), still remains ambiguity next plan selected
agent.
observations available overhearing tasks immediate interest us fall
level ambiguity. evacuation scenario example, two nodes corresponding plan

land-troops,

one instance

land-troops

picking

people transported another dropping o. recognizer observes
message indicating agent initiated execution

land-troops,



ambiguity two instances currently relevant. Furthermore, may
exist ambiguity plan agent select terminating

land-troops.

Algorithm 1 presents pseudo-code complete procedure incorporating evidence observations.

Incorporating Evidence Observed Initiation Message (lines 38)

Suppose

t, observed message, msg, corresponds initiation. one
X , consistent msg, know, certainty, agent executing X ,

that, time
plan,

regardless whatever evidence previously observed. Therefore, simply set
belief

Xt

true 1.0. multiple plans consistent

msg, distribute

unit probability consistent plan, weighted prior belief seeing given

94

fiMonitoring Teams Overhearing
Algorithm 1 Incorporate-Evidence(msg m, beliefs b, plans )
0
1: Initialize distributions b ; bt+1
0:0 plans
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:

plans X 2 consistent
initiation message
plans W precede X
b0 (X; :block )
b0 (X; :block ) + bt (W; block )wx wx
else {m termination message}
plans 2 succeed X
b0 (Y; :block )
b0 (Y; :block ) + bt (X; block )xy xy
Normalize distribution b0
plans X 2 b0 > 0
bt+1 (X; :block )
b0 (X; :block )
(X; b0(X; :block ); b; )
tmp
X
parent(tmp) 6= null
bt+1 (parent(tmp); :block )
bt+1 (parent(tmp); :block ) + bt+1 (tmp; :block )
tmp
parent(tmp)



Propagate-Down

message. prior belief depends predecessor plans

X

may terminated

prior seeing message.
support computation beliefs transitions predecessor plans
successors, well beliefs seeing message given transition, Overseer stores
two parameters:





.

former probability entering successor plan,

given predecessor plan,

W,

completed:

wx

X,

Pr(Xt jWt; done(W; + 1)).
+1

latter probability seeing message, given agent took specied
transition:

wx

Pr(msgt jWt ; done(W; + 1); Xt ).
+1

use previous runs acquire

, producing frequency count transitions
runs (see Section 4.2 discussion use

suitable values parameters,
messages seen
Overseer).

msg, time t, wish
distribute unit probability plans, X , (in unblocked state) consistent
msg. derive new belief plan X time + 1 follows:
Therefore, given observation initiation message,

msg; Xt+1 jE )
Pr(Xt+1 jmsg; E ) = Pr(Pr(
msg jE )
denominator simply normalization factor, candidate plans,

X.

Therefore, ignore derivation, focus numerator,

X Pr(
X
+ Pr(

expand possible predecessor plans,

/

W,

possible termination states

msg; Xt+1 ; Wt ; done(W; + 1)jE )

W

W

msg; Xt+1 ; Wt ; :done(W; + 1)jE )

95

W:

fiKaminka, Pynadath, & Tambe
second term 0, since cannot proceed

W



X



W





terminated.

second term, expand joint probability component conditional
probabilities:

/

X[Pr(
W

msg jWt ; done(W; + 1); Xt+1 ; E )

Pr(Xt jWt; done(W; + 1); E )
+1

Pr(Wt ; done(W; + 1)jE )]
assume probability sending message distribution plan transitions obey Markov property, independent plan history
time

t,

given current plan time

t.

Thus, rst two conditional probabilities

independent previous history observations. third exactly previous belief


W

blocked:

/

X[Pr(
W

msg jWt ; done(W; + 1); Xt+1 ) Pr(Xt+1 jWt ; done(W; + 1))

bt(W; block)]

X

rst two conditional probabilities exactly parameters,

/

W





:

wx wx bt (W; block )

(1)

Lines 45 Algorithm 1 perform exactly derived summation Equation 1 (the
normalization step carried line 9 (see below). similar procedure followed
message observed indicating termination
agent executing
successor. Thus,

X

(lines 68). case, know

X previous time step moved
X 's potential successor plans , set belief








proportional transition probability, similar initiation message:

msg; Yt+1 jE )
Pr(Yt+1 jmsg; E ) = Pr(Pr(
msg jE )
denominator normalization factor ignore. expand numerator possible states

X 's

execution:

/ Pr(msg; Yt

+1

; Xt ; done(X; + 1)jE )

+ Pr(msg; Yt+1 ; :Xt ; done(X; + 1)jE )
+ Pr(msg; Yt+1 ; Xt ; :done(X; + 1)jE )
+ Pr(msg; Yt+1 ; :Xt ; :done(X; + 1)jE )
96

fiMonitoring Teams Overhearing
rst term nonzero, since others correspond states execution
inconsistent observed message:

/ Pr(msg; Yt

+1

; Xt ; done(X; + 1)jE )

rewrite joint probability product conditional probabilities:

/ Pr(msgjXt ; done(X; + 1); Yt ; E )
Pr(Yt jXt ; done(X; + 1); E )
Pr(Xt ; done(X; + 1)jE )
+1

+1

use Markovian assumptions simplify conditional probabilities,
rewrite third probability using belief state:

/ Pr(msgjXt ; done(X; + 1); Yt ) Pr(Yt jXt ; done(X; + 1))
bt (X; block)
+1

+1

Finally, rewrite rst two conditional probabilities using parameters,





/xy xy bt (X; block)

:
(2)

Lines 78 Algorithm 1 perform exactly derived summation Equation 2.

Normalization sum (line 9).

Line 9 normalizes sum recapture well-

formed probability distribution. Note normalization step must take account
fact evidence may incorporated plan steps one ancestor
anotherin case evidence ancestor plan probabilistically redundant.
specic evidence (for descendent plan) useful visualization,
accurate.

Propagation Evidence (lines 1016)

Finally, recalculated beliefs set (line

11) changes recursively propagated decomposition hierarchy
plan's children (line 12), via call Algorithm 2. addition, recalculated beliefs
propagated plan's ancestors decomposition hierarchy (lines 1316), since
evidence child plan active evidence parent active well. assume
knowledge relative likelihood child plans, treat
equally likely.

additional knowledge likelihoods, could

easily exploit Propagate-Down algorithm.

Algorithm 2 Propagate-Down(plan , probability , beliefs b, plans )
1:
2:
3:
4:
5:

fc j c 2 M; c rst child g
= j C j
plans c 2 C
bt (Y; :block )
bt (Y; :block ) + 0
C
0

+1

+1

Propagate-Down(c; 0; b; )

97

fiKaminka, Pynadath, & Tambe
3.3 Belief Update Observation
overhearing tasks, great deal uncertainty agents complete
execution plan steps, since agents necessarily send messages upon every
termination initiation plan. Therefore, messages observed time t,

+1 must calculated based possibility agents may

system's beliefs time

initiated terminated plans without sending messages. support necessary
belief update, need model plan execution provides us probability plan
termination time (i.e.,

Pr(done(X; t))).

principle, probability distribution

arbitrarily complex, structure may vary enormously domain domain,
even plan plan within domain. domains, obtaining accurate
model distribution requires complex knowledge acquisition domain experts
else complex learning process part agent. addition, accurate model
may complex support ecient online inference.
Overseer instead uses temporal model supports ecient inference

simple parameter estimation procedures. Overseer models duration (leaf ) plan,

X , exponential random variable. words, probability plan completing
time units increases 1 e X . single parameter, X , corresponds
1/(mean duration X ), easily acquire domain experts previous
execution within

runs. inference, exponential random variable Markovian property,
probability plan's completion times



Pr(done(X; + 1)jXt ) 1
independent

long agent executing



t+1



e x ;

X

time t. strong assump-

tion may fully hold real-world domains, often good approximation.
Also, error associated approximation may acceptable, given enormous
gain inferential eciency (as show remainder section).
eciency gains manifest Overseer rolls model forward
time compute belief state next time slice. Given exponential random
variable model plan duration, probability completion leaf plan constant,

1

e x ,

plan

X.

plans children, probability completion exactly

probability completion last child (according temporal ordering
children).
computed probability plan termination, Overseer evaluates
plan agent may execute next. examines possible successors and, each, computes probability taking corresponding transition, conditioned fact

1

xy ),

message observed (

prior probability taking message (xy ).

Again, mentioned Section 3.2, Overseer makes Markovian assumption
plan history time



aect likelihood various transitions. Given

assumption, combine two parameters,

98





,

get desired conditional

fiMonitoring Teams Overhearing
probability transition, given observed message:

Pr(Yt+1 jXt ; done(X; + 1); :msgt )
(X; + 1); Yt+1 ) Pr(Yt+1 jXt ; done(X; + 1))
= Pr(:msgt jXt ; done
Pr(:msgt jXt ; done(X; + 1))
(1 xy )xy
=
Pr(:msgt jXt ; done(X; + 1); Zt+1 ) Pr(Zt+1 jXt ; done(X; + 1))

X
(1
=X
(1
Z

Z

= (1

xy )xy

xz )xz

xy )xy
X

(3)

normalizing denominator,
sors,

Y,

X ,

sum numerator possible succes-

pre-compute o-line. use value

likelihood agent send message upon terminating plan
special case

X

require

X

= 0, Equation 3 well-dened,

X determine
X time t.




possible transitions

message. case, agent cannot begun execution successor,

even though completed execution

X . X

belief agent longer executing
message (i.e., blocked state).
agent executing one

X 's

therefore probability mass signifying

X

time

+ 1,

waiting

words, increased belief

immediate successors time

+ 1,

given seen

message.
Algorithm 3 presents pseudo-code process propagating probabilities
forward time message observed. First, initializes values 0 (lines
15).

process continues going plans

X

2 M,

post-order

explore

children plans (i.e., plans reachable hierarchical decomposition transitions)
parents, sibling plans order execution. plan, algorithm executes four
stages: (1) determines plan's outgoing probabilities (lines 710); (2) determines

x ,

outgoing probability mass propagated along outgoing temporal transitions
without blocked waiting message (lines 1112); (3) propagates

x

along

non-blocked temporal outgoing transitions (lines 1320); nally (4) computes
belief agent execute plan next time-tick

bt+1 (X; :block )



blocking (lines 2122). remainder section explains four stages detail.

Calculating outgoing probability outx (lines 710).

outx

Algorithm 3, variable

represents total temporal outgoing probability plan,

X,

given belief

X time t. plan X leaf, derive temporal
outx , temporal model discussed previously, given belief
agent currently executing X (lines 78). X parent, lines 910 are, fact,
redundant: serve remind reader parent, , outy follows
's children execute line 20. depends critically post-order traversal
plan-hierarchy: outgoing probability parent derived outgoing
agent executing
outgoing probability,

probabilities last hierarchical-decomposition children, thus children's outgoing
probabilities must calculated parents'.

99

fiKaminka, Pynadath, & Tambe
Algorithm 3 Propagate-Forward(beliefs b, plans )
plans X 2
bt+1 (X; :block )
0:0
bt+1 (X; block )
0:0
outx
0:0
x
0:0
plans X 2 post-order


1:
2:
3:
4:
5:
6:



7:
8:

X leaf

bt (X; :block )(1

outx

else

9:



{X parent}



{children temporal order parents}

e x ) {calculate probability X terminating time t}

outx known { post-order guarantees children set line 20}
temporal outgoing transitions Tx!y X
x
x + (1 xy )xy
x > 0 {some transition taken}
temporal outgoing transitions Tx!y X

outx (1 xy )xy
Tx!y leads successor plan
bt+1 (Y; :block )
bt+1 (Y; :block ) +
(Y; ; b; )
else {Tx!y terminating transition}
outparent(x)
outparent(x) + (1 xy )xy {parent's outgoing probability chil-

10:
11:
12:
13:
14:
15:
16:
17:

Propagate-Down

18:
19:
20:

dren's}

bt+1 (X; block )
bt+1 (X; block ) + outx x
bt+1 (X; :block )
bt+1 (X; :block ) outx

21:
22:

Determining non-blocked outgoing probability x (lines 1112).
ability,

x

sum possible values numerator Equation 3 (i.e.,

temporal outgoing transitions originating
line 21,

X;

prob-

x

X ),

illustrated derivation. see

critical calculating belief agent terminated execution

yet begun execution successor (i.e., belief

bt+1 (X; block )



agent blocking).

Propagating x along temporal outgoing transitions (lines 1320).
key component propagation. every temporal outgoing transition
seer calculates

,



Tx!y ,

Overseer's belief joint event (i) agent completed execution

agent taking transition

TX !Y ,

observable message. calculation



X,

(ii)

(iii) agent without sending



derived follows:

= Probability X done ^ message observed ^ agent chose Tx!y
= Pr(done(X; t)jXt ) Pr(:msgjXt ; done(X; t)) Pr(Yt+1 jXt ; done(X; t); :msgt )
= outx x (1 xy )xy
x
= outx (1 xy )xy
(4)

transition

's

Over-

temporary variable holds probability mass corresponding

Tx!y

future state (at time

leads successor plan



+ 1)



(lines 1618),

temporal incoming probability.



added

Since decomposition

assumed immediate, incoming probability propagated (added)

100

's

rst

fiMonitoring Teams Overhearing
children (Algorithm 2). multiple rst children, denote alternative plan
decompositions single agent, compute probability dividing
probability incoming parent among them. children rst child plans
own, distribute new incoming probability turn, using method.
next time-step algorithm propagate rst children next
child, order execution.

reason assume plans take

least single time step complete.

Tx!y

X
added X 's parent's outgoing probability outparent(x) may used propagating parent(x)'s temporal
transition

special-case termination transition (line 1920),

successors. case, outgoing temporal probability

outgoing probability along temporal outgoing transitions. Note postorder traversal plan-hierarchy guarantees children explored
parents, thus

outparent(x)

fully computed time algorithm reaches

parent(x).

Computing X 's new blocked non-blocked probabilities (lines 2122).
outgoing probability mass propagated

X 's

steps remaining involve re-calculation Overseer's belief

X 's

blocked non-

blocked states. total temporal outgoing probability (whether blocked not)
must subtracted future belief agent executing
left

outx

bt (X; :block )

x .



children siblings,

X.

outx ;



probability mass

blocking message observed Overseer

added

X 's

future blocked state.

3.4 Discussion
overhearing approach outlined section maintains separate plan-recognition
mechanism agent, ignoring inter-agent dependencies. Using array individual models (Figure 3) updated passage time, messages
observed, state team taken combination likely state
individual agent. Algorithm 4 embodies approach: called every time tick, collects
messages observed, updates state agents.
EVACUATE [TASK FORCE]

PROCESS
ORDERS
[TASK FORCE]

.....

EXECUTE
MISSION
[TASK FORCE]

PROCESS
ORDERS
[TASK FORCE]
LANDING
ZONE
MANEUVERS
[FLIGHT TEAM]

FLY-FLIGHT
PLAN
GET
ORDERS
[FLIGHT TEAM]
[GET ORDERS]
FLY-CONTROL
ROUTE....
[FLIGHT TEAM]

EVACUATE [TASK FORCE]

LANDING
ZONE
MANEUVERS
[FLIGHT TEAM]

FLY-FLIGHT
PLAN
GET
ORDERS
[FLIGHT TEAM]
[GET ORDERS]

....

FLY-CONTROL
ROUTE....
[FLIGHT TEAM]

ESCORT
TRANSPORT
OPERATIONS OPERATIONS
[ESCORT]
[TRANSPORT]

.....

EXECUTE
MISSION
[TASK FORCE]

....
ESCORT
TRANSPORT
OPERATIONS OPERATIONS
[ESCORT]
[TRANSPORT]

Figure 3: Array single-agent recognizersone agent.
illustration operation algorithm, consider example domain
evacuation scenario. Overseer begins belief agent executing top-

Process-Orders) time 0 (i.e., b0 (Evacuate; :block ) = 1:0,
b0 (P rocessOrders; :block ) = 1:0). Overseer observes message initiation
Fly-Flight-Plan one helicopters, applies Incorporate-Evidence (Algolevel plan (and rst child,

101

fiKaminka, Pynadath, & Tambe
Algorithm 4 Array-Overseer(beliefs b, plan-hierarchy
1:
2:
3:
4:
5:

Agents 2
message observed
Incorporate-Evidence(ma; b; [a])
else {No message sent }
Propogate-Forward(b; [a])

array

[],

agents

A)



rithm 1). plan-hierarchy (Figure 1b) known

Process-Orders cannot

possible current future plan agent, helicopter question executing

Fly-Flight-Plan,

i.e.,

bt (P rocessOrders; :block ) = 0, bt (F lyF lightP lan; :block ) = 1:0.
Fly-Flight-Plan's rst children,

probability mass propagated

one, thus belief child set 1.0 well.
time passes message observed, uncertainty whether

Fly-Flight-Plan

Landing-Zone-Maneuvers active, possible future
states, duration Fly-Flight-Plan uncertain. Overseer would still assign
probability 1.0 top-level plan Evacuate. However, probability mass
Fly-Flight-Plan would propagated every time-tick Landing-Zone-Maneuvers


Propagate-Forward (Algorithm 3). propagation, incoming temporal

probability mass added belief execution

Landing-Zone-Maneuvers

would propagated rst children immediately. Assuming helicopter agent
free select either

Transport-Operations



Escort-Operations,

incoming proba-

bility would split evenly added prior belief two rst children.
temporal propagation step, outgoing belief rst children would
propagated via outgoing temporal transitions.
inference procedure described Algorithms 14 exploits particular structure
representation ways general existing algorithms cannot. pseudo-code
demonstrates single monitored agent, types belief updates time
complexity

linear

M,
(M N ).

number plans transitions

agents, space time complexity Algorithm 4

i.e.,

(M ).

Thus

N

gain eciency (compared approach DBN) two sources. First,
make Markovian assumption probability observing message depends
relevant plan active, independently execution history. assumption, incorporate evidence, based beliefs time

t.

Second, make

another Markovian assumption temporal model, allowing propagation algorithm
reason forward time



+1

based beliefs time

t,

without regard

previous history.

4. Monitoring Team Overhearing
previous section outlined ecient plan-recognition mechanism particularly
suitable monitoring single agent based communications. Monitoring team
achieved monitoring member team independently others. Unfortunately,
although time complexity approach acceptable, monitoring (recognition)
results poor.

evaluation Section 6.1 provides details, but, short,

average accuracy using approach experiments

102

less 4%.

fiMonitoring Teams Overhearing
main cause low accuracy scarcity observations, one identifying
characteristics monitoring overhearing. previously discussed, agents often switch
state unobservably (i.e., without sending message). Therefore, monitoring system
critically needs estimate correctly times agents switch state.

Since

agents rarely communicate (i.e., observations them), variance
temporal behavior (with respect system's predictions) tends cause large errors
monitoring.
address issue, bring back discussion agent independence assumption
made previous section. all, team-members communicate
independently other:

Communication team action intended

change state listener (Cohen & Levesque, 1990).
message may still change state upon

receiving

Agents rarely

message.

send



words, although

observed messages used previous section update belief state
sender, could also used update state listeners.

this,

monitoring system must know relationships team-members.
Knowledge social structures enables additional sophisticated forms monitoring.
instance, order maintain social structures, team-members communicate
predictably, particular points execution task. predictions
future observable behaviorcommunicationscan used reduce uncertainty. However, often case dicult correctly predict
specic agent communicate specic point task execution, easy predict
team-member will. Knowledge procedures employed team maintain
social structures useful allows monitoring system make predictions.
reason eects communications receivers, future observable behavior team-members, monitoring system must utilize knowledge social structures social procedures used team-members maintain structures.
exploitation social knowledge monitoring called Socially-Attentive Monitoring
(Kaminka & Tambe, 2000). section discusses concepts detail.

4.1 Exploiting Social Structures
computationally cheap, approach described earlier proved insucient evacuation domain.

monitoring overhearing tasks, monitoring system must address

scarce observations, agents rarely communicate time. Indeed, evacuation application, single message observed (on average) every 20 combined
individual state changes.
challenging conditions, system monitoring overhearing must come
rely extensively ability estimate agents change internal state without sending message.

representation presented earlier used simple, ecient,

temporal model this, based estimated average duration plans. However,
found high variance actual duration plan execution, compared duration
predicted average-duration model:



Plan execution times vary depending

external environment.

instance,

agents team running local network, response times queries

103

fiKaminka, Pynadath, & Tambe
may shorter communicating across continents. Indeed, latency times
Internet vary greatly, dicult predict.



Plan execution times vary depending
instance,

traveling

plan-step executed internally.



plans, used repeatedly within given evacuation team-

oriented program, take anywhere 15 seconds almost two minutes execute,
depending particular route followed.



Plan execution times vary depending

outcome plan-step.

instance,

route-planner functioning correctly, responds within seconds. However,
crashes return answer all, agents wait
relatively long time relying time-out decide failed.

problem addressed principle expressive model execution duration,
instance taking account internal execution context. However, practice,
model would likely much expensive computationally, would need rely
knowledge previous future steps, breaking Markovian assumption (e.g.,
determine duration based

plan-step executed,

improved temporal model

would reason likelihood given instance plan-step
second instance, opposed third). applications grow scale real world,
increasingly complex temporal model would continuously rened cover
increasingly complex temporal behavior agents.

Fortunately, temporal model

one way monitoring system estimate times agents change
internal state unobservedly.
alternative method estimating unobserved state changes utilize known dependencies agents exploit evidence state one agent infer state
another. particular, often true team settings one agent would send message

intending

aect state receivers particular way. Thus principle,

assumption receivers change state predictably, observation
message used evidence inference sender's state, well
receivers', i.e., state team-members. trade agent independence assumption made earlier assumption successful coordination. reasonable
assumption team settings, given agents actively attempting maintain
teamwork communications (Tambe, 1997; Kumar et

al., 2000; Dunin-Keplicz &

Verbrugge, 2001).
eects message receiver dependent relationship
sender receiver (where take relationship described mathematical
relation possible states sender receiver). principle, relationships underly

social structures structures interactions agents make

decisions one team-member dependent, predictable degree, teammates. Using knowledge dependencies, monitoring agent may use observations
communication action agent infer possible state another.
One simple example structure common many teams (e.g., Jennings, 1993;
Kinny, Ljungberg, Rao, Sonenberg, Tidhar, & Werner, 1992), indeed present also
application:

roles

govern team-members undertake tasks service

104

fiMonitoring Teams Overhearing
team goal. roles ideally bias decision mechanism team-members towards making decisions appropriate roles. Thus knowledge roles
team-members useful counter uncertainty faced monitoring agent.
instance, suppose monitoring agent knows evacuation application, particular team-member choose

Landing-Zone-Maneuvers

Transport-Ops,

rather

Escort-Ops,

child

(because team-member belongs TRANSPORT team,

rather ESCORT team). knowledge reduce uncertainty monitoring agent hasunder assumption team-member incorrectly choose

inappropriate

plan role. Overseer fact uses knowledge roles manner

alleviate uncertainty. monitoring use role information used previous
work (Tambe, 1996; Intille & Bobick, 1999), discussed Section 7.
However, much important social structure exists teams. Agents teams work

together, team-member ideally agreement

joint goals plans (Cohen

& Levesque, 1991; Levesque, Cohen, & Nunes, 1990; Jennings, 1995; Grosz & Kraus, 1996,
1999; Tambe, 1997; Rich & Sidner, 1997; Lesh, Rich, & Sidner, 1999; Kumar & Cohen,
2000; Kumar et al., 2000). phenomenonsometimes called

team coherence

(Kaminka

& Tambe, 2000)holds dierent levels team. Agents atomic subteam work
together plans selected subteam, subteams work together sibling subteams
higher level joint plans, etc. Individual agents may still choose execution,
service agreed-upon joint plans. Provided monitoring agent knows
plans jointly executed subteams, transitions taken
together subteams, use coherence heuristic, preferring hypotheses
team-members agreement joint plans, hypotheses
disagreement.
example, suppose entire team known executing

Fly-Flight-Plan

(Figure 1-b). Now, message one member TRANSPORT subteam observed,
indicating begun execution

Transport-Ops plan step.

Since plan step

jointly executed members TRANSPORT subteam (and them),
use coherence prefer hypothesis subteam members also

Transport-Ops. Furthermore, since plan-step service
Landing-Zone-Maneuvers plan, jointly executed TRANSPORT
initiated execution

ESCORT subteams, prefer coherent hypothesis team-members ESCORT
executing

Landing-Zone-Maneuvers.

Now, based known role, come

back plan-hierarchy infer members ESCORT subteam executing

Escort-Ops,

etc.

knowledge expected relationships, particular knowledge plans
joint team-members (i.e., subject coherence), part specication
distributed applicationand thus provided overhearing system designer
operator. fact, often readily available, since used agents
coordination.

instance, earlier discussed assumption team-

oriented programs available monitoring agent, hold knowledge
plans hierarchy executed (sub)teams encoded
plan-hierarchy. team hierarchy contains knowledge subteam/agent
part another subteam.

105

fiKaminka, Pynadath, & Tambe
Coherence powerful heuristic. assumes non-failing cases, teammembers successfully maintain joint execution particular plans. assumption, evidence decision made one team-member inuences (through coherence),
belief team-mates decided. lacking evidence, coherence prefers
hypotheses least team-members made joint decisions. instance, suppose transition team plan taken TRANSPORT team.
non-failure circumstances, two coherent hypotheses considering transition: Either members TRANSPORT took transition, none did. Evidence
one member, supporting one hypotheses, used infer state
members.
signicance property coherence monitoring system reduce
uncertainty even one agent, reduction amplied use
coherence heuristic apply agents well.

use coherence

heuristic thus lead signicant boost monitoring accuracy, since number
hypotheses underlying (probabilistic) disambiguation cut dramatically.
Section 6.1 provides in-depth evaluation use coherence knowledge roles
select plan recognition hypotheses Overseer.
use coherence signicantly increases time complexity computation.
least, requires setting inter-agent links array plan recognizers used
Overseer (Section 3.4), links represent probabilistic association plans executed jointly (in contrast temporal hierarchic
decomposition transitions used thus far). instance, specic plan
jointly agents



(representing agent



A's

B,

N

N

execution plan

X)

variable

(M N 2 )

N (N
2

XtB

1)

(representing

M,

XtA
agent B 's

inter-agent links be-

agents, one joint plans (of

agents, array recognizers

size

executed

link would constructed variable

execution plan). general, would
tween

X

[],

).

Thus given

individual agent's plan-hierarchy

run-time complexity exact-inference algorithm would least

quite likely much worse (since general exponential number

coherent non-coherent hypotheses select from).

next section (Section 5.1),

describe highly scalable (in number agents) representation reasoning
coherent hypotheses.

4.2 Exploiting Procedures Maintain Social Structures
monitoring system exploit knowledge procedures agents use maintain
social structures alleviate uncertainty resulting scarceness observations. instance, monitoring system could accurately predict

future observable

behavior monitored agents, observed predicted behavior,
monitoring system may infer agents reached state associated
predicted behavior. Thus predictions used eliminate monitoring hypotheses,
setting individual agent's

XY

probabilities reect prediction message

transmitted agent execution

X

terminates initiates

Y.

instance,

application, Ariadne information agent queried possible threats
route followed evacuation. may therefore possible predict

106

fiMonitoring Teams Overhearing
route taken helicopters, message sent Ariadne agent
teammates; thus message observed, Ariadne agent inferred
yet executed step. Furthermore, assumption coherence (discussed
above), monitoring system may infer team-members yet executed step, i.e., new route taken team.

inference obviously

dependent system's observational capabilities, found useful even
lossy observations monitoring system (see Section 6.2).
However, general, specic individual predictions dicult make. Teammembers often engaged joint tasks, require many agents tackle problem
together. settings, predicting individual communications may impossible.
instance, consider distributed search problem target solution found
somewhere search-space; dierent areas search space divided amongst
agents, understanding rst nd target communicate
others. would dicult accurately predict one agents communicate
(nd target), since could predict that, could focus agents' eorts area
alone. Yet easy predict least one agent nd target communicate.
Similarly, evacuation application, may dicult predict helicopter
reach civilians rstbut easy predict one will,
communicate location.
Indeed, teams utilize

social procedures



conventions

(Jennings, 1993) team-

members maintain relationships one another. Removal agent independence
assumption allows monitoring system exploit knowledge procedures, making predictions behavior team-members coordinating one another.
instance, knowledge failure-recovery procedures used team recover coordination failures allows monitoring system predict future behavior team-members
case failed execution. Similarly, knowledge communication procedures used
team (as part team-members' coordination) allows predicting future observable
messagesfuture interactions team-memberswithout necessarily specifying particular individual agent carry out.
example, suppose Overseer overhears message indicating ight team

Fly-Flight-Plan (Figure 1-b). time passed,
possible team either still executing Fly-Flight-Plan, terminated
already begun joint execution Landing-Zone-Maneuvers. However, Overinitiated joint execution

seer knows least one team-member explicitly communicate terminating

Fly-Flight-Plan initiating Landing-Zone-Maneuvers, communications observed, monitoring system eliminate possibility team
executing latter, eliminating uncertainty case (only

Fly-Flight-Plan



possible).
leave discussion technically social procedure form least one teammember communicate subteam take transition
converted
team-wide



XY

X







values next section, present technique representing

probabilities way allows ecient reasoning. remainder

section, address instead knowledge social procedures may acquired.
Social procedures communications may simple per-case rules, may involve
complex algorithms.

instance, Jennings (1993) suggests using heuristic application-

107

fiKaminka, Pynadath, & Tambe
dependent rules determine communication decisions.

STEAM (Tambe, 1997) instead

uses decision-theoretic procedure considers cost communication cost
miscoordination decision communicate. procedures proposed
well (e.g., Cohen & Levesque, 1991; Jennings, 1995; Rich & Sidner, 1997).

However,

regardless complexity, key point monitoring system necessarily
full knowledge procedures order exploit predictions:
needs approximate outcome, since use combination techniques
combat plan-recognition ambiguity, rather relying one technique.
decisions social procedures acquired learning previous runs
system.

Although detailed exploration appropriate learning mechanisms out-

side scope paper, provide strict demonstration feasibility learning
social procedures simple rote-learning, proved eective generating useful communications model signicantly reduced uncertainty monitoring evacuation
application.

simple mechanism records execution plans explicitly

communicated about, whether initiated terminated. learned rules
eective immediately, stored future monitoring task.
Figures 4ad present results using rote-learning mechanism four
dierent runs tasks.

X-axis denotes observed communication message-

exchanges task progresses.

Overall, 22 45 exchanges take place

run, exchange including one dozen broadcast messages agents
announce termination initiation plan. Y-axis shows number hypotheses
considered Overseer seeing message, without using probabilistic temporal
knowledge. Thus greater uncertainty hypothesis correct would reected
higher values Y-axis. beginning task execution, possible plans
considered possible, since ignore temporal knowledge graph. progress made
task, less less steps remain possible end reached, expect
see gradual (non-monotonic) decline move along X-axis. technique
successfully eliminates hypotheses considerations results Y-axis values

lower



baseline execution curve.
Figure 4, line marked

Learning

shows baseline (i.e., predictions,

learning component turned ). baseline shows relatively high level
ambiguity exists, since system cannot make predictions future states
agents, possible. learning technique applied on-line
(i.e., message seen immediately used future predictions), learned experience
immediately useful, ambiguity reduced somewhat (the line marked

On-Line Learning ).

However, exchanges either encountered late task execution, seen
once. cannot eectively used reduce ambiguity monitoring system
rst run. However, third line (

Learning )

presents number hypotheses

considered fully-learned model used. Here, model learned run G,
applied without modications runs system. seen, shows
signicantly reduction number hypotheses considered Overseer.



evaluation use communications predictions presented Sections 6.1 6.2;
however, full exploration use learning task beyond scope
paper.

108

fiMonitoring Teams Overhearing

25

learning
On-line learning
Using previously learned predictions

20

Number Recognized Plans

Number Recognized Plans

25

15
10
5
0

learning
On-line learning
Using previously learned predictions

20
15
10
5
0

0

5

10
15
20
25
30
35
Observed Communication Exchanges

40

45

0

5

(a) Learning experiment C

25

learning
On-line learning
Using previously learned predictions

20

40

45

40

45

(b) Experiment E

Number Recognized Plans

Number Recognized Plans

25

10
15
20
25
30
35
Observed Communication Exchanges

15
10
5
0

learning
On-line learning
Using previously learned predictions

20
15
10
5
0

0

5

10
15
20
25
30
35
Observed Communication Exchanges

40

45

0

(c) Experiment G

5

10
15
20
25
30
35
Observed Communication Exchanges

(d) Experiment

Figure 4: Learning communication decisions dierent experiments.

109

fiKaminka, Pynadath, & Tambe
4.3 Discussion
key characteristic monitoring overhearing tasks scarcity observations available monitoring system.

Fortunately, observations available monitoring

system often viewed observations

multi-agent actions :

sender message

changes state, often also intends change state recipients
(Cohen & Levesque, 1990).

Thus even single observation used evidence

inferring state sender receivers. stands contrast previous work,
addressed monitoring multiple

single-agent

actions.

monitoring team, monitoring system use knowledge social structures
procedures exploit information activities one team-member, hypothesizing activities another team-member. techniques specic
representation presented earlier. instance, increased belief one agent's execution
plan

X

based evidence teammate's execution

X

also used con-

structing appropriate probabilistic links nodes representing beliefs large
DBN representing two agents. start DBN representation discussed
Section 3.1, replicate single-agent network (containing

N

separate agents. number nodes

(M N ),
2



plans)

since represent plans

transitions individual agent. also introduce appropriate inter-agent links
capture inter-agent dependencies represented model teamwork. However,
upon introducing links, computational complexity performing DBN inference
2N .
explodes

(2

)

Obviously, social reasoning computationally expensive, even efcient representation described earlier.

next section provides details ecient

mechanism reasoning team using information role coherence, utilizing communications predictions. Using mechanism, techniques described
section resulted accuracy 97% (84% average across experiments)
compared average 4% without use social knowledge. Sections 6.1 6.2 present
detailed discussion results.

5. Plan-Recognition Overhearing
previous section outlined socially-attentive monitoring techniques, alleviating
uncertainty monitoring team agents exploiting knowledge social structures
social procedures monitored team. discussed using

nance

coherence



role mainte-

exploit knowledge ideal agreement agents specic plans executed

together, specic plans assigned agents fullling roles. Furthermore, discussed disambiguation based predictions future observable behavior, based
knowledge social procedures employed team-members. disambiguation
heuristics eliminate many (incorrect) hypotheses considered. However, reasoning
using techniques computationally expensive.
section presents ecient algorithm, building representation previously
presented, facilitates scalable monitoring overhearing large teams. key idea
represent hypotheses heuristics would considered valid,
eliminating consideration plans transitions would considered illegal
heuristics. Relying team-hierarchy bookeeping, coherent hypotheses

110

fiMonitoring Teams Overhearing
represented using single recognizer instead array recognizers, oering considerable
scalability team monitoring. However, since algorithm longer represent certain
hypotheses, scalability comes expense expressivity.

discuss scalable

representation trade-o oers below.

5.1 Ecient Reasoning Team Coherence
Coherence strong constraint, since team agents linear
number (O

(M )

size plan-hierarchy) coherent hypotheses,

exponential number incoherent hypotheses (O

(M N ) N number agents;

proof Appendix A). exploit property designing monitoring algorithms
reason linear number coherent hypotheses, therefore oer better
scalability number agents increases. algorithms may able reason
incoherent hypotheses, therefore less expressive. However, Section 6 demonstrates level accuracy even limited expressiveness sucient
purposes.

Furthermore, algorithms reason coherent hypotheses may still

able detect incoherent hypotheses, representing failure state two
team-members disagreement other.
begin presenting YOYO* algorithm, ecient technique reasoning
coherent hypotheses (Algorithm 5). YOYO* replaces array-based algorithm described
earlier (Algorithm 4). Similarly it, YOYO* called every time tick.

message

observed, state entire team propagated forward time. Otherwise, observed
messages collected together used evidence (dierent) plans implied
messages.
YOYO*'s key novelty relies

single

plan-hierarchy used represent

team-members together (regardless number), instead array structures. words, variable
teams associated

X

time

t.

X

Xt

represents Overseer's belief

agents



(as described team-oriented program) executing plan

Thus YOYO* makes extensive use information associating plans

transitions



teams subteams

H,

team-hierarchy. team hierarchy

plays critical bookeeping role respect, since maintains knowledge critical
correctly applying coherence single recognizer.
key distinction YOYO* array-based approach causes subtle,
critical, dierence way probabilities propagated along transitions. planhierarchy



individual agent, part array models, outgoing transition

represented hierarchical decomposition temporal step agent allowed take.
Alternative outgoing transitions therefore represent alternative paths execution available
agent.

hand, plan-hierarchy



used YOYO*, alternative

outgoing transitions tagged dierent subteams (that ancestors one another)
represent decision point agent, alternative paths execution decided
agents' roles team-memberships.
creates critical dierence values
previously (in Section 3) value
agent take transition

X

!



xy

XY



XY

interpreted.

referred probability specic

(given terminated execution

YOYO* refers probability entire team take transition

111

X ),



together.

fiKaminka, Pynadath, & Tambe

Algorithm 5 YOYO*(plan-hierarchy , team-hierarchy H , beliefs b)
1:
2:
3:
4:
5:
6:
7:

8:
9:
10:
11:
12:
13:
14:



new messages observed

Team-Propagate-Forward(b, )

else

Initialize distributions b0 ; bt+1 0 plans U 2 . ; Initialize I; E empty sets.
Messages mi

[ fX j X 2 M; mi initiation message; X consistent mi g
E
E [ fY j 2 M; mi termination message; consistent mi g
plans X 2
teammsg (X ) {T agent sending message initiating X }
plans W 2 precede X , transition W ! X allowed
b0 (X; :block )
b0 (X; :block ) + bt (W; block )wx wx
plans X 2 E

teamm sg (X ) {T agent sending message terminating X }
plans 2 M; 2
= succeed X , transition X ! allowed







15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:

b0 (Y; :block )

b0 (X; :block ) + bt (X; block )xy xy
Normalize distribution b0 taking teams account
plans X b0 (X; :block ) > 0
bt+1 (X; :block )
b0 (X; :block )
(X; b0 (X; :block ); b; )

team(X )
P
X
parent(P ) 6= null
bt+1 (parent(P ); :block )
bt+1 (P; :block )
team(parent(P )) = parentteam (T )
(parent(P ); T; P; b)
= parentteam (T )
P
parent(P )

Team-Propagate-Down

Scale

112

fiMonitoring Teams Overhearing
YOYO* unable represent hypotheses team-members take one transition,
others notunless two dierent groups members form dierent subteams
represented team-hierarchy, dierent transitions tagged
allowed dierent subteams.
value

XY

also interpreted dierently, critical way.



previous sections taken represent probability specic individual
communicate transition
probability

X

!Y

taken, YOYO* value represents instead

one team-members communicate

transition

taken team. Thus longer refers individual agents, (sub-)team.
way, YOYO* solves issue represent predictions type least one
team-member communicate step reached, discussed previously.


example,

suppose

Landing-Zone-Maneuvers

YOYO*

sets



belief







executing



p. Landing-Zone-Maneuvers,
Escort-Ops Transport-Ops, executed mem-

plan-step probability

YOYO*, two (rst) children:

bers th ESCORT TRANSPORT subteams, respectively.
agent case, probability

team

p

Unlike individual

divided among two children,

duplicated them: belief entire team executing

Landing-Zone-Maneuvers
Transport-Ops,

implies equally-likely belief TRANSPORT subteam executing
ESCORT subteam executing

Escort-Ops.

explain YOYO*'s operation

detail below:

message observed (lines 12).

Since observations available, state

entire team jointly propagated forward time calling Team-Propagate-forward
(Algorithm 7, Appendix A). slightly modied version propagate-forward
(Algorithm 3) takes dierent subteams account propagating beliefs: Given
total outgoing probability (either sibling child transition), outgoing transitions
taken dierent teams one team ancestor another (such
TRANSPORT ESCORT sub-teams), total probability would used
transition, instead splitting outgoing probability transitions. Appropriately, Team-Propagate-forward relies modied version PropagateDown algorithm (Algorithm 2), called Team-Propagate-Down (Algorithm 6, Appendix

A).

latter algorithm also used incorporation evidence (lines 327).

run-time complexity propagation process

(M ).

One messages observed (lines 37).



one messages ob-

served (since YOYO* single algorithm monitoring multiple potential message senders,
one message may observed once), YOYO* begins incorporate observations maintained beliefs team. process somewhat similar
Incorporate-Evidence algorithm, described earlier (Algorithm 1), takes account multiple observations (since

N

agents may sent message). Multiple messages

(from dierent agents) may refer plan, YOYO* must incorporate
evidence multiple times.
simple loop (lines 57) builds set



(of initialized plans)

plans) going incoming messages arrived time
complexity process (in worst case)

113

(N ).

E
t.

(of terminated
run-time

Here, YOYO* better

fiKaminka, Pynadath, & Tambe
array approach, since multiple messages always cause multiple updates array,
YOYO*, multiple messages may refer single plan, thus triggering single update.

Incorporating evidence initiated terminated plans (lines 815).
one plans
prior belief

X





(line 8), YOYO* sets new belief

b0 ,



weighted

X 's initiation (lines 1011), similarly done incorporate-

evidence algorithm (Algorithm 1), taking account team implied sender

processed message (line 9).
(teammsg

done lookup



using sender

(mi )): transitions allowed take followed.

transition allowed taken super-team





denition,

allowed

T.

similar

process done termination messages (lines 1215), course looking
possible successors plans consistent messages.

However, since

want cause updates line 11 line 15 cases termination message
initiation message refer transition, loop plans



(line 14) skips

plans already addressed previous step. Overall, run-time
complexity process

(M ).

Normalizing temporary distribution b0 (line 16).
b0

temporary distribution

resulting processing initiation termination messages normalized,

similar fashion analogous step algorithm 1. However, process must take
account plan-hierarchy question, also team-hierarchy. Unlike typical
normalization procedure, evidence two dierent plans, selected two dierent teams,
may necessarily compete other, therefore may necessarily require
normalization. instance, two messages observed, one implying team





P , another implying team B initiated execution
Q children joint parent J (executed jointly
normalized likelihood (1.0) assigned P

initiated execution plan
plan

Q,



(and



A; B ),
J

two subteams

Q

P

assigned propagation steps described below).

run-time complexity process

(M ) .

Propagating evidence (lines 1727).

First, beliefs set

plan implied observations, children (lines 1819). Then, team
execute plan determined lookup



using

team(X )



(line 20).

YOYO* begins propagate evidence plan's parents (lines 2126). belief
child plan propagated added belief parent (line 23).

However,

(P )) executed super-team current team ,

parent plan (parent

change probability must propagated children,
executed (subteams). Thus upward propagation alternated downward

1

propagation along hierarchical decomposition transitions . downward step executed
whenever team responsible joint execution parent plan longer
current subteam considered (T ), parent team team-hierarchy
given

parentteam (T )

H,

(lines 2426). condition satised, change

beliefs parent plan must propagated children
executed subteams. done via Scale algorithm (Algorithm 8, Appendix
A).
1. alternating upward-downward propagation origin YOYO*'s name.

114

fiMonitoring Teams Overhearing
downward propagation (line 25) implements subtle critical step: re-aligns
beliefs YOYO* maintains subteams implied message
beliefs made coherent existing evidence. Scale procedure,
re-distributes new state probability parent among children, child
gets scaled based relative weight parent.

end result state

probabilities children made sum state probability parent.
process recursive, never re-visits subtree, since carried hierarchicaldecomposition transitions previously updated.
downward propagation done, YOYO* updates current team

parentteam

parent team-hierarchy, line 26. Note call
team-hierarchy

H,

rather plan-hierarchy

M.

downward propagation took place, temporary variable
hierarchical decomposition



(line 27).

iteration loop begun line 17

reects lookup

Finally, regardless whether

P

(M

updated climb

+ H ) since worst case

plan-hierarchy team-hierarchy traversed. However, loop many repeat
(in worst case) plans plan-hierarchy, thus overall, run-time
complexity process

(M (M

example run YOYO*.

+ H )) = O(M 2 + H ).

following example illustrates YOYO*'s inference

upon observation message. Suppose single member TRANSPORT subteam
communicates initiating

Transport-Ops

plan. Upon observing message,

YOYO* looks sender, determine transitions taken (line 8).
proceeds determine new beliefs team

's execution Transport-Ops plan (lines

910, 16), incorporates new beliefs reect much increased belief

Transport-Ops children (lines 1819). Since
Landing-Zone-Maneuvers, null, YOYO* enters loop lines

TRANSPORT subteam executing
plan's parent,

2227. First, increases belief execution parent (line 23). Then, checks
condition line 24: Indeed, team execute

Landing-Zone-Maneuvers
Landing-Zone-Maneuvers

TEAM-FLY-OUT, parent TRANSPORT subteam (i.e.,

executed jointly TRANSPORT ESCORT subteams).
fore calls Scale procedure (line 25) re-adjust
children subtrees.

Transport-Ops

Landing-Zone-Maneuvers

YOYO* there-

Landing-Zone-Maneuvers'



two hierarchical-decomposition children:

(which YOYO* already updated) executed

Escort-Ops, executed ESCORT subteam.
Landing-Zone-Maneuvers Escort-Ops, increasing YOYO*'s
team executing Escort-Ops plan. process re-aligns
likelihood Escort-Ops executed

TRANSPORT subteam,
Scale climbs





beliefs ESCORT
prior beliefs YOYO*

current evidence, eect updating beliefs plans executed ESCORT
subteam, based single observation made member TRANSPORT team.
process repeats loop entire set beliefs updated aligned
respect observed message.

5.2 Scalability Number Agents
YOYO* oers signicant computational advantages compared individual representation (array) approach. YOYO* requires

115

single, fully-expanded plan-hierarchy

fiKaminka, Pynadath, & Tambe
represent entire team.

hierarchy

union

individual agent plan-

hierarchies, containing transitions plans, tagged subteams allowed
execute them.



addition YOYO* uses single copy team hierarchy.

size plan-hierarchy,

H

size team-hierarchy,

N

Suppose

number

agents team. agents added monitored team, team hierarchy
grows one new node represents new agent, connected appropriate

+ H ). Since
grows N , could write (M + N ) (compare array approach: (M N ),

sub-team team hierarchy. YOYO*'s space complexity therefore

H

(M

Algorithm 4).
analyze YOYO*'s run-time complexity, consider behavior Algorithm
5 separately cases communications observed, cases least
one message observed.

messages observed, update takes form

single call Team-Propagate-Forward (Algorithm 7),

(M )

process.



clearly best-case scenario YOYO*. one agent communicates, YOYO* would
go

(M





+ H ) = O(M + N ).

H

upward-downward propagation process once, thus

worst case scenario YOYO* occurs agents send messages, one


N

messages refers dierent plan (messages plans would merged

lines 57). case, would



dierent plans evidence exists,

one would require separate update lines 1727. Thus YOYO*'s
run-time complexity case

(N

+ + + (M + H )) = O(N + 2 + H ) = O(N + 2 + N )

Clearly, worst-case cannot continuously sustained monitored team, since agents
cannot continuously communicate state. thus believe average case
real-world domains

many

agents would much closer

(M

+ N)

case

presented earlier (see Section 6.4 empiric evaluation). case, YOYO*'s complexity
compares favorably procedure reasoning coherent hypotheses using array
recognizers,

(M N 2 )

process (at least), even one agent communicates (Section

4.1).

5.3 Discussion
YOYO* explicitly represents team single coherent entity. space run-time requirements preferable array based approach number agents grow,
considerably simplies reasoning coherence communications predictions.
hand, YOYO* sacrices capability represent failing team activities (incoherent hypotheses), one team-member executing one team-plan teammate
executing another.





mean individual actions taken agents

somehow locked together synchronous execution, individual agents must
execute individual action time. instance, two team-members

A; B

executing completely dierent path execution time (i.e., plan
steps

A1 ; :::; Ak



overall joint plan

B1 ; :::; Bl ) easily represented plan hierarchy includes
J , two rst hierarchical decomposition children, A1 B1 ,

116

fiMonitoring Teams Overhearing
selected

B , respectively. A1 would outgoing temporal transition A2 ,
B1 would outgoing temporal transition B2 , etc. Since J

etc. similarly

executed two team-members jointly, initial evidence one agent
executing individual plans would used YOYO* evidence
team-member begun parallel execution individual execution path.
evidence one agent executing individual actions would increase
likelihood agent continuing execution, pace. However,
would impossible YOYO* correctly represent monitoring hypothesis




executing child

J.

J , Ai ,



B

executing plan

J,

child

Given results evaluation conducted (Section 6), demonstrated

importance coherence accurate visualization, tradeo expressivity vs. scalability
justied: Overseer's accuracy much improved due use coherence.

Although YOYO* sacrices capability reason certain failure (incoherence)
hypotheses, still capable supporting failure-detection, important secondary goal
visualization. earlier work, shown merits coherence service detecting
disagreements team, particular demonstrating coherent monitoring leads
sound centralized disagreement detection, may lead sound complete disagreement
detection specic circumstances (Kaminka & Tambe, 2000). YOYO* fact
ecient way reason coherent hypotheses, provides good basis providing
sound disagreement detection results.

concern generality technique may raised based YOYO*'s reliance team-hierarchy.

However, believe reasonable expect large,

complex, real-world multi-agent systems type targeted paper would
organizational hierarchy sort associated (see, instance,

Tidhar,

1993b). Human organizations certainly demonstrate emergence hierarchies, especially organizations grow larger (e.g., big corporations, government organizations)
tackle mission-critical tasks (e.g., military organizations). addition, team-hierarchies
computational agents critical planning, maintaining network system security, etc. Thus believe use team-hierarchy weakness approach,
organizational structures become wide-spread computational multi-agent systems
already human multi-agent systems. Indeed, may possible gradually
learn team-hierarchy given coordinated team purpose monitoring; however,
discussion possibility outside scope paper.

Indeed, using team-hierarchy, apply assumption coherence representations algorithms well. instance, start DBN representation
team Section 4.3, unify multiple random variables used represent separate agents single random variable overall team/subteam.
YOYO*, size representation grows size plan hierarchy,
number agents. Thus, number nodes single-agent
case,

(M 2 ),

discussed Section 3.1.

However, again, complexity inference
2
.

answering plan-recognition queries still exponential number nodes,

117

(2 )

fiKaminka, Pynadath, & Tambe
6. Evaluation
section presents detailed evaluation dierent contributions contained within
Overseer. begin exploring relative contribution technique success

Overseer whole (Section 6.1).

focus evaluating Overseer's use

communications predictions respect lossless lossy observations (Section 6.2).
present comparison Overseer's performance human experts
non-experts (Section 6.3). Finally, empirically evaluate YOYO*'s scalability
application domain (Section 6.4).

6.1 Accuracy Evaluation
rst part evaluation tests contribution dierent techniques Overseer successful recognition correct state team-members. Figure 5 com-

pares average accuracy sample actual runs, marked J (X-axis).
1020-minute run, team executed task completely. dierent points
execution,

actual

state system compared state

predicted

Overseer, prediction taken current most-likely hypothesis.
run 2245 comparisons (data-points). percentage correct monitoring
hypotheses run across comparisons given 0-1 (0-100%) range,
Y-axis.
1
0.9

Temporal

Average Accuracy

0.8

Coherent
Coherent,
Temporal

0.7
0.6
0.5

Coherent, Comm

0.4

Coherent,
Temporal, Comm

0.3
0.2
0.1
0


B

C



E

F

G

H



J

Evaluation Run
Figure 5: Percent accuracy sample runs.

accuracy using individual models coherence (as Section 3)
presented leftmost bar (marked

Temporal )

group (Figure 5), clearly

low. approach straightforward attempt monitoring multiple agents monitoring individual, without considering interactions them, described
Section 3.

next bar presents monitoring accuracy coherence used

rule hypotheses (Section 5.1), ties broken randomly. next bar right

Coherent, Temporal ) presents results combining coherence probabilistic
temporal model (Sections 3 5.1). Then, bar marked (Coherent, Comm ) shows
(

eects combining use coherence use predictions based knowledge

118

fiMonitoring Teams Overhearing
communication procedures used team (Section 4.2). Here, communications
predictions used restrict set coherent hypotheses considered, ties bro-

Coherence, Temporal, Comm )

ken randomly. remaining bar (

presents monitoring

accuracy run using combination techniques.
results presented Figure 5 demonstrate eectiveness socially-attentive
monitoring techniques presented.

First, results show coherence heuristic

brings accuracy 1530% without using probabilistic reasoning. boost
performance particularly interesting result, relation coherence
technique previous techniques explored literature (Tambe, 1996; Intille & Bobick,
1999). Previous work successfully used relationships agents increase
accuracy monitoring. boost Overseer's accuracy based use role
teamwork relationships conrms results previous investigations.

However,

results also demonstrate technique sucient domain.
Overseer adds number novel techniques addressed previous work.



Coherent,

rst technique combines coherence temporal model plan-duration (

Temporal ),

results signicant increases accuracy, probabilistic

temporal information allows Overseer better handle lack observations.
possible alternative, explore evaluation, rely instead communications predictions rule hypotheses future states may may

Coherent, Comm ).

reached (

therefore interesting compare performance

Coherent, Temporal ) (Coherent, Comm ) bars.

two techniques comparing (

almost runs average accuracy using coherence communications predictions signicantly higher using coherence temporal model.
despite fact eective coherence technique uses arbitrary (random) selection
among available hypotheses: reason many cases communication predictions powerful enough rule hypotheses one two, signicantly
decreasing uncertainty agents' plan-horizons. Thus even random selection stands
better chance informed (by temporal model) selection among many
(1020) hypotheses.
However, runs J B show reversal trend compared runs. Figures
6ab show accumulative number errors task execution progresses run
(Figure 6-a) run J (Figure 6-b). error dened failure choose
correct hypothesis likely one (i.e., likely hypothesis reect
true state agent/team). message exchange corresponds one dozen
messages communicated agents, establishing terminating plan. two gures,
lower slope means better performance (less errors). line marked

Coherent

shows

accumulative number errors coherence used select correct hypothesis
choices turn erroneous since random choice made among
competing hypotheses. line marked

Coherent, Temporal

shows results using

coherence temporal model choose likely hypothesis. Similarly, line
marked

Coherent, Comm

shows results using coherence communications

predictions. Finally, remaining line displays results using combined technique,
using coherence, temporal model, communications predictions.
Figure 6-a, see two techniques (

Coherent, Temporal Coherent, Comm )

almost equal slopes result almost equal number errors end run I,

119

fi

7HPSRUDO



&RKHUHQW

























&RKHUHQW

&RKHUHQW




2EVHUYHG 0HVVDJH ([FKDQJHV

7HPSRUDO
&RPP










7HPSRUDO

&RPP



&RKHUHQW

&RKHUHQW
















&RPP



&RKHUHQW

&RKHUHQW









$FFXPXODWLYH (UURUV

&RKHUHQW








$FFXPXODWLYH (UURUV

Kaminka, Pynadath, & Tambe

7HPSRUDO
&RPP

2EVHUYHG 0HVVDJH ([FKDQJHV

(a) Run

(b) Run J

Figure 6: Accumulative number errors runs J.

though Figure 5 know due alleviated uncertainty, use communications predictions leads overall higher probability success (i.e.,

Coherent, Comm

technique results fewer alternative hypotheses, thus better chance correct). However, Figure 6-b see run J situation changed dramatically.
First, see two lines longer similar. line marked

Coherent, Comm



greater slope run I, indicating communications predictions able
reduce uncertainty, resulting lower average accuracy. Second, see temporal model results many less errors, evidenced much slower-rising slope
line marked

Coherent, Temporal.

Thus case, actual duration plans matched

temporal model accurately runs.
trying understand dierence runs J, B runs
system, discovered runs J B involved relatively failures part
team-members, including agents crashing responding all.

communications

predictions, however, learned based successful runsand thus correctly
predict communication messages would result team detected recovered
failures. Thus uncertainty alleviated, arbitrary selection
made among relatively many hypotheses. explains relatively lower accuracy
(

Coherent, Comm)

technique run J B. clearly shows limitation simple

learning approach took, intend address future work.

However,

factors inuence accuracy communication models, since lower
accuracy occur runs failures occurred.
results

Coherent, Temporal

technique vary well.

able

determine failures cause relative increase relative accuracy

Temporal

Coherent,

technique. However, variance results due additional factors. run C,

instance, technique results relatively higher accuracy, failure occurred.
Certainly, mission specications dier runs, machine loads cause
mission execution run slower faster, etc. great variance temporal behavior
system principal reason using communication prediction.
variance obvious graphs.

120



fiMonitoring Teams Overhearing
summary, despite variance results

Coherent, Temporal

technique (due

variance temporal behavior system simplicity temporal model),
possible sensitivity

Coherent, Comm

technique learned predictions,

clear two techniques work well combination, building coherence heuristic,
compensating other's weaknesses. runs, combined technique

Temporal, Comm

Coherent,

superior either technique alone. performance varied

72% accuracy (Run E) 97% (Run I). average accuracy across runs allcombination technique 84%, resulting signicant increases accuracy compared
initial solution began investigation (less 4%), human
novice performance (see Section 6.3).

Thus communications predictions need

perfect, temporal knowledge need precise, order useful.

6.2 Evaluating Use Communications Predictions
One key question use communications predictions sensitivity loss
observations. ecacy technique (see Figure 5) stems capability make
inferences based expected

future

observation. predictions used previous

section assumed observation loss, i.e., prediction stated particular message
observed, probability assigned prediction 1.0. settings
involving lossy observation streams, inference prove incorrect, Overseer
wait observation therefore correctly monitor actual state teammembers.
evaluate predictions' sensitivity observation loss, chose three experimental runs, E, I, J, represent extreme performance results Overseer:
Run E lowest accuracy (72%), Run highest (97%), run J showed
interesting reverse relative performance
(see Figure 5).

Coherent, Temporal



Coherent, Comm

runs, simulated observation loss rate 10%,

repeating trial three times dierent random seeds. words, ran total
9 trials, random 10% messages observed Overseer
observable Overseer (though still reached evacuation team-members
team-performance identical original settings).

set predictions

appropriately use 90%10% settings: expected message predicted appear
0.9 probability (as opposed 1.0 probability originally).
results experiments presented Figure 7. three dierent
runs, two bars presented. left (shaded) bar shows original results presented
previous section (i.e., observation loss, treatment possible loss
predictions). right bar shows average accuracy achieved Overseer three
trials (for run) 10% observations observable Overseer.
error-bars right bar mark minimum maximum accuracy values achieved
three trials run. Run I's error-bars unseen since three trials resulted
accuracy.
number promising conclusions drawn results.
First, runs E I, Overseer's average accuracy dropped less 8%, i.e.,
performance Overseer dropped less level loss introduced. Indeed,
run E, original performance poorest, almost change

121

fiKaminka, Pynadath, & Tambe

Average Accuracy

1
0.8
0.6
0.4
0.2
0

Run E

Run

Run J

Figure 7: Comparison average accuracy results 0% 10% observation losses.

performance. Performance run J drop slightly 10%,
least partially explained run J's previously discussed failures exploit communications predictions. Thus one promising conclusion drawn results
Overseer's performance degrade gracefully, rate comparable rate
degradation Overseer's input.
second conclusion Overseer's performance observation-loss settings
fairly invariant. Again, run E I, considered normative, show
little (if any) variance one trial next, despite change selection
observations made unobserved one trial next. Even run J,
representative normative runs, shows little variance respect average
accuracy observation loss.

result suggests may drop

performance observation loss (as expected), Overseer performs consistently
varying lossy settings.

6.3

Overseer Human Monitoring Overhearing

Another important facet evaluation Overseer examines performance comparison novice expert monitors evacuation application. evaluation
sheds light diculty monitoring task, demonstrates Overseer's performance comparable (sometimes higher, sometimes lower) human expert

performance, signicantly better novices.
conduct evaluation, examined three runs representatives Overseer's bounds performance discussed (runs E, I, J). rst author

paper served expert monitor, much experience overhearing evacua-

122

fiMonitoring Teams Overhearing
2

tion application possible (and specically actual test runs E, J) . established group novice monitors, made subjects generally familiar
hierarchical control structures unfamiliar either monitoring overhearing
evacuation application component agents. subject presented
printed books (one run) containing overheard messages (in human-readable
form), messages overheard Overseer optimal (lossless) conditions.
reference material, subject given copy plan-hierarchy, team-hierarchy,
average duration information available Overseer (the parameter

dierent

leaf plans). overheard message, second line print indicated time passed
since overhearing message, subject asked write best estimate
agents' current state (i.e., message overheard specied time
passed). felt dierent agents dierent sub-teams dierent states,
specify agent subteam doing. emphasize subjects presented
exactly runs Overseer evaluated.
actual test process began short explanation task, full explanation plan-hierarchy (including answering questions subjects
semantics dierent transitions, etc.), short test run allowed subject use plan-hierarchy team hierarchy (but without providing feedback
subject's accuracy). Then, questions answered, subjects
presented test books given unlimited time complete them, order
(though started book, required nish it). Subjects allowed
look forward next message completing answer, go back change
previous answers. encouraged seek assistance locating plans (in
plan-hierarchy) consistent messages, information provided plan
may correct two plans consistent. subjects nished runs,
test books taken together score computed. correct prediction
awarded 1, incorrect prediction 0same standard used scoring Overseer's accuracy. non-specic answer (i.e., somewhere sub-tree

Fly-Flight-Plan)

considered incorrect prediction, subjects repeatedly instructed
specic answer required.
results test presented Figure 8.

previous graphs, Y-axis

denotes percentage accurate monitoring hypotheses across data-points run
(2245, depending run). X-axis three categories, three dierent runs.
run, left bar (marked Novices) presents average accuracy achieved
novice monitors, middle bar (marked Experts) presents accuracy achieved
human expert monitor, nal bar (YOYO*) re-prints results presented
Figure 5 above. results show average accuracy novices clearly inferior
expert monitor Overseer. Overseer's performance
human expert runs J. However, human expert much better
Overseer run E.

draw several conclusions results. First, monitoring task Overseer
faced evacuation application trivial: novices failed achieve
2. settle one expert since training expert task time consuming
requires much familiarity internals evacuation application well TEAMCORE
architecture.

123

fiKaminka, Pynadath, & Tambe
70% average (in best run), generally performed signicantly worse (by 15%
more) human expert. Second, Overseer's performance dierent runs
comparable human expert (sometimes better, sometimes worse).

However,

Overseer's performance tended follow trend novices. words,
Overseer's accuracy tended go dierent runs similar manner

average novice human monitor, expert's accuracy remained fairly
constant across runs.

1

0.8

Novices

0.6

Experts
0.4

YOYO*
0.2

0



J

E

Figure 8: Accuracy human novice expert monitors compared Overseer.

6.4 Evaluating YOYO*'s Trading Expressivity Scalability
examine key trade-o expressivity eciency involved planrecognition techniques presented. accuracy discussion above, clear
coherence useful heuristic. YOYO* takes extreme approach, strictly ruling
reasoning incoherences.

impossible YOYO*, instance, represent

incoherence two team-members disagreement plan executed
common team. may thus impossible YOYO* explicitly represent hypotheses associated communication losses delays, cause incoherences.



approach individual represented separately allows representation,
respect expressive. However, failure-checks place,

able detect many incoherences, previously discussed.

YOYO*

hand, YOYO* oers signicant computational scalability respect
number agents monitored. Analysis YOYO*'s complexity (in contrast array

124

fiMonitoring Teams Overhearing
approach) already presented Section 5.2, follow empirical evaluation. Figure 9 reports space requirement YOYO* array-based approach
three dierent domains: evacuation domain, YOYO* evaluated
deployed, two additional domains built multi-agent teamsModSAF
(Tambe et al., 1995; Calder, Smith, Courtemanche, Mar, & Ceranowicz, 1993) RoboCup
(Tambe, Adibi, Al-Onaizan, Erdem, Kaminka, Marsella, & Muslea, 1999; Marsella, Adibi,
Al-Onaizan, Kaminka, Muslea, Tallis, & Tambe, 2001). YOYO* currently evaluated
domains, yet fully deployed there, believe partial
existing implementations sucient provide robust projections space savings
achieved domains.

believe projected savings implementation

two domains could provide rough guide savings designers could expect
deploying YOYO* additional domains.
domain, Figure 9 compares space requirements array-based approach
(left bar) YOYO* (right bar).

addition, dark-shaded region top

bar shows space required representing additional agent two
approaches, assumption additional plans added plan-hierarchy
agents added. discussed above, assumption favorable arraybased representation. gure shows signicant space savings achieved YOYO*.
First, representing teams current size, YOYO*'s space requirements
signicantly smaller.

Furthermore, YOYO*'s savings really shine examine

scalability two approaches.

array-based approach requires least

amount space shown gure darkly-shaded area, YOYO*'s requirements grow
one node additional agent. space requirements representing additional
agents small, don't show gure.

Number Nodes

900

600


Additional
Agent

300

Current
Application

0

Array

YOYO*

Evacuation (11 Agents)

Array

YOYO*

RoboCup (11 Agents)

Array

YOYO*

ModSAF (3 Agents)

Figure 9: Empirical savings applying YOYO* evacuation domains.
Earlier, Section 5.2, analyzed YOYO*'s worst case run-time complexity,
argued worst case behavior extreme, cannot sustained practice
since involves continuous communications among agents, infeasibility

125

fiKaminka, Pynadath, & Tambe
provided motivation exploring plan-recognition approach.

evidence

average case, consider evacuation application, agents communicate
average every 20 state changes. application, agents communicate parallel
4 5 exchanges (out dozens), cases one, parallel communications
referred plan, thus still requiring single update YOYO* (see discussion
Section 5.2). task execution would 3 agents (out 11) expected
communicate parallel dierent plans, scenario still dierent YOYO*'s worst
case scenario.
average length task execution domain approximately 900 time-ticks.
array approach would update state agent, time tick, whether
message would appear not.

Thus average complexity per time-tick

worst-case, least

(M N 2 ).

YOYO*, average complexity would

signicantly dierent: 899 900 time-ticks would result

(M + H ) process,

one time (out 900) would result process three times expensive (updating
state 3 dierent agents). worst case scenario occur
dierent runs.

7. Related Work
Aiello et al. (2001) present several benets overhearing agent conversations. suggest
overhearer may infer intent agents engaged conversations, oer
specic suggestions improving agents' performance.

instance, overhearing

conversation two agents keyword search web, overhearer may
suggest alternative keywords conduct search.

work closely related

research Overseer, indeed points several potential additional benets
overhearing technology. However, contrast work, Aiello et al. address
problem intent- plan-recognition. present algorithms inferring plans,
disambiguating recognized plans.
Overseer diers previous work plan-recognition focused

monitoring multiple agents, single agent.

previous work multi-agent plan

recognition either focused exploiting explicit teamwork reasoning (e.g.,

Tambe,

1996), explicitly reasoning uncertainty recognizing multi-agent plans (e.g.,
Devaney & Ram, 1998; Intille & Bobick, 1999), key novelty Overseer
eectively blends two threads together. provide detailed discussion below.
Like Overseer,
inferring
heuristic.

RESCteam

team plans

RESCteam

(Tambe, 1996) reasons explicitly team intentions

observations, similarly Overseer's use coherence

uses coherence restrict space requirements plan-library

used, similarly YOYO*.

However, Overseer uses advanced teamwork model

(e.g., predict failure states recovery actions), uses knowledge procedures
used team (i.e., communication decisions), also explicitly reasons uncertainty
time, allowing answer queries related likelihood current future team
plans (issues addressed

RESCteam ).

Indeed,

RESCteam

explicitly represent

ordering constraints plans, address scarce observations: assumes
observations available account possible changes state
observed agents.

126

fiMonitoring Teams Overhearing
Work (Devaney & Ram, 1998; Intille & Bobick, 1999) focuses explicitly
addressing uncertainty plan recognition multi-agent contexts, exploit
explicit notions teamwork. Devaney Ram (1998) use pattern matching recognize
team-tactics military operations. approach relies team-plan libraries, veried
domain experts, combine team- plan-hierarchies; organizational knowledge
explicitly represented technique.

Similarly, Intille Bobick (1999) rely

entirely coordination constraints among agents recognize team-tactics football,
sense use socially-attentive technique prefers hypotheses agents
maintaining roles. Intille Bobick's work uses single structure dierent
recognized tactic. investigations use position trace data monitored human teams.
work diers (Devaney & Ram, 1998; Intille & Bobick, 1999) several ways.
First, previous investigations applied settings observations continuously available monitored agent. contrast, Overseer targeted towards

overhearing,

limited observations available, time, number

agents actually observed. Overseer introduces number novel techniques (such
communications predictions) useful settings. second important dierence underlying representation used reasoning. introduce novel representation
particularly suited monitoring overhearing, Intille Bobick rely standard
belief networks, constructed particular way support reasoning spatial/temporal
coordination. Finally, explicit use make teamwork organizational structure
(the team-hierarchy) enables YOYO* principle reason coordination teamwork failures, previous monitoring techniques would fail recognize team's
actions (Intille & Bobick, 1999).
Huber (1996) reports use probabilistic plan recognition service observationbased coordination Net-trek domain, shows agents using plan recognition
coordination outperform agents using communications coordination.

Huber takes

coordination cooperative actions part self- interested agents, e.g., joining
agent attacking common enemy. Huber's work exploit knowledge
relationships agents limit computation increase accuracy. Huber's
system allow uncertainty caused missing observations, contrast
work, introduce specialized mechanisms (such ours) explicitly address
these.
Plan Recognition Bayesian Networks (PRBNs) (Charniak & Goldman, 1993) provide
general model plan events, evidence, inference. However, PRBN static
Bayesian network, must include nodes plans observations throughout
execution plans. Therefore, instead representing events single time
step (as DBNs described Section 3.1), must include nodes time steps.

, nite time horizon
2
steps, number nodes network (T N ). Inference
2

NM
space/time complexity exponential number nodes, (2
), prohibitive
lengths execution found example domains (e.g., = 900).
Therefore,

N

agents, executing plan hierarchy size

representation used YOYO* related existing approaches modeling
stochastic processes, particular used probabilistic plan recognition.



representation present perhaps closely resembles Hidden Markov Models (HMMs)
(Rabiner, 1989), used plan-recognition (Han & Veloso, 1999). One could, theory,

127

fiKaminka, Pynadath, & Tambe
represent plan state team agents within unconstrained state space
HMM. However, HMM state space would represent possible combinations
individual plan states agents, size HMM state space would
exponential number agents plans. Thus, standard algorithms HMM
inference would able exploit structure plan team hierarchies,
particular forms evidence (as described Section 3.2), way YOYO*.
Generalized versions HMM model (Ghahramani & Jordan, 1997; Jordan, Ghahramani,
& Saul, 1997) could compactly represent state space YOYO*, exact
inference intractable models. models ecient algorithms
approximate inference, would diculty determinism present
planning models.
Pynadath Wellman report Probabilistic State-Dependent Grammar (PSDG)
model (2000) avoids full complexity DBN inference making simplifying assumptions appropriate plan recognition. However, PSDG incorporate broader
classes inference YOYO*, intended single-agent plan recognition,
support concurrency general enough fashion multi-agent plan recognition.
Goldman, Geib Miller (1999) develop conceptual model Bayesian plan recognition include, one key novelties, ability infer plans single
agent lack observation action. However, Goldman et al. deal dierent
issue altogether one communications predictions address.

framework

looks sequence observations, observation may missing, observations actions following appear. framework allows inference plans
given rise missing observation ruled recognition hypotheses.

contrast, approach uses communications predictions make inference

plan-steps

yet

occur. Overseer probabilistically expects predictions

come true, infer additional information missing (predicted) observation
followed another. addition, approach fully implemented deployed
multi-agent settings, rather single agent.
complementary line work (in context TEAMCORE architecture)
focused

intended

plan-recognition monitoring, team-members may adapt

communications monitoring made easier (Tambe et

al., 2000).

work

(i) reduced, eliminate uncertainty, (ii) present methods
address uncertainty, here, However, presents interesting future direction
Overseer's development.

8. Summary Future Work
paper introduced monitoring overhearing, technique increasingly
important growing need monitor agent systems, particularly distributed deployed. presented Overseer, system monitoring teams overhearing routine
communications team-members exchange part execution joint tasks. Monitoring overhearing, plan-recognition task, presents characteristic challenges
previously addressed. include scarcity observations compared rate
change agent's state, fact agents individually observable,
observations essentially multi-agent actions. addition these, familiar challenges

128

fiMonitoring Teams Overhearing
demanding response times maintaining performance face scale-up
number monitored agents, also present.
address challenges, Overseer employs number novel techniques,
exploit knowledge relationships agents alleviate uncertainty increase eciency monitoring: (i) ecient probabilistic algorithm plan-recognition,
particularly suited monitoring communications; (ii) YOYO*, approach ecient
maintenance recognition coherent hypotheses; (iii) use social structures
procedures, e.g., team coherence communications maintain coherence, alleviate
uncertainty. demonstrate generality techniques, discussed potential use techniques representations plan-hierarchy, particular
DBNs (Kjrul, 1992).
provided in-depth empirical evaluation techniques one domains
Overseer applied. evaluation carefully examines contribution
technique overall recognition success, demonstrates techniques work
best together, complement relative weaknesses other. paper also presented evaluation scalability YOYO*, performance conditions
observation loss. Finally, presented comparison Overseer's performance
human expert novice monitors, demonstrated Overseer performance
comparable human experts, despite diculty monitoring task.
Several opportunities future research directions arise experimental results.
First, use rote-learning predict messages observed (provided feasibility demonstration), proved eective normative runs. However, simple mechanism
damaging rare patterns communications arose, experiments
shown. In-depth exploration role learning therefore one directions hope
pursue future.

addition, learning mechanisms derive plan-hierarchy

team-hierarchy structures records conversations also much interest.

Acknowledgements
paper based part Agents-2001 paper authors (Kaminka, Pynadath, & Tambe, 2001). Parts research carried rst author
Post Doctorate Fellow Computer Science Department, Carnegie Mellon University.
thank Manuela Veloso enthusiastic support project Carnegie Mellon
University, thank Yves Lesprance, Victor Lesser, George Bekey, Je Rickel,
Dan O'Leary useful comments. Oshra Kaminka deserves special thanks help
analyzing processing data. research supported DARPA awards F3060298-2-0108, F30602-98-2-0135, F30602-00-2-0549, managed Air Force Research
Labs/Rome site.

Appendix A. Additional algorithms proofs
appendix contains pseudo-code algorithms described paper,
pseudo-code provided body text itself. include modications
propagation procedures necessary propagation within YOYO*. addition,

129

fiKaminka, Pynadath, & Tambe
provide proof number coherent hypotheses
plan-library

M.

N

agents linear size

A.1 Number Incoherent Coherent Hypotheses
Let

Mi

monitoring plan-library agent

i; 1

N.

monitoring system reasons monitoring hypotheses

Mi

nite set possible plans agent



Mi .

monitoring agent

i,



words, view

may executing. Given query

agent's current state monitoring system, plan-recognition algorithm picks

ki

Mi hypotheses
mi jmi j = ki .

specic members

hypotheses

current state agentcall sets

construct overall team hypothesis, monitoring system must combine individual hypotheses form hypothesis team's state. agent i, monitoring
system chooses one individual hypothesis

hi

2 mi. combination forms team

state hypothesis. uncertainty state agent, i.e.,


i,

one team hypothesis exists.

ki

=1

However, uncertainty exists state

agents, clearly, process selecting individual hypotheses becomes combinatorial
nature, possible combinations individual hypotheses possible principle.
Let us consider many coherent hypotheses exist. restrict coherent
hypotheses, selection individual hypotheses agent constrained
selections agreementthe individual hypothesis selected
agent. Given selection individual state hypothesis
must choose

h1

=

h2

=

h2
h3

2m

=

:::

2 second agent,

=

hN .

h3

2m

h1

2m

1 rst agent,

3 third agent, etc.,

Since

k1

jM j individual
1

state

hypotheses rst agent, follows number coherent team-state hypotheses
bounded

jM j, i.e., size plan library agents.
1

coherent hypotheses bounded

fact, number

minki since members mmin ki matched

m. contrast, denition,
k1 k2 k3 ::: kN (min ki )

members individual hypothesis sets,
team-state hypotheses incoherent.
hypotheses.

A.2 YOYO* Propagation Algorithms (Section 5.1)
algorithms presented section support presented main text
paper, provided completeness.

may contain step

iterates teams take outgoing transition (e.g., line 1 algorithm 6,
line 13 algorithm 7). step requires clarication: iterating
outgoing teams meet condition, algorithm consults team-hierarchy
carry iteration

topmost

teams (in terms team-hierarchy)

meet condition. instance, application domain, team TASK-FORCE
(among others) two subteams TRANSPORTS ESCORTS. transition allowed
taken TRANSPORTS only, iteration teams allowed
take transition consider either ESCORTS TASK-FORCE. However,
transition allows TASK-FORCE, iteration step take place onceit
executed team TASK-FORCE, parent team TRANSPORTS
ESCORTS.

130

fiMonitoring Teams Overhearing

Algorithm 6 Team-Propagate-Down(plan , probability , beliefs, b, plans )
1:





2:
3:
4:
5:
6:

teams allowed take outgoing hierarchical-decomposition transition



fc j c 2 M; c rst child Y; c taken team g
= j CT j
plans c 2 CT
bt+1 (Y; :block )
bt+1 (Y; :block ) + 0
(c; 0 ; b; )

CT
0

Team-Propagate-Down

Algorithm 7 Team-Propagate-Forward(team-hierarchy H , beliefs b, plans )
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:

22:
23:

plans X 2
bt+1 (X; :block )
0:0
bt+1 (X; block )
0:0
outx
0:0
x
0:0
plans X 2 post-order




X leaf

outx

else



bt (X; :block )(1

{X parent}



{children temporal order parents}

e x ) {calculate probability X terminating time t}

outx known { post-order guarantees children set line 21}
temporal outgoing transitions Tx!y X
x
x + (1 xy )xy
teams E allowed take temporal outgoing transition
x > 0 {some transition taken}
temporal outgoing transitions Tx!y X taken E

outx (1 xy )xy
Tx!y leads successor plan
bt+1 (Y; :block )
bt+1 (Y; :block ) +
(Y; ; b; )
else {Tx!y terminating transition}
outparent(x)
outparent(x) + (1 xy )xy {parent's outgoing probability chil-

Team-Propagate-Down
dren's}

bt+1 (X; block )
bt+1 (X; block ) + outx x
bt+1 (X; :block )
bt+1 (X; :block ) outx

131

fiKaminka, Pynadath, & Tambe
Algorithm 8 may require clarications. First, important note
plans



(line 1) traversed pre-orderparents children. scaling calculation

depends parent scaled probability. Second, iteration sub-plans



essentially captures plans subtree rooted parent plan

subtree rooted

P 's

child

X,

X 's

except

already adjusted YOYO* prior

call algorithm. fact, use
sure

P,

X 's

team

siblings, alternatives

X



scale plans makes

team

T,

get scaled.

correct procedure called incorporating evidence

X

(rather

siblings).

Algorithm 8 Scale(parent plan P , team , child plan X , beliefs b)
1:
2:
3:

subplans P , team(Y ) 6= , pre-order
bt (Y;:block)
b (parent(Y ); :block )
bt+1 (Y; :block )
bt+1 (Y; :block )+ bt (parent
(Y );:block) t+1
bt (Y;block)
bt+1 (Y; block )
bt+1 (Y; block )+ bt (parent(Y );:block) bt+1 (parent(Y ); :block )



References
Ontological overhearing. Intelligent Agents VIII, Proceedings international workshop Agents, Theories,
Architectures, Languages (ATAL-2001).

Aiello, M., Busetta, P., Dona, A., & Serani, L. (2001).

Barber, K. S., & Martin, C. E. (2001). Dynamic reorganization decision-making groups.

Proceedings Fifth International Conference Autonomous Agents (Agents-01),
pp. 513520. ACM Press.

Calder, R. B., Smith, J. E., Courtemanche, A. J., Mar, J. M. F., & Ceranowicz, A. Z. (1993).

Modsaf behavior simulation control. Proceedings Third Conference
Computer Generated Forces Behavioral Reresentation Orlando, Florida. Institute
Simulation Training, University Central Florida.

Charniak, E., & Goldman, R. P. (1993). Bayesian model plan recognition.

Intelligence, 64 (1), 5379.

Articial

Cohen, P. R., Johnston, M., McGee, D., Oviatt, S., Pittman, J., Smith, I., Chen, L., & Clow,
J. (1997). Quickset: Multimodal interaction distributed applications.

Proceedings

Fifth Annual International Multimodal Conference (Multimedia '97), pp. 3140.
Cohen, P. R., & Levesque, H. J. (1990). Rational interaction basis communication.

Cohen, P. R., Morgan, J., & Pollack, M. E. (Eds.),

Intentions Commu-

nication, Systems Development Foundation Benchmark Series, chap. 12, pp. 221255.
MIT Press.

Nous, 35.
Decker, K. (1995). Environment Centered Analysis Design Coordination Mechanisms.

Cohen, P. R., & Levesque, H. J. (1991). Teamwork.

Ph.D. thesis, Department Computer Science, University Massachusetts, Amherst.
Devaney, M., & Ram, A. (1998). Needles haystack: Plan recognition large spatial

Proceedings Fifteenth National Conference
Articial Intelligence (AAAI-98), pp. 942947 Madison, WI.
domains involving multiple agents.

132

fiMonitoring Teams Overhearing
Dunin-Keplicz, B., & Verbrugge, R. (2001).

role dialogue collective problem

Proceedings fth International Symposium Logical Formalization
Commonsense Reasoning (Commonsense 2001), pp. 89104.
solving.

Finin, T., Labrou, Y., & Mayeld (1997). KQML agent communication language.
Bradshaw, J. (Ed.),

Software Agents. MIT Press.

Ghahramani, Z., & Jordan, M. I. (1997). Factorial hidden Markov models.

29, 245275.

Goldman, R. P., Geib, C. W., & Miller, C. A. (1999).


Machine Learning,

new model plan recognition.

Proceedings Conference Uncertainty Articial Intelligence (UAI-1999)

Stockholm, Sweden.
Grosz, B. (1996). Collaborating systems.

AI Magazine, 17 (2).

Grosz, B. J., & Kraus, S. (1999). evolution SharedPlans. Wooldridge, M., & Rao,
A. (Eds.),

Foundations Theories Rational Agency, pp. 227262.

Grosz, B. J., & Kraus, S. (1996). Collaborative plans complex group actions.

Intelligence, 86, 269358.

Articial

Han, K., & Veloso, M. (1999). Automated robot behavior recognition applied robotic soccer.

Proceedings IJCAI-99 Workshop Team Behavior Plan-Recognition.

Also appears Proceedings 9th International Symposium Robotics Research
(ISSR-99).
Horling, B., Benyo, B., & Lesser, V. (2001).

Using self-diagnosis adapt organizational

Proceedings Fifth International Conference Autonomous Agents
(Agents-01), pp. 529536.
Huber, M. J. (1996). Plan-Based Plan Recognition Models Eective Coordination
Agents Observation. Ph.D. thesis, University Michigan.
structures.

Huber, M. J., & Hadley, T. (1997). Multiple roles, multiple teams, dynamic environment:

Proceedings First International Conference Autonomous Agents (Agents-97), pp. 332339 Marina del Rey,
Autonomous netrek agents. Johnson, W. L. (Ed.),
CA. ACM Press.

Intille, S. S., & Bobick, A. F. (1999). framework recognizing multi-agent action

Proceedings Sixteenth National Conference Articial
Intelligence (AAAI-99), pp. 518525. AAAI Press.
visual evidence.

Jennings, N. R. (1993). Commitments conventions: foundations coordination
multi-agent systems.

Knowledge Engineering Review, 8 (3), 223250.

Jennings, N. R. (1995). Controlling cooperative problem solving industrial multi-agent
systems using joint intentions.

Articial Intelligence, 75 (2), 195240.

Jordan, M. I., Ghahramani, Z., & Saul, L. K. (1997).

Hidden Markov decision trees.

Mozer, M. C., Jordan, M. I., & Petsche, T. (Eds.),

Processing Systems, Vol. 9, p. 501. MIT Press.



Advances Neural Information

Kaminka, G. A., Pynadath, D. V., & Tambe, M. (2001). Monitoring deployed agent teams.

Proceedings Fifth International Conference Autonomous Agents (Agents01), pp. 308315.


133

fiKaminka, Pynadath, & Tambe
Kaminka, G. A., & Tambe, M. (2000).
monitoring.

Robust multi-agent teams via socially-attentive

Journal Articial Intelligence Research, 12, 105147.

Kinny, D., Ljungberg, M., Rao, A., Sonenberg, E., Tidhar, G., & Werner, E. (1992). Planned
team activity.

Castelfranchi, C., & Werner, E. (Eds.),

Articial Social Systems,

Lecture notes AI 830, pp. 227256. Springer Verlag, New York.
Kjrul, U. (1992).

computational scheme reasoning dynamic probabilistic net-

Proceedings Conference Uncertainty Articial Intelligence (UAI1992), pp. 121129 San Mateo, CA. Morgan Kaufmann.

works.

Knoblock, C. A., Minton, S., Ambite, J. L., Ashish, N., Modi, P. J., Muslea, I., Philpot,
A. G., & Tejada, S. (1998).

Modeling Web sources information integration.



Proceedings Fifteenth National Conference Articial Intelligence (AAAI-98).
Kumar, S., & Cohen, P. R. (2000). Towards fault-tolerant multi-agent system architecture.

Proceedings Fourth International Conference Autonomous Agents (Agents00), pp. 459466 Barcelona, Spain. ACM Press.


Kumar, S., Cohen, P. R., & Levesque, H. J. (2000). adaptive agent architecture: Achiev-

Proceedings Fourth International Conference Multiagent Systems (ICMAS-00), pp. 159166 Boston, MA.
ing fault-tolerance using persistent broker teams.
IEEE Computer Society.

Lenser, S., Bruce, J., & Veloso, M. (2001).
tonomous legged soccer robots.

Cmpack: complete software system au-

Proceedings Fifth International Conference

Autonomous Agents (Agents-01), pp. 204211. ACM Press.

Lesh, N., Rich, C., & Sidner, C. L. (1999). Using plan recognition human-computer collaboration.

Proceedings Seventh International Conference User Modelling

(UM-99) Ban, Canada.

Levesque, H. J., Cohen, P. R., & Nunes, J. H. T. (1990). acting together.

Eigth National Conference Articial Intelligence (AAAI-90)

Proceedings

Menlo-Park,

CA. AAAI Press.
Marsella, C. S., Adibi, J., Al-Onaizan, Y., Kaminka, G. A., Muslea, I., Tallis, M., & Tambe,
M. (2001). teammate: Experiences acquired design robocup teams.

Journal Autonomous Agents Multi-Agent Systems, 4 (12).
Martin, D. L., Cheyer, A. J., & Moran, D. B. (1999).

open agent architecture:

framework building distributed software systems.

13 (1-2), 92128.

Applied Articial Intelligence,

Ndumu, D. T., Nwana, H. S., Lee, L. C., & Collis, J. C. (1999). Visualizing debugging

Proceedings Third International Conference
Autonomous Agents (Agents-99). ACM Press.
distributed multi-agent systems.

Payne, T. R., Sycara, K., Lewis, M., Lenox, T. L., & Hahn, S. (2000).

Varying user

Proceedings Fourth International
Conference Autonomous Agents (Agents-00), pp. 412418.
interaction within multi-agent systems.



Pechoucek, M., Marik, V., & Stepankova, O. (2000).

Role acquaintance models

agent-based production planning. Klusch, M., & Kerschberg, L. (Eds.),

134

Cooperative

fiMonitoring Teams Overhearing
Information Agents IV, Proceedings Fourth International Workshop (CIA-2000),
No. 1860 LNAI, pp. 179190. Springer Verlag.
Pechoucek, M., Marik, V., & Stepankova, O. (2001). Towards reducing communication trac
multi-agent systems.

Journal Applied System Studies.

Pynadath, D. V., & Wellman, M. P. (2000). Probabilistic state-dependent grammars plan
recognition.

Proceedings Conference Uncertainty Articial Intelligence

(UAI-2000), pp. 507514.

Rabiner, L. R. (1989). tutorial Hidden Markov Models selected applications

Proceedings IEEE, 77 (2), 257286.
Reed, C. (1998). Dialogue frames agent communications. Proceedings Third
International Conference Multiagent Systems (ICMAS-98), pp. 246253.
speech recognition.

Rich, C., & Sidner, C. L. (1997).

COLLAGEN: agents collaborate people.

Proceedings First International Conference Autonomous Agents (Agents-97), pp. 284291 Marina del Rey, CA. ACM Press.
Tambe, M. (1996). Tracking dynamic team activity. Proceedings National Conference Articial Intelligence (AAAI).
Tambe, M. (1997). Towards exible teamwork. Journal Articial Intelligence Research,
7, 83124.
Johnson, W. L. (Ed.),

Tambe, M., Adibi, J., Al-Onaizan, Y., Erdem, A., Kaminka, G. A., Marsella, S. C., &
Muslea, I. (1999). Building agent teams using explicit teamwork model learning.

Articial Intelligence, 111 (1), 215239.

Tambe, M., Johnson, W. L., Jones, R., Koss, F., Laird, J. E., Rosenbloom, P. S., & Schwamb,
K. (1995).

16 (1).

Intelligent agents interactive simulation environments.

AI Magazine,

Tambe, M., Pynadath, D. V., Chauvat, N., Das, A., & Kaminka, G. A. (2000). Adaptive

Proceedings
Fourth International Conference Multiagent Systems (ICMAS-00), pp. 301308

agent integration architectures heterogeneous team members.
Boston, MA.

Tidhar, G. (1993a). Team oriented programming: Preliminary report. Tech. rep. 41, Australian Articial Intelligence Institute, Melbourne, Australia.
Tidhar, G. (1993b). Team oriented programming: Social structures. Tech. rep. 47, Australian
Articial Intelligence Institute, Melbourne, Australia.
Vercouter, L., Beaune, P., & Sayettat, C. (2000).

Towards open distributed information

Working Notes
AAAI-2000 Workshop Agent-Oriented Information Systems (AOIS-2000), pp.

systems way multi-agent conception framework.
2938.

135



fiJournal Artificial Intelligence Research 17 (2002) 35-55

Submitted 12/01; published 8/02

Inferring Strategies Sentence Ordering Multidocument
News Summarization
Regina Barzilay
Noemie Elhadad
Kathleen R. McKeown

regina@cs.columbia.edu
noemie@cs.columbia.edu
kathy@cs.columbia.edu

Columbia University, Computer Science Department
1214 Amsterdam Ave
New York, 10027, NY, USA

Abstract
problem organizing information multidocument summarization
generated summary coherent received relatively little attention. sentence
ordering single document summarization determined ordering sentences input article, case multidocument summarization
summary sentences may drawn different input articles. paper, propose
methodology studying properties ordering information news genre
describe experiments done corpus multiple acceptable orderings developed
task. Based experiments, implemented strategy ordering information
combines constraints chronological order events topical relatedness. Evaluation augmented algorithm shows significant improvement ordering
two baseline strategies.

1. Introduction
Multidocument summarization poses number new challenges single document summarization. Researchers already investigated issues identifying repetitions
contradictions across input documents determining information salient enough
include summary (Barzilay, McKeown, & Elhadad, 1999; Carbonell & Goldstein,
1998; Elhadad & McKeown, 2001; Mani & Bloedorn, 1997; McKeown, Klavans, Hatzivassiloglou, Barzilay, & Eskin, 1999; Radev & McKeown, 1998; White, Korelsky, Cardie, Ng,
Pierce, & Wagstaff, 2001). One issue received little attention organize
selected information output summary coherent. relevant
pieces information selected across input documents, summarizer
decide order present whole text makes sense. single
document summarization, one possible ordering extracted information provided
input document itself. However, Jing (1998) observed that, single document summaries written professional summarizers, extracted sentences always retain
precedence orders summary. Moreover, case multiple input documents,
provide useful solution: information may drawn different documents
therefore, single document provide ordering. Furthermore, order two
pieces information change significantly one document another.
paper, provide corpus based methodology studying ordering. goal
develop good ordering strategy context multidocument summarization
c
2002
AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiBarzilay, Elhadad & McKeown

targeted news genre. first question addressed importance ordering. conducted experiments show ordering significantly affects readers
comprehension text. experiments also show although single ideal
ordering information, ordering unconstrained problem; number good orderings given text limited. second question addressed analysis use
data infer strategy ordering. Existing corpus based methods, supervised
learning, easily applicable problem part lack training data.
Given multiple possible orderings, corpus providing one ordering
set information allow us differentiate sentences must together sentences happen together. led us develop corpus data
sets, contains multiple acceptable orderings single text. corpus
expensive construct therefore, provide enough data pure statistical
approaches. Instead, used hybrid corpus analysis strategy first automatically identifies commonalities across orderings. Manual analysis resulting clusters led
identification constraints ordering. Finally, evaluated plausible ordering strategies
asking humans judge results.
set experiments together suggests ordering algorithm integrates constraints approximation temporal sequence underlying events
relatedness content elements. evaluation plausible strategies measured
usefulness Chronological Ordering algorithm used previous summarization systems
(McKeown et al., 1999; Lin & Hovy, 2001) well alternative, original strategy,
Majority Ordering. evaluation showed two ordering algorithms alone
yield satisfactory results. first, Majority Ordering, critically linked level
similarity information ordering across input texts. input texts different
orderings, however, algorithm produces unpredictable unacceptable results.
second, Chronological Ordering produces good results information event-based,
therefore, temporally sequenced. texts refer events, describe
states properties, algorithm falls short.
automatic analysis revealed topical relatedness important constraint;
groups related sentences tend appear together. algorithm combines Chronological
Ordering constraints topical relatedness. Evaluation shows augmented
algorithm significantly outperforms either simpler methods alone. strategy
characterized bottom-up since final ordering text emerges data
groups together, whether related content chronological sequence. contrasts
top-down strategies RST (Moore & Paris, 1993; Hovy, 1993), schemas (McKeown, 1985) plans (Dale, 1992) impose external, rhetorically motivated ordering
data.
following sections, first show way information ordered summary
critically affect overall quality. give overview summarization
system, MultiGen. next describe two naive ordering algorithms evaluate
them, followed study multiple orderings produced humans. allows us
determine improve Chronological Ordering algorithm using cohesion
additional constraint. last section describes augmented algorithm along
evaluation.
36

fiSentence Ordering Multidocument News Summarization

2. Impact Ordering Overall Quality Summary
Even though problem ordering information multidocument summarization
received relatively little attention, hypothesize good ordering crucial produce
summaries quality. consensus architecture state art summarizers consists
content selection module salient information extracted regeneration
module information reformulated fluent text. Ideally, regeneration
component contains devices perform surface repairs text anaphora
resolution, introducing cohesion markers choosing appropriate lexical paraphrases.
claim paper multidocument summarization architecture needs
explicit ordering component. two pieces information extracted content selection
phase end together not, fact, next one another, surface devices
repair impaired flow information summary. ordering strategy would
help avoid situation.
clear ordering cannot improve output earlier stages summarizer,
among content selection1 ; however, finding acceptable ordering enhance user
comprehension summary and, therefore, overall quality. course, surface devices
still needed smooth output summary, scope paper (but
see (Schiffman, Nenkova, & McKeown, 2002)). section show quality
ordering direct effect user comprehension summary. verify hypothesis,
performed experiment, measuring impact ordering users comprehension
summaries.
selected ten summaries produced Columbia Summarization system (McKeown, Barzilay, Evans, Hatzivassiloglou, Kan, Schiffman, & Teufel, 2001). composed
router two underlying summarizers MultiGen DEMS (Difference Engine
Multidocument Summarization). Depending type input articles summarized, router selects appropriate summarizer. evaluated system
Document Understanding Conference 2001 (DUC) 2 evaluation, summaries produced
several systems graded human judges according different criteria, among
well information contained summary ordered. actually identify
possible impact ordering comprehension, selected summaries humans
judged ordering poor.3 summary, manually reordered sentences
generated summarizer, using input articles reference. so,
change content sentences reordered summaries
ones originally produced summaries. process yields ten additional reordered
summaries thus, overall collection contains twenty summaries.
Two subjects authors participated experiment. summary
read one participant without access input articles. distributed
summaries among judges none read original summary
reordering. asked grade well summary could understood, using
ratings Incomprehensible, Somewhat comprehensible Comprehensible.
1. information added deleted content selection performed.
2. http://www-nlpir.nist.gov/projects/duc/
3. selected summaries produced DEMS system. didnt select summary produced
MultiGen implemented ordering algorithm time. DEMS hand,
specific ordering strategy implemented thus provided us appropriate type data.

37

fiBarzilay, Elhadad & McKeown

results shown Figure 14 . Seven original summaries considered incomprehensible judge, two somewhat comprehensible, one original summary
fully comprehensible. reordered summaries obtained better grades overall five
summaries fully comprehensible, two somewhat comprehensible, three remained incomprehensible. assess statistical significance results, applied
Fisher exact test data set, conflating Incomprehensible Somewhat comprehensible summaries one category obtain 2x2 table. test adapted
case reduced size data set. obtained p-value 0.07 (Siegal
& Castellan, 1988), means reordering not, general, helpful,
7% chance reordering anyway would produce result different quality
original ordering. experiment indicates good ordering improve
overall comprehensibility summary.
Summary set
d13
d19
d24
d31
d32
d39
d45
d50
d54
d56

Original
Incomprehensible
Somewhat comprehensible
Incomprehensible
Somewhat comprehensible
Incomprehensible
Incomprehensible
Incomprehensible
Incomprehensible
Incomprehensible
Comprehensible

Reordered
Incomprehensible
Comprehensible
Comprehensible
Comprehensible
Somewhat comprehensible
Incomprehensible
Incomprehensible
Comprehensible
Somewhat comprehensible
Comprehensible

Figure 1: Impact ordering user comprehension summaries.

case low-scoring summaries, clear poor ordering likely
culprit. instance, readers easily identify grouping two following sentences
unsuitable choice could misleading. Miss Taylors health problems started
fall horse 13 filming movie National Velvet. recovery
Elizabeth Taylor, near death two weeks ago viral pneumonia, complicated yeast
infection, doctors said Friday. cases, information summary
poorly ordered readers cannot make sense text, observed interviews
readers tend blame content selection rather ordering,
even content issue. Thus, issue ordering isolated; affect
overall quality summary.

3. MultiGen Overview
framework MultiGen system (McKeown et al., 1999), multidocument summarizer trained tested news articles. MultiGen part
Columbia Summarization System. operates set news articles describing
4. set names ones used DUC evaluation.

38

fiSentence Ordering Multidocument News Summarization

event, creating summary synthesizes common information across documents.
system runs daily real data within Newsblaster 5 , tool collects news articles
multiple sources, organizes topical clusters provides summary
clusters.
case multidocument summarization articles event, source
articles contain repetitions contradictions. Extracting similar sentences would produce verbose repetitive summary, extracting
similar sentences would produce summary biased towards sources. MultiGen uses
comparison extracted similar sentences select appropriate phrases include
summary reformulates new text.
MultiGen consists analysis generation component. analysis component (Hatzivassiloglou, Klavans, & Eskin, 1999) identifies units text convey similar
information across input documents using statistical techniques shallow text analysis. similar text units identified, cluster themes. Themes sets
sentences different documents contain repeated information necessarily contain sentences documents (see two examples themes Figure 2).
theme, generation component (Barzilay et al., 1999) identifies phrases
intersection theme sentences selects part summary.
intersection sentences ordered produce coherent text. end,
theme single corresponding generated output sentence summary.
following section, describe different strategies ordering output sentences
obtain quality summary.
Theme 1
Mr. Salvi, 24, apparently killed prison cell last November.
state wouldnt execute killing two abortion clinic workers 1994, John
C. Salvi III took life.
John C. Salvi III, convicted killing two people shooting spree two
abortion clinics 1994, killed prison.
Theme 2
attorneys said attempted suicide twice prison.
lawyers said twice tried commit suicide jail, charge authorities
denied.
Figure 2: Two themes corresponding sentences. Theme 2 contains sentences
two articles, Theme 1 contains sentences three input articles.

4. Naive Ordering Algorithms Sufficient
producing summary, multidocument summarization system choose
order present output sentences. section, describe two algorithms
5. http://www.cs.columbia.edu/nlp/newsblaster

39

fiBarzilay, Elhadad & McKeown

ordering sentences suitable multidocument summarization news genre.
first algorithm, Majority Ordering (MO), relies original orders sentences
input documents. second one, Chronological Ordering (CO), uses time-related
features order sentences. strategy originally implemented MultiGen
followed summarization systems (Radev, Jing, & Budzikowska, 2000; Lin & Hovy,
2001). MultiGen framework, ordering sentences equivalent ordering themes,
describe algorithms terms themes. makes sense because, ultimately,
summary composed sequence sentences, one constructed
information one theme. evaluation shows methods alone provide
adequate strategy ordering.
4.1 Majority Ordering
4.1.1 Algorithm
single document summarization, order sentences output summary typically
determined order input text. strategy adapted multidocument
summarization. Consider two themes, h 1 h2 ; sentences h1 precede sentences
h2 input texts, presenting h 1 h2 likely acceptable
order. use majority ordering algorithm order sentences h 1
h2 varies one text another, must augment strategy. One way define
order h1 h2 adopt order occurring majority
texts h1 h2 occur. strategy defines pairwise order themes.
However, pairwise relation necessarily transitive. example, given themes
h1 , h2 h3 following situation: h1 precedes h2 text, h2 precedes
h3 text another text, h 3 precedes h1 yet another text;
conflict orders (T h1 , h2 , h3 ) (T h3 , h1 ). Since transitivity necessary
condition relation called order, relation form order.
We, therefore, expand pairwise relation provide total order.
words, find linear ordering themes maximizes agreement
orderings provided input texts. pair themes, h hj ,
keep two counts, Ci,j Cj,i ; Ci,j number input texts sentences
hi occur sentences hj , Cj,i opposite order. weight
linear order (T hi1 , . . . , hik ) defined sum counts every pair C il ,im ,
il im l, {1 . . . k}. Stating problem terms directed graph
nodes themes, vertex h hj weight Ci,j , looking
path maximal weight traverses node exactly (see Figure 3).
call graph precedence graph.
problem finding path maximal weight addressed Cohen,
Schapire, Singer (1999) task learning orderings. adopt two-stage
approach. first stage, given training corpus ordered instances set
features describing them, binary preference function learned. second stage, new
instances ordered agreement learned preference function maximized.
so, Cohen et al. (1999) represent preference function directed, weighted
graph. precedence graph seen graph preference function
40

fiSentence Ordering Multidocument News Summarization

h11 h12 h13
h23 h22 h24
h34 h31 h32 h33

Th 1
2

2

1

Th 2
2
1

1

Th 3

1
1

1

Th 4
Figure 3: Three input theme orderings corresponding precedence graph. h ji
sentence part theme hi input ordering j.

nodes hi hj Ci,j . orderings input articles provide us
directly preference function and, therefore, need learn it.
Unfortunately problem NP-complete; Cohen et al. (1999) prove reducing
CYCLIC-ORDERING (Galil & Megido, 1977). However, using modified version
topological sort provides us approximate solution. node, assign
weight equal sum weights outgoing edges minus sum weights
incoming edges. first pick node maximum weight, ordering ahead
nodes, delete outgoing edges precedence graph update
properly weights remaining nodes graph. iterate
nodes graph empty. Cohen et al. (1999) show algorithm produces
tight approximation optimal solution. Currently MultiGen uses implementation
algorithm ordering component.
Figures 4 5 show examples produced summaries. One feature strategy
produce several orderings weight. happens
tie two opposite orderings. situation, strategy provide enough
constraints determine one optimal ordering; ordering chosen randomly among
orders maximal weight.
4.1.2 Evaluation
asked three human judges (not including ourselves) classify quality order
information 25 summaries produced using MO algorithm three categories
Poor, Fair Good. use operational definition Poor summary text whose
41

fiBarzilay, Elhadad & McKeown

man accused firebombing two Manhattan subways 1994 convicted Thursday jury
rejected notion drug Prozac led commit crimes.
found guilty two counts attempted murder, 14 counts first-degree assault two counts
criminal possession weapon.
December 1994, Leary ignited firebombs two Manhattan subway trains. second blast injured 50
people 16 seriously, including Leary.
Leary wanted extort money Transit Authority.
defense argued Leary responsible actions toxic psychosis caused
Prozac.

Figure 4: summary produced using Majority Ordering algorithm, graded Good.

Hemingway, 69, died natural causes Miami jail arrested indecent exposure.
book wrote father, Papa: Personal Memoir, published 1976.
picked last Wednesday walking naked Miami.
difficult life.
transvestite later sex-change operation, suffered bouts drinking, depression drifting,
according acquaintances.
easy son great man, Scott Donaldson, told Reuters.
time death, lived Coconut Grove district well-known Bohemian
crowd.
due appear court later day charges indecent exposure resisting arrest.
sometimes went name Gloria wore womens clothes.
cause death hypertension cardiovascular disease.
Taken Miami-Dade Womens Detention Center, found dead cell early Monday,
spokeswoman Janelle Hall said.
booked womens jail sex-change operation, Hall added.

Figure 5: summary produced using Majority Ordering algorithm, graded Poor.

readability would significantly improved reordering sentences. Fair summary
text makes sense, reordering sentences yield better readability. Finally, summary cannot improved sentence reordering
considered Good summary.
judges asked grade summaries taking account order
information presented. help focus aspect texts,
resolved dangling references beforehand. Figure 13 shows grades assigned summaries three summaries graded Poor, 14 graded Fair, eight
graded Good. showing majority grade selected least two
judges. made possible experiments, judges strong agreement;
never gave three different grades summary.
MO algorithm produces small number Good summaries,
summaries graded Fair. instance, summary graded Good shown Figure 4
orders information natural way; text starts sentence summary
event, outcome trial given, reminder facts caused trial
possible explanation facts. Looking Good summaries produced
MO, found performs well input articles follow order
42

fiSentence Ordering Multidocument News Summarization

presenting information. words, algorithm produces good ordering
input articles orderings high agreement.
hand, analyzing Poor summaries, observed input texts
different orderings. trying maximize agreement input texts
orderings, MO produces new ordering occur input text. ordering
is, therefore, guaranteed acceptable. example new produced ordering
given Figure 5. summary would readable several sentences moved
around. example better ordering given Figure 6. summary,
three sentences related fact subject sex-change operation grouped
together, one produced majority ordering algorithm, scattered
throughout summary.

Hemingway, 69, died natural causes Miami jail arrested indecent exposure.
cause death hypertension cardiovascular disease.
picked last Wednesday walking naked Miami.
due appear court later day charges indecent exposure resisting arrest.
Taken Miami-Dade Womens Detention Center, found dead cell early Monday,
spokeswoman Janelle Hall said.
booked womens jail sex-change operation, Hall added.
transvestite later sex-change operation, suffered bouts drinking, depression drifting,
according acquaintances.
sometimes went name Gloria wore womens clothes.
difficult life.
easy son great man, Scott Donaldson, told Reuters.
time death, lived Coconut Grove district well-known Bohemian
crowd.
book wrote father, Papa: Personal Memoir, published 1976.

Figure 6: One possible better ordering summary graded Poor.

algorithm used order sentences accurately certain
input texts follow similar organizations. assumption may hold limited domains
documents fixed organization information. However, case,
input texts processing regularities. Looking daily statistics
Newsblaster collects clusters related articles synthesized one summary,
notice typical cluster size seven. every day several clusters
contain 20 70 articles summarized single summaries 6 .
big number input articles, cannot assume similar
ordering information. MOs performance critically depends agreement
orderings input texts; we, therefore, need ordering strategy fit
input data. on, focus Chronological Ordering algorithm
techniques improve it.

6. giant clusters correspond hot topics day news.

43

fiBarzilay, Elhadad & McKeown

4.2 Chronological Ordering
4.2.1 Algorithm
Multidocument summarization news typically deals articles published different
dates, articles cover events occurring wide range time. Using
chronological order summary describe main events helps user understand
happened. seems like natural appropriate strategy. mentioned earlier,
framework, ordering themes; using strategy, we, therefore, need assign
date themes. identify date event occurred requires detailed interpretation
temporal references articles. recent developments disambiguating temporal expressions event ordering (Wiebe, OHara, Ohrstrom-Sandgren, &
McKeever, 1998; Mani & Wilson, 2000; Filatova & Hovy, 2001), correlating events
date occurred hard task. case, approximate theme time
first publication time; is, first time theme reported set
input articles (see Figure 7). acceptable approximation news events; first
publication time event usually corresponds occurrence real life. instance,
terrorist attack story, theme conveying attack date previous
date theme describing trial following attack.
Theme 5
Oct 5, 11:35am

Oct 6, 6:13am
Oct 5, 10:20am

Hours crash, U.S. officials said tragedy
caused S-200 missile fired Ukraine military exercises
Crimean Peninsula.
U.S. officials said immediately crash evidence
passenger jet hit Ukrainian missile.
U.S. officials said crash caused S-200
missile fired mistakenly Ukrainian forces military exercises
Crimean Peninsula.

Figure 7: theme corresponding sentences. time theme shown underlined;
earliest publication time sentences.

Articles released news agencies marked publication time, consisting
date time two fields (hour minutes). Articles news agency
thus guaranteed different publication times. also quite likely articles
coming different news agencies. development MultiGen, processed
hundreds articles, never encountered two articles publication time.
Thus, publication time serves unique identifier articles. result, two
themes publication time, means reported first
time article.
Chronological Ordering (CO) algorithm takes input set themes orders
chronologically whenever possible. theme assigned date corresponding
first publication. so, select theme sentence earliest
publication time. call time stamp sentence assign publication time
44

fiSentence Ordering Multidocument News Summarization

time stamp theme. establishes partial order themes. two
themes date (that is, reported first time article)
sort according order presentation article. results total
order input themes. Figures 8 9 show examples summaries produced using
CO.
One four people accused along former Pakistani Prime Minister Nawaz Sharif agreed testify
case involving possible hijacking kidnapping charges, prosecutor said Wednesday.
Raja Quereshi, attorney general, said former Civil Aviation Authority chairman already
given statement police.
Sharifs lawyer dismissed news speaking reporters Sharif made appearance
judicial magistrate hear witnesses give statements him. Sharif said innocent.
allegations stem alleged attempt divert plane bringing army chief General Pervez Musharraf
Karachi Sri Lanka October 12.

Figure 8: summary produced using Chronological Ordering algorithm graded Good.

Thousands people attended ceremony Nairobi commemorating first anniversary
deadly bombings attacks U.S. Embassies Kenya Tanzania.
Saudi dissident Osama bin Laden, accused masterminding attacks, nine others still large.
President Clinton said, intended victims vicious crime stood everything right
country world.
U.S. federal prosecutors charged 17 people bombings.
Albright said mourning continues.
Kenyans observing national day mourning honor 215 people died there.

Figure 9: summary produced using Chronological Ordering algorithm graded Poor.

4.2.2 Evaluation
Following methodology used MO algorithm evaluation, asked three
human judges (not including ourselves) grade 25 summaries generated system
using CO algorithm applied collection input texts. results
shown Figure 13: ten summaries graded Poor, eight graded Fair
seven graded Good.
first suspicion approximation deviates much real chronological order events and, therefore, lowers quality sentence ordering. verify
hypothesis, identified sentences broke original chronological order restored ordering manually. Interestingly, displaced sentences mainly background
information. evaluation modified summaries shows visible improvement.
comparing Good (Figure 8) Poor (Figure 9) summaries, notice two phenomena: first, many badly placed sentences cannot ordered based temporal occurrence. instance, Figure 9, sentence quoting Clinton one event
sequence events described, rather, reaction main events.
tool assigning time stamps would assign sentence date Clinton made
statement. also true sentence reporting Albrights reaction. Assigning
45

fiBarzilay, Elhadad & McKeown

date reaction, generally sentence conveying background information,
placing chronological stream main events produce logical
ordering. ordering themes is, therefore, covered CO algorithm. Furthermore, sentences cannot assigned time stamp. instance, sentence,
vast, sparsely inhabited Xinjiang region, largely desert, many Chinese military
nuclear installations civilian mining. describes state rather event and,
therefore, trying describe temporal terms invalid. Thus ordering cannot
improved temporal level.
second phenomenon observed Poor summaries typically contain abrupt
switches topics generally incoherent. instance, Figure 9, quotes
US officials (third fifth sentences) split, sentences mourning (first
sixth sentences) appear far apart summary. Grouping together would
increase readability summary. point, need find additional constraints
improve ordering.

5. Improving Ordering: Experiments Analysis
previous section, showed using naive ordering algorithms produce
satisfactory orderings. section, investigate experiments humans
identify patterns orderings improve algorithm.
5.1 Collecting corpus multiple orderings
Sentences text ordered number ways, text whole still
convey meaning. majority possible orders likely unacceptable break conventions information presentation. One way identify
conventions find commonalities among different acceptable orderings information. Extracting regularities several acceptable orderings help us specify ordering
constraints given input type. naturally occurring existing collection
summaries multiple documents aware 7 . even collection would
sufficient since want analyze collection multiple summaries set
articles. created collection multiple orderings produced different humans. Using collection, studied common behaviors mapped strategies
ordering.
collection multiple orderings, along test corpus available
http://www.cs.columbia.edu/~noemie/ordering/. collected ten sets articles
collection. set consisted two three news articles reporting event.
set, manually selected intersection sentences, simulating MultiGen 8 .
average, set contained 8.8 intersection sentences. sentences cleaned explicit references (for instance, occurrences President resolved President
Clinton) connectives, participants would use clues ordering.
Ten subjects participated experiment, built one ordering per set
7. recent attempt, NIST DUC conference collected sets articles summarize one
summary per set.
8. performed manual simulation ensure ideal data provided subjects experiments.

46

fiSentence Ordering Multidocument News Summarization

intersection sentences. subject asked order intersection sentences set
form readable text. Overall, obtained 100 orderings, ten alternative
orderings per set. Figure 10 shows ten alternative orderings collected one set.
Participant
Participant
Participant
Participant
Participant
Participant
Participant
Participant
Participant
Participant

1
2
3
4
5
6
7
8
9
10












BGIHFCJAE
GBICFAJEH
BIGFJAEHC
CFGIBJAHE
GBIHFJACE
GIBFCEHJA
BGIFCHEJA
BCFGIEHAJ
GIBEHFAJC
BGICFAJEH

Figure 10: Multiple orderings one set collection. A, B, . . . J stand sentences. Underlined automatically identified blocks.

first observed surprisingly large portion orderings different.
ten sets, two sets identical orderings (in one set, two orderings
identical set, two pairs identical orderings). variety
produced orderings interpreted suggesting orderings
actually valid task maybe hard subjects allow
produce reasonable orderings. fact, subjects satisfied orderings
produced. Furthermore, manually went 100 orderings,
appeared valid. words, many acceptable orderings given one set
sentences. confirms intuition need look single ideal total
ordering rather construct acceptable one.
Looking various orderings, one might also conclude ordering would
well other. One piece evidence statement that,
shown section 2, orderings yield incomprehensible texts thus avoided.
Furthermore, text n sentences, n! possible orderings, small
fraction actually valid orderings. One way validate claim would
enumerate possible orderings single text evaluate one them.
would doable small texts (a text 5 sentences 120 possible orderings)
texts reasonable size. feasible way validate claim get
multiple orderings text large number subjects. asked subjects
order one text eight sentences. maximum 40,320 possible orderings
sentences. 50 subjects participated, obtained 21 unique orderings, showing
number acceptable orderings grow fast number participants.
conclude small fraction possible orderings information
text contains orderings render readable text.
47

fiBarzilay, Elhadad & McKeown

5.2 Analysis
several alternative orderings produced single summary exhibit commonalities.
noticed that, within multiple orderings set, sentences always appear
together. appear order one ordering another,
share adjacency relation. on, refer blocks. set,
identify blocks automatically clustering sentences across orderings. use distance
metric two sentences, average number sentences separate
orderings. Figure 10, instance, distance sentences G 2.
blocks identified clustering are: sentences B, D, G I; sentences J; sentences
C F; sentences E H.
observed blocks experiment correspond clusters topically
related sentences. blocks form units text dealing subject.
words, valid orderings contain blocks topically related sentences. notion
grouping topically related sentences known cohesion. defined Hasan (1984),
cohesion device sticking together different parts text. Studies show
level cohesion direct impact reading comprehension (Halliday & Hasan,
1976). Therefore, good orderings cohesive; makes summary readable.
Conversely, evaluation CO algorithm showed summaries judged
invalid contain abrupt switches topic. words, orderings cohesive
graded poorly. correlation quality ordering cohesion.
Incorporating cohesion constraint ordering strategy opportunistically grouping
sentences together would beneficial. Cohesion achieved surface devices,
repetition words coreferences. describe next include cohesion CO
algorithm based surface features.

6. Augmented Algorithm
Disfluencies arise output CO algorithm topics distributed
whole text, violating cohesion properties (McCoy & Cheng, 1991). typical scenario
illustrated Figure 11. inputs texts 1 , T2 , T3 (ordered publication time). A1 ,
A2 A3 belong theme, whose intersection sentence A, similarly
B C. themes B topically related, C related. Summary 1 ,
based chronological clues, contains two topical shifts; C back
C B. better summary would S2 , keeps B together.
6.1 Algorithm
goal remove disfluencies summary grouping together topically related
themes. main technical difficulty incorporating cohesion ordering algorithm
identify group topically related themes across multiple documents. words,
given two themes, need determine belong cohesion block.
single document, topical segmentation (Hearst, 1994) could used identify blocks,
technique possibility identifying cohesion sentences across multiple
documents. Segmentation algorithms typically exploit linear structure input text;
case, want group together sentences belonging different texts.
48

fiSentence Ordering Multidocument News Summarization

T1

T2

T3

S1

S2

A1
...
C1

C2
...
A2
B2

A3
B3
...
C3





C

B

B

C

Figure 11: Input texts T1 T2 T3 summarized Chronological Ordering (S1 ) Augmented algorithm (S2 ).

solution consists following steps. preprocessing stage, segment
input text (Kan, Klavans, & McKeown, 1998) based word distribution coreference
analysis, given two sentences within text, determine
topically related. Assume themes B exist, contains sentences (A 1 . . . ),
B contains sentences (B1 . . . Bm ). Recall theme set sentences conveying
similar information drawn different input texts. denote #AB number
pairs sentences (Ai , Bj ) appear text, #AB + number
sentence pairs appear text segment.
first stage, pair themes B, compute ratio #AB + /#AB
measure relatedness two themes. measure takes account positive
negative evidence. sentences B appear together
texts also segments, means B highly topically related.
case, ratio close 1. hand, among texts containing sentences
B, pairs segments, B topically
related. Accordingly, ratio close 0. B considered related ratio
higher predetermined threshold. determined experimentally value 0.6.
strategy defines pairwise relations themes. transitive closure
relation builds groups related themes and, result, ensures themes
appear together article related third theme still
linked. creates even higher degree relatedness among themes. use
threshold establish pairwise relations, transitive closure produce elongated
chains could link together unrelated themes. able identify topically
related themes. end first stage, grouped blocks.
second stage, assign time stamp block related themes using
earliest time stamp themes contains. adapt CO algorithm described 4.2.1
work level blocks. blocks themes correspond to, respectively,
themes sentences CO algorithm. analogy, easily show
adapted algorithm produces complete order blocks. yields macro-ordering
summary. still need order themes inside block.
last stage augmented algorithm, block, order themes
contains applying CO algorithm them. Figure 12 shows example summary
produced augmented algorithm.
49

fiBarzilay, Elhadad & McKeown

algorithm ensures cohesively related themes spread text
decreases number abrupt switches topics. Figure 12 shows Augmented
algorithm improves sentence order compared order summary produced
CO algorithm Figure 9; sentences quoting US officials grouped together,
descriptions mourning.
Thousands people attended ceremony Nairobi commemorating first anniversary
deadly bombings attacks U.S. Embassies Kenya Tanzania. Kenyans observing national
day mourning honor 215 people died there.
Saudi dissident Osama bin Laden, accused masterminding attacks, nine others still large.
U.S. federal prosecutors charged 17 people bombings.
President Clinton said, intended victims vicious crime stood everything right
country world. Albright said mourning continues.

Figure 12: summary produced using Augmented algorithm. Related sentences
grouped paragraphs.

6.2 Evaluation
Following methodology used evaluate MO CO algorithms, asked
judges grade 25 summaries produced Augmented algorithm. Results shown
Figure 13.
manual effort needed compare judge system output extensive considering
human judge read three summaries input set well skim
input texts verify misleading information introduced summaries.
collected corpus 25 sets articles evaluation. Overall, 75 summaries
evaluated. size corpus comparable collection used DUC
evaluation (30 sets articles). evaluation shows significant improvement
quality orderings CO algorithm Augmented algorithm. assess
significance improvement, used Fisher exact test, conflating Poor Fair
summaries one category (p-value 0.04). augmented algorithm also shows
improvement MO algorithm (p-value 0.07).

Majority Ordering
Chronological Ordering
Augmented Ordering

Poor
3
10
3

Fair
14
8
8

Good
8
7
14

Figure 13: Evaluation Majority Ordering, Chronological Ordering Augmented Ordering.

50

fiSentence Ordering Multidocument News Summarization

7. Related Work
Finding acceptable ordering studied domain independent text
summarization. single document summarization, summary sentences typically arranged order found full document, although Jing (1998)
reports human summarizers sometimes change original order. multidocument
summarization, summary consists fragments text sentences selected
different texts. Thus, complete ordering summary sentences
found original documents.
domain dependent summarization, possible establish possible orderings
priori. valid ordering traditionally derived manual analysis corpus
texts domain, typically operates set semantic concepts. semantic
representation information usually available input ordering component.
instance, specific domain news topic terrorist attacks, summaries
constructed first describing place attack, followed number
casualties, possible perpetrators are, etc.
Another alternative ordering information, still domain dependent framework, use data driven approach, produces flexible output.
priori defined simple ordering strategies combined together looking set features input. Elhadad McKeown (2001) use techniques produce patient
specific summaries technical medical articles. Examples features influence
ordering presence contradiction repetition, relevance patient characteristics,
type results reported. linear combination features assigns weight
semantic predicate included output, allowing ordered.
case, features domain dependent identified corpus analysis
interviews physicians. case domain independent system, would
entire new challenge define compute set features.
Producing good ordering information also critical task generation community, extensively investigated issue (McKeown, 1985; Moore & Paris, 1993;
Hovy, 1993; Bouayad-Agha, Power, & Scott, 2000; Mooney, Carberry, & McCoy, 1990). One
approach top-down, using schemas (McKeown, 1985) plans (Dale, 1992) determine
organizational structure text. approach postulates rhetorical structure
used select information underlying knowledge base.
domain limited, encoding developed kinds propositional content
match rhetorical elements schema plan, thereby allowing content selected
ordered. Rhetorical Structure Theory (RST) allows flexibility ordering content establishing relations pairs propositions. Constraints based intention
(e.g., Moore & Paris, 1993), plan-like conventions (e.g., Hovy, 1993), stylistic constraints
(e.g., Bouayad-Agha et al., 2000) used preconditions plan operators containing
RST relations determine relation used ordered respect
relations. Another approach (Mooney et al., 1990) bottom-up used group
together stretches text long, generated document finding propositions
related common focus. Since approach developed generation system,
finds related propositions comparisons proposition arguments semantic level.
51

fiBarzilay, Elhadad & McKeown

case, dealing surface representation, find alternative methods
grouping text fragments.
recent approach Duboue McKeown (2001) implemented
automatically estimate constraints information ordering medical domain,
content planning stage. Using collection semantically tagged transcripts written
domain experts, Duboue McKeown (2001) identify basic adjacency patterns contained
within plan, well ordering. MultiGen generates summaries news
topic. unconstrained domain, would impossible enumerate semantics
possible types sentences could match elements schema, plan
rhetorical relations. instance, Duboue McKeown build content planner based
set 29 semantic categories; case, regularity input
information. Furthermore, would difficult specify generic rhetorical plan
summary news. Instead, content determination MultiGen opportunistic, depending
kinds similarities happen exist set news documents. Similarly,
describe ordering scheme opportunistic bottom-up, depending
cohesion temporal connections happen exist selected text.
ordering component takes place content selection information
pipeline architecture, contrast generation systems, usually ordering
content selection come tandem. separation might come cost
good ordering given extracted information, possible go back
content selection extract new information. summarization, content selection driven
salience criteria. believe ordering strategy work different
content selectors, independently salience criteria. Therefore, choose keep
two components, selection ordering, two separate modules.

8. Conclusion Future Work
paper investigated information ordering constraints multidocument summarization news genre. evaluated two alternative ordering strategies, Chronological
Ordering (CO) Majority Ordering (MO). experiments show MO performs well
input texts follow similar organization information. domains
constraint holds, MO would appropriate highly effective strategy.
news genre cannot make assumption; thus appropriate solution.
Chronological Ordering (CO) algorithm provide acceptable solution many
cases, sufficient summaries contain information event based.
experiments, using corpus collected multiple alternative summaries
multiple documents, show cohesion important constraint contributing ordering.
Moreover, also show appropriate ordering information critical allow
easy comprehension summary case possible orderings
information acceptable. developed operational algorithm integrates cohesion
part CO algorithm, implemented part MultiGen summarization
system. evaluation system shows significant improvement summary quality.
paper focused augmenting CO algorithm, believe MO
promising strategy neglected. clear different forms
summarization useful different situations, depending intended purpose
52

fiSentence Ordering Multidocument News Summarization

summary types documents summarized. future work, plan
build approach used DUC 2001 evaluation, developed
summarizer would use different algorithms summary generation depending
type input text. suspect ordering strategies may differ also, depending
type summary. work first investigate whether use augmented
algorithm summary types. algorithm yield good orderings,
investigate corpus analysis summary type specific constraints. suspect
augmented algorithm may apply, instance, biographical summaries, since
information summarized mixture event-based information
chronologically ordered along descriptive information person. unclear
whether apply types summaries summaries different events,
since pieces information may temporally related other. also plan
identify types summaries would benefit using MO algorithm
augmented version (the way CO algorithm augmented cohesion
constraint).

9. Acknowledgments
work partially supported DARPA grant N66001-00-1-8919, Louis Morin
scholarship Viros scholarship. thank Eli Barzilay providing help
experiments interface, Michael Elhadad useful discussions comments,
many voluntary participants experiments. initial work problem
presented Human Language Technologies Conference (San Diego, 2001). also
thank anonymous reviewers HLT JAIR comments.

References
Barzilay, R., McKeown, K., & Elhadad, M. (1999). Information fusion context
multi-document summarization. Proc. 37th Annual Meeting Assoc.
Computational Linguistics.
Bouayad-Agha, N., Power, R., & Scott, D. (2000). text structure incompatible
rhetorical structure?. Proceedings First International Conference Natural
Language Generation (INLG2000), Mitzpe Ramon, Israel.
Carbonell, J., & Goldstein, J. (1998). use mmr, diversity-based reranking reordering documents producing summaries. Proceedings 21st Annual
International ACM SIGIR Conference Research Development Information
Retrieval.
Cohen, W., Schapire, R., & Singer, Y. (1999). Learning order things. Journal Artificial
Intelligence, 10, 243270.
Dale, R. (1992). Generating Referring Expressions: Constructing Descriptions Domain
Objects Processes. MIT Press, Cambridge, MA.
Duboue, P., & McKeown, K. (2001). Empirically estimating order constraints content
planning generation. Proceedings ACL/EACL 2001.
53

fiBarzilay, Elhadad & McKeown

Elhadad, N., & McKeown, K. (2001). Generating patient specific summaries medical
articles. Proceedings NAACL 2001 Workshop Automatic Summarization.
Filatova, E., & Hovy, E. (2001). Assigning time-stamps event-clauses. Proceedings
AACL/EACL 2001 Workshop Temporal Spatial Information Processing.
Galil, Z., & Megido, N. (1977). Cyclic ordering np-complete. Theoretical Compter Science,
5, 179182.
Halliday, M., & Hasan, R. (1976). Cohesion English. Longman.
Hasan, R. (1984). Reading Comprehension, chap. Coherence Cohesive Harmony.
Hatzivassiloglou, V., Klavans, J., & Eskin, E. (1999). Detecting text similarity short
passages: Exploring linguistic feature combinations via machine learning. Proceedings Joint SIGDAT Conference Empirical Methods Natural Language
Processing Large Corpora.
Hearst, M. (1994). Multi-paragraph segmentation expository text. Proceedings
32th Annual Meeting Association Computational Linguistics.
Hovy, E. (1993). Automated discourse generation using discourse structure relations. Artificial Intelligence, 63. Special Issue NLP.
Jing, H. (1998). Summary generation intelligent cutting pasting input
document. Tech. rep., Columbia University.
Kan, M.-Y., Klavans, J., & McKeown, K. (1998). Linear segmentation segment
relevence. Proceedings 6th International Workshop Large Corpora
(WVLC-6).
Lin, C.-Y., & Hovy, E. (2001). Neats: multidocument summarizer. Proceedings
Document Understanding Workshop (DUC).
Mani, I., & Bloedorn, E. (1997). Multi-document summarization graph search
matching. Proceedings Fifteenth National Conference Artificial Intelligence.
Mani, I., & Wilson, G. (2000). Robust temporal processing news. Proceedings
38th Annual Meeting Association Computational Linguistics.
McCoy, K., & Cheng, J. (1991). Focus attention: Constraining said next.
Paris, C., Swartout, W., & Mann, W. (Eds.), Natural Language Generation
Artificial Intelligence Computational Linguistics. Kluwer Academic Publishers.
McKeown, K. (1985). Text Generation: Using Discourse Strategies Focus Constraints
Generate Natural Language Text. Cambridge University Press, England.
McKeown, K., Barzilay, R., Evans, D., Hatzivassiloglou, V., Kan, M., Schiffman, B., &
Teufel, S. (2001). Columbia multi-document summarization: Approach evaluation.
Proceedings Document Understanding Workshop (DUC).
McKeown, K., Klavans, J., Hatzivassiloglou, V., Barzilay, R., & Eskin, E. (1999). Towards
multidocument summarization reformulatin: Progress prospects. Proceedings Seventeenth National Conference Artificial Intelligence.
54

fiSentence Ordering Multidocument News Summarization

Mooney, D., Carberry, S., & McCoy, K. (1990). generation high-level structure
extended explanations. Proceedings International Conference Computational Linguistics (COLING90), pp. 276281, Helsinki.
Moore, J., & Paris, C. (1993). Planning text advisory dialogues: Capturing intentional
rhetorical information. Journal Computational Linguistics, 19 (4).
Radev, D., Jing, H., & Budzikowska, M. (2000). Centroid-based summarization multiple documents: sentence extraction, utility-based evaluation, user studies.
Proceedings ANLP/NAACL 2000 Workshop Automatic Summarization.
Radev, D., & McKeown, K. (1998). Generating natural language summaries multiple
on-line sources. Computational Linguistics, 24(3), 469500.
Schiffman, B., Nenkova, A., & McKeown, K. (2002). Experiments multidocument summarization. Proceedings HLT Conference.
Siegal, S., & Castellan, N. J. (1988). Non-Parametric statistics behavioural sciences.
McGraw Hill.
White, M., Korelsky, T., Cardie, C., Ng, V., Pierce, D., & Wagstaff, K. (2001). Multidocument summarization via information extraction. Proceedings HLT Conference.
Wiebe, J., OHara, T., Ohrstrom-Sandgren, T., & McKeever, K. (1998). empirical
approach temporal reference resolution. Journal Artificial Intelligence, 9, 247
293.

55

fi
