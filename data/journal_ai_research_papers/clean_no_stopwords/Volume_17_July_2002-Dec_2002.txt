Journal Artificial Intelligence Research 17 (2002) 451-499Submitted 12/00; published 12/02Policy Recognition Abstract Hidden Markov Modelbuihh@cs.curtin.edu.ausvetha@cs.curtin.edu.augeoff@cs.curtin.edu.auHung H. BuiSvetha VenkateshGeoff WestDepartment Computer ScienceCurtin University TechnologyPO Box U1987, Perth, WA 6001, AustraliaAbstractpaper, present method recognising agent's behaviour dynamic,noisy, uncertain domains, across multiple levels abstraction. term problemview generally probabilistic inferencestochastic process representing execution agent's plan. contributionspaper twofold. terms probabilistic inference, introduce Abstract HiddenMarkov Model (AHMM), novel type stochastic processes, provide dynamic Bayesiannetwork (DBN) structure analyse properties network. describeapplication Rao-Blackwellised Particle Filter AHMM allows usconstruct ecient, hybrid inference method model. terms plan recognition,propose novel plan recognition framework based AHMM plan executionmodel. Rao-Blackwellised hybrid inference AHMM take advantageindependence properties inherent model plan execution, leading algorithmonline probabilistic plan recognition scales well number levels planhierarchy. illustrates stochastic models plan execution complex,exhibit special structures which, exploited, lead ecient plan recognitionalgorithms. demonstrate usefulness AHMM framework via behaviourrecognition system complex spatial environment using distributed video surveillancedata.on-line plan recognition uncertainty1. IntroductionPlan recognition problem inferring actor's plan watching actor's actionseffects. Often, actor's behaviour follows hierarchical plan structure. Thus,plan recognition, observer needs infer actor's plans sub-plansdifferent levels abstraction plan hierarchy. problem complicated twosources uncertainty inherent actor's planning process: (1) stochastic aspectplan refinement (a plan non-deterministically refined different sub-plans),(2) stochastic outcomes actions (the action non-deterministically resultdifferent outcomes). Furthermore, observer deal third source uncertaintyarising noise inaccuracy observation actor's plan.addition, would like observer able perform plan recognition task \online" observations actor's plan streaming in. refer generalproblem on-line plan recognition uncertainty.c 2002 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiBui, Venkatesh & Westseminal work plan recognition (Kautz & Allen, 1986) considers plan hierarchy,deal uncertainty aspects problem. result, approachpostulate set possible plans actor, unable determineplan probable. Since then, important role uncertainty reasoning planrecognition recognised (Charniak & Goldman, 1993; Bauer, 1994; van Beek, 1996),Bayesian probability argued appropriate model (Charniak & Goldman,1993; van Beek, 1996). dynamic, \on-line" aspect plan recognitionrecently considered (Pynadath & Wellman, 1995, 2000; Goldman, Geib, & Miller, 1999;Huber, Durfee, & Wellman, 1994; Albrecht, Zukerman, & Nicholson, 1998).recent work shares view online plan recognition largely problem probabilisticinference stochastic process models execution actor's plan.view offers general coherent framework modelling different sources uncertainty,stochastic process need deal become quite complex, especiallyconsider large plan hierarchy. Thus, main issue computational complexitydealing type stochastic processes, whether complexity scalablecomplex plan hierarchies.1.1 Aim Significancepaper, demonstrate type plan recognition problems describedscales reasonably well respect number levels abstraction plan hierarchy. contrast common-sense analysis levels planhierarchy would introduce variables stochastic process, turn, resultsexponential complexity w.r.t number levels hierarchy.order achieve this, first assume general stochastic model plan executionmodel three sources uncertainty involved. model planninghierarchy abstraction uncertainty developed recently abstractprobabilistic planning community (Sutton, Precup, & Singh, 1999; Parr & Russell, 1997;Forestier & Varaiya, 1978; Hauskrecht, Meuleau, Kaelbling, Dean, & Boutilier, 1998; Dean& Lin, 1995). advantage, adopt basic model, known abstract Markovpolicies (AMP) 1 model plan execution. AMP extension policyMarkov Decision Processes (MDP) enables abstract policy invokerefined policies policy hierarchy. Thus, AMP similar contingent plan prescribes sub-plan invoked applicable stateworld achieve intended goal, except represent uncertaintyplan refinement outcomes actions. Since AMP described simplyterms state space Markov policy selects among set AMP's, usingAMP model plan execution also helps us focus structure policyhierarchy.execution AMP leads special stochastic process calledAbstract Markov Model (AMM). noisy observation environment state (e.g.,effects action) modelled making state \hidden", similarhidden state Hidden Markov Models (Rabiner, 1989). result interestingnovel stochastic process term Abstract Hidden Markov Model. Intuitively,1. Also known options, policies, supervisor'sAbstract Markov Decision Processes452policies.fiPolicy recognition Abstract Hidden Markov ModelAHMM models AMP causes adoption policies actions differentlevels abstraction, turn generate sequence states observations.plan recognition task, observer given AHMM corresponding actor's planhierarchy, asked infer current policy executed actorlevels hierarchy, taking account sequence observations currently available.amounts reversing direction causality AHMM, i.e. determine setpolicies explain sequence observations hand. shall referproblem policy recognition.Viewing AHMM type dynamic Bayesian network (Dean & Kanazawa, 1989;Nicholson & Brady, 1992), known complexity kind inferencingDBN depends size representation so-called belief state, conditionaljoint distribution variables DBN time given observation sequence(Boyen & Koller, 1998). Thus ask following question: policyhierarchy affect size belief state representation corresponding AHMM?Generally, policy hierarchy K levels, belief state would leastK variables thus size joint distribution would O(exp(K )). However,AHMM specific network structure exhibits certain conditional independenceproperties among variables exploited eciency. first identifyuseful independence properties AHMM show compact representation special belief state case state sequence correctly observed(full observability assumption) starting ending time policy known.Consequently, policy recognition case performed eciently updatingAHMM compact belief state. partial result, although restricted usefulitself, leads important observation general belief state: although cannotrepresented compactly, approximated eciently collection compact special belief states. makes inference problem AHMM particularly amenabletechnique called Rao-Blackwellisation (Casella & Robert, 1996) allows usconstruct hybrid inference methods combine exact inference approximatesampling-based inference greater eciency. application Rao-BlackwellisationAHMM structure reduces sampling space need approximate spacefixed dimension depend K , ensuring hybrid inference algorithm scales well w.r.t K .contributions paper thus twofold. terms stochastic processesdynamic Bayesian networks, introduce AHMM, novel type stochastic processes,provide DBN structure analyse properties network. present application Rao-Blackwellised Particle Filter AHMM results ecienthybrid inference method stochastic model. terms plan recognition, proposenovel plan recognition framework based probabilistic inference using AHMMplan execution model. complexity inference problem addressed applyingrange recently developed techniques probabilistic reasoning plan recognitionproblem. work illustrates stochastic models plan executioncomplex, exhibit certain special structures exploited construct ecientplan recognition algorithms.453fiBui, Venkatesh & West1.2 Structure Papermain body paper organised follows. Section 2 introduces backgroundmaterial dynamic Bayesian networks probabilistic inference. Section 3 formally defines abstract Markov policy policy hierarchy. Section 4 presents AHMM,DBN representation conditional independence properties. algorithms policy recognition discussed Section 5, first special tractable casegeneral case. Section 6 presents experimental results AHMM framework,including real-time system recognising people behaviour complex spatial environment using distributed video surveillance data. Section 7 provides comparative reviewrelated work probabilistic plan recognition. Finally, conclude discuss directionsresearch Section 8.2. Background Probabilistic Inferenceaim section familiarise readers concepts probabilistic inferenceused later paper. subsections 2.1 2.2, discuss BayesianNetworks (BN) Dynamic Bayesian Networks (DBN) general. subsection 2.3,discuss Sequential Importance Sampling (SIS) algorithm, general approximatesampling-based inference method dynamic models. Subsections 2.4 2.5 introduceRao-Blackwellisation, technique improving sampling-based methods utilising certainspecial structures dynamic model. Later on, Rao-Blackwellisation usedkey computational technique performing policy recognition.2.1 Bayesian NetworksBayesian network (BN) (Pearl, 1988; Jensen, 1996; Castillo, Gutierrez, & Hadi, 1997)(also known probabilistic network belief network) well-established frameworkdealing uncertainty. provides graphical compact representation jointprobability distribution set domain variables X1; : : : Xn form directedacyclic graph (DAG) whose nodes correspond domain variables. nodeXi , links parent nodes P a(Xi ) parameterised conditional probability node given parents Pr(Xi j P a(Xi )). network structure togetherparametersencode factorisation joint probability distribution (JPD)QnPr(X1 ; : : : Xn) = i=1 Pr(Xi j P ai). Given Bayesian network, conditional independencestatements form X ? j Z (X independent given Z, X; Y; Z variables sets variables) asserted X d-separated Z networkstructure, d-separation graph separation concept DAGs (Pearl, 1988).network structure BN thus captures certain conditional independence properties amongdomain variables exploited ecient inference.main inference task Bayesian network calculate conditional probabilityset variables given values another set variables (the evidence).two types computation techniques this. Exact inference algorithms (Lauritzen& Spiegelhalter, 1988; Jensen, Lauritzen, & Olesen, 1990; D'Ambrosio, 1993) computeexact value conditional probability required based analytical transformationexploits conditional independence relationships variables network.454fiPolicy recognition Abstract Hidden Markov ModelApproximative inference algorithms (Pearl, 1987; York, 1992; Henrion, 1988; Fung & Chang,1989; Shachter & Peot, 1989) compute approximation required probability,usually obtained either \forward" sampling (Henrion, 1988; Fung & Chang, 1989;Shachter & Peot, 1989) (a variance Bayesian Importance Sampling (Geweke, 1989)),Gibbs (Monte-Carlo Markov-Chain) sampling (Pearl, 1987; York, 1992).algorithms advantages simple implementation, applied typesnetwork, trade accuracy estimates computation resources.known exact inference BN NP-hard respect network size (Cooper,1990), approximate inference, although scales well network size, NP-hardrespect hard-bound accuracy estimates (Dagum & Luby, 1993).light theoretical results, approximate inference useful large networksexact computation intractable, certain degree error probability estimatetolerated application.2.2 Dynamic Bayesian Networksmodel temporal dynamics environment, Dynamic Bayesian Network(DBN) (Dean & Kanazawa, 1989; Nicholson & Brady, 1992; Dagum, Galper, & Horvitz,1992) special Bayesian network architecture representing evolution domain variables time. DBN consists sequence time-slices time-slicecontains set variables representing state environment current time.time-slice Bayesian network, network structure replicatedtime-slice. temporal dynamics environment encoded via network linksone time-slice next. addition, time-slice contain observation nodesmodel (possibly noisy) observation current state environment.Given DBN sequence observations, might want draw predictionsfuture state variables (predicting), unobserved variablespast (smoothing) (Kjaerulff, 1992). problem solved using inference algorithm Bayesian networks described above. However, want revise predictionobservations arrive time, reapplying inference algorithm time observation sequence changes could costly, especially sequence grows. avoid this,need keep joint distribution variables current time-slice, givenobservation sequence date. probability distribution termed belief state(also known filtering distribution) plays important role inferencingDBN. existing inference schemes DBN involve maintaining updatingbelief state (i.e., filtering). new observation received, current belief staterolled one time-slice ahead following evolution model, conditioned newobservation obtain updated belief state.obvious problem approach size belief state needmaintain. noted interaction variables DBNlocalised, variables belief state highly connected (Boyen & Koller, 1998).marginalisation past time-slices usually destroys conditionalindependence current time-slice. size belief state large, exactinference methods like (Kjrulff, 1995) intractable, becomes necessary maintainapproximation actual belief state, either form approximate455fiBui, Venkatesh & Westdistribution represented compactly (Boyen & Koller, 1998), formset weighted samples Sequential Monte-Carlo Sampling methods (Doucet,Godsill, & Andrieu, 2000b; Kanazawa, Koller, & Russell, 1995; Liu & Chen, 1998).simple case DBN where, time-slice, single statevariable observation node, well-known Hidden Markov Model (HMM) (Rabiner, 1989). Filtering simple structure solved using dynamic programming discrete HMM (Rabiner, 1989), Kalman filtering linear Gaussianmodel (Kalman, 1960). recently, extensions HMM multiple hidden interacting chains Coupled Hidden Markov Models (CHMM) FactorialHidden Markov Models (FHMM) proposed (Brand, 1997; Ghahramani & Jordan,1997; Jordan, Ghahramani, & Saul, 1997). models, size belief stateexponential number hidden chains. Therefore, inference parameter estimation problems become intractable number hidden chains large. reason,approximate techniques required. CHMM (Brand, 1997) employs deterministic approximation approximates full dynamic programming keeping fixed number\heads" highest probabilities. \heads" thus chosen deterministically ratherrandomly sampling-based methods. FHMM (Ghahramani & Jordan, 1997; Jordan et al., 1997) uses variational approximation (Jordan, Ghahramani, Jaakkola, & Saul,1999) approximates full FHMM structure sparsified tractable structure.idea similar structured approximation method (Boyen & Koller, 1998).AHMM viewed type Coupled/Factorial HMM since AHMMalso consists number interacting chains. However type interactionAHMM different types interaction considered (Brand,1997; Jordan et al., 1997; Ghahramani & Jordan, 1997). main focusAHMM dynamics temporal abstraction among chains, rathercorrelation time interval. addition, node AHMMspecific meaning (policy, state, policy termination status), linksclear causal interpretation based policy selection persistence model.contrast Coupled/Factorial HMM nodes links usuallyclear semantic/causal interpretation. advantage prior knowledgetemporal decomposition abstract process incorporated AHMMnaturally.2.3 Sequential Importance Sampling (SIS)Sequential Importance Sampling (SIS) (Doucet et al., 2000b; Liu & Chen, 1998), alsoknown Particle Filter (PF), general Monte-Carlo approximation scheme dynamicstochastic models. principle, SIS method so-called BayesianImportance Sampling (BIS) estimatorR static case (Geweke, 1989). Supposewant estimate quantity f = f (x)p(x)dx, i.e., mean f (x) x randomvariable density p. Note f taken identity function eventf simply Pr(A). Let q(x) arbitrary2 density function, termed importancedistribution. Usually, importance distribution q chosen easy obtain2. weight properly defined, support q subset support p.456fiPolicy recognition Abstract Hidden Markov Modelrandom samples it. expectation estimation rewritten as:R [f (x)p(x)=q(x)]q(x)dx Eq f (x)p(x)=q(x)f = R[p(x)=q(x)]q(x)dx = Eq p(x)=q(x)expression, BIS estimator w.r.t q obtained:f f^BIS =1NPNi=1 f (x(i))w_ (x(i) ) XN= f (x(i))w~(x(i) )1 PN w_ (x(i) )i=1i=1Nfx(i) g N i.i.d samplesPtaken q(x), w_ (x) = p(x)=q(x) w~normalised weight w~(x(i) ) = w_ (x(i) )= w_ (x(i) ). Note normalised weightcomputed weight function w(x) / w_ (x), i.e., weight function needcomputed normalising constant factor. Rdynamic case, want estimate f = x~t f (~xt)p(~xt jo~t ) x~t = (x0 ; : : : ; xt )o~t = (o0; : : : ; ot ) two sequences random variables; ot represents observationavailable us time t. Often, (~xt ) Markov sequence ot observation xtHMM. DBN, xt corresponds set state variables ot correspondsset observations time-slice t. SIS method presented however appliesgeneral case (~xt ) non-Markov, ot depends xt.introduce importance distribution q(~xt jo~t ) obtain estimator:f f^SIS=NXf (~x(i) )w~ (~x(i) )i=1(1)ensure obtain sample q(~xtjo~t ) \online", i.e., sample new valuext sequence x~t current observation ot arrives, q must restrictedform:q(~xt jo~t ) = q(~xt 1 jo~t 1 )q(xt jx~t 1 ; o~t )restriction q, use weight function w(~xt ) = p(~xt ; o~t )=q(~xt jo~t )weight also updated \online" using:w(~xt ) = w(~xt 1 )p(xt ; ot jx~t 1 ; o~t 1 )=q(xt jx~t 1 ; o~t )(2)Let wt = w(~xt )=w(~xt 1 ) weight updating factor time t, qt = q(xt jx~t 1 ; o~t )sampling distribution used time t. (2)wt qt = p(xt ; ot jx~t 1 ; o~t 1 )(3)means p(xt ; ot jx~t 1 ; o~t 1 ) factorised two parts: wt qt . choosing different factorisations, obtain different forms qt thus different importantdistributions q. example, (~xt ; o~t ) HMM, qt chosen p(xt jxt 1 )wt = p(ot jxt ) likelihood weighting (LW) method, qt chosenp(xt jxt 1 ; ot ) wt = p(ot jxt 1 ) likelihood weighting evidence reversal (LW-ER) (Kanazawa et al., 1995). general, \forward" qt chosenp(xt jx~t 1 ; o~t 1 ) corresponding weight wt = p(ot jx~t ; o~t 1 ). \optimal" qt ,457fiBui, Venkatesh & Westsense discussed (Doucet et al., 2000b), chosen qt = p(xtjx~t 1 ; o~t )associating wt = p(ot jx~t 1 ; o~t 1 ).general SIS approximation scheme thus follows. time 1, maintain Nsample sequences fx~(ti)1 g N corresponding weight values fw(i) g. currentobservation ot arrives, sequence x~(ti)1 lengthened new value x(ti) sampleddistribution q(xt jx~(ti)1 ; o~t ). weight value x~(ti) updated using (2).new samples new weights obtained, expectation functional festimated using (1). procedure furthered enhanced re-sampling stepMarkov-chain sampling step (see Doucet et al. (2000b), Doucet, de Freitas, Murphy,Russell (2000a)). describe important improvements SIS here.32.4 Rao-BlackwellisationRao-Blackwellisation general technique improving accuracy sampling methodsanalytically marginalising variables sampling remainder (Casella &Robert, 1996). simplest form, consider problem estimating expectationE f (x), x joint product twoP variables r; z. Using direct Monte-Carlo sampling, obtain estimator: f^ = N1 N1 f (r(i); z(i) ). Alternatively, Rao-Blackwellisedestimator derived sampling variable r, variable zintegrated analytically:NXE f (r; z) = Er h(r) f^RB = N1 h(r(i) )1h(r) = Ez [f (r; z)jr]. convenience, r referred Rao-Blackwellisingvariable.Rao-Blackwellised estimator f^RB generally accurate f^number samples N . direct consequence Rao-Blackwell theoremgives relationship unconditional conditional variance:VAR X = VAR[E[X jY ]] + E[VAR[X jY ]]applying problem estimating E f (r; z), have:VAR f (r; z) = VAR[E[f (r; z)jr]] + E[VAR[f (r; z)jr]]thus VAR f (r; z) VAR[E[f (r; z)jr]] = VAR h(r). suggests direct MonteCarlo sampling, error RB-sampling (sample r marginalise z) alwayssmaller error sampling r z number samples, exceptdegenerated case. Bayesian Importance Sampling, using variance convergenceresult (Geweke, 1989), one also easily prove number samples tendinfinity, RB-BIS would generally better BIS number samples.3. Note improvements used orthogonal Rao-Blackwellisation procedure discussedsubsequently. implementation policy recognition algorithm later sections includere-sampling step, crucial keeping error SIS time control.458fiPolicy recognition Abstract Hidden Markov Model2.5 SIS Rao-Blackwellisation (RB-SIS)Since SIS form BIS, Rao-Blackwellisation also used improve performance (Liu & Chen, 1998; Doucetet al., 2000b). Let us consider problemRestimating expectation f = f (~xt)p(~xt jo~t ), variable xt joint producttwo variables (zt ; rt ). shall restrict case x~t Markovot observation xt , i.e., (~xt ; o~t ) represented DBN. addition,consider f depends current variable xt , i.e., f expectationfiltering distribution p(xt jo~t ). example, \future" event, i.e., eventRdepends fxt0 jt0 tg, estimate p(Ajo~t ) letting f (xt) = p(Ajxt )f = xt p(Ajxt )p(xt jo~t ) = p(Ajo~t ).R f (zt; rt)p(ztjr~t; o~t),Applying Rao-Blackwellisationsetting,leth(~r)=ztRf = h = r~t h(~rt )p(~rt jo~t ). Thus, use SIS estimate h , also obtainestimator f:Nf f^RBSIS = h^ SIS = X h(~rt(i) )w~(~rt(i) )(4)i=1benefit increase accuracy estimator,need sample variables r~t . side sample r~t , needcompute h(~rt ) using exact inference method. Furthermore, SIS procedureestimate h might require additional complexity since sequence r~t generally nonMarkov, ot longer depends rt . Overall, comparison normal SISestimator f^SIS (Eq. 1), number samples N , f^RBSIS accuratealso computationally demanding compute.see clearly involved implementing RB-SIS method, let us lookRao-Blackwellised belief state, i.e., belief state dynamic processRao-Blackwellising variables observed: Rt = p(zt ; rt ; ot jr~t 1 ; o~t 1 ) posteriorRt+ = p(zt jr~t ; o~t ). entities needed RB-SIS procedure computedtwo distributions. Indeed, functional h rewritten terms Rt+ as:h(~rt ) =Zztf (zt ; rt )p(zt jr~t ; o~t ) =Zztf (zt ; rt )Rt+ (zt )addition, performing SIS estimate h , Eq. (3), weightsampling distribution qt computed Rt :wt qt = p(rt ; ot jr~t 1 ; o~t 1 ) = Rt (rt ; ot ) =ZztRt (zt ; rt ; ot )(5)wt(6)Thus, computing RB belief state Rt posterior Rt+ essential stepRB-SIS method. Since maintain RB belief state sampleRB variables r~t, crucial done eciently using exact inferencemethod. xt composed many variables, case DBN, choiceRao-Blackwellising variables Rao-Blackwellised belief statemaintained tractable way. Hence, Rao-Blackwellisation especially usefulset variables DBN split two parts conditioning first partmakes structure second part tractable amenable exact inference.459fiBui, Venkatesh & WestBegin= 0; 1; : : :sample = 1; : : : ; NSample rti Rti (rt jot )Update weight w = w Rti (ot)Compute posterior RB bel state Rti = Rti (ztjrti ; ot)Compute new RB belief state Rti RtiCompute h RtiCompute estimator f^RBSIS = PNi h w~End( )( )( )( )( )( )+( )( )( )+1( )+=1( )( )( )+( )Figure 1: RB-SIS general DBNgeneral RB-SIS algorithm given Fig. 1. illustrating purpose, assume\optimal" qt corresponding wt used (qt = Rt (rt jot ) wt =Rt (ot )). time point, need maintain N samples r~t(i) , = 1; : : : ; N .sample, addition sample weight w(i) , also need store representationRB belief state corresponding sample sequence: R(ti) = p(rt; zt ; ot jr~t(i)1 ; o~t 1 )R(t+i) = p(zt jr~t(i) ; o~t ).number applications RB-SIS method (also known Rao-BlackwellisedParticle Filter (RBPF)) discussed literature. general frameworkusing RB-SIS inference DBNs presented Doucet et al. (2000a), Murphy(2000), Murphy Russell (2001). However, authors mainly focusedcase sequence Rao-Blackwellising variables (~rt ) Markov (for example,RB variables root nodes time slice). assumption simplifiessampling step RB procedure since obtaining sample RB variabletime + 1 straightforward. previous work (Bui, Venkatesh, & West, 2000),introduced hybrid-inference method AHMM special case statespace decomposition policy hierarchy, essentially RB-SIS method. Noteapplied AHMMs, sequence Rao-Blackwellising variables usesatisfy Markov property. case, care must taken design ecient samplingstep, especially sampling distribution next RB variabletractable form. use non-Markov RB variables also appears special modelsBayesian missing data model (Liu & Chen, 1998), partially observedGaussian state space model (Andrieu & Doucet, 2000) RB belief statemaintained Kalman filter.Since make Rao-Blackwellised belief state tractable, context variables framework context-specific independence (Boutilier, Friedman, Goldszmidt,& Koller, 1996) used conveniently Rao-Blackwellising variables (Murphy, 2000).Indeed, since context variable acts mixing gate different Bayesian network structures, conditioning variables would simplify structure remaining vari-460fiPolicy recognition Abstract Hidden Markov Modelables. property context variables, Boutilier et al. (1996) suggesteduse cut-set variables cut-set conditioning inference method (Pearl,1988). cut-set variables play similar role Rao-Blackwellising variableshelp simplify structure remaining network. Rao-Blackwellised sampling, instead summing possible values cut-set variablesintractable, number representative sampled values used.idea combining exact approximate inference RB sampling alsosimilar hybrid inference scheme described Dawid, Kjrulff, Lauritzen (1995),however it's unclear RB sampling described using model communicatingbelief universe. Also, Dawid et al. use hybrid inference mainly inference networksmixture continuous discrete variables, opposed RB whose goalimprove sampling performance.3. Abstract Markov Policiessection, formally introduce AMP concept originating literatureabstract probabilistic planning MDPs (Sutton et al., 1999; Parr & Russell, 1997;Forestier & Varaiya, 1978; Hauskrecht et al., 1998; Dean & Lin, 1995). main motivationabstract probabilistic planning scale MDP-based planning problems largestate space. noted hierarchical organisation policies help reducecomplexity MDP-based planning, similar role played plan hierarchyclassical planning (Sacerdoti, 1974). comparison classical plan hierarchy,policy hierarchy model different sources uncertainty planning processstochastic actions, uncertain action outcomes, stochastic environment dynamics.work planning concerned finding optimal policy givenreward function, work focuses policy recognition inverse problem, i.e.,infer agent's policies watching effects agent's actions. two problemshowever share common element model stochastic plan hierarchy. policyrecognition, although possible derive information reward functionobserving agent's behaviour, choose this, thus omitting modelreward function also optimality notion. leaves model open trackingarbitrary agent's behaviours, regardless whether optimal not.3.1 General Model3.1.1 Actions PoliciesMDP, world modelled set possible states , termed state space.state s, agent set actions available, action a, employed,cause world evolve next state s0 via transition probability (s; s0). agent'splan actions modelled policy prescribes agent would choose actionstate. policy , modelled selection function : ! [0; 1]state s, (s; a) probability agent choose action a.easy see that, given fixed policy P, resulting state sequence Markov chain0transition probabilities Pr(s j s) = (s; a)a (s; s0). Thus, policy alsoviewed Markov chain state space.461fiBui, Venkatesh & West3.1.2 Local Policiesoriginal MDP, behaviours modelled two levels: primitive actionlevel, plan level (policy). would like consider policies selectrefined policies on, number abstraction levels. idea formintermediate-level abstract policies policies defined local region state space,certain terminating condition, invoked executed like primitiveactions (Forestier & Varaiya, 1978; Sutton et al., 1999).Definition 1 (Local policy). local policy tuple = hS; D; fi; where:set applicable states.set destination states. fi : ! (0; 1] stopping probabilitiesfi (d) = 1; 8 2 n .: ! [0; 1] selection function. Given current state s, (s; a)probability action selected policy state s.set models local region policy applicable. calledset applicable states, since policy start state . shall assumediscrete, thus shall concerned technical details generalisingAHMM formulation continuous state space case. stopping conditionpolicy modelled set possible destination states set positive stoppingprobabilities fi (d); 2 fi (d) probability policy terminatecurrent state d. possible allow policy stop state outside, however, 2 n enforce condition fi (d) = 1, i.e., terminaldestination state. Sometimes, might want consider policies deterministicstopping condition. case, every destination terminal destination: 8d 2 D,fi (d) = 1. Thus, deterministically terminating policy, ignore redundantparameter fi , need specify set destinations D.Given starting state 2 , local policy defined generates Markov sequence states according transition model. time destination state 2reached, process stops probability fi (d). Since process starts within ,terminates one states D, destination states play rolepossible exits local region state space.want make clear policy currently referred to, shall usesubscripted notations , , fi , denote elements policy .Fig. 2 illustrates local policy visualised. Fig. 2(a) shows setapplicable states , set destinations D, chain starting within terminatingD. Bayesian network Fig. 2(b) provides detailed view chain startfinish. Bayesian network Fig. 2(c) abstract view chaininterested starting stopping states.3.1.3 Abstract Policieslocal policy defined selects among set primitive actions. Similarly,generally, define higher level policies select among set policies.462fiPolicy recognition Abstract Hidden Markov Model012(a)(b)(c)Figure 2: Visualisation policyDefinition 2 (Abstract Policy).Let set abstract policies. abstractpolicy policies tuple hS ; ; fi ; where:[2S set applicable states.[2D set destination states. fi : ! (0; 1] set stoppingprobabilities.: ! [0; 1] selection function (s; ) probabilityselects policy state s.Note recursiveness definition 2 allows abstract policy select among setabstract policies. base level, primitive actions viewed abstract policiesthemselves. Since primitive actions always stop one time-step, Da Sa fi (d) =1 8d 2 Da (Sutton et al., 1999). idea policies suitable stopping conditionviewed primitive actions first made explicit (Sutton, 1995),also introduces fi model representing stopping probabilities. subsequentwork (Sutton et al., 1999) introduces abstract policy concept name options.execution abstract policy follows. Starting state s,selects policy 2 according distribution (s; :). selected policyexecuted terminated state 2 . also destination state(d 2 ), policy stops probability fi (d). still continues, new policy0 2 selected d, executed termination (Fig. 3).remarks representation abstract policy needed here. Let2 [2 , denote subset policies applicable (s) =f 2 j 2 g. abstract policy well-defined, make surestate s, selects among policies applicable s. Thus,selection function (s; ) > 0 2 (s). helps keepspecification selection function manageable size, even setpolicies chosen large. addition, specification selectionfunction stopping probabilities make use factored representations (Boutilier,Dearden, & Goldszmidt, 2000) case state space composite setrelatively independent variables. ensures still compact specification463fiBui, Venkatesh & WestFigure 3: chain generated abstract policyprobabilities conditioned state variable, even though state spacehigh dimension.3.1.4 Policy HierarchyUsing abstract policies building blocks, construct hierarchy abstractpolicies follows:Definition 3 (Policy hierarchy). policy hierarchy sequence H = (0 ; 1 ; : : : ; K )K number levels hierarchy, 0 set primitive actions,k = 1; : : : ; K , k set abstract policies policies k 1 .top-level policy K executed, invokes sequence level-(K-1) policies,invokes sequence level-(K-2) policies on. level-1 policy invokesequence primitive actions leads sequence states. Thus, executionK generates overall state sequence (s0; s1 ; : : : ; st ; : : :) terminates onedestination states DK . K = 1 sequence simply Markov chain (withsuitable stopping conditions). However, K 2, generally non-Markovian,despite fact policies Markov, i.e., select lower level policiesbased solely current state (Sutton et al., 1999). knowing currentstate st alone provide information current intermediate-level policies,affect selection next state st+1. Intuitively, means agent'sbehaviour achieve given goal usually non-Markovian, since choice actionsdepends current state, also current intermediate intentionsagent.term dynamical process executing top-level abstract policy K AbstractMarkov Model (AMM). states partially observable, observationmodelled usual observation model Pr(ot j st ) = !(st; ot ). resulting processtermed Abstract Hidden Markov Model (AHMM) since states hiddenHidden Markov Model (Rabiner, 1989).idea higher level policy controlling lower level ones MDPtraced back work Forestier Varaiya (1978), investigated twolayer structure similar 2-level policy hierarchy deterministic stopping condition.Forestier Varaiya showed sub-process, obtained sub-sampling state464fiPolicy recognition Abstract Hidden Markov Model(a)(b)Figure 4: environment partitionsequence time level-1 policy terminates, also Markov, thus policieslevel 1 simply play role \extended" action. framework, given policyhierarchy, one consider \lifted" model policies level kobservations time points policy level k ends considered. level-kpolicies considered primitive actions, lifted model treatedlike normal model.3.2 State-Space Region-Based Decompositioncases, state space dimensions already exhibit natural hierarchicalstructure. example, spatial domain, set ground positions dividedsmall local spaces rooms, corridors, etc. set local spacesgrouped together form larger space higher level ( oors, buildings, etc).intuitive often-used method constructing policy hierarchy case viaso-called region-based decomposition state space (Dean & Lin, 1995; Hauskrechtet al., 1998). Here, state space successively partitioned sequence partitionsPK ; PK 1; :::P1 corresponding K levels abstraction, PK = fS g coarsestpartition, P1 finest. region Ri Pi, periphery Ri , P er(Ri)defined set states Ri, connected state Ri. Let P eriset peripheral states level i: P eri = [Ri2Pi P er(Ri ). Fig. 4(b) shows examplestate space representing building partitioned 4 regions corresponding4 rooms. peripheral states region shown Fig 4(a), Fig 4(b) showsperipheral states.construct policy hierarchy, first define region R1 2 P1 set abstractpolicies applicable R1 , P er(R1) destination states. example,room Fig 4, define set policies model agent's different behavioursinside room, e.g., getting particular door. policiesinitiated inside room, terminate agent steps room(not necessarily target door since policy might fail achieve intended465fiBui, Venkatesh & Westtarget). Note since P er(R1 ) \ R1 = ;, policies defined mannerdeterministic stopping conditions.Let set policies defined 1. higher level P2 , region R2 ,define set policies model agent's behaviours inside regionapplicable state space R2 , destination set P er(R2 ), constraint policiesmust use policies previously defined level-1 achieve goals. examplepolicy navigate room-doors get one building gate another. Letset policies defined level 2. Continuing higher levels,obtain policy hierarchy H = (0 ; 1 ; 2 ; : : : ; K ). policy hierarchy constructedState-space Region-based Decomposition termed SRD policy hierarchy.SRD policy hierarchy property set applicable statespolicies given abstraction level forms partition state space. Thus, statesequence (s0 ; : : : ; st ; : : :) resulting execution top level policy, inferexact starting terminating times intermediate-level policies. example,level k, starting/stopping times policies level time indices t'sstate sequence crosses region boundary: st 1 2 Rk st 62 Rkregion Rk partition Pk . Later section 5.1, show property helpssimplify complexity policy recognition problem.3.3 Policy Hierarchy Exampleexample, consider task monitor predict movement agentbuilding shown Fig. 5(a). room represented 5 5 grid, two adjacentrooms connected via door center common edge. four entrancesbuilding labeled north (N), west (W), south (S) east (E). addition, doorcenter building (C) acts like entrance building's north wingsouth wing. state (cell), agent move 4 possible directions exceptblocked wall.policy hierarchy model agent's behaviour environment constructed based region-based decomposition three levels abstraction. Firstly, regionhierarchy constructed. partition environment consists 8 rooms level 1,two wings (north south) level 2, entire building level 3. behavioursagent level 1 (within room) represented set level 1 policies.example, room, use 4 level-1 policies model agent's behaviours exitingroom via 4 different doors. essentially four Markov chains within roomterminate outside room. One way represent policies specifymovement action agent take given current position current heading.higher level, agent's behaviours within wing specified. example,use 3 level-2 policies wing model agent's behaviours exiting wingvia 3 wing exits. policies built top set level-1 policies alreadydefined. specify level-1 policies agent take leave wingintended exit. Finally, top level, agent's behaviours within entire buildingspecified. example, use 4 top-level policies model agent's behavioursleaving building via four building exits N, W, S, E. sample policiesparameters given Fig. 5(b).466fiPolicy recognition Abstract Hidden Markov ModelNLevel 1 Policy. (Destination right)Level 2 Policy (current state: W, destination : C)0.8W0.3Go rightdoor (level 1 policy)0.20.10.5RightEGo backdoor (level 1 policy)0.1CWRightdoorBackdoorLevel 3 (current state: W, destination: E)0.9Prior toplevel policyGo C (level 2 policy)N: 0.25, S: 0.25, E: 0.25, W: 0.25W0.1Go (level 2 policy)(a) environment(b) Parameters AHMMFigure 5: example policy hierarchy3.4 AMM Plan Execution Modelnow, presented AMM formal plan execution model used laterplan recognition process. subsection, discuss expressivenessAMM formal plan specification language, also suitability using AMMencode plans context plan recognition. Note discussion focusesrepresentational aspect AMM alone. discussion computational aspectsAMM/AHMM comparison works probabilistic plan recognitionpresented Section 7.AMM particularly well-suited representing goal-directed behaviours different levels abstraction. policy AMM viewed plan tryingachieve particular goal. However, unlike classical plan, policy specifies courseactions applicable states, similar contingent plan. endingpolicy could either means goal achieved, attempt achievegoal using current policy failed. interpretation persistence policyfits persistence model intentions (Cohen & Levesque, 1990): intentionends, guarantee intended goal achieved. Thus, conceptually,two types destination states: one corresponds intended goal states,corresponds unintended failure states resulting stochastic natureexecution plan. Due generality, AMM need distinguish two types; successful termination states unsuccessful onestreated possible destination states, albeit different reaching probabilities.44. One would expect agent would likely reach intended destination state ratherrandom failure state.467fiBui, Venkatesh & WestUsing AMM model plan execution thus allows us blur differenceplanning re-planning. time, moves recognitionclassical plan towards recognition agent's intention. existingframework probabilistic plan recognition explicitly represent current state,thus, relationship states adoption termination current plansignored (Goldman et al., 1999).5 Thus, would impossible tell current planfailed new plan attempt recover failure, current plansucceeded new plan part new higher level goal.expressive language describing abstract probabilistic plan HierarchicalAbstract Machines (HAM) proposed (Parr & Russell, 1997; Parr, 1998). HAM,abstract policy replaced stochastic finite automaton, call machineslower level. abstract policies written machines type.machine would choose one machines correspond policies lower levelgo back start state called machines terminated. HAMframework allows machines arbitrary finite number machine states transitionprobabilities,6 thus readily represent complex plans concatenationpolicies, alternative policy paths, etc. possible represent machine HAMpolicy AMM, however cost augmenting state space includemachine states machines current call stack. Thus, sizeAMM's new state space would exponential respect number nested levelsHAM's call stack. shows theory expressiveness HAMpolicy hierarchy same, performing policy recognition HAM-equivalent policyhierarchy probably unwise since state space becomes exponentially largeconversion. better idea would represent internal state machinevariable DBN perform inference DBN structure directly.AMM also closely related model probabilistic plan recognition calledProbabilistic State-Dependent Grammar (PSDG), independently proposed (Pynadath,1999; Pynadath & Wellman, 2000). PSDG described ProbabilisticContext Free Grammar (PCFG) (Jelinek, Lafferty, & Mercer, 1992), augmentedstate space, state transition probability table terminal symbol PCFG.addition, probability production rule made state dependent. result,terminal symbol acts like primitive actions non-terminal symbol choosesexpansion depending current state. Interestingly, PSDG directly relatedHAM language described above, similar way production-rule grammars relatedfinite automata. Given PSDG, convert equivalent HAM constructingmachine non-terminating symbol, modelling production rulesnon-terminating symbol automaton.policy hierarchy equivalent special class PSDG productionrules form X ! X X ! ; allowed. former rule models adoptionlower level policy higher level policy X , latter models terminationpolicy X . PSDG model considered (Pynadath, 1999; Pynadath & Wellman,2000) allows general rules form X ! Y1 : : : YmX , i.e., recursion symbol5. exceptions (Goldman et al., 1999; Pynadath & Wellman, 2000) discusseddetail Section 7.6. constraint recursion calling stack keep stack finite.468fiPolicy recognition Abstract Hidden Markov Modelmust located end expansion. Thus PSDG, policy might expandedsequence policies lower level executed one anothercontrol returned higher level policy. implicit assumptionpolicy sequence terminates, always state next policysequence applicable. Given assumption, language AHMM definecompound policy k policy simply orderly executes sequence policiesk 1 ; : : : ; k 1 , independent current state. PSDG equivalentlower level (1)(m)AHMM compound policies form allowed.Since AMM closely follows models used abstract probabilistic planning,used model recognise behaviours autonomous agent whose decisionmaking process equivalent abstract MDP. also useful formal languagespecifying contingent plans whose execution monitored using policyrecognition algorithm. language also rich enough specify range useful humanbehaviours, especially domains natural hierarchical decompositionstate space. Section 6 presents application AHMM framework problemrecognising people behaviours complex spatial environment. Here, policyAHMM represents evolution possible trajectories people movementperson performs certain task environment heading towards door, usingcomputer certain location, etc. policies different levels would representevolution trajectories different levels abstraction. Due existing hierarchydomain, policies constructed using region-based decompositionstate space. environment populated multiple cameras divided differentzones provide current location tracking target, albeit noisy one.noisy observations readily handled observation model AHMM.policy recognition algorithm applied infer person's current policydifferent levels hierarchy.One main restriction current AHMM model consider one toplevel policy time, thus unable model inter-leaving concurrent plans.Another subtle restriction assumption high level policy selects lowerlevel policies depending current state. state space interpretedstates external environment, assumption implies actor either fullobservation current state, least refines intentions based actor'sobservation current state (and entire observation history). Noterestrictions AHMM also apply case PSDG model.4. Dynamic Bayesian Network Representationsection, describe Dynamic Bayesian Network (DBN) representationAHMM. network serves two purposes: (1) tool derive probabilistic independence property stochastic model, (2) computational frameworkpolicy recognition algorithms Section 5.4.1 Network Constructiontime t, let st represent current state, tk represent current policy level k(k = 0; : : : ; K ), ekt represent ending status tk , i.e., boolean variable indicating469fiBui, Venkatesh & Westkkkekekek =Fe k-1e k-1 =Tek-1 =F(a)(b)(c)Figure 6: Sub-network policy terminationwhether policy tk terminates current time. variables would makecurrent time-slice full DBN. convenience, notation tall refers setcurrent policies ftK ; : : : ; t0 g. presenting full network, first describetwo sub-structures model policies terminated selected. full DBNeasily constructed sub-structures.4.1.1 Policy Terminationdefinition abstract policies, level-k policy tk terminates lower levelpolicy tk 1 terminates, so, tk terminates probability fitk (st). Bayesiannetwork representation, terminating status ekt therefore three parent nodes: tk , st ,etk 1 (Fig. 6(a)).parent variable ekt 1 however plays special role. ekt 1 = , meaning lowerlevel policy terminates current time, Pr(ekt = j tk ; st) = fitk (st) givesconditional probability ekt given two parent variables (Fig. 6(b)). However,ekt 1 = F , tk terminate ekt = F . Therefore, given ekt 1 = F , ektdeterministically determined independent two parent variables tkst . Using notion context-specific independence (CSI) (Boutilier et al., 1996),safely remove links two parents ekt context ekt 1false (Fig. 6(c)).bottom level, since primitive action always terminates immediately, e0t =t. Since modelling execution single top-level policy K , assumetop-level policy terminate remains unchanged: eKt = F tK = Kt. Also, note elt = ) ekt = k l, elt = F ) ekt = F k l.Thus, time t, exists 0 lt < K ekt = k lt , ekt = Fk > lt . variable lt termed highest level termination time t. Knowingvalue lt equivalent knowing terminating status current policies.4.1.2 Policy Selectioncurrent policy tk general dependent higher level policy tk+1, previousstate st 1 , previous policy level tk 1 ending status ekt 1 .Bayesian network, tk thus four variables parents (Fig. 7(a)). depen-470fiPolicy recognition Abstract Hidden Markov Modelk+1kprevkkeprevk+1kprevk(a)kprevek = Fek =Tsprevsprevprevsprevk+1kprev(b)(c)Figure 7: Sub-network policy selectiondency broken two cases, depending value parentnode ekt 1 .previous policy terminated (ekt 1 = F ), current policyprevious one: tk = tk 1 , variable tk thus independent tk+1 st 1 .Therefore, context ekt 1 = F , two links tk+1 st 1 current policyremoved, two nodes tk tk 1 merged together (Fig. 7(b)).previous policy terminated (ekt 1 = ), current policy selectedhigher level policy probability Pr(tk j tk+1; st 1 ) = tk+1 (st 1 ; tk ). context, tkindependent tk 1 corresponding link Bayesian network removed(Fig. 7(c)).4.1.3 Full DBNfull dynamic Bayesian network constructed policy, ending status,state variables putting sub-networks policy termination selection together(Fig. 8). top level, since eKt = F , remove ending status nodes mergetK single node K . base level, since e0t = , remove endingstatus nodes also links t0 t0+1. model observation hiddenstates, observation layer attached state layer shown Fig. 8.Suppose given context variable ekt known.modify full DBN using corresponding link removal node merging rules.result intuitive tree-shaped network Fig. 9, policy nodescorresponding policy entire duration grouped one. groupingdone since knowing value ekt equivalent knowing exact durationpolicy hierarchy. One would expect performing probabilistic inferencestructure simple full DBN Fig. 8. particular,state sequence known, remainder network Fig. 9 becomes singly-connected,i.e., directed graph undirected cycles, allowing inference performedcomplexity linear size network (Pearl, 1988). policy recognition algorithmsfollow later exploit extensively particular tractable case AHMM.471fiBui, Venkatesh & WestKLevel KPolicy2Stop statuse2Policy1Stop statuse1Action0StateObservationFigure 8: DBN representation Abstract Hidden Markov Model43...2...1................................................Figure 9: Simplified network duration policy known (action nodesomitted clarity)472fiPolicy recognition Abstract Hidden Markov Model4.2 Conditional Independence Current Time-Slicediscussion identifies tractable case AHMM, requires knowledgeentire history state policy ending status variables. subsection,focus conditional independence property nodes current time-slice:st ; t0 ; : : : ; tK . Since nodes make belief state future inferencealgorithm AHMM, independence properties among variables, exploited,provide compact representation belief state reduce inferencecomplexity.Due way policies invoked AMM, make intuitive remarkhigher level policies uence happens lower levelcurrent level. precisely, level k policy tk , know starting state, courseexecution fully determined, determined means without uencehappening higher levels. Furthermore, also know longpolicy executed, equivalently starting time, current state executionalso determined. Thus, higher level policies uence current stateexecution tk either starting state starting time. words, knowtk together starting time starting state, current higher level policiescompletely independent current lower level policies current state.theorem 1 formally states precise form. Note condition obtainedstrictest: one three conditional variables unknown, examplesAMMs higher level policies uence lower level ones.Theorem 1. Let tk bkt two random variables representing starting timestarting state, respectively, current level-k policy tk : tk = maxft0 < j ekt0 = gbkt = stk . Let t>k = ftk+1 ; : : : ; tK g denote set current policies level k + 1K, t<k = fst ; t0 ; : : : ; tk 1 g denote set current policies level k 10 together current state. have:t>k ? t<k j tk ; bkt ; tk(7)Proof. sketch intuitive proof theorem use Bayesiannetwork manipulation rules context-specific independence discussed4.1.1 4.1.2. alternative proof use CSI found (Bui et al.,2000).first note theorem obvious looking full DBN Fig. 8.Therefore, shall proceed modifying network structure contextknow tk .time tk , policies level k must terminate: eltk = l k.Thus remove links policies new policies time tk + 1.hand, time tk + 1 current time t, policies level kmust terminate: elt0 = F l k, tk + 1 t0 < t. Thus grouppolicies level l k time tk + 1 one node representing currentpolicy level l.two network manipulation steps result network structure shownFig. 10. modified network structure obtained, observe t>k473fiBui, Venkatesh & Westk+1kk-1......k...StatebtstTimek...Figure 10: Network structure conditioned tkd-separated tk bkt new structure. Thus t>k t<k independentgiven tk , bkt tk .t<k5. Policy Recognitionsection begin address problem policy recognition frameworkAHMM. assume policy hierarchy given modelled AHMM,however top level policy details execution unknown. problemdetermine top level policy current policies lower levels givencurrent sequence observations. concrete terms, interestedconditional probability:Pr(tK ; : : : ; t0 j o~t 1 )especially, marginals:Pr(tk j o~t 1 ); levels kComputing probabilities gives us information current policieslevels abstraction, current action (k = 0), top-level policy (k = K ),taking account observations date.typical monitoring situations, probabilities need computed \online",new observation becomes available. this, required update beliefstate (filtering distribution) AHMM time point t. problem generallyintractable unless belief state ecient representation affords closed formupdate procedure. case, belief state joint distribution K + 3 discretevariables: Pr(tK ; : : : ; t0 ; st ; lt j o~t ). Without structure imposed beliefstate, complexity updating exponential K .cope complexity, one generally resort form approximationtrade accuracy computational resources. hand, analysis474fiPolicy recognition Abstract Hidden Markov ModelAHMM network previous section suggests problem inference AHMMtractable special case history state terminating statusvariables known. Motivated property AHMM, main aim sectionderive hybrid inference scheme combines approximation tractableexact inference eciency. first treat special case policy recognitionbelief state AHMM tractable structure 5.1. present hybridinference scheme general case using Rao-Blackwellised Sequential ImportanceSampling (RB-SIS) method 5.2.5.1 Policy Recognition: Tractable CaseHere, address policy recognition problem two assumptions: (1) statesequence observed certainty, (2) exact time policy startsends known. precisely, observation time includes state historys~t = (s0 ; : : : ; st ) policy termination history ~lt = (l0 ; : : : ; lt ). belief stateneed compute case Bt = Pr(tall ; st ; lt j s~t 1 ; ~lt 1 ) posteriorabsorbing observation time t: Bt+ = Pr(tall j s~t ; ~lt ).first assumption means observer always knows true current stateoften referred \full observability". states fully observable, ignoreobservation layer fot g AHMM thus deal AMM instead.second assumption means observer fully aware current policyends new policy begins. policy hierarchy constructed region-baseddecomposition state space (subsection 3.2), termination status inferreddirectly state sequence. Thus SRD policy hierarchies, full observabilitycondition needed since second assumption subsumed first leftout. Except SRD policy hierarchies, two assumptions usually restrictivepolicy recognition algorithm presented useful itself. However,algorithm special case form exact step hybrid algorithm presentedsubsection 5.2 general case.5.1.1 Representation belief statefirst look conditional joint distribution Pr(tall ; st j s~t 1; ~lt 1 ). termination history ~lt 1 , derive precisely starting time current level-k policy:tk= maxf0g [ ft0 < tj ekt0 = g = maxf0g [ ft0 < tj lt0 kghand, knowing starting time together state history also givesus starting state bkt . Thus, starting time starting state tkderived s~t 1 ~lt 1 . Theorem 1, obtain level k:t>k ? t<k j tk ; s~t 1 ; ~lt 1words, given s~t 1 ~lt 1 , conditional joint distribution ftK ; : : : ; t0 ; st grepresented Bayesian network simple chain structure. denotechain network Ct Pr(tall ; st j s~t 1 ; ~lt 1 ) term belief chain role playsrepresentation belief state (Fig. 11(a)). chain drawn links475fiBui, Venkatesh & WestKBtCtk+1rootKeKek+1k+1kkk-1ekk-1e k-1110e10(a)(b)Figure 11: Representation belief statepoint away level-k node, say chain root level k. rootchain moved k another level k0 simply reversing links lyingk k0 using standard link-reversal operation Bayesian networks (Shachter, 1986).node belief chain also manageable size. principle, domaintk k , set policies level k, domain st , set possiblestates. K large, basically want model larger state space, setpolicies cover state space also large. sizes domains wouldlikely grow exponential w.r.t. K . However, given particular state, number policiesapplicable state would remain relatively constant independent K .policy tk , know starting state bkt , implies tk 2 k (bkt ), setlevel-k policies applicable bkt . Thus k (bkt ) used \local" domain tkavoid exponential dependency K . Similarly, domain st takenset neighbouring states st 1 (reachable st 1 performing one primitiveaction). given state, term maximum number relevant objects (applicablepolicies/actions, neighbouring states) single level degree connectivity Ndomain modelled. size conditional probability table linkbelief chain O(N 2), overall size belief chain O(K N 2 ).construct belief state Bt Ct. Since current terminating statussolely determined current policies current state, belief state Btfactorised into:Pr(tall ; st ; lt j s~t 1 ; ~lt 1 ) = Pr(lt j tall ; st ) Pr(tall ; st j s~t 1 ; ~lt 1 ) = Pr(lt j tall ; st)CtNote variable lt equivalent set variables feKt ; : : : ; e1t g. Thus, fullbelief state Bt realised adding Ct links current policiescurrent state terminating status variables ekt (Fig. 11(b)). size belief state476fiPolicy recognition Abstract Hidden Markov ModelKeKk+1Kek+1ek+1kkk-1ekek+1Kekk-1e k-110e1(a)(b)Figure 12: Belief state updating: Bt Bt+would still O(K N 2 ). state composite many orthogonal variables, factoredrepresentation used size belief state representation dependexponentially dimensionality state space. discuss factored representationssubsection 5.2.2.5.1.2 Updating belief stateSince belief state Bt represented simple belief network Fig. 11(b),expect general exact inference method updating belief state (Kjrulff,1995) work eciently. However, general method works undirected networkrepresentation belief state distribution inconvenient us laterwant sample distribution. Here, describe algorithm updatesbelief state closed form given directed network Fig. 11(b).Assuming complete specification belief state Bt , i.e., parameters Bayesian network representation, need compute parametersnew network Bt+1 . done two steps, standard \roll-over" beliefstate DBN: (1) absorbing new evidence st , lt (2) projecting belief statenext time step.first step corresponds instantiation variables st , e1t ; : : : ; eKtBayesian network Bt obtain Bt+ conditional joint distribution tK ; : : : ; t0 .checking conditional independence relationships Fig. 11(b), easy seeBt+ simple chain network structure. Thus, conceptually, problemupdate parameters chain Ct absorb given evidence form newchain Bt+. done number link-reversal steps follows.instantiate st, first move root chain Ct st. variable stparents instantiated deleted network (Fig. 12(a)).instantiate lt equivalent value assignment (eKt = F; : : : ; eltt +1 = F; eltt =T; : : : e1t = ), starting k = 1, iteratively reverse links tk 1 tktk ekt (Fig. 12(b)). algebraic forms, first link reversal operation corresponds477fiBui, Venkatesh & Westcomputing following probabilities:Pr(tk j st; e1t ; : : : ; ekt 1 ) =Pr(tk 1 j tk ; st; e1t ; : : : ; ekt 1 ) /X Pr(k j k 1) Pr(k 1 j ; e1; : : : ; ek 1)tk 1Pr(tk j tk 1) Pr(tk 1 j st ; e1t ; : : : ; ekt 1)(8)(9)second link reversal corresponds to:Pr(tk j st ; e1t ; : : : ; ekt ) / Pr(ekt j tk ; st; ekt 1 ) Pr(tk j st ; e1t ; : : : ; ekt 1)(10)Effectively, k-th link reversal step positions root chain Ct tk absorbsevidence ekt . repeating link reversal operations k = 1; : : : ; lt + 1, obtainnew chain Bt+ root level lt +1. Note need incorporateinstantiations ekt = F k > lt + 1 since direct consequencesinstantiation eltt+1 = F . parameters chain Bt+ given below. upwardlinks remain Ct , marginal level lt + 1 downwardlinks obtained results link reversal operations above:Pr(tk+1 j tk ; st ; lt ) = Pr(tk+1 j tk ); k lt + 1Pr(tk j st ; lt ) = Pr(tk j st; e1t ; : : : ; ekt ); k = lt + 1Pr(tk 1 j tk ; st ; lt ) = Pr(tk 1 j tk ; st ; e1t ; : : : ; ekt 1 ); k ltsecond step, continue compute Ct+1 Bt+. Since policieslevels higher lt terminate, t>l+1t = t>lt , retain upper sub-chainBt+ Ct+1 . lower part, k lt, new policy tk+1 created policy+1 state st , thus new sub-chain formed among variables <lttk+1t+1+1 ; st ) = k+1 (st ; k ). Note domain newly-createdparameters Pr(tk+1 j tk+1t+1t+1kknode t+1 (st ). new chain Ct+1 combination two sub-chains,chain root level lt + 1 (see Fig. 13). chain Ct+1 ,new belief state Bt+1 obtained simply adding terminating status variablesfekt+1 g Ct+1 .completes procedure updating belief state Bt Bt+1 , thus allowingus compute belief state Bt time step. Although belief state jointdistribution current variables, due simple structure, marginal distributionsingle variable computed easily. example, interestedcurrent level-k policy tk , marginal probability Pr(tk j s~t 1 ; ~lt 1 ) simply marginallevel-k node chain Ct, readily obtained chain parameters.complexity belief state updating procedure time proportional ltsince needs modify bottom lt levels belief state. hand,probability current policy level l terminates assumed exponentiallyPsmall w.r.t. l. Thus, average updating complexity time-step O( l l=exp(l))constant-bounded, thus depend number levels policyhierarchy. terms number policies states, updating complexity linearsize policy node belief chain, thus linear degree connectivitydomain.478fiPolicy recognition Abstract Hidden Markov ModelKtl +1Ct+1llt+1Bt+1t00t+1stt+1Figure 13: Belief state updating: Bt+ Ct+15.2 Policy Recognition: General Casereturn general case policy recognition, i.e., without two assumptionsprevious subsection. makes inference tasks AHMM much dicult.Since neither starting times starting states current policies knowncertainty, theorem 1 cannot used. Thus, set current policies longer formschain structure Ct since conditional independence properties currenttime-slice longer hold. therefore cannot hope represent belief state simplestructure previously. exact method updating belief state thusoperate structure size exponential K , bound intractableK large.cope complexity, approximation scheme sequential importancesampling (SIS) (Doucet et al., 2000b; Liu & Chen, 1998; Kanazawa et al., 1995)employed. previous work (Bui, Venkatesh, & West, 1999), applied SISmethod known likelihood weighting evidence reversal (LW-ER) (Kanazawa et al.,1995) AHMM-like network structure. However SIS method needs sampleproduct space layers AHMM thus becomes less accurate inecientlarge K . key get around ineciency utilise special structureAHMM, particularly, special tractable case, keep set variables needsampled minimum.improvement SIS method achieve presented subsection 2.5 name Rao-Blackwellised SIS (RB-SIS) method. Rao-Blackwellisationspecifically allows marginalisation variables analytically samplesremaining variables. result, reduces averaged error, measured varianceestimator (Casella & Robert, 1996).479fiBui, Venkatesh & Westorder apply RB-SIS AHMM, main problem identify variables used Rao-Blackwellising variables still sampled,remaining variables marginalised analytically. key choosing RaoBlackwellising variables, shown 2.5, variables observed,Rao-Blackwellised belief state becomes tractable. subsection 5.1, demonstrated state history s~t terminating status history ~lt observedbelief state simple network structure updated constant average complexity. Thus, (st ; lt ) used conveniently Rao-Blackwellising variablert . Note variables ~lt context variables help simplify networkstructure AHMM, state variables s~t help make remaining networksingly-connected exact inference operate eciently (see subsection 4.1.3).5.2.1 RB-SIS AHMMdiscuss specific application RB-SIS problem belief state updatingpolicy recognition AHMM. main objective use RB-SIS estimateconditional probability policy currently executed level-k given currentsequence observations Pr(tk+1 j o~t ).Mapping RB-SIS general framework subsection 2.5 AHMM structure,set current variables xt set current policies, terminating status nodes,current state: xt = (tall ; st; lt ). probability estimation Pr(tk+1 j o~t )viewed expectation letting f (tall ; st; lt ) = Pr(tk+1 jtall ; st ; lt ) that:X Pr(k jall ; ; l ) Pr(all ; ; l jo~ ) = Pr(k j o~ )f =t+1t+1tall ;st ;ltUsing RB-SIS estimate expectation, shall split xt two sets variables:set RB variables rt = (st; lt ), set remaining variables zt = tallset current policies. functional h, depends RB variablesobtained f integrating remaining variables (Eq. (5)),form:X Pr(k j ; ; l ) Pr(all j s~ ; ~l ; o~ ) = Pr(k j s~ ; ~l ) (11)h(~rt ) = h(~st ; ~lt ) =t+1t+1tallmarginal Ct+1 (tk+1 ) belief chain time + 1.RB belief state, belief state AHMM RB variablesknown, becomes:Rt = Pr(tall ; st; lt ; ot j s~t 1 ; ~lt 1 ; o~t 1 ) = Pr(tall ; st ; lt ; ot j s~t 1 ; ~lt 1 )(12)identical special belief state Bt discussed subsection 5.1, except minormodification attach observation variable ot .(11) (12), h function RB belief state computedeciently using exact inference techniques described 5.1. Thus RB-SISimplemented eciently minimal overhead exact inference.main RB-SIS algorithm AHMM given Fig. 14. Note needsample RB variables s~t ~lt . sample i, addition weights w(i) ,480fiPolicy recognition Abstract Hidden Markov ModelBegin= 0; 1; : : :sample = 1; : : : ; NSample sti ; lti Bti (st; ltj ot )Update weight w = w Bti (ot )Compute posterior RB bel state Bti = Bti (tall jsti ; lti ; ot)Compute belief chain Ct BtiCompute new belief state Bti CtCompute h = Ct (tk )Compute estimator Pr(tk j o~t) f^RBSIS = PNi h w~End( )( )( )( )( )( )( )+1( )( )+1( )+1( )+( )+( )( )( )( )+1+1+1=1( )( )Figure 14: RB-SIS policy recognitionB erKeKek+1k+1kk1ek = Fe k1 =10highest leveltermination lte1Figure 15: Sampling Rao-Blackwellising variables AHMMalso maintain parametric representation Rao-Blackwellised belief state Bt(i),value h function sample h(i) . weights samples, togethervalues h function combined yield approximation f.details obtain new samples time step worth notinghere. Since using optimal sampling distribution qt = Bt(st ; lt j ot ) sample481fiBui, Venkatesh & WestRB variables st lt , need perform evidence reversal step.7 donepositioning root belief chain Ct st reverse link st ot .gives us network structure Bter = Bt (st; lt ; tall j ot ) exactly Bt(see Fig. 15), except evidence ot absorbed marginal distributionst. weight wt = Bt(ot ) also obtained by-product evidence reversalstep. order sample st lt Bter without need compute marginaldistribution two variables, use forward sampling sample every variableBter , starting root node st proceeding upward. Since lt definitionhighest level policy termination, sampling stop first level k ekt = F .assign lt value k 1. unnecessary samples policy nodes alongway discarded. new samples st lt , updatingRB belief state Bt Bt+1 identical belief state updating procedure described5.1. h function obtained computing corresponding marginalnew belief chain Ct+1.time step, complexity maintaining sample (sampling new RBvariables updating RB belief state) O(lt ), thus, average, boundedconstant. overall complexity maintaining every sample thus O(N ) average.prediction needed, sample, compute h manipulating chainCt+1 complexity O(K ). Thus complexity time step predictionneeds made O(NK ).comparison use SIS method LW-ER, RB-SISorder computational complexity (the SIS also complexity O(NK )). However,SIS method needs sample every layers AHMM, RB-SIS methodneeds sample two sequences variables s~t, ~lt , avoids sample K policysequences f~tk g. Rao-Blackwellisation, dimension sample space becomesmuch smaller, importantly, grow K . result, accuracyapproximation RB-SIS method depend height hierarchyK . contrast, due problems sampling high dimensional space, accuracySIS methods tends degrade, especially K large.5.2.2 Performing Evidence Reversal Factored State Spacemany cases, state space Cartesian product many state variables representing relatively independent properties state: st = (s1t ; s2t ; : : : ; sM). Since overallstate space large, specifying action usual transition probability matrixproblematic. advantageous case represent state information factoredform, i.e., representing state variable smt separate node rather lumpingsingle node st. shown using factored representations, specifytransition probability action compact form since action likely affectsmall number state variables specification effects actionsmany regularities (Boutilier et al., 2000).7. term evidence reversal used paper refer general procedure linkobservation node reversed prior sampling (Kanazawa et al., 1995), thus allowing us sampleaccording optimal sampling distribution qt .482fiPolicy recognition Abstract Hidden Markov Modelrepresentation belief chain Ct also RB belief state Bt take directadvantage factored representation actions. Indeed, chain parameter Ct(st jt0 )link t0 st precisely transition probability action t0previous state st 1 (note st 1 known due Rao-Blackwellisation). conditionaldistribution extracted compact factored representation t0 generalform Bayesian network variables fs1t ; s2t ; : : : ; sMg. convenience, let usdenote Bayesian network F (:jt0 ). network usually sparse enough exact inference operate eciently. example, special case fs1t ; s2t ; : : : ; sMt gindependent given t0 st 1 , F factored completely productmarginals smt .Although factored representations used part RB belief state, care musttaken performing evidence reversal, i.e. reverse link state variableobservation node. procedure evidence reversal discussed previously (seeFig. 15), first position root Ct node st, thus need compute representdistribution Pr(st). factored state space case, becomes joint distribution0state variables fs1t ; s2t ; : : : ; sMg. Without conditioning current action ,factored representation state variables fst g cannot utilised, thus resultingcomplexity exponential .key get around diculty always keep specification distributioncurrent state conditioned current action, vice versa. Thus, computingBter = Bt (:jot ), first position root chain Ct t0, reverse evidenceot t0 st . algebraic form, use following factorisation jointdistribution current action state given current observation:Pr(t0 ; st jot ) = Pr(stjt0 ; ot ) Pr(t0 jot )(13)Fig. 16 illustrates evidence reversal procedure. model depicted here, Farbitrary Bayesian network. observation model specified attachingobservation nodes fo1t ; o2t ; : : :g state variables. overall network representingdistribution Pr(st ; ot j t0 ) denoted F obs(:jt0 ).first look first term RHS (13). Let F er (:jt0 ; ot ) representdistribution Pr(st j t0 ; ot ). Note F er obtained conditioning F obs(:jt0 )observation ot . achieved applying exact inference methodclustering algorithm (Lauritzen & Spiegelhalter, 1988) network F obs(:jt0 ).second term RHS (13), note that:Pr(ot j t0 ) =X Pr(s ; j 0) = X F obs(s ; j0)ststintegration readily obtained by-product performing clustering algorithm F obs(:jt0 ). Pr(ot j t0 ) known, compute Pr(t0 j ot ) by:Pr(t0 j ot ) / Pr(ot j t0 ) Pr(t0 )shows belief state evidence reversal Bter = Bt (:j ot ) still simplestructure exploits independence relationships state variables fsmt ggiven current action t0. Sampling RB variables structure proceed483fiBui, Venkatesh & West0F3t . ..2stF0obs3t2st1F er.. .1stst21o3t...4t2ot1oto3t.. .4tototBelief state evidence reversalBelief state evidence reversalFigure 16: Evidence reversal factored state spacefollows: Pr(t0 j ot ) first used sample t0; F er (stjt0 ; ot ) used sample st.obtained sample t0 st , proceed sample remaining nodesnetwork Bter obtain sample lt usual. Finally, note weightwt = Pr(ot ) also computed eciently by:Pr(ot ) =X Pr(o j 0) Pr(0)t0evidence reversal procedure, value t0 , need perform exactinference structure F obs (st; ot jt0 ). Thus complexity procedure heavilydepends complexity network structure F . However, noted,due nature factored representation, F usually sparse structureexact inference performed eciently. example, special case Fcompletely factored product independent state variablesindependently observed, complexity becomes linear w.r.t. .6. Experimental Resultssection, present experimental results policy recognition algorithm.subsection 6.1, demonstrate effectiveness Rao-Blackwellised sampling methodpolicy recognition comparing performance Rao-Blackwellised procedurelikelihood weighting sampling synthetic tracking task. subsection 6.2,present application AHMM framework problem tracking human behaviours complex spatial environment using distributed video surveillance data.484fiPolicy recognition Abstract Hidden Markov ModelNRm 6Rm 5North Wing25Rm 43650Rm 762 E16Rm 0W7Rm 3Rm 1Rm 2South WingFigure 17: environment sample trajectoryDestination probabilities1westsoutheastnorthProbability0.80.60.40.20051015202530 35Time4045505560Figure 18: Probabilities top-level destinations time6.1 Effectiveness Rao-Blackwellisationdemonstrate effectiveness Rao-Blackwellised inference method AHMM,consider synthetic tracking task required monitor predictmovement agent building environment previously discussed subsection 3.3. structure AHMM used one shown Fig. 5.parameters policies chosen manually, used simulate movementagent building. simulate observation noise, assume observation agent's true position anywhere among 8 neighbouring cellsprobabilities given predefined observation model.485fiBui, Venkatesh & West0.3SIS0.26/sqrt(x)RB-SIS0.055/sqrt(x)std. deviation0.250.20.150.10.05010203040Sample size (in 1000)50CPU Time (in second)(a) Sample size average error76.565.554.543.532.521.510.50SIS0.035*xRB-SIS0.08*x10203040Sample size (in 1000)50(b) Sample size CPU time0.25SISRB-SISstd. deviation0.20.150.10.05000.20.40.60.811.2CPU time (in second)1.41.6(c) CPU time average errorFigure 19: Performance profiles SIS vs. RB-SIS486fiPolicy recognition Abstract Hidden Markov Model0.003SIS0.00179375RB-SIS0.000235286Efficiency coefficient0.00250.0020.00150.0010.00050051015 20 25 30 35Sample size (in 1000)404550Figure 20: Eciency coecients SIS RB-SISimplement RB-SIS method (with re-sampling) use policy hierarchyspecification simulated observation sequence input algorithm. typicalrun, algorithm return probability main building exit, next wing exit,next room-door agent currently heading to. example track shownFig. 17. observations track arrive time, prediction probabilitydistribution main building exit track heading shown Fig. 18.illustrate advantage RB-SIS, also implement SIS method without RaoBlackwellisation (LW ER re-sampling (Kanazawa et al., 1995)) compareperformance two algorithms. run two algorithms using different sample population sizes obtain performance profiles. given sample size N , standarddeviation ((N )) 50 runs estimated probabilities top-level policies usedmeasure expected error probability estimates. also record averagetime taken update iteration.Fig. 19(a) plots standard deviation two algorithms differentp sample sizes.behaviour error follows closely theoretical curve (N ) = c= N , 2(N ) =c2 =N , cSIS 0:26 cRB SIS 0:055. expected, number samples,RB-SIS algorithm delivers much better accuracy.Fig. 19(b) plots average CPU time (T ) taken iteration versus samplesize. expected, (N ) linear N , RB-SIS taking twice longer dueoverhead updating RB belief state processing sample.Fig. 19(c) plots actual CPU time taken versus expected error two algorithms. shows CPU time spent, RB-SIS method still significantlyreduces error probability estimates.Note algorithm, quantity = 2 (N )T (N ) approximately constantsince dependency N cancels one another out. Thus, constant usedeciency coecient measure performance sampling algorithm independentnumber samples. example, algorithm twice smaller coecient,deliver accuracy half CPU time, half variance CPU time.Fig. 20 plots eciency coecients SIS RB-SIS, SIS 0:0018487fiBui, Venkatesh & WestRB SIS 0:000235. indicates performance gain almost order magnitude(8 folds) RB-SIS.6.2 Application Tracking Human BehavioursUsing policy recognition algorithm, implemented real-time surveillance systemtracks behaviour people complex indoor environment using surveillance videodata. environment consists corridor, Vision lab two oces (see Fig. 21).People enter/exit scene via left right entrance corridor. systemsix static cameras overlapping field views cover ground planescene.entire environment divided grid cells, current cell positiontracked object acts like current state AHMM. cameras calibratedreturn current position tracked object ground, howeverreturned coordinates unreliable cameras deal noisy video framesocclusion objects scene. information low-level tracking donemultiple cameras, readers referred (Nguyen, Venkatesh, West, & Bui, 2002).assume observation state area surrounding it, thusobservation model matrix specifying observation likelihood cell withinneighbourhood current state.policy hierarchy behaviours environment constructed follows. First,construct region hierarchy three levels. bottom level, identify 7regions special interest: corridor, two oces, areas surrounding Linuxserver, NT server, printer, remaining free space Vision lab (Fig. 21).higher level, regions Vision lab grouped together. top level consistsentire environment. policy hierarchy representing people's behaviors three levelscorresponding three levels region hierarchy (see Fig. 23). bottom level,interested behaviours take place within 7 regions interest.example, near Linux server, person might using Linux machine, simplypassing region, leading two different policies. Similar policies definedNT server region, printer region, two small oces. corridorinside Vision lab (region 1 5), construct different policies correspondingdifferent destinations person heading to. Region 5 also special policyrepresenting \walk-around" behaviour. middle level, three policies definedcorridor oce space representing person's plan exiting spaceleft/right entrance door Vision lab. define one policy Visionlab represent typical behaviour lab user (e.g., go Linux server, followedgo printer).8 Finally, top level region (the whole environment), define twopolicies representing person's leaving scene via left/right entrance.Fig. 21 22 show two concurrent trajectories two different people environment. sample video frames captured different cameras system shownFig. 24.AHMM model defined above, sequence observations returnedcameras, first determine performance profiles RB-SIS SIS real8. consider different groups lab users, group might give rise different policy level.488fiPolicy recognition Abstract Hidden Markov ModelCamera 2Camera 5TableBook shelfTableOffice 1Office 2Region 7Region 2Book shelfCamera 3Camera 4Region 1left entranceright entranceCorridorCamera 0Linux servertime slice 300Region 3time slice 150 > 180time slice 50time slice 60Printer1111000000001111Vision LabTableTableRegion 5Region 6Region 4NT serverCamera 1Figure 21: environment trajectory person 1489fiBui, Venkatesh & WestCamera 2Camera 5TableTableOffice 1Book shelfOffice 2Book shelfCamera 3Camera 4Corridorleft entranceright entrancetime slice 180Camera 0Linux regiontime slice 260Linux serverTableVision LabTable(Region 5)Printer1111000000001111NT regionPrinter regionNT serverCamera 1Figure 22: trajectory person 2Top levelenvironment2 policiesMiddle levelBottom levelCorridor & offices3 policiesCorridor5 policiesOffice 12 policiesVision lab1 policyOffice 22 policiesLinux region Printer region Empty space2 policies2 policies4 policiesFigure 23: region policy hierarchy490NT region2 policiesfiPolicy recognition Abstract Hidden Markov Model(a)(b)Figure 24: (a) Person 1 enters scene (b) Person 2 enters scene.0.60.2std. deviation0.5Efficiency coefficientRB-SISSIS0.40.30.20.10SIS0.06RB-SIS0.0110.150.10.05000.20.4 0.6 0.8 1 1.2CPU time (in second)1.41.60(a) Error vs. CPU time0.2 0.4 0.6 0.8 1 1.2 1.4 1.6CPU time (in second)(b) Eciency coecientsFigure 25: Performance RB-SIS SIS real tracking data491fiBui, Venkatesh & West1.4p(left_e)p(right_ e)1.2Probability10.80.60.40.20050100 150 200 250 300 350 400TimeFigure 26: probabilities person 1 leaving scene via entrances (top levelpolicies)environment. two algorithms behave similar way previous experimentsimulated data. Fig. 25 shows error curve CPU time twoalgorithms. eciency co-ecient RB-SIS case RB SIS 0:011,SIS SIS 0:06. shows RB-SIS still performs 5 times betterSIS domain.surveillance system, low level tracking module returns observationsrate approximately two per second. observation passed RB-SISalgorithm produces probability estimate current policy different levelshierarchy. moment, surveillance system run real time using twoAMD 1G machines. Examples output returned system two trajectoriesFig. 21 Fig. 22 given below.Fig. 26 shows probabilities person 1 exiting environment leftright entrance (denoted pleft e pright e respectively). beginning, pleft eincreases person 1 heading left entrance (see trajectory Fig. 21). Then,pleft e approximately constant time slice 50 person 1 inside Vision lab.one middle level policy defined Vision lab movementinside lab independent final exit/entrance. time slice 310, pleft e decreasesperson 1 leaving lab, turning right, entering oce 2. Then, increasesapproaches 1 leaving oce 2, turning left, going towards left entrance.contrast, pright e falls quickly zero time.look results querying bottom level policies. Fig. 27 showsdistribution possible destinations person 2 time slice 180 time slice 260,region 5 (see trajectory Fig 22). probabilities obtained showsystem able correctly detect \walk-around" behaviour.final result (Fig. 28) shows inferred behaviours person 1Linux server region. Initially, probabilities \using Linux server" \passingthrough" same. person stays position extended periodtime, system able identify correct behaviour person 1 \using Linuxserver".492fiPolicy recognition Abstract Hidden Markov Model1.4p(v_Linux)p(v_printer)p(v_NT)p(w_ around)1.2Probability10.80.60.40.20180 190 200 210 220 230 240 250 260TimeFigure 27: Behaviours person 2 inside Vision lab1.4p(u_Linux)p(pass)1.2Probability10.80.60.40.2050100150200Time250300Figure 28: Behaviour person 1 inside Linux server region493fiBui, Venkatesh & West7. Related Work Probabilistic Plan Recognitioncase using probabilistic inference plan recognition argued convincinglyCharniak Goldman (1993). However, plan recognition Bayesian network usedCharniak Goldman static network. Thus approach would run problems process on-line stream evidence plan. recentapproaches (Pynadath & Wellman, 1995, 2000; Goldman et al., 1999; Huber et al., 1994;Albrecht et al., 1998) used dynamic stochastic models plan recognition thussuitable on-line plan recognition uncertainty.Among these, closely related model AHMM Probabilistic StateDependent Grammar (PSDG) (Pynadath, 1999; Pynadath & Wellman, 2000). comparison representational aspect two models discussed subsection 3.4.terms algorithms plan recognition, Pynadath Wellman offer exactmethod deal case states fully observable. statespartially observable, brute-force approach suggested amounts summingpossible states. note even fully observable case, belief state needdeal still large since policy starting/ending times unknown.9 Sinceexact method used Pynadath Wellman, complexity maintainingbelief state would likely exponential number levels PSDG expansionhierarchy (i.e., height policy hierarchy). hand, RB-SIS policyrecognition algorithm handle partially observable states Rao-Blackwellisationprocedure ensures sampling algorithm scales well number levelspolicy hierarchy. Furthermore, noted subsection 3.4, consider compoundpolicies, PSDG converted AHMM. framework, compound policyk 1 ; : : : ; k 1 represented normal policy, slight modificationk = (1)(m)let variable ek take values 1 + 1, value + 1 indicatescompound policy terminated. policy recognition algorithmmodified also work model.Similar AHMM PSDG, recent work Goldman et al. (1999) alsomakes use detailed model plan execution process. Using rich languageprobabilistic Horn abduction, able model sophisticated plan structuresinterleaved/concurrent plans, partially-ordered plans. However work servesmainly representational framework, provides analysis complexity planrecognition setting.work probabilistic plan recognition date employed much coarsermodels plan execution. ignored important uence stateworld agent's planning decision (Goldman et al., 1999). best knowledge,none work date addressed problem partial noisy observationstate. Most, except PSDG, look observation outcomesactions, assume action observed directly accurately. notekind simplifying assumptions needed previous work computationalcomplexity performing probabilistic plan recognition remains manageable. contrary,work illustrates although plan recognition dynamic stochastic model9. course, SRD policy hierarchy considered full observability alone enough.494fiPolicy recognition Abstract Hidden Markov Modelcomplex, exhibit special types conditional independence which, exploited,lead ecient plan recognition algorithms.8. Conclusion Future Worksummary, presented approach on-line plan recognition uncertaintyusing AHMM model execution stochastic plan hierarchy noisyobservation. AHMM novel type stochastic processes, capable representingrich class plans associating uncertainty planning plan observationprocess. first analyse AHMM structure conditional independence properties. leads proposed hybrid Rao-Blackwellised Sequential Importance Sampling(RB-SIS) algorithm performing belief state updating (filtering) AHMMexploits structure AHMM greater eciency scalability. showcomplexity RB-SIS applied AHMM depends linearly numberlevels K policy hierarchy, sampling error depend K .terms plan recognition, results show stochastic processrepresenting execution plan hierarchy complex, exhibit certain conditional independence properties inherent dynamics planning actingprocess. independence properties, exploited, help reduce complexityperforming inference plan execution stochastic model, leading feasible scalablealgorithms on-line plan recognition noisy uncertain domains. scalabilityalgorithm policy recognition provides possibility consider complex planhierarchies detailed models plan execution process. key achieveeciency, shown paper, combination recently developed techniquesprobabilistic inference: compact representations Bayesian networks (context-sensitiveindependence, factored representations), hybrid DBN inference take advantage compact representations (Rao-Blackwellisation).Several future research directions possible. investigate AHMM,would like consider problem learning parameters AHMM databaseobservation sequences, e.g., learn plan execution model observing multipleepisodes agent executing plan. structure AHMM suggeststry learn model abstract policy separately. Indeed, observeexecution abstract policy separately, learning problem reduced HMMparameter re-estimation level-1 policies, simple frequency counting higher-levelpolicies. observation sequence long episode clear cut temporal boundarypolicies, problem becomes type parameter estimation DBNhidden variables, techniques dealing hidden variables EM (Dempster,Laird, & Rubin, 1977) applied.Extensions made AHMM make model expressive suitablerepresenting complex agents' plans. example, expressive plan executionmodel HAM model (Parr, 1998) considered state-independentsequences policies represented. current model also enriched considerset top-level policies interleaved execution. expectnew models would exhibit context-specific independence properties similar495fiBui, Venkatesh & WestAHMM, Rao-Blackwellised sampling methods policy recognition modelsderived.Acknowledgementwould like thank anonymous reviewers insightful commentshelped improve presentation contents paper. Many thanks NamNguyen implementation distributed tracking system used paper.ReferencesAlbrecht, D. W., Zukerman, I., & Nicholson, A. E. (1998). Bayesian models keyholeplan recognition adventure game. User Modelling User-adapted Interaction,8 (1{2), 5{47.Andrieu, C., & Doucet, A. (2000). Particle filtering partially observed Gaussian statespace models. Tech. rep. CUED-F-INFENG/TR. 393, Signal Processing Group, University Cambridge, Cambridge, UK.Bauer, M. (1994). Integrating probabilistic reasoning plan recognition. ProceedingsEleventh European Conference Artificial Intelligence.Boutilier, C., Dearden, R., & Goldszmidt, M. (2000). Stochastic dynamic programmingfactored representations. Artificial Intelligence, 121, 49{107.Boutilier, C., Friedman, N., Goldszmidt, M., & Koller, D. (1996). Context-specific independence Bayesian networks. Proceedings Twelveth Annual ConferenceUncertainty Artificial Intelligence.Boyen, X., & Koller, D. (1998). Tractable inference complex stochastic processes.Proceedings Fourteenth Annual Conference Uncertainty Artificial Intelligence.Brand, M. (1997). Coupled hidden Markov models modeling interacting processes. Tech.rep. 405, MIT Media Lab.Bui, H. H., Venkatesh, S., & West, G. (1999). Layered dynamic Bayesian networksspatio-temporal modelling. Intelligent Data Analysis, 3 (5), 339{361.Bui, H. H., Venkatesh, S., & West, G. (2000). recognition abstract Markov policies.Proceedings National Conference Artificial Intelligence (AAAI-2000), pp.524{530.Casella, G., & Robert, C. P. (1996). Rao-Blackwellisation sampling schemes. Biometrika,83, 81{94.Castillo, E., Gutierrez, J. M., & Hadi, A. S. (1997). Expert systems probabilistic networkmodels. Springer.Charniak, E., & Goldman, R. (1993). Bayesian model plan recognition. ArtificialIntelligence, 64, 53{79.Cohen, P. R., & Levesque, H. J. (1990). Intention choice commitment. ArtificialIntelligence, 42, 213{261.496fiPolicy recognition Abstract Hidden Markov ModelCooper, G. F. (1990). computational complexity probabilistic inference using Baysianbelief networks. Artificial Intelligence, 42, 393{405.Dagum, P., & Luby, M. (1993). Approximating probabilistic inference Bayesian beliefnetworks NP-hard. Artificial Intelligence, 60, 141{153.Dagum, P., Galper, A., & Horvitz, E. (1992). Dynamic network models forecasting.Proceedings Eighth Annual Conference Uncertainty Artificial Intelligence,pp. 41{48.D'Ambrosio, B. (1993). Incremental probabilistic inference. Proceedings NinthAnnual Conference Uncertainty Artificial Intelligence, pp. 301{308.Dawid, A. P., Kjrulff, U., & Lauritzen, S. (1995). Hybrid propagation junction trees.Zadeh, L. A. (Ed.), Advances Intelligent Computing, Lecture Notes ComputerScience, pp. 87{97.Dean, T., & Kanazawa, K. (1989). model reasoning persistence causation.Computational Intelligence, 5 (3), 142{150.Dean, T., & Lin, S.-H. (1995). Decomposition techniques planning stochastic domains. Proceedings Fourteenth International Joint Conference ArtificialIntelligence (IJCAI-95).Dempster, A., Laird, N., & Rubin, D. (1977). Maximum likelihood incomplete datavia EM algorithm. Journal Royal Statistical Society B, 39, 1{38.Doucet, A., de Freitas, N., Murphy, K., & Russell, S. (2000a). Rao-Blackwellised particle filtering dynamic Bayesian networks. Proceedings Sixteenth AnnualConference Uncertainty Artificial Intelligence.Doucet, A., Godsill, S., & Andrieu, C. (2000b). sequential Monte Carlo sampling methods Bayesian filtering. Statistics Computing, 10 (3), 197{208.Forestier, J.-P., & Varaiya, P. (1978). Multilayer control large Markov chains. IEEETransactions Automatic Control, 23 (2), 298{305.Fung, R., & Chang, K. C. (1989). Weighting integrating evidence stochastic simulation bayesian networks. Proceedings Fifth Conference UncertaintyArtificial Intelligence.Geweke, J. (1989). Bayesian inference econometric models using Monte Carlo integration.Econometrica, 57 (6), 1317{1339.Ghahramani, Z., & Jordan, M. I. (1997). Factorial hidden Markov models. Machine Learning, 29, 245{273.Goldman, R., Geib, C., & Miller, C. (1999). new model plan recognition. ProceedingsFifteenth Annual Conference Uncertainty Artificial Intelligence.Hauskrecht, M., Meuleau, N., Kaelbling, L. P., Dean, T., & Boutilier, C. (1998). Hierarchicalsolution Markov decision processes using macro-actions. ProceedingsFourteenth Annual Conference Uncertainty Artificial Intelligence.Henrion, M. (1988). Propagating uncertainty Bayesian networks probabilistic logicsampling. Lemmer, J., & Kanal, L. (Eds.), Uncertainty Artificial Intelligence 2,Amsterdam. North-Holland.497fiBui, Venkatesh & WestHuber, M. J., Durfee, E. H., & Wellman, M. P. (1994). automated mapping plansplan recognition. Proceedings Tenth Annual Conference UncertaintyArtificial Intelligence.Jelinek, F., Lafferty, J. D., & Mercer, R. L. (1992). Basic methods probabilistic context free grammar. Laface, P., & Mori, R. D. (Eds.), Recent Advances SpeechRecognition Understanding, pp. 345{360. Springer-Verlag.Jensen, F. (1996). Introduction Bayesian Networks. Springer.Jensen, F., Lauritzen, S., & Olesen, K. (1990). Bayesian updating recursive graphicalmodels local computations. Computational Statistics Quarterly, 4, 269{282.Jordan, M. I., Ghahramani, Z., Jaakkola, T. S., & Saul, L. K. (1999). introductionvariational methods graphical models. Machine learning, 37 (2), 183{233.Jordan, M. I., Ghahramani, Z., & Saul, L. K. (1997). Hidden Markov decision trees.Mozer, M. C., Jordan, M. I., & Petsche, T. (Eds.), Advances Neural InformationProcessing Systems 9, Cambridge, MA. MIT Press.Kalman, R. E. (1960). new approach linear filtering prediction problems. Transactions American Society Mechanical Engineering, Series D, Journal BasicEngineering, 82, 35{45.Kanazawa, K., Koller, D., & Russell, S. (1995). Stochastic simulation algorithms dynamic probabilistic networks. Proceedings Eleventh Annual ConferenceUncertainty Artificial Intelligence, pp. 346{351.Kautz, H., & Allen, J. F. (1986). Generalized plan recognition. Proceedings FifthNational Conference Artificial Intelligence, pp. 32{38.Kjaerulff, U. (1992). computational scheme reasoning dynamic probabilistic networks. Proceedings Eighth Annual Conference Uncertainty ArtificialIntelligence, pp. 121{129.Kjrulff, U. (1995). dHugin: computational system dynamic time-sliced Bayesiannetworks. International Journal Forecasting, 11, 89{111.Lauritzen, S., & Spiegelhalter, D. (1988). Local computations probabilities graphicalstructures application expert systems. Journal Royal StatisticalSociety B, 50, 157{224.Liu, J. S., & Chen, R. (1998). Sequential Monte Carlo methods dynamic systems.Journal American Statistical Association, 93, 1032{1044.Murphy, K., & Russell, S. (2001). Rao-blackwellised particle filtering dynamic Bayesiannetworks. Doucet, A., de Freitas, N., & Gordon, N. J. (Eds.), Sequential MonteCarlo Methods Practice. Springer-Verlag.Murphy, K. P. (2000). Bayesian map learning dynamic environments. AdvancesNeural Information Processing Systems 12, pp. 1015{1021. MIT Press.Nguyen, N. T., Venkatesh, S., West, G., & Bui, H. H. (2002). Coordination multiplecameras track multiple people. Proceedings Asian Conference ComputerVision (ACCV-2002), pp. 302{307.498fiPolicy recognition Abstract Hidden Markov ModelNicholson, A. E., & Brady, J. M. (1992). data association problem monitoringrobot vehicles using dynamic belief networks. Proceedings Tenth EuropeanConference Artificial Intelligence, pp. 689{693.Parr, R. (1998). Hierarchical control learning Markov Decision Processes. Ph.D.thesis, University California, Berkeley.Parr, R., & Russell, S. (1997). Reinforcement learning hierarchies machines.Advances Neural Information Processing Sytems (NIPS-97).Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks Plausible Inference. Morgan Kaufmann, San Mateo, CA.Pearl, J. (1987). Evidential reasoning using stochastic simulation causal models. ArtificialIntelligence, 32, 245{257.Pynadath, D. V. (1999). Probabilistic grammars plan recognition. Ph.D. thesis, Computer Science Engineering, University Michigan.Pynadath, D. V., & Wellman, M. P. (1995). Accounting context plan recognition,application trac monitoring. Proceedings Eleventh Annual ConferenceUncertainty Artificial Intelligence.Pynadath, D. V., & Wellman, M. P. (2000). Probabilistic state-dependent grammarsplan recognition. Proceedings Sixteenth Annual Conference UncertaintyArtificial Intelligence.Rabiner, L. R. (1989). tutorial Hidden Markov Models selected applicationsspeech recognition. Proceedings IEEE, 77 (2), 257{286.Sacerdoti, E. (1974). Planning hierarchy abstraction spaces. Artificial Intelligence,5, 115{135.Shachter, R. (1986). Evaluating uence diagrams. Operations Research, 34, 871{882.Shachter, R. D., & Peot, M. A. (1989). Simulation approaches general probabilisticinference belief networks. Proceedings Fifth Conference UncertaintyArtificial Intelligence.Sutton, R. S. (1995). Td models: Modelling world mixture time scales.Proceedings Internation Conference Machine Learning (ICML-95).Sutton, R. S., Precup, D., & Singh, S. (1999). MDP semi-MDPs: frameworktemporal abstraction reinforcement learning. Artificial Intelligence, 112, 181{211.van Beek, P. (1996). investigation probabilistic interpretations heuristics planrecognition. Proceedings Fifth International Conference User Modeling,pp. 113{120.York, J. (1992). Use Gibbs sampler expert systems. Artificial Intelligence, 56, 115{130.499fifffi! #"$ %'&)(+*-,/.00.213( 42*+5'(+*06789: ;)( .2<0!(=?>8 %&;A@2<0.B$CEDGFEHJI7CEKLB$CNMO-PRQEP3OSMTVUXWOZY\[VM]I7CEK_^`WTbaca]IdGO-P3afegIM3hE[iFjMlkmP3TbDGI7CEKnH:HJFEP3TbHSoqpr[)PtsjIuvQXWIHJIMwoyx`kzhEO-[)P3OSM3I2H:TVW|{}OJaFXWMaS~nnQXQEP3[JEIuLTM3I2[NCWK)[iPRIM]hXua~yTVCEDEQyO-PRIuLOCNMaff#$`|3cRiJ$c$$$$$ $#ffc2r?-$$ ' w2 2'2r+-ffEc'?+rVw!22:Sff?772]r3J727#rr2!]- +i?rr+b2/r 7+r?r++]rSrR7/?j+7r2+/r$7+J27r++:N+)2E:r]7+)V++'r7 ff+ r+7 +? +X+7?mr-2/r ?+r X7+|rG?r++ Nr+? 77 X77m+ r? +7++?E2/r 77S2r!X?R:+7-rVrAj/+7 ):G+rjGr7:+ffr7++| +r+?/ ! +:ffi7 ?E!?yX?fi++?/b?b/+G +G?+ ++/?G? 7?r7]ffN7+b7+VffG+i+G+j?!+br:++/2r72r +ryrr?2/r 77SXVffi?X7ff+:rE+rm/!"crr7yrt+!27V7+)r+#!7r+?iff?r#'3/Arff:!r+3? ]+Nr?++A )r)/+i7E!??r%$+Nr):/Srff&r+7S72/++2+r('??S +ri7r+)rN7#)$rV rR)2/rb:+ ff + '*rr7+ ' ,i !)E& .ff:2+rEffr+ 2!+ :?++7rAr+! 7/+ffff!r+ + ? rr+01+! r++77+!2 r +!rr ?rV?++/2/?V7r+7Arff +2ff: br yff +G??3ffE+ff +5476?:7+Nr|+ 8'rX ?/# r:/+!r r/?)/ i+?N?91+!+V+-+r: ffr+r+r7+r++!;7<2=8> 3?@BA-3CD? >E"FGHFI(JLKM#N8KIOGHFPRQSI2JT9FUPVJW9M#X-YZ7NYJQSI#[ffG]\SKPPQ_^`G]KaJQ_Y3IK\_[Yb/QSJT9cPdT9KNF eObY3W#[3T(JdFc2fOQ_bQSG]K\#KI9MJT#F]YbF]JQgG]K\bFPW9\SJPhG]\SFKab/\_XiP/T#YjUQgI#[kJT#FM9QSPGHbQScQSI9KaJQSY3IlfmYjnF]boYZBFIOPVFc!e`\_F2G]\SKPPQ_^OF]b/P2p.qnKW9F]brts Y3TOKNuQwv`xyyy{z#qnbFQScKIvOxyy|{z#}hQSF]JVJVF]b/QSG/Tv{~auzOhfOQ_JV r KG]\SQgI7vOxyyy{zOuG/TOKafOQ_bF r #QSI#[F]bvxyy3k"T#FPVFcF]JT#Y{MOPoeOKPQSG]K\g\_XbF\SXY3INYJQgI#[lJT#FM#FG]QgPQ_Y3IYZLQSI9M9QSN{QSMOW9K\G]\SKP/PQ_^9F]b/PoQgI9PQSM#FKI%FI9PVFcffeO\_FJnQgPBj QSM#F\_X2KG]GHF]f9JVFM7v`KI9M%ZYb/cK\S\_Xf9bYNFIQSIGHF]b/JKQSIG]KPVFPpDuGT9KafOQ_bFvu#bFWOI9M7vqLKabJ\_F]JVJ]v r F]Fvhxyy{zfiuG/T9Kaf`Q_bF r uQSI#[F]bvUxyy3vLJT9KaJ2JT#FQ_b2fmYjnF]bKGHJW9K\g\_XbF\gQ_FP-Y3IJT#FKaeOQS\gQ_JX%JVYeOW9Qg\SMkfmYJVFIJQSK\g\_XHk\gKab[F!G]\SKPP/Q_^9F]b/P]R)JUTOKP"F]NFIieF]FIYeOPVF]bNFMFH{fmF]b/Qgc2FIJK\g\_XJT9KaJPW9GTKI1FIOPVFc!e`\_FiG]KItPVY3cF]JQSc2FP%emFiKP\SKab[F5KPp:Ybl\SKab[F]b%JT9KI`JT#F5M9KaJKW9PVFM1JVYeOW9Qg\SMJT#FFI9PFc!eO\SFp Kab/[3QSI#FKI(JW r }hQSF]JVJVF]b/QSG/Tvxyy3lt"T9FI7vnKPQSc2f`\_Fl(W9FPVJQ_Y3IKab/QgPVFP]vI9Kc2F\SX2jUT9KaJBQgPRJT#FfiQSI(JVF]bFPVJnKffG]W9PJVY3c2F]bG]KI%TOKNFoQSIWOPQSI#[!P/W9G/TkK!G]\gKPPQ_^9F]bv(QSI9PJVFKMYZP/QSc2fO\_F.00. %%`!;V;LA2n3!fi9JR8! %&% r&2%%g2 ;fi\_Y{Y{W9fOPdQSIJT#F M9KaJKuv#KI9MW9PQSI9[!K\_[Yb/Q_JTOcPRPWOG/T%KPBI#FKab/FPVJBI#FQS[3TemYbBG]\gKPPQ_^9F]bPUp Kab/[3QSI#FKI(JWr }fiQ_F]JVJVF]b/QgG/T7vxyy3ZJVF]b%PVY3c2FYZfiJT#Flc2Y3PJbFcKab aKaeO\_FkbFGHFI(JPVJWOM9Q_FP2QSINYJQSI9[G]\SKPPQS^OG]KaJQ_Y3IK\_[Yb/QSJT9cP]vPVY3c2F"KW9JT#Yb/PdT9KNF"fmY3QSI(JVFMffY3W9JJT#F"QSI(JVF]bFPVJJVYe9bQSI#[hJT9QSP G]\SKPPQS^OG]KaJQ_Y3IfmYjnF]bdJVY!M9KaJKocQSI9QSI#[#vKI9MlcYbFof9bFG]QSPF\_XJVYcK FffQSI(JVF]bf9bF]JKae`QS\SQ_J)XKG]\_FKabUQgPPW#FoQSIkNYJQSI9[G]\SKPPQS^OG]KaJQ_Y3IK\_[Yb/QSJT9cPp.qLKW#F]b r Y3T9KN{Qwv0xyyy{zE QSM#[F]jLKXv KM9Q_[3KIvOEUQSGT9Kab/M9PY3I7v rKI9Fvxyy3U{Y3c2F!KW#JT9Yb/P[YF]NFIZ.W#bJT#F]bv0KI9MKab[3W9FJT9KaJ!JT9FQSc2fmYbJKI9GHF2YZ"QgIJVF]bfObF]JKaeOQS\SQSJXiTOKPoemF]FIcKab[3QgI9K\SQ_]FMQSIkJT#FM9FPQ_[3IkYZ JT#FPVFK\_[YbQ_JT9cP]v#KI9MlfOW#JLemFT9QSI9M%JT#FI#F]FMlJVYM#F]NuQSPVFoG]\SKPPQS^9F]b/PLjUQ_JTPJVbY3I#[G]\SKPP/Q_^OG]KaJQ_Y3IfYjBF]bop.EUQgM#[F]jnKX2F]JnK\D_vxyy3RqLW#JnQSI(JVF]bf9bF]JKaeOQg\SQ_JXK\SPVYff[YNF]b/IOPBJT9F {W9K\SQ_J)X-YZK-c2Y{M9F\Oe{Xf9bYN{QgM9QSI#[KI9PjBF]b/PnJVY2T#YjQSJBQSPBjBYb {QSI9[#v{KI9Mv{c2Y3PJnQScfYb/JKIJ\_Xv(jUT(X G]GHYb/MOQSI#[JVYqLKW#F]b rs Y3T9KN{Qp+xyyy3vLPVJVb/QSN{QSI9[iZ:YbGHY3c2f9bFT9FI9PQ_eOQg\SQ_JX5QSINYJQSI#[c2YuM#F\SPQSP-Y3I#FYZ JT#Ff9b/QgI9G]Q_fOK\f9bYeO\SFcPmbF{W9Q_b/QSI9[RZ.W#JW#bFdQSI(NFPVJQ_[3KaJQSY3I9P]0UT#F]XhK\gPVYbFcKab hJT9KafiJ ff+NYJQgI#["JVFG/TOI9QS{W#FPW9PWOK\S\_XbFP/W9\_JQSIQSI9GHY3cf9bFT#FI9P/Q_eO\_FhG]\SKPPQ_^OF]b/PLJT9KaJUG]KI9I9YJ"FKPQS\_X%emFoPT#Yj IJVYW9PVF]bP uY3cf9bFT#FI9P/Q_eOQS\SQSJXQgP]vY3IJT#FiYJT9F]blT9KI9M7v"KT9Kab/McQSI9QgI#[QSPP/W#Fp.qLW K r F]Fvh~a#xQ_J!M9F]fFIOM9PfiY3IfOKab/KcF]JVF]b/PffP/W9G/TKPffJT#FJ)X(fmFYZG]\SKP/PQ_^9F]b/PoWOPVFM7vJT9FK\_[Yb/Q_JTOc QSI9M9WOG]QSI#[kJT#FG]\SKPP/Q_^9F]b/P]v{JT#FoW9PVF]bcQgI9QSI#[ffJT#FfiY3W#JVfOW#JP]vuF]JGa"dUT#Y3W#[3T%JT#F{W9KIJQS^OG]KaJQ_Y3I%YZ0QSI(JVF]bf9b/F]JKaeOQS\SQ_J)XQSPPJQS\S\YfmFI#FMQgIJT#F[FI9F]b/K\RG]KPVFp.qLW K r F]Fv ~a#xvJT9F]bFKabF%PVY3c2F%G]\SW#FPGHY3cQgI#[lZ:bY3cJT#F]YbX-KI9M-f9b/KGHJQSGHFLYZcKG/T9QgI#F\_FKab/I9QSI9[ 8M9KaJK cQSI9QSI#[ QSI9M9QSG]KaJQgI#[ PVY3cFnfmYJVFI(JQSK\S\_XffQSIJVF]b/FPVJQSI#[bF{W9Q_bFcFIJPKI9MGHY3c2f9bY3cQgPVFPJVYM#F]NuQSPVFKIlF G]Q_FI(JU\_FKab/I9QgI#[ 8cQSI9QgI#[ffK\_[YbQ_JT9c^9bPVJobF{W9Q_bFc2FI(JZ:Yb!JT#F%K\_[Yb/Q_JTOc QSPoYe{NuQ_Y3W9P\_X5Q_JP![FI#F]b/K\SQ_KaJQSY3IKaeOQS\gQ_JQ_FP j Q_JT#Y3W#JG]\SKPP/Q_^OG]KaJQ_Y3IkPVJVbFI9[JT7v9Q_JLQSPnfY3QgIJ\_FP/PBJVYPFKab/G/TkZ:Yb"QSI(JVF]bFPVJQSI#[c2YuM#F\SPnYZJT9FM9KaJKu PFGHY3I9Mr KPG]W#F\wvnxyy {zbF{W9Q_bFcFIJ]vcYbFbF\SKaJVFMJVYcQSIOQSI#[#vQSPoJT9FPQ_]FYZLJT#FG]\SKP/PQ_^9F]b/Pp YuGr Kaf9f{Xvxyy3)Z"KG]G]W#bKaJVFvRKiG]\gKPPQ_^9F]bffjUQ_JTbFPVJVb/QSGHJVFMPQ_]F%G]KI\_FKMJVY5Z.KPVJVF]b2KI9MY{GM#F]F]fmF]bLW9I9M#F]b/PJKI9M9QSI#[# "T9QSPBQSPBYe(NuQ_Y3W9P\SXI#YJnKIkKaeOPY3\SW#JVFUbW9\_Fv{b/KaJT#F]bLKI%KafOf9bY#QScKaJVFhf9bY{XZ:YbQSIJVF]b/f9bF]JKaeOQS\gQ_JX hfOKaJT#Y3\_Y[3QSG-G]KPVFPoFH#QSPVJoQSIijUT9QgG/T7vmZ:YbhFH#Kc2fO\SFvK%\gKab[F2KI9M5W9Ie`K\SKI9GHFMJVbF]FG]KI emFNF]bXPQSc2fO\SF%JVYW9I9M#F]b/PJKI9M p.qLW VK r F]Fv"~a#xUYJVFiJT9KaJQSIJTOQSPFHuKcfO\_FvJT#FoKW#JT#YbPLFH{fO\gKQSIJTOKaJJT#FfiJVbF]FQSPLPQSc2f`\_FUemFG]KW9PVFoK\S\mQ_JPI9Y{M#FPLG]KIkemFoM#FPGHb/QSeFM%W9PQgI#[!Z:F]j!#"$&% % "T#F]b/F]ZYbFv3P/QSc2fO\SQgG]Q_JXoQSP K\SPVYoKPPVYuG]QSKaJVFMJVYoKfiPT#YbJ M#FPGHbQ_f9JQ_Y3I7vaeOW9J W9P/QSI#[ KhfOKab/JQSG]W9\SKabG]\SKPP"YZ GHY3IOGHF]f9J"bF]f9b/FPVFIJKaJQSY3I7JT9Q_bMfff`Kab/Kc2F]JVF]bBQg('OW#FI9G]QgI#[hGHY3cf9bFT#FI9P/Q_eOQS\SQSJXQSP JT#F I9KaJW#bFYZmJT#F"K\_[YbQ_JT9)c PY3W9JVfOW#J]+I9PQSM#FRJT#FLe9bY3KM-PGHYfmFBYZOPX{cffemY3\SQSGRG]\gKPPQ_^9F]bP]v8PY3c2FnG]\gKPPVFP YZ`GHY3I9GHF]fOJ b/F]f9bFPVFI(JKaJQ_Y3I9P Kaf9fmFKabJVY5Y *F]b2Ki[bFKaJVF]bGHY3c2Z:YbJ-ZYb2QSI(JVF]bf9bF]JKaJQSY3I7i}hFG]QSPQSY3IJVbF]FPemF\_Y3I9[JVYJT9QSP-PVF]Jkp.qnbFQgcKI7v#bFQgM9cKI7vo\SPT#FI7v r {JVY3I#Fv0xy +(vJT#Y3W#[3TJT#F]XK\SPVYbKQSPVF!PVY3cF!QSI(JVF]bf9bF]JKaeOQg\SQ_JXf9bYeO\SFc,PY3T9KN{Q r {Y3cc2F]b/^9F\SMp+xyy3{W#YJVFJTOKaJff+JT9FLG]\gQ_FIJP.- eOW9P/QSI#FPP0W9PVF]b/P0/uZ:Y3W9I9M-PVY3c2FLQSIJVF]b/FPVJQSI#[ fOKaJVJVF]b/I9PSQ IffJT#FLM#FG]QSPQ_Y3IffJVbF]FP]ve`W#JBJT9F]XM9QSMI#YJLZF]F\JT#FoPVJVbW9GHJW#bF jnKPI9KaJW9b/K\ZYbLJT#FcdUT#F]XjnF]bFo\_Y(YuQSI#[ffZYbJT9Y3PVF!J)jBYYb JT#b/F]F!KaJVJVb/Q_eOW9JVFPUKI9MNaK\SW#FP-p214351LKGHY3c!eOQgI9KaJQ_Y3IYZ[F]Y[b/Kaf`T9QSGKI9MQgI9M9W9PVJVbQ_FP0jUT#F]b/F PVY3c2F]JTOQSI#[ffVQgIJVF]bFPJQSI#[6 jLKPLT9Kaf9fmFI9QSI9[#+IKM9MOQ_JQ_Y3I7v3JT9F]XZF\SJQSJdjnKPBJVY{Y-\SQgcQ_JQSI#[fiJT9KaJBJT#F I9Y{M#FPRQSIKffM#FG]QSPQ_Y3IJVbF]FUbF]fObFPVFI(JRb/W9\SFPJT9KaJLK\S\9PVJKabJj Q_JTkJT#F!PKcF!KaJVJVb/Q_eOW9JVFP]7\_JT#Y3W#[3TI9YJ\SQScQ_JQgI#[Z:bY3c KG]\SKPP/Q_^OG]KaJQ_Y3INuQ_F]j"fmY3QSI(J]vdJT#FYb/M9F]b/QSI#[YZhI9Y{M#FPfOb/Q_YbJVY]G \SKPP/Q_^OG]KaJQ_Y3IG]KIJT9F]bF]ZYb/FcKF!Q_JW9I9GHY3cZYbJKae`\_FoJVYcQSI#FoK2M#FG]QgPQ_Y3IkJVbF]F8 YJQSGHFJTOKaJJT9QSPf9bYe`\_Fc cQS[3TJT#Y3\SMZYb2KI(XG]\SKPPffYZUGHY3I9GHF]f9JbF]fObFPVFI(JKaJQ_Y3IQSIJVF][bKaJQSI#[iKIYb/M9F]b/QSI#[if9b/Q_YbJVYkG]\SKPPQ_^`G]KaJQ_Y39I BM9FG]QSPQ_Y3Ii\SQSPVJP!p.E Q_NFPVJ]v xy3vK\_JVF]b/I9KaJQgI#[M#FG]QSP/Q_Y3IlJVbF]FPp.#bFWOI9M r KPY3I7v:<;>=fiiwcffffxyyy3v7e9b/KIOG/T9QSI9[2f9bY[b/KcPp KI9PVY3W#b r G \g\_FPVJVF]bv7~av7F]JGaU"T9F]bFFH#QSPVJP]vmT#YjnF]NF]bv7KJX{fmFLYZ`G]\SKPP/Q_^9F]b/P Y3IjUT9QgG/T-bF\SKaJVFMfOKafmF]b/P Kaf9fmFKabJVYoemFB[FI9F]b/K\S\_X!WOI9KI9QSc2Y3WOPY3IJT#FQSb cQSI9QSI#[KaeOQS\gQ_JQ_FP M9QgP VWOI9GHJQ_NFBI9Yb/cK\{ZYbc ZYb/c-W9\SKP"p.} h P]v(KI9M-JT#FQSbdI(W9cF]bY3W9P FH{JVFIOPQ_Y3I9PvJT9KaJdQSP]vM9QSP VW9IOGHJQ_Y3I9P"YZBGHY3I VWOI9GHJQ_Y3I9P]o+I(JVF]bFPVJQSI#[3\SXFI#Y3W#[3T7v7JT9QgP QSPhJT#F2G]\SKP/P j T9QSG/Tc2YJQ_NaKaJVFM5FKab/\_XjnYb {Pop.KI9MkK-[bFKaJKc2Y3W9I(JLYZjnYb {PLKaZ:JVF]bjLKab/M9PRY3I%JT#FhjBF\S \ fi {I#YjUJT9F]YbXYZ0\SFKab/I9QSI#[p dK\SQSKI(J]vUxy +#vUxy 3vBfOKabJ\_XeFG]KWOPVFYZUJT#FkJVFI9M#FI9GHXT{W9cKIOP-PF]Fc JVYT9KNFJVY5bF]f9bFPVFI(JuI#YjU\SFM#[FW9PQgI#[PQScQS\gKab/\_XlPT9KafmFM5b/WO\_FPp dK\SQSKI(J]vnxy 3"TOQSPfiG]\SKPP!QgPoK\SPVYlJT#FM9W9K\ YZLJT#FY3I#FQScfO\SQSG]Q_J\SX%W9PFM5e(XqnW VK r F]Fpw~a#xoJVYlG]KPVJoJT#FQ_bP/Q_]F2c2FKPW#bFZ:YbM#FG]QSPQSY3IiJVb/F]FPp:JVYPVJKaJVFffjUT#F]JT#F]bJT#FffGHY3I9GHF]f9J"bF]fObFPVFI(JVFMQSPPQgc2fO\_FhYb I#YJJUQSPLY3W#b KQSc QSIJTOQSPLfOKafmF]bJVYf9b/YfY3PFhJT9F]YbF]JQSG]K\b/FPW9\_JP"KIOMlKaf9f9bYuQgcKaJQ_Y3IK\_[Yb/QSJT9cPbF\SKaJVFMiJVY%JT#F-QgI9M9W9GHJQ_Y3IkYZRNF]bXfOKabJQSG]WO\SKabUNYJQSI9[%G]\SKP/PQ_^9F]b/PvOM#b/KjUQSI#[JT9FQ_bUbY{YJPhY3IiP/QSc2fO\_Fb/W9\SFUPVF]JPp.\S#Q Fh} dvujUQ_JTJT#FhYe +FGHJQSNFhJVF]F]flKffJVb/KM#F]Y *emF]JjnF]FIPQScfO\SQSG]Q_J)X-KIOMKG]G]W#bKGHXfiW#bkKQSc QSP%K\SPVYJVYf9bYNFJT9KaJ]vfiQSI JT9F5I{W9c2F]b/Y3W9PkQSI9M9W9GHJQSY3I K\_[Yb/QSJT9cPkK\_bFKM#X f9bYfmY3PVFMJT#bY3W9[3T#Y3W#JhJT#F-cKG/T9QSI9Fff\_FKab/IOQSI#[KIOMiM9KaJKkcQgI9QSI#[GHY3cc-W9I9QSJQ_FP]vmPVY3c2F-YZdJT#Fcvmf9bF]NuQ_Y3W9P/\_XW9PVFMiQSIM9FG]QSPQ_Y3IJVb/F]FP KI9MM#FG]QSP/Q_Y3Il\SQSPJP"QSI9M9WOGHJQ_Y3I7vOG]KIiemFFKPQS\_XKM9KafOJVFMJVY%GHYfFffjUQ_JTJT9QSPYe VFGHJQ_NFvaJT#F]bF]e{X\_FKM9QSI9[JVY"FKPVX fiDJVY fiQSc2fO\_FcFIJLp.KI9M!GHY3c2f`KabF7K\_[YbQ_JT9cP] "T#FdI#FHuJ0PFGHJQ_Y3If9bFPFIJP"KPVX{I(JT#FPQgPLYZ Y3W9bUGHY3IJVbQ_eOW#JQ_Y3Iv{j T9QSG/TQgPM#F]JKQS\_FMlQgIkJT#FbFPVJYZ JT#Fof`KafF]b< AJ? >C BA:3C?>T9QgPBf`KafF]b"QgPBfOb/QSI9G]Q_f`K\S\_X2GHY3I9GHF]b/I#FMljUQ_JT%JT#FoJT#F]YbF]JQgG]K\KI9MkFHufF]bQSc2FI(JK\7PVJW9M#XYZ0KPVF]JYZ"NYJQSI#[G]\SKP/PQ_^9F]b/P jUT9QgG/TjBFJT9QgI(QSPh\SQ#F\_XJVY%fObYNuQSM#FKIKG]G]W#b/KaJVFKI9PjBF]boJVYkJT#F2PQScfO\SQSG]Q_J)XfiKG]G]W#b/KGHXJVb/KM#F]Y * M9FG]QSPQ_Y3IGHY3ccQ_JVJVF]FPfip.} "p Y{G r KP/G]W#F\wvmxyy 3R} QSPRQSI#Z:Yb/cK\S\_XffJT#FqnY(Y3\SFKIcffWO\_JQSG]\SKPPhFHuJVFI9PQ_Y3I5YZBfmY3\_X{I9Y3cQSK\ M9QSPGHb/QgcQSI9KI(JUZ.W9I9GHJQ_Y3IOP] M#FG]QSPQ_Y3I5GHY3ccQ_JVJVF]FGHY3I(JKQSI9PdbW9\_FP]v3FKGT%YZJT9FPVFUemFQSI#[KfOKQ_bhp.cY3I#Y3cQSK\wvNFGHJVYbRKGTcY3I#Y3cQSK\9QgPRKGHY3I9MOQ_JQ_Y3IJT9KaJ]v jUT#FI^ObFM7vbF]JW#bI9PQ_JPNFGHJVYb ZJVF]bkFKG/TtcY3I#Y3cQSK\ T9KP%eF]FI1JVFPVJVFM7vUJT#FP/W9c YZJT#FbF]JW9b/I#FMNFGHJVYb/PQgP%WOPVFMJVYJK FJT#FM#FG]QSP/Q_Y3I7 "TOQSPkKM9M9Q_JQ_NFZ.KPT9Q_Y3IZ:YblGHY3c!eOQgI9QSI#[b/W9\SFP!QSPffKaeOPVFI(JffZ:bY3c G]\SKPPQSG]K\BqnY(Y3\_FKIG]\SKP/PQ_^9F]b/P!PW9G/TKP}hFG]QSPQ_Y3Ib/F]FP%p.}fi Yb-}hFG]QSP/Q_Y3IQgPVJP"p.} 9W9bJT#F]b/c2Yb/FvW9I9\SQ FBJT#FPFJjnY!\SKaJVJVF]bRG]\SKP/PVFP]v3JT#F"G]\gKPPQ_^9F]bGHY3I(JKQSI9PdKae`PVY3\SW#JVF\_X-I#YYb/M#F]bQSI#[#vI#FQ_JT#F]b Y3I-NaKab/QSKaeO\_FPp.W9IO\S#Q FB}fi v3I9Yb Y3Ic2Y3I9Y3cQSK\SPp.W9I9\g#Q FB} T#FIP(W G]Q_FIJ\SXPcK\g\} PKabFeOWOQS\_JfiKI9MKM#F{W9KaJVFb/FPVJVb/QSGHJQ_Y3IOPoKabFJK FI7v KI#F]j M9Qgc2FI9PQ_Y3I5QSIQgIJVF]bfObF]JQSI#[JT#FG]\SKPP/Q_^9F]b2QSP-Ye9JKQSI#FMvjUT9QSGTM9Y(FP2I#YJFH#QSPVJZ:Yb}h Yb2} hKc2F\_XvnKIXFHuKcfO\_FG]KIPKaJQSPZXcYbFfiJT9KI%Y3I#Ffib/W9\_FvuKI9MK} G]KIkJT9F]bF]ZYb/FhemFoQSI(JVF]bf9bF]JVFM%e{Xc2FKI9PLYZ0N8KabQ_Y3W9PBb/W9\_F%<$ % % p.QSIK2IOKQ_NFoGHY3INF]b/P/Q_Y3IYZ K2}h YbUK2} QSI(JVY2b/W9\_FfiPVF]JP]vOKI(X%FHuKc2f`\_FoPKaJQSPV^9FPLFH#KGHJ\_XY3I#FlbW9\_F }hFG]QSPQSY3IGHY3ccQ_JVJVF]FPbFPVFcffeO\_FYb[FI#F]b/K\SQS]FlYJT#F]bbW9\_FPVF]JPip Y3T#FI r #QSI#[F]bvxyyy3 +I1JT9QSPfOKafmF]bv"JT#FKW#JT#YbP%GHY3IOPQSM#F]bk} fiPT9KafmFMZ:Yb/cffWO\SKP]vUQSI1jUT9QgG/T1JT#FiY3W9JVfOW#JYZKcY3I#Y3cQSK\"QgPI#YJKG]\SKPPp.G]K\S\_FM ff+fmY3PQSJQ_N2F veOW#JKp.I#Y3!I fiI#F][3KaJQSNFGHY3I#^`M#FI9GHFiQgIJT#FG]\SKPP/Q_^OG]KaJQ_Y3I2KPRfY3P/Q_JQ_NF M9F]Z:KW9\SJ G]\gKPPf9bFMOQSGHJPJT#FYJT#F]bnG]\SKPP]v(G]K\S\_FM ffVI#F][3KaJQSN2F p:JT9QSPRQSPdKPVF]JVJQSI9[ojUQ_JT-JjnY!G]\SKPPFP Y3c2fOW#JQgI#[ JT9F"G]\SKPP YZmKI2YeOPVF]bNaKaJQ_Y3IemY3QS\SP M#YjUIJVYPW9ccQSI#[hJT#FGHY3I#^OM9FI9GHFPRYZ7JT9FUb/W9\SFPdQ_JBP/KaJQSPV^9FP]v{KI9MJT9FIM#FG]QgM9QSI#[oJT#F fmY3PQ_JQ_NFUG]\gKPPBQSZJT9F PW9c QSPd[b/FKaJVF]bJT9KI]F]bY#vdKI9MJT#FkI#F][3KaJQ_NFkG]\SKPP-YJT#F]bjUQgPVF}hFG]QSPQ_Y3IGHY3ccQSJVJVF]FP-Kab/F%Ki[FI#F]b/K\SQSKaJQ_Y3IYZJT#FPVFoZ:Yb/c-W9\SKP]vuQSI%jUT9QgG/T%jBFfibFcYNFJT#FoPVF]JVJQgI#([ P"GHY3I9PVJVbKQSIJp:J)jBYG]\gKPPVFPBKI9MKW#JT9Yb/Q_]FfiJT#Fc2FcffemF]b/PT9Q_ff9bFM9QSGHJQSY3IJVY2KabeOQ_JVbKabX2G]\SKPPVFP]vuJT#F]b/F]e(X\SFKM9QSI#[JVY2KffJVb/W#F NYJQSI#[G]\SKPPQ_^OF]b"T9QSPNYJQSI#[kZ.KPT9Q_Y3I5QSPfiK%Z:FKaJW#bFJT9KaJM#FG]QSP/Q_Y3IiGHY3ccQ_JVJVF]FPPTOKabFjUQ_JTM#FG]QSPQ_Y3IJKaeO\SFPp Y3T9KNuQ r{Y3ccF]b^9F\SM7v`xyy3#" YjnF]NF]bv#M#FG]QSPQ_Y3IJKaeO\_FPnG]\SKPPQS^9F]b/PdKabF eOKPVFMY3IcK VYb/Q_J)X2NYJQSI#[-YZ7JT#F:<;%$fiFH#Kc2fO\_FP-p.KI9MI#YJUYZb/W9\_FPv#YNF]boK2bFPVJVb/QgGHJVFM ff+jUQSIOM#Yjfi YZ JT9F!M#FPGHb/QSf9JQ_Y3INaKab/QSKaeO\SFP]R"T#F]XI#FGHFPP/Q_JKaJVFJT#F2PVJVYb/QSI#[%YZRcKI(XlFH#Kc2fO\_FPvmKIOMiJT9F-QSI(JVF]bf9b/F]JKaJQ_Y3I9PhYZdJT#F2M9KaJKkG]KIY3I9\_XlemFcKM#FJT#bY3W#[3TJT9QSP!jUQSI9M9Yjv KG]GHYb/M9QSI9[JVYJT9QSPfmYJVFI(JQSK\S\_X\SKab/[FPVF]J-YZ"FH#Kc2fO\_FP]l}hFG]QSP/Q_Y3IGHY3ccQSJVJVF]FPb/KaJT#F]bbF]fObFPVFI(J KIF G]Q_FIJjLKX-JVYoFI9GHYuM#FKfiNYJQSI#[oc2F]JT#YuM2QSI(JVYoKoPcK\S\{I(WOc!emF]bYZb/W9\_FP]v3KIOMJT#FjnKX-KoG]\gKPPdQSP [3Q_NFI2G]KIeFLe9b/Y3W#[3TJe`KG -JVYFKab/\_XffjBYb uPdQSIcKGT9QSI#F"\SFKab/I9QSI#[p \SKab r qnY3PVjnF\S\wvxyyux YbFZ:Yb/cK\7M#F]JKQS\gP"KabFf9b/YNuQSM#FMQSIkJT#FI9FH{JUPFGHJQ_Y3I7c2Y3I#[lY3W9boJT#F]YbF]JQSG]K\RbFPW9\_JPv7JT9KaJKabFf9b/FPVFIJVFMQSI5JT#F2Z:Y3\S\_Yj QSI#[PVFGHJQ_Y3I7vjBFfObYNuQSM#FZ:Yb/cK\9fObY(YZ.PJT9KaJBJT#F P/QSc2fO\SQgG]Q_JX fiKG]G]W#b/KGHX-JVb/KM#F]Y *QSPRK\SPVYffTOKab/M2JVYffKGT9Q_F]NFhZYbn} v(KPRjBF\S\`KPZ:Yb0JT#FnGHY3I9PVJVb/WOGHJQ_Y3I!YZ`GHY3c2fO\_FHoNYJVFPQSI(NY3\_NuQSI#[U}fio8"T9QSP0\SKPVJb/FPW9\_JP/T#YjUP0JT9KaJ]vjUTOQS\_FdcQ #QSI#[+# jUQ_JTemY{Y3PVJQSI#[f9bYNuQSM#FPUY3I#F!YZJT9Fffc2Y3PVJ fmYjnF]bZ:WO\G]\SKPP/Q_^OG]KaJQ_Y3IlK\S[Yb/Q_JT9cP-p.#b/Q_FMOcKI7v"hKPVJQ_Fv r "Q_eOPTOQ_b/KI9Qwv~avOf9b/W9I9QgI#[oemY(Y3PVJQgI#[ffQSPnFPPFIJQSK\g\_XT#FW#b/QgPVJQSG!p Kab[3QSI#FKI(JW r }fiQ_F]J fiJVF]b/QSGT7vxyy3"T9FK\_[YbQ_JT9c jBF5f9bYfmY3PVFZ:Yb%JT9F5QgI9M9W9GHJQ_Y3I YZ!}v p:Z:Yb FK 1+I9M9WOGHJQ_Y3I YZ}hFG]QSPQ_Y3I Y3ccQ_JVJVF]FPvdT9KPffJT#F%ZY3\S\SYjUQSI9[ F]XZ:FKaJW#bFP]i)JW9PVFPffbFGHFI(J-b/FPW9\_JP!Y3IfOKab/JQ_JQ_Y3IemY(Y3PJQSI#[#v3b/KI {QSI9[!\_Y3PPReY{Y3PVJQSI9[pDuG/T9Kaf`Q_bF r uQSI#[F]bvxyy3dKIOMPVY3c2FhKaemY3W#JRf9bW9I9QSI#[oqnY{Y3\_FKIZ:Yb/cffWO\SKP-p FKab/I9P r KIOPVY3W#bvxyy3ZY3\g\_YjUPhKkPG/T9Fc2F2G]\_Y3PVFJVY +# & PfiZYboM#FG]QgPQ_Y3IJVbF]FPfip fffiWOQSI9\SKI7v`xyy +(v9Yb } PnZYbM#FG]QSP/Q_Y3I\gQSPVJPfip UYuG r Kaf9f{Xv7xyy3 zuKPP/W9G/T7vuQ_JLM9Q *mF]b/PZ:bY3c f9b/F]N{Q_Y3WOPUPVJW9MOQ_FP"QSINYJQSI#[G]\gKPPQ_^9F]bPffp:emY(Y3PJQSI#[#v9eOKa[[3QgI#[p.qnbFQScKI7v0xyy|3V e{XZFKaJW9bFPPW9GTffKP0JT#FnZ:KGHJ JT9KaJ I#Y c2YuM9Q_^`G]KaJQ_Y3I!QSP0cKM#FBY3I!JT#FnFH#Kc2fO\_F P M9QSPVJVbQ_eOW#JQ_Y3IfiM9W9b/QSI#["QSIOM9W9GHJQ_Y3I7JBQSPBK\SPVY-Y3I#F Q_Z7Q_JPnM9Q *mF]bFI9GHFPRjUQ_JTJT#Ffi #BE b/WO\_FUQSI9MOW9GHJQ_Y3IKaf9fObY3KG/T5p Y3T#FI r #QSI#[F]bvxyyy3fiIcffWO\_JQSG]\SKPPKIOMc-W9\_JQS\SKaemF\{f9bYe`\_FcP] v f9bYfmY3PVFPdK!NF]bX2Z:KPJRKI9MP/QSc2fO\_FPVY3\gW#JQ_Y3IJVYob/K(I uQSI#[o\_Y3P/P0emY{Y3PVJQSI#[#vYfOJQScK\#QSI-Z.KQ_b/\_X[FI9F]b/K\#G]KPVFP]v{KI9M2KPVXuc2f9JVYJQSG]K\S\SX!Yf9JQScK\{QgI2c2Y3PVJYZ7JT#FhbFcKQSIOQSI#[oY3I#FP]dUT#FU[FI#F]bK\Of9b/YeO\_Fc YZ7bK(I {QgI#[!\_Y3PPBemY(Y3PJQSI#[jLKPnf9bF]NuQ_Y3W9P\_XGHY3I VFG fiJW#bFfi "hKab/MpDuG/T9Kaf`Q_bF r uQgI#[F]bvxyy3"T#Y3W#[3TlY3W#b"b/K(I uQSI#[2\_Y3P/P"emY(Y3PJQSI#[2K\_[Yb/Q_JTOc QSPI#YJLK\_jLKXuPLYf9JQScK\wv{jnFfiK\gPVY-P/T#YjJT9KaJLJT#Fh[FI#F]b/K\b/K(I uQSI#[-\_Y3PPnemY(Y3PJQSI#[!fObYeO\_Fc bF\SKaJVFM%JVYuGT9KafOQ_bF r uQSI9[F]bffp+xyy3"QgPUKGHJW9K\S\SXkI9YJ fi " KabM7v`KI9MG]KIemF!PVY3\SNFMQSIfmY3\_XuI#Y3cQgK\mJQSc2FvJT#Y3W#[3TQ_JRPVF]FcPdJVY!b/F(W9QSbFJT#FUW9PF"YZGHY3c2fO\_FH2KI9MJQSc2F fiDFHufFIOPQ_NFUK\_[YbQ_JT9cP]vbF\SKaJVFMJVYffJT#FcQSIOQScQ_KaJQ_Y3IlYZ p.PVXucc2F]JVb/QSGUPW#e`c2Y{MOW9\SKab"Z.W9I9GHJQ_Y3IOP]U"T9QgPUK\SPVY%fOKabJQgK\S\_X VWOPVJQ_^9FPUJT#F-WOPVFffYZY3W#bUP/QSc2fO\_FfiKI9MZ.KPVJUKafOf9bY#QScKaJQSY3IK\_[Yb/Q_JT9cl"T9F\SKPVJ-PVFGHJQ_Y3IYZJT9QSPfffOKafmF]b!fObFPVFI(JP!FHufmF]b/QSc2FI(JK\dbFP/W9\_JPffYe9JKQSI#FMjUQ_JY3IJT9Q_b/JX fiDY3I#FM#Y3cKQSIOP]v c2Y3PJlYZffj T9QSG/TKabFbFKM9QS\_X1KNaKQS\SKaeO\_FKI9MtG]KIemFZ:Y3W9I9MY3ItJT9FbF]fmY3PQ_JVYb/XYZcKG/TOQSI#F\_FKab/IOQSI#[2M9KaJKaeOKPVF%p.qn\gK Fv F]Y[3T7v r F]b/vxyy3+IYb/M9F]b!JVY F]F]fJT#FfOKafmF]b!PVF\_Z fiGHY3IJKQgI#FMKI9MKPffGHY3IOG]QSPVFKI9MbFKM9KaeO\SFKP!fmY3PP/Q_eO\_Fv7jnFT9KNFfiGT#Y3PVFI%JVYfOW#JnKIKaf9fmFI9MOQ KaJBJT#FhFI9MYZJT#FhfOKafmF]bnGHY3I(JKQSI9QgI#[ffK\S\`f9bY{YZ.PRYZY3W9bBbFP/W9\_JP]Cff< #C aCD? > ?F]J"! eF2JT9FI(W9cffemF]boYZG]\SKPPVFP]# I9\SFPPfiYJT#F]bjUQgPVFPVfmFG]Q_^9FM7v0KIFHuKcfO\_F$QSPoKlGHY3W#fO\SF$%p'&)(*!,]+ UjUT9F]bF"& QSP KIYeOPF]bN8KaJQSY3IiM#FP/GHb/Q_emFMlYNF]b.- NaKab/QSKaeO\SFP]v`KI9M/!,+ Q_JPhGHYbbFPfY3IOM9QSI#[G]\gKPPKc2Y3I#[10 2( x3(5464646(*!87 x:9 z3JVYFKGTFH#Kc2fO\_Fp'&)(*!,+ QSPKPPVYuG]QSKaJVFMKfijnFQ_[3T(J<; pVp'&)(*!,+ Vvb/F]f9bFPVFI(JQSI#[Q_JPfiKaf9fmFKab/KI9GHF-f9bYe`KaeOQS\SQ_J)XkjUQ_JTibFPVfmFGHJfiJVYkK%\_FKab/IOQSI#[P/Kc2fO\_F1=?> jUT9QgG/TijBF2M9QSPfY3PFYZ)@=A>QSPhQ_JPVF\_ZK%PW#eOPF]JUYZRKjUT#Y3\_F-M#Y3cKQSIijUT9QSGTljnF-M9FI#YJVFClB fifie(NuQ_Y3W9P\SXvOjnF-M#Y%I#YJfiT9KNFFI(JQ_bFKG]GHFPPnJVY1B p'=A>EDF%B QSI2[FI#F]bK\wvjnFUF]NFI%T9KNFG =?>HGJIKGLB#G p*GM4N3G M9FI#YJVFPRJT9FUG]Kab/M9QSIOK\SQ_JXz3jnFPW#fOfY3PFhQSIkK\S\JT9KaJLZ:Y3\S\_YjUPLJT9KaJHB QgPnMOQSPGHbF]JVFfijUQ_JT^OI9QSJVFfiG]KabM9QSI9K\SQSJX9 +I%JT#FfifOKabJQSG]WO\SKabG]KPVF:PORQfiiwcffffjUT#F]b/FA! %t~{v(JT#FLJjnY!G]\SKPPFPKabF"I#YJVFM ff fi p'!,+ % KI9M ff p'!,+ % xvKIOM2G]K\S\_FMbFPVfmFGHJQ_NF\SXJT#FkI#F][3KaJQ_NFKI9MfmY3PQ_JQ_NF%G]\SKPP]5"T#F%\_FKab/I9QSI9[iPKc2f`\_FQSPffJT#FkW9I9Q_Y3IYZ"JjnYPKc2fO\SFP]vI#YJVFM=?>KI9=A>Bv(GHY3I(JKQSI9QSI#[!bFPVfmFGHJQ_NF\_XJT#FhI#F][3KaJQ_NF KIOMfmY3PQ_JQ_NFFH#Kc2fO\SFP] )JnQSPjnYbJTj T9QS\_FJVY-JT9QS(I -JT#FUfmY3PQSJQ_NF"FH#Kc2fO\_FPBKPRemF\_Y3I#[3QgI#[oJVY-KffPW#eOPF]JdYZ B GHY3IJKQgI9QSI#[-K\S\9fmY3PPQSeO\_FLfmY3PQ_JQ_NFFH#Kc2fO\_FP]v9WOPW9K\S\_XG]K\S\_FMJT#F " 3{ ff.PfifOKabJoYZBY3W#bo[Y3K\dQSI5cKGT9QSI#F2\_FKab/IOQSI#[#v7QSPhJT#FI#F]FM5JVYeOWOQS\SMKkb/F\SQSKaeO\_F-Kaf9f9bYuQgcKaJQ_Y3IJVYJT#F!JVb/W#FG]\SKPP/Q_^OG]KaJQ_Y3IkYZ JT#FFH#Kc2fO\SFP"QSBlv9JT9KaJUQSPv9K[Y(YuMKaf9fObY#QScKaJQ_Y3IkYZ JT#FoJKab/[F]JGHY3I9GHF]f9J]ve{X!W9P/QSI#["Y3I9\SXoJT#FBFH#Kc2fO\SFP0QS"=?>n Y{Y{M-Kaf9f9b/Y#QScKaJQ_Y3I9P PT9K\g\T9KNFLKhT9Q_[3TffKG]G]W#b/KGHXYNF]b Blv{K\_JT9Y3W#[3T2jnF M#Y!I9YJRT9KNFfiKG]GHFPPBJVY!JT9QgPd(WOKIJQ_J)Xv(e`W#Jdb/KaJT#F]bBJVYffQ_JPdFPVJQScKaJVY2b Kffc2YbFYb\_FPPb/F\SQSKaeO\_F%KG]G]W#b/KGHXGHY3c2fOW9JKaeO\_FkYNF]b =?>n FlbF]Z:F]b2JT#FkbFKM#F]bJVYPVJKIOM9Kab/McKG/TOQSI#F\_FKab/IOQSI#[emY(Y uPffp Q_JG/T9F\S\wvxyy3"ZYb Z:W9bJT#F]bUGHY3I9P/QSM#F]b/KaJQ_Y3IOP"KaemY3W#J"JT9QSPUQSPPW#F } GHY3IJKQgI9PJjnYf`KabJPfi0(p ff ( P9 ( . j T#F]bF"FKGT 7QSPdK!cY3I#Y3cQSK\p.KffGHY3I!fi( . (5464646( ( 9 p -emFQSI9[ JT#F"I{W9cffemF]b YZmM#FPGHbQ_f9JQ_Y3INaKab/QSKae`\_FP]v7FKG/T!#"QSPoKfmY3PQ_JQ_NF2\SQSJVF]b/K\ KI9MFKG/T #"QSPoKI#F][3KaJQ_NF%\SQ_JVF]b/K\vKIOM5FKG/T$QgPffKiNFGHJVYbQSI!% &(H' 5#YbJT#F%P/KF%YZUbFKM9KaeOQS\gQ_JXv JT9QSPffNFGHJVYb/QSK\LI#YJKaJQSY3IP/T9K\S\demF F]f9JPVF]JBYZ7W9I#Yb/M#F]b/FM2fOKQ_b/P p:YbRb/W9\SFPW9I9GHJQSY3IYZ`\SQ_JVF]bK\SPYNF]bH0 ( ( ( ( .JT9bY3W#[3T#Y3W#JK\S\JT#FfifOKafmF]bvuF]NFIZ:Ybf9bYe`\_FcPBjUQ_JT%Y3I9\_XJ)jBYG]\SKPPVFP]BoI#FocQ_[3T(JLGT#Y{Y3PVFJVYKM9MlKPQgI#[3\_FfibFK\7b/KaJT9F]b"JT9KIlK~ fiGHY3cfY3I9FIJ"NFGHJVYbfiQSIJTOKaJ"G]KPVF}hF]Z:KW9\SJ FGHJVYb ) QSI - 2(x / ' [3KQSI7v7QSIiJT#FJjnYfiG]\SKPPG]KPFvQ_JfiQSPfiPW(G]Q_FI(JhJVY%b/F]fO\SKGHF) e{XkK2M9F]Z:KW9\SJ"G]\SKPP"QSI0 ( 7 93#YbffKIXiYeOPVF]bNaKaJQ_Y3I%& KI9M5KIX5c2Y3I#Y3cQgK\* v7JT#Ff9bYfmY3PQ_JQ_Y3I ff &kPKaJQSPV^9FP+ QgPhM9FI#YJVFMe{X&-,. "T#F2YfOfY3P/Q_JVFfffObYfmY3PQ_JQ_Y3Iff k& M#Y{FPoI#YJPKaJQSPVZ:X/ QSPfiM#FI#YJVFMe{Xff &1,20 u2"T#FG]\SKPP/Q_^OG]KaJQ_Y3IkYZKI(X%Ye`PVF]bNaKaJQ_Y3I& QSPcKM#FffQSIkJT#FoZ:Y3\S\_Yj QSI#[jnKX nM#F]^OI#F 3 h+ KP"Z:Y3\S\_Yj P3 + %44p (&5,6fi"T9FG]\SKPP"KPP/Q_[3I#FMJVY&QSP"JT#FI9fi Kab/[BcK8 " 3 + Q_ZAGKab[ncK8 " 3 + G % xavOKI9Mfi Kab/[BcK8 "879J9:<;>A=? @ ) YJT#F]b/jUQSPVF+ IYJT#F]bBjBYbM9P]v(QSZJT9FUcK8#QScK\9GHY3c2fmY3I#FI(JRYZ 3 + QSPRWOI9QS{W#FvJT#FIJT9F QSI9M9FH-[3Q_NFPBJT#FUG]\gKPPKPPQS[3I#FMJVYC&{BhJT#F]b/jUQSPVFv{jBFhJKFoJT#FfiQSI9M#FHYZJT#FocK8uQgcK\OGHY3c2fmY3I#FI(JLYZ ) GHYbb/FPVfmY3I9M9QSI#[JVYkJT#F2cK8#QScK\ GHY3c2fmY3I#FIJfiYZ 3 +%p:JQ_FPfiKabF2PVY3\_NFM5e{XK%b/KI9M#Y3cG/T9Y3QSGHF2Kc2Y3I#[kJT#F2cK8#QScK\GHY3c2fmY3I#FI(JP} GHY3IJKQSIOP-KPW#e7G]\SKP/PojUT9QSGTQSP-Kc2Y3I#[iJT#Fk\SKab[FPVJG]\SKPPVFPffYZ"qnY(Y3\SFKIZ:Yb/c-W9\SKPffJVYiemFr KPG]W#F\wv9xyy 3v{T#YjnF]NF]bJT9QSP G]\SKPP QSP \_FPP QSI(JVF]bFPVJQSI9[UZ:bY3c KUf9bKGHJQSG]K\fi\_FKab/IOKaeO\_Fop UYuGNuQ_F]j"fmY3QSI(JfiP/QSI9GHFb/W9\_FPoG]KIemFI(W9cF]bY3W9PoKI9MTOKab/MJVYQSI(JVF]bf9b/F]J] UF]NF]bJT9F\_FPP]v KlPW#e7G]\SKPPfiYZ} p UYuG r KP/G]W#F\wvRxyy 3hfObFPVFI(JPoKIQSI(JVF]bFPVJQSI#[kGHY3c2f9b/Y3cQSPVFemF]JjnF]FIbF]f9b/FPVFIJKaJQSY3I9K\fmYjnF]bKI9M QgIJVF]bfObF]JKaeOQS\SQSJXfmYjnF]b +ItJT9QSPG]\SKP/P]vfijUT9QSGTQgPlW9PVFMe{X !vFKGT YZJT#FNFGHJVYbLGHY3c2fmY3I#FIJPRKabF"bFPVJVbQSGHJVFM2JVC0 73x (2 ( :x 9fiKI9MFKG/TcY3I#Y3cQSK\#QSPdf9bFPVFI(JdKaJRc2Y3PVJRY3I9GHF:PO5:fi"T#FkNaK\SW#FP 7xavnuv xK\g\_Yj I9KaJW#bK\QSIJVF]b/f9bF]JKaJQ_Y3I9PYZ JT#Fb/W9\SFP]vemFQSI#[FQ_JT#F]bQSIZ.KNYbYZJT#FGHYbbFPfY3IOM9QSI#[G]\SKPPlp xvnI#FW#JVb/K\njUQ_JTbFPVfmFGHJJVYJT#FG]\SKPPlp.vBYbQSIM9QSPVZ.KNYb2YZ JT#FGHYbbFPfY3IOM9QSI#[%G]\SKPP2p 7x!"TOQSP P/W#e7G]\SKPP]vJVYkjUT9QSGTjnFbF\SKaJVF2KPo} ( 0 ( v7QSP]v7KPfijBF2I#Yjf9bYNFvnP/W *F]bQSI#[JT#FPKc2FlK\_[Yb/QSJT9cQSG%M#b/Kj"eOKG uPKP2}fi p " X3Ka^O\ r EUQSNFPVJ]v xy3a|3KI9M}p Y{G r Kaf9f{Xv7xyy3< RF]NFI%jUQ_JT9Y3W#JRbFPJVb/QSGHJQSI#[ffJT#FoGHY3c2fmY3I#FI(JPBYZJT#F NFGHJVYbP]v9YbLjUQ_JT%KIXbFPVJVbQSGHJQ_Y3IJVY5KPVF]J2GHY3I(JKQSI9QSI#[KaJ2\_FKPVJ-Y3I#Fb/FK\BNaK\SW#FvJT9F%GHY3I9PJVb/W9GHJQ_Y3IYZUPcK\g\RZ:Yb/c-W9\SKPjUQ_JTP(W G]QSFIJ\_XT9QS[3TKG]G]W#b/KGHXQSP!TOKab/M7"TOQSP!QSPffKiG]\SFKabcYJQ_N8KaJQSY3IZ:Yb-WOPQSI#[T9FW#b/QSPVJQgG]PQSIM#FG]QSP/Q_Y3IGHY3ccQ_JVJVF]F P QSI9M9WOGHJQ_Y3I7?Cff > @}C Cd< ABC@BC >fiff z N#AJ # C aC? > %(@F I9YjPT#Yj1JT9KaJRe`W9QS\SM9QgI#[ M#FG]QgPQ_Y3IGHY3ccQ_JVJVF]FPBQgPdK!T9KabMK\_[Yb/Q_JTOcQSGLJKP 2jUT9FI2Y3I#FUPVJVbQ_NFPJVYYe9JKQgIkeYJTP/cK\S\mKI9MlKG]G]W#bKaJVFZYbcffW9\gKP]d"T#F]bFoKabFoJ)jBY%W9PW9K\mI#YJQSY3I9PLYZ P/Q_]FojUT9QSGTG]KII9KaJW#bK\S\_X%eFffW9PVFMlZ:YbfiM#FG]QSPQ_Y3IGHY3ccQ_JVJVF]FP] "T#F!^Ob/PVJ"Y3I#F-QSP"JT9F!jUT#Y3\SF!I(WOc!emF]bUYZd\gQ_JVF]b/K\SPYZr KPG]W9F\wvxyy {zJT#FZYb/c-W9\SKp.Q_ZK\SQ_JVF]bK\dQSPfObFPVFI(J hJQSc2FP]v Q_J!QSPffGHY3W9I(JVFhJQSc2FPp UYuGr Kaf9f{Xvxyy3vRJT#FkPVFGHY3I9MY3I#FkQSPJT#FkI{W9c!emF]bffYZ"b/W9\_FP!YZ"JT#F%ZYbcffW9\gKp FKab/I9Pv QwvY{GRQSJVJ]v r dK\SQSKI(J]v0xy3fiW#bUb/FPW9\_JP"Qgc2fO\_X%JT9KaJhbF][3Kab/M9\_FP/P"YZJT#FffbFPVJVb/QSGHJQSY3IlYNF]bfiJT#F-NaK\SW#FPYZJT#FffNFGHJVYb/P2p.KP \_Y3I9[KP JT#F]XKabFffF\SFc2FIJP YZdKPF]JUjUQ_JTG]Kab/M9QSI9K\gQ_JX t~3vKI9MiK\_bFKM#XkZ:YbJjnY fiG]\SKPPFPfif9bYeO\_FcP]vOcQSIOQScQ_QSI9[-JT9FffPQ_]FffYZdKM9FG]QSPQ_Y3IiGHY3ccQ_JVJVF]F-ZYbhemYJTPQS]FffM#F]^OIOQ_JQ_Y3I9PQSPoKPTOKab/MKPPVY3\_NuQSI#[%jnF\S\ fi uI#YjUfi "hKab/M5f9bYe`\_FcP]"T#F]bF]Z:YbFvJT9F-JKP 5QgPoK\SPVYT9Kab/M5Z:Yb} ( 0 ( jUQ_JTkJT9FfOKabJQSG]WO\SKabLN8K\SW9F@P 7xavOuv xfiZYb"JT9FNFGHJVYb/P]! #"%$3'&("*))%+-, '.0/1"2.43#5" 6.874.:9 <;8" =3?>@A"*)CBAD75"6;'.#" E"F> HGI %KJML ":PRQSJ %UT "%<$ WV "%J %YX ! $ZT ] [N !\J ] "! %K]^J J % _` " [V ba V %KT "! ! % cV dJ %eJ fTgTgJ (%KJ % XhJ " % [N ji "fT! % =?> 1k36)jl {F]FoJT#F f9fmFI9M9Q_F%G]KIFKPQg\_XKMOKaf9J!"T#F]Yb/Fc x2JVYiJT#FG]KPVFjUT#F]bFJT9Fb/W9\_FP!KabFbF]fO\gKGHFMe{XjnFQ_[3T(JVFM}fi KPKM#NYuG]KaJVFMQSIeY{Y3PVJVFM +# pDuG/TOKafOQ_bF r uQgI#[F]bvUxyy3 "UF]bFvnFKG/T JVbF]FlbF]JW9b/I9P2KG]\SKPPm 0 x3( 7x:93vKI9MFKG/T JVbF]FlQSP[3Q_NFIK5b/FK\LjBFQ_[3T(J2JVY\_F]NF]bKa[FlQ_JPNYJVF"T#FPQ_[3IYZJT#F\gQSI#FKab!GHY3cffeOQSI9KaJQSY3I[3Q_NFPJT9FG]\SKPPYZ"KIFHuKcfO\_Fk"T#F2Z:Y3\S\_Yj QSI#[JT#F]YbFc T#Y3\SM9P!Ka[3KQSIjUQ_JTkKI(X\SQgcQ_JKaJQ_Y3I9PBY3IJT#Fo\_F]NF]bKa[3QSI#[2GHY(F G]Q_FIJPffp.KP"\_Y3I#[2KPKaJ"\_FKPVJY3I9FfiI9Y3!I fiD]F]bY2NaK\SW#FoQSPKW#JT#YbQ_]FM`v{YbRjUQ_JT9Y3W#JR\SQScQ_JKaJQ_Y3I2Y3IJT#F GHY{F G]Q_FI(JP]dqnX2JT9QSPvjnF c2FKIJT9KaJRZ:YbnFKG/T%YZ7JT#FKaf9fO\gQSG]KaeO\_F!\gQScQ_JKaJQ_Y3IOPffp:YbfijUQ_JT#Y3W9JvJT9Ffff9b/YeO\_Fc QgP fi "hKab/M7o"T#FPQ_]FI#YJQ_Y3IQSP JT#F2PW9cvYNF]bfiK\S\mJVbF]FPv9YZ JT#FQ_b"I{W9c!emF]bYZI#YuM#FP]#" E"F>onqpJ % :_` " OV V %KT "! ! %%KJ % XhJ " % [N Wi "fT! % =?> ]vXhJ $ !wJ'TgJ ""%<%KJ ! !wJ'TgJ " J 2]."% ! 3 "% " ! "%X J 3 jV !\J " fT rJ " J (%-ONsPut _! ] aH " 3 J 3 yx dJ %j]+ N8_ L H "!4$ J % "$ JML jV61T9QS\_FffQ_JUQSPUjBF\S\ {I9YjUIJT9KaJ emY{Y3PVJQSI#[2b/FPW9\_JP QSIlKb/KafOQSMlM9FGHbFKPQSI#[YZJT#FffF]b/bYbUYNF]b =A>JjUT9QgG/TG]KI%FKPQg\_X2KI9MbKafOQSM9\_XM#bYf%M#Yj IJVY-]F]bYp.KPn\SY3I#[ffKPnQ_JBQgPdfmY3PPQ_e`\_Fv"T#F]Yb/Fc ~!PT#YjUPJT9KaJoKaJVJVFc2f9JPfiJVYkF G]QSFIJ\_XbFM9W9GHFJT#FPQ_]F-YZRJT#F-NYJVF2jUT#FIemY{Y3PVJQSI#[%}h QSP fi "hKab/M7fi)ZJT#F f9bYeO\_Fc QSPdPQScfO\SQ_^9FM-JVYffJT#FUJVY-f9b/W9IOQSI#[hYZK!\SKab[FhGHY3I9PQSPJVFIJBNYJVF YZ}fi p Kab[3QSI9FKIJW r}fiQ_F]JVJVF]b/QSGT7v7xyy3v9JVYYe9JKQSI%KPcK\S\_F]bnGHY3I9PQSPJVFIJp:YbLjUQ_JT%\SQScQSJVFMF]bbYbHNYJVFfijUQ_JTbFPVJVbQSGHJVFMPQ_]Fv#Q_JQSPLKa[3KQSIkfmY3PP/Q_eO\_Fp.W9PQSI#[-JT#FoPKc2Fob/FM9W9GHJQ_Y3I`dJVYPT#YjtJT9KaJJT9QSPne9bQSI#[3?P fi "hKab/M9I9FPP]:POEzfiniwcffff#"%$3'&("*))%+-, ' .0/1"2.43#5" 6 .874.G=3?>@A"*)) 3 ;'"F.FffI9YjPVJKaJVF-KI9Mkf9bYNF!JT#FoF{W9Q_NaK\_FI(JYZ"T#F]YbFcxfij Q_JTkJT9QSP"I9F]jPQ_]FI#YJQSY3I7#" E"F> GI %KJML [N "-PuQ J %uT "%<$ WV "%J % $ZT ] [N $ ! %j] J J % _` " OV= > 1 % %<$ !V %KT "! ! % UV( J %KJ fTgTgJ (%KJ % XhJ "% [N Wi "fT! %! V % H %X!#" !\J 3 %Wi "fT! %:J % "T r_ P N8$ !#"E] " J %j]fi"V J % $ J [N $# J'Pff fi5] "6 XhJ $ 3 " J !\J H "! % 1k36)jl {F]FoJT#F f9fmFI9M9Q_fObF]N{QSY3W9PjnYb 1p FKabI9P-F]JK\D_vLxy3fffObYNFP2KPQScQg\SKabJT#F]YbFc GHY3IOGHF]b/I9QSI#[iJT#FkcQSI9Q ficQ_KaJQSY3IkYZJT#FPQS]FhYZ K2} nO"T9F]YbFc-G]KIemFfiP/T#YjUI%JVYemFfic2YbFo[FI#F]bK\wv9KPLJT#FG]\SKPPLYZ} ( 0 ( jUQ_JTkJ)jBYb/W9\_FPPJVb/QSGHJ\_X%GHY3IJKQSIOP"JT9KaJ"YZ } j Q_JTkJjnYc2Y3I9Y3cQSK\SP]"T9F-PVJKaJVFcFIJfiYZBUT#F]YbFcP-xav~{v KPhYf9JQScQ_KaJQ_Y3Iif9bYeO\_FcPUjLKPfiG/T#Y3PVFI5Z:YbhfOW#bF-GHY3I!fiNFI9Q_FIOGHFffzubF]fO\gKG]QSI#[JT#Fc e{XJT#FQ_bLKPPVYuG]QSKaJVFMkM#FG]QSP/Q_Y3If9b/YeO\_FcPhp.M#FG]QSM#FhjUT#F]JT#F]bnJT#F]bFhFH#QSPVJKGHY3I9PQSPJVFIJnZYbcffW9\gK!jUT9Y3PVFhP/Q_]FhQgPnI9Y-c2Yb/FhJTOKI%PY3c2F ^9{FM%JT#bFP/T#Y3\SM`jBY3W9\gMJVb/QSN{QSK\g\_X2cK FJT#FfObYeO\_FcPLI#YJUY3I9\_#X fi "hKab/M7v9e`W#J"K\SPVfi Y3c2f`\_F]JVF< C ?IlK\_[Yb/Q_JTOcv#} vOjnKPUf9bF]NuQ_Y3W9P\_Xf9bYfmY3PVFMp Y{G r KPG]W9F\wvxyy 3"ZYb eOW9QS\SMOQSI#[!M#FG]QgPQ_Y3IHG Y3ccQSJVJVF]FP])Jf9bYuGHF]FM9P2QSIJ)jBYPJKa[FP]"T#Fk^9b/PVJPVJKa[Fle`W9QS\SM9PffK5fmYJVFIJQSK\g\_X\SKab[FlP/W#eOPVF]JYZLM9Q *mF]bFIJfib/WO\_FP]vmFKG/TYZRjUT9QgG/T5QSPoKGHJW9K\S\SXiK} ( 0 ( jUQ_JTY3I9\_XiY3I#F2b/W9\SFIKPFGHY3I9MPVJKa[Fv Q_Jo[b/KM9WOK\S\_XiG]\gW9PVJVF]b/PoJT9FM#FG]QSPQ_Y3IGHY3ccQ_JVJVF]FP]v W9PQSI9[%JT9Ff9bYfmF]bJ)XiJT9KaJ!JT#FW9I9Q_Y3I5YZJjnY!} ( 0 ( Pj Q_JT2M9Q *mF]bFI(J bW9\_FPQSPPVJQg\S\uKo} ( 0 ( JRJT#FFI9MYZmJT9QSP f9b/Y{GHFM9W9bFvJT#FW9PVF]bnYe9JKQSIOPRK-PVF]JBYZ} Pv{KI9MJT#Fhc2Y3PVJLKG]G]W#b/KaJVFfiY3I#F QgPBGT#Y3PVFI%KI9Mb/F]JW#b/I#FM7 d{fmF]b/QScFIJK\bFPWO\_JPM9QgPVfO\SKXhJT9FnKaeOQg\SQ_JXoYZ#+} JVY eOWOQS\SMPcK\S\} P] +I!JT9KaJ fOKafmF]bv8jnFBf9b/YNuQSM#FBKIK\_[YbQ_JT9cZ:YbR\_FKab/I9QgI#[oM#FG]QSPQ_Y3I2GHY3ccQ_JVJVF]FPBjUT9QSGT2T9KPRKMOQ *F]b/FIJdPVJVbW9GHJW#bF"PQgI9GHF"Q_JeOW9Qg\SM9P0Y3I9\_X-Y3I#FU}YbFof9bFG]QSPF\_Xv QSPLKJT#b/F]FfiPJKa[F!K\_[Yb/Q_JTOc )JL^9b/PJne`W9QS\SM9PBKPVF]JYZb/WO\_FPLM#F]b/Q_NFM%Z:bY3cbFPWO\_JPY3IlemY{Y3PVJQSI#[2M#FG]QgPQ_Y3IJVbF]FPpDuGT9KafOQ_bF r uQSI#[F]bvxyy3nJ"JT#FIiG]K\SG]W9\SKaJVFPUJT#FNFGHJVYb/PW9PQgI#[KP/G/T#Fc2FkM#F]b/QSNFMZ:bY3c EUK(I uQSI#[\SY3PP!emY{Y3PVJQSI#[pDuG/T9Kaf`Q_bF r uQSI#[F]bvnxyy35J!^OI9K\g\_Xf9b/WOI#FPhJT#F^OI9K\ } ( 0 ( W9PQSI#[%JjnYlfmY3PPQSeO\_FffP/G/T#Fc2F2P fiKIOKaJW#b/K\ f9b/W9IOQSI#[j T9QSG/TjnFG]K\S\ff+fmFPPQScQSPVJQSG%f9b/WOI9QSI#6[ uvRKIOMf9b/WOI9QSI#[5W9PQSI9[\_Y{G]K\UGHY3INF]b[FIOGHFb/FPW9\_JPlp FKabI9P r KI9PY3W#bvxyy3v jUT9QSGT5jBFG]K\g\ ff+Yf9JQScQgPVJQSG-f9b/W9IOQSI#6[ uffUT#FM#F]Z.KW9\_JfiNFGHJVYb-QgPoK\_jnKX{PffG/T#Y3PFIJVYlemF2JT#FYeOPVF]b/NFMlM9QSPVJVbQ_eOW#JQ_Y3IYZKc!e`Q_[3W#Y3W9P\SXG]\SKPPQS^9FMkFHuKcfO\_FP]B&$*"=+"'.r'" ,j<> > 8 7d74"F" 3#.r#"($ kN$5787'"! 3';S#"%$6. 7#"($3u W#fOfY3PFUJT9KaJJT#FT(X{fYJT9FPQSPop.I#YJI#FGHFPPKabQS\_XKM#FG]QgPQ_Y3IkGHY3ccQ_JVJVF]Fv`Q_JcQ_[3T(JBemF214351BKM#FG]Q fiPQ_Y3IJVbF]F jnFUe`W9QS\SMbFK\gQ_]FPRK!fOKabJQ_JQ_Y3IYZ7JT#FUM#Y3cKQgI B QSI(JVYffM9QSP+Y3QSI(JdPW#e`PVF]JP*) ( (+) . (5464646(+)-,ffQ KP - - . / /0JT#FoZ.W9I9GHJQ_Y3IlbF]JW#b/I9QgI#[ffJT9FJVb/W#JTkNaK\SW#FoYZKf9bFMOQSG]KaJV/F . d}hF]^OI#F0 " 1 %0 " 1 %4; pVp'&)(*!,+V - -_p'&)(*!,+vm)5"76 ,! +A%98 / / (+, ' @ 1 732544; pVp'&)(*!,+V - -_'p &)(*!,+vm)5"76 ,! + %90 8 / / 4+, ' 2@ 1 37 254:PO ;fi"+IkYJT#F]b"jnYb/M9P]v 0 1 bF]f9bFPVFI(JPJT#FfiZ:b/KGHJQ_Y3IYZ FH#Kc2fO\_FPLYZ G]\SKPP 80f9bFPVFI(J"QSIkPW#e`PVF]J )5"v"KI9M 0 1 bF]fObFPVFI(JPBJT9FhZ:b/KGHJQ_Y3I%YZ0FHuKc2f`\_FPnYZ0G]\SKPPFP %90 8f9b/FPVFIJLQSI%PW#eOPF]J )5"3 G]GHYb/MOQSI#[JVY%uGT9KafOQ_b/F r uQSI#[F]b!p+xyy3vmKjnFK l\_FKab/I#F]b"PT9Y3W9\SMcQSIOQScQ_]F JT#F!GHb/Q_JVF]bQ_Y3I9%~ 40 " 1 0 " 1 4" 14p+x+IJT#F%G]KPVF%YZLKM#FG]QSP/Q_Y3IJVbF]Fv JT#FfOKabJQ_JQ_Y3IQSPJT9KaJffjUT9QSGTQSPeOW9QS\_JKaJffJT#F\SFKNFP-YZJT#FJVbF]FpfifffiWOQSI9\SKI7v xyy+(z0QSIJT#FG]KPVFYZnKM#FG]QSPQ_Y3I5\SQgPVJ]vmJT#F2fOKabJQ_JQSY3IQgP JTOKaJojUT9QSGTQSPheOW9QS\_JhKaJFKG/TkbW9\_FvJVY-jUT9QgG/TjnFfiKM9MJT9F PW#e`PVF]JBKPPY{G]QSKaJVFM%JVY-JT#FfiM#F]Z:KWO\_JRG]\SKPPop Y{Gr Kaf9f{Xv7xyy3uW#fOfY3PFJT9KaJhjBF-FI9GHYuM#F!JT#FM#FG]QSP/Q_Y3IlJVbF]FQSIJT#FffZ:Yb/c YZdKP/W#eOPVF]J YZRc2Y3I#Y3cQgK\SP]vOe{XJK uQSI#[Z:Yb"FKG/T\_FKaZ JT#F!\_Y[3QgG]K\ fi 6YZK\S\7KaJVJVb/Q_e`W#JVFP"Z:bY3c JT#F!bY(YJUJVYJT#F!\_FKaZ FKPW#bQSI#[ YNF]bhJT#FJVbF]F P\_FKNFPQSPnF(WOQ_N8K\SFIJBJVYcFKPW#bF YNF]bJT#F f`KabJQ_JQ_Y3IbFK\SQ_]FM%e{XJT#FfiPVF]JLYZc2Y3I#Y3cQSK\SP]" YjnF]NF]bvdJT#Fkc2Y3I#Y3cQgK\SP!KabF%M9QSP VY3QSI(JZ:bY3c FKGTYJT#F]bkp:FKGTFHuKcfO\_FP/KaJQSPV^9FPffFHuKGHJ\SXY3I#Fc2Y3I#Y3cQSK\ }hW9FiJVYJT9QSPf9bYfmF]bJ)Xv"Y3I9\_X PW#eOPVF]JP%G]KIemFbFK\gQ_]FM j Q_JT c2Y3I#Y3cQSK\gP]vYbF{W9Q_NaK\_FIJ\SXjUQ_JTKJVbF]F!T9KN{QSI9[ n\_FKNFP]uW9f9fmY3PVF"JT9KaJBjBFh[FI#F]b/K\SQS]FUJT9QSPRYeOPVF]bNaKaJQ_Y3Ie(X2b/Fc2YNuQSI#[ffJT#FhMOQSP VY3QSIJI9FPPdGHY3I9M9QSJQ_Y3IYNF]bJT#Fc2Y3I#Y3cQSK\SP] "T#FIKI(W9cffemF]bkYZ-PW9eOPVF]JP%YZffYbM#F]b kpw~ )QSPI#Yj fmY3PP/Q_eO\_FijUQ_JTY3I9\_Xc2Y3I#Y3cQSK\SP]v"KI9MQ_JkKaf9fmFKab/PJT9KaJkJT#FI(WOc!emF]b%YZbFK\SQ_]FMfOKab/JQ_JQ_Y3I9PG]KIeFFHufY3I9FIJQSK\g\_X\SKab[F]bfiW9PQgI#[M#FG]QSP/Q_Y3IGHY3ccQ_JVJVF]FPfiJT9KIM#FG]QSPQ_Y3IJVbF]FP] "UYjBF]NF]bv7JT#FffFHufmFGHJVFMbW9I9I9QSI9[2JQSc2FQSP%I#YJe`Q_[[F]bkjUT#FI WOPQSI#[M9FG]QSPQ_Y3I1GHY3ccQ_JVJVF]FP]vhPQSI9GHFiJT#F5I(W9cffemF]bYZf`KabJQ_JQ_Y3I9PQSP%QSIZ.KGHJemY3W9I9M#FMe{XJT#F I{W9cffemF]bdYZ7FHuKcfO\_FP]v G =?> G"T{W9P]v(jBFhcKXFHufFGHJnPVY3c2F bFM9W9GHJQ_Y3IQSIJT#F PQ_]FYZJT#F ZYbcffW9\gKjnF eOWOQS\SMjUT#FIW9PQSI9[!M#FG]QSPQSY3IGHY3ccQSJVJVF]Fv{j T9QSG/TQSPBYZQSIJVF]b/FPVJBJVYQSI(JVF]bf9bF]JBJT#FG]\SKPP/Q_^9F]bYe9JKQSI9FM7f9fO\SQgG]KaJQ_Y3IYZJT9QSPBf9b/QSI9G]QSfO\_F"QSI QgPBPVJVbKQ_[3TJVZ:YbjLKab/9K\SKab[FoM#FG]QSP/Q_Y3IGHY3ccQ_JVJVF]FQSPeOW9Qg\_JBe{X%[bYjUQgI#[2Q_JVF]b/KaJQ_NF\_Xv`QSIkKJVYf fiM#Yj IlZ.KPT9Q_Y3I7v#K2G]W#b/bFIJc2Y3I9Y3cQSK\w+IkJT9QSPc2Y3I9Y3cQSK\wvJT#F"\SQSJVF]b/K\uKM9M#FM2KaJdJT#F"G]W9bbFI(J PJVF]fQSP JT#FY3I#Fj T9QSG/T2cQSI9QScQS]FPJT#F"G]W9bbFI(J 1GHb/QSJVF]b/Q_Y3I7vYNF]bK\S\mfmY3PPQSeO\_F KMOM9Q_JQ_Y3I%YZ\SQ_JVF]b/K\gP]v{KIOMk[3Q_NFIJT9KaJ"JT9FI#F]j c2Y3I#Y3cQgK\7M#Y(FPUI#YJFHuQgPVJ"K\_bFKM#X%QSIJT#FnG]W#bbFI(J0M#FG]QgPQ_Y3IGHY3ccQ_JVJVF]Ffip.QgIYb/M#F]b JVYUfObF]NFIJ c-W9\_JQ_fO\SFdKM9M9Q_JQ_Y3IOP7YZ9KUPQgI#[3\_FRc2Y3I9Y3cQSK\"T#F GHb/Q_JVF]b/Q_Y3I QSPGHY3c2fOW9JVFM1W9P/QSI#[JT#Flf`KabJQ_JQ_Y3IQgI9M9W9GHFMYNF]b =A> e{XJT#FiG]W9bbFI(JPVF]JYZc2Y3I#Y3cQSK\SPeOW9Qg\_Jlp.Q_Z J)jBYFHuKcfO\_FPPKaJQgPVZXJT#FP/Kc2Fc2Y3I#Y3cQSK\SP]vnJT#F]XeF\SY3I#[JVYJT#FiPKc2FPW#e`PVF]JYZ JT#FkfOKab/JQ_JQ_Y3I` T#FII9YZ:W#b/JT#F]b2KM9M9Q_JQ_Y3IYZhK\SQ_JVF]b/K\LM#FGHbFKPFP2JT#F N8K\SW9FvBKI#F]j c2Y3I#Y3cQgK\0QSPhGHbFKaJVFMKI9M5QSIOQ_JQSK\SQ_]FMKaJ ff{v7KI9MiJT#FI5QSP [bYjUI5W9P/QSI#[JT9F-PKcFfff9bQSI9G]Q_fO\SFT#FII9YZ.W#bJT#F]b!GHb/FKaJQ_Y3IYZ"Kc2Y3I#Y3cQSK\RM#FGHb/FKPVFP-JT#fiF NaK\SW#Fv JT#FkK\_[Yb/Q_JT9c PVJVYfOP-KI9MbF]JW#bI9P JT#F"G]W#bbFI(J]v\SKab/[FLM9FG]QSPQ_Y3I2GHY3ccQ_JVJVF]FjUQ_JTPVJQS\g\(Fcf9JX-NFGHJVYb/P]+IJT#FZ:Y3\S\_Yj QSI#[fiPVJVF]fvG]K\SG]WO\SKaJVFPhJT#FPVF-NFGHJVYb/P]U+IKf9bF]NuQ_Y3W9P Kaf9f9bY3KGTJVYeOWOQS\SM9QSI9[ffb/WO\_F!PVF]JPhZ:Yb f9b/YeO\_FcPjUQ_JT-J)jBYG]\SKP/PVFP"p Y3T#FI r uQgI#[F]bv#xyyy3v{KI2QSJVF]b/KaJQ_NFL[bYj QSI#[ fiDf9b/WOI9QSI#[hK\_[Yb/Q_JT9c QSP M#FP/Q_[3I#FMpD #REfi3"T#Fb/WO\_F fiD[bYj QSI#[oKaf9f9bY3KGTYZ #REQgPGHF]bJKQSI9\_XG]\_Y3PVFJVYffjUT9Ka<J1M#Y{FPZ:Yb[bYj QSI#[lKl} PQgI9GHFQ_JoYf9JQScQ_]FPoK GHb/Q_JVF]b/QSY3I7v7XF]JffKI#YJKae`\_FM9Q *mF]bFI9GHFQSPJT9KaJQ_JM#Y{FPI#YJhGHY3c2fOW#JVF YNF]boKfOKabJQ_JQ_Y3IQSI9M9W9GHFMle(XlK%PVF]JUYZbW9\_FP]EUKaJT9F]bv`JT9FffG/T9Y3QSGHFffYZBQSPffJVY5[bYj KaJFKG/TPJVF]fK %eJ 3 ! lc2Y3I#Y3cQgK\wv f9b/W9I#FQ_J]vdKI9MJT#FI[bYj K5PVFGHY3I9Mc2Y3I9Y3cQSK\wvf9b/WOI#FQ_J]vBKI9MPVY5Y3IW9I(JQS\BK5^`I9K\B} h fiPT9KafmFMZYbcffW9\gKQgP-GHY3cfO\_F]JVFKI9MbF]JW#b/I9FM7 YJQSGHFJT9KaJ #RE K\SPYc2YuM9Q_^9FPJT#FjBFQ_[3T(JYZfiJT#FFHuKc2f`\_FP]vQSIKG]GHYb/M9KIOGHFijUQSJTqnY(Y3PVJQgI#([ PPVJKI9MOKab/M9PpDuGT9KafOQ_bF r uQSI#[F]bv7xyy3:POfin ,j*; 3 ; 7#"($iwc3 ;'"U"(7rE.R3 .r#"%$ffff'" #"($ B6.d.R*. 7#"($3uGT9KafOQ_bF r uQgI#[F]blp+xyy3T9KNFQSI(NFPVJQ_[3KaJVFMG]\gKPPQ_^OG]KaJQSY3If9bYeO\_FcPffj T#F]bFkJT#FlKQSc YZhJT#Ff9bYuGHFM9W#b/F!QSPhI#YJUJVYkf9bYN{QgM#F!KIKG]G]W#b/KaJVF2G]\SKPP ZYboPVY3cF!YeOPVF]b/N8KaJQ_Y3I EUKaJT9F]bv`JT9F-K\_[YbQ_JT9cY3W#JVfOW9JPKlPVF]JYZLNaK\SW#FPp:Y3I9FZYb!FKG/TG]\SKPPhKI9MjBFFHufmFGHJJT#FG]\gKPPYZnJT#FYeOPF]bN8KaJQSY3IJVYbFGHFQ_NF-JT#F\SKab[FPVJ N8K\gW#F!YZdK\S\DvOJT{W9PUemFQSI9[b/K(I FMT9Q_[3T#F]b JT9KIK\S\YJT#F]bP] "TOQSP"Kaf9f9b/Y3KG/T5QSPfOKabJQgG]W9\SKab/\_XWOPVF]Z:WO\Bj T#FIK5[3Q_NFIFHuKcfO\_FlG]KIemF\_Y3I#[5JVYc2YbFJTOKIY3I#FG]\SKPPp.c-W9\_JQS\gKaeF\f9bYe`\_FcPvfiKG]KPVFjUT#F]bFjnFFHufFGHJFKG/T YZffJT#FPFG]\SKPPVFPJVYbFGHFQ_NFJT#F[bFKaJVFPVJNaK\SW#FPGHY3c2fOKab/FMJVYJT#FG]\gKPPVFPJT#F!FHuKc2f`\_FP"M#Y{FP"I#YJ"emF\_Y3I9[-JVY#"T9F- " EJ 3 ! %<% b/F]f9bFPVFI(JPQSI#Z:Yb/cK\S\SX-JT9FfiI{W9cffemF]bnYZ0JQSc2FPLJT#FoT(X(fmYJT#FP/QSPRZ.KQS\SPnJVYb/K(IJT#FLG]\SKPP YZ`KI-FH#Kc2fO\_FLT9Q_[3T9F]b0JT9KIKhG]\SKPP JVYfijUT9QSGTffQSJ M#Y{FP I#YJ eF\SY3I#[# qnF]Z:YbFL[Y3QSI#[hZ:W9bJT#F]bvjnFh^Ob/PVJn[FI#F]b/K\SQ_]FhY3W#bG]\SKPP/Q_^OG]KaJQ_Y3I%PVF]JVJQSI#[#v9KIOMbF]f`\SKGHFfiJT#FhGHY3cc2Y3II#YJKaJQ_Y3I'p &)(*!,+dZ:YbKIFH#Kc2fO\_F e(XJT#Fhc2YbFh[FI#F]b/K\9Y3I9F'p &)( !, + "UF]bF*v !, + m/02 (:x 9 ' QSPRK!NFGHJVYbn[3QSN{QSI9[#vZ:YbBFKGT%G]\gKPP]vJT#F!cFc!emF]b/PTOQ_fJVYJT#FffG]\SKPPffp ffV %QSP"I9YKI9M ff]x QSP"XFPLYZ JT#FffGHYb/bFPVfmY3I9M9QSI9[-Ye`PVF]bNaKaJQ_Y3&{J!QSPQScfYb/JKIJoJVYI9YJVFJT9KaJJTOQSPPVF]JVJQSI9[QSPc2Yb/F[FI#F]b/K\RJT9KIJT#FWOPW9K\dqLKXFP/QSKIPF]JVJQSI#[#vQSIjUT9QSGTJT#F]bFkG]KIFHuQgPVJ!FH#Kc2fO\_FPk'p &)(*!,+]!KI9M'p &N(*! + ; p.W9PQSI9[JT#F%I#Y3!I fiDNFGHJVYbI#YJKaJQ_Y3IoZ:YbjUT9QgG/&1% & eOW#HJ !,+% 0 ! + ; UE K(I uQSI#[\_Y3P/PU[FI#F]bK\SQ_]FPhqnKXFPfiJVYJT9Fffc-W9\_JQS\SKaemF\mf9b/YeO\_FcP]vKI9MfmY3PVJW9\SKaJVFPnJT9KaJJT9F]bFoG]KIkeFfiPVY3c2FfiFH#Kc2fO\_FPnZ:YbjUT9QSGTjnFG]KI9I#YJLf9b/YNuQSM#FfiK-P/QSI#[3\_FhG]\SKPPKaJ"KJQSc2FvuF]NFIQ_ZL2 14351dKI(XYZJT#FoG]\SKPPVFPLJVYjUT9QgG/TJT#FfiFHuKc2f`\_F emF\_Y3I9[3PnKab/FhPWOPGHF]f9JQ_eO\SFUJVYKaf9fmFKabQSI9M9F]fFIOM#FIJ\SX\SKaJVF]bUjUQSJTkJT#FPKc2FYe`PVF]bNaKaJQ_Y3I7E K(I {QgI#[ff\_Y3P/PBqnY{Y3PVJQSI#[-bF]fO\SKGHFPnFKGTkFHuKc2f`\_F-'p &)( !, +e{XKPVF]JnYZRx ' = @ 'p ! 7x ' = @ dFHuKc2f`\_FP]vjUT#F]b/Fx ' = @ M#FI#YJVFP%JT#F " KccQSI#[jnFQ_[3T(JkYZ !+p J 1.2 1 JT9FI{W9cffeF]b%YZ!G]\SKP/PVFP%JVYjUTOQSG/T1JT#FFH#Kc2fO\_FffeF\SY3I#[3P RKGTYZJT#FPF-I#F]j FHuKcfO\_FPUQgPUM#FI#YJVFM'p &)( 8(ff(v7jUT9F]bfiFkKI9lPVfOKIiK\S\NaK\SW#FPQSE02 (3x (5464646(*!@7t:x 9 . %UT#FM9QSPVJVbQ_eOW#JQ_Y3IiYZLJT#FI#F]j FHuKcfO\_FPQSPbFI#Yb/cK\gQ_]FM7vPVYJT9KaJ;-pV'p &)( 8(ff{V? % ( @ ,, , + ' ' = @ ( 11 @ 1 j T#FI#F]NF]b !, +-/ % xKI9M !, +-/8%uvOKI9M2YJT#F]bjUQgPVFY3I9Y3 c QSK\ LYe9JKQSI9FMlZ:bY3c JT#F-\SKab[F-} v`KI9MlK\g\FH#Kc2fO\_FP PKaJQSPVZ:X{QgI#[Q_J] FK F-PY3c2Fffc2I#YjjBYb !jUQ_JTffJT9QSP bFPVJVb/QgGHJVFM-P/W#eOPVF]J YZ9FH#Kc2fO\_FP]vj T9QS\_FRG]K\gG]W9\SKaJQSI#[hJT#FGHYbbFPfY3IOM9QSI#["NFGHJVYbYZ d#G/T9KafOQSbF r uQSI#[F]bfip+xyy3Bf9bYfmY3PVFUK-GHY3PVJnZ:W9IOGHJQ_Y3IjUTOQSG/TjBFfiPT#Y3W9\gMcQSI9QgcQ_]F"QSI2YbM#F]bJVYcQgI9QScQ_]FhJT#FbK(I {QgI#[2\_Y3PP]d"TOQSPnZ:W9IOGHJQ_Y3IQSP%4+ ";-pVp'&)( 8(ff(V"$ , = = 14pw~3" F]bFv QSPKfiJWOI9KaeO\_FfOKabKc2F]JVF]bdjUT9QgG/T7v3QSI(JW9Q_JQSNF\_XvbF]f9bFPFIJPJT9FUGHY3I#^OM#FIOGHF"QSIJT#F"G/T9Y3QSGHFYZ( v`KI9M\_F]NF]bKa[FP Q_JP (WOK\SQ_JXL"T#F!eF]JVJVF]b- QgPUKaJUG]\SKP/PQ_Z:X{QSI9[2FHuKc2f`\_FP]v9JT#Fff\SKab[F]b QgP"G ?G+IY3W#boG]KPVF2T#YjBF]NF]bv0KW#JT#Yb/Q_QgI#[! % 0 xQSPhF{W9Q_NaK\_FIJhJVYKW#JT#Yb/QSQSI#[GHY3cfY3I9FIJPhZ:Yb QSI5PVF]JP0 7 (2 ( 9ffZ:Yb"KabeOQSJVb/KabX 0dY2b/FK\S\_XGHY3IOPVJVb/KQSIkJT#FGHY3cfY3I9FIJPYZ Qg0 73x (2 ( :x 93vOjnF!T9KNFG/T9Y3PVFIlJVYYfOJQScQ_]FoJT#FGHbQ_JVF]b/Q_Y3I%4+ ";-pVp'&)( 8(ff(V"$ , = = 1p 3p:JT#F]b/F]ZYbFoZ:Yb/G]QSI9["% xLuG/T9Kaf`Q_bF r uQSI#[F]bp+xyy3GHY3I+FGHJW#b/FoJT9KaJ^OI9M9QgI#[!JT#FoYfOJQScK\NFGHJVYbcQSIOQScQ_QSI9[ QgIF`pw~3%p:jUT9QSGTQSP-PQScQS\SKaboJVY5KI !\J J $&% TX{fmYJT#FPQSPffKG]GHYb/M9QSI#[iJVYJT#FQ_bhM#F]^OI9QSJQ_Y3I9Pv9Yb [3Q_NFIKf`KabJQSG]W9\SKabUN8K\SW9F!YZ#RvQSP fi " Kab/MijUT#FI!QSP I#YJ ^9{FM7vKI9MjUT#FIJT#FhGHY3c2fmY3I#FIJPnYZ Kab/FhQSIJT#FfiPVF]HJ 0 7!3x ( :x 93R"T#F ZY3\g\_YjUQgI#[!PVFGHJQ_Y3IkKM9M9bFPPVFPnM9Q_bFGHJ\SXJT#F-PVF]JVJQSI#[YZB#G/T9KafOQSbF r #QSI#[F]bffp+xyy3v7KI9Mf9bFPVFI(JPUGHY3c2f`\_FHuQSJX fiDJT#F]YbF]JQSGffbFPW9\SJP"PT#YjUQSI#[$:POfiJT9KaJJT9FcQSI9QScQ_KaJQ_Y3IYZ QSPoKGHJWOK\S\_XfY3\SX{I#Y3cQSK\wvmeOW#JT9QS[3T9\_XGHY3c2f`\SQSG]KaJVFMJVYKGT9Q_F]NFv K\S\JT#F5c2YbFZYb%jUT9KaJkQ_J%QSPP/W#f9fmY3PVFMJVYe9bQSI#[JVYJT#F5cQSI9QScQ_KaJQ_Y3IYZ QSI Y3W9b%PVF]JVJQgI#[#PVJVb/Q {QSI9[bFP/W9\_JojnFK\SPVYl[3Q_NFv I#YJobF\SKaJVFMJVYlJT#FfOW9bfmY3PVFYZBJT#F2f`KafF]bvQSPfiJT9KaJ!QSJQSPoKGHJW9K\S\_XJT#F!cK8uQScQ_KaJQ_Y3IkYZ j T9QSG/TQgP fi " Kab/M"T9FI7vujBFfObFPVFI(JJT#FKaf9f9bYuQgcKaJQ_Y3IK\_[Yb/QSJT9c jBFffT9KNFe`W9QS\_JLKI9MQSc2f`\_Fc2FI(JVFMJVYYf9JQ ficQ_]FBJT#FLGHY3c2fOW#JKaJQ_Y3IffYZ QSI!Y3W#b0PVF]JVJQgI#[p.GHY3cfY3I9FIJP YZ QSI!JT#FBPVF]J 0 73x (2 ( :x 98v{K\_Y3I#[ jUQ_JTQ_JPBf9bYfmF]bJQ_FP T9QS\_F jBFhZ:F]F\`JTOKaJBJT#FfiQSM#FKPnW9PVFMJVY2cQSI9QgcQ_]F QSIJT#FfiPVF]JVJQSI#[-YZ0uGT9KafOQ_bF ruQSI9[F]b p+xyy3nG]KIemFUKMOKaf9JVFMJVYffY3W#bLPVF]JVJQSI#[JVY-f9bYN{QgM#FUKIK\S[Yb/Q_JT9c JT9KaJnQgPdK\_jLKXuPBYfOJQScK\wvY3W#bK\_[YbQ_JT9c T9KPoJT9FKM#N8KI(JKa[FJVYemFPQgc2fO\_FvmZ.KPVJ]vKI9MK\gPVYkYf9JQScK\ Z:Yb!I{W9c2F]bY3W9PoG]KPFP]+IlcKI(XYJT#F]bhG]KPVFP]v9jnF!PT9Yj JT9KaJ Q_J"QSP"PVJQg\S\mKPVX{cf9JVYJQSG]K\S\_X%Yf9JQScK\7KP !oQSI9GHbFKPFP]fifffffiffff !"#$&% fi '& rfi')(*,+-+-.0/+IkJT#FoG]KPVFjUT#F]b/F FKGTGHY3c2fmY3I#FI(JYZ QSPnbFPVJVb/QSGHJVFMkJVY2JT9FPVF]J 0 7x3( :x 93v#G/T9KafOQSbF r #QSI#[F]bp+xyy3[3Q_NFLK"jLKXJVYfiG/T#Y{Y3PVF kJVY cQSI9QScQS]F ZYb KIX!fY3P/PQ_eO\_FGT#Y3QSGHFnYZ .p W9PQSI#[UY3W#b0I#YJKaJQSY3I`<%~x\SY[2100 43 (p +(jUQSJT90%0%4+4+"";-pVp'&)( 8(ff{V - -- /7-/;-pVp'&)( 8(ff{V - -- /7- /%t~ / /"(p 3% 7U~ / / 4pw|3EUF]fO\SKG]QSI#[2JTOQSPLN8K\gW#FoYZQSIkF` pw~3v`[3Q_NFP"JT#FoZ:Y3\S\_YjUQSI#[2I#F]jFH{f9b/FPPQ_Y3IkZ:Yb% 00~,5 0 0 (pDjUQSJT 0 0 %76 + " ;-pVp'&)( 8(ff(V - - -/87 -/ %t/ /n#G/T9KafOQSbF r uQSI#[F]bp+xyy3"b/KQSPVFfiJT#F!f9bYefi\_Fc ZmcQSI9QScQ_QSI#[ K PM#F]^OI#FMQSI-F{W9KaJQ_Y3I9P"pw~3 KIOMlpD F I#YjPT9YjJT9KaJdQ_J QSP fmY3\_XuI#Y3cQSK\w#" E"F> 98 J 6J8TgJMLrJ 3 "% V( j V2 J H J ;: $ " J (%/ =<fi4] ?> fi5 ;@+fi J %! fTgJ"!6XfT% [N " Vff % . J jV % < 0 7!x3( x:9 1k36)jl {F]FoJT#F f9fmFI9M9Q_/b KaJT9F]b-PVJVbQ#{QgI#[bFPW9\SJ[3Q_NFIJT#FGHY3IVFGHJW#bF%YZ uGT9KafOQ_bF r uQgI#[F]bp+xyy3-QSP!JT9KaJffQ_J-QSPJT#FcK8#QScQ_KaJQSY3IYZ !vRKI9MI#YJ2Q_JPcQSI9QgcQ_KaJQ_Y3I7v jUTOQSG/TQSP1 fi " Kab/M TOQS\_F%JT9QSPQSPI#YJJT#Ff`W#bfmY3PVFYZLJT#Ff9bFPFIJofOKafmF]bp:jnFKab/FQSI(JVF]bFPVJVFMQSIcQSI9QScQ_QSI#[ hv0jBFT9KNF%G/T#Y3PVFIJVY[3Q_NFoT#F]bFoK-e9b/QSF]Zf9bY{YZP F]JGTYZJT#FfibFP/W9\_J]v{jUT9QSGT%WOPVFPLG]\SKPPQSG]K\bFMOW9GHJQ_Y3I9PnZ:bY3c jBF\S \ fi {I#YjUIfi " KabMf9bYeO\SFcP]#" E"F> A8 " 'J TgJ L J 3 "% V WV J H J ;: $ " J (% =<fi5] ?> fi B @ fisJ % :_` " V XfT% [N " Vff % . J jV % <0 7!x3( x:9 1k36) ?. 6" 7rffAl uF]F JT#F f9fmFI9M9Q:PODCfififf!iwcffff' fiffffP f9bF]NuQ_Y3W9P\_XKab/[3W#FM2QSI"T#F]YbFc +#v{cQSI9QgcQ_QSI#[ QSI-JT#FPVF]JVJQSI9[oYZmuGT9KafOQ_bF r uQgI#[F]bLp+xyy3G]KIieF-M#Y3I#FffYf9JQScK\S\SXv9eOW#JUKaJhJT#FffFH{fmFI9PVFffYZdGHY3c2fO\_FHlYfOJQScQ_KaJQ_Y3If9bYuGHFM9W#bFPv9jUQ_JTi\SKab[FGHY3c2fO\SFHuQ_JQSFP]BfiI#FoG]KIljnY3I9M#F]bUjUT#F]JT#F]b"PWOG/Tf9b/Y{GHFM9W9bFP]v#JVYYf9JQgcQ_]FfiY3I9\_X%JT#FGHY3c2fOW9JKaJQ_Y3IYZ p.KP/cK\S\mfOKabJYZfivOKabFb/FK\S\_XjnF\S\7jnYbJTJT9FKM9Kaf9JKaJQ_Y3IJVYY3W#bUPVF]JVJQgI#[#v9QSIkjUT9QgG/Tc2YbF!N8K\SW9FPUKabF!KW9JT#Yb/Q_]FM7#F-Kab/F!I#Yj [Y3QSI#[JVY%PT#YjJT9KaJhKcffWOG/TP/QSc2fO\_F]b"GHY3cffeOQSIOKaJVYb/QSK\f9bYuGHFM9W#b/Fv jUQSJTtGHY3c2fOKab/KaJQ_NF\SXNF]b/X\SYj GHY3c2f`\_FHuQSJXvG]KIte9bQSI#[Yf9JQScK\fib/FPW9\_JPlQgIZ:KQ_b\_X[FI#F]b/K\PQ_JWOKaJQ_Y3I9P]"T#Fhc2Y3PVJnPQSc2fO\SFjnKXJVYM#FPGHb/Q_emF"c2Y3PJBYZ7JT#FPFhPQSJW9KaJQ_Y3I9PBQSPdJVYcK FfiJT#FZ:Y3\S\_Yj QSI#[2KPPW9cf9JQ_Y3IkY3IJT#FoFH#Kc2fO\SFPp2BKG/TFHuKc2f`\_FW9PVFMJVYGHY3c2fOW#JVF T9KPY3I9\SXY3I#Fff]x QSIQ_JP"G]\gKPPNFGHJVYb]G Kab/F]Z:W9\ bFKMOQSI#[YZBKPPW9c2fOJQ_Y3IpUbF]NFK\SPhJT9KaJoQ_J Qgc2fO\SQ_FP"JT9KaJfiFKG/T5FH#Kc2fO\_F-emF\_Y3I#[3PJVYFHuKGHJ\SXY3I#FoG]\SKPPv $ RQ_JLM#Y{FPnI9YJnfObF]NFIJKI%YeOPVF]b/N8KaJQ_Y3I%JVYemF F\SFc2FIJLYZ c2YbFhJT9KIkY3I#FG]\SKPPvuKPU\_Y3I#[2KPM9Q *mF]bFI(JnFH#Kc2fO\SFPnP/T9Kab/QSI#[-JT#FPKcFhYe`PVF]bNaKaJQ_Y3IT9KNFffM9Q *mF]bFIJLG]\SKPPFPp:JT#Fff]x YZmJT#F G]\SKPPdNFGHJVYbPBQSPRQSI2M9Q *mF]bFI(JdfmY3PQ_JQ_Y3I9PKcY3I#[JT#FPVFUFHuKc2f`\_FP"T#F]bF]Z:YbFv(F]NFIQ_ZQ_JM#Y{FPRI#YJBQSIJVF][bKaJVFUJT#FUcY3PVJR[FI#F]bK\9Z:FKaJW#bFPdYZmJT#F b/K(I uQSI#[o\_Y3PPBPVF]JVJQSI#[#v(Y3W#bBKP/PW9c2f9JQSY3I2PVJQS\S\KW#JT#YbQ_]FPdJVY-GHY3I9PQSM#F]bRf9bYeO\_FcP jUQ_JTI#Y3I]F]bYffqLKXFPBYfOJQScffWOc UT9QSPdQSPdbFK\S\_XQSI(JVF]bFPVJQSI#[#v{KPcKI(X!GHY3cc2Y3IO\_XW9PVFM-M9KaJKPVF]JPZ.K\S\(QSIJVYhJT#FLG]KaJVF][YbX-YZ9Y3W#b KPPW9c2fOJQ_Y3I7vaKP ZYb FHuKcfO\_FLcKIXM9KaJKPVF]JP YZ JT#F LbF]fmY3PQ_JVYbXYZ KGT9QSI#F FKab/I9QgI#[2M9KaJKaeOKPVFkp.qn\gK F!F]J K\D_vxyy3 QgI9K\S\_XvF]NFIQSZJT#FKPP/W9c2f9JQ_Y3IM9Y(FPI#YJ T#Y3\SM7vujnFPT#YjJT9KaJUQSIcKI(X%YZ0JT#F!bFcKQSI9QgI#[kp.QgIJVF]bFPJQSI#[(G]KPVFP]vuY3W#bLKaf9f9b/Y#QScKaJQ_Y3IK\_[Yb/Q_JT9c QSPnKPVX{cf9JVYJQSG]K\S\_XYf9JQgcK\wv{JT9KaJBQSPv(^OIOM9PdPVY3\SW9JQ_Y3I9PRG]\SY3PVF]bJVYJT#FffcQSI9QScK\ONaK\SW#FoYZ KHP !oQSI9GHb/FKPVFP]uW9f9fmY3PVFkZYbI#Yj JT9KaJp T#Y3\gM9P] fiW#b2Ye VFGHJQ_NFQgPJVYG]K\SG]W9\SKaJVFJT#FNFGHJVYb YZoPVY3c2Fc2Y3I#Y3cQSK\ FW9PF%JT9FlPT#YbJT9KIOM9P 0 0 ( 0 ( (5464646( 0 ( JVYM#FI9YJVFJT#FlPW9c YZhjBFQS[3TJP2YZJT#FFH#Kc2fO\SFP!PKaJQSPZXuQSI#[ oKI9MeF\SY3I#[3QSI#[kbFPVfmFGHJQ_NF\SX' JV YG]\SKPPVFPff2 (3x (5464646(*!@7txa FjLKIJffJVYcQSIOQScQ_]F KPf9bYfmY3PVFMQSIlFO p 3LuW#f9fmY3PVFfijUQ_JT9Y3W#J\_Y3PPYZ [FI#F]b/K\gQ_JX%JT9KaJ0 (0 0464640 ' ( (YJT#F]bj QSPVFvmbF]Yb/M#F]bfiJT#FG]\SKPPFPhPY%JTOKaJhJT9F]XlNF]b/Q_Z:XlJT9QSPhKPPVF]b/JQ_Y3I7 Q_NFIY3I9\_XJT#bF]F-fY3P/PQ_eO\_FNaK\SW#FPoZ:Yb!FKGTGHY3c2fmY3I#FI(JYZ v0JT#FJVFPVJQgI#[lYZK\S\ ' fmY3PP/Q_eOQS\SQSJQ_FP"Z:Yb QSPoFHufmY3I#FIJQgK\dKI9MJQSc2F fiGHY3IOPW9cQSI9[# qLW#JUjBF!G]KIlf9bYfmY3PVFK2NF]bXkZ.KPVJ"Kaf9f9b/Y3KG/T7 F-T9KNF-QSI9M#F]FMB "F> >xk36)jl {]F FoJT#F!:(- /- / 1f9fmFI9M9Q_"T{W9P]v(JT#F"Yf9JQgcK\ M#Y{FPRI#YJBemF\_Y3I#[oJVYffKffPVF]JRYZG]KabM9QSI9K\SQSJX ' v(eOW9JdJVYffKffPVF]JRYZG]Kab/MOQSI9K\SQ_J)Xkp'! . oW#bK\_[Yb/Q_JTOc QSPoJT#FIPVJVb/KQ_[3T(JVZ:YbjnKabM9ffPQgc2fO\_XlFHufO\_Yb/FJT9QSPoPVF]JffYZ kp'! . fiF\_Fc2FI(JP]vKI9F]F]fJT#F-NFGHJVYbT9KNuQSI#[%JT#F\_YjnFPVJfiN8K\gW#F!YZ ! UYJVFJT9KaJhJT9QSPhGHY3cffeOQSI9KaJVYb/QgK\0K\_[YbQ_JT9cT9KPnJT#FoKM#NaKIJKa[F!JVY-emFfiKM9Kaf9JKaeO\SFhJVY2c2Yb/Fh[FI9F]b/K\7PVF]JVJQSI#[3PLQSI%jUTOQSG/T 8f`KabJQSG]W9\SKabnNaK\SW#FPLKabFKW#JT#YbQ_]FMkZYbJT9FfiGHY3cfY3I9FIJPY+Z vuZ:Yb"KIX%^#uF80I9YJLI9FGHFPPKab/QS\SXF{W9K\JVY {dIkJTOKaJ"G]KPVFvJT#F!GHY3cfO\_FH#Q_JXkQSP\SKab[F]bv#eOW#J"\SQScQ_JVFM%JVY k'p ! 1 ("T9F]bFKabFP\SQ_[3T(J\_XcYbF[FI#F]bK\UPVF]JVJQSI9[3PQSIjUT9QSGTY3W#bK\_[YbQ_JT9c b/FcKQSI9P2YfOJQScK\wvLQSI0 fi p % 0( 0 "0 V pVp 0 "fOKabJQgG]W9\SKabUj T#FIljnFffG]KI5GHF]bJQ_Z:X( v pVp 0 "ff0 fi p % 0J( 0 "0 V " F]bF(v 0 M9FI#YJVFPfiJT#F2PW9c YZRjnFQ_[3T(JP YZBJT#F-FHuKc2f`\_FPemF\_Y3I#[3QSI9[ KaJd\_FKPVJJVYoG]\SKP/P vKI9M 0 M9FI#YJVFP JT#F"PW9c YZ`jBFQ_[3T(JP YZJT#FLFHuKc2f`\_FP emF\_Y3I#[3QSI#[:POfiKaJff\SFKPVJJVYiG]\gKPP 0v KI9M fiemF\_Y3I#[3QgI#[lKaJff\_FKPJJVYiG]\SKP/P %"TOQSPPT#YjUPJTOKaJ!F]NFIZYb-PVY3c2FfOKabJQgG]W9\SKabc-W9\_JQg\SKaemF\G]KPVFP]vUY3W9b%Kaf9fObY#QScKaJQ_Y3I1K\_[Yb/Q_JTOc G]KI1bFcKQSI1Yf9JQScK\w fiI#FG]KIjnY3I9M#F]b2Q_ZJT#FkYf9JQScK\SQ_JXQgPfffObFPVF]bNFMQSIJT#FkW9I#bFPVJVbQSGHJVFMc-W9\_JQg\SKaemF\dZ:b/Kc2F]jnYb` FlI#YjPT#YjtJT9KaJ]v#Q_ZYf9JQgcK\SQ_J)XQSPnI#YJLf9bFPVF]bNFMv{jnFoG]KIPVJQS\S\`f9bYNFfiJT#Fo(W9K\gQ_JXYZY3W#b"K\_[Yb/Q_JTOc Z:Yb[FI#F]b/K\cffW9\SJQS\SKaemF\mG]KPVFP]vOPT9YjUQSI9[KPVX{cf9JVYJQSGfiYf9JQScK\SQ_JXkKP !oQSIOGHbFKPVFP]fiW9b KafOf9bY#QScKaJQSY3I-K\S[Yb/Q_JT9c QSP b/W9IQSI-JT#Fc-W9\_JQS\gKaeF\(G]KPVFe{X!JVb/KI9PZYb/cQSI#[hJT#FLFHuKc2f`\_FPKP"Z:Y3\S\_YjUP dFKGTFH#Kc2fO\SF'p &)( !+ZYb"j T9QSG/Tx ' = @xffQSPJVb/KI9PZYb/cFMlQSI(JVYx ' = @ FHuKcfO\_FP]vOTOKNuQSI#[JT#FPKcFM#FPGHb/Q_fOJQ_Y3&{vKIOM5Y3I9\_XY3I9F ff]x lQSIJT#FQ_boNFGHJVYbv QSIPW9GTKkjnKX5JT9KaJojBFPfOKI5JT#Fx ' = @x ff]x !YZ`JT9F"Yb/Q_[3QSIOK\uFHuKc2f`\_F UT#FQ_bjnFQ_[3TJBQSPJT#FY3I#FUYZJT9F"Yb/Q_[3QSIOK\(FH#Kc2fO\SFv(M9Q_NuQSM#FMe{Xx ' = @ F!JT#FIb/W9IkY3W9bUK\_[Yb/Q_JTOc Y3IJT9QSPI9F]jPVF]J"YZ FHuKcfO\_FP"PKaJQgPVZXuQSI#[2KPP/W9c2f9JQ_Y3IpYjvmPW#fOfY3PFJT9KaJhZYbhKIXlFH#Kc2fO\SF'p &)( ! + vjnFffT9KNF%x @ Z:YbhPVY3cF U"T9F]bF!KabF-JjnY'=QSI(JVF]bFPVJQSI9[NFGHJVYb/P-jBFWOPVF"T9F2^9b/PVJoY3I#F%QSP v JT#FYfOJQScK\NFGHJVYbp:YbffKIYf9JQScK\NFGHJVYbHcQSIOQScQ_QSI9[ YNF]b%JT#FYb/Q_[3QSIOK\PVF]JYZhFHuKc2f`\_FP]vnJT#FlPVFGHY3I9MY3I9FQSP vRJT#FlNFGHJVYb%jnF^OI9McQSIOQScQ_QSI9[ YNF]bJT#FJVb/KI9PVZ:Yb/c2FM1PVF]J%YZFHuKcfO\_FP] T9KaJ%jnFijLKIJQSPJVYFPJQScKaJVF5JT#F{W9K\SQ_J)XY+Z jUQ_JT%bFPfFGHJJVY2JT9FoYf9JQScK\mNaK\SW#FfiYZ YNF]bUJT#FfiYb/Q_[3QgI9K\mPVF]J"YZFH#Kc2fO\SFP]v -pW9PQgI#[ffY3W9bLI9YJKaJQ_Y3I7R"T9F Z:Y3\S\_YjUQSI#[ffJT#F]YbFc [3Q_NFPKIKIOPVjBF]bJVY2JTOQSPnf9bYeO\_Fclv(e{X{W9KI(JQ_ZXuQSI#[Q_JP"GHY3I(NF]b[FI9GHF-JVYjLKab/M9P -p#" E"F> pk36)jl {F]FoJT#F-p 8x ' fffi1f9fmFI9M9Q_"T9F]bF]ZYb/Fv"QSIJT#FPVF]JYZK\S\Uf9bYeO\SFcP2Z:YbjUTOQSG/TZ:YbkPVY3c2F xav !vjnFYeOJKQSI-p < % p+x &#p+xV ffAp v{KI9MY3W#bdemY3W9I9M2GHY3I(NF]b[FPBJVYJT#FYf9JQgcffW9c KP<!QSI9GHbFKPFPdQSIJT9QSPG]\gKPPYZf9bYe`\_FcP]"qnXc2FKIOPUYZjnYb/M9P]vY3W#bfiPQSc2f`\_FKaf9f9bYuQgcKaJQ_Y3IK\S[Yb/Q_JT9c QSP {W9Q_JVF!FG]Q_FI(J Z:Ybf9bYe`\_FcPjUQSJTl\SKab[F-I(W9cffemF]bUYZdG]\SKP/PVFP] YJVFffJT9KaJhW9PQSI9[KP\SQS[3TJ\_Xc2Yb/F!QSI(NY3\_NFMfObY(YZv9jnFGHY3W9\SMT9KNF bFM9W9GHFMJT#FUGHY3I9PVJKI(J ff*$> !Z.KGHJVYbLQSI2"T#F]YbFc |oJVYJT9F P\SQS[3TJ\_X-PcK\S\SF]b ff*$ 7p+x 3$8 uYjv JVYl^#5JT#FQSM9FKP]vJT#FZY3\S\SYjUQSI9[kP/W#eOPVFGHJQ_Y3IMOQSPVfO\SKX{PfiJT9FFH{f`\SQSG]Q_Jp.KI9MP/QSc2fO\_F PVY3\gW#JQ_Y3IjUT#FIkJT9F]bF!KabFY3IO\_XJ)jBY%G]\SKPPVFP], $ ff ff !ff% %0 0 % 0KI9M 0 ( % 0 bF]f9bFPFIJQSI9[JT#F-ZbKGHJQ_Y3IYZ#YbfiJT#FPK F-YZRPQSc2f`\SQSG]Q_J)Xv9bFI9Kc2FFH#Kc2fO\_FPZ:bY3c JT#FffI#F][3KaJQ_NF!KI9MkfmY3PQSJQ_NFoG]\SKPPbFPfFGHJQSNF\_XvOPKaJQSPZXuQSI#[ B"T#Ffib/W9\_FfiJVYGT#Y{Y3PVFQSPLJT#FZ:Y3\S\_YjUQSI#[(B "F> > %n ! ! fXhJ 3 "! 3 J % ff $&! % "!pNX %#%$ ($ '% p 7x3( x#& # $5 $ # & $ '% p 7!x3( % p.2( x*#$) ( ##*&$ 5 $ % p 7!x3( 7 x % p.2( % p x3( x((% p.2( 7!x % p x3(' #% $ #+ & ( )% p x3( 7x#& 'k36)jl {F]FoJT#F f9fmFI9M9Q_:PO =fiiwcffff+-,kf3 "##"($"T#FK\S[Yb/Q_JT9c QSPKP/QSI#[3\_F fiDfOKP/PK\_[Yb/Q_JT9c FKGT b/WO\_FQSPkJVFPVJVFM Y3IO\_X Y3I9GHFvoZ:bY3c JT#F^9b/PVJb/W9\SFffJVYlJT9F\gKPVJoY3I#F#Yb!FKGTfmY3PPQ_e`\_F!b/WO\_Fv7KGHb/Q_JVF]b/Q_Y3Iff fipbF]JW#bI9P ffV"EA YbffV !8 -M#F]fmFI9M9QgI#[oY3Ij T#F]JT#F]bRJT9F b/WO\_FUPT#Y3WO\SM2emFUbFcYNFM%YbnI9YJ]d"T#F]bFhKabF J)jBYNF]b/P/Q_Y3I9PYZJT9QSP GHb/Q_JVF]b/QSY3I7""T#Fff^9b/PVJ"Y3I9Fv`jUTOQSG/TjBFG]K\Sfi\ ff+fmFPP/QScQSPVJQgG uvOQSP"e`KPVFMY3IGHY3I(NFIJQ_Y3IOK\0F]b/bYbcQSIOQScQ_KaJQ_Y3I1"T#FiPVFGHY3I9MY3I9Fv"G]K\S\_FM ff+YfOJQScQSPVJQgG uvLQgPM#F]b/QSNFMZb/Y3c KfObF]N{QSY3W9P2jnYb Y3If9b/WOI9QSI#[M#FG]QSPQSY3!I fiDJVbF]FP!p FKabI9P r KI9PVY3W#bvxyy3ff $ '&FPPQScQSPVJQSGhf9b/WOI9QSI#[-eOW9QS\gM9PBKPVF(W9FI9GHFYZ} Zb/Y3cJ T#F!QSIOQ_JQSK\Y3I#F J FKG/TPVJVF]fv#jnFbFc2YNFY3I#F-b/W9\_FvmPW9GTJT9KaJoQ_JPUb/Fc2YNaK\ e9b/QSI#[3P JT#F\_YjnFPVJfiF]bbYboKc2Y3I9[%K\S\0fmY3PPQ_e`\_FbFc2YN8K\gP YZRb/W9\_FQSIJT9FG]W#bb/FIJ!} RKGTJQScFJT#FF]b/bYb!YZLJT#F%G]W#bbFI(J!} QSPffI#YJ![b/FKaJVF]bffJT9KIJT#F\SYjnFPVJF]bbYbRZY3W9IOMK\_bFKM#XvfffipobF]JW#b/I9PdJVb/W#F"Z:YbRK\S\#bW9\_FPdK\_b/FKM#XffJVFPJVFMZ:YbdbFc2YN8K\Dd"T9QSPf9b/WOI9QSI#[b/F]JW#b/I9P JT#F2PcK\S\SFPVJ } T9KN{QSI9[JT#F2\_YjBFPJhF]b/bYbfiYZRJT#F2PVF{W#FI9GHF"TOQSPUfOb/W9I9QSI9[QSPb/KaJT#F]bhI9KaJW#b/K\Bp.KI9MPQgc2fO\_Fv9KI9Mc2YJQ_NaKaJVFMe{XkJT#FZ.KGHJUJT9KaJ JT#F!QSI9MOW9GHJQ_Y3IkYZ JT#Fff\gKab[F!}emF]ZYb/FBf9bW9I9QSI#[ M#Y(FP I#YJ \_FKM-JVYKhGHY3INFI(JQ_Y3I9K\#F]b/bYbcQSI9QScQ_KaJQ_Y3I70uWOG/TKhf9bYfmF]bJXffQSPbKaJT#F]bPVF\SM9Y3c QSI ff+JVYffiM#YjUIkKI9Mf9bW9I#2F !QgI9M9W9GHJQ_Y3IK\_[Yb/Q_JT9cP] 9YbFHuKc2f`\_Fv{GHY3cc2Y3IM9FG]QSPQ_Y3IJVbF]FQSI9MOW9GHJQ_Y3IK\S[Yb/Q_JT9cPBQSIJT9QSPnPG/T#FcFfiQgI9GHYbfmYb/KaJVFUNF]b/XPVYfOT9QgPVJQSG]KaJVFMf9b/W9I9QgI#[!GHb/Q_JVF]bQSKp Ep.qnbFQScKIlF]JUK\w_vxy +(v +# lfip fffiW9QgI9\SKI7v7xyy +(Vfiff ff $ '&FKab/IOP r KI9PVY3W#blp+xyy3fff9bFPFIJKiI9YNF\K\_[Yb/QSJT9c JVYf9b/WOI#FM#FG]QgPQ_Y3IJVb/F]FP]vdeOKPVFMY3IKVJ FPVJYNF]bk\_Y{G]K\g\_XYeOPF]bNFMF]bb/Yb/P]JPf9bQSI9G]Q_fO\SFQSPP/QSc2fO\_FFKGT QSI(JVF]b/I9K\UI#Y{M9FYZfiK}h QSPJVFPVJVFMiY3I9\_XkY3I9GHF-QSIlKemYJVJVY3c fiW9fZ.KPT9Q_Y3I7v`KI9MljnF!FPVJQgcKaJVF!JT#Fff\_Y{G]K\F]bbYb YNF]bfiJT#Fff\SFKab/I9QSI#[FH#Kc2fO\_FPob/FKG/T9QSI9[lJT9QSPI9Y{M#Fv0emF]ZYbFKIOMKaZ:JVF]b!JT#Fb/Fc2YNaK\dYZLJT#FI9Y{M#F)ZnJT#F\SY{G]K\F]b/bYbKaZ:JVF]bRbFc2YN8K\`QSPI#YJd[b/FKaJVF]bRJT9KI2JT9FU\_YuG]K\#F]bbYbdemF]Z:YbFv3fO\gW9P KofmFI9K\_JX-JVF]b/cv(JT#FI2jnFbFc2YNFJT#F-I#Y{M9FKI9MQ_JP PW#e9JVb/F]Fn"T9FfmFI9K\_JXkJVF]b/c cK FP JT#F!f9bW9I9QSI#[FPPFIJQSK\g\_XYfOJQScQSPVJQgGav#JT9KaJQSP]v7jnF2JVFI9M5JVYYNF]bf9b/W9I9F2JT#F2M#FG]QSPQ_Y3IJVbF]F " YjnF]NF]bv JT9K(I uPfiJVYl\_Y{G]K\WOI9Q_Z:Yb/cGHY3INF]b[FIOGHFbFPWO\_JP]vmKI9M5M9W#F-JVYJT#FffZ.KGHJoJT9KaJoGHF]bJKQSIP/W#e fiG]\SKPPFPUYZnM#FG]QSPQ_Y3IiJVbF]FPKab/F-b/FKPVY3I9KaeO\_Xi\SKab[FvFKab/IOP r KI9PVY3W9bp+xyy3KabFKaeO\_F%JVYf9bYNFJT9KaJjUQ_JTT9Q_[3Tf9bYeOKae`QS\SQ_J)Xv JT9F%YNF]bf9b/WOI9QSI#[jUQS\g\0I#YJoemFJVY{YlPVF]NF]bF2jUQ_JT5b/FPVfmFGHJhJVYJT9F2Yf9JQScK\PW9e9JVbF]FYZRJT#FQgI9Q_JQSK\ }fio F2bF]Z:F]bJT#FbFKM#F]bhJVYJT9FQ_bUfOKafmF]b"Z:YbhZ:W#b/JT#F]b"JT#F]YbF]JQgG]K\bFP/W9\_JP]vOI9YJ I#F]FM#FMT#F]bF"T9FfmY3QSIJ QSP"JT9KaJ e(XW9PQgI#[JT#F%bFPWO\_JP!YZ FKab/I9P r KIOPVY3W#blp+xyy3vRjnFG]KIYe9JKQSIKP/QScQS\SKab!JVFPVJZYb2} FFc2fOTOKPQ_]F-JT9KaJfiY3W#b emY3W9IOMicQS[3TJfiI#YJhFI +YXJT#F2PKcFffJT#F]Yb/F]JQSG]K\ f9bYfmF]bJQ_FPhKPhZYboM#FG]QgPQ_Y3IJVbF]FP]vBemFG]KW9PVFkYZUJT#FG]Kab/MOQSI9K\SQ_J)XbFKPVY3I9PeOb/Q_F '9XY3W9J\SQSI#FMemF]ZYbF "UYjBF]NF]bvLPW9GTKJVFPVJQSPQSI(JVF]bFPVJQSI9[!PQSI9GHF Q_JBcKX\_FKMFPfFG]QgK\S\_X-JVYffNF]bXP/cK\S\9KI9M%QSI(JVF]bf9bF]JKae`\_F"M#FG]QSPQSY3IGHY3ccQSJVJVF]FP]vjUQ_JTJT#FYe{N{Q_Y3WOP!T#YfmF2JT9KaJffJT#FQ_b!KG]G]W#bKGHXjUQS\S\ I#YJ-M#FGHbFKPVFJVY(YcffWOG/T7k9W#bJT9F]b/c2YbFv JT#FfOKafmF]bYZ FKabI9P r KI9PVY3W9b%p+xyy3ffM#Y{FP!I#YJ!GHY3I(JKQSIFH{fmF]b/Qgc2FIJK\dbFPW9\_JP F%JT9QS(I iY3W#bGHb/Q_JVF]bQ_Y3IKP"K2jLKXkJVYJVFPVJ T#FW#b/QSPJQSG]K\S\_X2JT#FoFHufmF]b/QSc2FI(JK\mZ:FKPQ_eOQS\gQ_JXYZPVY3cFoYZ0JT#F!bFPW9\_JPLYZFKab/IOP r KI9PY3W#bhp+xyy3n"T#FUfOb/QSI9G]Q_f`\_FBYZ7Y3W9bBGHb/Q_JVF]bQ_Y3IQSPRFHuKGHJ\SX2JT#F PKcFhKPBJT#FUYbQ_[3QSI9K\JVFPVJ2YZ FKab/I9P r KIOPVY3W#blp+xyy3 ffVG]KIjBFGHY3c2fOKab/FvRjUT#FIJVFPVJQSI9[5PY3c2Fkb/W9\_Fp ( ffKI9MW9PQgI#[lJT#FFHuKc2f`\_FP!JTOKaJ-PKaJQgPVZXJT9Fb/W9\SFv0JT#FF]bbYb/PffemF]ZYb/FKI9MKaZJVF]b-bFc2YN{QgI#[JT#F%b/W9\SF2 5F]J , = 1 bF]f9b/FPVFIJnJT#FhF]bbYbnemF]ZYbF bFc2YN{QSI9[ffJT#F b/W9\_Fv(Y3I%JT#Fh\SY{G]K\PKc2fO\SHF =?> , = 1 PKaJQSPZXuQSI#[c2Y3I#Y3cQSK#\ }hFI#YJVF nKP JT#FLF]bbYb emF]ZYb/FBbFcYNuQSI#[p ( vPVJQg\S\c2FKP/W#bFM-Y3IJT#F\_YuG]K\{P/Kc2fO\_F:PO $fi=?> , = 1 ff"T#FIjnF2M#F]^OI#F-JT#F2T#FW#b/QgPVJQSG ff+fmFI9K\SJX p:f9bY{YZdY3cQ_JVJVFM9fiQ_JfiQSPfiKkbY3W#[3T5W#f9fmF]bemY3W9IOMYZ FKab/I9P r KI9PY3W#bffp+xyy3v FccKx, = 1pD{F]JpVp( V ~3{\_Y[7p -0 \_Y[hx4%pw3G =A> , = 1 G{F]JpVp( VM#FI9YJVFP JT9FffcK8#QSc-W9c I{W9cffeF]b YZd\SQ_JVF]b/K\gPYZdK\S\bW9\_FP"FH#GHF]f9J2p ( QgIlJT#F-G]W#b fibFI(Jn} v(JT9KaJLKIKabe`Q_JVb/KabX2FH#Kc2fO\_FhGHY3W9\SMPKaJQSPVZ:Xd"T#F Z:KPVJnG]K\SG]W9\SKae`QS\SQ_J)XffYZ , 1 QSPRYeOJKQSI#FMKaJhJT#F!FHufmFI9PVF!YZBK[bFKaJVF]bob/QgP kYZYNF]bf9bW9I9QSI#[#v`jUT#Y3PVFffF *FGHJPhY3I5PVY3c2F-PcK\S\0 M9 = KaJKPVF]JPhjnF]bFFHufF]bQSc2FI(JK\S\_XM#b/KcKaJQgGZ:YbJT#F%KG]G]W9b/KGHX+IY3W#b-FHufF]bQSc2FI(JP]vjUT9QSGTGHY3I(JKQSINF]bXP/cK\S\M9KaJKPVF]JPvOjnF!T9KNFffG/T#Y3PVFIJVYJW9I9FKfOKab/Kc2F]JVF]bh\SQScQ_JQgI#[ffJT9FoF *FGHJP YZ JT9QSPGHY3cffeOQSI9KaJVYb/QgK\W#f fifmF]bemY3W9I9M7 Yb/F2f9bFG]QSPVF\SX v FT9KNFG/T#Y3PFI5JVYkWOI9Q_Z:Yb/c\_XkbFPKcfO\_"F =A>QSI(JVY%Kk\SKab[F]bP/W#eOPVF]JYZ aFH#Kc2fO\SFP]vLjUT#FIJT#FiQSI9Q_JQSK\ =A> GHY3I(JKQSI#FM1\_FPPJTOKI aFH#Kc2fO\SFP]qnXJT9QSPvBjnFKabJQ_^`G]QSK\S\_X%QSI9GHbFKPV#F G =A> , = 1 GuKIOMcQScQSGhZYb JT#F!PcK\g\M#Y3cKQSIOPI#F]j M#Y3cKQSI9PLjUQ_JTKIQSM#FI(JQ fiG]K\d\SKab/[F]bPQ_]FvjUQSJTiJT9FKM9M9Q_JQ_Y3IOK\emFI#F]^9JPfiJTOKaJobFKPVY3I9KaeO\SFGHY3c2fOKab/QSPY3I9PficKXemFcKM#F2Y3If9b/WOI9QSI#[#"T9FoN8K\SW9FoYZfffipVp ( VQSPJT#F]bF]Z:YbF ffV"AE 8 Q * , = 1 , 1=<C`>#Y3\S\SYjUQSI9[iKabF%JT#bF]F%FH{fmF]b/Qgc2FIJK\BPVFGHJQ_Y3I9PvdKQSc2FMKaJffJVFPVJQgI#[ Y3IJT9bF]F%QgPPW#FP]i"T#F^9b/PJBf9b/FPVFIJPLFHuJVFI9PQSNFhb/FPW9\_JPnY3I%JT#FfiJVb/KM#F]Y*PQSc2f`\SQSG]Q_J)XfiKG]G]W#bKGHX2Ye9JKQSI#FMke{X!v9KI9MGHY3c2fOKab/FP JT9FffbFP/W9\_JP jUQ_JTlJT9Y3PVFYe9JKQSI#FMiZYbfiPVJKaJVF fiDYZ fiDJT#F fiKabJ!K\S[Yb/Q_JT9cP "T#F-PVFGHY3I9M[Y{FPY3I%QSIM9F]f9JTKI9K\SX(]FPnZ:YbBJT#FficQSIOQSI#[ 8QSI(JVF]bf9bF]JKae`QS\SQ_J)XffQSPP/W#Fv(KI9MJT#FhJT9Q_b/Mf9bFPVFI(JPnbFPW9\_JPRY3II#Y3QSPFoJVY3\_F]b/KI9GHF!" !$3y> fi?;'87$ ff3$ufmF]b/QSc2FI(JPijBF]bFG]Kabb/QSFM Y3W9JW9P/QSI#[ JT9bF]FN8Kab/QgKIJPYZfijUQ_JT Yf9JQScQgPVJQSGfOb/W9I9QSI9[:p Y(vhjUQ_JT1fFP/PQScQSPJQSGkf9b/W9IOQSI#[1p:fvhKI9M1jUQ_JT#Y3W#Jf9b/W9IOQSI#[1p ff3 KaeO\_Fxf9bFPVFI(JPkPVY3c2F5bF fiPW9\SJPY3IN8Kab/QSY3W9P!M9KaJKPF]JP]vRc2Y3PVJffYZ"jUT9QgG/TjnF]bFJKFIZbY3c JT#F ob/F]fY3P/Q_JVYbX5YZ"cKG/TOQSI#F\_FKab/IOQSI#[M9KaJKae`KPVFp.qn\gK FF]JK\w_vffxyy3 #YbFKG/TtM9KaJKPF]J]vUJT#FF]NFIJWOK\oM9QSPGHbF]JQSKaJQ_Y3I YZKaJVJVb/Q_e`W#JVFPjLKPifF]b/ZYb/cFM Z:Y3\S\_Yj QSI#[f9bF]NuQ_Y3W9PbFGHY3cc2FIOM9KaJQ_Y3I9PiKI9MFHufmF]b/QSc2FI(JK\!PF]JW#fOPp.M#F KabN8K\gT#Y Y3c2FP r KP/G]W#F\wv0xyy +("UT#FbFPWO\_JPjnF]bF!GHY3c2fOW9JVFMW9PQgI#[K2JVF!I fiDZ:Y3\SMPJVb/KaJQ fi^9FMkGHbY3PP"N8K\SQgM9KaJQ_Y3If9bYuGHFM9W#bF2fip fffiW9QSIO\SKI7v`xyy|3n"T#Fo\_FKPVJLF]bb/Yb/PLZYb KabFW9IOM#F]b/\SQSI9FMZ:Yb FKGTM9Y3cKQSI7#YbhJT#FffP/K FffYZdGHY3c2f`Kab/QSPVY3I9Pv`GHY3\SW9cI ff/hJT#F]b/P fmY3QSI(JPY3W#J N8Kab/QSY3W9P"bFP/W9\_JPZ:Yb-YJT9F]bK\_[Yb/Q_JT9cP]vdQSI(JVFI9M#FMJVYT#F\_f[F]JVJQSI#[K[FI#F]b/K\LfOQSGHJW9bFYZUjUT9KaJ2G]KIemFJT#FkfmF]b fiZ:Yb/cKI9GHFP!YZBF G]QSFIJ-Kaf9f9bY3KGT#FPjUQSJTM9Q *mF]bFIJoY3W9JVfOW#JPp.M#FG]QgPQ_Y3I\SQSPJP]vJVbF]FP]v GHY3ccQSJVJVF]FP]vF]JGavOQSIJVF]b/cPnYZF]b/bYb/Pop.KI9M7vujUT#FI%Kaf9fO\gQSG]KaeO\_Fv{PQ_]FPB{Y3cF YZJT9FficY3PVJLbF\_F]NaKIJnbFPW9\SJPRZ:YbKabFPWOccKab/Q_]FMQgIkJT#F!PG]KaJVJVF]bf`\_YJP"YZ 0Kae`\_F!~{"T9FiQSI(JVF]bf9bF]JKaJQSY3I YZ KaeO\_FxW9P/QSI#[Y3I9\SXF]bbYb/P[3Q_NFP%JT#FiKM9N8KI(JKa[F5JVY jUQ_JTfmFPPQScQSPVJQSGf9b/W9I9QgI#[#vUK\S\hJT#Fc2Yb/FKP p:f%T9KPkJT#FKM#NaKI(JKa[FYZ-f9bYNuQSM9QgI#[PQgc2fO\_F]bZ:Yb/cffWO\SKPhJT9K/-p ff3v0KI9M5T9KPoKkcffW9GT5PQSc2fO\SF]b f9bW9I9QSI#[PJKa[FJT9K/p:Y(ffE"FP/W9\_JPK\SPVY5GHY3c2fOKab/FZ.KNYb/Kae`\_XJVY5JT#F ff/fiJT#F]b lb/FPW9\_JP]v eOWOQS\SM9QSI9[%FQSJT#F]b-} P]v}hUP]vYb-} Pi"T#F]XKabF!K\g\7JT#F!c2Yb/FffQSI(JVF]bFPVJQSI9[Q_Z0jnF!GHY3c2f`KabF!JT#F!F]bbYb/P"QgIJT#F!\SQS[3TJYZ JT#F-PQ_]FPYe9JKQgI#FM7B9YbJT#F ff RGT#6Y lM#Y3cKQSI7v jUQ_JTifFP/PQScQSPJQSGf9bW9I9QSI#[eFKaJPoQgc2f9bYNFM h~e{XJ)jBYlfmY3QSI(JP]v:$Qfi}hY3cKQSIW9PVJVb/K\gQSKIqLK\SKI9GHFqnbFKPVJ fiqLW#fOKBG/T#Y\gKPP/~" FKabJ fi" FKabJ fi" FKabJ fi "" F]fOKaJQ_JQSP" Yb/PVFb/QSPKaeYbR}R}hF]NFIR}hF]NFIO~W9I#[Y3(I mxY3(I #~Y3I(BQScKY3\_FuT{W#JVJ\_F"QgG]0KG]0Y(FFT9QgG]\_F~YJVFYJVF3xKNF]ZYb/cQSI#Ffi}o|F]bbx2)4 3~)~ 44 +|)| 4 3)~ 4Sx +~u3x 4a|~+ 4~)~ 4&ya~)~ 4&|3~a2 42x )4&~|)4-p:Y(2x )4ux34 3yx )4Sxa2 4+)~ 42x )4~+ 4 +)4 +~)y 4&|ux)| 4&|3)4&~3~)~ 4 +(~)| 4 +()| 4&uxx]2 4&yaa2 4 +yx]2 4x)| 43x34SxS4 xx34Sx)4&~3x 4&x34)4Sx~)4&y)4&y+)4 +x34x34&y~)4&y|)4&y~)4+ 4Sxx34+ 4Sx)y 4)4&|)~ 4&~x343x 4)4)~ 4&3x 4&y)~ 4+ 4&)4)4&~iwc83x 4&x]24+ 4x~)4 +)4&y4)4&yy)4Sxx]24&y) 4)4&|+ 4&|)4)4 +)| 4Sxx)| 4 +)4&y)4) 4 ++ 4&)4&y+ 4Sx)~ 4x + 4+4&)4+)4)4&~|)4&~x + 4+-p:f]F b/bx|)4x + 4a|+ 4 33 4Sx +~3 4&|~u3x 4Sxx)y 4 +~u3x 4&~a2 4 +5x)y 4&~ +2x )4 3)4x2)4~+ 4&~x~)4 +~ )4S2x+)~ 42x )4~u3x 4 +)y 4&y~)| 4Sx)4 ~)4&~3~a2 4Sx]~)| 48) 4 +3)y 4&y~ )4 +()y 4 +(x 4+3x 4&|y)4&y)444x34)4|)4)4 +4)&4~)&4)4x|)&4 ~)&4S4 x~)&4 |)&4 ~x)&4 ~+ 4)4+ &4 ~x34|)4+ 4+ 444)4|)&4 ~+ffff8+ 4Sx~3 4u~ x34x)| 4&|x3x 4Sx)4 +ux34 +~3 4 +~+ 4&~x 4x]24 +S4 x)| 4&|~u3x 4)y 4&~~)| 4SxS4 xx )4|u3x 4) 4&y~)y 4 +x)~ 4)~ 4x 4&|x3x 4&~)4x + 4&yx 4) 4Sxx S4 x-p ff3]F bbx)4Sx +x + 4&~y)| 4&ya3 4Sx +u3x 4 +~~)| 4 +(~u3x 4&~)4 +~a2 42x )4&~y~a2 4&~|~a2 4&|3x)| 4&|3~+ 43~+ 4&|~u3x 48+)~ 42x )4u3x 4&ax)~ 4)~ 4&yy3 4&| ++ 4 ux~ )4)4Sxx]2 4x)~ 4~a2 4&~ +4&y~)~ 4&|y8+ 4&x)444~+ 4&|+x 4&4~)y 4~) 4 +) 4&x~)4+324&+)| 4&~4++x~)4x)4x + 4x x34 +x)~ 4)4)4&x)y 4)y 4&y~+ 4 +)~ 4y)4 +~+ 4&y)4~)~ 4&~~+ 4)~ 42x )4&yx|)4 +y)4x )4&|+324Sx+ 4&~x)y 4&)4+~|)4u3x 4&4)| 4~)4 +~u3x 4&y)4&&4 ~x 4&y)~ 4Sxx~)4|) 4&y|)4&+ 4+ )4+)| 4x) 4&y~)y 4| )4) 4&y)~ 4hJT#F]b2x )4Sx 4ff0 )~a2 4Sx @fffi 0 )+ 4&y .!( @ )3 4 42* 0 ))~ 4 4ff~|)4 @ 0 )~ux34 G~~)4 . 0~u3x 4& fi0 4x)y 4&~ 4A 02x )4 ( 4 ))4 Gx)| 4 ux fi @~ )43 ( . .x )4 (. )~ )4Sx .ff )+)| 4&| "x)| 4&|| 0~)y 4 ( @ 0)~ 4&|3 . 0~ )4&G)4 @!( fi )x34 .ff@ )x)4 ( 40)~)4&| 24 0 )+ 4fix]24&y fi)4 .!( @ @~~)4&"~ux34&~ @ 0 )0Kae`\_Fx ufmF]b/QSc2FI(JK\mbFPWO\_JPW9PQSI9[1!3Y I(NFIJQSY3I9P 8 QSP"JT#FffjUT#Y3\_FffI(W9cffemF]bUYZd\SQSJVF]b/K\SP"YZdK%} v QSPUQSJP I{W9cffeF]bUYZdb/W9\_FPL9Ybff/hJT#F]bP uv#I(W9cffemF]b/PRKab/F [3Q_NFI%Y3IJT#FhZYb/c F]bbYb PQ_]F v(j T#F]bFikQSPBQSc2f9b/YNFM h~%p fi~ fi n L,1eOW9Qg\SM9QSI#[l} P]vdPQ_]FQSPffJT#FI(WOc!emF]b-YZU\SQ_JVF]b/K\gP%p.}hY3cQSI9[Y3P]vUxyy3 @ QSPff } eOWOQS\SM9QSI9[l} P]vr Kaf9f(Xvxyy3 QgP +# p.#b/KI9G r Q_JVJVFI7v"xyy3 tQSP+}I#YJKaJQ_Y3IOP!Z:Y3\S\_Yj p UYuGeOW9Qg\SM9QSI#[o} P]vuI#YJKaJQ_Y3IOPRZ:Y3\S\_Y`j 5p Y{G r KPG]W#F\wv7xyy 3 "2QSPUx fi FKabFPVJ FQ_[3T(eYbBb/W9\_FhKI9M)!QgP +# lp:f9b/WOI#FM7v#M#F]Z.KW9\_JLfOKab/Kc2F]JVF]bPneOW9Qg\SM9QSI#[ff}hUP]z9JT#FPQS]FoYZ KJVb/F]F!QSPQ_JPj T#Y3\_FoI(WOc!emF]bYZI#YuM#FP]eOW#J JT#Fff} Ye9JKQSI9FMiGHY3I(JKQSI9P bY3W#[3T9\SX%FQS[3TJhJQSc2FP ZF]jnF]bo\SQ_JVF]b/K\gP"JT9KI fi~ fi n fiP M#FG]QgPQ_Y3I\SQSPJ] Z-jBFFH#GHF]f9J ff YJVF uv-Y3I K\S\fiYJT9F]bf9bYe`\_FcPkY3ItjUTOQSG/TjnFM9QSPfY3PFiYZ fi~ fi n fi P$: :fi50504545454040403535353025201530252015302520151010105550005101520 25 30 35WIDC(p) err. (%)404550005101520 25 30 35WIDC(p) err. (%)4045500100100808080604020WIDC() #litterals100WIDC() #litteralsWIDC(o) #litteralsWIDC() err. (%)50WIDC() err. (%)WIDC(o) err. (%)6040200204060WIDC(p) #litterals80100101520 25 30 35WIDC(o) err. (%)404060WIDC(o) #litterals80455060402000500204060WIDC(p) #litterals80100020100KaeO\_F!~&huG]KaJVJVF]b/fO\_YJPPW9ccKab/Q_QSI9[ PVY3c2FLbFP/W9\_JP0YZ` KaeO\_FfixBZ:Yb JT#FLJT#bF]F.'OKNYb/P YZ!vQSIJVF]b/cPLYZF]bbYbp:^9bPVJLbYjhBKI9MkPQS]F2#p 8nv#PVFGHY3I9MkbYjhv#Y3IkJT#FfiJT9Q_bJ)XM9KaJKPVF]JPRKGTfmY3QSI(JoKaeYNF2JT#F % \SQSI#FM#F]fOQSGHJPoKkM9KaJKPF]JZYboj T9QSG/TJT#FK\S[Yb/Q_JT9cQSI5KaeOPG]QgPPKfmF]bZ:Yb/cPLemF]JVJVF]bbFPWO\_JP]v3jnF"Y3W#JVfmF]bZ:Yb/c fi~ fi n Y3I2emYJTKG]G]W#bKGHXKI9MPQ_]F QSI9K\g\_Xv3Y3I ff YJVF uv9I#YJVFUJT9KaJjUQ_JT5YfOJQScQSPVJQgGf9b/W9I9QgI#[%QgPoP\SQ_[3T(J\_XY3W9JVfF]b/ZYb/cFMe(X fi~ fi n e{X~)4 ux kv e`W#JoJT#F} Ye9JKQSI9FMlQSP a2N / JQScFP"PcK\S\SF]bJT9KIkJT#F!M#FG]QgPQ_Y3Ik\SQSPVJLYZ fi~ fi n U9)Z jnFM#jBF\g\mY3IJT#FbFPWO\_JPUYZ +# {vPQScQS\SKabUGHY3I9G]\gW9PQ_Y3I9PhG]KIemFffe9b/Y3W#[3TJ UY3Ix~Y3W9J YZhxMOKaJKPVF]JPfiY3IjUT9QSGTjnFb/KI +# {v p:f ^OI9M9PfiPcK\S\_F]bfiZYbcffW9\gKP]vKI9MPVJQS\g\emFKaJP +# & PffKG]G]W#b/KGHXY3Iy%YZnJT#Fc{W9KI(JQ_JKaJQ_NFGHY3c2f`Kab/QSPVY3IYZ 8 Ka[3KQgI9PVJoJT#F2I{W9c!emF]bfiYZBI9Y{M#FPhYZBJT#F}fi"PoPT#YjUPhJT9KaJoY3I+M9KaJKPVF]JPfiY3W#JhYZRJT9F%x 5p Y3\_Fv0uT{W#JVJ\_Fvm"QSG] KG]Y{Fv W9PVJVb/K\SQgKI`vOJT#F2} PfiKabFc2YbFJT9KI|JQSc2FP PcK\S\SF]bv9jUT9Qg\_FoJT#F]XY3I9\_XQSIOG]W#bUK\SY3PPUQSIKG]G]W#b/KGHXlZ:Ybfi~YZJT#FcvKI9M\SQgcQ_JVFMkJVY5xa& %#Yb JT9QSP0\SKaJVJVF]b f9bYeO\_Fc p."QSG] KG]Y{Fv3K [3\SQSc2fOPFdKaJ KaeO\_FhxRPT#YjUP0JT9KaJ0JT9FB} P]vajUQ_JTff\_FPPJT9KIb/W9\_FP Y3I5KNF]b/Ka[Fv F]F]fOPoGHY3c2fOKabKaJQ_NF\_XicY3PVJ YZBJT#F2QSI#Z:Yb/cKaJQ_Y3IiGHY3IJKQgI#FMQSI}hUPhTOKNuQSI#[c2YbFUJT9KIKT{W9I9M#b/FM-\SFKNFP]BfiIcKIXf9b/YeO\_FcP jUT#F]b/F"cQSI9QSI9[fiQgPPW#FPKabF GHb/W9G]QSK\wv3P/W9G/TK!PQ_]FbFM9WOGHJQ_Y3I%jBY3W9\gMemFfijBF\g\`jnYbJT%JT#Fp.GHY3c2fOKabKaJQ_NF\_XkP\SQ_[3T(Jd\SY3PPLQSIkKG]G]W#b/KGHXv9emFG]KW9PVFfijnF F]F]fK!P/Q_[3I9Q_^OG]KI(JfOKabJRYZ7JT#FUQSI#Z:Yb/cKaJQSY3I2Y3INF]bXP/cK\S\#G]\SKPP/Q_^9F]b/P]vJT(W9PB\S#Q F\_X-JVY!emFUQgIJVF]bfObF]JKaeO\_Fn"<74" fi#E" 72@y;'87 .d.53#"F.+I5JT#F h}o|M#Y3cKQSI7v7FKG/TFHuKc2f`\_F2T9KPx]keOQSIOKabXlNaKab/QSKaeO\_FP!"T#FJVFI(JTQSPoQ_bb/F\_F]N8KI(JoQSIJT#FPVJVbY3I9[FPVJPVFI9PVFp Y3TOI7v Y3T9KN{QDv r 8'9F][F]bvffxyy+( "T#FJKab[F]JlGHY3I9GHF]f9JQSP%K fi} h p.K:$4zfiiwc70 6 ( 64 6 6-fi 6 * 6-( 60 6 .fffffi/x.fi/xxfi/x@M#F]Z.KW9\_J )xfi/xxxu&y|(xfi/xfi/xu 3Q_[3W#bFx } Ye9JKQSI#FMY3IJT9F fi}fi|!M#Y3cKQSIjUQ_JT-p:fdUT#F"^9b/PJdJT#bF]F b/W9\_FPFH#KGHJ\_XFI9GHY{M9FJT#FoJKab[F]JhGHY3I9GHF]f9J]v`KIOMkJT#F!Q_bb/F\_F]N8KI(JLN8KabQSKaeO\_FQSPKae`PVFIJUZbY3c JT#F}40fi*@@*@(fi*0(.(4fi(.@fiQ_[3W#bF!~& aK b/JUYZK}fiYeOJKQSI#FMY3IJT#F fi}fi|M#Y3cKQSIljUQ_JT +# { Y3PQ_JQSNF!\SQ_JVF]b/K\gP\SKaemF\7JT#FQSIJVF]bI9K\uI#Y{M9FP] 0YoG]\SKPPQSZX!KIYe`PVF]bNaKaJQ_Y3I7vJT#F\_F]Z:J FM#[FLYZKfiI#YuM#FLQSP ZY3\S\SYjnFMjUT#FIKI2YeOPVF]bNaKaJQ_Y3IGHY3I(JKQSI9P p fffiff` % JT9FfY3P/Q_JQ_NF"\SQ_JVF]bK\wv3KI9MJT#Fb/QS[3TJFM#[F QSP ZY3\g\_YjnFMYJT#F]bjUQSPFffp J 1.2 1dJT#F \gQ_JVF]b/K\OQgPRI#F][3KaJQ_NFfiQSI2JT9FUYeOPVF]b/N8KaJQ_Y3Id"T#F"emY3\SMP/(W9Kab/F QSPBW9PVFMJVY%M9QgPVfO\SKXJT#Ffff9bFPVFIOGHF!YZJT#F-Q_bbF\_F]NaKI(J"N8KabQSKaeO\_FQSIJT#F!JVb/F]F I9KQ_NF-GHY3INF]b/P/Q_Y3IYZ JTOQSPLJVbF]F!QSIkbW9\_FPLZ:Yb"emYJTlG]\SKPPVFP"[FI#F]b/KaJVFP a2b/W9\_FPv{Z:YbUK2JVYJK\YZxay2\SQ_JVF]b/K\gP]$: 2;fi}jUQ_JTFKG/Tc2Y3I#Y3cQSK\RGHY3I(JKQSI9QSI9[iKaJc2Y3PVJ-JT#bF]Fk\SQ_JVF]b/K\SPhYNF]b2JT#F^9b/PVJ-I9QSI#FN8Kab/QgKaeO\_FPp 0 6 ( 6 . p 4 6 6 p fi 6 * 6 @ uW9G/TK2ZYbcffW9\gK-QgPJX{fOQSG]K\S\SX%T9KabMkJVYFI9GHYuM#FW9PQgI#[K5PcK\S\BM#FG]QSPQSY3IJVbF]F5+IY3W9bffFHufmF]b/QSc2FI(JP!j Q_JT-p:Y(-KI9p:fvjBFT9KNFbFcKab FM5JT9KaJoJT#FJKab[F]JoZ:Yb/cffWO\SKQSJPVF\_ZRQSPfiK\ScY3PVJoK\_jnKX{P!KI5F\_Fc2FI(JhYZBJT#F2G]\SKPPQS^9F]bfieOW9QS\_J]vKI9MkJT#FffQ_bbF\_F]NaKI(JLKaJVJVbQ_eOW#JVFQSPK\SjnKX{P"Kae`PVFIJ]B QS[3W#bFxoPT#YjUP"KIFH#Kc2fO\SFoYZ } jUTOQSG/TkjLKPYe9JKQSI9FMkY3IlKb/W9I%YZ ! YJVFJT9KaJJT9FGHY3I9GHF]f9JbF]JW#bI#FMQSPK fi} 9 Q_[3W#bF!~M9F]fOQSGHJPKfOKabJYZ K2JVbF]FoYe9JKQgI#FMkY3IJT9QSPLM#Y3cKQSIkjUQ_JT +# { T9QS\SFhJT9FoJVbF]FKaf9fmFKab/PLJVYemFo(WOQ_JVFo\SKab[FZ:YbnJT9FhM#Y3cKQSI7v(I9YJVFhJT9F f9b/FPVFI9GHFhYZJT#FfiQ_bbF\_F]NaKI(JRNaKab/QSKaeO\_F QSIJT9F JVbF]FvujUTOQSG/T%Q_JBGHY3I(JVb/Q_e`W#JVFPJVY-FI9\SKab[F jUT9QS\_F"cK {QSI9[!Q_JRT9KabM#F]bRJVYcQSI#FdfiI%cKI(X2YJT#F]bnM9Y3cKQSI9P]vjBFhYeOPVF]bNFMfmF]b/PQSPJVFIJb/W9\SFPYbhP/W#e7GHY3I9GHF]f9JP"JT9bY3W#[3TlJT9Fx]GHb/Y3PP fiDNaK\SQSM9KaJQ_Y3Ilb/W9I9P]"uQScQS\SKab/\_XJVY fi}o|{v`jUT9FI#F]NF]bUjnFGHY3W9\SMkcQgI#FUJT#FfibFP/W9\_JPBjUQ_JTkKP(W G]Q_FI(J\_XKG]G]W#bKaJV,F {I#YjU\_FM#[FfiYZ0JT#FoM#Y3cKQSI7v{JT#FPVFfifOKaJVJVF]bI9PjnF]bF-cY3PVJ QSI(JVF]bFPVJQgI#[#U#YbfiFH#Kc2fO\_Fv`JT#F-} P Ye9JKQSI9FMlY3IiJT#F R}hF]NFI5M#Y3cKQSIiGHY3IJKQgI#FMc2Y3PVJLYZJT9FhJQgc2FhKGHY3cffeOQSI9KaJQSY3IYZ0JjnY2b/W9\_FPBjUQ_JTY3I#Ffi\SQ_JVF]b/K\`FKG/T7v#j T9QSG/TbF]f9b/FPVFIJVFMK-NF]bXKG]G]W#b/KaJVF!jnKX%JVYG]\gKPPQ_Z:Xy-Y3W#JYZ JT#F2x]2fmY3PPQ_e`\_F G]\SKP/PVFP]BfiIkJT#F YJVFKI9M YJVF3x!M#Y3cKQSI9P]vjnFK\SPVYYeOPVF]b/NFMGHY3I9PVJKI(JfOKaJVJVF]b/IOP]v0PVY3cF2YZBjUTOQSG/TKabF2jnF\S\ uI#Yj Ip.qn\gK FF]J!K\w_vRxyy3oJVYf9bYN{QgM#FhKNF]b/X%KG]G]W#bKaJVFG]\SKPPQ_^`G]KaJQ_Y3IkZYb"K-JQSI(XP/Q_]F dNFIZ:Yb YJVF3xojUT9F]bFoG]\SKPPQSG]K\mPVJWOM9Q_FPYZ:JVFIbF]fmYbJF]b/bYb/P2YNF]bx~ %vKI9M1K\Sc2Y3PVJI#F]NF]bKabY3WOI9M x] p " Y3\_JVFvxyy 3vjnFYeOPF]bNFMY3IcY3PVJ!YZJT#Fb/W9I9P!K} GHY3I(JKQSI9QgI#[KIKG]G]W9b/KaJVFbW9\_FjUQSJTJjnY\gQ_JVF]b/K\SPoY3IO\_Xv0j Q_JTjUT9QgG/T-p:fnf9b/YNuQSM#FMkY3IlKNF]b/Ka[F-KIlF]bbYbUW9IOM#F]bx] %jnKPfiK\SPVY%GHY3c2fOKabFMJVY +# Y3IKbFK\0jBYb\SMM#Y3cKQSIY3IijUT9QgG/TcQSI9QSI#[QgPPW#FPhKabFKP%GHb/W9G]QSK\"KPG]\SKPPQS^OG]KaJQ_Y3IPVJVb/FI#[J9T 5Ka[b/QSG]W9\_JW9bF IFHufmF]b/QSc2FI(JQSP2emFQSI#[G]Kab/b/Q_FMY3W9JQSIKabJQSI9QS{W#F-e(XJT#F2}fi} p.}hF]fOKabJc2FI(JK\R}fiQ_bFGHJQSY3I5YZ [b/QSG]W9\SJW#bFKI9M#YbFPVJv0JVYKG/TOQ_F]NFemF]JVJVF]b-WOI9M#F]b/PVJKIOM9QSI#[kYZJT#FeFTOKNuQ_Yb!YZZ.Kab/c2F]b/Pv QSIfOKabJQSG]WO\SKabbF][3Kab/MOQSI#[lJT#FQSb!jUQS\g\SQSI#[3I#FP/PJVY2GHY3IJVbKGHJ"K p.OKab/cQSI#[0F]bb/Q_JVYb/QgK\ Y3I(JVb/KGHJ hPW9K\`Z.Kab/cQSI#[-GHY3IJVbKGHJPjUQ_JTFQ_JT#F]bLJT#FPVJKaJVFp.#b/KIOGHFBYb BW#bYfmFUM9QgMI#YJLGHY3IJKQgIGHY3ccQ_Jc2FI(JPnZYbnJT#FhZ:Kabc2F]bLJVY-PKaJQgPVZX+I%K "vFKG/TZ.Kab/c2F]b2GHY3ccQ_JP-JVY5KMOKaf9J-KIOM YbG/T9KI9[FkTOQSPffKa[bQSG]W9\_JW#bK\dJVFG/TOI9QS{W#FP-Yb-fObY{MOW9GHJQ_Y3I9P]vJVYFIOPW#bFP/W9PVJKQSI9Kae`\_FM#F]NF\_YfOcFIJffZYb-\_Y{G]K\BKa[b/QSG]W9\SJW#bF%IFHuGT9KI#[F%ZYb-JT9QSP]v T#FbFGHFQSNFPJT#F[3W9Kab/KI(JVF]F2JVYYe9JKQSI^OIOKI9G]QSK\ T#F\_f5ZYbfiJT9QgPhGHY3I(JVb/KGHJ]v KI9MJVYeF-JVb/KQSI9FMiJVYI#F]j Ka[bQSG]W9\ fiJW#b/K\ JVFGT9I9QS{W#FP]uWOG/TKM#Y3cKQgIQSPfiK[Y(YuM5JVFPVJemFM5JVYF]NaK\SW9KaJVFKcF]JT#Y{M5Y3IJT#F2eOKPQSPfiYZf9bFMOQSGHJKaeOQS\SQSJXKI9MQSI(JVF]bf9bF]JKaeOQg\SQ_JXv7emFG]KW9PFYZLJT#FfO\SKGHFYZLWOI9GHF]bJKQSI(JXQSIKa[b/QgG]W9\_JW#bFv KI9MJT#FkZ.KGHJ2JT9KaJYe9JKQSI9QSI9[iM9KaJKG]KIemFkKTOKab/MKI9M\_Y3I#[JKP JT#F}fi} TOKPffJVYemFkKP2KG fiG]W#b/KaJVFKPfifmY3PP/Q_eO\_F-QSIiQSJPfif9bFM9QSGHJQSY3I9P KIOMQgIJVF]bfObF]JKaJQ_Y3I9P]v7JVYlcKI9Ka[FKPfiemFPVJoKPfifY3P/PQ_eO\_F-Q_JPbF\SKaJQSY3I9PT9Q_f`PjUQ_JTZ:Kabc2F]b/P]v#KI9M%QSIJT#FoG]KPVFfiYZ BP]v(JVY2cK FfiJT#FfiemFPVJnf9bY3c2YJQSY3IG]Kc2f`KQ_[3IZ:YbUJT#FPVFffI#F]j GHY3I(JVb/KGHJP] [b/QSG]W9\SJW#bFoQSP"K\SPYNF]bXlPVFI9P/Q_JQ_NFoJVYK ffVPT#YjLG]KPVF-F *FGHJ Lf9b/YNuQSM#FMF]NFIlZ:F]j bF]fObFPVFI(JKaJQ_NFZ.Kab/c2F]b/PLjUQg\S\mT9KNF!P/W#eOPGHb/QSeFMJVYJT#FGHY3I(JVb/KGHJP]vGHY3c2fOKab/KaJQSNF\_XcKIXYJT#F]b/PUKabF!\S#Q F\SXJVYZ:Y3\S\_Yj+I5JT9QSPoPVJWOM#XvZ:bY3cJT#FM#FPGHbQ_f9JQ_Y3IYZ ~kN8KabQSKaeO\_FPfiZ:YbKaemY3W#J!|abF]f9b/FPVFIJKaJQSNFZ:Kabc2F]b/PPKaJQSPZXuQSI#[JT#FGHb/Q_JVF]b/QgK5JVYKM9T#F]b/FJVYK "vRJT#FiKQSc QSPJVYM#F]NF\_Yf1cY{M#F\gP2ZYb%JT#Y3PVFjUT#YKabFKGHJW9K\g\_XjUQg\S\SQSI#[JVYlKM9T#F]bFv7JT#Y3PFI#YJojUQS\S\gQSI#[JVYlKM9T9F]bFvKI9MJT#Y3PVFG]W9bbFI(J\_XiW9IOGHF]bJKQSI7dKab/QSKae`\_FP2KabFM9KaJKY3IFKG/T1Ka[b/QSG]W9\_JW9b/K\nFH{fO\SY3Q_JKaJQ_Y3Ip.PQS]FvBJVF]bbKQSII9KaJW#bFvn^OI9KIOG]QSK\LM9KaJKuvJX{fmFYZ f9bYuM9W9GHJQ_Y3Iv{F]JGvOKP"jnF\S\KP c2YbFfmF]b/PY3I9K\7M9KaJKY3IlJT#FZ.Kab/c2F]b/P!p:FMOW9G]KaJQ_Y3I7v`Z:KcQg\_XPVJKaJW9PvYe VFGHJQ_NFP]v(fF]bPVY3I9K\#KI9PVjnF]bdJVY!Ko{W#FPVJQSY3I9I9KQ_bFvF]JGaB"T9QSP bF]f9b/FPVFIJPRKPcK\S\#MOKaJKPVF]JJVYcQSI#Fv{eOW#J]vuQSI(JVF]bFPVJQSI#[3\SXvJT#FhbFPW9\SJPRYe9JKQgI#FMjnF]bFfiM9Q *mF]bFI(JRjUT#FIf9bYuGHFPPQgI#[!Q_JnjUQ_JT +#YHb-p:f:$5Ofiiwcffffp'& &:- &Efi- J&$ ! V6p'& $8! &:-0p'& &:- &Efi- J&$ ! V6p'= $5- ff( J&3!] 6p'& fi0&38'$ 58 $M#F]Z.KW9\_J )KMOT#F]bFfi/xxu ~fi/xfi/xu&|KM9T9F]bFxxQ_[3W#bF/& "T#F!} Ye9JKQSI#FMY3IiJT#F-Ka[b/QSG]W9\_JW9b/K\7M9KaJKip.PF]FffJVFHuJUZ:YbUJT#F-QSI(JVF]bf9bF]JKaJQ_Y3IYZJT#FN8Kab/QgKaeO\_FPFbKI5eYJTK\S[Yb/Q_JT9cPfiQSI5Kx] fiDZ:Y3\SMPVJVbKaJQ_^9FMGHbY3PP fiDN8K\SQgM9KaJQ_Y3IFH{fmF]b/Qgc2FIJ]1-p:fYe9JKQSI9FMffKfi~)4& KNF]b/Ka[FF]b/bYb I|"Y3W9J0YZx]hb/WOI9P]v8JT#FnP/Kc2Fn} jLKP QgI9M9W9GHFM7)J QSP0f9bFPVFI(JVFMQSI- Q_[3W#bF {qnKP/QSG]K\S\_XvaJT9QSP } f9bYNFP JT9KaJ f9bFM9QSGHJQgI#[UJT#F ff KM9T9F]bF2 fiG]\SKPP QSP JT#FnFKPQ_FPVJ JKP vZ:Y3\S\_YjnFMle{XJT#FfObFM9QSGHJQ_Y3IlYZJT#F ffVKM9T9F]b2F G]\SKP/P]"T#F ff> p.W9I9GHF]bJKQgIlZ.Kab/c2F]b/PQSP"f9b/FM9QSGHJVFMY3I9\_Xe(XJT9FfiM9F]Z:KW9\SJBNFGHJVYbn"T9QSPnPVF]FcPnb/KaJT9F]b"I9KaJW#b/K\ jUT9F]bFKPnJT#FfiFH{JVbFcFoeFTOKNuQ_Yb/PBJVFI9MJVYemFG]\_FKab"JVYM#F]JVF]b/cQSI9Fv#JT#F!W9I9GHF]b/JKQSIJ)X%QgPJT#FT9Kab/M9FPVJJVYf9bFMOQSGHJ]+# p.M#F]Z.KW9\_JfffOKab/Kc2F]JVF]b/PoQSI9MOW9GHFMKi}h jUT9QgG/TjLKPK\Sc2Y3PVJffJT#FFH#KGHJJVb/KI9PGHbQ_f9JQ_Y3IYZb/W9\SF-xav9K-b/W9\SF jUTOQSG/T%PKXuPJT9KaJLZ.Kab/c2F]b/PLj Q_JTkI#YffFMOW9G]KaJQ_Y3Ip:jUQ_JT9Y3W#JnKI(XkKa[b/QSG]W9\_JW9b/K\`MOQ_fO\_Y3cKYbkJVb/KQSI#F]FP/T9Q_fOPKI9MI#YY3I#[Y3QSI#[f9bY VFGHJKabFI#YJj QS\S\SQSI9[JVYKMOT#F]bF "T9QSPb/W9\SFiQSP%c2Y3PVJ\_XQSI(JVF]bFPVJQSI9[%emFG]KW9PFQ_Jfif9bYNFPJT9KaJoFM9W9G]KaJQ_Y3IQgPoKPVJVbY3I#[Z.KGHJVYb!M#F]JVF]b/cQSI9QSI#[%JT#F ff KMOT#F]b2FKI9PVjnF]b"T#Fff}hUPUQSI9MOW9GHFMlK\SPVYGHY3IJKQSI9FMY3I#FffYbUJ)jBYkc2YbF!\gQ_JVF]b/K\SP"PF]fOKab/KaJQSI#[JT#F ffVKM9T9F]b2FKI9M ff2 1G]\SKPPVFPp.KNF]bKa[FF]bbY2b ")| 4 vmeOW9JUY3I9\_XkZ:F]j YJT9F]bhJTOQSI#[3PUGHY3WO\SMlemFffcQSI#FMlZ:bY3c JT#FJVbF]FPUYZ +# {vQSIkJT#F\SQS[3TJYZ JT#Fof9b/YeO\_Fc KM9M#b/FPPVFM7E W9\_F~QgI1 Q_[3W#b/F M9QSMI#YJT9KNFJT#F5F(W9QSN8K\_FI(JkQSI JT9F5}fi"PkQSIOM9W9GHFM7 T9KaJQ_J%P/KXuPQSP-QSI(JVF]bFPVJQSI#[iZYb-JT#Fk}fi} nvemFG]KW9PVF%Q_J!eOb/QSI#[3P!JT#FZ:Y3\S\_YjUQSI#[iGHY3I9G]\SW9PQSY39I Z:Kab/cF]b/P!j Q_JT#Y3W#JY3I#[Y3QSI9[2f9bY VFGHJP]vOKI9MI#YJ"PF\S\SQSI#[-JT#FQ_bfObY{MOW9GHJPnY3I9\_XJVYKjUT#Y3\_FPK\SF]bv#KabFY3IkJT#,F uI9Q_Z:FfiFM#[FZ:Yb2JT#FQ_b2c2FcffeF]bPT9Q_fp:FQ_JT#F]bQSI ffVKM9T#F]b/2F uvRYbQSI ff KM9T#F]b/2F Q_JT#Y3W#J-[Y3QSI#[5Z.W#bJT#F]b2QSI(JVY\_YuG]K\`Ka[bQSG]W9\_JW#bK\OGHY3I9PQgM#F]b/KaJQ_Y3I9PvJT9QSPBb/W9\SFvZ:YbnJT9Fh}fi} RI#[3QSI9F]F]b/P]vb/F]f9bFPVFI(JPLKIKG]G]W#bKaJVFNuQ_F]j YZ JT#FZ.Kab/c2F]b/P"KGHJWOK\S\_XkGHY3IJVbY3\g\SQSI#[JT#FQ_bFHufO\_Y3QSJKaJQ_Y3IlGHY3PVJP]vOeFQgI#[FQ_JT#F]b"Z:Yb"Yb Ka[3KQgI9PVJBP]v#KI9MJT9KaJFMOW9G]KaJQ_Y3IfOWOPT#FPnJVYjLKab/M9PUJT#Fc2FcffeF]bPT9Q_fp.GHY3c!e`QSI9KaJQ_Y3IYZ b/W9\SFPhx!KI9Ml~3vf9bYe`KaeO\_XemFG]KW9PFQ_J"K\S\_YjUPJT#Fc JVYPVF]FJT#FZ.W#JW#b/FofYJVFI(JQSK\7emFI#F]^OJPLYZ JT9FGHY3IJVb/KGHJ]vemF]JVJVF]bJT9KIlQSJP"G]W#bbFI(J"GHY3I9PVJVbKQSIJP'.d"m "#?;'#"($|cp.qLKW#F]b r Y3T9KNuQwvoxyyy{z!hfOQ_JV r KG]\SQSI7vx yyy3v3F]NFIGHY3I9PQgM#F]bFMkp.qnKW9F]b r1s Y3T9KN{QDvuxyyy30KP Q_JP0fmYJVFIJQSK\{cKQSI!f9bYeO\SFc d{fmF]b/QScFIJK\PVJW9MOQ_FPUPT9Yj JT9KaJfiPW#eOPVJKI(JQSK\0I#Y3QSPVF-\_F]NF\SPhG]KIK\SJVF]b JT#F-NYJVFJVYJT9FfffmY3QSI(JUJT9KaJfiQ_JPhKG]G]W#b/KGHXQSP\_YjnF]bJTOKI JT9KaJ%YZKP/QSI#[3\_FlYZQSJPG]\SKP/PQ_^9F]bipDfifOQ_JV r KG]\SQSI7voxyyy3 hfOQ_JV r KG]\SQSIp+xyyy3fifmY3QSI(JhY3W#JfiJT#FbF]jBFQS[3TJQSI9[kP/G/T#Fc2F2YZBJT#F2FH#Kc2fO\_FPfiQSIemY(Y3PJQSI#[kKPfieFQgI#[%K%fmYJVFI(JQSK\bFKPVY3IZYbBJT9QSPemFT9KN{QSYb"T#Y3W#[3T2jnFUM#YffI#YJBW9PF"KIX2bF]jnFQ_[3T(JQSI#[!P/G/T#Fc2Fv{jnFUT9KNFfiG/T9Y3PVFIZ:YbJT#F-PK F!YZdGHY3c2f`\_F]JVFI#FPP JVYKM9M9bFPP"JT9F!emFT9KNuQ_Yb"Y<Z -p:f"Ka[3KQSI9PVJhI#Y3QSPVFv`KI9MGHY3c2f`KabFQ_JPb/FPW9\_JP%jUQ_JTfmF]b/TOKafOPkJT#FcK VYbQSI9MOW9GHJQ_Y3IK\_[Yb/Q_JTOc jUQ_JTjUT9QgG/TjnFPT9KabFJT9F ff+JVYf fiM#YjUIKI9M5f9b/WOI#2F kQSI9M9W9GHJQSY3IiPGT#Fc2F +# fip ffoW9QSI9\SKIv xyy +(UT9QSPfiPVJW9M#XbF\SQ_FPfiY3I5JT#F fi}o|M#Y3cKQgI7vnQgIjUT9QSGTjnFbF]fO\gKGHFJT#FlYbQ_[3QSI9K\x] G]\SKPPI#Y3QSPVFp.qnWOIJQSI9F r hQ_eO\_F]JVJ]voxyy~3e(XNaKab/Q_Y3W9PQSIOGHbFKPQSI#[KcY3W9IJPdYZmG]\gKPPdI#Y3QSPFb/KI#[3QSI#[oZ:bY3c JVY +3 e{X2PVJVF]fOPYZ~ %v3YbBN8KabQ_Y3W9PY3QSPVFiTOKI9M9\SQSI9[5QgPKGHb/WOG]QSK\UQSP/PW#FZ:YbemY{Y3PVJQSI#[:$$fi0.50.35WIDCC4.5Bayes0.450.40.250.350.3error (%)error (%)WIDCC4.5Bayes0.30.250.20.150.20.150.10.10.050.050000.05 0.1 0.15 0.2 0.25 0.3 0.35 0.400.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4class noise (%)100attribute noise (%)110WIDCC4.5Bayes (DC)Bayes (DT)908090807070size60sizeWIDCC4.5Bayes (DC)Bayes (DT)10050406050403030202010100000.050.10.150.20.250.30.350.40class noise (%)0.050.10.150.20.250.30.350.4attribute noise (%)Q_[3W#bF,+( R\_YJPkYZffJT#F5F]bbYb/Pp.W#fmKIOMP/Q_]FPp.M#Yj I`YZ-p:fv +# KI9MqLKXFPb/W9\_FKa[3KQSI9PVJ"NaKab/Q_Y3WOPG]\SKPP"I#Y3QgPVF\_F]NF\SP!p.\SF]ZJLKIOMKaJVJVb/Q_eOW#JVFffI#Y3QSPVFo\_F]NF\SPffp:b/Q_[3T(JSQ I9GHb/FKPQSI#["Kc2Y3WOIJPYZ9KaJVJVb/Q_eOW#JVFBI#Y3QSPVFdQSIJT#FBPKcFdb/KI#[F "T#F fi}o|"M#Y3cKQSI!T9KPJT#FRKM#NaKI(JKa[FJT9KaJ2JT#FkJKab[F]JGHY3IOGHF]f9JQSP {I9YjUI7vBKI9MQ_JT9KPemF]FIKMOM#bFPPVFMQSIKPW9eOPVJKI(JQSK\BKcY3W9IJ2YZf9bF]NuQ_Y3W9PhFHufmF]b/QSc2FI(JK\ jBYb {P] FT9KNFPQSc-W9\SKaJVFMGHYb/bFPVfmY3I9M9QSI9[%M9KaJKPF]JPoY.Z ux~FHuKc2f`\_FPFKG/Tv#ZYbnFKG/TI#Y3QgPVFh\SF]NF\w RKG/TP/W9G/T%M9KaJKPVF]JLjLKPBfObY{GHFP/PVFM%e(X-p:fBKI9M +# {v#W9PQSI9[ffKx] fiDZ:Y3\S!M fiGHbY3PP fiDN8K\SQgM9KaJQ_Y3If9b/Y{GHFM9W9bFR Q_[3W#b,F +M#F]fOQSGHJPJT9FbFPW9\SJPYe9JKQSI#FMlZYb"JT9FF]bbYb/P KI9MZ:YbUJT#F!P/Q_]FP"YZ JT#F!G]\gKPPQ_^9F]bP]B"T9FPQ_]FYZK} QSP"Q_JPj T#Y3\_F!I{W9cffeF]bUYZ \gQ_JVF]b/K\SP]v9KIOMJT9KaJUYZK}fi QSPUQ_JPI(WOc!emF]bYZQSI(JVF]b/I9K\7I#YuM#FP]T9QS\_F JT#FRbFPQSPVJKIOGHFdKa[3KQSI9PVJI#Y3QgPVFdPVF]FcPJVY"emF b/F\SKaJQ_NF\_XhjBF\g\M9QSPVJVb/QSeOW#JVFMhKc2Y3I#H[-p:fKI9M +# 'p-p:fUPVF]FcP JVYfmF]bZ:Yb/c emF]JVJVF]bhZYbhG]\SKPPhI#Y3QSPVFv9j T9QS\_F +# PVF]FcP JVYfmF]bZ:Yb/cemF]JVJVF]b"Z:Yb"KaJVJVb/Q_eOW#JVFoI#Y3QgPVFv9KfOT#FI#Y3cFI#Y3Ic2YbFQSI(JVF]bFPVJQgI#[2GHY3c2FPZ:bY3c JT#FPQ_]FPLYZ JT#FoZ:Yb fic-W9\SKPQSI9MOW9GHFM7 QSb/PVJ]vuJT#F} P"T9KNFoNF]bXkPcK\S\mPQ_],F '`W9GHJW9KaJQ_Y3I9PLGHY3c2f`KabFMJVY2JT#F}fi"P Z:YbG]\SKPP!I#Y3QSPVFPo[b/FKaJVF]bffJT9KI~a %v0JT9F}fi"PT9KNFPQ_]FQgI9GHbFKPQSI9[%e{XKZ.KGHJVYb!YZoxa fi)~{uFGHY3I9M7vI#YJVFLJT9KaJ JT#Fnb/KaJQ_YheF]J)jBF]FIJT9FnI{W9cffeF]b YZOI#YuM#FP0YZ9JT#FnJKab[F]Jd}fiovaKI9M-JT#FnI{W9cffemF]bYZ`\gQ_JVF]b/K\SP$: CfiiwcffffYZnJT#FJKab[F]J!} QgP{#YbffKcK +Yb/QSJXYZLG]\gKPPfiYb!KaJVJVb/Q_e`W#JVFI#Y3QSPVF\SF]NF\SP]vJT#F2bKaJQ_YemF]JjnF]FIJT#Fo}fi"PLeOW9Qg\SMKI9M%JT#Fo} PLeOW9Qg\_JBQSP{v#jUQSJTKfOKaJT9Y3\_Y[3QSGhG]KPVFoZYbx] KaJVJVbQ_eOW#JVFfiI#Y3QSPVFvuZ:YbjUT9QgG/TJT#Fffb/KaJQ_YQgP|{"T9FPVFbFcKab{P]v`K\_Y3I#[j Q_JTJT#FZ.KGHJhJT9KaJ"JT#F-} P"eOW9Qg\_JT9KNFKNF]bXbFKPVY3IOKaeO\_FPQ_]FLjUT#FIGHY3c2f`KabFM2JVYoJT9KaJ YZJT#FLJKab[F]JR} ZYbdKI(X-JX{fFKI9M2\SF]NF\uYZ`I#Y3QSPFvJVFI9MJVYiP/T#Yj Kl[Y{Y{MI#Y3QSPVFT9KI9M9\SQgI#[kZY1b p:f f`KabJZ:bY3c JT#FPFGHY3I9PQgM#F]b/KaJQ_Y3I9Pv0[3\SQgc2fOPVFPKaJoJT#F2} PfiY3W#JVfOW9Jhe{X -p:fhP/T#Yj JT9KaJfiF]NFIZ:Yb\SKab[F2I#Y3QgPVF2\_F]NF\SP]vQ_JocKIOKa[FPoJVYk^OI9MGHY3I9GHF]f9JPhPVXuIJKGHJQgG]K\S\_XG]\_Y3PVFJVYJT#FJKab[F]Jfi} O#YbhFH#Kc2fO\_Fv9Y3I9FYZJT#F!} PUY3W#JVfOW#JUKaffJG]\SKPPffI#Y3QSPVFQSPFH#KGHJ\_XJT#FJKab[F]J-} z K\SPVY#v Q_J!QSP!Y3I9\_X5Z:YbffG]\SKPPffI#Y3QSPV=F x~ p.KI9MKaJVJVb/QSeOW#JVFI#Y3QSPF x| nJT9KaJ PVY3c2F!} PZ:Y3W9I9MM9YI#YJUPVXuIJKGHJQgG]K\S\_XkQSI9G]\SW9M9F JT#F!JKab[F]J } KI(X{cYbF< ? >AaCD? >E FGHFI(JLKM#N8KIOGHFPRQSI2JT9FUPVJW9M#X-YZ7NYJQSI#[ffG]\SKPPQ_^`G]KaJQ_Y3IK\_[Yb/QSJT9cPdT9KNF eObY3W#[3T(JdFc2fOQ_bQSG]K\#KI9M"JT#F]YbF]JQgG]K\LbFPW9\_JPG]\_FKab\_XPT#YjUQSI#[JT#FM9QSP/GHb/QScQSIOKaJQ_Y3IfmYjnF]b2YZUFI9PFc!eO\SF%G]\SKP/PQ_^9F]b/P"T9QSPfOKafmF]bKM9M#bFP/PVFPnZbY3c K-JT#F]YbF]JQgG]K\7KI9M%Fc2fOQ_b/QgG]K\9fmY3QSI(JBYZNuQ_F]jJT#Fo{W#FPVJQ_Y3I%YZj T#F]JT#F]bLY3I#FcQ_[3T(JT9KNFJVYM9QSPVfmFI9PVFkjUQSJTQSIJVF]b/f9bF]JKaeOQS\gQ_JXQSIYb/M#F]bJVY F]F]fG]\SKPPQ_^`G]KaJQ_Y3IPVJVbFI9[JT71+IYb/M#F]bnJVYGHYfFhjUQ_JTJT9QSPRf9bYeO\_FclvjnFhT9KNFhGT#Y3PVFI%JVYPVJW9M#XK-G]\SKPPBYZGHY3I9GHF]f9JnbF]f9b/FPVFIJKaJQSY3I9PbFPVFcffeO\SQgI#[c-W9\_JQS\gQSI#FKabUM9QgPGHb/QScQgI9KIJUfY3\SX{I#Y3cQSK\SP]vOKM9F(W9KaJVF2Z:YbocQSI9QgI#[QSPP/W#FPUj T#FIiM9FK\SQSI#[jUQ_JT5NYJQgI#[lf9bYuGHFM9W#b/FP]v7jUT9QSGT5jBFM#F]^OI#F2KP}hFG]QSPQSY3I Y3ccQSJVJVF]FP]%fiW#boJT9F]YbF]JQSG]K\bFP/W9\_JPPT#Yj1JTOKaJnPVJVbQ_N{QgI#[oZYbLPQScfO\SQSG]Q_J)X-QgP]v(\SQ FUZ:YbncKI(X2YJT#F]bG]\SKPPFPRYZGHY3I9GHF]fOJBbF]fObFPVFI(JKaJQ_Y3I9P]v#KT9Kab/MffGHY3c2fOW#JKaJQSY3I9K\3f9b/YeO\_FctjUT9FI!M#FK\SQgI#[jUQ_JT} Yb0YJT9F]b GHY3c2f`\_FHoNYJQSI#[UfObY{GHFMOW#bFP]vaKI9Mf9bYNFPhJT#F-T9FW#b/QSPVJQgGoI9KaJW#bFffYZdYJT#F]bhbFPW9\_JPUJVbXuQSI#[JVY%f9b/WOI#FKM9Kaf9JQ_NF-emY(Y3PJQSI#[#""T9QgP"fOKafmF]bf9bYfmY3PVFP!JVYKMOKaf9J-Kif9bF]NuQ_Y3W9PffPG/T9Fc2FJVYeOW9Qg\SM5jBFK \_FKab/I#F]b/Pv P/W9G]GHFPPVZ.W9\dZ:Yb-JT#FQSIOM9W9GHJQ_Y3IYZ"M#FG]QSP/Q_Y3IJVbF]FP-KI9MM#FG]QSPQSY3I\SQSPVJPv0JVYiJT#F%G]KPFYZ"} "T9QSPQgP!KIYb/Q_[3QSI9K\RKaf9f9bY3KGTQSZBjnFbF]Z:F]bJVYJT#FoPVJKaJVF fiDYZ fiDJT#F fiKabJfiK\_[Yb/Q_JTOcPLeOW9QS\gM9QSI#[GHY3c2f`\_FH%NYJVFPUf9bYuGHFM9W#bFPv{W9P/W9K\S\_XjnYb uQSI#[QSIiJT#FPVJVbY3I#[k\_FKab/I9QgI#[Z:b/Kc2F]jnYb `fiW#bfiK\_[Yb/QSJT9cv !vbF\SQSFP"Y3IbFGHFI(JPfiYbfiI9F]j bFP/W9\_JPKaemY3W#J fOKabJQ_JQSY3I!emY{Y3PVJQSI#[#vb/KI {QSI9[ \_Y3PP emY{Y3PVJQSI#[#v3KI9M-f9bW9I9QSI#[#)JGHY3c2FPj Q_JT!J)jB,'`KNYb/P]v(Y3I#FjUQ_JT5YfOJQScQSPVJQgGfffOb/W9I9QSI9[%KI9M5Y3I9FjUQ_JT5fmFPPQgcQSPVJQSGfff9b/WOI9QSI#[#qnYJTYe9JKQSI9FMFH{fmF]b/Qgc2FIJK\g\_X[Y{Y{M1bFPW9\SJPY3IJT9FPQgc2fO\SQSG]QSJX fiKG]G]W#b/KGHXJVb/KM#F]Y * v"eOW#Jj T#F]bFKPYf9JQScQSPJQSGkf9b/W9IOQSI#[G]\_FKab/\SXY3W#JVfmF]bZ:Yb/cP YJT#F]bK\_[Yb/QSJT9cPhQSIJT9F\gQ_[3TJ YZRJT#FPQ_]F-YZRJT9F-Z:Yb/c-W9\SKP Ye9JKQSI#FMvfmFPP/QScQSPVJQgGf9b/WOI9QSI#[hJVFI9M9P JVY!KGT9Q_F]NFhKc2YbFbFKPY3I9KaeO\_FJVb/KM9F]Y * v{jUQ_JT2T9QS[3T2KG]G]W#b/KG]Q_FPRYe9JKQSI#FMY3IP/cK\S\Z:Yb/cffWO\SKP]L"T9QSP"QgP"K\S\7JT#F-c2YbF-QSIJVF]b/FPVJQSI#[KP fmFPPQScQgPVJQSGhf9b/W9IOQSI#[QSP"eOKPFMlY3IKI9KaJW#b/K\0KI9MPQScfO\_Fhf9b/W9I9QgI#[fffObY{GHFMOW#bF<> ? @ O>"T9KI {PhKabFM9W#F!JVYk}fi} KabJQSIOQS(W9Fv 8 n } p dJKaeO\SQgPPVFc2FI(JhKaJQ_Y3I9K\ M9 RIOPVFQ_[3I#Fc2FI(JuW#f F] bQ_FW#b [bY3I9Y3cQS{W#FhM9Fh}fiQ VY3I`RKI9M QSPVF FKI!fi Y3W9QSPnZ:YbLTOKNuQSI#[-f9bYNuQSM#FMJT#FoKa[b/QSG]WO\_JW#b/K\M9KaJKuv0ZYb!PJQScffWO\SKaJQSI#[kM9QSPG]WOPPQ_Y3I9PhKabY3W9IOM5Y3W#bbFPWO\_JP]vKI9M5Z:Yb!T9KN{QSI9[kKW9JT#Yb/Q_]FMJT9F2fOW#eO\SQ fiG]KaJQ_Y3IYZ PVY3c2F!YZ0JT#Fob/FPW9\_JPLYe9JKQgI#FM7"T9K(I uPLJVY T9c2FM QSI#Y3W9GT#FoZ:Yb"T9KNuQSI#[2fmY3QSI(JVFMkY3W#JJT#FUQgIJVF]bFPJBQSI2cQgI9QScQ_QgI#[hP/W#eOc2YuM9W9\SKab Z.W9I9GHJQ_Y3IOP] QSIOK\S\_XvJT#FhKW#JT#YbdjUQgPT#FPJVYffJT9K(I FM#bY}hY3cQSI#[Y3PUKI9MJT#Fb/F]N{Q_F]jnF]b/PZ:Yb"JT#FQSbN8K\SWOKaeO\_FoPW#[[FPVJQSY3I9P]:$fi`>@RCk36)N6)" 5"Z>cuQSIOGHF JT#FoT9KabM9I#FPPBbFPW9\SJPBYZ "T#F]YbFcPhxfiKI9M-KabFoPVJKaJVFMZ:YbJT#FfiJjnYfiG]\SKPPFP"G]KPVFv#jnFPT9K\S\9W PVFfiJT#FoI#YJKaJQSY3I , 1 % , 1 - x / 7 , 1 - /mZ:Yb"PVY3c2FoKabe`Q_JVb/KabXbW9\_F-p , 1 ( , 1 v#jUT9F]bF , 1 - /QSPnJT#FNaK\SW#FZ:Yb-G]\gKPPff fi KI9M , 1 - x /QSPoJT#F%N8K\gW#FZ:YbffG]\SKPP ff u fmY3PQSJQ_NFNaK\SW#FZ:Yb , 1 cFKI9PJT9Ka(J , 1 QSPfiQSIZ.KNYbYZnG]\SKPP)ff kjUT9F]bFKPfiKI#F][3KaJQ_NF2NaK\SW#F-[3Q_NFPK , 1 QSIZ:KNYbYZBG]\gKPP)ff fi udK\SW#FhZ:Yb , 1 [3Q_NFPB5K , 1 I9FW#JVb/K\9j Q_JT2bFPVfmFGHJBJVYffJT#FhG]\SKPPVFP FhW9PFUK!b/FM9W9GHJQ_Y3I2Z:bY3c JT#Ffi " KabMf9bYeO\SFc ff QSIOQScffWOc YNF]b ip KabF]X r Y3T9I9PVY3I7v7xy3ay3<6> " ff QSI9QSc-W9c YNF]bufi " . 7r'"(" GHY3\S\_FGHJQ_Y3IYZ0PW9eOPVF]JPBYZK!^`I9Q_JVF PF]J>n fY3P/Q_JQ_NF QgIJVF][F]bvfi3 " .d7 '" R}hY(FPff GHY3I(JKQSIKGHYNF]b YZPQS]FKaJUc2Y3PVJfiv#JT9KaJhQSP]v#KPW9eOPVF]JG G v9PW9G/TlJT9KaJUKI(X%F\SFc2FIJUYZ >emF\_Y3I9[3PJVYKaJU\_FKPJ"Y3I#Fc2FcffemF]b"YZfi|GGjUQ_JT"T9Fhb/FM9W9GHJQ_Y3IQSPLGHY3I9PJVb/W9GHJVFMlKPZ:Y3\S\_YjUP Zb/Y3c K ff QSIOQScffWOc YNF]bQgI9PVJKI9GHFfijnFoeOW9QS\SM%K\_FKab/IOQSI#[ffP/Kc2fO\_F.=?>P/W9G/T%JT9KaJ"Q_ZJT#F]bFfiFHuQgPVJPKGHYNF]bUYZ PQ_]FG G YZ >Lv{JT9FIkJT#F]bFfiFHuQgPVJPKM#FG]QgPQ_Y3IGHY3ccQSJVJVF]FjUQ_JT G Gu\gQ_JVF]b/K\SPLGHY3I9PQgPVJVFIJUjUQ_JT =?>Lv9KI9M7v#bFG]Q_fObY{G]K\g\_Xv#Q_Z0JT9F]bFoFHuQgPVJPKM9FG]QSPQ_Y3IGHY3ccQ_JVJVF]Fffj Q_JT \SQSJVF]b/K\SP"GHY3I9P/QSPVJVFI(J"jUQ_JT =A>nvOJT9FIJT#F]bFffFHuQSPJPUKGHYNF]bhYZdP/Q_]FYHZ >n "UFIOGHFv ^`I9M9QSI#[kJT#FPcK\S\_FPJM#FG]QSPQ_Y3IGHY3ccQ_JVJVF]FkGHY3I9PQSPJVFIJj Q_J=?> QSPoF{W9Q_NaK\_FI(JJVY^OI9MOQSI#[JT9FP/cK\S\_FPVffJ ZYbojUTOQSG/TJT#F]bFFH#QSPVJPoKPVY3\gW#JQ_Y3IiJVY ff QSIOQScffWOc YNF]b uvKIOM5JT9QSPfiQSPQSI(JVb/KGHJKaeO\_FQSZ % 0 2F]J !"M9FI#YJVF5JT#FF\_Fc2FI(JkYZ 2v KI9M "JT#FF\_Fc2FI(JkY1Z >n FM#F]^OI#F5KPVF]JZ GG"qnY(Y3\_FKI NaKab/QSKaeO\_FPiQSI Y3I9FJVYY3I#FGHYbb/FPVfmY3I9M#FI9GHFj Q_JT JT#FF\_Fc2FI(JPYZ 2vjUT9QgG/TjnFWOPVFJVYtM#FP/GHb/Q_emFJT#FFH#Kc2fO\_FPiY#Z =A>n "T#FGHYbbFPVfmY3I9M9QgI#[ PVF]J5YZ\SQSJVF]b/K\SPQSPiM9FI#YJVFM0 ( ( ( ( . ( . (5464646( ( M93R"T9FfiP/Kc2fO\_F =?>GHY3I(JKQSI9P"JjnYM9QSP VY3QSI(JnPW9eOPVF]JP JT#FPVF]JYZ fmY3PQ fiJQ_NFhFHuKcfO\_F?P =?> v#KI9MJT#FhPF]JBYZI9F][3KaJQ_NFfiY3I#FAP =?> <=?> GHY3IJKQgI9@P GL> GFH#Kc2fO\SFP]v{M9FI#YJVFMe{X $ ( (P$ . (5464646(P$ 4 FGHY3I9PVJVb/W9GHJoFKGTfmY3PQ_JQ_NF-FH#Kc2fO\_FPVYkJT9KaJQ_JhFI9GHYuM#FPfiJT#F2c2FcffeF]bPT9Q_fYZ JT#FGHYbbFPfY3IOM9QSI#[-F\_Fc2FI(J"YZ >QSIkJT#F!F\_Fc2FI(JPYZ YbFf9bFG]QgPVF\_XvxGL> GM(P$%"#"$ 6"#"$ 4" !7 ' :"% !'&7 ' :=A> GHY3IJKQSIOPUKPQgI#[3\_FoI#F][3KaJQ_NFFH#Kc2fO\SFvOM#F]^OI#FMke{X"$ %" 4" (fi uW#f9fmY3PVF JT#F]bFhFHuQgPVJPKGHYNF]b( Z >PKaJQSPZXuQSI#[ G Gpwy3p+x]FGHbFKaJVFKM#FG]QSPQSY3IGHY3ccQ_JVJVF]FGHY3I9PQgPVJQSI#[ffYZcY3I#Y3cQSK\SPvFKG/TljUQ_JTY3I#Fo\SQ_JVF]b/K\OY3I9\_XKI9MkKPPY{G]QSKaJVFM%JVY2K-fmY3PQ_JQ_NF k RKGTc2Y3I#Y3cQSK\dGHYuM#FP!Y3I9FYZJT#FPF]JP!QSI"T9FM#F]Z.KW9\_J!G]\SKP/P!QSP ff fi ulUT9QSPM#FG]QgPQ_Y3IGHY3ccQ_JVJVF]F*)QSP GHY3I9PQSPVJVFI(JUj Q_JTlJT#FffFHuKcfO\_FP"YZ<=A>+ =A> vOYJT#F]b/jUQSPVF!PY3c2FffF\SFc2FIJ YZ >jnY3W9\SMI#YJ emFGHYNF]b/FM7dZJT9F]bF KabF Y3I9\_XJjnY-N8K\SW9FPRKW#JT#YbQ_]FMZ:YbRJT#F NFGHJVYb/PLKI9MJT9F]XKab/F uv{jBFhPQSc2f`\_XGHbFKaJVFK} GHY3I9PQSPVJQgI#[YZnY3I#Fc2Y3I9Y3cQSK\ jUQ_JTI9F][3KaJQ_NF\SQ_JVF]bK\SPfiKPPVYuG]QSKaJVFMJVYKI#F][3KaJQSNF$: 2=fiiwcffffc2Y3I9Y3cQSK\>/hQ_[3W#bF &n"T#FoPQ kfmY3PPQ_eO\SFhG]KPVFPUYZ b/W9\_FP]p:JT#F2NaK\SW#F-ZYboJT9FI#F][3KaJQ_NFG]\SKPPoQgP [b/FKaJVF]bJT9KI5JT#F2Y3I#FYZBJT#F2fmY3PQ_JQ_NFG]\SKPPzFKG/TYZnJT#FI#F][3KaJQ_NF-\SQ_JVF]b/K\gPnGHYuM#FPUY3I#FoYZ JT#F!PVF]JP"QgI R"T#FM#F]Z.KW9\_JG]\SKP/P"QSP ff ufi uW#f9fmY3PVF!I9Yj JT9KaJhJT#F]bF-FHuQSPJPhK%M#FG]QSP/Q_Y3IGHY3ccQ_JVJVF]F jUQ_JTKaJfic2Y3PVJ \SQSJVF]b/K\SPhGHY3I9PQSPVJVFI(JjUQ_JT =A>nd}hFI#YJV5F ( ( . (5464646( # uFKG/Tic2Y3I#Y3cQSK\YZ v#QSIkI#YPVfmFG]Q_^OG Yb/M#F]bv#KI9( ( . (5464646(JT#FQ_bhKPPVYuG]QSKaJVFMN8K\gW#FPUZ:Y)b kU"T#F-c2Y3I#Y3cQgK\SP"YZ G]KIiemF\_Y3I9[JVY%JT#bF]F!J)X(fmFPhYZdPW#e`PVF]JPUYZc2Y3I#Y3cQSK\SPfi cY3I#YJVY3I#Y3W9P c2Y3I#Y3cQSK\gPp:jUQ_JT#Y3W#J"I9F][3KaJQ_NF!\SQ_JVF]bK\SPvfi cY3I#Y3cQSK\SPGHY3I(JKQSI9QgI#[2Y3I9\_XkI#F][3KaJQ_NF!\gQ_JVF]b/K\SP]vfi cY3I#Y3cQSK\SPGHY3I(JKQSI9QgI#[2fmY3PQ_JQ_NFKI9MI9F][3KaJQ_NFff\SQSJVF]b/K\SP]F]JW9PoG]K\S\ bFPVfmFGHJQ_NF\_X vv JT9FPVFJT#bF]FG]\SKPPFP]_Q NFI5JT9KaJoFKG/Tc2Y3I#Y3cQgK\0YZG]KI5eF2KPPY{G]QSKaJVFM5JVYlK%fmY3PQ_JQSNFffYbKI#F][3KaJQSNF kv7JT#F]bFFH#QSPVJPfiY3IJT#F2jUT#Y3\SF-PQ_iG]\SKPPVFPfiYZb/W9\SFP]vuf9bFPVFI(JVFMQSI Q_[3W9bF {IXc2Y3I#Y3cQgK\ YZ GHY3I(JKQSI9QgI#[KaJk\SFKPVJY3I#F5fmY3PQ_JQ_NF5\SQ_JVF]b/K\hG]KItY3I9\SXemFPKaJQgPV^9FMe(XfmY3PQ_JQ_NFLFH#Kc2fO\_FP UT#F]bF]Z:YbFv(Q_Z`JT#F]bF"FH#QSPVJPdb/W9\_FP emF\_Y3I#[3QgI#[fiJVY!G]\SKPP/0Yb hv3jBF G]KI2bFc2YNFJT#Fc jUQSJT#Y3W#J \_Y3PQSI#[fiGHY3I9PQgPVJVFI9GHX9W#bJT9F]b/c2YbFvP/QSI9GHF $ GHY3IJKQgI9P Y3I9\_X-I#F][3KaJQ_NF"\SQ_JVF]bK\SP]vQ_Z9jnFbFc2YNFffJT9FQ_b I#F][3KaJQSNFff\SQ_JVF]bK\SPZ:bY3c K\S\b/W9\_FP"eF\SY3I#[3QSI#[2JVY%G]\SKPP p.cK {QSI9[JT#Fc [YJVYG]\gKPPv{jnFoM#Y2I#YJ\_Y3PVFfiGHY3I9PQSPJVFI9GHX PK-GHY3IOPVF(W9FI9GHFv#jBFoG]KIPW9f9fmY3PVFUjUQSJT#Y3W#JL\_Y3PPnYZ[FI#F]bK\SQ_JXJT9KaJUK\g\mb/W9\_FPLYZ KabF!QSIG]\gKPPv9vuYb" -FI#Yj JVbFKaJoQSI9M#F]fmFI9M#FI(J\_X%JjnYlG]KPVFP]vM#F]fmFI9MOQSI#[Y3IjUT#F]JT9F]b JT#F2M#F]Z.KW9\_JhG]\SKPPhYZ QSPff 2Yb ff fi uxaUUT#FM#F]Z.KW9\_J-G]\SKPP-QSP ff fi u IXfmY3PQ_JQSNFFH#Kc2fO\_F%PKaJQSPV^9FPffJT#F]bF]Z:YbF%Kic2Y3I9Y3cQSK\RQgIUT#F]bF2G]KIFH#QSPVJfiJjnYlJX{fmFPfiYZBfmY3PQSJQ_NFffFH#Kc2fO\SFP JT9Y3PVFPKaJQSPVZ:XuQSI#[kKaJ\_FKPVJoY3I#F2b/WO\_FffYZG]\gKPPv9KI9MJT#Y3PVFI9YJUPKaJQSPVZ:XuQSI#[KIXG]\SKPP"Rb/W9\SF2p:JT9F]bF]ZYb/F!PKaJQSPVZ:XuQSI#[2KaJU\_FKPVJY3I9Fob/W9\_FYZG]\SKP/P $ PKaJQSP^9FP"K\S\7G]\SKP/PnKI9M b/WO\_FP]d"T#F]b/F]ZYbFv,= 1 7,4G]\gKPPG]\SKP/PE4p+xx1UT9QSPRP/T#YjUPBJT9KaJ]vuQ_Z7K!fmY3PQSJQ_NF"FH#Kc2fO\_FhI#YJBPKaJQgPVZXuQSI#[ffKIXG]\gKPPRbW9\_FPjnY3W9\SMPKaJQSPVZ:XK\S\G]\gKPPh b/WO\_FP]vOJT9FIQSJUjnY3W9\SMlemF-cQSPG]\SKP/PQ_^9FM7vOjUT9QSGTiQSP QSc2fmY3PPQSeO\_Foe{XJT#F-GHY3IOPQSPVJVFI9GHXT(X{fYJT9FPQSP]RUT9QSPL[3Q_NFP KIQSc2fmYbJKI(Jf9bYfmF]bJ)XvOI9Kc2F\SXJT9KaJ KIXkfmY3PQ_JQ_NFoFH#Kc2fO\SF!I#YJ$: $fiP/KaJQSPVZ:X{QSI9[ffKI(XG]\SKPPndb/WO\_F G]KI9I9YJLP/KaJQSPVZ:XK\S\`G]\gKPPn bW9\_FP] F]JLW9PLG]K\S\<k JT9QSPBf9bYfmF]bJ)XQgIjUTOKaJ!Z:Y3\S\_Yj P] FkI#Yj PT9Yj T#Yj JVY5eOW9QS\gMKNaK\SQSMPVY3\SW#JQ_Y3IJVY ff QSIOQScffWOc YNF]b<j Q_JTKaJUc2Y3PVJ kF\_Fc2FI(JP]R#YbhKIXkfmY3PQ_JQSNFhFH#Kc2fO\SF $ vfi QSZ $ PKaJQSPV^9FPfiKaJo\_FKPVJfiY3I#F2G]\SKP/P Ub/W9\_FvmG/T#Y{Y3PVFQSIK PW#eOPVF]JhYZA>1GHYbb/FPVfmY3I9M9QSI#[kJVYK2fmY3PQ_JQ_NF\SQSJVF]b/K\YZ PY3c2F!PKaJQSP^9FMG]\SKPPnb/W9\SFd"T9QSPLPW#e`PVF]J"GHY3IJKQgI9P$fi QSZH$ M#Y(FPI#YJPKaJQSPZXKI(XG]\gKPP-b/W9\_Fv JT#F]b/FFH#QSPVJP-Z:bY3c k PY3c2FG]\SKPP- b/W9\_Fj T9QSG/TkQSPI9YJ"PKaJQSPV^9FM c2Y3I#[K\g\I9F][3KaJQ_NF!\SQ_JVF]bK\SPnYZ0K2G]\SKPPL b/W9\_FhjUT9QSGTkQSPI#YJP/KaJQSPV^9FMie(X$ vGT#Y(Y3PFffY3I#FffjUT9QSGTQSPUfmY3PQ_JQ_NF!Qg$ p.G]KW9PQSI#[%Q_J I9YJUJVYkPKaJQSPVZ:XJT#FbW9\_FvKI9MJT9FI2G/T#Y{Y3PVF"JT#F"GHYb/bFPVfmY3I9M9QSI9[ F\_FcFIJYZ "T9QgP P/W#eOPVF]J YZ >5GHY3IJKQgI9P$JVF]b/KaJQSI9[%JT9FKaeYNF2f9bYuGHFM9W#bF-Z:YbK\S\fmY3PQSJQ_NFffFH#Kc2fO\SFP]v7jBF2YeOJKQSI5K%GHYNF]b!YZ>GHY3I!fiP/QSPVJQSI#[YZKaJUc2Y3PJ PW#eOPF]JPYZ >L~{UUT#FM#F]Z.KW9\_J"G]\SKPPUQSP ff u?$ PKaJQSPV^9FPUK\S\7G]\SKPP/BKI9Ml b/W9\_FPd"T#F]bF]Z:YbFv,= 1 7,4G]\gKPPG]\SKP/PE4p+x~31RNFI5Q_ZJT#F2QSI#F{W9K\SQ_J)XQSP I9YjPVJVb/QSGHJ]v7Q_J [3Q_NFPfiJT#FPKc2F-f9bYuGHFM9W#bFffZYbfiFG]QSFIJ\_XeOW9QS\SMfiQgI#[JT#FkPVY3\SW9JQ_Y3IJVY ff QSI9QSc-W9c YNF]bjUQSJTKaJc2Y3PVJ F\_Fc2FI(JP]ve(XW9PQSI#[JT#FPKc2FKab/[3W9c2FI(JUKPUQSIkJT9Fof9bFGHF]FM9QSI9[G]KPVF"TOQSPLFI9M9PLJT#F!f9bY{YZYZ"T#F]YbFc xak36)N6)" 5"Z>cFoW9PVFfiK-bFM9W9GHJQ_Y3IZ:bY3cJT9F fi "hKab/M%f9bYeO\SFcff~ fifi Y3\SYb/KaeOQS\SQSJX kp FKab/I9PnF]JK\w_v7xy3<6> " ff~ fi fi Y3\_Yb/KaeOQS\gQ_JX ufi " . 7r'"(" ^OI9Q_JVF%PVF]J> % 0 ( ( . (5464646( 4 9kKIOMKGHY3\S\_FGHJQ_Y3IYZUGHY3I9PJVb/KQSI(JPffYNF]b#>nv% 0 ! ( (*! . (5464646(*! 93vOPW9GTJT9KaJ ^m/0x3(/~)(5464646(RGG 9 (*! >nfi3 " .d7 '" R}hY(FPJT9F]bFFH#QSPVJ"K~ fi fi Y3\SYb/KaJQ_Y3IlYZ JT#FoF\SFc2FIJP"YZ<>Lv J 1.21BKZ:WOI9GHJQ_Y3I)> 0 x3/( ~ 29 PW9GTJT9KaJfi|pm/0x3(/~)(5464646(RGG 98(p ( 1 m! p%0p 1"T9F"bFM9W9GHJQSY3IQSPRGHY3IOPVJVb/W9GHJVFM%KPdZ:Y3\S\_YjUP Zb/Y3c K ff~ fi fi Y3\_Yb/KaeOQg\SQ_JX !QgI9PVJKI9GHFv(jBF eOW9QS\SMK \SFKab/I9QSI#[P/Kc2fO\_F =A>PWOG/TJTOKaJBQ_ZJT#F]bF FHuQSPJPRKff~ fi fi Y3\_Yb/KaJQ_Y3IYZ7JT#F"F\SFc2FIJPBYZ >nv(JT#FI!JT#F]bFFHuQgPVJP!KiM#FG]QSPQ_Y3IGHY3ccQ_JVJVF]FjUQ_JTJ)jBYib/W9\_FP!GHY3I9PQSPVJVFI(J!j Q_JT=?>Lv KIOM7vbFG]QSf9bYuG]K\S\_Xv0QSZJT#F]bF!FHuQSPJP"KM#FG]QSP/Q_Y3IlGHY3ccQSJVJVF]FjUQ_JTJ)jBYb/W9\_FPGHY3IOPQSPVJVFI(J"jUQ_J=?>nv#JT#FIJT#F]bFFH#QSPVJPUK~ fifi Y3\SYb/KaJQ_Y3IYZ JT#FoF\_Fc2FI(JPY<Z >nR9W9bJT#F]b/c2Yb/Fv#JT#F]bFI#F]NF]b"FH#QSPVJPK2M9FG]QSPQ_Y3IGHY3ccQ_JVJVF]FjUQ_JTY3I9\_XfiY3I#Fdb/WO\_FdGHY3I9PQSPJVFIJ0jUQ_J@=A>n " FI9GHFv^OI9MOQSI#[LJT#FRM#FG]QgPQ_Y3IGHY3ccQ_JVJVF]FBj Q_JToJT#FRP/cK\S\ fiFPVJhI(W9cffemF]bUYZb/WO\_FPUGHY3I9P/QSPVJVFI(JUjUQ_J=?>QSPUKaJfi\_FKPVJhKPhTOKab/MlKPfiPVY3\_NuQSI#[ ff~ fi fi Y3\_Yb/KaeOQS\gQ_JX uvKI9MJTOQSPQSPQSI(JVb/KGHJKaeO\_FffQ_Z % 0 2:BCQfiiwcffffF]J !"M9FI#YJVF5JT#FF\_Fc2FI(JkYZ2v KI9M "JT#FF\_Fc2FI(JkYZ1>n FM#F]^OI#F5KPVF]JYZ/GL>HG"qnY{Y3\_FKI N8KabQSKaeO\_FPQSI Y3I#FJVYY3I9FGHYb/bFPVfmY3I9M#FI9GHFjUQ_JT JT#FF\_Fc2FI(JPYZ >nv-jUT9QgG/TjnFWOPVFJVYtM#FP/GHb/Q_emFJT#FFH#Kc2fO\_FPiYZ#=A>n "T#FGHYbbFPVfmY3I9M9QgI#[ PVF]J5YZ\SQSJVF]b/K\SPQSPiM9FI#YJVFM0 ( ( ( ( . ( . (5464646( 4 ( 4 93 oW#bbFM9W9GHJQSY3ItQSPcKM#FQSIJT#FJ)jBYfiG]\gKPPVFPlZ:b/Kc2F]jnYb "T#FPKc2f`\_.F =?>GHY3I(JKQSI9PJ)jBY%M9QSP VY3QSI(JnP/W#eOPVF]JP dJT9FPVF]J"YZ fY3P/Q_JQ_NFfiFHuKcfO\_FP =?> Rv`KI9MkJT#FPVF]J"YZI#F][3KaJQ_NFY3I#F@P =?>=A>1GHY3IJKQSIOP GL> G`FH#Kc2fO\_FPvM#FI#YJVFMe{X $ ( (P$ . (5464646(P$ 4 FGHY3I9PJVb/W9GHJFKG/TifmY3PQ_JQ_NFfiFH#Kc2fO\_FPYJT9KaJUQ_JLbF]fObFPVFI(JPUKIF\_FcFIJ"Y<Z >n YbFfObFG]QSPVF\_Xv" 4p+x3" ( " &A= > GHY3I(JKQSI9PGGdFH#Kc2fO\_FP]v M#FI#YJVFMe{XF$ ( (P$ . (5464646(P$ F5GHY3IOPVJVb/W9GHJ%FKG/T I9F][3KaJQ_NFxGL> GM(P$%6" 4FH#Kc2fO\_FPVYJT9KaJUQ_JFI9GHYuM#FPFKGTlYZ JT#F!GHY3IOPVJVb/KQSI(JPYZYbFf9b/FG]QSPVF\_XxGGM(P$%#"%"$ 6#""$ 4" : 7 '"% : 7& 'p+x +(Q_JT#Y3W#J\SY3PP7YZ{[FI#F]b/K\SQ_J)XvjnFRcKFRZY3W#b0KPPW9c2fOJQ_Y3I9PY3IJT#FdQgI9PVJKI9GHFYZ ff~ fi fi Y3\_YbKaeOQS\SQ_J)X&M9W#FoJVYJT#FoZ:KGHJ JT9KaJUQ_J"QgPI#YJ"JVb/Q_NuQSK\xaUUT#F]bF M9Y(FPnI#YJnFHuQSPJBPVY3c2F F\_Fc2FI(JBYZ >f9b/FPVFIJnQSIK\g\OGHY3I9PVJVbKQSIJPIJT9QSPBG]KPVFhQgI9M#F]FM7vJT9FJVb/Q_NuQSK\LGHY3\_Yb/KaJQ_Y3IGHY3IOPQSPVJP2QSI[3QSN{QSI9[JVYY3I9FYZhPWOG/TF\_FcFIJP2Y3I9FlGHY3\_YbvLKI9MJT#FYJT9F]b GHY3\_Yb"JVYK\S\7YJT#F]b"F\SFc2FIJPUYZ >n~{p'*(ffJ( 8( D8 Cm/0x3(/~)(5464646(RGL> G 9 jUQ_JT % 0KI9M % 0 8v& m0x3(/~)(5464646(RGG 9 (,0 ( "390 !,+ 6 0 ( 1 9-0 !,+4p+x23fiJT#F]bjUQSPFQgI9M#F]FM7vJT9F]bF2jBY3WO\SM5FHuQgPVJp'*(ff( 8( 8w:m 0x3(/~)(5464646(RGL>HG 9 j Q_JT % 0KI9M % 0 8P/W9G/TJTOKaJx (/)~ (5464646(RGG 9 (,0 ( "39 !,+ 0 ( 1 9 !,+(p+x|3& m03KIOMlQSIJT9KaJ G]KPVFv`K2JVbQ_N{QgK\7PVY3\SW#JQ_Y3IkJVY ff~ fi fi Y3\_YbKaeOQS\SQ_J)X& jBY3W9\gMGHY3I9PQSPVJ"QgI[3Q_NuQSI#[JVYY3I#F!GHY3\_YbhKI9MkJVY " JT#FoYJT#F]b Y3I#FvOKI9MlJVY Y3I#F!GHY3\_YbhKI9MkJVY 1 JT#FYJT9F]bUY3I#F{ B KG/TF\_FcFIJ%YZ"> eF\SY3I#[3PJVYKaJk\_FKPVJ%Y3I#FGHY3IOPVJVb/KQSI(J%QgI hJT#F]bj QSPVFv"Q_J%G]KI1emFb/Fc2YNFM7+# BKG/TlGHY3IOPVJVb/KQSI(J"GHY3IJKQgI9PKaJ"\_FKPVJJ)jBY2F\_FcFIJPZ:bY3c>nBfiJT#F]bjUQSPFhQ_JG]KIkemFfibFc2YNFM7fi uW9f9fmY3PVFJT9F]bFFHuQgPVJPKPVY3\gW#JQ_Y3IJVY ff~ fi fi Y3\_Yb/KaeOQS\gQ_JX u FeOWOQS\SMJT#F} j Q_JTJjnYc Y3I#Y3cQSK\SPnYZLp FKab/I9PF]J"K\w_vxy3"GHY3I9PQSPJVFIJjUQSJTJT9FoFHuKc2f`\_FP]d"T#FIv{jnFoeOW9Qg\SMJ)jBYbW9\_FP2e{XiKPPVYuG]QSKaJQSI9[%JT9F-J)jBYic2Y3I#Y3cQSK\gP JVYlPY3c2Flp.KabeOQ_JVb/Kab/X#UfmY3PQ_JQ_NF-NaK\SW#FffUT#F2M#F]Z:KWO\_JhG]\gKPPoQSPff fi uBUT9QSPL\_FKM9PJVYKM#FG]QSPQSY3IGHY3ccQ_JVJVF]Fj Q_JTJjnYb/WO\_FPGHY3I9PQSPJVFIJ"j Q_JT =?>nfi uW9f9fmY3PVFfiJT9KaJUJT#F]b/FFHuQgPVJPUKM9FG]QSPQ_Y3IGHY3ccQ_JVJVF]F 5j Q_JTKaJ c2Y3PJ"JjnYb/WO\_FP"GHY3I9PQgPVJVFIJUjUQ_JT=?>LFI#Yj PT#Yj JT9KaJ2JT#F]bFkFH#QSPVJP2K5NaK\SQSM~ fi fi Y3\_Yb/KaJQSY3IYZUJT9F%F\SFc2FIJPYZ >n F^9b/PJP/T#Yj JT#b/F]Fl\_FccKPjUTOQSG/TPT9K\g\BemFW9PVFM\gKaJVF]bY3I7"T#FI7vdjnFlPT#Yj JT9KaJJT#FM#FG]QgPQ_Y3IGHY3ccQSJVJVF]F%QSP!KGHJW9K\S\_XF{W9Q_NaK\_FI(JJVYiKi} h j Q_JTJjnY5c2Y3I#Y3cQSK\gPGHY3I9PQSPJVFIJffjUQ_J=A>n FGHY3I9G]\SWOM#FUe{XW9PQSI9[!f9bF]NuQ_Y3W9PRbFPW9\SJP p FKab/IOPRF]JK\w_vmxy3BY3IT9YjJVYffJVbKI9PVZ:Yb/c JTOQSPR} hQSI(JVYK2NaK\SQSM~ fi fi Y3\SYb/KaJQ_Y3IiYZ0JT#F!F\_Fc2FI(JP"Y<Z >n:BC6:fip N "RT fTgJ"! J %( % " J %8a WV " (%KJ J Wi f"! ]fi J H J "fJ(% " ! "% X 3 " J !wJ H "! %j]fi J J % J "! "fJ 6J 3 "! !%KJ J !\J ] "! % !" 4B "F> >""4(p RbY(YZ PVJVb/KQS[3TJVZ:YbjLKab/M`B "F> >jV "! !%KJ J aji "fT! %K]J J %.61p:+I9M#F]FM7v Z:Yb-KI(XN8KabQSKaeO\_Fv JT#F]bFFHuQSPJJjnYifmY3PQSJQ_NFFH#Kc2fO\_FP-T9KNuQSI#[JT#FGHYbb/FPVfmY3I9M9QSI#[fmY3PQ_JQ_NFo\SQSJVF]b/K\wv#KI9MJT#FffGHYbbFPVfmY3I9M9QgI#[-I9F][3KaJQ_NFff\SQSJVF]b/K\pN R" fTgJ"! J %% " J 8%B "F> > "fJ(% Wi "6 ! X $ ! % 1k36)jl uW#f9fmY3PVF%JT9KaJ GHY3IJKQgI9PY3I#Fb/W9\SFvjUT#Y3PVFc2Y3I#Y3cQSK\LQSP2G]K\S\_FM ( Z"JT#FlM#F]Z.KW9\_JG]\SKPPnQSP ff fi uvuK\g\#fmY3PQ_JQ_NF"FH#Kc2fO\SFPBPKaJQgPVZX ( v(jUTOQSG/TQSPdQSc2fmY3PP/Q_eO\_FLe{X FccK +( JT#F c2Y3I9Y3cQSK\jnY3W9\SMemFFc2fOJXv KI9M GHY3WO\SMI#YJemFGHY3IOPQSPVJVFI(J]k)ZLJT#FM9F]Z:KW9\SJG]\SKPP!QgP ff uv JT#FI9F][3KaJQ_NFFH#Kc2fO\_FPhKabFffG]\gKPPQ_^9FMe(X ( KIOMlJT#F]bF]Z:YbF ( uh"T{W9P]vOI#Y%fmY3PQ_JQ_NF!FHuKc2f`\_FffPKaJQgPV^9FP (" 4#bY3c FccK {vFQSJT#F]b ( % " ( #"-KI9MI#YkI#F][3KaJQ_NFFH#Kc2fO\_F-G]KIP/KaJQSPVZ:XlQ_J-p.QScfY3P/PQ_eO\_FvYb ( GHY3IJKQSIOP-KaJ\_FKPVJ-JjnY5I#F][3KaJQ_NF\SQ_JVF]b/K\gP]v KIOMJT#F%GHY3I9PVJVb/KQgIJPK\S\BT9KNFQSIGHY3cc2Y3IJjnYF\_Fc2FI(JP-YZn> iUT(W9Pv JT9F%QSIOPVJKI9GHFYZ ff~ fi fi Y3\_Yb/KaeOQg\SQ_JX QSP!JVbQ_N{QgK\wvjUTOQSG/TQSP!Qgc2fmY3PPQ_eO\SF"T9QgPLFI9M9PLJT#FfObY(YZ0YZ FccK {F-I#YjP/T#Yj JT9KaJ"JT#F!M9F]Z:KW9\SJLG]\gKPP"YZ 5QSP ff fi un#YbUJT#FffPKF!YZ PQSc2f`\SQSG]Q_J)Xv{jnFj"bQ_JVFoJT#FJjnY5c2Y3I#Y3cQSK\gPoYZ e{/X ( KI91. l"T9FM#F]Z.KW9\_J!G]\SKP/P!QSPffM#FI#YJVFM 1m 0 ff fi uv ff )93 KuQSI#[JT#FKPP/W9c2f9JQ_Y3I5JTOKaJ % ff lQScfO\SQ_FP JT9KaJ!K\S\I9F][3KaJQ_NFFH#Kc2fO\_FPc-W9PVJP/KaJQSPVZ:XiKaJ!\_FKPJY3I#Fc2Y3I#Y3cQSK\7QSIfi #W#f9fmY3PVF2JT9KaJ ( KI9M . u%"T9FI7v0I#YfY3P/Q_JQ_NF2FH#Kc2fO\_FG]KIPKaJQSPZXFQ_" J T#F]4 b (Yb . 9bY3c JT#F%JjnYfmY3PP/Q_eOQS\SQSJQ_FPfiYZ FccK {vY3IO\_XJT#F%^9b/PVJffY3I#FkQSP!NaK\SQSMp " ( "G]KIOI#YJoemFP/KaJQSPV^9FMe{XiKI(XI#F][3KaJQSNF2FHuKc2f`\_Fff"T{W9P]v ( KI9M/ . GHY3I(JKQSI5FKG/TKaJ\_FKPVJJ)jBY%I#F][3KaJQ_NF-\SQ_JVF]b/K\SP20 ( ":90 ( 19( (p+xp+x3. 4FKabF2QSIJT#FPVFGHY3I9MG]KPVFYZRJVb/Q_NuQSK\SQSJXYZnJT#F2QSI9PVJKI9GHFYZ ff~ fi fi Y3\_YbKaeOQS\SQ_J)X& uv0PQSI9GHFcK{QSI9[2JT#F!KPPWOc2f9JQ_Y3I%JT9KaJ 5QgPGHY3I9PQSPVJVFI(JUQScfO\SQ_FP&fi #W#f9fmY3PVFfiJT9KaJm0x3(/~)(5464646(RGG 9 (,0 ( "39 0 !,+ 60 ( 1 9- 0 !,+4p+xy3KI9M .u \S\I#F][3KaJQ_NFFH#Kc2fO\_FPUcffW9PJUPKaJQSPVZ:X ( ( QSPZ:Yb/GHFMJVYkemFc2Y3I#YJVY3I#Y3W9PoP/QSI9GHF-YJT#F]bjUQSPFkp:[3Q_NFIJT9KaJ E% ff K\S\ I#F][3KaJQ_NF2FH#Kc2fO\_FPhjnY3W9\SMP/T9KabF!KGHY3cc2Y3II9F][3KaJQ_NF-\gQ_JVF]b/K\wv#JT{W9PUK\g\GHY3I9PVJVb/KQgIJPUjBY3W9\gMlPT9KabFffKGHY3cc2Y3IF\_Fc2FI(JYZ >nvKI9M JT#FQSIOPVJKI9GHFlY)Z ff~ fi fi Y3\SYb/KaeOQS\SQSJX jBY3WO\SMemFJVb/Q_NuQSK\w . emFQSI#[PKaJQgPV^9FM(:BC5zfiiwcffffe{XKaJ2\_FKPVJ-Y3I#FkfmY3PQ_JQ_NFFHuKcfO\_Fp:YJT9F]bjUQSPVFv jBY3WO\SMemF%F(WOQ_N8K\SFIJffJVY5KPQSI9[3\_F fiDb/W9\_FM9FG]QSPQ_Y3IGHY3ccQSJVJVF]FvfiKIOM1jnFZ.K\S\fiQSIJT#FGHY3IJVb/KMOQSGHJQ_Y3IYZ FccK 3vfiQ_JGHY3IJKQgI9PKaJcY3PVJ Y3I9F-I#F][3KaJQSNF\gQ_JVF]b/K\wZdQ_J GHY3I(JKQSI9PhFH#KGHJ\_XlY3I#FI#F][3KaJQ_NF\SQ_JVF]bK\wv`Q_JhQSPUP/KaJQSPV^9FMie(XFH#KGHJ\_XffY3I#FLfY3P/Q_JQ_NFRFH#Kc2fO\SFv3KI9M-jBFLG]KIbF]fO\SKGHFLQ_J e(X!JT#Fc2Y3I#YJVY3I#Y3W9P c2Y3I9Y3cQSK\(jUQ_JTGL>HG)7 xfmY3PQ_JQSNF\SQ_JVF]bK\SPp:jnF%\_FKNFFcf9JXJT9FfmY3PQ_JQ_Y3IYZ"JT#FQgI9Q_JQSK\I#F][3KaJQSNFk\gQ_JVF]b/K\Y3I9PVF{W#FIJ\SXv9PQScQS\gKab/\_X-ZYb ( v#jBFG]KIPW9f9fmY3PVF JTOKaJ . QSPLc2Y3I#YJVY3I#Y3WOP] F!M9QSPJQSI#[3W9QSP/TJ)jBY%G]KPVFP]" 4Z G ( GG . GvOI#Y2fmY3PQSJQ_NFfiFHuKc2f`\_FG]KIPKaJQgPVZX- ( dqnXkZ.KGHJ{v ( % " ( #"vOKI9MI9YI#F][3KaJQ_NFFH#Kc2fO\SFG]KIPKaJQSPZXkQ_J]v9KGHY3I(JVb/KM9QSGHJQSY3Ip 5G]KI9I#YJ"emFGHY3I9P/QSPVJVFI(JZ G ( G G . G . G]KI9I9YJeFFc2f9J)X`z!JT#F]bF]Z:YbFQ_JkGHY3IJKQSIOPKGHF]b/JKQSItI(WOc!emF]bYZ-fmY3PQ_JQ_NF5\SQ_JVF]bK\SP] BKG/TtfmY3PQSJQ_NF5FHuKc2f`\_FPKaJQSPVZ:X{QgI#![ . cffWOPVJK\SPVYPKaJQSPZX ( vP/QSI9GHF5YJT#F]bjUQgPVFQSPI#YJlGHY3I9PQgPVJVFIJ]z2uQSI9GHF ( KI9M . KabFc2Y3I#YJVY3I#Y3W9P+v . QSPK[FI9F]b/K\SQ_KaJQ_Y3IYZ ( v KI9MKI(XFHuKc2f`\_FPKaJQgPVZXuQSI#[ ( p.QgIfOKabJQgG]W9\SKabv0JT#F%I9F][3KaJQ_NFFH#Kc2fO\SFPLc-W9PVJ"PKaJQSPZX . v9KGHY3I(JVb/KM9QgGHJQ_Y3I7"T9F]bF]ZYb/F %)ff fi un"TOQSPZ:Yb/GHFPUK\S\fY3P/Q_JQ_NFoFH#Kc2fO\_FPUJVYPKaJQSPZXkKaJ \_FKPJ"Y3I#FffcY3I#Y3cQSK\7YZ. uJffGHY3cFP(iKI9*( % ffp FccK +( \S\I#F][3KaJQ_NFFHuKcfO\_FPc-W9PVJPKaJQgPVZ/X . v KI9M5jnFK\SPVYlT9KN/F G ( G G . G"4YfY3P/Q_JQ_NFFHuKcfO\_FG]KIPKaJQgPVZX . vKIOM FccK %[3QSNFPFQ_JT#F](b ( % " ( "lp.PKaJQSP^9FM5e(XI#YkFH#Kc2fO\_Fv7QSc2fmY3PP/Q_eO\_FnY(b . GHY3IJKQSIOPoKaJ\_FKPVJfiJjnYlI#F][3KaJQ_NF\SQSJVF]b/K\SP]vjUT#Y3PVF2GHYbb/FPVfmY3I9M9QSI#[F\_Fc2FI(JPYHZ >Kab/FPT9KabFMe(X5K\S\dGHY3I9PJVb/KQSI(JP]v0KI9MjBFYeOJKQSIKa[3KQSIJTOKaJJT#FQSIOPVJKI9GHF2YZ ff~ fifi Y3\SYb/KaeOQS\SQSJX 2QSPLJVb/Q_NuQSK\w"T9F]bF]ZYb/Fv (KI9M .uvKIOMlFKG/T5c2Y3I9Y3cQSK\QgPUPKaJQSP^9FMle{XlKaJh\SFKPVJUY3I#FfffmY3PQ_JQ_NFFH#Kc2fO\_FQgP!JT{W9PffF(W9QSN8K\_FI(J-JVYK5} jUQ_JTJT#FPKc2F%JjnYc2Y3I#Y3cQSK\gP]vKI9MjnFG]KIW9PVFKkf9bF]NuQ_Y3W9PfiPVY3\gW#JQ_Y3Ip FKab/I9PF]JK\w_vRxy3fiJVYe`W9QS\SMKkN8K\gQSM~ fi fi Y3\_Yb/KaJQSY3I72 QSb/PVJ]vjnFG]KIPW#fOfY3PFdJT9KaJ 2QSP Ka[3KQSIffcY3I#YJVY3I#Y3W9PLp FKab/I9P F]J K\w_v#xy3d"T#FI7vaPQSIOGHFRFKG/T-fmY3PQ_JQSNFdFHuKcfO\_FPKaJQSP^9FP KaJd\_FKPVJ Y3I#Fc2Y3I#Y3cQSK\7p % ff fi v3JT#FIZ:YbK\S\NaKab/QSKae`\_FvJT#F]bFnFHuQgPVJPKfic2Y3I#Y3cQSK\(jUT9QgG/TM#Y{FP"I#YJUGHY3I(JKQSIJT9F!GHYbbFPVfmY3I9MOQSI#[-fY3P/Q_JQ_NF\SQ_JVF]bK\w"T#F!~ fi Y3\_YbKaJQ_Y3IlQSPJT9FIEUFG]K\S\RJTOKaJ GHY3I(JKQSI9P-J)jBYc2Y3I#Y3cQSK\SP]iuW9f9fmY3PVFJT9KaJ"87 c(QSI .j 00 "J9 4m0x3(/~)(5464646(RGL> G 9 ( p %pw~aY3WO\SMJT9QgP!emFQgINaK\SQSM "T9KaJ-jBY3W9\gMc2FKIJT9KaJ-JT#F]bF%FHuQgPVJPKiGHY3I9PJVb/KQSI(J !UPWOG/TJT9KaJ"m ! ( p "#% % ! UT9QSPjnY3W9\SMc2FKI JT9KaJJT#FlGHYbb/FPVfmY3I9M9QSI#[I#F][3KaJQSNFlFHuKcfO\_FPKaJQSP^9FP vOK2GHY3I(JVb/KM9QgGHJQ_Y3Ip FKabI9PF]JUK\w_vxy3L"T9QgPLFI9M9PLJT#FfObY(YZ YZ "T#F]YbFc {k36)N6)" 5"Z>c}hF]^OI#FJT9FoZ:W9IOGHJQ_Y3I~' (0 (% & P/W9G/TJTOKaJ02(x3(5464646(*!7x:9 (- /%4 ; pVp'&)( 8(ff(V"p( 9 (+ "pw~uxjUQSJTnpJ( 9% $ - -um 6m0 / / $m0--/6:BC>;/ / - -_pRm6pm06 m0/ /.4fi>>(>(>(>(>.>4>(>>.>.>4>4.>.>4>4>>>(>>-8?m.>4>>(>.>4>>(>>.>>4GHY(FG]QSFIJ"YZ; pVp'& ( 8(ff{V QSI+ / -- /- //~~$ x$ x$ x$ x~J$J~ $$ x$ x~~~$ $x $x $$ x$ x~$ $~~x $x $~J$~J$x $x $x $x $~~KaeO\_F/& 3Y PPQSeO\_FiGHY{FG]Q_FI(JPkYZ@;pVp'& ( 8(ff{VFT9KNF^#uFM Z:YbPT#YbJ >:x 9up +v > . % %v8> 4 % v8> % %(% 02(x3(5464646(*!7[FI#F]b/K\SQ_]FPJT#FJT#bF]FFH{f9b/FPPQ_Y3I9PfiYZ QSI5F{W9KaJQ_Y3I9Ppw~3vLp 3vKI9MKM#F{W9KaJVFNaK\SW#FPZ:YbfiR8 Yjv`jBF!GT#FGkJT9KaJ 5PKaJQSPV^9FP"JT#FPW#eOcY{M9WO\SKabQSI#F{W9K\SQ_J)X- + / - / - / - /@(YJVFJT9KaJpDfijUQ_JTpw~~3Z:YbK\S\LPW#eOPF]JP( 0 2( x3(5464646(*!17 x:39 "T#F F]XQSPJVYFH#KcQSI#FkJT#FGHY{FG]Q_FI(J2YZ FKGT;-pVp'&)( 8(ff{VvRZ:Yb!FKG/TPVF]J02(x3(5464646(*! 7tx:9up +ffv %vfi v JVYjUT9QSGTiYb G]KIemF\_Y3I#[#d KaeO\_F/fObFPVFI(JPJT#FPVF!GHY{FG]Q_FI(JP] Fff[F]J"Z:bY3c KaeO\_F/-+ / - / 7 p - / - /: %~@7 $ 7 $ 4 ; pVp'& ( 8(ff{V - -_p=m 6 5pum 6 / / 4+ ""TOQSPd\SKPVJn(WOKIJQ_J)XQSP !ZYbLKI(X2fY3P/PQ_eO\_FGT#Y3QSGHFhYZd"T9F]bF]ZYb/Fv(cQSIOQScQ_QSI9[ QSIKIX2YZQ_JP JT#bF]FLZ:Yb/cP YZOF`"pw~3v`p 3vKI9MpD0emY3QS\SP0M#Yj IJVYficQSI9QScQSQSI#[ Y3IffJT9FLP/W#eOc2YuM9W9\SKab PVXuPVJVFcp 02(x3(5464646(*! 7 x:9 ( op:jUQSJTJT#F!KM#F{W9KaJVFNaK\SW#FP"YZ L"T9QSPLf9b/YeO\_Fc KM9cQSJPfmY3\_X{I9Y3cQSK\ fiDJQScFPVY3\_NuQSI#[-K\_[Yb/Q_JTOcPhp JPG/T9F\wv YNK PVv r uGT#b/Q VNF]bv`xyuxaz fffiW#F]X{b/KI9I#Fvmxyy3T9KaJQSPncffW9GTQSI(JVF]bFPVJQSI9[QSPJT9KaJdJT9FUK\_[Yb/Q_JTOcP {I9YjUIKab/FUT9Q_[3T9\SXffGHY3c2fO\gQSG]KaJVFMKI9M2JQgc2F"GHY3I9PW9cQSI#[fiZYbBJT#F[FI#F]b/K\ncQSIOQScQ_KaJQ_Y3I5YZ pfiffoW#F]X(bKI9I#FvLxyy3 " YjnF]NF]bvjUT#FIW9PQSI#[JT9FNaK\SW#FYZKP-QSIF`!p +("KI9M KPhQSIF`ffpDv`JT9FffGHYbbFPfY3IOM9QSI#[2Z.W9I9GHJQ_Y3I 5emFGHY3c2FPhPW#eOc2YuM9W9\gKab"PVX{cc2F]JVb/QSGp - / % -M02(x3(5464646(*!"7 x:9 /: P2P/W9G/T7vBc2YbFkFG]Q_FI(Jlp.KI9MPQSc2f`\_F]boK\S[Yb/Q_JT9cP-FH#QSPVJ-JVYcQSIOQScQ_]F #YbnFHuKc2f`\_FvJT#F]b/FUFH#QSPVJPRK!fmYjnF]bZ:WO\9GHY3c!e`QSI9KaJVYb/QSK\OK\_[Yb/Q_JT9c jBYb{QSI9[QSI kp'!pfifffiW#F]X{b/KI9I9Fvxyy3 YJVF!JT9KaJJTOQSP"QSPPVJQg\S\mK2NF]bX\SKab[FGHY3c2f`\_FHuQSJX:BCfiiwcffff" 5"Z>k36) .?6" 7rff * )c"T#FRbFM9W9GHJQ_Y3IffQSPcKM9FRZ:bY3c JT#F? fi " Kab/Mfff9bYe`\_Fc 3 fiffp.#FQ_[Fv9xyy|3d"TOQSPQSPJT#FBG]\SKP/PQSG]K\3 f9bYeO\SFc p KabF]X r Y3TOI9PVY3I7vLxy3ay3vdeOW#JffFKG/TNaKab/QSKaeO\_FKaf9fmFKab/P!QSIFHuKGHJ\SX lG]\SKWOPVFP]hPQSI#[!K!jBF\g\ fi {I9YjUIbFM9W9GHJQ_Y3Ip KabF]X r Y3TOI9PVY3I7vOxy3ay3v#f`Ka[F {vujUQ_JTKIKM9MOQ_JQ_Y3I9K\9P/QSc2fO\_F[3KM#[F]J]vfijnF5G]KItcK FKb/FM9W9GHJQ_Y3IZ:bY3c 3 fiJVYNF]bJVFHtGHYNF]bp:JT{W9P]vhQSI9M#F]fmFI9M9FIJ%PVF]JvYe9JKQSIOQSI#[ Kh[b/Kaf`QgI!jUTOQSG/T-K\S\{NF]bJQSGHFPT9KNF"M#F][bF]FLFQ_JT#F]b {vYbduv3KI9M-Z:YbjUT9QSGT!JT9FL\gKab[FPVJQSI9M9F]fFIOM#FIJdPF]Jhp:Z:YbnPKaJQgPV^OKaeO\_F QSI9PVJKI9GHFPRY%Z 3 fi3RT9KPRP/Q_]1F G3 G a~{v{jUT#F]bCF G3#G3QSPdJT#FhI(WOc!emF]bYZNF]b/JQSGHFPYZ d#bY3c JT9QgPBf`KabJQSG]W9\SKabn[b/KafOTv{jnFfieOW9QS\gMK2PQScfO\_F"bFMOW9GHJQ_Y3I%JVY2Y3W#bLf9bYeO\SFc YZcK8#QScQ_QgI#[ YJVFRJT9KaJ PQSI9GHFdjnFBKab/FRPVFKab/GT9QSI#[ ZYb KIYeO\SQSN{Q_Y3WOP7TX{fmYJT#FPQSP]vJT#FdYeOPF]bN8KaJQSY3I9PKabFI#YJ Qgc2fmYbJKIJ-p:jBFG]KI5PW#f9fmY3PVFoJT9KaJfiK\S\FHuKc2f`\_FP TOKNF-JT#FffPKcFffYeOPF]bN8KaJQSY3I`U"T9KaJhQSPjUT(XfiJT#FBb/FM9W9GHJQ_Y3IoY3IO\_XfieOW9QS\SMOP7G]\SKPP0NFGHJVYb/Pp:YNF]b G3 GG]\SKP/PVFPvaFI9GHYuM9QSI#["JT9FBG]\SKPP0c2FcffeF]bPT9Q_fYZ`KI(X-YZOJT#FPVFQSM9FIJQSG]K\{YeOPF]bN8KaJQSY3I9P] "T#FQSM#FKhQSP JT9KaJJT#FG]\SKPPFPKabF"QSIffY3I#F fiDJVY fiDY3I#F cKaf9fOQSI#[jUQ_JTkJT9FNF]bJQSGHFP]v`KI9MJT#F]bFKab/FJjnYPVF]JPUYZ G]\gKPPNFGHJVYb/P eOW9QS\SJBZ:bY3cG3#GNFGHJVYb/P]v{FI9GHYuM9QSI#[oJT#F NF]bJQSGHFPRYZ RKG/TY3I#FUQgPdK!G]\SKP/PNFGHJVYbLjUQ_JT2Y3I9\SXfi KffPVF]JdjUQSJY3I9F ff]x GHYbb/FPVfmY3I9M9QSI#[!JVY-JT9F NF]bJVFHmv9KI9M%JT#FhbFcKQSIOQSI#[!GHY3c2fmY3I#FI(JPLKabFfi]F]bY{FP] RKGTYZ JT#FGHYb/bFPVfmY3I9M9QSI9[-FH#Kc2fO\SFP"T9KNF!jBFQ_[3T(ffJ 0fi KkPVF]JfijUQSJTG GONFGHJVYb/PvjUT#F]bF G GOQSPhJT#FI(WOc!emF]bhYZdFM#[FPfiYZ- B KG/TY3I#FFI9GHYuM#FPfiKIFM9[Fv9KI9MJT9F]bF]ZYb/FhGHY3I(JKQSI9PnJjnY ff]x lp.KI9MJT#F b/FcKQSI9QSI9[!KabFfi]F]bY{FPdGHYb/bFPVfmY3I9M9QSI9[JVYJT9FJjnYNF]bJQgGHFP"YZ JT#FFM#[FBKG/TYZ JT9FGHYbbFPVfmY3I9M9QgI#[FHuKc2f`\_FPT9KNFffjBFQS[3TJff0Y3IOPQSM#F]bhZYbcffW9\gKPpw~3vBp 3 ZYboFH#Kc2fO\SFff"T#F]XiKabF2JT#F2PW9c YZRJT9FGHY3IJVb/QSeOW#JQ_Y3IiJVY YZJT#FFH#Kc2fO\SFPT9KNuQSI#[jBFQ_[3T(J 0 v0KI9MJT#FFH#Kc2fO\_FPTOKNuQSI#[jnFQ_[3TJ 0 IJT#FPVFG]KPVFPv0jnFG]KIlb/F]j"b/Q_JVF W9PQSI9[-JT9F[FI#F]b/QSGfiFHuf9bFP/PQ_Y39I% (pw~ 3% 0 $ 7p*G3 G:7 9 7p 7x p*G3 G37 9Hp*G3 G37 17 x $ 7p*G3 G:7 9 (Lpw~+(% 0 $ p*G3 G:7 9Hpw~ $ 7pw~ 4pw~3" F]bFv QSPdJT#FfiI{W9c!emF]bBYZFM#[FPLT9KNuQSI#[ffJT#FQ_bBJjnY-NF]b/JQSGHFPLQSIJT#FfiPVF]JLGHYbbFPVfmY3I9MOQSI#[JVY-JT#FxNaK\SW#FPRQSI v SQ PJT#FUI{W9cffemF]bdYZmFM#[FPRT9KN{QgI#[JT#FQ_bRJjnY!NF]bJQSGHFPnQSIJT#F PVF]JBGHYbb/FPVfmY3I9M9QSI#[JVYJT#FC7 xfiNaK\SW#FPQgI v9KI9M QSPLJT#FI{W9c!emF]bLYZ FM#[FPUT9KN{QgI#[Y3I#FoYZ0JT9FQ_bNF]bJQSGHFP"QgIkJT#F xPVF]J]vOKIOMJT#FYJT#F]bUY3I#F!QSIkJT#F!7 xPVF]J] QgPLJT#F!I{W9c!emF]bYZ xoNaK\SW#FPQSIuW9f9fmY3PVF JTOKaJff0 ff0 p214351 0G3#G 4 0 R"T#FIkJT9FcK8uQgcQ_KaJQ_Y3IkYZ QSPLJT#FcK8#Q ficQ_KaJQSY3IYZ v`ZY3\S\SYjnFMe(XkJT#FffcK8uQgcQ_KaJQ_Y3IYZ KMOcQ_JP"KcK8uQSc-W9c Z:Yb #%G3 G a~{vKI9MjUQSJTJTOQSP-N8K\SW9F%Z:Yb vBQSJG]KIeFkPT#YjUIJT9KaJcK8#QScQSQSI#[emY3QS\SP-M#YjUIJVYcK8#QScQ_]F~fi vhJT9KaJlQSP]v JT#F p:jBFQS[3TJVFM`%I{W9cffemF]b%YZ-FM#[FPI#YJZ.K\S\SQgI#[FI(JQ_bF\_XQSI(JVYJT9F5PF]JlGHYb fibFPVfmY3I9MOQSI#[JVYJT#F xkNaK\SW#FP]zLjUT9FI#F]NF]bJT#F 3 fi5QSI9PVJKIOGHFlQSP2PKaJQSPV^`KaeO\_Fp.KI9MW9P/QSI#[5JT#FfOKabJQgG]W9\SKabLM#F][bF]FPLYZJT9F NF]bJQgGHFPv9JT9QSPnPVF]JGHYbbFPfY3IOM9PRJVY2JT9Fh\SKab/[FPVJQSI9M#F]fmFI9M#FI(JRPVF]JYZ -k36)N6)bB^"Z> >T#F f9bY{YZ7YZ7JT9QSPn\_FccKffQSPn(W9QSJVF PVJVb/KQS[3TJVZ:YbjLKab/M7v{eOW#JdjnF [3QSNFhQ_JnZ:YbnGHY3c2f`\_F]JVFI#FPP]"G]KIemFbF]j"bQ_JVJVFIKP%4" &$:BC" (pw~|3fijUQSJT0 , " 1 0 , " 1% 0 8 ( " % !7" x $(pw~3!7 x $jUT9F]bF pJ( 9% -/?7 -/D uW9f9fmY3PVFZ:YblGHY3IJVbKM9QSGHJQ_Y3IJT9KaJkZ:YblPVY3c2Fvff %lp( 9u FPQgc2fO\_XfmF]b/c-W#JVFJT#F2JjnYlNaK\SW#FP -/BKIOM -/Dv0KIOM5jBFPT9Yj JT9KaJoJT9FI#F]jNaK\SW#F!YZ KaZJVF]bv vQSP I#YJh[bFKaJVF]bfiJT9KI eF]Z:YbFfffF]bcffW#JQgI#[#v @ UT#F!M9Q *mF]bFI9GHFffemF]JjnF]FIKIOM @ G]KIemFLFKPQS\_XM#FGHY3c2fmY3PVFM2W9P/QSI#[fiJT#FUI#YJKaJQSY3I , " 1 @ p'*ff(um/0 2( x3(5464646(*! l7 x:9 (O5% 0{KPhJT#F-N8K\SW9F!YZ k" p:F`pw~3VhQSI@ vmKIOM, " 1 p'*ff(=m 0 2( x3(5464646(*!.7 x:9 (O % 0{ KP JT9F!NaK\SW#FYZ" p:F` pw~3VUQSI F-K\SPVYM#F]^OI9F(( m/0 2( x3(5464646(*!7 x:9 (O % 0% 0 8( , " 1 % , 1 , 1 , " 1 , " 1 4 pw~3*ffF-M#F]^OI#FoQSIkJT#FffPKc2FjLKX , " 1 @ F!YeOJKQSI7 @ % , " 1 7 , " 1 @4 ' , " 1 7 , " 1 @4pw~y3( 7& "RbYNuQSI#[2JT9KaJ 7 @ 2G]KIemFoYe9JKQSI#FMlKP"ZY3\S\SYjUP]d Q_bPVJ]v0 7 0 "$, " 1 7 , " 1 @ %xH7 $E4!A7 xF-K\SPVYT9KNFm0 x3/( ~)(5464646(*! 9 0( 69~ 0" $: 7 ~ 0 " $ : 7 ~ 0 $, " 1 7 , " 1 @ % ~!A0$7 x!A7 x!A7 x!7 x~0 7 0 "%,$ : 7 $!7x~0 7 0 "$ :%8x 7 $E4!7 x" F]bFUjnF TOKNFfiW9PVFUJT9F"Z:KGHJnJT9KaJ %" k"T9QSPP/T#YjUPBJT9KaJ 7 @ uvuKI9MFI9M9PJT#FfObY(YZ0YZ FccKxak36)N6)" 5"Z>c0YhKNY3QSMffGHY3I9Z:W9P/Q_Y3I7v8jBFLG]K\S\ JT#FnNaK\SW#FdYZ GHY3c2fOW#JVFMffYNF]b JT#FnJVb/KI9PVZ:Yb/c2FMffPVF]J YZ#FHuKc2f`\_FP]vKI9M p Z:Yb m0 ( 9KI9Mm0 ( 9KPhJT#FffNaK\SW#FffYZRGHb/Q_JVF]bQ_Y3I WOPQSI#[NFGHJVYb/ h)JfiQSPPQScfO\_FhJVYYe9JKQSIlK ffVP(W G]Q_FI(J 2emY3W9I9M%JVYGT#FGJT9FJT#F]YbFcF!T9KNF-p % p 7p % - p4> 3LG > Gx4> 3GL> Gx0 4 4 $ = 4 $ = " "$ (GL>HG 734 "734p0 4 4 $ = 4 $ = " "$ 4"87 4GL> G 734p ux:BC Cfi" F]bFv0 l4 QSP"JT#FffPWOciwcffffYZjBFQS[3TJP YZ JT#F!FH#Kc2fO\_FP QSIJT#F!Yb/Q_[3QSI9K\PVF]J]v`j T#Y3PVFNFGHJVYb/PfiT9KNFwp .p v`PQSIOGHFoY3W#bUK\_[Yb/QSJT9c QSPYfOJQScK\wvff]x cKaJG/T9QSI9[JT#FF\_FcFIJPUYZ<>L YJVF!JT9KaJKI9MjnFYe9JKQgI-p-p4> 3GL> Gx0 4 4GL> G734$ ="87 44$ = " 7 $ ="734 4$ = ""$ 4qnXkJK{QgI#[2Y3I9\_X%JT#FofmY3PQ_JQ_NFof`KabJYZ0JT9Fb/Q_[3T(J fiT9KI9MPQgM#Fv9KI9MkbFcKab{QSI9[2JT9KaJfi> 3 (RGL> G3x ( bm >nv&6 "734$ = " $* ' 4 4 (6 " 7 ? +4 $ = " :p JT#Fb/QS[3TJhPW9cQgPUp'!7 GL> G $ K I9MJT#Fff\_F]ZJY3I9FQSP *p GL> JG 7x 5 $av"fi JT9F!GHY(FG]Q_FIJUYZ*04QSI QSP 54% 6 734 $ = 6 "7 ? +4 $ = vjnF[F]J-p-p$ GL> *p GGL>p'! G37 7GLx> G 0 4 44> 3LG > Gx-p $ 7p p'C!7 7 x9-pOx!7$4> 3GL>HGxfffi04 54(KP G]\SKQSc2FM7k36)N6)bB^"Z> > %nemFGHY3c2FP"QSIJTOKaJUG]KPVFjUT9F]bF % - x /% 0 $ 0 $ (p ~37 - /DB"T#F]bFfiKabFo^9NFoM9Q *mF]bFI(JLN8K\SW9FPBZ:Ybfikv#[3Q_NuQSI#[-b/QSPF JVYI9QgI#F M9Q#*F]bFI(J%%%%%,x ,,7 x ,7 ~ ,U~% p 7x3( x% p7 x3(% p7 x3(7 x% p.2(7 x% p x3(7 x(%%4:BCp.2( x (% p.2( % p 3x ( x (p 3x ( (fiQ% 5jUT#F]bF 0 7U~)( 7x3(2(x3(/~ 93 0 7x3(2(x3(/~ 93vJT9FN8K\gW#F % 5PT#Y3W9\SM5emFf9bF]Z:F]bbFMkJVYJT#FNaK\SW#F % 17 xQ *iJT9F!GHYbbFPVfmY3I9MOQSI#[ QgPPcK\S\_F]bv#JT9KaJUQSP0 $ 0 $EUFKabb/KI#[3QSI9[2JVF]b/cP[3Q_NFP0 0 (&>0 $ & 0 $ & 4p 3R"TOQSP\_FKM9PLJVYJT9Fb/W9\_FfiYZ JT#F\_FccKuqLKW#F]bv"_v rs Y3T9KNuQwvaEup+xyyy3 IffFc2fOQSb/QSG]K\GHY3cfOKab/QSPVY3IffYZ9NYJQSI9[hG]\SKP/PQ_^OG]KaJQ_Y3I-K\_[Yb/QSJT9cPqLKa[[3QSI9[#vOemY(Y3PJQSI#[#v#KI9MNaKab/QSKI(JP] 8 "5 J " 2J 3v > vx]6`xy{qL\SK Fv _v F]Y[3T7v "_v r F]bv p+xyy3 bF]fmY3PQ_JVYb/X-YZcKG/T9QSI9F \_FKab/IOQSI#[M9KaJKaeOKPFP]_fffifi fi "!fifi$#"% & $ ff' ff( $ #qnbFQScKIv p+xyy|3LqnKa[[3QgI#[f9b/FM9QSGHJVYb/P] 8 "6 J0 " 2J 3v <) vx~ `x +3uqnbFQScKIv _vR#b/FQSM9cKI7v"ff_vnfi\SPT9FI7vE _v r {JVY3I9Fv Up+xy +( Q !#"%<%KJ" J " V*U 3 %<%KJ V % KM9PVjnYbJT7qLW Kuv _v r F]F"v + fipw~a#xd}hKaJK2cQSI9QSI#[-GHb/Q_JVF]b/QgK!Z:YbLJVbF]F fiDeOKPVFMkbF][b/FPPQ_Y3IkKI9MkG]\SKPP/Q_^OG]K fiJQSY3I7oI , 2 /j V J 3 %-[N @ p H " J "!bQ dN ]V /. fX ! W V23{ PJ % a] JP " ""% % v`f9fO~30 5|{qLW9I(JQSI#Fv _v r hQ_eO\_F]JVJ]vo`p+xyy~3 Z.W#bJT#F]bdGHY3c2f`Kab/QSPVY3IYZmPVfO\SQSJVJQSI#[hb/W9\_FP Z:YbR}hFG]QSPQ_Y3I fibF]FQgI9M9W9GHJQ_Y3I 8 "6 J 10 " 2J 33v 2v { {\SKab `v 0_v r qBY3PjBF\S\Dv`Ep+xyyuxoEUW9\SF!QSI9M9WOGHJQ_Y3IjUQ_JT fi&~ PVY3cFffbFGHFI(JoQSc2f9b/YNFc2FI(JP]U+I, > /j V J 3 % [N 54 $# " G EJ 376 %<%KJ J " 2J 3vOfOf72x `x|uxaY3T#FIv _v r uQSI#[F]bv +Rp+xyyy3 uQSc2f`\_Fv`9KPJ!KI9M *mFGHJQ_NFE W9\_F FKabI#F]b-8, _/j V J 3 % [N :9 " J "! Q 4N ]V <;J J "! p ! !wJ 3( ]v#f9f 5+~{M#F Kab/N8K\ST9Y Y3c2FP]vOn _v r KPG]W#F\Dv-p+xyy +(L#} v9K2PVJVYuG/T9KPVJQgGK\_[Yb/Q_JTOc ZYbU\SFKab/I9QSI#[M9FG]QSPQ_Y3I\SQgPVJPhjUQ_JT\SQScQ_JVFM5GHY3c2fO\_FH#Q_JX ; "! %[N 8 " " J % " V ; J J "! p ! !\J _3{ H=v 9>8v`~u?x 5a3~{}fiQ_F]JVJVF]b/QSGT7v0 npw~a IFH{fmF]b/QScFIJK\dGHY3cfOKab/QSPVY3IYZLJT#bF]FcF]JT#Y{MOPoZYb-GHY3I9PVJVb/WOGHJQSI#[FIOPVFc!e`\_FP YZ`M#FG]QSP/Q_Y3IJVbF]F2P 3qnKa[[3QgI#[#vaeY{Y3PVJQSI9[#v8KI9Mffb/KI9M9Y3cQ_KaJQ_Y3I7 8 "5 J @" 2J 33v>) 8v0x `2x 3(}hY3cQSI#[Y3Pv 0Rp+xyy3 RbY{GHFP/P fiDYb/Q_FI(JVFM "UFW9b/QSPVJQSG-Z:Yb YuM#F\PVF\SFGHJQ_Y3I7-8, 2 /j V J 3 % [N:9 p H " J "!cQ dN H 8 "6 J" 6J 33v9f9fx~30 `x {#FQ_[Fv ffLp+xyy|3 JT#bFPT9Y3\SMYZ"\SI -ZYbKaf9f9b/Y#QScKaJQSI#[iPVF]J-GHYNF]b+B, > /j V J 3 % [N2< ;:Q 8 69%eJ $ZT [NRQ$ J 33v9f9f ux +C5ux{#b/KIOG v U_v r Q_JVJVFI7v(p+xyy3 hPQSI#["K dF]b/c-W#JKaJQ_Y3IffFPVJZ:Yb JVJVb/QSeOW#JVFdPVF\_FGHJQSY3I!QSI}hFG]QSP/Q_Y3I"bF]FP]m7,L 2 W V J 3 % [N9 p ] " J "!AQ dN H 8 "5 J ff0 " 2J 3v{f9f2x ~ `x|au#bFWOI9M7Dv +-_v r KPY3I7v p+xyyy3 "T9FK\_JVF]bI9KaJQSI#[M#FG]QSPQSY3I JVbF]F\_FKabI9QSI#[K\_[Yb/Q_JT9cl +I, > /j V J 3 % [N E9 p ] " J "!^Q dN H 8 "6 J F" 2J 33v{fOfx~ +C`x {:BC>=fiiwcffff#b/QSFM9cKI7v _v "hKPVJQ_Fvao_v r "QSeOPT9Q_bKI9QwvHE{pw~a M9M9QSJQ_NF Y[3QgPVJQSGREUF][bFPPQSY3I 8Kfi{JKaJQgPVJQSG]K\fiQ_F]j YZqnY{Y3PVJQSI#[# ;+ "! % [N 6 " J % J % v < 23v' 3053 +#KabF]Xv _v r Y3T9I9PVY3I7v}-Lp+xy3ay3 Q$ ] %)" Vp . "6 "rJ !wJ . ]," 3 $ZJ V [N,v_ QfT! %<% RqnF\S\0F\_F]fOT9Y3I#F KaemYb/KaJVYb/QSFP]b JP/G/T#F\wv _vN K PVv _v r uG/T9b/Q VNF]bv up+xyux`"T#FnF\S\SQ_fOPY3QSMoc2F]JT#YuMKI9MffQSJP0GHY3I9PF(W#FIOGHFPQgIGHY3c!eOQgI9KaJVYb/QSK\7YfOJQScQ_KaJQ_Y3I Q J " J<" v 9avx|y `xy3(" Y3\_JVFvBE! p+xyy 3 F]bXPQScfO\_FG]\SKPPQS^OG]KaJQ_Y3Ib/WO\_FP2fmF]bZ:Yb/c jnF\S\Y3I cY3PVJGHY3cc2Y3IO\_XW9PVFMMOKaJKPVF]JP] 8 "6 J0 " 2J 33v 9 9av| {yuxa" X3Ka^O\wv _v r EUQSNFPVJ]v#Ep+xy3a|3 Y3I9PJVb/W9GHJQSI#[-Yf9JQScK\M9FG]QSPQ_Y3I%JVbF]FPQS.P fiGHY3c2f`\_F]JVF^p dN8 K _,3Hvvx2`x(" J 2 %<%KJ%Y3TOI7vr"ff_v Y3TOKNuQwvOE_v 'OF][F]bv p+xyy +(bbF\SF]N8KI(J"Z:FKaJW#bFPUKIOMlJT#F!P/W#eOPVF]J"PVF\SFGHJQ_Y3IfObYeO\_FcRI , > /j V J 3 % [N :9 9 p ] " J "!vQ dN ]V 8 "6 J 1" 2J 33vfOfx~u?x `x~y{FKab/IOP]v _v r KI9PVY3W#bv +Up+xyy3 KPVJ]vRqnYJVJVY3c fiW#f}hFG]QSPQ_Y3I"bF]F db/W9IOQSI#[5K\_[Y fibQ_JT9c jUQSJT UFKab fifif9JQScK\[FI9F]b/K\SQ_KaJQ_Y3I +I ,L 2 /W V J 3 %/[N 9 p ] " J "!Q dN ]V 8 "6 J 0 " 2J 3v`f9fO~|y {~3(FKab/IOP]v _v Qwv _v BQ_JVJ]v _v r dK\SQSKI(J]v up+xy3OfiI!JT9FB\_FKab/IOKaeOQS\SQ_J)XUYZ#emY{Y3\_FKIZ:Yb/c-W9\SKaF+I, > /j V J 3 % 9 ;Q 8 69%eJ $ZT ONRQfT$ J 3v9f9f#~ {~y {Y3T9KN{QDvL}-_v r {Y3cc2F]b^9F\SMvn}-!p+xyy3 0Kab/[F]JVJQSI#[qLW9PQSI9FPPkW9PVF]b/P%jUQ_JT}hFG]QSPQSY3It"KaeO\_F\SKPPQ_^OF]b/P]a:,L 2 W V J 3 % ) p ] " J "!#Q dN H . fX ! W V23{ PJ % a]J P " ""% % vOf9f#~ +y {~ {KI9PVY3W#bv +_v r G \S\_FPVJVF]bvu}-pw~adqBY{Y3PVJQSI9[WOPQSI#[ffe9b/KI9GT9QSI#[fff9bY[b/KcP+5, > /j V J 3 %9 > %p H " J "!Q dN ]V qQfT$ " J "! " 2J 3 av f9f ~~a~~ +#Kab[3QSI#FKI(JW7v#}-_v r }fiQ_F]JVJVF]b/QgG/T7v#o p+xyy3 db/WOI9QSI#[!KMOKaf9JQ_NFfiemY(Y3PVJQgI#[#+5, > /j V J 3 % [N:9 ) p H " J "!cQ dN H 8 "6 J" 6J 33v9f9fO~ux?x {~ux{Q_JG/T#F\g\wv9op+xyy3 8 "6 J" 2J 33 G b/Kj fi "hQS\S\DY{G `vaE_v r KP/G]W#F\wva{p+xy3OfiI!\SFKab/I9QSI#["M9FG]QSPQ_Y3IGHY3ccQ_JVJVF]FP]{:,L 2 W V J 3 % 9 <p H " J "!cQ dN H 8 "5 J 1" 6J 33vOf9f( +9x 5+~au Yb[3KI KW#Z.cKI9I7Y{G `vE!_v r Kaf9f{Xv Rp+xyy3fiI5JT#F2fmYjnF]boYZLM#FG]QSPQ_Y3I5\SQgPVJP]+8,L 2 W V J 3 % [N 79p H " J "!cQ dN H 8 "5 J 1" 6J 33vOf9f( +9x 5+~au Yb[3KI KW#Z.cKI9I7hfOQSJVv9}ff_v r KG]\gQSI7v9Ep+xyyy3 YfOW9\SKabUFI9PVFcffeO\_Fc2F]JT#YuM9P 9K2P/W#bNF]X$ "! [N1;J dJ"!p ! !wJ 3(*" % " v 9 9avx|y `xy{fffiW#F]X{b/KI9I9Fv np+xyy3 QgI9QScQ_QgI#[PVX{cc2F]JVb/QSG2PW9eOc2YuM9W9\SKabfiZ.W9I9GHJQ_Y3I9P 8 " " J"! , _33 " TgJ 33v 2 < v `x~{fffiW9QgI9\SKI7v 9E!p+xyy +( Q) 1 !` 3 "fT %vNA "6 J ! " 2J 3 Yb/[3KI KW#Z.cKI9IfffiW9QgI9\SKI7v ELp+xyy|3qLKa[[3QSI#[#v qnY(Y3PJQSI#[iKIOM +# {l+B, > /j V J 3 % [N 59 > " J "!]Vp(3]#v9ff`~u3uQ dN ; J dJ"! ! !wJ:BC%$fiEUQgM#[F]jnKXv _v KM9Q_[3KI7v }-_v E QSG/T9KabM9PVY3I7v_v r KI#Fv np+xyy3I(JVF]bf9b/F]JKaeO\_FemY{Y3PVJVFMIOKQ_NFe`KXFP5G]\SKPPQS^OG]KaJQ_Y3I7 +I ,L 2 WV J 3 % [N ) p H " J "! Q 4N ]V. fX ! j V23( PUJ % a] J P " ""% % vOfOfx]#x?`x]+#EUQSNFPVJ]vOEp+xy3 FKabI9QSI#[M#FG]QgPQ_Y3I\SQSPJP] 8 "6 J 0 " 2J 3v < v`~~y{~+|{uGT9KafOQ_bFv E "_v #bFW9IOM7v +_v qLKabJ\SF]JVJ]v _v r F]Fv dnp+xyy3qnY{Y3PVJQSI#[JT#F Kab/[3QSI KI9F]j FHufO\SKI9KaJQ_Y3I ZYb%JT#FlF *mFGHJQ_NFI#FP/PYZ hYJQSI#[c2F]JT#YuM9P] ;+ "! %/ON)% " J % J % v <" vx| u?x `x||{uGT9KafOQ_bFv#E!! U_v r uQSI#[F]bv +p+xyy3R+c2f9bYNFMkemY(Y3PVJQgI#[-K\S[Yb/Q_JT9cPLW9P/QSI#[GHY3I#^OM#FI9GHF fiDbKaJVFMfObFM9QSGHJQ_Y3IOP]8, 2 /j V J 3 % [N 79 9 -p ] " J "! Q dN ]V Q$ " J "!0 " 2J 3 8v`f9fOa {yuxadK\SQSKI(J]v p+xy +( JT#F]Yb/XYZdJT#Fff\SFKab/I9KaeO\_F QfTgT $ 2J" J % [N ;:Q 8 v <@ vxx +Cxx +~{dK\SQSKI(J]v Up+xy 3 FKab/I9QgI#[M9QSP W9I9GHJQ_Y3IOPYZfiGHY3I VWOI9GHJQ_Y3I9P]I , > /j V J 3 % [Np H " J "! J Q dN H ; J J "! p ! !\J 3{ Hv9fOf |a &||{:5QfiJournal Artificial Intelligence Research 17 (2002) 333-361Submitted 2/2002; published 11/2002New Technique Combining Multiple Classifiers usingDempster-Shafer Theory EvidenceAhmed Al-AniMohamed Derichea.alani@qut.edu.aum.deriche@qut.edu.auSignal Processing Research CentreQueensland University TechnologyGPO Box 2434, Brisbane, Q 4001, AustraliaAbstractpaper presents new classifier combination technique based DempsterShafer theory evidence. Dempster-Shafer theory evidence powerful methodcombining measures evidence different classifiers. However, sinceavailable methods estimates evidence classifiers limitations,propose new implementation adapts training data overall meansquare error minimized. proposed technique shown outperform availableclassifier combination methods tested three different classification problems.1. Introductionfield pattern recognition, main objective achieve highest possible classification accuracy. attain objective, researchers, throughout past decades,developed numerous systems working different features depending upon application interest. features extracted data different typeslike continuous variables, binary values, etc. such, classification algorithm usedspecific set features may appropriate different set features. addition,classification algorithms different theories, hence achieve different degreessuccess different applications. Even though, specific feature set used specificclassifier might achieve better results obtained using another feature set and/orclassification scheme, conclude set classification scheme achievebest possible classification results (Kittler, Hatef, Duin, & Matas, 1998). differentclassifiers may offer complementary information patterns classified, combining classifiers, efficient way, achieve better classification results singleclassifier (even best one).explained Xu et al. (1992), problem combining multiple classifiers consiststwo parts. first part, closely dependent specific applications, includes problemsmany type classifiers used specific application?,classifier type features use?, well problemsrelated construction individual complementary classifiers. secondpart, common various applications, includes problems related questioncombine results different existing classifiers better resultobtained?. work, concentrating problems related second issue.c2002AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiAl-Ani & Dericheoutput information various classification algorithms categorizedthree levels: abstract, rank, measurement levels. abstract level,classifier outputs unique label, case syntactic classifiers.rank level, classifier ranks labels subset labels queue labeltop first choice. type discussed Ho et al. (1994).measurement level, classifier attributes class measurement value reflectsdegree confidence specific input belongs given class. Among three levels,measurement level contains highest amount information abstract levelcontains lowest. reason, adopted, work, measurement level.Kittler et al. (1998) differentiated two classifier combination scenarios.first scenario, classifiers use representation input pattern.hand, classifier uses representation input pattern secondscenario. illustrated first case, classifier considered produce estimate posteriori class probability. However, second caselonger possible consider computed posteriori probabilities estimatesfunctional value, classification systems operate different measurement systems. Kittler et al. (1998) focused second scenario, conductedcomparative study performance several combination schemes namely; product,sum, min, max, median. assuming joint probability distributions conditionally independent, found sum rule gave best results. well knownapproach used combining results different classifiers weightedsum, weights determined Bayesian decision rule (Lam & Suen,1995). alternative method presented Hashem & Schmeiser (1995), costfunction used minimize mean square error (MSE) order calculate linearcombination corresponding outputs number trained artificial neural networks (ANNs). expectation maximization algorithm used Chen & Chi (1998)perform linear combination. fuzzy integral used Cho & Kim (1995a,1995b) combine multiple ANNs, (Rogova, 1994; Mandler & Schurmann, 1988)used Dempster-Shafer theory evidence combine result several ANNs. Manycombination methods also used combine classifiers, baggingboosting (Dietterich, 1999), powerful methods diversifying combiningclassification results obtained using single classification algorithm specific featureset. bagging, get family classifiers training different portions trainingset. method works follows. first create N training bags. single training bagobtained taking training set size sampling training set timesreplacement. training instances occur multiple times bag, others mayappear all. Next, bag used train classifier. classifierscombined. Boosting, hand, based multiple learning iterations.iteration, instances incorrectly classified given greater weight next iteration. so, iteration, classifier forced concentrate instancesunable correctly classify earlier iterations. end, trained classifierscombined.paper, focus combining classification results obtained using N differentfeature sets, f 1 , , f N . feature set used train classifier, henceN different classifiers, c1 , , cN . specific input x, classifier cn produces334fiA New Technique Combining Multiple ClassifiersFeatureExtraction1f1Classifier1c1CombinationxFeatureExtractionNfNClassifierzyNcNFigure 1: multi-classifier recognition systemreal vector yn = [y n (1), n (k), n (K)]T , K number class labelsn (k) corresponds degree cn considers x label k. degree couldprobability, Bayesian classifier, scoring system. Fig. 1 showsblock diagram multi-classifier recognition system.Unlike statistical-based combination techniques, Dempster-Shafer theory evidenceability represent uncertainties lack knowledge. quite importantproblem classifier combination, usually certain level uncertaintyassociated performance classifiers. Since available classifier combination methods based theory accurately estimate evidence classifiers,paper attempts solve issue proposing new technique based gradientdescent learning algorithm, aims minimizing MSE combined output target output given training set. Aha (1995) gave following definitionlearning:Learning denotes changes system adaptive senseenable system task tasks drawn populationeffectively next time.Based above, show instead attempting find analytical formulaaccurately measures evidence, one obtain good estimate evidence usingappropriate learning procedures, discussed later.basic concepts Dempster-Shafer theory evidence presentednext section. Section three discusses existing methods computing evidence.proposed combination technique presented section four. Section five comparesproposed algorithm conventional methods used Kittler et al. (1998), fuzzyintegral, previous implementation Dempster-Shafer theory. Section six providesconclusion paper.2. Dempster-Shafer Theory EvidenceDempster-Shafer (D-S) theory evidence (Shafer, 1976) powerful tool representing uncertain knowledge. theory inspired many researchers investigate335fiAl-Ani & Derichedifferent aspects related uncertainty lack knowledge applications reallife problem. Today, D-S theory covers several different models, theoryhints (Kohlas & Monney, 1995) transferable belief model (TBM) (Smets, 1998).latter adopted paper represents powerful tool combiningmeasures evidence.Let = {1 , ....., K } finite set possible hypotheses. set referredframe discernment, powerset denoted 2 . Following basic conceptstheory:Basic belief assignment (BBA). basic belief assignment function assignsvalue [0, 1] every subset satisfies following:Xm() = 0,m(A) = 1(1)worth mentioning m() could positive considering unnormalized combination rule explained later. probability theory measure probabilityassigned atomic hypotheses , m(A) part belief supports A,support anything specific, i.e., strict subsets A. 6= , m(A) reflects ignorance belief cannot subdivide finer subsets. m(A) measuresupport willing assign composite hypothesis expense supportm(i ) atomic hypotheses . subset m(A) > 0 called focal element.partial ignorant associated leads following inequality: m(A) + m(A) 1,compliment A. words, D-S theory evidence allows usrepresent actual knowledge without forced overcommitignorant.Belief function. belief function, bel(.), associated BBA m(.) functionassigns value [0, 1] every nonempty subset B . called degree beliefB definedXbel(B) =m(A)(2)ABconsider basic belief assignment generalization probability density function whereas belief function generalization probability function.Combination rule. Consider two BBAs m1 (.) m2 (.) belief functions bel1 (.)bel2 (.) respectively. Let Aj Bk focal elements bel1 bel2 respectively.m1 (.) m2 (.) combined obtain belief mass committed C accordingfollowing combination orthogonal sum formula (Shafer, 1976),Xm1 (Aj )m2 (Bk )m(C) = m1 m2 (C) =j,k,Aj Bk =C1Xj,k,Aj Bk =336,m1 (Aj )m2 (Bk )C=6(3)fiA New Technique Combining Multiple Classifiersdenominator normalizing factor, intuitively measures much m1 (.)m2 (.) conflicting. Smets (1990) proposed unnormalized combination rule:Xm1 (Aj )m2 (Bk ), C(4)m12 (C) =Aj Bk =Crule implies m() could positive, case reflects kind contradiction belief state. work consider m() = 0 usenormalized combination rule. comparison normalized unnormalized combination rules problem combining classifiers considered future.Combining several belief functions. combination rule easily extendedseveral belief functions repeating rule new belief functions. Thus pairwiseorthogonal sum n belief functions bel1 , bel2 , , beln , formed((bel1 bel2 ) bel3 ) beln =nbeli(5)i=1Notation. According Smets (2000), full notation bel related functions is:<belY,t[ECY,t ](w0 A) = xrepresents agent, time, frame discernment, < boolean algebrasubsets , w0 actual world, subset , ECY,t agent knowst. Thus, expression denotes degree belief held w0belongs set worlds equal x. belief based evidential corpusECY,t held t.practice, many indices omitted simplicity sake. Usually < power set, 2 . bel defined 2 , < explicitly stated. w0 denotedA. and/or omitted values missing elements clearly definedcontext. Furthermore, EC usually conditioning event. So, bel(A) oneoften used notations (Smets, 2000). proposed method, adoptfollowing notation: beln (k ), agent classifier, subsets concernclass labels.important mention combination rule given Eq. 3 assumesbelief functions combined independent. Consider certain informationwould like measure belief, think process mappingoriginal information level belief level. Liu & Bundy (1992) explainedindependence original information level would lead independence belief level.But, two independent belief functions rooted original information level,original information may may independent. problem combiningmultiple classifiers, original information level consists outputs classifierscombined, belief level consists evidence classifiers (or BBAs).assumption BBAs independent, whether obtained independentdependent original information, hence justify use D-S theory. fact, many337fiAl-Ani & Dericheexisting classifier combination methods assume classification results different classifiers independent (Mandler & Schurmann, 1988; Hansen & Salamon, 1990; Xu et al.,1992). Since classifiers evidence plays crucial role combination performance,increased interest proper estimation evidence. next section,discuss number existing classifier combination methods estimate evidenceclassifiers, section 4 present proposed method.3. Existing Methods Computing EvidenceMandler & Schurmann (1988) proposed method transforms distance measuresdifferent classifiers evidence. achieved first calculating distancelearning data sets number reference points order estimate statistical distributions intra- interclass distances. both, posteriori probability functionestimated, indicating degree input pattern belongs certain referencepoint. Then, class label, class conditional probabilities combinedevidence value ranging 0 1, considered BBA class.Finally, Dempsters combination rule used combine BBAs different classifiers give final result. explained Rogova (1994), method brought forwardquestions choice reference vectors distance measure. Moreover, approximations associated estimation parameters statistical models intra-interclass distances lead inaccurate measure evidence.Xu et al. (1992) used K + 1 classes perform classification task,(K + 1)th class denotes classifier idea class input comesfrom. classifier cn , n = 1..N , recognition, substitution, rejection rates (nr , ns ,1 nr ns ) used measure BBA, mn , follows:1. maximum output specific classifier belongs K + 1, mnfocal element mn () = 1.2. maximum output belongs one K classes, mn two focal elementsk k mn (k ) = nr , mn (k ) = ns . classifier says nothingpropositions, mn () = 1 mn (k ) mn (k ).drawback method way evidence measured. two problemsassociated method. Firstly, many classifiers produce binary outputs,rather probability like outputs. So, first case, inaccurate assign 0mn (k ) mn (k ). Secondly, way measuring evidence ignores fact classifiersnormally performance different classes. clear impactperformance combination method compared conventionalmethods especially Bayesian (Xu et al., 1992).Rogova (1994) used several proximity measures reference vector classifiers output vector. proximity measure gives highest classification accuracylater transformed evidences. reference vector used mean vector, nk ,output set classifier cn class label k. number proximity measures,dnk , nk yn considered. classifier, proximity measure class338fiA New Technique Combining Multiple Classifierstransformed following BBAs:mk (k ) = dnk ,mk () = 1 dnkmk (k ) = 1 (1 dnl ), mk () =(1 dnl )l6=kl6=kevidence classifier cn class k obtained combining knowledgek , thus mk mk . Finally, Dempsters combination rule used combine evidencesclassifiers obtain measure confidence class label. Note firstcombination performed respect class label (Rogova used notations kk), second one agent n. idea promising one. However,major drawback way reference vectors calculated, mean outputvectors may best choice. Also, trying several proximity measures choosingone gives highest classification accuracy questionable.4. Proposed Combination Techniquesection estimate value mn (k ), represents belief class labelk produced classifier cn . addition, also estimate mn (), reflectsignorance associated classifier cn . Since ultimate objective minimizeMSE combined classification results target output, mn (k ) mn ()estimated using iterative procedure aims attaining objective.first compare yn , output classification vector produced classifier cn ,reference vector, wkn , obtained distance used estimate BBAs.BBAs combined obtain new output vector, z, represents combinedconfidence class label. wkn measured MSE ztarget vector, t, training dataset minimized. Note two indices wkn .Thus, class label k, dont consider value assigned classifier cn ,rather whole output vector (values assigned class label).Let frame discernment = {1 , k , , K }, k hypothesisPinput x class k. Considering BBA, mn , mn (k ) 0, mn () =1 Kk=1 mn (k ), mn 0 elsewhere. Let dn (k ) distance measure gnunnormalized ignorance classifier cn , mn (k ) mn () estimated accordingfollowing formulas:(6)dn (k ) = exp(kwkn yn k2 )mn (k ) =dn (k )KX(7)dn (k ) + gnk=1mn () =gnKX(8)dn (k ) + gnk=1mn (k ) mn () normalized values dn (k ) gn respectively. Similarwkn , minimized MSE used estimate gn .339fiAl-Ani & DericheEvidences classifiers combined according normalized combination ruleobtain measure confidence class label. k th element new combinedvector given by:z(k) = m(k ) = m1 (k ) mN (k ) =mn (k )(9)nNLgiven classifier cn , let = {1 N } \ {n}, mI = iI mi , Eq. 9 writtenas:z(k) = mI (k ) mn (k )(10)according Eq. 3, combination two BBAs is:mj (k ) ml (k ) =mj (k )ml (k ) + mj (k )ml () + mj ()ml (k )XX1mj (p )ml (q )p(11)qq6=pwkn gn initialized randomly, values adjusted accordingtraining dataset MSE z minimized.Err = kz tk2(12)values wkn gn adjusted according formulas:Errwkn [old]Errgn [new] = gn [old]gn [old]wkn [new] = wkn [old](13)(14)learning rates. terms Err/wkn Err/gn derivedfollows:ErrwknErrgn==Err z(k) mn (k )z(k) mn (k ) wknErr z(k) mn (k )z(k) mn (k ) gn340(15)(16)fiA New Technique Combining Multiple Classifierswhere,Err= 2[z(k) t(k)](17)z(k)("#XXz(k)=1mn (p )mI (q ) [mI (k ) + mI ()] + [mn (k )mI (k ) +mn (k )pqq6=p"mn (k )mI () + mn ()mI (k )]#),XmI (p )pp6=k#2"1XXpmn (p )mI (q )(18)qq6=pX2 exp(kwkn yn k2 )[wkn yn ][dn (p ) + gn ]pmn (k )=wknp6=kX[dn (p ) + gn ]2(19)pmn (k )dn (k )=Xgn[dn (p ) + gn ]2(20)pFig. 2 shows flow chart learning procedures. found adjustingvalues gn achieved first iterations. continuing trainingfine-tune values wkn improvement training set,reach pre-defined maximum number epochs1 , result could enhanced.Note weight values adjusted pattern (not batch training). fixvalue = 106 , first initialized 5 104 , changed accordingvalue MSE, described flow chart.Although computational cost involved implementing technique highercombination methods2 , need perform training once,done off-line. Then, optimal values wkn gn , perform on-linecombination, comparable combination methods.hand, indicated beginning section, consider referencevector, wkn , class. leads increase training time number classesand/or classifiers increases. alternative consider using reference valueclass, wkn . save 50% training time case severalclassifiers classes. Note learning formulas applicable replacing wknwkn yn ykn . refer two alternative approaches DS1 DS2,respectively. following section, compare DS1 DS2 well-knowncombination methods.1. maximum number epochs set 50 experiments described paper2. Training time experiments conducted section 5 required less 3 minutesconventional PC341fiAl-Ani & DericheStartTh=Errnew =Errold =It_no =It_nomax=Randomly initializewkn g nn =1: N, k =1: KInitialize learningrates-4-6=510 , =10error thresholdcurrent MSEprevious MSEcurrent no. iterationsmax. no. iterationspatternIt_no=It_no+1Errold = ErrnewComputemn(k ) mn()Adjustwkn g nComputez ErrnewYesErrold -Errnew>Th= 1.03= 0.7YesIt_no<It_nomax-4> 10EndFigure 2: Training procedure proposed techniqueworth mentioning although training procedures proposedmethod backpropagation algorithm ANN based minimizing MSE usingiterative approaches, proposed method ANN similar. backpropagationtraining operates passing weighted sum input activation function,usually multi-layer architecture known multi-layer perceptron (MLP). Extractingrules trained MLP challenging problem. hand, trainingproposed method operates measuring distance classification vectorreference vector. distance would later used measure belief classlabel classifiers. final confidence class label obtained combiningbeliefs classifiers. Unlike MLP, belief given class label classifierindicates contribution towards final confidence. reader may refer (Denoeux,2000) description ANN classifier based D-S theory.342fiA New Technique Combining Multiple Classifiers5. Performance Analysis Different Combination Methodsfollowing three classification problems considered: texture classification,classification speech segments according manner articulation, speakeridentification. ANNs used perform classification three problems.case, classifiers sorted according performance, best classifierreferred c1 , 2nd best c2 , worst one cN .problem, consider different number classes, combine resultsdifferent number classifiers, combining results best, worst mixturesbest worst classifiers investigated. example, five classifierswould like combine two these, consider combining best two,{c1 , c2 }, best one worst one, {c1 , c5 }, worst two classifiers, {c4 , c5 }. followingcombination methods tested: weighted sum (WS)3 , average (Av), median (Md),maximum (Mx), majority voting (MV), fuzzy integral (FI) (Cho & Kim, 1995a) 4 , RogovasD-S method (DS0) (Rogova, 1994), proposed method two alternatives (DS1& DS2). training set used train ANNs used estimate confusionmatrix WS FI, well estimate evidence DS0, DS1, DS2.Two measures used compare performance different combinationmethods, namely: overall performance error reduction rate (ERR). overall performance mean classification accuracy obtained combining considered subsets2, , N classifiers. ERR percentage error reduction obtained combiningclassifiers reference best single classifier:ERR =ERBSC ERCC100ERBSC(21)ERBSC error rate best single classifier ERCC error rate obtained combining considered classifiers. Unlike classification accuracy, ERR clearlyshows performance combined classifiers improves deteriorates comparedbest single classifier. words, shows merit performing combination. specifically concentrate maximum ERR obtained combiningconsidered subsets 2, , N classifiers. addition, also investigatevalue ERR gets affected increasing number combined classifiers.5.1 Texture ClassificationSeveral experiments carried classification texture images.textures considered are: bark, brick, bubbles, leather, raffia, water, weave, woodwool (USC, 1981). order obtain better comparison different combinationmethods, considered classifying first two textures, first three, first fivefinally nine textures. Additive Gaussian noise, different signal-to-noise ratio,added (1024 1024) pixels image texture class form trainingtesting sets. 961 patterns obtained image using (64 64) windowsoverlap 32 pixels.3. weights classifier determined according classification accuracy class labelusing training dataset4. reader may refer Appendix brief description method343fiAl-Ani & DericheNo. classes2359SDH186.9684.5885.1080.97SDH285.7384.5284.6277.44SDH384.4483.9184.3477.51SDH485.4586.2483.4675.72En91.1489.7288.8483.65Table 1: Texture classification accuracy five original classifiers different numberclass labelsFour nine-feature vectors calculated using statistics sum difference histogram(SDH) co-occurrence matrix different directions, vertical (SDH1 ), horizontal(SDH2 ), two diagonals (SDH3 SDH4 ) . direction, features usedwere: mean, variance, energy, correlation, entropy, contrast, homogeneity, cluster shade,cluster prominence. fractal dimension (FD) also used form tenthfeature vector. energy contents texture images (En) used formanother feature vector using 9 different masks. tenth feature FD.five feature vectors used input ANN. numberstraining testing patterns depend upon number classes considered, i.e. casetwo classes, 15376 patterns used train networks 5766 test them.results obtained shown Table 1. Note number classes increasesoverall accuracy decreases. addition, performance En classifiers foundbetter four.No. classes2359WS89.1688.5289.6084.96Av89.0488.3989.4184.55Md87.6687.4187.9983.37Mx90.1288.8689.2382.90MV88.0987.3087.8383.23FI90.0888.7190.2886.76DS088.7088.4089.5284.87DS190.6690.2192.6989.83DS290.7290.0891.5086.79Table 2: Overall performance various combination methods different numberclass labels (texture classification)overall performance tested combination methods different number classlabels shown Table 2. case 2 classes, clear overall performancesDS1 DS2 better combination methods. mixturesgood bad classifiers considered, performance combination methods, exceptDS1 DS2, closer worse best single classifier. shownTable 3 combination {c1 , c3 , c4 , c5 }, {c1 , c4 , c5 }, {c1 , c5 }, etc5 . 3 5classes considered, DS1 performs slightly better DS2, outperformmethods. gap DS1 methods gets wider 9 classesconsidered. superiority DS1 reflects advantage using whole output vectormeasuring evidences classifiers.5. reader may refer Appendix B detailed results cases344fiA New Technique Combining Multiple ClassifiersClassifiersc1 , c2c1 , c5c4 , c5c1 , c2 , c3c1 , c2 , c5c1 , c4 , c5c3 , c4 , c5c1 , c2 , c3 , c4c1 , c2 , c3 , c5c1 , c2 , c4 , c5c1 , c3 , c4 , c5c2 , c3 , c4 , c5c1 , c2 , c3 , c4 , c5WS92.5691.1685.0791.2191.0389.8085.3889.9489.7089.7288.5786.0788.81Av92.5991.1285.0791.2190.8189.5985.3889.7089.4289.4988.4586.1188.54Md92.5991.1285.0788.9288.6886.2185.4787.8487.5387.3786.3085.8786.63Mx92.5191.0985.2291.6291.4891.2185.4091.4791.4291.4891.0986.2591.33MV92.5191.0985.2288.9288.7186.2185.4889.1389.0488.9487.0386.2686.59FI92.6191.0085.0791.6991.4891.2485.3391.5991.2991.4090.9886.1391.21DS092.4091.3385.1590.8190.4388.8885.2289.1388.9289.0087.8185.9388.10DS192.4691.6285.1092.4092.4791.6885.4392.2192.3292.2591.7886.6692.21DS292.4691.6185.1292.5392.3991.7885.4092.3392.4292.2691.8786.8092.33Table 3: Classification accuracy texture images using different combination methods (2textures)best ERR values WS, FI, DS0, DS1 DS2 determined according Eq.21. Since WS widely used literature, outperforms conventionalmethods (Av, Md, Mx, MV), observed Table 2, use representative conventional methods performing comparison FI, DS0, DS1DS2. Figure 3a shows ERR values 2 classes considered. clearmaximum ERR values five combination methods close, ranging14% 16%. obtained combining best two classifiers WS, FI DS0,DS1 DS2 use three classifiers obtain maximum ERR. mentionedearlier, performance first four individual classifiers weakerEn. Notice that, DS1 DS2, significant degradation ERRnumber combined classifiers increases.case 3 classes, DS1 DS2 outperform combination methodsterms maximum ERR. achieve values 17.3% 19.6% respectively,compared 11.4% less methods shown Figure 3b. addition, ERRDS1 DS2 affected number combined classifiers increases.case 5 classes, maximum ERR values sorted descending order are:DS1 50.7%, DS2 40.2%, FI 31.6%, WS 28.1%, DS0 23.8%, shown Figure 3c.addition, ERR values DS1 improve number combined classifiers increases, DS2second best, ERR values methods degrade number combinedclassifiers increases. case 9 classes, superiority DS1 becomes clearer,shown Figure 3d, maximum ERR value DS1 54% compared 37.5% lessmethods. worth mentioning even though maximum ERR valuesmethods degrade, still perform better best single classifier. leadsus conclude number classes increases, performance classifiercombination methods gets better overall.345fiAl-Ani & Deriche203010200101002010(a) 2 classes(b) 3 classes20WSFIDS0DS1DS2ERR3050504040303020201010(c) 5 classes022.533.544.55(d) 9 classes22.533.544.55No. combined classifiersFigure 3: ERR different classifier combination methods obtained considering differentnumber classifiers cases: (a) 2 classes, (b) 3 classes, (c) 5 classes,(d) 9 classesTaking facts consideration, sort methods descending orderfollows: DS1, DS2, FI, WS, DS0, conventional methods. Thus, summary,problem texture classification, proposed technique two alternatives(DS1 DS2) clearly outperforms standard combination methods increaseclassification accuracy 2 7%. cases 2 3 classes, littledifference performance DS1 DS2. using reference vectorssmall size, 2 1 3 1, make big impact upon estimation evidencecompared obtained using single reference value. size reference vectorincreases, 5 1 9 1 two cases, impact estimating evidencebecomes clearer, leads better results, cost increasing computationalload.5.2 Speech Segment ClassificationSix different input feature sets used classify speech segments accordingmanner articulation, were: 13 mel-frequency cepstral coefficients (MFC), 16 logmel-filter bank (MFB), 12 linear predictive cepstral coefficients (LPC), 12 linear predictive346fiA New Technique Combining Multiple ClassifiersNo. classes369MFC88.2183.1678.48MFB90.9885.5083.24LPC81.6474.7771.64LPR80.6974.0670.03WVT90.6484.3381.33ARP70.8762.9056.66Table 4: Speech segment classification accuracy six original classifiers differentnumber class labelsreflection coefficients (LPR), 10 wavelet energy bands (WVT), 12 autoregressive modelparameters (ARP). experiment, speech obtained TIMIT database(MIT, SRI, & TI, 1990). Segments 152 speakers (56456 segments) used trainANNs, 52 speakers (19228 segments) test them. Three cases considered:3 classes (vowel, consonant, silence), 6 classes (vowel, nasal, fricative, stop, glide,silence), finally 9 classes (vowel, semi-vowel, nasal, fricative, stop, closure, lateral,rhotic, silence). classification results three cases summarized Table4.No. classes369WS90.8085.5483.05Av90.4184.9182.31Md90.2084.6281.93Mx86.1581.1675.63MV89.5184.0381.00FI90.6585.2982.73DS090.9085.1882.86DS191.5787.1885.20DS291.3186.3784.22Table 5: Overall performance various combination methods different numberclass labels (speech segment classification)two best individual classifiers MFB WVT three cases, followedMFC methods. Unlike texture classifiers one good classifier four,relatively, weak classifiers, three good classifiers (MFB, MFC WVT)three weak classifiers (LPC, LPR ARP).overall performance values various combination methods displayedTable 5. case 3 classes, seen overall performance DS1better DS2 outperform methods. becomes evenclearer number classes increases (with 2% increase accuracy).ERR values case 3 classes shown Figure 4a. maximum ERRvalue DS1 23.4%, achieved combining six classifiers, compared 20.3%DS2 19.6% less methods. gap DS1methods gets wider consider 6 9 classes shown Figures 4b 4c.good classifiers experiment compared textureexperiment, variations ERR values number classifiers increasesfound smaller. addition, see number classes increases DS1 keepssteady superior performance terms ERR 10% increase.summary, DS1 outperforms methods terms overall performanceERR measurements. followed DS2, WS, rest methods.347fiAl-Ani & Deriche2525202015151010(b) 6 classes(a) 3 classes5234562345625ERR20WSFIDS0DS1DS21510(c) 9 classes523456No. combined classifiersFigure 4: ERR different classifier combination methods obtained considering differentnumber classifiers cases: (a) 3 classes, (b) 6 classes, (c) 9 classes5.3 Speaker IdentificationThree limited-scope experiments carried perform speaker identification using 2,3, 4 speakers. Speech data TIMIT database also used (MIT et al., 1990).number training patterns 3232, 4481 5931 respectively, numbertesting patterns 1358, 1921 2542 respectively. features used classifyspeech segments according manner articulation used identify speakers.Classification results six classifiers shown Table 6. performanceindividual classifiers quite similar speech segment problem, threegood classifiers are: MFB, MFC LPC three weak classifiers are: LPR, WVTARP.overall performance various combination methods shown Table 7.case 2 classes, clear overall performance combination methodscomparable. superiority DS1, lesser degree DS2, becomes clearnumber classes increases (more patterns included estimate evidence).Note that, high performance individual classifiers case 2classes, small difference performance combination methods great impactERR, explains graphs fluctuations, shown Figure 5a. seen348fiA New Technique Combining Multiple ClassifiersNo. classes234MFC94.5885.8485.01MFB96.1787.2585.96LPC92.4982.2080.84LPR89.6081.0077.97WVT87.8074.3970.93ARP84.5573.0364.59Table 6: Speaker identification accuracy six original classifiers different numberspeakersNo. classes234WS95.5390.8083.05Av95.5090.4182.31Md95.2690.2081.93Mx95.3686.1575.63MV95.2189.5181.00FI95.2590.6582.73DS095.4690.9082.86DS195.4891.5785.20DS295.4591.3184.22Table 7: Overall performance various combination methods different numberclass labels (speaker identification)maximum ERR overall performance combination methods close.results favor DS1 DS2, additional computationalcost. Lets consider case 3 classes, Figure 5b shows maximum ERRDS2 highest followed DS1, outperform methods.case 4 classes, maximum ERR DS1 30%, compared 27% lessmethods, shown Figure 5c. figure also shows ERR values DS2 WSclose. However, overall performance DS2 better WS, DS2considered second best method followed WS, DS0 finally FI.results clearly show performance DS1 DS2 get affectednumber training patterns, crucial achieving good estimation evidenceclassifier. clear case 2 speakers. performance, however, getbetter number speakers training patterns increase. words, DS1DS2 require larger number patterns work properly. Failing provide numberpatterns, conventional methods, WS, achieve similar performance.experiments textures, speech segments speaker classification showproposed technique clearly outperforms methods terms overall performanceERR, providing sufficient number patterns estimate evidence classifiersexists. Also, among different combination methods, DS1 DS2 least effectedinclusion weak classifiers. experiments also show BBAs couldbetter estimated using reference vectors rather reference values, especially largenumber classes.worth mentioning one combination methods merit.example, MV useful combination method dealing classifiersproduce results abstract level. working measurement level, combination methods could better performance.Mx method provide good results performance combined classifiers close. case, classifier higher confidence provide better results349fiAl-Ani & Deriche402035153010255200(a) 2 classes(b) 3 classes155234562345630ERR25WSFIDS0DS1DS2201510(c) 4 classes523456No. combined classifiersFigure 5: ERR different classifier combination methods obtained considering differentnumber classifiers cases: (a) 2 classes, (b) 3 classes, (c) 4 classesindividual classifier. shown Tables 11-13 (refer Appendix B),good results achieved combining best two three classifiers speechsegment experiment compared best individual classifier. However, cleardifference performance classifiers, case considering mixtures goodbad classifiers, using Mx combine classification results goodchoice. case dont information performance classifiers, i.e.,training dataset, Av Md methods could provide attractive choice.Similar findings (Kittler et al., 1998; Alkoot & Kittler, 1999), performancetwo methods found close slight favor Av method. classification accuracy different classifiers available, WS method representsgood choice, outperforms Av almost conducted experiments.expected, associating classifier weight reflects performance, wouldmake better classifier contributes towards final decision. performancecombined classifiers close, combining results using AvWS methods would lead similar performance, shown Tables 11-13cases combining best two three speech segment classifiers.FI DS0 represent two non-linear combination methods. According (Cho &Kim, 1995a), performance FI slightly better WS tested using350fiA New Technique Combining Multiple Classifiersoptical character recognition database, similar results obtainedtexture experiments. However, speech segment classification speaker identificationexperiments, performance FI good WS. hand,experiments conducted show WS slightly outperforms DS0. Note Rogova(1994) compared DS0 original classifiers. main problem FIDS0 appropriate estimation parameters. example, desired sumfuzzy densities affects combination results FI, choice proximitymeasure reference vector plays important role performance DS0.DS1 DS2 differ DS0 appropriate measure reference vectors,hence accurate estimation evidence classifier. exploitcomplementary information provided different classifiers. words,accurate estimation evidence classifier lead minimizing MSEcombined results, hence resolving conflicts classifiers.6. Conclusiondeveloped work new powerful classifier combination technique basedD-S theory evidence. technique, based adjusting evidence differentclassifiers minimizing MSE training data, gave good results terms overallperformance error reduction rate. test algorithm, three experiments carriedout: texture classification, speech segments classification, speaker identification.experiments showed superiority proposed technique comparedconventional methods, fuzzy integral, another D-S implementation uses differentmeasure evidence. shown accurate estimation evidence differentclassifiers based whole output vectors (DS1) gives best performance, especiallyhigher number class labels. drawback algorithm trainingcomputationally expensive (this used accurately estimate evidenceclassifier). However, executed off-line, such, major effectperformance algorithm. also shown proposed algorithm easilyachieve increase classification accuracy order 2% 7% comparedcombination methods. believe work enhancing technique,scheme form new framework pattern classification future.Acknowledgmentauthors wish thank Dr. J. Chebil Dr. M. Mesbah valuable commentspaper. authors also acknowledge support Queensland UniversityTechnology work presented paper. Dr. Deriche acknowledges supportKing Fahd University, Saudi Arabia, currently leave.Appendix A. Classifier Combination Based Fuzzy IntegralFuzzy integral non-linear combination method defined respect fuzzy measure.Detailed explanation classifier combination based g fuzzy measure foundwork Cho & Kim (1995a, 1995b).351fiAl-Ani & Derichefinite set elements, Z, g fuzzy measure (Sugeno, 1977) defined setfunction g: 2Z [0, 1] satisfies following conditions:1. g() = 0, g(Z) = 1,2. g(A) g(B) B,3. {Ai }i=1 increasing sequence measurable sets, limi g(Ai ) = g(limi Ai ),4. g(A B) = g(A) + g(B) + g(A)g(B)A, B Z B = , > 1. Let h : Z [0, 1] fuzzysubset Z. fuzzy integral Z function h respect fuzzy measure gdefinedh(z) g(.) = max min min h(z).g(E)EZ=zEmax [min(, g(F ))],[0,1]F = {z|h(z) }Let Z = {z1 , zn }, suppose h(z1 ) h(z2 ) h(zn ), (if not, Z rearrangedrelation holds). fuzzy integral e, respect fuzzy measure gZ computedne = max[min(h(zi ), g(Ai ))],i=1Ai = {z1 , zi }g(A1 ) = g({z1 }) = g 1g(Ai ) = g + g(Ai1 ) + g g(Ai1 ), 1 < nQgiven solving: + 1 = ni=1 (1 + g ), (1, ) 6= 0.calculated solving (n 1)st degree polynomial finding unique root greater1.problem combining classifiers, Z represents set classifiers, objectconsideration classification, hk (zi ) partial evaluation objectclass k . Corresponding classifier zi , degree importance, g , reflectsgood zi classification class k must given. densities inducedtraining dataset.352fiA New Technique Combining Multiple ClassifiersAppendix B. Tables Classification Accuracy Different CombinationMethodsClassifiersc1 , c2c1 , c5c4 , c5c1 , c2 , c3c1 , c2 , c5c1 , c4 , c5c3 , c4 , c5c1 , c2 , c3 , c4c1 , c2 , c3 , c5c1 , c2 , c4 , c5c1 , c3 , c4 , c5c2 , c3 , c4 , c5c1 , c2 , c3 , c4 , c5WS90.8989.6985.0589.9289.5589.0585.7689.2989.0788.8788.6086.4588.54Av90.7989.5785.0589.8389.3988.8085.7389.0788.8388.7888.3886.4488.47Md90.7989.5785.0588.0487.5486.9585.4987.9887.2487.3487.0586.1887.06Mx90.8389.6884.6790.4890.2389.6284.8190.1790.0190.0289.3985.5289.73MV90.1789.1084.8187.7787.0986.6285.4987.9187.5087.6187.5286.3187.03FI90.2288.9985.1389.8889.5689.2685.6789.8589.5889.6489.4486.3689.65DS090.8189.9285.5189.5989.1888.8085.9188.8288.8188.6688.3986.4688.29DS191.0990.4585.4991.2691.1290.7787.2791.4491.4891.1691.3188.3791.50DS290.8190.2985.4491.7391.1090.7386.8891.5191.5391.2691.0087.2091.61Table 8: Classification accuracy texture images using different combination methods (3textures)Classifiersc1 , c2c1 , c5c4 , c5c1 , c2 , c3c1 , c2 , c5c1 , c4 , c5c3 , c4 , c5c1 , c2 , c3 , c4c1 , c2 , c3 , c5c1 , c2 , c4 , c5c1 , c3 , c4 , c5c2 , c3 , c5 , c6c1 , c2 , c3 , c4 , c5WS91.9891.9585.1491.4990.7790.6186.2990.2690.1489.7390.3286.4189.65Av91.8791.7485.1991.2990.5090.3586.2290.0389.9189.4390.0686.3889.39Md91.8791.7485.1988.7887.9287.6785.4088.3788.1787.6287.9185.9987.27Mx90.2890.7284.7790.3990.3490.2985.9990.1290.2590.1990.5085.9890.11MV89.8989.5884.5088.6087.7487.4385.6488.9089.0088.4588.5185.7987.81FI92.2191.3084.9492.3591.5491.4185.9191.8691.8391.1191.8386.1591.22DS091.4591.5585.8291.0890.3290.2586.9889.9390.0989.4190.2087.2189.51DS193.4093.2786.2894.3793.6693.6989.1694.4894.4193.8294.5089.4794.46DS292.8192.7285.3693.1992.9692.9087.2993.1993.2692.5693.3386.9793.01Table 9: Classification accuracy texture images using different combination methods (5textures)353fiAl-Ani & DericheClassifiersc1 , c2c1 , c5c4 , c5c1 , c2 , c3c1 , c2 , c5c1 , c4 , c5c3 , c4 , c5c1 , c2 , c3 , c4c1 , c2 , c3 , c5c1 , c2 , c4 , c5c1 , c3 , c4 , c5c2 , c3 , c4 , c5c1 , c2 , c3 , c4 , c5WS88.4586.3979.5587.1086.4885.9280.2786.4285.7085.7985.4281.6085.33Av88.1385.9779.4086.5385.8585.3280.2185.9585.1185.3984.9281.4484.88Md88.1385.9779.4084.2083.6683.2279.6384.5683.3784.2983.0681.1583.19Mx85.4482.2778.7484.6584.0882.9779.5484.3383.9183.8383.4780.7583.74MV85.9183.0078.5384.6084.1783.6779.3885.1684.2684.9184.0881.0383.35FI89.7888.1879.3789.5188.7288.2579.9789.1888.5288.5288.3481.5488.02DS089.2687.1079.2887.0686.9285.9879.8085.9685.4185.9484.8181.0284.83DS191.4290.0781.2292.0092.1392.0182.4892.4592.0292.4892.3584.7092.43DS289.2088.0879.9188.5988.5388.3080.8988.7088.3088.6688.3582.1788.65Table 10: Classification accuracy texture images using different combination methods (9textures)Classifiersc1 , c2c1 , c6c5 , c6c1 , c2 , c3c1 , c2 , c6c1 , c5 , c6c4 , c5 , c6c1 , c2 , c3 , c4c1 , c2 , c3 , c6c1 , c2 , c5 , c6c1 , c4 , c5 , c6c3 , c4 , c5 , c6c1 , c2 , c3 , c4 ,c1 , c2 , c3 , c4 ,c1 , c2 , c3 , c5 ,c1 , c2 , c4 , c5 ,c1 , c3 , c4 , c5 ,c2 , c3 , c4 , c5 ,c1 , c2 , c3 , c4 ,c5c6c6c6c6c6c5 , c6WS92.3489.9981.0992.6392.1789.8584.9892.5992.6292.2590.1588.7992.7592.5792.7392.1491.4191.5192.62Av92.3488.1180.6592.6191.7988.7984.9692.5792.4791.9389.5188.4292.6492.4892.5091.7091.0490.9892.36Md92.3488.1180.6592.3791.8388.2084.7692.4292.5091.8289.3488.3092.2392.3092.2091.0790.6390.5292.24Mx92.3483.9576.1992.3485.9784.1779.3691.6486.9486.0184.6483.2591.4286.9686.9386.1985.7985.7386.95MV92.2282.6476.1092.2791.6087.5084.0892.0492.0291.9689.8488.4692.1391.9291.9190.9790.4190.6091.97FI91.8491.0682.0392.3692.0389.6684.8992.3892.4992.1489.4888.4692.4992.2592.5391.7190.9891.1592.38DS092.3890.9281.5492.6392.2790.3484.6292.6192.7392.3790.1288.7692.7492.5692.7692.2391.4691.5092.61DS192.4591.4882.2992.7992.5391.9285.6592.7792.7892.7791.9290.5193.0792.7793.0392.7892.4892.6793.09Table 11: Classification accuracy speech segments using different combination methods(3 classes)354DS292.2991.4282.0192.6792.2391.7985.3692.6492.5492.4991.8489.9492.8192.5692.7292.4692.1492.4092.64fiA New Technique Combining Multiple ClassifiersClassifiersc1 , c2c1 , c6c5 , c6c1 , c2 , c3c1 , c2 , c6c1 , c5 , c6c4 , c5 , c6c1 , c2 , c3 , c4c1 , c2 , c3 , c6c1 , c2 , c5 , c6c1 , c4 , c5 , c6c3 , c4 , c5 , c6c1 , c2 , c3 , c4 ,c1 , c2 , c3 , c4 ,c1 , c2 , c3 , c5 ,c1 , c2 , c4 , c5 ,c1 , c3 , c4 , c5 ,c2 , c3 , c4 , c5 ,c1 , c2 , c3 , c4 ,c5c6c6c6c6c6c5 , c6WS86.9784.3074.6088.0986.4884.3379.2788.0387.6486.5184.6183.8487.9087.5787.6986.7186.3686.7087.67Av86.9581.9873.9188.0885.7682.8078.7387.9187.1785.8483.6483.1287.8787.2487.1786.0085.8585.9587.33Md86.9581.9873.9187.7786.0181.8877.8487.8187.2685.9083.2882.8487.4486.9886.9185.5485.2685.1887.02Mx86.4677.9770.3887.1180.3878.6474.0786.5882.5980.5479.4779.2886.0182.7682.6481.2181.5081.6382.76MV86.3076.6670.2087.7685.3181.2477.2687.2986.9586.1083.8583.0587.3586.8586.9685.6385.5785.2386.95FI86.6785.0175.0087.5186.4983.8878.4687.6787.3786.6983.9783.2287.7287.3687.5286.4686.1086.0687.35DS086.6484.5274.2087.4986.4584.5678.5187.4887.2586.5984.2983.5687.3487.0887.3286.3985.9585.8186.98DS188.1286.7176.4788.7388.1987.1680.1788.9888.6188.4787.3886.0089.1588.9588.9388.6488.2688.3789.14Table 12: Classification accuracy speech segments using different combination methods(6 classes)355DS287.5986.3975.6888.1087.5086.4579.3988.0988.0887.5786.6884.9588.1588.1188.1287.5687.3887.2888.01fiAl-Ani & DericheClassifiersc1 , c2c1 , c6c5 , c6c1 , c2 , c3c1 , c2 , c6c1 , c5 , c6c4 , c5 , c6c1 , c2 , c3 , c4c1 , c2 , c3 , c6c1 , c2 , c5 , c6c1 , c4 , c5 , c6c3 , c4 , c5 , c6c1 , c2 , c3 , c4 ,c1 , c2 , c3 , c4 ,c1 , c2 , c3 , c5 ,c1 , c2 , c4 , c5 ,c1 , c3 , c4 , c5 ,c2 , c3 , c4 , c5 ,c1 , c2 , c3 , c4 ,c5c6c6c6c6c6c5 , c6WS84.5881.8570.4885.4184.2082.1875.9485.4485.3484.4882.4181.0285.5285.5385.5484.6083.9784.1485.32Av84.6178.5969.0485.4283.4480.2675.2385.3084.9783.7781.4480.5185.4385.0185.1684.0383.3283.4884.93Md84.6178.5969.0485.0083.5379.1974.4385.2084.9983.7781.0380.1584.9484.4184.7683.3482.7482.3284.70Mx83.7771.4862.8783.8174.1872.3267.2383.4176.4974.6173.6172.7482.9377.0476.6275.5175.8075.4077.08MV83.6670.5062.6585.0282.7077.8673.4684.9684.8283.9881.4979.8384.7784.5384.6683.6983.1682.6684.51FI84.0682.5371.2285.0084.1181.2075.3085.1185.1984.5881.6180.0685.4584.9685.3884.1783.6783.2985.07DS084.1582.5169.9785.3484.0182.5375.5485.1585.1484.5382.4480.4185.4285.0085.2584.4283.9183.4485.19DS186.1184.4173.2486.8586.0585.1078.2187.0586.7986.6785.6583.8687.3287.0987.1186.8286.5986.5587.26Table 13: Classification accuracy speech segments using different combination methods(9 classes)356DS285.6083.7271.9486.1585.4484.5676.9286.1386.1685.8684.7682.2586.3286.0986.2285.7885.4585.5685.23fiA New Technique Combining Multiple ClassifiersClassifiersc1 , c2c1 , c6c5 , c6c1 , c2 , c3c1 , c2 , c6c1 , c5 , c6c4 , c5 , c6c1 , c2 , c3 , c4c1 , c2 , c3 , c6c1 , c2 , c5 , c6c1 , c4 , c5 , c6c3 , c4 , c5 , c6c1 , c2 , c3 , c4 ,c1 , c2 , c3 , c4 ,c1 , c2 , c3 , c5 ,c1 , c2 , c4 , c5 ,c1 , c3 , c4 , c5 ,c2 , c3 , c4 , c5 ,c1 , c2 , c3 , c4 ,c5c6c6c6c6c6c5 , c6WS96.1095.3890.2596.6895.8194.6692.2096.9097.0495.8895.8895.0296.8296.1096.5395.7496.3995.1696.53Av96.1094.9590.6996.6895.7494.7392.1396.9096.8295.8895.8194.9596.7596.1096.4695.6796.3295.2396.61Md96.1094.9590.6996.9095.2394.3791.7796.9796.9795.7495.5294.3096.2595.4596.1795.3895.6095.0296.53Mx96.1094.9590.8396.9795.3895.0992.6496.6896.1095.1695.5294.0196.5396.3295.8895.6096.3995.4596.17MV96.1094.9590.8396.9095.2394.5191.7096.6196.5395.9695.4594.3096.2595.4596.1095.3195.5294.9596.25FI95.1696.2587.5196.6196.1794.9591.4896.6196.9796.1794.9594.3096.8296.2596.7595.8195.9695.1695.96DS096.0295.3689.3296.9895.7394.6291.7597.0596.9195.9595.9595.1496.6996.0296.4795.8896.2495.1496.54DS195.5196.1788.5996.9195.5196.2491.1696.6996.7695.8095.8894.5596.7696.2496.7696.0296.3995.5896.54Table 14: Speaker identification accuracy using different combination methods (2 speakers)357DS295.8096.1788.6696.5495.8896.1791.1696.6996.6995.8096.2494.4096.6196.1096.5495.9596.2495.5896.39fiAl-Ani & DericheClassifiersc1 , c2c1 , c6c5 , c6c1 , c2 , c3c1 , c2 , c6c1 , c5 , c6c4 , c5 , c6c1 , c2 , c3 , c4c1 , c2 , c3 , c6c1 , c2 , c5 , c6c1 , c4 , c5 , c6c3 , c4 , c5 , c6c1 , c2 , c3 , c4 ,c1 , c2 , c3 , c4 ,c1 , c2 , c3 , c5 ,c1 , c2 , c4 , c5 ,c1 , c3 , c4 , c5 ,c2 , c3 , c4 , c5 ,c1 , c2 , c3 , c4 ,c5c6c6c6c6c6c5 , c6WS89.2288.9180.3790.5390.3788.7084.5491.1091.2590.6390.3786.8891.2091.3690.9991.4191.0590.3791.51Av89.1788.5580.9090.4790.5888.6084.1791.1091.5190.4790.3286.7891.2091.3191.1591.6790.9990.2791.36Md89.1788.5580.9090.3289.9087.3583.6090.5891.3690.4789.4885.9490.5891.2590.5890.9989.6989.2291.78Mx88.7087.6179.4489.2888.6587.2583.2489.5988.7088.8187.8784.6489.5988.9688.8188.8688.3488.2488.91MV88.9185.5877.9390.0690.0686.9383.3490.3290.0688.3988.5584.5489.5990.3290.0690.4789.5988.8190.89FI87.8289.3875.9089.8089.4388.2983.0890.9490.8990.1689.5485.7990.8490.8990.7390.8989.8588.9691.46DS089.2288.8679.4490.4790.5888.9683.8691.3191.6290.5890.4786.1591.7291.3691.2091.4691.0489.3891.46DS189.3389.9080.3790.5890.3290.1184.6491.7891.6290.9491.5787.4091.9391.9391.6291.8391.8390.4291.93Table 15: Speaker identification accuracy using different combination methods (3 speakers)358DS289.1789.9579.8591.2090.2190.5885.0691.5192.0490.2191.4687.3591.7892.4091.8892.0991.4190.3291.98fiA New Technique Combining Multiple ClassifiersClassifiersc1 , c2c1 , c6c5 , c6c1 , c2 , c3c1 , c2 , c6c1 , c5 , c6c4 , c5 , c6c1 , c2 , c3 , c4c1 , c2 , c3 , c6c1 , c2 , c5 , c6c1 , c4 , c5 , c6c3 , c4 , c5 , c6c1 , c2 , c3 , c4 ,c1 , c2 , c3 , c4 ,c1 , c2 , c3 , c5 ,c1 , c2 , c4 , c5 ,c1 , c3 , c4 , c5 ,c2 , c3 , c4 , c5 ,c1 , c2 , c3 , c4 ,c5c6c6c6c6c6c5 , c6WS87.4584.7874.0089.1887.9685.6080.8489.7789.2687.8487.0684.7489.6189.7789.2689.1088.0088.9989.42Av87.5383.7974.4789.1888.0885.4180.6889.8589.2287.3386.7484.3889.6189.7389.1489.0687.8888.8789.26Md87.5383.7974.4788.2487.5383.3279.5889.6588.7186.9086.2384.3089.0288.8388.3688.2086.9887.2188.91Mx87.2983.4072.0388.1686.3583.5277.1888.0487.2986.3583.9980.7288.0087.4587.2986.7485.2185.8087.37MV86.9881.5571.2887.9287.3383.1278.7688.5988.2087.1085.4483.0188.4788.8788.0488.3687.4587.0688.24FI86.5585.4869.8388.3287.2584.6680.2989.6588.7587.3786.8284.0789.1889.0688.5588.3687.9288.0089.22DS087.6983.8771.9989.1087.6584.6278.8089.6188.9187.6586.6683.8389.6189.6189.1888.9587.8887.9289.54DS187.7385.3773.2989.3888.0886.1581.5190.1789.5088.3288.1685.6890.0189.9389.7389.6589.3889.2689.89Table 16: Speaker identification accuracy using different combination methods (4 speakers)359DS287.4184.7873.1388.8787.4185.1380.6889.6188.7187.6987.1484.6689.7389.5088.5988.9589.0288.7589.73fiAl-Ani & DericheReferencesAha, D. (1995). Machine learning. Tutorial presented 1995 Artificial IntelligenceStatistics Workshop.Alkoot, F., & Kittler, J. (1999). Experimental evaluation expert fusion strategies. PatternRecognition Letters, 20, 13611369.Chen, K., & Chi, H. (1998). method combining multiple classifiers soft competition different feature sets. Neurocomputing, 20, 227252.Cho, S., & Kim, J. (1995a). Combining multiple neural networks fuzzy integral robustclassification. IEEE Transactions Systems, Man Cybernetics, 25, 380384.Cho, S., & Kim, J. (1995b). Multiple networks fusion using fuzzy logic. IEEE TransactionsNeural Networks, 6, 497501.Denoeux, T. (2000). neural network classifier based DempsterShafer theory. IEEETransactions Systems, Man Cybernetics, 30, 131150.Dietterich, T. (1999). experimental comparison three methods constructing ensembles decision trees: Bagging boosting randomization. Machine Learning,40, 139158.Hansen, L., & Salamon, P. (1990). Neural network ensembles. IEEE TransactionsPattern Analysis Machine Intelligence, 12, 9931001.Hashem, S., & Schmeiser, B. (1995). Improving model accuracy using optimal linear combinations trained neural networks. IEEE Transactions Neural Networks, 6,792794.Ho, T., Hull, J., & Srihari, S. (1994). Decision combination multiple classifier system.IEEE Transactions Pattern Analysis Machine Intelligence, 16, 6675.Kittler, J., Hatef, M., Duin, R., & Matas, J. (1998). combining classifiers. IEEETransactions Pattern Analysis Machine Intelligence, 20, 226239.Kohlas, J., & Monney, P. (1995). mathematical theory hints. approachDempster-Shafer theory evidence. Berlin: SpringerVerlag.Lam, L., & Suen, C. (1995). Optimal combinations pattern classifiers. Pattern RecognitionLetters, 16, 945954.Liu, W., & Bundy, A. (1992). combination different pieces evidence using incidencecalculus. Tech. rep. RP 599, Dept. Artificial Intelligence, Univ. Edinburgh.Mandler, E., & Schurmann, J. (1988). Combining classification results independentclassifiers based dempstershafer theory evidence. Gelsema, E., & Kanal,L. (Eds.), Pattern recognition artificial intelligence, pp. 381393. North-Holland.MIT, SRI, & TI (1990). DARPA TIMIT acoustic-phonetic continuous speech corpus..http://www.ldc.upenn.edu/doc/TIMIT.html.Rogova, G. (1994). Combining results several neural network classifiers. NeuralNetworks, 7, 777781.Shafer, G. (1976). mathematical theory evidence. Princeton University Press.360fiA New Technique Combining Multiple ClassifiersSmets, P. (1990). combination evidence transferable belief model. IEEETransactions Pattern Analysis Machine Intelligence, 12, 447458.Smets, P. (1998). transferable belief model quantified belief representation.Gabbay, D., & Smets, P. (Eds.), Handbook defeasible reasoning uncertainty,pp. 267301. Kluwer.Smets, P. (2000). Data fusion transferable belief model. 3rd Intl. Conf. InformationFusion, pp. 2133.Sugeno, M. (1977). Fuzzy measures fuzzy integrals: survey. Gupta, M., Saridis, G.,& Gaines, B. (Eds.), Fuzzy automata decision processes, pp. 89102. Amsterdam:North-Holland.USC (1981). USC-SIPI image database.. http://sipi.usc.edu/services/database/.Xu, L., Krzyzak, A., & Suen, C. (1992). Methods combining multiple classifiersapplications handwriting recognition. IEEE Transactions Systems, ManCybernetics, 22, 418435.361fi fffiff ff!ff#"%$'&)(+*,,*-/.,0$213.*&45678 9;:<ff,*0=?>6"9%$!*<ff,*@BADCFE)GHIJLKNMONE)OQPRKNSDT%GVUWKNCYXLMZ[8U]\WE)G_^F`EbHVcDUdONUWeU%Tf^hgfiDOkjlCNCNe5M[8gmHVMUWinpoqr/q/sutvq/wyx)z{or/z{o]25m]' 0fi8 5 0ff5 '0]_'|/}~~/ ~/]{}/}/W} }qqmqoq{~/|~ ~}~W 5ymV{b+8?{5)'0!5ff)?N?'ffd'{5!!#+0D!'D+' 5'bf? N'5?';!'+' 5'W'0'5'm ' R?!'d0'' ' 5fi+{5!3'0fi5'+'+{0?!0?ffff? ' 'D_! v 5?ff?'' 50 ' ?)' D?+ffd+?? fi50 ff? Vb]?'5 {!ff?b'5?'m'{!0!'d+' 5''0'%?''R'0' ?]ff '+'+5? v! {5?%'{5!' 0f?]!5 0'0!'f?!'Ffi+!? 0 ' ff '+'+5? F! {5?'{5!' 0?'!0'N5'+ffF'd0''' 8?_ 0D!'5 ;'fi+!? 0 ' D! 8!'R'{5!' 0b R';3'?+'' ' 8?_'ffi%{5ff8?V? 08 D'%!'5b%?'ffR+8 'ff '0fi''0! ffbff? 03)W0+5?' 5?_0?' '0' R?_ ' 58'+!d'5VN 8]]{f3/fi_ D??v fffi W3 %5 _ff$ 3%#& f#3%_ '& (F#3)mFfiF* ?+ff$ 3%#/)%fiD+%3+ #&.!"#ff-,-/+* ?+0#,1 1#,fiD23fiD%$#?_ff;+<_ '= f* ?+"68>7'? +ff-,A@ffBBC5DFE_ffG,H@ffBBI*,KJ%LL@9M14NO PQ* 5# #B3d3!N!R# $SRR?T ]U_ WVXff&31;{_ff Z #,*R=ffm/fi5N!5#[ ff##<f]\53 #'<ff ff53+ ;_??fiM5#5#4,M/!)ffff##5#$5%U N(m?#* !,* ^! ff #S+%3+ ##Z *)_?Fff ff ffv/!{, Fff_]33 #?[ % #N!R-1`_T RV'#37 ( F$ff\53 #'<N?v3dffffG1 f$ffSN!R#NF_fffi 3 ff;+P ^Nffff-! ff RS? 5#//%ff*)/A%# p#v53+b] : Wfi! cfip?fi^3?]6XdAeTf79M1 $fd/fi_ ^#?[ % # 3%^ :#%!1(_T#5#( :W`! ff #yff ff #-,%5 fi; /ffff* ^ g RU _ WVXffy=3=N! R#, fi?5#_ffp={ff #`J51){ff #=Dh ?ff* !gPfi?fi^3?53+b"`! ff #ff4,(<3 ff /% ff*v53+bi/!,) ?p+ % 3+ 25 fi5 5#?[ % #-,T33 #?[ jV#-,kNff )* ! % #!fi% #-, !F33!#`Q NU _ !0ff34/+/5m+%3+ 7683+5# #:925fi5 53+ ;%#lnmokp qnrMsXt uXvjw(xyZrMsRxGzj{jqMsXrnzj|F}~OuX~WOuXt rnFM%}xG~Wp ~WOuXt rnFv%+~{~W~WKt w(|jp ~Ww(~W!uX~+}kt uXvj~rnp j~Ku'kTt jt jqff~OsX~OsMwH{~OsXqn~OsFff wHzjn5Mnffl'R|jzj{jp Wp P+nMt p M{jp ~(uK!n 8M5Gn !7vjt 'v+MP{~HuX~Wx8uX~+}7t }rnw)Mt jxuXv;zj|PuXr7nM2~OjMw(|jp ~WxWm^ow(rMsX~(xGrn|jvjt x8uXt +uX~+}t w(|jp ~Ww(~W!u'uXt rnrMy$uXvj~)Mp qnrMsXt uXvjw(xFt xgjrMug+nMt p M{jp ~(yZrMs|jzj{jp zjxG~nm*,,* 9 ' fff9A;ffHVff0 7)ffg{6"'"/9jfi~}~~/]{}/}v3 R?!1<Y{ff#?R RV' #37 (F$ff\53 #'`N?:&3 !yU_ 5Nff*N/fi53+`%#yff ffff`+WVX/ff`\53 #'N?1 b#,{ff # R?)3b H+S dff3 % ff4Hb1b )B!fififf]]{/{f3mff#4? 5#_?F 2'HSv+ /H k5V3R ?!)nV#DNffff# * ?+/!1f?A'Hd+ /!,mffA%A?5##FR ?fN#U _ f*#ffNff*!1!#"$&% z $ (q '*),+-/.1032)z{o5476 t98;:z{=<38xr/o>+?82 @n :A' +{z{o5BDCf;+b& mU_ WVXffy<3 ?ff=32Hb& _ 53#*#333 +b4ffp`Y{ff#@dp$ff5Q68>7'? +ff-,@ffBBC5DE_ffG,@ffBBI9M1FNW+ ?;W;N?:)+% ffD?fiM5 Nff ff #-,c73A+kU _ fp_ :/U # p _ff #R?fiM5 38;5= 7W+ #!1 W_ vff\5ff ,^ &ff 3# 7%5/S%)_ff ffff3+/ :2V+ #v3) ! :A+SU _ !]1 f2 +b33#5#3+ff% H (! ff #//?? 5#/f$ ff* 3#7/!,j%5fi^5fi5 5# [ ff]5; f _ ' %F !Nfi^ffg :H*; fi!H!3 g ?T6 /% ff*%#fiB?fi3?8, <U N"ff Q 37Hb9ffP :G,-P/+c O,kRVX fi !P!3 7 ?"#6 ?# *yff n9MN1 fi!P!3 c ?!ff *+Nfi7 ffA%cRVX fi!^!3 ) ?%ff#F!ffF*+fi7 ffn1fN/fi!3 fiU _ WVXffQ3& +b ?ff& 3cHb N?&3 %$ 5% # PU _ v<%#+v_?% ff#B3p# 5#%# p/kR?(? 5#/R$3 % #v/A%5 -9EGF5HIHKJMLONQPOCSRTNULGFVWHKJ>EGXUNUXAYVGEZ7[M\ E*VHKJ>EGXUNUXAYVGES^" ff*#"3fi7 5%,]]ffRS^" ff*#43fiPMffN$##P/3)+;fiMTfi!c!3T ; 5%`6#ffNF>_ #3$##5%#59$##S^" ff*#"# 5c :^!ff]/+) 7fi!%$ 3%#-,] 8Zj U_ !0SR ff#gN?? ! %/3#'k 5+%/3#',N 3 #']fi#%/3#'1NW ?5 # 5% #-,A ` +b 23#5# h3S+?+"`/R$ff*3#4+#!1cY{ff#&J51 J?5#_?%Fff53+d?fiM5#5#YRf,%5 _=ff ++ M"* ?S %Ffi=)%# ?_ff"+U _ff ffffiff53 #?[ % # /fi5N! ff1* p ff ? i_3 fiff,$ y=2 g ?c 5% F&Nff ff ff< ?%?!,- 2Y#5#? 5#_ffff #PJ51 h( 7_{Fff2+%ff fff5P_- R3+ _?$ %fiF _ ff7+) 8U _$ff* 3#%+ #!1 _T#% #ff#,3_NffNff* ff%# `.?#* ff-0 5# 5#f <Y, 3T = 3 !#pfffi 3 % ;f %"{S6P_YR%,-J%LL@9M,-%5 3ff5% ?c`+" P_?+W/f!p# 5% #-1`cedgfbah*i>jMCfi }fiff|/|! $&% z 3< 8xr/o>+?82 @n :A' +{z{o5Br+/oM: 4 %/}30 {}wf($ %S3 N#5#YRf,3ffN b#7@%,3K+?fiM5] :)M?%2jU#[, % $#&%lfiM$##?!,'$% fiP #3$##?!,)(3%.- /+/0 "! n14We #Q\53 #' ?7;*& fi!!3dUN ?dB3#* ,+5P_H kRVX fi !;U N?!81 f25P_g + 5% ff4RVX fi!(!3 ?!, ff3 % #T+75P_( ff`fi !^!3 ) ?!/, 3(!ff5F/fi5N! 1( 1^#2(<36 (4@9M,ffvM ?A%Vff R#p_ff Z #'<68## 3 3 fiM5% j9 P5S8!pRVX fi!!3U N]3k]ff3 % #ff#2/.U _ff#0#61 527 g 8-,5dff ffp#7(3fi336 (98 @!L :n9M,/;ff5b?T%k_ff5% ff-,53 +SRVXfi !T!3 f+ ?!1V !VOL [M\ X *[NUX#J HK[ML [ V7N VOL:;3<=?>@.ACBDFEHGJI"EHKLM<?>=KNfiGO@3PCQ=/RS>,TUWV NMKAIYX[Zfi\^]O_a`3X 'ff? !0b X b'ff? !]! 5\ {! ' ` ff?')+'dc ? 05 _ 5 ' ` ff?'8+'dc? 0dce !)?_? 030 ''0 ` !'' ' ? 0dc?fgheij > j DkSACS>/Il` 55ff? 0 ' d?ff?'50 inm oqp l ? ) ? crOsut vxwyyz,{,| ` ?/!{!838' 55ff?,c}~, r s| ` ?fi%{58?' 0b h ~, r ? _~ ~, r cKAxNMKAI)ZC { l~ | f v,vqz,tHn ` !)?' 03'0R? }~, r s| {0] ' qz,tH c` c =?> ? ' 0b h ~, r ? _~ ~, r ` Z ' }~, r s| c6 ='+? 5 ' D?!8?';' ;'{5 qz,tH ` c'+? 5;' f? nW ` c` j c B@3;3S '5'?'; ' 55ff h ~, r =`3 c=?> ? ' 0b h ~, r ` Z ' }~, r s| c6 =`. c=?> ? fge9 =`h c3' W ' ;fid3' ' N8 ' R?'' R3' ~, r ?30 ''1f qz,tH ` c qz,tH ` cHOf`3 c';'f? d?_W ' 6W Z`u c@ " rOsut vxwyyz,{,| jnV @ Wf+b+?'5'?HN ?fiW ` c _~ ~, rjnV @ B' ' ;+8'5 5 ? =`3 c'5+m' ffb' _~ ~, r 'R' ' f?'5ff5'' 0b _~ ~, r 'D'0!{0b''5 )?`3 cV9 =?> 30 ''0` Go cV^ =?> ' 03' ~, r` oo c~, r _~ ~, r` Oo j c V^ B@3;3Sb#S@%ge%ff53+T_??fiM5Mc+M##5#:%43 1( ff % ?2 NU _ 2+3 N <3&#&%&'$%6 #+ff]S3V!jU3n9K ffF+P_^#[ ff-,h#&% 6 #+ff]SV!jU3n92 ffc+3_SjU#[ ff-1Nf#&%&'$% /33fi2+3 57d 6 fff?# h5WV5%d;fi5 53+9 / "u6 )+ffA!+!,kJ%LL@9M;1 fPN/fi53+ 57du#&%&'$% /WS1(ff 53+ ;fiW#5 [ ffS!"{ff #HJ51 {, ?_ff #ff#1fi4/fi;'$%/,/%5`h*iU`Q`fi~}~~/]{}/}fffifififififi#%$ & '(' ) # *-, #%. /_T#5#YRf %b?v# /`N !35B!i` ?%! ),% ?%?fi2# $##H+Mff"L%+5# Tfi?A?5#/7UN?R S1 /3!&68 %!5 :9R%+5# ?!, ?%?Dff"" :Mc, :)5N 5 _%+5# ?A!vff7c :M81 k" :3 # [ P ?%;+ #-,$ !Tfi?6 9 @9)ff_ ff*Tfi?Tm%+ 5#%fi_?fi` D$# #RU N?6 k@9(_ ff*^fi?)fi_?fi54 ;!% #RU N?!1^_ !^ F ?%?3)+ ff) :#%!fififififififi"!+) # * DC'(' ) #%0 ") #%0 DC"#1#, #%. fi7ff 5%ff-1] T3!d%+5# ?2# , ?%?) c :M3# #%$# 4] )*5m%+5# ?# ,3fig+ ff5]N'56W@ffBBJ9M, ?%?H :M#4 6 #%$65 , %# . 9%Jfi;?%ff= :Wk?#*$5/fi/5P6 #%$87 , #%. 9M,_` ?%?# 8 6 #%$ 5 , #%. 9%J; :W-?#*$5R/576, #%.97#%$ 9M1] N*! ;fiff %+5# ?:# ,K ?%?Rfi"ff 5%ff R# 2# ]$3!*5!,%?# ?%? P :4DC_ ff*" :M!# 46 #%$+5 , #%. 9%J5,# 8 6 #%$ 5 , #%. 9%J5,;# #%$ ,/<# 4, #%. 1(N/fi5N! ff,R ;52f 3H!! $_ gfi^ :A2 +Vfffi N+,?+ff_ P3#QRU ff"5P_ (5UN ?!1<Y{ NfipF5_!'m ffLR1@p @!LLR,g :ff%LUN ?!1]f75P (v_d>R+ff$4+]#[ c 7%!%4+Sd$#" b$##UN ?f!!1_T#5#YRf7'Hy##b/fi5N! 5P%5Bfi]'{/ #<R>R+ff<5<(Qfi?R4f%?+ff#/%!) 3+"J=<?> @ACBCB;DEfi"F Eff1Ff//5+d3;68! ##7fi3%O S,% J% 3c]5P_ 7 Afi!!3UN ?f ;9H%5vff#]?(75P_ ( fi!^!3UN ?%5 4+(_7 ff`5F! p18fdff368! ##(fi3^J%L*95 `%?) 5P_))+ #)b W?5 y# 5% #-f1 f7 ^ K R#5#3d!_ ff*?2%# B#?+$/fi?!1 fNM ?ff] :#?%?()15ffN'H# #!1f;#5## 33 # [ ?5 ;M ?Lf?\53 #'2fi? 6 W9 fim!+T [ /#6 + 4@9M1 ^# 33 #?[ % #3 :#mffP5dRR##5 4#6 + /KJ @ffJ9k %8++ /%ff-,% :b?P H_?4, #b3T#b$# F+T 8N/ ?c\53 #'1 ^ ?2 <_Nff&#35& #ff# " ?%?c)14_^ : //5+# 5% #-b, S# #Q3+ 7f?%b, % : Fff#5% #QQ+3'H` ?%?!b, B+3 :-1 f?fiM5 3d++ ff%& ff%7 :?f4 P_?#6 + <h9 ?%?^a#6 + 5f9 fiP ?+ ff?5 y# 5% #-1!"!u,R+ ff5] #ff#R?%2+N^$R`#6 + 9H\53 #'37Nff #6 + C9M1"NO H$2 ]! 32?%## ]\53 #'3/ ?% " `\53 #'*<,( 3H5+3m 3ff"5S c! 81 fWM ?mfiW!ffv!M+?P\53 #'^%1"_AP NffQm?5 # 5% #-,37/ffB*+#6 +@@9M1E ff4 # 5#% ?!, 2/5+3AdM 2%# 4jU1_ff ?fi"# #<#6 F+ =I9g :RM T+;_!ff3g%f#A+_/+ 8m1 fc!u3ff !fi *# kU 3+ DM54 %($# # ?k (! ;fi;/!m$# #?k#3 m$# #?k!<>R"K 2G = , IHCfiJ DCAP2G = , IHCfiJ3"L =`"MNO, G =`>R>RQfiffR=<?> A@ CBCB;DEfiSMNO, G =TMNO, G =UMNO, G =VL =<L =MNO, G =6W TMNO, G =;WMNO, G =L VO\ VOYM[ Nh*ifi }fiff|/|W;1K_/}30 {}fff{5 %,P_ ff,M!46W@ffBB9M,3KF $^N_) $3b/fi_ ff1K_^ : F^! 3!ffN#Hfffi_ff/%;+N^ -%U3+dM?)_ffNff!fi*(%#p?_ff^+S3^!M1(YR5M?ffidff3%ff4fi5#!M 5Q6#+ 9M1f;?+3 mff!fiNff?2%*c#_ ff*fpff!fi*M ?!1fiR_ 5!g #3%$##?gc!ffF#3F ff!fi,?ff*ff"5MNO, G =MNO, G =3MNO, G =MNO, G =DCYRf,fiM(\53#'PN?1 ?K'Hd $?!-/5+!,Mm!fi%#-,#-%# #$ ff* 3 :k H+ #D# \53#' ?v /ff\5ff*p# 5% #!L1 f#3 P 34\53 #' N?Y{ff#%4%3 : 3 &/5+v$,?B#_ ff*4+ 3+ # 3$##?; #3 c!% # ?)v_ :Mlff\5#]mffG,5 :($P?fiM537N?d3fi* % !!1NW/_T#5#>Rff-,fi!fi%#7 ?%?7?=DC! 8 zT<38x;'?z 49<Vzz 4>:A+sf3ff#?5#_?+ ff]5P_ P )ff 5%ff M?7+yff3%#ff#5P_ P ^# 5FM?!1 fff `FM!N3?5% S_ff U_ff U_ P+!fi%D]3fiR!^ 8M?f3^ ?#, ff-,/U _ 5Nff* ^ff/+ 5% P%Tfif/! R3fiM ?%5 ;/+ fNf%+ 5# Afi?bNff%3 fiff#v_ ?!1fi`cfcm?#* ff` 5fi5$ff :^R/M%#pM/!fffff#6;Vff{5 %,-J%LLL*9)?)# 5dM?)P%^ c# 5d!^ fi!T!3_U N?!1bfmfi5-,N ffNff*ff_T#5#2YY23ff b#AJ5, ;fi+V*+ % 3+ /_ffff - %ff ff ffM ?!, ]#)ff?KT# 5#' -ff 5%ff/! !11df`Q:;3<=?>@.ACBDEE Iff K;3SEHKLMPCSAEHS/;3S/Q AC@3= VUWV NMKAI !)?' 03b';ff?')+'\ ff?')+'b? 0ij > j DkSACS>/I wr }~ { ` '0 '0fi%{5)?_!5 0'0R' 0b R'm! " cKAxNMKAI" !8?_'5+ ' 5 5{55]' 03b';ff?')+'` c @ V @.AC@ j ;3 @ fiS$" ` 5!)?V!5 0'0' 0dc` j c =?> 55' ~ g \= `3~ c`3 c >SNS j wr }~ { ' 0`. cPCS/;3S/Q 3' '' 'R' 0 5 `3~ c 5'! ' D+\ ^\ ?ff?'8+'b? 08 5'0dfi''5'f!`h c\ 5'0dfi'f!5 0'0'=?> 55' ~ g= `3~ c `3~ c`3 cS/;3@3Dk@ Vj ACS 'f!5 0'0' m3'`u cjnv'f!5 0'0' '! "`3 c V >SNS jb#PJ5ge%ff53+WM/!fffff##5#41h*i>hfi~}~~/]{}/}`WN ^+_T#5#2YYpfi;D!T ]kfi!c!3WUN ?&%L`D!T )M?H1KNO g m3mffff!A VM? H,H18fT ; +% %/fi5N!!?*?-%j_]ff ffffP :!#c ! H1 ! UN% 3d4* 6 j9M1]NW # 3#,$!cff ff ffBM ?3ffN' #6 + @9H* ;fi?Rfiv!;+@&#6 + J9M1 %UR!], B?5 # 5% # ) #5#6 + //h+ 9M,DM D3ff&+ /!]#6 + I9M1! H, DM %# ` #?+( Hfi W3mff ff ff-1 ;?5 vM , ( ;3HNffF+ %c@ 6 j9gfi?mfiff: H fi !]!3U N?/ ff 5 3RM <#6 + 59M1_^ : NM vff ff #-,g vM3ff3% ff&!#6 + C9 6 j92fi?c :R fi!;!3U N?Pff5ff ff ffBM Dfi ffNff* ff&5@`#6 + 9M1 f332 ff* 5)/fi2 #5#%5 Fff?H %" T/5+;# 5% #vfi!)!3 ;U N?A* 5# 2 N2fi@ 6 j9 @)+P ( n,R%/ ^ :#%# 5% #F T* 5# #VU N?]fi*5 $ #5+c ?F 5%25!##ff ff ffM ?!1kNW; 3;ff;U N??&ffQ5=/ P/ ff ff ffM ?cff ?S ?( ]%RM ?c5*S !A ff"fi !(!3U N?g%^m?#* ;ff2H_ff"ff ?ff"%ff/?% T5 P+S_dff ff ff c :#%N# 5% #!1NW3 R 3 !#fffi 3 % Pf %"{ff, 2Yp3%NffNff* ff` 2#5` :YRf1 b#ch7# ?A W/ffR2#5#f <Y1RNWF# ;H#5,Rf <Y] 3 )YRfff ff(# (_?T_?+T+/_d!ffF*+; c f! H)1 kNff%YRf +DfP _ ff*]+ #%]?5 v# 5% #-,U N)m?#* 6 j)9 fiW* R ffff 7\53 #'N?c%5 p3)ffp( :#%!KK K K K K,6O 8J fi,6O 8J fi"K>R> =VGOKK K ;,ff,6O 8J fi,6O 8J fi@!`baDC&f383F%N^\53#'/N?%]"YRf'$%KKff'5 ($( ff-U g%g)m?#*g $Mf$##UN ?$ ,-5]# 5%#`+( ff-fffi;2+*ff\5k+<@P ^ff`5pU?## 5%#-1bafcv?+4 :(7?5#_ffFN ffNff*%#p3H+ff2c# 5#'] bff/m!ff3-,_ff c dUff!#4N73#H4 3!#fffi3%G = , IHCfiJ/fi5N! 4fi_T#5#YRf +_y!Q6:<! ##ffW, #fi3(J%L*9M1gfW?/#c2 #ff5% 7# 5#'S M?;5!ff4_T#5#f <Y,fi5 Nb3 ++NA5ff)/b !81 fg/5+5ff)/Rb 3k % NmM H ;_A!ffffP _ ff*b# 5% #k _T# 5#f <Y,%?/# g A5?87 6 j9fi?!b1 fH/N$ *P5ff)/Bb 37 %Dff53+ N?fiM5 %#fi"ff!ff*/! ff #&m+N;5R&\53 #'/!1 f ! :/5U #5%+fi 3 % #!,fi #p"YRLfU ff! #%# B`3 fi:#mffQ5NM< 2YYfi_?fi5(+S_/_!+ Wfi5 -1DCbafiba1G = , IHCfiJ`G = , IHCfiJ! <38xr/o>+?82 <Vz{qo %q/s.WqU8qK4>:A+s :#s,4 % zq/s`$ < 2qz57d / ;%5 y3T#ff= :!fi%4!3Z/ _ :M,V&O#&%&'$%/;%5y32_?F?fiM5ff5"dff53+W;YRf #5#41fi% #Q%ffB/dQ 57d / <6 57dT fff ?#J5W_ 5% =;fi+V53+ %, )+ffA!+!,HJ%LL@d9 %7 ?d_ :<7 #&% fi'$% R,f g3ff#y3T+3!3fi5# :4Dff3%#=_!'m ff&`h*iU``fi }fiff|/|/}30 {}:;3<=?>@.ACBDG E IMG j j [@ V @ V <)EHS>,RS>OPCKLM<?>=KN9Q= V PxAx>KQ AC@3= VX Zfi\^]O_ `3X 'ff? !0b X b'ff? !)! 5[UWV NMKAI\ {! ' ` ff?')+'dc? 05_ 5 ' ` ff?')+'dc ? 0dce !)?_? 030 ''0 ` !'' ' ? 0dc ?fgheij > j DkSACS>/I wr }~ { ` '0 '0fi%{5)?_!5 0'0R' 0D']! " cl` 55ff? 0 ' d?ff?'50 inm oqp l pGo i5i ? ) ? crOsut vxwyyz,{,| ` ?/!{!838' 55ff?,c}~, r s| ` fi%{5)?' 0b R'{0?$cKAxNMKAI" !8?_'5+ ' 5 5{55]' 03b';ff?')+'` c @ V @.AC@ j ;3 @ fiS$" ` 5!)?V!5 0'0' 0dc` j c =?> 55' ~ g \= `3~ c`3 c >SNS j wr }~ { ' 0`. c5? :;3<=?>@.ACBDFEHG 'd'')W' 'N ?? W Zfffi`h c=?> 55' ~ g \ H5 '0dfi'f'''0'= `3~ c `3~ c`3 cjnv'f'''0' ; 'd! "`u c V >SNS jb#Ph5FNO 5%#3+M#7f%E*V KEGXUNUXAY5XUN]Y{ ff1% #&% 3/ ,+4 Q!3Z/ ]N?5&3 5#i $##3 ?S%fi;!3 Z/ffW$##,_ '$% 3^C0N?5] 5#` ]ff#1g_$*"!3 Z/ff!% # 7 ?!#&% $,)'$%57d / N%c!3 Z/W_ :"! D=2 g# 3 D3 fi! 5% h'$% <6 #+ ff&&3!V jU 3n9K %S_WA# m$#, vff# ##'O#&% "6 #+ ff"] !V jU 3n9K %"_d%#p$# /#6 b#N`{ff #`h51 J9M1f 57d /F3dfi 53% :N?54 ! ?P38,/K%1#&% ?'$% c 5! 3F!#^+P T3%]_^3 fiMffg* ?+WV1FdH*5ff#, * ?+ W?/fiAf " ff*#P3+ *(3%G1fRM ?)%5 fi;/+c3+ *T;3%P R$* W3 57/5 4* U 5%3c+ ff-1fNfi?3 2 57d !]ff=5yV/c%# & S_?+#&% ?'$% " 5!<_ffB4\53 #'&N?/ :N/fi5v! ? _ ff* ?fiM5P N5!1`NW+ #-,K %#+2 = 3+p5 ! ; ;?ff)#&% ?'$% ] 5! 53?T] _ ff*%P# 5#!,5/ _ ff*8/fi5N! ;!+FVdff ff ff"% 7#5#^5vfi #N+W!V ff# # P%N#5#%^ %b ?W*+/ !*T _ ff*3!3 Z % #+ !1f(N?f; TYRf # 5#%gffK+c_)jU# [ ff-, 5?+cN/%fic# fi$#S3%57d / & Sff #= H ! :_ 746:%# ^#&% pff\5F+@!LL'$% pff\5F+=L S9M1 ^ ),!ff,K %PRN% #-, bNffNff* ff_T#5#YRffi, 3_ :MNffP#&% %``&MCG_DCeffS^``MCDC1Z7[M\ E*V [M\ [MLMCh*i`DCDCfi~}~~/]{}/}' % R,%Nffe`57du#3!,R 5% %( #&% k'$% +%V' ff$#&%&'$% /1FfN?+ 3cNffQN %#8O^" ff& (N Jfi)%53Fffm?fiM5vff53+A :HN/fi57T\53#'; VM?K :;7#ff-,*Uff-1 RU ff<-, #&%&'$%/ 3fi53% N7 57d / 757u/ R3)Nff#Fff\5#fi ff*)+] P3 # [ ff#&%&'$%l/ P%$% R,(pfi3 #?[ % #`+ * : 7 jU ?!_, ?_ff #ff#%1 f#&%&'$%L/ R` 57d/fi+ 5% ffv`{ff #`h51 J/5 b#? 5, ?_ff #ff#1``/fi)#b]]{WD@VMN&`fiff8 /fifR# ]/!, ?5#_ff=Y{ff#&J51 J5,_ ?ff*^+ & K%V$ff=?5##R?!1Wf3%+ &?$)+;%"+ & F+fiMRR ? bR^ ffA3% %/?^68>7f2f79M1 fA5?5#;nV#vR?!,$ffp3m/fi_ ff,3(N/fi5% 2+Sd+fiM4>7f2f R?76 ff5-,]3% ! +b5*VWY fi/, YRP5 -,@ffBBC9M,k%# +NR/fi !3 fi5# ?) g +b` ]&3WV1f$ffvU _ WVXffp33vR ?(3+ ( c :#%N+ /!U@%1f ff5+J51^%S 5+Dp /fi5%#h51%3!ff#1%/!fffff#ff51%+%3+ 5fi5 5#[?%#` 8/C51%433#[?%#I*1%* !%#51%p!fi%#Y{ff#`h51@%,+5%R+ /7@d`J5,?ff*fSNff _ ffffp%/ R+:fi #= p $ff? 5 #p #N! R#1 k53 ; :$ V=! ff # ff ff #+ /Th Sm? 5#_ffp3!={ff #TJ51 JJ51 h5,R%( %?# FU _ WVXff"! ff #FFff ff #Ffi^3ff"{ffnV#3h51 J51 ! Rv?# Hb+ /:) 3Avfic3ffF3{ff #)h51 h Rh51 C5,?_ff#ff#1fD$ff<? 5 # #R ?d3# 5% #* 5 #1/NOd3# 5% # ,c*F+ /(ffff+/__?% ff_! :N% 3+# +v+ #v3H :-1NOf3;3 +*5 # {,WU _ !0 )*#ffNff*)//+K ;/?K$ff;? 5 ## R ?!1 fyU _ !0 p B B/% ff*p53+b! ff # fi 3 % # 3?5#_ffv`{ff #=h51 I*1@ffAPAPh*ifi }#"$&% z >o +/xzwfiff|/|+- Kq 4>:zs?4 A: '*)/}>+?82tvo30 {}4 4>:A+snpz zfiM#3! ff#&]fi! ;fi?fi23?46XdAeTf79%3WyN$*=# V!#^Nff ff41^dAeTf 53+b #+5W!dfi ! R%+5# ?!,3#%/#!,ff/+ % "# + 5!,F #5R ?,8N!%$3] #+536!NG1#,)@ffBBC9M1 f?ff3;_ : MNffp ff5V5 75% ff #4 7 _ ff*f+ %?!1cDCdHffS?+d :M%#p/* VU%#p?#!,!R53+b" #nV+ 573 #b N%, $# # ;##3++,-m?#*!, ?#*!,k #fi!+/b,KRVN#-,R #5Rv?, p!#;?fi%4fi!3 fi^3??!1dHffN?#) K3%$5%+4?+!,!N :M%#p%$%53+b" #+5T3#bP3/% ,c+ 5,P$ffc# +5!1cdHff%p?+4?+p?#!,W!N?ffNff* D?fip5%,c! :ffRV5!3 fiv*{_ /*,cY !Nff*3 ?#-,) fiM3yfi5*53v #3+/?!152^;T++M%c?+^Rff!fi*d?+( cHb, :f?5* ?+F, ff+%,_P,T,/=dT,?_ff#ff#1/%+_ % %/S%# <Jhv/% ff* ?ff* '{/ KNff b5QdAeTf 3%3!,ffffR%HNW+#F :Fd;fiM#fi!3fi )!ff*#R f?%/3#%#-,_%!,*dm%3R,;]ffi : F3 1 f`% %/3 ?_ff<5R /ff##dAeTfa% %//ffdAeTf R!!ff/ff5$3 % #-, %$ %L2% ff /% ff*ff ?ff*dAeTf /% ff* !1 %!ff ?!,( `% %/3Sfi% R D#!?fff MT H _ ff*T'{_?2 g /3?1 `!ff,k N!ff!% # & ?<6 /% ff* ]%FffQdAeTf79 fi=5S# ff ff ff _ 5+#3 A%# y+NN ff # ff^c/ff=5`ff5b5 # #5$ff* 3^dAeTf /% ff* !m, ff ff*; :/ 8N*?+ #% #;+< NW+ # 1 f3/3ff % B!F3fi 53% : 4dAeTf 53+b3,A#3fi53% " :?N5] N! ?2 (dAeTlf 53+b`! ff #= :_ :R?+% #yff5Nff V5 1&`OP/ffDCeaSRz'58 54 ' +-/.1032)z{o5476 t98;:z{ <38xr/o>+?824 4>:A+snpz zq/s<Vzz 4>:A+sfR?A U_ WVXffp43 ";_ :MNffv( :#%!1%!%%M3 :Tfi?1(35;LR1 S+&@!LLR,V;Uff"5P_ g ffffff" ]M?)ff\5+/h51)f%M?]ffS3m# 5%#%R?^S+%U_ g :;ffff#FF* ! % #-81 fW_ff #/ F@ RJ%RL ?F :?5&%+%5# ff3 8 %U_ 5Nff* !1)dH ! R?+ #) K Nff VU _*#ff 3D+m 4+3#P 35P_; ?%? pM $R +<+ff&;ff 5%#<]?T%?%?cHy*#U _ff#7ff3 3%3%$5%+?+!1gdHff\5ff*#,*mfff%_ :MNff) 8bU _ 5Nff* 5N* ff* ##3#) ?%f/ f(5P_# 5% #8 (;#5; ^YRf #5##6 +/TJVM@ffJ/ _T# 5#YRf79M1NW7 3# 5% # )R ?!,j )U _ff ff ff7]* ?+ 2dAeTf 53+bT/!1 % ^@%7 F ffB/!,+ ! ;%# < ]fi?7q(QM #Z 1"NWN<3 =#$ffy= 3W/fi_ ff,- ; ?%?dfi_?fi5v=+%/_P,ba<Y#5#&dT, fff*ffAP?_h*ifi~}~~/]{}/}1H?LGX 7X HK[M\IZ7[ *NJML E##H M?A?5#/Pd/mfi7 ff+n1mfc?5#_ff#5% # ]R ?k;! ?+ 8 : % W%+ %? B/dT,ff #Mff7k%S?+%3 # 7^ #6 + % 4_ % *9 3PR:% #ffQ :R p/!, G1 1#b, ## ff/+P 8Z5 %U _ !0 g 5# 532* ?+?!1 52#D% : ]ff5c-,5/fi5%7%/ ff/% ff* !,*m%* ?+/K3ff-1H{T{ff #"h51: ^/ P! 3 A4U _ !0 f*#ffNff*%333vR ?!1jjNS>,AEHS/;3S/Q ACS EHKLM<?>=KNMPff G{! ' m? +'' :fih5?0?{'b 5?m 50?ff'?ff?ff 0'5' 5?m 50?ff fiff{'b {5'?ff?ff 0'5' 5' 5 5fiff{'b {5)5''++?bfifi{5!''fihj5hl r fi: ffhGrOrz f3e :fiffhG: hGl rh rOrz f3e fi: ffhG1l e : hGlrlhoGioOjoGi`{% S@%)NWffp/;7 :M>R?!1 ^ 7# #fi7 #Ab5RV/- #+5!1)YR3_@d3( :Td/%ff*!,/`_2J; :^ ffd/%ff*!,% W/ 2@%, (J5, 3d2@ fi2 :(" ff/% ff* !)1 f/fiff7_ ff*b%+ 5# ;/! k%#?$1(d/fi5N! Kfi?# ffD( 81 fA3 +* *b :% #%$ ;#Z?(Nff45 * ?+!1DCX/fi5% ff#" : %?5`%+%, mffR*?+#%ff3%5 dffvM?fi7{_?+]/F $ 57d /,G1 1#,*%5/ $fffi^ffS+P) 57di*UF5G1_A+ % T, :+,!ffBM?fiS<S*UB5b^ b#? " :#&%&'$%& 57d /, ?_ff #ff#N1 (H4 g ?NM ?!,@ ^&J5, % ff`P?!_, fi;3 3+ ff % /J51 ^ ; %2 RU _ W!V ff ff ffy/ 2D@ (Jfi#Z *!, ffi%/S#;3 P*U 5G]1 f?+3 :Wff ffU #&]'H?%+ % fiS ?N3 #'683+ 4 H ?%?7#9M,?F ff53 #'368 5ff3 % # ff#;*D$# #) ?n)9 /)# g %Fff/ ?%?fi,7Nff V$*A!7,U _ff#23 %$5%+" ?+ !1/``<!4qK4>:A'74>: q %f&URp+ u/`bTff4 M:qK4>:A+s +- <38xr/o>+?82;'qoq z{oy$ff?5#y#DCR?v+fi<3 ff/!1NW<3+ ,+%3+ F _ ff?<3+5# #WfiSN ff< :7'H$V3%#!,kSfi!DQ! ff$ 3%#-1fSfi!R$ 3%#Q3+7/%ff* !ff*+3 F#5 [ ff$9M,k%?7 ! ff$3 % #vfiVfffi 3 % 7RVX fi!T!3U N?P#6 $ ?# *vff n9M1$##S <6XdAeTfSRhoGifi }jfiff|/|/}30 {}S/PxA UWV K QS EHKLM<?>=KNMP: hGh rOrz f3e :fiffhGj5h rOrz 3f ej5h : hG: ffhGj5h rOrz f3e firOrz f3e fi: ffhGrOrz f3e : hG1l el; 5?0?ff fiff''fi +5'+0{5N5! {'?'5 D{5fiff{'b R 5N5! {'?'5 D{5'++{5!;{5fiff' 5R 5% PJ5%(H c`_?+ff#&%&'$%lQ`57d/ffi :v+%T1mf?$##9 b#?fiff5,?_ff#ff#1/fiPfibffb# %f7#&%&'$%/?ff**U 5 v/yff\53#'N?#&%&Ru6 '$% (9%%2%v+% T1 jVff3 2@ (Jff $##_W/Dffffffi54NffRVU _ !v, ;@ cJ'H! ff/H :/#&%&'$% *U 5G1b#Qff5%fyN/Fv b#%VW^c ` 57d/mRV$#&%&'$%l/1f+?`5{ff\5#fiff= P?='H_ ?# ff-1 NW57dy/](73Kff$* 268LR, L*]9 <6W@!LLR,@!LL*m9 Vff*RM $# #c%# #ZVdff\5- [ 1`DC/?Y5 % 3+ _ ff ?W`3+ 5# #A :k?5+5;6#%+5# ?n9A_!'m ff=?'HF$ 3%#3)?+ff&/fi * ?+^%#=BRffR+%46 L L 9M1 T3$/5N5 b%+ 5# ?dff ]_ffy/fi##ff<<+=h%L* fi3d+4%y!*fi fi%S ?++ ?!1_T/& %+ 5# ?;%# #Z *#Q _ ff*3+5# #^ fiF#;ff7%P :?%?? 5#/"/S6:5/# + 5n9M,% k#) ]fi]3 +) %+ 5# ?-%# #Z *#T _ ff*-fi3+5# #!)1 f?R%+ 5# ?%fi ff+*n_, 3P ?%?^ :MNff3?kfi?- %bfiH5 fi5 53+ F : k H3ffR/VfiH ff+ * n1ffffB8' Iff 1DCEGF5HIHKJMLONUX [N#NULGXOFKN VGEhooDCEGF5HIHKJMLONUX Z7[ *NJML Efi~}~~/]{}/}$/ #+5fiN$*)+p5!D/%+ M&?5#(%fiR?+RVR% #QN !v ! % :/Nff ]5,);Nff ]U_ 33#bM?p! ?!R^5$#!ff df$# /68>cffb,k@ffBBh9M1NW` 3^H b,$ R ]+ % 3+ b#3W3^+! ff7N?8$S# +5!,% ?K ^ff 3#;%! F !%5_)ff/+$ff0 FRff %; %?5 #y3c ! :c+3 NU _ !1/NW& dAeTLf fi 3 % #& NU _7ff ff&%!W $ff] #+ 5fi ffF* ?+, ff3 3% ) !FfiT?#S !] _?Nff5 1^NW % ;h5,U _ Wff ff ffy$/# +5fi;3 3+ ff`URT+"#$dAeTf 53+b]/!, ?5 =? 5#_ff"5vS3 3+Ab5 / # +5!1jjEHKNN=?>,AC@ V < j Q AC=?>P>@ V Q@.N j ; j Q AC=?>P{! ' m? +''?; 50?!ff!+?''0'?'!';!fififi{5!'5!5 5{! ' m? +''fifi{5!'5!! ' '0!0pff 0'5''?]0'0!0pff 0'5''0!0'' 5'+0 ?{'bR 5?; 50?ffj5h l rr rz f3el rh rOrz f3erOrz f3el r'?ff?/ff 0'5'{ 5?; 50?ff{'b R{5'?ff?/ff 0'5'{ 5' 5R 5{'b R{5)5''++?bfifi{5!''fih{! ' m? +''{! ' m? +''fifi{5!'5!+?{'0b5 '% Ph5)NWff`?5#P65 /- #+5n9f`?W+%3+ 5fi5 5ZV[?%#6#$ #+5n9M1<38 >+?82@:A'58 U: K4>:A+xr/oqq_ff 33#[?%#/N!R] ]_)ffS+P33#[ A^ F V*]3%3 <4 < :R?%# u fi!`!3 ?ff\5ff*!1gNO)3 +/_7ffp%SN! R :^33 #?[ R+ fiM3!3 Z % #v?!1YR433 #?[ % #-, ^? 5#_ffp4 3fff #-/, #%))+]N/fi3+ 5# #2 _ ff*N/!1 fpfi5 N?; pU 3+ ff 3%S ?+S35N5<6:ffS3 ! jb9 %+ 5# )_U _ !0 )* ?+F :#3!b1 ffff ff ff%+ 5#3% #+ff=& O3!V jU 32 F ;3%541 f !V jU 3W ?ff* !3 !,$c/Dff 3ff#,S5P_2m+ ?2m# ff<!3 !1 H Qff #^ H !V jU 3]6 ! W9 fiff=+p% P /5P_T]+ ?!12NW b#/C5,- :+ ,$ O3!V jU 3 ?ff*( , ! !V jU 3Kff ?K!3 fiR?fiK3?76XdAeTf79 ff ?K!3 H. ?# *0#5#4,WffDC8hoOjfi }fiff|/|/}30 {}86 RVWdAeTf79M152H :A5fi/m%A ! ,* ?ff*;ff/26 @%, 2J/@9k -dAeTf /%ff*!,A :D%%^3+5# #c ;ff*;$ 3%#FdAeTf #6 kdAeTf7m9 /% ff* !)1 fc 5fi/f%( 73+ 5# #] RVWdAeTf#6 b?# *f9 /% ff* ` ; 5F!d=/3+ 5# #4m?# *ff !ff*+/3_2J368ff43j9M1SRb#PC5^f3+5# #c )5P_ 5P 2dAeTf/%ff*46#)dAeTf79d ?#* SRff6#]?#*9Q7 f%<6#Q?fi5n9M1 Wc 5fi/@%,2J5,8/@ ?ff*P3+5# #c 7dAeTf/%ff*;_ff#`+<4?$ /!1Bfff33W ?ff*%?#*vSR fff!ffF<2J51b#I*^f3+5# #c )5P_ 5P 2dAeTf/%ff*46#)dAeTf79dSR?#* ff6#V?#*9M,Amff_(c3+5# #F /%ff*( :f/ @ /JR^]% 3#6 3 ?fi5n9M1 fff`3?ff* W?# *ffW!ffp@%1SRLL<L52B$, ] 5fi/7 f/ @ /@ b#C #<" 5%f$##" ?36XdAeTf /%ff*n9M,] b#3I45fi/ % /J%#hoLfi~}~~/]{}/}b#5^f3+5# #K -dAeTf/%ff*m"2?5#_ff/5/%+ MA_@W (J5,ffbdb?# * ff &!ff*+p/%+ (J<68ff<3j9f$1( + k5 ?+ fiSRT=<=D2L" 5%4 ;$##] ?!,% ?P]5fi/7 2J b#"C @ b#4I% %2 ;? 5 #^]/Td$## ?]6XdAeTfl/%ff*n9%Tmffb+N^!% # 2 ?2#6 ?# *N#3 n9M1 U F :g ^ffH33 #?[ % #;V/2J@ 3 ff* /dAeTf `RVWdAeTf 3+ 5# #-, b#?TC Nff_ffN3 Z/ff +ff% 2_!+ F 5+ ^33 #?[ % #N! R-,5R%+( 7 5% ;$# # 7 ?!1NWNff gcm]'{/ #<! S+?ff*P "5P_7$# #?46XdAeTf /% ff* !), Q 3/fi_9P+y!?m_ ?7fffB/%+P :/ $ ?f/% ff* !1 52/ ) m-, f38?ffS+d!?/_ ?F ?DNR/%+/6: 2 /%+n9( :2 ;!% #/ ?/6 /% ff* T%# cdAeTf79M152 ffi* % ?F ! 8 $ ffD%$ f3 %8 / fiP!3 Z % #ff^ ;N/fi53+= F Nfi? ;5fi/=]vy=5fi/= gff*$ 3 % #;33 # [ ? ) 5 #K%F ! P#6 ff # # #'$#&% *9M,"!1% f,(D+ ; : K%K c6:# 3 3 fiM5% '$% *9M,%! # # 4! % # P ?% ff* $ 3 % #-{, ?_ff # ff#1 W + ,5P_5H$333 #?[ % #4]R@ b#/I; Dfi?" ^ ;ff`37`% ?ff*g 25P_5F k3!3 Z/ff/5+ ?g@%1KNW] 3F;ff,Fff# ##'yQ #3 3 fiM5% _?+% ff :/%+ 2@Sb#4I*p1 fN:% #4 : W/%+ (J] =_7 : b#5V, %/^_@ (J(8%+ 5# ;. + k5 ?+ fi0#1f%$ff]33 #?[ % #SN! R" "_Wfi ff"+33 # [ %/]3 +DTfi33+ 5# #P 23 ! j%+ 5# ?!1 _T fi5 i+ 533 #?[ % #3?ff* ffB b#SB51]e^m! ff,/+4/fiP5 fid?ff* % #-, #d3c/"!#T+N/fi! 5/;733 #?[ % #-1NW= ff5G, #32cff ?fi` % ! ff /'H4$# ;!3 ?!1PNO]fi%V53%, !3ff`ff D*3'H!3 ?!,!ffy*4'H4 _ ff*W%+ 5# Pfi?!, %5U _ (H43#b 2+"N/fi1VLRVLD@fiLfi"MN>_D^DChofi }fiff|/|/}b#PB5^f3+5# #4 AdAeTf30 {}SR/%ff* y?# *ff T%# ?_ffT+p+ ?Tfi?68#7,#-,; N#9- :Fff*$ 3%#R/A fffR/%+ M!1b#S@!LR^f3+5# #P dAeTfSR/%ff*)D?#*D ff%#R?_ffK+U 3dcu!Nff*^ ?#p3 N! 526W@!?$A+SLR1@79M1 fi7# VffT_!'m ff"+_?#*F$ 3%#F "_^ff-,5 H _ ff?//%+fi4G1 b%+S_p@ d2p@ fiff ff ff NUR ffN?!1 f"ff3?ff* R?# *y_ 5+ff#<? 5#_ff<5/%WVM&d2@DC<38xr/o>+?82 ?s?4z{o>2oz 4qK4>:A+s 4 % >o +?8r % @ :A'58qU:qK4>:A+sYR333#[?%#p3) 4fi% 7 :%U_ W* !%#3 )`3 pVb#?7vC IF#c <_N ff< %c 32#Z *2 _ ff ;_!'mff& gDC#!1hoOhfi~}~~/]{}/}SRdAeTfl/%ff*y?#* ffW!fiM"?%, T%2 NfiN#Z *2# Vff ?F/ =! ffff /%+ M!1 b# B+5%?3fiN _ff :]`+?+ $fi5?;#p#;3HbR^%A+5?+ V3;pN$*m53+b/ #+) :^dAeTf 3?b1 f3k/fi % #D%% ; ff-dAeTf 53+bc/! ff #S'{/ #/g_%+# ff]5/5d) ?%?m]ff/+ 5% ?g Wfi53% ff??+ ffvfi5 "%5 5?g+;ff5%"? 5 #K%5 fi##8/ ! ff3 % ff3 ?%?!1b#=@!L 33 + * ?+ 8, F#3PQ _ ff*Pfi P?!1 ^ " %U 3fi!Nff*" ?#;]]ff %+ 5# 3 5<%6:%5 S*ff]#D%+ 5# ?F %mfi%fffi 3 % %%m+ %?H_P, d)9MU 3!Nff*^ ?#-,#;ffMNpff5 R5 fiM#5fi/*vfiPffffi 3 % 2 :?fiM#53+b/4! ff #p^ !" _ff ff jN?ff#F_ff 33 # [ ff"Nff+ # #!1 b#@!L! ?fiM#Sff/+ 5% ?;#Z *g _ ff ?g_!'mffv-dAeTf F?#* ff;fU 3!Nff*S ?#fi?!,Fff/+ 5%%g 3KN?ffNff*!, #_fffi 3 %, 3)U ff ff*g3?% %+ff1 A]#]3 +d%F %!,##f3(bR^3 %f/%+^_d@ =d2@7c _ ff*)3?d$3 % #!,5 !_?ff 7 p3 fiM#(U 3u!Nff*T ?#v_ '1>ROCDCcc;SR?_cDCDCcc<38xr/o>+?82 .WqU8qK4>:A+sNW3M T+F!fi%3 ff 53+b"/!, ;Nff U_ W^?+ff=Rff/%+)_ffff*!^ gIjL_! ]6 %L4dAeTf /%ff*%=J%L]RVWdAeTf?(N/# :9M)1 fW?# H :?/% ff*!,fi5#[ ffFv% ,%7 N/%+fi! ?+ 88<! ff &dAeTLf /% ff* !1S_^$PB%L)dAeTLf /% ff*R!ff*+F%T ?+^K 7/%+!%1 fP! ff ffyff# ##'fi?36 #&% *9: /%+c_@%, (J5, Qd2N@ fiN#Z *##2 & ;fi?cNff&& N!/% ff* (ff" : f3 1( 2 ('HN/%+2fi?A/( _#Z *#1 ^ ; %2 D!!5`fi?WfiDff3 % #ff##-,$?/# P Rff3 % #ff###3 d$# # 5% u6 '$% *9M;]#m&'$% SffP_ff5 !ff`5pff ff ]#mTfi?F ff53 #?[ % # /fi5N! &( V, %"+2 g! ff v/)%# =#mc5%$# # c ?!1#ff#&%_@_2J2@(Jd2@%5I*1 ff51J51hJ51Jh511DC5D!'$%JC51C51B51@ffJ51 C51ff ff7FSL [ #&%ffB51>1R@%1 J@%1 JI%J51hC51 LCB51 JJ51 L*51J51 L?+%!'$%I*1JI*1 hJ%LR1 L@ 51 LLR1 L*ff7FSL [2YRfi W?#;ffii45!iIjL _ 5+=6#%ff LidAeTf /%ff*F J%LRVWdAeTf ?"N?ff( #&% R,H'$% N7FSL [ %1hoff%LR1 LIjLR1 LR@%1I*1h51_ffff*D!SNy/#:9M,fi }fiff|/|/}30 {}$&% fiz .1032)z{o54 ' + z :#s <38xr/o>+?82 @n :A' +{z{o5Bf)dAeTf++5%?%bU_ WVXffR#3bD# 5%#;R?bP%5U_ ) 35Pff\5?+ff4ff 53#'" dffv/d/!(%+5# ?26: ?%?n9K %mfi2Wfffi 3 % ) :mM ^+ #-1NW] 3F;ff#]3)$#+W K _ ff*V/%+H#6/n9]Ng% %!!b1 f)ff ff #7 RF//) ?ff* P ^/+ #F3g ! :H+ WU _ !DR 2ff 3#] _ffF$ ]Nff#_ ?]683 #b "5P_P$# #?dQ]+ 5% ff5P_P#3 $# # ?n9M, ^mffff #_ ?)3 #b P 5+ %/3 #',U _ff ff?#%/3 #'3]ff&? 5 #6X#_55 %+[?[ 3 -,k@ffBB 9M,k%5_ff/S^ ?%?gff/ T# #KVffNM ?!1NWS %fi 3 % #S? 5#_ff`3W/fi_ ff,$ /ff # D! %/3 #'= 5# 53]m5+ %/3 #', N3 #'#%/3 #'1DCSRffSRPbfi # # 4 dAeTf 53+b` ff*+3 ]% + % ?_ da;PN !ff#/ff&<NU_ !0 7 5+] H/'{/ K3%+RR?!15?fiM$*;! 3N _ff ] ff ff #/! ;%+ 5# ?;%fi3ff_ ff*U _ 5Nff* !1 ` ! ff8, %P% + %"_ /fi # #" NU N!_ ff`ff^mffG1A_AT 3)% + %RfiP#v! %+ 5# ?) %Tff_ffffS : ]M % #-1 ffU _ !0 g 5+ 2 -?+ ff"%g cdAeTf$3 % #_d/fi # #ff*+]'Hv$3 % #H/ff3` RU48/% ff* !,%b##Z *#? +* ?+/!1 f3/fi # #v?# ff/%+_d@ 3_2J51DC>C_T#% # ff#,//fi##S 3_d_ :MNff3+F4/7 8_ :MN+%3+5fi5 5#[?%# P3 ff /!,A5i 8 3#+<&!ffff /!5/fi /6 1 1#, _ ff*3%]_!'m ff<R= ff/%ff*T%fiMR$##?P : P$%9 QffQN/fi5%+ 5# /fi]3+ 5# #^ :P ?/fi !1_T*#Z *^ _ ff R3 3^3+ 5# #ff3_$ ff* 3#v* ?+ F%/fi^ FP? 5 #-1kW_ ^/3 : bd/fi # #(HffP]?# +NA! ff ff$53+b"# + W*4 W%+ 5# 7W%+ 5# PP/% #3%5 3$ ff* 3#*?+ //ff44U 3+U _ (bR^ ff1DCDCOC$7!ff3+"+p+%DR?T )/fi##U5V_c 3AHbQ6 YRf%,?cP_ ff,?da>5+ f %,-J%LL@9M17N!R# $*A k!#3;* ?+;+Sc%(U_ fiVf DT_ ffy+NRN !c54N!R< (_ 3ff`?fiM,- d#?ff*%#B3273%ff<ffy/2 5`*&fi!P!37 ?"6:%#<MN$##D5%S%c ?+7J%L S%9 =%# `# 3 R$# #5% Nc# W$# , %# ` N* ff* #`+b B#_ff# @!L "1 Afpff ff NNM, # ff #\53 #'F((_ff4 7/+fN$*#+ ff81 fAff ?fiP# #P : 8ff ffWM g;%U _ ;8% g+ff# [ff #W/" ?%?TRM 7 %fi;Nff #F?+% 1^NW3 3Wff,R?Rfip#Z *#Q/ p*# #]#; _ff% &@" %N]?ff ffff=53U _ff D%c/+T P ?%?2R5 /_53+b# +5!1 f#g %F fU _ g/]ff ff]/%# NS#&%&'$%5% #3)+ 5% ff5b#?A@ffC @S{ff # 1 J5,%5 Ri m$# #k ;/%+_@ d2@ P #&%&'$%/<h#&%&'$% * U 53 ff& :% + %?_ dT,kff$* 2%#AP&PhoPfi~}~~/]{}/}^5%_ ?!1NOg ]_^ffS%H) -%U_ ]ffffff/%+3(#;4 #&%&'$% *U 5$ ff ff ff/%+ffiP!#7+S 7*U 5G1)#)fi!vd 3>/ ) !2* Vfi)IB>/_`/)!!NOv3]mff^bR^57d #3!,(%p + 5!&=_?+F?#!,(3ffM ?);_%g!#W)$# A+P^+V'! :gM g - 57d /1)f3?NK %)q#&% ?'$% 5! n, #&% _F3 fifb$#, h'$% )f$# 1g3 fiM#{, 4#&%&'$%l/ H, #&% "_d^3 fif$#, k'$%lV$# 1NW 3H b 3\53 #'N?) a#&%&Ru6 '$%(9 = ff 53 #?[ % # /fi5N!(y7_ ffQ ff-1f3ff #BU 32%*& 37\53 #'&N?7_ffBff ff ff-,bN/fi53+%# F/ f*# #A\53 #'PN?(3 #b ;c+WVX/ffSN?1 *#.+!/0 /fi5N! j1MC/`53#" + 2 M:A'*+ ,+- 4 %wqozq/sS8 M:A'74>: 'fiffz52U_ 5ff]7DC_ ff*Nff fi 3 %#V %?-%*##-3#b U_ff#3! fi'$%ff#<7 ## #&%ff#7S5Mpfi"! 8:2 5+; ffFffSR?fiM5y4#&%&'$% /12YR$c%^##; -+m/fi5N! f3K/ffSS) :#%dfiNff*! m! ##'$%/,H p/ 3 p###&% UN ?M S+Q_4_!+ ff1;ff<5 y?+, #3$# 7+3N\53#'=N?h ,"; :#%#&%&'$% 5!MC3#'N?$#&%'$%'j1gNO3?++]7_ff c *##* !%#4 b/fi5N!;3+N;W_ 'S%ffff" :3 K5"5;^ 2j1mcfi/R#&%&'$%l/ffff)cV$*A/ff4p/fi5N!NWi_T# 5#YRf,K `\53 #'N?k%,A< _ ff*O#&%&'$% 5! u3/ff& #&%&Ru6 '$% (9M,%(v3A 7ff53 #?[ % #p/fi5N! ff1NOd3 # 5#ffN#U+ #?fiM5 a6:v#df$*#&%&'$% / vfi"bR^ fi j9c ff "'H&N??OF fiFff\5#fi ff*pff" %D!+ ##` 4*U 5g _! ff ffi5*7'Hff53+ !DR#] 7fi?( %^+(_dff ff ff4 :%/fi5N! 5q(v fi_ ff*!1KNW43(,#*(_!ff3_!+ ^_ffd# f* ! % #3(/*# # 1e^m! ff, &_T# 5#YRf 3v ff53+ 4_??fiM5 u#5#4,) #% # 3_ ff*!1 YR3 3 # 5% #R ?!m, _ :&3"/# 5% #6:'{/ #`J 9^* -5RM ?%fi;+ ff=54 :] #) F ?%?3`$R1NW3R ?!f, `\53 #' N?y3"ff :vM ff ff #a6: :%5c'H]N??1d) fidff\5#fi ff*n]9 (mff_( :) dff ff # ?%?f?#%bff ;#d$ ff* 3 :H+ #P#P\53 #'?/ff\5ff*#5% #!D : ) 3(, c\53 #'"N?d3A_!+ ^ k1 !^;U 3 %*1YR$7 %TmDff N$*;#6 j9 l` #&%&'$% / ,$%#&% '$%Lfi#2& #3 N$# # ?!V, ?_ff #ff#1pff ff ff9(`fi, / <_S!ff= :DC5MCDCDCAPSff>R>RWhofi }fiff|/|/}30 {}W3M ;1ANO^ `_^3%W$*(%WffRN\53#'%MS32ff45"c :#%; 8#-W3c#&%( &# %*69B 5 ( 9 '9Bfi B) &#$' %5% 5 ( $' % 5 (' % 5 ($fiBNW33( 8#-,?ff*^5P_ ) KMd$##?) )Mc%#3\53#')7%55dU #Q!%#UN ?!1 H ffffp4 _ ff* <fi,-/?$3fi2 _c!ff]5] 3H 8#-18fc3,R!ff]5]3H 8#-,?jU 3%f$* #&% , #&% C( Ru6 '$%(;9 4 jU 3%f$*fi1( ]1 f3;3^pb#2@@%81 f;# _H 33m3ff\55+2 (\53 #'c/;,%5 ff\53 #&%&Ru6 '$%(9M1fiB9BDCfiB9B9B5W5tppointsqualityqg=TP/(FP+g)RTPTP0-gb#S@@%fpFP)_ ?7 ;M?c%#<FN\53#' 'b#S@ffJ5/`^?4%##?+3\53#'!ff *+&"_?#&%&Ru6 '$% (9M15RV:kWN )#&%&'$% /,$*/%# # ]\53#' fi %$`3S3,;iff# c=_ S! :"M ff1 ^=%vik#&%&'$%/=`+V'! :F3S! ff /fi4 B/ $*p %p/fip ?ff*pM?"%# &_?+#&%&'$%5! F1 f3W?+% ?c %d$*2%7%_!ffy&S_?+d3 D%$S3]ff\5?#* $ ff%5 y3cff=5= /3 +D= /_?41PNO?ff* ffS5fi/#,%/5+"5P_K_?!, :; 1#&%&'$% / )%ff% 2 (3g$*(68L % %9 P (!#Rb5%3Aff #-,%%_;!ffP A_?41f7ff* ^b% #3;$*76 1( L*9M;1 f33+ 5% ffv b#S@ffJ5152P 8-,% : q \5 3 #'7N?ffP5#&% 3'$% ;#% #R33 fiK F]ff* G61* F%# / %NT\53 #';3 (P3)6 fi'$%9 #&%/,;# # _3A+ *fFff\5$+ j1* A%# v#A\53 #'"3 W%$7 c3W"ff#` F ; ! :2_ff1 fR$* ^ %T%_R!ff*+] ;_?fi;/5+p$* mS &#&%&'$% / :]5R/ffNff*( k 23)%##_ j, + fi "$*/68L % %W9 ` /ff #`+;fiM2 /#m5#*2ff1 f33+ 5% ffp b#/@ffh51!P N%PmFfi"#5b 4 :RQ)/%5 B3cB_ff Z%1"NW3F, /fi5N! A%ff d#/fi)%/fi5N! (%ff7Nfi1fN*ff* #y32+`N;bR= #&%&'$% / 1;_Ac ;/5++ %^+ #]#) ?%?;fi2ffF"/+m/% # ?A\53 #'HMC1G = , IHCfiJ7 D@7G = , IHCfiJ9eHK[ML [M\A\ VO\7 D@9fihofi B9B5fi~}~~/]{}/}b#S@ffh5/`^?b#S@O#Q#?+ \53#'kRV%!ffv"c_?: #&%'$%/11g3ffNff** ?+?];q#&%&'$%c/5+f# 5% #-1?jV/%% :+#3)5% ]$5ff1gY{ b#P@ P :m7'{/ / 3ffNff*g _$ff*3#N* ?+?%?%#&%&'$%l/ 1ff5fi 8 #/ - ?^ ?%?m3K+_)5RS #Rb]+P%g5/ nV# ff#D2 F ?%?!{, #;\53 #'R? S_(+ ff-1 HDc #!,+#^ ff5#=/ = /ff #` H / ! :2#mPff1 fD?+3T %cRV#ff /5P_'$% ff #!12e^m!ff, !ff /5P_#&%/0 f)mffG1AdHff\5ff*#,5 #ff#v; ?%?)+?A %%fiP!#7+]! :c#m7ff,- N# 5#%k2_N% +`?_ff 33 #?[ % #?fi c+4! :H_ Hff1 52#; WM ?F %;ff#h#&% fi{, vfiS 2_ )/fiH#&%&'$%l/ /, ff S5 P+S %b /fif7+ #48* ?+!?!1b#P@+ 5% ? ^_ ff )_!'mff"\53 #';N??% ) :MNffF+ff ffH/ ) ff5 ?%?g%5#*F_ 8/fiF - 1#&%&'$% / ;6 $*+%V' ff. (R/ 0 9M,*%g (3 % (. ! 5!0 _ff Zg ?%?( ! :K#mg6 $* b f+%V' ff". ;/ 0 9M1KNW; ?K%ff m3;3 fiO(R3G,% ; _ff<_+N$ *2 %#cffy!ff*7 #5#" /8+ #!ffS%# N73 fi (_?a%-1 ^,!ff,5 %g_T#5#YRf 38ff53+N# F%&p+ % ffNff* fi;; : ?!D1 f3TN?2 %+N,5fi/ ?!,\53 #'N?c/ff4p/fi5N! cffv?#p/_!+ (V+ #-1>R>RR>R*ffDC3 .1032 M: ?4. U8 K4>:A+ +- 4 %)z{o #wzs qWqqOCzffS8 M:A'74>: 'z;$/ )N/fi53 F N??!8, )#&%&'$% *U 5K :R?5P'H4N??%^_ ff`+Mff-1%fRffc;W _?%ff` :+%?2_ dT1f#&%&'$%fi* U 53 ; : ] 3N?`m`+ ff +Q %] :" _ ff*h(fi?*//m&+ ff-1 _T/ ff&#Q &*U 5f#&%&'$% / SmFff ff ff-P3?# ffQ*U 53 ?ff* ffQ5= b<3?b#?T@ffC @ 5m1 fT ]3?] ?ff*H #&%&'$% *pU 53 KffvS NT;ff: %/ ff"5" N?, :2fi?(_!'mff`LR1d@ %LR1b#?7@ffCVM@ / : W+ % ?^_ ff/+ 5% 7 %)$ 3!?f%R P3 fi?+/fi)#&%&'$%L/ ,- ^ %2 :'$% fi?T ;N?D3W% P+"/APPDCh5j*ififfPfi }fiff|/|/}30 {}b#S@*ff5%f;\53#'7ffN #]/fi5N! "ff]+ffff/%WV6$*n9&%#h#&%fi?!,%A\53#'ffN #*V2(/fi5N! K%{!3 +i* /%+%# 3 fi#&% fi ?;6:R5# *%/fi- 1#&%&'$% / j9 %mff5+ _QffRVP#KV#S\53 #'?!1>R5</ F$# #U N?!1<_T!M=+& v#3R F!#Rff #-,K 3;(dU_ffffp?#!1KNWM )+]%b77 _ ff7/c5#A#"7! :/fi(#&%&'$% / 3^?c?!1DCb#S@ffC5%f! :#&%&'$%/fi =#&%&'$%*U 53Q / RVff \53 #' N??#&%&R6u'$% (9;6: b=3 j9#&% M'$% 6:3j9 %% + %_P1 %_ff3_@ d2@7ff $# #HbV/ff ff ff5< "NffU _ ff* ?+ N53+bS?5 #!1/Pb#S@I*%f]! :/fi7 A#&%&'$%RVU 53 ?ff*u/ffp%^%+% T1h5job#S@ 5%f?ff*5! : /fi =#&%&'$%*U 53p ?ff* V/8ffR%F%+%2dT1fi~}~~/]{}/}DC#&%&'$%*U53 :N??KffR ff#Z *!, RB?3#' #R3D+1yf+5#'Q %* ?+ /"6:3!33$ffy3+45/%+ M7_@ d2N@ ff ff ff<5=U _ n9Wfi/%#R#3%$##f5%T%5 ]3 %S W5S%5 J^Hb g_!+ ff1KNW# #-,:N/7%#'$% L` "F$# #5% pRU N?;D%$'H& N?3fi H :m/) ff/%# J^ S%# J 1/,5 %H :m+ %?A_ffi)'HPF % /)68_2J "d2@9%5 /3 / (fi]_!'mffS 1#&%&'$%*U 53 !1/NO J N?+ ?Q1SN?Sm"ffB<U _ 5Nff* c%#dAeTfa-, %^ ?+%3_2J;3fffP_ff3! ff ff-1f( _ ff?_!'m ff;5RPb/f3ff#R?N/fi53+3b+Wff3%ffHbR3 ,N??8* ?+?!,!fi%#3N??f433#[?%#-1!#" <38xr/o>+?82 @n :A' +{z{o5BfA ff :K b* 5##'RR3 R3?ffP57E_ffY1!8G16W@ffBBC9M,>R?5#/d++ ff!ff#_ff/^> YH5_?N??fiM5 ff268>7^ff UR5nV#i :"Y5%3+ &5 "?n9R ++ff5 ^_ 68>7'? +ff-,2@ffBBC9N `NWf$57Y6:E _ffG,$@ffBBI*, J%LL@9M15 ^_ ?%A2?fiMc+b;Rfff3%# ff4,{G1 1#,]% fiNff<+3_fffi 3 % &% `6 ff3 % #9M,k%? `NW$f 57Y UR ff3^ +b`+4# ZV ff3 % #`% %/?!,-%5 3%ff3 % ff=+p"5P_g c ?fiM+b68Wf %fiff Wf ?_,$@ffBBI*D3 k#ff-,-@ffBBC5DE _ff f [+b G,-@ffBB 9M,/+#ff{"T/ff" kNW #)5468f [+b5 %,$J%LL@%D ff{5f [+b G,@ffBB 59M1f2/+N$ *g ?%?H5 ^_ `NW$f 57Y, ff3 % ff"+; 3]/fi_ ff,Rc2ff53+ g : f43cN??A* ?+?;?fiM5ff53+ fi`3ff /fi5% ff #]_ff#71 _ ff3 % ff fi5 +vfi5+/!dff ff #-, ?ff* ff {ff #J51 h5b, 3 W!/fiM!0 ]6W@ffBBR@9cHb&?#-1^ P %%+Nfi5 ?)+F+R 3% #p#3 +S_7ff :Wff{31+ ,) &&_ )WN 5 )N'VW#5#6 fi+b5 %,7J%LL@9M,T%5fi 3 ?+R3% #N; #P+7!3 Z % #R; #-,j K!3 Z % #R?%#fi5* ff$/Rff (%# R?_ff+fi!g!3 !1NO;% 3W/?83 +2+V'ff#Z g ?-,fiDffP_& )WN 5 )N'VWBm3D_ffff*K. 5 5b0HbR^ ff%$2 / fi !P!3 !,%5 & <_;!mffB<? 5 #`%#fi5* ffB#Z _,$ W&Rff 1;3 fiM#, /R/% #; !,*R ff;5P_; ff{5 ;6GJ%LLL*]9 Sff]c/3K :g %]3#5#3)/fi_ ff,R 3 # [ ?K 2$)ff\5ffNff*];N?T%5 ]+_d% 3W/ff5F! p)+S_d!ffF ffR/% #p!!1H %$ 7Nff* #ffvfi5 ?(+N43U ##H :% #F%$!3 cNffP_5O1 52H /?+2%*` ?fi5 ?dfi;;* ?+2 :dV`33A %!,3 #b 2 P!3 !3 Z % #p#v#5#f5ff{2J6XdA3 fibW# !+!,-@ffBB;9 _ 6 5 3 +b G, ` [ ! %,e^,5 %,@ffBC9M, !"2 5N# 5#41NW"5N#5#g#/ ^/5+g !uffM ?gff/^b`>b`QdQafb`b`f!df&f&c` b`ed` b`fcfifUaSah5j5jffffffi }fiff|/|/}30 {}S^_c )* ?+%%3?5+5(%# " ff*) 5%12YR/ff\5ff*#FffvM?fiff/3ffU N/! !m, 1 1#,f/!!`# $##pUN ?ff=5v!##vffvM ?!;1 f3(/3^+ 5( $3%# :3N7;ff/ %m3F%5R :g WS3NR ?F%5 N3!{, /ff5G,Nff%^3 5* ?+_ ?A8/H ff* d$3 % #-1fffff*fi5 ?2+v&3%2R ffF 3WfiV53% S/37 ( F+ fiM 5 #5#4p1 fff ff*#Q!ff#_ff3WVF# 5#Ad 2JVWYRf 6 ff{5 %, 3 5 -,Rd> ff !b,kR+b G,J%LLJ]9 2YRf 6 ff{5 %,ff ![ff ,3 5 -,J%LLJ9c; +%V' ff<m?#* ffQ5#5#4,3 fiT+3 /NffNff* ffp4_T# 5#f <Y4? 5#_ffv 3;/fi_ ff1NW+ <m?#* p 3 ffN$*v$5+ 6 fffi/,@ffBBCp9#% ff 3# ?6XYR5 fi/ff,;@ffBBB9M1 NW+ <m?#* ffQ_ffff3 +4fi fi53* ( 5# 5#NffNff* ffpc ?fiMfi5 ?%5dN6XdHff-,R@ffBBB9M, 6 , A5-, i%_3!,5@ffBBV9 7f)_^N 68We -,Y5R M3 -,+?[ #G,K@ffBB9M1;_ fi fi53*2 g ;m?#* ffQ5p#5#2_ff&ffy3 +p=ff{* UR2 FR/% #d/!Wff ff #6P_5 %,kJ%LLL*9M,ffWS/3: ) dM /!fff ff ## 5#2YY"? 5#_ffp 3;/fi_ ff1`f;dfibaf (d`U`fI``>dcf`edf! z{q('58oz ' +- ?s?4z{oz '74>:#srsz '*'fi5#%Md!fi%#=N??Wff53+ %ff_ ffNff%"/3 Q#[ = da6! ff+#/3+5# #g5?6! ff+B/ #++ff4 :=3 ,(i5] #+B-9M1>7'? +ff-,7@ffBBC9S%#fv_ ? 8#%BW@E@P/c?7'H] #+5%ff7_ ffpURff#ff#v+ffQ6:+%V' ff V(V!/*9M13 fiM#,! Km?#* ffdff3 % # ]!!5dff53+ %,ff6R966R9 56 6R9 6%9+;9 `ff35pkR+b G, 3 5 -, ff{5 46GJ%LLL*9M,5?( < ff53 #' dM S6 6R9M/, G1 1#, c5%j%9 pff3 % #d!!56R9 6%9M81 f3]ff53+ %3m! :3 % #] kk 2N??AffF5 ^_P1m??N5 . ff # 0gN??;* ?+?!], +N&. ff #0gN?RV?+?; 23 ff /%+i_" %b ff *+& !*!;, 5 #%/3 #'6'. /%+ 3* ?+# `+N! <%# #/+ 3;fi* %0 9U _ff ff?"6 /%+ 3* ?+ `+=R##R3R53"+=*96X#_55 %+[?[ 3 -,@ffBB 9M1BBDE> H B @E@ ED > H BMC@E@ DE> H B E@ @b`B@E@?DE> HSRfDE> HSRedff! <38xr/o>+?82 W. qU8qK4>:A+s z{q('58oz 'fi%#4 )ffp/f4Q`57du/6u)+ ffA!+!,kJ%LL@9%%^!3WVZ/ %_ :M4^ K #3R3fiMZ7[M\ E*V/HKJ>EGXUNUXAYV L [N V&'$% h! 6 #+ff`3V!jU3n9%g ffF+7_^#[ ff-,ff###'1NULGFV HKJ>EGXUNUXAYVbL [N V6#&% $6 #+ff V!jU3n9c%/ ffP+&_"jU#[ ff-1yf` 57dl/v3Rfi53%"]! :N?5]D!?T ]=3 ,VD/)%$#&% ?'$% S5!MC 3!#P+"3%k =_P3 fiMffW#Z *!1(_Tfi53%fi5`+F!fiRV%R!g ffN/)3F5/cWfi? F1` 57di*UF5ff/5/F%#ST_?+#&% ?'$% 75!MC ;\53#'SN?T :(N/fi5P!?KD_C ff*(?fiM 5!1h5jfi~}~~/]{}/}`_ # M%#?+=vfi?& P 57d *U 5gN %# fi" N+fiM!fi%#iN??;ff M?fiM,)5 Dff#v!!5ff,m3 4N " ffQ+ 5* P %ffQ+=_%b ff *+`F!*!,K]5!N??f _ 68> ff ff, b% 5+-,ff,(J%LLL*9 _T+ ff %% # %% #=68_2936 m5%[ffG,Y5fi?!,?5R, J%LL@9( %^P/ d!! 5p4Nc+?fff3 % #d_ :15W# [ ffd!!5R3!fi,! ff, H#% g5P31NWR# #+/ dfi?S 57d *U 5$\53 #'"N?, fN$*! ?)N??fiM #Z 768N?52 )3+ 5# #*5?k_$9M, (5%68N?53 fi 3%S3 ff$9M, # [ # [ 78NM d!;68N?5DN3 #'p= 5+ %/3 #'" g3ff=bR^ ffj9Md1 f?N??Tm/ff+!fi% 7 d?# ;d 2JVWYRf33v#5#fi6 ff{5!WG1#, J%LLJ9M1>_ O^?dWd>R`MC1`/`b`e`fif! <38xr/o>+?82@:A'58qU:qK4>:A+sf % 733 #?[ % #/N! R)ff ^_ffN/fiF_+ % 3+ ]S%#3b??fiM5 :H*?fi5!1]f3;??fiM5`ff*5%ff5fi5#/p #+/cT/d _ffff*Hfifi53% ?%+Q _ffff*;fi fi53% p$;WU #5%+% B#34#6b !,c@ffBII*D ,52, !b,@ffBB 5D T*%-,J%LLL*9M1fP33 #?[ % #3]#3f?# W!_,!ff,-ff=#pff ff*#+ND%+ ff* #%# F3 # 5% #Q ^% &6X;fiM-,b 3 ff,?-,H@ffBBB5D ff5-,W5+ ?-,E 5,J%LLJ5D> ?> 5!ffG,$@ffBBC5D/ , ^5SNV 5#,H{ ? ff-,J%LL@9Mm1 fT33 #?[ % #S#3]?# ]5fi5#D?A :;$?!k_!+ f+ 5%/%+ M/+7 ffS ff, ff% ( )N/fi53+;/%+!{, ?;/%+! ,ff% /%+ ff#$/ :W%%W!V # 7\5?+ #R1 fff ff*p* ?+F]33 #?[ % #&f#3?# 7;R/ff^ffQ5& ] : ff%ff`5P_RNU #'" K%R?# !1f? 5* ?+ ffy`N/fi5"33 #?[ % #3N! R$ff` 3f/fi_ T%#]/33 #?[ % #;N! RK ;;(33 #?[ % #_/K_@ d2f@ ;+*(H b5P_ff, ff{5 %_, E!+ 5 ffb6GJ%LLJ9M1ffcMC`R@cbSdPfK!]fif3/fi_ d?ff*3ffmQ3 B#5#*!5%ff*+3ffQ+ffbR^ff(3 RR?!1bf(3!#RDffN/5 ?#$*fN$_ff # %U _ WVXffNS3; q#&%&'$% / 1NO Ffi* %?mfi$#/3 #';+TbR^ ff%^ _ ff*( !ff3 kff53 #?[ % #Q#6 5 !ff35]k( /fi5N! " c3#5#"9;ff `\53 #'iN?%Nff?; ##\53 #' ?D3 +Bff53+ Fi3R?!%1 f/fi_ fi?^ %WU _ !0 W*#ffNff*` R #pR ?W3Tff ?fi: %! ?+ 8V#% 7bR^ ffcff5% #-1f$ffvU _ WVXffp33vR ?)3+ ( 7 :#%N+ /!ff5+,%% c 5+ W/fi5% #-,/3{,/!%ff ff #-_, + % 3+ 5 fi5 5#?[ % #=)/!/,333 #?[ % #-, ?WRV! % #N!fi% #-b1 f)N+ /!,*? 5#_ffD/!; 3b/fi_ ff, fi%3N/fff ff #S_d/!K -#5f/!, :#mff/5 %+ % 3+ 5 fi+V5#?[ % #/ %b$(# +5+T ffd? 5 #!1OCDCh5jfi }fiff|/|/}30 {}YR$; #+5W ?ff*fff*% :M%#%$W/!, !,3^/#-,?A 8 #v3mUR ffNff#FN$ *;/%+ M4? 5 #-,5_ff2 !Fff "U _+]/ PN! P5 fi5 5#?[ % # 3_!+ 5+ 8/!1 `Vff, !?7U _ !0 TRff 7 %^ /%+3ffi53% 7 :^ ff%d32++# 1;NW# #-,&33 #?[ % #yff /< 5+ ]ff3 %#/]/D/%+"#?A3#* m*+; ?ff# ##'" #3 3 fiM5%1fD?ff* ffBfi5 <+`? 5 ##&?U _ cbR^ ff%!+ 152 * ff* #=;c2+4v++ ff%c%3U _ W5% c+p! R#& %P%N8ff BU _ d< ]bR^ ff]3R ?!1"NWQP!7,k$#/3 #'/; #FR ?f3ffi* %P 3fi5 -1/&af3$Hbc;$ffc5cF(dm%33+^ YR ffmff5#,5YR#ff3%#-,HYR ffv Y{$!,88ffB ff/f%fWff 3#YR$ K : A?HdHN_!##ff?!__? * 53P6:NYAVM@ffBBBV@@ *B 9M1 E fi& 5% ! 82+ 5> 5+ Buk33ff YR= :4?43%$5%#QFU_ 5Nff*fi ?fi;3?53+b&! ff #-,K+^! 3 5 :D33%$ 5% ##3K k _ ff*H\53 #'/N??!, ]+;f ! 55E !+ 5 ffb :R$* 5(+S ff3 % ff4Hpb33 #?[ % #-13+&ffcDCff>RS/Sd ?5R, `716GJ%LL@9M1;`fff 5bK -!3Z/ 5K5Nff3%ff*2!3Z/ 5!17NWWL J * L VGE E X + 1LONUX 7X#[M\x+N VO\A\ X * V,+GVffWL J GV V fiMX + * EJ Z NKV?V,+NJMLONUF * FVGE*V J/+*Z*VOL V,+GV J/+ 1LONUX 7X#[M\x+N VO\A\ X * V,+GV1Y{5 ff1d;fiM-,Y15>/1#,Ka b3ff, 1Rf1#,(aY?-, T16W@ffBBB9M1 V [fiMX + * E X +fiX +*Z7JMLC0 [NUX#J/+Y5X EGF([M\X.-*[NUX#/J +1 `a `>d 8-1dA3fib,q1#,/d W# !+!,c176W@ffBB9M1 fdfi2J # #5#41T[ X +!V V [MCL +(X + * ,,m5%[ffG,n1#,Y5fi?!,RdT1#,PJCR@ RJh51N , #+!,O_C ff#RMP?fiM ff1ANWWL J GV V fiMX + * E J Z &+H+(F([M\VOLGX [/+ E7J 7X#[NUX#J/+ Z7JML 1LONUX 7X#[M\ x+N VO\A\ X * V,+GV1fWQ`%fiff!, 1#,?dafW?_, 1k6W@ffBBI9M1)dA3-3 1!T[ X +!"V V [MCL +(X + * ,#%$j,BBAP@O*C51f [ f +bG,-Y1#,d ff{5 %f , P16GJ%LL@9M1& VO\ [NUX#/J +?[M(\ '&[N)[ X +(X + * 1HY{5 ff1ff5-, P1;a1#, cW5+?-,c 1 c 1#, E 5,_P1H6GJ%LLJ9M1x+*Z7JMCL 0 [NUX#/J +,Y5X EGF([M\ .X -*[NUX#/J +,X +*fiI[N[0 X +(X + * [/+ fi,++?.J -\ V fi * /V fiMX E JMYVOL %1 `a `>d 8-1ff5-, P1!1#,3d N'5G, >/1 T1F6W@ffBBJ9M1O52`D3S g*5WVXfiff %+5# ?Wff 3# 7ff 5%#-1!T[ X +!"V V [MCL +(X + * ,0, IOP@!LJ51ff5-, P11#,]3%!+b5*VWYfi/,Sc 1#,Sd YRP5-,?1$6W@ffBBC9M1%P2+PbR^ff3 _T !71NW 1fiMYM/[ +GVGEX +32+?.J -\ V fi * !V 'eX E JMYVOL &/[ + fi4'&[N4[ X +(X + * 1_T_T_^NdHff-, E1 E1K6W@ffBBB9M12_/J +*Z*VOL ,V +GVJ Z &0)?!1h5j5hfi~}~~/]{}/}ff-, ;1#,d Yfi/,`71 126W@ffBBC9M1 U_ 5Nff*S%# ! $5+ #5#41 NWW L J GV V fiMX + * E/J Z NKV ( XALON V V,+Nx+N VOLC+?[NUX#J/+?[M\ J/+*Z*VOL V,+GV J/+/T[ X +!V V [MLC+(X + * 1Ma 5?fiM1cP_ ff,Pf1#,&d ff{5 %f ,P1]6GJ%LLL*9M1 dHR/M%# !!1 NW WL J GV V fiMX + * E J Z NKVJMFSLON WFSL J H(V [/+ J/+*Z*VOL V,+GVfiJ/+*WLGX +7X H?\ VGE@J Z,'&[N[ X +(X + * [/+ fi 2+?J.-\ V fi * V 'eX E JMYVOL %1$Y{5 ff1cP_ ff, f1#, ff{5 %f , P1#,d E!+5 ffb,-f1k6GJ%LLJ9M1(YR33#[?%#-R_N!RDfi 3 %#R$ 3%#R ff1RNW)WL J GVV fiMX + * EbJ Z N KV x+N VOCL +?[NUX#/J +?[M\fiJML +5E SJ H/J + x+N VO\A\ X * ,V +ffN '&[N[ &+?[M\ >EGX EeX + V fiMX 7X +!V&/[ + fi3 S[MCL 0 [ JM\ J * ' ! ##1cP_ ff,f1#,Id YRf%,fic16GJ%LL@9M1qff + \ X +!V '&[N4[ X +(X + * VOLGYVOnL 1K^` >R H +f b )NW+#,*+ _j_!1 1 ff1cW!/fiM!,3H 1g6W@ffBBR@9M1d;5p/3N_!4ff 53#[?%#!132+?.J -\ V fi * V fi7FSX EGXUNUX#/J +JMFSCL +?[M\ ,,hCR@PRh%LR1cT-, 1#,3c fi_ ff,_P1!1#,Wc ff,kY1_P1#, eT3%+b5,!1$_P1K6W@ffBBC9M1dH+WVO_C ff#ff?c?Nff*]/%ffNff*F 53+bP #+5!1 JMFSCL +?[M\?J Z &0 VOLGX /[ + JM\A\ V * /V [ML fiMX#JM\ J * %,#! ,@!LJ%L P@!Lh%LR1eW-,Af1#,^Y5R M3-,AY1#,d +[?#G,5126W@ffBB9M1 _ ff*" 5 #5#Yfi 3ff+3UR7!3Z %#-1PNWWL J GV V fiMX + * EJ Z N KVfiJML +5E SJ H /J + V [MCL +(X + * ZGL /J 0 ?VIN[N V * JMLG.X -*[NUX#/J +1fi+bG, 1#,/d ff{5 %f , P1P6GJ%LL@9M1 dA3Z %# M&?fiM%# _&)` NW5b)` N'VWdT1 NWWL J * L VGE EbX + 1LONUX 7X#[M\ x+N VO\A\ X * ,V +GVWL J GV V fiMX + * EeJ Z1N K,V ?,V +N / JMLONUF * FVGE*)V /J +*Z*VOL ,V +GV /J +1LONUX 7X#[M\ x+N VO\A\ X * ,V +GV1Y{5 ff1>?4,f1 _P1#,a>5!ffG,eP11k6W@ffBBC9M1 33#[?%#ff5\5?( :^;3fi7%%/?!N/fi53+-1 KL /[ +KE7[ *NUX#/J +KE /J + 2+?.J -\ V fi * V /[ + fi3'&[N[q + * X +!V VOLGX + * ,(0,BJhAPRBh51>ff ff,1#,?b% 5+-,*Nn1#, ff,eP16GJ%LLL*9M1k_T*!5%ff] g :g#5# 53%5b7%#5#!1 NW( #fiJML +5E SJ H /J + V7N.[ V [MCL +(X + * FSXA\ fiMX + *1FKN/J 0 [NUX 1fiMY5X GV ?NUL [N V * XVGEZ7JM4LJ fi VO\ VO\ V *NUX#/J +/[ + fi)V7NJ fi /J 0 OX +?[NUX#/J +1>7'? +ff-,KE1T6W@ffBBC9M1U #5RF_1fiMYM[/+GVGEQX + 2+?J.-\ V fi *V 'eX E#/%+#3+5%!3+ + * 1 `ffN )?!1JMYVOL [/+ fi)'&[N[3 X (X Ka>cffb,Nn1k6W@ffBBh9M1HNW#d ;ff?3=?fiMN4Nff -3%3!1x+* ,+ , !,hR@I RhhI*13+*!1HIH?\ XV fi 1LONUX7X#[M\ N VO\A\ X V GV OPff{5 %f [ f +bG,Y16W@ffBB>59M14x+ fiMF*NUXAYV"3J * X WL J * L [/00 X + * "?V ?+(Xfi7FVGE [/+ fi HIH?\ X [.f , P1#,!aNUX#/J +KnE 1 33He^H5R-1ff{5 %f , P1#,35-,1#,F>dff f !b, T1#,d kR+bG, 1)6GJ%LLJ9M1i_Tfi&!3Z %##+d/3 1 NW,WL J GV V fiMX + * EbJ Z NKV x+N VOLC+?[NUX#J/+?[M\ff J/+*Z*VOL V,+GV/J + '&[N3[ X +(X + * 1ff{5 %f , P1#, cP_ ff, f1#,!d M!,H16W@ffBB9M1)_ ff!fi"# ) :^+M#RnV#-1 x+N VO\A\ X * ,V +N >EON ,V 0&E (KVOXAL HIH?\ X [NUX#/J +KnE , ,!%ff L PSff C51ff{5 %f , P1#,/f ff![ff ,3H 1#,3d 35-, 1F6GJ%LLJ9M1 2` YRf f` ff3%#b&3 `/5+WVXM c ?%S+M#-1NWWL J GV V fiMX + * E J ZN KV - VO\ ZON x+N VOCL +?[NUX#/J +?[M4\ /J +*Z*VOL,V +GVGE&/J + x+ fiMF *NUXAY4V 3J * X WL J * L /[ 00 X + * 1Y{5 ff1NWh5jfi }fiff|/|/}30 {}!b, 1eP1g6W@ffBBff9M1 U ##"33#[?%# =bR^ffS3WVWL J GV V MX + * E J ZeNKV XAL EON x+N VOLC+?[NUX#J/+?[M\! J/+*Z*VOL V,+GV&J/+ 2+?J.-\ V fi * V"'eX E JMYVOL[ &[N[ X (X, ;1#, A5-, T1Sc 1#,Sd _%3!,1 a16W@ffBB9M1>7^ffVX/ffS?fiMDU #5%+ff ?fiMRM?H+NffmRff*( fiM ff #'1T[ X +!V V [MLC+(X + * , j, JR@IOPJ>LR13R,eP1#,!d k#ff-,eP16W@ffBBC9M1&52#5#:)D* ?+ff*ff?!1NWWL J GV V fiMX + * EJ ,Z VOCL +!V7NUX OE&/[ + fi >EON ,V 0&E $j153+bG,(7` 1-Y1#,`a [ ! %f ,-Nn1#, e^, 1#,?d ff{5 %f , P16W@ffBC9M1%fP#ZV $ffNffRVH?fiM++ff_ @*ff #7?+ fi 3 %#<Q "Nff g!1"NWWL J GV V fiMX + * E&J Z N KV X ZON Q[NUX#/J +?[M\ /J +*Z*VOL ,V +GV&/J + 1LONUX 7X#[M\ x+N VO\A\ X * ,V +GV1S`a 4>d V;1#, 52,-eP1 1#,1FNWfi/+ fi3' ) + + * 1,eP1-1)+!,> H1#,MdV [MLC(+ X + *ffA!+!,c156GJ%LL@9M1 `) +!3Z %#2 :Nff 3bff*Nff*!1 T[ X +!V#,$J%LhAPRJhR@%1,K`YR5fi/, 71 1#,ff, ;1k6W@ffBBB9M1gNWNff$5+D#5#A;RffV5%ffff#!1 + "C+ + * , !,$JBI RhhC51T[ X !V V [ML (XOPffSRWL J GV V MX EfiJ Z N KV XAL EON N VOL ?[NUX#J ?[M\ J *Z*VOL V GV@J ?J \ V VeX E JMYVOL [ &[N[ X (X/MC,*Y1 1#, ^5NV 5#,1#, H{?ff-,a1*eP1 6GJ%LL@9M1WL J GV V fiMX + * E J Z/NKV 2"'4'#fiJML +5E SJ H /J +3X EGF([M\ '&[N)[ X +(X + * 1kR+bG, 1#,S 35-, 1#,Kd ff{5 %f , P1-6GJ%LLL*9M16)ff#%_ :M^ m?#*ffFff3%#!!51&NW WL J GVV fiMX + * EfiJ ZN KV JMFSLON WFSL J H(V /[ + /J +*Z*VOL ,V +GV@/J + WLGX +7X H?\ VGE9J )Z '&[N[X +(X + * /[ + fi32+?.J -\ V fi * "V 'eX E JMYVOL %1$Y{5 ff1b!, 1E 16W@ffBII9M1 GH?\ JML [NJML '&[N[ &+?[M\ >EGX nE 1g_T3+"E?!1T*%-,fi_P1 6GJ%LLL*9M13X EGF([M\ .X -*[NUX#/J + Z7JML fiI[N[ 0 X +(X + * 1*+ __ ))P@%1%-1 ZV+ 1 >_ j*%?j_ _T*+*R_%G_ 3 fiff>c?fWffffJ%LLLR1 - O1YRf%,c1#,?cP_ ff, f1#,?d >5+ f %,3c 1k6GJ%LL@9M1)dHP/;_ #[ ffFp_ #[ ff5;?fiMF #3^ F]dAeTf /%ff*c%%/1cNW WL J GV V fiMX + * E J Z WX * N/J +*Z*VOL ,V +GV/J + 1LONUX 7X#[M\ x+N VO\A\ X * ,V +GVeX + V fiMX 7X +!VQX + WFSL J H(V 1-Y{5 ff1E_ffG,Y1g6W@ffBBI9M13_TB#5#:#ZVff3%#K3 & /!1/NW WL J GV V fi.X + * E J Z&N KV XAL EON WFSL J H(V /[ + /0/HKJ>EGXAF 0 /J + WLGX +7X H?\ VGE J "Z '&[N,[ X +(X + * /[ + fi,2+?.J -\ V fi * V'eX E JMYVOL %1$Y{5 ff1Y#_ 55%+[,_P1#, [?3-,%_P16W@ffBB 9M1 52 ff#^N??F V* ?+?);bR^ZVff43 1=NW*fi + *1x+ C+/+ /+ ,+ /+ 2+ .- fi *'/+ fi3' ) + + * 1_T_T_^N1)?!1E_ffG,Y1K6GJ%LL@9M1NW#;#5] :2bR^ff/3 =%%/?!17NW/+ (' 3 + + * 1 {Y 5 ff1VO\ [NUX#J ?[M\ &[N[ X (XE_ffG,Y1#, f [ f +bG,kY1K6W@ffBBff9M1fN ?5#`?fiM ff4/k;fiM]ffRV5/RffZV'!ffk##4 g%"3N )1^NWWL J GV V fiMX + * E [ * LGF5HIH(V,+NUL VfiffbV,+T[>E X +!VO\A\ VG4E VOCL +!,V +1 T#1fT-1E_ff Y1#,E!+5 ffb,Rf1#, bfi/,*_P1Nn1#,5Y!_?!,%_P1#,Ia 3R,eP1#,>c;%b5bffG,IH1#, >7#{?WVff-,E 16W@ffBBC9M1 W * 5##'4 33fiR %]1HNW WL J GV V fiMX + * E J ZN KV /VOCL 0 /[ + fiJML +5E SJ H /J + T[ X +!4V V [MCL +(X + * 1 T#1d;ffS#+[1h5jfiJournal Artificial Intelligence Research 17 (2002) 309-332Submitted 06/02; published 10/02Analysis Phase Transition NK LandscapesYong GaoJoseph Culbersonygao@cs.ualberta.cajoe@cs.ualberta.caDepartment Computing ScienceUniversity AlbertaEdmonton, Alberta, Canada, T6G 2H1Abstractpaper, analyze decision version NK landscape modelperspective threshold phenomena phase transitions two random distributions,uniform probability model fixed ratio model. uniform probabilitymodel, prove phase transition easy sense polynomialalgorithm solve random instance problem probability asymptotic1 problem size tends infinity. fixed ratio model, establish severalupper bounds solubility threshold, prove random instances parametersupper bounds solved polynomially. This, together empiricalstudy random instances generated phase transition region, suggestsphase transition fixed ratio model also easy.1. IntroductionNK landscape fitness landscape model devised Kauffman (1989). appealingproperty NK landscape ruggedness landscape tunedchanging parameters. years, NK landscape modelstudied perspectives statistics computational complexity (Weinberger, 1996;Wright, Thompson, & Zhang, 2000). study genetic algorithms, NK landscapemodels used prototype benchmark analysis performancedifferent genetic operators effects different encoding methods algorithmsperformance (Altenberg, 1997; Hordijk, 1997; Jones, 1995).field combinatorial search optimization, one interesting discoveriesthreshold phenomena phase transitions. Roughly speaking, phase transitioncombinatorial search refers phenomenon probability random instanceproblem solution drops abruptly 1 0 order parameterrandom model crosses critical value called threshold. Closely related phasetransition solubility hardness solving problems. strong empirical evidence theoretical arguments showing hardest instances problemsusually occur around threshold instances generated parameters far awaythreshold relatively easy. Since seminal work Cheeseman et al. (Cheeseman, Kanefsky, & Taylor, 1991), many NP-complete combinatorial search problemsshown phase transition associated easy-hard-easy pattern (Cook& Mitchell, 1997; Culberson & Gent, 2001; Freeman, 1996; Gent, MacIntyre, Prosser, &c2002AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiGao & CulbersonWalsh, 1998; Kirkpatrick & Selman, 1994; Mitchell, Selman, & Levesque, 1992; Vandegriend& Culberson, 1998).paper, analyze NK landscape model perspective thresholdphenomena phase transitions. establish two random models decision problemNK landscapes study threshold phenomena associated hardnessphase transitions two models.rest paper organized follows. Section 2, introduce NK fitnesslandscape probabilistic models, uniform probability model fixed ratiomodel. Section 3 Section 4, threshold phenomena phase transitionsNK landscapes analyzed. uniform probability model, prove phasetransition uniform probability model easy sense polynomialalgorithm solve random instance problem probability asymptotic1 problem size tends infinity. fixed ratio model, establish two upperbounds solubility threshold, prove random instances parametersupper bounds solved polynomially. This, together empirical studyrandom instances generated phase transition region, suggestsphase transition fixed ratio model also easy. Section 5, reportexperimental results typical hardness fixed ratio model. Section 6, concludeinvestigation discuss implications results.2. NK Landscapes Probabilistic ModelsNK landscape f (x) =nPfi (xi , (xi )), real-valued function defined binary stringsi=1fixed length, n > 0 positive integer x = (x1 , , xn ) {0, 1}n . sumn local fitness functions fi , 1 n. local fitness function fi (xi , (xi )) dependsmain variable xi neighborhood (xi ) Pk ({x1 , , xn }\{xi }) Pk (X)denotes set subsets size k X. important parameters NKlandscape number variables n, size neighborhood k = |(xi )|.NK landscape, neighborhood (xi ) chosen two ways: randomneighborhood, k variables randomly chosen set {x1 , , xn }\{xi },adjacent neighborhood, k variables indices nearest (modulo n)chosen. example, even integer k, k variables (xi ) definedx((n+i k ) mod n) , , x((n+i+ k ) mod n) . variables neighborhood deter22mined, local fitness function fi determined fitness lookup table specifiesfunction value fi 2k+1 possible assignments variables xi (xi ).Throughout paper, consider NK landscapes random neighborhoods.simplify discussion, assume local fitness functions take binaryvalues. Given NK landscape f , corresponding decision problem stated follows:maximum f (x) equal n? NK landscape decision problem insolublesolution it.proved NK landscape model NP complete k 2 (e.g.,Weinberger, 1996; Wright et al., 2000). proofs based reduction SATdecision problem NK landscapes. study typical hardness NK landscapedecision problems framework thresholds phase transitions, introduce two310fiPhase Transition NK Landscapesrandom models. models defined below, neighborhood set (xi )variable xi selected randomly choosing without replacement k = |(xi )| variablesx\{xi }.Definition 2.1. Uniform Probability Model N (n, k, p): model, fitness valuelocal fitness function fi (xi , (xi )) determined follows: assignmentDom(fi ) = {0, 1}k+1 , let fi (y) = 0 probability p fi (y) = 1probability 1 p, done possible assignment local fitnessfunction independently.Definition 2.2. Fixed Ratio Model N (n, k, z): model, parameter z takesvalues [0, 2k+1 ]. z integer, specify local fitness function fi (xi , (xi ))randomly choosing without replacement z tuples possible assignments = (y1 , , yz )Dom(fi ) = {0, 1}k+1 , defining local fitness function follows:0, ;fi (y) =1, else.non-integer z = (1 )[z] + [z + 1] [z] integer part z, chooserandomly without replacement [(1 )n] local fitness functions determine fitnessvalues according N (n, k, [z]). rest local fitness functions determined according N (n, k, [z] + 1).theory random graphs, two related random models G(n, p)n(n1)possible edges included graph independently probability2p, G(n, m) exactly edges chosen randomly without replacementset n(n1)possible edges. well known monotone graph2properties, results proved G(n, p) (or G(n, m)) also hold asymptotically G(n, N p)(correspondingly, G(n, N)) N = n(n1). However, cannot expect similar2relations exist two random models NK landscapes defined unlessparameter k tends infinity. result, asymptotic behaviors two NK landscapemodels significantly different fixed k.conclude section establishing relation decision problem NKlandscapes SAT problem. decision problem NK landscapef (x) =nXfi (xi , (xi )),i=1maximum f (x) equal greater n?, reduced (k+1)-SAT problemfollows:zV(1) local fitness function fi (xi , (xi )), construct conjunction Ci =Cijj=1clauses exactly k + 1 variable-distinct literals set variables {xi , (xi )},z number zero values fi takes Cij assignmentyj {0, 1}k+1 falsifies Cij , fi (yj ) = 0.nV(2) (k+1)-SAT conjunction =Ci .i=1311fiGao & Culbersonx0000111100110011z01010101fi01101001Clausesxyzx zx zx zTable 1: local fitness function equivalent 3-clauses.Table 1 shows example fitness assignment local fitness function fi = fi (x, y, z)associated equivalent 3-SAT clauses. easy see assignmentvariables x, y, z, fi (s) = 1 assignment satisfies formulax z, x z, x z, x z.3. Analysis Uniform Probability Modeluniform probability model N (n, k, p), parameter p determines many zerovalues local fitness function take. interested solubility hardnessNK landscape decision problem change parameter p increases 0 1.turns fixed p > 0, decision problem asymptotically trivially insoluble.quite similar phenomena random models constraint satisfactionproblem observed Achlioptas et al. (1997).gain insight problem, consider case p = p(n)function problem size n lim p(n) = 0. analysis shows solubilitynproblem depends fast p(n) decreases:(1)1lim p(n)n 2k+1 = +,(3.1)nproblem still asymptotically trivially insoluble probability asymptotic 1, least one local fitness function always fitness value 0;(2) hand p(n) decreases fast enough, i.e.,1lim p(n)n 2k+1 < +,(3.2)nproblem decomposed set independent sub-problems. either caseproblem solved polynomial time. case (3.1) difficult prove,prove case (3.2), need make use following concepts results.Definition 3.1. connection graph NK landscape instance f (x) =nPi=1graph G = G(V, E) satisfying312fi (xi , (xi ))fiPhase Transition NK Landscapes(1) vertex v V corresponds local fitness function;(2)There edge vi , vj corresponding local fitness functionsfi , fj share variables, i.e., neighborhoods (xi ) (xj ) xi xj non-emptyintersection, least one zero value.Definition 3.2. Let f (x) =nPfi (xi , (xi )) NK landscape instance con-i=1nection graph G = G(V, E). Let G1 , , Gl connected components G. Sincevertices G correspond local fitness functions, regard Gi set local fitnessfunctions. 1 l, let Ui x = (x1 , , xn ) set variables appeardefinition local fitness functions Gi .easy see (U1 , Ul ) excluding independent vertices forms disjoint partition(a subset of) variables x = (x1 , , xn ), local fitness functions Gidepend variables Ui . Furthermore, NK decision problem soluble1 l, assignment si {0, 1}|Ui | variables Uilocal fitness function g Gi , g(s) = 1.Theorem 3.1 summarizes result uniform probability model.1Theorem 3.1. p(n) lim p(n)n 2k+1 exists, k fixed,there polynonmial time algorithm successfully solves random instance N (n, k, p) probabilityasymptotic 1 n tends infinity.11Proof: consider two cases: lim p(n)n 2k+1 = + lim p(n)n 2k+1 < +.n(1) case lim p(n)nn12k+1n= +.Let Ai event fi (y) = 0 possible assignment {0, 1}k+1 letnA=Ai event least one Ai occurs.i=1lim P r{A} = 1 lim P r{nnn\Aci }i=1= 1 lim (1 p(n)2nk+1)n .1shown k fixed lim p(n)n 2k+1 = +, lim P r{A} = 1. followsnnprobability asymptotic one, least one local fitness functiontakes values 0 possible assignments. therefore show case,NK decision problem insoluble checking local fitness functions one one.takes linear time.1(2) case lim p(n)n 2k+1 < +.nConsider algorithm first finds connected components Gi , 1 lconnection graph G NK model, uses brute force find assignmentsi {0, 1}|Ui | variables Ui local fitness function g Gi ,g(s) = 1. time complexity algorithm O(n2 + n 2M(n,k,p) ) M(n, k, p) =max(|Ui |, 1 l) maximum size subsets (Ui , 1 l) associated313fiGao & Culbersonconnected components connection graph. prove theorem, need show1M(n, k, p) O(log n). following, show lim p(n)n 2k+1 < +,nlim P r{M(n, k, p) 2k + 2} = 1nConsider connection graph G = G(V, E) NK model. random graphedge two nodes two corresponding local fitness functionsshare variables local fitness functions take least one zero fitnessvalue. However, definition edge probabilities independent. vx Eknow fx least one zero probability xw E greateredge x.deal resort following proof construction. Let Cm = {v1 , . . . , vm }subset V size m. Let ordering (permutation) v1 . . . vm . sayCm variable connected respect ordering , denoted C(Cm , ),i, 2 either1. j < f(j) f(i) share variable;2. j, 1 j variable xj one k random variables fi .Lemma induced subgraph G[Cm ] connected exists least one orderingv1 . . . vm C(Cm , ).proof, consider ordering vertices depth first search connectedsubgraph. case, connections case 1.expected number permutations C(Cm , )Ec = E[|{ : C(Cm , )}|] = m!Pr{C(Cm , )}observeexpected number connected induced graphs verticesnless pm0 Ec , p0 probability fi takes least one value zero.show value goes zero limit 2k + 2. Finally, since connectedsubgraph vertices must one < m, follows largestconnected component size 2k + 1.randomly generated permutation Cm , let Ci set first verticespermutation. 2 define Pi probability f(i) shares least onevariable f(j) j < given C(Ci1 , /1, , 1). Let P1 = 1. (A onevertex subgraph always connected.)> 1 Pi = Pr{j < i, f(i) f(j) share variables, given C(Ci1 , )one k random variables f(i) {x1 . . . xm } {xi }}.Pr{C(Cm , )} =Pi .i=2Finally, > 1 note Ci1 (i 1)k distinct variables. Ci1connected number variables may less this. Thus,nk(i1)mkn1kPi 1314.fiPhase Transition NK Landscapescombinatorial part reduces(n k(i 1) m) . . . (n k(i 1) k + 1)(n 1) . . . (n k)n ki + 1 k.n1So, Pr{C(Cm , )}1i=2n ki + 1n1k !!m1km + 2 k1 1n1m1 !1, m, k fixed.nNoting pmn 2k +1 , see expected number connected subgraphs0size boundedm1 !1n2k +1p0Ec n nngoes zero = 2k +2. follows M(n, k, p) less 2k +2 probabilityasymptotic 1. completes proof.4. Analysis Fixed Ratio Modeldiscussed previous section, uniform probability model N (n, k, p)NK landscapes asymptotically trivial. Part cause asymptotic triviality liesfact parameter p decrease quickly n, asymptoticallyleast one local fitness function takes value 0 possibleassignments, making whole decision problem insoluble. section, studyfixed ratio model N (n, k, z). model, require local fitness functionfixed number zero values trivially insoluble situation uniform probabilitymodel avoided. note idea used study flawlessCSP (Gent et al., 1998).Recall fixed ratio model, choose neighborhood structure localfitness way uniform probability model N (n, k, p). determinefitness value local fitness function fi , randomly without replacement select exactlyz tuples {s1 , , sz } {0, 1}k+1 , let fi (sj ) = 0 1 j z fi (s) = 1every {0, 1}k+1 .fixed ratio model, interested probability instanceN (n, k, z) soluble changes parameter z increases 0 2k+1 . easynPsee property exists assignment x f (x) =fi (xi , (xi )) = ni=1315fiGao & Culbersonmonotone parameter z number tuples local fitness function takeszero. Actually, following Lemma property solubility probabilityfixed ratio model:Lemma 4.1. fixed ratio model, z1 > z2 ,P r{N (n, k, z1 )is soluble} P r{N (n, k, z2 )is soluble}.Furthermore,P r{N (n, k, z)is soluble} =1, z 1;0, z = 2k+1 .Based Lemma parallel study threshold phenomenarandom combinatorial structures 3-Coloring random graphs random3-SAT, suggest following conjecture:Conjecture 4.1. exists threshold zc1, z < zc ;lim P r{N (n, k, z)is soluble} =n0, z > zc .Conjectures like starting point study phase transition manyrandom combinatorial structures 3-coloring random graphs random SAT,existence thresholds still open question (Achlioptas, 1999; Cook &Mitchell, 1997). However, bounding thresholds important topicstudy phase transition (Achlioptas, 1999, 2001; Dubois, 2001; Franco & Gelder, 1998;Franco & Paul, 1983; Frieze & Suen, 1996; Kirousis, P.Kranakis, D.Krizanc, & Y.Stamation,1994). section, establish two upper bounds threshold parameterzc , theoretically prove random instances generated parameter zupper bounds solved probability asymptotic 1 polynomial (evenlinear) algorithms.Characterizing sharpness thresholds also great interest studyphase transition. proving every monotone graph property thresholdbehavior (Friedgut & Kalai, 1996), Friedgut (1999) established necessary sufficientcondition monotone graph property sharp threshold, usedprove sharpness thresholds 3-colorability 3-SAT problems (Friedgut, 1999;Achlioptas, 1999). fixed ratio model discussed paper, suspectexhibit coarse threshold behavior, would like leave detailed investigationproblem future research direction.4.1 Upper Bound z = 3.0derivation upper bound based concept conflicting pair localfitness functions. say two local fitness functions fi fj conflict1. fi fj share least one variable x;316fiPhase Transition NK Landscapes2. assignment {0, 1}n , fi (s)fj (s) = 0.obvious instance NK decision problem insoluble exists pairconflicting local fitness functions.Based second moment method theory probability (Alon & Spencer,1992), prove following upper bound result. takes linear time checkpair conflicting local fitness functions, see fixed ratio modelN (n, 2, z) linearly solvable z > 3.0.Theorem 4.1. Define event conflicting pair local fitnessfunctions N (n, 2, z). fixed ratio model N (n, 2, z) z = 3.0 + ,lim P r{A} = 1nthus problem insoluble probability asymptotic 1.Proof: Without loss generality, may write f fi 4 zeroes fitnessvalue assignment 1 n, 3 zeroes n + 1 n. Let Iij indicatorfunction event fi fj conflicts other, i.e.,1, fi fj conflicts other;Iij =0, else.PIij . claim lim P r{S = 0} = 0.=1i,jnnChebyschevs inequality,P r{S = 0} P r{|S E(S)| E(S)}V ar(S).(E(S)2 )(4.3)Since 1 n, fi exactly 4 zeros fitness value assignment, knowtwo local fitness function fi , fj , 1 i, j n, conflictexactly one common variable x one following true: (1)fi (s) =0(or 1), fj (s) = 1(or 0) assignments x = 1(respectively x = 0);(2)fi (s) = 1(or 0), fj (s) = 0(or 1) assignments x = 1(respectively x =0);Since probability two local fitness functions share least one variable equaln2 n4122n1 n1 ,22P r{Iij = 1} =11= ( ),n!n2 n422n1 n122218!24> 0, 1 i, j n,317(4.4)fiGao & Culbersonhence,XE(S) =XE(Iij ) =1i,jnP r{Iij = 1} (n).1i,jnPconsider variance S. Since =Iij ,1i,jnPV ar(S) =PV ar(Iij ) + 2i,j[E{Iij Ilm } E{Iij }E{Ilm }](i,j)6=(l,m).(E(S))2LetPA1 =P2A2 =V ar(Iij )i,j(E(S))2[E{Iij Ilm } E{Iij }E{Ilm }](i,j)6=(l,m)(E(S))2.easy see lim A1 = 0. prove lim A2 = 0, consider two cases:nnCase 1: 6= j 6= 6= l. case, two random variables Iij Ilm actuallyindependent. follows E{Iij Ilm } E{Iij }E{Ilm } = 0.Case 2: (i, j) 6= (l, m), one common, say j = l. case,2 !1E{Iij Ilm } E{Iij }E{Ilm } = P r{Iij = 1}P r{Ijm = 1|Iij = 1}n2 !11=P r{Ijm = 1|Iij = 1}nnGiven fi fj conflict other, conditional probability fj fmconflict still ( n1 ).3 pairsSincePthere Cnijjm satisfying condition Case 2, know[E{Iij Ilm } E{Iij }E{Ilm }] (n). therefore, lim A2 = 0. followsn(i,j)6=(l,m)V ar(S)= 0.n (E(S)2 )lim P r{S = 0} limnSince event {S > 0} implies exists conflicting pair local fitness functions,theorem follows.4.2 2-SAT Sub-problems N (n, 2, z) Tighter Upper Boundsubsection, establish tighter upper bound z > 2.837 threshold fixedratio model N (n, 2, z) showing asymptotically N (n, 2, z) contains unsatisfiable2-SAT sub-problem probability 1 value z greater 2.873. alsogives us polynomial time algorithm determines N (n, 2, z) insolubleprobability asymptotic 1 z > 2.837.318fiPhase Transition NK LandscapesRecall Section 2 instance N (n, 2, z) equivalent 3-SAT instance.idea show probability asymptotic 1, instance N (n, 2, z)contain set specially structured 3-clauses, called t-3-module (Definition 10.3, Franco& Gelder, 1998):= {M1 , . . . , M3p+2 }, = 3p + 2,M1 = (u1 u2 z1 , u1 u2 z1 );Mp1 = (up1 zp1 , up1 zp1 );Mp = (up u0 zp , u0 zp );Mp+1 = (up+1 up+2 zp+1 , up+1 up+2 zp+1 );M3p1 = (u3p1 u3p z3p1 , u3p1 u3p z3p1 );M3p = (u3p u0 z3p , u3p u0 z3p )M3p+1 = (u0 u1 z3p+1 , u0 u1 z3p+1 );M3p+2 = (u0 up+1 z3p+2 , u0 up+1 z3p+2 );u1 , , u3p+1 , z1 , , z3p+1 binary variables. Notice t-3-module reduced 2-SAT problem containing two contradictory cycles hence unsatisfiable.result proved two steps. first step, shown z > 2.837average number t-3-modules contained N (n, 2, z) tends infinity n increases.second step, use result established Alon Spencer (1992) secondmoment method prove z > 2.837 probability N (n, 2, z) contains leastone t-3-module tends 1.Let us start first step show average number t-3-modules containedN (n, 2, z) tends infinity n increases.Definition 4.1. Given t-3-module NK landscape instance f =nPfi , k = 2,i=1sequence local fitness functionsg = (g1 , , gt ) (f1 , , fn )said possible match(PM) 1 t, main variable gm onethree variables occur 3-module Mm . subsequence (h1 , , hl ) possiblematch g legal 1 < j l, hm 6= hj .Lemma 4.2. Let f (x) =nPfi (xi , (xi )) instance N (n, 2, z) t-3-i=1module. number possible matchest-3-module 3 . Further,number legal possible matches ( 3+2 5 )t .319fiGao & CulbersonProof: 1 t, exactly 3 possible choices gm :fi1 (xi1 , (xi1 )), fi2 (xi2 , (xi2 )), fi3 (xi3 , (xi3 )),xi1 , xi2 , xi3 correspond three variables occur 3-module Mm .Therefore, 3t possible matches t-3-module.prove second conclusion, divide t-3-module 3 parts = (M1 , M2 , M3 ),M1 = (Mm , 1 p), M2 = (Mm , p + 1 3p 1), M3 =(M3p , M3p+1 , M3p+2 ). Letting L1 , L2 , L3 number legal possible matchesM1 , M2 , M3 respectively. Since literals M1 variable-distinct literalsM2 , number legal possible matches, L, t-3-module satisfiesL1 L2 L 27L1 L2 .estimate order L1 . end, consider probability space (, P ),set sequences (g1 , , gp ) local fitness functions possibly match M1P uniform probability distribution. Then, number legal possible matchesL1 = || P r{a random sample legal}(4.5)Let g = (g1 , , gp ) random sample xgm denote main variablelocal fitness function gm ,1P r{xgm = |um |} = P r{xgm = |um+1 |} = P r{xgm = |zm |} = ,3|u| denotes variable corresponding literal u.Let Bm , 0 < p event first local fitness functions g1 , , gmpossible match g = (g1 , , gp ) mutually distinct. Since M1 consecutive3-modules share variables,Bm = {(g1 , , gm ) : gi 6= gi+1 , 1 1}.Let bm = P r{gm 6= gm1 | Bm1 }, 2, b1 = 1. Notice B1 = . Then,P r{g = (g1 , , gp )is legal} = P r{Bp }= P r{g1 6= g2 , g2 6= g3 , , gp1 6= gp }= P r{B1 }P r{g2 6= g1 | B1 } P r{g3 6= g2 | B2 } P r{gp 6= gp1 | Bp1 }(4.6)= b1 b2 bpRecalling xgm denotes main variable local fitness function gm ,bp = P r{gp1 6= gp , xgp1 = |up | | Bp1 } + P r{gp1 6= gp , xgp1 6= |up | | Bp1 }= P r{gp1 6= gp | Bp1 , xgp1 = |up |} P r{xgp1 = |up | | Bp1 } +P r{gp1 6= gp | Bp1 , xgp1 6= |up |} P r{xgp1 6= |up | | Bp1 }2ap + (1 ap )=31= 1 ap ,3320(4.7)fiPhase Transition NK Landscapesap = P r{xgp1 = |up | | Bp1 }. ap ,P r{Bp1 , xgp1 = |up |}P r{Bp1 }1=(P r{Bp1 , xgp1 = |up |, xgp2 = |up1 |}P r{Bp1 }ap =+ P r{Bp1 , xgp1 = |up |, xgp2 6= |up1 |})(4.8)1=(P r{xgp1 = |up | | Bp1 , xgp2 = |up1 |} P r{Bp1 , xgp2 = |up1 |}P r{Bp1 }+ P r{xgp1 = |up | | Bp1 , xgp2 6= |up1 |} P r{Bp1 , xgp2 6= |up1 |})111=P r{Bp1 , xgp2 = |up1 |} + P r{Bp1 , xgp2 6= |up1 |}P r{Bp1 } 23last equation formula given Bp1 xgp2 = |up1 |(or xgp2 6= |up1 |), two (three, respectively) choices selecting local fitnessfunction gp1 . Consider two terms P r{Bp1 , xgp2 = |up1 |} P r{Bp1 , xgp2 6=|up1 |} (4.8),P r{Bp1 , xgp2 = |up1 |}= P r{gp2 6= gp1 | Bp2 , xgp2 = |up1 |} P r{Bp2 , xgp2 = |up1 |}2= Pr{xgp2 = |up1 | | Bp2 } P r{Bp2 }32= ap1 P r{Bp2 }3(4.9)P r{Bp1 , xgp2 6= |up1 |}= P r{gp2 6= gp1 | Bp2 , xgp2 6= |up1 |} P r{Bp2 , xgp2 6= |up1 |}= P r{xgp2 6= |up1 | | Bp2 } P r{Bp2 }(4.10)= (1 ap1 ) P r{Bp2 }plugging (4.9) (4.10) (4.8), getP r{Bp2 } 111ap =ap1 + (1 ap1 ) =.P r{Bp1 } 333bp1This, together (4.7), gives usbp = 11.9bp1(4.11)difficult show sequence {bp } decreasing lower bounded 0.Letting lim bp = b taking limit sides, getpb=13211,9b(4.12)fiGao & Culbersonthus, b =thus,3 56 .case, b =3+ 56b 1 bpsince b1 = 1. follows bp b =prove expected number legal possible matches L1 M13+ 56!p3+ 5.6(4.5), know number legal possible matches greater!p!p3+53+53p=.62let p = bp3+ 56(4.13)p3+ 5,2= bp b. (4.11) (4.12),p = bp b =means seriespPbp1 bdp1 , 0 < < 1,9bbp1convergent. followsm=1(1 +p1) (1 +)bbconverges finite positive constant c. Therefore,b1 bp = (b + 1 ) (b + p )p1= bp 1 +1 +bb!p3+ 5c6(4.14)sufficient large p constant c.show number legal possible matches L2 M2Similarly,2p+23+ 5. Recalling number legal possible matches L t-3-module2satisfies L1 L2 L 27L1 L2 , second conclusion follows.following Lemma calculates probability matching local fitness functionimplies matched 3-module.Lemma 4.3. Given 3-module x w, x w, local fitness function gmain variable xg g one three Boolean variables |x|, |y|, |w|, let z =2 + , 0 1 parameter fixed ratio model N (n, 2, z). probabilityg contains 3-module!116p0 =(1 ) +(4.15)n128562322fiPhase Transition NK LandscapesProof: Since xg already one variables 3-module, probability1two variables also 3-module n1.( 2 )Now, assume variables local fitness function gvariables 3-module. definition fixed ratio model, g two zerosfitness value assignment probability (1 ), three zeros fitnessassignment probability . Note local fitness function g implies 3-modulex w, x wg(x, y, w) = 0g(x, y, w) = 0.definition fixed ratio model, happens probability168 (1 ) + 823Lemma follows.preparation, prove average number t-3-modulescontained N (n, 2, z) tends infinity.Theorem 4.2. Let number t-3-modules contained N (n, 2, z) =(ln2 n). Then, z = 2 + > 2.837,lim E{At } = .n(4.16)Proof: Lemma 4.2, ( 3+2 5 )t legal possible matches fixedt-3-module. Lemma 4.3, know possible legal match g = {g1 , , gt }implies t-3-module probability pt0 . proof Theorem 10.1 (Franco &Gelder, 1998),2t2 nt1 (n + 1)t(4.17)n!16possible t-3-modules, nt1 = (nt+1)!. Let r = 28(1 ) + 56, write p0 =1r.(n12 )E{At } =====!t3+ 5p0 2t2 nt1 (n + 1)t2!t13+ 5r 2t2 nt1 (n + 1)tn122!t!tn2 n (n + 1)t13+ 52rn1n24(n + 1)22!t3+ 54 n (n + 1)tn1r4(n + 1)2(n(n 1))tn221(2(3 + 5)r)t (1),4nn323(4.18)fiGao & Culbersonfourth equation (4.18) due fact positive integer n q2q < n2 , nq eq /2n nq nq . follows lim E{At } =n2(3 +5)r > 1.(4.19)Solving inequality (4.19) gives us > 0.837, is, z = 2 + > 2.837. provesTheorem 4.2.Based Chebychevs inequality, prove N (n, 2, z) contains t-3-modulesprobability 1, need show variance , number contained t-3-modules,o(E{At }). purpose, follow Franco Gelders approach (Lemma 4.1, Franco& Gelder, 1998) apply second moment method (Alon & Spencer, 1992):Lemma 4.4. (Alon & Spencer, 1992, Ch. 4.3 Cor 3.5) Given random structure(e.g.,random CNF formula), let W set substructures consideration, A(w)set substructures sharing clauses w W . Let Iw = 1 w randomstructure 0 otherwise.(1) elementsPW symmetric;(2) = E{Iw } ;wWP(3)P r(w | w) = o(), w W ,wA(w)n , probability random structure contains substructure tends1.use Lemma study 2-SAT sub-problem NK landscapes, viewrandom structure random instance N (n, 2, z), W sett-3-modules symmetric definitions(Sections 5 10, Franco & Gelder,1998).Theorem 4.3. z = 2 + > 2.837, N (n, 2, z) asymptotically insolubleprobability 1.Proof:Let number t-3-modules implied N (n, 2, z) = O(ln2 n).Theorem 4.2 shows lim E{At } = . Lemma 4.4, enough shownw W ,XP r(w | w) = o(E{At }),(4.20)wA(w)P r(w | w) conditional probability N (n, 2, z) implies t-3-module wgiven implies w, A(w) set t-3-modules sharing clauses w.Suppose w shares Q, 1 Q 2t clauses w, Q clausesdistributed among q 3-modules. Further, let q1 number 3-modules whose twoclauses shared q2 = q q1 number 3-modules one clauseshared.Let T1 3-module w shares exactly one clause 3-module T2 w.claim conditional probability T1 implied N (n, 2, z) given wimplied N (n, 2, z),11+ O( ).(4.21)6n324fiPhase Transition NK LandscapesWithout loss generality, assume T2 = {xyu, xy u} T1 = {xyu, xy u}.Since w implied N (n, 2, z), local fitness function g = g(|x|, |y|, |u|) impliesT2 . conditional probability T1 implied, less equal P1 + P2P1 conditional probability g also implies clause x u given g impliesT2 , P2 conditional probability clause x u implied localfitness functions. definition N (n, 2, z), P1 = 61 . Since local fitnessfunction implies x u variables g = g(|x|, |y|, |u|),P2 = O( n1 ). claim proved. follows that, sufficiently large n,!tqq 23+ 51q1P r{w | w} cp01(4.22)26p0 defined Lemma 4.3 c fixed constant.Let AQ,q,q2 (w) set t-3-modules share Q clauses w Qclauses distributed q different 3-modules. before, q1 number 3-moduleswhose two clauses shared q2 = q q1 number 3-modulesone clause shared. claim|AQ,q,q2 (w)| = |A2q,q,0 (w)|6q2 .(4.23)A2q,q,0 (w) set t-3-modules share 2q clauses q 3-modulesw. Let = {M1 , , Mt } t-3-module clauses Mi , 1 qshared w. Let = {M1 , , Mt } t-3-module clausesMi , 1 q1 shared 3-modules Mi , q1 + 1 q1 + q2 oneclause shared. Since q2 3-modules, 6 ways choose non-sharedclauses, 6q2 t-3-modules AQ,q,q2 (w) correspond one t-3-moduleA2q,q,0 . claims follow. formula (55) (56) (Franco & Gelder, 1998)(4.23), follows(O(t) tq 2(tq) q22 n6, q p + 1,n2|AQ,q,q2 (w)| < O(1)(4.24)tq2(tq)q2n6, q > p + 1.n 2611Let r = 28(1 ) + 56, write p0 = n1r. Then,( 2 )|AQ,q,q2 (w)|P r{w | w}O(t) tq 2(tq) q2 3 + 5 tq 1 q22 2 n6 (p0 ) ( )n26!tqO(t)13+ 52 2tq n2(tq)rn1 tqn2(4.25)2O(t) 1(2(3 + 5)r))tqn 4nO(t)E{At }(2(3 + 5)r))q , q p + 3n|AQ,q,q2 (w)|P r{w | w} O(1)E{At }(2(3 +3255)r))q , q > p + 3.(4.26)fiGao & CulbersonTherefore,XXP r(w | w) =|AQ,q,q2 (w)|P r{w | w}Q,q,q2wA(w)=XXX XX X O(t)qE{At }(2(3 + 5)r)) +O(1)E{At }(2(3 + 5)r))q .nqqQ=1 qp+3Q=1 q>p+322(4.27)Since 2(3 +5)r) > 1 z > 2.837,XwA(w)P r(w | w)O(t4 )E{At } + t3 E{At }(4r)(p+3)n(4.28)= o(E{At }).completes proof Theorem 4.3.5. Experimentsstudy threshold phenomena NK landscapes started experimentalinvestigation. Many theoretical results previous section motivatedobservations made experiments. section, describe approachmethods used experimental study, report results observationsmade.experiments, instance NK landscape decision problem convertedequivalent 3-SAT problem, 3-SAT problem solved using Robertos relsatanenhanced version famous Davis-Putnam algorithm SAT problems implementedC ++ . source code relsat found http://www.cs.ubc.ca/ hoos/SATLIB/.experiments, generated random instances NK landscape decision problem random model N (n, 2, z). result, equivalent SAT problemrandom NK landscape instance 3-SAT problem n variables (on average) znclauses. definition, parameter z 0 8. z 1, 3-SAT instancesolved easily setting literals correspond main variableslocal fitness function true. z increases, get clauses 3-SATproblem becomes constrained. aims experiments threefold:(1)Investigating exists threshold phenomenon random NK landscapemodel; (2) Locating threshold parameter z; (3)Determininghard instances around threshold.5.1 Experiments Fixed Ratio Modelpart experiments, generate 100 random instances N (n, 2, z)parameters n = 29 216 z = 2.71, 2.72, , 3.00. instancesconverted 3-SAT instances solved relsat. Figure 1 shows fraction insolubleinstances function parameter z. seen exists thresholdphenomenon threshold around 2.83. shows upper bound z = 2.837tight.326fiPhase Transition NK Landscapes10.90.80.7n=512n=1024n=2048n=4096n=8192n=16384n=32768n=65536z=2.840.60.50.40.30.20.102.72.752.82.852.92.953Figure 1: Fractions insoluble instances(Y-axis) function z (X-axis).Figure 2, plot square root average search cost functionparameter n. figure indicates average search O(n2 ) parameterz. also observed 99 percent insoluble instances solvedquickly preprocessing stage relsat. indicates must smallstructures make instances insoluble. detailed experimental resultsfound Gaos thesis (Gao, 2001).5.2 Experiments 2-SAT sub-Problempart experiments motivated theoretical analyses Section 4.2.idea explained follows. Letf (x) =nXfi (xi , (xi ))i=1instance decision problem NK landscape^^= C1 C2 Cnequivalent 3-SAT problem Ci set 3-clauses equivalent local fitnessfunction fi . i, set 2-clauses Di (possibly empty) implied Ci .example, Ci three 3-clauses ((x, y, z), (x, y, z), (x, y, z)), set 2-clauses Diwould ((x, z), (x, y)). conjunction Di , denoted , 2-SAT problem.obvious original 3-SAT problem satisfiable 2-SAT sub-problemsatisfiable. experiment, generate instances NK landscape N (n, 2, z), convert327fiGao & Culberson35z=2.71z=2.80z=2.84z=2.86z=2.90302520151050012345674x 10Figure 2: Square root average search cost (Y-axis, seconds) function n(X-axis).10.90.80.7n=512n=1024n=2048n=4096n=8192n=16384n=32768n=65536z=2.840.60.50.40.30.20.102.72.752.82.852.92.953Figure 3: Fractions insoluble instances(Y-axis) function z (X-axis) 2-SATsub-problems.equivalent 3-SAT problems, extract 2-SAT sub-problems. 2-SAT328fiPhase Transition NK Landscapes40z=2.71z=2.80z=2.84z=2.86z=2.9035302520151050012345674x 10Figure 4: Square root average search cost (Y-axis, seconds) function n(X-axis) 2-SAT sub-problems.problems solved relsat solver. 2-SAT problem unsatisfiable,original NK landscape instance also insoluble.experimental settings experiment originalproblem. results shown Figures 3-4, parallel Figures 1-2 resultsoriginal 3-SAT problems Section 5.1. see patterns insoluble fractionssearch cost similar found original 3-SAT problems.soluble-insoluble phase transition occurring around 2.83, fraction unsatisfiableinstances lower fraction original 3-SAT problems.also observed average search cost 2-SAT sub-problems remainsoriginal 3-SAT problems. tells us difficulty solvingsoluble instance NK landscape almost solving 2-SAT problem,hence easy. Therefore, average NK landscape N (n, 2, z) also easy parametersthreshold almost instances soluble.6. Implications ConclusionsOne questions arises work implications design analysis genetic algorithms. NK landscapes initially conceived simplified modelsevolutionary landscapes could tuned respect ruggedness epistaticinteractions (Kauffman, 1989). study genetic algorithms, NK landscape modelsused prototype benchmark analysis performance different genetic operators effects different encoding methods algorithms329fiGao & Culbersonperformance (Altenberg, 1997; Hordijk, 1997; Jones, 1995). Kauffman (1993) pointsparameters primarily affect number ruggedness measures n k.Nevertheless, fact k 2 discrete NK landscape NP-complete (Wrightet al., 2000) neighbors arbitrarily chosen could construed implyingrandom landscapes fixed k practice hard.results paper serve cautionary note maycase. analyses show fixed k uniform probability model trivially solvableproblem size tends infinity. fixed ratio model, derived two upperbounds threshold solubility phase transition, proved problemcontrol parameter upper bounds solved polynomial timeprobability asymptotic 1 due existence easy sub-problems 2-SAT.series experiments also conducted investigate hardness problemcontrol parameters around threshold. experiments,observed problem also easy around threshold.proofs hold decision version problem component functions discrete {0, 1}. proofs obtained noticing clusteringfunctions, clauses, selected subsets variables implies overall problemdecomposable independent subproblems, problem contains small substructures identify solution. subproblems components connectiongraph defined Section 3 2-SAT sub-problems studied Section 4.2. currently unclear us extent analysis extended optimization versionNK model, would like study problem future.response question implications GAs? suggest followingspeculative line enquiry. discrete model use, soluble instances readilysolved standard algorithmic approach based recognizing componentsconnection graph. (This surprise us pointedHeckendorn, Rana, Whitley (1999) Even relatively old algorithms DavisPutnam deterministic exact orders magnitude faster GAs.) 1similar connectivity developed real valued distributions, example cappingminimum value allow sub-function take. speculateclustering imposed fixed values k would also generate localized structures realvalues applied considering optimization instead decision, perhapsfuzzy boundaries. fact, observation flip side limited epistasis. Geneticalgorithms, variants probabilistic model-building algorithms (Larranaga& Lozano, 2001), designed mimic natural evolution, supposed take advantagesituation. So, extent NK landscapes accurate reflectionfeatures exploited evolutionary algorithms, pose following question. possibleidentify fuzzy components exist, design algorithmexploits landscape features evolutionary algorithms do, farefficiently, done uniform discrete decision problem?landscapes designed intent studying limited interactions,results also seen confirmation indeed limited epistasis leads easier problems. another domain, traditional research search optimization,1. thanks anonymous referee pointing us work Heckendorn, et al. (Heckendornet al., 1999)330fiPhase Transition NK Landscapesneed test bed problems real world connections tunablerespect difficulty. NK landscapes might domain generating 3-SATinstances. disappointing restricted k instances generated easyhigh probability.Acknowledgmentsresearch supported part Natural Sciences Engineering Research CouncilGrant No. OGP8053. thank anonymous reviewers comments.ReferencesAchlioptas, D. (1999). Threshold Phenomena Random Graph Colouring Satisfiability. Ph.D. thesis, Department Computer Science, University Toronto, Toronton,Canada.Achlioptas, D. (2001). survey lower bounds random 3-sat via differential equations.Theoretical Computer Science, 265, 159185.Achlioptas, D., Kirousis, L., Kranakis, E., Krizanc, D., & Molloy, M. (1997). Randomconstraint satisfaction: accurate picture. Proceedings CP97, pp. 107120. Springer.Alon, N., & Spencer, J. (1992). Probabilistic Method. Wiley, New York.Altenberg, L. (1997). Nk fitness landscapes. Back, T., Fogel, D., & Michalewicz, Z.(Eds.), Handbook Evolutionary Computation. Oxford University Press, New York.Cheeseman, P., Kanefsky, B., & Taylor, W. (1991). really hard problems are.Proceedings 12th International Joint Conference Artificial Intelligence, pp.331337. Morgan Kaufmann.Cook, S., & Mitchell, D. (1997). Finding hard instances satisfiability problem:survey. Du, Gu, & Pardalos (Eds.), Satisfiability Problem: Theory Applications,Vol. 35 DIMACS Series Discrete Mathematics Theoretical Computer Science.American Mathematical Society.Culberson, J., & Gent, I. (2001). Frozen development graph coloring. Theoretical Computer Science, 265 (1-2), 227264.Dubois, O. (2001). Upper bounds satisfiability threshold. Theoretical ComputerScience, 265 (1-2), 187197.Franco, J., & Gelder, A. (1998). perspective certain polynomial time solvable classessatisfiability. Discrete Applied Mathematics, appear.Franco, J., & Paul, M. (1983). Probabilistic analysis davis-putnam proceduresolving satisfiability. Discrete Applied Mathematics, 5, 7787.Freeman, J. (1996). Hard random 3-sat problems davis-putman procedure. ArtificialIntelligence, 81, 183198.331fiGao & CulbersonFriedgut, E. (1999). Sharp thresholds graph properties k-sat problem. J. Amer.Math. Soc., 10171054.Friedgut, E., & Kalai, G. (1996). Every monotone graph property sharp threshold.Proc. Amer. Math. Soc., 29933002.Frieze, A., & Suen, S. (1996). Analysis two simple heuristics random instancek-sat. J. Algorithm, 20 (2), 312355.Gao, Y. (2001). Threshold phenomena NK landscapes. Masters thesis, DepartmentComputing Science, University Alberta, Edmonton, Alberta, Canada.Gent, I., MacIntyre, I., Prosser, P.and Smith, B., & Walsh, T. (1998). Random constraintsatisfaction: Flaws structure. Tech. rep. APES-08-1998, APES Research Group.Heckendorn, R., Rana, S., & Whitley, D. (1999). Polynomial time summary statisticsgeneralization maxsat. GECCO99: Proceedings Genetic EvolutinaryComputation Conference, pp. 281288. Morgan Kaufmann.Hordijk, W. (1997). measure landscapes. Evolutionary Computation, 4 (4), 335360.Jones, T. (1995). Evolutionary Algorithms, Fitness Landscapes Search. Ph.D. thesis,University New Mexico, Albuquerque, NM.Kauffman, S. (1989). Adaptation rugged fitness landscapes. Stein, D. (Ed.), LecturesSciences Complexity, Santa Fe Institute Studies Sciences Complexity,pp. 527618. Addison Wesley.Kauffman, S. (1993). Origins Order: Self-organization Selection Evolution.Oxford University Press, Inc.Kirkpatrick, S., & Selman, B. (1994). Critical behavior satisfiability randomboolean expressions. Science, 264, 12971301.Kirousis, L., P.Kranakis, D.Krizanc, & Y.Stamation (1994). Approximating unsatisfiability threshold random formulas. Random Structures Algorithms, 12 (3),253269.Larranaga, P., & Lozano, J. (2001). Estimation Distribution Algorithms: New ToolEvolutinary Computation. Kluwer Academic Publishers, New York.Mitchell, D., Selman, B., & Levesque, H. (1992). Hard easy distributions sat problems.Proceedings 10th Natl. Conf Artificial Intelligence, pp. 459465. AAAIPress.Vandegriend, B., & Culberson, J. (1998). Gn,m phase transition hardHamiltonian Cycle problem. Journal Artificial Intelligence Research, 9, 219245.Weinberger, E. D. (1996). Np completeness kauffmans NK model, tunable ruggedfitness landscape. Tech. rep. 96-02-003, Santa Fe Institute, Santa Fe.Wright, A. H., Thompson, R. K., & Zhang, J. (2000). computational complexity NKfitness functions. IEEE Transactions Evolutionary Computation, 4 (4), 373379.332fiJournal Artificial Intelligence Research 17 (2002) 229-264Submitted 12/01; published 9/02Knowledge Compilation MapAdnan Darwichedarwiche@cs.ucla.eduComputer Science DepartmentUniversity California, Los AngelesLos Angeles, CA 90095, USAPierre Marquismarquis@cril.univ-artois.frUniversite dArtoisF-62307, Lens Cedex, FranceAbstractpropose perspective knowledge compilation calls analyzing different compilation approaches according two key dimensions: succinctness target compilationlanguage, class queries transformations language supports polytime.provide knowledge compilation map, analyzes large number existing target compilation languages according succinctness polytime transformationsqueries. argue analysis necessary placing new compilation approaches withincontext existing ones. also go beyond classical, flat target compilation languages basedCNF DNF, consider richer, nested class based directed acyclic graphs (suchOBDDs), show include relatively large number target compilation languages.1. IntroductionKnowledge compilation emerged recently key direction research dealingcomputational intractability general propositional reasoning (Darwiche, 1999; Cadoli & Donini,1997; Boufkhad, Gregoire, Marquis, Mazure, & Sas, 1997; Khardon & Roth, 1997; Selman &Kautz, 1996; Schrag, 1996; Marquis, 1995; del Val, 1994; Dechter & Rish, 1994; Reiter & deKleer, 1987). According direction, propositional theory compiled off-line targetlanguage, used on-line answer large number queries polytime. keymotivation behind knowledge compilation push much computational overheadoff-line phase, amortized on-line queries. knowledge compilation serveimportant purposes well. example, target compilation languages associatedalgorithms simple, allowing one develop on-line reasoning systems simple softwarehardware platforms. Moreover, simplicity algorithms operate compiled languageshelp streamlining effort algorithmic design single task: generating smallestcompiled representations possible, turns main computational bottleneckcompilation approaches.three key aspects knowledge compilation approach: succinctnesstarget language propositional theory compiled; class queriesanswered polytime based compiled representation; class transformationsapplied representation polytime. AI literature thus far focused mostlytarget compilation languages variations DNF CNF formulas, Horn theoriesprime implicates. Moreover, focused mostly clausal entailment queries, littlediscussion tractable transformations compiled theories.goal paper provide broad perspective knowledge compilation consideringrelatively large number target compilation languages analyzing accordingsuccinctness class queries/transformations admit polytime.c2002AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiDarwiche & MarquisInstead focusing classical, flat target compilation languages based CNF DNF,consider richer, nested class based representing propositional sentences using directed acyclicgraphs, refer NNF. identify number target compilation languagespresented AI, formal verification, computer science literature showspecial cases NNF. class, list extra conditions need imposedNNF obtain specific class, identify set queries transformationsclass supports polytime. also provide cross-rankings different subsets NNF, accordingsuccinctness polytime operations support.main contribution paper map deciding target compilation languagesuitable particular application. Specifically, propose one starts identifying set queries transformations needed given application, choosingsuccinct language supports operations polytime.paper structured follows. start formally defining NNF language Section 2,list number conditions NNF give rise variety target compilation languages.study succinctness languages Section 3 provide cross-rankingcompares according measure. consider number queries applicationsSection 4 compare different target compilation languages according tractabilityrespect queries. Section 5 dedicated class transformations, applications,tractability respect different target compilation languages. finally closeSection 6 concluding remarks. Proofs theorems delegated Appendix A.2. NNF Languageconsider dozen languages paper, subsets NNF language,defined formally follows (Darwiche, 1999, 2001a).Definition 2.1 Let PS denumerable set propositional variables. sentence NNFProoted, directed acyclic graph (DAG) leaf node labeled true, false, X X,X P S; internal node labeled arbitrarily many children.size sentence NNFP , denoted | |, number DAG edges. heightmaximum number edges root leaf DAG.Figure 1 depicts sentence NNF, represents odd parity function (we omit referencevariables PS confusion anticipated). propositional sentence representedsentence NNF, NNF language complete.important distinguish representation language target compilationlanguage. representation language one expect humans read writeease. language CNF popular representation language, language Hornclauses (especially expressed rules form). hand, target compilation languageneed suitable human specification interpretation, tractable enoughpermit non-trivial number polytime queries and/or transformations. considernumber target compilation languages qualify representation languagesperspective, suitable humans construct interpret. also considernumber representation languages qualify target compilation languages.1formal characterization representation languages outside scope paper.language qualify target compilation language, require permits polytimeclausal entailment test. Note polytime consistency test sufficient here, oneconsistency test given theory justify compilation. Given definition, NNF1. appears proposing target compilation languages AI literature, usually implicitrequirement proposed language also representation language. shall see later, however,powerful target compilation languages suitable humans specify interpret directly.230fiA Knowledge Compilation MapDecomposability(a)(b)A,BSmoothness(c)DeterminismC,DA,BA,BBBCCBBCCBBCCFigure 1: sentence NNF. size 30 height 4.qualify target compilation language unless P=NP (Papadimitriou, 1994), manysubsets do. define number subsets below, obtained imposingconditions NNF.distinguish two key subsets NNF: flat nested subsets. first considerflat subsets, result imposing combinations following properties:Flatness: height sentence 2. sentence Figure 3 flat,one Figure 1 not.Simple-disjunction: children or-node leaves share variables (thenode clause).Simple-conjunction: children and-node leaves share variables (thenode term). sentence Figure 3 satisfies property.Definition 2.2 language f-NNF subset NNF satisfying flatness. language CNFsubset f-NNF satisfying simpledisjunction. language DNF subset f-NNF satisfyingsimpleconjunction.CNF permit polytime clausal entailment test (unless P=NP) and, hence, qualifytarget compilation language. dual DNF does.following subset CNF, prime implicates, quite influential computer science:Definition 2.3 language PI subset CNF clause entailed sentencesubsumed clause appears sentence; clause sentence subsumedanother.dual PI, prime implicants IP, also defined.Definition 2.4 language IP subset DNF term entailing sentencesubsumes term appears sentence; term sentence subsumedanother term.work representing set prime implicates propositional theorycompact way, allowing exponential number prime implicates represented polynomialspace certain casessee example TRIE representation (de Kleer, 1992), ZBDDrepresentation used (Simon & del Val, 2001), implicit representation based metaproducts, proposed (Madre & Coudert, 1992). representations differentlanguage PI sense necessarily support queries transformations231fiDarwiche & Marquisreport Tables 5 7. also exhibit different succinctness relationshipsones report Table 3.Horn theories (and renamable Horn theories) represent another target compilation subset CNF,consider since restrict attention complete languages L only, i.e.,require every propositional sentence logically equivalent element L.consider nested subsets NNF language, impose restrictionheight sentence. Instead, subsets result imposing one followingconditions: decomposability, determinism, smoothness, decision, ordering. start definingfirst three properties. on, C node NNF, Vars(C) denotes setvariables label descendants node C. Moreover, NNF sentence rooted C,Vars() defined Vars(C).Decomposability (Darwiche, 1999, 2001a). NNF satisfies property conjunction C NNF, conjuncts C share variables. is, C1 , . . . , Cnchildren and-node C, Vars(Ci ) Vars(Cj ) = 6= j. Consider and-nodemarked Figure 1(a). node two children, first contains variables A, Bsecond contains variables C, D. and-node decomposable since two childrenshare variables. and-node Figure 1(a) also decomposable and, hence,NNF figure decomposable.Determinism (Darwiche, 2001b): NNF satisfies property disjunction CNNF, two disjuncts C logically contradictory. is, C1 , . . . , Cnchildren or-node C, Ci Cj |= false 6= j. Consider or-node markedFigure 1(b), two children corresponding sub-sentences B B A.conjunction two sub-sentences logically contradictory. or-nodedeterministic or-nodes Figure 1(b). Hence, NNF figuredeterministic.Smoothness (Darwiche, 2001b): NNF satisfies property disjunction CNNF, disjunct C mentions variables. is, C1 , . . . , Cn childrenor-node C, Vars(Ci ) = Vars(Cj ) 6= j. Consider marked or-node Figure 1(c).node two children, mentions variables A, B. or-nodesmooth or-nodes Figure 1(c). Hence, NNF figure smooth.hard ensure decomposability. also hard ensure determinism preserving decomposability. Yet sentence NNF smoothed polytime, preserving decomposabilitydeterminism. Preserving flatness, however, may blow-up size given NNF. Hence, smoothness important complexity viewpoint unless flatness.properties decomposability, determinism smoothness lead number interestingsubsets NNF.Definition 2.5 language DNNF subset NNF satisfying decomposability; d-NNF subset satisfying determinism; s-NNF subset satisfying smoothness; d-DNNF subset satisfyingdecomposability determinism; sd-DNNF subset satisfying decomposability, determinismsmoothness.Note DNF strict subset DNNF (Darwiche, 1999, 2001a). following decision propertycomes literature binary decision diagrams (Bryant, 1986).Definition 2.6 (Decision) decision node N NNF sentence one labeled true,false, or-node form (X ) (X ), X variable,decision nodes. latter case, dVar (N ) denotes variable X.Definition 2.7 language BDD set NNF sentences, root sentencedecision node.232fiA Knowledge Compilation MapX1X1 X1X2X2X3X3trueX2X2X2X2X3X310X3X3falseFigure 2: left, sentence BDD language. right, corresponding binary decisiondiagram.NNF sentence Figure 2 belongs BDD subset.BDD language corresponds binary decision diagrams (BDDs), known formalverification literature (Bryant, 1986). Binary decision diagrams depicted using compactnotation though: labels true false denoted 1 0, respectively; decisionX. BDD sentence left Figure 2 correspondsnode X X denotedbinary decision diagram right Figure 2. Obviously enough, every NNF sentence satisfiesdecision property also deterministic. Therefore, BDD subset d-NNF.show later, BDD qualify target compilation language (unless P=NP),following subset does.Definition 2.8 FBDD intersection DNNF BDD.is, sentence FBDD decomposable satisfies decision property. FBDD languagecorresponds free binary decision diagrams (FBDDs), known formal verification (Gergov &Meinel, 1994a). FBDD usually defined BDD satisfies read-once property:path root leaf, variable appear once. FBDDs also knownread-once branching programs theory literature. Imposing read-once property BDDequivalent imposing decomposability property corresponding BDD sentence.influential subset BDD language obtained imposing ordering property:Definition 2.9 (Ordering) Let < total ordering variables PS. language OBDD<subset FBDD satisfying following property: N or-nodes, Nancestor node , dVar (N ) < dVar (M ).Definition 2.10 language OBDD union OBDD< languages.OBDD language corresponds wellknown ordered binary decision diagrams (OBDDs)(Bryant, 1986).final language definition follows:Definition 2.11 MODS subset DNF every sentence satisfies determinism smoothness.233fiDarwiche & MarquisXZX ZFigure 3: sentence language MODS.NNFCO,d-NNFs-NNFCE,DNNFf-NNFVA, IM, CTBDDd-DNNFEQ?VA, IMFBDDEQ?DNFsd-DNNFCNFEQOBDDSEOBDD<EQ, SEVA, IM, EQ, SEMODSIPCO , CE, EQ, SE,PIFigure 4: set DAG-based languages considered paper. edge L1 L2 meansL1 proper subset L2 . Next subset, list polytime queries supportedsubset ancestors (see Section 4).Figure 3 depicts sentence MODS. show later, MODS tractable NNF subsetshall consider (together OBDD< ). surprising since syntax sentenceMODS, one immediately recover sentence models.languages discussed far depicted Figure 4, arrows denote set inclusion.Table 1 lists acronyms languages, together descriptions. Table 2 listskey language properties discussed section, together short description each.3. Succinctness Compiled Theoriesdiscussed dozen subsets NNF language. subsets wellknown studied extensively computer science literature. Others, DNNF(Darwiche, 2001a, 1999) d-DNNF (Darwiche, 2001b), relatively new. question is:subset one adopt particular application? argue paper, depends234fiA Knowledge Compilation MapAcronymNNFDNNFd-NNFs-NNFf-NNFd-DNNFsd-DNNFBDDFBDDOBDDOBDD<DNFCNFPIIPMODSDescriptionNegation Normal FormDecomposable Negation Normal FormDeterministic Negation Normal FormSmooth Negation Normal FormFlat Negation Normal FormDeterministic Decomposable Negation Normal FormSmooth Deterministic Decomposable Negation Normal FormBinary Decision DiagramFree Binary Decision DiagramOrdered Binary Decision DiagramOrdered Binary Decision Diagram (using order <)Disjunctive Normal FormConjunctive Normal FormPrime ImplicatesPrime ImplicantsModelsTable 1: Language acronyms.PropertyFlatnessSimple DisjunctionSimple ConjunctionDecomposabilityDeterminismSmoothnessDecisionOrderingShort Descriptionheight NNF 2Every disjunction clause, literals share variablesEvery conjunction term, literals share variablesConjuncts share variablesDisjuncts logically disjointDisjuncts mention set variablesnode form true, false, (X X ),X variable , decision nodesDecision variables appear order path NNFTable 2: Language properties.235fiDarwiche & Marquisthree key properties language: succinctness, class tractable queries supports,class tractable transformations admits.goal following sections construct map place differentsubsets NNF language according criteria. map serve guidesystem designers choosing target compilation language suitable application.also provides example paradigm studying evaluating target compilation languages.start study succinctness2 section (Gogic, Kautz, Papadimitriou, & Selman, 1995).Definition 3.1 (Succinctness) Let L1 L2 two subsets NNF. L1 least succinctL2 , denoted L1 L2 , iff exists polynomial p every sentence L2 ,exists equivalent sentence L1 || p(||). Here, || || sizes ,respectively.stress require exists function computes givenpolytime; require polysize exists. Yet, proofs Appendix contain specificalgorithms computing certain cases. relation clearly reflexive transitive,hence, pre-ordering. One also define relation <, L1 < L2 iff L1 L2 L2 6 L1 .Proposition 3.1 results Table 3 hold.occurrence cell row r column c Table 3 means fragment Lrgiven row r least succinct fragment Lc given column c. occurrence 6 (or6 ) means Lr least succinct Lc (provided polynomial hierarchycollapse case 6 ). Finally, presence question mark reflects ignorancewhether Lr least succinct Lc . Figure 5 summarizes results Proposition 3.1 termsdirected acyclic graph.classical result knowledge compilation states possible compile propositional formula polysize data structure that: entail set clauses,clausal entailment decided time polynomial size, unless NP P/poly(Selman & Kautz, 1996; Cadoli & Donini, 1997). last assumption implies collapsepolynomial hierarchy second level (Karp & Lipton, 1980), considered unlikely.use classical result knowledge compilation proofs Proposition 3.1,explains parts conditioned polynomial hierarchy collapsing.excluded subsets BDD, s-NNF, d-NNF f-NNF Table 3 sincequalify target compilation languages (see Section 4). kept NNF CNF though givenimportance. Consider Figure 5 depicts Table 3 graphically. exception NNFCNF, languages depicted Figure 5 qualify target compilation languages. Moreover,exception language PI, DNNF succinct among target compilation languagesweknow PI succinct DNNF, know whether DNNF succinctPI.DNNF MODS, succinctness ordering target compilation languages:DNNF <d-DNNF <FBDD <OBDD <OBDD<< MODS.DNNF obtained imposing decomposability NNF; d-DNNF adding determinism; FBDDadding decision; OBDD OBDD< adding ordering (w.r.t. total ordering PSfirst case specific one second case). Adding properties reduces languagesuccinctness (assuming polynomial hierarchy collapse).One important fact stress adding smoothness d-DNNF affect succinctness: sd-DNNF d-DNNF languages equally succinct. also interesting compare2. general notion space efficiency (model preservation polysize reductions) exists (Cadoli, Donini,Liberatore, & Schaerf, 1996), need full generality here.236fiA Knowledge Compilation MapLNNFDNNFd-DNNFsd-DNNFFBDDOBDDOBDD<DNFCNFPIIPMODSNNF66666666666DNNF6666666666d-DNNF66666666sd-DNNF66666666FBDD6666666OBDD666666OBDD<66666DNF666666666CNF6666666666PI???666666IP??666666MODS?Table 3: Succinctness target compilation languages. means result holds unlesspolynomial hierarchy collapses.NNFDNNFsd-DNNF=CNFd-DNNFDNFFBDDPIOBDDIPOBDD<MODSFigure 5: edge L1 L2 indicates L1 strictly succinct L2 : L1 < L2 ,L1 = L2 indicates L1 L2 equally succinct: L1 L2 L2 L1 . Dottedarrows indicate unknown relationships; instance, dotted arrow DNNF PImeans know whether DNNF least succinct PI. edgesconditioned polynomial hierarchy collapsingsee Table 3.sd-DNNF (which succinct influential FBDD, OBDD OBDD< languages) MODS,tractable language. sd-DNNF MODS smooth, deterministic decomposable. MODS, however, flat obtains decomposability stronger conditionsimple-conjunction. Therefore, sd-DNNF viewed result relaxing MODSflatness simple-conjunction conditions, maintaining decomposability, determinismsmoothness. Relaxing conditions moves language three levels succinctness hierarchy, although compromises polytime test sentential entailment possibly oneequivalence show Section 4.237fiDarwiche & Marquis4. Querying Compiled Theoryevaluating suitability target compilation language particular application, succinctness language must balanced set queries transformationssupports polytime. consider section number queries, returns valuable information propositional theory, identify target compilation languagesprovide polytime algorithms answering queries. restrict attention paperexistence polytime algorithms answering queries, present algorithmsthemselves. interested reader referred (Darwiche, 2001a, 2001b, 1999; Bryant, 1986)algorithms proofs theorems Appendix others.queries consider tests consistency, validity, implicates (clausal entailment), implicants, equivalence, sentential entailment. also consider counting enumerating theorymodels; see Table 4. One also consider computing probability propositional sentence,assuming variables probabilistically independent. subsets consider, however,done polytime whenever models counted polytime.on, L denotes subset language NNF.Definition 4.1 (CO, VA) L satisfies CO (VA) iff exists polytime algorithm mapsevery formula L 1 consistent (valid), 0 otherwise.One main applications compiling theory enhance efficiency answeringclausal entailment queries:Definition 4.2 (CE) L satisfies CE iff exists polytime algorithm maps every formulaL every clause NNF 1 |= holds, 0 otherwise.key application clausal entailmentVis testing equivalence. Specifically, supposedesignVexpressed set clauses = specification expressed also set clauses= j j , want test whether design specification equivalent. compilingtargets support polytime clausal entailment test, testequivalence polytime. is, equivalent iff |= j j|= i.number target compilation languages shall consider support direct polytime equivalent test:Definition 4.3 (EQ, SE) L satisfies EQ (SE) iff exists polytime algorithm maps everypair formulas , L 1 ( |= ) holds, 0 otherwise.Note sentential entailment (SE) stronger clausal entailment equivalence. Therefore,language L satisfies SE, also satisfies CE EQ.completeness, consider following dual CE:Definition 4.4 (IM) L satisfies IM iff exists polytime algorithm maps every formulaL every term NNF 1 |= holds, 0 otherwise.Finally, consider counting enumerating models:Definition 4.5 (CT) L satisfies CT iff exists polytime algorithm maps every formulaL nonnegative integer represents number models (in binary notation).Definition 4.6 (ME) L satisfies iff exists polynomial p(., .) algorithmoutputs models arbitrary formula L time p(n, m), n sizenumber models (over variables occurring ).238fiA Knowledge Compilation MapNotationCOVACEIMEQSECTQuerypolytime consistency checkpolytime validity checkpolytime clausal entailment checkpolytime implicant checkpolytime equivalence checkpolytime sentential entailment checkpolytime model countingpolytime model enumerationTable 4: Notations queries.LNNFDNNFd-NNFs-NNFf-NNFd-DNNFsd-DNNFBDDFBDDOBDDOBDD<DNFCNFPIIPMODSCOVACEIMSECTEQ???Table 5: Subsets NNF language corresponding polytime queries.means satisfy unless P = NP.means satisfiesTable 4 summarizes queries interested acronyms.following proposition states know availability polytime algorithmsanswering queries, respect languages introduced Section 2.Proposition 4.1 results Table 5 hold.results Proposition 4.1 summarized Figure 4. One draw number conclusionsbased results figure. First, NNF, s-NNF, d-NNF, f-NNF, BDD fall one equivalenceclass support polytime queries CNF satisfies VA IM; hence, nonequalifies target compilation language case. remaining languagessupport polytime tests consistency clausal entailment. Therefore, simply imposing eithersmoothness (s-NNF), determinism (d-NNF), flatness (f-NNF), decision (BDD) NNF language lead tractability respect queries considerneitherproperties seem significant isolation. Decomposability (DNNF), however, exceptionleads immediately polytime tests consistency clausal entailment, polytimealgorithm model enumeration.239fiDarwiche & MarquisRecall succinctness ordering DNNF < d-DNNF < FBDD < OBDD < OBDD< < MODSFigure 5. adding decomposability (DNNF), obtain polytime tests consistencyclausal entailment, addition polytime model enumeration algorithm. adding determinismdecomposability (d-DNNF), obtain polytime tests validity, implicant model counting,quite significant. clear, however, whether combination decomposabilitydeterminism leads polytime test equivalence. Moreover, adding decision property topdecomposability determinism (FBDD) appear increase tractability respectgiven queries3 , although lead reducing language succinctness shown Figure 5.hand, adding ordering property top decomposability, determinism decision,leads polytime tests equivalence (OBDD OBDD< ) well sentential entailment providedordering < fixed (OBDD< ).succinctness ordering NNF < DNNF < DNF < IP < MODS Figure 5, noteDNNF obtained imposing decomposability NNF, DNF obtained imposing flatnesssimple-conjunction (which stronger decomposability). interesting DNFless succinct DNNF, yet support polytime queries; see Figure 4. However,addition smoothness (and determinism) top flatness simple-conjunction (MODS) leadsfive additional polytime queries, including equivalence entailment tests.4close section noting determinism appears necessary (but sufficient)polytime model counting: deterministic languages, d-DNNF, sd-DNNF, FBDD, OBDD, OBDD<MODS, support polytime counting. Moreover, polytime counting implies polytime test validity,opposite true.5. Transforming Compiled Theoryquery operation returns information theory without changing it. transformation, hand, operation returns modified theory, operatedusing queries. Many applications require combination transformations queries.Definition 5.1 (C, C) Let L subset NNF. L satisfies C (C) iff exists polytimealgorithm maps every finite set formulas 1 , . . . , n L formula L logicallyequivalent 1 . . . n (1 . . . n ).Definition 5.2 (C) Let L subset NNF. L satisfies C iff exists polytime algorithmmaps every formula L formula L logically equivalent .language satisfies one properties, say closed corresponding operator. Closure logical connectives important two key reasons. First,implications compilers constructed given target language. example, clauseeasily compiled language L, closure conjunction implies compilingCNF sentence L easy. Second, implications class polytime queries supportedtarget language: language L satisfies CO closed negation conjunction,must satisfy SE (to test whether |= , do, Refutation Theorem,test whether inconsistent). Similarly, language satisfies VA closednegation disjunction, must satisfy SE Deduction Theorem.3. Deciding equivalence two sentences FBDD, d-DNNF, sd-DNNF, easily shown coNP.However, proof coNP-hardness, deterministic polytime algorithms decidingproblems. Actually, latter case quite unlikely equivalence problem FBDD intensivelystudied, algorithm sight. Note, however, equivalence two sentences FBDDdecided probabilistically polytime (Blum, Chandra, & Wegman, 1980), similarly sentences d-DNNF(Darwiche & Huang, 2002).4. Given flatness, simple-conjunction smoothness, obtain determinism simply removing duplicatedterms.240fiA Knowledge Compilation Mapimportant stress languages closed logical operator,number operands bounded constant. refer bounded closure.Definition 5.3 (BC, BC) Let L subset NNF. L satisfies BC (BC) iff existspolytime algorithm maps every pair formulas L formula Llogically equivalent ( ).turn another important transformation:Definition 5.4 (Conditioning) (Darwiche, 1999) Let propositional formula, letconsistent term. conditioning , noted | , formula obtained replacingvariable X true (resp. false) X (resp. X) positive (resp. negative) literal .Definition 5.5 (CD) Let L subset NNF. L satisfies CD iff exists polytime algorithmmaps every formula L every consistent term formula L logicallyequivalent | .Conditioning number applications, corresponds restriction literatureBoolean functions. main application conditioning due theorem, saysconsistent iff | consistent (Darwiche, 2001a, 1999). Therefore, language satisfies COCD, must also satisfy CE. Conditioning also plays key role building compilersenforce decomposability. two sentences 1 2 decomposable (belong DNNF),conjunction 1 2 necessarily decomposable since sentences may share variables.Conditioningused ensure decomposability case since 1 2 equivalentW(|)(12 | ) , term covering variables shared 1 2 . NoteW(|)(12 | ) must decomposable since 1 | 2 | mention variables. previous proposition indeed generalization multiple variables well-knownShannon expansion literature Boolean functions. also basis compiling CNFDNNF (Darwiche, 1999, 2001a).Another critical transformation shall consider forgetting (also referred marginalization, elimination middle terms (Boole, 1854)):Definition 5.6 (Forgetting) Let propositional formula, let X subset variablesPS. forgetting X , denoted X., formula mention variableX every formula mention variable X, |= preciselyX. |= .Therefore, forget variables X remove reference X , maintaininginformation captures complement X. Note X. unique logicalequivalence.Definition 5.7 (FO, SFO) Let L subset NNF. L satisfies FO iff exists polytimealgorithm maps every formula L every subset X variables PS formulaL equivalent X.. property holds singleton X, say L satisfies SFO.Forgetting important transformation allows us focus/project theory setvariables. example, know variables X never appear entailment queries,forget variables compiled theory maintaining ability answerqueries correctly. Another application forgetting counting/enumerating instantiations variables Y, consistent theory . query answeredcounting/enumerating models X., X complement Y. Forgetting alsoapplications planning, diagnosis belief revision. instance, SATPLAN framework,241fiDarwiche & MarquisNotationCDFOSFOCBCCBCCTransformationpolytime conditioningpolytime forgettingpolytime singleton forgettingpolytime conjunctionpolytime bounded conjunctionpolytime disjunctionpolytime bounded disjunctionpolytime negationTable 6: Notations transformations.LNNFDNNFd-NNFs-NNFf-NNFd-DNNFsd-DNNFBDDFBDDOBDDOBDD<DNFCNFPIIPMODSCDFOSFOCBCCBCC??Table 7: Subsets NNF language polytime transformations.means satisfies,means satisfy, means satisfy unless P=NP.compiling away fluents actions amounts forgetting variables. model-based diagnosis, compiling away every variable except abnormality ones remove piece informationrequired compute conflicts diagnoses system (Darwiche, 2001a). Forgettingalso used design update operators valuable properties (Herzig & Rifi, 1999).Table 6 summarizes transformations interested acronyms. followingproposition states know tractability transformations respectidentified target compilation languages.Proposition 5.1 results Table 7 hold.One draw number observations regarding Table 7. First, languages consider satisfyCD and, hence, lend efficient application conditioning transformation.forgetting multiple variables, DNNF, DNF, PI MODS permit polytime. importantstress none FBDD, OBDD OBDD< permits polytime forgetting multiple variables.noticeable since recent applications OBDD< planningwithin so-calledsymbolic model checking approach planning (A. Cimmati & Traverso, 1997)depend crucially242fiA Knowledge Compilation Mapoperation forgetting may suitable use language satisfies FOcase. Note, however, OBDD OBDD< allow forgetting single variable polytime,FBDD allow even that. d-DNNF similar FBDD satisfies neither FO SFO.also interesting observe none target compilation languages closedconjunction. number them, however, closed bounded conjunction, including OBDD< ,DNF, IP MODS.disjunction, target compilation languages closed disjunctionDNNF DNF. OBDD< PI languages, however, closed bounded disjunction. Again,d-DNNF, FBDD OBDD languages closed neither.target compilation languages closed negation FBDD, OBDD OBDD< ,known whether d-DNNF sd-DNNF closed operation. Note d-DNNFFBDD support set polytime queries (equivalence checking unknown both)indistinguishable viewpoint. Moreover, difference twolanguages Table 7 closure FBDD negation, seem significantlight closure either conjunction disjunction. Note, however, d-DNNFsuccinct FBDD given Figure 5.Finally, OBDD< target compilation language closed negation, boundedconjunction, bounded disjunction. closure actually plays important role compilingpropositional theories OBDD< basis state-of-the-art compilers purpose(Bryant, 1986).6. Conclusionmain contribution paper methodology analyzing propositional compilation approaches according two key dimensions: succinctness target compilation language,class queries transformations supports polytime. second main contributionpaper comprehensive analysis, according proposed methodology,dozen languages produced knowledge compilation map, cross-rankslanguages according succinctness, polytime queries transformationssupport. map allows system designers make informed decisions target compilationlanguage use: class queries/transformations decided based application interest, designer chooses succinct target compilation language supportsoperations polytime. Another key contribution paper uniform treatmentapplied diverse target compilation languages, showing subsets NNFlanguage. Specifically, identified number simple, yet meaningful, properties, includingdecomposability, determinism, decision flatness, showed combinations properties give rise different target compilation languages. studied subsets include well knownlanguages PI, influential AI; OBDD< , influential formalverification; CNF DNF, quite influential computer science. subsetsalso include relatively new languages DNNF d-DNNF, appear representinteresting, new balances language succinctness query/transformation tractability.Acknowledgmentsrevised extended version paper Perspective Knowledge Compilation,Proceedings 17th International Joint Conference Artificial Intelligence (IJCAI01), pp.175-182, 2001. wish thank Alvaro del Val, Mark Hopkins, Jerome Lang anonymousreviewers suggestions comments, well Ingo Wegener helpissues discussed paper. work done second author visitingresearcher Computer Science Department UCLA. first author partly243fiDarwiche & Marquissupported NSF grant IIS-9988543 MURI grant N00014-00-1-0617. second authorpartly supported IUT de Lens, Universite dArtois, Nord/Pas-de-Calais RegionTACT-TIC project, European Community FEDER Program.Appendix A. Proofssimplify proofs main propositions later on, identified number lemmaslist below. proofs lemmas direct, include completeness.Lemma A.1 Every sentence d-DNNF translated equivalent sentence sd-DNNFpolytime.Proof: Let = 1 . . . n or-node d-DNNF sentence . Suppose smoothandWlet V = VVars(). Consider sentence obtained replacing nodeni=1 vV \Vars(i ) (v v). equivalent smooth. Moreover,computed time polynomial size satisfies decomposability determinism. 2Lemma A.2 Every sentence FBDD translated equivalent sentence FBDD s-NNFpolytime.Proof: Let sentence FBDD let node . always replace (Y )(Y ), variable , preserving equivalence decision property. Moreover,long variable appear ancestor , decomposabilityalso preserved (that is, resulting sentence FBDD). Note ancestor respectbinary decision diagram notation see left Figure 2.Now, suppose (X ) (X ) or-node . Suppose or-nodesmooth. Hence, appears Vars() Vars() (orway around). Since decomposable, cannot ancestor (since casewould also ancestor , impossible decomposability ). Hence, replace (Y ) (Y ), preserving equivalence, decision decomposability.repeating process, smooth preserving necessary properties. Finally,note every or-node (X ) (X ) , need repeat process| Vars() Vars() | + | Vars() Vars() | times. Hence, smoothing operation performed polytime.2Lemma A.3 subset L NNF satisfies CO CD, also satisfies ME.Proof: Let sentence L. First, test inconsistent (can done polytime).is, return empty set models. Otherwise, construct decision-tree representationmodels . Given ordering variables x1 , . . . , xn Vars(), start treeconsisting single root node. = 1 n, repeat following leaf node(corresponds consistent term) :a. | xi consistent, add xi child ;b. | xi consistent, add xi child .key points are:Test (a) Test (b) performed time polynomial size (since L satisfiesCO CD).244fiA Knowledge Compilation MapEither Test (a) Test (b) must succeed (since consistent).Hence, number tests performed O(mn), number leaf nodes finaldecision tree (bounded number models ) n number variables .2Lemma A.4 subset NNF satisfies CO CD, also satisfies CE.Proof: test whether sentence entails non-valid clause , |= , suffices test whether| inconsistent (Darwiche, 2001a).2Lemma A.5 Let two sentences share variables. valid iff validvalid.Proof: valid iff inconsistent. Since share variables,inconsistent iff inconsistent is. true iff valid valid.2Lemma A.6 Let sentence d-DNNF let clause. sentence d-DNNFequivalent constructed polytime size .WnVi1Proof: Let l1 , . . . , ln literals appear clause . = i=1 (li j=1 lj )equivalent clause , d-DNNF, constructed polytime size . letterm equivalent . equivalent (( | ) ) . last sentenced-DNNF constructed polytime size .2Lemma A.7 subset NNF satisfies VA CD, also satisfies IM.Proof: test whether consistent term entails sentence , |= , suffices test whethervalid. sentence equivalent ( ), ( ( | )), ( | ).Since | share variables, disjunction valid iff valid | valid (byLemma A.5). cannot valid since consistent. | constructed polytime sincelanguage satisfies CD validity tested polytime since language satisfies VA. 2Lemma A.8 Every CNF DNF formula translated equivalent sentence BDDpolytime.Proof: straightforward convert clause term equivalent sentence BDD. ordergenerate BDD sentence corresponding conjunction (resp. disjunction) BDD sentences, sufficient replace 1-sink (resp. 0-sink) root .2Lemma A.9 subset NNF satisfies EQ, satisfies CO VA.Proof: true false belong every NNF subset. inconsistent iff equivalent false.valid iff equivalent true.2Lemma A.10 subset NNF satisfies SE, satisfies EQ, CO VA.Proof: Sentences 1 2 equivalent iff 1 |= 2 2 |= 1 . EQ implies CO VA(Lemma A.9).2245fiDarwiche & MarquisLemma A.11 Let sentence d-DNNF let clause. validitytested time polynomial size .Proof: Construct polytime given Lemma A.6 check validity,done polytime too.2Lemma A.12 every propositional formula every consistent term , |equivalentVars().( ).Proof: Without loss generality, assume given disjunctively-interpreted setmodels (over Vars()). Conditioning leads (1) removing every model ,(2) projecting remaining models every variable removed. Conjoiningleads exactly (1), forgetting every variable resulting formula leads exactly (2)(Lang, Liberatore, & Marquis, 2000).2Lemma A.13 sentence f-NNF converted equivalent sentence polynomial time, CNF DNF.Proof: consider three cases sentence :1. root node and-node. case, turned CNF sentencepolynomial time simply ensuring or-node clause (that is, disjunctionliterals share variables). Let C or-node . Since flat rootand-node, C must child root children C must leaves. Hence,easily ensure C clause follows:one edge C leaf X another edge C X (C valid),replace edge root C edge root true.one edge C leaf node X, keep oneedges delete rest.2. root or-node. turned DNF sentence dual way.53. root leaf node. already CNF sentence.2Lemma A.14 prime implicant (resp. essential prime implicant) sentence iffprime implicate (resp. essential prime implicate) . 6Proof: folklore result, immediate definitions.2Proof Proposition 3.1proof proposition broken eight steps. step, prove numbersuccinctness relationships different languages, apply transitivity succinctnessrelation infer even relationships. Associated step proof table246fiA Knowledge Compilation MapLNNFDNNFd-DNNFFBDDOBDDOBDD<DNFCNFPIIPMODSsd-DNNFNNFDNNFd-DNNFFBDDOBDDOBDD<DNFCNFPIIPMODSsd-DNNFTable 8:LNNFDNNFd-DNNFFBDDOBDDOBDD<DNFCNFPIIPMODSsd-DNNFNNFDNNFd-DNNFFBDDOBDDOBDD<DNF666CNF6666PI66666IPMODSsd-DNNF66666Table 9:mark relationships proved stepwe dont show marks firsttable though.Table 8: Follows immediately language inclusions reported Figure 4.Table 9: prove DNF 6 PI CNF 6 IP (this slightly generalizes resultsDNF 6 CNF CNF 6 DNF given (Gogic et al., 1995)).Vn1Let us consider CNF formula n = i=0 (x2i x2i+1 ). formula prime implicatesform7 (and clause n essential prime implicate it). Hence negation nprime implicants form (as easy consequence Lemma A.14).Since Quines early work (Quine, 1959), know number essential prime implicants(resp. prime implicates) formula lower bound number terms (resp. clauses)found DNF (resp. CNF) representation (indeed, representation mustinclude essential prime). n 2n essential prime implicants. Indeed, easily showninduction n given (i) every literal occurring n occurs once, (ii) set primeimplicants nontautological clause set literals occurring (up logical equivalence),(iii) distribution property prime implicants (see e.g., (dual of) Proposition 40 (Marquis,2000)) states IP ( ) = max({PI PI | PI IP (), PI IP ()}, |=) (up logicalequivalence). Subsequently, n 2n essential prime implicates (cf. Lemma A.14). Accordingly,obtain DNF 6 PI CNF 6 IP. also obtain PI 6 IP IP 6 PI. Now,wellknown DNF formulas exponentially many prime implicants (see proofProposition 5.1 show IP satisfy SFO). Hence, negations CNF5. Note f-NNF satisfies C negation CNF sentence (resp. DNF sentence) turnedDNF (resp. CNF) linear time.6. prime implicant (resp. prime implicate) essential iff disjunction (resp. conjunction) primeimplicants (resp. prime implicates) except equivalent .7. correctness (the dual of) Quines consensus algorithm computing prime implicants (Quine, 1955)ensures it, since clause n subsumed another clause consensi performed sincenegated variables.247fiDarwiche & MarquisLNNFDNNFd-DNNFFBDDOBDDOBDD<DNFCNFPIIPMODSsd-DNNFNNFDNNFd-DNNFFBDDOBDDOBDD<DNF66666666CNF66666666PI666666666IPMODSsd-DNNF666666666Table 10:LNNFDNNFd-DNNFFBDDOBDDNNFDNNFd-DNNFOBDD<FBDD666OBDD6666OBDD<DNFCNFPIIPMODSsd-DNNF66666666666666666666666666666DNFCNFPIIPMODSsd-DNNF6666666666Table 11:formulas exponentially many prime implicates. Subsequently IP 6 DNF PI 6 CNF.remaining results table follow fromLtransitivity .n1Table 10: parity function = i=0 xi linear size OBDD< representations (Bryant,1986) exponential size CNF DNF representations. reason 2nessential prime implicants (resp. essential prime implicates) number essential primeimplicants (resp. essential prime implicates) formula lower bound sizeDNF (resp. CNF) representation. easily shows CNF 6 OBDD DNF 6 OBDD.remaining results table follow language inclusions reported Figure 4.Table 11: shown (Darwiche, 2001b) sentence d-DNNFexponential FBDD representations. Accordingly, FBDD 6 d-DNNF. (Gergov & Meinel,1994a), shownVthat OBDD 6 FBDD. Finally, easy show OBDD< 6 OBDD (for instance,nformula n = i=1 (xi yi ) OBDD< representation size polynomial n whenever <satisfies x1 < y1 < x2 < . . . < xn < yn , OBDD< representation size exponentialn provided < s.t. x1 < x2 < . . . < xn < y1 < y2 < . . . < yn ). remaining resultstable follow language inclusions reported Figure 4.Table 12: L 6 L means L 6 L unless polynomial hierarchy PH collapses.results table follow since existence polysize knowledge compilation functions clausalentailment implies collapse polynomial hierarchy PH (Selman & Kautz, 1996; Cadoli &Donini, 1997). Now, DNNF CNF, sentence CNF exists polysize equivalentsentence DNNF. Therefore, test whether clause entailed polytime testingwhether clause entailed . proves existence polysize knowledge compilationfunctions clausal entailment, leading collapse polynomial hierarchy PH.true d-DNNF sd-DNNF since languages support polytime clausal entailment test(see Proposition 4.1).Table 13: (Wegener, 1987) (Theorem 6.2 pp. 436), family n2 -variable boolean functionspointed out. Provided every interpretation n2 variables represents n-verticesdigraph (for every 1 i, j n, I(xi,j ) = 1 iff (i, j) arc digraph), (I) = 1 iff248fiA Knowledge Compilation MapLNNFDNNFd-DNNFFBDDOBDDOBDD<DNFCNFPIIPMODSsd-DNNFNNF66DNNFd-DNNFFBDDOBDDOBDD<DNFCNFPIIPMODS6sd-DNNF6666666666666666666666666666666666666666666666666Table 12:LNNFDNNFd-DNNFFBDDOBDDCNFPIIPMODSsd-DNNF66OBDD<DNFNNFDNNFd-DNNF66FBDD6666666OBDD66666666OBDD<DNFCNFPIIPMODSsd-DNNF666666666666666666666666666666666666666666666Table 13:digraph represented contains k-clique special kind (k parameter family).shown certain values k (depending n), every FBDD representation exponentialsize. Moreover, shown cubic number prime implicants. showsFBDD 6 IP, hence FBDD 6 DNF. FBDD satisfies C (see Proposition 5.1),8 cannotcase polynomial size FBDD. Since cubic number prime implicates,obtain FBDD 6 PI, hence FBDD 6 CNF. remaining results table follow since FBDDOBDD OBDD< .Table 14: Assume d-DNNF DNF holds. consequence, every sentence DNFcompiled equivalent d-DNNF sentence polynomial size. Now, checking whether clauseentailed CNF sentence equivalent checking whether DNF sentencevalid. Checking whether () validwhen () d-DNNF sentence clausecanachieved polynomial time Lemma A.11. Therefore, () polysize compilation8. is, sentence FBDD negated polytime yield sentence FBDD too.LNNFDNNFd-DNNFFBDDOBDDNNFDNNF6OBDD<d-DNNF66DNFCNFPIIPMODSsd-DNNF666FBDD6666666OBDD666666666OBDD<DNF666666666666666666CNF66666666PI666666666IPMODS666666666sd-DNNF6666666Table 14:24966fiDarwiche & MarquisLNNFDNNFd-DNNFFBDDOBDDOBDD<DNFCNFPIIPMODSsd-DNNFNNFDNNFd-DNNF666666FBDD66666666OBDD666666666OBDD<DNF6666666666666666666CNFPI6666666666666666666IP6666666666MODSsd-DNNF666666666666666Table 15:CNF sentence , allowing clausal entailment achieved polynomial time. existence() every CNF sentence implies collapse polynomial hierarchy (Selman &Kautz, 1996; Cadoli & Donini, 1997). Hence, obtain d-DNNF 6 DNF. consequence,also d-DNNF 6 DNNF. Finally, since every d-DNNF sentence turned polynomial timeequivalent sd-DNNF sentence Lemma A.1, sd-DNNF d-DNNF. Moreover, sinced-DNNF sd-DNNF, obtain sd-DNNF 6 DNF, sd-DNNF 6 DNNF, sd-DNNF FBDD, sd-DNNFOBDD, sd-DNNF OBDD< , FBDD 6 sd-DNNF, OBDD< 6 sd-DNNF, DNF 6 sd-DNNF, CNF 6 sd-DNNF, PI6 sd-DNNF IP 6 sd-DNNF.Table 15: Let us show WMODS less succinct PI, IP, sd-DNNF OBDD.nFirst, let us consider formula = i=1 xi . represented PI, IP, sd-DNNF OBDDformulas size polynomial n. Contrastingly, cannot represented MODS formulasize polynomial n since 2n 1 models Vars(). Now, well-known oldgood Quine-McCluskeys algorithm generating prime implicants MODS representationpropositional formula runs time polynomial number models (Wegener, 1987).shows IP MODS. CNF OBDD< , obvious decision tree (or Shannon tree)respects given total ordering Vars() generated polynomial timeMODS representation . decision tree 1-leaves number modelsVars(). Accordingly, n 0-leaves n = |Vars()|. Since setpaths root tree 0-leaf read CNF representation , obtainCNF MODS. hand, since reducing decision tree derive corresponding OBDD<done polynomial time, follows OBDD< representation also generatedMODS representation it. Hence, OBDD< MODS. remaining results table followlanguage inclusions reported Figure 4. 2Proof Proposition 4.1proof proposition broken twelve steps. step, prove numberresults. Associated step proof table mark resultsproved step. table last step includes results declared proposition.Table 16: Every classical CNF DNF formula translated straightforward wayequivalent f-NNF sentence (with tree structure) polytime. Moreover, every NNF sentencetranslated equivalent s-NNF sentence polytime (Lemma A.1). Given CONP-hard (resp. VA coNP-hard) classical CNF (resp. DNF) sentences, inclusionvarious NNF subsets reported Figure 4, obtain table.Table 17: SE implies CO VA (Lemma A.10). Moreover, since CT implies COVA, IM implies VA (valid term), CE implies CO (inconsistent clause), obtaintable.250fiA Knowledge Compilation MapLCOVANNFDNNFd-NNFd-DNNFBDDFBDDOBDDOBDD<CEIMEQCTSEEQDNFCNFPIIPMODSs-NNFf-NNFsd-DNNFTable 16:LCOVACEIMCTSENNFDNNFd-NNFd-DNNFBDDFBDDOBDDOBDD<DNFCNFPIIPMODSs-NNFf-NNFsd-DNNFTable 17:LCOVACEIMCTSENNFDNNFd-NNFd-DNNFBDDFBDDOBDDOBDD<DNFCNFPIIPMODSs-NNFf-NNFsd-DNNFEQTable 18:251fiDarwiche & MarquisLCOVACEIMCTSENNFDNNFd-NNFd-DNNFBDDFBDDOBDDOBDD<DNFCNFPIIPMODSs-NNFf-NNFsd-DNNFEQTable 19:LCOVACEIMCTSENNFDNNFd-NNFd-DNNFBDDFBDDOBDDOBDD<DNFCNFPIIPEQs-NNFf-NNFMODSsd-DNNFTable 20:Table 18: sentence consistent (resp. valid) iff model (resp. 2n models,n = |Vars()|). Moreover, number models given number edges outgoingor-node MODS representation . Accordingly, CO, VA CT achievedpolynomial time given MODS formula gives us table.Table 19:Because DNNF satisfies CE (Darwiche, 2001a), CE implies CO MODS DNFDNNF, IP DNFsd-DNNF d-DNNF DNNF, obtain table.Table 20: use following results:CD CO imply CE (Lemma A.4).CD VA imply IM (Lemma A.7).CD CO imply (Lemma A.3).considered NNF subsets satify CD (cf. Proposition 5.1).NNF subset satisfy CO cannot satisfy ME.well-known FBDD satisfies CO, VA CT, OBDD< satisfies (in addition)EQ (Gergov & Meinel, 1994a; Bryant, 1992).Since |= holds iff inconsistent since OBDD< satisfies CO, C BC (cf.Proposition 5.1), OBDD< also satisfies SE.252fiA Knowledge Compilation MapLCOVACEIMCTSENNFDNNFd-NNFd-DNNFBDDFBDDOBDDOBDD<DNFCNFPIIPMODSs-NNFf-NNFsd-DNNFEQTable 21:LCOVACEIMCTSENNFDNNFd-NNFd-DNNFBDDFBDDOBDDOBDD<DNFCNFPIIPMODSs-NNFf-NNFsd-DNNFEQTable 22:Obviously enough, query concerning OBDD equivalent corresponding query concerning OBDD< provided one DAG brought play. Togetherresults, conclude OBDD satisfies CO, VA CT. Since fragment satisfies CDwell, satisfies CE, IM addition. also satisfies EQ (see Theorem 8.11(Meinel & Theobald, 1998)) satisfy SE (unless P = NP). Indeed, knownchecking consistency two OBDD< formulas (based two different variable orderings <) NP-complete (Lemma 8.14 (Meinel & Theobald, 1998)). Since OBDDsatisfies C since consistent iff 6|= , checking sentential entailment OBDDformulas coNP-complete.results lead table.Table 21: known IM satisfied classical CNF formulas (hence, PI) (in ordercheck whether non-valid clause implied consistent term, sufficient testshare literal). CNF (hence, PI) also known satisfy VA. obtain table.Table 22: Every sentence CNF DNF turned equivalent sentence BDDpolytime (Lemma A.8). Hence, CNF DNF cell implies corresponding BDD cell.Similarly, since BDD d-NNF, BDD cell implies corresponding d-NNF cell.leads table.Table 23: Since EQ implies CO VA (Lemma A.9), CO VA cell impliescorresponding EQ cell. leads table.Table 24: definition, PI satisfies CE IP satisfies IM. Since PI CNF IP DNF,implies PI IP satisfy SE. Now, SE implies EQ, hence PI IP satisfy EQ(actually, two equivalent formulas share prime implicates prime implicants(both forms canonical ones, provided one representative per equivalence class considered,253fiDarwiche & MarquisLCOVACEIMEQCTSENNFd-NNFd-DNNFBDDFBDDOBDDOBDD<DNNFDNFCNFPIIPMODSs-NNFf-NNFsd-DNNFTable 23:LCOVACEIMEQCTSENNFDNNFd-NNFd-DNNFBDDFBDDOBDDOBDD<DNFCNFPIIPMODSs-NNFf-NNFsd-DNNFTable 24:254fiA Knowledge Compilation MapLCOVACEIMEQCTSENNFDNNFd-NNFd-DNNFBDDFBDDOBDDOBDD<DNFCNFPIIPMODSs-NNFf-NNFsd-DNNFTable 25:LCOVACEIMEQCTSENNFDNNFd-NNFd-DNNFBDDFBDDOBDDOBDD<DNFCNFPIIPMODSs-NNFf-NNFsd-DNNFTable 26:only)). Since PI satisfies CE, also satisfies CO. Since satisfies CD well (cf. Proposition 5.1),also satisfies (Lemma A.3). Contrastingly, models counting problem monotone Kromformulas (i.e. conjunctions clauses containing two literals positive literals)#P-complete (Roth, 1996). formulas easily turned prime implicates formpolynomial time (Marquis, 2000), hence PI satisfy CT. Now, since negationformula prime implicates form formula prime implicants form (cf. Lemma A.14),since number models Vars() 2|Vars()| minus number modelsVars(), necessarily IP satisfy CT. also imply IP satisfies VA,leading table.Table 25: proof Proposition 3.1, shown prime implicantscomputed polytime MODS representation . immediate consequence, since IPsatisfies IM, EQ SE, obtain MODS satisfies IM, EQ SE, leading table.Table 26: Since d-DNNF satisfies CT (Darwiche, 2001b), also satisfies VA. Since satisfiesCD (Proposition 5.1), also satisfies IM well (Lemma A.7). Since sd-DNNF d-DNNF,results follow sd-DNNF. Hence, obtain table.Table 27: known determining whether conjunction two FBDD formulas 1 2consistent NP-complete (Gergov & Meinel, 1994b) Moreover, FBDD satisfies C. Since 1 2inconsistent iff 1 |= 2 , reduce consistency test entailment test. Hence, FBDDsatisfy SE. Since FBDD d-DNNF, d-DNNF satisfy SE either. Finally, since everyd-DNNF translated equivalent sd-DNNF sentence polytime (Lemma A.1), sd-DNNFsatisfy SE either. leads final table above. 2255fiDarwiche & MarquisLCOVACEIMEQCTSENNFDNNFd-NNFd-DNNFBDDFBDDOBDDOBDD<DNFCNFPIIPMODSs-NNFf-NNFsd-DNNFTable 27:Proof Proposition 5.1proof proposition broken eight steps. step corresponds onetransformations, prove results pertaining transformation.CD. show language L satisfies CD, want show sentence Lconsistent term , construct polytime sentence belongs Lequivalent | .NNF, f-NNF, CNF DNF. property trivially satisfied languages:belongs languages, replacing literals Boolean constantresults sentence language. case DNF (resp. CNF),inconsistent terms (valid clauses) may result conditioning,removed easily polynomial time.DNNF. sufficient prove conditioning preserves decomposability. everypropositional sentences , every consistent term , share variables,| | share variables either since Vars(|) Vars() Vars(|)Vars().d-NNF d-DNNF. Since NNF DNNF satisfy CD, sufficient prove conditioning preserves determinism, i.e. every propositional formulas , every consistentterm , |= false, (|) (|) |= false. |= false, every term, ( ) |= false. Since ( ) (( )|) , implies(( )|) |= false. Since consistent share variable ( )|, mustcase ( )| inconsistent. equivalent state (|) (|) |=false.s-NNF sd-DNNF. Since NNF satisfies CD, since conditioning preserves decomposability determinism, show conditioning also preserves smoothness. follows immediately since two propositional sentences , consistentterm , Vars() = Vars() Vars( | ) = Vars( | ).BDD, FBDD, OBDD OBDD< . wellknown BDD satisfies CDthe conditioningoperation binary decision diagrams known restrict operation (Bryant, 1986).condition sentence BDD consistent term , replace every node labeledvariable one two children, according sign variable .resulting sentence also BDD equivalent | . applies FBDD,OBDD OBDD< .PI. prime implicates computed polytime primeimplicates form term (see Proposition 36 (Marquis, 2000)). Moreover, since256fiA Knowledge Compilation MapPI satisfies FO (see below), prime implicates Vars().( ) computedpolytime. exactly prime implicates | according Lemma A.12.WnIP.WnLet = i=1 formula prime implicants form. clear formula( i=1 ) | DNF formula equivalent | . Now, claimWnthat formulaobtained keeping logically weakest terms | among ( i=1 ) | primeimplicants formula equivalent | . Removing terms clearly truth-preserving.Since generating requires O(n2 ) entailment tests among terms, sincetests easily achieved polynomial time, obtain IP satisfies CD. Now,prove prime implicants form? Since pair different termscannot compared w.r.t. logical entailment, correctness Quines consensusalgorithm generating prime implicants shows sufficient prove everyconsensus among two terms inconsistent entails another term . Letsrecall consensus DNF formulas resolution CNF formulas. Sinceprime implicants form, every consensus among two terms inconsistententails another term . happens terms (here, prime implicants)conditioned ? containing negation literal removedremaining ones shortened removing every literal . Hence,every pair terms 1 , 2 , consensus 1 2 ,consensus 1 | 2 |: conditioning cannot create new consensus.Now, remains prove unproductive consensus termsrendered productive conditioning. Formally, let 1 = 10 l 2 = 20 ltwo prime implicates s.t. l (resp. l) appear 10 (resp. 20 ).consensus 10 20 1 2 . Let us assume 1 2 survivedconditioning: means 1 | 2 | consistent. Especially, l belongs1 | l belongs 2 |. Accordingly, consensus 1 | 2 |.construction, consensus equivalent (10 |)(20 |), hence equivalent (10 20 )|.Now, 10 20 inconsistent, (10 20 )| inconsistent well done.Otherwise, let us assume exists prime implicant 3 s.t. 10 20 |= 3holds. Necessarily, 3 preserved conditioning . Otherwise, 3 wouldcontain negation literal , since every literal 3 literal 1literal 2 , 2 3 would survived conditioning. Since 10 20 |= 3holds, necessarily (10 20 )| |= 3 |. completes proof.MODS. Direct consequence Lemma A.12 fact MODS satisfies BC FO(see below).FO.DNNF DNF. known DNNF satisfies FO (Darwiche, 2001a). also knownDNF satisfies FO (Lang et al., 2000).NNF, s-NNF, f-NNF, d-NNF, BDD CNF. Let sentence CNF. showprevious languages satisfies FO, test consistencypolytime. Since CNF satisfy CO (see Proposition 4.1), follows noneprevious languages satisfy FO unless P = NP. First, note must alsobelong NNF f-NNF. Moreover, turned sentence BDD polytime(Lemma A.8) sentence s-NNF polytime (see proof Lemma A.1).also turned sentence d-NNF polytime since BDD d-NNF.Suppose one previous languages, call L, satisfy FO. testconsistency polytime follows:Convert sentence L polytime (as shown above).Compute Vars()., done polytime assumption.257fiDarwiche & MarquisTest validity Vars()., done polytime since sentencecontains variablesall check whether sentence evaluatestrue.Finally, note definition forgetting implies sentence consistent iffVars(). valid, completes proof.d-DNNF sd-DNNF. Follows immediately since none languages satisfies SFOunless P = NP (see below).IP. Follows immediately since IP satisfy SFO.FBDD, OBDD OBDD< . show FBDD (resp. OBDD, OBDD< ) satisfies FO,every sentence DNF, must exist equivalent sentence FBDD (resp.OBDD, OBDD< ), size polynomial size . contradicts factFBDD (resp. OBDD, OBDD< ) 6 DNFsee Table 3.Given DNF consisting terms 1 , ..., n , convert terms equivalent FBDD (resp. OBDD, OBDD< ) sentences 1 , . . . , n polytime. Let {v1 , . . . , vn1 }set variables belong P S. Construct new set variablesP 0 = P {v1 , . . . , vn1 }. case OBDD OBDD< , also assumenew variables earlier variables P ordering. Consider sentence= {v1 , . . . , vn1 }.1 , respect variables P 0 , inductively definedby:= , = n,= (i vi ) (i+1 vi ), = 1, . . . , n 1.Clearly enough, FBDD (resp. OBDD, OBDD< ) sentence equivalentWto 1 Wcomputednntime polynomial input size. Moreover, i=1 i=1 .Hence, FBDD (resp. OBDD, OBDD< ) satisfies FO, convert DNF sentenceequivalent FBDD (resp. OBDD, OBDD< ) size polynomial sizegiven DNF. impossible general.PI. known prime implicates X. exactly prime implicatescontain variable X (see Proposition 55 (Marquis, 2000)). Hence,prime implicates computed time polynomial input sizeprime implicates form.MODS. Given MODS formula subset X P S, formula obtained removingevery leaf node (and corresponding incoming edges) labeled literal x xs.t. x X MODS representation X.this easy consequence Propositions18 20 (Lang et al., 2000). See also polytime operation forgetting DNNF,defined (Darwiche, 2001a), applies MODS, sinceMODS DNNF, easily modified guarantees outputMODS input also MODS.SFO.DNNF, DNF, PI MODS. Immediate fact languages satisfiesFO (see above).NNF, d-NNF, s-NNF, f-NNF, BDD, OBDD< CNF. Direct fact x. (|x)(|x) holds fact fragments satisfies CD BC.OBDD. Direct fact one OBDD sentence considered transformationOBDD< satisfies SFO.d-DNNF, sd-DNNF FBDD. Let 1 2 two FBDD formulas. Let x variableincluded Vars(1 ) Vars(2 ). formula = (x 1 ) (x 2 ) FBDD258fiA Knowledge Compilation Mapformula since decomposability decision preserved construction. Since x.equivalent 1 2 , FBDD would satisfy SFO, would satisfy BC well,case unless P = NP (see below). conclusion drawnd-DNNF. Hence, FBDD d-DNNF satisfy SFO unless P = NP. Since every d-DNNFformula turned polynomial time equivalent sd-DNNF formula, obtainsd-DNNF satisfy SFO unless P = NP.IP. Let us show number prime implicants x. exponentially greaternumber prime implicants . Let 0 following DNF formula:0 =k __(pi qi,j )i=1 j=1k^pi .i=10 (m + 1)k + mk primes implicants (Chandra & Markowsky, 1978). Now, letformula:=k __(x pi qi,j ) (xi=1 j=1k^pi ).i=1Since 0 obtained removing every term every occurrence xx, 0 equivalent {x}. (see (Lang et al., 2000)). Now, mk + 1prime implicants; indeed, every term prime implicant, converse holdssince every term maximal w.r.t. logical entailment every consensus two termsinconsistent. completes proof.C.NNF, s-NNF, d-NNF, CNF. property trivially satisfied languages since determinism smoothness concerned or-nodes. Hence, 1 , . . . , n belongone languages, 1 . . . n .BDD. wellknown conjunction two BDDs easily computedconnecting 1-sink root (see proof Lemma A.8). sizeresulting BDD sum sizes respective BDDs . Accordingly,repeat operation n times time polynomial input size.f-NNF. Direct fact f-NNF satisfy BC.FBDD, OBDD, OBDD< , DNF, PI IP. straightforward convert clauseequivalent formula languages polynomial time. proof Proposition 3.1, show specific CNF formulas cannot turned equivalent FBDD(resp. OBDD, OBDD< , DNF, PI IP) formulas polynomial space (see Tables 9 10).Hence, conversion cannot accomplished polynomial time either. impliesnone FBDD, OBDD, OBDD< , DNF, PI IP satisfies C.DNNF, d-DNNF sd-DNNF. Direct fact none languages satisfyBC unlessP = NP.VnMODS. Let = i=1 , = (xi,1 xi,2 ), 1..n. 3 modelsVars(i ). Since 3n models, MODS representation size polynomialinput size.BC.259fiDarwiche & MarquisNNF, s-NNF, d-NNF, BDD CNF. Immediate since languages satisfy C (seeabove).DNNF, d-DNNF, sd-DNNF, FBDD OBDD. Checking whether conjunction two OBDD<formulas 1 2 (w.r.t. two different variable orderings <) consistent NP-complete(see Lemma 8.14 (Meinel & Theobald, 1998)). Since OBDD satisfies CO, cannot satisfyBC unless P = NP. Since OBDD FBDD d-DNNF DNNF, d-DNNF DNNF satisfyCO, none satisfy BC unless P = NP. Finally, since every d-DNNF formulaturned polynomial time equivalent smoothed d-DNNF formula sincesd-DNNF satisfies CO, cannot case sd-DNNF satisfy BC unless P = NP.OBDD< . Well-known fact (Bryant, 1986).Vn1Wn1f-NNF. Let 1 = i=0 (x2i x2i+1 ) CNF formula 2 = i=0 (x02i x02i+1 ) DNFformula. 1 2n essential prime implicants n essential prime implicates (seeproof Proposition 3.1, Table 9). duality, 2 n essential prime implicants 2nessential prime implicates. Now, 1 2 two f-NNF formulas. Lemma A.13,know every f-NNF formula turned polynomial time CNF formulaDNF formula. f-NNF would satisfy BC, f-NNF formula s.t. 1 2 couldcomputed time polynomial input size. Hence, either CNF formula equivalent1 2 DNF formula equivalent 1 2 could computed polytime.impossible since 1 2 n + 2n essential prime implicates n 2n essentialprime implicants. Hence every CNF (resp. DNF ) formula equivalent 1 2 sizeexponential |1 | + |2 |.Note case two f-NNF formulas 1 2 considerationturned polynomial time either two CNF formulas two DNF formulas,f-NNF formula equivalent 1 2 computed time polynomial inputsize (this obvious two CNF formulas considered next item proofshows achieved two DNF formulas considered).DNF MODS. 1 2 sentences one languages L, constructsentence L equivalent 1 2 simply taking conjunctions oneterm 1 one term 2 , removing redundant literals resultingterms removing inconsistent terms result. disjunctionresulting terms sentence L equivalent 1 2 computedpolynomial time.Vk VmWkPI. Let 1 = i=1 pi 2 = i=1 j=1 (pi qi,j ). Sentence 1 one prime implicate2 k prime implicates. 1 2 (m + 1)k + k prime implicates(Chandra & Markowsky, 1978).IP. Let IP () set prime implicants . IP (1 2 ) = max({12 | 1 IP (1 ), 2 IP (2 )}, |=) (up logical equivalence). See e.g., (dual of) Proposition 40 (Marquis, 2000).260fiA Knowledge Compilation MapC.NNF, s-NNF, DNNF DNF. property trivially satisfied languages sincedecomposability concerned and-nodes, since every NNF formulaturned polynomial time equivalent smoothed NNF formula.d-NNF BDD. Direct consequence fact d-NNF BDD satisfies CC. Especially, well-known disjunction two BDDseasily computed connecting 0-sink root (see proofLemma A.8). size resulting BDD sum sizes respectiveBDDs . Accordingly, repeat operation n times time polynomialinput size.f-NNF. Since f-NNF satisfy C satisfies C, cannot satisfy C (dueDe Morgans laws).FBDD, OBDD, OBDD< , CNF, PI, IP MODS. straightforward convert termequivalent formula previous languages polynomial time.proof Proposition 3.1, show specific DNF formulas cannot turnedequivalent FBDD (resp. OBDD, OBDD< , CNF , PI, IP MODS) formulas polynomial space(see Tables 9, 10 15). Hence, conversion cannot accomplished polynomialtime either. implies none FBDD, OBDD, OBDD< , CNF, PI, IP MODS satisfiesC.d-DNNF sd-DNNF. Immediate form fact none classes satisfies BCunless P = NP (see below).BC.NNF, d-NNF, DNNF, s-NNF, BDD DNF. Immediate since languages satisfiesC.OBDD< . Well-known fact (Bryant, 1986).OBDD, FBDD, d-DNNF sd-DNNF. Checking whether conjunction two OBDD< formulas 1 2 (w.r.t. two different variable orderings <) consistent NP-complete (seeLemma 8.14 (Meinel & Theobald, 1998)). Now, 1 2 inconsistent iff 1 2valid. Since OBDD satisfies C, OBDD formula equivalent 1 (resp. 2 )computed time polynomial |1 | (resp. |2 |). Since OBDD FBDD d-DNNF,resulting formulas also FBDD d-DNNF formulas. OBDD (resp. FBDD, d-DNNF)would satisfy BC, OBDD (resp. FBDD, d-DNNF) formula equivalent 1 2could computed time polynomial |1 | + |2 |. since d-DNNF satisfies VA,impossible unless P = NP. Finally, since every d-DNNF formula turnedpolynomial time equivalent sd-DNNF formula, sd-DNNF cannot satisfy BC unlessP = NP.f-NNF. Since f-NNF satisfy BC satisfies C, cannot satisfy BC (dueDe Morgans laws).CNF. 1 2 two CNF sentences, construct CNF sentenceequivalent 1 2 simply taking disjunctions one clause 1one clause 2 , removing redundant literals inside resulting clausesremoving valid clause result. conjunction resulting clausesCNF sentence equivalent 1 2 , computed polynomial time.PI. Let PI () set prime implicates sentence . PI (1 2 ) =min({1 2 | 1 PI (1 ), 2 PI (2 )}, |=). See Proposition 40 (Marquis, 2000).261fiDarwiche & MarquisVkWk WmIP. Let 1 = i=1 pi 2 = i=1 j=1 (pi qi,j ). Sentence 1 one prime implicant2 k prime implicants. 1 2 (m + 1)k + k prime implicants(Chandra & Markowsky, 1978).VnMODS. Let 1 = i=1 xi 2 = y. Sentence 1 1 model Vars(1 ) 21 model Vars(2 ). 1 2 2n + 1 models Vars(1 ) Vars(2 ).C.NNF, s-NNF, f-NNF, BDD, FBDD, OBDD OBDD< . property obviously satisfiedNNF. s-NNF also satisfies C since every NNF formula turned polynomial timeequivalent s-NNF formula. f-NNF satisfies C since applying De Morgans lawsf-NNF formula results f-NNF formula. Finally, forms BDDs,sufficient switch labels sinks achieve negation (Bryant, 1986).CNF. negation DNF formula CNF formula computedpolynomial time, CNF would satisfy C, would possible turn DNFformula equivalent CNF formula polynomial time (by involution negation).know possible polynomial space since CNF 6 DNF(see proofProposition 3.1). Hence, CNF satisfy C.DNF. Dual proof (just replace CNF DNF vice-versa).Vn1PI. formula n = i=0 (x2i x2i+1 ) prime implicates form (see proofProposition 3.1, Table 9). formula exponentially many prime implicants,negations prime implicates n . Since n exponentially manyprime implicates, cannot case PI satisfies C.IP. take dual proof (prime implicates case). formulaWn1n = i=0 (x2i x2i+1 ) prime implicants form. formula exponentially manyprime implicates, negations prime implicants n . Since nexponentially many prime implicants, cannot case IP satisfies C.DNNF. negation CNF formula computed polynomial time DNFformula, hence DNNF formula. DNNF would satisfy C, would possibleturn CNF formula equivalent DNNF one (by involution negation).DNNF satisfies CO, would P = NP.d-NNF. Following procedure negating d-NNF sentence :9Traverse nodes DAG , visiting children node visitnode itself. visiting node, construct negation follows:true negation false.false negation true.(N10 , . . . , Nk0 ) negation (N1 , . . . , Nk ). Here, Ni0 node representingnegation Ni .((N10 , M1 ), . . . , (Nk0 , Mk )) negation (N1 , . . . , Nk ). Here, Ni0node representing negation Ni , Mi node representing conjunction N1 . . . Ni1 .Return negation root d-NNF .implement four steps visit node k children,construct O(k) nodes O(k) edges.10 Hence, procedure complexity9. Mark Hopkins pointed us procedure.10. assume or-node (resp. and-node) less two children removed replaced uniquechild f alse (resp. true) children. simplification process equivalence-preservingachieved time linear size input DAG.262fiA Knowledge Compilation Maplinear size original d-NNF. easy check result equivalentnegation given d-NNF sentence also d-NNF.sd-DNNF d-DNNF. Unknown.VnSnMODS. = Si=1 xi one model i=1 {xi } negation 2n 1nmodels i=1 {xi }. Hence MODS cannot satisfy C. 2ReferencesA. Cimmati, E. Giunchiglia, F. G., & Traverso, P. (1997). Planning via model checking: decisionprocedure AR. Proceedings 4th European Conference Planning (ECP97), pp.130142.Blum, M., Chandra, A. K., & Wegman, M. N. (1980). Equivalence free Boolean graphsdecided probabilistically polynomial time. Information Processing Letters, 10 (2), 8082.Boole, G. (1854). investigation laws thought. Walton Maberley, London.Boufkhad, Y., Gregoire, E., Marquis, P., Mazure, B., & Sas, L. (1997). Tractable cover compilations.Proc. 15th International Joint Conference Artificial Intelligence (IJCAI97), pp.122127, Nagoya.Bryant, R. E. (1986). Graph-based algorithms Boolean function manipulation. IEEE Transactions Computers, C-35, 677691.Bryant, R. E. (1992). Symbolic Boolean manipulation ordered binary decision diagrams. ACMComputing Surveys, 24 (3), 293318.Cadoli, M., & Donini, F. (1997). survey knowledge compilation. AI Communications, 10,137150. (printed 1998).Cadoli, M., Donini, F., Liberatore, P., & Schaerf, M. (1996). Comparing space efficiency propositional knowledge representation formalisms. Proc. 5rd International ConferenceKnowledge Representation Reasoning (KR96), pp. 364373.Chandra, A., & Markowsky, G. (1978). number prime implicants. Discrete Mathematics,24, 711.Darwiche, A. (1999). Compiling knowledge decomposable negation normal form. ProceedingsInternational Joint Conference Artificial Intelligence (IJCAI99), pp. 284289. MorganKaufmann, California.Darwiche, A. (2001a). Decomposable negation normal form. Journal ACM, 48 (4), 608647.Darwiche, A. (2001b). tractability counting theory models application beliefrevision truth maintenance. Journal Applied Non-Classical Logics, 11 (1-2), 1134.Darwiche, A., & Huang, J. (2002). Testing equivalence probabilistically. Tech. rep. D123, ComputerScience Department, UCLA, Los Angeles, Ca 90095.de Kleer, J. (1992). improved incremental algorithm generating prime implicates. Proc.10th National Conference Artificial Intelligence (AAAI92), pp. 780785, San Jose,California.Dechter, R., & Rish, I. (1994). Directional resolution: Davis-Putnam procedure, revisited.Proceedings Fourth International Conference Principles Knowledge RepresentationReasoning (KR94), pp. 134145, Bonn.del Val, A. (1994). Tractable databases: make propositional unit resolution completecompilation. Proceedings International Conference Principles Knowledge Representation Reasoning (KR94), pp. 551561. Morgan Kaufmann Publishers, Inc., SanMateo, California.263fiDarwiche & MarquisGergov, J., & Meinel, C. (1994a). Efficient analysis manipulation obdds extendedfbdds. IEEE Transactions Computers, 43 (10), 11971209.Gergov, J., & Meinel, C. (1994b). complexity analysis manipulation Booleanfunctions terms decision diagrams. Information Processing Letters, 50, 317322.Gogic, G., Kautz, H., Papadimitriou, C., & Selman, B. (1995). comparative linguisticsknowledge representation. Proc. 14th International Joint Conference ArtificialIntelligence (IJCAI95), pp. 862869, Montreal.Herzig, A., & Rifi, O. (1999). Propositional belief base update minimal change. ArtificialIntelligence, 115 (1), 107138.Karp, R., & Lipton, R. (1980). connections non-uniform uniform complexityclasses. Proc. 12th ACM Symposium Theory Computing (STOC80), pp. 302309.Khardon, R., & Roth, D. (1997). Learning reason. Journal ACM, 44 (5), 697725.Lang, J., Liberatore, P., & Marquis, P. (2000). Propositional independencePart I: formulavariableindependence forgetting. Submitted.Madre, J. C., & Coudert, O. (1992). new method compute prime essential prime implicantsboolean functions. Advanced research VLSI parallel systems, ProceedingsBrown/MIT conference, pp. 113128.Marquis, P. (2000). Consequence finding algorithms, Vol. 5 Handbook Defeasible ReasoningUncertainty Management Systems: Algorithms Uncertain Defeasible Reasoning.Kluwer Academic Publishers.Marquis, P. (1995). Knowledge compilation using theory prime implicates. Proc. InternationalJoint Conference Artificial Intelligence (IJCAI95), pp. 837843. Morgan Kaufmann Publishers, Inc., San Mateo, California.Meinel, C., & Theobald, T. (1998). Algorithms Data Structures VLSI Design: OBDD Foundations Applications. Springer.Papadimitriou, C. (1994). Computational complexity. AddisonWesley.Quine, W. (1955). way simplify truth functions. American Mathematical Monthly, 52, 627631.Quine, W. (1959). cores prime implicants truth functions. American MathematicalMonthly, 66, 755760.Reiter, R., & de Kleer, J. (1987). Foundations assumption-based truth maintenance systems:Preliminary report. Proceedings Fifth National Conference Artificial Intelligence(AAAI), pp. 183188.Roth, D. (1996). hardness approximate reasoning. Artificial Intelligence, 82 (1-2), 273302.Schrag, R. (1996). Compilation critically constrained knowledge bases. Proc. 13thNational Conference Artificial Intelligence (AAAI96), pp. 510515, Portland, Oregan.Selman, B., & Kautz, H. (1996). Knowledge compilation theory approximation. JournalAssociation Computing Machinery, 43, 193224.Simon, L., & del Val, A. (2001). Efficient consequence finding. Proc. 17th InternationalJoint Conference Artificial Intelligence (IJCAI01), pp. 359365, Seattle (WA).Wegener, I. (1987). complexity boolean functions. Wiley-Teubner, Stuttgart.264fiJournal Artificial Intelligence Research 17 (2002) 379-449Submitted 4/02; published 12/02Specific-to-General Learning Temporal EventsApplication Learning Event Definitions VideoAlan FernRobert GivanJeffrey Mark SiskindAFERN @ PURDUE . EDUGIVAN @ PURDUE . EDUQOBI @ PURDUE . EDUSchool Electrical Computer EngineeringPurdue University, West Lafayette, 47907 USAAbstractdevelop, analyze, evaluate novel, supervised, specific-to-general learner simple temporal logic use resulting algorithm learn visual event definitions videosequences. First, introduce simple, propositional, temporal, event-description language calledAMA sufficiently expressive represent many events yet sufficiently restrictive supportlearning. give algorithms, along lower upper complexity bounds, subsumption generalization problems AMA formulas. present positive-examplesonlyspecific-to-general learning method based algorithms. also present polynomialtimecomputable syntactic subsumption test implies semantic subsumption withoutequivalent it. generalization algorithm based syntactic subsumption used placesemantic generalization improve asymptotic complexity resulting learning algorithm.Finally, apply algorithm task learning relational event definitions videoshow yields definitions competitive hand-coded ones.1. IntroductionHumans conceptualize world terms objects events. reflected facttalk world using nouns verbs. perceive events taking place objects,interact world performing events objects, reason effectsactual hypothetical events performed us others objects. also learn newobject event types novel experience. paper, present evaluate novel implemented techniques allow computer learn new event types examples. show resultsapplication techniques learning new event types automatically constructedrelational, force-dynamic descriptions video sequences.wish acquired knowledge event types support multiple modalities. Humansobserve someone faxing letter first time quickly able recognize future occurrencesfaxing, perform faxing, reason faxing. thus appears likely humans uselearn event representations sufficiently general support fast efficient use multiplemodalities. long-term goal research allow similar cross-modal learning useevent representations. intend learned representations used vision (as describedpaper), planning (something beginning investigate), robotics (somethingleft future).crucial requirement event representations capture invariants eventtype. Humans classify picking cup table picking dumbbell floorpicking up. suggests human event representations relational. abstractc 2002 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiF ERN , G IVAN , & ISKINDrelational notion picking parameterized participant objects rather distinctpropositional notions instantiated specific objects. Humans also classify event pickingmatter whether hand moving slowly quickly, horizontally vertically, leftwardrightward, along straight path circuitous one. appears characteristicsparticipant-object motion distinguish picking event types. Rather, factobject picked changes supported resting initial locationsupported grasped agent. suggests primitive relations usedbuild event representations force dynamic (Talmy, 1988).Another desirable property event representations perspicuous. Humansintrospect describe defining characteristics event types. introspection allows us create dictionaries. support introspection, prefer representation languageallows characteristics explicitly manifest event definitions emergent consequences distributed parameters neural networks hidden Markov models.develop supervised learner event representation possessing desired characteristics follows. First, present simple, propositional, temporal logic called AMAsublanguage variety familiar temporal languages (e.g. linear temporal logic, LTL Bacchus & Kabanza, 2000, event logic Siskind, 2001). logic expressive enough describevariety interesting temporal events, restrictive enough support effective learner,demonstrate below. proceed develop specific-to-general learner AMA logic giving algorithms complexity bounds subsumption generalization problems involvingAMA formulas. show semantic subsumption intractable, provide weaker syntactic notion subsumption implies semantic subsumption checked polynomialtime. implemented learner based upon syntactic subsumption.next show means adapt (propositional) AMA learner learn relational concepts.evaluate resulting relational learner complete system learning force-dynamic eventdefinitions positive-only training examples given real video sequences. firstsystem perform visual-event recognition video. review prior work comparecurrent work later paper. fact, two prior systems built oneauthors. H OWARD (Siskind & Morris, 1996) learns classify events video using temporal,relational representations. representations force dynamic. L EONARD (Siskind,2001) classifies events video using temporal, relational, force-dynamic representationslearn representations. uses library hand-code representations. work addslearning component L EONARD , essentially duplicating performance hand-codeddefinitions automatically.demonstrated utility learner visual-eventlearning domain,note many domains interesting concepts take form structured temporal sequences events. machine planning, macro-actions represent useful temporal patternsaction. computer security, typical application behavior, represented perhaps temporal patterns system calls, must differentiated compromised application behavior (and likewiseauthorized-user behavior intrusive behavior).follows, Section 2 introduces application domain recognizing visual eventsprovides informal description system learning event definitions video. Section 3introduces AMA language, syntax semantics, several concepts needed analysislanguage. Section 4 develops analyzes algorithms subsumption generalizationproblems language, introduces practical notion syntactic subsumption. Sec380fiL EARNING EMPORAL E VENTStion 5 extends basic propositional learner handle relational data negation, controlexponential run-time growth. Section 6 presents results visual-event learning. Sections 78 compare related work conclude.2. System Overviewsection provides overview system learning recognize visual events video.aim provide intuitive picture system providing technical details. formalpresentation event-description language, algorithms, theoretical empirical results appears Sections 36. first introduce application domain visual-event recognitionL EONARD system, event recognizer upon learner built. Second, describepositive-only learner fits overall system. Third, informally introduce AMAevent-description language used learner. Finally, give informal presentationlearning algorithm.2.1 Recognizing Visual EventsL EONARD (Siskind, 2001) system recognizing visual events video camera inputexample simple visual event hand picking block. research originallymotivated problem adding learning component L EONARDallowing L EONARDlearn recognize event viewing example events type. Below, give high-leveldescription L EONARD system.L EONARD three-stage pipeline depicted Figure 1. raw input consists video-frameimage sequence depicting events. First, segmentation-and-tracking component transformsinput polygon movie: sequence frames, frame set convex polygons placedaround tracked objects video. Figure 2a shows partial video sequence pick eventoverlaid corresponding polygon movie. Next, model-reconstruction componenttransforms polygon movie force-dynamic model. model describes changingsupport, contact, attachment relations tracked objects time. Constructingmodel somewhat involved process described Siskind (2000). Figure 2b showsvisual depiction force-dynamic model corresponding pick event. Finally, eventrecognition component armed library event definitions determines events occurredmodel and, accordingly, video. Figure 2c shows text output inputevent-recognizer pick event. first line corresponds output indicatesinterval(s) pick occurred. remaining lines text encodingevent-recognizer input (model-reconstruction output), indicating time intervals variousforce-dynamic relations true video.event-recognition component L EONARD represents event types event-logic formulas like following simplified example, representing x picking z .4P ICK U P (x; y; z ) = (S UPPORTS (z; ) ^ C ONTACTS (z; )); (S UPPORTS (x; ) ^ ATTACHED (x; ))formula asserts event x picking z defined sequence two statesz supports way contact first state x supports way attachmentsecond state. UPPORTS , C ONTACTS , ATTACHED primitive force-dynamic relations.formula specific example general class AMA formulas uselearning.381fiF ERN , G IVAN , & ISKINDimagesequenceSegmentationTrackingpolygonscenesequenceModelReconstructiontrainingmodelseventlabelsmodelsequenceEventLearnerEventClassificationeventlabelslearned eventdefinitionsFigure 1: upper boxes represent three primary components L EONARDs pipeline.lower box depicts event-learning component described paper. inputlearning component consists training models target events (e.g., movies pickevents) along event labels (e.g., P ICK U P (hand; red; green)) outputevent definition (e.g., temporal logic formula defining P ICK U P (x; y; z )).2.2 Adding Learning ComponentPrior work reported paper, definitions L EONARD event-recognition libraryhand coded. Here, add learning component L EONARD learn recognizeevents. Figure 1 shows event learner fits overall system. input eventlearner consists force-dynamic models model-reconstruction stage, along eventlabels, output consists event definitions used event recognizer. takesupervised-learning approach force-dynamic model-reconstruction process appliedtraining videos target event type. resulting force-dynamic models along labelsindicating target event type given learner induces candidate definitionevent type.example, input learner might consist two models corresponding two videos,one hand picking red block green block label P ICK U P (hand; red; green)one hand picking green block red block label P ICK U P (hand; green; red)theoutput would candidate definition P ICK U P (x; y; z ) applicable previously unseenpick events. Note learning component positive-only sense learningtarget event type uses positive training examples (where target event occurs)use negative examples (where target event occur). positive-only settinginterest appears humans able learn many event definitions given primarilypositive examples. practical standpoint, positive-only learner removes often difficulttask collecting negative examples representative event learned(e.g., typical non-pickup event?).construction learner involves two primary design choices. First, must chooseevent representation language serve learners hypothesis space (i.e., space event definitions may output). Second, must design algorithm selecting good event definitionhypothesis space given set training examples event type.2.3 AMA Hypothesis Spacefull event logic supported L EONARD quite expressive, allowing specificationwide variety temporal patterns (formulas). help support successful learning, use382fiL EARNING EMPORAL E VENTS(a)Frame 0Frame 1Frame 2Frame 13Frame 14Frame 20Frame 0Frame 1Frame 2Frame 13Frame 14Frame 20(b)(PICK-UP HAND RED GREEN)@{[[0,1],[14,22])}(c)(SUPPORTED? RED)@{[[0:22])}(SUPPORTED? HAND)@{[[1:13]), [[24:26])}(SUPPORTS? RED HAND)@{[[1:13]), [[24:26])}(SUPPORTS? HAND RED)@{[[13:22])}(SUPPORTS? GREEN RED)@{[[0:14])}(SUPPORTS? GREEN HAND)@{[[1:13])}(CONTACTS? RED GREEN)@{[[0:2]), [[6:14])}(ATTACHED? RED HAND)@{[[1:26])}(ATTACHED? RED GREEN)@{[[1:6])}Figure 2: L EONARD recognizes pick event. (a) Frames raw video input automatically generated polygon movie overlaid. (b) frames visual depictionautomatically generated force-dynamic properties. (c) text input/outputevent classifier corresponding depicted movie. top line outputremaining lines make input encodes changing force-dynamic properties.GREEN represents block table RED represents block picked up.383fiF ERN , G IVAN , & ISKINDrestrictive subset event logic, called AMA, learners hypothesis space. subset excludesmany practically useless formulas may confuse learner, still retaining substantialexpressiveness, thus allowing us represent learn many useful event types. restrictionAMA formulas form syntactic learning bias.basic AMA formulas called states express constant properties time intervals arbitrary duration. example, UPPORTS (z; ) ^ C ONTACTS (z; ) state tells usz must support contact . general, state conjunction numberprimitive propositions (in case force-dynamic relations). Using AMA also describesequences states. example, (S UPPORTS (z; ) ^ C ONTACTS (z; )) ; (S UPPORTS (x; ) ^ATTACHED (x; )) sequence two states, first state given secondstate indicating x must support attached . formula true whenever firststate true time interval, followed immediately second state truetime interval meeting first time interval. sequences called timelines sinceMeets Ands. general, timelines contain number states. Finally,conjoin timelines get AMA formulas (Ands MAs). example, AMA formula[(S UPPORTS (z; y) ^ C ONTACTS (z; y)) ; (S UPPORTS (x; y) ^ ATTACHED (x; y))] ^[(S UPPORTS (u; v) ^ ATTACHED (u; v)) ; (S UPPORTS (w; v) ^ C ONTACTS (w; v))]defines event two timelines must true simultaneously time interval.Using AMA formulas represent events listing various property sequences (MA timelines),must occur parallel event unfolds. important note, however,transitions states different timelines AMA formula occur relation oneanother. example, AMA formula, transition two states firsttimeline occur before, after, exactly transition states second timeline.important assumption leveraged learner primitive propositions used construct states describe liquid properties (Shoham, 1987). purposes, say propertyliquid holds time-interval holds subintervals. force-dynamicproperties produced L EONARD liquide.g., hand UPPORTS block intervalclearly hand supports block subintervals. primitive propositionsliquid, properties described states (conjunctions primitives) also liquid. However, properties described AMA formulas not, general, liquid.2.4 Specific-to-General Learning Positive DataRecall examples wish classify learn force-dynamic models,thought (and derived from) movies depicting temporal events. Also recalllearner outputs definitions AMA hypothesis space. Given AMA formula, saycovers example model true model. particular target event type (suchP ICK U P ), ultimate goal learner output AMA formula covers examplemodel model depicts instance target event type. understandlearner, useful define generality relationship AMA formulas. say AMAformula 1 general (less specific) AMA formula 2 2 covers everyexample 1 covers (and possibly more).11. formal analysis, use two different notions generality (semantic syntactic). section,ignore distinctions. note, however, algorithm informally describe later section basedsyntactic notion generality.384fiL EARNING EMPORAL E VENTSlearning goal find AMA formula consistent set positiveonly training data, one result trivial solution returning formula coversexamples. Rather fix problem adding negative training examples (which ruletrivial solution), instead change learning goal finding least-generalformula covers positive examples.2 learning approach pursuedvariety different languages within machine-learning literature, including clausal first-orderlogic (Plotkin, 1971), definite clauses (Muggleton & Feng, 1992), description logic (Cohen &Hirsh, 1994). important choose appropriate hypothesis space bias learningapproach hypothesis returned may simply (or resemble) one two extremes, eitherdisjunction training examples universal hypothesis covers examples.experiments, found that, enough training data, least-general AMA formula oftenconverges usefully.take standard specific-to-general machine-learning approach finding least-generalAMA formula covers set positive examples. approach relies computation twofunctions: least-general covering formula (LGCF) example model least-generalgeneralization (LGG) set AMA formulas. LGCF example model least generalAMA formula covers example. Intuitively, LGCF AMA formula capturesinformation model. LGG set AMA formulas least-general AMAformula general formula set. Intuitively, LGG formula setAMA formula captures largest amount common information among formulas.Viewed differently, LGG formula set covers examples covered formulas,covers examples possible (while remaining AMA).3resulting specific-to-general learning approach proceeds follows. First, use LGCFfunction transform positive training model AMA formula. Second, return LGGresulting formulas. result represents least-general AMA formula coverspositive training examples. Thus, specify learner, remains provide algorithms computing LGCF LGG AMA language. informally describealgorithms computing functions, formally derived analyzed Sections 3.4 4.2.5 Computing AMA LGCFincrease readability presentation, follows, dispense presenting examples primitive properties meaningfully named force-dynamic relations. Rather,examples utilize abstract propositions b. current application, propositions correspond exclusively force-dynamic properties, may applications.demonstrate system computes LGCF example model.Consider following example model: fa@[1; 4]; b@[3; 6]; c@[6; 6]; d@[1; 3]; d@[5; 6]g . Here,take number (1, . . . , 6) represent time interval arbitrary (possibly varyingnumber) duration nothing changes, fact p@[i; j ] indicates proposition p continuously true throughout time intervals numbered j . modeldepicted graphically, shown Figure 3. top four lines figure indicate time2. avoids need negative examples corresponds finding specific boundary version space(Mitchell, 1982).3. existence uniqueness LGCF LGG defined formal property hypothesis spaceproven AMA Sections 3.4 4, respectively.385fiF ERN , G IVAN , & ISKIND1234bb56bbca^d; a^b^d ; a^b ; b^d ; b^c^dFigure 3: LGCF Computation. top four horizontal lines figure indicate intervals propositions a; b; c true model givenfa@[1; 4]; b@[3; 6]; c@[6; 6]; d@[1; 3]; d@[5; 6]g . bottom line shows modeldivided intervals transitions occur. LGCF timeline,shown bottom figure, state no-transition intervals.state simply contains true propositions within corresponding interval.intervals propositions a; b; c, true model. bottom linefigure shows model divided five time intervals propositionschange truth value. division possible assumption propositionsliquid. allows us, example, break time-interval true three consecutive subintervals true. dividing model intervals transitions,compute LGCF simply treating intervals state timeline,states contain propositions true corresponding time interval.resulting five-state timeline shown bottom figure. show later simplecomputation returns LGCF model. Thus, see LGCF model alwaystimeline.2.6 Computing AMA LGGdescribe algorithm computing LGG two AMA formulasthe LGGformulas computed via sequence 1 pairwise LGG applications, discussed later.Consider two timelines: 1 = (a ^ b ^ c); (b ^ c ^ d); e 2 = (a ^ b ^ e); a; (e ^ d).useful consider various ways timelines true simultaneously alongarbitrary time interval. this, look various ways two timelinesaligned along time interval. Figure 4a shows one many possible alignmentstimelines. call alignments interdigitationsin general, exponentially manyinterdigitations, one ordering state transitions differently. Note interdigitationallowed constrain two transitions different timelines occur simultaneously (thoughdepicted figure).44. Thus, interdigitation provides ordering relation transitions need anti-symmetric, reflexive,transitive, total.386fiL EARNING EMPORAL E VENTS(a)a^b^e(b)a^b^cb^c^de^dea^b^c a^b^c a^b^c b^c^da^b^ea^b ;e^de^d; true ;ee^d;eFigure 4: Generalizing timelines (a ^ b ^ c); (b ^ c ^ d); e (a ^ b ^ e); a; (e ^ d). (a)One exponentially many interdigitations two timelines. (b) Computinginterdigitation generalization corresponding interdigitation part (a). Statesformed intersecting aligned states two timelines. state true representsstate propositions.Given interdigitation two timelines, easy construct new timeline musttrue whenever either timelines true (i.e., construct generalization two timelines).Figure 4b, give construction interdigitation given Figure 4a. top twohorizontal lines figure correspond interdigitation, divided every stateeither timeline two identical states, whenever transition occurs statetimeline. resulting pair timelines simultaneous transitions viewedsequence state pairs, one timeline. bottom horizontal line labeledtimeline one state state pair, state intersectionproposition sets state pair. Here, true represents empty set propositions, statetrue anywhere.call resulting timeline interdigitation generalization (IG) 1 2 .clear IG true whenever either 1 2 true. particular, 1 holds alongtime-interval model, sequence consecutive (meeting) subintervalssequence states 1 true. construction, IG aligned relative 1 alonginterval view states sets, states IG subsets correspondingaligned state(s) 1 . Thus, IG states true model alignment, showingIG true model.general, exponentially many IGs two input timelines, one possibleinterdigitation two. Clearly, since IG generalization input timelines,conjunction IGs. conjunction AMA formula generalizesinput timelines. fact, show later paper AMA formula LGGtwo timelines. show conjunction IGs 1 2 servesLGG.387fiF ERN , G IVAN , & ISKIND[(a ^ b); b; e; true; e] ^[(a ^ b); b; true; e] ^[(a ^ b); b; true; true; e] ^[(a ^ b); b; true; e] ^[(a ^ b); b; true; d; e] ^[(a ^ b); true; true; e] ^[(a ^ b); true; e] ^[(a ^ b); true; d; e] ^[(a ^ b); a; true; true; e] ^[(a ^ b); a; true; e] ^[(a ^ b); a; true; d; e] ^[(a ^ b); a; d; e] ^[(a ^ b); a; true; d; e]formula LGG, contains redundant timelines pruned. First,clear different IGs result timelines, remove one copytimeline LGG. Second, note timeline 0 general timeline, ^ 0 equivalent thus, prune away timelines generalizationsothers. Later paper, show efficiently test whether one timeline generalanother. performing pruning steps, left first next lasttimelines formulathus, [(a ^ b); a; d; e] ^ [(a ^ b); b; e; true; e] LGG 12 .demonstrated compute LGG pairs timelines. useprocedure compute LGG pairs AMA formulas. Given two AMA formulas computeLGG simply conjoining LGGs pairs timelines (one AMA formula)i.e., formulam^n^LGG(i ; 0j )jLGG two AMA formulas 1 ^ ^ 01 ^ ^ 0n , 0jtimelines.informally described LGCF LGG operations needed carryspecific-to-general learning approach described above. follows, formally developoperations analyze theoretical properties corresponding problems, discussneeded extensions bring (exponential, propositional, negation-free) operationspractice.3. Representing Events AMApresent formal account AMA hypothesis space analytical developmentalgorithms needed specific-to-general learning AMA. Readers primarily interestedhigh-level view algorithms empirical evaluation may wish skip Sections 3 4instead proceed directly Sections 5 6, discuss several practical extensionsbasic learner present empirical evaluation.study subset interval-based logic called event logic (Siskind, 2001) utilizedL EONARD event recognition video sequences. logic interval-based explicitly rep388fiL EARNING EMPORAL E VENTSresenting possible interval relationships given originally Allen (1983) calculusinterval relations (e.g., overlaps, meets, during). Event-logic formulas allow definitionevent types specify static properties intervals directly dynamic propertieshierarchically relating sub-intervals using Allen relations. paper, formal syntaxsemantics full event logic needed Proposition 4 given Appendix A.restrict attention much simpler subset event logic call AMA, definedbelow. believe choice event logic rather first-order logic, well restrictionAMA fragment event logic, provide useful learning bias ruling large numberpractically useless concepts maintaining substantial expressive power. practical utilitybias demonstrated via empirical results visual-eventrecognition application.AMA also seen restriction LTL (Bacchus & Kabanza, 2000) conjunctionUntil, similar motivations. present syntax semantics AMA alongkey technical properties AMA used throughout paper.3.1 AMA Syntax Semanticsnatural describe temporal events specifying sequence properties must holdconsecutive time intervals. example, hand picking block might become blocksupported hand block supported hand. representsequences timelines5 , sequences conjunctive state restrictions. Intuitively,timeline given sequence propositional conjunctions, separated semicolons,taken represent set events temporally match sequence consecutive conjunctions.AMA formula conjunction number timelines, representing eventssimultaneously viewed satisfying conjoined timelines. Formally, syntaxAMA formulas given by,stateAMA::= true j prop j prop ^ state::= (state) j (state);// may omit parens::= j ^ AMAprop primitive proposition (sometimes called primitive event type). takegrammar formally define terms timeline, formula, AMA formula, state. k formula formula k states, k -AMA formula AMA formulawhose timelines k -MA timelines. often treat states proposition setstrue empty set AMA formulas MA-timeline sets. may also treat formulassets statesit important note, however, formulas may contain duplicate states,duplication significant. reason, treating timelines sets,formally intend sets state-index pairs (where index gives states position formula).indicate explicitly avoid encumbering notation, implicit index mustremembered whenever handling duplicate states.semantics AMA formulas defined terms temporal models. temporal model= hM; set PROP propositions pair mapping natural numbers(representing time) truth assignments PROP, closed natural-number interval .note Siskind (2001) gives continuous-time semantics event logic models5. stands Meets/And, timeline Meet sequence conjunctively restricted intervals.389fiF ERN , G IVAN , & ISKINDdefined terms real-valued time intervals. temporal models defined use discretenatural-number time-indices. However, results still apply continuous-time semantics. (That semantics bounds number state changes continuous timeline countable number.) important note natural numbers domain representingtime discretely, prescribed unit continuous time represented naturalnumber. Instead, number represents arbitrarily long period continuous timenothing changed. Similarly, states timelines represent arbitrarily long periods timeconjunctive restriction given state holds. satisfiability relation AMAformulas given follows:state satisfied model hM; iff [x] assigns P true every x 2 PAMA formula 1 ^ 2 ^ ^ n satisfied iff satisfied M.2 s.timeline s1 ; s2 ; : : : ; sn satisfied model hM; [t; t0 ]i iff exists t00[t; t0 ] hM; [t; t00 ]i satisfies s1 either hM; [t00 ; t0 ]i hM; [t00 + 1; t0 ]i satisfiess2 ; : : : ; sn .condition defining satisfaction timelines may appear unintuitive first duefact two ways s2 ; : : : ; sn satisfied. reason becomes clear recalling using natural numbers represent continuous time intervals. Intuitively,continuous-time perspective, timeline satisfied consecutive continuous-timeintervals satisfying sequence consecutive states timeline. transitionconsecutive states si si+1 occur either within interval constant truth assignment (thathappens satisfy states) exactly boundary two time intervals constant truthvalue. definition, cases correspond s2 ; : : : ; sn satisfied timeintervals [t00 ; t0 ] [t00 + 1; t0 ] respectively.satisfies say model covers M. say AMA 1subsumes AMA 2 iff every model 2 model 1 , written 2 1 , say 1properly subsumes 2 , written 2 < 1 , also 1 6 2 . Alternatively, may state2 1 saying 1 general (or less specific) 2 1 covers 2 . Siskind(2001) provides method determine whether given model satisfies given AMA formula.Finally, useful associate distinguished timeline model. projectionmodel = hM; [i; j ]i written MAP(M) timeline s0 ; s1 ; : : : ; sj state skgives true propositions (i + k ) 0 k j i. Intuitively, projection givessequence propositional truth assignments beginning end model. Latershow projection model viewed representing model precisesense.following two examples illustrate basic behaviors AMA formulas:Example 1 (Stretchability). S1 ; S2 ; S3 , S1 ; S2 ; S2 ; : : : ; S2 ; S3 , S1 ; S1 ; S1 ; S2 ; S3 ; S3 ; S3equivalent timelines. general, timelines property duplicating stateresults formula equivalent original formula. Recall that, given model hM; i,view truth assignment [x] representing continuous time-interval. intervalconceptually divided arbitrary number subintervals. Thus state satisfiedhM; [x; x]i, state sequence ; ; : : : ; .390fiL EARNING EMPORAL E VENTSExample 2 (Infinite Descending Chains). Given propositions B , timeline =subsumed formulas A; B , A; B ; A; B , A; B ; A; B ; A; B , . . . .intuitively clear semantics viewed continuous-time perspective. intervalB true broken arbitrary number subintervalsB hold. example illustrates infinite descending chains AMAformulas entire chain subsumes given formula (but member equivalent givenformula). general, AMA formula involving propositions B subsume .(A ^ B )3.2 Motivation AMAtimelines natural way capture stretchable sequences state constraints.consider conjunction sequences, i.e., AMA? several reasons language enrichment. First all, show AMA least-general generalization (LGG)uniquethis true MA. Second, informally, argue parallel conjunctive constraints important learning efficiency. particular, space formulaslength k grows size exponentially k , making difficult induce long formulas.However, finding several shorter timelines characterize part long sequencechanges exponentially easier. (At least, space search exponentially smaller.) AMAconjunction timelines places shorter constraints simultaneously often capturesgreat deal concept structure. reason, analyze AMA well and,empirical work, consider k -AMA.AMA language propositional. intended applications relational, first-order,including visual-event recognition. Later paper, show propositional AMA learning algorithms develop effectively applied relational domains. approachfirst-order learning distinctive automatically constructing object correspondence across examples (cf. Lavrac, Dzeroski, & Grobelnik, 1991; Roth & Yih, 2001). Similarly, though AMAallow negative state constraints, Section 5.4 discuss extend resultsincorporate negation learning algorithms, crucial visual-event recognition.3.3 Conversion First-Order Clausesnote AMA formulas translated various ways first-order clauses.straightforward, however, use existing clausal generalization techniques learning.particular, capture AMA semantics clauses, appears necessary define subsumptiongeneralization relative background theory restricts us continuous-time first-ordermodel space.example, consider AMA formulas 1 = ^ B 2 = A; B Bpropositionsfrom Example 2 know 1 2 . Now, consider straightforward clausaltranslation formulas giving C1 = A(I ) ^ B (I ) C2 = A(I1 ) ^ B (I2 ) ^ EETS (I1 ; I2 ) ^= PAN (I1 ; I2 ), Ij variables represent time intervals, EETS indicatestwo time intervals meet other, PAN function returns time interval equalunion two time-interval arguments. meaning intend capture satisfyingassignments C1 C2 indicate intervals 1 2 satisfied, respectively.clear that, contrary want, C1 6 C2 (i.e., 6j= C1 ! C2 ), since easyfind unintended first-order models satisfy C1 , C2 . Thus translation,similar translations, capture continuous-time nature AMA semantics.391fiF ERN , G IVAN , & ISKINDorder capture AMA semantics clausal setting, one might define first-order theoryrestricts us continuous-time modelsfor example, allowing derivation property Bholds interval, property also holds sub-intervals. Given theory ,j= C1 ! C2 , desired. However, well known least-general generalizations relative background theories need exist (Plotkin, 1971), prior work clausalgeneralization simply subsume results AMA language.note particular training set, may possible compile continuous-time background theory finite adequate set ground facts. Relative ground theories,clausal LGGs known always exist thus could used application. However,compiling approaches look promising us require exploiting analysis similar one given paperi.e., understanding AMA generalization subsumptionproblem separately clausal generalization exploiting understanding compilingbackground theory. pursued compilations further.Even given compilation procedure, problems using existing clausal generalization techniques learning AMA formulas. clausal translationsAMA found, resulting generalizations typically fall outside (clausal translationsformulas the) AMA language, language bias AMA lost. preliminary empirical work video-event recognition domain using clausal inductive-logic-programming (ILP)systems, found learner appeared lack necessary language bias find effectiveevent definitions. believe would possible find ways build language biasILP systems, chose instead define learn within desired language bias directly,defining class AMA formulas, studying generalization operation class.3.4 Basic Concepts Properties AMAuse following convention naming results: propositions theorems keyresults work, theorems results technical difficulty, lemmastechnical results needed later proofs propositions theorems. numberresults one sequence, regardless type. Proofs theorems propositions providedmain textomitted proofs lemmas provided appendix.give pseudo-code methods non-deterministic style. non-deterministic language functions return one value non-deterministically, either containnon-deterministic choice points, call non-deterministic functions. Since nondeterministic function return one possible value, depending choices madechoice points encountered, specifying function natural way specify richly structured set (if function arguments) relation (if function arguments). actuallyenumerate values set (or relation, arguments provided) one simply usestandard backtracking search different possible computations corresponding differentchoices choice points.3.4.1 UBSUMPTIONG ENERALIZATIONTATESbasic formulas deal states (conjunctions propositions). propositionalsetting computing subsumption generalization state level straightforward. state S1subsumes S2 (S2 S1 ) iff S1 subset S2 , viewing states sets propositions. this,derive intersection states least-general subsumer states unionstates likewise general subsumee.392fiL EARNING EMPORAL E VENTS3.4.2 NTERDIGITATIONSGiven set timelines, need consider different ways model could simultaneously satisfy timelines set. start model (i.e., first time point),initial state timeline must satisfied. time point model, onetimelines transition second state timelines must satisfied placeinitial state, initial state timelines remains satisfied. sequencetransitions subsets timelines, final state timeline holds. waychoosing transition sequence constitutes different interdigitation timelines.Viewed differently, model simultaneously satisfying timelines induces co-occurrencerelation tuples timeline states, one timeline, identifying tuples co-occurpoint model. represent concept formally set tuples co-occurring states,i.e., co-occurrence relation. sometimes think set tuples ordered sequencetransitions. Intuitively, tuples interdigitation represent maximal time intervalstimeline transition, tuples giving co-occurring statestime interval.relation R X1 Xn simultaneously consistent orderings 1 ,. . . ,n, if,whenever R(x1 ; : : : ; xn ) R(x01 ; : : : ; x0n ), either xi x0i , i, x0i xi , i. sayR piecewise total projection R onto component totali.e., every state Xiappears R.Definition 1 (Interdigitation). interdigitation set f1 ; : : : ; n g timelines cooccurrence relation 1 n (viewing timelines sets states6 ) piecewise totalsimultaneously consistent state orderings . say two states 2s0 2 j 6= j co-occur iff tuple contains s0 . sometimes refersequence tuples, meaning sequence lexicographically ordered state orderings.note exponentially many interdigitations even two timelines (relativetotal number states timelines). Example 3 page 396 shows interdigitation twotimelines. Pseudo-code non-deterministically generating arbitrary interdigitation settimelines found Figure 5. Given interdigitation timelines s1 ; s2 ; : : : ; smt1 ; t2 ; : : : ; tn (and possibly others), following basic properties interdigitations easilyverifiable:1. < j , si tk co-occur k 02.< k, sj co-occur tk0.(s1 ; t1 ) (sm ; tn ).first use interdigitations syntactically characterize subsumption timelines.Definition 2 (Witnessing Interdigitation). interdigitation two timelines 1 2witness 1 2 iff every pair co-occurring states s1 2 1 s2 2 2 ,s2 subset s1 (i.e., s1 s2 ).following lemma proposition establish equivalence witnessing interdigitationssubsumption.6. Recall, that, formally, timelines viewed sets state-index pairs, rather sets states. ignoredistinction notation, readability purposes, treating timelines though state duplicated.393fiF ERN , G IVAN , & ISKIND1:an-interdigitation (f1 ; 2 ; : : : ; n g)// Input: timelines 1 ; : : : ; n// Output: interdigitation f1 ; : : : ; n g2:3:S0 := hhead(1 ); : : : ; head(n )i;1 n; ji j = 1return hS0 i;0:= fi ji j > 1g;00 := a-non-empty-subset-of (T 0 );4:5:6:7:8::= 1 n2 000i := rest(i )else 0i := ;9:10:12:12:return extend-tuple (S0 ; an-interdigitation (f01 ; : : : ; 0n g));13:Figure 5: Pseudo-code an-interdigitation(), non-deterministically computes interdigitation set f1 ; : : : ; n g timelines. function head() returns firststate timeline . rest() returns first state removed. extend-tuple(x,I )extends tuple adding new first element x form longer tuple. a-non-emptysubset-of(S ) non-deterministically returns arbitrary non-empty subset .Lemma 1. timeline model M, satisfies , witnessinginterdigitation MAP(M) .Proposition 2. timelines 1 2 , 11 2 .2 iff interdigitation witnessesProof: show backward direction induction number states n timeline 1 .n = 1, existence witnessing interdigitation 1 2 implies every state 2subset single state 1 , thus model 1 model 2 1 2 .Now, suppose induction backward direction theorem holds whenever 1 nfewer states. Given arbitrary model n + 1 state 1 interdigitation Wwitnesses 1 2 , must show also model 2 conclude 1 2 desired.Write 1 s1 ; : : : ; sn+1 2 t1 ; : : : ; tm . witnessing interdigitation, W must identifymaximal prefix t1 ; : : : ; tm 2 made states co-occur s1 thussubsets s1 . Since = hM; [t; t0 ]i satisfies 1 , definition must exist t00 2 [t; t0 ]hM; [t; t00 ]i satisfies s1 (and thus t1 ; : : : ; tm ) hM; 0 satisfies s2 ; : : : ; sn+1 0 equaleither [t00 ; t0 ] [t00 + 1; t0 ]. either case, straightforward construct, W , witnessinginterdigitation s2 ; : : : ; sn+1 tm +1 ; : : : ; tm use induction hypothesis showhM; 0 must satisfy tm +1; : : : ; tm . follows satisfies 2 desired.forward direction, assume 1 2 , let model 1 =MAP(M). clear exists satisfies 1 . follows satisfies 2 .Lemma 1 implies witnessing interdigitation MAP(M) 2 thus1 2 . 20000394fiL EARNING EMPORAL E VENTS3.4.3 L EAST-G ENERAL C OVERING F ORMULAlogic discriminate two models contains formula satisfies one other.turns AMA formulas discriminate two models exactly much richer internal positive event logic (IPEL) formulas so. Internal formulas define event occurrenceterms properties within defining interval. is, satisfaction hM; dependsproposition truth values given inside interval . Positive formulascontain negation. Appendix gives full syntax semantics IPEL (which usedstate prove Lemma 3 ). fact AMA discriminate models well IPELindicates restriction AMA formulas retains substantial expressive power leadsfollowing result serves least-general covering formula (LGCF) componentspecific-to-general learning procedure. Formally, LGCF model within formula languageL (e.g. AMA IPEL) formula L covers covering formulaL strictly less general. Intuitively, LGCF model, unique, representativeformula model. analysis uses concept model embedding. say modelembeds model M0 iff MAP(M) MAP(M0 ).Lemma 3.E2 IP EL, model embeds model satisfies E , satisfies E .Proposition 4. projection model LGCF internal positive event logic (andhence AMA), semantic equivalence.Proof: Consider model M. know MAP(M) covers M, remains showMAP(M) least general formula so, semantic equivalence.Let E IPEL formula covers M. Let M0 model covered MAP(M)want show E also covers M0 . know, Lemma 1, witnessinginterdigitation MAP(M0 ) MAP(M). Thus, Proposition 2, MAP(M0 ) MAP(M)showing M0 embeds M. Combining facts Lemma 3 follows E also coversM0 hence MAP(M) E . 2Proposition 4 tells us that, IPEL, LGCF model exists, unique,timeline. Given property, AMA formula covers timelines coveredanother AMA formula 0 , 0 . Thus, remainder paper, consideringsubsumption formulas, abstract away temporal models deal insteadtimelines. Proposition 4 also tells us compute LGCF model constructingprojection model. Based definition projection, straightforwardderive LGCF algorithm runs time polynomial size model7 . noteprojection may contain repeated states. practice, remove repeated states, sincechange meaning resulting formula (as described Example 1).3.4.4 C OMBINING NTERDIGITATIONG ENERALIZATIONPECIALIZATIONInterdigitations useful analyzing conjunctions disjunctions timelines.conjoining set timelines, model conjunction induces interdigitation timelinesco-occurring states simultaneously hold model point (viewing statessets, states resulting unioning co-occurring states must hold). constructing7. take size model = hM; sum x 2 number true propositions (x).395fiF ERN , G IVAN , & ISKINDinterdigitation taking union tuple co-occurring states get sequence states,get timeline forces conjunction timelines hold. call sequenceinterdigitation specialization timelines. Dually, interdigitation generalization involvingintersections states gives timeline holds whenever disjunction set timelinesholds.Definition 3. interdigitation generalization (specialization) set timelinestimeline s1 ; : : : ; sm , that, interdigitation tuples, sj intersection(respectively, union) components jth tuple sequence . set interdigitationgeneralizations (respectively, specializations) called IG() (respectively, IS()).Example 3. Suppose s1 ; s2 ; s3 ; t1 ; t2 ; t3 sets propositions (i.e., states). Consider timelines = s1 ; s2 ; s3 = t1 ; t2 ; t3 . relationf hs1; t1 ; hs2; t1 ; hs3; t2 ; hs3; t3 ginterdigitation states s1 s2 co-occur t1 , s3 co-occurst2 t3 . corresponding IG memberss1 \ t1 ; s2 \ t1 ; s3 \ t2 ; s3 \ t3s1 [ t1 ; s2 [ t1 ; s3 [ t2 ; s3 [ t32 IG(fS; g)2 IS(fS; g):t1 s1 ; t1 s2 ; t2 s3 ; t3 s3 , interdigitation witnessesT.timeline IG() (dually, IS()) subsumes (is subsumed by) timelineeasily verified using Proposition 2. complexity analyses, note number statesmember IG() IS() bounded number statestimelines bounded total number states timelines. number interdigitations , thus members IG() IS(), exponential total number states. algorithms present later computing LGGsrequire computation IG () IS(). give pseudo-code computequantities. Figure 6 gives pseudo-code function an-IG-member non-deterministicallycomputes arbitrary member IG() (an-IS-member same, except replace intersection union). Given set timelines compute IG() executing possibledeterministic computation paths function call an-IG-member(), i.e., computing setresults obtainable non-deterministic function possible decisions non-deterministicchoice points.give useful lemma proposition concerning relationships conjunctions disjunctions concepts (the former AMA concepts). convenience here,use disjunction concepts, producing formulas outside AMA obvious interpretation.Lemma 5. Given formula subsumes member set formulas, alsosubsumes member 0 IG(). Dually, subsumed member ,also subsumed member 0 IS(). case, length 0 boundedsize .396fiL EARNING EMPORAL E VENTSan-IG-member (f1 ; 2 ; : : : ; n g)// Input: timelines 1 ; : : : ; n// Output: member IG(f1 ; 2 ; : : : ; n g)return map (intersect-tuple ; an-interdigitation (f1 ; : : : ; n g));Figure 6: Pseudo-code an-IG-member, non-deterministically computes memberIG(T ) set timelines. function intersect-tuple(I ) takes tuplesets argument returns intersection. higher-order function map(f; )takes function f tuple arguments returns tuple lengthobtained applying f element making tuple results.Proposition 6.following hold:1. (and-to-or) conjunction set timelines equals disjunction timelinesIS().2. (or-to-and) disjunction set timelines subsumed conjunctiontimelines IG().Proof: prove or-to-and, recall that, 2 0 2 IG(), 0 .WVimmediate ( ) ( IG()). Using dual argument, showWVVW( IS()) ( ). remains Vto show ( ) ( ISW()), equivalent showingtimeline subsumed ( ) also subsumed ( IS()) (by Proposition 4). ConsiderVtimeline ( )this implies member subsumes . LemmaW5 implies 0 2 IS() 0 . get ( IS())desired. 2Using and-to-or, reduce AMA subsumption subsumption, exponential increase problem size.Proposition 7.2 ; 1 2 .AMA12 , 12 1 2 IS( 1) 2 2Proof: forward direction show contrapositive. Assume 1 2 IS( 1 )2 2 2 W1 6 2 . Thus, timeline1 6 2 .Wtells us ( IS( 1 )) 6 2 , thus ( IS( 1 )) 6 2 and-to-or get1 6 2 .backward direction assume 1 2 IS( 1 ) 2 2 2 1 2 .Wtells us 1 2 IS( 1 ), 1 2 thus, 1 = ( IS( 1 )) 2 . 24. Subsumption Generalizationsection study subsumption generalization AMA formulas. First, givepolynomial-time algorithm deciding subsumption formulas showdeciding subsumption AMA formulas coNP-complete. Second give algorithms complexity bounds construction least-general generalization (LGG) formulas based397fiF ERN , G IVAN , & ISKINDMA-subsumes (1 ; 2 )// Input: 1 = s1 ; : : : ; sm 2// Output: 1 2= t1 ; : : : ; tn1. path v1;1 vm;n SG(1 ; 2 ) return TRUE. example,(a)(b)(c)Create array Reachable(i,j ) boolean values, FALSE, 00 j n.:= 1 m, Reachable(i; 0) := TRUE;j := 1 n, Reachable(0; j ) := TRUE;:= 1j := 1 nReachable(i; j ) := (ti sj ^ ( Reachable(iReachable(i; jReachable(iReachable(m; n) return TRUE;1; j ) _1) _1; j 1));2. Otherwise, return FALSE;Figure 7: Pseudo-code subsumption algorithm.defined main text.SG(1 ; 2 ) subsumption graphanalysis subsumption, including existence, uniqueness, lower/upper bounds, algorithmLGG AMA formulas. Third, introduce polynomial-timecomputable syntactic notionsubsumption algorithm computes corresponding syntactic LGG exponentially faster semantic LGG algorithm. Fourth, Section 4.4, give detailed exampleshowing steps performed LGG algorithms compute semantic syntactic LGGstwo AMA formulas.4.1 Subsumptionmethods rely critically novel algorithm deciding subsumption question 1 2formulas 1 2 polynomial-time. note merely searching possibleinterdigitations 1 2 witnessing interdigitation provides obvious decision proceduresubsumption questionhowever, are, general, exponentially many interdigitations. reduce subsumption problem finding path graph pairs states1 2 , polynomial-time operation. Pseudo-code resulting subsumption algorithm shown Figure 7. main data structure used subsumption algorithmsubsumption graph.Definition 4. subsumption graph two timelines 1 = s1 ; ; sm 2 = t1 ; ; tn(written SG(1 ; 2 )) directedgraph G = hV; E V = fvi;j j 1 m; 1 j ng .(directed) edge set E equals hvi;j ; vi ;j j si tj ; si tj ; i0 + 1; j j 0 j + 1 .0000achieve polynomial-time bound one simply use polynomial-time pathfinding algorithm. case special structure subsumption graph exploited determine398fiL EARNING EMPORAL E VENTSdesired path exists (mn) time, example method shown pseudo-code illustrates.following theorem asserts correctness algorithm assuming correct polynomial-timepath-finding method used.Lemma 8. Given timelines 1 = s1 ; : : : ; sm 2 = t1 ; : : : ; tn , witnessinginterdigitation 1 2 iff path subsumption graph SG(1 ; 2 ) v1;1vm;n .Theorem 9.mial time.Given timelines 1 2 , MA-subsumes(1 ; 2 ) decides 12 polyno-Proof: algorithm clearly runs polynomial time. Lemma 8 tells us line 2 algorithmreturn TRUE iff witnessing interdigitation. Combining Proposition 2 showsalgorithm returns TRUE iff 1 2 . 2Given polynomial-time algorithm subsumption, Proposition 7 immediately suggestsexponential-time algorithm deciding AMA subsumptionby computing subsumptionexponentially many timelines one formula timelines formula.next theorem suggests cannot better worst casewe argueAMA subsumption coNP-complete reduction boolean satisfiability. Readers uninterestedtechnical details argument may skip directly Section 4.2.develop correspondence boolean satisfiability problems, include negation,AMA formulas, lack negation, imagine boolean variable two AMApropositions, one true one false. particular, given boolean satisfiability problemn variables p1 ; : : : ; pn , take set PROPn set containing 2n AMA propositionsTruek Falsek k 1 n. represent truth assignment pivariables AMA state sA given follows:sA = fTruei j 1 n; A(pi ) = trueg [ fFalsei j 1 n; A(pi ) = falsegProposition 7 suggests, checking AMA subsumption critically involves exponentiallymany interdigitation specializations timelines one AMA formulas. proof,design AMA formula whose interdigitation specializations seen correspond truthassignments8 boolean variables, shown following lemma.Lemma 10.Given n, let conjunction timelinesn[i=1f(PROPn; Truei; Falsei; PROPn); (PROPn; Falsei; Truei; PROPn)g:following facts truth assignments Boolean variables p1 ; : : : ; pn :1. truth assignment A, PROPn ; sA ; PROPn semantically equivalent memberIS( ).2. 2 IS( ) truth assignment PROPn ; sA ; PROPn .8. truth assignment function mapping boolean variables true false.399fiF ERN , G IVAN , & ISKINDlemma hand, tackle complexity AMA subsumption.Theorem 11.Deciding AMA subsumption coNP-complete.Proof: first show deciding AMA-subsumption 1 2 coNP providingpolynomial-length certificate answer. certificate non-subsumptioninterdigitation timelines 1 yields member IS( 1 ) subsumed 2 .certificate checked polynomial time: given interdigitation, correspondingmember IS( 1 ) computed time polynomial size 1 , testwhether resulting timeline subsumed timeline 2 using polynomial-time MAsubsumption algorithm. Proposition 7 guarantees 1 6 2 iff timeline IS( 1 )subsumed every timeline 2 , certificate exist exactlyanswer subsumption query no.show coNP-hardness reduce problem deciding satisfiability 3-SAT formula= C1 ^ ^ Cm problem recognizing non-subsumption AMA formulas. Here,Ci (li;1 _ li;2 _ li;3 ) li;j either proposition p chosen P = fp1 ; : : : ; pn gnegation :p. idea reduction construct AMA formula viewexponentially many members IS( ) representing truth assignments. constructtimeline view representing :S show satisfiable iff 6 .Let defined Lemma 10. Let formula s1 ; : : : ; sm ,si =fFalsej j li;k = pj kg [fTruej j li;k = :pj kg:si thought asserting Ci . start showing satisfiable6 . Assume satisfied via truth assignment Awe know Lemma 100 2 IS( ) semantically equivalent PROPn ; sA ; PROPn . showPROPn ; sA ; PROPn subsumed , conclude 6 using Proposition 7, desired.Suppose contradiction PROPn ; sA ; PROPn subsumed state sA mustsubsumed state si . Consider corresponding clause Ci . Since satisfiesCi satisfied least one literals li;k must true. Assume li;k = pj (adual argument holds li;k = :pj ), si contains Falsej sA contains TruejFalsej thus, sA 6 si (since si 6 sA ), contradicting choice i.complete proof, assume unsatisfiable show . UsingProposition 7, consider arbitrary 0 IS( )we show 0 . Lemma 10know truth assignment 0 PROPn ; sA ; PROPn . Since unsatisfiableknow Ci satisfied hence :Ci satisfied A. impliesprimitive proposition si sA . Let W following interdigitation =PROPn ; sA ; PROPn = s1 ; : : : ; sm :fhPROPn; s1 hPROPn; s2 hPROPn; sii hsA; sii hPROPn; sii hPROPn; si+1i hPROPn; smigsee tuple co-occurring states given state subsumedstate . Thus W witnessing interdigitation PROPn ; sA ; PROPn ,holds Proposition 2combining 0 PROPn ; sA ; PROPn get 0 . 2Given hardness result later define weaker polynomial-timecomputable subsumptionnotion use learning algorithms.400fiL EARNING EMPORAL E VENTS4.2 Least-General Generalization.AMA LGG set AMA formulas AMA formula generalformula set strictly general formula. existenceAMA LGG nontrivial infinite chains increasingly specific formulasgeneralize given formulas. Example 2 demonstrated chains subsumeeextended AMA subsumees. example, member chain P ; Q, P ; Q; P ; Q,P ; Q; P ; Q; P ; Q; : : : covers 1 = (P ^ Q); Q 2 = P ; (P ^ Q). Despite complications,AMA LGG exist.Theorem 12. LGG finite set AMA formulas subsumedgeneralizations .Proof: Let set 2 IS( 0 ). Let conjunction timelinesgeneralize size larger . Since finite number primitivepropositions, finite number timelines, well defined9 . showleast-general generalization . First, note timeline generalizes thus(by Proposition 6), must generalize . Now, consider arbitrary generalization 0 .Proposition 7 implies 0 must generalize formula . Lemma 5 impliestimeline 0 must subsume timeline longer size also subsumestimelines . must timeline , choice , every timeline0 subsumes timeline . follows 0 subsumes , LGG subsumedLGGs , desired. 20Given AMA LGG exists unique show compute it. first stepstrengthen or-to-and Proposition 6 get LGG sublanguage.Theorem 13. set formulas, conjunction timelines IG() AMALGG .Proof: Let specified conjunction. Since timeline IG() subsumes timelines, subsumes member . show least-general formula, considerAMA formula 0 also subsumes members . Since timeline 0 must subsumemembers , Lemma 5 implies timeline 0 subsumes member IG() thustimeline 0 subsumes . implies 0 . 2characterize AMA LGG using IG.Theorem 14.IG( 2 IS( )) AMA LGG set AMA formulas.Proof: Let = f 1 ; : : : ; n g E = 1 _ _ n . know AMA LGGmust subsume E , would fail subsume one . Using and-to-or representWWE disjunction timelines given E = ( IS( 1 )) _ _ ( IS( n )). AMALGG must least-general formula subsumes E i.e., AMA LGG settimelines fIS( )j 2 g. Theorem 13 tells us LGG timelines givenIG( fIS( )j 2 g). 29. must least one timeline, timeline state true401fiF ERN , G IVAN , & ISKIND1:2:3:4:5:6:7:8:9:10:11:12:13:14:15:semantic-LGG(f 1 ; 2 ; : : : ; g)// Input: AMA formulas 1 ; : : : ;// Output: LGG f 1 ; : : : ; g:= fg;:= 1all-values(an-IS-member ( ))(80 2 : 6 0 )0 := f00 2 j 00 g;:= (S 0 ) [ fg;G := fg;all-values(an-IG-member(S ))(80 2 G : 0 6 )G0 := f00 2 G j 00 g;G := (G G0 ) [ fg;Vreturn (G)Figure 8: Pseudo-code computing semantic AMA LGG set AMA formulas.Theorem 14 leads directly algorithm computing AMA LGGFigure 8 givespseudo-code computation. Lines 4-9 pseudo-code correspond computationfIS( )j 2 g, timelines included set subsumed timelinesalready set (which checked polynomial time subsumption algorithm).pruning, accomplished test line 7, often drastically reduces size timeline set perform subsequent IG computationthe final result affectedpruning since subsequent IG computation generalization step. remainderpseudo-code corresponds computation IG( fIS( )j 2 g) includetimelines final result subsume timeline set. pruning step (the testline 12) sound since one timeline subsumes another, conjunction timelinesequivalent specific one. Section 4.4.1 traces computations algorithmexample LGG calculation.Since sizes IS() IG() exponential sizes inputs, codeFigure 8 doubly exponential input size. conjecture cannot better this,yet proven doubly exponential lower bound AMA case. inputformulas timelines algorithm takes singly exponential time, since IS(fg) =MA. prove exponential lower bound input formulas MA. Again,readers uninterested technical details proof safely skip forward Section 4.3.argument, take available primitive propositions set fpi;j j 1n; 1 j ng, consider timelines1 = s1; ; s2; ; : : : ; sn;2 = s;1 ; s;2 ; : : : ; s;n ;402fiL EARNING EMPORAL E VENTSsi; = pi;1 ^ ^ pi;ns;j = p1;j ^ ^ pn;j :show AMA LGG 1 2 must contain exponential number timelines.particular, show AMA LGG equivalent conjunction subsetIG(f1 ; 2 g), certain timelines may omitted subset.Lemma 15. AMA LGG settimelines IG() j 0 j j jtimelines equivalent conjunction 0Proof: Lemma 5 implies timeline must subsume timeline 0 2 IG().conjunction 0 0 must equivalent , since clearly covers coveredLGG . Since 0 formed taking one timeline IG() timeline ,j 0 j j j. 2 complete argument showing exponentially manytimelines IG(f1 ; 2 g) cannot omitted conjunction remains LGG.Notice i; j si; \s;j = pi;j . implies state IG(f1 ; 2 g)contains exactly one proposition, since state formed intersecting state 12 . Furthermore, definition interdigitation, applied here, implies following two factstimeline q1 ; q2 ; : : : ; qm IG(f1 ; 2 g):1. q1= p1;1 qm = pn;n.2. consecutive states qk= i0 j= pi;j qk+1 = pi ;j , i0 either + 1, j 0 either j j + 1,= j0.00Together facts imply timeline IG(f1 ; 2 g) sequence propositions startingp1;1 ending pn;n consecutive propositions pi;j ; pi ;j differenti0 equal + 1 j 0 equal j j + 1. call timeline IG(f1 ; 2 g) squarepair consecutive propositions pi;j pi ;j either i0 = j 0 = j .following lemma implies square timeline omitted conjunction timelinesIG(1 ; 2 ) remain LGG 1 2 .0000Lemma 16. Let 1 2 given let = IG(f1 ; 2 g).timelines subset omits square timeline, < 0 .V0 whosen 2)! hence exponenThe number square timelines IG(f1 ; 2 g) equal (n (21)!(n 1)!tial size 1 2 . completed proof following result.Theorem 17.smallest LGG two formulas exponentially large.Proof: Lemma 15, AMA LGG 0 1 2 equivalent conjunctionnumber timelines chosen IG(f1 ; 2 g). However, Lemma 16, conjunctionn 2)! timelines, must 0 , must exponentiallymust least (n (21)!(n 1)!large. 2Conjecture 18.smallest LGG two AMA formulas doubly-exponentially large.403fiF ERN , G IVAN , & ISKINDshow lower-bound AMA LGG complexity merely consequenceexistence large AMA LGGs. Even small LGG, expensive computedue difficulty testing AMA subsumption:Theorem 19. Determining whether formula AMA LGG two given AMA formulas 12 co-NP-hard, co-NEXP, size three formulas together.Proof: show co-NP-hardness use straightforward reduction AMA subsumption. Giventwo AMA formulas 1 2 decide 1 2 asking whether 2 AMA LGG 12 . Clearly 1 2 iff 2 LGG two formulas.show co-NEXP upper bound, note check exponential time whether 12 using Proposition 7 polynomial-time subsumption algorithm. remainsshow check whether least subsumer. Since Theorem 14 showsLGG 1 2 IG(IS( 1 ) [ IS( 2 )), LGG 6 IG(IS( 1 ) [ IS( 2 )).Thus, Proposition 7, least subsumer, must timelines 1 2 IS( )2 2 IG(IS( 1 ) [ IS( 2 )) 1 6 2 . use exponentially long certificatesanswers: certificate pair interdigitation I1 interdigitation I2IS( 1 ) [ IS( 2 ), corresponding members 1 2 IS( ) 2 2 IG(IS( 1 ) [ IS( 2 ))1 6 2 . Given pair certificates I1 I2 , 1 computed polynomial time,2 computed exponential time, subsumption checkedpolynomial time (relative size, exponential). LGGIG(IS( 1 ) [ IS( 2 )), certificates exist. 24.3 Syntactic Subsumption Syntactic Least-General Generalization.Given intractability results semantic AMA subsumption, introduce tractable generality notion, syntactic subsumption, discuss corresponding LGG problem. usesyntactic forms generality efficiency familiar ILP (Muggleton & De Raedt, 1994)where, example, -subsumption often used place entailment generality relation.Unlike AMA semantic subsumption, syntactic subsumption requires checking polynomiallymany subsumptions, polynomial time (via Theorem 9).Definition 5. AMA 1 syntactically subsumed AMA 2 (written 1timeline 2 2 2 , timeline 1 2 1 1 2 .syn 2) iffProposition 20. AMA syntactic subsumption decided polynomial time.Syntactic subsumption trivially implies semantic subsumptionhowever, conversehold general. Consider AMA formulas (A; B ) ^ (B ; A), A; B ; Bprimitive propositions. (A; B ) ^ (B ; A) A; B ; A; however, neither A; BA; B ; B ; A; B ; A, A; B ; syntactically subsume (A; B ) ^ (B ; A).Syntactic subsumption fails recognize constraints derived interactiontimelines within formula.Syntactic Least-General Generalization. syntactic AMA LGG syntactically least-generalAMA formula syntactically subsumes input AMA formulas. Here, least means404fiL EARNING EMPORAL E VENTSformula properly syntactically subsumed syntactic LGG syntactically subsume inputformulas. Based hardness gap syntactic semantic AMA subsumption, one mightconjecture similar gap exists syntactic semantic LGG problems. Provinggap exists requires closing gap lower upper bounds AMA LGG shownTheorem 14 favor upper bound, suggested Conjecture 18. cannot yetshow hardness gap semantic syntactic LGG, give syntactic LGG algorithmexponentially efficient best semantic LGG algorithm found (thatTheorem 14). First, show syntactic LGGs exist unique mutual syntacticsubsumption (and hence semantic equivalence).Theorem 21. exists syntactic LGG AMA formula set syntactically subsumed syntactic generalizations .Proof: Let conjunction timelines syntactically generalizesize larger . proof Theorem 12, well defined. showsyntactic LGG . First, note syntactically generalizes timelinegeneralizes timeline every member , choice . consider arbitrarysyntactic generalization 0 . definition syntactic subsumption, timeline0 must subsume timeline ff member ff . Lemma 5 impliestimeline 0 size larger subsumes ff subsumed .choice , timeline 0 must timeline . follows 0 syntactically subsumes, syntactic LGG subsumed syntactic generalizations . 2general, know semantic syntactic LGGs different, though clearly syntacticLGG semantic generalization must subsume semantic LGG. example, (A; B ) ^(B ; A), A; B ; semantic LGG A; B ; A, discussed above; syntactic LGG(A; B ; true) ^ (true; B ; A), subsumes A; B ; subsumed A; B ; A. Evenso, formulas:Proposition 22.AMA , synequivalent .Proof: forward direction immediate since already know syntactic subsumption impliessemantic subsumption. reverse direction, note implies timelinesubsumes thus since single timeline timeline subsumes timelinedefinition syntactic subsumption. 2Proposition 23.syntactic AMA LGG formula set also semantic LGG .Proof: Now, consider syntactic LGG . Proposition 22 implies semanticgeneralization . Consider semantic LGG 0 . show 0 concludesemantic LGG . Proposition 22 implies 0 syntactically subsumes . follows0 ^ syntactically subsumes . But, 0 ^ syntactically subsumed , syntacticLGG follows 0 ^ syntactically subsumes , would least syntacticgeneralization . ( 0 ^ ), implies 0 , desired. 2note stronger result stating formula syntactic LGG set formulas semantic LGG immediate consequence results above.405fiF ERN , G IVAN , & ISKINDfirst examination, strengthening appears trivial, given equivalence syn. However, semantically least necessarily stronger condition syntactically leastwe ruled possibility semantically least generalization maysyntactically subsume another generalization semantically (but syntactically) equivalent.(This question open, found example phenomenon either.)Proposition 23 together Theorem 21 nice consequence learning approachsyntactic LGG two AMA formulas semantic LGG formulas, longoriginal formulas syntactic LGGs sets timelines. learning approach starts training examples converted timelines using LGCF operation,syntactic LGGs computed (whether combining training examples once, incrementally computing syntactic LGGs parts training data) always syntactic LGGs setstimelines hence also semantic LGGs, spite fact syntactic subsumptionweaker semantic subsumption. note, however, resulting semantic LGGs mayconsiderably larger smallest semantic LGG (which may syntactic LGG all).Using Proposition 23, show cannot hope polynomial-time syntactic LGGalgorithm.Theorem 24.smallest syntactic LGG two formulas exponentially large.Proof: Suppose always syntactic LGG two formulas exponentially large.Since Proposition 23 formula also semantic LGG, always semantic LGGtwo formulas exponentially large. contradicts Theorem 17. 2discouraging, algorithm syntactic LGG whose time complexitymatches lower-bound, unlike semantic LGG case, best algorithmdoubly exponential worst case. Theorem 14 yields exponential time method computingsemantic LGG set timelines since timeline , IS() = , simplyconjoin timelines IG(). Given set AMA formulas, syntactic LGG algorithm usesmethod compute polynomially-many semantic LGGs sets timelines, one choseninput formula, conjoins results.Theorem 25.1 ; : : : ; n .formula2 IG(f1 ; : : : ; n g) syntactic LGG AMA formulasVProof: Let 2 IG(f1 ; : : : ; n g). timeline must subsumeoutput IG set containing timeline thus syntactically subsumes .show syntactically least formula, consider 0 syntactically subsumes every. show syn 0 conclude. timeline 0 0 subsumes timeline Ti 2 ,i, assumption syn 0 . Lemma 5, 0 must subsume memberIG(fT1 ; : : : ; Tn g)and member timeline timeline 0 0 subsumestimeline . conclude syn 0 , desired. 2Vtheorem yields algorithm computes syntactic AMA LGG exponential timepseudo-code method given Figure 9. exponential time bound follows factexponentially many ways choose 1 ; : : : ; line 5,exponentially many semantic-LGG members line 6 (since timelines)theproduct two exponentials still exponential.406fiL EARNING EMPORAL E VENTS1:2:3:4:5:6:syntactic-LGG(f 1 ; 2 ; : : : ; g)// Input: AMA formulas f 1 ; : : : ; g// Output: syntactic LGG f 1 ; : : : ; gG := fg;h1 ; : : : ; 2 1semantic-LGG(f1 ; : : : ; g)7:8:9:10:Vreturn ((80 2 G : 0 6 )G0 := f00 2 G j 00 g;G := (G G0 ) [ fg;G)Figure 9: Pseudo-code computes syntactic AMA LGG set AMA formulas.formula returned algorithm shown actually subset syntactic LGG givenTheorem 25. subset syntactically (and hence semantically) equivalent formulaspecified theorem, possibly smaller due pruning achieved statementlines 79. timeline pruned set (semantically) subsumed timelineset (one timeline kept semantically equivalent group timelines, random).pruning timelines sound, since timeline pruned output subsumesformula outputthis fact allows easy argument pruned formula syntactically equivalent (i.e. mutually syntactically subsumed by) unpruned formula. Section 4.4.2traces computations algorithm example LGG calculation. note empirical evaluation discussed Section 6, cost terms accuracy usingefficient syntactic vs. semantic LGG. know learned definitions made errorsdirection overly specificthus, since semantic-LGG least specificsyntactic-LGG would advantage using semantic algorithm.method exponential amount work even result small (typicallymany timelines pruned output subsume remains). stillopen question whether output-efficient algorithm computing syntactic AMALGGthis problem coNP conjecture coNP-complete. One route settlingquestion determine output complexity semantic LGG input formulas.believe problem also coNP-complete, proven this; problem P,output-efficient method computing syntactic AMA LGG based Theorem 25.summary algorithmic complexity results section found Table 3conclusions section paper.4.4 Examples: Least-General Generalization Calculationswork details semantic syntactic LGG calculation. considerAMA formulas = (A; B ) ^ (B ; A) = A; B ; A, semantic LGG A; B ;syntactic LGG (A; B ; true) ^ (true; B ; A).407fiF ERN , G IVAN , & ISKIND4.4.1 EMANTIC LGG E XAMPLEfirst step calculating semantic LGG, according algorithm given Figure 8,compute interdigitation-specializations input formulas (i.e., IS() IS( )). Trivially,IS() = = A; B ; A. calculate IS( ), must consider possible interdigitations , three,f hA; B ; hB; B ; hB; Ai gf hA; B ; hB; Ai gf hA; B ; hA; Ai ; hB; Ai ginterdigitation leads corresponding member IS( ) unioning (conjoining) statestuple, IS( )f (A ^ B ); B ; (A ^ B );(A ^ B );(A ^ B ); A; (A ^ B ) g:Lines 59 semantic LGG algorithm compute set , equal uniontimelines IS( ) IS(), subsumed timelines removed. formulas, seetimeline IS( ) subsumed thus, = = A; B ; A.computing , algorithm returns conjunction timelines IG(S ), redundanttimelines removed (i.e., subsuming timelines removed). case, IG(S ) = A; B ; A,trivially, one timeline , thus algorithm correctly computes semantic LGGA; B ; A.4.4.2 YNTACTIC LGG E XAMPLEsyntactic LGG algorithm, shown Figure 9, computes series semantic LGGstimeline sets, returning conjunction results (after pruning). Line 5 algorithm, cyclestimeline tuples cross-product input AMA formulas. case tuplesT1 = hA; B ; A; A; B T2 = hA; B ; A; B ; Aifor tuple, algorithmcomputes semantic LGG tuples timelines.semantic LGG computation tuple uses algorithm given Figure 8,argument always set timelines rather AMA formulas. reason, lines 49 superfluous, timeline 0 , IS(0 ) = 0 . case tuple T1 , lines 49algorithm compute = fA; B ; A; A; B g. remains compute interdigitationgeneralizations (i.e., IG(S )), returning conjunction timelines pruning (lines1015 Figure 8). set interdigitations are,f hA; Ai ; hB; Ai ; hB; B ; hB; Ai gf hA; Ai ; hB; B ; hB; Ai gf hA; Ai ; hA; B ; hB; B ; hB; Ai gf hA; Ai ; hA; B ; hB; Ai gf hA; Ai ; hA; B ; hA; Ai ; hB; Ai gintersecting states interdigitation tuples get IG(S ),f A; true; B ; true; A; B ; true; A; true; B ; true; A; true; true; A; true; A; true g408fiL EARNING EMPORAL E VENTSSince timeline A; B ; true subsumed timelines IG(S ), timelinespruned. Thus semantic LGG algorithm returns A; B ; true semantic LGG timelinesT1 .Next syntactic LGG algorithm computes semantic LGG timelines T2 . Followingsteps T1 , find semantic LGG timelines T2 true; B ; A. SinceA; B ; true true; B ; subsume one another, set G computed lines 59syntactic LGG algorithm equal f A; B ; true; true; B ; g. Thus, algorithm computessyntactic LGG (A; B ; true) ^ (true; B ; A). Note that, case, syntacticLGG general semantic LGG.5. Practical Extensionsimplemented specific-to-general AMA learning algorithm based LGCF syntactic LGG algorithms presented earlier. implementation includes four practical extensions.first extension aims controlling exponential complexity limiting lengthtimelines consider. Second describe often efficient LGG algorithm basedmodified algorithm computing pairwise LGGs. third extension deals applyingpropositional algorithm relational data, necessary application domain visual eventrecognition. Fourth, add negation AMA language show compute corresponding LGCFs LGGs using algorithms AMA (without negation). Adding negationAMA turns crucial achieving good performance experiments. endsection review overall complexity implemented system.5.1 k-AMA Least-General Generalizationalready indicated syntactic AMA LGG algorithm takes exponential time relativelengths timelines AMA input formulas. motivates restricting AMAlanguage k -AMA practice, formulas contain timelines k states.k increased algorithm able output increasingly specific formulas costexponential increase computational time. visual-eventrecognition experiments shownlater, increased k , resulting formulas became overly specific computational bottleneck reachedi.e., application best values k practically computableability limit k provided useful language bias.use k -cover operator order limit syntactic LGG algorithm k -AMA. k -coverAMA formula syntactically least general k -AMA formula syntactically subsumesinputit easy show k -cover formula formed conjoining k -MAtimelines syntactically subsume formula (i.e., subsume timeline formula) .Figure 10 gives pseudo-code computing k -cover AMA formula. shownalgorithm correctly computes k -cover input AMA formula. algorithm calculatesset least general k -MA timelines subsume timeline inputthe resulting k -MAformulas conjoined redundant timelines pruned using subsumption test. notek -cover AMA formula may exponentially larger formula; however,practice, found k -covers exhibit undue size growth.Given k -cover algorithm restrict learner k -AMA follows: 1) Computek-cover AMA input formula. 2) Compute syntactic AMA LGG resulting kAMA formulas. 3) Return k -cover resulting AMA formula. primary bottleneck409fiF ERN , G IVAN , & ISKIND1:2:3:4:5:6:7:8:9:10:11:12:13:14:15:17:18:19:20:Vk-cover(k; 1im )V// Input: positive natural number k , AMA formula 1imV// Output: k -cover 1imG := fg;:= 1:= hP1 ; : : : ; Pn all-values(a-k-partition (k; )):= ( P1 ); : : : ; ( Pn );(80 2 G : 0 6 )G0 := f00 2 G j 00 g;G := (G G0 ) [ fg;Vreturn ( G)Pa-k-partition (k; s1 ; : : : ; sj )// Input: positive natural number k , timeline s1 ; : : : ; sj// Output: tuple k sets consecutive states partitions s1 ; : : : ; sjk return hfs1g; : : : ; fsj gi;k = 1 return hfs1 ; : : : ; sj gi;l := a-member-of(f1; 2; : : : ; j k + 1g);P0 = fs1 ; : : : ; sl g;jreturn extend-tuple (P0 ; a-k-partition (k// pick next block size// construct next block1; sl+1 ; : : : ; sj ));Figure 10: Pseudo-code non-deterministically computing k-cover AMA formula, alongnon-deterministic helper function selecting k block partition statestimeline.original syntactic LGG algorithm computing exponentially large set interdigitationgeneralizationsthe k -limited algorithm limits complexity computes interdigitationgeneralizations involving k -MA timelines.5.2 Incremental Pairwise LGG Computationimplemented learner computes syntactic k-AMA LGG AMA formula setshowever,directly use algorithm describe above. Rather compute LGG formulasets via single call algorithm, typically efficient break computationsequence pairwise LGG calculations. describe approach potentialefficiency gains.straightforward show syntactic semantic subsumptionLGG( 1 ; : : : ; ) = LGG( 1 ; LGG( 2 ; : : : ; )) AMA formulas. Thus,recursively applying transformation incrementally compute LGG AMA formulas via sequence 1 pairwise LGG calculations. Note since LGG operator410fiL EARNING EMPORAL E VENTScommutative associative final result depend order processformulas. refer incremental pairwise LGG strategy incremental approachstrategy makes single call k-AMA LGG algorithm (passing entire formulaset) direct approach.simplify discussion consider computing LGG formula setargument extended easily AMA formulas (and hence k-AMA). Recall syntacticLGG algorithm Figure 9 computes LGG() conjoining timelines IG() subsume others, eliminating subsuming timelines form pruning. incrementalapproach applies pruning step pair input formulas processedin contrast,direct approach must compute interdigitation-generalization input formulaspruning happen. resulting savings substantial, typically compensatesextra effort spent checking pruning (i.e. testing subsumption timelinesincremental LGG computed). formal approach describing savings constructedbased observation 2IG(f1 ;2 g) IG(fg[ ) 2LGG(1 ;2 ) IG(fg[ )seen compute LGG [ f1 ; 2 g, latter possibly much cheapercompute due pruning. is, LGG(1 ; 2 ) typically contains much smaller numbertimelines IG(f1 ; 2 g).Based observations implemented system uses incremental approachcompute LGG formula set. describe optimization used system speedupcomputation pairwise LGGs, compared directly running algorithm Figure 9. Givenpair AMA formulas 1 = 1;1 ^ ^ 1;m 2 = 2;1 ^ ^ 2;n , let syntacticLGG obtained running algorithm Figure 9. algorithm constructs computingLGGs timeline pairs (i.e., LGG(1;i ; 2;j ) j ) conjoining resultsremoving subsuming timelines. turns often avoid computing manyLGGs. see consider case exists j 1;i 2;j , knowLGG(1;i ; 2;j ) = 2;j tells us 2;j considered inclusion (it maypruned). Furthermore know LGG involving 2;j subsume 2;j thuspruned . shows need compute LGGs involving 2;j , ratherneed consider adding 2;j constructing .observation leads modified algorithm (used system) computingsyntactic LGG pair AMA formulas. new algorithm computes LGGsnon-subsuming timelines. Given AMA formulas 1 2 , modified algorithm proceedsfollows: 1) Compute subsumer set = f 2 1 j 90 2 2 s:t: 0 g [ f 2 2 j 90 21 s:t: 0 g. 2) Let AMA 01 ( 02 ) result removing timelines 1 ( 2 ). 3) Let 0 syntactic LGG 01 02 computed running algorithm Figure 9(if either 0i empty 0 empty). 4) Let 0 conjunction timelinessubsume timeline 0 . 5) Return = 0 ^ 0 . method avoids computing LGGsinvolving subsuming timelines (an exponential operation) cost performing polynomiallymany subsumption tests (a polynomial operation). noticed significant advantageusing procedure experiments. particular, advantage tends grow processtraining examples. due fact incrementally process training examplesresulting formulas become generalthus, general formulas likelysubsuming timelines. best case 1 syn 2 (i.e., timelines 2 subsuming), see step 2 produces empty formula thus step 3 (the expensive step) performsworkin case return set = 2 desired.411fiF ERN , G IVAN , & ISKIND5.3 Relational DataL EONARD produces relational models involve objects (force dynamic) relationsobjects. Thus event definitions include variables allow generalization objects.example, definition P ICK U P (x; y; z ) recognizes P ICK U P (hand; block; table) wellP ICK U P (man; box; floor). Despite fact k -AMA learning algorithm propositional,still able use learn relational definitions.take straightforward object-correspondence approach relational learning. viewmodels output L EONARD containing relations applied constants. Since (currently)support supervised learning, set distinct training examples event type.implicit correspondence objects filling role across different training models given type. example, models showing P ICK U P (hand; block; table)P ICK U P (man; box; floor) implicit correspondences given hhand; mani, hblock; boxi,htable; floori. outline two relational learning methods differ much objectcorrespondence information require part training data.5.3.1 C OMPLETE BJECT C ORRESPONDENCEfirst approach assumes complete object correspondence given, input, alongtraining examples. Given information, propositionalize training modelsreplacing corresponding objects unique constants. propositionalized models givenpropositional k -AMA learning algorithm returns propositional k -AMA formula.lift propositional formula replacing constant distinct variable. Lavrac et al.(1991) taken similar approach.5.3.2 PARTIAL BJECT C ORRESPONDENCEapproach assumes complete object-correspondence information. sometimespossible provide correspondences (for example, color-coding objects fill identicalroles recording training movies), information always available.partial object correspondence (or even none all) available, automatically completecorrespondence apply technique.moment, assume evaluation function takes two relational modelscandidate object correspondence, input, yields evaluation correspondence quality. Given set training examples missing object correspondences, perform greedysearch best set object-correspondence completions models. method worksstoring set P propositionalized training examples (initially empty) set U unpropositionalized training examples (initially entire training set). first step, P empty,evaluate pairs examples U , possible correspondences, select pair yieldshighest score, remove examples involved pair U , propositionalize according best correspondence, add P . subsequent step, use previouslycomputed values pairs examples, one U one P , possible correspondences. select example U correspondence yields highest averagescore relative models P example removed U , propositionalized accordingwinning correspondence, added P . fixed number objects, effort expendedpolynomial size training set; however, number objects b appeartraining example allowed grow, number correspondences must considered grows412fiL EARNING EMPORAL E VENTSbb . reason, important events involved manipulate modest numberobjects.evaluation function based intuition object roles visual events (as wellevents domains) often inferred considering changes initialfinal moments event. Specifically, given two models object correspondence,first propositionalize models according correspondence. Next, compute ADDDELETE lists model. ADD list set propositions true finalmoment initial moment. DELETE list set propositions trueinitial moment final moment. add delete lists motivated STRIPS actionrepresentations (Fikes & Nilsson, 1971). Given ADDi DELETEi lists models 1 2,evaluation function returns sum cardinalities ADD1 \ ADD2 DELETE1 \DELETE2 . heuristic measures similarity ADD DELETE lists twomodels. intuition behind heuristic similar intuition behind STRIPS actiondescription languagei.e., differences initial final momentsevent occurrence related target event, event effects described ADDDELETE lists. found evaluation function works well visual-event domain.Note, full object correspondences given learner (rather automaticallyextracted learner), training examples interpreted specifying target eventtook place well objects filled various event roles (e.g., P ICK U P (a,b,c)). Rather,object correspondences provided training examples interpreted specifyingexistence target event occurrence specify objects fill roles (i.e., trainingexample labeled P ICK U P rather P ICK U P (a,b,c)). Accordingly, rules learnedcorrespondences provided allow us infer target event occurredobjects filled event roles. example object correspondences manually providedlearner might produce rule,"4 (S UPPORTS (z; y) ^ C ONTACTS (z; y));P ICK U P (x; y; z ) =(S UPPORTS (x; y) ^ ATTACHED (x; y))#whereas learner automatically extracts correspondences would instead produce rule,"4 (S UPPORTS (z; y) ^ C ONTACTS (z; y));P ICK U P =(S UPPORTS (x; y) ^ ATTACHED (x; y))#worth noting, however, upon producing second rule availability single trainingexample correspondence information allows learner determine roles variables,upon output first rule. Thus, assumption learner reliablyextract object correspondences, need label training examples correspondence information order obtain definitions explicitly recognize object roles.5.4 Negative InformationAMA language allow negated propositions. Negation, however, sometimes necessary adequately define event type. section, consider language AMA ,superset AMA, addition negated propositions. first give syntax semanticsAMA , extend AMA syntactic subsumption AMA . Next, describe approach413fiF ERN , G IVAN , & ISKINDlearning AMA formulas using above-presented algorithms AMA. show approach correctly computes AMA LGCF syntactic AMA LGG. Finally, discussalternative, related approach adding negation designed reduce overfitting appearsresult full consideration negated propositions.AMA syntax AMA, new grammar building states negatedpropositions:literalstate::= true j prop j :3prop::= literal j literal ^ stateprop primitive proposition. semantics AMAstate satisfaction.AMA exceptpositive literal P (negative literaltrue (false), every x 2 .10:3P ) satisfied model hM; iff [x] assigns Pstate l1 ^ ^ lm satisfied model hM; iff literal li satisfied hM; i.Subsumption. important difference AMA AMA Proposition 2, establishing existence witnessing interdigitations subsumption, longer true .words, two timelines 1 ; 2 2 AMA , 1 2 , needinterdigitation witnesses 1 2 . see this, consider AMA timelines:1 = (a ^ b ^ c); b; a; b; (a ^ b ^ : c)2 = b; a; c; a; b; a; : c; a; bargue:1. interdigitation witnesses 1 2 . see this, first show that,witness, second fourth states 1 (each b) must interdigitate aligneither first fifth, fifth ninth states 2 (also, b). eithercases, third state 1 interdigitate states 2 subsume it.2. Even so, still 1 2 . see this, consider model hM; satisfies 1 .must interval [i1 ; i2 ] within hM; [i1 ; i2 ]i satisfies third state 1 ,state a. two cases:(a) proposition c true point hM; [i1 ; i2 ]i. Then, one verify hM;satisfies 1 2 following alignment:12==(a ^ b ^ c); b;b;a;a; c; a;b;b;(a ^ b ^ : c)a; : c; a; b10. note important use notation :3P rather :P . event-logic, formula :Psatisfied model whenever P false instant model. Rather, event-logic interprets :3Pindicating P never true model (as defined above). Notice first form negation yieldliquid propertyi.e., :P true along interval necessarily subintervals. second formnegation, however, yield liquid property provided P liquid. important learning algorithms,since assume states built liquid properties.414fiL EARNING EMPORAL E VENTS(b) proposition c false everywhere hM; [i1 ; i2 ]i. Then, one verify hM;satisfies 1 2 following alignment:1 =(a ^ b ^ c);2 =b; a; c; a;follows 1 2 .b;b;a;a; : c; a;b; (a ^ b ^ : c)blight examples, conjecture computationally hard compute AMAsubsumption even timelines. reason, extend definition syntactic subsumption AMA way provides clearly tractable subsumption test analogousdiscussed AMA.Definition 6. AMA 1 syntactically subsumed AMA 2 (written 1 syn 2 ) ifftimeline 2 2 2 , timeline 1 2 1 witnessing interdigitation1 2 .difference definition previous one AMA needtest witnessing interdigitations timelines rather subsumption timelines.AMA formulas, note new old definition equivalent (due Proposition 2);however, AMA new definition weaker, result general LGG formulas.one might expect, AMA syntactic subsumption implies semantic subsumption testedpolynomial-time using subsumption graph described Lemma 8 test witnesses.Learning. Rather design new LGCF LGG algorithms directly handle AMA ,instead compute functions indirectly applying algorithms AMA transformedproblem. Intuitively, adding new propositions models (i.e., training examples) represent proposition negations. Assume training-example modelsset propositions P = fp1 ; : : : ; pn g. introduce new set P = fp1 ; : : : ; pn g propositionsuse construct new training models P [ P assigning true pi timemodel iff pi false model time. forming new set training models (eachtwice many propositions original models) compute least general AMA formulacovers new models (by computing AMA LGCFs applying syntactic AMA LGGalgorithm), resulting AMA formula propositions P [ P . Finally replace pi:3pi resulting AMA formula 0 propositions P turnssyntactic subsumption 0 least general AMA formula covers original trainingmodels.show correctness transformational approach computing AMALGCF syntactic LGG. First, introduce notation. Let set modelsP . Let set models P [ P , time, i, exactly one pipi true. Let following mapping M: hM; 2 M, [hM; i]unique hM 0 ; 2 j 2 i, 0 (j ) assigns pi true iff (j ) assigns pitrue. Notice inverse functional mapping M. approach handlingnegation using purely AMA algorithms begins applying original training models.follows, consider AMA formulas propositions P , AMA formulaspropositions P [ P .Let F mapping AMA AMA 2 AMA , F [ ] AMA formulaidentical except :3pi replaced pi . Notice inverse F func415fiF ERN , G IVAN , & ISKINDtion AMA AMA corresponds final step approach described above.following lemma shows one-to-one correspondence satisfaction AMAformulas models satisfaction AMA formulas models M.Lemma 26. model hM; 2 2 AMA ,[hM; i].covers hM;iffF [ ] coversUsing lemma, straightforward show transformational approach computesAMA LGCF semantic subsumption (and hence syntactic subsumption).Proposition 27.hM; 2 M, let AMA LGCF model [hM; i].LGCF hM; i, equivalence.F 1 [] unique AMAThen,Proof: know covers [hM; i], therefore Lemma 26 know F 1 [] covershM; i. show F 1[] least-general formula AMA covers hM; i.sake contradiction assume 0 2 AMA covers hM; 0 < F 1 [].follows model hM 0 ; 0 covered F 1 [] 0 . Lemma 26F [0 ] covers [hM; i] since unique AMA LGCF [hM; i],equivalence, F [0 ]. However, also [hM 0 ; 0 i] coveredF [0 ] gives contradiction. Thus, 0 exist. followsAMA LGCF. uniqueness AMA LGCF equivalence follows AMAclosed conjunction; two non-equivalent LGCF formulas, couldconjoined get LGCF formula strictly less one them. 2use fact F operator preserves syntactic subsumption. particular, giventwo timelines 1 ; 2 , clear witnessing interdigitation 1 2 triviallyconverted witness F [1 ] F [2 ] (and vice versa). Since syntactic subsumption definedterms witnessing interdigitations, follows 1 ; 2 2 AMA , ( 1 syn 2 ) iff(F [ 1 ] syn F [ 2 ]). Using property, straightforward show compute syntacticAMA LGG using syntactic AMA LGG algorithm.Proposition 28.AMAformulas1 ; : : : ; ,letfF [ 1 ]; : : : ; F [ ]g. Then, F 1[ ] unique syntactic AMAsyntactic AMA LGGLGG f 1 ; : : : ; g.Proof: know i, F [ ] syn thus, since F 1 preserves syntactic subsumption,i, syn F 1 [ ]. shows F 1 [ ] generalization inputs.show F 1 [ ] least formula. sake contradiction assumeF 1 [ ] least. follows must 0 2 AMA 0 <syn F 1 [ ]i, syn 0 . Combining fact F preserves syntactic subsumption, getF [ 0 ] <syn i, F [ ] F [ 0 ]. contradicts fact LGG;must F 1 [ ] syntactic AMA LGG. argued elsewhere, uniquenessLGG follows fact AMA closed conjunction. 2propositions ensure correctness transformational approach computingsyntactic LGG within AMA . case semantic subsumption, transformational approachcorrectly compute AMA LGG. see this, recall given two timelines 1 ; 2 2 AMA , 1 2 , witnessing interdigitation. Clearly416fiL EARNING EMPORAL E VENTSsemantic subsumption, AMA LGG 1 2 2 . However, semantic AMA LGGF [1 ] F [2 ] F [2 ]. reason since witness F [1 ] F [2 ](and F [i ] timelines), know Proposition 2 F [1 ] 6 F [2 ]. Thus, F [2 ]cannot returned AMA LGG, since subsume input formulasthis showstransformational approach return 2 = F 1 [F [2 ]]. Here, transformationalapproach produce AMA formula general 2 .computational side, note that, since transformational approach doubles number propositions training data, algorithms specifically designed AMA mayefficient. algorithms might leverage special structure transformed examplesAMA algorithms ignorein particular, exactly one pi pi true time.Boundary Negation. experiments, actually compare two methods assigning truthvalues pi propositions training data models. first method, called full negation,assigns truth values described above, yielding syntactically least-general AMA formulacovers examples. found, however, using full negation often results learning overlyspecific formulas. help alleviate problem, second method places bias usenegation. choice bias inspired idea that, often, much useful informationcharacterizing event type pre- post-conditions. second method, called boundarynegation, differs full negation allows pi true initial final momentsmodel (and pi false). pi must false times. is, allowinformative negative information beginnings ends training examples.found boundary negation provides good trade-off negation (i.e., AMA),often produces overly general results, full negation (i.e., AMA ), often produces overlyspecific much complicated results.5.5 Overall Complexity Scalabilityreview overall complexity visual event learning component discussscalability issues. Given training set temporal models (i.e., set movies), systemfollowing: 1) Propositionalize training models, translating negation descried Section 5.4.2) Compute LGCF propositional model. 3) Compute k -AMA LGG LGCFs.4) Return lifted (variablized) version LGG. Steps two four require little computationaloverhead, linear sizes input output respectively. Steps one threecomputational bottlenecks systemthey encompass inherent exponential complexityarising relational temporal problem structure.Step One. Recall Section 5.3.2 system allows user annotate training examples object correspondence information. technique propositionalizing modelsshown exponential number unannotated objects training example. Thus,system requires number objects relatively small correspondence informationgiven small number objects. Often event class definitions interestedinvolve large number objects. true, controlled learning settingmanage relational complexity generating training examples small number (orzero) irrelevant objects. case domains studied empirically paper.less controlled setting, number unannotated objects may prohibit usecorrespondence techniquethere least three ways one might proceed. First, try417fiF ERN , G IVAN , & ISKINDdevelop efficient domain-specific techniques filtering objects finding correspondences.is, particular problem may possible construct simple filter removes irrelevantobjects consideration find correspondences remaining objects. Second,provide learning algorithm set hand-coded first-order formulas, defining setdomain-specific features (e.g., spirit Roth & Yih, 2001). features usedpropositionalize training instances. Third, draw upon ideas relational learningdesign truly first-order version k -AMA learning algorithm. example, one could useexisting first-order generalization algorithms generalize relational state descriptions. Effectivelyapproach pushes object correspondence problem k -AMA learning algorithm rathertreating preprocessing step. Since well known computing first-order LGGsintractable (Plotkin, 1971), practical generalization algorithms retain tractability constrainingLGGs various ways (e.g., Muggleton & Feng, 1992; Morales, 1997).Step Three. system uses ideas Section 5.2 speedup k -AMA LGG computationset training data. Nevertheless, computational complexity still exponential k thus,practice restricted using relatively small values k . restriction limitperformance visual event experiments, expect limit direct applicabilitysystem complex problems. particular, many event types interest mayadequately represented via k -AMA k small. event types, however, often containsignificant hierarchical structurei.e., decomposed set short sub-event types.interesting research direction consider using k -AMA learner componenthierarchical learning systemthere could used learn k -AMA sub-event types. notelearner alone cannot applied hierarchically requires liquid primitive events,learns non-liquid composite event types. work required (and intended) constructhierarchical learner based perhaps non-liquid AMA learning.Finally, recall compute LGG examples, system uses sequence 1pairwise LGG calculations. fixed k , pairwise calculation takes polynomial time. However, since size pairwise LGG grow least constant factor respectinputs, worst-case time complexity computing sequence 1 pairwise LGGs exponential m. expect worst case primarily occur target event typecompact k -AMA representationin case hierarchical approach describedappropriate. compact representation, empirical experience indicatesgrowth occurin particular, pairwise LGG tends yield significant pruning. problems, reasonable assumptions amount pruning11 imply timecomplexity computing sequence 1 pairwise LGGs polynomial m.6. Experiments6.1 Data Setdata set contains examples 7 different event types: pick up, put down, stack, unstack, move,assemble, disassemble. involve hand two three blocks. detaileddescription sample video sequences event types, see Siskind (2001). Key framessample video sequences event types shown Figure 11. results segmentation,11. particular, assume size pairwise k-AMA LGG usually bounded sizes k-coversinputs.418fiL EARNING EMPORAL E VENTStracking, model reconstruction overlaid video frames. recorded 30 movies7 event classes resulting total 210 movies comprising 11946 frames.12replaced one assemble movie (assemble-left-qobi-04), duplicate copy another (assembleleft-qobi-11) segmentation tracking errors.event classes hierarchical occurrences events one class contain occurrences events one simpler classes. example, movie depictingOVE (a; b; c; d) event (i.e. moves b c d) contains subintervals P ICK U P (a; b; c)P UT (a; b; d) events occur. experiments, learning definition eventclass movies event class used training. train moviesevent classes may also depict occurrence event class learned subevent.However, evaluating learned definitions, wish detect events correspondentire movie well subevents correspond portions movie. example, givenmovie depicting OVE (a; b; c; d) event, wish detect OVE(a; b; c; d) eventalso P ICK U P (a; b; c) P UT (a; b; d) subevents well. movie type dataset, set intended events subevents detected. definitiondetect intended event, deem error false negative. definition detects unintendedevent, deem error false positive. example, movie depicts OVE(a; b; c; d) event,intended events OVE(a; b; c; d), P ICK U P (a; b; c), P UT (a; b; c). definitionpick detects occurrence P ICK U P (c; b; a) P ICK U P (b; a; c), P ICK U P (a; b; c),charged two false positives well one false negative. evaluate definitionsterms false positive negative rates describe below.6.2 Experimental Procedureevent type, evaluate k -AMA learning algorithm using leave-one-movie-out crossvalidation technique training-set sampling. parameters learning algorithm kdegree negative information used. value either P, positive propositionsonly, BN, boundary negation, N, full negation. parameters evaluation procedureinclude target event type E training-set size N . Given information, evaluationproceeds follows: movie (the held-out movie) 210 movies, apply k AMA learning algorithm randomly drawn training sample N movies 30 moviesevent type E (or 29 movies one 30). Use L EONARD detect occurrenceslearned event definition . Based E event type , record number falsepositives false negatives , detected L EONARD . Let FP FN total numberfalse positives false negatives observed 210 held-out movies respectively. Repeatentire process calculating FP FN 10 times record averages FP FN.13Since event types occur frequently data others simpler eventsoccur subevents complex events vice versa, report FP FN directly.Instead, normalize FP dividing total number times L EONARD detected targetevent correctly incorrectly within 210 movies normalize FN dividing total12. source code data used experiments available Online Appendix 1, alsoftp://ftp.ecn.purdue.edu/qobi/ama.tar.Z.13. record times experiments, system fast enough give live demos N = 29k = 3 boundary negation, giving best results show (though dont typically record 29 trainingvideos live demo reasons). less favorable parameter settings (particularly k = 4 fullnegation) take (real-time) hour so.419fiF ERN , G IVAN , & ISKINDpickputstackunstackmoveassembledisassembleFigure 11: Key frames sample videos 7 event types.420fiL EARNING EMPORAL E VENTSnumber correct occurrences target event within 210 movies (i.e., human assessmentnumber occurrences target event). normalized value FP estimates probability target event occur given predicted occur, normalizedvalue FN estimates probability event predicted occur givenoccur.6.3 Resultsevaluate k -AMA learning approach, ran leave-one-movie-out experiments, describedabove, varying k , , N . 210 example movies recorded color-coded objectsprovide complete object-correspondence information. compared learned event definitionsperformance two sets hand-coded definitions. first set HD1 hand-coded definitionsappeared Siskind (2001). response subsequent deeper understanding behaviorL EONARD model-reconstruction methods, manually revised definitions yield anotherset HD2 hand-coded definitions gives significantly better FN performance costFP performance. Appendix C gives event definitions HD1 HD2 along setmachine-generated definitions, produced k -AMA learning algorithm, given training datak = 30 = BN.6.3.1 BJECT C ORRESPONDENCEevaluate algorithm finding object correspondences, ignored correspondence information provided color coding applied algorithm training models eventtype. algorithm selected correct correspondence 210 training models. Thus,data set, learning results correspondence information given identicalcorrespondences manually provided, except that, first case, rulesspecify particular object roles, discussed section 5.3.2. Since evaluation procedure usesrole information, rest experiments use manual correspondence information, providedcolor-coding, rather computing it.correspondence technique perfect experiments, may suitedevent types. Furthermore, likely produce errors noise levels increase. Sincecorrespondence errors represent form noise learner makes special provisionshandling noise, results likely poor errors common. example,worst case, possible single extremely noisy example cause LGG trivial (i.e.,formula true). cases, forced improve noise tolerance learner.6.3.2 VARYING kfirst three rows Table 1 show FP FN values 7 event types k 2 f2; 3; 4g ,N = 29 (the maximum), = BN. Similar trends found = P = N.general trend that, k increases, FP decreases remains FN increases remainssame. trend consequence k -cover approach. because, k increases,k -AMA language contains strictly formulas. Thus k1 > k2 , k1 -cover formulanever general k2 -cover. strongly suggests, prove, FPnon-increasing k FN non-decreasing k .results show 2-AMA overly general put assemble, i.e. gives highFP. contrast, 3-AMA achieves FP = 0 event type, pays penalty FN compared421fiF ERN , G IVAN , & ISKINDk2 BNpickputstackunstackmoveassembledisassembleFPFN000.140.1900.1200.03000.750003BNFPFN0000.200.4500.1000.0300.0700.104BNFPFN0000.200.4700.1200.0300.0700.173PFPFN0.4200.50.1900.420.020.1100.0300.0300.103BNFPFN0000.200.4500.1000.0300.0700.103NFPFN00.0400.3900.5800.1600.1300.200.2HD1FPFN0.010.020.010.2200.8200.6200.0301.000.5HD2FPFN0.130.00.110.1900.4200.0200.000.7700.0Table 1: FP FN learned definitions, varying k , hand-coded definitions.2-AMA. Since 3-AMA achieves FP = 0, likely advantage moving k -AMAk > 3. is, expected result FN become larger. effect demonstrated4-AMA table.6.3.3 VARYINGRows four six Table 1 show FP FN 7 event types 2 fP; BN; Ng, N = 29,k = 3. Similar trends observed values k . general trend that,degree negative information increases, learned event definitions become specific.words, FP decreases FN increases. makes sense since, negative informationadded training models, specific structure found data exploitedk -AMA formulas. see that, = P, definitions pick putoverly general, produce high FP. Alternatively, = N, learned definitionsoverly specific, giving FP = 0, cost high FN. experiments, well others,found = BN yields best worlds: FP = 0 event types lower FNachieved = N.Experiments shown demonstrated that, without negation pick put down,increase k arbitrarily, attempt specialize learned definitions, never significantly reduce FP. indicates negative information plays particularly important roleconstructing definitions event types.422fiL EARNING EMPORAL E VENTS6.3.4 C OMPARISONH -C ODED EFINITIONSbottom two rows table 1 show results HD1 HD2 . yet attemptedautomatically select parameters learning (i.e. k ). Rather, focus comparinghand-coded definitions parameter set judged best performing across eventtypes. believe, however, parameters could selected reliably using cross-validationtechniques applied larger data set. case, parameters would selected perevent-type basis would likely result even favorable comparison hand-codeddefinitions.results show learned definitions significantly outperform HD1 current dataset. HD1 definitions found produce large number false negatives currentdata set. Notice that, although HD2 produces significantly fewer false negatives event types,produces false positives pick put down. hand definitionsutilize pick put macros defining events.performance learned definitions competitive performance HD2 .main differences performance are: (a) pick put down, learned HD2 definitionsachieve nearly FN learned definitions achieve FP = 0 whereas HD2 significantFP, (b) unstack disassemble, learned definitions perform moderately worse HD2respect FN, (c) learned definitions perform significantly better HD2 assembleevents.conjecture manual revision could improve HD2 perform well (and perhaps better than) learned definitions every event class. Nonetheless, view experimentpromising, demonstrates learning technique able compete with, sometimesoutperform, significant hand-coding efforts one authors.6.3.5 VARYING Npractical interest know training-set size affects algorithms performance.application, important method work well fairly small data sets, tediouscollect event data. Table 2 shows FN learning algorithm event type, Nreduced 29 5. experiments, used k = 3 = BN. Note FP = 0event types N hence shown. expect FN increase N decreased,since, specific-to-general learning, data yields more-general definitions. Generally, FNflat N > 20, increases slowly 10 < N < 20, increases abruptly 5 < N < 10.also see that, several event types, FN decreases slowly, N increased 20 29.indicates larger data set might yield improved results event types.6.3.6 P ERSPICUITYL EARNED EFINITIONSOne motivation using logic-based event representation support perspicuityin respectresults mixed. note perspicuity fuzzy subjective concept. Realizing this,say event definition perspicuous humans knowledge languagewould find definition natural. Here, assume human detailed knowledge model-reconstruction process learner trying fit. Adding assumptionwould presumably make definitions qualify perspicuous, many complex features learned definitions appear fact due idiosyncrasies model-reconstructionprocess. sense, evaluating perspicuity output entire system,423fiF ERN , G IVAN , & ISKINDlearner itself, key route improving perspicuity sense would improveintuitive properties model-reconstruction output without change learner.learned hand-coded definitions similar respect accuracy, typicallylearned definitions much less perspicuous. simplest event types, however, learneddefinitions arguably perspicuous. look issue detail. Appendix C giveshand-coded definitions HD1 HD2 along set machine-generated definitions.learned definitions correspond output k -AMA learner run 30 trainingmovies event type k = 3 = BN (i.e., best performing configurationrespect accuracy).Perspicuous Definitions. P ICK U P (x; y; z ) P UT (x; y; z ) definitions particular interest since short state sequences appear adequate representing event typesthus, hope perspicuous 3-AMA definitions. fact, hand-coded definitions involve short sequences. Consider hand-coded definitions P ICK U P(x; y; z )the definitionsroughly viewed 3-MA timelines form begin;trans;end.14 State begin asserts factsindicate z held x end asserts facts indicate heldx z . State trans intended model fact L EONARDs model-reconstructionprocess always handle transition begin end smoothly (so definitionbegin;end work well). make similar observations P UT OWN(x; y; z ).Figure 15 gives learned 3-AMA definitions P ICK U P (x; y; z ) P UT (x; y; z )definitions contain six two 3-MA timelines respectively. Since definitions consistsmultiple parallel timelines, may first seem perspicuous. However, closer examinationreveals that, definition, single timeline arguably perspicuousweplaced perspicuous timelines beginning definition. perspicuous timelinesnatural begin;trans;end interpretation. fact, practically equivalent definitionsP ICK U P (x; y; z ) P UT (x; y; z ) HD2 .15mind, notice HD2 definitions overly general indicated significantfalse positive rates. learned definitions, however, yield false positives without significantincrease false negatives. learned definitions improve upon HD2 essentially specializingHD2 definitions (i.e., perspicuous timelines) conjoining non-perspicuoustimelines. non-perspicuous timelines often intuitive, capture patternsevents help rule non-events. example, learned definition P ICK U P (x; y; z )non-perspicuous timelines indicate ATTACHED (y; z ) true transition periodevent. attachment relationship make intuitive sense. Rather, representssystematic error made model reconstruction process pick events.summary, see learned definitions P ICK U P (x; y; z ) P UT (x; y; z )contain perspicuous timeline one non-perspicuous timelines. perspicuous timelines give intuitive definition events, whereas non-perspicuous timelines capture nonintuitive aspects events model reconstruction process important practice.note that, experienced users, primary difficulty hand-coding definitions L EONARD14. Note event-logic definition P ICK U P(x; y; z ) HD2 written compact form 3-MA,definition converted 3-MA (and hence 3-AMA). Rather, HD1 cannot translated exactly 3-MAsince uses disjunctionit disjunction two 3-MA timelines.15. primary difference HD2 definitions contain negated propositions. learner considersproposition negation proposition true point training movies. Many negatedpropositions HD2 never appear positively, thus included learned definitions.424fiL EARNING EMPORAL E VENTSdetermining non-perspicuous properties must included. Typically requires manyiterations trial error. automated technique relieve user task. Alternatively,could view system providing guidance task.Large Definitions. TACK (w; x; y; z ) U NSTACK (w; x; y; z ) events nearly identicalput pick respectively. difference pickingputting onto two block (rather single block) tower (i.e., composed blocks z ).Thus, might expect perspicuous 3-AMA definitions. However, seelearned definitions TACK (w; x; y; z ) U NSTACK (w; x; y; z ) Figures 16 17 involvemany timelines P ICK U P (w; x; ) P UT (w; x; ). Accordingly,definitions quite overwhelming much less perspicuous.Despite large number timelines, definitions general structurepick put down. particular, contain distinguished perspicuous timeline,placed beginning definition, conjoined many non-perspicuous timelines.clear that, above, perspicuous timelines natural begin;trans;end interpretationand, again, similar definitions HD 2 . case, however, definitionsHD2 overly general (committing false positives). Thus, inclusionnon-perspicuous timelines detrimental effect since unnecessarily specialize definitionresulting false negatives.suspect primary reason large number non-perspicuous timelines relativedefinitions pick put stems increased difficulty constructingforce-dynamic models. inclusion two block tower examples causes modelreconstruction process produce unintended results, particularly transition periodsTACK U NSTACK . result often many unintuitive physically incorrect patternsinvolving three blocks hand produced transition period. learnercaptures patterns roughly via non-perspicuous timelines. likely generalizingdefinitions including training examples would filter timelines, makingoverall definition perspicuous. Alternatively, interest consider pruning learneddefinitions. straightforward way generate negative examples. these,could remove timelines (generalizing definition) contribute toward rejectingnegative examples. unclear prune definitions without negative examples.Hierarchical Events. OVE(w; x; y; z ), SSEMBLE (w; x; y; z ), ISASSEMBLE (w; x; y; z )inherently hierarchical, composed four simpler event types. hand-coded definitions leverage structure utilizing simpler definitions macros. light,clear that, viewed non-hierarchically, (as learner does) events involve relativelylong state sequences. Thus, 3-AMA adequate writing perspicuous definitions.spite representational shortcoming, learned 3-AMA definitions perform quite well.performance supports one arguments using AMA section 3.2. Namely, giveneasier find short rather long sequences, practical approach finding definitions longevents conjoin short sequences within events. Examining timelines learned3-AMA definitions reveals might expect. timeline captures often understandableproperty long event sequence, conjunction timelines cannot consideredperspicuous definition. future direction utilize hierarchical learning techniquesimprove perspicuity definitions maintaining accuracy.425fiF ERN , G IVAN , & ISKINDNpickputstackunstackmoveassembledisassemble292520151050.00.00.010.010.070.220.200.200.210.220.270.430.450.470.500.530.600.770.100.160.170.260.360.540.030.050.080.140.230.350.070.090.120.200.320.570.100.100.120.160.260.43Table 2: FN k= 3, = BN, various values N .note, however, that, level, learned definition OVE (w; x; y; z ) given Figure 18 perspicuous. particular, first 3-MA timeline naturally interpreted givingpre- post-conditions move action. is, initially x supported hand wempty finally x supported z hand w empty. Thus, care preand post-conditions, might consider timeline perspicuous. remaining timelinesdefinition capture pieces internal event structure facts indicating x movedhand. weaker case made assemble disassemble. first timelinelearned definitions Figures 19 20 interpreted giving pre- post-conditions.However, cases, pre(post)-conditions assemble(disassemble) quite incomplete.incompleteness due inclusion examples model-reconstruction processproperly handle initial(final) moments.7. Related Workdiscuss two bodies related work. First, present previous work visual event recognition relates experiments here. Second, discuss previous approaches learningtemporal patterns positive data.7.1 Visual Event Recognitionsystem unique combines positive-only learning temporal, relational,force-dynamic representation recognize events real video. Prior work investigated various subsets features systembut, date, system combined piecestogether. Incorporating one pieces system significant endeavor. respect, competing approaches directly compare system against. Given this,following representative list systems common features ours. meantcomprehensive focuses pointing primary differences systems ours, primary differences actually render systems loosely relatedours.Borchardt (1985) presents representation temporal, relational, force-dynamic event definitions definitions neither learned applied video. Regier (1992) presents techniques learning temporal event definitions learned definitions neither relational, forcedynamic, applied video. addition learning technique truly positive-onlyrather,extracts implicit negative examples event type positive examples event types.426fiL EARNING EMPORAL E VENTSYamoto, Ohya, Ishii (1992), Brand Essa (1995), Siskind Morris (1996), Brand, Oliver,Pentland (1997), Bobick Ivanov (1998) present techniques learning temporal eventdefinitions video learned definitions neither relational force dynamic. PinhanezBobick (1995) Brand (1997a) present temporal, relational event definitions recognizeevents video definitions neither learned force dynamic. Brand (1997b) MannJepson (1998) present techniques analyzing force dynamics video neither formulateevent definitions apply techniques recognizing events learning event definitions.7.2 Learning Temporal Patternsdivide body work three main categories: temporal data mining, inductive logicprogramming, finite-statemachine induction.Temporal Data Mining. sequence-mining literature contains many general-to-specific (levelwise) algorithms finding frequent sequences (Agrawal & Srikant, 1995; Mannila, Toivonen,& Verkamo, 1995; Kam & Fu, 2000; Cohen, 2001; Hoppner, 2001). explore specific-togeneral approach. previous work, researchers studied problem mining temporalpatterns using languages interpreted placing constraints partially totally orderedsets time points, e.g., sequential patterns (Agrawal & Srikant, 1995) episodes (Mannila et al.,1995). languages place constraints time points rather time intervals workhere. recently work mining temporal patterns using interval-based patternlanguages (Kam & Fu, 2000; Cohen, 2001; Hoppner, 2001).Though languages learning frameworks vary among approaches, share twocentral features distinguish approach. First, typically goalfinding frequent patterns (formulas) within temporal data setour approach focusedfinding patterns frequency one (covering positive examples). first learningapplication visual-event recognition yet required us find patterns frequency lessone. However, number ways extend method directionbecomes necessary (e.g., deal noisy training data). Second, approachesuse standard general-to-specific level-wise search techniques, whereas chose take specificto-general approach. One direction future work develop general-to-specific level-wisealgorithm finding frequent formulas compare specific-to-general approach.Another direction design level-wise version specific-to-general algorithmwhereexample, results obtained k -AMA LGG used efficiently calculate(k + 1)-AMA LGG. Whereas level-wise approach conceptually straightforward general-tospecific framework clear specific-to-general case. familiartemporal data-mining systems take specific-to-general approach.First-Order Learning Section 3.3, pointed difficulties using existing first-orderclausal generalization techniques learning AMA formulas. spite difficulties, stillpossible represent temporal events first-order logic (either without capturing AMAsemantics precisely) apply general-purpose relational learning techniques, e.g., inductivelogic programming (ILP) (Muggleton & De Raedt, 1994). ILP systems require positivenegative training examples hence suitable current positive-only framework.Exceptions include G OLEM (Muggleton & Feng, 1992), P ROGOL (Muggleton, 1995), C LAU DIEN (De Raedt & Dehaspe, 1997), among others. performed full evaluation427fiF ERN , G IVAN , & ISKINDInputsAMASubsumptionSemanticSyntacticPPcoNP-complete PSemantic AMA LGGLower Upper SizePcoNP EXPcoNP NEXP 2-EXP?Syntactic AMA LGGLower Upper SizePcoNP EXPPcoNP EXPTable 3: Complexity Results Summary. LGG complexities relative input plus output size.size column reports worst-case smallest correct output size. ? indicatesconjecture.systems, early experiments visual-event recognition domain confirmed beliefhorn clauses, lacking special handling time, give poor inductive bias. particular, manylearned clauses find patterns simply make sense temporal perspective and,turn, generalize poorly. believe reasonable alternative approach may incorporatesyntactic biases ILP systems done, example, Cohen (1994), Dehaspe De Raedt(1996), Klingspor, Morik, Rieger (1996). work, however, chose work directlytemporal logic representation.Finite-State Machines Finally, note much theoretical empirical researchlearning finite-state machines (FSMs) (Angluin, 1987; Lang, Pearlmutter, & Price, 1998).view FSMs describing properties strings (symbol sequences). case, however,interested describing sequences propositional models rather sequences symbols.suggests learning type factored FSM arcs labeled sets propositionsrather single symbols. Factored FSMs may natural direction extendexpressiveness current language, example allowing repetition. awarework concerned learning factored FSMs; however, likely inspiration drawnsymbol-based FSM-learning algorithms.8. Conclusionpresented simple logic representing temporal events called AMA showntheoretical empirical results learning AMA formulas. Empirically, weve given firstsystem learning temporal, relational, force-dynamic event definitions positive-only inputapplied system learn definitions real video input. resultingperformance matches event definitions hand-coded substantial effort humandomain experts. theoretical side, Table 3 summarizes upper lower boundsshown subsumption generalization problems associated logic.case, provided provably correct algorithm matching upper bound shown.table also shows worst-case size smallest LGG could possibly take relative inputsize, AMA inputs. key results table polynomial-timesubsumption AMA syntactic subsumption, coNP lower bound AMA subsumption,exponential size LGGs worst case, apparently lower complexity syntactic AMALGG versus semantic LGG. described build learner based results appliedvisual-event learning domain. date, however, definitions learn neither crossmodal perspicuous. performance learned definitions matches hand428fiL EARNING EMPORAL E VENTScoded ones, wish surpass hand coding. future, intend address cross-modalityapplying learning technique planning domain. also believe addressing perspicuitylead improved performance.Acknowledgmentsauthors wish thank anonymous reviewers helping improve paper. worksupported part NSF grants 9977981-IIS 0093100-IIS, NSF Graduate FellowshipFern, Center Education Research Information Assurance SecurityPurdue University. Part work performed Siskind NEC Research Institute,Inc.Appendix A. Internal Positive Event Logicgive syntax semantics event logic called Internal Positive Event Logic(IPEL). logic used main text motivate choice small subsetlogic, AMA, showing, Proposition 4, AMA define set models IPELdefine.event type (i.e., set models) said internal whenever contains model= hM; i, also contains model agrees truth assignments [i] 2 .Full event logic allows definition non-internal events, example, formula = 3< Psatisfied hM; interval 0 entirely preceding P satisfiedhM; 0 i, thus internal. applications considering appear requirenon-internal events, thus currently consider events internal.Call event type positive contains model = hM; [1; 1]i (1) truthassignment assigning propositions value true. positive event type cannot require proposition false point time.IPEL fragment full propositional event logic describe positive internalevents. conjecture, yet proven, positive internal events representablefull event logic Siskind (2001) represented IPEL formula. Formally, syntaxIPEL formulas givenE ::= true j prop j E1 _ E2 j 3R E1 j E1 ^R E2 ;0Ei IPEL formulas, prop primitive proposition (sometimes called primitive eventtype), R subset thirteen Allen interval relations fs,f,d,b,m,o,=,si,fi,di,bi,ai,oi g (Allen,1983), R0 subset restricted set Allen relations fs,f,d,=g, semanticsAllen relation given Table 4. difference IPEL syntax full propositionalevent logic event logic allows negation operator, that, full event logic, R0subset thirteen Allen relations. operators ^ ; used define AMA formulasmerely abbreviations IPEL operators ^f=g ^fmg respectively, AMA subsetIPEL (though distinguished subset indicated Proposition 4).thirteen Allen interval relations binary relations set closed naturalnumber intervals. Table 4 gives definitions relations, defining [m1 ; m2 ] r [n1 ; n2 ]Allen relation r . Satisfiability IPEL formulas defined follows,429fiF ERN , G IVAN , & ISKINDI1[m1 ; m2 ][m1 ; m2 ][m1 ; m2 ][m1 ; m2 ][m1 ; m2 ][m1 ; m2 ][m1 ; m2 ]Relationfb=I2[n1 ; n2 ][n1 ; n2 ][n1 ; n2 ][n1 ; n2 ][n1 ; n2 ][n1 ; n2 ][n1 ; n2 ]EnglishstartsfinishesmeetsoverlapsequalsDefinitionm1 = n1 m2m1 n1 m2m1 n1 m2n2= n2n2m2 n1m2 = n1 m2 + 1 = n1m1 n1 m2 n2m1 = n1 m2 = n2Inversesifidibimioi=Table 4: Thirteen Allen Relations (adapted semantics).true satisfied every model.prop satisfied model hM; iff [x] assigns prop true every x 2 .E1 _ E2 satisfied model iff satisfies E1 satisfies E2.3RE satisfied model hM; iff r 2 R interval 0 0 rhM; 0 satisfies E .E1 ^R E2 satisfied model hM; iff r 2 R exist intervals I1 I2I1 r I2 , PAN (I1 ; I2 ) = hM; I1 satisfies E1 hM; I2 satisfies E2 .prop primitive proposition, E Ei IPEL formulas, R set Allen relations,PAN (I1 ; I2 ) minimal interval contains I1 I2 . definition, easyshow, induction number operators connectives formula, IPEL formulasdefine internal events. One also verify definition satisfiability given earlier AMAformulas corresponds one give here.Appendix B. Omitted ProofsLemma 1. timeline model M, satisfies witnessinginterdigitation MAP(M) .Proof: Assume = hM; satisfies timeline = s1 ; : : : ; sn , let 0 =MAP(M). straightforward argue, induction length , exists mappingV 0 states sub-intervals ,2 V 0 (s), [i] satisfies s,V 0(s1) includes initial time point ,V 0(sn) includes final time point ,2 [1; n 1], V 0(si ) meets V 0(si+1) (see Table 4).430fiL EARNING EMPORAL E VENTSLet V relation states 2 members 2 true 2 V 0 (s). Noteconditions V 0 ensure every 2 every 2 appear tuple V (notnecessarily together). use V construct witnessing interdigitation W .Let R total, one-to-one, onto function time-points corresponding states 0 ,noting 0 one state time-point , 0 = MAP(hM; i). Note R preservesordering that, j , R(i) later R(j ) 0 . Let W composition V Rrelations V R.show W interdigitation. first show state 0 appearstuple W , W piecewise total. States must appear, trivially, appearstuple V , R total. States 0 appear 2 appears tuple V , Ronto states 0 .suffices show states , W (s; s0 ) W (t; t0 ) impliess0 later t0 0 , W simultaneously consistent. conditions defining V 0imply every number 2 V (s) less equal every j 2 V (t). order-preservationproperty R, noted above, implies every state s0 2 V R(s) later statet0 2 V R(t) 0 , desired. W interdigitation.argue W witnesses 0 . Consider 2 2 0 W (s; t).construction W , must 2 V 0 (s) ith state 0 . Since 0 = MAP(M),follows set true propositions [i]. Since 2 V 0 (s), know [i] satisfiess. follows t, s. 22 IPEL, model embeds model satisfies E satisfies E .Proof: Consider models = hM; M0 = hM 0 ; 0 embeds M0 , let= MAP(M) 0 = MAP(M0 ). Assume E 2 IPEL satisfied M0 , showE also satisfied M.know definition embedding 0 thus witnessing interdigitation W 0 Proposition 2. know one-to-one correspondencenumbers (I 0 ) states (0 ) denote state (0 ) corresponding 2 (i0 2 0 )Lemma 3. Esi (ti ). correspondence allows us naturally interpret W mapping V subsets0 subsets follows: I10 0 , V (I10 ) equals set 2 i0 2 I10 ,si co-occurs ti W . use following properties V ,001. I10 sub-interval 0 , V (I10 ) sub-interval .2. I10 sub-interval 0 , hM; V (I10 )i embeds hM 0 ; I10 i.3. I10 I20 sub-intervals 0 , r Allen relation, I10 rI20 iff V (I10 )rV (I20 ).4. I10 I20 sub-intervals 0 , V (S PAN (I10 ; I20 )) = PAN (V (I10 ); V (I20 )).5.V (I 0 ) = .sketch proofs properties. 1) Use induction length I10 ,definition interdigitation. 2) Since V (I10 ) interval, MAP(hM; V (I10 )i) well defined.MAP(hM; V (I10 )i) MAP(hM 0 ; I10 i) follows assumption embeds M0 . 3)Appendix A, see Allen relations defined terms relation natural431fiF ERN , G IVAN , & ISKINDnumber endpoints intervals. show V preserves (but <) singleton sets(i.e., every member V (fi0 g) every member V (fj 0 g) i0 j 0 ) V commutes set union. follows V preserves Allen interval relations. 4) Use factV preserves sense argued, along fact PAN (I10 ; I20 ) dependsminimum maximum numbers I10 I20 . 5) Follows definition interdigitationconstruction V .use induction number operators connectives E prove that, M0satisfies E , must M. base case E = prop, prop primitive proposition,true. Since M0 satisfies E , know prop true 0 [x0 ] x0 2 0 . Since W witnesses0 , know that, prop true 0 [x], prop true [x], x 2 V (x0 ).Therefore, since V (I 0 ) = , prop true 0 [x], x 2 , hence M0 satisfies E .inductive case, assume claim holds IPEL formulas fewer N operators connectiveslet E1 ; E2 two formulas. E = E1 _ E2 , claim triviallyholds. E = 3R E1 , R must subset set relations fs,f,d,=g. Notice Ewritten disjunction 3r E1 formulas, r single Allen relation R. Thus,suffices handle case R single Allen relation. Suppose E = 3fsg E1 . Since M0satisfies E , must sub-interval I10 0 I10 0 hM 0 ; I10 satisfies E1 . LetI1 = V (I10 ), know properties V V (I 0 ) = , and, hence, I1 . Furthermore, know hM; I1 embeds hM 0 ; I10 i, and, thus, inductive hypothesis, hM; I1satisfies E1 . Combining facts, get E satisfied M. Similar arguments holdremaining three Allen relations. Finally, consider case E = E1 ^R E2 , Rset Allen relations. Again, suffices handle case R single Allen relationr. Since M0 satisfies E = E1 ^r E2 , know sub-intervals I10 I20 0PAN (I10 ; I20 ) = 0 , I10 r I20 , hM 0 ; I10 satisfies E1 , hM 0 ; I20 satisfies E2 . facts,properties V , easy verify satisfies E . 2Lemma 5. Given formula subsumes member set formulas,also subsumes member 0 IG(). Dually, subsumed member ,also subsumed member 0 IS(). case, length 0bounded size .Proof: prove result IG(). proof IS() follows similar lines. Let=f1 ; : : : ; ng, = s1; : : : ; sm, assume 1 n, . Proposition 2, i, witnessing interdigitation Wi . combine Wiinterdigitation , show corresponding member IG() subsumed. construct interdigitation , first notice that, sj , Wi specifies setstates (possibly single state least one) co-occur sj . Furthermore, sinceWi interdigitation, easy show set states corresponds consecutive subsequence states let j;i timeline corresponding subsequence.let j = fj;i j 1 ng, ffj interdigitation j . take unionffj , 1 j m. show interdigitation . Since state appearingmust co-occur least one state sj least one Wi , least one tuple ffj ,and, hence, tuple piecewise total.Now, define restriction i;j components j , < j , relation giventaking set pairs formed shortening tuples omitting components except432fiL EARNING EMPORAL E VENTSith j th. Likewise define ffi;jk k . show interdigitation, sufficesshow i;j simultaneously consistent. Consider states si sj timelinesj , respectively, i;j (si ; sj ). Suppose ti occurs si i, tj 2 j ,i;j (ti ; tj ) holds. suffices show sj later tj j . Since i;j (si ; sj ) i;j (ti ; tj ),i;j00must ffi;jk (si ; sj ) ffk (ti ; tj ), respectively, k k . know k k0si ti Wi simultaneously consistent. k = k , sj later tj j ,ffk must simultaneously consistent, interdigitation. Otherwise, k < k 0 . sjlater tj j , desired, Wj simultaneously consistent. simultaneouslyconsistent, interdigitation .Let 0 member IG() corresponding . show 0 . knowstate s0 2 0 intersection states tuple ffj say s0 derivesffj . Consider interdigitation 0 0 , 0 (sj ; s0 ), sj 2 s0 2 0 ,s0 derives ffj . 0 piecewise total, every tuple 0 derives ffj , ffjempty. 0 simultaneously consistent tuples 0 deriving later ffk must laterlexicographic ordering , given simultaneous consistency Wk interdigitations usedconstruct ffj . Finally, know sj subsumes (i.e., subset of) state tupleffj , Wk witnessing interdigitation k , and, hence, subsumes (is subsetof) intersection states. Therefore, sj 2 co-occurs s0 2 0 0s0 sj . Thus, 0 witnessing interdigitation 0 , Proposition 2 0 .size bound 0 follows, since, pointed main text, size memberIG() upper-bounded number states . 20Lemma 8. Given timelines 1 = s1 ; : : : ; sm 2 = t1 ; : : : ; tn , witnessinginterdigitation 1 2 iff path subsumption graph SG(1 ; 2 ) v1;1vm;n .Proof: Subsumptiongraph SG(1 ; 2 ) equal hV; E V = fvi;j j 1 m; 1 j ngE = hvi;j ; vi ;j j si tj ; si tj ; i0 + 1; j j 0 j + 1 . Notecorrespondence vertices state tupleswith vertex vi;j corresponding hsi ; tj i.forward direction, assume W witnessing interdigitation 1 2 .know that, states si tj co-occur W , si tj since W witnesses 1 2 .vertices corresponding tuples W called co-occurrence vertices, satisfyfirst condition belonging edge E (that si tj ). follows definitioninterdigitation v1;1 vm;n co-occurrence vertices. Consider co-occurrencevertex vi;j equal vm;n , lexicographically least co-occurrence vertex vi ;j vi;j(ordering verticesorderingpair subscripts). show i, j , i0 , j 0 satisfyffrequirements vi;j ; vi ;j 2 E . not, either i0 > + 1 j 0 > j + 1. i0 > + 1,co-occurrence vertex vi+1;j , contradicting W piecewise total. j 0 > j + 1,since W piecewise total, must co-occurrence vertex vi ;j +1 : i00 <i00 > i0 , contradicts simultaneous consistency W , i00 = i, contradictslexicographically least choice vi ;j . follows every co-occurrence vertex vm;nedge another co-occurrence vertex closer Manhattan distance vm;n , thuspath v1;1 vm;n .reverse direction assume path vertices SG(1 ; 2 ) v1;1 vm;ngiven by, vi1 ;j1 ; vi2 ;j2 ; : : : ; vir ;js i1 = j1 = 1, ir = m; js = n. Let W set state00000000000004330fiF ERN , G IVAN , & ISKINDtuples corresponding vertices along path. W must simultaneously consistentorderings directed edges non-decreasing orderings. W mustpiecewise total edge cross one state transition either 1 2 ,edge set definition. W interdigitation. Finally, definition edge set E ensurestuple hsi ; tj W property si tj , W witnessing interdigitation1 2 , showing 1 2 , desired. 2Lemma 10. Given n, let conjunction timelinesn[i=1f(PROPn; Truei; Falsei; PROPn); (PROPn; Falsei; Truei; PROPn)g:following facts truth assignments Boolean variables p1 ; : : : ; pn :1. truth assignment A, PROPn ; sA ; PROPn semantically equivalent memberIS( ).2. 2 IS( ) truth assignment PROPn ; sA ; PROPn .Proof: prove first part lemma, construct interdigitationcorresponding member IS( ) equivalent PROPn ; sA ; PROPn . Intuitively, constructensuring tuple consists states form Truek Falsek agreetruth assignmentthe union states tuple, taken IS( ) equal sA . Let= fT0 ; T1 ; T2 ; T3 ; T4 g interdigitation exactly five state tuples Ti . assignstates timeline tuples follows:1. k , 1 kn A(pk ) true,timeline s1 ; s2 ; s3 ; s4 = Q; ruek ; F alsek ; Q, assign state si tuple Ti ,assign state s1 T0 well,timeline s01 ; s02 ; s03 ; s04 = Q; F alsek ; ruek ; Q, assign state s0i tuple Ti 1 ,state s04 tuple T4 well.2. k , 1 k n A(pk ) false, assign states tuples item 1interchanging roles ruek F alsek .clear piecewise total simultaneously consistent state orderings, interdigitation. union states T0 , T1 , T3 , T4 equalPROPn , since PROPn included state tuples. Furthermore, seeunion states T2 equal sA . Thus, member IS( ) corresponding equalPROPn ; PROPn ; sA ; PROPn ; PROPn , semantically equivalent PROPn ; sA ; PROPn ,desired.prove second part lemma, let member IS( ). first argueevery state must contain either Truek Falsek 1 k n. k , since contains PROPn ; Truek ; Falsek ; PROPn , every member IS( ) must subsumed PROPn ; Truek ;Falsek ; PROPn . So, subsumed PROPn ; Truek ; Falsek ; PROPn . every state PROPn ;Truek ; Falsek ; PROPn contains either Truek Falsek , implying , desired.434fiL EARNING EMPORAL E VENTSNext, claim 1 k n, either Truek Falsek i.e., either statesinclude Truek , states include Falsek (and possibly both). prove claim, assume,sake contradiction, that, k , 6 Truek 6 Falsek . Combining assumption first claim, see must states s0 contains ruekF alsek , s0 contains F alsek ruek , respectively. Consider interdigitationcorresponds member IS( ). know s0 equal unionstates tuples 0 , respectively, . 0 must include one state timelines1 ; s2 ; s3 ; s4 = PROPn ; Truek ; Falsek ; PROPn s01 ; s02 ; s03 ; s04 = PROPn ; Falsek ; Truek ; PROPn .Clearly, since include Falsek , includes states s1 s02 , likewise 0 includesstates s2 s01 . follows simultaneously consistent state orderingss1 ; s2 ; s3 ; s4 s01 ; s02 ; s03 ; s04 , contradicting choice interdigitation. showseither Truek Falsek .Define truth assignment 1 k n, A(pk ) Truek .Since,for k , Truek Falsek , follows state subsumedsA . Furthermore, since begins ends PROPn , easy give interdigitationPROPn ; sA ; PROPn witnesses PROPn ; sA ; PROPn . Thus,PROPn ; sA ; PROPn . 2Lemma 16. Let 1 2 given page 402, proof Theorem 17, let =VIG(f1 ; 2 g). 0 whose timelines subset omits squaretimeline, < 0 .Proof: Since timelines 0 subset timelines , know 0 . remainsshow 0 6 . show constructing timeline covered 0 , .Let = s1 ; s2 ; : : : ; s2n 1 square timeline included 0 . Recallsi single proposition proposition set P = fpi;j j 1 n; 1 j ng, that,consecutive states si si+1 , si = pi;j , si+1 either pi+1;j pi;j +1 . Define newtimeline = s2 ; s3 ; : : : ; s2n 2 si = (P si ). show 6 (so 6 ),that, 0 fg, 0 (so 0 ).sake contradiction, assume must interdigitation Wwitnessing . show induction that, 2, W (si ; sj ) implies j > i.base case, = 2, know s2 6 s2 , since s2 6 s2 , W (s2 ; s2 ) false, sinceW witnesses subsumption. inductive case, assume claim holds i0 < i,W (si ; sj ). know si 6 si , thus 6= j . W piecewise total, mustW (si 1 ; sj ) j 0 , and, induction hypothesis, must j 0 > 1. Since Wsimultaneously consistent sk sk state orderings, 1 < i, j 0 j .follows j > desired. Given claim, see s2n 2 cannot co-occur Wstate , contradicting fact W piecewise total. Thus 6 .Let 0 = s01 ; : : : ; s0m timeline fg, construct interdigitationwitnesses 0 . Note assumed square, 0 need be. Let j smallestindex sj 6= s0j since s1 = s01 = p1;1 , 6= 0 , know j must exist,range 2 j m. use index j guide construction interdigitation. Let Winterdigitation 0 , exactly following co-occurring states (i.e., state tuples):001. 1 j1, si+1 co-occurs s0i .435fiF ERN , G IVAN , & ISKINDm, sj co-occurs s0i.j + 1 2n 2, si co-occurs s0m .2. j3.easy check W piecewise total simultaneously consistent stateorderings , interdigitation. show W witnesses 0showing states subsumed states co-occur W . co-occurringstates si+1 s0i corresponding first item s0i = si implies s0icontained si+1 , giving si+1 s0i . consider co-occurring states sj s0isecond item above. Since square, choose k l sj 1 = pk;l , sj eitherpk+1;l pk;l+1. addition, since sj 1 = s0j 1 s0j either pk+1;l ; pk;l+1 pk+1;l+1sj 6= s0j . cases, find state 0 s0j equal sj followsnoting proposition indices never decrease across timeline 0 16 . thereforethat, j , sj s0i . Finally, co-occurring states si s0m item three above,si s0m , since s0m = pn;n, states . Thus, shown co-occurringstates W , state subsumed co-occurring state 0 . Therefore, W witnesses0 , implies 0 . 2Lemma 26. model hM; 2 2 AMA ,[hM; i].covers hM;iffF [ ] coversProof: Recall set models propositions set P = fp1 ; : : : ; pn gassume AMA uses primitive propositions P (possibly negated). alsoset propositions P = fp1 ; : : : ; pn g, assume formulas AMA use propositionsP [ P set models P [ P , i, exactly one pi pitrue time. Note F [ ] AMA [hM; i] M. prove lemma viastraightforward induction structure proving result literals, states,timelines, finally AMA formulas.prove result literals, consider two cases (the third case true trivial). First,single proposition pi , 0 = F [pi ] = pi . Consider model hM; 2 lethM 0 ; = [hM; i]. following relationships yield desired result.covers hM;iffiffiff2 , [i] assigns pi true2 , 0 [i] assigns pi true0 = pi covers [hM; i](by definition satisfiability)(by definition )(by definition satisfiability)second case negated proposition :3pi here, get 0 = pi . LethM; 2 hM 0 ; = [hM; i]. following relationships yield desired result.covers hM;iffiffiff2 , [i] assigns pi false2 , 0 [i] assigns pi true0 = pi covers [hM; i](by definition satisfiability)(by definition )(by definition satisfiability)proves lemma literals.16. Notepk+1;l+1 .required square possible +1 equal0sj436sji.e., could equalfiL EARNING EMPORAL E VENTSprove result states, use induction number k literals state. basecase k = 1 (the state single literal) proven above. assume lemmaholds states k fewer literals let = l1 ^ ^ lk+1 hM; 2 M.inductive assumption know = l1 ^ ^ lk covers hM; iff F [] covers [hM; i].base case also know lk+1 covers hM; iff F [lk+1 ] covers [hM; i]. factsdefinition satisfiability states, get covers hM; iff F [] ^ F [lk+1 ] covers[hM; i]. Clearly F property F [] ^ F [lk+1 ] = F [ ], showing lemma holdsstates.prove result timelines, use induction number k states timeline.base case k = 1 (the timeline single state) proven above. assumelemma holds timelines k fewer states. Let = s1 ; : : : ; sk+1 hM; [t; t0 ]i 2hM 0 ; [t; t0 ]i = [hM; [t; t0 ]i]. following relationships.covers hM; [t; t0 ]iiffiffiffiffexists t00 2 [t; t0 ], s1 covers hM; [t; t00 ]i= s2 ; : : : ; sk+1 covers either hM; [t00 ; t0 ]i hM; [t00 + 1; t0 ]iexists t00 2 [t; t0 ], F [s1 ] covers hM 0 ; [t; t00 ]iF [] covers either hM 0 ; [t00 ; t0 ]i hM 0 ; [t00 + 1; t0 ]iF [s1 ]; F [] covers hM 0 ; [t; t0 ]iF [ ] covers hM 0 ; [t; t0 ]ifirst iff follows definition satisfiability; second follows inductivehypothesis, base case, fact [t; t0 ] [hM; i] = hM 0 ; i; thirdfollows definition satisfiability; fourth follows fact F [s1 ]; F [] =F [ ].Finally, prove result AMA formulas, induction number k timelinesformula. base case k = 1 (the formula single timeline) provenabove. assume lemma holds AMA formulas k fewer timelineslet = 1 ^ ^ k+1 hM; 2 M. inductive assumption, know0 = 1 ^ ^ k covers hM; iff F [ 0 ] covers [hM; i]. base case, alsoknow k+1 covers hM; iff F [k+1 ] covers [hM; i]. facts definitionsatisfiability, get covers hM; iff F [ 0 ] ^ F [k+1 ] covers [hM; i]. Clearly Fproperty F [ 0 ] ^ F [k+1 ] = F [ ], showing lemma holds AMA formulas.completes proof. 2Appendix C. Hand-coded Learned Definitions Used Experimentsgive two sets hand-coded definitions, HD1 HD2 , used experimentalevaluation. also give set learned AMA event definitions seven event types.learned definitions correspond output k -AMA learning algorithm, given availabletraining examples (30 examples per event type), k = 3 = BN. event definitionswritten event logic, :3p denotes negation proposition p.437fiF ERN , G IVAN , & ISKIND104P ICK U P (x; y; z )=P UT OWN(x; y; z )=TACK (w; x; y; z )=U NSTACK (w; x; y; z )=OVE(w; x; y; z )SSEMBLE(w; x; y; z )ISASSEMBLE(w; x; y; z )44444=4==:3x = ^ :3z = x ^ :3z = y^CB UPPORTED(y ) ^ :3ATTACHED(x; z )^B 8 23 9 CCB >:3ATTACHED(x; y) ^ :3S UPPORTS(x; y)^>>CB >>7>CB >>6UPPORTS (z; )^>7>CB >>6>7>CB >>6:3UPPORTED(x) ^ :3ATTACHED(y; z )^ 7 ; >>CB >>6>>CB >>54:3S UPPORTS(y; x) ^ :3S UPPORTS(y; z )^>>CB >>>>B >>:3S UPPORTS(x; z ) ^ :3S UPPORTS(z; x)= CCB <CBB > [2ATTACHED(x; ) _ ATTACHED(y; z )] ;3 > C>CB >ATTACHED(x; ) ^ UPPORTS(x; )^>>CB >>>67>CB >>:3S UPPORTS(z; y)^>67>CB >>>67>CB >>:3UPPORTED(x)^:3TTACHED(y;z)^>67>CB >>>>>45@ >:3UPPORTS(y;x)^:3UPPORTS(y;z)^>>>>;::3S UPPORTS(x; z ) ^ :3S UPPORTS(z; x)10:3x = ^ :3z = x ^ :3z = y^CB UPPORTED(y ) ^ :3ATTACHED(x; z )^B 8 23 9 CCB >TTACHED(x; ) ^ UPPORTS (x; )^>>CB >>>C7B >>6:3UPPORTS(z;)^>>C7B >>6>>CB >>67:3UPPORTED(x)^:3TTACHED(y;z)^;>>CB >>67>>CB >>45:3UPPORTS(y;x)^:3UPPORTS(y;z)^>>CB >>>>B >>:3UPPORTS(x;z)^:3UPPORTS(z;x)= CCB <CBB > [2ATTACHED(x; ) _ ATTACHED(y; z )] ;3 > C>CB >TTACHED(x; ) ^ :3 UPPORTS(x; )^:3>>> CB >7 >>CB >>6 UPPORTS (z; )^>>7 > CB >6>CB >>6 :3S UPPORTED(x) ^ :3ATTACHED(y; z )^ 7 >>>7 > CB >6>>@ >4 :3S UPPORTS(y; x) ^ :3S UPPORTS(y; z )^ 5 >>>>>;::3S UPPORTS(x; z ) ^ :3S UPPORTS(z; x)32:3z = w ^ :3z = x ^ :3z = y^4 P UT OWN(w; x; ) ^ UPPORTS(z; )^ 5:ATTACHED(z; y):3z = w ^ :3z = x ^ :3z = y^P ICK U P (w; x; ) ^ UPPORTS(z; ) ^ :ATTACHED(z; ):3y = z ^ [P ICK U P(w; x; y); P UT OWN(w; x; z )]P UT OWN(w; y; z ) ^f g TACK (w; x; y; z )U NSTACK(w; x; y; z ) ^f g P ICK U P (x; y; z )<<Figure 12: HD1 event-logic definitions seven event types.438fiL EARNING EMPORAL E VENTS01:3x = ^ :3z = x ^ :3z = y^BC(y) ^ :3ATTACHED (x; z )^B UPPORTEDC39 CB 8 2B >CTTACHED (x; ) ^ :3S UPPORTS (x; )^:3>>B >C> 6>7>B >C> 6 UPPORTS (z; ) ^ C ONTACTS (z; )^>7>B >C>>76>B >C> 6 :3S UPPORTED (x) ^ :3ATTACHED (y; z )^ 7 ^f<;mg >>B >C>>76>B >C>> 4 :3S UPPORTS (y; x) ^ :3S UPPORTS (y; z )^ 5>4B >C>>>P ICK U P (x; y; z ) = B >= C<BCUPPORTS (x; z ) ^ :3S UPPORTS (z; x):33B2CB >C>TTACHED(x;)^UPPORTS(x;)^>B >C>> 6>7B >C>>:3UPPORTS(z;)^>67B >C>> 6>7B >C>>>:3UPPORTED(x)^:3TTACHED(y;z)^67B >C> 6>>7B >C>>>45@ >:3UPPORTS(y;x)^:3UPPORTS(y;z)^>>>>;::3S UPPORTS(x; z) ^ :3S UPPORTS(z; x)01:3x = ^ :3z = x ^ :3z = y^CB(y) ^ :3ATTACHED (x; z )^CB UPPORTED39 CB 8 2CB >TTACHED (x; ) ^ UPPORTS (x; )^>>CB >>> 67>CB >>>UPPORTS(z;)^:376>CB >>> 67>CB >>>:3UPPORTED(x)^:3TTACHED(y;z)^^76>f<;gCB >>>7> C> 6B >>54>:3UPPORTS(y;x)^:3UPPORTS(y;z)^4 B>C>>>P UT (x; y; z ) = B >= C<CB:3UPPORTS (x; z ) ^ :3S UPPORTS (z; x)3CB2CB >>:3ATTACHED (x; y) ^ :3S UPPORTS(x; y)^>CB >>>>67CB >>> 6 UPPORTS (z; ) ^ C ONTACTS (z; )^>7CB >>>>67B >C>> 6 :3S UPPORTED (x) ^ :3ATTACHED (y; z )^ 7>B >C>>>67B >> C>>4 :3S UPPORTS (y; x) ^ :3S UPPORTS (y; z )^ 5@ >>>>>;::3S UPPORTS(x; z) ^ :3S UPPORTS(z; x)Figure 13: Part HD2 event-logic definitions.439fiF ERN , G IVAN , & ISKIND01:3w = x ^ :3y = w ^ :3y = x^B :3z = w ^ :3z = x ^ :3z = ^CBCB UPPORTED (x) ^ :3ATTACHED(w; )^CB 8 29 C3B >CATTACHED(w; x) ^ UPPORTS (w; x)^>B >>C> 6>B >7>C:3UPPORTS(y; x)^>B >>7>6C> 6>B >7>CUPPORTS(z; ) ^ C ONTACTS(z; )^>B >7>6>C> 6>B >7C>:3ATTACHED(z; )^^fmg >B >76C>>> 6>7B >C>:3UPPORTED(w) ^ :3ATTACHED(x; )^ 7>B >6C>>> 4>B >C>5:3S UPPORTS(x; w) ^ :3S UPPORTS(x; y)^>B >>>= CB <CBC2 :3S UPPORTS(w; ) ^ :3S UPPORTS(y; w)3B >C:3ATTACHED(w; x) ^ :3S UPPORTS(w; x)^>B >C>>B >C67>>UPPORTS(y; x) ^ C ONTACTS (y; x)^>B >C67>>>B >C67>>>B >C6 UPPORTS(z; ) ^ C ONTACTS(z; )^7>>>>B >C67>>B >C7> 6 :3ATTACHED(z; )^>>>B >C67>>B >C> 6 :3S UPPORTED(w) ^ :3ATTACHED(x; )^ 7>>>>@ >45:3S UPPORTS(x; w) ^ :3S UPPORTS(x; y)^>>>>:;:3S UPPORTS(w; y) ^ :3S UPPORTS(y; w)10:3w = x ^ :3y = w ^ :3y = x^CB :3z = w ^ :3z = x ^ :3z = ^CBCB UPPORTED(x) ^ :3ATTACHED(w; )^9 CB 8 23CB >:3ATTACHED(w; x) ^ :3S UPPORTS(w; x)^>C>B >>C>6B >7>>C>6 UPPORTS (y; x) ^ C ONTACTS (y; x)^B >7>>>C>6B >7>C>B >7> 6 UPPORTS (z; ) ^ C ONTACTS (z; )^>>C>6B >7C>6 :3ATTACHED(z; )^B >7 ^f mg >>>>C>6B >7>C>B >> 6 :3S UPPORTED(w) ^ :3ATTACHED(x; )^ 7>>C>B >45:3S UPPORTS(x; w) ^ :3S UPPORTS(x; y)^>C>B >>=<CBCB2 :3S UPPORTS(w; ) ^ :3S UPPORTS(y; w) 3CB >ATTACHED(w; x) ^ UPPORTS(w; x)^>C>B >>>6C7>B >>C7>B >> 6 :3S UPPORTS(y; x)^>>6C7>B >>6 UPPORTS (z; ) ^ C ONTACTS (z; )^C7>B >>>>6C7>B >>C7>B >> 6 :3ATTACHED(z; )^>>6C7>B >>C>B >> 6 :3S UPPORTED(w) ^ :3ATTACHED(x; )^ 7>>>45@ >:3S UPPORTS(x; w) ^ :3S UPPORTS(x; y)^>>>>;::3S UPPORTS(w; y) ^ :3S UPPORTS(y; w):3y = z ^ [P ICK U P(w; x; y); P UT OWN(w; x; z )]P UT OWN(w; y; z ) ^f g TACK (w; x; y; z )U NSTACK (w; x; y; z ) ^f g P ICK U P (x; y; z )<;TACK(w; x; y; z )4=<;U NSTACK(w; x; y; z )OVE(w; x; y; z )SSEMBLE(w; x; y; z )ISASSEMBLE(w; x; y; z )4=44=4==<<Figure 14: Part II HD2 event-logic definitions.440fiL EARNING EMPORAL E VENTS3 90 8 2UPPORTED (y ) ^ UPPORTS (z; )^>>>>>B >> 4 C ONTACTS (y; z ) ^ : UPPORTS(x; )^5; >>>B >>>>B >>: ATTACHED(x; y) ^ : ATTACHED(y; z )=B <BUPPORTED(y );B > 23 >^>B >UPPORTED (y ) ^ UPPORTS (x; )^>>>B >>>B >>54ATTACHED(x; ) ^ : UPPORTS(z; )^>>>B >;:B: C ONTACTS(y; z ) ^ : ATTACHED(y; z9)B 8B > UPPORTED(y );>B >>=B <UPPORTED(y ) ^ ATTACHED(x; )^B;^B >ATTACHED(y; z )>B >>:;BB 8 [S UPPORTED(y ) ^ ATTACHED(x; )] 9B < [S UPPORTED(y ) ^ C ONTACTS (y; z )] ; =BBB : [S UPPORTED(y ) ^ ATTACHED(y; z )] ; ; ^BB 8 [2S UPPORTED(y ) ^ ATTACHED(x; )]3 9B >UPPORTED (y ) ^ UPPORTS (z; )^>>B >>> 4 C ONTACTS (y; z ) ^ : UPPORTS(x; )^B >5; >=B <B:TTACHED(x; ) ^ : ATTACHED(y; z )^B >>>B >[UPPORTED()^UPPORTS(z;)];>>>B >;B : [S UPPORTED(y ) ^ ATTACHED(x; )]9B 8B > [S UPPORTED(y ) ^ UPPORTS (z; )] ;>>B >>>> [S UPPORTED(y ) ^ ATTACHED(x; )] ;B >B < 23 =BUPPORTED() ^ UPPORTS (x; )^B >>5 >@ >>> 4 ATTACHED(x; ) ^ : UPPORTS(z; )^>>:;3333P ICK U P (x; y; z )4=333333:3C ONTACTS(y; z ) ^ :3ATTACHED(y; z )P UT OWN(x; y; z )4=1CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC3 90 8 2UPPORTED(y ) ^ UPPORTS(x; ) ^ ATTACHED(x; )^>>>>> 4 : UPPORTS(z; ) ^ : C ONTACTS(y; z )^>B >5; >>B >>>=B <: ATTACHED(y; z )B^B > UPPORTED (y );>>B >>>>B >UPPORTED(y ) ^ UPPORTS (z; ) ^ C ONTACTS(z; )^>B >>>;B ::UPPORTS(x; ) ^ :TTACHED(x; )B 89B <BUPPORTED (y ) ^ ATTACHED(x; ) ;=@UPPORTED (y ) ^ ATTACHED(x; ) ^ ATTACHED(y; z ) ;:;33333UPPORTED (y )Figure 15: learned 3-AMA definitions P ICK U P (x; y; z ) P UT (x; y; z ).4411CCCCCCCCCCCCfiF ERN , G IVAN , & ISKIND0 8>>B <BB >B >B :B (BBBBB (BBBBB (BBBBB (BBBBB (BBBBB 8B <BBB :BB (BBBBB (BBBBB 8BB <BBB :B 8BB <BBB :BB (BBBBB 8B <BBB :BB 8B >B >B <B@ >>:h^^^^UPPORTED(y ) ATTACHED(w; x) UPPORTS(z; ) C ONTACTS(y; z )UPPORTS(x; )UPPORTS(y; x)C ONTACTS(x; )ATTACHED(x; ):3^ :3^ :3^ :3;9>>=1CC>^ CUPPORTED(y ) ^ UPPORTED(x) ^ UPPORTS(y; x) ^ C ONTACTS(x; ) ^ C ONTACTS(y; z )^>; CC:3S UPPORTS(x; y) ^ :3ATTACHED(w; x) ^ :3ATTACHED(x; y) ^ :3)ATTACHED(y; z)CC[S UPPORTED(y) ^ ATTACHED(w; x)] ;C[S UPPORTED(y) ^ ATTACHED(x; y)] ;^CC[S UPPORTED(y) ^ UPPORTED(x) ^ UPPORTS(y; x) ^ C ONTACTS(x; y)])CC[S UPPORTED(y) ^ ATTACHED(w; x)] ;[S UPPORTED(y) ^ UPPORTS(x; y) ^ ATTACHED(w; x) ^ ATTACHED(x; y) ^ ATTACHED(y; z)] ; ^ CCC[S UPPORTED(y) ^ UPPORTED(x)S UPPORTS(y; x)])CC[S UPPORTED(y) ^ ATTACHED(w; x)] ;C[S UPPORTED(y) ^ UPPORTED(x) ^ UPPORTS(x; y) ^ UPPORTS(y; x) ^ ATTACHED(w; x)] ; ^CC[S UPPORTED(y) ^ UPPORTED(x) ^ UPPORTS(y; x)])CC[S UPPORTED(y) ^ ATTACHED(w; x) ^ UPPORTS(z; y) ^ C ONTACTS(y; z)] ;C[S UPPORTED(y) ^ ATTACHED(y; z)] ;^CC[S UPPORTED(y) ^ UPPORTED(x) ^ UPPORTS(y; x) ^ C ONTACTS(y; z)] )CC[S UPPORTED(y) ^ ATTACHED(w; x) ^ UPPORTS(z; y) ^ C ONTACTS(y; z)] ;C[S UPPORTED(y) ^ ATTACHED(w; x) ^ ATTACHED(y; z)] ;^CC[hS UPPORTED(y) ^ UPPORTED(x) ^ UPPORTS(y; x)]9CUPPORTED(y ) ^ ATTACHED(w; x) ^ UPPORTS(z; ) ^ C ONTACTS(y; z )^C=;C:3S UPPORTS(x; y) ^ :3S UPPORTS(y; x) ^ :3C ONTACTS(x; y) ^ :3ATTACHED(x; y)C^C[S UPPORTED(y) ^ ATTACHED(w; x)] ;;C[S UPPORTED(y) ^ UPPORTED(x) ^ UPPORTS(y; x)]C)C[S UPPORTED(y) ^ ATTACHED(w; x)] ;C[S UPPORTED(y) ^ ATTACHED(w; x) ^ UPPORTS(z; y) ^ C ONTACTS(y; z)] ; ^CC[S UPPORTED(y) ^ UPPORTED(x)]C)C[S UPPORTED(y) ^ ATTACHED(w; x)] ;C[S UPPORTED(y) ^ ATTACHED(w; x) ^ UPPORTS(z; y) ^ UPPORTED(x)] ; ^CC[S UPPORTED(y) ^ UPPORTED(x)]C9C[hS UPPORTED(y) ^ ATTACHED(w; x)] ;=CUPPORTED(y ) ^ C ONTACTS(y; z ) ^ UPPORTS(z; ) ^ UPPORTED(x)^C;^C:3S UPPORTS(x; y) ^ :3ATTACHED(x; y);CC[S UPPORTED(y) ^ UPPORTED(x)]9CUPPORTED(y );Ch=CUPPORTED(y ) ^ C ONTACTS(y; z ) ^ UPPORTS(z; ) ^ UPPORTED(x)^^;C:3S UPPORTS(x; y) ^ :3ATTACHED(x; y) ^ :3ATTACHED(y; z)C;C[S UPPORTED(y) ^ UPPORTED(x) ^ UPPORTS(y; x)] )CC[S UPPORTED(y) ^ ATTACHED(w; x)] ;C[S UPPORTED(y) ^ C ONTACTS(y; z) ^ UPPORTED(x)] ; ^CC[S UPPORTED(y) ^ UPPORTED(x) ^ UPPORTED(y)x]9 C[S UPPORTED(y) ^ ATTACHED(w; x)] ;= CC[hS UPPORTED(y) ^ UPPORTED(x) ^ UPPORTS(y; x)] ;^CUPPORTED(y ) ^ UPPORTED(x) ^ UPPORTS(y; x) ^ C ONTACTS(x; ) ^ C ONTACTS(y; z )^; CC:3S UPPORTS(x; y) ^ :3ATTACHED(w; x) ^ :3ATTACHED(x; y) ^ :3ATTACHED(y; z)9 CUPPORTED(y );> Ch>= CUPPORTED(y ) ^ UPPORTED(x) ^ UPPORTS(y; x) ^ UPPORTS(z; )^C;CCONTACTS(x; ) ^ C ONTACTS(y; z )h>UPPORTED(y ) ^ UPPORTED(x) ^ UPPORTS(y; x) ^ C ONTACTS(x; ) ^ C ONTACTS(y; z )^>;[S UPPORTED(y)] ;h:3S UPPORTS(x; y) ^ :3ATTACHED(w; x) ^ :3ATTACHED(x; y) ^ :3ATTACHED(y; z)Figure 16: learned 3-AMA definition TACK (w; x; y; z ).442fiL EARNING EMPORAL E VENTS0 8>>B >>B >>B >>B <BB >B >>B >B >>>B >B :BB (BBBBB (BBBBBB (BBBBB (BBBBB 8BB >>B >>B >B <BB >B >>B >:B >B 8BB >>B >>B >B <BB >B >>B >>B :BB (BBBBB 8BB ><BBB >B :BB (BBBBB (BBBBBB 8B >B <B@>:"#9UPPORTED(x) ^ UPPORTED(y ) ^ UPPORTS(y; x)^>>>;C ONTACTS(x; ) ^ C ONTACTS(y; z ) ^ :3S UPPORTS(w; x)^>>>>:3S UPPORTS(x; y) ^ :3ATTACHED(w; x) ^ :3ATTACHED(x; y)>=[2S UPPORTED(x) ^ UPPORTED(y)] ;3^UPPORTED(x) ^ UPPORTED(y ) ^ ATTACHED(w; x) ^ UPPORTS(z; )^>>>6 C ONTACTS(y; z ) ^ ATTACHED(w; x) ^ :3S UPPORTS(x; )^7 >>45 >>:3S UPPORTS(y; x) ^ :3C ONTACTS(x; y)^>;:3ATTACHED(x; y) ^ :3ATTACHED(y; z))[S UPPORTED(x) ^ UPPORTED(y) ^ UPPORTS(y; x)] ;[S UPPORTED(x) ^ UPPORTED(y) ^ ATTACHED(w; x) ^ ATTACHED(y; z)] ; ^[S UPPORTED(x) ^ UPPORTED(y) ^ ATTACHED(w; x) ^ C ONTACTS(y; z)] )[S UPPORTED(x) ^ UPPORTED(y) ^ UPPORTS(y; x) ^ C ONTACTS(y; z)] ;[S UPPORTED(x) ^ UPPORTED(y) ^ ATTACHED(y; z)] ;^[S UPPORTED(x) ^ UPPORTED(y) ^ ATTACHED(w; x) ^ C ONTACTS(y; z)] )[S UPPORTED(x) ^ UPPORTED(y) ^ UPPORTS(y; x) ^ C ONTACTS(x; y)] ;[S UPPORTED(x) ^ UPPORTED(y) ^ UPPORTS(y; x) ^ ATTACHED(x; y)] ; ^[S UPPORTED(x) ^ UPPORTED(y) ^ ATTACHED(w; x)] )[S UPPORTED(x) ^ UPPORTED(y) ^ UPPORTS(y; x)] ;[S UPPORTED(x) ^ UPPORTED(y) ^ C ONTACTS(y; z)] ; ^[S UPPORTED(x) ^ UPPORTED(y) ^ ATTACHED(w; x)]9[S UPPORTED(x) ^ UPPORTED(y) ^ UPPORTS(y; x)] ;>>>>[2S UPPORTED(x) ^ UPPORTED(y) ^ ATTACHED(w; x)] ;3 >=UPPORTED(x) ^ UPPORTED(y ) ^ ATTACHED(w; x) ^ UPPORTS(z; )^^7 >6 C ONTACTS(y; z ) ^ ATTACHED(w; x) ^ :3S UPPORTS(x; )^5 >4>>:3S UPPORTS(y; x) ^ :3C ONTACTS(x; y)^>;ATTACHED(x; ) ^ :3ATTACHED(y; z ):323 9UPPORTED(x) ^ UPPORTED(y ) ^ UPPORTS(y; x)^>>>6 C ONTACTS(x; ) ^ C ONTACTS(y; z )^7 >>45; =:3S UPPORTS(w; x) ^ :3S UPPORTS(x; y)^^:3ATTACHED(w; x) ^ :3ATTACHED(x; y)>>>>[S UPPORTED(x) ^ UPPORTED(y) ^ UPPORTS(y; x)] ;>;[S UPPORTED(x) ^ UPPORTED(y) ^ ATTACHED(w; x)][S UPPORTED(x) ^ UPPORTED(y) ^ UPPORTS(y; x) ^ C ONTACTS(y; z)] ; )[S UPPORTED(x) ^ UPPORTED(y) ^ UPPORTS(y; x) ^ ATTACHED(y; z)] ; ^[S UPPORTED(x) ^ UPPORTED(y) ^ ATTACHED(w; x)]9[S UPPORTED(x) ^ UPPORTED(y) ^ UPPORTS(y; x)] ;>=UPPORTED(x) ^ UPPORTED(y ) ^ UPPORTS(y; x) ^ ATTACHED(y; z )^^;UPPORTS(x; ) ^ ATTACHED(w; x) ^ ATTACHED(x; )>;[S UPPORTED(x) ^ UPPORTED(y) ^ ATTACHED(w; x)])[S UPPORTED(x) ^ UPPORTED(y)] ;[S UPPORTED(x) ^ UPPORTED(y) ^ UPPORTS(y; x) ^ ATTACHED(w; x)] ; ^[S UPPORTED(x) ^ UPPORTED(y) ^ UPPORTS(w; x) ^ ATTACHED(w; x)] )[S UPPORTED(x) ^ UPPORTED(y) ^ UPPORTS(y; x)] ;[S UPPORTED(x) ^ UPPORTED(y) ^ UPPORTS(w; x) ^ ATTACHED(w; x)] ; ^[S UPPORTED(x) ^ UPPORTED(y) ^ ATTACHED(w; x)]9[S UPPORTED(x) ^ UPPORTED(y) ^ UPPORTS(y; x)] ;>=UPPORTED(x) ^ UPPORTED(y ) ^ C ONTACTS(y; z )^;:3S UPPORTS(x; y) ^ :3ATTACHED(x; y) ^ :3ATTACHED(y; z)>;[S UPPORTED(x) ^ UPPORTED(y)]Figure 17: learned 3-AMA definition U NSTACK (w; x; y; z ).4431CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCfiF ERN , G IVAN , & ISKIND0 8>>>B >>B >>B >>B >B <BB >B >>B >>B >>B >>B >B :B 8B >B <BBB >B :B 8B >B <BBB >B :B 8B >B <BBB >B :B 8B >B <BBB >B :B 8B >B <BBB >B :B 8B >B <B@>:264UPPORTED (x) ^ UPPORTS (y; x) ^ C ONTACTS (y; x)^:3S UPPORTS(w; x) ^ :3S UPPORTS(z; x) ^ :3C ONTACTS(x; z)^:3ATTACHED(w; x) ^ :3ATTACHED (y; x) ^ :3ATTACHED (x; z)375UPPORTED (x);UPPORTED (x) ^ UPPORTS (z; x) ^ C ONTACTS (x; z )^6:4 3S UPPORTS (w; x) ^ :3S UPPORTS (y; x) ^ :3C ONTACTS (y; x)^:3ATTACHED(w; x) ^ :3ATTACHED9(y; x) ^ :3ATTACHED (x; z)[S UPPORTED (x) ^ UPPORTS (y; x)] ; >=[S UPPORTED (x) ^ ATTACHED (w; x)] ; > ^;UPPORTED (x)9>UPPORTED (x);=[S UPPORTED (x) ^ ATTACHED (w; x) ^ ATTACHED (x; z )] ; > ^;UPPORTED (x)9>[S UPPORTED (x)] ;=[S UPPORTED (x) ^ ATTACHED (x; z )] ; > ^[S UPPORTED (x) ^ C ONTACTS (x; z )] ;9>UPPORTED (x);=[S UPPORTED (x) ^ ATTACHED (w; x) ^ UPPORTS (w; x)] ; > ^;UPPORTED (x)9>UPPORTED (x);=[S UPPORTED (x) ^ ATTACHED (w; x) ^ ATTACHED (y; x)] ; > ^;UPPORTED (x)9[S UPPORTED (x) ^ C ONTACTS (y; x)] ; >=[S UPPORTED (x) ^ ATTACHED (y; x)] ; >;UPPORTED (x)2Figure 18: learned 3-AMA definition OVE (w; x; y; z ).444375;9>>>>>>>>>>=>>>>>>>>>>;1^CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCfiL EARNING EMPORAL E VENTS0 8>>>B >>>B >B >>>B <BBB >B >>B >>B >>B >>B >:BB 8B >B >B >>B ><BBB >B >>B >>B :B 8BB >B <BB >B :B 8BB >B <BB >B :B 8BB >B <BB >B :B 8BB >B <@>:239:3S UPPORTED (x) ^ :3S UPPORTS(z; y) ^ :3S UPPORTS(y; x)^ 7 >>>6>:4 3C ONTACTS (x; ) ^ :3C ONTACTS (z; )^5; >>>>>>:3ATTACHED(w; x) ^ :3ATTACHED (z; y)=true;2642643UPPORTED (x) ^ UPPORTED (y ) ^ UPPORTS (z; )^7UPPORTS (y; x) ^ C ONTACTS (x; )^5C ONTACTS (z; ) ^ :3ATTACHED (w; ):3S UPPORTED (x) ^ :3S UPPORTS(z; y) ^ :3S UPPORTS(y; x)^:3C ONTACTS(x; y) ^ :3C ONTACTS(z; y)^:3ATTACHED(w; x) ^ :3ATTACHED (z; y)ATTACHED (w; );UPPORTED (y )9>=true;375;>>>>>>>>>>;9>>>>>=>>>>>;[S UPPORTED (y) ^ :3ATTACHED (w; x) ^ :3ATTACHED (z; y)] ; > ^;UPPORTED (y )9>true;=[S UPPORTED (y) ^ ATTACHED (z; y)] ; > ^[S UPPORTED (y) ^ C ONTACTS (z; y)] ;true;[S UPPORTED (y) ^ UPPORTS (z; y)C ONTACTS (z; y) ^ ATTACHED (w; x)] ;UPPORTED (y )9>true;=[S UPPORTED (y) ^ ATTACHED (w; y)ATTACHED (z; y)] ; >;UPPORTED (y )Figure 19: learned 3-AMA definition SSEMBLE (w; x; y; z ).4451^^9>=>;^CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCfiF ERN , G IVAN , & ISKIND0 8>>B >>B >>B >>B >>B <BB >B >B >>B >>B >>B >>B :B 8B >B >B <BB >B >B :B 8B >B >B <BB >B >B :B 8B >B >B <BB >B >B :B 8B >B >B <BB >B >B :B 8B <BBB :BB 8B <B@:329UPPORTED (x) ^ UPPORTED(y ) ^ UPPORTS(y; x) ^ UPPORTS (z; )^>>7 >>6 C ONTACTS (x; ) ^ C ONTACTS(z; ) ^ : UPPORTS(w; x)^7; >>6>5 >4 : UPPORTS(w; ) ^ : UPPORTS(x; ) ^ : ATTACHED(x; w)^>>=: ATTACHED(w; y) ^ : ATTACHED(x; y) ^ : ATTACHED(z; y)^UPPORTED(y );>>23>>UPPORTED (y ) ^ : UPPORTED(x) ^ : UPPORTS(w; x)^>>>>4 : UPPORTS(z; ) ^ : UPPORTS(y; x) ^ : C ONTACTS(x; )^ 5 ;>>;: C ONTACTS(z; y) ^ : ATTACHED(x; w) ^ : ATTACHED9(z; y)[ UPPORTED (x) ^ UPPORTED (y )] ;>>=UPPORTED(x) ^ UPPORTED (y ) ^ UPPORTS (w; x)^^;UPPORTS(z; ) ^ C ONTACTS (z; ) ^ ATTACHED(x; w)>>;UPPORTED(y )9UPPORTED(x) ^ UPPORTED (y ) ^ UPPORTS (z; )^>>;=UPPORTS(y; x) ^ C ONTACTS (x; ) ^ C ONTACTS(z; )^[ UPPORTED (x) ^ UPPORTED (y ) ^ UPPORTS (y; x) ^ ATTACHED (x; )] ; >>;UPPORTED(y )9[ UPPORTED (x) ^ UPPORTED (y ) ^ UPPORTS (y; x) ^ C ONTACTS (z; )] ; >>=UPPORTED(x) ^ UPPORTED (y ) ^ UPPORTS (x; )^;^UPPORTS(y; z ) ^ ATTACHED(x; ) ^ ATTACHED(z; )>>;UPPORTED(y )9[ UPPORTED (x) ^ UPPORTED (y ) ^ UPPORTS (y; x)] ;>>=UPPORTED(x) ^ UPPORTED (y ) ^ UPPORTS (x; )^;^UPPORTS(y; z ) ^ ATTACHED(x; ) ^ ATTACHED(z; ) ^ ATTACHED(x; w)>>;UPPORTED(y )9UPPORTED(y );=[ UPPORTED (y ) ^ ATTACHED (w; ) ^ ATTACHED (z; )] ;^;UPPORTED(y )9UPPORTED(y );=[ UPPORTED (y ) ^ UPPORTS (w; ) ^ ATTACHED (w; )] ;;UPPORTED(y )333333333333333Figure 20: learned 3-AMA definition ISASSEMBLE (w; x; y; z ).4461CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCfiL EARNING EMPORAL E VENTSReferencesAgrawal, R., & Srikant, R. (1995). Mining sequential patterns. Proceedings EleventhInternational Conference Data Engineering, pp. 314.Allen, J. F. (1983). Maintaining knowledge temporal intervals. Communications ACM,26(11), 832843.Angluin, D. (1987). Learning regular sets queries counterexamples. InformationComputation, 75, 87106.Bacchus, F., & Kabanza, F. (2000). Using temporal logics express search control knowledgeplanning. Artificial Intelligence, 16, 123191.Bobick, A. F., & Ivanov, Y. A. (1998). Action recognition using probabilistic parsing. Proceedings IEEE Computer Society Conference Computer Vision Pattern Recognition,pp. 196202, Santa Barbara, CA.Borchardt, G. C. (1985). Event calculus. Proceedings Ninth International Joint ConferenceArtificial Intelligence, pp. 524527, Los Angeles, CA.Brand, M. (1997a). inverse Hollywood problem: video scripts storyboards viacausal analysis. Proceedings Fourteenth National Conference Artificial Intelligence, pp. 132137, Providence, RI.Brand, M. (1997b). Physics-based visual understanding. Computer Vision Image Understanding, 65(2), 192205.Brand, M., & Essa, I. (1995). Causal analysis visual gesture understanding. ProceedingsAAAI Fall Symposium Computational Models Integrating Language Vision.Brand, M., Oliver, N., & Pentland, A. (1997). Coupled hidden Markov models complex actionrecognition. Proceedings IEEE Computer Society Conference Computer VisionPattern Recognition.Cohen, P. (2001). Fluent learning: Elucidating structure episodes. ProceedingsFourth Symposium Intelligent Data Analysis.Cohen, W. (1994). Grammatically biased learning: Learning logic programs using explicit antecedent description lanugage. Artificial Intelligence, 68, 303366.Cohen, W., & Hirsh, H. (1994). Learning CLASSIC description logic: Theoretical experimental results. Proceedings Fourth International Conference Principles KnowledgeRepresentation Reasoning, pp. 121133.De Raedt, L., & Dehaspe, L. (1997). Clausal discovery. Machine Learning, 26, 99146.Dehaspe, L., & De Raedt, L. (1996). DLAB: declarative language bias formalism. ProceedingsNinth International Syposium Methodologies Intelligent Systems, pp. 613622.Fikes, R., & Nilsson, N. (1971). STRIPS: new approach application theorem provingproblem solving. Artificial Intelligence, 2(3/4).Hoppner, F. (2001). Discovery temporal patternsLearning rules qualitative behaviourtime series. Proceedings Fifth European Conference Principles PracticeKnowledge Discovery Databases.447fiF ERN , G IVAN , & ISKINDKam, P., & Fu, A. (2000). Discovering temporal patterns interval-based events. ProceedingsSecond International Conference Data Warehousing Knowledge Discovery.Klingspor, V., Morik, K., & Rieger, A. D. (1996). Learning concepts sensor data mobilerobot. Artificial Intelligence, 23(2/3), 305332.Lang, K., Pearlmutter, B., & Price, R. (1998). Results Abbadingo one DFA learning competition new evidence-driven state merging algorithm. Proceedings FourthInternational Colloquium Grammatical Inference.Lavrac, N., Dzeroski, S., & Grobelnik, M. (1991). Learning nonrecursive definitions relationsLINUS. Proceedings Fifth European Working Session Learning, pp. 265288.Mann, R., & Jepson, A. D. (1998). Toward computational perception action. ProceedingsIEEE Computer Society Conference Computer Vision Pattern Recognition, pp.794799, Santa Barbara, CA.Mannila, H., Toivonen, H., & Verkamo, A. I. (1995). Discovery frequent episodes sequences.Proceedings First International Conference Knowledge Discovery Data Mining.Mitchell, T. (1982). Generalization search. Artificial Intelligence, 18(2), 51742.Morales, E. (1997). Pal: pattern-based first-order inductive system. Machine Learning, 26, 227252.Muggleton, S. (1995). Inverting entailment Progol. Machine Intelligence, 14, 133188.Muggleton, S., & Feng, C. (1992). Efficient induction logic programs. Muggleton, S. (Ed.),Inductive Logic Programming, pp. 281298. Academic Press.Muggleton, S., & De Raedt, L. (1994). Inductive logic programming: Theory methods. JournalLogic Programming, 19/20, 629679.Pinhanez, C., & Bobick, A. (1995). Scripts machine understanding image sequences.Proceedings AAAI Fall Symposium Series Computational Models IntegratingLanguage Vision.Plotkin, G. D. (1971). Automatic Methods Inductive Inference. Ph.D. thesis, Edinburgh University.Regier, T. P. (1992). Acquisition Lexical Semantics Spatial Terms: Connectionist ModelPerceptual Categorization. Ph.D. thesis, University California Berkeley.Roth, D., & Yih, W. (2001). Relational learning via propositional algorithms: information extraction case study. Proeedings Seventeenth International Joint Conference ArtificialIntelligence.Shoham, Y. (1987). Temporal logics AI: Semantical ontological considerations. ArtificialIntelligence, 33(1), 89104.Siskind, J. M. (2000). Visual event classification via force dynamics. Proceedings Seventeenth National Conference Artificial Intelligence, pp. 149155, Austin, TX.Siskind, J. M. (2001). Grounding lexical semantics verbs visual perception using forcedynamics event logic. Journal Artificial Intelligence Research, 15, 3190.448fiL EARNING EMPORAL E VENTSSiskind, J. M., & Morris, Q. (1996). maximum-likelihood approach visual event classification. Proceedings Fourth European Conference Computer Vision, pp. 347360,Cambridge, UK. Springer-Verlag.Talmy, L. (1988). Force dynamics language cognition. Cognitive Science, 12, 49100.Yamoto, J., Ohya, J., & Ishii, K. (1992). Recognizing human action time-sequential images usinghidden Markov model. Proceedings IEEE Conference Computer VisionPattern Recognition, pp. 379385.449fiJournal Artificial Intelligence Research 17 (2002) 1-33Submitted 8/01; published 7/02Critical AssessmentBenchmark Comparison PlanningAdele E. HoweEric DahlmanComputer Science DepartmentColorado State University, Fort Collins, CO 80523howe@cs.colostate.edudahlman@cs.colostate.eduAbstractRecent trends planning research led empirical comparison becoming commonplace. field started settle methodology comparisons,obvious practical reasons requires running subset planners subset problems.paper, characterize methodology examine eight implicit assumptionsproblems, planners metrics used many comparisons. problem assumptions are: PR1) performance general purpose plannerpenalized/biased executed sampling problems domains, PR2) minor syntacticdifferences representation affect performance, PR3) problems solvable STRIPS capable planners unless require ADL. planner assumptions are:PL1) latest version planner best one use, PL2) default parameter settingsapproximate good performance, PL3) time cut-offs unduly bias outcome.metrics assumptions are: M1) performance degrades similarly planner rundegraded runtime environments (e.g., machine platform) M2) number plansteps distinguishes performance. find assumptions supportedempirically; particular, planners affected differently assumptions.conclude call community devote research resources improving statepractice especially enhancing available benchmark problems.1. Introductionrecent years, comparative evaluation become increasingly common demonstratingcapabilities new planners. Planners directly comparedproblems taken set domains. result, recent advances planningtranslated dramatic increases size problems solved (Weld,1999), empirical comparison highlighted improvements.Comparative evaluation planning significantly uenced expeditedArtificial Intelligence Planning Scheduling (AIPS) conference competitions.competitions dual effect highlighting progress field providingrelatively unbiased comparison state-of-the-art planners. individual researcherscompare planners others, include fewer planners fewer test problemstime constraints.support first competition 1998 (McDermott, 2000), Drew McDermott defined,contributions organizing committee, shared problem/domain definitionlanguage, PDDL (McDermott et al., 1998) (Planning Domain Definition Language). Usingc 2002 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiHowe & Dahlmancommon language means planners' performance directly compared, withoutentailing hand translation factoring different representational capabilities.second benefit, lack translation (or least human accomplished translation) meant performance could compared large number problemsdomains1. fact, five competition planners given large number problems(170 problems ADL track 165 STRIPS track) within seven domains,including one domain planner developers never seen prior competition.first competition generated large collection benchmarks: seven domains usedcompetition plus 21 considered use. 28 domains availableftp://ftp.cs.yale.edu/pub/mcdermott/domains/. second competition added threenovel domains set.third major benefit competitions appear motivated researchers develop systems others use. number entrants went fivefirst competition 16 second. Additionally, 1998 competitors sixsixteen 2000 competitors made code available web sites. Thus, othersperform comparisons.paper, describe current practice comparative evaluation evolvedsince AIPS competitions critically examine underlying assumptionspractice. summarize existing evidence assumptions describeexperimental tests others previously considered. assumptionsorganized three groups concerning critical decisions experiment design:problems tested, planners included performance metrics collected.Comparisons (as part competitions specific researchers) proven enormously useful motivating progress field. goal understand assumptionsreaders know far comparative results generalized. contrastcompetitions, community cannot legislate fairness individual researcher's comparative evaluations, readers may able identify cases results viewedeither skeptically confidence. Thus, conclude paper observationscall considerably research new problems, metrics methodologiessupport planner evaluation.Also contrast competitions, goal declare winner. goalalso critique individual studies. Consequently, draw attention awaypossible interpretation, whenever possible, report results using letter designatorsassigned randomly planners.2. Planning Competitions Direct ComparisonsRecently, AIPS competitions spurred considerable interest comparative evaluation. roots comparative planner evaluation go back considerably further, however.Although researchers able run side-by-side comparisons planners1. solve particular planning problem (i.e., construct sequence actions transform initial stategoal state), planners require domain theory problem description. domain theory representsabstract actions executed environment; typically, domain descriptions includevariables instantiated specific objects values. Multiple problems defineddomain; problem descriptions require initial state description, goal state associationdomain.2fiA Critical Assessment Benchmark Comparison Planningothers, able demonstrate performance planner well-known problems, could viewed de facto benchmarks. Sussman's anomaly (Sussman, 1973)Blocksworld premier planning benchmark problem domain many years;every planner needed \cut teeth" it.researchers tired Blocksworld, many called additional benchmark problemsenvironments. Mark Drummond, Leslie Kaelbling Stanley Rosenschein organizedworkshop benchmarks metrics (Drummond, Kaelbling, & Rosenschein, 1990).Testbed environments, Martha Pollack's TileWorld (Pollack & Ringuette, 1990)Steve Hanks's TruckWorld (Hanks, Nguyen, & Thomas, 1993), used comparingalgorithms within planners. 1992, UCPOP (Penberthy & Weld, 1992) distributedlarge set problems (117 problems 21 domains) demonstration purposes.1995, Barry Fox Mark Ringer set planning scheduling benchmarks web page(http://www.newosoft.com/~benchmrx/) collect problem definitions, emphasismanufacturing applications. Recently, PLANET (a coordinating organization European planning scheduling researchers) proposed planning benchmark collectioninitiative (http://planet.dfki.de).Clearly, benchmark problems become well-established means demonstratingplanner performance. However, practice known benefits pitfalls; Hanks, PollackCohen (1994) discuss detail context agent architecture design.benefits include providing metrics comparison supporting experimental control.pitfalls include lack generality results potential benchmarksunduly uence next generation solutions. words, researchers constructsolutions excel benchmarks, regardless whether benchmarks accuratelyrepresent desired real applications.obtain benefits listed benchmarks, problems often idealizedsimplified versions real problems. Cohen (1991) points , research papersAI, least AAAI conference, exploit benchmark problems; yet relatebenchmarks target tasks. may significant problem; example, studyowshop scheduling2 benchmarks, found performance standard benchmark set generalize performance problems realistic structure (Watson,Barbulescu, Howe, & Whitley, 1999). study Blocksworld problems foundbest known Blocksworld benchmark problems atypical require shortplans solution optimal solutions easy find (Slaney & Thiebaux, 2001).spite diculties, benchmark problems AIPS competitions considerably uenced comparative planner evaluations. example, AIPS 2000 conference proceedings (Chien, Kambhampati, & Knoblock, 2000), papers improvements classical planning (12 44 papers conference) relied heavilycomparative evaluation using benchmark problems; papers concerned scheduling,specific applications, theoretical analyses special extensions standard paradigm(e.g., POMDP, sensing). 12 classical papers, six used problems AIPS98competition benchmark set, six used problems Kautz Selman's distributionproblems blackbox (Kautz, 2002) three added problemswell. paper showed results subset problems benchmark distributions2. Scheduling area related planning actions already known, sequence stillneeds determined. Flowshop scheduling type manufacturing scheduling problem.3fiHowe & Dahlman(e.g., Drew McDermott's first competition) logistics, blocksworld, rocketgripper domains popular (used 11, 7, 5 5 papers, respectively). availability planners competition also exploited; eight papers comparedsystems AIPS98 planners: blackbox, STAN, IPP HSP (in 5, 3, 3 1papers, respectively).3. Assumptions Direct Comparisoncanonical planner evaluation experiment follows procedure Table 1. proceduredesigned compare performance new planner previous state arthighlight superior performance set cases new planner. exact formexperiment depends purpose, e.g., showing superiority class problemhighlighting effect design decision.1. Select and/or construct subset planner domains2. Construct problem set by:running large set benchmark problemsselecting problems desirable featuresvarying facet problem increase diculty (e.g., number blocks)3. Select planners are:representative state art problemssimilar distinct new planner, depending point comparison advance new planneravailable able parse problems4. Run problems planners using default parameters setting upper limittime allowed5. Record problems solved, many plan steps/actions solutionmuch CPU time required either solve problem, fail timeTable 1: Canonical comparative planner evaluation experiment.protocol depends three selections: problems, planners evaluation metrics.simply practical even desirable run available planners availableproblems. Thus, one needs make informed decisions select. purposepaper examine assumptions underlying decisions help makeinformed. Every planner comparison adopt every one assumptions,assumptions ones commonly found planner comparisons. example,comparisons designed specific purpose (e.g., show scale-up certain problemssuitability planner logistics problems) carefully select particular typesproblems benchmark sets.4fiA Critical Assessment Benchmark Comparison PlanningProblems Many planning systems developed solve particular type planningproblem explore specific type algorithmic variation. Consequently, one would expectperform better problems developed. Evendesigned specific purpose, test set used development maysubtly biased development. community knows planner performance dependsproblem features, general, how, why. Researchers tend designplanners general purpose. Consequently, comparisons assumeperformance general-purpose planner penalized/biasedexecuted sampling problems domains (problem assumption 1).community also knows problem representation uences planner performance.example, benchmark problem sets include many versions Blocksworld problems, designed different planner developers. versions vary problem representation,minor apparently syntactic changes (e.g., clauses ordered within operators,initial conditions goals, whether information extraneous) changes ecting addition domain knowledge (e.g., constraints included whethervariables typed). Consequently, comparisons assumesyntactic representational modifications either matter affect planner equally (problem assumption 2).PDDL includes field, :requirements, capabilities required planner solveproblem. PDDL1.0 defined 21 values :requirements field; base/default requirement :strips, meaning STRIPS derived add delete sets action effects. :adl(from Pednault's Action Description Language) requires variable typing, disjunctive preconditions, equality built-in predicate, quantified preconditions conditional effectsaddition :strips capability. Yet, many planners either ignore :requirementsfield reject problem specifies :adl (ignoring many requirementscould also cause trouble). Thus, comparisons assumeproblems benchmark set solvable STRIPS planner unlessrequire :adl (problem assumption 3).Planners wonderful trend making planners publicly available led dilemmadetermining use configure them. problem compoundedlongevity planner projects; projects produced multiple versions.Consequently, comparisons tend assumelatest version planner best (planner assumption 1).planners may also include parameters. example, blackbox planner allowsuser define strategy applying different solution methods. Researchers expectparameters affect performance. Consequently, comparisons assumedefault parameter settings approximate good performance (planner assumption2).5fiHowe & DahlmanExperiments invariably use time cut-offs concluding planning yet foundsolution declared failure. Many planners would need exhaustively search large spacedeclare failure. practical reasons, time threshold set determinehalt planner, failure declared time-out reached. Thus, comparisonsassumeone picks suciently high time-out threshold, highly unlikelysolution would found slightly time granted (plannerassumption 3).Metrics Ideally, performance would measured based well plannerjob (i.e., constructing `best' possible plan solve problem) ecientlyso. planner shown solve possible problems, basicmetric performance number percentage problems actually solved withinallowed time. metric commonly reported competitions. However, researchpapers tend report directly typically test relatively small numberproblems.Eciency clearly function memory effort. Memory size limitedhardware. Effort measured CPU time, preferably always platformlanguage. problems CPU time well known: programmer skillvaries; research code designed fast prototyping fast execution; numbersliterature cannot compared newer numbers due processor speed improvements.However, CPU times regenerated experimenter's environment one assumesperformance degrades similarly reductions capabilities runtimeenvironment (e.g., CPU speed, memory size) (metric assumption 1).words, experimenter user system expect codeoptimized particular compiler/operating system/hardware configuration,perform similarly moved another compatible environment.commonly reported comparison metric computation time. secondnumber steps actions (for planners allow parallel execution) plan. Althoughplanning seeks solutions achieving goals, goals defined terms statesworld, lend well general measures quality. fact, quality likelyproblem dependent (e.g., resource cost, amount time execute, robustness),number plan steps favored. Comparisons assumenumber steps resulting plan varies planner solutions approximates quality (metric assumption 2).comparison, competitions especially, unenviable task determiningtrade-off combine three metrics (number solved, time, number steps). Thus,number steps matter, comparison could simplified.converted assumption testable question. either summarizedliterature question ran experiment test it.6fiA Critical Assessment Benchmark Comparison Planning3.1 Experimental Setupkey issues examined previously, directly indirectly. those,simply summarize results subsections follow. However, openquestions. those, ran seven well known planners large set 2057 benchmarkproblems. planners accept PDDL representation, although built-intranslators PDDL internal representation others rely translatorsadded. several versions planner available, included (for total13 planners). basic problem set comprises UCPOP benchmarks, AIPS982000 competition test sets additional problem set developed specific application.exception permuted problems (see section Problem Assumption2 specifics), problems run 440 MHz Ultrasparc 10s 256 Megabytesmemory running SunOS 2.8. Whenever possible, versions compiled developersused; source code available, compiled systems accordingdevelopers' instructions. planners written Common Lisp run AllegroCommon Lisp version 5.0.1. planners compiled GCC (EGCS version2.91.66). planner given 30 minute limit wall clock time3 find solution;however, times reported run times returned operating system.3.1.1 Plannersplanners called primitive-action planners (Wilkins & desJardins,2001), planners require relatively limited domain knowledge construct planssimple action descriptions. AIPS98 competition required planners acceptPDDL, majority planners used study competition entrants laterversions thereof 4 . common language facilitated comparison planners without address effects translation step. two exceptions UCPOPProdigy; however, representations similar PDDL translated automatically. planners represent five different approaches planning: plan graph analysis,planning satisfiability, planning heuristic search, state-space planning learningpartial order planning. possible, used multiple versions planner,necessarily recent. conducted study period time (almost 1.5 years), froze set early on; comparing performance declarewinner think lack recent versions undermined resultstesting assumptions.IPP (Koehler, Nebel, Hoffmann, & Dimopoulos, 1997) extends Graphplan (Blum &Furst, 1997) algorithm accept richer plan description language. early versions,language subset ADL extends STRIPS formalism Graphplanallow conditional universally quantified effects operators. version 4.0,negation handled via introduction new predicates negated preconditions3. used actual time lightly loaded machines occasionally system would thrash dueinadequate memory resulting little progress considerable time.4. used BUS system manager running planners (Howe, Dahlman, Hansen, Scheetz, &von Mayrhauser, 1999), implemented AIPS98 competition planners. facilitatedrunning many different planners, somewhat bias included.7fiHowe & Dahlmancorresponding mutual exclusion rules; subsequent versions handle directly (Koehler,1999). used AIPS98 version IPP well later 4.0 version.SGP (Sensory Graph Plan) (Weld, Anderson, & Smith, 1998) also extends Graphplanricher domain description language, primarily focusing uncertainty sensing.IPP, transformation performed using expansion techniques removequantification. SGP also directly supports negated preconditions conditional effects.SGP tends slower (it implemented Common Lisp instead C)Graphplan based planners. used SGP version 1.0b.STAN (STate ANalysis) (Fox & Long, 1999) extends Graphplan algorithm partadding preprocessor (called TIM) infer type information problem domain.information used within planning algorithm reduce size searchspace Graphplan algorithm would search. STAN also incorporated optimized datastructures (bit vectors planning graph) help avoid many redundant calculations performed Graphplan. Additionally, STAN maintains wave front graphconstruction track remaining goals limit graph construction. Subsequent versionsincorporated analyses (e.g., symmetry exploitation) additional simpler planning engine. Four versions STAN tested: AIPS98 competition version, version3.0, version 3.0s development snapshot version 4.0.blackbox (Kautz & Selman, 1998) converts planning problems Boolean satisfiabilityproblems, solved using variety different techniques. user indicatestechniques tried order. constructing satisfiability problem,blackbox uses planning graph constructed Graphplan. blackbox, usedversion 2.5 version 3.6b.HSP (Heuristic Search Planner) (Bonet & Geffner, 1999) based heuristic search.planner uses variation hill-climbing random restarts solve planning problems.heuristic based using Graphplan algorithm solve relaxed formplanning problem. study, used version 1.1, algorithmic refinementversion entered AIPS98 competition, version 2.0.Prodigy 5 (The Prodigy Research Group, 1992) combines state-space planning backward chaining goal state. plan construction consists head-plantotally ordered actions starting initial state tail-plan partially orderedactions related goal state. Although ocially entered competition, informal results presented AIPS98 competition suggested Prodigy performed wellcomparison entrants. used Prodigy version 4.0.UCPOP (Barrett, Golden, Penberthy, & Weld, 1993) Partial Order Causal Linkplanner. decision include UCPOP based several factors. First,expand quantifiers negated preconditions; domains, expansiongrounding operators great make problem insolvable. Second, UCPOPbased significantly different algorithm interest recently resurfaced.used UCPOP version 4.1.5. thank Eugene Fink code translates PDDL Prodigy.8fiA Critical Assessment Benchmark Comparison PlanningSource# Domains # ProblemsBenchmarks50293AIPS 19986202AIPS 20005892Developers113Application372Table 2: Summary problems testing set: source problems, numberdomains problems within domains.3.1.2 Test ProblemsFollowing standard practice, experiments require planners solve commonly availablebenchmark problems AIPS competition problems. addition, test assumptions uence domains (assumption PR1) representations problems(assumption PR2), also include permuted benchmark problems application problems. section describes set problems domains study,focusing source composition.problems require STRIPS capabilities (i.e., add delete lists). choseleast common denominator several reasons. First, capable planners still handleSTRIPS requirements; thus, maximized number planners could includedexperiment. Also, surprisingly, problems type available. Second,examining assumptions evaluation, including effect required capabilitiesperformance. propose duplicate effort competitions singlingplanners distinction, rather, purpose determine factors differentiallyaffect planners.bulk problems came AIPS98 AIPS 2000 problem setsset problems distributed PDDL specification. remaining problemssolicited several sources. source counts problems domainssummarized Table 2.Benchmark Problems preponderance problems planning test sets \toyproblems": well-known synthetic problems designed test attribute planners.Blocksworld domain long included evaluation well known,subgoal interactions supports constructing increasingly complex problems(e.g., towers blocks). benchmark problems simplified versions realisticplanning problems, e.g., tire, refrigerator repair logistics domains. usedset included UCPOP planner. problems contributed large numberpeople include multiple encodings problems/domains, especially Blocksworld.AIPS Competitions: 1998 2000 first AIPS competition, Drew McDermott solicited problems competitors well constructing own,mystery domain, semantically useless names objects operators.Problems generated domain automatically. competition included 155problems six domains: robot movement grid, gripper balls9fiHowe & Dahlmanmoved rooms robot two grippers, logistics transporting packages, organizing snacks movie watching, two mystery domains, disguised logisticsproblems.format 1998 competition required entrants execute 140 problemsfirst round. problems, 52 could solved planner. round two,planners executed 15 new problems three domains, one includedfirst round.2000 competition attracted 15 competitors three tracks: STRIPS, ADLhand-tailored track. required performance problems five domains: logistics,Blocksworld, parts machining, Freecell (a card game), Miconic-10 elevator control.domains determined organizing committee, Fahiem Bacchuschair, represented somewhat broader range. chose problems UntypedSTRIPS track set.scientific standpoint, one interesting conclusions competitions observed trade-offs performance. Planners appeared excel differentproblems, either solving set finding solution faster. 1998, IPP solvedproblems found shorter plans round two; STAN solved problems fastest;HSP solved problems round one; blackbox solved problems fastestround one. 2000, awards given two groups distinguished planners acrossdifferent categories planners (STRIPS, ADL hand tailored), accordingjudges, \it impossible say one planner best"(Bacchus, 2000);TalPlanner FF highest distinguished planner group. graphs performance show differences computation time relative planners problemscale-up. However, planner failed solve problems, makes trendsharder interpret (the computation time graphs gaps).purpose competitions showcase planner technologysucceeded admirably. planners solved much harder problems couldaccomplished years past. trend planners handling increasingly dicultproblems, competition test sets may become historical interest tracking field'sprogress.Problems Solicited Planner Developers also asked planner developersproblems used development. One developer, Maria Fox, sent us domain(Sodor, logistics application) set problems used. wouldincluded domains problems received others.Applications Miconic elevator domain AIPS2000 competitionderived actual planning application. domain problems extremelysimplified (e.g., removing arithmetic).add another realistic problem comparison, included one planning application set test domains: generating cases test software interface.similarities software interface test cases plans, developed system,several years ago, automatically generating interface test cases using AI planner.system designed generate test cases user interface Storage Technology's robot tape library (Howe, von Mayrhauser, & Mraz, 1997). interface (i.e.,commands interface) coded domain theory. example, mount com10fiA Critical Assessment Benchmark Comparison Planningmand/action's description required drive empty effect changingposition tape mounted changing status tape drive. Problemsdescribed initial states tape library (e.g., tapes resident,status devices software controller) goal states human operator mightwish achieve.time, found simplest problems could generated usingplanners available. included application part knew wouldchallenge. part test set, include three domain theories (different wayscoding application involving 8-11 operators) twenty-four problems domain.included 24 wanted include enough problems see effect,many overly bias results. problems relatively simple, requiringmovement one tape coupled status changes,still dicult could solved original system.3.2 Problem AssumptionsGeneral-purpose planners exhibit differential capabilities domains sometimes evenproblems within domain. Thus, selection problem set would seem criticalevaluation. example, many problems benchmark sets variants logisticsproblems; thus, general-purpose planner actually tailored logistics may appearbetter overall current benchmarks. section, empirically examinepossible problem set factors may uence performance results.Problem Assumption 1: Extent Performance General PurposePlanners Biased Toward Particular Problems/Domains? Although plannersdeveloped general purpose, competitions previous studies shownplanners excel different domains/problems. Unfortunately, community yetgood understanding planner well particular domain. studiedimpact problem selection performance two ways.First, assessed whether performance might positively biased toward problemstested development. developer6 asked indicate domains useddevelopment. compared planner's performance developmentproblems (i.e., development set) problems remaining complete test set(rest). ran 2x2 2 tests comparing number problems solved versus faileddevelopment test sets. included number solved failed analysistimed-out problems made difference results7.results analysis summarized Table 3; Figure 1 graphically displaysratio successes failures development problems. plannersexcept C performed significantly better development problems. suggestsplanners tailored (intentionally not) particular types problemstend better test sets biased accordingly. example, one6. decided studying planners way representationsdevelopment problems PDDL.7. One planner exception rule; one case, planner timed far frequentlynon-development problems.11fiHowe & DahlmanDevelopmentPlanner Sol. Fail4856B4234C300G4335H52911320J11424K3756L6332RestSol. Fail2P207 1026 51.70 0.001226 929 51.27 0.001549 160.13 0.722233 924 49.56 0.001234 655 91.41 0.001328 920 187.72 0.001388 949 157.62 0.001203 987 27.82 0.001358 846 52.13 0.001Table 3: 2 results comparing outcome development versus problems.planners set, STAN, designed emphasis logistics problems (Fox &Long, 1999).Figure 1: Histogram ratios success/failures development problemsplanners.analysis introduces variety biases. developers tended give us shortlists probably really representative actually used. set usedmoving target, rather stationary suggests. set problems includedexperimentation publication may different still. Consequently, secondpart, broadened question determine effect different subsets problems12fiA Critical Assessment Benchmark Comparison Planningn510203000000113002200030000Rank Dominance4 5 6 75 7 10 44 10 6 71 3 8 71 1 9 68 9 10 Total Pairs10 18 21785 23 207811 8 40789 8 4478Table 4: Rank dominance counts 10 samples domains domain sizes (n) five30.performance. 10 trials, randomly selected n domains (and companionproblems) form problem set. counted many problems couldsolved planner ranked relative performance planner. Thus,value n, obtained 10 planner rankings. focused rankings problemssolved two reasons: First, domain includes different number problems, makingcount problems variable across trials. Second, relative ranking getsheart whether one planner might considered improvement another.tested values 5, 10, 20 30 n (30 half domains disposal).give sense variability size, n = 5, problems solved trialvaried 11 64. assess changes rankings across trials, computed rankdominance pairs planners; rank dominance defined number trialsplanner x's rank lower planner y's (note: ties would count toward neitherplanner). 13 planners study resulted 78 dominance pairings. relativeranking two planners stable, one would expect one always dominateother, i.e., rank dominance 10.Table 4 shows number pairs value (0-10) rank dominancefour values n. given pair, used highest number rank dominancepair, e.g., one always lower rank, pair's rank dominance 10five, five. ties, maximum less five.data suggest even picking half domains, rankings completelystable: 56% pairings, one always dominates, 22% 0.3 greater chanceswitching relative ranking. values degrade n decreases 27% alwaysdominating n = 5.Problem Assumption 2: Syntactic Representation Differences AffectPerformance? Although well known planners' performance dependsrepresentation (Joslin & Pollack, 1994; Srinivasan & Howe, 1995), two recent developmentsplanner research suggest effect needs better understood. First, commonrepresentation, i.e., PDDL, may bias performance. planners rely pre-processingstep convert PDDL native representation, step usually requires makingarbitrary choices ordering coding. Second, advantage planners basedGraphplan supposed less vulnerable minor changes representa13fiHowe & DahlmanPlannerBCEFGHJKLNone Subset65 3153070 29545318 7418202 16939111 132167112 13816070 2954591 29029109 134167150 12413660 30545112 28414212 14850Table 5: number problems planners able solve all, nonesubset permutations.tion. Although reasoning claim sound, exigencies implementation mayrequire re-introduction representation sensitivity.evaluate sensitivity representation, ten permutations problemAIPS2000 set generated, resulting 4510 permuted problems. permutationsconstructed randomly reordering preconditions operator definitionsorder definitions operators within domain definition.limited number problems study ten permutations problems would prohibitive. selected AIPS2000 problems attentionrecently developed benchmark set. Even within set, domainspermuted would result different domains transformation used. purposes investigation, limited set modificationspermutations preconditions operators known affect planners practical considerations limited number permutations couldexecuted. Finally, expediency, ran permutations smaller number fasterplatforms expedited throughput computation time factorstudy.analyze data, divided performance permutations problemsthree groups based whether planner able solve permutations,none permutations subset permutations. planner insensitiveminor representational changes, subset count zero. resultsTable 5, see planners affected permutation operation.susceptibility permuting problem strongly planner dependent (2 = 1572:16,P < 0:0001), demonstrating planners vulnerable others.examining number Subset column, one assess degree susceptibility. planners sensitive reorderings, even relied Graphplan14fiA Critical Assessment Benchmark Comparison Planning00165166152145001381300131693582161961991858461691608242120016313915715000138130016149002000000000225526856127938437627628544150224042137280197180168165017139130013180Pre.80016916416215700138130019168Pre.SafetyStripsTyping00531000000009BCEFGHJKLFeatureAxiomsCond. Eff.Dis. Pre.EqualityPlanner0016013914914500138130013151Table 6: number problems claiming require PDDL feature solvedplanner.methodology. sensitive E, F, J (which included Graphplan basedplanners 40% problems mixed results permutations) CL least sensitive (3-4% affected).Problem Assumption 3: Performance Depend PDDL RequirementsFeatures? planners intended handle STRIPS problems.problems test set claim require features STRIPS; one would expectplanners would able handle problems. addition,planners claim able handle given feature may well planners.Table 6 shows effects feature requirements ability solve problems. datatable based features specified :requirements list PDDLdefinition domain.verify requirements accurate necessary; thus, problemmay solvable ignoring part PDDL syntax understood,problem may mislabeled designer. evident cases plannersupport given feature still appears able solve correspondingproblem. planners, e.g., older versions STAN, reject problem requiresSTRIPS without trying solve it; ADL problem makes useSTRIPS features would attempted.guidance planner use when, results must viewedskepticism. example, would appear based results planner might15fiHowe & Dahlmangood choice problems conditional effects able solve manyproblems. would mistake, since planner cannot actually handle typesproblems. cases, problems claim require ADL, fact, makeuse STRIPS subset.Clearly, certain problems solved specific planners. instance, Cplanners able handle safety constraints, based data,C, E appear handle domain axioms. half planners troubletyped problems. gaps appear due problems translationnative representation.3.3 PlannersPublicly available, general-purpose planners tend large programs developedperiod years enhanced include additional features time. Thus, several versionslikely available, versions likely features turnedon/off via parameter settings.authors release later versions planning systems, general assumptionnewer versions outperform predecessors. However, maycase practice. instance, planner could better optimized toward specific classproblem turn hurts performance problems. Also, advancedcapabilities, even unused, may incur overhead solution problems.comparison purposes, one use latest version? First, testedquestion study comparing multiple versions four planners. Second,planner relies parameter settings tune performance. Some, blackbox,many parameters. Others none. Comparisons tend use default publishedparameter settings people usually understand effects parameterstuning extremely time consuming. practice undermine faircomparison?Planner Assumption 1: Latest Version Best? study, comparedperformance multiple versions four planners (labeled section W, X,Z, larger version numbers indicating subsequent versions). considered two criteriaimprovement: outcome planning computation time solved problems.outcome planning one of: solved, failed timed-out. criterion, statisticallyanalyzed data superior performance one versions. outcome resultsplanners summarized Table 7. table shows, rarely new versionresult problems solved. Z improved number test problemssolved subsequent versions.check whether differences outcome significant, ran 2x3 2 testsplanner version independent variable outcome dependent. Table 8 summarizesresults 2 analysis. Z, compared version successor only.differences significant except transition Z 2 3 (this expectedtwo versions extremely similar).Another planner performance metric, evaluated, speed solution.analysis, limited comparison problems solvedversions planner. classified problem whether later version solved16fiA Critical Assessment Benchmark Comparison PlanningPlanner Version Solved Failed Timeout Solved?W1286664533W22551082147+X15029733X2441940103+13877503392382771329+Z12401043201Z2276959248*Z3268963252+Z4421878184*Table 7: Version performance: counts outcome change number solved.oldnewPlanner Version Version 2PW12320.96 .0001X1298.84 .000112.46.79Z1210.96 .004Z23.158 .924Z3448.50 .0001Table 8: 2 results comparing versions planner.problem faster, slower, time preceding version. resultsTable 9, see planners improved average speed solutionsubsequent versions, exception Z (transition 1 2 versions). However,Z increase number problems solved versions.Planner Old New Faster Slower TotalW121616130252X122951260421122228253357Z128412130235Z231318453268Z341159221228Table 9: Improvements execution speed across versions. Faster column countsnumber cases new version solved problem faster; Slower specifiescases new version took longer solve given problem.17fiHowe & DahlmanPlanner Assumption 2: Parameter Settings Matter Fair Comparison?planner set, three obvious, easily manipulable parameters: Blackbox, HSPUCPOP. blackbox extensive set parameters control everythingmuch trace information print sequence solver applications. HSP's functionvaried include (or not) loop detection, change search heuristic varynumber paths expand. UCPOP, user change strategies governing nodeorderings aw selection.run experiments assumption plannersparameters clear literature parameters matter.Blackbox relies heavily random restarts trying alternative SAT solvers. KautzSelman (1999), authors blackbox carefully study aspects blackbox's designdemonstrate differential performance using different SAT solvers; propose hypothesesperformance differences working better models performance variation.heart HSP heuristic search. Thus, performance varies dependingheuristics. Experiments HSP FF (a planner builds ideasHSP) shown importance heuristic selection search space expansion,computation time problem scale (Haslum & Geffner, 2000; Hoffmann & Nebel,2001).HSP, heuristic search critical UCPOP's performance. set studiesexplored alternative settings aw selection heuristics employed UCPOP (Joslin &Pollack, 1994; Srinivasan & Howe, 1995; Genevini & Schubert, 1996), producing dramaticimprovements domains heuristics. Pollack et al. (1997) confirmed,good default strategy could derived, performance bestcircumstances.Thus, parameters control fundamental aspects algorithms,search strategies, role parameters comparisons cannot easily dismissed.Planner Assumption 3: Time Cut-offs Unfair? Planners often admitfailure. Instead, planner stops used allotted time foundsolution. setting time threshold requirement planner execution.comparison, one might always wonder whether enough time allotted fair {perhaps solution almost found execution terminated.determine whether cut-off 30 minutes fair, examined distributiontimes declared successes failures8. Across planners problem set,found distributions skewed (approximately log normal long right tails)planners quick declare success failure, going so.Table 10 shows max, mean, median standard deviation success failure timesplanners. differences mean median indicate distributionskew, low standard deviations relative observed max times. max timeshows rare occasions planners might make decision within 2 minutescut-off.8. separated two usually observed significant difference distributions timesucceed time fail { half planners quick succeed slow fail, halfreversed relationship.18fiA Critical Assessment Benchmark Comparison PlanningPlannerBCEFGHJKLSuccessesMax Mean Median667.9 34.01.31608.5 38.50.51455.4 89.91.6481.0 17.81.11076 26.20.11282.4 44.40.11456.2 44.60.7657.7 29.581.41713.8 115.40.21596.5 43.64.31110.5 31.00.321611.9 54.42.01675.3 53.41.45Sd98.7182.8244.677.4126.8126.8188.580.6303.1127.4121.8180.9196.5FailuresMax Mean Median1116.4 44.94.91692.0 45.617.81.40.40.13713.6 26.31.11622.8 286.9260.61188.4 22.30.21196.5 43.816.71080.6 93.81.450.65.14.91796 11.011.01298.8 27.712.1847.1 124.168.41.60.90.8Sd128.896.80.4122.6189.1104.878.5162.16.357.965.2164.80.4Table 10: Max, mean, median standard deviations (Sd) computation timessuccess failure planner.table show, observed distributions show,values greater half time cut-off. Figures 2 3 displaydistributions planner F, means middle set plannersquite typical distributions. Consequently, least problems, cut-off 15minutes (900 seconds) would significantly change results.30020010000104 208 312 416 520 624 728 832 936 1040 1144 1248success.timeFigure 2: Histogram times, seconds, planner F succeed.19fiHowe & Dahlman6004002000096192 288 384 480 576 672 768 864 960 1056 1152fail.timeFigure 3: Histogram times, seconds, planner F fail.3.4 Performance Metricscomparisons emphasize number problems solved CPU time completion metrics. Often, problems organized increasing diculty show scale-up.Comparing based metrics leaves lot open interpretation. example,planners designed find optimal plan, measured number steps eitherparallel sequential plan. Consequently, planners may require computation.Thus, ignoring plan quality, planners may unfairly judged. also hypothesizehardware software platform tests vary results. plannerdeveloped machine 1GB memory, likely performance degradeless. key issue whether effect less uniform across set planners.section, examine two issues: execution platform effect planquality.Metric Assumption 1: Performance Vary Planners RunDifferent Hardware Platforms? Often planner run competitionsomeone else's lab, hardware software platforms differ platform useddevelopment. Clearly, slowing processor speed slow planning,requiring higher cut-offs. Reduction memory may well change set problemssolved increase processing time due increased swapping. Changinghardware configuration may change way memory cached organized, favoringplanners' internal representations others. Changing compilers could also affectamount type optimizations code. exact effects probably unknown.assumption changes affect planners less equally.test this, ran planners less powerful, lower memory machine comparedresults two platforms: base Sun Ultrasparc 10/440 256mb memoryUltrasparc 1/170 128mb memory. operating system compilersversions machines. problems run platforms.followed much methodology comparison planner versions: comparingnumber problems solved time solution. Table 11 shows resultsmeasured problems solved, failed timed-out planner two platforms.20fiA Critical Assessment Benchmark Comparison PlanningPlanner Platform Solved Failed Timed-Out 2p % ReductionUltra 19438327Ultra 109538920 1.09 .581BUltra 112134637Ultra 1012135330 0.80 .670CUltra 13547143Ultra 103677130 0.85 .654Ultra 121859227Ultra 1021759228 0.01 .998-.4EUltra 128014579Ultra 1028415070 0.66 .721FUltra 127715572Ultra 1028415466 0.35 .842GUltra 112034737Ultra 1012135231 0.57 .751HUltra 111635038Ultra 1012233844 0.80 .677Ultra 126520138Ultra 1027420129 1.36 .513JUltra 12802204Ultra 102852172 0.73 .692KUltra 110837026Ultra 1010836828 0.08 .960LUltra 114933916Ultra 1015034113 0.32 .851Ultra 125065189Ultra 1025866180 0.35 .843Table 11: Number problems solved, failed timed-out planner twohardware platforms. Last column percentage reduction numbersolved faster slower platforms.21fiHowe & DahlmanPlannerBCEFGHJKLFaster# Mean925.181204.0229431.8917711.022752.6827114.861175.021156.8626125.7328042.2410715.2614816.8119432.72SlowerSd # Mean30.76 110.01 0101.71 600.2982.82 390.2312.27 172.44 017.17 125.24 0119.97 0138.16 075.42 098.54 1139.73 560.30Sd0.140.140.18Total110146214010094121354217280277120116265280108149250Table 12: Improvements execution speed moving slower faster platform. Countsproblems solved platforms. faster slower,mean standard deviation (Sd) difference also provided.before, also looked change time solution. Table 12 shows timesolution changes planner. surprisingly, faster processor memorynearly always lead better performance. Somewhat surprisingly, difference far lessdoubling might expected; mean differences much lessmean times faster processor (see Table 10 mean solution times).Also, effect seems vary planners. Based counts, Lisp-basedplanners appear less susceptible trend (the ones sometimes fasterslower platform). However, advantages small, affecting primarilysmaller problems. think effect due need load Lisp imagestartup centralized server; thus, computation time small problemsdominated network delay. Older versions planners appear less sensitiveswitch platform.study, platforms make little difference results, despitedoubling processor speed doubling memory. However, two platformsunderpowered compared development platforms planners.chose platforms differed characteristics (processor speedmemory amount) access 20 identically configured machines.really observe difference, 1GB9 memory may needed.Recent trends planning technology exploited cheap memory: translationspropositional representations, compilation problems built-in caching memorymanagement techniques. Thus, planners designed trade-off memory time;9. propose figure amount requested participants AIPS 2000planning competition.22fiA Critical Assessment Benchmark Comparison Planningplanners understandably affected memory limitations problems.Given results study, considered performing careful study memoryartificially limiting memory plannersaccess enough suciently large machines likely make difference coulddevise scheme fairly across planners (which implementeddifferent languages require different software run-time environments).Another important factor may memory architecture/management. plannersinclude memory managers, map better hardware platformsothers (e.g., HSP uses linear organization appears fit well Intel's memoryarchitecture).Metric Assumption 2: Number Plan Steps Vary? Several researchersexamined issue measuring plan quality directing planning based it, e.g.,(Perez, 1995; Estlin & Mooney, 1997; Rabideau, Englehardt, & Chien, 2000). numbersteps plan rather weak measure plan quality, far, onewidely used primitive-action planning.expect planners sacrifice quality (as measured plan length) speed.Thus, ignoring even measure plan quality may unfair planners.check whether appears factor problem set, counted plan lengthplans returned output compared lengths across planners.planners construct parallel plans, adopted general definition:sequential plan length. compared plan lengths returned plannerevery successfully solved problem.found 11% problems solved one planner (not necessarilyone). planners found equal length solutions 62% remained (493problems). calculated standard deviation (SD) plan length solutionsproblem analyzed SDs. found minimum observed SD 0.30,maximum 63.30, mean 2.43 standard deviation 5.45. Thirteencases showed SDs higher 20. Obviously, cases involved fairly long plans (up165 steps); cases problems logistics gripper domains.check whether planners favored minimal lengths, counted numbercases planner found shortest length plan (ties attributedplanners) variance plan length. Table 13 lists results.planners find shortest length plans one third problems. Planner Fdesigned optimize plan length, shows results. one exception,older planners rarely find shortest plans.4. Interpretation Results Recommendationsprevious section presented summarization analysis planner runs.section, ect results mean empirical comparison planners;summarize results recommend partial solutions. possible guaranteefairness propose magic formula performing evaluations, statepractice general certainly improved. propose three general recommendations12 recommendations targeted specific assumptions.23fiHowe & DahlmanPlanner Count178B169C0161E5F319G171H176222J0K159L151283Table 13: Number plans planner found shortest plan. datainclude problems different length plans found.Many targeted recommendations amount requesting problem planner developers precise requirements expectations contributions.planners extremely complex time consuming build, documentation may inadequate determine subsequent version differs previousconditions (e.g., parameter settings, problem types) planner fairlycompared. current positive trend making planners available, behoovesdeveloper include information distribution system.sweeping recommendation shift research focus away developingbest general-purpose planner. Even competitions, planners identifiedsuperior ones designed specific classes problems, e.g., FF IPP.competitions done great job exciting interest encouraging developmentpublic availability planners incorporate representation.However, advance research, informative comparative evaluationsdesigned specific purpose { test hypothesis predictionperformance planner10. experimental hypothesis focuses analysis oftenleads naturally justified design decisions experiment itself. example, Hoffmann Nebel, authors Fast-Forward (FF) system, state introductionJAIR paper FF's development motivated specific set benchmarkdomains; system heuristic, designed heuristics fit expectations/needs domains (Hoffmann & Nebel, 2001). Additionally, partevaluation, compare specific system system commonalitiespoint various advantages disadvantages design decisions specific10. Paul Cohen advocated experimental methodology artificial intelligence basedhypotheses, predictions models considerable detail; see Cohen (1991, 1995).24fiA Critical Assessment Benchmark Comparison Planningproblems. Follow-up work researchers comparing systems FFwell-defined starting point comparison.Recommendation 1: Experiments driven hypotheses. Re-searchers precisely articulate advance experiments expectations new planner augmentations existing planner addstate art. expectations turn justify selectionproblems, planners metrics form core comparativeevaluation.general issue whether results accurate. reported resultsoutput planners. planner stated output successful,took face value. However, examining output, determinedclaims successful solution erroneous { proposed solution would work.way ensure output correct solution checker. Drew McDermottused solution checker AIPS98 competition. However, plannersprovide output compatible format checker. Thus, another concerncomparative evaluation output needs cross-checked.declaring winner (i.e., planner exhibited superior performance), thinklack solution checker casts serious doubt results. part,concerned factors cause observed success rates change.Recommendation 2: input standardized PDDL, outputstandardized, least format returned plans.Another general issue whether benchmark sets representative spaceinteresting planning problems. test directly (in fact, sureone could so), clustering results observations others planningcommunity suggest set biased toward logistics problems. Additionally, manyproblems getting dated longer distinguish performance. researchersbegun formally analyze problem set, either service building improvedplanners (e.g., Hoffmann & Nebel, 2001) better understand planning problems.example, related area scheduling, group identified distinctive patternstopology search spaces different types classical scheduling problemsrelated topology performance algorithms (Watson, Beck, Barbulescu, Whitley, &Howe, 2001). Within planning, Hoffmann examined topology local search spacessmall problems benchmark collection found simple structurerespect well-known relaxations (Hoffmann, 2001). Additionally, workedpartial taxonomy, based three characteristics, analyzed domains. Helmertanalyzed computational complexity subclass benchmarks, transportationproblems, identified key features affect diculty problems (Helmert,2001).Recommendation 3: benchmark problem sets eval-uated over-hauled. Problems easily solved removed.Researchers study benchmark problems/domains classify25fiHowe & Dahlmanproblem types key characteristics. Developers contribute application problems realistic versions evolving set.remainder section describes recommendations improving stateart planner comparisons.Problem Assumption 1: General Purpose Planners Biased Toward Particular Problems/Domains? set problems planner developedstrong effect performance planner. either effectunintentional over-specialization result concerted effort partdevelopers optimize system solve specific problem. one exception, everyplanner fared better tailored subset problems (training set). Consequently,must conclude choice subset problems may well affect outcomecomparison.fair planner comparison must account likely biases problem set. Goodperformance certain class problems imply good performance general.large performance differential planners targeted problem domain (i.e., wellfocus problems poorly others) may well indicate developerssucceeded optimizing performance planner.Recommendation 4: Problem sets constructed highlightdesigners' expectations superior performance planner,specific selection criteria.hand, goal demonstrate across board performance,results randomly selecting domains suggests biases mitigated.Recommendation 5: highlighting performance \general" problemsgoal, problem set selected randomly benchmarkdomains.Problem Assumption 2: Syntactic Representation Differences AffectPerformance? Many studies, including this, shown planners may sensitiverepresentational features. representations translated automaticallymean performance unaffected. algorithmtheoretically insensitive factor mean practice is.planners showed sensitivity permuted problems, degree sensitivity varied.outcome suggests translators even minor variations problem descriptionsimpact outcome used care, especially sensitivityfocus study planner vulnerable effect.Recommendation 6: Representation translators avoided usingnative versions problems testing multiple versions problems necessary.many planner developers participating AIPS competitions, becomeless issue.importantly, researchers explicitly testing effect alternative phrasings planning problems determine sensitivity performance separateeffects advice/tuning essence problem.26fiA Critical Assessment Benchmark Comparison PlanningRecommendation 7: Studies consider role minor syntactic vari-ations performance include permuted problems (i.e., initial conditions,goals, preconditions actions) problem sets demonstrate robustness, provide opportunity learning protect developersaccidentally over-fitting algorithm set test problems.Problem Assumption 3: Performance Depend PDDL RequirementsFeatures? planners perform quite advertised expected givenproblem features. discrepancy could many possible causes: problems incorrectlyspecified, planners less sensitivity thought, solutions correct, etc.example, many problems benchmark set designed competitionseven intended widely used may specified carefully enough.Recommendation 8: problems contributed benchmark set,developers verify requirements stated descriptionproblem correctly ect subset features needed. Planner evaluatorsuse problems match planner's capabilities.Depending cause, results skewed, e.g., planner may unfairlymaligned unable solve problem specifically designed solve.recommendation addresses gaps specification problem set,mismatches capabilities specifiable PDDL planners possessremain.Recommendation 9: Planner developers develop vocabularyplanner's capabilities, PDDL ags, specify expectedcapabilities planner's distribution.Planner Assumption 1: Latest Version Best? results suggestnew versions run faster, often solve problems. Thus, newest version mayrepresent \best" (depending definition) performance class planner.competitions fields, e.g., automatic theorem proving community, requireprevious year's best performer compete well; advantage establishingbaseline performance well allowing comparison focus may shifttime.Recommendation 10: primary evaluation metric speed, newerversion may best competition. number problems solved onewishes establish progress made, may worth runningolder version well. recommendation 9 followed,evaluators select version based guidance.Planner Assumption 2: Effect Parameter Settings? Perfor-mance planners vary parameter settings. Unfortunately, oftendicult figure set parameters properly, changing settings makesdicult compare results across experiments. Generally, issue27fiHowe & Dahlmandevelopers users tend rely default parameter settings. Unfortunately,sometimes developers exploit alternative settings experiments, complicatinglater comparison.Recommendation 11: planner includes parameters, developerguide users settings. not, default settingsused developers others experiments facilitate comparison.Planner Assumption 3: Time Cut-offs Unfair? found little benefitincreasing time cut-offs beyond 15 minutes problems.Recommendation 12: total computation time bottleneck, runproblems separate batches, incrementally increasing time cut-offruns including unresolved problems subsequent runs.additional problems solved run, stop.Metric Assumption 1: Alternative Platforms Lead Different Performance? experiments, performance vary much expected.result suggests researchers general developing specific hardware/softwareconfigurations, recent trends suggest otherwise, least regards memory. Again,systems research prototypes, behooves developer clearhis/her expectations anyone subsequently using system accommodate requests studies.Recommendation 13: factors planner design, researchersmust clearly state hardware/software requirements planners,design based platform assumptions. Additionally, careful study memory versus time trade-offs undertaken, given recent trends memory exploitation.Metric Assumption 2: Number Plan Steps Vary? certainly can.one neglects quality measures, planners penalized efforts declarebest planner.Recommendation 14: expedite generalizing across studies, reportsdescribe performance terms solved (how many types),much time required quality solutions. Tradeoffs reported, possible, e.g., 12% increase computation time30% decrease plan length. Additionally, design goal findoptimal solution, compare planners design goal.Good metrics plan quality sorely needed. latest specification PDDLspecification supports definition problem-specific metrics (Fox & Long, 2002);metrics indicate whether total-time (a new concept supported specification actiondurations) specified functions minimized maximized. additionexcellent start, general metrics plan-length total-time alsoneeded expedite comparisons across problems.28fiA Critical Assessment Benchmark Comparison PlanningRecommendation 15: Developing good metrics valuable research contri-bution. Researchers consider worthwhile project, conference organizers reviewers encourage papers topic, planner developersimplement planners responsive new quality metrics (i.e.,support tunable heuristics evaluation criteria).5. ConclusionsFair evaluation comparison planners hard. Many apparently benign factors exertsignificant effects performance. Superior performance one planner anotherproblem neither intentionally designed solve may explained minorrepresentational features. However, comparative analysis general problems practicalimportance practical create specialized solution every problem.analyzed effects experiment design decisions empirical comparisonplanners made recommendations ameliorating effects decisions.recommendations common sense suggestions improving currentmethodology.expand beyond current methodology require least two substantive changes.First, field needs question whether trying show performanceplanning problems general. shift general comparisons focused comparisons (onproblem class mechanism hypothesis testing) could produce significant advancesunderstanding planning.Second, benchmark problem sets require attention. Many problemsdiscarded simple show much. domains far removedreal applications. may time revisit testbeds. example, several researchersrobotics constructed interactive testbed comparing motion planning algorithms(Piccinocchi, Ceccarelli, Piloni, & Bicchi, 1997). testbed consists user interfacedefining new problems, collection well-known algorithms simulator testingalgorithms specific problems. Thus, user design his/her problems compare performance various algorithms (including own) via web site.testbed affords several advantages current paradigm static benchmark problemsdeveloper conducted comparisons, particular, replicability extendabilitytest set. Alternatively, challenging problem sets developed modifying deployedapplications (Wilkins & desJardins, 2001; Engelhardt, Chien, Barrett, Willis, & Wilklow,2001).recent years, planning community significantly improved size planningproblems solved reasonable time advanced state artempirical comparison systems. interpret results empirical comparisonsunderstand motivate development planning, communityneeds understand effects empirical methodology itself. purposepaper understanding initiate dialogue methodologyused.29fiHowe & DahlmanAcknowledgmentsresearch partially supported Career award National ScienceFoundation IRI-9624058 grant Air Force Oce Scientific Research F4962000-1-0144. U.S. Government authorized reproduce distribute reprintsGovernmental purposes notwithstanding copyright notation thereon.grateful reviewers careful reading well-considered commentssubmitted version; hope done justice suggestions.ReferencesBacchus,F.(2000).AIPS-2000planningcompetition.http://www.cs.toronto.edu/aips2000/SelfContainedAIPS-2000.ppt.Barrett, A., Golden, K., Penberthy, S., & Weld, D. (1993). UCPOP User's Manual. Dept.Computer Science Engineering, University Washington, Seattle, WA. TR93-09-06.Blum, A. L., & Furst, M. L. (1997). Fast planning planning graph analysis. ArtificialIntelligence Journal, 90 (1-2), 225{279.Bonet, B., & Geffner, H. (1999). Planning heuristic search: New results. ProceedingsFifth European Conference Planning (ECP-99) Durham, UK.Chien, S., Kambhampati, S., & Knoblock, C. A. (Eds.)(2000). Proceedings FifthInternational Conference Artificial Intelligence Planning Scheduling (AIPS2000). AAAI Press, Breckenridge, CO.Cohen, P. R. (1991). survey eighth national conference artificial intelligence:Pulling together pulling apart? AI Magazine, 12 (1), 16{41.Cohen, P. R. (1995). Empirical Methods Artificial Intelligence. MIT Press.Drummond, M. E., Kaelbling, L. P., & Rosenschein, S. J. (1990). Collected notesbenchmarks metrics workshop. Artificial intelligence branch FIA-91-06, NASAAmes Research Center.Engelhardt, B., Chien, S., Barrett, T., Willis, J., & Wilklow, C. (2001). data-chasercitizen explorer benchmark problem sets. Proceedings Sixth EuropeanConference Planning (ECP 01) Toledo, Spain.Estlin, T. A., & Mooney, R. J. (1997). Learning improve ecicency qualityplanning. Proceedings Fifteenth International Joint Conference ArtificialIntelligence, pp. 1227{1233, Nagoya, Japan.Fox, M., & Long, D. (1999). ecient implementation plan-graph STAN.Journal Artificial Intelligence Research, 10, 87{115.Fox, M., & Long, D. (2002). PDDL2.1: extension PDDL expressing temporalplanning domains. Available http://www.dur.ac.uk/d.p.long/pddl2.ps.gz.30fiA Critical Assessment Benchmark Comparison PlanningGenevini, A., & Schubert, L. (1996). Accelerating partial-order planners: techniqueseffective search control pruning. Journal Artificial Intelligence Research, 5,95{137.Hanks, S., Nguyen, D., & Thomas, C. (1993). beginner's guide truckworld simulator. Dept. Computer Science Engineering UW-CSE-TR 93-06-09, UniversityWashington.Hanks, S., Pollack, M. E., & Cohen, P. R. (1994). Benchmarks, test beds, controlledexperimentation design agent architectures. AI Magazine, 17{42.Haslum, P., & Geffner, H. (2000). Admissible heuristics optimal planning. Proceedings Fifth International Conference Artificial Intelligence PlanningScheduling (AIPS 2000), pp. 140{149, Breckenridge, CO. AAAI Press.Helmert, M. (2001). complexity planning transportation domains. 6thEuropean Conference Planning (ECP'01), Lecture Notes Artificial Intelligence,New York, Springer-Verlag.Hoffmann, J. (2001). Local search topology planning benchmarks: empirical analysis.Proceedings 17th International Joint Conference Artificial IntelligenceSeattle, WA, USA.Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generationheuristic search. Journal Artificial Intelligence Research, 14, 253{302.Howe, A. E., Dahlman, E., Hansen, C., Scheetz, M., & von Mayrhauser, A. (1999). Exploiting competitive planner performance. Proceedings Fifth European ConferencePlanning, Durham, UK.Howe, A. E., von Mayrhauser, A., & Mraz, R. T. (1997). Test case generation AIplanning problem. Automated Software Engineering, 4 (1), 77{106.Joslin, D., & Pollack, M. (1994). Least-cost aw repair: plan refinement strategypartial-order planning. Proceedings Twelfth National Conference ArtificialIntelligence, pp. 1004{1009, Seattle, WA.Kautz, H., & Selman, B. (1998). BLACKBOX: new approach applicationtheorem proving problem solving. Working notes AIPS98 WorkshopPlanning Combinatorial Search, Pittsburgh, PA.Kautz,H.blackbox:SAT technology planning system.http://www.cs.washington.edu/homes/kautz/blackbox/index.html.Kautz, H., & Selman, B. (1999). Unifying SAT-based graph-based planning. Proceedings Sixteenth International Joint Conference Artificial Intelligence, Stockholm, Sweden.Koehler, J. (1999). Handling conditional effects negative goals IPP. Tech. rep.128, Institute Computer Science, Albert Ludwigs University, Freiburg, Germany.31fiHowe & DahlmanKoehler, J., Nebel, B., Hoffmann, J., & Dimopoulos, Y. (1997). Extending planning graphsADL subset. Proceedings Fourth European Conference Planning.McDermott, D., Ghallab, M., Howe, A., Knoblock, C., Ram, A., Veloso, M., Weld, D., &Wilkins, D. (1998). Planning Domain Definition Language.McDermott, D. (2000). 1998 AI planning systems competition. AI Magazine, 21 (2),35{56.Penberthy, J. S., & Weld, D. S. (1992). UCPOP: sound, complete, partial order planneradl. Proceedings Third International Conference Knowledge Representation Reasoning, pp. 103{114.Perez, M. A. (1995). Learning Search Control Knowledge Improve Plan Quality. Ph.D.thesis, Carnegie-Mellon University.Piccinocchi, S., Ceccarelli, M., Piloni, F., & Bicchi, A. (1997). Interactive benchmarkplanning algorithms web. Proceedings IEEE International ConferenceRobotics Automation.Pollack, M. E., & Ringuette, M. (1990). Introducing Tileworld: Experimentally evaluating agent architectures. Proceedings Eight National Conference ArtificialIntelligence, pp. 183{189, Boston, MA.Pollack, M., Joslin, D., & Paolucci, M. (1997). Flaw selection strategies partial-orderplanning. Journal Artificial Intelligence Research, 6, 223{262.Rabideau, G., Englehardt, B., & Chien, S. (2000). Using generic prferences incrementallyimprove plan quality. Proceedings Fifth International Conference ArtificialIntelligence Planning Scheduling (AIPS 2000), Breckenridge, CO.Slaney, J., & Thiebaux, S. (2001). Blocks world revisited. Artificial Intelligence Journal,125 (1-2), 119{153.Srinivasan, R., & Howe, A. E. (1995). Comparison methods improving search eciencypartial-order planner. Proceedings 14th International Joint ConferenceArtificial Intelligence, pp. 1620{1626, Montreal, Canada.Sussman, G. A. (1973). computational model skill acquisition. Tech. rep. Memo no.AI-TR-297, MIT AI Lab.Prodigy Research Group (1992). PRODIGY 4.0; manual tutorial. SchoolComputer Science 92-150, Carnegie Mellon University.Watson, J., Barbulescu, L., Howe, A., & Whitley, L. D. (1999). Algorithm performanceproblem structure ow-shop scheduling. Proceedings Sixteenth NationalConference Artificial Intelligence (AAAI-99), Orlando, FL.Watson, J., Beck, J., Barbulescu, L., Whitley, L. D., & Howe, A. (2001). Toward descriptive model local search cost job-shop scheduling. Proceedings SixthEuropean Conference Planning (ECP'01), Toledo, Spain.32fiA Critical Assessment Benchmark Comparison PlanningWeld, D., Anderson, C., & Smith, D. (1998). Extending graphplan handle uncertaintysensing actions. Proceedings Fifteenth National Conference ArtificialIntelligence Madison, WI.Weld, D. S. (1999). Recent advances AI planning. AI Magazine, 20 (2), 93{122.Wilkins, D. E., & desJardins, M. (2001). call knowledge-based planning. AI Magazine,22 (1), 99{115.33fiJournal Artificial Intelligence Research 17 (2002) 289-308Submitted 6/02; published 10/02Unified Model Structural OrganizationLanguage MusicRens BodRENS@ILLC.UVA .NLInstitute Logic, Language ComputationUniversity Amsterdam, Nieuwe Achtergracht 1661018 WV Amsterdam, NETHERLANDS,School Computing, University LeedsLS2 9JT Leeds, UKAbstractgeneral model predict perceived phrase structure languagemusic? usually assumed humans separate faculties languagemusic, work focuses commonalities rather differencesmodalities, aiming finding deeper "faculty". key idea perceptual systemstrives simplest structure (the "simplicity principle"), biasedlikelihood previous structures (the "likelihood principle"). present series dataoriented parsing (DOP) models combine two principles testedPenn Treebank Essen Folksong Collection. experiments show (1)combination two principles outperforms use either them, (2) exactlymodel parameter setting achieves maximum accuracy languagemusic. argue results suggest interesting parallel linguisticmusical structuring.1. Introduction: Problem Structural Organizationwidely accepted human cognitive system tends organize perceptual informationhierarchical descriptions conveniently represented tree structures. Treestructures used describe linguistic perception (e.g. Wundt, 1901; Chomsky,1965), musical perception (e.g. Longuet-Higgins, 1976; Lerdahl & Jackendoff, 1983)visual perception (e.g. Palmer, 1977; Marr, 1982). Yet, little attention paidcommonalities different forms perception question whetherexists general, underlying mechanism governs perceptual organization. paperstudies exactly question: acknowledging differences perceptualmodalities, general model predict perceived tree structure sensoryinput? studying question, use empirical methodology: modelmight hypothesize tested manually analyzed benchmarkslinguistically annotated Penn Treebank (Marcus et al. 1993) musically annotatedEssen Folksong Collection (Schaffrath, 1995). argue general modelstructural organization language, music vision, carry experimentslinguistic musical benchmarks, since benchmark visual tree structures currentlyavailable, best knowledge.Figure 1 gives three simple examples linguistic, musical visual informationcorresponding tree structures printed (these examples resp. taken Martin et al.1987, Lerdahl & Jackendoff, 1983, Dastani, 1998).2002 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiBODList sales products 1973NPNPNPVDTPPNPPPNPNList sales products 1973Figure 1: Examples linguistic, musical visual input tree structuresThus, tree structure describes parts input combine constituentsconstituents combine representation whole input. Note linguistictree structure labeled syntactic categories, whereas musical visual treestructures unlabeled. language syntactic constraintswords combined larger constituents (e.g. English determiner combinednoun precedes noun, expressed rule NP DT N),music (and lesser extent vision) restrictions: principle notemay combined note.Apart differences, also fundamental commonality: perceptual inputundergoes process hierarchical structuring found input itself. mainproblem thus: derive perceived tree structure given input?problem trivial may illustrated fact inputs also assignedfollowing, alternative tree structures:NPPPNPVDTNPPPNPNList sales products 1973Figure 2: Alternative tree structures inputs Figure 1alternative structures possible perceived. linguistic treestructure Figure 1 corresponds meaning different tree Figure 2.two musical tree structures correspond different groupings motifs. twovisual structures correspond different visual Gestalts. alternative treestructures possible, plausible: correspond structuresactually perceived human cognitive system.phenomenon input may assigned different structural organizationsknown ambiguity problem. problem one hardest problems modelinghuman perception. Even language, phrase-structure grammar may specifywords combined constituents, ambiguity problem notoriously hard (cf.Manning & Schtze, 1999). Charniak (1997: 37) argues many sentences WallStreet Journal one million different parse trees. ambiguity problem290fiA UNIFIED MODEL STRUCTURAL ORGANIZATION LANGUAGE MUSICmusical input even harder, since virtually constraints notes maycombined constituents. Talking rhythm perception music, Longuet-HigginsLee (1987) note "Any given sequence note values principle infinitely ambiguous,ambiguity seldom apparent listener.".following Section, discuss two principles traditionally proposedsolve ambiguity: likelihood principle simplicity principle. Section 3,argue new integration two principles within data-oriented parsing framework.hypothesis human cognitive system strives simplest structure generatedshortest derivation, biased frequency previouslyperceived structures. Section 4, go computational aspects model.Section 5, discuss linguistic musical test domains. Section 6 presents empiricalinvestigation comparison model. Finally, Section 7, give discussionapproach go combinations simplicity likelihood proposedliterature.2. Two principles: Likelihood Simplicitypredict set possible tree structures tree actuallyperceived human cognitive system? field visual perception, two competingprinciples traditionally proposed govern structural organization. first, initiatedHelmholtz (1910), advocates likelihood principle: perceptual input organizedprobable structure. second, initiated Wertheimer (1923) developedGestalt psychologists, advocates simplicity principle: perceptual systemviewed finding simplest rather probable structure (see Chater, 1999,overview). two principles also used linguistic musical structuring.following, briefly review principles modality.2.1 Likelihoodlikelihood principle particularly influential field natural languageprocessing (see Manning Schtze, 1999, review). field, appropriatetree structure sentence assumed likely structure. likelihood treecomputed probabilities parts (e.g. phrase-structure rules) turnestimated large manually analyzed language corpus, i.e. treebank. State-of-the-artprobabilistic parsers Collins (2000), Charniak (2000) Bod (2001a) obtain around90% precision recall Penn Wall Street Journal treebank (Marcus et al. 1993).likelihood principle also applied musical perception, e.g. Raphael (1999)Bod (2001b/c). probabilistic natural language processing, probable musicaltree structure computed probabilities rules fragments taken largeannotated musical corpus. musical benchmark used modelsEssen Folksong Collection (Schaffrath, 1995).Also vision science, huge interest probabilistic models (e.g. Hoffman, 1998;Kersten, 1999). Mumford (1999) even seen fit declare Dawning Stochasticity.Unfortunately, visual treebanks currently available.2.2 Simplicitysimplicity principle long tradition field visual perception psychology (e.g.Restle, 1970; Leeuwenberg, 1971; Simon, 1972; Buffart et al. 1983; van der Helm, 2000).291fiBODfield, visual pattern formalized constituent structure means visual codinglanguage based primitive elements line segments angles. Perceptiondescribed process selecting simplest structure corresponding "shortestencoding" visual pattern.notion simplicity also applied music perception. Collard et al. (1981) usecoding language Leeuwenberg (1971) predict metrical structure four preludesBach's Well-Tempered Clavier. well-known music perception theoryproposed Lerdahl Jackendoff (1983). theory contains two kinds rules: "wellformedness rules" "preference rules". role well-formedness rules definekinds formal objects (grouping structures) theory employs. grouping structureslistener actually hears, described preference rules describe Gestaltpreferences kind identified Wertheimer (1923), therefore also seenembodiment simplicity principle.Notions simplicity also exist language processing. example, Frazier (1978)viewed arguing parser prefers simplest structure containing minimalattachments. Bod (2000a) defines simplest tree structure sentence structuregenerated smallest number subtrees given treebank.3. Combining Likelihood Simplicitykey idea current paper principles play role perceptual organization,albeit rather different ones: simplicity principle general cognitive preferenceeconomy, likelihood principle probabilistic bias due previous perceptualexperiences. Informally stated, working hypothesis human cognitive systemstrives simplest structure generated shortest derivation,biased frequency previously perceived structures (some combinationssimplicity likelihood discussed Section 7). formally instantiate workinghypothesis, first need model defines set possible structures input.paper, chosen model defines set phrase-structures inputbasis treebank previously analyzed input, known Data-OrientedParsing DOP model (see Bod, 1998; Collins & Duffy, 2002). DOP learns grammarextracting subtrees given treebank combines subtrees analyze fresh input.chosen DOP (1) uses subtrees arbitrary size, thereby capturing nonlocal dependencies, (2) obtained competitive results various benchmarks(Bod, 2001a/b; Collins & Duffy, 2002). following, first review DOP modeldiscuss use likelihood simplicity principles approach. Next, showtwo principles combined instantiate working hypothesis.3.1 Data-Oriented ParsingSection, illustrate DOP model linguistic example (for rigorous definitionDOP, reader referred Bod, 1998). come back musical examplesSection 5. Suppose given following extremely small linguistic treebank twotrees resp. wanted dress rack saw dog telescope(actual treebanks contain tens thousands trees, cf. Marcus et al. 1993):292fiA UNIFIED MODEL STRUCTURAL ORGANIZATION LANGUAGE MUSICNPVPVNPwantedPPNPsawNPdress PVPVPPNPVPNPNPPdog telescoperackFigure 3: example treebankDOP model parse new sentence, e.g. saw dress telescope,combining subtrees treebank means substitution operation (indicated ):VPNPNPPPNPPdress=telescopeVPPPNPVVPNPVPPPNPVsawsawPNPdress telescopeFigure 4: Parsing sentence combining subtrees Figure 3Thus substitution operation combines two subtrees substituting second subtreeleftmost nonlexical leaf node first subtree (the result may combinedthird subtree, etc.). combination subtrees results tree structurewhole sentence called derivation. Since many different subtrees, varioussizes, typically also many different derivations produce, however, tree;instance:NPVPNPVPVsawdressPVPNPPPNP=NPVPVtelescopePPNPPNPsaw dress telescopeFigure 5: different derivation produces parse tree293fiBODinteresting case occurs different derivations produce differentparse trees. happens sentence ambiguous; example, DOP also producesfollowing alternative parse tree saw dress telescope:NPVPVVsawP=PPNPNPtelescopeNPVPVNPsawNPPPPPNPdressdressPNPtelescopeFigure 6: different derivation produces different parse tree3.2 Likelihood-DOPBod (1993), DOP enriched likelihood principle predict perceived treestructure set possible structures. model, call Likelihood-DOP,computes probable tree input occurrence-frequencies subtrees.probability subtree t, P(t), computed number occurrences t, | |, dividedtotal number occurrences treebank-subtrees root label t.Let r(t) return root label t. may write:P(t) =|t|t': r(t')= r( t)| t' |probability derivation t1...tn computed product probabilitiessubtrees ti:P(t1...tn ) =P(ti)seen, may different derivations generate parse tree.probability parse tree thus sum probabilities distinct derivations. Lettid i-th subtree derivation produces tree T, probability givenP(T) =P(tid)294fiA UNIFIED MODEL STRUCTURAL ORGANIZATION LANGUAGE MUSICparsing sentence s, interested trees assigned s,denote Ts. best parse tree, Tbest, according Likelihood-DOP treemaximizes probability Ts:Tbest = arg max P(Ts)TsThus Likelihood-DOP computes probability tree sum products,product corresponds probability certain derivation generating tree.distinguishes Likelihood-DOP statistical parsing models identify exactlyone derivation parse tree thus compute probability tree oneproduct probabilities (e.g. Charniak, 1997; Collins, 1999; Eisner, 1997). Likelihood-DOP'sprobability model allows including counts subtrees wide range sizes: everythingcounts single-level rules counts entire trees.Note subtree probabilities Likelihood-DOP directly estimatedrelative frequencies treebank-trees. relative-frequency estimator obtainscompetitive results several domains (Bonnema et al. 1997; Bod, 2001a; De Pauw, 2000),maximize likelihood training data (Johnson, 2002).may hidden derivations relative-frequency estimator cannot deal with. 1estimation procedures take account hidden derivations maximizelikelihood training data. example, Bod (2000b) presents Likelihood-DOP modelestimates subtree probabilities maximum likelihood re-estimation procedurebased expectation-maximization algorithm (Dempster et al. 1977). However, sincerelative frequency estimator far outperformed estimator (seeBod et al. 2002b), stick relative frequency estimator current paper.3.3 Simplicity-DOPLikelihood-DOP justice preference humans display simpleststructure generated shortest derivation input. Bod (2000a), simplest treestructure input defined tree constructed smallest numbersubtrees treebank. refer model Simplicity-DOP. Insteadproducing probable parse tree input, Simplicity-DOP thus produces parsetree generated shortest derivation consisting fewest treebank-subtrees,independent probabilities subtrees. define length derivation d,L(d), number subtrees d; thus = t1...tn L(d) = n. Let derivationresults parse tree T, best parse tree, Tbest, according Simplicity-DOPtree produced derivation minimal length:Tbest = arg min L(d Ts )TsSection 3.2, Ts parse tree sentence s. example, given treebank Figure3, simplest parse tree saw dress telescope given Figure 5, since1 subtrees restricted depth 1 relative frequency estimator coincidemaximum likelihood estimator. depth-1 DOP model corresponds stochastic context-freegrammar. well-known DOP models allow subtrees greater depth outperform depth-1DOP models (Bod, 1998; Collins & Duffy, 2002).295fiBODparse tree generated derivation two treebank-subtrees,parse tree Figure 6 (and parse tree) needs least three treebank-subtreesgenerated. 2shortest derivation may unique: happen different parse treessentence generated minimal number treebank-subtrees (alsoprobable parse tree may unique, never happens practice). caseback frequency ordering subtrees. is, subtrees root labelassigned rank according frequency treebank: frequent subtree (orsubtrees) root label gets rank 1, second frequent subtree gets rank 2, etc.Next, rank (shortest) derivation computed sum rankssubtrees involved. derivation smallest sum, highest rank, taken finalbest derivation producing final best parse tree Simplicity-DOP (see Bod, 2000a).performed one little adjustment rank subtree. adjustment averagesrank subtree ranks sub-subtrees. is, instead simply takingrank subtree, compute rank subtree (arithmetic) mean rankssub-subtrees (including subtree itself). effect techniqueredresses low-ranked subtree contains high-ranked sub-subtrees.Simplicity-DOP Likelihood-DOP obtain rather similar parse accuracyWall Street Journal Essen Folksong Collection (in terms precision/recall -- seeSection 6), best trees predicted two models quite match. suggestscombined model, justice simplicity likelihood, may boost accuracy.3.4 Combining Likelihood-DOP Simplicity-DOP: SL-DOP LS-DOPunderlying idea combining likelihood simplicity human perceptual systemsearches simplest tree structure (generated shortest derivation)biased likelihood tree structure. is, instead selecting simplest treeper se, combined model selects simplest tree among n likeliest trees, nfree parameter. course ways combine simplicity likelihoodwithin DOP framework. straightforward alternative would selectprobable tree among n simplest trees, suggesting perceptual systemsearching probable structure among simplest ones. referfirst combination simplicity likelihood (which selects simplest among nlikeliest trees) Simplicity-Likelihood-DOP SL-DOP, second combination(which selects likeliest among n simplest trees) Likelihood-Simplicity-DOP LSDOP. Note n=1, Simplicity-Likelihood-DOP equal Likelihood-DOP, sinceone probable tree select from, Likelihood-Simplicity-DOP equalSimplicity-DOP, since one simplest tree select from. Moreover, n gets large,SL-DOP converges Simplicity-DOP LS-DOP converges Likelihood-DOP.varying parameter n, able compare Likelihood-DOP, Simplicity-DOPseveral instantiations SL-DOP LS-DOP.2 One might argue straightforward metric simplicity would return parse treesmallest number nodes (rather smallest number treebank-subtrees). metricknown perform quite badly (see Manning & Schtze, 1999; Bod, 2000a).296fiA UNIFIED MODEL STRUCTURAL ORGANIZATION LANGUAGE MUSIC4. Computational IssuesBod (1993) showed standard chart parsing techniques applied Likelihood-DOP.treebank-subtree converted context-free rule r lefthand side rcorresponds root label righthand side r corresponds frontier labelst. Indices link rules original subtrees maintain subtree's internalstructure probability. rules used create derivation forest sentence(using chart parser -- see Charniak, 1993), probable parse computedsampling sufficiently large number random derivations forest ("Monte Carlodisambiguation", see Bod, 1998). technique successfully applied parsingATIS portion Penn Treebank (Marcus et al. 1993), extremely time consuming.mainly number random derivations sampled reliablyestimate probable parse increases exponentially sentence length (seeGoodman, 2002). therefore questionable whether Bod's sampling technique scaledlarger domains Wall Street Journal (WSJ) portion Penn Treebank.Goodman (1996) showed Likelihood-DOP reduced compact stochasticcontext-free grammar (SCFG) contains exactly eight SCFG rules nodetraining set trees. Although Goodman's method still allow efficient computationprobable parse (in fact, problem computing probable parseLikelihood-DOP NP-hard -- see Sima'an, 1996), method allow efficientcomputation "maximum constituents parse", i.e. parse tree likelylargest number correct constituents. Unfortunately, Goodman's SCFG reduction methodbeneficial indeed subtrees used, maximum parse accuracy usuallyobtained restricting subtrees. example, Bod (2001a) shows "optimal"subtree set achieving highest parse accuracy WSJ obtained restrictingmaximum number words subtree 12 restricting maximum depthunlexicalized subtrees 6. Goodman (2002) shows subtree restrictions,subtree depth, may incorporated reduction method, found reductionmethod optimal subtree set.paper therefore use Bod's subtree-to-rule conversion method LikelihoodDOP, use Bod's Monte Carlo sampling technique derivation forests,turned computationally prohibitive. Instead, use well-known Viterbioptimization algorithm chart parsing (cf. Charniak, 1993; Manning & Schtze, 1999)allows computing k probable derivations input cubic time. Usingalgorithm, estimate probable parse tree input 10,000probable derivations, summing probabilities derivations generate tree.Although approach guarantee probable parse tree actually found,shown Bod (2000a) perform least well estimation probableparse Monte Carlo techniques ATIS corpus. Moreover, approach knownobtain significantly higher accuracy selecting parse tree generated singleprobable derivation (Bod, 1998; Goodman, 2002), therefore considerpaper.Simplicity-DOP, also first convert treebank-subtrees rewrite rulesLikelihood-DOP. Next, simplest tree, i.e. shortest derivation, efficientlycomputed Viterbi optimization way probable derivation, providedassign rules equal probabilities, case shortest derivation equalprobable derivation. seen follows: rule probability pprobability derivation involving n rules equal p n, since 0<p<1 derivation297fiBODfewest rules greatest probability. experiments Section 6, giverule probability mass equal 1/R, R number distinct rules derived Bod'smethod. mentioned 3.3, shortest derivation may unique. casecompute shortest derivations input apply ranking schemederivations. ranks shortest derivations computed summing rankssubtrees involve. shortest derivation smallest sum subtree rankstaken produce best parse tree.SL-DOP LS-DOP, compute either n likeliest n simplest trees meansViterbi optimization. Next, either select simplest tree among n likeliest ones (forSL-DOP) likeliest tree among n simplest ones (for LS-DOP). experiments, nnever larger 1,000.5. Test Domainslinguistic test domain used Wall Street Journal (WSJ) portion PennTreebank (Marcus et al. 1993). portion contains approx. 50,000 sentencesmanually annotated perceived linguistic tree structures using predefined setlexico-syntactic labels. Since WSJ extensively used describedliterature (cf. Manning & Schtze, 1999; Charniak, 2000; Collins, 2000; Bod, 2001a),go here.musical test domain used European folksongs Essen FolksongCollection (Schaffrath, 1995; Huron, 1996), correspond approx. 6,200 folksongsmanually enriched perceived musical grouping structures. EssenFolksong Collection previously used Bod (2001b) Temperley (2001) testmusical parsers. current paper presents first experiments Likelihood-DOP,Simplicity-DOP, SL-DOP LS-DOP collection. Essen folksongsrepresented staff notation encoded Essen Associative Code (ESAC).pitch encodings ESAC resemble "solfege": scale degree numbers used replacemovable syllables "do", "re", "mi", etc. Thus 1 corresponds "do", 2 corresponds "re", etc.Chromatic alterations represented adding either "#" "b" number.plus ("+") minus ("-") signs added number note falls resp.principle octave (thus -1, 1 +1 refer al "do", different octaves).Duration represented adding period underscore number. period (".")increases duration 50% underscore ("_") increases duration 100%;one underscore may added number. number duration indicator,duration corresponds smallest value. Thus pitches ESAC encoded integers1 7 possibly preceded followed symbols octave, chromatic alterationduration. pitch encoding treated atomic symbol, may simple "1"complex "+2#_.". pause represented 0, possibly followed durationindicators, also treated atomic symbol. loudness timbre indicators usedESAC.Phrase boundaries indicated hard returns ESAC. phrases unlabeled (cf.Section 1 paper). Yet make ESAC annotations readable DOP models,added three basic labels phrase structures: label "S" whole song,label "P" phrase, label "N" atomic symbol. way, obtainedconventional tree structures could directly employed DOP models parse newinput. use label "N" distinguishes annotations previous work (Bod,298fiA UNIFIED MODEL STRUCTURAL ORGANIZATION LANGUAGE MUSIC2001b/c) used labels song phrase ("S" "P"). addition "N"enhances productivity robustness musical parsing model, although also leadsmuch larger number subtrees.example, assume simple melody consisting two phrases, (1 2) (2 3),tree structure given Figure 7.PPNNNN1223Figure 7: Example musical tree structure consisting two phrasesSubtrees extracted tree structure include following:PNPPNNNN2331Figure 8: subtrees extracted tree figure 7Thus first subtree indicates phrase starting note 1, followed exactly one(unspecified) note, phrase followed exactly one (unspecified) phrase.subtrees used parse new musical input way explainedlinguistic parsing Section 3.6. Experimental Evaluation Comparisonevaluate DOP models, used blind testing method randomly dividestreebank training set test set, strings test set parsedmeans subtrees training set. applied standard PARSEVAL metricsprecision recall compare proposed parse tree P corresponding correct testset parse tree follows (cf. Black et al. 1991):# correct constituents P# correct constituents PPrecision =Recall =# constituents P# constituentsconstituent P "correct" exists constituent label spansatomic symbols (i.e. words notes).3 Since precision recall obtain rather3 precision recall scores computed using "evalb" program (available viahttp://www.cs.nyu.edu/cs/projects/proteus/evalb/)299fiBODdifferent results (see Bod, 2001b), often balanced single measureperformance, known F-score (see Manning & Schtze, 1999):F-score =2 Precision RecallPrecision + Recallexperiments, divided treebanks (i.e. WSJ Essen FolksongCollection) 10 training/test set splits: 10% WSJ used test material time(sentences 40 words), Essen Folksong Collection test sets 1,000 folksongsused time. words test set unknown training set,guessed categories using statistics word-endings, hyphenation capitalization(cf. Bod, 2001a); unknown notes. previous work (Bod, 2001a), limitedmaximum size subtrees depth 14, used random samples 400,000 subtreesdepth > 1 14.4 Next, restricted maximum number atomic symbolssubtree 12 maximum depth unlexicalized subtrees 6. subtreessmoothed technique described Bod (1998: 85-94) based simple Good-Turingestimation (Good, 1953).Table 1 shows mean F-scores obtained SL-DOP LS-DOP languagemusic various values n. Recall n=1, SL-DOP equal Likelihood-DOPLS-DOP equal Simplicity-DOP.n1510111213141520501001,000SL-DOPLS-DOP(simplest among n likeliest)(likeliest among n simplest)LanguageMusicLanguageMusic87.9%89.3%90.2%90.2%90.2%90.2%90.2%90.2%90.0%88.7%86.8%85.6%86.0%86.8%87.2%87.3%87.3%87.3%87.2%87.2%86.9%85.6%84.3%84.3%85.6%86.1%87.0%87.0%87.0%87.0%87.0%87.0%87.1%87.4%87.9%87.9%84.3%85.5%85.7%85.7%85.7%85.7%85.7%85.7%85.7%86.0%86.0%86.0%Table 1: F-scores obtained SL-DOP LS-DOP language music4 random subtree samples selected first exhaustively computing complete setsubtrees (this computationally prohibitive). Instead, particular depth > 1 sampledsubtrees randomly selecting node random tree training set, selectedrandom expansions node subtree particular depth obtained. repeatedprocedure 400,000 times depth > 1 14.300fiA UNIFIED MODEL STRUCTURAL ORGANIZATION LANGUAGE MUSICTable shows increase accuracy SL-DOP LS-DOPvalue n increases 1 11. accuracy SL-DOP decreases n=13converges Simplicity-DOP (i.e. LS-DOP n=1), accuracy LS-DOP continuesincrease converges Likelihood-DOP (i.e. SL-DOP n=1). highest accuracyobtained SL-DOP 11 n 13, language music. Thus SL-DOP outperformsLikelihood-DOP Simplicity-DOP, selection simplest structuretop likeliest ones turns promising model selection likelieststructure top simplest ones. According paired t-testing, accuracyimprovement SL-DOP n=11 SL-DOP n=1 (when equal Likelihood-DOP)statistically significant language (p<.0001) music (p<.006).surprising SL-DOP reaches highest accuracy small value n.even surprising exactly model (with parameter setting) obtainsmaximum accuracy language music. model embodies ideaperceptual system strives simplest structure searches amongprobable structures.compare results language others, also tested SL-DOP n=11standard division WSJ, uses sections 2 21 training (approx. 40,000sentences) section 23 testing (2416 sentences 100 words) (see e.g. Manning &Schtze, 1999; Charniak, 2000; Collins, 2000). division, SL-DOP achieved F-score90.7% best previous models obtained F-score 89.7% (Collins, 2000; Bod,2001a). terms error reduction, SL-DOP improves 9.6% models.common also report accuracy sentences 40 words WSJ, SLDOP obtained F-score 91.8%.musical results compared Bod (2001b/c), tested three probabilisticparsing models increasing complexity training/test set splits EssenFolksong Collection. best results obtained hybrid DOP-Markov parser:80.7% F-score. significantly worse best result 87.3% obtained SL-DOPsplits Essen folksongs. difference may explained facthybrid DOP-Markov parser Bod (2001b/c) takes account context highernodes tree sister nodes, DOP models presentedcurrent paper take subtree account (almost) arbitrary width depth, therebycovering larger amount musical context. Moreover, mentioned Section 5, modelsBod (2001b/c) use label "N" notes; instead, Markov approach usedparse new sequences notes.would also interesting compare musical results melodic parserTemperley (2001), uses system preference rules similar Lerdahl Jackendoff(1983), also evaluated Essen Folksong Collection.tested several test sets 1,000 randomly selected folksongs, Temperley used one testset 65 folksongs moreover cleaned eliminating folksongs irregularmeter (Temperley, 2001: 74). therefore difficult compare results Temperley's;yet, noteworthy Temperley's parser correctly identified 75.5% phraseboundaries. Although lower 87.3% obtained SL-DOP, Temperley's parser"trained" previously analyzed examples like model (though noteTemperley's results obtained tuning optimal phrase length parseraverage phrase length Essen Folksong Collection).perhaps mentioned parsing models trained treebanks widelyused natural language processing, still rather uncommon musical processing.301fiBODmusical parsing models, including Temperley's, employ rule-based approachparsing based combination low-level rules -- "prefer phrase boundarieslarge intervals" -- higher-level rules -- "prefer phrase boundaries changesharmony". low-level rules usually based well-known Gestalt principlesproximity similarity (Wertheimer, 1923), prefer phrase boundaries largerintervallic distances. However, Bod (2001c) shown Gestalt principlespredict incorrect phrase boundaries number folksongs, higher-levelphenomena cannot alleviate incorrect predictions. folksongs contain phraseboundary falls large pitch time interval (which calledjump-phrases) rather intervals -- would predicted Gestalt principles.Moreover, musical factors, melodic parallelism, meter harmony, predictexactly incorrect phrase boundaries cases (see Bod, 2001b/c details).conjectured jump-phrases inherently memory-based, reflecting idiomdependent pitch contours (cf. Huron, 1996; Snyder, 2000), best capturedmemory-based model tries mimic musical experience listenercertain culture (Bod, 2001c).7. Discussion Conclusionseen combination simplicity likelihood quite rewarding linguisticmusical structuring, suggesting interesting parallel two modalities. Yet, onemay question whether model massively memorizes re-uses previously perceivedstructures cognitive plausibility. Although question important wantclaim cognitive relevance model, appears evidence people storevarious kinds previously heard fragments, language (Jurafsky, 2002) music(Saffran et al. 2000). people store fragments arbitrary size, proposed DOP?overview article, Jurafsky (2002) reports large body psycholinguistic evidenceshowing people store lexical items bigrams, also frequent phraseseven whole sentences. case sentences, people store idiomatic sentences,also "regular" high-frequency sentences.5 Thus, least languageevidence humans store fragments arbitrary size provided fragmentscertain minimal frequency. suggests humans need always parse new inputrules grammar, productively re-use previously analyzed fragments.Yet, evidence people store fragments hear, suggested DOP.high-frequency fragments seem memorized. However, human perceptualfaculty needs learn fragments stored, initially need keep trackfragments (with possibility forgetting them) otherwise frequencies neveraccumulate. results model continuously incrementally updates fragmentmemory given new input -- correspondence DOP approach, alsoapproaches (cf. Daelemans, 1999; Scha et al. 1999; Spiro, 2002).acknowledge importance rule-based system acquiring fragment memory,substantial memory available may efficient construct tree meansalready parsed fragments constructing entirely means rules. many cognitive5 results derived differences reaction times sentence recognitionfrequency (whole) test sentences varied, variables, lexical frequency,bigram frequency, plausibility, syntactic/semantic complexity, etc., kept constant.302fiA UNIFIED MODEL STRUCTURAL ORGANIZATION LANGUAGE MUSICactivities advantageous store results, immediately retrievedmemory, rather computing time scratch. shown,example, manual reaches (Rosenbaum et al. 1992), arithmetic operations (Rickard et al.1994), word formation (Baayen et al. 1997), mention few. linguistic musicalparsing may exception this.stressed experiments reported paper limited least tworespects. First, musical test domain rather restricted. wide variety linguistictreebanks currently available (see Manning & Schtze, 1999), number musicaltreebanks extremely limited. thus need larger richer annotated musicalcorpora covering broader domains. development annotated corpora may timeconsuming, experience natural language processing shown wortheffort, since corpus-based parsing systems dramatically outperform grammar-based parsingsystems. second limitation experiments evaluated parseresults rather parse process. is, assessed accuratelymodels mimic input-output behavior human annotator, without investigatingprocess annotator arrived perceived structures. unlikely humansprocess perceptual input computing 10,000 likely derivations using random samples400,000 subtrees current paper. Yet, many applications sufficesknow perceived structure rather process led structure.seen combination simplicity likelihood predicts perceived structurehigh degree accuracy.proposals integrating principles simplicity likelihoodhuman perception (see Chater, 1999 review). Chater notes contextInformation Theory (Shannon, 1948), principles simplicity likelihood identical.context, simplicity principle interpreted minimizing expected length encodemessage i, log2 p bits, leads result maximizingprobability i. used information-theoretical definition simplest structureSimplicity-DOP, would return structure Likelihood-DOP, improvedresults would obtained combination two. hand, definingsimplest structure one generated smallest number subtrees, independentprobabilities, created notion simplicity provably different notionlikely structure, which, combined Likelihood-DOP, obtained improved results.Another integration two principles may provided notion MinimumDescription Length MDL (cf. Rissanen, 1978). MDL principle viewedpreferring statistical model allows shortest encoding training data.relevant encoding consists two parts: first part encodes model data,second part encodes data terms model (in bit length). MDL closely relatedstochastic complexity (Rissanen, 1989) Kolmogorov complexity (Li Vitanyi, 1997),used natural language processing estimating parameters stochasticgrammar (e.g. Osborne, 1999). leave open research question whetherMDL successfully used estimating parameters DOP's subtrees. However,since MDL known give asymptotically results maximum likelihood estimation(MLE) (Rissanen, 1989), application DOP may lead unproductive model.maximum likelihood estimator assign training set trees empiricalfrequencies, assign 0 weight trees (see Bonnema, 2002 proof).would result model generate training data strings.Johnson (2002) argues may overlearning problem rather problem303fiBODMLE per se, standard methods, cross-validation regularization, would seemprinciple ways avoid overlearning. leave issue futureinvestigation.idea general underlying model language music uncontroversial.linguistics usually assumed humans separate language faculty, LerdahlJackendoff (1983) argued separate music faculty. work proposeseparate faculties exist, wants focus commonalities ratherdifferences faculties, aiming finding deeper "faculty" may holdperception general. hypothesis perceptual system strives simpleststructure searches among likeliest structures.AcknowledgementsThanks Aline Honingh, Remko Scha, Neta Spiro, Menno van Zaanen three anonymousreviewers excellent comments. preliminary version paper presentedkeynote talk LCG workshop ("Learning Computational Grammars", Tbingen, 2001).ReferencesBaayen, R. H., Dijkstra, T. & Schreuder, R. (1997). Singular Plurals Dutch: EvidenceParallel Dual-Route Model. Journal Memory Language, 37, 94-117.Black, E., Abney, S., Flickinger, D., Gnadiec, C., Grishman, R., Harrison, P., Hindle, D.,Ingria, R., Jelinek, F., Klavans, J., Liberman, M., Marcus, M., Roukos, S., Santorini, B.& Strzalkowski, T. (1991). Procedure Quantitatively Comparing SyntacticCoverage English, Proceedings DARPA Speech Natural LanguageWorkshop, Pacific Grove, Morgan Kaufmann.Bod, R. (1993). Using Annotated Language Corpus Virtual Stochastic Grammar.Proceedings AAAI-93, Menlo Park, Ca.Bod, R. (1998). Beyond Grammar: Experience-Based Theory Language. Stanford:CSLI Publications (Lecture notes number 88).Bod, R. (2000a). Parsing Shortest Derivation. Proceedings COLING-2000,Saarbrcken, Germany.Bod, R. (2000b). Combining Semantic Syntactic Structure Language Modeling.Proceedings ICSLP-2000, Beijing, China.Bod, R. (2001a). Minimal Set Fragments Achieves Maximal ParseAccuracy? Proceedings ACL'2001, Toulouse, France.Bod, R. (2001b). Memory-Based Model Music Analysis. Proceedings InternationalComputer Music Conference (ICMC'2001), Havana, Cuba.Bod, R. (2001c). Memory-Based Models Melodic Analysis: Challenging GestaltPrinciples. Journal New Music Research, 31(1), 26-36. (availablehttp://staff.science.uva.nl/~rens/jnmr01.pdf)304fiA UNIFIED MODEL STRUCTURAL ORGANIZATION LANGUAGE MUSICBod, R., Hay, J. & Jannedy, S. (Eds.) (2002a). Probabilistic Linguistics. Cambridge,MIT Press. (in press)Bod, R., Scha, R. & Sima'an, K. (Eds.) (2002b). Data-Oriented Parsing. Stanford, CSLIPublications. (in press)Bonnema, R. (2002). Probability Models DOP. Bod et al. (2002b).Bonnema, R., Bod, R. & Scha, R. (1997). DOP Model Semantic Interpretation,Proceedings ACL/EACL-97, Madrid, Spain.Buffart, H., Leeuwenberg, E. & Restle , F. (1983). Analysis Ambiguity Visual PatternCompletion. Journal Experimental Psychology: Human PerceptionPerformance. 9, 980-1000.Charniak, E. (1993). Statistical Language Learning, Cambridge, MIT Press.Charniak, E. (1997). Statistical Techniques Natural Language Parsing, AI Magazine,Winter 1997, 32-43.Charniak, E. (2000). Maximum-Entropy-Inspired Parser. Proceedings ANLPNAACL'2000, Seattle, Washington.Chater, N. (1999). Search Simplicity: Fundamental Cognitive Principle?Quarterly Journal Experimental Psychology, 52A(2), 273-302.Chomsky, N. (1965). Aspects Theory Syntax, Cambridge, MIT Press.Collard, R., Vos, P. & Leeuwenberg, E. (1981). Melody Tells Metre Music .Zeitschrift fr Psychologie. 189, 25-33.Collins, M. (1999). Head-Driven Statistical Models Natural Language Parsing, PhDthesis, University Pennsylvania, PA.Collins, M. (2000). Discriminative Reranking Natural Language Parsing, ProceedingsICML-2000, Stanford, Ca.Collins, M. & Duffy, N. (2002). New Ranking Algorithms Parsing Tagging: KernelsDiscrete Structures, Voted Perceptron. Proceedings ACL'2002,Philadelphia, PA.Daelemans, W. (1999). Introduction Special Issue Memory-Based LanguageProcessing. Journal Experimental Theoretical Artificial Intelligence 11(3),287-296.Dastani, M. (1998). Languages Perception. ILLC Dissertation Series 1998-05, UniversityAmsterdam.Dempster, A., Laird, N. & Rubin, D. (1977). Maximum Likelihood Incomplete Data viaEM Algorithm, Journal Royal Statistical Society, 39, 1-38.305fiBODDe Pauw, G. (2000). Aspects Pattern-matching Data-Oriented Parsing, ProceedingsCOLING-2000, Saarbrcken, Germany.Eisner, J. (1997). Bilexical Grammars Cubic-Time Probabilistic Parser, ProceedingsFifth International Workshop Parsing Technologies, Boston, Mass.Frazier, L. (1978). Comprehending Sentences: Syntactic Parsing Strategies. PhD.Thesis, University Connecticut.Good, I. (1953). Population Frequencies Species Estimation PopulationParameters, Biometrika 40, 237-264.Goodman, J. (1996). Efficient Algorithms Parsing DOP Model, ProceedingsEmpirical Methods Natural Language Processing, Philadelphia, PA.Goodman, J. (2002). Efficient Parsing DOP PCFG-Reductions. Bod et al. 2002b.von Helmholtz, H. (1910). Treatise Physiological Optics (Vol. 3), Dover, New York.Hoffman, D. (1998). Visual Intelligence. New York, Norton & Company, Inc.Huron, D. (1996). Melodic Arch Western Folksongs. Computing Musicology 10, 223.Johnson, M. (2002). DOP Estimation Method Biased Inconsistent. ComputationalLinguistics, 28, 71-76.Jurafsky, D. (2002). Probabilistic Modeling Psycholinguistics: ComprehensionProduction. Bod et al. 2002a. (available http://www.colorado.edu/ling/jurafsky/prob.ps)Kersten, D. (1999). High-level vision statistical inference. Gazzaniga , S. (Ed.), NewCognitive Neurosciences, Cambridge, MIT Press.Leeuwenberg, E. (1971). Perceptual Coding Language Perceptual AuditoryPatterns. American Journal Psychology. 84, 307-349.Lerdahl, F. & Jackendoff, R. (1983). Generative Theory Tonal Music. Cambridge,MIT Press.Li, M. & Vitanyi, P. (1997). Introduction Kolmogorov ComplexityApplications (2nd ed.). New York, Springer.Longuet-Higgins, H. (1976). Perception Melodies. Nature 263, 646-653.Longuet-Higgins, H. Lee, C. (1987). Rhythmic Interpretation Monophonic Music.Mental Processes: Studies Cognitive Science, Cambridge, MIT Press.Manning, C. & Schtze, H. (1999). Foundations Statistical Natural LanguageProcessing. Cambridge, MIT Press.Marcus, M., Santorini, B., & Marcinkiewicz, M. (1993). Building Large Annotated CorpusEnglish: Penn Treebank, Computational Linguistics 19(2).306fiA UNIFIED MODEL STRUCTURAL ORGANIZATION LANGUAGE MUSICMarr, D. (1982). Vision. San Francisco, Freeman.Martin, W., Church, K. & Patil, R. (1987). Preliminary Analysis Breadth-first ParsingAlgorithm: Theoretical Experimental Results. Bolc, L. (Ed.), Natural LanguageParsing Systems, Springer Verlag, Berlin.Mumford, D. (1999). dawning age stochasticity. Based lectureAccademia Nazionale dei Lincei. (available http://www.dam.brown.edu/people/mumford/Papers/Dawning.ps)Osborne, M. (1999). Minimal description length-based induction definite clause grammarsnoun phrase identification. Proceedings EACL Workshop ComputationalNatural Language Learning. Bergen, Norway.Palmer, S. (1977). Hierarchical Structure Perceptual Representation. CognitivePsychology, 9, 441-474.Raphael, C. (1999). Automatic Segmentation Acoustic Musical Signals Using HiddenMarkov Models. IEEE Transactions Pattern Analysis Machine Intelligence,21(4), 360-370.Restle , F. (1970). Theory Serial Pattern Learning: Structural Trees. PsychologicalReview, 86, 1-24.Rickard, T., Healy, A. & Bourne Jr., E. (1994). cognitive structure basic arithmeticskills: Operation, order symbol transfer effects. Journal ExperimentalPsychology: Learning, Memory Cognition, 20, 1139-1153.Rissanen, J. (1978). Modeling shortest data description. Automatica, 14, 465-471.Rissanen, J. (1989). Stochastic Complexity Statistical Inquiry. Series ComputerScience - Volume 15. World Scientific, 1989.Rosenbaum, D., Vaughan, J., Barnes, H. & Jorgensen, M. (1992). Time course movementplanning: Selection handgrips object manipulation. Journal ExperimentalPsychology: Learning, Memory Cognition, 18, 1058-1073.Saffran, J., Loman, M. & Robertson, R. (2000). Infant Memory Musical Experiences.Cognition, 77, B16-23.Scha, R., Bod, R. & Sima'an, K. (1999). Memory-Based Syntactic Analysis. JournalExperimental Theoretical Artificial Intelligence, 11(3), 409-440.Schaffrath, H. (1995). Essen Folksong Collection Humdrum Kern Format. D.Huron (ed.). Menlo Park, CA: Center Computer Assisted ResearchHumanities.Shannon, C. (1948). Mathematical Theory Communication. Bell System TechnicalJournal. 27, 379-423, 623-656.Sima'an, K. (1996). Computational Complexity Probabilistic Disambiguation meansTree Grammars. Proceedings COLING-96, Copenhagen, Denmark.307fiBODSimon, H. (1972). Complexity Representation Patterned Sequences Symbols.Psychological Review. 79, 369-382.Snyder, B. (2000). Music Memory. Cambridge, MIT Press.Spiro, N. (2002). Combining Grammar-based Memory-based Models PerceptionTime Signature Phase. Anagnostopoulou, C., Ferrand, M. & Smaill, A. (Eds.).Music Artificial Intelligence, Lecture Notes Artificial Intelligence, Vol. 2445,Springer-Verlag, 186-197.Temperley, D. (2001). Cognition Basic Musical Structures. Cambridge, MITPress.Wertheimer, M. (1923). Untersuchungen zur Lehre von der Gestalt. PsychologischeForschung 4, 301-350.Wundt, W. (1901). Sprachgeschichte und Sprachpsychologie. Engelmann, Leipzig.308fiJournal Artificial Intelligence Research 17 (2002) 57-81Submitted 12/01; published 8/02Logic Reasoning Upper ProbabilitiesJoseph Y. HalpernRiccardo Pucellahalpern@cs.cornell.eduriccardo@cs.cornell.eduDepartment Computer ScienceCornell UniversityIthaca, NY 14853http://www.cs.cornell.edu/home/halpernAbstractpresent propositional logic reason uncertainty events,uncertainty modeled set probability measures assigning interval probabilityevent. give sound complete axiomatization logic, showsatisfiability problem NP-complete, harder satisfiability propositionallogic.1. IntroductionVarious measures exist attempt quantify uncertainty. many trained useprobability theory, probability measures obvious choice. However, probabilitycannot easiliy capture certain situations interest. Consider simple example: supposebag 100 marbles; know 30 red know remaining 70either blue yellow, although know exact proportion blue yellow.modeling situation pick ball bag random, needassign probability three different events: picking red ball (red-event), pickingblue ball (blue-event), picking yellow ball (yellow-event). clearly assignprobability .3 red-event, clear probability assign blue-eventyellow-event.One way approach problem represent uncertainty using set probability measures, probability measure possible proportion blue yellowballs. instance, could use set probabilities P = { : [0, .7]},gives red-event probability .3, blue-event probability , yellow-event probability.7 . set probabilities P assign pair functions, upper lowerprobability measure, event X give supremum (respectively, infimum)probability X according probability measures P. measuresused deal uncertainty manner described above, lower upperprobability event defines range probability event.1 (This exampleviewed giving frequentist interpretation upper probabilities. Upper probabilitiesalso given subjective interpretation, example, considering oddssomeone would willing accept reject bet (Smith, 1961; Walley, 1991).)1. Note using sets probability measures way model situation. alternativeapproach, using inner measures, studied Fagin Halpern (1991).c2002AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiHalpern & PucellaGiven measure uncertainty, one define logic reasoning it. Fagin,Halpern Megiddo (1990) (FHM on) introduce logic reasoningprobabilities, possible-worlds semantics assigns probability possibleworld. provide axiomatization logic, prove sound completerespect semantics. also show satisfiability problem logic,somewhat surprisingly, NP-complete, hence harder satisfiability problempropositional logic. moreover show logic extended notionsuncertainty, inner measures (Fagin & Halpern, 1991) Dempster-Shafer belieffunctions (Shafer, 1976).paper, describe logic reasoning upper probability measures, alonglines FHM logic. logic allows reasoning linear inequalities involvingupper probabilities measures. Like logics considered FHM, logic agnosticinterpretation upper probabilities, whether frequentist subjectivist.main challenge derive provably complete axiomatization logic; this,need characterization upper probability measures terms propertiesexpressed logic. Many semantic characterizations upper probability measuresproposed literature. characterization Anger Lembcke (1985) turnsbest suited purposes. Even though reasoning potentiallyinfinite sets probability measures, satisfiability problem logic remains NPcomplete. Intuitively, need guess small number probability measures satisfygiven formula, polynomially many size formula. Moreover, probabilitymeasures taken defined finite state space, polynomial sizeformula. Thus, need basically determine polynomially many valuesa valueprobability measure stateto decide satisfiability formula.rest paper structured follows. Section 2, review requiredmaterial probability theory theory upper probabilities. Section 3,present logic axiomatization. Section 4, prove axiomatizationsound complete respect natural semantic models expressed terms upperprobability spaces. Finally, Section 5, prove decision problem logicNP-complete. proofs new, technical results given Appendix A.make paper self-contained, also review Anger Lembckes results Appendix B.2. Characterizing Upper Probability Measuresstart brief review relevant definitions. Recall probability measurefunction : [0, 1] algebra subsets (that closedcomplements unions), satisfying () = 0, () = 1, (A B) = (A) + (B)disjoint sets A, B .2 probability space tuple (, , ), set,algebra subsets (the measurable sets), probability measure defined. Given set P probability measures, let P upper probability measure defined2. infinite, could also require -algebra (i.e., closed countable unions)countably additive. Requiring countable additivity would affect results, since showtake finite. ease exposition, required it.58fiA Logic Reasoning Upper ProbabilitiesP (X) = sup{(X) : P} X .3 Similarly, P (X) = inf{(X) : P}lower probability X . straightforward derivation shows relationshipP (X) = 1P (X) holds upper lower probabilities, X complementX . duality, restrict discussion upper probability measurespaper, understanding results lower probabilities similarlyderived. Finally, upper probability space tuple (, , P) P set probabilitymeasures .would like set properties completely characterizes upper probability measures. words, would like set properties allow us determinefunction f : R (for algebra subsets ) upper probability measure,is, whether exists set P probability measures X ,P (X) = f (X).4One approach characterization upper probability measures adaptcharacterization Dempster-Shafer belief functions; functions knownlower envelope probability measures dominate them, thus form subclassclass lower probability measures. duality noted earlier, characterizationlower probability measures would yield characterization upper probability measures.characterization belief functions derived generalization followinginclusion-exclusion principle probabilities (obtained replacing equalityinequality):(n[nX(1)i1 (Ai ) =i=1i=1X(J{1,... ,n}|J|=i\Aj )).jJseems reasonable characterization lower (or upper) probability measurescould derived along similar lines. However, well known, properties derivableinclusion-exclusion principle (which include properties reportedliterature) insufficient characterize upper probability measures. Huber (1981, p. 257)Walley (1991, p. 85) give examples showing insufficiencies properties.give sense insufficiency simple properties, consider following inclusionexclusionstyle properties, taken (Walley, 1991). simplifystatement properties, let P 1 = P P +1 = P .P P(1) P (A1 ) ni=1 |I|=i (1)i+1 P (1) ( jI Aj ),(2) P (A1 )Pn Pi=1|I|=i (1)i+1 P (1)i+1 (jIAj ),(3) P (A B) + P (A B) P (A) + P (B) P (A B) + P (A B),3. literature, term upper probability sometimes used restricted sense here.example, Dempster (1967) uses term denote class measures later characterizedDempster-Shafer belief functions (Shafer, 1976); belief functions fact upper probability measuressense, converse true (Kyburg, 1987). measure theory literature, callupper probability measures special case upper envelopes measures, definedsup sets general measures, probability measures.4. possible define notion upper probability arbitrary set subsets , necessearilyalgebra, simply requiring f coincides P domain, set P probabilitymeasures. See Walley (1991) details.59fiHalpern & Pucella(4) P (A) + P (B) P (A B) + P (A B) P (A) + P (B),(5) P (A) + P (B) P (A B) + P (A B) P (A) + P (B).Note without alternation upper probabilities lower probabilities,(1) (2) would standard notions subadditivity superadditivity, respectively. subadditivity superadditivity hold upper lower probabilities,respectively, (1) (2) stronger properties. easily verified five propertieshold upper probability measures. question whether completely characterizeclass upper probability measures. show inherent incompletenessproperties proving derivable following simple property,insufficient characterize upper probability measures:(6) B = , P (A) + P (B) P (A B) P (A) + P (B).Proposition 2.1: Property (6) implies properties (1)-(5).Observe property (6) already given Walley (1991, p. 84), properties (d)(e). following example shows insufficiency Property (6). Let P setprobability measures {1 , 2 , 3 , 4 } = {a, b, c, d} (with containing subsets) defined singletons1 (b) =141 (c) =141 (d) =142 (a) = 0 2 (b) =182 (c) =382 (d) =12383 (c) = 03 (d) =121 (a) =143 (a) =183 (b) =4 (a) =384 (b) = 0 4 (c) =184 (d) = 12 ,extended additivity . defines upper probability measure P. Consider function : [0, 1] definedP (X) + X = {a, b, c}(X) =P (X)otherwise.claim function , small enough > 0, satisfies property (6), cannotupper probability measure.Proposition 2.2: 0 < < 18 , function satisfies property (6),upper probability measure. is, cannot find set P 0 probability measures= (P 0 ) .example clearly illustrates need go beyond inclusion-exclusion principlefind properties characterize upper probability measures. turns out, variouscomplete characterizations described literature (Lorentz, 1952; Huber,1976, 1981; Williams, 1976; Wolf, 1977; Giles, 1982; Anger & Lembcke, 1985; Walley, 1991).characterizations obtained considering upper lower expectations,rather working directly upper lower probabilities. Anger Lembcke (1985)60fiA Logic Reasoning Upper Probabilitiesgive characterization terms upper lower probabilities. Since characterizationparticularly well-suited logic presented next section, review here.characterization based notion set cover. set said coveredn times multiset {{A1 , . . . , }} sets every element appears leastn sets A1 , . . . , : x A, exists distinct i1 , . . . , {1, . . . , m}j n, x Aij . important note {{A1 , . . . , }} multiset, set; Ai necessarily distinct. (We use {{ }} notation denotemultisets.) (n, k)-cover (A, ) multiset {{A1 , . . . , }} covers k timescovers n + k times. example, {{1, 2}, {2, 3}, {1, 3}} covers {1, 2, 3} 2 times,{{{1, 2}, {2, 3}, {1, 3}, {2}, {2}}} (2,2) cover ({2}, {1, 2, 3}).notion (n, k)-cover key concept Anger Lembckes characterizationupper probability measures.Theorem 2.3: (Anger & Lembcke, 1985) Suppose set, algebra subsets, : R. exists set P probability measures = Psatisfies following three properties:UP1. () = 0,UP2. () = 1,UP3. natural numbers m, n, k subsets A1P, . . . , , {{A1 , . . . , }}(n, k)-cover (A, ), k + n(A)i=1 (Ai ).Proof: reproduce proof result Appendix B.Note UP1 redundant presence UP2 UP3. Indeed, {{, }}(0, 1)-cover (, ), applying UP3 yields () + () = 1. Since UP2 states() = 1, means () = 0. consequence UP3 B,(A) (B), since {{B}} (1, 0)-cover (A, ). Therefore, , (A) [0, 1].need strengthen Theorem 2.3 order prove main result paper,namely, completeness axiomatization logic introduce next section.show cardinality state space finite, need finitelymany instances property UP3. Notice cannot derive Theorem 2.3alone: even || finite, UP3 provide bound m, number setsconsider (n, k) cover set A. Indeed, seem priori reasonvalue m, n, k bounded. Bounding value (and hence nk, since larger m) one key technical results paper,necessary foundation work.Theorem 2.4: exist constants B0 , B1 , . . . finite set,algebra subsets , : R, exists set P probability measures= P satisfies following properties:UPF1. () = 0,UPF2. () = 1,UPF3. integers m, n, k B|| sets A1 , P. . . , , {{A1 , . . . , }}(n, k)-cover (A, ), k + n(A)i=1 (Ai ).61fiHalpern & PucellaProperty UPF3 significantly weaker UP3. principle, checking UP3holds given function requires checking holds arbitrarily large collectionssets, even underlying set finite. hand, UPF3 guaranteesfinite, fact sufficient look collections size B|| . observationkey completeness result.Theorem 2.4 prescribe values constants B0 , B1 , . . . . Indeed,proof found Appendix relies Ramsey-theoretic argument evenprovide bound Bi s. could certainly attempt obtain bounds,obtaining completely unnecessary purposes. get completenessaxiomatization logic introduced next section, sufficient existfinite constants B0 , B1 , . . . .3. Logicsyntax logic straightforward, taken FHM. fix set 0 ={p1 , p2 , . . . } primitive propositions. set propositional formulas closure0 . assume special propositional formula true, abbreviatetrue false. use p represent primitive propositions, representpropositional formulas. term expression form 1 l(1 ) + + k l(k ),1 , . . . , k reals k 1. basic likelihood formula statement form ,term real. likelihood formula Boolean combination basiclikelihood formulas. use f g represent likelihood formulas. use obviousabbreviations needed, l() l() l() + (1)l() a, l() l()l() l() 0, l() l() a, l() < (l() a) l() =(l() a) (l() a). Define length |f | likelihood formula f numbersymbols required write f , coefficient counted one symbol. Let LQUlanguage consisting likelihood formulas. (The QU stands quantitative uncertainty.name logic taken (Halpern, 2002).)FHM, operator l interpreted either probability belief (in senseDempster-Shafer). first interpretation, formula l() + l() 2/3would intereted probability plus probability least 2/3.interpret l upper probaiblity. Thus, logic allows us make statementsinequalities involving upper probabilities.capture interpretation, assign semantics formulas LQU using upperprobability space, defined Section 2. Formally, upper probability structuretuple = (, , P, ) (, , P) upper probability space associatesstate (or world) truth assignment primitive propositions 0 . Thus,(s)(p) {true, false} p 0 . Let [[p]]M = {s : (s)(p) = true}.call measurable p 0 , [[p]]M measurable. measurable[[]]M measurable propositional formulas . paper, restrict attentionmeasurable upper probability structures. Extend (s) truth assignmentpropositional formulas standard way, associate propositional formulaset [[]]M = {s : (s)() = true}. easy structural induction shows [[]]M62fiA Logic Reasoning Upper Probabilitiesmeasurable set. = (, , P, ), let|= 1 l(1 ) + + k l(k ) iff 1 P ([[1 ]]M ) + + k P ([[k ]]M )|= f iff 6|= f|= f g iff |= f |= g.Note LQU express lower probabilities: follows duality upperlower probabilities |= l() 1 iff P ([[]]M ) .5Consider following axiomatization AXup upper probability, prove soundcomplete next section. key axioms simply translation LQUcharacterization upper probability given Theorem 2.3. FHM, AXup dividedthree parts, dealing respectively propositional reasoning, reasoning linearinequalities, reasoning upper probabilities.Propositional reasoningTaut. instances propositional tautologies LQU (see below).MP. f f = g infer g.Reasoning linear inequalitiesIneq. instances valid formulas linear inequalities (see below).Reasoning upper probabilitiesL1. l(false) = 0.L2. l(true) = 1.L3. l() 0.WVL4. l(1 ) + + l(m ) nl() k J{1,... ,m}, |J|=k+n jJ jWV6J{1,... ,m}, |J|=k jJ j propositional tautologies.L5. l() = l() propositional tautology.difference AXup axiomatization reasoning probabilitygiven FHM axiom l( ) + l( ) = l() FHM, expressesadditivity probability, replaced L4. Although may immediatelyobvious, L4 logical analogue SUP3. see this,first note {{A1 , . . . , }}coverstimesJ{1,... ,m}, |J|=n jJ Aj . Thus, formulaWVsays(moreJ{1,... ,m}, |J|=k+n jJ jWprecisely, setVof worlds true)covered k +n times {{1 , . . . , n }}, J{1,... ,m}, |J|=k jJ j says wholespace covered k times {{1 , . . . , n }}; roughly speaking, multiset {{1 , . . . , n }}(n, k)-cover (, true). conclusion L4 thus corresponds conclusion5. Another approach, keeping FHM, would interpret l lower probability measure.hand, interpreting l upper probability measure keeping literatureupper probabilities.6. Note that, according syntax LQU , 1 , . . . , must propositional formulas.63fiHalpern & PucellaUP3. Note way UP1 follows UP2 UP3, axiom L1 (aswell L3) follows L2 L4.Instances Taut include formulas form f f , f arbitraryformula LQU . could replace Taut simple collection axioms characterizepropositional reasoning (see, example, (Mendelson, 1964)), chosen focusaspects reasoning upper probability.FHM, axiom Ineq includes valid formulas linear inequalities.inequality formula formula form a1 x1 + + xn c, variables x1 , . . . , xn .inequality formula said valid true every possible assignment realnumbers variables. get instance Ineq, replace variable xi occursvalid inequality formula primitive likelihood term form l(i ) (naturallyoccurence variable xi must replaced primitive likelihood term l(i )).Taut, replace Ineq sound complete axiomatization Booleancombinations linear inequalities. One axiomatization given FHM.4. Soundness Completenessformula f provable axiom system AX f proven using axiomsrules inferences AX. AX sound respect class structures everyformula provable AX valid (i.e., valid every structure M); AX completerespect every formula valid provable AX.goal prove AXup sound complete axiomatization reasoningupper probability (i.e., respect upper probability structures). soundnessAXup immediate earlier disscussion. Completeness is, usual, harder. Unfortunately, standard technique proving completeness modal logic, involvesconsidering maximal consistent sets canonical structures (see, example, (Popkorn,1994)) work. briefly review approach, point difficulties.standard approach uses following definitions. formula consistentaxiom system AX provable AX. finite set formulas {1 , . . . , n }consistent AX formula 1 n consistent AX; infinite setformulas consistent AX finite subsets consistent AX. Fmaximal AX-consistent set F consistent AX strict superset Fconsistent AX. AX includes Taut MP, hard show, usingpropositional reasoning, every AX-consistent set formulas extendedmaximal AX-consistent set.show AX complete respect class structures, must showevery formula valid provable AX. this, sufficient showevery AX-consistent formula satisfiable structure M. Typically,done constructing called canonical structure c whose statesmaximal AX-consistent sets, showing formula satisfied world wc iff one formulas canonical set associated world w.Unfortunately, approach cannot used prove completeness here. see this,consider set formulasF 0 = {l()1, n = 1, 2, . . . } {l() > 0}.n64fiA Logic Reasoning Upper Probabilitiesset clearly AXup consistent according definition, since every finite subsetsatisfiable upper probability structure AXup sound respect upperprobability structures. thus extended maximal AXup consistent set F .However, set F 0 formulas satisfiable: possible assign l() valuesatisfy formulas time. Hence, F satisfiable. Thus,canonical model approach, least applied naively, simply work.take different approach here, similar one taken FHM. tryconstruct single canonical model. course, still must show formula fAXup -consistent satisfiable upper probability structure.explicit construction, depending f . proceed follows.simple argument, easily reduce problem case fconjunction basic likelihood formulas negations basic likelihood formulas. LetNp1 , . . . , pN primitive propositions appear f . Observe 22inequivalent propositional formulas p1 , . . . , pN . argument goes follows. Letatom p1 , . . . , pN formula form q1 . . . qN , qi either pi pi .clearly 2N atoms p1 , . . . , pN . Moreover, easy see formulaNp1 , . . . , pN written unique way disjunction atoms. 22disjunctions, claim follows.Continuing construction structure satisfying f , let 1 , . . . , 22Ncanonical listing inequivalent formulas p1 , . . . , pN . Without loss generality, assume 1 equivalent true, 22N equivalent false. Since every propositional formula p1 , . . . , pN provably equivalent , followsf provably equivalent formula f 0 conjunct f 0 form1 l(1 ) + + 22N l(22N ) . Note negation formula form1 l(1 ) + + 22N l(22N ) < or, equivalently, (1 )l(1 ) + + (22N )l(22N ) > .Thus, formula f gives rise natural way system inequalities form:1,1 l(1 ) + + 1,22N l(22N )...r,1 l(1 ) + + r,22N l(22N )0 l( ) + + 01,11N l(22N )1,22...0s,1 l(1 ) + + 0 2N l(22N )s,21......r> 1......> .(1)express (1) conjunction inequality formulas, replacing occurrencel(i ) (1) xi . Call inequality formula f .f satisfiable upper probability structure , take xiupper probability ; gives solution f . However, f may solutionwithout f satisfiable. example, f formula l(p) = 1/2 l(p) = 0,f obvious solution; f , however, satisfiable upper probability structure,upper probability set corresponding p upper probabilityset corresponding p must sum least 1 upper probability structures. Thus,must add constraints solution force act like upper probability.UP1UP3 or, equivalently, axioms L1L4, describe exactly additional constraints needed. constraint corresponding L1 (or UP1) x1 = 0, since65fiHalpern & Pucellaassumed 1 formula false. Similarly, constraint corresponding L2Nx22N = 1. constraint corresponding L3 xi 0, = 1, . . . , 22 .L4? seems require infinite collection constraints, UP3 does.7UPF3 comes play. turns that, f satisfiable all,satisfiable structure 2N worlds, one atom p1 , . . . , pN .Thus, need add instances L4 k, m, n < B2N 1 , . . . , ,among 1 , . . . , 22N . Although large number formulas (in fact, knowexactly large, since depends B2N , computed), sufficespurposes finite number. instances L4, inequalityform a1 x1 + + a22N x22N k. Let f, inequality formula corresponding f ,conjunction consisting f , together inequalities correspondingrelevant instances L4, equations inequalities x1 = 0, x22N = 1, xi 0N= 1, . . . , 22 , corresponding axioms L1L3.Proposition 4.1: formula f satisfiable upper probability structure iffinequality formula f solution. Moreover, f solution, f satisfiableupper probability structure 2|f | worlds.Theorem 4.2: axiom system AXup sound complete upper probability structures.Proof: soundness, easy see every axiom valid upper probabilitystructures, including L4, represents UP3.completeness, proceed discussion above. Assume formula fsatisfiable upper probability structure; must show f AXup inconsistent.first reduce f canonical form. Let g1 gr disjunctive normal formexpression f (where gi conjunction basic likelihood formulasnegations). Using propositional reasoning, show f provably equivalentdisjunction. Since f unsatisfiable, gi must also unsatisfiable. Thus, sufficientshow unsatisfiable conjunction basic likelihood formulas negationsinconsistent. Assume f conjunction. Using propositional reasoning axiomNL5, f equivalent likelihood formula f 0 refers 22 propositional formulas, say1 , . . . , 22N . Since f unsatisfiable, f 0 . Proposition 4.1, inequality formulaf0 corresponding f 0 solution. Thus, Ineq, formula f 00 resultsreplacing instance xi f0 l(i ) AXup provable. conjuncts f 00instances axioms L1L4 AXup provable. follows f 0 AXup provable,hence f .5. Decision Proceduresettled issue soundness completeness axiom system AXup ,turn problem complexity deciding satisfiability. Recall problem7. Although dealing finitely many formulas here, 1 , . . . , 22N , recall formulas1 , . . . , L4 need distinct, potentially infinitely many instances L4 dealwith.66fiA Logic Reasoning Upper Probabilitiessatisfiability: given likelihood formula f , want determine exists upperprobability structure |= f . show, satisfiability problemNP-complete, thus harder satisfiability propositional logic.decision problem make sense, need restrict language slightly.allow real numbers coefficients likelihood formulas, carefully discussissue representation numbers. avoid complications, restrictlanguage (in section) allow integer coefficients. Note still expressrational coefficients standard trick clearing denominator. example,express 32 l() 1 2l() 3 l() 23 3l() 2. Recall defined|f | length f , is, number symbols required write f ,coefficient counted one symbol. Define ||f || length longest coefficientappearing f , written binary. size rational number ab , denoted || ab ||,b relatively prime, defined ||a|| + ||b||.preliminary result required analysis decision procedure showsformula satisfied upper probability structure, satisfied structure(, , P, ), small terms number states , cardinalityset P probability measures, size coefficients f .Theorem 5.1: Suppose f likelihood formula satisfied upper probabilitystructure. f satisfied structure (, , P, ), || |f |2 , = 2 (everysubset measurable), |P| |f |, (w) rational number ||(w)||O(|f |2 ||f || + |f |2 log(|f |)) every world w P, (w)(p) = false everyworld w every primitive proposition p appearing f .Theorem 5.2: problem deciding whether likelihood formula satisfiableupper probability structure NP-complete.Proof: lower bound, clear given propositional formula satisfiable ifflikelihood formula l() > 0 satisfiable, therefore satisfiability problem NP-hard.upper bound, given likelihood formula f , guess small satisfying structure= (, , P, ) f form guaranteed exist Theorem 5.1. describemodel size polynomial |f | ||f ||. (The fact (w)(p) = falseevery world w every primitive proposition p appearing f meansmust describe propositions appear f .) verify |= f follows.Let l() arbitrary likelihood term f . compute [[]]M checking truthassignment seeing whetherP truth assignment makes true.replace occurence l() f maxP { s[[]]M (s)} verify resultingexpression true.6. Conclusionconsidered logic syntax logic reasoning probability, inner measures, belief presented FHM, uncertainty interpreted upperprobability set probability measures. interpretation, providedsound complete axiomatization logic. showed satisfiability problem NP-complete (as reasoning probability, inner measures,67fiHalpern & Pucellabeliefs), despite deal probability structures possibility infinitely manystates infinite sets probability measures. key step axiomatization involvesfinding characterization upper probability measures captured logic.key step complexity result involves showing formula satisfiable all,satisfiable small structure, size state space, well sizeset probability measures size probabilities involved, polynomiallength formula.Given similarity spirit results various interpretations uncertainty operator (as probability, inner measure, belief function, upper probability),including fact complexity decision problem NP-complete cases,conjecture underlying result results follow.would interesting make precise.FHM, conditional probabilities well probabilities investigated. not,paper, discussed conditional upper probabilities. main reason that,unlike probability, cannot characterize conditional upper probabilities terms (unconditional) upper probabilities. Thus, results really tell us nothing conditionalupper probabilities. might interest consider logic allows conditional upper probabilities primitive likelihood terms (that is, allows likelihood terms forml( | )). intrinsic difficult giving semantics language, farclear appropriate axiomatization would be, effect extensioncomplexity.Finally, worth noting semantic framework developed FHMfact rich enough talk gambles (that is, real-valued functions setstates) expectation gambles. Expectation functions defineddifferent measures uncertainty, including upper probabilities, difficultextend FHM logic order reason expectation. One advantage workingexpectation functions typically easier characterize correspondingmeasures; instance, characterization expected upper probabilities much simplerupper probabilities (Huber, 1981; Walley, 1981, 1991). However, gettingcomplete axiomatization quite nontrivial. refer reader (Halpern & Pucella,2002) details subject. remark Wilson Moral (1994) takestarting point Walleys notion lower upper previsions. consideracceptance one set gambles implies acceptance another gamble. Since acceptanceinvolves expectation, cannot expressed logic considered paper; however,expressed easiliy logic (Halpern & Pucella, 2002).Acknowledgmentspreliminary version paper appears Uncertainty Artificial Intelligence, Proceedings Seventeenth Conference, 2001. Thanks Dexter Kozen, Jon Kleinberg,Hubie Chen discussions concerning set covers. Vicky Weissman read draft paperprovided numerous helpful comments. also thank anonymous UAI JAIRreviewers useful comments suggestions. work supported partNSF grants IRI-96-25901 IIS-0090145, ONR grants N00014-00-1-03-68fiA Logic Reasoning Upper Probabilities41, N00014-01-10-511, N00014-01-1-0795. first author also supported partGuggenheim Fulbright Fellowship sabbatical leave; sabbatical supportCWI Hebrew University Jerusalem also gratefully acknowledged.Appendix A. ProofsProposition 2.1: Property (6) implies properties (1)-(5).Proof: introduce following auxiliary properties help derive implications:(7) P (A) + P (B) P (A B) + P (A B).(8) P (A) + P (B) P (A B) + P (A B).(9) P (A B) + P (A B) P (A) + P (B).(10) B = ,P (A) + P (B) P (A B) P (A) + P (B) P (A B) P (A) + P (B).Using properties, show following chain implications:(6) = (10)(10) = (9) = (3)(10) = (7) = (4)(10) = (8) = (5)(4), (5) = (1), (2).implication (4), (5) = (1), (2) follows easily mutual induction n.base case following instances properties (4) (5): P (A B) P (A) + P (B)P (A B) P (A B) P (A) + P (B) P (A B). details left reader.prove remaining implications.(9) = (3): Since (9) already one inequalities (3), remains showimplies inequality (3), is, P (A)+P (B) P (AB)+P (AB).P (A B) + P (A B) = 1 P (A B) + 1 P (A B)= 1 P (A B) + 1 P (A B)= 2 (P (A B) + P (A B))= 2 (P (B A) + P (B A))2 (P (B) + P (A))= 1 P (B) + 1 P (A)= P (B) + P (A).69fiHalpern & Pucella(7) = (4): Since (7) already one inequalities (4), remains showimplies inequality (4), is, P (AB)+P (AB) P (A)+P (B).P (A) + P (B) = 1 P (A) + 1 P (B)= 2 (P (A) + P (B))2 (P (A B) + P (A B))= 1 P (A B) + 1 P (A B)= 1 P (A B) + 1 P (A B)= P (A B) + P (A B).(8) = (5): Since (8) already one inequalities (5), remains showimplies inequality (5), is, P (AB)+P (AB) P (A)+P (B).P (A) + P (B) = 1 P (A) + 1 P (B)= 2 (P (A) + P (B))2 (P (A B) + P (A B))= 1 P (A B) + 1 P (A B)= 1 P (A B) + 1 P (A B)= P (A B) + P (A B).next implications, given A, B, let Z = B.(10) = (9):P (A B) = P ((A Z) B)P (A Z) + P (B)[since (A Z) B = ]P ((A Z) Z) P (Z) + P (B)= P (A) + P (B) P (A B).(10) = (7):P (A B) = P ((A Z) B)P (A Z) + P (B)P ((A Z) Z) P (Z) + P (B)= P (A) + P (B) P (A B).(10) = (8):P (A B) = P ((A Z) B)P (A Z) + P (B)P ((A Z) Z) P (Z) + P (B)= P (A) + P (B) P (A B).70fiA Logic Reasoning Upper Probabilities(6) = (10): Again, since (6) already comprises two inequalities (10),remains show implies two, is, B = ,P (A) + P (B) P (A B) P (A) + P (B).First, show P (A) + P (B) P (A B). Using (6), knowP (A B) + P (A) P ((A B) A) = P (B).words, P (A B) P (B) + P (A). this, deriveP (A B) = 1 P (A B)= 1 P (A B)1 (P (B) P (A))= 1 P (B) + P (A)= P (B) + P (A).Second, show P (A B) P (A) + P (B). Using (6), knowP (A B) + P (A) P ((A B) A) = P (B).(The last equality follows fact (A B) = B B = .)words, P (A B) P (B) P (A). this, deriveP (A B) = 1 P (A B)= 1 P (A B)1 (P (B) P (A))= 1 P (B) + P (A)= P (B) + P (A).Proposition 2.2: 0 < < 18 , function satisfies property (6),upper probability measure. is, cannot find set P 0 probability measures= (P 0 ) .Proof: given 0 < < 81 . easy check mechanically satisfies (6).show set P 0 = (P 0 ) . way contradiction,assume P 0 . properties sup, means P 0({a, b, c}) > 43 , since ({a, b, c}) = 34 + > 34 . Consider detail. Since P,must X , X 6= {a, b, c}, (X) (P 0 ) (X) = P (X). particular,({a, b}), ({b, c}), ({a, c}) 21 . Therefore,3({a, b}) + ({b, c}) + ({a, c}) .2(2)However, standard properties probability, follows({a, b}) + ({b, c}) + ({a, c}) = 2({a, b, c}) > 27133= ,42fiHalpern & Pucellacontradicts (2). Therefore, , therefore P 0 cannot exist, upperprobability measure.Theorem 2.4: exists constants B0 , B1 , . . . algebra subsetsfunction : R, exists set P probability measures= P satisfies following properties:UPF1. () = 0,UPF2. () = 1,UPF3. integers m, n, k B|| sets A1 , P. . . , , {{A1 , . . . , }}(n, k)-cover (A, ), k + n(A)i=1 (Ai ).Proof: view Theorem 2.3, need show exist constant B0 , B1 , . . .function satisfies UP3 iff satisfies UPF3. Clearly, UP3 always impliesUPF3, sufficient show exists B0 , B1 , . . . UPF3 impliesUP3.need terminology proceeding. exact (n, k)-cover (A, ) coverC property every element appears exactly n + k sets C,every element appears exactly k sets C. Thus, (n, k)-cover (A, )many extra sets, long sets cover least n + k times k times,exact cover necessary sets, right total number elements.exact (n, k)-cover C (A, ) decomposable exists exact (n1 , k1 )-cover C1exact (n2 , k2 )-cover C2 (A, ) C1 C2 form nontrivial partition C,n = n1 + n2 k = k1 + k2 . Intuitively, exact cover C decomposablesplit two exact covers. follows easily induction exact (n, k)cover, exists (not necessarily unique) finite set nondecomposable exact coversC1 , . . . , CmPm(ni , ki )-cover, Ci nontrivial partition CP, mwith Ci exactn = i=1 ni k = i=1 . (If C nondecomposable, take = 1C1 = C.) One easily verify C exact (n, k)-cover (A, ) C 0 Cexact (n0 , k 0 )-cover (A, ) n0 + k 0 < n + k, C decomposable.following lemma highlights important property exact coversperspective. says set , cannot large nondecomposableexact cover (A, ).Lemma A.1: exists sequence B10 , B20 , B30 , . . . , every exact00(n, k)-cover (A, ) n > B||k > B||decomposable.Proof: clearly sufficient show finite find B||required properties. Fix . Given , first show exists NAn > NA k > NA , every exact (n, k)-cover (A, ) decomposable. Supposesake contradiction case. means find infinitesequence C1 , C2 , . . . Ci nondecomposable exact (ni , ki )-cover (A, ),either n1 < n2 < . . . k1 < k2 < . . . .derive contradiction, use following lemma, known Dicksons Lemma(Dickson, 1913).72fiA Logic Reasoning Upper ProbabilitiesLemma A.2: Every infinite sequence d-dimensional vectors naturalnumbers contains monotonically nondecreasing subsequence pointwiseordering (where x pointwise ordering iff xi yi i).Proof: straightforward prove induction k k d,every infinite sequence vectors x1 , x2 , . . . contains subsequence xi1 , xi2 , . . .xij1 , xij2 , . . . nondecreasing sequence natural numbersj k. base case immediate observation every infinitesequence natural numbers contains nondecreasing subsequence.inductive step, observe xi1 , xi2 , . . . subsequence xij1 , xij2 , . . .nondecreasing sequence natural numbers j k, sequence12xik+1, xik+1, . . . natural numbers must nondecreasing subsequence.determines subsequence original sequence appropriate propertyj k + 1.Let S1 , . . . , S2|| arbitrary ordering 2|| subsets . associateCCcover C 2|| -dimensional vector xC = (xC1 , . . . , x2|| ), xi numbertimes subset Si appears multiset C. key property association0C 0 C multisets, C 0 C iff xC xC pointwise ordering.Consider sequence vectors xC1 , xC2 , . . . associated sequence C1 , C2 , . . .nondecomposable exact covers (A, ). Lemma A.2, nondecreasing subsequence vectors, xCi1 xCi2 . means Ci1 Ci2 . Sincen1 < n2 < . . . k1 < k2 < . . . , every cover chain must distinct. pairexact covers chain Ci Ci+1 , meaning Ci+1 decomposable, contradicting assumption. Therefore, must exist NA exact (n, k)-covern > NA k > NA decomposable.0= max{NA : {1, . . . , ||}}. easy see choicedefine B||works.0 , N = 1, 2, . . . , B 0get constants B1 , B2 , . . . , let BN = 2N BNNLemma A.1. show UPF3 implies UP3 choice B1 , B2 , . . . .Assume UPF3 holds. Fix . Suppose C = {{A1 , .P. . , }} (n, k)-cover(A, ) |C| = m. want show k + n(A)i=1 (Ai ). proceedfollows.first step show that, without loss generality, C exact (n, k)-cover(A, ). Let Bi consist states Ai either appearsn + k sets A1 , . . . , Ai1 appears k setsA1 , . . . , Ai1 . Let A0i = Ai Bi . Let C 0 = {{A01 , . . . , A0m }}. easy check C 0exact (n, k)-cover (A, ). A, appears exactly n + k sets C 0 (itappears A0j iff Aj among first n + k sets C appeared) and, similarly,A, appears exactly k sets C 0 . Clearly UP3 holds C 0 ,holds C, since (A0i ) (Ai ) = 1, . . . , m. Thus, assume without lossgenerality C exact (n, k)-cover A.also assume without loss generality set C empty (otherwise,simply remove empty sets C; resulting set still (n, k)-cover(A, )). two cases consider. max(m, n, k) B|| , desired result73fiHalpern & Pucellafollows UPF3. not, consider decomposition C multisets C1 , . . . , Cp ,Ch exact (nh , kh )-cover (A, ) decomposable. claimmax(|Ch |, nh , kh ) B|| h = 1, . . . , p. nh > B|| kh > B|| ,immediate Lemma A.1 Ch decomposed, contradictingfactPCh decomposable. |Ch | > B|| , observe XCh |X| |Ch |.0 , must appears least 2B 0Since |Ch | > B|| = 2||B||||0 k > B 0 .sets Ch . Since Ch exact (nh , kh )-cover, follows either nh > B||h||then, Lemma A.1, Ch decomposable, contradiction.apply UPF3 C1 , . . . , Ck getX(X) nh (A) kh .XChSince Ch form decomposition C,ppXXXkh(X) nh (X)XChh=1pXh=1XppXX(Ai ) (nh )(A)khi=1Pph=1XXCh(X)pXh=1decomposition, n = h=1 nh k =showing UP3 holds, desired.nh (A)h=1pXkhh=1h=1Pph=1 kh ,thereforePmi=1 (Ai ) n(A)k,Proposition 4.1: formula f satisfiable upper probability structure iffinequality formula f solution. Moreover, f solution, f satisfiableupper probability structure 2|f | worlds.Proof: Assume first f satisfiable. Thus upper probability structure= (, , P, ) |= f . Section 4, let p1 , . . . , pN primitive propositions appear f , let 1 , . . . , 22N canonical listing inequivalentformulas p1 , . . . , pN . Without loss generality, assume 1 equivalenttrue, 22N equivalent false. Define vector x letting xi = P ([[i ]]M ),N1 22 . Since |= f , immediate x solution inequality2Nformula f . Moreover, since 1 = false 2= true, follows x1 = 0 (sinceP ([[false]]M ) = P () = 0) x2N = 1 (since P ([[true]]M ) = P () = 1). Final2ly, consider conjunct f corresponding instance L4; suppose formxi1 + xWSince conjunct appearsf, must caseim nxim+1 k. VWV(im+1 J{1,... ,m}, |J|=k+n J{1,... ,m}, jJ ij ) ( |J|=k jJ ij ) propositional tautology. Thus, follows [[i1 ]]M , . . . , [[im ]]M (n, k)-cover ([[im+1 ]]M , [[true]]M ).follows UP3P ([[i1 ]]M ) + + P ([[im ]]M ) nP ([[]]M ) k.74fiA Logic Reasoning Upper ProbabilitiesThus, x solution inequality formulas corresponding L4. Hence, x solutionf.converse, assume x solution f. construct upper probabilitystructure = (S, E, P, ) |= f follows. Let p1 , . . . , pN primitivepropositions appearing f . Let = {1 , . . . , 2N } atoms p1 , . . . , pN . Let Eset subsets S. observed earlier, every propositional formula p1 , . . . , pnequivalent unique disjunction atoms. Thus, get canonical collection1 , . . . , 22N inequivalent formulas p1 , . . . , pn identifying formuladifferent element E, 1 corresponds empty set 22N correspondsS. Define set function taking ({i1 , . . . , ij }) = xi disjunctionatoms i1 , . . . , ij . Let ()() = true iff .sufficient show upper probability (of set P probabilitymeasures), since clear (S, E, P, ) |= f (since x solution f, systeminequalities derived formula f ). this, Theorem 2.4, suffices verifyUPF1, UPF2, UPF3, using B2N UPF3, since |S| = 2N .UPF1: () = x1 = 0.UPF2: (S) = x2N = 1.2UPF3: Suppose A1 , . . . , E satisfy premises property UPF3, k, m, n B2N . Let i1 , . . . , im , im+1 canonicalA1 , . . . , AmW, A, respectively. Clearly,Vformulas correspondingiffm+1jJ{1,...J{1,... ,m}, |J|=k+n jJ,m}, |J|=k+n TjJ jpropositional tautology similarly J{1,... ,m}, |J|=k jJ Aij iffWVPmJ{1,... ,m}, |J|=k jJ ij propositional tautology. Thus,j=1 xijxk one inequality formulas f . Thus, followsPim+1k, desired. definition , thereforej=1 xij xiPm+1k + n(A)i=1 (Ai ), UPF3 holds.Theorem 5.1: Suppose f likelihood formula satisfied upper probabilitystructure. f satisfied structure (, , P, ), || |f |2 , = 2 (everysubset measurable), |P| |f |, (w) rational number ||(w)||O(|f |2 ||f || + |f |2 log(|f |)) every world w P, (w)(p) = false everyworld w every primitive proposition p appearing f .Proof: first step proof involves showing P set probability measuresdefined algebra finite space , assume without loss generalityset X , probability measure X P X (X) = P (X)(rather P (X) sup (X) P).Lemma A.3: Let P set probability measures defined algebra finite set. exists set P 0 probability measures that, X , P (X) =(P 0 ) (X); moreover, probability measure X P 0 X (X) = P (X).addition, interpretation , = (, , P, ) = (, , P 0 , ),likelihood formulas f , |= f iff 0 |= f .75fiHalpern & PucellaProof: Since finite, show P 0 exists, clearly suffices show that,X , probability measure X X (X) = P (X) and, P 0 = P {X },P (Y ) = (P 0 ) (Y ) .Given X, exists P (X) = P (X), done. Otherwise,construct sequence 1 , 2 , . . . probability measures P limi (X) =P (X) and, , sequence (Y ) converges limit. Let X1 , . . . , Xnenumeration sets , X1 = X. inductively construct sequencemeasures m1 , m2 , . . . P n mi (Xj ) converges limit klimi mi (X) = P (X). = 1, know must sequence 11 , 12 , . . .measures P 1i (X) converges P (X). inductive step, < n,suppose constructed appropriate sequence m1 , m2 , . . . . Consider sequencereal numbers mi (Xm+1 ). Using Bolzano-Weierstrass theorem (Rudin, 1976) (whichsays every sequence real numbers convergent subsequence), sequenceconvergent subsequence. Let (m+1)1 , (m+1)2 , . . . subsequence m1 , m2 , . . .generates convergent subsequence. sequence probability measures clearlyrequired properties. completes inductive step.Define X (Y ) = limi ni (Y ). easy check X indeed probabilitymeasure, X (X) = P (X), P 0 = P {X }, P (Y ) = (P 0 ) (Y ). shows appropriate set P 0 exists.Now, given , let = (, , P, ) 0 = (, , P 0 , ). straightforward inductionstructure f shows |= f iff 0 |= f . base case:(, , P, ) |= a1 l(1 ) + + l(n )a1 P ([[1 ]]M ) + + P ([[n ]]M )a1 (P 0 ) ([[1 ]]M 0 ) + + (P 0 ) ([[n ]]M 0 )(, , P 0 , ) |= a1 l(1 ) + + l(n ) a.others cases trivial.FHM, prove Theorem 5.1, make use following lemmaderived Cramers rule (Shores, 1999) simple estimates sizedeterminant (see also (Chvatal, 1983) simpler variant):Lemma A.4: system r linear equalities and/or inequalities integer coefficientslength l nonnegative solution, nonnegative solutionr entries positive, size member solution O(rl +r log(r)).Continuing proof Theorem 5.1, suppose f satisfiable upperprobability structure. Proposition 4.1, system f equality formulas solution,f satisfied upper probability structure finite state space. Thus, Lemma A.3, f satisfied structure = (, , P, ) X , existsX P X (X) = P (X).completeness proof, write f disjunctive normal form. disjunctg conjunction |f | 1 basic likelihood formulas negations. Since|= f , must disjunct g |= g. Suppose g conjunctionr basic likelihood formulas negations basic likelihood formulas. Let p1 , . . . , pN76fiA Logic Reasoning Upper Probabilitiesprimitive formulas appearing f . Let 1 , . . . , 2N atoms p1 , . . . , pN .proof completeness, derive system equalities inequalities g.slightly complicated system, however. Recall propositional formulap1 , . . . , pN disjunction atoms. Let 1 , . . . , k propositional formulasappear g. Notice k < |f | (since symbols f , coefficients,propositional formulas). system equations inequalitiesconstruct involve variables xij , = 1, . . . , k j = 1, . . . , 2N . Intuitively, xijrepresents [[i ]]M ([[ j ]]M ), [[i ]]M P [[i ]]M ([[i ]]M ) = P ([[i ]]M ). Thus,system includes k < |f | equations following form,xi1 + + xi2N = 1,= 1, . . . , k. Since [[i ]]M ([[i ]]M ) ([[i ]]M ) P, Ei subsetW{1, . . . , 2N } = jEi j , system includes k 2 k inequalities formXXxijxi 0 j ,jEii0jEii0 .pair i,6=conjunct g form 1 l(1 ) + +n l(k ) , corresponding inequalityPwhere, roughly speaking, replace l(i )[[i ]]M ([[]]M ).8 Since [[i ]]M corresponds jEi xij , appropriate inequalitykXi=1Xxij .jEiNegations formulas correspond negated inequality formula; before,equivalent formula form(kXi=1Xxij ) > .jEiNotice |f | inequalities corresponding conjuncts g. Thus,altogether, k(k 1) + 2|f | < |f |2 equations inequalitiessystem (since k < |f |). know system nonnegative solution (takingxij [[i ]]M ([[ j ]]M )). follows Lemma A.4 system solutionx = (x11 , . . . , x12N , . . . , xk1 , . . . , xk2N ) |f |2 entries positive, entrysize O(|f |2 ||f || + |f |2 log(|f |)).use solution construct small structure satisfying formula f . Let ={i : xij positive, j}; suppose = {i1 , . . . , it0 }, t0 t. Let= (S, E, P, ) t0 states, say s1 , . . . , st0 , E consists subsets S. Let(sh ) truth assignment corresponding formula ih , is, (sh )(p) = trueih p (and (sh )(p) = false p appear f ). DefineP = {j : 1 k}, j (sh ) = xih j . clear construction |= f .Since |P| = k < |f |, |S| = t0 |f |2 j (sh ) = xih j , where, construction, sizexih j O(|f |2 ||f || + |f |2 log(|f |)), theorem follows.8. simplicity here, implicitly assuming formulas appears conjunctg. without loss generality, since appear, put in, taking = 0.77fiHalpern & PucellaAppendix B. Proof Characterization Upper Probabilitiesmake paper self-contained, appendix give proof Theorem 2.3.proof give essentially Anger Lembcke (1985). Walley (1991) givesalternate proof along somewhat similar lines. Note functional g defineproof corresponds construction Walleys Natural Extension Theorem,needed version result.Theorem 2.3: Suppose set, algebra subsets , : R.exists set P probability measures = P satisfiesfollowing three properties:UP1. () = 0,UP2. () = 1,UP3. integers m, n, k subsets A1 , . . . ,Pm , {{A1 , . . . , }}(n, k)-cover (A, ), k + n(A)i=1 (Ai ).Proof: direction characterization straightforward. Given P = {i }iIset probability measures, show P satisfies UP1-UP3.UP1: P () = sup{i ()} = sup{0} = 0UP2: P () = sup{i ()} = sup{1} = 1UP3: GivenSA1 , . . . ,J{1,... ,m},|J|=k+n jJ AijJ{1,... ,m},|J|=k jJ Aij , ki () + ni (A)PmPPm(Aj ), kP+ ni (A)j=1 (Aj ) supi { j=1 (Aj )}Pj=1(A ). sup {k+n (A)} = k+n sup { (A)} =jj=1 supi {i (Aj )} =j=1 P P(A ), required.k + nP (A), k + nP (A)Pjj=1direction, first prove general lemma relating problemHahn-Banach Theorem. general definitions needed. Suppose givenspace W algebra F subsets W . Let K vector space generatedindicator functions 1X defined0 x 6 X1X (x) =1 x X,X F. sublinear functional K mapping c : K R c(h) = c(h)0 c(h1 + h2 ) c(h1 ) + c(h2 ) h1 , h2 . sublinear functional increasingh 0 implies c(h + h0 ) c(h0 ) h0 K. following result formulationwell-known Hahn-Banach Theorem (see, example, (Conway, 1990)).Theorem (Hahn-Banach): Let K vector space R, let g sublinearfunctional K. linear subspace K : R linear functional(x) g(x) x M, linear functional 0 : K R0 |M = 0 (x) g(x) x K.Lemma B.1: Let g : F [0, 1] g(W ) = 1 supposeincreasing sublinear functional g K78fiA Logic Reasoning Upper Probabilities1. g(1K ) = g(K) K F;2. g(h) 0 h 0;3. g(1) 1 (where g() identified g(1W )).g upper probability measure.Proof: show g upper probability exhibiting set {X : X }probability measures, property X (X) = g(X) X (Y ) g(X) 6= X.probability measure X constructed application Hahn-BanachTheorem.Given X F, define linear functional subspace generated 1X(1X ) = g(1X ). claim (h) g(h) h subspace. Since elementssubspace form 1X , two cases consider: 0 < 0.0, (1X ) = g(1X ) = g(1X ), since g sublinear. Moreover, 0 = g(0) =g(1X + 1X ) g(1X ) + g(1X ), g(1X ) g(1X ). Thus, > 0,(1X ) = g(1X ) g(1X ) = g(1X ).Now, Hahn-Banach Theorem, extend linear functional 0K 0 (h) g(h) h. claim (a) 0 (1Y ) 0 K (b)0 (1) = 1. (a), note 0 (1Y ) g(1Y ) 0 assumption, 0 (1Y ) 0.(b), note 0 (1) g(1) = g(W ) = 1 0 (1) = 0 (1) g(1) 1 (sinceg(1) 1, assumption).Define X (Y ) = 0 (1Y ). Since 0 (1W ) = 1, X (W ) = 1. 0 disjoint,immediate linearity X (Y 0 ) = X (Y ) + X (Y 0 ). construction,X (Y ) g(1Y ) = g(Y ) 6= X, X (X) = (1X ) = g(1X ) = g(X). Bottomline: probability measure X dominated g X (X) = g(X).Take P = {X : X }. Since X X (X) = g(X)X (Y ) g(X) (if 6= X), P (X) = X (X) = g(X). Therefore, g = P .main result follows showing construct, function satisfyingproperties Theorem 2.3, sublinear functional c K required properties.Suppose g : R function satisfying UP1-UP3. show discussionTheorem 2.3 text, UP1-UP3 show range g fact [0, 1].PSince gsatisfies UP3, {{K1 , . . . , Km }} (n, k)-coverPm (K, ), k +ng(K) i=1 Ki .equivalentsaying k + n1K Pi=1 1Ki . Hence, K1 , . . . , KmPk + n1K1i=1 Ki , k + ng(K)i=1 g(Ki ), equivalentlyk1X+g(Ki ) g(K).n n(3)i=1observation motivates following definition functional g : K R{, }:()k1Xk1Xg(h) = inf +g(Ki ) : m, n, k N, m, n > 0, K1 , . . . , Km F, +1Ki h .n nn ni=1i=1goal show g satisfies conditions Lemma B.1.79fiHalpern & Pucellaalmost immediate definitions g increasing: h 0 nk +1 Pmk1 Pm00i=1 1Ki h + h , n + ni=1 1Ki h .nsee g sublinear, note easy see using properties infg(h1 + h2 ) g(h1 ) + g(h2 ). show g(h) = g(h) 0, first observedefinition g equivalent()XXinf +g(Ki ) : N, , R+ , K1 , . . . , Km F +1Ki h .i=1i=1Consider first case > 0.()XXg(h) = inf +g(Ki ) : +1Ki hi=1= inf(+Xi=1= inf(i=1)1X1Ki hg(Ki ) : +1+i=1Xi=1)1Xg(Ki ) : +1Ki hi=1= g(h).= 0, clear definition g g(1 ) g(). (3) followsg(1 ) g(), hence g(0) = g(1 ) = g() = 0.immediate definition g g(1K ) g(K) K F; factg(1K ) = g(K) follows (3).immediate definition g(1) 1.h 0, h 0; since g increasing, g(h) g(h + h) = g(0), since gsublinear, g(0) = 0.Since conditions Lemma B.1 satisfied, g upper probability measure.ReferencesAnger, B., & Lembcke, J. (1985). Infinitely subadditive capacities upper envelopesmeasures. Zeitschrift fur Wahrscheinlichkeitstheorie und Verwandte Gebiete, 68, 403414.Chvatal, V. (1983). Linear Programming. W. Freeman Co., San Francisco, Calif.Conway, J. B. (1990). Course Functional Analysis (Second edition). No. 96 GraduateTexts Mathematics. Springer-Verlag.Dempster, A. P. (1967). Upper lower probabilities induced multivalued mapping.Annals Mathematical Statistics, 38 (2), 325339.80fiA Logic Reasoning Upper ProbabilitiesDickson, L. E. (1913). Finiteness odd perfect primitive abundant numbersn distinct prime factors. American Journal Mathematics, 35 (4), 413422.Fagin, R., & Halpern, J. Y. (1991). Uncertainty, belief probability. ComputationalIntelligence, 7 (3), 160173.Fagin, R., Halpern, J. Y., & Megiddo, N. (1990). logic reasoning probabilities.Information Computation, 87 (1,2), 78128.Giles, R. (1982). Foundations theory possibility. Gupta, M. M., & Sanchez, E.(Eds.), Fuzzy Information Decision Processes, pp. 183195. North-Holland.Halpern, J. Y. (2002). Reasoning uncertainty. Book manuscript.Halpern, J. Y., & Pucella, R. (2002). Reasoning expectation. Proc. EighteenthConference Uncertainty Artificial Intelligence (UAI 2002).Huber, P. J. (1976). Kapazitaten statt Wahrscheinlichkeiten? Gedanken zur Grundlegungder Statistik. Jber. Deutsch. Math.-Verein, 78, 8192.Huber, P. J. (1981). Robust Statistics. Wiley Interscience.Kyburg, Jr., H. E. (1987). Bayesian non-Bayesian evidential updating. Artificial Intelligence, 31, 271293.Lorentz, G. G. (1952). Multiply subadditive functions. Canadian Journal Mathematics,4 (4), 455462.Mendelson, E. (1964). Introduction Mathematical Logic. Van Nostrand, New York.Popkorn, S. (1994). First Steps Modal Logic. Cambridge University Press, Cambridge;New York.Rudin, W. (1976). Principles Mathematical Analysis (Third edition). McGraw-Hill.Shafer, G. (1976). Mathematical Theory Evidence. Princeton University Press, Princeton, NJ.Shores, T. (1999). Applied Linear Algebra Matrix Analysis (Second edition). McGrawHill.Smith, C. A. B. (1961). Consistency statistical inference decision. JournalRoyal Statistical Society, Series B, 23, 125.Walley, P. (1981). Coherent lower (and upper) probabilities. Manuscript, Dept. Statistics,University Warwick.Walley, P. (1991). Statistical Reasoning Imprecise Probabilities. Chapman Hall.Williams, P. M. (1976). Indeterminate probabilities. Przelecki, M., Szaniawski, K., &Wojciki, E. (Eds.), Formal Methods Methodology Empirical Sciences, pp.229246.Wilson, N., & Moral, S. (1994). logical view probability. Proc. 11th EuropeanConference Artificial Intelligence (ECAI-94), pp. 7195.Wolf, G. (1977). Obere und Untere Wahrscheinlichkeiten. Doctoral dissertation, Eidgenossischen Technischen Hochschule, Zurich. (Diss. ETH 5884).81fiJournal Artificial Intelligence Research 17 (2002) 171-228Submitted 3/02; published 9/02Towards Adjustable Autonomy Real Worldscerri@isi.edupynadath@isi.edutambe@usc.eduPaul ScerriDavid V. PynadathMilind TambeInformation Sciences Institute Computer Science DepartmentUniversity Southern California4676 Admiralty Way, Marina del Rey, CA 90292 USAAbstractAdjustable autonomy refers entities dynamically varying autonomy, transferring decision-making control entities (typically agents transferring controlhuman users) key situations. Determining whether transfers-of-controloccur arguably fundamental research problem adjustable autonomy. Previous work investigated various approaches addressing problem oftenfocused individual agent-human interactions. Unfortunately, domains requiring collaboration teams agents humans reveal two key shortcomings previousapproaches. First, approaches use rigid one-shot transfers control resultunacceptable coordination failures multiagent settings. Second, ignore costs (e.g.,terms time delays effects actions) agent's team due transfers-ofcontrol.remedy problems, article presents novel approach adjustable autonomy, based notion transfer-of-control strategy. transfer-of-control strategyconsists conditional sequence two types actions: (i) actions transfer decisionmaking control (e.g., agent user vice versa) (ii) actions changeagent's pre-specified coordination constraints team members, aimed minimizingmiscoordination costs. goal high-quality individual decisions mademinimal disruption coordination team. present mathematical modeltransfer-of-control strategies. model guides informs operationalizationstrategies using Markov Decision Processes, select optimal strategy, givenuncertain environment costs individuals teams. approachcarefully evaluated, including via use real-world, deployed multi-agent systemassists research group daily activities.1.IntroductionExciting, emerging application areas ranging intelligent homes (Lesser et al., 1999),routine organizational coordination (Pynadath et al., 2000), electronic commerce (Collinset al., 2000a), long-term space missions (Dorais et al., 1998) utilize decision-makingskills agents humans. new applications brought forth increasinginterest agents' adjustable autonomy (AA), i.e., entities dynamically adjustinglevel autonomy based situation (Mulsiner & Pell, 1999). Many excitingapplications deployed unless reliable AA reasoning central component.AA, entity need make decisions autonomously; rather choose reduceautonomy transfer decision-making control users agents,c 2002 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiScerri, Pynadath & Tambeexpected net benefit (Dorais et al., 1998; Barber, Goel, & Martin, 2000a;Hexmoor & Kortenkamp, 2000).central problem AA determine whether transfers decision-makingcontrol occur. key challenge balance two potentially con icting goals.one hand, ensure highest-quality decisions made, agent transfer control human user (or another agent) whenever user superior decision-makingexpertise.1 hand, interrupting user high costs user mayunable make communicate decision, thus transfers-of-control minimized. Previous work examined several different techniques attempt balancetwo con icting goals thus address transfer-of-control problem. example,one technique suggests decision-making control transferred expectedutility higher expected utility making autonomous decision(Horvitz, Jacobs, & Hovel, 1999). second technique uses uncertainty sole rationaledeciding control, forcing agent relinquish control userwhenever uncertainty high (Gunderson & Martin, 1999). Yet techniques transfercontrol user erroneous autonomous decision could cause significant harm (Doraiset al., 1998) agent lacks capability make decision (Ferguson, Allen, &Miller, 1996).Unfortunately, previous approaches transfer-of-control reasoning indeedprevious work AA, focused domains involving single agent singleuser, isolated interactions entities. applied interacting teamsagents humans, interaction agent human impacts interaction entities, techniques lead dramatic failures. particular,presence entities team members introduces third goal maintaining coordination (in addition two goals already mentioned above), previoustechniques fail address. Failures occur two reasons. Firstly, previous techniquesignore team related factors, costs team due incorrect decisions duedelays decisions transfers-of-control. Secondly (and importantly),techniques use one-shot transfers-of-control, rigidly committing one two choices: (i)transfer control wait input (choice H ) (ii) act autonomously (choice A). However,given interacting teams agents humans, either choice lead costly failuresentity control fails make report decision way maintains coordination.instance, human user might unable provide required input due temporary communication failure; may cause agent fail part joint action,joint action may dependent user's input. hand, forcingless capable entity make decision simply avoid miscoordination lead poordecisions significant consequences. Indeed, seen Section 2.2, appliedrigid transfer-of-control decision-making domain involving teams agents users,failed dramatically.Yet, many emerging applications involve multiple agents multiple humans actingcooperatively towards joint goals. address shortcomings previous AA workdomains, article introduces notion transfer-of-control strategy. transfer-ofcontrol strategy consists pre-defined, conditional sequence two types actions: (i)1. AA problem general involves transferring control one entity another, paper,typically focus interactions involving autonomous agents human users.172fiTowards Adjustable Autonomy Real Worldactions transfer decision-making control (e.g., agent user vice versa);(ii) actions change agent's pre-specified coordination constraints team members,rearranging activities needed (e.g., reordering tasks buy time make decision).agent executes strategy performing actions order, transferring controlspecified entity changing coordination required, point timeentity currently control exercises control makes decision. Thus, previouschoices H two many different possibly complex transfer-ofcontrol strategies. instance, ADAH strategy implies agent initially attemptsmake autonomous decision. agent makes decision autonomously strategyexecution ends there. However, chance unable make decisiontimely manner, perhaps computational resources busy higherpriority tasks. avoid miscoordination agent executes action changescoordination constraints activity. example, action could informagents coordinated action delayed, thus incurring cost inconvenienceothers buying time make decision. still cannot make decision,eventually take action H , transferring decision-making control user waitingresponse. general, strategies involve available entities contain manyactions change coordination constraints. strategies may useful singleagent single-human settings, particularly critical general multiagent settings,discussed below.Transfer-of-control strategies provide exible approach AA complex systemsmany actors. enabling multiple transfers-of-control two (or more) entities,rather rigidly committing one entity (i.e., H ), strategy attempts providehighest quality decision, avoiding coordination failures. particular, multiagentsetting often uncertainty whether entity make decisionso, e.g., user may fail respond, agent may able make decisionexpected communication channel may fail. strategy addresses uncertaintyplanning multiple transfers control cover contingencies. instance,ADH strategy, agent ultimately transfers control human attempt ensureresponse provided case agent unable act. Furthermore, explicitcoordination-change actions, i.e., actions, reduce miscoordination effects, cost,better decisions made. Finally, since utility transferring control changingcoordination dependent actions taken afterwards, agent must plan strategyadvance find sequence actions maximizes team benefits. example,reacting current situation repeatedly taking giving control strategyADHADH : : : may costly planning ahead, making bigger coordinationchange, using shorter ADH strategy. developed decision theoretic modelstrategies, allows expected utility strategy calculated and, hence,strategies compared.Thus, key AA problem select right strategy, i.e., one providesbenefit high-quality decisions without risking significant costs interrupting usermiscoordination team. Furthermore, agent must select right strategy despitesignificant uncertainty. Markov decision processes (MDPs) (Puterman, 1994) naturalchoice implementing reasoning explicitly represent costs, benefitsuncertainty well lookahead examine potential consequences sequences173fiScerri, Pynadath & Tambeactions. Section 4, general reward function presented MDP resultsagent carefully balancing risks incorrect autonomous decisions, potential miscoordinationcosts due changing coordination team members. Detailed experimentsperformed MDP, key results follows. relative importancecentral factors, cost miscoordination, varied resulting MDP policiesvaried desirable way, i.e., agent made decisions autonomously costtransferring control entities increased. experiments reveal phenomenonreported literature: agent may act autonomously coordinationchange costs either low high, \middle" range, agent tends actless autonomously.research conducted context real-world multi-agent system,called Electric Elves (E-Elves) (Chalupsky, Gil, Knoblock, Lerman, Oh, Pynadath, Russ,& Tambe, 2001; Pynadath et al., 2000), used six monthsUniversity Southern California, Information Sciences Institute. E-Elves assistsgroup researchers project assistant daily activities, providing excitingopportunity test AA ideas real environment. Individual user proxy agents calledFriday (from Robinson Crusoe's servant Friday) act team assist reschedulingmeetings, ordering meals, finding presenters day-to-day activities. courseseveral months, MDP-based AA reasoning used around clock E-Elves,making many thousands autonomy decisions. Despite unpredictability user'sbehavior agent's limited sensing abilities, MDP consistently made sensibleAA decisions. Moreover, many times agent performed several transfers-of-controlcope contingencies user responding. One lesson learned actuallydeploying system sometimes users wished uence AA reasoning, e.g.,ensure control transferred particular circumstances. allow usersuence AA reasoning, safety constraints introduced allow users preventagents taking particular actions ensuring take particular actions.safety constraints provide guarantees behavior AA reasoning, makingbasic approach generally applicable and, particular, making applicabledomains mistakes serious consequences.rest article organized follows. Section 2 gives detailed descriptionAA problem presents Electric Elves motivating example application. Section3 presents formal model transfer-of-control strategies AA. (Readers interestedmathematical details may wish skip Section 3.) operationalizationstrategies via MDPs described Section 4. Section 5, results detailedexperiments presented. Section 6 looks related work, including earlier AA workanalyzed within strategies framework. Section 7 gives summary article.Finally, Section 8 outlines areas work could extended make applicableapplications.2.Adjustable Autonomy { Problemgeneral AA problem previously formally defined literature, particularly multiagent context. following, formal definition problem givenclearly define task AA reasoning. team, may consist entirely174fiTowards Adjustable Autonomy Real Worldagents include humans, joint activity, ff. entity team workscooperatively joint activity. agent, A, role, , team. Dependingspecific task, roles need performed successfully orderjoint activity succeed. primary goal agent success ffpursues performing . Performing requires one non-trivial decisionsmade. make decision, d, agent draw upon n entities setE = fe1 : : : en g, typically includes agent itself. entity E (e.g., humanuser) capable making decision d. entities E necessarily partteam performing ff. Different agents users differing abilities make decisionsdue available computational resources, access relevant information, etc. Coordinationconstraints, , exist roles members team. example,various roles might need executed simultaneously certain ordercombined quality total cost. critical facet successful completion joint taskff, given jointness, ensure coordination team members maintained,i.e., violated. Thus, describe AA problem instance tuple:hA; ff; ; ; d; E i.AA perspective, agent take two types actions decision, d.First, transfer control entity E capable making decision. general,restrictions when, often long decision-making controltransferred particular entity. Typically, agent also transfer decision-makingcontrol itself. general, assume agent transfers control,guarantee exact time response exact quality decision madeentity control transferred. fact, cases know whetherentity able make decision even whether entity knowdecision-making control, e.g., control transferred via email, agent may knowuser actually read email.second type action agent take request changes coordination constraints, , team members. coordination change gives agentpossibility changing requirements surrounding decision made, e.g.,required timing, cost quality decision, may allow better fulfill responsibilities. coordination change might involve reordering delaying tasks mayinvolve changing roles, may dramatic change team pursues ffcompletely different way. Changing coordination cost, may betterincur cost violate coordination constraints, i.e., incur miscoordination costs.Miscoordination team members occur many reasons, e.g., constraintlimits total cost joint task might violated one team member incurs higherexpected cost team members reduce costs. article,primarily concerned constraints related timing roles, e.g., ordering constraints requirements simultaneous execution. turn, usually requiresagent guards delayed decisions although also require decisionmade soon.Thus, AA problem agent, given problem instance, hA; ff; ; ; d; E i,choose transfer-of-control coordination-change actions maximizes overallexpected utility team. remainder section describe concrete, real175fiScerri, Pynadath & Tambeworld domain AA (Section 2.1) initial failed approach motivates solution(Section 2.2).2.1 Electric Elvesresearch initiated response issues arose real applicationresulting approach extensively tested day-to-day running application.Electric Elves (E-Elves) project USC/ISI deploy agent organizationsupport daily activities human organization (Pynadath et al., 2000; Chalupskyet al., 2001). believe application fairly typical future generation applications involving teams agents humans. operation human organizationrequires performance many everyday tasks ensure coherence organizationalactivities, e.g., monitoring status activities, gathering information keeping everyone informed changes activities. Teams software agents aid organizationsaccomplishing tasks, facilitating coherent functioning rapid, exible responsecrises. number underlying AI technologies support E-Elves, e.g., technologiesdevoted agent-human interactions, agent coordination, accessing multiple heterogeneousinformation sources, dynamic assignment organizational tasks, deriving informationorganization members (Chalupsky et al., 2001). technologies useful,AA fundamental effective integration E-Elves day-to-day runningreal organization and, hence, focus paper.basic design E-Elves shown Figure 1(a). agent proxy calledFriday (after Robinson Crusoes' man-servant Friday) acts behalf useragent team. design Friday proxies discussed detail (Tambe, Pynadath,Chauvat, Das, & Kaminka, 2000) (where referred TEAMCORE proxies).Currently, Friday perform several tasks user. user delayed meeting,Friday reschedule meeting, informing Fridays, turn inform users.research presentation slot open, Friday may respond invitation presentbehalf user. Friday also order user's meals (see Figure 2(a)) trackuser's location, posting Web page. Friday communicates users using wirelessdevices, personal digital assistants (PALM VIIs) WAP-enabled mobile phones,via user workstations. Figure 1(b) shows PALM VII connected Global PositioningService (GPS) device, tracking users' locations enabling wireless communicationFriday user. Friday's team behavior based teamwork model,called STEAM (Tambe, 1997). STEAM encodes enforces constraints rolesrequired success joint activity, e.g., meeting attendees arrivemeeting simultaneously. role within team needs filled, STEAM requiresteam member assigned responsibility role. find best suited person,team auctions role, allowing consider combination factors assignbest suited user. Friday bid behalf user, indicating whether usercapable and/or willing fill particular role. Figure 2(b) shows tool allows usersview auctions progress intervene desire. auction progress, JayModi's Friday bid Jay capable giving presentation, unwillingso. Paul Scerri's agent highest bid eventually allocated role.176fiTowards Adjustable Autonomy Real WorldFridayFridayFridayFriday(a)(b)Figure 1: (a) Overall E-Elves architecture, showing Friday agents interacting users.(b)Palm VII communicating users GPS device detectinglocation.177fiScerri, Pynadath & TambeAA critical success E-Elves since, despite range sensing devices,Friday considerable uncertainty user's intentions even location; hence,Friday always appropriate information make correct decisions.hand, user required information, Friday cannot continually askuser input, since interruptions disruptive time-consuming. fourdecisions E-Elves AA reasoning applied: (i) whether user attendmeeting time; (ii) whether close auction role; (iii) whether user willingperform open team role; (iv) order lunch. paper,focus AA reasoning two decisions: whether user attend meetingtime whether close auction role. decision whether userattend meeting time often used dicult decisions Fridayfaces. brie describe decision close auction later show insightprovided model strategies led significant reduction amount coderequired implement AA reasoning decision. decision volunteer usermeeting similar earlier decisions, omitted brevity; decision orderlunch currently implemented simpler fashion (at least yet) illustrativefull set complexities.central decision Friday, describe terms problem formulation,hA; ff; ; ; d; E i, whether user attend meeting currently scheduled meeting time. case, Friday agent, A. joint activity, ff, meetingattendees attend meeting simultaneously. Friday acts proxy user, hencerole, , ensure user arrives currently scheduled meeting time.coordination constraint, , Friday's role roles Fridaysoccur simultaneously, i.e., users must attend currently scheduled time.attendee arrives late, all, time attendees wasted;hand, delaying meeting disruptive users' schedules. decision, d, whetheruser attend meeting could made either Friday user, i.e.,E = fuser; Fridayg. Clearly, user often better placed make decision.However, Friday transfers control user decision, must guard miscoordination, i.e., attendees wait, waiting user response.decisions potentially costly, e.g., incorrectly telling attendees userattend, Friday avoid taking autonomously. buy timeuser make decision gather information, Friday could changecoordination constraints action. Friday several different actions disposal, including delaying meeting different lengths time, well ablecancel meeting entirely. user also request action, e.g., via dialog boxFigure 5(a), buy time make meeting. user decides required,Friday conduit Fridays (and hence users) informed.Friday must select sequence actions, either transferring control user, delayingcancelling meeting autonomously announcing user attend,maximize utility team.second AA decision look decision close auction openrole assign user role.2 case, joint activity, ff, group research2. also roles submitting bids auction AA decisions simpler, hencefocus here.178fiTowards Adjustable Autonomy Real World(a)(b)Figure 2: (a) Friday transferring control user decision whether order lunch.(b) E-Elves auction monitoring tool.meeting role, , auctioneer. Users always submit bidsrole immediately; fact, bids may spread several days, users mightbid all. specific decision, d, focus whether close auctionassign role continue waiting incoming bids. individual team membersprovide bids, auctioneer agent human team leader decides presenter basedinput (E = fuser; auctioneer agentg). team expects willing presenterhigh-quality research presentation, means presenter need timeprepare. Thus, coordination constraint, capable, willing user mustallocated role enough time prepare presentation. Despite individuallyresponsible actions, agent team may reach highly undesirable decision, e.g., assigninguser week week, hence advantage getting human team leader'sinput. agent faces uncertainty (e.g., better bids come in?), costs (i.e., laterassignment, less time presenter prepare), needs considerpossibility human team leader special preferencepresentation particular meeting. transferring control, agent allowshuman team leader make assignment. decision, coordination-change action,D, would reschedule research meeting. However, relative cost cancellingmeeting, cost rescheduling high rescheduling useful action.2.2 Decision-Tree ApproachOne logical avenue attack AA problem E-Elves apply approachused previously reported, successful meeting scheduling system, particular CAP(Mitchell, Caruana, Freitag, McDermott, & Zabowski, 1994). Like CAP, Friday learneduser preferences using C4.5 decision-tree learning (Quinlan, 1993). Friday recorded valuesdozen carefully selected attributes user's preferred action (identified asking179fiScerri, Pynadath & Tambeuser) whenever make decision. Friday used data learn decisiontree encoded autonomous decision making. AA, Friday also asked userwanted decisions taken autonomously future. responses, Fridayused C4.5 learn second decision tree encoded rules transferring control.Thus, second decision tree indicated Friday act autonomously, wouldtake action suggested first decision tree. Initial tests C4.5 approachpromising (Tambe et al., 2000), key problem soon became apparent.Friday encountered decision learned transfer control user,would wait indefinitely user make decision, even though inaction causedmiscoordination teammates. particular, team members would arrivemeeting location, waiting response user's Friday, would endcompletely wasting time response arrived. address problem, userrespond within fixed time limit (five minutes), Friday took autonomous action.Although performance improved, resulting system deployed 24/7 leddramatic failures, including:1. Example 1: Tambe's (a user) Friday incorrectly cancelled meeting divisiondirector Friday over-generalized training examples.2. Example 2: Pynadath's (another user) Friday incorrectly cancelled group's weeklyresearch meeting time-out forced choice (incorrect) autonomousaction.3. Example 3: Friday delayed meeting almost 50 times, time 5 minutes.correctly applying learned rule ignoring nuisance restmeeting participants.4. Example 4: Tambe's Friday automatically volunteered presentation,actually unwilling. Friday over-generalized examplestimeout occurred took undesirable autonomous action.Clearly, team context, rigidly transferring control one agent (user) failed. Furthermore, using time-out rigidly transferred control back agent,capable making high-quality decision, also failed. particular, agent neededbetter avoid taking risky decisions explicitly considering costs (example 1),take lower cost actions delay meetings buy user time respond (example 24). Furthermore, example 3 showed, agent needed plan ahead, avoid takingcostly sequences actions could replaced single less costly action (example3). theory, using C4.5 Friday might eventually able learn rules wouldsuccessfully balance costs deal uncertainty handle special caseson, large amount training data would required.3.Strategies Adjustable Autonomyavoid rigid one-shot transfers control allow team costs considered,introduce notion transfer-of-control strategy, defined follows:180fiTowards Adjustable Autonomy Real WorldDefinition 3.1 transfer-of-control strategy pre-defined, conditional sequence twotypes actions: (i) actions transfer decision-making control (e.g., agentuser agents, vice versa) (ii) actions change agent's pre-specifiedcoordination constraints team members, aimed minimizing miscoordination costs.agent executes transfer-of-control strategy performing specified actionssequence, transferring control specified entity changing coordination required,point time entity currently control exercises controlmakes decision. Considering multi-step strategies allows agent exploit decisionmaking sources considered risky exploit without possibility retaking control.example, control could transferred capable always available decisionmaker taken back decision made serious miscoordination occurred.complex strategies, potentially involving several coordination changes, give agentoption try several decision-making sources exible getting inputhigh-quality decision makers. result, transfer-of-control strategies specifically allowagent avoid costly errors, enumerated previous section.3Given AA problem instance, hA; ff; ; ; d; E , agent transfer decision-makingcontrol decision entity ei 2 E , denote transfer-of-controlaction symbol representing entity, i.e., transferring control ei denotedei . agent transfers decision-making control, may stipulate limit timewait response entity. capture additional stipulation,denote transfer-of-control actions time limit, e.g., ei (t) represents eidecision-making control maximum time t. action two possible outcomes:either ei responds time makes decision, respond decisionremains unmade time t. addition, agent mechanismchange coordination constraints (denoted D) change expected timingdecision. action changes coordination constraints, , team members.action associated value, Dvalue , specifies magnitude (i.e., muchalleviated temporal pressure), cost, Dcost , specifies price paidmaking change. concatenate actions specify complete transferof-control strategy. instance, strategy H (5)A would specify agent firstrelinquishes control asks entity H (denoting H uman user). user respondsdecision within five minutes, need go further. not,agent proceeds next transfer-of-control action sequence. example,next action, A, specifies agent make decision complete task.transfers control occur case. define space possiblestrategies following regular expression:= (E R)((E R) + D)(1)(E R) possible combinations entity maximum time.readability, frequently omit time specifications transfer-ofcontrol actions instead write order agent transfers control among3. domains, may make sense attempt get input one entity once, hencerequiring strategies actions might executed parallel. However, work, firststep, consider strategies. Furthermore, relevant domains hand.181fiScerri, Pynadath & Tambeentities executes Ds (e.g., often write HA instead H (5)A). timespecifications omitted, assume transfers happen optimal times,4 i.e.,times lead highest expected utility. consider strategiessequence actions different timings strategy, agent O(jE jk )possible strategies select from, k maximum length strategy jE jnumber entities. Thus, agent wide range options, even practicalconsiderations lead reasonable upper bound k jE j. agent must selectstrategy maximizes overall expected utility ff.rest section, present mathematical model transfer-of-control strategies AA use model guide search solution. Moreover, modelprovides tool predicting performance various strategies, justifying useexplaining observed phenomena use. Section 3.1 presents model AAstrategies detail. Section 3.2 reveals key properties complex strategies, including dominance relationships among strategies. Section 3.3 examines E-Elves applicationlight model, make specific predictions properties successfulAA approach reasoning application class have. predictions shapeoperationalization strategies Section 4.3.1 Mathematical Model Strategiestransfer-of-control model presented section allows calculation expectedutility (EU) individual strategies, thus allowing strategies compared. calculation strategy's EU considers four elements: likely relative quality differententities' decisions; probability getting response entity particular time;cost delaying decision; costs benefits changing coordination constraints. parameters might also modeled similar manner, experienceE-Elves AA work suggests parameters critical onesacross wide range joint activities.first element model expected quality entity's decision. general,capture quality entity's decision time functions EQ = fEQde (t) :R ! Rg. quality decision ects probability entity make\appropriate" decision costs incurred decision wrong. expected qualitydecision calculated decision theoretic way, multiplying probabilityoutcome, i.e., decision, utility decision, i.e., cost benefitdecision. example, higher probability entity make mistake,lower quality, even lower mistakes might costly. quality decisionentity make vary time information available changestime \think". second element model probability entitymake decision control transferred it. functions, P = fP>e (t) : R ! [0; 1]g,represent continuous probability distributions timeentity e respond.R t0 eiis, probability ei respond time t0 0 P> (t)dt.third element model representation cost inappropriate timingdecision. general, making decision particular point time incurs4. best time transfer control found, e.g., differentiating expected utility equationSection 3.1 solving 0.182fiTowards Adjustable Autonomy Real Worldcost function time, t, coordination constraints, ,team members. stated earlier, focus cases constraint violations due delaysmaking decisions. Thus, cost due violation constraints causedmaking decision point time. write wait-cost function :W = f (; t) returns cost making decision particular point timegiven coordination constraints, . miscoordination cost fundamental aspectmodel given emphasis multiagent domains. called \wait cost" modelsmiscoordination arises team \waits" entity make ultimatedecision. domains like E-Elves, team incurs wait costs situations (forexample) meeting attendees assembled meeting room timemeeting, kept waiting without input decision Friday (potentiallycannot provide high-quality decision, get input user). Noticedifferent roles lead different wait cost functions, since delays performancedifferent roles different effects team. assumepoint time, , costs accrue, i.e., f (; t) = f (; ).deadline, , maximum cost due inappropriate timing decisionincurred. Finally, assume that, general, , wait cost function nondecreasing, ecting idea bigger violations constraints lead higher wait costs.final element model coordination-change action, D, moves agentaway deadline hence reduces wait costs incurred.model effect letting W function Dvalue (rather t)action fixed cost, Dcost , incurred immediately upon execution.example, E-Elves domain, suppose time meeting, Friday delaysmeeting 15 minutes (D action). Then, following time period, incurrelatively low cost making decision 15 minutes meeting (t Dvalue ),rather relatively high cost making decision time meeting.Other, possibly complex, models action could also used.use four elements compute EU arbitrary strategy, s. utilityderived decision made time entity control qualityentity's decision minus costs incurred waiting t, i.e., EUedc (t) = EQdec (t)W (t). coordination-change action taken also effect utility.coordination change value Dvalue taken time , incurred wait costW (). Then, t, wait cost incurred W (t Dvalue ) W ( Dvalue ).Thus, action taken time cost Dcost value Dvalue ,utility decision time (t > ) is: EUedc (t) = EQdec (t) W () W ( Dvalue ) +W (t Dvalue) Dcost. calculate EU entire strategy, multiply responseprobability mass function's value instant EU receiving responseinstant, integrate products. Hence, EU strategy givenproblem instance, hA; ff; ; ; d; E , is:Z 1hA;ff;;;d;EEUs=P (t)EUedc (t) :dt(2)0 >strategy involves several actions, need ensure probability responsefunction wait-cost calculation ect control situation pointstrategy. example, user, H , control time t, P> (t) ect H's183fiScerri, Pynadath & TambeW (0)EUAd = EQdA (0)EUedEUeA==Z0Z0EUedDeA =P>(t) (EQde (t)P>(t) (EQde (t)W (t)):dt +W (t)):dt +1P>(t) (EQde (t)Z1ZR(3)W (D)):dt (4)P>(t):dt (EQda (T )W (T )) (5)00 P> (t)(EQe (t) W (t)):dt +P>(t)(EQe (t) W () + W ( Dvalue ) W (t Dvalue ) Dcost ):dt +R1P> (t)(EQA (t) W () + W ( Dvalue ) W (T Dvalue ) Dcost ):dt(6)RTTable 1: General AA EU equations sample transfer control strategies.probability responding t, i.e., P>H (t0 ). end, break integralEquation 2 separate terms, term representing one segment strategy,e.g., strategy UA would one term U control anothercontrol.Using basic technique writing EU calculations, writespecific equations arbitrary transfer-of-control strategies. Equations 3-6 Table 1show EU equations strategies A, e , eA e DeA respectively. equationsassume agent, A, make decision instantaneously (or least, delaysignificant enough affect overall value decision). equations createdwriting integral segments strategy, described above.time agent takes control e , time occurs.One write equations complex strategies way. Noticeequations make assumptions particular functions.Given EU strategy calculated, AA problem agent reducesfinding following transfer-of-control strategy maximize EU. Formally,agent's problem is:Axiom 3.1 problem hA; ff; ; ; d; E , agent must select 2 8s0 2S; s0 6= s; EUshA;ff;;;d;E EUsh0A;ff;;;d;E184fiTowards Adjustable Autonomy Real World50-50.1w 0.20.30.41.20.8pFigure 3: Graph comparing EU two strategies, H DA (solid line) H (dashed line)given particular instantiation model constant expected decisionmaking quality, exponentially rising wait costs, Markovian response probabilities. p parameter P>(t) function, higher p meaning longerexpected response time. w parameter W (t) function higher wmeaning rapidly accruing wait costs.3.2 Dominance Relationships among Strategiesagent could potentially find strategy highest EU examiningevery strategy S, computing EU, selecting strategy highest value.example, consider problem domains constant expected decision-making quality,exponentially rising wait costs, Markovian response probabilities. Figure 3 showsgraph EU two strategies (H DA H ) given particular model instantiation.Notice that, different response probabilities rates wait cost accrual, one strategyoutperforms other, neither strategy dominant entire parameter space.EU strategy also dependent timing transfers control, turndepend relative quality entities' decision making. Appendix providesdetailed analysis.Fortunately, evaluate compare every candidateexhaustive search find optimal strategy. instead use analytical methodsdraw general conclusions relative values different candidate strategies.particular, present three Lemmas show domain-level conditionsparticular strategy types superior others. Lemmas also lead us the, perhapssurprising, conclusion complex strategies necessarily superior single-shotstrategies, even multi-agent context; fact, particular strategy dominatesstrategies across domains.Let us first consider AA subproblem whether agent ever take backcontrol another entity. show that, certain conditions, agentalways eventually take back control, strategy selection process ignorestrategies agent (i.e., strategies ending A). agent'sgoal strike right balance waiting indefinitely user response185fiScerri, Pynadath & Tambetaking risky autonomous action. Informally, agent reasons eventuallymake decision expected cost continued waiting exceeds differenceuser's decision quality own. formally, agent eventually take backdecision-making control iff, time t:ZP> (t0 )W (t0 ):dt0 W (t) > EQdU (t) EQdA (t)(7)left-hand side calculates future expected wait costs right-hand sidecalculates extra utility gained getting response user. resultleads following general conclusion strategies end giving control backagent:Lemma 1: 2 isRa strategy ending e 2 E , s0 sA, EUsd0 > EUsd iff8e 2 E; 9t < P>(t0 )W (t0 ):dt0 W (t) > EQde (t) EQdA(t)Lemma 1 says if, point time, expected cost indefinitely leavingcontrol hands user exceeds difference quality agent'suser's decisions, strategies ultimately give agent control dominatenot. Thus, rate wait cost accrual increases differencerelative quality decision-making abilities decreases user's probability responsedecreases, strategies agent eventually takes back control dominate.key consequence Lemma (in opposite direction) that, rate costs accrueaccelerate, probability response stays constant (i.e., Markovian),agent indefinitely leave control user (if user originallygiven control), since expected wait cost change time. Hence, evenagent faced situation potentially high total wait costs, optimal strategymay one-shot strategy handing control waiting indefinitely,expected future wait costs point time relatively low. Thus, Lemma 1 isolatescondition consider appending transfer-of-control actionstrategy.perform similar analysis identify conditionsinclude action strategy. agent incentive changing coordinationconstraints via action due additional time made available getting highquality response entity. However, overall value action dependsnumber factors (e.g., cost taking action timing subsequenttransfers control). calculate expected value comparing EUstrategy without D. useful increased expected valuestrategy greater cost, Dcost .Lemma 2: sR2 s0 included EUsd0 > EUsd iffRP> (t0 )W (t):dt0P>(t0 )W (tjD):dt0 > Dcostillustrate consequences Lemma 2 considering specific problem modelAppendix (i.e., P> (t) = exp , W (t) = ! exp!t , EQde (t) = c, candidate strategiesiff ( ! )! exp ( !) (1 exp !Dvalue ) >eA e DA). case, EUedDA > EUeADcost. Figure 4 plots value action vary rate wait cost accumulation,w, parameter Markovian response probability function, p. graph shows186fiTowards Adjustable Autonomy Real WorldValue0.160.120.080.040-0.040.1 0.2w0.3 0.4 0.510.750.5 p0.25Figure 4: value action particular model (P> (t) = expEQde (t) = c).,W (t) = ! exp!t ,benefit highest probability response neither lowhigh. probability response low, user unlikely respond,even given extra time; hence, agent incurred Dcost benefit.also little value probability response high, user likelyrespond shortly D, meaning little effect (the effectwait costs action taken). Overall, according Lemma 2, pointsgraph goes Dcost , agent include action, and, points,not. Figure 4 demonstrates value action specific subclass problemdomains, extend conclusion general case well. instance,specific model exponential wait costs, models wait costs growslowly, fewer situations Lemma 2's criterion holds (i.e.,useful). Thus, Lemma 2 allows us eliminate strategies consideration, basedevaluation criterion particular domain interest.Given Lemma 2's evaluation adding single action strategy, naturalask whether second, third, etc. action would increase EU even further. words,complex strategy better simple one, even complex strategy evenbetter? answer \not necessarily".8K 2 N; 9W 2 W; 9P 2 P; 9EQ 2 EQ optimal strategyactions.Informally, Lemma 3 says cannot fix single, optimal number actions,every possible number actions, potential domain (i.e., combinationLemma 3:Kwait-cost, response-probability, expected-quality functions) numberactions justified optimal. Consider situation costfunction number Ds date (i.e., cost K th f (K )). example,E-Elves' meeting case, cost delaying meeting third time muchhigher cost first delay, since delay successively annoyingmeeting participants. Hence, test usefulness K th strategy,187fiScerri, Pynadath & Tambegiven specific model Appendix I, is:!exp exp! )(8)f (K ) < !(exp Dvalue! 1) ( expDepending nature f (K ), Equation 8 hold number Ds, so,K , conditions strategy K Ds optimal. instance,Section 5.3, show maximum length optimal strategy randomconfiguration 25 entities usually less eight actions.Equation 8 illustrates value additional limited changing Dcost ,Lemma 3 also shows us factors affect value additional D.example, even constant Dcost , value additional depends manyactions agent performs. Figure 4 shows value dependsrate wait costs accrue. rate wait cost accrual accelerates time (e.g.,exponential model), action slows acceleration, rendering second actionless useful (since wait costs accruing slowly). Notice also Ds becomevalueless deadline, wait costs stop accruing.Taken together, Lemmas 1-3 show particular transfer-of-control strategy dominates others across domains. Moreover, different strategies, single-shotstrategies arbitrarily complex strategies, appropriate different situations, althoughrange situations particular transfer-of-control action provides benefitquite narrow. Since strategy might low EU set parameters, choosingwrong strategy lead poor results. hand, understandparameter configuration intended application domain, Lemmas 1-3 provide usefultools focusing search optimal transfer-of-control strategy. Lemmasused off-line substantially reduce space strategies need searchedfind optimal strategy. However, general may many strategies findingoptimal strategy may possible feasible.3.3 Model Predictions E-Elvessection, use model predict properties successful approach AAE-Elves. Using approximate functions probability response, wait cost,expected decision quality, calculate EU various strategies determinetypes strategies going useful. Armed knowledge, predictkey properties successful implementation.key feature E-Elves user mobile. moves around environment, probability responding requests decisions changes drastically, e.g.,likely respond workstation. calculate EU different strategies,need know P>(t), means need estimate response probabilitiesmodel change user moves around. Friday communicates viaworkstation dialog box, user respond, average, five minutes. However,Friday communicates via Palm pilot average user response time hour. Usersgenerally take longer decide whether want present research meeting, takingapproximately two days average. So, function P>(t) average value5 minutes user oce, average one hour user contactedvia Palm pilot average two days decision whether present188fiTowards Adjustable Autonomy Real Worldresearch meeting. also necessary estimate relative quality user, EQdU (t),Friday's decision making, EQdA (t). assume user's decision-making EQdU (t)high respect Friday's, EQdA (t). uncertainty user intentions makeshard Friday consistently make correct decisions time userarrive meetings, although sensors (e.g., GPS device) give indicationuser's location. dealing important meetings, cost Friday's errorshigher. Thus, cases, decision-making quality user Fridaysimilar, i.e., EQUd (t) EQAd (t); cases, order magnitudedifference, i.e., EQUd (t) 10 EQAd (t). wait cost function, W (t), much largerbig meetings small increase rapidly attendees wait longer meetingroom. Finally, cost delays, i.e., Dcost , vary order magnitude.particular, cost rescheduling meetings varies greatly, e.g., cost reschedulingsmall informal meetings colleagues far less rescheduling full lecture room5 PM Friday.parameters laid show parameters vary decision decision.specific decision, use Markovian response probabilities (e.g., useroce, average response time five minutes), exponentially increasing wait costs,constant decision-making quality (though changes decision decision) calculateEU interesting strategies. Calculating EU different strategies using valuesdifferent parameters shown allows us draw following conclusions (Table 5Section 5.3 presents quantitative illustration predictions):strategy e used, since combinations user locationmeeting importance EU strategy low.Multiple strategies required, since different user locations meeting importance different strategies optimal.Since quite different strategies required user different locations,AA reasoning need change strategies user changes location.strategy reasonable EU possible parameter instantiations, hence alwaysusing strategy occasionally cause dramatic failures.decisions, strategies end agent taking decision, since strategiesending user control generally low EU.predictions provide important guidance successful solution AAE-Elves. particular, make clear approach must exibly choosedifferent strategies adjust depending meeting type user location.Section 2.2 described unsuccessful C4.5 approach AA E-Elves identifiedseveral reasons mistakes occurred. particular, rigidly transferring controlone entity ignoring potential team costs involved agent's decision highlightedreasons dramatic mistakes Friday's autonomy reasoning. Reviewing C4.5approach light notion strategies, see Friday learned one strategystuck strategy. particular, originally, Friday would wait indefinitely userresponse, i.e., would follow strategy e , learned transfer control. shown later189fiScerri, Pynadath & TambeTable 5, strategy low EU. fixed-length timeout introduced,Friday would follow strategy e (5)A. strategy high EU EQUd (t) EQAd (t)low EU EQUd (t) 10 EQAd (t). Thus, model explains phenomenonobserved practice.hand, use model understand C4.5's failure casemean never useful AA. Different strategies requiredcertain parameters (like probability response wait cost) change significantly.applications parameters change dramatically decision decision,one particular strategy may always appropriate. applications, C4.5 might learnright strategy small amount training data perform acceptably well.4.Operationalizing Strategies MDPsformalized problem AA selection transfer-of-control strategy highest EU. need operational mechanism allows agentperform selection. One major conclusion previous section differentstrategies dominate different situations, applications E-Elves require mechanism(s) selecting strategies situation-sensitive fashion. particular,mechanism must exibly change strategies situation changes. required mechanism must also represent utility function specified expected decision qualities,EQ, costs violating coordination constraints, W, coordination-change cost,Dcost. Finally, mechanism must also represent uncertainty entity responseslook ahead possible responses (or lack thereof) may occur future.MDPs natural means performing decision-theoretic planning required findbest transfer-of-control strategy. MDP policies provide mapping agent'sstate optimal transfer control strategy. encoding parameters modelAA strategies MDP, MDP effectively becomes detailed implementationmodel and, hence, assumes properties. use standard algorithms (Puterman,1994) find optimal MDP policy and, hence, optimal strategies followstate.simplify exposition, well illustrate generality resulting MDP,section describes mapping AA strategies MDP four subsections.particular, Section 4.1 provides direct mapping strategies abstract MDP. Section4.2 fills state features enable concrete realization reward function,still maintaining domain-independent view. Thus, section completely defines generalMDP AA potentially reusable across broad class domains. Section 4.3 illustratesimplemented instantiation MDP E-Elves. Section 4.4 addresses practicalissues operationalizing MDPs domains E-Elves.4.1 Abstract MDP Representation AA ProblemMDP representation's fundamental state features capture state control:controlling-entity entity currently decision-making control.ei -response response ei made agent's requests input.190fiTowards Adjustable Autonomy Real WorldOriginal State ActionDestination Stateectrl timeectrl ei -responsetimeejtkeieiyestk+1ejtkeieitk+1eitkwaiteiyestk+1eitkwaiteitk+1eitkeitk DvalueProbability11R tk+1 eitkR P> (t)dttk+1 eitk P> (t)dtR tk+1eitkR P> (t)dttk+1 eitk P> (t)dt1Table 2: Transition probability function AA MDP. ectrl controlling-entity.time current time, typically discretized ranging 0 deadline,| i.e., set ft0 = 0; t1 ; t2 ; : : : ; tn = g.ei -response null time = , agent terminal state. formercase, decision value ei -response.specify set actions MDP representation = E [fD; waitg.set actions subsumes set entities, E , since agent transfer decision-makingcontrol one entities. action coordination-change actionchanges coordination constraints, discussed earlier. \wait" action puts transferring control making autonomous decision, without changing coordinationteam. agent reason \wait" best action when, time, situationlikely change put agent position improved autonomous decisiontransfer-of-control, without significant harm. example, E-Elves domain, timescloser meeting, users generally make accurate determinations whetherarrive time, hence sometimes useful wait meeting longtime off.transition probabilities (specified Table 2) represent effects actionsdistribution effects (i.e., ensuing state world). If, statetime = tk , agent chooses action transfers decision-making control entity,ei , agent itself, outcome state controlling-entity = eitime = tk+1 . two possible outcomes ei -response: either entity respondsdecision transition (producing terminal state), not,derive probability distribution two P. \wait" action similarbranch, except controlling-entity remains unchanged. Finally, action occursinstantaneously, time controlling entity respond, resultingstate effectively moves earlier time (e.g., tk tk Dvalue ).derive reward function MDP straightforward fashionstrategy model. Table 3 presents complete specification reward function.transitions take time, i.e., transferring control receiving response(Table 3, row 1) \wait" (Table 3, row 2), agent incurs wait cost interval.transitions agent performs D, agent incurs cost action (Table 3,row 3). terminal states response ei , agent derives expected qualityentity's decision (Table 3, row 4). policy maximizes reward agentexpects receive according AA MDP model correspond exactly optimal191fiScerri, Pynadath & Tambecontrolling-entity time ei -response ActionejtkeieitkwaiteitkeitkyesRewardW (k + 1) W (k)W (k + 1) W (k)DcostEQdei (tk )Table 3: Reward function AA MDP.transfer-of-control strategy. Note reward function described abstractfashion|for example, specify compute agent's expected qualitydecision, EQAd (t).4.2 MDP Representation AA Problem within Team Contextgiven high-level description MDP implementing notiontransfer-of-control strategies AA. remainder section provides detailedlook MDP broad class AA domains (including E-Elves) agentacts behalf user filling role, , within context team activity, ff.reward function compares EU different strategies, finding optimal onecurrent state. facilitate calculation, need represent parameters usedmodel. introduce following state features capture aspects AAproblem team context:team-orig-expect- team originally expected fulfilling .team-expect- team's current expectations fulfilling role implies.agent-expect- agent's (probabilistic) estimation fulfilled.\other ff attributes" encapsulate aspects joint activity affecteddecision.add specific features generic AA state features alreadypresented, overall state, within MDP representation decision d, tuple:hcontrolling-entity; team-orig-expect-; team-expect-; agent-expect-; ff-status;ei -response; time; ff attributesiexample, meeting scenario, team-orig-expect- could \Meet 3pm", teamexpect- could \Meet 3:15pm" user requested delay, agent-expect- could\Meet 3:30pm" agent believes user make rescheduled meeting.transition probability function AA MDP team context includesunderlying AA transition probabilities Table 3, must also include probabilitiesnew state features. particular, addition temporal effectaction described Section 4.1, additional effect coordination ff.action changes value team-expect- feature (in domain-dependent192fiTowards Adjustable Autonomy Real Worlddeterministic way). actions affect team's expectations. team-orig-expect-feature change; include simplify definition reward function.transition probabilities agent-expect- ff-specific features domain-specific.provide example transition probabilities Section 4.3.final part MDP representation reward function. team AA MDPframework uses reward function breaks function Table 3 follows:R(s; a) = f (team-orig-expect-(s); team-expect- (s); agent-expect- (s);ff-status (s); time(s); a)X=EQde (time(s)) e -response(9)e 2E nfAg1 f1 (k team-orig-expect- (s) team-expect- (s) k)21 f21 (time(s))22 f22 (k team-expect-(s) agent-expect-(s) k)+3 f3 (ff-status (s)) + 4 f4 (a)(10)first component reward function captures value getting responsedecision-making entity agent itself. Notice one entity actuallyrespond, one e -response non-zero. corresponds EQed (t) functionused model bottom row Table 3. f1 function ects inherentvalue performing role team originally expected, hence deterring agenttaking costly coordination changes unless gain indirect valueso. corresponds Dcost mathematical model third row Table 3.f21 corresponds second row Table 3, represents wait cost function,W (t), model. component encourages agent keep team membersinformed role's status (e.g., making decision taking explicit action),rather causing wait without information. Functions f22 f3 representquality agent's decision, represented QAd (t). standard MDP algorithmscompute expectation agent's reward, expectation qualityproduce desired EQAd (t) fourth row Table 3. first quality function, f22 ,ects value keeping team's understanding role performedaccordance agent expects user actually perform role. agentreceives reward role performed exactly team expects,uncertainty agent's expectation, errors possible. f22 represents costscome errors. second quality component, f3 , uences overall reward basedsuccessful completion joint activity, encourages agent take actionsmaximize likelihood joint activity succeeds. desire jointtask succeed implicit mathematical model must explicitly representedMDP. component, f4 , augments first row Table 3 account additionalcosts transfer-of-control actions. particular, f4 broken follows:(f4 (a) =q(e ) 2 E0otherwise193(11)fiScerri, Pynadath & Tambefunction q(e ) represents cost transferring control particular entity, e.g.,cost WAP phone message user. Notice, detailed, domain-specific costsappear directly model.Given MDP's state space, actions, transition probabilities, reward function,agent use value iteration generate policy P : ! specifies optimalaction state (Puterman, 1994). agent executes policy takingaction policy dictates every state finds itself. policymay include several transfers control coordination-change actions. particularseries actions depends activities user. interpret policycontingent combination many transfer-of-control strategies, strategy followchosen depending user's status (i.e., agent-expect-).4.3 Example: E-Elves MDPsexample AA MDP generic delay MDP, instantiatedmeeting Friday may act behalf user. Recall decision, d, whetherlet meeting attendees wait user begin meeting. joint activity,ff, meeting agent role, , ensuring user attendsmeeting scheduled time. coordination constraints, , attendeesarrive meeting location simultaneously effect action delaycancel meeting.delay MDP's state representation, team-orig-expect- originally-scheduledmeeting-time, since attendance originally scheduled meeting time teamoriginally expects user best possible outcome. team-expect- timerelative-to-meeting, may increase meeting delayed. ff-status becomes statusof-meeting. agent-expect- represented explicitly; instead, user-location usedobservable heuristic user likely attend meeting. example,user away department shortly meeting begin unlikelyattending time, all. state features, total state space contains2800 states individual meeting, large number states arisingfine-grained discretization time.general reward function mapped delay MDP reward function following way.(g(N; ff) N < 4(12)1otherwiseN number times meeting rescheduled g function takesaccount factors like number meeting attendees, size meeting delaytime originally scheduled meeting time. function effectively forbidsagent ever performing 4 actions.delay MDP, functions, f21 f22 , correspond cost makingmeeting attendees wait, merge single function, f2 . expectconsolidation possible similar domains team's expectations relatef1 =194fiTowards Adjustable Autonomy Real Worldtemporal aspect role performance.(f2 =h(late; ff) late > 00otherwise(13)late difference scheduled meeting time time userarrives meeting room. late probabilistically calculated MDP baseduser's current location model user's behavior.8><rff + ruser user attendsf3 = > rffmeeting takes place, user attend: 0otherwise(14)value, rff , models inherent value ff, value ruser models user'sindividual value ff.f4 given previously Equation 11. cost communicating userdepends medium used communicate. example, higher costcommunicating via WAP phone via workstation dialog box.users asked input, assumed that, respond, response\correct", i.e., user says delay meeting 15 minutes, assumeuser arrive time re-scheduled meeting. user asked fronthis/her workstation, dialog like one shown Figure 5 popped up, allowing userselect action taken. expected quality agent's decision calculatedconsidering agent's proposed decision possible outcomes decision.example, agent proposes delaying meeting 15 minutes, calculationdecision quality includes probability benefits user actually arrive15 minutes originally scheduled meeting time, probability costsuser arrives originally scheduled meeting time, etc.(a)(b)Figure 5: (a) Dialog box delaying meetings. (b) small portion delay MDP.delay MDP also represents probabilities change user location (e.g.,oce meeting location) occur given time interval. Figure 5(b) shows portion195fiScerri, Pynadath & Tambestate space, showing user-response, user location features. transitionlabeled \delay n" corresponds action \delay n minutes". figure also showsmultiple transitions due \ask" (i.e., transfer control user) \wait" actions,relative probability outcome represented thickness arrow.state transitions correspond uncertainty associated user's response (e.g.,agent performs \ask" action, user may respond specific information mayrespond all, leaving agent effectively \wait"). One possible policy produceddelay MDP, subclass meetings, specifies \ask" state S0 Figure 5(b)(i.e., agent gives autonomy). world reaches state S3, policy specifies\wait". However, agent reaches state S5, policy chooses \delay 15",agent executes autonomously. terms strategies, sequence actionsH D.Earlier, described another AA decision E-Elves, namely whether closeauction open team role. Here, brie describe key aspects mappingdecision MDP. auction must closed time user preparemeeting, sucient time given interested users submit bidshuman team leader choose particular user. team-orig-expect- (s) highquality presenter selected enough time prepare. action, henceteam-expect- (s) = team-orig-expect- (s). agent-expect-(s) whether agent believeshigh-quality bid believes bid arrive time user allocatedrole. agent's decision quality, EQdA (t), function number bidssubmitted quality bids, e.g., team members submittedbids one user's bid stands out, agent confidently choose userpresentation. Thus, ff-status primarily quality best bid far differencequality bid second-best bid. critical componentreward function Equation 10 2 component, gives reward agentfulfills users' expectation willing presenter high-quality presentation.4.4 User-Specified Constraintsstandard MDP algorithms provide agent optimal policies subject encoded probabilities reward function. Thus, agent designer access correctmodels entities' (e.g., human users E-Elves) decision qualities probabilities response, agent select best possible transfer-of-control strategy.However, possible entities accurate informationabilities agent designer. exploit knowledge, entity couldcommunicate model quality decision probability response directlyagent designer. Unfortunately, typical entity unlikely able expressknowledge form MDP reward function transition probabilities. agentcould potentially learn additional knowledge interactionsentities domain. However, learning may require arbitrarily large numberinteractions, take place without benefit entities' insideknowledge.alternative, provide language constraints allows entitiesdirectly immediately communicate inside information agent. constraint196fiTowards Adjustable Autonomy Real WorldFigure 6: Screenshot tool entering constraints. constraint displayed forbidstransferring control (i.e., forces transfer) five minutes meetingteammates previously given information user's attendancemeeting.language provides entities simple way inform agent specific propertiesneeds. entity use constraint forbid agent entering specific statesperforming specific actions specific states. constraints directly communicateduser via tool shown Figure 6. instance, figure shown userforbidding agent autonomous action five minutes meeting. defineforbidden-action constraints set, Cfa , element constraintboolean function, cfa : !ft; f g. Similarly, define forbidden-state constraintsset, Cfs , elements, cfs : !ft; f g. constraint returns particular domainelement (either state state-action pair, appropriate), constraint appliesgiven element. example, forbidden-action constraint, cfa , forbids actionperformed state cfa (s; a) = t.provide probabilistic semantics, suitable MDP context, first providenotation. Denote probability agent ever arrive state sf followingjP ). Then, define semanticspolicy, P , initial state si Pr(si !fjP ) = 0. semantics givenforbidden-state constraint cfs requiring Pr(si !f^P (s )=ajP ) = 0forbidden-action constraint, cfa , bit complex, requiring Pr(si!ff(i.e., cfa forbids agent entering state sf performing action a).cases, aggregation constraints may forbid actions state sf . case,conjunction allows agent still satisfy forbidden-action constraints avoiding sf(i.e., state sf becomes forbidden). state, sf , becomes indirectly forbiddenfashion, action potentially leads agent ancestor statesf likewise becomes forbidden. Hence, effect forbidding constraints propagatebackward state space, affecting state/action pairs beyond causeimmediate violations.197fiScerri, Pynadath & Tambeforbidding constraints powerful enough entity communicate widerange knowledge decision quality probability response agent.instance, E-Elves users forbidden agents rescheduling meetingslunch time. so, users provide feature specification states wantforbid, meeting-time =12 PM. specification generates forbidden-stateconstraint, cfs , true state, s, meeting-time =12 PM s. constrainteffectively forbids agent performing action would result statemeeting-time =12PM. Similarly, users forbidden autonomous actions certainstates providing specification actions want forbid, e.g., action 6=\ask".generates forbidden-action constraint, cfa , true state/action pair,(s; a), 6=\ask". example, user might specify constraint statesoce, time meeting knowalways make decisions case. Users easily create complicated constraintsspecifying values multiple features, well using comparison functions= (e.g., 6=, >).Analogous forbidding constraints, also introduce required-state requiredaction constraints, defined sets, Crs Cra , respectively. interpretation providedrequired-state constraint symmetric, opposite forbidden-statejP ) = 1. Thus, state, agent must eventually reachconstraint: Pr(si !f^P (s )=ajP ) = 1.required state, sf . Similarly, required-action constraint, Pr(si!ffusers specify constraints forbidding counterparts (i.e., specifying values relevant state features action, appropriate). addition,requiring constraints also propagate backward. Informally, forbidden constraints focuslocally specific states actions, required constraints express global propertiesstates.resulting language allows agent exploit synergistic interactionsinitial model transfer-of-control strategies entity-specified constraints. example,forbidden-action constraint prevents agent taking autonomous actionparticular state equivalent user specifying agent must transfer controluser state. AA terms, user instructs agent consider transferof-control strategies violate constraint. exploit pruning strategyspace user, extended standard value iteration also consider constraintsatisfaction generating optimal strategies. Appendix II provides descriptionnovel algorithm finds optimal policies respecting user constraints. appendixalso includes proof algorithm's correctness.5. Experimental Resultssection presents experimental results aimed validating claims made previous sections. particular, experiments aim show utility complex transfer-ofcontrol strategies effectiveness MDPs technique operationalization.Section 5.1 details use E-Elves daily activities Section 5.2 discussespros cons living working assistance Fridays. Section 5.3 showscharacteristics strategies type domain (in particular, different strategies198fiTowards Adjustable Autonomy Real Worldused practice). Finally, Section 5.4 describes detailed experiments illustratecharacteristics AA MDP.5.1 E-Elves Daily UseE-Elves system heavily used ten users research group ISI, June2000 December 2000.5 Friday agents ran continuously, around clock, sevendays week. exact number agents running varied period execution,usually five ten Friday agents individual users, capability matcher (with proxy),interest matcher (with proxy). Occasionally, temporary Friday agents operatedbehalf special guests short-term visitors.Daily Counts Exchanged MessagesNo. Messages300250200150100500Jun Jul Aug Sep Oct Nov DecDateFigure 7: Number daily coordination messages exchanged proxies seven-monthperiod.Figure 7 plots number daily messages exchanged Fridays seven months(June December, 2000). size daily counts ects large amountcoordination necessary manage various activities, high variability illustratesdynamic nature domain (note low periods vacations final exams).Figure 8(a) illustrates number meetings monitored user. sevenmonths, nearly 700 meetings monitored. users fewer 20 meetings,others 250. users 50% meetings delayed (this includesregularly scheduled meetings cancelled, instance due travel). Figure 8(b)shows usually 50% delayed meetings autonomously delayed.graph, repeated delays single meeting counted once. graphs show5. user base system greatly reduced period due personnel relocationsstudent graduations, remains use smaller number users.199fiUser Delays vs. Autonomous DelaysMeetings Monitored vs. Meetings Delayed400350300250200150100500140Number MeetingsitoramanantambenairscerrimodipynadathjunghTotal DelaysHuman Delays120MonitoredDelayedkulkarniNumber MeetingsScerri, Pynadath & Tambe1008060402001Users2345678Users(a)(b)Figure 8: (a) Monitored vs. delayed meetings per user. (b) Meetings delayed autonomouslyvs. hand.agents acting autonomously large number instances, but, equally importantly,humans also often intervening, indicating critical importance adjustable autonomyFriday agents.seven-month period, presenter USC/ISI's TEAMCORE research grouppresentations decided using auctions. Table 4 shows summary auction results.Column 1 (\Date") shows dates research presentations. Column 2 (\No.Bids") shows total number bids received decision. key featureauction decisions made without 9 users entering bids; fact, one case,4 bids received. Column 3 (\Best bid") shows winning bid. winner typicallybid < 1; 1 >, i.e., indicating user represents capable willingpresentation | high-quality bid. Interestingly, winner July 27 madebid < 0; 1 >, i.e., capable willing. team able settle winnerdespite bid highest possible, illustrating exibility. Finally, columns4 (\Winner") 5 (\Method") show auction outcome. `H' column 5 indicatesauction decided human, `A' indicates decided autonomously. fiveseven auctions, user automatically selected presenter. two manualassignments due exceptional circumstances group (e.g., first-time visitor),illustrating need AA.DateNo. bids Best bid Winner MethodJul 6, 200171,1ScerriHJul 20, 200191,1ScerriJul 27, 200170,1KulkarniAug 3, 200181,1NairAug 3, 200141,1TambeSept 19, 20016-,VisitorHOct 31, 200171,1TambeTable 4: Results auctioning research presentation slot.200fiTowards Adjustable Autonomy Real World5.2 Evaluating Pros Cons E-Elves Usegeneral effectiveness E-Elves shown several observations.E-Elves' operation, group members exchanged email messages announcemeeting delays. Instead, Fridays autonomously informed users delays, thus reducingoverhead waiting delayed members. Second, overhead sending emails recruitannounce presenter research meetings assumed agent-run auctions. Third,web page, Friday agents post users' location, commonly used avoidoverhead trying track users manually. Fourth, mobile devices kept usersinformed remotely changes schedules, also enabling remotely delaymeetings, volunteer presentations, order meals, etc. Users began relying Fridayheavily order lunch one local \Subway" restaurant owner even suggested: \. . .computers getting order food. . . might think marketingthem!!". Notice daily use E-Elves number different users occurredMDP implementation AA replaced unreliable C4.5 implementation.However, agents ensured users spent less time daily coordination (andmiscoordination), price paid. One issue users feltless privacy location continually posted web monitoredagent. Another issue security private information credit card numbersused ordering lunch. users adjusted agents monitor daily activities,users adjusted behavior around agent. One examplebehavior users preferring minute two early meeting lestagent decide late delay meeting. general, since agents never madecatastrophically bad decisions users felt comfortable using agent frequentlytook advantage services.emphatic evidence success MDP approach that, since replacingC4.5 implementation, agents never repeated catastrophic mistakesenumerated Section 2.2. particular, Friday avoids errors error 3 Section2.2 selecting strategy single, large action, higher EUstrategy many small Ds (e.g., DDDD). Friday avoids error 1, large costassociated erroneous cancel action significantly penalizes EU cancellation.Friday instead chooses higher-EU strategy first transfers control usertaking action autonomously. Friday avoids errors errors 2 4 selectingstrategies situation-sensitive manner. instance, agent's decision-makingquality low (i.e., high risk), agent perform coordination-change actionallow time user response agent get information.words, exibly uses strategies like e DeA, rather always using e (5)A strategydiscussed Section 2.2. indicates reasonably appropriate strategy chosensituation. Although current agents occasionally make mistakes, errorstypically order transferring control user minutes earlier maynecessary. Thus, agents' decisions reasonable, though always optimal.66. inherent subjectivity user feedback makes determination optimality dicult.201fiScerri, Pynadath & Tambe5.3 Strategy Evaluationprevious section looked application MDP approach E-Elvesaddress strategies particular. section, specifically examine strategiesE-Elves. show Fridays indeed follow strategies strategies followedones predicted model. also show model led insight that,turn, led dramatic simplification one part implementation. Finally, showuse strategies limited E-Elves application showing empiricallythat, random configurations entities, optimal strategy onetransfer-of-control action 70% cases.Figure 9 shows frequency distribution number actions taken per meeting(this graph omits \wait" actions). number actions taken meeting correspondslength part strategy followed (the strategy may longer,decision made actions taken). graph shows MDPfollowed complex strategies real world followed different strategiesdifferent times. graph bears model's predictions different strategies wouldrequired good solution AA problem E-Elves domain.Table 5 shows EU values computed model strategy selectedMDP. Recall MDP explicitly models users' movements locations,model assumes users move. Hence, order accuratecomparison model MDP's results, focus casesuser's location change (i.e., probability response constant).EU values calculated using parameter values set Section 3.3. Notice,MDP often perform Ds transferring control buy time reduceuncertainty. model abstraction domain, actions, like changesuser location, captured. Except slight discrepancy first casematch MDP's behavior model's predictions exact, providedignore actions beginning MDP strategies. Thus, despite modelconsiderably abstracted domain high correlation MDPpolicies model's suggested strategies. Moreover, general properties policiespredicted model borne exactly. particular, recall modelpredicted different strategies would required, strategy e would used,generally strategies ending would best | properties MDP policies.model predicts parameters vary greatly sucient findsingle optimal strategy follow strategy situation. MDPdecision close auction instance E-Elves. patternbehavior followed every time open role needs filled team. consistencyarises wait cost (since meetings same)pattern incoming bids reasonably consistent (variations individuals' behaviorcancel look team whole). model predictsparameters change, find optimal strategy parametersexecute strategy every time. However, since MDP worked effectivelymeeting AA, MDP also chosen implementing auction AA.realized parameters vary greatly, concluded MDP could replacedsimple implementation optimal strategy. verify hypothesis, replaced202fiTowards Adjustable Autonomy Real WorldNo. meetingsNo. actions per meeting20018016014012010080604020002468No. actions1012Figure 9: frequency distribution number steps taken AA strategymeeting scenario. actions taken meeting, meetingcancelled Friday started AA reasoning.LocationeeA e DA MDPSmall meeting, active participantoce14.8 -277 41.9 42.05 DDe DA@ dept. 14.8 -6E7 31.4 28.0 DDeA@ meet loc. 14.8 -2E5 39.2 39.1eALarge meeting, passive participantoce14.6 -7E12 30.74 30.65 DDeA@ dept. 14.6 -2E17 14.6 7.7DDeA@ meet loc. 14.5 -7E14 25.1 23.5eATable 5: EU values simple strategies calculated model. last columnshows strategy actually followed MDP.203fiScerri, Pynadath & TambeDate No. Bids MDP eA7/20/00925% 26%7/27/00714% 20%8/3/00829% 23%Table 6: Auction results. \MDP" column shows percentage available auctiontime remaining MDP chose close auction. \eA" columnshows percentage available auction time remaining strategy eA,EQde (t) proportional number bids received (\No. Bids" column),would closed auction.general MDP code three simple lines code implementing eA strategy,determined optimal particular parameters problem. Using log filesrecorded actual auctions reported (Scerri, Pynadath, & Tambe, 2001),experimentally verified MDP eA strategy produced result.Table 6 shows percentage available auction time remaining (e.g., auctionopened four days role performed, closing auction one daywould correspond 25%) MDP version eA version code closedauction. number bids used estimate agent's expected decision quality.timing auction closing close, certainly within hours. resultprecisely MDP strategy implementations, MDPimplementation reactive incoming bids strategy implementation.confirm need strategies phenomenon unique particularsettings E-Elves, experiment run randomly generated configurationsentities. wait cost configuration increased exponentially, rateaccrual varying configuration configuration. configurations contained3 25 entities, randomly chosen Markovian response probabilities randomlychosen, constant, decision-making quality. cost value action alsorandomly selected. configuration, agent could respond instantly,lower decision quality entities. configuration,optimal transfer-of-control strategy found. Figure 10(a) shows percentage optimalstrategies (z-axis) length (y-axis \jOpt. Strat.j"), separated accordingrate wait costs accrued (x-axis, \Wait Cost Param"). figure showsrate wait cost accrues low, optimal strategies lengthone, agent handing control entity highest decision-makingquality. rate wait cost accrual high, strategies length two,agent brie giving best decision maker opportunity make decisiontaking back control acting wait costs became high. intermediatevalues wait cost parameter, considerably variation lengthoptimal strategy. Figure 10(b) shows percentage optimal strategies lengthwait cost parameter 0.12 (i.e., slice Figure 10(a)). Hence, strategiesoften contained several transfers control several coordination changes. Thus,experiment shows complex transfer-of-control strategies useful, E-Elves,204fiTowards Adjustable Autonomy Real Worldrange domains, especially wait costs neither negligibleaccruing fast.Strategy Lengths w = 0.1235% Opt. Strats.3025% Opt. Strats.1009080706050403020100122015103|Opt. Strat.|45678 00.35 0.40.25 0.30.15 0.20.1WaitCostParam0.05501(a)2345|Opt. Strat.|678(b)Figure 10: (a) Percentage optimal strategies certain length, broken according fast wait costs accruing. (b) Percentage optimal strategiescertain length wait cost parameter = 0.12.Thus, shown MDP produces strategies Friday followsstrategies practice. Moreover, strategies followed ones predicted model.practical use, followed prediction model, i.e., MDPrequired auctions, able substantially reduce complexity one partsystem. Finally, showed need strategies specifically phenomenonE-Elves domain.5.4 MDP ExperimentsExperience using MDP approach AA E-Elves indicates effectivemaking reasonable AA decisions. However, order determine whether MDPsgenerally useful tool AA reasoning, systematic experiments required.section, present systematic experiments determine important propertiesMDPs AA. MDP reward function designed result optimal strategyfollowed state.experiments, vary one parameters weightsdifferent factors Equation 10. MDP instantiated range valuesparameter policy produced value. case, total policydefined 2800 states. policy analyzed determine basic propertiespolicy. particular, counted number states policy specifies ask,delay, say user attending say user attending. statisticsshow broadly policy changes parameters change, e.g., whether Friday givesautonomy less cost coordination change increased. firstaim experiments simply confirm policies change desired expectedway parameters reward function changed. instance, Friday's expecteddecision quality increased, states makes autonomous205fiScerri, Pynadath & Tambedecision. Secondly, practical perspective critical understand sensitiveMDP policies small variations parameters, sensitivity would meansmall variations parameter values significantly impact MDP performance.Finally, experiments reveal interesting phenomena.first experiment looks effect 1 parameter Equation 10, represented delay MDP implementation team repair cost (function g Equation12), policies produced delay MDP. parameter determines averse Friday changing coordination constraints. Figure 11 shows propertiespolicy change team repair cost value varied. x-axis gives valueteam repair cost, y-axis gives number times action appearspolicy. Figure 11(a) shows number times Friday ask user input.number times transfer control exhibits interesting phenomenon: numberasks maximum intermediate value parameter. low values,Friday \confidently" (i.e., decision quality high) make decisions autonomously,since cost errors low, hence less value relinquishing autonomy.high team repair costs, Friday \confidently" decide autonomously makecoordination change. intermediate region Friday uncertain needscall user's decision making often. Furthermore, cost delayingmeeting increases, Friday delay meeting less (Figure 11(b)) tell teamuser attending often (Figure 11(d)). so, Friday gives user less timearrive meeting, choosing instead announce user attending.Essentially, Friday's decision quality become close enough user's decision qualityasking user worth risk respond cost askinginput. Except jump value zero non-zero value,number times Friday says user attending change (Figure 11(c)).delay MDP use E-Elves team repair cost parameter set two. Aroundvalue policy changes little, hence slight changes parameter leadlarge changes policy.second experiment, vary 2 parameter Equation 10, implementeddelay MDP variable team wait cost (function h Equation 13).factor determines heavily Friday weigh differencesteam expects user fulfill role user actually fulfill role.particular, determines cost team members wait meeting roomuser. Figure 12 shows changes policy parameter varied (againx-axis shows value parameter y-axis shows number timesaction appears policy). graph number times agent askspolicy (Figure 12(a)), exhibits phenomena 1 parameter varied,i.e., increasing decreasing parameter increases. graphs show that,cost teammates' time increases, Friday acts autonomously often (Figure 12(bd)). Friday asks whenever potential costs asking lower potential costserrors makes { cost time waiting user decision increases, balancetips towards acting. Notice phenomenon number asks increasingdecreasing occurs way 1 parameter; however, occursslightly different reason. case, waiting costs low, Friday's decision-makingquality high acts autonomously. waiting costs high, Friday cannot206fiTowards Adjustable Autonomy Real WorldNumber delays policy6866646260585654525048# delays# asksNumber asks policy02468"Team repair cost" weight14013012011010090807060504030100(a)Number Attending messages policy# Attending# attending14013513012512011511010510095902468"Team repair cost" weight10(b)Number Attending messages policy02468"Team repair cost" weight107060504030201000(c)2468"Team repair cost" weight(d)Figure 11: Properties MDP policy team repair cost varied.20710fiScerri, Pynadath & Tambeafford risk user respond quickly, acts autonomously (despitedecision quality low). Figure 12(b) shows number delay actions takenFriday increases, states meeting already delayed twice.indicates normally expensive third delay meeting startsbecome worthwhile cost teammates wait meeting room high.delay MDP, value 1 used 2 . decision transfer control (i.e., ask)particularly sensitive changes parameter around value|again, slightchanges significant impact.Number Asks policyNumber Delays policy70# delays# asks5040301008060402002002468100"Cost teammates time" weight46810(b)Number Attending messages policy30# AttendingNumber Attending messages policy2602402202001801601401201008002"Cost teammates time" weight(a)# AttendingTotal1st Delay2nd Delay3rd Delay12060246810"Cost teammates time" weight25201510500(c)246810"Cost teammates time" weight(d)Figure 12: Properties MDP policy teammate time cost varied. (b) showsnumber times meeting delayed states yetdelayed, delayed already, delayedtwice already.third experiment, value 3 , weight joint task, varied(Figure 13). E-Elves, value joint task includes value usermeeting value meeting without user. experiment, value208fiTowards Adjustable Autonomy Real Worldmeeting without user varied. Figure 13 shows policy changes valuemeeting without user changes (again x-axis shows value parametery-axis shows number times action appears policy). graphsshow significantly instability values. large changesresult simultaneous change utility taking key actions expectedquality Friday's decision making, e.g., utility saying user attending muchhigher meeting low value without user. current delay MDP,value set 0.25, part graph insensitive small changesparameter.three experiments above, specific E-Elves parameters regionsgraph small changes parameter lead significant changes policy.However, regions graphs policy change dramatically smallchanges parameter. indicates domains, parameters differentE-Elves, policies sensitive small changes parameters.180160140120100806040200-10Number delays policy120100# delays# asksNumber asks policy806040-8-6-4-20Joint activity weight20-102-8(a)Number Attending messages policy20# attending# attending180160140120-8-6-4-20Joint activity weight2(b)Number Attending messages policy200100-10-6-4-20Joint activity weight151050-102(c)-8-6-4-2Joint activity weight02(d)Figure 13: Properties MDP policy importance successful joint taskvaried.209fiScerri, Pynadath & Tambeexperiments show three important properties MDP approach AA.First, changing parameters reward function generally lead changespolicy expected desired. Second, value parameters uencedpolicy, effect AA reasoning often reasonably small, suggesting smallerrors model affect users greatly. Finally, interesting phenomenanumber asks reaching peak intermediate values parameters revealed.three previous experiments examined behavior MDP changesparameters reward function changed. another experiment, centraldomain-level parameter affecting behavior MDP, i.e., probability gettinguser response cost getting response (corresponding f4 ), varied. Figure14 shows number times Friday chooses ask (y-axis) variesexpected time get user response (x-axis) cost (each linegraph represents different cost). MDP performs expected, choosing askoften cost low and/or likely get prompt response. Noticethat, cost low enough, Friday sometimes choose ask user evenlong expected response time. Conversely, expected response time sucientlyhigh, Friday assume complete autonomy. graph also shows distinctchange number asks point (depending cost), outside changepoint graphs relatively at. key reason fairly rapid change numberasks often difference quality Friday's user's decisionmaking fairly small range. mean response time increases, expected waitcosts increase, eventually becoming high enough Friday decide act autonomouslyinstead asking.# AsksNumber Asks Policy7060504030201000.01Cost = 0.0001Cost = 0.2Cost = 1.00.1110Mean Response Time100Figure 14: Number ask actions policy mean response time (in minutes) varied.x-axis uses logarithmic scale.conclude section quantitative illustration impact constraintsstrategy selection. experiment, merged user-specified constraintsE-Elves users, resulting set 10 distinct constraints. started unconstrained210fiTowards Adjustable Autonomy Real WorldFigure 15: (a) Number possible strategies (logarithmic). (b) Time required strategygeneration.instance delay MDP added constraints one time, counting strategiessatisfied applied constraints. repeated experiments expandedinstances delay MDP, increased initial state space increasingfrequency decisions (i.e., adding values time-relative-to-meeting feature).expansion results three new delay MDPs, artificial, uencedreal delay MDP. Figure 15a displays results (on logarithmic scale), linecorresponds original delay MDP (2760 states), lines B (3320 states), C (3880states), (4400 states) correspond expanded instances. data pointmean five different orderings constraint addition. four MDPs, constraintssubstantially reduce space possible agent behaviors. instance, originaldelay MDP, applying 10 constraints eliminated 1180 2760 original statesconsideration, reduced mean number viable actions per acceptable state3.289 2.476. end result 50% reduction size (log10 ) strategy space.hand, constraints alone provide complete strategy, sinceplots stay well 0, even 10 constraints. Since none individual usersable/willing provide 10 constraints, cannot expect anyone add enough constraintscompletely specify entire strategy. Thus, MDP representation associatedpolicy selection algorithms still far redundant.constraints' elimination behaviors also decreases time required strategyselection. Figure 15b plots total time constraint propagation value iterationfour MDPs Figure 15a (averaged five constraint orderings).data point also mean five separate iterations, total 25 iterationsper data point. values zero-constraint case correspond standard value iteration without constraints. savings value iteration restricted strategy spacedramatically outweigh cost pre-propagating additional constraints. addition,savings increase size MDP. original delay MDP (A),28% reduction policy-generation time, largest MDP (D), 53%reduction. Thus, introduction constraints provide dramatic accelerationagent's strategy selection.211fiScerri, Pynadath & Tambe6.Related Workdiscussed related work Section 1. section adds discussion.Section 6.1, examine two representative AA systems { detailed experimentalresults presented { explain results via model. illustratespotential applicability model systems. Section 6.2, examine AAsystems areas related work, meta-reasoning, conditional planninganytime algorithms.6.1 Analyzing AA Work Using Strategy ModelGoodrich, Olsen, Crandall, Palmer (2001) report tele-operated teams robots,user's high-level reasoning robots' low-level skills requiredachieve task. Within domain, examined effect user neglectrobot performance. idea user neglect similar idea entities taking timemake decisions; case, user \neglects" robot, joint task takes longerperform. domain, coordination constraint user input must arriverobot work low-level actions needs perform. Four control systemstested robot, giving different amount autonomy robot,performance measured user neglect varied.Although quite distinct E-Elves system, mapping Goodrich's team robotsAA problem formulation provides interesting insights. systeminteresting feature entity robot call decision, i.e., user, alsopart team. Changing autonomy robot effectively changes naturecoordination constraints user robot. Figure 16 shows performance(y-axis) four control policies amount user neglect increased (x-axis).experiments showed higher robot autonomy allowed operator \neglect"robot without serious impact performance.notion transfer-of-control strategies used qualitatively predictbehavior observed practice, even though Goodrich et al. (2001) usenotion strategies. lowest autonomy control policy used Goodrich et al. (2001)pure tele-operation one. Since robot cannot resort decision making,represent control policy strategy U , i.e., control indefinitely handsuser. second control policy allows user specify waypoints on-boardintelligence works details getting waypoints. Since robot highlevel decision-making ability, strategy simply give control user. However,since coordination robot user abstract, i.e., coordinationconstraints looser, wait cost function less severe. Also human giving lessdetailed guidance fully tele-operated case (which good according(Goodrich et al., 2001)), hence use lower value expected quality userdecision. denote approach Uw p distinguish fully tele-operated case.next control policy allows robot choose waypoints given userinputs regions interest. robot also accept waypoints user. abilityrobot calculate waypoints modeled D, since effectively changescoordination entities, removing user's need give waypoints. modelcontrol policy strategy U DU . final control policy full autonomy, i.e., A.212fiTowards Adjustable Autonomy Real WorldPerformanceUDUU wpUNeglect(a)Goodrich robot operation EU6040EU200-20-40-6021.5(b)1p0.50Figure 16: Goodrich al's various control strategies plotted neglect. (a) Experimental results. Thinner lines represent control systems intelligenceautonomy. (b) Results theoretically derived model strategies presented article (p parameter probability response function).Robot decision making inferior user, hence robot's decision quality lessuser's. graphs four strategies, plotted probability responseparameter (getting smaller right, match \neglect" Goodrich et al graph)shown Figure 16. Notice shape graph theoretically derived model,shown Figure 16(b), qualitatively shape experimentally derivedgraph, Figure 16(a). Hence, theory predicted qualitatively performancefound experimentation.common assumption earlier AA work entity askeddecision make decision promptly, hence strategies handling contingency213fiScerri, Pynadath & Tambelack response required. example, Horvitz's (1999) work usingdecision theory aimed developing general, theoretical models AA reasoninguser workstation. prototype system, called LookOut, helping users managecalendars implemented test ideas (Horvitz, 1999). Although systemsdistinctly different E-Elves, mapping problem formulation allows usanalyze utility approaches across range domains without implementapproach domains.critical difference Horvitz's work work LookOutaddress possibility receiving (timely) response. Thus, complex strategiesrequired. typical case LookOut, agent three options: takeaction, take action, engage dialog. central factor uencingdecision whether user particular goal action would aid, i.e., usergoal, action useful, he/she goal, actiondisruptive. Choosing act act corresponds pursuing strategy A.7 Choosingseek user input corresponds strategy U . Figure 17(a) shows graph differentoptions plotted probability user goal (corresponds Figure 6Horvitz (1999)). agent's expected decision quality, EQdA (t) derived Equation2 Horvitz (1999). (In words, Horvitz's model performs detailed calculationsexpected decision quality.) model predicts selection strategiesHorvitz does, i.e., choosing strategy EQdA (t) low, U otherwise (assumingtwo strategies available). However, model predicts somethingHorvitz consider, i.e., rate wait costs accrue becomesnon-negligible choice simple. Figure 17(b) shows EU twostrategies changes rate wait costs accruing increased. fact optimalstrategy varies wait cost suggests Horvitz's approach would immediatelyappropriate domain wait costs non-negligible, e.g., would needmodified many multi-agent settings.6.2 Approaches AASeveral different approaches taken core problem whethertransfer decision-making control. example, Hexmoor examines much time agentAA reasoning (Hexmoor, 2000). Similarly, Dynamic Adaptive Autonomyframework, group agents allocates votes amongst themselves, hence defining amountuence agent decision thus, definition, autonomyagent respect decision (Barber, Martin, & Mckay, 2000b). relatedapplication meeting scheduling Cesta, Collia, D'Aloisi (1998) taken approachproviding powerful tools users constrain monitor behavior proxyagents, agents explicitly reason relinquishing control user.least work done multiagent context, possibility multipletransfers control considered.Complementing work, researchers focused issues architecturesAA. instance, AA interface 3T architecture (Bonasso, Firby, Gat, Kortenkamp,7. consider choosing act autonomous decision, hence categorize way autonomous action214fiTowards Adjustable Autonomy Real WorldHorvitzs EU Calculations Wait Cost1EU0-1-200.20.40.60.8Probability User Goal1(a)Horvitzs EU Calculations Wait Cost0.4EU0.20-0.2-0.4-0.600.05 0.1 0.15 0.2 0.25 0.3(b)wFigure 17: EU different agent options. solid (darkest) line shows EU takingautonomous action, dashed (medium dark) line shows EU autonomously deciding act dotted line shows EU transferringcontrol user. (a) Plotted probability user goal,wait cost. (b) plotted wait cost, fixed probability user goal.Miller, & Slack, 1997) implemented solve human-machine interaction problemsexperienced number NASA projects (Brann, Thurman, & Mitchell, 1996).experiences showed interaction system required waydeliberative layer detailed control actuators. AA controls layersencapsulated referred 3T's fourth layer { interaction layer215fiScerri, Pynadath & Tambe(Schreckenghost, 1999). similar area AA technology required safety-criticalintelligent software, controlling nuclear power plants oil refineries (Musliner& Krebsbach, 1999). work resulted system called AEGIS (Abnormal EventGuidance Information System) combines human agent capabilities rapidreaction emergencies petro-chemical refining plant. AEGIS features shared taskrepresentation users intelligent system work (Goldman,Guerlain, Miller, & Musliner, 1997). key hypothesis work model needsmultiple levels abstraction user interact level see fit.Interesting work Fong, Thorpe, Baur (2002) extended idea tele-operatedrobotics re-defining relationship robot user collaborative one,rather traditional master-slave configuration. particular, robot treatshuman resource perform perceptual cognitive functions robotdetermines cannot adequately perform. However, yet work lookedpossibility user available provide input required, would requirerobot perform complex transfer-of-control reasoning.previous work AA ignored complex strategies AA, workresearch fields potentially relevant. example, research issues addressed fields mixed-initiative decision-making (Collins, Bilot, Gini, & Mobasher,2000b), anytime algorithms (Zilberstein, 1996), multi-processor scheduling (Stankovic, Ramamritham, & Cheng, 1985), meta-reasoning (Russell & Wefald, 1989), game theory (Fudenberg & Tirole, 1991), contingency plans (Draper, Hanks, & Weld, 1994; Peot &Smith, 1992) have, least superficial, similarities AA problem. However,turns core assumptions focus research areas differentenough algorithms developed related fields directly applicableAA problem.mixed-initiative decision making human user assumed continually available(Collins et al., 2000b; Ferguson & Allen, 1998), negating need reasoninglikelihood response. Furthermore, often little time pressure coordinationconstraints. Thus, basic problem transferring control humanagent common mixed-initiative decision making AA, assumptionsquite different leading distinct solutions. Likewise, related research fields makedistinctly different assumptions lead distinctly different solutions. instance,contingency planning (Draper et al., 1994; Peot & Smith, 1992) deals problemcreating plans deal critical developments environment. Strategies relatedcontingency planning plans deal specific contingencyentity making decision manner maintains coordination. However, contingency planning, key diculty creating plans. contrast, AA, creatingstrategies straightforward key diculty choosing strategies.contribution recognizing need strategies addressing AA problem, instantiating strategies via MDPs, development general, domain-independentreward function leads MDP choosing optimal strategy particular situation.Similarly, another related research area meta-reasoning (Russell & Wefald, 1989).Meta-reasoning work looks online reasoning computation. type meta-reasoning,closely related AA, chooses sequences computations different ex216fiTowards Adjustable Autonomy Real Worldpected quality running time, subject constraint choosing highest-qualitysequence computations possible (because takes long) (Russell & Wefald,1989). idea treat computations actions \meta-reason" EUcertain combinations computation (base-level) actions. output metareasoning sequence computations executed sequence. AA parallels metareasoning consider reasoning transferring control entities reasoningselecting computations, i.e., think entities computations. However, AA,aim one entity make high-quality decision, meta-reasoning, aimsequence computations high quality. Moreover, meta-reasoningassumption computations guaranteed return timely result executed,apply AA. Finally, meta-reasoning looks sequence computations usefixed amount time, AA reasons trading extra time better decision(possibly buying time action). Thus, algorithms developed meta-reasoningapplicable AA.Another research area conceptual similarity AA field anytime algorithms (Zilberstein, 1996). anytime algorithm quickly finds initial solutionincrementally tries improve solution stopped. AA problem similarassume agent make immediate decision, problemproperty solution always available (an important property anytimealgorithm). However, case general, i.e., agent alwaysanswer. Furthermore, anytime algorithms generally need deal multiple,distributed entities, opportunity change coordination (i.e., usingaction).Multi-processor scheduling looks assigning tasks nodes order meet certaintime constraints (Stankovic et al., 1985). entities thought \nodes", AAalso assigning tasks nodes. multiprocessor scheduling, qualitycomputation performed nodes usually assumed equal, i.e., nodeshomogeneous. Thus, reasoning trades quality time required,AA. Moreover, deadlines externally imposed multi-processor scheduling algorithms,rather exibly reasoned AA. Multi-processor scheduling algorithmssometimes deal node rejecting task cannot fulfill time constraintsnetwork failures. However, AA problem focuses failure get responsecentral issue load balancing auxiliary issue, multi-processor schedulingopposite focus. difference focus leads algorithms developedmultiprocessor scheduling community well suited AA (and vice versa).7.ConclusionsAdjustable autonomy critical success real-world agent systems allowsagent leverage skills, resources decision-making abilities entities,human agent. Previous work addressed AA context single-agentsingle-human scenarios, solutions scale increasingly complex multiagent systems. particular, previous work used rigid, one-shot transfers controlconsider team costs and, importantly, consider possibility costly217fiScerri, Pynadath & Tambemiscoordination team members. Indeed, applied rigid transfer-of-controlapproach multi-agent context, failed dramatically.article makes three key contributions enable application AAcomplex multiagent domains. First, article introduces notion transfer-of-controlstrategy. transfer-of-control strategy consists conditional sequence two typesactions: (i) actions transfer decision-making control (ii) actions changeagent's pre-specified coordination constraints team members, aimed minimizingmiscoordination costs. strategies allow agents plan sequences transfer-of-controlactions. Thus, strategy allows agent transfer control entities best able makedecisions, buy time decisions made still avoid miscoordination | evenentity control transferred fails make decision. Additionally,introduced idea changing coordination constraints mechanism givingagent opportunity provide high-quality decisions, showed changescan, cases, effective way increasing team's expected utility.second contribution article mathematical model AA strategiesallows us calculate expected utility strategies. model showscomplex strategies indeed better single-shot strategies situations,always superior. fact, analysis showed particular strategy dominateswhole space AA decisions; instead, different strategies optimal differentsituations.third contribution article operationalization notion transferof-control strategies via Markov Decision Processes general reward functionleads MDP find optimal strategies multiagent context. general, domainindependent reward function allow approach potentially appliedmulti-agent domains. implemented, applied, tested MDP approach AA reasoning real-world application supporting researchers daily activities. Daily useshowed MDP approach effective balancing need avoid risky autonomousdecisions potential costly miscoordination. Furthermore, detailed experimentsshowed policies produced MDPs desirable properties, transferring control user less often probability getting timely response low.Finally, practical experience system revealed users require ability manipulate AA reasoning agents. end, introduced constraint languageallows user limit range behavior MDP exhibit. presentedalgorithm processing constraints, showed desirable propertyreducing time takes find optimal policies.8.Future Workmodel AA presented article suciently rich model wide varietyinteresting applications. However, key factors modeledcurrent formulation required domains. One key issue allow agentfactor AA reasoning agents AA reasoning. instance,Elves domain, one agent likely decide delay meeting, another agent maywait decision avoid asking user. Conversely, agent takeback control decision knows another agent going continue waiting user input,218fiTowards Adjustable Autonomy Real Worldmight also continue wait input. interactions substantially increasecomplexity reasoning agent needs perform. article, assumedagent finding transfer-of-control strategy single, isolated decision.general, many decisions made agent ableignore interactions decisions. example, transferring control manydecisions user, reduces probability getting prompt response them.Reasoning interactions add complexity required reasoningagent.Another focus future work generalizing AA decision making allowtypes constraints | coordination constraints | taken account.would turn require generalization concept action include typesstop-gap actions may lead different types strategies agent could pursue.Additionally, transfer-of-control actions could generalized allow parts decisiontransferred, e.g., allow input received user without transferring totalcontrol him/her, allow actions could performed collaboratively. Similarly,actions reversible, agent could make decision allow user reverseit. hope generalizations would improve applicability adjustableautonomy research complex domains.Acknowledgmentsresearch supported DARPA award no. F30602-98-2-0108. effortmanaged Air Force Research Labs/Rome site. article unifies, generalizes, significantly extends approaches described previous conference papers (Scerri et al., 2001;Scerri, Pynadath, & Tambe, 2002; Pynadath & Tambe, 2001). thank colleagues,especially, Craig Knoblock, Yolanda Gil, Hans Chalupsky Tom Russ collaboratingElectric Elves project. would also like thank JAIR reviewersuseful comments.219fiScerri, Pynadath & TambeAppendix A: Example Instantiation ModelAppendix, present detailed look one possible instantiation AA model.use instantiation calculate EU commonly used strategies showEU varies parameters rate wait cost accrual timetransfers control performed. instantiation, agent, A, one entitycall decision (i.e., user U ), hence E = fA; U g. W (t), use followingfunction:(!tW (t) = !! expexp! otherwise(15)exponential wait cost function ects idea big delay much worsesmall one. polynomial similar function could also used exponentialused since makes mathematics cleaner. probability response use:P>(t) = exp . Markovian response probability ects entity likelyrespond next point time previous point. users moving around dynamic environment, turns reasonable approximation.entities' decision-making quality constant time, particular, EQdA (t) = ffEQdU (t) = fi . Assuming constant decision-making quality always accuratedynamic environment since information available entity may change (hence uencingability make decision) however, decisions involving static facts preferencesdecision-making quality relatively constant. functions coarse approximation range interesting applications, including E-Elves. Table 7 shows resultinginstantiated equations simple strategies (For convenience let = !). Figures18(a) (b) show graphically EU eA strategy varies along different axes (wparameter wait cost function, higher w means faster accruing wait costsp parameter response probability function, higher p means faster response).Notice EU depends transfer time (T) much fi (the user'sdecision quality). Figure 18(d) shows value (as discussed earlier).Figure 18(c) compares EU e DeA e strategies. complextransfer-of-control strategy (i.e., transfers control makes), atterEU graph plotted wait cost (w) response probability (p) parameters.particular, fall-off wait costs high probability response lowdramatic complex strategy.Appendix B: Constraint Propagation Algorithm CorrectnessSection 4.4, examined need user-specified constraints conjunctionMDP-based approach strategies. must thus extend standard MDP policyevaluation algorithms support evaluation strategies accountingstandard quantitative reward function new qualitative constraints. appendixprovides novel algorithm developed evaluate strategies accounting220fiTowards Adjustable Autonomy Real World54.543.53020151050-51.50.1w 0.20.30.51 p010(a)T203040(b)Value0.160.120.080.040-0.0450-50.1w 0.20.34201612beta80.41.20.8p0.1 0.2w0.3 0.4 0.5(c)10.750.5 p0.25(d)Figure 18: Equation 17, i.e., strategy eA plotted (a) ! (i.e., w, ratewait costs accrue) (i.e., p likelihood response) (b) (transfertime)and beta (the user's decision quality). (c) Comparing strategies e DeAe (dotted line e ). (d) value D.221fiScerri, Pynadath & TambeEUed = exp !(= ! expEUeA(1) + exp1)!+fi(fffi)(16)!+fi(17)EUedDeAt =(18)!value! (exp 1) + fi (1 exp ) + ! exp(exp exp ) +(Dcost fi )(exp exp ) + ! exp! (exp !Dvalue 1)(exp exp )exp (Dcost ff + !(exp! exp!( Dvalue ) + exp!(T Dvalue ) ))Table 7: Instantiated AA EU equations simple transfer control strategies.both. also present detailed proof algorithm's output correct strategy(i.e., strategy highest expected utility, subject user-specified constraints).standard MDP value iteration algorithm, value strategy particularstate single number, expected utility U . addition two typesconstraints, value tuple hF; N; U i. F represents strategy's ability satisfyforbidding constraints; therefore, boolean indicating whether state forbiddennot. N represents strategy's ability satisfy necessary constraints; therefore,set requiring constraints satisfied. traditional value iteration,U expected reward. instance, value state, V (s) = htrue; fcrs g; 0:3i,executing policy state achieve expected value 0.3 satisfyrequired-state constraint crs . However, guaranteed satisfy requiredstate, required-action, constraints. addition, forbidden, nonzeroprobability violating forbidden-action forbidden-state constraint. recordforbidding constraints policy violates, since violating one equallybad. record requiring constraints policy satisfies, since satisfyingconstraints preferable satisfying them. Therefore, sizevalue function grows linearly number requiring constraints, independentnumber forbidding constraints.Following form standard value iteration, initialize value functionstates considering immediate value strategy given state, withoutlookahead. precisely:V 0 (s)*_c2Cfs+c(s); fc 2 Crs jc(s)g ; RS (s)(19)Thus, state forbidden forbidden-state constraints immediately apply,satisfies required-state constraints immediately apply. standard valueiteration, expected utility value reward function state.222fiTowards Adjustable Autonomy Real Worldvalue iteration, must define updated value function V t+1 refinementprevious iteration's value function, V . States become forbidden V t+1violate constraints directly successors forbidden according V .States satisfy requirements satisfy directly successors satisfyrequirement. simplify following expressions, define 0 setsuccessors: fs0 2 jMssa 0 > 0g. following expression provides precise definitioniterative step:*___maxc(s) _c(s; a) _F 0;a2A c2C000c2Cfa V (s )=hF ;N ;U 0 i;s0 2S 0fs\fc 2 Crsjc(s)g [ fc 2 Cra jc(s; a)g [ N 0;V (s0 )=hF 0 ;N 0 ;U 0 i;s0 2S 0+XRS (s) + R(s; a) + Mssa 0 U 0(20)V (s0 )=hF 0 ;N 0 ;U 0 i;s0 2S 0standard value iteration, iterative step specifies maximization possible choices action. However, two additional components represent valuestrategy respect constraints, longer obvious comparisonfunction use evaluating candidate actions. Therefore, perform maximizationusing following preference ordering, x means preferable x:ht; N; Uf; N 0; U 0ff ffhF; N; UF; N 0 N; Uff0hF; N; U F; N; U 0 > UV t+1 (s)words, satisfying forbidden constraint takes highest priority, satisfyingrequiring constraints second, increasing expected value last. define optimalaction, P (s), action, a, final V (s) expression maximized.Despite various set operations Equation 20, time complexity iterationstep exceeds standard value iteration linear factor, namely numberconstraints, jCfs j + jCfa j + jCrsj + jCra j. eciency derives factconstraints satisfied/violated independently other. determination whethersingle constraint satisfied/violated requires time standard valueiteration, hence overall linear increase time complexity.expected value lowest priority, separate iterative stepEquation 20 two phases: constraint propagation value iteration.constraint-propagation phase, compute first two components value function, hF; N; i. value-iteration phase computes third component, h; ; U i,standard value iteration. However, ignore state/action pairs that, accordingresults constraint propagation, violate forbidding constraint (ht; N; i) requiring constraint (hf; N Crs [ Cra ; i). component-wise independenceEquation 20, two-phase algorithm computes identical value function original,single-phase version (over state/action pairs satisfy constraints).rest Appendix provide proof correctness modified valueiteration policy. Given policy, P , constructed according algorithm, must223fiScerri, Pynadath & Tambeshow agent following P obey constraints specified user. agentbegins state, 2 , must prove satisfy constraintsV (s) = hf; Cra [ Crs ; U i. prove results forbidding requiring constraintsseparately.Theorem 1 agent following policy, P , value function, V , generated Section 4.4, state 2 violate forbidding constraint probability zeroV (s) = hf; N; U (for U N ).Proof: prove theorem induction subspaces states, classified\close" violating forbidding constraint. precisely, partitionstate space, , subsets, Sk , defined contain states violate forbiddingconstraint minimum k state transitions. words, S0 contains statesviolate forbidding constraint directly; S1 contains states violateforbidding constraints themselves, successor state (following transitionprobability function, P ) (i.e., successor state S0 ); S2 contains statesviolate forbidding constraints, successors do,least one successor state successor state (i.e., successor stateS1 ); etc. jS j nonempty subsets mutually exclusive sequence.make partition exhaustive, special subset, S1 , contains statesagent never violate forbidding constraint following P . first show, inductionk, 8s 2 Sk (0 k jS j), V (s) = ht; N; U i, required theorem.Basis step (S0): definition, agent violate forbidding constraint 2 S0 .Therefore, either 9c 2 Cfs c(s) = 9c 2 Cfa c(s; P (s)) = t,know, Equation 20, V (s) = ht; N; U i.Inductive step (Sk ; 1 k jS j): Assume, induction hypothesis, 8s0 2Sk 1 , V (s0 ) = ht; N 0 ; U 0 i. definition Sk , state, 2 Sk , least onesuccessor state, s0 2 Sk 1 . Then, according Equation 20, V (s) = ht; N; U i,disjunction 0 must include s0 , F 0 = t.Therefore, induction, know 2 Sk (0 k jS j), V (s) = ht; N; U i.show 8s 2 S1 , V (s) = hf; N; U i. prove, induction t, that,state, 2 S1, V (s) = hf; N; U i.Basis step (V 0 ): definition, 2S1 , thereff cannot exist c 2 Cfsc(s) = t. Then, Equation 19, V 0 (s) = f; N 0 ; U 0 .Inductive step (V ; > 0): Assume,inductivehypothesis, that, s0 2 S1 ,ffV 1 (s0 ) = hf; N 0 ; U 0 i. know V (s) = f; N ; U three disjunctionsEquation 20 false. first false, described basis step. second termsimilarly false, since, definition S1, cannot exist c 2 Cfac(s; P (s)) = t. evaluating third term, first note 0 S1. words,successor states also S1 (if successor s0 2 Sk finite k,2 Sk+1). Since successors S1 , know, inductive hypothesis,disjunction V 1 successorsfffalse. Therefore, three disjunctiveterms Equation 20 false, V (s) = f; N ; U .Therefore, induction, know 2 S1 , V (s) = hf; N; U i. definitionstate partition, two results prove theorem required. 2224fiTowards Adjustable Autonomy Real WorldTheorem 2 agent following policy, P , value function, V , generated describedSection 4.4, state 2 satisfy every requiring constraintprobability one V (s) = hF; Cra [ Crs ; U (for U F ).Proof Sketch: proof parallels Theorem 1, state partition, Sk ,k corresponds maximum number transitions satisfying requiringconstraint. However, here, states S1 violate constraint, rathersatisfy it. cycles state space prevent guarantee satisfying requiringconstraint within fixed number transitions, although probability satisfactionlimit may 1. current constraint semantics, decidedsituation fails satisfy constraint, algorithm behaves accordingly. cycleseffect handling forbidding constraints, where, saw Theorem 1,need consider minimum -length trajectory. 2proofs two theorems operate independently, policy-specified actionsatisfy constraints, action exists. precedence forbidding constraintsrequiring ones effect optimal action states. However,con icting forbidding requiring constraints state, preference orderingcauses agent choose policy satisfies forbidding constraint violatesrequiring constraint. agent make opposite choice simply changepreference ordering Section 4.4. Regardless choice, Theorems 1 2,agent use value function, V , identify existence violationnotify user violation possible constraint con ict.ReferencesBarber, K., Goel, A., & Martin, C. (2000a). Dynamic adaptive autonomy multi-agentsystems. Journal Experimental Theoretical Artificial Intelligence, 12 (2), 129{148.Barber, K. S., Martin, C., & Mckay, R. (2000b). communication protocol supportingdynamic autonomy agreements. Proceedings PRICAI 2000 Workshop TeamsAdjustable Autonomy, pp. 1{10, Melbourne, Australia.Bonasso, R., Firby, R., Gat, E., Kortenkamp, D., Miller, D., & Slack, M. (1997). Experiences architecture intelligent reactive agents. Journal ExperimentalTheorectical Artificial Intelligence, 9 (1), 237{256.Brann, D., Thurman, D., & Mitchell, C. (1996). Human interaction lights-out automation: field study. Proceedings 1996 Symposium Human InteractionComplex Systems, pp. 276{283, Dayton, USA.Cesta, A., Collia, M., & D'Aloisi, D. (1998). Tailorable interactive agents schedulingmeetings. Lecture Notes AI, Proceedings AIMSA'98, No. 1480, pp. 153{166.Springer Verlag.Chalupsky, H., Gil, Y., Knoblock, C., Lerman, K., Oh, J., Pynadath, D., Russ, T., & Tambe,M. (2001). Electric Elves: Applying agent technology support human organizations.International Conference Innovative Applications AI, pp. 51{58.225fiScerri, Pynadath & TambeCollins, J., Bilot, C., Gini, M., & Mobasher, B. (2000a). Mixed-initiative decision-supportagent-based automated contracting. Proceedings International ConferenceAutonomous Agents (Agents'2000).Collins, J., Bilot, C., Gini, M., & Mobasher, B. (2000b). Mixed-initiative decision supportagent-based automated contracting. Proceedings International ConferenceAutonomous Agents (Agents'2000), pp. 247{254.Dorais, G., Bonasso, R., Kortenkamp, D., Pell, B., & Schreckenghost, D. (1998). Adjustableautonomy human-centered autonomous systems mars. ProceedingsFirst International Conference Mars Society, pp. 397{420.Draper, D., Hanks, S., & Weld, D. (1994). Probabilistic planning information gatheringcontingent execution. Hammond, K. (Ed.), Proc. Second International Conference Artificial Intelligence Planning Systems, pp. 31{37, University Chicago,Illinois. AAAI Press.Ferguson, G., Allen, J., & Miller, B. (1996). TRAINS-95 : Towards mixed-initiativeplanning assistant. Proceedings Third Conference Artificial IntelligencePlanning Systems, pp. 70{77.Ferguson, G., & Allen, J. (1998). TRIPS : intelligent integrated problem-solving assistant. Proceedings Fifteenth National Conference Artificial Intelligence(AAAI98), pp. 567{573, Madison, WI, USA.Fong, T., Thorpe, C., & Baur, C. (2002). Robot partner: Vehicle teleoperation collaborative control. Workshop Multi-Robot Systems, Naval Research Laboratory,Washington, D.C.Fudenberg, D., & Tirole, J. (1991). Game Theory. MIT Press, Cambridge, Massachusetts.Goldman, R., Guerlain, S., Miller, C., & Musliner, D. (1997). Integrated task representation indirect interaction. Working Notes AAAI Spring SymposiumComputational Models Mixed-Initiative Interaction.Goodrich, M., Olsen, D., Crandall, J., & Palmer, T. (2001). Experiments adjustableautonomy. Hexmoor, H., Castelfranchi, C., Falcone, R., & Cox, M. (Eds.), Proceedings IJCAI Workshop Autonomy, Delegation Control: InteractingIntelligent Agents.Gunderson, J., & Martin, W. (1999). Effects uncertainty variable autonomy maintainance robots. Agents'99 Workshop Autonomy Control Software, pp. 26{34.Hexmoor, H. (2000). cognitive model situated autonomy. Proceedings PRICAI2000, Workshop Teams Adjustable Autonomy, pp. 11{20, Melbourne, Australia.Hexmoor, H., & Kortenkamp, D. (2000). Introduction autonomy control software. JournalExperiemental Theoretical Artificial Intelligence, 12 (2), 123{128.Horvitz, E. (1999). Principles mixed-initiative user interfaces. Proceedings ACMSIGCHI Conference Human Factors Computing Systems (CHI'99), pp. 159{166,Pittsburgh, PA.226fiTowards Adjustable Autonomy Real WorldHorvitz, E., Jacobs, A., & Hovel, D. (1999). Attention-sensitive alerting. ProceedingsConference Uncertainty Artificial Intelligence (UAI'99), pp. 305{313, Stockholm, Sweden.Lesser, V., Atighetchi, M., Benyo, B., Horling, B., Raja, A., Vincent, R., Wagner, T., Xuan,P., & Zhang, S. (1999). UMASS intelligent home project. ProceedingsThird Annual Conference Autonomous Agents, pp. 291{298, Seattle, USA.Mitchell, T., Caruana, R., Freitag, D., McDermott, J., & Zabowski, D. (1994). Experiencelearning personal assistant. Communications ACM, 37 (7), 81{91.Mulsiner, D., & Pell, B. (1999). Call papers: AAAI spring symposium adjustableautonomy. www.aaai.org.Musliner, D., & Krebsbach, K. (1999). Adjustable autonomy procedural controlrefineries. AAAI Spring Symposium Agents Adjustable Autonomy, pp.81{87, Stanford, California.Peot, M. A., & Smith, D. E. (1992). Conditional nonlinear planning. Hendler, J. (Ed.),Proc. First International Conference Artificial Intelligence Planning Systems, pp.189{197, College Park, Maryland. Morgan Kaufmann.Puterman, M. L. (1994). Markov Decision Processes. John Wiley & Sons.Pynadath, D., Tambe, M., Arens, Y., Chalupsky, H., Gil, Y., Knoblock, C., Lee, H., Lerman,K., Oh, J., Kamachandran, S., Rosenbloom, P., & Russ, T. (2000). Electric-elves:Immersing agent organization human organization. ProceedingsAAAI Fall Symposium Socially Intelligent Agents { Human Loop.Pynadath, D., & Tambe, M. (2001). Revisiting Asimov's first law: response callarms. Intelligent Agents VIII Proceedings International workshop Agents,Theories, Architectures Languages (ATAL'01).Quinlan, J. R. (1993). C4.5: Programs machine learning. Morgan Kaufmann, SanMateo, CA.Russell, S. J., & Wefald, E. (1989). Principles metareasoning. Brachman, R. J.,Levesque, H. J., & Reiter, R. (Eds.), KR'89: Principles Knowledge RepresentationReasoning, pp. 400{411. Morgan Kaufmann, San Mateo, California.Scerri, P., Pynadath, D., & Tambe, M. (2001). Adjustable autonomy real-world multiagent environments. Proceedings Fifth International Conference Autonomous Agents (Agents'01), pp. 300{307.Scerri, P., Pynadath, D., & Tambe, M. (2002). elf acted autonomously: Towardstheory adjustable autonomy. First International Joint Conference Autonomous Agents Multi-Agent Systems (AAMAS'02).Schreckenghost, D. (1999). Human interaction control software supporting adjustableautonomy. Musliner, D., & Pell, B. (Eds.), Agents Adjustable Autonomy,AAAI 1999 Spring Symposium Series, pp. 116{119.Stankovic, J., Ramamritham, K., & Cheng, S. (1985). Evaluation exible task scheduling algorithm distributed hard real-time system. IEEE Transactions Computers, 34 (12), 1130{1143.227fiScerri, Pynadath & TambeTambe, M. (1997). Towards exible teamwork. Journal Artificial Intelligence Research(JAIR), 7, 83{124.Tambe, M., Pynadath, D. V., Chauvat, N., Das, A., & Kaminka, G. A. (2000). Adaptiveagent integration architectures heterogeneous team members. ProceedingsInternational Conference MultiAgent Systems, pp. 301{308.Zilberstein, S. (1996). Using anytime algorithms intelligent systems. AI Magazine, 17 (3),73{83.228fiJournal Artificial Intelligence Research 17 (2002) 363378Submitted 5/02; published 11/02Competitive Safety Analysis: Robust Decision-MakingMulti-Agent Systemsmoshet@ie.technion.ac.ilMoshe TennenholtzFaculty Industrial Engineering ManagementTechnion Israel Institute TechnologyHaifa 32000, IsraelAbstractMuch work AI deals selection proper actions given (known unknown) environment. However, way select proper action facing agentsquite unclear. work AI adopts classical game-theoretic equilibrium analysispredict agent behavior settings. approach however provide usguarantee agent. paper introduce competitive safety analysis.approach bridges gap desired normative AI approach, strategyselected order guarantee desired payoff, equilibrium analysis. showsafety level strategy able guarantee value obtained Nash equilibrium,several classical computer science settings. Then, discuss concept competitivesafety strategies, illustrate use decentralized load balancing setting, typicalnetwork problems. particular, show many agents, possibleguarantee expected payoff factor 8/9 payoff obtained Nashequilibrium. discussion competitive safety analysis decentralized load balancingdeveloped deal many communication links arbitrary speeds. Finally,discuss extension concepts Bayesian games, illustrate usebasic auctions setup.1. IntroductionDeriving solution concepts multi-agent encounters major challenge researchersvarious disciplines. famous popular solution concept economicsliterature Nash equilibrium. Although Nash equilibrium extensions modifications powerful descriptive tools, widely used AI literature(Rosenschein & Zlotkin, 1994; Kraus, 1997; Sandholm & Lesser, 1995), appealnormative AI perspective somewhat less satisfactory.1 wish equip agentaction guarantees desired outcome, expected utility, without relyingagents rationality.2 paper shows that, surprisingly, desire obtainingguaranteed expected payoff, payoff order value obtained1. restrict cases exists equilibrium dominant strategies, doneCS literature (Nisan & Ronen, 1999), corresponding equilibrium appealingnormative perspective. However, cases rarely exist.2. Maximizing expected payoff facing set possible environment behaviors fundamental AI.particular, discussed context game trees, context planning incompleteinformation, need obtain desired goal regardless initial configuration, wellcontext reinforcement learning, wish maximize expected payoff actualmodel (selected set possible models adversarial way) initially unknown. (Russell & Norvig,1995).c2002AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiTennenholtzNash equilibrium, achievable various classical computer science settings. resultsinspired several interesting examples counter-intuitive behaviors obtained following Nash equilibria solution concepts (Roth, 1980; Aumann, 1985). Oneinteresting challenging examples introduced Aumann (Aumann,1985). Aumann presented 2-person 2-choice (2 2) game g, safety-level (probabilistic maximin) strategy game Nash equilibrium it, yieldexpected payoff Nash equilibrium g. observation may significant positive ramifications agents design perspective. safety-level strategy agentguarantees expected payoff equals expected payoff Nash equilibrium,serve desirable robust protocol agent! Given above, interestedwhether optimal safety level strategy leads expected payoff similar oneobtained Nash equilibrium simple games represent basic variants classicalcomputer science problems. show, indeed case 2 2 games capturingsimple variants classical load balancing leader election problems. generalquestion refers general 2 2 games. show safety-level strategy(strictly) mixed one, expected payoff identical expected payoff obtainedNash equilibrium generic non-reducible 2 2 game. also showlonger necessarily case pure safety-level strategy. addition, considergeneral 2-person set-theoretic games (which naturally extend 2 2 leader election games)show set-theoretic game g possesses strictly mixed strategy equilibriumsafety level value player game equals expected payoff obtainsequilibrium. Following this, define concept C-competitive safety strategies.Roughly speaking, strategy called C-competitive safety strategy, guaranteesexpected payoff C1 expected payoff obtained Nash equilibrium.show extended decentralized load balancing setting 9/8-competitive strategyexists, number players large. also discuss extensions resultgeneral settings. particular, deal cases arbitrary number communicationlines, arbitrary different speeds communication. show ratio 4/3obtained allow arbitrary speeds two communication lines connecting sourcetarget. also consider notion k-regular network, k ratioaverage communication speed lowest speed communication (in given setcommunication lines), show k-competitive safety strategy exists generalk-regular networks. Then, discuss C-competitive strategies context Bayesiangames. particular show existence e-competitive safety strategy classicalfirst-price auctions setup.Imagine agent designed deal communication user differenttargets. Selecting routes messages multi-agent system non-trivial task.efficiency agent depends actions selected users (and agents)try also communicate similar targets. cases, game-theoretic analysisidentify Nash equilibria may emerge setting. However, adoptingstrategy prescribed Nash equilibrium may quite dangerous agent.agents may fail choose strategies prescribed equilibrium, resultoutcome agent quite poor. would much better agent couldguaranteed similar payoff (to one obtained Nash equilibrium) without relyingagents behavior. computational settings, (machine other) failures364fiCompetitive Safety Analysispossible, rationality assumptions participants behavior minimized,safety-level strategy special appeal, especially yields value closeexpected payoff obtained Nash equilibrium.Previous work concerned comparing payoffs obtainedoptimal centralized (and Pareto-efficient) controller expected payoffs obtainedNash-equilibria corresponding game (Koutsoupias & Papadimitriou, 1999).3work spirit competitive analysis, central topic theoretical computerscience (Borodin & El-Yaniv, 1998). work considered suggesting complementary approach, comparing safety-level value agents expected payoff Nashequilibrium.rest paper organized follows. Section 2 provide basicdefinitions notations. sections 3 4 deal simple variants loadbalancing leader election problems. use examples showingsafety-level strategies quite competitive attractive, leading valueNash equilibrium. generalized section 5 context general 2 2 games.discussion another extension dealing set-theoretic games discussed section 6.section 7 deal several settings decentralized load balancing, increasing levelcomplexity. particular show existence desired competitive safety strategiessettings many agents many possible routes. Section 8 illustrates usecompetitive safety analysis games incomplete information.2. Basic Definitions Notationsgame tuple G = hN = {1, . . . , n}, {Si }ni=1 , {Ui }ni=1 i, N set n players,Si finite set pure strategies available player i, Ui : ni=1 Si < payofffunction player i. Given Si , denote set probability distributionselements Si (Si ). element (Si ) called mixed strategy player i.called pure strategy assigns probability 1 element Si , calledstrictly mixed strategy assigns positive probability element Si . tuple= (t1 , . . . , tn ) ni=1 (Si ) called strategy profile. denote Ui (t) expectedpayoff player given strategy profile t. strategy profile = (t1 , . . . , tn ) Nashequilibrium N , Ui (t) Ui (t1 , t2 , . . . , ti1 , t0i , ti+1 , . . . , tn ) every t0i Si . Nashequilibrium = (t1 , . . . , tn ) called pure strategy Nash equilibrium ti pure strategyevery N . Nash equilibrium = (t1 , . . . , tn ) called strictly mixed strategyNash equilibrium every N ti strictly mixed strategy. Givengame g mixed strategy player i, (Si ), safety level value obtainedchoosing game g, denoted val(t, i, g), minimal expected payoff playermay obtain employing arbitrary strategy profiles players.strategy t0 player val(., i, g) maximal called safely-level strategy (orprobabilistic maximin strategy) player i. Hence, safety-level strategy agent i,ssaf e (Si ) satisfiesssaf e argmaxs(Si ) min(s1 ,s2 ,...,si1 ,si+1 ,...,sn )j6=i Sj Ui (s1 , s2 , . . . , si1 , s, si+1 , . . . , sn )3. work extended e.g. (Roughgarden, 2001; Roughgarden & Tardos, 2002).365fiTennenholtzstrategy e Si dominates strategy f Si every (s1 , s2 , . . . , si1 , si+1 , . . . , sn )j6=i (Sj ) Ui (s1 , . . . , sj1 , e, sj+1 , . . . , sn )Ui (s1 , . . . , sj1 , f, sj+1 , . . . , sn ), strict inequality least one tuple.game called non-reducible exist e, f Si , N ,e dominates f . game called generic every N , pair strategies e, f Si ,(s1 , s2 , . . . , si1 , si+1 , . . . , sn ) j6=i Sj , Ui (s1 , . . . , si1 , e, si+1 , . . . , sn ) =Ui (s1 , . . . , si1 , f, si+1 , . . . , sn ) e f coincide. generic game different strategies player i, assuming fixed strategy profile rest players, leaddifferent payoffs. property simply says fixed environment (capturedstrategy profile rest players), different strategies player leadsomewhat different payoffs (e.g. result costs, outcomes, etc.) game called2 2 game n = 2 |S1 | = |S2 | = 2.3. Decentralized Load Balancingsection consider decentralized load balancing, two rational players needsubmit messages simple communication network: network two parallel communication lines e1 , e2 connecting nodes t. player message needsdeliver t, needs decide route taken. communication linee1 faster one, therefore value transmitting single message along e1 X > 0value transmitting single message along e2 X 0.5 < < 1.4player needs decide communication line used sending messaget. players choose communication line value onedrops factor two (a player obtain X2 players choose e1 , playerobtain X2 players choose e2 ). matrix form, game presentedfollows:!X/2, X/2X, XM=X, XX/2, X/2Proposition 1 optimal safety-level value player decentralized load balancing game equals expected payoff strictly mixed strategy equilibrium game.Proof: Consider following equations probability choose e1 symmetricequilibrium, player selects e1 probability p e2 probability 1 p.equation derived fact Nash equilibrium every strategysupport lead identical expected payoffs. Notice solving equationalso prove existence strictly mixed strategy Nash equilibrium.pXX+ (1 p)X = pX + (1 p)22Hence, p X2 + X pX = pX + X2 p X2 , X X2 = p X2 + p X2 . impliesp=21+4. Notice later paper, X constant. important factor ratiopayoffs.366fiCompetitive Safety AnalysisNotice 0 < p < 1 required. safety level mixed strategy satisfies followingequation. equation derived fact expected payoff (mixed)safety-level strategy identical strategy player.pXX+ (1 p)X = pX + (1 p)22Hence, p X2 +X pX = pX + X2 p X2 . implies pX p X2 +pX p X2 =) = Xtherefore p( X+X22 . get:p=X2 ,1+Notice Nash equilibrium different safety level strategy. However,consider expected payoff obtained Nash equilibrium safety levelstrategy: Nash value is:2X2 1+X1+ 21+safety level value is:1X+X1+ 21+show values coincide. enough show that:2 12+= 1.52(1 + )1+1+however trivially holds since sides equal 1.5 1+2Notice proposition shows agent guarantee expectedpayoff equals payoff Nash equilibrium decentralized load balancinggame. obtained using strategy differs agents strategies Nashequilibria game (which provide guarantee). Notice playerscould used mediator/correlation devise, play game repeatedly,mediator could directed use strategies leading payoff higherone guaranteed safety-level strategy. use mediator/correlationdevise, well discussion repeated games, beyond scope paper.4. Leader Election: Decentralized Votingleader election setting, players vote identity player takelead particular task. failure obtain agreement leader badoutput, modelled leading 0 payoff. Assume players strategieseither vote 1 vote 2, denoted a1 , a2 respectively, Ui (aj , ak ) > 0,i, j, k {1, 2}, j = k. Notice setting captures various forms leaderelection, e.g. player prefers selected, prefers playerselected, etc. matrix form, game presented follows (where a, b, c, > 0):M=a, b0, 03670, 0c,!fiTennenholtzProposition 2 optimal safety-level value player leader election game equalsexpected payoff strictly mixed strategy equilibrium game.Proof: strictly mixed Nash equilibrium probability q choosing a1player 2 satisfy:qU1 (a1 , a1 ) = (1 q)U1 (a2 , a2 )equality implied fact pure strategy supportmixed strategy agent, Nash equilibrium, yield expected payoff(otherwise, deviation rational.) Hence, equality captures factstrategy player 2 equilibrium selected way utility agent 1using either a1 a2 same.Similarly, probability p choosing a1 player 1 satisfypU2 (a1 , a1 ) = (1 p)U2 (a2 , a2 )Hence, strictly mixed strategy Nash equilibrium exists, q =U1 (a2 ,a2 )U1 (a1 ,a1 )+U1 (a2 ,a2 )U2 (a2 ,a2 )U2 (a1 ,a1 )+U2 (a2 ,a2 )seen equations strictly mixed strategyp=equilibrium exists. Consider w.l.o.g player 1. expected payoff obtains)U1 (a2 ,a2 )equilibrium qU1 (a1 , a1 ) = UU11(a(a11,a,a11)+UPlayer 1s safety level strategy satisfies1 (a2 ,a2 )0following, p probability choosing a1 :p0 U1 (a1 , a1 ) = (1 p0 )U1 (a2 , a2 )Hence, p0 =U1 (a2 ,a2 )U1 (a1 ,a1 )+U1 (a2 ,a2 ) Notice)U1 (a2 ,a2 ).p0 U1 (a1 , a1 ) = UU11(a(a11,a,a11)+U1 (a2 ,a2 )p0 = q. safety level value there-get Nash equilibrium safety levelfore:strategies different, expected payoffs players coincide.2Notice proposition shows agent guarantee expectedpayoff equals payoff Nash equilibrium leader election game.5decentralized load balancing game, obtained using strategy differsagents strategies Nash equilibria game (which provide guarantee).5. Safety Level General 2 2 Gamesresults presented previous sections refer 2-person 2-choice variants central problems occurring computational contexts. Given encouraging resultsframework basic settings, wish consider two types extensions:1. Generalize results broader family simple games.2. Generalize results general CS-related settings, dealing particulargames many players, found load-balancing settings.5. reader confuse fact p0 = q similarity safety-level Nash equilibrium. Indeed, p0 refers probability choosing a1 player 1, q refers probabilitychoosing action player 2.368fiCompetitive Safety Analysissection deal first point. Later, particular section 7,deal second one. interest see whether results sections 3-4extended forms 2 2 games. Notice load balancing leaderelection settings represented non-reducible generic 2 2 games. trueregard game presented Aumann:M=2, 66, 04, 20, 4!Non-reducible generic games attractive concept. dominated strategiesgame add understanding interaction, since strategies safelyignored. fact game generic also quite appealing: quite natural assumepair actions lead different outcomes fix rest environment.show:Theorem 1 Let G 2 2 non-reducible generic game. Assume optimal safetylevel value player obtained strictly mixed strategy, value coincidesexpected payoff player Nash equilibrium G.Proof: Denote strategies available players a1 , a2 . Use following notation: = U1 (a1 , a1 ), b = U1 (a1 , a2 ), c = U1 (a2 , a1 ), = U1 (a2 , a2 ), e = U2 (a1 , a1 ), f =U2 (a1 , a2 ), g = U2 (a2 , a1 ), h = U2 (a2 , a2 )matrix form, presented as:M=a, ec, gb, fd, h!strictly mixed strategy Nash equilibrium exists satisfy that:qa + (1 q)b = qc + (1 q)dpe + (1 p)g = pf + (1 p)hp q probabilities choosing a1 players 1 2, respectively. getqa + b qb = qc + qd, implies q(a b c + d) = b.Similarly, get pe + g pg = pf + h ph, impliesp(e g f + h) = h g. Hence, strictly mixed strategy Nash equilibriumhave:dbq=abc+dhgp=egf +hNotice since game generic 6= b. > b q strictly0 1 c > contradict non-reducibility. < b q strictly0 1 > c, also contradicts non-reducibility. Similarly, sincegame generic h 6= g. h > g p strictly 0 1 f > e369fiTennenholtzcontradict non-reducibility. h < g p strictly 01 e < f , also contradicts non-reducibility. Given get p qdefine strictly mixed strategy equilibrium G. Consider safety level strategyplayer 1. player 1 chooses a1 probability p0 satisfies that:p0 + (1 p0 )c = p0 b + (1 p0 )dimplies need p0 a+cp0 c = p0 b+dp0 d, implies p0 (acb+d) =c. Hence,dcp0 =acb+dab1 p0 =acb+dCompute expected payoff player 1 strictly mixed Nash equilibrium, givenac, that:1 q = abc+dqa + (1 q)b =da cb(d b)a + (a c)b=abc+dabc+dexpected payoff safety level strategy player 1 be:p0 + (1 p0 )c =(d c)a + (a b)cda cb=abc+dabc+dHence, get expected payoffs Nash equilibrium safety level strategies player 1 coincide. computation player 2 similar.25.1 Case Pure Safety-Level Strategiesreader may wonder whether previous result also proved caserestrictions structure safety-level strategy game g. severalAI contexts, discussion pure maximin strategies, probabilistic behaviorconsidered. course, probabilistic maximin strategies powerful, manycases best safety level obtained mixed strategy pure one.However, interest consider case safety-level strategy pureone. show, exists generic non-reducible 2 2 game g, optimalsafety level strategy player pure, expected payoff player lowerexpected payoff player Nash equilibria g. Consider game g,U1 (1, 1) = 100, U1 (1, 2) = 40, U1 (2, 1) = 60, U1 (2, 2) = 50, U2 (1, 1) = 100, U2 (1, 2) =210, U2 (2, 1) = 200, U2 (2, 2) = 90. matrix form game looks follows:M=100, 10060, 20040, 21050, 90!easy check g generic non-reducible. particular, dominatedstrategies, payoffs obtained player different strategy profiles differentone another. game pure Nash equilibria. strictly mixed strategy370fiCompetitive Safety Analysisequilibrium probability q choosing a1 player 2 satisfy 100q + 40(1 q) =60q+50(1q), i.e. 60q+40 = 10q+50, q = 0.2. equilibrium probabilityplayer 1 choose a1 p = 0.5, expected payoff player 1 100q+40(1q) = 52.safety-level strategy player 1 perform a2 , guaranteeing payoff 50, given(a2 , a2 ) saddle point zero-sum game payoffs player 2 takencomplement 0 player 1s original payoffs. Hence, value safety levelstrategy player 1 50 < 52.26. Beyond 2 2 Gamesleader election game instance general set games: set-theoretic games.set theoretic game sets strategies available players identical,payoff player uniquely determined set strategies selected player.example, 2-person set-theoretic game U1 (s, t) = U1 (t, s), U2 (s, t) =U2 (t, s) every s, S1 = S2 . Notice set-theoretic games typical votingcontexts. typical voting context care votes, indentityvoters. prove following:Proposition 3 Given 2-person set theoretic game g strictly mixed strategy Nashequilibrium, value optimal safety level strategy player equals expectedpayoff equilibrium.Proof: Let = S1 = S2 = {s1 , s2 , . . . , sl }. Let = (t1 , t2 ) strictly mixed strategyNash equilibrium. Denote tuple probabilities associated ti (pi1 , . . . , pil ) (i{1, 2}, |S1 | = |S2 | = l). strictly mixed Nash equilibrium expectedpayoff player 1 is:lj=1 p2j U1 (se , sj ) ()every 1 e l. Consider strategy f player 1 assigns probability p2jstrategy sj . Then, every strategy se selected player 2, expected payoff fgivenlj=1 p2j U1 (sj , se ) = lj=1 p2j U1 (se , sj ) = ()implies safety level strategy player 1 yields expected payoffidentical expected payoff player 1 equilibrium. Similar reasoningapplied player 2.27. Competitive Safety StrategiesLet set strategies. Consider family games (g1 , g2 , . . . , gj , . . .)player them, set strategies games S, jplayers, addition i, gj . example, consider family decentralized loadbalancing settings. (n 1)-th game extended load-balancing setting consistn players, one i. players submit messages along e1 e2 .payoff player participating n-person decentralized load balancing gameXXk (resp. k ) chosen e1 (resp. e2 ) additional k 1 participants chosen371fiTennenholtzcommunication line. mixed strategy (S) called C-competitive safetystrategy exists constant C > 0,nash(i, gj )Cj val(t, i, gj )limnash(i, gj ) lowest expected payoff player might obtain equilibriumgj , val(t, i, gj ) expected payoff guaranteed choosing game gj .extended decentralized load balancing setting 6 typical basic network problem.C small, C-competitive safety strategy context provide useful protocolbehavior. show:Theorem 2 exists 9/8-competitive safety strategy extended decentralizedload-balancing setting.Proof: Consider following strategy profile players n-person decentralized1load balancing game: players {1, 2, . . . , 1+ne} choose e1 , rest choosee2 . W.l.o.g assume = 1 player make computationexpected payoffs. easy verify strategy profile equilibriumgame, expected payoff player boundedX(1 + )()nIntuitively, equilibrium obtained partitioning players way payoffusing communication lines (almost) equal. Consider following strategy1player i: select e1 probability 1+select e2 probability 1+. Notice(if adopted participants) Nash equilibrium. However, showcompetitive safety strategy small C > 0 . Consider arbitrary numberparticipants n, (n 1) (i.e. excluding player i) n 1 participants usee2 rest use e1 , arbitrary 0 1. expected payoff obtained usingbe:1XX+1 + (n 1) + 1 1 + (1 )(n 1) + 1value greater equal to:1XX+1 + n + 1 1 + (1 )n + 1equals11X+1 + n + 1 (1 )n + 1Simplifying get:Xn+2( )1 + (1 + n)(n n + 1)6. later term extended load-balancing setting refers family games above.372fiCompetitive Safety AnalysisDividing (**) (***) get ratio is:(1 + )2 ( 2 )n2 + n + 1n(n + 2)n approaches infinity ratio approaches(1 + )2( 2 )Given 0.5 < 1 0 1 get ratio bounded 9/8desired.27.1 Extensions: Arbitrary Speeds Linkssection generalize result obtained context decentralized load balancing case parallel communication lines leading source target.value obtained agent (w.l.o.g. agent 1) submitting message along linei, ni agents decided submit messages line given Xni ,1 = 1 2 > 0. extension enables us handle general binarycase 0 < < 1, well discuss cases safety level strategyeffective general m-lines situation. Using ideas developed case = 2,show:j6=i jTheorem 3 exists i=1mi2 i=1competitive safety strategy extendedi=1 jdecentralized load-balancing setting, allow (rather 2) parallel communication lines, arbitrary s.Proof: Following ideas previous theorem, exists equilibrium agent1 obtains (X/n)mi=1 . Intuitively, equilibrium players distributedway payoff using different communication lines (almost) identical.particular, agents {1, 2, . . . , m1 ne}, 1 = 1 assigned communicationi=1line 1, hence agent 1s payoff prescribed.Consider following strategy agents: choose communication lineprobabilityj6=i ji=1 j6=i jGiven above, expected payoff agent minimized (using similar ideasones proof Theorem 2), splitting agents equally amongcommunication lines. Hence, expected payoff agent least:i=1Xj6=i jm2 Xj=1 j=n(1 + )i=1 j6=i j+ n i=1 j6=i jHence, ratio expected payoff Nash equilibrium expectedpayoff guaranteed bounded by:m+ni=1 j6=i j()i=12nj=1 j373fiTennenholtzimplies, n large existencei=1 i=1 j6=i jcompetitivem2j=1 jstrategy.2general binary case, 1 = 1, 2 = , 0 < 1,implies existence(1 + )24competitive strategy.Corollary 1 Given extended load balancing setting, = 2, arbitrary speedscommunication lines (0 < 1), exists 43 -competitive strategy.22Proof: see notice 1 + < (1+)< 1/3 (1+)44decreasing interval (0, 1]. Hence, considering strategy prescribedtheorem 1/3 selecting e1 otherwise, guaranteed ratio1 + 1/3 = 4/3.2Consider general m-links (i.e. parallel communication lines) case.average network quality (or speed), Q, defined i=1. network calledQk-regular k. Many networks k-regular small k. example, 0.5before, network 2-regular regardless number edges.Corollary 2 Given k-regular network, exists k-competitive safety strategyextended decentralized load-balancing setting, allow (rather 2) paralleledges.Proof: show above, observeQi=1 i=1 j6=i ji=1 j6=i j=m2j=1 jj=1 jlatter smaller equalQ=kdesired.2Together, Theorem 3 corollaries 1 2 extend results decentralized loadbalancing general case parallel communication lines.8. Competitive Safety Analysis Bayesian Gamesresults presented previous sections refer games complete information.games studied context refer fundamental settings AI gametheory intersection, deal issues congestion. section, showideas applied games incomplete information well.game incomplete information payoff player given behaviorset players private information player. order illustrate competitive safetyanalysis games incomplete information, chosen consider basicmechanism, first-price auction. selection first-price auction accident.374fiCompetitive Safety AnalysisAuctions fundamental theory economic mechanism design7 , amongauctions possess dominant strategy, assuming independent private valuemodel, first-price auctions probably common ones.consider setting good g put sale, n potential buyers.buyer valuation (i.e. maximal willingness pay) g drawnuniform distribution interval real numbers [0, 1]. valuation privateinformation agent has. exact valuation known agent,distribution agent valuations commonly known. valuations assumedindependent one another. first price auction, potential buyer askedsubmit bid good g. assume bids buyer valuation vnumber interval [0, v].8 good allocated bidder submittedhighest bid (with lottery determine winner case tie). auction setupdefined using Bayesian game.9 game players potential bidders,payoff player valuation v vp wins good pays p, 0get good. reader see, distinguished feature gamesplayers utility function depends agents private valuation, therefore knownit. equilibrium concept also extended context Bayesian games.auction setup agents strategy function valuations monetary bids.strategy profile equilibrium agents strategy best responseagents strategies given distribution agents valuations. particular,equilibrium game bid player valuation v (1 n1 )v.nGiven above, expected payoff agent valuation v, vn . before,question whether guarantee payoff proportional expected payoffequilibrium.discussing appropriate strategy, emphasize formal issueregard competitive safety strategies Bayesian games. Notice definitioncompetitive safety strategies, assume players competitive actionindependent number players. hand, suggested equilibriumanalysis above, behavior first-price auction may heavily depend number players.order address issue, make use revelation principle, discussedeconomic mechanism design literature. revelation principle tells us one replaceabove-mentioned first-price auction following auction: bidder askedreveal valuation, good sold bidder reported highestvaluation; agent reported valuation v 0 turn winnerasked pay (1 n1 )v 0 . mechanism player submit bids 0nn1 v. turns reporting true valuation equilibrium auction,yield (in equilibrium) allocation, payments, expected utilityparticipants, original auction. convenient consider revelationmechanism, since facing number participants, bidders strategy equilibriumalways same.7. general discussion mechanism design see (Mas-Colell, Whinston, & Green, 1995), Chapter 23,(Fudenberg & Tirole, 1991), Chapter 7).8. general, buyers may submit bids higher valuations, strategies dominated strategies, existence effect equilibrium discussed paper.9. formal definition exposition Bayesian games found (Fudenberg & Tirole, 1991).375fiTennenholtzGiven above, first-price auction setup identified family (Bayesian)games (g1 , g2 , . . .) gj Bayesian game associated (the revelation mechanismof) first-price auction j +1 potential buyers. definition C-competitive strategiesapplied context well.Theorem 4 exists e-competitive strategy first-price auction setup.Proof: player 1 valuation v submits bid b auction additionaln 1 players, worst case payoffZn1bnv2 =0Zdv2n1bnv3 =0dv2Zn1bnvn =0(vn1b)dvnnsays order win, player bid higher playersnbids. players bid revelation mechanism however n1timesn1valuation, therefore integrate valuations n timesplayer bid. agent winner gain v n1n b bids bvaluation v (given rules revelation mechanism). maximizedn 1 n 1 n1(vb)(b)=0dbnnn1 , i.e. b = v.Hence, expected value maximized (n 1)vbn2 = n1n nbtherefore get safety-level strategy coincides case equilibriumstrategy. expected payoff equilibrium shown v n /n. expected payoffguaranteed strategy(n 1 n1 1v)vnnratio safety level value equilibrium value therefore boundedn1( n1n ) , greater equal e , approaches numberplayers approaches infinity.2interesting observation theorem, safety-level strategyidentical equilibrium strategy. connection occurs although game0-sum game. interesting observe since consider revelation mechanismssafety-level strategy turns independent number participants.result also obtained consider standard first-price auctions, ratherrevelation mechanisms associated them; nevertheless, require us allowplayer choose action knowing number potential bidders (as correspondingequilibrium analysis).9. Discussionprevious work AI attempted show potential power decision-theoreticapproaches rely classical game-theoretic analysis. particular, work theoretical computer science competitive analysis extended deal rationalityconstraints (Tennenholtz, 2001), order become applicable multi-agent systems.376fiCompetitive Safety Analysisintroduced competitive safety analysis, bridging gap normative AI/CS approach classical equilibrium analysis. shown observation, dueAumann, safety-level strategies may yield value Nash equilibrium gameszero-sum, provides powerful normative tool computer scientists AIresearchers interested protocols non-cooperative environments. illustrateduse power competitive safety analysis various contexts. shown generalresults 2 2 games, well games many participants, introduceduse competitive safety analysis context decentralized load balancing, leaderelection, auctions. Notice work concerned normative approachdecision making multi-agent systems. make claims applicabilityapproach descriptive purposes, i.e. prediction people behavecorresponding situations. Although exists much literature failure Nash equilibrium, still powerful concept action prediction multi-agent systems.setting decentralized load balancing discussed part paper central gametheory applications.10 Given importance setting CS perspective,providing robust agent protocols setting major challenge work multiagent systems. order however build robust protocols, relying standard equilibriumanalysis might satisfactory, safety guarantees required. work suggestsprotocols analysis providing guarantees, bridging gap classicalAI/decision-theoretic reasoning equilibrium analysis game theory.Acknowledgementswork carried author sabbatical leave computerscience department Stanford university. preliminary version paper appearsproceedings AAAI-2002.ReferencesAumann, R. (1985). non-transferable utility value: comment Roth-Shaperexamples. Econometrica, 53 (3), 667677.Borodin, A., & El-Yaniv, R. (1998). On-Line Computation Competitive Analysis. CambridgeUniversity Press.Fudenberg, D., & Tirole, J. (1991). Game Theory. MIT Press.Koutsoupias, E., & Papadimitriou, C. (1999). Worst-Case Equilibria. STACS.Kraus, S. (1997). Negotiation cooperation multi-agent environments. Artificial Intelligence,94, 7997.Mas-Colell, A., Whinston, M., & Green, J. (1995). Microeconomic Theory. Oxford University Press.Monderer, D., & L.S.Shapley (1996). Potential games. Games Economic Behavior, 14, 124143.Nisan, N., & Ronen, A. (1999). Algorithmic mechanism design. Proceedings STOC-99.10. See literature potential congestion games, e.g. (Monderer & L.S.Shapley, 1996; Rosenthal,1973).377fiTennenholtzRosenschein, J. S., & Zlotkin, G. (1994). Rules Encounter. MIT Press.Rosenthal, R. (1973). class games possessing pure-strategy nash equilibria. InternationalJournal Game Theory, 2, 6567.Roth, A. E. (1980). Values games without side payments: difficulties current concepts.Econometrica, 48 (2), 457465.Roughgarden, T. (2001). price anarchy independent network topology. Proceedings34th Annual ACM Symposium Theory Computing, pp. 428437.Roughgarden, T., & Tardos, E. (2002). bad selfish routing?. Journal ACM, 49 (2),236259.Russell, S., & Norvig, P. (1995). Artificial Intelligence: Modern Approach. Prentice Hall.Sandholm, T. W., & Lesser, V. (1995). Equilibrium Analysis Possibilities UnenforcedExchange Multiagent Syustems. Proc. 14th International Joint Conference ArtificialIntelligence, pp. 694701.Tennenholtz, M. (2001). Rational Competitive Analysis. Proc. 17th International JointConference Artificial Intelligence, pp. 10671072.378fiJournal Artificial Intelligence Research 17 (2002) 265287Submitted 10/01; published 9/02Numbers Really Matter?Hei ChanAdnan Darwichehei@cs.ucla.edudarwiche@cs.ucla.eduComputer Science DepartmentUniversity California, Los AngelesLos Angeles, CA 90095, USAAbstractCommon wisdom small distinctions probabilities (parameters) quantifying belief network matter much results probabilistic queries. Yet,one develop realistic scenarios small variations network parameterslead significant changes computed queries. pending theoretical questionanalytically characterize parameter changes matter. paper,study sensitivity probabilistic queries changes network parameters provetight bounds impact parameters queries. analyticresults pinpoint interesting situations parameter changesmatter. results important knowledge engineers help identifyinfluential network parameters. also help explain previous experimentalresults observations regards network robustness parameter changes.1. Introductionbelief network compact representation probability distribution (Pearl, 1988;Jensen, 2001). consists two parts, one qualitative quantitative.qualitative part belief network (called structure) directed acyclic graphnodes represent domain variables edges represent direct influencesvariables. quantitative part belief network set conditional probability tables(CPTs) quantify beliefs influences. Figure 1 depicts structurebelief network Figure 2 depicts CPTs.1Automated reasoning systems based belief networks become quite popular recently enjoyed much success number real-world applications. Centraldevelopment systems construction belief network (hence, probability distribution) faithfully represents domain interest. Although automaticsynthesis belief networksbased design information certain applications basedlearning techniques othershas drawing lot attention recently, mainstreammethods constructing networks continue based traditional knowledge engineering (KE) sessions involving domain experts. One central issues ariseKE sessions assessment impact changes network parameters mayprobabilistic queries interest.Consider example following common method constructing belief networksmedical diagnosis applications (Coupe, Peek, Ottenkamp, & Habbema, 1999). First,1. specific network CPTs distributed evaluation version commercial HUGINsystem http://www.hugin.com/.c2002AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiChan & DarwicheFireSmokeTamperingAlarmLeavingReportFigure 1: belief network structure.Firetruefalsex|u.01.99FiretruetruefalsefalseSmoketruefalsetruefalsex|u.9.1.01.99AlarmtruetruefalsefalseLeavingtruefalsetruefalsex|u.88.12.001.999FiretruetruetruetruefalsefalsefalsefalseTamperingtruefalsex|u.02.98TamperingtruetruefalsefalsetruetruefalsefalseAlarmtruefalsetruefalsetruefalsetruefalsex|u.5.5.99.01.85.15.0001.9999LeavingtruetruefalsefalseReporttruefalsetruefalsex|u.75.25.01.99Figure 2: CPTs belief network shown Figure 1.network structure developed. Next, parameters estimated non-experts usingcombination statistical data qualitative influences available textbook materials.Finally, medical experts brought evaluate network fine-tune parameters.One method evaluation pose diagnostic scenarios network, compareresults queries expected experts. example, given setsymptoms e, two potential diagnoses z, network may give us conclusionPr (y | e)/Pr (z | e) = 2, domain expert may believe ratioless 4. Assuming network structure correct, central questionthen: network parameters changed give us correct ratio,much?automate task identifying parameter changes, recently developed belief network tool, called SamIam (Sensitivity Analysis, Modelling, Inference266fiWhen Numbers Really Matter?Figure 3: screen shot SamIam performing sensitivity analysis belief networkshown Figure 1.More)2 . One feature sensitivity analysis, allows domain experts fine-tunenetwork parameters order enforce constraints results certain queries. Usersspecify constraint want enforce, SamIam automatically decide whether given parameter relevant constraint, is, computeminimum amount change parameter needed enforce constraint.technical details approach sensitivity analysis subject Section 2.experimented SamIam, ran scenarios found surprisingfirst glance. Specifically, many occasions queries would quitesensitive small variations certain network parameters. Consider scenario Figure 3one example, corresponds network detailed Figures 1 2. Here,evidence e = report, smoke: people reported evacuating building,evidence smoke. evidence make tampering likely fire,given belief network indeed reflect Pr (tampering | e) = .50Pr (fire | e) = .03. wanted, however, probability tampering less .65.Hence, asked SamIam identify parameter changes enforce constraint,made two recommendations:1. either decrease probability false report, Pr (report | leaving), currentvalue .01 .0047,2. SamIam developed UCLA Automated Reasoning Group.http://reasoning.cs.ucla.edu/.267web pagefiChan & Darwiche2. increase prior probability tampering current value .02 .036.Therefore, distinctions .02 .036, one .01 .0047,really matter case induces absolute change .15 probabilistic queryinterest. Note also implicit SamIams recommendations parametersvariables Fire, Smoke, Leaving, Alarm irrelevant enforcing constraint, i.e.matter much change parameters, would able enforcedesired constraint.example shows absolute change query much largerabsolute change corresponding parameters. Later, show exampleinfinitesimal change network parameter leads change .5 correspondingquery. also show examples relative change probability querylarger corresponding relative change network parameter. One wonderswhether different method measuring probabilistic change (other absoluterelative), allows one non-trivially bound change probabilistic queryterms corresponding change network parameter.answer related questions, conduct Section 3 analytic studypartial derivative probabilistic query Pr (y | e) respect network parameterx|u . study leads us three main results:1. bound derivative terms Pr (y | e) Pr (x | u) only, independent aspect given belief network;2. bound sensitivity queries infinitesimal changes network parameters;3. bound sensitivity queries arbitrary changes network parameters.last bound particular shows amount change probabilistic querybounded terms amount change network parameter, long changeunderstood relative change odds. result number practical implications. First, relieve experts precise specifying certainparameters subjectively. Next, important approximate inference algorithmspre-process network parameters eliminate small distinctions parameters,order increase efficiency inference (Poole, 1998). Finally, used showautomated reasoning systems based belief networks robust and, hence, suitablereal-world applications (Pradhan, Henrion, Provan, Del Favero, & Huang, 1996).Section 4 indeed dedicated exploring implications bounds,provide analytic explanation certain parameter changes dont matter.finally close Section 5 concluding remarks. Proofs theorems givenAppendix A.2. Tuning Network Parametersreport section tool developing, called SamIam, finetuning network parameters (Laskey, 1995; Castillo, Gutierrez, & Hadi, 1997; Jensen, 1999;Kjrulff & van der Gaag, 2000; Darwiche, 2000). Given belief network, evidencee, instantiation variables E belief network, two events zvariables Z respectively, Y, Z 6 E, tool efficiently identify parameterchanges needed enforce following types constraints:268fiWhen Numbers Really Matter?Difference: Pr (y | e) Pr (z | e) ;Ratio: Pr (y | e)/Pr (z | e) .two constraints often arise debug belief networks. example,make event likely event z, given evidence e, specifying constraint,Pr (y | e) Pr (z | e) 0, make event least twice likely event z, givenevidence e, specifying constraint, Pr (y | e)/Pr (z | e) 2. discuss nextone would enforce two constraints, need settle notational conventionstechnical preliminaries first.Variables denoted upper-case letters (A) values lower-case letters (a).Sets variables denoted bold-face upper-case letters (A) instantiationsdenoted bold-face lower-case letters (a). variable values true false,use denote = true denote = false. CPT variable Xparents U defines set conditional probabilities form Pr (x | u), x valuevariable X, u instantiation parents U, Pr (x | u) probability knownnetwork parameter denoted x|u . finally recall basic fact belief networks.probability instantiation x network variables X equals productnetwork parameters consistent instantiation. example,probability instantiation fire, tampering, smoke, alarm, leaving, report Figure 1 equals.01 .98 .9 .99 .12 .01, product network parameters (from Figure 2)consistent instantiation.2.1 Binary Variablesfirst consider parameters binary variable X, two values x x and,hence, two parameters x|u x|u parent instantiation u. assumevariable X parent instantiation u meta parameter x|u ,x|u = x|u x|u = 1 x|u . Therefore, goal determine amountchange meta parameter x|u would lead simultaneous change x|ux|u . use meta parameter x|u meaningful change x|ux|u without changing since x|u + x|u = 1.First observe probability instantiation e, Pr (e), linear functionnetwork parameter x|u belief network (Russell, Binder, Koller, & Kanazawa,1995; Castillo et al., 1997). fact, probability linear meta parameter x|u .Theorem 2.1 derivative Pr (e) respect meta parameter x|u given by:Pr (e)Pr (e, x, u) Pr (e, x, u)=,x|ux|ux|u(1)x|u 6= 0 x|u 6= 0.3 designate derivative constant e .Theorem 2.1, e = Pr (e, x, u)/x|u Pr (e, x, u)/x|u constant termsx|u x|u (and consequently, x|u ) since Pr (e, x, u) = Kx x|u Pr (e, x, u) = Kx x|u ,3. either previous parameters zero, use differential approach Darwiche (2000)compute derivative directly.269fiChan & DarwicheKx = Pr (u)Pr (e | x, u) Kx = Pr (u)Pr (e | x, u) constants termsx|u x|u . substituting y, e z, e e Theorem 2.1, get:y,e =Pr (y, e)x|u=Pr (y, e, x, u) Pr (y, e, x, u);x|ux|u(2)z,e =Pr (z, e)x|u=Pr (z, e, x, u) Pr (z, e, x, u).x|ux|u(3)Now, want enforce Difference constraint, Pr (y | e) Pr (z | e) ,suffices ensure Pr (y, e) Pr (z, e) Pr (e). Suppose previous constrainthold, wish establish applying change meta parameterx|u . change leads change e Pr (e). also changes Pr (y, e) Pr (z, e)y,e z,e , respectively. Hence, enforce Difference constraint, needsolve following inequality:[Pr (y, e) + y,e ] [Pr (z, e) + z,e ] [Pr (e) + e ].Rearranging terms, get following result.Corollary 2.1 satisfy Difference constraint, need change meta parameter x|u , that:Pr (y, e) Pr (z, e) Pr (e) [y,e + z,e + e ],constants defined Equations 1, 2 3.similarly solve parameter changes enforce Ratio constraint,Pr (y | e)/Pr (z | e) , following inequality:[Pr (y, e) + y,e ]/[Pr (z, e) + z,e ] .Rearranging terms, get following result.Corollary 2.2 satisfy Ratio constraint, need change meta parameter x|u, that:Pr (y, e) Pr (z, e) [y,e + z,e ],constants defined Equations 2 3.Difference Ratio constraints, solution , any, alwaysone two forms:q, computed q < 0, case new value meta parameter x|umust interval [0, p + q].q, computed q > 0, case new value meta parameter x|umust interval [p + q, 1].270fiWhen Numbers Really Matter?Note p current value meta parameter x|u (before change). manyparameters, intervals empty and, therefore, way changemeta parameters enforce constraint.question solve inequalities, efficiently, meta parameters. Note may one possible parameter change would enforcegiven constraint, need identify changes. either Corollary 2.12.2, easily solve amount change needed, , know followingprobabilities: Pr (e), Pr (y, e), Pr (z, e), Pr (e, x, u), Pr (e, x, u), Pr (y, e, x, u), Pr (y, e, x, u),Pr (z, e, x, u), Pr (z, e, x, u). leads following complexity technique.Corollary 2.3 algorithm compute Pr (i, x, u), given instantiation i, family instantiations x, u every variable X, time O(f ),solve Corollaries 2.1 2.2 parameters time O(f ). runningalgorithm three times, = e, = y, e, finally = z, e.Recall family variable X set containing X, parents Ubelief network.join-tree algorithm (Jensen, Lauritzen, & Olesen, 1990) differential approach (Darwiche, 2000) compute Pr (i, x, u), given instantiationfamily instantiations x, u every variable X O(n exp w) time. Here, n numbervariables belief network, w width given elimination order. SamIamuses differential approach, thus running time identify possible parameterchanges network also O(n exp w). Note also time needed answerone simplest queries, computing probability evidence e.2.2 Multi-Valued Variablesresults easily extended multi-valued variables, long assume modelchanging co-varying parameters one changes (Darwiche, 2000; Kjrulff &van der Gaag, 2000). parameter x|u changes, need use scheme changeparameters, xi |u xi 6= x, order ensure sum-to-one constraint.common way use proportional scheme. scheme,change parameters ratios remain same.example, suppose three parameters x1 |u = .6, x2 |u = .3 x3 |u = .1.x1 |u changes .8, two parameter values changed x2 |u = .3(.2/.4) = .15x3 |u = .1(.2/.4) = .05 accordingly. define meta parameter x|usimultaneously changes parameters according proportional scheme.obtain linear relation Pr (e) x|u , partial derivative given by:Pr (e)Pr (e, x, u)=x|ux|uPxi 6=x Pr (e, xi , u)Pxi 6=x xi |u.similar result Theorem 2.1, way groupedvalues xi 6= x value x. use Corollaries 2.1 2.2 solveDifference Ratio constraints.present another example illustrate results used practice.271fiChan & DarwicheExample 2.1 Consider network Figure 3. Here, set evidencesmoke, report people evacuating building, i.e. e = smoke, report.got posteriors Pr (fire | e) = .25 Pr (tampering | e) = .02. thoughtcase posterior fire less .5 asked SamIam recommendnecessary changes enforce constraint, Pr(fire | e) Pr (fire | e) 0.five recommendations case, three could ruled based qualitativeconsiderations:1. increase prior fire .03 (from .01);2. increase prior tampering .80 (from .02);3. decrease Pr (smoke | fire) .003 (from .01);4. increase Pr (leaving | alarm) .923 (from .001);5. increase Pr (report | leaving) .776 (from .01).Clearly, sensible change either increase prior fire, decreaseprobability smoke without fire.example similar ones suggest identifying parameter changesmagnitudes inevitable developing faithful belief network, yet trivialexperts accomplish task visual inspection belief network, often duesize complexity. Sensitivity analysis tools SamIam help facilitateidentifying important parameters need fine-tuned order satisfy certainconstraints. course, given multiple constraints, need cautiousimplementing recommendation made SamIam due one constraint, mayresult violating constraints. case, parameter changes recommendedSamIam used help experts focusing attention relevantparameters.Moreover, previous examples illustrate need develop analytic toolsunderstand explain sensitivity queries certain parameter changes.also need reconcile sensitivities exhibited examples previous experimental studies demonstrating robustness probabilistic queries small parameterchanges certain application areas, diagnosis (Pradhan et al., 1996). addressparticular questions next two sections.3. Sensitivity Probabilistic Queries Parameters Changesstarting point understanding sensitivity query Pr (y | e) changesmeta parameter x|u analyze derivative Pr (y | e)/x|u . analysis,assume X binary, variables network multi-valued.following theorem provides simple bound derivative, terms Pr (y | e)Pr (x | u) only. use simple bound study effect changes metaparameters probabilistic queries.272fiWhen Numbers Really Matter?6pd bound 40.8200.60.40.20.4Pr(x| u)Pr(y|e)0.20.60.8Figure 4: plot upper bound partial derivative Pr (y | e)/x|u , givenTheorem 3.1, Pr (x | u) Pr (y | e).Theorem 3.1 X binary variable belief network, then:4Pr (y | e)Pr (y | e)(1 Pr (y | e)).x|uPr (x | u)(1 Pr (x | u))bound Theorem 3.1 tight, show later examplederivative assumes bound exactly. main point note boundindependent given belief network.5plot bound Pr (x | u) Pr (y | e) shown Figure 4. numberobservations order plot:extreme values Pr (x | u), bound approaches infinity, thus smallabsolute change meta parameter x|u big impact queryPr (y | e).hand, bound approaches 0 extreme values query Pr (y | e).Therefore, small absolute change meta parameter x|u small effectabsolute change query.One implications result belief network queriesinterest Pr (y | e) extreme values, queries robust smallchanges network parameters. course assumes robustness understood4. theorem results follow requires x|u 6= 0 x|u 6= 1, since useexpression Equation 2.1 conditions.5. Note exact closed form derivative Pr (y | e)/x|u (Darwiche, 2000; Greiner,Grove, & Schuurmans, 1997), form includes terms specific given belief network.273fiChan & DarwicheXEFigure 5: network used Example 3.1.small change absolute value given query. Interestingly enough,disease diagnosed finding ethat is, probability Pr (y | e) quite highsurprising queries would robust small perturbationsnetwork parameters. seems explain results Pradhan et al. (1996),robustness confirmed queries Pr (y | e) .9.Another implication result one careful changingparameters extreme. parameters potentially influential onemust handle care.Therefore, worst situation robustness viewpoint materializes one extreme parameters non-extreme queries. case, queries sensitivesmall variations parameters.Example 3.1 Consider network structure Figure 5. two binary nodes, Xrespective parameters x , x , . assume E deterministicbinary node value E e iff X = . dictates following CPT E:Pr (e | x, y) = 1, Pr (e | x, y) = 1, Pr (e | x, y) = 0 Pr (e | x, y) = 0. conditionalprobability Pr (y | e) expressed using root parameters x as:Pr (y | e) =x.x + xSince x /x = 1 x /x = 1, derivative Pr (y | e) respect metaparameter x given by:Pr (y | e)x==(x + x )y x (y )(x + x )2.(x + x )2equal upper bound given Theorem 3.1:Pr (y | e)(1 Pr (y | e))Pr (x)(1 Pr (x))==(x )(x )x x (x + x )2.(x + x )2Now, set x = , derivative becomes:Pr (y | e)1=,x4x x274fiWhen Numbers Really Matter?x (or x ) approaches 0, derivative approaches infinity. Finally, set x == , Pr (y | e) = .5, keep constant change x0, get new result Pr (y | e) = 0.Example 3.1 illustrates three points. First, shows bound Theorem 3.1tight, i.e. construct belief network assumes bound. Second, givesexample network derivative Pr (y | e)/x|u tends infinity, thereforecannot bound derivative constant. Finally, shows infinitesimal absolutechange meta parameter (changing x 0) induce non-infinitesimal absolutechange query (Pr (y | e) changes .5 0). following theorem, however,shows possible consider relative notion change.Theorem 3.2 Assume x|u .5 without loss generality.6 Suppose x|uinfinitesimal change applied meta parameter x|u , leading change Pr (y | e)query Pr (y | e). have:Pr (y | e)x|u.Pr (y | e) 2x|ufunction f (x), quantity:(f (x) f (x0 ))/f (x0 ),(x x0 )/x0(xx0 )0limtypically known sensitivity f x x0 . Therefore, Theorem 3.2 showssensitivity Pr (y | e) x|u bounded.example application Theorem 3.2, consider Example 3.1 again. changex 0 amounts relative change | /| = 1. corresponding changePr (y | e) .5 0 amounts relative change | .5/.5| = 1. Hence, relativechange query great viewpoint.7relative change Pr (y | e) may greater double relative change x|unon-infinitesimal changes derivative Pr (y | e)/x|u depends valuex|u (Darwiche, 2000; Jensen, 1999). Going back Example 3.1, set x = .5= .01, obtain result Pr (y | e) = .01. increase x .6, relative change20%, get new result Pr (y | e) = 0.0149, relative change 49%,double relative change x .question is: Suppose change meta parameter x|u arbitraryamount (not infinitesimal amount), say corresponding changequery Pr (y | e)? following result.Theorem 3.3 Let O(x | u) denote odds x given u: O(x | u) = Pr (x | u)/(1 Pr (x |u)), let O(y | e) denote odds given e: O(y | e) = Pr (y | e)/(1 Pr (y | e)).Let O0 (x | u) O0 (y | e) denote odds applied arbitrary change6. binary variable X, x|u > .5, instead choose meta parameter x|u without lossgenerality.7. consider meta parameter x = 1 instead, relative change x amount/(1 ). Theorem 3.2 applicable case (assuming close 0) sincetheorem requires chosen meta parameter greater .5.275fiChan & Darwichemeta parameter x|u X binary variable belief network. changepositive, then:O(x | u)O0 (y | e)O0 (x | u);O0 (x | u)O(y | e)O(x | u)negative, then:O0 (x | u)O0 (y | e)O(x | u)0.O(x | u)O(y | e)(x | u)Combining results, have:| ln(O0 (y | e)) ln(O(y | e))| | ln(O0 (x | u)) ln(O(x | u))|.Theorem 3.3 means relative change odds given e boundedrelative change odds x given u, X binary variable.8 Note resultmakes assumptions whatsoever structure given belief network.illustrate theorem, go back Example 2.1. intend increaseposterior Pr (fire | e) .25 .5, e = smoke, report. log-odds changequery thus lo(Pr (y | e)) = | ln(O0 (y | e)) ln(O(y | e))| = 1.1. fiverecommendations made SamIam calculate log-odds change, lo(x|u ) =| ln(O0 (x | u)) ln(O(x | u))| parameter change:1. increase prior fire .03 (from .01): lo(x|u ) = 1.1;2. increase prior tampering .80 (from .02): lo(x|u ) = 5.3;3. decrease Pr (smoke | fire) .003 (from .01): lo(x|u ) = 1.2;4. increase Pr (leaving | alarm) .923 (from .001): lo(x|u ) = 9.4;5. increase Pr (report | leaving) .776 (from .01): lo(x|u ) = 5.8.Therefore, see recommended parameter changes satisfy Theorem 3.3,i.e. log-odds change query bounded log-odds change parameter.interesting special case Theorem 3.3 X root node X = .basic probability theory, have:O(x | e) = O(x)Pr (e | x).Pr (e | x)ratio Pr (e | x)/Pr (e | x) independent Pr (x), ratio O(x | e)/O(x) alsoindependent prior. Therefore, conclude that:O0 (x | e)O0 (x)=.O(x | e)O(x)(4)means find exact amount change needed meta parameter xorder induce particular change query Pr (x | e). need useexpensive technique Section 2 case.8. recently expanded results multi-valued variables, arbitrarily change parameters0x|u new values x|u, values x. resulting bound is: | ln(O0 (y | e)) ln(O(y | e))|00ln(maxx x|u /x|u ) ln(minx x|u/x|u ) (Chan & Darwiche, 2002).276fiWhen Numbers Really Matter?Example 3.2 Consider network Figure 3. Suppose e = report, smoke. Currently, Pr (tampering) = .02 Pr (tampering | e) = .50. wish increase conditional probability .65. compute new prior probability Pr 0 (tampering) usingEquation 4:.65/.35Pr 0 (tampering)/(1 Pr 0 (tampering))=,.50/.50.02/.98giving us Pr 0 (tampering) = .036, equal result obtained using SamIamSection 1. changes Pr (tampering) Pr (tampering | e) bring log-oddsdifference .616.Theorem 3.3 number implications. First, given particular query Pr (y | e)meta parameter x|u , used bound effect change x|uquery Pr (y | e). Going back Example 3.2, may wish know impactconditional probabilities apply change making Pr 0 (tampering) = .036.log-odds changes conditional probabilities network bounded.616. example, currently Pr (fire | e) = .029. Using Theorem 3.3, find rangenew conditional probability value Pr 0 (fire | e):!.029Pr 0 (fire | e)lnln.616,1 P r0 (fire | e).971giving us range .016 Pr 0 (fire | e) .053. exact value Pr 0 (fire | e), obtainedinference, .021, within computed bounds.Second, Theorem 3.3 used efficiently approximate solutions DifferenceRatio problems discussed Section 2. is, given desirable changevalue query Pr (y | e), use Theorem 3.3 immediately compute lower boundminimum change meta parameter x|u needed induce change. methodapplied constant time serve preliminary recommendation,method proposed Section 2 much expensive computationally.Third, suppose SamIam used recommend parameter changes wouldinduce desirable change given query. Suppose SamIam returnednumber changes, capable inducing necessary change.question is: one changes adopt? main principle appliedsituations adopt minimal change. minimal case?Theorem 3.3 reveals, notion minimality based amount absolute changemisleading. Instead, suggests one adopts change minimizesrelative change odds, queries shown robustchange precise sense.example, given two parameter changes, one .1 .15, another.4 .45. changes give us absolute change .05. However, firstchange log-odds change .462, second one log-odds change .205.Therefore, two parameter changes give us absolute change differentamounts log-odds change.hand, two parameter changes give us relative changealso different amounts log-odds change. example, given two parameterchanges, one .1 .2, another .2 .4. changes double original277fiChan & Darwicheparameter value. However, first change log-odds change .811, secondone log-odds change .981.Finally, result used obtain better intuitive understanding parameterchanges matter, topic discuss next section.4. Changes (Dont) Matterreturn central question: changes network parameters mattermatter? mentioned earlier, experimental studiesinvestigating robustness belief networks parameter changes (Pradhan et al.,1996). also shown simple intuitive examples networkssensitive small parameter changes. calls better understandingeffect parameter changes queries, one intuitively sort situationschanges matter. goal section developunderstanding looking closely implications Theorem 3.3.start first highlighting difference theorem previous resultssensitivity analysis.4.1 Network-Specific Sensitivity AnalysisOne main differences results sensitivity analysis approachesneed know belief network, hence, need performinference. clarify difference, compare sensitivity function approach(van der Gaag & Renooij, 2001), computes sensitivity function relatesquery, f (x), parameter, x, form:f (x) =ax+b,cx+da, b, c, constants depend given network computedperforming inference suggested van der Gaag Renooij (2001).Going back Example 2.1, express query Pr (fire | smoke, report)function parameter x = Pr (smoke | fire). function given by:f (x) =0.003165,0.9684 x + 0.003165plot function Figure 6. see current parameter value .01,query value .25, decrease .003, query value increases .5,one suggested parameter changes SamIam.However, find bound relations query parameterusing Theorem 3.3, without inference network (and without knowingnetwork). example, changing current parameter value .01 .003, newquery value within bounds .09 .53. hand, wantquery value increase .5, least decrease parameter value .01.003, increase .03.278fiWhen Numbers Really Matter?______Pr(fire|smoke, report)Pr(fire| smoke, report)10.50.80.40.60.30.40.20.20.1___0.20.40.60.81___Pr(smoke, fire)0.0050.010.0150.02Pr(smoke, fire)Figure 6: plot query Pr (fire | smoke, report) parameter Pr (smoke |fire). second graph shows magnification first graph regionPr (smoke | fire) 0 .02.4.2 Assuring Query RobustnessOne important issues yet settle is: mean parameterchange matter? One think least three definitions. First, absolutechange probability Pr (y | e) small. Second, relative change probabilityPr (y | e) small. Third, relative change odds O(y | e) small. first notionone prevalent literature, shall adopt rest section.Suppose belief network diagnostic application suppose concerned robustness query Pr (y | e) respect changes networkparameters. application, particular disease e particular findingpredicts disease, Pr (y | e) = .9. Let us define robustness caseabsolute change .05 given query. Now, let X binary variablenetwork let us ask: kind changes parameters X guaranteedkeep query within desirable range? use Theorem 3.3 easily answerquestion. First, changing parameter , want value queryremain .95, must ensure that:| ln((p + )/(1 p )) ln(p/(1 p))| | ln(.95/.05) ln(.9/.1)| = .7472,p current value parameter. Similarly, want ensure queryremains .85, want ensure that:| ln((p + )/(1 p )) ln(p/(1 p))| | ln(.85/.15) ln(.9/.1)| = .4626.Figure 7 plots permissible change function p, current valueparameter. main point observe amount permissible changedepends current value p, smaller changes allowed extreme values p.also interesting note easier guarantee query stay .95guarantee stays .85. general, likely parameter change reduce279fiChan & Darwiche0.150.10.050.20.40.60.81p0.050.10.15Figure 7: amount parameter change would guarantee query Pr (y | e) = .9stay within interval [.85, .95], function current parameter valuep. outer envelope guarantees query remain .95, innerenvelope guarantees query remain .85.0.040.020.20.40.60.81p0.020.04Figure 8: amount parameter change would guarantee query Pr (y | e) = .6stay within interval [.55, .65], function current parameter valuep. outer envelope guarantees query remain .65, innerenvelope guarantees query stay .55.value query close 1 (and increase value query close0). Finally, increasing parameter, parameter value close .4allow biggest absolute change. decreasing parameter, valueclose .6 allow biggest absolute change.let us repeat exercise assuming initial value queryPr (y | e) = .6, yet insisting measure robustness. Figure 8 plots280fiWhen Numbers Really Matter?86lo40.8200.6Pr(x| u)0.40.20.4Pr(x| u)0.20.60.8Figure 9: plot log-odd difference, lo = | ln(O0 (x | u)) ln(O(x | u))|,Pr (x | u) Pr 0 (x | u).lololo6465534343222110.20.40.60.81p10.20.40.60.81p0.20.40.60.81pFigure 10: plots log-odd difference, lo = | ln(O0 (x | u)) ln(O(x | u))|,new parameter value p0 = Pr 0 (x | u). figures correspond differentinitial values parameter, p = Pr (x | u) = .1, .5, .9, respectively.permissible changes function p, current value parameter. Again,amount permissible change becomes smaller probability p approaches 0 1.main point emphasize permissible changes much smallerprevious example, since initial value query extreme. Therefore,query much less robust previous one.generally, Figure 9 plots log-odds difference, | ln(O0 (x | u)) ln(O(x | u))|,Pr (x | u) = p Pr 0 (x | u) = p + , Figure 10 shows cross-sections Figure 9three different values p. Again, plots explain analytically affordabsolute changes non-extreme probabilities (Pradhan et al., 1996; Poole, 1998).281fiChan & DarwicheFigure 10, also notice although plot symmetric p = .5,p = .1 p = .9, i.e. absolute changes p p give us different amountslog-odds change. example, changing parameter .1 .05 give us largerlog-odds change changing parameter .1 .15. also notice plotsp = .1 p = .9 mirror images other. Therefore, log-odds changecomplementary parameter changes x|u x|u .close section emphasizing figures identify parameter changesguarantee keeping queries within certain ranges. However, belief networkspecific properties, specific topology, possible query robustparameter changes outside identified bounds.5. Conclusionpaper, presented efficient technique fine-tuning parameters beliefnetwork. technique suggests minimal changes network parameters ensurecertain constraints enforced probabilistic queries. Based technique,experimented belief networks, find networkssensitive parameter changes previous experimental studies seem suggest.observation leads us analytic study effect parameter changes,aim characterizing situations parameter changes matter.reported number results direction. central result shows beliefnetworks robust specific sense: relative change query odds boundedrelative change parameter odds. closer look result, meaning,implications provides interesting characterizations parameter changesmatter, explains analytically previous experimental resultsobservations matter.Acknowledgmentsshorter version paper appeared Proceedings 17th Conference Uncertainty Artificial Intelligence (UAI-01), pp. 6574. work partially supportedNSF grant IIS-9988543, MURI grant N00014-00-1-0617, DiMI grant 00-10065.Appendix A. ProofsTheorem 2.1 derivative Pr (e) respect meta parameter x|u givenby:Pr (e, x, u) Pr (e, x, u)Pr (e)=,x|ux|ux|ux|u 6= 0 x|u 6= 0.282fiWhen Numbers Really Matter?Proof Russell et al. (1995), semantics first derivative Pr (e) respectparameter x|u given by:9Pr (e)Pr (e, x, u)=,x|ux|ux|u 6= 0, and:Pr (e, x, u)Pr (e)=,x|ux|ux|u 6= 0. x|u = x|u x|u = 1 x|u , have:Pr (e)x|u=Pr (e) Pr (e)x|ux|u=Pr (e, x, u) Pr (e, x, u),x|ux|ux|u 6= 0 x|u 6= 0.2Theorem 3.1 X binary variable belief network, then:Pr (y | e)Pr (y | e)(1 Pr (y | e)).x|uPr (x | u)(1 Pr (x | u))Proof Darwiche (2000), derivative Pr (y | e)/x|u equal to:Pr (y | e)Pr (y, x, u | e) Pr (y | e)Pr (x, u | e).=x|uPr (x | u)Since:Pr (y | e)Pr (y | e) Pr (y | e),=x|ux|ux|uhave:Pr (y | e)x|u==Pr (y, x, u | e) Pr (y | e)Pr (x, u | e) Pr (y, x, u | e) Pr (y | e)Pr (x, u | e)Pr (x | u)Pr (x | u)Pr (y, x, u | e) Pr (y | e)Pr (x, u | e) Pr (x | u)(Pr (y, u | e) Pr (y | e)Pr (u | e)).Pr (x | u)(1 Pr (x | u))order find upper bound derivative, would like bound termPr (y, x, u | e)Pr (y | e)Pr (x, u | e). Since, Pr (y, x, u, e) Pr (y, u, e) Pr (y, x, u, e)Pr (x, u, e), have:Pr (y, x, u | e) Pr (y | e)Pr (x, u | e) Pr (y, x, u | e) Pr (y | e)Pr (y, x, u | e)= Pr (y, x, u | e)Pr (y | e)Pr (y, u | e)Pr (y | e).9. allow notations Pr (e)/x|u Pr (e)/x|u assuming Pr (e) functions x|u x|u ,even though allowed belief networks change x|u x|u .283fiChan & DarwicheTherefore, upper bound derivative given by:Pr (y | e)Pr (y, u | e)Pr (y | e) Pr (x | u)(Pr (y, u | e) Pr (y | e)Pr (u | e)),x|uPr (x | u)(1 Pr (x | u))equal following term:Pr (y | e)Pr (y, u | e) Pr (y | e)Pr (y, u | e)+Pr (x | u)1 Pr (x | u)(1 Pr (x | u))Pr (y | e)Pr (y, u | e) + Pr (x | u)Pr (y | e)Pr (y, u | e)=Pr (x | u)(1 Pr (x | u))Pr (y, u | e)Pr (y | e) Pr (x | u)(P r(y, u | e) Pr (y | e)Pr (u | e))=.Pr (x | u)(1 Pr (x | u))Since Pr (y, u | e) Pr (y | e) Pr (y, u | e) Pr (y | e), upper boundderivative given by:Pr (y | e)x|u=Pr (y | e)Pr (y, u | e) Pr (y | e)Pr (y, u | e)+Pr (x | u)1 Pr (x | u)Pr (y | e)Pr (y | e) Pr (y | e)Pr (y | e)+Pr (x | u)1 Pr (x | u)Pr (y | e)(1 Pr (y | e)).Pr (x | u)(1 Pr (x | u))order find lower bound derivative, note Pr (y | e) = 1 Pr (y | e),thus Pr (y | e)/x|u = Pr (y | e)/x|u . Therefore, get lower boundfinding upper bound derivative Pr (y | e)/x|u multiplying 1:Pr (y | e)x|uPr (y | e)(1 Pr (y | e))Pr (x | u)(1 Pr (x | u))=Pr (y | e)(1 Pr (y | e)).Pr (x | u)(1 Pr (x | u))Combining upper bound lower bound, have:Pr (y | e)Pr (y | e)(1 Pr (y | e)).2x|uPr (x | u)(1 Pr (x | u))Theorem 3.2 Assume x|u .5 without loss generality. Suppose x|uinfinitesimal change applied meta parameter x|u , leading change Pr (y | e)query Pr (y | e). have:Pr (y | e)x|u.Pr (y | e) 2x|u284fiWhen Numbers Really Matter?Proof x|u infinitesimal, Theorem 3.1:Pr (y | e)x|uPr (y | e)'x|uPr (y | e)(1 Pr (y | e)).Pr (x | u)(1 Pr (x | u))Arranging terms, have:Pr (y | e)Pr (y | e)1 Pr (y | e) x|u1 Pr (x | u) x|u1 x|u.5 x|u=x|u2,x|usince Pr (x | u) = x|u .5.2Theorem 3.3 Let O(x | u) denote odds x given u: O(x | u) = Pr (x | u)/(1Pr (x |u)), let O(y | e) denote odds given e: O(y | e) = Pr (y | e)/(1 Pr (y | e)).Let O0 (x | u) O0 (y | e) denote odds applied arbitrary changemeta parameter x|u X binary variable belief network. changepositive, then:O(x | u)O0 (y | e)O0 (x | u);0(x | u)O(y | e)O(x | u)negative, then:O0 (x | u)O0 (y | e)O(x | u)0.O(x | u)O(y | e)(x | u)Combining results, have:| ln(O0 (y | e)) ln(O(y | e))| | ln(O0 (x | u)) ln(O(x | u))|.Proof obtain result integrating bound Theorem 3.1. particular,0change x|u x|u> x|u , consequently Pr (y | e) changes Pr 0 (y | e),separate variables upper bound derivative Theorem 3.1, integrateintervals, yield:Z Pr 0 (y|e)Pr (y|e)dPr (y | e)Pr (y | e)(1 Pr (y | e))Z 0x|ux|udx|u.x|u (1 x|u )gives us solution:ln(Pr 0 (y | e)) ln(Pr (y | e)) ln(1 Pr 0 (y | e)) + ln(1 Pr (y | e))00ln(x|u) ln(x|u ) ln(1 x|u) + ln(1 x|u ),285fiChan & Darwichetaking exponentials, have:0 /(1 0 )x|uPr 0 (y | e)/(1 Pr 0 (y | e))x|u,Pr (y | e)/(1 Pr (y | e))x|u /(1 x|u )equivalent to:O0 (x | u)O0 (y | e).O(y | e)O(x | u)Similarly, separate variables lower bound derivative Theorem 3.1, integrate intervals, yield:Z Pr 0 (y|e)Pr (y|e)dPr (y | e)Pr (y | e)(1 Pr (y | e))Z 0x|ux|udx|u.x|u (1 x|u )gives us solution:ln(Pr 0 (y | e)) ln(Pr (y | e)) ln(1 Pr 0 (y | e)) + ln(1 Pr (y | e))00ln(x|u) + ln(x|u ) + ln(1 x|u) ln(1 x|u ),taking exponentials, have:x|u /(1 x|u )Pr 0 (y | e)/(1 Pr 0 (y | e))00 ),Pr (y | e)/(1 Pr (y | e))x|u /(1 x|uequivalent to:O0 (y | e)O(x | u)0.O(y | e)(x | u)0Therefore, following inequality x|u> x|u :O(x | u)O0 (y | e)O0 (x | u).O0 (x | u)O(y | e)O(x | u)0hand, change x|u x|u< x|u , instead integratex|u . integrals satisfy two inequalities:0x|uZ Pr (y|e)Pr 0 (y|e)Z Pr (y|e)Pr 0 (y|e)Z x|udPr (y | e)Pr (y | e)(1 Pr (y | e))dPr (y | e)Pr (y | e)(1 Pr (y | e))0x|udx|u;x|u (1 x|u )Z x|u0x|udx|u.x|u (1 x|u )solve inequalities similarly get result:O0 (x | u)O0 (y | e)O(x | u)0.O(x | u)O(y | e)(x | u)00Combining results x|u> x|u x|u< x|u , have:| ln(O0 (y | e)) ln(O(y | e))| | ln(O0 (x | u)) ln(O(x | u))|.2286fiWhen Numbers Really Matter?ReferencesCastillo, E., Gutierrez, J. M., & Hadi, A. S. (1997). Sensitivity analysis discrete Bayesiannetworks. IEEE Transactions Systems, Man, Cybernetics, 27, 412423.Chan, H., & Darwiche, A. (2002). distance measure bounding probabilistic beliefchange. Proceedings Eighteenth National Conference Artificial Intelligence(AAAI), pp. 539545.Coupe, V. M. H., Peek, N., Ottenkamp, J., & Habbema, J. D. F. (1999). Using sensitivity analysis efficient quantification belief network. Artificial IntelligenceMedicine, 17, 223247.Darwiche, A. (2000). differential approach inference Bayesian networks. Proceedings 16th Conference Uncertainty Artificial Intelligence (UAI), pp.123132.Greiner, R., Grove, A., & Schuurmans, D. (1997). Learning Bayesian nets performwell. Proceedings 13th Conference Uncertainty Artificial Intelligence(UAI), pp. 198207.Jensen, F. V., Lauritzen, S., & Olesen, K. (1990). Bayesian updating recursive graphicalmodels local computation. Computational Statistics Quarterly, 4, 269282.Jensen, F. V. (1999). Gradient descent training bayesian networks. ProceedingsFifth European Conference Symbolic Quantitative Approaches ReasoningUncertainty (ECSQARU), pp. 190200.Jensen, F. V. (2001). Bayesian Networks Decision Graphs. Springer-Verlag, Inc., NewYork.Kjrulff, U., & van der Gaag, L. C. (2000). Making sensitivity analysis computationallyefficient. Proceedings 16th Conference Uncertainty Artificial Intelligence(UAI), pp. 317325.Laskey, K. B. (1995). Sensitivity analysis probability assessments Bayesian networks.IEEE Transactions Systems, Man, Cybernetics, 25, 901909.Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks Plausible Inference. Morgan Kaufmann Publishers, Inc., San Mateo, California.Poole, D. (1998). Context-specific approximation probabilistic inference. Proceedings14th Conference Uncertainty Artificial Intelligence (UAI), pp. 447454.Pradhan, M., Henrion, M., Provan, G., Del Favero, B., & Huang, K. (1996). sensitivitybelief networks imprecise probabilities: experimental investigation. ArtificialIntelligence, 85, 363397.Russell, S., Binder, J., Koller, D., & Kanazawa, K. (1995). Local learning probabilisticnetworks hidden variables. Proceedings Fourteenth International JointConference Artificial Intelligence (IJCAI), pp. 11461152.van der Gaag, L. C., & Renooij, S. (2001). Analysing sensitivity data probabilistic networks. Proceedings 17th Conference Uncertainty Artificial Intelligence(UAI), pp. 530537.287fiJournal Articial Intelligence Research 17 (2002) 83135Submitted 10/01; published 08/02Monitoring Teams Overhearing:Multi-Agent Plan-Recognition Approachgalk@cs.biu.ac.ilGal A. KaminkaComputer Science DepartmentBar Ilan UniversityRamat Gan 52900, Israelpynadath@isi.edutambe@usc.eduDavid V. PynadathMilind TambeComputer Science Department Information Sciences InstituteUniversity Southern California4676 Admiralty WayLos Angeles, CA 90292, USAAbstractRecent years seeing increasing need on-line monitoring teams cooperating agents, e.g., visualization, performance tracking. However, monitoringdeployed teams, often cannot rely agents always communicate statemonitoring system. paper presents non-intrusive approach monitoringoverhearing, monitored team's state inferred (via plan-recognition) teammembers' routine communications, exchanged part coordinated task execution,observed (overheard) monitoring system. Key challenges approach include demanding run-time requirements monitoring, scarceness observations(increasing monitoring uncertainty), need scale-up monitoring address potentially large teams. address these, present set complementary novel techniques,exploiting knowledge social structures procedures monitored team: (i)ecient probabilistic plan-recognition algorithm, well-suited processing communications observations; (ii) approach exploiting knowledge team's social behavior predict future observations execution (reducing monitoring uncertainty);(iii) monitoring algorithms trade expressivity scalability, representingcertain useful monitoring hypotheses, allowing number agentsdierent activities represented single coherent entity. present empiricalevaluation techniques, combination apart, monitoring deployed teamagents, running machines physically distributed across country, engagedcomplex, dynamic task execution. also compare performance techniqueshuman expert novice monitors, show techniques presented capablemonitoring human-expert levels, despite diculty task.1. IntroductionRecent years seen tremendous growth applications involving distributed multi-agentteams, formed agents collaborate specic joint task (e.g., Jennings, 1995; Pechoucek, Marik, & Stepankova, 2000, 2001; Kumar & Cohen, 2000; Kumar, Cohen, &Levesque, 2000; Horling, Benyo, & Lesser, 2001; Lenser, Bruce, & Veloso, 2001; Barber &Martin, 2001). growth led increasing need monitoring techniques allowc 2002 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiKaminka, Pynadath, & Tambesynthetic agent human operator monitor identify state distributed team.Previous work discussed critical role monitoring visualization (e.g., Ndumu,Nwana, Lee, & Collis, 1999), identifying failures execution (e.g., Horling et al., 2001),providing advice improve performance (e.g., Aiello, Busetta, Dona, & Serani, 2001),facilitating collaboration monitoring agent members team(e.g., Grosz & Kraus, 1996).paper focuses monitoring cooperative agent teams overhearing internal communications.allows human operator synthetic agent monitorcoordinated execution task, listening messages team-members exchangeother.contrasts previous techniques impractical settingsdirect observations team members unavailable (e.g., team-membersphysically distributed away observer), large-scale applications composedalready-deployedagents dynamically integrated jointly execute task.example, one common technique,report-based monitoring, requiresmonitoredteam-member communicate state monitoring agent regular intervals,least whenever team-member changes state. reporting provides monitoringagent accurate information state team. Unfortunately, report-based monitoring suers several diculties monitoring large deployed teams interestreal-world (see Section 2 detailed discussion): First, requires intrusive modicationsbehavior agents, report state needed dierent monitoring applications. However, since agents already deployed, repeated modicationsbehavior agents dicult implement complex manage.par-ticular, legacy proprietary systems notoriously expensive modify (for instance,consider notorious modications address Year 2000 bug, also known Y2K).Second, bandwidth requirements report-based monitoring (which relies communication channels) unrealistic (Jennings, 1993, 1995; Grosz & Kraus, 1996; Pechouceketal., 2000, 2001; Vercouter, Beaune, & Sayettat, 2000). addition, network delaysunreliable lossy communication channels key concern report-based monitoringapproaches.therefore advocate alternative monitoring approach, based multi-agent keyholeplan-recognition (Tambe, 1996; Huber & Hadley, 1997; Devaney & Ram, 1998; Intille &Bobick, 1999; Kaminka & Tambe, 2000).approach, monitoring system infersunobservable state agents based observable actions, using knowledgeplans give rise actions. approach non-intrusive, requiring changesagents' behaviors; allows changes requested monitoring information.assumes access knowledge plans may explain observable actionhoweverknowledge readily available monitoring system assume deployedcollaborative environment. Indeed, cases, monitoring system may deployedhuman operator team. additional benet plan-recognition approachrely inference compensate occasional communication losses,therefore robust communication failures.general, observable actions agents distributed teamroutinecommunications, agents exchange part task execution (Ndumu et al., 1999).Fortunately, growing popularity agent integration tools (Tambe, Pynadath, Chauvat,Das, & Kaminka, 2000; Martin, Cheyer, & Moran, 1999) agent communications (Finin,84fiMonitoring Teams OverhearingLabrou, & Mayeld, 1997; Reed, 1998) increases standardization aspects agent communications, provides increasing opportunities observing interpreting inter-agentcommunications.assume monitored agents truthful messages, sincecommunicating teammates; attempting deceivemonitoring agent prevent overhearing (as deployed human operator team).Given (possibly stochastic) model plans agents mayexecuting, monitoring system using plan-recognition infer current stateagents observed routine messages.However, application plan-recognition techniques overhearing poses signicantchallenges. First, key characteristic overhearing task scarcity observations.Explanations overheard messages (i.e., observed actions) sometimes fairly easydisambiguate, uncertainty arises relatively observe:team members cannot practice continuously communicate amongstate (Jennings, 1995; Grosz & Kraus, 1996). Thus team-members changestate keeping quiet. Another key characteristic overhearing observableactions inherentlyagentlistening.multi-agent actions :sends messages.agents communicate, singleothers implicitly act role communicationsYet despite scarcity observable communications, multi-agent natureobserved actions, monitoring system must infer state agents team,times. Previous investigations multi-agent plan-recognition (Tambe, 1996; Devaney& Ram, 1998; Intille & Bobick, 1999; Kaminka & Tambe, 2000) typically madeassumption changes state agents observable eect: Uncertaintyresulted ambiguity explanations observed actions. Furthermore,investigations addressed settings observable actions individual (each actioncarried single agent).addition challenges unique overhearing, monitoring system mustaddress additional challenges stemming use monitoring service visualization.representation algorithms must support soft real-time response; reasoningmust done quickly useful visualization.Furthermore, real-world applicationsdemand techniques scale number agents increases, monitoring largeteams. However, many current representations plan-recognition computationally intense (e.g., Kjrul, 1992), address single-agent recognition tasks (e.g., Pynadath& Wellman, 2000). Multi-agent plan-recognition investigations typically explicitlyaddressed scalability concerns (Devaney & Ram, 1998; Intille & Bobick, 1999).paper presents Overseer, implemented monitoring system capable monitoring large distributed applications composed previously-deployed agents.Overseerbuilds previous work multi-agent plan-recognition (Tambe, 1996; Intille & Bobick,1999; Kaminka & Tambe, 2000) utilizing knowledge relationships agentsunderstand decisions interact. However, previous techniques proved insucient, Overseer includes number novel multi-agent plan-recognition techniquesaddress scarcity observations, well severe response-time scale-up requirements imposed realistic applications. Key contributions include: (i)linear timeprobabilistic plan-recognition representation associated algorithms, exploitnature observed communications eciency; (ii) method addressing unavailableobservations exploiting knowledgesocial procedures85teams eectively predictfiKaminka, Pynadath, & Tambe(and hence eectively monitor) future observations normal failed execution, thusallowing inference lack observations; (iii) YOYO*, algorithm usesteam-hierarchy )knowledge team organizational structure (model agent team(with dierent parallel activities taken individual agents) using single structure,instead modeling agent individually. YOYO* sacrices expressivity (the abilityaccurately monitor team certain coordination failure states) signicant gainseciency scalability.present rigorous evaluation Overseer's dierent monitoring techniques oneapplication domains show techniques presented result signicant boostsOverseer's monitoring accuracy eciency, beyond techniques explored previouswork. evaluate Overseer's capability address lossy observations, key concernreport-based monitoring. Furthermore, evaluate Overseer's performance comparisonhuman expert novice monitors, show Overseer's performance comparable human experts, despite diculty task, Overseer's reliancecomputationally-simple techniques. One key lessons draw Overseercombination computationally-cheap multi-agent plan-recognition techniques, exploiting knowledge expected structures interactions among team-members,competitive approaches focus accurate modeling individual agents (andmay computationally expensive).paper organized follows.Section 2 presents motivation designOverseer, using examples actual distributed application Overseerapplied.Section 3 presents novel single-agent plan-recognition representationassociated algorithms, particularly suited monitoring agent based observedcommunications. Section 4 explores several methods Overseer uses address uncertaintyusing representation monitoring team agents. Section 5 presents YOYO*,allows ecient reasoning using methods previously discussed. Section 6 presentsevaluation dierent techniques incorporated YOYO*. Section 7 contraststechniques presented previous related investigations, nally, Section 8 concludespresents plans future work. addition, several appendices present pseudocode algorithms discussed text, portions data used experiments,readers may wish replicate experiments.2. Motivation Illustrative ExamplesSeveral considerations, based experience actual distributed applications,directed us towards plan-recognition approach advocate paper. presentconsiderations context illustrative complex distributed application,also use evaluating Overseer Section 6. application, distributed team11 20 agents executes simulation evacuation civilians threatened location.integrated system allows human commander interactively provide locationsstranded civilians, safe areas evacuation key points. Simulated helicopterscoordinated mission evacuate civilians, relying various information agentsdynamically obtain information enemy threats, (re)plan routes avoid threatsobstacles, etc. distributed team composed diverse agents four dierent research groups: Quickset multi-modal command input agent (Cohen, Johnston, McGee,86fiMonitoring Teams OverhearingOviatt, Pittman, Smith, Chen, & Clow, 1997), Retsina route planner (Payne, Sycara,Lewis, Lenox, & Hahn, 2000), Ariadne information agent (Knoblock, Minton, Ambite, Ashish, Modi, Muslea, Philpot, & Tejada, 1998) eight synthetic helicopter pilots(Tambe, Johnson, Jones, Koss, Laird, Rosenbloom, & Schwamb, 1995).agents designed work together taskthey already builtdeployed prior creation team. team integrated using Teamcore(Tambe etal., 2000), accomplishes integration wrapping agentproxy maintains collaboration agents (via proxies). proxiesagents form team, jointly executing distributed application describedoriented program.team-program consists of:team hierarchy, team decomposes subteams, sub-subteams.plan hierarchy, contains team plans decompose subteam plansAssignment teams team hierarchy plans plan hierarchy.example, Figure 1-a shows part team/subteam hierarchy usedevacuation-domain (described below).Here, instance, TRANSPORT subteamFLIGHT-TEAM, subteam TASK-FORCE. Figure 1-b shows abbreviated planhierarchy domain.High-level team plans,compose team plans,Process-Orders,Evacuate,typically de-and, ultimately, leaf-levelplans executed individuals. Temporal transitions used constrain order execution plans. teams assigned execute plans, e.g., TASKFORCE team jointly executes Evacuate, TRANSPORT subteam executesTransport-Operations (Transport-Ops) step.team-oriented programapplication consists 40 team-plans. plans may get executed repeatedlythough, agent may execute hundreds plan steps part executionsingle team-oriented program.execute team-oriented program, proxy uses domain-independent teamworkmodel, called STEAM (Tambe, 1997).teamwork model automatically generatescommunication messages required ensure appropriate coordination among proxies.instance, STEAM requires agent privately obtains beliefbelterminatesteam plan, agent send message rest team terminateteam plan, along private beliefbelled termination. avoid jammingcommunication channels ood messages every single plan, STEAMchooses communicate selectively. Thus, whereas communicating initiationtermination every plan would led 2000 messages generatedone run, 100 messages get exchanged one run using STEAM (Tambeetal., 2000).Figure 2 displays messages exchanged among team members evac-uation application, use STEAM. rst message sent proxycalled teamquicksetmembers team TEAM-EVAC (another name TASKFORCE). content message indicates team terminate plancalleddetermine-number-of-helos.second message sent proxy called87fiKaminka, Pynadath, & TambeTASK FORCEEVACUATE [TASK FORCE].....GET ORDERSROLEFLIGHTTEAMESCORTROUTEPLANNERTRANSPORTESCORT ESCORTTRANSPORT ...LEADDIVISION 1FOLLOWPROCESSORDERS[TASK FORCE]EXECUTEMISSION[TASK FORCE]LANDINGZONEMANEUVERS[FLIGHT TEAM]FLY-FLIGHTPLANGETORDERS[FLIGHT TEAM][GET ORDERS]FLY-CONTROLROUTE....[FLIGHT TEAM](a).........ESCORTTRANSPORTOPERATIONS OPERATIONS[ESCORT][TRANSPORT](b)Figure 1: Portions team-hierarchy (a) plan-hierarchy (b) used domain.Dotted lines show temporal transitions.team_auto2 members subteam TEAM-ESCORT-FOLLOW (a subteam ESCORTS). content message indicates subteam establish commitment plan namedprepare-to-execute-mission.online appendix presents samplelogs overheard messages complete runs, well plan team hierarchiesevacuation application.discussed Section 1, capability automatically monitoring progressteam critical.need team monitoring amplied distributedsettings, since human operator one place cannot directly observe agents executingremote location.instance, trial runs evacuation simulation applicationdescribed above, monitoring sometimes required series frantic phone calls among humanoperators dierent states, trying verify successful execution systemoperating.even agent team co-located multiple computers oneroom, diversity agents made extremely dicult observer automaticallymonitor state team observing dierent agent output screens.Overseer built provide monitoring tracking routine communica-tions among agents (Figure 2).Using plan-recognition, allows humans agentsquery present future likely plans entire team, subteamsindividualsto monitor progress, compute likelihoods failure, etc. However, givenagent team communicates selectively plans executed, Overseer's planrecognition faces signicant uncertainty. Furthermore, Overseer must able answerqueries on-line, must therefore work eciently.discussed later, addressingchallenges required several novel team-based plan-recognition techniques developed.Several considerations led us away report-based monitoringTeamcore applications. First, report-based monitoring requires agents' code mod-ied communicate reports needed monitoring; monitoring requirements change88fiMonitoring Teams OverhearingLog Message Received; Fri Sep 17 18:27:54 1999:Logging Agent: teamquicksetMessage==> tell:content teamquickset terminate-jpg constant determine-number-of-helosnumber-of-helos-determined *yes* 4 4 98 kqml_string:receiver TEAM-EVAC 9 kqml_word:reply-with nil 3 kqml_word:team TEAM-EVAC 9 kqml_word:sender teamquickset 12 kqml_word:kqml-msg-id 21547+tsevet.isi.edu+7 22 kqml_wordLog Message Received; Fri Sep 17 18:30:35 1999:Logging Agent: TEAM_auto2Message==> tell:content TEAM_auto2 establish-commitment prepare-to-execute-mission58 kqml_string:receiver TEAM-ESCORT-FOLLOW 18 kqml_word:reply-with nil 3 kqml_word:team TEAM-ESCORT-FOLLOW 18 kqml_word:sender TEAM_auto2 10 kqml_word:kqml-msg-id 20752+dui.isi.edu+16 20 kqml_wordFigure 2: Example KQML messages used observations Overseer.89fiKaminka, Pynadath, & Tambeone application next, information needed agent.Un-fortunately, agents proxies already deployed several government laboratories universities.Modifying agents deployed location problematicintrusivemodications interfere carefully designed timing specications giventasks, requiring modications agent developers. distributed natureTeamcore implies centralized server controls behavioragents, instead changes required dierent proxy types.Indeed, general,modifying legacy proprietary applications (including integration architecture)course known dicult process, solution requires constant modicationsagents architecture scale up.second important consideration computational bandwidth requirementsreport-based monitoring. repeatedly noted literature, one cannot expectagents able communicate continuously fully monitor agents (e.g.,Jennings, 1993, 1995; Grosz & Kraus, 1996; Pechoucek et al., 2001; Vercouter et al., 2000).team 11 (used example paper), regularly scheduled state reportsagents required temporal resolution would require approximately 50,000 messagessent 15-minute run, number nearly doubling reach 20 agents.instead 11 agents report state changes, announcing plan initiationtermination, approximately 2,000 messages sent.However, stillorder-of-magnitude normal 100 messages exchanged11 agents part routine execution. Even network could support bandwidthnecessary report-based monitoring, also signicant computational burdenmonitoring system process incoming reports.hand, plan-recognition approach seemed like natural task.First, doesn't require changes behavior monitored agents, thussuitable monitoring agents already deployed. Second, doesn't addcomputational burdens monitored agents network, since usesobservations already available. Third, main knowledge source plan-recognition systems typically rely ona plan libraryis fact easily available accessible formmonitoring system team-oriented program used integrate agents,since operator deploying monitoring system assumed one describeintegration team-oriented program rst place. Thus plan-recognition's sometimescriticized assumption correct plan-library fact satised fully monitoringapplication.Note assumption holds even agents using integration architecture: knowledge rely (possibly stochastic) modelcomponents execution together, communications used integratethem. Therefore, paper focuses team-oriented programs (described above),techniques introduced appear generalizable types representation languagesdistributed systems, TMS (Decker, 1995), team-oriented programming (Tidhar,1993a) others. Furthermore, plan-library need contain implemetation detailsnames key steps. Thus even agents utilizing radically-dierent representationsplan-hierarchy monitored, long execution states correspondingteam-oriented program (which case order coordinateteam-members).90fiMonitoring Teams OverhearingMonitoring overhearing poses unique challenges previously discussed. However,also oers unique opportunities plan recognition. earlier stated assumptionagents truthful communications, seek deceive teammatesmonitoring system, prevent overhearing way (e.g., encryption).assumption justied monitoring system deployed operator monitoredagents, agent team-member. Failures team coordinate (e.g., due clockasynchrony unintentional erroneous messages) therefore cause corresponding failuresmonitoring. However, make additional assumptions messages beyondmade monitored agents themselves.assumption allows plan-recognition system treat observations certainty:message overheard terminating plancertainty indeed planplan recognition ambiguity.XX,monitoring system inferlonger executed. However, eliminateFirst, multiple instantiations planXmay exist,message specify one terminated. Second, upon termination plan,monitored team-member must often choose multiple alternative plan stepsfollowX,yet choice evident observations.Indeed, dicultymonitoring overhearing demonstrated human monitoring performance: Novicehuman monitors managed achieve approximately 60% accuracy average.3. Monitoring Team Agents Separate Individualssection, present representation associated baseline algorithms supportoverhearing based plan-hierarchy team-hierarchy.begin making as-sumption agent independence, observations beliefs one agent's stateexecution bearing beliefs another agent's state. assumptioncontrasted another: assume instead team-members successfulcoordination, knowing one agent begun executing joint plan would naturally increase likelihood teammates begun well, agents wouldconsidered independent. fact, successful teamworkrequiresinterdependency amongagents (Grosz, 1996).However, initial assumption agent independence provides baseline comparison,closely follows current approaches multi-agent plan recognition, oftenassume observations individual agent continuously available.Latersections (Sections 4 5) highlight unique challenges tackled monitoringoverhearing, take agent interdependencies account.thus begin maintaining separate plan recognizer agent.recog-nizer observes messages respective agent sends. basisobservations, recognizer maintains probabilistic estimate state executionvarious plans agent may currently executing. Knowledge plans assignedagents team memberships available application plan-hierarchyteam-hierarchy team-oriented program used constructing monitored application.Section 3.1 presents language use probabilistic representation teamoriented program.exploit various independence properties within team-oriented pro-grams achieve compact representation possible plan states agents. Sec-91fiKaminka, Pynadath, & Tambetion 3.2 presents algorithm updating recognizer's beliefs agents' planstates upon observation message.algorithm performs updateeciency gained exploiting particular semantics communicated messages, namelymessage observation indicates initiation/termination par-certainty.ticular planSection 3.3 presents algorithm updating recognizer'sbeliefs agents' plan statesmessage observed. absenceevidence, algorithm eciently updates recognizer's beliefs usingtemporal model agents' plan execution makes strong Markovian assumption.Finally, Section 3.4 presents overall recognition procedure, well illustrationcomplexity analysis procedure.3.1 Plan-State Representationaddress uncertainty monitoring probabilistic model supports quantitative evaluation recognized plan hypotheses. Since monitoring agentsduration execution, use time series plan-state variables.point time, agent's plan state state team-oriented programcurrently executing, i.e., path root leaf team-oriented program tree.represent plans program set boolean random variables,variableXtrepresent beliefs agent's actual state timevariablesfXt g.XfXt g,t.probability distributiontrue agent actively executing plantimedistribution takes account dependencies among dierentplans team-oriented program (e.g., parent-child relationships), well temporal dependencies plan state times+ 1.simplify dependencydone(X; t),1 execution terminatedstructure, useful introduce additional boolean random variables,true plantimet.Xexecuted timenumber possible representations capturing distribution performing inference variables.However, generality plan hierarchy,dynamic nature domain, requirements task eliminate existing approaches consideration. instance, could potentially generate DBNDynamicBelief Network (Kjrul, 1992)to represent probabilistic distribution planvariables. so, include nodes representing plan variables,representingdone(X; t).Xt ,welllinks among nodes represent structure planhierarchy (e.g., parent-child relationships, temporal constraints), conditional probability tables accordingly. also represent temporal progress teamincluding nodes variables next time slice,nodesXt+1links.Xt+1 .add linksXtnodes represent dynamics conditional probability tablestransition nodeXtnodeYt+1 (X6= ), wouldalso add binary nodes indicating observation message along transition. Thus,plan hierarchy(4Mplan nodes, corresponding DBN representation+ 2 ) = O(M 2 ) binary random variables.standard DBN inference algorithms maintain belief state,posterior probability distribution variables time slice,t,bt ,representingconditionedobservations made far (from time 0t). inference algorithms update92fiMonitoring Teams Overhearingbelief state incorporate new evidence variables,next time-tick's belief state,bt+1 .Xt ,also computeextract desired probability plan-state variables examining posterior probabilities storedbt .Given dependencystructure plan model, space time complexity performing inference using2DBN (either incorporating single observation, computing bt+1 )(2 )single agent.DBN method suciently ecient support on-line monitoring real-worlddomains, since every time step, recognizer must perform inferentialstep exponential computational complexity.existsingle-agentplan-recognitiontechniques avoid exponential complexity DBNs using representationinference algorithms aimed particular properties plan-recognition task (e.g.,Pynadath & Wellman, 2000).specialized representations avoid full generalityDBNs, still capturing broad class interesting planning agent models.Givenspecialized representation, single-agent plan-recognition algorithms exploitparticular structure plan models achieve ecient online inference.Drawing inspiration success work single-agent domains, adoptsimilar methodology multi-agent domain.words, developednovel plan-recognition representation suited capturing team-oriented programs.structural assumptions make representation support ecient inferencespecialized algorithms, well naturally supporting extension represent interagent dependencies (as discussed Section 4).represent team-oriented plan directed graph, whose vertices plans,whose edges signify temporal hierarchical decomposition transitions plans:Children edges denote hierarchical decomposition plan sub-plans.Sibling edgesdenote temporal orderings plans. Following structure plan hierarchy,variablesfXt g form directed connected graph, node Xt onehierarchical-decomposition incoming transition parent node (representing parentplan), number temporal incoming transitions plans precede orderexecution. graph may contain multiple nodes single plan, plan potential child multiple parent plans. node may number temporal outgoingtransitions immediate successor sibling nodes (representing plans may followorder execution), number hierarchical-decomposition outgoing transitionsnode'splanXt .rstchildren (i.e., executed rst decompositiongraph forms tree along hierarchical decomposition transitions,plan descendent. hand, may cycles along temporaltransitions (to siblings). words, plan may outgoing temporal transition(meaning selected execution upon termination),node temporal path leading back plan (meaning rst nodetemporal sequence plans may executed repeatedly). may also twoalternative temporal paths leading indirectly one node another.perform inference representation, borrow standard DBN inferencealgorithms' notion belief state,bt .DBN case, belief state representsposterior probability distribution variables time slice, t, conditionedobservations made far. addition, plan, distinguish state actualexecutionblockedstate, indicating execution terminated, execution93fiKaminka, Pynadath, & Tambesuccessor yet begun (perhaps agent process sendingmessage).bt (X; block )Thus,beliefXterminated, agentbt (X; :block ) belief time monitoredX , yet terminated. precisely, denePr(Xt ; done(X; + 1)jE ) bt (X; :block) Pr(Xt ; :done(X; + 1)jE ),begun execution successor;agent currently executingE denotes evidence received far. recognizer observesbt (X; block )message agent timet,updates previous belief state,bt+1 ,evidence new belief state,bt+1 ,incorporatingaccording method described Section3.2. observe message agent timenew belief state,bt ,t,propagates beliefusing method described Section 3.3 simulate plan executiontime.3.2 Belief Update Observed Messageobserving team communications, recognizer expect occasionally receiveevidence form messages (sent individual agent member) identify eitherplan initiation termination.incorporating evidence, exploit assumptionagents truthful messages. words, observe initiationmessage plan,X,timet,termination message plan,X,Xttrue certainty.timet,Likewise, observedone(X; + 1)true certainty.precisely, algorithms presented section specialized exploit prop-, either Pr(Xt j; E ) = 1Pr(done(X; t)j; E ) = 1, possible previously observed evidence, E .erty observed communications, observationThough messages assumed truthful, still remains ambiguity.message uniquely species relevantFirst,plan, uniquely specify relevant node.words, recognizer still unsure particularrefers to, since graph may contain multipleXtXtnode messagenodes consistent message. Fur-thermore, message announces termination plan (even ambiguitycorresponding node), still remains ambiguity next plan selectedagent.observations available overhearing tasks immediate interest us falllevel ambiguity. evacuation scenario example, two nodes corresponding planland-troops,one instanceland-troopspickingpeople transported another dropping o. recognizer observesmessage indicating agent initiated executionland-troops,ambiguity two instances currently relevant. Furthermore, mayexist ambiguity plan agent select terminatingland-troops.Algorithm 1 presents pseudo-code complete procedure incorporating evidence observations.Incorporating Evidence Observed Initiation Message (lines 38)Supposet, observed message, msg, corresponds initiation. oneX , consistent msg, know, certainty, agent executing X ,that, timeplan,regardless whatever evidence previously observed. Therefore, simply setbeliefXttrue 1.0. multiple plans consistentmsg, distributeunit probability consistent plan, weighted prior belief seeing given94fiMonitoring Teams OverhearingAlgorithm 1 Incorporate-Evidence(msg m, beliefs b, plans )01: Initialize distributions b ; bt+10:0 plans2:3:4:5:6:7:8:9:10:11:12:13:14:15:16:plans X 2 consistentinitiation messageplans W precede Xb0 (X; :block )b0 (X; :block ) + bt (W; block )wx wxelse {m termination message}plans 2 succeed Xb0 (Y; :block )b0 (Y; :block ) + bt (X; block )xy xyNormalize distribution b0plans X 2 b0 > 0bt+1 (X; :block )b0 (X; :block )(X; b0(X; :block ); b; )tmpXparent(tmp) 6= nullbt+1 (parent(tmp); :block )bt+1 (parent(tmp); :block ) + bt+1 (tmp; :block )tmpparent(tmp)Propagate-Downmessage. prior belief depends predecessor plansXmay terminatedprior seeing message.support computation beliefs transitions predecessor planssuccessors, well beliefs seeing message given transition, Overseer storestwo parameters:.former probability entering successor plan,given predecessor plan,W,completed:wxX,Pr(Xt jWt; done(W; + 1)).+1latter probability seeing message, given agent took speciedtransition:wxPr(msgt jWt ; done(W; + 1); Xt ).+1use previous runs acquire, producing frequency count transitionsruns (see Section 4.2 discussion usesuitable values parameters,messages seenOverseer).msg, time t, wishdistribute unit probability plans, X , (in unblocked state) consistentmsg. derive new belief plan X time + 1 follows:Therefore, given observation initiation message,msg; Xt+1 jE )Pr(Xt+1 jmsg; E ) = Pr(Pr(msg jE )denominator simply normalization factor, candidate plans,X.Therefore, ignore derivation, focus numerator,X Pr(X+ Pr(expand possible predecessor plans,/W,possible termination statesmsg; Xt+1 ; Wt ; done(W; + 1)jE )WWmsg; Xt+1 ; Wt ; :done(W; + 1)jE )95W:fiKaminka, Pynadath, & Tambesecond term 0, since cannot proceedWXWterminated.second term, expand joint probability component conditionalprobabilities:/X[Pr(Wmsg jWt ; done(W; + 1); Xt+1 ; E )Pr(Xt jWt; done(W; + 1); E )+1Pr(Wt ; done(W; + 1)jE )]assume probability sending message distribution plan transitions obey Markov property, independent plan historytimet,given current plan timet.Thus, rst two conditional probabilitiesindependent previous history observations. third exactly previous beliefWblocked:/X[Pr(Wmsg jWt ; done(W; + 1); Xt+1 ) Pr(Xt+1 jWt ; done(W; + 1))bt(W; block)]Xrst two conditional probabilities exactly parameters,/W:wx wx bt (W; block )(1)Lines 45 Algorithm 1 perform exactly derived summation Equation 1 (thenormalization step carried line 9 (see below). similar procedure followedmessage observed indicating terminationagent executingsuccessor. Thus,X(lines 68). case, knowX previous time step movedX 's potential successor plans , set beliefproportional transition probability, similar initiation message:msg; Yt+1 jE )Pr(Yt+1 jmsg; E ) = Pr(Pr(msg jE )denominator normalization factor ignore. expand numerator possible statesX 'sexecution:/ Pr(msg; Yt+1; Xt ; done(X; + 1)jE )+ Pr(msg; Yt+1 ; :Xt ; done(X; + 1)jE )+ Pr(msg; Yt+1 ; Xt ; :done(X; + 1)jE )+ Pr(msg; Yt+1 ; :Xt ; :done(X; + 1)jE )96fiMonitoring Teams Overhearingrst term nonzero, since others correspond states executioninconsistent observed message:/ Pr(msg; Yt+1; Xt ; done(X; + 1)jE )rewrite joint probability product conditional probabilities:/ Pr(msgjXt ; done(X; + 1); Yt ; E )Pr(Yt jXt ; done(X; + 1); E )Pr(Xt ; done(X; + 1)jE )+1+1use Markovian assumptions simplify conditional probabilities,rewrite third probability using belief state:/ Pr(msgjXt ; done(X; + 1); Yt ) Pr(Yt jXt ; done(X; + 1))bt (X; block)+1+1Finally, rewrite rst two conditional probabilities using parameters,/xy xy bt (X; block):(2)Lines 78 Algorithm 1 perform exactly derived summation Equation 2.Normalization sum (line 9).Line 9 normalizes sum recapture well-formed probability distribution. Note normalization step must take accountfact evidence may incorporated plan steps one ancestoranotherin case evidence ancestor plan probabilistically redundant.specic evidence (for descendent plan) useful visualization,accurate.Propagation Evidence (lines 1016)Finally, recalculated beliefs set (line11) changes recursively propagated decomposition hierarchyplan's children (line 12), via call Algorithm 2. addition, recalculated beliefspropagated plan's ancestors decomposition hierarchy (lines 1316), sinceevidence child plan active evidence parent active well. assumeknowledge relative likelihood child plans, treatequally likely.additional knowledge likelihoods, couldeasily exploit Propagate-Down algorithm.Algorithm 2 Propagate-Down(plan , probability , beliefs b, plans )1:2:3:4:5:fc j c 2 M; c rst child g= j C jplans c 2 Cbt (Y; :block )bt (Y; :block ) + 0C0+1+1Propagate-Down(c; 0; b; )97fiKaminka, Pynadath, & Tambe3.3 Belief Update Observationoverhearing tasks, great deal uncertainty agents completeexecution plan steps, since agents necessarily send messages upon everytermination initiation plan. Therefore, messages observed time t,+1 must calculated based possibility agents maysystem's beliefs timeinitiated terminated plans without sending messages. support necessarybelief update, need model plan execution provides us probability plantermination time (i.e.,Pr(done(X; t))).principle, probability distributionarbitrarily complex, structure may vary enormously domain domain,even plan plan within domain. domains, obtaining accuratemodel distribution requires complex knowledge acquisition domain expertselse complex learning process part agent. addition, accurate modelmay complex support ecient online inference.Overseer instead uses temporal model supports ecient inferencesimple parameter estimation procedures. Overseer models duration (leaf ) plan,X , exponential random variable. words, probability plan completingtime units increases 1 e X . single parameter, X , corresponds1/(mean duration X ), easily acquire domain experts previousexecution withinruns. inference, exponential random variable Markovian property,probability plan's completion timesPr(done(X; + 1)jXt ) 1independentlong agent executingt+1e x ;Xtime t. strong assump-tion may fully hold real-world domains, often good approximation.Also, error associated approximation may acceptable, given enormousgain inferential eciency (as show remainder section).eciency gains manifest Overseer rolls model forwardtime compute belief state next time slice. Given exponential randomvariable model plan duration, probability completion leaf plan constant,1e x ,planX.plans children, probability completion exactlyprobability completion last child (according temporal orderingchildren).computed probability plan termination, Overseer evaluatesplan agent may execute next. examines possible successors and, each, computes probability taking corresponding transition, conditioned fact1xy ),message observed (prior probability taking message (xy ).Again, mentioned Section 3.2, Overseer makes Markovian assumptionplan history timeaect likelihood various transitions. Givenassumption, combine two parameters,98,get desired conditionalfiMonitoring Teams Overhearingprobability transition, given observed message:Pr(Yt+1 jXt ; done(X; + 1); :msgt )(X; + 1); Yt+1 ) Pr(Yt+1 jXt ; done(X; + 1))= Pr(:msgt jXt ; donePr(:msgt jXt ; done(X; + 1))(1 xy )xy=Pr(:msgt jXt ; done(X; + 1); Zt+1 ) Pr(Zt+1 jXt ; done(X; + 1))X(1=X(1ZZ= (1xy )xyxz )xzxy )xyX(3)normalizing denominator,sors,Y,X ,sum numerator possible succes-pre-compute o-line. use valuelikelihood agent send message upon terminating planspecial caseXrequireX= 0, Equation 3 well-dened,X determineX time t.possible transitionsmessage. case, agent cannot begun execution successor,even though completed executionX . Xbelief agent longer executingmessage (i.e., blocked state).agent executing oneX 'stherefore probability mass signifyingXtime+ 1,waitingwords, increased beliefimmediate successors time+ 1,given seenmessage.Algorithm 3 presents pseudo-code process propagating probabilitiesforward time message observed. First, initializes values 0 (lines15).process continues going plansX2 M,post-orderexplorechildren plans (i.e., plans reachable hierarchical decomposition transitions)parents, sibling plans order execution. plan, algorithm executes fourstages: (1) determines plan's outgoing probabilities (lines 710); (2) determinesx ,outgoing probability mass propagated along outgoing temporal transitionswithout blocked waiting message (lines 1112); (3) propagatesxalongnon-blocked temporal outgoing transitions (lines 1320); nally (4) computesbelief agent execute plan next time-tickbt+1 (X; :block )blocking (lines 2122). remainder section explains four stages detail.Calculating outgoing probability outx (lines 710).outxAlgorithm 3, variablerepresents total temporal outgoing probability plan,X,given beliefX time t. plan X leaf, derive temporaloutx , temporal model discussed previously, given beliefagent currently executing X (lines 78). X parent, lines 910 are, fact,redundant: serve remind reader parent, , outy follows's children execute line 20. depends critically post-order traversalplan-hierarchy: outgoing probability parent derived outgoingagent executingoutgoing probability,probabilities last hierarchical-decomposition children, thus children's outgoingprobabilities must calculated parents'.99fiKaminka, Pynadath, & TambeAlgorithm 3 Propagate-Forward(beliefs b, plans )plans X 2bt+1 (X; :block )0:0bt+1 (X; block )0:0outx0:0x0:0plans X 2 post-order1:2:3:4:5:6:7:8:X leafbt (X; :block )(1outxelse9:{X parent}{children temporal order parents}e x ) {calculate probability X terminating time t}outx known { post-order guarantees children set line 20}temporal outgoing transitions Tx!y Xxx + (1 xy )xyx > 0 {some transition taken}temporal outgoing transitions Tx!y Xoutx (1 xy )xyTx!y leads successor planbt+1 (Y; :block )bt+1 (Y; :block ) +(Y; ; b; )else {Tx!y terminating transition}outparent(x)outparent(x) + (1 xy )xy {parent's outgoing probability chil-10:11:12:13:14:15:16:17:Propagate-Down18:19:20:dren's}bt+1 (X; block )bt+1 (X; block ) + outx xbt+1 (X; :block )bt+1 (X; :block ) outx21:22:Determining non-blocked outgoing probability x (lines 1112).ability,xsum possible values numerator Equation 3 (i.e.,temporal outgoing transitions originatingline 21,X;prob-xX ),illustrated derivation. seecritical calculating belief agent terminated executionyet begun execution successor (i.e., beliefbt+1 (X; block )agent blocking).Propagating x along temporal outgoing transitions (lines 1320).key component propagation. every temporal outgoing transitionseer calculates,Tx!y ,Overseer's belief joint event (i) agent completed executionagent taking transitionTX !Y ,observable message. calculationX,(ii)(iii) agent without sendingderived follows:= Probability X done ^ message observed ^ agent chose Tx!y= Pr(done(X; t)jXt ) Pr(:msgjXt ; done(X; t)) Pr(Yt+1 jXt ; done(X; t); :msgt )= outx x (1 xy )xyx= outx (1 xy )xy(4)transition'sOver-temporary variable holds probability mass correspondingTx!yfuture state (at timeleads successor plan+ 1)(lines 1618),temporal incoming probability.addedSince decompositionassumed immediate, incoming probability propagated (added)100'srstfiMonitoring Teams Overhearingchildren (Algorithm 2). multiple rst children, denote alternative plandecompositions single agent, compute probability dividingprobability incoming parent among them. children rst child plansown, distribute new incoming probability turn, using method.next time-step algorithm propagate rst children nextchild, order execution.reason assume plans takeleast single time step complete.Tx!yXadded X 's parent's outgoing probability outparent(x) may used propagating parent(x)'s temporaltransitionspecial-case termination transition (line 1920),successors. case, outgoing temporal probabilityoutgoing probability along temporal outgoing transitions. Note postorder traversal plan-hierarchy guarantees children exploredparents, thusoutparent(x)fully computed time algorithm reachesparent(x).Computing X 's new blocked non-blocked probabilities (lines 2122).outgoing probability mass propagatedX 'ssteps remaining involve re-calculation Overseer's beliefX 'sblocked non-blocked states. total temporal outgoing probability (whether blocked not)must subtracted future belief agent executingleftoutxbt (X; :block )x .children siblings,X.outx ;probability massblocking message observed OverseeraddedX 'sfuture blocked state.3.4 Discussionoverhearing approach outlined section maintains separate plan-recognitionmechanism agent, ignoring inter-agent dependencies. Using array individual models (Figure 3) updated passage time, messagesobserved, state team taken combination likely stateindividual agent. Algorithm 4 embodies approach: called every time tick, collectsmessages observed, updates state agents.EVACUATE [TASK FORCE]PROCESSORDERS[TASK FORCE].....EXECUTEMISSION[TASK FORCE]PROCESSORDERS[TASK FORCE]LANDINGZONEMANEUVERS[FLIGHT TEAM]FLY-FLIGHTPLANGETORDERS[FLIGHT TEAM][GET ORDERS]FLY-CONTROLROUTE....[FLIGHT TEAM]EVACUATE [TASK FORCE]LANDINGZONEMANEUVERS[FLIGHT TEAM]FLY-FLIGHTPLANGETORDERS[FLIGHT TEAM][GET ORDERS]....FLY-CONTROLROUTE....[FLIGHT TEAM]ESCORTTRANSPORTOPERATIONS OPERATIONS[ESCORT][TRANSPORT].....EXECUTEMISSION[TASK FORCE]....ESCORTTRANSPORTOPERATIONS OPERATIONS[ESCORT][TRANSPORT]Figure 3: Array single-agent recognizersone agent.illustration operation algorithm, consider example domainevacuation scenario. Overseer begins belief agent executing top-Process-Orders) time 0 (i.e., b0 (Evacuate; :block ) = 1:0,b0 (P rocessOrders; :block ) = 1:0). Overseer observes message initiationFly-Flight-Plan one helicopters, applies Incorporate-Evidence (Algolevel plan (and rst child,101fiKaminka, Pynadath, & TambeAlgorithm 4 Array-Overseer(beliefs b, plan-hierarchy1:2:3:4:5:Agents 2message observedIncorporate-Evidence(ma; b; [a])else {No message sent }Propogate-Forward(b; [a])array[],agentsA)rithm 1). plan-hierarchy (Figure 1b) knownProcess-Orders cannotpossible current future plan agent, helicopter question executingFly-Flight-Plan,i.e.,bt (P rocessOrders; :block ) = 0, bt (F lyF lightP lan; :block ) = 1:0.Fly-Flight-Plan's rst children,probability mass propagatedone, thus belief child set 1.0 well.time passes message observed, uncertainty whetherFly-Flight-PlanLanding-Zone-Maneuvers active, possible futurestates, duration Fly-Flight-Plan uncertain. Overseer would still assignprobability 1.0 top-level plan Evacuate. However, probability massFly-Flight-Plan would propagated every time-tick Landing-Zone-ManeuversPropagate-Forward (Algorithm 3). propagation, incoming temporalprobability mass added belief executionLanding-Zone-Maneuverswould propagated rst children immediately. Assuming helicopter agentfree select eitherTransport-OperationsEscort-Operations,incoming proba-bility would split evenly added prior belief two rst children.temporal propagation step, outgoing belief rst children wouldpropagated via outgoing temporal transitions.inference procedure described Algorithms 14 exploits particular structurerepresentation ways general existing algorithms cannot. pseudo-codedemonstrates single monitored agent, types belief updates timecomplexitylinearM,(M N ).number plans transitionsagents, space time complexity Algorithm 4i.e.,(M ).ThusNgain eciency (compared approach DBN) two sources. First,make Markovian assumption probability observing message dependsrelevant plan active, independently execution history. assumption, incorporate evidence, based beliefs timet.Second, makeanother Markovian assumption temporal model, allowing propagation algorithmreason forward time+1based beliefs timet,without regardprevious history.4. Monitoring Team Overhearingprevious section outlined ecient plan-recognition mechanism particularlysuitable monitoring single agent based communications. Monitoring teamachieved monitoring member team independently others. Unfortunately,although time complexity approach acceptable, monitoring (recognition)results poor.evaluation Section 6.1 provides details, but, short,average accuracy using approach experiments102less 4%.fiMonitoring Teams Overhearingmain cause low accuracy scarcity observations, one identifyingcharacteristics monitoring overhearing. previously discussed, agents often switchstate unobservably (i.e., without sending message). Therefore, monitoring systemcritically needs estimate correctly times agents switch state.Sinceagents rarely communicate (i.e., observations them), variancetemporal behavior (with respect system's predictions) tends cause large errorsmonitoring.address issue, bring back discussion agent independence assumptionmade previous section. all, team-members communicateindependently other:Communication team action intendedchange state listener (Cohen & Levesque, 1990).message may still change state uponreceivingAgents rarelymessage.sendwords, althoughobserved messages used previous section update belief statesender, could also used update state listeners.this,monitoring system must know relationships team-members.Knowledge social structures enables additional sophisticated forms monitoring.instance, order maintain social structures, team-members communicatepredictably, particular points execution task. predictionsfuture observable behaviorcommunicationscan used reduce uncertainty. However, often case dicult correctly predictspecic agent communicate specic point task execution, easy predictteam-member will. Knowledge procedures employed team maintainsocial structures useful allows monitoring system make predictions.reason eects communications receivers, future observable behavior team-members, monitoring system must utilize knowledge social structures social procedures used team-members maintain structures.exploitation social knowledge monitoring called Socially-Attentive Monitoring(Kaminka & Tambe, 2000). section discusses concepts detail.4.1 Exploiting Social Structurescomputationally cheap, approach described earlier proved insucient evacuation domain.monitoring overhearing tasks, monitoring system must addressscarce observations, agents rarely communicate time. Indeed, evacuation application, single message observed (on average) every 20 combinedindividual state changes.challenging conditions, system monitoring overhearing must comerely extensively ability estimate agents change internal state without sending message.representation presented earlier used simple, ecient,temporal model this, based estimated average duration plans. However,found high variance actual duration plan execution, compared durationpredicted average-duration model:Plan execution times vary dependingexternal environment.instance,agents team running local network, response times queries103fiKaminka, Pynadath, & Tambemay shorter communicating across continents. Indeed, latency timesInternet vary greatly, dicult predict.Plan execution times vary dependinginstance,travelingplan-step executed internally.plans, used repeatedly within given evacuation team-oriented program, take anywhere 15 seconds almost two minutes execute,depending particular route followed.Plan execution times vary dependingoutcome plan-step.instance,route-planner functioning correctly, responds within seconds. However,crashes return answer all, agents waitrelatively long time relying time-out decide failed.problem addressed principle expressive model execution duration,instance taking account internal execution context. However, practice,model would likely much expensive computationally, would need relyknowledge previous future steps, breaking Markovian assumption (e.g.,determine duration basedplan-step executed,improved temporal modelwould reason likelihood given instance plan-stepsecond instance, opposed third). applications grow scale real world,increasingly complex temporal model would continuously rened coverincreasingly complex temporal behavior agents.Fortunately, temporal modelone way monitoring system estimate times agents changeinternal state unobservedly.alternative method estimating unobserved state changes utilize known dependencies agents exploit evidence state one agent infer stateanother. particular, often true team settings one agent would send messageintendingaect state receivers particular way. Thus principle,assumption receivers change state predictably, observationmessage used evidence inference sender's state, wellreceivers', i.e., state team-members. trade agent independence assumption made earlier assumption successful coordination. reasonableassumption team settings, given agents actively attempting maintainteamwork communications (Tambe, 1997; Kumar etal., 2000; Dunin-Keplicz &Verbrugge, 2001).eects message receiver dependent relationshipsender receiver (where take relationship described mathematicalrelation possible states sender receiver). principle, relationships underlysocial structures structures interactions agents makedecisions one team-member dependent, predictable degree, teammates. Using knowledge dependencies, monitoring agent may use observationscommunication action agent infer possible state another.One simple example structure common many teams (e.g., Jennings, 1993;Kinny, Ljungberg, Rao, Sonenberg, Tidhar, & Werner, 1992), indeed present alsoapplication:rolesgovern team-members undertake tasks service104fiMonitoring Teams Overhearingteam goal. roles ideally bias decision mechanism team-members towards making decisions appropriate roles. Thus knowledge rolesteam-members useful counter uncertainty faced monitoring agent.instance, suppose monitoring agent knows evacuation application, particular team-member chooseLanding-Zone-ManeuversTransport-Ops,ratherEscort-Ops,child(because team-member belongs TRANSPORT team,rather ESCORT team). knowledge reduce uncertainty monitoring agent hasunder assumption team-member incorrectly chooseinappropriateplan role. Overseer fact uses knowledge roles manneralleviate uncertainty. monitoring use role information used previouswork (Tambe, 1996; Intille & Bobick, 1999), discussed Section 7.However, much important social structure exists teams. Agents teams worktogether, team-member ideally agreementjoint goals plans (Cohen& Levesque, 1991; Levesque, Cohen, & Nunes, 1990; Jennings, 1995; Grosz & Kraus, 1996,1999; Tambe, 1997; Rich & Sidner, 1997; Lesh, Rich, & Sidner, 1999; Kumar & Cohen,2000; Kumar et al., 2000). phenomenonsometimes calledteam coherence(Kaminka& Tambe, 2000)holds dierent levels team. Agents atomic subteam worktogether plans selected subteam, subteams work together sibling subteamshigher level joint plans, etc. Individual agents may still choose execution,service agreed-upon joint plans. Provided monitoring agent knowsplans jointly executed subteams, transitions takentogether subteams, use coherence heuristic, preferring hypothesesteam-members agreement joint plans, hypothesesdisagreement.example, suppose entire team known executingFly-Flight-Plan(Figure 1-b). Now, message one member TRANSPORT subteam observed,indicating begun executionTransport-Ops plan step.Since plan stepjointly executed members TRANSPORT subteam (and them),use coherence prefer hypothesis subteam members alsoTransport-Ops. Furthermore, since plan-step serviceLanding-Zone-Maneuvers plan, jointly executed TRANSPORTinitiated executionESCORT subteams, prefer coherent hypothesis team-members ESCORTexecutingLanding-Zone-Maneuvers.Now, based known role, comeback plan-hierarchy infer members ESCORT subteam executingEscort-Ops,etc.knowledge expected relationships, particular knowledge plansjoint team-members (i.e., subject coherence), part specicationdistributed applicationand thus provided overhearing system designeroperator. fact, often readily available, since used agentscoordination.instance, earlier discussed assumption team-oriented programs available monitoring agent, hold knowledgeplans hierarchy executed (sub)teams encodedplan-hierarchy. team hierarchy contains knowledge subteam/agentpart another subteam.105fiKaminka, Pynadath, & TambeCoherence powerful heuristic. assumes non-failing cases, teammembers successfully maintain joint execution particular plans. assumption, evidence decision made one team-member inuences (through coherence),belief team-mates decided. lacking evidence, coherence prefershypotheses least team-members made joint decisions. instance, suppose transition team plan taken TRANSPORT team.non-failure circumstances, two coherent hypotheses considering transition: Either members TRANSPORT took transition, none did. Evidenceone member, supporting one hypotheses, used infer statemembers.signicance property coherence monitoring system reduceuncertainty even one agent, reduction amplied usecoherence heuristic apply agents well.use coherenceheuristic thus lead signicant boost monitoring accuracy, since numberhypotheses underlying (probabilistic) disambiguation cut dramatically.Section 6.1 provides in-depth evaluation use coherence knowledge rolesselect plan recognition hypotheses Overseer.use coherence signicantly increases time complexity computation.least, requires setting inter-agent links array plan recognizers usedOverseer (Section 3.4), links represent probabilistic association plans executed jointly (in contrast temporal hierarchicdecomposition transitions used thus far). instance, specic planjointly agents(representing agentA'sB,NNexecution planX)variable(M N 2 )N (N2XtB1)(representingM,XtAagent B 'sinter-agent links be-agents, one joint plans (ofagents, array recognizerssizeexecutedlink would constructed variableexecution plan). general, wouldtweenX[],).Thus givenindividual agent's plan-hierarchyrun-time complexity exact-inference algorithm would leastquite likely much worse (since general exponential numbercoherent non-coherent hypotheses select from).next section (Section 5.1),describe highly scalable (in number agents) representation reasoningcoherent hypotheses.4.2 Exploiting Procedures Maintain Social Structuresmonitoring system exploit knowledge procedures agents use maintainsocial structures alleviate uncertainty resulting scarceness observations. instance, monitoring system could accurately predictfuture observablebehavior monitored agents, observed predicted behavior,monitoring system may infer agents reached state associatedpredicted behavior. Thus predictions used eliminate monitoring hypotheses,setting individual agent'sXYprobabilities reect prediction messagetransmitted agent executionXterminates initiatesY.instance,application, Ariadne information agent queried possible threatsroute followed evacuation. may therefore possible predict106fiMonitoring Teams Overhearingroute taken helicopters, message sent Ariadne agentteammates; thus message observed, Ariadne agent inferredyet executed step. Furthermore, assumption coherence (discussedabove), monitoring system may infer team-members yet executed step, i.e., new route taken team.inference obviouslydependent system's observational capabilities, found useful evenlossy observations monitoring system (see Section 6.2).However, general, specic individual predictions dicult make. Teammembers often engaged joint tasks, require many agents tackle problemtogether. settings, predicting individual communications may impossible.instance, consider distributed search problem target solution foundsomewhere search-space; dierent areas search space divided amongstagents, understanding rst nd target communicateothers. would dicult accurately predict one agents communicate(nd target), since could predict that, could focus agents' eorts areaalone. Yet easy predict least one agent nd target communicate.Similarly, evacuation application, may dicult predict helicopterreach civilians rstbut easy predict one will,communicate location.Indeed, teams utilizesocial proceduresconventions(Jennings, 1993) team-members maintain relationships one another. Removal agent independenceassumption allows monitoring system exploit knowledge procedures, making predictions behavior team-members coordinating one another.instance, knowledge failure-recovery procedures used team recover coordination failures allows monitoring system predict future behavior team-memberscase failed execution. Similarly, knowledge communication procedures usedteam (as part team-members' coordination) allows predicting future observablemessagesfuture interactions team-memberswithout necessarily specifying particular individual agent carry out.example, suppose Overseer overhears message indicating ight teamFly-Flight-Plan (Figure 1-b). time passed,possible team either still executing Fly-Flight-Plan, terminatedalready begun joint execution Landing-Zone-Maneuvers. However, Overinitiated joint executionseer knows least one team-member explicitly communicate terminatingFly-Flight-Plan initiating Landing-Zone-Maneuvers, communications observed, monitoring system eliminate possibility teamexecuting latter, eliminating uncertainty case (onlyFly-Flight-Planpossible).leave discussion technically social procedure form least one teammember communicate subteam take transitionconvertedteam-wideXYXvalues next section, present technique representingprobabilities way allows ecient reasoning. remaindersection, address instead knowledge social procedures may acquired.Social procedures communications may simple per-case rules, may involvecomplex algorithms.instance, Jennings (1993) suggests using heuristic application-107fiKaminka, Pynadath, & Tambedependent rules determine communication decisions.STEAM (Tambe, 1997) insteaduses decision-theoretic procedure considers cost communication costmiscoordination decision communicate. procedures proposedwell (e.g., Cohen & Levesque, 1991; Jennings, 1995; Rich & Sidner, 1997).However,regardless complexity, key point monitoring system necessarilyfull knowledge procedures order exploit predictions:needs approximate outcome, since use combination techniquescombat plan-recognition ambiguity, rather relying one technique.decisions social procedures acquired learning previous runssystem.Although detailed exploration appropriate learning mechanisms out-side scope paper, provide strict demonstration feasibility learningsocial procedures simple rote-learning, proved eective generating useful communications model signicantly reduced uncertainty monitoring evacuationapplication.simple mechanism records execution plans explicitlycommunicated about, whether initiated terminated. learned ruleseective immediately, stored future monitoring task.Figures 4ad present results using rote-learning mechanism fourdierent runs tasks.X-axis denotes observed communication message-exchanges task progresses.Overall, 22 45 exchanges take placerun, exchange including one dozen broadcast messages agentsannounce termination initiation plan. Y-axis shows number hypothesesconsidered Overseer seeing message, without using probabilistic temporalknowledge. Thus greater uncertainty hypothesis correct would reectedhigher values Y-axis. beginning task execution, possible plansconsidered possible, since ignore temporal knowledge graph. progress madetask, less less steps remain possible end reached, expectsee gradual (non-monotonic) decline move along X-axis. techniquesuccessfully eliminates hypotheses considerations results Y-axis valueslowerbaseline execution curve.Figure 4, line markedLearningshows baseline (i.e., predictions,learning component turned ). baseline shows relatively high levelambiguity exists, since system cannot make predictions future statesagents, possible. learning technique applied on-line(i.e., message seen immediately used future predictions), learned experienceimmediately useful, ambiguity reduced somewhat (the line markedOn-Line Learning ).However, exchanges either encountered late task execution, seenonce. cannot eectively used reduce ambiguity monitoring systemrst run. However, third line (Learning )presents number hypothesesconsidered fully-learned model used. Here, model learned run G,applied without modications runs system. seen, showssignicantly reduction number hypotheses considered Overseer.evaluation use communications predictions presented Sections 6.1 6.2;however, full exploration use learning task beyond scopepaper.108fiMonitoring Teams Overhearing25learningOn-line learningUsing previously learned predictions20Number Recognized PlansNumber Recognized Plans25151050learningOn-line learningUsing previously learned predictions2015105005101520253035Observed Communication Exchanges404505(a) Learning experiment C25learningOn-line learningUsing previously learned predictions2040454045(b) Experiment ENumber Recognized PlansNumber Recognized Plans25101520253035Observed Communication Exchanges151050learningOn-line learningUsing previously learned predictions2015105005101520253035Observed Communication Exchanges40450(c) Experiment G5101520253035Observed Communication Exchanges(d) ExperimentFigure 4: Learning communication decisions dierent experiments.109fiKaminka, Pynadath, & Tambe4.3 Discussionkey characteristic monitoring overhearing tasks scarcity observations available monitoring system.Fortunately, observations available monitoringsystem often viewed observationsmulti-agent actions :sender messagechanges state, often also intends change state recipients(Cohen & Levesque, 1990).Thus even single observation used evidenceinferring state sender receivers. stands contrast previous work,addressed monitoring multiplesingle-agentactions.monitoring team, monitoring system use knowledge social structuresprocedures exploit information activities one team-member, hypothesizing activities another team-member. techniques specicrepresentation presented earlier. instance, increased belief one agent's executionplanXbased evidence teammate's executionXalso used con-structing appropriate probabilistic links nodes representing beliefs largeDBN representing two agents. start DBN representation discussedSection 3.1, replicate single-agent network (containingNseparate agents. number nodes(M N ),2plans)since represent planstransitions individual agent. also introduce appropriate inter-agent linkscapture inter-agent dependencies represented model teamwork. However,upon introducing links, computational complexity performing DBN inference2N .explodes(2)Obviously, social reasoning computationally expensive, even efcient representation described earlier.next section provides details ecientmechanism reasoning team using information role coherence, utilizing communications predictions. Using mechanism, techniques describedsection resulted accuracy 97% (84% average across experiments)compared average 4% without use social knowledge. Sections 6.1 6.2 presentdetailed discussion results.5. Plan-Recognition Overhearingprevious section outlined socially-attentive monitoring techniques, alleviatinguncertainty monitoring team agents exploiting knowledge social structuressocial procedures monitored team. discussed usingnancecoherencerole mainte-exploit knowledge ideal agreement agents specic plans executedtogether, specic plans assigned agents fullling roles. Furthermore, discussed disambiguation based predictions future observable behavior, basedknowledge social procedures employed team-members. disambiguationheuristics eliminate many (incorrect) hypotheses considered. However, reasoningusing techniques computationally expensive.section presents ecient algorithm, building representation previouslypresented, facilitates scalable monitoring overhearing large teams. key idearepresent hypotheses heuristics would considered valid,eliminating consideration plans transitions would considered illegalheuristics. Relying team-hierarchy bookeeping, coherent hypotheses110fiMonitoring Teams Overhearingrepresented using single recognizer instead array recognizers, oering considerablescalability team monitoring. However, since algorithm longer represent certainhypotheses, scalability comes expense expressivity.discuss scalablerepresentation trade-o oers below.5.1 Ecient Reasoning Team CoherenceCoherence strong constraint, since team agents linearnumber (O(M )size plan-hierarchy) coherent hypotheses,exponential number incoherent hypotheses (O(M N ) N number agents;proof Appendix A). exploit property designing monitoring algorithmsreason linear number coherent hypotheses, therefore oer betterscalability number agents increases. algorithms may able reasonincoherent hypotheses, therefore less expressive. However, Section 6 demonstrates level accuracy even limited expressiveness sucientpurposes.Furthermore, algorithms reason coherent hypotheses may stillable detect incoherent hypotheses, representing failure state twoteam-members disagreement other.begin presenting YOYO* algorithm, ecient technique reasoningcoherent hypotheses (Algorithm 5). YOYO* replaces array-based algorithm describedearlier (Algorithm 4). Similarly it, YOYO* called every time tick.messageobserved, state entire team propagated forward time. Otherwise, observedmessages collected together used evidence (dierent) plans impliedmessages.YOYO*'s key novelty reliessingleplan-hierarchy used representteam-members together (regardless number), instead array structures. words, variableteams associatedXtimet.XXtrepresents Overseer's beliefagents(as described team-oriented program) executing planThus YOYO* makes extensive use information associating planstransitionsteams subteamsH,team-hierarchy. team hierarchyplays critical bookeeping role respect, since maintains knowledge criticalcorrectly applying coherence single recognizer.key distinction YOYO* array-based approach causes subtle,critical, dierence way probabilities propagated along transitions. planhierarchyindividual agent, part array models, outgoing transitionrepresented hierarchical decomposition temporal step agent allowed take.Alternative outgoing transitions therefore represent alternative paths execution availableagent.hand, plan-hierarchyused YOYO*, alternativeoutgoing transitions tagged dierent subteams (that ancestors one another)represent decision point agent, alternative paths execution decidedagents' roles team-memberships.creates critical dierence valuespreviously (in Section 3) valueagent take transitionX!xyXYXYinterpreted.referred probability specic(given terminated executionYOYO* refers probability entire team take transition111X ),together.fiKaminka, Pynadath, & TambeAlgorithm 5 YOYO*(plan-hierarchy , team-hierarchy H , beliefs b)1:2:3:4:5:6:7:8:9:10:11:12:13:14:new messages observedTeam-Propagate-Forward(b, )elseInitialize distributions b0 ; bt+1 0 plans U 2 . ; Initialize I; E empty sets.Messages mi[ fX j X 2 M; mi initiation message; X consistent mi gEE [ fY j 2 M; mi termination message; consistent mi gplans X 2teammsg (X ) {T agent sending message initiating X }plans W 2 precede X , transition W ! X allowedb0 (X; :block )b0 (X; :block ) + bt (W; block )wx wxplans X 2 Eteamm sg (X ) {T agent sending message terminating X }plans 2 M; 2= succeed X , transition X ! allowed15:16:17:18:19:20:21:22:23:24:25:26:27:b0 (Y; :block )b0 (X; :block ) + bt (X; block )xy xyNormalize distribution b0 taking teams accountplans X b0 (X; :block ) > 0bt+1 (X; :block )b0 (X; :block )(X; b0 (X; :block ); b; )team(X )PXparent(P ) 6= nullbt+1 (parent(P ); :block )bt+1 (P; :block )team(parent(P )) = parentteam (T )(parent(P ); T; P; b)= parentteam (T )Pparent(P )Team-Propagate-DownScale112fiMonitoring Teams OverhearingYOYO* unable represent hypotheses team-members take one transition,others notunless two dierent groups members form dierent subteamsrepresented team-hierarchy, dierent transitions taggedallowed dierent subteams.valueXYalso interpreted dierently, critical way.previous sections taken represent probability specic individualcommunicate transitionprobabilityX!Ytaken, YOYO* value represents insteadone team-members communicatetransitiontaken team. Thus longer refers individual agents, (sub-)team.way, YOYO* solves issue represent predictions type least oneteam-member communicate step reached, discussed previously.example,supposeLanding-Zone-ManeuversYOYO*setsbeliefexecutingp. Landing-Zone-Maneuvers,Escort-Ops Transport-Ops, executed mem-plan-step probabilityYOYO*, two (rst) children:bers th ESCORT TRANSPORT subteams, respectively.agent case, probabilityteampUnlike individualdivided among two children,duplicated them: belief entire team executingLanding-Zone-ManeuversTransport-Ops,implies equally-likely belief TRANSPORT subteam executingESCORT subteam executingEscort-Ops.explain YOYO*'s operationdetail below:message observed (lines 12).Since observations available, stateentire team jointly propagated forward time calling Team-Propagate-forward(Algorithm 7, Appendix A). slightly modied version propagate-forward(Algorithm 3) takes dierent subteams account propagating beliefs: Giventotal outgoing probability (either sibling child transition), outgoing transitionstaken dierent teams one team ancestor another (suchTRANSPORT ESCORT sub-teams), total probability would usedtransition, instead splitting outgoing probability transitions. Appropriately, Team-Propagate-forward relies modied version PropagateDown algorithm (Algorithm 2), called Team-Propagate-Down (Algorithm 6, AppendixA).latter algorithm also used incorporation evidence (lines 327).run-time complexity propagation process(M ).One messages observed (lines 37).one messages ob-served (since YOYO* single algorithm monitoring multiple potential message senders,one message may observed once), YOYO* begins incorporate observations maintained beliefs team. process somewhat similarIncorporate-Evidence algorithm, described earlier (Algorithm 1), takes account multiple observations (sinceNagents may sent message). Multiple messages(from dierent agents) may refer plan, YOYO* must incorporateevidence multiple times.simple loop (lines 57) builds set(of initialized plans)plans) going incoming messages arrived timecomplexity process (in worst case)113(N ).Et.(of terminatedrun-timeHere, YOYO* betterfiKaminka, Pynadath, & Tambearray approach, since multiple messages always cause multiple updates array,YOYO*, multiple messages may refer single plan, thus triggering single update.Incorporating evidence initiated terminated plans (lines 815).one plansprior beliefX(line 8), YOYO* sets new beliefb0 ,weightedX 's initiation (lines 1011), similarly done incorporate-evidence algorithm (Algorithm 1), taking account team implied senderprocessed message (line 9).(teammsgdone lookupusing sender(mi )): transitions allowed take followed.transition allowed taken super-teamdenition,allowedT.similarprocess done termination messages (lines 1215), course lookingpossible successors plans consistent messages.However, sincewant cause updates line 11 line 15 cases termination messageinitiation message refer transition, loop plans(line 14) skipsplans already addressed previous step. Overall, run-timecomplexity process(M ).Normalizing temporary distribution b0 (line 16).b0temporary distributionresulting processing initiation termination messages normalized,similar fashion analogous step algorithm 1. However, process must takeaccount plan-hierarchy question, also team-hierarchy. Unlike typicalnormalization procedure, evidence two dierent plans, selected two dierent teams,may necessarily compete other, therefore may necessarily requirenormalization. instance, two messages observed, one implying teamP , another implying team B initiated executionQ children joint parent J (executed jointlynormalized likelihood (1.0) assigned Pinitiated execution planplanQ,(andA; B ),Jtwo subteamsQPassigned propagation steps described below).run-time complexity process(M ) .Propagating evidence (lines 1727).First, beliefs setplan implied observations, children (lines 1819). Then, teamexecute plan determined lookupusingteam(X )(line 20).YOYO* begins propagate evidence plan's parents (lines 2126). beliefchild plan propagated added belief parent (line 23).However,(P )) executed super-team current team ,parent plan (parentchange probability must propagated children,executed (subteams). Thus upward propagation alternated downward1propagation along hierarchical decomposition transitions . downward step executedwhenever team responsible joint execution parent plan longercurrent subteam considered (T ), parent team team-hierarchygivenparentteam (T )H,(lines 2426). condition satised, changebeliefs parent plan must propagated childrenexecuted subteams. done via Scale algorithm (Algorithm 8, AppendixA).1. alternating upward-downward propagation origin YOYO*'s name.114fiMonitoring Teams Overhearingdownward propagation (line 25) implements subtle critical step: re-alignsbeliefs YOYO* maintains subteams implied messagebeliefs made coherent existing evidence. Scale procedure,re-distributes new state probability parent among children, childgets scaled based relative weight parent.end result stateprobabilities children made sum state probability parent.process recursive, never re-visits subtree, since carried hierarchicaldecomposition transitions previously updated.downward propagation done, YOYO* updates current teamparentteamparent team-hierarchy, line 26. Note callteam-hierarchyH,rather plan-hierarchyM.downward propagation took place, temporary variablehierarchical decomposition(line 27).iteration loop begun line 17reects lookupFinally, regardless whetherP(Mupdated climb+ H ) since worst caseplan-hierarchy team-hierarchy traversed. However, loop many repeat(in worst case) plans plan-hierarchy, thus overall, run-timecomplexity process(M (Mexample run YOYO*.+ H )) = O(M 2 + H ).following example illustrates YOYO*'s inferenceupon observation message. Suppose single member TRANSPORT subteamcommunicates initiatingTransport-Opsplan. Upon observing message,YOYO* looks sender, determine transitions taken (line 8).proceeds determine new beliefs team's execution Transport-Ops plan (lines910, 16), incorporates new beliefs reect much increased beliefTransport-Ops children (lines 1819). SinceLanding-Zone-Maneuvers, null, YOYO* enters loop linesTRANSPORT subteam executingplan's parent,2227. First, increases belief execution parent (line 23). Then, checkscondition line 24: Indeed, team executeLanding-Zone-ManeuversLanding-Zone-ManeuversTEAM-FLY-OUT, parent TRANSPORT subteam (i.e.,executed jointly TRANSPORT ESCORT subteams).fore calls Scale procedure (line 25) re-adjustchildren subtrees.Transport-OpsLanding-Zone-ManeuversYOYO* there-Landing-Zone-Maneuvers'two hierarchical-decomposition children:(which YOYO* already updated) executedEscort-Ops, executed ESCORT subteam.Landing-Zone-Maneuvers Escort-Ops, increasing YOYO*'steam executing Escort-Ops plan. process re-alignslikelihood Escort-Ops executedTRANSPORT subteam,Scale climbsbeliefs ESCORTprior beliefs YOYO*current evidence, eect updating beliefs plans executed ESCORTsubteam, based single observation made member TRANSPORT team.process repeats loop entire set beliefs updated alignedrespect observed message.5.2 Scalability Number AgentsYOYO* oers signicant computational advantages compared individual representation (array) approach. YOYO* requires115single, fully-expanded plan-hierarchyfiKaminka, Pynadath, & Tamberepresent entire team.hierarchyunionindividual agent plan-hierarchies, containing transitions plans, tagged subteams allowedexecute them.addition YOYO* uses single copy team hierarchy.size plan-hierarchy,Hsize team-hierarchy,NSupposenumberagents team. agents added monitored team, team hierarchygrows one new node represents new agent, connected appropriate+ H ). Sincegrows N , could write (M + N ) (compare array approach: (M N ),sub-team team hierarchy. YOYO*'s space complexity thereforeH(MAlgorithm 4).analyze YOYO*'s run-time complexity, consider behavior Algorithm5 separately cases communications observed, cases leastone message observed.messages observed, update takes formsingle call Team-Propagate-Forward (Algorithm 7),(M )process.clearly best-case scenario YOYO*. one agent communicates, YOYO* wouldgo(M+ H ) = O(M + N ).Hupward-downward propagation process once, thusworst case scenario YOYO* occurs agents send messages, oneNmessages refers dierent plan (messages plans would mergedlines 57). case, woulddierent plans evidence exists,one would require separate update lines 1727. Thus YOYO*'srun-time complexity case(N+ + + (M + H )) = O(N + 2 + H ) = O(N + 2 + N )Clearly, worst-case cannot continuously sustained monitored team, since agentscannot continuously communicate state. thus believe average casereal-world domainsmanyagents would much closer(M+ N)casepresented earlier (see Section 6.4 empiric evaluation). case, YOYO*'s complexitycompares favorably procedure reasoning coherent hypotheses using arrayrecognizers,(M N 2 )process (at least), even one agent communicates (Section4.1).5.3 DiscussionYOYO* explicitly represents team single coherent entity. space run-time requirements preferable array based approach number agents grow,considerably simplies reasoning coherence communications predictions.hand, YOYO* sacrices capability represent failing team activities (incoherent hypotheses), one team-member executing one team-plan teammateexecuting another.mean individual actions taken agentssomehow locked together synchronous execution, individual agents mustexecute individual action time. instance, two team-membersA; Bexecuting completely dierent path execution time (i.e., planstepsA1 ; :::; Akoverall joint planB1 ; :::; Bl ) easily represented plan hierarchy includesJ , two rst hierarchical decomposition children, A1 B1 ,116fiMonitoring Teams OverhearingselectedB , respectively. A1 would outgoing temporal transition A2 ,B1 would outgoing temporal transition B2 , etc. Since Jetc. similarlyexecuted two team-members jointly, initial evidence one agentexecuting individual plans would used YOYO* evidenceteam-member begun parallel execution individual execution path.evidence one agent executing individual actions would increaselikelihood agent continuing execution, pace. However,would impossible YOYO* correctly represent monitoring hypothesisexecuting childJ.J , Ai ,Bexecuting planJ,childGiven results evaluation conducted (Section 6), demonstratedimportance coherence accurate visualization, tradeo expressivity vs. scalabilityjustied: Overseer's accuracy much improved due use coherence.Although YOYO* sacrices capability reason certain failure (incoherence)hypotheses, still capable supporting failure-detection, important secondary goalvisualization. earlier work, shown merits coherence service detectingdisagreements team, particular demonstrating coherent monitoring leadssound centralized disagreement detection, may lead sound complete disagreementdetection specic circumstances (Kaminka & Tambe, 2000). YOYO* factecient way reason coherent hypotheses, provides good basis providingsound disagreement detection results.concern generality technique may raised based YOYO*'s reliance team-hierarchy.However, believe reasonable expect large,complex, real-world multi-agent systems type targeted paper wouldorganizational hierarchy sort associated (see, instance,Tidhar,1993b). Human organizations certainly demonstrate emergence hierarchies, especially organizations grow larger (e.g., big corporations, government organizations)tackle mission-critical tasks (e.g., military organizations). addition, team-hierarchiescomputational agents critical planning, maintaining network system security, etc. Thus believe use team-hierarchy weakness approach,organizational structures become wide-spread computational multi-agent systemsalready human multi-agent systems. Indeed, may possible graduallylearn team-hierarchy given coordinated team purpose monitoring; however,discussion possibility outside scope paper.Indeed, using team-hierarchy, apply assumption coherence representations algorithms well. instance, start DBN representationteam Section 4.3, unify multiple random variables used represent separate agents single random variable overall team/subteam.YOYO*, size representation grows size plan hierarchy,number agents. Thus, number nodes single-agentcase,(M 2 ),discussed Section 3.1.However, again, complexity inference2.answering plan-recognition queries still exponential number nodes,117(2 )fiKaminka, Pynadath, & Tambe6. Evaluationsection presents detailed evaluation dierent contributions contained withinOverseer. begin exploring relative contribution technique successOverseer whole (Section 6.1).focus evaluating Overseer's usecommunications predictions respect lossless lossy observations (Section 6.2).present comparison Overseer's performance human expertsnon-experts (Section 6.3). Finally, empirically evaluate YOYO*'s scalabilityapplication domain (Section 6.4).6.1 Accuracy Evaluationrst part evaluation tests contribution dierent techniques Overseer successful recognition correct state team-members. Figure 5 com-pares average accuracy sample actual runs, marked J (X-axis).1020-minute run, team executed task completely. dierent pointsexecution,actualstate system compared statepredictedOverseer, prediction taken current most-likely hypothesis.run 2245 comparisons (data-points). percentage correct monitoringhypotheses run across comparisons given 0-1 (0-100%) range,Y-axis.10.9TemporalAverage Accuracy0.8CoherentCoherent,Temporal0.70.60.5Coherent, Comm0.4Coherent,Temporal, Comm0.30.20.10BCEFGHJEvaluation RunFigure 5: Percent accuracy sample runs.accuracy using individual models coherence (as Section 3)presented leftmost bar (markedTemporal )group (Figure 5), clearlylow. approach straightforward attempt monitoring multiple agents monitoring individual, without considering interactions them, describedSection 3.next bar presents monitoring accuracy coherence usedrule hypotheses (Section 5.1), ties broken randomly. next bar rightCoherent, Temporal ) presents results combining coherence probabilistictemporal model (Sections 3 5.1). Then, bar marked (Coherent, Comm ) shows(eects combining use coherence use predictions based knowledge118fiMonitoring Teams Overhearingcommunication procedures used team (Section 4.2). Here, communicationspredictions used restrict set coherent hypotheses considered, ties bro-Coherence, Temporal, Comm )ken randomly. remaining bar (presents monitoringaccuracy run using combination techniques.results presented Figure 5 demonstrate eectiveness socially-attentivemonitoring techniques presented.First, results show coherence heuristicbrings accuracy 1530% without using probabilistic reasoning. boostperformance particularly interesting result, relation coherencetechnique previous techniques explored literature (Tambe, 1996; Intille & Bobick,1999). Previous work successfully used relationships agents increaseaccuracy monitoring. boost Overseer's accuracy based use roleteamwork relationships conrms results previous investigations.However,results also demonstrate technique sucient domain.Overseer adds number novel techniques addressed previous work.Coherent,rst technique combines coherence temporal model plan-duration (Temporal ),results signicant increases accuracy, probabilistictemporal information allows Overseer better handle lack observations.possible alternative, explore evaluation, rely instead communications predictions rule hypotheses future states may mayCoherent, Comm ).reached (therefore interesting compare performanceCoherent, Temporal ) (Coherent, Comm ) bars.two techniques comparing (almost runs average accuracy using coherence communications predictions signicantly higher using coherence temporal model.despite fact eective coherence technique uses arbitrary (random) selectionamong available hypotheses: reason many cases communication predictions powerful enough rule hypotheses one two, signicantlydecreasing uncertainty agents' plan-horizons. Thus even random selection standsbetter chance informed (by temporal model) selection among many(1020) hypotheses.However, runs J B show reversal trend compared runs. Figures6ab show accumulative number errors task execution progresses run(Figure 6-a) run J (Figure 6-b). error dened failure choosecorrect hypothesis likely one (i.e., likely hypothesis reecttrue state agent/team). message exchange corresponds one dozenmessages communicated agents, establishing terminating plan. two gures,lower slope means better performance (less errors). line markedCoherentshowsaccumulative number errors coherence used select correct hypothesischoices turn erroneous since random choice made amongcompeting hypotheses. line markedCoherent, Temporalshows results usingcoherence temporal model choose likely hypothesis. Similarly, linemarkedCoherent, Commshows results using coherence communicationspredictions. Finally, remaining line displays results using combined technique,using coherence, temporal model, communications predictions.Figure 6-a, see two techniques (Coherent, Temporal Coherent, Comm )almost equal slopes result almost equal number errors end run I,119fi7HPSRUDO&RKHUHQW&RKHUHQW&RKHUHQW2EVHUYHG 0HVVDJH ([FKDQJHV7HPSRUDO&RPP7HPSRUDO&RPP&RKHUHQW&RKHUHQW&RPP&RKHUHQW&RKHUHQW$FFXPXODWLYH (UURUV&RKHUHQW$FFXPXODWLYH (UURUVKaminka, Pynadath, & Tambe7HPSRUDO&RPP2EVHUYHG 0HVVDJH ([FKDQJHV(a) Run(b) Run JFigure 6: Accumulative number errors runs J.though Figure 5 know due alleviated uncertainty, use communications predictions leads overall higher probability success (i.e.,Coherent, Commtechnique results fewer alternative hypotheses, thus better chance correct). However, Figure 6-b see run J situation changed dramatically.First, see two lines longer similar. line markedCoherent, Commgreater slope run I, indicating communications predictions ablereduce uncertainty, resulting lower average accuracy. Second, see temporal model results many less errors, evidenced much slower-rising slopeline markedCoherent, Temporal.Thus case, actual duration plans matchedtemporal model accurately runs.trying understand dierence runs J, B runssystem, discovered runs J B involved relatively failures partteam-members, including agents crashing responding all.communicationspredictions, however, learned based successful runsand thus correctlypredict communication messages would result team detected recoveredfailures. Thus uncertainty alleviated, arbitrary selectionmade among relatively many hypotheses. explains relatively lower accuracy(Coherent, Comm)technique run J B. clearly shows limitation simplelearning approach took, intend address future work.However,factors inuence accuracy communication models, since loweraccuracy occur runs failures occurred.resultsCoherent, Temporaltechnique vary well.abledetermine failures cause relative increase relative accuracyTemporalCoherent,technique. However, variance results due additional factors. run C,instance, technique results relatively higher accuracy, failure occurred.Certainly, mission specications dier runs, machine loads causemission execution run slower faster, etc. great variance temporal behaviorsystem principal reason using communication prediction.variance obvious graphs.120fiMonitoring Teams Overhearingsummary, despite variance resultsCoherent, Temporaltechnique (duevariance temporal behavior system simplicity temporal model),possible sensitivityCoherent, Commtechnique learned predictions,clear two techniques work well combination, building coherence heuristic,compensating other's weaknesses. runs, combined techniqueTemporal, CommCoherent,superior either technique alone. performance varied72% accuracy (Run E) 97% (Run I). average accuracy across runs allcombination technique 84%, resulting signicant increases accuracy comparedinitial solution began investigation (less 4%), humannovice performance (see Section 6.3).Thus communications predictions needperfect, temporal knowledge need precise, order useful.6.2 Evaluating Use Communications PredictionsOne key question use communications predictions sensitivity lossobservations. ecacy technique (see Figure 5) stems capability makeinferences based expectedfutureobservation. predictions used previoussection assumed observation loss, i.e., prediction stated particular messageobserved, probability assigned prediction 1.0. settingsinvolving lossy observation streams, inference prove incorrect, Overseerwait observation therefore correctly monitor actual state teammembers.evaluate predictions' sensitivity observation loss, chose three experimental runs, E, I, J, represent extreme performance results Overseer:Run E lowest accuracy (72%), Run highest (97%), run J showedinteresting reverse relative performance(see Figure 5).Coherent, TemporalCoherent, Commruns, simulated observation loss rate 10%,repeating trial three times dierent random seeds. words, ran total9 trials, random 10% messages observed Overseerobservable Overseer (though still reached evacuation team-membersteam-performance identical original settings).set predictionsappropriately use 90%10% settings: expected message predicted appear0.9 probability (as opposed 1.0 probability originally).results experiments presented Figure 7. three dierentruns, two bars presented. left (shaded) bar shows original results presentedprevious section (i.e., observation loss, treatment possible losspredictions). right bar shows average accuracy achieved Overseer threetrials (for run) 10% observations observable Overseer.error-bars right bar mark minimum maximum accuracy values achievedthree trials run. Run I's error-bars unseen since three trials resultedaccuracy.number promising conclusions drawn results.First, runs E I, Overseer's average accuracy dropped less 8%, i.e.,performance Overseer dropped less level loss introduced. Indeed,run E, original performance poorest, almost change121fiKaminka, Pynadath, & TambeAverage Accuracy10.80.60.40.20Run ERunRun JFigure 7: Comparison average accuracy results 0% 10% observation losses.performance. Performance run J drop slightly 10%,least partially explained run J's previously discussed failures exploit communications predictions. Thus one promising conclusion drawn resultsOverseer's performance degrade gracefully, rate comparable ratedegradation Overseer's input.second conclusion Overseer's performance observation-loss settingsfairly invariant. Again, run E I, considered normative, showlittle (if any) variance one trial next, despite change selectionobservations made unobserved one trial next. Even run J,representative normative runs, shows little variance respect averageaccuracy observation loss.result suggests may dropperformance observation loss (as expected), Overseer performs consistentlyvarying lossy settings.6.3Overseer Human Monitoring OverhearingAnother important facet evaluation Overseer examines performance comparison novice expert monitors evacuation application. evaluationsheds light diculty monitoring task, demonstrates Overseer's performance comparable (sometimes higher, sometimes lower) human expertperformance, signicantly better novices.conduct evaluation, examined three runs representatives Overseer's bounds performance discussed (runs E, I, J). rst authorpaper served expert monitor, much experience overhearing evacua-122fiMonitoring Teams Overhearing2tion application possible (and specically actual test runs E, J) . established group novice monitors, made subjects generally familiarhierarchical control structures unfamiliar either monitoring overhearingevacuation application component agents. subject presentedprinted books (one run) containing overheard messages (in human-readableform), messages overheard Overseer optimal (lossless) conditions.reference material, subject given copy plan-hierarchy, team-hierarchy,average duration information available Overseer (the parameterdierentleaf plans). overheard message, second line print indicated time passedsince overhearing message, subject asked write best estimateagents' current state (i.e., message overheard specied timepassed). felt dierent agents dierent sub-teams dierent states,specify agent subteam doing. emphasize subjects presentedexactly runs Overseer evaluated.actual test process began short explanation task, full explanation plan-hierarchy (including answering questions subjectssemantics dierent transitions, etc.), short test run allowed subject use plan-hierarchy team hierarchy (but without providing feedbacksubject's accuracy). Then, questions answered, subjectspresented test books given unlimited time complete them, order(though started book, required nish it). Subjects allowedlook forward next message completing answer, go back changeprevious answers. encouraged seek assistance locating plans (inplan-hierarchy) consistent messages, information provided planmay correct two plans consistent. subjects nished runs,test books taken together score computed. correct predictionawarded 1, incorrect prediction 0same standard used scoring Overseer's accuracy. non-specic answer (i.e., somewhere sub-treeFly-Flight-Plan)considered incorrect prediction, subjects repeatedly instructedspecic answer required.results test presented Figure 8.previous graphs, Y-axisdenotes percentage accurate monitoring hypotheses across data-points run(2245, depending run). X-axis three categories, three dierent runs.run, left bar (marked Novices) presents average accuracy achievednovice monitors, middle bar (marked Experts) presents accuracy achievedhuman expert monitor, nal bar (YOYO*) re-prints results presentedFigure 5 above. results show average accuracy novices clearly inferiorexpert monitor Overseer. Overseer's performancehuman expert runs J. However, human expert much betterOverseer run E.draw several conclusions results. First, monitoring task Overseerfaced evacuation application trivial: novices failed achieve2. settle one expert since training expert task time consumingrequires much familiarity internals evacuation application well TEAMCOREarchitecture.123fiKaminka, Pynadath, & Tambe70% average (in best run), generally performed signicantly worse (by 15%more) human expert. Second, Overseer's performance dierent runscomparable human expert (sometimes better, sometimes worse).However,Overseer's performance tended follow trend novices. words,Overseer's accuracy tended go dierent runs similar manneraverage novice human monitor, expert's accuracy remained fairlyconstant across runs.10.8Novices0.6Experts0.4YOYO*0.20JEFigure 8: Accuracy human novice expert monitors compared Overseer.6.4 Evaluating YOYO*'s Trading Expressivity Scalabilityexamine key trade-o expressivity eciency involved planrecognition techniques presented. accuracy discussion above, clearcoherence useful heuristic. YOYO* takes extreme approach, strictly rulingreasoning incoherences.impossible YOYO*, instance, representincoherence two team-members disagreement plan executedcommon team. may thus impossible YOYO* explicitly represent hypotheses associated communication losses delays, cause incoherences.approach individual represented separately allows representation,respect expressive. However, failure-checks place,able detect many incoherences, previously discussed.YOYO*hand, YOYO* oers signicant computational scalability respectnumber agents monitored. Analysis YOYO*'s complexity (in contrast array124fiMonitoring Teams Overhearingapproach) already presented Section 5.2, follow empirical evaluation. Figure 9 reports space requirement YOYO* array-based approachthree dierent domains: evacuation domain, YOYO* evaluateddeployed, two additional domains built multi-agent teamsModSAF(Tambe et al., 1995; Calder, Smith, Courtemanche, Mar, & Ceranowicz, 1993) RoboCup(Tambe, Adibi, Al-Onaizan, Erdem, Kaminka, Marsella, & Muslea, 1999; Marsella, Adibi,Al-Onaizan, Kaminka, Muslea, Tallis, & Tambe, 2001). YOYO* currently evaluateddomains, yet fully deployed there, believe partialexisting implementations sucient provide robust projections space savingsachieved domains.believe projected savings implementationtwo domains could provide rough guide savings designers could expectdeploying YOYO* additional domains.domain, Figure 9 compares space requirements array-based approach(left bar) YOYO* (right bar).addition, dark-shaded region topbar shows space required representing additional agent twoapproaches, assumption additional plans added plan-hierarchyagents added. discussed above, assumption favorable arraybased representation. gure shows signicant space savings achieved YOYO*.First, representing teams current size, YOYO*'s space requirementssignicantly smaller.Furthermore, YOYO*'s savings really shine examinescalability two approaches.array-based approach requires leastamount space shown gure darkly-shaded area, YOYO*'s requirements growone node additional agent. space requirements representing additionalagents small, don't show gure.Number Nodes900600AdditionalAgent300CurrentApplication0ArrayYOYO*Evacuation (11 Agents)ArrayYOYO*RoboCup (11 Agents)ArrayYOYO*ModSAF (3 Agents)Figure 9: Empirical savings applying YOYO* evacuation domains.Earlier, Section 5.2, analyzed YOYO*'s worst case run-time complexity,argued worst case behavior extreme, cannot sustained practicesince involves continuous communications among agents, infeasibility125fiKaminka, Pynadath, & Tambeprovided motivation exploring plan-recognition approach.evidenceaverage case, consider evacuation application, agents communicateaverage every 20 state changes. application, agents communicate parallel4 5 exchanges (out dozens), cases one, parallel communicationsreferred plan, thus still requiring single update YOYO* (see discussionSection 5.2). task execution would 3 agents (out 11) expectedcommunicate parallel dierent plans, scenario still dierent YOYO*'s worstcase scenario.average length task execution domain approximately 900 time-ticks.array approach would update state agent, time tick, whethermessage would appear not.Thus average complexity per time-tickworst-case, least(M N 2 ).YOYO*, average complexity wouldsignicantly dierent: 899 900 time-ticks would result(M + H ) process,one time (out 900) would result process three times expensive (updatingstate 3 dierent agents). worst case scenario occurdierent runs.7. Related WorkAiello et al. (2001) present several benets overhearing agent conversations. suggestoverhearer may infer intent agents engaged conversations, oerspecic suggestions improving agents' performance.instance, overhearingconversation two agents keyword search web, overhearer maysuggest alternative keywords conduct search.work closely relatedresearch Overseer, indeed points several potential additional benetsoverhearing technology. However, contrast work, Aiello et al. addressproblem intent- plan-recognition. present algorithms inferring plans,disambiguating recognized plans.Overseer diers previous work plan-recognition focusedmonitoring multiple agents, single agent.previous work multi-agent planrecognition either focused exploiting explicit teamwork reasoning (e.g.,Tambe,1996), explicitly reasoning uncertainty recognizing multi-agent plans (e.g.,Devaney & Ram, 1998; Intille & Bobick, 1999), key novelty Overseereectively blends two threads together. provide detailed discussion below.Like Overseer,inferringheuristic.RESCteamteam plansRESCteam(Tambe, 1996) reasons explicitly team intentionsobservations, similarly Overseer's use coherenceuses coherence restrict space requirements plan-libraryused, similarly YOYO*.However, Overseer uses advanced teamwork model(e.g., predict failure states recovery actions), uses knowledge proceduresused team (i.e., communication decisions), also explicitly reasons uncertaintytime, allowing answer queries related likelihood current future teamplans (issues addressedRESCteam ).Indeed,RESCteamexplicitly representordering constraints plans, address scarce observations: assumesobservations available account possible changes stateobserved agents.126fiMonitoring Teams OverhearingWork (Devaney & Ram, 1998; Intille & Bobick, 1999) focuses explicitlyaddressing uncertainty plan recognition multi-agent contexts, exploitexplicit notions teamwork. Devaney Ram (1998) use pattern matching recognizeteam-tactics military operations. approach relies team-plan libraries, verieddomain experts, combine team- plan-hierarchies; organizational knowledgeexplicitly represented technique.Similarly, Intille Bobick (1999) relyentirely coordination constraints among agents recognize team-tactics football,sense use socially-attentive technique prefers hypotheses agentsmaintaining roles. Intille Bobick's work uses single structure dierentrecognized tactic. investigations use position trace data monitored human teams.work diers (Devaney & Ram, 1998; Intille & Bobick, 1999) several ways.First, previous investigations applied settings observations continuously available monitored agent. contrast, Overseer targeted towardsoverhearing,limited observations available, time, numberagents actually observed. Overseer introduces number novel techniques (suchcommunications predictions) useful settings. second important dierence underlying representation used reasoning. introduce novel representationparticularly suited monitoring overhearing, Intille Bobick rely standardbelief networks, constructed particular way support reasoning spatial/temporalcoordination. Finally, explicit use make teamwork organizational structure(the team-hierarchy) enables YOYO* principle reason coordination teamwork failures, previous monitoring techniques would fail recognize team'sactions (Intille & Bobick, 1999).Huber (1996) reports use probabilistic plan recognition service observationbased coordination Net-trek domain, shows agents using plan recognitioncoordination outperform agents using communications coordination.Huber takescoordination cooperative actions part self- interested agents, e.g., joiningagent attacking common enemy. Huber's work exploit knowledgerelationships agents limit computation increase accuracy. Huber'ssystem allow uncertainty caused missing observations, contrastwork, introduce specialized mechanisms (such ours) explicitly addressthese.Plan Recognition Bayesian Networks (PRBNs) (Charniak & Goldman, 1993) providegeneral model plan events, evidence, inference. However, PRBN staticBayesian network, must include nodes plans observations throughoutexecution plans. Therefore, instead representing events single timestep (as DBNs described Section 3.1), must include nodes time steps., nite time horizon2steps, number nodes network (T N ). Inference2NMspace/time complexity exponential number nodes, (2), prohibitivelengths execution found example domains (e.g., = 900).Therefore,Nagents, executing plan hierarchy sizerepresentation used YOYO* related existing approaches modelingstochastic processes, particular used probabilistic plan recognition.representation present perhaps closely resembles Hidden Markov Models (HMMs)(Rabiner, 1989), used plan-recognition (Han & Veloso, 1999). One could, theory,127fiKaminka, Pynadath, & Tamberepresent plan state team agents within unconstrained state spaceHMM. However, HMM state space would represent possible combinationsindividual plan states agents, size HMM state space wouldexponential number agents plans. Thus, standard algorithms HMMinference would able exploit structure plan team hierarchies,particular forms evidence (as described Section 3.2), way YOYO*.Generalized versions HMM model (Ghahramani & Jordan, 1997; Jordan, Ghahramani,& Saul, 1997) could compactly represent state space YOYO*, exactinference intractable models. models ecient algorithmsapproximate inference, would diculty determinism presentplanning models.Pynadath Wellman report Probabilistic State-Dependent Grammar (PSDG)model (2000) avoids full complexity DBN inference making simplifying assumptions appropriate plan recognition. However, PSDG incorporate broaderclasses inference YOYO*, intended single-agent plan recognition,support concurrency general enough fashion multi-agent plan recognition.Goldman, Geib Miller (1999) develop conceptual model Bayesian plan recognition include, one key novelties, ability infer plans singleagent lack observation action. However, Goldman et al. deal dierentissue altogether one communications predictions address.frameworklooks sequence observations, observation may missing, observations actions following appear. framework allows inference plansgiven rise missing observation ruled recognition hypotheses.contrast, approach uses communications predictions make inferenceplan-stepsyetoccur. Overseer probabilistically expects predictionscome true, infer additional information missing (predicted) observationfollowed another. addition, approach fully implemented deployedmulti-agent settings, rather single agent.complementary line work (in context TEAMCORE architecture)focusedintendedplan-recognition monitoring, team-members may adaptcommunications monitoring made easier (Tambe etal., 2000).work(i) reduced, eliminate uncertainty, (ii) present methodsaddress uncertainty, here, However, presents interesting future directionOverseer's development.8. Summary Future Workpaper introduced monitoring overhearing, technique increasinglyimportant growing need monitor agent systems, particularly distributed deployed. presented Overseer, system monitoring teams overhearing routinecommunications team-members exchange part execution joint tasks. Monitoring overhearing, plan-recognition task, presents characteristic challengespreviously addressed. include scarcity observations compared ratechange agent's state, fact agents individually observable,observations essentially multi-agent actions. addition these, familiar challenges128fiMonitoring Teams Overhearingdemanding response times maintaining performance face scale-upnumber monitored agents, also present.address challenges, Overseer employs number novel techniques,exploit knowledge relationships agents alleviate uncertainty increase eciency monitoring: (i) ecient probabilistic algorithm plan-recognition,particularly suited monitoring communications; (ii) YOYO*, approach ecientmaintenance recognition coherent hypotheses; (iii) use social structuresprocedures, e.g., team coherence communications maintain coherence, alleviateuncertainty. demonstrate generality techniques, discussed potential use techniques representations plan-hierarchy, particularDBNs (Kjrul, 1992).provided in-depth empirical evaluation techniques one domainsOverseer applied. evaluation carefully examines contributiontechnique overall recognition success, demonstrates techniques workbest together, complement relative weaknesses other. paper also presented evaluation scalability YOYO*, performance conditionsobservation loss. Finally, presented comparison Overseer's performancehuman expert novice monitors, demonstrated Overseer performancecomparable human experts, despite diculty monitoring task.Several opportunities future research directions arise experimental results.First, use rote-learning predict messages observed (provided feasibility demonstration), proved eective normative runs. However, simple mechanismdamaging rare patterns communications arose, experimentsshown. In-depth exploration role learning therefore one directions hopepursue future.addition, learning mechanisms derive plan-hierarchyteam-hierarchy structures records conversations also much interest.Acknowledgementspaper based part Agents-2001 paper authors (Kaminka, Pynadath, & Tambe, 2001). Parts research carried rst authorPost Doctorate Fellow Computer Science Department, Carnegie Mellon University.thank Manuela Veloso enthusiastic support project Carnegie MellonUniversity, thank Yves Lesprance, Victor Lesser, George Bekey, Je Rickel,Dan O'Leary useful comments. Oshra Kaminka deserves special thanks helpanalyzing processing data. research supported DARPA awards F3060298-2-0108, F30602-98-2-0135, F30602-00-2-0549, managed Air Force ResearchLabs/Rome site.Appendix A. Additional algorithms proofsappendix contains pseudo-code algorithms described paper,pseudo-code provided body text itself. include modicationspropagation procedures necessary propagation within YOYO*. addition,129fiKaminka, Pynadath, & Tambeprovide proof number coherent hypothesesplan-libraryM.Nagents linear sizeA.1 Number Incoherent Coherent HypothesesLetMimonitoring plan-library agenti; 1N.monitoring system reasons monitoring hypothesesMinite set possible plans agentMi .monitoring agenti,words, viewmay executing. Given queryagent's current state monitoring system, plan-recognition algorithm pickskiMi hypothesesmi jmi j = ki .specic membershypothesescurrent state agentcall setsconstruct overall team hypothesis, monitoring system must combine individual hypotheses form hypothesis team's state. agent i, monitoringsystem chooses one individual hypothesishi2 mi. combination forms teamstate hypothesis. uncertainty state agent, i.e.,i,one team hypothesis exists.ki=1However, uncertainty exists stateagents, clearly, process selecting individual hypotheses becomes combinatorialnature, possible combinations individual hypotheses possible principle.Let us consider many coherent hypotheses exist. restrict coherenthypotheses, selection individual hypotheses agent constrainedselections agreementthe individual hypothesis selectedagent. Given selection individual state hypothesismust chooseh1=h2=h2h32m=:::2 second agent,=hN .h32mh12m1 rst agent,3 third agent, etc.,Sincek1jM j individual1statehypotheses rst agent, follows number coherent team-state hypothesesboundedjM j, i.e., size plan library agents.1coherent hypotheses boundedfact, numberminki since members mmin ki matchedm. contrast, denition,k1 k2 k3 ::: kN (min ki )members individual hypothesis sets,team-state hypotheses incoherent.hypotheses.A.2 YOYO* Propagation Algorithms (Section 5.1)algorithms presented section support presented main textpaper, provided completeness.may contain stepiterates teams take outgoing transition (e.g., line 1 algorithm 6,line 13 algorithm 7). step requires clarication: iteratingoutgoing teams meet condition, algorithm consults team-hierarchycarry iterationtopmostteams (in terms team-hierarchy)meet condition. instance, application domain, team TASK-FORCE(among others) two subteams TRANSPORTS ESCORTS. transition allowedtaken TRANSPORTS only, iteration teams allowedtake transition consider either ESCORTS TASK-FORCE. However,transition allows TASK-FORCE, iteration step take place onceitexecuted team TASK-FORCE, parent team TRANSPORTSESCORTS.130fiMonitoring Teams OverhearingAlgorithm 6 Team-Propagate-Down(plan , probability , beliefs, b, plans )1:2:3:4:5:6:teams allowed take outgoing hierarchical-decomposition transitionfc j c 2 M; c rst child Y; c taken team g= j CT jplans c 2 CTbt+1 (Y; :block )bt+1 (Y; :block ) + 0(c; 0 ; b; )CT0Team-Propagate-DownAlgorithm 7 Team-Propagate-Forward(team-hierarchy H , beliefs b, plans )1:2:3:4:5:6:7:8:9:10:11:12:13:14:15:16:17:18:19:20:21:22:23:plans X 2bt+1 (X; :block )0:0bt+1 (X; block )0:0outx0:0x0:0plans X 2 post-orderX leafoutxelsebt (X; :block )(1{X parent}{children temporal order parents}e x ) {calculate probability X terminating time t}outx known { post-order guarantees children set line 21}temporal outgoing transitions Tx!y Xxx + (1 xy )xyteams E allowed take temporal outgoing transitionx > 0 {some transition taken}temporal outgoing transitions Tx!y X taken Eoutx (1 xy )xyTx!y leads successor planbt+1 (Y; :block )bt+1 (Y; :block ) +(Y; ; b; )else {Tx!y terminating transition}outparent(x)outparent(x) + (1 xy )xy {parent's outgoing probability chil-Team-Propagate-Downdren's}bt+1 (X; block )bt+1 (X; block ) + outx xbt+1 (X; :block )bt+1 (X; :block ) outx131fiKaminka, Pynadath, & TambeAlgorithm 8 may require clarications. First, important noteplans(line 1) traversed pre-orderparents children. scaling calculationdepends parent scaled probability. Second, iteration sub-plansessentially captures plans subtree rooted parent plansubtree rootedP 'schildX,X 'sexceptalready adjusted YOYO* priorcall algorithm. fact, usesureP,X 'steamsiblings, alternativesXscale plans makesteamT,get scaled.correct procedure called incorporating evidenceX(rathersiblings).Algorithm 8 Scale(parent plan P , team , child plan X , beliefs b)1:2:3:subplans P , team(Y ) 6= , pre-orderbt (Y;:block)b (parent(Y ); :block )bt+1 (Y; :block )bt+1 (Y; :block )+ bt (parent(Y );:block) t+1bt (Y;block)bt+1 (Y; block )bt+1 (Y; block )+ bt (parent(Y );:block) bt+1 (parent(Y ); :block )ReferencesOntological overhearing. Intelligent Agents VIII, Proceedings international workshop Agents, Theories,Architectures, Languages (ATAL-2001).Aiello, M., Busetta, P., Dona, A., & Serani, L. (2001).Barber, K. S., & Martin, C. E. (2001). Dynamic reorganization decision-making groups.Proceedings Fifth International Conference Autonomous Agents (Agents-01),pp. 513520. ACM Press.Calder, R. B., Smith, J. E., Courtemanche, A. J., Mar, J. M. F., & Ceranowicz, A. Z. (1993).Modsaf behavior simulation control. Proceedings Third ConferenceComputer Generated Forces Behavioral Reresentation Orlando, Florida. InstituteSimulation Training, University Central Florida.Charniak, E., & Goldman, R. P. (1993). Bayesian model plan recognition.Intelligence, 64 (1), 5379.ArticialCohen, P. R., Johnston, M., McGee, D., Oviatt, S., Pittman, J., Smith, I., Chen, L., & Clow,J. (1997). Quickset: Multimodal interaction distributed applications.ProceedingsFifth Annual International Multimodal Conference (Multimedia '97), pp. 3140.Cohen, P. R., & Levesque, H. J. (1990). Rational interaction basis communication.Cohen, P. R., Morgan, J., & Pollack, M. E. (Eds.),Intentions Commu-nication, Systems Development Foundation Benchmark Series, chap. 12, pp. 221255.MIT Press.Nous, 35.Decker, K. (1995). Environment Centered Analysis Design Coordination Mechanisms.Cohen, P. R., & Levesque, H. J. (1991). Teamwork.Ph.D. thesis, Department Computer Science, University Massachusetts, Amherst.Devaney, M., & Ram, A. (1998). Needles haystack: Plan recognition large spatialProceedings Fifteenth National ConferenceArticial Intelligence (AAAI-98), pp. 942947 Madison, WI.domains involving multiple agents.132fiMonitoring Teams OverhearingDunin-Keplicz, B., & Verbrugge, R. (2001).role dialogue collective problemProceedings fth International Symposium Logical FormalizationCommonsense Reasoning (Commonsense 2001), pp. 89104.solving.Finin, T., Labrou, Y., & Mayeld (1997). KQML agent communication language.Bradshaw, J. (Ed.),Software Agents. MIT Press.Ghahramani, Z., & Jordan, M. I. (1997). Factorial hidden Markov models.29, 245275.Goldman, R. P., Geib, C. W., & Miller, C. A. (1999).Machine Learning,new model plan recognition.Proceedings Conference Uncertainty Articial Intelligence (UAI-1999)Stockholm, Sweden.Grosz, B. (1996). Collaborating systems.AI Magazine, 17 (2).Grosz, B. J., & Kraus, S. (1999). evolution SharedPlans. Wooldridge, M., & Rao,A. (Eds.),Foundations Theories Rational Agency, pp. 227262.Grosz, B. J., & Kraus, S. (1996). Collaborative plans complex group actions.Intelligence, 86, 269358.ArticialHan, K., & Veloso, M. (1999). Automated robot behavior recognition applied robotic soccer.Proceedings IJCAI-99 Workshop Team Behavior Plan-Recognition.Also appears Proceedings 9th International Symposium Robotics Research(ISSR-99).Horling, B., Benyo, B., & Lesser, V. (2001).Using self-diagnosis adapt organizationalProceedings Fifth International Conference Autonomous Agents(Agents-01), pp. 529536.Huber, M. J. (1996). Plan-Based Plan Recognition Models Eective CoordinationAgents Observation. Ph.D. thesis, University Michigan.structures.Huber, M. J., & Hadley, T. (1997). Multiple roles, multiple teams, dynamic environment:Proceedings First International Conference Autonomous Agents (Agents-97), pp. 332339 Marina del Rey,Autonomous netrek agents. Johnson, W. L. (Ed.),CA. ACM Press.Intille, S. S., & Bobick, A. F. (1999). framework recognizing multi-agent actionProceedings Sixteenth National Conference ArticialIntelligence (AAAI-99), pp. 518525. AAAI Press.visual evidence.Jennings, N. R. (1993). Commitments conventions: foundations coordinationmulti-agent systems.Knowledge Engineering Review, 8 (3), 223250.Jennings, N. R. (1995). Controlling cooperative problem solving industrial multi-agentsystems using joint intentions.Articial Intelligence, 75 (2), 195240.Jordan, M. I., Ghahramani, Z., & Saul, L. K. (1997).Hidden Markov decision trees.Mozer, M. C., Jordan, M. I., & Petsche, T. (Eds.),Processing Systems, Vol. 9, p. 501. MIT Press.Advances Neural InformationKaminka, G. A., Pynadath, D. V., & Tambe, M. (2001). Monitoring deployed agent teams.Proceedings Fifth International Conference Autonomous Agents (Agents01), pp. 308315.133fiKaminka, Pynadath, & TambeKaminka, G. A., & Tambe, M. (2000).monitoring.Robust multi-agent teams via socially-attentiveJournal Articial Intelligence Research, 12, 105147.Kinny, D., Ljungberg, M., Rao, A., Sonenberg, E., Tidhar, G., & Werner, E. (1992). Plannedteam activity.Castelfranchi, C., & Werner, E. (Eds.),Articial Social Systems,Lecture notes AI 830, pp. 227256. Springer Verlag, New York.Kjrul, U. (1992).computational scheme reasoning dynamic probabilistic net-Proceedings Conference Uncertainty Articial Intelligence (UAI1992), pp. 121129 San Mateo, CA. Morgan Kaufmann.works.Knoblock, C. A., Minton, S., Ambite, J. L., Ashish, N., Modi, P. J., Muslea, I., Philpot,A. G., & Tejada, S. (1998).Modeling Web sources information integration.Proceedings Fifteenth National Conference Articial Intelligence (AAAI-98).Kumar, S., & Cohen, P. R. (2000). Towards fault-tolerant multi-agent system architecture.Proceedings Fourth International Conference Autonomous Agents (Agents00), pp. 459466 Barcelona, Spain. ACM Press.Kumar, S., Cohen, P. R., & Levesque, H. J. (2000). adaptive agent architecture: Achiev-Proceedings Fourth International Conference Multiagent Systems (ICMAS-00), pp. 159166 Boston, MA.ing fault-tolerance using persistent broker teams.IEEE Computer Society.Lenser, S., Bruce, J., & Veloso, M. (2001).tonomous legged soccer robots.Cmpack: complete software system au-Proceedings Fifth International ConferenceAutonomous Agents (Agents-01), pp. 204211. ACM Press.Lesh, N., Rich, C., & Sidner, C. L. (1999). Using plan recognition human-computer collaboration.Proceedings Seventh International Conference User Modelling(UM-99) Ban, Canada.Levesque, H. J., Cohen, P. R., & Nunes, J. H. T. (1990). acting together.Eigth National Conference Articial Intelligence (AAAI-90)ProceedingsMenlo-Park,CA. AAAI Press.Marsella, C. S., Adibi, J., Al-Onaizan, Y., Kaminka, G. A., Muslea, I., Tallis, M., & Tambe,M. (2001). teammate: Experiences acquired design robocup teams.Journal Autonomous Agents Multi-Agent Systems, 4 (12).Martin, D. L., Cheyer, A. J., & Moran, D. B. (1999).open agent architecture:framework building distributed software systems.13 (1-2), 92128.Applied Articial Intelligence,Ndumu, D. T., Nwana, H. S., Lee, L. C., & Collis, J. C. (1999). Visualizing debuggingProceedings Third International ConferenceAutonomous Agents (Agents-99). ACM Press.distributed multi-agent systems.Payne, T. R., Sycara, K., Lewis, M., Lenox, T. L., & Hahn, S. (2000).Varying userProceedings Fourth InternationalConference Autonomous Agents (Agents-00), pp. 412418.interaction within multi-agent systems.Pechoucek, M., Marik, V., & Stepankova, O. (2000).Role acquaintance modelsagent-based production planning. Klusch, M., & Kerschberg, L. (Eds.),134CooperativefiMonitoring Teams OverhearingInformation Agents IV, Proceedings Fourth International Workshop (CIA-2000),No. 1860 LNAI, pp. 179190. Springer Verlag.Pechoucek, M., Marik, V., & Stepankova, O. (2001). Towards reducing communication tracmulti-agent systems.Journal Applied System Studies.Pynadath, D. V., & Wellman, M. P. (2000). Probabilistic state-dependent grammars planrecognition.Proceedings Conference Uncertainty Articial Intelligence(UAI-2000), pp. 507514.Rabiner, L. R. (1989). tutorial Hidden Markov Models selected applicationsProceedings IEEE, 77 (2), 257286.Reed, C. (1998). Dialogue frames agent communications. Proceedings ThirdInternational Conference Multiagent Systems (ICMAS-98), pp. 246253.speech recognition.Rich, C., & Sidner, C. L. (1997).COLLAGEN: agents collaborate people.Proceedings First International Conference Autonomous Agents (Agents-97), pp. 284291 Marina del Rey, CA. ACM Press.Tambe, M. (1996). Tracking dynamic team activity. Proceedings National Conference Articial Intelligence (AAAI).Tambe, M. (1997). Towards exible teamwork. Journal Articial Intelligence Research,7, 83124.Johnson, W. L. (Ed.),Tambe, M., Adibi, J., Al-Onaizan, Y., Erdem, A., Kaminka, G. A., Marsella, S. C., &Muslea, I. (1999). Building agent teams using explicit teamwork model learning.Articial Intelligence, 111 (1), 215239.Tambe, M., Johnson, W. L., Jones, R., Koss, F., Laird, J. E., Rosenbloom, P. S., & Schwamb,K. (1995).16 (1).Intelligent agents interactive simulation environments.AI Magazine,Tambe, M., Pynadath, D. V., Chauvat, N., Das, A., & Kaminka, G. A. (2000). AdaptiveProceedingsFourth International Conference Multiagent Systems (ICMAS-00), pp. 301308agent integration architectures heterogeneous team members.Boston, MA.Tidhar, G. (1993a). Team oriented programming: Preliminary report. Tech. rep. 41, Australian Articial Intelligence Institute, Melbourne, Australia.Tidhar, G. (1993b). Team oriented programming: Social structures. Tech. rep. 47, AustralianArticial Intelligence Institute, Melbourne, Australia.Vercouter, L., Beaune, P., & Sayettat, C. (2000).Towards open distributed informationWorking NotesAAAI-2000 Workshop Agent-Oriented Information Systems (AOIS-2000), pp.systems way multi-agent conception framework.2938.135fiJournal Artificial Intelligence Research 17 (2002) 35-55Submitted 12/01; published 8/02Inferring Strategies Sentence Ordering MultidocumentNews SummarizationRegina BarzilayNoemie ElhadadKathleen R. McKeownregina@cs.columbia.edunoemie@cs.columbia.edukathy@cs.columbia.eduColumbia University, Computer Science Department1214 Amsterdam AveNew York, 10027, NY, USAAbstractproblem organizing information multidocument summarizationgenerated summary coherent received relatively little attention. sentenceordering single document summarization determined ordering sentences input article, case multidocument summarizationsummary sentences may drawn different input articles. paper, proposemethodology studying properties ordering information news genredescribe experiments done corpus multiple acceptable orderings developedtask. Based experiments, implemented strategy ordering informationcombines constraints chronological order events topical relatedness. Evaluation augmented algorithm shows significant improvement orderingtwo baseline strategies.1. IntroductionMultidocument summarization poses number new challenges single document summarization. Researchers already investigated issues identifying repetitionscontradictions across input documents determining information salient enoughinclude summary (Barzilay, McKeown, & Elhadad, 1999; Carbonell & Goldstein,1998; Elhadad & McKeown, 2001; Mani & Bloedorn, 1997; McKeown, Klavans, Hatzivassiloglou, Barzilay, & Eskin, 1999; Radev & McKeown, 1998; White, Korelsky, Cardie, Ng,Pierce, & Wagstaff, 2001). One issue received little attention organizeselected information output summary coherent. relevantpieces information selected across input documents, summarizerdecide order present whole text makes sense. singledocument summarization, one possible ordering extracted information providedinput document itself. However, Jing (1998) observed that, single document summaries written professional summarizers, extracted sentences always retainprecedence orders summary. Moreover, case multiple input documents,provide useful solution: information may drawn different documentstherefore, single document provide ordering. Furthermore, order twopieces information change significantly one document another.paper, provide corpus based methodology studying ordering. goaldevelop good ordering strategy context multidocument summarizationc2002AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiBarzilay, Elhadad & McKeowntargeted news genre. first question addressed importance ordering. conducted experiments show ordering significantly affects readerscomprehension text. experiments also show although single idealordering information, ordering unconstrained problem; number good orderings given text limited. second question addressed analysis usedata infer strategy ordering. Existing corpus based methods, supervisedlearning, easily applicable problem part lack training data.Given multiple possible orderings, corpus providing one orderingset information allow us differentiate sentences must together sentences happen together. led us develop corpus datasets, contains multiple acceptable orderings single text. corpusexpensive construct therefore, provide enough data pure statisticalapproaches. Instead, used hybrid corpus analysis strategy first automatically identifies commonalities across orderings. Manual analysis resulting clusters ledidentification constraints ordering. Finally, evaluated plausible ordering strategiesasking humans judge results.set experiments together suggests ordering algorithm integrates constraints approximation temporal sequence underlying eventsrelatedness content elements. evaluation plausible strategies measuredusefulness Chronological Ordering algorithm used previous summarization systems(McKeown et al., 1999; Lin & Hovy, 2001) well alternative, original strategy,Majority Ordering. evaluation showed two ordering algorithms aloneyield satisfactory results. first, Majority Ordering, critically linked levelsimilarity information ordering across input texts. input texts differentorderings, however, algorithm produces unpredictable unacceptable results.second, Chronological Ordering produces good results information event-based,therefore, temporally sequenced. texts refer events, describestates properties, algorithm falls short.automatic analysis revealed topical relatedness important constraint;groups related sentences tend appear together. algorithm combines ChronologicalOrdering constraints topical relatedness. Evaluation shows augmentedalgorithm significantly outperforms either simpler methods alone. strategycharacterized bottom-up since final ordering text emerges datagroups together, whether related content chronological sequence. contraststop-down strategies RST (Moore & Paris, 1993; Hovy, 1993), schemas (McKeown, 1985) plans (Dale, 1992) impose external, rhetorically motivated orderingdata.following sections, first show way information ordered summarycritically affect overall quality. give overview summarizationsystem, MultiGen. next describe two naive ordering algorithms evaluatethem, followed study multiple orderings produced humans. allows usdetermine improve Chronological Ordering algorithm using cohesionadditional constraint. last section describes augmented algorithm alongevaluation.36fiSentence Ordering Multidocument News Summarization2. Impact Ordering Overall Quality SummaryEven though problem ordering information multidocument summarizationreceived relatively little attention, hypothesize good ordering crucial producesummaries quality. consensus architecture state art summarizers consistscontent selection module salient information extracted regenerationmodule information reformulated fluent text. Ideally, regenerationcomponent contains devices perform surface repairs text anaphoraresolution, introducing cohesion markers choosing appropriate lexical paraphrases.claim paper multidocument summarization architecture needsexplicit ordering component. two pieces information extracted content selectionphase end together not, fact, next one another, surface devicesrepair impaired flow information summary. ordering strategy wouldhelp avoid situation.clear ordering cannot improve output earlier stages summarizer,among content selection1 ; however, finding acceptable ordering enhance usercomprehension summary and, therefore, overall quality. course, surface devicesstill needed smooth output summary, scope paper (butsee (Schiffman, Nenkova, & McKeown, 2002)). section show qualityordering direct effect user comprehension summary. verify hypothesis,performed experiment, measuring impact ordering users comprehensionsummaries.selected ten summaries produced Columbia Summarization system (McKeown, Barzilay, Evans, Hatzivassiloglou, Kan, Schiffman, & Teufel, 2001). composedrouter two underlying summarizers MultiGen DEMS (Difference EngineMultidocument Summarization). Depending type input articles summarized, router selects appropriate summarizer. evaluated systemDocument Understanding Conference 2001 (DUC) 2 evaluation, summaries producedseveral systems graded human judges according different criteria, amongwell information contained summary ordered. actually identifypossible impact ordering comprehension, selected summaries humansjudged ordering poor.3 summary, manually reordered sentencesgenerated summarizer, using input articles reference. so,change content sentences reordered summariesones originally produced summaries. process yields ten additional reorderedsummaries thus, overall collection contains twenty summaries.Two subjects authors participated experiment. summaryread one participant without access input articles. distributedsummaries among judges none read original summaryreordering. asked grade well summary could understood, usingratings Incomprehensible, Somewhat comprehensible Comprehensible.1. information added deleted content selection performed.2. http://www-nlpir.nist.gov/projects/duc/3. selected summaries produced DEMS system. didnt select summary producedMultiGen implemented ordering algorithm time. DEMS hand,specific ordering strategy implemented thus provided us appropriate type data.37fiBarzilay, Elhadad & McKeownresults shown Figure 14 . Seven original summaries considered incomprehensible judge, two somewhat comprehensible, one original summaryfully comprehensible. reordered summaries obtained better grades overall fivesummaries fully comprehensible, two somewhat comprehensible, three remained incomprehensible. assess statistical significance results, appliedFisher exact test data set, conflating Incomprehensible Somewhat comprehensible summaries one category obtain 2x2 table. test adaptedcase reduced size data set. obtained p-value 0.07 (Siegal& Castellan, 1988), means reordering not, general, helpful,7% chance reordering anyway would produce result different qualityoriginal ordering. experiment indicates good ordering improveoverall comprehensibility summary.Summary setd13d19d24d31d32d39d45d50d54d56OriginalIncomprehensibleSomewhat comprehensibleIncomprehensibleSomewhat comprehensibleIncomprehensibleIncomprehensibleIncomprehensibleIncomprehensibleIncomprehensibleComprehensibleReorderedIncomprehensibleComprehensibleComprehensibleComprehensibleSomewhat comprehensibleIncomprehensibleIncomprehensibleComprehensibleSomewhat comprehensibleComprehensibleFigure 1: Impact ordering user comprehension summaries.case low-scoring summaries, clear poor ordering likelyculprit. instance, readers easily identify grouping two following sentencesunsuitable choice could misleading. Miss Taylors health problems startedfall horse 13 filming movie National Velvet. recoveryElizabeth Taylor, near death two weeks ago viral pneumonia, complicated yeastinfection, doctors said Friday. cases, information summarypoorly ordered readers cannot make sense text, observed interviewsreaders tend blame content selection rather ordering,even content issue. Thus, issue ordering isolated; affectoverall quality summary.3. MultiGen Overviewframework MultiGen system (McKeown et al., 1999), multidocument summarizer trained tested news articles. MultiGen partColumbia Summarization System. operates set news articles describing4. set names ones used DUC evaluation.38fiSentence Ordering Multidocument News Summarizationevent, creating summary synthesizes common information across documents.system runs daily real data within Newsblaster 5 , tool collects news articlesmultiple sources, organizes topical clusters provides summaryclusters.case multidocument summarization articles event, sourcearticles contain repetitions contradictions. Extracting similar sentences would produce verbose repetitive summary, extractingsimilar sentences would produce summary biased towards sources. MultiGen usescomparison extracted similar sentences select appropriate phrases includesummary reformulates new text.MultiGen consists analysis generation component. analysis component (Hatzivassiloglou, Klavans, & Eskin, 1999) identifies units text convey similarinformation across input documents using statistical techniques shallow text analysis. similar text units identified, cluster themes. Themes setssentences different documents contain repeated information necessarily contain sentences documents (see two examples themes Figure 2).theme, generation component (Barzilay et al., 1999) identifies phrasesintersection theme sentences selects part summary.intersection sentences ordered produce coherent text. end,theme single corresponding generated output sentence summary.following section, describe different strategies ordering output sentencesobtain quality summary.Theme 1Mr. Salvi, 24, apparently killed prison cell last November.state wouldnt execute killing two abortion clinic workers 1994, JohnC. Salvi III took life.John C. Salvi III, convicted killing two people shooting spree twoabortion clinics 1994, killed prison.Theme 2attorneys said attempted suicide twice prison.lawyers said twice tried commit suicide jail, charge authoritiesdenied.Figure 2: Two themes corresponding sentences. Theme 2 contains sentencestwo articles, Theme 1 contains sentences three input articles.4. Naive Ordering Algorithms Sufficientproducing summary, multidocument summarization system chooseorder present output sentences. section, describe two algorithms5. http://www.cs.columbia.edu/nlp/newsblaster39fiBarzilay, Elhadad & McKeownordering sentences suitable multidocument summarization news genre.first algorithm, Majority Ordering (MO), relies original orders sentencesinput documents. second one, Chronological Ordering (CO), uses time-relatedfeatures order sentences. strategy originally implemented MultiGenfollowed summarization systems (Radev, Jing, & Budzikowska, 2000; Lin & Hovy,2001). MultiGen framework, ordering sentences equivalent ordering themes,describe algorithms terms themes. makes sense because, ultimately,summary composed sequence sentences, one constructedinformation one theme. evaluation shows methods alone provideadequate strategy ordering.4.1 Majority Ordering4.1.1 Algorithmsingle document summarization, order sentences output summary typicallydetermined order input text. strategy adapted multidocumentsummarization. Consider two themes, h 1 h2 ; sentences h1 precede sentencesh2 input texts, presenting h 1 h2 likely acceptableorder. use majority ordering algorithm order sentences h 1h2 varies one text another, must augment strategy. One way defineorder h1 h2 adopt order occurring majoritytexts h1 h2 occur. strategy defines pairwise order themes.However, pairwise relation necessarily transitive. example, given themesh1 , h2 h3 following situation: h1 precedes h2 text, h2 precedesh3 text another text, h 3 precedes h1 yet another text;conflict orders (T h1 , h2 , h3 ) (T h3 , h1 ). Since transitivity necessarycondition relation called order, relation form order.We, therefore, expand pairwise relation provide total order.words, find linear ordering themes maximizes agreementorderings provided input texts. pair themes, h hj ,keep two counts, Ci,j Cj,i ; Ci,j number input texts sentenceshi occur sentences hj , Cj,i opposite order. weightlinear order (T hi1 , . . . , hik ) defined sum counts every pair C il ,im ,il im l, {1 . . . k}. Stating problem terms directed graphnodes themes, vertex h hj weight Ci,j , lookingpath maximal weight traverses node exactly (see Figure 3).call graph precedence graph.problem finding path maximal weight addressed Cohen,Schapire, Singer (1999) task learning orderings. adopt two-stageapproach. first stage, given training corpus ordered instances setfeatures describing them, binary preference function learned. second stage, newinstances ordered agreement learned preference function maximized.so, Cohen et al. (1999) represent preference function directed, weightedgraph. precedence graph seen graph preference function40fiSentence Ordering Multidocument News Summarizationh11 h12 h13h23 h22 h24h34 h31 h32 h33Th 1221Th 2211Th 3111Th 4Figure 3: Three input theme orderings corresponding precedence graph. h jisentence part theme hi input ordering j.nodes hi hj Ci,j . orderings input articles provide usdirectly preference function and, therefore, need learn it.Unfortunately problem NP-complete; Cohen et al. (1999) prove reducingCYCLIC-ORDERING (Galil & Megido, 1977). However, using modified versiontopological sort provides us approximate solution. node, assignweight equal sum weights outgoing edges minus sum weightsincoming edges. first pick node maximum weight, ordering aheadnodes, delete outgoing edges precedence graph updateproperly weights remaining nodes graph. iteratenodes graph empty. Cohen et al. (1999) show algorithm producestight approximation optimal solution. Currently MultiGen uses implementationalgorithm ordering component.Figures 4 5 show examples produced summaries. One feature strategyproduce several orderings weight. happenstie two opposite orderings. situation, strategy provide enoughconstraints determine one optimal ordering; ordering chosen randomly amongorders maximal weight.4.1.2 Evaluationasked three human judges (not including ourselves) classify quality orderinformation 25 summaries produced using MO algorithm three categoriesPoor, Fair Good. use operational definition Poor summary text whose41fiBarzilay, Elhadad & McKeownman accused firebombing two Manhattan subways 1994 convicted Thursday juryrejected notion drug Prozac led commit crimes.found guilty two counts attempted murder, 14 counts first-degree assault two countscriminal possession weapon.December 1994, Leary ignited firebombs two Manhattan subway trains. second blast injured 50people 16 seriously, including Leary.Leary wanted extort money Transit Authority.defense argued Leary responsible actions toxic psychosis causedProzac.Figure 4: summary produced using Majority Ordering algorithm, graded Good.Hemingway, 69, died natural causes Miami jail arrested indecent exposure.book wrote father, Papa: Personal Memoir, published 1976.picked last Wednesday walking naked Miami.difficult life.transvestite later sex-change operation, suffered bouts drinking, depression drifting,according acquaintances.easy son great man, Scott Donaldson, told Reuters.time death, lived Coconut Grove district well-known Bohemiancrowd.due appear court later day charges indecent exposure resisting arrest.sometimes went name Gloria wore womens clothes.cause death hypertension cardiovascular disease.Taken Miami-Dade Womens Detention Center, found dead cell early Monday,spokeswoman Janelle Hall said.booked womens jail sex-change operation, Hall added.Figure 5: summary produced using Majority Ordering algorithm, graded Poor.readability would significantly improved reordering sentences. Fair summarytext makes sense, reordering sentences yield better readability. Finally, summary cannot improved sentence reorderingconsidered Good summary.judges asked grade summaries taking account orderinformation presented. help focus aspect texts,resolved dangling references beforehand. Figure 13 shows grades assigned summaries three summaries graded Poor, 14 graded Fair, eightgraded Good. showing majority grade selected least twojudges. made possible experiments, judges strong agreement;never gave three different grades summary.MO algorithm produces small number Good summaries,summaries graded Fair. instance, summary graded Good shown Figure 4orders information natural way; text starts sentence summaryevent, outcome trial given, reminder facts caused trialpossible explanation facts. Looking Good summaries producedMO, found performs well input articles follow order42fiSentence Ordering Multidocument News Summarizationpresenting information. words, algorithm produces good orderinginput articles orderings high agreement.hand, analyzing Poor summaries, observed input textsdifferent orderings. trying maximize agreement input textsorderings, MO produces new ordering occur input text. orderingis, therefore, guaranteed acceptable. example new produced orderinggiven Figure 5. summary would readable several sentences movedaround. example better ordering given Figure 6. summary,three sentences related fact subject sex-change operation groupedtogether, one produced majority ordering algorithm, scatteredthroughout summary.Hemingway, 69, died natural causes Miami jail arrested indecent exposure.cause death hypertension cardiovascular disease.picked last Wednesday walking naked Miami.due appear court later day charges indecent exposure resisting arrest.Taken Miami-Dade Womens Detention Center, found dead cell early Monday,spokeswoman Janelle Hall said.booked womens jail sex-change operation, Hall added.transvestite later sex-change operation, suffered bouts drinking, depression drifting,according acquaintances.sometimes went name Gloria wore womens clothes.difficult life.easy son great man, Scott Donaldson, told Reuters.time death, lived Coconut Grove district well-known Bohemiancrowd.book wrote father, Papa: Personal Memoir, published 1976.Figure 6: One possible better ordering summary graded Poor.algorithm used order sentences accurately certaininput texts follow similar organizations. assumption may hold limited domainsdocuments fixed organization information. However, case,input texts processing regularities. Looking daily statisticsNewsblaster collects clusters related articles synthesized one summary,notice typical cluster size seven. every day several clusterscontain 20 70 articles summarized single summaries 6 .big number input articles, cannot assume similarordering information. MOs performance critically depends agreementorderings input texts; we, therefore, need ordering strategy fitinput data. on, focus Chronological Ordering algorithmtechniques improve it.6. giant clusters correspond hot topics day news.43fiBarzilay, Elhadad & McKeown4.2 Chronological Ordering4.2.1 AlgorithmMultidocument summarization news typically deals articles published differentdates, articles cover events occurring wide range time. Usingchronological order summary describe main events helps user understandhappened. seems like natural appropriate strategy. mentioned earlier,framework, ordering themes; using strategy, we, therefore, need assigndate themes. identify date event occurred requires detailed interpretationtemporal references articles. recent developments disambiguating temporal expressions event ordering (Wiebe, OHara, Ohrstrom-Sandgren, &McKeever, 1998; Mani & Wilson, 2000; Filatova & Hovy, 2001), correlating eventsdate occurred hard task. case, approximate theme timefirst publication time; is, first time theme reported setinput articles (see Figure 7). acceptable approximation news events; firstpublication time event usually corresponds occurrence real life. instance,terrorist attack story, theme conveying attack date previousdate theme describing trial following attack.Theme 5Oct 5, 11:35amOct 6, 6:13amOct 5, 10:20amHours crash, U.S. officials said tragedycaused S-200 missile fired Ukraine military exercisesCrimean Peninsula.U.S. officials said immediately crash evidencepassenger jet hit Ukrainian missile.U.S. officials said crash caused S-200missile fired mistakenly Ukrainian forces military exercisesCrimean Peninsula.Figure 7: theme corresponding sentences. time theme shown underlined;earliest publication time sentences.Articles released news agencies marked publication time, consistingdate time two fields (hour minutes). Articles news agencythus guaranteed different publication times. also quite likely articlescoming different news agencies. development MultiGen, processedhundreds articles, never encountered two articles publication time.Thus, publication time serves unique identifier articles. result, twothemes publication time, means reported firsttime article.Chronological Ordering (CO) algorithm takes input set themes orderschronologically whenever possible. theme assigned date correspondingfirst publication. so, select theme sentence earliestpublication time. call time stamp sentence assign publication time44fiSentence Ordering Multidocument News Summarizationtime stamp theme. establishes partial order themes. twothemes date (that is, reported first time article)sort according order presentation article. results totalorder input themes. Figures 8 9 show examples summaries produced usingCO.One four people accused along former Pakistani Prime Minister Nawaz Sharif agreed testifycase involving possible hijacking kidnapping charges, prosecutor said Wednesday.Raja Quereshi, attorney general, said former Civil Aviation Authority chairman alreadygiven statement police.Sharifs lawyer dismissed news speaking reporters Sharif made appearancejudicial magistrate hear witnesses give statements him. Sharif said innocent.allegations stem alleged attempt divert plane bringing army chief General Pervez MusharrafKarachi Sri Lanka October 12.Figure 8: summary produced using Chronological Ordering algorithm graded Good.Thousands people attended ceremony Nairobi commemorating first anniversarydeadly bombings attacks U.S. Embassies Kenya Tanzania.Saudi dissident Osama bin Laden, accused masterminding attacks, nine others still large.President Clinton said, intended victims vicious crime stood everything rightcountry world.U.S. federal prosecutors charged 17 people bombings.Albright said mourning continues.Kenyans observing national day mourning honor 215 people died there.Figure 9: summary produced using Chronological Ordering algorithm graded Poor.4.2.2 EvaluationFollowing methodology used MO algorithm evaluation, asked threehuman judges (not including ourselves) grade 25 summaries generated systemusing CO algorithm applied collection input texts. resultsshown Figure 13: ten summaries graded Poor, eight graded Fairseven graded Good.first suspicion approximation deviates much real chronological order events and, therefore, lowers quality sentence ordering. verifyhypothesis, identified sentences broke original chronological order restored ordering manually. Interestingly, displaced sentences mainly backgroundinformation. evaluation modified summaries shows visible improvement.comparing Good (Figure 8) Poor (Figure 9) summaries, notice two phenomena: first, many badly placed sentences cannot ordered based temporal occurrence. instance, Figure 9, sentence quoting Clinton one eventsequence events described, rather, reaction main events.tool assigning time stamps would assign sentence date Clinton madestatement. also true sentence reporting Albrights reaction. Assigning45fiBarzilay, Elhadad & McKeowndate reaction, generally sentence conveying background information,placing chronological stream main events produce logicalordering. ordering themes is, therefore, covered CO algorithm. Furthermore, sentences cannot assigned time stamp. instance, sentence,vast, sparsely inhabited Xinjiang region, largely desert, many Chinese militarynuclear installations civilian mining. describes state rather event and,therefore, trying describe temporal terms invalid. Thus ordering cannotimproved temporal level.second phenomenon observed Poor summaries typically contain abruptswitches topics generally incoherent. instance, Figure 9, quotesUS officials (third fifth sentences) split, sentences mourning (firstsixth sentences) appear far apart summary. Grouping together wouldincrease readability summary. point, need find additional constraintsimprove ordering.5. Improving Ordering: Experiments Analysisprevious section, showed using naive ordering algorithms producesatisfactory orderings. section, investigate experiments humansidentify patterns orderings improve algorithm.5.1 Collecting corpus multiple orderingsSentences text ordered number ways, text whole stillconvey meaning. majority possible orders likely unacceptable break conventions information presentation. One way identifyconventions find commonalities among different acceptable orderings information. Extracting regularities several acceptable orderings help us specify orderingconstraints given input type. naturally occurring existing collectionsummaries multiple documents aware 7 . even collection wouldsufficient since want analyze collection multiple summaries setarticles. created collection multiple orderings produced different humans. Using collection, studied common behaviors mapped strategiesordering.collection multiple orderings, along test corpus availablehttp://www.cs.columbia.edu/~noemie/ordering/. collected ten sets articlescollection. set consisted two three news articles reporting event.set, manually selected intersection sentences, simulating MultiGen 8 .average, set contained 8.8 intersection sentences. sentences cleaned explicit references (for instance, occurrences President resolved PresidentClinton) connectives, participants would use clues ordering.Ten subjects participated experiment, built one ordering per set7. recent attempt, NIST DUC conference collected sets articles summarize onesummary per set.8. performed manual simulation ensure ideal data provided subjects experiments.46fiSentence Ordering Multidocument News Summarizationintersection sentences. subject asked order intersection sentences setform readable text. Overall, obtained 100 orderings, ten alternativeorderings per set. Figure 10 shows ten alternative orderings collected one set.ParticipantParticipantParticipantParticipantParticipantParticipantParticipantParticipantParticipantParticipant12345678910BGIHFCJAEGBICFAJEHBIGFJAEHCCFGIBJAHEGBIHFJACEGIBFCEHJABGIFCHEJABCFGIEHAJGIBEHFAJCBGICFAJEHFigure 10: Multiple orderings one set collection. A, B, . . . J stand sentences. Underlined automatically identified blocks.first observed surprisingly large portion orderings different.ten sets, two sets identical orderings (in one set, two orderingsidentical set, two pairs identical orderings). varietyproduced orderings interpreted suggesting orderingsactually valid task maybe hard subjects allowproduce reasonable orderings. fact, subjects satisfied orderingsproduced. Furthermore, manually went 100 orderings,appeared valid. words, many acceptable orderings given one setsentences. confirms intuition need look single ideal totalordering rather construct acceptable one.Looking various orderings, one might also conclude ordering wouldwell other. One piece evidence statement that,shown section 2, orderings yield incomprehensible texts thus avoided.Furthermore, text n sentences, n! possible orderings, smallfraction actually valid orderings. One way validate claim wouldenumerate possible orderings single text evaluate one them.would doable small texts (a text 5 sentences 120 possible orderings)texts reasonable size. feasible way validate claim getmultiple orderings text large number subjects. asked subjectsorder one text eight sentences. maximum 40,320 possible orderingssentences. 50 subjects participated, obtained 21 unique orderings, showingnumber acceptable orderings grow fast number participants.conclude small fraction possible orderings informationtext contains orderings render readable text.47fiBarzilay, Elhadad & McKeown5.2 Analysisseveral alternative orderings produced single summary exhibit commonalities.noticed that, within multiple orderings set, sentences always appeartogether. appear order one ordering another,share adjacency relation. on, refer blocks. set,identify blocks automatically clustering sentences across orderings. use distancemetric two sentences, average number sentences separateorderings. Figure 10, instance, distance sentences G 2.blocks identified clustering are: sentences B, D, G I; sentences J; sentencesC F; sentences E H.observed blocks experiment correspond clusters topicallyrelated sentences. blocks form units text dealing subject.words, valid orderings contain blocks topically related sentences. notiongrouping topically related sentences known cohesion. defined Hasan (1984),cohesion device sticking together different parts text. Studies showlevel cohesion direct impact reading comprehension (Halliday & Hasan,1976). Therefore, good orderings cohesive; makes summary readable.Conversely, evaluation CO algorithm showed summaries judgedinvalid contain abrupt switches topic. words, orderings cohesivegraded poorly. correlation quality ordering cohesion.Incorporating cohesion constraint ordering strategy opportunistically groupingsentences together would beneficial. Cohesion achieved surface devices,repetition words coreferences. describe next include cohesion COalgorithm based surface features.6. Augmented AlgorithmDisfluencies arise output CO algorithm topics distributedwhole text, violating cohesion properties (McCoy & Cheng, 1991). typical scenarioillustrated Figure 11. inputs texts 1 , T2 , T3 (ordered publication time). A1 ,A2 A3 belong theme, whose intersection sentence A, similarlyB C. themes B topically related, C related. Summary 1 ,based chronological clues, contains two topical shifts; C backC B. better summary would S2 , keeps B together.6.1 Algorithmgoal remove disfluencies summary grouping together topically relatedthemes. main technical difficulty incorporating cohesion ordering algorithmidentify group topically related themes across multiple documents. words,given two themes, need determine belong cohesion block.single document, topical segmentation (Hearst, 1994) could used identify blocks,technique possibility identifying cohesion sentences across multipledocuments. Segmentation algorithms typically exploit linear structure input text;case, want group together sentences belonging different texts.48fiSentence Ordering Multidocument News SummarizationT1T2T3S1S2A1...C1C2...A2B2A3B3...C3CBBCFigure 11: Input texts T1 T2 T3 summarized Chronological Ordering (S1 ) Augmented algorithm (S2 ).solution consists following steps. preprocessing stage, segmentinput text (Kan, Klavans, & McKeown, 1998) based word distribution coreferenceanalysis, given two sentences within text, determinetopically related. Assume themes B exist, contains sentences (A 1 . . . ),B contains sentences (B1 . . . Bm ). Recall theme set sentences conveyingsimilar information drawn different input texts. denote #AB numberpairs sentences (Ai , Bj ) appear text, #AB + numbersentence pairs appear text segment.first stage, pair themes B, compute ratio #AB + /#ABmeasure relatedness two themes. measure takes account positivenegative evidence. sentences B appear togethertexts also segments, means B highly topically related.case, ratio close 1. hand, among texts containing sentencesB, pairs segments, B topicallyrelated. Accordingly, ratio close 0. B considered related ratiohigher predetermined threshold. determined experimentally value 0.6.strategy defines pairwise relations themes. transitive closurerelation builds groups related themes and, result, ensures themesappear together article related third theme stilllinked. creates even higher degree relatedness among themes. usethreshold establish pairwise relations, transitive closure produce elongatedchains could link together unrelated themes. able identify topicallyrelated themes. end first stage, grouped blocks.second stage, assign time stamp block related themes usingearliest time stamp themes contains. adapt CO algorithm described 4.2.1work level blocks. blocks themes correspond to, respectively,themes sentences CO algorithm. analogy, easily showadapted algorithm produces complete order blocks. yields macro-orderingsummary. still need order themes inside block.last stage augmented algorithm, block, order themescontains applying CO algorithm them. Figure 12 shows example summaryproduced augmented algorithm.49fiBarzilay, Elhadad & McKeownalgorithm ensures cohesively related themes spread textdecreases number abrupt switches topics. Figure 12 shows Augmentedalgorithm improves sentence order compared order summary producedCO algorithm Figure 9; sentences quoting US officials grouped together,descriptions mourning.Thousands people attended ceremony Nairobi commemorating first anniversarydeadly bombings attacks U.S. Embassies Kenya Tanzania. Kenyans observing nationalday mourning honor 215 people died there.Saudi dissident Osama bin Laden, accused masterminding attacks, nine others still large.U.S. federal prosecutors charged 17 people bombings.President Clinton said, intended victims vicious crime stood everything rightcountry world. Albright said mourning continues.Figure 12: summary produced using Augmented algorithm. Related sentencesgrouped paragraphs.6.2 EvaluationFollowing methodology used evaluate MO CO algorithms, askedjudges grade 25 summaries produced Augmented algorithm. Results shownFigure 13.manual effort needed compare judge system output extensive consideringhuman judge read three summaries input set well skiminput texts verify misleading information introduced summaries.collected corpus 25 sets articles evaluation. Overall, 75 summariesevaluated. size corpus comparable collection used DUCevaluation (30 sets articles). evaluation shows significant improvementquality orderings CO algorithm Augmented algorithm. assesssignificance improvement, used Fisher exact test, conflating Poor Fairsummaries one category (p-value 0.04). augmented algorithm also showsimprovement MO algorithm (p-value 0.07).Majority OrderingChronological OrderingAugmented OrderingPoor3103Fair1488Good8714Figure 13: Evaluation Majority Ordering, Chronological Ordering Augmented Ordering.50fiSentence Ordering Multidocument News Summarization7. Related WorkFinding acceptable ordering studied domain independent textsummarization. single document summarization, summary sentences typically arranged order found full document, although Jing (1998)reports human summarizers sometimes change original order. multidocumentsummarization, summary consists fragments text sentences selecteddifferent texts. Thus, complete ordering summary sentencesfound original documents.domain dependent summarization, possible establish possible orderingspriori. valid ordering traditionally derived manual analysis corpustexts domain, typically operates set semantic concepts. semanticrepresentation information usually available input ordering component.instance, specific domain news topic terrorist attacks, summariesconstructed first describing place attack, followed numbercasualties, possible perpetrators are, etc.Another alternative ordering information, still domain dependent framework, use data driven approach, produces flexible output.priori defined simple ordering strategies combined together looking set features input. Elhadad McKeown (2001) use techniques produce patientspecific summaries technical medical articles. Examples features influenceordering presence contradiction repetition, relevance patient characteristics,type results reported. linear combination features assigns weightsemantic predicate included output, allowing ordered.case, features domain dependent identified corpus analysisinterviews physicians. case domain independent system, wouldentire new challenge define compute set features.Producing good ordering information also critical task generation community, extensively investigated issue (McKeown, 1985; Moore & Paris, 1993;Hovy, 1993; Bouayad-Agha, Power, & Scott, 2000; Mooney, Carberry, & McCoy, 1990). Oneapproach top-down, using schemas (McKeown, 1985) plans (Dale, 1992) determineorganizational structure text. approach postulates rhetorical structureused select information underlying knowledge base.domain limited, encoding developed kinds propositional contentmatch rhetorical elements schema plan, thereby allowing content selectedordered. Rhetorical Structure Theory (RST) allows flexibility ordering content establishing relations pairs propositions. Constraints based intention(e.g., Moore & Paris, 1993), plan-like conventions (e.g., Hovy, 1993), stylistic constraints(e.g., Bouayad-Agha et al., 2000) used preconditions plan operators containingRST relations determine relation used ordered respectrelations. Another approach (Mooney et al., 1990) bottom-up used grouptogether stretches text long, generated document finding propositionsrelated common focus. Since approach developed generation system,finds related propositions comparisons proposition arguments semantic level.51fiBarzilay, Elhadad & McKeowncase, dealing surface representation, find alternative methodsgrouping text fragments.recent approach Duboue McKeown (2001) implementedautomatically estimate constraints information ordering medical domain,content planning stage. Using collection semantically tagged transcripts writtendomain experts, Duboue McKeown (2001) identify basic adjacency patterns containedwithin plan, well ordering. MultiGen generates summaries newstopic. unconstrained domain, would impossible enumerate semanticspossible types sentences could match elements schema, planrhetorical relations. instance, Duboue McKeown build content planner basedset 29 semantic categories; case, regularity inputinformation. Furthermore, would difficult specify generic rhetorical plansummary news. Instead, content determination MultiGen opportunistic, dependingkinds similarities happen exist set news documents. Similarly,describe ordering scheme opportunistic bottom-up, dependingcohesion temporal connections happen exist selected text.ordering component takes place content selection informationpipeline architecture, contrast generation systems, usually orderingcontent selection come tandem. separation might come costgood ordering given extracted information, possible go backcontent selection extract new information. summarization, content selection drivensalience criteria. believe ordering strategy work differentcontent selectors, independently salience criteria. Therefore, choose keeptwo components, selection ordering, two separate modules.8. Conclusion Future Workpaper investigated information ordering constraints multidocument summarization news genre. evaluated two alternative ordering strategies, ChronologicalOrdering (CO) Majority Ordering (MO). experiments show MO performs wellinput texts follow similar organization information. domainsconstraint holds, MO would appropriate highly effective strategy.news genre cannot make assumption; thus appropriate solution.Chronological Ordering (CO) algorithm provide acceptable solution manycases, sufficient summaries contain information event based.experiments, using corpus collected multiple alternative summariesmultiple documents, show cohesion important constraint contributing ordering.Moreover, also show appropriate ordering information critical alloweasy comprehension summary case possible orderingsinformation acceptable. developed operational algorithm integrates cohesionpart CO algorithm, implemented part MultiGen summarizationsystem. evaluation system shows significant improvement summary quality.paper focused augmenting CO algorithm, believe MOpromising strategy neglected. clear different formssummarization useful different situations, depending intended purpose52fiSentence Ordering Multidocument News Summarizationsummary types documents summarized. future work, planbuild approach used DUC 2001 evaluation, developedsummarizer would use different algorithms summary generation dependingtype input text. suspect ordering strategies may differ also, dependingtype summary. work first investigate whether use augmentedalgorithm summary types. algorithm yield good orderings,investigate corpus analysis summary type specific constraints. suspectaugmented algorithm may apply, instance, biographical summaries, sinceinformation summarized mixture event-based informationchronologically ordered along descriptive information person. unclearwhether apply types summaries summaries different events,since pieces information may temporally related other. also planidentify types summaries would benefit using MO algorithmaugmented version (the way CO algorithm augmented cohesionconstraint).9. Acknowledgmentswork partially supported DARPA grant N66001-00-1-8919, Louis Morinscholarship Viros scholarship. thank Eli Barzilay providing helpexperiments interface, Michael Elhadad useful discussions comments,many voluntary participants experiments. initial work problempresented Human Language Technologies Conference (San Diego, 2001). alsothank anonymous reviewers HLT JAIR comments.ReferencesBarzilay, R., McKeown, K., & Elhadad, M. (1999). Information fusion contextmulti-document summarization. Proc. 37th Annual Meeting Assoc.Computational Linguistics.Bouayad-Agha, N., Power, R., & Scott, D. (2000). text structure incompatiblerhetorical structure?. Proceedings First International Conference NaturalLanguage Generation (INLG2000), Mitzpe Ramon, Israel.Carbonell, J., & Goldstein, J. (1998). use mmr, diversity-based reranking reordering documents producing summaries. Proceedings 21st AnnualInternational ACM SIGIR Conference Research Development InformationRetrieval.Cohen, W., Schapire, R., & Singer, Y. (1999). Learning order things. Journal ArtificialIntelligence, 10, 243270.Dale, R. (1992). Generating Referring Expressions: Constructing Descriptions DomainObjects Processes. MIT Press, Cambridge, MA.Duboue, P., & McKeown, K. (2001). Empirically estimating order constraints contentplanning generation. Proceedings ACL/EACL 2001.53fiBarzilay, Elhadad & McKeownElhadad, N., & McKeown, K. (2001). Generating patient specific summaries medicalarticles. Proceedings NAACL 2001 Workshop Automatic Summarization.Filatova, E., & Hovy, E. (2001). Assigning time-stamps event-clauses. ProceedingsAACL/EACL 2001 Workshop Temporal Spatial Information Processing.Galil, Z., & Megido, N. (1977). Cyclic ordering np-complete. Theoretical Compter Science,5, 179182.Halliday, M., & Hasan, R. (1976). Cohesion English. Longman.Hasan, R. (1984). Reading Comprehension, chap. Coherence Cohesive Harmony.Hatzivassiloglou, V., Klavans, J., & Eskin, E. (1999). Detecting text similarity shortpassages: Exploring linguistic feature combinations via machine learning. Proceedings Joint SIGDAT Conference Empirical Methods Natural LanguageProcessing Large Corpora.Hearst, M. (1994). Multi-paragraph segmentation expository text. Proceedings32th Annual Meeting Association Computational Linguistics.Hovy, E. (1993). Automated discourse generation using discourse structure relations. Artificial Intelligence, 63. Special Issue NLP.Jing, H. (1998). Summary generation intelligent cutting pasting inputdocument. Tech. rep., Columbia University.Kan, M.-Y., Klavans, J., & McKeown, K. (1998). Linear segmentation segmentrelevence. Proceedings 6th International Workshop Large Corpora(WVLC-6).Lin, C.-Y., & Hovy, E. (2001). Neats: multidocument summarizer. ProceedingsDocument Understanding Workshop (DUC).Mani, I., & Bloedorn, E. (1997). Multi-document summarization graph searchmatching. Proceedings Fifteenth National Conference Artificial Intelligence.Mani, I., & Wilson, G. (2000). Robust temporal processing news. Proceedings38th Annual Meeting Association Computational Linguistics.McCoy, K., & Cheng, J. (1991). Focus attention: Constraining said next.Paris, C., Swartout, W., & Mann, W. (Eds.), Natural Language GenerationArtificial Intelligence Computational Linguistics. Kluwer Academic Publishers.McKeown, K. (1985). Text Generation: Using Discourse Strategies Focus ConstraintsGenerate Natural Language Text. Cambridge University Press, England.McKeown, K., Barzilay, R., Evans, D., Hatzivassiloglou, V., Kan, M., Schiffman, B., &Teufel, S. (2001). Columbia multi-document summarization: Approach evaluation.Proceedings Document Understanding Workshop (DUC).McKeown, K., Klavans, J., Hatzivassiloglou, V., Barzilay, R., & Eskin, E. (1999). Towardsmultidocument summarization reformulatin: Progress prospects. Proceedings Seventeenth National Conference Artificial Intelligence.54fiSentence Ordering Multidocument News SummarizationMooney, D., Carberry, S., & McCoy, K. (1990). generation high-level structureextended explanations. Proceedings International Conference Computational Linguistics (COLING90), pp. 276281, Helsinki.Moore, J., & Paris, C. (1993). Planning text advisory dialogues: Capturing intentionalrhetorical information. Journal Computational Linguistics, 19 (4).Radev, D., Jing, H., & Budzikowska, M. (2000). Centroid-based summarization multiple documents: sentence extraction, utility-based evaluation, user studies.Proceedings ANLP/NAACL 2000 Workshop Automatic Summarization.Radev, D., & McKeown, K. (1998). Generating natural language summaries multipleon-line sources. Computational Linguistics, 24(3), 469500.Schiffman, B., Nenkova, A., & McKeown, K. (2002). Experiments multidocument summarization. Proceedings HLT Conference.Siegal, S., & Castellan, N. J. (1988). Non-Parametric statistics behavioural sciences.McGraw Hill.White, M., Korelsky, T., Cardie, C., Ng, V., Pierce, D., & Wagstaff, K. (2001). Multidocument summarization via information extraction. Proceedings HLT Conference.Wiebe, J., OHara, T., Ohrstrom-Sandgren, T., & McKeever, K. (1998). empiricalapproach temporal reference resolution. Journal Artificial Intelligence, 9, 247293.55fi