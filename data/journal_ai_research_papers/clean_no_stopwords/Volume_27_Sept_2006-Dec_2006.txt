Journal Artificial Intelligence Research 27 (2006) 465-503Submitted 04/06; published 12/06Preference-based Search using Example-Critiquing SuggestionsPaolo ViappianiBoi FaltingsPAOLO . VIAPPIANI @ EPFL . CHBOI . FALTINGS @ EPFL . CHArtificial Intelligence Laboratory (LIA)Ecole Polytechnique Federale de Lausanne (EPFL)Station 14, 1015 Lausanne, SwitzerlandPearl PuPEARL . PU @ EPFL . CHHuman Computer Interaction Group (HCI)Ecole Polytechnique Federale de Lausanne (EPFL)Station 14, 1015 Lausanne, SwitzerlandAbstractconsider interactive tools help users search preferred item largecollection options. particular, examine example-critiquing, technique enabling usersincrementally construct preference models critiquing example options presentedthem. present novel techniques improving example-critiquing technology addingsuggestions displayed options. suggestions calculated based analysis userscurrent preference model potential hidden preferences. evaluate performancemodel-based suggestion techniques synthetic real users. Results showsuggestions highly attractive users stimulate express preferencesimprove chance identifying preferred item 78%.1. Introductioninternet makes unprecedented variety opportunities available people. Whether lookingplace go vacation, apartment rent, PC buy, potential customer facedcountless possibilities. people difficulty finding exactly looking for,current tools available searching desired items widely considered inadequate.Artificial intelligence provides powerful techniques help people address essential problem. Search engines effective locating items users provide correct queries.However, users know map preferences query find itemclosely matches requirements.Recommender systems (Resnick et al., 1994; Adomavicius & Tuzhilin, 2005; Burke, 2002b)address problem mapping explicit implicit user preferences items likely fitpreferences. range systems require little input usersuser-involved systems. Many collaborative filtering techniques (Konstan et al., 1997), infer userpreferences past actions, previously purchased rated items. hand,popular comparison websites1 often require users state least preferences desiredattribute values producing list recommended digital cameras, portable computers, etc.article, consider tools provide recommendations based explicitly stated preferences, task call preference-based search. particular, problem defined as:1. E.g., www.shopping.comc2006AI Access Foundation. rights reserved.fiV IAPPIANI , FALTINGS , & P UGiven collection = {o1 , .., } n options, preference-based search (PBS)interactive process helps users identify preferred option, called targetoption ot , based set preferences stated attributestarget.Tools preference-based search face tradeoff two conflicting design goals:decision accuracy, measured percentage time user finds target optionusing tool,user effort, measured number interaction cycles task time user takesfind option believes target using tool.target option, refer option user prefers among available options.determine accuracy product search tool, measure whether target option userfinds tool corresponds option finds reviewing available optionsoffline setting. procedure, also known switching task, used consumer decisionmaking literature (Haubl & Trifts, 2000). Notice procedure used measureaccuracy system. suggest procedure models human decision behavior.one approach, researchers focus purely accuracy order help users find preferred choice. example, Keeney Raiffa (1976) suggested method obtain precise modelusers preferences. method, known value function assessment procedure, asksuser respond long list questions. Consider case search ideal apartment. Suppose decision outcome involves trading preferred values size apartmentdistance apartment city center. typical assessment questionform else equal, better: 30 sqm 60 minutes distance 20 sqm 5 minutes distance? Even though results obtained way provide precise model determinepreferred outcome user, process often cognitively arduous. requiresdecision maker full knowledge value function order articulate answersvalue function assessment questions. Without training expertise, even professionals knownproduce incomplete, erroneous, inconsistent answers (Tversky, 1974). Therefore, techniques useful well-informed decision makers, less users need helprecommender system.Recently, researches made significant improvement method. Chajewska, Koller,Parr (2000) consider prior probability distribution users utility function ask questionshighest value information attributes give highest expected utility. Eventhough developed decision problems uncertainty, adaptive elicitation principleused preference elicitation product search often modeled decisionmultiple objectives (see related work section approach Price & Messinger, 2005).Boutilier (2002) Boutilier, Patrascu, Poupart, Schuurmans (2005) improvedmethod taking account value assigned future preference elicitation questions orderreduce user effort modeling maximum possible regret stopping criterion.another extreme, researchers emphasized providing recommendations little effort possible users. Collaborative filtering techniques (Konstan et al., 1997), example, infer implicit model users preferences items rated. exampletechnique Amazons people bought item also bought... recommendation. However, users may still make significant effort assigning ratings order obtain accurate466fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONSrecommendations, especially new user systems (known new user problem).techniques produce recommendations based users demographic data (Rich, 1979; Krulwich,1997).1.1 Mixed Initiative Based Product Search Recommender Systemstwo extremes, mixed-initiative dialogue systems emerged promising solutions flexibly scale users effort specifying preferences accordingbenefits perceive revealing refining preferences already stated. alsoreferred utility knowledge-based recommender systems according Burke (2002b),utility-based decision support interface systems (DSIS) according Spiekermann Paraschiv(2002). mixed-initiative system, user takes initiative state preferences, typicallyreaction example options displayed tool. Thus, user provide explicit preferencesdecision-theoretic methods, free flexibly choose information provide,recommender systems.success systems depends AI techniques supporting searchrecommending task, also effective user-system interaction model motivates usersstate complete accurate preferences. must strike right compromise recommendation accuracy offers effort requires users. key criterion evaluatesystems therefore accuracy vs. effort framework favors systems offer maximum accuracy requiring less user effort. framework first proposedPayne, Bettman, Johnson (1993) studying user behaviors high-stake decision making settings later adapted online user behaviors medium-stake decision making environments Pu Chen (2005) Zhang Pu (2006).current practice, mixed-initiative product search recommender system computesdisplay set (i.e., items presented user) based closeness items userspreference model. However, set items likely provide diversity hence maycompromise decision accuracy. Consider example user looking portablePC gives low price long battery life initial preferences. best matching productslikely standard models 14-inch display weight around 3 kilograms.user may thus never get impression good variety available weight size, maynever express preferences criteria. Including lighter product display set maygreatly help user identify true choice hence increase decision accuracy.Recently, need recommending best matches, called candidates, alsodiverse set items, called suggestions, recognized. One first recognizeimportance suggestive examples ATA (Linden, Hanks, & Lesh, 1997), explicitlygenerated examples showed extreme values certain attributes, called extreme examples.case-based recommender systems, strategy generating similar diverse casesused (McSherry, 2002; Smyth & McGinty, 2003). Hebrard, Hnich, OSullivan, Walsh (2005) investigated algorithms generating similar diverse solutions constraint programming,used recommend configurable products. complexity algorithmsanalyzed.far, suggestive examples aim providing diverse set items without analyzing deeply whether variety actually helps users make better decisions. One exceptioncompromise-driven diversity generation strategy McSherry (2003) proposes suggest467fiV IAPPIANI , FALTINGS , & P Uitems representative possible compromises user might prepared consider.Pu Li (2005) pointed out, tradeoff reasoning (making compromises) increase decision accuracy, indicates compromise-driven diversity might high potentialachieve better decision quality users. However, empirical studies carriedprove this.1.2 Contribution Workconsider mixed-initiative framework explicit preference model, consisting iterative process showing examples, eliciting critiques refining preference model. Usersnever forced answer questions preferences yet possess. hand,preferences volunteered constructed, directly asked. key differencenavigation-by-proposing used mixed-initiative user interaction model opposedvalue assessment-by-asking used traditional decision support systems.set simulated real-user involved experiments, argue including diversesuggestions among examples shown mixed initiative based product recommendersignificant improvement state-of-the-art field. specifically, showmodel-based suggestion techniques developed indeed motivate users expresspreferences help achieve much higher level decision accuracy without additionaleffort.rest article organized follows. first describe set model-based techniquesgenerating suggestions preference-based search. novelty method includes: 1)expands users current preference model, 2) generates set suggestions based analysislikelihood missing attributes, 3) displays suggested options whose attractivenessstimulates users preference expression. validate theory, examine suggestiontechniques help users identify target choice simulation environments realusers. base evaluation experiments two main criteria. Firstly, considercompleteness users preference model measured preference enumeration, i.e., numberfeatures user stated preferences. higher enumeration, likelyuser considered aspects decision goal, therefore decision likelyrational. Secondly, consider decision accuracy measured contrary switching rate,number users find target option using tool choose anotherproduct reviewing options detail. smaller switching rate, likely usercontent chosen using tool, thus higher decision accuracy.success suggestion techniques confirmed experimental evaluations. onlineevaluation performed real users exploring student housing database. supervised userstudy additionally carried 40 users, performed within-subject experiment setupevaluated quantitative benefits model-based suggestion. results demonstratemodel-based suggestion increased decision accuracy 78%, users effortusing example-critiquing search tool without suggestions. user studiesconsider particular criteria accuracy vs. effort never carried researchersvalidating suggestion strategies optimal elicitation procedures.Finally, end reviewing related works followed conclusion.468fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONSInitialpreferencesUser revisespreference modelcritiquing examplesSystem shows KexamplesUser picks finalchoiceFigure 1: Example-critiquing interaction. dark box computers action, boxes showactions user.2. Example-critiquingmany cases, users searching products information familiar availableitems characteristics. Thus, preferences well established, constructedlearning possibilities (Payne et al., 1993). allow construction take place,search tool ask questions complete realistic context, abstract way.good way follow principle implement example critiquing interaction (seeFigure 1). shows examples available options invites users state critiqueexamples. allows users better understand preferences.Example-critiquing proposed numerous researchers two main forms: systemswithout explicit preference models:systems without preference models, user proceeds tweaking current best example (I like cheaper,I like French cuisine) make fitpreferences better. preference model represented implicitly currently chosenexample interaction navigation-by-proposing. Examples systemsFindMe systems (Burke, Hammond, & Young, 1997; Burke, 2002a), ExpertClerksystem (Shimazu, 2001), dynamic critiquing systems (Reilly, McCarthy, McGinty, &Smyth, 2004).systems preference models, critique added explicit preference modelused refine query. Examples systems explicit preference models includeATA system (Linden et al., 1997), SmartClient (Pu & Faltings, 2000), recentlyincremental critiquing (McCarthy, McGinty, Smyth, & Reilly, 2005).article, focus example-critiquing explicit preference model advantage effectively resolving users preference conflicts. Moreover, approach helpsusers make particular choice, also obtains accurate preference model future purchasescross-domain recommendations.469fiV IAPPIANI , FALTINGS , & P U2.1 Examplesimple example consider student looking housing. Options characterizedfollowing 4 attributes:1. rent Swiss Francs;2. type accommodation: room shared apartment, studio, apartment3. distance university minutes;4. furnished/unfurnished.Assume choice among following options:o1o2o3o4o5o6o7rent400500600600650700800type-of-accommodationroomroomapartmentstudioapartmentstudioapartmentdistance-to-university17321453227furnishedyesyesyesAssume user initially articulates preference lowest price. also hiddenpreferences unfurnished accomodation, distance less 10 minutes university. None options satisfy preferences, suitable option requiresuser make tradeoff among preferences. Let us assume tradeoffs optiono4 would users preferred option. call target option.user may start search first preference (lowest price), tool wouldshow k best options according order shown table. Here, let k = 1option o1 shown.example-critiquing tool without preference model, user indicates critiquecurrently shown example, system searches another example similarpossible current one also satisfying critique. case, user might critiqueo1 furnished, tool might show o3 similar unfurnishedpreference. user might add critique option 10 minutesuniversity, system would return o7 similar option satisfies critique.user might critique option expensive, case system wouldreturn o3 similar preference cheaper option. memoryearlier critiques, process stuck cycle, user never discover target o4 .tool preference model, user able state preference unfurnishedoption, making o3 best option. Next, might add additional preference distanceless 10 minutes university, ending o4 target choice. illustratesexplicit preference model ensures convergence process. fact, decision theoryshows preferences expressed, user always able identifytarget choice. Note however complex scenarios might require explicit tradeoffs amongpreferences locate right target choice (Pu & Kumar, 2004).470fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONSpopular approach obtain preference model elicit asking questions user.However, lead means objectives (Keeney, 1992) distract true target choice.example, tool might first ask user whether prefers room, studio apartment.user truly preference, might try translate preference unfurnished optionpreference apartment, since likely unfurnished. However,true preference shift best tradeoff o4 o3 even o7 . illustratesimportance mixed-initiative approach user state preferences orderinitiative.example-critiquing framework raises issues model preferences, generatesolutions shown user, efficiently implement process. brieflysummarize results previous work addressing issues.2.2 Preference Modelingtool forces users formulate preferences using particular attributes particular order,fall prey means objectives (Keeney, 1992) catalog knowledge relate true intentions. Means objectives objectives person believescorrelate positively true objectives. example, manufacturer reputation goodquality may become objective impossible state objective quality itself.avoid means objectives, require preference model allows users state preferences incrementally using attribute, order wish. Furthermore, preference modelmust easy revise critiquing cycle adding removing preferences.rules commonly used techniques question-answer dialogues selectionfixed set preferences commonly used web today.effective formalism satisfies criteria formulate preferences using soft constraints. soft constraint function attribute combination attributes numberindicates degree constraint violated. generally, values softconstraint elements semiring (Bistarelli, Montanari, & Rossi, 1997).several soft constraints, combined single preference measure. Examples combination operators summing taking maximum. overall preference order outcomesgiven combined measure.example, attribute take values a, b c, soft constraint indicatingpreference value b could map c 1, b 0, thus indicating bviolate preference. preference surface area least 30 square meters,small violation 5 square meters could acceptable, expressed piecewise linearfunction:10.2(30 x)0x < 2525 x 30x > 30example-critiquing, critique expressed soft constraint, preferencemodel incrementally constructed simply collecting critiques. Note also possibleuser express several preferences involving attributes, example express onesoft constraint surface area least 30 square meters (as above), another471fiV IAPPIANI , FALTINGS , & P Usoft constraint 50 square meters. soft constraints combinedsumming effects, result leads piecewise linear function:1x < 250.2(30 x)25 x 30030 < x < 500.2(x 50)50 x 551x > 55Thus, soft constraints allow users express relatively complex preferences intuitive manner.makes soft constraints useful model example-critiquing preference models. Furthermore,exist numerous algorithms combine branch-and-bound constraint consistency techniques efficiently find preferred options combined order. detailsuse soft constraints preference models provided Pu & Faltings (2004).However soft constraints technique allows user partially incrementally specifypreferences. advantage utility functions necessary elicit userspreference every attribute. attributes whose values concern current decision contextelicited. example, user interested certain brand notebooks,concern stating preferences products. parsimonious approachsimilar adaptive elicitation method proposed Chajewska et al. (2000). However,example-critiquing preference-based search, users preferences volunteered reactionsdisplayed examples, elicited; users never forced answer questions preferenceswithout benefit concrete decision context.2.3 Generating Candidate Choicesgeneral, users able state preferences numerical precision. Instead,practical tool needs use approximate preference model users specify preferences qualitative way.good way implement preference model use standardized soft constraintsnumerical parameters chosen fit users. models necessarily inaccuratecertain users. However, inaccuracy compensated showing one, setk best candidate solutions. user chooses preferred one set, thuscompensating preference models inaccuracy. technique commonly usedsearch engines.analyzed technique several types preference models: weighted soft constraints, fuzzy-lexicographic soft constraints, simple dominance relations (Faltings, Torrens, &Pu, 2004).remarkable result weighted fuzzy-lexicographic constraint models, assuming bound possible error (deviation true value one used application)soft constraints modeling preferences, probability true preferred solutionwithin k depends number preferences error bound soft constraintsoverall size solution set. Thus, particularly suitable searchinglarge space items.also found preference model contains many different soft constraints, probability finding preferred option among k best quickly decreases. Thus, compensating472fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONSmodel inaccuracy showing many solutions useful preference models relativelysimple. Fortunately, often case preference-based search, people usually lackpatience input complex models.result, desirable process practice might two-stage process examplecritiquing preference model used first stage narrow set optionslarge (thousands) space possibilities small (20) promising subset. second phasewould use tweaking interaction preference model maintained find best choice.Pu Chen (2005) shown tradeoff strategies tweaking interaction provide excellentdecision accuracy even user preferences complex.2.4 Practical ImplementationAnother challenge implementing example-critiquing large scale practical settingsrequires solutions computed specifically preference model particular user.may challenge web sites many users.However, shown (Torrens, Weigel, & Faltings, 1998; Torrens, Faltings, & Pu, 2002)computation data necessary computing solutions coded compact formrun applet users computer. allows completely scaleable architectureload central servers higher conventional web site. Torrens, Faltings &Pu (2002) describe implementation example-critiquing using architecture toolplanning travel arrangements. commercialized part tool business travelers (Pu& Faltings, 2000).3. Suggestionsbasic example-critiquing cycle, expect users state additional preference longperceive bring better solution. process ends users longer see potentialimprovements stating additional preferences thus reached optimum. However, sinceprocess one hill-climbing, optimum may local optimum. Considerexample user looking notebook computer low price range. Sincepresented products weight, say around 3 kg, might never bother looklighter products. marketing science literature, called anchoring effect (Tversky, 1974).Buyers likely make comparisons products reference product, caseset displayed heavy products. Therefore, buyer might consider possibility lighternotebook might fit requirements better, accept sub-optimal result.hillclimbing, local minima avoided randomizing search process.Consequently, several authors proposed including additional examples selected ordereducate user opportunities present choice options (Linden et al., 1997;Shimazu, 2001; McSherry, 2002; Smyth & McClave, 2001). Thus, displayed examples wouldinclude:candidate examples optimal current preference query,suggested examples chosen stimulate expression preferences.473fiV IAPPIANI , FALTINGS , & P UDifferent strategies suggestions proposed literature. Linden (1997) used extreme examples, attribute takes extreme value. Others use diverse examplessuggestions (Smyth & McClave, 2001; Smyth & McGinty, 2003; Shimazu, 2001).Consider example searching housing mentioned previous section. Recallchoice among following options:o1o2o3o4o5o6o7rent400500600600650700800type-of-accommodationroomroomapartmentstudioapartmentstudioapartmentdistance-to-university17321453227furnishedyesyesyesinitial dialogue system, user stated preference lowest price. Consequently, options ordered o1 o2 o3 = o4 o5 o6 o7 .Assume system shows one candidate, promising option accordingknown preferences: o1 . options shown suggestions motivateuser express remaining preferences?Linden et al. (1997) proposed using extreme examples, defined examples attributetakes extreme value. example, consider distance: o6 example smallestdistance. However, much higher price, furnished satisfy usershidden preference. Thus, give user impression closer distance achievablewithout compromising preferences. user wants distance less 5minutes option o6 good suggestion, otherwise o4 likely better. Another problemextreme examples need two examples attribute, usuallyuser absorb.Another strategy (Smyth & McClave, 2001; McSherry, 2002, 2003; Smyth & McGinty, 2003;Shimazu, 2001) select suggestions achieve certain diversity, also observing certaingoodness according currently known preferences. tool already shows o1 optimal example, different example o5 , differs attributes excessiveprice. o5 good suggestion? shows user following opportunities:apartment instead room: however, o3 would cheaper way achieve this.distance 32 instead 17 minutes: however, o2 would cheaper way achieve this.unfurnished instead furnished: however, o3 would cheaper way achieve this.Thus, o5 diverse, give user accurate picture true opportunities are. problem diversity consider already known preferences,case price, dominance relations imply available options.mitigated somewhat combining diversity similarity measures, example using linearcombination (Smyth & McClave, 2001; McSherry, 2003), solve problemeffects diversity limited attributes without known preferences similarityapplied attributes known preferences.474fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONSconsider strategies generating suggestions based current preference model.call strategies model-based suggestion strategies.assume user minimizing effort add preferencesmodel expects impact solutions. case when:user see several options differ possible preference,options relevant, i.e. could acceptable choices,already optimal already stated preferences.cases, stating additional preference irrelevant: options would evaluateway, preference effect options would eligible anywayalready best choices, stating would wasted effort. contrary, upon displaysuggested outcome whose optimality becomes clear particular preference stated,user recognize importance stating preference. seems confirmeduser studies.led us following principle, call look-ahead principle, basismodel-based suggestion strategies:Suggestions optimal current preference model, provide high likelihood optimality additional preference added.stress heuristic principle based assumptions human behaviorcannot formally prove. However, justified fact suggestion strategies basedlook-ahead principle work well real user studies, report later article.example, o4 o3 highest probability satisfying lookahead principle:currently dominated o1 . o4 becomes Pareto-optimal user wants studio,unfurnished option, distance less 14 minutes. o3 becomes Pareto-optimal userwants apartment, unfurnished option, distance less 17 minutes. Thus, givegood illustration possible within set examples.develop method computing suggestions show generatesuggestions.3.1 Assumptions Preference Modelshow implement model-based suggestion strategies, define preferencemodels minimal assumptions shape user preferences might take. stressassumptions made generating suggestions. preference model usedsearch tool could diverse specific required application.consider collection options = {o1 , .., } fixed set k attributes ={A1 , .., Ak }, associated domains D1 , .., Dn . option characterized valuesa1 (o), ..., ak (o); ai (o) represents value takes attribute Ai .qualitative domain (the color, name neighborhood) consists enumerated setpossibilities; numeric domain numerical values (as price, distance center), either discretecontinuous. numeric domains, consider function range(Att) gives rangeattribute domain defined. simplicity call qualitative (respectively numeric)attributes qualitative (numeric) domains.users preferences assumed independent defined individual attributes:475fiV IAPPIANI , FALTINGS , & P UDefinition 1 preference r order relation r values attribute a; r expressestwo values equally preferred. preference model R set preferences {r1 , .., rm }.Note r might partial total order.preferences combination attributes, total travel timejourney, assume model includes additional attributes model combinationsmake assumption independent preferences attribute. drawbackdesigner know preferential dependence advance. However, requireddesigning user interface anyway.preference ri always applies attribute ai , simplify notation applyri ri options directly: o1 ri o2 iff ai (o1 ) ri ai (o2 ). use ri indicate riholds ri .Depending formalism used modeling preferences, different ways combining order relations given individual preferences ri users preference model Rcombined order options. example, preference may expressed number,combination may formed summing numbers corresponding preferencetaking minimum maximum.rational decision maker prefer option another first least goodcriteria better least one. concept expressed Pareto-dominance (alsocalled dominance), partial order relation options.Definition 2 option Pareto-dominated option o0 respect Rri R, ri o0 least one rj R, rj o0 . write R o0 (equivalently sayo0 Pareto-dominates write o0 R o).also say dominated (without specifying o0 ).Note use symbol individual preferences sets preferences., meaning R o0 r R, r o0 .following, assumption make combination dominancepreserving according definition Pareto-dominance. Pareto dominance generalorder relation defined based individual preferences. forms dominationdefined extensions Pareto dominance. following, whenever use dominancewithout specification, refer Pareto-dominance.Definition 3 preference combination function dominance-preserving wheneveroption dominates another option individual orders, dominates combinedorder.combination functions used practice dominance-preserving. examplecombination dominance-preserving case preferences representedsoft constraints combined using Min(), fuzzy CSP (Ruttkay, 1994). case, twooptions constraint valuationso1 (0.3, 0.5, 0.7)o2 (0.3, 0.4, 0.4)considered equally preferred combination function in(0.3, 0.5, 0.7) = 0.3 =in(0.3, 0.4, 0.4), even though o1 dominated o2 .476fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONS3.2 Qualitative Notions Optimalitymodel-based suggestion strategies going introduce based principle selecting options highest chance becoming optimal. determined consideringpossible new preferences characterizing likelihood make option optimal. Sinceknow weight new preference take users perception, must evaluateusing qualitative notion optimality. present two qualitative notions, one basedPareto-optimality another based combination function used generating candidatesolutions.obtain suggestion strategies valid preference modeling formalism,using qualitative optimality criteria based concept Pareto-dominance introduced before.Definition 4 option Pareto-optimal (PO) dominatedoption.Since dominance partial order, Pareto optimal options seen maximal elementsO. Pareto-optimality useful applies preference model long combination function dominance-preserving.dominance-preserving combination function, option preferredcombined preference order Pareto-optimal, since option o0 dominates wouldpreferred. Therefore, Pareto-optimal solutions optimal combined preferenceorder, matter combination function is. makes Pareto-optimality useful heuristicgenerating suggestions independently true preference combination users mind.example-critiquing, users initially state subset R eventual preference modelR. preference added, dominated options respect R become Pareto-optimal.hand, option loose Pareto-optimality preferences added exceptoption equally preferred respect preferences considered becomedominated.Note one also consider using weak Pareto-optimality defined Chomicki(2003), consider options equal respect attributes preferencestated.introduce notions dominating set equal set:Definition 5 dominating set option respect set preferences R set>options dominate o:(o) = {o0 : o0 R o}. write O> (o), without specifying R,set preferences, R clear context.equal set option respect R set options equally preferred= (o) = {o0 : o0 o}. also use > = .o:Rfollowing observation basis evaluating likelihood dominated optionbecome Pareto-optimal new preference ri stated.Proposition 1 dominated option respect R becomes Pareto-optimal respectR ristrictly better respect ri options dominate respect Rworse respect ri options equally preferred respect R.477fiV IAPPIANI , FALTINGS , & P UProof 1 Suppose option o0 dominates respect R strictlybetter o0 new preference ri ; o0 would still dominate o, could Paretooptimal. Similarly, suppose equally preferred o00 o00 strictly betterrespect ri ; o00 would dominate o, could Pareto-optimal.Thus, dominating set O> equal set O= given option potential dominatorsnew preference considered.Utility-dominance consider forms dominance long imply Paretodominance. particular, might use total order established combination function defined preference modeling formalism, weighted sum. call utility-domination,utility-optimal option preferred one.may ask option become utility-optimal. weaker form Proposition 1 holdsutility domination:Proposition 2 dominance-preserving combination functions, utility-dominated option o0respect R may become utility-optimal respect R ri o0 strictly betterrespect ri options currently utility-dominate worse optionscurrently equally preferred.Proof 2 Suppose option became utility-optimal without preferredaccording new preference; would violation assumption combination function dominance-preserving.Even though sufficient condition, Proposition 2 used heuristic characterizeoptions chance become utility-optimal.3.3 Model-based Suggestion Strategiespropose model-based suggestion strategies implemented conceptPareto- utility-dominance. based look-ahead principle discussed earlier:suggestions optimal current preference model, highlikelihood becoming optimal additional preference added.assume system knows subset R users preference model R. ideal suggestionoption optimal respect full preference model R dominated R,current (partial) preference model. optimal full model, Propositions 1 2know suggestions break dominance relations dominating set.Model-based strategies order possible suggestions likelihood breaking dominancerelations.3.3.1 C OUNTING TRATEGYfirst suggestion strategy, counting strategy, based assumption dominatingoptions independently distributed. Proposition 1 compute probabilitydominated option becomes Pareto-optimal currently hidden preference as:478fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONSpopt (o) =0pd (o, )0pnw (o, o0 )o0 O= (o)O> (o)pd probability new preference makes escape domination relationdominating option o0 , i.e. preferred o0 according new preference; similarly pnwprobability worse equally preferred option o0 .Evaluating probability requires exact probability distribution possible preferences,general difficult obtain.strategy assumes pd = pnw constant dominance relations.popt (o) =pdo0 (o)|O (o)|= pdSince pd 1, probability largest smallest set (o). Consequently, bestsuggestions lowest value following counting metric:FC (o) = |O (o)|(1)counting strategy selects option lowest value metric best suggestion.3.3.2 P ROBABILISTIC TRATEGYprobabilistic strategy uses precise estimate chance particular solutionbecome Pareto-optimal.General assumptions assume preference ri expressed cost function ci .order well-defined interface, cost functions usually restricted familyfunctions parameterized one parameters. assume single parameter ,method generalized handle cases multiple parameters:ci = ci (, ai (o)) = ci (, o)assume possible preferences characterized following probability distributions:pai , probability user preference attribute ai ,p(), probability distribution parameter associated cost functionconsidered attributeuser experiments last section, use uniform distribution both. probability preference attribute makes o1 preferred o2 computed integratingvalues cost o1 less o2 . expressed using Heavyside stepfunction H(x) (x > 0) 1 else 0:479fiV IAPPIANI , FALTINGS , & P UZ(o1 , o2 ) =H(ci (, o2 ) ci (, o1 ))p()dqualitative domain, iterate sum probability contribution casesvalue makes o1 preferred o2 :(o1 , o2 ) =XH(ci (, o2 ) ci (, o1 ))p()Didetermine probability simultaneously breaking dominance relation dominating equal options , aQfirst possibility assume independence options,thus calculate (o, ) = o0 (o, o0 ), chance breaking one singledomination preference attribute i.better estimate defined require independence assumption, directlyconsiders distribution dominating options. breaking dominance relationoptions dominating set ai , dominating options must less preferredvalue ai considered option.numeric domains, integrate possible values , check whether givenoption lower cost dominators O> weigh probability particularvalue .Z(o, O> ) = [H(ci (, o0 ) ci (, o))]p()do0 O>qualitative domains, replace integral summation .also need consider second condition Proposition 1, namely new dominancerelations options equal set created. done adding second termintegral:Z(o, ) =[H(ci (, o0 ) ci (, o))H (ci (, o00 ) ci (, o))]p()d(2)o00 O=o0 O>H modified Heavyside function assigns value 1 whenever differencetwo costs 0 greater. (H (x) (x 0) 1 else 0).consider overall probability becoming Pareto optimal preference addedcombination event new preference particular attribute, chancepreference attribute make option preferred values dominatingoptions:FP (o) = 1(1 Pai (o, ))(3)ai Auassume user one hidden preference, use following simplification:XFP (o) =Pai (o, )(4)ai Au480fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONSalso good approximation probabilities additional preferences small.cases, select options highest values suggestions.computation depends particular choice preference representation manycases greatly simplified exploiting properties cost functions. general,designer application consider preferences user express userinterface translate quantitative cost functions. similar approach takenKiessling (2002) design PREFERENCE SQL, database system processing queriespreferences.consider several examples common preference functions showsuggestions computed cases.Preference single value qualitative domain Let value preferred user;function ci (, x) gives penalty every value attribute ai except . would allowexpress statements like prefer German cars, meaning cars manufactured Germanypreferred cars manufactured another country.ci (, x) ai (x) = 0 else 1.probability breaking dominance relation option o1 o2 simplifiesprobability value option o1 attribute preferred value, differsvalue o2 .p[ = ai (o1 )] ai (o1 ) 6= ai (o2 )(o1 , o2 ) =0otherwise1(meaning value|Di |domain equally likely preferred value), probability becomes 1/|Di | ai (o1 ) 6=ai (o2 ), 0 otherwise.probability breaking dominance relations set dominators without creatingnew dominance relations single dominator, long optionsdifferent value ai :1/|Di | (o0 O> ) ai (o) 6= ai (o0 )(o, )(5)0otherwiseAssuming uniform distribution, p() =Note that, given structure preference, (o, ) = (o, O> ), optionbreak dominance relations ai (o) takes preferred value case,option strictly better respect preference.Directional preferences particular case preferences numeric domains preference order assumed known direction, price (cheaper always preferred,everything else equal). case, (o1 , o2 ) computed simply comparing values options take attribute (Figure 2).(o1 , o2 )ai (o1 ) < ai (o2 ) 1 else 0ai (o1 ) > ai (o2 ) 1 else 0481ai numeric, natural preference <ai numeric, natural preference >(6)fiV IAPPIANI , FALTINGS , & P UFigure 2: directional preference, cost function monotone function attribute value.case shown here, smaller values preferred.Figure 3: preference LessThan() represented step function, option preferredset options minimum value li reference value falls valuesgiven option li .set options whose values ai lie li hi(o, )1 ai (o) < li0 otherwise(7)smaller values always preferred,(o, )1 ai (o) > hi0 otherwise(8)larger values always preferred. Note cases, expressions independentshape cost function long monotonic.Threshold preferences numeric domains Another commonly used preference expressionnumeric domains define smallest largest acceptable threshold, i.e. express preferenceLessThan() (the value lower ) GreaterThan() (the valuegreater ). preference straightforwardly expressed cost function follows482fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONSFigure 4: preference LessThan() represented graded step function, option preferred set options minimum value li reference value falls intervalai (o) li , = 1/.step curve (Figure 3). express fact usually tolerance small violations,generally graded step function, cost gradually increases, might used (Figure 4).possible cost function LessThan might following:Min(1, (x )) x >clessthan (, x) =(9)0otherwiseassigning penalty option takes value greater reference value ; costdifference value reference, maximum 1. parameterexpresses degree violations allowed; following computationsconvenient use length ramp 0 1 = 1/.case computation (o1 , o2 ) be, ai (o1 ) < ai (o2 ):Z ai (o2 )(o1 , o2 ) =1p()d = p[(ai (o1 ) t) < < ai (o2 )];ai (o1 )t0 otherwise (since lower values preferred Equation 9).transition phase 0 1 small (the cost function approximates step functionFigure 3), (o1 , o2 ) ' p[ai (o1 )t < < ai (o2 )], approximating probability referencepoint falling two options. Assuming uniform distribution, probability evaluates(ai (o2 )ai (o1 )+t)/range(ai ), range(ai ) difference largest smallestvalues ai . reasoning illustrated Figure 4.probability computed conditioned knowledge polarity users preference (LessThan case), needs weighted probability polarity. Below,assume polarities equally likely, use weight 1/2.dominance relations broken simultaneously considered optionvalue attribute smaller bigger options dominating set.estimate probability reference value new preference falls waydominance relations broken, sufficient consider extrema valuesdominating options take considered attribute:hi = maxo0 O> ai (o0 )483fiV IAPPIANI , FALTINGS , & P UFigure 5: example peaked preferences. gi greatest value ai (o) ai option(o), si smallest value ai (o). m1 = (ai (o) + gi )/2, m2 = (ai (o) + si )/2two midpoints ai (o) gi , si . make preferred options (o),fall max(m1 , ai (o) t) min(m2 , ai (o) + t). seen graphically,case interval ]m1 , ai (o) + t[.li = mino0 O> ai (o0 )values current option lies outside interval [li , hi ], consider probability breaking relations single dominance case. proportionaldifference current option value minimum/maximum, scaled rangevalues ai :(ai (o1 ) hi + t)/2 range(ai ) ai (o1 ) > hi(li ai (o1 ) + t)/2 range(ai ) ai (o1 ) < li(o, )0otherwise(10)Peaked preferences numeric domains Another common case preferences particular numerical value , example prefer arrive around 12am. allow tolerancedeviation, cost function might slope directions:cpeak (x, ) = |ai (o) |.case, option preferred another one closer . example, lettingmidpoint ai (o1 ) ai (o2 ) supposing ai (o1 ) < ai (o2 ),(o1 , o2 ) = p[ < m]calculating probability simultaneously breaking dominance relations withoutgenerating new ones, define gi maximum dominating equal options valueai less ai (o) si minimum value dominating equal options greaterai (o). option preferred whenever ai (o) closer , intervalcase one half interval si gi , have:(o, ) =si girange(ai )484fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONSrealistic cost function would include saturation point cost alwaysevaluates 1, shown Figure 5:cpeakwithsaturation (x, ) = Min(1, |ai (o) |).(11)Let = 1/ tolerance preference either side, gi greatest value ai (o)ai option (o), si smallest value ai (o). define two midpointsm1 = (ai (o) + gi )/2 m2 = (ai (o) + si )/2, have:(o, ) = p[max(m1 , ai (o) t) < < min(m2 , ai (o) + t)]reference point uniformly distributed, evaluates to:(o, ) =min(m2 , ai (o) + t) max(m1 , ai (o) t)range(ai )(12)3.4 Examplefollowing table shows relevant values example shown earlier. Recallearlier identified o4 o3 attractive suggestions.o1o2o3o4o5o6o7O+rent(a1 )type(a2 )2distance(a3 )3furnished(a4 )4popto1o1 , o2o1 , o2o1 o4o1 o5o1 o6400500600600650700800roomroomapartmentstudioapartmentstudioapartment00.50.5000173214532270.250.050.2000.050yesyesyes00.50.50000.1250.4510.49400.0250counting strategy, options ranked according size set O+ . Thus, o2highest ranked suggestion, followed o3 o4 .probabilistic strategy, attribute values option compared range valuespresent dominators. attribute, leads values indicated table.assume user equally likely preference attribute, probabilityPai = 0.5, probabilistic strategy scores options shown last column table.Clearly, o4 best suggestion, followed o3 . o2 also o6 follow behind.Thus, least example, model-based strategies successful identifying goodsuggestions.3.5 Optimizing Set Several Suggestionsstrategies discussed far concern generating single suggestions. However, practiceoften possible show set l suggestions simultaneously. Suggestions interdependent,likely obtain better results choosing suggestions diverse way. needdiversity also observed others (Shimazu, 2001; Smyth & McClave, 2001).precisely, choose group G suggested options maximizing probabilitypopt (G) least one suggestions set G become optimal new userpreference:popt (G) = 1(1 Pai (1(1 (o0 , (o0 )))))(13)o0 Gai Au485fiV IAPPIANI , FALTINGS , & P UExplicitly optimizing measure would lead combinatorial complexity. Thus, usealgorithm adds suggestions one one order contribution measure givenalready chosen suggestions. similar algorithm used Smyth McClave (2001)Hebrard et al. (2005) generate diverse solutions.algorithm first chooses best single suggestion first element set G.evaluates option much would change combined measure popt (G)added current G, adds option largest increment. process repeatsdesired size set G reached.3.6 ComplexityLet n number options, k number attributes number preferences,number dominators, Au attributes user state preference.three model-based strategies based dominating set option. use straightforward algorithm computes intersection set options betterrespect individual preferences. sets, n elements, complexity algorithm O(n2 m). general, dominating set option size O(n)output procedure size O(n2 ), unlikely find much betteralgorithm.dominating sets known, counting strategy complexity O(nd),attribute probabilistic strategies complexity O(ndku ), ku = |Au | ku < k.general, depends data-set. worst case proportional n, resultingcomplexity O(n2 ).utility used domination criterion, dominating set composed optionshigher ranking. Therefore process computing dominating set highlysimplified performed computing candidates. However algorithm stilloverall worst case complexity O(n2 ): last option ranking n 1 dominators,= O(n).several examples selected according diversity, complexity increases sincemetrics must recomputed selecting suggestion.comparison, consider extreme strategy, proposed initially Linden et al. ATA (1997).selects options either smallest largest value attributeuser initially state preference. strategy needs scan available optionsonce. complexity O(n), n number options (the size catalog). Thus,significantly efficient, appear provide benefits model-basedstrategy, shall see experiments.Another strategy considered comparison, generating maximally diverse set options (Hebrard et al., 2005; Smyth & McClave, 2001), exponential complexity numberavailable options. However, greedy approximations (Hebrard et al., 2005) complexityO(n2 ) , similar model-based strategies.greedy algorithm use optimizing set several suggestions addcomplexity; distances computed attribute, greedy algorithmcomputing set suggestions complexity proportional product numberoptions, number attributes, square number suggestions computed.486fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONS100randomdiversityextremescountingprobabilistic assuming independenceprobabilistic assuming independencefraction users8060402001234number preferences56Figure 6: Simulation results database actual apartment offers. 100 simulated users,randomly chosen preference model 6 hidden preferences, plot number timessimulation discovered least number preferences shown abscissa. highercurve, preferences discovered average.suspect exact optimization would NP-hard number suggestions,proof this.4. Experimental Results: Simulationssuggestion strategies presented heuristic, clear performs bestassumptions underlying design. Since evaluations real users carriedspecific design, first select best suggestion strategy simulating interactioncomputer generated user randomly generated preferences. allows us comparedifferent techniques much greater detail would possible actual user study, thusselect promising techniques development. followed real user studiesdiscussed next section.simulations, users randomly generated set preferences different attributes items stored database. measure accuracy, interested whetherinteraction allows system obtain complete model users preferences. testsdesign objective suggestion strategies (to motivate user express many preferencespossible) given assumptions user behavior hold. verify assumptionsreasonable study real users reported next section.simulation starts assigning user set randomly generated preferences selectingone initial preference. stage interaction, simulated user presented5 suggestions.implemented 6 different strategies suggestions, including three model-based strategies described well following three strategies comparison:random strategy suggests randomly chosen options;487fiV IAPPIANI , FALTINGS , & P U100randomdiversityextremescountingprobabilistic assuming independenceprobabilistic assuming independencefraction users80604020012345number preferences678Figure 7: Simulation results randomly generated catalogs. 100 simulated users, randomly chosen preference model 8 hidden preferences, plot number timessimulation discovered least number preferences shown abscissa. highercurve, preferences discovered average.extremes strategy suggests options attributes take extreme values, proposedLinden (1997);diversity strategy computes 20 best solutions according current modelgenerates maximally diverse set 5 them, following proposal McSherry (2002).simulated user behaves according opportunistic model stating one hiddenpreferences whenever suggestions contain option would become optimal preference added model proper weight. interaction continues eitherpreference model complete, simulated user states preference. Notecomplete preference model discovered, user finds target option.first ran simulation catalog student accommodations 160 options describedusing 10 attributes. simulated user shown 5 suggestions, randomly generatedmodel 7 preferences, one given user initially. results shown Figure 6.value x, shows percentage runs (out 100) discover least x 6hidden preferences complete model. Using random suggestions baseline, seeextremes strategy performs slightly better, diversity provides significant improvement.model-based strategies give best results, counting strategy equallygood diversity, probabilistic strategies providing markedly better results.another test, ran simulation catalog 50 randomly generated options9 attributes, random preference model 9 preferences, one known initially.results shown Figure 7. see much pronounced differencemodel-based non model-based strategies. attribute fact attributesless correlated, thus extreme diversity filters tend produce solutions scat488fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONS#P / #A6/66/96/12random0.120.120.11extreme0.090.120.13diversity0.230.270.24counting0.570.650.62prob10.590.630.64prob20.640.670.63Table 1: fraction preferences correctly discovered function number attributes;keeping constant number preferences (6) discovered. attributes integer domains.#P / #A3/96/99/9random0.250.110.041extreme0.360.120.17diversity0.280.110.05counting0.700.670.66prob10.710.680.70prob20.710.680.73Table 2: fraction preferences correctly discovered (on average) function numberpreferences discovered. attributes integer domains.tered space possibilities. Also probabilistic strategy possible implementations(assuming attributes values independent not) give close results.investigated impact number preferences, number type attributes,size data set random data sets. following, prob1 refers probabilistic strategyindependence assumption, prob2 probabilistic strategy without assumption.Surprisingly discovered varying number attributes slightly changes results. Keeping number preferences constant 6 (one initial preference), ransimulations number attributes equal 6, 9 12. average fraction discovered preferences varied strategy simulation scenario 5%, shownTable 1.impact variation number preferences discover shown Table 2.model-based strategies perform significatively better random choice, suggestionsextrema, maximization diversity. shows importance considering alreadyknown preferences selecting suggestions.domaintypemixedintegerrandomchoice0.0480.04extremediversitycountingprob1prob20.300.170.180.050.810.660.870.700.860.72Table 3: fraction preferences correctly discovered function different kindsattribute domains: integer domains mix 5 integer, 2 discrete domains 2 domainsnatural order. ran 100 simulations 9 attributes 9 preferences.489fiV IAPPIANI , FALTINGS , & P Udatasize5075100200randomchoice0.250.160.110.05extremediversitycountingprob1prob20.500.420.290.220.560.540.570.540.890.880.900.860.940.970.960.910.930.950.970.93Table 4: fraction preferences correctly discovered function database size. ran100 simulations 9 attributes 9 preferences (mixed domains).performances higher mixed domains numeric domains (Table 3).easily explained larger outcome space second case.Interestingly, size item set grows, performance random extreme strategiessignificantly degrades model-based strategies maintain performance (Table 4).simulations, appears probabilistic suggestion strategy best all, sometimes significant margin. thus chose evaluate strategy real user study.5. Experimental Results: User Studystrategies developed far depend many assumptions user behaviortruly tested evaluating real users. However, many factorsinfluence user behavior, testing general hypotheses possible. Here, interestedverifying that:1. using model-based suggestions leads complete preference models.2. using model-based suggestions leads accurate decisions.3. complete preference models tend give accurate decisions, reasoningunderlying model-based suggestions correct.measure decision accuracy percentage users find preferred choice usingtool. preferred choice determined subjects go entiredatabase offers detail finished using tool. measure decision accuracy,also called switching rate, commonly accepted measure marketing science (e.g., Haubl& Trifts, 2000).performed user studies using FlatFinder, web application finding student housinguses actual offers university database updated daily. database idealcontains high enough number - 200 - offers present real search problem,time small enough feasible go entire list determinebest choice less 1 hour. recruited student subjects interest finding housingthus quite motivated perform task accurately.studied two settings:490fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONSunsupervised setting, monitored user behavior publicly accessible examplecritiquing search tool listing. allowed us obtain data hundreddifferent users; however, possible judge decision accuracy sinceable interview users themselves.supervised setting, 40 volunteer students use tool supervision. Here,could determine decision accuracy asking subjects carefully examine entiredatabase offers determine target option end procedure. Thus, coulddetermine switching rate measure decision accuracy.10 attributes: type accommodation (room family house, room shared apartment, studio apartment, apartment), rent, number rooms, furnished (or not), type bathroom(private shared), type kitchen (shared, private), transportation available (none, bus, subway,commuter train), distance university distance town center.numerical attributes, preference consists relational operator (less than, equal, greaterthan), threshold value importance weight 1-5; example, price less 600Francs importance 4. qualitative attributes, preference specifies certain valuepreferred certain importance value. Preferences combined summing weightswhenever preference satisfied, options ordered highest valuepreferred.Users start stating set PI initial preferences, obtain options pressingsearch button. Subsequently, go sequence interaction cycles refinepreferences critiquing displayed examples. system maintains current setpreferences, user state additional preferences, change reference value existingpreferences, even remove one preferences. Finally, process finishesfinal set preferences PF , user chooses one displayed examples.increment preferences | PF PI | number extra preferences stated representsdegree process stimulates preference expression.search tool made available two versions:C, showing set 6 candidate apartments without suggestions,C+S, showing set 3 candidate apartments 3 suggestions selected accordingprobabilistic strategy utility-dominance criterion.describe results two experiments.5.1 Online User StudyFlatFinder hosted laboratory web-server made accessible students lookingaccommodation winter 2004-2005. user, anonymously recorded loginteractions later analysis. server presented users alternate versions system,i.e. (C+S) without (C) suggestions. collected logs 63 active users wentseveral cycles preference revision.analyzing results experiments, whenever present hypothesis comparingusers group, show statistical significance using paired test. hypotheses491fiV IAPPIANI , FALTINGS , & P Unumber critiquing cyclesinitial preferencesfinal preferencesincrementtool without suggestions2.892.393.040.64tool suggestions3.002.233.691.46Table 5: Average behavior users on-line experiment. collected logs real users lookingstudent accommodation tool, hosted laboratory website.comparing users different groups, use impaired student test indicate statistical significance. cases, indicate significance p, probability obtaining observed datacondition null hypothesis true. Values p < 0.05 considered significant, p< 0.01 highly significant p < 0.001 highly significant.first considered increment initial preference enumeration | PI | final preferenceenumeration | PF |, shown Table 5. increment average 1.46 toolsuggestions C+S 0.64 tool C (128% increase), showing higher involvementusers see suggestions. hypothesis confirmed p = 0.002.interesting see groups users interacted similar number cycles(average 2.89 3.00; p = 0.42, null hypothesis cannot rejected), numberinitial preferences also close (average 2.39 2.23, null hypothesis cannot rejected p= 0.37), meaning groups relatively unbiased.result test (Table 5) shows clearly users likely state preferencessuggestions present, thus verifying Hypothesis 1. However, online experiment,able measure decision accuracy. order obtain measures, also conductedsupervised user study.5.2 Supervised User studysupervised user study used tool online user study users followedinteraction.measure improvement accuracy, instructed users identify preferred item searching database using interface 1. choice recorded calledc1 . users instructed interact database using interface 2 indicatenew choice (c2 ) latter improvement c1 opinion. evaluate whethersecond choice better initial one, instructed users review apartments (100apartments case) tell us whether c1 , c2 , completely different one truly seemed best.Thus, experiment allowed us measure decision accuracy, since obtained true targetchoice user. users stood first choice, indicated found targetchoice without help second interface. users stood second choice,indicated found target choice help second interface. users choseyet another item, indicated found target choice even though performedsearch interfaces.40 subjects, mostly undergraduate students, 9 different nationalities took part study.(27 40) searched apartment area used online492fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONSCharacteristicsGenderMaleFemaleAge10s20s30sEducationUndergraduatePhdFamiliar online apartment searchYesFamiliar apartments areaYesParticipants319236236426142713Table 6: Demographic characteristics participants supervised user study.group 1(C first)Tool versionDecision Accuracy (mean)Preference Enumeration (mean)Interaction cycles (mean)Interaction time (min.,mean)Interactionfirst interfaceC0.455.305.608:09group 2(C+S first)Tool versionDecision Accuracy (mean)Preference Enumeration (mean)Interaction cycles (mean)Interaction time (mean)C+S0.725.444.057.39Interactionsecond interfaceC+S0.806.154.554.33C0.674.506.253.33Table 7: Results supervised experiment. Decision accuracy preference enumeration (the numberpreferences stated) higher suggestions provided (interface C+S, showing 3 candidates 3 suggestions) rather suggestions provided (interface C, 6 candidates).493fiV IAPPIANI , FALTINGS , & P Usites (26 40) look accommodations. Table 6 shows demographic characteristics. subjects motivated interest finding better apartment themselves,meant treated study seriously.overcome bias due learning fatigue, divided users two groups,asked interact versions two different orders:group 1 used tool C (step 1) C+S (step 2)group 2 used tool C+S (step 1) C (step 2)groups examined entire list find true preferred option. versiontool group, recorded fraction subjects final choice made usinginterface equal target option decision accuracy. groups, referaccuracy interface 1 acc1 , accuracy interface 2 acc2 .expected order presenting versions would important. usersrealized preferences found satisfactory option, likely consistentthat. Therefore, expected acc2 > acc1 cases. However, expected averageaccuracy would significantly increase suggestions, results would show acc2 >>acc1 first group acc2 slightly higher acc1 group 2.Table 7 shows results. next section want verify Hypothesis 2 (decision accuracyimproves suggestions) 3 (preference enumeration improves accuracy). Finallycheck whether mediation phenomenon present (meaning improvement accuracyentirely explained fact suggestions lead increase preferences).Decision Accuracy improves suggestions Figure 8 shows variation decision accuracynumber interaction cycles two groups.group 1, interaction tool C, average accuracy 45%, interactionC+S, version suggestions, goes 80%. confirms hypothesissuggestions improve accuracy p = 0.00076. 10 20 subjects group switchedanother choice two versions, 8 reported new choice better.Clearly, use suggestions significantly improved decision accuracy group.Users group 2 used C+S straight away achieved average accuracy 72% outset.expected consequent use tool C would small positive effect accuracy,reality accuracy decreased 67%. 10 subjects changed final choice using toolwithout suggestions, 6 said newly chosen equally good oneoriginally chose. fact accuracy drop significantly case surprisingusers remember preferences using tool suggestions thus stateaccurately independently tool. conclude group improvedaccuracy simply result performing search second time, due provisionsuggestions tool. Also, closeness accuracy levels reached groupsusing suggestions interpreted confirmation significance.also note users interface C+S needed fewer cycles (and thus less effort) makedecisions (average 4.15) interface C (5.92).Interestingly, price chosen apartment increased first group (average 586.75C 612.50 C+S; p = 0.04, statistically significant), whereas decreased second group(average 527.20 C+S 477.25 C; p = 0.18, decrease statically significant).494fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONSUser study - Group 210.80.80.60.6AccuracyAccuracyUser study - Group 110.40.20.40.2001) tool without suggestions2) tool suggestions1) tool suggestions2) tool without suggestions(a) group 1, accuracy dramatically increased (b) group 2, accuracy already highused version suggestions (C+S).use version suggestions (C+S).interaction cycles tool C showing 6 candidatesincrease accuracy further.User study - Group 276655Interaction cyclesInteraction cyclesUser study - Group 1743432211001) tool without suggestions2) tool suggestions1) tool suggestions2) tool without suggestions(c) group 1, users needed less interaction cycles (d) group 2, number interaction cycles sig-make choice using interface sugges- nificantly increased used version withtions (C+S).suggestions (C).Figure 8: Decision accuracy interaction cycles groups users supervised experiment.495fiV IAPPIANI , FALTINGS , & P Ufoundstill found0.450.55|P | <= 00.830.17|P | > 0Table 8: users find target first use tool, table shows fractionfind target next try, depending whether size preference modelincrease. (|P | variation number stated preferences |P |two uses tool).believe subjects first group find good choice, thus paid relatively highprice get apartment would feel comfortable. Conditioned high price,willing spend even discovered interesting featuressuggestions. hand, subjects group 2 already found good choice first usetool, unwilling accept high price find better choicesecond search without suggestions.Thus, conclude Hypothesis 2 confirmed: suggestions indeed increase decision accuracy.Preference enumeration improves accuracy study, notice suggestionspresent, users state higher number preferences (average 5.8 preferences vs. 4.8 withoutsuggestions, p = 0.021), Hypothesis 1 confirmed.validate hypothesis 3, higher preference enumeration also leads accurate decisions, compare average size preference model users foundtarget solution first use tool not. groups, users findtarget first try stated average 5.56 preferences (5.56 group 1 5.57 group 2)users find target stated average 4.88 preferences (5.09 group 14.67 group 2). shows increased preference enumeration indeed improves accuracyunfortunately find statistically significant (p = 0.17). fact, chancecorrelation due users informed thus making accurate decisionsstating preferences.evaluation independent users priori knowledge, considered usersfind target first try only. measure correlation preference enumerationaccuracy, considered often increase preference enumeration second tryled finding preferred option second try. Table 8 shows among users whosepreference model grow size, 45% found target, whereas increasedpreference model, 83% found target. Again, see significant confirmation higherpreference enumeration leads accurate decision real users (p = 0.038251).Finally, third confirmation obtained considering influence variationssize preference model decision accuracy, shown Table 9. column correspondsusers size preference model decreased, stayed same, increased. alsoshows fraction accuracy increased, stayed decreased (noteaccuracy 1 first step, cannot increase). see significant increaseaccuracy occurs size preference model increases. cases496fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONSacc > 0acc = 0acc < 00.230.620.15|P | < 00.140.710.14|P | = 00.380.620.00|P | > 0Table 9: Variation accuracy variation number stated preferences |P | twouses tool.random variations major increases. statistical test shows hypothesisincrease preference enumeration causes increase accuracy confirmed p = 0.0322.Thus, conclude hypothesis 3 also validated user study; complete preference model indeed leads accurate decisions.Mediation analysis Since three hypotheses verified, presence suggestions leadincrease preferences stated consequently increase accuracy. 3-stepmediation analysis want check whether mediation phenomenon, meaningincrease accuracy entirely explained increase preferences.However, Sobel test show statistical significance (p=0.14), cannot concludeincrease preference enumeration mediator. interpretation suggestionsinfluence decision accuracy also making users state better preferences.5.3 Observationsobjective measure confidence price people willing pay chosenoption measure satisfaction, since would pay choice satisfiesbased attributes. 40 subjects, average rent chosen housingsuggestion CHF 569.85, increase 7% average without suggestions,CHF532.00. fact, observe general correlation price accuracy, 910 subjects find target first interaction finally chose apartmenthigher rent.subjects notably liked interaction (average 4.1 5) significant differenceversions. asked subjects version considered productive.majority them, 22 40, preferred version suggestions, 13 preferred versioncandidates 5 opinion.Another indication suggestions helpful average time complete decision task:took subjects average 8:09 minutes find target without suggestions, versionsuggestions took 7:39 minutes average. Thus, using suggestions users take less timeobtain accurate decision.6. Related WorkExample-based search tools Burke others (1997) among first recognizechallenge developing intelligent tools preference-based search. approach, called as497fiV IAPPIANI , FALTINGS , & P Usisted browsing combines searching browsing knowledge based assistance recognizesusers integral part search process.developed FindMe approach, consisting family prototypes implementintuition variety domains (restaurants, apartments, cars, video, etc.). main featurespossibility similarity based retrieval (look restaurant similar this, SanFrancisco), support tweaking (look bigger, nicer, closer centre, ..), abstraction highlevel features (users might look restaurant casual look, look defineddatabase directly, decoupled basic features), multiple similarity metrics.display follows hierarchical sort preferences (described goals: minimize price, findseafood cuisine) fixed priority. restaurant advisor tested on-line several years.Another early similar work ATA system Linden et al. (1997). ATA toolplanning travel itineraries based users constraints. followed so-called candidate-critiquingcycle users could post constraints travel would shown 3 best matchingflights database. ATA tested on-line several months.recent work, Shearin Lieberman (2001), described AptDecision, examplecritiquing interface user able guide search giving feedback feature (inform either positive negative weights) time. critiques storedprofile displayed bottom part interface modified stored lateruse. Instead providing feedback manually, user might prefer let AptDecision learnprofile weights comparing two sample examples. However, investigate strategiessuggestions.Improving example selection Techniques induce users state preferences accurately proposed various recommender systems. Suggestion mechanisms include extreme values, diversity, compound critiques.ATA system Linden et al. (1997) included suggestion strategy showing extremeexamples applied airplane travel domain, example first last flight day.simulations, compared model-based techniques strategy.Several researchers (Bridge & Ferguson, 2002; Smyth & McClave, 2001; McSherry, 2002;McGinty & Smyth, 2003; Smyth & McGinty, 2003; McSherry, 2003) studied issueachieving good compromise generating similar diverse results case-based retrieval.consider problem finding cases similar given query case,time maximize diversity options proposed user. Smyth et. al (2003) improvescommon query show like this: adaptive search algorithm alternatesstrategy privileges similarity one privileges diversity (refocus). McSherry (2002) tookidea provided selection algorithms maximize diversity similaritytime. McSherry (2003) proposes technique retrieved cases associated setlike cases share identical differences query case. like cases displayedamong examples, accessible users demand. Thus, retrieval set diverse.Reilly et al. (2004) also uses mixture similarity diversity, goal providingpossible standardized critiques allow trade-offs analysis e-commerce environment. critique is, scope, modification users current preferences narrowing searchindication trade-off. Users select either unit critiques revise preferencesindividual attributes, compound critiques revise preferences multiple attributes.compound critiques organized categories displayed natural language form, ex498fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONSample memory larger heavier. One innovations work automaticgeneration sensible critiques involving several features based available items using Apriorialgorithm. simulated real user studies shown compound critiques significantlyreduce number interaction cycles.approaches, however, differ sense explicitpreference model. recent work Hebrard et al. (2005) investigated computationalproblem generating diverse solutions constraint satisfaction problems.Dialogue-based approaches Many related works try simulate human conversationorder guide customer decision making process. Shimazu (2001) describes ExpertClerk, agent system imitates human salesclerk. first phase, agent triesnarrow possibilities asking questions. optimal discrimination tree built usinginformation gain (as ID3 algorithm) node represents specific question user,users answer leads specific portion subtree. fact, node equivalentcrisp constraint, problem getting node compatible examples may occur.second phase, agent proposes three possible items, chosen one central twoopposite extreme region available product space. shown intelligent usestrategies (asking proposing) efficient one two strategies alone.Thompson, Goker, Langley (2004) also propose conversational, dialogue-based approachADAPTIVE PLACE ADVISOR, conversational recommendation system restaurantsPalo Alto area. approach mimics conversation proceeds questions like typefood would like?; user might either answer particular answer like Chinese, saycare aspect, ask advisor possible choices. Userpreferences obtained current conversation treated crisp constraints itemssatisfy considered. items satisfy preferences, systemmay ask user whether willing relax constraints.tool also develops long-term user model keeps track preferences expressedprevious interactions. used sort results shown user.Using prior knowledge also possible optimize set examples given expectationusers preferences, without actually asking users state preferences.approach described Price Messinger (2005). work differsconsider preferences individual user, average preferences group users.Preference elicitation optimized using prior distributions possible preferences.approach proposed Chajewska et al. (2000) produce efficient preference elicitationprocedure. elicitation question-answering interaction questions selectedmaximize expected value information. Boutilier (2002) extended work takingaccount values future questions optimize decision quality minimizing user effort.views elicitation procedure decision process uses observable Markov process(POMDP) obtain elicitation strategy.approaches require users familiar enough available options answerquestion value functions without benefit example outcomes assess them. contrast,mixed-initiative system described user free furnish informationconfident about. also questionable whether one assume prior distribution preferencespersonalized recommendation systems users may diverse.499fiV IAPPIANI , FALTINGS , & P U7. Conclusionconsidered AI techniques used product search recommender systems based setpreferences explicitly stated users. One challenges recognized field elicitationaccurate preference model user. particular, face dilemma accuracycost user effort.systems may introduce severe errors model users cannot expendamount effort required state preferences, others may require little effort providegeneral recommendations preference model never completely established.ideal solution one provides users accurate recommendations minimizingeffort stating preferences. Therefore, article also examined user interaction issuesemphasized models motivate users state complete accurate preferences,requiring least amount effort user.conjectured benefit discovering attractive recommendations presents strong motivation users state additional preferences. Thus, developed model-based approachanalyzes users current preference model potential hidden preferences order generateset suggestions would attractive rational user. suggestion set calculated basedlook-ahead principle: good suggestion outcome becomes optimal additionalhidden preferences considered. simulations, demonstrated superior performance model-based strategies comparison proposed strategies.validated hypothesis strategies highly likely stimulate usersexpress preferences significant within-subject user study involving 40 real users.measured decision accuracy, defined percentage users actually foundpreferred option tool, example-critiquing tool without suggestions.study showed users able achieve significantly higher level decision accuracyexample-critiquing tool suggestions without suggestions, increasing 4580%, effort spent tools comparable. shows significant potentialimproving tools currently use.important note performance obtained users boundparticular dialogue, free interact system initiative.process particularly supports preference expression users unfamiliardomain, typically decisions require low medium financial commitments. highlyimportant decisions users understand preferences well, preference elicitation techniques (Keeney & Raiffa, 1976; Boutilier et al., 2005) likely provide superior results.strategies based general notion Pareto-optimality, appliedbroad range preference modeling formalisms, including utility functions, soft constraints(Bistarelli et al., 1997), CP-networks (Boutilier, Brafman, Domshlak, Hoos, & Poole, 2004).greatly strengthen performance example-critiquing systems applications rangingdecision support e-commerce.8. Acknowledgementsauthors would like thank Vincent Schickel-Zuber significant contribution development web based interface FlatFinder, Jennifer Graetzel insightful sug500fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONSgestions various draft versions manuscript improve readability. worksupported Swiss National Science Foundation contract No. 200020-103421.ReferencesAdomavicius, G., & Tuzhilin, A. (2005). Toward next generation recommender systems:survey state-of-the-art possible extensions. IEEE Transactions KnowledgeData Engineering, 17(6), 734749.Bistarelli, S., Montanari, U., & Rossi, F. (1997). Semiring-based constraint satisfaction optimization. Journal ACM, 44(2), 201236.Boutilier, C. (2002). pomdp formulation preference elicitation problems. ProceedingsEighteenth National Conference Artificial Intelligence (AAAI02), pp. 239246.Boutilier, C., Brafman, R. I., Domshlak, C., Hoos, H. H., & Poole, D. (2004). CP-nets: toolrepresenting reasoning conditional ceteris paribus preference statements. JournalArtificial Intelligence Research, 21, 135191.Boutilier, C., Patrascu, R., Poupart, P., & Schuurmans, D. (2005). Regret-based utility elicitationconstraint-based decision problems.. Proceedings Nineteenth International JointConference Artificial Intelligence (IJCAI05), pp. 929934.Bridge, D. G., & Ferguson, A. (2002). Diverse product recommendations using expressive language case retrieval. Proceedings 6th European Conference AdvancesCase-Based Reasoning (ECCBR02), pp. 4357.Burke, R. (2002a). Interactive critiquing catalog navigation e-commerce. Artificial Intelligence Review, 18(3-4), 245267.Burke, R. D. (2002b). Hybrid recommender systems: Survey experiments. User Model. UserAdapt. Interact., 12(4), 331370.Burke, R. D., Hammond, K. J., & Young, B. C. (1997). FindMe approach assisted browsing.IEEE Expert, 12(4), 3240.Chajewska, U., Koller, D., & Parr, R. (2000). Making rational decisions using adaptive utilityelicitation. Proceedings Seventeenth National Conference Artificial IntelligenceTwelfth Conference Innovative Applications Artificial Intelligence (AAAI00), pp.363369. AAAI Press / MIT Press.Chomicki, J. (2003). Preference formulas relational queries. ACM Trans. Database Syst., 28(4),427466.Faltings, B., Torrens, M., & Pu, P. (2004). Solution generation qualitative models preferences. Computational Intelligence, pp. 246263(18). ACM.Haubl, G., & Trifts, V. (2000). Consumer decision making online shopping environments:effects interactive decision aids. Marketing Science, 19(1), 421.Hebrard, E., Hnich, B., OSullivan, B., & Walsh, T. (2005). Finding diverse similar solutionsconstraint programming. Proceedings Twentieth National Conference ArtificialIntelligence (AAAI05), pp. 372377.501fiV IAPPIANI , FALTINGS , & P UKeeney, R. L. (1992). Value-Focused Thinking. Path Creative Decision Making. Cambridge:Harvard University Press.Keeney, R. L., & Raiffa, H. (1976). Decisions Multiple Objectives: Preferences ValueTradeoffs. John Wiley Sons, New York.Kiesling, W. (2002). Foundations preferences database systems. Proceedings 28thInternational Conference Large Data Bases (VLDB02), pp. 311322.Konstan, J. A., Miller, B. N., Maltz, D., Herlocker, J. L., Gordon, L. R., & Riedl, J. (1997). Grouplens: Applying collaborative filtering usenet news. Commun. ACM, 40(3), 7787.Krulwich, B. (1997). Lifestyle finder: Intelligent user profiling using large-scale demographic data.AI Magazine, 18(2), 3745.Linden, G., Hanks, S., & Lesh, N. (1997). Interactive assessment user preference models:automated travel assistant. Proceedings Fifth Internation Conference User Modeling (UM97).McCarthy, K., McGinty, L., Smyth, B., & Reilly, J. (2005). live-user evaluation incremental dynamic critiquing. Proceedings 6th International Conference Case-BasedReasoning (ICCBR05), Vol. 3620, pp. 339352. Springer LNAI.McGinty, L., & Smyth, B. (2003). role diversity conversational recommender system.Proceedings Fifth International Conference Case-Based Reasoning (ICCBR03),pp. 276290. LNAI 2689.McSherry, D. (2002). Diversity-conscious retrieval. Proceedings 6th European ConferenceAdvances Case-Based Reasoning (ECCBR02), pp. 219233.McSherry, D. (2003). Similarity compromise. Proceedings 5th International Conference Case-Based Reasoning (ICCBR03), pp. 291305.Payne, J., Bettman, J., & Johnson, E. (1993). Adaptive Decision Maker. Cambridge UniversityPress.Price, R., & Messinger, P. R. (2005). Optimal recommendation sets: Covering uncertainty userpreferences. Proceedings Twentieth National Conference Artificial Intelligence(AAAI05), pp. 541548.Pu, P., & Chen, L. (2005). Integrating tradeoff support product search tools e-commerce sites.Proceedings ACM Conference Electronic Commerce (EC05), pp. 269278.Pu, P., & Faltings, B. (2000). Enriching buyers experiences: smartclient approach. Proceedings SIGCHI conference Human factors computing systems (CHI00), pp.289296. ACM Press New York, NY, USA.Pu, P., & Faltings, B. (2004). Decision tradeoff using example-critiquing constraint programming. Constraints: International Journal, 9(4).Pu, P., & Kumar, P. (2004). Evaluating example-based search tools. Proceedings ACMConference Electronic Commerce (EC04).Reilly, J., McCarthy, K., McGinty, L., & Smyth, B. (2004). Dynamic critiquing. Proceedings7th European Conference Advances Case-Based Reasoning (ECCBR04), pp.763777.502fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONSResnick, P., Iacovou, N., Suchak, M., Bergstorm, P., & Riedl, J. (1994). Grouplens: open architecture collaborative filtering netnews. Proceedings ACM 1994 ConferenceComputer Supported Cooperative Work, pp. 175186, Chapel Hill, North Carolina. ACM.Rich, E. (1979). User modeling via stereotypes. Cognitive Science, 3, 329354.Ruttkay, Z. (1994). Fuzzy constraint satisfaction. Proceedings 3rd IEEE ConferenceFuzzy Systems, pp. 12631268, Orlando.Shearin, S., & Lieberman, H. (2001). Intelligent profiling example. Proceedings IntelligentUser Interfaces (IUI 2001), pp. 145151.Shimazu, H. (2001). Expertclerk: Navigating shoppers buying process combinationasking proposing. Proceedings Seventeenth International Joint ConferenceArtificial Intelligence (IJCAI01), Vol. 2, pp. 14431448.Smyth, B., & McClave, P. (2001). Similarity vs. diversity. Proceedings 4th InternationalConference Case-Based Reasoning (ICCBR01), pp. 347361.Smyth, B., & McGinty, L. (2003). power suggestion. Proceedings EighteenthInternational Joint Conference Artificial Intelligence (IJCAI 2003), Acapulco, Mexico, pp.127132.Spiekermann, S., & Paraschiv, C. (2002). Motivating humanagent interaction: Transferring insightsbehavioral marketing interface design. Electronic Commerce Research, 2(3), 255285.Thompson, C. A., Goker, M. H., & Langley, P. (2004). personalized system conversationalrecommendations. Journal Artificial Intelligence Research, 21, 393428.Torrens, M., Faltings, B., & Pu, P. (2002). Smart clients: Constraint satisfaction paradigmscaleable intelligent information systems. Special issue Constraints Agents. CONSTRAINTS: Internation Journal. Kluwer Academic Publishers, pp. 4969.Torrens, M., Weigel, R., & Faltings, B. (1998). Distributing problem solving web usingconstraint technology. Proceedings International Conference Tools ArtificialIntelligence (ICTAI98), pp. 4249, Taipei, Taiwan. IEEE Computer Society Press.Tversky, A. (1974). Judgement uncertainity: Heuristics biases. Science, 185, 11241131.Zhang, J., & Pu, P. (2006). Performance evaluation consumer decision support systems. International Journal E-Business Research, 2, 2845.503fiJournal Artificial Intelligence Research 27 (2006) 577615Submitted 2/2006; published 12/2006Understanding Algorithm PerformanceOversubscribed Scheduling ApplicationLaura Barbulesculaurabar@cs.cmu.eduRobotics InstituteCarnegie Mellon UniversityPittsburgh, PA 15213 USAAdele E. HoweL. Darrell WhitleyMark Robertshowe@cs.colostate.eduwhitley@cs.colostate.edumroberts@cs.colostate.eduComputer Science DepartmentColorado State UniversityFort Collins, CO 80523 USAAbstractbest performing algorithms particular oversubscribed scheduling application,Air Force Satellite Control Network (AFSCN) scheduling, appear little common. Yet, careful experimentation modeling performance real probleminstances, relate characteristics best algorithms characteristicsapplication. particular, find plateaus dominate search spaces (thus favoring algorithms make larger changes solutions) randomizationexploration critical good performance (due lack gradient informationplateaus). Based explanations algorithm performance, develop newalgorithm combines characteristics best performers; new algorithms performance better previous best. show hypothesis driven experimentationsearch modeling explain algorithm performance motivate designnew algorithm.1. IntroductionEffective solution Air Force Satellite Control Network (AFSCN) oversubscribedscheduling problem runs counter works well similar scheduling problems.similar oversubscribed problems, e.g., United States Air Force (USAF) Air Mobility Command (AMC) airlift (Kramer & Smith, 2003) scheduling telescope observations (Bresina,1996), well solved heuristically guided constructive repair based search. bestperforming solutions AFSCN genetic algorithm (Genitor), Squeaky Wheel Optimization (SWO) randomized next-descent local search. yet foundconstructive repair based solution competitive.three best performing solutions AFSCN appear little common, makingdifficult explain superior performance. Genitor combines two candidate solutionspreserving elements each. SWO creates initial greedy solution attemptsimprove scheduling tasks known contribute detrimentally current evaluation. Randomized local search makes incremental changes based observed immediategradients schedule evaluation. paper, examine performance differc2006AI Access Foundation. rights reserved.fiBarbulescu, Howe, Whitley, & Robertsent algorithms, identify factors help explain performance leverageexplanations design new search algorithm well suited characteristicsapplication.target application oversubscribed scheduling application alternative resources. AFSCN (Air Force Satellite Control Network) access scheduling requires assigningaccess requests (communication relays U.S.A. government satellites) specific time slotsantenna ground station. oversubscribed tasks accommodated given available resources. considered oversubscribed, leastproblem instances need overtax available resources; application though,appears problem instances specify tasks feasibly scheduled.application challenging shares characteristics applicationsEarth Observing Satellites (EOS). important team human schedulerslaboriously performed task every day least 15 years minimal automatedassistance.algorithms designed traverse essentially search space: solutionsrepresented permutations tasks, greedy schedule builder convertsschedule assigning start time resources tasks orderappear permutation. find search space dominated large flatregions (plateaus). Additionally, size plateaus increases dramatically bestsolution approached. presence plateaus indicates algorithm needseffectively manage order find improving solutions.explored number different hypotheses explain performancealgorithm. hypotheses include following:Genitor, genetic algorithm, identifies patterns relative task orderings, similar backbones SAT (Singer, Gent, & Smaill, 2000), preserved memberspopulation. effect type classic building block hypothesis (Goldberg,1989).SWO starts extremely close best solution need enact much change.hypothesis also implies relatively easy modify good greedy solutionsfind best known solutions.Randomized Local Search performs essentially random walk plateaus findexits leading better solutions; given distribution solutions lack gradientinformation, may good strategy any.tested hypotheses. limited evidence existence buildingblocks backbone structure. Squeaky Wheel Optimization quickly findgood solutions, cannot reliably find best known solutions. Therefore, firsttwo hypotheses somewhat supported data, hypotheses enoughexplain observed performance.third hypothesis appears best explanation particular localsearch strategy used works well. light this, formulated another hypothesis:SWO Genitor make long leaps search space, allow relativelyquickly traverse plateaus.578fiUnderstanding Algorithm Performancelast hypothesis appears well explain performance two methods.genetic algorithm leaps naturally longer early phases searchparent solutions less similar.Based studies, constructed new search algorithm exploitslearned search space behavior successful algorithms. AttenuatedLeap Local Search makes multiple changes solution evaluating candidatesolution. addition, number changes decreases proportionately expected proximity solution. number multiple changes, length leap, largerearly search, reduces (shortens) better solutions found. findalgorithm performs quite well: quickly finds best known solutions AFSCNproblems.2. AFSCN SchedulingU.S.A. Air Force Satellite Control Network currently responsible coordinatingcommunications civilian military organizations 100 USAF managed satellites. Space-ground communications performed using 16 antennas locatednine tracking stations around globe 1 . Figure 1 shows map current configurationAFSCN; map shows one fewer tracking station antennae data,due resources apparently taken off-line recently. Customer organizations submit task requests reserve antenna tracking station specified timeperiod based visibility windows target satellites tracking stations. Twotypes task requests distinguished: low altitude high altitude orbits. lowaltitude tasks specify requests access low altitude satellites; requests tendshort (e.g., 15 minutes) tight visibility window. High altitude tasks specifyrequests high altitude satellites; durations requests variedusually longer, large visibility windows.Approximately 500 requests typically received single day. Separate schedulesproduced staff human schedulers Schriever Air Force Base day.500 requests, often 120 conflicts remain first pass scheduling. Conflictsdefined requests cannot scheduled, since conflict scheduledrequests (this means 120 requests remain unscheduled initial scheduleproduced).real problem data, extract description problem specification termstask requests scheduled corresponding type (low high altitude), duration,time windows alternative resources. AFSCN data also include informationsatellite revolution numbers, optional site equipment, tracking station maintenance times(downtimes), possible loss data due antenna problems, various comments, etc.;incorporate information problem specification. informationtype task (low high altitude) well identifier satellite involvedincluded task specification. However, know satellite identifier1. U.S.A. government planning make AFSCN core Integrated Satellite ControlNetwork managing satellite assets U.S.A. government agencies well, e.g., NASA, NOAA,DoD affiliates. 2011, system first becomes operational, Remote Tracking Stationsincreased enhanced accommodate additional load.579fiBarbulescu, Howe, Whitley, & RobertsFigure 1: Map current AFSCN network including tracking stations, control relay.figure produced U.S.A. Space Missile Systems Center (SMC).corresponds actual satellite rely precomputed visibility informationpresent requests.problem instance consists n task requests. task request , 1 n, specifiesrequired processing duration TiDur . task request also specifies number j 0pairs form (Rj , TijWin ), identifying particular alternative resource (antennaRj ) time window TijWin task. duration taskpossible alternative resources. start end visibility time window specificalternative resource; therefore duration same, time windowsdifferent alternative resources. resource assigned request,duration needs allocated within corresponding time window. denotelower upper bounds time window j corresponding request ijWin (LB)TijWin (UB), respectively. task, one alternative antennas needschosen; also, tasks cannot preempted processing initiated.requests made specific antenna, often different antennatracking station may serve alternate capabilities. assumeantennas tracking station serve alternate resources.always case practice, assumption made previous research Air580fiUnderstanding Algorithm PerformanceForce Institute Technology (AFIT) 2 . low altitude request specifies possible resourcesantennas present single tracking station (for visibility reasons, one trackingstation accommodate request). Usually two three antennas presenttracking station, therefore, two three possible resources associatedrequests. High altitude requests specify antennas presenttracking stations satisfy visibility constraints; many 14 possible alternativesspecified data.Previous research development AFSCN scheduling focused minimizingnumber request conflicts AFSCN scheduling, alternatively, maximizing numberrequests scheduled without conflict. requests cannot scheduledwithout conflict bumped schedule. happens humanscarry AFSCN scheduling3 . Satellites valuable resources, AFSCN operatorswork fit every request. means practice negotiationcustomers, requests given less time requested, shifted less desirable,still usable time slots. effect, requests altered requests leastpartially satisfied deferred another day. using evaluation function minimizesnumber request conflicts, assumption made fit manyrequests possible requiring human schedulers figure placerequests bumped.However, given requests need eventually scheduled, designed newevaluation criterion schedules requests allowing overlap minimizing sum overlaps conflicting tasks. appears yield schedulesmuch closer human schedulers construct. conflicting tasks bumpedschedule, large difficult schedule tasks likely bumped;placing requests back negotiated schedule means deconstructing minimalconflict schedule rebuilding new schedule. Thus, schedule minimizes conflictsmay help much constructing negotiated schedule, whereas scheduleminimizes overlaps suggest ways fitting tasks schedule, examplereducing tasks duration two three minutes, shifting start outsiderequested window short amount time.obtained 12 days data AFSCN application 4 . first seven daysweek 1992 given us Colonel James Moore Air Force InstituteTechnology. data used first research projects AFSCN. obtainedadditional five days data schedulers Schriever Air Force Base. Table 2 summarizescharacteristics data. best known solutions obtained performing longruns hundreds experiments. Using various algorithms allowing hundreds2. fact, large antennas needed high altitude requests, smaller antennas handle lowaltitude requests. Depending type antennas present tracking station, antennasalways serve alternate resources request.3. met several schedulers Schriever discuss procedure crosscheck solution. appreciate assistance Brian Bayless William Szary settingmeeting giving us data.4. approval make public some, data.See http://www.cs.colostate.edu/sched/data.html details obtaining problems.581fiBarbulescu, Howe, Whitley, & RobertsIDA1A2A3A4A5A6A7R1R2R3R4R5Date10/12/9210/13/9210/14/9210/15/9210/16/9210/17/9210/18/9203/07/0203/20/0203/26/0304/02/0305/02/03# Requests322302311318305299297483457426431419# High169165165176163155155258263243246241# Low153137146142142144142225194183185178Best Conflicts84324664229172812Best Overlaps10413289304546773486250725146Table 1: Problem characteristics 12 days AFSCN data used experiments.ID used tables. Best conflicts best overlaps best knownvalues problem two objective functions.thousands evaluations, found better solutions 5 . referproblems 1992 problems, recent problems, Rproblems.3. Related Scheduling ResearchAFSCN application multiple resource, oversubscribed problem. Examplesapplications USAF Air Mobility Command (AMC) airlift scheduling (Kramer &Smith, 2003), NASAs shuttle ground processing (Deale et al., 1994), scheduling telescopeobservations (Bresina, 1996) satellite observation scheduling (Frank, Jonsson, Morris,& Smith, 2001; Globus, Crawford, Lohn, & Pryor, 2003).AMC scheduling assigns delivery missions air wings (Kramer & Smith, 2003).system adopts iterative repair approach greedily creating initial schedule orderingtasks priority attempting insert unscheduled tasks retractingre-arranging conflicting tasks.Gerry scheduler designed manage large set tasks needed preparespace shuttle next mission (Zweben, Daun, & Deale, 1994). Tasks describedterms resource requirements, temporal constraints required time windows.original version used constructive search dependency-directed backtracking,adequate task; subsequent version employed constraint-directed iterative repair.satellite scheduling, customer requests data collection need matchedsatellite tracking station resources. requests specify instruments required,window time request needs executed, location sensing/communication event. task constraints need coordinated resource5. best known values obtained running Genitor population size increased 400allowing 50,000 evaluations per run.582fiUnderstanding Algorithm Performanceconstraints; include windows visibility satellites, maintenance periodsdowntimes tracking stations, etc. Typically, requests need scheduledaccommodated available resources. general description satellitescheduling domain provided Jeremy Frank et al. (2001).Pemberton (2000) solves simple one-resource satellite scheduling problemrequests priorities, fixed start times fixed durations. objective functionmaximizes sum priorities scheduled requests. priority segmentation algorithm proposed, hybrid algorithm combining greedy approach branchand-bound. Wolfe Sorensen (2000) define complex one-resource problem,window-constrained packing problem (WCP), specifies request earlieststart time, latest final time minimum maximum duration. objective function complex, combining request priority position scheduled requestrequired window number requests scheduled. Two greedy heuristic approachesgenetic algorithm implemented; genetic algorithm found perform best.Globus et al. (2003) compare genetic algorithm, simulated annealing, Squeaky WheelOptimization (Joslin & Clements, 1999) hill climbing simplified, synthetic formsatellite scheduling problem (two satellites single instrument) findsimulated annealing excels genetic algorithm performs relatively poorly.general version satellite scheduling (EOS observation scheduling), Frank et al. (2001)propose constraint-based planner stochastic greedy search algorithm basedBresinas Heuristic-Biased Stochastic Sampling (HBSS) algorithm (Bresina, 1996). HBSSoriginally applied scheduling astronomy observations telescopes.Lematre et al. (2000) research problem scheduling set photographs AgileEOS (ROADEF Challenge, 2003). Task constraints include minimal time twosuccessive acquisitions, pairings requests images acquired twice differenttime windows, hard requirements certain images must always acquired.find local search approach performs better hybrid algorithm combining branchand-bound various domain-specific heuristics.AFSCN application previously studied researchers Air Force Institute Technology (AFIT). Gooley (1993) Schalck (1993) described algorithms basedmixed-integer programming (MIP) insertion heuristics, achieved good overall performance: 91% 95% requests scheduled. Parish (1994) used Genitor(Whitley, 1989) genetic algorithm, scheduled roughly 96% task requests, outperforming MIP approaches. three researchers used AFIT benchmarksuite consisting seven problem instances, representing actual AFSCN task request datavisibilities seven consecutive days October 12 18, 1992. Later, Jang (1996)introduced problem generator employing bootstrap mechanism produce additionaltest problems qualitatively similar AFIT benchmark problems. Jangused generator analyze maximum capacity AFSCN, measuredaggregate number task requests satisfied single-day.general decision problem AFSCN Scheduling minimal conflicts N Pcomplete, special subclasses AFSCN Scheduling polynomial. Burrowbridge (1999)considers simplified version AFSCN scheduling, task specifies one resource (antenna) low-altitude satellites present. objective maximizenumber scheduled tasks. Due orbital dynamics low-altitude satellites,583fiBarbulescu, Howe, Whitley, & Robertstask requests problem negligible slack ; i.e., window size equalrequest duration. Assuming one task scheduled per time window, wellknown greedy activity-selector algorithm (Cormen, Leiserson, & Rivest, 1990) usedschedule requests since yields solution maximal number scheduled tasks.schedule low altitude requests one multiple antennas present particularground station, extended greedy activity-selector algorithm multiple resourceproblems. proved extension greedy activity-selector optimally schedules low altitude requests general problem AFSCN Scheduling (Barbulescu,Watson, Whitley, & Howe, 2004b).4. Algorithmsimplemented variety algorithms AFSCN scheduling: iterative repair, heuristicconstructive search, local search, genetic algorithm (GA), Squeaky Wheel Optimization (SWO). shown Section 5, found randomized next descent localsearch, GA SWO work best AFSCN scheduling.also considered constructive search algorithms based texture (Beck, Davenport,Davis, & Fox, 1998) slack (Smith & Cheng, 1993) constraint-based scheduling heuristics.implemented straightforward extensions algorithms application.results poor; number request tasks combined presence multiplealternative resources task make application methods impractical.report performance values constructive search methodsmethods depend critically heuristics; uncomfortable concludingmethods poor may found good enough heuristics them.also tried using commercial off-the-shelf satellite scheduling package similarlypoor results. report performance values commercial systemdesigned specifically application accesssource determine reason poor performance.4.1 Solution RepresentationPermutation based representations frequently used solving scheduling problems(e.g., Whitley, Starkweather, Fuquay, 1989; Syswerda, 1991; Wolfe, Sorensen, 2000; Aickelin, Dowsland, 2003; Globus et al., 2003). algorithms, except iterative-repair,encode solutions using permutation n task request IDs (i.e., [1..n]). schedulebuilder used generate solutions permutation request IDs. schedule builderconsiders task requests order appear . task request assignedfirst resource available sequence resource window pairs providedtask description (this first feasible resource sequence); earliest possiblestarting time chosen resource. minimizing number conflicts,request cannot scheduled alternative resources, droppedschedule (i.e., bumped). minimizing sum overlaps, request cannotscheduled without conflict alternative resources, assign resource584fiUnderstanding Algorithm Performanceoverlap requests scheduled far minimized. 6 Note schedulebuilder favor order alternative resources specified request,even though preference specified alternatives.4.2 Iterative RepairIterative repair methods successfully used solve various oversubscribed scheduling problems, e.g., Hubble Space Telescope observations (Johnston & Miller, 1994) spaceshuttle payloads (Zweben et al., 1994; Rabideau, Chien, Willis, & Mann, 1999). NASAsASPEN (A Scheduling Planning Environment) framework (Chien et al., 2000), employs constructive repair-based methods used model solvereal-world space applications scheduling EOS. recently, Kramer Smith(2003) used repair-based methods solve airlift scheduling problem USAF AirMobility Command.case, key component implementation domain appropriate ordering heuristic guide repairs. AFSCN scheduling, Gooleys algorithm (1993)uses domain-specific knowledge implement repair-based approach. implementimprovement Gooleys algorithm guaranteed yield results least goodproduced original version.Gooleys algorithm two phases. first phase, low altitude requestsscheduled, mainly using Mixed Integer Programming (MIP). large numberlow altitude requests, requests divided two blocks. MIP proceduresfirst used schedule requests first block. MIP used schedulerequests second block, inserted schedule around requestsfirst block. Finally, interchange procedure attempts optimize total numberlow altitude requests scheduled. needed low altitude requestsscheduled disjoint blocks. low altitude requests scheduled, start timeassigned resources remain fixed. implementation, replaced first phasegreedy algorithm (Barbulescu et al., 2004b) proven schedule optimal numberlow altitude requests7 . greedy algorithm modifies well-known activity-selectoralgorithm (Cormen et al., 1990) multiple resource problems: algorithm still schedulesrequests increasing order due date, however specifies requestscheduled resource idle time start time minimum.version accomplishes function Gooleys first phase,guarantee optimal number low-altitude requests scheduled. Thus, resultguaranteed equal better Gooleys original algorithm.second phase, high altitude requests inserted schedule (withoutrescheduling low altitude requests). order insertion high altituderequests computed. requests sorted decreasing order ratio durationrequest average length time windows (this similar flexibilitymeasure defined Kramer Smith, 2003 AMC); ties broken based numberalternative resources specified (fewer alternatives scheduled first). high6. two non-scheduled tasks overlap other, mutual overlap part sumoverlaps. overlap scheduled requests considered.7. algorithm optimally solves problem scheduling low altitude requests, polynomialtime.585fiBarbulescu, Howe, Whitley, & Robertsaltitude requests considered insertion, interchange procedure attemptsaccommodate unscheduled requests, rescheduling high altitude requests.unscheduled high altitude request, list candidate requests reschedulingcomputed (such successful rescheduling operation, unscheduled requestplaced spot initially occupied candidate). heuristic measureused determine requests candidate list rescheduled.chosen candidates, scheduling alternatives available, procedure appliedidentify requests rescheduled. interchange procedure definedtwo levels recursion called three satellite interchange.4.3 Randomized Local Search (RLS)implemented hill-climber call randomized local search, starts randomly generated solution iteratively moves toward better equally good neighboring solution. successfully applied number well-knownscheduling problems, selected domain-independent move operator, shift operator. current solution , neighborhood defined considering (N 1) 2pairs (x, y) positions , subject restriction 6= x 1. neighbor0corresponding position pair (x, y) produced shifting job positionx position y, leaving relative job orders unchanged. x < y,0 = ((1), ..., (x 1), (x + 1), ..., (y), (x), (y + 1), ..., (n)). x > y,0 = ((1), ..., (y 1), (x), (y), ..., (x 1), (x + 1), ..., (n)).Given large neighborhood size, use shift operator conjunction nextdescent hill-climbing. implementation completely randomizes neighbor examine next, replacement: step, x chosen randomly.general approach termed stochastic hill-climbing Ackley (1987).value randomly chosen neighbor equal better value currentsolution, becomes new current solution.emphasized Randomized Local Search, stochastic hill-climbing,sometimes much effective steepest-descent local search next-descent localsearch neighbors checked predefined order (as opposed random order).Forrest Mitchell (1993) showed random mutation hill climber (much like RLSAckleys stochastic hill climber) found solutions much faster steepest-descent localsearch problem called Royal Road function. random mutation hillclimber also found solutions much faster hill climber generated examinedneighbors systematically (in predefined order). Random mutation hill climberalso much effective genetic algorithm problem despite existencewould appear natural building blocks function. notableRoyal Road function staircase like function, step staircaseplateau.4.4 Genetic AlgorithmGenetic algorithms found perform well AFSCN scheduling problemearly studies (Parish, 1994). Genetic algorithms also found effectiveoversubscribed scheduling applications, scheduling F-14 flight simulators (Syswerda,586fiUnderstanding Algorithm Performance1991) abstraction NASAs EOS problem (Wolfe & Sorensen, 2000). studies,used version Genitor originally developed warehouse scheduling application(Starkweather et al., 1991); also version used Parish AFSCN scheduling.Like genetic algorithms, Genitor maintains population solutions; implementation, fixed population size 200. step algorithm, pair parentsolutions selected, crossover operator used generate single child solution,replaces worst solution population. Selection parent solutionsbased rank fitness, relative solutions population. FollowingParish (1994) Starkweather et al. (1991), used Syswerdas (1991) position-basedcrossover operator.Syswerdas position-based crossover operator starts selecting number randompositions second parent. corresponding selected elements appear exactlypositions offspring. remaining positions offspring filledelements first parent order appear parent:Parent 1: B C E F G H JParent 2: C F J H G B ESelected Elements:* ***Offspring: C F E G H B Jimplementation, randomly choose number positions selected,larger one third total number positions smaller twothirds total number positions.4.5 Squeaky Wheel OptimizationSqueaky Wheel Optimization (SWO) (Joslin & Clements, 1999) repeatedly iteratescycle composed three phases. First, greedy solution built, based priorities associated elements problem. Then, solution analyzed, elementscausing trouble identified based contribution objective function. Third,priorities trouble makers modified, considered earlier next iteration. cycle repeated, termination conditionmet.constructed initial greedy permutation SWO sorting requests increasing order flexibility. flexibility measure similar definedAMC application (Kramer & Smith, 2003): duration request dividedaverage time window possible alternative resources. break ties basednumber alternative resources available. requests equal flexibilities numbersalternative resources, earlier request scheduled first. multiple runs SWO,restarted modified permutation created performing 20 random swapsinitial greedy permutation.minimizing sum overlaps, identified overlapping requeststrouble spots schedule. Note overlap, considered one requestscheduled; request (or requests, two requests involved)overlapping request. sorted overlapping requests increasing ordercontribution sum overlaps. associated request distance587fiBarbulescu, Howe, Whitley, & Robertsmove forward, based rank sorted order. fixed minimum distancemoving forward one maximum distance five (this seems work betterpossible values tried). distance values equally distributed among ranks.moved requests forward permutation increasing order contributionsum overlaps: requests smaller overlaps moved first. tried versionsSWO distance move forward proportional contributionsum overlaps fixed. However, versions performed worse rank baseddistance implementation described above. minimizing conflicts scheduleconflicts equal contribution objective function; therefore decided moveforward fixed distance five (we tried values two seven fivebest).4.6 Heuristic Biased Stochastic Sampling (HBSS)HBSS (Bresina, 1996) incremental construction algorithm multiple rootto-leaf paths stochastically generated. step, HBSS algorithm needsheuristically choose next request schedule unscheduled requests. usedflexibility measure described SWO rank unscheduled requests. computeflexibility request order decreasing order flexibility;request given rank according ordering (first request rank 1, secondrequest rank 2, etc.). bias function applied ranks; noted Bresina (1996,p.271), choice bias function reflects confidence one heuristics accuracy- higher confidence, stronger bias. flexibility heuristic effectivegreedy heuristic constructing solutions AFSCN scheduling. Therefore usedrelatively strong bias function, exponential bias. rank r, bias computed:bias(r) = er . probability select unscheduled request rank rcomputed as:bias(r)P (r) = PiUnscheduled bias(rank(i))Unscheduled represents set unscheduled requests.implementation HBSS re-compute flexibility unscheduled tasksevery time choose next request scheduled. words, HBSS buildingpermutation requests schedule builder produces corresponding schedule.terms CPU time, means time required HBSS build solutionsimilar algorithms (dominated number evaluations). versionre-computing flexibility unscheduled tasks tasks scheduled would lotexpensive. fact, EOS similar oversubscribed scheduling problem,Globus et al. (2004) found updating heuristic values HBSS schedulinghundreds times slower permutation-based techniques, required farmemory, produced poor schedules.588fiUnderstanding Algorithm Performance5. Works Well?first step understanding best solve problem assess methods performbest. results running algorithms summarized Tables 2 3respectively. Genitor, randomized local search (RLS) Squeaky Wheel Optimization(SWO), report best mean value standard deviation observed 30runs, 8000 evaluations per run. HBSS, statistics taken 240,000 samples.Genitor RLS initialized random permutations.best known values sum overlaps (see Table 2) obtained runningGenitor population size increased 400 50,000 evaluations; hundreds experiments using numerous algorithms, found better solutionsthese. report algorithm better Genitor means betterGenitor algorithms limited 8000 evaluations.exception Gooleys algorithm, CPU times dominated numberevaluations therefore similar. Dell Precision 650 3.06 GHz Xeonrunning Linux, 30 runs 8000 evaluations per run take 80 190 seconds (forprecise values, see Barbulescu et al., 2004).increase number requests received day recent R problemscauses increase number percentage unscheduled requests. problems, eight task requests (or 2.5% tasks) scheduled; 97.5%99% task requests scheduled. R problems, 42 (or 8.7%tasks) scheduled; 91.3% 97.2% tasks requests scheduled.compare algorithm performance, statistical analyses include Genitor, SWO,RLS. also include analyses algorithms SWO1Move (a variant SWOexplore Section 6.5.2), ALLS (a variant Local Search present Section 7).judge significant differences final evaluations using ANOVA five algorithmsrecent days data. ANOVAs came back significant, justifiedperforming pair-wise tests. examined single-tailed, two sample t-test wellnon-parametric Wilcoxon Rank Sum test. Wilcoxon test significance resultst-test except two pairs, present p-values t-testclose rejection threshold p .005 per pair-wise test 8 .minimizing conflicts, many algorithms find solutions best knownvalues. Pair-wise t-tests show Genitor RLS significantly different R1,R3, R4. Genitor significantly outperforms RLS R2 (p = .0023) R5 (p = .0017).SWO perform significantly different RLS five days significantlyoutperforms Genitor R5. Genitor significantly outperforms SWO R2 R4; however,adjusting parameters used run SWO may fix problem. factsurprising well SWO performs minimizing conflicts, given chosesimple implementation, tasks conflict moved forward fixeddistance. HBSS performs well problems; however, fails find best knownvalues R1, R2 R3. original solution problem, Gooleys, computessingle solution; results improved sampling variant (see Section 6.2.1).8. Five algorithms imply, worst, 10 pair-wise comparisons per day data. control experimentwise error, use (very conservative, simple) Bonferroni adjustment; adjustment knownincrease probability Type II error (favoring false acceptance distributions similar).= .05, judge two algorithms significantly different p .005.589fiBarbulescu, Howe, Whitley, & RobertsDayA1A2A3A4A5A6A7R1R2R3R4R5Min84324664229172812GenitorMean8.643.032.064.16.03643.729.317.6328.0312.03SD0.4900.180.250.30.1800.980.460.490.180.18Min84324664229172812RLSMean8.74.03.12.24.76.166.0644.029.818.028.3612.4SD0.4600.30.480.460.370.251.250.710.690.660.56Min84324664329182812SWOMean8432.0646643.329.961828.312SD0.00.00.00.250.00.00.00.460.180.00.460Min84324664532192812HBSSMean9.764.643.373.094.276.397.3548.4435.1621.0831.2212.36GooleySD0.460.660.540.430.450.490.541.151.270.891.100.55117545764536202913Table 2: Performance Genitor, RLS, SWO, HBSS Gooleys algorithm termsbest mean number conflicts. Statistics Genitor, local searchSWO collected 30 independent runs, 8000 evaluations per run.HBSS, 240,000 samples considered. Min numbers boldface indicate bestknown values.minimizing overlaps, RLS finds best known solutions twoproblems. significantly outperforms Genitor R1 R2, significantly under-performsR3, significantly differ performance R4 R5. RLS SWOperform significantly different except R3 RLS under-performs. SWO significantlyoutperforms Genitor five days. However, run beyond 8000 evaluations, Genitorcontinues improve solution quality SWO fails find better solutions. HBSSfinds best known solutions problems. comparison, computedoverlaps corresponding schedules built using Gooleys algorithm presentlast column Table 3; however, Gooleys algorithm designed minimizeoverlaps.5.1 Progress Toward SolutionSWO Genitor apply different criteria determine solution modifications. RLS randomly chooses first shift resulting equally good improving solution. assesseffect differences, tracked best value obtained far runningalgorithms. problem, collected best value found SWO, Genitor RLSincrements 100 evaluations, 8000 evaluations. averaged values 30runs SWO, RLS, Genitor, respectively.typical example objective function presented Figures 2 3.objective functions, curves similar, relative performance. SWO quicklyfinds good solution, performance levels off. RLS progresses quicklyfirst half search, Genitor exacts smaller improvements. second halfsearch though, RLS takes longer find better solutions, Genitor continuessteadily progress toward best solution. best far Genitor improve590fiUnderstanding Algorithm PerformanceDayA1A2A3A4A5A6A7R1R2R3R4R5Min10413289304546913519275738146GenitorMean106.91328.49.230.445.146.1987.8540.7292.3755.4146.5SD0.60.01.20.70.50.40.640.813.310.910.31.9Min10413289304546798494250725146RLSMean106.7613.6630.710.1630.8345.1349.96848.66521.9327.53755.46147.1SD1.812.594.312.391.360.55.9538.4220.2855.3425.422.85Min10413289304546798491265731146SWOMean10413.428.113.33045.146841.4503.8270.1736.2146.0SD0.02.00.67.80.00.30.014.06.52.83.00.0Min128432895045831105598416827146HBSSMean158.770.152.545.782.665.5126.41242.6681.8571.0978.4164.4GooleySD28.731.116.913.013.216.812.542.127.046.028.710.8687535217216231152260171310478991288198Table 3: Performance Genitor, local search, SWO, HBSS Gooleys algorithmterms best mean sum overlaps. statistics collected 30independent runs, 8000 evaluations per run. HBSS, 240,000 samplesconsidered. Min numbers boldface indicate best known values.quickly best far RLS. unexpected: best solutionGenitor population isnt likely improve frequently beginning run.sense, tracking evolution median population running Genitor wouldindicative progress; use best far allow uniform comparisonthree algorithms.observe two differences objective functions. First, minimizing number conflicts, Genitor RLS eventually equal outperform SWO. minimizingoverlaps, Genitor RLS take longer find good solutions; 8000 evaluations, SWOfound best solutions. Second, minimizing number conflicts, towardend run, Genitor outperforms RLS. minimizing overlaps, RLS performs better Genitor. Best known solutions R problems minimizing overlapsobtained running RLS 50,000 evaluations 30 runs. Running SWO 50,000evaluations 30 runs results small improvements, two problems.6. Hypotheses Explaining Algorithm PerformanceGenitor, SWO RLS successful algorithms tested AFSCNproblem. Although operate search space (permutations), traversespace rather differently. puzzle three apparently well suitedproblem. solve puzzle, first, describe plateaus dominant featuresearch space. show greedy schedule builder main reason presenceplateaus. Then, test hypotheses appear follow dominanceplateaus characteristics algorithm.study, greedy schedule builder well objective function partproblem specification. Therefore, formulating testing hypotheses, considersearch space features (such plateaus number identical solutions) fixed.591fi36GenitorRLSSWO70Average Best Far Number BumpsAverage Best Far Number BumpsBarbulescu, Howe, Whitley, & Roberts6050403005001000150020002500Evaluations3000350034333231302940004000GenitorRLSSWO3545005000550060006500Evaluations700075008000Figure 2: Evolutions average best value conflicts obtained SWO, RLSGenitor 8000 evaluations, 30 runs. left figure depicts improvement average best value first 4000 evaluations. last4000 evaluations depicted right figure; note scale differenty-axis. curves obtained R2.850GenitorRLSSWO1600Average Best Far Sum OverlapsAverage Best Far Sum Overlaps1800140012001000800600400050010001500Evaluations200025003000GenitorRLSSWO8007507006506005505003000400050006000Evaluations70008000Figure 3: Evolutions average best value sum overlaps obtained SWO, RLSGenitor 8000 evaluations, 30 runs. left figure depictsimprovement average best value first 3000 evaluations. last5000 evaluations depicted right figure; note scale differenty-axis. curves obtained R2.6.1 Redundancy Search Spacethird neighbors RLS result exactly scheduleoverlaps minimal conflicts evaluation functions (Barbulescu et al., 2004a; Barbulescu,Whitley, & Howe, 2004c); 62% neighbors RLS result evaluation(see Section 6.4). AFSCN search space dominated plateaus three reasons.592fiUnderstanding Algorithm Performancemain reason presence plateaus greedy schedule builder: requestscheduled first available resource list possible alternatives. example,consider permutation n1 total n requests. last request X insertedfirst position permutation schedule builder applied, scheduleobtained. scan permutation n 1 requests left right, successivelyinserting X second position, third on, building correspondingschedule. long none requests appearing X permutation requireparticular spot occupied X first feasible alternative scheduled,schedule obtained. happens two reasons: 1) requests insertedschedule order appear permutation 2) greedyschedule builder considers possible alternatives order specifiedaccepts first alternative request scheduled. Let k + 1first position insert X alter S; means first feasible alternativeschedule request position k overlaps spot occupied X S. Xinserted position k + 1, new schedule S1 obtained; schedule S1built inserting X subsequent positions, encountering request firstfeasible alternative overlaps spot occupied X S1, etc. example alsoshows shifting permutation might change corresponding schedule.address presence plateaus search space result greedyschedule builder, could used randomization scheme diversify scheduler.However, randomization implementing schedule builder result problems unpredictability value assigned permutation. example, ShawFleming (1997) argue use randomization schedule builder detrimental performance genetic algorithm indirect representation used (forchromosomes schedules, case Genitor AFSCN scheduling).support idea noting general, genetic algorithms rely preservationgood fitness values. Also, SWO, randomization schedule builder changessignificance reprioritization one iteration next one. schedulerrandomized, new order requests likely result schedulerepaired version previous one. permutation requeststransformed multiple different schedules nondeterministic naturescheduler, SWO mechanism operate intended.second reason plateaus search space presence time windows.request X needs scheduled sometime end day, even appearsbeginning permutation, still occupy spot schedule towardsend (assuming scheduled) therefore, requests (whichappeared X permutation).third reason discretization objective function. Clearly, rangeconflicts small number discrete values (with weak upper bound numbertasks). range overlaps still discrete larger conflicts. Usingoverlaps evaluation function, approximately 20 times unique objective functionvalues observed search compared searches objective minimizeconflicts. effect discretization seen differing results using twoobjective functions. Thus, one reason including studies showeffects discretization.593fiBarbulescu, Howe, Whitley, & Roberts6.2 Genitor Learn Patterns Request Ordering?hypothesize Genitor performs well discovers interactionsrequests matter. examine sets permutations correspond schedulesbest known values identify chains common request orderings permutations,similar spirit notion backbone SAT (e.g., Singer et al., 2000). presencechains would support hypothesis Genitor discovering patterns requestorderings. classic building block hypothesis: pattern presentparent solutions contributes evaluation critical way; patternsrecombined inherited genetic recombination (Goldberg, 1989).6.2.1 Common Request OrderingsOne particular characteristics AFSCN scheduling problem presencetwo categories requests. low altitude requests fixed start times specifyone three alternative resources. high altitude requests implicitly specify multiplepossible start times (because corresponding time windows usually longerduration needs scheduled) 14 possible alternative resources. Clearlylow altitude requests constrained. suggests possible solution pattern,low altitude requests would scheduled first.explore viability pattern, implemented heuristic scheduleslow altitude requests high altitude ones; call heuristic splitheuristic. incorporated split heuristic schedule builder: given permutationrequests, new schedule builder first schedules low altitude requests,order appear permutation. Without modifying position lowaltitude requests schedule, high altitude requests inserted schedule,order appear permutation. idea scheduling lowaltitude requests high altitude requests basis Gooleys heuristic (1993).Also, split heuristic similar contention measures defined Frank et al. (2001).results obtained using split heuristic surprising: minimizingconflicts, best known valued schedules obtained quickly problems simplysampling small number random permutations. results obtained sampling 100random permutations shown Table 4.performance split heuristic transfer R problemsminimizing number overlaps, results Table 4 offer indication possiblerequest ordering pattern good solutions. Genitor fact performing welldiscovers scheduling low high altitude requests produces good solutions?general explanation Genitors performance, hypothesize Genitordiscovering patterns request ordering: certain requests must comerequests. test this, identify common request orderings present solutions obtainedmultiple runs Genitor. ran 1000 trials Genitor selected solutionscorresponding best known values. First, checked request orderings formrequestA requestB appear permutations corresponding bestknown solutions problems corresponding good solutions R problems.results summarized Table 5. Sol. Value columns show valuesolutions chosen analysis (out 1000 solutions). number solutions (out594fiUnderstanding Algorithm PerformanceDayA1A2A3A4A5A6A7BestKnown8432466Random Sampling-SMin Mean Stdev88.20.4144033.30.4622.430.5144.660.4866.50.51660Table 4: Results running random sampling split heuristic (Random SamplingS) 30 experiments, generating 100 random permutations per experimentminimizing conflicts.1000) corresponding chosen value shown # Solutions columns.analyzing common pairs request orderings minimizing number conflicts,observed pairs specified low altitude request appearing high altitudeone. Therefore, separate pairs two categories: pairs specifying low altituderequest high altitude requests (column: (Low,High) Pair Count) rest(column: Pairs). problems, results clearly show commonpairs ordering requests specify low altitude request high altitude request.R problems, pairs observed. part, might duesmall number solutions corresponding value (only 25 1000 R1minimizing conflicts). small number solutions corresponding value alsoreason big pair counts reported minimizing overlaps R problems.know problems split heuristic results best-known solutionsminimizing conflicts; therefore, results Table 5 somewhat surprising. expectedsee low-before-high common pairs requests problems minimizingnumber conflicts; instead, pair counts similar two objective functions.Genitor seems discover patterns request interaction, specify lowaltitude request high altitude request.results Table 5 heavily biased number solutions considered 9 . Indeed,let denote number solutions identical value (the number column # Solutions).Also, let n denote total number requests. Suppose preferences orderingstasks good solutions. request ordering B probability1/2 present one solutions, therefore, probability 1/2present solutions. Given exist n (n 1) possible precedences,expected number common orderings preferences orderings tasksexist n(n 1)/2s . problems R5, >= 420. expected numbercommon orderings assuming preferences orderings tasks exist smallern(n 1)/2420 , negligible. Therefore, number actually detected common9. wish thank anonymous reviewer earlier version work insightful observation;rest paragraph based his/her comments.595fiBarbulescu, Howe, Whitley, & RobertsDayA1A2A3A4A5A6A7R1R2R3R4R5Sol.Value84324664329172812Minimizing Conflicts#(Low,High)Solutions Pair Count42077100029936869371328624596710110004325216657364470789745489257Pairs111391031495211610Sol.Value10713289304546947530285744146Minimizing Overlaps#(Low,High)Solutions Pair Count9227895950833729121176464881712489157152815301597371185311240722109Pairs73105171011122230840034711Table 5: Common pairs request orderings found permutations corresponding bestknown/good Genitor solutions objective functions.precedences (approximately 30 125 low high pairs anywhere 117 others) seem actual request patterns. also caseR problems. Indeed, example, R1, = 15, expected number commonorderings preferences orderings tasks exist 7.1, numberactually detected precedences 2815 low high 1222 pairs.experiment found evidence support hypothesis Genitor solutionsexhibit patterns low high altitude requests. Given result, next investigatesplit heuristic (always scheduling low high altitude requests) enhanceperformance Genitor. answer question, run second experiment using Genitor,split heuristic schedule builder used evaluate every schedule generatedsearch.Table 6 shows results using split heuristic Genitor R problems.Genitor split heuristic fails find best-known solution R2 R3.surprising: fact, show scheduling low altitude requestshigh altitude requests may prevent finding optimal solutions.results minimizing sum overlaps shown Table 7. exceptionA3, A4 A6, Genitor using split heuristic fails find best known solutionsproblems. R problems, using split heuristic actually improves resultsobtained Genitor R1 R2; noted R1 R2 solutionsgood found RLS using 8000 evaluation however. Thus searchhybridizes genetic algorithm schedule builder using split heuristic sometimeshelps sometimes hurts terms finding good solutions.attempted identify longer chains common request ordering. successful: Genitor seem discover patterns request ordering, multiple differentpatterns request orderings result conflicts (or even schedule).596fiUnderstanding Algorithm PerformanceDayR1R2R3R4R5BestKnown4229172812Genitor NewSchedule BuilderMin Mean Stdev4242030300181802828012120Table 6: Minimizing conflicts: results running Genitor split heuristic 30 trials,8000 evaluations per trial.DayA1A2A3A4A5A6A7R1R2R3R4R5BestKnown10413289304546774486250725146Genitor NewSchedule BuilderMin Mean Stdev1191190.043430.028280.0990.050500.045450.069690.0907 924.33 6.01513 516.63 5.03276 276.03 0.18752 752.03 0.01461460.0Table 7: Minimizing sum overlaps: results running Genitor split heuristicusing split heuristic schedule builder evaluate schedule. resultsbased 30 experiments, 8000 evaluations per experiment.could think patterns building blocks. Genitor identifies good building blocks(orderings requests resulting good partial solutions) propagates finalpopulation (and final solution). patterns essential building good solution.However, patterns ubiquitous (not necessary) and, therefore,attempts identify across different solutions produced Genitor failed.597fiBarbulescu, Howe, Whitley, & RobertsDayA1A2A3A4A5A6A7R1R2R3R4R5Minimizing ConflictsBest Known Min Mean Stdev888.00.0444.00.0333.160.46222.130.34444.030.18666.230.63666.00.04242* 43.430.56293030.10.31717* 17.730.44282828.530.57121213.10.4Minimizing OverlapsBest Known Min Mean Stdev104104 104.460.68131313.831.89282830.131.969911.661.39303030.330.54454548.36.63464646.260.45774851 889.96 31.34486503522.29.8250268276.44.19725738 758.26 12.27146147 151.032.19Table 8: Statistics results obtained 30 runs SWO initialized randompermutations (i.e., RandomStartSWO), 8000 evaluations per run. meanbest value 30 runs well standard deviations shown.entries indicate values better corresponding SWO values.problem, best known solution objective function alsoincluded.6.3 SWOs Performance Due Initialization?graphs search progress SWO (Figures 2 3) show starts muchbetter solutions algorithms. initial greedy solution SWO translated best known values five problems (A2, A3, A5, A6 R5) minimizingnumber conflicts two problems (A6 R5) minimizing overlaps.important initial greedy permutation SWO? answer question,replaced initial greedy permutation (and variations subsequent iterations SWO)random permutations used SWO mechanism iteratively move forwardrequests conflict. call version SWO RandomStartSWO. comparedresults produced RandomStartSWO results SWO assess effectsinitial greedy solution. results produced RandomStartSWO presented Table 8.entries indicate RandomStartSWO produced better result SWO.exception R2, minimizing number conflicts, best known valuesobtained RandomStartSWO problems. fact, R1 R3, best resultsobtained slightly better best found SWO. minimizing sumoverlaps, best known values obtained problems; R problems,performance SWO worsens initialized random permutation. However,RandomStartSWO still performs better well Genitor (with exception R2minimizing number conflicts R5 overlaps) objective functions.results suggest initial greedy permutation main performance factorSWO: performance RandomStartSWO competitive Genitor.598fiUnderstanding Algorithm PerformanceDayA1A2A3A4A5A6A7R1R2R3R4R5TotalNeighbors1030419060196100100489924168880487616232324207936180625184900174724MinimizingRandom PermsMeanAvg %87581.184.979189.387.48293786.88475984.37795284.374671.584.076489.687.318956681.517343483.415320784.815745985.115434788.3ConflictsOptimal PermsMeanAvg %91609.188.983717.992.484915.488.987568.287.182057.488.778730.388.679756.591.019073682.017726485.215641386.516299688.115958191.3MinimizingRandom PermsMeanAvg %75877.473.670440.977.773073.376.572767.772.467649.373.263667.471.66783977.414551462.613756866.112651170.013068470.613367276.5OverlapsOptimal PermsMeanAvg %88621.286.081141.989.582407.786.38529084.879735.986.275737.985.277584.388.516048969.016035077.113901276.914595378.915262987.3Table 9: Statistics number neighbors resulting schedules valueoriginal, 30 random optimal permutations, objectivefunctions6.4 RLS Performing Random Walk?RLS spends time traversing plateaus search space (by accepting nonimproving moves). section, study average length random walksplateaus encountered local search. show search progresses random walksbecome longer finding improvement, mirroring progress RLS. notesimilar phenomenon observed SAT (Frank, Cheeseman, & Stutz, 1997).third shifting pairs requests result schedules identicalcurrent solution (Barbulescu et al., 2004a, 2004c). However, even larger numberneighbors result different schedules value current solution.means accepted moves search non-improving moves; search endsrandomly walking plateau exit found. collected resultsnumber schedules value original schedule, perturbing solutions possible pairwise changes. Note schedules include ones identicalcurrent solution. results summarized Table 9. report averagepercentage neighbors identical value original permutation. results showthat: 1) 84% shifts result schedules value original one, minimizing conflicts. minimizing overlaps, 62% (usuallyaround 70%) shifts result value schedules. 2) Best known solutionsslightly same-value neighbors random permutations; difference statistically significant minimizing overlaps. suggests plateaus correspondinggood values search space might larger size plateaus correspondingrandom permutations.assess size plateaus impact RLS, performed random walksfixed intervals RLS. every 500 evaluations RLS, identified current599fiBarbulescu, Howe, Whitley, & Robertssolution Crt. Crt, performed 100 iterations local search startingCrt stopping soon better solution maximum number equally goodsolutions encountered. problems, best known solutions often found earlysearch; 100 iterations local search started Crt would reachmaximum number equally good solutions. Therefore, chose limit 1000 stepsplateau problems 8000 steps R problems. averagednumber equally good solutions encountered 100 trials search performedCrt; represents average number steps needed find exit plateau.Figure 4 displays results obtained R4; similar behavior observed restproblems. Note used log scale axis graph correspondingminimizing overlaps: 100 walks performed current solution value 729end taking maximum number steps allowed (8000) without finding exitplateau. Also, random walk steps counts equal moves; number evaluationsneeded RLS (x-axis) considerably higher due needing check detrimental movesaccepting equal ones. results show large plateaus present searchspace; improving moves lead longer walks lower plateaus, detrimentalmoves factored in, appears mirror performance RLS.180010000LS729729LS729 7291600292912003029100080030306003231291000Average number steps plateauAverage number steps plateau1400293030307828141007947867867777517408641068944104001450200033630451000200030004000Evals5000600070008000101000200030004000Evals5000600070008000Figure 4: Average length random walk plateaus minimizing conflicts (left)overlaps (right) single local search run R4. labels graphsrepresent value current solution. Note log scale axisgraph corresponding minimizing overlaps. best known valueproblem 28 minimizing conflicts 725 minimizing overlaps.AFSCN scheduling problems, states plateau least oneneighbor better value (this neighbor represents exit). However, numberexits small percentage total number neighbors, therefore, localsearch small probability finding exit. Using terminology introducedFrank et al. (1997), plateaus encountered search AFSCN domainwould classified benches, meaning exits states lower levels present.exits plateau, plateau local minimum. Determiningplateaus local minima (by enumerating states plateau neighbors)600fiUnderstanding Algorithm Performanceprohibitive large size neighborhoods large number equallygood neighbors present state search space. Instead, focus averagelength random walk plateau factor local search performance. lengthrandom walk plateau depends two features: size plateaunumber exits plateau. Preliminary investigations show numberimproving neighbors solution decreases solution becomes better - thereforeconjecture exits higher level plateaus lower levelones. would account trend needing steps find exit movinglower plateaus (corresponding better solutions). also possible plateauscorresponding better solutions larger size; however, enumerating statesplateau AFSCN domain impractical (following technique developed Franket al., 1997, first iteration breadth first search would result approximately0.8 (n 1)2 states plateau).6.5 Long Leaps Instrumental?problems large plateaus (e.g., research published Gent Walsh,1995 SAT), hypothesize long leaps search space instrumentalalgorithm perform well AFSCN scheduling. SWO moving forward multiple requestsknown problematic. position crossover mechanism Genitorviewed applying multiple consecutive shifts first parent, requestsselected positions second parent moved selected positionsfirst. sense, time crossover operator applied, multiple move proposedfirst parent. hypothesize multiple move mechanism present SWOGenitor allows make long leaps space thus reach solutions fast.Note knew exactly requests move, moving forward smallnumber requests (or even one) might needed reach solutionsquickly. Finding requests move difficult; fact studied performanceinformed move operator moves requests positions guaranteeschedule changes (Roberts et al., 2005). found surprising results: informedmove operator performs worse random unrestricted shift employed RLS.argue multiple moves desired algorithm feature make likelyone moves right one.investigate hypothesis role multiple moves traversingsearch space, perform experiments variable number moves stepGenitor SWO. Genitor, vary number crossover positions allowed.SWO, vary number requests conflict moved forward.6.5.1 Effect Multiple Moves Genitortest effect multiple moves Genitor, change Syswerdas position crossoverimposing fixed number selected positions second parent (see Section 4.4description Syswerdas position crossover). call implementation Genitor-kk number selected positions. Recall implementation Syswerdas positioncrossover randomly selects number positions larger one third smallertwo thirds total number positions. multiple moves indeed factor601fiBarbulescu, Howe, Whitley, & RobertsAverage Best Far Sum Overlaps2000GenitorGenitor-10Genitor-50Genitor-100Genitor-150Genitor-300Genitor-35019001800170016001500140013001200050010001500 2000 2500EvaluationsAverage Best Far Sum Overlaps1600300035004000GenitorGenitor-10Genitor-50Genitor-100Genitor-150Genitor-300Genitor-3501500140013001200110010009004000450050005500 6000 6500Evaluations700075008000Figure 5: Evolutions average best value obtained Genitor versionsfixed number selected positions crossover. 8000 evaluations, 30runs. graphs obtained R1; best solution value 773.performance increasing number selected positions point resultfinding improvements faster. positions selected, offspringsimilar first parent. number selected positions large, close numbertotal requests, offspring similar second parent. offspringsimilar one two parents, expect slower rate finding improvementscurrent best solution. Therefore, small large k values, expect Genitor-k602fiUnderstanding Algorithm PerformanceDayA1A2A3A4A5A6A7R1R2R3R4R5Min115655985742273613Genitor-10Mean Stdev14.931.947.131.7710.42.1210.662.79.62.2912.631.810.61.7566.54.3847.163.5931.12.4141.92.7420.732.53Min84324664732192812Genitor-50Mean Stdev9.260.634.030.183.360.553.130.814.730.696.830.946.10.3052.02.8234.531.4721.61.6730.962.0413.230.81Min84324664229172812Genitor-100Mean Stdev8.660.474.00.03.00.02.230.504.260.446.030.186.00.045.831.6830.00.7818.030.6128.330.4712.460.62Genitor-150Min Mean Stdev88.530.544.00.033.00.022.060.2544.20.466.060.2566.00.04244.361.242929.60.561717.630.612828.10.41212.20.4Table 10: Performance Genitor-k, k represents fixed number selected positions Syswerdas position crossover, terms best mean numberconflicts. Statistics taken 30 independent runs, 8000 evaluationsper run. Min numbers boldface indicate best known values.find improvements much slower rate Genitor Genitor-k average k values(values closer half number requests).study, run Genitor-k k=10, 50, 100, 150, 200, 250, 300 350.allowed 8000 evaluations per run performed 30 runs problem. resultssummarized Tables 10 11 minimizing number conflicts Tables 1213 minimizing sum overlaps. Note A6 A7 299 297requests schedule respectively. Therefore Genitor-k k = 300 k = 350 cannotrun two problems. Also note example, k = 200 mean200 differences selected positions two parents. offspring likelysimilar parents, regardless value k, parents similar.minimizing number conflicts, worst results produced k = 10.k = 50, results improve, best knowns found problems; however, R1,R2, R3, best knowns found. Starting k = 100 k = 250 Genitor-kfinds best known solutions problems. means standard deviations alsosimilar k values; smallest means standard deviations correspondk = 200 problems k = 250 R problems (with exception R3k = 200 produces better results). k = 300, best knowns foundanymore problems; 300 close size five problemsfeasible run Genitor-300. decay performance significant Rproblems: increase means standard deviations k = 300 k = 350;however, best knowns still found four five problems. Note k = 400would lot closer total number requests R problems; believeperformance would degraded R problems larger k values.minimizing overlaps, observe trends similar ones minimizingnumber conflicts. k = 10 produces poor results, followed k = 50. Similar results603fiBarbulescu, Howe, Whitley, & RobertsDayA1A2A3A4A5A6A7R1R2R3R4R5Min84324664229172812Genitor-200Mean Stdev8.560.564.00.03.00.02.00.04.30.466.060.256.00.044.031.1529.360.4917.330.428.030.1812.10.3Min84324664229172812Genitor-250Mean Stdev8.90.34.030.183.060.253.130.814.730.586.50.576.060.2544.030.8529.40.4917.70.65280.012.060.25Min9944104329172812Genitor-300Mean Stdev11.81.6613.661.769.22.18.561.9413.862.1444.261.0129.70.5917.730.5828.030.1812.160.37Genitor-350Min Mean Stdev4345.461.222930.130.861718.630.82828.630.711212.60.81Table 11: Performance Genitor-k, k represents fixed number selected positions Syswerdas position crossover, terms best mean numberconflicts. Statistics collected 30 independent runs, 8000 evaluations per run. Min numbers boldface indicate best known values.dashes indicate permutation solutions A6 A7 shorter300 (299 297, respectively), therefore cannot select 300 positionspermutations.DayA1A2A3A4A5A6A7R1R2R3R4R5Min1493051594394671321743480866208Genitor-10Mean Stdev221.5338.8569.6629.22122.8636.12124.542.2590.732.01145.0633.12115.6627.961531.13 107.35961.1381.62652.590.371069.2374.65309.0346.3Min10713289304546987557319768146Genitor-50Mean Stdev115.76 11.5315.733.8636.268.1919.369.333.063.6249.65.5451.77.891139.5 76.57643.8650.0391.56 47.31840.23 38.79172.13 18.18Min10713289304546914515268735146Genitor-100Mean Stdev107.20.7613.431.5428.91.729.230.7230.360.9645.360.846.52.23991.13 38.19549.118.8305.3 20.63757.43 15.95151.537.63Min10713289304546915516269731146Genitor-150Mean Stdev107.10.5413.030.1828.160.649.060.3630.430.545.160.4647.633.9963.96 26.89540.86 15.82291.3 13.36752.7 14.07148.235.26Table 12: Performance Genitor-k, k represents fixed number selected positions Syswerdas position crossover, terms best mean sumoverlaps. Statistics collected 30 independent runs, 8000 evaluationsper run. Min numbers boldface indicate best known values.produced k = 100, 150, 200, 250. k = 150 results smallest means standarddeviations problems, k = 200 k = 250 produce best results Rproblems. k = 300 k = 350, similarly minimizing number conflicts,604fiUnderstanding Algorithm PerformanceDayA1A2A3A4A5A6A7R1R2R3R4R5Min10713289304546878512268730146Genitor-200Mean Stdev107.10.7413.20.9228.91.69.10.430.61.346.332.747.634.2970.1 38.38538.43 13.94287.96 11.05752.1 12.25147.6332.95Min10713289304546914511270734146Genitor-250Mean Stdev108.032.2217.05.831.634.4710.363.4131.562.2250.968.8249.935.39968.63 31.59538.93 12.88292.23 12.85754.53 11.89147.963.7Min113116633776935526272745146Genitor-300Mean Stdev157.66 26.21185.56 33.27106.23 26.2178.06 25.78160.0 36.59986.737.9551.63 12.27299.4316.3764 13.36148.63.84Min927532299743146Genitor-350Mean Stdev1008.8 42.17559.4619.7332.46 20.14785.36 26.6315710.6Table 13: Performance Genitor-k, k represents fixed number selected positions Syswerdas position crossover, terms best mean sumoverlaps. Statistics taken 30 independent runs, 8000 evaluationsper run. Min numbers boldface indicate best known values.means standard deviations increase best solutions found; best knownsfound R5.terms evolution solution, observe similar trends twoobjective functions. typical examples presented Figure 5 (minimizing overlapsR1). Genitor-k k = 10 slower finding improvements k = 50 slowerk = 100. k = 150 k = 250 performing similarly also similaroriginal Genitor implementation. k = 300 still moving space rate thatssimilar Genitors. k = 350 performance start decay.original implementation crossover operator (with variable number selected position) shown work well domain also schedulingapplications (Syswerda, 1991; Watson, Rana, Whitley, & Howe, 1999; Syswerda & Palmucci, 1991). test problems, results subsection show numbercrossover positions influences performance Genitor, terms best solutionsfound terms rate finding improvements. small number crossoverpositions (10 50), solutions found competitive, improvementsfound slower rate original Genitor implementation. Similarity Genitorsoriginal performance obtained k values 100 250. Higher k values resultdecay performance. results also offer empirical motivation choicenumber crossover positions original Genitor implementation. Indeed,original implementation, crossover uses number positions randomly selectedone third two thirds total number requests. translatessizes problems sets number positions approximately 100300.605fiBarbulescu, Howe, Whitley, & RobertsDayA1A2A3A4A5A6A7R1R2R3R4R5Minimizing ConflictsMin Mean Stdev88044033022044066066042* 43.40.729 29.90.318 18028 28.10.312 120Minimizing OverlapsMin Mean Stdev104 104013 13028 28099030 30045 45046 460872 926.7 22.1506 522.9 8.9271 283.0 6.1745 765.2 10.7146 1460Table 14: Performance modified version SWO one request movedforward constant distance 5. minimizing conflicts minimizingsum overlaps, request randomly chosen. statistics collected30 independent runs, 8000 evaluations per run. indicatesbest value better corresponding SWO result. Min numbers boldfaceindicate best known values.6.5.2 Effect Multiple Moves SWOhypothesize multiple moves present SWO necessary performance.test hypothesis, start investigating effect moving forward onerequest. somewhat similar shifting operator present RLS: request shiftedforward permutation. However, implement SWO reprioritization mechanism,restrict chosen request moved position gets moved.minimizing conflicts, one bumped requests randomly chosen; minimizingoverlaps, one requests contributing sum overlaps randomly chosen.minimizing conflicts minimizing sum overlaps chosen requestmoved forward constant distance five 10 . call new algorithm SWO1Move.results obtained running SWO1Move 30 runs 8000 evaluations per runpresented Table 14. entries indicate value produced SWO1Movebetter corresponding SWO result. initial solutions identicalsolutions produced using flexibility heuristic initializing SWO.minimizing conflicts, SWO1Move performs well SWO (in fact, findsbest known solution R1 well). minimizing sum overlaps, performanceSWO R problems worsens significantly one task moved forward. Previously, implemented SWO1Move minimizing overlaps moving forward requestcontributes total overlap (Barbulescu et al., 2004c). Randomly choosing10. tried values; average, value five seems work best.606fiUnderstanding Algorithm PerformanceDayR1R2R3R4Min840512284764k=10Mean862.5530.2291.36778.57Stdev11.289.184.658.45Min815498266749k=20Mean829.77506.53268.9757.3Stdev8.455.252.216.16Min798493266740k=30Mean820.63508.97271.07744.47Stdev8.125.263.522.6Min825508266737k=40Mean841.13526.26273.2747.2Stdev8.026.253.545.06Table 15: Performance modified version SWO k requests contributingsum overlaps moved forward constant distance 5. statisticscollected 30 independent runs, 8000 evaluations per run.request moved forward improved performance SWO1Move. Randomizationuseful SWO become trapped cycles (Joslin & Clements, 1999); however,improvement enough equal performance SWO minimizing overlapsnew days data. fact, longer runs SWO1Move random choicerequest moved (30 runs 50,000 evaluations) produce solutions still worseobtained SWO. results support conjecture performanceSWO due simultaneous moves requests.attribute discrepancy SWO1Move performance two objectivefunctions difference discretization two search spaces. minimizingconflicts, SWO1Move needs identify requests cannot scheduled.fine tuning needed minimizing sum overlaps; besides identifying requestscannot scheduled, SWO1Move also needs find positions requestspermutation sum overlaps minimized. conjecture finetuning achieved simultaneously moving forward multiple requests.Next, investigate changes performance increasing number requests(from requests contributing objective function) moved forward. designexperiment constant number requests involved conflicts movedforward. this, need decide many requests move ones. Movingtwo three requests forward results small improvements results Table 14.Therefore, run multiple versions SWO moving k requests forward, k = 10, 20,30, 40. determined empirically moving multiple requests (more five)forward, choosing random opposed based contribution sumoverlaps hurts algorithm performance. determine requests moved forward,step sort requests contributing sum overlaps decreasing ordercontribution move forward first k (or them, k greaternumber requests contributing sum overlaps).results obtained R1, R2, R3 R4 summarized Table 15.problems, new SWO versions find best known solutions. include R5study SWO greedy initial permutation computed R5 correspondsbest known value schedule. results show general performance improvement kgrows 10 20. k = 20 k = 30 produce similar performance R1, R2 R3.R4, k = 30 results better performance k = 20. k = 40 results worseningperformance R1 R2. Note algorithm performance R3 change607fiBarbulescu, Howe, Whitley, & Robertsk >= 20. surprising; since good solutions (in terms overlaps)problem correspond schedules small number overlapping tasks, moving forward20 requests means moving requests conflict good solutionsfound. results indicate problems set, minimizing overlaps,SWO allowed move forward constant number k requests, k = 30 seemsgood choice.results section support hypothesis moving multiple requests forwardnecessary obtain good SWO performance. First, showed moving onerequest forward (or small number requests, smaller 30 R problems) resultsinferior SWO performance. Second, number requests moved forward increased(from 10 up), performance SWO improves.7. New Algorithm: Attenuated Leap Local Searchempirical data analyses suggest key competitive performanceapplication moving quickly possible across plateaus. Two competitivealgorithms, Genitor SWO, perform multiple moves. simpler algorithm, RLS, actuallyfinds best known solutions 8000 evaluations, even though perform multiple moves. RLS however, perform significant number neutral movessolutions evaluation. Given this, conjecture version local searchperforms multiple moves evaluating result may even better suitedapplication. intuition behind conjecture search sample greaterdistances (i.e., longer single move) quickly find exits plateaus.modified RLS move operator follows: choose number pairs positionsapply shifting pairs, one another, without building scheduleshift; build schedule shifting applied designated numberpairs. first version, tried static number shifts (10 turnedbest value); however, performed better sometimes worse original moveoperator. next conjectured search progresses better solutions, numbershifts also decrease probability finding detrimental moves (ratherimproving) increases significantly well. better solution, fewer exitsexpected harder find.implemented multiple move hill-climber variable move count operator: givendecay rate, start shifting ten requests, nine, eight etc. chose decrementnumber shifts every 800 evaluations; call version hill-climbing AttenuatedLeap Local Search (ALLS). similar idea behind temperature dependenthill-climbing move operator implemented Globus et al. (2004), numberrequests move chosen random biased large number requestsmoved early search later requests moved 11 . Hill-climbingtemperature dependent operator produced better results EOS simply choosingrandom number requests move.ALLS performs remarkably well. shown Table 16, finds best known valuesproblems using conflicts two problems using overlaps (as11. operator similar temperature dependent behavior simulated annealing; explainsname operator.608fiUnderstanding Algorithm PerformanceAverage Best Far Number Bumps70GenitorRLSSWOALLS65605550454035302505001000150020002500EvaluationsAverage Best Far Number Bumps32300035004000GenitorRLSSWOALLS31.53130.53029.52928.5284000450050005500 6000 6500Evaluations700075008000Figure 6: Evolutions average best value obtained Genitor, RLS, SWO ALLS8000 evaluations, 30 runs. improvement first 4000evaluations shown top figure. last 4000 evaluations depictedbottom figure; note scale different y-axis. graphsobtained R4; best solution value 28.RLS). Additionally, finds better best values algorithms settwo problems non-best solutions. fact, single tailed, two sample t-test comparingALLS RLS shows ALLS finds statistically significantly better solutions (p < 0.023)conflicts overlaps five recent days.609fiBarbulescu, Howe, Whitley, & RobertsAverage Best Far Number Overlaps1700GenitorRLSSWOALLS1600150014001300120011001000900800700050010001500 2000 2500EvaluationsAverage Best Far Number Overlaps900300035004000GenitorRLSSWOALLS8808608408208007807607407204000450050005500 6000 6500Evaluations700075008000Figure 7: Evolutions average best value obtained Genitor, RLS, SWO ALLS8000 evaluations, 30 runs. improvement first 4000evaluations shown top figure. last 4000 evaluations depictedbottom figure; note scale different y-axis.The graphsobtained R4; best solution value 725.Section 5, discussed comparison across algorithms (again p < 0.005).much restrictive performance comparison, ALLS still outperforms RLS,SWO Genitor pair-wise tests. minimizing conflictsminimizing overlaps, ALLS significantly outperforms algorithms R1.610fiUnderstanding Algorithm PerformanceDayA1A2A3A4A5A6A7R1R2R3R4R5Minimizing ConflictsMin Mean Stdev88.20.444.00.033.00.022.030.1844.10.366.00.066.00.042 42.630.722929.10.31717.50.5728 28.070.251212.00.0Minimizing OverlapsMin Mean Stdev104 107.11.241313.00.02828.331.399.130.733030.230.434545.00.04646.00.0785 817.83 27.07490 510.37 19.14250 273.33 43.68725 740.07 19.56146 146.03 0.19Table 16: Statistics results obtained 30 runs ALLS, 8,000 evaluations perrun. best mean values well standard deviations shown.Bold indicates best known values.minimizing conflicts, ALLS outperforms five twelve pair-wise testsfour days (for difference significant). exceptions are: R2, R3,R4, R5 Genitor R4 RLS. minimizing overlaps, ALLS significantlyoutperforms Genitor R2, RLS R3, Genitor R4 SWO R5; restpair-wise comparisons statistically significant p < 0.005. clear ALLSleast good best algorithms outperforms days data.ALLS also finds improving solutions faster Genitor RLS (see Figures 67 R4 conflicts overlaps). ALLS achieves good performancecombining power finding good solutions fast using multiple moves beginningsearch accuracy locating best solutions using one-move shiftingend search.6.4 showed solutions improve random walks plateaus becomelonger. Two hypotheses support observation: 1) plateaus bigger 2) plateausharder escape fewer exits. two hypotheses consistentmissing exits replaced moves equal value. consistent exitsreplaced worse moves. ALLS design implicitly assumes latter. exitsreplaced equal moves search progresses moves would neededper large step12 . fact, ran tests increased number movessearch progresses found significantly worsen performance.example, R1 minimizing overlaps, shifting initially ten requests increasingnumber shifted requests 1 every 800 iterations (instead decreasing ALLS)12. wish thank anonymous reviewer insightful observation.611fiBarbulescu, Howe, Whitley, & Robertsresults minimum overlap 885, mean 957.97 standard deviation51.36, significantly worse corresponding ALLS result.8. Conclusionkey algorithm characteristic AFSCN appears multiple moves. fact,observation might hold oversubscribed scheduling problems well. Globus etal. (Globus et al., 2004) found solving oversubscribed problem schedulingfleets EOS using hill-climbing, moving one request time inefficient.temperature dependent hill-climbing operator proved work better simply choosingrandom number requests move. domain, permutation representationgreedy deterministic schedule builder used. conjecture schedule builderalso results multiple permutations mapped schedule, thereforeplateaus present EOS search space well. fact movingone request improved results suggests conjecture could also hold EOSscheduling: multiple moves might speed plateau traversal domain well.developed tested four hypotheses explaining performance three competitive algorithms real scheduling application. found hypotheses heldvarying degrees. Based evidence, designed new algorithm combinedappeared critical elements best performing algorithms producedalgorithm performed better original ones. results suggest multiple moves useful algorithm feature obtain good performance results AFSCNscheduling. Alternatively, possible fact one move iterationwould enough obtain good performance, difficult identify requestmove. Future research direction examine heuristics combining HBSSSWO decide request move forward, well heuristics find moverequest guarantee change schedule. Also future research, testingoversubscribed scheduling applications determine extent analysesresults generalize: exhibit characteristics amenablekind solution?Acknowledgmentsresearch supported part grant Air Force Office Scientific Research, Air Force Materiel Command, USAF grant number F49620-03-1-0233. AdeleHowe also supported National Science Foundation Grant No. IIS-0138690.opinions, findings, conclusions recommendations expressed materialauthor(s) necessarily reflect views National ScienceFoundation. U.S. Government authorized reproduce distribute reprintsGovernmental purposes notwithstanding copyright notation thereon.612fiUnderstanding Algorithm PerformanceReferencesAckley, D. (1987). Connectionist Machine Genetic Hillclimbing. Kluwer AcademicPublishers.Aickelin, U., & Dowsland, K. (2003). indirect genetic algorithm nurse schedulingproblem. Computers & Operations Research, 31 (5), 761778.Barbulescu, L., Howe, A., Whitley, L., & Roberts, M. (2004a). Trading places:schedule multi-resource oversubscribed scheduling problem. ProceedingsInternational Conference Planning Scheduling, Whistler, CA.Barbulescu, L., Watson, J., Whitley, D., & Howe, A. (2004b). Scheduling Space-GroundCommunications Air Force Satellite Control Network. Journal Scheduling,7, 734.Barbulescu, L., Whitley, L., & Howe, A. (2004c). Leap look: effective strategyoversubscribed problem. Proceedings Nineteenth National ArtificialIntelligence Conference, San Jose, CA.Beck, J., Davenport, A., Davis, E., & Fox, M. (1998). ODO Project: Toward UnifiedBasis Constraint-directed Scheduling. Journal Scheduling, 1, 89125.Bresina, J. (1996). Heuristic-Biased Stochastic Sampling. Proceedings ThirteenthNational Conference Artificial Intelligence, pp. 271278, Portland, OR.Burrowbridge, S. E. (1999). Optimal Allocation Satellite Network Resources. MastersThesis. Virginia Polytechnic Institute State University.Chien, S., Rabideau, G., Knight, R., Sherwood, R., Engelhardt, B., Mutz, D., Estlin, T.,Smith, B., Fisher, F., Barrett, T., Stebbins, G., & Tran, D. (2000). ASPEN - Automating space mission operations using automated planning scheduling. 6thInternational SpaceOps Symposium (Space Operations), Toulouse (France).Cormen, T., Leiserson, C., & Rivest, R. (1990). Introduction Algorithms. MIT press,Cambridge, MA.Deale, M., Yvanovich, M., Schnitzuius, D., Kautz, D., Carpenter, M., Zweben, M., Davis,G., & Daun, B. (1994). Space Shuttle ground processing scheduling system.Zweben, M., & Fox, M. (Eds.), Intelligent Scheduling, pp. 423449. Morgan Kaufmann.Forrest, S., & Mitchell, M. (1993). Relative Building-Block Fitness Building BlockHypothesis. Whitley, L. D. (Ed.), Foundations Genetic Algorithms 2, pp. 109126. Morgan Kaufmann.Frank, J., Cheeseman, P., & Stutz, J. (1997). gravity fails: Local search topology.Journal Artificial Intelligence Research, 7, 249281.Frank, J., Jonsson, A., Morris, R., & Smith, D. (2001). Planning scheduling fleetsearth observing satellites. Proceedings Sixth International SymposiumArtificial Intelligence, Robotics, Automation Space.Gent, I., & Walsh, T. (1995). Unsatisfied variables local search. Hybrid Problems,Hybrid Solutions, pp. 7385. IOS Press Amsterdam.613fiBarbulescu, Howe, Whitley, & RobertsGlobus, A., Crawford, J., Lohn, J., & Pryor, A. (2003). Scheduling earth observing satellitesevolutionary agorithms. International Conference Space Mission Challenges Information Technology, Pasadena, CA.Globus, A., Crawford, J., Lohn, J., & Pryor, A. (2004). comparison techniquesscheduling earth observing satellites. Proceedings Sixteenth Innovative Applications Artificial Intelligence Conference, San Jose, CA.Goldberg, D. (1989). Genetic Algorithms Search, Optimization Machine Learning.Addison-Wesley, Reading, MA.Gooley, T. (1993). Automating Satellite Range Scheduling Process. Masters Thesis.Air Force Institute Technology.Jang, K. (1996). Capacity Air Force Satellite Control Network. MastersThesis. Air Force Institute Technology.Johnston, M., & Miller, G. (1994). Spike: Intelligent scheduling Hubble space telescopeobservations. Morgan, M. B. (Ed.), Intelligent Scheduling, pp. 391422. MorganKaufmann Publishers.Joslin, D. E., & Clements, D. P. (1999). Squeaky Wheel Optimization. JournalArtificial Intelligence Research, Vol. 10, pp. 353373.Kramer, L., & Smith, S. (2003). Maximizing flexibility: retraction heuristic oversubscribed scheduling problems. Proceedings 18th International Joint ConferenceArtificial Intelligence, Acapulco, Mexico.Lematre, M., Verfaillie, G., & Jouhaud, F. (2000). manage new generationAgile Earth Observation Satellites. 6th International SpaceOps Symposium (SpaceOperations), Toulouse, France.Parish, D. (1994). Genetic Algorithm Approach Automating Satellite Range Scheduling. Masters Thesis. Air Force Institute Technology.Pemberton, J. (2000). Toward Scheduling Over-Constrained Remote-Sensing Satellites.Proceedings Second NASA International Workshop Planning SchedulingSpace, San Francisco, CA.Rabideau, G., Chien, S., Willis, J., & Mann, T. (1999). Using iterative repair automateplanning scheduling shuttle payload operations. Innovative ApplicationsArtificial Intelligence (IAAI 99), Orlando,FL.ROADEF Challenge (2003).French Society Operations Research Decision Analisys ROADEF Challenge 2003.http://www.prism.uvsq.fr/vdc/ROADEF/CHALLENGES/2003/.Roberts, M., Whitley, L., Howe, A., & Barbulescu, L. (2005). Random walks neighborhood bias oversubscribed scheduling. Multidisciplinary International ConferenceScheduling (MISTA-05), New York, NY.Schalck, S. (1993). Automating Satellite Range Scheduling. Masters Thesis. Air ForceInstitute Technology.614fiUnderstanding Algorithm PerformanceShaw, K., & Fleming, P. (1997). Use rules preferences schedule buildersgenetic algorithms production scheduling. Proceedings AISB97 WorkshopEvolutionary Computation. Lecture Notes Computer Science, 1305, 237250.Singer, J., Gent, I., & Smaill, A. (2000). Backbone Fragility Local Search CostPeak. Journal Artificial Intelligence Research, Vol. 12, pp. 235270.Smith, S., & Cheng, C. (1993). Slack-based Heuristics Constraint Satisfaction Problems.Proceedings Eleventh National Conference Artificial Intelligence (AAAI93), pp. 139144, Washington, DC. AAAI Press.Starkweather, T., McDaniel, S., Mathias, K., Whitley, D., & Whitley, C. (1991). Comparison Genetic Sequencing Operators. Booker, L., & Belew, R. (Eds.), Proc.4th Intl. Conf. GAs, pp. 6976. Morgan Kaufmann.Syswerda, G. (1991). Schedule Optimization Using Genetic Algorithms. Davis, L. (Ed.),Handbook Genetic Algorithms, chap. 21. Van Nostrand Reinhold, NY.Syswerda, G., & Palmucci, J. (1991). Application Genetic Algorithms ResourceScheduling. Booker, L., & Belew, R. (Eds.), Proc. 4th Intl. Conf. GAs.Morgan Kaufmann.Watson, J. P., Rana, S., Whitley, D., & Howe, A. (1999). Impact Approximate Evaluation Performance Search Algorithms Warehouse Scheduling. JournalScheduling, 2(2), 7998.Whitley, D., Starkweather, T., & Fuquay, D. (1989). Scheduling Problems TravelingSalesmen: Genetic Edge Recombination Operator. Schaffer, J. D. (Ed.), Proc.3rd Intl. Conf. GAs. Morgan Kaufmann.Whitley, L. D. (1989). GENITOR Algorithm Selective Pressure: Rank BasedAllocation Reproductive Trials Best. Schaffer, J. D. (Ed.), Proc. 3rdIntl. Conf. GAs, pp. 116121. Morgan Kaufmann.Wolfe, W. J., & Sorensen, S. E. (2000). Three Scheduling Algorithms Applied EarthObserving Systems Domain. Management Science, Vol. 46(1), pp. 148168.Zweben, M., Daun, B., & Deale, M. (1994). Scheduling rescheduling iterativerepair. Zweben, M., & Fox, M. (Eds.), Intelligent Scheduling. Morgan Kaufmann.615fiJournal Artificial Intelligence Research 27 (2006) 119151Submitted 1/06; published 10/06Comparison Different Machine Transliteration ModelsJong-Hoon Ohrovellia@nict.go.jpComputational Linguistics GroupNational Institute Information Communications Technology (NICT)3-5 Hikaridai, Seika-cho, Soraku-gun, Kyoto 619-0289 JapanKey-Sun Choikschoi@cs.kaist.ac.krComputer Science Division, Department EECSKorea Advanced Institute Science Technology (KAIST)373-1 Guseong-dong, Yuseong-gu, Daejeon 305-701 Republic KoreaHitoshi Isaharaisahara@nict.go.jpComputational Linguistics GroupNational Institute Information Communications Technology (NICT)3-5 Hikaridai, Seika-cho, Soraku-gun, Kyoto 619-0289 JapanAbstractMachine transliteration method automatically converting words one language phonetically equivalent ones another language. Machine transliteration playsimportant role natural language applications information retrieval machine translation, especially handling proper nouns technical terms. Four machinetransliteration models grapheme-based transliteration model, phoneme-based transliteration model, hybrid transliteration model, correspondence-based transliteration modelproposed several researchers. date, however, little researchframework multiple transliteration models operate simultaneously. Furthermore, comparison four models within frameworkusing data. addressed problems 1) modeling four models withinframework, 2) comparing conditions, 3) developingway improve machine transliteration comparison. comparison showedhybrid correspondence-based models effectivefour models used complementary manner improve machine transliterationperformance.1. Introductionadvent new technology flood information Web,become increasingly common adopt foreign words ones language. usually entails adjusting adopted words original pronunciation follow phonological rulestarget language, along modification orthographical form. phonetictranslation foreign words called transliteration. example, English worddata transliterated Korean de-i-teo1 Japanese de-e-ta. Transliteration particularly used translate proper names technical terms languages1. paper, target language transliterations represented Romanized form singlequotation marks hyphens syllables.c2006AI Access Foundation. rights reserved.fiOh, Choi, & Isaharausing Roman alphabets ones using non-Roman alphabets EnglishKorean, Japanese, Chinese. transliteration one main causesout-of-vocabulary (OOV) problem, transliteration means dictionary lookup impractical (Fujii & Tetsuya, 2001; Lin & Chen, 2002). One way solve OOV problemuse machine transliteration. Machine transliteration usually used support machinetranslation (MT) (Knight & Graehl, 1997; Al-Onaizan & Knight, 2002) cross-languageinformation retrieval (CLIR) (Fujii & Tetsuya, 2001; Lin & Chen, 2002). CLIR, machinetransliteration bridges gap transliterated localized form original formgenerating possible transliterations original form (or generating possibleoriginal forms transliteration)2 . example, machine transliteration assistquery translation CLIR, proper names technical terms frequently appearsource language queries. area MT, machine transliteration helps preventing translation errors translations proper names technical terms registeredtranslation dictionary. Machine transliteration therefore improve performanceMT CLIR.Four machine transliteration models proposed several researchers: grapheme3 -based transliteration model (G ) (Lee & Choi, 1998; Jeong, Myaeng, Lee, &Choi, 1999; Kim, Lee, & Choi, 1999; Lee, 1999; Kang & Choi, 2000; Kang & Kim, 2000;Kang, 2001; Goto, Kato, Uratani, & Ehara, 2003; Li, Zhang, & Su, 2004), phoneme4 based transliteration model (P ) (Knight & Graehl, 1997; Lee, 1999; Jung, Hong, &Paek, 2000; Meng, Lo, Chen, & Tang, 2001), hybrid transliteration model (H ) (Lee,1999; Al-Onaizan & Knight, 2002; Bilac & Tanaka, 2004), correspondence-basedtransliteration model (C ) (Oh & Choi, 2002). models classified termsunits transliterated. G sometimes referred direct methoddirectly transforms source language graphemes target language graphemes withoutphonetic knowledge source language words. P sometimes referredpivot method uses source language phonemes pivot producestarget language graphemes source language graphemes. P therefore usuallyneeds two steps: 1) produce source language phonemes source language graphemes;2) produce target language graphemes source phonemes5 . H C make usesource language graphemes source language phonemes producing targetlanguage transliterations. Hereafter, refer source language grapheme source2. former process generally called transliteration, latter generally called backtransliteration (Knight & Graehl, 1997)3. Graphemes refer basic units (or smallest contrastive units) written language: example,English 26 graphemes letters, Korean 24, German 30.4. Phonemes simplest significant unit sound (or smallest contrastive units spoken language); example, /M/, /AE/, /TH/ /M AE TH/, pronunciation math. useARPAbet symbols represent source phonemes. ARPAbet one methods used coding sourcephonemes ASCII characters (http://www.cs.cmu.edu/~laura/pages/arpabet.ps). denotesource phonemes pronunciation two slashes, /AH/, use pronunciation basedCMU Pronunciation Dictionary American Heritage(r) Dictionary English Language.5. two steps explicit transliteration system produces target language transliterationsproducing pronunciations source language words; implicit system uses phonemesimplicitly transliteration stage explicitly learning stage, described elsewhere (Bilac& Tanaka, 2004)120fiA Comparison Machine Transliteration Modelsgrapheme, source language phoneme source phoneme, target language graphemetarget grapheme.transliterations produced four models usually differ models usedifferent information. Generally, transliteration phonetic process, P , ratherorthographic one, G (Knight & Graehl, 1997). However, standard transliterations restricted phoneme-based transliterations. example, standardKorean transliterations data, amylase, neomycin are, respectively, phonemebased transliteration de-i-teo, grapheme-based transliteration a-mil-la-a-je, neo-ma-i-sin, combination grapheme-based transliteration ne-ophoneme-based transliteration ma-i-sin. Furthermore, unit transliteratedrestricted either source grapheme source phoneme, hard produce correcttransliteration many cases. example, P cannot easily produce grapheme-basedtransliteration a-mil-la-a-je, standard Korean transliteration amylase, Ptends produce a-mil-le-i-seu based sequence source phonemes /AE AHL EY S/. Multiple transliteration models therefore applied better covervarious transliteration processes. date, however, little published researchregarding framework multiple transliteration models operate simultaneously.Furthermore, reported comparison transliteration models withinframework using data although many English-to-Korean transliteration methods based G compared data (Kang& Choi, 2000; Kang & Kim, 2000; Oh & Choi, 2002).address problems, 1) modeled framework four transliteration models operate simultaneously, 2) compared transliterationmodels conditions, 3) using results comparison,developed way improve performance machine transliteration.rest paper organized follows. Section 2 describes previous work relevantstudy. Section 3 describes implementation four transliteration models.Section 4 describes testing results. Section 5 describes way improve machinetransliteration based results comparison. Section 6 describes transliteration ranking method used improve transliteration performance. Section 7concludes paper summary look future work.2. Related WorkMachine transliteration received significant research attention recent years.cases, source language target language English Asian language, respectively example, English Japanese (Goto et al., 2003), English Chinese (Menget al., 2001; Li et al., 2004), English Korean (Lee & Choi, 1998; Kim et al., 1999;Jeong et al., 1999; Lee, 1999; Jung et al., 2000; Kang & Choi, 2000; Kang & Kim, 2000;Kang, 2001; Oh & Choi, 2002). section, review previous work related fourtransliteration models.2.1 Grapheme-based Transliteration ModelConceptually, G direct orthographical mapping source graphemes targetgraphemes. Several transliteration methods based model proposed,121fiOh, Choi, & Isaharabased source-channel model (Lee & Choi, 1998; Lee, 1999; Jeong et al.,1999; Kim et al., 1999), decision tree (Kang & Choi, 2000; Kang, 2001), transliterationnetwork (Kang & Kim, 2000; Goto et al., 2003), joint source-channel model (Li et al.,2004).methods based source-channel model deal English-Korean transliteration. use chunk graphemes correspond source phoneme. First,English words segmented chunk English graphemes. Next, possible chunksKorean graphemes corresponding chunk English graphemes produced. Finally,relevant sequence Korean graphemes identified using source-channelmodel. advantage approach considers chunk graphemes representing phonetic property source language word. However, errors first step(segmenting English words) propagate subsequent steps, making difficultproduce correct transliterations steps. Moreover, high time complexitypossible chunks graphemes generated languages.method based decision tree, decision trees transform sourcegrapheme target graphemes learned directly applied machine transliteration. advantage approach considers wide range contextualinformation, say, left three right three contexts. However, considerphonetic aspects transliteration.Kang Kim (2000) Goto et al. (2003) proposed methods based transliteration network for, respectively, English-to-Korean English-to-Japanese transliteration.frameworks constructing transliteration network similar composednodes arcs. node represents chunk source graphemes correspondingtarget graphemes. arc represents possible link nodes weight showingstrength. Like methods based source-channel model, methods considerphonetic aspect form chunks graphemes. Furthermore, segment chunkgraphemes identify relevant sequence target graphemes one step.means errors propagated one step next, methods basedsource-channel model.method based joint source-channel model simultaneously considers sourcelanguage target language contexts (bigram trigram) machine transliteration.main advantage use bilingual contexts.2.2 Phoneme-based Transliteration ModelP , transliteration key pronunciation source phoneme ratherspelling source grapheme. model basically source grapheme-to-source phonemetransformation source phoneme-to-target grapheme transformation.Knight Graehl (1997) modeled Japanese-to-English transliteration weightedfinite state transducers (WFSTs) combining several parameters including romaji-tophoneme, phoneme-to-English, English word probabilities, on. similar modeldeveloped Arabic-to-English transliteration (Stalls & Knight, 1998). Meng et al. (2001)proposed English-to-Chinese transliteration method based English grapheme-to-phonemeconversion, cross-lingual phonological rules, mapping rules English phonemesChinese phonemes, Chinese syllable-based character-based language models. Jung122fiA Comparison Machine Transliteration Modelset al. (2000) modeled English-to-Korean transliteration extended Markov window.method transforms English word English pronunciation using pronunciation dictionary. segments English phonemes chunks English phonemes;chunk corresponds Korean grapheme defined handcrafted rules. Finally,automatically transforms chunk English phonemes Korean graphemes usingextended Markov window.Lee (1999) modeled English-to-Korean transliteration two steps. English graphemeto-English phoneme transformation modeled manner similar method basedsource-channel model described Section 2.1. English phonemestransformed Korean graphemes using English-to-Korean standard conversion rules(EKSCR) (Korea Ministry Culture & Tourism, 1995). rules formcontext-sensitive rewrite rules, PA PX PB y, meaning English phoneme PXrewritten Korean grapheme context PA PB , PX , PA , PB represent English phonemes. example, PA = , PX = /SH/, PB = end si meansEnglish phoneme /SH/ rewritten Korean grapheme si occurs endword (end) phoneme (). approach suffers propagationerrors limitations EKSCR. first step, grapheme-to-phoneme transformation, usually results errors, errors propagate next step. Propagated errorsmake difficult transliteration system work correctly. addition, EKSCRcontain enough rules generate correct Korean transliterations since main focusmapping English phoneme Korean graphemes without taking accountcontexts English grapheme.2.3 Hybrid Correspondence-based Transliteration ModelsAttempts use source graphemes source phonemes machine transliterationled correspondence-based transliteration model (C ) (Oh & Choi, 2002)hybrid transliteration model (H ) (Lee, 1999; Al-Onaizan & Knight, 2002; Bilac & Tanaka,2004). former makes use correspondence source grapheme sourcephoneme produces target language graphemes; latter simply combines GP linear interpolation. Note H combines grapheme-based transliteration probability (P r(G )) phoneme-based transliteration probability (P r(P ))using linear interpolation.Oh Choi (2002) considered contexts source grapheme corresponding source phoneme English-to-Korean transliteration. used EKSCR basic rules method. Additional contextual rules semi-automatically constructedexamining cases EKSCR produced incorrect transliterationslack contexts. contextual rules form context-sensitive rewriterules, CA CX CB y, meaning CX rewritten target grapheme contextCA CB . Note CX , CA , CB represent correspondence English grapheme phoneme. example, read CA = ( : /V owel/), CX =(r : /R/), CB = ( : /Consonant/) NULL English grapheme r correspondingphoneme /R/ rewritten null Korean graphemes occurs vowel phonemes,( : /V owel/), consonant phonemes, ( : /Consonant/). main advantageapproach application sophisticated rule reflects context source123fiOh, Choi, & Isaharagrapheme source phoneme considering correspondence. However, lackportability languages rules restricted Korean.Several researchers (Lee, 1999; Al-Onaizan & Knight, 2002; Bilac & Tanaka, 2004)proposed hybrid model-based transliteration methods. model G P WFSTs source-channel model combine G P linear interpolation.P , several parameters considered, source grapheme-to-source phonemeprobability, source phoneme-to-target grapheme probability, target language word probability. G , source grapheme-to-target grapheme probability mainly considered. main disadvantage hybrid model dependence sourcegrapheme source phoneme taken consideration combining process;contrast, Oh Chois approach (Oh & Choi, 2002) considers dependence usingcorrespondence source grapheme phoneme.3. Modeling Machine Transliteration Modelssection, describe implementation four machine transliteration models(G , P , H , C ) using three machine learning algorithms: memory-based learning,decision-tree learning, maximum entropy model.3.1 Framework Four Machine Transliteration ModelsFigure 1 summarizes differences among transliteration models componentfunctions. G directly transforms source graphemes (S) target graphemes (T).P C transform source graphemes source phonemes generate targetgraphemes6 . P uses source phonemes, C uses correspondencesource grapheme source phoneme generates target graphemes.describe differences two functions, P (SP )T . H representedlinear interpolation P r(G ) P r(P ) means (0 1). Here, P r(P )probability P produce target graphemes, P r(G ) probability Gproduce target graphemes. thus regard H composed componentfunctions G P (SP , P , ST ). use maximum entropy modelmachine learning algorithm H H requires P r(P ) P r(G ),maximum entropy model among memory-based learning, decision-tree learning,maximum entropy model produce probabilities.train component function, need define features represent traininginstances data. Table 1 shows five feature types, fS , fP , fStype , fP type , fT .feature types used depend component functions. modeling componentfunction feature types explained Sections 3.2 3.3.3.2 Component Functions Transliteration ModelTable 2 shows definitions four component functions used. definedterms input output: first last characters notationcorrespond respectively input output. role component function6. According (gf )(x) = g(f (x)), write ((SP )T SP )(x) = (SP )T (SP (x)) (P SP )(x) =P (SP (x)).124fiA Comparison Machine Transliteration ModelsST(SP)TSPPSS:: Source graphemesPP:: Source PhonemesTT:: Target graphemesPTG : STP : PT SPC : ( SP )T SPH : Pr( P )+ (1 ) Pr( G )Figure 1: Graphical representation component function four transliterationmodels: set source graphemes (e.g., letters English alphabet), Pset source phonemes defined ARPAbet, set target graphemes.Feature typefSfS,StypefStypefPfP,P typefP typefTDescription possible valuesSource graphemes S:26 letters English alphabetSource grapheme types:Consonant (C) Vowel (V)Source phonemes P(/AA/, /AE/, on)Source phoneme types: Consonant (C), Vowel (V),Semi-vowel (SV), silence (//)Target graphemesTable 1: Feature types used transliteration models: fS,Stype indicates fS fStype ,fP,P type indicates fP fP type .transliteration model produce relevant output input.performance transliteration model therefore depends strongly componentfunctions. words, better modeling component function, betterperformance machine transliteration system.modeling strongly depends feature type. Different feature types used(SP )T , P , ST functions, shown Table 2. three componentfunctions thus different strengths weaknesses machine transliteration.ST function good producing grapheme-based transliterations poor producing125fiOh, Choi, & IsaharaNotationSP(SP )TPSTFeature types usedfS,Stype , fPfS,Stype , fP,P type , fTfP,P type , fTfS,Stype , fTInputsi , c(si )si , pi , c(si ), c(pi )pi , c(pi )si , c(si )OutputpitititiTable 2: Definition component function: si , c(si ), pi , c(pi ), ti respectively represent ith source grapheme, context si (sin , , si1 si+1 , , si+n ),ith source phoneme, context pi (pin , , pi1 pi+1 , , pi+n ),ith target grapheme.phoneme-based ones. contrast, P function good producing phoneme-basedtransliterations poor producing grapheme-based ones. amylase standardKorean transliteration, a-mil-la-a-je, grapheme-based transliteration, ST tendsproduce correct transliteration; P tends produce wrong ones like ae-meol-le-iseu, derived /AE AH L EY S/, pronunciation amylase. contrast,P produce de-i-teo, standard Korean transliteration dataphoneme-based transliteration, ST tends give wrong one, like da-ta.(SP )T function combines advantages ST P utilizing correspondence source grapheme source phoneme. correspondence enables (SP )T produce grapheme-based phoneme-based transliterations. Furthermore, correspondence provides important clues use resolving transliterationambiguities7 . example, source phoneme /AH/ produces much ambiguity machine transliteration mapped almost every vowel sourcetarget languages (the underlined graphemes following example corresponds /AH/:holocaust English, hol-lo-ko-seu-teu Korean counterpart, ho-ro-ko-o-su-toJapanese counterpart). know correspondence source graphemesource phoneme, easily infer correct transliteration /AH/correct target grapheme corresponding /AH/ usually depends source graphemecorresponding /AH/. Moreover, various Korean transliterations sourcegrapheme a: a, ae, ei, i, o. case, English phonemes correspondingEnglish grapheme help component function resolve transliteration ambiguities, shown Table 3. Table 3, underlined example words shownlast column pronounced English phoneme second column. lookingEnglish grapheme corresponding English phoneme, find correct Koreantransliterations easily.Though (SP )T effective ST P many cases, (SP )T sometimes works poorly standard transliteration strongly biased either graphemebased phoneme-based transliteration. cases, either source grapheme sourcephoneme contribute correct transliteration, making difficult (SP )Tproduce correct transliteration. ST , P , (SP )T core parts7. Though contextual information also used reduce ambiguities, limit discussionfeature type.126fiA Comparison Machine Transliteration ModelsKorean GraphemeaeeiEnglish Phoneme/AA//AE//EY//IH//AO/Example usageadagio, safari, vivaceadvantage, alabaster, travertinechamber, champagne, chaosadvantage, average, silageallspice, ball, chalkTable 3: Examples Korean graphemes derived English grapheme corresponding English phonemes: underlines example words indicateEnglish grapheme corresponding English phonemes second column.G , P , C , respectively, advantages disadvantages three componentfunctions correspond transliteration models used.Transliteration usually depends context. example, English graphemetransliterated Korean graphemes basis context, like ei context-ation context art. context information used, determiningcontext window size important. context window narrow degradetransliteration performance lack context information. example,English grapheme -tion transliterated Korean, one right English graphemeinsufficient context three right contexts, -ion, necessary get correctKorean grapheme, s. context window wide also degrade transliterationperformance reduces power resolve transliteration ambiguities. Manyprevious studies determined appropriate context window size 3.paper, use window size 3, previous work (Kang & Choi, 2000; Goto et al.,2003). effect context window size transliteration performance discussedSection 4.Table 4 shows identify relevant output component function usingcontext information. L3-L1, C0, R1-R3 represent left context, current context(i.e., transliterated), right context, respectively. SP function producesrelevant source phoneme source grapheme. SW = s1 s2 . . . snEnglish word, SW pronunciation represented sequence source phonemesproduced SP ; is, PSW = p1 p2 . . . pn , pi = SP (si , c(si )). SP transformssource graphemes phonemes two ways. first one search pronunciationdictionary containing English words pronunciation (CMU, 1997). second oneestimate pronunciation (or automatic grapheme-to-phoneme conversion) (Andersen, Kuhn, Lazarides, Dalsgaard, Haas, & Noth, 1996; Daelemans & van den Bosch, 1996;Pagel, Lenzo, & Black, 1998; Damper, Marchand, Adamson, & Gustafson, 1999; Chen,2003). English word registered pronunciation dictionary, must estimate pronunciation. produced pronunciation used P P (SP )TC . training automatic grapheme-to-phoneme conversion SP , use CMUPronouncing Dictionary (CMU, 1997).ST , P , (SP )T functions produce target graphemes using input. LikeSP , three functions use previous outputs, represented fT .127fiOh, Choi, & IsaharaSPSTP(SP )TypefSfStypefPfSfStypefTfPfP typefTfSfPfStypefP typefTL3$$$$$$$$$$$$$$L2$$$$$$$$$$$$$$L1$$$$$$$$$$$$$$C0bCR1VR2VR3rCOutput/B/VrCb/////R/Cb//V//r/R/CCbbC/B/Cb/B/CCV/AO/V/AO/VVTable 4: Framework component function: $ represents start words meansunused contexts component function.shown Table 4, ST , P , (SP )T produce target grapheme b source graphemeb source phoneme /B/ board /B AO R D/. b /B/first source grapheme board first source phoneme /B AO R D/, respectively,left context $, represents start words. Source graphemes (o, a, r )type (V: vowel, V: vowel, C: consonant) right context ST(SP )T . Source phonemes (/AO/, //, /R/) type (V: vowel, //: silence,V: vowel) right context P (SP )T . Depending feature typeused component function described Table 2, ST , P , (SP )T producesequence target graphemes, TSW = t1 t2 . . . tn , SW = s1 s2 . . . snPSW = p1 p2 . . . pn . board, SW , PSW , TSW represented follows.// represents silence (null source phonemes), represents null target graphemes.SW = s1 s2 s3 s4 s5 = b rPSW = p1 p2 p3 p4 p5 = /B/ /AO/ / / /R/ /D/TSW = t1 t2 t3 t4 t5 = b deu3.3 Machine Learning Algorithms Component Functionsection describe way model component functions using three machine learning algorithms (the maximum entropy model, decision-tree learning, memory-basedlearning)8 . four component functions share similar framework, limitfocus (SP )T section.8. three algorithms typically applied automatic grapheme-to-phoneme conversion (Andersenet al., 1996; Daelemans & van den Bosch, 1996; Pagel et al., 1998; Damper et al., 1999; Chen, 2003).128fiA Comparison Machine Transliteration Models3.3.1 Maximum entropy modelmaximum entropy model (MEM) widely used probability model incorporate heterogeneous information effectively (Berger, Pietra, & Pietra, 1996).MEM, event (ev) usually composed target event (te) history event (he);say ev =< te, >. Event ev represented bundle feature functions, f ei (ev),represent existence certain characteristics event ev. feature functionbinary-valued function. activated (f ei (ev) = 1) meets activating condition; otherwise deactivated (f ei (ev) = 0) (Berger et al., 1996). Let source languageword SW composed n graphemes. SW, PSW , TSW representedSW = s1 , , sn , PSW = p1 , , pn , TSW = t1 , , tn , respectively. PSW TSWrepresent pronunciation target language word corresponding SW, pi tirepresent source phoneme target grapheme corresponding si . Function (SP )Tbased maximum entropy model representedP r(TSW |SW, PSW ) = P r(t1 , , tn |s1 , , sn , p1 , , pn )(1)assumption (SP )T depends context information window size k,simplify Formula (1)P r(TSW |SW, PSW )P r(ti |tik , , ti1 , pik , , pi+k , sik , , si+k )(2)t1 , , tn , s1 , , sn , p1 , , pn represented fT , fS,Stype , fP,P type ,respectively, rewrite Formula (2)P r(TSW |SW, PSW )P r(ti |fT(ik,i1) , fP,P type(ik,i+k) , fS,Stype(ik,i+k) )(3)index current source grapheme source phoneme transliteratedfX(l,m) represents features feature type fX located position l position m.important factor designing model based maximum entropy modelidentify feature functions effectively support certain decisions model.basic philosophy feature function design component function contextinformation collocated unit interest important. thus designed featurefunction collocated features feature type different feature types.Features used (SP )T listed below. features used activating conditionshistory events feature functions.Feature type features used designing feature functions (SP )T (k = 3)possible features fS,Stypeik,i+k , fP,P typeik,i+k , fTik,i1 (e.g., fSi1 ,fPi1 , fTi1 )possible feature combinations features feature type (e.g.,{fSi2 , fSi1 , fSi+1 }, {fPi2 , fPi , fPi+2 }, {fTi2 , fTi1 })possible feature combinations features different feature types (e.g.,{fSi1 , fPi1 }, {fSi1 , fTi2 } , {fP typei2 , fPi3 , fTi2 })fS,Stypeik,i+k fP,P typeik,i+k129fiOh, Choi, & Isaharaf ejtetif e1f e2f e3f e4f e5bbbbbfT(ik,i1)fS,Stype(ik,i+k)fTi1 = $fTi2 = $fSi+1fP,P type(ik,i+k)fSi = bfSi1 = $= fStypei+2 = VfSi+3 = rfPi = /B/fPi = /B/fPi+1 = /AO/fP typei = CTable 5: Feature functions (SP )T derived Table 4.fS,Stypeik,i+k fTik,i1fP,P typeik,i+k fTik,i1Generally, conditional maximum entropy model gives conditional probabilityP r(y|x) represented Formula (4) (Berger et al., 1996).P r(y|x) =Z(x) =X1exp( f ei (x, y))Z(x)Xexp(X(4)f ei (x, y))(SP )T , target event (te) target graphemes assigned, history event(he) represented tuple < fT(ik,i1) , fS,Stype(ik,i+k) , fP,P type(ik,i+k) >. Therefore,rewrite Formula (3)P r(ti |fT(ik,i1) , fS,Stype(ik,i+k) , fP,P type(ik,i+k) )X1exp( f ei (he, te))= P r(te|he) =Z(he)(5)Table 5 shows example feature functions (SP )T ; Table 4 used derivefunctions. example, f e1 represents event (history event) fSi bfPi /B/ te (target event) fTi b. model component function basedMEM, Zhangs maximum entropy modeling tool used (Zhang, 2004).3.3.2 Decision-tree learningDecision-tree learning (DTL) one widely used well-known methodsinductive inference (Quinlan, 1986; Mitchell, 1997). ID3, greedy algorithmconstructs decision trees top-down manner, uses information gain,measure well given feature (or attribute) separates training examples basistarget class (Quinlan, 1993; Manning & Schutze, 1999). use C4.5 (Quinlan, 1993),well-known tool DTL implementation Quinlans ID3 algorithm.training data component function represented features located L3L1, C0, R1-R3, shown Table 4. C4.5 tries construct decision tree lookingregularities training data (Mitchell, 1997). Figure 2 shows part decision130fiA Comparison Machine Transliteration Modelstree constructed (SP )T English-to-Korean transliteration. set target classesdecision tree (SP )T set target graphemes. rectangles indicateleaf nodes, represent target classes, circles indicate decision nodes.simplify examples, use fS fP . Note feature typescomponent function, described Table 4, actually used construct decision trees.Intuitively, effective feature among L3-L1, C0, R1-R3 (SP )T maylocated C0 correct outputs (SP )T strongly depend source graphemesource phoneme C0 position. expected, effective featuredecision tree located C0 position, is, C0(fP ). (Note first featuretested decision trees effective feature.) Figure 2, decision treeproduces target grapheme (Korean grapheme) instance x(SP ) retrievingdecision nodes C0(fP ) = /AO/ R1(fP ) = / / represented .C0(fC0(fPP): /AO/ (*)C0(fSS): eC0(fSS):C0(fC0(fSS): o(*)x(SPT)C0(fSS): otherseuR1(fPP): /R/L2(fSS): $C0(fSS):L2(fSS):R1(fR1(fPP): /~/(*)R1(fPP): others(*)(*)L2(fSS): rFeature type L3 L2fS$$fP$$L1C0R1R2R3br(SP)T/B/ /AO/ /~/ /R/ /D/Figure 2: Decision tree (SP )T .3.3.3 Memory-based learningMemory-based learning (MBL), also called instance-based learning case-based learning, example-based learning method. based k-nearest neighborhood algorithm (Aha, Kibler, & Albert, 1991; Aha, 1997; Cover & Hart, 1967; Devijver & Kittler.,1982). MBL represents training data vector and, training phase, placestraining data examples memory clusters examples basis knearest neighborhood principle. Training data MBL represented formtraining data decision tree. Note target classes (SP )T , MBLoutputs, target graphemes. Feature weighting deal features differing importance also done training phase9 . produces output using similarity-based9. TiMBL (Daelemans, Zavrel, Sloot, & Bosch, 2004) supports gain ratio weighting, information gainweighting, chi-squared (2 ) weighting, shared variance weighting features.131fiOh, Choi, & Isaharareasoning test data examples memory. test data xset examples memory , similarity x estimated usingdistance function (x, )10 . MBL selects example yi cluster examplessimilar x assigns examples target class xs target class. useMBL tool called TiMBL (Tilburg memory-based learner) version 5.0 (Daelemans et al.,2004).4. Experimentstested four machine transliteration models English-to-Korean English-toJapanese transliteration. test set former (EKSet) (Nam, 1997) consisted7,172 English-Korean pairs number training items 6,000blind test items 1,000. EKSet contained transliteration variations, meaningone transliteration English word. test set latter (EJSet)contained English-katakana pairs EDICT (Breen, 2003) consisted 10,417 pairsnumber training items 9,000 blind test items1,000. EJSet contained transliteration variations, like <micro, ma-i-ku-ro>, <micro,mi-ku-ro>; average number Japanese transliterations English word 1.15.EKSet EJSet covered proper names, technical terms, general terms. usedCMU Pronouncing Dictionary (CMU, 1997) training pronunciation estimation (orautomatic grapheme-to-phoneme conversion) SP . training automatic graphemeto-phoneme conversion done ignoring lexical stress vowels dictionary (CMU,1997). evaluation done terms word accuracy (W A), evaluation measureused previous work (Kang & Choi, 2000; Kang & Kim, 2000; Goto et al., 2003; Bilac &Tanaka, 2004). Here, W represented Formula (6). generated transliterationEnglish word judged correct exactly matched transliterationword test data.WA =number correct transliterations output systemnumber transliterations blind test data(6)evaluation, used k-fold cross-validation (k=7 EKSet k=10 EJSet).test set divided k subsets. used turn testing remainderused training. average W computed across k trials used evaluationresults presented section.conducted six tests.Hybrid Model Test: Evaluation hybrid transliteration model changing value(the parameter hybrid transliteration model)Comparison Test I: Comparison among four machine transliteration modelsComparison Test II: Comparison four machine transliteration models previouslyproposed transliteration methods10. Modified value difference metric, overlap metric, Jeffrey divergence metric, dot product metric, etc.used distance function (Daelemans et al., 2004).132fiA Comparison Machine Transliteration ModelsDictionary Test: Evaluation transliteration models words registeredregistered pronunciation dictionary determine effect pronunciation dictionarymodelContext Window-Size Test: Evaluation transliteration models various sizescontext windowTraining Data-Size Test: Evaluation transliteration models various sizes training data sets4.1 Hybrid Model Testobjective test estimate dependence performance Hparameter . evaluated performance changing 0 1 intervals0.1 (i.e., =0, 0.1, 0.2, , 0.9, 1.0). Note hybrid model representedP r(P ) + (1 ) P r(G ). Therefore, H G = 0 P = 1.shown Table 6, performance H depended G P . example,performance G exceeded P EKSet. Therefore, H tended performbetter 0.5 > 0.5 EKSet. best performance attained= 0.4 EKSet = 0.5 EJSet. Hereinafter, use = 0.4EKSet = 0.5 EJSet linear interpolation parameter H .00.10.20.30.40.50.60.70.80.91.0EKSet58.8%61.2%62.0%63.0%64.1%63.4%61.1%59.6%58.2%57.0%55.2%EJSet58.8%60.9%62.6%64.1%65.4%65.8%65.0%63.4%62.1%61.2%59.2%Table 6: Results Hybrid Model Test.4.2 Comparison Testobjectives first comparison test compare performance among fourtransliteration models (G , P , H , C ) compare performance modelcombined performance three models (G+P +C ). Table 7 summarizesperformance model English-to-Korean English-to-Japanese transliteration,133fiOh, Choi, & IsaharaDTL, MBL11 MEM represent decision-tree learning, memory-based learning,maximum entropy model.unit transliterated restricted either source grapheme sourcephoneme G P ; dynamically selected basis contexts HC . means G P could produce incorrect result either sourcephoneme source grapheme, which, respectively, consider, holds keyproducing correct transliteration result. reason, H C performed betterG P .Transliteration ModelGPHCG+P +CDTL53.1%50.8%N/A59.5%72.0%EKSetMBL54.6%50.6%N/A60.3%71.4%MEM58.8%55.2%64.1%65.5%75.2%DTL55.6%55.8%N/A64.0%73.4%EJSetMBL58.9%56.1%N/A65.8%74.2%MEM58.8%59.2%65.8%69.1%76.6%Table 7: Results Comparison Test I.table, G+P +C means combined results three transliteration models,G , P , C . exclude H combining implementedMEM (the performance combining four transliteration models discussedSection 5). evaluating G+P +C , judged transliteration results correctleast one correct transliteration among results produced threemodels. Though C showed best results among three transliteration models dueability use correspondence source grapheme source phoneme,source grapheme source phoneme create noise correct transliterationproduced one. words, correct transliteration stronglybiased either grapheme-based phoneme-based transliteration, G P maysuitable producing correct transliteration.Table 8 shows example transliterations produced transliteration model.G produced correct transliterations cyclase bacteroid, Pgeoid silo. C produced correct transliterations saxhorn bacteroid, Hproduced correct transliterations geoid bacteroid. shown results,transliterations one transliteration model produce correctly. example,G , P , C produced correct transliterations cyclase, silo, saxhorn,respectively. Therefore, three transliteration models used complementarymanner improve transliteration performance least one usually producecorrect transliteration. combination increased performance compared G ,P , C (on average, 30.1% EKSet 24.6% EJSet). short, G , P , Ccomplementary transliteration models together produce correct transliterations,11. tested possible combinations (x, ) weighting scheme supportedTiMBL (Daelemans et al., 2004) detect significant differences performancevarious combinations. Therefore, used default setting TiMBL (Overlap metric (x, )gain ratio weighting feature weighting).134fiA Comparison Machine Transliteration Modelscombining different transliteration models improve transliteration performance.transliteration results produced G+P +C analyzed detail Section 5.cyclasebacteroidgeoidsilosaxhorncyclasebacteroidgeoidsilosaxhornGsi-keul-la-a-jebak-te-lo-i-deuje-o-i-deusil-losaek-seonHsa-i-keul-la-a-jebak-te-lo-i-deuji-o-i-deusil-losaek-seonPsa-i-keul-la-a-jebak-teo-o-i-deuji-o-i-deusa-il-losaek-seu-ho-leunCsa-i-keul-la-a-jebak-te-lo-i-deuge-o-i-deusil-losaek-seu-honTable 8: Example transliterations produced transliteration model ( indicatesincorrect transliteration).subsequent testing, used maximum entropy model machine learningalgorithm two reasons. First, produced best results three algorithmstested12 . Second, support H .4.3 Comparison Test IItest, compared four previously proposed machine transliteration methods (Kang& Choi, 2000; Kang & Kim, 2000; Goto et al., 2003; Bilac & Tanaka, 2004) fourtransliteration models (G , P , H , C ), based MEM. Table 9 showsresults. trained tested previous methods data sets usedfour transliteration models. Table 10 shows key features methods modelsviewpoint information type usage. Information type indicates typeinformation considered: source grapheme, source phoneme, correspondencetwo. example, first three methods use source grapheme. Informationusage indicates context used whether previous output used.obvious table information types transliteration modelconsiders, better performance. Either source phoneme correspondenceconsidered methods Kang Choi (2000), Kang Kim (2000),Goto et al. (2003) key higher performance method BilacTanaka (2004) H C .viewpoint information usage, models methods considerprevious output tended achieve better performance. example, method Goto etal. (2003) better results Kang Choi (2000). machine translit12. one-tail paired t-test showed results MEM always significantly better (exceptG EJSet) DTL MBL (level significance = 0.001).135fiOh, Choi, & IsaharaMethod/ModelKang Choi (2000)Kang Kim (2000)Previous methodsGoto et al. (2003)Bilac Tanaka (2004)GPMEM-based modelsHCEKSet51.4%55.1%55.9%58.3%58.8%55.2%64.1%65.5%EJSet50.3%53.2%56.2%62.5%58.8%59.2%65.8%69.1%Table 9: Results Comparison Test II.Method/ModelKang Choi (2000)Kang Kim (2000)Goto et al. (2003)Bilac Tanaka (2004)GPHCInfo. typeP C++++ ++++ ++ + +Info. usageContext< 3 +3 >Unbounded< 3 +3 >Unbounded< 3 +3 >< 3 +3 >< 3 +3 >< 3 +3 >PO++++++Table 10: Information type usage previous methods four transliteration models, S, P, C, PO respectively represent source grapheme, sourcephoneme, correspondence P, previous output.eration sensitive context, reasonable context size usually enhances transliterationability. Note size context window previous methods limited 3context window wider 3 degrades performance (Kang & Choi, 2000)significantly improve (Kang & Kim, 2000). Experimental results related contextwindow size given Section 4.5.Overall, H C better performance previous methods (on average,17.04% better EKSet 21.78% better EJSet), G (on average, 9.6% betterEKSet 14.4% better EJSet), P (on average, 16.7% better EKSet19.0% better EJSet). short, good machine transliteration model 1) considereither correspondence source grapheme source phonemesource grapheme source phoneme, 2) reasonable context size, 3)consider previous output. H C satisfy three conditions.136fiA Comparison Machine Transliteration Models4.4 Dictionary TestTable 11 shows performance transliteration model dictionary test.test, evaluated four transliteration models according way pronunciation generation(or grapheme-to-phoneme conversion). Registered represents performance wordsregistered pronunciation dictionary, Unregistered represents unregisteredwords. average, number Registered words EKSet 600,EJSet 700 k-fold cross-validation test data. words, Registered wordsaccounted 60% test data EKSet 70% test dataEJSet. correct pronunciation always acquired pronunciation dictionaryRegistered words, pronunciation must estimated Unregistered wordsautomatic grapheme-to-phoneme conversion. However, automatic graphemeto-phoneme conversion always produce correct pronunciations estimated ratecorrect pronunciations 70% accuracy.GPHCEKSetRegistered Unregistered60.91%55.74%66.70%38.45%70.34%53.31%73.32%54.12%80.78%68.41%EJSetRegistered Unregistered61.18%50.24%64.35%40.78%70.20%50.02%74.04%51.39%81.17%62.31%Table 11: Results Dictionary Test: means G+P +H+C .Analysis results showed four transliteration models fall three categories. Since G free need correct pronunciation, is, usesource phoneme, performance affected pronunciation correctness. Therefore,G regarded baseline performance Registered Unregistered.P (P SP ), H ( P r(P )+(1 ) P r(G )), C ((SP )T SP ) dependsource phoneme, performance tends affected performance SP .Therefore, P , H , C show notable differences performance RegisteredUnregistered. However, performance gap differs strength dependence. P falls second category: performance strongly depends correctpronunciation. P tends perform well Registered poorly Unregistered. HC weakly depend correct pronunciation. Unlike P , make usesource grapheme source phoneme. Therefore, perform reasonably wellwithout correct pronunciation using source grapheme weakens negativeeffect incorrect pronunciation machine transliteration.Comparing C P , find two interesting things. First, P sensitiveerrors SP Unregistered. Second, C showed better results RegisteredUnregistered. P C share function, SP , key factor accountingperformance gap component functions, P (SP )T .results shown Table 11, infer (SP )T (in C ) performed betterP (in P ) Registered Unregistered. (SP )T , source grapheme corre137fiOh, Choi, & Isaharasponding source phonemes, P consider, made two contributionshigher performance (SP )T . First, source grapheme correspondencemade possible produce accurate transliterations. (SP )T considerscorrespondence, (SP )T powerful transliteration ability P , usessource phonemes, correspondence needed produce correct transliterations. main reason (SP )T performed better P Registered. Second,source graphemes correspondence compensated errors produced SP producing target graphemes. main reason (SP )T performed better PUnregistered. comparison C G , performances similar Unregistered. indicates transliteration power C similar G , eventhough pronunciation source language word may correct. Furthermore,performance C significantly higher G Registered. indicatestransliteration power C greater G correct pronunciationgiven.behavior H similar C . Unregistered, P r(G ) H madepossible H avoid errors caused P r(P ). Therefore, worked better P .Registered, P r(P ) enabled H perform better G .results test showed H C perform better G Pcomplementing G P (and thus overcoming disadvantage) considering eithercorrespondence source grapheme source phonemesource grapheme source phoneme.4.5 Context Window-Size Testtesting effect context window size, varied size 1 5.Regardless size, H C always performed better G P .size 4 5, model difficulty identifying regularities training data.Thus, consistent drops performance models size increased3 4 5. Although best performance obtained size 3, shownTable 12, differences performance significant range 2-4. However,significant difference size 1 size 2. indicateslack contextual information easily lead incorrect transliteration. example,produce correct target language grapheme -tion, need right threegraphemes (or least right two) t, -ion (or -io). results testing indicatecontext size 1 avoid degraded performance.4.6 Training Data-Size TestTable 13 shows results Training Data-Size Test using MEM-based machinetransliteration models. evaluated performance four modelsvarying size training data 20% 100%. Obviously, training dataused, higher system performance. However, objective test determine whether transliteration models perform reasonably well even small amounttraining data. found G sensitive four models amounttraining data; largest difference performance 20% 100%.contrast, showed smallest performance gap. results test shows138fiA Comparison Machine Transliteration ModelsContext Size12345G44.9%57.3%58.8%56.1%53.7%Context Size12345G46.4%58.2%58.8%56.4%53.9%EKSetP44.9%52.8%55.2%54.6%52.6%EJSetP52.1%59.5%59.2%58.5%56.4%H51.8%61.7%64.1%61.8%60.4%C52.4%64.4%65.5%64.3%62.5%65.8%74.4%75.8%74.4%73.9%H58.0%65.6%65.8%64.4%62.9%C62.0%68.7%69.1%68.2%66.3%70.4%76.3%77.0%76.0%75.5%Table 12: Results Context Window-Size Test: means G+P +H+C .combining different transliteration models helpful producing correct transliterationseven little training data.Training Data Size20%40%60%80%100%Training Data Size20%40%60%80%100%EKSetGP46.6% 47.3%52.6% 51.5%55.2% 53.0%58.9% 54.0%58.8% 55.2%EJSetGP47.6% 51.2%52.4% 55.1%55.2% 57.3%57.9% 58.8%58.8% 59.2%H53.4%58.7%61.5%62.6%64.1%C57.0%62.1%63.3%64.6%65.5%67.5%71.6%73.0%74.7%75.8%H56.4%60.7%62.9%65.4%65.8%C60.4%64.8%66.6%68.0%69.1%69.6%72.6%74.7%76.7%77.0%Table 13: Results Training Data-Size Test: means G+P +H+C .5. DiscussionFigures 3 4 show distribution correct transliterations producedtransliteration model combination models, based MEM. G ,139fiOh, Choi, & IsaharaP , H , C figures represent set correct transliterations producedmodel k-fold validation. example, |G | = 4,220 EKSet |G | = 6,121EJSet mean G produced 4,220 correct transliterations 7,172 English wordsEKSet (|KT G| Figure 3) 6,121 correct ones 10,417 English words EJSet(|JT G| Figure 4). important factor modeling transliteration model reflectdynamic transliteration behaviors, means transliteration process dynamicallyuses source grapheme source phoneme produce transliterations. Duedynamic behaviors, transliteration grapheme-based transliteration, phoneme-basedtransliteration, combination two. forms transliterations classifiedbasis information upon transliteration process mainly relies (eithersource grapheme source phoneme combination two). Therefore,effective transliteration system able produce various types transliterationstime. One way accommodate different dynamic transliteration behaviorscombine different transliteration models, handle different behavior.Synergy achieved combining models one model produce correcttransliteration others cannot. Naturally, models tend producetransliteration, less synergy realized combining them. Figures 3 4 showsynergy gained combining transliteration models terms size intersectionunion transliteration models.G407P82680 3,051344207624C|KTG-(G P C )|=1,777(a) G +P +CG1887899 3,126119HP305374P267 129713 3,423457311H|KTG-(G P H )|=2,002(b) G +P +H252C|KTG-(H P C )|=1,879(c) P +H +CG393H340 36946 3,685763451C|KTG-(G H C )|=1,859(d) G +H +CFigure 3: Distributions correct transliterations produced models English-toKorean transliteration. KTG represents Korean Transliterations Goldstandard. Note |G P H C | = 5,439, |G P H C | =3,047, |KT G| = 7,172.figures show that, area intersection different transliteration modelsbecomes smaller, size union tends become bigger. main characteristicsobtained figures summarized Table 14. first thing note|G P | clearly smaller intersection. main reasonG P use common information (G uses source graphemes P uses sourcephonemes). However, others use least one source grapheme source phoneme(source graphemes information common G , H , C source phonemesinformation common P , H , C ). Therefore, infer synergyderived combining G P greater derived combinations.140fiA Comparison Machine Transliteration ModelsG379P141805 4,796628261963CG378HP12806 4,925202222308P267 135786 5,574916647H185CG207H313 176183 5,418649942C|JTG-(G P C )|=2,444|JTG-(G P H )|=2,870|JTG-(H P C )|=2,601|JTG-(G H C )|=2,529(a) G +P +C(b) G +P +H(c) P +H +C(d) G +H +CFigure 4: Distributions correct transliterations produced models English-toJapanese transliteration. JTG represents Japanese Transliterations Goldstandard. Note |G P H C |=8,021, |G P H C |=4,786,|JT G| = 10,417.|G ||P ||H ||C ||G P ||G C ||G H ||C H ||P C ||P H ||G P ||G C ||G H ||C H ||P C ||P H |EKSet4,2023,9474,5834,6803,1333,7314,0254,1363,6753,5835,0515,1884,7965,1644,9884,982EJSet6,1186,1586,8467,1894,9375,6015,7316,3605,7595,8417,3457,7127,2397,6817,5947,169Table 14: Main characteristics obtained Figures 3 4.However, size union various pairs transliteration models Table 14shows |C H | |G C | bigger |G P |. main reasonmight higher transliteration power C H compared G PC H cover KTG JTG G P . second thingnote contribution transliteration model |G P H C |estimated difference |G P H C | union threetransliteration models. example, measure contribution H141fiOh, Choi, & Isaharadifference |G P H C | |G P C |. shown Figures 3(a)4(a)), H makes smallest contribution C (Figures 3(b) 4(b)) makeslargest contribution. main reason H making smallest contributiontends produce transliteration others, intersection Hothers tends large.also important rank transliterations produced transliteration systemsource language word basis relevance. transliteration systemproduce list transliterations, reflecting dynamic transliteration behavior,fail perform well unless distinguish correct wrong transliterations.Therefore, transliteration system able produce various kinds transliterations depending dynamic transliteration behaviors able rankbasis relevance. addition, application transliteration results naturallanguage applications machine translation information retrieval requirestransliterations ranked assigned relevance score.summary, 1) producing list transliterations reflecting dynamic transliteration behaviors (one way combine results different transliteration models,reflecting one dynamic transliteration behaviors) 2) ranking transliterations terms relevance necessary improve performancemachine transliteration. next section, describe way calculate relevancetransliterations produced combination four transliteration models.6. Transliteration Rankingbasic assumption transliteration ranking correct transliterationsfrequently used real-world texts incorrect ones. Web data reflecting real-worldusage transliterations thus used language resource rank transliterations.Transliterations appear frequently web documents given either higherrank higher score. goal transliteration ranking, therefore, rank correcttransliterations higher rank incorrect ones lower. transliterations producedgiven English word four transliteration models (G , P , H , C ), basedMEM, ranked using web data.transliteration ranking relies web frequency (number web documents).obtain reliable web frequencies, important consider transliteration corresponding source language word together rather transliteration alone.aim find correct transliterations corresponding source language wordrather find transliterations frequently used target language. Therefore, best approach transliteration ranking using web data find web documentstransliterations used translations source language word.bilingual phrasal search (BPS) retrieves Web Web search engine query,phrase composed transliteration source language word (e.g., {a-milla-a-je amylase}). BPS enables Web search engine find web documentscontain correct transliterations corresponding source language word. Notephrasal query represented brackets, first part transliterationsecond part corresponding source language word. Figure 5 shows Korean Japaneseweb documents retrieved using BPS amylase Korean/Japanese transliterations,142fiA Comparison Machine Transliteration ModelsRetrievedRetrievedKoreanKoreanwebwebpagespagesforforqueryquery{a-mil-la-a-jeamylase}{a-mil-la-a-je amylase}RetrievedRetrievedJapaneseJapanesewebwebpagespagesforforqueryquery{a-mi-ra-a-jeamylase}{a-mi-ra-a-je amylase}Queryamylaseamylase(amylase))amylase(amylase)[amylase]amylase][amylase]a-mil-la-a-jea-mil-la-a-jeamylaseamylaseamylase)a-mil-la-a-jeamylase)a-mil-la-a-je((amylase)amylase]a-mil-la-a-jeamylase]a-mil-la-a-je[[amylase]amylaseamylase(amylase))amylase(amylase)[amylase]amylase][amylase]a-mi-ra-a-jea-mi-ra-a-jeamylaseamylaseamylase)a-mi-ra-a-jeamylase)a-mi-ra-a-je((amylase)amylase]a-mi-ra-a-jeamylase]a-mi-ra-a-je[[amylase]Figure 5: Desirable retrieved web pages transliteration ranking.a-mil-la-a-je a-mi-ra-a-je. web documents retrieved BPS usually containtransliteration corresponding source language word translation pair, oneoften placed parentheses, shown Figure 5.dilemma arises, though, regarding quality coverage retrieved web documents. Though BPS generally provides high-quality web documents contain correcttransliterations corresponding source language word, coverage relatively low,meaning may find web documents transliterations. example, BPS Japanese phrasal query {a-ru-ka-ro-si-su alkalosis} Koreanphrasal query {eo-min ermine} found web documents. Therefore, alternative searchmethods necessary BPS fails find relevant web documents. bilingualkeyword search (BKS) (Qu & Grefenstette, 2004; Huang, Zhang, & Vogel, 2005; Zhang,Huang, & Vogel, 2005) used BPS fails, monolingual keyword search(MKS) (Grefenstette, Qu, & Evans, 2004) used BPS BKS fail.Like BPS, BKS makes use two keywords, transliteration source languageword, search engine query. Whereas BPS retrieves web documents containingtwo keywords phrase, BKS retrieves web documents containing anywheredocument. means web frequencies noisy transliterations sometimeshigher correct transliterations BKS, especially noisy transliterations one-syllable transliterations. example, mok, Korean transliterationproduced mook one-syllable noisy transliteration, higher web frequencymu-keu, correct transliteration mook, mok common Korean143fiOh, Choi, & Isaharanoun frequently appears Korean texts meaning neck. However, BKSimprove coverage without great loss quality retrieved web documentstransliterations composed two syllables.Though BKS higher coverage BPS, fail retrieve web documentscases. cases, MKS (Grefenstette et al., 2004) used. MKS,transliteration alone used search engine query. BPS BKS act liketranslation model, MKS acts like language model. Though MKS cannot giveinformation whether transliteration correct, provide informationwhether transliteration likely target language word. three search methodsused sequentially (BPS, BKS, MKS). one method fails retrieve relevant webdocuments, next one used. Table 15 summarizes conditions applyingsearch method.Along three search strategies, three different search engines used obtainweb documents. search engines used purpose satisfy two conditions: 1) support Korean/Japanese web document retrieval 2) support phrasalkeyword searches. Google13 , Yahoo14 , MSN15 satisfy conditions, usedsearch engines.Search methodBPSBKSMKSConditionP PW FBP Sj (e, ck )) 6= 0Pj Pck CW FBP Sj (e, ck )) = 0P j P ck CWFBKSj (e, ck )) 6= 0Pj Pck CW FBP Sj (e, ck ) = 0P j P ck CWFBKSj (e, ck ) = 0P j P ck Cjck CW FM KSj (e, ck ) 6= 0Table 15: Conditions search method applied.RF (e, ci ) =XN W Fj (e, ci ) =jXjPW Fj (e, ci )ck C W Fj (e, ck )(7)Web frequencies acquired three search methods three search engines used rank transliterations basis Formula (7), ci ithtransliteration produced four transliteration models, e source language wordci , RF function ranking transliterations, W F function calculating webfrequency, N W F function normalizing web frequency, C set produced transliterations, j index j th search engine. used normalized web frequencyranking factor. normalized web frequency web frequency dividedtotal web frequency produced transliterations corresponding one source languageword. score transliteration calculated summing normalized13. http://www.google.com14. http://www.yahoo.com15. http://www.msn.com144fiA Comparison Machine Transliteration Modelsweb frequencies transliteration given three search engines. Table 16 showsexample ranking English word data possible Korean transliterations, de-iteo, de-i-ta, de-ta, web frequencies obtained using BPS. normalizedW FBP (N W FBP ) search engine calculated follows.N W FBP (data, de-i-teo) = 94,100 / (94,100 + 67,800 + 54) = 0.5811N W FBP (data, de-i-ta) = 67,800 / (94,100 + 67,800 + 54) = 0.4186N W FBP (data, de-ta) = 54 / (94,100 + 67,800 + 54) = 0.0003ranking score de-i-teo calculated summing N W FBP (data, de-iteo) search engine:RFBP (data, de-i-teo) = 0.5810 + 0.7957 + 0.3080 = 1.6848Search EngineBCRFc1 = de-i-teoWFNWF94,100 0.5811101,834 0.79571,3580.30801.6848e=datac2 = de-i-taWFNWF67,800 0.418626,132 0.20423,028 0.68681.3096c3 = de-taWF NWF540.0003110.0001230.00520.0056Table 16: Example transliteration ranking data transliterations; W F , N W F ,RF represent W FBP , N W FBP , RFBP , respectively.6.1 Evaluationtested performance transliteration ranking two conditions: 1)test data (ALL) 2) test data least one transliteration model producedcorrect transliteration (CTC). Testing showed overall performancemachine transliteration testing CTC showed performance transliteration ranking alone. used performance individual transliteration models(G , P , H , C ) baseline. results shown Table 17. Top-n meanscorrect transliteration within Top-n ranked transliterations. averagenumber produced Korean transliterations 3.87 Japanese ones 4.50;note P C produced one transliteration pronunciationvariations. results English-to-Korean English-to-Japanese transliterationindicate ranking method effectively filters noisy transliterations positionscorrect transliterations top rank; correct transliterationsTop-1. see transliteration ranking (in Top-1) significantly improved performanceindividual models EKSet EJSet16 . overall performance16. one-tail paired t-test showed performance improvement significant (level significance= 0.001.145fiOh, Choi, & Isaharatransliteration (for ALL) well ranking (for CTC) relatively good. Notably, CTC performance showed web data useful language resource rankingtransliterations.Test dataCTCGPHCTop-1Top-2Top-3Top-1Top-2Top-3EKSet58.8%55.2%64.1%65.5%71.5%75.3%75.8%94.3%99.2%100%EJSet58.8%59.2%65.8%69.1%74.8%76.9%77.0%97.2%99.9%100%Table 17: Results Transliteration ranking.6.2 Analysis Resultsdefined two error types: production errors ranking errors. production errorcorrect transliteration among produced transliterations. rankingerror correct transliteration appear Top-1 ranked transliterations.examined relationship search method transliteration ranking. Table 18 shows ranking performance search method. RTC representscorrect transliterations ranked search method. NTC represents test dataranked, is, coverage search method. ratio RTC NTC representsupper bound performance difference RTC NTC numbererrors.best performance BPS. BPS handled 5,270 7,172 casesEKSet 8,829 10,417 cases EJSet. is, best job retrievingweb documents containing transliteration pairs. Analysis ranking errors revealedmain cause errors BPS transliteration variations. variationscontribute ranking errors two ways. First, web frequencies transliterationvariations higher standard ones, variations ranked higherstandard ones, shown examples Table 19. Second, transliterationsinclude transliteration variations (i.e., correct transliterations), correctranking cannot be. case, ranking errors caused production errors.BPS, 603 cases EKSet 895 cases EJSet.NTC smaller BKS MKS BPS retrieves web documentswhenever possible. Table 18 shows production errors main reason BPS failsretrieve web documents. (When BKS MKS used, production errors occurred146fiA Comparison Machine Transliteration ModelsTop-1Top-2Top-3RTCNTCBPS83.8%86.6%86.6%4,5685,270EKSetBKSMKS55.1% 16.7%58.4% 27.0%58.2% 31.3%5962751,024878BPS86.2%88.3%88.35%7,8008,829EJSetBKS19.0%22.8%22.9%188820MKS2.7%4.2%4.3%33768Table 18: Ranking performance search method.compact Koreanpathos Koreancohen Japanesecriteria JapaneseTransliterationkom-paek-teukeom-paek-teupa-to-seupae-to-seuko-o-he-nko-o-e-nku-ra-i-te-ri-aku-ri-te-ri-aWeb Frequency1,0751,7931,61514,062231121041,050Table 19: Example ranking errors BPS used ( indicates variation).87117 cases EKSet 22118 cases EJSet). results also show BKSeffective MKS.trade-off quality coverage retrieved web documents important factor transliteration ranking. BPS provides better quality rather widercoverage, effective since provides reasonable coverage.7. Conclusiontested compared four transliteration models, grapheme-based transliterationmodel (G ), phoneme-based transliteration model (P ), hybrid transliterationmodel (H ), correspondence-based transliteration model (C ), English-toKorean English-to-Japanese transliteration. modeled framework fourtransliteration models compared within framework. Using results,examined way improve performance machine transliteration.found H C effective G P . main reasonbetter performance C uses correspondence sourcegrapheme source phoneme. use correspondence positively affectedtransliteration performance various tests.17. 596 (RTC BKS EKSet) + 275 (RTC MKS EKSet) = 87118. 188 (RTC BKS EJSet) + 33 (RTC MKS EJSet) = 221147fiOh, Choi, & Isaharademonstrated G , P , H , C used complementary transliteration models improve chances producing correct transliterations. combinationfour models produced correct transliterations English-to-Korean transliteration English-to-Japanese transliteration compared model alone. Givenresults, described way improve machine transliteration combines differenttransliteration models: 1) produce list transliterations combining transliterations produced multiple transliteration models; 2) rank transliterationsbasis relevance.Testing showed transliteration ranking based web frequency effective waycalculate relevance transliterations. web data reflects real-worldusage, used filter noisy transliterations, used targetlanguage words incorrect transliterations source language word.several directions future work. Although considered transliteration variations, test sets mainly covered standard transliterations. corporaweb pages, however, routinely find types transliterations misspelled transliterations, transliterations common phrases, etc. along standard transliterations transliteration variations. Therefore, testing using transliterationsneeded enable transliteration models compared precisely. achievemachine transliteration system capable higher performance, need sophisticated transliteration method sophisticated ranking algorithm. Though manycorrect transliterations acquired combination four transliterationmodels, still transliterations none models produce. needdevise method produce them. transliteration ranking method works well,but, depends web data, faces limitations correct transliterationappear web data. need complementary ranking method handle cases.Moreover, demonstrate effectiveness four transliteration models, needapply various natural language processing applications.Acknowledgmentsgrateful Claire Cardie anonymous reviewers providing constructiveinsightful comments earlier drafts paper.ReferencesAha, D. W. (1997). Lazy learning: Special issue editorial. Artificial Intelligence Review,11:710.Aha, D. W., Kibler, D., & Albert, M. (1991). Instance-based learning algorithms. MachineLearning, 6 (3766).Al-Onaizan, Y., & Knight, K. (2002). Translating named entities using monolingualbilingual resources. Proceedings ACL 2002, pp. 400408.Andersen, O., Kuhn, R., Lazarides, A., Dalsgaard, P., Haas, J., & Noth, E. (1996). Comparison two tree-structured approaches grapheme-to-phoneme conversion.Proceedings ICSLP 1996, pp. 18081811.148fiA Comparison Machine Transliteration ModelsBerger, A. L., Pietra, S. D., & Pietra, V. J. D. (1996). maximum entropy approachnatural language processing. Computational Linguistics, 22 (1), 3971.Bilac, S., & Tanaka, H. (2004). Improving back-transliteration combining informationsources. Proceedings IJCNLP2004, pp. 542547.Breen, J. (2003). EDICT Japanese/English dictionary .le. Electronic Dictionary Research Development Group, Monash University. http://www.csse.monash.edu.au/~jwb/edict.html.Chen, S. F. (2003). Conditional joint models grapheme-to-phoneme conversion.Proceedings Eurospeech, pp. 20332036.CMU (1997). CMU pronouncing dictionary version 0.6. http://www.speech.cs.cmu.edu/cgi-bin/cmudict.Cover, T. M., & Hart, P. E. (1967). Nearest neighbor pattern classification. InstituteElectrical Electronics Engineers Transactions Information Theory, 13 (2127).Daelemans, W., Zavrel, J., Sloot, K. V. D., & Bosch, A. V. D. (2004). TiMBL: TilburgMemory-Based Learner - version 5.1 reference guide. Tech. rep. 04-02, ILK TechnicalReport Series.Daelemans, W., & van den Bosch, A. (1996). Language-independent data-orientedgrapheme-to-phoneme conversion. J. Van Santen, R. Sproat, J. O., & Hirschberg,J. (Eds.), Progress Speech Synthesis, pp. 7790. Springer Verlag, New York.Damper, R. I., Marchand, Y., Adamson, M. J., & Gustafson, K. (1999). Evaluatingpronunciation component text-to-speech systems English: performance comparison different approaches. Computer Speech Language, 13 (2), 155176.Devijver, P. A., & Kittler., J. (1982). Pattern recognition: statistical approach. PrenticeHall.Fujii, A., & Tetsuya, I. (2001). Japanese/English cross-language information retrieval: Exploration query translation transliteration. Computers Humanities,35 (4), 389420.Goto, I., Kato, N., Uratani, N., & Ehara, T. (2003). Transliteration considering contextinformation based maximum entropy method. Proceedings MT-SummitIX, pp. 125132.Grefenstette, G., Qu, Y., & Evans, D. A. (2004). Mining web create languagemodel mapping English names phrases Japanese. ProceedingsWeb Intelligence, pp. 110116.Huang, F., Zhang, Y., & Vogel, S. (2005). Mining key phrase translations web corpora. Proceedings Human Language Technology Conference ConferenceEmpirical Methods Natural Language Processing, pp. 483490.Jeong, K. S., Myaeng, S. H., Lee, J. S., & Choi, K. S. (1999). Automatic identificationback-transliteration foreign words information retrieval. Information ProcessingManagement, 35 (1), 523540.149fiOh, Choi, & IsaharaJung, S. Y., Hong, S., & Paek, E. (2000). English Korean transliteration modelextended markov window. Proceedings 18th conference Computationallinguistics, pp. 383 389.Kang, B. J. (2001). resolution word mismatch problem caused foreign word transliterations English words Korean information retrieval. Ph.D. thesis, ComputerScience Dept., KAIST.Kang, B. J., & Choi, K. S. (2000). Automatic transliteration back-transliterationdecision tree learning. Proceedings 2nd International Conference LanguageResources Evaluation, pp. 11351411.Kang, I. H., & Kim, G. C. (2000). English-to-Korean transliteration using multiple unbounded overlapping phoneme chunks. Proceedings 18th International Conference Computational Linguistics, pp. 418424.Kim, J. J., Lee, J. S., & Choi, K. S. (1999). Pronunciation unit based automatic EnglishKorean transliteration model using neural network. Proceedings Korea CognitiveScience Association, pp. 247252.Knight, K., & Graehl, J. (1997). Machine transliteration. Proceedings 35th AnnualMeetings Association Computational Linguistics, pp. 128135.Korea Ministry Culture & Tourism (1995). English Korean standard conversion rule.http://www.hangeul.or.kr/nmf/23f.pdf.Lee, J. S. (1999). English-Korean transliteration retransliteration model Crosslingual information retrieval. Ph.D. thesis, Computer Science Dept., KAIST.Lee, J. S., & Choi, K. S. (1998). English Korean statistical transliteration informationretrieval. Computer Processing Oriental Languages, 12 (1), 1737.Li, H., Zhang, M., & Su, J. (2004). joint source-channel model machine transliteration.Proceedings ACL 2004, pp. 160167.Lin, W. H., & Chen, H. H. (2002). Backward machine transliteration learning phonetic similarity. Proceedings Sixth Conference Natural Language Learning(CoNLL), pp. 139145.Manning, C., & Schutze, H. (1999). Foundations Statistical natural language Processing.MIT Press.Meng, H., Lo, W.-K., Chen, B., & Tang, K. (2001). Generating phonetic cognateshandle named entities English-Chinese cross-language spoken document retrieval.Proceedings Automatic Speech Recognition Understanding, 2001. ASRU 01,pp. 311314.Mitchell, T. M. (1997). Machine learning. New-York: McGraw-Hill.Nam, Y. S. (1997). Foreign dictionary. Sung Dang.Oh, J. H., & Choi, K. S. (2002). English-Korean transliteration model using pronunciation contextual rules. Proceedings COLING2002, pp. 758764.Pagel, V., Lenzo, K., & Black, A. W. (1998). Letter sound rules accented lexicon compression. Proceedings International Conference Spoken Language Processing,pp. 20152018.150fiA Comparison Machine Transliteration ModelsQu, Y., & Grefenstette, G. (2004). Finding ideographic representations Japanese nameswritten Latin script via language identification corpus validation.. Proc.ACL, pp. 183190.Quinlan, J. R. (1986). Induction decision trees. Machine Learning, 1, 81106.Quinlan, J. R. (1993). C4.5: Programs Machine Learning. Morgan Kauffman.Stalls, B. G., & Knight, K. (1998). Translating names technical terms arabic text.Proceedings COLING/ACL Workshop Computational Approaches SemiticLanguages, pp. 3441.Zhang, L. (2004). Maximum entropy modeling toolkit python C++. http://homepages.inf.ed.ac.uk/s0450736/software/maxent/manual.pdf.Zhang, Y., Huang, F., & Vogel, S. (2005). Mining translations OOV terms webcross-lingual query expansion. Proceedings 28th annual internationalACM SIGIR conference Research development information retrieval, pp.669670.151fiJournal Artificial Intelligence Research 27 (2006) 381-417Submitted 3/06; published 11/06Multi-Issue Negotiation DeadlinesShaheen S. FatimaMichael WooldridgeS.S.FATIMA @ CSC . LIV. AC . UKM.J.W OOLDRIDGE @ CSC . LIV. AC . UKDepartment Computer Science,University Liverpool, Liverpool L69 3BX, U.K.Nicholas R. JenningsNRJ @ ECS . SOTON . AC . UKSchool Electronics Computer Science,University Southampton, Southampton SO17 1BJ, U.K.Abstractpaper studies bilateral multi-issue negotiation self-interested autonomous agents.Now, number different procedures used process; three mainones package deal procedure issues bundled discussed together,simultaneous procedure issues discussed simultaneously independentlyother, sequential procedure issues discussed one another. Sinceyields different outcome, key problem decide one usecircumstances. Specifically, consider question model agents timeconstraints (in form deadlines discount factors) information uncertainty (inagents know opponents utility function). model, consider issuesindependent interdependent determine equilibria caseprocedure. doing, show package deal fact optimal procedureparty. go show that, although package deal may computationally complex two procedures, generates Pareto optimal outcomes (unlike two),similar earliest latest possible times agreement simultaneous procedure (whichbetter sequential procedure), (like two procedures) generates uniqueoutcome certain conditions (which define).1. IntroductionNegotiation key form interaction multiagent systems (Maes, Guttman, & Moukas, 1999;Sandholm, 2000). process disputing agents decide divide gainscooperation. Since decision made jointly agents (Rosenschein & Zlotkin,1994; Raiffa, 1982; Pruitt, 1981; Fisher & Ury, 1981; Young, 1975; Kraus, 2001), agentobtain prepared allow them. Now, simplest form negotiationinvolves two agents single-issue. example, consider scenario buyerseller negotiate price good. begin, two agents likely differ pricebelieve trade take place, process joint decision-makingeither arrive price mutually acceptable fail reach agreement. Since agentslikely begin different prices, one must move toward other,series offers counter offers, order obtain mutually acceptable outcome. However,agents actually perform negotiations, must decide rules makingoffers counter offers. is, must set negotiation protocol (Lax & Sebenius, 1986;Osborne & Rubinstein, 1990; Rosenschein & Zlotkin, 1994; Kraus, Wilkenfeld, & Zlotkin, 1995;Lomuscio, Wooldridge, & Jennings, 2003).c2006AI Access Foundation. rights reserved.fiFATIMA , W OOLDRIDGE , & J ENNINGSbasis protocol, agent chooses strategy (i.e., offers makecourse negotiation). competitive scenarios self-interested agents, participant defines strategy maximise individual utility. Furthermore, scenarios,agents optimal strategy depends strongly information opponent (Fatima,Wooldridge, & Jennings, 2002, 2004). example, strategy buyer would use knewsellers reserve price differs one would use not. this,seen outcome single-issue negotiation depends four key factors (Harsanyi, 1977):negotiation protocol, players strategies, players preferences possible outcomes,information players other. However, bilateral negotiations,parties involved need settle one issue. example, agents may need comeagreements objects/services characterised attributes price, delivery time,quality, reliability, on. multi-issue negotiations, outcome also depends oneadditional factor: negotiation procedure (Schelling, 1956, 1960; Fershtman, 1990), specifies issues settled. Broadly speaking, three ways negotiating multipleissues (Keeney & Raiffa, 1976; Raiffa, 1982):Package deal: approach links issues discusses together bundle.Simultaneous negotiation: involves settling issues simultaneously, independently,other.Sequential negotiation: involves negotiating issues sequentially, one another.Now, three different procedures different properties yield different outcomesnegotiators (Fershtman, 2000). key question answer is: best? Here,since concerned self-interested agents, notion optimal procedure onemaximises agents individual return. However, optimality part story;given motivations also concerned Pareto optimality solutionsprocedures (because Pareto optimality ensures utility go wasted), computationalcomplexity procedures (because scenarios information uncertainty, agents needcompute equilibrium offers process negotiation, opposed complete information scenario strategies precompiled), actual time agreement (becausescenarios information uncertainty, time depends agents beliefs opponent agreement may occur first time period), uniqueness solutionsgenerate (because allows agents know actual shares).One immediate observation vein package deal gives rise possibilitymaking tradeoffs across issues. tradeoffs possible different agents value differentissues differently. example, two issues one agent values firstsecond, agent values second issue first, possible maketradeoffs thereby improve utility agents relative situation without tradeoffs.contrast, simultaneous sequential approaches, issues settled independentlyscope tradeoffs them. Moreover, seek answer questionoptimality types situation commonly faced agents real-world contexts.Thus, consider negotiations are:1. Time constraints. Agents time constraints form deadlines discountfactors. view deadlines essential element since negotiation cannot go indefinitely, rather must end within reasonable time limit (Livne, 1979). Likewise, discount382fiM ULTI -I SSUE N EGOTIATIONEADLINESfactors essential since desirability good traded often declines time.happens either good perishable due inflation. Moreover, strategicbehaviour agents deadlines discount factors differs without (see Rubinstein, 1982, single issue bargaining without deadlines Sandholm & Vulkan, 1999;& Manove, 1993; Fershtman & Seidmann, 1993; Kraus, 2001, bargaining deadlines discount factors). instance, presence deadline induces negotiatorplay strategy ensures best possible agreement deadline reached.Likewise, presence discount factor means reaching agreement todayreaching tomorrow. Hence, agents try reach agreement sooner ratherlater.2. Uncertainty opponents negotiation parameters. information agentsnegotiation opponent likely uncertain (see Fudenberg & Tirole, 1983;Fudenberg, Levine, & Tirole, 1985; Rubinstein, 1985, single issue bargaining uncertainty). Moreover, bargaining situations, one players may know somethingrelevance not. example, bargaining price secondhand car, seller knows quality, buyer not. situations saidasymmetry information players (Muthoo, 1999). hand, symmetric information situations players information. Again, agentsoperate situations analyse cases.3. Interdependence issues. issues negotiation may independent interdependent. former case, agents utility issue depends agreementreached it, issues settled. latter case, agentsutility issue depends agreement reached alsoissues settled (Bar-Yam, 1997; Klein, Faratin, Sayama, & Bar-Yam, 2003).situations common multiagent systems analyse cases.Thus study five different settings: i) complete information setting (CI), ii) settingindependent issues symmetric uncertainty agents utilities (SUI ), iii) settingindependent issues asymmetric uncertainty agents utilities (AUI ), iv) settinginterdependent issues symmetric uncertainty agents utilities (SUD ), v) settinginterdependent issues asymmetric uncertainty agents utilities (AUD ).methodology first derive equilibria proceduressettings, this, determine optimal. see, analysis showsthat, settings, package deal best. go analyse proceduresterms performance metrics. Specifically, show that, settings, packagedeal generates Pareto optimal outcome. also show although package deal may computationally complex two procedures, similar earliest latest possibletimes agreement simultaneous procedure (which better sequential procedure),(like two procedures) generates unique outcome certain situations (whichdefine). key results study summarised Table 1.previously formal comparison different procedures find optimalone (see Section 7 details). However, work least one following majorlimitations. First, focused comparing procedures negotiation without deadlines. Noteexisting work obtained equilibrium negotiation deadlines, single383fiFATIMA , W OOLDRIDGE , & J ENNINGSInformationsettingCITimeagreementtcTimecomputeequilibriumParetooptimal?Uniqueequilibrium?SUI , SUDAUI , AUDCISUI SUDAUI AUDCI,SUI ,SUD ,AUI , AUDCISUI ,SUD ,AUI , AUDPackage dealSimultaneousSequentialcth issuetc = 11 ccth issuetec = 1tlc = min(2r 1, n)1 ccth issuetc = 11 ccth issuetec = 1tlc = min(2r 1, n)1 ccth partitiontc = c1 ccth partitiontec = tsctlc = tsc + min(2r 1, n)1 cO(mn)O(mr 3 (n T2 ))O(M n)O(|Sz |z r 3 (n T2 ))O(mr3 (n2)2)O(|Sz |z r3 (n2)2)O(M n)O(|Sz |z r 3 (nO(|Sz |z r3 (nYesC1C3 C4C2C5C2C5Table 1: summary key results. tsc denotes start time cth partition, tec earliestpossible time agreement, tlc latest possible time agreement).issue case (Sandholm & Vulkan, 1999; Stahl, 1972), special type sequential proceduremultiple issues (Fatima et al., 2004). See Section 7 details. Second, focussedindependent issues asymmetric information settings. Third, focused findingoptimal procedure, considered additional solution properties different procedures.Given this, paper makes threefold contribution. First, obtain equilibriumprocedure deadlines. Second, analyse multiple issues independentinterdependent. Moreover, analyse symmetric asymmetric information settings.Finally, basis equilibrium different procedures, provide first comprehensivecomparison solution properties (viz. time complexity, Pareto optimality, uniqueness,time agreement). taken together, results clearly indicate choices tradeoffsinvolved choosing negotiation procedure wide range circumstances. knowledgeused system designer responsible designing mechanismused moderate negotiation encounters agents choosearrange interactions. Furthermore, knowledge also tells agents equilibriumoffers negotiation.remainder paper organised follows. begin giving brief overviewsingle-issue negotiation Section 2. Section 3, study three multi-issue proceduressetting complete information issues independent. study undertakenprovide foundation Sections 4, 5, 6, treat information agentsutilities uncertain. specifically, Section 4, analyse scenario symmetric uncer38422 ))) T2 )fiM ULTI -I SSUE N EGOTIATIONEADLINEStainty opponents utility. Section 5, analyse scenario asymmetric uncertaintyopponents utility. Sections 4 5 deal independent issues. Section 6,extend analysis interdependent issues. Section 7 discusses related literature Section 8concludes. Appendix provides summary notation employed throughout paper.2. Single-Issue NegotiationAssume two agents: b. agent time constraints form deadlinesdiscount factors. Since focus competitive scenarios self-interested agents, modelnegotiation using split pie game analysed Osborne Rubinstein (1994), Binmore,Osborne, Rubinstein (1992). begin introducing complete information game.Let two agents negotiating single issue (i). issue pie size 1agents want determine divide themselves. deadline (i.e., numberrounds negotiation must end). Let n N+ denote deadline. agents useRubinsteins alternating offers protocol (Osborne & Rubinstein, 1994), proceedsseries time periods. One agents, say a, starts negotiation first time period (i.e., = 1)making offer (xi ), lies interval [0, 1], b. Agent b either accept rejectoffer. accepts, negotiation ends agreement getting share xi b gettingyi = 1 xi . Otherwise, negotiation proceeds next time period, agent b makescounter-offer. process making offers continues one agents either accepts offerquits negotiation (resulting conflict). Thus, three possible actions agent taketime period: accept last offer, make new counter-offer, quit negotiation.essential feature negotiations involving alternating offers pie assumedshrink time (Rubinstein, 1982). Specifically, shrinks step offer counteroffer.shrinkage models decrease value pie (representing fact pie perishestime inflation). shrinkage represented discount factor denoted 0 <1 both1 agents. = 1, size pie 1, subsequent time periods > 1,pie shrinks it1 .denote set real numbers R set real numbers interval [0, 1] R1 .let [xti , yit ] denote offer made time period xti yit denote share agentb respectively. Then, given pie, set possible offers is:{[xti , yit ] : xti 0, yit 0, xti + yit = it1 }xti R1 yit R1 . players utility function defined set R. Let uai :R1 N+ R ubi : R1 N+ R denote utility functions two agents. time t,b receive share xti yit respectively (where xti + yit = it1 ), utilities are:xi nui (xi , t) =0 otherwiseubi (yit , t)=yit n0 otherwise1. different discount factor different agents makes presentation involved without leadingchanges analysis strategic behaviour agents time complexity finding equilibriumoffers. Hence single discount factor agents.385fiFATIMA , W OOLDRIDGE , & J ENNINGSconflict utility (i.e., utility received event deal struck) zeroagents. Note shown explicitly agents utility function implicit.because, time period t, xti yit denote bs actual shares respectively (notratios shares) xti + yit = it1 . words included agents share.become clearer show agents shares Expression 1.setting, agents reason follows order determine offer. Let agentdenote first mover (i.e., = 1, proposes b split pie). begin, considercase deadline agents n = 1. b accepts, division occurs agreed; not,neither agent gets anything (since n = 1 deadline). Here, powerful positionable propose keep 100 percent pie give nothing b 2 . Since deadline n = 1,b accepts offer agreement takes place first time period.Now, consider case deadline n = 2. first round, size pie 1shrinks second round. order decide offer first round, looksahead = 2 reasons backwards3 . Agent reasons negotiation proceeds secondround, b take 100 percent shrunken pie offering [0, ] leave nothing a. Thus,first time period, offers b anything less , b reject offer. Hence,first time period, agent offers [1 , ]. Agent b accepts agreement occurs firsttime period.general, deadline n, negotiation proceeds follows. before, agent decidesoffer first round looking ahead far = n reasoning backwards.decision making leads make following offer first time period:n1n1[j=0[(1)j ij ], 1 j=0[(1)j ij ]](1)Agent b accepts offer negotiation ends first time period. Note equilibriumoutcome depends makes first move. Since two agents either couldmove first, get two possible equilibrium outcomes.basis equilibrium single-issue negotiation complete information,first obtain equilibrium multiple issues determine optimal negotiation procedurevarious settings previously described.3. Multi-Issue Negotiation Complete Informationmentioned Section 1, existing literature provide analysis multi-issueprocedures negotiation deadlines. Hence, begin analysing complete informationsetting. base, extend case information uncertainty.b negotiate > 1 independent issues (Section 6 deals interdependentissues). issues distinct pies agents want determine split them.Let = {1, 2, . . . , m} denote set pies. before, pie size 1. Let discountfactor issue c, 1 c m, 0 < c 1. issue, let n denote agents2. possible b may reject proposal. practice, propose offer enoughinduce b accept. However, keep exposition simple, assume get whole pie making100 percent proposal.3. backward reasoning method adopted (Stahl, 1972). model generalisation (Stahl, 1972);time period t, agent model propose offer zero t1 (because size piet1 ), player (Stahl, 1972) given fixed number alternatives choose from.386fiM ULTI -I SSUE N EGOTIATIONEADLINESdeadline. offer time period (where 1 n), agent (bs) shareissues represented element vector xt Rm1 (y R1 ). Thus, agent shareissue c time xtc , agent bs share yct = (ct1 xtc ). shares b togetherrepresented package [xt , ].define agents cumulative utility using additive form. two reasons this.First, common form cumulative utilities traditional multi-issue utility theory(Keeney & Raiffa, 1976). Second, additive cumulative utilities linear problem+making tradeoffs becomes computationally tractable4 . functions U : Rm1 R1 N Rb+U : R1 R1 N R give cumulative utilities b respectively time t.defined follows:(c=1 kc uc (xc , t) n(2)U ([xt , ], t) =0otherwiseU b ([xt , ], t) =(b bc=1 kc uc (yc , t)0notherwise(3)bka Rm+ denotes element vector constants agent k R+ b.R+ denotes set positive real numbers. vectors indicate agents value different, agent values issue c issue c + 1. Likewiseissues. example, kca > kc+1agent b. words, issues perfect substitutes (i.e., matters agenttotal utility issues subset Varian, 2003; Mas-Colell,Whinston, & Green, 1995). settings study, issues perfect substitutes.agent complete information negotiation parameters (i.e., n, m, kca , kcb , c1 c m). complete information setting, determine equilibriumpackage deal, simultaneous procedure, sequential procedure.3.1 Package Deal Procedureprocedure, agents use protocol single-issue negotiation (described Section 2). However, offer package deal includes proposal issue negotiation.Thus, issues, offer includes divisions, one issue. Agents allowed eitheraccept complete offer (i.e., issues) reject complete offer. agreement thereforetake place either issues none them.per single-issue negotiation, agent decides offer looking ahead reasoningbackwards. However, since offer package deal includes share issues,agents make tradeoffs across issues order maximise cumulative utilities.1 c m, equilibrium offer issue c time denoted [atc , btc ] atc btc denoteshares agent b respectively. denote equilibrium package time [at , bt ]4. Using form additive one make function nonlinear. Consequently agents tradeoff problembecomes global optimization problem nonlinear objective function. Due computational complexity,nonlinear optimization problems solved using approximation methods (Horst & Tuy, 1996; BarYam, 1997; Klein et al., 2003). Moreover, methods general depend cumulativeutilities actually defined. order overcome difficulty, used additive form defining cumulativeutilities. Consequently, tradeoff problem linear optimization problem, exact solutionfound polynomial time (as shown Theorems 1 2). Although results apply defined additivecumulative utilities, Section 6.4 discuss would hold nonlinear utilities.387fiFATIMA , W OOLDRIDGE , & J ENNINGSRm1 (b R1 ) element vector denotes (bs) shareissues. Also, 1 n, t1 Rm1 element vector represents sizespies time t. symbol 0 denotes element vector zeroes. Note 1 n,+ bt = t1 (i.e., sum agents shares (at time t) pie equal sizepie t). Finally, time period (for 1 n) let a(t) (respectively b(t)) denoteequilibrium strategy agent (respectively b).mentioned Section 1, package deal allows agents make tradeoffs. let TRADEOFFA(TRADEOFFB ) denote agent (bs) function making tradeoffs. Given this, following theorem characterises equilibrium package deal procedure.Theorem 1 package deal procedure, following strategies form Nash equilibrium.equilibrium strategy = n is:OFFER [n1 , 0] TURNa(n) =ACCEPTbs TURNb(n) =OFFER [0, n1 ] bs TURNACCEPTTURNpreceding time periods < n, [xt , ] denotes offer made time t, equilibriumstrategies defined follows:OFFER tradeoffa(ka , kb , , ub(t), m, t)TURNa(t) =(U ([x , ], t) ua(t)) ACCEPT else REJECT bs TURNb(t) =OFFER tradeoffb(ka , kb , , ua(t), m, t)bs TURN(U b ([xt , ], t) ub(t)) ACCEPT else REJECT TURNua(t) = U ([at+1 , bt+1 ], + 1) ub(t) = U b ([at+1 , bt+1 ], + 1). agreement takesplace = 1.Proof: look ahead last time period (i.e., = n) reason backwards. begin,negotiation reaches deadline (n), agent whose turn takes everything leavesnothing opponent. Hence, get strategies a(n) b(n) given statementtheorem.preceding time periods (t < n), offering agent proposes package givesopponent cumulative utility equal opponent would get equilibrium offernext time period. time period t, either b could offering agent. Considercase makes offer t. package offers gives b cumulative utilityU b ([at+1 , bt+1 ], + 1). However, since one issue, one packagegives b cumulative utility U b ([at+1 , bt+1 ], + 1). among packages, offersone maximises cumulative utility (because utility maximiser). Thus, problemfind package [at , bt ] to:maximisec=1 kc act1atc )kcb = ub(t)c=1 (c0 atc 13881 c(4)fiM ULTI -I SSUE N EGOTIATIONEADLINEStradeoff problem similar fractional knapsack problem (Martello & Toth, 1990; Cormen, Leiserson, Rivest, & Stein, 2003), optimal solution generated usinggreedy approach5 (i.e., filling knapsack items decreasing order value per unitweight). items knapsack problem analogous issues case. difference fractional knapsack problem starts empty knapsack aims fillitems maximise cumulative value, agents tradeoff problem viewedstarting agent 100 per cent issues aiming give away portionsissues opponent latter gets given cumulative utility, resulting lossutility minimised. Thus, order find split issues, agent considerskca /kcb 1 c kca /kcb utility needs give order increase bs utilityone. Since wants maximise utility give b utility U b ([at+1 , bt+1 ], + 1),divides pies gets maximum possible share issues kca /kcbhigh gives agent b maximum possible share issues kca /kcb low. Thus,begins giving b maximum possible share issue lowest kca /kcb .issue next lowest kca /kcb repeats process b gets cumulativeutility U b ([at+1 , bt+1 ], + 1). order facilitate process making tradeoffs, individa /k b . function tradeoffa takes sixual elements kb arranged kca /kcb > kc+1c+1parameters: ka , kb , , ub(t), m, uses described greedy method solvemaximisation problem given Equation 4 return corresponding package.one package solves Equation 4, tradeoffa returns one (because agentgets equal utility packages agent b). function tradeoffbagent b analogous a.hand, equilibrium strategy agent receives offer follows.time period t, let b denote receiving agent. Then, b accepts [xt , ] ub(t) U b ([xt , ], t), otherwise rejects offer get higher utility next time period. equilibriumstrategy receiving agent defined analogously. Hence get equilibrium strategies(a(t) b(t)) given statement theorem.way, reason backwards obtain offers = 1. first mover makesoffer agent accepts it. agreement therefore occurs first time period.Theorem 2 package deal procedure, time taken determine equilibrium offer= 1 O(mn) number issues n deadline.Proof: know Theorem 1 time compute equilibrium offer = n linearnumber issues (see strategies a(n) b(n)). Consider time period < n. timeperiod, function tradeoffa used make tradeoffs. time complexity tradeoffa(which uses greedy approach described proof Theorem 1) O(m) (Martello & Toth,1990; Cormen et al., 2003). function needs repeated every time period(n 1)th first. Hence time complexity finding offer first time periodO(mn).5. time complexity approach O(m) (Martello & Toth, 1990), denotes number items. Notegreedy method fractional knapsack problem takes O(m) time regardless whether coefficientskca kcb (for 1 c m) Equation 4 positive negative (Martello & Toth, 1990). present setting(as mentioned beginning Section 3) coefficients positive. However, come acrossnegative coefficients deal interdependent issues Section 6.389fiFATIMA , W OOLDRIDGE , & J ENNINGSTheorem 3 package deal procedure generates Pareto optimal outcome.Proof: Recall consider competitive negotiations. Hence, individual issue c (where1 c m), increase one agents utility results decrease other. However,package deal procedure, agent considers cumulative utility issues. Consequently, process backward reasoning, time < n, agent makes tradeoffsmaximises cumulative utility without lowering opponent (with respectopponent would offer next time period). Hence equilibrium outcome package dealPareto optimal.Theorem 4 given first mover, package deal procedure unique equilibrium outcomefollowing condition false:C1 . exists j (where 1 1 j m) (i 6= j)(kia /kib = kja /kjb ).Proof: Consider time period < n let denote offering agent. Recall Theorem 1splits issues increasing order kia /kib . Thus, given j, kia /kib = kja /kjb ,agent indifferent two issues (i j) splits first. example,= 2, n = 2, = 0.5, k1a = 1, k2a = 2, k1b = 2, k2b = 4, k1a /k1b = k2a /k2b = 0.5.offering agent = 1, offer (1, 0) issue 1 (1/4, 3/4) issue 2. givescumulative utility 1.5 3 b. Alternatively offer (0, 1) issue 1 (3/4, 1/4)issue 2 since also results cumulative utilities b.hand, kia /kib 6= kja /kjb , splits issue first kia /kib < kja /kjb issue j firstkia /kib > kja /kjb . words, one possible equilibrium offer maketime < n. Likewise one possible equilibrium offer b make time < n.Since unique offer time period, equilibrium outcome unique.Note uniqueness refer Theorem 4 respect given first mover.first mover changes, equilibrium outcome may change, following example illustrates.Let = 2, n = 2, = 0.5, k1a = 1, k2a = 2, k1b = 2, k2b = 1. offering agent= 1, equilibrium offer (1/4, 3/4) first issue (1, 0) second. resultscumulative 2.25 1.5 b. contrast, b offering agent = 1, equilibriumoffer (0, 1) first issue (3/4, 1/4) second. results cumulative utility1.5 2.25 b. following discussion, use term unique mean uniquerespect given first mover.3.2 Simultaneous Procedureprocedure, issues partitioned > 1 disjoint subsets. 1 c , letSc denote cth partition c=1 Sc = {1, . . . , m}. issues within subset settledusing package deal. Negotiation partitions starts = 1. Thus, = m,issues settled simultaneously independently other. extreme,one partition (i.e., = 1) package deal procedure described Section 3.1. Sinceissues subset (i.e., Sc ) settled using package deal, equilibriumpartitions obtained Theorem 1. Consequently, get following results.First, agreement issue occurs first round. negotiationpartition starts = 1. Also, Theorem 1, know agreement package deal390fiM ULTI -I SSUE N EGOTIATIONEADLINESoccurs = 1. Hence, simultaneous procedure, agreement partition (and henceissue) occurs first time period.Second, simultaneous procedure, time taken determine equilibrium offer= 1 c=1 O(|Sc |n) |Sc | number issues cth partition n deadline.explained follows. Since time taken find equilibrium offer = 1package deal (i.e., = 1) O(mn) (see Theorem 2), time taken compute equilibriumoffer = 1 cth partition O(|Sc |n). Hence, partitions, time complexityc=1 O(|Sc |n) equal O(M n), denotes number issues largestpartition.Third, follows Theorem 4 simultaneous procedure unique equilibriumoutcome following condition C2 true:C2 . partition c (where 1 c ) condition C1 true.Finally, Theorem 5 shows, simultaneous procedure may generate Pareto optimaloutcome.Theorem 5 simultaneous procedure may generate Pareto optimal outcome.Proof: package deal allows tradeoffs made across issues, simultaneousprocedure allows tradeoffs made across issues within partition across partitions.Hence simultaneous procedure may generate Pareto optimal outcome. showcounter example. Consider case n = 2, = 0.5, = 3, = 2, S1 = {1, 2}, S2 = {3},k1a = 1, k2a = 2, k3a = 3, k1b = 1, k2b = 0.5, k3b = 0.25. Let denote first mover.Theorem 1, know equilibrium partition S1 , agent gets share 0.25 issue1 1 issue 2, b gets share 0.75 issue 1 nothing issue 2. partition S2 ,agent gets share 1/2. Thus, cumulative utility three issues 3.75b 0.875.consider case three issues discussed using package deal. Here, = 1parameters remain same. equilibrium outcome procedure, getscumulative utility 5.125 b gets 0.875. means procedure = 2generate Pareto optimal outcome.3.3 Sequential Procedureprocedure, issues partitioned > 1 disjoint subsets. 1 c , let Scdenote cth partition c=1 Sc = {1, . . . , m}. partitions negotiated sequentially,one another. issues within subset settled using package deal. Negotiationfirst partition starts time = 1. negotiation cth (for 1 c ) partition ends tc ,negotiation (c + 1)th partition starts time tc + 1. player gets shareissues partition soon partition settled. Thus, = m, issues settledsequence. extreme, one partition (i.e., = 1) packagedeal procedure described Section 3.1. Since issues subset (i.e., Sc ) settledusing package deal, equilibrium subsets obtained Theorem 1substituting appropriate negotiation start times partition.391fiFATIMA , W OOLDRIDGE , & J ENNINGSTheorem 6 sequential procedure, equilibrium time agreement cth partition(for 1 c ) Tc = c.Proof: Theorem 1, know agreement package deal occurs first timeperiod. Hence, negotiation partition ends time period starts (i.e.,negotiation cth partition starts = c results agreement time period).time taken settle issues therefore .Note time complexity sequential procedure (i.e., time compute equilibriumoffers) simultaneous procedure. Also, like simultaneous procedure,equilibrium outcome sequential procedure may Pareto optimal. Finally, conditionequilibrium outcome sequential procedure uniquesimultaneous procedure.3.4 Optimal Procedureobtained equilibrium outcomes three multi-issue procedures, compareterms utilities generate player. procedure gives playermaximum utility optimal one.Note that, sequential procedure, equilibrium outcome strongly depends orderpartitions settled. ordering called negotiation agenda. twoways defining agenda (Fershtman, 1990): exogenously endogenously. agendadetermined actual negotiation issues begins, said exogenous.hand, endogenous agenda, agents decide issue settle nextprocess negotiation. agenda gives agent maximum utility possibleagendas optimal one (Fatima et al., 2004). objective determine optimalagenda, consider given agenda compare equilibrium outcome sequentialprocedure agenda outcomes simultaneous package deal procedures,order find optimal procedure. following theorem characterises procedure.Theorem 7 Irrespective issues split > 1 partitions, package dealoptimal parties.Proof: order compare agents utility different procedures, important takeaccount initiates negotiation. package deal, first mover makes offerissues. Hence compare agents utilities three procedures, given agentfirst mover three procedures issues.first show outcome package deal worse simultaneousprocedure. Consider simultaneous procedure > 1. procedure, n,offering agent makes tradeoffs across issues partition independently partitions. consider package deal procedure (i.e., = 1 partitions). procedure,offering agent makes tradeoffs across issues. Since difference procedure= 1 one > 1 former makes tradeoffs across issueslatter not, agents utility former procedure worse utilitylatter.show given (where > 1), agent, outcome simultaneousprocedure better sequential one (irrespective agenda sequentialprocedure). considering partitions.392fiM ULTI -I SSUE N EGOTIATIONTimeagreement (tc )Time computeequilibriumPareto optimal?Unique equilibrium?EADLINESPackage dealcth issuetc = 11 cO(mn)Simultaneouscth issuetc = 11 cO(M n)Sequentialcth partitiontc = c1 cO(M n)YesC1C2C2Table 2: comparison outcomes three multi-issue procedures complete information setting (CI).Partition c = 1. Since negotiation first partition starts = 1 simultaneous sequential procedures, outcome partition = 1> 1. Hence, first partition, agent gets equal utility two procedures.Partition c > 1. Let agent denote first mover partition c (for 2 c )U denote cumulativesimultaneous sequential procedures. Also, let Usimsequtility partition equilibrium outcome simultaneous sequentialbb denote bs cumulative utilityprocedures respectively. Likewise, let UsimUseqpartition equilibrium outcome simultaneous sequential proceduresrespectively.simultaneous procedure, negotiation partition starts first timeperiod. agreement partition also occurs first time period. hand,sequential procedure, negotiation cth partition starts cth time periodresults agreement time period (see Theorem 6). Since pie shrinks, agent bs cumulative utilitytime, agent cumulative utility Usimgreater Useqbb .Usimgreater UseqThus, simultaneous procedure better sequential one agents. Furthermore(as shown above), outcome package deal worse simultaneousprocedure agents. Therefore, agent, package deal optimal procedure.results summarised Table 2. analysis, negotiation parameters n, c ,kca , kcb (for 1 c m) common knowledge agents. However, unlikelycase encounters. Therefore extend analysis incomplete informationscenarios uncertainty utility functions6 . Section 4, focus symmetric information setting agent uncertain others utility function. Then, Section 5,examine asymmetric information setting one two agents uncertainothers utility function, agent knows utility function agents.6. two sources uncertainty: uncertainty negotiation deadline uncertainty discountfactors. Future work deal uncertainty discount factors. However, independent issues, analysedcase symmetric uncertainty deadlines (Fatima, Wooldridge, & Jennings, 2006). extensionwork case interdependent issues another direction future work.393fiFATIMA , W OOLDRIDGE , & J ENNINGS4. Multi-Issue Negotiation Symmetric Uncertainty Opponents Utilitysymmetric information setting, agent uncertain opponents utility function:1 c m, agent (b) uncertain kcb (kca ). Specifically, let K denote vector r vectorsvector Ki Rm+ (for 1 r) consists constant positive real numbers.b7r vectors possible values ka Rm+ k R+ . words, r typesagent r types agent b. Let P : N+ R1 denote discrete probability distributionfunction ka P b : N+ R1 kb . domain two functions [1..r].words, 1 r, P (i) (P b (i)) probability agent (b) type i. 1 c m,let Kic denote cth element vector Ki .setting, vector K functions P P b common knowledge negotiators. Also, agent knows type, opponent. addition, agentknows r, , n, m.Since r types agent r types agent b, define r different cumulativeutility functions two agents. agent (b) type (for 1 r) utility++bUia : Rm1 R1 N R (Ui : R1 R1 N R) division specified package[xt , ] time is:(c=1 Kic uc (xc , t) n(5)Ui ([x , ], t) =0otherwise(bc=1 Kic uc (yc , t) nb(6)Ui ([x , ], t) =0otherwiseNote that, before, issues perfect substitutes. setting, determine equilibrium outcomes three multi-issue procedures compare them.4.1 Package Deal Procedureknow Theorem 1 equilibrium outcome complete information setting depends kca kcb (for 1 c m). However, setting, uncertainty kcakcb . Hence use standard expected utility theory (Neumann & Morgenstern, 1947; Fishburn,1988; Harsanyi & Selten, 1972) find agents optimal strategy. so, however,first introduce notation.1 r, let a(i, t) denote equilibrium strategy agent typetime period t. Analogously, b(i, t) denotes equilibrium strategy agent b typetime period t. Note 1 r, [at , bt ] package offered time equilibrium,+ bt = t1 (i.e., pie, sum shares two agents equal sizepie time t). Also, 1 r, let a(i, j, t) denote equilibrium strategyagent type time period t, assuming b type j. Analogously, b(i, j, t) denotesequilibrium strategy agent b type time period t, assuming type j.Also, let eua(i, t) denote cumulative utility agent type expects get bsequilibrium offer time (i.e., receiving agent b offering agent t). Likewise,eub(i, t) denotes cumulative utility agent b type expects get equilibriumoffer time (i.e., b receiving agent offering agent t). let eua(i, j, t) denoteagent expected cumulative utility equilibrium offer time type i,7. agents type indicates r vectors corresponds to.394fiM ULTI -I SSUE N EGOTIATIONEADLINESassuming b type j. Note utility offering agent t. leteub(i, j, t) denote agent bs expected cumulative utility equilibrium offer time btype assuming type j. Note bs utility offering agentt.Recall setting, agent knows type, opponent.Since r possible types, r possible offers agent make time period(one offer corresponding opponents types). Among r offers, one givesagent maximum expected cumulative utility optimal offer. cth offer (1 c r)gives agent maximum expected cumulative utility, say optimal choiceagent c. time period t, let opta(i, t) (optb(i, t)) denote optimal choice agent(b) type i.= n, offering agent gets everything opponent gets zero utility. Thus, = n,following:eua(i, n) = 01 r(7)eub(i, n) = 0XKic ct1eua(i, j, n) =1 r(8)1 r 1 j r(9)1 r 1 j r(10)eub(i, j, n) =c=1XKic ct1c=1Note = n, eua(i, j, n) eub(i, j, n) depend j last time period,offering agent gets 100 percent pies. preceding time periods < n,following:eua(i, t) = eua(i, , + 1)1 r = opta(i, + 1)(11)eub(i, t) = eub(i, , + 1)1 r = optb(i, + 1)rXF (i, j, e, t) P b (e)1 r 1 j reua(i, j, t) =(12)(13)e=1eub(i, j, t) =rXF b (i, j, e, t) P (e)1 r 1 j r(14)e=1Fafunctiontakes four parameters: i, j, e, t, returns utility agent typegets offering equilibrium package time t, assuming agent b type jfact type e. Obviously, agent b accepts offer Ueb (a(i, j, t), t) eub(e, , + 1)= optb(e, + 1). Otherwise, agent b rejects offer negotiation proceeds nextround case expected utility EUA (i, + 1). Hence, F defined follows:Ui (a(i, j, t), t) Ueb (a(i, j, t), t) eub(e, , + 1) = optb(e, + 1)F (i, j, e, t) =eua(i, + 1)otherwisestrategy a(i, j, t) = n defined follows:OFFER [n1 , 0] turn(i, j, n) =ACCEPTotherwise395fiFATIMA , W OOLDRIDGE , & J ENNINGSpreceding time periods < n defined as:OFFER tradeoffa1(K, , eub(j, t), i, j, m, t, P , P b ) turn(i, j, t) =Uia ([xt , ], t) EUA (i, t) ACCEPT else REJECTotherwise[xt , ] denotes offer made function8 TRADEOFFA 1 defined follows.Like TRADEOFFA , function TRADEOFFA 1 solves following maximisation problem:maximisec=1 Kic act1atc )Kjc = eub(j, t)c=1 (c0 atc 11 c(15)denotes type j b. However, difference TRADEOFFA 1TRADEOFFA arises one package maximises cumulative utility (i.e.,c=1 Kic ac ) giving b cumulative utility eub(j, t). one package,Theorem 1, matter packages offers b (because agentscomplete information). Hence, TRADEOFFA return one package. However,present setting, uncertainty. Therefore, one package maximisescumulative utility giving b cumulative utility eub(j, t), TRADEOFFA 1 returnspackage maximises expected cumulative utility. instance, let [at , bt ] onepackage maximises cumulative utility. expected cumulative utility [at , bt ](i.e., eua(i, j, t)) given Equation 13 where:Ui ([a , b ], t) Ueb ([at , bt ], t) eub(e, , + 1) = optb(e, + 1)F (i, j, e, t) =eua(i, + 1) otherwiseObviously, one package maximises expected cumulative utilitygives b utility eub(j, t) TRADEOFFA 1 returns one package.turn agent b. agent, F b , B(i, j, t), tradeoffb1 defined analogouslyfollows:bUi (b(i, j, t), t) Uea (b(i, j, t), t) eua(e, , + 1) = opta(e, + 1)bF (i, j, e, t) =eub(i, + 1)otherwisestrategy b(i, j, t) = n defined follows:OFFER [0, n1 ] bs turnB (i, j, n) =ACCEPTotherwisepreceding time periods < n defined as:OFFER tradeoffb1(K, , eua(j, t), i, j, m, t, P , P b ) bs turnB (i, j, t) =Uib ([xt , ], t) EUB (i, t) ACCEPT else REJECTotherwise8. method making tradeoffs proposed Faratin, Sierra, Jennings (2002) incomplete information setting, method differs ours. Also, Faratin et al. present method making tradeoffs,show resulting offer equilibrium. contrast, method shows resulting offerequilibrium.396fiM ULTI -I SSUE N EGOTIATIONEADLINESThus, optimal choice agent (i.e., opta(i, t)) agent b (i.e., optb(i, t))defined follows:opta(i, t) = arg maxrj=1 eua(i, j, t)1 r(16)maxrj=1 eub(i, j, t)1 r(17)optb(i, t) = argNote offering agents optimal choice = n depend opponents type sinceoffering agent gets pies.compute optimal choice first time period reasoning backwards = n.= 1, agent type offering agent, offers package correspondsagent b type opta(i, 1). Likewise, agent b type offering agent, offerspackage corresponds agent type optb(i, 1).However, since opta(i, 1) optb(i, 1) obtained absence complete information,agreement may may take place first time period. agreement occur= 1, agents need update beliefs follows. Let Tta {1, 2, . . . , r} denoteset possible types agent time t. = 1, T1a = {1, 2, . . . , r} T1b ={1, 2, . . . , r}. Assume agent type makes offer = 1. offer makesgets rejected, means b type opta(i, 1) updates beliefs b usingBayes rule. Now, basis offer = 1 (say [x1 , 1 ]), agent b infer possibletypes agent a. Thus, agent b updates beliefs using Bayes rule. belief update rulestime defined below.UPDATE BELIEFS: Agent puts weight posterior distribution bs typeTtb {optb(i, t)} using Bayes rule. Agent b puts weight posteriordistribution type K using Bayes rule K {1, 2, . . . , r} setpossible types offer [xt , ] equilibrium.belief update rule case b offers = 1 analogous caseoffers = 1.Thus offer = 1 gets rejected, negotiation goes next round. = 2,offering agent (say agent type i) finds opta(i, 2) updated beliefs. processupdating beliefs making offers continues agreement reached.Section 3, used concept Nash equilibrium agents complete information. However, current setting, agent uncertain opponents typeagents optimal strategy depends beliefs opponent. Hence use conceptsequential equilibrium (Kreps & Wilson, 1982; van Damme, 1983) setting. Sequentialequilibrium defined terms two elements: strategy profile system beliefs.strategy profile comprises pair strategies, one agent. belief system following properties. agent belief opponents type. time period, agentsstrategy optimal given current beliefs (during time period) opponents possiblestrategies. time period, agents beliefs (about opponent) consistentoffers received. Using concept sequential equilibrium, following theorem characterisesequilibrium package deal procedure.Theorem 8 package deal procedure, following strategies form sequential equilibrium.equilibrium strategies = n are:OFFER [n1 , 0] TURNa(i, n) =ACCEPTbs TURN397fiFATIMA , W OOLDRIDGE , & J ENNINGSb(i, n) =OFFER [0, n1 ] bs TURNACCEPTTURN1 r. preceding time periods < n, [xt , ] denotes offer made time t,equilibrium strategies defined follows:OFFER tradeoffa1(K, , eub(, t), i, , m, t, P , P b ) TURNoffer gets rejected UPDATE BELIEFSa(i, t) =RECEIVE OFFER UPDATE BELIEFSbs TURN(Uia ([xt , ], t) eua(i, t)) ACCEPT else REJECTOFFER tradeoffb1(K, , eua(, t), i, , m, t, P , P b ) bs TURNoffer gets rejected UPDATE BELIEFSb(i, t) =RECEIVE OFFER UPDATE BELIEFSTURNb(Ui (x , ], t) eub(i, t)) ACCEPT else REJECT1 r. Here, = opta(i, t) = optb(i, t). earliest possible time agreement= 1 latest possible time agreement = min(2r 1, n).Proof: time = n, offering agent takes pies leaves nothing opponent.opponent accepts get a(i, n) b(i, n). consider time period < n.Recall negotiation complete information setting (see Section 3.1), time < n,offering agent proposes package gives opponent cumulative utility equalopponent would get equilibrium offer next time period. However,current incomplete information setting, agent knows type opponent.Hence, scenario, time < n, offering agent (say a) proposes package gives bexpected cumulative utility equal b would get equilibrium offer nexttime period (i.e., eub(, t)). package determined tradeoffa1 function. Likewise,b offering agent time t, makes tradeoffs using tradeoffb1 offersexpected cumulative utility eua(, t).obtain equilibrium offer = n 1 reason backwards obtainequilibrium offer = 1. However, since offers computed absence completeinformation (i.e., basis expected utilities), agreement may may take place= 1. agreement take place = 1, negotiation proceeds follows. Considertime period 1 < n. Let [xt , ] denote offer made time t. agentreceives offer (say agent a) updates beliefs using Bayes rule: put weightposterior distribution bs type K K {1, 2, . . . , r} set possible types boffer [xt , ] equilibrium. proposed offer ([xt , ]) gets rejected, offeringagent (say agent b type i) updates beliefs using Bayes rule: put weight posteriordistribution type Tta {optb(i, t)}. belief update rule case agentoffers time analogous rule. belief update rules incorporatedagents strategies give a(i, t) b(i, t) shown statement theorem.show beliefs specified consistent. time period < n, letstrategy profile (a(i, t), b(i, t)) assign probability 1 specified posterior beliefsprobability rest support opponents type. 0, strategy pairconverges (a, b). Also, beliefs generated strategy pair converge beliefs describedabove. Given beliefs, strategies b sequentially rational.398fiM ULTI -I SSUE N EGOTIATIONEADLINESearliest possible time agreement = 1. show following example. Letn = 2, = 2, r = 2, = 1/2, K = [1, 2; 5, 1]. Let agent offering agent time = 1.Assume type 1 (i.e., ka = [1, 2]). Let P b (1) = 0.1 P b (2) = 0.9. Since r = 2, agentplay two possible strategies time = 1: one corresponds case b type 1corresponds case b type 2. former case, equilibriumoffer = 1 [0, 1] first issue [ 43 , 14 ] second one. Hence eua(1, 1, 1) = 1.5.latter case, equilibrium offer = 1 [ 52 , 35 ] first issue [1, 0] secondissue. Hence eua(1, 2, 1) = 2.16. Since eua(1, 2, 1) > eua(1, 1, 1), opta(1, 1) = 2 playslatter strategy. b fact type 2, accepts offer = 1. b facttype 1, rejects offer = 1 since get higher utility = 2. agreement thereforeoccurs = 2. Thus, earliest possible time agreement = 1.consider case type offers = 1 agreement occurtime. offer gets rejected, knows b type opta(i, 1). Thus numberpossible types b reduced r 1. happens every time makes offer (i.e., everyalternate time period) gets rejected. negotiation reaches time period = 2r 1,one possible type b. Likewise, one possible type agent a. agreementtherefore takes place = 2r 1. However, n < 2r 1 agreement occurs = n (seea(i, n) b(i, n)). words, agreement occur = 1, occurslatest = min(2r 1, n).mentioned earlier, one package solves Equation 15, tradeoffa1returns one maximises expected cumulative utility. Let paij(where denotes typej b) denote set possible packages tradeoffa1 return time t.set pbijagent b defined analogously.Theorem 9 given first mover, package deal procedure unique equilibrium outcomecondition C3 false C4 true.C3 . exists i, j, c, d, (c 6= d) (i 6= j) (Kic /Kjc = Kid /Kjd )1 r, 1 j r, 1 c m, 1 m.ijC4 . |paij| = 1 |pbt | = 1 1 r, 1 j r, 6= j, 1 n.Proof: Let denote agent type j denote bs type 6= j, 1 r, 1 k r.Note b type, similar preferences different issues. 6= jagents gain making tradeoffs different types. restproof condition C3 follows Theorem 4. Consider C4 . C3 true, know that,time t, tradeoffa1 returns package solves Equation 15 maximises expectedcumulative utility. Hence paijcontains single element, one possible packagetradeoffa1 return. Likewise, pbijcontains single element, onepossible package tradeoffb1 return. one possible offer timeperiod 1 n, equilibrium outcome unique.order determine time complexity package deal, first find complexitytradeoffa1 function. mentioned before, tradeoffa1 differs tradeoffaone package solves maximisation problem Equation 15.know Theorem 9 one package condition C3 true. also399fiFATIMA , W OOLDRIDGE , & J ENNINGSknow Theorem 1 using greedy approach, tradeoffa considers issuesincreasing order Kic /Kjc denotes type j denotes bs type. Let Spij denoteset issues (where 0 ij < m, 1 p ij , denotes type, j denotes bs type)that:|Spij | > 1 1 p ijand:c,dSpijKicKjc=KidKjdwords, Spij set issues c belong Spij Kic /Kjc = Kid /Kjd ,ij number sets satisfy condition. ij = 0 meansone package solves Equation 15. ij > 0 one package solvesEquation 15 among tradeoffa1 must find one maximises expectedcumulative utility. example set issues = {1, 2, 3, 4}, r = 2, K1 = {5, 6, 7, 8},K2 = {9, 6, 7, 8}, D12 = 1, S112 = {2, 3, 4}, |S112 | = 3. making tradeoffs,consider issues S112 order three issues needs giveamount utility order increase bs utility 1. three issues S112 ordered3! different ways resulting 3! different packages. among 3! different packages,tradeoffa1 must find one maximises expected cumulative utility. general,ij > 1, let ij denote number9 possible packages tradeoffa1 needs considerij is:ijij|Spij |!=p=1words, type bs type j, ij packages solve Equation 15among tradeoffa1 must find one maximises expected cumulativeutility. Dij = 0, ij = 1. Let defined as:=max1ir,1jr,i6=jij(18)words, maximum number packages tradeoffa1 searchfind one maximises expected cumulative utility (considering possible typespossible types b). Note that, before, b different types (i.e., 6= jEquation 18) agents gain making tradeoffs different types.time complexity tradeoffa1 depends .Theorem 10 time complexity tradeoffa1 O(m).Proof: know Theorem 2 time complexity finding one package solvesEquation 15 O(m). However, one package solves Equation 15tradeoffa1 returns one maximises expected cumulative utility. time computeexpected cumulative utility one package O(m). maximum numberpackages needs find expected cumulative utility . Thus time complexitytradeoffa1 O(m).9. Note ij defined terms factorial |Spij |, |Spij | independent assumed|Spij | m.400fiM ULTI -I SSUE N EGOTIATIONEADLINESCorollary 1 ij = 0 1 r, 1 j r, 6= j, time complexitytradeoffa1 complexity tradeoffa.Proof: ij = 0 1 r, 1 j r, 6= j, ij = 1 = 1. timecomplexity tradeoffa1 O(m).Theorem 11 time complexity computing equilibrium offers package deal procedure O(mr 3 (n T2 )) = min(2r 1, n).Proof: Let denote agent offers = 1 assume n even (the proof oddn analogous). begin last time period reason backwards. Since n evenstarts = 1, bs turn offer last time period. = n, time taken findeub(i, j, t) (for given j) O(m) (see Equation 10). Hence, time taken find eub(i, j, t)possible types b (i.e., 1 j r) O(mr). Note that, stage, eub(i, 1) known1 r (see Equation 12).consider time period = n 1. Since n even, turn offer = n 1.order find a(i, t), first need find = opta(i, t). Equation 16 knowthat, given i, time find opta(i, t) depends time taken find eua(i, j, t)turn depends time find fa (i, j, e, t) (see Equation 13). time taken fa (i, j, e, t)depends time taken a(i, j, t). given given j, time taken find a(i, j, t)time taken function tradeoffa. Since eub(j, t) already known time t, timetaken tradeoffa1 O(m) (see Theorem 10). time taken find fa (i, j, e, t) thereforeO(m). Given this, time find eua(i, j, t) (for given i, j, t) O(mr). Hence,given i, time find = opta(i, t) O(mr 2 ). stage, EUB (, t) known (see lastsentence first paragraph proof). Consequently, given i, time find a(i, t)O(mr 2 ). Recall agent knows type opponent. Henceneed determine a(i, t) possible types (i.e., 1 r). takes O(mr 3 ) time.Note stage eua(i, j, t) known possible values possible values j(where 1 r 1 j r).consider time period = n 2 bs turn offer. = n 2 given i,time find optb(i, t) O(mr 2 ) time find optb(i, t) possible typesb (i.e., 1 r) O(mr 3 ).way, time required necessary computation time period< n O(mr 3 ). Hence, total time find equilibrium offer first time periodO((n 1)mr 3 ). However, noted previously, agreement may may occur firsttime period. agreement take place = 1, agents update beliefscompute equilibrium offer = 2 updated beliefs. time computeequilibrium offer = 2 O((n 2)mr 3 ). process updating beliefs findingequilibrium offer repeated = min(2r 1, n) times. Hence time complexitypackage deal Ti=1 O((n i)mr 3 ) = O(mr 3 (n T2 )) (see Cormen et al., 2003, page 47details simplify expression form Ti=1 O((n i)mr 3 )).Theorem 12 package deal procedure generates Pareto optimal outcome.Proof: follows Theorem 3. difference complete information settingTheorem 3 current incomplete information setting former setting agentsmaximise cumulative utilities, whereas current setting maximise expectedcumulative utilities. Specifically, every time period, offering agent maximises expected401fiFATIMA , W OOLDRIDGE , & J ENNINGScumulative utility issues opponents expected cumulative utility equalopponent would get equilibrium offer next time period. Hence,current setting, equilibrium offer every time period Pareto optimal.4.2 Simultaneous ProcedureRecall procedure, > 1 partitions discussed parallel independentlyother. offers made negotiation one partition affect offersothers. Specifically, negotiation partition starts = 1 partitionsettled using package deal procedure. Since partition dealt separately, resultsTheorem 8 apply directly partitions.Let c denote cth partition. Then, Theorem 11, know time takencth (for 1 c ) partition O(|Sc |c r 3 (n T2 )). Let partition |Sc |c highestdenoted Sz . time complexity simultaneous procedure O(|Sz |z r 3 (n2 )). Also, Theorem 5, follows simultaneous procedure may generate Paretooptimal outcome. Finally, Theorem 9 know simultaneous procedure uniqueequilibrium outcome following condition satisfied:C5 . partition c (where 1 c ) condition (C3 C4 ) false.4.3 Sequential Procedureprocedure, > 1 partitions discussed independently one another. Also,1 c , negotiation cth partition starts time period follows agreement(c 1)th partition. Since package deal used partition, following resultsobtained basis Theorem 8.First, Theorem 8 applies > 1 partitions. Thus, sequential procedure,negotiation cth (for 1 c ) partition starts time tc , ends earliesttime tc latest tc + min(2r 1, n). Second, follows Theorem 11 timetaken sequential procedure O(|Sz |z r 3 (n T2 )). Third, sequential procedure maygenerate Pareto optimal outcome (see Theorem 5). Finally, conditions uniquenesssimultaneous procedure.4.4 Optimal Procedureobtained equilibrium outcomes three procedures defined incompleteinformation scenario, compare terms expected utilities generateplayer. Again, procedure gives player maximum expected utility optimal one.Theorem 13 package deal optimal agent.Proof: proof Theorem 7. difference completeinformation setting Theorem 7 current incomplete information settingpackage deal procedure former setting (during time period < n), offering agent proposes package maximises cumulative utility, giving opponent cumulativeutility equal opponent would get equilibrium offer next time period.hand, current incomplete information setting, offering agent proposespackage maximises expected cumulative utility giving opponent expected402fiM ULTI -I SSUE N EGOTIATIONTimeagreementTime computeequilibriumPareto optimal?Unique equilibrium?Package dealEarliest: 1Latest: min(2r 1, n)issuesO(mr 3 (n T2 ))EADLINESSimultaneousEarliest: 1Latest: min(2r 1, n)issuesO(|Sz |z r 3 (nYesC3 C4C52 ))Sequentialcth partitiontec = tscltc = tc + min(2r 1, n)1 cO(|Sz |z r 3 (n T2 ))C5Table 3: comparison expected outcomes three multi-issue procedures symmetric information setting (for sequential procedure, tsc denotes start timecth partition, tec earliest possible time agreement, tlc latest possible timeagreement).cumulative utility equal opponent would get equilibrium offer nexttime period. Also, agent, package deal maximises expected cumulative utilityissues (since tradeoffs made across issues). simultaneous proceduremaximises agents expected cumulative utility partition (i.e., simultaneous procedure make tradeoffs across partitions). Hence agents expected cumulative utilityissues higher package deal relative simultaneous procedure. Furthermore,irrespective issues partitioned partitions, know simultaneousprocedure better sequential one agent (see Theorem 7). Hence, package dealoptimal agent.results summarised Table 3.5. Multi-Issue Negotiation Asymmetric Uncertainty OpponentsUtilitybargaining situations, one players may know something relevancemay know. example, bargaining price second hand car, seller knowsquality buyer not. situations said asymmetry informationplayers (Muthoo, 1999). asymmetric information setting differs symmetric oneexplored previous section one two agents (say a) complete information,(say b) uncertain utility function: 1 c m, agent b uncertainkca . Here, K, P , P b , n, r, defined Section 4. negotiation parameters K, P ,P b , r, , n, common knowledge negotiators. Furthermore, knows typeb, b knows type a. Finally, definitions cumulativeutility functions remain Section 4. setting, determine equilibriumthree multi-issue procedures.403fiFATIMA , W OOLDRIDGE , & J ENNINGS5.1 Package Deal Procedureextend analysis Section 4 current setting follows. clear last timeperiod (t = n), utilities eua(i, t) eub(i, t) per Section 4. Let j denote bs actualtype. Recall agent knows j. Hence basis Equation 13 SUI setting,get eua(i, j, t) current asymmetric information setting follows:eua(i, j, t) = F (i, j, j, t)1 r 1 j r(19)hand, since agent b uncertain type, definitions eub(i, t)eub(i, j, t) given Section 4. Also, definitions F , F b , a(i, j, t), b(i, j, t), opta(i, t),optb(i, t) time periods remain Section 4.Finally, setting, belief updating apply agent complete information. agent b updates beliefs a. done way describedSection 4. bs uncertainty, use concept sequential equilibrium settingwell. following theorem characterises equilibrium package deal procedure.Theorem 14 package deal procedure following strategies form sequential equilibrium. equilibrium strategies = n are:OFFER [n1 , 0] TURNa(i, n) =ACCEPTbs TURNb(i, n) =OFFER [0, n1 ] bs TURNACCEPTTURN1 r. preceding time periods < n, [xt , ] denotes offer made time t,equilibrium strategies defined follows:OFFER tradeoffa1(K, , eub(j, t), i, j, m, t, P , P b ) TURNa(i, t) =RECEIVE OFFERbs TURN(Uia ([xt , ], t) eua(i, t)) ACCEPT else REJECTOFFER tradeoffb1(K, , eua(, t), i, , m, t, P , P b ) bs TURNoffer gets rejected UPDATE BELIEFSb(i, t) =TURNRECEIVE OFFER UPDATE BELIEFS(Uib (xt , ], t) eub(i, t)) ACCEPT else REJECT1 r. Here, j denotes agent bs type = optb(i, t). earliest possible timeagreement = 1 latest possible time = min(2r 1, n).Proof: Theorem 8. difference knows bs type (j). Hence informationused parameter tradeoffa1.earliest possible time agreement = 1. show following example.Let n = 2, = 2, r = 2, = 1/2, K = [1, 2; 5, 1]. Let b (i.e., agent uncertaininformation) offering agent time = 1. Assume b type 2 (i.e., kb = [5, 1]). LetP (1) = 0.9 P (2) = 0.1. Since r = 2, b play two possible strategies time = 1:one corresponds case type 1 corresponds casetype 2. former case, bs equilibrium offer = 1 [0, 1] first issue404fiM ULTI -I SSUE N EGOTIATIONEADLINES[ 34 , 14 ] second. Hence eub(1, 1, 1) = 4.725. latter case, bs equilibrium offer= 1 [ 52 , 35 ] first issue [1, 0] second one. Hence eub(1, 2, 1) = 3. Sinceeub(1, 1, 1) > eub(1, 2, 1), optb(1, 1) = 1 b plays former strategy. facttype 1, accepts bs offer = 1. fact type 2, rejects bs offer = 1since get higher utility = 2. agreement therefore occurs = 2. Thus, earliestpossible time agreement = 1.consider case agent b type offers = 1 agreementoccur time. bs offer gets rejected, knows type optb(i, 1). Thusnumber possible types reduced r 1. happens every time b makesoffer (i.e., every alternate time period) gets rejected. negotiation reaches time period= 2r 1, one possible type a. Since knows bs type, agreement thereforetakes place = 2r 1. However, n < 2r 1 agreement occurs = n (see a(i, n)b(i, n)). words, agreement occur = 1, occurs latest= min(2r 1, n).Note latest possible time agreement asymmetric information settingsymmetric information setting Theorem 8. because, asymmetric setting,although knows bs type, b uncertain type. Also, takes 2r 1 time periods bcome know actual type. Hence, earliest latest time agreementsettings.Theorem 15 time complexity computing equilibrium offers package deal procedure O(mr 3 T2 (n T2 )) = min(2r 1, n).Proof: Let denote agent offers = 1 assume n even (the proof oddn analogous). begin last time period reason backwards. Since n evenagent starts = 1, bs turn offer last time period. = n, timetaken find eub(i, j, t) (for given j) O(m) (see Equation 10). Hence, time takenfind eub(i, j, t) possible types b (i.e., 1 j r) O(mr). Note that, stage,eub(i, 1) known 1 r (see Equation 12).consider time period = n 1. Since n even, turn offer = n 1.order find a(i, t), first need find = opta(i, t). Equation 16 knowthat, given i, time find opta(i, t) depends time taken find eua(i, j, t) which,turn, depends time find fa (i, j, e, t) (see Equation 19). time taken fa (i, j, e, t)depends time taken a(i, j, t). given given j, time taken find a(i, j, t)time taken tradeoffa1. Since eub(j, t) already known time t, time takenfunction tradeoffa1 O(m) (as Theorem 2). time taken find fa (i, j, e, t) thereforeO(m). Given this, time find eua(i, j, t) (for given i, j, t) O(m) since bs typeknown agents see Equation 19. Hence, given i, time find = opta(i, t)O(mr). stage, EUB (, t) known (see last sentence first paragraphproof). Consequently, given i, time find a(i, t) O(mr). Recall b knowtype. Hence need determine a(i, t) possible types (i.e., 1 r).takes O(mr 2 ) time. Note stage eua(i, j, t) known possible valuespossible values j (where 1 r 1 j r).consider time period = n 2 bs turn offer. differencecomputation = n 1 = n 2 former case, time find eua(i, j, t)(for given i, j, t) O(m) since bs type known agents. However latter405fiFATIMA , W OOLDRIDGE , & J ENNINGScase, time find eub(i, j, t) (for given i, j, t) O(mr) since type knownb (see Equation 14). Consequently, given i, time find b(i, t) O(mr 2 ). timedetermine b(i, t) possible types b (i.e., 1 r) O(mr 3 ) time. Notestage eub(i, j, t) known possible values possible values j (where 1 r1 j r).way, time required necessary computation odd time period< n O(mr 2 ), even time period O(mr 3 ). Hence, total time findequilibrium offer first time period O(mr 3 ( n12 )). However, noted previously,agreement may may occur first time period. agreement take place =1, agents update beliefs compute equilibrium offer = 2 updatedbeliefs. time compute equilibrium offer = 2 O(mr 3 ( n22 )). processupdating beliefs finding equilibrium offer repeated = min(2r 1, n) times.3Hence time complexity package deal Ti=1 O(mr 3 ( ni2 )) = O(mr (n 2 ) 2 ).Theorem 16 package deal procedure generates Pareto optimal outcome.Proof: per Theorem 12.Theorem 17 given first mover, package deal procedure unique equilibrium outcomeC3 C4 true.Proof: per Theorem 9.5.2 Simultaneous ProcedureTheorem 14 applies > 1 partitions. Hence, Theorem 15, knowtime taken cth (for 1 c ) partition O(|Sc |c r 3 ( nT2 ) 2 ). Hence, time complexity3simultaneous procedure O(|Sz |z r (n 2 ) 2 ). Also, Theorem 5, followssimultaneous procedure may generate Pareto optimal outcome. Finally, Theorem 17know simultaneous procedure unique equilibrium outcome condition C5 true.5.3 Sequential ProcedureFirst, Theorem 14 applies > 1 partitions. Thus, sequential procedure,negotiation cth (for 1 c ) partition starts time tc , ends earliest timetc latest tc + min(2r 1, n). Second, follows Theorem 15 time takensequential procedure O(|Sz |z r 3 (n T2 ) T2 ). Third, sequential procedure maygenerate Pareto optimal outcome (see Theorem 5). Finally, conditions uniquenesssimultaneous procedure.5.4 Optimal Procedurefollows Theorem 13 that, agent, optimal procedure package deal.results summarised Table 4.6. Multi-Issue Negotiation Interdependent Issuesindependent issues case Section 4, agents utility issue c (for 1 c m) dependsshare issue independent issues. However, many cases,406fiM ULTI -I SSUE N EGOTIATIONPackage dealEarliest: 1Latest: min(2r 1, n)issuesTimeagreementTime computeequilibriumPareto optimal?Unique equilibrium?O(mr 3 T2 (n2 ))EADLINESSimultaneousEarliest: 1Latest: min(2r 1, n)issuesO(|Sz |z r 3 (nYesC3 C42)2)Sequentialcth partitiontec = tscltc = tc + min(2r 1, n)1 cO(|Sz |z r 3 (n T2 ) T2 )C5C5Table 4: comparison expected outcomes three multi-issue procedures asymmetric information setting (for sequential procedure, tsc denotes start timecth partition, tec earliest possible time agreement, tlc latest possible timeagreement).agents utility issue depends share issue, also shareothers (Klein et al., 2003). Given this, section focus interdependent issues.Specifically, model interdependence issues follows. Consider package [xt , ].package, agent type i, utility issue c time form:(Kic xc +j=1 ij (xc xj ) n(20)uic ([x , ], t) =0otherwiseagent b type i, is:ubic ([xt , ], t)(Kic yc +j=1 ij (yc yj ) n=0otherwise(21)Kic denotes constant positive real number ij constant real number mayeither positive negative. before, agents cumulative utility sum utilitiesindividual issues:(c=1 Kic xc n(22)Uia ([xt , ], t) =0otherwise(c=1 Kic yc n(23)Uib ([xt , ], t) =0otherwiseK denotes vector analogous vector K except individual elementslatter constant positive real numbers, former may positive negative.Note Equations 5 6, coefficients positive (i.e., Kic > 0 1 r1 c m). Equations 22 23, coefficient (Kic ) may positive negative realnumber.407fiFATIMA , W OOLDRIDGE , & J ENNINGScumulative utility functions linear (see Pollak, 1976; Charness & Rabin, 2002;Sobel, 2005, forms utility functions interdependent preferences10 ). mentionedbefore, chose linear form reasons computational tractability.setting vector K functions P P b common knowledge negotiators. Also, agent knows type, opponent. addition, agentknows r, , n, m. words, symmetric uncertainty opponents utility(as see Section 6.4, results asymmetric case easily obtainedfollowing analysis symmetric case).6.1 Package Deal Procedurecumulative utilities defined Equations 22 23, Theorem 18 characterises equilibrium package deal.Theorem 18 package deal procedure, following strategies form sequential equilibrium. equilibrium strategies = n are:OFFER [n1 , 0] TURNa(i, n) =ACCEPTbs TURNOFFER [0, n1 ] bs TURNb(i, n) =ACCEPTTURN1 r. preceding time periods < n, [xt , ] denotes offer made time t,equilibrium strategies defined follows:OFFER tradeoffa1(K, , eub(, t), i, , m, t, P , P b ) TURNoffer gets rejected UPDATE BELIEFSa(i, t) =RECEIVE OFFER UPDATE BELIEFSbs TURN(Ui ([x , ], t) eua(i, t)) ACCEPT else REJECTOFFER tradeoffb1(K, , eua(, t), i, , m, t, P , P b ) bs TURNoffer gets rejected UPDATE BELIEFSb(i, t) =RECEIVE OFFER UPDATE BELIEFSTURN(Uib (xt , ], t) eub(i, t)) ACCEPT else REJECT1 r. Here, = opta(i, t) = optb(i, t). earliest possible time agreement= 1 latest possible time = min(2r 1, n).Proof: Theorem 8. difference independent issues setting Theorem 8present interdependent issues one terms definition cumulative utilities:Equations 5 6, coefficients positive (i.e., Kic > 0 1 r 1 c m).Equations 22 23, coefficient (Kic ) may positive negative real number.However, greedy method (given Theorem 1) solving fractional knapsack problemEquation 15 works positive negative coefficients (Martello & Toth, 1990; Cormen et al.,2003). Hence, proof Theorem 8 applies setting well.10. Although (Pollak, 1976; Charness & Rabin, 2002; Sobel, 2005) forms discussed contextagents utility depends utility agents, may equally well interpreted caseagents utility issue depends share issues.408fiM ULTI -I SSUE N EGOTIATIONEADLINESTheorem 19 time complexity computing equilibrium offers package deal procedure O(mr 3 (n T2 )) = min(2r 1, n).Proof: Theorem 11. Since method making tradeoffs settingsymmetric uncertainty independent issues (i.e., SUI ), time complexityTheorem 11.obvious Theorems 9 12 extend setting well.6.2 Simultaneous Procedurefollows results Section 4.2 apply setting well.6.3 Sequential Procedurealso follows results Section 4.3 apply setting well.6.4 Optimal Procedurefollows Theorem 13 package deal remains optimal procedure even issuesinterdependent. results setting Section 4 summarisedTable 3.Finally, consider asymmetric information setting Section 5 current contextinterdependent issues. analysis symmetric uncertainty interdependentissues, clear method making tradeoffs remains irrespective whetherinformation symmetric asymmetric. Consequently, case asymmetric informationinterdependent issues, get results Section 5.Recall analysis done linear cumulative utilities. discussresults would hold complex utility functions non-linear11 . cumulative utilitiesnonlinear, tradeoff problem becomes global optimization problem nonlinearobjective function. Due computational complexity, nonlinear optimization problemssolved using approximation methods (Horst & Tuy, 1996; Bar-Yam, 1997; Klein et al.,2003). contrast, tradeoff problem linear optimization problem, exact solutionfound polynomial time (as shown Theorems 1 2). Although resultsapply linear cumulative utilities, difficult see would hold nonlinearcase. First, time agreement case would hold (nonlinear) functions.time depends actual definition agents cumulative utilitiesinformation setting (i.e., whether information complete). Second, let O()denote time complexity TRADEOFFA 1 nonlinear utilities package deal = 1,O(c ) cth partition. Also, let Sz denote partition O(z )highest partitions. Then, know Theorem 11 time complexitypackage deal setting symmetric uncertainty O(r 3 (n T2 )). Consequently, timecomplexity simultaneous sequential procedures O(z r 3 (n T2 )). Third,package deal outcome additive cumulative utilities Pareto optimal, packagedeal outcome nonlinear utilities may Pareto optimal. (as stated above)11. Note bilateral bargaining players utility functions nonlinear studied Hoel (1986)context single issue opposed multi-issue case focus study.409fiFATIMA , W OOLDRIDGE , & J ENNINGSnonlinear optimization problems solved using approximation methods linearoptimization problem solved using exact method (as proof Theorem 1). Finally,since conditions unique solution depend actual definition cumulative utilities,conditions given Tables 1 2, 3, 4 may hold forms utility functions.7. Related WorkSince Schelling (1956) first noted fact outcome negotiation depends choicenegotiation procedure, much research effort devoted study different proceduresnegotiating multiple issues. instance, Fershtman (1990) extended model developedRubinstein (1982), splitting single pie, sequential negotiation two pies. However,model assumes complete information, imposes agenda exogenously, studies relationagenda outcome sequential bargaining game. detail, two piesdifferent sizes, analyses effect going first large small pie.number researchers also studied negotiations endogenous agenda (Inderst,2000; & Serrano, 2003; Bac & Raff, 1996). Inderst (2000) players discount factors,deadlines. independent issues, work assumes complete information studiesthree different negotiation procedures: package deal, simultaneous, sequential negotiationendogenous agenda. main result package deal optimal procedureprocedure exist multiple equilibria. Serrano (2003) extend work findingconditions equilibrium becomes unique. Note work differsanalyse negotiations discount factors deadlines, considermuch common automated negotiations. Moreover, independentinterdependent issues without making complete information assumption.Bac Raff (1996) also developed model endogenous agenda. extendedmodel developed Rubinstein (1985) single pie bargaining incomplete informationadding second pie. model, players discount factors, deadlines.size pie known agents discounting factor assumed equalissues agents. Also, asymmetric information: one players knowsdiscounting factor opponent, player knows discountingfactor, uncertain opponents. detail, factor take one two values, Hprobability x, L probability 1 x. probabilities common knowledge.model, authors determine equilibrium package deal sequential procedure.show that, certain conditions, sequential procedure optimal one. However,three key differences model ours. First, analyse symmetricasymmetric information settings, Bac Raff analyse latter. Second, negotiatorsmodel deadline, Bac Raff not. Again, believe analysiscovers situations often occur automated negotiation settings. Finally, Bac Raff focusindependent issues, analyse independent interdependent issues.slightly different approach (from ones) taken Busch Horstmann (1997).Again, extended model developed Rubinstein (1985), adding preliminary periodagents bargain agenda. outcome stage used agendanegotiating issues. complete information model, two pies bargaining.Furthermore, two issues become available negotiation different time points. playersdiscount factors fixed time costs, deadlines. Since two issues, two410fiM ULTI -I SSUE N EGOTIATIONEADLINESpossible agendas. outcome two agendas compared package deal.main result players may conflicting preferences optimal agenda. Notekey difference model issues model availablebeginning, model two issues become available different time points.Furthermore, Busch Horstman assume complete information, not.models mentioned above, perhaps one closest one developedInderst (2000). Unlike work, Inderst assumes complete information independent issues.Also, model player deadlines, do. However, Inderst model players timepreferences discount factors. Also, like model, issues negotiation availablebeginning negotiation. terms results, Inderst shows package dealoptimal procedure. study also shows package deal optimal procedureagents. Finally, work provides detailed analysis attributes different procedures(such time agreement, time complexity, Pareto optimality, conditionsuniqueness), Inderst not.summary, aforementioned models multi-issue negotiation differleast one three major ways. players model discount factors deadlines,general characteristic models players discount factorsdeadlines12 . Negotiation deadlines studied Sandholm Vulkan (1999) (incontext single issue) Fatima et al. (2004) sequential procedure = m. Giventhis, contribution lies firstly finding equilibrium three procedures. Second,analyse asymmetric symmetric information settings, previous work analysesformer. Third, analyse independent interdependent issues previous workfocuses primarily independent issues. Furthermore, existing literature comparedifferent multi-issue procedures terms attributes (viz. time complexity, Pareto optimality,uniqueness, time agreement). considering these, study allows informed choicemade wider range tradeoffs involved determiningappropriate procedure.Finally, would like point Fatima et al. (2006), considered independent issuescarried study work, symmetric information settinguncertainty negotiation deadline (as opposed uncertainty agents utility functions focus work). key result (Fatima et al., 2006) similar resultcurrent work, namely optimal procedure (Fatima et al., 2006) package deal.8. Conclusions Future Workpaper studied bilateral multi-issue negotiation self-interested agents wide rangesettings. player time constraints form deadlines discount factors. Specifically,considered independent interdependent issues studied three main multi-issueprocedures conducting negotiations: package deal, simultaneous procedure,sequential procedure. determined equilibria procedure two different informationsettings. first, symmetric uncertainty opponents utility. second,asymmetric uncertainty opponents utility. analysed settingscase independent interdependent issues. setting, compared outcomes12. (Fatima et al., 2004) studies multi-issue model deadlines, focuses determining equilibrium onespecific sequential procedure: one partition single issue.411fiFATIMA , W OOLDRIDGE , & J ENNINGSdifferent procedures showed package deal optimal agent. comparedthree procedures terms four attributes: time complexity procedure, Paretooptimality equilibrium solution, uniqueness equilibrium solution, timeagreement (see Table 1).detail, study shows package deal fact optimal procedureparty. also showed although package deal may computationally complextwo procedures, generates Pareto optimal outcomes (unlike two procedures),similar earliest latest possible times agreement simultaneous procedure (whichbetter sequential procedure), (like two procedures) generates uniqueoutcome certain conditions (which defined).several interesting directions extending current analysis. First, work,modelled players time preferences form discount factors commonbasis analysis. However, existing literature (Busch & Horstman, 1997) showsoutcome negotiation discount factors differ outcome negotiationfixed time costs. will, therefore, interesting extend results negotiations fixedtime costs. Second, present work analysed setting uncertainty utility functions.Generalisation results scenarios sources uncertainties agentsdiscount factors another direction future work.Acknowledgementsgrateful Sarit Kraus detailed comments earlier versions paper. alsothank anonymous referees; comments helped us substantially improve readabilityaccuracy paper.412fiM ULTI -I SSUE N EGOTIATIONEADLINESAppendix A. Summary Notationa, b two negotiating agents.n Negotiation deadline agents.Total number issues.set issues.Sc subset (Sc S).Number issues largest partition.Number partitions simultaneous sequential procedures.c Discount factor issue c (for 1 c m).element vector represents discount factor issues.xt element vector denotes share issues time t.element vector denotes bs share issues time t.[xt , ] package offered time t.atc Agent share issue c equilibrium offer time period t.btc Agent bs share issue c equilibrium offer time period t.element vector denotes share issues equilibrium time t.bt element vector denotes bs share issues equilibrium time t.[at , bt ] equilibrium package offered time t.Uia Cumulative utility function agent type i.Uib Cumulative utility function agent b type i.ua(t) Agent cumulative utility equilibrium offer time t.ub(t) Agent bs cumulative utility equilibrium offer time t.a(i, j, t) Agent equilibrium offer time type assuming b type j.b(i, j, t) Agent bs equilibrium offer time b type assuming type j.a(i, t) Equilibrium strategy agent type time t.b(i, t) Equilibrium strategy agent b type time t.eua(i, t) Cumulative utility agent type expects get bs equilibrium offertime (i.e., receiving agent b offering agent t).413fiFATIMA , W OOLDRIDGE , & J ENNINGSeub(i, t) Cumulative utility agent b type expects get equilibrium offertime (i.e., b receiving agent offering agent t).eua(i, j, t) Agent expected cumulative utility equilibrium offer time typeassuming b type j.eub(i, j, t) Agent bs expected cumulative utility equilibrium offer time b typeassuming type j.r Number types agent (and also number types agent b).Tta Set possible types agent time t.Ttb Set possible types agent b time t.P probability distribution function ka .P b probability distribution function kb .K vector r vectors element turn vector positive reals.Spij subset (Spij denotes type j b) |Spij | > 1KidKic.=Kc,dSpij Kjcjdtradeoffa Agent function making tradeoffs complete information setting.tradeoffb Agent bs function making tradeoffs complete information setting.tradeoffa1 Agent function making tradeoffs four incomplete information settings:SUI , SUD , AUI , AUD .tradeoffb1 Agent bs function making tradeoffs four incomplete information settings:SUI , SUD , AUI , AUD .Maximum number packages tradeoffa1 (or tradeoffb1) search findone maximises (or bs) expected cumulative utility (considering possible typesb).paijset possible packages tradeoffa1 return time (i denotes typej b).pbijset possible packages tradeoffb1 return time (i denotes typej b).ReferencesBac, M., & Raff, H. (1996). Issue-by-issue negotiations: role information time preference.Games Economic Behavior, 13, 125134.Bar-Yam, Y. (1997). Dynamics Complex Systems. Addison Wesley.414fiM ULTI -I SSUE N EGOTIATIONEADLINESBinmore, K., Osborne, M. J., & Rubinstein, A. (1992). Noncooperative models bargaining.Aumann, R. J., & Hart, S. (Eds.), Handbook Game theory Economic Applications,Vol. 1, pp. 179225. North-Holland.Busch, L. A., & Horstman, I. J. (1997). Bargaining frictions, bargaining procedures impliedcosts multiple-issue bargaining. Economica, 64, 669680.Charness, G., & Rabin, M. (2002). Understanding social preferences simple tests. Quarterly Journal Economics, 117(3), 817869.Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2003). introduction algorithms.MIT Press, Cambridge, Massachusetts.Faratin, P., Sierra, C., & Jennings, N. R. (2002). Using similarity criteria make trade-offsautomated negotiations. Artificial Intelligence Journal, 142(2), 205237.Fatima, S. S., Wooldridge, M., & Jennings, N. R. (2002). influence information negotiation equilibrium. Agent Mediated Electronic Commerce IV, Designing MechanismsSystems, No. 2531 LNCS, pp. 180 193. Springer Verlag.Fatima, S. S., Wooldridge, M., & Jennings, N. R. (2004). agenda based framework multiissue negotiation. Artificial Intelligence Journal, 152(1), 145.Fatima, S. S., Wooldridge, M., & Jennings, N. R. (2006). efficient procedures multi-issue negotiation. Proceedings Eighth International Workshop Agent Mediated ElectronicCommerce (AMEC), pp. 7185, Hakodate, Japan.Fershtman, C. (1990). importance agenda bargaining. Games Economic Behavior,2, 224238.Fershtman, C. (2000). note multi-issue two-sided bargaining: bilateral procedures. GamesEconomic Behavior, 30, 216227.Fershtman, C., & Seidmann, D. J. (1993). Deadline effects inefficient delay bargainingendogenous commitment. Journal Economic Theory, 60(2), 306321.Fishburn, P. C. (1988). Normative thoeries decision making risk uncertainty.Bell, D. E., Raiffa, H., & Tversky, A. (Eds.), Decision making: Descriptive, normative,prescriptive interactions. Cambridge University Press.Fisher, R., & Ury, W. (1981). Getting yes: Negotiating agreement without giving in. HoughtonMifflin, Boston.Fudenberg, D., Levine, D., & Tirole, J. (1985). Infinite horizon models bargaining one sidedincomplete information. Roth, A. (Ed.), Game Theoretic Models Bargaining. UniversityCambridge Press, Cambridge.Fudenberg, D., & Tirole, J. (1983). Sequential bargaining incomplete information. ReviewEconomic Studies, 50, 221247.Harsanyi, J. C. (1977). Rational behavior bargaining equilibrium games social situations. Cambridge University Press.Harsanyi, J. C., & Selten, R. (1972). generalized Nash solution two-person bargaining gamesincomplete information. Management Science, 18(5), 80106.415fiFATIMA , W OOLDRIDGE , & J ENNINGSHoel, M. (1986). Perfect equilibria sequential bargaining games nonlinear utility functions.Scandinavian Journal Economics, 88(2), 383400.Horst, R., & Tuy, H. (1996). Global optimazation: Deterministic approaches. Springer.In, Y., & Serrano, R. (2003). Agenda restrictions multi-issue bargaining (ii): unrestricted agendas.Economics Letters, 79, 325331.Inderst, R. (2000). Multi-issue bargaining endogenous agenda. Games Economic Behavior, 30, 6482.Keeney, R., & Raiffa, H. (1976). Decisions Multiple Objectives: Preferences Value Tradeoffs. New York: John Wiley.Klein, M., Faratin, P., Sayama, H., & Bar-Yam, Y. (2003). Negotiating complex contracts. IEEEIntelligent Systems, 8(6), 3238.Kraus, S. (2001). Strategic negotiation multi-agent environments. MIT Press, Cambridge,Massachusetts.Kraus, S., Wilkenfeld, J., & Zlotkin, G. (1995). Negotiation time constraints. ArtificialIntelligence Journal, 75(2), 297345.Kreps, D. M., & Wilson, R. (1982). Sequential equilibrium. Econometrica, 50, 863894.Lax, D. A., & Sebenius, J. K. (1986). manager negotiator: Bargaining cooperationcompetitive gain. Free Press, New York.Livne, Z. A. (1979). role time negotiation. Ph.D. thesis, Massachusetts InstituteTechnology.Lomuscio, A., Wooldridge, M., & Jennings, N. R. (2003). classification scheme negotiationelectronic commerce. International Journal Group Decision Negotiation, 12(1),3156.Ma, C. A., & Manove, M. (1993). Bargaining deadlines imperfect player control. Econometrica, 61, 13131339.Maes, P., Guttman, R., & Moukas, A. (1999). Agents buy sell. CommunicationsACM, 42(3), 8191.Martello, S., & Toth, P. (1990). Knapsack problems: Algorithms computer implementations.John Wiley Sons. Chapter 2.Mas-Colell, A., Whinston, M. D., & Green, J. R. (1995). Microeconomic Theory. Oxford UniversityPress.Muthoo, A. (1999). Bargaining Theory Applications. Cambridge University Press.Neumann, J. V., & Morgenstern, O. (1947). Theory Games Economic Behavior. Princeton:Princeton University Press.Osborne, M. J., & Rubinstein, A. (1990). Bargaining Markets. Academic Press, San Diego,California.Osborne, M. J., & Rubinstein, A. (1994). Course Game Theory. MIT Press.Pollak, R. A. (1976). Interdependent preferences. American Economic Review, 66(3), 309320.416fiM ULTI -I SSUE N EGOTIATIONEADLINESPruitt, D. G. (1981). Negotiation Behavior. Academic Press.Raiffa, H. (1982). Art Science Negotiation. Harvard University Press, Cambridge, USA.Rosenschein, J. S., & Zlotkin, G. (1994). Rules Encounter. MIT Press.Rubinstein, A. (1982). Perfect equilibrium bargaining model. Econometrica, 50(1), 97109.Rubinstein, A. (1985). bargaining model incomplete information time preferences.Econometrica, 53, 11511172.Sandholm, T. (2000). Agents electronic commerce: component technologies automated negotiation coalition formation.. Autonomous Agents Multi-Agent Systems, 3(1), 7396.Sandholm, T., & Vulkan, N. (1999). Bargaining deadlines. AAAI-99, pp. 4451, Orlando,FL.Schelling, T. C. (1956). essay bargaining. American Economic Review, 46, 281306.Schelling, T. C. (1960). strategy conflict. Oxford University Press.Sobel, J. (2005). Interdependent preferences reciprocity. Journal Economic Literature, XLIII,392436.Stahl, I. (1972). Bargaining Theory. Economics Research Institute, Stockholm School Economics, Stockholm.van Damme, E. (1983). Refinements Nash equilibrium concept. Berlin:Springer-Verlag.Varian, H. R. (2003). Intermediate Microeconomics. W. W. Norton Company.Young, O. R. (1975). Bargaining: Formal theories negotiation. Urbana: University IllinoisPress.417fiJournal Artificial Intelligence Research 27 (2006) 505549Submitted 06/06; published 12/06Resource Allocation Among Agents MDP-InducedPreferencesDmitri A. Dolgovddolgov@ai.stanford.eduTechnical Research Department (AI & Robotics Group)Toyota Technical Center2350 Green RoadAnn Arbor, MI 48105, USAEdmund H. Durfeedurfee@umich.eduElectrical Engineering Computer ScienceUniversity Michigan2260 Hayward St.Ann Arbor, MI 48109, USAAbstractAllocating scarce resources among agents maximize global utility is, general, computationally challenging. focus problems resources enable agents executeactions stochastic environments, modeled Markov decision processes (MDPs),value resource bundle defined expected value optimal MDPpolicy realizable given resources. present algorithm simultaneously solvesresource-allocation policy-optimization problems. allows us avoid explicitly representing utilities exponentially many resource bundles, leading drastic(often exponential) reductions computational complexity. use algorithmcontext self-interested agents design combinatorial auction allocating resources. empirically demonstrate effectiveness approach showingcan, minutes, optimally solve problems straightforward combinatorialresource-allocation technique would require agents enumerate 2100 resourcebundles auctioneer solve NP-complete problem input size.1. Introductionproblem resource allocation ubiquitous many diverse research fieldseconomics, operations research, computer science, applications ranging decentralized scheduling (e.g., Wellman, Walsh, Wurman, & MacKie-Mason, 2001) network routing (e.g., Feldmann, Gairing, Lucking, Monien, & Rode, 2003) transportationlogistics (e.g., Sheffi, 2004; Song & Regan, 2002) bandwidth allocation (e.g., McMillan,1994; McAfee & McMillan, 1996), name few. core question resource allocation distribute set scarce resources among set agents (either cooperativeself-interested) way maximizes measure global utility, social welfare(sum agents utilities) one popular criteria.many domains, agents utility obtaining set resources definedagent accomplish using resources. example, value vehicledelivery agent defined additional revenue agent obtain usingvehicle. However, figure best utilize resource (or set resources), agentc2006AI Access Foundation. rights reserved.fiDolgov & DurfeeAvailableResourcesAvailableActionsResource-AllocationProblemPlanning Problem(MDP)Utility FunctionResourcesBest Plan &PayoffFigure 1: Dependency Cycle: formulate planning problems, agents needknow resources get, utility functions, defineinput resource-allocation problem, depend solutions planningproblems.often must solve non-trivial planning problem actions might long-term, nondeterministic effects. Therefore, agents value set resources defined solutionplanning problem, formulate planning problem agent needs knowresources obtain. leads cyclic dependencies (depicted Figure 1), whereininput resource allocation problem depends solution planning problem,vice versa. Unfortunately, anything simplest domains, neither resourceallocation planning problem solved closed form, making impossibleobtain parameterized solutions.focus paper solving interdependent problems resource allocationstochastic planning. main question consider allocate resourcesway maximizes social welfare agents utility function agentdefined Markov decision process (Puterman, 1994) whose action set parameterizedresources. paper, specifically focus non-consumable resources (suchvehicles) enable actions, consumed action execution.briefly mention case consumable resources Section 6, refer workDolgov (2006) detailed treatment.assume agents MDPs weakly-coupled, meaning agents interactresources, resources allocated, transition rewardfunctions MDPs independent. model weakly-coupled MDPs connectedvia shared resources similar Meuleau, Hauskrecht, Kim, Peshkin, Kaelbling,Dean, Boutilier (1998) Benazera, Brafman, Meuleau, Hansen (2005),differs assume resources allocated once, prior actionstaken. one-shot allocation assumption limits approach somewhat,also allows approach apply broadly non-cooperative settings (withoutassumption, game-theoretic analysis agents interactions significantlycomplex). importantly, allows us avoid state space explosion (due includingresource information MDP states), limits work findingapproximately optimal solutions non-trivial problems.main result presented paper thus new algorithm that,conditions, optimally solves resource-allocation policy-optimization problemssimultaneously. considering two problems together, sidesteps dependency cycle506fiResource Allocation Among Agents MDP-Induced Preferencesmentioned above, allows us avoid explicit representation utility functionsresource bundles, leading exponential reduction complexity combinatorialresource allocation flat utility functions. empirically demonstrate resultingalgorithm scales well finding optimal solutions problems involving numerous agentsresources.algorithm viewed contributing new approach dealing computational complexity resource allocation domains complex utility functionslinearly decomposable resources (due effects substitutabilitycomplementarity). combinatorial allocation problems, finding optimal allocation NP-complete (often exponentially large) space resource bundles (Rothkopf,Pekec, & Harstad, 1998). Previous approaches addressing complexity includeddetermining classes utility functions lead tractable problems (as surveyedde Vries & Vohra, 2003), iterative algorithms resource allocation preference elicitation (as surveyed Sandholm & Boutilier, 2006), concise languages expressingagents preferences (Sandholm, 1999; Nisan, 2000; Boutilier & Hoos, 2001; Boutilier, 2002).novelty approach respect explicitly embraces underlying processes define agents utility functions, cases processesmodeled resource-parameterized MDPs. so, approach useMDP-based models concise language agents utility functions, importantly, directly exploits structure models drastically reduce computationalcomplexity simultaneously solving planning resource-allocation problems.context cooperative agents, approach viewed way solvingweakly-coupled multiagent MDPs, agents transition reward functions independent, space joint actions constrained, as, example, models usedSingh Cohn (1998) Meuleau et al. (1998). perspective, conceptresources viewed compact way representing interactions agents,similarly model used Bererton, Gordon, Thrun (2003); however, workdiffers number assumptions. Moreover, algorithms easily modified workmodels constraints joint actions modeled directly (for example,via SAT formulas).non-cooperative agents, apply resource-allocation algorithm mechanismdesign problem (e.g., Mas-Colell, Whinston, & Green, 1995), goal allocateresources among agents way maximizes social welfare, givenparticipating agent selfishly maximizing utility. domains self-interestedagents complex preferences exhibit combinatorial effects resources,combinatorial auctions (e.g., de Vries & Vohra, 2003) often used resource-allocation.Generalized Vickrey Auction (GVA) (MacKie-Mason & Varian, 1994), extension Vickrey-Clarke-Groves (VCG) mechanisms (Vickrey, 1961; Clarke, 1971; Groves,1973) combinatorial auctions, particularly attractive nice analyticalproperties (as described Section 4.1). develop variant VCG auction,agents submit resource-parameterized MDPs bids, auctioneer simultaneously solves resource-allocation policy-optimization problems, thus retainingcompact representation agents preferences throughout process. describe extensions mechanism distributing computation encoding MDP informationreduce revelation private information.507fiDolgov & Durfeeremainder paper proceeds follows. brief review MDPsSection 2, present (in Section 3) model decision-making agent: resourceparameterized MDP capacity constraints. analyze problem optimal policyformulation resource-parameterized capacity-constrained MDP, study properties, present solution algorithm, based formulation (NP-complete)problem mixed integer program.building blocks, move multiagent setting present mainresult, algorithm simultaneously allocating resources planning across agents(Section 4). Based algorithm, design combinatorial auction allocatingresources among self-interested agents. describe distributed implementationmechanism, discuss techniques preserving information privacy. Section 5,analyze computational efficiency approach, empirically demonstrating exponential reductions computational complexity, compared straightforward combinatorialresource-allocation algorithm flat utility functions. Finally, Section 6, concludediscussion possible generalizations extensions approach. concisenessbetter readability, proofs generalizations deferred appendices.2. Markov Decision Processesbase model agents decision problems infinite-horizon fully-observable MDPstotal expected discounted reward optimization criterion (although resultsalso applicable classes MDPs, MDPs average per-step rewards).section introduces notation assumptions, serves brief overviewbasic MDP results (see, example, text Puterman (1994) detailed discussionmaterial section).classical single-agent, unconstrained, stationary, fully-observable MDP defined4-tuple hS, A, p, ri, where:finite set states agent in.finite set actions agent execute.p : 7 [0, 1] defines transition function. probability agentgoes state upon execution action state p(|s, a).P assume that, action, corresponding transition matrix stochastic:p(|s, a) = 1 S, A.r : 7 R defines reward function. agent obtains reward r(s, a)executes action state S. assume rewards bounded.discrete-time fully-observable MDP, time step, agent observes currentstate system chooses action according policy. policy saidMarkovian (or history-independent) choice action depend historystates actions encountered past, rather current statetime. If, addition that, policy depend time, called stationary.definition, stationary policy always Markovian. deterministic policy always prescribesexecution action state, randomized policy chooses actionsaccording probability distribution.508fiResource Allocation Among Agents MDP-Induced PreferencesFollowing standard notation (Puterman, 1994), refer different classes policiesxy , x = {H, M, S} specifies whether policy History-dependent, Markovian,Stationary, = {R, D} specifies whether policy Randomized Deterministic(e.g., class stationary deterministic policies labeled SD ). Obviously, HySy xR xD , history-dependent randomized policies HR stationarydeterministic policies SD least general, respectively.stationary randomized policy thus mapping states probability distributionsactions: : 7 [0, 1], (s, a) defines probability actionexecuted state s. stationary deterministic policy viewed degenerate caserandomized policy one action state nonzeroprobability executed.unconstrained discounted MDP, goal find policy maximizestotal expected discounted reward infinite time horizon:1hXU (, ) = E()t rt (, ) ,(1)t=0[0, 1) discount factor (a unit reward time + 1 worthagent reward time t), rt (random) reward agent receives time t,whose distribution depends policy initial distribution state space: 7 [0, 1].One important results theory MDPs states that, unconstrained discounted MDP total expected reward optimization criterion, always exists optimal policy stationary, deterministic, uniformly optimal,latter term means policy optimal distributions starting state.2several commonly-used ways finding optimal policy, centralconcept value function policy, v : 7 R, v (s) expectedcumulative value reward agent would receive started state behavedaccording policy . given policy , value every state unique solutionfollowing system |S| linear equations:XXv (s) =r(s, a)(s, a) +p(|s, a)v (),S.(2)find optimal policy, handy consider optimal value function v : 7 R,v (s) represents value state s, given agent behaves optimally.optimal value function satisfies following system |S| nonlinear equations:hXv (s) = max r(s, a) +p(|s, a)v () ,S.(3)v,Given optimal value functionoptimal policy simply act greedily respectv (with method tie-breaking case multiple optimal actions):h(P1 arg maxa r(s, a) + p(|s, a)v () ,(s, a) =(4)0 otherwise.1. Notation: (x)y exponent, xy superscript.2. Uniform optimality policies reason included component textbook MDP.509fiDolgov & DurfeeOne possible ways solving optimal value function formulatenonlinear system (3) linear program (LP) |S| optimization variables v(s)|S||A| constraints:Xmin(s)v(s)subject to:(5)v(s) r(s, a) +Xp(|s, a)v(),S, A,arbitrary constant vector |S| positive components ((s) > 0 S).3many problems (including ones focus paper), useful consider equivalent dual LP |S||A| optimization variables x(s, a) |S|constraints:4XXr(s, a)x(s, a)maxxsubject to:XXXx(, a)x(s, a)p(|s, a) = (),(6)S;x(s, a) 0S, A.optimization variables x(s, a) often called visitation frequencies occupation measure policy. think initial probability distribution, x(s, a)interpretedP total expected number times action executed state s.Then, x(s) = x(s, a) gives total expected flow state s, constraintsLP interpreted conservation flow states.optimal policy computed solution dual LP as:x(s, a),(7)(s, a) = Px(s, a)Pnon-negativity guarantees x(s, a) > 0 S. general, appearslead randomized policies. However, bounded LP n constraints always basicfeasible solution (e.g., Bertsimas & Tsitsiklis, 1997), definitionn non-zero components. strictly positive, basic feasible solution LP (7)precisely |S| nonzero components (one state), guarantees existenceoptimal deterministic policy. policy easily obtained LP solvers(e.g., simplex always produce solutions map deterministic policies).Furthermore, mentioned above, unconstrained discounted MDPs, alwaysexist policies uniformly optimal (optimal initial distributions).dual LP (6) yields uniformly optimal policies strictly positive used. However,3. overloading objective function coefficients initial probability distributionMDP earlier intentional explained shortly.4. Note authors (e.g., Altman, 1996) prefer opposite convention, (6) called dual,(5), primal.510fiResource Allocation Among Agents MDP-Induced Preferencessolution (x) dual LP retains interpretation expected number times statevisited action executed initial probability distributionused LP.main benefit dual LP (6) manifested constrained MDPs (Altman, 1999;Kallenberg, 1983; Heyman & Sobel, 1984), action, addition producingreward r(s, a), also incurs vector costs k (s, a) : 7 R k [1..K]. problem maximize expected reward, subject constraints expected costs.Constrained models type arise many domains, telecommunication applications (e.g., Ross & Chen, 1988; Ross & Varadarajan, 1989), often desirablemaximize expected throughput, subject conditions average delay. problems,constraints imposed expected costs, solved polynomial timeusing linear programming simply augmenting dual LP (6) following linearconstraints:XXk (s, a)x(s, a) bk ,k [1..K],(8)bk upper bound expected cost type k. resulting constrained MDPdiffers standard unconstrained MDP: particular, deterministic policieslonger optimal, uniformly optimal policies not, general, exist problems(Kallenberg, 1983).reason easily augmentable constraints, dual LP (6) alsoforms basis approach. However, constraints arise resource-allocationproblems focus paper different linear constraints (8),leading different optimization problems different properties requiring differentsolution techniques (as described detail Section 3).conclude background section introducing simple unconstrained MDPserve basis running example, refer throughout restpaper.Example 1 Consider simple delivery domain, depicted Figure 2, agentobtain rewards delivering furniture (action a1 ) delivering appliances (action a2 ).Delivering appliances produces higher rewards (as shown diagram),damage delivery vehicle. agent delivers furniture, damage vehiclenegligible, whereas agent delivers appliances, vehicle guaranteed functionreliably first year (state s1 ), (state s2 ) 10% probability failure,per year. vehicle serviced (action a3 ), resetting condition, expenselowering profits. truck break (state s3 ), repaired (action a4 ),significant negative impact profits. assume discount factor = 0.9.optimal value function v (s1 ) 95.3, v (s2 ) 94.7, v (s3 ) 86.7,corresponding optimal occupation measure (assuming uniform ) following (listingnon-zero elements): x(s1 , a2 ) 4.9, x(s2 , a3 ) 4.8, x(s3 , a4 ) 0.3. mapsoptimal policy dictates agent start delivering appliances (action a2state s1 ), service vehicle first year (action a3 state s2 ), fixvehicle ever gets broken (a4 s3 ) (the latter zero probability happeningpolicy agent starts state s1 s2 ).511fiDolgov & Durfeea1: deliver furniturep=1r=5s1(initial)a4: fix truckp=1r=1a1: deliver furniturep=1r=5a2: deliver appliancesp=1r=10a3: service truckp=1r=9s2(2nd year)a2: deliver appliancesp=0.9r=10p=0.1r=10s3(truck broken)Figure 2: Unconstrained MDP example delivery domain. Transition probabilities (p)rewards (r) shown diagram. Actions shown result transitionstate reward. also noop action a0 correspondsnothing; change state produces zero reward.3. Agent Model: Resource-Parameterized MDPsection, introduce model decision-making agent, describesingle-agent stochastic policy-optimization problem defines agents preferencesresources. show that, single-agent problem, formulated MDP whoseaction set parameterized resources available agent, stationary deterministicpolicies optimal, uniformly optimal policies not, general, exist. also showproblem finding optimal policies NP-complete. Finally, present policyoptimization algorithm, based formulation problem mixed integer linearprogram (MILP).model agents resource-parameterized MDP follows. agent setactions potentially executable, action requires certain combinationresources. capture local constraints sets resources agent use, useconcept capacities: resource capacity costs associated it,agent capacity constraints. example, delivery company needs vehicles loadingequipment (resources allocated) make deliveries (execute actions). However,equipment costs money requires manpower operate (the agents local capacitycosts). Therefore, amount equipment agent acquire successfully utilizeconstrained factors budget limited manpower (agents local capacitybounds). two-layer model capacities resources represented separately mightseem unnecessarily complex (why fold together impose constraints directlyresources?), separation becomes evident useful multiagent modeldiscussed Section 4. emphasize difference here: resources itemsallocated among agents, capacities define inherent limitations individualagent combinations resources usefully possess.agents optimization problem choose subset available resourcesviolate capacity constraints, best policy feasible bundleresources yields highest utility. words, single-agent problem analyzed512fiResource Allocation Among Agents MDP-Induced Preferencessection constraints total resource amounts (they introducedmultiagent problem next section), constraints due agentscapacity limits. Adding limited resource amounts single-agent model wouldsimple matter, since constraints handled simple pruning agentsaction space. Further, note without capacity constraints, single-agent problemwould trivial, would always optimal agent simply take resourcespotential use. However, presence capacity constraints, face problemsimilar cyclic dependency Figure 1: resource-selection problem requiresknowing values resource bundles, defined planning problem,planning problem ill-defined resource bundle chosen. section,focus single-agent problem selecting optimal subset resources satisfiesagents capacity constraints assume agent value acquiring additionalresources exceed capacity bounds.resources model outlined non-consumable, i.e., actions requireresources consume execution. mentioned Introduction,work focus non-consumable resources, briefly outline caseconsumable resources Section 6.model agents optimization problem n-tuple hS, A, p, r, O, , C, ,b, i:hS, A, p, ri standard components MDP, defined earlier Section 2.set resources (e.g., = {production equipment, vehicle, . . .}). userefer resource type.: 7 R function specifies resource requirements actions;(a, o) defines much resource action needs executable (e.g.,(a, vehicle) = 1 means action requires one vehicle).C set capacities agent (e.g., C = {space, money, manpower, . . .}).use c C refer capacity type.: C 7 R function specifies capacity costs resources; (o, c) definesmuch capacity c C unit resource requires (e.g., (vehicle, money) =$50000 defines monetary cost vehicle, (vehicle, manpower) = 2 meanstwo people required operate vehicle).b : C 7 R specifies upper bound capacities;b(c) gives upper boundcapacity c C (e.g.,b(money) = $1,000,000 defines budget constraint,b(manpower) = 7 specifies size workforce).: 7 R initial probability distribution; (s) probability agentstarts state s.goal find policy yields highest expected reward, conditions resource requirements policy exceed capacity bounds513fiDolgov & Durfeeagent. words, solve following mathematical program:5max U (, )subject to:nXX(o, c) max (a, o)H(s, a)b(c),(9)c C,H Heaviside step function nonnegative argument, defined as:(0 z = 0,H(z) =1 z > 0.constraint (9) interpreted follows. argument H nonzerothePpolicy assigns nonzero probability using action least one state. Thus,functionH( (s, a)) serves indicatorus whether agent plans useP tellsaction policy, max (a, o)H( (s, a)) tells us much resourceagent needs policy. take max respect a, resourceused different actions. Therefore, summed resources o, left-handside gives us total requirements policy terms capacity c,greater boundb(c).following example illustrates single-agent model.Example 2 Let us augment Example 1 follows. Suppose agents needs obtaintruck perform delivery actions (a1 a2 ). truck also required servicerepair actions (a3 a4 ). Further, deliver appliances, agent needs acquireforklift, needs hire mechanic able repair vehicle (a4 ). noopaction a0 requires resources. maps model three resources (truck, forklift,mechanic): = {ot , , om }, following action resource costs (listingnon-zero ones):(a1 , ot ) = 1, (a2 , ot ) = 1, (a2 , ) = 1, (a3 , ot ) = 1, (a4 , ot ) = 1, (a4 , om ) = 1.Moreover, suppose resources (truck ot , forklift , mechanic om )following capacity costs (there one capacity type, money: C = {c1 })(ot , c1 ) = 2, (of , c1 ) = 3, (om , c1 ) = 4,agent limited budgetb = 8. can, therefore acquire twothree resources, means optimal solution unconstrained problemExample 1 longer feasible.Let us observe MDP-based model agents preferences presentedfully general discrete indivisible resources, i.e., non-decreasing utility functionresource bundles represented via resource-constrained MDP model describedabove.5. formulation assumes stationary policy, supported argument Section 3.1.514fiResource Allocation Among Agents MDP-Induced PreferencesTheorem 1 Consider finite set n indivisible resources = {oi } (i [1, n]),N available units resource. Then, non-decreasing utility functiondefined resource bundles f : [0, m]n 7 R, exists resource-constrained MDPhS, A, p, r, O, , C, ,b, (with resource set O) whose induced utility functionresource bundles f . words, every resource bundle z [0, m]n ,value optimal policy among whose resource requirements exceed z(call set (z)) f (z):f : [0, m]n 7 R, hS, A, p, r, O, , C, ,b, :n fihXfiz [0, m]n , (z) = fi max (a, oi )H(s, a) zi = max U (, ) = f (z).(z)Proof: See Appendix A.1.Let us comment Theorem 1 establishes generality MDP-based preference model introduced section, construction used proof little practical interest, requires MDP exponentially large state action space. Indeed,advocate mapping arbitrary unstructured utility functions exponentially-largeMDPs general solution technique. Rather, contention techniques apply domains utility functions induced stochastic decision-making process(modeled MDP), thus resulting well-structured preferences resourcesexploited drastically lower computational complexity resource-allocationalgorithms.3.1 Properties Single-Agent Constrained MDPsection, analyze constrained policy-optimization problem (9). Namely,show stationary deterministic policies optimal problem, meaningnecessary consider randomized, history-dependent policies. However, solutionsproblem (9) not, general, uniformly optimal (optimal initial distribution).Furthermore, show (9) NP-hard, unlike unconstrained MDPs,solved polynomial time (Littman, Dean, & Kaelbling, 1995).begin showing optimality stationary deterministic policies (9).following, use HR refer class history-dependent randomized policies (thegeneral policies), SD HR refer class stationary deterministicpolicies.Theorem 2 Given MDP = hS, A, p, r, O, , C, ,b, resource capacityHRconstraints, exists policyfeasible solution , existsstationary deterministic policy SD SD also feasible, expected total rewardSD less :HR , SD SD : U ( SD , ) U (, )Proof: See Appendix A.2.result Theorem 2 surprising: intuitively, stationary deterministicpolicies optimal, history dependence increase utility policy,515fiDolgov & Durfeeusing randomization increase resource costs. latter true including action policy incurs costs terms resources regardlessprobability executing action (or expected number times actionexecuted). true dealing non-consumable resources; property hold MDPs consumable resources (as discuss detailSection 6).show uniformly optimal policies always exist constrainedproblem. result well known another class constrained MDPs, constraintsimposed total expected costs proportional expected numbertimes corresponding actions executed (discussed earlier Section 2). MDPsconstraints arise, example, bounds imposed expected usageconsumable resources, mentioned Section 2, problems solved usinglinear programming augmenting dual LP (6) linear constraints expectedcosts (8). Below, establish result problems non-consumable resourcescapacity constraints.Observation 1 always exist uniformly optimal solutions (9).words, exist two constrained MDPs differ initial conditions: =hS, A, p, r, O, , C, ,b, 0 = hS, A, p, r, O, , C, ,b, 0 i, policyoptimal problems simultaneously, i.e., two policies 0optimal solutions 0 , respectively, following holds:U (, ) > U ( 0 , ),U (, 0 ) < U ( 0 , 0 )(10)demonstrate observation example.Example 3 Consider resource-constrained problem Example 2. easy seeinitial conditions = [1, 0, 0] (the agent starts state s1 certainty),optimal policy states s1 s2 Example 1 (s1 a2 s2 a3 ),which, given initial conditions, results zero probability reaching state s3 (tonoop a0 assigned). policy requires truck forklift. However,agent starts state s3 ( = [0, 0, 1]), optimal policy fix truck (execute a4s3 ), resort furniture delivery (do a1 s1 assign noop ao s2 ,never visited). policy requires mechanic truck. two policiesuniquely optimal corresponding initial conditions, suboptimal initialconditions, demonstrates uniformly optimal policy exists example.intuition behind fact uniformly optimal policies not, general, existconstrained MDPs since resource information part MDP statespace, constraints imposed resource usage, principle Bellman optimality hold (optimal actions different states cannot chosen independently).Given constrained MDP, possible construct equivalent unconstrained MDPstandard properties optimal solutions (by folding resource informationstate space, modeling resource constraints via transition function), resultingstate space exponential number resources.analyze computational complexity optimization problem (9).516fiResource Allocation Among Agents MDP-Induced PreferencesTheorem 3 following decision problem NP-complete. Given instance MDPhS, A, p, r, O, , C, ,b, resources capacity constraints, rational number ,exist feasible policy , whose expected total reward, given , less ?Proof: See Appendix A.3.Note complexity result stems limited capacities agentsfact define resource requirements policy set resourcesneeded carry actions nonzero probability executed. If,however, defined constraints expected resource requirements, actionslow probability executed would lower resource requirements, optimal policieswould randomized, problem would equivalent knapsack continuouslydivisible items, solvable polynomial time via LP formulation MDPslinear constraints (6,8).3.2 MILP Solutionanalyzed properties optimization problem (9), presentformulation (9) mixed integer linear program (MILP). Given establishedNP-completeness (9) previous section, MILP (also NP-complete) reasonableformulation allows us reap benefits vast selection efficient algorithmstools (see, example, text Wolsey, 1998 references therein).section rest paper assume resource requirementsactions binary, i.e., (a, o) = {0, 1}. make assumption simplifydiscussion, limit generality results. briefly describe casenon-binary resource costs Appendix B completeness, refer workDolgov (2006) detailed discussion examples.Let us rewrite (9) occupation measure coordinates x adding constraints(9) standard LP occupancy coordinates (6). Noticing (for statesnonzero probability visited) (s, a) x(s, a) either zero nonzero simultaneously:XXx(s, a) ,A,(s, a) = HHthat, (a, o) = {0, 1}, total resource requirements policy simplifiedfollows:XnXXmax (a, o)Hx(s, a) = H(a, o)x(s, a) ,O,(11)get following program x:XXmaxx(s, a)r(s, a)xsubject to:XXXx(, a)x(s, a)p(|s, a) = (),X(o, c)HXS;(a, o)Xx(s, a)b(c),c C;x(s, a) 0,S, A.517(12)fiDolgov & Durfeechallenge solving mathematical program constraints nonlineardue Heaviside function H.linearize Heaviside function, augment originalvariablesPoptimizationxPset |O| binary variables (o) {0, 1}, (o) = H(a, o)x(s, a) .words, (o) indicator variable shows whether policy requires resource o.Using (o), rewrite resource constraints (12) as:X(o, c)(o)b(c),c C,(13)linear . synchronize x via following linear inequalities:XX1/X(a, o)x(s, a) (o),O,(14)PPX maxo (a, o) x(s, a) normalization constant, upper bound argument H() used. bound X guaranteedexistP1 max(a,o),sincediscountedproblems.example,useX=(1)P1x valid occupation measure MDPs,a x(s, a) = (1 )6discount factor .Putting together, problem (9) finding optimal policies resource constraints formulated following MILP:XXmaxx(s, a)r(s, a)x,subject to:XXXx(, a)x(s, a)p(|s, a) = (),XS;(o, c)(o)b(c),c C;XO;(15)1/X(a, o)Xx(s, a) (o),x(s, a) 0,S, A;(o) {0, 1},O.illustrate MILP construction example.Example 4 Let us formulate MILP constrained problem Example 3. Recall problem three resources = {ot , , om } (truck, forklift,mechanic), one capacity type C = {c1 } (money), actions following resourcerequirements (again, listing nonzero ones):(a1 , ot ) = 1, (a2 , ot ) = 1, (a2 , ) = 1, (a3 , ot ) = 1, (a4 , ot ) = 1, (a4 , om ) = 1PP6. Instead using single X resources, different X(o) (a, o) x(s, a) usedevery resource, leading uniform normalization potentially better numerical stabilityMILP solver.518fiResource Allocation Among Agents MDP-Induced Preferencesresources following capacity costs:(ot , c1 ) = 2,(of , c1 ) = 3,(om , c1 ) = 4,agent limited budget, i.e., capacity bound,b(c1 ) = 8.compute optimal policy arbitrary , formulate problemMILP described above. Using binary variables (o) = {(ot ), (of ), (om )},express constraint capacity cost following inequality:2(ot ) + 3(of ) + 4(om ) 8,constraints synchronizePoccupation measure x binary indicators (o),set X = (1 )1 maxo (a, o) = 4(1 )1 . Combiningconstraints (15), get MILP 12 continuous 4 binary variables,|S| + |C| + |O| = 3 + 3 + 1 = 7 constraints (not counting last two sets range constraints).mentioned earlier, even though solving programs is, general, NP-completetask, wide variety efficient algorithms tools so. Therefore,one benefits formulating optimization problem (9) MILP allowsus make use highly efficient existing tools.4. Multiagent Resource Allocationconsider multiagent problem resource allocation several agents,resource preferences agents defined constrained MDP modeldescribed previous section. reiterate main assumptions problem:1. Weak coupling. assume agents weakly-coupled (Meuleau et al., 1998),i.e., interact shared resources, resources allocated, agents transitions rewards independent. assumption criticalresults.72. One-shot resource allocation. resources distributed agentsstart executing MDPs. reallocation resources MDPphase. assumption critical results; allowing reallocation resourceswould violate weak-coupling assumption.3. Initial central control resources. assume beginningresource-allocation phase, resources controlled single authority.standard sell-auction setting. problems resources distributed7. agents cooperative, assumption weak coupling relaxed (at expenseincrease complexity), MILP-based algorithm simultaneously performing policy optimization resource allocation applied consider joint state spaces interactingagents. self-interested agents, violation weakly-coupled assumption would meanagents would playing Markov game (Shapley, 1953) resources allocated, wouldsignificantly complicate strategic analysis agents bidding strategies initial resourceallocation.519fiDolgov & Durfeeamong agents begin with, face problem designing computationallyefficient combinatorial exchange (Parkes, Kalagnanam, & Eso, 2001),complicated problem outside scope work. However, manyideas presented paper could potentially applicable domain well.4. Binary resource costs. before, assume agents resource costs binary.assumption limiting. case non-binary resources discussedAppendix B.Formally, input resource-allocation problem consists following:set agents; use refer agent.{hS, A, pm , rm , , ,bm i} collection weakly-coupled single-agent MDPs,defined single-agent model Section 3. simplicity, without lossgenerality, assume agents state action spaces A,transition reward functions pm rm , initial conditions ,well resource requirements : 7 {0, 1} capacity boundsbm : C 7 R. also assume agents discount factor ,assumption trivially relaxed.C sets resources capacities, defined exactly single-agentmodel Section 3.: C 7 R specifies capacity costs resources, defined exactlysingle-agent model Section 3.b : 7 R specifies upper bound amounts shared resources (thisdefines additional bound multiagent problem).Given above, goal design mechanism allocating resourcesagents economically efficient way, i.e., way maximizes social welfareagents (one often-used criteria mechanism design). would also likemechanism efficient computational standpoint.Example 5 Suppose two delivery agents. MDP capacity constraintsfirst agent exactly defined previously Examples 1 2. MDPsecond agent almost first agent, differencegets slightly higher reward delivering appliances: r2 (s1 , a2 ) = 12 (whereasr1 (s1 , a2 ) = 10 first agent). Suppose two trucks, one forklift, onemechanic shared two agents. bounds specified follows:b(ot ) = 2,b(of ) = 1,b(om ) = 1.problem decide agent get forklift, getmechanic (trucks plentiful example).520fiResource Allocation Among Agents MDP-Induced Preferences4.1 Combinatorial Auctionspreviously mentioned, problem finding optimal resource allocation amongself-interested agents complex valuations combinations resources arisesmany different domains (e.g., Ferguson, Nikolaou, Sairamesh, & Yemini, 1996; Wellmanet al., 2001) often called combinatorial allocation problem. natural widelyused mechanism solving problems combinatorial auction (CA) (e.g., de Vries& Vohra, 2003). CA, agent submits set bids resource bundlesauctioneer, decides resources agent get price.Consider problem allocating among set agents set indivisible resources O, total quantity resource bounded b(o). earliersimplifying assumption actions resource requirements binary implies agentsinterested bundles contain one unit particular resource.combinatorial auction, agent submits bid bmw (specifying muchagent willing pay) every bundle w W value umw > 0.cases, possible express bids without enumerating bundles (for example, usingXOR bidding language (Sandholm, 1999) necessary consider bundlesstrictly positive value, subset bundle value).techniques often reduce complexity resource-allocation problem, not,general, avoid exponential blow number bids. Therefore, describesimplest combinatorial auction flat bids, noted many concisebidding languages exist special cases reduce number explicit bids.collecting bids, auctioneer solves winner-determination problem(WDP), solution prescribes resources distributed among, utility um qagents prices. agent wins bundle w price qwww(we assuming risk-neutral agents quasi-linear utility functions). Thus, optimalbidding strategy agent depends auctioneer allocates resources setsprices.Vickrey-Clarke-Groves (VCG) mechanisms (Vickrey, 1961; Clarke, 1971; Groves, 1973)widely used family mechanisms certain attractive properties (discussed detail below). instantiation VCG mechanism contextcombinatorial auctions Generalized Vickrey Auction (GVA) (MacKie-Mason & Varian, 1994), allocates resources sets prices follows. Given bids bmwagents, auctioneer chooses allocation maximizes sum agents bids.problem NP-complete (Rothkopf et al., 1998) expressed following inm = {0, 1} indicator variablesteger program, optimization variables zwshow whether bundle w assigned agent m, nwo = {0, 1} specifies whether bundle wcontains o:88. related algorithms solving WDP (e.g., Sandholm, 2002), useinteger program (16) representative formulation class algorithms perform searchspace binary decisions resource bundles.521fiDolgov & DurfeeXmaxzXzwbwmM wWsubject to:Xzw1,M;(16)wWXXmMwWzwnwo b(o),O.first constraint (16) says agent receive one bundle,second constraint ensures total amount resource assigned agentsexceed total amount available. Notice MILP (16) performs summationexponentially large sets bundles w W . outlined above, auction XORbidding, sets would typically smaller, but, general, still exponentially large.GVA assigns resources according optimal solution ze (16) sets paymentagent to:Xm0 m0qw= Vmzewbw ,(17)m0 6=mVmvalue (16) participate auction (the optimalvalue submit bids), second term sum agents bidssolution ze WDP participating.GVA number nice properties. strategy-proof, meaning dominantstrategy every agent bid true value every bundle: bmw = uw . auctioneconomically efficient, meaning allocates resources maximize socialwelfare agents (because, agents bid true values, objective function(16) becomes social welfare). Finally, GVA satisfies participation constraint,meaning agent decreases utility participating auction.straightforward way implement GVA MDP-based problem following.Let agent enumerate resource bundles W satisfy local capacityconstraints definedbm (c) (this sufficient MDP model implies free disposalresources agents, make assumption auctioneer).bundle w W , agent would determine feasible action set A(w) formulateMDP (w) = hS, A(w), pm (w), rm (w), i, pm (w) rm (w) transitionreward functions defined pruned action space A(w). Every agent wouldsolve (w) corresponding feasible bundle find optimal policyem (w), whoseexpected discounted reward would define value bundle w: uw = U (e(w), ).mechanism suffers two major complexity problems. First, agentsenumerate exponential number resource bundles compute valuesolving corresponding (possibly large) MDP. Second, auctioneer solveNP-complete winner-determination problem exponentially large input. followingsections devoted tackling complexity problems.Example 6 Consider two-agent problem described Example 5, two trucks, oneforklift, services one mechanic auctioned off. Using straightforwardversion combinatorial auction outlined above, agent would consider522fiResource Allocation Among Agents MDP-Induced Preferences2|O| = 23 = 8 possible resource bundles (since resource requirements agentsbinary, neither agent going bid bundle contains two trucks). everyresource bundle, agent formulate solve corresponding MDPcompute utility bundle.example, assume agents start state s1 (different initial conditionswould result different expected rewards, thus different utility functions), valuenull resource bundle agents would 0 (since action would ableexecute noop a0 ). hand, value bundle [ot , , om ] = [1, 1, 1]contains resources would 95.3 first agent 112.4 second one.value bundle [1, 1, 0] agent would value [1, 1, 1] (sinceoptimal policies initial conditions put s1 require mechanic).agents submit bids auctioneer, solve WDP viainteger program (16) |M|2|O| = 2(2)3 = 16 binary variables. Given above,optimal way allocate resources would assign truck agents,forklift second agent, mechanic either (or neither) two. Thus,agents would receive bundles [1, 0, 0] [1, 1, 0], respectively, resulting social welfare50 + 112.4 = 162.4. However, least one agents non-zero probabilitystarting state s3 , value resource bundles involving mechanic would changedrastically, would optimal resource allocation social value.4.2 Avoiding Bundle Enumerationavoid enumerating resource bundles non-zero value agent, two thingsrequired: i) mechanism support concise bidding language allowsagent express preferences auctioneer compact manner, ii)agents able find good representation preferences language.simple way achieve model create auction agents submitspecifications resource-parameterized MDPs auctioneer bids: languagecompact and, given assumption agent formulate planning problemMDP, require additional computation agents. However,changes communication protocol agents auctioneer, similarlyconcise bidding languages (Sandholm, 1999; Nisan, 2000; Boutilier & Hoos, 2001;Boutilier, 2002). such, simply moves burden solving valuation problemagents auctioneer, lead gains computationalefficiency. mechanism also implications information privacy issues,agents reveal local MDPs auctioneer (which might wantdo). Nevertheless, build idea increase efficiency solvingvaluation winner-determination problems keeping agentsMDP information private. address ways maintaining information privacy nextsection, moment focus improving computational complexity agentsvaluation auctioneers winner-determination problems.question pose section follows. Given bid agent consists MDP, resource information capacity bounds hS, A, pm , rm , , ,bm i,auctioneer formulate solve winner-determination problem efficiently523fiDolgov & Durfeesimply enumerating agents resource bundles solving standard integerprogram (16) exponential number binary variables?Therefore, goal auctioneer find joint policy (a collection single-agentpolicies weak-coupling assumption) maximizes sum expected totaldiscounted rewards agents, conditions that: i) agent assigned setresources violates capacity boundbm (i.e., agent assigned resourcescarry), ii) total amounts resources assigned agents exceedglobal resource bounds b(o) (i.e., cannot allocate agents resourcesavailable). problem expressed following mathematical program:XmaxUm ( , )subject to:XX(o, c)H (a, o)(s, a)bm (c),Xc C, M;(18)(a, o)HX(s, a) b(o),O.Obviously, decision version problem NP-complete, subsumes singleagent MDP capacity constraints, NP-completeness shown Section 3.1.Moreover, problem remains NP-complete even absence single-agent capacityconstraints. Indeed, global constraint amounts shared resources sufficientmake problem NP-complete, shown straightforward reductionKNAPSACK, similar one used single-agent case Section 3.1.linearize (18) similarly single-agent problem Section 3.2, yieldingfollowing MILP, simply multiagent version (15) (recall assumptionsection resource requirements binary):XXXmaxxm (s, a)rm (s, a)x,subject to:XXXxm (, a)xm (s, a)pm (|s, a) = (),XS, M;(o, c) (o)bm (c),c C, M;(19)X(o) b(o),O;1/XX(a, o)Xxm (s, a) (o),O, M;xm (s, a) 0,S, A, M;(o) {0, 1},O, M,X maxo,m (a, o) xm (s, a) upper bound argument H(),used normalization. single-agent case, bound guaranteed existdiscounted MDPs easy obtain.PP524fiResource Allocation Among Agents MDP-Induced PreferencesMILP (19) allows auctioneer solve WDP without enumeratepossible resource bundles. compared standard WDP formulation (16),order |M|2|O| binary variables, (19) |M||O| binary variables.exponential reduction attained exploiting knowledge agents MDP-basedvaluations simultaneously solving policy-optimization resource-allocation problems. Given worst-case solution time MILPs exponential numberinteger variables, reduction significant impact worst-case performancemechanism. average-case running time also reduced drastically, demonstratedexperiments, presented Section 5.Example 7 apply mechanism discussed running example alternative straightforward combinatorial auction presented Example 6, winnerdetermination MILP (19) look follows. |M||S||A| = (2)(3)(5) = 30 continuous occupation-measure variables xm , |M||O| = (2)(3) = 6 binary variables (o).|M||S| = (2)(3) = 6 conservation-of-flow constraints involve continuousvariables only, well |M||C| + |O| + |M||O| = (2)(1) + 3 + (2)(3) = 9 constraintsinvolve binary variables.capacity constraints agents exactly single-agent case describedExample 4, global resource constraints be:1 (ot ) + 2 (ot ) 2,1 (of ) + 2 (of ) 1,1 (om ) + 2 (om ) 1.Notice example one binary decision variable per resource per agent(yielding 6 variables simple problem). exponentially fewernumber binary variables straightforward CA formulation Example 6,requires one binary variable per resource bundle per agent (yielding 16 variablesproblem). Given MILPs NP-complete number integer variables,reduction 16 6 variables noticeable even small problem like onelead drastic speedup larger domains.mechanism described instantiation GVA, well-knownproperties VCG mechanisms, auction strategy-proof (the agents incentivelie auctioneer MDPs), attains socially optimal resource allocation,agent decreases utility participating auction.sum results section: agents submit MDP information auctioneer instead valuations resource bundles, essentiallyremoved computational burden agents time significantly simplified auctioneers winner-determination problem (the number integer variablesWDP reduced exponentially).4.3 Distributing Winner-Determination ProblemUnlike straightforward combinatorial auction implementation discussed earlier Section 4.1, agents shared computational burden auctioneer,mechanism Section 4.2, agents submit information auctioneeridle waiting solution. suggests potential improvementscomputational efficiency. Indeed, given complexity MILPs, would beneficial525fiDolgov & Durfeeexploit computational power agents offload computationauctioneer back agents (we assume agents cost helpingwould prefer outcome computed faster).9 Thus, would like distributecomputation winner-determination problem (19), common objective distributed algorithmic mechanism design (Feigenbaum & Shenker, 2002; Parkes & Shneidman,2004).10concreteness, base algorithm section branch boundmethod solving MILPs (Wolsey, 1998), exactly techniques also workMILP algorithms (e.g., cutting planes) perform search space LPrelaxations MILP. branch bound MILPs binary variables, LP relaxations created choosing binary variable setting either 0 1, relaxingintegrality constraints binary variables. solution LP relaxation happens integer-valued, provides lower bound value global solution.non-integer solution provides upper bound current subproblem, (combinedlower bounds) used prune search space.Thus, simple way auctioneer distribute branch bound algorithmsimply farm LP relaxations agents ask solve LPs. However,easy see mechanism strategy-proof. Indeed, agent taskedperforming computation determining optimal resource allocationassociated payments could benefit lying outcome computationauctioneer. common phenomenon distributed mechanism implementations:whenever WDP calculations offloaded agent participating auction,agent might able benefit sabotaging computation. several methodsensuring strategy-proofness distributed implementation. approach bestsuited problem based idea redundant computation (Parkes & Shneidman,2004),11 multiple agents asked task disagreementcarefully punished discourage lying. rest section, demonstrateeasy implement case.basic idea simple: let auctioneer distribute LP relaxations agents,check solutions re-solve problems agents return incorrect solutions(this would make truthful computation weakly-dominant strategy agents,nonzero punishment used achieve strong dominance). strategyauctioneer removes incentive agents lie yields exactly solutioncentralized algorithm. However, order beneficial, complexitychecking solution must significantly lower complexity solving problem.Fortunately, true LPs.Suppose auctioneer solve following LP, written twoequivalent ways (let us refer one left primal, one right9. observed Parkes Shneidman (2004), assumption bit controversial, since desireefficient computation implies nonzero cost computation, agents cost helpingmodeled. is, nonetheless, common assumption distributed mechanism implementations.10. describe one simple way distributing mechanism, others also possible.11. Redundant computation discussed Parkes Shneidman (2004) context ex post Nashequilibria, whereas interested dominant strategies, high-level idea similar.526fiResource Allocation Among Agents MDP-Induced Preferencesdual):min vmax rT xsubject to:(20)subject to:Ax = ;v r.x 0.strong duality property, primal LP solution v , dual alsosolution x , v = rT x . Furthermore, given solution primal LP, easycompute solution dual: complementary slackness, vT = rT B 1 x = B 1 ,B square invertible matrix composed columns correspond basicvariables solution.well-known properties used auctioneer quickly check optimalitysolutions returned agents. Suppose agent returns v solutionprimal LP. auctioneer calculate dual solution vT = rT B 1 check whetherrT x = v. Thus, expensive operation auctioneer performinversion B, done sub-cubic time. matter fact,implementation perspective, would efficient ask agents returnprimal dual solutions, since many popular algorithms compute processsolving LPs.Thus, provided simple method allows us effectively distributewinner-determination problem, maintaining strategy-proofness mechanismnegligible computation overhead auctioneer.4.4 Preserving Information Privacymechanism discussed far drawback requires agentsreveal complete information MDPs auctioneer. problem alsoexacerbated distributed WDP algorithm previous section, sinceagent reveal MDP information auctioneer, informationalso spread agents via LP relaxations global MILP. showalleviate problem.Let us note that, saying agents prefer reveal local information,implicitly assuming external factor affects agents utilitiescaptured agents MDPs. sensible way measure value informationchanges ones decision-making process outcomes. Since effect partmodel (in fact, contradicts weak-coupling assumption), cannot domainindependent manner define constitutes useful information, badagent reveal much MDP. Modeling effects carefully analyzinginteresting research task, outside scope paper. Thus,purposes section, content mechanism hides enough informationmake impossible auctioneer agent uniquely determine transitionreward function agent (in fact, information revealed agent mapinfinitely many MDPs agents).12 Many transformations possible;present one illustrate concept.12. stringent condition would require agents preferences resource bundles revealed(Parkes, 2001), set lower bar here.527fiDolgov & Durfeemain idea approach modify previous mechanism agentssubmit private information auctioneer encrypted form allowsauctioneer solve winner-determination problem, allow inferagents original MDPs.First, note that, instead passing MDP auctioneer, agent submitequivalent LP (6). So, question becomes: agent transform LPway auctioneer able solve it, able infer transitionreward functions originating MDP? words, problem reducesfollowing. Given LP L1 (created MDP = hS, A, p, r, via (6)), needfind transformation L1 L2 solution transformed LP L2 uniquelymap solution original LP L1 , L2 reveal transition rewardfunctions original MDP (p r). show simple change variables suffices.Suppose agent m1 MDP-originated LP going ask agent m2 solve it.order maintain linearity problem (to keep simple m2 solve), m1limit linear transformations. Consider linear, invertible transformationprimal coordinates u = F v, linear, invertible transformation dual coordinates= Dx. Then, LP (20) transformed (by applying F , switchingdual, applying D) equivalent LP new coordinates y:max rT D1subject to:(F 1 )T AD1 = (F 1 )T ;(21)D1 0.value optimal solution (21) value optimal solution(20), given optimal solution (21), easy compute solutionoriginal: x = D1 . Indeed, perspective dual, primal transformation Fequivalent linear transformation dual equality constraints Ax = , (givenF non-singular) effect solution objective function. Furthermore,dual transformation equivalent change variables modifies solutionvalue objective function.However, problem transformations gives away D1 . Indeed,agent m2 able simply read (up set multiplicative constants) transformation constraints D1 0. Therefore, diagonal matrices positivecoefficients (which equivalent stretching coordinate system) trivially deduced m2 , since also map 0. Choosing negative multiplier xi(inverting axis) pointless, flips non-negativity constraints yi 0,immediately revealing sign m2 .Let us demonstrate that, given MDP corresponding LP L1 ,choose F impossible m2 determine coefficients L1(or equivalently original transition reward functions p r). agent m2receives L2 (as (21)), knows L2 created MDP, columnsconstraint matrix original LP L1 must sum constant:XXAji = 1p(|s, a) = 1 .(22)j528fiResource Allocation Among Agents MDP-Induced Preferencesa1:p=1r=3a1:p=1r=1s2s1a2:p=1r=4a2:p=0.99r=9.8a2:p=0.5r=0.02a1:p=0.5r=0.02a2:p=0.01r=0.98a1:p=0.5r=0.02a1:p=1r=1s2s1a2:p=1r=2a2:p=0.5r=0.02(a)a1:p=1r=3a1:p=1r=1s2s1a2:p=1r=4a2:p=0.99r=9.8(b)Figure 3: Preserving privacy example. Two different MDPs lead LPconstraint matrix.gives m2 system |S| nonlinear equations diagonal arbitrary F ,total |S||A| + |S|2 free parameters. everything degeneratecases (which easily handled appropriate choice F ), equationshugely under-constrained infinitely many solutions. matter fact,sacrificing |S| free parameters, m1 choose F waycolumns constraints L2 also sum constant 0 (0, 1), wouldeffect transforming L1 L2 corresponds another valid MDP 2 . Therefore,given L2 , infinitely many original MDPs transformations Fmap LP L2 .also consider connection resource capacity costs agents occupation measures global WDP (19). two things auctioneerable do: i) determine value agents policy (to able maximizesocial welfare), ii) determine resource requirements policies (to checkresource constraints). So, question is, transformation affect these?noted earlier, transformation change objective function, firstrequirement holds. hand, change occupation measure xm (s, a)arbitrary multipliers. However, multiplicative factor xm (s, a) effect usagenon-consumable resources, matters whether corresponding xm (s, a) zero(step function H nullifies scaling effect). Thus, second condition also holds.Example 8 Consider two-state MDP depicted Figure 3a represents decisionmaking problem sales company, two states corresponding possible marketconditions, two actions two possible sales strategies. Market conditions states1 much favorable state s2 (the rewards actions higher).transitions two states correspond probabilities market conditions changingrewards reflect expected profitability two states. Obtaining numbersrealistic scenario would require performing costly time-consuming research,company might want make information public.Therefore, company participate resource-allocation mechanism described above, would want encrypt MDP submitting auctioneer.529a2:p=0.5r=0.02fiDolgov & DurfeeMDP following reward functionr = (1, 19.622, 0.063, 0.084)T ,following transition function:10p(a1 ) =,0.5 0.5p(a2 ) =0.986 0.014.0.50.5(23)(24)Using = 0.8, corresponds following conservation flow constraint matrix:0.2 0.212 0.4 0.4A=.(25)0 0.012 0.60.6submitting LP auctioneer, agent applies following transformations:20,(26)= diag(1, 0.102, 47.619, 47.619), F =0.084 0.126yielding following new constraint matrix:0.1100011= (F ) AD =.0 0.9 0.1 0.1(27)However, constraint matrix A0 corresponds non-transformed conservationflow constraint different MDP (shown Figure 3b) = 0.9, followingreward function:r = (1, 2, 3, 4)T ,(28)following transition function:1 0p(a1 ) =,0 1p(a2 ) =0 1.0 1(29)Therefore, auctioneer receives constraint matrix A0 , way knowing whether agent MDP transition function (29) transformedusing (26) MDP transition function (24) transformed. Noticedynamics two MDPs vary significantly: transition probabilities stateconnectivity. second MDP reveal information originating MDPcorresponding market dynamics.sum up, can, large extent, maintain information privacy mechanismallowing agents apply linear transformations original LPs. informationrevealed mechanism consists agents resource costs (a, o), capacity boundsbm (c), sizes state action spaces (the latter hidden addingdummy states actions MDP).revealed information used infer agents preferences resource requirements. Further, numeric policies revealed, lack information transitionreward functions renders information worthless (as illustrated Example 8,could multiple originating MDPs different properties).530fiResource Allocation Among Agents MDP-Induced Preferences5. Experimental Resultssection present empirical analysis computational complexityresource-allocation mechanism described Section 4. report results computational complexity mechanism Section 4.2, agents submitMDPs auctioneer, simultaneously solves resource-allocation policyoptimization problems. far additional speedup achieved distributing WDP,described Section 4.3, report empirical results, since well-establishedparallel programming literature parallel versions branch-and-bound MILPsolvers consistently achieve linear speedup (Eckstein, Phillips, & Hart, 2000). duefact branch-and-bound algorithms require little inter-process communication.experiments, implemented multiagent delivery problem, basedmultiagent rover domain (Dolgov & Durfee, 2004). problem, agents operatestochastic grid world delivery locations randomly placed throughout grid.delivery task requires set resources, limited quantities resources.random delivery locations grid, location set deliveriesaccepts. resource size requirements (capacity cost), delivery agentbounded space hold resources (limited capacity). agents participateauction bid delivery resources. setting, value resource dependsresources agent acquires deliveries make. Givenbundle resources, agents policy optimization problem find optimal deliveryplan. exact parameters used experiments critical trends seenresults presented below, sake reproducibility domain describeddetail Appendix C.13 resource costs experiments presentedbinary.Computational complexity constrained optimization problems vary greatlyconstraints tightened relaxed. Therefore, first step analysis empiricalcomputational complexity mechanism, investigate running time dependscapacity constraints agent bounds total amountsresources shared agents. common types constrained optimizationconstraint-satisfaction problems, natural expect WDP MILPeasy solve problem over- under-constrained either capacityresource bounds. empirically verify this, varied local capacity constraint levels 0(meaning agents cannot use resources) 1 (meaning agent capacityuse enough resources execute optimal unconstrained policy), well globalconstraint levels 0 meant resources available agents, 1meant enough resources assign agent desired resourcebundle. experiments, part MILP solver played CPLEX 8.1Pentium-4 machine 2GB RAM (RAM bottleneck due usesparse matrix representations). typical running-time profile shown Figure 4.problem easy over-constrained, becomes difficult constraintsrelaxed abruptly becomes easy capacity resource levels startapproach utopia.13. also investigated other, randomly generated domains, results qualitatively same.531fiDolgov & Durfee10.90.8Local Constraint Level6t, sec420110.5Local Constraints0.5000.70.60.50.40.30.20.100Global Constraints0.20.40.6Global Constraint Level0.81Figure 4: Running time MDP-based winner-determination MILP (19) different levels global (b) local (b) constraints. constraint levels fractionsutopian levels needed implement optimal unconstrained policies.Problems involved 10 agents, operating 5-by-5 grid, 10 sharedresource types. data point shown average ten runs randomlygenerated problems.following experiments aim avoid easy regions constraint levels.Therefore, given complexity profiles, set constraint levels 0.5 localcapacity global resource bounds. also set discount factor = 0.95.value chosen arbitrarily, investigations effect valuerunning time MILP revealed significant trends.begin comparing performance MDP-based auction (Section 4.2)performance straightforward CA flat preferences (as described Section 4.1).results summarized Figure 5, compares time takes solvestandard winner-determination problem space resource bundles (16)time needed solve combined MDP-WDP problem (19) used mechanism,number resources increased (with 5 agents, 5-by-5 grid). Despite factalgorithms exponential worst-case running time, number integervariables (16) exponentially larger MILP (19), effect clearlydemonstrated Figure 5. Furthermore, comparison gives extremely optimisticview performance standard CA, take account additionalcomplexity valuation problem, requires formulating solving largenumber MDPs (one per resource bundle). hand, latter embeddedWDP mechanism (19), thus including time solving valuation problemcomparison would magnify effect. fact, experiments, timerequired solve MDPs valuation problem significantly greatertime solving resulting WDP MILP. However, present quantitative resultseffect here, difference implementation (iterating resourcebundles solving MDPs done via straightforward implementation Matlab,532fiResource Allocation Among Agents MDP-Induced PreferencesFigure 5: Gains computation efficiency: MDP-based WDP versus WDP straightforward CA implementation. latter include time solvingMDPs compute resource-bundle values. Error bars show standarddeviation ten runs.n=5, |O| = 104103102t, sec1011001011051015Number Agents |M|2025Figure 6: Scaling MDP-based winner-determination MILP (19) agents. Agentsoperated 5-by-5 grids shared 10 types resources.MILPs solved using highly-optimized CPLEX code). parallelization WDPperformed experiments either algorithm.analyze performance algorithm larger problems infeasiblestraightforward CA. Figure 6 illustrates scaling effect number agentsparticipating auction increased. below, point plot correspondssingle run experiment (with less ten runs performed every valueparameters), solid line mean. Recall size WDP scales linearly533fiDolgov & Durfeen = 10, |M| = 5n = 5, |M| = 102102101110t, sect, sec10010010110110020406080Number Resource Types |O|210100(a)020406080Number Resource Types |O|100(b)n = 7, |M| = 103102t, sec10110010110210020406080Number Resource Types |O|100(c)(d)Figure 7: (a)(c): scaling MDP-based winner-determination MILP (19)number resources three sets problems different grid sizes (n)different numbers agents (|M|); (d): linear-scale plot tail data(c).number agents. graph therefore reflects rather standard scaling effectNP-complete problem. seen plot, problems 25 agents10 resource types well within reach method, average taking around30 minutes.Next, analyze method scales number resource types. Figure 7shows solution time function number resource types three differentsets problems. problems, number actions scaled linearly numberresource types, action required constant number resources, i.e., number534fiResource Allocation Among Agents MDP-Induced Preferencesn = 5, |M| = 3807060t, sec50403020100051015Resources Per Action20Figure 8: Complexity MDP-based winner-determination MILP (19) functionnumber actions resource requirements.nonzero (a, o) per action constant (two) regardless total number resourcetypes. problems exhibit interesting trait wherein running time peaksrelatively low numbers resource types, falls quickly, increases muchslowly number resource types increases (as illustrated Figure 7d, useslinear scale). due fact total number resource typesmuch higher number resources required action, less contentionparticular resource among agents one agents actions. Therefore,problems become relatively under-constrained solution time increases slowly.better illustrate effect, ran set experiments inverse ones shownFigure 7: kept total number resource types constant increased numberresource types required action. results shown Figure 8. running-timeprofile similar observed earlier varied local global constraints:total number resources per action low high, problem under- overconstrained relatively easy solve, complexity increases significantlynumber resources required resource range 50-80% totalnumber resource types.Based above, would expect actions resource requirements increasedtotal number resource types, problem would scale gracefullyFigure 7. example, Figure 9 illustrates running time problems numberresources required action scales linearly total number resources. There,complexity increase significantly faster. However, unreasonable assumemany domains number actions not, fact, increase totalnumber resource types involved. Indeed, natural assume total numberresource types increases problem becomes complicated numbertasks agent perform increases. However, resource requirementsaction increase well? delivery agent running example acquires ability535fiDolgov & Durfeen= 5, |M| = 54103102t, sec10110010110210010203040Number Resource Types |O|50Figure 9: Complexity actions resource requirements grow proportionally totalnumber resource types. number resource types needed action10% total number resource types |O|.deliver pizza, might need new resources perform actions related new activity,one would expect resource requirements delivering furniture applianceschange. Therefore, believe many real applications, method scalegracefully total number resource types.experiments illustrate point domains agents preferences defined underlying Markov decision processes, resource-allocationmechanism developed paper lead significant computational advantages.shown Figure 7, method successfully applied large problems that,argue, well beyond reach combinatorial resource-allocation mechanisms flatpreferences. experiments show (Figure 5), even small problems, combinatorialresource allocation mechanisms flat preferences time-consuming, attempts empirically evaluate simpler mechanisms larger problems proved futile.instance, method takes one minute solve problem that, standardCA, requires agents enumerate 2100 bundles auctioneer solveNP-complete problem input size.6. Generalizations, Extensions, Conclusionsmany possible extensions generalizations work presented here,briefly outline several below.treatment paper focused problem resource allocation amongself-interested agents, algorithms also apply cooperative MDPs weaklyinteracting agents. cooperative setting, concept resources viewedcompact way model inter-agent constraints inability include combinations joint actions policies. weakly-coupled MDPs, agents536fiResource Allocation Among Agents MDP-Induced Preferencesindependent transition reward functions, certain combinations joint actionsfeasible widely used model agents interactions (e.g., Singh & Cohn, 1998).model resource-centric, direct models also certainly possible. example, agents use SAT formulas describe valid combinations joint actions. caseeasily handled via simple modifications single multiagent MILPs (15)(19). Indeed, SAT formula expressed set linear inequalitiesbinary variables (a) (or (a) multiagent case), directly addedcorresponding MILP (see case non-binary resources Appendix B MILPdefined indicators (a), instead (o) used binary case).mentioned previously, work extended handle consumable resourcesused whenever agents execute actions. fact, conditions, problemconsiderably simplified domains kinds resources.important change redefine value particular resource bundleagent. difficulty that, given policy, total use consumable resourcesuncertain, definition value resource bundle becomes ambiguous. Onepossibility define value bundle payoff best policy whose expectedresource usage exceed amounts resources bundle. interpretation(a, o) would also change mean amount resource consumed actionevery time executed. would make constraints (19) linear occupationmeasure, would tremendously simplify WDP (making polynomial).analogous models used constrained MDPs (Altman & Shwartz, 1991), brieflydescribed earlier Section 2. Information privacy handled similarly casenon-consumable resources. However, given transformation = Dx, resource costfunction also scaled D1 (since total consumption consumableresources proportional occupation measure). additional benefithiding resource cost functions (unlike case non-consumable resourcesrevealed). detailed treatment model consumable resourcespresented work Dolgov (2006), including discussion risk-sensitive cases,value resource bundle defined payoff best policy whose probabilityexceeding resource amounts bounded.work exploited structure agents preferences stems underlyingpolicy-optimization problems. However, latter modeled using flat MDPsenumerate possible states actions. flat MDPs scale well duecurse dimensionality (Bellman, 1961). address this, WDP MILP modifiedwork factored MDPs (Boutilier, Dearden, & Goldszmidt, 1995) using factoredresource-allocation algorithm (Dolgov & Durfee, 2006), based dual ALPmethod solving factored MDPs developed Guestrin (2003). method allows usexploit types structure resource-allocation algorithms: structure agentspreferences induced underlying MDPs, well structure MDPs themselves.resource-allocation mechanism discussed paper assumed one-shot allocationresources static population agents. interesting extension work wouldconsider system agents resources arrive depart dynamically,online mechanism design work (Parkes & Singh, 2003; Parkes, Singh, & Yanovsky, 2004).Combining MDP-based model utility functions dynamics online problemscould valuable result thus appears worthwhile direction future work.537fiDolgov & Durfeeagent population static, periodic re-allocation resources allowed, techniqueslike phasing used solve resulting problem (Wu & Durfee, 2005).summarize results paper, presented variant combinatorial auction resource allocation among self-interested agents whose valuations resource bundlesdefined weakly-coupled constrained MDPs. problems, mechanism,exploits knowledge structure agents MDP-based preferences, achievesexponential reduction number integer decision variables, turn leadstremendous speedup straightforward implementation, confirmed experimental results. mechanism implemented achieve reduction computationalcomplexity without sacrificing nice properties VCG mechanism (optimal outcomes, strategy-proofness, voluntary participation). also discussed distributedimplementation mechanism retains strategy-proofness (using factLP solution easily verified), reveal agents private MDP information(using transformation agents MDPs).believe models solution algorithms described paper significantlyapplicability combinatorial resource-allocation mechanisms practical problems, utility functions resource bundles defined sequential stochasticdecision-making problems.7. Acknowledgmentsthank anonymous reviewers helpful comments, well colleaguesSatinder Singh, Kang Shin, Michael Wellman, Demothenis Teneketsis, Jianhui Wu,Jeffrey Cox valuable discussions related work.material based part upon work supported Honeywell International,DARPA IPTO COORDINATORs program Air Force Research LaboratoryContract No. FA875005C0030. views conclusions contained document authors, interpreted representing officialpolicies, either expressed implied, Defense Advanced Research Projects AgencyU.S. Government.Appendix A. ProofsA.1 Proof Theorem 1Theorem 1 Consider finite set n indivisible resources = {oi } (i [1, n]),N available units resource. Then, non-decreasing utility functiondefined resource bundles f : [0, m]n 7 R, exists resource-constrained MDPhS, A, p, r, O, , C, ,b, (with resource set O) whose induced utility functionresource bundles f . words, every resource bundle z [0, m]n ,value optimal policy among whose resource requirements exceed z(call set (z)) f (z):f q : [0, m]n 7 R, hS, A, p, r, O, , C, ,b, :hn fiXfiz [0, m]n , (z) = fi max (a, oi )H(s, a) zi = max U (, ) = f (z).538(z)fiResource Allocation Among Agents MDP-Induced Preferencess000a11s1000a21a11a21a0r=f(0,0,0)a31s0100a31s110 a0a31a11s001a31s101 a0a21a21a0r=f(0,0,1)a0r=f(0,1,1)s0a0r=0s011a11a0r=f(1,1,1)s111Figure 10: Creating MDP resources arbitrary non-decreasing utility function.case shown three binary resources. transitions deterministic.Proof: statement shown via straightforward construction MDPexponential number (one per resource bundle) states actions. presentreduction linear number actions exponential number states. choicedue fact that, although reverse mapping requiring two states exponentiallymany actions even straightforward, MDP feels somewhat unnatural.Given arbitrary non-decreasing utility function f , corresponding MDPconstructed follows (illustrated Figure 10 n = 3 = 1). state spaceMDP consists (m+1)n +1 states one state (sz ) every resource bundle z [0, m]n ,plus sink state (s0 ).action space MDP = a0 {aij }, [1, n], j [1, m] consists mn + 1actions: actions per resource oi , [1, n], plus additional action a0 .transition function p deterministic defined follows. Action a0 applicable every state leads sink state s0 . Every action aij applicablestates sz , zi = (j 1) leads certainty states zi = j:01 = aij , = sz , = sz0 , zi = (j 1), zi = j,p(|s, a) = 1 = a0 , = s0 ,0 otherwise.words, aij applies states j 1 units resource leadsstate amount ith resource increases j.reward function r defined follows. rewards state s0 ,action a0 action produces rewards states:(f 0 (z) = ao , = sz , z [0, m]nr(s, a) =0otherwise,f 0 simple transformation f compensates effects discounting:f 0 (z) = f (z)()539Pzi.fiDolgov & DurfeePwords, takes zi transitions get state sz , contributiontotal discounted reward exactly f (z).resource requirements actions follows: action a0 requireresources, every action aij requires j units resource oi .Finally, initial conditions (sz=0 ) = 1, meaning agent always startsstate corresponds empty resource bundle (state s000 Figure 10).capacity costs limitsb used, set C = .easy see MDP constructed above, given resource bundle z,policy feasible set (z) zero probability reaching state sz0z0 > z (for component i). Furthermore, optimal policy set (z)transition state sz (since f (z) non-decreasing) use action a0 , thus obtainingtotal discounted reward f (z).A.2 Proof Theorem 2Theorem 2 Given MDP = hS, A, p, r, O, , C, ,b, resource capacityconstraints, exists policy HR feasible solution , existsstationary deterministic policy SD SD also feasible, expected total rewardSD less :HR , SD SD : U ( SD , ) U (, )Proof: Let us label A0 set actions non-zero probabilityexecuted according , i.e.,A0 = {a|s : (s, a) > 0}Let us also construct unconstrained MDP: 0 = hS, A0 , p0 , r0 i, p0 r0restricted versions p r action domain limited A0 :p0 : A0 7 [0, 1]r0 : A0 7 Rp0 (|s, a) = p(|s, a), r0 (s, a) = r(s, a) S, S, A0Due well-known property unconstrained infinite-horizon MDPs totalexpected discounted reward optimization criterion, 0 guaranteed optimalstationary deterministic solution (e.g., Theorem 6.2.10, Puterman, 1994), labelSD .Consider SD potential solution . Clearly, SD feasible solution,actions come set A0 includes actions uses non-zero probability,means resource requirements (as (9)) SD greater. Indeed:nnXXmax0 (a, o)H(s, a) ,(30)SD (s, a) max0 (a, o) = max (a, o)HaAaAaAfirst inequality due fact H(z) 1 z, second equalityfollows definition A0 .540fiResource Allocation Among Agents MDP-Induced Preferencess1a1:r=v(u1),a1,o1)=1o1)=c(z1)a2:v(u2),,o)=12 2o2)=c(z2):r=s2a0:r=0,,.)=0r=...s3a0:r=0,,.)=0sm1-mv(u ),am,om)=1om)=c(zm)a0:r=0,,.)=0sm+1a0:r= ,=0Figure 11: Reduction KNAPSACK M-OPER-CMDP. transitions deterministic.Furthermore, observe SD yields total reward 0 . Additionally, since SD uniformly optimal solution 0 , is, particular, optimalinitial conditions constrained MDP . Therefore, SD constitutes feasiblesolution whose expected reward greater equal expected rewardfeasible policy .A.3 Proof Theorem 3Theorem 3 following decision problem NP-complete. Given instance MDPhS, A, p, r, O, , C, ,b, resources capacity constraints, rational number ,exist feasible policy , whose expected total reward, given , less ?Proof: shown Theorem 2, always exists optimal policy (9)stationary deterministic. Therefore, presence NP obvious, since can,polynomial time, guess stationary deterministic policy, verify satisfies resourceconstraints, calculate expected total reward (the latter done solvingstandard system linear Markov equations (2) values states).show NP-completeness problem, use reduction KNAPSACK (Garey& Johnson, 1979). Recall KNAPSACK NP-complete problem, askswhether, given set items z Z, cost c(z) value v(z),exists subset Z 0 Z total value items Z 0 lessc, i.e.,P constant vb,Pthe total cost items greater another constant bc(z)bcv(z)vb.reductionillustratedFigure11proceeds00zZzZfollows.Given instance KNAPSACK |Z| = m, let us number items zi ,[1, m] notational convenience. instance KNAPSACK, createMDP + 1 states {s1 , s2 , . . . sm+1 }, + 1 actions {a0 , . . . }, types resources= {o1 , . . . om }, single capacity C = {c1 }.transition function states defined follows. Every state si , [1, m]two transitions it, corresponding actions ai a0 . actions lead statesi+1 probability 1. State sm+1 absorbing transitions lead backitself.reward cost functions defined follows. want action ai , [1, m](which corresponds item zi KNAPSACK) contribute v(zi ) total discounted541fiDolgov & Durfeereward. Hence, set immediate reward every action ai v(zi )()1i , which, giventransition function implies state si reached exactly step 1, ensuresaction ai ever executed, contribution total discounted rewardv(zi )()1i ()i1 = v(zi ). Action a0 produces reward zero states.resource requirements actions defined follows. Action ai , [1, m]needs resource oi , i.e., (ai , oj ) = 1 = j. set cost resource oicost c(zi ) item KNAPSACK problem. null action a0 requires resources.order complete construction, set initial distribution = [1, 0, . . .]agent starts state s1 probability 1. also define decision parameter = vbupper bound single capacityb=bc.Essentially, construction allows agent choose action ai a0 every state si .Choosing action ai equivalent putting item zi knapsack, action a0corresponds choice including zi knapsack. Therefore, existspolicy expected payoff less = vb usesb = bcshared resource exists solution original instanceKNAPSACK.Appendix B. Non-binary Resource Requirementsdescribe MILP formulation capacity-constrained single-agent optimization problem (9) arbitrary resource costs : 7 R, opposed binary costsassumed main parts paper. corresponding multiagent winnerdetermination problem (the non-binary equivalent (19)) follows immediatelysingle-agent MILP.arbitrary resource costs, obtain following non-binary equivalent optimization problem (12) occupation measure coordinates:maxxXXx(s, a)r(s, a)subject to:XXXx(, a)x(s, a)p(|s, a) = (),XS;nX(o, c) max (a, o)Hx(s, a)b(c),c C;x(s, a) 0,S, A.linearize sum max operators (31), let us observe inequalitynXg(ui ) max f (z, ui ) = g(u1 ) max f (z, u1 ) + . . . + g(un ) max f (z, un )zZzZzZequivalent following system |Z|n linear inequalities:g(u1 )f (z1 , u1 ) + g(u2 )f (z2 , u2 ) + . . . + g(un )f (zn , un ) a,542z1 , z2 , . . . zn Z.(31)fiResource Allocation Among Agents MDP-Induced PreferencesApplying constraints (31), express original system |C| nonlinearconstraints (each max):XnX(o, c) max (a, o)Hx(s, a)b(c),c Cfollowing system |C||A||O| constraints max removed:X(o, c)(ao , o)HXx(s, a)b(c),c C, ao1 , ao2 , . . . A.(32)Notice way eliminating maximization exponentially increases numberconstraints, expansion enumerates possible actions resource(i.e., enumerates policies resource used action a1 , usedaction a2 , action a3 , etc.) However, many problems resources usedactions. cases, constraintsQ become redundant, numberconstraints reduced |C||A||O| |C| |Ao |, Ao number actionsuse resource o.linearize Heaviside function analogously case binary resource costsSection 3.2: create binary indicator variable corresponds argumentH() tie occupation measure x via linear inequalities. differencenon-binary resource costs, instead usingP indicators resources, use indicatorsactions: (a) {0, 1}, (a) = H( x(s, a)) indicator shows whetheraction used policy. Using expanding max above, representoptimization problem (9) following MILP:maxx,XXx(s, a)r(s, a)subject to:XXXx(, a)x(s, a)p(|s, a) = (),XS;(o, c)(ao , o)(ao )b(c),c C, ao1 , ao2 , . . . A;(33)Xx(s, a)/X (a),A;x(s, a) 0,S, A;(a) {0, 1},A,PX max x(s, a) constant finite upper bound expected numbertimes action used,P exists discounted MDP. can, example, letX = (1 )1 , since s,a x(s, a) = (1 )1 x valid occupation measureMDP discount factor .Example 9 Let us formulate MILP constrained problem Example 3. Recallthree resources = {ot , , om } (truck, forklift, mechanic), one capacity543fiDolgov & Durfeetype C = {c1 } (money), actions following resource requirements (listingnonzero ones):(a1 , ot ) = 1, (a2 , ot ) = 1, (a2 , ) = 1, (a3 , ot ) = 1, (a4 , ot ) = 1, (a4 , om ) = 1resources following capacity costs:(ot , c1 ) = 2, (of , c1 ) = 3, (om , c1 ) = 4,agent limited budget, i.e., capacity boundb(c1 ) = 8.compute optimal policy arbitrary , formulate problemMILP using techniques described above. Using binary variables {(ai )} = {i } ={1 , 2 , 3 , 4 },14 express constraint capacity cost following system|C||A||O| = 1(4)3 = 64 linear constraints:(2)(1)1 + (3)(0)1 + (4)(0)1 8,(2)(1)1 + (3)(0)1 + (4)(0)2 8,(2)(1)1 + (3)(0)1 + (4)(0)3 8,(2)(1)1 + (3)(0)1 + (4)(1)4 8,(2)(1)1 + (3)(1)2 + (4)(0)1 8,...(2)(0)4 + (3)(0)4 + (4)(1)4 8.easy see constraints redundant, fact actionrequires small subset resources allows us prune many constraints.fact, resource used byQmultiple actions ot . Therefore, accordanceearlier discussion, need |Ao | = 1 4 1 = 4 constraints:(2)(1)1 + (3)(1)2 + (4)(1)4 8,(2)(1)2 + (3)(1)2 + (4)(1)4 8,(2)(1)3 + (3)(1)2 + (4)(1)4 8,(2)(1)4 + (3)(1)2 + (4)(1)4 8,four constraints corresponds case first resource (ot ) useddifferent action.mentioned earlier, set X = (1 )1 constraints synchronizeoccupation measure x binary indicators . Combining constraintsQ(33), get MILP 12 continuous 4 binary variables, |S|+|C| |Ao |+|A| = 3 + 4 + 3 = 10 constraints (not counting last two sets range constraints).Finally, let us observe expanding resource action sets, problemrepresented using binary resources only. domain contains mostly binaryrequirements, may effective expand non-binary resource requirementsaugmenting resource set O, use binary formulation Section 3.2 ratherdirectly applying more-general formulation described above.14. create 0 noop action a0 , resource costs zero, dropsexpressions.544fiResource Allocation Among Agents MDP-Induced PreferencesAppendix C. Experimental Setupappendix details experimental domains constructed. deliverydomain |M| agents operating n-by-n grid sharing |O| resource types,used following parameters.resources enable agents carry delivery tasks. problem |O| resourcetypes, |O| delivery actions, performing action [1, |O|] requires randomsubset resources (where number resources required actionimportant parameter, whose effect complexity discussed Section 5). probabilitytask [1, |O|] carried location 0.1+0.4(|O|i)/(|O|1), i.e., uniformlydistributed 0.1 0.5, function action ID (actions lower IDsrewarding, per definition reward function below, executedfewer locations).n2 /5 possible delivery locations randomly placed grid. deliverylocation assigned set delivery tasks executed (a single locationused multiple delivery tasks, single task carried severallocations). assignment tasks locations done randomly.agent 4 + |O| actions: drive four perpendicular directionsexecute one delivery tasks. drive actions result movement intendeddirection probability 0.8 probability 0.2 produce change location.movement actions incur negative reward, amount depends sizeagent. problem |M| agents, movement penalty incurred agent[1, |M|] 1 9(m 1)/(|M| 1), i.e., distributed uniformly [1, 10] functionagents ID.Execution action corresponding delivery task [1, |O|] locationtask assigned produces reward 100i/|O| moves agent new randomlocation grid. new location chosen randomly problem generation (thusknown agent), transition deterministic, induces topology nearbyremote locations. Attempting execution delivery task incorrect locationchange state produces zero reward.agents bid delivery resources |O| types. cglob |M| unitsresource, cglob global constraint level (set 0.5 experiments,described detail Section 5). one capacity type: size. sizerequirements making deliveries type [1, |O|] i. capacity limit agentcloc /2|O|(|O| + 1), cloc local constraint level (set 0.5experiments, described detail Section 5).initial location agent randomly selected uniform distribution.discount factor = 0.95.ReferencesAltman, E. (1996). Constrained Markov decision processes total cost criteria: Occupation measures primal LP. Methods Models Operations Research, 43 (1),4572.545fiDolgov & DurfeeAltman, E., & Shwartz, A. (1991). Adaptive control constrained Markov chains: Criteria policies. Annals Operations Research, special issue Markov DecisionProcesses, 28, 101134.Altman, E. (1999). Constrained Markov Decision Processes. Chapman HALL/CRC.Bellman, R. (1961). Adaptive Control Processes: Guided Tour. Princeton UniversityPress.Benazera, M. E., Brafman, R. I., Meuleau, N., & Hansen, E. (2005). Planning continuous resources stochastic domains. Proceedings Nineteenth InternationalJoint Conference Artificial Intelligence (IJCAI-05), pp. 12441251.Bererton, C., Gordon, G., & Thrun, S. (2003). Auction mechanism design multi-robotcoordination. Thrun, S., Saul, L., & Scholkopf, B. (Eds.), Proceedings ConferenceNeural Information Processing Systems (NIPS). MIT Press.Bertsimas, D., & Tsitsiklis, J. N. (1997). Introduction Linear Optimization. AthenaScientific.Boutilier, C. (2002). Solving concisely expressed combinatorial auction problems. Proceedings Eighteenth National Conference Artificial Intelligence (AAAI-02),pp. 359366.Boutilier, C., Dearden, R., & Goldszmidt, M. (1995). Exploiting structure policy construction. Proceedings Fourteenth International Joint Conference ArtificialIntelligence (IJCAI-95), pp. 11041111.Boutilier, C., & Hoos, H. H. (2001). Bidding languages combinatorial auctions. Proceedings Seventeenth International Joint Conference Artificial Intelligence(IJCAI-01), pp. 12111217.Clarke, E. H. (1971). Multipart pricing public goods. Public Choice, 18, 1933.de Vries, S., & Vohra, R. V. (2003). Combinatorial auctions: survey. INFORMS JournalComputing, 15 (3), 284309.Dolgov, D. (2006). Integrated Resource Allocation Planning Stochastic MultiagentEnvironments. Ph.D. thesis, Computer Science Department, University Michigan.Dolgov, D. A., & Durfee, E. H. (2004). Optimal resource allocation policy formulation loosely-coupled Markov decision processes. Proceedings FourteenthInternational Conference Automated Planning Scheduling (ICAPS-04), pp.315324.Dolgov, D. A., & Durfee, E. H. (2006). Resource allocation among agents preferencesinduced factored MDPs. Proceedings Fifth International Joint ConferenceAutonomous Agents Multiagent Systems (AAMAS-06), Hakodate, Japan.Eckstein, J., Phillips, C., & Hart, W. (2000). Pico: object-oriented framework parallelbranch bound. Proceedings Workshop Inherently Parallel AlgorithmsOptimization Feasibility Applications.Feigenbaum, J., & Shenker, S. (2002). Distributed algorithmic mechanism design: Recentresults future directions. Proceedings Sixths International Workshop546fiResource Allocation Among Agents MDP-Induced PreferencesDiscrete Algorithms Methods Mobile Computing Communications, pp.113. ACM Press, New York.Feldmann, R., Gairing, M., Lucking, T., Monien, B., & Rode, M. (2003). Selfish routingnon-cooperative networks: survey. Proceedings Twenty-Eights InternationalSymposium Mathematical Foundations Computer Science (MFCS-03), pp. 2145. Springer-Verlag.Ferguson, D., Nikolaou, C., Sairamesh, J., & Yemini, Y. (1996). Economic models allocating resources computer systems. Clearwater, S. (Ed.), Market-Based Control:Paradigm Distributed Resource Allocation, pp. 156183, Hong Kong. WorldScientific.Garey, M. R., & Johnson, D. S. (1979). Computers Intractability: Guide TheoryNP-Completeness. W. H. Freeman & Co.Groves, T. (1973). Incentives teams. Econometrica, 41 (4), 617631.Guestrin, C. (2003). Planning Uncertainty Complex Structured Environments.Ph.D. thesis, Computer Science Department, Stanford University.Heyman, D. P., & Sobel, M. J. (1984). Volume II: Stochastic Models Operations Research.McGraw-Hill, New York.Kallenberg, L. (1983). Linear Programming Finite Markovian Control Problems. Math.Centrum, Amsterdam.Littman, M. L., Dean, T. L., & Kaelbling, L. P. (1995). complexity solving Markovdecision problems. Proceedings Eleventh Annual Conference UncertaintyArtificial Intelligence (UAI95), pp. 394402, Montreal.MacKie-Mason, J. K., & Varian, H. (1994). Generalized Vickrey auctions. Tech. rep.,University Michigan.Mas-Colell, A., Whinston, M. D., & Green, J. R. (1995). Microeconomic Theory. OxfordUniversity Press, New York.McAfee, R. P., & McMillan, J. (1996). Analyzing airwaves auction. Journal EconomicPerspectives, 10 (1), 15975.McMillan, J. (1994). Selling spectrum rights. Journal Economic Perspectives, 8 (3),14562.Meuleau, N., Hauskrecht, M., Kim, K.-E., Peshkin, L., Kaelbling, L., Dean, T., & Boutilier,C. (1998). Solving large weakly coupled Markov decision processes. ProceedingsFifteenth National Conference Artificial Intelligence (AAAI-98), pp. 165172.Nisan, N. (2000). Bidding allocation combinatorial auctions. Electronic Commerce.Parkes, D. (2001). Iterative Combinatorial Auctions: Achieving Economic Computational Efficiency. Ph.D. thesis, Department Computer Information Science,University Pennsylvania.Parkes, D. C., Kalagnanam, J. R., & Eso, M. (2001). Achieving budget-balanceVickrey-based payment schemes exchanges. Proc. 17th International Joint Conference Artificial Intelligence (IJCAI-01), pp. 11611168.547fiDolgov & DurfeeParkes, D. C., & Shneidman, J. (2004). Distributed implementations Vickrey-ClarkeGroves mechanisms. Proceedings Third International Joint ConferenceAutonomous Agents Multi Agent Systems (AAMAS-04), pp. 261268.Parkes, D. C., & Singh, S. (2003). MDP-based approach Online Mechanism Design.Proceedings Seventeenths Annual Conference Neural Information ProcessingSystems (NIPS-03).Parkes, D. C., Singh, S., & Yanovsky, D. (2004). Approximately efficient online mechanismdesign. Proceedings Eighteenths Annual Conference Neural InformationProcessing Systems (NIPS-04).Puterman, M. L. (1994). Markov Decision Processes. John Wiley & Sons, New York.Ross, K., & Chen, B. (1988). Optimal scheduling interactive non-interactive traffictelecommunication systems. IEEE Transactions Automatic Control, 33, 261267.Ross, K., & Varadarajan, R. (1989). Markov decision processes sample path constraints: communicating case. Operations Research, 37, 780790.Rothkopf, M. H., Pekec, A., & Harstad, R. M. (1998). Computationally manageable combinational auctions. Management Science, 44 (8), 11311147.Sandholm, T., & Boutilier, C. (2006). Preference elicitation combinatorial auctions.Cramton, Shoham, & Steinberg (Eds.), Combinatorial Auctions, chap. 10. MIT Press.Sandholm, T. (1999). algorithm optimal winner determination combinatorialauctions. Proceedings Sixteenth International Joint Conference ArtificialIntelligence (IJCAI-99), pp. 542547, San Francisco, CA, USA. Morgan KaufmannPublishers Inc.Sandholm, T. (2002). Algorithm optimal winner determination combinatorial auctions. Artificial Intelligence, 135 (1-2), 154.Shapley, L. S. (1953). Stochastic games. Proceedings National Academy Science, USA,39, 10951100.Sheffi, Y. (2004). Combinatorial auctions procurement transportation services.Interfaces, 34 (4), 245252.Singh, S., & Cohn, D. (1998). dynamically merge Markov decision processes.Jordan, M. I., Kearns, M. J., & Solla, S. A. (Eds.), Advances Neural InformationProcessing Systems, Vol. 10, pp. 10571063. MIT Press.Song, J., & Regan, A. (2002). Combinatorial auctions transportation service procurement: carrier perspective. Transportation Research Record, 1833, 4046.Vickrey, W. (1961). Counterspeculation, auctions competitive sealed tenders. JournalFinance, 16, 837.Wellman, M. P., Walsh, W. E., Wurman, P. R., & MacKie-Mason, J. K. (2001). Auctionprotocols decentralized scheduling. Games Economic Behavior, 35, 271303.Wolsey, L. (1998). Integer Programming. John Wiley & Sons.548fiResource Allocation Among Agents MDP-Induced PreferencesWu, J., & Durfee, E. H. (2005). Automated resource-driven mission phasing techniquesconstrained agents. Proceedings Fourth International Joint ConferenceAutonomous Agents Multiagent Systems (AAMAS-05), pp. 331338.549fiJournal Artificial Intelligence Research 27 (2006) 335-380Submitted 05/06; published 11/06Anytime Point-Based Approximations Large POMDPsJoelle PineauJPINEAU @ CS . MCGILL . CASchool Computer ScienceMcGill UniversityMontreal QC, H3A 2A7 CANADAGeoffrey GordonGGORDON @ CS . CMU . EDUMachine Learning DepartmentCarnegie Mellon UniversityPittsburgh PA, 15232 USASebastian ThrunTHRUN @ STANFORD . EDUComputer Science DepartmentStanford UniversityStanford CA, 94305 USAAbstractPartially Observable Markov Decision Process long recognized rich framework real-world planning control problems, especially robotics. However exact solutions framework typically computationally intractable smallest problems.well-known technique speeding POMDP solving involves performing value backupsspecific belief points, rather entire belief simplex. efficiency approach,however, depends greatly selection points. paper presents set novel techniquesselecting informative belief points work well practice. point selection procedurecombined point-based value backups form effective anytime POMDP algorithm calledPoint-Based Value Iteration (PBVI). first aim paper introduce algorithmpresent theoretical analysis justifying choice belief selection technique. second aimpaper provide thorough empirical comparison PBVI state-of-the-artPOMDP methods, particular Perseus algorithm, effort highlight similaritiesdifferences. Evaluation performed using standard POMDP domains realistic robotictasks.1. Introductionconcept planning long tradition AI literature (Fikes & Nilsson, 1971; Chapman,1987; McAllester & Roseblitt, 1991; Penberthy & Weld, 1992; Blum & Furst, 1997). Classicalplanning generally concerned agents operate environments fully observable,deterministic, finite, static, discrete. techniques able solve increasinglylarge state-space problems, basic assumptions classical planningfull observability, staticenvironment, deterministic actionsmake unsuitable robotic applications.Planning uncertainty aims improve robustness explicitly reasoning typeuncertainty arise. Partially Observable Markov Decision Process (POMDP) (Astrom,1965; Sondik, 1971; Monahan, 1982; White, 1991; Lovejoy, 1991b; Kaelbling, Littman, & Cassandra, 1998; Boutilier, Dean, & Hanks, 1999) emerged possibly general representation(single-agent) planning uncertainty. POMDP supersedes frameworks termsc2006AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiP INEAU , G ORDON & HRUNrepresentational power simply combines essential features planninguncertainty.First, POMDPs handle uncertainty action effects state observability, whereas manyframeworks handle neither these, handle stochastic action effects. handle partial state observability, plans expressed information states, instead world states,since latter ones directly observable. space information states spacebeliefs system might regarding world state. Information states easily calculatedmeasurements noisy imperfect sensors. POMDPs, information states typicallyrepresented probability distributions world states.Second, many POMDP algorithms form plans optimizing value function. powerful approach plan optimization, since allows one numerically trade alternativeways satisfy goal, compare actions different costs/rewards, well plan multipleinteracting goals. value function optimization used planning approachesfor example Markov Decision Processes (MDPs) (Bellman, 1957)POMDPs unique expressingvalue function information states, rather world states.Finally, whereas classical conditional planners produce sequence actions, POMDPsproduce full policy action selection, prescribes choice action possibleinformation state. producing universal plan, POMDPs alleviate need re-planning,allow fast execution. Naturally, main drawback optimizing universal plan computational complexity so. precisely seek alleviate work describedpaperknown algorithms exact planning POMDPs operate optimizing value functionpossible information states (also known beliefs). algorithms run wellknown curse dimensionality, dimensionality planning problem directly relatednumber states (Kaelbling et al., 1998). also suffer lesser known cursehistory, number belief-contingent plans increases exponentially planninghorizon. fact, exact POMDP planning known PSPACE-complete, whereas propositionalplanning NP-complete (Littman, 1996). result, many POMDP domainsstates, actions sensor observations computationally intractable.commonly used technique speeding POMDP solving involves selecting finite setbelief points performing value backups set (Sondik, 1971; Cheng, 1988; Lovejoy,1991a; Hauskrecht, 2000; Zhang & Zhang, 2001). usefulness belief point updateswell acknowledged, backups applied thoroughlyexplored.paper describes class Point-Based Value Iteration (PBVI) POMDP approximationsvalue function estimated based strictly point-based updates. context,choice points integral part algorithm, approach interleaves value backupssteps belief point selection. One key contributions paper presentationanalysis set heuristics selecting informative belief points. range naiveversion combines point-based value updates random belief point selection, sophisticated algorithm combines standard point-based value update estimate errorbound approximate exact solutions select belief points. Empirical theoretical evaluation techniques reveals importance taking distance pointsconsideration selecting belief points. result approach exhibits good perfor336fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDPmance belief points (sometimes less number states), thereby overcomingcurse history.PBVI class algorithms number important properties, discussedgreater length paper:Theoretical guarantees. present bound error value function obtainedpoint-based approximation, respect exact solution. bound applies numberpoint-based approaches, including PBVI, Perseus (Spaan & Vlassis, 2005),others.Scalability. able handle problems order 103 states, order magnitude larger problems solved traditional POMDP techniques.empirical performance evaluated extensively realistic robot tasks, including search-formissing-person scenario.Wide applicability. approach makes assumptions nature structuredomain. PBVI framework assume known discrete state/ action/observation spacesknown model (i.e., state-to-state transitions, observation probabilities, costs/rewards),additional specific structure (e.g., constrained policy class, factored model).Anytime performance. anytime solution achieved gradually alternating phasesbelief point selection phases point-based value updates. allows effectivetrade-off planning time solution quality.PBVI many important properties, number recent POMDP approaches exhibit competitive performance (Braziunas & Boutilier, 2004; Poupart & Boutilier,2004; Smith & Simmons, 2004; Spaan & Vlassis, 2005). provide overview techniques later part paper. also provide comparative evaluation algorithmsPBVI using standard POMDP domains, effort guide practitioners choicealgorithm. One algorithms, Perseus (Spaan & Vlassis, 2005), closely related PBVIdesign performance. therefore provide direct comparison two approachesusing realistic robot task, effort shed light comparative strengths weaknesses two approaches.paper organized follows. Section 2 begins exploring basic concepts POMDPsolving, including representation, inference, exact planning. Section 3 presents generalanytime PBVI algorithm theoretical properties. Section 4 discusses novel strategies select good belief points. Section 6 presents empirical comparison POMDP algorithms usingstandard simulation problems. Section 7 pursues empirical evaluation tackling complex robotdomains directly comparing PBVI Perseus. Finally, Section 5 surveys number existingPOMDP approaches closely related PBVI.2. Review POMDPsPartially Observable Markov Decision Processes provide general planning decision-makingframework acting optimally partially observable domains. well-suited greatnumber real-world problems decision-making required despite prevalent uncertainty.generally assume complete correct world model, stochastic state transitions, imperfect state tracking, reward structure. Given information, goal find action337fiP INEAU , G ORDON & HRUNstrategy maximizes expected reward gains. section first establishes basic terminology essential concepts pertaining POMDPs, reviews optimal techniques POMDPplanning.2.1 Basic POMDP TerminologyFormally, POMDP defined six distinct quantities, denoted {S, A, Z, T, O, R}. first threeare:States. state world denoted s, finite set states denoted ={s0 , s1 , . . .}. state time denoted st , discrete time index. statedirectly observable POMDPs, agent compute belief statespace S.Observations. infer belief regarding worlds state s, agent take sensor measurements. set measurements, observations, denoted Z = {z0 , z1 , . . .}.observation time denoted zt . Observation zt usually incomplete projectionworld state st , contaminated sensor noise.Actions. act world, agent given finite set actions, denoted ={a0 , a1 , . . .}. Actions stochastically affect state world. Choosing right actionfunction history core problem POMDPs.Throughout paper, assume states, actions observations discrete finite.mathematical convenience, also assume actions observations alternatedtime.fully define POMDP, specify probabilistic laws describe state transitionsobservations. laws given following distributions:state transition probability distribution,(s, a, s0 ) := P r(st = s0 | st1 = s, at1 = a) t,(1)probability transitioning state s0 , given agent state selects action a, (s, a, s0 ). Since conditional probability distribution,P0s0 (s, a, ) = 1, (s, a). notation suggests, time-invariant.observation probability distribution,O(s, a, z) := P r(zt = z | st1 = s, at1 = a) t,(2)probability agent perceive observation z upon executing action state s.Pconditional probability defined (s, a, z) triplets, zZ O(s, a, z) =1, (s, a). probability function also time-invariant.Finally, objective POMDP planning optimize action selection, agent givenreward function describing performance:338fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDPreward function. R(s, a) : <, assigns numerical value quantifyingutility performing action state s. assume reward bounded, Rmin <R < Rmax . goal agent collect much reward possible time.precisely, wants maximize sum:E[Xtt0 rt ],(3)t=t0rt reward time t, E[ ] mathematical expectation, 0 < 1discount factor, ensures sum Equation 3 finite.items together, states S, actions A, observations Z, reward R, probabilitydistributions, O, define probabilistic world model underlies POMDP.2.2 Belief ComputationPOMDPs instances Markov processes, implies current world state, st , sufficient predict future, independent past {s0 , s1 , ..., st1 }. key characteristicsets POMDPs apart many probabilistic models (such MDPs) fact statest directly observable. Instead, agent perceive observations {z1 , . . . , zt },convey incomplete information worlds state.Given state directly observable, agent instead maintain complete traceobservations actions ever executed, use select actions. action/observation trace known history. formally defineht := {a0 , z1 , . . . , zt1 , at1 , zt }(4)history time t.history trace get long time goes on. well-known fact historyneed represented explicitly, instead summarized via belief distribution (Astrom, 1965), following posterior probability distribution:bt (s) := P r(st = | zt , at1 , zt1 , . . . , a0 , b0 ).(5)course requires knowing initial state probability distribution:b0 (s) := P r(s0 = s),(6)defines probability domain state time = 0. common eitherspecify initial belief part model, give runtime system tracksbeliefs selects actions. work, assume initial belief (or set possibleinitial beliefs) available planner.belief distribution bt sufficient statistic history, suffices conditionselection actions bt , instead ever-growing sequence past observationsactions. Furthermore, belief bt time calculated recursively, using belief one timestep earlier, bt1 , along recent action at1 observation zt .339fiP INEAU , G ORDON & HRUNdefine belief update equation, (), as:(bt1 , at1 , zt ) = bt (s0 )X=O(s0 , at1 , zt ) (s, at1 , s0 ) bt1 (s)s0P r(zt |bt1 , at1 )(7)denominator normalizing constant.equation equivalent decades-old Bayes filter (Jazwinski, 1970), commonlyapplied context hidden Markov models (Rabiner, 1989), known forwardalgorithm. continuous generalization forms basis Kalman filters (Kalman, 1960).interesting consider nature belief distributions. Even finite state spaces,belief continuous quantity. defined simplex describing space distributionsstate space S. large state spaces, calculating belief update (Eqn 7) computationally challenging. Recent research led efficient techniques belief state computationexploit structure domain (Dean & Kanazawa, 1988; Boyen & Koller, 1998; Poupart &Boutilier, 2000; Thrun, Fox, Burgard, & Dellaert, 2000). However, far complex aspect POMDP planning generation policy action selection, described next.example robotics, calculating beliefs state spaces 106 states easily done realtime (Burgard et al., 1999). contrast, calculating optimal action selection policies exactly appearsinfeasible environments dozen states (Kaelbling et al., 1998),directly size state space, complexity optimal policies.Hence assume throughout paper belief computed accurately, insteadfocus problem finding good approximations optimal policy.2.3 Optimal Policy Computationcentral objective POMDP perspective compute policy selecting actions.policy form:(b) a,(8)b belief distribution action chosen policy .particular interest notion optimal policy, policy maximizes expected future discounted cumulative reward:(bt0 ) = argmax EXt=t0fififitt0 rt fibt0 .fi(9)two distinct interdependent reasons computing optimal policy challenging. widely-known reason so-called curse dimensionality: problemn physical states, defined belief states (n 1)-dimensional continuous space.less-well-known reason curse history: POMDP solving many ways like searchspace possible POMDP histories. starts searching short histories (throughselect best short policies), gradually considers increasingly long histories. Unfortunately number distinct possible action-observation histories grows exponentiallyplanning horizon.340fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDPtwo cursesdimensionality historyoften act independently: planning complexitygrow exponentially horizon even problems states, problemslarge number physical states may still small number relevant histories. cursepredominant depends problem hand, solution technique. example,belief point methods focus paper specifically target curse history, leavingvulnerable curse dimensionality. Exact algorithms hand typicallysuffer far curse history. goal therefore find techniques offer bestbalance both.describe straightforward approach finding optimal policies Sondik (1971).overall idea apply multiple iterations dynamic programming, compute increasinglyaccurate values belief state b. Let V value function maps belief states values<. Beginning initial value function:V0 (b) = maxXR(s, a)b(s),(10)sSt-th value function constructed (t 1)-th following recursive equation:"Vt (b) = max#XXR(s, a)b(s) +sSP r(z | a, b)Vt1 ( (b, a, z)) ,(11)zZ(b, a, z) belief updating function defined Equation 7. value function updatemaximizes expected sum (possibly discounted) future pay-offs agent receivesnext time steps, belief state b. Thus, produces policy optimal planninghorizon t. optimal policy also directly extracted previous-step value function:#"(b)= argmaxXR(s, a)b(s) +XP r(z | a, b)Vt1 ( (b, a, z)) .(12)zZsSSondik (1971) showed value function finite horizon expressed setvectors: = {0 , 1 , . . . , }. -vector represents |S|-dimensional hyper-plane,defines value function bounded region belief:XVt (b) = max(s)b(s).(13)sSaddition, -vector associated action, defining best immediate policyassuming optimal behavior following (t 1) steps (as defined respectively sets{Vt1 , ..., V0 }).t-horizon solution set, , computed follows. First, rewrite Equation 11 as:Vt (b) = maxaAXsSR(s, a)b(s) +XzZmaxt1XXsS(s, a, s0 )O(s0 , a, z)(s0 )b(s) . (14)s0Notice representation Vt (b), nonlinearity term P (z|a, b) Equation 11cancels nonlinearity term (b, a, z), leaving linear function b(s) inside maxoperator.341fiP INEAU , G ORDON & HRUNvalue Vt (b) cannot computed directly belief b B (since infinitelymany beliefs), corresponding set generated sequence operationsset t1 .a,zfirst operation generate intermediate sets a,, A, z Z (Step 1):a, (s) = R(s, a)a,a,zia,z (s)=X(15)000(s, a, )O(s , a, z)i (s ), t1s0a, ia,z |S|-dimensional hyper-plane.Next create (a A), cross-sum observations1 , includes one a,za,z(Step 2):a,z12...a,z= a,+(16)Finally take union sets (Step 3):= aA .(17)forms pieces backup solution horizon t. actual value function Vtextracted set described Equation 13.Using approach, bounded-time POMDP problems finite state, action, observationspaces solved exactly given choice horizon . environmentagent might able bound planning horizon advance, policy (b) approximation optimal one whose quality improves expectation planning horizon (assuming0 < 1).mentioned above, value function Vt extracted directly set . important aspect algorithm (and optimal finite-horizon POMDP solutions)value function guaranteed piecewise linear, convex, continuous function belief (Sondik, 1971). piecewise-linearity continuous properties direct result factVt composed finitely many linear -vectors. convexity property resulta,maximization operator (Eqn 13). worth pointing intermediate sets a,z,also represent functions belief composed entirely linear segments. propertyholds intermediate representations incorporate expectation observationprobabilities (Eqn 15).worst case, exact value update procedure described could require time doubly exponential planning horizon (Kaelbling et al., 1998). better understand complexityexact update, let |S| number states, |A| number actions, |Z| numberobservations, |t1 | number -vectors previous solution set. Step 1 creates|A| |Z| |t1 | projections Step 2 generates |A| |t1 ||Z| cross-sums. So, worst case,new solution requires:|t | = O(|A||t1 ||Z| )(18)1. symbol denotes cross-sum operator. cross-sum operation defined two sets, ={a1 , a2 , . . . , } B = {b1 , b2 , . . . , bn }, produces third set, C = {a1 + b1 , a1 + b2 , . . . , a1 + bn , a2 +b1 , a2 + b2 , . . . , . . . , + bn }.342fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDP-vectors represent value function horizon t; computed timeO(|S|2 |A| |t1 ||Z| ).often case vector completely dominated another vectorentire belief simplex:b < j b, b.(19)Similarly, vector may fully dominated set vectors (e.g., 2 Fig. 1 dominated combination 1 3 ). vector pruned away without affectingsolution. Finding dominated vectors expensive. Checking whether single vectordominated requires solving linear program |S| variables |t | constraints. Nonethelesstime-effective apply pruning iteration prevent explosion solutionsize. practice, |t | often appears grow singly exponentially t, given clever mechanismspruning unnecessary linear functions. enormous computational complexity longkey impediment toward applying POMDPs practical problems.V={ 0 , 1 , 2 , 3 }Figure 1: POMDP value function representation2.4 Point-Based Value BackupExact POMDP solving, outlined above, optimizes value function beliefs. Manyapproximate POMDP solutions, including PBVI approach proposed paper, gain computational advantage applying value updates specific (and few) belief points, ratherbeliefs (Cheng, 1988; Zhang & Zhang, 2001; Poon, 2001). approaches differ significantly(and great consequence) select belief points, set points selected,procedure updating value standard. describe procedure updatingvalue function set known belief points.Section 2.3, value function update implemented sequence operationsset -vectors. assume interested updating value function fixedset belief points, B = {b0 , b1 , ..., bq }, follows value function containone -vector belief point. point-based value function therefore representedcorresponding set {0 , 1 , . . . , q }.Given solution set t1 , simply modify exact backup operator (Eqn 14)one -vector per belief point maintained. point-based backup gives -vectorvalid region around b. assumes belief points regionaction choice lead facets Vt1 point b. key idea behindalgorithms presented paper, reason large computational savings associatedclass algorithms.343fiP INEAU , G ORDON & HRUNobtain solution set previous set t1 , begin generating intera,zmediate sets a,, A, z Z (exactly Eqn 15) (Step 1):a,a, (s) = R(s, a)a,zia,z (s)=(20)0X00(s, a, )O(s , a, z)i (s ), t1 .s0Next, whereas performing exact value update requires cross-sum operation (Eqn 16),operating finite set points, instead use simple summation. construct ,(Step 2):ba = a,+Xargmax(a,zzZX(s)b(s)), b B.(21)sSFinally, find best action belief point (Step 3):b = argmax(X,aA sS(s)b(s)), b B.= bB b(22)(23)operations preserve best -vector belief point b B, estimatevalue function belief simplex (including b/ B) extracted setbefore:XVt (b) = max(s)b(s).(24)sSbetter understand complexity updating value set points B, let |S|number states, |A| number actions, |Z| number observations, |t1 | number-vectors previous solution set. exact update, Step 1 creates |A| |Z| |t1 |projections (in time |S|2 |A| |Z| |t1 |). Steps 2 3 reduce set |B| components(in time |S| |A| |t1 | |Z| |B|). Thus, full point-based value update takes polynomial time,even crucially, size solution set remains constant every iteration.point-based value backup algorithm summarized Table 1.Note algorithm outlined Table 1 includes trivial pruning step (lines 13-14),whereby refrain adding vector already included it. result, oftencase |t | |B|. situation arises whenever multiple nearby belief points supportvector. pruning step computed rapidly (without solving linear programs) clearlyadvantageous terms reducing set .point-based value backup found many POMDP solvers, general serves improve estimates value function. also integral part PBVI framework.3. Anytime Point-Based Value Iterationdescribe algorithmic framework new class fast approximate POMDP algorithms called Point-Based Value Iteration (PBVI). PBVI-class algorithms offer anytime solutionlarge-scale discrete POMDP domains. key achieving anytime solution interleave344fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDP=BACKUP(B, t1 )actionobservation z Zsolution vector t1Pia,z (s) = s0 (s, a, s0 )O(s0 , a, z)i (s0 ),Enda,za,z=EndEnd=belief point hb BPPPb = argmaxaA[(s)b(s)]sS R(s, a)b(s) +zZ maxa,zsSIf(b/ )= bEndReturn12345678910111213141516Table 1: Point-based value backuptwo main components: point-based update described Table 1 steps belief set selection. approximate value function find guaranteed bounded error (comparedoptimal) discrete POMDP domain.current section focuses overall anytime algorithm theoretical properties, independent belief point selection process. Section 4 discusses detail various noveltechniques belief point selection.overall PBVI framework simple. start (small) initial set belief pointsapplied first series backup operations. set belief points grown,new series backup operations applied belief points (old new), on,satisfactory solution obtained. interleaving value backup iterations expansionsbelief set, PBVI offers range solutions, gradually trading computation time solutionquality.full algorithm presented Table 2. algorithm accepts input initial belief pointset (BInit ), initial value (0 ), number desired expansions (N ), planning horizon(T ). common choice BInit initial belief b0 ; alternately, larger set could used,especially cases sample trajectories available. initial value, 0 , typically setminpurposefully low (e.g., 0 (s) = R1, S). this, show pointbased solution always lower-bound exact solution (Lovejoy, 1991a). followssimple observation failing compute -vector lower value function.problems finite horizon, run value backups expansionbelief set. infinite-horizon problems, select horizon[Rmax Rmin ] < ,Rmax = maxs,a R(s, a) Rmin = mins,a R(s, a).345(25)fiP INEAU , G ORDON & HRUNcomplete algorithm terminates fixed number expansions (N ) completed. Alternately, algorithm could terminate value function approximation reachesgiven performance criterion. discussed below.algorithm uses BACKUP routine described Table 1. assume momentEXPAND subroutine (line 8) selects belief points random. performs reasonablywell small problems easy achieve good coverage entire belief simplex.However scales poorly larger domains exponentially many points needed guaranteegood coverage belief simplex. sophisticated approaches selecting belief pointspresented Section 4. Overall, PBVI framework described offers simple yet flexibleapproach solving large-scale POMDPs.=PBVI-MAIN(BInit , 0 , N , )B=BInit= 0N expansionsiterations=BACKUP(B,)EndBnew =EXPAND(B,)B = B BnewEndReturn1234567891011Table 2: Algorithm Point-Based Value Iteration (PBVI)belief set B horizon t, algorithm Table 2 produce estimate valuefunction, denoted VtB . show error VtB optimal value function Vbounded. bound depends densely B samples belief simplex ; densersampling, VtB converges Vt , t-horizon optimal solution, turn bounded errorrespect V , optimal solution. cutting PBVI iterations sufficiently largehorizon, show difference VtB optimal infinite-horizon Vlarge. overall error PBVI bounded, according triangle inequality, by:kVtB V k kVtB Vt k + kVt V k .(26)second term bounded kV0 V k (Bertsekas & Tsitsiklis, 1996). remaindersection states proves bound first term, denote .Begin assuming H denotes exact value backup, H denotes PBVI backup.define (b) error introduced specific belief b performing one iterationpoint-based backup:(b) = |HV B (b) HV B (b)| .Next define maximum total error introduced one iteration point-based backup:= |HV B HV B |= max (b).b346fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDPFinally define density B set belief points B maximum distance beliefsimplex belief set B. precisely:B = maxmin kb b0 k1 .0b bB(27)prove following lemma:Lemma 1. error introduced PBVI performing one iteration value backup B,instead , bounded(Rmax Rmin )B1Proof: Let b0 point PBVI makes worst error value update, b Bclosest (1-norm) sampled belief b0 . Let vector maximal b, 0vector would maximal b0 . failing include 0 solution set, PBVI makes error0 b0 b0 . hand, since maximal b, 0 b b. So,0 b 0 b0==0 b0 b0 + (0 b 0 b)0 b0 b 0 + b 0 b(0 ) (b0 b)k0 k kb0 bk1k0 k B(Rmax Rmin )B1Add zeroAssume optimal bRe-arrange termsHolder inequalitydefinition Blast inequality holds -vector represents reward achievable startingstate following sequence actions observations. Therefore sum rewardsminmaxmust fall R1R1.Lemma 1 states bound approximation error introduced one iteration point-basedvalue updates within PBVI framework. look bound multiple value updates.Theorem 3.1. belief set B horizon t, error PBVI algorithm = kVtBVt k bounded(Rmax Rmin )B(1 )2Proof:= ||VtB Vt ||B HV ||= ||HVt1t1=definition HB HV B || + ||HV B HV ||||HVt1t1t1t1(Rmax Rmin )BB+ ||HVt1 HVt1 ||1(Rmax Rmin )BB V ||+ ||Vt1t11triangle inequality(Rmax Rmin )B1(Rmax Rmin )B(1)2definition t1+ t1lemma 1contraction exact value backupsum geometric series347fiP INEAU , G ORDON & HRUNbound described section depends densely B samples belief simplex .case beliefs reachable, PBVI need sample densely,(Fig. 2). error bounds convergence resultsreplace set reachable beliefs0hold . simply need re-define b lemma 1.side note, worth pointing PBVI makes assumption regardinginitial value function V0B , point-based solution V B guaranteed improveaddition belief points. Nonetheless, theorem presented section shows bounderror VtB (the point-based solution) V (the optimal solution) guaranteeddecrease (or stay same) addition belief points. cases VtB initializedminpessimistically (e.g., V0B (s) = R1, S, suggested above), VtB improve (or staysame) value backup addition belief points.section thus far skirted issue belief point selection, however bound presentedsection clearly argues favor dense sampling belief simplex. randomlyselecting points according uniform distribution may eventually accomplish this, generallyinefficient, particular high dimensional cases. Furthermore, take advantagefact error bound holds dense sampling reachable beliefs. Thus seekefficient ways generate belief points random entire simplex. issueexplored next section.4. Belief Point Selectionsection 3, outlined prototypical PBVI algorithm, conveniently avoiding questionbelief points selected. clear trade-off including fewerbeliefs (which would favor fast planning good performance), versus including many beliefs(which would slow planning, ensure better bound performance). bringsquestion many belief points included. However number pointsconsideration. likely collections belief points (e.g., frequently encountered)likely produce good value function others. brings questionbeliefs included.number approaches proposed literature. example, exact valuefunction approaches use linear programs identify points value function needsimproved (Cheng, 1988; Littman, 1996; Zhang & Zhang, 2001), however typicallyexpensive. value function also approximated learning value regular points,using fixed-resolution (Lovejoy, 1991a), variable-resolution (Zhou & Hansen, 2001) grid.less expensive solving LPs, scales poorly number states increases. Alternately, one use heuristics generate grid-points (Hauskrecht, 2000; Poon, 2001). tendsscalable, though significant experimentation required establish heuristicsuseful.section presents five heuristic strategies selecting belief points, fast naiverandom sampling, increasingly sophisticated stochastic simulation techniques.effective strategy propose one carefully selects points likely largestimpact reducing error bound (Theorem 3.1).strategies consider focus selecting reachable beliefs, rather gettinguniform coverage entire belief simplex. Therefore useful begin discussionlooking reachability assessed.348fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDPexact POMDP value iteration solutions optimal initial belief, PBVI (andrelated techniques) assume known initial belief b0 . shown Figure 2, useinitial belief build tree reachable beliefs. representation, path treecorresponds sequence belief space, increasing depth corresponds increasing planhorizon. selecting set belief points PBVI, including reachable beliefs would guarantee optimal performance (conditioned initial belief), expense computationalgrow exponentially planning horitractability, since set reachable beliefs, ,sufficiently small computationalzon. Therefore, best select subset Btractability, sufficiently large good value function approximation.2b0...ba z ba zba z0 q0 0 a0 z01 1ba z1 q...ba z1 0............ba z ba z...ba z ba zp 0p 1ba zp q...0 1.........0 0......ba z0 0 ap zqba z0 1 a0 z0ba z0 1 ap zq............Figure 2: set reachable beliefsdomains initial belief known (or unique), still possible use reachability analysis sampling initial beliefs (or using set known initial beliefs) seedmultiple reachability trees.discuss five strategies selecting belief points, used withinPBVI framework perform expansion belief set.4.1 Random Belief Selection (RA)first strategy also simplest. consists sampling belief points uniform distribution entire belief simplex. sample simplex, cannot simply samplePb(s) independently [0, 1] (this would violate constraint b(s) = 1). Instead, usealgorithm described Table 3 (see Devroye, 1986, details including proof uniformcoverage).random point selection strategy, unlike strategies presented below, focusreachable beliefs. reason, necessarily advocate approach. Howeverinclude obvious choice, far simplest implement, usedrelated work Hauskrecht (2000) Poon (2001). smaller domains (e.g., <20 states),2. strategies discussed assume belief point set, B, approximately doubles size beliefexpansion. ensures number rounds value iteration logarithmic (in final number beliefpoints needed). Alternately, strategy could used (with little modification) add fixed number newbelief points, may require many rounds value iteration. Since value iteration much expensivebelief computation, seems appropriate double size B expansion.349fiP INEAU , G ORDON & HRUNBnew =EXPANDRA (B, )Bnew = BForeach b B:= number states= 0 :btmp [i]=randuniform (0,1)EndSort btmp ascending order= 1 : 1bnew [i]=btmp [i + 1] btmp [i]EndBnew = Bnew bnewEndReturn Bnew1234567891011121314Table 3: Algorithm belief expansion random action selectionperforms reasonably well, since belief simplex relatively low-dimensional. large domains(e.g., 100+ states), cannot provide good coverage belief simplex reasonable numberpoints, therefore exhibits poor performance. demonstrated experimental resultspresented Section 6.remaining belief selection strategies make use belief tree (Figure 2) focusreachable beliefs, rather trying cover entire belief simplex.4.2 Stochastic Simulation Random Action (SSRA)generate points along belief tree, use technique called stochastic simulation. involvesrunning single-step forward trajectories belief points already B. Simulating single-stepforward trajectory given b B requires selecting action observation pair (a, z),computing new belief (b, a, z) using Bayesian update rule (Eqn 7). caseStochastic Simulation Random Action (SSRA), action selected forward simulationpicked (uniformly) random full action set. Table 4 summarizes belief expansionprocedure SSRA. First, state drawn belief distribution b. Second, actiondrawn random full action set. Next, posterior state s0 drawn transitionmodel (s, a, s0 ). Finally, observation z drawn observation model O(s0 , a, z). Usingtriple (b, a, z), calculate new belief bnew = (b, a, z) (according Equation 7),add set belief points Bnew .strategy better picking points random (as described above), restrictsBnew belief tree (Fig. 2). However belief tree still large, especiallybranching factor high, due large numbers actions/observations. selectivepaths belief tree explored, one hope effectively restrict belief setfurther.350fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDPBnew =EXPANDSSRA (B, )Bnew = BForeach b Bs=randmultinomial (b)a=randuniform (A)s0 =randmultinomial (T (s, a, ))z=randmultinomial (O(s0 , a, ))bnew = (b, a, z) (see Eqn 7)Bnew = Bnew bnewEndReturn Bnew1234567891011Table 4: Algorithm belief expansion random action selectionsimilar technique stochastic simulation discussed Poon (2001), however belief set initialized differently (not using b0 ), therefore stochastic simulationsrestricted set reachable beliefs.4.3 Stochastic Simulation Greedy Action (SSGA)procedure generating points using Stochastic Simulation Greedy Action (SSGA)based well-known -greedy exploration strategy used reinforcement learning (Sutton &Barto, 1998). strategy similar SSRA procedure, except rather choosingaction randomly, SSEA choose greedy action (i.e., current best action given beliefb) probability 1 , chose random action probability (we use = 0.1).action selected, perform single-step forward simulation SSRA yield new beliefpoint. Table 5 summarizes belief expansion procedure SSGA.similar technique, featuring stochastic simulation using greedy actions, outlinedHauskrecht (2000). However case, belief set included extreme points beliefsimplex, stochastic simulation done extreme points, rather initialbelief.4.4 Stochastic Simulation Exploratory Action (SSEA)error bound Section 3 suggests PBVI performs best belief set uniformly denseset reachable beliefs. belief point strategies proposed thus far ignore information.next approach propose gradually expands B greedily choosing new reachable beliefsimprove worst-case density.Unlike SSRA SSGA select single action simulate forward trajectorygiven b B, Stochastic Sampling Exploratory Action (SSEA) one step forwardsimulation action, thus producing new beliefs {ba0 , ba1 , ...}. However acceptnew beliefs {ba0 , ba1 , ...}, rather calculates L1 distance ba closestneighbor B. keep point ba farthest away point already B.351fiP INEAU , G ORDON & HRUNBnew =EXPANDSSGA (B, )Bnew = BForeach b Bs=randmultinomial (b)randuniform [0, 1] <a=randuniform (A)ElsePa=argmax sS (s)b(s)Ends0 =randmultinomial (T (s, a, ))z=randmultinomial (O(s0 , a, ))bnew = (b, a, z) (see Eqn 7)Bnew = Bnew bnewEndReturn Bnew123456789101112131415Table 5: Algorithm belief expansion greedy action selectionuse L1 norm calculate distance belief points consistent error boundTheorem 3.1. Table 6 summarizes SSEA expansion procedure.Bnew =EXPANDSSEA (B, )Bnew = BForeach b BForeachs=randmultinomial (b)s0 =randmultinomial (T (s, a, ))z=randmultinomial (O(s0 , a, ))ba = (b, a, z) (see Eqn 7)EndPbnew = maxaA minb0 Bnew sS |ba (s) b0 (s)|Bnew = Bnew bnew (see Eqn 7)EndReturn Bnew12345678910111213Table 6: Algorithm belief expansion exploratory action selection4.5 Greedy Error Reduction (GER)SSEA strategy able improve worst-case density reachable beliefs,directly minimize expected error. would like directly minimize352fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDPerror, measure bound error (Lemma 1). therefore propose final strategygreedily adds candidate beliefs effectively reduce error bound.empirical results, presented below, show strategy successful one discoveredthus far.understand expand belief set GER strategy, useful re-considerbelief tree, reproduce Figure 3. node tree corresponds specific belief.divide nodes three sets. Set 1 includes belief points already B,case b0 ba0 z0 . Set 2 contains belief points immediate descendants pointsB (i.e., nodes grey zone). candidates select newpoints added B. call set envelope (denoted B). Set 3 contains reachablebeliefs.b0...ba z ba z0 q1 q......1 1......00 a0 z0......ba z1 0...ba z...ba z ba zp 0p 1ba zp q...0 1ba z ba z......0 0...ba zba z0 0 ap zq......Figure 3: set reachable beliefsneed decide belief b removed envelope B added setactive belief points B. Every point added B improve estimate valuefunction. new point reduce error bounds (as defined Section 3 pointsalready B; however, error bound new point might quite large. meanslargest error bound points B monotonically decrease; however, particularpoint B (such initial belief b0 ) error bound decreasing.find point reduce error bound, look analysisLemma 1. Lemma 1 bounds amount additional error single point-based backup introduces. Write b0 new belief considering adding, write b beliefalready B. Write value hyper-plane b, write 0 b0 . lemmapoints out,(b0 ) (0 ) (b0 b)evaluating error, need minimize b B. Also, since know0 done backups b0 , make conservative assumption chooseworst-case value 0 [Rmin /(1 ), Rmax /(1 )]|S| . Thus, evaluate:((b0 ) minbBXsSmax(s))(b0 (s) b(s)) b0 (s) b(s)( R1Rmin( 1 (s))(b0 (s) b(s)) b0 (s) < b(s)353(28)fiP INEAU , G ORDON & HRUNone could simply pick candidate b0 B currently largest error bound,3would ignore reachability considerations. Rather, evaluate error b B,weighing error fringe nodes reachability probability:(b0 ),X(b) = maxaAO(b, a, z) ( (b, a, z))X= maxaA(29)zZXXzZ(s, a, s0 )O(s0 , a, z)b(s) ( (b, a, z)),sS s0noting (b, a, z) B, ( (b, a, z)) evaluated according Equation 28.Using Equation 29, find existing point b B largest error bound.directly reduce error adding set one descendants. select next-step belief(b, a, z) maximizes error bound reduction:B=B (b, a, z),b, := argmax(30)XO(b, a, z) ( (b, a, z))(31)bB,aA zZz := argmax O(b, a, z) ( (b, a, z))(32)zZTable 7 summarizes GER approach belief point selection.Bnew =EXPANDGER (B, )Bnew = BN =|B|= 1 : NPb, := argmaxbB,aA zZ O(b, a, z) ( (b, a, z))z := argmaxzZ O(b, a, z) ( (b, a, z))bnew = (b, a, z)Bnew = Bnew bnewEndReturn Bnew12345678910Table 7: Algorithm belief expansioncomplexity adding one new points GER O(SAZB) (where S=#states,A=#actions, Z=#observations, B=#beliefs already selected). comparison, value backup (forone point) O(S 2 AZB), point typically needs updated several times. pointempirical results below, belief selection (even GER) takes minimal time comparedvalue backup.concludes presentation belief selection techniques PBVI framework.summary, three factors consider picking belief point: (1) likely3. tried this, however perform well empirically suggest Equation 29,consider probability reaching belief.354fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDPoccur? (2) far belief points already selected? (3) current approximatevalue point? simplest heuristic (RA) accounts none these, whereasothers (SSRA, SSGA, SSEA) account one, GER incorporates three factors.4.6 Belief Expansion Exampleconsider simple example, shown Figure 4, illustrate difference variousbelief expansion techniques outlined above. 1D POMDP (Littman, 1996) four states, onegoal (indicated star). two actions, left right, expected(deterministic) effect. goal state fully observable (observation=goal), threestates aliased (observation=none). reward +1 received goal state,otherwise reward zero. assume discount factor = 0.75. initial distributionuniform non-goal states, system resets distribution whenever goal reached.Figure 4: 1D POMDPbelief set B always initialized contain initial belief b0 . Figure 5 shows partbelief tree, including original belief set (top node), envelope (leaf nodes).consider belief expansion method might do.b0=[ 1/ 3 1/ 3 0 1/ 3 ]a=lefta=right[ 2/ 3 0 1/ 3 0 ]Pr(z=none)=2/3b1=[ 1 0 0 0 ][ 0 1/ 3 1/ 3 1/ 3 ]Pr(z=goal) = 1/3Pr(z=none)=2/3b2=[ 0 0 1 0 ]b3=[ 0 0.5 0 0.5 ]Pr(z=goal) = 1/3b4=[ 0 0 1 0 ]Figure 5: 1D POMDP belief treeRandom heuristic pick belief point (with equal probability) entire beliefsimplex. directly expand branches belief tree, eventually put samplesnearby.Stochastic Simulation Random Action 50% chance picking action.Then, regardless action picked, theres 2/3 chance seeing observation none,1/3 chance seeing observation goal. result, SSRA select: P r(bnew = b1) = 0.5 32 ,P r(bnew = b2) = 0.5 13 , P r(bnew = b3) = 0.5 23 , P r(bnew = b4) = 0.5 31 .355fiP INEAU , G ORDON & HRUNStochastic Simulation Greedy Action first needs know policy b0 .iterations point-based updates (Section 2.4) applied initial (single point) belief set reveal(b0 ) = lef t.4 result, expansion belief greedily select action lef probability 1 + |A|= 0.95 (assuming = 0.1 |A| = 2). Action right selected beliefexpansion probability |A|= 0.05. Combining along observation probabilities,tell SSGA expand follows: P r(bnew = b1) = 0.95 32 , P r(bnew = b2) = 0.95 13 ,P r(bnew = b3) = 0.05 23 , P r(bnew = b4) = 0.05 13 .Predicting choice Stochastic Simulation Exploratory Action slightly complicated. Four cases occur, depending outcomes random forward simulation b0 :1. action left goes b1 (P r = 2/3) action right goes b3 (P r = 2/3), b1selected ||b0 b1 ||1 = 4/3 whereas ||b0 b3 ||1 = 2/3. case occurP r = 4/9.2. action left goes b1 (P r = 2/3) action right goes b4 (P r = 1/3), b4selected ||b0 b4 ||1 = 2. case occur P r = 2/9.3. action left goes b2 (P r = 1/3) action right goes b3 (P r = 2/3), b2selected ||b0 b2 ||1 = 2. case occur P r = 2/9.4. action left goes b2 (P r = 1/3) action right goes b4 (P r = 1/3), eitherselected (since equidistant b0 ). case b2 b4 P r = 1/18selected.told, P r(bnew = b1) = 4/9, P r(bnew = b2) = 5/18, P r(bnew = b3) = 0, P r(bnew = b4) =5/18.looking belief expansion using Greedy Error Reduction, need computeerror ( (b0 , a, z)), a, z. consider Equation 28: since B one point, b0 , necessarily b = b0 . estimate , apply multiple steps value backup b0 obtain= [0.94 0.94 0.92 1.74]. Using b such, estimate error candidate belief: (b1 ) = 2.93, (b2 ) = 4.28, (b3 ) = 1.20, (b4 ) = 4.28. Note Bone point, dominating factor distance b0 . Next, factor observationprobabilities, Eqns 31-32, allows us determine = lef z = none,therefore select bnew = b1 .summary, note SSGA, SSEA GER favor selecting b1 , whereas SSRA picksoption equal probability (considering b2 b4 actually same). general,problem size, reasonable expand entire belief tree. techniquesdiscussed quickly, except RA pick exact nodes belieftree, select equally good nearby beliefs. example provided simply illustratedifferent choices made strategy.5. Review Point-Based Approaches POMDP Solvingprevious section describes new class point-based algorithms POMDP solving. ideausing point-based updates POMDPs explored previously literature,4. may obvious reader, follows directly repeated application equations 2023.356fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDPsection summarize main results. approaches discussed below, procedureupdating value function given point remains unchanged (as outlined Section 2.4).Rather, approaches mainly differentiated belief points selected,updates ordered.5.1 Exact Point-Based Algorithmsearlier exact POMDP techniques use point-based backups optimize value function limited regions belief simplex (Sondik, 1971; Cheng, 1988). techniquestypically require solving multiple linear programs find candidate belief points valuefunction sub-optimal, expensive operation. Furthermore, guarantee exact solution found, relevant beliefs must generated systematically, meaning reachablebeliefs must considered. result, methods typically cannot scale beyond handfulstates/actions/observations.work Zhang Zhang (2001), point-based updates interleaved standard dynamic programming updates accelerate planning. case points generatedsystematically, rather backups applied set witness points LP points.witness points identified result standard dynamic programming updates, whereasLP points identified solving linear programs identify beliefs valueyet improved. procedures significantly expensive belief selection heuristics presented paper results limited domains dozenstates/actions/observations. Nonetheless approach guaranteed converge optimal solution.5.2 Grid-Based Approximationsexists many approaches approximate value function using finite set belief pointsalong values. points often distributed according grid pattern beliefspace, thus name grid-based approximation. interpolation-extrapolation rule specifiesvalue non-grid points function value neighboring grid-points. approachesignore convexity POMDP value function.Performing value backups grid-points relatively straightforward: dynamic programmingupdates specified Equation 11 adapted grid-points simple polynomial-timealgorithm. Given set grid points G, value bG G defined by:"GV (b ) = max#XXGb (s)R(s, a) +sSP r(z | a, b)V ( (b, a, z)) .(33)zZ(b, a, z) part grid, V ( (b, a, z)) defined value backups. Otherwise,V ( (b, a, z)) approximated using interpolation rule as:V ( (b, a, z) =|G|X(i)V (bG),(34)i=1P|G|(i) 0 i=1 (i) = 1. produces convex combination grid-points.two interesting questions respect grid-based approximations (1) calculateinterpolation function; (2) select grid points.357fiP INEAU , G ORDON & HRUNgeneral, find interpolation leads best value function approximation pointb requires solving following linear program:Minimize|G|X(i)V (bG)(35)i=1Subjectb=|G|X(i)bG(36)i=1|G|X(i) = 1(37)i=10 (i) 1, 1 |G|.(38)Different approaches proposed select grid points. Lovejoy (1991a) constructsfixed-resolution regular grid entire belief space. benefit value interpolationscalculated quickly considering neighboring grid-points. disadvantage numbergrid points grows exponentially dimensionality belief (i.e., numberstates). simpler approach would select random points belief space (Hauskrecht,1997). requires slower interpolation estimating value new points.methods less ideal beliefs encountered uniformly distributed.particular, many problems characterized dense beliefs edges simplex (i.e.,probability mass focused states, states zero probability), lowbelief density middle simplex. distribution grid-points better reflectsactual distribution belief points therefore preferable.Alternately, Hauskrecht (1997) also proposes using corner points belief simplex (e.g.,[1 0 0 . . . ], [0 1 0 . . . ], . . . , [0 0 0 . . . 1]), generating additional successor belief pointsone-step stochastic simulations (Eqn 7) corner points. also proposes approximateinterpolation algorithm uses values |S|1 critical points plus one non-critical pointgrid. alternative approach Brafman (1997), builds grid also startingcritical points belief simplex, uses heuristic estimate usefulness graduallyadding intermediate points (e.g., bk = 0.5bi + 0.5bj , pair points). HauskrechtsBrafmans methodsgenerally referred non-regular grid approximationsrequire fewerpoints Lovejoys regular grid approach. However interpolation rule used calculatevalue non-grid points typically expensive compute, since involves searchinggrid points, rather neighboring sub-simplex.Zhou Hansen (2001) propose grid-based approximation combines advantagesregular non-regular grids. idea sub-sample regular fixed-resolution gridproposed Lovejoy. gives variable resolution grid since parts beliefsdensely sampled others restricting grid points lie fixed-resolution gridapproach guarantee fast value interpolation non-grid points. Nonetheless, algorithmoften requires large number grid points achieve good performance.Finally, Bonet (2002) proposes first grid-based algorithm POMDPs -optimality(for > 0). approach requires thorough coverage belief space every pointwithin grid-point. value update grid point fast implement, sinceinterpolation rule depends nearest neighbor one-step successor beliefgrid point (which pre-computed). main limitation fact -coverage belief358fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDPspace attained using exponentially many grid points. Furthermore, methodrequires good coverage entire belief space, opposed algorithms Section 4,focus coverage reachable beliefs.5.3 Approximate Point-Based Algorithmssimilar PBVI-class algorithms approaches update valuegradient grid point (Lovejoy, 1991a; Hauskrecht, 2000; Poon, 2001). methods ablepreserve piecewise linearity convexity value function, define value functionentire belief simplex. methods use random beliefs, and/or require inclusion large number fixed beliefs corners probability simplex. contrast,PBVI-class algorithms propose (with exception PBVI+RA) select reachable beliefs,particular belief points improve error bounds quickly possible. ideausing reachability analysis (also known stochastic simulation) generate new points explored earlier approaches (Hauskrecht, 2000; Poon, 2001). However analysisindicated stochastic simulation superior random point placements. re-visitquestion (and conclude otherwise) empirical evaluation presented below.recently, technique closely related PBVI called Perseus proposed (Vlassis& Spaan, 2004; Spaan & Vlassis, 2005). Perseus uses point-based backups similar onesused PBVI, two approaches differ two ways. First, Perseus uses randomly generatedtrajectories belief space select set belief points. contrast beliefpoint selection heuristics outlined PBVI. Second, whereas PBVI systematically updatesvalue belief points every epoch value iteration, Perseus selects subset pointsupdate every epoch. method used select points following: points randomlysampled one time value updated. continues value pointsimproved. insight resides observing updating -vector one point often alsoimproves value estimate nearby points (which removed sampling set).approach conceptually simple empirically effective.HSVI algorithm (Smith & Simmons, 2004) another point-based algorithm, differsPBVI picks belief points, orders value updates. maintains lowerupper bound value function approximation, uses select belief points.updating upper bound requires solving linear programs generally expensivestep. ordering value update follows: whenever belief point expandedbelief tree, HSVI updates value direct ancestors (parents, grand-parents, etc.,way back initial belief head node). contrast PBVI performs batchbelief point expansions, followed batch value updates points. respects,HSVI PBVI share many similarities: offer anytime performance, theoretical guarantees,scalability; finally HSVI also takes reachability account. evaluate empiricaldifferences HSVI PBVI next section.Finally, RTBSS algorithm (Paquet, 2005) offers online version point-based algorithms.idea construct belief reachability tree similar Figure 2, using current belieftop node, terminating tree fixed depth d. value nodecomputed recursively finite planning horizon d. algorithm eliminate subtreescalculating bound value, comparing value computed subtrees.RTBSS fact combined offline algorithms PBVI, offline algorithm359fiP INEAU , G ORDON & HRUNused pre-compute lower bound exact value function; used increase subtreepruning, thereby increasing depth online tree construction thus also qualitysolution. online algorithm yield fast results large POMDP domains. Howeveroverall solution quality achieve error guarantees offline approaches.6. Experimental Evaluationsection looks variety simulated POMDP domains evaluate empirical performancePBVI. first three domainsTiger-grid, Hallway, Hallway2are extracted established POMDP literature (Cassandra, 1999). fourthTagwas introducedearlier work new challenge POMDP algorithms.first goal experiments establish scalability PBVI framework;accomplished showing PBVI-type algorithms successfully solve problems excess800 states. also demonstrate PBVI algorithms compare favorably alternative approximatevalue iteration methods. Finally, following example Section 4.6, study larger scaleimpact belief selection strategy, confirms superior performance GERstrategy.6.1 Maze Problemsexists set benchmark problems commonly used evaluate POMDP planning algorithms (Cassandra, 1999). section presents results demonstrating performance PBVIclass algorithms problems. benchmark problems relatively small(at 92 states, 5 actions, 17 observations) compared robotics planning domains,useful analysis point view comparison previous work.initial performance analysis focuses three well-known problems POMDP literature: Tiger-grid (also known Maze33), Hallway, Hallway2. three maze navigationproblems various sizes. problems fully described Littman, Cassandra, Kaelbling(1995a); parameterization available Cassandra (1999).Figure 6a presents results Tiger-grid domain. Replicating earlier experiments Brafman (1997), test runs terminate 500 steps (theres automatic reset every time goalreached) results averaged 151 runs.Figures 6b 6c present results Hallway Hallway2 domains, respectively.case, test runs terminated goal reached 251 steps (whichever occurs first),results averaged 251 runs. consistent earlier experiments Littman,Cassandra, Kaelbling (1995b).three figures compare performance three different algorithms:1. PBVI Greedy Error Reduction (GER) belief point selection (Section 4.5).2. QMDP (Littman et al., 1995b),3. Incremental Pruning (Cassandra, Littman, & Zhang, 1997),QMDP heuristic (Littman et al., 1995b) takes account partial observability current step, assumes full observability subsequent steps:QM DP (b) = argmaxaA360XsSb(s)QM DP (s, a).(39)fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDPresulting policy ability resolve uncertainty, cannot benefit long-terminformation gathering, compare actions different information potential. QMDP seenproviding good performance baseline. three problems considered, finds policyextremely quickly, policy clearly sub-optimal.end spectrum, Incremental Pruning algorithm (Zhang & Liu, 1996; Cassandra et al., 1997) direct extension enumeration algorithm described above. principal insight pruning dominated -vectors (Eqn 19) interleaved directlycross-sum operator (Eqn 16). resulting value function same, algorithmefficient discards unnecessary vectors earlier on. Incremental Pruning algorithmtheoretically find optimal policy, three problems considered would take farlong. fact, iterations exact backups completed reasonable time. threeproblems, resulting short-horizon policy worse corresponding PBVI policy.shown Figure 6, PBVI+GER provides much better time/performance trade-off. findspolicies better obtained QMDP, matter seconds, therebydemonstrating suffer paralyzing complexity Incremental Pruning.take closer look results may surprised see performancePBVI actually decreases points (e.g., dip Fig. 6c), unexpected.important remember theoretical properties PBVI guarantee boundestimate value function, shown here, necessarily imply policyneeds improve monotonically. Nonetheless, value function converges, policy(albeit slower rate).6.2 Tag Problemprevious section establishes good performance PBVI well-known simulation problems, quite small fully demonstrate scalability algorithm.provide better understanding PBVIs effectiveness large problems, section presentsresults obtained applying PBVI Tag problem, robot version popular gamelasertag. problem, agent must navigate environment goal searching for,tagging, moving target (Rosencrantz, Gordon, & Thrun, 2003). Real-world versionsproblem take many forms, Section 7 present similar problem domaininteractive service robot must find elderly patient roaming corridors nursing home.synthetic scenario considered order magnitude larger (870 states)POMDP benchmarks literature (Cassandra, 1999). formulated POMDP problem, goal robot optimize policy allowing quickly find person, assumingperson moves (stochastically) according fixed policy. spatial configurationenvironment used throughout experiment illustrated Figure 7.state space described cross-product two position features, Robot ={s0 , . . . , s29 } Person = {s0 , . . . , s29 , sf ound }. start independently-selected randompositions, scenario finishes Person = sf ound . robot select five actions:{North, South, East, West, Tag}. reward 1 imposed motion action; Tag actionresults +10 reward robot person cell, 10 otherwise. Throughout scenario, Robots position fully observable, Move action predictabledeterministic effect, e. g.:P r(Robot = s10 | Robot = s0 , N orth) = 1,361fiP INEAU , G ORDON & HRUN2.50.7PBVI+GERQMDPIncPrunePBVI+GERQMDPIncPrune0.621.5REWARDREWARD0.510.40.30.20.50.10 2101010121010TIME (secs)0 21031010101011010TIME (secs)(a) Tiger-grid210310(b) Hallway0.450.4PBVI+GERQMDPIncPrune0.35REWARD0.30.250.20.150.10.050 2101010110TIME (secs)21010(c) Hallway2Figure 6: PBVI performance well-known POMDP problems. figure shows sumdiscounted reward function computation time different problem domain.262728232425202122101112131415161718190123456789Figure 7: Spatial configuration domain362fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDPadjacent cell direction. position person, hand,completely unobservable unless agents cell. Meanwhile step,person (with omniscient knowledge) moves away robot P r = 0.8 stays placeP r = 0.2, e. g.:P r(P erson = s16 | P erson = s15 &Robot = s0 ) = 0.4P r(P erson = s20 | P erson = s15 &Robot = s0 ) = 0.4P r(P erson = s15 | P erson = s15 &Robot = s0 ) = 0.2.Figure 8 shows performance PBVI Greedy Error Reduction Tag domain. Results averaged 1000 runs, using different (randomly chosen) start positions run.QMDP approximation also tested provide baseline comparison. results show gradual improvement PBVIs performance samples added (each shown data point representsnew expansion belief set value backups). also confirms computation time directly related number belief points. PBVI requires fewer 100 belief points overcomeQMDP, performance keeps improving points added. Performance appearsconverging approximately 250 belief points. results show PBVI-class algorithmeffectively tackle problem 870 states.6PBVI+GERQMDP8REWARD101214161820 010110231010TIME (secs)410510Figure 8: PBVI performance Tag problem. show sum discounted reward functioncomputation time.problem far beyond reach Incremental Pruning algorithm. single iterationoptimal value iteration problem size could produce 1020 -vectors pruning.Therefore, applied.section describes one version Tag problem, used simulation purposeswork others (Braziunas & Boutilier, 2004; Poupart & Boutilier, 2004; Smith &Simmons, 2004; Vlassis & Spaan, 2004). fact, problem re-formulated varietyways accommodate different environments, person motion models, observation models.Section 7 discusses variations problem using realistic robot person models,presents results validated onboard independently developed robot simulator.363fiP INEAU , G ORDON & HRUN6.3 Empirical Comparison PBVI-Class Algorithmsestablish good performance PBVI+GER number problems, considerempirical results different PBVI-class algorithms. allows us compare effectsvarious belief expansion heuristics. repeat experiments Tiger-grid, Hallway,Hallway2 Tag domains, outlined above, case compare performance fivedifferent PBVI-class algorithms:1. PBVI+RA: PBVI belief points selected randomly belief simplex (Section 4.1).2. PBVI+SSRA: PBVI belief points selected using stochastic simulation random action (Section 4.2).3. PBVI+SSGA: PBVI belief points selected using stochastic simulation greedy action(Section 4.3).4. PBVI+SSEA: PBVI belief points selected using stochastic simulation exploratoryaction (Section 4.4).5. PBVI+GER: PBVI belief points selected using greedy error reduction (Section 4.5).PBVI-class algorithms converge optimal value function given sufficiently largeset belief points. rate converge depends ability generally pickuseful points, leave points containing less information. Since computation timedirectly proportional number belief points, algorithm best performancegenerally one find good solution fewest belief points.Figure 9 shows comparison performance five PBVI-class algorithmsenumerated four problem domains. pictures, present performanceresults function computation time.5seen results, smallest domainTiger-gridPBVI+GER similar performance random approach PBVI+RA. Hallway domain, PBVI+GER reaches nearoptimal performance earlier algorithms. Hallway2, unclear fivealgorithms best, though GER seems converge earlier.larger Tag domain, situation interesting. PBVI+GER combinationclearly superior others. reason believe PBVI+SSEA could match performance, would require order twice many points so. Nonetheless, PBVI+SSEAperforms better either PBVI+SSRA PBVI+SSGA. random heuristic (PBVI+RA),reward improve regardless many belief points added (4000+), therefore include results. results presented Figure 9 suggest choicebelief points crucial dealing large problems. general, believe GER (andSSEA lesser degree) superior heuristics solving domains large numbersaction/observation pairs, ability selectively chooses branchesreachability tree explore.side note, surprised SSGAs poor performance (in comparison SSRA)Tiger-grid Tag domains. could due poorly tuned greedy bias ,5. Nearly identical graphs produced showing performance results function number belief points.confirms complexity analysis showing computation time directly related number beliefpoints.364fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDP2.50.7RASSRASSGASSEAGER0.51.5REWARDREWARD20.61RASSRASSGASSEAGER0.40.30.20.50.10 210101011010TIME (secs)2100 210310110(a) Tiger-grid0110TIME (secs)21010(b) Hallway60.45REWARD0.38SSRASSGASSEAGER10REWARD0.40.35RASSRASSGASSEAGER0.250.20.151214160.1180.050 210110010TIME (secs)11020 010210(c) Hallway2110231010TIME (secs)410510(d) TagFigure 9: Belief expansion results showing execution performance function computationtime.investigate length. Future investigations using problems larger number actions mayshed better light issue.terms computational requirement, GER expensive compute, followedSSEA. However cases, time perform belief expansion step generally negligible(< 1%) compared cost value update steps. Therefore seems best useeffective (though expensive) heuristic.PBVI framework accommodate wide variety strategies, past describedpaper. example, one could extract belief points directly sampled experimental traces.subject future investigations.6.4 Comparative Analysisresults outlined show PBVI-type algorithms able handle wide spectrumlarge-scale POMDP domains, sufficient compare performance PBVI365fiP INEAU , G ORDON & HRUNQMDP Incremental Pruningthe two ends spectrumas done Section 6.1. factsignificant activity recent years development fast approximate POMDPalgorithms, worthwhile spend time comparing PBVI frameworkalternative approaches. made easy fact many validated usingset problems described above.Table 8 summarizes performance large number recent POMDP approximation algorithms, including PBVI, four target domains: Tiger-grid, Hallway, Hallway2, Tag.algorithms listed selected based availability comparable published results availablecode, cases algorithm could re-implemented easily.compare empirical performance, terms execution performance versus planning,set simulation domains. However often case, results showsingle algorithm best solving problems. therefore also compile summaryattributes characteristics algorithm, attempt tell algorithm may besttypes problems. Table 8 includes (whenever possible) goal completion rates, sumrewards, policy computation time, number required belief points, policy size (number-vectors, number nodes finite state controllers). number belief points policysize often identical, however latter smaller single -vector best multiplebelief points.results marked [*] computed us 3GHz Pentium 4; results likelycomputed different platforms, therefore time comparisons may approximate best.Nonetheless number samples size final policy useful indicatorscomputation time. results reported PBVI correspond earliest data point Figures 6 8 PBVI+GER achieves top performance.Algorithms listed order performance, starting algorithm(s) achieving highest reward. results assume standard (not lookahead) controller (see Hauskrecht, 2000,definition).Overall, results indicate algorithms achieve sub-par performance termsexpected reward. case QMDP, fundamental limitations algorithm.Incremental Pruning exact value-directed compression theoretically reach optimalperformance, would require longer computation time so. grid method (see Tiger-gridresults), BPI (see Tiger-grid, Hallway Tag results) PBUA (see Tag results) suffersimilar problem, offer much graceful performance degradation. worth noting noneapproaches assumes known initial belief, effect solving harder problems.results BBSLS sufficiently extensive comment length, appears ablefind reasonable policies small controllers (see Tag results).remaining algorithmsHSVI, Perseus, PBVI+GERall offer comparableperformance relatively large POMDP domains. HSVI seems offer good control performance full range tasks, requires bigger controllers, therefore probably slower,especially domains high stochasticity (e.g., Tiger-grid, Hallway, Hallway2). trade-offsPerseus PBVI+GER less clear: planning time, controller size performancequality quite comparable, fact two approaches similar. Similaritiesdifferences two approaches explored Section 7.366fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDPMethodTiger-Grid (Maze33)HSVI (Smith & Simmons, 2004)Perseus (Vlassis & Spaan, 2004)PBUA (Poon, 2001)PBVI+GER[*]BPI (Poupart & Boutilier, 2004)Grid (Brafman, 1997)QMDP (Littman et al., 1995b)[*]IncPrune (Cassandra et al., 1997)[*]Exact VDC (Poupart & Boutilier, 2003)[*]HallwayPBUA (Poon, 2001)HSVI (Smith & Simmons, 2004)PBVI+GER[*]Perseus (Vlassis & Spaan, 2004)BPI (Poupart & Boutilier, 2004)QMDP (Littman et al., 1995b)[*]Exact VDC (Poupart & Boutilier, 2003)[*]IncPrune (Cassandra et al., 1997)[*]Hallway2PBVI+GER[*]Perseus (Vlassis & Spaan, 2004)HSVI (Smith & Simmons, 2004)PBUA (Poon, 2001)BPI (Poupart & Boutilier, 2004)Grid (Brafman, 1997)QMDP (Littman et al., 1995b)[*]Exact VDC (Poupart & Boutilier, 2003)[*]IncPrune (Cassandra et al., 1997)[*]TagHSVI (Smith & Simmons, 2004)PBVI+GER[*]Perseus (Vlassis & Spaan, 2004)BBSLS (Braziunas & Boutilier, 2004)BPI (Poupart & Boutilier, 2004)QMDP (Littman et al., 1995b)[*]PBUA (Poon, 2001)[*]IncPrune (Cassandra et al., 1997)[*]Goal%Reward Conf.Int.Time(s)|B|||n.a.n.a.n.a.n.a.n.a.n.a.n.a.n.a.n.a.2.352.342.302.27 0.131.810.940.2760.00.01034110412116397163420n.v.0.0224hrs+24hrs+n.v.10000660512n.a.174n.a.n.a.n.a.4860134n.v.5081500n.a.5n.v.n.v.100100100n.v.n.v.5139390.530.520.51 0.030.510.510.2650.1610.1614501083619352497300.0324hrs+24hrs+300n.v.6410000n.a.n.a.n.a.n.a.n.v.1341645515005n.v.n.v.100n.v.100100n.v.982248480.37 0.040.350.350.350.28n.v.0.1090.1370.1376101001027898274280n.v.1.4424hrs+24hrs+3210000n.v.1840n.a.337n.a.n.a.n.a.31561571n.v.1500n.a.5n.v.n.v.100100n.v.n.v.n.v.1900-6.37-6.75 0.39-6.85-8.31-9.18-16.62-19.9-19.91011389463076100054597721.3324hrs+24hrs+n.v.25610000n.a.n.a.n.a.4096n.a.1657203205309405n.v.n.v.n.a.=not applicablen.v.=not available[*]=results computed usTable 8: Results PBVI standard POMDP domains367fiP INEAU , G ORDON & HRUN6.5 Error Estimatesresults presented thus far suggest PBVI framework performs best usingGreedy Error Reduction (GER) technique selecting belief points. scheme, decide belief points included, estimate error bound set candidate pointspick one largest error estimate. error bound estimated describedEquation 28. consider question estimate evolves pointsadded. natural intuition first points, error estimates large,density belief set increases, error estimates become much smaller.Figure 10 reconsiders four target domains: Tiger-grid, Hallway, Hallway2 Tag.case, present reward performance function number belief points (toprow graphs), error estimate point selected according order pointspicked (bottom row graphs). addition, bottom graphs also show (in dashed line) trivialRminbound error ||Vt Vt || Rmax1, valid t-step value function arbitrarypolicy. expected, bound typically tighter trivial bound. Tag, occursnumber belief points exceeds number states, surprising, givenbound depends distance reachable beliefs, states reachable beliefsdomain. Overall, seems reasonably good correspondence improvementperformance decrease error estimates. conclude figure eventhough PBVI error quite loose, fact informative guiding exploration beliefsimplex.note significant variance error estimates one belief point next,illustrated non-monotonic behavior curves bottom graphs Figure 10.behavior attributed possibilities. First, fact error estimategiven belief approximate. value function used calculate error estimateapproximate. addition, fact new belief points always selectedenvelope reachable beliefs, set reachable beliefs. suggests GER couldimproved maintaining deeper envelope candidate belief points. Currently envelopecontains points 1-step forward simulations points already selected. mayuseful consider points 23 steps ahead. predict would reduce jaggedness seenFigure 10, importantly, also reduce number points necessary good performance.course, tradeoff time spent selecting points time spent planning wouldre-evaluated light.7. Robotic Applicationsoverall motivation behind work described paper desire provide high-qualityrobust planning real-world autonomous systems, particular robots. practical side, search robust robot controller large part guided Nursebotproject (Pineau, Montermerlo, Pollack, Roy, & Thrun, 2003). overall goal projectdevelop personalized robotic technology play active role providing improved careservices non-institutionalized elderly people. Pearl, shown Figure 11, main roboticplatform used project.many services nursing-assistant robot could provide (Engelberger, 1999; Lacey& Dawson-Howe, 1998), much work date focused providing timely cognitive reminders (e.g., medications take, appointments attend, etc.) elderly subjects (Pollack, 2002).368fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDPTigergridHallway2.5Reward2Hallway20.80.40.60.30.40.20.20.1Tag5101.51150.500101102103100010# belief points601102100010310# belief points1102102020Error210310# belief points40015401530010202001051001000101105005030203010 10# belief points110210# belief points03010 10110210310# belief points5010110210# belief points3100010110210310# belief pointsFigure 10: Sum discounted reward (top graphs) estimate bound error (bottomgraphs) function number selected belief points.Figure 11: Pearl Nursebot, interacting elderly people nursing facilityimportant component task finding patient whenever time issue reminder.task shares many similarities Tag problem presented Section 6.2. case,however, robot-generated map real physical environment used basis spatialconfiguration domain. map shown Figure 12. white areas correspond freespace, black lines indicate walls (or obstacles) dark gray areas visibleaccessible robot. One easily imagine patients room physiotherapy unit lyingeither end corridor, common area shown upper-middle section.overall goal robot traverse domain order find missing patientdeliver message. robot must systematically explore environment, reasoningspatial coverage human motion patterns, order find person.369fiP INEAU , G ORDON & HRUNFigure 12: Map environment7.1 POMDP Modelingproblem domain represented jointly two state features: RobotPosition, PersonPosition.feature expressed discretization environment. experimentsassume discretization 2 meters, means 26 discrete cells feature, total676 states.assumed person robot move freely throughout space. robotsmotion deterministically controlled choice action (North, South, East, West). robotfifth action (DeliverMessage), concludes scenario used appropriately (i.e.,robot person location).persons motion stochastic falls one two modes. Part time, personmoves according Brownian motion (e.g., moves cardinal direction P r = 0.1, otherwise stays put). times, person moves directly away robot. Tag domainSection 6.2 assumes person always moves always moves away robot. realistic person cannot see robot. current experiment instead assumes personmoves according Brownian motion robot far away, moves away robotcloser (e.g., < 4m). person policy designed way encourage robotfind robust policy.terms state observability, two components: robot senseposition, sense persons position. first case, assumptionrobot knows position times. may seem like generous (oroptimistic) assumption, substantial experience domains size maps qualitydemonstrated robust localization abilities (Thrun et al., 2000). especially trueplanning operates relatively coarse resolution (2 meters) compared localization precision(10 cm). exact position information assumed planning domain, executionphase (during actually measure performance) update belief using full localizationinformation, includes positional uncertainty whenever appropriate.Regarding detection person, assumption robot knowledgepersons position unless s/he within range 2 meters. plausible given robotssensors. However, even short-range, small probability (P r = 0.01) robotmiss person therefore return false negative.general, one could make sensible assumptions persons likely position (e.g., basedknowledge daily activities), however currently information therefore assume uniform distribution initial positions. persons subsequent movements370fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDPexpressed motion model described (i.e., mix Brownian motion purposeful avoidance).reward function straightforward: R = 1 motion action, R = 10robot decides DeliverMessage cell person, R = 100robot decides DeliverMessage persons absence. task terminates robotsuccessfully delivers message (i.e., = DeliverM essage srobot = sperson ). assumediscount factor 0.95.assume known initial belief, b0 , consisting uniform distribution states.used selecting belief points planning, subsequently executing testingfinal policy.initial map (Fig. 12) domain collected mobile robot, slightly cleanedhand remove artifacts (e.g., people walking by). assumed model parametersdescribed here, applied PBVI planning problem such. Value updates belief pointexpansions applied alternation (in simulation) policy able find person99% trials (trials terminated person found 100 execution steps).final policy implemented tested onboard publicly available CARMEN robot simulator (Montemerlo, Roy, & Thrun, 2003).7.2 Comparative Evaluation PBVI Perseussubtask described here, 626 states, beyond capabilities exact POMDP solvers.Furthermore, demonstrated below, MDP-type approximations equipped handleuncertainty type exhibited task. main purpose analysis evaluateeffectiveness point-based approach described paper address problem.results Tag domain (Section 6.2) hint fact PBVI algorithms may ablehandle task, realistic map modified motion model provide new challenges.begin investigation directly comparing performance PBVI (with GER belief points selection) Perseus algorithm complex robot domain. Perseusdescribed Section 5; results presented produced using code provided authors (Perseus, 2004). Results algorithms assume fixed POMDP model generatedrobot simulator. model stored solved offline algorithm.PBVI Perseus parameters set. PBVI requires: number new beliefpoints add expansion (Badd ) planning horizon expansion (H). Perseusrequires: number belief points generate random walk (B) maximum planningtime (T ). Results presented assume following parameter settings: Badd = 30, H = 25,B=10,000, =1500. algorithms fairly robust changes parameters.6Figure 13 summarizes results experiment. suggest number observations.shown Figure 13(a), algorithms find best solution similar time,PBVI+GER better anytime performance Perseus (e.g., much better policy foundgiven 100 sec).shown Figure 13(b), algorithms require similar number -vectors.shown Figure 13(c), PBVI+GER requires many fewer beliefs.6. 25% change parameter value yielded sensibly similar results terms reward number vectors,though course time, memory, number beliefs varied.371fiP INEAU , G ORDON & HRUN510120PBVI+GERGERPerseusQMDPPBVI+GERPerseus10015# alpha vectorsREWARD2025303580604040204550 1100110231010TIME (secs)100 010410110510PBVI+GERPerseus410# beliefs310210110010 010110210TIME (secs)310410(b)Memory requirement = (#alphas + #beliefs)*#states(a)210TIME (secs)310410(c)810PBVI+GERPerseus710610510410010110210TIME (secs)310410(d)Figure 13: Comparison PBVI Perseus robot simulation domainrequires fewer beliefs, PBVI+GER much lower memory requirements;quantified Figure 13(d).new results suggest PBVI Perseus similar performance objectivefind near-optimal solution, time memory constrained. cases one willingtrade accuracy time, PBVI may provide superior anytime performance. casesmemory limited, PBVIs conservative approach respect belief point selectionadvantageous. properties suggest PBVI may scale better large domains.7.3 Experimental Results Robot Simulatorresults presented assume POMDP model used planning testing (i.e., compute reward Figure 13(a)). useful carry large numberexperiments. model however cannot entirely capture dynamics realistic robot system,therefore concern policy learned point-based methods performwell realistic robot. verify robustness approach, final PBVI control policyimplemented tested onboard publicly available CARMEN robot simulator (Montemerloet al., 2003).372fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDPresulting policy illustrated Figure 14. figure shows five snapshots obtainedsingle run. particular scenario, person starts far end left corridor.persons location shown figures since observable robot.figure instead shows belief person positions, represented distribution point samples(grey dots Fig. 14). point represents plausible hypothesis persons position.figure shows robot starting far right end corridor (Fig. 14a). robot moves towardleft rooms entrance (Fig. 14b). proceeds check entire room (Fig. 14c).relatively certain person nowhere found, exits room (Fig. 14d),moves left branch corridor, finally finds person endcorridor (Fig. 14e).policy optimized start position (for person robot). scenarioshown Figure 14 one longer execution traces since robot ends searching entireenvironment finding person. interesting compare choice actionsnapshots (b) (d). robot position practically identical. Yet (b) robot choosesgo room, whereas (d) robot chooses move toward left. directresult planning beliefs, rather states. belief distribution person positionsclearly different two cases, therefore policy specifies different courseaction.Figure 15 looks policy obtained solving problem using QMDP heuristic. Four snapshots offered different stages specific scenario, assuming personstarted far left side robot far right side (Fig. 15a). proceedingroom entrance (Fig. 15b), robot continues corridor almost reaches end(Fig. 15c). turns around comes back toward room entrance, stations(Fig. 15d) scenario forcibly terminated. result, robot cannot find persons/he left edge corridor room. Whats more, runningaway behavior adopted subject, even person starts elsewhere corridor,robot approaches person gradually retreat left similarly escape robot.Even though QMDP explicitly plan beliefs, generate different policy actionscases state identical belief different. seen comparing Figure 15 (b) (d). these, robot identically located, however belief personpositions different. (b), probability mass left robot, therefore travels direction. (d), probability mass distributed evenly three branches(left corridor, room, right corridor). robot equally pulled directions therefore stopsthere. scenario illustrates strength QMDP. Namely, many casesnecessary explicitly reduce uncertainty. However, also shows sophisticatedapproaches needed handle cases.results show PBVI perform outside bounds simple maze domains,able handle realistic problem domains. particular, throughout evaluation, robotsimulator way constrained behave described POMDP model (Sec. 7.1).means robots actions often stochastic effects, robots position alwaysfully observable, belief tracking performed asynchronously (i.e., alwaysstraightforward ordering actions observations). Despite misalignment modelassumed planning, execution environment, control policy optimized PBVI couldsuccessfully used complete task.373fiP INEAU , G ORDON & HRUN(a) t=1(b) t=7(c) t=12(d) t=17(e) t=29Figure 14: Example PBVI policy successfully finding person374fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDP(a) t=1(b) t=7(c) t=17(d) t=27Figure 15: Example QMDP policy failing find person375fiP INEAU , G ORDON & HRUN8. Discussionpaper describes class anytime point-based POMDP algorithms called PBVI, combines point-based value updates strategic selection belief points, solve large POMDPs.extensions PBVI framework, whereby value updates applied groups beliefpoints according spatial distribution, described (Pineau, Gordon, & Thrun, 2004).main contributions pertaining PBVI framework summarized.Scalability. PBVI framework important step towards truly scalable POMDP solutions.achieved bounding policy size selection small set belief points.Anytime planning. PBVI-class algorithms alternates steps value updating stepsbelief point selection. new points added, solution improves, expense increasedcomputational time. trade-off controlled adjusting number points. algorithm terminated either satisfactory solution found, planning timeelapsed.Bounded error. provide theoretical bound error approximation introducedPBVI framework. result holds range belief point selection methods, leaddirectly development new PBVI-type algorithm: PBVI+GER, estimateserror bound used directly select belief points. Furthermore find boundsuseful assessing stop adding belief points.Exploration. proposed set new point selection heuristics, explore treereachable beliefs select useful belief points. successful technique described, GreedyError Reduction (GER), uses estimate error bound candidate belief points selectuseful points.Improved empirical performance. PBVI demonstrated ability reduce planning timenumber well-known POMDP problems, including Tiger-grid, Hallway, Hallway2.operating set discrete points, PBVI algorithms perform polynomial-time value updates,thereby overcoming curse history paralyzes exact algorithms. GER technique usedselect points allows us solve large problems fewer belief points alternative approaches.New problem domain. PBVI applied new POMDP planning domain (Tag),generated approximate solution outperformed baseline algorithms QMDP IncrementalPruning. new domain since adopted test case algorithms (Vlassis &Spaan, 2004; Smith & Simmons, 2004; Braziunas & Boutilier, 2004; Poupart & Boutilier, 2004).fosters increased ease comparison new techniques. comparative analysisprovided Section 7.2 highlighting similarities differences PBVI Perseus.Demonstrated performance. PBVI applied context robotic search-and-rescuetype scenario, mobile robot required search environment find non-stationaryindividual. PBVIs performance evaluated using realistic, independently-developed, robotsimulator.significant portion paper dedicated thorough comparative analysis point-basedmethods. includes evaluating range point-based selection methods, well evaluatingmechanisms ordering value updates. comparison point-based selection techniques suggest GER method presented Section 4.5 superior naive techniques. termsordering value updates, randomized strategy used Perseus algorithm appearseffective accelerate planning. natural next step would combine GER belief selectionheuristic Perseuss random value updates. performed experiments along lines,376fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDPachieve significant speed-up current performance PBVI Perseus (e.g.,reported Figure 13(a)). likely belief points chosen carefully (as GER),points needs updated systematically therefore additional benefitusing randomized value updates.Looking towards future, important remember demonstratedability solve problems large POMDP standards, many real-world domains far exceedcomplex domains considered paper. particular, unusual problemexpressed number multi-valued state features, case number states growsexponentially number features. concern belief point-vector dimensionality |S| (where |S| number states) dimensions updatedsimultaneously. important issue address improve scalability point-based valueapproaches general.various existing attempts overcoming curse dimensionality POMDPs.thesee. g. belief compression techniques Roy Gordon (2003)cannotincorporated within PBVI framework without compromising theoretical properties (as discussed Section 3). Others, particular exact compression algorithm Poupart Boutilier(2003), combined PBVI. However, preliminary experiments directionyielded little performance improvement. reason believe approximate value compression would yield better results, expense forgoing PBVIs theoretical properties. challenge therefore devise function-approximation techniques reducedimensionality effectively, maintaining convexity properties solution.secondary (but less important) issue concerning scalability PBVI pertainsnumber belief points necessary obtain good solution. problems addressed thus farusually solved O(|S|) belief points, need true. worse case, numberbelief points necessary may exponential plan length. PBVI framework accommodate wide variety strategies generating belief points, Greedy Error Reductiontechnique seems particularly effective. However unlikely definitive answer beliefpoint selection. general terms, relates closely well-known issue explorationversus exploitation, arises across wide array problem-solving techniques.promising opportunities future research aside, PBVI framework alreadypushed envelope POMDP problems solved existing computational resources.field POMDPs matures, finding ways computing policies efficiently likely continuemajor bottleneck. hope point based algorithms PBVI play leadingrole search efficient algorithms.Acknowledgmentsauthors wish thank Craig Boutilier, Michael Littman, Andrew Moore Matthew Masonmany thoughtful comments discussions regarding work. also thank Darius Braziunas,Pascal Poupart, Trey Smith Nikos Vlassis, conversations regarding algorithmsresults. contributions Michael Montemerlo Nicholas Roy conducting empiricalrobot evaluations gratefully acknowledged. Finally, thank three anonymous reviewersone dedicated editor (Sridhar Mahadevan) whose feedback significantly improved paper.work funded DARPA MARS program NSFs ITR program (Project: RoboticAssistants Elderly, PI: J. Dunbar-Jacob).377fiP INEAU , G ORDON & HRUNReferencesAstrom, K. J. (1965). Optimal control markov decision processes incomplete state estimation. Journal Mathematical Analysis Applications, 10, 174205.Bellman, R. (1957). Dynamic Programming. Princeton University Press.Bertsekas, D. P., & Tsitsiklis, J. (1996). Neuro-Dynamic Programming. Athena Scientific.Blum, A. L., & Furst, M. L. (1997). Fast planning planning graph analysis. ArtificialIntelligence, 90(1-2), 281300.Bonet, B. (2002). epsilon-optimal grid-based algorithm partially obserable Markov decisionprocesses. Machine Learning: Proceedings 2002 International Conference (ICML),pp. 5158.Boutilier, C., Dean, T., & Hanks, S. (1999). Decision-theoretic planning: Structural assumptionscomputational leverage. Journal Artificial Intelligence Research, 11, 194.Boyen, X., & Koller, D. (1998). Tractable inference complex stochastic processes. Proceedings Fourteenth Conference Uncertainty Artificial Intelligence (UAI), pp. 3342.Brafman, R. I. (1997). heuristic variable grid solution method POMDPs. ProceedingsFourteenth National Conference Artificial Intelligence (AAAI), pp. 727733.Braziunas, D., & Boutilier, C. (2004). Stochastic local search POMDP controllers. Proceedings Nineteenth National Conference Artificial Intelligence (AAAI), pp. 690696.Burgard, W., Cremers, A. B., Fox, D., Hahnel, D., Lakemeyer, G., Schulz, D., Steiner, W., & Thrun,S. (1999). Experiences interactive museum tour-guide robot. Artificial Intelligence,114, 355.Cassandra, A. (1999).Tonysresearch/ai/pomdp/code/index.html.POMDPpage.http://www.cs.brown.edu/Cassandra, A., Littman, M. L., & Zhang, N. L. (1997). Incremental pruning: simple, fast, exactmethod partially observable Markov decision processes. Proceedings ThirteenthConference Uncertainty Artificial Intelligence (UAI), pp. 5461.Chapman, D. (1987). Planning conjunctive goals. Artificial Intelligence, 32(3), 333377.Cheng, H.-T. (1988). Algorithms Partially Observable Markov Decision Processes. Ph.D. thesis,University British Columbia.Dean, T., & Kanazawa, K. (1988). Probabilistic temporal reasoning. Proceedings SeventhNational Conference Artificial Intelligence (AAAI), pp. 524528.Devroye, L. (1986). Non-Uniform Random Variate Generation. Springer-Verlag, New York.Engelberger, G. (1999). Handbook Industrial Robotics. John Wiley Sons.Fikes, R. E., & Nilsson, N. J. (1971). STRIPS: new approach application theoremproving problem solving. Artificial Intelligence, 2, 189208.Hauskrecht, M. (1997). Incremental methods computing bounds partially observable Markovdecision processes. Proceedings Fourteenth National Conference Artificial Intelligence (AAAI), pp. 734739.378fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDPHauskrecht, M. (2000). Value-function approximations partially observable Markov decisionprocesses. Journal Artificial Intelligence Research, 13, 3394.Jazwinski, A. M. (1970). Stochastic Processes Filtering Theory. Academic, New York.Kaelbling, L. P., Littman, M. L., & Cassandra, A. R. (1998). Planning acting partiallyobservable stochastic domains. Artificial Intelligence, 101, 99134.Kalman, R. E. (1960). new approach linear filtering prediction problems. TransactionsASME, Journal Basic Engineering, 82, 3545.Lacey, G., & Dawson-Howe, K. M. (1998). application robotics mobility aidelderly blind. Robotics Autonomous Systems, 23, 245252.Littman, M. L. (1996). Algorithms Sequential Decision Making. Ph.D. thesis, Brown University.Littman, M. L., Cassandra, A. R., & Kaelbling, L. P. (1995a). Learning policies partially obsevable environments: Scaling up. Tech. rep. CS-95-11, Brown University, DepartmentComputer Science.Littman, M. L., Cassandra, A. R., & Kaelbling, L. P. (1995b). Learning policies partially obsevable environments: Scaling up. Proceedings Twelfth International ConferenceMachine Learning, pp. 362370.Lovejoy, W. S. (1991a). Computationally feasible bounds partially observed Markov decisionprocesses. Operations Research, 39(1), 162175.Lovejoy, W. S. (1991b). survey algorithmic methods partially observable Markov decisionprocesses. Annals Operations Research, 28, 4766.McAllester, D., & Roseblitt, D. (1991). Systematic nonlinear planning. Proceedings NinthNational Conference Artificial Intelligence (AAAI), pp. 634639.Monahan, G. E. (1982). survey partially observable Markov decision processes: Theory, models, algorithms. Management Science, 28(1), 116.Montemerlo, M., Roy, N., & Thrun, S. (2003). Perspectives standardization mobile robotprogramming: Carnegie Mellon navigation (CARMEN) toolkit. ProceedingsIEEE/RSJ International Conference Intelligent Robots Systems (IROS), Vol. 3, pp. pp24362441.Paquet, S. (2005). Distributed Decision-Making Task Coordination Dynamic, UncertainReal-Time Multiagent Environments. Ph.D. thesis, Universite Laval.Penberthy, J. S., & Weld, D. (1992). UCPOP: sound, complete, partial order planning ADL.Proceedings Third International Conference Knowledge Representation Reasoning, pp. 103114.Perseus (2004) http://staff.science.uva.nl/mtjspaan/software/approx.Pineau, J., Gordon, G., & Thrun, S. (2004). Applying metric-trees belief-point POMDPs.Neural Information Processing Systems (NIPS), Vol. 16.Pineau, J., Montermerlo, M., Pollack, M., Roy, N., & Thrun, S. (2003). Towards robotic assistantsnursing homes: challenges results. Robotics Autonomous Systems, 42(3-4), 271281.Pollack, M. (2002). Planning technology intelligent cognifitve orthotics. Proceedings6th International Conference AI Planning & Scheduling (AIPS).379fiP INEAU , G ORDON & HRUNPoon, K.-M. (2001). fast heuristic algorithm decision-theoretic planning. Masters thesis,Hong-Kong University Science Technology.Poupart, P., & Boutilier, C. (2000). Value-directed belief state approximation POMDPs.Proceedings Sixteenth Conference Uncertainty Artificial Intelligence (UAI), pp.409416.Poupart, P., & Boutilier, C. (2003). Value-directed compression POMDPs. Advances NeuralInformation Processing Systems (NIPS), Vol. 15.Poupart, P., & Boutilier, C. (2004). Bounded finite state controllers. Advances Neural Information Processing Systems (NIPS), Vol. 16.Rabiner, L. R. (1989). tutorial hidden Markov models selected applications speechrecognition. Proceedings IEEE, 77(2), 257285.Rosencrantz, M., Gordon, G., & Thrun, S. (2003). Locating moving entities dynamic indoorenvironments teams mobile robots. Second International Joint ConferenceAutonomous Agents MultiAgent Systems (AAMAS), pp. 233240.Roy, N., & Gordon, G. (2003). Exponential family PCA belief compression POMDPs.Advances Neural Information Processing Systems (NIPS), Vol. 15, pp. 10431049.Smith, T., & Simmons, R. (2004). Heuristic search value iteration POMDPs. ProceedingsTwentieth Conference Uncertainty Artificial Intelligence (UAI).Sondik, E. J. (1971). Optimal Control Partially Observable Markov Processes. Ph.D. thesis,Stanford University.Spaan, M., & Vlassis, N. (2005). Perseus: Randomized point-based value iteration POMDPs.Journal Artificial Intelligence Research (JAIR), 195220.Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MIT Press.Thrun, S., Fox, D., Burgard, W., & Dellaert, F. (2000). Robust Monte Carlo localization mobilerobots. Artificial Intelligence, 128(1-2), 99141.Vlassis, N., & Spaan, M. T. J. (2004). fast point-based algorithm POMDPs. ProceedingsBelgian-Dutch Conference Machine Learning.White, C. C. (1991). survey solution techniques partially observed Markov decisionprocess. Annals Operations Research, 32, 215230.Zhang, N. L., & Liu, W. (1996). Planning stochastic domains: Problem characteristics approximation. Tech. rep. HKUST-CS96-31, Dept. Computer Science, Hong Kong University Science Technology.Zhang, N. L., & Zhang, W. (2001). Speeding convergence value iteration partiallyobservable Markov decision processes. Journal Artificial Intelligence Research, 14, 2951.Zhou, R., & Hansen, E. A. (2001). improved grid-based approximation algorithm POMDPs.Proceedings 17th International Joint Conference Artificial Intelligence (IJCAI),pp. 707716.380fiJournal Artificial Intelligence Research 27 (2006) 203-233Submitted 01/06; published 10/06Active Learning Multiple ViewsIon Musleaimuslea@languageweaver.comLanguage Weaver, Inc.4640 Admiralty Way, Suite 1210Marina del Rey, CA 90292Steven Mintonminton@fetch.comFetch Technologies, Inc.2041 Rosecrans Ave., Suite 245El Segundo, CA 90245Craig A. Knoblockknoblock@isi.eduUniversity Southern California4676 Admiralty WayMarina del Rey, CA 90292AbstractActive learners alleviate burden labeling large amounts data detectingasking user label informative examples domain. focusactive learning multi-view domains, several disjoint subsetsfeatures (views), sufficient learn target concept. papermake several contributions. First, introduce Co-Testing, first approachmulti-view active learning. Second, extend multi-view learning frameworkalso exploiting weak views, adequate learning conceptgeneral/specific target concept. Finally, empirically show Co-Testingoutperforms existing active learners variety real world domains wrapperinduction, Web page classification, advertisement removal, discourse tree parsing.1. IntroductionLabeling training data machine learning algorithm tedious, time consuming,error prone process; furthermore, application domains, labeling examplemay also extremely expensive (e.g., may require running costly laboratory tests).Active learning algorithms (Cohn, Atlas, & Ladner, 1994; Roy & McCallum, 2001; Tong& Koller, 2001) cope problem detecting asking user labelinformative examples domain, thus reducing users involvement datalabeling process.paper, introduce Co-Testing, active learning technique multi-viewlearning tasks; i.e., tasks several disjoint subsets features (views),sufficient learn concepts interest. instance, Web page classificationmulti-view task Web pages classified based words appeareither documents hyperlinks pointing (Blum & Mitchell, 1998);similarly, one classify segments televised broadcast based either videoaudio information, one perform speech recognition based either sound lipmotion features (de Sa & Ballard, 1998).c2006AI Access Foundation. rights reserved.fiMuslea, Minton, & KnoblockCo-Testing two-step iterative algorithm requires input labeledmany unlabeled examples. First, Co-Testing uses labeled examples learnhypothesis view. applies learned hypotheses unlabeled examplesdetects set contention points (i.e., unlabeled examples views predictdifferent label); finally, queries (i.e., asks user label) one contentionpoints, adds newly labeled example training set, repeats whole process.Intuitively, Co-Testing relies following observation: if, unlabeled example,hypotheses learned view predict different label, least one makesmistake particular prediction. asking user label contention point,Co-Testing guaranteed provide useful information view made mistake.paper make several contributions. First, introduce Co-Testing, familyactive learners multi-view learning tasks. Second, extend traditional multi-viewlearning framework also allowing use weak views, one adequately learnconcept strictly general specific target concept (allprevious multi-view work makes strong view assumption view adequatelearning target concept). Last least, show that, practice, Co-Testing clearlyoutperforms existing active learners variety real world domains wrapperinduction, Web page classification, advertisement removal, discourse tree parsing.Compared previous work, Co-Testing unique several ways:1. existing multi-view approaches (Blum & Mitchell, 1998; Collins & Singer, 1999; Pierce& Cardie, 2001), also use small set labeled large set unlabeledexamples, based idea bootstrapping views other. contrast, Co-Testing first algorithm exploits multiple views active learningpurposes. Furthermore, Co-Testing allows simultaneous use strong weakviews without additional data engineering costs.2. existing active learners, pool domain features together, typically designedexploit properties specific particular (type of) base learner (i.e., algorithm used learn target concept); example, uncertainty reduction methodsassume base learner provides reliable estimate confidenceprediction. contrast, Co-Testing uses multiple views detect contentionpoints, among chooses next query. approach several advantages:- converges quickly target concept based idea learningmistakes (remember contention point guaranteed representmistake least one views). contrast, existing active learners oftentimes query examples classified correctly, low confidence.- simplest form (i.e., Naive Co-Testing, described section 4),makes assumptions properties base learner. precisely,simply querying arbitrary contention point, Co-Testing guaranteedprovide mistaken view highly informative example.- considering contention points query candidates, allows usequery selection heuristics - computationally - expensive appliedentire set unlabeled examples.204fiActive Learning Multiple Viewsremainder paper organized follows. First, introduce conceptsnotation, followed comprehensive survey literature active multi-viewlearning. formally introduce Co-Testing family algorithms presentempirical evaluation variety real-world domains.2. Preliminaries: Terminology Notationgiven learning task, set possible domain examples called instancespace denoted X. x X represents particular example instance.paper concerned mostly examples represented feature vectorsstore values various attributes features describe example.concept learned called target concept, seen functionc : X {l1 , l2 , . . . , lN } classifies instance x member one N classesinterest l1 , l2 , . . . , lN . order learn target concept, user provides set trainingexamples, consists instance x X label, c(x). notationhx, c(x)i denotes training example. symbol L used denote set labeledtraining examples (also known training set).Given training set L target concept c, inductive learning algorithm Lsearches function h : X {l1 , l2 , . . . , lN } x X, h(x) = c(x). learnerL searches h within set H possible hypotheses, (typically) determinedperson designs learning algorithm. hypothesis h consistenttraining set L hx, c(x)i L, h(x) = c(x). Finally, version space V H,Lrepresents subset hypotheses H consistent training set L.definition, passive learning algorithm takes input randomly chosen trainingset L. contrast, active learning algorithms ability choose examples L.is, detect informative examples instance space X askuser label them; examples chosen labeling called queries.paper focus selective sampling algorithms, active learners choosequeries given working set unlabeled examples U (we use notation hx, ?idenote unlabeled examples). paper terms active learning selectivesampling used interchangeably.traditional, single-view machine learning scenario, learner access entireset domain features. contrast, multi-view setting one partition domainsfeatures subsets (views) sufficient learning target concept. Existing multiview learners semi-supervised algorithms: exploit unlabeled examples boostaccuracy classifiers learned view bootstrapping views other.multi-view learning, example x described different set featuresview. example, domain k views V1 , V2 , . . . Vk , labeled example seentuple hx1 , x2 , . . . , xk , li, l label, x1 , x2 , . . . , xk descriptionsk views. Similarly, k-view unlabeled example denoted hx1 , x2 , . . . , xk , ?i.example x, Vi (x) denotes descriptions xi x Vi . Similarly, Vi (L) consistsdescriptions Vi examples L.205fiMuslea, Minton, & Knoblock3. Background Active Multi-view LearningActive learning seen natural development earlier work optimumexperimental design (Fedorov, 1972). early 1980s, machine learning communitystarted recognizing advantages inductive systems capable queryinginstructors. example, order detect errors Prolog programs, AlgorithmicDebugging System (Shapiro, 1981, 1982) allowed ask user several types queries.Similarly, concept learning systems Marvin (Sammut & Banerji, 1986) cat(Gross, 1991) used queries integral part respective learning strategies.literature review structured follows. First, discuss early, mostlytheoretical results query construction. focus selective sampling algorithms,select next query one unlabeled examples working set. Finally,conclude reviewing existing multi-view learning algorithms.3.1 Active Learning Query Constructionearliest approaches formalizing active learning appeared seminal papersAngluin (1982, 1988) Valiant (1984), focused exact concept inductionlearning pac framework, respectively. theoretic work focused learning classesconcepts regular sets, monotone dnf expressions, expressions. Besidesmembership queries example target concept?, Angluin also usedsophisticated types queries equivalence queries (is concept equivalenttarget concept?) superset queries (is concept superset target concept?).early active learners took constructive approach query generationsense query (artificially) constructed setting values attributesquery informative possible. practice, may raise seriousproblems; example, consider hand-writing recognizer must discriminate10 digits (Lang & Baum, 1992). scenario, informative query may consistimage represents fusion two similarly-looking digits, 3 5.presented image, user cannot label properly representrecognizable digit. Consequently, query wasted totally irrelevant image.Similar situations appear many real world tasks text classification, informationextraction, speech recognition: whenever active learner artificially builds querydomain, highly unlikely newly created object meaninghuman user.Despite practical applicability issue, constructive approach active learningleads interesting theoretical insights merits various types queries.example, researchers considered learning with:- incomplete queries, querys answer may dont know. (Angluin &Slonim, 1991; Goldman & Mathias, 1992; Sloan & Turan, 1994; Blum, Chalasani,Goldman, & Slonim, 1998);- malicious queries, answer queries may erroneous (Angluin, Krikis,Sloan, & Turan, 1997; Angluin & Krikis, 1994; Angluin, 1994).New learning problems also considered, unrestricted dnf expressions (Jackson, 1994; Blum, Furst, Jackson, Kearns, Mansour, & Rudich, 1994) unions boxes206fiActive Learning Multiple Views(Goldberg, Goldman, & Mathias, 1994) tree patterns (Amoth, Cull, & Tadepalli, 1998,1999) Horn clauses (Reddy & Tadepalli, 1997). Researchers also reported resultsapplying active learning neural networks (Hwang, Choi, Oh, & Marks, 1991; Baum, 1991;Watkin & Rau, 1992; Hasenjager & Ritter, 1998) combining declarative bias (priorknowledge) active learning (Tadepalli, 1993; Tadepalli & Russell, 1998).3.2 Selective SamplingSelective sampling represents alternative active learning approach. typically appliesclassification tasks learner access large number unlabeled examples.scenario, rather constructing informative query, active learner asksuser label one existing unlabeled examples. Depending source unlabeledexamples, two main types sampling algorithms: stream- pool- based.former assumes active learner access (infinite) stream unlabeledexamples (Freund, Seung, Shamir, & Tishby, 1997; Argamon-Engelson & Dagan, 1999;Dagan & Engelson, 1995); successive examples presented it, active learnermust decide labeled user. contrast, pool-basedscenario (Lewis & Gale, 1994; Lewis & Catlett, 1994; McCallum & Nigam, 1998; Muslea,Minton, & Knoblock, 2000, 2002a), learner presented working set unlabeledexamples; order make query, active learner goes entire poolselects example labeled next.Based criterion used select next query, selective sampling algorithms fallthree main categories:- uncertainty reduction: system queries example current hypothesismakes least confident prediction;- expected-error minimization: system queries example maximizes expectedreduction classification error;- version space reduction: system queries example that, labeled, removesmuch possible version space.uncertainty reduction approach selective sampling works follows: first, one useslabeled examples learn classifier; system queries unlabeled exampleclassifier makes least confident prediction. straightforward ideaapplied base learner one reliably estimate confidencepredictions. Confidence-estimation heuristics proposed variety base learnerslogistic regression (Lewis & Gale, 1994; Lewis & Catlett, 1994), partially hiddenMarkov Models (Scheffer & Wrobel, 2001), support vector machines (Schohn & Cohn, 2000;Campbell, Cristianini, & Smola, 2000), inductive logic programming (Thompson, Califf,& Mooney, 1999).second, sophisticated approach selective sampling, expected-error minimization, based statistically optimal solution active learning problem.scenario, intuition query unlabeled example minimizes error rate(future) classifier test set. Even though (extremely simple) baselearners one find optimal queries (Cohn, Ghahramani, & Jordan, 1996),207fiMuslea, Minton, & Knoblocktrue inductive learners. Consequently, researchers proposed methods estimateerror reduction various types base learners. example, Roy McCallum(2001) use sample estimation method Naive Bayes classifier; similar approachesalso described parameter learning Bayesian nets (Tong & Koller, 2000)nearest neighbor classifiers (Lindenbaum, Markovitch, & Rusakov, 2004).heuristic approach expected-error minimization summarized follows.First, one chooses loss function (Roy & McCallum, 2001) used estimatefuture error rate. unlabeled example x working set consideredpossible next query, system estimates expected reduction error ratepossible label x may take. Finally, system queries unlabeled exampleleads largest estimated reduction error rate.Finally, typical version space reduction active learner works follows: generatescommittee several hypotheses, queries unlabeled examplesdisagreement within committee greatest. two-class learning problem,strategy translates making queries remove approximately half version space.Depending method used generate committee, one distinguish several typesactive learners:- Query-by-Committee selects committee randomly sampling hypothesesversion space. Query-by-Committee applied variety base learnersperceptrons (Freund et al., 1997), Naive Bayes (McCallum & Nigam, 1998), Winnow (Liere & Tadepalli, 1997). Furthermore, Argamon-Engelson Dagan (1999,1995) introduce extension Query-by-Committee Bayesian learning.Bayesian framework, one create committee sampling classifiers accordingposterior distributions; is, better hypothesis explains trainingdata, likely sampled. main limitation Query-by-Committeeapplied base learners feasible randomly sample hypotheses version space.- sg-net (Cohn et al., 1994) creates 2-hypothesis committee consists mostgeneral most-specific classifier. two hypotheses generated modifying base learner learns classifier labels many possibleunlabeled examples working set positive negative, respectively.approach obvious drawback: requires user modify base learnergenerate most-general most-specific classifiers.- Active-Decorate (Melville & Mooney, 2004) seen generalizationimprovement sg-net. generates large diverse committee successivelyaugmenting original training set additional sets artificially-generated examples. precisely, generates artificial examples keeping distributioninstance space; applies current committee example,labels artificial example label contradicts committeespredictions. new classifier learned augmented dataset,entire process repeated desired committee size reached. Active-Decoratesuccessfully used domains nominal numeric features, unclearcould applied domains text classification extraction,generating artificial examples may problematic.208fiActive Learning Multiple Views- Query-by-Bagging Query-by-Boosting (Abe & Mamitsuka, 1998) create committee using well-known bagging (Breiman, 1996) boosting (Schapire, 1990)algorithms, respectively. algorithms introduced c4.5 base learner,bagging boosting known work extremely well.general, committee-based sampling tends associated version spacereduction approach. However, base learners support vector machines, oneuse single hypothesis make queries remove (approximately) half versionspace (Tong & Koller, 2001). Conversely, committee-based sampling also seenrelying uncertainty reduction principle: all, unlabeled exampledisagreement within committee greatest also seen exampleleast certain classification.3.3 Multi-view, Semi-supervised Learningalready mentioned, Blum Mitchell (1998) provided first formalization learningmulti-view framework. Previously, topic largely ignored, though ideaclearly shows applications word sense disambiguation (Yarowsky, 1995)speech recognition (de Sa & Ballard, 1998). Blum Mitchell proved two independent, compatible views used pac-learn (Valiant, 1984) concept basedlabeled many unlabeled examples. also introduced Co-Training, firstgeneral-purpose, multi-view algorithm.Collins Singer (1999) proposed version Co-Training biased towardslearning hypotheses predict label unlabeled examples.introduce explicit objective function measures compatibility learnedhypotheses use boosting algorithm optimize objective function. relatedpaper (Dasgupta, Littman, & McAllester, 2001), authors provide pac-like guaranteesnovel Co-Training algorithm (the assumption is, again, viewsindependent compatible). Intuitively, Dasgupta et al. (2001) show ratiocontention points unlabeled examples upper-bound error rate classifierslearned two views.Abney (2002) extends work Dasgupta et al. relaxing view independenceassumption. precisely, author shows even views weakly dependent, ratio contention points unlabeled examples still represents upper-boundtwo views error rate. Unfortunately, paper introduces theoretical definition weak dependence views, without providing intuitive explanationpractical consequences.Researchers proposed two main types extensions original Co-Training algorithm: modifications actual algorithm changes aiming extend practicalapplicability. former cover wide variety scenarios:- Co-EM (Nigam & Ghani, 2000; Brefeld & Scheffer, 2004) uses Expectation Maximization(Dempster, Laird, & Rubin, 1977) multi-view learning. Co-EM seenclosest implementation theoretical framework proposed Blum Mitchell(1998).209fiMuslea, Minton, & Knoblock- Ghani (2002) uses Error-Correcting Output Codes allow Co-Training Co-EMscale problems large number classes.- Corrected Co-Training (Pierce & Cardie, 2001) asks user manually correctlabels bootstrapped examples. approach motivated observationquality bootstrapped data crucial Co-Trainings convergence.- Co-Boost (Collins & Singer, 1999) Greedy Agreement (Abney, 2002) Co-Trainingalgorithms explicitly aim minimize number contention points.second group extensions Co-Training motivated fact that, practice,one also encounters many problems straightforward way splitfeatures two views. order cope problem, Goldman Zhou (2000)advocate use multiple biases instead multiple views. authors introducealgorithm similar Co-Training, bootstraps hypotheses learnedtwo different base learners; approach relies assumption base learnersgenerate hypotheses partition instance space equivalence classes. recentpaper, Zhou Goldman (2004) use idea multi-biased committee activelearning; i.e., use various types base learners obtain diverse committee,query examples committee disagree most.Within multi-view framework, Nigam Ghani (2000) show that, bag-ofwords text classification, one create two views arbitrarily splitting original setfeatures two sub-sets. approach fits well text classification domain,features abundant, unlikely work types problems.alternative solution proposed Raskutti, Ferra, Kowalczyk (2002),authors create second view consists variety features measure examplessimilarity N largest clusters domain. Finally, Muslea, Minton, Knoblock(2002b) propose meta-learning approach uses past experiences predict whethergiven views appropriate new, unseen learning task.4. Co-Testing Family Algorithmssection, discuss detail Co-Testing family algorithms. alreadymentioned, Co-Testing seen two-step iterative process: first, useslabeled examples learn hypothesis view; queries unlabeled exampleviews predict different labels. adding queried example trainingset, entire process repeated number iterations.remainder section organized follows: first, formally present CoTesting family algorithms discuss several members. introduceconcepts strong weak views, analyze Co-Testing exploit typesviews (previous multi-view learners could use strong views). Finally, comparecontrast Co-Testing related approaches.4.1 Family AlgorithmsTable 1 provides formal description Co-Testing family algorithms. inputconsists k views V1 , V2 , . . . , Vk , base learner L, sets L U labeled210fiActive Learning Multiple ViewsTable 1: Co-Testing family algorithms: repeatedly learn classifier viewquery example predict different labels.Given:- base learner L- learning domain features V = {a1 , a2 , . . . , }- k views V1 , V2 , . . . , Vk V =k[i=1Vi i, j {1, 2, . . . , k}, 6= j, Vi Vj =- sets L U labeled unlabeled examples, respectively- number N queries made- LOOP N iterations- use L learn classifiers h1 , h2 , . . . , hk views V1 , V2 , . . . , Vk , respectively- let ContentionP oints = { hx1 , x2 , . . . , xk , ?i U | i, j hi (xi ) 6= hj (xj ) }- let hx1 , x2 , . . . , xk , ?i = SelectQuery(ContentionP oints)- remove hx1 , x2 , . . . , xk , ?i U ask label l- add hx1 , x2 , . . . , xk , li L- hOU = CreateOutputHypothesis( h1 , h2 , . . . , hk )unlabeled examples, respectively. Co-Testing algorithms work follows: first, learnclassifiers h1 , h2 , . . . , hk applying algorithm L projection examplesL onto view. apply h1 , h2 , . . . , hk unlabeled examples U createset contention points, consists unlabeled examples least twohypotheses predict different label. Finally, query one contention pointsrepeat whole process number iterations. making allowednumber queries, Co-Testing creates output hypothesis used make actualpredictions.various members Co-Testing family differ two respects:strategy used select next query, manner output hypothesisconstructed. words, Co-Testing algorithm uniquely defined choicefunctions SelectQuery() CreateOutputHypothesis().paper consider three types query selection strategies:- naive: choose random one contention points. straightforward strategyappropriate base learners lack capability reliably estimatingconfidence predictions. naive query selection strategy independentdomain base learner properties, follows usedsolving multi-view learning task.- aggressive: choose query contention point Q least confidenthypotheses h1 , h2 , . . . , hk makes confident prediction; formally,211fiMuslea, Minton, & KnoblockQ=arg maxminxContentionP oints i{1,2,...,k}Conf idence(hi (x))Aggressive Co-Testing designed high accuracy domains, littlenoise. domains, discovering unlabeled examples misclassifiedhigh confidence translates queries remove significantly halfversion space.- conservative: choose contention point confidence predictionsmade h1 , h2 , . . . , hk close possible (ideally, would equally confidentpredicting different labels); is,Q=arg minxContentionP ointsmaxf {h1 ,...,hk }Conf idence(f (x))ming{h1 ,...,hk }Conf idence(g(x))!Conservative Co-Testing appropriate noisy domains, aggressive strategy may end querying mostly noisy examples.Creating output hypothesis also allows user choose variety alternatives, as:- weighted vote: combines vote hypothesis, weighted confidencerespective predictions.XhOU (x) = arg maxlLabelsConf idence(g(x))g {h1 , . . . , hk }g(x) = l- majority vote: Co-Testing chooses label predicted hypotheseslearned k views.hOU (x) = arg maxlLabelsX1g {h1 , . . . , hk }g(x) = lstrategy appropriate least three views, base learnercannot reliably estimate confidence predictions.- winner-takes-all: output hypothesis one learned view makessmallest number mistakes N queries. obvious solution2-view learning tasks base learner cannot (reliably) estimate confidence predictions. denote istakes(h1 ), istakes(h2 ), . . . , istakes(hk )number mistakes made hypotheses learned k views Nqueries,hOU (x) = arg min istakes(g)g{h1 ,...,hk }212fiActive Learning Multiple Views4.2 Learning Strong Weak Viewsoriginal multi-view setting (Blum & Mitchell, 1998; Muslea et al., 2000), one makesstrong views assumption view sufficient learn target concept. However,practice, one also encounters views one accurately learn conceptstrictly general specific concept interest (Muslea, Minton, &Knoblock, 2003). often case domains involve hierarchical classification,information extraction email classification. example, may extremelyeasy discriminate (with high accuracy) work personal emails based solelyemails sender; however, information may insufficient predictingwork personal sub-folder email stored.introduce notion weak view, one accurately learnconcept strictly general specific target concept. Notelearning weak view qualitatively different learning approximationtarget concept: latter represents learning imperfect features, formertypically refers (easily) learnable concept strict generalization/specializationtarget concept (note that, real world, imperfect features noisy labels affectlearning strong weak views).context learning strong weak views, redefine contention pointsunlabeled examples strong views predict different label.necessary step two reasons: first, weak view inadequate learningtarget concept, typically disagrees strong views large number unlabeledexamples; turn, would increase number contention points skewdistribution. Second, interested fixing mistakes made weak view,rather using view additional information source allows faster learningstrong views (i.e., fewer examples).Even though weak views inadequate learning target concept,exploited Co-Testing SelectQuery() CreateOutputHypothesis()functions. particular, weak views extremely useful domains twostrong views:- weak view used CreateOutputHypothesis() tie-breakertwo strong views predict different label.- SelectQuery() designed that, ideally, query would represent mistakestrong views. done first detecting contention points -- weak view disagrees strong views; among these, nextquery one weak view makes confident prediction.queries likely represent mistake strong views, rather onethem; turn, implies simultaneous large cuts strong version spaces,thus leading faster convergence.section 5.2.2 describe Co-Testing algorithm exploits strong weak viewswrapper induction domains (Muslea et al., 2003; Muslea, Minton, & Knoblock, 2001).Note learning strong weak views clearly extends beyond wrapper inductiontasks: example, idea exploiting complementary information sources (i.e., different213fiMuslea, Minton, & Knoblocktypes features) appears two multi-strategy learners (Kushmerick, Johnston, &McGuinness, 2001; Nahm & Mooney, 2000) discussed section 4.3.2.4.3 Co-Testing vs. Related Approachesalready mentioned section 3.3, existing multi-view approaches typically semisupervised learners bootstrap views other. two exceptions (Musleaet al., 2002a; Jones, Ghani, Mitchell, & Riloff, 2003) interleave Co-Testing Co-EM(Nigam & Ghani, 2000), thus combining best worlds: semi-supervised learningprovides active learner accurate hypotheses, lead informative queries; active learning provides semi-supervised learner informativetraining set, thus leading faster convergence.4.3.1 Co-Testing vs. Existing Active LearnersIntuitively, Co-Testing seen committee-based active learner generatescommittee consists one hypothesis view. Also note Co-Testingcombined virtually existing single-view active learners: among contentionpoints, Co-Testing select next query based heuristics discussedsection 3.2.two main differences Co-Testing active learners:- except Co-Testing variants (Muslea et al., 2002a; Jones et al., 2003),active learners work single-view framework (i.e., pool togetherdomain features).- single-view active learners typically designed particular (class of) base learner(s).example, Query-by-Committee (Seung, Opper, & Sompolinski, 1992) assumesone randomly sample hypotheses version space, UncertaintySampling (Lewis & Gale, 1994; Lewis & Catlett, 1994) relies base learnersability reliably evaluate confidence predictions. contrast, basicidea Co-Testing (i.e., querying contention points) applies multi-view problem,independently base learner used.Co-Testing approach active learning advantages disadvantages.one hand, Co-Testing cannot applied problems least twoviews. hand, multi-view problem, Co-Testing usedbest base learner particular task. contrast, single-view framework, oneoften must either create new active learning method particular base learner or, evenworse, modify existing base learner used conjunction existingsampling algorithm.illustrate last point, let us briefly consider learning information extraction,goal use machine learning extracting relevant strings collectiondocuments (e.g., extract perpetrators, weapons, victims corpus newsstories terrorist attacks). information extraction different nature typicalclassification task, existing active learners cannot applied straightforward manner:- information extraction free text (ie), existing active learners (Thompsonet al., 1999; Soderland, 1999; Scheffer & Wrobel, 2001) crafted based heuristics214fiActive Learning Multiple Viewsspecific respective base learners, rapier, whisk, Partially Hidden MarkovModels. alternative discussed Finn Kushmerick (2003), explorevariety ie-specific heuristics used active learning purposesanalyze trade-offs related using heuristics.- wrapper induction, goal extract data Web pages shareunderlying structure, reported results applying (singleview) active learning. typical wrapper induction algorithms (Musleaet al., 2001; Kushmerick, 2000; Hsu & Dung, 1998) base learners lackproperties exploited single-view active learners reviewed section 3.2.:determinist learners noise sensitive, provide confidence predictions,make mistakes training set.contrast, Co-Testing applies naturally wrapper induction (Muslea et al., 2000,2003) information extraction free text (Jones et al., 2003). duefact Co-Testing rely base learners properties identify highlyinformative set candidate queries; instead, focuses contention points, which,definition, guaranteed represent mistakes views.4.3.2 Exploiting Weak Viewsbriefly discuss two learning tasks seen learning strongweak views, even though formalized such, views usedactive learning. additional application domain strong weak views, wrapperinduction, discussed length section 5.2.discotex (Nahm & Mooney, 2000) system designed extract job titles,salaries, locations, etc computer science job postings newsgroup austin.jobs.discotex proceeds four steps: first, uses rapier (Califf & Mooney, 1999) learnextraction rules item interest. Second, applies learned rules large,unlabeled corpus job postings creates database populated extracteddata. Third, text mining database, discotex learns predict value itembased values fields; e.g., may discover job requires c++corba development platforms include Windows. Finally, systemdeployed rapier rules fail extract item, mined rules used predictitems content.scenario, rapier rules represent strong view sufficientextracting data interest. contrast, mined rules represent weak viewcannot learned used themselves. Furthermore, discotex discardsaccurate mined rules, highly-specific, followsweak view used learn concepts specific target concept. NahmMooney (2000) show mined rules improve extraction accuracy capturinginformation complements rapier extraction rules.Another domain strong weak views presented Kushmerick et al. (2001).learning task classify lines text business card persons name,affiliation, address, phone number, etc. domain, strong view consistswords appear line, based Naive Bayes text classifier learned.weak view, one exploit relative order lines card learning215fiMuslea, Minton, & KnoblockHidden Markov Model predicts probability particular ordering linesbusiness card (e.g., name followed address, followed phone number).weak view defines class concepts general target concept:line orderings possible, even though equally probable. Even thoughorder text lines cannot used accurately classify lines,combined strong view, ordering information leads classifier clearlyoutperforms stand-alone strong view (Kushmerick et al., 2001).Note approaches use strong weak views passive, ratheractive learning. is, given fixed set labeled unlabeled examples,algorithms learn one weak one strong hypothesis used craft domainspecific predictor outperforms individual hypothesis. contrast, Co-Testingactive learner seamlessly integrates weak strong hypotheses without requiringadditional, domain-specific data engineering.5. Empirical Validationsection empirically compare Co-Testing state art learners.goal test following hypothesis: given multi-view learning problem, Co-Testingconverges faster single-view counterparts.begin presenting results three real-world classification domains: Webpage classification, discourse tree parsings, advertisement removal. focusimportant industrial application, wrapper induction (Muslea et al., 2001; Kushmerick,2000; Hsu & Dung, 1998), goal learn rules extract relevant datacollection documents (e.g., extract book titles prices Web site).results classification wrapper induction analyzed separately because:- three classification tasks, two strong views available;contrast, wrapper induction two strong one weak views,allows us explore wider range options.- classification domain, exactly one available dataset. contrast,wrapper induction use testbed 33 distinct tasks. imbalance numberavailable datasets requires different presentation styles results.- contrast typical classification, major requirement wrapper induction learn(close to) 100%-accurate extraction rules handful examples (Muslea,2002, pages 3-6). requirement leads significant differences experimental setup interpretation results (e.g., results excellentclassification tasks may unacceptable wrapper induction).5.1 Co-Testing Classificationbegin empirical study using three classification tasks compare Co-Testingexisting active learners. first introduce three domains respective views;discuss learners used evaluation analyze experimental results.216fiActive Learning Multiple ViewsDomainLadtfibmc4NaiveBayescoursesCo-TestingQueryOutputSelectionHypothesisnaivewinnernaivewinnernaiveweightedconservativevoteSingle-view AlgorithmsQBCqBagqBstUSRndTable 2: algorithms used classification. last five columns denote Query-byCommittee/-Bagging/-Boosting, Uncertainty Sampling Random Sampling.5.1.1 Views used Co-Testingapplied Co-Testing three real-world classification domains natural,intuitive way create two views:- ad (Kushmerick, 1999) classification problem two classes, 1500 attributes,3279 examples. ad, images appear Web pages classified adsnon-ads. view V1 consists textual features describe image; e.g.,1-grams 2-grams caption, url page containsimage, url page image points to, etc. turn, V2 describesproperties image itself: length, width, aspect ratio, origin (i.e.,image page contains coming Web server?).- courses (Blum & Mitchell, 1998) domain two classes, 2206 features, 1042examples. learning task consists classifying Web pages course homepagespages. courses two views consist words appear pagewords appear hyperlinks pointing them, respectively.- tf (Marcu, Carlson, & Watanabe, 2000) classification problem seven classes, 99features 11,193 examples. context machine translation system, usesshift-reduce parsing paradigm learn rewrite Japanese discourse treesEnglish-like discourse trees. case, V1 uses features specific shift-reduceparser: elements input list partial trees stack. V2 consistsfeatures specific Japanese tree given input.5.1.2 Algorithms used EvaluationTable 2 shows learners used empirical comparison. implementedactive learners extensions MLC++ library (Kohavi, Sommerfield, & Dougherty,1997). domain, choose base learner follows: applying primitivelearners MLC ++ dataset (10-fold cross-validation), select one obtainsbest performance. precisely, using following base learners: ib (Aha,1992) ad, Naive Bayes (Blum & Mitchell, 1998) courses, mc4,implementation c4.5, tf.217fiMuslea, Minton, & Knoblockfive single-view algorithms Table 2 use available features (i.e., V 1 V2 )learn target concept.1 three domains, Random Sampling (Rnd) usedstrawman; Query-by-Bagging -Boosting, denoted qBag qBst, also runthree domains. contrast, Uncertainty Sampling (US) applied adcourses mc4, base learner tf, provide estimateconfidence prediction.known method randomly sampling ib mc4 version spaces,Query-by-Committee (QBC) applied ad tf. However, apply QBCcourses borrowing idea McCallum Nigam (1998): create committee sampling hypotheses according (Gamma) distribution Naive Bayesparameters estimated training set L.Query-by-Committee use typical 2-hypothesis committee. Query-byBagging -Boosting, use relatively small 5-hypothesis committeescpu constraints: running time increases linearly number learned hypotheses,and, domains, takes 50 cpu hours complete experiments even5-hypothesis committees.limitations respective base learners (i.e., above-mentionedissue estimating confidence prediction), ad tf use Naive Co-Testingwinner-takes-all output hypothesis; is, query randomly selected amongcontention points, output hypothesis one learned view makesfewest mistakes queries. contrast, courses follow methodologyoriginal Co-Training paper (Blum & Mitchell, 1998), output hypothesisconsists weighted vote classifiers learned view.courses investigate two Co-Testing query selection strategies: naiveconservative. third, aggressive query selection strategy appropriate courseshyperlink view significantly less accurate one (after all, onerarely encounters handful words hyperlink). Consequently,high-confidence contention points unfixable mistakes hyperlink view,means even seeing correct label, cannot classified correctlyview.5.1.3 Experimental Resultslearners performance evaluated based 10-fold, stratified cross validation. ad,algorithm starts 150 randomly chosen examples makes 10 queries40 learning episodes, total 550 labeled examples. courses, algorithmsstart 6 randomly chosen examples make one query 175 learningepisodes. Finally, tf algorithms start 110 randomly chosen examples make20 queries 100 learning episodes.Figures 1 2 display learning curves various algorithms ad, tf,course. three domains, Co-Testing reaches highest accuracy (i.e., smallest errorrate). Table 3 summarizes statistical significance results (t-test confidence least1. preliminary experiment, also ran algorithms individual views. resultsV1 V2 either worse V1 V2 differences statistically insignificant.Consequently, sake simplicity, decided show single-view results V 1 V2 .218fiActive Learning Multiple Viewserror rate (%)AD9Naive Co-Testing8.5Uncertainty Sampling8Rnd7.576.565.554.543.5150 200 250 300 350 400 450 500labeled examplesAD10Naive Co-TestingqBagqBstRnderror rate (%)9876543150 200 250 300 350 400 450 500labeled examplesTF32Naive Co-TestingqBagqBstRnderror rate (%)30282624222018110510910131017102110labeled examplesFigure 1: Empirical results ad tf problems219fiMuslea, Minton, & Knoblockcourses12Conservative Co-TestingUncertainty SamplingQBCRnderror rate (%)1086422060100140180labeled examplescourses12Conservative Co-TestingqBagqBstRnderror rate (%)1086422060100140180labeled examplescourses12Conservative Co-TestingNaive Co-Testingerror rate (%)1086422060100140180labeled examplesFigure 2: Empirical results courses problem220fiActive Learning Multiple ViewsNaive Co-TestingAlgorithmRandom SamplingUncertainty SamplingQuery-by-CommitteeQuery-by-BaggingQuery-by-BoostingNaive Co-TestingadConservative Co-TestingtfcoursesLossTieWinLossTieWinLossTieWin0000-021815-191714-00000-2126060-7089318591-000002802149214928Table 3: Statistical significance results empirical (pair-wise) comparison variousalgorithms three domains.95%) obtained pair-wise comparison various algorithms. comparisonsperformed right-most half learning curve (i.e., towards convergence).best way explain results Table 3 via examples: results comparing NaiveCo-Testing Random Sampling ad appear first three columns firstrow. three numbers (i.e., 0, 0, 19) mean (all) 19 comparison points NaiveCo-Testing outperforms Random Sampling statistically significant manner. Similarly,comparing Naive Conservative Co-Testing courses (the last three columnslast row) leads following results: 28 comparison points Conservative CoTesting outperforms Naive Co-Testing statistically significant manner; 21points differences statistically insignificant; finally, comparison point NaiveCo-Testing outperforms Conservative counterpart.results Table 3 summarized follows. First all, single-view algorithmoutperforms Co-Testing statistically significant manner comparison points.Furthermore, except comparison Query-by-Bagging -Boosting ad,difference accuracy statistically insignificant almost comparison points, CoTesting clearly outperform algorithms domains.Finally, let us briefly comment applying multi-view, semi-supervised learnersthree tasks above. mentioned section 3.3, algorithms bootstrap viewstraining view examples labeled high-confidenceview. ad tf, could use multi-view, semi-supervised learningbase learners ib mc4 provide (reliable) estimate confidencepredictions. precisely, mc4 provides estimate all, ibs estimatesextremely poor training data scarce (e.g., see poor performanceUncertainty Sampling ad, barely outperforms Random Sampling).courses, applied Co-Training Co-EM conjunctionNaive Bayes base learner. multi-view learners reach maximum accuracy(close 95%) based solely 12 labeled 933 unlabeled examples,221fiMuslea, Minton, & KnoblockR2R1Name:<i>Ginos</i><p>Phone:<i> (800)111-1717 </i><p>Cuisine:Figure 3: forward backward rules detect beginning phone number.performance improve statistically significant manner.2 shown Figure 2,training data scarce (i.e., 40 labeled examples), Co-Testings accuracyless 95%; however, making additional queries, Co-Testing reaches 98% accuracy,Co-Training Co-EM remain 95% even trained 180 labeled 765unlabeled examples. results consistent different goals activesemi-supervised learning: former focuses learning perfect target conceptminimal amount labeled data, latter uses unlabeled examples boostaccuracy hypothesis learned handful labeled examples.5.2 Co-Testing Wrapper Inductionfocus different type learning application, wrapper induction (Muslea et al.,2001; Kushmerick, 2000), goal learn rules extract relevant sub-stringscollection documents. Wrapper induction key component commercialsystems integrate data variety Web-based information sources.5.2.1 Views used Co-TestingConsider illustrative task extracting phone numbers documents similarfragment Figure 3. find phone number begins,3 one use ruleR1 = SkipT o( Phone:<i> )rule applied forward, beginning page, ignores everythingfinds string Phone:<i>. Note forward-going rules representway detect phone number begins: alternative approach use ruleR2 = BackT o( Cuisine ) BackT o( ( Number ) )applied backward, end document. R2 ignores everythingfinds Cuisine then, again, skips first number parentheses.Forward backward rules R1 R2 learned user-providedexamples state art wrapper induction system stalker (Muslea et al., 2001),use base learner Co-Testing. Intuitively, stalker creates forward2. recent paper (Brefeld & Scheffer, 2004) shows - text classification - svm appropriateNaive Bayes base learner Co-EM, though necessarily Co-Training. MLC ++library provide svm base learner, could compare results BrefeldScheffer (2004), Co-EM + svm reaches 99% accuracy based 12 labeled 933 unlabeledexamples. However, fairness, unlikely Co-Testing could lead even faster convergence.3. shown Muslea et al. (2001), end phone number found similar manner.222fiActive Learning Multiple Viewsbackward rule consumes tokens precede follow extraction point,respectively. follows rules R1 R2 represent descriptionsconcept (i.e., beginning phone number) learned two different views:sequences tokens precede follow beginning item, respectively.views strong views sufficient accurately extract itemsinterest (Muslea et al., 2001, 2000).addition two views, rely mostly context itemextracted (i.e., text surrounding item), one use third view describescontent item extracted. example, phone numbers describedsimple grammar: ( Number ) Number - Number; similarly, urls starthttp://www., end .html, contain html tags.content-based view weak view often represents conceptgeneral target one. example, phone number grammar cannot discriminate home, office, cell, fax numbers appear within Webpage; similarly, url grammar cannot distinguish urls interest (e.g.,products review) ones (e.g., advertisements).weak view, use base learner version DataPro (Lerman, Minton, &Knoblock, 2003) described elsewhere (Muslea et al., 2003). DataPro learns -positives examples - prototypes items extracted; i.e., finds statistically significant sequences tokens (1) highly unlikely generatedchance (2) describe content many positive examples. features usedbase learner consist length range (in tokens) seen examples, tokentypes appear training set (e.g., Number, AllCaps, etc), start- endpattern (e.g., http://www. AlphaNum .html, respectively).5.2.2 Algorithms used Evaluationextraction rules learned two strong views provide estimateconfidence extractions, Co-Testing algorithm implementedbased solely forward backward views Naive Co-Testing winner-takes-alloutput hypothesis:- query randomly chosen (Naive Co-Testing) among contention points,documents learned rules extract different strings.- output hypothesis rule learned view makes fewest mistakesallowed number queries (i.e., winner-takes-all).Given additional, content-based view, also implement aggressive versionCo-Testing wrapper induction:- contention points are, again, unlabeled examples rules learnedstrong views extract string.- aggressive query selection strategy works selecting contention pointhypothesis learned weak view maximally confident stalkerrules extracting incorrect strings. formally, contention point, let 1s2 strings extracted strong views; let us also denote n1 n2223fiMuslea, Minton, & Knoblocknumber constraints learned weak views violated s1 s2 .Using notation, next query contention point min(n1 , n2 )largest value.- output hypothesis obtained following majority voting scheme: stringsextracted strong views identical, represent extracted item;otherwise result one two strings violates fewer constraintslearned weak view.empirical evaluation below, compare two Co-Testing algorithmsRandom Sampling Query-by-Bagging. former used strawman,latter general-purpose active learner applied straightforwardmanner wrapper induction (for details, see discussion section 4.3.1). Finally,existing multi-view, semi-supervised learners cannot used wrapper inductionbase learners provide estimate confidence extraction; evenestimate could obtained, wrapper induction algorithms extremely sensitivemislabeled examples, would make bootstrapping process unacceptably brittle.paper, implementation Random Sampling identical NaiveCo-Testing winner takes all, except randomly queries one unlabeledexamples working set. Query-by-Bagging, committee hypothesescreated repeatedly re-sampling (with substitution) examples original trainingset L. use relatively small committee (i.e., 10 extraction rules) learninghandful examples, re-sampling replacement leads distincttraining sets. order make fair comparison Co-Testing, run Query-by-Baggingstrong view report best obtained results.5.2.3 Experimental Resultsempirical comparison, use 33 difficult wrapper induction taskstestbed introduced Kushmerick (1998, 2000). tasks, previously usedliterature (Muslea et al., 2003; Muslea, 2002), briefly described Table 4. use20-fold cross-validation compare performance Naive Aggressive Co-Testing,Random Sampling, Query-by-Bagging 33 tasks. algorithm starts tworandomly chosen examples makes 18 successive queries.results summarized follows: 12 tasks, two Co-Testingalgorithms learn 100% accurate rules; another 18 tasks, Co-Testing least anotheralgorithm reach 100% accuracy, Co-Testing requires smallest number queries.Finally, remaining three tasks, algorithm learns 100% accurate rule.Figure 4 shows aggregate performance four algorithms 33 tasks.six graphs, X axis shows number queries made algorithm,axis shows number tasks 100% accurate rule learned basedexactly X queries. mentioned earlier, algorithms start 2 random examplesmake 18 additional queries, total 20 labeled examples. convention, rightmost point X axis, labeled 19 queries, represents number tasksrequire allowed 18 queries learn 100% accurate rule. additional19 queries data-point allows us summarize results without dramatically extendingX axis beyond 18 queries: extraction tasks Random Sampling224fiActive Learning Multiple ViewsTaskIDS1-0S1-1S1-2S2-0S2-1S2-2S2-3S3-0S3-1S3-3S3-4S3-5S6-1S9-10S9-11S11-1S11-2SourcenameComputerESPCNN/TimeAllPoliticsFilm.comSearchPharmaWebInternetTravel Net.InternetAddressItemnamePriceURLItemURLSourceTitleDateURLNameSizeDateTimeUniversityArrival TimeAvailabilityEmailUpdateTaskIDS11-3S15-1S19-1S19-3S20-3S20-5S24-0S24-1S24-3S25-0S26-3S26-4S26-5S28-0S28-1S30-1Nmbexs4044044045015014994921751751751751752744399191SourcenameFinderNewJourShops.NetDemocraticParty OnlineForeignLanguagesTravelersus Tax CodeCD ClubWeb ServerCyberiderCycling wwwCongressQuarterlyItemnameOrganizationNameScoreItem NameScoreFile TypeLanguageURLTranslationURLPriceArtistAlbumURLRelevancePerson NameNmbexs723552012019132869042469032837737737775175130Table 4: 33 wrapper induction tasks used empirical evaluation.Query-by-Bagging need hundreds queries learn correct rules, histograms wouldbecome difficult read entire X axis shown.shown Figure 4, two Co-Testing algorithms clearly outperform single-viewcounterparts, Aggressive Co-Testing significantly better Naive Co-Testing(the results statistically significant confidence least 99%). Aggressive CoTesting learns 100%-accurate rules 30 33 tasks; tasks, extractionrules learned seven queries. Naive Co-Testing learns 100% accurate rules28 33 tasks. 26 28 tasks, extraction rules learned basedsix queries. contrast, Random Sampling Query-by-Bagging learn 100%accurate rules seven twelve tasks, respectively. words,Co-Testing algorithms learn correct target concept twice many tasksQuery-by-Bagging Random Sampling.must emphasize power Aggressive Co-Testing high-accuracy taskswrapper induction: 11 33 tasks, single, aggressively-chosen query sufficientlearn correct extraction rule. contrast, Naive Co-Testing converges singlequery four 33 tasks, two learners never converge singlequery.three tasks Aggressive Co-Testing learn 100% accurate rules,failure due fact one views significantly less accurateone. leads majority contention points mislabeled bad view,- turn - skews distribution queries towards mistakes bad view.Consequently, Co-Testings performance suffers queries uninformative225fi201510501extraction task convergedextraction task convergedAggressive Co-Testing25471013queries16201510501471013queries16201510501Query-by-Bagging (FB)25Naive Co-Testing2519extraction task convergedextraction task convergedMuslea, Minton, & Knoblock19471013queries16191619Random Sampling25201510501471013queriesFigure 4: Convergence results 33 wrapper induction tasks.views: good view makes correct prediction them, bad viewinadequate learn target concept. order cope problem, introducedview validation algorithm (Muslea et al., 2002b) predicts whether viewsappropriate particular task.Finally, let us briefly compare results ones obtained wien (Kushmerick, 2000), wrapper induction system evaluatedextraction tasks used here. two experimental setups identical (i.e., crossvalidation vs. random splits) informal comparison; however, putsresults perspective contrasting Co-Testing another state art approachwrapper induction.results summarized follows: wien fails 18 33 task; 18 tasksinclude three Aggressive Naive Co-Testing failed learn perfect rules.remaining 15 tasks, wien requires 25 90 examples 4 learn correctrule. 15 tasks, Aggressive Naive Co-Testing learn 100% accuraterules based eight examples (two random plus six queries).4. wien framework, example consists document items interest labeled.example, page contains list 100 names, labeled, represents single labeled example.contrast, stalker labeled document represents 100 distinct labeled examples. ordercompare wien stalker results, convert wien data stalker-like data multiplyingnumber labeled wien pages average number item occurrences page.226fiActive Learning Multiple Views6. Conclusionpaper introduce Co-Testing, active learning technique multi-viewlearning tasks. novel approach active learning based idea learningmistakes; i.e., Co-Testing queries unlabeled examples views predict differentlabel (such contention points guaranteed represent mistakes made one views).analyzed several members Co-Testing family (e.g., Naive, ConservativeAggressive Co-Testing). also introduced evaluated Co-Testing algorithmsimultaneously exploits strong weak views.empirical results show Co-Testing powerful approach active learning. experiments use four extremely different base learners (i.e., stalker, ib, NaiveBayes, mc4) four different types domains: wrapper induction, text classification (courses), ad removal (ad), discourse tree parsing (tf). scenarios,Co-Testing clearly outperforms single-view, state art active learning algorithms.Furthermore, except Query-by-Bagging, Co-Testing algorithmapplied problems considered empirical evaluation. contrast Queryby-Bagging, poor performance courses wrapper induction, Co-Testingobtains highest accuracy among considered algorithms.Co-Testings success due ability discover mistakes made view.contention point represents mistake (i.e., erroneous prediction) least oneviews, follows query extremely informative view misclassifiedexample; is, mistakes informative correctly labeled examples.particularly true base learners stalker, improve currenthypothesis unless provided examples misclassified instances.limitation, Co-Testing applied multi-view tasks; is, unlessuser provide two views, Co-Testing cannot used all. However, researchersshown besides four problems above, multiple views exist variety real worldproblems, named entity classification (Collins & Singer, 1999), statistical parsing(Sarkar, 2001), speech recognition (de Sa & Ballard, 1998), word sense disambiguation(Yarowsky, 1995), base noun phrase bracketing (Pierce & Cardie, 2001).concern Co-Testing related potential violations twomulti-view assumptions, require views uncorrelated compatible.example, case correlated views, hypotheses learned view maysimilar contention points among select next query. termsview incompatibility, remember that, three 33 wrapper induction tasks, oneviews inaccurate Co-Testing could outperform Random Sampling.two companion papers (Muslea et al., 2002a, 2002b) proposed practical solutionsproblems.Acknowledgmentsresearch based upon work supported part National Science FoundationAward No. IIS-0324955 grant number 0090978, part Defense AdvancedResearch Projects Agency (DARPA), Department Interior, NBC, Acquisition Services Division, Contract No. NBCHD030010, part Air Force227fiMuslea, Minton, & KnoblockOffice Scientific Research grant number FA9550-04-1-0105. U.S.Governmentauthorized reproduce distribute reports Governmental purposes notwithstandingcopy right annotation thereon. views conclusions contained hereinauthors interpreted necessarily representing official policiesendorsements, either expressed implied, organizations personconnected them.ReferencesAbe, N., & Mamitsuka, H. (1998). Query learning using boosting bagging. Proceedings 15th International Conference Machine Learning (ICML-98), pp.110.Abney, S. (2002). Bootstrapping. Proceedings 40th Annual Meeting Association Computational Linguistics, pp. 360367.Aha, D. (1992). Tolerating noisy, irrelevant novel attributes instance-based learningalgorithms. International Journal Man-Machine Studies, 36 (1), 267287.Amoth, T., Cull, P., & Tadepalli, P. (1998). Exact learning tree patterns queriescounterexamples. Proceedings Conference Computational LearingTheory, pp. 175186.Amoth, T., Cull, P., & Tadepalli, P. (1999). Exact learning unordered tree patternsqueries. Proceedings Conference Computational Learing Theory, pp.323332.Angluin, D. (1982). note number queries needed identify regular languages.Information Control, 51, 7687.Angluin, D. (1988). Queries concept learning. Machine Learning, 2, 319342.Angluin, D. (1994). Exact learning DNF formulas malicious membership queries.Tech. rep. YALEU/DCS/TR-1020, Yale University.Angluin, D., & Krikis, M. (1994). Malicious membership queries exceptions. Tech. rep.YALEU/DCS/TR-1019, Yale University.Angluin, D., Krikis, M., Sloan, R., & Turan, G. (1997). Malicious omissions errorsanswers membership queries. Machine Learning, 28, 211255.Angluin, D., & Slonim, D. (1991). Randomly fallible teachers: learning monotone DNFincomplete membership oracle. Machine Learning, 14 (1), 726.Argamon-Engelson, S., & Dagan, I. (1999). Committee-based sample selection probabilistic classifiers. Journal Artificial Intelligence Research, 11, 335360.Baum, E. (1991). Neural net algorithms learn polynomial time examplesqueries. IEEE Transactions Neural Networks, 2, 519.Blum, A., Chalasani, P., Goldman, S., & Slonim, D. (1998). Learning unreliableboundary queries. Journal Computer System Sciences, 56 (2), 209222.228fiActive Learning Multiple ViewsBlum, A., Furst, M., Jackson, J., Kearns, M., Mansour, Y., & Rudich, S. (1994). Weaklylearning DNF characterizing statistical query learning using Fourier analysis.Proceedings 26th ACM Symposium Theory Computing, pp. 253262.Blum, A., & Mitchell, T. (1998). Combining labeled unlabeled data co-training.Proceedings 1988 Conference Computational Learning Theory, pp. 92100.Brefeld, U., & Scheffer, T. (2004). Co-EM support vector learning. Proceedings21st International Conference Machine Learning (ICML-2004), pp. 121128.Breiman, L. (1996). Bagging predictors. Machine Learning, 24(2), 123140.Califf, M. E., & Mooney, R. (1999). Relational learning pattern-match rules information extraction. Proceedings Sixteenth National Conference ArtificialIntelligence (AAAI-99), pp. 328334.Campbell, C., Cristianini, N., & Smola, A. (2000). Query learning large margin classifiers. Proceedings 17th International Conference Machine Learning(ICML-2000), pp. 111118.Cohn, D., Atlas, L., & Ladner, R. (1994). Improving generalization active learning.Machine Learning, 15, 201221.Cohn, D., Ghahramani, Z., & Jordan, M. (1996). Active learning statistical models.Advances Neural Information Processing Systems, Vol. 9, pp. 705712.Collins, M., & Singer, Y. (1999). Unsupervised models named entity classification.Proceedings Empirical NLP Large Corpora Conference, pp. 100110.Dagan, I., & Engelson, S. (1995). Committee-based sampling training probabilisticclassifiers. Proceedings 12th International Conference Machine Learning,pp. 150157.Dasgupta, S., Littman, M., & McAllester, D. (2001). PAC generalization bounds cotraining. Neural Information Processing Systems, pp. 375382.de Sa, V., & Ballard, D. (1998). Category learning multi-modality. Neural Computation, 10 (5), 10971117.Dempster, A., Laird, N., & Rubin, D. (1977). Maximum likelihood incomplete datavie em algorithm. Journal Royal Statistical Society, 39, 138.Fedorov, V. V. (1972). Theory optimal experiment. Academic Press.Finn, A., & Kushmerick, N. (2003). Active learning selection strategies informationextraction. Proceedings ECML-2004 Workshop Adaptive Text ExtractionMining (ATEM-2003).Freund, Y., Seung, H. S., Shamir, E., & Tishby, N. (1997). Selective sampling usingquery committee algorithm. Machine Learning, 28, 133168.Ghani, R. (2002). Combining labeled unlabeled data multiclass text classification.Proceedings 19th International Conference Machine Learning (ICML-2002),pp. 187194.229fiMuslea, Minton, & KnoblockGoldberg, P., Goldman, S., & Mathias, D. (1994). Learning unions boxes membership equivalence queries. Proceedings Conference ComputationalLearing Theory, pp. 198207.Goldman, S., & Mathias, D. (1992). Learning k -term DNF formulas incompletemembership oracle. Proceedings Conference Computational Learing Theory, pp. 7784.Goldman, S., & Zhou, Y. (2000). Enhancing supervised learning unlabeled data.Proceedings 17th International Conference Machine Learning (ICML-2000),pp. 327334.Gross, K. (1991). Concept acquisition attribute evolution experiment selection.Ph.D. thesis, School Computer Science, Carnegie Mellon University.Hasenjager, M., & Ritter, H. (1998). Active learning local models. Neural ProcessingLetters, 7, 107117.Hsu, C.-N., & Dung, M.-T. (1998). Generating finite-state transducers semi-structureddata extraction web. Journal Information Systems, 23(8), 521538.Hwang, J.-N., Choi, J., Oh, S., & Marks, R. (1991). Query-based learning appliedpartially trained multilayer perceptrons. IEEE Transactions Neural Networks, 2,131 136.Jackson, J. (1994). efficient membership-query algorithm learning DNF respectuniform distribution. Proceedings IEEE Symposium FoundationsComputer Science, pp. 4253.Jones, R., Ghani, R., Mitchell, T., & Riloff, E. (2003). Active learning information extraction multiple view feature sets. Proceedings ECML-2004 WorkshopAdaptive Text Extraction Mining (ATEM-2003).Kohavi, R., Sommerfield, D., & Dougherty, J. (1997). Data mining using MLC++, machine learning library C++. International Journal AI Tools, 6(4), 537566.Kushmerick, N. (1999). Learning remove internet advertisements. ProceedingsThird International Conference Autonomous Agents (Agents-99), pp. 175181.Kushmerick, N. (2000). Wrapper induction: efficiency expressiveness. Artificial Intelligence Journal, 118 (1-2), 1568.Kushmerick, N., Johnston, E., & McGuinness, S. (2001). Information extraction textclassification. IJCAI-2001 Workshop Adaptive Text Extraction Mining.Lang, K., & Baum, E. (1992). Query learning work poorly human oracleused. Proceedings IEEE International Joint Conference Neural Networks.Lerman, K., Minton, S., & Knoblock, C. (2003). Wrapper maintenance: machine learningapproach. Journal Artificial Intelligence Research, 18, 149181.Lewis, D., & Catlett, J. (1994). Heterogeneous uncertainty sampling supervised learning.Proceedings 11th International Conference Machine Learning (ICML-94),pp. 148156.230fiActive Learning Multiple ViewsLewis, D., & Gale, W. (1994). sequential algorithm training text classifiers.Proceedings Research Development Information Retrieval, pp. 312.Liere, R., & Tadepalli, P. (1997). Active learning committees text categorization.14th National Conference Artificial Intelligence (AAAI-97), pp. 591596.Lindenbaum, M., Markovitch, S., & Rusakov, D. (2004). Selective sampling nearestneighbor classifiers. Machine Learning, 54 (2), 125152.Marcu, D., Carlson, L., & Watanabe, M. (2000). automatic translation discoursestructures. Proceedings 1st Annual Meeting North American ChapterAssociation Computational Linguistics (NAACL-2000), pp. 917.McCallum, A., & Nigam, K. (1998). Employing EM pool-based active learningtext classification. Proceedings 15th International Conference MachineLearning, pp. 359367.Melville, P., & Mooney, R. J. (2004). Diverse ensembles active learning. ProceedingsInternational Conference Machine Learning, pp. 584591.Muslea, I. (2002). Active Learning Multiple Views. Ph.D. thesis, Department Computer Science, University Southern California.Muslea, I., Minton, S., & Knoblock, C. (2000). Selective sampling redundant views.Proceedings National Conference Artificial Intelligence (AAAI-2000), pp.621626.Muslea, I., Minton, S., & Knoblock, C. (2001). Hierarchical wrapper induction semistructured sources. Journal Autonomous Agents Multi-Agent Systems, 4, 93114.Muslea, I., Minton, S., & Knoblock, C. (2002a). Active + Semi-supervised Learning = Robust Multi-view Learning. 19th International Conference Machine Learning(ICML-2002), pp. 435442.Muslea, I., Minton, S., & Knoblock, C. (2002b). Adaptive view validation: first steptowards automatic view detection. 19th International Conference MachineLearning (ICML-2002), pp. 443450.Muslea, I., Minton, S., & Knoblock, C. (2003). Active learning strong weak views:case study wrapper induction. Proceedings International Joint ConferenceAtificial Intelligence (IJCAI-2003), pp. 415420.Nahm, U.-Y., & Mooney, R. (2000). mutually beneficial integration data mininginformation extraction. 17th National Conference Artificial Intelligence(AAAI-2000), pp. 627632.Nigam, K., & Ghani, R. (2000). Analyzing effectiveness applicability co-training.Proceedings Information Knowledge Management, pp. 8693.Pierce, D., & Cardie, C. (2001). Limitations co-training natural language learninglarge datasets. Proceedings Empirical Methods Natural Language Processing(EMNLP-2001), pp. 110.Raskutti, B., Ferra, H., & Kowalczyk, A. (2002). Combining clustering co-trainingenhance text classification using unlabeled data. Proceedings SIGKDDInternational Conference Knowledge Discovery Data Mining, pp. 620625.231fiMuslea, Minton, & KnoblockReddy, C., & Tadepalli, P. (1997). Learning horn definitions equivalence membership queries. Proceedings 7th International Workshop Inductive LogicProgramming, pp. 243255.Roy, N., & McCallum, A. (2001). Toward optimal active learning sampling estimation error reduction. Proceedings 18th International ConferenceMachine Learning (ICML-2001), pp. 441448.Sammut, C., & Banerji, R. B. (1986). Learning concepts asking questions. Carbonell,R. S. M., Carbonell, J., & 2), T. M. M. V. (Eds.), Machine Learning: ArtificialIntelligence Approach, pp. 167192. Morgan Kaufmann.Sarkar, A. (2001). Applying co-training methods statistical parsing. Proceedings2nd Annual Meeting North American Chapter AssociationComputational Linguistics (NAACL-2001), pp. 175182.Schapire, R. (1990). strength weak learnability. Machine Learning, 5(2), 197227.Scheffer, T., & Wrobel, S. (2001). Active learning partially hidden Markov models.Proceedings ECML/PKDD-2001 Workshop Active Learning, DatabaseSampling, Experimental Design: Views Instance Selection.Schohn, G., & Cohn, D. (2000). Less more: Active learning support vector machines.Proceedings 17th International Conference Machine Learning (ICML2000), pp. 839846.Seung, H. S., Opper, M., & Sompolinski, H. (1992). Query committee. Proceedings1988 Conference Computational Learning Theory (COLT-72), pp. 287294.Shapiro, E. (1981). general incremental algorithm infers theories facts.Proceedings 7th International Joint Conference Artificial Intelligence, pp.446451.Shapiro, E. (1982). Algorithmic program diagnosis. Proceedings 9th ACM Symposium Principles Programming Languages, pp. 299308.Sloan, R., & Turan, G. (1994). Learning queries incomplete information (extendedabstract). Proceedings Conference Computational Learing Theory, pp.237245.Soderland, S. (1999). Learning extraction rules semi-structured free text. MachineLearning, 34, 233272.Tadepalli, P. (1993). Learning queries examples tree-structured bias.Proceedings 10th International Conference Machine Learning (ICML-93),pp. 322329.Tadepalli, P., & Russell, S. (1998). Learning queries examples structureddeterminations. Machine Learning, 245295.Thompson, C., Califf, M. E., & Mooney, R. (1999). Active learning natural languageparsing information extraction. Proceedings 16th International Conference Machine Learning (ICML-99), pp. 406414.Tong, S., & Koller, D. (2000). Active learning parameter estimation Bayesian networks. Advances Neural Information Processing Systems, Vol. 13, pp. 647653.232fiActive Learning Multiple ViewsTong, S., & Koller, D. (2001). Support vector machine active learning applicationstext classification. Journal Machine Learning Research, 2, 4566.Valiant, L. (1984). theory learnable. Communications ACM, 27 (11), 11341142.Watkin, T., & Rau, A. (1992). Selecting examples perceptrons. Journal Physics A:Mathematical General, 25 (1), 113121.Yarowsky, D. (1995). Unsupervised word sense disambiguation rivaling supervised methods. Proceedings 33rd annual meeting Association ComputationalLinguistics, pp. 189196.Zhou, Y., & Goldman, S. (2004). Democratic co-learning. Proceedings InternationalConference Tools Artificial Intelligence, pp. 594602.233fiJournal Artificial Intelligence Research 27 (2006) 441-464Submitted 03/06; published 12/06Set Intersection Consistency Constraint NetworksYuanlin Zhangyzhang@cs.ttu.eduDepartment Computer Science, Texas Tech UniversityLubbock, TX 79414 USARoland H. C. Yapryap@comp.nus.edu.sgDepartment Computer Science, National University Singapore3 Science Drive 2, Singapore 117543Abstractpaper, show close relation consistency constraintnetwork set intersection. proof schema provided generic way obtain consistency properties properties set intersection. approach simplifiesunderstanding unifies many existing consistency results, also directs studyconsistency set intersection properties many situations, demonstratedresults convexity tightness constraints paper. Specifically,identify new class tree convex constraints local consistency ensures globalconsistency. generalizes row convex constraints. Various consistency results alsoobtained constraint networks some, contrast existing work,constraints tight.1. Introductionconstraint network consists set variables finite domains systemconstraints variables. important task find assignmentvariables constraints network satisfied. assignmentexists, network satisfiable globally consistent, assignment called solution.problem determining global consistency general constraint network NPcomplete. Usually search procedure employed find solution. practice, dueefficiency considerations, search usually equipped filtering algorithmprunes values variable combinations values certain number variablescannot part solution. filtering algorithm make constraint networklocally consistent sense consistent assignment variables alwaysextensible new variable. important interesting question local consistency is:local consistency obtained sufficient determine global consistencynetwork without search? filtering algorithm polynomialcomplexity, positive answer would mean network solvedpolynomial time.Much work done explore relationship local global consistency particular properties local consistency general. One directionmake use topological structure constraint network. classical resultgraph constraint network tree, arc consistency network sufficientensure global consistency (Freuder, 1982).c2006AI Access Foundation. rights reserved.fiZhang & Yapsecond direction1 makes use semantic properties constraints. monotoneconstraints, path consistency implies global consistency (Montanari, 1974). Van BeekDechter (1995) generalize monotone constraints larger class row convex constraints.Dechter (1992) shows certain level consistency constraint network whosedomains limited size ensures global consistency. Later, Van Beek Dechter (1997)study consistency constraint networks tight loose constraints.existing work along two approaches used specific different techniquesstudy local global consistency. particular, little commonality detailsexisting work. much existing work, techniques consequentlyproofs given developed specifically results concerned.paper, show much work connected togethernew approach studying consistency constraint network. unite two seeminglydisparate areas: study set intersection special sets study k-consistencyconstraint networks. fact, k-consistency expressed terms set intersection,allows one obtain relationships local global consistency constraintnetwork properties set intersection special sets. main resultapproach proof schema used lift results set intersection,rather general, particular consistency results constraint networks. One benefitproof schema lies provides modular way greatly simplify understandingproofs consistency results. benefit considerable often proofs manyexisting results complex hard-wired. Using new approach, showprecisely various properties set intersection key results.Furthermore, proofs become mechanical.following sketch illustrates briefly use approach. One property setintersection intersection every pair (2) tree convex sets (see Section 3)empty, intersection whole collection sets empty too.property, see local information intersection every pair sets givesrise global information intersection sets. Intuitively, relationshiplocal global information corresponds obtaining global consistencylocal consistency. proof schema used lift result tree convex setsfollowing consistency result. binary constraint network tree convex constraints,(2+1)-consistency (path consistency) implies global consistency network.usefulness new set-based approach twofold. Firstly, gives clear picturemany existing results. example, many well known results second directionbased semantic properties constraints (including van Beek & Dechter, 1995, 1997),well results first direction, shown easy proofs make useset intersection properties. Secondly, directing study consistency setintersection properties, helps improve existing results derive new resultsdemonstrated sections 57.paper organized follows. Section 2, present necessary notationsconcepts. Section 3, focus properties intersection tree convex sets sets1. difference work concerned studying tractability constraintlanguages (e.g., Schaefer, 1978; Jeavons, Cohen, & Gyssens, 1997). latter considers problemswhose constraints fixed set relations former studies constraint networksspecial properties.442fiSet Intersection Consistency Constraint Networkscardinality restrictions. Section 4, develop characterization k-consistencyutilizing set intersection proof schema offers generic way obtain consistencyresults set intersection properties. power new approach demonstratednew consistency results convexity tightness constraints. Tree convexconstraints studied Section 5. constraint network tree convex constraints,local consistency ensures global consistency, result intersection property treeconvex sets. tightness constraints studied Section 6. Thanks intersectionproperties sets cardinality restriction, relation local global consistencyidentified weakly tight constraint networks Section 6.1. networks requiresome, rather all, constraints m-tight, improving tightness result van BeekDechter (1997). help relational consistency, show global consistencyachieved local consistency weakly tight constraint networks Section 6.2.type result tightness known before. Section 6.3, exploreconstraint network weakly m-tight present several results numbertight constraints sufficient necessary network weakly tight. make full usetightness constraints network, propose dually adaptive consistencySection 6.4. Dually adaptive consistency constraint network determinedtopology tightest relevant constraint variable. completeness, includeSection 7 results tightness tree convexity based relational consistency.conclude Section 8.2. Preliminariesconstraint network R defined set variables N = {x1 , x2 , . . . , xn }; set finitedomains = {D1 , D2 , . . . , Dn } domain Di , 1..n, set valuesvariable xi take; set constraints C = {cS1 , cS2 , . . . , cSe } Si , 1..e,subset {x1 , x2 , . . . , xn } constraint cSi relation defined domainsvariables Si . Without loss generality, assume that, two constraintscSi , cSj C (i 6= j), Si 6= Sj . arity constraint cSi number variables Si .variable x, Dx denotes domain. rest paper, often use networkmean constraint network.instantiation variables = {x1 , . . . , xj } denoted = (a1 , . . . , aj )ai Di 1..j. extension variable x(/ ) denoted (a, u)u Dx . instantiation set variables consistent satisfies constraintsR involve variables outside .constraint network R k-consistent consistent instantiationdistinct k 1 variables, new variable x, exists u Dx(a, u) consistent instantiation k variables. R strongly k-consistentj-consistent j k. strongly n-consistent network called globally consistent.information constraint networks consistency, reader referredwork Mackworth (1977), Freuder (1978) Dechter (2003).443fiZhang & Yap3. Properties Set Intersectionsection, develop number set intersection results used laterderive results consistency. set intersection property concerned is:Given collection l finite sets, conditions intersectionl sets empty?Here, particularly interested intersection property sets two interesting useful restrictions: convexity cardinality.3.1 Tree Convex SetsGiven collection sets, structures associated elements setsobtain interesting useful set intersection results. studysets whose elements form tree. first introduce concept tree convex set.Definition 1 Given discrete set U tree vertices U , set U treeconvex exists subtree whose vertices A.subtree tree subgraph tree. Next define saycollection sets tree convex.Definition 2 Given collection discrete sets S, let union sets U .sets tree convex tree U every set tree convex .collection sets said tree convex exists tree setscollection tree convex tree.b........ ............. ... .................................................................................................... ..................................................................................................bc...................................c............................................ ............................................... ....... ........ ...... ...............ee(a)f(b)Figure 1: (a) tree nodes {a, b, c, d, e} (b) partial order nodes {a, b, c, d, e, f }Example 1 Consider set U = {a, b, c, d, e} tree given Figure 1. subset{a, b, c, d} tree convex given tree. set {b, a, c, e} since elementsset subtree. However, {b, c, e} tree convex elements formsubtree given tree.Example 2 Consider = {{1, 9}, {3, 9}, {5, 9}}. construct tree {1, 3, 5, 9}9 root 1, 3, 5 children, set covers nodes exactly onebranch tree. Hence, sets tree convex.444fiSet Intersection Consistency Constraint NetworksTree convex sets following intersection property.Lemma 1 (Tree Convex Sets Intersection)Given finite collectionfinite sets S,assume sets tree convex.E 6= iff E1 , E2 S, E1 E2 6= .ESProof. Let l number sets S, tree that, Ei S, Eivertices subtree Ti . Assuming rooted tree, every Ti (i 1..l) rootedtree whose root exactly node nearest root . Let ri denote root Ti1..l.proveEi 6= , want show intersection trees {Ti | 1..l}i1..lempty. following propositions subtrees necessary main proof.Proposition 1 Let T1 , T2 two subtrees tree , = T1 T2 . tree.= , trivial tree. let 6= . Since portion T1 , circuitit. necessary prove connected. show, two nodes u, v ,path them. u, v T1 u, v T2 respectively imply existpaths P1 : u, . . . , v T1 P2 : u, . . . , v T2 respectively. Recall uniquepath u v T1 T2 subtrees . Therefore, P1 P2 covernodes edges, thus , intersection T1 T2 . P1path want.Proposition 2 Let T1 , T2 two subtrees tree , = T1 T2 . emptyleast one roots T1 T2 .Let r1 r2 roots T1 T2 respectively. r1 , proposition correct.Otherwise, show r2 . Assume contrary r2/ . Clearly, r1 6= r2 . Let rfirst common ancestor r1 r2 v root (T tree Proposition 1).paths P1 : r1 , . . . , v T1 ; P2 : r2 , . . . , v T2 ; P3 : r, . . . , r1 , P4 : r, . . . , r2. Since v descendant r1 r2 , P1 P2 share vertex v. Since rfirst common ancestor r1 r2 , P3 P4 share vertex r. alsoverified P3 P1 share r1 , P2 P4 share r2 , vertex sharedeither P1 P4 P2 P3 . Hence, closed walk P3 P1 P20 P40 , P20 P40reverse P2 P4 respectively, simple circuit. contradicts circuit.Further, following observation.Proposition 3 Let tree root r, T1 T2 two subtrees roots r1r2 respectively. Let r1 closer r r2 , intersection T1 T2 .r1 root empty.proposition true r1 = r2 . let r1 farther r r2 . Clearly r2/ T1thus r2/T.Proposition2,rroot.1Let =Ti . ready prove main result 6= . Select tree Tmaxi1..lT1 , T2 , . . . , Tl root rmax farthest away r among roots445fiZhang & Yapconcerned trees. accordance Proposition 3, Tmax intersect everytree implies rmax node every Ti (i 1..l). Therefore, rmax . 2Remark. partial order represented acyclic directed graph. tempting generalize tree convexity partial convexity following way.Given set U partial order it, set U partially convexset nodes connected subgraph partial order. Given collection sets S,let union sets U . sets partially convex partialorder U every set partially convex partial order.However, generalization, get result similar Lemma 1,illustrated following example. Consider three sets {c, b, d}, {d, f, a} {a, e, c}nodes diagram given Figure 1(b). sets partially convexintersect pairwise. However, intersection three sets empty.3.2 Sets Cardinality RestrictionsAnother useful restriction place sets restrict cardinalities.special case, consider set one element a. intersection every setempty, able conclude every set contains a, thus intersectionsets empty. Generally, set elements, followingresult.Lemma 2 Consider finite collection l sets S={E1 , E2 , . . . , El } number < l.Assume one set E1 elements.\E 6=ESiff intersection E1 sets empty.Proof. necessary condition immediate.prove sufficient condition, show intersection E1k (m k l 1) sets empty induction k. k = m, lemmatrue according assumption. Assuming intersection E1k 1 ( m) sets empty, show intersection E1 ksets empty. Without loss generality, subscripts k sets numbered2 k + 1. 2 k + 1, let Ai intersection E1 k sets except Ei :Ai = E1 . . . Ei1 Ei+1 . . . Ek+1 .First, show contradiction exist i, j 2..k + 1, 6= jAi Aj 6= . Assume Ai Aj = distinct j. According constructionAi s,[E1Ai ,i2..k+1446fiSet Intersection Consistency Constraint Networks|Ai | 1 induction assumption. Hence,X|E1 ||Ai | k > m,i2..k+1contradicts |E1 | m.Since Ai Aj 6= i, j 2..k + 1, 6= j,\Ei 6= .Ai Aj =i1..k+12lemma leads following corollary intersection every + 1 setsempty.Corollary 1 (Small Set Intersection) Consider finite collection l setsnumber < l. Assume one set elements.\E 6=ESiff intersection + 1 sets empty.specialized versions (Zhang & Yap, 2003) Lemma 2existing works van Beek Dechter (1997) David (1993) based.sets concern cardinality larger certain number, intersectionsets empty conditions. reader may refer Large SetsIntersection lemma (Zhang & Yap, 2003) details.4. Set Intersection Consistencysection, first relate consistency constraint networks set intersection. Usingresult, present proof schema allows us study relationship localglobal consistency properties set intersection.Underlying concept k-consistency whether instantiation variablesextended new variable relevant constraints new variablesatisfied. relevant constraint variable xi respect constraint containsxi variables . Given instantiation , relevant constraint allowsset (possibly empty) values new variable. call set extension set.satisfiability relevant constraints depends whether intersection extensionsets non-empty (see Lemma 3).Definition 3 Given constraint cSi , variable x Si , instantiation Si {x},extension set x respect cSi definedEi,x (a) = {b Dx | (a, b) satisf ies cSi }.extension set trivial empty; otherwise non-trivial.447fiZhang & YapRecall Dx refers domain variable x. Throughout paper, oftencase instantiation {x} already given, {x} supersetSi {x}. Let b instantiation obtained restricting variablesSi {x}. ease presentation, continue use Ei,x (a), rather Ei,x (b), denoteextension b x constraint cSi . make presentation easy follow,three parameters i, a, x may omitted expression hereafter wheneverclear context. example, given instantiation new variablex, emphasize different extension sets respect different constraints cSi , writeEi instead Ei,x (a) simply denote extension set.Example 3 Consider network variables {x1 , x2 , x3 , x4 , x5 }:cS1 =cS2 =cS3 =cS4 =D1 = D4{(a, b, d), (a, b, a)}, S1 = {x1 , x2 , x3 };{(b, a, d), (b, a, b)}, S2 = {x2 , x4 , x3 };{(b, d), (b, c)},S3 = {x2 , x3 };{(b, a, d), (b, a, a)}, S4 = {x2 , x5 , x3 };= D5 = {a}, D2 = {b}, D3 = {a, b, c, d}.Let = (a, b, a) instantiation variables = {x1 , x2 , x4 }. relevant constraintsx3 cS1 , cS2 , cS3 . cS4 relevant since contains x5 outside . extensionsets x3 respect relevant constraints are:E1 (a) = {d, a}, E2 (a) = {d, b}, E3 (a) = {d, c}.intersection extension sets empty, implying extendedsatisfy relevant constraints cS1 , cS2 cS3 .Let = (b, c) instantiation {x2 , x3 }. E1,x1 (a) = thus trivial.words, trivial extension set, instantiation extended satisfyconstraint concern.relationship k-consistency set intersection characterized following lemma.Lemma 3 (Set Intersection Consistency; Lifting) constraint network R kconsistent consistent instantiation (k 1) distinct variables= {x1 , x2 , . . . , xk1 }, new variable xk ,\Eij 6=j1..lEij extension set xk respect cSij , cSi1 , . . . , cSil relevantconstraints.Proof. follows directly definition k-consistency Section 2definition extension set. 2insight behind lemma examine consistency perspective setintersection.448fiSet Intersection Consistency Constraint NetworksExample 4 Consider Example 3. would like check whether network 4consistent. Consider instantiation again. trivial consistent instantiationsince network doesnt constraint among variables . extend x,need check first three constraints cS1 cS3 . extension feasibleintersection E1 , E2 , E3 empty. show network 4-consistent,exhausting consistent instantiations three variables. Conversely, knownetwork 4-consistent, immediately say intersection three extensionsets x empty.usefulness lemma allows consistency information obtainedintersection extension sets, vice versa. point view consistencyset intersection, results set intersection properties, including Section 3,lifted get various consistency results constraint network followingproof schema.Proof Schema1. (Consistency Set) certain level consistency constraint network,derive information intersection extension sets Lemma 3.2. (Set Set) local intersection information sets, information mayobtained intersection sets.3. (Set Consistency) new information intersection extension sets,higher level consistency obtained Lemma 3.4. (Formulate conclusion consistency constraint network). 2proof schema, step 1 (consistency set), step 3 (set consistency), step 4straightforward many cases. So, Lemma 3 also called lifting lemmaset intersection result (step 3), easily consistency results network(step 4). proof schema establishes direct relationship set intersectionconsistency properties constraint network.following sections, demonstrate set intersection propertiesproof schema used obtain new results consistency constraint network.5. Global Consistency Tree Convex Constraintsnotion extension set plays role bridge restrictions set(s)properties special constraints. section, consider constraints arisingtree convex sets (Lemma 1). constraint tree convex extension sets respectconstraint tree convex.Definition 4 constraint cS tree convex respect xi tree Ti Disets= {ES,xi | ES,xi non-trivial extension instantiation {xi }}tree convex Ti . constraint cS tree convex tree uniondomains variables S, tree convex respect every x .Example 5 Tree convex constraints occur relationship amongvalues variable. Consider constraint accessibility set facilities449fiZhang & Yapset persons. personnel include network engineer, web server engineer, applicationengineer, team leader. relationship among staff team leadermanages rest, forms tree structure shown Figure 2(b). differentaccessibilities system includes basic access, access network routers, accessweb server, access file server. order access routers servers,one basic access right, implying tree structure (Figure 2(c)) accessrights. constraint team leader able access facilitiesengineer access corresponding facility (e.g., web server engineer accessweb server). tree convex constraint shown Figure 2(a) rowsnamed initials engineers columns initials access rights.tree union personnel accessibilities obtained respectivetrees (in Figure 2(b) (c)) adding edge, say web server leader. Noteconstraint Figure 2(a) row convex.nwlr*wf***(a)**b****leadernetworkengineerweb applicationengineer engineer routers(b)basic accesswebserverfileserver(c)Figure 2: tree convex constraint accessibilities staffsExample 6 Tree convex constraints also used model scene labeling problemsnaturally shown Zhang Freuder (2004).Definition 5 constraint network tree convex exists tree unionvariable domains constraints tree convex .Tree convex constraints generalize row convex constraints introduced van BeekDechter (1995).Definition 6 constraint cS row convex respect x sets= {ES,x | ES,x non-trivial extension instantiation {x}}tree convex tree node one child. tree calledtotal ordering. constraint cS row convex if, total ordering unioninvolved domains, row convex respect every x S.Example 7 constraint c Example 5 row convex, b (basic access)neighbor r (routers), w (web server), f (file server). However, total ordering,value neighbor two values. Hence, c row convextree convex.property set intersection tree convex sets proof schema,following consistency results tree convex constraints.450fiSet Intersection Consistency Constraint NetworksTheorem 1 (Tree Convexity) Let R network constraints arity rstrongly 2(r 1) + 1 consistent. R tree convex globally consistent.Proof. network strongly 2(r 1) + 1 consistent assumption. provenetwork k consistent k {2r, . . . , n}.Consider instantiation k 1 variables new variable x. Letnumber relevant constraints l. relevant constraint, one extension setx. So, l extension sets. intersection l sets empty,value x extended instantiation satisfies relevant constraints.(Consistency Set) Consider two l extension sets: E1 E2 . twocorresponding constraints involve 2(r1)+1 variables since arity constraintr two constraints x variable. consistency lemma,R (2(r 1) + 1)-consistent implies intersection E1 E2 empty.(Set Set) Since relevant constraints tree convex given tree,extension sets x tree convex. Henceforth, fact every two extensionsets intersect shows intersection l extension sets empty, treeconvex sets intersection lemma.(Set Consistency) consistency lemma, R k-consistent. 2Since row convex constraint tree convex, result generalizes consistency resultrow convex constraints reported van Beek Dechter (1995). interestingobserve latter lifted set intersection results convex sets (Zhang& Yap, 2003).question raised Theorem 1 efficient check whether constraintnetwork tree convex. Yosiphon (2003) proposed algorithm recognize treeconvex constraint network polynomial time.6. Consistency Tightness Constraintssection, present various consistency results networks m-tightconstraints.6.1 Global Consistency Weakly Tight Networkstightness constraints related consistency constraint networkvan Beek Dechter (1997). m-tightness constraint characterizedcardinality extension sets following way.Definition 7 (van Beek & Dechter, 1997) constraint cSi m-tight respect x Siiff instantiation Si {x},|Ei,x | |Ei,x | = |Dx |.constraint cSi m-tight iff m-tight respect every x Si .Given instantiation, extension set respect x domainvariable x, i.e., |Ei,x | = |Dx |, instantiation supported values x thuseasy satisfiable. Hence, definition above, instantiations affectm-tightness constraint.451fiZhang & Yapxbbcc..................... ................... .................................................................................................................................................................................. ................................. ..................... ................................. ................... ............................... ............................................................. ......... ..................................................... ........................................................................................................................................................................Figure 3: constraint cxy 2-tight 3-tightExample 8 Consider constraint cxy Figure 3 Dx = Dy = {a, b, c}. edgegraph denotes ends allowed cxy . verified valuesx, extension sets cardinality 2, values y, extension setscardinality 1 3. Hence, cxy said 2-tight 3-tight 1-tight.specially interested following tightness.Definition 8 constraint cSi properly m-tight respect x Si iff instantiation Si {x},|Ei,x | m.constraint cSi properly m-tight iff properly m-tight respect every x Si .constraint m-tight properly m-tight. converse might true.example, constraint x y, x {1, 2, . . . , 10} {1, 2, . . . , 10}, 9-tightproperly 9-tight. properly 10-tight since |Ex (10)| = 10 = 10.Next, define special constraint network allows us make accurateconnection tightness constraints consistency network.Definition 9 constraint network weakly m-tight level k iff every set variables{x1 , x2 , . . . , xl }(k l < n) new variable x, exists properly m-tight constraintamong relevant constraints x respect {x1 , x2 , . . . , xl }.x1x2y1x3x4y3y2y4(b)(a)Figure 4: Two constraint networks. thin edge represents properly m-tight constraintthick one represents non properly m-tight constraint452fiSet Intersection Consistency Constraint NetworksExample 9 network Figure 4(a) weakly tight level 3 threevariables fourth variable, one relevant constraints properly m-tight.network Figure 4(b) weakly tight level 3 since {y1 , y3 , y4 } y2 , nonerelevant constraints cy1 y2 cy4 y2 properly m-tight.small set intersection corollary (Corollary 1), following consistencyresult weakly m-tight network.Theorem 2 (Weak Tightness) constraint network R constraints arityr strongly ((m+1)(r1)+1)-consistent weakly m-tight level ((m+1)(r1)+1),globally consistent.Proof. Let j = (m+1)(r1)+1. constraint network R shown k-consistentk (j < k n).Let = {x1 , . . . , xk1 } set k 1 variables, instantiationvariables . Consider additional variable xk . Without loss generality, letrelevant constraints cS1 , . . . , cSl , Ei extension set xk respectcSi l.(Consistency Set) Consider + 1 l extension sets. corresponding+ 1 constraints contain (m + 1)(r 1) + 1 variables including xk . Since R((m+1)(r1)+1)-consistent, set intersection consistency lemma, intersection+ 1 extension sets empty.(Set Set) network weakly m-tight level ((m + 1)(r 1) + 1). So, mustproperly m-tight constraint among relevant constraints cS1 , . . . , cSl . Let cSi .know extension set |Ei | m. Since intersection every + 1 extensionsets empty, l extension sets share common element small set intersectioncorollary.(Set Consistency) lifting lemma, R k-consistent. 2similar fashion, main tightness result van Beek Dechter (1997),constraints required m-tight, lifted small sets intersectioncorollary Zhang Yap (2003). uniform treatment lifting set intersection resultsconsistency results absent existing works (e.g., Dechter, 1992; van Beek &Dechter, 1995, 1997; David, 1993).tightness result van Beek Dechter (1997) requires every constraintm-tight. weak tightness theorem, hand, require constraintsproperly m-tight. following example illustrates difference.Example 10 weakly m-tight network, interested topological structure.Thus omitted domains variables here. Consider network five variableslabeled {1, 2, 3, 4, 5}. network, pair variables three variables,constraint. Assume network already strongly 4-consistent.Since network already strongly 4-consistent, simply ignore instantiationsless 4 variables. introduce level network weaklym-tight. interesting level 4. Table 1 shows relevant constraintspossible extension four instantiated variables one. first row, 1234 5453fiZhang & YapExtension1234 5,2345 1,3451 2,4512 3,5123 4,125*,231 ,132 ,123 ,124 ,135 ,241 ,142 ,143*,134*,145 ,251*,152*,153 ,154 ,Relevant constraints235, 245, 345, 15+,341, 351, 451, 21 ,342, 352, 452, 12 ,243, 253, 453, 13 ,234, 254, 354, 14 ,25 ,31 ,32+,23+,24 ,35 ,41 ,42 ,43 ,34+,4551+525354Table 1: Relevant constraints extending instantiation four variables new variablestands extending instantiation variables {1, 2, 3, 4} variable 5. Entriessecond column denote constraint. example, 125 denotes c125 . constraints{1, 2, 5} {1, 3, 4} (suffixed * table) properly m-tight, network weaklym-tight level 4. Alternatively, constraints {1, 5}, {2, 3} {3, 4} (suffixed +)properly m-tight, network also weakly m-tight. tightness result vanBeek Dechter (1997) requires binary ternary constraints m-tight.6.2 Making Weakly Tight Networks Globally ConsistentConsider weak tightness theorem previous section. Generally, weakly m-tightnetwork might level local consistency required theorem. temptingenforce level consistency network make globally consistent. However,procedure may result constraints higher arity.Example 11 Consider network variables {x, x1 , x2 , x3 }. Let domains x1 , x2 , x3{1, 2, 3}, domain x {1, 2, 3, 4}, constraints variablestake different values: x 6= x1 , x 6= x2 , x 6= x3 , x1 6= x2 , x1 6= x3 , x2 6= x3 . networkstrongly path consistent. checking 4-consistency network, knowinstantiation (1, 2, 3) {x1 , x2 , x} consistent extended x3 . enforce 4-consistency, necessary introduce ternary constraint {x1 , x2 , x} make(1, 2, 3) longer valid instantiation.make new network globally consistent, newly introduced constraintshigher arity may turn require higher local consistency accordance Theorem 2.Therefore, difficult predict exact level consistency (variable based) enforcenetwork make globally consistent.section, relational consistency used make constraint network globallyconsistent.Definition 10 (van Beek & Dechter, 1997) constraint network relationally m-consistentiff given (1) distinct constraints cS1 , . . . , cSm , (2) xi=1 Si , (3)consistent instantiation variables (i=1 Si {x}), exists extensionx extension consistent relations. network stronglyrelationally m-consistent relationally j-consistent every j m.454fiSet Intersection Consistency Constraint NetworksVariables longer concern relational consistency. Instead, constraintsbasic unit consideration. Intuitively, relational m-consistency concerns whetherconstraints agree every one shared variables. makes sense differentconstraints interact exactly shared variables.Relational 1-, 2-consistency also called relational arc, path consistency,respectively.Using relational consistency, able obtain global consistency enforcing localconsistency network.Proposition 4 weak m-tightness level k constraint network preservedprocess enforcing relational consistency network.Proof. Let R constraint network relational consistency enforcing R1network consistency enforcing. Clearly, R R1 set variables.Consider set variables {x1 , x2 , . . . , xl } (k l < n) new variable x. SinceR weakly m-tight level k, exists properly m-tight constraint c amongrelevant constraints x respect {x1 , x2 , . . . , xl }. Enforcing relational consistencyconstraint network tighten constraint. So, proper m-tightness cpreserved. Hence, R1 weakly m-tight level k. 2main result subsection.Theorem 3 constraint network weakly m-tight level (m + 1)(r 1) + 1, rmaximal arity constraints network, globally consistent madestrongly relationally (m + 1)-consistent.Proof. Proposition 4, network still weakly m-tight (m + 1)(r 1) + 1enforcing strong relational (m + 1)-consistency it. Let r1 maximal arityconstraints new network consistency enforcing. Clearly, r1 r. So, networkm-tight (m + 1)(r1 1) + 1 Proposition 6. theorem follows immediatelyTheorem 8 Section 7. 2implication theorem long certain properly m-tight constraints certain combinations variables, network made globally consistentenforcing relational (m + 1)-consistency.following observation weak m-tightness network.Proposition 5 constraint network weakly m-tight level constraintevery two variables network properly m-tight.Proof. Consider level k, set variables = {x1 , x2 , . . . , xl }(k l n),new variable x/ . Since constraint two variables properly m-tight,constraint c{x1 ,x} x1 x properly m-tight. Therefore, properly m-tightconstraint c{x1 ,x} among relevant constraints instantiation . 2observation shows proper m-tightness constraints every twovariables sufficient determine level local consistency needed ensure globalconsistency constraint network.Remark. Proposition 5 assumes constraint every two variables.constraint two variables, universal constraint introduced.455fiZhang & Yapcase, enforce path consistency constraint network make binaryconstraints tighter lower level relational consistency needed make networkglobally consistent.6.3 Properties Weakly Tight Constraint NetworksSince weakly m-tight constraint network global consistency achievedlocal consistency, interesting important investigate conditions networkweakly m-tight. Although Proposition 5 shows sufficient condition, requires everybinary constraint tight. see Example 9(a), required numbertight constraints constraint network weakly tight reduced.subsection focused understanding relationship number tightconstraints weak tightness constraint network.strong relationship among different levels weak tightness network.Proposition 6 constraint network weakly m-tight level k m, weaklym-tight level j > k.Proof. j > k, prove network weakly tight level j. is,set variables = {x1 , . . . , xj }(k j < n) new variable x, showexists m-tight relevant constraint x respect . Since network weaklytight k < j, exists m-tight relevant constraint x respect subset. constraint still relevant x respect , thus one look for. 2following, present two results sufficient conditions constraint networkweakly m-tight.Theorem 4 Given constraint network (V, D, C) number m, every x V ,least n 2 properly m-tight binary constraints it, network weaklym-tight level 2.Proof. two variables {x, y} third variable z, relevant constraintsz respect {x, y} cxz cyz . know number relevant binaryconstraints z respect V n 1. n 2 properly m-tight meanseither cxz cyz must properly m-tight. 2fact, weak tightness higher level, need fewer constraints m-tightshown following result.Theorem 5 constraint network (V, D, C) weakly m-tight level k every x V ,least n k properly m-tight binary constraints it.Proof. set k variables new variable z, showproperly m-tight relevant constraint z respect . Otherwise, none kbinary constraints z properly m-tight. Since total number relevant binaryconstraints z n 1, number properly m-tight binary constraints z(n1)k, contradicts z involved nk properly m-tight binary constraints.2456fiSet Intersection Consistency Constraint Networksresult reveals constraint network weakly tight level k, couldneed n(n k + 1)/2 properly m-tight binary constraints, contrast resultTheorem 3 binary constraints required properly m-tight.immediate question is: minimum number m-tight constraints requirednetwork weakly tight? answered following result weaktightness level 2.Theorem 6 Given number m, constraint network weakly m-tight level 2,needs leastn(n 1)/2 2bn/3c n = 0, 1 (mod 3)otherwise(n 2)(3n 1)/6m-tight binary ternary constraints.Proof.Given network, weak m-tightness level 2 depends tightnessbinary ternary constraints. Among weakly m-tight (at level 3) constraintnetworks n variables, let R1 network minimal set properly m-tightbinary ternary constraints.following exposition, constraint denoted scope. example,use {u, v, w} {u, v} denote ternary constraint c{u,v,w} binary constraint cuvrespectively. constraint non-properly-m-tight properly m-tight.proof consists three steps.Step 1. preserving weak m-tightness R1 number properly mtight constraints R1 , modify, necessary, proper m-tightness constraintsR1 that, properly weak m-tight constraint {u, v, w}, none binaryconstraints {u, v}, {v, w}, {u, w} properly m-tight.modify proper m-tightness constraint c R1 remove c networkintroduce new constraint set variables c desirable properm-tightness.claim that, properly m-tight constraint {u, v, w}, one {u, v},{v, w}, {u, w} properly m-tight. Otherwise, least two properly mtight, means {u, v, w} modified properly m-tight, contradictingminimality number properly m-tight constraints R1 .Assume {u, v} properly m-tight. Since {u, v, w} properly m-tight,reason {u, v} properly m-tight. reason exists anothervariable z one {u, z} {v, z} properly m-tight, {u, v, z}properly m-tight, too. See Figure 5. Without loss generality, let {u, z} properly mtight, implying constraint {v, z} properly m-tight. constraint {z, v, w}properly m-tight {v, z} {v, w} properly m-tight.modify constraints {u, v, w} {z, v, w} properly m-tightmodify constraints {z, v} {v, w} properly m-tight. modification preservesnumber properly m-tight constraints R1 weak m-tightness R1 .Step 2. preserving weak m-tightness R1 number properly m-tightconstraints R1 , next modify, necessary, proper m-tightness constraintsR1 two properly m-tight ternary constraints share variables.457fiZhang & Yap................................................ ........................................................................................................ .... ..... .. ................... ................................... ........................ ...................... . ...............................................................................zuwvFigure 5: circle represents properly m-tight ternary constraint {u, v, w}. edgetwo variables indicates binary constraint. tick besides edge meansproperly m-tight cross means not.Case 1: Two properly m-tight constraints {u, v, w} {u, v, z} share two variables{u, v}. See Figure 6(a). Since {w, u} {u, z} properly m-tight (in terms step1), {w, u, z} properly m-tight. Since {w, v} {v, z} m-tight, {w, v, z}m-tight.modify four ternary constraints properly m-tight modify fourbinary constraints {w, u}, {u, z}, {z, v} {v, w} properly m-tight. preservesweak m-tightness R1 number properly m-tight constraints R1 .wvuxzzvwwvuuvuwx(b)(a)Figure 6: dotted ellipse together three variables inside represents ternaryconstraint. (a) Left: Two ternary constraints share two variables {u, v}. Right:ternary constraints properly m-tight. (b) Left: Two ternaryconstraints share one variable w. Right: ternary constraintsproperly m-tight.Case 2: Two properly m-tight constraints {u, v, w}, {w, x, y} share one variablew. Since {u, w} {w, x} properly m-tight, {u, w, x} properly m-tight.Since {v, w} {w, y} properly m-tight, {v, w, y} properly m-tight.Similarly, {u, w, y} {v, w, x} properly m-tight. Now, modify fourbinary constraints {u, w}, {w, x}, {v, w}, {w, y} properly m-tight sixternary constraints non-properly-m-tight, new network still weakly m-tightfewer m-tight constraints. contradicts minimality number properlym-tight constraints R1 . Hence, case 2 possible.Step 3. result first two steps, network R1 , scopes properlym-tight ternary constraints disjoint, binary constraint two variablesproperly m-tight ternary constraint properly m-tight.458fiSet Intersection Consistency Constraint NetworksLet B (and respectively) set properly m-tight binary (and ternaryrespectively) constraints R1 .Assume |T | = k. Since difficult count B, count maximum numbernon-properly-m-tight binary constraints R1 . 3k non-properly-m-tight binaryconstraints due . non-properly-m-tight binary constraintsvariable variable outside . Let V 0 variables outside .|V 0 | = n 3k. non-properly-m-tight constraints fall variablesV 0 . Since R1 weakly tight level 2, two non-properly-m-tight constraintsvariable V 0 . Hence, (n 3k)/2 non-properly-m-tight constraintsn 3k even, otherwise (n 3k 1)/2 ones. number, denoted ,properly m-tight constraints R1 would sum cardinality B:= k + (n(n 1)/2 3k b(n 3k)/2c) = n(n 1)/2 2k b(n 3k)/2c.fact minimal implies k maximized. n multiple 3,number properly m-tight constraints n(n 1)/2 2n/3; n 1 multiple3, number n(n 1)/2 2(n 1)/3; otherwise number (n 1)(3n 1)/6. 2result shows concept k-consistency still need significantnumber constraints properly m-tight predict global consistency networkterms constraint tightness.6.4 Dually Adaptive Consistencymain purpose characterization weak m-tightness network help identifyconsistency condition solution network found without backtracking, i.e., efficiently. studied constraint tightness concept k-consistencyprevious subsections. subsection, introduce dually adaptive consistencyachieve backtrack free search taking account tightness constraintstopological structure network.idea adaptive consistency (Dechter & Pearl, 1987) enforce necessarylevel consistency part network ensure global consistency. assumesordering variables. variable x, requires consistent instantiationrelevant variables x consistently extensible x. variablesplay direct role x thus ignored dealing x.first introduce notations used adaptive consistency.width variable respect variable ordering number constraintsinvolving x variables x. See Figure 7 example.Given network, variable ordering, variable x, directionally relevant constraints x involving x variables x. following, DR(x)used denote directionally relevant constraints x, used denote variablesoccurring constraints DR(x).constraints DR(x) consistent x if, consistent instantiation {x}, exists u Dx (a, u) satisfies constraintsDR(x).next define adaptive consistency network.459fiZhang & Yapx1...... ................................................. ........ 2........ ........ ............. ....3 ........ ....... .................... ....................4...................xxxx5Figure 7: variables {x1 , x2 , . . . , x5 } ordered according subscripts. example, x1 x2 . width x2 1.Definition 11 Given constraint network ordering variables, networkadaptively consistent variable x, directionally relevant constraintsconsistent x.adaptive consistency presented algorithm Dechter (2003) although,purpose paper, prefer declarative characterization.adaptively consistent network, solution found without backtracking.Proposition 7 Given constraint network ordering variables, backtrackfree search ensured network adaptively consistent.Proof. Assume found consistent instantiation first k variables (in termsgiven ordering). consistently extended xk+1 directionallyrelevant constraints xk+1 consistent xk+1 . 2network adaptively consistent, algorithm Dechter (2003, p. 105)used enforce adaptive consistency it.Adaptive consistency accurate estimating local consistencyensures global consistency, also makes intuitive algorithms enforce consistencyfind solution.knowledge constraint tightness presented previous subsections,know network adaptively consistent, sufficient make suresome, all, directionally relevant constraints variable consistent.position define dually adaptive consistency constraint network.Definition 12 Consider constraint network ordering variables.variable x network, let cx one tightest directionally relevant constraintsx cx properly mx -tight. network dually adaptively consistent1) variable x whose width greater mx , directionally relevantconstraints consistent it,2) variable x whose width greater mx , cx consistent everymx directionally relevant constraints x.Thanks set intersection result Lemma 2, main result duallyadaptive consistency.460fiSet Intersection Consistency Constraint NetworksTheorem 7 Given constraint network ordering variables, backtrack freesearch ensured dually adaptively consistent.Proof. need prove network adaptively consistent:variable x, directionally relevant constraints DR(x) consistent x. Letvariables involved DR(x). Consider consistent instantiation {x}. showexists u Dx (a, u) satisfies constraints DR(x). Let l numberconstraints DR(x), let cx one tightest constraint DR(x) propertightness mx . constraint ci DR(x), let extension set x ci Ei .sufficient showc DR(x) Ei 6= .know cx consistent every mx constraints. Hence, Ex , extension setcx , intersects every mx extension sets a. Lemma 2 impliesc DR(x) Ei 6= .2theorem, need tightest directionally relevant constraintvariable, totally n 1 constraints, predict global consistency network.could considered significant improvement results previous twosubsections.Compared result Dechter Pearl (1987), theorem also provideslower level (the smaller tightness width) consistency ensuring global consistency.constraint network dually adaptively consistent respect variableordering, made enforcing required consistency variable,reverse order given variable ordering. make procedure efficient,chose better variable ordering, depending topological structurenetwork tightness constraints.7. Tightness Convexity Revisitedconsistency results derived small set intersection tree convex set intersectionSection 5 Section 6.1 rephrased relational consistency setting.example, new version weak tightness based relational consistency given follows.Theorem 8 (Weak Tightness) constraint network R constraints arityr strongly relationally (m + 1)-consistent weakly m-tight level (m + 1)(r1) + 1, globally consistent.Proof. Let j = (m + 1)(r 1) + 1. constraint network R shownk-consistent k (j < k n).Let = {x1 , . . . , xk1 } set k 1 variables, consistent instantiationvariables . Consider new variable xk . Without loss generality, let cS1 , . . . , cSlrelevant constraints xk , Ei extension set xk respect cSil.461fiZhang & Yap(Consistency Set) Consider + 1 l extension sets. Since R relationally(m + 1)-consistent, intersection + 1 extension sets empty.(Set Set) network weakly m-tight. So, must properly m-tightconstraint relevant constraints cS1 , . . . , cSl . Let cSi . extension set |Ei | m.Since every + 1 extension sets non-empty intersection, l extension setsshare common element small set intersection result (Corollary 1).(Set Consistency) lifting lemma, R k-consistent. 2Compared weak tightness theorem Section 6.1, exposition resultneater proof simpler.completeness, also include new version tree convex theorem usingrelational consistency. proof omitted since simplified version oneSection 5 hinted proof above.Theorem 9 (Tree Convexity) Let R tree convex constraint network. R globallyconsistent strongly relationally path consistent.8. Conclusionlifting lemma proof schema, shown set intersection resultseasily lifted consistency results constraint network. advantagesapproach studying consistency.Firstly, although approach offer completely new way prove consistency results, provide uniform way understand many seemingly different resultsimpact convexity tightness global consistency. addition resultsshown here, results also obtained easily lifting lemma proofschema. example, work David (1993) obtained lifting corollaryLemma 2 (Zhang & Yap, 2003). work Sam-Haroud Faltings (1996) convexconstraint networks continuous domains lifted Hellys theorem (Eckhoff,1993) intersection convex sets Euclidean spaces.Secondly, establishment relationship set intersection consistencyconstraint network makes easier communicate consistency results researchers outside constraint network community. also made possiblecontribute consistency results exploiting knowledge set intersection properties.importantly, approach singles fact set intersection properties playfundamental role determining consistency constraint network. perspectivehelps us focus properties set intersection discover generalize intersectionproperties tree convex sets sets cardinality restrictions. correspondingconsistency results extended understanding convexity tightness constraints since Dechter van Beeks work (1995, 1997). identify new class treeconvex constraints global consistency ensured certain level local consistency. generalizes row convex constraints van Beek Dechter (1995). alsoshow weakly m-tight constraint network made globally consistent enforcinglocal consistency. type result tightness new. Detailed study carriedconstraint network weakly m-tight. make full use tightnessconstraints, propose dually adaptive consistency exploits topology462fiSet Intersection Consistency Constraint Networkssemantics constraint network, results relation setintersection consistency. dually adaptive consistency, topology networktightest relevant constraint variable determine local consistencyensures backtrack-free search.Acknowledgmentsindebted Dr. Peter van Beek Dr. Fengming Dong helpful discussions.constructive comments anonymous referees various versions paperimproved quality. material based works partially supported grantAcademic Research Fund National University Singapore ScienceFoundation Ireland Grant 00/PI.1/C075. materials paper appearedProceedings International Joint Conference Artificial Intelligence 2003 (Zhang& Yap, 2003) Proceedings Principles Practice Constraint Programming2004 (Zhang, 2004).ReferencesDavid, P. (1993). functional bijective constraints make CSP polynomial.Proceedings Thirteenth International Joint Conference Artificial Intelligence,Vol. 1, pp. 224229 Chambery, France. IJCAI, Inc.Dechter, R. (1992). local global consistency. Artificial Intelligence, 55, 87107.Dechter, R. (2003). Constraint Processing. Morgan Kaufmann, San Francisco, CA.Dechter, R., & Pearl, J. (1987). Network-based heuristics constraint satisfaction problems. Artificial Intelligence, 34, 138.Eckhoff, J. (1993). Helly, Radon, Caratheodory type theorems. Gruber, P. M.,& Wills, J. M. (Eds.), Handbook Convex Geometry, pp. 389448. North Holland,Amsterdam.Freuder, E. (1978). Synthesizing constraint expressions. Communications ACM, 21 (11),958966.Freuder, E. (1982). sufficient condition backtrack-free search. Journal ACM,29 (1), 2432.Jeavons, P. G., Cohen, D. A., & Gyssens, M. (1997). Closure properties constraints.Journal ACM, 44 (4), 527548.Mackworth, A. K. (1977). Consistency networks relations. Artificial Intelligence, 8 (1),118126.Montanari, U. (1974). Networks constraints: fundamental properties applications.Information Science, 7 (2), 95132.Sam-Haroud, D., & Faltings, B. V. (1996). Solving non-binary convex CSPs continousdomains. Proceedings International Conference Principles PracticeConstraint Programming 1996, pp. 410424 Cambridge, Massachusetts. Springer.463fiZhang & YapSchaefer, T. J. (1978). complexity satisfiability problems. Proceedings 10thACM Symposium Theory Computing, pp. 216226.van Beek, P., & Dechter, R. (1995). minimality global consistency row-convexconstraint networks. Journal ACM, 42 (3), 543561.van Beek, P., & Dechter, R. (1997). Constraint tightness looseness versus localglobal consistency. Journal ACM, 44 (4), 549566.Yosiphon, G. (2003). Efficient algorithm identifying tree convex constraints. Manuscript.Zhang, Y. (2004). tightness constraints. Proceedings Principles PracticeConstraint Programming 2004, pp. 777781 Toronto, Canada. Springer.Zhang, Y., & Freuder, E. C. (2004). Tractable tree convex constraints. ProceedingsNational Conference Artificial Intelligence 2004, pp. 197202 San Jose, CA, USA.AAAI press.Zhang, Y., & Yap, R. H. C. (2003). Consistency set intersection. ProceedingsInternational Joint Conference Artificial Intelligence 2003, pp. 263268 Acapulco,Mexico. IJCAI Inc.464fiJournal Artificial Intelligence Research 27 (2006) 1-23Submitted 02/06; published 09/06Variational Inference Procedure Allowing InternalStructure Overlapping Clusters DeterministicConstraintsDan Geigerdang@cs.technion.ac.ilComputer Science Dept., Technion,Haifa, 32000, IsraelChristopher Meekmeek@microsoft.comMicrosoft Research, Microsoft Corporation,Redmond, WA 98052, USAYdo Wexlerywex@cs.technion.ac.ilComputer Science Dept., Technion,Haifa, 32000, IsraelAbstractdevelop novel algorithm, called VIP*, structured variational approximateinference. algorithm extends known algorithms allow efficient multiple potentialupdates overlapping clusters, overcomes difficulties imposed deterministicconstraints. algorithms convergence proven applicability demonstratedgenetic linkage analysis.1. IntroductionProbabilistic graphical models elegant framework represent joint probability distributions compact manner. independence relationships random variablesnodes graph represented absence arcs model.intuitively appealing presentation also naturally enables design efficient generalpurpose algorithms computing marginal probabilities, called inference algorithms.general inference problem NP-hard (Cooper, 1990; Dagum & Luby, 1993),although many cases model small (or, precisely, smalltreewidth) exact inference algorithms feasible, others timespace complexity makes use algorithms infeasible. cases fast yetaccurate approximations desired.focus variational algorithms: powerful tool efficient approximate inferenceoffers guarantees form lower bound marginal probabilities.family approaches aims minimize KL divergence distribution Qtarget distribution P finding best distribution Q family distributionsinference feasible. particular, joint distribution P (X) setdiscrete variables X goal compute marginal probability P (Y = y)X. assume exact computation feasible. idea replaceP distribution Q used compute lower bound P (Y = y).c2006AI Access Foundation. rights reserved.fiGeiger, Meek & Wexlerlet H = X \ . Then, using Jensens inequality get following bound:log P (y) = logXhQ(h)P (y, h) XP (y, h)Q(h) log= D(Q(H) || P (Y = y, H))Q(h)Q(h)hD( || ) denotes KL divergence two probability distributions. quantity D(Q || P ) often called free-energy P Q possibly un-normalizeddistributions. Variational techniques aim choose distribution Q lowerbound high possible, equivalently, KL divergence Q(h)P (h|Y = y) minimized.Variational approaches mean field, generalized mean field, structuredmean field differ respect family approximating distributionsused, structural mean field approach subsuming remaining approachesspecial cases. research several authors guided work: Saul & Jordan (1996),Ghahramani & Jordan (1997), Wiegerinck (2000) Bishop & Winn (2003).contributions paper threefold. First develop extensionalgorithm Wiegerinck (2000), call vip? , allows set potentialsapproximating distribution Q updated simultaneously even clusters Q overlap. Algorithm vip? N -fold faster Wiegerincks algorithm N N grid-like modelsyields two orders magnitude improvement large graphs genetic linkageanalysis model large pedigrees. Note simultaneous updates first presentedphylogenic trees Jojic et al. (2004). Second, prove convergence vip? previous variational methods via novel proof method, using properties KL divergence.Third, extend vip? allow deterministic constraints model demonstrateapplicability extension genetic linkage analysis.2. Backgroundbackground section based primarily paper Weigerinck (2000),turn builds pioneering works papers Saul & Jordan (1996) Ghahramani& Jordan (1997). review provides new exposition material.denote distributions P (x) Q(x) related un-normalized distributionsP (x) P (x) Q(x) Q(x). LetX finite set variables x instantiation1 Qvariables. Let P (x) = ZP (di ) di projection instantiationx variables Di X non-negative function, commonly calledpotential. constant ZP normalizes product potentials subsets {Di }Ii=1allowed overlap. often suppress arguments potential distribution,using instead (di ) P instead P (X).goal find distribution Q minimizes QKL divergence Q P .constrain Q form Q(x) = Z1Q j j (cj ) ZQ normalizingconstant C1 , . . . , CJ possibly overlapping subsets X, call clusters. Finding optimum Q, however, difficult. modest common goaldevising iterative converging algorithms iteration KL divergenceapproximating distribution Q P decreases unless Q stationary point.Throughout, define Q(w|u) = |W1\U | instantiations U = u Q(u) = 0.Consequently, terms equality Q(w, u) = Q(u)Q(w|u) well defined even2fiA Variational Inference ProcedurePQ(u) = 0. Moreover, convention maintains propertiesW \U Q(w|u) = 1111Q(w, z|u) = Q(w|z, u)Q(z|u) = |W \{U Z}| |Z\U | = |{W Z}\U | . also noteQ(x) log Q(x) = 0 whenever Q(x) = 0 thus KL divergenceD(Q || P ) =XQ(x) logxQ(x)P (x)finite P (x) = 0 Q(x) > 0 instance x.starting point algorithm developed Wiegerinck (2000). algorithm findsdistribution Q follows: iterates clusters Cj instantiations cjupdate potentials j (cj ) = ej (cj ) via following update equation:j (cj )XXQ(ck |cj ) log k (ck ) +{k:gkj =1} Ck \CjXXQ(di |cj ) log (di )(1){i:fij =1} Di \Cjgkj fij two indicator functions defined via gkj = 0 Q(Ck |cj ) = Q(Ck )every instance cj Cj 1 otherwise, fij = 0 Q(Di |cj ) = Q(Di ) every instancecj Cj 1 otherwise. Wiegerinck (2000) proved convergence algorithm stationary point using Lagrangians. Throughout call iterative procedure, Wiegerincksalgorithm.Wiegerincks algorithm relies step algorithm compute conditionalprobabilities Q(ck |cj ) Q(di |cj ) un-normalized distribution Q representedset potentials j (cj ). accomplished inference algorithmbucket elimination algorithm sum-product algorithm described Dechter (1999)QKschischang, Frey & Loeliger (2001) . important note Q(x) = j j (cj )computation conditionals affected multiplying j constant.Wiegerincks algorithm generalizes mean field (MF) algorithm generalizedmean field (GMF) algorithm (Xing, Jordan & Russell, 2003, 2004). mean field algorithm special case Wiegerincks algorithm Cj contains singlevariable. Similarly, generalized mean field algorithm special case Cjdisjoint subsets variables. Cj disjoint clusters, formula j Eq. 1simplifies GMF equations follows (first term drops out):j (cj )XXQ(di |cj ) log (di ).(2){i:fij =1} Di \Cjterm Q(di |cj ) made explicit Cj disjoint clusters (Bishop & Winn2003). particular, set Di \ Cj partitions Dik = (Di \ Cj ) Ck Qk = 1, . . . , Jk 6= j. Note Dik = Di Ck . Using notation, Q(di |cj ) = k Q(dki )Q(dki ) = 1 whenever Dik = . factorization simplifies formula jfollows:XX Xj (cj )Q(d1i ) . . .Q(dJi ) log (di ).(3){i:fij =1} Di1DiJ3fiGeiger, Meek & Wexlersimplification achieved automatically using bucket elimination computingj . iterated sums Eq. 3 fact buckets formed bucket eliminationCj disjoint.Eq. 1 requires repeated computation quantities Q(ck |cj ) Q(di |cj ). repetition significant could many indices k Q(Ck |cj ) 6= Q(Ck ),many indices Q(Di |cj ) 6= Q(Di ). computations share many subcomputations therefore reasonable add data structure facilitate efficientimplementation function calls. particular, possible save computationssets C1 , . . . , CJ form junction tree.set clusters C1 , . . . , CJ forms junction tree iff exists set trees JT one node, called Cj , cluster variables Cj , every two nodes CiCj JT, connected path JT, node Ck path,Ci Cj Ck holds. set trees mean undirected graph, necessarilyconnected, cycles. Note definition allows junction tree disconnected graph.QQ C1 , . . . , CJ form junction tree, Q(x) decomposable formQ(x) = j j (cj )/ e e (se ), j marginals subsets Cj X,e marginals intersections Se = Ci Cj , one two neighboring clustersjunction tree (Jensen 1996).Wiegerinck (2000) enhanced basic algorithm maintainsconsistentjunctionPPtree JT distribution Q(x). Consistency means Cj \Ck j = Ck \Cj kevery two clusters. consistent junction tree, potential j (Cj ) proportionalQ(Cj ). update potential algorithm may yield inconsistent junctiontree, however, consistency maintained applying DistributeEvidence(j ) (Jensen1996) update potential. procedure DistributeEvidence(0j ) acceptsinput consistent junction tree new cluster marginal 0j Cj , updatespotential every neighboring cluster Ck Cj viaCj \Ck0j (cj )Cj \Ckj (cj )P0k (ck )k (ck ) P(4)neighboring cluster recursively propagates update applying Eq. 4neighbors except one update came. output procedureconsistent junction tree, clusters, 0j (possibly un-normalized)marginal probability Q Cj , conditional probability Q(X|Cj ) remainsunchanged (Jensen 1996, pp. 74).Wiegerincks enhanced algorithm, uses junction tree, iteratively updatespotential cluster (node junction tree), using potentials clustersseparators. However, since junction tree may consistent update,algorithm applies procedure DistributeEvidence(j ) junction tree,update. Note description omits normalization step Wiegerinck (2000)needed convergence.time consuming computation variational algorithms computing conditional probabilities form Q(ck |cj ) Q(di |cj ). distinguish among conditional probabilities follows.4fiA Variational Inference ProcedureDefinition: conditional probability Q(A|cj ) subsumed Q set target variables subset cluster Ck Q (i.e., (A \ Cj ) Ck ).Wiegerincks enhanced algorithm substantial computational benefits conditional probabilities subsumed. cases needed quantities Eq. 1, Q(di |cj )Q(ck |cj ), obtained mere lookup junction tree, one callDistributeEvidence made update.Weigerincks basic enhanced algorithms assume structure j , namely,algorithms hold tables j explicit entry every instantiation Cj . Sincecomputations Q(ck |cj ) Q(di |cj ) grow exponentially size Di Ck ,algorithms become infeasible large cliques clusters. simplification, additionalstructure j suggested Wiegerinck (2000, Section 4) form,j (cj ) =njjl (cjl ),(5)l=1sets Cjl , l = 1, . . . , nj , possibly overlapping subsets Cj , cjlprojection instantiation cj variables Cjl . Using structure sufficienthold tables subsets Cjl considerably smaller. Note jentry instantiation cj , nj = 1 j (cj ) = j1 (cj1 ). Weigerinck usesstructure potentials j following assumptions:Definition [SelfQcompatibility]: distribution Q clusters Cj subsets Cjl1form Q(x) = ZQ j j (cj ), clusters factor according Eq. 5, self compatibleevery Cj Ck set indices Njk = {l : Q(Ck |cj ) = Q(Ck |cjl )} non-emptyregardless values potentials j , cj arbitrary instantiation Cjcjl projection cj Cjl .Definition [Compatibilitywrt P ]: distribution Q clusters Cj subsets CjlQform Q(x) = Z1Q j j (cj ), clusters factor according Eq. 5, compatibleQwrt distribution P sets Di form P (x) = Z1P (di ) every Di Cjset indices Mij = {l : Q(Di |cj ) = Q(Di |cjl )} non-empty, cj arbitraryinstantiation Cj cjl projection cj Cjl .Note self-compatibility compatibility wrt P depend form Qparticular realization potentials j .assumptions Weigerinck states considerable simplifications deduced, provides examples statement.note algorithms Bishop & Winn (2003) Jojic et al. (2004) usestronger assumption clusters Cj approximating distribution Q disjointQ(Ck |cj ) = Q(Ck ). assumption, implies Q(Ck |cj ) = Q(Ck |cjl )Q(Di |cj ) = Q(Di |cjl ) every index l, relaxed requiring equalitieshold single index l (but possibly multiple indices).5fiGeiger, Meek & Wexler3. Multiple Potential Update using Overlapping Clusterssection develop new algorithm, called vip? , uses additional structurepotentials offered Eq. 5 speed computations. particular, rather updatnjing potential jl separately, offer way update set potentials {jl }l=1simultaneously, saving considerable computations. Furthermore, simultaneous updateenhanced using junction tree, despite fact sets {Cjl } need formjunction tree, {Cj } form junction tree.algorithm uses definitions self compatibility compatibility wrt P , definedearlier, following definition indices.Definition: Let indicator function gjk (l) equal 1 single fixed index l Njk0 indices Njk Q(Ck |cj ) 6= Q(Ck ), equal 0 otherwise. Letindicator function fij (l) equal 1 single fixed index l Mij 0 indicesMij Q(Di |cj ) 6= Q(Di ), equal 0 otherwise.Algorithm vip? given Figure 1. convergence proved Section 4. proofrequires Q self-compatible, compatible wrt P , addition, satisfy (P (x) = 0)(Q(x) = 0). Note D(Q || P ) = distributions Q satisfy lastassumption.main improvement algorithm efficient update potentials. potentials j factorize smaller potentials jl according Eq. 5, algorithm vip?updates jl instead updating whole potential j , done Weigerincks algorithms.update potentials jl done vip? equivalent updating j accordingEq. 1, irrelevant constant, require compute update equationinstance cluster Cj . proposed change considerably speeds previousalgorithms.algorithm gets input target distribution P sets Di form P (x) =1 Q(di ) approximating distribution Q clusters Cj self-compatible,ZPcompatible wrt P satisfiescondition (P (x) = 0) (Q(x) = 0). Distribution QQform Q(x) = Z1Q j j (cj ) potential every cluster Cj factors accordingQnjjl (cjl ) clusters form consistent junction tree. algorithmj (cj ) = l=1iterates clusters, updating potential every instantiation subsetsCjl according Eq. 6. apply update equation, quantities Q(di |cjl ) computedvia variable propagation (Jensen, pp 69-80) junction tree. quantitiessubsumed, obtained mere lookup junction tree. Then, updatingpotentials subsets Cjl cluster Cj , procedure DistributeEvidence appliedmake junction tree consistent respect j . Since clusters Cj formjunction tree via subsets Cjl , Eq. 4 replaced Eq. 7. convergence,algorithm vip? outputs approximating distribution Q revised potentials.Example 1 target distribution P N N grid pairwise potentials (see Figure 2a)approximating family defined single row set columns grid,augmented edges middle vertex (see Figure 2b) C7 rowgrid Ci (i = 1, . . . , N = 6) columns. Using notation Xi,j denotevertex row column j grid, cluster C7 associated N 1 subsets6fiA Variational Inference ProcedureAlgorithm VIP? (Q,P)QQInput: Two probability distributions P (x) = Z1P (di ) Q(x) = Z1Q j j (cj )Qnjinitial potentials j (cj ) = l=1jl (cjl ) form consistent junction tree, Qself-compatible, compatible wrt P , satisfies (P (x) = 0) (Q(x) = 0).Output:revised set potentials jl (cj ) defining probability distribution Q via Q(x)Q(cj,l jl jl ) Q stationary point D(Q || P ).Iterate clusters Cj convergenceStep 1.l = 1, . . . , nj :every instantiation cjl Cjl apply following update equation:jl (cjl )XXXQ(ck |cjl ) log k (ck ) +{k:gjk (l)=1} Ck \CjlXQ(di |cjl ) log (di ) (6){i:fij (l)=1} Di \Cjljl (cjl ) ejl (cjl )Note: Q(di |cjl ) computed via variable propagation (Jensen, pp 69-80) junctiontree JT. However, quantities subsumed, obtained mere lookupJT.Step 2. Make JT consistent respect j :DistributeEvidence(JT, j )DistributeEvidence(JT, 0j )Input: junction tree JT nodes Ck potentials k (ck ) =node Cj revised potential 0j .Output: consistent junction tree.Qnkl=1 kl (ckl ).startinginitialization source(j) 0; updated {j}(updated6= )first element updated; updated updated\{}neighboring nodes Ck C JT k 6= source()PQn 0C\Cl=1 l (cl )0km (ckm ) km (ckm ) P k QnC \Ckl=1 l (cl )single subset Ck (C Ck ) Ckmsource(k)updated updated{k}Figure 1: Algorithm vip?7(7)fiGeiger, Meek & Wexler(a)(b)(c)Figure 2: (a) Grid-like P distribution (b) & (c) Approximating distributions Q.C7l = {X3,l , X3,l+1 }. column cluster Cj associated 2N-4=8 subsets CjlCjl = {Xl,j , Xl+1,j } N-1 subsets (l = 1, . . . , 5), Cjl = {X1,j , X3,j } l = N ,Cjl = {XlN +4,j , X3,j } additional N-4 subsets (l = 7, 8).choice induces self-compatible approximating distribution Q; every column clusterCj independent another cluster given subset contains X3,j (such Cj2 ).addition, row cluster C7 independent every column cluster Cj given C7j .induced distribution also compatible wrt P ; vertical edge Dv = {Xi,j , Xi+1,j }P , distribution Q satisfies Q(Dv |ck ) = Q(Dv |ck2 ) column cluster Ckk 6= j, Q(Dv |c7 ) = Q(Dv |c7j ). addition, horizontal edge Dh = {Xi,j , Xi,j+1 }P , distribution Q satisfies Q(Dh |c7 ) = Q(Dh |c7j ), Q(Dh |ck ) = Q(Dh |ck2 ) k 6=j, j + 1. Finally, edge Dh k = j, j + 1, approximating distribution satisfiesQ(Dh |ck ) = Q(Dh |ckl ) Ckl = {Xi,k , X3,k }, due additional N 3 edges addedcolumn cluster.Like Wiegerincks enhanced algorithm, algorithm vip? substantial computationalbenefits conditional probabilities Q(di |cjl ) subsumed. cases neededquantities, Q(di |cjl ) Q(ck |cjl ), obtained mere lookup junction treestep 1 algorithm, one call DistributeEvidence made step 2,demonstrated next paragraph. computational efficiency vip? achievedeven quantities Q(di |cjl ) subsumed factor subsumed probabilities.Disjoint clusters one special case, quantities Q(di |cjl ) factorsubsumed probabilities Q(dki |cjl ), Dik = Di Ck , obtainable lookupjunction tree.Consider Example 1 compare computational cost vip? versus Wiegerincksbasic enhanced algorithms. Assume Wiegerincks basic algorithm (Eq. 1), usesdistribution Q given Figure 2c, 35 clusters Cj0 60 sets Di . Therefore,junction tree used, 4 (60 + 34) = 376 conditionals computed cluster Cj0(edge) boundary grid, 94 four possible values edgecluster Cj0 . Clearly, additional clusters introduced, shown example Figure 2b,computational cost grows. using junction tree, done Wiegerincks enhanced algorithm, subsumed conditional probabilities, computed separatelyWiegerincks basic algorithm, computed single call DistributeEvidence.computation covers subsets Figure 2c. conditionals sub8fiA Variational Inference Procedure(a)(b)(c)Figure 3: target distribution P grid pairwise potentials (a). Two differentpartitions grid clusters shown Figures (b) (c), containsubsets.sumed Q(di |cj ) horizontal edges Di contained single cluster, namely,edges 2a 2c. factor two subsumed probabilities, one computedsingle call described earlier requires second call DistributeEvidence.example, let Di = {X1 , X2 } horizontal edge P overlap Cj0 ,Q(x1 , x2 |c0j ) = Q(x1 |c0j , x2 )Q(x2 |c0j ). two conditionals subsumed, secondcall DistributeEvidence needed obtain Q(x1 |c0j , x2 ). yields 25 calls DistributeEvidence. However, Example 1, one call DistributeEvidence sufficientcompute conditionals two adjacent horizontal edges, yielding need15 calls. Therefore, since 4 15 = 60 calls DistributeEvidence, sincecost junction tree algorithm typically twice cost computing conditionalprobabilities without using junction tree, yields 3-fold speedup Wiegerincksenhanced algorithm versus Wiegerincks basic algorithm. edges boundary,speedup factor less 3. size grid grows, smaller fraction edgesboundary, and, thus, speedup approaches 3-fold speedup.significant speedup obtained using algorithm vip? clusters Cj subsetsdescribed Figure 2b. Note additional subsets needed meet compatibility assumption vip? . Algorithm vip? makes one call DistributeEvidenceper cluster Cj non-subsumed conditional, rather every edge cluster Cj0 .Since vip? uses N + 1 clusters Cj , speedup compared Wiegerincks enhancedalgorithm approaches N N N grid grows. O(N ) speedup confirmedexperiments section (Figure 9).Another potential benefit vip? possibility alternating differentchoices clusters contain identical subsets Cjl . simple example gridFigure 3a, two choices illustrated Figures 3b 3c. two sets clusters update potentials j differently therefore yield better approximationsdistance D(Q || P ) reduced every alternation. general, iterateset choices clusters execute vip? one choice using initial potentialspotentials jl found earlier choice clusters. practical benefit optionadded flexibility remains tested application.9fiGeiger, Meek & Wexler4. Proof Convergencedevelop several lemmas culminate proof convergence algorithm vip? .Lemma 1 states two un-normalized probability distributions P (x) Q(x)KL divergence minimized Q(x) proportional P (x). Lemma 2 rewritesKL divergence D(Q || P ) terms potentials PQ P using quantity j (cj )which, according Lemma 3, differs j (cj ) = l jl (cjl ) constant. Finally,Theorem 1 asserts KL divergence Q P decreases iterationAlgorithm vip? unless Q stationary point. proof exploits new formD(Q || P ) provided Lemma 2, replaces term j (cj ) terms jl (cjl ) usedupdate equation vip? . final observation, uses Lemma 1, closes proofshowing potentials updated algorithm vip? , KL divergenceminimized wrt j .first lemma provides variant well known property KL. Recallevery two probability distributions Q(x) P (x), KL divergence D(Q(x) || P (x)) 0equality holds Q(x) = P (x) (Cover & Thomas 1991; Theorem 2.6.3).similar result holds also un-normalized probability distributions.Lemma 1 Let Q(x) P (x) non-negative functionsletQ(x) =D(Q(x) || P (x))P min{Q|xPx P (x)= ZP > 0,Q(x)=ZQ }ZQ positive constant. Q(x) =ZQZP P (x).Proof. observeP (x)D(Q(x) || P (x)) = ZQ D( Q(x)ZQ || ZP ) + ZQ logZQZPimplies, using cited result normalized distributions, minimumP (x)obtained Q(x)ZQ = ZP , yielding desired claim.next lemma rewrites KL divergence optimizing update equationcluster Cj becomes readily available.Lemma 2 Let P (x) =tions. Then,1ZPQ(di )D(Q || P ) =XCjQ(x) =Q(cj ) log1ZQQjj (cj ) two probability distribu-j (cj )+ log(ZP ) log(ZQ )j (cj )(8)j (cj ) = ej (cj ) ,j (cj ) =X XQ(ck |cj ) log k (ck ) +X Xk Ck \Cj10Di \CjQ(di |cj ) log (di )(9)fiA Variational Inference ProcedureProof: RecallD(Q || P ) =XQ(x) logXQ(x)= [H(Q) + EQ [log P (x)]]P (x)(10)H(Q) denotes entropy Q(x) EQ denotes expectation respect Q.entropy term writtenX XH(Q) =Q(cj )Q(x|cj ) [log Q(cj ) + log Q(x|cj )]Cj X\Cj=PCjQ(cj ) log Q(cj )PCjQ(cj )PX\CjQ(x|cj ) log Q(x|cj ).variation well known form H(Q) derived splittingsummationPX summation Cj X \ Cj , using fact Q(cj ) X\Cj Q(x|cj ) =Q(cj ) holds every distribution. split sum X \ Cj Q(cj ) > 0 use1 QXk k (ck )ZQ=log k (ck ) log Q(cj ) log(ZQ )log Q(x|cj ) = logQ(cj )kThus,XQ(x|cj ) log Q(x|cj ) =X\CjP PPQ(ck |cj )Q(x|ck , cj ) log k (ck ) X\Cj Q(x|cj ) [log Q(cj ) + log(ZQ )]Pusing Q(ck , cj ) X\{Ck Cj } Q(x|ck , cj ) = Q(ck , cj ) term rewrittenXH(Q) =Q(cj ) log Q(cj )kX\CjCjPCj Q(cj )hPk6=jPCk \Cj Q(ck |cj ) log k (ck ) + logj (cj )Q(cj )+ log(ZQ )Note Q(cj ) = 0 bracketed term multiplied zero, due equality0 log 0 = 0, product also zero.second term Eq. 10 similarly writtenXXXEQ [log P (x)] =Q(cj )Q(x|cj ) log (di ) log(ZP )=XQ(cj )CjX XCj(11)X\CjQ(di |cj ) log (di ) log(ZP )Di \CjHence Eq. 10 rewrittenXD(Q || P ) =Q(cj ) log Q(cj )CjXCjQ(cj )X XQ(ck |cj ) log k (ck ) +X Xk Ck \Cj11Di \CjQ(di |cj ) log (di )fiGeiger, Meek & WexlerXCjQ(cj ) logQ(cj )+ log(ZP ) log(ZQ )j (cj )Denoting bracketed term j (cj ), letting j (cj ) = ej (cj ) , getD(Q || P ) =XCjQ(cj ) logj (cj )+ log(ZP ) log(ZQ ).j (cj )Pnext lemma shows j (cj ), defined Eq. 9, j (cj ) = l jl (cjl ), usedupdate potentials Q vip? , differ additive constant dependcj . argued Theorem 1, fact difference constant enables vip?use latter form, efficient representation.QQQLemma 3 Let P (x) = Z1P (di ) Q(x) = Z1Q j j (cj ) j (cj ) = l jl (cjl ),two probability distributions Q self-compatible compatible wrt P . LetXXXXjl (cjl ) =Q(ck |cjl ) log k (ck ) +Q(di |cjl ) log (di ) (12){k:gjk (l)=1} Ck \Cjl{i:fij (l)=1} Di \CjlThen, difference j (cj ) defined Eq. 9 j (cj ) =depend cj .Pljl (cjl ) constantPProof: first argue term form Ck \Cj Q(ck |cj ) log k (ck ) termPform Di \Cj Q(di |cj ) log (di ) Eq. 9 depends cj appears exactlysingle subset Cjl Eq. 12. argue every term Eq. 12 appearsEq. 9.Since Q self-compatible, follows every cluster Ck depends Cjfunction gkj (l) equalsPone single subset Cjl , namely Q(ck |cj ) = Q(ck |cjl ),case expressionCk \Cj Q(ck |cjl ) log k (ck ) appears Eq. 12. Similarly, since Qcompatible wrt P follows every set Di depends Cj function fij (l)equalsone single subset Cjl , namely Q(di |cj ) = Q(di |cjl ), case expressionPDi \Cj Q(di |cjl ) log (di ) appears second term Eq. 12.remains show every term Eq. 12 appears Eq. 9. Since Q selfcompatible, implied Ck Cj Cjl thus summing Ck \ Cj equivalentsumming Ck \ Cjl . Therefore, every k gjk (l) = 1, first termEq. 12 appears Eq. 9. Similarly, since Q compatible wrt P , impliedDi Cj Cjl thus summing Di \ Cj equivalent summing Di \ Cjltherefore every fij (l) = 1 second term Eq. 12 appears Eq. 9.Theorem 1 (Convergence vip? ) Let initial approximating distribution Q selfcompatible compatible wrt given distribution P , assume (P (x) = 0)(Q(x) = 0). Then, revised distribution Q retains properties, iterationAlgorithm vip? KL divergence Q P decreases unless Q stationarypoint.12fiA Variational Inference ProcedureQProof. Let Q(x) = Z1Q jl jl (cjl ) jl (cjl ) = ejl (cjl ) . need show0?startQ of0 iteration vip function Q defined revised potentials0j (cj ) = l jl (cjl ) probability distribution listed propertiescloser P KL divergence Q start previous iteration.First, show Q0 maintains properties listed theorem throughoutupdates done vip? . properties self-compatibility compatibility wrt Pderived form Q thus affected updates done vip? .property(P (x) = 0) (Q(x) = 0), consider instance x P (x) = 0. Since1 QP (x) = ZP (di ) exists potential P (di ) = 0, diQprojection x set Di . Since Q(x) = 0 Q(x) = Z1Q jl jl (cjl ) existssubset Cjl Q(cjl ) = 0, cjl projection x Cjl . Algorithm vip?1convention,updates jl (cjl ) log (di ) = Q(di |cjl ) = |Di \Cjl |0yielding Q (x) = 0, claimed.Now, show additional zeroes introduced Q whenever (P (x) = 0)(Q(x) = 0). Hence, normalizing constant ZQ > 0 therefore revised Q0probability distribution. instances cjl Q(cjl ) > 0 terms Q(ck |cjl ) log (ck )Q(di |cjl ) log (di ) finite long (P (x) = 0) (Q(x) = 0). implies jl (cjl )updated positive value thus, additional zeroes introduced Q.Using given form Q,1 XQ(cj ) =k (ck ) j (cj ).(13)ZQX\Cj k6=jdenote bracketed coefficient j (cj ) Bj (cj ) note constantsense depend quantity j optimized.use Eq. 13 rewrite KL divergence justified Eq. 8 Lemma 2:j (cj )Bj (cj )1 XD(Q || P ) =j (cj )Bj (cj ) log+ log(ZP ) log(ZQ ).(14)ZQj (cj )Bj (cj )CjDue Lemma 3, distance D(Q || Pj (cj )P) changes constant replacing(c)?jjj (cj ) = e, j (cj ) = l jl (cjl ) computed via Eq. 6 vip . Notej (cj ) depend (cj ) function Q(x) conditionaldistribution X \ Cj given Cj (via Q(ck |cj )). Hence, Lemma 1 states minimumD(Q || P ) wrt j achieved j (cj ) proportional j (cj ). potential jheld implicitly partial potentials jl , step 1 vip? updates j (cj ) viaEq. 6 proportional j (cj ) setting potential jl (cjl ) proportionaljl (cjl ). proportionality constant matter j multiplied ,arbitrary constraining constant ZQ also multiplied , influences cancelEq. 14. simplicity, algorithm uses = 1 therefore j (cj ) ej (cj ) . Algorithmvip? implicitly computes j (cj ) according formula hence decreases D(Q || P )iteration improving j (cj ) holding cluster potentials fixed. SinceKL divergence lower bounded zero, vip? converges.13fiGeiger, Meek & Wexlerproperties Q required Theorem 1 self-compatibility compatibility wrtP derived form Q satisfied setting clusters Cj appropriately.addition, condition (P (x) = 0) (Q(x) = 0) trivially satisfied strictly positivedistributions P .Note difference j (cj ) defined Eq. 9 j (cj ) defined Eq. 1constant depend cj . Consequently, convergence proof also appliesWiegerincks algorithm, algorithm special case vip? every clusterCj single subset Cj1 = Cj .5. Handling Deterministic Potentialsdistribution P strictly positive property (P (x) = 0) (Q(x) = 0)must hold convergence proof vip? apply. section provide sufficientcondition Q retain property.Definition: instantiation W = w feasible (wrt distribution P ) P (W = w) > 0.Otherwise, instantiation infeasible.QDefinition: constraining set wrt distribution P (x) = Z1P (di ) sets Diminimal set variables Di infeasible instantiation .QDefinition: distribution Q(x) = Z1Q j j (cj ) clusters Cj containable wrtQdistribution P (x) = Z1P (di ), every constraining set P exists leastone cluster Cj Cj .QQTheorem 2 Let P (x) = Z1P (di ) Q(x) = Z1Q j j (cj ) two distributionsQj (cj ) = l jl (cjl ) Q containable compatible wrt P strictly positive. Then, vip? iterates clusters Cj , revised distribution Q satisfies(P (x) = 0) (Q(x) = 0).Proof: definition constraining set, every infeasible instantiation x,exists infeasible instantiation constraining set projection x. show vip? updates Q(x) = 0 instantiations. Since Q containablewrt P exists cluster Cj contains . Furthermore, since Di Diset P since Q compatible wrt P , exists subset Cjl contains .every instantiation cjl projection Cjl expression jl (cjl ) updatedaccording QEq. 6 vip? . true Q(di |cjl ) > 0 log (di ) = .1Since Q(x) = ZQ j,l jl (cjl ) update implies Q(x) = 0.Whenever first two compatibility conditions Theorem 1 hold, follows vip?converges containable distributions. Note since every iteration vip? decreasesKL divergence, following iterations change Q greater zero instantiationinfeasible wrt P , leads infinite distance. However, containabilityimplies stronger property stated next theorem.14fiA Variational Inference ProcedureQQTheorem 3 Let P (x) = Z1P (di ) Q(x) = Z1Q j j (cj ) two distributionsQj (cj ) = l jl (cjl ) Q containable wrt P (P (x) = 0) (Q(x) = 0). Then,vip? iterates clusters Cj , revised distribution Q satisfies (Q(x) = 0)(P (x) = 0).Proof: Consider instantiation x P (x)> 0. show Eq. 6 vip? upQdates Q(x) positive value. Since Q(x) = Z1Q j,l jl (cjl ), sufficient showrevised potential jl (cjl ) positive subset Cjl instance cjlprojection x Cjl . instances cjl value jl (cjl ) set Eq. 6finite value since (di ) > 0 every instance di projection x set Di ,k (ck ) = 0 implies Q(ck |cjl ) = 0. Therefore, jl (cjl ) = ejl (cjl ) > 0 Q(x) > 0.consequence Theorem 3 Q(x) = 0 iff P (x) = 0. Conditions weakercontainability may sufficient ensure requirement needed convergence, however,containability easily satisfiable applications variational techniques explicatednext section.6. Genetic Linkage Analysis via Variational AlgorithmsGenetic linkage analysis takes input family pedigree individualsaffected genetic disease, affection status members pedigree, marker readingsacross genome, mode inheritance. output likelihood data function location disease gene given pedigree. Locations yielding maximumclose maximum likelihood singled suspect regions scrutiny.exact computation likelihood often complex approximations needed.Algorithm vip? developed facilitate likelihood computations. particular, vip? allows overlapping clusters minimizes loss valuableinformation and, importantly, handle deterministic constraints common models. section, describe standard probabilistic modelgenetic linkage, several approximate distributions use applying vip?genetic linkage model, demonstrate vip? real-world data set large pedigree115 individuals.standard probabilistic model genetic linkage based pedigree contains several variables person location conditional probability tablesvariable Xm given set variables called parents Xm denoted (Xm ).distribution P (x) represents joint distribution variables pedigreewritten using multiple indices; one set indices persons (i), one loci (j),another type variable (t) follows:P (x) =YYji,tP (xi,tj |(xj )) =t{ps,ms,pg,mg,f }1 YYZPjt{ps,ms,pg,mg,f }15i,ti,ti,tj (xj |(xj ))(15)fiGeiger, Meek & Wexlerfive possible types variables are: paternal selector (ps), maternal selector (ms),paternal genotype (pg), maternal genotype (mg) phenotype (f). Thus, set Dji,tequals {Xji,t , (Xji,t )}.denote variables different types, ps, ms, pg, mg f, individuali,mlocus j Sji,p , Sji,m , Gi,pFji respectively. notation possible potentialsj , Gja,pa,mi,pi,mb,pb,mi,mi,pi,pi,mi,mP (Gi,pj , Gj , Gj , Sj ), (Gj , Gj , Gj , Sj ), (Sj , Sj1 ), (Sj , Sj1 )i,m(Fji , Gi,pj , Gj ) b father mother pedigree, respectively.i,pa,pa,mi,msi,mexemplifying sets Dji,pg = {Gi,p= {Sji,m , Sj1}, Dji,f =j , Sj , Gj , Gj }, Dji,m{Fji , Gi,pj , Gj }, father individual pedigree. note firsttwo types potentials possibly last one deterministic potentials equalzero instantiations.directedQ acyclic graph along probability distribution R factors accordingR(Z) = R(zi |(zi )) called Bayesian network. Bayesian network definedEq. 15, describes parents-offspring interaction simple genetic analysis problemtwo siblings parents across 3 loci, given Figure 4. dashed boxescontain variables describe variables single location. exampleassume phenotype variable depends genotype single locus.reflected fact edges single locus point phenotype variable.full semantics variables details regarding conditional probabilitytables found paper Fishelson & Geiger (2002); details neededhere.use several choices cluster Bayesian network P (x) Q selfcompatible compatible wrt P . addition, since potentials P constrained(e.g. i,pgj ), choose clusters Q containable wrt P . According Theorem 2choice ensures Q satisfies conditions necessary convergence vip? ,particular (P (x) = 0) (Q(x) = 0).Consider partition network slots, containing set consecutive loci.simple case every slot single locus subsets Cji containsvariables related one individual genotypes parents slot. set(i)Cji = {Gj , Sji } Cj = {Cji } (i) denotes union parents.illustration setting pedigree two siblings parents threeloci given Figure 5. setting, self-compatibility trivially satisfiedclusters Cj Q disjoint, Q containable wrt P since sets Dji,ps Dji,ms ,potentials constrained, span across single locus. remainsshow compatibility Q wrt P satisfied. sets Dji,t contained single subsetCji trivial Q(Dji,t |cj ) = Q(Dji,t |cji ) = 1. Otherwise, equals ps ms withouti,pi,pi,pi,ploss generality, Q(Sj1, Sji,p |cj ) = Q(Sj1|cj ) = Q(Sj1|cji ) = Q(Sj1, Sji,p |cji ).complex setup, similar Example 1, add cluster CJ+1cuts across loci selector variables individual r, shown Figure 6.(i)subset Cji set Cji = {GjS , Sji , Sjr } clusters Cj = {Cji }, j = 1 . . . J.raddition, set CJ+1 = l {CJ+1,l } subsets CJ+1,l = {Sl,l+1}, singlechosen individual r. verify Q still satisfies conditions Theorem 1. Selfcompatibility maintained since Q(Cj |cJ+1 ) = Q(Cj |cJ+1,j ), Q(CJ+1 |cj ) = Q(CJ+1 |cjr ),16fiA Variational Inference ProcedureFigure 4: Bayesian network representation pedigree two siblings parents3-loci model. circles, squares diamond shapes represent genotype,phenotype selector variables respectively.Q(Ck |cj ) = Q(Ck |cjr ) every two clusters Cj , Ck j, k J. Sets Dji,t6= ms, ps contained cluster Cj thus maintain independence givensubset. = ms, ps sets Dji,t connect two adjacent loci independent CJ+1given CJ+1,j , independent clusters Cj given subset Cji , maintainingcompatibility Q wrt P . Finally, Q containable wrt P since clusters previousoption remain.Immediate extensions clustering schemes allow every slot contain severalconsecutive loci set possibly one individual R cut across loci.maintain compatibility Q wrt P latter extension, subsets CjR set(R)CjR = {Gj , SjR }, (R) denotes union individuals R parents.describe experiments performed using large pedigree 115 individualsspanning across 21 locations, studied Narkis et al. (2004) locate areacontains gene causes fatal neurological disorder (LCCS type 2). First,proximity disease gene markers tested two-point analysis- model-selection method two loci considered simultaneously, onedisease locus. method, loci yield likelihood maxima suggestprobable locations disease locus. Two-point analysis abovementioned pedigreetook several days using exact inference software superlink v1.5 designed geneticlinkage analysis.17fiGeiger, Meek & WexlerFigure 5: schematic division pedigree clusters, locus cluster.cluster C3 variables every individual separate ellipsenumber individual written. two clusters marked areasC14 C23 .log-likelihood probabilities obtained vip? using abovementioned extendedclustering scheme 5 clusters across loci cluster cutting acrossloci, shown Figure 7. figure shows clearly exact approximate loglikelihood curves similar shape almost identical extremum points,major difference absolute value.Next, tested vip? three-point analysis problems pedigree,two markers considered simultaneously along one disease locus. noteexact inference task specified pedigree hard single PC, taking severalweeks. Since exact location disease gene known high probability,wished test whether lower-bounds found vip? indicate location.considered two nearby markers (number 4 6) seven models differlocation speculated disease gene: first two, disease locus positionedleft marker 4 distances 0.01 0.02 centi-Morgan (cM), remaining fivepositioned right marker 4 distances 0.01 0.05 cM 0.01 cM differencelocations. location disease gene 0.01cM right marker 4.algorithm run three times model random initial potentials, takingaccount maximum value obtained. results test plotted Figure 8versus approximation found sampling software simwalk2 introduced Sobel,Papp & Lange (2002) designed approximate pedigree analysis. shown,probabilities found vip? higher approach location disease gene.true probabilities found simwalk2. However, note vip?18fiA Variational Inference Procedureln-likelihoodFigure 6: pedigree partitioned clusters, locus cluster additional cluster C4 , striped area, contains variables one individuals.0-20-40-60-80-100-120-140-160-180-2001 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21ExactlocusVIP* - 5 clusters across lociVIP* - disjoint clustersFigure 7: Approximations log-likelihood two-point analysis using vip? .much slower problem simwalk2, taking several hours run. addition,19fiGeiger, Meek & Wexlernote ln-likelihood probabilities Figures 8(a) (b) drawn differentscales due markedly different output two methods.-182-77-78-186ln-likelihoodln-likelihood-184-188-190-192-194-79-80-81-82-0.02-0.010.010.020.030.040.05-0.02location (relative marker 4)-0.010.010.020.030.040.05location (relative marker 4)(a) using vip?(b) using simwalk2Figure 8: Approximations log-likelihood three-point analysis.compared convergence times vip? Wiegerincks algorithm various sizeproblems genetic linkage analysis. original network performed testincludes 332 variables represents pedigree 28 individuals four loci. createvarious sized problems, subsets original pedigree increasing number individualsconsidered. addition, fair comparison, clusters Wiegerincks algorithmchosen subset subsets used vip? . Since number iterationsconvergence vary significantly two algorithms, report ratioiteration times also tests theoretical speedup predicted Section 3 vip?Wiegerincks algorithm. Figure 9 illustrates ratio time update iterationtwo algorithms, evident ratio increases linearly problem size.ratios indicated averaged 5 runs 10 iterations every problem size.Finally examine convergence vip? Figure 10 using six representativesoriginal 21 two-point analysis runs described earlier, different network.algorithm halted change lower-bound smaller 1053 iterations. Although runs converge rate, seems obeycertain pattern convergence first iterations show significant improvementslower-bound, followed slow convergence local maximum, anothermoderate improvement better maximum point.7. Discussionpaper present efficient algorithm called vip? structured variational approximate inference. algorithm, extends known algorithms, handle overlappingclusters overcome difficulties imposed deterministic constraints. showN N grid-like models, algorithm vip? N fold faster Wiegerincks algorithm,20fiA Variational Inference Procedure2018ratio iteration times161412108642010121416182022242628number individualsFigure 9: Speedup vip? Wiegerincks algorithm.-70-90ln-likelihood-110-130-150-170-190-210-2301357911131517192123iterationFigure 10: Convergence vip? 6 runs two-point analysis.junction tree used. addition, prove convergence vip? previousvariational methods via novel proof method, using properties KL divergence.Finally, algorithm vip? tested Bayesian networks model genetic linkage analysis problems. graphs resemble grid-like models notoriously difficultapproximate due numerous deterministic constraints. results show linearimprovement speed vip? versus Wiegerincks algorithm, approximation21fiGeiger, Meek & Wexlerfollows shape real likelihood probabilities. Nevertheless, Figure 7 shows variational methods Wiegerincks algorithm vip? still appropriate produceaccurate approximation likelihood genetic linkage analysis.Acknowledgmentspaper extension paper originally appeared 10th workshopArtificial Intelligence Statistics (Geiger & Meek 2005). thank D. Heckerman, N.Jojic V. Jojic helpful discussions. also thank two anonymous reviewerscorrecting several errors appeared early version well improvingpresentation. Part work done first author visitor MicrosoftResearch. work supported Israeli Science Foundation Israeli ScienceMinistry.ReferencesBishop, C. & Winn, J. (2003). Structured variational distributions VIBES. ArtificialIntelligence Statistics. Society Artificial Intelligence Statistics.Cooper, G. (1990). Probabilistic inference using belief networks NP-hard. ArtificialIntelligence, 42, 393405.Cover, T. M. & Thomas, J. A. (1991). Elements Information Theory. Wiley.Dagum, P. & Luby, M. (1993). Approximating probabilistic inference Bayesian beliefnetworks NP-hard. Artificial Intelligence, 60 (1), 141153.Dechter, R. (1999). Bucket elimination: unifying framework reasoning. ArtificialIntelligence, 113 (1-2), 4185.Fishelson, M. & Geiger, D. (2002). Exact genetic linkage computations general pedigrees.Bioinformatics, 18, S189S198.Geiger, D. & Meek, C. (2005). Structured variational inference procedures realizations. Proceedings Tenth International Workshop Artificial IntelligenceStatistics, Barbados. Society Artificial Intelligence Statistics.Ghahramani, Z. & Jordan, M. I. (1997). Factorial hidden Markov models. Machine Learning, 29, 245273.Jensen, F. V. (1996). Introduction Bayesian Networks. Springer.Jojic, V., Jojic, N., Meek, C., Geiger, D., Siepel, A., Haussler, D., & Heckerman, D.(2004). Efficient approximations learning phylogenetic HMM models data.Bioinformatics, 20, 161168.Kschischang, F. R., Frey, B. J., & Loeliger, H. A. (2001). Factor graphs sum-productalgorithm. IEEE Transactions information theory, 47 (2), 498519.22fiA Variational Inference ProcedureNarkis, G., Landau, D., Manor, E., Elbedour, K., Tzemach, A., Fishelson, M., Geiger, D.,Ofir, R., Carmi, R., & Birk, O. (2004). Homozygosity mapping lethal congenitalcontractural syndrome type 2 (LCCS2) 6 cM interval chromosome 12q13.American Journal Medical Genetics, 130 (3), 272276.Saul, L. & Jordan, M. I. (1996). Exploiting tractable substructures intractable networks.Advances Neural Information Processing Systems (NIPS). MIT Press.Sobel, E., Papp, J., & Lange, K. (2002). Detection integration genotyping errorsstatistical genetics. American Journal Human Genetics, 70, 496508.Wiegerinck, W. (2000). Variational approximations mean field theory junction tree algorithm. Uncertainty Artificial Intelligence, (pp. 626633). MorganKaufmann.Xing, E. P., Jordan, M. I., & Russell, S. (2003). generalized mean field algorithmvariational inference exponential families. Uncertainty Artificial Intelligence,(pp. 583591). Morgan Kaufmann.Xing, E. P., Jordan, M. I., & Russell, S. (2004). Graph partition strategies generalizedmean field inference. Uncertainty Artificial Intelligence, (pp. 602 610). MorganKaufmann.23fiJournal Artificial Intelligence Research 27 (2006) 551-575Submitted 03/06; published 12/06Causes Ineradicable Spurious Predictions Qualitative Simulationzgr YlmazA. C. Cem SayDepartment Computer EngineeringBoazii UniversityBebek 34342 stanbul, TurkeyYILMOZGU@BOUN.EDU.TRSAY@BOUN.EDU.TRAbstractrecently proved sound complete qualitative simulator exist, is,long input-output vocabulary state-of-the-art QSIM algorithm used,always input models cause simulator coverage guarantee make spuriouspredictions output. paper, examine whether meaningfully expressive restrictionvocabulary possible one build simulator soundnesscompleteness properties. prove several negative results: sound qualitative simulators,employing subsets QSIM representation retain operating region transition feature,support least addition constancy constraints, shown inherently incomplete.Even simulations restricted run single operating region, constraintvocabulary containing addition, constancy, derivative, multiplication relations makesconstruction sound complete qualitative simulators impossible.1. Introductionrecently proved (Say & Akn, 2003) sound complete qualitative simulatorexist, is, long input-output vocabulary state-of-the-art QSIM algorithm(Kuipers, 1994) used, always input models cause simulatorcoverage guarantee make spurious predictions output. paper, examine whethermeaningfully expressive restriction vocabulary possible one buildsimulator always output consistent solutions input model.prove several negative results: sound qualitative simulators, employing subsets QSIMrepresentation retain operating region transition feature, support leastaddition constancy constraints, shown inherently incomplete. problem persistsvariables forced change continuously region transitions slightly largerset constraint types allowed. Even simulations restricted run singleoperating region, constraint vocabulary containing addition, constancy, derivative,multiplication relations makes construction sound complete qualitative simulatorsimpossible. findings may helpful researchers interested constructing qualitativesimulators improved theoretical coverage guarantees using weaker representations.2. Backgroundstart brief overview qualitative simulation, concentrating representations usedinput-output vocabularies qualitative simulators. Subsection 2.2 summarizes previouswork two theoretical properties qualitative simulators interest us. Subsection 2.3short requirements specification hypothetical sound complete qualitative simulator.2006 AI Access Foundation. rights reserved.fiYILMAZ & SAY2.1 Qualitative Simulationmany domains, scientists engineers incomplete amount informationmodel governing dynamic system consideration, renders formulatingexact ordinary differential equation (ODE) impossible. Incompletely specified differentialequations may also appear contexts aim find collective proofs behavioralproperties infinite set systems sharing most, all, structure ODEsdescribing them. proceed reasoning task cases, mathematical tools embodyingmethods making use available information obtain (hopefully small) setpossible solutions matching model needed. Qualitative reasoning (QR) researchersdevelop AI programs use weak representations (like intervals rather point valuesquantities, general shape descriptions rather exact formulae functional relationships)vocabularies perform various reasoning tasks systems incompletespecifications. following, use notation terminology QSIM (Kuipers, 1994),state-of-the art qualitative simulation methodology, although notedincompleteness results proving valid reasoners whose input-outputvocabularies rich enough support representational techniques usedproofs.qualitative simulator takes input qualitative differential equation model systemterms constraints representing relations systems variables. additionmodel, qualitative values variables time point simulationstart also given. algorithm produces list possible future behaviors mayexhibited systems whose ordinary differential equations match input model.variables system modeled QSIM continuously differentiable functions time.limits variable first derivatives exist approach endpointsdomains. variable quantity space; totally ordered collection symbols (landmarks)representing important values take. Zero standard landmark commonvariables. Quantity spaces allowed landmarks - ends, functionalrelationships asymptotic shapes explicitly represented. appropriate, quantityspace declared span proper subset extended reals; instance, makessense bound quantity space variable certainly nonnegative (like pressure)0 left. necessary, user specify one bounds quantity spaceunreachable; example, unreachable value variables modelsdiscussed paper. (reachable) points intervals quantity space make setpossible qualitative magnitudes variable. qualitative direction variable definedsign derivative; therefore possible values are: inc (+), dec () std (0).variables qualitative value pair consisting qualitative magnitude qualitativedirection. collection qualitative values variables makes state system.laws according system operates represented constraints describingtime-independent relations variables. step simulation, QSIM uses settransition rules implicitly generate possible next values variables.combinations values filtered constitute complete states,every constraint still satisfied new values variables, remain.seven basic types constraints QSIM. (See Table 1.) type constraintimposes different kind relation arguments. example, constraintA(t) = B(t), combination variable values variables B(nonzero) sign magnitudes directions filtered out. Sometimes, additionalknowledge constraints allows filtering. example, knowB landmark values a1 b1 moment time past,552fiCAUSES INERADICABLE SPURIOUS PREDICTIONS QUALITATIVE SIMULATIONeliminate value combinations B magnitudes less (or greater)landmarks. a1 b1 called corresponding values constraint,equation a1 = b1 correspondence. constraint model (except derivativetype) correspondence equations. sign algebra (Kuipers, 1994) employedimplement arithmetic relations using qualitative magnitudes. Note that, since + ( )relationship corresponds infinite number possible quantitative functionsmonotonicity property, single QSIM model containing constraints correspondinfinitely many ODEs.CONSTRAINT NAMEaddNOTATIONX(t) + Y(t) = Z(t)constantX(t) = landmarkderivatived/dt(X,Y)M+X(t) = f(Y(t)), f +X(t) = f(Y(t)), fminusmultX(t) = Y(t)X(t) Y(t) = Z(t)EXPLANATIONX(t) = 0dtX(t) = Y(t)dtf X(t) = f(Y(t)), f > 0f domainf X(t) = f(Y(t)), f < 0f domainTable 1: Qualitative Constraint TypesQSIM input vocabulary enables user describe complicated models termsseveral different constraint sets representing different operating regions systemconsideration. user specifies boundaries applicability ranges operatingregions terms conditions indicate simulator effect transitionanother operating region obtained.operating region transition occur, one specifyfollowing possible transition:Boolean expressions composed primitives form VariableName=QualitativeValue,trigger transition satisfied,name target operating region,names variables inherit qualitative magnitudes and/or directionsfirst state transition last state transition,Value assignments variables explicitly specified values first statetransition.provided qualitative system model, name initial operating region,description qualitative values variables initial state, QSIM starts simulation,generates tree system states represent solutions qualitative differentialequation composed constraints input. root tree input initial statetime-point label t0, representing numerical value initial instant. Every path553fiYILMAZ & SAYroot leaf predicted behavior system. qualitative format,behavior usually corresponds infinite set trajectories sharing qualitativestructure phase space. Time-point interval states appear alternately behaviors longoperating region valid. Operating region transitions reflected behaviors twotime-point states following other.2.2 Related Work Soundness Incompletenessimportant property qualitative simulators coverage guarantee: qualitativesimulation algorithm sound guaranteed that, ODE initial state matchessimulators input, behavior output matches ODEs solution.Kuipers (1986) proved exists qualitative simulator (namely, QSIM)soundness property. guarantee makes qualitative simulation valuable design diagnosismethod (Kuipers, 1994): design, set simulation predictions modelcontain catastrophic failure, proof modeled system exhibit failure(Shults & Kuipers, 1997). diagnosis, none behaviors simulation outputmodel exhibited particular system, 100% sure actual systemgoverned model.Another property one would wish ones qualitative simulator possess completeness;is, guarantee every behavior output corresponds solution least oneODE matching input. early days QR research, conjectured (de Kleer & Brown,1984) qualitative simulators employing local constraint satisfaction methods (Weld & deKleer, 1990) complete. However, paper contained guaranteedcoverage theorem, Kuipers (1986) also showed version QSIM described there, and,indeed, qualitative simulators day, incomplete, demonstratingsimulation frictionless mass-spring oscillator predicts unrealizable (spurious) behaviors,amplitude decreases periods increases others. lack guaranteepredicted behaviors real negative impact potential applications: design,set simulation predictions model contain catastrophic failure,necessarily point error mechanism; maybe prediction questionspurious behavior. similar problem occurs diagnosis applications.Several types spurious qualitative simulation predictions discoveredfollowing years: Struss (1990) pointed that, whenever variable appearedarithmetic constraint, spurious states could pass filter. instance, filters addconstraint unable delete states involving nonzero values variable Z equationA(t) + Z(t) = A(t) nonzero. Clearly, sound complete qualitative simulatorwould possess algebraic manipulation capabilities enable us conclude Z = 0case. Say Kuru (1993) discovered class spurious predictions caused rigidityinternal representation correspondences, unnecessarily weak implementationsubtraction. Say (1998) showed spurious behaviors due lack explicitenforcement lHpitals rule original algorithm. Yet another family inconsistentpredictions found caused weaknesses methods used distinguish finiteinfinite time intervals behaviors (Say, 2001, also see Missier, 1991). Knik Say(2003) proved model behavior descriptions could encode informationrelative (finite) lengths intervals contain, failure check overallconsistency pieces information yields another class spurious predictions. Finally,Say (2003) showed similar encoding could occur exact numerical valueslandmarks, sound complete qualitative simulator would support capability554fiCAUSES INERADICABLE SPURIOUS PREDICTIONS QUALITATIVE SIMULATIONcomparing magnitudes two elements rich subset real numbersavoid particular set spurious predictions.Interestingly, discoveries actually good news users qualitativesimulators: order able say particular predicted behavior spurious, thereforesuitable elimination simulator output without forsaking soundness property, onefirst proves behavior mathematically inconsistent simulated modelstarting state. instance, aforementioned spurious oscillations frictionless massspring system shown violate conservation constraint follows directlystructure input equations. proof seen specification newfilter routine would eliminate exactly set behaviors violate lawestablishes. kinetic energy constraint (Fouch & Kuipers, 1992) filterdeveloped fashion eliminate class spurious predictions exemplified onesmass-spring system (Kuipers 1994). spurious prediction classes mentionedprevious paragraph had, fact, discovered simultaneously cures.question whether exists sound complete qualitative simulator finallysettled Say Akn (2003). proved that, sound qualitative simulator usinginput-output representation task specification QSIM methodology, exist inputmodels initial states whose simulation output contain spurious predictions. (Notesay present QSIM algorithm augmented filters makesound complete; refutes existence program whatsoever performjob.)proof Say Akn (2003) shows sound complete qualitative simulatoremploying vocabulary mentioned above, existed, could used solve giveninstance Hilberts Tenth Problem, famously undecidable (Matiyasevich, 1993).procedure involves building QSIM model representing given problem, simulating severaltimes starting carefully constructed initial states representing candidate solutions,examining output read solution. model set contain inconsistencyanswer considered problem no, existence onebehaviors output means yes. Since impossible make decision correctlygeneral case, follows would input models giving rise behavior predictionswhose consistency status determined simulator, whose best course actionwould include output, keep soundness guarantee intact. casescorrect answer no, would result prediction spurious behaviors. Noteineradicable spurious predictions, unlike ones discussed earlier.important note proof necessarily mean hope constructingsound complete qualitative simulator lost. One may try weaken input-outputrepresentation longer possesses problematic power enables oneunambiguously encode instances Hilberts Tenth Problem QSIM model. (Of course,weakening must kept minimum possible level resulting program usefulreasoner; instance, removing programs ability distinguish negativenonnegative numbers would possibly yield sound complete simulator, outputprogram would state everything possible wantmethods.) one examine incompleteness proof (Say & Akn, 2003) seeexactly features QSIM representation used construction reduction;future qualitative simulator supporting vocabulary subset would incorporatingproblem start.listing QSIM representational items used proof: M+,derivative, mult, constant constraint types utilized. (Note absence addconstraint, implemented using others, list.) Qualitative interval555fiYILMAZ & SAYmagnitudes like (0, ), one might call infinite uncertainty actual valuerepresented number, used initializing several variables, form essential partargument. QSIMs ability explicitly represent infinite limits utilized equatinglandmark number , stating twice limit function arctan x x nearsinfinity. Finally, operating region transition feature used heavily, since thankscharacteristic sine function two dependent variables representedqualitative vocabulary.Section 3, examine several different ways weakening QSIM vocabulary tryunderstand combinations features responsible problem ineradicablespurious predictions.2.3 Desiderata Sound Complete Qualitative Simulatorimportant point clarify exactly one would expect hypothetical soundcomplete qualitative simulator. input model yields finite behavior tree genuinesolutions, obvious program supposed print descriptions behaviorsforming branches tree, nothing else, finite time. input model initialstate inconsistent, i.e., correct output empty tree, program reportinconsistency finite time.Finally, input yields behavior tree infinitely many branches, programsupposed run forever, adding new state output every while. formally,every positive i, integer program printed firststates behavior tree (according ordering root, i.e. initial state,state number 1, descendants particular state printed state itself)end sth step execution. Note requirements mean soundcomplete simulator would able decide whether initial system state descriptiongiven consistent input model within finite time. necessity usedproofs incompleteness Section 3.3. New Incompleteness Results Qualitative Simulatorssection, examine two different ways restricting qualitative vocabularyhope obtaining representation allows construction sound completesimulators. Subsection 3.1 considers usage several reduced sets qualitative constrainttypes, retaining operating region transition feature. also examine possiblerestriction way variable values handled operating region transitions. Subsection3.2 investigation capabilities qualitative simulators restricted inputmodels single operating region. variants shown exhibit problemineradicable spurious predictions soundness guarantee present.3.1 Reduced Constraint Setsresults subsection based undecidability properties abstract computationaldevices called unlimited register machines (URMs). first present brief introductionURMs, proceed proofs.556fiCAUSES INERADICABLE SPURIOUS PREDICTIONS QUALITATIVE SIMULATION3.1.1 UNLIMITED REGISTER MACHINESeasiest way thinking URM see computer infinite memorysupports particularly simple programming language. URM (Cutland, 1980) program Pconsists finite sequence instructions I1, I2, ..., I|P|. instructions refer machinesregisters Ri, store arbitrarily big natural number. use notation r1, r2,r3, ... register contents.purposes, sufficient consider three types URM instructions:succ(n): Increment content register n one.Rn rn + 1zero(n): Set content register n zero.Rn 0jump(m, n, q): Compare registers n. equal, continue instruction q.rm = rn jump IqURM program starts execution first instruction. current instructionjump whose equality condition satisfied, followed next instruction list.program ends attempts continue beyond last instruction, jump nonexistentaddress attempted. assume without loss generality jumps address I|P|+1.P = I1, ..., I|P| URM program, computes function P(k) : Nk N. P(k)(a1, ..., ak)computed follows:- Initialization: Store a1, ..., ak registers R1, ..., Rk, respectively, set registersreferenced program 0.- Iteration: Starting I1, execute instructions order described above.- Output: program ends, computed value function number r1contained register R1. program never stops, P(k)(a1, ..., ak) undefined.Table 2 contains example URM program computes function f(x, y) = x + y. Notefunction N2 N, input values x stored registers R1 R2,output function expected stored R1 end program.I1:zero(3)I2:jump(2, 3, 6)I3:succ(1)I4:succ(3)I5:jump(1, 1, 2)Table 2: URM Program Computing f(x, y) = x +program first sets R3 zero. checks see R2 = R3 (in case = 0).Otherwise, increments R1 R3. continues x incremented times,value R1 returned.URM model computation equivalent numerous alternative modelsTuring machine model, Gdel-Kleene partial recursive functions model Churchs lambda557fiYILMAZ & SAYcalculus, (Cutland, 1980; Shepherdson & Sturgis, 1963) sense set functionscomputable URMs identical set functions computedmodels. means device simulate given URM powerfulTuring machine, since simulate given Turing machine. proofsincompleteness QSIM vocabulary reduced constraint sets, make usefact halting problem URMs undecidable (Cutland, 1980).3.1.2 SOUND COMPLETE QSIM REDUCED CONSTRAINT SETS SOLVES HALTINGPROBLEMincompleteness results new subsets QSIM vocabulary presentedsubsection based following theorem, shows QSIM simulateURM, thereby Turing-equivalent computational power.Theorem 1: execution URM program P |P| instructions given inputrepresented simulation QSIM model |P|+2 operating regions.Proof: proof construction. Suppose given URM program Pinstructions I1, ..., I|P|. Let R1, ..., RN registers mentioned instructions P.Ri, define QSIM variable NRi represent it, and, case Rinonzero initial value ai, set auxiliary QSIM variables representing ai. Table 3 describesidea behind representation. four variables named U, W, Z, B. Urepresents clock rises 0 1 every computational step. W derivative U.Z constant zero every operating region. B additional auxiliary variable.CONSTRAINTSINITIAL VALUESCONCLUSIONSONE(t) ONE(t) = ONE(t)ONE(t) + ONE(t) = TWO(t)ONE(t) + TWO(t) = THREE(t)ONE(t0) = one (0, )ONE constant 1TWO constant 2THREE constant 3Table 3: QSIM Model Fragment Demonstrating Representability Exact Integer ValuesQSIM model |P|+2 operating regions: instruction Ii Pcorresponding operating region named OpRegi. two remaining regions OpReg0,corresponding initialization stage P, OpReg|P|+1, corresponding end.specification operating region must contain constraints validregion, Boolean conditions (if any) composed primitives formVariable = <qualitative magnitude, qualitative direction> would trigger transitionsoperating regions obtained, lists detail variables inheritprevious magnitudes and/or directions transition, initializednew values switch. Tables 4-9 describe prepare items operatingregions target model, based program P. five different operating regiontemplates (or types) used construction; one URM instruction type, oneOpReg0, one OpReg|P|+1.model OpReg0 depicted Table 4. simulation P start.NRi variables equated proper initial values specified user P: onesinitialized zero handled constant 0 constraints. ones positive initial values558fiCAUSES INERADICABLE SPURIOUS PREDICTIONS QUALITATIVE SIMULATIONspecified constant values using add constraints link numbervariables exemplified Table 3; instance, NR2 initialized three,constraint THREE(t) + Z(t) = NR2(t). add constraint B, U, ONE serves expressfact landmark named one Us quantity space also equal 1. (Noteadd constraints mentioned paragraph exist OpReg0, since would disruptintended behavior operating regions.)seen Tables 4-8, exactly variables keep values transition dependstype target operating region. Regions corresponding instructions type zero(n)inherit value Rn predecessors, since involve replacementvalue zero anyway. types regions, including succ(n) type, inheritregister contents predecessors. (Although value Rn change succinstruction, new value depends old one, unlike case zero(n). correspondingQSIM variable NRn increases continuously simulation region type succ(n),new region transition occurs exactly moment increased one unit.)Operating Region: OpReg0{Type: Initialization}Constraint Set: d/dt(U, W)B(t) + U(t) = ONE(t) correspondence 0 + one = onerequired number representation constraints (see Table 3)add constraints linking NRi relevant number variables (see text)variables except U B constant.Possible Transition:Trigger: ( U = <one, inc> )New operating region: OpReg1Variables inheriting magnitudes directions: See Table 5, indexed type OpReg1Variables new asserted values: U <0, inc>Table 4: Model Operating Region OpReg0, Corresponding Initialization URMTYPE TARGETREGIONjump(m, n, q)VARIABLES INHERITINGQUALITATIVE MAGNITUDESvariables except U BVARIABLES INHERITINGQUALITATIVE DIRECTIONSvariables except U, B, NRisucc(n)variables except U Bvariables except U, B, NRizero(n)variables except U NRnvariables except U, B, NRiEndvariables except Uvariables except U NRiTable 5: Variables Inherit Magnitudes and/or Directions According TypeTarget Operating Region559fiYILMAZ & SAYsimulation given URM program proceeds follows: described previoussubsection, URM starts initial configuration, registers R1, ..., Rk storenonnegative integers a1, ..., ak, form input program, respectively. Nkregisters set 0. Correspondingly, NRi variables QSIM modelquantity space [0, ). NRi variables nonzero initial values start simulationqualitative values <(0, ), std>, whereas ones start <0, std>. quantity spacevariable U [0, one], landmark one equated 1, mentioned above. U startsinitially qualitative value <0, inc>. derivative U, W, quantity space [0, speed, ),speed also equated 1. starts qualitative value <speed, std> constantwhole simulation. variable B quantity space (-, 0, ) starts <(0, ), dec>.started OpReg0, QSIM compute single qualitative behavior segment, endstransition OpReg1 U reaches <one, inc> time-point t1.Operating Region: OpRegi{Type: zero(n)}Constraint Set: d/dt(U, W)NRn(t) = 0variables except U constant.Possible Transition:Trigger: ( U = <one, inc> )New operating region: OpRegi+1Variables inheriting magnitudes directions: See Table 5, indexed type OpRegi+1Variables new asserted values: U <0, inc>Table 6: Model Template Operating Regions Corresponding zero(n) InstructionsOperating Region: OpRegi{Type: succ(n)}Constraint Set: d/dt(U, W)B(t) + U(t) = NRn(t)variables except U NRn constant.Possible Transition:Trigger: ( U = <one, inc> )New operating region: OpRegi+1Variables inheriting magnitudes directions: See Table 5, indexed type OpRegi+1Variables new asserted values: U <0, inc>Table 7: Model Template Operating Regions Corresponding succ(n) Instructions560fiCAUSES INERADICABLE SPURIOUS PREDICTIONS QUALITATIVE SIMULATIONNote zero uncertainty values variables, even ones initialmagnitude (0, ), start simulation.model constrained sound complete qualitative simulator guaranteedproduce exactly one behavior prediction initial state corresponding valid URM input.see this, sufficient observe that, step simulation, sufficientinformation available simulator compute exact numerical value every variablemodel. (This corresponds tracing URM program keeping note registercontents step.) modeled URM halts particular input given initialstate, QSIM behavior supposed finite one, ending variable U attemptsexceed one OpReg|P|+1. URM computation halt, QSIM behaviorsupposed single infinite sequence states, never visits OpReg|P|+1.Operating Region: OpRegi{Type: jump(m, n, q)}Constraint Set: d/dt(U, W)NRm(t) + B(t) = NRn(t)variables except U constant.Possible Transition:Trigger: ( U = <one, inc> ) ( B <0, std> )New operating region: OpRegi+1Variables inheriting magnitudes directions: See Table 5, indexed type OpRegi+1Variables new asserted values: U <0, inc>Possible Transition:Trigger: ( U = <one, inc> ) ( B = <0, std> )New operating region: OpRegqVariables inheriting magnitudes directions: See Table 5, indexed type OpRegqVariables new asserted values: U <0, inc>Table 8: Model Template Operating Regions Corresponding jump(m, n, q) InstructionsOperating Region: OpReg|P|+1{Type: End}Constraint Set: d/dt(U, W)variables except U constant.Table 9: Model Operating Region OpReg|P|+1, Corresponding End URMProgramready state new version incompleteness theorem.561fiYILMAZ & SAYTheorem 2: Even qualitative representation narrowed derivative, add,mult, constant constraints used QDEs, variable forced start finitevalue zero uncertainty initial state, still impossible build sound completequalitative simulator based input-output vocabulary.Proof: Assume sound complete simulator exists. show solvehalting problem URMs using algorithm subroutine.Construct corresponding QSIM model described Theorem 1 URM program Pwhose halting status particular input supposed decided. define new variablequantity space [0, one, ), landmark one equated number 1. startsvalue <one, std> initial state. Add constraints indicating constantoperating regions, specify value inherited possible transitions. Insertnew constraint S(t) = 0 OpReg|P|+1. Consider simulator supposedchecking initial state consistency. Note would inconsistencysimulation ever enters OpReg|P|+1, since new constraint inserted region sayszero, would contradict inherited value one. simulatorsupposed make spurious predictions expected reject initial state time t0inconsistent simulation going enter OpReg|P|+1, words, URM programconsideration going halt. sound complete simulator rejectinitial state due inconsistency, goes simulation, concludeprogram P halt. forms decision procedure halting problem. Sincehalting problem undecidable, obtained contradiction, conclude soundcomplete simulator using representation exist.fact possible remove derivative constraint (which used proofensure behavior tree one branch) representation well,incompleteness result shown would still stand:Theorem 3: Even qualitative representation narrowed add, mult,constant constraints used QDEs, variable forced start finite valuezero uncertainty initial state, still impossible build sound completequalitative simulator based input-output vocabulary.Proof: make minor modification proof Theorem 2. observeconstruction Theorem 1, U always starts every operating region <0, inc> factderivative positive constant forces reach value <one, inc> next time point.transition next operating region occurs, U receives value <0, inc>.happens remove variable W derivative constraints model? case,since Us derivative fixed, three possible states U second time pointsimulation operating region: <one, inc>, <one, std>, <(0, one), std>. fixproblem inserting another possible region transition specification regions,except OpReg|P|+1. transition triggered U one values <one, std>,<(0, one), std>, target OpReg|P|+1. variable proof Theorem 2,well variables, inherited completely transition. unwantedbehaviors would created due elimination Us derivative end OpReg|P|+1,therefore eliminated spurious accordance argument previousproof. Hence, again, simulator supposed accept initial state consistentP halt, meaning sound complete simulation impossiblerepresentation well.562fiCAUSES INERADICABLE SPURIOUS PREDICTIONS QUALITATIVE SIMULATIONInterestingly, one even restrict representation nonnegative numberssupported, incompleteness result proved still stands:Theorem 4: Even qualitative representation narrowed add, mult,constant constraints used QDEs, variable forced start finite valuezero uncertainty initial state, variable allowed negative value timesimulation, still impossible build sound complete qualitative simulatorbased input-output vocabulary.Proof: previous proof, variable B ever possibility negative value,occur jump region. replace definition jump region templateTable 10, introduce new variables C Y. insert constraints sayvariables constant operating regions. C start zero, inheritedtransitions, except target region type jump. seen Table 10, B getsvalue 1 two compared register values equal. unequal, Bpositive value different 1. setup, Bs quantity space defined [0, one, ),one equated 1, variable ever negative value simulation. B startssimulation value <one, dec> satisfy add constraint seen Table 4. restargument identical Theorem 3.Operating Region: OpRegi{Type: jump(m, n, q)}Constraint Set: NRm(t) + ONE(t) = C(t)NRn(t) + ONE(t) = Y(t)B(t) C(t) = Y(t)variables except U constant.Possible Transition:Trigger: ( U = <one, inc> ) ( B <one, std> )New operating region: OpRegi+1Variables inheriting magnitudes directions: Depends type OpRegi+1,Variables new asserted values: U <0, inc>Possible Transition:Trigger: ( U = <one, inc> ) ( B = <one, std> )New operating region: OpRegqVariables inheriting magnitudes directions: Depends type OpRegq,Variables new asserted values: U <0, inc>Table 10: Alternative Model Template Operating Regions Corresponding jump(m, n, q)Instructions Avoids Negative NumbersAlternatively, keep negative numbers remove mult constraintrepresentation, drop requirement variable starts simulation value zerouncertainty.563fiYILMAZ & SAYTheorem 5: Even qualitative representation narrowed add constantconstraints used QDEs, still impossible build sound complete qualitativesimulator based input-output vocabulary.Proof: used mult constraint proofs Theorems 1-3 equating variablelandmark values unambiguous integers. Assume delete mult constraintsmodel Theorem 3. number variables Table 3 replaced setup shownTable 11. Ri supposed initialized positive integer ai P, equate NRiaiunit variable OpReg0 using method explained proof Theorem 1. Noteuse constant add constraints (and lot auxiliary variables) purpose.CONSTRAINTSONEUNIT(t) = unitONEUNIT(t) + ONEUNIT(t) = TWOUNITS(t)ONEUNIT(t) + TWOUNITS(t) = THREEUNITS(t)CONCLUSIONSTWOUNITS constant 2unitTHREEUNITS constant 3unitTable 11: Sample Model Fragment Equating Variables Integer Multiples PositiveLandmark unitlandmarks previously named one variables quantity spaces equatedunit. new model, execution succ(n) instruction increments NRns value one unit.jump instruction compares landmarks whose values equal uunit vunit insteadcomparing two landmarks whose values equal natural numbers u v. zero instructionsets target register 0, previous construction. modeled machineoriginal URM does, since multiplication values coefficient unitchange flow program, and, particular, whether halts input not. restargument identical proof Theorem 3.observe variables change qualitative magnitudes directionsdiscontinuously operating region transitions proofs previous theorems.next theorem proves maintaining soundness completeness simultaneously impossibleeven allow qualitative variable perform change, forcevariables magnitude direction inherited next operating region.Theorem 6: Even qualitative representation narrowed derivative, addconstant constraints used QDEs, variables magnitude direction allowedperform discontinuous changes operating region transitions, still impossible buildsound complete qualitative simulator based input-output vocabulary.Proof: again, make changes QSIM models used simulating givenURM previous theorems. always, QSIM variable NRi Nregisters Ri appearing URM program. addition that, define variables Diji, j {1, ...,N} j. satisfies equation Dij = NRi NRj throughoutsimulation; is, keep track differences pairs register values. clearlyachieved inserting several add constraints operating regions model.difference variables enable us compare two register values operating regions typejump.564fiCAUSES INERADICABLE SPURIOUS PREDICTIONS QUALITATIVE SIMULATIONFurthermore, define auxiliary variables TRi {1, ..., N}. TRi initializedvalues corresponding NRi, using technique NRi.instruction type given URM program, define two operating regions.clock variable U increase first operating regions value <unit, std>,decrease next one <unit, std> <0, std>, performing discontinuous jumpprogram. order obtain variable behavior, make use simple harmonicoscillator model given Table 12, variable X (denoting displacementrest position oscillating object) oscillates values unit/2 unit/2,variable U equated X + unit/2, oscillating 0 unit. model template givenTable 12 added every operating region. (That table contains variable names usedconstructions previous proofs. variables treated previously describedmanner, unless proof specifies otherwise.) following lemma establishes correctnessconstruction.CONSTRAINTSCORRESPONDENCESMEANINGHALFUNIT(t) + HALFUNIT(t) = ONEUNIT(t)c1 + c1 = unitc1 = unit / 2HALFUNIT(t) + V(t) = E(t)c1 + v1 = 0v1 = unit / 2d/dt(X, V)dX=Vdtd/dt(V, A)d2X=AdtX(t) + A(t) = Z(t)d2X+ X =0dtX(t) + HALFUNIT(t) = U(t)U = X+unit/2Table 12: Model Template Obtain Desired Behavior Variable U ClockOscillating Qualitative Values <0, std> <unit, std> (This Template InsertedConstructed Operating Regions.)Lemma 7: number r represented QSIM landmark, QSIM variable Xequated function r sin(t t0) using derivative, add constant constraints.Proof Lemma 7:seen Table 12, equationd2X (t ) + X (t ) = 0dtexpressed using derivative, add constant constraints. equation generalsolution formX (t ) = c1 sin + c2 cos ,565(1)fiYILMAZ & SAYhence time derivative V formV (t ) = c1 cos c2 sin .Assume X V initialized follows:X (t0 ) = 0V (t0 ) = r .substituting values equations above, one obtains equation system0 = c1 sin t0 + c2 cos t0r = c1 cos t0 c2 sin t0 ,whose solution (Ylmaz, 2005) yields c1 = r cos t0 c2 = r sin t0. Substituting c1 c2Equation (1), get X (t ) = r (cos 0 sin sin 0 cos ) = r sin (t 0 ) , thereby provinglemma.Proof Theorem 6 (continued):Therefore, equate landmark v1 V unit/2 shown Table 12, initialize XV 0 v1, respectively, ensureX (t ) =unitsin(t t0 ) ,2i.e., variable X oscillates values unit/2 unit/2, desired.consistent Lemma 7, oscillating variables Table 12 start simulationqualitative values listed Table 13. variables, except B, starts value<(0, ), inc>, initialized previously described.VARIABLEQUANTITY SPACEINITIAL VALUEU[0, unit]<(0, unit), dec>E(-, 0, )<0, std>X(-, 0, )<0, dec>V(-, v1, 0, )<v1, std>(-, 0, )<0, inc>Table 13: Quantity Spaces Initial Values Oscillating Variablesgoing denote two operating regions corresponding ith instructionURM program OpRegi,1 OpRegi,2. variables qualitative values inheritedpossible transitions, variable ever undergoes discontinuous change. Lookingcarefully Tables 14-21, correspond initialization, instruction types, endingURM, see simulation flows unique branch exception zero type566fiCAUSES INERADICABLE SPURIOUS PREDICTIONS QUALITATIVE SIMULATIONoperating regions, possibility simulation branches onebehavior, behaviors correspond expected trajectory actualURM directed OpReg|P|+1,1. (Note transitions infinite landmarks needconsidered, since assume infinite landmarks specified unreachable valuesvariables models.) registers stay constant OpReg|P|+1,1, single operatingregion corresponding end URM program, reached. rest proofTheorem 2. contradiction variable ensures behavior nonhalting URM leads consistent initial state, hence determining consistency initialstate equivalent deciding halting problem, leading contradiction.Operating Region: OpReg0{Type: Initialization}Constraint Set: required input value representation constraints (see Table 11)B(t) + U(t) = ONEUNIT(t) correspondence 0 + unit = unitadd constraints linking NRi TRi relevant nunit variablesadd constraints defining Dij variablesclock constraints (Table 12)variables except B, U, X, V, E, constant.Possible Transition:Trigger: ( U = <0, std> )New operating region: OpReg1,1Variables inheriting qualitative values: variablesTable 14: Template Single Operating Region Corresponding Initialization Stage3.2 Simulation within Single Operating Regionincompleteness proofs subsection 3.1 (as well Say & Akn, 2003) dependcapability turning constraints necessary, providedoperating region transition feature. Would problem persist forsook feature,focused simulation qualitative models single operating region? showanswer question affirmative.3.2.1 HILBERTS TENTH PROBLEMname suggests, Hilberts Tenth Problem tenth 23 problemsannounced 1900 famous mathematician David Hilbert challengemathematicians 20th century. asks algorithm deciding whether givenmultivariate polynomial integer coefficients integer solutions. provenalgorithm exists (Matiyasevich, 1993). fact used Say Akn (2003)original proof existence ineradicable spurious predictions outputs qualitativesimulators employing operating region transition feature larger set constraint typesdeal paper.567fiYILMAZ & SAYproof presented shortly, use undecidability slightly modified variantsetup described Hilbert: assume guarantee none variables givenpolynomial zero solution whose existence question. clear modifiedproblem unsolvable well, following argument: Assume algorithmtakes multivariate polynomial integer coefficients input, announceswhether solution variables nonzero integer values exists finite time.use subroutine construction algorithm sought Hilberts originalproblem follows: systematically produce 2n polynomials input polynomial nvariables, new polynomials corresponds different subsetvariables original polynomial replaced zero. run newpolynomials. easy see find one polynomials nonzerointeger solutions original polynomial integer solutions.Operating Region: OpRegi,1{Type: zero(n)}Constraint Set: add constraints defining Dij variablesclock constraints (Table 12)variables except U, X, V, E, A, NRn, Dij n {i,j} constant.Possible Transition:Trigger: ( U = <unit, std> ) ( NRn = <0, std> )New operating region: OpRegi,2Variables inheriting qualitative values: variablesPossible Transition:Trigger: (( U = <unit, std> ) ( NRn <0, std> )) ( NRn = <(0, ), std> ) ( NRn = <(-, 0), std> )New operating region: OpReg|P|+1, 1Variables inheriting qualitative values: variablesTable 15: Template First Operating Region Corresponding zero(n) Instructions3.2.2 SOUND COMPLETE QSIM WITHIN SINGLE OPERATING REGION SOLVES HILBERTSTENTH PROBLEMTheorem 8: Even qualitative representation narrowed derivative, add,mult constant constraints used QDEs, simulation proceeds singleoperating region, still impossible build sound complete qualitative simulator basedinput-output vocabulary.going start proof preliminary lemmata, firstreminiscent Lemma 7 previous subsection:Lemma 9: real constant equated QSIM variable Xi, QSIM variable Yiequated function sin ( X (t t0 )) using derivative, add, mult, constant constraints.Proof: case Xi = 0 trivial, handled single constant constraint.remaining case, consider following equation set:568fiCAUSES INERADICABLE SPURIOUS PREDICTIONS QUALITATIVE SIMULATIONOperating Region: OpRegi,2{Type: zero(n)}Constraint Set: add constraints defining Dij variablesclock constraints (Table 12)variables except U, X, V, E, A, TRn constant.Possible Transition:Trigger: ( U = <0, std> ) ( TRn = <0, std> )New operating region: OpRegi+1,1Variables inheriting qualitative values: variablesPossible Transition:Trigger: (( U = <0, std> ) ( TRn <0, std> ) ) ( TRn = <(0, ), std> ) ( TRn = <(-, 0), std> )New operating region: OpReg|P|+1, 1Variables inheriting qualitative values: variablesTable 16: Template Second Operating Region Corresponding zero(n) InstructionsOperating Region: OpRegi,1{Type: succ(n)}Constraint Set: TRn(t)+ U(t)= NRn(t)add constraints defining Dij variablesclock constraints (Table 12)variables except U, X, V, E, A, NRn, Dij n {i,j} constant.Possible Transition:Trigger: ( U = <unit, std> )New operating region: OpRegi,2Variables inheriting qualitative values: variablesTable 17: Template First Operating Region Corresponding succ(n) Instructionsd2Yi (t ) + Wi Yi (t ) = 0dtXi > 0X ,Wi = X i2 , Wi =X , X < 0.initial valuesYi (t0 ) = 0569(2)(3)fiYILMAZ & SAYOperating Region: OpRegi,2{Type: succ(n)}Constraint Set: TRn(t)+ U(t)= NRn(t)add constraints defining Dij variablesclock constraints (Table 12)variables except U, X, V, E, A, TRn constant.Possible Transition:Trigger: ( U = <0, std> )New operating region: OpRegi+1,1Variables inheriting qualitative values: variablesTable 18: Template Second Operating Region Corresponding succ(n) InstructionsOperating Region: OpRegi,1{Type: jump(m, n, q)}Constraint Set: add constraints defining Dij variablesclock constraints (Table 12)variables except U, X, V, E, constant.Possible Transition:Trigger: ( U = <unit, std> )New operating region: OpRegi,2Variables inheriting qualitative values: variablesTable 19: Template First Operating Region Corresponding jump(m, n, q) InstructionsVi (t0 ) = X ,Vi(t) time derivative Yi(t).general solution Equation (2) is:()()Yi (t ) = c1 sin Wi + c2 cos Wi .Substituting Wi Equation (3) initial values equations Yi Vi,solving equation systems results following (Ylmaz, 2005):Xi > 0, c1 = cos(Xit0) c2 = sin(Xit0).Xi < 0, c1 = cos(Xit0) c2 = sin(Xit0).substitute formula Yi(t), obtain:Yi (t ) = cos( X t0 )sin ( X ) sin ( X t0 ) cos( X ) = sin ( X (t t0 )) ,570Xi > 0,fiCAUSES INERADICABLE SPURIOUS PREDICTIONS QUALITATIVE SIMULATIONOperating Region: OpRegi,2{Type: jump(m, n, q)}Constraint Set: add constraints defining Dij variablesclock constraints (Table 12)variables except U, X, V, E, constant.Possible Transition:Trigger: ( Dmn = <0, std> ) ( U = <0, std> )New operating region: OpRegq,1Variables inheriting qualitative values: variablesPossible Transition:Trigger: ( Dmn <0, std> ) ( U = <0, std> )New operating region: OpRegi+1,1Variables inheriting qualitative values: variablesTable 20: Template Second Operating Region Corresponding jump(m, n, q) InstructionsOperating Region: OpReg|P|+1, 1{Type: End}Constraint Set: S(t) = 0variables except U, X, V, E, constant.Table 21: Model Operating Region Corresponding End URM ProgramYi (t ) = cos( X t0 )sin (( X ) ) sin ( X t0 ) cos(( X ) ) = sin ( X (t t0 )) ,Xi < 0.Hence, Yi(t) = sin ( X (t t0 )) Xi 0.Table 22 shows Equations (2) (3) initial values given representableusing derivative, add, mult, constant constraints. Note Xi kept constantinitialized either (0, ) (, 0), depending intended sign number, YiCi must start zero, consistent construction above.Lemma 10: Starting t0, function = sin(tt0) reaches value 0 first time timepoint tE = t0 + . Moreover function Yi = sin(Xi(tt0)) reaches 0 time point tEXi integer.Proof: equation sin(tt0) = 0 implies tt0 = n, n , since interested firsttime point t0 becomes 0, get tE = t0 + . part secondstatement, assume function Yi = sin(Xi(tt0)) reaches 0 tE = t0 + .sin ( X (t 0 + 0 )) = sin ( X ) = 0 implies Xi integer. part, useknowledge Xi integer conclude Yi(tE) = sin(Xi(t0 + t0)) = sin(Xi) = 0.571fiYILMAZ & SAYCONSTRAINTSMEANINGZ=0Xi(t) + Ci(t) = Vi(t)Vi(t0) = Xid/dt(Yi, Vi)dYi= Vi (t )dtd/dt(Vi, Ai)2Yi= Ai (t )dtXi(t) Xi(t) = Wi(t)Wi = X i2Wi(t) Yi(t) = Li(t)Li (t ) = Wi Yi (t )Ai(t) + Li(t) = Z(t)2Yi+ Wi Yi (t ) = 0dtTable 22: Model Fragment Used Obtain Relationship Yi = sin ( X (t t0 ))Proof Theorem 8: already mentioned, proof relies contradiction, namelysound complete simulator, existed, could used construct algorithm solvingHilberts Tenth Problem, follows:Assume given polynomial P(x1, x2, x3, ..., xn) integer coefficients. startconstructing QSIM model fragment says P(x1, x2, x3, ..., xn) = 0: alreadyseen Section 3.1 equate desired integer QSIM variable. Represent integersappearing coefficients polynomial manner. Introduce QSIM variable Xixi, declare Xi constant, use add mult constraints equate sumproducts P(X1, X2, X3, ..., Xn) QSIM variable P, initialized 0. Notetantamount saying present values Xi form solution polynomial.clearly done single operating region, constraints types mult, addconstant.extend model necessary constraints auxiliary variables equatenew variable function sin(tt0). (Either Lemma 7 Lemma 9 usedpurpose.) specify Ys quantity space [0, ), simulation guaranteed finish= tE = t0 + . Xi, define associated auxiliary variables Ci, Li, Wi, Vi, Ai Yi,add template Table 22 model express relationship Yi = sin(Xi(tt0)). alsoequate variable YS sum squares Yi, i.e. YS =n2. Note YS = 0,=1Yi 0.Finally, need make sure consistent behaviors ones Xiintegers (that is, relying Lemma 10, behaviors variable YS becomes 0 tE).serve aim, add constraint F(t) Y(t) = YS(t) model.simulate model 2n times, run corresponding different way initializingXi magnitudes selected set {(0, ), (, 0)}. sound complete simulator572fiCAUSES INERADICABLE SPURIOUS PREDICTIONS QUALITATIVE SIMULATIONwould accept initial states Xi whose values causeinconsistency model. Xi correspond exactly integer solutionsgiven polynomial, following reasoning variable F:Note F defined YS/Y F(t) Y(t) = YS(t) constraint. know Y, Yi,hence YS initially 0, meaning one use lHpitals rule find initialvalue F. important, since Fs initial magnitude derivative infinite, QSIMeven supposed consider successors initial state. (We declare infinite landmarksunreachable values variables, mentioned earlier. Even Fs magnitude finitederivative infinite, simulation supposed continue, continuityrequirement would violated.) Fortunately,nsin ( X (t ))2F (t ) =0=1sin (t t0 )finite magnitude derivative t0: = t0, use lHpitals rule findn0F (t0 ) = =02Xsin ( X (t 0 t0 )) cos( X (t0 t0 ))=1= 0.cos(t0 t0 )Fs qualitative direction;dF(t ) =dt2 X sin ( X (t t0 )) cos( X (t t0 )) sin 2 ( X (t t0 )) cos(t t0 ),sin (t t0 )sin 2 (t t0 )=1nturns out, several applications lHpitals rule,dF(t0 ) =dtnX2,=1clearly finite positive number, Fs initial qualitative value therefore <0, inc>.Obviously, F = YS/Y guaranteed finite tE, reaches 0. variable YSnonzero (implying least one Yi nonzero, Lemma 10 correspondingXi integer) tE, F(tE) equal , impossible since infinity declaredunreachable, states would eliminated spurious. If, hand, YS(tE) = 0,then, see lHpitals rule, knowledge Xi integers,n0F (t E ) = =0=1n2 X sin ( X (t E t0 ))cos ( X (t E t0 ))=cos (t E t0 )2X=1sin ( X ) cos( X )cos( )= 0,behaviors ending states supposed included simulation output.supposedly complete sound simulator rejects initial states model dueinconsistency 2n runs, reason behavior predictions consideredsimulator ended F(tE) = , inconsistency propagated back initial state ledrejection cases. conclude polynomial integer solutions.hand, even one simulations prints initial state goessuccessors, conclude solution exists. forms decision procedure required573fiYILMAZ & SAYHilberts Tenth Problem, leading contradiction. Therefore, sound complete simulationimpossible even one restricts oneself single operating region limited constraintvocabulary mentioned statement theorem.4. Conclusionpaper, considered several alternative subsets qualitative representation,showed ineradicable spurious prediction problem persists even addconstant constraints allowed. one allows mult constraint well, resultingqualitative simulator inherently incomplete even representation negative numbersforbidden every variable forced specified zero uncertainty (i.e. singleunambiguous real number) initial state. final proof shows even abilityhandling models multiple operating regions removed representation,incompleteness problem would still persist, provided add, constant, derivative, multconstraints allowed vocabulary. Note none vocabularies includemonotonic function constraint, relation type native qualitativerepresentation.Although results paper demonstrated using QSIM representation inputoutput, valid qualitative simulators whose input output vocabulariesexpressive specified subsets QSIM. (Also note proofs applyautomatically semi-quantitative simulators, whose representations extensionpure QSIM.) believe results important sense provide deeperinsight causes spurious predictions, helpful researchers aimingconstruct provably sound complete simulators using weaker representations.Finally, wish stress findings amount bad piece newsusefulness qualitative simulators practical domains usually utilizedmay seem uninitiated eye. ones model specified level precisioninvolved models paper, one employ qualitative reasoner anyway.really annoys users qualitative simulators occasional prediction eradicablespurious behaviors, strengthening algorithms additional filters increasingmathematical sophistication get rid continues important lineresearch.ReferencesCutland, N. J. (1980). Computability: Introduction Recursive Function Theory. Cambridge,UK: Cambridge University Press.de Kleer, J., & Brown, J. S. (1984). qualitative physics based confluences. ArtificialIntelligence, 24, 7-83.Fouch, P., & Kuipers, B. J. (1992). Reasoning energy qualitative simulation. IEEETransactions Systems, Man, Cybernetics, 22, 47-63.Knik, T., & Say, A. C. C. (2003). Duration consistency filtering qualitative simulation.Annals Mathematics Artificial Intelligence, 38, 269-309.Kuipers, B. J., (1986). Qualitative simulation. Artificial Intelligence, 29, 289-338.574fiCAUSES INERADICABLE SPURIOUS PREDICTIONS QUALITATIVE SIMULATIONKuipers, B. J. (1994). Qualitative Reasoning: Modeling Simulation IncompleteKnowledge. Cambridge, MA: MIT Press.Matiyasevich, Y. (1993). Hilberts Tenth Problem. Cambridge, MA: MIT Press.Missier, A. (1991). Mathematical structures qualitative calculus, contribution qualitativesimulation. (In French) Ph.D. thesis, Institut National des Sciences Appliques de Toulouse.Say, A. C. C. (1998). LHpitals filter QSIM. IEEE Transactions Pattern AnalysisMachine Intelligence, 20, 1-8.Say, A. C. C. (2001). Improved reasoning infinity using qualitative simulation. ComputingInformatics, 20, 487-507.Say, A. C. C. (2003). Sound complete qualitative simulation requires quantitative filtering.Annals Mathematics Artificial Intelligence, 38, 257-267.Say, A. C. C., & Akn, H. L. (2003). Sound complete qualitative simulation impossible.Artificial Intelligence, 149, 251-266.Say, A. C. C., & Kuru, S. (1993). Improved filtering QSIM algorithm. IEEE TransactionsPattern Analysis Machine Intelligence, 15, 967-971.Shepherdson, J. C., & Sturgis, H. E. (1963). Computability recursive functions. JournalACM, 10, 217-255.Shults, B., & Kuipers, B. (1997). Proving properties continuous systems: Qualitativesimulation temporal logic. Artificial Intelligence, 92, 91-129.Struss, P. (1990). Problems interval-based qualitative reasoning. Weld, D. S., & de Kleer, J.(Eds.) Readings Qualitative Reasoning Physical Systems. San Mateo, CA: MorganKaufmann, 288-305.Weld, D. S., & de Kleer, J. (Eds.) (1990). Readings Qualitative Reasoning PhysicalSystems. San Mateo, CA: Morgan Kaufmann.Ylmaz, . (2005). Computability-theoretic limitations qualitative simulation. M. S. Thesis,Boazii University, stanbul, Turkey.(http://www.cmpe.boun.edu.tr/graduate/allthesis/m_3.pdf)575fiJournal Artificial Intelligence Research 27 (2006) 617-674Submitted 07/06; published 12/06Uncertainty Soft Temporal Constraint Problems: GeneralFramework Controllability Algorithms Fuzzy CaseFrancesca RossiKristen Brent VenableFROSSI @ MATH . UNIPD .KVENABLE @ MATH . UNIPD .University Padova, Department Pure Applied Mathematics,Via Trieste, 63 35121 PADOVA ITALYNeil Yorke-SmithNYSMITH @ AI . SRI . COMSRI International,333 Ravenswood Ave, Menlo Park, CA 94025 USAAbstractreal-life temporal scenarios, uncertainty preferences often essential coexistingaspects. present formalism quantitative temporal constraints preferencesuncertainty defined. show three classical notions controllability (that is, strong,weak, dynamic), developed uncertain temporal problems, generalized handle preferences well. defining general framework, focus problemspreferences follow fuzzy approach, properties assure tractability.problems, propose algorithms check presence controllability properties. particular, show setting dealing simultaneously preferences uncertaintyincrease complexity controllability testing. also develop dynamic execution algorithm,polynomial complexity, produces temporal plans uncertainty optimalrespect fuzzy preferences.1. IntroductionCurrent research temporal constraint reasoning, exposed difficulties real-life problems, found lacking expressiveness flexibility. rich application domainsoften necessary simultaneously handle temporal constraints, also preferencesuncertainty.need seen many scheduling domains. motivation line researchdescribed paper domain planning scheduling NASA space missions. NASAtackled many scheduling problems temporal constraints used reasonable success, showing limitations lack capability deal uncertaintypreferences. example, Remote Agent (Rajan, Bernard, Dorais, Gamble, Kanefsky, Kurien,Millar, Muscettola, Nayak, Rouquette, Smith, Taylor, & Tung, 2000; Muscettola, Morris, Pell, &Smith, 1998) experiments, consisted placing AI system on-board plan executespacecraft activities, represents one interesting examples this. Remote Agent workedhigh level goals specified, example, duration frequency time windowswithin spacecraft take asteroid images used orbit determinationon-board navigator. Remote Agent dealt flexible time intervals uncontrollable events;however, deal preferences: temporal constraints hard. benefitadding preferences framework would allow planner handle uncontrollable eventstime maximizing mission managers preferences.c2006AI Access Foundation. rights reserved.fiROSSI , V ENABLE ,& YORKE -S MITHrecent NASA application rovers domain (Dearden, Meuleau, Ramakrishnan,Smith, & Washington, 2002; Bresina, Jonsson, Morris, & Rajan, 2005). NASA interestedgeneration optimal plans rovers designed explore planetary surface (e.g. SpiritOpportunity Mars) (Bresina et al., 2005). Dearden et al. (2002) describe problem generating plans planetary rovers handle uncertainty time resources. approachinvolves first constructing seed plan, incrementally adding contingent branchesplan order improve utility. Again, preferences could used embed utilities directlytemporal model.third space application, used several times paper running example,concerns planning fleets Earth Observing Satellites (EOS) (Frank, Jonsson, Morris, & Smith,2001). planning problem involves multiple satellites, hundreds requests, constraintsserve request, resources instruments, recording devices, transmittersground stations. response requests placed scientists, image data acquired EOS.data either downlinked real time recorded board playback later time.Ground stations satellites available receive downlinked images. Different satellitesmay able communicate subset resources, transmission rates differsatellite satellite station station. Further, may different financial costsassociated using different communication resources. (Frank et al., 2001) EOS scheduling problem dealt using constraint-based interval representation. Candidate plansrepresented variables constraints, reflect temporal relationship actionsconstraints parameters states actions. Also, temporal constraints necessarymodel duration ordering constraints associated data collection, recording, downlinking tasks. Solutions preferred based objectives (such maximizing number highpriority requests served, maximizing expected quality observations, minimizingcost downlink operations). Uncertainty present due weather: specifically due durationpersistence cloud cover, since image quality obviously affected amount cloudstarget. addition, events need observed may happen unpredictabletimes uncertain durations (e.g. fires volcanic eruptions).existing frameworks, Simple Temporal Problems Preferences (STPPs) (Khatib,Morris, Morris, & Rossi, 2001), address lack expressiveness hard temporal constraintsadding preferences temporal framework, take account uncertainty. models, Simple Temporal Problems Uncertainty (STPUs) (Vidal & Fargier, 1999), accountcontingent events, notion preferences. paper introduce frameworkallows us handle preferences uncertainty Simple Temporal Problems.proposed model, called Simple Temporal Problems Preferences Uncertainty (STPPUs),merges two pre-existing models STPPs STPUs.STPPU instance represents quantitative temporal problem preferences uncertaintyvia set variables, representing starting ending times events (which controllableagent not), set soft temporal constraints variables, includes interval containing allowed durations event allowed times events.preference function associating element interval value specifies muchvalue preferred. soft constraints defined controllable uncontrollableevents. order clarify modeled STPPU, let us emphasize gradualityallowed terms preferences uncertainty. sense, uncertainty represented contingent STPPU constraints contingent STPU constraints:618fiU NCERTAINTYSOFT TEMPORAL CONSTRAINT PROBLEMSdurations assumed equally possible. addition expressing uncertainty, STPPUs, contingent constraints soft different preference levels associated different durationscontingent events.problems, consider notions controllability similar defined STPUs,used instead consistency presence uncertainty, adapthandle preferences. notions, usually called strong, weak, dynamic controllability, referpossibility controlling problem, is, executing agent assigning valuescontrollable variables, way optimal respect Nature decided,decide, uncontrollable variables. word optimal crucial, since STPUs,preferences, need care controllability, optimality. fact,notions define paper directly correspond STPUs called strong, weak,dynamic optimal controllability.defining controllability notions proving properties, considerrestrictions shown make temporal problems preferences tractable(Khatib et al., 2001; Rossi, Sperduti, Venable, Khatib, Morris, & Morris, 2002), i.e, semi-convexpreference functions totally ordered preferences combined idempotent operator.context, controllability notions, give algorithms check whetherhold, show adding preferences make complexity testingproperties worse case without preferences. Moreover, dealing different levelspreferences, also define testing algorithms refer possibility controlling problemmaintaining preference least certain level (called -controllability). Finally,context dynamic controllability, also consider execution dynamic optimal plans.Parts content paper appeared (Venable & Yorke-Smith, 2003; Rossi, Venable, & Yorke-Smith, 2003; Yorke-Smith, Venable, & Rossi, 2003; Rossi, Venable, & Yorke-Smith,2004). paper extends previous work least two directions. First, papers optimal controllability (strong dynamic) checked separately, checkoptimal (strong dynamic) controllability and, hold, algorithm returnhighest given problem -strong -dynamic controllable. Moreover, resultspresented uniform technical environment, providing thorough theoretical study properties algorithms computational aspects, makes use several unpublishedproofs.paper structured follows. Section 2 give background temporal constraintspreference uncertainty. Section 3 define formalism Simple TemporalProblems preferences uncertainty and, Section 4, describe new notionscontrollability. Algorithms test notions described respectively Section 5 OptimalStrong Controllability, Section 6 Optimal Weak Controllability, Section 7 OptimalDynamic Controllability. Section 8 give general strategy using notions. Finally, Section 9, discuss related work, Section 10 summarize main resultspoint directions future developments. make paper readable, proofstheorems contained Appendix.2. Backgroundsection give main notions temporal constraints (Dechter, Meiri, & Pearl, 1991)framework Temporal Constraint Satisfaction Problems Preferences (TCSPPs) (Khatib619fiROSSI , V ENABLE ,& YORKE -S MITHet al., 2001; Rossi et al., 2002), extend quantitative temporal constraints (Dechter et al., 1991)semiring-based preferences (Bistarelli, Montanari, & Rossi, 1997). also describe SimpleTemporal Problems Uncertainty (STPUs) (Vidal & Fargier, 1999; Morris, Muscettola, & Vidal,2001), extend tractable subclass temporal constraints model agent-uncontrollablecontingent events, define corresponding notions controllability, introduced (Vidal& Fargier, 1999).2.1 Temporal Constraint Satisfaction ProblemsOne requirements temporal reasoning system planning scheduling problemsability deal metric information; words, handle quantitative informationduration events (such take ten twenty minutes get home). Quantitativetemporal networks provide convenient formalism deal information. considerinstantaneous events variables problem, whose domains entire timeline.variable may represent either beginning ending point event, neutral pointtime. effective representation quantitative temporal networks, based constraints, withinframework Temporal Constraint Satisfaction Problems (TCSPs) (Dechter et al., 1991).paper interested particular subclass TCSPs, known Simple TemporalProblems (STPs) (Dechter et al., 1991). problem, constraint time-points XXj represented constraint graph edge X Xj , labeled single interval [aij , bij ]represents constraint aij Xj Xi bij . Solving STP means finding assignmentvalues variables temporal constraints satisfied.Whereas complexity general TCSP comes one intervalconstraint, STPs solved polynomial time. Despite restriction single interval perconstraint, STPs shown valuable many practical applications. STPsattracted attention literature.STP associated directed weighted graph G = (V, Ed ), called distancegraph. set nodes constraint graph twice number edges:binary constraint variables X Xj , distance graph edge Xi Xjlabeled weight bij , representing linear inequality X j Xi bij , well edge Xj Xilabeled weight aij , representing linear inequality X Xj aij .path Xi Xj distance graph Gd , say variables Xi0 = Xi , Xi1 , Xi2 , . . .P, Xik = Xj induces following path constraint: X j Xi kh=1 bih1 ih . intersectioninduced path constraints yields inequality X j Xi dij , dij length shortestpath Xi Xj , length defined, i.e. negative cycles distancegraph. STP consistent distance graph negative cycles (Shostak, 1981;Leiserson & Saxe, 1988). means enforcing path consistency, algorithmPC-2, sufficient solving STPs (Dechter et al., 1991). follows given STP effectively specified another complete directed graph, called d-graph, edge Xi Xjlabeled shortest path length ij distance graph Gd .(Dechter et al., 1991) shown consistent STP backtrack-free (that is, decomposable) relative constraints d-graph. Moreover, set temporal constraintsform [dji , dij ] minimal STP corresponding original STP possible find onesolutions using backtrack-free search simply assigns variable valuesatisfies minimal network constraints compatibly previous assignments. Two specific solu-620fiU NCERTAINTYSOFT TEMPORAL CONSTRAINT PROBLEMStions (usually called latest earliest assignments) given L = {d01 , . . . , d0n }SE = {d10 , . . . , dn0 }, assign variable respectively latest earliest possible time(Dechter et al., 1991).d-graph (and thus minimal network) STP found applying FloydWarshalls Pairs Shortest Path algorithm (Floyd, 1962) distance graph complexityO(n3 ) n number variables. graph sparse, Bellman-Ford Single SourceShortest Path algorithm used instead, complexity equal O(nE), Enumber edges. refer (Dechter et al., 1991; Xu & Choueiry, 2003) detailsefficient STP solving.2.2 Temporal CSPs PreferencesAlthough expressive, TCSPs model hard temporal constraints. means constraintssatisfied, solutions constraint equally satisfying. However,many real-life situations solutions preferred others and, thus, global problemfind way satisfy constraints optimally, according preferences specified.address need, TCSP framework generalized (Khatib et al., 2001)associate temporal constraint preference function specifies preferencedistance allowed constraint. framework merges TCSPs semiring-based softconstraints (Bistarelli et al., 1997).Definition 1 (soft temporal constraint) soft temporal constraint 4-tuple h{X, }, I, A, fconsistingset two variables {X, } integers, called scope constraint;set disjoint intervals = {[a1 , b1 ], . . . , [an , bn ]}, ai , bi Z, ai bi= 1, . . . , n;set preferences A;preference function f : A, mapping elements preferencevalues, taken set A.Given assignment variables X , X = v x = vy , say assignmentsatisfies constraint h{X, }, I, A, f iff exists [a , bi ] ai vy vx bi .case, preference associated assignment constraint f (v vx ) = p.2variables preference set STPP apparent, omit writesoft temporal constraint pair hI, f i.Following soft constraint approach (Bistarelli et al., 1997), preference set carrieralgebraic structure known c-semiring. Informally c-semiring = hA, +, , 0, 1iset equipped two operators satisfying proscribed properties (for details, see Bistarelliet al., 1997)). additive operator + used induce ordering preference set A; giventwo elements a, b A, b iff + b = a. multiplicative operator used combinepreferences.621fiROSSI , V ENABLE ,& YORKE -S MITHDefinition 2 (TCSPP) Given semiring = hA, +, , 0, 1i, Temporal Constraint SatisfactionProblems Preferences (TCSPP) pair hV, Ci, V set variables Cset soft temporal constraint pairs variables V preferences A.2Definition 3 (solution) Given TCSPP hV, Ci semiring S, solution complete assignment variables V . solution said satisfy constraint c C preference pprojection pair variables cs scope satisfies c preference p. writepref (t, c) = p.2solution global preference value, obtained combining, via operator,preference levels solution satisfies constraints C.Definition 4 (preference solution) Given TCSPP hV, Ci semiring S, preferencesolution = hv1 , . . . , vn i, denoted val(t), computed cC pref (s, c).2optimal solutions TCSPP solutions best global preferencevalue, best determined ordering values semiring.Definition 5 (optimal solutions) Given TCSPP P = hV, Ci semiring S, solutionP optimal every solution 0 P , t0 6S t.2Choosing specific semiring means selecting class preferences. example, semiringSF CSP = h[0, 1], max, min, 0, 1iallows one model so-called fuzzy preferences (Ruttkay, 1994; Schiex, 1992), associateelement allowed constraint preference 0 1 (with 0 worst1 best preferences), gives complete assignment minimal among preferences selected constraints. optimal solutions solutions maximalpreference. Another example semiring CSP = h{f alse, true}, , , f alse, truei,allows one model classical TCSPs, without preferences, general TCSPP framework.paper refer fuzzy temporal constraints. However, absence preferencestemporal constraints always modelled using two elements 0 1constraints. Thus preferences always coexists hard constraints.special case occurs constraint TCSPP contains single interval. analogydone case without preferences, problems called Simple Temporal ProblemsPreferences (STPPs). class temporal problems interesting because, noted above,STPs polynomially solvable general TCSPs NP-hard, computational effectadding preferences STPs immediately obvious.Example 1 Consider EOS example given Section 1. Figure 1 show STPPmodels scenario three events scheduled satellite: start time (Ss)ending time (Se) slewing procedure starting time (Is) image retrieval.slewing activity example take 3 10 units time, ideally 3 5 unitstime, shortest time possible otherwise. image taking start time 320 units time slewing initiated. third constraint, variables Se,models fact better image taking start soon slewing stopped.2622fiU NCERTAINTYSOFT TEMPORAL CONSTRAINT PROBLEMS11 10.90.80.70.60.53 4 5 6 78 9 10SsSe11 1 10.90.90.80.80.70.70.60.63204 3 2 10 1 2 3456Figure 1: STPP Example 1.following example, instead, consider STPP uses set-based semiring:Sset = h(A), , , , Ai. Notice that, fuzzy semiring, multiplicative operator, i.e.,intersection, idempotent, order induced additive operator, i.e., union, partial.Example 2 Consider scenario three friends, Alice, Bob, Carol, want meet drinkdinner must decide time meet reserve dinner dependinglong takes get restaurant. variables involved problem are: globalstart time X0 , value 0 domain, start time drink (Ds), timeleave dinner (De), time arrival restaurant (Rs). meet, drink,8 9:00pm leave dinner half hour. Moreover, dependingrestaurant choose, take 20 40 minutes get dinner. Alice prefersmeet early dinner early, like Carol. Bob prefers meet 8:30 go bestrestaurant farthest. Thus, following two soft temporal constraints. firstconstraint defined variable pair (X0 , Ds), interval [8:00,9:00] preferencefunction, fs , that, fs (8 : 00) = {Alice, Carol}, fs (8 : 30) = {Bob} fs (9 : 00) = .second constraint binary constraint pair (De,Rs), interval [20, 40] preferencefunction fse , that, fse (20) = {Alice, Carol} fse (20) = fse (20) = {Bob}.additional hard constraint variable pair (Ds, De), modeledinterval [30, 30] single preference equal {Alice, Carol, Bob}. optimal solution(X0 = 0, Ds = 8 : 00, De = 8 : 30, Rs = 8 : 50), preference {Alice, Carol}. 2Although TCSPPs STPPs NP-hard, (Khatib et al., 2001) tractable subclassSTPPs described. tractability assumptions are: semi-convexity preference functions,idempotence combination operator semiring, totally ordered preference set.preference function f soft temporal constraint hI, f semi-convex iff < + , set{x I, f (x) y} forms interval. Notice semi-convex functions include linear, convex,also step functions. aggregation operator totally ordered set idempotentmin (Dubois & Prade, 1985), i.e. combination operator F CSP semiring.tractability assumptions met, STPPs solved polynomial time. (Rossiet al., 2002) two polynomial solvers tractable subclass STPPs proposed. One solver623fiROSSI , V ENABLE ,& YORKE -S MITHbased extension path consistency TCSPPs. second solver decomposes problemsolving set hard STPs.2.3 Simple Temporal Problems Uncertaintyreasoning concerns activities agent performs interacting external world, uncertainty often unavoidable. TCSPs assume activities durations controlagent. Simple Temporal Problems Uncertainty (STPUs) (Vidal & Fargier, 1999) extendSTPs distinguishing contingent events, whose occurrence controlled exogenous factorsoften referred Nature.STPs, activity durations STPUs modelled intervals. start times activities assumed controlled agent (this brings loss generality). end times,however, fall two classes: requirement (free Vidal & Fargier, 1999) contingent.former, STPs, decided agent, agent control latter:observe occurrence event; observation supposed known immediatelyevent. information known prior observation time-point nature respectinterval duration. Durations contingent links assumed independent.STPU, variables thus divided two sets depending type time-pointsrepresent.Definition 6 (variables) variables STPU divided into:executable time-points: points, b , whose time assigned executing agent;contingent time-points: points, e , whose time assigned external world.2distinction variables leads constraints also divided two sets, requirement contingent, depending type variables constrain. Note STPsconstraints binary. Formally:Definition 7 constraints STPU divided into:requirement constraint (or link) r ij , generic time-points ti tj 1 , interval Iij =[lij , uij ] lij (tj ) (ti ) uij (ti ) value assigned variable ticontingent link ghk , executable point bh contingent point ek , interval Ihk =[lij , uij ] contains possible durations contingent event represented b hek .2formal definition STPU following:Definition 8 (STPU) Simple Temporal Problem Uncertainty (STPU) 4-tuple N ={Xe , Xc , Rr , Rc } that:Xe = {b1 , . . . , bne }: set executable time-points;Xc = {e1 , . . . , enc }: set contingent time-points;1. general ti tj either contingent executable time-points.624fiU NCERTAINTYStartCookingSOFT TEMPORAL CONSTRAINT PROBLEMS[20,40]EndCooking[0,10]requirement constr.[30,60]contingent constr.StartDinnercontingent timepointEndDinnerexecutable timepointFigure 2: STPU Example 3.Rr = {ci1 j1 , . . . , ciC jC }: set C requirement constraints;Rc = {gi1 j1 , . . . , giG jG }: set G contingent constraints.2Example 3 example taken (Vidal & Fargier, 1999), describes scenariomodeled using STPU. Consider two activities Cooking dinner. Assumedont want eat dinner cold. Also, assume control start cookingdinner starts finish cooking dinner over.STPU modeling example depicted Figure 2. two executable time-points {Startcooking, Start-dinner} two contingent time-points {End-cooking, End-dinner}. Moreover,contingent constraint variables {Start-cooking, End-cooking} models uncontrollable durationfixing dinner take anywhere 20 40 minutes; contingent constraintvariables {Start-dinner, End-dinner} models uncontrollable duration dinner last30 60 minutes. Finally, requirement constraint variables {End-cooking, Startdinner} simply bounds 10 minutes time food readydinner starts.2Assignments executable variables assignments contingent variables distinguished:Definition 9 (control sequence) control sequence assignment executable time-points.said partial assigns values proper subset executables, otherwise complete.2Definition 10 (situation) situation set durations contingent constraints.contingent constraints assigned duration said partial, otherwise complete.2Definition 11 (schedule) schedule complete assignment time-points X e Xc .schedule identifies control sequence, , consisting assignments executabletime-points, situation, , set durations identified assignmentscontingent constraints. Sol(P ) denotes set schedules STPU.2easy see situation corresponds STP. fact, durationscontingent constraints fixed, uncertainty problem, becomesSTP, called underlying STP. formalized notion projection.Definition 12 (projection) projection P , corresponding situation , STP obtainedleaving requirement constraints unchanged replacing contingent constraint g hk625fiROSSI , V ENABLE ,& YORKE -S MITHconstraint h[hk , hk ]i, hk duration event represented g hk . P roj(P )set projections STPU P .22.4 Controllabilityclear order solve problem uncertainty possible situations must considered.notion consistency defined STPs apply since requires existence singleschedule, sufficient case since situations equally possible.2reason, (Vidal & Fargier, 1999), notion controllability introduced. ControllabilitySTPU is, sense, analogue consistency STP. Controllable means agentmeans execute time-points control, subject constraints. notioncontrollability expressed, terms ability agent find, given situation,appropriate control sequence. ability identified strategy:Definition 13 (strategy) strategy map : P roj(P ) Sol(P ), every projection P , S(P ) schedule induces durations contingent constraints.Further, strategy viable if, every projection P , S(P ) solution P .2write [S(P )]x indicate value assigned executable time-point x scheduleS(P ), [S(P )]<x history x S(P ), is, set durations contingent constraints occurred S(P ) execution x, i.e. partial solution far.(Vidal & Fargier, 1999), three notions controllability introduced STPUs.2.4.1 TRONG C ONTROLLABILITYfirst notion is, name suggests, restrictive terms requirementscontrol sequence must satisfy.Definition 14 (Strong Controllability) STPU P Strongly Controllable (SC) iffexecution strategy s.t. P P roj(P ), S(P ) solution P , [S(P1 )]x = [S(P2 )]x ,P1 , P2 projections every executable time-point x.2words, STPU strongly controllable fixed execution strategy workssituations. means fixed control sequence consistent possiblescenario world. Thus, notion strong controllability related conformantplanning. clearly strong requirement. Vidal Fargier (1999) suggest, SC mayrelevant applications situation observable completecontrol sequence must known beforehand (for example cases activities dependcontrol sequence, production planning area).(Vidal & Fargier, 1999) polynomial time algorithm checking STPU stronglycontrollable proposed. main idea rewrite STPU given input equivalent STPexecutable variables. important notice, contents paper,algorithm StronglyControllable takes input STPU P = {X e , Xc , Rr , Rc } returnsoutput STP defined variables Xe . STPU input strongly controllable iff derivedSTP consistent. Moreover, every solution STP control sequence guarantees2. Tsamardinos (2002) augmented STPUs include probability distributions possible situations;paper implicitly assume uniform, independent distribution link.626fiU NCERTAINTYSOFT TEMPORAL CONSTRAINT PROBLEMSstrong controllability STPU. STP consistent, output StronglyControllableminimal form.(Vidal & Fargier, 1999) shown complexity StronglyControllable O(n 3 ),n number variables.2.4.2 W EAK C ONTROLLABILITYhand, notion controllability fewest restrictions control sequencesWeak Controllability.Definition 15 (Weak Controllability) STPU P said Weakly Controllable (WC) iffP P roj(P ) strategy s.t. (P ) solution P .2words, STPU weakly controllable viable global execution strategy:exists least one schedule every situation. seen minimum requirement since,property hold, situations way executecontrollable events consistent way. also looks attractive since, STPU shownWC, soon one knows situation, one pick apply control sequencematches situation. Unfortunately (Vidal & Fargier, 1999) shown propertyuseful classical planning. Nonetheless, WC may relevant specific applications (as largescale warehouse scheduling) actual situation totally observable (possiblybefore) execution starts, one wants know advance that, whatever situation,always least one feasible control sequence.(Vidal & Fargier, 1999) conjectured (Morris & Muscettola, 1999) provencomplexity checking weak controllability co-NP-hard. algorithm proposedtesting WC (Vidal & Fargier, 1999) based classical enumerative process lookaheadtechnique.Strong Controllability implies Weak Controllability (Vidal & Fargier, 1999). Moreover,STPU seen STP uncertainty ignored. enforcing path consistency removeselements contingent intervals, elements belong solution. so,possible conclude STPU weakly controllable.Definition 16 (pseudo-controllability) STPU pseudo-controllable applying path consistency leaves intervals contingent constraints unchanged.2Unfortunately, path consistency leaves contingent intervals untouched, cannot conclude STPU weakly controllable. is, WC implies pseudo-controllabilityconverse false. fact, weak controllability requires given possible combination durations contingent constraints STP corresponding projection must consistent.Pseudo-controllability, instead, guarantees possible duration contingent constraint least one projection contains duration consistent STP.2.4.3 DYNAMIC C ONTROLLABILITYdynamic applications domains, planning, situation observed time. Thusdecisions made even situation remains partially unknown. Indeed distinctionStrong Dynamic Controllability equivalent conformant conditional planning. final notion controllability defined (Vidal & Fargier, 1999) address627fiROSSI , V ENABLE ,& YORKE -S MITHPseudocode DynamicallyControllable1. input STPU W;2. W pseudo-controllable write DC stop;3. Select triangles ABC, C uncontrollable, C,upper bound BC interval, v, non-negative.4. Introduce tightenings required Precede casewaits required Unordered case.5. possible regressions waits,converting unconditional waits lower bounds.Also introduce lower bounds provided general reduction.6. steps 3 4 produce new (or tighter)constraints, return true, otherwise go 2.Figure 3: Algorithm DynamicallyControllable proposed (Morris et al., 2001) checking DCSTPU.[x,y]Crequirement constr.contingent constr.contingent timepoint[p,q][u,v]executable timepointBFigure 4: triangular STPU.case. give definition provided (Morris et al., 2001) equivalentcompact.Definition 17 (Dynamic Controllability) STPU P Dynamically Controllable (DC) iffstrategy P1 , P2 P roj(P ) executable time-point x:1. [S(P1 )]<x = [S(P2 )]<x [S(P1 )]x = [S(P2 )]x ;2. S(P1 ) solution P1 S(P2 ) solution P2 .2words, STPU dynamically controllable exists viable strategy built,step-by-step, depending observed events step. SC = DC DC =WC. Dynamic Controllability, seen useful controllability notion practice, alsoone requires complicated algorithm. Surprisingly, Morris et al. (2001) MorrisMuscettola (2005) proved DC polynomial size STPU representation. Figure 3pseudocode algorithm DynamicallyControllable shown.paper extend notion dynamic controllability order deal preferences. algorithm propose test extended property require good (evencomplete) understanding DynamicallyControllable algorithm. Thus, givenecessary details algorithm.628fiU NCERTAINTYSOFT TEMPORAL CONSTRAINT PROBLEMSseen, algorithm based considerations triangles constraints.triangle shown Figure 4 triangular STPU one contingent constraint, AC, two executabletime-points, B, contingent time-point C. Based sign u v, three differentcases occur:Follow case (v < 0): B always follow C. STPU path consistent also DCsince, given time C occurs A, definition path consistency, alwayspossible find consistent value B.Precede case (u 0): B always precede happen simultaneously C.STPU dynamically controllable v x u, interval [p, q] ABreplaced interval [y v, x u], sub-interval containing elements[p, q] consistent element [x, y].Unordered case (u < 0 v 0): B either follow precede C. ensure dynamiccontrollability, B must wait either C occur first, = v units time goA. words, either C occurs B executed first value consistentCs time, B safely executed units time execution. describedadditional constraint expressed wait AB written < C, >,= v. course x v raise lower bound AB, p, v(Unconditional Unordered Reduction), case raise x x > p (GeneralUnordered reduction) .shown waits propagated (in Morris et al., 2001, term regressedis used) one constraint another: wait AB induces wait another constraint involving A,e.g. AD, depending type constraint DB. particular, two possible wayswaits regressed.Regression 1: assume AB constraint wait hC, ti. Then, DBconstraint (including AB itself) upper bound, w, possible deduce wait hC,wi AD. Figure 5(a) shows type regression.Regression 2: assume AB constraint wait hC, ti, 0. Then,contingent constraint DB lower bound, z, B 6= C, possiblededuce wait hC, zi AD. Figure 5(b) shows type regression.Assume simplicity without loss generality executed time 0. Then, Bexecuted wait C executed first. wait expires, B safelyexecuted time left interval. Figure 6 shows, possible consider FollowPrecede cases special cases Unordered. Follow case put dummy waitend interval, meaning B must wait C executed case (Figure 6(a)). Precede case, set wait expires first element interval meaningB executed C element interval consistent C (Figure 6(b)). Unordered case thus seen combination two previous states. partinterval wait seen Follow case (in fact, B must wait C waitexpires), second part including following wait seen Precede case (afterwait expired, B executed assignment B corresponds elementpart interval AB consistent possible future value assigned C).629fiROSSI , V ENABLE ,& YORKE -S MITH[x,y][x,y]CContingent<C,t><C,tw>C[u,v]Contingent<C,t><C,tz>[p,q][u,v][p,q]BB[z,w][z,w]requirement constr.contingent constr.controllable timepointrequirement constr.contingent constr.controllable timepointcontingent timepointcontingent timepoint(a) Regression 1(b) Regression 2Figure 5: Regressions algorithm DynamicallyControllable.Follow Casewait C executedwaitexecute regardless CPrecede CasewaitUnordered Casewait fo C executedexecute regardless CwaitFigure 6: resulting AB interval constraint three cases consideredDynamicallyControllable algorithm.DynamicallyControllable algorithm applies rules triangles STPUregresses possible waits. inconsistency found, requirement interval becomesempty contingent interval squeezed, STPU DC algorithm returns STPUconstraints may waits satisfy, intervals contain elements appearleast one possible dynamic strategy. STPU given execution algorithmdynamically assigns values executables according current situation.pseudocode execution algorithm, DC-Execute, shown Figure 7. executionalgorithm observes, time goes by, occurrence contingent events accordinglyexecutes controllables. controllable B, execution triggered (1) live,630fiU NCERTAINTYSOFT TEMPORAL CONSTRAINT PROBLEMSPseudocode DC-Execute1. input STPU P ;2. Perform initial propagation start time-point;3. repeat4. immediately execute executable time-pointsreached upper bounds;5. arbitrarily pick executable time-point xlive enabled yet executed, whose waits,any, satisfied;6. execute x;7. propagate effect execution;8. network execution complete return;9. else advance current time,propagating effect contingent time-points occur;10. false;Figure 7: Algorithm executes dynamic strategy STPU.is, current time within bounds, (2) enabled, is, executables constrainedhappen occurred, (3) waits imposed contingent time-points Bexpired.DC-Execute produces dynamically consistent schedule every STPU algorithmDynamicallyControllable reports success (Morris et al., 2001). complexity algorithmO(n3 r), n number variables r number elements interval. Sincepolynomial complexity relies assumption bounded maximum interval size, Morris et al.(2001) conclude DynamicallyControllable pseudo-polynomial. DC algorithm strongpolynomial complexity presented (Morris & Muscettola, 2005). new algorithm differsprevious one mainly manipulates distance graph rather constraintgraph STPU. complexity O(n 5 ). important notice purposes that,distance graph produced output new algorithm, possible directly recoverintervals waits STPU produced output original algorithm described (Morriset al., 2001).3. Simple Temporal Problems Preferences Uncertainty (STPPUs)Consider temporal problem would model naturally preferences addition hardconstraints, one also features uncertainty. Neither STPP STPU adequate modelproblem. Therefore propose call Simple Temporal Problems Preferences Uncertainty, STPPUs short.Intuitively, STPPU STPP time-points partitioned two classes, requirement contingent, STPU. Since time-points controllableagent, notion consistency STP(P) replaced controllability,STPU. Every solution STPPU global preference value, STPP, seeksolution maximizes value, satisfying controllability requirements.631fiROSSI , V ENABLE ,& YORKE -S MITHprecisely, extend definitions given STPPs STPUs fit STPPUsfollowing way.Definition 18 context preferences:executable time-point variable, x , whose time assigned agent;contingent time-point variable, e , whose time assigned external world;soft requirement link rij , generic time-points ti tj 3 , pair hIij , fij i, Iij =[lij , uij ] lij (tj ) (ti ) uij (ti ) value assigned variable ti ,fij : Iij preference function mapping element interval elementpreference set, A, semiring = hA, +, , 0, 1i;soft contingent link ghk , executable point bh contingent point ek , pair hIhk , fhkinterval Ihk = [lhk , uhk ] contains possible durations contingent eventrepresented bh ek fhk : Ihk preference function maps elementinterval element preference set A.2types constraints, preference function represents preference agentduration event distance two events. However, soft requirementconstraints agent control guided preferences choosing valuestime-points, soft contingent constraints preference represents merely desire agentpossible outcomes Nature: control outcomes. noticedSTPPUs uncertainty modeled, like STPUs, assuming complete ignoranceevents likely happen. Thus, durations contingent events assumed equallypossible (or plausible) different levels plausibility allowed.state formally definition STPPUs, combines preferencesdefinition STPP contingency definition STPU.Definition 19 (STPPU) Simple Temporal Problem Preferences Uncertainty (STPPU)tuple P = (Ne , Nc , Lr , Lc , S) where:Ne set executable time-points;Nc set contingent time-points;= hA, +, , 0, 1i c-semiring;Lr set soft requirement constraints S;Lc set soft contingent constraints S.2Note that, STPPs, also STPPUs model hard constraints soft constraintselement interval mapped maximal element preference set. Further, withoutloss generality, following assumptions made STPUs (Morris et al., 2001), assumetwo contingent constraints end time-point.3. Again, general ti tj either contingent executable time-points.632fiU NCERTAINTYSOFT TEMPORAL CONSTRAINT PROBLEMScomplete assignment time-points compute global preference,STPPs. done according semiring-based soft constraint schema: first projectassignment soft constraint, obtaining element interval preferenceassociated element; combine preferences obtained constraintsmultiplicative operator semiring. Given two assignments preference, bestchosen using additive operator. assignment optimal assignmentpreference better semirings ordering.following summarize definitions given STPUs, extending directlySTPPUs.Definition 20 Given STPPU P :schedule complete assignment time-points N e Nc ;Sched(P) set schedules P ; Sol(P) set schedules Pconsistent constraints P (see Definition 1, Section 2.2);Given schedule P , situation (usually written ) set durations contingent constraints s;Given schedule P , control sequence (usually written set assignmentsexecutable time-points s;T, schedule [T, ]x = []x 4 , x Ne , every contingent constraint,ghk Lc , defined executable bh contingent time-point ek , [T, ]ek -[T, ]bh = hk ,hk duration ghk ;projection P corresponding situation STPP obtained P leavingrequirement constraints unchanged replacing contingent constraint g hk softconstraint h[hk , hk ], f (hk )i, hk duration event represented g hk, f (hk ) preference associated duration;Given projection P indicate Sol(P ) set solutions P defineOptSol(P ) = {s Sol(P )| 6 s0 Sol(P ), pref (s0 ) > pref (s)}; set preferences totally ordered indicate opt(P ) preference optimal solutionP ;Proj(P) set projections STPPU P;strategy map : P roj(P ) Sched(P ) every projection P , s(P )schedule includes ;strategy viable , S(P ) solution P , is, satisfies soft temporalconstraints. Thus viable strategy mapping : P roj(P ) Sol(P ). caseindicate pref (S(P )) global preference associated schedule S(P ) STPPP .24. Regarding notation, case hard constraints, given executable time-point x, write [S(P )]xindicate value assigned x S(P ), [S(P )]<x indicate durations contingent eventsfinish prior x S(P ).633fiROSSI , V ENABLE ,& YORKE -S MITH10.90.5x=18=yECSC110.9p=10.90.60.6u=65=q4=vSArequirement constr.1contingent constr.0.6contingent timepoint0.8EAexecutable timepoints=25=tFigure 8: Example STPPU Earth Observing Satellites domain.Example 4 Consider example following scenario Earth Observing Satellitesdomain (Frank et al., 2001) described Section 1. Suppose request observing regioninterest received accepted. collect data, instrument must aimedtarget images taken. might be, however, certain period timewindow allocated observation, region interest covered clouds. earliercloud coverage ends better, since maximise quality quantity retrieveddata; coverage controllable.Suppose time window reserved observation 1 8 units timestart counting time cloud occlusion region interest observable. Also, suppose,order observation succeed, aiming procedure must start 5 unitsstarting time, ideally 3 units, actually begin least 1 time unitweather becomes observable. Ideally aiming procedure start slightly cloudcoverage end. starts early, then, since instrument activated immediatelyaimed, clouds might still occlude region image quality poor. hand,waits long clouds disappeared precious timeocclusion wasted aiming instrument instead taking images. aiming procedurecontrolled mission manager take anywhere 2 5 units time.ideal duration 3 4 units, since short time 2 units would put instrument pressure,long duration, like 5 units, would waste energy.scenario, rather tedious describe words, compactly represented STPPUshown Figure 8 following features:set executable time-points SC (Start Clouds), SA (Start Aiming), EA (End Aiming);contingent time-point EC (End Clouds);set soft requirement constraints {SC SA, SA EC, SA EA};soft contingent constraint {SC EC};634fiU NCERTAINTYSOFT TEMPORAL CONSTRAINT PROBLEMSfuzzy semiring SFCSP = h[0, 1], max, min, 0, 1i.solution STPPU Figure 8 schedule = {SC = 0, SA = 2, EC = 5, EA = 7}.situation associated projection contingent constraint, SC EC,i.e. = 5, control sequence assignment executable time-points, i.e. ={SC = 0, SA = 2, EA = 7}. global preference obtained considering preferencesassociated projections constraints, pref(2) = 1 SC SA, pref(3) = 0.6SA EC, pref(5) = 0.9 SA EA, pref(5) = 0.8 SC EC. preferencesmust combined using multiplicative operator semiring, min,global preference 0.6. Another solution 0 = {SC = 0, SA = 4, EC = 5, EA = 9}global preference 0.8. Thus s0 better solution according semiring ordering sincemax(0.6, 0.8) = 0.8.24. Controllability Preferencesconsider possible extend notion controllability accommodate preferences. general interested ability agent execute time-pointscontrol, subject constraints also best possible way respect preferences.transpires meaning best possible way depends types controllabilityrequired. particular, concept optimality must reinterpreted due presence uncontrollable events. fact, distinction nature events induces differencemeaning preferences expressed them, mentioned previous section. scenario given certain level desirability, expressing much agent likessituation. Then, agent often several choices events controls consistentscenario. choices might preferable respect others. expressedpreferences requirement constraints information guide agentchoosing best possible actions take. Thus, concept optimality relativespecific scenario. final preference complete assignment overall value combinesmuch corresponding scenario desirable agent well agent reactedscenario.concepts controllability propose are, thus, based possibilityagent execute events control best possible way given actual situation. Acting optimal way seen lowering preference given uncontrollableevents.4.1 Strong Controllability Preferencesstart considering strongest notion controllability. extend notion, takingaccount preferences, two ways, obtaining Optimal Strong Controllability -Strong Controllability, preference level. see, first notion corresponds strongerrequirement, since assumes existence fixed unique assignment executable timepoints optimal every projection. second notion requires fixed assignmentoptimal projections maximum preference value greater ,yield preference 6< cases.635fiROSSI , V ENABLE ,& YORKE -S MITHDefinition 21 (Optimal Strong Controllability) STPPU P Optimally Strongly Controllable(OSC) iff viable execution strategy s.t.1. [S(P1 )]x = [S(P2 )]x , P1 , P2 P roj(P ) every executable time-point x;2. S(P ) OptSol(P ), P P roj(P ). 2words, STPPU OSC fixed control sequence works possiblesituations optimal them. definition, optimal meansassignment agent choose executable time-points could yield higher preferencesituation. Since powerful restriction, mentioned before, instead lookreaching certain quality threshold:Definition 22 (-Strong Controllability) STPPU P -Strongly Controllable (-SC),preference, iff viable strategy s.t.1. [S(P1 )]x = [S(P2 )]x , P1 , P2 P roj(P ) every executable time-point x;2. S(P ) OptSol(P ),P P roj(P ) 6 s0 OptSol(P ) pref (s0 ) > ;3. pref (S(P )) 6< otherwise.2words, STPPU -SC fixed control sequence works situations results optimal schedules situations optimal preference levelprojection > schedule preference smaller cases.4.2 Weak Controllability PreferencesSecondly, extend similarly least restrictive notion controllability. Weak Controllability requires existence solution possible situation, possibly different one situation.extend definition requiring existence optimal solution every situation.Definition 23 (Optimal Weak Controllability) STPPU P Optimally Weakly Controllable(OWC) iff P P roj(P ) strategy s.t. (P ) optimal solution P .2words, STPPU OWC if, every situation, control sequence resultsoptimal schedule situation.Optimal Weak Controllability STPPU equivalent Weak Controllability corresponding STPU obtained ignoring preferences, formally prove Section 6.reason projection P least one solution must optimal solution.Moreover, STPPU underlying STPU either WC not. Hencemake sense define notion -Weak Controllability.4.3 Dynamic Controllability PreferencesDynamic Controllability (DC) addresses ability agent execute schedule choosingincrementally values assigned executable time-points, looking past.preferences available, desirable agent acts way guaranteedconsistent possible future outcome also way ensures absence regretsw.r.t. preferences.636fiU NCERTAINTYSOFT TEMPORAL CONSTRAINT PROBLEMSDefinition 24 (Optimal Dynamic Controllability) STPPU P Optimally Dynamically Controllable (ODC) iff viable strategy P 1 , P2 P roj(P ) executabletime-point x:1. [S(P1 )]<x = [S(P2 )]<x [S(P1 )]x = [S(P2 )]x ;2. S(P1 ) OptSol(P1 ) S(P2 ) = OptSol(P2 ).2words, STPPU ODC exists means extending current partial controlsequence complete control sequence future way resulting scheduleoptimal. before, also soften optimality requirement preference reachingcertain threshold.Definition 25 (-Dynamic Controllability) STPPU P -Dynamically Controllable (-DC)iff viable strategy P 1 , P2 P roj(P ) every executable time-point x:1. [S(P1 )]<x = [S(P2 )]<x [S(P1 )]x = [S(P2 )]x ;2. S(P1 ) OptSol(P1 ) S(P2 ) OptSol(P2 ) 6 s1 OptSol(P1 ) pref (s1 ) >6 s2 OptSol(P2 ) pref (s2 ) > ;3. pref(S(P1 )) 6< pref(S(P2 )) 6< otherwise.2words, STPPU -DC means extending current partial controlsequence complete sequence; optimality guaranteed situations preference6> . projections resulting dynamic schedule preference smaller.4.4 Comparing Controllability Notionsconsider relation among different notions controllability STPPUs.Recall STPUs, SC = DC = W C (see Section 2). start giving similarresult holds definitions optimal controllability preferences. Intuitively,single control sequence optimal situations, clearly executeddynamically, assigning values control sequence current time reaches them.Moreover if, whatever final situation be, know consistently assign valuesexecutables, looking past assignments, never backtrack preferences,clear every situation least optimal solution.Theorem 1 STPPU P OSC, ODC; ODC, OWC.Proofs theorems given appendix. opposite implications Theorem 1hold general. fact sufficient recall hard constraints special case softconstraints use known result STPUs (Morris et al., 2001).examples consider following two, defined fuzzy semiring. Figure 9 showsSTPPU OWC ODC. is, fact, easy see assignment C,projection STPPU consistently extended assignment B. However,show Section 7 STPPU depicted ODC.637fiROSSI , V ENABLE ,& YORKE -S MITH11 10.90.80.70.60.5x=3 45 6789 10=yCcontingent10.91 1 10.90.80.90.80.80.70.70.70.60.60.6p=3 4 56 7=qrequirement constr.u=4 3 2 1Bcontingent constr.0 123contingent timepointexecutable timepointFigure 9: STPPU OWC ODC.112C1213B1requirement constr.contingent constr.contingent timepointexecutable timepointFigure 10: STPPU ODC OSC.638456=vfiU NCERTAINTYSOFT TEMPORAL CONSTRAINT PROBLEMSFigure 10, instead, shows ODC STPPU OSC. B two executable timepoints C contingent time-point. two projections, say P 1 P2 , corresponding respectively point 1 point 2 AC interval. optimal preference level 1.fact, hA = 0, C = 1, B = 2i solution P 1 preference 1 hA = 0, C = 2, B = 3isolution P2 preference 1. STPPU ODC. fact, dynamic strategyassigns B value 2, C occurs 1, value 3, C occurs 2 (assuming always assigned0). However single value B optimal scenarios.Similar results apply case -controllability, following formal treatment shows.Theorem 2 given preference level , STPPU P -SC -DC.Again, converse hold general. example consider STPPU shownFigure 10 = 1. Assuming = 1, STPPU 1-DC but, shown above,1-SC.Another useful result controllability property holds given preference level, say ,holds also < , stated following theorem.Theorem 3 Given STPPU P preference level , P -SC (resp. -DC), -SC(resp. -DC), < .Let us consider case preference set totally ordered. eliminateuncertainty STPPU, regarding contingent time-points executables, obtainSTPP. STPP solved obtaining optimal preference value opt. preference level,opt, useful relate optimal controllability -controllability. stated followingtheorem, STPPU optimally strongly dynamically controllable satisfiescorresponding notion -controllability = opt.Theorem 4 Given STPPU P defined c-semiring totally ordered preferences, let opt =maxT Sol(P ) pref (T ). Then, P OSC (resp. ODC) iff opt-SC (resp. opt-DC).OWC, formally prove Section 6 STPPU OWC iff STPU obtainedignoring preference functions WC. relation min -controllabilitycontrollability without preferences, recall considering elements intervals mappedpreference min coincides definition considering underlying STPU obtainedignoring preference functions STPPU. Thus, min -X holds iff X holds, X eitherSC DC.Figure 11 summarize relationships holding among various controllability notionspreferences totally ordered. instead partially ordered, relationshipsopt X min X, X controllability notion, make sense. fact,partially ordered case, several optimal elements several minimal elements,one.5. Determining Optimal Strong Controllability -Strong Controllabilitynext sections give methods determine levels controllability hold STPPU.Strong Controllability fits off-line scheduling allowed, sense fixed optimalcontrol sequence computed execution begins. approach reasonable planning639fiROSSI , V ENABLE ,& YORKE -S MITHOSCODC/ opt-SC/ opt-DC/ -SC/ -DC/ min -SC/ min -DCOWC/ SC/ DC/ WCFigure 11: Comparison controllability notions total orders. min smallest preferenceconstraint: opt min .algorithm knowledge possible outcomes, agents preferences.situation requires us find fixed way execute controllable events consistentpossible outcome uncontrollables give best possible final preference.5.1 Algorithm Best-SCalgorithm described section checks whether STPPU OSC. OSC,algorithm detect also return highest preference level problem-SC.algorithms present paper rely following tractability assumptions,inherited STPPs: (1) underlying semiring fuzzy semiring F CSP defined Section 2.2, (2) preference functions semi-convex, (3) set preferences [0, 1] discretized finite number elements according given granularity.algorithm Best-SC based simple idea: preference level , findscontrol sequences guarantee strong controllability projections optimalpreference , optimality optimal preference . Then, keepscontrol sequences preference levels > .pseudocode shown Figure 12. algorithm takes input STPPU P (line 1).first step, lowest preference min computed. Notice that, efficiently, analyticalstructure preference functions (semi-convexity) exploited.line 3 STPU obtained P cutting preference level min considered.STPU obtained applying function min -Cut(STPPU G) G=P 5 . general, result-Cut(P ) STPU Q (i.e., temporal problem uncertainty preferences) definedfollows:Q variables domains P;every soft temporal constraint (requirement contingent) P variables X , Xj ,say c = hI, f i, is, Q , simple temporal constraint variables defined{x I|f (x) }.Notice semi-convexity preference functions guarantees set {x I|f (x) }forms interval. intervals Q contain durations requirement contingent eventslocal preference least .5. Notice function -Cut applied STPPs STPPUs: first case output STP,latter case STPU. Notice also that, -Cut known concept fuzzy literature.640fiU NCERTAINTYSOFT TEMPORAL CONSTRAINT PROBLEMSPseudocode Best-SC1. input STPPU P ;2. compute min ;3. STPU Qmin min -Cut(P );4. (StronglyControllable (Qmin ) inconsistent) write min -SC stop;5. else {6. STP P min StronglyControllable (Qmin );7. preference min + 1;8. bool OSCfalse, bool -SCfalse;9. {10.STPU Q -Cut(P );11.(PC(Q ) inconsistent) OSCtrue;12.else {13.(StronglyControllable(PC(Q )) inconsistent) -SC true;14.else {N15.STP P P 1StronglyControllable(PC(Q )) ;16.(P inconsistent) { -SC true };17.else { + 1 };18.}19.}20.}while (OSC=false -SC=false);21. (OSC=true) write P OSC;22. (-SC=true) write P ( 1) -SC;23. se =Earliest-Solution(P 1 ), sl =Latest-Solution(P 1 );24. return P 1 , se , sl ;25. };Figure 12: Algorithm Best-SC: tests STPPU OSC finds highestSTPPU P -SC.641fiROSSI , V ENABLE ,& YORKE -S MITHSTPU Qmin obtained, algorithm checks strongly controllable. STPobtained applying algorithm StronglyControllable (Vidal & Fargier, 1999) STPU Q minconsistent, then, according Theorem 3, hope higher preference, algorithm stop (line 4), reporting STPPU -SC 0 thus OSC well.If, instead, inconsistency found, Best-SC stores resulting STP (lines 5-6) proceedsmoving next preference level min + 1 6 (line 7).remaining part algorithm (lines 9-21), three steps performed preferencelevel considered:Cut STPPU P obtain STPU Q (line 10);Apply path consistency Q considering STP: PC(Q ) (line 11);Apply strong controllability STPU PC(Q ) (line 13).Let us consider last two steps detail.Applying path consistency STPU Q means considering STP, is, treating contingent constraints requirement constraints. denote algorithm PC algorithm enforcingpath-consistency temporal network (see Section 2.1 Dechter et al., 1991). returnsminimal network leaving intervals values contained least one solution.allows us identify situations, , correspond contingent durations locallypreference consistent least one control sequence elements Q .words, applying path consistency Q leaves contingent intervals durationsbelong situations corresponding projections optimal value least .test gives inconsistency, means given STPU, seen STP, solution,hence projections corresponding scenarios STPPU P optimal preference <(line 11).third last step applies StronglyControllable path-consistent STPU PC(Q ), reintroducing information uncertainty contingent constraints. Recall algorithmrewrites contingent constraints terms constraints executable time-points.STPU strongly controllable, StronglyControllable leave requirement intervalselements identify control sequences consistent possible situation. case,applying StronglyControllable PC(Q ) find, any, control sequences PC(Q )consistent possible situation PC(Q ).However, STPU PC(Q ) strongly controllable, control sequences found mightoptimal scenarios optimal preference lower . order keepcontrol sequences guarantee optimal strong controllability preference levels ,STP obtained StronglyControllable(PC(Q )) intersected corresponding STP foundprevious step (at preference level 1), P 1 (line 15). recall given twotwo STPs, P1 P2 , defined set variables, STP P3 = P1 P2variables P1 P2 temporal constraint, c3ij = c1ij c2ij , intersectioncorresponding intervals P1 P2 . intersection becomes empty constraintSTP obtained inconsistent, conclude control sequence guaranteestrong controllability optimality preference level and, time, preferences6. writing min + 1 mean next preference level higher min defined terms granularitypreferences [0,1] interval.642fiU NCERTAINTYSOFT TEMPORAL CONSTRAINT PROBLEMSTable 1: table row corresponds preference level represents intervalsSTPU Q obtained cutting STPPU Figure 8 level .STPU(SC EC)(SC SA)(SA EC)Q0.5Q0.6Q0.7Q0.8Q0.9Q1[1, 8][1, 7][1, 6][1, 5][1, 4][1, 2][1, 5][1, 5][1, 5][1, 5][1, 5][1, 3][6, 4][6, 4][5, 2][4, 1][3, 0][2, 1]Table 2: table row corresponds preference level represents intervalsSTPU PC(Q ) obtained applying path consistency STPUs Table 1.STPU0.5PC(Q )PC(Q0.6 )PC(Q0.7 )PC(Q0.8 )PC(Q0.9 )PC(Q1 )(SC EC)(SC SA)(SA EC)[1, 8][1, 7][1, 6][1, 5][1, 4][1, 2][1, 5][1, 5][1, 5][1, 5][1, 5][2, 3][4, 4][4, 4][4, 2][4, 1][3, 0][2, 1]< (line 16). If, instead, STP obtained consistent, algorithm Best-SC considers nextpreference level, + 1, performs three steps again.output algorithm STP, P 1 , obtained iteration previous onecausing execution stop (lines 23-24) two solutions, e sl . STP,show shortly, contains control sequences guarantee -SC = 1.1 highest preference level cutting gives consistent problem, STPPUOSC. solutions provided algorithm respectively earliest, e , latest, sl ,solutions P 1 . fact, proved (Dechter et al., 1991) mentioned Section 2.1, sinceP 1 minimal, earliest (resp. latest) solution corresponds assigning variablelower (resp. upper) bound interval constraint defined X0 variable.indicated algorithm procedures Earliest-Solution Latest-Solution. Let us also recallevery solution found P 1 without backtracking.formally proving correctness algorithm Best-SC, give example.Example 5 Consider STPPU described Example 4, depicted Figure 8. simplicityfocus triangular sub-problem variables SC, SA, EC. example, min = 0.5.Table 1 shows STPUs Q obtained cutting problem preference level = 0.5, . . . , 1.Table 2 shows result applying path consistency (line 11) STPUs shownTable 1. seen, STPUs consistent. Finally, Table 3 shows STPs definedexecutable variables, SC SA, obtained applying StronglyControllableSTPUs Table 2.643fiROSSI , V ENABLE ,& YORKE -S MITHTable 3: table row corresponds preference level represents intervalsSTP StronglyControllable PC(Q ) obtained applying strong controllability checkSTPUs Table 2.(SC SA)STP0.5StronglyControllable(PC(Q ))StronglyControllable(PC(Q0.6 ))StronglyControllable(PC(Q0.7 ))StronglyControllable(PC(Q0.8 ))StronglyControllable(PC(Q0.9 ))StronglyControllable(PC(Q1 ))[4, 5][3, 5][4, 5][4, 5][4, 4][3, 3]looking Tables 2 3 easy deduce Best-SC stop preference level1. fact, looking carefully Table 3, see STP P 0.9 consists interval [4, 4]constraint SC SA, StronglyControllable(PC(Q 1 )) consist interval [3, 3]constraint. Obviously intersecting two gives inconsistency, causing conditionline 16 Figure 12 satisfied.conclusion executing Best-SC example depicted Figure8 0.9-SCOSC. Let us see correct. Without loss generality assume SCassigned value 0. last line Table 3 observe value assignedSA optimal scenarios optimal preference 1 (that EC assigned1 2) 3. However, assigning 3 SA optimal EC happens 6, since scenariooptimal preference value 0.7 (e.g. SA assigned 5) case would globalpreference 0.6 (given constraint SA EC) 7 .25.2 Properties Best-SCprove algorithm Best-SC correctly identifies whether STPPU P OSC, and,not, finds highest preference level P -SC. Let us first consider eventsBest-SC stops.Event 1. StronglyControllable(Q min ) inconsistent (line 4);Event 2. PC(Q ) returns inconsistency (line 11);Event 3. PC(Q ) consistent strongly controllable (line 13);Event 4. PC(Q ) strongly controllable, however intersection STP obtainedStronglyControllable(PC(Q )) STP obtained previous preference level,P 1 , inconsistent (line 16).First notice algorithm terminates.Theorem 5 Given STPPU P finite number preference levels, execution algorithm Best-SC P terminates.7. Recall fuzzy semiring context global preference assignment computed taking minimumpreference assigned projections.644fiU NCERTAINTYSOFT TEMPORAL CONSTRAINT PROBLEMSIntuitively, either one termination events occur preference levels exhausted.Next, let us show Best-DC sound complete algorithm checking STPPUOSC finding highest preference level -SC.said before, cutting STPPU P preference level gives STPU Q .Moreover, every situation = {1 , . . . , l } Q seen situation Pfj (j ) , j. implies every projection P P roj(Q ), STP, corresponds projection P P roj(P ) STPP. situations Q , followswrite always P interpreted STP seen projection QSTPP seen projection P . following lemmas state propertiesrelate solutions projections two contexts: without preferences.Theorem 6 Consider STPPU P = hNe , Nc , Lr , Lc , SF CSP preference level , consider STPU Q = hNe , Nc , L0r , L0c obtained cutting P , STPU PC(Q )=hNe , Nc ,L00r , L00c i. Then:1. situation P , P P roj(PC(Q )) iff optP (P ) ;2. every control sequence , solution = StronglyControllable(PC(Q ), iff PProj(PC (Q )), T, Sol(P ) pref (T, ) .first part theorem states that, applying path consistency STPU Q , removesituations cannot extended complete solutions Q , thus correspond projections optimal preference strictly less . second part lemma considersSTP obtained applying StronglyControllable path consistency. particular statedsolutions result, projections PC (Q ), solutions preferenceleast . Notice implies result optimal solutions projections Poptimal preference exactly . might optimal, however, projectionsoptimal preference strictly greater .theorem, get following corollary, clarifies relationSTPU obtained cutting STPPU preference level , -SC STPPU.Corollary 1 Consider STPPU P preference level assume , situation P ,opt(P ) , P corresponding projection. Then, STPU PC(Q ), obtainedcutting P , applying path consistency, SC P -SC.consider preference levels min , compute correspondingSTPs, say min , . . . , , STP identify assignments executable variables guaranteeing strong controllability optimality level. intersecting STPs keepcommon solutions thus guarantee strong controllability optimalitysituations P optimal preference smaller equal .Theorem 7 Consider STPPU P , preference levels min , assumecorresponding STPs, min , . . . , obtained cutting P preference levels Nmin , . . . , ,enforcing strong controllability consistent. Then, Sol(P ), P = i=min ,..., ,iff P P roj(P ): T, Sol(P ), opt(P ) , pref (T, ) = opt(P ), otherwisepref (T, ) .645fiROSSI , V ENABLE ,& YORKE -S MITHconsider events Best-SC stop provestrong controllability properties hold.Theorem 8 execution algorithm Best-SC STPPU P stops due occurrenceEvent 1 (line 4), P -SC 0.case underlying STPU obtained STPPU ignoring preferencefunctions strongly controllable. Since cutting higher preferences give even smallerintervals hope controllability level execution halt.Theorem 9 execution algorithm Best-SC STPPU P stops due occurrenceEvent 2 (line 11) preference level ,1 = opt = maxT Sol(P ) pref (T );P OSC control sequence solution STP P opt (returned algorithm) iffoptimal scenario P .event occurs algorithm cuts STPPU given preference level STPUobtained, seen STP, inconsistent. particular, means projection P roj(P )optimal preference equal greater preference level. However, levelreached, previous level, assignments guaranteeing SC optimalityfound. Moreover, previous level must also highest preference solutionP , opt(P ). means opt(P )-SC established, Theorem 4 equivalentOSC.Theorem 10 execution algorithm Best-SC STPPU P stops due occurrenceEvent 3 (line 13) Event 4 (line 16) preference level , P OSC ( 1)SC solution STP P 1 (returned algorithm) that, P P roj(P ):T, Sol(P ), opt(P ) 1, pref (T, ) = opt(P ), otherwise pref (T, ) 1.Intuitively, algorithm reaches stops line 13, projections Poptimal preference corresponding set situations SC. Notice exactlysituation considered Corollary 1. instead stops line 16, set situations SC,none assignments guaranteeing SC situations optimalsituations preference levels . cases problem -SC. However, assumingfirst level execution stopped problem 1-SC.conclude section considering complexity Best-SC.Theorem 11 Determining OSC highest preference level -SC STPPU nvariables ` preference levels achieved time O(n 3 `).Notice cannot use binary search preference levels (in contrast algorithmsSTPPs), since correctness procedure based intersection result obtainedgiven preference level, , obtained preference levels < .theorem allows us conclude cost adding preferences, thus considerable expressive power, low. fact, complexity still polynomial grownfactor equal number preference levels.646fiU NCERTAINTYSOFT TEMPORAL CONSTRAINT PROBLEMS6. Determining Optimal Weak ControllabilityOptimal Weak Controllability least useful property practice also propertyadding preferences smallest impact terms expressiveness. OWC requiresexistence optimal solution every possible scenario. equivalent requiringexistence solution every situation, stated following theorem.Theorem 12 STPPU P OWC iff STPU Q, obtained simply ignoring preference functions constraints WC.ignoring preference functions mean mapping soft constraint hI, f hardconstraint hIi defined variables. theorem allows us conclude that, checkOWC, enough apply algorithm WeaklyControllable proposed (Vidal & Ghallab, 1996)described Section 2. If, instead, given scenario , find optimalsolution projection, STPP P roj(), using one solvers described (Rossi et al.,2002).Let us consider Example 4 again. Section 5 showed STPU obtained cuttingSTPPU Figure 8 preference level min strongly controllable. Since SC implies WC,conclude STPU weakly controllable and, thus, STPPU Figure 8 OptimallyWeakly Controllable.7. Determining Optimal Dynamic Controllability -Dynamic ControllabilityOptimal Dynamic Controllability (ODC) interesting useful property practice.described Section 1, many industrial applications solved dynamic fashion,making decisions response occurrences events execution plan.true space application domains, planning mission handled decomposingproblem set scheduling subproblems, depend occurrence semipredictable, contingent events (Frank et al., 2001).section describe algorithm tests whether STPPU P ODC and, ODC,finds highest P -DC. algorithm presented bears similaritiesBest-SC, sense decomposes problem STPUs corresponding different preferencelevels performs bottom search dynamically controllable problems space.Notice algorithm attractive also practice, since output minimal formproblem assignments belonging least one optimal solution left domainsexecutable time-points. minimal form given input execution algorithm,also describe, assigns feasible values executable time-points dynamicallyobserving current situation (i.e., values contingent time-points occurred).7.1 Necessary Sufficient Condition Testing ODCdefine necessary sufficient condition ODC, defined intervalsSTPPU. propose algorithm tests condition, showsound complete algorithm testing ODC.first claim that, given STPPU, dynamic controllability STPUs obtainedcutting STPPU applying PC every preference level necessary sufficientcondition optimal dynamic controllability given STPPU.647fiROSSI , V ENABLE ,& YORKE -S MITHTheorem 13 Given STPPU P , consider preference level STPU Q , obtainedcutting P , consistent. STPU PC(Q ) DC P ODC -DC,.Unfortunately condition sufficient, since STPPU still ODC evenevery preference level STPU obtained PC DC. example shown Figure 9described below.Example 6 Another potential application STPPUs scheduling aircraft analysis airborneparticles (Coggiola, Shi, & Young, 2000). example consider aircraft equippedinstruments Small Ice Detector Nevzorov probe, used discriminate liquid ice given types clouds. analysis important predictionevolution precipitatory systems occurrence severity aircraft icing (Field,Hogan, Brown, Illingworth, Choularton, Kaye, Hirst, & Greenaway, 2004). instruments needuncertain amount time determine predominant state, liquid ice,activated inside cloud.example shown Figure 9 consider sensing event represented variablesC start time maneuver aircraft represented variable B. Dueinstruments function, aircraft maneuver impact analysis. example constraint ACrepresents duration sensing event preference function models factearlier predominant state determined better. Constraint AB models instead factmaneuver start soon possible, example, due time constraints imposedaircrafts fuel availability. Constraint BC models fact maneuver ideally startsensing event ended.Let us call P STPPU depicted Figure 9. order determine highest preference levelschedule P can, example use algorithm Chop-solver (Rossi et al., 2002).highest preference level cutting functions gives consistent STP 1 (interval [3, 3]AB, [3, 5] AC interval [0, 2] BC consistent STP). optimal solutions P , regardedSTPP, global preference 1.Consider STPUs obtained cutting every preference level highest, 1,lowest 0.5. minimum preference constraint P min = 0.5 and, easy see,STPUs obtained cutting P applying PC preference levels 0.5 1DC. However, P ODC. fact, dynamic assignment B belongs optimalsolution projections corresponding elements 3, 4 5 [x, y] 3. executing B 3cause inconsistency C happens 10, since 10 3 = 7 doesnt belong [u, v].2elaborate example find sufficient condition ODC. Consider intervalsAB, [p , q ], waits < C, > obtained applying DC checking algorithm preferencelevel . shown Table 4.look first last intervals, resp., = 1 = 0.5, way assignvalue B time induces preference 1 constraints AB BC, C occurs 3, 45, also satisfies wait < C, 4 >, ensuring consistency C occurs 10. dependsfact intersection [p 1 , q 1 ], i.e., [3], sub interval [p 0.5 , q 0.5 ] satisfies< C, 4 >, is, [4, 7], empty.claim non-emptiness intersection, together DC STPUsobtained cutting problem preference levels necessary sufficient condition648fiU NCERTAINTYSOFT TEMPORAL CONSTRAINT PROBLEMSTable 4: table row corresponds preference level represents correspondinginterval wait AB constraint STPPU shown Figure 9.[p , q ]wait10.90.80.70.60.5[3, 3][3, 4][3, 5][3, 6][3, 7][3, 7]< C, 3 >< C, 3 >< C, 3 >< C, 3 >< C, 4 >ODC. following section describe algorithm tests condition. Then,Section 7.3, prove algorithm sound complete w.r.t. testing ODCfinding highest level -DC.7.2 Algorithm Best-DCalgorithm Best-DC echoes Section 5s algorithm checking Optimal Strong Controllability.done Best-SC, considers STPUs obtained cutting STPPU various preferencelevels. preference level, first tests whether STPU obtained considering STPpath consistent. Then, checks path consistent STPU obtained dynamically controllable,using algorithm proposed (Morris et al., 2001). Thus, control sequences guaranteeDC scenarios different optimal preferences found. next step selectsequences satisfy DC requirement optimal preference levels.pseudocode given Figure 13. Algorithm Best-DC takes input STPPU P (line 1)computes minimum preference, min , assigned constraint (line 2).min known, STPU obtained cutting P min computed (line 3).STPU seen STPPU P variables intervals constraints Ppreferences. STPU, denoted Q min , given input algorithmDynamicallyControllable. Qmin dynamically controllable, P ODC DC (for min , hence ), shown Theorem 13. algorithm detectsinconsistency halts (line 4). If, instead, Q min dynamically controllable, STPUreturned output DynamicallyControllable saved denoted P min (line 6). NoticeSTPU minimal, sense intervals elements belongingleast one dynamic schedule (Morris et al., 2001). addition, since preferences,elements requirement intervals, well belonging least one dynamic schedule,part optimal schedules scenarios projection optimal preference equalmin 8 .line 7 preference level updated next value ordering considered (according given preference granularity). line 8 two Boolean flags, ODC -DCdefined. Setting flag ODC true signal algorithm established problem ODC, setting flag -DC true signal algorithm found highestpreference level STPPU -DC.8. fact, preference least min definition.649fiROSSI , V ENABLE ,& YORKE -S MITHPseudocode Best-DC1. input STPPU P ;2. compute min ;3. STPU Qmin min -Cut(P );4. (DynamicallyControllable(Q min ) inconsistent) write min -DC stop;5. else {6. STP P min DynamicallyControllable(Qmin );7. preference min + 1;8. bool ODC false, bool -DC false;9. {10.STPU Q -Cut(P );11.(PC(Q ) inconsistent) ODC true;12.else {13.(DynamicallyControllable(PC(Q )) inconsistent) -DC true;14.else {15.STPU DynamicallyControllable(PC(Q ));16.if(Merge(P 1 , ) FAILS) { -DC true }17.else {18.STPU P Merge(P 1 , );19.+ 1;20.};21.};22.};23. }while (ODC=false -DC=false);24. (ODC=true) write P ODC;25. (-DC=true) write P ( 1) -DC;26. return STPPU F 1 resulting STPPU(P ,P 1 );27. };Figure 13: Algorithm tests STPPU ODC and, not, finds highest STPPUP -DC.650fiU NCERTAINTYSOFT TEMPORAL CONSTRAINT PROBLEMSPseudocode Merge1. input (STPU , STPU +1 );2. STPU P +1 ;3. constraint AB, B executables, P +1define interval [p0 , q 0 ] wait t0 ,given { interval [p , q ], wait }{ interval [p+1 , q +1 ], wait t+1 +1 }, follows:;4. (t = p t+1 = p+1 ) (Precede - Precede)5. p0 max(p , p+1 ), q 0 min(q , q +1 ), t0 max(t , t+1 );6. (q 0 < p0 ) return FAILED;7. (p < < q p+1 t+1 < q +1 ) (Unordered - Unordered Precede)8. t0 max(t , t+1 ), q 0 min(q , q +1 );9. (q 0 < t0 ) return FAILED;10. output P +1 .Figure 14: Algorithm Merge.Lines 9-25 contain main loop algorithm. short, time loop executed,cuts P current preference level looks cutting produced path consistent STPU(seen STP). so, checks path consistent version STPU also dynamicallycontrollable and, also test passed, new STPU created merging currentresults previous levels.describe step detail. Line 10 cuts P current preference level . line 11consistency STPU Q tested applying algorithm PC. PC returns inconsistency,conclude P schedule preference (or greater).next step check STPU PC(Q ) DC. Notice required preferencelevels optimal level order P ODC, order P -DC(Theorem 13). applying algorithm DynamicallyControllable detects PC(Q ) dynamically controllable, algorithm sets flag -DC true. If, instead, PC(Q ) dynamicallycontrollable resulting minimal STPU saved denoted (line 15).line 16, output procedure Merge tested. procedure used combineresults preference 1 preference , applying STPU obtainedend previous iteration, P 1 , STPU . pseudocode Mergeshown Figure 14, describe detail shortly. inconsistency found, newSTPU obtained merging procedure denoted P (line 18) new preference levelconsidered (line 19).Lines 24-27 take care output. Lines 24 25 write output P ODC or, not,highest -DC. line 27 final STPPU, F , given output, obtainedSTPU P 1 , is, STPU obtained last iteration cyclecompleted success (i.e., reached line 20). Function Resulting STPPU restorespreferences intervals P 1 setting P . showrequirement constraints F contain elements corresponding dynamic schedulesalways optimal, result P ODC, optimal scenarios correspondingprojections optimal preference guarantee global preference level leastothers, result P -DC.651fiROSSI , V ENABLE ,& YORKE -S MITHpseudocode procedure Merge given Figure 14. input consists two STPUsdefined set variables. describing Merge works, assume giveninput two STPUs, +1 , obtained cutting two STPPUs preference levels + 1applying, hypothesis success, PC DynamicallyControllable (line 1 Figure 14).line 2, Merge initializes STPU given output . formally proven Theorem 14, due semi-convexity preference functionsP roj(T +1 ) P roj(T ). Notice Merge leaves contingent constraints unaltered. Thus,projection optimal preference + 1 contained set projections P +1 .Merge considers every requirement constraint defined two executables, say B,respectively +1 . Since assuming algorithm DynamicallyControllableapplied STPUs, waits intervals. Figure 6 illustrates threecases interval AB be. wait expires upper bound interval(Figure 6 (a)), execution B must follow execution every contingent time-point(Follow case). wait coincides lower bound interval (Figure 6 (b)),execution B must precede contingent time-point (Precede case). Finally, shownFigure 6 (c), wait within interval, B Unordered case leastcontingent time-point, say C.Merge considers case corresponding intervals +1 (line 3).intervals respectively indicated [p , q ], wait , [p+1 , q +1 ], wait t+1 .Merge obtains new interval [p0 , q 0 ] new wait t0 , replace old wait +1 .Interval [p0 q 0 ] contain values projections AB constraintoptimal solution STPP corresponding situation +1 . Wait t0 waitrespected dynamic execution order guarantee solution obtainedoptimal, projection corresponding final scenario preference + 1.Due semi-convexity preference functions cannot case that:AB Follow Precede case Unordered case +1 ;AB Follow case Precede case +1 ;AB Precede case Follow case +1 ;means cases considered are:AB Follow case +1 ;AB Precede case +1 ;AB Unordered case Precede Unordered case +1 ;first two cases AB interval left T+1 . formal motivationcontained proof Theorem 14. However, informally, say AB interval+1 already satisfies desired property.lines 4 5 case AB Precede case STPUs examined. Here, Balways occur contingent time-point. values [p , q ] (resp. [p+1 , q +1 ])assignments B consistent future occurrence C mapped preference (resp. + 1). Clearly intersection taken order lower652fiU NCERTAINTYSOFT TEMPORAL CONSTRAINT PROBLEMSpreference C occurs preference + 1. Line 6 considers event intersection empty. means common assignment B, given A,optimal scenarios optimal preference scenarios optimal preference + 1.lines 7 8 two scenarios considered: AB Unordered casePrecede case +1 AB Unordered case STPUs. Figure 15shows second case. Merge takes union parts intervals preceding waitintersection parts following wait. intuition underlying executionB identifying element either [p , [ [p+1 , t+1 [ preceded executioncontingent time-points wait. means B executed,contingent time-point C, time C executed, say C ,associated preference, say fAC (tC ), constraint AC STPPU P known. propagationinformation allow us identify elements [p , [ (resp. [p+1 , t+1 [)preference fAC (tC ) thus optimal assignment B. means elementsinterval [p , [ interval [p+1 , t+1 [ eligible chosen. example, f AC (tC ) =might values B preference equal optimal case wouldC occurred time fAC (tC ) > . since case knowpreference C occurred, propagation step prune non-optimal choices B.short, leaving elements allows flexibility propagation step. Moreover,proven Theorem 14, p p+1 .instead consider elements interval [t , q ], know identify assignmentsB executed regardless C happen (however know happenpreference greater ). means must take intersection partcorresponding one, [t+1 , q +1 ], order guarantee consistency optimality alsoC occurs time preference = + 1. easy way see interval [t , q ]may contain elements P mapped preference . elements optimalscenarios C happens time associated preference = AC constraint;however, cannot optimal scenarios C occurring time preference + 1.Line 9 handles case two parts intervals, following waits,empty intersection. case, optimality cannot guaranteed neither level + 1,particular contingent events occur waits expire.7.3 Properties Best-DCshow Best-DC sound complete algorithm testing ODC findinghighest preference level STPPU given input -DC. recall, more,results follow rely tractability assumptions requiring semi-convex preferencefunctions fuzzy semiring h[0, 1], max, min, 0, 1i underlying structure.Let us consider STPPU P STPUs +1 , defined previous section. Then,STPU P +1 =Merge (T , +1 ) contingent constraints 9 requirement constraints defined merging procedure. start proving Merge soundcomplete algorithm testing existence viable dynamic strategy, commonSTPUs, optimal projections optimal preference equal either + 1.9. recall projections coincide projections STPPU P optimal preference (seeTheorem 6), that, due semi-convexity preference functions, P roj(T +1 ) P roj(T ).653fiROSSI , V ENABLE ,& YORKE -S MITHInterval ABSTPU +1Interval ABSTPU(a)+1+1+1pqpqMerged interval ABp(b)+1(c)qFigure 15: Merging two intervals Unordered case.Theorem 14 Consider STPPU P STPUs, +1 , obtained cutting P respectivelylevel + 1 applying PC, without finding inconsistencies, DynamicallyControllablesuccess. Consider STPU P +1 = Merge(T , +1 ).Then, Merge(T , +1 ) failP +1 dynamically controllableviable dynamic strategy every projection P P roj(P +1 ),opt(Pi ) = opt(Pi ) = + 1 P , pref (S(Pi )) = opt(Pi );otherwise pref (S(Pi )) + 1.following theorem extends result merging procedure two preferencelevels, particular preference levels smaller equal given threshold .Theorem 15 Consider STPPU P every preference level, , define STPU obtainedcutting P , applying PC DynamicallyControllable. Assume ,DC. Consider STPU P :P = Merge(Merge(. . . Merge(Merge(T min , min +1 ), min +2 ), . . . ), )min minimum preference constraint P. Assume that, applied, Mergealways returned consistent STPU. Then, viable dynamic strategy S, PP roj(P ), opt(Pi ) S(Pi ) optimal solution Pi , otherwise pref (S(Pi )) + 1.Theorem 15 allows us prove main result. Informally, Best-DC applies Mergelowest preference highest threshold , returned problem becomes inconsistent. projection STPPU optimal solution higher , then, usingTheorem 15, conclude STPPU ODC; otherwise -DC.Let us start enumerating conditions Best-DC terminates:654fiU NCERTAINTYSOFT TEMPORAL CONSTRAINT PROBLEMSEvent 1. Best-DC stops STPU obtained level min DC (line 4);Event 2. Best-DC exits reached preference level STPU (seenSTP) path consistent (line 11);Event 3. Best-DC stops reached preference level path consistent STPU dynamically controllable (line 13);Event 4. Best-DC stops procedure Merge found inconsistency (line 16).following theorem shows execution Best-DC always terminates.Theorem 16 Given STPPU P, execution algorithm Best-DC P terminates.Best-DC considers preference level, starting lowest moving timeone level according granularity preference set. stops either inconsistencyfound levels, assumed finite, precessed.ready prove soundness completeness Best-DC. split proofthree theorems, considering different terminating condition. first theorem considerscase underlying STPU obtained P , ignoring preferences, DC.case output STPPU -DC level thus ODC.Theorem 17 Given STPPU P input, Best-DC terminates line 4 iff 6 0 P-DC.next theorem considers case highest preference level reached successmerging procedure also highest optimal preference projection P .case, problem ODC.Theorem 18 Given STPPU P input, Best-DC terminates line 11 iff P ODC.last result considers case least projection optimal preference strictly higher highest reached success merging procedure. caseproblem ODC Best-DC found highest level STPPU -DC.Theorem 19 Given STPPU P input, Best-DC stops lines 13 16 preference level iff P( 1)-DC ODC.mentioned Section 2.3, (Morris & Muscettola, 2005), proven checking DCSTPU done O(n5 ), n number variables. revised algorithm processes distance graph STPU, rather constraint graph. also maintains additionalinformation, form additional labeled edges correspond waits. main featurenew algorithm, noted earlier, strongly polynomial algorithm determiningdynamic controllability STPU. important context stress factoutput two algorithms, presented (Morris et al., 2001) (Morris & Muscettola, 2005),essentially same. fact easy obtain, polynomial time O(n 2 ), constraint graphwaits produced DynamicallyControllable starting distance graph producednew algorithm, vice versa.655fiROSSI , V ENABLE ,& YORKE -S MITHTheorem 20 complexity determining ODC highest preference level -DCSTPPU n variables, bounded number preference levels ` time O(n 5 `).complexity result given Theorem 20 unexpectedly good. fact, shows costadding considerable expressive power preferences STPUs factor equalnumber different preference levels. implies solving optimization problem and,time, controllability problem, remains P, number different preference levelsbounded.7.4 Execution Algorithmexecution algorithm propose similar STPUs presented (Morris et al.,2001), described Section 2 shown Figure 7. course execution algorithmSTPPUs take input STPPU Best-DC successfully applied.line 2 Figure 7, algorithm performs initial propagation starting point. maindifference STPPU execution algorithm STPU algorithm (Morris et al., 2001)definition propagation also involves preferences.Definition 26 (soft temporal propagation) Consider STPPU P variable Pvalue vY D(Y ). propagating assignment = v P , means:constraints, cXY involving X already assigned value v X D(X):replace interval cXY interval h[vY vX , vY vX ]i;cut P preference level minX {fcXY (vY vX )}.2call ODC-Execute algorithm DC-Execute propagation definedDefinition 26. Assume apply ODC-Execute ODC -DC STPPU P Best-DCapplied. If, given time , preference partial schedule ,know P ODC -DC , Theorem 14 Theorem 15, executionalgorithm assigning values +1 . Assume contingent event occurslowers preference 2. propagated STPPU cut preferencelevel 2. on, execution algorithm assign values 2 and, Theorem 14Theorem 15, new waits imposed assignments executablesoptimal situation optimal preference 2. situationsassignments guarantee preference least 2.8. Using AlgorithmsSection 4.4 described relations notions controllability. general strategy,given STPPU, first property consider OSC. holds, solution obtained feasibleoptimal possible scenarios. However, OSC strong property holds infrequently.STPPU OSC, still need control sequence execution begins,Best-SC find best solution consistent possible future situations.commonly, dynamic controllability useful. control sequence needsknown execution begins, ODC ideal. Notice that, results Section 4.4,STPPU may OSC still ODC. If, however, STPPU even ODC,656fiU NCERTAINTYSOFT TEMPORAL CONSTRAINT PROBLEMSBest-DC give dynamic solution highest preference. Recall, shownSection 4.4, given preference level , -SC implies -DC vice versa. Thus,may given STPPU -SC -DC > . -SC means fixedway assign values executables optimal situations optimalpreference give preference least cases. hand, -DCimplies solution obtained dynamically, ODC-Execute algorithm, optimalsituations best solution preference yield preferencecases. Thus, > , using dynamic strategy guarantee optimality situationshigher preference others.last possibility check OWC. least allow executing agent knowadvance situation solution. Moreover, situation revealedexecution begins, using solvers STPPs described (Rossi et al., 2002)allow us find optimal assignment scenario.9. Related Worksection survey work regard closely related ours. Temporal uncertaintystudied before, defined different ways according different contextsused.start considering work proposed Vila Godo (1994). propose Fuzzy Temporal Constraint Networks, STPs interval constraint mappedpossibility distribution. fact, handle temporal uncertainty using possibility theory (Zadeh,1975), using term uncertainty describe vagueness temporal information available.aim model statements called less hour ago, uncertaintylack precise information temporal event. goal thus completely differentours. fact, scenario agent must execute activities certain times,activities constrained temporal relations uncertain events. goal find wayexecute agents control way consistent whatever nature decidesfuture.(Vila & Godo, 1994), instead, assume imprecise temporal information eventshappened past. aim check information consistent, is,contradictions implied study entailed set constraints. order modelimprecise knowledge, possibilities used. Every element interval mappedvalue indicates possible event certain is. Thus, another major differenceapproach consider preferences, possibilities. hand,work presented allow express information possible probable valuecontingent time-point. one lines research want pursue future.Moreover, (Vila & Godo, 1994), concerned classical notion consistency(consistency level) rather controllability.Another work related way handle uncertainty Badaloni Giacomin (2000).introduce Flexible Temporal Constraints soft constraints used express preferencesamong feasible solutions prioritized constraints used express degree necessityconstraints satisfaction. particular, consider qualitative Allen-style temporal relationsassociate relation preference. uncertainty deal timeoccurrence event whether constraint belongs constraint problem.657fiROSSI , V ENABLE ,& YORKE -S MITHmodel, information coming plausibility information coming preferencesmixed distinguishable solver. words, possible say whethersolution bad due poor preference relation due violating constrainthigh priority. approach, instead, uncertainty preferences separated. compatibilityuncertain event change preference assignment executable.robustness temporal uncertainty handled intrinsically different degrees controllability.(Dubois, HadjAli, & Prade, 2003b) authors consider fuzziness uncertainty temporal reasoning introducing Fuzzy Allen Relations. precisely, present extensionAllen relational calculus, based fuzzy comparators expressing linguistic tolerance. Duboiset al. (2003b) want handle situations information dates relative positionsintervals complete but, reason, interest describing precise manner. example, one wants speak terms approximate equality, proximityrather terms precise equality. Secondly, want able deal available information pervaded imprecision, vagueness uncertainty. framework presentedrestrict uncertainty event occur within range. hand, putcomplete ignorance position, would equivalent, context (Duboiset al., 2003b), setting 1 possibilities contingent events. Moreover, (Dubois et al.,2003b) allow preferences address controllability. Instead, consider, similarly(Vila & Godo, 1994), notions consistency entailment. first notion checkedcomputing transitive closure fuzzy temporal relations using inference rules appropriatelydefined. second notion checked defining several patterns inference.Another work addresses also temporal uncertainty presented (Dubois, Fargier, &Prade, 1995) (Dubois, Fargier, & Prade, 2003a). work preferences activitiesill-known durations classical job-shop scheduling problem handled using fuzzyframework. three types constraints: precedence constraints, capacity constraintsdue dates, release time constraints. order model unpredictable events use possibility theory. authors mention (Dubois et al., 1995), possibility distributions viewedmodeling uncertainty well preference (see Dubois, Fargier, & Prade, 1993). Everything depends whether variable X possibility distribution defined controllablenot. Thus Dubois et al. (1995) distinguish controllable uncontrollable variables. However allow specify preferences uncontrollable events. preference functionscontingent constraints would interpreted possibility distributions framework.sense, work complementary theirs. assume constraint possibility distributioncontingent events always equal 1 allow representation informationless possible values; hand, allow specify preferences also uncontrollable events. They, contrary, allow put possibility distributions contingent events,preferences.Finally, Dubois et al. (1995) show scheduling problem uncertain durationsformally expressed kind constraints problem involving call flexibledurations (i.e. durations fuzzy preferences). However interpretation quite different:case flexible durations, fuzzy information comes specifications preferencesrepresents possible values assigned variable representing duration.case imprecisely known durations, fuzzy information comes uncertainty realvalue durations. formal correspondence two constraints closeauthors distinguish among describing solving procedure. Further, problem658fiU NCERTAINTYSOFT TEMPORAL CONSTRAINT PROBLEMSsolve find starting times activities activities take place withinglobal feasibility window whatever actual values unpredictable durations be. Clearlyequivalent Optimal Strong Controllability. address problem dynamicweak controllability preferences.10. Summary Future Workdefined formalism model problems quantitative temporal constraintspreferences uncertainty, generalized formalism three classical notionscontrollability (that is, strong, weak dynamic). focused tractable classproblems, developed algorithms check presence properties.work advances state art temporal reasoning uncertainty since providesway handle preferences context, select best solution (rather feasible one)presence uncontrollable events. Moreover, shows computational propertiescontrollability checking algorithms change adding preferences. particular, dynamiccontrollability still checked polynomial time considered class problems, producing dynamically temporal plans uncertainty optimal respect preferences.Among future directions want pursue within line research, first deeperstudy methods algorithms adding preferences different fuzzy ones. Noticeframework proposed able represent kind preference withinsoft constraint framework. However, algorithms apply fuzzy preferences semiconvex functions. particular, would like consider impact design complexityalgorithms uncontrollable events underlying preference structuresweighted probabilistic semiring. semirings characterized non-idempotentmultiplicative operators. problem applying constraint propagation (Bistarelliet al., 1997), path-consistency, constraints. Thus search propagation techniquesadapted environment featuring uncertainty well. noticed(Peintner & Pollack, 2005) algorithms finding optimal solutions STPs preferencesweighted semiring proposed. Another interesting class preferences utilitarianones. context preference represents utility goal maximize sumutilities. preferences used temporal context without uncertainty example(Morris, Morris, Khatib, Ramakrishnan, & Bachmann, 2004).Recently, another approach handling temporal uncertainty introduced (Tsamardinos, 2002; Tsamardinos, Pollack, & Ramakrishnan, 2003a): Probabilistic Simple Temporal Problems (PSTPs); similar ideas presented (Lau, Ou, & Sim, 2005). PSTP framework,rather bounding occurrence uncontrollable event within interval, STPUs,probability distribution describing event likely occur defined entire setreals. STPUs, way problem solved depends assumptions made regardingknowledge uncontrollable variables. particular define Static SchedulingOptimization Problem, equivalent finding execution satisfying SC STPUs,Dynamic Scheduling Optimization Problem, equivalent finding dynamic execution strategycontext STPUs. framework, optimal means highest probabilitysatisfying constraints. Preferences considered framework. believewould interesting add preferences also approach. first step could consists keeping,strategy, separately global preference probability success. way659fiROSSI , V ENABLE ,& YORKE -S MITHcould use existing frameworks handling two aspects. Then, order strategiesgiving priority preferences, thus taking sense risky attitude, or, contrary,giving priority probabilities, adopting cautious attitude. step directionrecently proposed (Morris, Morris, Khatib, & Yorke-Smith, 2005), where, however, authors,rather actually extending notions consistency PSTPs handle preferences, considerinducing preferences probabilities. contrast, approach preliminary advanced (Pini,Rossi, & Venable, 2005).focused attention non-disjunctive temporal problems, is,one interval per constraint. would like consider adding uncertainty Disjunctive Temporal Problems (Stergiou & Koubarakis, 2000), consider scenariospreferences uncertainty. problems polynomial even without preferences uncertainty shown cost adding preferences small (Peintner & Pollack,2004), hope hold environments uncertainty well. Surprisingly,uncertainty Disjoint Temporal Problems considered yet, although easy seeallowing multiple intervals constraint form uncontrollability. We, thus, planstart defining DTPUs (preliminary results Venable Yorke-Smith, 2005) mergeapproach existing one DTPPs.Extending Conditional Temporal Problems, framework proposed (Tsamardinos, Vidal, &Pollack, 2003b), also topic interest us. model Boolean formula attachedtemporal variable. formulae represent conditions must satisfied orderexecution events enabled. framework uncertainty temporalvariables executed. believe would interesting extend approach orderallow conditional preferences: allowing preference functions constraints differentshapes according truth values formulas, occurrence eventtime. would provide additional gain expressiveness, allowing one express dynamicaspect preferences change time.AppendixTheorem 1 STPPU P OSC, ODC; ODC, OWC.Proof: Let us assume P OSC. viable execution strategy that, P 1 , P2P roj(P ) every executable time-point x, [S(P 1 )]x = [S(P2 )]x S(P1 ) OptSol(P1 )S(P2 ) OptSol(P2 ). Thus, particular, [S(P1 )]x = [S(P2 )]x every pair f projections[S(P1 )]<x = [S(P2 )]<x . allows us conclude P OSC also ODCstrategy witness OSC also witness ODC.Let us assume P ODC. Then, particular, viable dynamic strategyP1 P roj(P ), S(P1 ) optimal solution P1 . clearly means every projectionleast optimal solution. Thus P OWC. 2Theorem 2 given preference level , STPPU P -SC -DC.Proof: Assume P -SC. viable strategy that: [S(P 1 )]x = [S(P2 )]x ,P1 , P2 P roj(P ) every executable time-point x, S(P ) optimal solutionprojection P , optimal solution P preference > pref (S(P )) 6< ,otherwise.660fiU NCERTAINTYSOFT TEMPORAL CONSTRAINT PROBLEMSThus, [S(P1 )]x = [S(P2 )]x also pairs projections, P 1 P2 [S(P1 )]<x =[S(P2 )]<x . implies P -DC. 2Theorem 3 Given STPPU P preference level , P -SC (resp. -DC), -SC(resp. -DC), < .Proof: P -SC viable strategy that: [S(P 1 )]x = [S(P2 )]x , P1 , P2P roj(P ) every executable time-point x, S(P ) optimal solution Poptimal solution P preference > pref (S(P )) 6< , otherwise. But, course,< set projections optimal solution preference > includedprojections optimal solution preference > . Moreover, projections,Pz , pref (S(Pz )) 6< implies pref (S(Pz )) 6< since > . Similarly -DC.2Theorem 4 Given STPPU P , let opt = max Sol(P ) pref (T ). Then, P OSC (resp. ODC) iffopt-SC (resp. opt-DC).Proof: result comes directly fact P P roj(P ), opt(Pi ) opt,always least projection, Pj , opt(Pj ) = opt.2Theorem 5 Given STPPU P finite number preference levels, execution algorithm Best-SC P terminates.Proof: Consider STPPU P optimal preference value opt = max Sol(P ) pref (T ), is,highest preference assigned solutions. definition, Qopt+1 consistent.means algorithm reaches level opt + 1 (that is, next preference level higher optgranularity preferences) condition line 11 satisfied executionhalt. looking lines 9-20 see either one events cause executionterminate occurs preference level incremented line 16. Since finite numberpreference levels, allows us conclude algorithm terminate finite numbersteps. 2Theorem 6 Consider STPPU P = hNe , Nc , Lr , Lc , SF CSP preference level , consider STPU Q = hNe , Nc , L0r , L0c obtained cutting P , STPU PC(Q )=hNe , Nc ,L00r , L00c i. Then:1. situation P , P P roj(PC(Q )) iff optP (P ) ;2. every control sequence , solution = StronglyControllable(PC(Q ) iff, PProj(PC (Q )), T, Sol(P ) pref (T, ) .Proof: prove item theorem.1. (): Consider situation P P roj(PC(Q )). Since PC(Q ) path consistent, consistent partial assignment (e.g. defined ) extended completeconsistent assignment, say T, PC(Q ). Moreover, T, Sol(P ), pref (T, ) ,since preference functions semi-convex every interval PC(Q ) subintervalcorresponding one Q . Thus, opt(P ) P . (): Consider situationopt(P ) . implies T, Sol(P ) pref (T, ) . Since661fiROSSI , V ENABLE ,& YORKE -S MITHfuzzy semiring, happens iff min cij Lr Lc fij (T, ) cij ) . Thus mustfij (T, cij ) , cij Lr Lc thus (T, ) cij c0ij , c0ij L0r L0c .implies P P roj(Q ). Moreover, since T, consistent solution P Q ,P P roj(PC(Q )).2. construction , Sol(T ) iff, P P roj(PC(Q )), T, Sol(P )Sol(PC(Q )). Notice fact T, Sol(PC(Q )) implies pref (T, ) . 2Corollary 1 Consider STPPU P preference level assume , situation P ,opt(P ) , P corresponding projection. Then, STPU PC(Q ), obtainedcutting P , applying path consistency, SC P -SC.Proof: item 1 Theorem 6 get P projection P opt(P )iff P P roj(PC(Q )). Thus, complete assignments controllable contingentvariables P global preference iff PC(Q ) consistent, i.e., iff Q path consistent. Letus assume PC(Q ) SC. item 2 Theorem 6, fixed assignmentcontrollable variables solution every projection P roj(PC(Q )) and, everyprojection, gives global preference .means either set projections common solution P every commonsolution gives preference strictly lower . Thus, P -SC since requires existencefixed assignment controllable variables must optimal solution projectionspreference (Definition 22, Item 1 2) give preferenceprojections (Definition 22, Item 3).Theorem 7 Consider STPPU P , preference levels min , assumecorresponding STPs, min , . . . , obtained cutting P preference levels Nmin , . . . , ,enforcing strong controllability consistent. Then, Sol(P ), P = i=min ,..., ,iff P P roj(P ): T, Sol(P ), opt(P ) , pref (T, ) = opt(P ), otherwisepref (T, ) .Proof: (): Let us first recall given two STPs, P1 P2 , defined set variables,STP P3 = P1 P2 variables P1 P2 temporal constraint c3ij =c1ij c2ij , is, intervals P3 intersection corresponding intervals P 1P2 . Given this, fact set projections P set projectionsSTPU obtained cutting P min , immediately derive Theorem 6solution P satisfies condition. (): Let us consider control sequence P6 Sol(P ). Then, j {min . . . } 6 Sol(T j ). Theorem 6 concludeP opt(P ) = j T, optimal solution P . 2Theorem 8 execution algorithm Best-SC STPPU P stops due occurrenceEvent 1 (line 4), P -SC 0.Proof: every preference level min , Q =-Cut(P ), =min -Cut(P )=Qmin . occurrence Event 1 implies Qmin strongly controllable. mustQ , min . thus P -SC min . Theorem 3 allows us conclude> min . 2662fiU NCERTAINTYSOFT TEMPORAL CONSTRAINT PROBLEMSTheorem 9 execution algorithm Best-SC STPPU P stops due occurrenceEvent 2 (line 11) preference level ,1 = opt = maxT Sol(P ) pref (T );P OSC control sequence solution STP P opt (returned algorithm) iffoptimal scenario P .Proof: condition line 11 satisfied STPU Q , means schedulesP preference . However, condition satisfied previous preferencelevel, 1, means schedules preference 1. allows us conclude1 optimal preference STPPU P seen STPP, is, 1 = opt =maxT Sol(P ) pref (T ). Since assuming line 11 executed Best-SC level opt + 1,conditions lines 13 16 must satisfied preference opt. meanslevel opt STP P opt (line 15) consistent. looking line 15, see STP P optsatisfies hypothesis Theorem 7 preference min preference opt. allows usconclude solution P opt optimal scenario P vice versa. Thus, P opt-SCand, Theorem 4, OSC. 2Theorem 10 execution algorithm Best-SC STPPU P stops due occurrenceEvent 3 (line 13) Event 4 (line 16) preference level P OSC ( 1)SC solution STP P 1 (returned algorithm) that, P P roj(P ):T, Sol(P ), opt(P ) 1, pref (T, ) = opt(P ), otherwise pref (T, ) 1.Proof: Event 3 Event 4 occurs condition line 11 must satisfied preference level . means STPU PC(Q ) consistent thus schedules Ppreference . Event 3 occurs, condition line 13 must satisfied. STPU obtainedcutting P preference level applying path consistency strongly controllable.thus conclude, using Corollary 1, P OSC. However since algorithm executedline 11 preference level , 1 must reached line 18. looking line 15see STP P 1 satisfies hypothesis Theorem 7 preference min preference level1. allows us conclude P 1-SC.instead Event 4 occurs P inconsistent (by Theorem 7) meanscommon assignment executables optimal scenarios preference <time preference equal . However since execution reached line16 preference level , assume successfully completed loop preference1 conclude P 1-SC.2Theorem 11 Determining optimal strong controllability highest preference level -SCSTPPU n variables ` preference levels achieved O(n 3 `).Proof: Notice first complexity procedure -Cut (lines 3 10) intersecting twoSTPs (line 15) linear number constraints thus O(n 2 ). Assuming `different preference levels, conclude complexity Best-SC boundedapplying ` times StronglyControllable, O(n 3 `) (see Section 2).2Theorem 12 STPPU P OWC iff STPU Q, obtained simply ignoring preference functions constraints WC.663fiROSSI , V ENABLE ,& YORKE -S MITHProof: P OWC, every situation P exists control sequenceschedule T, consistent optimal projection P . every projection P Pcorresponding projection Q, say Q , STP obtained P ignoringpreference functions. easy see Definition 1 Section 2.2 implies assignmentoptimal solution P solution Q . STPU Q WC every projectionQ exists control sequence schedule , solution Q . Definition 1 Section 2.2 conclude corresponding STPP P least solution thusmust least optimal solution, solution solution higherpreference. 2Theorem 13 Given STPPU P , consider preference level STPU Q , obtainedcutting P , consistent. STPU PC(Q ) DC P ODC -DC,.Proof: Assume preference level PC(Q ) DC. meansviable execution strategy : P roj(PC(Q )) Sol(PC(Q )) P1 , P2P roj(Q ) executable x, [S(P1 )]<x = [S(P2 )]<x [S(P1 )]x = [S(P2 )]x .Let us recall that, due semi-convexity preference functions, cutting STPPUgiven preference level return smaller intervals constraints. Thus, everyprojection P roj(Q ) (which STP) corresponds projection P roj(P )STPP obtained STP restoring preference functions P.Let us assume, contrary, P ODC and, thus, exists viable strategy0: P roj(P ) Sol(P ) P1 , P2 P roj(P ), [S 0 (P1 )]<x = [S 0 (P2 )]<x[S 0 (P1 )]x = [S 0 (P2 )]x , pref (S 0 (Pi )) = opt(Pi ), = 1, 2. Consider, restriction0 projections P roj(PC(Q )). Since pref (S 0 (P ) = opt(P ) every P , mustP P roj((PC(Q )), 0 (P ) Sol((PC(Q )). Thus restriction 0 satisfiesrequirements strategy definition DC. contradiction factPC(Q ) DC. Thus P cannot ODC.Theorem 6, P P roj(P ), P P roj(PC(Q )) iff opt(P ) . allows usconclude P -DC. Finally, Theorem 3 allows conclude P -DC, .2Lemma 1 (useful proof Theorem 14) Consider STPU Q DynamicallyControllable reported success Q. Consider constraint AB, B executablesexecution always precedes B, defined interval [p, q] wait max 10 . Then,exists viable dynamic strategy Q P roj(Q), [S(Qi )]B [S(Qi )]A tmax .Proof: dynamic strategy produced algorithm DC-Execute shown Figure 7, Section 2. fact, line 5 stated executable B executed soon as, currenttime, three following conditions satisfied: (1) B live, i.e. current time must lie lower upper bounds, (2) B enabled, i.e. variables must precede Bexecuted, (3) waits B satisfied. Let us denote current time ,assume B live enabled . Thus, ([S(Q )]A ) [p, q]. third requirement satisfiedone two following scenarios: either last contingent time-point Bwait occurred thus B executed immediately, waits contingent10. Notice tmax longest wait B must satisfy imposed contingent time-point C constraint AB.664fiU NCERTAINTYSOFT TEMPORAL CONSTRAINT PROBLEMStime-points, among B wait, yet occurred expired .cases must tmax + [S(Qi )A ]. Thus, ([S(Qi )]B = ) [S(Qi )]A tmax . 2Theorem 14 Consider STPPU P STPUs, +1 , obtained cutting P respectivelylevel + 1 applying PC, without finding inconsistencies, DynamicallyControllablesuccess. Consider STPU P +1 = Merge(T , +1 ).Then, Merge(T , +1 ) failP +1 dynamically controllableviable dynamic strategy every projection P P roj(P +1 ),opt(Pi ) = opt(Pi ) = + 1 P , pref (S(Pi )) = opt(Pi );otherwise pref (S(Pi )) + 1.Proof: following constructive proof which, assuming Merge failed, strategyS, satisfying requirements theorem, defined.First notice P roj(P +1 ) = P roj(T ). fact, line 2 Merge, P +1 initialized. Merge changes requirement intervals leaving contingent intervals unaltered.Furthermore, P roj(T +1 ) P roj(T ). seen using first claim Theorem 6Section 5.Let 0 00 viable dynamic execution strategies obtained running DC-Execute respectively +1 . Now, since P roj(T +1 ) P roj(T ), projectionsmapped two, possibly different, schedules: one 0 one 00 . every projectionPi P roj(P +1 ) every executable B, notice 00 [Pi ]<B exists equal0 [Pi ]<B . thus define history B (which recall set durations contingent events finished prior B) new strategy S[Pi ]<B = 0 [Pi ]<B everyprojection Pi P roj(P +1 ) . Notice 00 [Pi ]<B defined history B Pi containsduration mapped preference exactly equal thus P cannot projection+1 .consider define depending case AB constraint+1 .Constraint AB Follow Unordered Follow +1 . cases, Mergechange interval AB, leaving .Let us first analyze scenario AB Follow case STPUs.case, execution B always follow contingent time point Cproblems. Thus, every projection P P roj(P +1 ), S[P ]<B = . Sinceproblems dynamically controllable [p , q ] 6= [p+1 , q +1 ] 6= . Furthermore,since path consistency enforced problems, constraints minimalform (see Section 2), is, every value AB [p , q ] (resp. [p+1 , q +1 ])situation (resp. +1 ) T, Sol(P ) AB = AB . Finally, sinceP roj(T +1 ) P roj(T ), must [p+1 , q +1 ] [p , q ].Next consider scenario AB Unordered case +1 . Let us startproving that, case, must [p +1 , q +1 ] [p , ]. First, show665fiROSSI , V ENABLE ,& YORKE -S MITHp+1 p . definition, p+1 situation P P roj(T +1 )schedule T, Sol(P ) AB = p+1 . Since P roj(T +1 )P roj(T ), p+1 [p , q ]. Next let us prove must > q +1 . Noticewait induces partition situations two sets: that, everycontingent point C, AC < , contingent point C 0 , AC 0 .first case, contingent events occurred expiration waitB executed tA + (where tA execution time A). secondcase safe execute B tA + . Given P roj(T +1 ) P roj(T ), Bconstrained follow execution every contingent time-point +1 , mustprojections +1 belong first set partition thus q+1 < .cases is, hence, sufficient define new strategy follows: projections,Pi , Pj P roj(P +1 ) [S(Pi )]<B = [S(Pj )]<B [S(Pi )]B = [S(Pj )]B =[S 00 (Pi )]B [S 00 (Pi )]B exists, otherwise [S(Pi )]B = [S(Pj )]B = [S 0 (Pi )]B . assignmentguarantees identify projections constraints mapped preferences +1 [S 00 (Pi )]Bexists thus Pi P roj(T +1 ), otherwise projections P roj(T )P roj(T +1 ).Constraint AB Precede case +1 . B must precede contingent timepoint C. means assignment B corresponding value [p , q ] (resp.[p+1 , q +1 ]) extended complete solution projection P roj(T ) (resp.P roj(T +1 )). Interval [p0 , q 0 ] is, fact, obtained Merge, intersecting two intervals.Since assuming Merge failed, intersection cannot empty (line 6Figure 14). can, thus, example, define follows: pair projectionsPi , Pj P roj(P +1 ) [S(Pi )]<B = [S(Pj )]<B [S(Pi )]B (= [S(Pj )]B ) = p0 .Constraint AB Unordered Unordered Precede +1 . First let us recallresult applying Merge interval [p 0 , q 0 ], p0 = p , q 0 = min(q , q +1 )wait t0 = max(t , t+1 ). Since, hypothesis, Merge failed, must 0 q 0(line 9, Figure 14.Notice that, due semi-convexity preference functions, p p+1 . fact, Bexecuted tA + p (where tA time executed)contingent time-points B wait occurred. Let us indicate x mlb+1 ),(resp. x+1mlb ) maximum lower bound AC constraint (resp.+1B wait C. must p xmlb (resp. p+1 xmlb ). However duesemi-convexity preference functions x mlb x+1mlb .case define strategy follows. pair projections Pi , PjP roj(P +1 ), [S(Pi )]<B =[S(Pj )]<B [S(Pi )]B = [S(Pj )]B = max([S 00 (Pi )]B ,[S 0 (Pi )]B ) whenever [S 00 (Pi )]B defined. Otherwise [S(Pi )]B =[S(Pj )]B = [S 0 (Pi )]B .Lemma 1 max([S 00 (Pi )]B , [S 0 (Pi )]B ) t0 , hence [S(Pi )]B = ([S(Pj )]B )[p0 , q 0 ].Let us consider preferences induced constraints assignment. Firstlet us consider case max([S 00 (Pi )]B , [S 0 (Pi )]B ) = [S 00 (Pi )]B . Since 00dynamic strategy +1 assignment identify projections preference + 1.instead max([S 00 (Pi )]B , [S 0 (Pi )]B ) = [S 0 (Pi )]B , must [S 0 (Pi )]B > [S 00 (Pi )]B .666fiU NCERTAINTYSOFT TEMPORAL CONSTRAINT PROBLEMSHowever know, Lemma 1 [S 00 (Pi )]B t+1 t0 [S 0 (Pi )]B t0 .implies [S 0 (Pi )]B [p+1 , t0 ] thus assignment preference +1. Finally, [S 00 (Pi )]B defined, noted above, Pi 6 P roj(T +1 ) thusopt(Pi ) = (since Theorem 6 Section 5 P P roj(T ) opt(Pi )). Thus, [S(Pi )]B =[S(Pj )]B = [S 0 (Pi )]B , which, assignment , identifiespreferences = opt(Pi ).shown that, Merge fail, dynamic strategy (withrequired additional properties) certifies P+1 dynamically controllable.Assume, instead, Merge fails constraint. two caseshappen. first one AB Precede case +1 [p , q ] [p+1 , q +1 ]= . proven (Morris et al., 2001), projection AB viable dynamic strategy[p , q ] projection AB viable dynamic strategy +1 [p+1 , q +1 ].dynamic viable strategies give optimal solutions projections optimal preferenceequal . dynamic viable strategies +1 give optimal solutions projectionsoptimal preference equal + 1. Since projections +1 subset ,[p , q ] [p+1 , q +1 ] = strategy either optimal projection+1 vice-versa.second case occurs Merge fails constraint AB either Unorderedcase +1 Unordered case precede case +1 .cases failure due fact [t , q ] [t+1 , q +1 ] = . must either q +1 <q < t+1 . upper bound interval AB q +1 must leastcontingent time-point C executing B q +1 either inconsistentassignment C gives preference lower + 1. side, waitconstraint AB must least contingent time-point C 0 executing Beither inconsistent optimal future occurrences C.way define viable dynamic strategy simultaneously optimal projections optimalvalue equal optimal value + 1. 2Lemma 2 (Useful proof Theorem 15) Consider strategies 0 , 00 definedTheorem 14.1. projection P +1 , Pi , pref (S(Pi )) pref (S 0 (Pi )) every projection, Pz ,+1 , pref (S(Pz )) + 1;2. constraint AB, [S(Pi )]B t0 .Proof:1. Obvious, since cases either [S(P )]B = [S 0 (Pi )]B [S(Pi )]B = [S 00 (Pi ) ]Bpref (S 00 (Pi )) pref (S 0 (Pi )) since every executable B [S 00 (Pi )]B +1 . Moreover,every projection Pz +1 , every executable B, [S(Pz )]B = [S 00 (Pz )]B .2. Derives directly fact either [S(P )]B = [S 0 (Pi )]B [S(Pi )]B = [S 00 (Pi )]BLemma 1 2.667fiROSSI , V ENABLE ,& YORKE -S MITHTheorem 15 Consider STPPU P every preference level, , define STPU obtainedcutting P , applying PC DynamicallyControllable. Assume ,DC. Consider STPU P :P = Merge(Merge(. . . Merge(Merge(T min , min +1 ), min +2 ), . . . ), )min minimum preference constraint P. Assume that, applied, Mergealways returned consistent STPU. Then, viable dynamic strategy S, PP roj(P ), opt(Pi ) S(Pi ) optimal solution Pi , otherwise pref (S(Pi )) + 1.Proof: prove theorem induction. First, notice that, construction P roj (T min ) =P roj(P ). allows us conclude P roj(P ) = P roj(P ), since, every time Mergeapplied, new STPU contingent constraints STPU given first argument.Now, since min dynamically controllable viable dynamic strategies, say minmin (Pi ) optimal opt(Pi ) = min and, otherwise, pref (S(Pi )) min .Consider P min +1 =Merge (T min ,T min +1 ). Theorem 14, knowstrategy, min +1 , min +1 (Pi ) optimal solution Pi opt(Pi ) min + 1pref (S(PI )) min + 1 otherwise.Let us assume STPU P min +k , defined hypothesis, satisfies thesisP min +k+1 , defined hypothesis, min + k + 1 , not. Noticeimplies strategy, min +k , min +k (Pi ) optimal solution Piopt(Pi ) min + k pref (S(Pi )) min + k projections. Since min +k + 1 , then, hypothesis also min +k+1 DC. Moreover, construction,P min +k+1 =Merge (P min +k ,T min +k+1 ), since Merge doesnt fail. Thus, using Theorem 14using strategy min +k P min +k construction Theorem 14, Lemma 2,obtain dynamic strategy, min +k+1 , every projection Pi , pref (S min +k+1 (Pi ))pref (S min +k (Pi )) min +k+1 (Pj ) optimal solution projections P jopt(Pj ) = min + k + 1 pref (S(Pj )) min + k + 1 projections.allows us conclude min +k+1 (Ph ) optimal solution projections P hopt(Ph ) min + k + 1. contradiction assumption P min +k+1 doesnt satisfythesis theorem. 2Theorem 16 Given STPPU P, execution algorithm Best-DC P terminates.Proof: assume preference set discretized finite number differentpreferences. Best-DC starts lowest preference cuts level P. If, given level,STPU obtained consistent dynamically controllable merging procedure fails,Best-DC stops level. Assume, instead, that, moves preference ordering,none events occur. However certain point cutting level highermaximum preference function (or outside preference set) casecutting problem give inconsistent STP.2Theorem 17 Given STPPU P input, Best-DC terminates line 4 iff 6 0 P-DC.Proof: . Assume Best-DC terminates line 4. Then, STPU obtained cutting Pminimum preference, min , constraint DC. However cutting minimum668fiU NCERTAINTYSOFT TEMPORAL CONSTRAINT PROBLEMSpreference constraint preference level 0 gives STPU. Theorem 13conclude P -DC 0 and, thus, ODC.. Assume P -DC preferences 0. cutting P minimum preferencemin cannot give dynamically controllable problem, otherwise, P would min -DC. Hence,Best-DC exit line 4. 2Theorem 18 Given STPPU P input, Best-DC terminates line 11 iff P ODC.Proof: . Assume Best-DC terminates line 11 considering preference level . Then,STPU Q obtained cutting STPPU P level path consistent. immediately conclude projection P P roj(Pi ) opt(Pi ) .Since Best-DC terminate before, must assume preference 1,tests (path consistency, dynamic controllability, Merge) successful.consider STPU P 1 obtained end iteration corresponding preferencelevel 1. easy see P 1 satisfies hypothesis Theorem 15. allows usconclude viable dynamic strategy every projection P ,opt(Pi ) 1, S(Pi ) optimal solution Pi . However since know projectionsP opt(Pi ) < , allows us conclude P ODC.. P ODC viable strategy every pair projections, P , PjP roj(P ), executable B, [S(P )]<B = [S(Pj )]<B [S(Pi )]B = [S(Pj )]BS(Pi ) optimal solution Pi S(Pj ) optimal solution Pj .Theorem 17 know Best-DC cannot stop line 4.Let us consider line 13 show Best-DC sets -DC true line Pcannot ODC. fact condition setting -DC true line 13 STPU obtainedcutting P preference level path consistent dynamically controllable. meansprojections, e.g. Pj , P opt(Pj ) = . However, dynamic strategyset projections. Thus, P cannot ODC.Let us consider line 16, show that, P ODC Best-DC cannot set -DC true.Best-DC sets -DC true Merge failed. Using Theorem 14, concludedynamic viable strategy every projection P , P , (remember P roj(P 1 ) =P roj(P )) S(Pi ) optimal solution opt(Pi ) . However, know projectionsP optimal preference equal (since assuming Best-DC stopping line 1611). Thus, P cannot ODC.2Theorem 19 Given STPPU P input, Best-DC stops lines 13 16 preference level iff P( 1)-DC ODC.Proof: . Assume Best-DC sets -DC true line 13, considering preference level. Thus, STPU obtained cutting P level path consistent DC. However sincemust first preference level happens, otherwise Best-DC would stoppedsooner, conclude iteration preference level 1 successful. ConsideringP 1 using Theorem 15 conclude viable dynamic strategy that,every projection P , Pi , opt(Pi ) 1 S(Pi ) optimal solution Pipref (S(Pi )) 1 otherwise. definition 1-dynamic controllability.Best-DC terminates line 16, Theorem 15 Theorem 14 conclude that,viable dynamic strategy every projection P , P , opt(Pi ) 1669fiROSSI , V ENABLE ,& YORKE -S MITHS(Pi ) optimal solution Pi pref (S(Pi )) 1 otherwise, strategyguaranteeing optimality also projections optimal preference . Again, P 1-DC.. P -DC, 0 Theorem 17, Best-DC stop line 4. P-DC, ODC, 0 Theorem 18, Best-DC stop line 11.Theorem 16, Best-DC always terminates, must stop line 13 16.2Theorem 20 complexity determining ODC highest preference level -DCSTPPU n variables, bounded number preference levels l O(n 5 `).Proof: Consider pseudocode algorithm Best-DC Figure 13.complexity min -Cut(P ) line 3 O(n2 ), since every constraint must considered,O(n2 ) constraints, constraint time finding intervalelements mapped preference min constant. complexity checking STPU obtained DC O(n5 ). Thus, lines 3 4, always performed, overall complexityO(n5 ). Lines 7 8, clearly, take constant time.Let us consider fixed preference level compute cost complete iteration .(line 10) complexity -Cut(P ) O(n 2 );(line 11) complexity applying PC testing path consistency O(n 3 ) (see Section 2.1,(Dechter et al., 1991));(line 13) complexity testing DC using DynamicallyControllable O(n 5 ), (see Section 2 Morris Muscettola, 2005);(line 15) constant time;(line 16-18) complexity Merge O(n 2 ), since O(n2 ) constraints mustconsidered constraint merging two intervals constant cost;(line 19) constant time.conclude complexity complete iteration given preference level O(n 5 ).worst case, cycle performed ` times. can, thus, conclude totalcomplexity Best-DC O(n5 `) since complexity operations performed lines 24-27constant. 2ReferencesBadaloni, S., & Giacomin, M. (2000). Flexible temporal constraints. 8th Conference Information Processing Management Uncertainty knowledge-Based System (IPMU 2000),pp. 12621269.Bistarelli, S., Montanari, U., & Rossi, F. (1997). Semiring-based constraint solving optimization. Journal ACM, 44(2), 201236.Bresina, J., Jonsson, A., Morris, P., & Rajan, K. (2005). Activity planning mars explorationrovers. 15th International Conference Automated Planning Scheduling (ICAPS2005), pp. 4049.670fiU NCERTAINTYSOFT TEMPORAL CONSTRAINT PROBLEMSCoggiola, M., Shi, Z., & Young, S. (2000). Airborne deployment instrument real-timeanalysis single aerosol particles. Aerosol Science Technology, 33, 2029.Dearden, R., Meuleau, N., Ramakrishnan, S., Smith, D., & Washington, R. (2002). Contingencyplanning planetary rovers. 3rd Intl. Workshop Planning Scheduling Space.Dechter, R., Meiri, I., & Pearl, J. (1991). Temporal constraint networks. Artificial Intelligence,49(1-3), 6195.Dubois, D., Fargier, H., & Prade, H. (1993). Flexible constraint satisfaction problems application scheduling problems. Tech. rep. Report IRIT/93-30-R, I.R.I.T., Universite P.Sabatier.Dubois, D., Fargier, H., & Prade, H. (1995). Fuzzy constraints job shop-scheduling. JournalIntelligent Manufacturing, 6, 215234.Dubois, D., Fargier, H., & Prade, H. (2003a). Fuzzy scheduling: Modelling flexible constraintsvs. coping incomplete knowledge. European Journal Operational Research, 147,231252.Dubois, D., HadjAli, A., & Prade, H. (2003b). Fuzziness uncertainty temporal reasoning.Journal Universal Computer Science, 9(9), 1168.Dubois, D., & Prade, H. (1985). review fuzzy set aggregation connectives. Journal Information Science, 36(1-2), 85121.Field, P., Hogan, R., Brown, P., Illingworth, A., Choularton, T., Kaye, P., Hirst, E., & Greenaway,R. (2004). Simultaneous radar aircraft observations mixed-phase cloud 100mscale. Quarterly Journal Royal Meteorological Society, 130, 18771904.Floyd, R. W. (1962). Algorithm 97: Shortest path. Communication ACM, 36(6), 345.Frank, J., Jonsson, A., Morris, R., & Smith, D. (2001). Planning scheduling fleets earthobserving satellites. 6th Intl. Symposium AI, Robotics, Automation Space (iSAIRAS01).Khatib, L., Morris, P., Morris, R. A., & Rossi, F. (2001). Temporal constraint reasoningpreferences. Nebel, B. (Ed.), 17th International Joint Conference Artificial Intelligence,(IJCAI 2001), pp. 322327. Morgan Kaufmann.Lau, H. C., Ou, T., & Sim, M. (2005). Robust temporal constraint networks. Proc. 17th IEEEConf. Tools Artificial Intelligence (ICTAI05), pp. 8288 Hong Kong.Leiserson, C. E., & Saxe, J. B. (1988). mixed-integer linear programming problemefficiently solvable. Journal Algorithms, 9(1), 114128.Morris, P., Morris, R., Khatib, L., Ramakrishnan, S., & Bachmann, A. (2004). Strategies globaloptimization temporal preferences. Wallace, M. (Ed.), Proceeding 10th International Conference Principles Practice Constraint Programming (CP-04), Vol. 3258Lecture Notes Computer Science, pp. 588603. Springer.671fiROSSI , V ENABLE ,& YORKE -S MITHMorris, P. H., Muscettola, N., & Vidal, T. (2001). Dynamic control plans temporal uncertainty. Nebel, B. (Ed.), 17th International Joint Conference Artificial Intelligence(IJCAI 2001), pp. 494502. Morgan Kaufmann.Morris, P. H., & Muscettola, N. (1999). Managing temporal uncertainty waypoint controllability. Dean, T. (Ed.), 16th International Joint Conference Artificial Intelligence(IJCAI99), pp. 12531258. Morgan Kaufmann.Morris, P. H., & Muscettola, N. (2005). Temporal dynamic controllability revisited. 20th NationalConference Artificial Intelligence (AAAI 2005), pp. 11931198. AAAI Press / MITPress.Morris, R. A., Morris, P. H., Khatib, L., & Yorke-Smith, N. (2005). Temporal planning preferences probabilities. ICAPS05 Workshop Constraint Programming PlanningScheduling.Muscettola, N., Morris, P. H., Pell, B., & Smith, B. D. (1998). Issues temporal reasoningautonomous control systems. Agents, pp. 362368.Peintner, B., & Pollack, M. E. (2004). Low-cost addition preferences DTPs TCSPs.McGuinness, D. L., & Ferguson, G. (Eds.), 19th National Conference Artificial Intelligence, pp. 723728. AAAI Press / MIT Press.Peintner, B., & Pollack, M. E. (2005). Anytime, complete algorithm finding utilitarian optimalsolutions STPPs. 20th National Conference Artificial Intelligence (AAAI 2005), pp.443448. AAAI Press / MIT Press.Pini, M. S., Rossi, F., & Venable, K. B. (2005). Possibility theory reasoning uncertainsoft constraints. Godo, L. (Ed.), 8th European Conference Symbolic QuantitativeApproaches Reasoning Uncertainty (ECSQARU 2005), Vol. 3571 LNCS, pp. 800811. Springer.Rajan, K., Bernard, D. E., Dorais, G., Gamble, E. B., Kanefsky, B., Kurien, J., Millar, W., Muscettola, N., Nayak, P. P., Rouquette, N. F., Smith, B. D., Taylor, W., & Tung, Y. W. (2000).Remote Agent: autonomous control system new millennium. Horn, W. (Ed.),14th European Conference Artificial Intelligence, ECAI 2000, pp. 726730. IOS Press.Rossi, F., Sperduti, A., Venable, K., Khatib, L., Morris, P., & Morris, R. (2002). Learning solving soft temporal constraints: experimental study. Van Hentenryck, P. (Ed.), PrinciplesPractice Constraint Programming, 8th International Conference (CP 2002), Vol. 2470LNCS, pp. 249263. Springer.Rossi, F., Venable, K. B., & Yorke-Smith, N. (2004). Controllability soft temporal constraintproblems. 10th International Conference Principles Practice Constraint Programming (CP-04), Vol. 3258 LNCS, pp. 588603.Rossi, F., Venable, K., & Yorke-Smith, N. (2003). Preferences uncertainty simple temporal problems. Proc. CP03 Workshop: Online-2003 (International Workshop OnlineConstraints Solving - Handling Change Uncertainty).672fiU NCERTAINTYSOFT TEMPORAL CONSTRAINT PROBLEMSRuttkay, Z. (1994). Fuzzy constraint satisfaction. Proceedings 1st IEEE Conference Evolutionary Computing, pp. 542547 Orlando.Schiex, T. (1992). Possibilistic Constraint Satisfaction problems handle soft constraints?. Dubois, D., & Wellman, M. P. (Eds.), 8th Annual Conference UncertaintyArtificial Intelligence (UAI92), pp. 268275. Morgan Kaufmann.Shostak, R. E. (1981). Deciding linear inequalities computing loop residues. JournalACM, 28(4), 769779.Stergiou, K., & Koubarakis, M. (2000). Backtracking algorithms disjunctions temporal constraints. Artificial Intelligence, 120(1), 81117.Tsamardinos, I. (2002). probabilistic approach robust execution temporal plans uncertainty. Vlahavas, I. P., & Spyropoulos, C. D. (Eds.), Methods Applications ArtificialIntelligence, Second Hellenic Conference AI (SETN 2002), Vol. 2308 LNCS, pp. 97108. Springer.Tsamardinos, I., Pollack, M. E., & Ramakrishnan, S. (2003a). Assessing probability legal execution plans temporal uncertainty. Workshop Planning UncertaintyIncomplete Information Thirteenth International Conference Automated PlanningScheduling (ICAPS 2003).Tsamardinos, I., Vidal, T., & Pollack, M. E. (2003b). CTP: new constraint-based formalismconditional, temporal planning. Constraints, 8(4), 365388.Venable, K., & Yorke-Smith, N. (2003). Simple Temporal Problems Preferences Uncertainty. Doctoral Consortium 13th International Conference Automated PlanningScheduling (ICAPS 2003). AAAI Press.Venable, K., & Yorke-Smith, N. (2005). Disjunctive temporal planning uncertainty. 19thInternational Joint Conference Artificial Intelligence (IJCAI 2005), pp. 172122. MorganKaufmann.Vidal, T., & Fargier, H. (1999). Handling contingency temporal constraint networks: consistency controllabilities. Journal Experimental Theoretical Artificial Intelligence,11(1), 2345.Vidal, T., & Ghallab, M. (1996). Dealing uncertain durations temporal constraint networksdedicated planning. Wahlster, W. (Ed.), 12th European Conference Artificial Intelligence (ECAI96), pp. 4854. John Wiley Sons.Vila, L., & Godo, L. (1994). fuzzy temporal constraint networks. Mathware Soft Computing,3, 315334.Xu, L., & Choueiry, B. Y. (2003). new efficient algorithm solving simple temporal problem. 10th Intl. Symposium Temporal Representation Reasoning Fourth Intl.Conf. Temporal Logic (TIME-ICTP03), pp. 212222.673fiROSSI , V ENABLE ,& YORKE -S MITHYorke-Smith, N., Venable, K. B., & Rossi, F. (2003). Temporal reasoning preferences uncertainty. Gottlob, G., & Walsh, T. (Eds.), 18th International Joint Conference ArtificialIntelligence (IJCAI03), pp. 13851386. Morgan Kaufmann.Zadeh, L. A. (1975). Calculus fuzzy restrictions. Fuzzy Sets Applications CognitiveDecision Processes, 140.674fiJournal Artificial Intelligence Research 27 (2006) 299-334Submitted 01/06; published 11/06Properties Applications Programs Monotone ConvexConstraintsLengning LiuMirosaw TruszczynskiLLIU 1@ CS . UKY. EDUMIREK @ CS . UKY. EDUDepartment Computer Science, University Kentucky,Lexington, KY 40506-0046, USAAbstractstudy properties programs monotone convex constraints. extendformalisms concepts results normal logic programming. include notionsstrong uniform equivalence characterizations, tight programs Fages Lemma,program completion loop formulas. results provide abstract account propertiesrecent extensions logic programming aggregates, especially formalism lparseprograms. imply method compute stable models lparse programs means off-theshelf solvers pseudo-boolean constraints, often much faster smodels system.1. Introductionstudy programs monotone constraints (Marek & Truszczy nski, 2004; Marek, Niemela,& Truszczynski, 2004, 2006) introduce related class programs convex constraints.formalisms allow constraints appear heads program rules, sets apartrecent proposals integrating constraints logic programs (Pelov, 2004; Pelov,Denecker, & Bruynooghe, 2004, 2006; DellArmi, Faber, Ielpa, Leone, & Pfeifer, 2003; Faber,Leone, & Pfeifer, 2004), makes suitable abstract basis formalisms lparseprograms (Simons, Niemela, & Soininen, 2002).show several results normal logic programming generalize programs monotone constraints. also discuss techniques results extendedsetting programs convex constraints. apply general results designimplement method compute stable models lparse programs show oftenmuch effective smodels (Simons et al., 2002).Normal logic programming semantics stable models effective knowledge representation formalism, mostly due ability express default assumptions (Baral, 2003; Gelfond& Leone, 2002). However, modeling numeric constraints sets normal logic programmingcumbersome, requires auxiliary atoms leads large programs hard process efficiently. Sinceconstraints, often called aggregates, ubiquitous, researchers proposed extensions normallogic programming explicit means express aggregates, generalized stable-model semantics extended settings.Aggregates imposing bounds weights sets atoms literals, called weight constraints,especially common practical applications included recent extensions logicprograms aggregates. Typically, extensions allow aggregates appearc2006AI Access Foundation. rights reserved.fiL IU & RUSZCZY NSKIheads rules. notable exception formalism programs weight constraints (Niemel a,Simons, & Soininen, 1999; Simons et al., 2002), refer lparse programs 1 .Lparse programs logic programs whose rules weight constraints headswhose bodies conjunctions weight constraints. Normal logic programs viewedsubclass lparse programs semantics lparse programs generalizes stable-modelsemantics normal logic programs (Gelfond & Lifschitz, 1988). Lparse programs onecommonly used extensions logic programming weight constraints.Since rules lparse programs may weight constraints heads, concept onestep provability nondeterministic, hides direct parallels lparse normal logicprograms. explicit connection emerged Marek Truszczy nski (2004) Marek et al.(2004, 2006) introduced logic programs monotone constraints. programs allow aggregates heads rules support nondeterministic computations. Marek Truszczy nski(2004) Marek et al. (2004, 2006) proposed generalization van Emden-Kowalski onestep provability operator account nondeterminism, defined supported stable modelsprograms monotone constraints mirror normal logic programming counterparts,showed encodings smodels programs programs monotone constraints.paper, continue investigations programs monotone constraints. shownotions uniform strong equivalence programs (Lifschitz, Pearce, & Valverde, 2001;Lin, 2002; Turner, 2003; Eiter & Fink, 2003) extend programs monotone constraints,characterizations (Turner, 2003; Eiter & Fink, 2003) generalize, too.adapt programs monotone constraints notion tight program (Erdem & Lifschitz, 2003) generalize Fages Lemma (Fages, 1994).introduce extensions propositional logic monotone constraints. define completion monotone-constraint program respect logic, generalize notionloop formula. prove loop-formula characterization stable models programsmonotone constraints, extending setting monotone-constraint programs results obtainednormal logic programs Clark (1978) Lin Zhao (2002).Programs monotone constraints make explicit references default negation operator.show allowing general class constraints, called convex, default negationeliminated language. argue results paper extend programs convexconstraints.paper shows programs monotone convex constraints rich theoryclosely follows normal logic programming. implies programs monotone convex constraints form abstract generalization extensions normal logic programs. particular, results obtain abstract setting programs monotone convex constraintsspecialize lparse programs and, cases, yield results new.results practical implications. properties program completion loopformulas, specialized class lparse programs, yield method compute stable modelslparse programs means solvers pseudo-boolean constraints, developed propositional satisfiability integer programming communities (Een & Sorensson, 2003; Aloul, Ramani,Markov, & Sakallah, 2002; Walser, 1997; Manquinho & Roussel, 2005; Liu & Truszczy nski, 2003).describe method detail present experimental results performance. resultsshow method problems used testing typically outperforms smodels.1. Aggregates heads rules also studied recently Son Pontelli (2006) Son, Pontelli,Tu (2006).300fiP ROPERTIES PPLICATIONS P ROGRAMS ONOTONE C ONVEX C ONSTRAINTS2. Preliminariesconsider propositional case assume fixed set propositional atoms.lead loss generality, common interpret programs variables termspropositional groundings.definitions results present section come papers Marek Truszczynski (2004) Marek et al. (2006). general allow constraintsinfinite domains programs inconsistent constraints heads.Constraints. constraint expression = (X, C), X C P(X) (P(X)denotes powerset X). call set X domain constraint = (X, C) denoteDom(A). Informally speaking, constraint (X, C) describes property subsets domain,C consisting precisely subsets X satisfy constraint (have property) C.paper, identify truth assignments (interpretations) sets atoms assigntruth value true. is, given interpretation At, |= .say interpretation satisfies constraint = (X, C) (M |= A), X C.Otherwise, satisfy A, (M 6|= A).constraint = (X, C) consistent |= A. Clearly, constraint= (X, C) consistent C 6= .note propositional atoms regarded constraints. Let At.define C(a) = ({a}, {{a}}). evident |= C(a) |= a. Therefore,paper often write shorthand constraint C(a).Constraint programs. Constraints building blocks rules programs. Marek Truszczynski (2004) defined constraint programs sets constraint rulesA1 , . . . , Ak , not(Ak+1 ), . . . , not(Am )(1)A, A1 , . . . , constraints default negation operator.context constraint programs, refer constraints negated constraints literals.Given rule r form (1), constraint (literal) head r set {A 1 , . . . ,Ak , . . . , not(Ak+1 ), . . . , not(Am )} literals body r 2 . denote head bodyr hd (r) bd (r), respectively. define headset r, written hset(r), domainhead r. is, hset(r) = Dom(hd (r)).constraint program P , denote At(P ) set atoms appear domainsconstraints P . define headset P , written hset(P ), union headsetsrules P .Models. concept satisfiability extends standard way literals not(A) (M |= not(A)6|= A), sets (conjunctions) literals and, finally, constraint programs.M-applicable rules. Let interpretation. rule (1) -applicable satisfiesevery literal bd (r). denote P (M ) set -applicable rules P .Supported models. Supportedness property models. Intuitively, every atom supportedmodel must reasons in. reasons -applicable rules whose heads contain domains. Formally, let P constraint program subset At(P ). modelP supported hset(P (M )).Examples. illustrate concept examples. Let P constraint program consistsfollowing two rules:2. Sometimes view body rule conjunction literals.301fiL IU & RUSZCZY NSKI({c, d, e}, {{c}, {d}, {e}, {c, d, e}})({a, b}, {{a}, {b}}) ({c, d}, {{c}, {c, d}}), not(({e}, {{e}}))set = {a, c} model P satisfies heads two rules. rules P-applicable. first provides support c, second one a. Thus,supported model.set 0 = {a, c, d, e} also model P . However, support P . Indeed,appears headset second rule. rule 0 -applicable so, supporta. Therefore, 0 supported model P .4Nondeterministic one-step provability. Let P constraint program set atoms. set0 nondeterministically one-step provable means P , 0 hset(P (M ))0 |= hd (r), every rule r P (M ).nondeterministic one-step provability operator TPnd program P operatorP(At) every At, TPnd (M ) consists sets nondeterministicallyone-step provable means P .operator TPnd nondeterministic assigns family subsets At,possible outcome applying P . general, Pnd partial, since maysets TPnd (M ) = (no set derived means P ). instance,P (M ) contains rule r hd (r) inconsistent, TPnd (M ) = .Monotone constraints. constraint (X, C) monotone C closed superset, is,every W, X, W C W C.Cardinality weight constraints provide examples monotone constraints. Let X finiteset let Ck (X) = {Y : X, k |Y |}, k non-negative integer. (X, C k (X))constraint expressing property subset X least k elements. call lowerbound cardinality constraint X denote kX.general class constraints weight constraints. Let X finite set, say X ={x1 , . . . , xn }, let w, w1 , . . . , wn non-negative reals. interpret wi weight assigned xi . lower-bound weight constraint constraint form (X, C w ), Cw consists subsets X whose total weight (the sum weights elements subset)least w. writew[x1 = w1 , . . . , xn = wn ].weights equal 1 w integer, weight constraints become cardinality constraints. also note constraint C(a) cardinality constraint 1{a} also weightconstraint 1[a = 1]. Finally, observe lower-bound cardinality weight constraintsmonotone.Cardinality weight constraints (in somewhat general form) appear languagelparse programs (Simons et al., 2002), discuss later paper. notation adoptedconstraints paper follows one proposed Simons et al. (2002).use cardinality weight constraints examples. also focuslast part paper, use abstract results design new algorithm computemodels lparse programs.Monotone-constraint programs. call constraint programs built monotone constraintsmonotone-constraint programs programs monotone constraints. is, monotone-constraintprograms consist rules rules form (1), A, 1 , . . . , monotone constraints.302fiP ROPERTIES PPLICATIONS P ROGRAMS ONOTONE C ONVEX C ONSTRAINTSon, unless explicitly stated otherwise, programs consider monotone-constraintprograms.2.1 Horn Programs Bottom-up ComputationsSince allow constraints infinite domains inconsistent constraints heads rules,results given subsection general counterparts Marek Truszczy nski(2004) Marek et al. (2004, 2006). Thus, sake completeness, presentproofs.rule (1) Horn k = (no occurrences negation operator body or, equivalently,monotone constraints). constraint program Horn every rule program Horn.Horn constraint program associate bottom-up computations, generalizing corresponding notion bottom-up computation normal Horn program.Definition 1. Let P Horn program. P -computation (transfinite) sequence hX1. X0 = ,2. every ordinal number , X X+1 X+1 TPnd (X ),3. every limit ordinal , X = < X .Let = hX P -computation. Since every < 0 , X X 0 At, leastordinal number Xt +1 = Xt , words, least ordinal P -computationstabilizes. refer length P -computation t.Examples. simple example showing programs computations lengthexceeding so, transfinite induction definition cannot avoided. Let Pprogram consisting following rules:({a0 }, {{a0 }}) .({ai }, {{ai }}) (Xi1 , {Xi1 }), = 1, 2, . . .({a}, {{a}}) (X , {X }),Xi = {a0 , . . . ai }, 0 i, X = {a0 , a1 , . . .}. Since body last rule contains constraint infinite domain X , become applicable finite stepcomputation. However, become applicable step so, X +1 . Consequently,X+1 6= X .4P -computation = hX i, call X result computation denoteRt . Directly definitions, follows Rt = Xt .Proposition 1. Let P Horn constraint program P -computation. R supportedmodel P .Proof. Let = Rt result P -computation = hX i. need show that: (1)model P ; (2) hset(P (M )).(1) Let us consider rule r P |= bd (r). Since = Rt = Xt (wherelength t), Xt |= bd (r). Thus, Xt +1 |= hd (r). Since = Xt +1 , model r and,consequently, P , well.303fiL IU & RUSZCZY NSKI(2) prove induction that, every set X computation t, X hset(P (M )).base case holds since X0 = hset(P (M )).= + 1, X TPnd (X ). follows X hset(P (X )). Since P Hornprogram X , hset(P (X )) Shset(P (M )). Therefore, X hset(P (M )).limit ordinal, X = < X . induction hypothesis, every < ,X hset(P (M )). Thus, X hset(P (M )). induction, hset(P (M )).Derivable models. use computations define derivable models Horn constraint programs.set atoms derivable model Horn constraint program P P -computationt, = Rt . Proposition 1, derivable models P supported models P so,also models P .Derivable models similar least model normal Horn programderived program means bottom-up computation. However, due nondeterminismbottom-up computations Horn constraint programs, derivable models general uniqueminimal.Examples. example, let P following Horn constraint program:P = {1{a, b} }{a}, {b} {a, b} derivable models. derivable models {a} {b} minimalmodels P . third derivable model, {a, b}, minimal model P .4Since inconsistent monotone constraints may appear heads Horn rules, Hornprograms P sets X At, TPnd (X) = . Thus, Horn constraint programscomputations derivable models. However, Horn constraint program models,existence computations derivable models guaranteed.see this, let model Horn constraint program P . define canonical computation tP,M = hXP,M specifying choice next set computation part (2)Definition 1. Namely, every ordinal , setP,MX+1= hset(P (XP,M )) M.is, include XP,M atoms occurring heads XP,M -applicable rulesbelong . denote result tP,M Can(P, ). Canonical computations indeedP -computations.Proposition 2. Let P Horn constraint program. model P , sequence P,MP -computation.Proof. P fixed, simplify notation proof write X insteadXP,M .prove assertion, suffices show (1) hset(P (X )) TPnd (X ), (2)X hset(P (X )) , every ordinal .(1) Let X r P (X). Since constraints bd (r) monotone, X |= bd (r), |=bd (r), well. fact model P follows |= hd (r). Consequently,hset(P (X)) |= hd (r) every r P (X). Since hset(P (X)) hset(P (X)),hset(P (X)) TPnd (X).304fiP ROPERTIES PPLICATIONS P ROGRAMS ONOTONE C ONVEX C ONSTRAINTSDirectly definition canonical computation P obtain everyordinal , X . Thus, (1), follows.(2) proceed induction. basis evident X0 = . Let us consider ordinal > 0let us assume (2) holds every ordinal < . = + 1, X = X+1 =hset(P (X )) . Thus, induction hypothesis, X X . Since P Horn constraintprogram, follows P (X ) P (X ). ThusX = X+1 = hset(P (X )) hset(P (X )) M.limit ordinal every < , X X and, before, also P (X ) P (X ). Thus,induction hypothesis every < ,X hset(P (X )) hset(P (X )) M,impliesX =[X hset(P (X )) M.<Canonical computations following fixpoint property.Proposition 3. Let P Horn constraint program. every model P ,hset(P (Can(P, ))) = Can(P, ).P,M= XP,M = Can(P, ).Proof. Let length canonical computation tP,M . Then, X+1Since X+1 = hset(X ) , assertion follows.gather properties derivable models extend properties least model normalHorn logic programs.Proposition 4. Let P Horn constraint program. Then:1. every model P , Can(P, ) greatest derivable model P contained2. model P derivable model = Can(P, )3. minimal model P derivable model P .Proof. (1) Let 0 derivable model P 0 . Let = hX P -derivation0 = Rt . prove every ordinal , X XP,M . proceed transfiniteinduction. Since X0 = X0P,M = , basis induction evident. Let us consider ordinal> 0 assume every ordinal < , X XP,M .= + 1, X TPnd (X ) so, X hset(P (X )). induction hypothesismonotonicity constraints bodies rules P , X hset(P (XP,M )). Thus,since X Rt = 0 ,P,MX hset(P (XP,M )) = X+1= XP,M .305fiL IU & RUSZCZY NSKIcase limit ordinal straightforward X = < X XP,M = < XP,M .(2) () = Can(P, ), result canonical P -derivation P .particular, derivable model P .() derivable model P , also model P . (1) followsCan(P, ) greatest derivable model P contained . Since derivable,= Can(P, ).(3) (1) follows Can(P, ) derivable model P Can(P, ) . Sinceminimal model, Can(P, ) = and, (2), derivable model P .2.2 Stable Modelssection, recall adapt setting definition stable models proposedstudied Marek Truszczynski (2004) Marek et al. (2004, 2006) Let P monotoneconstraint program subset At(P ). reduct P , denoted P , programobtained P by:1. removing P rules whose body contains literal not(B) |= B;2. removing literals not(B) bodies remaining rules.reduct monotone-constraint program Horn since contains occurrences defaultnegation. Therefore, following definition sound.Definition 2. Let P monotone-constraint program. set atoms stable model Pderivable model P . denote set stable models P St(P ).definitions reduct stable models follow generalize proposed normallogic programs, since setting Horn constraint programs, derivable models play roleleast model.normal logic programming standard extensions, stable models monotoneconstraint programs supported models and, consequently, models.Proposition 5. Let P monotone-constraint program. At(P ) stable model P ,supported model P .Proof. Let stable model P . Then, derivable model P and, Proposition 1,supported model P . follows model P . Directly definitionreduct follows model P .also follows hset(P (M )). every rule r P (M ), rule r 0 P (M ),head non-negated literals body r. Thus, hset(P (M ))hset(P (M )) and, consequently, hset(P (M )). follows supported modelP.Examples. example stable models monotone-constraint program. Let Pmonotone-constraint program contains following rules:2{a, b, c} 1{a, d}, not(1{c})1{b, c, d} 1{a}, not(3{a, b, d}))1{a}306fiP ROPERTIES PPLICATIONS P ROGRAMS ONOTONE C ONVEX C ONSTRAINTSLet = {a, b}. Therefore, 6|= 1{c} 6|= 3{a, b, d}. Hence reduct P containsfollowing three Horn rules:2{a, b, c} 1{a, d}1{b, c, d} 1{a}1{a}Since = {a, b} derivable model P , stable model P .0Let 0 = {a, b, c}. 0 |= 1{c} 6|= 3{a, b, d}. Therefore, reduct P containstwo Horn rules:1{b, c, d} 1{a}1{a}0Since 0 = {a, b, c} derivable models P , 0 also stable model P . notestable models monotone-constraint program, general, form anti-chain.4normal logic program Horn least model (only) stable model.analogous situation.Proposition 6. Let P Horn monotone-constraint program. At(P ) derivablemodel P stable model P .Proof. every set atoms P = P . Thus, derivable model Pderivable model P or, equivalently, stable model P .next four sections paper show several fundamental results concerningnormal logic programs extend class monotone-constraint programs.3. Strong Uniform Equivalence Monotone-constraint ProgramsStrong equivalence uniform equivalence concern problem replacing rules logicprogram others without changing overall semantics program. specifically,strong equivalence concerns replacement rules within arbitrary programs, uniformequivalence concerns replacements non-fact rules. case, stipulationresulting program must stable models original one. Strong (and uniform)equivalence important concept due potential uses program rewriting optimization.Strong uniform equivalence studied literature mostly normal logicprograms (Lifschitz et al., 2001; Lin, 2002; Turner, 2003; Eiter & Fink, 2003).Turner (2003) presented elegant characterization strong equivalence smodels programs,Eiter Fink (2003) described similar characterization uniform equivalence normaldisjunctive logic programs. show characterizations adapted casemonotone-constraint programs. fact, one show representations normal logicprograms monotone-constraint programs (Marek et al., 2004, 2006) definitions characterizations strong uniform equivalence reduce introduced developed originallynormal logic programs.307fiL IU & RUSZCZY NSKI3.1 M-maximal Modelskey role approach played models Horn constraint programs satisfying certainmaximality condition.Definition 3. Let P Horn constraint program let model P . set NN model P hset(P (N )) N -maximal model P , written N |= P .Intuitively, N -maximal model P N satisfies rule r P (N ) maximallyrespect . is, every r P (N ), N contains atoms belong hset(r)domain head r.illustrate notion, let us consider Horn constraint program P consisting single rule:1{p, q, r} 1{s, t}.Let = {p, q, s, t} N = {p, q, s}. One verify N models P .Moreover, since rule P N -applicable, {p, q, r} N , N -maximalmodel P . hand, N 0 = {p, s} -maximal even though N 0 model Pcontained .several similarities properties models normal Horn programs maximal models Horn constraint programs. state prove one turnsespecially relevant study strong uniform equivalence.Proposition 7. Let P Horn constraint program let model P .-maximal model P Can(P, ) least -maximal model P .Proof. first claim follows directly definition. prove second one, simplifynotation: write N Can(P, ) X XP,M .first show N -maximal model P . Clearly, N . Moreover, Proposition3, hset(P (N )) = N . Thus, N indeed -maximal model P .show N least -maximal model P .Let N 0 -maximal model P . show transfinite induction N N 0 .Since X0 = , basis induction holds. Let us consider ordinal > 0 let us assumeX N 0 , every < . show N N 0 , sufficient show X N 0 .Let us assume = + 1 < . Then, since X N 0 P Horn constraintprogram, P (X ) P (N 0 ). Consequently,X = X+1 = hset(P (X )) hset(P (N 0 )) N 0 ,last inclusion follows factSthatN 0 -maximal model P .limit ordinal, X = < X inclusion X N 0 follows directlyinduction hypothesis.3.2 Strong Equivalence SE-modelsMonotone-constraint programs P Q strongly equivalent, denoted P Q, everymonotone-constraint program R, P R Q R set stable models.study strong equivalence monotone-constraint programs, generalize conceptSE-model due Turner (2003).308fiP ROPERTIES PPLICATIONS P ROGRAMS ONOTONE C ONVEX C ONSTRAINTSclose connections strong equivalence normal logic programs logichere-and-there. semantics logic here-and-there given terms Kripke modelstwo words which, rephrased terms pairs interpretations (pairs sets propositionalatoms), give rise SE-models.Definition 4. Let P monotone-constraint program let X, sets atoms. say(X, ) SE-model P following conditions hold: (1) X ; (2) |= P ; (3)X |=Y P . denote SE(P ) set SE-models P .Examples. illustrate notion SE-model monotone-constraint program, let P consistfollowing two rules:2{p, q, r} 1{q, r}, not(3{p, q, r})}1{p, s} 1{p, r}, not(2{p, r})observe = {p, q} model P . Let N = . N P (N ) empty.follows hset(P (N )) = N so, N |=M P . Hence, (N, ) SE-modelsP .Next, let N 0 = {p}. clear N 0 . Moreover, P (N 0 ) = {1{p, s} 1{p, r}}.Hence hset(P (N 0 )) = {p} N 0 so, N 0 |=M P . is, (N 0 , ) another SEmodel P .4SE-models yield simple characterization strong equivalence monotone-constraint programs. state prove it, need several auxiliary results.Lemma 1. Let P monotone-constraint program let model P . (M, )(Can(P , ), ) SE-models P .Proof. requirements (1) (2) SE-model hold (M, ). Furthermore, sincemodel P , |= P . Finally, also hset(P (M )) . Thus, |=M P .Similarly, definition canonical computation Proposition 1, imply first two requirements definition SE-models (Can(P , ), ). third requirement followsProposition 7.Lemma 2. Let P Q two monotone-constraint programs SE(P ) = SE(Q).St(P ) = St(Q).Proof. St(P ), model P and, Lemma 1, (M, ) SE(P ). Hence,(M, ) SE(Q) and, particular, |= Q. Lemma 1 again,(Can(QM , ), ) SE(Q).assumption,(Can(QM , ), ) SE(P )so, Can(QM , ) |=M P or, terms, Can(QM , ) -maximal model P .Since St(P ), = Can(P , ). Proposition 7, least -maximal modelP . Thus, Can(QM , ). hand, Can(QM , ) so,= Can(QM , ). follows stable model Q. inclusion provedway.309fiL IU & RUSZCZY NSKILemma 3. Let P R two monotone-constraint programs. SE(P R) = SE(P )SE(R).Proof. assertion follows following two simple observations. First, every setatoms, |= (P R) |= P |= R. Second, every two sets Xatoms, X |=Y (P R)Y X |=Y P X |=Y RY .Lemma 4. Let P , Q two monotone-constraint programs. P Q, P Qmodels.Proof. Let model P . r denote constraint rule (M, {M }) . Then,St(P {r}). Since P Q strongly equivalent, St(Q {r}). followsmodel Q {r} so, also model Q. converse inclusion provedway.Theorem 1. Let P Q monotone-constraint programs. P Q SE(P ) =SE(Q).Proof. () Let R arbitrary monotone-constraint program. Lemma 3 implies SE(PR) = SE(P ) SE(R) SE(Q R) = SE(Q) SE(R). Since SE(P ) = SE(Q),SE(P R) = SE(Q R). Lemma 2, P R Q R stable models.Hence, P Q holds.() Let us assume SE(P ) \ SE(Q) 6= let us consider (X, ) SE(P ) \ SE(Q). followsX |= P . Lemma 4, |= Q. Since (X, )/ SE(Q), X 6|= QY . followsX 6|= QY hset(QY (X)) 6 X. first case, rule r QY (X)X 6|= hd (r). Since X QY Horn constraint program, r QY (Y ). Let us recall|= Q so, also |= QY . follows |= hd (r). Since hset(r) hset(QY (X)),hset(QY (X)) |= hd (r). Thus, hset(QY (X)) 6 X (otherwise, monotonicityhd (r), would X |= hd (r)).property holds second case. Thus, follows(hset(QY (X)) ) \ X 6= .defineX 0 = (hset(QY (X)) ) \ X.Let R constraint program consisting following two rules:(X, {X})(Y, {Y }) (X 0 , {X 0 }).Let us consider program Q0 = Q R. Since |= Q X , |= Q0 . Thus, |= QY0 and,particular, Can(QY0 , ) well defined. Since R QY0 , X Can(QY0 , ). Thus,hset(QY0 (X)) hset(QY0 (Can(QY0 , ))) = Can(QY0 , )(the last equality follows Proposition 3). also Q Q 0 so,X 0 hset(QY (X)) hset(QY0 (X)) Y.310fiP ROPERTIES PPLICATIONS P ROGRAMS ONOTONE C ONVEX C ONSTRAINTSThus, X 0 Can(QY0 , ). Consequently, Proposition 3, Can(QY0 , ). Since Can(QY0 , ), = Can(QY0 , ) so, St(Q0 ).Since P Q strongly equivalent, St(P0 ), P0 = P R. Let us recall(X, ) SE(P ). Proposition 7, Can(P , ) least -maximal model P . Since X-maximal model P (as X |=Y P ), follows Can(P , ) X. Since X 0 6 X,Can(P0Y , ) X. Finally, since X 0 , 6 X. Thus, 6= Can(P0Y , ), contradiction.follows SE(P ) \ SE(Q) = . symmetry, SE(Q) \ SE(P ) = , too. Thus, SE(P ) =SE(Q).3.3 Uniform Equivalence UE-modelsLet set atoms. rD denote monotone-constraint rulerD = (D, {D}) .Adding rule rD program forces atoms true (independently program).Monotone-constraint programs P Q uniformly equivalent, denoted P u Q,every set atoms D, P {rD } Q {rD } stable models.SE-model (X, ) monotone-constraint program P UE-model P everySE-model (X 0 , ) P X X 0 , either X = X 0 X 0 = holds. write U E(P )denote set UE-models P . notion UE-model generalization notionUE-model due Eiter Fink (2003) setting monotone-constraint programs.Examples. Let us look program used illustrate concept SE-model.showed (, {p, q}) ({p}, {p, q}) SE-models P . Directly definitionUE-models follows ({p}, {p, q}) UE-model P .4present characterization uniform equivalence monotone-constraint programsassumption sets atoms finite. One prove characterization uniformequivalence arbitrary monotone-constraint programs, generalizing one results EiterFink (2003). However, characterization proof complex and, brevity,restrict attention finite case only.start auxiliary result, allows us focus atoms At(P ) deciding whether pair (X, ) sets atoms SE-model monotone-constraint programP.Lemma 5. Let P monotone-constraint program, X two sets atoms. (X, )SE(P ) (X At(P ), At(P )) SE(P ).Proof. Since X given, X implies X At(P ) At(P ), first conditiondefinition SE-model holds sides equivalence.Next, note every constraint C, |= C Dom(C) |= C. Therefore,|= P At(P ) |= P . is, second condition definition SE-modelholds (X, ) holds (X At(P ), At(P )).Finally, observe P = P At(P ) P (X) = P (X At(P )). Therefore,hset(P (X)) = hset(P At(P ) (X At(P ))).Since hset(P At(P ) (X At(P ))) At(P ), followshset(P (X)) X311fiL IU & RUSZCZY NSKIAt(P ) hset(P At(P ) (X At(P ))) X At(P ).Thus, X |=Y P X At(P ) |=Y At(P ) P At(P ) . is, third conditiondefinition SE-model holds (X, ) holds (X At(P ), At(P )).Lemma 6. Let P monotone-constraint program At(P ) finite. every(X, ) SE(P ) X 6= , set{X 0 : X X 0 Y, X 0 6= Y, (X 0 , ) SE(P )}(2)maximal element.Proof. At(P )X = At(P )Y , every element \X, \{y} maximal elementset (2). Indeed, since (X, ) SE(P ), Lemma 5, (X At(P ), At(P )) SE(P ).Since X At(P ) = At(P ) 6 At(P ), X At(P ) = (Y \ {y}) At(P ). Therefore,((Y \{y})At(P ), At(P )) SE(P ). Lemma 5 fact \{y} ,(Y \ {y}, ) SE(P ). Therefore, \ {y} belongs set (2) so, maximal elementset.Thus, let us assume At(P ) X 6= At(P ) . Let us define X 0 = X (Y \ At(P )).X X 0 X 0 6= . Moreover, element X 0 \ X belongs At(P ). is,X 0 At(P ) = X At(P ). Thus, Lemma 5, (X 0 , ) SE(P ) so, X 0 belongs set(2). Since \ X 0 At(P ), finiteness At(P ) follows set (2) contains maximalelement containing X 0 . particular, contains maximal element.Theorem 2. Let P Q two monotone-constraint programs At(P ) At(Q) finite.P u Q U E(P ) = U E(Q).Proof. () Let arbitrary set atoms stable model P {r }.model P {rD }. particular, model P so, (Y, ) U E(P ). follows(Y, ) U E(Q), too. Thus, model Q. Since model r , . Consequently,model Q {rD } thus, also (Q {rD })Y .Let X = Can((Q {rD })Y , ). X and, Proposition 7, X -maximalmodel (Q {rD })Y . Consequently, X -maximal model QY . Since X |= Q,(X, ) SE(Q).Let us assume X 6= . Then, Lemma 6, maximal set X 0 X X 0, X 0 6= (X 0 , ) SE(Q). follows (X 0 , ) U E(Q). Thus, (X 0 , ) U E(P )so, X 0 |=Y P . Since X 0 , X 0 |=Y (P {rD })Y . recall stable modelP {rD }. Thus, = Can((P {rD })Y , ). Proposition 7, X 0 get X 0 = ,contradiction. follows X = and, consequently, stable model Q {r }.symmetry, every stable model Q {rD } also stable model P {rD }.() First, note (Y, ) U E(P ) model P . Next, note PQ models. Indeed, argument used proof Lemma 4 works alsoassumption P u Q. Thus, (Y, ) U E(P ) (Y, ) U E(Q).let us assume U E(P ) 6= U E(Q). Let (X, ) element (U E(P ) \ U E(Q))(U E(Q) \ U E(P )). Without loss generality, assume (X, ) U E(P ) \ U E(Q).Since (X, ) U E(P ), follows312fiP ROPERTIES PPLICATIONS P ROGRAMS ONOTONE C ONVEX C ONSTRAINTS1. X2. |= P and, consequently, |= Q3. X 6= (otherwise, earlier observations, (X, ) would belong U E(Q)).Let R = (Q {rX })Y . Clearly, R Horn constraint program. Moreover, since |= QX , |= R. Thus, Can(R, ) defined. X Can(R, ) . claimCan(R, ) 6= . Let us assume contrary Can(R, ) = . St(Q {r X }).Hence, St(P {rX }), is, = Can((P {rX })Y , ). Proposition 7,least -maximal model (P {rX })Y X -maximal model (P {rX })Y (since(X, ) SE(P ), X |=Y P so, X |=Y (P {rX })Y , too). Consequently, X and,X , X = , contradiction.Thus, Can(R, ) 6= . Proposition 7, Can(R, ) -maximal model R. SinceQY R, follows Can(R, ) -maximal model QY so, (Can(R, ), )SE(Q). Since Can(R, ) 6= , Lemma 6 follows maximal set X 0Can(R, ) X 0 , X 0 6= (X 0 , ) SE(Q). definition, (X 0 , ) U E(Q).Since (X, )/ U E(Q). X 6= X 0 . Consequently, since X X 0 , X 0 6= (X, ) U E(P ),(X 0 , )/ U E(P ).Thus, (X 0 , ) U E(Q) \ U E(P ). applying argument (X 0 , )show existence X 00 X 0 X 00 , X 0 6= X 00 , X 00 6= (X 00 , ) SE(P ).Consequently, X X 00 , X 6= X 00 6= X 00 , contradicts fact (X, )U E(P ). follows U E(P ) = U E(Q).Examples. Let P = {1{p, q} not(2{p, q})}, Q = {p not(q), q not(p)}.P Q strongly equivalent. note programs {p}, {q}, {p, q} models.Furthermore, ({p}, {p}), ({q}, {q}), ({p}, {p, q}), ({q}, {p, q}), ({p, q}, {p, q}) (, {p, q})SE-models two programs 3 .Thus, Theorem 1, P Q strongly equivalent.also observe first five SE-models precisely UE-models P Q. Therefore,Theorem 2, P Q also uniformly equivalent.possible two monotone-constraint programs uniformly strongly equivalent.add rule p P , rule p q Q, two resulting programs, say P 0 Q0 ,uniformly equivalent. However, strongly equivalent. programs P 0 {q p}Q0 {q p} different stable models. Another way show observing (, {p, q})SE-model Q0 SE-model P 0 .44. Fages Lemmageneral, supported models stable models logic program (both normal casemonotone-constraint case) coincide. Fages Lemma (Fages, 1994), later extended ErdemLifschitz (2003), establishes sufficient condition supported model normal logic program stable. section, show Fages Lemma extends programsmonotone constraints.3. Lemma 5 Theorem 1, follows SE-models contain atoms At(P ) At(Q)essential ones.313fiL IU & RUSZCZY NSKIDefinition 5. monotone-constraint program P called tight set At(P ) atoms,exists mapping ordinals every rule 1 , . . . , Ak , not(Ak+1 ),. . . , not(Am ) P (M ), X domainXi domain Ai , 1 k,every x X every ki=1 Xi , (a) < (x).show tightness provides sufficient condition supported modelstable. order prove general result, first establish Horn case.Lemma 7. Let P Horn monotone-constraint program let supported model P .P tight , stable model P .Proof. Let arbitrary supported model P P tight . Let mappingshowing tightness P . show every ordinal every atom x(x) , x Can(P, ). proceed induction.basis induction, let us consider atom x (x) = 0. Sincesupported model P x , exists rule r P (M ) x hset(r). Moreover,since P tight , every bd (r) every Dom(A) , (y) < (x) = 0.Thus, every bd (r), Dom(A) = . Since |= bd (r) since P Horn monotoneconstraint program, follows |= bd (r). Consequently, hset(r) Can(P, ) so,x Can(P, ).Let us assume assertion holds every ordinal < let us consider x(x) = . before, since supported model P , exists rule r P (M )x hset(r). assumption, P tight and, consequently, every bd (r)every Dom(A) , (y) < (x) = . induction hypothesis, every bd (r),Dom(A) Can(P, ). Since P Horn monotone-constraint program, Can(P, ) |=bd (r). Proposition 3, hset(r) Can(P, ) so, x Can(P, ).follows Can(P, ). definition canonical computation,Can(P, ) . Thus, = Can(P, ). Proposition 6, stable model P .Given lemma, general result follows easily.Theorem 3. Let P monotone-constraint program let supported model P . Ptight , stable model P .Proof. One check supported model P , supported model reductP . Since P tight , reduct P tight , too. Thus, stable model P(by Lemma 7) and, consequently, derivable model P (by Proposition 6). followsstable model P .5. Logic PLmc Completion Monotone-constraint Programcompletion normal logic program (Clark, 1978) propositional theory whose modelsprecisely supported models program. Thus, supported models normal logic programscomputed means SAT solvers. conditions, instance, assumptionsFages Lemma hold, supported models stable. Thus, computing models completionyield stable models, idea implemented first version cmodels software (Babovich &Lifschitz, 2002).314fiP ROPERTIES PPLICATIONS P ROGRAMS ONOTONE C ONVEX C ONSTRAINTSgoal extend concept completion programs monotone constraints.completion, define it, retains much structure monotone-constraint rules allowus, restricted setting lparse programs, use pseudo-boolean constraint solvers computesupported models programs. section define completion prove resultrelating supported models programs models completion. discuss extensionsresult next section practical computational applications Section 8.define completion, first introduce extension propositional logic monotoneconstraints, formalism denote PLmc . formula logic PLmc expression builtmonotone constraints means boolean connectives , (and infinitary counterparts),. notion model constraint, discussed earlier, extends standardway class formulas logic PLmc .set L = {A1 , . . . , Ak , not(Ak+1 ), . . . , not(Am )} literals, defineL = A1 . . . Ak Ak+1 . . . .Let P monotone-constraint program. form completion P , denoted Comp(P ),follows:1. every rule r P include Comp(P ) PLmc formula[bd (r)] hd (r)2. every atom x At(P ), include Comp(P ) PLmc formula_x {[bd (r)] : r P, x hset(r)}(we note set rules P infinite, disjunction may infinitary).following theorem generalizes fundamental result program completion normallogic programming (Clark, 1978) case programs monotone constraints.Theorem 4. Let P monotone-constraint program. set At(P ) supported modelP model Comp(P ).Proof. () Let us suppose supported model P . model P , is,rule r P , |= bd (r) |= hd (r). Since |= bd (r) |= [bd (r)] ,follows formulas Comp(P ) first type satisfied .Moreover, since supported model P , hset(P (M )). is, every atomx , exists least one rule r P x hset(r) |= bd (r). Therefore,formulas Comp(P ) second type satisfied , too.() Let us suppose model Comp(P ). Since |= bd (r) |=[bd (r)] , since satisfies formulas first typeW Comp(P ), model P .Let x . WSince satisfies formula x {[bd (r)] : r P, x hset(r)}, followssatisfies {[bd (r)] : r P, x hset(r)}. is, r P satisfies[bd (r)] (and so, bd (r), too) x hset(r). Thus, x hset(P (M )). Hence, supportedmodel P .Theorems 3 4 following corollary.315fiL IU & RUSZCZY NSKICorollary 5. Let P monotone-constraint program. set At(P ) stable model PP tight model Comp(P ).observe material section necessary require constraintsappearing bodies program rules monotone. However, since interestedcase, adopted monotonicity assumption here, well.6. Loops Loop Formulas Monotone-constraint Programscompletion alone quite satisfactory relates supported stable models monotoneconstraint programs models PLmc theories. Loop formulas, proposed Lin Zhao(2002), provide way eliminate supported models normal logic programs,stable. Thus, allow us use SAT solvers compute stable models arbitrary normal logicprograms those, supported stable models coincide.extend idea monotone-constraint programs. section, restrictconsiderations programs P finitary, is, At(P ) finite. restriction impliesmonotone constraints appear finitary programs finite domains.Let P finitary monotone-constraint program. positive dependency graph Pdirected graph GP = (V, E), V = At(P ) hu, vi edge E exists ruler P u hset(r) v Dom(A) monotone constraint bd (r) (that is,appears non-negated bd (r)). note positive dependency graphs finitary programsfinite.Let G = (V, E) directed graph. set L V loop G subgraph G inducedL strongly connected. loop maximal proper subset loop G.Thus, maximal loops vertex sets strongly connected components G. maximal loopterminating edge G L maximal loop.concepts extended case programs. loop (maximal loop, terminatingloop) monotone-constraint program P , mean loop (maximal loop, terminating loop)positive dependency graph GP P . observe every finitary monotone-constraintprogram P terminating loop, since GP finite.Let X At(P ). GP [X] denote subgraph GP induced X. observeX 6= every loop GP [X] loop GP .Let P monotone-constraint program P . every model P (in particular, everymodel Comp(P )), define = \ Can(P , ). Since model P ,model P . Thus, Can(P , ) well defined .every loop graph GP define corresponding loop formula. First,constraint = (X, C) set L At, set A|L = (X, {Y C : L = }) call A|Lrestriction L. Next, let r monotone-constraint rule, sayr = A1 , . . . , Ak , not(Ak+1 ), . . . , not(Am ).L At, define PLmc formula L (r) settingL (r) = A1 |L . . . Ak |L Ak+1 . . . .Let L loop monotone-constraint program P . Then, loop formula L, denotedLP (L), PLmc formula__LP (L) =L {L (r) : r P L hset(r) 6= }316fiP ROPERTIES PPLICATIONS P ROGRAMS ONOTONE C ONVEX C ONSTRAINTS(we recall use convention write constraint C(a) = ({a}, {{a}}). loopcompletion finitary monotone-constraint program P PL mc theoryLComp(P ) = Comp(P ) {LP (L) : L loop GP }.following theorem exploits concept loop formula provide necessary sufficient condition model stable model. transfinite one.Theorem 6. Let P finitary monotone-constraint program. set At(P ) stable modelP model LComp(P ).Proof. () Let stable model P . supported model P and, Theorem 4,|= Comp(P ).Let L loop P . L = |= LP (L). Thus, let us assume L 6= .Since stable model P , derivable model P , is, = Can(P , ).Let (Xn )n=0,1,... canonical P -derivation respect (since assume Pfinite constraint P finite domain, P -derivations reach results finitely manysteps). Since Can(P , ) L = L 6= , smallest index n Xn L 6= .particular, follows n > 0 (as X0 = ) L Xn1 = .Since Xn = hset(P (Xn1 ) Xn L 6= , rule r P (Xn1 )hset(r) L 6= , is, L hset(r)) 6= . Let r 0 rule P , contributes rP . Then, every literal not(A) bd (r 0 ), |= not(A). Let bd (r 0 ). bd (r)so, Xn1 |= A. Since Xn1 L = , Xn1 |= A|L , too, monotonicity A|L , |= A|L .Thus, |= L (r0 ). Since hset(r 0 ) L 6= , L hset(r)) 6= so, |= LP (L). Thus,|= LComp(P ).() Let us consider set At(P ) stable model P .supported model P 6|= Comp(P ) model LComp(P ). Thus, let usassume supported model P . follows 6= . Let L terminatingloop GP [M ].Let r0 arbitrary rule P Lhset(r 0 )) 6= , let r rule obtained r 0removing negated constraints body. Now, let us assume |= r0 (L). followsevery literal not(A) bd (r 0 ), |= not(A). Thus, r P . Moreover, since L terminatingloop GP [M ], every constraint bd (r 0 ), Dom(A)M L. Since |= A|L , followsCan(P , ) |= A. Consequently, hset(r 0 ) LW hset(r 0 ) Can(P , ) so,000L Can(PW, ) 6= , contradiction. Thus, 6|= {r (L) : r P L hset(r )) 6= }.Since |= L, follows 6|= LP (L) so, 6|= LComp(P ).following result follows directly proof Theorem 6 provides us wayfilter specific non-stable supported models Comp(P ).Theorem 7. Let P finitary monotone-constraint program model Comp(P ).empty, violates loop formula every terminating loop G P [M ].Finally, point that, Theorem 6 hold program P contains infinitely manyrules. counterexample:Examples. Let P set following rules:317fiL IU & RUSZCZY NSKI1{a0 } 1{a1 }1{a1 } 1{a2 }1{an } 1{an+1 }Let = {a0 , . . . , , . . .}. supported model P . stable model P. However, = \ contain terminating loop. problem arisesinfinite simple path GP [M ]. Therefore, GP [M ] sink, yetterminating loop either.4results section, concerning program completion loop formulas importantly, loop-completion theorem form basis new software system computestable models lparse programs. discuss matter Section 8.7. Programs Convex Constraintsdiscuss programs convex constraints, closely related programsmonotone constraints. Programs convex constraints interest involve explicit occurrences default negation operator not, yet expressive programsmonotone-constraints. Moreover, directly subsume essential fragment class lparseprograms (Simons et al., 2002).constraint (X, C) convex, every W, Y, Z X W Z W, Z C,C. constraint rule form (1) convex-constraint rule A, 1 , . . . ,convex constraints = k. Similarly, constraint program built convex-constraint rulesconvex-constraint program.concept model discussed Section 2 applies convex-constraint programs. definesupported stable models convex-constraint programs, view special programsmonotone-constraints.end, define upward downward closures constraint = (X, C)constraints A+ = (X, C + ) = (X, C ), respectively,C + = {Y X : W C, W },C = {Y X : W C, W }.note constraint A+ monotone. call constraint (X, C) antimonotone C closedsubset, is, every W, X, C W W C. clearconstraint antimonotone.upward downward closures allow us represent convex constraint conjunction monotone constraint antimonotone constraint.Namely, followingproperty convex constraints.Proposition 8. constraint (X, C) convex C = C + C .Proof. () Let us assume C = C + C let us consider set 0 00 ,0 , 00 C. follows 0 C + 00 C . Thus, C + C .Consequently, C, implies (X, C) convex.318fiP ROPERTIES PPLICATIONS P ROGRAMS ONOTONE C ONVEX C ONSTRAINTS() definitions directly imply C C + C C . Thus, C C + C . Let usconsider C + C . sets 0 , 00 C 0 00 . SinceC convex, C. Thus, C + C C so, C = C + C .Proposition 8 suggests encoding convex-constraint programs monotone-constraint programs. present it, need notation. constraint = (X, C), call constraint(X, C), C = P(X) \ C, dual constraint A. denote A. direct consequence definitions constraint monotone dual antimonotone.Let C convex constraint. set mc(C) = {C} C monotone. set mc(C) ={not(C)}, C antimonotone. define mc(C) = {C + , not(C )}, C neither monotoneantimonotone. Clearly, C mc(C) models.Let P convex-constraint program. mc(P ) denote program monotone constraints obtained replacing every rule r P rule r 0[hd (r0 ) = hd (r)+ bd (r 0 ) = {mc(A) : bd (r)}and, hd (r) monotone, also additional rule r 00hd (r00 ) = (, ) bd (r 00 ) = {hd (r) } bd (r 0 ).observation above, constraints appearing rules mc(P ) indeed monotone, is,mc(P ) program monotone constraints.follows Proposition 8 model P model mc(P ).extend correspondence supported stable models convex constraint program Pmonotone-constraint program mc(P ).Definition 6. Let P convex constraint program. set atoms supported (orstable) model P supported (or stable) model mc(P ).definitions, monotone-constraint programs viewed (almost) directly convexconstraint programs. Namely, note monotone antimonotone constraints convex.Next, observe monotone constraint, expression not(A) meaningantimonotone constraint sense every interpretation , |= not(A)|= A.Let P monotone-constraint program. cc(P ) denote program obtained Preplacing every rule r form (1) P r 0[[hd (r0 ) = hd (r) bd (r 0 ) = {Ai : = 1, . . . , k} {Aj : j = k + 1, . . . , m}One show programs P cc(P ) models, supported models stablemodels. fact, every monotone-constraint program P P = mc(cc(P )).Remark. Another consequence discussion default negation operator eliminated syntax price allowing antimonotone constraints using antimonotoneconstraints negated literals.2Due correspondences established above, one extend convex-constraintprograms concepts results discussed earlier context monotone-constraint programs. many cases, also stated directly language convex-constraints.319fiL IU & RUSZCZY NSKIimportant us notions completion loop formulas, lead newalgorithms computing stable models lparse programs. Therefore, discussdetail.mentioned, could use Comp(mc(P )) definition completion Comp(P )convex-constraint logic program P . definition Theorems 9 extends caseconvex-constraint programs. However, Comp(mc(P )) involves monotone constraintsnegations convex constraints appear P . Therefore, propose anotherapproach, preserves convex constraints P .end, first extend logic PLmc convex constraints. extension,denote PLcc refer propositional logic convex-constraints, formulasboolean combinations convex constraints. semantics formulas given notionmodel obtained extending boolean connectives concept model convexconstraint.Thus, difference logic PLmc , used define completionloop completion monotone-convex programs logic PL cc former uses monotone constraints building blocks formulas, whereas latter based convex constraints.fact, since monotone constraints special convex constraints, logic PL mc fragmentlogic PLcc .Let P convex-constraint program. completion P , denotedComp(P ), following set PLcc formulas:1. every rule r P include Comp(P ) PLcc formula[bd (r)] hd (r)(as before, set convex constraints L, L denotes conjunction constraintsL)2. every atom x At(P ), include Comp(P ) PLcc formula_x {[bd (r)] : r P, x hset(r)}(again, note set rules P infinite, disjunction may infinitary).One show following theorem.Theorem 8. Let P convex-constraint program let At(P ). supportedmodel P model Comp(P ).Proof. (Sketch) definition, supported model P supportedmodel mc(P ). matter routine checking Comp(mc(P )) Comp(P )models. Thus assertion follows Theorem 4.Next, restrict attention finitary convex-constraint programs, is, programs finiteset atoms, extend class programs notions positive dependency graphloops. end, exploit representation monotone-constraint program mc(P ). is,define positive dependency graph, loops loop formulas P positive dependencygraph, loops loop formulas mc(P ), respectively. particular, L loop P320fiP ROPERTIES PPLICATIONS P ROGRAMS ONOTONE C ONVEX C ONSTRAINTSL loop mc(P ) loop formula L, respect convex-constraint program P ,defined loop formula LP (L) respect program mc(P ) 4 . note since loopformulas monotone-constraint programs modify non-negated literals bodies rulesleave negated literals intact, seems simple way extend notion loopformula case convex-constraint program P without making references mc(P ).define loop completion finitary convex-constraint program P PL cc theoryLComp(P ) = Comp(P ) {LP (L) : L loop P }.following theorem provides necessary sufficient condition setatoms stable model convex-constraint program.Theorem 9. Let P finitary convex-constraint program. set At(P ) stable modelP model LComp(P ).Proof. (Sketch) Since stable model P stable model mc(P ), Theorem 6 implies stable model P stable model LComp(mc(P )).matter routine checking LComp(mc(P )) LComp(P ) models.Thus, result follows.similar way, Theorem 7 implies following result convex-constraint programs.Theorem 10. Let P finitary convex-constraint program model Comp(P ).empty, violates loop formula every terminating loop G P [M ].emphasize one could simply use LComp(mc(P )) definition loop completionconvex-constraint logic program. However, definition completion componentloop completion retains structure constraints program P , important usingloop completion computation stable models, topic address next sectionpaper.8. Applicationssection, use theoretical results program completion, loop formulas loopcompletion programs convex constraints design implement new method computing stable models lparse programs (Simons et al., 2002).8.1 Lparse ProgramsSimons et al. (2002) introduced studied extension normal logic programming weightatoms. Formally, weight atom expression= l[a1 = w1 , . . . , ak = wk ]u,ai , 1 k propositional atoms, l, u wi , 1 k non-negative integers.weights wi equal 1, cardinality atom, written l{a1 , . . . , ak }u.4. one minor simplification one might employ. monotone constraint A, equivalentantimonotone so, convex. Thus, eliminate operator loop formulas convex-constraintprograms writing instead A.321fiL IU & RUSZCZY NSKIlparse rule expression form1 , . . . ,A, A1 , . . . , weight atoms. refer sets lparse rules lparse programs. Simonset al. (2002) defined lparse programs semantics stable models.set atoms model (or satisfies) weight atom l[a1 = w1 , . . . , ak = wk ]ulkX{wi : ai } u.i=1semantics weight atom l[a1 = w1 , . . . , ak = wk ]u identified constraint(X, C), X = {a1 , . . . , ak }kX{wi : ai } u}.C = {Y X : li=1notice weights weight atom W non-negative. Therefore, 0 0000 models W , 0 also model W . follows constraint(X, C) define convex.Since (X, C) convex, weight atoms represent class convex constraints lparse programs syntactically class programs convex constraints. relationship extendsstable-model semantics. Namely, Marek Truszczy nski (2004) Marek et al. (2004, 2006)showed lparse programs encoded programs monotone constraintsconcept stable model preserved. transformation used coincides encodingmc described previous section, restrict latter lparse programs. Thus,following theorem.Theorem 11. Let P lparse program. set stable model P accordingdefinition Simons et al. (2002) stable model P according definitiongiven previous section (when P viewed convex-constraint program).follows compute stable models lparse programs use results obtainedearlier paper, specifically results program completion loop formulas convexconstraint programs.Remark. precise, syntax lparse programs general. allows atomsnegated atoms appear within weight atoms. also allows weights negative. However,negative weights lparse programs treated notational convenience. Specifically,expression form = w within weight atom (where w < 0) represents expressionnot(a) = w (eliminating negative weights way weight atom requires modifications bounds associated weight atom). Moreover, introducing new propositionalvariables one remove occurrences negative literals programs. transformations preserve stable models (modulo new atoms). Marek Truszczy nski (2004) Marek et al. (2004,2006) provide detailed discussion transformation.addition weight atoms, bodies lparse rules may contain propositional literals (atomsnegated atoms) conjuncts. replace propositional literals weight atoms322fiP ROPERTIES PPLICATIONS P ROGRAMS ONOTONE C ONVEX C ONSTRAINTSfollows: atom replaced cardinality atom 1{a}, literal not(a)cardinality atom {a}0. transformation preserves stable models, too. Moreover,size resulting program increase constant factor. Thus,transformations discussed here, monotone- convex-constraint programs capture arbitrary lparseprograms.28.2 Computing Stable Models Lparse Programssection present algorithm computing stable models lparse programs. methoduses results obtained Section 7 reduce problem computing modelsloop completion lparse program. loop completion formula logic PL cc ,class convex constraints restricted weight constraints, defined previoussubsection. denote fragment logic PLcc consisting formulas PLwa .make method practical, need programs compute models theories logicPLwa . show general way adapt task off-the-shelf pseudo-boolean constraintsolvers (Een & Sorensson, 2003; Aloul et al., 2002; Walser, 1997; Manquinho & Roussel, 2005; Liu& Truszczynski, 2003).Pseudo-boolean constraints (PB short) integer programming constraints variables 0-1 domains. write inequalitiesw1 x1 + . . . + wk xk comp w,(3)comp stands one relations , , < >, w w integer coefficients(not necessarily non-negative), xi integers taking value 0 1. set pseudo-booleanconstraints pseudo-boolean theory.Pseudo-boolean constraints viewed constraints. basic idea treat 0-1 variable x propositional atom (which denote letter). correspondence,pseudo-boolean constraint (3) equivalent constraint (X, C), X = {x 1 , . . . , xk }C = {Y X :kX{wi : xi } comp w}i=1sense solutions (3) correspond models (X, C) (x = 1 solutionxi true corresponding model). particular, coefficients w bound w (3)non-negative, comp = , constraint (3) equivalent monotone lower-boundweight atom w[x1 = w1 , . . . , xn = wn ].follows arbitrary weight atom represented one two pseudo-boolean constraints. generally, arbitrary PLwa formula F encoded set PB constraints.describe translation two-step process.first step consists converting F clausal form cl (F )5 . control sizetranslation, introduce auxiliary propositional atoms. Below, describe translation F 7cl (F ) assumption F formula loop completion lparse program P .main motivation compute stable models logic programs end algorithmscomputing models loop completions sufficient.5. PLwa clause formula B1 . . . Bm H1 . . . Hn , Bi Hj weight atoms.323fiL IU & RUSZCZY NSKILet F formula loop completion lparse-program P . define cl (F ) follows(in transformation, use propositional atom x shorthand cardinality atom C(x) =1{x}).1. F form A1 . . . A, cl (F ) = F2. F form x ([bd (r1 )] ) . . . ([bd (rl )] ), introduce new propositionalatoms br,1 , . . . , br,l set cl (F ) consist following PLwa clauses:x br,1 . . . br,l[bd (ri )] br,i , every bd (ri )br,i Aj , every bd (ri ) Aj bd (ri )W3. F form L r {L (r)}, L set atoms, every L (r) conjunction weightW atoms, introduce new propositional atoms bdf L,r every L (r) Frepresent L weight atom WL = 1[li = 1 : li L]. define cl (F ) consistfollowing clauses:_WLbdfL,rWL (r) bdfL,r , every L (r) FbdfL,r Aj , every L (r) F Aj L (r).clear size cl (F ) linear size F .second step translation, converts PLwa formula C clausal form setPB constraints, pb (C). define translation C pb (C), let us consider PLwa clause CformB1 . . . B H 1 . . . H n ,(4)Bi Hi weight atoms.introduce new propositional atoms b1 , . . . , bm h1 , . . . , hn represent weight atomclause. noted earlier paper, simply write x weight atoms form 1[x =1]. new atoms, clause (4) becomes propositional clause b 1 . . . bm h1 . . . hn .represent following PB constraint:b1 . . . bm + h1 + . . . + hn 1 m.(5)later paper, use symbols denote propositional variables corresponding 0-1 integer variables. context always imply correct meaning symbols.convention, easy see propositional clause b 1 . . . bm h1 . . . hnPB constraint (5) models.introduce next PB constraints enforce equivalence newly introduced atomsbi (or hi ) corresponding weight atoms Bi (or Hi ).Let B = l[a1 = w1 , . . . , ak = wk ]u weight atom b propositional atom. split BB + B introduce two atoms b+ b . model B b, model pseudoboolean constraints following three equivalences: b b + b , b+ B + , b B .1. first equivalence captured three propositional clauses. Hence following threePB constraints model equivalence:b + b+ 0324(6)fiP ROPERTIES PPLICATIONS P ROGRAMS ONOTONE C ONVEX C ONSTRAINTSb + b 0(7)b+ b + b 1(8)2. second equivalence, b+ B + , modeled following two PB constraints(l) b+ +kX(ai wi ) 0(9)i=1(kXwi l + 1) b+ +kX3. Similarly, third equivalence,kX(10)i=1i=1((ai wi ) l 1bB,modeled following two PB constraintswi u) b +kXi=1i=1(u + 1) b +kX(ai wi )kXwi(11)i=1(ai wi ) u + 1(12)i=1PLwadefine pb (C),clause C, set pseudo-boolean constraints (5)(6), (7), (8), (11), (12), (9), (10) constructed every weight atom occurring C. One verifysize pb (C) linear size C. Therefore, pb (cl (F )) size linear sizeF.special case Bi Hj weight atoms form 1[bi = 1] 1[hj = 1],need introduce new atoms PB constraints (6), (7), (8), (11), (12), (9), (10).pb (C) consists single PB constraint (5).following theorem establishing correctness transformation . prooftheorem straightforward.Theorem 12. Let F loop completion formula logic PLwa , set atoms,At(F ). model F PLwa logic unique extension 0new atoms At(pb (cl (F ))) 0 model pseudo-boolean theorypb (cl (F )).note use solvers designed PLwa theories, translation pb longerneeded. benefit using solvers need split weight atoms PL watheories need auxiliary atoms introduced pb .8.2.1 LGORITHMfollow approach proposed Lin Zhao (2002). paper, first computecompletion lparse program. Then, iteratively compute models completion usingPB solver. Whenever model found, test stability. model stable modelprogram, extend completion loop formulas identified Theorem 10. Often, addingsingle loop formula filters several models Comp(P ) stable models P .results given previous section ensure algorithm correct. presentFigure 1. note may happen worst case exponentially many loop formulas325fiL IU & RUSZCZY NSKIInput: P lparse program;pseudo-boolean solverBEGINcompute completion Comp(P ) P ;:= pb (cl (Comp(P )));(solver finds models )output stable models found terminate;:= model found A;(M stable) output terminate;compute reduct P P respect ;compute greatest stable model 0 , contained , P ;:= \ 0 ;find terminating loops ;compute loop formulas convert PB constraints usingpb cl ;add PB constraints computed previous step ;(true);ENDFigure 1: Algorithm pbmodelsneeded first stable model found determine stable models exist (Lin &Zhao, 2002). However, problem arises rarely practical situations 6 .implementation pbmodels supports several PB solvers satzoo (Een & Sorensson,2003), pbs (Aloul et al., 2002), wsatoip (Walser, 1997). also supports program wsatcc (Liu &Truszczynski, 2003) computing models PLwa theories. last program used,transformation, clausal PLwa theories pseudo-boolean theories needed. firsttwo four programs complete PB solvers. latter two local-search solvers basedwsat (Selman, Kautz, & Cohen, 1994).output message stable model found first line loop simplystable models exist since case local-search algorithm, failure find modelcompletion (extended loop formulas iteration two subsequent ones)imply models exist.8.3 Performancesection, present experimental results concerning performance pbmodels. experiments compared pbmodels, combined several PB solvers, smodels (Simons et al., 2002)cmodels (Babovich & Lifschitz, 2002). focused experiments problems whose state6. fact, many cases programs turn tight respect supported models. Therefore, supportedmodels stable loop formulas necessary all.326fiP ROPERTIES PPLICATIONS P ROGRAMS ONOTONE C ONVEX C ONSTRAINTSments explicitly involve pseudo-boolean constraints, designed pbmodels problemsmind.benchmark problems tried cmodels perform well. one case (vertexcover benchmark) performance cmodels competitive, although even casebest performer. Therefore, report results compiled cmodels.complete set results obtained experiments refer http://www.cs.uky.edu/ai/pbmodels.experiments used instances following problems: traveling salesperson, weightedn-queens, weighted Latin square, magic square, vertex cover, Towers Hanoi. lparseprograms used first four problems involve general pseudo-boolean constraints. Programsmodeling last two problems contain cardinality constraints only.Traveling salesperson problem (TSP). instance consists weighted complete graph nvertices, bound w. edge weights w non-negative integers. solution instanceHamiltonian cycle whose total weight (the sum weights edges) lessequal w.randomly generated 50 weighted complete graphs 20 vertices, end, caseassign every edge complete undirected graph integer weight selected uniformlyrandom range [1..19]. setting w 100 obtained set easy instances, denotedTSP-e (the bound high enough every instance set solution).collection graphs, also created set hard instances, denoted TSP-h, setting w 62.Since requirement total weight stronger, instances set general taketime.Weighted n-queens problem (WNQ). instance problem consists weighted n nchess board bound w. weights bound non-negative integers. solutioninstance placement n queens chess board two queens attackweight placement (the sum weights squares queens) greaterw.randomly generated 50 weighted chess boards size 20 20, chess boardrepresented set n n integer weights wi,j , 1 i, j n, selected uniformly randomrange [1..19]. created two sets instances, easy (denoted wnq-e) hard(denoted wnq-h), setting bound w 70 50, respectively.Weighted Latin square problem (WLSQ). instance consists n n array weights w i,j ,bound w. weights wi,j w non-negative integers. solution instancen n array L entries {1, . . . , n}P thatPeach element {1, . . . , n} occursexactly row column L, ni=1 nj=1 L[i, j] wi,j w.set n = 10 randomly generated 50 sets integer weights, selecting uniformlyrandom range [1..9]. created two families instances, easy (wlsq-e) hard(wlsq-h), setting w 280 225, respectively.Magic square problem. instance consists positive integer n. goal constructn n array using integer 1, . . . n2 entry array exactly wayentries row, column main diagonals sum n(n 2 + 1)/2.experiments used magic square problem n = 4, 5 6.Vertex cover problem. instance consists graph n vertices edges, nonnegative integer k bound. solution instance subset vertices graphk vertices least one end vertex every edge graph subset.327fiL IU & RUSZCZY NSKIrandomly generated 50 graphs, 80 vertices 400 edges. graph, setk smallest integer vertex cover many elements still exists.Towers Hanoi problem. slight generalization original problem. consideredcase six disks three pegs. instance consists initial configuration diskssatisfies constraint problem (larger disk must top smaller one)necessarily requires disks one peg. initial configurations selected31, 36, 41 63 steps away goal configuration (all disks largestsmallest third peg), respectively. also considered standard version problemseven disks, initial configuration 127 steps away goal.encoded problems program general syntax lparse, allowsuse relation symbols variables (Syrjanen, 1999). programs available http://www.cs.uky.edu/ai/pbmodels. used programs combination appropriate instances inputs lparse (Syrjanen, 1999). way, problemset instances generated family ground (propositional) lparse programs stablemodels programs represent solutions corresponding instances problem (if stable models, solutions). used families lparse programs inputs solvers testing. ground programs also available http://www.cs.uky.edu/ai/pbmodels.tests, used pbmodels following four PB solvers: satzoo (Een & Sorensson,2003), pbs (Aloul et al., 2002), wsatcc (Liu & Truszczynski, 2003), wsatoip (Walser, 1997).particular, wsatcc deals PLwa theories directly.experiments run machines 3.2GHz Pentium 4 CPU, 1GB memory, runningLinux kernel version 2.6.11, gcc version 3.3.4. cases, used 1000 secondstimeout limit.first show results magic square towers Hanoi problems. Table 1,solver instance, report corresponding running time seconds. Local-searchsolvers unable solve instances two problems includedtable.Benchmarkmagic square (4 4)magic square (5 5)magic square (6 6)towers Hanoi (d = 6, = 31)towers Hanoi (d = 6, = 36)towers Hanoi (d = 6, = 41)towers Hanoi (d = 6, = 63)towers Hanoi (d = 7, = 127)smodels1.36> 1000> 100016.1932.21296.32> 1000> 1000pbmodels-satzoo1.7028.1375.5818.4731.7249.90> 1000> 1000pbmodels-pbs2.410.31> 10001.441.543.123.6722.83Table 1: Magic square towers Hanoi problemspbmodels-satzoo pbmodels-pbs perform better smodels programs obtainedinstances problems. observe pbmodels-pbs performs exceptionally welltower Hanoi problem. solver compute plan 7 disks,requires 127 steps. Magic square Towers Hanoi problems highly regular. problems328fiP ROPERTIES PPLICATIONS P ROGRAMS ONOTONE C ONVEX C ONSTRAINTSTSP-eTSP-hwnq-ewnq-hwlsq-ewlsq-hvtxcov# SAT instances5031492945850# UNSAT instances01004410# UNKNOWN instances018121110Table 2: Summary InstancesTSP-eTSP-hwnq-ewnq-hwlsq-ewlsq-hvtxcovsumsmodels45/177/311/52/221/10/050/40136/68pbmodels-satzoo50/3016/1426/230/049/2947/2650/1238/123pbmodels-pbs18/30/00/00/046/1947/2347/3158/48Table 3: Summary instancesoften challenge local-search problems, may explain poor performance observedpbmodels-wsatcc pbmodels-wsatoip two benchmarks.remaining four problems, used 50-element families instances, generated randomly way discussed above. studied performance complete solvers(smodels, pbmodels-satzoo pbmodels-pbs) instances. included local-searchsolvers (pbmodels-wsatcc pbmodelswsatoip) comparisons restricted attentioninstances determined satisfiable (as local-search solvers are, design, unable decide unsatisfiability). Table 2, family list many instancessatisfiable, unsatisfiable, many instances none solvers tried abledecide satisfiability.Table 3, seven families instances complete solver, reporttwo values s/w, number instances solved solver w numbertimes fastest among three.results Table 3 show overall pbmodels-satzoo solved instances pbmodelspbs, followed smodels. look number times solver fastest one,pbmodels-satzoo clear winner overall, followed smodels pbmodels-pbs.Looking seven families tests individually, see pbmodels-satzoo performed bettertwo solvers five families. two smodels best performer(although, clear winner vertex-cover benchmark; solvers essentiallyineffective wnq-h).also studied performance pbmodels combined local-search solvers wsatcc (Liu& Truszczynski, 2003) wsatoip (Walser, 1997). study, considered instances seven families knew satisfiable. Table 4 presents results solvers329fiL IU & RUSZCZY NSKITSP-eTSP-hwnq-ewnq-hwlsq-ewlsq-hvtxcovsumsmodels45/37/011/02/021/00/050/0136/3pbmd-satzoo50/516/226/00/045/07/050/0194/7pbmd-pbs18/20/00/00/044/08/047/0117/2pbmd-wsatcc32/719/649/4529/1545/337/150/36231/143pbmd-wsatoip47/3428/2249/429/1445/148/750/15256/110Table 4: Summary SAT instancesstudied (including complete ones). before, entry provides pair numbers s/w,number solved instances w number times solver performed bettercompetitors.results show superior performance pbmodels combined local-search solvers.solve instances complete solvers (including smodels). addition, significantlyfaster, winning much frequently complete solvers (complete solvers faster12 instances, local-search solvers faster 253 instances).results demonstrate pbmodels solvers pseudo-boolean constraints outperformssmodels several types search problems involving pseudo-boolean (weight) constraints).note also analyzed run-time distributions families instances.run-time distribution regarded accurate detailed measure performancealgorithms randomly generated instances7 . results consistent summary resultspresented confirm conclusions. discussion run-time distributions requiresmuch space, include analysis here. available website http://www.cs.uky.edu/ai/pbmodels.9. Related workExtensions logic programming means model properties sets (typically consistingground terms) extensively studied. Usually, extensions referred common term logic programming aggregates. term comes fact propertiessets practical interest defined aggregate operations sum, count, maximum, minimum average. chose term constraint stress speak abstractproperties define constraints truth assignments (which view sets atoms).Mumick, Pirahesh, Ramakrishnan (1990), Kemp Stuckey (1991) amongfirst study logic programs aggregates. Recently, Niemela et al. (1999) Simons et al.(2002) introduced class lparse programs. discussed formalism detail earlierpaper.Pelov (2004) Pelov et al. (2006) studied general class aggregates developed systematic theory aggregates logic programming based approximation theory(Denecker, Marek, & Truszczynski, 2000). resulting theory covers stable modelssemantics also supported-model semantics extensions 3-valued Kripke-Kleene7. Hoos Stutzle (2005) provide detailed discussion matter context local-search methods.330fiP ROPERTIES PPLICATIONS P ROGRAMS ONOTONE C ONVEX C ONSTRAINTSwell-founded semantics. formalism introduced studied Pelov (2004) Pelov et al.(2006) allows arbitrary aggregates (not monotone ones) appear bodies rules.However, allow aggregates appear heads program clauses. Due differences syntax scope semantics studied simple way relate Pelovs(2004) Pelov et al.s (2006) formalism programs monotone (convex) constraints.note though programs abstract monotone constraints heads rules formC(a) viewed almost literally programs formalism Pelov (2004) Pelov et al.(2006) stable models according definitions used paperPelov (2004) Pelov et al. (2006).Faber et al. (2004) developed theory disjunctive logic programs aggregates. SimilarlyPelov (2004) Pelov et al. (2006), Faber et al. (2004) allow aggregates appearheads program clauses. one differences approach programsmonotone (convex) constraints studied here. major difference relatedpostulate minimality stable models (called answer sets context formalismconsidered Faber et al., 2004). keeping spirit original answer-set semantics(Gelfond & Lifschitz, 1991), answer sets disjunctive programs aggregates, definedFaber et al. (2004), minimal models. Stable models programs abstract constraintsproperty. However, class programs abstract monotone constraintsheads rules form C(a) semantics answer sets defined Faber et al. (2004)coincides semantics stable models Marek Truszczy nski (2004) Marek et al.(2004, 2006).Yet another approach aggregates logic programming presented Son Pontelli(2006). approach considered programs syntax similar programs monotone abstract constraints. allowed arbitrary constraints (not monotone ones) scopeoperator. general principle behind definition stable-model semantics SonPontelli (2006) view program constraints concise representation setinstances, normal logic program. Stable models program constraintsdefined stable models instances quite different operator-based definitionMarek Truszczynski (2004) Marek et al. (2004, 2006). However, programsmonotone constraint atoms fall scope formalism Son Pontelli (2006)approaches coincide.also note recently Son et al. (2006) presented conservative extension syntaxproposed Marek Truszczynski (2004) Marek et al. (2006), clauses builtarbitrary constraint atoms.Finally, point work Ferraris Lifschitz (2004) Ferraris (2005) treatsaggregates nested expressions. particular, Ferraris (2005) introduces propositional logiccertain nonclassical semantics, shows extends several approaches programsaggregates, including Simons et al. (2002) (restricted core lparse programs) Faberet al. (2004). nature relationship formalism Ferraris (2005) programsabstract constraints remains open problem.10. Conclusionswork shows concepts, techniques results normal logic programming, concerningstrong uniform equivalence, tightness Fages lemma, program completion loop formu331fiL IU & RUSZCZY NSKIlas, generalize abstract setting programs monotone convex constraints.general properties specialize new results lparse programs (with exception characterization strong equivalence lparse programs, first obtained Turner, 2003).Given results implemented new software pbmodels computing stable modelslparse programs. approach reduces problem computing models theories consisting pseudo-boolean constraints, several fast solvers exist (Manquinho & Roussel,2005). experimental results show pbmodels PB solvers, especially local search PBsolvers, performs better smodels several types search problems tested. Moreover,new efficient solvers pseudo-boolean constraints become available (the problem receiving much attention satisfiability integer programming communities), performancepbmodels improve accordingly.Acknowledgmentsacknowledge support NSF grants IIS-0097278 IIS-0325063. gratefulreviewers useful comments suggestions.paper combines extends results included conference papers (Liu & Truszczy nski,2005b, 2005a).ReferencesAloul, F., Ramani, A., Markov, I., & Sakallah, K. (2002). PBS: backtrack-search pseudo-boolean solveroptimizer. Proceedings 5th International Symposium Theory ApplicationsSatisfiability, pp. 346 353.Babovich, Y., & Lifschitz, V. (2002). Cmodels package.. http://www.cs.utexas.edu/users/tag/cmodels.html.Baral, C. (2003). Knowledge representation, reasoning declarative problem solving. Cambridge University Press.Clark, K. (1978). Negation failure. Gallaire, H., & Minker, J. (Eds.), Logic data bases, pp. 293322.Plenum Press, New York-London.DellArmi, T., Faber, W., Ielpa, G., Leone, N., & Pfeifer, G. (2003). Aggregate functions disjunctive logicprogramming: semantics, complexity, implementation DLV. Proceedings 18th International Joint Conference Artificial Intelligence (IJCAI-2003), pp. 847852. Morgan Kaufmann.Denecker, M., Marek, V., & Truszczynski, M. (2000). Approximations, stable operators, well-founded fixpoints applications nonmonotonic reasoning. Minker, J. (Ed.), Logic-Based Artificial Intelligence, pp. 127144. Kluwer Academic Publishers.Een, N., & Sorensson, N. (2003). extensible SAT solver. Theory Applications SatisfiabilityTesting, 6th International Conference, SAT-2003, Vol. 2919 LNCS, pp. 502518. Springer.Eiter, T., & Fink, M. (2003). Uniform equivalence logic programs stable model semantics.Proceedings 2003 International Conference Logic Programming, Vol. 2916 Lecture NotesComputer Science, pp. 224238, Berlin. Springer.Erdem, E., & Lifschitz, V. (2003). Tight logic programs. Theory Practice Logic Programming, 3(4-5),499518.Faber, W., Leone, N., & Pfeifer, G. (2004). Recursive aggregates disjunctive logic programs: Semanticscomplexity.. Proceedings 9th European Conference Artificial Intelligence (JELIA2004), Vol. 3229 LNAI, pp. 200 212. Springer.332fiP ROPERTIES PPLICATIONS P ROGRAMS ONOTONE C ONVEX C ONSTRAINTSFages, F. (1994). Consistency Clarks completion existence stable models. Journal MethodsLogic Computer Science, 1, 5160.Ferraris, P. (2005). Answer sets propositional theories. Logic Programming Nonmonotonic Reasoning, 8th International Conference, LPNMR 2005, Vol. 3662 LNAI, pp. 119131. Springer.Ferraris, P., & Lifschitz, V. (2004). Weight constraints ans nested expressions. Theory Practice LogicProgramming, 5, 4574.Gelfond, M., & Leone, N. (2002). Logic programming knowledge representation A-prolog perspective. Artificial Intelligence, 138, 338.Gelfond, M., & Lifschitz, V. (1988). stable semantics logic programs. Proceedings 5thInternational Conference Logic Programming, pp. 10701080. MIT Press.Gelfond, M., & Lifschitz, V. (1991). Classical negation logic programs disjunctive databases. NewGeneration Computing, 9, 365385.Hoos, H., & Stutzle, T. (2005). Stochastic Local Search Algorithms Foundations Applications.Morgan-Kaufmann.Kemp, D., & Stuckey, P. (1991). Semantics logic programs aggregates. Logic Programming,Proceedings 1991 International Symposium, pp. 387401. MIT Press.Lifschitz, V., Pearce, D., & Valverde, A. (2001). Strongly equivalent logic programs. ACM TransactionsComputational Logic, 2(4), 526541.Lin, F. (2002). Reducing strong equivalence logic programs entailment classical propositional logic.Principles Knowledge Representation Reasoning, Proceedings 8th International Conference (KR2002). Morgan Kaufmann Publishers.Lin, F., & Zhao, Y. (2002). ASSAT: Computing answer sets logic program SAT solvers. Proceedings 18th National Conference Artificial Intelligence (AAAI-2002), pp. 112117. AAAIPress.Liu, L., & Truszczynski, M. (2003). Local-search techniques propositional logic extended cardinalityatoms. Rossi, F. (Ed.), Proceedings 9th International Conference Principles PracticeConstraint Programming, CP-2003, Vol. 2833 LNCS, pp. 495509. Springer.Liu, L., & Truszczynski, M. (2005a). Pbmodels - software compute stable models pseudobooleansolvers. Logic Programming Nonmonotonic Reasoning, Proceedings 8th InternationalConference (LPNMR-05), LNAI 3662, pp. 410415. Springer.Liu, L., & Truszczynski, M. (2005b). Properties programs monotone convex constraints.Proceedings 20th National Conference Artificial Intelligence (AAAI-05), pp. 701706. AAAIPress.Manquinho, V., & Roussel, O. (2005).univ-artois.fr/PB05/.Pseudo boolean evaluation 2005..http://www.cril.Marek, V., Niemela, I., & Truszczynski, M. (2004). Characterizing stable models logic programscardinality constraints. Proceedings 7th International Conference Logic ProgrammingNonmonotonic Reasoning, Vol. 2923 Lecture Notes Artificial Intelligence, pp. 154166.Springer.Marek, V., Niemela, I., & Truszczynski, M. (2006). Logic programs monotone abstract constraint atoms.Theory Practice Logic Programming. Submitted.Marek, V., & Truszczynski, M. (2004). Logic programs abstract constraint atoms. Proceedings19th National Conference Artificial Intelligence (AAAI-04), pp. 8691. AAAI Press.Mumick, I., Pirahesh, H., & Ramakrishnan, R. (1990). magic duplicates aggregates. Proceedings 16th International Conference Large Data Bases, VLDB 1990, pp. 264277.Morgan Kaufmann.333fiL IU & RUSZCZY NSKINiemela, I., Simons, P., & Soininen, T. (1999). Stable model semantics weight constraint rules. Proceedings LPNMR-1999, Vol. 1730 LNAI, pp. 317331. Springer.Pelov, N. (2004). Semantics logic programs aggregates. PhD Thesis. Department ComputerScience, K.U.Leuven, Leuven, Belgium.Pelov, N., Denecker, M., & Bruynooghe, M. (2004). Partial stable models logic programs aggregates.Lifschitz, V., & Niemela, I. (Eds.), Logic programming Nonmonotonic Reasoning, Proceedings7th International Conference, Vol. 2923, pp. 207219. Springer.Pelov, N., Denecker, M., & Bruynooghe, M. (2006). Well-founded stable semantics logic programsaggregates. Theory Practice Logic Programming. Accepted (available http://www.cs.kuleuven.ac.be/dtai/projects/ALP/TPLP/).Selman, B., Kautz, H., & Cohen, B. (1994). Noise strategies improving local search. Proceedings12th National Conference Artificial Intelligence (AAAI-1994), pp. 337343, Seattle, USA.AAAI Press.Simons, P., Niemela, I., & Soininen, T. (2002). Extending implementing stable model semantics.Artificial Intelligence, 138, 181234.Son, T., & Pontelli, E. (2006). constructive semantic characterization aggregates anser set programming. Theory Practice Logic Programming. Accepted (available http://arxiv.org/abs/cs.AI/0601051).Son, T., Pontelli, E., & Tu, P. (2006). Answer sets logic programs arbitrary abstract constraint atoms.Proceedings 21st National Conference Artificial Intelligence (AAAI-06). AAAI Press.Syrjanen, T. (1999). lparse, procedure grounding domain restricted logic programs. http://www.tcs.hut.fi/Software/smodels/lparse/.Turner, H. (2003). Strong equivalence made easy: Nested expressions weight constraints. TheoryPractice Logic Programming, 3, (4&5), 609622.Walser, J. (1997). Solving linear pseudo-boolean constraints local search. Proceedings 14thNational Conference Artificial Intelligence (AAAI-97), pp. 269274. AAAI Press.334fiJournal Artificial Intelligence Research 27 (2006) 55-83Submitted 10/05; published 09/06Cognitive Principles Robust Multimodal InterpretationJoyce Y. ChaiZahar PrasovShaolin Qujchai@cse.msu.eduprasovza@cse.msu.eduqushaoli@cse.msu.eduDepartment Computer Science EngineeringMichigan State UniversityEast Lansing, MI 48824 USAAbstractMultimodal conversational interfaces provide natural means users communicate computer systems multiple modalities speech gesture.build eective multimodal interfaces, automated interpretation user multimodal inputsimportant. Inspired previous investigation cognitive status multimodalhuman machine interaction, developed greedy algorithm interpreting userreferring expressions (i.e., multimodal reference resolution). algorithm incorporatescognitive principles Conversational Implicature Givenness Hierarchy applies constraints various sources (e.g., temporal, semantic, contextual) resolvereferences. empirical results shown advantage algorithm ecientlyresolving variety user references. simplicity generality, approachpotential improve robustness multimodal input interpretation.1. IntroductionMultimodal systems provide natural eective way users interact computersmultiple modalities speech, gesture, gaze. Since rst appearancePut-That-There system (Bolt, 1980), number multimodal systemsbuilt, among systems combine speech, pointing (Neal & Shapiro, 1991;Stock, 1993), gaze (Koons, Sparrell, & Thorisson, 1993), systems integrate speechpen inputs (e.g., drawn graphics) (Cohen, Johnston, McGee, Oviatt, Pittman, Smith,Chen, & Clow, 1996; Wahlster, 1998), systems combine multimodal inputs outputs(Cassell, Bickmore, Billinghurst, Campbell, Chang, Vilhjalmsson, & Yan, 1999), systemsmobile environments (Oviatt, 1999a), systems engage users intelligentconversation (Gustafson, Bell, Beskow, Boye, Carlson, Edlund, Granstrom, House, & Wiren,2000; Stent, Dowding, Gawron, Bratt, & Moore, 1999). Earlier studies shownmultimodal interfaces enable users interact computers naturally eectively(Oviatt, 1996, 1999b).One important aspect building multimodal systems multimodal interpretation,process identies meanings user inputs. particular, key elementmultimodal interpretation known reference resolution, process ndsproper referents referring expressions. referring expression phrasegiven user inputs (most likely speech inputs) refer specicentity entities. referent entity (e.g., specic object) user refers.Suppose user points House 6 screen says much one.c2006AI Access Foundation. rights reserved.fiChai, Prasov, & Qucase, reference resolution must infer referent House 6 assignedreferring expression one. paper particularly addresses problem referenceresolution multimodal interpretation.multimodal conversation, way users communicate system dependsavailable interaction channels situated context (e.g., conversation focus, visualfeedback). dependencies form rich set constraints various aspects (e.g.,semantic, temporal, contextual). correct interpretation attainedsimultaneously considering constraints.Previous studies shown user referring behavior multimodal conversationoccur randomly, rather follows certain linguistic cognitive principles.human machine interaction, earlier work shown strong correlationscognitive status Givenness Hierarchy form referring expressions (Kehler, 2000).Inspired early work, developed greedy algorithm multimodal referenceresolution. algorithm incorporates principles Conversational ImplicatureGivenness Hierarchy applies constraints various sources (e.g., gesture, conversationcontext, visual display). empirical results shown promise algorithmeciently resolving variety user references. One major advantage greedyalgorithm prior linguistic cognitive knowledge used guidesearch prune search space constraint satisfaction. simplicitygenerality, approach potential improve robustness interpretationprovide practical solution multimodal reference resolution (Chai, Prasov, Blaim,& Jin, 2005).following sections, rst demonstrate dierent types referring behaviorobserved studies. briey introduce underlying cognitive principleshuman-human communication describe principles used computational model eciently resolve multimodal references. Finally, presentexperimental results.2. Multimodal Reference Resolutionprevious work (Chai, Hong, & Zhou, 2004b; Chai, Hong, Zhou, & Prasov, 2004),multimodal conversational system developed users acquire real estate information1 .Figure 1 snapshot graphical user interface. Users interact interfacespeech gesture. Table 1 shows fragment conversation.fragment, user exhibits dierent types referring behavior. example,input U1 considered simple input. type simple input onereferring expression spoken utterance one accompanying gesture. Multimodalfusion combines information speech gesture likely resolverefers to. second user input (U2 ), accompanying gesture referringexpression explicitly used speech utterance. time, system needsuse conversation context infer object interest house mentionedprevious turn conversation. third user input, multiple referringexpressions multiple gestures. types inputs considered complex inputs.1. first prototype system developed IBM T. J. Watson Research Center P. Hong,M. Zhou, colleagues Intelligent Multimedia Interaction group.56fiMinimizing Conflicts: Heuristic Repair MethodFigure 1: snapshot multimodal conversational system.U1S1U2S2U3S3Speech: much cost?Gesture: point position screenSpeech: price 400KGraphics: highlight house discussionSpeech: large?Speech: 2500 square feetSpeech: Compare house oneGesture: ....circle....cirle (put two consecutive circles screen)Speech: comparison resultsGraphics: show table comparisonTable 1: fragment demonstrating interaction dierent types referring behaviorComplex inputs dicult resolve. need consider temporal relationsreferring expressions gestures, semantic constraints speciedreferring expressions, contextual constraints prior conversation.example, case U3 , system needs understand refers housefocus previous turn; house one alignedtwo consecutive gestures. subtle variations constraints, includingtemporal ordering, semantic compatibility, gesture recognition results leaddierent interpretations.example, see multimodal conversation, way user interacts system dependent available input channels (e.g., speechgesture), also upon his/her conversation goals, state conversation,multimedia feedback system. words, rich context involves57fiChai, Prasov, & Qudependencies many dierent aspects established interaction. Interpretinguser inputs situated rich context. example, temporal relationsspeech gesture important criteria determine informationtwo modalities combined. focus attention prior conversationshapes users refer objects, thus, inuences interpretation referringexpressions. Therefore, need simultaneously consider temporal relationsreferring expressions gestures, semantic constraints specied referring expressions, contextual constraints prior conversation. paper,present ecient approach driven cognitive principles combine temporal,semantic, contextual constraints multimodal reference resolution.3. Related WorkConsiderable eort devoted studying user multimodal behavior (Cohen, 1984;Oviatt, 1999a) mechanisms interpret user multimodal inputs (Chai et al., 2004b;Gustafson et al., 2000; Huls, Bos, & Classen, 1995; Johnston, Cohen, McGee, Oviatt,Pittman, & Smith, 1997; Johnston, 1998; Johnston & Bangalore, 2000; Kehler, 2000; Koonset al., 1993; Neal & Shapiro, 1991; Oviatt, DeAngeli, & Kuhn, 1997; Stent et al., 1999; Stock,1993; Wahlster, 1998; Wu & Oviatt, 1999; Zancanaro, Stock, & Strapparava, 1997).multimodal reference resolution, early work keeps track focus spacedialog (Grosz & Sidner, 1986) display model capture objects visiblegraphical display (Neal, Thielman, Dobes, M., & Shapiro, 1998). checks semanticconstraints type candidate objects referenced propertiesreference resolution. modied centering model multimodal reference resolutionalso introduced previous work (Zancanaro et al., 1997). idea basedcentering movement turns, segments discourse constructed.discourse entities appearing segment accessible current turnused constrain referents referring expressions. Another approach introduceduse contextual factors multimodal reference resolution (Huls et al., 1995).approach, salience value assigned instance based contextual factors.determine referents multimodal referring expressions, approach retrievessalient referent satises semantic restrictions referring expressions.earlier approaches greedy nature, largely dependent semanticconstraints and/or constraints conversation context.resolve multimodal references, two important issues. First mechanism combine information various sources modalities. second capability obtain best interpretation (among possible alternatives) given settemporal, semantic, contextual constraints. section, give brief introductionthree recent approaches address issues.3.1 Multimodal FusionApproaches multimodal fusion (Johnston, 1998; Johnston & Bangalore, 2000), althoughfocus dierent problem overall input interpretation, provide eective solutionsreference resolution. two major approaches multimodal fusion: unication58fiMinimizing Conflicts: Heuristic Repair Methodbased approaches (Johnston, 1998) nite state approaches (Johnston & Bangalore,2000).unication-based approach identies referents referring expressions unifyingfeature structures generated speech utterances gestures using multimodal grammar (Johnston et al., 1997; Johnston, 1998). multimodal grammar combinestemporal spatial constraints. Temporal constraints encode absolute temporal relations speech gesture (Johnston, 1998),. grammar rules predenedbased empirical studies multimodal interaction (Oviatt et al., 1997). example, onerule indicates speech gesture combined speech either overlapsgesture follows gesture within certain time frame. unication approachalso process certain complex cases (as long satisfy predened multimodalgrammar) speech utterance accompanied one gesture dierenttypes (Johnston, 1998). Using approach accommodate various situationsdescribed Figure 1 require adding dierent rules cope situation.specic user referring behavior exactly match existing integration rules(e.g., temporal relations), unication would fail therefore references wouldresolved.nite state approach applies nite-state transducers multimodal parsingunderstanding (Johnston & Bangalore, 2000). Unlike unication-based approachchart parsing subject signicant computational complexity concerns (Johnston& Bangalore, 2000), nite state approach provides ecient, tight-couplingmultimodal understanding speech recognition. approach, multimodal contextfree grammar dened transform syntax multimodal inputs semanticmeanings. domain-specic semantics directly encoded grammar. Basedgrammars, multi-tape nite state automata constructed. automataused identifying semantics combined inputs. Rather absolute temporalconstraints unication-based approach, approach relies temporal orderdierent modalities. parsing stage, gesture input gesturetape (e.g., pointing particular person) combined speech expressionspeech tape (e.g., person) considered referent expression.problem approach multi-tape structure takes input speechgesture incorporate conversation history consideration.3.2 Decision Listidentify potential referents, previous work investigated Givenness Hierarchy (tointroduced later) multimodal interaction (Kehler, 2000). Based data collectedWizard Oz experiments, investigation suggests users tend tailorexpressions perceive systems beliefs concerning cognitive statusreferents prominence (e.g., highlight) display. tailored referringexpressions resolved high accuracy based following decision list:1. object gestured to, choose object.2. Otherwise, currently selected object meets semantic type constraints imposedreferring expression, choose object.59fiChai, Prasov, & Qu3. Otherwise, visible object semantically compatible, chooseobject.4. Otherwise, full NP (such proper name) used uniquely identify referent.studies (Chai, Prasov, & Hong, 2004a), found decision listfollowing limitations:Depending interface design, ambiguities (from systems perspective) couldoccur. example, given interface one object (e.g., house) sometimescreated top another object (e.g., town), pointing gesture could resultmultiple potential objects. Furthermore, given interface crowded objects,nger point could also result multiple objects dierent probabilities.decision list able handle ambiguous cases.User inputs always simple (consisting one referring expressionone gesture indicated decision list). fact, study (Chai et al.,2004a), found user inputs also complex, consisting multiple referringexpressions and/or multiple gestures. referents referring expressionscould come dierent sources, gesture inputs conversation context.temporal alignment speech gesture also important determiningcorrect referent given expression. decision list able handletypes complex inputs.Nevertheless, previous ndings (Kehler, 2000) inspired work providedbasis algorithm described paper.3.3 OptimizationRecently, probabilistic approach developed optimizing reference resolution basedgraph matching (Chai et al., 2004b). graph-matching approach, informationgathered multiple input modalities conversation context representedattributed relational graphs (ARGs) (Tsai & Fu, 1979). Specically, two graphs used.One graph represents referring expressions speech utterances (i.e., called referringgraph). referring graph contains referring expressions used speech utterancerelations expressions. node corresponds one referring expressionconsists semantic temporal information extracted expression.edge represents semantic temporal relation two referring expressions.resulting graph fully connected, undirected, graph. example, shownFigure 2(a), speech input compare house, green house, brown one,three nodes generated referring graph representing three referring expressions.node contains semantic temporal features related corresponding referringexpression. include expressions semantic type (house, town, etc.), numberpotential referents, type dependent features (size, price, etc.), syntactic categoryexpression, timestamp expression produced. edge containsfeatures describing semantic temporal relations pair nodes. semanticfeatures simply indicate whether two nodes share semantic type60fiMinimizing Conflicts: Heuristic Repair MethodFigure 2: Reference resolution probabilistic graph-matchinginferred utterance. Otherwise, semantic type relation deemedunknown. temporal features indicate two expressions uttered rst.Similarly, another graph represents potential referents gathered gestures, history, visual display (i.e., called referent graph). node referent graphcaptures semantic temporal information potential referent, togetherselection probability. selection probability particularly applied objects indicated gesture. gesture pointing circle potentially introduceambiguity terms intended referents, selection probability used indicatelikely object selected particular gesture. selection probabilityderived function distance location entity focus pointrecognized gesture display. referring graph, edge referentgraph captures semantic temporal relations two potential referentswhether two referents share semantic type temporal ordertwo referents introduced discourse. example, since gesture inputconsists two pointings, referent graph (Figure 2b) consists potential referentstwo pointings. objects rst dashed rectangle potential referentsselected rst pointing, second dashed rectangle correspondsecond pointing. Furthermore, salient objects prior conversation also included referent graph since could potential referents well (e.g.,rightmost dashed rectangle Figure 2b).Given graph representations, reference resolution problem becomes probabilistic graph-matching problem (Gold & Rangarajan, 1996). goal nd matchreferring graph Gs referent graph Gc 2 achieves maximumcompatibility (i.e., maximizes Q(Gc , Gs )) described following equation:2. subscription Gs refers speech referring expressions c Gc refers candidate referents.61fiChai, Prasov, & QuQ(Gc , Gs ) =(x , )N odeSim(x , )xP+xn P (x , )P (y , n )EdgeSim(xy , mn )(1)P (x , ) matching probability referent node x referring node. overall compatibility Q(Gc , Gs ) depends node compatibility N odeSimedge compatibility EdgeSim, dened temporal semanticconstraints (Chai et al., 2004). algorithm converges, P (x , ) gives matchingprobabilities referent node x referring node maximizes overallcompatibility function. Using matching probabilities, system able identifyprobable referent x referring node . Specically, referring expressionmatches potential referent assigned referent probability matchexceeds empirically computed threshold. threshold met, referringexpression remains unresolved.Theoretically, approach provides solution maximizes overall satisfactionsemantic, temporal, contextual constraints. However, like many optimizationapproaches, algorithm non-polynomial. relies expensive matching process,attempts every possible assignment, order converge optimal interpretationbased constraints. However, previous linguistic cognitive studies indicateuser language behavior occur randomly, rather follows certain cognitive principles. Therefore, question arises whether knowledge cognitive principlesused guide matching process reduce complexity.4. Cognitive PrinciplesMotivated previous work (Kehler, 2000), specically focus two principles: Conversational Implicature Givenness Hierarchy.4.1 Conversational ImplicatureGrices Conversational Implicature Theory indicates interpretation inferenceutterance communication guided set four maxims (Grice, 1975). Amongfour maxims, Maxim Quantity Maxim Manner particularly usefulpurpose.Maxim Quantity two components: (1) make contribution informative required (for current purposes exchange), (2) makecontribution informative required. context multimodal conversation,maxim indicates users generally make unnecessary gestures speechutterances. especially true pen-based gestures since usually require specialeort user. Therefore, pen-based gesture intentionally delivered user,information conveyed often crucial component used interpretation.Grices Maxim Manner four components: (1) avoid obscurity expression, (2)avoid ambiguity, (3) brief, (4) orderly. maxim indicates usersintentionally make ambiguous references. use expressions (either speechgesture) believe uniquely describe object interest listeners (incase computer system) understand. expressions choose depend62fiMinimizing Conflicts: Heuristic Repair MethodStatusExpression Formf ocusActivatedthat, this, NF amiliarNU nique identif iableNRef erentialindef inite NIdentif iableFigure 3: Givenness Hierarchyinformation mental models current state conversation. However,information users mental model might dierent information systempossesses. information gap happens, dierent ambiguities could occursystem point view. fact, ambiguities intentionally causedhuman speakers, rather systems incapability choosing among alternativesgiven incomplete knowledge representation, limited capability contextual inference,factors (e.g., interface design issues). Therefore, system anticipatedeliberate ambiguities users (e.g., user utters house refer particularhouse screen), rather focus dealing types ambiguitiescaused systems limitations (e.g., gesture ambiguity due interface designspeech ambiguity due incorrect recognition).two maxims help positioning role gestures reference resolution.particular, maxims put potential referents indicated gestureimportant position, described Section 5.4.2 Givenness HierarchyGivenness Hierarchy proposed Gundel et al. explains dierent determinerspronominal forms signal dierent information memory attention state (i.e.,cognitive status) (Gundel, Hedberg, & Zacharski, 1993). Figure 3, sixcognitive statuses hierarchy. example, focus indicates highest attentionalstate likely continue topic. Activated indicates entities short termmemory. statuses associated forms referring expressions.hierarchy, cognitive status implies statuses list. example, focusimplies Activated, Familiar, etc. use particular expression form signalsassociated cognitive status met, also signals lower statusesmet. words, given form used describe lower status also usedrefer higher status, vice versa. Cognitive statuses necessary conditions63fiChai, Prasov, & Quappropriate use dierent forms referring expressions. Gundel et al. found dierentreferring expressions almost exclusively correlate six statuses hierarchy.Givenness Hierarchy investigated earlier algorithms resolving pronouns demonstratives spoken dialog systems (Eckert & Strube, 2000; Byron, 2002)multimodal interaction (Kehler, 2000). particular, would like extend previous work (Kehler, 2000) investigate whether Conversational Implicature Givenness Hierarchy used resolve variety references simple complex,precise ambiguous. Furthermore, decision list used Kehler (2000) proposed based data analysis implemented evaluated real-timesystem. Therefore, second goal design implement ecient algorithmincorporating cognitive principles empirically compare performanceoptimization approach (Chai et al., 2004), nite state approach (Johnston & Bangalore,2000), decision list approach (Kehler, 2000).5. Greedy Algorithmgreedy algorithm always makes choice looks best moment processing.is, makes locally optimal choice hope choice lead globally optimal solution. Simple ecient greedy algorithms used approximatemany optimization problems. explore use Conversational ImplicatureGivenness Hierarchy designing ecient greedy algorithm. particular, extenddecision list Kehler (2000) utilize concepts two cognitive principlesfollowing way:Corresponding Givenness Hierarchy, following hierarchy holds potentialreferents: F ocus > V isible. hierarchy indicates objects focus higherstatus terms attention states objects visual display. Focuscorresponds cognitive statuses focus Activated Givenness Hierarchy,Visible corresponds statuses Familiar Uniquely identifiable. NoteGivenness Hierarchy ne grained terms dierent statuses. applicationmay able distinguish dierence statuses (e.g., focusActivated) eectively use them. Therefore, Focus Visible introducedgroup similar statuses (with respect application) together. Sinceneed dierentiate objects mentioned recently (e.g.,focus activated) objects accessible either graph displaydomain model (e.g., familiar unique identiable), assigndierent modied statuses (e.g., Focus Visible).Based Conversational Implicature, since pen-based gesture takes special effort deliver, must convey certain useful information. fact, objects indicatedgesture highest attentional state since deliberately singleduser. Therefore, combining (1) (2), derive modied hierarchyGesture > F ocus > V isible > Others. Others corresponds indenite casesGivenness Hierarchy. modied hierarchy coincides processing orderKehlers decision list (2000). modied hierarchy guide greedy64fiMinimizing Conflicts: Heuristic Repair Methodalgorithm search solutions. Next, describe detail algorithmrelated representations functions.5.1 Representationturn3 (i.e., receiving user input) conversation, use three vectorsrepresent rst three statuses modied hierarchy: objects selected gesture,objects focus, objects visible display follows:Gesture vector (g ) captures objects selected series gestures. element giobject potentially selected gesture. elements gi gj < j,gesture selects objects gi should: 1) temporally precede gesture selectsgj 2) gesture selects gj since one gesture could resultmultiple objects.Focus vector (f) captures objects focus selectedgesture. element represents object considered focus attentionprevious turn conversation. temporal precedence relationelements. consider corresponding objects simultaneouslyaccessible current turn conversation.captures objects visible display neitherDisplay vector (d)selected gesture (i.e., g) focus (f). also temporal precedence relation elements. elements simultaneously accessible.Based representations, object domain interest belongs eitherone vectors Others. object vectors consistsfollowing attributes:Semantic type object. example, semantic type could HouseTown.attributes object. domain dependent feature. set attributesassociated semantic type. example, house object Price, Size,Year Built, etc. attributes. Furthermore, object visual propertiesreect appearance object display Color object icon.identier object. object unique name.selection probability. refers probability given object selected.Depending interface design, gesture could result list potential referents.use selection probability indicate likelihood object selectedgesture. calculation selection probability described later. objectsfocus vector display vector, selection probabilities set 1/NN total number objects respective vector.3. Currently, user inactivity (i.e., 2 seconds input either speech gesture) usedboundary decide interaction turn.65fiChai, Prasov, & QuTemporal information. relative temporal ordering information corresponding gesture. Instead applying time stamps previous work (Chai et al.,2004b), use index gestures according order occurrences. object selected rst gesture, temporal informationwould 1.addition vectors capture potential referents, user input, vectorrepresents referring expressions speech utterance (r) also maintained.element (i.e., referring expression) following information:identier potential referent indicated referring expression.example, identier potential referent expression house number eighthouse object identier Eight.semantic type potential referents indicated expression. example,semantic type referring expression house House.number potential referents indicated referring expressionutterance context. example, singular noun phrase refers one object.phrase like three houses provides exact number referents (i.e., 3).Type dependent features. features associated potential referents,Color Price, extracted referring expression.temporal ordering information indicating order referring expressionsuttered. Again, instead specic time stamp, usetemporal ordering information. utterance consists N consecutive referringexpressions, temporal ordering information would 1, 2,N .syntactic categories referring expressions. Currently, referringexpression, assign one six syntactic categories (e.g., demonstrativepronoun). Details explained later.four vectors updated user turn conversation based currentuser input system state (e.g., shown screen identiedfocus previous turn conversation).5.2 Algorithmow chart pseudo code algorithm shown Figure 4.multimodal input particular turn conversation, algorithm takes inputsvector (r) referring expressions size k, gesture vector (g ) size m, focussize l. rst creates three matricesvector (f ) size n, display vector (d)G[i][j], F [i][j], D[i][j] capture scores matching referring expressionr object three vectors. Calculation matching score described later.Note that, g ,f, empty, corresponding matrix (i.e., G, F ,D) empty.66fiMinimizing Conflicts: Heuristic Repair MethodInitializeMatchMatrix (,,,){(i = 1..m; j = 1..k) G[i][j] = Match(gi, rj)(i = 1..n; j = 1..k) F[i][j] = Match(fi, rj)(i = 1..l; j = 1..k) D[i][j] = Match(di, rj)}YesG emptyGreedySortingGesture {index_max = 1; //index column(i = 1..m) {find j index_max, G[i][j] largest among elements row i.add mark * G[i][j];index_max = j; } //complete finding best match view objectAssignReferentsFromMatrix (G);}references resolved?YesYesF emptyReturn resultsGreedySortingFocus{(j = 1..k)(rj resolved)Cross column j F //only keep ones resolved( = 1..n){find j F[i][j] largest among elements row i.mark * F[i][j]; }AssignReferentsFromMatrix (F);}references resolved?GreedySortingDisplay{(j = 1..k)(rj resolved)Cross column j D;( = 1..l){find j D[i][j] largest among elements row i.mark * D[i][j]; }AssignReferentsFromMatrix (D);}Return resultsAssignReferentsFromMatrix (Matrix X){(i = 1..k) // i.e., expression ri column(ri indicates specific number N N elementsith column X *)assign N largest elements * ri referents.else assign elements * ri referents;}Figure 4: greedy algorithm multimodal reference resolution67YesReturn resultsfiChai, Prasov, & QuBased matching scores three matrices, algorithm applies greedysearch guided modied hierarchy described earlier. Since Gesturehighest status, algorithm rst searches Gesture Matrix (G) keeps trackmatching scores referring expressions objects gestures. identieshighest (or multiple highest) matching scores assigns possible objectsgestures expressions (GreedySortingGesture).referring expressions left resolved gestures processed,algorithm looks objects Focus Matrix (F ) since Focus next highest cognitive status (GreedySortingFocus). still expressions resolved,algorithm looks objects Display Matrix (D) (GreedySortingDisplay). Currently,algorithm focuses three statuses. Certainly, still expressionsresolved steps, algorithm consult proper name resolution.referring expressions resolved, system output results.next multimodal input, system generate four new vectors apply greedyalgorithm again.Note GreedySortingGesture, use index-max keep track column indexcorresponds largest matching value. algorithm incrementally processesrow matrix, index-max incrementally increase. referring expressions gesture aligned according order occurrences.Since objects Focus Matrix Display Matrix temporal precedencerelations, GreedySortingFocus GreedySortingDisplay use constraint.reason call algorithm greedy always nds best assignmentreferring expression given cognitive status hierarchy. words, algorithmalways makes best choice referring expression one time accordingorder occurrence utterance. One imagine mistaken assignmentmade expression aect assignment following expressions. Therefore,greedy algorithm may lead globally optimal solution. Nevertheless, generaluser behavior following guiding principles makes greedy algorithm useful.One major advantage greedy algorithm use modied hierarchy signicantly prune search space compared graph-matching approach.Given referring expressions n potential referents various sources (e.g., gesture,conversation context, visual display), algorithm nd solution O(mn).Furthermore, algorithm goes beyond simple precise inputs illustrateddecision list Kehler (2000). scoring mechanism (described later) greedysorting process accommodate complex ambiguous user inputs.5.3 Matching Functionsimportant component algorithm matching score object (o)referring expression (e). use following equation calculate matching score:atch(o, e) = [P (o|S) P (S|e)] Compatibility(o, e)(2)S{G,F,D}formula, represents possible associated status object o. couldthree potential values: G (representing Gesture), F (Focus), (Display).function determined three components:68fiMinimizing Conflicts: Heuristic Repair Methodrst, P (o|S), object selectivity component measures probabilityobject referent given status (S) object (i.e., gesture, focus,visual display).second, P (S|e), likelihood status component measures likelihoodstatus potential referent given particular type referring expression.third, Compatibility(o, e), compatibility component measuressemantic temporal compatibility object referring expressione.Next explain three components detail.5.3.1 Object Selectivitycalculate P (o|S = Gesture), use function takes considerationdistance object focus point gesture display (Chai et al.,2004b).Given object Focus (i.e., selected gesture), P (o|S = F ocus) = 1/N ,N total number objects Focus vector. object neitherselected gesture, focus, visible screen, P (o|S = Display) =1/M , total number objects Display vector. Currently,applied simplest uniform distribution objects focus graphicaldisplay. future, intend incorporate recency conversation discoursemodel P (o|S = F ocus) use visual prominence (e.g., based visual characteristics)model P (o|S = Display). Note that, discussed earlier Section 5.1, objectassociated one three statuses. words, given object o,one P (o|S = Gesture), P (o|S = F ocus), P (o|S = Display) non-zero.5.3.2 Likelihood StatusMotivated Givenness Hierarchy earlier work (Kehler, 2000) formreferring expressions reect cognitive status referred entities users mentalmodel, use likelihood status measure probability reected status givenparticular type referring expression. particular, use data reported Kehler(2000) derive likelihood status potential referents given particular typereferring expression P (S|e). categorize referring expressions following sixcategories:Empty: referring expression used utterance.Pronouns: it, they,Locative adverbs:Demonstratives: this, that, these,Denite Noun Phrases: noun phrases denite articleFull noun phrases: types proper nouns.69fiChai, Prasov, & QuP (S|E)VisibleFocusGestureSumEmpty00.560.441Pronoun00.850.151Locative00.570.431Demonstratives00.330.671Definite00.070.671Full00.470.161Table 2: Likelihood status referents given particular type expressionTable 2 shows estimated P (S|e). Note that, original data provided Kehler(2000), zero count certain combination referring type referent status.zero counts result zero probability table. use smoothingtechniques re-distribute probability mass. Furthermore, probability massassigned status Others.5.3.3 Compatibility Measurementterm Compatibility(o, e) measures compatibility object referringexpression e. Similar compatibility measurement earlier work (Chai et al.,2004), dened multiplication many factors following equation:Compatibility(o, e) = Id(o, e) Sem(o, e)Attrk (o, e) emp(o, e)(3)kequation:Id(o, e) captures compatibility identier (or name) identier(or name) specied e. indicates identier potential referent,expressed referring expression, match identier true referent.particularly useful resolving proper nouns. example, referringexpression house number eight, correct referent identiernumber eight. Id(o, e) = 0 identities e dierent. Id(o, e) = 1identities e either one/both unknown.Sem(o, e) captures semantic type compatibility e. indicatessemantic type potential referent expressed referring expressionmatch semantic type correct referent. Sem(o, e) = 0 semantic typese dierent. Sem(o, e) = 1 unknown.Attrk (o, e) captures type-specic constraint concerning particular semantic feature(indicated subscript k). constraint indicates expected featurespotential referent expressed referring expression compatiblefeatures associated true referent. example, referring expressionVictorian house, style feature Victorian. Therefore, objectpossible referent style object Victorian. Thus, dene following:Attrk (o, e) = 0 e feature k values feature kequal. Otherwise, Attrk (o, e) = 1.70fiMinimizing Conflicts: Heuristic Repair Method(House 3(House 9 (House 1Town 1)Town 2) Town 2)Gesture input: ... ..i..i...iSpeech input: Compare houses.TimeFigure 5: example complex inputemp(o, e) captures temporal compatibility e. consider temporal ordering speech gesture. Specically, temporalcompatibility dened following:emp(o, e) = exp(|OrderIndex(o) OrderIndex(e)|)(4)order speech accompanying gestures occur importantdeciding gestures aligned referring expressions.order accompanying gestures introduced discourseconsistent order corresponding referring expressionsuttered. example, suppose user input consists three gestures g1 , g2 , g3two referring expressions, s1 , s2 . possible g3 align s1g2 align s2 . Note that, status object either Focus Visible,emp(o, e) = 1. denition temporal compatibility dierentfunction used previous work (Chai et al., 2004) takes real time stampsconsideration. Section 6.2 shows dierent performance results based dierenttemporal compatibility functions.5.4 ExampleFigure 5 shows example complex input involves multiple referring expressionsmultiple gestures. interface displays house icons top town icons,point (or circle) could result house town object. example, rstgesture results House 3 Town 1. second gesture results House 9Town 2, third results House 1 Town 2. Suppose input takesplace, House 8 highlighted screen previous turn conversation (i.e.,House 8 focus). Furthermore, eight objects visible screen.resolve referents expressions houses, greedy algorithm takesfollowing steps:r created lengths 6, 1, 8, 2, respectively1. four input vectors, g ,f, d,represent six objects gesture vector, one object focus, eight objectsgraphical display, two referring expressions used utterance.2. Gesture Matrix G62 , Focus Matrix F12 , Display Matrix D82 created.3. three matrixes initialized Equation 2. Figure 6 shows resultingGesture Matrix. probability values P (S|e) come Table 2. dierence71fiChai, Prasov, & QuStatus(G)Referring Expression MatchPotentialReferentj = 1:j = 2: houses1 0.15 1 = 0.15= 1: House 31 0.67 0.37 = 0.25*Gesture 1= 2: Town 21 0.15 0 = 01 0.67 0 = 0= 3: House 91 0.15 0.37 = 0.0551 0.67 1 = 0.67*= 4: Town 21 0.15 0 = 01 0.67 0 = 0Gesture 2= 5: House 11 0.15 0.14 = 0.021 0.67 0.37 = 0.25*= 6: Town 21 0.15 0 = 01 0.67 0 = 0Gesture 3(a) Gesture MatrixStatus(F)PotentialReferentReferring Expression MatchFocus= 1: House 8j = 1:j = 2: houses1 0.85 1= 0.85*(b) Focus MatrixFigure 6: Gesture Matrix (a) Focus Matrix (b) processing example Figure 5.cell Referring Expression Match columns corresponds instantiationmatching function.compatibility values house objects Gesture Matrix mainly duetemporal ordering compatibilities.4. Next GreedySortingGesture procedure executed. row Gesture Matrix, algorithm nds largest legitimate value marks corresponding cell*. legitimate means corresponding cell row + 1either column column right corresponding cellrow i. values shown bold Figure 6(a). Next, startingcolumn, algorithm checks referring expression whether existscorresponding column. so, objects assigned referringexpressions based number constraints. case, since specic numbergiven referring expression houses, three marked objects assignedhouses.5. houses, still left resolved. algorithm continuesexecute GreedySortingFocus. Focus Matrix prior executing GreedySortingFocusshown Figure 6(b). Note since houses longer considered,corresponding column deleted Focus Matrix. Similar previous step,largest non-zero match value marked (shown bold Figure 6(b)) assignedremaining referring expression it.6. resulting Display Matrix shown point, referring expressions resolved.72fiMinimizing Conflicts: Heuristic Repair Methods1 : the(adj) (N |N s)s2 : (this|that)(adj )Ns3 : (these|those)(num+ )(adj )Ns4 : it|this|that|(this|that|the)adj ones5 : (these|those)num+ adj ones|thems6 : here|theres7 : empty expressions8 : proper nounss9 : multiple expressionsTotal Num:g1gest.24030111113g2onept843080115066g3mult.pts03000003410g4onecir233311025131198g5mult.cirs010000001314g6pts &cirs17500003218TotalNum139136212731531219Table 3: Detailed description user referring behavior6. Evaluationuse data collected previous work (Chai et al., 2004) evaluate greedyalgorithm. questions addressed evaluation following:impact temporal alignment speech gesture performance greedy algorithm?role modeling cognitive status greedy algorithm?eective greedy algorithm compared graph matching algorithm(Section 3.3)?error sources contribute failure real-time reference resolution?greedy algorithm compared nite state approach (Section 3.1)decision list approach (Section 3.2)?6.1 Experiment Setupevaluation data collected eleven subjects participated study.subjects asked interact system using speech gestures(e.g., pointing circle) accomplish tasks related real estate information seeking.rst task nd least expensive house populated town. orderaccomplish task, user would rst nd town highestpopulation nd least expensive house town. next task involvedobtaining description house located previous task. next taskcompare house located rst task houses particulartown terms price. Additionally, least expensive house second towndetermined. Another task nd expensive house particular town.73fiChai, Prasov, & QuS0 : referring expressionS1 : One referring expressionS2 : Multiple referring expressionsTotal Num:G0 :Gesture1 (a)11 (a)1 (c)13G1 : OneGesture2 (a)151 (b)11 (c)164G2 : MultiGesture0 (c)23 (c)19 (c)42TotalNum318531219Table 4: Summary user referring behaviorlast task involved comparing resulting houses previous four tasks.last task, previous four tasks may completely partially repeated.tasks designed users required explore interface acquire varioustypes information.acoustic model subject trained individually minimize speech recognition errors. study session videotaped capture audio videoscreen movement (including gestures system responses). IBM Viavoice speechrecognizer used process speech input.Table 3 provides detailed description referring behavior observed study.columns indicate whether gesture, one gesture (pointing circle), multiple gestures involved multimodal input. rows indicate type referring expressionsspeech utterance. table entry shows number particular combinationspeech gesture inputs.Table 4 summarizes Table 3 terms whether gesture, one gesture, multiplegestures (shown columns) whether referring expression, one referring expression,multiple referring expressions (shown rows) involved input. Notetable intended input counted one input even input may splitturns system run time.Based Table 4, categorize user inputs following three categories:Simple Inputs One-Zero Alignment: inputs contain speech referringexpression gesture (i.e.,< S0 , G0 >), one referring expression zero gesture(i.e.,< S1 , G0 >), referring expression one gesture (i.e., < S0 , G1 >).types inputs require conversation context visual context resolvereferences. One example type U2 Table 1. data, total14 inputs belong category (marked (a) Table 4).Simple Inputs One-One Alignment: inputs contain exactly one referringexpression one gesture (i.e., < S1 , G1 >). types inputs resolvedmostly combining gesture speech using multimodal fusion. total 151inputs belong category (marked (b) Table 4).Complex Inputs: inputs contain one referring expression and/or gesture. corresponds entry < S1 , G2 >, < S2 , G0 >,< S2 , G1 >,< S2 , G2 > Table 4. One example type U3 Table 1. total 5474fiMinimizing Conflicts: Heuristic Repair MethodNo. Correctly ResolvedSimple One-Zero AlignmentSimple One-One AlignmentComplexTotalAccuracyOrdering51042413360.7%Absolute51041912858.4%Combined51042313260.3%Table 5: Performance comparison based dierent temporal compatibility functionsinputs belong category (marked (c) Table 4). types inputsparticularly challenging resolve.section, focus dierent performance evaluations based threetypes referring behaviors.6.2 Temporal Alignment Speech Gesturemultimodal interpretation, align speech gesture based temporalinformation important question. especially case complex inputsmultimodal input consists multiple referring expressions multiple gestures.evaluated dierent temporal compatibility functions greedy approach. particular,compared following three functions:ordering temporal constraint Equation 4.absolute temporal constraint dened following formula:emp(o, e) = exp(|BeginT ime(o) BeginT ime(e)|)(5)Here, absolute timestamps potential referents (e.g., indicated gesture)referring expressions used instead relative orders relevant entitiesuser input.combined temporal constraint combines two aforementioned constraints,giving equal weight determining compatibility score objectreferring expression.results shown Table 5. Dierent temporal constraints aect processing complex inputs. ordering temporal constraint worked slightly betterabsolute temporal constraint. fact, temporal alignment speech gesture often one problems may aect interpretation results. Previous studies foundgestures tend occur corresponding speech unit takes place (Oviatt et al.,1997). ndings suggest users tend tap screen rst startspeech utterance. behavior observed simple command based system (Oviattet al., 1997) speech unit corresponds single gesture (i.e., simple inputswork).75fiChai, Prasov, & QuNon-overlapOverlapTotal :Speech First7%8%15%Gesture First45%40%85%Total52%48%100%Table 6: Overall temporal relations speech gesturestudy, found temporal alignment gesture correspondingspeech units still issue needs investigated order improverobustness multimodal interpretation. Table 6 shows percentage dierenttemporal relations observed study. rows indicate whether overlapspeech referring expressions accompanied gestures. columns indicatewhether speech (more precisely, referring expressions) gesture occurred rst.Consistent previous ndings (Oviatt et al., 1997), cases (85% time),gestures occurred referring expressions uttered. However, 15% casesspeech referring expressions uttered corresponding gesture occurred.Among cases, 8% overlap referring expressions gesture7% overlap.Furthermore, although multimodal behaviors sequential (i.e., non-overlap)simultaneous (e.g., overlap) integration quite consistent course interaction (Oviatt, Coulston, Tomko, Xiao, Bunsford, Wesson, & Carmichael, 2003),exceptions. Figure 7 shows temporal alignments individual users study.User 2 , User 6, User 8 maintained consistent behavior User 2s gesture alwayshappened overlapped corresponding speech referring expressions; User6s gesture always occurred ahead speech expressions without overlapping; User8s speech referring expressions always occurred corresponding gestures (withoutoverlap). users exhibited varied temporal alignment speechgesture interaction. dicult system using pre-dened temporalconstraints anticipate accommodate dierent behaviors. Therefore,desirable mechanism automatically learn user behavior alignmentautomatically adjust behavior.One potential approach introduce calibration process real human computerinteraction. calibration process, two tasks performed user. rsttask, user asked describe objects graph display speechdeictic gestures. second task, user asked respond systemquestions using speech deictic gestures. reason users performtwo tasks identify whether dierence user initiated inputssystem initiated user responses. Based tasks, temporal relationsspeech units corresponding gestures captured used real-timeinteraction.76fiMinimizing Conflicts: Heuristic Repair MethodPercentage OccuranceNon-overlap Speech FirstOverlap Speech FirstNon-overlap Gesture FirstOverlap Gesture First10.90.80.70.60.50.40.30.20.101234567891011User IndexFigure 7: Temporal alignment behavior user studyNo. Correctly ResolvedSimple One-Zero AlignmentSimple One-One AlignmentComplexTotalCognitive Principles510424133without Cognitive Principles59218115Table 7: role cognitive principles greedy algorithm6.3 Role Cognitive Principlesexamine role modeling cognitive status multimodal reference, compared two congurations greedy algorithm. rst conguration basedmatching score dened Equation 2, incorporates cognitive principles describedearlier. second conguration uses matching score completely dependent compatibility referring expression gesture (i.e., Section 5.3.3)without using cognitive principles (i.e., P (o|S) P (S|e) included Equation2).Table 7 shows comparison results terms two congurations. algorithmusing cognitive principles outperforms algorithm use cognitiveprinciples 15%. performance dierence applies simple inputsone-one alignment complex inputs. results indicate modeling cognitivestatus potentially improve reference resolution performance.77fiChai, Prasov, & QuTotal NumTotalSimple One-Zero AlignmentSimple One-One AlignmentComplex2191415154Graph-matchingNum %13059.4%750.0%10468.9%1935.2%GreedyNum %13360.7%535.7%10468.9%2444.4%Table 8: Performance comparison graph-matching algorithm greedyalgorithm6.4 Greedy Algorithm versus Graph-matching Algorithmcompared greedy algorithm graph-matching algorithm termsperformance runtime. Table 8 shows performance comparison. Overall, greedyalgorithm performs comparably graph-matching algorithm.compare runtime, ran algorithm user 10 times inputrun 100 times. words, user input run 1000 times algorithmget average runtime measurement. experiment done UltraSPARC-IIIserver 750MHz 64bit.greedy algorithm graph-matching algorithm functioncalls process speech inputs (e.g., parsing) gesture inputs (e.g., identify potentiallyintended objects). dierence algorithms specic implementationsregarding graph creation matching graph-matching algorithm greedysearch greedy algorithm. result, average time greedy algorithmprocess simple inputs complex inputs 17.3 milliseconds 21.2 millisecondsrespectively. average time graph matching algorithm process simplecomplex inputs 22.3 milliseconds 24.8 milliseconds respectively. results showaverage greedy algorithm runs slightly faster graph-matching algorithmgiven current implementation, although worst case, graph-matching algorithmasymptotically complex.6.5 Real-time Error Analysisunderstand bottleneck real-time multimodal reference resolution, examinederror cases algorithm failed provide correct referents.Like spoken dialog systems, speech recognition major bottleneck. Althoughtrained users acoustic model individually, speech recognition rate stilllow. 127 inputs correctly recognized referring expressions. Amonginputs, 103 resolved correct referents. Fusing inputs multiplemodalities together sometimes compensate recognition errors (Oviatt, 1996).Among 92 inputs referring expressions incorrectly recognized, 29correctly assigned referents due mutual disambiguation. mechanism reduce78fiMinimizing Conflicts: Heuristic Repair Methodrecognition errors, especially utilizing information modalities,important provide robust solution real time multimodal reference resolution.second source errors comes another common problem spoken dialogsystems, namely out-of-vocabulary words. example, area vocabulary.additional semantic constraint expressed area captured. Therefore,system could identify whether house town referred user utteredarea. important system capability acquire knowledge (e.g.,vocabulary) dynamically utilizing information modalities interactioncontext. Furthermore, errors also came lack understanding spatial relations(as house close red one) superlatives (as expensive house).Algorithms aligning visual features resolve spatial references desirable (Gorniak& Roy, 2004).addition two main sources, errors caused unsynchronized inputs.Currently, use idle status (i.e., 2 seconds input either speech gesture)boundary delimit interaction turn. Two types synchronizationobserved. rst type unsynchronized inputs user (such big pausespeech gesture) comes underlying system implementation.system captures speech inputs gesture inputs two dierent serversTCP/IP protocol. communication delay sometimes split one synchronized inputtwo separate turns inputs (e.g., one turn speech input alone turngesture input alone). better engineering mechanism synchronizing inputs desired.disuencies users also accounted small number errors. current algorithm incapable distinguishing disuent cases normal cases. Fortunately,disuent situations occur frequently study (only 6 inputs disuency). consistent previous ndings speech disuency rate lowerhuman machine conversation spontaneous speech (Brennan, 2000). humancomputer conversation, users tend speak carefully utterances tend short. Recentndings indicated gesture patterns could used additional source identifydierent types speech disuencies human-human conversation (Chen, Harper, &Quek, 2002). Based limited cases, found gesture patterns could indicatorsspeech disuencies occur. example, user says show redhouse (point house A), green house (still point house A), behaviorpointing house dierent speech description usually indicates repair. Furthermore, gestures also involve disuencies; example, repeatedly pointing objectgesture repetition. Failure identifying disuencies caused problems referenceresolution. ideal mechanism identify disuencies usingmultimodal information.6.6 Comparative Evaluation Two Approachesexamine greedy algorithm compared nite state approach(Section 3.1) decision list approach (Section 3.2), conducted comparative evaluation. original nite state approach, N-best speech hypotheses maintainedspeech tape. data here, best speech hypothesis speechinput. Therefore, manually updated incorrectly recognized words nite79fiChai, Prasov, & QuNo. Correctly ResolvedSimple Inputs one-one alighmentSimple Inputs zero-one alighmentComplex InputsTotalGreedy116824148Finite State115013128Decision List88120100Table 9: Performance comparison two approachesstate approach would penalized lack N-best speech hypotheses 4 .modied data used three approaches. Table 9 shows comparison results.shown table, greedy algorithm correctly resolved inputsnite state approach decision list approach. major problem nite stateapproach incorporate conversation context nite state transducer.problem contributes failure resolving simple inputs zero-one alignmentcomplex inputs. major problem decision list approach,described earlier, lack capabilities process ambiguous gestures complexinputs.Note greedy algorithm algorithm obtain full semantic interpretation multimodal input. rather algorithm specically referenceresolution, uses information context gesture resolve speech referring expressions. regard, greedy algorithm dierent nite state approachwhose goal get full interpretation user inputs reference resolutionpart process.7. ConclusionMotivated earlier investigation cognitive status human machine interaction,paper describes greedy algorithm incorporates cognitive principles underlying human referring behavior resolve variety references human machine multimodalinteraction. particular, algorithm relies theories Conversation ImplicatureGivenness Hierarchy eectively guide system searching potential referents. empirical studies shown modeling form referring experssionsimplication cognitive status achieve better results algorithmconsiders compatibility referring expressions potential referents.greedy algorithm eciently achieve comparable performance previous optimizationapproach based graph-matching. Furthermore, greedy algorithm handlesvariety user inputs ranging precise ambiguous simple complex,outperforms nite state approach decision list approach experiments.simplicity generality, approach potential improve robustness multimodal interpretation. learned investigation prior4. Note corrected inputs direct correspondence recognizedwords transcribed words maintain consistency timestamps.80fiMinimizing Conflicts: Heuristic Repair Methodknowledge linguistic cognitive studies benecial designing ecientpractical algorithms enabling multimodal human machine communication.Acknowledgmentswork supported NSF CAREER award IIS-0347548. authors would likethank anonymous reviewers valuable comments suggestions.ReferencesBolt, R. (1980). Put there: Voice gesture graphics interface. ComputerGraphics, 14 (3), 262270.Brennan, S. (2000). Processes shape conversation implications computational linguistics. Proceedings 38th Annual Meeting ACL, pp. 18.Byron, D. (2002). Resolving pronominal reference abstract entities. Proceedings40th Annual Meeting ACL, pp. 8087.Cassell, J., Bickmore, T., Billinghurst, M., Campbell, L., Chang, K., Vilhjalmsson, H., &Yan, H. (1999). Embodiment conversational interfaces: Rea. ProceedingsCHI99, pp. 520527.Chai, J., Hong, P., Zhou, M., & Prasov, Z. (2004). Optimization multimodal interpretation. Proceedings 42nd Annual Meeting Association ComputationalLinguistics (ACL), pp. 18.Chai, J., Prasov, Z., Blaim, J., & Jin, R. (2005). Linguistic theories ecient multimodalreference resolution: empirical study. Proceedings 10th InternationalConference Intelligent User Interfaces(IUI), pp. 4350.Chai, J., Prasov, Z., & Hong, P. (2004a). Performance evaluation error analysismultimodal reference resolution conversational system. Proceedings HLTNAACL 2004 (Companion Volumn), pp. 4144.Chai, J. Y., Hong, P., & Zhou, M. X. (2004b). probabilistic approach reference resolution multimodal user interfaces. Proceedings 9th International ConferenceIntelligent User Interfaces (IUI), pp. 7077.Chen, L., Harper, M., & Quek, F. (2002). Gesture patterns speech repairs.Proceedings International Conference Multimodal Interfaces (ICMI), pp. 155160.Cohen, P. (1984). pragmatics referring modality communication. Computational Linguistics, 10, 97146.Cohen, P., Johnston, M., McGee, D., Oviatt, S., Pittman, J., Smith, I., Chen, L., & Clow, J.(1996). Quickset: Multimodal interaction distributed applications. ProceedingsACM Multimedia, pp. 3140.Eckert, M., & Strube, M. (2000). Dialogue acts, synchronising units anaphora resolution. Journal Semantics, Vol. 17(1), pp. 5189.81fiChai, Prasov, & QuGold, S., & Rangarajan, A. (1996). graduated assignment algorithm graph-matching.IEEE Trans. Pattern Analysis Machine Intelligence, 18 (4), 377388.Gorniak, P., & Roy, D. (2004). Grounded semantic composition visual scenes. JournalArtificial Intelligence Research, 21, 429470.Grice, H. P. (1975). Logic conversation. Cole, P., & Morgan, J. (Eds.), Speech Acts,pp. 4158. New York: Academic Press.Grosz, B. J., & Sidner, C. (1986). Attention, intention, structure discourse.Computational Linguistics, 12 (3), 175204.Gundel, J. K., Hedberg, N., & Zacharski, R. (1993). Cognitive status formreferring expressions discourse. Language, 69 (2), 274307.Gustafson, J., Bell, L., Beskow, J., Boye, J., Carlson, R., Edlund, J., Granstrom, B., House,D., & Wiren, M. (2000). Adapt - multimodal conversational dialogue systemapartment domain. Proceedings 6th International Conference SpokenLanguage Processing (ICSLP), Vol. 2, pp. 134137.Huls, C., Bos, E., & Classen, W. (1995). Automatic referent resolution deicticanaphoric expressions. Computational Linguistics, 21 (1), 5979.Johnston, M. (1998). Unication-based multimodal parsing. Proceedings COLINGACL98, pp. 624630.Johnston, M., & Bangalore, S. (2000). Finite-state multimodal parsing understanding.Proceedings COLING00, pp. 369375.Johnston, M., Cohen, P., McGee, D., Oviatt, S., Pittman, J., & Smith, I. (1997). Unicationbased multimodal integration. Proceedings ACL97, pp. 281288.Kehler, A. (2000). Cognitive status form reference multimodal human-computerinteraction. Proceedings AAAI00, pp. 685689.Koons, D. B., Sparrell, C. J., & Thorisson, K. R. (1993). Integrating simultaneous inputspeech, gaze, hand gestures. Maybury, M. (Ed.), Intelligent MultimediaInterfaces, pp. 257276. MIT Press.Neal, J. G., & Shapiro, S. C. (1991). Intelligent multimedia interface technology. Sullivan,J., & Tyler, S. (Eds.), Intelligent User Interfaces, pp. 4568. ACM: New York.Neal, J. G., Thielman, C. Y., Dobes, Z. H., M., S., & Shapiro, S. C. (1998). Natural languageintegrated deictic graphic gestures. Maybury, M., & Wahlster, W. (Eds.),Intelligent User Interfaces, pp. 3851. CA: Morgan Kaufmann Press.Oviatt, S., Coulston, R., Tomko, S., Xiao, B., Bunsford, R., Wesson, M., & Carmichael, L.(2003). Toward theory organized multimodal integration patterns humancomputer interaction. Proceedings Fifth International Conference MultimodalInterfaces, pp. 4451.Oviatt, S., DeAngeli, A., & Kuhn, K. (1997). Integration synchronization inputmodes multimodal human-computer interaction. Proceedings ConferenceHuman Factors Computing Systems: CHI97, pp. 415422.82fiMinimizing Conflicts: Heuristic Repair MethodOviatt, S. L. (1996). Multimodal interfaces dynamic interactive maps. ProceedingsConference Human Factors Computing Systems: CHI96, pp. 95102.Oviatt, S. L. (1999a). Multimodal system processing mobile environments. ProceedingsThirteenth Annual ACM Symposium User Interface Software Technology(UIST2000), pp. 2130.Oviatt, S. L. (1999b). Mutual disambiguation recognition errors multimodal architecture. Proceedings Conference Human Factors Computing Systems:CHI99, pp. 576583.Stent, A., Dowding, J., Gawron, J. M., Bratt, E. O., & Moore, R. (1999). commandtalkspoken dialog system. Proceedings ACL99, pp. 183190.Stock, O. (1993). Alfresco: Enjoying combination natural language processinghypermedia information exploration. Maybury, M. (Ed.), Intelligent MultimediaInterfaces, pp. 197224. MIT Press.Tsai, W. H., & Fu, K. S. (1979). Error-correcting isomorphism attributed relationalgraphs pattern analysis. IEEE Trans. Sys., Man Cyb., 9, 757768.Wahlster, W. (1998). User discourse models multimodal communication. Maybury, M., & Wahlster, W. (Eds.), Intelligent User Interfaces, pp. 359370. ACM Press.Wu, L., & Oviatt, S. (1999). Multimodal integration - statistical view. IEEE TransactionsMultimedia, 1 (4), 334341.Zancanaro, M., Stock, O., & Strapparava, C. (1997). Multimodal interaction informationaccess: Exploiting cohesion. Computational Intelligence, 13 (7), 439464.83fiJournal Artificial Intelligence Research 27 (2006) 153201Submitted 05/06; published 10/06Solving Factored MDPs Hybrid State ActionVariablesBranislav Kvetonbkveton@cs.pitt.eduIntelligent Systems Program5406 Sennott SquareUniversity PittsburghPittsburgh, PA 15260Milos Hauskrechtmilos@cs.pitt.eduDepartment Computer Science5329 Sennott SquareUniversity PittsburghPittsburgh, PA 15260Carlos Guestringuestrin@cs.cmu.eduMachine Learning DepartmentComputer Science Department5313 Wean HallCarnegie Mellon UniversityPittsburgh, PA 15213AbstractEfficient representations solutions large decision problems continuousdiscrete variables among important challenges faced designers automated decision support systems. paper, describe novel hybrid factored Markovdecision process (MDP) model allows compact representation problems,new hybrid approximate linear programming (HALP) framework permitsefficient solutions. central idea HALP approximate optimal value functionlinear combination basis functions optimize weights linear programming.analyze theoretical computational aspects approach, demonstratescale-up potential several hybrid optimization problems.1. Introductiondynamic decision problem components uncertainty often formulatedMarkov decision process (MDP). MDP represents controlled stochastic process whosedynamics described state transitions. Objectives control modeled rewards(or costs), assigned state-action configurations. simplest form, statesactions MDP discrete unstructured. models solved efficientlystandard dynamic programming methods (Bellman, 1957; Puterman, 1994; Bertsekas &Tsitsiklis, 1996).Unfortunately, textbook models rarely meet practice needs. First, real-worlddecision problems naturally described factored form may involve combinationdiscrete continuous variables. Second, guarantees compact formsoptimal value function policy problems exist. Therefore, hybrid optimizationproblems usually discretized solved approximately methods discrete-statec2006AI Access Foundation. rights reserved.fiKveton, Hauskrecht, & GuestrinMDPs. contribution work principled, sound, efficient approach solvinglarge-scale factored MDPs avoids discretization step.framework based approximate linear programming (ALP) (Schweitzer & Seidmann, 1985), already applied solve decision problems discrete stateaction variables efficiently (Schuurmans & Patrascu, 2002; de Farias & Van Roy, 2003;Guestrin et al., 2003). applications include context-specific planning (Guestrin et al.,2002), multiagent planning (Guestrin et al., 2002), relational MDPs (Guestrin et al., 2003),first-order MDPs (Sanner & Boutilier, 2005). work, show adapt ALPsolving large-scale factored MDPs hybrid state action spaces.presented approach combines factored MDP representations (Sections 3 4)optimization techniques solving large-scale structured linear programs (Section 6).leads various benefits. First, quality complexity value function approximationscontrolled using basis functions (Section 3.2). Therefore, prevent exponentialblowup complexity computations techniques cannot. Second, alwaysguarantee HALP returns solution. quality naturally depends choice basisfunctions. analyzed Section 5.1, selected appropriately, achieve closeapproximation optimal value function V . Third, well-chosen class basis functionsyields closed-form solutions backprojections value functions (Section 5.2).step important solving hybrid optimization problems efficiently. Finally, solvinghybrid factored MDPs reduces building satisfying relaxed formulations originalproblem (Section 6). formulations solved efficiently cutting plane method,studied extensively applied mathematics operations research.better readability paper, proofs deferred Appendix A. followingnotation adopted throughout work. Sets members represented capitalsmall italic letters s, respectively. Sets variables, subsets, memberssets denoted capital letters X, Xi , Xi . general, corresponding smallletters represent value assignments objects. subscripted indices C denotediscrete continuous variables variable set value assignment. functionDom() computes domain variable domain function. function Par()returns parent set variable graphical model (Howard & Matheson, 1984; Dean& Kanazawa, 1989).2. Markov Decision ProcessesMarkov decision processes (Bellman, 1957) provide elegant mathematical frameworkmodeling solving sequential decision problems presence uncertainty. Formally,finite-state Markov decision process (MDP) given 4-tuple = (S, A, P, R),= {s1 , . . . , sn } set states, = {a1 , . . . , } set actions, P : [0, 1]stochastic transition function state dynamics conditioned preceding stateaction, R : R reward function assigning immediate payoffs state-actionconfigurations. Without loss generality, reward function assumed nonnegativebounded constant Rmax (Puterman, 1994). Moreover, assumetransition reward models stationary known priori.decision problem formulated MDP, goal find policy :maximizes objective function. paper, quality policy measured154fiSolving Factored MDPs Hybrid State Action Variablesinfinite horizon discounted reward :#"X(t)(t) (0)R(s , (s )) ,E(1)t=0[0, 1) discount factor, s(t) state time step t, expectationtaken respect state-action trajectories start states s(0) followpolicy thereafter. states s(0) chosen according distribution . optimalitycriterion assures exists optimal policy stationary deterministic(Puterman, 1994). policy greedy respect optimal value function V ,fixed point Bellman equation (Bellman, 1957):"#XV (s) = max R(s, a) +P (s | s, a)V (s ) .(2)Bellman equation plays fundamental role dynamic programming (DP) methodssolving MDPs (Puterman, 1994; Bertsekas & Tsitsiklis, 1996), including value iteration,policy iteration, linear programming. focus paper linear programmingmethods refinements. Briefly, well known optimal value function Vsolution linear programming (LP) formulation (Manne, 1960):Xminimize(s)V (s)(3)subject to: V (s) R(s, a) +XP (s | s, a)V (s ) S, A;V (s) represents variables LP, one state s, (s) > 0 strictlypositive weighting state space S. number constraints equals cardinalitycross product state action spaces |S A|.Linear programming efficient solutions studied extensively appliedmathematics operations research (Bertsimas & Tsitsiklis, 1997). simplex algorithmcommon way solving LPs. worst-case time complexity exponential numbervariables. ellipsoid method (Khachiyan, 1979) offers polynomial time guaranteesimpractical solving LPs even moderate size.LP formulation (3) solved compactly cutting plane method (Bertsimas& Tsitsiklis, 1997) objective function constraint space structured. Briefly,method searches violated constraints relaxed formulations original LP. everystep, start relaxed solution V (t) , find violated constraint given V (t) , addLP, resolve new vector V (t+1) . method iterated violated constraintfound, V (t) optimal solution LP. approach potential solvelarge structured linear programs identify violated constraints efficiently (Bertsimas& Tsitsiklis, 1997). violated constraint method found often referredseparating hyperplane separation oracle, respectively.Delayed column generation based similar idea cutting plane method,applied column space variables instead row space constraints. BendersDantzig-Wolfe decompositions reflect structure constraint space oftenused solving large structured linear programs.155fiKveton, Hauskrecht, & Guestrin3. Discrete-State Factored MDPsMany real-world decision problems naturally described factored form. Discrete-statefactored MDPs (Boutilier et al., 1995) allow compact representation structure.3.1 Factored Transition Reward Modelsdiscrete-state factored MDP (Boutilier et al., 1995) 4-tuple = (X, A, P, R),X = {X1 , . . . , Xn } state space described set state variables, = {a1 , . . . , }set actions1 , P (X | X, A) stochastic transition model state dynamics conditionedpreceding state action, R reward function assigning immediate payoffsstate-action configurations. state system completely observed representedvector value assignments x = (x1 , . . . , xn ). assume values every statevariable Xi restricted finite domain Dom(Xi ).Transition model: transition model given conditional probability distribution P (X | X, A), X X denote state variables two successive time steps.Since complete tabular representation P (X | X, A) infeasible, assumetransition model factors along X as:P (X | X, a) =nP (Xi | Par(Xi ), a)(4)i=1described compactly dynamic Bayesian network (DBN) (Dean & Kanazawa,1989). DBN representation captures independencies among state variables XX given action a. One-step dynamics every state variable modeled conditionalprobability distribution P (Xi | Par(Xi ), a), Par(Xi ) X denotes parent set Xi .Typically, parent set subset state variables simplifies parameterizationmodel. principle, parent set extended state variables X .extension poses new challenges solving new problems efficiently (Guestrin,2003). Therefore, omit discussion modeling intra-layer dependenciespaper.Reward model: reward modelfactors similarly transition model. particular,Preward function R(x, a) = j Rj (xj , a) additive function local reward functionsdefined subsets Xj A. graphical models, local functions describedcompactly reward nodes Rj , conditioned parent sets Par(Rj ) = Xj A.allow representation, formally extend DBN influence diagram (Howard& Matheson, 1984).Example 1 (Guestrin et al., 2001) illustrate concept factored MDP, consider network administration problem, computers unreliable fail.failures computers propagate network connections whole network.instance, server X1 (Figure 1a) down, chance neighboring computer X21. simplicity exposition, discuss simpler model, assumes single action variable insteadfactored action space = {A1 , . . . , }. conclusions Sections 3.1 3.3 extend MDPsfactored action spaces (Guestrin et al., 2002).156fiSolving Factored MDPs Hybrid State Action Variables(a)(b)(c)Figure 1: a. Four computers ring topology. Direction propagating failures denotedarrows. b. graphical representation factored transition reward modelstaking action a1 4-ring topology. future state server X1independent rest network server rebooted. Rewardnodes R1 Rj (j 2) denote components 2x1 xj (j 2) rewardmodel. c. graphicalrepresentation linear value function approximationPV w (x) = w0 + 4i=1 wi xi 4-ring topology. Reward nodes H0 Hi (i 1)denote value function components w0 wi xi (i 1).crashes increases. administrator prevent propagation failures rebootingcomputers already crashed.network administration problem formulated factored MDP. statenetwork completely observable represented n binary variables X = {X1 , . . . , Xn },variable Xi denotes state i-th computer: 0 (being down) 1 (running).time step, administrator selects action set = {a1 , . . . , an+1 }.action ai (i n) corresponds rebooting i-th computer. last action an+1 dummy.transition function reflects propagation failures network encodedlocally conditioning parent set every computer. natural metric evaluatingperformance administrator total number running computers. metricfactors along computer states xi represented compactly additive rewardfunction:R(x, a) = 2x1 +nXxj .j=2weighting states establishes preferences maintaining server X1 workstations X2 , . . . , Xn . example transition reward models taking action a14-ring topology (Figure 1a) given Figure 1b.3.2 Solving Discrete-State Factored MDPsMarkov decision processes solved exact DP methods polynomial time sizestate space X (Puterman, 1994). Unfortunately, factored state spaces exponentialnumber state variables. Therefore, DP methods unsuitable solving large157fiKveton, Hauskrecht, & Guestrinfactored MDPs. Since factored representation MDP (Section 3.1) may guaranteestructure optimal value function policy (Koller & Parr, 1999), resort valuefunction approximations alleviate concern.Value function approximations successfully applied variety real-worlddomains, including backgammon (Tesauro, 1992, 1994, 1995), elevator dispatching (Crites& Barto, 1996), job-shop scheduling (Zhang & Dietterich, 1995, 1996). partialsuccesses suggest approximate dynamic programming powerful tool solvinglarge optimization problems.work, focus linear value function approximation (Bellman et al., 1963; VanRoy, 1998):V w (x) =Xwi fi (x).(5)approximation restricts form value function V w linear combination|w| basis functions fi (x), w vector optimized weights. Every basis functiondefined complete state space X, usually limited small subset statevariables Xi (Bellman et al., 1963; Koller & Parr, 1999). role basis functions similarfeatures machine learning. often provided domain experts, althoughgrowing amount work learning basis functions automatically (Patrascu et al., 2002;Mahadevan, 2005; Kveton & Hauskrecht, 2006a; Mahadevan & Maggioni, 2006; Mahadevanet al., 2006).Example 2 demonstrate concept linear value function model, considernetwork administration problem (Example 1) assume low chance single computerfailing. value function Figure 1c sufficient derive close-to-optimal policy4-ring topology (Figure 1a) indicator functions fi (x) = xi capture changesstates individual computers. instance, computer Xi fails, linear policy:"#Xwu(x) = arg max R(x, a) +P (x | x, a)V (x )ximmediately leads rebooting it. failure already propagated computer Xi+1 ,policy recovers next step. procedure repeated spread initialfailure stopped.3.3 Approximate Linear ProgrammingVarious methods fitting linear value function approximation proposedanalyzed (Bertsekas & Tsitsiklis, 1996). focus approximate linear programming(ALP) (Schweitzer & Seidmann, 1985), recasts problem linear program:minimizewXxsubject to:X(x)Xwi fi (x)wi fi (x) R(x, a) +(6)XP (x | x, a)x158Xwi fi (x )x X, A;fiSolving Factored MDPs Hybrid State Action Variablesw represents variables thePLP, (x) 0Pstate relevance weights weightingquality approximation, x P (x | x, a) wi fi (x ) discounted backprojection value function V w (Equation 5). ALP formulation easily derivedstandard LP formulation (3) substituting V w (x) V (x). formulationfeasible set basis functions contains constant function f0 (x) 1. assumebasis function always present. Note state relevance weights longerenforced strictly positive (Section 1). Comparing standard LP formulation (3),solved optimal value function V arbitrary weights (s) > 0, solutione ALP formulation depends weights (x). Intuitively, higher weights,wehigher quality approximation V wcorresponding state.Since basis functions usually restricted subsets state variables (Section 3.2),summation terms ALP formulation computed efficiently (Guestrin et al., 2001;Schuurmans & Patrascu, 2002).Pexample, order summation backprojectionPterm rearranged wi x P (xi | x, a)fi (xi ), allows aggregationspace Xi instead X. Similarly, factored form (x) yields efficiently computableobjective function (Guestrin, 2003).number constraints ALP formulation exponential number statevariables. Fortunately, constraints structured. results combining factoredtransition reward models (Section 3.1) linear approximation (Equation 5).consequence, constraints satisfied without enumerating exhaustively.Example 3 notion factored constraint space important compact satisfactionexponentially many constraints. illustrate concept, let us consider linear valuefunction (Example 2) 4-ring network administration problem (Example 1). Intuitively,combining graphical representations P (x | x, a1 ), R(x, a1 ) (Figure 1b), V w (x)(Figure 1c), obtain factored model constraint violations:XP (x | x, a1 )V w (x ) R(x, a1 )w (x, a1 ) = V w (x)=Xxwi fi (x)= w0 +Xwi4XXP (xi | x, a1 )fi (xi ) R(x, a1 )xiwi xi w0 w1 P (x1 = 1 | a1 )i=14Xwi P (xi = 1 | xi , xi1 , a1 ) 2x14Xxj .j=2i=2arbitrary solution w (Figure 2a). Note cost function:w (x, a1 ) = w +4Xw (xi ) +4Xw (xi , xi1 )i=2i=1linear combination constant w x, univariate bivariate functions w (xi )w (xi , xi1 ). represented compactly cost network (Guestrin et al., 2001),undirected graph set variables X. Two nodes graph connected159fiKveton, Hauskrecht, & Guestrin(a)(b)Figure 2: a. graphical representation combining factored transition reward models(Figure 1b) linear approximation (Figure 1c). Reward nodes G0 Gi(i 1) represent discounted backprojection terms w0 wi xi (i 1).Gray regions cost components constraint space. b. cost networkcorresponding factored constraint space (Figure 2a). network capturespairwise dependencies X1 X2 , X2 X3 , X3 X4 . treewidth costnetwork 1.cost terms depends variables. Therefore, cost network correspondingfunction w (x, a1 ) must contain edges X1 X2 , X2 X3 , X3 X4 (Figure 2b).Savings achieved compact representation constraints related efficiencycomputing arg minx w (x, a1 ) (Guestrin, 2003). computation done variableelimination complexity increases exponentially width tree decompositioncost network. smallest width tree decompositions referred treewidth.Inspired factorization, Guestrin et al. (2001) proposed variable-elimination method(Dechter, 1996) rewrites constraint space ALP compactly. Schuurmans Patrascu (2002) solved problem cutting plane method. method iterativelysearches violated constraint:XX (t)P (xi | x, a)fi (xi ) R(x, a)(7)arg minwi fi (xi )x,axirespect solution w(t) relaxed ALP. constraint added LP,resolved new solution w(t+1) . procedure iterated violated constraintfound, w(t) optimal solution ALP.quality ALP formulation studied de Farias Van Roy (2003).eBased work, conclude ALP yields close approximation V woptimalwvalue function V weighted max-norm error kV V k,1/L minimized.return theoretical result Section 5.1.160fiSolving Factored MDPs Hybrid State Action Variablese solution ALP formulationTheorem 1 (de Farias & Van Roy, 2003) Let we(6). expected error value function V wbounded as:2 Lemin kV V w k,1/L ,V V w1 w1,Pkk1, L1 -norm weighted state relevance weights , L(x) = wiL fi (x)Lyapunov function inequality L(x) supa EP (x |x,a) [L(x )] holds, [0, 1)denotes contraction factor, kk,1/L max-norm reweighted reciprocal 1/L.eeV V wNote L1 -norm distance V V wequalsexpectationE1,state space X respect state relevance weights . Similarly Theorem 1,utilize L1 L norms rest work measure expected worst-caseerrors value functions. norms defined follows.Definition1 L1 (Manhattan) L (infinity) norms typically defined kf k1 =Px |f (x)| kf k = maxx |f (x)|. state space X represented discretecontinuous variables XD XC , definition norms changes accordingly:XZkf k1 =|f (x)| dxC kf k = sup |f (x)| .(8)xDxxCfollowing definitions:XZkf k1, =(x) |f (x)| dxCxDxCkf k, = sup (x) |f (x)|(9)xcorrespond L1 L norms reweighted function (x).4. Hybrid Factored MDPsDiscrete-state factored MDPs (Section 3) permit compact representation decision problems discrete states. However, real-world domains often involve continuous quantities,temperature pressure. sufficient discretization quantities may requirehundreds points single dimension, renders representation transitionmodel (Equation 4) infeasible. addition, rough uninformative discretization impactsquality policies. Therefore, want avoid discretization defer necessary.step direction, discuss formalism representing hybrid decision problemsdomains discrete continuous variables.4.1 Factored Transition Reward Modelshybrid factored MDP (HMDP) 4-tuple = (X, A, P, R), X = {X1 , . . . , Xn }state space described state variables, = {A1 , . . . , } action space describedaction variables, P (X | X, A) stochastic transition model state dynamics conditionedpreceding state action, R reward function assigning immediate payoffsstate-action configurations.22. General state action space MDP alternative term hybrid MDP. term hybridrefer dynamics model, discrete-time.161fiKveton, Hauskrecht, & GuestrinP(X2 | X2 = 0)P(X1 )P(X2 | X2 = 1, X1 = 0)P(X2 | X2 = 1, X1 = 1)Probability density8642000.5X11444333222111000.5X20100.5X21000.5X21Figure 3: Transition functions continuous variables X1 X2 taking action a14-ring topology (Example 4). densities shown extreme valuesparent variables X1 X2 .State variables: State variables either discrete continuous. Every discrete variableXi takes values finite domain Dom(Xi ). Following Hauskrecht Kveton (2004),assume every continuous variable bounded [0, 1] subspace. general,assumption mild permits modeling closed interval R. statesystem completely observed described vector value assignments x = (xD , xC )partitions along discrete continuous components xD xC .Action variables: action space distributed represented action variables A.composite action defined vector individual action choices = (aD , aC )partitions along discrete continuous components aD aC .Transition model: transition model given conditional probability distribution P (X | X, A), X X denote state variables two Qsuccessive time steps.assume distribution factors along X P (X | X, A) = ni=1 P (Xi | Par(Xi ))described compactly DBN (Dean & Kanazawa, 1989). Typically, parentset Par(Xi ) X small subset state action variables allows localparameterization transition model.Parameterization transition model: One-step dynamics every state variabledescribed conditional probability distribution P (Xi | Par(Xi )). Xi continuousvariable, transition function represented mixture beta distributions (Hauskrecht& Kveton, 2004):XP (Xi = x | Par(Xi )) =ij Pbeta (x | j , j )(10)j( + ) 1x(1 x)1 ,Pbeta (x | , ) =()()ij weight assigned j-th component mixture, j = ij (Par(Xi ))j = ij (Par(Xi )) arbitrary positive functions parent set. mixture betadistributions provides general class transition functions yet allows closed-form162fiSolving Factored MDPs Hybrid State Action Variablessolutions3 expectation terms HALP (Section 5). every j = 1, Equation 10 turnspolynomial Xi . Due Weierstrass approximation theorem (Jeffreys & Jeffreys,1988), polynomial sufficient approximate continuous transition densityXi precision. Xi discrete variable, transition model parameterized|Dom(Xi )| nonnegative discriminant functions j = ij (Par(Xi )) (Guestrin et al., 2004):jP (Xi = j | Par(Xi )) = P|Dom(Xi )|j=1.(11)jNote parameters j , j , j (Equations 10 11) functions instantiatedvalue assignments variables Par(Xi ) X A. keep separate parameters everystate variable Xi although indexing reflect explicitly. restrictionfunctions return valid parameters state-action pairs (x, a). Hence,P|Dom(X )|assume j (x, a) 0, j (x, a) 0, j (x, a) 0, j=1 j (x, a) > 0.Reward model: reward Pmodel factors similarly transition model. particular,reward function R(x, a) = j Rj (xj , aj ) additive function local reward functionsdefined subsets Xj Aj . graphical models, local functions describedcompactly reward nodes Rj , conditioned parent sets Par(Rj ) = Xj Aj .allow representation, formally extend DBN influence diagram (Howard& Matheson, 1984). Note form reward functions Rj (xj , aj ) restricted.Optimal value function policy: optimal policy defined greedilyrespect optimal value function V , fixed point Bellman equation:(12)V (x) = sup R(x, a) + EP (x |x,a) V (x )XZP (x | x, a)V (x ) dxC .= sup R(x, a) +xCxDAccordingly, hybrid Bellman operator given by:V (x) = sup R(x, a) + EP (x |x,a) V (x ) .(13)rest paper, denote expectation terms discrete continuous variablesunified form:XZEP (x) [f (x)] =P (x)f (x) dxC .(14)xDxCExample 4 (Hauskrecht & Kveton, 2004) Continuous-state network administrationvariation Example 1, computer states represented continuous variablesinterval 0 (being down) 1 (running). time step, administrator3. term closed-form refers generally accepted set closed-form operations functions extendedgamma incomplete beta functions.163fiKveton, Hauskrecht, & Guestrinselects single action set = {a1 , . . . , an+1 }. action ai (i n) correspondsrebooting i-th computer. last action an+1 dummy. transition model capturespropagation failures network encoded locally beta distributions:= 20a=i=26= 2 + 13xi 5xi E[Par(Xi )] == 10 2xi 6xi E[Par(Xi )]P (Xi = x | Par(Xi )) = Pbeta (x | , )variables xi E[Par(Xi )] denote state i-th computer expectedstate parents. Note transition function similar Example 1. instance,4-ring topology, modes transition densities continuous variables X1 X2taking action a1 (Figure 3):Pb(X2Pb(X1 | = a1 ) = 0.95 Pb(X2 | X2 = 1, X1 = 0, = a1 ) 0.67| X2 = 0, = a1 ) = 0.10 Pb(X2 | X2 = 1, X1 = 1, = a1 ) = 0.90equal expected values discrete counterparts (Figure 1b). reward functionadditive:R(x, a) =2x21+nXx2jj=2establishes preferences maintaining server X1 workstations X2 , . . . , Xn .4.2 Solving Hybrid Factored MDPsValue iteration, policy iteration, linear programming fundamental dynamicprogramming methods solving MDPs (Puterman, 1994; Bertsekas & Tsitsiklis, 1996).Unfortunately, none techniques suitable solving hybrid factored MDPs. First,complexity exponential number state variables variables discrete.Second, methods assume finite support optimal value function policy,may exist continuous variables present. Therefore, feasible approach solvingarbitrary HMDPs likely approximate. rest section, review two majorclasses methods approximating value functions hybrid domains.Grid-based approximation: Grid-based methods (Chow & Tsitsiklis, 1991;Rust, 1997)transform initial state space X set grid points G = x(1) , . . . , x(N ) . pointsused estimate optimal value function VG grid, turn approximatesV . Bellman operator grid defined (Rust, 1997):NXPG (x(j) | x(i) , a)V (x(j) ) ,(15)TG V (x(i) ) = max R(x(i) , a) +j=1(i)(j) | x(i) , a) transition function, normalwhere PG (x(j) | x(i) , a) = 1aP(x )P (x(j) | x(i) , a). operator allows computationized term (x(i) ) = Nj=1 P (xGvalue function VG standard techniques solving discrete-state MDPs.164fiSolving Factored MDPs Hybrid State Action VariablesInputs:hybrid factored MDP = (X, A, P, R)basis functions f0 (x), f1 (x), f2 (x), . . .initial basis function weights w(0)set states G = x(1) , . . . , x(N )Algorithm:t=0stopping criterion metevery state x(j)every basis function fi (x)Xji = fhi (x(j) )h (t)iiyj = maxa R(x(j) , a) + EP (x |x(j) ,a) V w (x )w(t+1) = (XT X)1 XTt=t+1Outputs:basis function weights w(t)Figure 4: Pseudo-code implementation least-squares value iteration (L2 VI)linear value function approximation (Equation 5).oftenstopping criterion(t)w(t)V w measuredbased number steps L2 -norm error V2set G. discussion Sections 5.2 6 provides recipe efficient(t)implementation backup operation V w (x(j) ).Rust (1997) analyzed convergence methods random pseudo-randomsamples. Clearly, uniform discretization increasing precision guarantees convergenceVG V causes exponential blowup state space (Chow & Tsitsiklis, 1991).overcome concern, Munos Moore (2002) proposed adaptive algorithm nonuniform discretization based Kuhn triangulation. Ferns et al. (2005) analyzed metricsaggregating states continuous-state MDPs based notion bisimulation. TrickZin (1993) used linear programming solve low-dimensional problems continuousvariables. continuous variables discretized manually.Parametric value function approximation: alternative approach solving factoredMDPs continuous-state components approximation optimal value functionV parameterized model V (Bertsekas & Tsitsiklis, 1996; Van Roy, 1998; Gordon,1999). parameters typically optimized iterativelyapplyingbackup operatorfinite set states. least-squares error V V 2 commonly minimizederror metric (Figure 4). Online updating gradient methods (Bertsekas & Tsitsiklis, 1996;Sutton & Barto, 1998) another way optimizing value functions. limitationtechniques solutions often unstable may diverge (Bertsekas, 1995).hand, generate high-quality approximations.165fiKveton, Hauskrecht, & GuestrinParametric approximations often assume fixed value function models. However,cases, possible derive flexible forms V combine well backup operator. instance, Sondik (1971) showed convex piecewise linear functions sufficientrepresent value functions DP backups partially-observable MDPs (POMDPs)(Astrom, 1965; Hauskrecht, 2000). Based idea, Feng et al. (2004) proposed methodsolving MDPs continuous variables. obtain full DP backups, value functionapproximation restricted rectangular piecewise linear convex (RPWLC) functions.restrictions placed transition reward models MDPs. advantageapproach adaptivity. major disadvantages restrictions solved MDPscomplexity RPWLC value functions, may grow exponentially numberbackups. result, without modifications, approach less likely succeedsolving high-dimensional distributed decision problems.5. Hybrid Approximate Linear Programmingovercome limitations existing methods solving HMDPs (Section 4.2), extenddiscrete-state ALP (Section 3.3) hybrid state action spaces. refer novelframework hybrid approximate linear programming (HALP).Similarly discrete-state ALP, HALP optimizes linear value function approximation (Equation 5). Therefore, transforms initially intractable problem computingV hybrid state space X lower dimensional space w. HALP formulationgiven linear program4 :minimizewXwi(16)subject to:Xwi Fi (x, a) R(x, a) 0 x X, A;w represents variables LP, denotes basis function relevance weight:= E(x) [fi (x)]XZ=(x)fi (x) dxC ,xD(17)xC(x) 0 state relevance density function weights quality approximation,Fi (x, a) = fi (x) gi (x, a) denotes difference basis function fi (x)discounted backprojection:gi (x, a) = EP (x |x,a) fi (x )XZP (x | x, a)fi (x ) dxC .=xD(18)xC4. precisely, HALP formulation (16) linear semi-infinite optimization problem infinitenumber constraints. number basis functions finite. brevity, refer optimizationproblem linear programming.166fiSolving Factored MDPs Hybrid State Action VariablesVectors xD (xD ) xC (xC ) discrete continuous components value assignments x (x ) state variables X (X ). linear program rewritten compactly:minimizewE [V w ]subject to: Vw(19)Vw0using Bellman operator .HALP formulation reduces discrete-state ALP (Section 3.3) stateaction variables discrete, continuous-state ALP (Hauskrecht & Kveton, 2004)state variables continuous. formulation feasible set basis functionscontains constant function f0 (x) 1. assume basis function present.rest paper, address several concerns related HALP formulation.First, analyze quality approximation relate minimizationmax-norm error kV V w k , commonly-used metric (Section 5.1). Second,present rich classes basis functions lead closed-form solutions expectationterms objective function constraints (Equations 17 18). terms involvesums integrals complete state space X (Section 5.2), therefore hardevaluate. Finally, discuss approximations constraint space HALP introduceframework solving HALP formulations unified way (Section 6). Note completesatisfaction constraint space may possible since every state-action pair (x, a)induces constraint.5.1 Error Boundsquality ALP approximation (Section 3.3) studied de Farias VanRoy (2003). follow work extend structured state action spacescontinuous variables. proceed, demonstrate solution HALPformulation (16) constitutes upper bound optimal value function V .ee solution HALP formulation (16). V wProposition 1 Let wV .result allows us restate objective E [V w ] HALP.e solution HALP formulation (16):Proposition 2 Vector wminimizewE [V w ]subject to:V w V w 0minimizewkV V w k1,subject to:V w V w 0;solves:kk1, L1 -norm weighted state relevance density functionhybrid Bellman operator.167fiKveton, Hauskrecht, & GuestrinBased Proposition 2, conclude HALP optimizes linear value function approximation respect reweighted L1 -norm error kV V w k1, . following theoremdraws parallel minimizing objective max-norm error kV V w k .eprecisely, theorem says HALP yields close approximation V woptimal valuefunction V V close span basis functions fi (x).e optimal solution HALP formulation (16). expectedTheorem 2 Let weerror value function V wbounded as:2ewVVmin kV V w k ,1 w1,kk1, L1 -norm weighted state relevance density function kkmax-norm.eUnfortunately, Theorem 2 rarely yields tight bound V V w. First, hard1,guarantee uniformly low max-norm error kV V w k dimensionality problemgrows basis functions fi (x) local. Second, bound ignores state relevancedensity function (x) although one impacts quality HALP solutions. addressconcerns, introduce non-uniform weighting max-norm error Theorem 3.e optimal solution HALP formulation (16). expectedTheorem 3 Let weerror value function V wbounded as:eV V w1,2E [L]min kV V w k,1/L ,1 wPkk1, L1 -norm weighted state relevance density , L(x) = wiL fi (x)Lyapunov function inequality L(x) supa EP (x |x,a) [L(x )] holds, [0, 1)denotes contraction factor, kk,1/L max-norm reweighted reciprocal 1/L.Note Theorem 2 special form Theorem 3 L(x) 1 = . Therefore,Lyapunov function L(x) permits least good bounds Theorem 2. makebounds tight, function L(x) return large values regions state space,unimportant modeling. turn, reciprocal 1/L(x) close zeroundesirable regions, makes impact max-norm error kV V w k,1/L lesslikely. Since state relevance density function (x) reflects importance states,term E [L] remain small. two factors contribute tighter boundsTheorem 2.PSince Lyapunov function L(x) = wiL fi (x) lies span basis functions fi (x),Theorem 3 provides recipe achieving high-quality approximations. Intuitively, goodset basis functions always involves two types functions. first type guarantees smallerrors |V (x) V w (x)| important regions state space, state relevancedensity (x) high. second type returns high values state relevance density(x) low, vice versa. latter functions allow satisfaction constraint spaceV w V w unimportant regions state space without impacting optimizedobjective function kV V w k1, . Note trivial value function V w (x) = (1)1 Rmax168fiSolving Factored MDPs Hybrid State Action Variablessatisfies constraints HALP unlikely leads good policies. comprehensivediscussion selecting appropriate (x) L(x), refer case studies de FariasVan Roy (2003).discussion concluded clarifying notion state relevance density (x).demonstrated Theorem 4, choice closely related quality greedy policyevalue function V w(de Farias & Van Roy, 2003).e optimal solution HALP formulation (16). expectedTheorem 4 Let werror greedy policy:hhiieu(x) = arg sup R(x, a) + EP (x |x,a) V w(x )bounded as:kV V u k1,1e,V V w11,u,kk1, kk1,u, weighted L1 -norms, V u value function greedy policyu, u, expected frequency state visits generated following policy u giveninitial state distribution .Based Theorem 4, may conclude expected error greedy policies HALPapproximations bounded = u, . Note distribution u, unknowneoptimizing V wfunction optimized quantity itself. break cycle,de Farias Van Roy (2003) suggested iterative procedure solves several LPsadapts u, accordingly. addition, real-world control problems exhibit lot structure,permits guessing u, .Finally, important realize although bounds (Theorems 3 4) buildfoundation better HALP approximations, rarely used practiceoptimal value function V generally unknown. all, known, needapproximate it. Moreover, note optimization kV V w k,1/L (Theorem 3)hard problem methods would minimize error directly (Patrascuet al., 2002). Despite facts, bounds provide loose guidance empirical choicesbasis functions. Section 7, use intuition propose basis functionsclosely approximate unknown optimal value functions V .5.2 Expectation TermsSince basis functions often restricted small subsets state variables, expectationterms (Equations 17 18) HALP formulation (16) efficiently computable.unify analysis expectation terms, E(x) [fi (x)] EP (x |x,a) [fi (x )], showevaluation constitutes computational problem EP (x) [fi (x)], P (x)denotes factored distribution.discuss expectation terms constraints, note transition functionP (x | x, a) factored parameterization determined state-action pair (x, a).keep pair (x, a) fixed rest section, corresponds choosing singleconstraint (x, a). Based selection, rewrite expectation terms EP (x |x,a) [fi (x )]169fiKveton, Hauskrecht, & Guestrinsimpler notation EP (x ) [fi (x )], P (x ) = P (x | x, a) denotes factored distributionfixed parameters.also assume state relevance density function (x) factors along X as:(x) =n(xi ),(20)i=1(xi ) distribution random state variable Xi . Based assumption,rewrite expectation terms E(x) [fi (x)] objective function new notationEP (x) [fi (x)], P (x) = (x) denotes factored distribution. line discussionlast two paragraphs, efficient solutions expectation terms HALP obtainedsolving generalized term EP (x) [fi (x)] efficiently. address problem restsection.computing expectation term EP (x) [fi (x)] complete state space X,recall basis function fi (x) defined subset state variables Xi . Therefore,may conclude EP (x) [fi (x)] = EP (xi ) [fi (xi )], P (xi ) denotes factored distributionlower dimensional space Xi . assumptions made, local expectationterm EP (xi ) [fi (xi )] may still hard compute. Although estimated varietynumerical methods, instance Monte Carlo (Andrieu et al., 2003), techniquesimprecise sample size small, quite computationally expensive high precisionneeded. Consequently, try avoid approximation step. Instead, introduceappropriate form basis functions leads closed-form solutions expectationterm EP (xi ) [fi (xi )].particular, let us assume every basis function fi (xi ) factors as:fi (xi ) = fiD (xiD )fiC (xiC )(21)along discrete continuous components fiD (xiD ) fiC (xiC ), continuouscomponent decouples product:fiC (xiC ) =fij (xj )(22)Xj XiCunivariate basis function factors fij (xj ). Note basis functions remain multivariatedespite two independence assumptions. make presumptions computationalpurposes relaxed later section.Based Equation 21, conclude expectation term:EP (xi ) [fi (xi )] = EP (xi ) [fiD (xiD )fiC (xiC )]= EP (xi) [fiD (xiD )] EP (xiC ) [fiC (xiC )](23)decomposes along discrete continuous variables XiD XiC , xi = (xiD , xiC )P (xi ) = P (xiD )P (xiC ). evaluation discrete part EP (xi ) [fiD (xiD )] requiresaggregation subspace XiD :X(24)P (xiD )fiD (xiD ),EP (xi ) [fiD (xiD )] =xiD170fiSolving Factored MDPs Hybrid State Action VariablesProbability densityfpoly (x2 )fpwl (x2 )fbeta (x2 )444333222111000.5X21000.5X21000.5X21Figure 5: Expectation three basis functions f (x2 ) (Example 5) respect transition function P (X2 | X2 = 1, X1 = 0, = a1 ) Figure 3. Every basis functionf (x2 ) depicted thick black line. transition function shown lightgray color. Darker gray lines represent values product P (x2 | x, a1 )f (x2 ).area corresponds expectation terms EP (x2 |x,a1 ) [f (x2 )].Qcarried efficiently O( Xj Xi |Dom(Xj )|) time (Section 3.3). FollowingEquation 22, continuous term EP (xi ) [fiC (xiC )] decouples product:CEP (xi ) [fiC (xiC )] = EP (xi )CC=Xj XiCfij (xj )EP (xj ) [fij (xj )] ,(25)Xj XiCEP (xj ) [fij (xj )] represents expectation terms individual random variables Xj .Consequently, efficient solution local expectation term EP (xi ) [fi (xi )] guaranteedefficient solutions univariate components EP (xj ) [fij (xj )].paper, consider three univariate basis function factors fij (xj ): piecewise linearfunctions, polynomials, beta distributions. factors support general classbasis functions yet allow closed-form solutions expectation terms EP (xj ) [fij (xj )].solutions provided following propositions demonstrated Example 5.Proposition 3 (Polynomial basis functions) Let:P (x) = Pbeta (x | , )beta distribution X and:f (x) = xn (1 x)mpolynomial x (1 x). EP (x) [f (x)] closed-form solution:EP (x) [f (x)] =( + ) ( + n)( + m).()() ( + + n + m)171fiKveton, Hauskrecht, & GuestrinCorollary 1 (Beta basis functions) Let:P (x) = Pbeta (x | , )f (x) = Pbeta (x | f , f )beta distributions X. EP (x) [f (x)] closed-form solution:EP (x) [f (x)] =( + ) (f + f ) ( + f 1)( + f 1).()() (f )(f ) ( + f + + f 2)Proof: direct consequence Proposition 3. Since integration distributive operation,claim straightforwardly generalizes mixture beta distributions P (x).Proposition 4 (Piecewise linear basis functions) Let:P (x) = Pbeta (x | , )beta distribution X and:f (x) =X1[li ,ri ] (x)(ai x + bi )piecewise linear (PWL) function x, 1[li ,ri ] (x) represents indicator functioninterval [li , ri ]. EP (x) [f (x)] closed-form solution:X++(F (ri ) F (li )) + bi (F (ri ) F (li )) ,aiEP (x) [f (x)] =+F (u) = Fbeta (u | , ) F + (u) = Fbeta (u | + 1, ) denote cumulative densityfunctions beta distributions.Example 5 Efficient closed-form solutions expectation terms HALP illustrated4-ring network administration problem (Example 4) three hypothetical univariatebasis functions:fpoly (x2 ) = x42fbeta (x2 ) = Pbeta (x2 | 2, 6)fpwl (x2 ) = 1[0.3,0.5] (x2 )(5x2 1.5) + 1[0.5,0.7] (x2 )(5x2 + 3.5)Suppose goal evaluate expectation terms single constraint correspondsnetwork state x = (0, 1, 0, 0) administrator rebooting server. Basedassumptions, expectation terms constraint (x, a1 ) simplify as:EP (x |x,a1 ) f (x2 ) = EP (x2 |x,a1 ) f (x2 ) ,transition function P (x2 | x, a1 ) given by:P (x2 | x, a1 ) = P (X2 = x2 | X2 = 1, X1 = 0, = a1 )= Pbeta (x2 | 15, 8).172fiSolving Factored MDPs Hybrid State Action VariablesClosed-form solutions simplified expectation terms EP (x2 |x,a1 ) [f (x2 )] computed as:ZPbeta (x2 | 15, 8)x4EP (x2 |x,a1 ) fpoly (x2 ) =2 dx2x2(15 + 8) (15 + 4)(8)(15)(8) (15 + 8 + 4)0.20ZPbeta (x2 | 15, 8)Pbeta (x2 | 2, 6) dx2EP (x2 |x,a1 ) fbeta (x2 ) =(Proposition 3)=x2(15 + 8) (2 + 6) (15 + 2 1)(8 + 6 1)(15)(8) (2)(6) (15 + 2 + 8 + 6 2)0.22ZPbeta (x2 | 15, 8)1[0.3,0.5] (x2 )(5x2 1.5) dx2 +EP (x2 |x,a1 ) fpwl (x2 ) =(Corollary 1)=x2Zx2(Proposition 4)Pbeta (x2 | 15, 8)1[0.5,0.7] (x2 )(5x2 + 3.5) dx215(F + (0.5) F + (0.3)) 1.5(F (0.5) F (0.3))15 + 815(F + (0.7) F + (0.5)) + 3.5(F (0.7) F (0.5))515 + 80.30= 5F (u) = Fbeta (u | 15, 8) F + (u) = Fbeta (u | 15+1, 8) denote cumulative densityfunctions beta distributions. graphical interpretation computations presentedFigure 5. Brief inspection verifies term EP (x2 |x,a1 ) [fpwl (x2 )] indeed largestone.point, obtained efficient closed-form solutions factored basis functionsstate relevance densities. Unfortunately, factorization assumptions Equations 20, 21,22 rarely justified practice. rest section, show relax them.Section 6, apply current results propose several methods approximatelysatisfy constraint space HALP.5.2.1 Factored State Relevance Density FunctionsNote state relevance density function (x) unlikely completely factored(Section 5.1). Therefore, independence assumption Equation 20 extremelyP limiting.relax assumption, approximate (x)Q linear combination (x) = (x)factored state relevance densities (x) = ni=1 (xi ). result, expectation termsobjective function decompose as:E (x) [fi (x)] = EP (x) [fi (x)]XE (x) [fi (x)] ,=173(26)fiKveton, Hauskrecht, & Guestrinfactored terms E (x) [fi (x)] evaluated efficiently (Equation 23). Moreover,assume factored densities (x) polynomials, linear combination (x)polynomial. Due Weierstrass approximation theorem (Jeffreys & Jeffreys, 1988),polynomial sufficient approximate state relevance density (x) precision.follows linear combinations permit state relevance densities reflect arbitrarydependencies among state variables X.5.2.2 Factored Basis FunctionsPline previous discussion, note linear value function V w (x) = wi fi (x)factored basis functions (Equations 21 22) sufficient approximate optimalvalue function V within max-norm error kV V w k . Based Theoremknow2, weweset basis functions guarantees bound L1 -norm error V V 1, .Therefore, despite independence assumptions (Equations 21 22), potentialeobtain arbitrarily close HALP approximation V wV .6. Constraint Space Approximationse HALP formulation (16) determined finite set activeoptimal solution wconstraints vertex feasible region. Unfortunately, identification active sethard computational problem. particular, requires searching exponentialnumber constraints, state action variables discrete, infinite numberconstraints, variables continuous. result, general infeasiblee HALP formulation. Hence, resort approximationsfind optimal solution wb close w.e notionconstraint space HALP whose optimal solution wapproximation formalized follows.Definition 2 HALP formulation relaxed:Xwiminimizew(27)subject to:Xwi Fi (x, a) R(x, a) 0(x, a) C;subset C constraints satisfied.HALP formulation (16) solved approximately solving relaxed formulations(27). Several methods building solving approximate LPs proposed:Monte Carlo sampling constraints, (Hauskrecht & Kveton, 2004), -grid discretizationconstraint space (Guestrin et al., 2004), adaptive search violated constraint(Kveton & Hauskrecht, 2005). remainder section, introduce methods.on, denote optimal solutions complete relaxed HALP formulationse w,b respectively.symbols weproceed, note V wupper bound optimal value functionbV (Figure 6a), relaxed value function V w(Figure 6b). reasonbbrelaxed HALP formulation guarantee constraint V wV wbwsatisfied states x. result, cannot simply use Proposition 1 prove V V .174fiSolving Factored MDPs Hybrid State Action VariableseVwV011X10 01bVwV011X1X2e wbwObjective value1bV VwValue functionValue functioneV Vw(a)0 0X21ewbw011w10 0(b)w2(c)Figure 6: a. Graphical relation value function V HALP approximationeeVw. function V wguaranteed upper bound V . b. relaxedbHALP approximation V wmay lead upper bound. c. Graphical relatione w.b feasible regionsoptimal relaxed solutions wcomplete relaxed HALP formulations shown dark light gray colors.ebvalue function approximations V wV wtypically nonlinear statespace X always linear space parameters w.beFurthermore, note inequality E V wE V walways holds optimale feasible relaxed HALP (Figure 6c). observations become helpfulsolution wunderstanding rest section.6.1 MC-HALPsimplest case, constraint space HALP approximated Monte Carlo(MC) sample. relaxation, set constraints C selected respectproposal distribution state-action pairs (x, a). Since set C finite, establishesrelaxed formulation (27), solved LP solver. algorithm buildssatisfies relaxed MC-HALP formulations outlined Figure 7.Constraint sampling easily applied continuous domains space complexityproportional number state action components. Hauskrecht Kveton (2004)used solve continuous-state factored MDPs refined heuristics (Kveton& Hauskrecht, 2004). discrete-state domains, quality sampled approximationsanalyzed de Farias Van Roy (2004). result summarized Theorem 5.e solution ALP formulationTheorem 5 (de Farias & Van Roy, 2004) Let wb solution relaxed formulation whose constraints sampled respect(6) wproposal distribution state-action pairs (x, a). exist distributionsample size:N(1 )K ln1751+ ln(1 )fiKveton, Hauskrecht, & GuestrinInputs:hybrid factored MDP = (X, A, P, R)basis functions f0 (x), f1 (x), f2 (x), . . .proposal distributionAlgorithm:initialize relaxed HALP formulation empty set constraintst=0stopping criterion metsample (x, a)add constraint (x, a) relaxed HALPt=t+1solve relaxed MC-HALP formulationOutputs:basis function weights wFigure 7: Pseudo-code implementation MC-HALP solver.probability least 1 :ebV V wV V w1,1,+ kV k1, ,kk1, L1 -norm weighted state relevance weights , problem-specificconstant, K denote numbers actions basis functions, scalarsinterval (0, 1).Unfortunately, proposing sampling distribution guarantees polynomial boundsample size hard knowing optimal policy (de Farias & Van Roy, 2004).conclusion parallel importance sampling. Note uniform Monte Carlosampling guarantee low probability constraints violated sufficientbound magnitude violation (de Farias & Van Roy, 2004).6.2 -HALPAnother way approximating constraint space HALP discretizing continuousvariables XC AC uniform -grid. new discretized constraint space preservesoriginal factored structure spans discrete variables only. Therefore, compactlysatisfied methods discrete-state ALP (Section 3.3). algorithm buildssatisfies relaxed -HALP formulations outlined Figure 8. Note new constraintspace involves exponentially many constraints O(1/ + 1|XC |+|AC | ) number stateaction variables XC AC .6.2.1 Error BoundsRecall -HALP formulation approximates constraint space HALP finiteset equally-spaced grid points. section, study quality approximation176fiSolving Factored MDPs Hybrid State Action VariablesInputs:hybrid factored MDP = (X, A, P, R)basis functions f0 (x), f1 (x), f2 (x), . . .grid resolutionAlgorithm:discretize continuous variables XC AC 1/ + 1 equally-spaced valuesidentify subsets Xi Ai (Xj Aj ) corresponding domains Fi (x, a) (Rj (x, a))evaluate Fi (xi , ai ) (Rj (xj , aj )) configurations xi ai (xj aj ) -gridcalculate basis function relevance weightssolve relaxed -HALP formulation (Section 3.3)Outputs:basis function weights wFigure 8: Pseudo-code implementation -HALP solver.bound terms violating constraints complete HALP. precisely, proveb violates constraints complete HALP smallrelaxed HALP solution wbeamount, quality approximation V wclose V w. next section, extendbwresult relate V grid resolution . proceed, quantify notionconstraint violation.b optimal solution relaxed HALP formulation (27). vectorDefinition 3 Let wb -infeasible if:wbbVwV w,(28)hybrid Bellman operator.b closer qualityIntuitively, lower -infeasibility relaxed HALP solution w,beapproximation V wV w. Proposition 5 states intuition formally. particular,bsays relaxed HALP formulation leads close approximation V woptimalb violates constraintsvalue function V complete HALP solution wsmall amount.e optimal solution HALP formulation (16) wbProposition 5 Let woptimal -infeasible solution relaxed formulation (27). expected errorbvalue function V wbounded as:2be,V V wV V w+11,1,kk1, L1 -norm weighted state relevance density function .Based Proposition 5, generalize conclusions Section 5.1 relaxed HALPformulations.instance, may draw parallel optimizing relaxed objectivebE V wmax-norm error kV V w k,1/L .177fiKveton, Hauskrecht, & Guestrinb optimal -infeasible solution relaxed HALP formulation (27).Theorem 6 Let wbexpected error value function V wbounded as:bV V w1,2E [L]2min kV V w k,1/L +,w11Pkk1, L1 -norm weighted state relevance density , L(x) = wiL fi (x)Lyapunov function inequality L(x) supa EP (x |x,a) [L(x )] holds, [0, 1)denotes contraction factor, kk,1/L max-norm reweighted reciprocal 1/L.Proof: Direct combination Theorem 3 Proposition 5.6.2.2 Grid ResolutionSection 6.2.1, bounded error relaxed HALP formulation -infeasibility(Theorem 6), measure constraint violation complete HALP. However, uncleargrid resolution relates -infeasibility. section, analyze relationship. Moreover, show exploit factored structure constraintb efficiently.space achieve -infeasibility relaxed HALP solution wb optimal -infeasible solution -HALP formulationFirst, let us assume wZ = XA joint set state action variables. derive boundP relatingbwbi Fi (z) R(z), assume magnitudes constraint violations (z) = wLipschitz continuous.Definition 4 function f (x) Lipschitz continuous if:f (x) f (x ) K x xx, x X;(29)K referred Lipschitz constant.Based -grid discretization constraint space, know distancepoint z closest grid point zG = arg minz kz z k bounded as:kz zG k < .2(30)bLipschitz continuity w(z), conclude:Kwb.(z) K kzG zkb (zG ) w2(31)bSince every constraint relaxed -HALP formulation satisfied, w(zG ) nonnegativebgrid points zG . result, Equation 31 yields w(z) > K/2 every state-actionb -infeasible K/2.pair z = (x, a). Therefore, based Definition 3, solution wb guaranteed choosing 2/K.Conversely, -infeasibility wUnfortunately, K may increase rapidly dimensionality function. addressissue, use structure constraint space demonstratecase. First, observe global Lipschitz constant Kglob additive local Lipschitzconstants correspond terms wbi Fi (z) Rj (z). Moreover, Kglob N Kloc ,178fiSolving Factored MDPs Hybrid State Action VariablesInputs:hybrid factored MDP = (X, A, P, R)basis functions f0 (x), f1 (x), f2 (x), . . .initial basis function weights w(0)separation oracleAlgorithm:initialize relaxed HALP formulation empty set constraintst=0stopping criterion metquery oracle violated constraint (xO , aO ) respect w(t)constraint (xO , aO ) violatedadd constraint relaxed HALPresolve LP new vector w(t+1)t=t+1Outputs:basis function weights w(t)Figure 9: Pseudo-code implementation HALP solver cutting plane method.N denotes total number terms Kloc maximum local constants.b achievedFinally, parallel Equation 31, -infeasibility relaxed HALP solution wdiscretization:22.N KlocKglob(32)Since factors wbi Fi (z) Rj (z) often restricted small subsets state actionvariables, Kloc change little size problem increases structurefixed. prove Kloc bounded, bound weights wbi . basis functionsunit magnitude, weights wbi intuitively bounded |wbi | (1)1 Rmax ,Rmax denotes maximum one-step reward HMDP.Based Equation 32, conclude number discretization points singledimension 1/ + 1 bounded polynomial N , Kloc , 1/. Hence, constraintspace relaxed -HALP formulation involves O([N Kloc (1/)]|X|+|A| ) constraints,|X| |A| denote number state action variables. idea variable eliminationused write constraints compactly O([N Kloc (1/)]T +1 (|X|+|A|)) constraints(Example 3), treewidth corresponding cost network. Therefore, satisfyingconstraint space polynomial N , Kloc , 1/, |X|, |A|, still exponential .6.3 Cutting Plane MethodMC -HALP formulations (Sections 6.1 6.2) approximate constraint spaceHALP finite set constraints C. Therefore, solved directly linearprogramming solver. However, number constraints large, formulating solving179fiKveton, Hauskrecht, & GuestrinInputs:hybrid factored MDP = (X, A, P, R)basis functions f0 (x), f1 (x), f2 (x), . . .basis function weights wgrid resolutionAlgorithm:discretize continuous variables XC AC (1/ + 1) equally-spaced valuesidentify subsets Xi Ai (Xj Aj ) corresponding domains Fi (x, a) (Rj (x, a))evaluate Fi (xi , ai ) (Rj (xj , aj )) configurations xi ai (xj aj ) -gridbuild cost networkP factored cost function:w (x, a) = wi Fi (x, a) R(x, a)find violated constraint cost network:(xO , aO ) = arg minx,a w (x, a)Outputs:state-action pair (xO , aO )Figure 10: Pseudo-code implementation -HALP separation oracle .LPs complete set constraints infeasible. section, show buildrelaxed HALP approximations efficiently cutting plane method.cutting plane method solving HALP formulations outlined Figure 9. Briefly,approach builds set LP constraints incrementally adding violated constraintset every step. remainder paper, refer method returnsb separation oracle. Formally, every HALPviolated constraint arbitrary vector woracle approaches optimization problem:hhbbarg min V w(x) EP (x |x,a) V w(x ) R(x, a) .(33)x,aConsequently, problem solving hybrid factored MDPs efficiently reduces designefficient separation oracles. Note cutting plane method (Figure 9) appliedsuboptimal solutions Equation 33 correspond violated constraints.presented approach directly used satisfy constraints relaxed -HALPformulations (Schuurmans & Patrascu, 2002). Briefly, solver Figure 9 iteratesviolated constraint found -HALP separation oracle (Figure 10) returnsviolated constraint discretized cost network given intermediate solution w(t) .Note although search violated constraint polynomial |X| |A|(Section 6.2.2), running time solver (Guestrin, 2003). fact,number generated cuts exponential |X| |A| worst case. However,oracle embedded ellipsoid method (Khachiyan, 1979) yields polynomial-timealgorithm (Bertsimas & Tsitsiklis, 1997). Although technique impractical solvinglarge LPs, may conclude approach indeed polynomial-time implementedparticular way.Finally, note searching violated constraint (Equation 33) application beyond satisfying constraint space HALP. instance, computation greedy180fiSolving Factored MDPs Hybrid State Action Variablesbpolicy value function V w:hiihbu(x) = arg max R(x, a) + EP (x |x,a) V w(x )hiihb= arg min R(x, a) EP (x |x,a) V w(x )(34)almost identical optimization problem, state variables X fixed. Moreover,magnitude violated constraint equal lowest relaxedb -infeasible (Equation 28):HALP solution whhhiiibb= min V w(x) max R(x, a) + EP (x |x,a) V w(x )xhiihbb= min V w(x) R(x, a) EP (x |x,a) V w(x ) .(35)x,a6.4 MCMC-HALPpractice, MC -HALP formulations (Sections 6.1 6.2) built blindlyselected set constraints C. specifically, constraints MC-HALP formulationchosen randomly (with respect prior distribution ) -HALP formulationbased uniform -grid. discretized constraint space preserves original factoredstructure, allows compact satisfaction. However, complexity solving-HALP formulation exponential treewidth discretized constraint space. Notediscretized constraint space represented binary variables only, treewidthincreases multiplicative factor log2 1/ + 1, 1/ + 1 denotes numberdiscretization points single dimension. Consequently, even treewidth problemrelatively small, solving -HALP formulation becomes intractable small values .address issues discussed approximations (Sections 6.1 6.2), proposenovel Markov chain Monte Carlo (MCMC) method finding violated constraintrelaxed HALP. procedure directly operates domains continuous variables,takes account structure factored MDPs, space complexity proportionalnumber variables. separation oracle easily embedded ellipsoidcutting plane method solving linear programs (Section 6.3), therefore constituteskey step towards solving HALP efficiently. proceed, represent constraintspace HALP compactly state optimization problem finding violated constraintsfactored representation.6.4.1 Compact Representation ConstraintsSection 3.3, showed factored representation constraint space allowscompact satisfaction. Following idea, define violation magnitude w (x, a):(36)w (x, a) = V w (x) EP (x |x,a) V w (x ) R(x, a)X=wi [fi (x) gi (x, a)] + R(x, a),measures amount solution w violates constraints completeHALP. represent magnitude violation w (x, a) compactly influence diagram181fiKveton, Hauskrecht, & Guestrin(ID), X decision nodes, X random variables. representationbuilt transition model P (X | X, A), factored captures independenciesamong variables X, X , A. extend diagram three types reward nodes,one term Equation 36: Hi = wi fi (x) every basis function, Gi = wi fi (x )every backprojection, Rj = Rj (xj , aj ) every local reward function. constructioncompleted adding arcs graphically represent dependencies reward nodesvariables. Finally, verify that:XXw (x, a) = EP (x |x,a) (Hi + Gi ) +Rj .(37)jConsequently, decision maximizes expected utility ID correspondsviolated constraint. graphical representation violation magnitude w (x, a)4-ring network administration problem (Example 4) given Figure 2a. structureconstraint space identical Example 3 basis functions univariate.conclude algorithm solving IDs applied find violatedconstraint. However, methods (Cooper, 1988; Jensen et al., 1994; Ortiz, 2002)restricted discrete variables. Fortunately, special properties ID representationallow simplification. basis functions chosen conjugate transitionmodel (Section 5.2), obtain closed-form solution expectation term EP (x |x,a) [Gi ](Equation 18), random variables X marginalized diagram. newrepresentation contains random variables known cost network (Section 3.3).Note problem finding violated constraint ID representationalso identical finding maximum posteriori (MAP) configuration random variablesBayesian networks (Dechter, 1996; Park & Darwiche, 2001, 2003; Yuan et al., 2004).latter problem difficult alternating summation maximization operators.Since marginalized random variables X , solve maximization problemstandard large-scale optimization techniques.6.4.2 Separation Oracle OMCMCfind violated constraint cost network, apply Metropolis-Hastings(MH) algorithm (Metropolis et al., 1953; Hastings, 1970) propose Markov chain whoseinvariant distribution converges vicinity arg maxz w (z), z = (x, a) valueassignment joint set state action variables Z = X A.short, Metropolis-Hastings algorithm defines Markov chain transitsexisting state z proposed state z acceptance probability:p(z )q(z | z )A(z, z ) = min 1,,(38)p(z)q(z | z)q(z | z) p(z) proposal distribution target density, respectively.mild restrictions p(z) q(z | z), frequency state visits generated Markovchain always converges target function p(z) (Andrieu et al., 2003). remaindersection, discuss choices p(z) q(z | z) solve optimization problem.55. introduction Markov chain Monte Carlo (MCMC) methods, refer work Andrieu et al.(2003).182fiSolving Factored MDPs Hybrid State Action VariablesTarget density: violation magnitude w (z) turned density transformation p(z) = exp[ w (z)]. Due monotonic character, p(z) retains set globalmaxima w (z). Therefore, search arg maxz w (z)PcanRbe done new functionp(z). prove p(z) density, demonstrate zD zC p(z) dzC normalizingconstant, zD zC discrete continuous parts value assignment z.|ZC | . result, integralRFirst, note integrand zC restricted space [0, 1]zC p(z) dzC proper p(z) bounded, hence Riemann integrable finite.prove p(z) = exp[ w (z)] bounded, bound magnitude violation w (z).basis functions unit magnitude, weights wbi bounded |wbi | (1)1 Rmaxw1(Section 6.2.2), turn yields bound | (z)| (|w| (1) +1)Rmax . Therefore,p(z) bounded treated density function.find mode p(z), employ simulating annealing (Kirkpatrick et al., 1983)generate non-homogeneous Markov chain whose invariant distribution equal p1/Tt (z),Tt cooling schedule limt Tt = 0. weak regularity assumptionsp(z), p (z) probability density concentrates set global maximap(z) (Andrieu et al., 2003). cooling schedule Tt decreases Tt c/ ln(t + 1),c problem-specific constant, chain Equation 38 converges vicinityarg maxz w (z) probability converging 1 (Geman & Geman, 1984). However,logarithmic cooling schedule slow practice, especially high initial temperaturec. overcome problem, select smaller value c (Geman & Geman, 1984)required convergence criterion. Therefore, convergence chain globaloptimum arg maxz w (z) longer guaranteed.Proposal distribution: take advantage factored character Z adoptfollowing proposal distribution (Geman & Geman, 1984):q(z | z) =p(zi | zi ) zi = zi,0otherwise(39)zi zi value assignments variables Zi original proposedstates. Zi discrete variable, conditional:p(z1 , . . . , zi1 , zi , zi+1 , . . . , zn+m )p(zi | zi ) = Pzi p(z1 , . . . , zi1 , zi , zi+1 , . . . , zn+m )(40)derived closed form. Zi continuous variable, closed form cumulativedensity function unlikely exist. sample conditional, embed another MHstep within original chain. experimental section, use Metropolis algorithmacceptance probability:p(zi | zi ),A(zi , zi ) = min 1,p(zi | zi )(41)zi zi original proposed values variable Zi . Note samplingconditionals performed space w (z) locally.183fiKveton, Hauskrecht, & GuestrinInputs:hybrid factored MDP = (X, A, P, R)basis functions f0 (x), f1 (x), f2 (x), . . .basis function weights wAlgorithm:initialize state-action pair z(t)t=0stopping criterion metevery variable Zisample u U[0,1](t)sample zi| zi )p(Z1/T1 (z |z(t) )pu < min 1, 1/Tt 1 (t)(t)(zi |zi )p(t+1)zi= zielse(t+1)(t)zi= ziupdate Tt+1 according cooling schedulet=t+1(xO , aO ) = z(t)Outputs:state-action pair (xO , aO )Figure 11: Pseudo-code implementation MCMC-HALP oracle OMCMC . symbolU[0,1] denotes uniform distribution interval [0, 1]. Since testingviolated constraints (Figure 9) inexpensive, implementation MCMCHALP solver Section 7 tests constraints z(t) generated Markov chainlast one. Therefore, separation oracle OMCMC returnsone constraint per chain.Finally, assuming zi = zi (Equation 39), derive non-homogenous Markovchain acceptance probability:A(z, z ) ====()p1/Tt (z )q(z | z )min 1, 1/Tp (z)q(z | z)(p1/Tt (z | zi )p1/Tt (zi )p(zimin 1, 1/Tp (zi | zi )p1/Tt (zi )p(zi(p1/Tt (z | zi )p1/Tt (zi )p(zimin 1, 1/Tp (zi | zi )p1/Tt (zi )p(zi)(p1/Tt 1 (zi | zi ),min 1, 1/T 1p (zi | zi )184| zi )| zi )| zi )| zi )))(42)fiSolving Factored MDPs Hybrid State Action Variablesconverges vicinity violated constraint. Yuan et al. (2004) proposedsimilar chain finding MAP configuration random variables Bayesian networks.6.4.3 Constraint SatisfactionMCMC-HALP separation oracle OMCMC (Figure 11) converges violated constraint(not necessarily violated) polynomial time, ellipsoid method guaranteedsolve HALP formulations polynomial time (Bertsimas & Tsitsiklis, 1997). Unfortunately,convergence chain within arbitrary precision requires exponential number steps(Geman & Geman, 1984). Although bound loose practical interest, suggeststime complexity proposing violated constraints dominates time complexitysolving relaxed HALP formulations. Therefore, oracle OMCMC search violatedconstraints efficiently. Convergence speedups directly apply work include hybridMonte Carlo (HMC) (Duane et al., 1987), Rao-Blackwellization (Casella & Robert, 1996),slice sampling (Higdon, 1998).7. ExperimentsExperimental section divided three parts. First, show HALP solve simpleHMDP problem least efficiently alternative approaches. Second, demonstratescale-up potential framework compare several approaches satisfy constraintspace HALP (Section 6). Finally, argue solving constraint satisfaction problemdomains continuous variables without discretizing them.experiments performed Dell Precision 380 workstation 3.2GHz Pentium4 CPU 2GB RAM. Linear programs solved simplex method LP SOLVEpackage. expected return policies estimated Monte Carlo simulation 100trajectories. results randomized methods additionally averaged 10 randomlyinitialized runs. Whenever necessary, present errors expected values. errorscorrespond standard deviations measured quantities. discount factor 0.95.7.1 Simple Exampleillustrate ability HALP solve factored MDPs, compare L2 (Figure 4)grid-based value iteration (Section 4.2) 4-ring topology network administrationproblem (Example 4). experiments conducted uniform non-uniform gridsvarying sizes. Grid points kept fixed compared methods, allows faircomparison. value iteration methods iterated 100 steps terminated earlierBellman error drops 106 . L2 HALP methods approximateoptimal value function V linear combination basis functions, one computerXi (fi (x) = xi ), one every connection Xi Xj ring topology (fij (x) = xi xj ).assume basis functions sufficient derive one-step lookahead policyreboots least efficient computer. believe policy close-to-optimalring topology. constraint space complete HALP formulation approximatedMC-HALP -HALP formulations (Sections 6.1 6.2). state relevance densityfunction (x) uniform. experimental results reported Figure 12.185fiKveton, Hauskrecht, & GuestrinN891625561-HALPReward Time52.1 2.2<152.1 2.2<152.1 2.2<152.1 2.22Uniform -gridL2 VIReward Time52.1 2.2252.1 2.2752.1 2.25552.1 2.257747.6 2.2<151.5 2.22052.0 2.3 2 216N10502501 250MC-HALPReward Time45.2 5.1<150.2 2.4<151.5 2.4<151.8 2.3<1Non-uniform gridL2 VIReward Time45.9 5.8151.8 2.2451.9 2.22251.9 2.2110Grid-based VIReward Time47.5 2.8<148.7 2.5<150.4 2.3251.6 2.26011/21/41/8 6HeuristicsPolicyRewardDummy 25.0 2.8Random 42.1 3.3Server47.6 2.2Utopian 83.0Grid-based VIReward TimeFigure 12: Comparison three approaches solving hybrid MDPs 4-ring topologynetwork administration problem (Example 4). methods compareduniform non-uniform grids varying size (N ) expected discountedreward policies computation time (in seconds).verify solutions non-trivial, compare three heuristic policies:dummy, random, server. dummy policy dummy (x) = a5 always takes dummyaction a5 . Therefore, establishes lower bound performance administrator.random policy behaves randomly. server policy server (x) = a1 protects serverX1 . performance heuristics shown Figure 12. Assuming rebootcomputers time step, utopian upper bound performance policyderived as:"#X1ER(xt , (xt ))max R(x , )max E1 x,a P (x |x,a)t=0Z4X1=P (xj | x, a)x22P (x1 | x, a)x2+maxj dx11 x,a xj=2Z5Pbeta (x | 20, 2)x2 dx1 x83.0.(43)analyze quality HALP solutions respect optimal value functionV (Section 5.1) one unknown.Based results, draw following conclusions. First, grid-based value iterationpractical solving hybrid optimization problems even small size. main reasonspace complexity method, quadratic number grid points N .state space discretized uniformly, N exponential number state variables.Second, quality HALP policies close L2 VI policies. result positivesince L2 value iteration commonly applied approximate dynamic programming. Third,186fiSolving Factored MDPs Hybrid State Action VariablesL2 HALP approaches yield better policies grid-based value iteration.result due quality value function estimator. extremely good performance= 1 explained monotonicity reward basis functions. Finally,computation time L2 VI policies significantly longer computation timeHALP policies. Since step L2 value iteration (Figure 4) hard formulatingcorresponding relaxed HALP, result comes surprise.7.2 Scale-up Potentialillustrate scale-up potential HALP, apply three relaxed HALP approximations(Section 6) solve two irrigation network problems varying complexity. problemschallenging state-of-the-art MDP solvers due factored state action spaces.Example 6 (Irrigation network operator) irrigation network system irrigation channels connected regulation devices (Figure 13). goal irrigation networkoperator route water channels optimize water levels whole system.optimal levels determined type planted crop. simplicity exposition,assume irrigation channels oriented size.optimization problem formulated factored MDP. state networkcompletely observable represented n continuous variables X = {X1 , . . . , Xn },variable Xi denotes water level i-th channel. time step, irrigationnetwork operator regulates devices Ai pump water every pair inboundoutbound channels. operation modes devices described discrete actionvariables = {A1 , . . . , }. Inflow outflow devices (no inbound outbound channels)controlled pump water network.transition model reflects water flows irrigation network encoded locallyconditioning operation modes A:P (Xij= x | Par(Xij)) Pbeta (x | , )ij = ij +X= 46ij + 2= 46(1 ij ) + 21ahij (Ai ) min(1 ij , min(xhi , ))hij = xijX1aijk (Aj ) min(xij , j )kXij represents water level regulation devices Ai Aj , 1ahij (Ai )1aijk (Aj ) denote indicator functions water routing actions ahij aijkdevices Ai Aj , j highest tolerated flows devices.short, transition model conserves water mass network adds varianceresulting state Xij. introduced indexing state action variables explained6-ring irrigation network Figure 14a. rest paper, assume inflow0.1 inflow device Ai (i = 0.1), outflow 1 outflow device Aj (j = 1),highest tolerated flow 1/3P remaining devices Ak (k = 1/3).reward function R(x, a) = j Rj (xj ) factored along individual irrigation channelsdescribed univariate function:Rj (xj ) = 2xj187fiKveton, Hauskrecht, & Guestrin(a)(b)(c)Figure 13: Illustrations three irrigation network topologies: a. 6-ring, b. 6-ring-of-rings,c. 33 grid. Irrigation channels regulation devices representedarrows rectangles. Inflow outflow nodes colored light darkgray. ring ring-of-rings networks parameterized total numberregulation devices except last four (n).outflow channel (one regulation devices must outflow), function:Rj (xj ) =N (xj | 0.4, 0.025) N (xj | 0.55, 0.05)+25.632remaining channels (Figure 14b). Therefore, reward maintaining optimalwater levels pumping water irrigation network. Several examples irrigationnetwork topologies shown Figure 13.Similarly Equation 43, derive utopian upper bound performance policyarbitrary irrigation network as:#""X1R(xt , (xt ))E0.2nin + (n nout )1t=0#ZPbeta (x | 46x + 2, 46(1 x) + 2)R(x ) dx ,(44)maxxxn total number irrigation channels, nin nout denote number inflowoutflow channels, respectively, R(x ) = N (x | 0.4, 0.025)/25.6+N (x | 0.55, 0.05)/32.analyze quality HALP solutions respect optimal value functionV (Section 5.1) one unknown.rest section, illustrate performance three HALP approximations,MC-HALP, -HALP, MCMC-HALP (Section 6), ring ring-of-rings topologies(Figure 13) irrigation network problem. constraints MC-HALP formulationsampled uniformly random. establishes baseline HALP approximations.-HALP MCMC-HALP formulations generated iteratively cutting plane188fiSolving Factored MDPs Hybrid State Action Variablesfi (xi )0.6DensityRewardNonoutflow channel0.40.2000.5110.50.50100(a)DensityReward100.5Xj1(b)0.5010fi+2n (xi )Outflow channel2fi+n (xi )110.50.5000.5Xi0.51fi+3n (xi )0100.5Xi1(c)Figure 14: a. Indexing used description transition function Example 6.parameters h, i, j, k equal 6, 7, 10, 1, respectively. b. Univariatereward functions water levels Xj (Example 6). c. Univariate basis functionswater levels Xi .method. MCMC oracle OMCMC simulated 500 steps initial temperaturec = 0.2, leads decreasing cooling schedule T0 = 0.2 T500 0.02.parameters selected empirically demonstrate characteristics oracle OMCMCrather maximize performance. value function V approximated linearcombination four univariate piecewise linear basis functions channel (Figure 14c).assume basis functions sufficient derive one-step lookahead policyroutes water channels water levels high low (Figure 14b).believe policy close-to-optimal irrigation networks. state relevancedensity function (x) uniform. experimental results reported Figures 1517.Based results, draw following conclusions. First, HALP approximationsscale dimensionality solved problems. shown Figure 16, returnpolicies grows linearly n. Moreover, time complexity computing polynomialn. Therefore, problem approximate solution structured, take advantagestructure avoid exponential blowup computation time. time,quality policies deteriorating increasing problem size n.Second, MCMC solver (N = 250) achieves highest objective values solvedproblems. Higher objective values interpreted closer approximations constraintspace HALP since solvers operate relaxed formulations HALP. Third, qualityMCMC-HALP policies (N = 250) surpasses MC-HALP policies (N = 106 )solvers consume approximately computation time. result dueinformative search violated constraints MCMC-HALP solver. Fourth, qualityMCMC-HALP policies (N = 250) close -HALP policies ( = 1/16) althoughsignificant difference objective values. analysis showsshape value functions similar (Figure 17) differ weight189fiKveton, Hauskrecht, & GuestrinRingtopology-HALP 1/4=1/81/16MCMC10N=50250MC102N=104106UtopianOV24.355.459.160.970.170.716.240.851.2n=6n = 12Reward TimeOVReward34.6 2.011 36.2 53.9 2.739.6 2.541 88.1 61.5 3.540.3 2.6281 93.2 62.6 3.430.3 4.938 86.3 47.6 6.340.2 2.6194 110.3 62.4 3.540.2 2.6940 112.0 63.0 3.425.0 5.1< 1 16.9 41.9 5.637.9 2.810 52.8 58.8 3.539.4 2.7855 67.1 60.3 3.849.179.2Ring-of-ringstopology-HALP 1/4=1/81/16MCMC10N=50250MC102N=104106UtopianOV28.465.468.966.980.981.713.744.355.8n=6Reward40.4 2.547.5 3.047.0 2.935.3 6.147.1 2.947.2 2.931.0 4.943.3 3.245.1 3.159.1Time854954 417603091 522<1121 026OV44.1107.9113.194.6131.9134.115.459.075.1Time44107665623281 609<1181 415OV48.0118.8126.1109.5148.8151.717.263.881.1n = 18Reward74.3 2.984.3 3.886.3 3.856.8 7.485.0 3.685.4 3.851.8 8.875.9 6.682.9 3.8109.2Time871781 119874832 280<1311 938n = 12n = 18Reward TimeOVReward Time66.5 3.2382 59.8 93.0 3.893176.1 4.1 2 379 148.8 105.3 4.2 5 87777.3 4.2 19 794 156.9 107.8 4.1 53 65554.4 9.4107 110.6 47.8 13.215776.6 3.6571 181.4 104.6 4.485977.3 3.5 2 800 186.0 106.6 3.9 4 29146.1 6.4< 1 16.8 66.6 9.4168.9 5.426 71.5 92.2 6.84974.3 3.8 1 738 92.0 103.1 4.2 2 53999.2139.3Figure 15: Comparison three HALP solvers two irrigation network topologies varying sizes (n). solvers compared objective value relaxed HALP(OV), expected discounted reward corresponding policy, computation time (in seconds). -HALP, MCMC-HALP, MC-HALP solversparameterized resolution -grid (), number MCMC chains (N ),number samples (N ). Note quality policies improveshigher grid resolution (1/) larger sample size (N ). Upper boundsexpected returns shown last rows tables.constant basis function f0 (x) 1. Note increasing w0 affect qualitygreedy policy V w . However, trick allows satisfaction constraint spaceHALP (Section 5.1).Finally, computation time -HALP solver seriously affected topologiesirrigation networks, explained follows. small large n,time complexity formulating cost networks ring ring-of-rings topologies growsrates 1/ + 12 1/ + 13 , respectively. Since -HALP method consumessignificant amount time constructing cost networks, quadratic (in 1/ + 1) timecomplexity ring topology worsens cubic (in 1/ + 1) ring-of-rings topology.hand, similar cross-topology comparison MCMC-HALP solver showscomputation times differ multiplicative factor 2. difference due190fiSolving Factored MDPs Hybrid State Action VariablesRing topologyHALPReward125100MCMC125f(n) = 3.823n + cR2 = 1.000100125f(n) = 3.766n + cR2 = 1.0001007575755050506912151810.75TimeMC0.591215181f(n) = 0.019n + cR2 = 0.9980.750.50.2506912n15180691215181518151815181f(n) = 0.031n + cR2 = 0.9990.750.50.256f(n) = 3.594n + cR2 = 0.999f(n) = 0.025n + cR2 = 0.9990.256912n151806912nRing-of-rings topologyHALPReward125100MCMC125f(n) = 5.092n + cR2 = 1.00010075912151824Time10050691215182f(n) = 0.002n3 + cR2 = 0.9971.5160.5006912n1518f(n) = 4.838n + cR2 = 1.0007550612f(n) = 4.964n + cR2 = 1.000755018MC12569122f(n) = 0.064n + cR2 = 0.9981.51f(n) = 0.035n + cR2 = 0.9980.56912n151806912nFigure 16: Scale-up potential -HALP, MCMC-HALP, MC-HALP solvers twoirrigation network topologies varying sizes (n). graphs show expecteddiscounted reward policies computation time (in hours) functionsn. HALP solvers parameterized resolution -grid ( = 1/16),number MCMC chains (N = 250), number samples (N = 106 ).Note trends approximated polynomial f (n) (gray line)high degree confidence (the coefficient determination R2 ), c denotesconstant independent n.increased complexity sampling p(zi | zi ), results complex localdependencies ring-of-rings topology treewidth.proceed, note relaxed formulations (Figure 15) significantly lessconstraints complete sets (Section 6.3). instance, MC-HALP formulation(N = 106 ) 6-ring irrigation network problem originally established 106 randomlysampled constraints. Based empirical results, constraints satisfied greedily191fiKveton, Hauskrecht, & GuestrinMCHALP MCMCHALPHALPb (x)|wbwbwbwbwbwbwbwbwbVwX1 V (x)| X2 V (x)| X3 V (x)| X4 V (x)| X5 V (x)| X6 V (x)| X7 V (x)| X8 V (x)| X9 V (x)| X102102102100 0.5 1 0 0.5 1 0 0.5 1 0 0.5 1 0 0.5 1 0 0.5 1 0 0.5 1 0 0.5 1 0 0.5 1 0 0.5 1X1X2X3X4X5X6X7X8X9X10bFigure 17: Univariate projections V w(x)|Xj =bwPi:Xj =Xiwbi fi (xi ) approximate value func-tions V 6-ring irrigation network problem (Figure 13a). functionslearned 40 basis functions (Figure 14c) -HALP, MCMC-HALP,MC-HALP solvers. solvers parameterized resolution -grid( = 1/16), number MCMC chains (N = 250), number samplesb(N = 106 ). Note univariate projections V w(x)|Xj similar.proximity greedy policies explained based observation.-HALPOVReward Time1 30.4 48.3 3.091/2 42.9 58.7 3.13421/4 49.1 61.9 3.1 9 443MCMCNOVReward Time10 45.3 43.6 6.58350 116.2 72.2 3.6458250 118.5 73.2 3.7 2 012MCN OVReward Time102 12.8 56.6 4.5<1104 49.9 53.4 5.919106 71.7 70.3 3.9 1 400Figure 18: Comparison three HALP solvers 3 3 grid irrigation network problem(Figure 13). solvers compared objective value relaxed HALP(OV), expected discounted reward corresponding policy, computation time (in seconds). -HALP, MCMC-HALP, MC-HALP solversparameterized resolution -grid (), number MCMC chains (N ),number samples (N ). Note quality policies improveshigher grid resolution (1/) larger sample size (N ). upper boundexpected returns 87.2.subset 400 constraints average (Kveton & Hauskrecht, 2004). Similarly, oracleOMCMC MCMC-HALP formulation (N = 250) iterates 250500(10+10) =2, 500, 000 state-action configurations (Figure 11). However, corresponding LP formulationsinvolve 700 constraints average.7.3 Curse Treewidthring ring-of-rings topologies, treewidth constraint space (in continuousvariables) 2 3, respectively. result, oracle perform variable elimination192fiSolving Factored MDPs Hybrid State Action Variablessmall , -HALP solver returns close-to-optimal policies. Unfortunately, smalltreewidth atypical real-world domains. instance, treewidth complex3 3 grid irrigation network (Figure 13c) 6. perform variable elimination = 1/16,separation oracle requires space 1/ + 17 228 , memory limitexisting PCs. analyze behavior separation oracles (Section 6) setting,repeat experiments Section 7.2 3 3 grid irrigation network.Based results Figure 18, conclude time complexity -HALPsolver grows rate 1/ + 17 . Therefore, approximate constraint space satisfaction(MC-HALP MCMC-HALP) generates better results combinatorial optimizationinsufficiently discretized -grid (-HALP). conclusion parallel largestructured optimization problems continuous variables. believe combinationexact approximate steps delivers best tradeoff quality complexitysolutions (Section 6.4).8. ConclusionsDevelopment scalable algorithms solving real-world decision problems challengingtask. paper, presented theoretically sound framework allows compactrepresentation efficient solutions hybrid factored MDPs. believe resultsapplied variety optimization problems robotics, manufacturing, financialmathematics. work extended several interesting directions.First, note concept closed-form solutions expectations terms HALPlimited choices Section 5.2. instance, show P (x) f (x)normal densities, EP (x) [f (x)] closed-form solution (Kveton & Hauskrecht, 2006b).Therefore, directly reason normal transition functions instead approximatingmixture beta distributions. Similar conclusions true piecewise constant,piecewise linear, gamma transition basis functions. Note efficient solutionsapply approach solving hybrid factored MDPs approximates optimal valuefunction linear combination basis functions (Equation 5).Second, constraint space HALP (16) V w V w 0 exhibits structureconstraint space approximate policy iteration (API) (Guestrin et al., 2001; Patrascuet al., 2002) kV w V w k , variable subject minimization. result,work provides recipe solving API formulations hybrid state action domains.discrete-state spaces, Patrascu et al. (2002) Guestrin (2003) showed API returnsbetter policies ALP set basis functions. Note API complexALP every step API involves satisfying constraint kV w V w kfixed .Third, automatic learning basis functions seems critical application HALPreal-world domains. Patrascu et al. (2002) analyzed problem discrete-state spacesproposed greedy approach learning basis functions. Kveton Hauskrecht (2006a)generalized ideas showed learn parametric basis functions hybrid spaces.believe combination greedy search state space analysis (Mahadevan,2005; Mahadevan & Maggioni, 2006) yield even better basis functions.Finally, proposed several bounds (Section 5.1 6.2.1) may explain qualitycomplete relaxed HALP formulations. future, plan empirically evaluate193fiKveton, Hauskrecht, & Guestrintightness variety low-dimensional hybrid optimization problems (Bresina et al.,2002; Munos & Moore, 2002) known optimal value functions.Acknowledgmentwork supported part National Science Foundation grants CMS-0416754ANI-0325353. first author supported Andrew Mellon Predoctoral Fellowshipsacademic years 2004-06. first author also recognizes support Intel Corporationsummer 2005 2006.Appendix A. ProofsProof Proposition 1: Bellman operator known contraction mapping.Based monotonicity, value function V , V V implies V V V .eeeSince constraints HALP formulation (16) enforce V wV w, conclude V wV .Proof Proposition 2: Based Proposition 1, note constraint V w V wguarantees V w V . Subsequently, claim proved realizing:arg min E [V w ] = arg min E [V w V ]wwE [V w V ] = E |V w V |= E |V V w |= kV V w k1, .proof generalizes discrete-state case (de Farias & Van Roy, 2003) withoutalternations.Proof Theorem 2: Similarly Theorem 2 (de Farias & Van Roy, 2003), claimproved three steps. First, find point w feasible region HALPV w within O() distance V w , where:w = arg min kV V w kw= V V w .point w given by:w = w +(1 + )e,1e = (1, 0, . . . , 0) indicator constant basis function f0 (x) 1. pointsatisfies requirements feasibility handily verified solving:(1 + )(1 + )wwwwV V= V+V+11= V w V w + (1 + )0,194fiSolving Factored MDPs Hybrid State Action Variableslast step follows inequality:wwwwV + V VV VVww= V V + V V(1 + ).Subsequently, bound max-norm error V w using triangle inequality:wwwV V w+VVVV1+= 1+12,=1eyields bound weighted L1 -norm error V w:eV V w 1,V V w1,V V w2.1proof generalizes discrete-state case (de Farias & Van Roy, 2003) withoutalternations.Proof Theorem 3: Similarly Theorem 2, claim proved three steps: findingpoint w feasible region HALP, bounding max-norm error V w ,eturn yields bound L1 -norm error V w. comprehensive proof discretestate case done de Farias Van Roy (2003). proof generalizes structuredstate action spaces continuous variables.Proof Proposition 3: proposition proved sequence steps:ZPbeta (x | , )xn (1 x)m dxEP (x) [f (x)] =Zx( + ) 1x(1 x)1 xn (1 x)m dx=()()xZ( + )=x+n1 (1 x)+m1 dx()() xZ( + ) ( + n)( + m)( + + n + m) +n1=x(1 x)+m1 dx()() ( + + n + m) x ( + n)( + m)Z( + ) ( + n)( + m)=Pbeta (x | + n, + m) dx .()() ( + + n + m) x{z}|1195fiKveton, Hauskrecht, & GuestrinSince integration distributive operation, claim straightforwardly generalizesmixture beta distributions P (x).Proof Proposition 4: proposition proved sequence steps:ZXPbeta (x | , )1[li ,ri ] (x)(ai x + bi ) dxEP (x) [f (x)] =x=XZriPbeta (x | , )(ai x + bi ) dxliX Z=aiXai=Xai=riPbeta (x | , )x dx + bili+ZZriliriPbeta (x | , ) dxPbeta (x | + 1, ) dx + biliZriliPbeta (x | , ) dx++(F (ri ) F (li )) + bi (F (ri ) F (li )) .+Since integration distributive operation, claim straightforwardly generalizesmixture beta distributions P (x).Proof Proposition 5: claim proved three steps. First, construct pointbw feasible region HALP V w within O() distance V w.point w given by:b+w=we,1e = (1, 0, . . . , 0) indicator constant basis function f0 (x) 1. pointsatisfies requirements feasibility handily verified solving:bbwwwwV V= V +V +11bb= VwV w+0,bbinequality V wV wholds -infeasibilityw.optimalbb eSincee feasible relaxed HALP, conclude E V wsolution wE V w. Subsequently,inequality yields bound weighted L1 -norm error V w :wbwV V= E V +V1,1hb= E V w+E [V ]1heE [V ]E V w+1e.= V V w+11,196fiSolving Factored MDPs Hybrid State Action VariablesFinally, combine result triangle inequality:wbbwwwV V 1, + V VV V1,1,2eV V w,+11,bleads bound weighted L1 -norm error V w.ReferencesAndrieu, C., de Freitas, N., Doucet, A., & Jordan, M. (2003). introduction MCMCmachine learning. Machine Learning, 50, 543.Astrom, K. (1965). Optimal control Markov processes incomplete state information.Journal Mathematical Analysis Applications, 10 (1), 174205.Bellman, R. (1957). Dynamic Programming. Princeton University Press, Princeton, NJ.Bellman, R., Kalaba, R., & Kotkin, B. (1963). Polynomial approximation new computational technique dynamic programming: Allocation processes. MathematicsComputation, 17 (82), 155161.Bertsekas, D. (1995). counterexample temporal differences learning. Neural Computation, 7 (2), 270279.Bertsekas, D., & Tsitsiklis, J. (1996). Neuro-Dynamic Programming. Athena Scientific,Belmont, MA.Bertsimas, D., & Tsitsiklis, J. (1997). Introduction Linear Optimization. Athena Scientific, Belmont, MA.Boutilier, C., Dearden, R., & Goldszmidt, M. (1995). Exploiting structure policy construction. Proceedings 14th International Joint Conference ArtificialIntelligence, pp. 11041111.Bresina, J., Dearden, R., Meuleau, N., Ramakrishnan, S., Smith, D., & Washington, R.(2002). Planning continuous time resource uncertainty: challenge AI.Proceedings 18th Conference Uncertainty Artificial Intelligence, pp.7784.Casella, G., & Robert, C. (1996). Rao-Blackwellisation sampling schemes. Biometrika,83 (1), 8194.Chow, C.-S., & Tsitsiklis, J. (1991). optimal one-way multigrid algorithm discretetime stochastic control. IEEE Transactions Automatic Control, 36 (8), 898914.Cooper, G. (1988). method using belief networks influence diagrams. ProceedingsWorkshop Uncertainty Artificial Intelligence, pp. 5563.Crites, R., & Barto, A. (1996). Improving elevator performance using reinforcement learning. Advances Neural Information Processing Systems 8, pp. 10171023.de Farias, D. P., & Van Roy, B. (2003). linear programming approach approximatedynamic programming. Operations Research, 51 (6), 850856.197fiKveton, Hauskrecht, & Guestrinde Farias, D. P., & Van Roy, B. (2004). constraint sampling linear programming approach approximate dynamic programming. Mathematics OperationsResearch, 29 (3), 462478.Dean, T., & Kanazawa, K. (1989). model reasoning persistence causation.Computational Intelligence, 5, 142150.Dechter, R. (1996). Bucket elimination: unifying framework probabilistic inference.Proceedings 12th Conference Uncertainty Artificial Intelligence, pp.211219.Duane, S., Kennedy, A. D., Pendleton, B., & Roweth, D. (1987). Hybrid Monte Carlo.Physics Letters B, 195 (2), 216222.Feng, Z., Dearden, R., Meuleau, N., & Washington, R. (2004). Dynamic programmingstructured continuous Markov decision problems. Proceedings 20th Conference Uncertainty Artificial Intelligence, pp. 154161.Ferns, N., Panangaden, P., & Precup, D. (2005). Metrics Markov decision processesinfinite state spaces. Proceedings 21st Conference UncertaintyArtificial Intelligence.Geman, S., & Geman, D. (1984). Stochastic relaxation, Gibbs distribution, Bayesianrestoration images. IEEE Transactions Pattern Analysis Machine Intelligence, 6 (6), 721741.Gordon, G. (1999). Approximate Solutions Markov Decision Processes. Ph.D. thesis,Carnegie Mellon University.Guestrin, C. (2003). Planning Uncertainty Complex Structured Environments.Ph.D. thesis, Stanford University.Guestrin, C., Hauskrecht, M., & Kveton, B. (2004). Solving factored MDPs continuous discrete variables. Proceedings 20th Conference UncertaintyArtificial Intelligence, pp. 235242.Guestrin, C., Koller, D., Gearhart, C., & Kanodia, N. (2003). Generalizing plans newenvironments relational MDPs. Proceedings 18th International JointConference Artificial Intelligence, pp. 10031010.Guestrin, C., Koller, D., & Parr, R. (2001). Max-norm projections factored MDPs.Proceedings 17th International Joint Conference Artificial Intelligence, pp.673682.Guestrin, C., Koller, D., & Parr, R. (2002). Multiagent planning factored MDPs.Advances Neural Information Processing Systems 14, pp. 15231530.Guestrin, C., Koller, D., Parr, R., & Venkataraman, S. (2003). Efficient solution algorithmsfactored MDPs. Journal Artificial Intelligence Research, 19, 399468.Guestrin, C., Venkataraman, S., & Koller, D. (2002). Context specific multiagent coordination planning factored MDPs. Proceedings 18th National ConferenceArtificial Intelligence, pp. 253259.Hastings, W. K. (1970). Monte Carlo sampling methods using Markov chainsapplication. Biometrika, 57, 97109.198fiSolving Factored MDPs Hybrid State Action VariablesHauskrecht, M. (2000). Value-function approximations partially observable Markovdecision processes. Journal Artificial Intelligence Research, 13, 3394.Hauskrecht, M., & Kveton, B. (2004). Linear program approximations factoredcontinuous-state Markov decision processes. Advances Neural Information Processing Systems 16, pp. 895902.Higdon, D. (1998). Auxiliary variable methods Markov chain Monte Carlo applications. Journal American Statistical Association, 93 (442), 585595.Howard, R., & Matheson, J. (1984). Influence diagrams. Readings PrinciplesApplications Decision Analysis, Vol. 2, pp. 719762. Strategic Decisions Group,Menlo Park, CA.Jeffreys, H., & Jeffreys, B. (1988). Methods Mathematical Physics. Cambridge UniversityPress, Cambridge, United Kingdom.Jensen, F., Jensen, F., & Dittmer, S. (1994). influence diagrams junction trees.Proceedings 10th Conference Uncertainty Artificial Intelligence, pp.367373.Khachiyan, L. (1979). polynomial algorithm linear programming. Doklady AkademiiNauk SSSR, 244, 10931096.Kirkpatrick, S., Gelatt, C. D., & Vecchi, M. P. (1983). Optimization simulated annealing.Science, 220 (4598), 671680.Koller, D., & Parr, R. (1999). Computing factored value functions policies structured MDPs. Proceedings 16th International Joint Conference ArtificialIntelligence, pp. 13321339.Kveton, B., & Hauskrecht, M. (2004). Heuristic refinements approximate linear programming factored continuous-state Markov decision processes. Proceedings14th International Conference Automated Planning Scheduling, pp. 306314.Kveton, B., & Hauskrecht, M. (2005). MCMC approach solving hybrid factoredMDPs. Proceedings 19th International Joint Conference Artificial Intelligence, pp. 13461351.Kveton, B., & Hauskrecht, M. (2006a). Learning basis functions hybrid domains.Proceedings 21st National Conference Artificial Intelligence, pp. 11611166.Kveton, B., & Hauskrecht, M. (2006b). Solving factored MDPs exponential-familytransition models. Proceedings 16th International Conference AutomatedPlanning Scheduling, pp. 114120.Mahadevan, S. (2005). Samuel meets Amarel: Automating value function approximationusing global state space analysis. Proceedings 20th National ConferenceArtificial Intelligence, pp. 10001005.Mahadevan, S., & Maggioni, M. (2006). Value function approximation diffusionwavelets Laplacian eigenfunctions. Advances Neural Information ProcessingSystems 18, pp. 843850.199fiKveton, Hauskrecht, & GuestrinMahadevan, S., Maggioni, M., Ferguson, K., & Osentoski, S. (2006). Learning representation control continuous Markov decision processes. Proceedings 21stNational Conference Artificial Intelligence.Manne, A. (1960). Linear programming sequential decisions. Management Science,6 (3), 259267.Metropolis, N., Rosenbluth, A., Rosenbluth, M., Teller, A., & Teller, E. (1953). Equationstate calculations fast computing machines. Journal Chemical Physics, 21,10871092.Munos, R., & Moore, A. (2002). Variable resolution discretization optimal control. Machine Learning, 49, 291323.Ortiz, L. (2002). Selecting Approximately-Optimal Actions Complex Structured Domains.Ph.D. thesis, Brown University.Park, J., & Darwiche, A. (2001). Approximating MAP using local search. Proceedings17th Conference Uncertainty Artificial Intelligence, pp. 403410.Park, J., & Darwiche, A. (2003). Solving MAP exactly using systematic search. Proceedings 19th Conference Uncertainty Artificial Intelligence, pp. 459468.Patrascu, R., Poupart, P., Schuurmans, D., Boutilier, C., & Guestrin, C. (2002). Greedylinear value-approximation factored Markov decision processes. Proceedings18th National Conference Artificial Intelligence, pp. 285291.Puterman, M. (1994). Markov Decision Processes: Discrete Stochastic Dynamic Programming. John Wiley & Sons, New York, NY.Rust, J. (1997). Using randomization break curse dimensionality. Econometrica,65 (3), 487516.Sanner, S., & Boutilier, C. (2005). Approximate linear programming first-order MDPs.Proceedings 21st Conference Uncertainty Artificial Intelligence.Schuurmans, D., & Patrascu, R. (2002). Direct value-approximation factored MDPs.Advances Neural Information Processing Systems 14, pp. 15791586.Schweitzer, P., & Seidmann, A. (1985). Generalized polynomial approximations Markovian decision processes. Journal Mathematical Analysis Applications, 110,568582.Sondik, E. (1971). Optimal Control Partially Observable Markov Decision Processes.Ph.D. thesis, Stanford University.Sutton, R., & Barto, A. (1998). Reinforcement Learning: Introduction. MIT Press,Cambridge, MA.Tesauro, G. (1992). Practical issues temporal difference learning. Machine Learning,8 (3-4), 257277.Tesauro, G. (1994). TD-Gammon, self-teaching backgammon program, achieves masterlevel play. Neural Computation, 6 (2), 215219.Tesauro, G. (1995). Temporal difference learning TD-Gammon. CommunicationsACM, 38 (3), 5868.200fiSolving Factored MDPs Hybrid State Action VariablesTrick, M., & Zin, S. (1993). linear programming approach solving stochastic dynamicprograms. Tech. rep., Carnegie Mellon University.Van Roy, B. (1998). Planning Uncertainty Complex Structured Environments.Ph.D. thesis, Massachusetts Institute Technology.Yuan, C., Lu, T.-C., & Druzdzel, M. (2004). Annealed MAP. Proceedings 20thConference Uncertainty Artificial Intelligence, pp. 628635.Zhang, W., & Dietterich, T. (1995). reinforcement learning approach job-shop scheduling. Proceedings 14th International Joint Conference Artificial Intelligence, pp. 11141120.Zhang, W., & Dietterich, T. (1996). High-performance job-shop scheduling timedelay TD() network. Advances Neural Information Processing Systems 8, pp.10241030.201fiJournal Artificial Intelligence Research 27 (2006) 419-439Submitted 12/05; published 12/06Engineering NoteFluCaP: Heuristic Search Planner First-Order MDPsSteffen HolldoblerEldar KarabaevOlga Skvortsovash@iccl.tu-dresden.deeldar@iccl.tu-dresden.deskvortsova@iccl.tu-dresden.deInternational Center Computational LogicTechnische Universitat Dresden, Dresden, GermanyAbstractpresent heuristic search algorithm solving first-order Markov Decision Processes (FOMDPs). approach combines first-order state abstraction avoids evaluating states individually, heuristic search avoids evaluating states. Firstly,contrast existing systems, start propositionalizing FOMDPperform state abstraction propositionalized version apply state abstraction directly FOMDP avoiding propositionalization. kind abstraction referredfirst-order state abstraction. Secondly, guided admissible heuristic, searchrestricted states reachable initial state. demonstrate usefulness techniques solving FOMDPs system, referred FluCaP(formerly, FCPlanner), entered probabilistic track 2004 International Planning Competition (IPC2004) demonstrated advantage plannersproblems represented first-order terms.1. IntroductionMarkov decision processes (MDPs) adopted representational computational model decision-theoretic planning problems much recent work, e.g., Barto,Bradtke, Singh (1995). basic solution techniques MDPs rely dynamicprogramming (DP) principle (Boutilier, Dean, & Hanks, 1999). Unfortunately, classical dynamic programming algorithms require explicit enumeration state space growsexponentially number variables relevant planning domain. Therefore,algorithms scale complex AI planning problems.However, several methods avoid explicit state enumeration developedrecently. One technique, referred state abstraction, exploits structure factored MDP representation solve problems efficiently, circumventing explicit state spaceenumeration (Boutilier et al., 1999). Another technique, referred heuristic search,restricts computation states reachable initial state, e.g., RTDPBarto et al. (1995), envelope DP Dean, Kaelbling, Kirman, Nicholson (1995)LAO Feng Hansen (2002). One existing approach combines techniques symbolic LAO algorithm Feng Hansen (2002) performs heuristicsearch symbolically factored MDPs. exploits state abstraction, i.e., manipulates setsstates instead individual states. precisely, following SPUDD approach Hoey,St-Aubin, Hu, Boutilier (1999), MDP components, value functions, policies,admissible heuristic functions compactly represented using algebraic decision diagramsc2006AI Access Foundation. rights reserved.fiHolldobler, Karabaev & Skvortsova(ADDs). allows computations LAO algorithm performed efficiently usingADDs.Following ideas symbolic LAO , given initial state, use admissible heuristicrestrict search states reachable initial state. Moreover,exploit state abstraction order avoid evaluating states individually. Thus,work much spirit symbolic LAO extends important way.Whereas symbolic LAO algorithm starts propositionalization FOMDP,performs state abstraction propositionalized version meanspropositional ADDs, apply state abstraction directly structure FOMDP,avoiding propositionalization. kind abstraction referred first-order stateabstraction.Recently, following work Boutilier, Reiter, Price (2001), Holldobler Skvortsova(2004) developed algorithm, referred first-order value iteration (FOVI)exploits first-order state abstraction. dynamics MDP specified Probabilistic Fluent Calculus established Holldobler Schneeberger (1990),first-order language reasoning states actions. precisely, FOVI produceslogical representation value functions policies constructing first-order formulaepartition state space clusters, referred abstract states. effect,algorithm performs value iteration top clusters, obviating need explicitstate enumeration. allows problems represented first-order termssolved without requiring explicit state enumeration propositionalization.Indeed, propositionalizing FOMDPs impractical: number propositions grows considerably number domain objects relations.dramatic impact complexity algorithms depends directly number propositions. Finally, systems solving FOMDPs rely propositionalizingstates also propositionalize actions problematic first-order domains,number ground actions also grows dramatically domain size.paper, address limitations proposing approach solving FOMDPscombines first-order state abstraction heuristic search novel way, exploitingpower logical representations. algorithm viewed first-order generalization LAO , contribution show perform heuristic searchfirst-order MDPs, circumventing propositionalization. fact, showimprove performance symbolic LAO providing compact first-order MDP representation using Probabilistic Fluent Calculus instead propositional ADDs. Alternatively,approach considered way improve efficiency FOVI algorithmusing heuristic search together symbolic dynamic programming.2. First-order Representation MDPsRecently, several representations propositionally-factored MDPs proposed,including dynamic Bayesian networks Boutilier et al. (1999) ADDs Hoey et al.(1999). instance, SPUDD algorithm Hoey et al. (1999) used solveMDPs hundreds millions states optimally, producing logical descriptions valuefunctions involve hundreds distinct values. work demonstrates large420fiFluCaP: Heuristic Search Planner First-Order MDPsMDPs, described logical fashion, often solved optimally exploiting logicalstructure problem.Meanwhile, many realistic planning domains best represented first-order terms.However, existing implemented solutions first-order MDPs rely propositionalization, i.e., eliminate variables outset solution attempt instantiating termspossible combinations domain objects. technique impracticalnumber propositions grows dramatically number domain objectsrelations.example, consider following goal statement taken colored Blocksworldscenario, blocks, addition unique identifiers, associated colors.G = X0 . . . X7 . red(X0 ) green(X1 ) blue(X2 ) red(X3 ) red(X4 )red(X5 ) green(X6 ) green(X7 ) ower(X0 , . . . , X7 ) ,ower(X0 , . . . , X7 ) represents fact eight blocks comprise one tower.assume number blocks domain color distribution agreesgoal statement, namely eight blocks a, b, . . . , h domain,four red, three green one blue. Then, full propositionalizationgoal statement G results 4!3!1! = 144 different ground towers,exactly many ways arranging four red, three green one blue block towereight blocks required color characteristics.number ground combinations, hence, complexity reasoning propositional planner, depends dramatically number blocks and, importantly,number colors domain. fewer colors domain contains, hardersolve propositional planner. example, goal statement G0 , Gabove, eight blocks color, results 8! = 40320 ground towers,grounded.address limitations, propose concise representation FOMDPs withinProbabilistic Fluent Calculus logical approach modelling dynamically changingsystems based first-order logic. first, briefly describe basics theoryMDPs.2.1 MDPsMarkov decision process (MDP), tuple (Z, A, P, R, C), Z finite setstates, finite set actions, P : Z Z [0, 1], written P(z 0 |z, a), specifiestransition probabilities. particular, P(z 0 |z, a) denotes probability endingstate z 0 given agent state z action executed. R : Z R realvalued reward function associating state z immediate utility R(z). C : Rreal-valued cost function associating cost C(a) action a. sequentialdecision problem consists MDP problem finding policy : Zmaximizes total expected discounted reward received executing policyinfinite (or indefinite) horizon.value state z, starting z following policy afterwards,computed following system linear equations:XV (z) = R(z) + C((z)) +P(z 0 |z, (z))V (z 0 ),z 0 Z421fiHolldobler, Karabaev & Skvortsova0 1 discount factor. take equal 1 indefinite-horizon problemsonly, i.e., goal reached system enters absorbing staterewards costs accrued. optimal value function V satisfies:XV (z) = R(z) + max{C(a) +P(z 0 |z, a)V (z 0 )} ,aAz 0 Zz Z.competition, expected total reward model used optimality criterion. Without discounting, care required design planning problemsensure expected total reward bounded optimal policy. followingrestrictions made problems used planning competition:1. problem goal statement, identifying set absorbing goal states.2. positive reward associated transitioning goal state.3. cost associated action.4. done action available states, could used end accumulation reward.conditions ensure MDP model planning problem positive boundedmodel described Puterman (1994). positive reward transitioninggoal state. Since goal states absorbing, is, outgoing transitions,maximum value state bounded goal reward. Furthermore, done actionensures action available state guarantees non-negative futurereward.2.2 Probabilistic Fluent CalculusFluent Calculus (FC) Holldobler Schneeberger (1990) originally setfirst-order logic program equality using SLDE-resolution sole inference rule.Probabilistic Fluent Calculus (PFC) extension original FC expressingplanning domains actions probabilistic effects.StatesFormally, let denote set function symbols. distinguish two function symbols, namely binary function symbol , associative, commutative, admitsunit element, constant 1. Let = \ {, 1}. Non-variable -termscalled fluents. function names fluents referred fluent names. example,on(X, table) fluent meaning informally block X table,fluent name. Fluent terms defined inductively follows: 1 fluent term;fluent fluent term; F G fluent term, F G fluent terms. example,on(b, table) holding(X) fluent term denoting informally block b tableblock X robots gripper. words, freely occurring variablesassumed existentially quantified.422fiFluCaP: Heuristic Search Planner First-Order MDPsassume fluent may occur state. Moreover, functionsymbols, except binary operator, constant 1, fluent names constants,disallowed. addition, binary function symbol allowed appearoutermost connective fluent term. denote set fluents F set fluentterms LF , respectively. abstract state defined pair (P, N ), P LFN LF . denote individual states z, z1 , z2 etc., abstract states Z, Z1 , Z2 etc.set abstract states LP N .interpretation F, denoted I, pair (, ), domain setfinite sets ground fluents F; interpretation function assignsfluent term F set F abstract state Z = (P, N ) set Zfollows:F = {d | .F d}Z = {d | .P N N ./ (N )I },substitution. example, Figure 1 depicts interpretation abstractstate ZZ = (on(X, a) on(a, table), {on(Y, X), holding(X 0 )})informally read: exists block X blocktable, block X exists block X 0robot holds. Since Z contains finite sets ground fluents satisfyP -part satisfy elements N -part, subtract sets groundfluents belong Ni N set ground fluents correspondP -part. Thus, bold area Figure 1 contains exactly sets groundfluents (or, individual states) satisfy P -part Z none elementsN -part. example, individual state z1 = {on(b, a), on(a, table)} belongs Z ,whereas z2 = {on(b, a), on(a, table), holding(c)} not. words, abstract statescharacterized means conditions must hold ground instance thereofand, thus, represent clusters individual states. way, abstract states embodyform state space abstraction. kind abstraction referred first-order stateabstraction.ActionsActions first-order terms starting action function symbol. example,action picking block X another block might denoted pickup (X, ).Formally, let Na denote set action names disjoint . action space tuple= (A, Pre , Eff ), set terms form a(p1 , . . . , pn ), referredactions, Na pi either variable, constant; Pre : LP Nprecondition a; Eff : LP N effect a.far, described deterministic actions only. actions PFC mayprobabilistic effects well. Similar work Boutilier et al. (2001), decomposestochastic action deterministic primitives natures control, referred natureschoices. use relation symbol choice/2 model natures choice. Consider actionpickup (X, ):choice (pickup (X, ), A)(A = pickupS (X, ) = pickupF (X, )) ,423fiHolldobler, Karabaev & Skvortsova{on(b,a), on(a,table)}{on(c,a), on(a,table), on(b,d)}{on(b,a), on(a,table), holding(c)}{on(c,a), on(a,table), on(b,c)}{on(b,a), on(a,table)}{on(c,a), on(a,table), on(b,d)}{on(b,a), on(a,table), holding(c)}{on(c,a), on(a,table), on(b,c)}(b)(a){on(b,a), on(a,table)}{on(c,a), on(a,table), on(b,d)}{on(b,a), on(a,table), holding(c)}{on(c,a), on(a,table), on(b,c)}(c)Figure 1: (a) Interpretation fluent term F = on(X, a) on(a, table); (b) Bold areainterpretation abstract state Z 0 = (on(X, a) on(a, table), {on(Y, X)});(c) Bold area interpretation abstract state Z = (on(X, a)on(a, table), {on(Y, X), holding(X 0 )}).424fiFluCaP: Heuristic Search Planner First-Order MDPspickupS (X, ) pickupF (X, ) define two natures choices action pickup (X, ),viz., succeeds fails. example, natures choice pickupS definedfollows:Pre (pickupS (X, )) := (on(X, ) e, {on(W, X)})Eff (pickupS (X, )) := (holding(X), {on(X, )}) ,fluent e denotes empty robots gripper. simplicity, denote setnatures choices action Ch (a) := {aj |choice (a, aj )}. Please note nowhereaction descriptions restrict domain discourse pre-specified setblocks.natures choices aj associated action define probabilityprob (aj , a, Z) denoting probability one natures choices aj chosenstate Z. example,prob (pickupS (X, ), pickup (X, ), Z) = .75states probability successful execution pickup action state Z.75.next step, define reward function state. example, mightwant give reward 500 states block X block 0,otherwise:reward (Z) = 500 Z v (on(X, a), )reward (Z) = 0 Z 6v (on(X, a), ) ,v denotes subsumption relation, described detail Section 3.2.1.One observe specified reward function without explicit state enumeration. Instead, state space divided two abstract states depending whethernot, block X block a. Likewise, value functions specified respectabstract states only. contrast classical DP algorithms, statesexplicitly enumerated. Action costs analogously defined follows:cost(pickup (X, )) = 3penalizing execution pickup -action value 3.Inference MechanismHerein, show perform inferences, i.e., compute successors given abstract state,action schemata directly, avoiding unnecessary grounding. note computationpredecessors performed similar way.Let Z = (P, N ) abstract state, a(p1 , . . . , pn ) action parametersp1 , . . . , pn , preconditions Pre (a) = (Pp , Np ) effects Eff (a) = (Pe , Ne ). Letsubstitutions. action a(p1 , . . . , pn ) forward applicable, simply applicable, Z, denoted forward (Z, a, , ), following conditions hold:(f1) (Pp U1 ) =AC1 P(f2) Np Np .N N .(P N U2 ) =AC1 (P Np ) ,425fiHolldobler, Karabaev & SkvortsovaU1 U2 new AC1-variables AC1 equational theoryrepresented following system associativity, commutativity, unit elementequations:EAC1 = { (X, Y, Z) X (Y Z) = (X ) Z(X, ) X = X(X) X 1 = X}.words, conditions (f1) (f2) guarantee Z contains positivenegative preconditions action a. action forward applicable ZZsucc = (P 0 , N 0 ),P 0 := (Pe U1 )N 0 := N \ Np Ne(1)referred a-successor Z denoted succ(Z, a, , ).example, consider action pickupS (X, ) defined above, take Z = (P, N ) =(on(b, table) on(X1 , b) e, {on(X2 , X1 )}). action pickupS (X, ) forward applicableZ = {X 7 X1 , 7 b, U1 7 on(b, table)} = {X2 7 W, U2 7 1}. Thus,Zsucc = succ(Z, pickupS (X, ), , ) = (P 0 , N 0 )P 0 = holding(X1 ) on(b, table) N 0 = {on(X1 , b)} .3. First-Order LAO*present generalization symbolic LAO algorithm Feng Hansen (2002),referred first-order LAO (FOLAO ), solving FOMDPs. Symbolic LAOheuristic search algorithm exploits state abstraction solving factored MDPs. Giveninitial state, symbolic LAO uses admissible heuristic focus computationparts state space reachable initial state. Moreover, specifies MDPcomponents, value functions, policies, admissible heuristics using propositional ADDs.allows symbolic LAO manipulate sets states instead individual states.Despite fact symbolic LAO shows advantageous behaviour comparisonclassical non-symbolic LAO Hansen Zilberstein (2001) evaluates statesindividually, suffers important drawback. solving FOMDPs, symbolicLAO propositionalizes problem. approach impractical large FOMDPs.intention show improve performance symbolic LAO providingcompact first-order representation MDPs heuristic search performedwithout propositionalization. precisely, propose switch representationalformalism FOMDPs symbolic LAO propositional ADDs Probabilistic FluentCalculus. FOLAO algorithm presented Figure 2.symbolic LAO , FOLAO two phases alternate complete solutionfound, guaranteed optimal. First, expands best partial policyevaluates states fringe using admissible heuristic function. performsdynamic programming states visited best partial policy, update valuespossibly revise current best partial policy. note focus partial policiesmap subcollection states actions.426fiFluCaP: Heuristic Search Planner First-Order MDPspolicyExpansion(, 0 , G)E := F :=f rom := 0repeat{succ(Z, aj , , )},:=Zf rom aj Ch(a)(a, , ) := (Z)F := F (to G)E := E f romf rom := G E(f rom = )E := E FG := G Freturn (E, F, G)FOVI(E, A, prob, reward, cost, , V )repeatV 0 := Vloop Z Elooploop , forward (Z, a, , )Q(Z, a, ,P) := reward(Z) + cost(a)+prob(aj , a, Z) V 0 (succ(Z, aj , , ))aj Ch(a)end loopend loopV (Z) := max Q(Z, a, , )(a,,)end loopV := normalize(V )r := kV V 0 kstopping criterion:= extractP olicy(V )return (V, , r)FOLAO (A, prob, reward, cost, , 0 , h, )V := hG :=Z 0 , initialize arbitrary actionrepeat(E, F, G) := policyExpansion(, 0 , G)(V, , r) := FOVI(E, A, prob, reward, cost, , V )(F = ) rreturn (, V )Figure 2: First-order LAO algorithm.policy expansion step, perform reachability analysis find set F statesyet expanded, reachable set 0 initial statesfollowing partial policy . set states G contains states expandedfar. expanding partial policy mean defined larger setstates dynamic programming step. symbolic LAO , reachability analysis ADDsperformed means image operator symbolic model checking, computes427fiHolldobler, Karabaev & Skvortsovaset successor states following best current policy. Instead, FOLAO , applysucc-operator, defined Equation 1. One observe since reachabilityanalysis FOLAO performed abstract states defined first-order entities,reasoning successor states kept first-order level. contrast, symbolicLAO would first instantiate 0 possible combinations objects, orderable perform computations using propositional ADDs later on.contrast symbolic LAO , dynamic programming step performed usingmodified version SPUDD, employ modified first-order value iteration algorithm(FOVI). original FOVI Holldobler Skvortsova (2004) performs value iterationentire state space. modify computes states reachableinitial states, precisely, set E states visited best current partial policy. way, improve efficiency original FOVI algorithmusing reachability analysis together symbolic dynamic programming. FOVI producesPFC representation value functions policies constructing first-order formulaepartition state space abstract states. effect, performs value iterationtop abstract states, obviating need explicit state enumeration.Given FOMDP value function represented PFC, FOVI returns best partialvalue function V , best partial policy residual r. order update valuesstates Z E, assign values current value function successorsZ. compute successors respect natures choices aj . residual rcomputed absolute value largest difference current newlycomputed value functions V 0 V , respectively. note newly computed valuefunction V taken normalized form, i.e., result normalize proceduredescribed Section 3.2.1. Extraction best partial policy straightforward:One simply needs extract maximizing actions best partial value function V .symbolic LAO , FOLAO converges -optimal policy three conditions met: (1) current policy unexpanded states, (2) residualr less predefined threshold , (3) value function initialized admissible heuristic. original convergence proofs LAO symbolic LAO HansenZilberstein (2001) carry straightforward way FOLAO .calling FOLAO , initialize value function admissible heuristicfunction h focuses search subset reachable states. simple way createadmissible heuristic use dynamic programming compute approximate valuefunction. Therefore, order obtain admissible heuristic h FOLAO , performseveral iterations original FOVI. start algorithm initial value functionadmissible. Since step FOVI preserves admissibility, resulting valuefunction admissible well. initial value function assigns goal rewardstate thereby overestimating optimal value, since goal reward maximal possiblereward.Since computations FOLAO performed abstract states instead individualstates, FOMDPs solved avoiding explicit state action enumeration propositionalization. first-order reasoning leads better performance FOLAO comparisonsymbolic LAO , shown Section 4.428fiFluCaP: Heuristic Search Planner First-Order MDPs= { Z 0 }Z0a11a12Z1F,GZ2= { Z 1 , Z 2 }F = {Z1,Z 2 }E = { Z 0 , Z 1 , Z 2}G = {Z1,Z 2 }= { Z 0 }Z1Z0GFOVIA ({ Z 0 , Z 1 , Z 2})a)a21Z2a22FZ3= { Z 2 }Z0= { Z 2 , Z 3 }F = {Z3}E = {Z0}b)= { Z 4 , Z 5 }Z 1 F = { Z , Z ,Z }453,,{ZZZ=E23 ,Z 4 ,Z 5 }0,,{Z=ZZGG3 ,Z 4 ,Z 5 }21a11Z2Z3Z4a12Fc)Z5FOVIA ( { Z 0 , Z 2 , Z 3 , Z 4 , Z 5 } )Figure 3: Policy Expansion.3.1 Policy Expansionpolicy expansion step FOLAO similar one symbolic LAOalgorithm. Therefore, illustrate expansion procedure means example. Assume start initial state Z0 two nondeterministic actions a1 a2applicable Z0 , two outcomes a11 , a12 a21 , a22 , respectively. Without lossgenerality, assume current best policy chooses a1 optimal actionstate Z0 . construct successors Z1 Z2 Z0 respect outcomes a11a12 action a1 .fringe set F well set G states expanded far contain states Z1Z2 only, whereas, set E states visited best current partial policy getsstate Z0 addition. See Figure 3a. next step, FOVI performed set E.assume values updated way a2 becomes optimal actionZ0 . Thus, successors Z0 recomputed respect optimal actiona2 . See Figure 3b.One observe one a2 -successors Z0 , namely Z2 , elementset G thus, contained already fringe F previous expansionstep. Hence, state Z2 expanded value recomputed. shownFigure 3c, states Z4 Z5 a1 -successors Z2 , assumption a1optimal action Z2 . result, fringe set F contains newly discoveredstates Z3 , Z4 Z5 perform FOVI E = {Z0 , Z2 , Z3 , Z4 , Z5 }. state Z1contained E, belong best current partial policy,429fiHolldobler, Karabaev & Skvortsovadynamic programming step performed states visited bestcurrent partial policy.3.2 First-Order Value IterationFOLAO , first-order value iteration algorithm (FOVI) serves two purposes: First,perform several iterations FOVI order create admissible heuristic h FOLAO .Second, dynamic programming step FOLAO , apply FOVI states visitedbest partial policy order update values possibly revise currentbest partial policy.original FOVI Holldobler Skvortsova (2004) takes finite state spaceabstract states, finite set stochastic actions, real-valued reward cost functions,initial value function input. produces first-order representation optimalvalue function policy exploiting logical structure FOMDP. Thus, FOVIseen first-order counterpart classical value iteration algorithm Bellman(1957).3.2.1 NormalizationFollowing ideas Boutilier et al. (2001), FOVI relies normalization statespace represents value function. normalization state space, meanequivalence-preserving procedure reduces size state space. wouldeffect state space contains redundant entries, usually case symboliccomputations.Although normalization considered important issue, donehand far. best knowledge, preliminary implementation approach Boutilier et al. (2001) performs rudimentary logical simplificationsauthors suggest using automated first-order theorem prover normalization task.Holldobler Skvortsova (2004) developed automated normalization procedureFOVI that, given state space, delivers equivalent one contains redundancy.technique employs notion subsumption relation.formally, let Z1 = (P1 , N1 ) Z2 = (P2 , N2 ) abstract states. Z1 saidsubsumed Z2 , written Z1 v Z2 , exist substitutionsfollowing conditions hold:(s1) (P2 U1 ) =AC1 P1(s2) N2 N2 .N1 N1 .(P1 N1 U2 ) =AC1 (P1 N2 ) ,U1 U2 new AC1-variables. motivation notion subsumptionabstract states inherited notion -subsumption first-order clausesRobinson (1965) difference abstract states contain complicated negative parts contrast first-order clauses.example, consider two abstract states Z1 Z2 defined follows:Z1 = (on(X1 , a) on(a, table), {red(Y1 )})Z2 = (on(X2 , a), {red(X2 )}) ,430fiFluCaP: Heuristic Search Planner First-Order MDPsN0123456789Number statesSupdateSnorm962414942312933328393614860452627547955681159Time, msecUpdate Norm14413933884121377162079462519513268107353411038731574131154Runtime, msecRuntime w/o norm, msec145396896139321252570337536444030428514459322191329377514805753n/an/an/an/aTable 1: Representative timing results first ten iterations FOVI.Z1 informally asserts block X1 block tableblocks red. Whereas Z2 informally states block X2 blockX2 red. show Z1 v Z2 . relation holds since conditions (s1)(s2) satisfied. Indeed,(on(X2 , a) U1 ) =AC1 on(X1 , a) on(a, table)(on(X1 , a) on(a, table) red(Y1 ) U2 ) = (on(X1 , a) on(a, table) red(X2 ))= {X2 7 X1 , U1 7 on(a, table)} = {Y1 7 X1 , U2 7 1}.One note subsumption language abstract states inherits complexity bounds -subsumption (Kapur & Narendran, 1986). Namely, deciding subsumption two abstract states NP-complete, general. However, Karabaev et al.(2006) recently developed efficient algorithm delivers solutions subsumption problem case abstract states fluent terms.purpose normalization, convenient represent value functionset pairs form hZ, i, Z abstract state real value. essence,normalization algorithm seen exhaustive application following simplification rule value function V .hZ1 , hZ2 ,Z1 v Z2hZ2 ,Table 1 illustrates importance normalization algorithm providing representative timing results first ten iterations FOVI. experiments carriedproblem taken colored Blocksworld scenario consisting ten blocks.Even relatively simple problem FOVI normalization switchedscale beyond sixth iteration.results Table 1 demonstrate normalization iterationFOVI dramatically shrinks computational effort next iterations. columnslabelled Supdate Snorm show size state space performing value updates431fiHolldobler, Karabaev & Skvortsovanormalization, respectively. example, normalization factor, i.e., rationumber Supdate states obtained performing one update stepnumber Snorm states obtained performing normalization step, seventhiteration 11.6. means ninety percent state space containedredundant information. fourth fifth columns Table 1 contain time UpdateNorm spent performing value updates normalization, respectively.total runtime Runtime, normalization switched on, given sixth column.seventh column labelled Runtime w/o norm depicts total runtime FOVInormalization switched off. would sum values seventh columnvalues sixth column sixth iteration inclusively, subtract latterformer divide result total time Norm needed performing normalizationfirst six iterations, would obtain normalization gain threeorders magnitude.4. Experimental Evaluationdemonstrate advantages combining heuristic search together first-orderstate abstraction system, referred FluCaP, successfully enteredprobabilistic track 2004 International Planning Competition (IPC2004). experimental results obtained using RedHat Linux running 3.4GHz Pentium IVmachine 3GB RAM.Table 2, present performance comparison FluCaP together symbolicLAO examples taken colored Blocksworld (BW) scenario introducedIPC2004.main objective investigate whether first-order state abstraction using logiccould improve computational behaviour planning system solving FOMDPs.colored BW problems main interest since ones representedfirst-order terms hence ones allowed us make use first-orderstate abstraction. Therefore, concentrated design domain-dependentplanning system tuned problems taken Blocksworld scenario.colored BW problems differ classical BW ones that, alongunique identifier, block assigned specific color. goal formula, specified firstorder terms, provides arrangement colors instead arrangement blocks.outset solving colored BW problem, symbolic LAO starts propositionalizing components, namely, goal statement actions. that, abstractionusing propositional ADDs applied. contrast, FluCaP performs first-order abstraction colored BW problem directly, avoiding unnecessary grounding. following,show abstraction technique affects computation heuristic function.create admissible heuristic, FluCaP performs twenty iterations FOVI symbolicLAO performs twenty iterations approximate value iteration algorithm similarAPRICODD St-Aubin, Hoey, Boutilier (2000). columns labelled H.timeNAS show time needed computing heuristic function number abstractstates covers, respectively. comparison FluCaP, symbolic LAO needs evaluatefewer abstract states heuristic function takes considerably time. One432fiFluCaP: Heuristic Search Planner First-Order MDPsFluCaPFluCaP31.18.725.19.516.512.7285.476.7128.5 85.063.3135.0n/a757.02813718.3443.6 1241n/an/an/an/an/an/an/an/an/an/aLAO*LAO*FluCaPFOVIFluCaPLAO*FluCaP494 22.3 22.0 23.4496 23.1 17.8 22.7495 27.3 11.7 15.7493 137.6 78.5 261.6492 150.5 33.0 119.1496 221.3 16.6 56.4491 1644 198.1 2776494 1265 161.6 1809494 2210 27.3 317.7n/a n/a 1212 n/an/a n/a 598.5 n/an/a n/a 215.3 1908n/a n/a 1809 n/an/a n/a 3548 n/a4.21.30.321.09.31.2171.3143.612.3804.1301.2153.217331751353432688246143112101n/an/an/an/an/a410172551061539130295321334258328395620197276152251077687278384717389021201475912109n/an/a7251n/an/a0.860.860.867.057.057.0565.965.965.9n/an/an/an/an/a0.820.680.664.246.506.2423.651.261.266.6379.711211.2 1072.5 1072.72.11.93.12.32.03.52.42.04.13.02.35.76.1Table 2: Performance comparison FluCaP (denoted FluCaP) symbolic LAO(denoted LAO*), cells n/a denote fact plannerdeliver solution within time limit one hour. NAS NGS numberabstract ground states, respectively.conclude abstract states symbolic LAO enjoy complex structureFluCaP.note that, comparison FOVI, FluCaP restricts value iteration smallerstate space. Intuitively, value function, delivered FOVI, covers largerstate space, time allocated heuristic search FluCaPused performing additional iterations FOVI. results column labelled %justify harder problem (that is, colors contains), higherpercentage runtime spent normalization. Almost test problems, effort spentnormalization takes three percent total runtime average.order compare heuristic accuracy, present column labelled NGSnumber ground states heuristic assigns non-zero values to. One seeheuristics returned FluCaP symbolic LAO similar accuracy, FluCaPtakes much less time compute them. reflects advantage plain first-orderabstraction comparison marriage propositionalization abstraction usingpropositional ADDs. examples, gain several orders magnitude H.time.column labelled Total time presents time needed solve problem.time, planner must execute 30 runs initial state goal state. one-hour blockallocated problem. note that, comparison FluCaP, time requiredheuristic search symbolic LAO (i.e., difference Total time H.time) growsconsiderably faster size problem. reflects potential employing433%FOVI1517494495495493493495491494494n/an/an/an/an/aNGS, 103NASFluCaP8494495495493492494491494494490490492486481H.time, sec.LAO*7494496496493493495492494494n/an/an/an/an/aTotal time, sec.FluCaP6FOVI5C43243243243234FluCaPBTotal av. rewardLAO*ProblemfiHolldobler, Karabaev & SkvortsovaB202224262830323436Total av. reward, 500489.0487.4492.0482.8493.0491.2476.0475.6n/aTotal time, sec.137.5293.8757.3817.02511.33580.43953.83954.1n/aH.time, sec.56.8110.2409.8117.2823.31174.0781.8939.4n/aNAS711976167611412832429028113248n/aNGS 10211.71.1 1031.0 1064.6 1088.6 10111.1 10157.4 10179.6 1020n/aTable 3: Performance FluCaP larger instances one-color Blocksworld problems,cells n/a denote fact planner deliver solution withintime limit.first-order abstraction instead abstraction based propositional ADDs heuristicsearch.average reward obtained 30 runs, shown column Total av. reward,planners evaluation score. reward value close 500 (which maximum possiblereward) simply indicates planner found reasonably good policy. timenumber blocks B increases 1, running time symbolic LAO increases roughly10 times. Thus, could scale problems seven blocks.contrast FluCaP could solve problems seventeen blocks. notenumber colors C problem affects efficiency abstraction technique.FluCaP, C decreases, abstraction rate increases which, turn, reflecteddramatic decrease runtime. opposite holds symbolic LAO .addition, compare FluCaP two variants. first one, denoted FOVI,performs heuristic search all, rather, employs FOVI compute -optimaltotal value function policy extracted. second one, denoted FluCaP ,performs trivial heuristic search starting initial value function admissibleheuristic. expected, FluCaP combines heuristic search FOVI demonstratesadvantage plain FOVI trivial heuristic search. results illustratesignificance heuristic search general (FluCaP vs. FOVI) importance heuristicaccuracy, particular (FluCaP vs. FluCaP ). FOVI FluCaP scale problemsseven blocks.Table 3 presents performance results FluCaP larger instances one-colorBW problems number blocks varying twenty thirty four. believeFluCaP scale problems larger size implementation yetwell optimized. general, believe FluCaP system sensitivesize problem propositional planners are.experiments targeted one-color problems are,one hand, simplest ones us and, hand, bottleneck propositionalplanners. structure one-color problems allows us apply first-order state abstraction full power. example, 34-blocks problem FluCaP operates3.3 thousand abstract states explode 9.6 1041 individual states proposition434fiFluCaP: Heuristic Search Planner First-Order MDPsTotal av. reward, 500UMassMichiganPurdue1Purdue2Purdue3CaracasToulouseC335000000DresdenB58115811151821CanberraProblem494.6486.5479.7494.6489.7479.1467.5351.8285.7496.4492.8486.3494.6489.9n/an/an/an/an/an/an/a494.8n/an/an/an/an/an/an/an/an/an/an/an/an/an/a496.5486.6481.3494.1488.7480.3469.4462.4455.7496.5486.4481.5494.6490.3479.7467.7-54.9455.1495.8487.2481.9494.4490481.1486.3n/a459n/an/an/a494.9488.8465.7397.2n/an/an/an/an/a494.1n/an/an/an/an/aTable 4: Official competition results colored non-colored Blocksworld scenarios.May, 2004. n/a-entries table indicate either plannersuccessful solving problem attempt solve it.alization. propositional planner must highly optimized order copenon-trivial state space.note additional colors larger instances (more 20 blocks) BW problemscause dramatic increase computational time, consider problemsunsolved. One also observe number abstract states NAS increasesnumber blocks non-monotonically problems generated randomly.example, 30-blocks problem happens harder 34-blocks one. Finally,note results appear Tables 2 3 obtained using new versionevaluation software rely propositionalization contrast initialversion used competition.Table 4 presents competition results IPC2004, FluCaP competitivecomparison planners colored BW problems. FluCaP performwell non-colored BW problems problems propositional ones (thatis, goal statements initial states ground) FluCaP yet incorporateoptimization techniques applied modern propositional planners. contestantsindicated origin. example, Dresden - FluCaP, UMass - symbolic LAO etc.pickup action cost 1, gain five points total reward meansplan contains ten fewer actions average. competition domains log filesavailable online appendix Younes, Littman, Weissman, Asmuth (2005).Although empirical results presented work obtaineddomain-dependent version FluCaP, recently developed (Karabaev et al.,2006) efficient domain-independent inference mechanism core domainindependent version FluCaP.435fiHolldobler, Karabaev & Skvortsova5. Related Workfollow symbolic DP (SDP) approach within Situation Calculus (SC) Boutilieret al. (2001) using first-order state abstraction FOMDPs. One differencerepresentation language: use PFC instead SC. course symbolic value iteration, state space may contain redundant abstract states dramatically affectalgorithms efficiency. order achieve computational savings, normalization must performed remove redundancy. However, original work Boutilier et al. (2001)done hand. best knowledge, preliminary implementationSDP approach within SC uses human-provided rewrite rules logical simplification.contrast, Holldobler Skvortsova (2004) developed automated normalizationprocedure FOVI incorporated competition version FluCaP bringscomputational gain several orders magnitude. Another crucial differencealgorithm uses heuristic search limit number states policy computed.ReBel algorithm Kersting, van Otterlo, De Raedt (2004) relates FOLAOalso uses representation language simpler Situation Calculus.feature makes state space normalization computationally feasible.motivation, approach closely connected Relational Envelope-based Planning(REBP) Gardiol Kaelbling (2003) represents MDP dynamics compact setrelational rules extends envelope method Dean et al. (1995). However, REBPpropositionalizes actions first, afterwards employs abstraction using equivalenceclass sampling. contrast, FOLAO directly applies state action abstractionfirst-order structure MDP. respect, REBP closer symbolic LAOFOLAO . Moreover, contrast PFC, action descriptions REBP allow negationappear preconditions effects. organization, FOLAO , symbolic LAO ,similar real-time DP Barto et al. (1995) online search algorithm MDPs.contrast, FOLAO works offline.algorithms classified deductive approaches solving FOMDPs.characterized following features: (1) model-based, (2)aim exact solutions, (3) logical reasoning methods used compute abstractions.note FOVI aims exact solution FOMDP, whereas FOLAO , dueheuristic search avoids evaluating states, seeks approximate solution.Therefore, would appropriate classify FOLAO approximate deductiveapproach FOMDPs.another vein, research developing inductive approaches solvingFOMDPs, e.g., Fern, Yoon, Givan (2003). authors propose approximatepolicy iteration (API) algorithm, replace use cost-function approximationspolicy representations API direct, compact state-action mappings, usestandard relational learner learn mappings. effect, Fern et al. provide policylanguage biases enable solution large relational MDPs. inductive approachescharacterized following features: (1) model-free, (2) aimapproximate solutions, (3) abstract model used generate biased samplesunderlying FOMDP abstract model altered based them.recent approach Gretton Thiebaux (2004) proposes inductive policy construction algorithm strikes middle-ground deductive inductive tech436fiFluCaP: Heuristic Search Planner First-Order MDPsniques. idea use reasoning, particular first-order regression, automaticallygenerate hypothesis language, used input inductive solver.approach Gretton Thiebaux related SDP approach sensefirst-order domain specification language well logical reasoning employed.6. Conclusionsproposed approach combines heuristic search first-order state abstraction solving FOMDPs efficiently. approach seen two-fold:First, use dynamic programming compute approximate value function servesadmissible heuristic. heuristic search performed find exact solutionstates reachable initial state. phases, exploitpower first-order state abstraction order avoid evaluating states individually.experimental results show, approach breaks new ground exploring efficiencyfirst-order representations solving MDPs. comparison existing MDP plannersmust propositionalize domain, e.g., symbolic LAO , solution scales better largerFOMDPs.However, plenty remaining done. example, interestedquestion extent optimization techniques applied modern propositionalplanners combined first-order state abstraction. future competitions,would like face problems goal and/or initial states partially definedunderlying domain contains infinitely many objects.current version FOLAO targeted problems allow efficientfirst-order state abstraction. precisely, problems polynomially translated PFC. example colored BW domain, existentially-closedgoal descriptions linearly translated equivalent PFC representation. Whereasuniversally-closed goal descriptions would require full propositionalization. Thus, current version PFC less first-order expressive than, e.g., Situation Calculus. future,would interesting study extensions PFC language, particular, findtrade-off PFCs expressive power tractability solution methodsFOMDPs based PFC.Acknowledgementsgrateful anonymous reviewers thorough reading previous versions paper. also thank Zhengzhu Feng fruitful discussionsproviding us executable symbolic LAO planner. greatly appreciateDavid E. Smith patience encouragement. valuable comments helpedus improve paper. Olga Skvortsova supported grant within Graduate Programme GRK 334 Specification discrete processes systems processesoperational models logics auspices Deutsche Forschungsgemeinschaft(DFG).437fiHolldobler, Karabaev & SkvortsovaReferencesBarto, A. G., Bradtke, S. J., & Singh, S. P. (1995). Learning act using real-time dynamicprogramming. Artificial Intelligence, 72 (1-2), 81138.Bellman, R. E. (1957). Dynamic programming. Princeton University Press, Princeton, NJ,USA.Boutilier, C., Dean, T., & Hanks, S. (1999). Decision-theoretic planning: Structural assumptions computational leverage. Journal Artificial Intelligence Research,11, 194.Boutilier, C., Reiter, R., & Price, B. (2001). Symbolic Dynamic Programming FirstOrder MDPs. Nebel, B. (Ed.), Proceedings Seventeenth International Conference Artificial Intelligence (IJCAI2001), pp. 690700. Morgan Kaufmann.Dean, T., Kaelbling, L., Kirman, J., & Nicholson, A. (1995). Planning time constraintsstochastic domains. Artificial Intelligence, 76, 3574.Feng, Z., & Hansen, E. (2002). Symbolic heuristic search factored Markov Decision Processes. Dechter, R., Kearns, M., & Sutton, R. (Eds.), Proceedings EighteenthNational Conference Artificial Intelligence (AAAI2002), pp. 455460, Edmonton,Canada. AAAI Press.Fern, A., Yoon, S., & Givan, R. (2003). Approximate policy iteration policy languagebias. Thrun, S., Saul, L., & Scholkopf, B. (Eds.), Proceedings Seventeenth Annual Conference Neural Information Processing Systems (NIPS2003), Vancouver,Canada. MIT Press.Gardiol, N., & Kaelbling, L. (2003). Envelope-based planning relational MDPs. Thrun,S., Saul, L., & Scholkopf, B. (Eds.), Proceedings Seventeenth Annual ConferenceNeural Information Processing Systems (NIPS2003), Vancouver, Canada. MITPress.Gretton, C., & Thiebaux, S. (2004). Exploiting first-order regression inductive policyselection. Chickering, M., & Halpern, J. (Eds.), Proceedings Twentieth Conference Uncertainty Artificial Intelligence (UAI2004), Banff, Canada. MorganKaufmann.Hansen, E., & Zilberstein, S. (2001). LAO*: heuristic search algorithm finds solutionsloops. Artificial Intelligence, 129, 3562.Hoey, J., St-Aubin, R., Hu, A., & Boutilier, C. (1999). SPUDD: Stochastic Planning usingDecision Diagrams. Laskey, K. B., & Prade, H. (Eds.), Proceedings Fifteenth Conference Uncertainty Artificial Intelligence (UAI1999), pp. 279288,Stockholm. Morgan Kaufmann.Holldobler, S., & Schneeberger, J. (1990). new deductive approach planning. NewGeneration Computing, 8, 225244.Holldobler, S., & Skvortsova, O. (2004). Logic-Based Approach Dynamic Programming.Proceedings Workshop Learning Planning Markov ProcessesAdvances Challenges Nineteenth National Conference Artificial Intelligence (AAAI04), pp. 3136, San Jose, CA. AAAI Press.438fiFluCaP: Heuristic Search Planner First-Order MDPsKapur, D., & Narendran, P. (1986). NP-completeness set unification matchingproblems. Siekmann, J. H. (Ed.), Proceedings Eighth International Conference Automated Deduction (CADE1986), pp. 489495, Oxford, England. SpringerVerlag.Karabaev, E., Ramme, G., & Skvortsova, O. (2006). Efficient symbolic reasoning firstorder MDPs. Proceedings Workshop Planning, Learning MonitoringUncertainty Dynamic Worlds Seventeenth European ConferenceArtificial Intelligence (ECAI2006), Riva del Garda, Italy. appear.Kersting, K., van Otterlo, M., & De Raedt, L. (2004). Bellman goes relational. Brodley,C. E. (Ed.), Proceedings Twenty-First International Conference MachineLearning (ICML2004), pp. 465472, Banff, Canada. ACM.Puterman, M. L. (1994). Markov Decision Processes - Discrete Stochastic Dynamic Programming. John Wiley & Sons, Inc., New York, NY.Robinson, J. (1965). machine-learning logic based resolution principle. JournalAssociation Computing Machinery, 12 (1), 2341.St-Aubin, R., Hoey, H., & Boutilier, C. (2000). APRICODD: Approximate policy construction using decision diagrams. Leen, T. K., Dietterich, T. G., & Tresp, V. (Eds.),Proceedings Fourteenth Annual Conference Neural Information ProcessingSystems (NIPS2000), pp. 10891095, Denver. MIT Press.Younes, H., Littman, M., Weissman, D., & Asmuth, J. (2005). first probabilistic trackInternational Planning Competition. Journal Artificial Intelligence Research,24, 851887.439fiJournal Artificial Intelligence Research 27 (2006) 235297Submitted 03/06; published 10/06Modelling Mixed Discrete-Continuous Domains PlanningMaria FoxDerek Longmaria.fox@cis.strath.ac.ukderek.long@cis.strath.ac.ukDepartment Computer Information SciencesUniversity Strathclyde,26 Richmond Street, Glasgow, G1 1XH, UKAbstractpaper present pddl+, planning domain description language modellingmixed discrete-continuous planning domains. describe syntax modelling stylepddl+, showing language makes convenient modelling complex timedependent effects. provide formal semantics pddl+ mapping planning instancesconstructs hybrid automata. Using syntax semantic modelconstruct semantic mapping labelled transition systems complete formalinterpretation pddl+ planning instances.advantage building mapping pddl+ HA theory forms bridgePlanning Real Time Systems research communities. One consequenceexpect make use theoretical properties HAs.example, restricted class Reachability problem (which equivalentPlan Existence) decidable.pddl+ provides alternative continuous durative action model pddl2.1,adding flexible robust model time-dependent behaviour.1. Introductionpaper describes pddl+, extension pddl (McDermott & AIPS98 Planning Competition Committee, 1998; Fox & Long, 2003; Hoffmann & Edelkamp, 2005) familydeterministic planning modelling languages. pddl+ intended support representation mixed discrete-continuous planning domains. pddl developed McDermott (McDermott & AIPS98 Planning Competition Committee, 1998) standardmodelling language planning domains. later extended (Fox & Long, 2003)allow temporal structure modelled certain restricting assumptions. resulting language, pddl2.1, extended include domain axioms timed initialliterals, resulting pddl2.2 (Hoffmann & Edelkamp, 2005). pddl2.1, durative actionsfixed-length duration discrete effects modelled. limited capabilitymodel continuous change within durative action framework also provided.pddl+ provides flexible model continuous change use autonomous processes events. modelling continuous processes also considered McDermott (2005), Herrmann Thielscher (1996), Reiter (1996), Shanahan (1990), Sandewall (1989) others knowledge representation reasoningcommunities, well Henzinger (1996), Rasmussen, Larsen Subramani (2004),Haroud Faltings (1994) others real time systems constraint-reasoningcommunities.c2006AI Access Foundation. rights reserved.fiFox & Longfrequently used subset pddl2.1 fragment modelling discretised change.part used 3rd International Planning Competition used basispddl2.2. continuous modelling constructs pddl2.1 adoptedcommunity large, partly considered attractive naturalway represent certain kinds continuous change (McDermott, 2003a; Boddy, 2003).wrapping continuous change inside durative actions pddl2.1 forces episodes changevariable coincide logical state changes. important limitation continuousdurative actions pddl2.1 therefore planning agent must take full controlchange world, change without direct action partagent.key extension pddl+ provides ability model interactionagents behaviour changes initiated world. Processes run timecontinuous effect numeric values. initiated terminated eitherdirect action agent events triggered world. referthree-part structure start-process-stop model. make distinction logicalnumeric state, say transitions logical states instantaneous whilstoccupation given logical state endure time. approach takes transitionsystem view modelling change allows direct mapping languagesreal time systems community modelling approach used (Yi, Larsen,& Pettersson, 1997; Henzinger, 1996).paper provide detailed discussion features pddl+, reasonsaddition. develop formal semantics primitives terms formalmapping pddl+ Henzingers theory hybrid automata (Henzinger, 1996).Henzinger provides formal semantics means labelled transition system.therefore adopt labelled transition semantics planning instances goingroute. explain means plan valid showing planinterpreted accepting run corresponding labelled transition system.note that, certain constraints, Plan Existence problem pddl+ planninginstances (which corresponds Reachability problem corresponding hybrid automaton) remains decidable. discuss constraints utility modellingmixed discrete-continuous planning problems.2. MotivationMany realistic contexts planning applied feature mixture discretecontinuous behaviours. example, management refinery (Boddy & Johnson,2004), start-up procedure chemical plant (Aylett, Soutter, Petley, Chung, & Edwards, 2001), control autonomous vehicle (Leaute & Williams, 2005)coordination activities planetary lander (Blake et al., 2004) problemsreasoning continuous change fundamental planning process.problems also contain discrete change modelled traditional planningformalisms. situations motivate need model mixed discrete-continuous domainsplanning problems.236fiModelling Mixed Discrete-Continuous Domains Planningpresent two motivating examples demonstrate discrete continuous behaviours interact yield interesting planning problems. Boddy Johnsonspetroleum refinery domain battery power model Beagle 2.2.1 Petroleum refinery production planningBoddy Johnson (2004) describe planning scheduling problem arising management petroleum refinement operations. objects problem include materials,form hydrocarbon mixtures fractions, tanks processing units.operation refinery mixtures fractions pass series processingunits including distillation units, desulphurisation units cracking units. Insideunits converted combined produce desired materials remove wasteproducts. Processes include filling emptying tanks, caseshappen simultaneously tank, treatment materials transfertanks. continuous components problem include process unit control settings,flow volumes rates, material properties volumes time-dependent propertiesmaterials combined tanks consequence refinement operations.example demonstrating utility continuous model arises constructiongasoline blend. success gasoline blend depends chemical balanceconstituents. Blending results materials pumped tankspipelines rates enable exact quantities required chemical constituentscontrolled. example, diluting crude oil less sulphrous materialrate in-flow diluting material, volume tank, balancedout-flow diluted crude oil perhaps refinement operations.Boddy Johnson treat problem planning scheduling refinery operationsoptimisation problem. Approximations based discretisation lead poor solutions,leading financial motivation Boddy Johnsons application. observe,moderately large refinery produce order half million barrels per day.calculate 1% decrease efficiency, resulting approximation, could resultloss quarter million dollars per day. accurate model continuousdynamics efficient cost-effective refinery.Boddy Johnsons planning scheduling approach based dynamic constraintsatisfaction involving continuous, non-linear, constraints. domain-specific solverconstructed, demonstrating direct handling continuous problem componentsrealistic. Boddy Johnson describe applying solver real problem involving 18,000 continuous constraints including 2,700 quadratic constraints, 14,000 continuousvariables around 40 discrete decisions (Lamba, Dietz, Johnson, & Boddy, 2003; Boddy& Johnson, 2002). interesting observe scale problem solvable,optimality, reasonable computational effort.2.2 Planning Activities Planetary LanderBeagle 2, ill-fated probe intended surface Mars, designed operate withintight resource constraints. constraint payload mass, desire maximise sciencereturn rigours hostile Martian environment combine make essentialsqueeze high performance limited energy time available mission.237fiFox & LongOne tightest constraints operations energy. Beagle 2, energystored battery, recharged solar power consumed instruments, on-boardprocessor, communications equipment heater required protect sensitive componentsextreme cold Martian nights. features Beagle 2 commondeep space planetary landers.performance battery solar panels subject variations dueageing, atmospheric dust conditions temperature. Nevertheless, long periodscommunication windows, lander achieve dense scientific data-gatheringactivities carefully planned planning must performed nominalmodel behaviour battery, solar panels instruments. state chargebattery lander falls within envelope defined maximum level capacitybattery minimum level dictated safety requirements lander.safety requirement ensures enough power nightfall power heaternight operations achieve next communications session.operations change state battery charge, causing follow continuouscurve within envelope. order achieve dense performance, operationslander must pushed envelope tightly possible. equationsgovern physical behaviour energy curve complex, approximationpossible tractable accurate discretised modelcurve would be. refinery domain, approximation cost: coarserapproximation model, less accurately possible determine limitsperformance plan.paper refer simplified model domain, call PlanetaryLander Domain. details model presented Appendix C, discussedSection 4.3.2.3 Remarkstwo examples plans must interact background continuous behaviourstriggered world. refinery domain concurrent episodes continuous change(such filling emptying tank) affect variable (such sulphurcontent crude oil tank), flow tank must carefullycontrolled achieve mixture right chemical composition. Beagle 2 domainpower generation consumption processes act concurrently power supplyway must controlled avoid supply dropping critical minimalthreshold. domains continuous processes subject discontinuous firstderivative effects, resulting events triggered, actions executed processesinteracting. events trigger discontinuities might coincide end-pointsactions. planner needs explicit model events might triggeredorder able reason effects.argue discretisation represents inappropriate simplification domains,adequate modelling continuous dynamics necessary capture criticalfeatures planning.238fiModelling Mixed Discrete-Continuous Domains Planning3. Layout PaperSection 4 explain pddl+ builds foundations pddl family languages. describe syntactic elements new pddl+ remindreader representation language used expressing temporal plans family.develop detailed example domain, battery power model planetary lander,continuous modelling required properly capture behavioursplan must interact. complete section formal proof showing pddl+strictly expressive pddl2.1.Section 5 explain theory hybrid automata relevant work,provide key automaton constructs use developmentsemantics pddl+. Section 6 present mapping planning instances HAs.using syntactic constructs HA semantic model.Section 7 discuss subset Reachability problem decidable,might interested models context planning. concludepaper discussion related work.4. Formalismsection present syntactic foundations pddl+, clarifying extendforegoing line development pddl family languages. rely definitionssyntactic structures pddl2.1, call Core Definitions.published 2003 (Fox & Long, 2003) repeat Appendix easereference.pddl+ includes timed initial literal construct pddl2.2 (which provides syntactically convenient way expressing class events predictedinitial state). Although derived predicates powerful modelling concept,far included pddl+. work required explore relationshipderived predicates start-process-stop model considerpaper.4.1 Syntactic Foundationspddl+ builds directly discrete fragment pddl2.1: is, fragment containing fixed-length durative actions. supplemented timed initial literalspddl2.2 (Hoffmann & Edelkamp, 2005). introduces two new constructs: events processes. represented similar syntactic frames actions. elementsformal syntax relevant given (these read conjunctionBNF description pddl2.1 given Fox & Long, 2003).<structure-def><structure-def>::=:events <event-def>::=:events <process-def>following event Planetary Lander Domain. models transitionnight day occurs clock variable daytime reaches zero.239fiFox & Long(:event daybreak:parameters ():precondition (and (not (day)) (>= (daytime) 0)):effect (day))BNF event identical actions, processes modifiedallowing conjunction process effects effects field. process effectstructure continuous effect pddl2.1:<process-effect>::=(<assign-op-t> <f-head> <f-exp-t>)following process taken Planetary Lander Domain. describesbattery state charge, soc, affected power demand exceeds supply.interpretation process effects explained Section 4.2.(:process discharging:parameters ():precondition (> (demand) (supply)):effect (decrease soc (* #t (- (demand) (supply)))))provide basic abstract syntactic structures form core pddl+planning domain problem semantic mappings constructed.Core Definition 1 defines simple planning instance actions structures describing state change. Definition 1 extends Core Definition 1 include eventsprocesses. avoid repeating parts core definition unchangedextended version.Definition 1 Planning Instance planning instance defined pair= (Dom, P rob)Dom = (F s, Rs, As, Es, P s, arity) tuple consisting finite sets functionsymbols, relation symbols, actions, function arity mapping symbolsrespective arities, described Core Definition 1. addition contains finite setsevents Es processes P s.Ground events, E, defined obvious generalisation Core Definition 6defines ground actions. fact events required least one numericprecondition makes special case actions. details ground processes, P,given Definition 2. Processes continuous effects primitive numeric expressions(PNEs). Core Definition 1 defines PNEs ground instances metric function expressions.Definition 2 Ground Process p P ground process followingcomponents:Name process schema name together actual parameters.240fiModelling Mixed Discrete-Continuous Domains PlanningTime0.01:0.01:0.710.915.02:18.03:19.51:21.04:ActionAction 1Action 2Action 3Action 4Action 5Action 6Action 7Action 8Duration[13.000][1.000][1.000][1.000]Figure 1: example pddl+ plan showing time stamp duration associatedaction, applicable. Actions 2, 3, 4 7 instantaneous,associated duration.Precondition proposition, P rep , atoms either groundatoms planning domain else comparisons terms constructedarithmetic operations applied PNEs real values.Numeric Postcondition numeric postcondition conjunction additive assignment propositions, NPp , rvalues1 expressions assumedform (* #t exp) exp #t-free.Definition 3 Plan plan, planning instance ground action set A, finiteset pairs Q>0 (where Q>0 denotes set positive rationals).pddl family languages imposes restrictive formalism representationplans. temporal members family, pddl2.1 (Fox & Long, 2003), pddl2.2 (Hoffmann & Edelkamp, 2005) pddl+, plans expressed collections time-stampedactions. Definition 3 makes precise. actions durative plan also recordsdurations must execute. Figure 1 shows abstract examplepddl+ plan actions fixed-length durative actions (their durations shown square brackets action name). Plans report eventsprocesses.plans time stamps interpreted amount time elapsed sincestart plan, whatever units used modelling durations timedependent effects.Definition 4 Happening happening time point one discretechanges occurs, including activation deactivation one continuous processes.term used denote set discrete changes associated single time point.1. Core Definition 3 defines rvalues right-hand sides assignment propositions.241fiFox & Long4.2 Expressing Continuous Changepddl2.1 time-dependent effect continuous change numeric variable expressed means intervals durative activity. Continuous effects representedupdate expressions refer special variable #t. variable syntactic device marks update time-dependent. example, consider following twoprocesses:(:process heatwater:parameters ():precondition (and (< (temperature) 100) (heating-on)):effect (increase (temperature) (* #t (heating-rate))))(:process superheat:parameters ():precondition (and (< (temperature) 100) (secondaryburner-on)):effect (increase (temperature) (* #t (additional-heating-rate))))processes active (that is, water heating secondaryburner applied water yet boiling) lead combined effect equivalentto:dtemperature= (heating-rate) + (additional-heating-rate)dtActions continuous update expressions effects represent increasedlevel modelling power provided fixed length, discrete, durative actions.pddl+ continuous update expressions restricted occur process effects.Actions events, instantaneous, restricted expression discretechange. introduces three-part modelling periods continuous change: actionevent starts period continuous change numeric variable expressed meansprocess. action event finally stops execution process terminateseffect numeric variable. goals plan might achieved activeprocess stopped.Notwithstanding limitations durative actions, observed Boddy (2003)McDermott (2003a), modelling continuous change, durative action modelconvenient capturing activities endure time whose internal structureirrelevant plan. includes actions whose fixed duration might dependvalues parameters. example, continuous activities riding bicycle (whoseduration might depend start destination ride), cleaning windoweating meal might conveniently modelled using fixed-length durative actions. pddl+force modeller represent change lower level abstractionrequired adequate capture domain. activities need modelledfixed duration actions might suffice.following durative action, taken Planetary Lander Domain, illustrates durative actions used alongside processes events unnecessary expose internal structure associated activity. case, actionmodels preparation activity represents pre-programmed behaviour. constants242fiModelling Mixed Discrete-Continuous Domains PlanningpartTime1 B-rate defined initial state duration schedule effectswithin specified interval behaviour known advance applicationprepareObs1 action.(:durative-action prepareObs1:parameters ():duration (= ?duration (partTime1)):condition (and (at start (available unit))(over (> (soc) (safelevel)))):effect (and(at start (not (available unit)))(at start (increase (demand) (B-rate)))(at end (available unit))(at end (decrease (demand) (B-rate)))(at end (readyForObs1))))4.3 Planetary Lander Examplepresent example pddl+ domain description, illustrating continuousfunctions, driven interacting processes, events actions, constrain structureplans. example based simplified model solar-powered lander. actionssystem durative actions draw fixed power throughout operation.two observation actions, observe1 observe2, observe two differentphenomena. system must prepare these, either using single long action,called fullPrepare, using two shorter actions, called prepareObs1 prepareObs2,specific one observation actions. shorter actions higher powerrequirements execution single preparation action. lander requiredexecute observation actions communication link established (controlledtimed initial literal), sets deadline activities.activities carried background fluctuating power supply.lander equipped solar panels generate electrical power. generationprocess governed position sun, night power generated,rising smoothly peak midday falling back zero dusk. curve powergeneration shown Figure 2. Two key events affect power generation: nightfallgeneration process ends lander enters night operational mode. mode drawsconstant power requirement heater used protect instruments, additionrequirements instruments. dawn night operations end generation restarts.events triggered simple clock driven twin processespower generation night operations reset events.lander equipped battery, allowing store electrical energy charge.solar panels producing power required instrumentslander, excess directed recharging battery (the charging process),demand instruments exceeds solar power shortfall mustsupplied battery (the discharging process). charging process followsinverse exponential function, since rate charging proportional power devotedcharging also proportional difference maximum current levelscharge. Discharge occurs linearly rate determined current demandslander activities. Since solar generation process non-linear function time243fiFox & Long201816Power (Watts)1412108642002468Time (hours dawn)101214Figure 2: Graph power generated solar panels.Charging(Supply exceeds demand)SupplyffffDischarging(Demand exceeds supply)ffffffffffffffDemandffStart planEnd planffffffffffActionfifffifffifffifffiAction BffAction CfiffDawnNightfallFigure 3: abstracted example lander plan showing demand curve supply curveperiod execution.day, state charge battery follows complex curve discontinuitiesrate change caused instantaneous initiation termination durativeinstrument actions. Figure 3 shows example plan demand curve generatescompared supply period.Figures 5 6 show graphs battery state charge two alternative plansshown Figure 4. plans start hour dawn deadline set 10hours later. parameters set ensure 15 hours daylight,244fiModelling Mixed Discrete-Continuous Domains Planning2.6:4.7:6.8:7.9:0.1: (fullPrepare) [5]5.2: (observe1) [2]7.3: (observe2) [2](prepareObs1) [2](observe1) [2](prepareObs2) [1](observe2) [2]Figure 4: Two alternative plans complete observations deadline.plan must complete within two hours midday. battery begins 45% fullycharged.Value699.519715fullPrepare00daybreakd>sobserve15.1observe2-Time10Figure 5: Graph battery state charge (as percentage full charge) first plan.timepoint marked > first point demand exceeds supply,battery begins recharge. vertical lines mark pointsprocesses affected. state charge falling intervaldischarge process active rising charge process active.lander subject critical constraint throughout activities: battery statecharge may never fall safety threshold. typical requirement remotesystems protect system failures unexpected problems intendedensure always enough power survive human operatorsopportunity intervene. threshold marked Figure 5, seenstate charge drops approximately 20%. lowest point graphtime 2.95 hours dawn, solar power generation matches instrumentdemand. point discharging process ends generation process starts.time point correspond start end activities landerpoint explicitly selected planner. is, instead, point definedintersection two continuous functions. order confirm satisfaction constraint,state charge may never fall safety threshold, state charge mustmonitored throughout activity. sufficient consider valueend points, state charge well minimum required, since curvemight dip well values middle.use example illustrate points later paper. complete domain description initial state problem instance found Appendix C,245fiFox & LongValue698.1479pObs100obs1daybreakpObs2obs2 -Time10Figure 6: Graph battery state charge (as percentage full charge) second plan.previous case, discontinuities gradient state chargecorrespond points charge discharge process changedaction (start end point) event.two reports generated Val (Howey, Long, & Fox, 2004) availableonline appendices associated paper.4.4 Expressive Power pddl+consider whether pddl+ represents real extension expressive powerpddl2.1. course, fragment pddl2.1 used competitionwidely used since (the fragment restricted discrete durative actions) include parts express continuous change, without elements pddl2.1certainly less expressive pddl+. section discuss differencesmodelling continuous change using continuous durative action constructs pddl2.1,modelling using start-process-stop model.pddl2.1, complete continuous durative actions, comprises powerful modellinglanguage. Allowing continuous effects within flexible duration actions offers expressivecombination appears close processes events pddl+. essential difference languages arises separation, pddl+, changesworld directly enacted executive indirect changesdue physical processes consequences.model physical processes consequences pddl2.1 requires additiondomain model artificial actions simulate way processes eventsinteract eachother direct actions executive. example, forceintervals abut, triggering event correctly modelled, requires artificialactions force corresponding end points intervals synchronise. actionsmust applied planner, since dynamic force indirect eventscoincide way would coincide nature. earlier work (Fox & Long,2004) show clips constructed pddl2.1 used achieve effect.Clips prevent time passing end points actions modelling background246fiModelling Mixed Discrete-Continuous Domains PlanningSupplyStart planEnd planDemandfifififififififififififiActionfifififififififififififififififfffffffffffffAction BffffffPlan activitiesffffffffffffffffffffffffffffffffffffffffffffCCInitiation actionCCChargingClip actionsNCTermination actionDischargingGenerationNight operationsNSimulation activitiesFigure 7: illustration structure simulation activities required modelsimple pddl+ plan pddl2.1. B actions, C chargingdischarging processes, respectively.behaviour world. example shown Figure 7 illustrates clips usedmodel interacting continuous effects pddl2.1 representation Planetary LanderDomain.example shows two activities executing backdrop continuous chargingdischarging battery. bell-shaped curve represents solar power production, starts daybreak, reaches peak midday drops zeronightfall. Two concurrent power-consuming activities, B, executingdaylight hours. stepped curve shows (cumulative) power requirements. pddl+representation plan would contain two actions B processesevents governing power consumption production would triggered autonomouslywould explicit plan. contrast, pddl2.1 representationplan would contain durative actions episodes charge, C, discharge, D,need precisely positioned (using clips) respect two activitiesB. Clips required actions C fixed durationsjoined together force respect underlying timeline. two dottedrectangles figure depict pddl2.1 plan containing 28 action instances additionB. these, four points simulating intersections supplydemand curves correspond end points actions B.planner using pddl2.1 model forced construct points simulationbackground behaviours. necessary clip actions would explicit plan.seen, construction accurate simulation pddl2.1 far trivial.Indeed, although issue highlight example, cases247fiFox & Longsimulation constructed consistent use -separation interferingaction effects. occurs events process interactions occur arbitrarily smalltemporal separations. Even simulations constructed, lack distinctiondirect indirect causes change means planner forced constructsimulated process event sequences though part plan constructing.means planner required consider simulation components thoughchoice points plan construction, leading combinatorial blowcost constructing plans.explicit distinction actions events yields compact plan representationpddl+. pddl2.1 plan, using simulation events processes, would containexplicit representations every happening execution trace pddl+ plan.fact pddl2.1 plan represents form constructive proof existenceexecution trace pddl+ plan one way understand Theorem 1 below: workvalidating pddl+ plan required construct proof pddl2.1 plan wouldsupply explicitly.distinguishing direct action executive continuous behaviours physical world facilitate decomposition planning problemdiscrete continuous components. decomposition admits use hybridreasoning techniques, including Mixed Integer Non-Linear Programming (MINLP) (Grossmann, 2002), Benders Decomposition (Benders, 1962), Branch-and-Bound approachesrelax discrete components domain continuous representations (Androulakis,2001), techniques proved promising mixed discrete-continuousproblem-solving (Wu & Chow, 1995). contrast, trying treat hybrid problem usingpurely discrete reasoning techniques seems likely result unmanageable combinatorial explosion. course, trade-offs cannot fully understood planners existtackling mixed discrete-continuous domains featuring complex non-linear change.prove pddl+ formally greater expressive power pddl2.1.Theorem 1 pddl+ strictly expressive pddl2.1.Proof: demonstrate showing encode computation arbitraryregister machine (RM) language pddl+. instructions RM encodedpddl+ events correct execution plan made depend terminationcorresponding RM program. means general plan validation problempddl+ plans undecidable, pddl2.1 plans decidable.pddl2.1 plans explicitly list points plan state transition occurs (asactions) checked validity simulated execution. contrast, pddl+plan leaves events implicit, plan cannot tested without identifying eventstriggered confirming outcomes.simulate arbitrary RM program, need action initiate executionprogram:(:action start:parameters ():precondition ():effect (started))248fiModelling Mixed Discrete-Continuous Domains Planningconstruct family events simulate execution program. useencoding register machine three instructions: inc(j,k) incrementsregister j jumps instruction k, dec(j,k,z), tests register j jumpsinstruction z zero otherwise decrements jumps instruction k,HALT terminates program. assume instructions labelled 0, . . . , nregisters used labelled 0, . . . , m. also assume instruction 0 startprogram.(:event beginExection:parameters ():precondition (started):effect(and (not (started))(in 0)))instruction form: l:inc(j,k) l label, construct:(:event dol:parameters ():precondition (in l):effect(and (not (in l))(in k)(increase (reg j) 1)))instruction form: l:dec(j,k,z) construct:(:event dol:parameters ():precondition (in l):effect(and (not (in l))(when (= (reg j) 0) (in z))(when (> (reg j) 0) (and (decrease (reg j) 1)(in k)))))Finally, instruction l:HALT have:(:event dol:parameters ():precondition (in l):effect(and (not (in l))(halted)))create initial state registers reg 0. . .reg initialised 0goal halted. apparent plan:1:(beginExecution)valid computation embedded RM halts. Therefore, general planvalidation system pddl+ would able solve halting problem.Theorem 1 formal demonstration increase expressive power offeredpddl+. depends fact pddl+ plan defined exclude explicit indicationevents processes triggered execution plan. mightargued artificial problem, two points consider. Firstly,249fiFox & Longavoiding requirement events processes captured explicitly planremain agnostic nature reasoning planner might performphenomena. might planner synthesise approximation continuous process simplifies reasoning sufficiently accurate allow placeactions around process behaviour, would insufficient determineprecise moments process triggers events. Secondly, planner might abledetermine collection processes events irrelevant valid executionplan constructed solve problem, even though apparent patternprocesses events triggered execution plan. case,requirement plan correctly explicitly captures background activityunreasonable additional demand.undecidability pddl+ validation problem need confronted practice.certain restrictions imposed (no cascading events, functions restricted polynomialsexponentials), undermine ability capture realistic domains,processes events underlying pddl+ plan efficiently simulated using well-knownnumerical methods. (Fox, Howey, & Long, 2006) show numerical simulationachieved pddl+ plan validator, VAL. validation procedure must simulateprocesses events ensure critical values remain acceptable ranges throughoutplan (and satisfy conditions planned actions). restrictions sensibleapply, particular sequences events may triggered time point,also forms continuous functions arise domain, prevent usachieving close approximations realistic behaviours. Boddy Johnson (2004)Hofmann Williams (2006) use linear quadratic approximations model complexnon-linear functions. use quartic approximation inverse exponential functionrepresent power dynamics model planetary lander (see Appendix C).practice, although formal separation expressive power pddl+pddl2.1, conceptual separation activities executiveworld important feature pddl+.present simple family domains illustrate pddl2.2 encodings growlarger pddl+ domains encoding equivalent behaviours. difference arisesfact durative actions encapsulate way process starts,also way concludes. means domains significant choicedifferent ways start end process, pddl2.1 encoding expands fastercorresponding pddl+ encoding. Consider pddl+ domain containing followingaction process schemas:(:action Ai:parameters ():precondition (and (not (started)) (ai )):effect (and (started) (not (ai )) (assign (dur) dAi )))(:action Bj:parameters ():precondition (and (bj ) (= (C) (* (dur) dBj ))250fiModelling Mixed Discrete-Continuous Domains Planning:effect (and (not (started)) (done)))(:process P:parameters ():precondition (started):effect (increase (C) (* #t 1)))action schemas families Ai Bj , indexed j take values{1, ..., n} j {1, ..., m} respectively. values dAi dBj (different) actioninstance-dependent constants. plan starting initial state {(ax ), (by )}, C = 0,achieves done, must contain actions Ax , , separated exactly dAx .dBy .encode equivalent durative action model requires action schema:(:durative-action ABi,j:parameters ():duration (= ?duration (* dAi dBj )):condition (and (at start (ai )) (at end (bj ))):effect (and (at start (not (ai ))) (at end (done))))seen, size encoding family pddl+ domains growsO(n + m), corresponding size pddl2.2 encodings grows O(n.m).need couple possible initiation process possible conclusionprocess leads multiplicative growth. Reification propositions durativeaction encoding used reduce encoding O(n + m) encoding,ground action set continues grow O(n.m) compared O(n + m) growthground actions processes pddl+ model.clear easier build plan given O(n.m) encoding,provides ready-made solutions problem. However, trade-off explored lieslarge representation tolerated obtain advantage general. alwayspossible compile parts solution problem problem representation,price paid size encoding effort required construct it.basis argue compact representation preferable. examplepresented artificial example demonstrating theoretical difference expressivepowers pddl2.2 pddl+. remains seen whether phenomenon arisespractice realistic domains.5. pddl+ Hybrid Automatasection discuss role Hybrid Automata relation pddl+. motivateinterest Hybrid Automata proceed describe detail.251fiFox & Long5.1 Relevance HA TheoryResearchers concerned modelling real-time systems developed techniquesmodelling reasoning mixed discrete-continuous systems (Yi et al., 1997; Henzinger, Ho, & Wong-Toi, 1995; Rasmussen et al., 2004). techniques becomewell-established. theory hybrid automata (Henzinger, 1996; Gupta, Henziner, &Jagadeesan, 1997; Henzinger & Raskin, 2000), focus interestmodel-checking community years, provides underlying theoretical basiswork. discussed Section 2, central motivation extensions introducedpddl+ enable representation mixed discrete-continuous domains. Therefore, theory hybrid automata provides ideal formal basis developmentsemantics pddl+.Henzinger (1996) describes digital controller analogue plant paradigmaticexample mixed discrete-continuous system. discrete states (control modes)dynamics (control switches) controller modelled vertices edgesgraph. continuous states dynamics plant modelled vectors realnumbers differential equations. behaviour plant depends statecontroller, vice versa: controller switches modes updatevariables describe continuous behaviour plant hence bringdiscrete changes state plant. continuous change state plantaffect invariant conditions control mode controller result controlswitch.similar way, pddl+ distinguishes processes, responsible continuous change,events actions, responsible discrete change. Further, constraint pddl+,numeric values appear values functions whose arguments drawn finitedomains, corresponds requirement made hybrid automata dimensionautomaton finite.important contribution work demonstrate pddl+ support succinct encodings deterministic hybrid automata use planning. expectformal (semantics formal properties) practical (model-checking techniques) results Hybrid Automata theory able exploited planning communityaddressing problem planning discrete-continuous planning domains. Indeed,cross-fertilisation already beginning (Dierks, 2005; Rasmussen et al., 2004; Edelkamp,2003).5.2 Hybrid Automatapresent relevant definition Hybrid Automaton Henzingers theory (Henzinger, 1996) used construction formal semanticspddl+ planning domains.Definition 5 Hybrid Automaton Hybrid Automaton H consists following components:Variables. finite set X = {x1 , . . . , xn } real-valued variables. number ncalled dimension H. write X set {x1 , . . . , xn } dotted variables,252fiModelling Mixed Discrete-Continuous Domains Planningrepresenting first derivatives continuous change, X 0 set {x01 , . . . , x0n }primed variables, representing values conclusion discrete change.Control Graph. finite directed graph hV, Ei. vertices V control modes.edges E control switches.Initial, invariant flow conditions. Three vertex labelling functions, init, inv,f low, assign control mode v V three predicates. initialcondition init(v) predicate whose free variables X. invariantcondition inv(v) predicate whose free variables X. flow conditionf low(v) predicate whose free variables X X.Jump conditions. edge labelling function jump assigns controlswitch e E predicate. jump condition jump(e) predicate whose freevariables X X 0 .H-Events. finite set h-events function, hevent : E , assignscontrol switch h-event.h-event referred Henzinger event, changed nameavoid terminological confusion events pddl+.Figure 8 shows simple dynamic system expressed hybrid automaton.initial, jump flow conditions necessarily satisfied unique valuations.multiple valuations satisfy conditions possible behaviourautomaton non-deterministic.observed Henzingers model needs extended, simple way,include undefined value, , real-valued variables. pddl+ statescontain unassigned real-valued variables, shown Core Definition 2 definesmetric valuation state. role value allow situationsmetric fluent created domain, given initial value. fluentgiven undefined value attempts inspect assigned valueconsidered yield error. introduces semantic difficulties leftdetails modification implicit.input language finite automaton defined setsequences symbols alphabet, possible define input languageHybrid Automaton. case, elements language called traces:Definition 6 Trace Given Hybrid Automaton, H, h-event set , trace Helement language (R0 ) .Informally, trace consists sequence h-events interleaved real values corresponding time periods h-events applied. timeh-event applied readily determined summing values time periods sequence point h-event appears: h-events take time execute. Notedefinition require trace accepted Hybrid Automaton:property traces consider Section 6.4.minor point note definition trace allows tracesfirst transition occurs time 0. convention semantics pddl2.1 forbid253fiFox & Longpumponpumprate measures flow rate tank(0 pump off, P pump on)maxthreshold = 10.waterlevel = pumprateturn pumpJump: waterlevel = waterlevel.Inv:waterlevel < 10Flow:waterlevel = 0pumpoff.waterlevel = PpumponInv:waterlevel < 10Flow:turn pumpJump: waterlevel = waterlevelInv:floodJump:waterlevel = 10waterlevel = waterlevelFlow:.waterlevel = 0floodedFigure 8: simple tank-filling situation modelled hybrid automaton. threecontrol modes three control switches. control switch flood jumpcondition requires level exceed bath capacity. Flow conditionsgovern change water level.254fiModelling Mixed Discrete-Continuous Domains PlanningTHAimpliesTracesinterpretationinterpretationrepresentationPlanninginstancePlansimpliesFigure 9: semantic mapping plans tracesactions occur time 0. reason discussed (Fox & Long, 2003), but,briefly, order consistent model states hold intervalclosed left open right, initial state (which holds time 0) mustpersist non-zero interval. consequence, interested tracesaction transitions time 0.6. Semanticssection present semantics pddl+. begin explaining approachproceed develop semantics incrementally.6.1 Semantics pddl+present semantics two stages. Section 6.2 give semantics planning instances terms Hybrid Automata, defining formal mapping planningconstructs constructs corresponding automata. Figure 9 illustrates syntacticrelationship pddl+ planning instance plans implies,semantic relationships pddl+ instance corresponding HybridAutomaton plans implied model traces impliedautomaton. pddl+ instance plans syntactic constructs HAtraces provide formal semantics. show that, whilst plans interpretedtraces, traces represented plans means abstraction events appearingtraces. figure represents first stage development formalisation. summarise, Section 6.3, Henzingers interpretation Hybrid Automataterms labelled transition systems accompanying transition semantics. usesemantic step basis second stage formalism, shown Figure 13.important distinction make planning models actionsevents requires us introduce time-slip monitoring process (explained below),used ensure events executed immediately preconditions satisfied.Core Definition 4 define PNEs mapped vector position-indexed~ = hX1 , ..., Xn i. purpose mapping allow us define manipvariables, Xulate entire collection PNEs consistent way. collection given valuationstate shown Core Definition 2 logical metric components stateidentified. updating function defined Core Definition 8 specifies relationship255fiFox & Longmust hold valuations PNEs application action.Normalisation expressions use PNEs involves replacing PNEscorresponding position-indexed variable denoting position valuation held withinstate. performed semantic function N . Update expressions constructedusing primed form position-indexed variable lvalue2 effect, distinguish pre- post-condition values variable. mapping planning instancesHybrid Automata make use collection position-indexed variables formset metric variables constructed automaton. Definition 5, Henzinger usesnames X, X 0 X vectors variables, post-condition variables followingdiscrete updates derivatives variables continuous change, respectively.order reduce potential confusion following, note use X, X 0X Henzinger does, X1 , . . . , Xn names position-indexed variablesplanning instance interpreted Xn+1 extra variable used representtime-slip.6.2 Semantics Planning Instancefollowing present semantics planning instance stages orderfacilitate understanding. begin definition uniprocess planning instanceevent-free uniprocess planning instance. introduce general conceptplanning instance. definitions rely concept relevance actions, eventsprocesses, present.following definition uses interpretation preconditions defined Core Definition 9. core definition explains how, given proposition P logical state s,truth proposition determined. N um(s, P ) predicate PNEsdomain. explained Core Definition 9, determine truth propositionstate, respect vector numeric values ~x, formal numeric parametersproposition substituted values ~x resulting proposition evaluatedlogical state. purpose Definition 7 identify actions, events processescould applicable given logical state, values metric fluents appropriatesatisfy preconditions.Definition 7 Relevance Actions, Events Processes ground action (evente, process p) planning instance dimension n, relevant logical statevalue ~x Rn N um(s, P rea )(~x) (N um(s, P ree )(~x) N um(s, P rep )(~x),respectively).Ps (Es ) set ground processes (events) relevant state s.general, action, event process relevant particular (logical) state mightactually become applicable, since valuations numeric state arisesystem logical state might include satisfy preconditionscorresponding transition.construction HA, mappings described below, vertices controlgraph subsets ground atoms therefore equivalent logical states. use2. lvalue update expression variable left expression, valueexpression right assigned.256fiModelling Mixed Discrete-Continuous Domains Planningvariable v denote vertex Pv (Ev ) denote processes (events) relevantcorresponding logical state.given logical state subset relevant processes active, accordingprecise valuation metric fluents current state. first considerrestricted case one active process affects value variabletime, call uniprocess planning instance. proposition unary-contextflow(i,), defined below, used describe effects ith variable process ,active. later extend definition concurrent case multipleprocesses may contribute behaviour variable.Definition 8 Uniprocess Planning Instance planning instance uniprocess planning instance if, metric variable, Xi , set processes affect valueXi relevant state v, denoted Pv |Xi , contains processes whose preconditions pairwisemutually exclusive. is, 1 , 2 Pv |Xi (1 6= 2 ) numeric stateN (P re1 ) N (P re2 ).Definition 9 Unary-context-flow v logical state uniprocess planning instancedimension n Pv |Xi unary-context-flow proposition defined follows.Let effect Xi take form (increase Xi (* #t Qi )) expression Qi .unary-context-flowv (i, ) = (N (P ) Xi = Qi )begin presenting semantics event-free uniprocess planning instanceis, uniprocess planning instance contains events. extend definitioninclude events, present semantics uniprocess planning instance. Finallyintroduce concurrent process effects definition semantics planninginstance.Definition 10 Semantics Event-free Uniprocess Planning Instance eventfree uniprocess planning instance, = (Dom, P rob), interpreted Hybrid Automaton,HI , follows:Variables. variables HI X = {X1 , . . . , Xn }, n dimensionplanning problem.Control Graph. set vertices V formed subsets ground atomsplanning instance. set edges E contains edge e v v 0iff action, a, relevant v and:v 0 = (v Dela ) Addaaction associated edge e.Initial, invariant flow conditions. vertex labelling function init definedas:f alsev 6= InitlogicalVinit(v) =N (Initnumeric ) {Xi = |Xi 6 N (Initnumeric )} otherwise257fiFox & Longvertex labelling function inv proposition True.vertex labelling function flow defined:f low(v) = (n^i=1^unary-context-flowv (i, ) (Pv |Xi^N (P ) Xi = 0) )Pv |XiJump conditions. edge labelling function jump defined follows. Givenedge e vertex v, associated action a:jump(e) = N (P rea ) U Fa (X) = X 0U Fa updating function action a, defined Core Definition 8specifies relationship must hold valuations PNEsapplication action.H-events. set names ground actions. edge labelling functionhevent : E assigns edge name action associated edge.flow condition states that, variable, precondition one processescould affect true process defines rate change (through unarycontext-flow proposition), else, none process preconditions satisfiedrate change variable zero.illustrate construction present simple example. planetary landerdomain requires events cannot used example event-free model.Consider pddl+ domain containing following actions process:(:action startEngine:precondition (stopped):effect (and (not (stopped))(running)))(:action accelerate:precondition (running):effect (increase (a) 1))(:action decelerate:precondition (running):effect (decrease (a) 1))(:action stop:precondition (and (= (v) 0) (running)):effect (and (not (running))(stopped)(assign (a) 0)))258fiModelling Mixed Discrete-Continuous Domains PlanningInv: TrueFlow:startEngineJump: =v = 0= 0d=0v=0a=0accelerateJump: =v = v= +1Inv: TrueFlow:d=vv=aa=0runningstoppedstopJump:v=0=v = 0= 0decelerateJump: =v = v= 1Figure 10: hybrid automaton constructed translation event-free uniprocessplanning instance. ignore init function, simply asserts appropriate initial state particular problem instance.(:process moving:precondition (running):effect (and (increase (d) (* #t (v)))(increase (v) (* #t (a)))))translation process described Definition 10 leads hybrid automaton shownFigure 10. seen, two vertices, corresponding logical states{stopped} {running}. four actions translate edges, edge linking vertexaction relevant one logical effects enacted.metric effects actions encoded jump conditions associated edge, usingconvention primed versions variables refer state followingtransition. Note variables explicitly affected action constrainedtake value transition transition:metric equivalent strips assumption. stop action metric preconditionexpressed jump condition transition, requiring velocity variable,v, zero transition. stopped state process affect variables,flow conditions simply assert variables zero rate change.running state moving process relevant indeed, since preconditions,active whenever system state. effect process expressedflow conditions state show distance variable, d, changesvalue velocity, v, changes turn value acceleration, a. constraintscreate system differential equations describing simultaneous effects velocityacceleration system.259fiFox & Longconsider case events included one processactive one fluent one time.planning domains important distinguish state changes deliberately planned, called actions, those, called events, brought spontaneously world. distinction HA, control switchescalled events. distinction complicates relationship plans traces,plans contain control switches correspond actions. eventstriggered evolution domain influence planned actions mustinferred added sequence actions order arrive corresponding traces.Henzinger et al. (1998) discuss use -moves, transitionslabelled corresponding control-switch, special label . significancetransitions appear traces. trace correspondsaccepting run using -moves contain transitions labelledelements . -moves appear time transitions, lengthstransitions accumulated single transition corresponding trace.purpose silent transitions allow special book-keeping transitionsinserted automata used simulate automata syntactically richerconstraints, allowing various reducibility results demonstrated. convenient aspect-moves affect traces transferred originalautomata simulations.pddl+, events similar -moves appear explicitly plans.However, contrast -moves, applicable events always forced occuractions may applied state.extending event-free planning instances include events require mechanismcapturing fact events occur instant triggeredworld, convenience planner. time must allowed passsatisfaction event preconditions triggering event.semantic models use variable measure amount time elapsespreconditions event becoming true event triggering. Obviously quantity,call time-slip, must 0 valid planning instance. HAconstruct associate invariant vertex control graph enforcerequirement. might appear simpler way handle events would simply assertinvariant condition state preconditions events false,event represented outgoing transition jump condition specifyingprecondition corresponding event. However, possible jump conditiontransition inconsistent invariant state leaves since musthold simultaneously time transition made.variable used monitor time-slip planning instance dimension nvariable Xn+1 . variable operates clock tracking passage time eventbecomes applicable. define time-slippage proposition switch clock wheneverpreconditions event become true state. event applicableclock switched off.260fiModelling Mixed Discrete-Continuous Domains PlanningDefinition 11 Time-slippage planning instance dimension n variable Xn+1called time-slip variable time-slippage defined follows._time-slippage(R) = (Xn+1 = 0 Xn+1 = 1) (N (P ree ) Xn+1 = 1)eRR set ground events.use time-slip allows us model pddl+ domains directly Hybrid Automatastandard form. alternative would introduce modified definition Hybrid Automata makes explicit distinction controllable uncontrollable transitions(actions events respectively) require uncontrollable transitionsalways occur immediately jump conditions satisfied. approach wouldlead essentially equivalent formalism, would complicate opportunity drawexisting body research Hybrid Automata, followedtime-slip approach.interpretation Uniprocess Planning Instance extends interpretationEvent-free Uniprocess Planning Instance. added components underlined easecomparison.Definition 12 Semantics Uniprocess Planning Instance unary process planning instance = (Dom, P rob) interpreted Hybrid Automaton, HI , follows:Variables. variables HI X = {X1 , . . . , Xn+1 }, n dimensionplanning problem.n + 1th variable special control variable used measure time-slip.Control Graph. set vertices V formed subsets ground atomsplanning instance. set edges E contains edge e v v 0iff action event, a, relevant v and:v 0 = (v Dela ) Addaaction event associated edge e.Initial, invariant flow conditions. vertex labelling function init definedas:f alsev 6= InitlogicalVinit(v) =N (Initnumeric ) {Xi = |Xi 6 N (Initnumeric )} otherwisevertex labelling function inv simple proposition ensures time-slip zero.inv(v) = (Xn+1 = 0)vertex labelling function flow defined:VVf low(v) = ( ni=1unary-context-flowv (i, )V Pv |Xi( Pv |X N (P ) Xi = 0) time-slippage(Ev ))261fiFox & LongJump conditions. edge labelling function jump defined follows. Givenedge e vertex v, associated action a:^jump(e) = N (P rea ) U Fa (X) = X 0N (P reev )evEvGiven edge e vertex v, associated event ev:jump(e) = N (P reev ) U Fev (X) = X 0U Fa (U Fev ) updating function action (event ev) respectively.H-events. set names ground actions events. edgelabelling function hevent : E assigns edge name action eventassociated edge.case, flow condition says thing event-free uniprocess planninginstance, additional constraint whenever precondition eventsatisfied, time-slip variable must increase rate 1 (and may increase rate zerootherwise). Since invariant condition every state insists time-slip variablenever greater 0, valid trace machine cannot rest state periodtime preconditions event become true. also seenjump condition action transitions asserts event preconditions must false.ensures events always applied action transitions permitted.extend preceding simple example domain include event, illustrateconstruction described Definition 12:(:event engineExplode:parameters ():precondition (and (running) (>= (a) 1) (>= (v) 100)):effect (and (not (running)) (assign (a) 0) (engineBlown)))corresponding machine shown Figure 11. structure machinesimilar previous example, includes extra state, reachable event transition. addition event also requires addition time-slip variable, .behaviour variable controlled, particular, new flow constraintrunning state ensures event precondition becomes true time-slipstarts increase soon time passes. addition variable controlalso propagates jump flow conditions states.Finally consider case concurrent process effects occur mustcombined. general case refer rest paper.given logical state subset relevant processes active, accordingprecise valuation metric fluents current state. proposition context-flow(i,)asserts rate change ith variable defined precisely processes, provided (and they) active, affectedprocess. following definition explains contributions rate change262fiModelling Mixed Discrete-Continuous Domains PlanningInv: = 0Flow:d=0a=0 v=0=0 =1stoppedstartEngineJump: =v = 0= 0=Inv: = 0accelerateJump: =v = v= +1< 0 v < 100=1 v 100 = 1Flow:d=v v=a a=0=0 =1runningstopJump:v=0=v = 0= 0=Inv: = 0Flow:d=0v=0=0 =1engineBlowna=0engineExplodedecelerateJump: =v = v= 1< 0 v < 100=Jump: 1v 100= 0v = v==Figure 11: hybrid automaton constructed translation uniprocess planninginstance.variable several different concurrent processes combined (see also Section 4.2).simply involves summing contributions active instant. assumewithout loss generality contributions increasing effects. Decreasing effectshandled simply negating contributions made effects.Definition 13 Combined Concurrent Effects Given finite set process effects, E =e1 . . . ek , ei form (increase Pi (* #t Qi )), combined concurrenteffect E PNE P , called C(P, E), definedX{Qi | = 1, . . . k, P = Pi }Given set processes, , combined concurrent effect PNE P , denotedC(P, ), C(P, E), E set effects processes .noted E contains processes affect specific variable, P ,C(P, E) = 0.Definition 14 Context-flow v logical state planning instance dimensionn subset Pv , context-flow proposition defined follows.^^context-flowv (i, ) = (N (P rep )N (P rep )) Xi = C(Xi , )ppPv \1 n.263fiFox & Longempty context flow proposition asserts Xi = 0 i.interpretation Planning Instance extends interpretation UniprocessPlanning Instance. Again, added components underlined convenience.Definition 15 Semantics Planning Instance planning instance = (Dom, P rob)interpreted Hybrid Automaton, HI , follows:Variables. variables HI X = {X1 , . . . , Xn+1 }, n dimensionplanning problem. n + 1th variable special control variable usedmeasure time-slip .Control Graph. set vertices V formed subsets ground atomsplanning instance. set edges E contains edge e v v 0iff action event, a, relevant v and:v 0 = (v Dela ) Addaaction event associated edge e.Initial, invariant flow conditions. vertex labelling function init definedas:f alsev 6= InitlogicalVinit(v) =N (Initnumeric ) {Xi = |Xi 6 N (Initnumeric )} otherwisevertex labelling function inv simple proposition ensures time-slipzero.inv(v) = (Xn+1 = 0)vertex labelling function flow defined:f low(v) = (n^^context-flowv (i, )) time-slippage(Ev )i=1 P(Pv )Jump conditions. edge labelling function jump defined follows. Givenedge e vertex v, associated action a:^jump(e) = N (P rea ) U Fa (X) = X 0N (P reev )evEvGiven edge e vertex v, associated event ev:jump(e) = N (P reev ) U Fev (X) = X 0H-events. set names ground actions events. edgelabelling function hevent : E assigns edge name actionevent associated edge.264fiModelling Mixed Discrete-Continuous Domains Planningfinal conjunct jump definition actions ensures state cannotleft action event preconditions satisfied. possibleone event simultaneously applicable state. discussedSection 6.4.illustration final extension sequence definitions, add oneprocess preceding example:(:process windResistance:parameters ():precondition (and (running) (>= (v) 50)):effect (decrease (v) (* #t (* 0.1 (* (- (v) 50) (- (v) 50))))))process causes vehicle slowed wind resistance becomes effective50mph, proportional square speed excess 50mph. leadsflow constraint running state two new clauses replace originalconstraint rate change velocity. new clauses shown secondbox right Figure 12. observed, velocity vehiclegoverned two different differential equations, according whether v < 50 v 50.equations are:dvv < 50dt = a,dv2 , v 50=0.1(v50)dtsolution first is: v = + v0 v0 velocity pointequation first applies (and measured point). solution second is:c0 ( 10a 50)ec1 + 50 + 10av=1 c0 ec1c0 constant determined initial value velocityc1 = 10a5process first applies (and, again, measured point). shownexample, simple differential equations expressed pddl+ leadcomplex expressions. course, significant difference provisionsemantics expressiveness finding planning algorithm managepaper concerned former. anticipate planningrequire sensible constraints extent expressive power pddl+exploited.definition semantics planning instance constructed around basicframework discrete state space model domain. follows familiar discreteplanning model semantics. continuous dimensions model constructedensure Hybrid Automaton always start initial state consistentplanning instance (modelled init labelling function). state invariants ensuretime-slip occurs model that, therefore, events always occurpreconditions satisfied. noted since negation event preconditionsadded jump conditions exiting transitions, impossible stateexited way triggered event. Finally, flow models effect265fiFox & LongInv: = 0Flow:d=0a=0 v=0=0 =1stoppedstartEngineJump: =v = 0= 0=Inv: = 0accelerateJump: =v = v= +1< 0 v < 100=1 v 100 = 1Flow:d=v a=0=0 =1runningstopJump:v=0=v = 0= 0=v 50 v = 0.1 (v 50)v < 50 v =2Inv: = 0Flow:engineExplodedecelerateJump: =v = v= 1< 0 v < 100=Jump: 1v 100= 0v = v==d=0v=0=0 =1engineBlowna=0Figure 12: hybrid automaton constructed translation planning instance.real values active processes state. flow function assignsproposition state determines piece-wise continuous behaviourreal values planning domain. function piece-wise differentiable,finite number segments within finite interval. reason possiblebehaviour metric fluent undergoing continuous change affect preconditionprocess cause continuous change metric fluents change.change cannot cause discontinuity value metric fluents themselves,cause discontinuity derivatives. consequence timeinterval two successive actions events might include finite sequence distinctperiods continuous change. seen following section, requiresacceptable trace describing behaviour explicitly subdivide intervalsequence subintervals continuous change governed stable setdifferential equations.6.3 SemanticsHenzinger gives semantics constructing mapping Labelled Transition Systems (Keller, 1976). Figure 13 shows complete semantic relationship planninginstances labelled transition systems plans accepting runs. tophalf figure shows relationship already constructed Henzinger give semantics Hybrid Automata. completes bridge planning instanceslabelled transition systems. details mapping Hybrid Automata labelledtransition semantics provided section.following definitions repeated Henzingers paper (1996).266fiModelling Mixed Discrete-Continuous Domains PlanningLabelledtransitionsystemsAcceptingrunsimpliesinterpretationTHAinterpretationimpliesTracesinterpretationinterpretationrepresentationPlanninginstancePlansimpliesFigure 13: semantic mapping LTSDefinition 16 Labelled Transition System labelled transition system, S, consistsfollowing components:State Space. (possibly infinite) set, Q, states subset, Q0 Q initialstates.Transition Relation. (possibly infinite) set, A, labels. labelbinary relation state space Q. triple q q 0 called transition.Definition 17 Transition Semantics Hybrid Automata timed transitionHybrid Automaton H labelled transition system componentssystem SH0Q, Q , , A, defined follows:Define Q, Q0 V Rn , (v, ~x) Q iff closed proposition inv(v)[X := ~x]true, (v, ~x) Q0 iff init(v)[X := ~x] inv(v)[X := ~x] true.set Q called state space H.= R0 .event , define (v, ~x) (v 0 , ~x0 ) iff control switch e Ethat: (1) source e v target e v 0 , (2) closed propositionjump(e)[X, X 0 := ~x, ~x0 ] true, (3) hevent(e) = .non-negative real R0 , define (v, ~x) (v 0 , ~x0 ) iff v = v 0differentiable function f : [0, ] Rn , first derivative f : (0, ) Rnthat: (1) f (0) = ~x f () = ~x0 (2) reals (0, ), inv(v)[X := f ()]f low(v)[X, X := f (), f()] true. function f called witnesstransition (v, ~x) (v 0 , ~x0 ).last definition see requirement interval continuous change timed transition system governed single set differential267fiFox & Longequations, single solution exhibited (continuous differentiable) witnessfunction.labelled transition system allows transitions arbitrary non-negative intervals time, processes execute dictated witness functioncorresponding period. definition plans (Definition 3) allow rational timesassociated actions, consequence rational intervals elapseactions. means plans restricted expressing subsettransitions possible labelled transition system. return discussionpoint following section, consider relationship plans accepting runs explicitly.6.4 Interpretation Plans Tracescomplete two-layered semantics presented Figure 13 showing plan interpreted using Henzingers notion trace acceptance. conclude presentationformal semantics pddl+.Using Henzingers syntax semantic model, first map plans tracesrely interpretation traces terms accepting runs. plan set timestamped actions (Definition 3): neither events processes appear specificationplan, even though planned actions initiate them. contrast, since Henzingerdistinguish actions events, trace HA contains controlswitches might actions events, together explicit time intervalsthem. Plans finite, concerned finite traces, plans normallysubsets traces, missing events possible subdivision intervalsactions distinct subintervals continuous activity.define new structure, plantrace, contains sequence control switchescorresponding actions plan interpreted. map plantraces setstraces proceed indicated above.Definition 18 Plantrace Let H Hybrid Automaton, h-event set partitionedtwo subsets, A, actions, E, events. plantrace H elementlanguage (Q>0 A+ ) .plantrace consists sequences one action control switches (denoted A+ ),following single time interval must greater 0 length (0 lengthintervals allowed actions either side would actuallyoccurring simultaneously). example, sequence h3 a0 a1 a2 2.7 a3 a4 plantrace.Note allowed rational valued intervals actions.consistent history pddl irrational time points considered.semantics Hybrid Automata actions occur time pointconsidered sequenced according ordering recordedtrace. reality, possible execute actions time yet ensuresomehow ordered respect possible consequences interaction. orderrespect constraint introduce additional element interpretation plans:consider impact ordering actions time stamp plan possiblepermutations order confirm possible interactions them.motivates following definition:268fiModelling Mixed Discrete-Continuous Domains PlanningDefinition 19 Permutation equivalent plantraces Two plantraces 1 2 , permutation equivalent, written 1 2 1 transformed 2 permutingsubsequence contains actions.Definition 20 Plan projection projection plan, P , yields plantrace proj(P )follows. Assume plan (a sequence pairs times action instance names)given sorted time:proj(P )= proj2(0, P )proj2(t, hi)= hiproj2(t, h(t1 , a), resti) = hai + proj2(t1 , rest), = t1= ht1 t, ai + proj2(t1 , rest), otherwisePlan projection functional description process plans interpretedplantraces. process involves constructing sequence intervals collectionsactions share time execution, interleaved sequences actionsoccur together execution time. significant point makeactions given time execution, order occurplantrace determined simply (arbitrary) order listed plan.affect interpretation plan see following definition.Definition 21 Interpretation plan interpretation plan P planninginstance set P TP plantraces HI permutation equivalent proj(P ).taking plantraces permutation equivalent projection planremove dependency interpretation plan ordering actionstime stamp. objective link validity plans acceptancetraces, consider trace acceptance.Henzinger defines trace acceptance trace HA. definition equivalentfollowing:Definition 22 Trace Acceptance trace, = hai ii=1,...,n ai R acceptedH sequence r = hqi ii=0,...,n , qi states timed transitionH, and:system SHq0 Q0 ..= 1, . . . , n, qi1 qi transition SHr called accepting run H and, qn = (v, ~x), say ends state vfinal values ~x.plan contain transitions represent events. reason, makefollowing definition:Definition 23 Trace abstraction trace, , Hybrid Automaton h-events partitioned two sets, actions events E, abstracted create plantraceremoving events replacing maximal contiguous sequence numberssingle number equal sum sequence. Finally, last valuemodified trace number removed.269fiFox & Longuse definitions interpretation plantraces. avoid unnecessary multiplication terms, reuse term accepted rely context disambiguateform acceptance intend use.Definition 24 Plantrace Acceptance Given Hybrid Automaton, H, h-event setpartitioned action events E, plantrace, , accepted Htrace 0 accepted H abstraction 0 .important observe definition implies checking acceptanceplantrace could computationally significantly harder checking standard traceacceptance. test requires discovery events could completegaps actions plantrace. However, since events constrainedapplicable forced applied, provided restrict attention commuting events, problem determining plantrace acceptanceinvolve searching alternative event sequences. reasonable constraints placedkinds event cascades may interleave actions, problem checkingplantrace acceptance becomes straightforward.Finally, return plans consider plans actually valid.Definition 25 Validity Plan plan P , planning instance I, validplantraces P TP accepted Hybrid Automaton HI . plan achieves goalG every accepted trace abstraction P TP ends state satisfies G.constraint simultaneously executed actions non-mutex sufficient ensurenecessary consider one representative set permutationequivalent plantraces order confirm validity plan.definitions constructed demonstrate relationship plans, plantraces,traces accepting runs. observed definitions leave open possibilityevents trigger non-deterministic way. possibility arisesone event applicable state events commute. case,non-deterministic choice made, accepting run, applicableevents. possible action execute events statetime-slip process, process affect eventsapplied. non-deterministic choice applicable events would allow pddl+capture actions non-deterministic outcomes. purposes paper restrictattention event-deterministic planning instances.Definition 26 Event-deterministic Planning Instances pddl+ planning instance,I, event-deterministic every state HI two events, e1 e2 , applicable,transition sequences e1 followed e2 e2 followed e1 valid reachresulting state. case e1 e2 said commute.every pair events ever applicable state commute planninginstance event-deterministic. general, deciding whether planning instance eventdeterministic expensive operation entire state space must enumerated.However, much easier construct event-deterministic planning instancesnecessary consider whether pairs events commute. particular, non-mutexevents always commute.270fiModelling Mixed Discrete-Continuous Domains Planningconclude making observations relationship plansaccepting runs. Firstly, every valid plan corresponds collection accepting runslabelled transition system corresponds HA interpretationplanning instance. difference accepting runs corresponding givenplan order events actions executed given single time point.contrast, accepting runs corresponding plan.situation arises domain admits accepting runs actions occurring irrationaltime points. would possible extend plans allow irrational timestamps actions.restriction rationals based fact explicit report plan generatedplanner make use timestamps finite representation,countably many plans expressed. fact uncountably manypossible transitions based use arbitrary real time values use usplanner cannot express all. point relevance observation, discussed(Gupta et al., 1997), constructing plans execution practical interestrely measurement time arbitrary precision. Instead, appropriatelook plans form core fuzzy tube traces accepted.case, difference rational irrational timestamps becomes irrelevant, sinceirrational value lies arbitrarily close rational value, robust plan representedusing rational timestamps alone. consider important direction futureexploration, planning problems require additional specification metricsize fuzzy tube solution plan must define, traces tubehigh probability acceptance (Fox, Howey, & Long, 2005).7. Analysisprevious sections constructed semantics pddl+ mapping HybridAutomata constructed formal relationship plans traces.consequence, demonstrate general pddl+ domains provide succinct encodingscorresponding Hybrid Automata, since pddl+ model state spaceexponential size encoding.established relationship pddl+ domains Hybrid Automata,benefit large body research Hybrid Automata subclasses. One issue widely addressed boundary decidableundecidable classes Hybrid Automata boundary reinterpretedreachability question interesting subsets pddl+ language.following consider subsets pddl+ interesting sensemodelling different kinds restricted continuous temporal behaviours.7.1 Reachability within Hybrid AutomataReachability problem Hybrid Automata problem determining, given, visitsautomaton H, whether trajectory timed transition system, SHstate form (v, x). context Hybrid Automata, v typically error state,Reachability questions posed determine whether automaton safe.context planning, Reachability question equivalent Plan Existence.discussed Henzingers paper (1996), general Reachability question Hybrid Au271fiFox & Longtomata undecidable. unsurprising, since introducing metric fluents arbitrarybehaviours language results sufficient expressive power model Turing Machinecomputations. Indeed, Helmert shown (2002) even relatively simple operationsdiscrete metric variables sufficient create undecidable planning problems. However, various constraints, Reachability decidable several kinds hybrid system,including Initialised Rectangular Automata (Henzinger et al., 1998). following discussion restrict attention deterministic Initialised Rectangular Automata, focussingparticularly Timed Automata (Alur & Dill, 1994), Priced Timed Automata (Rasmussenet al., 2004) Initialised Singular Automata (Henzinger, 1996) relationshipsfragments pddl family languages.simplify definition Rectangular Automata introduce following definition:Definition 27 Interval Constraint constraint variable x form x ./ crational constant c ./ {, <, =, >, } interval constraint. conjunctioninterval constraints also interval constraint.Rectangular Automata Hybrid Automata initial, invariant flowconditions interval constraints, whose flow conditions refer variables Xwhose jump conditions conjunction interval constraints constraints formx0i = xi . Rectangular Automata may non-deterministic interval constraintsdetermine initial, flow jump conditions might determine unique valuesvariables constrain. Initialised Rectangular Automata meet additionalconstraint control switch, e, v w, f low(v)i 6= f low(w)i x0i = xiappear jump(e).Initialised Rectangular Automata important represent boundarydecidability Hybrid Automata (Henzinger et al., 1998).Since pddl deterministic language, interested deterministicversion Rectangular Automata. Singular Automaton Rectangular Automatondeterministic jumps variables finite slope (that is, flow conditions determineunique constant rate change variable). initialised continuousvariable reset every time rate change altered flow function. factvariables finite slope allows rates change modified. Initialised SingularAutomata allow modelling linear continuous change rate changemodified provided corresponding variable reset occurs. constraintprevents modelling stopwatches (Alur & Dill, 1994), ensures decidabilityReachability problem. Whilst quite expressive, automata cannot capture dynamicsarise many continuous planning domains. example, would possiblemodel effect, level water tank, adding second water supply timefilling process. According reset constraint level value wouldreset zero second water source introduced.Timed Automaton Singular Automaton every variable clock (aone-slope variable). automata used model timed behaviour expressconstraints temporal separation events (Alur & Dill, 1994). However, cannotused model continuous change quantities clocks cannot usedstore intermediate values. stopped reset zero, cannot operatememory cells. Alur Dill (1994) prove reachability decidable Timed Automata272fiModelling Mixed Discrete-Continuous Domains Planninginfinite part model (the behaviour clocks) decomposedfinite number regions. demonstrates infinite character TimedAutomata characterised underlying finite behaviour. Helmert (2002) usedsimilar regionalisation technique proving plan existence question planningmodels including certain combinations metric conditions effects remains decidable.Priced Timed Automaton Timed Automaton costs associatededges locations automaton. Costs accumulated traces enablepreference ordering traces. PTAs used solve simple Linear Programmingscheduling problems (Rasmussen et al., 2004). Costs behave like clocks exceptstopped, rates changed, without reset. retain decidabilitydespite addition cost variables use restricted: costs cannot referredjump conditions although updated following edge delay transitions.PTAs used model planning problems actions associatedlinearly changing costs. example, Airplane scheduling bench mark, planesincur cost penalties late early landing, expressed syntax pddl+solved using PTA solution techniques (Rasmussen et al., 2004). modelsrestrictive: dependence logical dynamics domain cost values cannotexpressed costs cannot, example, used keep track resource levelsplanning resources over-subscribed. However, capable expressingclass problems require modelling continuous change thereforeseen fundamental step towards modelling mixed discrete-continuous domains.Since PTAs allow modelling non-trivial planning domains continuous changebegin constructing fragment pddl+ yields state-space models exactly equivalent PTAs. remainder section discuss relationshipsricher pddl+ fragments different automata.7.2 pddl+ Priced Timed AutomataRasmussen et al. (2004) describe components Priced Timed Automaton (PTA)follows. contains set real-valued clocks, C, constraints expressedset clock constraints, B(C). set actions, Act. PTA given 5-tuple(L, l0 , E, I, P ), L finite set locations (that is, states), l0 initial location,E L B(C) Act 2C L, : L B(C) function assigning invariants locationsP : (L E) N assigns prices edges locations. edge, E = (l, b, a, r, l0 )transition locations l l0 using action a, jump condition b (overclocks) resets clocks r zero. price function represents discrete costtransitions continuous cost associated staying location.modelling arbitrary Priced Timed Automata define pddl+ fragmentrefer pddl+P . following definition fragment unique.subsets pddl+ exist expressive power, including subsets directlyrelying processes events. excluding events fragment triviallyguaranteed deterministic language.pddl+P fragment uses standard pddl+ language features, subjectfollowing constraints:273fiFox & Long1. Processes may logical preconditions exactly one process must activestate except, possibly, one special state, error.2. process must increase metric fluents rate 1, except one specialvariable, c, may increased constant rate.3. action may preconditions refer metric fluents exceptc. preconditions must appear forms (called clock constraints)conforming following: (./ xi n) (./ (- xi xj ) m) n, naturalnumbers ./ {<, , =, , >}.4. action may reset value metric fluent, c, zero. mayincrease value c constant value.5. domain may contain events whose precondition may include literals clockconstraints. effect every event must leave system special stateerror, transitions possible.6. plan metric form: (:metric minimize (c)).constraints ensure state space yielded pddl+P description,transition behaviour, equivalent (within constant multiple encoding size) PTA.cannot demonstrate direct equivalence pddl+P PTAs pddl+Pmodels exponentially compact explicit PTA corresponds.compaction similar obtained factorising PTA models (Dierks,2005). demonstrate indirect equivalence two languages Theorem 2.Definition 28 Indirectly Equivalent Expressiveness Given two languages, L1 L2 ,L1 indirectly equivalent expressive power L2 sentence, s1 , L1 definesmodel, Ms1 , L2 express Ms1 polynomial increase encoding size(in size Ms1 ) sentence, s2 , L2 expressed L1polynomial increase size encoding (in size s2 ).note definition asymmetric: sentences L1 define modelsexpressed efficiently L2 , sentences L2 efficiently expressed directlyL1 . sentences L1 might compact encodings corresponding modelstherefore cannot claim direct equivalence expressiveness L1 L2 .intentional allows us exploit pddl property compact encodinglanguage state spaces transition behaviours planning domains defines.Theorem 2 pddl+P indirectly equivalent expressive power Priced Timed Automata.proof theorem found Appendix B.Lemma 1 sentence, s, pddl+ defines transition system doublyexponential size s.274fiModelling Mixed Discrete-Continuous Domains Planningstraightforward: set literals defined pddl+ problem instanceexponential number parameters predicate highest aritystate space defines exponential size set literals.Corollary 1 Reachability pddl+P decidable.follows Theorem 2, Lemma 1 decidability PTAs (Larsen, Behrmann,Brinksma, Fehnker, Hune, Pettersson, & Romijn, 2001).pddl+P extended, remaining decidable, allowing additional metricfluents whose (non-continuous) behaviour constrained according one decidablesubsets identified Helmert (2002), provided fluents distinct clockcost variables.similarly define language fragment expressive power equivalent Initialised Singular Automata. Initialised Singular Automata represent expressiveform deterministic automaton decidable Reachability problem. constraintslimit extent reason dependence behaviour temporalmetric quantities.Initialised Singular Automaton continuous change restricted variablesslope 1, contrast clocks Timed Automata. variables finite slope (thatis, rates change take one finite set different values), mustinitialised given constant whenever rates change altered. valuesvariables referred jump conditions automaton.modelling Initialised Singular Automata define pddl+ fragmentrefer pddl+ISA . fragment contains syntactic components pddl+Psubject slightly different constraints:1. Processes may logical preconditions exactly one process must activestate except, possibly, one special state, error.2. process must increase metric fluents constant rates.3. action may preconditions refer metric fluents.preconditions must appear forms (called clock constraints): (./ xi n)(./ (- xi xj ) m) n, natural numbers ./ {<, , =, , >}.4. action may reset value metric fluent constant natural numbervalue. action causes transition state new process activemust also reset metric fluents whose rates change different newprocess.5. domain may contain events whose precondition may include literals clockconstraints. effect every event must leave system special stateerror, transitions possible.275fiFox & Longfragment contain special plan metric: problems pddl+ISA interestplan existence problem.Theorem 3 pddl+ISA indirectly equivalent expressive power Initialised SingularAutomata.proof result analogous Theorem 2. constraints ensurebehaviour Initialised Singular Automata captured language language contains expressions effectively modelled within Initialised SingularAutomata.interest review domains considered paper, planetarylander domain accelerating vehicle domain, respect modelling powerpddl+P pddl+ISA . first instance, since domains involve non-linearchange, power generation state charge curves distance travelledvehicle acceleration non-zero, clear domains lie outsidemodelling power constrained languages. feasible consider approximatingnon-linear behaviour cases. example, generation curve might approximated small set linear functions (with corresponding loss opportunitiesexploit margins model). generation curve tied absolute pointstimeline values points linear functions would requiredmeet order approximate original curve identified advance. ordercreate reasonable approximation, functions would require different slopes (shallowstart, steeper shallower again, approximate first half bellcurve), cannot achieved using pddl+P , since allows clock variables.pddl+ISA powerful enough express differently sloped linearly changing variableskind. Unfortunately, state charge curve, even approximations, beyondexpressive power either language. pddl+ISA problem mustmemory old state charge slope charge curve changes.pddl+P cost variable could used model state charge, sincecapacity used memory different rates change. However,cost variable cannot used preconditions actions, means attemptmodel battery way would force decoupling battery statecharge actions use power. realistic model battery managementlies outside power pddl+P pddl+ISA .However, interesting problems involving continuous change perfectly amenable,Dierks (2005) Behrmann et al. (2005) shown. Aircraft Landing problem (Beasley, Krishnamoorthy, Sharaiha, & Abramson, 2000) modelled PTAone source continuous change modelled cost variable.domain, number aircraft must land single airport, sometimeearliest latest landing time close target time possible. earliest, latesttarget times defined aircraft. cost associated problemcharge associated landing plane early late, charge decreaseslinearly earliest landing time towards target time increases linearlytarget latest landing time. behaviour aircraft dependentvalue cost variable, although quality landing schedule determined276fiModelling Mixed Discrete-Continuous Domains PlanningDeterministic Hybrid AutomataHybrid AutomataLinear AutomataPDDL+UndecidableDeterministic Linear AutomataPDDL+metric fluentsbesides clockcost variablessatisfy oneHelmertsconstraint sets.#t linRectangular AutomataPDDL+ ISAInitialised Singular AutomataPDDL+ PTAPriced Timed AutomataDeterministic Timed AutomataDPDDLTT+SEDPDDLTTDPDDLSEInitialised Rectangular AutomataDecidableNondeterministic TAFinite AutomataDeterministicNondeterministicDPDDLNPDDLFigure 14: Mapping pddl fragments corresponding deterministic automata. pddlfamily deterministic languages. However, extension support temporal,numeric logical non-determinism would give access automataright hand side figure.it. Aircraft Landing problem optimisation problem quantityoptimized changes continuously time.Figure 14 present formal relationships pddl+ fragments classeshybrid automata. bottom half figure concerns decidable fragments pddl+whilst top half concerns undecidable fragments. figure, dpddl pddl+fragment fixed duration durative actions allowed (and events processes),restricted start effects npddl (non-temporal pddl) fragmentoccur. Initial effects significant makepossible create domains problems solved exploitingconcurrency. reason effects restricted end pointsactions, always possible find sequential plan solve problemconcurrent solution. cases concurrency required solve problem,durative actions sequentialised durations simply summed discrete endeffects. actions initial effects possible effectsadded start action deleted end, creating windows opportunityactions must fitted concurrently exploit effects.concurrency matters necessary monitor passage time requirespower timed automata. language variants show follows:277fiFox & LongdpddlSE allows start effects, raising need concurrency explainedabove.dpddlT , dpddl together use plan metrics using termtotal-time: also requires concurrency since time required plan dependsextent non-interfering actions selected reduce make-spanplan.dpddlT +SE dpddl together total-time allowing use starteffects.pddl+#t lin pddl+ restricted linear rates change metric fluents.restriction insufficient ensure decidability, use linear rates changemakes possible apply linear constraint solvers problems. consequence,subset pddl+ captures continuous planning problems planningtechnology already applied (Shin & Davis, 2005; McDermott, 2003b; Wolfman & Weld, 1999; Penberthy & Weld, 1994) (in first these, particular,models actually expressed pddl+).bottom half figure npddl dpddl include metric conditions effects constrained occur decidable combinations defined Helmert (2002). Helmertdemonstrated adding (discrete) metric effects conditions propositional pddlfragment already adds dramatically expressive power language. particular,quite limited set (discrete) metric effects conditions decidability alreadylost. However, restrictions use metric variables leave decidablefragment. order extensions discussing retain decidability must not,course, sacrifice adopting rich set discrete metric effects preconditions.lower half figure work within constraints. resultsextend Helmerts introducing continuous metric change, demonstrating boundariesretain decidability. top half figure constraints lifted. lefthand half figure concerns deterministic models: pddl+ language expressingdeterministic domains, restricted attention side. right-hand halfconcerns non-deterministic variants models considered. includeprovide general context results.8. Related Worksection discuss relationship pddl+ several related formalisms literature. addition, consider extent pddl+ addressesinadequacies pddl2.1 terms expressive power convenience. paperpddl2.1 published Journal Artificial Intelligence Research Special Issue3rd IPC (Fox & Long, 2003). editors special issue invited five influentialmembers planning community contribute short commentaries language, indicating support for, objections to, choices made modelling timetime-dependent change. Fahiem Bacchus, Mark Boddy, Hector Geffner,Drew McDermott David Smith. discuss parts commentariesrelevant modelling durative behaviour continuous change explain278fiModelling Mixed Discrete-Continuous Domains Planningbelieve pddl+ addresses issues raised. interesting note manyobjections raised commentaries addressed start-process-stop modelpddl+. begin considering commentaries go discuss relatedformalisms.8.1 pddl+ versus pddl2.1commentators invited comment decisions made pddl2.1,limitations impose temporal domain modelling. issues raisedcommentators addressed pddl+. section identify issuesraised relevant development pddl+ explain think pddl+resolves them.Bacchus (2003) proposes alternative continuous durative actions pddl2.1similarities start-process-stop model pddl+. approaches recognise durative activity sometimes best modelled using underlying, interruptibleprocess. Whilst Bacchus proposes initiation running processeswrapped durative actions conditional effects, pddl+ achieves effectcleanly separated continuous autonomous processes events. pddl+ expressbehaviours dependent continuous variables time, Bacchus proposal limited purely time-dependent processes (he allow interacting processesconsider forms continuous change).McDermott Boddy consistently supported use autonomous processesrepresentation continuous change. commentary McDermott (2003a) identifies weaknesses durative action-based representation change arguescontinuous durative actions pddl2.1, allow modelling duration inequalities time-dependent effects, headed extinction favour straightforwardautonomous processes. start-process-stop model pddl+ replaces continuousdurative actions pddl2.1 constructs fully exploit autonomous processes support richer natural models continuous domains. shownpaper, modelling events adds expressive power Boddy anticipates (Boddy, 2003).commentary Smith (2003) raises philosophical objections durativeaction model pddl2.1 argues restrictive support convenient modelsinteresting durative behaviours. pddl2.1 actions specify effects startend points, although conditions required remain invariant wholedurative interval. Smith proposes durative action model richer proposedpddl2.1, effects occur arbitrary points within durative intervalconditions might also required hold identified timepoints startend action. Although, principle, possible decompose pddl2.1 durativeactions sequences actions achieve effects, Smith correctly observeswould generally result inconvenient impractical models. argues actionrepresentations encapsulate many consequences application wayfrees planner burden reasoning minutiae. observescomputational effort involved, stringing together sub-actions requiredrealise complex activity, would normally prohibitive.279fiFox & Longagree pddl2.1 durative action model restrictive forcing effectsoccur end points actions. Smiths rich durative model seenencapsulating effects starting ending one processes, togethereffects processes, action-based representation. committing activitycertain amount time actions abstract time-dependent details avoidneed planner reason interactions. simplificationdoubt sufficient many practical contexts (and indeed, sufficientsatellite domain discusses commentary). might indeed interestprovide representations abstractions start-process-stop model.point goes heart contribution paper: providedset primitives building modelling constructs. providing formal semanticsprimitives provided way interpreting abstract constructs builtprimitives. argue that, combination natural modelling concepts like fixedlength durative actions, start-process-stop primitives provide usable planning domaindescription language. However, concerned formal underpinningslanguage rather modelling convenience provides. agree Smithabstract modelling constructs, built primitives, might enhance modellingexperience way abstract programming constructs enhance programmingexperience programming machine code level.8.2 Related Formalismsnumber representational formalisms proposed expressing temporalmetric activity planning. closest recent counterpart pddl+ modellinglanguage, Opt, Optop planner (McDermott, 2004). language developed independently, Drew McDermott, time pddl+ first proposed,similarities Opt pddl+ due discussions developerstwo languages time. Opt pddl-like dialect strongly influencedwork McDermott authors pddl family languages. Opt supports autonomous processes run preconditions satisfiedcontrol planner. Unlike pddl+, Opt contain explicit events embedded inside processes run long preconditions remaintrue. Opt also retains durative actions alternative explicit modelling continuous change models timed initial literals derived predicates. planner, Optop,developed McDermott (McDermott, 2005) subset Opt models linearcontinuous change. Planners already exist handling interesting subsets pddl+,directly (Shin & Davis, 2005) indirectly (Dierks, 2005). later case, languagePTA solver UPPAAL-cora (Behrmann et al., 2005) used, modellingpower equivalent pddl+P .semantics Opt processes given terms infinitely many situations occurring within finite time, associated different fluent values continuouslychanging variables. Opt pddl+ fundamentally related Reiters work continuous dynamics situation calculus (Reiter, 2001). McDermott developed situationcalculus semantics Opt, whereas constructed explicit relationshippddl+ theory Hybrid Automata order make explicit relationship be280fiModelling Mixed Discrete-Continuous Domains Planningtween pddl+ planning control theory. similar relationship drawn CIRCAarchitecture (Musliner, Durfee, & Shin, 1993), integrates planning real timecontrol using probabilistic timed automata.qualitative reasoning community proposed hybrid state-based models dynamic physical systems (Forbus, 1984; de Kleer & Brown, 1984; Kuipers, 1984). Kuipers (1984)considers qualitative simulation physical systems described terms continuouslyvarying parameters. proposes qualitative representation differential equationsgoverning behaviour system, expressed systems constraints keyparameters describing state system discrete points time. representation supports commonsense reasoning evolution physical systemsquantitative reasoning would computationally prohibitive.formalisms developed within fields planning reasoningaction change. Temporal resource management provided HSTS Europa (Frank & Jonsson, 2003; Jonsson, Morris, Muscettola, Rajan, & Smith, 2000), IxTeT (Laborie & Ghallab, 1995), CIRCA (Musliner et al., 1993), LPSAT (Wolfman & Weld,1999), Zeno (Penberthy & Weld, 1994) HAO* (Benazera, Brafman, Meuleau, Mausam,& Hansen, 2005) mention systems planning literature.part, systems plan-generation systems using representation languages supportrestricted modelling continuous change metric time. contrast, pddl+ proposes unrestricted representation language, semantics, without describing specificsearch algorithms construction plans. Finding efficient algorithms reasoningpddl+ domains separate topic, already progress (Shin& Davis, 2005; Dierks, 2005; McDermott, 2004) mentioned above. course, demands practical planning restrict ambitious one using pddl+ modelreal planning applications, reason impose artificial restrictionsexpressiveness language.key objective HSTS (Heuristic Scheduling Testbed System) (Muscettola, 1993)maintain much flexibility possible development plan, planrobustly executed face unexpected events environment. HSTS embodiesclose integration planning scheduling, enabling representation complexresource-intensive planning problems dynamic constraint satisfaction problems (DCSP).DDL, Domain Description Language HSTS, distinction made domainattributes (ie: components domain exhibit behaviours) states,activity attribute represented separate time line. distinctionmade states actions: actions added time lines inserting tokensrepresenting predicates holding flexible intervals time. token associatedset compatibilities explain constrained respect activitiestime lines. Compatibilities express relations similarTIMELOGIC constructs Allen Koomen (Allen & Koomen, 1983). Choicesdevelopment plan explored heuristic search inconsistenciesDCSPs representing corresponding partial plans result pruning.Events kind provided pddl+ expressed disjuncts compatibilityconstraints associated actions produce them. example, actionopening water source fill tank would expressed token constrained meeteither event flooding interval water source closed. Then, whether281fiFox & Longtank floods depends long interval filling lasts, floodingevent avoided expressing constraint end water level exceedstank capacity. process water level increases tank fillingexpressed using sequence compatibilities, allow variables take arbitrarily manycontiguous values sequence interval. actual water level endinterval identified, using linear programming techniques, one valuessequence. notion procedural reasoning (Frank, Jonsson, & Morris, 2000)introduced framework support efficient reasoning rates changecontinuous variables interactions within plan.HSTS therefore supports representation interaction actions, processesevents exploitation development flexible plan/schedules.respect, DDL somewhat expressive pddl+ flexibilitytemporal database. Allowing intervals last amount time specified lowerupper bound introduces bounded temporal flexibility reasoning framework.IxTeT (Laborie & Ghallab, 1995) partial order causal link planner usestask representation similar discrete durative actions pddl2.1. keydifference pddl2.1 discrete durative actions restricted representationstep function change start end points interval, whilst IxTeT taskseffects specified point interval. allows piecewise continuous changerepresented. Continuous change cannot modelled (except means smallintervals piecewise representation appropriate function). Furthermore,durative actions IxTeT fixed duration endure amount timewithin specified interval. Thus, IxTeT also models bounded temporal flexibility ableconstruct flexible plans. IxTeT continues traditions POCL planning (McAllester& Rosenblitt, 1991; Penberthy & Weld, 1992) plan built partiallyordered graph activities complex flexible temporal constraints. Simple TemporalNetwork (Dechter, Meiri, & Pearl, 1991) used determine consistency giventemporal constraint set. STNs, also used HSTS, powerful technique temporalreasoning restricted reasoning discrete time points.important difference modelling continuous process changecomputing values continuous-valued variables planning. systems,continuous change explicitly modelled, trajectories constructedvariables throughout timeline plan. systems, continuous processesdetermine behaviour metric variables implicit, values variablesavailable, computation, certain times along trajectories.Zeno (Penberthy & Weld, 1994) uses explicit representation processes differentialequations solves determine whether temporal metric constraintsproblem met partial plan (and identify values continuous-valuedresources action preconditions require them). LPSAT (Wolfman & Weld, 1999) alsouses explicit model processes govern continuous change (although uselinear constraint solving limits linear processes). different approach,processes explicitly modelled, seen HAO* (Benazera et al., 2005). Here,although continuous-valued resources modelled, way change timenot. different possible metric outcomes action discretised associatedprobabilities. Plan construction seen terms policy construction within282fiModelling Mixed Discrete-Continuous Domains Planninghybrid MDP framework. Time managed way metricresource (a certain action take time units probability 1 p) needmodel passage time directly. Whilst time-dependent nature metric effectsactions captured way, actions cannot interact passage timeorder exploit control episodes continuous change.9. Conclusionspaper presented planning domain description language, pddl+,supports modelling continuous dynamics. provided formal semanticsspecifying mapping pddl+ constructs deterministic hybrid automata.also related fragments pddl+ automata different levels expressivepower. goal develop pddl extension properly models passagetime, continuous change quantities time, support modelling mixeddiscrete-continuous planning domains.primary goal establish baseline mixed discrete-continuous modelling, provide formal semantics resulting language. Additionally wantedmake strong connection planning automata theory order facilitatecross-fertilisation ideas planning real-time systems modelchecking communities. explored relationship fragments pddl+automata-theoretic models boundary decidability order better understand gained lost expressive power addition removal modellingconstructs.focussed make pddl+ convenient modelling modelling convenience related expressive power. agree might desirablebuild abstract modelling constructs top baseline language order enhancemodelling convenience. Nevertheless, pddl+ used experimental purposes, development technology mixed discrete-continuous planning,presented usable language builds directly upon current standard modellinglanguage temporal domains. presented two examples domain modelsexploit processes, events durative actions succinct representation continuouschange. Future work consider powerful modelling constructs might builtsupport convenient modelling larger scale mixed discrete-continuous domains.Acknowledgmentswould like extend special thanks David Smith detailed critical analysisearlier drafts paper many insightful comments suggestions. wouldalso like thank Subbarao Kambhampati anonymous referees helping usorganise clarify presentation work, Jeremy Frank, Stefan Edelkamp,Nicola Muscettola, Drew McDermott, Brian Williams Mark Boddy, helpedus refine sharpen ideas formulations.283fiFox & LongAppendix A. pddl2.1 Core Definitionsappendix present definitions (Fox & Long, 2003) relevantpaper, ease reference. detailed discussions definitionsrelationships see original source.Core Definition 1 Simple Planning Instance simple planning instance definedpair= (Dom, P rob)Dom = (F s, Rs, As, arity) 4-tuple consisting (finite sets ) function symbols,relation symbols, actions (non-durative), function arity mapping symbolsrespective arities. P rob = (Os, Init, G) triple consisting objectsdomain, initial state specification goal state specification.primitive numeric expressions planning instance, P N Es, terms constructed function symbols domain applied (an appropriate number )objects drawn Os. dimension planning instance, dim, numberdistinct primitive numeric expressions constructed instance.atoms planning instance, Atms, (finitely many) expressions formedapplying relation symbols Rs objects Os (respecting arities).Init consists two parts: Initlogical set literals formed atoms Atms.Initnumeric set propositions asserting initial values subset primitivenumeric expressions domain. assertions assign single primitivenumeric expression constant real value. goal condition propositioninclude atoms formed relation symbols objects planning instancenumeric propositions primitive numeric expressions numbers.collection action schemas (non-durative actions) expressed syntaxpddl. primitive numeric expression schemas atom schemas used actionschemas formed function symbols relation symbols (used appropriatearities) defined domain applied objects Os schema variables.Core Definition 2 Logical States States Given finite collection atomsplanning instance I, AtmsI , logical state subset AtmsI . planning instancedimension dim, state tuple (R, P(AtmsI ), Rdim) R = R {}denotes undefined value. first value time state, secondlogical state third value vector dim values dim primitive numericexpressions planning instance.initial state planning instance (0, Initlogical , ~x) ~x vector valuesR corresponding initial assignments given Initnumeric (treating unspecifiedvalues ).Core Definition 3 Assignment Proposition syntactic form numeric effectconsists assignment operator (assign, increase, decrease, scale-up scale-down),one primitive numeric expression, referred lvalue, numeric expression (whicharithmetic expression whose terms numbers primitive numeric expressions),referred rvalue.284fiModelling Mixed Discrete-Continuous Domains Planningassignment proposition corresponding numeric effect formed replacingassignment operator equivalent arithmetic operation (that (increase p q)becomes (= p (+ p q)) on) annotating lvalue prime.numeric effect assignment operator either increase decreasecalled additive assignment effect, one operator either scale-up scale-downcalled scaling assignment effect others called simple assignment effects.Core Definition 4 Normalisation Let planning instance dimension dimIletindexI : P N EsI {1, . . . , dim}(instance-dependent) correspondence primitive numeric expressionsinteger indices elements vector dimI real values, Rdim.normalised form ground proposition, p, defined result substituting primitive numeric expression f p, literal XindexI (f ) . normalisedform p referred N (p). Numeric effects normalised first convertingassignment propositions. Primed primitive numeric expressions replaced~ used represent vector hX1 . . . Xn i.corresponding primed literals. XCore Definition 5 Flattening Actions Given planning instance, I, containing action schema AsI , set action schemas f latten(A), defined set S,initially containing constructed follows:contains action schema, X, conditional effect, (when P Q), createtwo new schemas copies X, without conditional effect, conjoincondition P precondition one copy Q effects copy,conjoin (not P) precondition copy. Add modified copies S.contains action schema, X, formula containing quantifier, replaceX version quantified formula ( Q ( var1 . . . vark ) P) Xreplaced conjunction (if quantifier, Q, forall) disjunction (if Qexists) propositions formed substituting objects variablevar1 . . . vark P possible ways.steps repeated neither step applicable.Core Definition 6 Ground Action Given planning instance, I, containing actionschema AsI , set ground actions A, GAA , defined setstructures, a, formed substituting objects schema variables schema,X, f latten(A) components are:Name name action schema, X, together values substitutedparameters X forming a.Prea , precondition a, propositional precondition a. set groundatoms appear Prea referred GPrea .Adda , positive postcondition a, set ground atoms assertedpositive literals effect a.285fiFox & LongDela , negative postcondition a,is set ground atoms assertednegative literals effect a.NPa , numeric postcondition a, set assignment propositions corresponding numeric effects a.following sets primitive numeric expressions defined ground action,GAA :La = {f |f appears lvalue a}Ra = {f |f PNE rvalue appears P rea }La = {f |f appears lvalue additive assignment effect a}Core Definition 7 Valid Ground Action Let ground action. validprimitive numeric expression appears lvalue one simple assignmenteffect, one different type assignment effect.Core Definition 8 Updating Function Let valid ground action. updatingfunction composition set functions:dim{NPFp : RdimR | p N P }NPFp (~x) = ~x0 primitive numeric expression x0i appear~ 0 := ~x0 , X~ := ~x] satisfied.lvalue N (p), x0i = xi N (p)[X~ 0 := ~x0 , X~ := ~x] read result normalising pnotation N (p)[X~ 0 actual values ~xsubstituting vector actual values ~x0 parameters X~formal parameters X.Core Definition 9 Satisfaction Propositions Given logical state, s, groundpropositional formula pddl2.1, p, defines predicate Rdim, Num(s, p), follows:Num(s, p)(~x)iff~ := ~x]|= N (p)[X|= q means q true interpretation atom, a,numeric comparison, assigned true iff s, numeric comparison interpretedusing standard equality ordering reals logical connectives given usualinterpretations. p satisfied state (t, s, ~x) Num(s, p)(~x).Comparisons involving , including direct equality two values undefined, enclosing propositions also undefined satisfied state.Core Definition 10 Applicability Action Let ground action. applicable state P rea satisfied s.286fiModelling Mixed Discrete-Continuous Domains PlanningAppendix B. Proof theoremTheorem 2 pddl+P indirectly equivalent expressive power Priced Timed Automata.begin showing arbitrary PTA expressed pddl+P domainwithout blow-up size encoding. show converse alsocase.Given PTA hL, l0 , E, I, P construct pddl+P model follows. edgee = (li , g, a, r, lj ), g clock constraint, action r subset clockvariables reset edge, construct following instantaneous action schema, calledtransition action, models instantaneous transition li lj .(:action transitione:parameters ():precondition (and (in li ) g):effect (and {x r (assign (x) 0)}(increase (c) P(e))(not (in li ))(in lj )))also construct, location li , following process schema:(:process process-locationli:parameters ():precondition (in li ):effect(and (increase (c) (* #t P(li )){x C (increase (x) (* #t 1))}))Finally, construct event location:(:event event-locationli:parameters ():precondition (and (in li ) (not (I(li )))):effect(not (in li )))initial state specifies clock variable cost variable starts value0. asserts (in l0 ). special error state empty state (if event triggeredremove current location proposition, leaving impossible progress).Note domain valid pddl+P . two actions applied parallelsystem ever satisfy one condition form (in li ).construction correctly capture PTA, remains shown PTAtrajectory corresponds pddl+P plan domain plan correspondstrajectory.Consider (valid) PTA trajectory,12(l0 , u0 )(l1 , u1 ). . . (ln , un )287fiFox & Longui clock valuation transition may either edgepositive time delay. case time delay transitions, location remainsclock valuation updated delay duration, edge transitions locationupdated clock valuation remains same. trajectory mapped plancreating action instance edge transition (using corresponding actionpddl+P description). action set applied time correspondingsum time delay transitions precede transition trajectory.valid plan since processes active exactly times pddl modelcorresponding time transitions trajectory.Similarly, given valid pddl plan domain, plan defines trajectorymapping instantaneous actions corresponding edge transitionsgaps time delay transitions. trajectory valid oneconstruction actions process models. Note valid plan triggerevent, since leave system state cannot progressed, preventingsatisfaction goal. means invariant conditions location alwaysmaintained.consider opposite direction proof: pddl+P planning instancesyield state space transition models expressed PTAs constantfactor transformation. observe constraints pddl+P language ensuresclock variables cost variable distinguished behave exactly requiredPTA. ground state space, states correspond directly locations PTAlegal actions transition states correspond edges correspondingPTA. exception event transitions leading exceptional error state,edge pddl+P transition system will, constraints defining language, alwayscorrespond instantaneous action action determines clock constraintsreset effects corresponding PTA edge. Exactly one process active state,causes variables behave clocks (except cost variable). events governinvariants states, causing violation invariant condition triggertransition error state.correspondence trajectories PTA defined way planspddl+P transition system immediate, subject observations madeabove.Appendix C. Planetary Lander Domain pddl+following domain encoding shows pddl+ model Planetary Lander problemdiscussed Section 2.2. According implementation details systems designed handlepddl+ models, might necessary introduce events manage transitioncharging discharging, imprecision system measuringvalues demand supply might lead difficulties boundary supplydemand equal.(define (domain power)(:requirements :typing :durative-actions :fluents :time288fiModelling Mixed Discrete-Continuous Domains Planning:negative-preconditions :timed-initial-literals)(:types equipment)(:constants unit - equipment)(:predicates (day) (commsOpen) (readyForObs1) (readyForObs2)(gotObs1) (gotObs2)(available ?e - equipment))(:functions (demand) (supply) (soc) (charge-rate) (daytime)(heater-rate) (dusk) (dawn)(fullTime) (partTime1) (partTime2)(obs1Time) (obs2Time) (obs1-rate) (obs2-rate)(A-rate) (B-rate) (C-rate) (D-rate) (safeLevel)(solar-const))(:process charging:parameters ():precondition (and (< (demand) (supply)) (day)):effect (and (increase (soc) (* #t (* (* (- (supply) (demand))(charge-rate))(- 100 (soc)))))))(:process discharging:parameters ():precondition (> (demand) (supply)):effect (decrease soc (* #t (- (demand) (supply)))))(:process generating:parameters ():precondition (day):effect (and (increase (supply)(* #t (* (* (solar-const) (daytime))(+ (* (daytime)(- (* 4 (daytime)) 90)) 450))))(increase (daytime) (* #t 1))))(:process night-operations:parameters ():precondition (not (day)):effect (and (increase (daytime) (* #t 1))(decrease (soc) (* #t (heater-rate)))))(:event nightfall:parameters ():precondition (and (day) (>= (daytime) (dusk))):effect (and (assign (daytime) (- (dawn)))(not (day)))289fiFox & Long)(:event daybreak:parameters ():precondition (and (not (day)) (>= (daytime) 0)):effect (day))(:durative-action fullPrepare:parameters ():duration (= ?duration (fullTime)):condition (and (at start (available unit))(over (> (soc) (safelevel)))):effect (and (at start (not (available unit)))(at start (increase (demand) (A-rate)))(at end (available unit))(at end (decrease (demand) (A-rate)))(at end (readyForObs1))(at end (readyForObs2))))(:durative-action prepareObs1:parameters ():duration (= ?duration (partTime1)):condition (and (at start (available unit))(over (> (soc) (safelevel)))):effect (and (at start (not (available unit)))(at start (increase (demand) (B-rate)))(at end (available unit))(at end (decrease (demand) (B-rate)))(at end (readyForObs1))))(:durative-action prepareObs2:parameters ():duration (= ?duration (partTime2)):condition (and (at start (available unit))(over (> (soc) (safelevel)))):effect (and (at start (not (available unit)))(at start (increase (demand) (C-rate)))(at end (available unit))(at end (decrease (demand) (C-rate)))(at end (readyForObs2))))(:durative-action observe1:parameters ():duration (= ?duration (obs1Time)):condition (and (at start (available unit))(at start (readyForObs1))(over (> (soc) (safelevel)))290fiModelling Mixed Discrete-Continuous Domains Planning(over (not (commsOpen)))):effect (and (at start (not (available unit)))(at start (increase (demand) (obs1-rate)))(at end (available unit))(at end (decrease (demand) (obs1-rate)))(at end (not (readyForObs1)))(at end (gotObs1))))(:durative-action observe2:parameters ():duration (= ?duration (obs2Time)):condition (and (at start (available unit))(at start (readyForObs2))(over (> (soc) (safelevel)))(over (not (commsOpen)))):effect (and (at start (not (available unit)))(at start (increase (demand) (obs2-rate)))(at end (available unit))(at end (decrease (demand) (obs2-rate)))(at end (not (readyForObs2)))(at end (gotObs2)))))Appendix D. Durative Actions pddl+syntax durative actions seen purely syntactic convenience. ordersupport view, durative actions must mapped directly equivalent startprocess-stop representation using basic syntax pddl+. reason performingmapping order give durative actions semantics terms underlyingstructures pddl+, given meaning terms hybrid automatadiscussed Section 6. mapping follows.Consider following generic structure pddl2.1 durative action, excluding useduration inequalities continuous effects. Conditional effects ignored, sincehandled flattening actions described Core Definition 5. complicationconditional effects combine initial final conditions discussed (Fox & Long,2003) affect basic principles demonstrate translation givehere. Similarly, convenience, consider duration constraints referring endstate extension treatment manage constraints straightforward.(:durative-action name:parameters (~p):duration (= ?duration Dur[~p]):condition (and (at start P reS ) (at end P reE ) (over Inv)):effect (and (at start P ostS )(at end P ostE [?duration])))construct following structures pddl+:291fiFox & Long(:action name-start:parameters (~p):precondition (and P reS (not (name clock started p~))):effect (and P ostS(name clock started p~)(assign (name clock p~) 0)(assign (name duration p~) Dur[~p])(increase (clock count) 1))(:process name-process:parameters (~p):precondition (name clock started p~):effect (increase (name clock p~) (* #t 1))(:event name-failure:parameters (~p):precondition (and (name clock started p~)(not (= (name clock p~) (name duration p~)))(not Inv)):effect (assign (name clock p~) (+ (name duration p~) 1)))(:action name-end:parameters (~p):precondition (and P reE (name clock started p~)(= (name clock p~) (name duration p~))):effect (and P ostE [(name duration p~)](not (name clock started p~))(decrease (clock count) 1)))complete transformation, initial state (= (clock count) 0) addedgoal condition (= (clock count) 0) added it.Note clock uniquely determined name arguments durativeaction, clock shared different durative actions. Also noteone action start clock one terminate it. planmakes use durative action transformed domain durative actionsimulated actions start stop clock. order actions executesuccessfully conditions must identical stipulated durative actioneffects equivalent original durative action. Furthermore, end actionexecuted clock reached correct duration value (which recordedstart). clock driven process active start actionexecuted end action executed. event used monitorinvariant conditions. ever invariant becomes false clock runningevent sets clock duration durative action. makesimpossible complete action terminate clock, valid execution traceconstructed achieve goal event triggered. Every time clock292fiModelling Mixed Discrete-Continuous Domains Planningstarts count incremented decremented clock stops. count mustzero end, meaning every clock must stopped therefore every durativeaction must ended plan complete.duration action managed using metric fluent store durationoutset order use value conclusion action. value fixedconstant simplified replacing metric fluent appropriateconstant.Packaging actions, events processes durative action abstracts detailsinterval ends whether action event. example, durativeaction used represent activity filling bath, end point representaction turning taps, whilst durative action representing ball dropped,end action event ball landing. However, syntacticdifference structures encoding examples allows distinctiondrawn end point action one event. mappingdurative actions actions, processes events requires arbitrary decisionmade handle end points durative actions. chosen useactions, alternative formulation possible using events.mapping converts every durative action family pddl+ constructs showntwo actions start end interval, process execute interval,and monitoring event invariant. action always used endinterval planner must always choose apply order obtain goal state. finalplan terminating action appear, chosen planner, even though applicationfact forced, point application must consistent duration constraintoriginal durative action. Thus, although planner free choose whetherapply action, order construct valid plan forced apply actionpoint exactly meets appropriate temporal constraints. course, end pointssimulated durative actions trivially post-processed make plan containingdurative actions instead underlying components.ReferencesAllen, J., & Koomen, J. A. (1983). Planning Temporal World Model. ProceedingsEigth International Joint Conference Artificial Intelligence, pp. 741747.Alur, R., & Dill, D. L. (1994). Theory Timed Automata. Theoretical Computer Science,126, 183235.Androulakis, I. P. (2001). MINLP: Branch Bound Methods. Floudas, C. A., &Pardalos, P. M. (Eds.), Encyclopaedia Optimisation, Vol. 3, pp. 325331. KluwerAcademic.Aylett, R., Soutter, J., Petley, G., Chung, P., & Edwards, D. (2001). Planning plant operating procedures chemical plant. Engineering Applications Artificial Intelligence,14(3).Bacchus, F. (2003). power modelinga response PDDL2.1. Journal AI Research, 20, 125132.293fiFox & LongBeasley, J., Krishnamoorthy, M., Sharaiha, Y., & Abramson, D. (2000). Scheduling AircraftLandings: Static Case. Transportation Science, 34 (2), 180197.Behrmann, G., Larsen, K., & Rasmussen, J. (2005). Optimal Scheduling Using PricedTimed Automata. SIGMETRICS Perform. Eval. Rev., 32 (4), 3440.Benazera, E., Brafman, R., Meuleau, N., Mausam, & Hansen, E. A. (2005). AO*Algorithm Planning Continuous Resources. Workshop PlanningUncertainty Autonomous Systems, associated International ConferenceAI Planning Scheduling (ICAPS).Benders, J. F. (1962). Partitioning Procedures Solving Mixed-Variables ProgrammingProblems. Numerische Mathematik, 4, 238252.Blake, O., Bridges, J., Chester, E., Clemmet, J., Hall, S., Hannington, M., Hurst, S., Johnson, G., Lewis, S., Malin, M., Morison, I., Northey, D., Pullan, D., Rennie, G., Richter,L., Rothery, D., Shaughnessy, B., Sims, M., Smith, A., Townend, M., & Waugh, L.(2004). Beagle2 Mars: Mission Report. Lander Operations Control Centre, NationalSpace Centre, University Leicester.Boddy, M. (2003). Imperfect match: PDDL2. real applications. Journal AI Research,20, 133137.Boddy, M., & Johnson, D. (2002). new method solution large systems continuous constraints. Proceedings 1st International Workshop Global ConstrainedOptimization Constraint Satisfaction (COCOS-02).Boddy, M., & Johnson, D. (2004). Integrated planning scheduling petroleum refinery operations. Proceedings ICAPS Workshop Integrating PlanningScheduling (WIPIS).de Kleer, J., & Brown, J. S. (1984). Qualitative Physics based Confluences. ArtificialIntelligence, 24, 783.Dechter, R., Meiri, I., & Pearl, J. (1991). Temporal constraint networks. Artificial Intelligence, 49.Dierks, H. (2005). Finding Optimal Plans Domains Restricted Continuous EffectsUPPAAL-cora. First Workshop Validation Verification Planning,ICAPS-05.Edelkamp, S. (2003). Promela Planning. Proceedings 10th International SPIN Workshop Model Checking Software, pp. 197212.Forbus, K. (1984). Qualitative Process Theory. Artificial Intelligence, 24, 85168.Fox, M., Howey, R., & Long, D. (2005). Exploration Robustness Plans. WorkshopVerification Validation Model-based Planning Scheduling Systems, associated International Conference AI Planning Scheduling (ICAPS)).Fox, M., Howey, R., & Long, D. (2006). Exploration Robustness Plans. Proceedings 21st National Conference Artificial Intelligence (AAAI-06).Fox, M., & Long, D. (2003). PDDL2.1: Extension PDDL Expressing TemporalPlanning Domains. Journal AI Research, 20, 61124.294fiModelling Mixed Discrete-Continuous Domains PlanningFox, M., & Long, D. (2004). Investigation Expressive Power PDDL2.1.Proceedings Sixteenth European Conference Artificial Intelligence.Frank, J., & Jonsson, A. (2003). Constraint-based Attribute Interval Planning. JournalConstraints, 8 (Special Issue Constraints Planning)(4), 339364.Frank, J., Jonsson, A., & Morris, P. (2000). Reformulating Planning Dynamic Constraint Satisfaction (Extended Abstract). Symposium Abstraction, Reformulation Approximation (SARA).Grossmann, I. E. (2002). Review Nonlinear, Mixed-Integer Disjunctive ProgrammingTechniques. Optimization Engineering, 3, 227252.Gupta, V., Henziner, T., & Jagadeesan, R. (1997). Robust Timed Automata. HART97:Hybrid Real-time Systems, LNCS 1201, pp. 331345. Springer-Verlag.Haroud, D., & Faltings, B. (1994). Global Consistency Continuous Constraints.Principles Practice Constraint Programming, pp. 4050.Helmert, M. (2002). Decidability undecidability results planning numericalstate variables. Proceedings sixth conference AI Planning Systems (AIPS).Henzinger, T. (1996). Theory Hybrid Automata. Proceedings 11th Annual Symposium ogic Computer Science. Invited tutorial., pp. 278292. IEEEComputer Society Press.Henzinger, T., Ho, P.-H., & Wong-Toi, H. (1995). user guide HYTECH. E.Brinksma, W.R. Cleaveland, K.G. Larsen, T. Margaria, B. Steffen, editors, ToolAlgorithms Construction Analysis Systems: (TACAS 95), volume1019 Lecture Notes Computer Science, pp. 4171.Henzinger, T., & Raskin, J.-F. (2000). Robust Undecidability Timed Hybrid Systems.Proceedings 3rd International Workshop Hybrid Systems: ComputationControl. LNCS 1790., pp. 145159. Springer-Verlag.Henzinger, T. A., Kopke, P. W., Puri, A., & Varaiya, P. (1998). Whats DecidableHybrid Automata?. Journal Computer System Sciences, 57, 94124.Herrmann, C. S., & Thielscher, M. (1996). Reasoning continuous processes.Clancey, B., & Weld, D. (Eds.), Proceedings Thirteenth National ConferenceArtificial Intelligence (AAAI), pp. 639644, Portland, OR. MIT Press.Hoffmann, J., & Edelkamp, S. (2005). Classical Part IPC-4: Overview. JournalAI Research, appear.Hofmann, A., & Williams, B. (2006). Robust execution temporally flexible plansbipedal walking devices. Proceedings 16th International Conference Automated Planning Scheduling (ICAPS), pp. 386389.Howey, R., Long, D., & Fox, M. (2004). Val: Automatic plan validation, continuous effectsmixed initiative planning using pddl. Proceedings 16th IEEE InternationalConference Tools Artificial Intelligence.Jonsson, A., & Frank, J. (2000). Framework Dynamic Constraint Reasoning usingProcedural Constraints. Proceedings 14th European Conference AI, pp. 9397.295fiFox & LongJonsson, A., Morris, P., Muscettola, N., Rajan, K., & Smith, B. (2000). Planning Interplanetary Space: Theory Practice. Proceedings 5th International ConferenceAI Planning Systems, pp. 177186.Keller, R. (1976). Formal Verification Parallel Programs. Communications ACM,19 (7), 371384.Kuipers, B. (1984). Commonsense Reasoning Causality: Deriving BehaviourStructure. Artificial Intelligence, 24, 169203.Laborie, P., & Ghallab, M. (1995). Planning sharable resource constraints. Proc.14th International Joint Conference AI. Morgan Kaufmann.Lamba, N., Dietz, M., Johnson, D., & Boddy, M. (2003). method global optimizationlarge systems quadratic constraints. Proceedings 2nd International WorkshopGlobal Constrained Optimization Constraint Satisfaction (COCOS-03).Larsen, K. G., Behrmann, G., Brinksma, E., Fehnker, A., Hune, T., Pettersson, P., &Romijn, J. (2001). use optimistic pessimistic resource profiles informsearch activity based planner. Proceedings 13th Conference ComputerAided Verification (CAV-01)). Springer Verlag, Lecture Notes Computer Science2102.Leaute, T., & Williams, B. (2005). Coordinating Agile Systems Model-basedExecution Temporal Plans. Proceedings 20th National Conference AI(AAAI), pp. 114120.McAllester, D., & Rosenblitt, D. (1991). Systematic Nonlinear Planning. ProceedingsNinth National Conference Artificial Intelligence (AAAI-91), Vol. 2, pp.634639, Anaheim, California, USA. AAAI Press/MIT Press.McDermott, D. (2003a). PDDL2.1 Art Possible? Commentary FoxLong. Journal AI Research, 20, 145148.McDermott, D. (2003b). Reasoning autonomous processes estimated-regressionplanner. Proceedings International Conference Automated PlanningScheduling (ICAPS03).McDermott, D. (2005). Reasoning Autonomous Processes Estimated RegressionPlanner. Proceedings 13th International Conference Automated PlanningScheduling (ICAPS), pp. 143152. AAAI-Press.McDermott, D., & AIPS98 Planning Competition Committee (1998). PDDLthe planning domain definition language. Tech. rep., Available at: www.cs.yale.edu/homes/dvm.McDermott, D. (2004). Opt Optop API. Tech. rep., Yale University.Muscettola, N. (1993). HSTS: Integrating Planning Scheduling. Zweben, M., & Fox,M. (Eds.), Intelligent Scheduling, pp. 169212. Morgan Kaufmann, San Mateo, CA.Musliner, D. J., Durfee, E. H., & Shin, K. G. (1993). CIRCA: Cooperative IntelligentReal-time Control Archtecture. IEEE Transactions Systems, Man Cybernetics,23 (6), 15611574.296fiModelling Mixed Discrete-Continuous Domains PlanningPenberthy, J., & Weld, D. (1992). UCPOP: sound, complete, partial-order plannerADL. Proc. Int. Conf. Principles Knowledge Representation Reasoning,pp. 103114, Los Altos, CA. Kaufmann.Penberthy, S., & Weld, D. (1994). Temporal Planning Continuous Change. Proceedings Twelfth National Conference Artificial Intelligence (AAAI), pp.10101015. AAAI/MIT Press.Rasmussen, J. I., Larsen, K. G., & Subramani, K. (2004). Resource Optimal Schedulingusing Priced Timed Automata. Proceedings 10th International ConferenceTools Algorithms Construction Analysis Systems (TACAS), pp.220235. Springer-Verlag, Lecture Notes Computer Science, 2988.Reiter, R. (1996). Natural Actions, Concurrency Continuous Time SituationCalculus. Aiello, L., Doyle, J., & Shapiro, S. (Eds.), KR-96: Principles KnowledgeRepresentation Reasoning, pp. 213. Morgan Kaufmann.Reiter, R. (2001). Knowledge Action: Logical Foundations Secifying ImplementingDynamical Systems. MIT Press.Sandewall, E. (1989). Combining Logic Differential Equations describing Real WorldSystems. Proceedings Knowledge Representation (KR), pp. 412420.Shanahan, M. (1990). Representing Continuous Change Event Calculus. Proceedings 9th European Conference AI, pp. 598603.Shin, J.-A., & Davis, E. (2005). Processes Continuous Change SAT-based Planner.Artificial Intelligence, 166, 194253.Smith, D. (2003). case durative actions: commentary PDDL2.1. JournalAI Research, 20, 149154.Wolfman, S., & Weld, D. (1999). LPSAT System Application ResourcePlanning. Proceedings Sixteenth International Joint Conference ArtificialIntelligence.Wu, S. J., & Chow, P. T. (1995). Genetic Algorithms Nonlinear Mixed Discrete-IntegerOptimization Problems via Meta-Genetic Parameter Optimization. Engineering Optimization, 24 (2), 137159.Yi, W., Larsen, K., & Pettersson, P. (1997). UPPAAL Nutshell. International JournalSoftware Tools Technology Transfer, 1 (1).297fiJournal Artificial Intelligence Research 27 (2006) 85117Submitted 01/06; published 09/06Learning Sentence-internal Temporal RelationsMLAP @ INF. ED . AC . UKMirella LapataAlex LascaridesALEX @ INF. ED . AC . UKSchool Informatics,University Edinburgh,2 Buccleuch Place,Edinburgh, EH8 9LW,Scotland, UKAbstractpaper propose data intensive approach inferring sentence-internal temporalrelations. Temporal inference relevant practical NLP applications either extract synthesize temporal information (e.g., summarisation, question answering). method bypassesneed manual coding exploiting presence markers like after, overtly signaltemporal relation. first show models trained main subordinate clauses connectedtemporal marker achieve good performance pseudo-disambiguation task simulatingtemporal inference (during testing temporal marker treated unseen models mustselect right marker set possible candidates). Secondly, assess whether proposedapproach holds promise semi-automatic creation temporal annotations. Specifically,use model trained noisy approximate data (i.e., main subordinate clauses) predictintra-sentential relations present TimeBank, corpus annotated rich temporal information.experiments compare contrast several probabilistic models differing feature space, linguistic assumptions data requirements. evaluate performance gold standard corporaalso human subjects.1. Introductioncomputational treatment temporal information recently attracted much attention, partincreasing importance potential applications. multidocument summarization,example, information included summary must extracted variousdocuments synthesized meaningful text. Knowledge temporal order eventsimportant determining content communicated correctly mergingpresenting information summary. Indeed, ignoring temporal relations either informationextraction summary generation phase may result summary misleadingrespect temporal information original documents. question answering, one oftenseeks information temporal properties events (e.g., X resign? ) eventsrelate (e.g., X resign Y? ).important first step towards automatic handling temporal phenomena analysisidentification time expressions. expressions include absolute date time specifications (e.g., October 19th, 2000 ), descriptions intervals (e.g., thirty years ), indexical expressions(e.g., last week ), etc. therefore surprising much previous work focused recog-c 2006 AI Access Foundation. rights reserved.fiL APATA & L ASCARIDESnition, interpretation, normalization time expressions 1 (Wilson, Mani, Sundheim, & Ferro,2001; Schilder & Habel, 2001; Wiebe, OHara, Ohrstrom Sandgren, & McKeever, 1998). Reasoningtime, however, goes beyond temporal expressions; also involves drawing inferencestemporal relations among events temporal elements discourse. additional challengetask stems nature temporal information itself, often implicit (i.e.,overtly verbalized) must inferred using linguistic non-linguistic knowledge.Consider examples (1) taken Katz Arosio (2001). Native speakers inferJohn first met kissed girl; left party kissing girl walkedhome; events talking asking name temporally overlap (andoccurred left party).(1)a.John kissed girl met party.b.Leaving party, John walked home.c.remembered talking asking name.temporal relations described part interpretation text, even thoughovert markers, while, signaling them. inferable varietycues, including order clauses, compositional semantics (e.g., informationtense aspect), lexical semantics world knowledge. paper describe data intensiveapproach automatically captures information pertaining temporal relations among eventslike ones illustrated (1).standard approach task would acquire model temporal relationscorpus annotated temporal information. Although efforts underway develop treebanksmarked temporal relations (Katz & Arosio, 2001) devise annotation schemes suitable coding temporal relations (Saur, Littman, Gaizauskas, Setzer, & Pustejovsky, 2004; Ferro,Mani, Sundheim, & Wilson, 2000; Setzer & Gaizauskas, 2001), existing corpora smallsize amenable supervised machine learning techniques normally require thousands training examples. TimeBank 2 corpus, example, contains set 186 news reportdocuments annotated TimeML mark-up language temporal events expressions (fordetails, see Sections 2 7). corpus consists 68.5K words total. ContrastPenn Treebank, corpus often used many NLP tasks contains approximately 1Mwords (i.e., 16 times larger TimeBank). annotation temporal informationtime-consuming also error prone. particular, n kinds temporal relations,number possible relations annotate polynomial factor n number eventstext. Pustejovsky, Mani, Belanger, Boguraev, Knippen, Litman, Rumshisky, See, Symonen, vanGuilder, van Guilder, Verhagen (2003) found evidence annotation task sufficientlycomplex human annotators realistically identify small number temporal relations text, thus compromising recall.default large volumes data labeled temporal information, turn unannotatedtexts nevertheless contain expressions overtly convey information want models learn. Although temporal relations often underspecified, sometimes temporalmarkers, before, after, while, make relations among events explicit:1. See also Time Expression Recognition Normalisation (TERN) evaluation exercise (http://timex2.mitre.org/tern.html).2. Available http://www.cs.brandeis.edu/jamesp/arda/time/timebank.html86fiL EARNING ENTENCE - INTERNAL EMPORAL R ELATIONS(2)a.Leonard Shane, 65 years old, held post president William Shane, 37,elected last year.b.results announced market closed.c.Investors markets sat awaiting U.S. trade figures.precisely type data exploit making predictions temporalrelationships among events text. assess feasibility approach initiallyfocusing sentence-internal temporal relations. large corpus, obtain sentences likeones shown (2), main clause connected subordinate clause temporalmarker, develop probabilistic framework temporal relations inferredgathering informative features two clauses. models view markersentence training corpus label learned. test corpus markerremoved models task pick likely labelor equivalently marker.also examine whether models trained data containing main subordinate clausestogether temporal connectives used infer relations among events temporalinformation underspecified overt temporal markers absent (as three sentences (1)). purpose, resort TimeBank corpus. latter contains detailedannotations events temporal relations irrespectively whether connectives presentnot. Using TimeBank annotations solely test data, assess whether approachput forward generalizes different structures corpora. evaluation study also highlightwhether model learned unannotated examples could alleviate data acquisition bottleneckinvolved creation temporal annotations. example, automatically creating highvolume annotations could subsequently corrected manually.attempting infer temporal relations probabilistically, consider several classes models varying degrees faithfulness linguistic theory. models differ along two dimensions:employed feature space underlying independence assumptions. compare contrast models utilize word-co-occurrences models exploit linguistically motivatedfeatures (such verb classes, argument relations, on). Linguistic features typically allowmodels form generalizations classes words, thereby requiring less training dataword co-occurrence models. also compare contrast two kinds models: one assumesproperties two clauses mutually independent; makes slightly realistic assumptions dependence. (Details models features used given Sections 34). furthermore explore benefits ensemble learning methods temporal interpretation task show improved performance achieved different learners (modelingsufficiently distinct knowledge sources) combined. machine learning experiments complemented study investigate human performance interpretation task therebyassessing feasibility providing ceiling model performance.next section gives overview previous work area computing temporal information discusses related work utilizes overt markers means avoiding manuallabeling training data. Section 3 describes probabilistic models Section 4 discussesfeatures motivation behind selection. experiments presented Sections 57.Section 8 offers discussion concluding remarks.87fiL APATA & L ASCARIDES2. Related WorkTraditionally, methods inferring temporal relations among events discourse utilizedsemantics inference-based approach. involves complex reasoning variety rich information sources, including elaborate domain knowledge detailed logical form representations(e.g., Dowty, 1986; Hwang & Schubert, 1992; Hobbs et al., 1993; Lascarides & Asher, 1993; Kamp& Reyle, 1993; Kehler, 2002). approach, theoretically elegant, impractical exceptapplications narrow domains. (at least) two reasons. First, grammars producedetailed semantic representations inevitably lack linguistic coverage brittle facenatural data; similarly, representations domain knowledge lack coverage. Secondly,complex reasoning required rich information sources typically involves nonmonotonicinferences (e.g., Hobbs et al., 1993; Lascarides & Asher, 1993), become intractable excepttoy examples.Allen (1995), Hitzeman, Moens, Grover (1995), Han Lavie (2004) proposecomputationally tractable approaches infer temporal information text, hand-crafting algorithms integrate shallow versions knowledge sources exploitedtheoretical literature (e.g., Hobbs et al., 1993; Kamp & Reyle, 1993). type symbolicapproach promising, overcomes impracticalities utilizing full logical formscomplex reasoning rich domain knowledge sources, grounded empirical evidenceway various linguistic features contribute temporal semantics discourse;algorithms evaluated real data. Moreover, approach typically domain-dependentrobustness compromised porting new domains applications.Acquiring model temporal relations via machine learning training corpus promisesprovide systems precise, robust, grounded empirical evidence. numbermarkup languages recently emerged greatly facilitate annotation efforts creating suitable corpora. notable example TimeML (Pustejovsky, Ingria, Sauri, Castano, Littman,Gaizauskas, & Setzer, 2004; see also annotation scheme Katz & Arosio, 2001), metadatastandard expressing information temporal properties events temporal relationsthem. scheme used annotate variety temporal expressions, includingtensed verbs, adjectives nominals correspond times, events states. type temporal information expressed various linguistic expressions includes classevent, tense, grammatical aspect, polarity (positive negative), time denoted (e.g., oneannotate yesterday denoting day document date), temporal relationspairs eventualities events times. TimeMLs expressive capabilities illustratedTimeBank corpus contains temporal annotations news report documents (for details,see Section 7).Mani, Schiffman, Zhang (2003) Mani Schiffman (2005) demonstrateTimeML-compliant annotations useful learning model temporal relations news text.focus problem ordering pairs successively described events. decision tree classifier trained corpus temporal relations provided human subjects. Using featuresposition sentence within paragraph (and position paragraph text),discourse connectives, temporal prepositions temporal modifiers, tense features, aspectshifts tense shifts, best model achieves 75.4% accuracy identifying temporal orderevents. Boguraev Ando (2005) use semi-supervised learning recognizing events inferring temporal relations (between event time expression). method exploits TimeML88fiL EARNING ENTENCE - INTERNAL EMPORAL R ELATIONSannotations TimeBank corpus large amounts unannotated data. first buildclassifier TimeML annotations using variety features based syntactic analysisidentification temporal expressions. original feature vectors next augmentedunlabeled data sharing structural similarities training data. algorithm yields performances well baseline tasks.Conceivably, existing corpus data annotated discourse structure, RST treebank (Carlson et al., 2001), might reused train temporal relations classifier. instance,text spans connected RESULT, implied semantics relation eventsfirst span temporally precede second; thus, classifier rhetorical relations could indirectly contribute classifier temporal relations. Corpus-based methods computing discourse structure beginning emerge (e.g., Marcu, 1999; Soricut & Marcu, 2003; Baldridge &Lascarides, 2005). currently automatic mapping discourse structurestemporal consequences; although potential eventually using linguistic resources labeled discourse structure acquire model temporal relations, potential cannotpresently realized.Continuing topic discourse relations, worth mentioning Marcu Echihabi(2002) whose approach bypasses altogether need manual coding supervised learningsetting. key insight work rhetorical relations (e.g., EXPLANATION CONTRAST)sometimes signaled discourse connective (e.g., EXPLANATIONCONTRAST). extract sentences containing markers corpus, (automatically) identify text spans connected marker, remove marker replacerhetorical relation signals. Naive Bayes classifier trained automatically labeled data.model designed maximally simple employs solely word bigrams features. Specifically, bigrams constructed cartesian product words occurring two text spansassumed word pairs conditionally independent. Marcu Echihabi demonstrateknowledge-lean approach performs well, achieving accuracy 49.70% distinguishing six relations (over baseline 16.67%). However, since model relies exlusivelyword-co-occurrences, extremely large training corpus (in order 40 sentences) requiredavoid sparse data (see Sporleder & Lascarides, 2005 detailed discussion tradeofftraining size feature space discourse-based models).sense, considering complexity various models used infer temporaldiscourse relations, Marcu Echihabis (2002) model lies simple extreme spectrum,whereas semantics inference-based approaches discourse interpretation (e.g., Hobbs et al.,1993; Asher & Lascarides, 2003) lie extreme, latter theories assume independence among properties spans, exploit linguistic non-linguistic featuresfull. paper, aim explore number probabilistic models lietwo extremes, thereby giving us opportunity study tradeoff complexitymodel one hand, amount training data required other. particularly interested assessing performance models smaller training sets usedMarcu Echihabi (2002); models useful classifiers trained data setsrelatively rare temporal markers exploited.work differs Mani et al. (2003) Boguraev Ando (2005)exploit manual annotations way. aim however similar, since also infer temporalrelations pairs events. share Marcu Echihabi (2002) use dataovert markers proxy hand coded relations. Apart fact interpretation task89fiL APATA & L ASCARIDESdifferent theirs, work departs Marcu Echihabi (2002) three importantways. First, propose alternative models explore contribution linguistic informationinference task, investigating enables one train considerably smaller data sets.Secondly, proposed models used infer relations events realistic setting,temporal markers naturally absent (i.e., test data simulated removingmarkers question). finally, evaluate models human subjects performingtask, well gold standard corpus.3. Problem FormulationGiven main clause subordinate clause attached it, task infer temporal markerlinking two clauses. P SM j SS represents probability marker j relates main clauseSM subordinate clause SS . aim identify marker j set possible markersmaximizes joint probability P j SS :ff fifififfff fifififfff fifififfff fifififfargmax P SM j SS(3)tjargmax P SM P SS SM P j SM SStjignore terms P SM P SS SM (3) constant. use Bayes Rule calculateP j SM SS :argmax P j SM SS(4)tjargmax P j P SM SS jargmax P j P 1tjn tjtjSM SS vectors features 1n 1n characteristic propositionsoccurring marker j (our features described detail Section 4.2). Estimatingdifferent P 1n j terms feasible unless large set trainingdata. therefore make simplifying assumption temporal marker j determinedobserving feature pairs representative main subordinate clause. assumefeature pairs conditionally independent given temporal marker arbitrary:rather considering pairs cartesian product 1n (see Marcu & Echihabi,2002), restrict feature pairs belong class i. Thus, probabilityobserving conjunction 1n given j is:ff fifififffffifififfffffargmax P jtjffffn1(5)P tjexample, assuming feature space consisted solely nouns verbs, wouldestimate P j taking account noun-noun verb-verb bigramsattested SS SM co-occur j .model (4) simplified assuming likelihood subordinateclause SS conditionally independent main clause (i.e., P SS SM jP SS j P SM j ).90fiL EARNING ENTENCE - INTERNAL EMPORAL R ELATIONSassumption clearly simplification makes estimation probabilities P jP SS j reliable face sparse data:ff fifififfff fifififfffffffargmax P j P SM j P SS j(6)tjSM SS vectors features 1n 1n representing clausesco-occurring marker j . individual features (instead feature pairs) assumedconditionally independent given temporal marker, therefore:argmax P jtjn(7)P tj P tj1ffReturning example feature space nouns verbs, P j P jestimated considering often verbs nouns co-occur j . co-occurrencesestimated separately main subordinate clauses.Throughout paper use terms conjunctive model (5) disjunctivemodel (7). effectively treat temporal interpretation problem disambiguation task.(confusion) set temporal markers, e.g., after, before, since , select one maximizes (5) (7) (see Section 4 details confusion set corpus). conjunctive modelexplicitly captures dependencies main subordinate clauses, whereas disjunctivemodel somewhat simplistic relationships features across two clausesrepresented directly. However, two values features main subordinate clausesco-occur frequently particular marker, conditional probability featuresmarker approximate right biases.conjunctive model closely related kinds symbolic rules inferringtemporal relations used semantics inference-based accounts (e.g., Hobbs et al., 1993).Many rules typically draw relationships verbs clauses, nounsclauses, on. disjunctive conjunctive models different MarcuEchihabis (2002) model several respects. utilize linguistic features rather wordbigrams. conjunctive models features two-dimensional dimension belongingfeature class. disjunctive model added difference assumes independencefeatures attested two clauses.4. Parameter Estimationffffffffestimate parameters models large corpus. simplest form,features words making main subordinate clauses. order extractrelevant features, first identify clauses hypotactic relation, i.e., main clausessubordinate clause constituent. training phase, estimate probabilities P jP j disjunctive model simply counting occurrence featuresmarker j (i.e., f j ) ( f j ). essence, assume modelcorpus representative way various temporal markers used English.conjunctive model estimate co-occurrence frequencies f j . Features zerocounts smoothed models; adopt m-estimate uniform priors, equalsize feature space (Cestnik, 1990).ffff91fffffffffiL APATA & L ASCARIDES(S1 (S (NP (DT The) (NN company))(VP (VBD said)(S (NP (NNS employees))(VP (MD will)(VP (VB lose)(NP (PRP their) (NNS jobs))(SBAR-TMP (IN after)(S (NP (DT the) (NN sale))(VP (AUX is) (VP (VBN completed)))))))))))Figure 1: Extraction main subordinate clause parse tree4.1 Data Extractionorder obtain training testing data models described previous section, subordinate clauses (and main clause counterparts) extracted B LLIP corpus (30words). latter Treebank-style, machine-parsed version Wall Street Journal (WSJ,years 198789) produced using Charniaks (2000) parser. study focused following (confusion) set temporal markers: after, before, while, when, as, once, until, since .initially compiled list temporal markers discussed Quirk, Greenbaum, Leech, Svartvik(1985) eliminated markers frequency less 10 per million corpus.extract main subordinate clauses connected temporal discourse markers, firsttraversing tree top-down identify tree node bearing subordinate clause labelinterested extract subtree dominates. Assuming want extractsubordinate clauses, would subtree dominated SBAR-TMP Figure 1 indicatedarrow pointing (see sale completed ). found subordinate clause,proceed extract main clause traversing tree upwards identifying node immediately dominating subordinate clause node (see arrow pointing Figure 1, employeeslose jobs ). cases subordinate clause sentence initial, first identifySBAR-TMP node extract subtree dominated it, traverse tree downwardsorder extract S-tree immediately dominating it.experiments described focus solely subordinate clauses immediately dominated S, thus ignoring cases nouns related clauses via temporal marker (e.g., Johnleft lunch ). Note one main clause qualify attachment sitessubordinate clause. Figure 1 subordinate clause sale completed attached either said loose. similar structural ambiguities identifyingsubordinate clause; example see (8), conjunction lie within scopesubordinate -clause (and indeed, parser disambiguates structural ambiguity correctlycase):(8)[ Mr. Grambling made $250,000 banks money [ Colonial caughtdenied remaining $100,000. ] ]relying parser providing relatively accurate resolutions structural ambiguities, unavoidably create noise data. estimate extent noise,manually inspected 30 randomly selected examples temporal discourse markers92fiL EARNING ENTENCE - INTERNAL EMPORAL R ELATIONSTMarksinceTOTALFrequency35,89515,90413,2286,5725,3073,5242,74263883,810Distribution (%)42 8319 0015 797 846 334 203 270 76100 00Table 1: Subordinate clauses extracted B LLIP corpusi.e., 240 examples total. examples inspected true positives temporal discourse markers save one, parser assumed took sentential complement whereasreality NP complement (i.e., anti-poverty worker ):(9)[ first moved West Virginia [ anti-poverty worker, decided stay startpolitical career, eventually serving two terms governor. ] ]cases noise due fact parser either overestimates underestimatesextent text span two clauses. 98.3% main clauses 99.6% subordinate clauses accurately identified data set. Sentence (10) example parserincorrectly identifies main clause: predicts -clause attached denationalisecountrys water industry. Note, however, subordinate clause (as managers resistedmove workers threatened lawsuits ) correctly identified.(10) [ Last July, government postponed plans [ denationalise countrys water industry[ managers resisted move workers threatened lawsuits. ] ] ]size corpus obtain extraction methods detailed Table 1.83,810 instances overall (i.e., 0.20% size corpus used Marcu Echihabi,2002). Also note distribution temporal markers ranges 0.76% (for ) 42.83%(for ).discourse markers confusion set underspecify temporal semantic information.example, entail temporal overlap (see (11a), Kamp & Reyle, 1993), temporalprogression (see (11c), Moens & Steedman, 1988). true once, since, :(11) a.b.(12) a.b.Mary left Bill preparing dinner.(temporal overlap)built bridge, solved traffic problems. (temporal progression)John moved London, got job council.John living London, got job council.93(temporal progression)(temporal overlap)fiL APATA & L ASCARIDES(13) a.b.(14) a.b.John worked council since hes living London.John moved London since got job council there.temporal precedence)(temporal overlap)(cause henceGrand melodies poured contemplated Caesars conquest Egypt. (temporal overlap)went bank ran cash.(cause, hence temporal precedence)means model chooses when, once, since likely markermain subordinate clause, temporal relation events described left underspecified. course semantics limits range possible relations,model identify specific relation conveyed markers given example. Similarly, ambiguous temporal use signals eventualitiestemporally overlap (see (15a)) contrastive use convey particular temporalrelation (although relations may conveyed features sentence, tense,aspect world knowledge; see (15b)).(15) a.stock market rising steadily, even companies stuffed cash rushedissue equity.b.point history directly opposed Liberal Theology, appealspirit somehow detachable Jesus history run much along similarlines Liberal approach.inspected 30 randomly-selected examples markers underspecified readings(i.e., when, once, since, ). marker entails temporal overlap interpretation 70% time entails temporal overlap 75% time, whereas sincelikely entail temporal progression (74% 80%, respectively). markersreceive predominantly temporal interpretations corpus. Specifically, non-temporaluses 13.3% instances sample 25%. interpretation modelapplied, could use biases disambiguate, albeit coarsely, markers underspecified meanings. Indeed, demonstrate Experiment 3 (see Section 7) model usefulestimating unambiguous temporal relations, even original sentence temporalmarker, ambiguous otherwise.4.2 Model Featuresnumber knowledge sources involved inferring temporal ordering including tense, aspect, temporal adverbials, lexical semantic information, world knowledge (Asher & Lascarides,2003). selecting features represent knowledge sources, notwithstanding indirectlyimperfectly, aim empirically assess contribution temporal inference task.introduce features provide motivation behind selection.Temporal Signature (T) well known verbal tense aspect impose constraintstemporal order events also choice temporal markers. constraints perhapsbest illustrated system Dorr Gaasterland (1995) examine inherent (i.e., statesevents) non-inherent (i.e., progressive, perfective) aspectual features interact timestamps eventualities order generate clauses markers relate them.94fiL EARNING ENTENCE - INTERNAL EMPORAL R ELATIONSFINITENON - FINITEMODALITYASPECTVOICENEGATION======past, present0, infinitive, ing-form, en-form/ future, ability, possibility, obligation0,imperfective, perfective, progressiveactive, passiveaffirmative, negativeTable 2: Temporal signaturesFeatureFINPASTACTMODNEGonceM0.690.280.870.220.97onceS0.720.340.510.020.98sinceM0.750.350.850.070.95sinceS0.790.710.810.050.97Table 3: Relative frequency counts temporal features main (subscript M) subordinate(subscript S) clausesAlthough cannot infer inherent aspectual features verb surface form (for wouldneed dictionary verbs aspectual classes together process assigns aspectualclasses given context), extract non-inherent features parse trees. firstidentify verb complexes including modals auxiliaries classify tensed non-tensedexpressions along following dimensions: finiteness, non-finiteness, modality, aspect, voice,polarity. values features shown Table 2. features finiteness non-finitenessmutually exclusive.Verbal complexes identified parse trees heuristically devising set 30 patterns search sequences auxiliaries verbs. parser output verbs classifiedpassive active building set 10 passive identifying patterns requiring passiveauxiliary (some form get ) past participle.illustrate example, consider parse tree Figure 1. identify verbalgroups lose completed main subordinate clause respectively. formermapped features present, 0, future, imperfective, active, affirmative , whereas latter/ imperfective, passive, affirmative , 0 indicates verb form finitemapped present, 0, 0,0/ indicates absence modal. Table 3 show relative frequencies corpusfiniteness (FIN), past tense (PAST), active voice (ACT), negation (NEG) main subordinateclauses conjoined markers since. seen differencesdistribution counts main subordinate clauses different markers.instance, past tense frequent since subordinate clauses modal verbsoften attested since main clauses compared main clauses. Also,main clauses likely active, whereas subordinate clauses either activepassive.95fiL APATA & L ASCARIDESTMarksinceVerbMsellcomesaybecomeriseprotectmakewaitVerbSleaveacquireannouncecompleteexpectpaysellcompleteSupersenseMcommunicationmotionstativestativestativecommunicationstativecommunicationSupersenseScommunicationmotionstativestativechangepossessionmotionsocialLevinMsaysaysaysaysaysaycharacterizesayLevinSsaybeginbegingetbegingetgetamuseTable 4: frequent verbs verb classes main (subscript M) subordinate clauses (subscript M)Verb Identity (V) Investigations interpretation narrative discourse shown specific lexical information plays important role determining temporal interpretation (e.g., Asher& Lascarides, 2003). example, fact verbs like push cause movement objectverbs like fall describe movement subject used interpret discourse(16) pushing causing falling, thus making linear order events mismatchtemporal order.(16) Max fell. John pushed him.operationalize lexical relationships among verbs data counting occurrencemain subordinate clauses lemmatized version B LLIP corpus. Verbs extractedparse trees containing main subordinate clauses. Consider tree Figure 1.Here, identify lose complete, without preserving information tense passivisationexplicitly represented temporal signatures. Table 4 lists frequent verbsattested main (VerbM ) subordinate (VerbS ) clauses conjoined temporal markers after,as, before, once, since, until, when, (TMark).Verb Class (VW , VL ) verb identity feature capture meaning regularities concerningtypes verbs entering temporal relations. example, Table 4 sell pay possessionverbs, say announce communication verbs, come rise motion verbs. AsherLascarides (2003) argue many rules inferring temporal relations specifiedterms semantic class verbs, opposed verb forms themselves, maximizelinguistic generalizations captured model temporal relations. purposes,additional empirical motivation utilizing verb classes well verbs themselves: reducesrisk sparse data. Accordingly, use two well-known semantic classifications obtainingdegree generalization extracted verb occurrences, namely WordNet (Fellbaum,1998) verb classification proposed Levin (1995).Verbs WordNet classified 15 broad semantic domains (e.g., verbs change, verbscognition, etc.) often referred supersenses (Ciaramita & Johnson, 2003). therefore mappedverbs occurring main subordinate clauses WordNet supersenses (feature V W ). Semantically ambiguous verbs correspond one semantic class. resolve ambiguity96fiL EARNING ENTENCE - INTERNAL EMPORAL R ELATIONSTMarksinceNounNyearmarkettimestockcompanypresidentactgroupNounScompanydollaryearplacemonthyearactactSupersenseMactactactactactactyearchairmanSupersenseSactactgroupactactactyearplanAdjMlastrecentlongfirstnewlastfirstAdjSnewpreviousnewnewlastnextlastTable 5: frequent nouns, noun classes, adjectives main (subscript M) subordinateclauses (subscript M)heuristically always defaulting verbs prime sense (as indicated WordNet) selecting corresponding supersense. cases verb listed WordNet defaultlemmatized form.Levin (1995) focuses relation verbs arguments hypothesizesverbs behave similarly respect expression interpretation argumentsshare certain meaning components therefore organized semantically coherent classes(200 total). Asher Lascarides (2003) argue classes provide important informationidentifying semantic relationships clauses. Verbs data mappedcorresponding Levin classes (feature V L ); polysemous verbs disambiguated methodproposed Lapata Brew (2004). 3 Again, verbs included Levin, lemmatized verbform used. Examples frequent Levin classes main subordinate clauseswell WordNet supersenses given Table 4.Noun Identity (N) verbs, also nouns provide important informationsemantic relation two clauses; Asher Lascarides (2003) discuss examplenoun meal one sentence salmon serves trigger inferencesevents part-whole relation (eating salmon part meal). examplecorpus concerns nouns share market. former typically found main clausespreceding latter often subordinate clause. Table 5 shows frequently attested nouns (excluding proper names) main (Noun ) subordinate (NounS ) clausestemporal marker. Notice time denoting nouns (e.g., year, month ) relatively frequentdata set.Nouns extracted lemmatized version B LLIP corpus. Figure 1 nounsemployees, jobs sales relevant Noun feature. cases noun compounds,compound head (i.e., rightmost noun) taken account. small set rules usedidentify organizations (e.g., United Laboratories Inc.), person names (e.g., Jose Y. Campos ),3. Lapata Brew (2004) develop simple probabilistic model determines given polysemous verbframe likely meaning overall (i.e., across corpus), without relying availability disambiguatedcorpus. model combines linguistic knowledge form Levin (1995) classes frame frequencies acquired parsed corpus.97fiL APATA & L ASCARIDESlocations (e.g., New England ) subsequently substituted general categoriesperson, organization, location.Noun Class (NW ) verbs, Asher Lascarides (2003) argue favor symbolic rulesinferring temporal relations utilize semantic classes nouns wherever possible,maximize linguistic generalizations captured. example, argue oneinfer causal relation (17) basis noun bruise cause via act-on predicateunderspecified agent (other nouns class include injury, sinking, construction ):(17) John hit Susan. bruise enormous.Similarly, inferring salmon part meal (18) rests fact noun salmon,one sense least, denotes edible substance.(18) John ate wonderful meal. devoured lots salmon.case verbs, nouns also represented supersenses WordNet taxonomy. Nouns WordNet form single hierarchy; instead partitioned accordingset semantic primitives 25 supersenses (e.g., nouns cognition, events, plants, substances,etc.), treated unique beginners separate hierarchies. nouns extractedparser mapped WordNet classes. Ambiguity handled way verbs.Examples frequent noun classes attested main subordinate clauses illustratedTable 5.Adjective (A) motivation including adjectives feature set twofold. First, hypothesize temporal adjectives (e.g., old, new, later ) frequent subordinate clausesintroduced temporal markers before, after, therefore may provide cluesrelations signaled markers. Secondly, similarly verbs nouns, adjectives carry important lexical information used inferring semantic relation holds twoclauses. example, antonyms often provide clues temporal sequence two events(see incoming outgoing (19)).(19) incoming president delivered inaugural speech. outgoing president resigned lastweek.verbs nouns, adjectives extracted parsers output. frequentadjectives main (AdjM ) subordinate (AdjS ) clauses given Table 4.Syntactic Signature (S) syntactic differences main subordinate clauses capturedsyntactic signature feature. feature viewed measure tree complexity,encodes main subordinate clause number NPs, VPs, PPs, ADJPs,ADVPs contains. feature easily read parse tree. syntactic signaturemain clause Figure 1 [NP:2 VP:2 ADJP:0 ADVP:0 PP:0] subordinateclause [NP:1 VP:1 ADJP:0 ADVP:0 PP:0]. frequent syntactic signature main clauses[NP:2 VP:1 PP:0 ADJP:0 ADVP:0]; subordinate clauses typically contain adverbial phrase [NP:2VP:1 ADJP:0 ADVP:1 PP:0]. One motivating case using syntactic feature involves verbsdescribing propositional attitudes (e.g., said, believe, realize ). set temporal discourse markersvarying distributions relative semantic scope verbs. example, one98fiL EARNING ENTENCE - INTERNAL EMPORAL R ELATIONSwould expect take narrow semantic scope (i.e., until-clause would typically attachverb sentential complement propositional attitude verb, rather propositionalattitude verb itself), situation might different once.Argument Signature (R) feature captures argument structure profile main subordinate clauses. applies verbs encodes whether verb direct indirect object,whether modified preposition adverbial. rules inferring temporal relationsHobbs et al. (1993) Asher Lascarides (2003) attest, predicate argument structureclauses crucial making correct temporal inferences many cases. take simple example, observe inferring causal relation (16) crucially depends fact subjectfall denotes person direct object push ; without this, relation causalone would inferred.syntactic signature, feature read main subordinate clause parsetrees. parsed version B LLIP corpus contains information subjects. NPs whosenearest ancestor VP identified objects. Modification relations recoveredparse trees finding PPs ADVPs immediately dominated VP. Figure 1argument signature main clause [SUBJ OBJ] subordinate [OBJ].Position (P) feature simply records position two clauses parse tree,i.e., whether subordinate clause precedes follows main clause. majority mainclauses data sentence initial (80.8%). However, differences among individualmarkers. example, clauses equally frequent positions. 30% clausessentence initial whereas 90% clauses found second position. statistics clearly show relative positions main vs. subordinate clauses goingrelatively informative interpretation task.following sections describe experiments models introduced Section 3. first investigate performance temporal interpretation context pseudodisambiguation task (Experiment 1). also describe study humans (Experiment 2)enables us examine depth models behavior difficulty inference task.Finally, evaluate proposed approach realistic setting, using sentencescontain explicit temporal markers (Experiment 3).5. Experiment 1: Temporal Inference Pseudo-disambiguationMethod models trained main subordinate clauses extracted B LLIPcorpus detailed Section 4. testing phase, occurrences relevant temporal markersremoved models used select marker originally attestedcorpus. experimental setup admittedly artificial, important revealing difficultytask hand. model performs deficiently pseudo-disambiguation task, littlehope inferring temporal relations natural setting events neither connected viatemporal markers found main-subordinate relationship.Recall obtained 83,810 main-subordinate pairs. randomly partitionedtraining (80%), development (10%) test data (10%). Eighty randomly selected pairstest data reserved human study reported Experiment 2. performed parametertuning development set; results reported unseen test set, unless otherwisestated. compare performance conjunctive disjunctive models, thereby assessing99fiL APATA & L ASCARIDESSymbols$&#Meaningsignificantly different Majority Baselinesignificantly different Word-based Baselinesignificantly different Conjunctive Modelsignificantly different Disjunctive Modelsignificantly different Conjunctive Ensemblesignificantly different Disjunctive EnsembleTable 6: Meaning diacritics indicating statistical significance ( 2 tests, p0 05)effect feature (in)dependence temporal interpretation task. Furthermore, compareperformance two proposed models baseline disjunctive model employsw j ) Pw j ). modelword-based feature space (see (7) Presembles Marcu Echihabis (2002)s model make use linguisticallymotivated features presented previous section; needed estimating parameterscorpus main-subordinate clause pairs. also report performance majority baseline(i.e., always select when, frequent marker data set).order assess impact feature classes (see Section 4.2) interpretation task,feature space exhaustively evaluated development set. nine classes,results 9 9!k ! combinations k arity combination (unary, binary, ternary, etc.).measured accuracy class combinations (1,023 total) development set.these, selected best performing ones evaluating models test set.ffffffffResults results shown Table 7. report accuracy F-score. set diacriticsused indicate significance (on accuracy) throughout paper (see Table 6). best performing disjunctive model test set (accuracy 62.6%) observed combination verbs(V) syntactic signatures (S). combination verbs (V), verb classes (V L , VW ), syntactic signatures (S) clause position (P) yielded highest accuracy (60.3%) conjunctivemodel. conjunctive disjunctive models performed significantly better majoritybaseline word-based model also significantly outperformed majority baseline.disjunctive model (SV) significantly outperformed conjunctive one (V W VL PSV).attribute conjunctive models worse performance data sparseness. clearlytrade-off reflecting true complexity task inferring temporal relationsamount training data available. size data set favors simpler modelcomplex one. difference performance models relying linguistically-motivatedfeatures word-based model also shows linguistic abstractions useful overcomingsparse data.analyzed data requirements models varying amount instancestrained. Figure 2 shows learning curves best conjunctive disjunctivemodels (VW VL PSV SV). comparison, also examine training data size affects(disjunctive) word-based baseline model. seen, disjunctive model advantageconjunctive one; difference pronounced smaller amounts training data.small performance gains obtained increased training data word baseline model.considerably larger training set required model competitive lin100fiL EARNING ENTENCE - INTERNAL EMPORAL R ELATIONSModelMajority BaselineWord-based BaselineConjunctive (VW VL PSV)Disjunctive (SV)Accuracy42 6$#&48 2 $#&60 3 #&62 6 $#&Ensemble (Conjunctive)Ensemble (Disjunctive)64 570 6F-scoreNA44.753.362.3$&$#59.969.1Table 7: Summary results temporal pseudo-disambiguation task; comparison baselinemodels conjunctive disjunctive models ensembles (V: verbs, V W :WordNet verb supersenses, VL : Levin verb classes, P: clause position, S: syntactic signature)70Accuracy (%)65Word-based BaselineConjunctive ModelDisjunctive Model6055504540K K K K K K K K K K K K K K K K K K K K3.3 6.7 10 13.4 16.8 20.1 23.4 26.8 30.1 33.5 36.840.2 43.6 46.9 50.3 53.6 56.9 60.3 63.6 67.1Number instances training dataFigure 2: Learning curve conjunctive, disjunctive, word-based models.guistically aware models. result agreement Marcu Echihabi (2002) employlarge corpus (1 billion words, extract 40 million training examples)training word-based model.analysis models output revealed feature combinations performed reasonably well individual markers disjunctive conjunctive model, even thoughoverall accuracy match best feature combinations either model class.accuracies combinations shown Table 8. example, NPRSTV one bestcombinations generating disjunctive model, whereas SV better(feature abbreviations introduced Section 4.2). Given complementarity differentmodels, obvious question whether combined. important finding machinelearning set classifiers whose individual decisions combined way (an ensemble ) accurate component classifiers errors individual101fiL APATA & L ASCARIDESTMarkDisjunctive ModelFeaturesAccuracyConjunctive ModelFeaturesAccuracysinceNPRSTVANNW PSVSVPRSPRSTVL PSPSTVL VW RTVW PTVVW VL SVTVVW PVL VVL NVVL PVVW VL PV69 957 042 140 725 185 549 069 479 657 011 3371086 59695Table 8: Best feature combinations individual markers (development set; V: verbs, V W : WordNet verb supersenses, VL : Levin verb classes, N: nouns, NW : WordNet noun supersenses,P: clause position, R: argument signature, S: syntactic signature, T: tense signature)classifiers sufficiently uncorrelated (Dietterich, 1997). next section reports ensemblelearning experiments.Ensemble Learning ensemble classifiers set classifiers whose individual decisionscombined classify new examples. simple idea applied variety classification problems ranging optical character recognition medical diagnosis part-of-speechtagging (for overviews, see Dietterich, 1997; van Halteren, Zavrel, & Daelemans, 2001). Ensemblelearners often yield superior results individual learners provided component learnersaccurate diverse (Hansen & Salamon, 1990).ensemble typically built two steps: first multiple component learners trainednext predictions combined. Multiple classifiers generated either using subsamplestraining data (Breiman, 1996a; Freund & Shapire, 1996) manipulating set inputfeatures available component learners (Cherkauer, 1996). Weighted unweighted votingmethod choice combining individual classifiers ensemble. sophisticatedcombination method stacking learner trained predict correct output classgiven input outputs ensemble classifiers (Wolpert, 1992; Breiman, 1996b; van Halterenet al., 2001). words, second-level learner trained select output basispatterns co-occurrence output several component learners.generated multiple classifiers (for combination ensemble) varying numbertype features available conjunctive disjunctive models discussed previoussection. outputs models next combined using c5.0 (Quinlan, 1993), decision-treesecond level-learner. Decision trees among widely used machine learning algorithms.perform general specific search feature space, adding informative featurestree structure search proceeds. objective select minimal set featuresefficiently partitions feature space classes observations assemble tree(for details, see Quinlan, 1993). classification test case made traversing treeeither leaf node found branches match test case, returningfrequent class last node.102fiL EARNING ENTENCE - INTERNAL EMPORAL R ELATIONSConjunctive EnsemblePSVVWNW VL NPVVW VLPRTVVWVLNSVVWPSVVW PVVW NW PSVVLNSVPSVPVDisjunctive EnsembleANW NPSV APSVASVPRSVWPRSPRSTPRSVPSVAPTVSVVW VLNPVPSVWVL PSVVWVL PVVWVLPSVLPVVLNPSVSVTVVPSVNSVSVLNPRSTVTable 9: Component models ensemble learning (A: adjectives, V: verbs, V W : WordNet verbsupersenses, VL : Levin verb classes, N: nouns, NW : WordNet noun supersenses, P: clauseposition, R: argument signature, S: syntactic signature, T: tense signature)Learning framework requires primary training set training component learners;secondary training set training second-level learner test set assessing stackedclassifier. trained decision-tree learner development set using 10-fold cross-validation.experimented 133 different conjunctive models 65 disjunctive models; best resultsdevelopment set obtained combination 22 conjunctive models 12 disjunctive models. component models presented Table 9. ensembles performancetest set reported Table 7.seen, types ensemble significantly outperform word-based baseline,best performing individual models. Furthermore, disjunctive ensemble significantly outperforms conjunctive one. Table 10 details performance two ensembles individualmarker. ensembles difficulty inferring markers since, ; difficultypronounced conjunctive ensemble. believe worse performance predicting relations due combination sparse data ambiguity. First, observethree classes fewest examples data set (see Table 1). Secondly, temporallyambiguous, conveying temporal progression temporal overlap (see example (12)).ambiguity observed since (see example (13)). Finally, although temporal sensealways conveys temporal overlap, non-temporal, contrastive sense potentiallycreates noise training data, discussed Section 4.1. Another contributing factorpoor performance lack sufficient training data. Note extracted instancesmarker constitute 4.2% data. fact, model often confuses marker sincesemantically similar while. could explained fact majority trainingexamples since interpretations imply temporal overlap, thereby matching temporalrelation implied while, turn also majority interpretation training corpus(the non-temporal, contrastive sense accounting 13.3% training examples).Let us examine classes features impact interpretation taskobserving component learners selected ensembles. shown Table 8, verbs eitherlexical forms (V) classes (VW , VL ), syntactic structure main subordinate clauses(S) position (P) important features interpretation. Verb-based featurespresent component learners making conjunctive ensemble 10 (out 12) learnersdisjunctive ensemble. argument structure feature (R) seems influence(it present five 12 component (disjunctive) models), however suspectoverlap S. Nouns, adjectives temporal signatures seem small impact103fiL APATA & L ASCARIDESTMarksinceDisjunctive EnsembleAccuracyF-score66 462 551 424 626 291 028 847 870 663 962 050 635 338 286 941 252 469 1Conjunctive EnsembleAccuracyF-score59 359 017 1003990 511 517 364 557 655 122 3004584 715 824 459 9Table 10: Ensemble results sentence interpretation individual markers (test set)interpretation task, least WSJ domain. results far point importancelexicon inferring temporal relations also indicate syntactic complexitytwo clauses another key predictor. Asher Lascarides (2003) symbolic theory discourseinterpretation also emphasizes importance lexical information inferring temporal relations,Soricut Marcu (2003) find syntax trees useful inferring discourse relations,temporal consequences.6. Experiment 2: Human EvaluationMethod assessed temporal interpretation model comparing performancehuman judges. Participants asked perform multiple choice task. givenset 40 main-subordinate pairs (five marker) randomly chosen test data.marker linking two clauses removed participants asked select missing wordset eight temporal markers, thus mimicking models task. Examples materialsparticipants saw given Apendix A.study conducted remotely Internet. Subjects first read set instructionsexplained task, fill short questionnaire including basic demographic information.random order main-subordinate pairs random order markers per pair generatedsubject. study completed 198 volunteers, native speakers English. Subjectsrecruited via postings local Email lists.Results results summarized Table 11. measured well subjects (Human)agree gold standard (Gold)i.e., corpus experimental itemsselectedand well agree (Human-Human). also show welldisjunctive ensemble (Ensemble) agrees subjects (Ensemble-Human) gold standard (Ensemble-Gold). measured agreement using Kappa coefficient (Siegel & Castellan,1988) also report percentage agreement facilitate comparison model. casescompute pairwise agreements report mean.104fiL EARNING ENTENCE - INTERNAL EMPORAL R ELATIONSHuman-HumanHuman-GoldEnsemble-HumanEnsemble-GoldK.410.421.390.413%45.046.944.347.5Table 11: Agreement figures subjects disjunctive ensemble (Human-Human: inter-subjectagreement, Human-Gold: agreement subjects gold standard corpus,Ensemble-Human: agreement ensemble subjects, Ensemble-Gold: agreement ensemble gold standard corpus)since.55.14.05.17.10.06.20.16.06.33.05.06.09.03.07.05.03.02.52.10.04.05.09.08.10.02.08.35.04.10.09.03since.04.03.03.07.63.03.04.04.01.03.15.03.03.65.03.02.20.20.08.17.06.05.45.10.01.23.04.05.01.03.03.52Table 12: Confusion matrix based percent agreement subjectsshown Table 11 moderate agreement 4 among humans selecting appropriate temporal marker main subordinate clause. ensembles agreement goldstandard approximates human performance interpretation task (K413 Ensemble-Goldvs. K421 Human-Gold). agreement ensemble subjects also closeupper bound, i.e., inter-subject agreement (see Ensemble-Human Human-Human Table 11).analysis revealed majority disagreements among subjects aroseclauses. also problematic ensemble model (see Table 10). inter-subjectagreement 33% clauses 35% clauses. markers, subjectagreement around 55%. highest agreement observed since (63%65% respectively). confusion matrix summarizing resulting inter-subject agreementinterpretation task shown Table 12.moderate agreement entirely unexpected given markers semantically similar cases one marker compatible temporal implicaturesarise joining two clauses. example, compatible after, as, before,once, since. Besides when, compatible since, while. Consider examplefollowing sentence experimental materials: older women divorcinghusbands retire. Although right connective according corpus,4. Landis Koch (1977) give following five qualifications different values Kappa: .00.20 slight, .21.40fair, .41.60 moderate, .61.80 substantial, whereas .811.00 almost perfect.105fiL APATA & L ASCARIDESalso valid choices. Indeed often chosen instead subjects (seeTable 12). Also note neither model subjects access context surroundingsentence whose marker must inferred. sentence lot want getget kicked (again taken materials), knowing referents important selecting right relation. cases, substantial background knowledge requiredmake valid temporal inference. sentence certified deaths requiredFDA acts? (see Appendix A), one must know FDA stands (i.e., Federal, Food, Drug,Cosmetic Act). less strict evaluation setting one connective consideredcorrect (on basis semantic compatibility), inter-subject agreement K640 (67.7%).Moreover, ensembles agreement subjects K609 (67%).next evaluate performance ensemble model challenging task. testdata far somewhat artificially created removing temporal marker connectingmain subordinate clause. Although experimental setup allows develop evaluate temporal inference models relatively straightforwardly, remains unsatisfactory. cases temporal model would required interpreting events attested main-subordinateclauses variety constructions (e.g., parataxis indirect speech) may containtemporal markers. use annotations TimeBank corpus investigating whethermodel, trained automatically annotated data, performs well realistic test set.7. Experiment 3: Predicting TimeML RelationsMethod mentioned earlier TimeBank corpus manually annotatedTimeML coding scheme. scheme, verbs, adjectives, nominals annotated EVENTsmarked attributes class event (e.g., state, reporting), tense(e.g., present, past), aspect (e.g., perfective, progressive), polarity (positive negative).TLINK tag used represent temporal relationships events, eventtime. relationships inter- intra-sentential. Table 13 illustrates TLINK relationships sentences taken TimeBank corpus. focus solely intra-sentential temporalrelations events; Table 13 include IDENTITY relationship commonlyattested inter-sententially.intent use model presented previous sections interpret temporalrelationships events like shown Table 13 absence overtly verbalized temporal information (e.g., temporal markers). However, one stumbling block performing kindevaluation corpus model trained uses different labelsTable 13 (e.g., (ambiguous) temporal markers like ). Fortunately, temporal markers considered TimeML relations less semantically compatible, mappingdevised. First notice relations Table 13 redundant. instanceinverse AFTER, INCLUDED inverse INCLUDES, on. Furthermore,semantic distinctions fine-grained model identify accurately (e.g.,IBEFORE (immediately before), SIMULTANEOUS DURING). therefore reduced relationsTable 13 smaller set collapsing BEFORE, IBEFORE, IAFTER (immediatelyafter) one relationship. Analogously, collapsed SIMULTANEOUSLY DURING, INCLUDESINCLUDED, BEGINS BEGUN BY, ENDS ENDED BY. reduced relation setalso shown Table 13 (within parentheses).106fiL EARNING ENTENCE - INTERNAL EMPORAL R ELATIONS(BEFORE)IBEFORE(BEFORE)(BEFORE)IAFTER(BEFORE)INCLUDES(INCLUDES )INCLUDED(INCLUDES )(INCLUDES)ENDS(ENDS)ENDED(ENDS)BEGINS(BEGINS)BEGUN(BEGINS)SIMULTANEOUSTable 13:Pacific First Financial Corp. said shareholders approved acquisition Royal Trusstco Ltd. Toronto $27 share,$212 million.first would launch much-feared direct invasionSaudi Arabia, hoping seize Saudi oil fields improvebargaining position.Washington today Federal Aviation Administration released air traffic control tapes night TWA flight eighthundred went down.addition, Hewlett-Packard acquired two-year option buyextra 10%, half may sold directly HewlettPackard Octel.offer, shareholders receive one right 105common shares owned.purchase price disclosed preliminary prospectus issued connection MGM Grands planned offering sixmillion common shares.According Jordanian officials, smaller line Jordan remained operating.government may move seize money Mr. Antarusing pay legal fees.Financial Times 100-share index shed 47.3 points close2082.1, 4.5% previous Friday.DPC, investor group led New York-based Crescott Investment Associates, filed suit state court Los Angeles seeking nullify agreement.Saddam said begin withdrawing troops Iranian territory Friday release Iranian prisoners war.Nearly 200 Israeli soldiers killed fighting Hezbollahguerrillas guerrillas.relationships TimeBank; events participating relationship markedboldface; coarse-grained set relationships shown within parentheses.TILINKnext defined mapping temporal connectives reduced set TimeMLrelations (see Table 14). mapping cannot one-to-one, since connectivescompatible one temporal relationship (see Section 4.1). instanceindicate INCLUDES relationship. also expect mapping relatively noisygiven temporal markers entail non-temporal relationships (e.g., ). Table 14 includesadditional relation, namely no-temp-rel. thus option assigning temporalrelation, thereby avoiding pitfall making wrong prediction cases non-temporal107fiL APATA & L ASCARIDESTMarkafter,before,once,whenas,when,whileas,when,whilesinceno-temp-relTimeMLRelINCLUDESSIMULTANEOUSBEGINSENDS- TEMP - RELTrainInst31 64321 85922 1652 8105 33322 523TestInst8772463601964967Table 14: Mapping temporal markers coarse-grained set TimeML relations; numbertraining test instances per relation.inferences entailed two events. next describe training test instancesgenerated experiments.disjunctive ensemble model Experiment 1 trained B LLIP corpus usingfeatures component learners described Sections 4.2 5. training data consistedoriginal 83,810 main-subordinate clause pairs labeled temporal relations Table 14 (second column). added 22,523 instances representative - TEMP - RELrelation. instances gathered randomly concatenating main subordinate clausesbelonging different documents (for similar method, see Marcu & Echihabi, 2002). hypothesize two clauses trigger temporal relations, since neither syntacticallysemantically related. Instances connectives since mapped labels BEGINSENDS, respectively. addition BEGINS, since signal BEFORE, INCLUDES, SIMULTANE OUS temporal relations. However, experiments instances since used exclusivelylearn BEGINS relation. far perfect, felt necessary since BEGINS represented temporal marker. training instances equally splitrelationships INCLUDES SIMULTANEOUS. Similarly, data equallysplit among BEFORE, INCLUDES, SIMULTANEOUS. Instances after, before,exclusively used learning relation. number training instances per relation(TrainInst) given Table 14.test data, used sentences TimeBank corpus. tested ensemble modelintra-sentential event-event relations. Furthermore, excluded sentences overt temporalconnectives, want positively influence models performance. TimeBankcorpus explicitly annotated - TEMP - REL relation. however sentencescorpus whose events participate temporal relationship. therefore hypothesized sentences representative - TEMP - REL . total number test instances(TestInst) used experiment given Table 14.Results results summarized Table 15. compare performance disjunctiveensemble Section 5 naive word-based model. models trainedmain subordinate clauses B LLIP corpus. also report accuracy majoritybaseline defaults frequent class B LLIP training data (i.e., BEFORE). Finally,report performance (disjunctive) ensemble model trained testedTimeBank corpus (see column TestInst Table 14) using leave-one-out crossvalidation.Comparison latter model B LLIP-trained ensemble indicate whether unan108fiL EARNING ENTENCE - INTERNAL EMPORAL R ELATIONSModelMajority BaselineWord-based BaselineEnsemble (Disjunctive)Ensemble (Disjunctive)TrainCorpusB LLIPB LLIPB LLIPTimeBankAccuracy34 739 153 042 7F-scoreNA21.145.840.5Table 15: Results predicting TimeML event-event relationships; comparison wordbased baseline disjunctive ensemble models.TimeMLRelBEGINSENDSINCLUDESSIMULTANEOUS- TEMP - RELB LLIPAccuracy F-score46.447 610.57814.13750.051 546.747 862.866 153.045 8TimeBankAccuracy F-score63 253 2000047778598678949 653 542 740 5Table 16: Ensemble results inferring individual temporal relations; comparison ensemble model trained B LLIP TimeBank corpora.notated data indeed useful reducing annotation effort training requirements temporalinterpretation models.seen, disjunctive model trained B LLIP corpus significantly outperformstwo baseline models. also outperforms ensemble model trained TimeBank widemargin.5 find results encouraging considering approximations temporal interpretation model noise inherent B LLIP training data. Also note that, despitelinguistically informed, feature space encodes basic semantic temporal distinctions.example, aspectual information taken account, temporal expressions analyzed detail. One would hope extensive feature engineering would result improvedresults.examined performance varies class. Table 16 provides comparisontwo ensemble models trained B LLIP TimeBank corpus, respectively.models difficulty BEGINS ENDS classes. entirely surprising, sinceclasses represented relatively small number training instances (see Table 14). twomodels yield comparable results BEFORE, whereas B LLIP-trained ensemble delivers betterperformance INCLUDES, SIMULTANEOUS, - TEMP - REL .5. Unfortunately, cannot use 2 test assess whether differences two ensembles statisticallysignificant due leave-one-out crossvalidation methodology employed training testing TimeBank corpus. necessary given small size event-event relation data extracted TimeBank (2,533instances total, see Table 14).109fiL APATA & L ASCARIDESaware previous work attempts similar task. However, worthmentioning Boguraev Ando (2005) consider interpretation event-time temporal relations inter- intra-sententially. report accuracies ranging 53.1% 58.8% dependingintervening distance events times question (performance betterevents times occurring close other). Interestingly, interpretation model exploitsunannotated corpora conjunction TimeML annotations increase amount labeleddata training. method identifies unannotated instances distributionally similarmanually annotated corpus. contrast, rely solely unannotated data trainingexploiting instances explicitly marked temporal information. interesting future directioncombination data TimeML annotations basis devising improved models(for details, see Section 8).8. General Discussionpaper proposed data intensive approach temporal inference. introduced modelslearn temporal relations sentences temporal information made explicit via temporal markers assessed potential inferring relations cases overt temporal markersabsent. Previous work focused automatic tagging temporal expressions (Wilsonet al., 2001), learning ordering events manually annotated data (Mani et al., 2003),inferring temporal relations events time expressions annotatedunannotated data (Boguraev & Ando, 2005).models bypass need manual annotation training exclusively instancestemporal relations made explicit presence temporal markers. comparedcontrasted several models varying linguistic assumptions employed feature space.also explored tradeoff model complexity data requirements. results indicateless sophisticated models (e.g., disjunctive model) tend perform reasonably utilizingexpressive features training data sets relatively modest size. experimentedvariety linguistically motivated features ranging verbs semantic classes temporalsignatures argument structure. Many features inspired symbolic theoriestemporal interpretation, often exploit semantic representations (e.g., two clauses)well complex inferences world knowledge (e.g., Hobbs et al., 1993; Lascarides & Asher,1993; Kehler, 2002).best model achieved F-score 69.1% inferring temporal relations trainedtested B LLIP corpus context pseudo-disambiguation task. performancesignificant improvement baseline compares favorably human performancetask. Detailed exploration feature space revealed lexicalalso syntactic information important temporal inference. result agreementSoricut Marcu (2003) find syntax trees encode sufficient information enable accuratederivation discourse relations.also evaluated models performance realistic task predicting temporalrelations explicitly signaled text. end, evaluated B LLIP-trainedmodel TimeBank, corpus manually annotated temporal relations according TimeML specifications. experimental set-up challenging many perspectives. First, temporal markers used study received multiple meanings. ambiguity unavoidably introduced certain amount noise estimating parameters model110fiL EARNING ENTENCE - INTERNAL EMPORAL R ELATIONSdefining mapping markers TimeML relations. Second, guaranteerelations signaled temporal markers connecting main subordinate clauses hold eventsattested syntactic configurations non-temporal subordination coordination. Givenapproximations, model performed reasonably, reaching overall F-score 45.8%temporal inference task showing best performance relations BEFORE, INCLUDES, SIMUL TANEOUS - TEMP - REL . results show possible infer temporal informationcorpora even semantically annotated way hold promise relievingdata acquisition bottleneck associated creating temporal annotations.important future direction lies modeling temporal relations events across sentences. order achieve full-scale temporal reasoning, current model must extendednumber ways. involve incorporation extra-sentential information modelingtask well richer temporal information (e.g., tagged time expressions; see Mani et al., 2003).current models perform inference task independently surrounding context. Experiment 2 revealed rather difficult task; even humans cannot easily make decisions regardingtemporal relations out-of-context. future work, plan take account contextual (lexical syntactic) well discourse-based features (e.g., coreference resolution). Many linguistsalso observed identifying discourse structure text, conceptualized hierarchical structure rhetorically connected segments, identifying temporal relations amongevents logically co-dependent tasks (e.g., Kamp & Reyle, 1993; Hobbs et al., 1993; Lascarides& Asher, 1993). example, fact interpret (1a) forming narrative (1c)(1c) providing background information (1b) yields temporal relations among eventsdescribed Section 1: namely, temporal progression kissing girl walkinghome, temporal overlap remembering talking walking home.(1)a.b.c.John kissed girl met party.Leaving party, John walked home.remembered talking asking name.logical relationship discourse structure temporal structure suggestsoutput discourse parser (e.g., Marcu, 1999; Soricut & Marcu, 2003; Baldridge & Lascarides,2005) could used informative source features inferring temporal relations acrosssentence boundaries. would analogous discourse level use madesentential parser source features experiments inferring sentence-internal temporalrelations.approach presented paper also combined annotations presentTimeML corpus semi-supervised setting similar Boguraev Ando (2005) yieldimproved performance. Another interesting direction future work would use modelsproposed bootstrapping approach. Initially, model learned unannotated dataoutput manually edited following annotate automatically, correct manually methodologyused provide high volume annotation Penn Treebank project. iteration modelretrained progressively accurate representative data. Another issue related naturetraining data concerns temporal information entailed markersambiguous. could remedied either heuristically discussed Section 4.1 usingmodels trained unambiguous markers (e.g., before, ) disambiguate instances multiplereadings. Another possibility apply separate disambiguation procedure training data(i.e., prior learning temporal inference models).111fiL APATA & L ASCARIDESFinally, would like investigate utility temporal inference models withincontext specific natural language processing applications. thus intend explorepotential improving performance multi-document summarisation system. example,temporal reasoning component could useful extracting temporally congruent events,also structuring output summaries, i.e., temporally ordering extracted sentences.Although models presented target primarily interpretation tasks, could also adaptedgeneration tasks, e.g., inferring temporal marker generatedplaced.Acknowledgmentswork supported EPSRC (Lapata, grant GR/T04540/01; Lascarides,grant GR/R40036/01). grateful Regina Barzilay Frank Keller helpfulcomments suggestions. Thanks anonymous referees whose feedback helped substantially improve present paper. preliminary version work publishedproceedings NAACL 2004; also thank anonymous reviewers papercomments.112fiL EARNING ENTENCE - INTERNAL EMPORAL R ELATIONSAppendix A. Experimental Materials Human Evaluationfollowing list materials used human evaluation study reported Experiment 2(Section 6). sentences extracted B LLIP corpus following procedure describedSection 4.1.1234567891011121314151617181920addition, agencies werent always efficient getting word agenciescompanybarred.Mr. Reagan learned newsNational Security Adviser Frank Carlucci called tell hedseen television.instance, National Geographic caused uproarused computer neatly move twoEgyptian pyramids closer together photo.Rowes Wharf looks bestseen new Airport Water Shuttle speeding across Bostonharbor.older women divorcinghusbands retire.Together prepared head Fortune companyenjoying tranquil country life.estimated 190,000 legal abortions adolescents occurred, unknown numberillegal unreported abortions took place well.Mr. Rough, late 40s, allegedly leaked informationserved New YorkFederal Reserve Bank director January 1982 December 1984.contest became obsession Fumio Hirai, 30-year-old mechanical engineer, whose wife tookignoringtwo men tinkered months dancing house plants.calls whole experience wonderful, enlightening, fulfilling proud MCI functionedwellgone.lot want getget kicked out.prices started falling, market $1.5 billion week new issues, says headinvestment banking major Wall Street firm.start feeling sorry fair sex, note Bundys, Bunkers.Organization Petroleum Exporting Countries travel rocky roadPersian Gulfmembers rule world oil markets.certified deaths requiredFDA acts?Currently, large store builtsmaller merchants area approve it, difficulttime consuming process.review began last weekRobert L. Starer named president.lower rate camenations central bank, Bank Canada, cut weekly bank rate7.2% 7.54%.Black residents Washingtons low-income Anacostia section forced three-month closingChinese-owned restaurantowner threatened elderly black woman customer pistol.Laurie Massas back hurt monthsdelivery truck slammed car 1986.Table 17: Materials temporal pseudo-disambiguation task; markers bodlface indicategold standard completion; subjects asked select missing word settemporal markers after, before, while, when, as, once, until, since113fiL APATA & L ASCARIDES2122232425262728293031323334353637383940Donald Lasater, 62, chairman chief executive office, assume posts Mr. Farrell vacatessuccessor found.council said national assembly replaced appointed legislatorsnew elections heldU.S. lifts economic sanctions.problems disappear, Mr. Melzer suggests working base, raw materialforms money supply.green-coffee importer said sufficient supply Brazilharvest gets full swingnext month.pumpfire hand out.gene inserted human TIL cells, another safety check would made.part bus system subject market discipline, entire operation tends respond.China contrast,joint ventures legal, hundreds created.company said problem goes awaycar warms up.Toronto merger complete, combined entity 352 lawyers.justices ruled admission could usedclearly chosen speech silence.sinceMilosevics popularity risenbecame party chief Serbia, Yugoslavias biggest republic,1986.sincegovernment says already eliminated 600 million hours paperwork yearCongresspassed Paperwork Reduction Act 1980.sinceserious rebellion Conservative ranksMr. Mulroney elected four yearsago.sinceleast eight settlement attemptsTexas court handed multi-billiondollar judgment two years ago.sinceBrud LeTourneau, Seattle management consultant Merit smoker, laughskeeps trying flick non-existent ashes ashtray.Britains airports disrupted24-hour strike air traffic control assistants resultedcancellation thank 500 flights lengthy delays travelers.Stocks plungedinvestors ignored cuts European interest rates dollar bond rallies.Bostons Logan Airport, Delta plane landed wrong runwayanother jet takingoff.Polish strikers shut Gdansks portWarsaw rushed riot police city.Table 17: (continued)114fiL EARNING ENTENCE - INTERNAL EMPORAL R ELATIONSReferencesAllen, J. (1995). Natural Language Understanding. Benjamin Cummins.Asher, N., & Lascarides, A. (2003). Logics Conversation. Cambridge University Press.Baldridge, J., & Lascarides, A. (2005). Probabilistic head-driven parsing discourse structure.Proceedings Ninth Conference Computational Natural Language Learning, pp.96103, Ann Arbor, MI.Boguraev, B., & Ando, R. K. (2005). TimeML-compliant text analysis temporal reasoning.Proceedings 19th International Joint Conference Artificial Intelligence, pp. 9971003, Edingburgh, UK.Breiman, L. (1996a). Bagging predictors. Machine Learning, 2(24), 123140.Breiman, L. (1996b). Stacked regressions. Machine Learning, 3(24), 4964.Carlson, L., Marcu, D., & Okurowski, M. (2001). Building discourse-tagged corpus framework Rhetorical Structure Theory. Proceedings 2nd SIGDIAL Workshop Discourse Dialogue, Eurospeech 2001, Aalborg, Denmark.Cestnik, B. (1990). Estimating probabilities: crucial task machine learning. Proceedings16th European Conference Artificial Intelligence, pp. 147149, Stockholm, Sweden.Charniak, E. (2000). maximum-entropy-inspired parser. Proceedings 1st ConferenceNorth American Chapter Assocation Computational Linguistics, pp. 132139,Seattle, WA.Cherkauer, K. J. (1996). Human expert-level performance scientific image analysis tasksystem using combined artificial neural networks. Working Notes AAAI WorkshopIntegrating Multiple Learned Models, pp. 1521, Portland, OR.Ciaramita, M., & Johnson, M. (2003). Supersense tagging unknown words WordNet.Proceedings 8th Conference Empirical Methods Natural Language Processing,pp. 168175, Sapporo, Japan.Dietterich, T. G. (1997). Machine learning research: Four current directions. AI Magazine, 18(4),97136.Dorr, B., & Gaasterland, T. (1995). Selecting tense aspect connective words language generation. Proceedings 14th International Joint Conference Artificial Intelligence,pp. 12991307, Montreal, Canada.Dowty, D. (1986). effects aspectual class temporal sturcture discourse: Semanticspragmatics?. Linguistics Philosophy, 9(1), 3761.Fellbaum, C. (Ed.). (1998). WordNet: Electronic Database. MIT Press, Cambridge, MA.Ferro, L., Mani, I., Sundheim, B., & Wilson, G. (2000). TIDES temporal annotation guidelines.Tech. rep., MITRE Corporation.Freund, Y., & Shapire, R. E. (1996). Experiments new boosting algorithm. Proceedings13th International Conference Machine Learning, pp. 148156, Stanford, CA.Han, B., & Lavie, A. (2004). framework resolution time natural language. ACM Transactions Asian Language Information Processing (TALIP), 3(1), 1132.115fiL APATA & L ASCARIDESHansen, L. K., & Salamon, P. (1990). Neural network ensembles. IEEE Transactions PatternAnalysis Machine Intelligence, 12, 9931001.Hitzeman, J., Moens, M., & Grover, C. (1995). Algorithms analyzing temporal structurediscourse. Proceedings 7th Meeting European Chapter AssociationComputational Linguistics, pp. 253260, Dublin, Ireland.Hobbs, J. R., Stickel, M., Appelt, D., & Martin, P. (1993). Interpretation abduction. ArtificialIntelligence, 63(12), 69142.Hwang, C., & Schubert, L. (1992). Tense trees finite structure discourse. Proceedings30th Annual Meeting Association Computational Linguistics, pp. 232240,Newark, DE.Kamp, H., & Reyle, U. (1993). Discourse Lexicon: Introduction ModeltheoreticSemantics Natural Language, Formal Logic Discourse Representation Theory. KluwerAcademic Publishers.Katz, G., & Arosio, F. (2001). annotation temporal information natural language sentences.Proceedings ACL Workshop Temporal Spatial Information Processing, pp. 104111, Toulouse, France.Kehler, A. (2002). Coherence, Reference Theory Grammar. CSLI Publications, Cambridge University Press.Landis, J. R., & Koch, G. G. (1977). measurement observer agreement categorical data.Biometrics, 33, 159174.Lapata, M., & Brew, C. (2004). Verb class disambiguation using informative priors. ComputationalLinguistics, 30(1), 4573.Lascarides, A., & Asher, N. (1993). Temporal interpretation, discourse relations commonsenseentailment. Linguistics Philosophy, 16(5), 437493.Levin, B. (1995). English Verb Classes Alternations. Chicago University Press.Mani, I., & Schiffman, B. (2005). Temporally anchoring ordering events news. Pustejovsky, J., & Gaizauskas, R. (Eds.), Time Event Recognition Natural Language. JohnBenjamins.Mani, I., Schiffman, B., & Zhang, J. (2003). Inferring temporal ordering events news.Proceedings 1st Human Language Technology Conference Annual MeetingNorth American Chapter Association Computational Linguistics, pp. 5557, Edmonton, Canada.Marcu, D. (1999). decision-based approach rhetorical parsing. Proceedings 37thAnnual Meeting Association Computational Linguistics, pp. 365372, College Park,MD.Marcu, D., & Echihabi, A. (2002). unsupervised approach recognizing discourse relations.Proceedings 40th Annual Meeting Association Computational Linguistics,pp. 368375, Philadelphia, PA.Moens, M., & Steedman, M. J. (1988). Temporal ontology temporal reference. ComputationalLinguistics, 14(2), 1528.116fiL EARNING ENTENCE - INTERNAL EMPORAL R ELATIONSPustejovsky, J., Ingria, B., Sauri, R., Castano, J., Littman, J., Gaizauskas, R., & Setzer, A. (2004).specification TimeML. Mani, I., Pustejovsky, J., & Gaizauskas, R. (Eds.),Language Time: reader, pp. 545558. Oxford University Press.Pustejovsky, J., Mani, I., Belanger, L., Boguraev, B., Knippen, B., Litman, J., Rumshisky, A., See,A., Symonen, S., van Guilder, J., van Guilder, L., & Verhagen, M. (2003). ARDA summerworkshop graphical annotation toolkit TimeML. Tech. rep..Quinlan, R. J. (1993). C4.5: Programs Machine Learning. Series Machine Learning. MorganKaufman, San Mateo, CA.Quirk, R., Greenbaum, S., Leech, G., & Svartvik, J. (1985). Comprehensive GrammarEnglish Language. Longman, London.Saur, R., Littman, J., Gaizauskas, R., Setzer, A., & Pustejovsky, J. (2004). TimeML AnnotationGuidelines. TERQAS Workshop. Version 1.1.Schilder, F., & Habel, C. (2001). temporal expressions temporal information: Semantictagging news messages. Proceedings ACL Workshop Temporal Spatial Information Processing, pp. 6572, Toulouse, France.Setzer, A., & Gaizauskas, R. (2001). pilot study annotating temporal relations text.Proceedings ACL Workshop Temporal Spatial Information Processing, pp. 7380,Toulouse, France.Siegel, S., & Castellan, N. J. (1988).McGraw-Hill, New York.Non Parametric Statistics Behavioral Sciences.Soricut, R., & Marcu, D. (2003). Sentence level discourse parsing using syntactic lexical information. Proceedings 1st Human Language Technology Conference AnnualMeeting North American Chapter Association Computational Linguistics, pp.228235, Edmonton, Canada.Sporleder, C., & Lascarides, A. (2005). Exploiting linguistic cues classify rhetorical relations.Proceedings Recent Advances Natural Language Processing, pp. 532539, Borovets,Bulgaria.van Halteren, H., Zavrel, J., & Daelemans, W. (2001). Improving accuracy word class taggingcombination machine learning systems. Computational Linguistics, 27(2), 199230.Wiebe, J. M., OHara, T. P., Ohrstrom Sandgren, T., & McKeever, K. J. (1998). empiricalapproach temporal reference resolution. Journal Artifical Intelligence Research, 9, 247293.Wilson, G., Mani, I., Sundheim, B., & Ferro, L. (2001). multilingual approach annotatingextracting temporal information. Proceedings ACL Workshop Temporal SpatialInformation Processing, pp. 8187, Toulouse, France.Wolpert, D. H. (1992). Stacked generalization. Neural Networks, 5, 241259.117fiJournal Artificial Intelligence Research 27 (2006) 25-53Submitted 10/05; published 9/06Generative Prior Knowledge Discriminative ClassificationArkady EpshteynGerald DeJongaepshtey@uiuc.edudejong@uiuc.eduDepartment Computer ScienceUniversity Illinois Urbana-Champaign201 N. GoodwinUrbana, IL, 61801 USAAbstractpresent novel framework integrating prior knowledge discriminative classifiers. framework allows discriminative classifiers Support Vector Machines(SVMs) utilize prior knowledge specified generative setting. dual objectivefitting data respecting prior knowledge formulated bilevel program,solved (approximately) via iterative application second-order cone programming.test approach, consider problem using WordNet (a semantic databaseEnglish language) improve low-sample classification accuracy newsgroup categorization. WordNet viewed approximate, readily available source backgroundknowledge, framework capable utilizing flexible way.1. IntroductionSVM (Vapnik, 1995) classification accuracy many classification tasks oftencompetitive human subjects, number training examples requiredachieve accuracy prohibitively large domains. Intelligent user interfaces,example, must adopt behavior individual user limited amountinteraction order useful. Medical systems diagnosing rare diseases generalizewell seeing examples. natural language processing task performsprocessing level n-grams phrases (which frequent translation systems)cannot expect see sequence words sufficient number times even largetraining corpora. Moreover, supervised classification methods rely manually labeleddata, expensive obtain. Thus, important improve classificationperformance small datasets. classifiers competitive humansability generalize seeing examples. Various techniquesproposed address problem, active learning (Tong & Koller, 2000b; Campbell,Cristianini, & Smola, 2000), hybrid generative-discriminative classification (Raina, Shen,Ng, & McCallum, 2003), learning-to-learn extracting common information relatedlearning tasks (Thrun, 1995; Baxter, 2000; Fink, 2004), using prior knowledge.work, concentrate improving small-sample classification accuracyprior knowledge. prior knowledge proven useful classification (Scholkopf,Simard, Vapnik, & Smola, 2002; Wu & Srihari, 2004; Fung, Mangasarian, & Shavlik, 2002;Epshteyn & DeJong, 2005; Sun & DeJong, 2005), notoriously hard apply practicemismatch form prior knowledge employedclassification algorithms (either prior probabilities explicit constraints hypothesisc2006AI Access Foundation. rights reserved.fiEpshteyn & DeJongspace classifier) domain theories articulated human experts.unfortunate various ontologies domain theories available abundance,considerable amount manual effort required incorporate existing prior knowledgenative learning bias chosen algorithm. would take applyexisting domain theory automatically classification task specificallydesigned? work, take first steps towards answering question.experiments, domain theory exemplified WordNet, linguisticdatabase semantic connections among English words (Miller, 1990). apply WordNet standard benchmark task newsgroup categorization. Conceptually, generativemodel describes world works, discriminative model inextricably linkedspecific classification task. Thus, reason believe generative interpretationdomain theory would seem natural generalize better across differentclassification tasks. Section 2 present empirical evidence is, indeed,case WordNet context newsgroup classification. reason, interpretdomain theory generative setting. However, many successful learning algorithms(such support vector machines) discriminative. present framework allowsuse generative prior discriminative classification setting.algorithm assumes generative distribution data givenBayesian framework: P rob(data|model) prior P rob0 (model) known. However,instead performing Bayesian model averaging, assume single modelselected a-priori, observed data manifestation model (i.e.,drawn according P rob(data|M )). goal learning algorithm estimate. estimation performed two-player sequential game full information.bottom (generative) player chooses Bayes-optimal discriminator function f (M )probability distribution P rob(data|model = ) (without taking training dataaccount) given model . model chosen top (discriminative) playerway prior probability occurring, given P rob0 (M ), high, forcesbottom player minimize training-set error Bayes-optimal discriminatorf (M ). estimation procedure gives rise bilevel program. show that,problem known NP-hard, approximation solved efficiently iterativeapplication second-order cone programming.remaining issue construct generative prior P rob0 (model) automatically domain theory. describe solve problem Section 2,also argue generative setting appropriate capturing expert knowledge, employing WordNet illustrative example. Section 3, give necessarypreliminary information important known facts definitions. framework incorporating generative prior discriminative classification described detail Section4. demonstrate efficacy approach experimentally presenting resultsusing WordNet newsgroup classification Section 5. theoretical explanationimproved generalization ability discriminative classifier constrained generativeprior knowledge appears Section 6. Section 7 describes related work. Section 8 concludespaper outlines directions future research.26fiGenerative Prior Knowledge Discriminative Classification2. Generative vs. Discriminative Interpretation Domain KnowledgeWordNet viewed network, nodes representing words links representingrelationships two words (such synonyms, hypernyms (is-a), meronyms (partof), etc.). important property WordNet semantic distance - length(in links) shortest path two words. Semantic distance approximatelycaptures degree semantic relatedness two words. set experimentevaluate usefulness WordNet task newsgroup categorization. postingrepresented bag-of-words, binary feature representing presencecorresponding word. evaluation done pairwise classification tasksfollowing two settings:1. generative framework assumes posting x = [x1 , .., xn ] generateddistinct probability distribution newsgroup. simplest versionLinear Discriminan Analysis (LDA) classifier posits x|(y = 1) N ( 1 , I)x|(y = 1) N (2 , I) posting x given label {1, 1}, R(nn)identity matrix. Classification done assigning probable labelx: y(x) = 1 P rob(x|1) > P rob(x| 1). well-known (e.g. see Duda, Hart, &Stork, 2001) decision rule equivalent one given hyperplanec1 , ..,cn ] estimated via(2 1 )T x 21 (T2 2 T1 1 ) > 0. means bi = [1maximum likelihood training data [x1 , y1 ], .., [xm , ym ] .2. discriminative SVM classifier sets separating hyperplane directly minimizenumber errors training data:c1 , .., wcn ], bb] = arg minw,b kwk s.t. yi (wT xi + b) 1, = 1, .., m.[wb = [wexperiment conducted learning-to-learn framework (Thrun, 1995; Baxter,2000; Fink, 2004). first stage, classifier trained using training datatraining task (e.g., classifying postings newsgroups atheism guns).second stage, classifier generalized using WordNets semantic information.third stage, generalized classifier applied different, test task (e.g., classifyingpostings newsgroups atheism vs. mideast) without seeing data newclassification task. way classifier generalize setting useoriginal sample acquire information WordNet, exploit informationhelp label examples test sample. learning perform task,system also learns utilize classification knowledge implicit WordNet.describe second third stages two classifiers detail:1. intuitive interpret information embedded WordNet follows: titlenewsgroup guns, words semantic distancegun (e.g., artillery, shooter, ordnance distance two) providesimilar degree classification information. quantify intuition, let li,train =j1n[li,train, .., li,train, .., li,train] vector semantic distances WordNetfeature word j label training task newsgroup {1, 2}. Define1. standard LDA classifier assumes x|(y = 1) N (1 , ) x|(y = 1) N (2 , )estimates covariance matrix well means 1 , 2 training data. experiments,take = I.27fiEpshteyn & DeJong1)Train: atheism vs. guns2)Train: atheism vs. guns3)Train: guns vs. mideastTest: atheism vs. mideastTest: guns vs. mideastTest: atheism vs. mideast110.910.90.90.80.80.80.70.70.70.60.60.60.50.50.50200 400 600 800 1000 1200 1400 1600 18000200 400 600 800 1000 1200 1400 1600 18000200 400 600 800 1000 1200 1400 1600 1800Legend:GenerativeDiscriminativeFigure 2.1: Test set accuracy percentage versus number training points 3different classification experiments. classification task, random testset chosen full set articles 20 different ways. Error barsbased 95% confidence intervals.P(v) ,cjj=vi,trainj=v||j:li,trainj:l, = 1, 2, | | denotes cardinality set. compressesinformation bi based assumption words equidistant newsgrouplabel equally likely appear posting newsgroup. testperformance compressed classifier new task semantic distances givenj). Noticeli,test , generative distributions reconstructed via ji := (li,testclassifier trained tested task, applying functionequivalent averaging components means generative distributioncorresponding equivalence classes words equidistant label.classifier tested different classification task, reconstruction process reassignsaverages based semantic distances new labels.2. less intuitive interpret WordNet discriminative setting. One possibleinterpretation coefficients w j separating hyperplane governedsemantic distances labels, captured compression function 0 (v, u) ,Pcjwjj=u=v,l2,train1,trainjj|j:l1,train=v,l2,train=u|j:ljjreconstructed via w j := 0 (l1,test, l2,test).Note LDA generative classifier SVM discriminative classifierhypothesis space separating hyperplanes. resulting test set classificationaccuracy classifier classification tasks 20-newsgroup dataset28fiGenerative Prior Knowledge Discriminative Classification(Blake & Merz, 1998) presented Figure 2.1. x-axis graph representssize training task sample, y-axis - classifiers performance testclassification task. generative classifier consistently outperforms discriminativeclassifier. converges much faster, two three tasks discriminative classifierable use prior knowledge nearly effectively generative classifier evenseeing 90% available training data. generative classifier alsoconsistent performance - note error bars much smallerdiscriminative classifier. results clearly show potential using backgroundknowledge vehicle sharing information tasks. effective sharingcontingent appropriate task decomposition, supplied tuned generativemodel.evidence Figure 2.1 seemingly contradicts conventional wisdom discriminative training outperforms generative sufficiently large training samples. However,experiment evaluates two frameworks context using ontology transferinformation learning tasks. never done before. experiment demonstrates interpretation semantic distance WordNet intuitivegenerative classification setting, probably better reflects human intuitionsbehind WordNet.However, goal construct classifier performs well without seeingexamples test classification task. also want classifier improvesbehavior sees new labeled data test classification task. presents usproblem: one best-performing classifiers (and certainly best textclassification task according study Joachims, 1998) SVM, discriminativeclassifier. Therefore, rest work, focus incorporating generative priorknowledge discriminative classification framework support vector machines.3. Preliminariesobserved constraints probability measure half-spacecaptured second-order cone constraints Gaussian distributions (see, e.g., tutorialLobo, Vandenberghe, Boyd, & Lebret, 1998). allows efficient processingconstraints within framework second-order cone programming (SOCP). intendmodel prior knowledge elliptical distributions, family probability distributionsgeneralizes Gaussians. follows, give brief overview second-ordercone programming relationship constraints imposed Gaussian probabilitydistribution. also note possible extend argument presented Lobo etal. (1998) elliptical distributions.Second-order cone program mathematical program form:min v x(3.1)xs.t. kAi x + bi k cTi x + di , = 1, ..., N(3.2)x Rn optimization variable v Rn , Ai R(ki xn) , bi Rki , ci Rn ,di R problem parameters (kk represents usual L2 -norm paper). SOCPssolved efficiently interior-point methods, described Lobo et al. (1998)tutorial contains excellent overview theory applications SOCP.29fiEpshteyn & DeJonguse elliptical distribution model distribution data a-priori. Ellipticaldistributions distributions ellipsoidally-shaped equiprobable contours. densityfunction n-variate elliptical distribution form f,,g (x) = c(det )1 g((x)T 1 (x )), x Rn random variable, Rn location parameter,R(nxn) positive definite (n n)-matrix representing scale parameter, functiong() density generator, c normalizing constant. use notation X E(, , g) denote random variable X elliptical distributionparameters , , g. Choosing appropriate density generator functions g, Gaussiandistribution, Student-t distribution, Cauchy distribution, Laplace distribution,logistic distribution seen special cases elliptical distribution. Using elliptical distribution relaxes restrictive assumptions user makeimposing Gaussian prior, keeping many desirable properties Gaussians, as:1. X E(, , g), R(kn) , B Rk , AX + B E(A + B, AAT , g)2. X E(, , g), E(X) = .3. X E(, , g), V ar(X) = g , g constant dependsdensity generator g.following proposition shows elliptical distributions, constraint P (w x+b0) (i.e., probability X takes values half-space {w x + b 0} less) equivalent second-order cone constraint 21 :Proposition3.1. X E(, , g), P rob(w x + b 0) 12 equivalent (w +1/2b)/g, w , g, constant depends g .Proof. proof identical one given Lobo (1998) Lanckriet et al. (2001)Gaussian distributions provided completeness:Assume P rob(w x + b 0) .(3.3)Let u = w x+b. Let u denote mean u, denote variance. constraint3.3 writtenuuu(3.4)P rob( ) .properties elliptical distributions, u = w + b, = g 1/2 w , uu)E(0, 1, g). Thus, statement 3.4 expressed P robXE(0,1,g) (X w +b1/2 wkgk, equivalent w +b1 (), (z) = P robXE(0,1,g) (X z).1/2 wkgkproposition follows g, = g 1 ().Proposition 3.2. monotonically decreasing g, P robXE(,,g) (x) equivalent1/2 (x ) g,c, , g,c,, = g 1 ( ||c ) constant dependsg, c, , .Proof. Follows directly definition P robXE(,,g) (x).30fiGenerative Prior Knowledge Discriminative Classification4. Generative Prior via Bilevel Programmingdeal binary classification task: classifier function f (x) mapsinstances x Rn labels {1, 1}. generative setting, probability densitiesP rob(x|y = 1; 1 ) P rob(x|y = 1; 2 ) parameterized = [1 , 2 ] provided (orestimated data), along prior probabilities class labels (y = 1)(y = 1), Bayes optimal decision rule given classifierf (x|) = sign(P rob(x|y = 1; 1 )(y = 1) P rob(x|y = 1; 2 )(y = 1)),sign(x) := 1 x 0 1 otherwise. LDA, instance, parameters 12 means two Gaussian distributions generating data given label.Informally, approach incorporating prior knowledge straightforward: assumetwo-level hierarchical generative probability distribution model. low-level probabilitydistribution data given label P rob(x|y; ) parameterized , which, turn,known probability distribution P rob0 (). goal classifier estimatevalues parameter vector training set labeled points [x 1 , y1 ]...[xm , ym ].estimation performed two-player sequential game full information.bottom (generative) player, given , selects Bayes optimal decision rule f (x|).top (discriminative) player selects value high probability occurring(according P rob0 ()) force bottom player select decision ruleminimizes discriminative error training set. give formalspecification training problem formulate bilevel program.assumptions subsequently relaxed enforce tractability flexibility.use elliptical distribution E(1 , 1 , g) model X|y = 1, another ellipticaldistribution E(2 , 2 , g) model X|y = 1. parameters , , = 1, 2 known,Bayes optimal decision rule restricted class linear classifiers 2 formfw,b (x) = sign(w x + b) given f (x) minimizes probability error amonglinear discriminants: P rob(error) = P rob(w x + b 0|y = 1)(y = 1) + P rob(w x + b0|y = 1)(y = 1) = 12 (P robXE(1 ,1 ,g) (wT x + b 0) + P robXE(2 ,2 ,g) (wT x + b 0)),assuming equal prior probabilities classes. model uncertaintymeans elliptical distributions , = 1, 2 imposing elliptical prior distributionslocations means: E(ti , , g), = 1, 2. addition, ensure optimizationproblem well-defined, maximize margin hyperplane subject imposedgenerative probability constraints:min kwk(4.1)1 ,2s.t.yi (wT xi + b) 1, = 1, ..,P robi E(ti ,i ,g) (i ) , = 1, 2(4.2)(4.3)[w, b] solves min[P robXE(1 ,1 ,g) (w x + b 0) + P robXE(2 ,2 ,g) (w x + b 0)]w,b(4.4)bilevel mathematical program (i.e., optimization problemconstraint region implicitly defined another optimization problem), strongly2. decision rule restricted class classifiers H optimal probability error largerclassifier H (Tong & Koller, 2000a).31fiEpshteyn & DeJongNP-hard even constraints objectives linear (Hansen, Jaumard,& Savard, 1992). However, show possible solve reasonable approximation problem efficiently several iterations second-order cone programming.First, relax second-level minimization (4.4) breaking two constraints:P robXE(1 ,1 ,g) (wT x + b 0) P robXE(2 ,2 ,g) (wT x + b 0) . Thus, instead looking Bayes optimal decision boundary, algorithm looks decisionboundary low probability error, low error quantified choice .Propositions 3.1 3.2 enable us rewrite optimization problem resultingrelaxation follows :min kwk(4.5)1 ,2 ,w,bs.t.yi (wT xi + b) 1, = 1, ..,1/2(i ti ) , = 1, 2P robi E(ti ,i ,g) (i ) , = 1, 2w 1 + bP robXE(1 ,1 ,g) (wT x + b 0)1/21 ww 2 + bP robXE(2 ,2 ,g) (wT x + b 0)1/22 w(4.6)(4.7)(4.8)(4.9)Notice form program depend generator function gelliptical distribution - constants depend it. defines far systemwilling deviate prior choice generative model, boundstail probabilities error (Type Type II) system tolerate assumingchosen generative model correct. constants depend specific generatorg amount error user willing tolerate. experiments, selectvalues constants optimize performance. Unless user wants controlprobability bounds constants, sufficient assume a-prioriprobability distributions (both prior hyper-prior) elliptical, without makingcommitments.algorithm solves problem repeating following two steps:1. Fix top-level optimization parameters 1 2 . step combines objectives maximizing margin classifier training data ensuringdecision boundary (approximately) Bayes optimal respect givengenerative probability densities specified 1 , 2 .2. Fix bottom-level optimization parameters w, b. Expand feasible regionprogram step 1 function 1 , 2 . step fixes decision boundarypushes means generative distribution far away boundaryconstraint (4.7) allow.steps repeated convergence (in practice, convergence detectedoptimization parameters change appreciably one iteration next).step algorithm formulated second-order cone program:32fiGenerative Prior Knowledge Discriminative ClassificationStep 1. Fix 1 2 . Removing unnecessary constraints mathematicalprogram pushing objective constraints, get following SOCP:min(4.10)w,bs.t. kwk(4.11)yi (wT xi + b) 1, = 1, ..,(4.12)wT1+b1/21 w(4.13)w 2 + b1/22 w(4.14)Step 2. Fix w, b expand span feasible region, measuredw 1 +b .1/21 ww 2 +b1/22 wRemoving unnecessary constraints, get:w 2 + b w 1 + bmax1/21 ,2 1/22 w1 w1/2(i ti ) , = 1, 2s.t.(4.15)(4.16)behavior algorithm illustrated Figure 4.1.following theorems state algorithm converges.Theorem4.1. Supposenalgorithm produces sequence iterates(t) (t)(t)(t), quality iterate evaluated margin w(t) .1 , 2 , w , bt=0evaluation function converges.(t)(t)(t)(t)Proof. Let 1 , 2 values prior location parameters, w1 , b1minimum error hyperplane algorithm finds end t-th step. end(t+1) (t+1)(t + 1)-st step, w1, b1still feasible region t-th step SOCP.(t) )T(t)2 +b1/2 (t)w2true function f ( (w(t) )T(t)1 +b1/2 (t)w1, (w)=(w(t) )T 2 +b(t)1/2 (t)2 w(w(t) )T 1 +b(t)1/2 (t)1 wmonotonically increasing one arguments argument fixed,(t+1) (t+1)fixing 1 (or 2 ) fixes exactly one argument. solution 1, 2end(t+1)(t + 1)-st step(t+1)fixing 1(t)(t)(w(t)+b) 21/2 (t)2 w< , f could increased(t)using value 2 beginning step ensures(t) )T(t)(w2 +b1/2 (t)2 w, contradicts observation f maximized end(t+1)second step. contradiction reached(t)(w(t)+b) 11/2 (t)1 w< . Sinceminimum error hyperplane previousiteration feasible region start(t)must decrease monotonically one iterationnext iteration, objective wnext. Since bounded zero, algorithm converges.33fiEpshteyn & DeJong1)2)554433221100110123451101233)54433221100054)51141234511012345Figure 4.1: Steps iterative (hard-margin) SOCP procedure:(The region hyperprior probability larger shaded priordistribution. covariance matrices represented equiprobable elliptical contours.example, covariance matrices hyperprior prior distributionsmultiples other. Data points two different classes represented diamondssquares.)1. Data, prior, hyperprior algorithm executed.2. Hyperplane discriminator end step 1, iteration 13. Priors end step 2, iteration 14. Hyperplane discriminator end step 2, iteration 2algorithm converges end step 2 problem (step 3 movehyperplane).addition convergence objective function, accumulation pointssequence iterates characterized following theorem:n(t) (t)Theorem 4.2. accumulation points sequence 1 , 2 , w(t) , b(t) (i.e., limitingpoints convergent subsequences) feasible descent directions originaloptimization problem given (4.5)-(4.9).Proof. See Appendix A.34fiGenerative Prior Knowledge Discriminative Classificationpoint feasible descent directions, sufficiently small step alongdirectional vector either increase objective function, leave unchanged, takealgorithm outside feasible region. set points feasible descent directionssubset set local minima. Hence, convergence point somewhatweaker result convergence local minimum.practice, observed rapid convergence usually within 2-4 iterations.Finally, may want relax strict assumptions correctness prior/linearseparability data introducing slack variables optimization problem above.results following program:min1 ,2 ,w,b,i ,1 ,2 ,1 ,2kwk + C1X+ C2 (1 + 2 ) + C3 (1 + 2 )(4.17)i=1s.t.yi (wT xi + b) 1 , = 1, ..,1/2(i ti ) + , = 1, 2w 1 + b1/21 w 1w 2 + b1/22 w 20, = 1, ..,0, = 1, 20, = 1, 2(4.18)(4.19)(4.20)(4.21)(4.22)(4.23)(4.24)before, problem solved two-step iterative SOCP procedure.Imposing generative prior soft constraints ensures that, amount trainingdata increases, data overwhelms prior algorithm converges maximummargin separating hyperplane.5. Experimentsexperiments designed demonstrate usefulness proposed approachincorporation generative prior discriminative classification, addressbroader question showing possible use existing domain theory aidclassification task specifically designed. order constructgenerative prior, generative LDA classifier trained data trainingclassification task estimate Gaussian location parameters bi , = 1, 2, describedSection 2. compression function (v) subsequently computed (also describedjSection 2), used set hyperprior parameters via ji := (li,test), = 1, 2.order apply domain theory effectively task specificallydesigned, algorithm must able estimate confidence decompositiondomain theory respect new learning task. order model uncertaintyapplicability WordNet newsgroup categorization, system estimated confidencehomogeneity equivalence classes semantic distances computing variance35fiEpshteyn & DeJong0.85Bilevel Gen/Discr0.80.750.70.650.60.550.50.50.550.60.65 0.7SVM0.750.80.85Figure 5.1: Performance bilevel discriminative classifier constrained generativeprior knowledge versus performance SVM. point represents uniquepair training/test tasks, 0.5% test task data used training.results averaged 100 experiments.Prandom variable (v) follows: (v) ,j:lc(ji (v))2ji,train=vj|j:li,tran=v|. hyperprior confidencematrices , = 1, 2 reconstructedrespect test task semantic distancesj(li,test), k = j. Identity matrices usedli,test , = 1, 2 follows: [i ]j,k :=0, k 6= jcovariance matrices lower-level prior: 1 = 2 := I. rest parametersset follows: := 0.2, := 0.01, C1 = C2 := 1, C3 := . constantschosen manually optimize performance Experiment 1 (for training task: atheismvs. guns, test task: guns vs. mideast, see Figure 5.2) without observing dataclassification tasks.resulting classifier evaluated different experimental setups (with differentpairs newsgroups chosen training test tasks) justify followingclaims:1. bilevel generative/discriminative classifier WordNet-derived prior knowledge good low-sample performance, showing feasibility automaticallyinterpreting knowledge embedded WordNet efficacy proposedalgorithm.2. bilevel classifiers performance improves increasing training sample size.3. Integrating generative prior discriminative classification framework resultsbetter performance integrating prior directly generativeframework via Bayes rule.36fiGenerative Prior Knowledge Discriminative Classification4. bilevel classifier outperforms state-of-the-art discriminative multitask classifierproposed Evgeniou Pontil (2004) taking advantage WordNet domaintheory.order evaluate low-sample performance proposed classifier, four newsgroups20-newsgroup dataset selected experiments: atheism, guns, middle east,auto. Using categories, thirty experimental setups created possibleways assigning newsgroups training test tasks (with pair newsgroups assignedtask, constraint training test pairs cannot identical) 3 .experiment, compared following two classifiers:1. bilevel generative-discriminative classifier knowledge transfer functions(v), (v), = 1, 2 learned labeled training data provided training task (using 90% available data task). resulting priorsubsequently introduced discriminative classification framework via approximate bilevel programming approach2. vanilla SVM classifier minimizes regularized empirical risk:minw,b,iXi=1+ C1 kwk2s.t.yi (wT xi + b) 1 , = 1, ..,(5.1)(5.2)classifiers trained 0.5% available data test classificationtask4 , evaluated remaining 99.5% test task data. results, averagedone hundred randomly selected datasets, presented Figure 5.1, showsplot accuracy bilevel generative/discriminative classifier versus accuracySVM classifier, evaluated thirty experimental setups. pointslie 45o line, indicating improvement performance due incorporation priorknowledge via bilevel programming framework. amount improvement ranges10% 30%, improvements statistically significant 5%level.next experiment conducted evaluate effect increasing training data(from test task) performance system. experiment, selectedthree newsgroups (atheism, guns, middle east) generated six experimental setupsbased possible ways splitting newsgroups unique training/test pairs.addition classifiers 1 2 above, following classifiers evaluated:3. state-of-the art multi-task classifier designed Evgeniou Pontil (2004).classifier learns set related classification functions ft (x) = wtT x + bt classification tasks {training task, test task} given m(t) data points [x1t , y1t ], .., [xm(t)t , ym(t)t ]3. Newsgroup articles preprocessed removing words could interpreted nounsWordNet. preprocessing ensured one part WordNet domain theory exercisedresulted virtually reduction classification accuracy.4. SeDuMi software (Sturm, 1999) used solve iterative SOCP programs.37fiEpshteyn & DeJongtask minimizing regularized empirical risk:minw0 ,wt ,bt ,itXX m(t)i=1+C1 Xkwt w0 k2 + C1 kw0 k2C2s.t. yit (wtT xit + bt ) 1 , = 1, .., m(t),0, = 1, .., m(t),(5.3)(5.4)(5.5)regularization constraint captures tradeoff final models w closeaverage model w0 large margin training data. 90%training task data made available classifier. Constant C1 := 1 chosen,C2 := 1000 selected set {.1, .5, 1, 2, 10, 1000, 105 , 1010 } optimizeclassifiers performance Experiment 1 (for training task: atheism vs. guns,test task: guns vs. mideast, see Figure 5.2) observing .05% test task data(in addition training task data).4. LDA classifier described Section 2 trained 90% test task data. Sinceclassifier bottom-level generative classifier used bilevelalgorithm, performance gives upper bound performance bottomlevel classifier trained generative fashion.Figure 5.2 shows performance classifiers 1-3 function size trainingdata test task (evaluation done remaining test-task data). resultsaveraged one hundred randomly selected datasets. performance bilevelclassifier improves increasing training data discriminative portionclassifier aims minimize training error generative prior imposedsoft constraints. expected, performance curves classifiers convergeamount available training data increases. Even though constants used mathematical program selected single experimental setup, classifiers performancereasonable wide range data sets across different experimental setups,possible exception Experiment 4 (training task: guns vs. mideast, testing task: atheismvs. mideast), means constructed elliptical priors much closerexperiments. Thus, prior imposed greater confidencewarranted, adversely affecting classifiers performance.multi-task classifier 3 outperforms vanilla SVM generalizing data pointsacross classification tasks. However, take advantage prior knowledge,classifier does. gain performance bilevel generative/discriminative classifierdue fact relationship classification tasks captured muchbetter WordNet simple linear averaging weight vectors.constants involved bilevel classifier generative classifiers Bayesian priors, hard fair comparison classifiers constrainedgenerative priors two frameworks. Instead, generatively trained classifier 4gives empirical upper bound performance achievable bottom-level classifiertrained generatively test task data. accuracy classifier shownhorizontal plots Figure 5.2. Since discriminative classification knownsuperior generative classification problem, SVM classifier outperforms38fiGenerative Prior Knowledge Discriminative Classification1) Train:atheism vs. guns2) Train:atheism vs. guns3) Train:guns vs. mideastTest:atheism vs. mideastTest:guns vs. mideastTest:atheism vs. guns1110.950.950.950.90.90.90.850.850.850.80.80.80.750.750.750.70.70.70.650.650.650.60.60.60.550.550010 20 30 40 50 60 70 80 90 1004) Train: guns vs. mideast1020304050607080905) Train: atheism vs. mideast0.5501110.950.950.90.90.90.850.850.850.80.80.80.750.750.750.70.70.70.650.650.650.60.6010203040506070809030405060708090Test:atheism vs. guns0.950.55206) Train: atheism vs. mideastTest:guns vs. mideastTest:atheism vs. mideast100.60.550.55010 20 30 40 50 60 70 80 90 1000102030405060708090Legend:LDA,max performanceBilevel Gen/DiscrSVMMultitask SVMFigure 5.2: Test set accuracy percentage versus number test task training pointstwo classifiers (SVM Bilevel Gen/Discr) tested six different classificationtasks. classification experiment, data set split randomlytraining test sets 100 different ways. error bars based 95%confidence intervals.generative classifier given enough data four six experimental setups.interesting, that, range training sample sizes, bilevel classifier constrainedgenerative prior outperforms SVM trained samplegenerative classifier trained much larger sample four setups. means that,unless prior knowledge outweighs effect learning, cannot enable LDA classifiercompete bilevel classifier problems.Finally, set experiments performed determine effect varying mathematical program parameters generalization error. parametervaried set values, rest parameters held fixed ( increasedmaximum feasible value). evaluation done setup Experiment 1 (for39fiEpshteyn & DeJong1) Accuracy function2) Accuracy function0.180.180.160.160.140.140.120.120.10.10.080.080.060.060.040.040.020.020000.050.10.150.200.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.91Figure 5.3: Plots test set accuracy percentage versus mathematical program parametervalues. classification task, random training set size 9 chosenfull set test task articles 100 different ways. Error bars based95% confidence intervals. experiments performed trainingtask: atheism vs. guns, test task: guns vs. mideast.training task:atheism vs. guns, test task: guns vs. mideast), training set size9 points. results presented Figure 5.3. Increasing value equivalentrequiring hyperplane separator smaller error given prior. Decreasingvalue equivalent increasing confidence hyperprior. actionstighten constraints (i.e., decrease feasible region). good prior knowledge,effect improving generalization performance small training samplessince prior imposed higher confidence. precisely observeplots Figure 5.3.6. Generalization Performancealgorithm generalize well low sample sizes? section, derivetheorem demonstrates convergence rate generalization errorconstrained generative-discriminative classifier depends parameters mathematical program margin, would expected case large-marginclassification without prior. particular, show certainty generative prior knowledge increases, upper bound generalization error classifierconstrained prior decreases. increasing certainty prior, meaneither hyper-prior becomes peaked (i.e., confidence locationsprior means increases) desired upper bounds Type Type II probabilitieserror classifier decrease (i.e., requirement lower-level discriminativeplayer choose restricted Bayes-optimal hyperplane strictly enforced).argument proceeds bounding fat-shattering dimension classifier constrained prior knowledge. fat-shattering dimension large margin classifiergiven following definition (Taylor & Bartlett, 1998):Definition 6.1. set points = {x1 ...xm } -shattered set functions Fmapping domain X R real numbers r 1 , ..., rm that,b {1, 1}m , function fb F b(fb (xi ) ri ) , = 1..m. say40fiGenerative Prior Knowledge Discriminative Classificationr 1 , ..., rm witness shattering. fat-shattering dimension F functionfatF () maps cardinality largest -shattered set S.Specifically, consider class functionsF = {x w x : kxk R, kwk = 1,(6.1)wT (1 )w 21/21/2,,()(),1122 }.121/21/21 w2 wfollowing theorem bounds fat-shattering dimension classifier:Theorem 6.2. Let F class a-priori constrained functions defined (6.1),let min (P ) max (P ) denote minimum maximum eigenvalues matrix P ,222 )),respectively. set points -shattered F , |S| 4R ( (1222(1 )(1 )2 k (max (2 )), kt2ktk(,= max(1 , 2 ) 1 = min( min) 2 = min( min2k2 kk1 kmax (2 )) +kt2 k)kt1 k2 (max (1 ))2),kt1 k((max (1 ))2 +kt1 k)assuming 0, kti k kti k,1 ,2= 1, 2.Proof. See Appendix B.following corollary follows directly Taylor Bartletts (1998)Theorem 1.5 bounds classifiers generalization error based fat-shatteringdimension:Corollary 6.3. Let G class real-valued functions. Then, probability least1 independently generated examples z, classifier h = sgn(g) sgn(G)2margin least examples z, error h(d8m)log(32m)+log())=f().G=Fclassfunctionslog( 8emGG16222defined (6.1), dF 265R (4( 2 (1 ))) . G = F 0 usual class large marginclassifiers (without prior), result (Taylor & Bartlett, 1998) shows F 0265R2.22Notice bounds depend R. However, bound classifier constrained2generative prior also depends term 4( 2 (1 2 )). particular, increases, tightening constraints, bound decreases, ensuring, expected,quicker convergence generalization error. Similarly, decreasing also tightensconstraints decreases upper bound generalization error. > 12 ,factor 4(2 (1 2 )) less 1 upper bound fat-shattering dimension dFtighter usual bound no-prior case dF 0 .Since controls amount deviation decision boundary Bayesoptimal hyperplane depends variance hyper-prior distribution, tighteningconstraints corresponds increasing confidence prior. Note highvalue represents high level user confidence generative elliptical model. Alsonote two ways increasing tightness hyperprior constraint (4.7)- one user-defined parameter , automaticallyestimated covariance matrices , = 1, 2. matrices estimate extent41fiEpshteyn & DeJongequivalence classes defined WordNet create appropriate decomposition domaintheory newsgroup categorization task. Thus, tight constraint (4.7) representshigh level user confidence means generative classification model (estimatedWordNet) good correspondence partition words imposedsemantic distance WordNet elliptical generative model data.approaches zero approaches highest feasible value, solution bilevelmathematical program reduces restricted Bayes optimal decision boundary computedsolely generative prior distributions, without using data.Hence, shown that, prior imposed increasing level confidence(which means elliptical generative model deemed good, estimatesmeans good, turn implies domain theory well-suitedclassification task hand), convergence rate generalization error classifierincreases. Intuitively, precisely desired effect increased confidence priorsince benefit derived training data outweighed benefit derivedprior knowledge. low data samples, result improved accuracy assumingdomain theory good, plots Figure 5.3 show.7. Related Worknumber approaches combining generative discriminative models. Several focus deriving discriminative classifiers generative distributions (Tong& Koller, 2000a; Tipping, 2001) learning parameters generative classifiers viadiscriminative training methods (Greiner & Zhou, 2002; Roos, Wettig, Grunwald, Myllymaki, & Tirri, 2005). closest spirit approach Maximum EntropyDiscrimination framework (Jebara, 2004; Jaakkola, Meila, & Jebara, 1999), performsdiscriminative estimation parameters generative model, taking account constraints fitting data respecting prior. One important differenceframework that, estimating parameters, maximum entropy discrimination minimizes distance generative model prior, subject satisfyingdiscriminative constraint training data classified correctly given margin.framework, hand, maximizes margin training data subjectconstraint generative model far prior. emphasismaximizing margin allows us derive a-priori bounds generalization errorclassifier based confidence prior (yet) available maximum entropy framework. Another difference approach performs classificationvia single generative model, maximum entropy discrimination averages setgenerative models weighted probabilities. similar distinctionmaximum-a-posteriori Bayesian estimation repercussions tractability. Maximum entropy discrimination, however, general framework senseallowing richer set behaviors based different priors.Ng et al. (2003, 2001) explore relative advantages discriminative generativeclassification propose hybrid approach improves classification accuracylow-sample high-sample scenarios. Collins (2002) proposes use Viterbialgorithm HMMs inferencing (which based generative assumptions), combineddiscriminative learning algorithm HMM parameter estimation. research42fiGenerative Prior Knowledge Discriminative Classificationdirections orthogonal work since explicitly consider questionintegration prior knowledge learning problem.context support vector classification, various forms prior knowledgeexplored. Scholkopf et al. (2002) demonstrate integrate prior knowledgeinvariance transformations importance local structure kernel function.Fung et al. (2002) use domain knowledge form labeled polyhedral sets augmenttraining data. Wu Srihari (2004) allow domain experts specify confidenceexamples label, varying effect example separating hyperplaneproportionately confidence. Epshteyn DeJong (2005) explore effects rotational constraints normal separating hyperplane. Sun DeJong (2005)propose algorithm uses domain knowledge (such WordNet) identify relevantfeatures examples incorporate resulting information form soft constraintshypothesis space SVM classifier. Mangasarian et al. (2004) suggest use priorknowledge support vector regression. approaches, prior knowledge takesform explicit constraints hypothesis space large-margin classifier.work, emphasis generating constraints automatically domain knowledgeinterpreted generative setting. demonstrate WordNet application,generative interpretation background knowledge intuitive natural languageprocessing problems.Second-order cone constraints applied extensively model probability constraints robust convex optimization (Lobo et al., 1998; Bhattacharyya, Pannagadatta, &Smola, 2004) constraints distribution data minimax machines (Lanckrietet al., 2001; Huang, King, Lyu, & Chan, 2004). work, far know, first onemodels prior knowledge constraints. resulting optimization problemconnection Bayes optimal classification different approachesmentioned above.work also related empirical Bayes estimation (Carlin & Louis, 2000). empirical Bayes estimation, hyper-prior parameters generative model estimatedusing statistical estimation methods (usually maximum likelihood method moments)marginal distribution data, approach learns parametersdiscriminatively using training data.8. Conclusions Future Work.Since many sources domain knowledge (such WordNet) readily available, believesignificant benefit achieved developing algorithms automatically applyinginformation new classification problems. paper, argued generative paradigm interpreting background knowledge preferable discriminativeinterpretation, presented novel algorithm enables discriminative classifiersutilize generative prior knowledge. algorithm evaluated context complete system which, faced newsgroup classification task, able estimateparameters needed construct generative prior domain theory, useconstruction achieve improved performance new newsgroup classification tasks.work, restricted hypothesis class linear classifiers. Extendingform prior distribution distributions elliptical and/or looking43fiEpshteyn & DeJongBayes-optimal classifiers restricted expressive class linear separatorsmay result improvement classification accuracy non linearly-separable domains.However, obvious approximate expressive form prior knowledgeconvex constraints. kernel trick may helpful handling nonlinear problems,assuming possible represent optimization problem exclusively termsdot products data points constraints. important issue requiresstudy.demonstrated interpreting domain theory generative settingintuitive produces good empirical results. However, usually multiple waysinterpreting domain theory. WordNet, instance, semantic distancewords one measure information contained domain theory. Other,complicated, interpretations might, example, take account types linkspath words (hypernyms, synonyms, meronyms, etc.) exploit commonsense observations WordNet words closer category labellikely informative words farther away. Comparing multiple waysconstructing generative prior domain theory and, ultimately, selecting oneinterpretations automatically fruitful direction research.Acknowledgmentsauthors thank anonymous reviewers valuable suggestions improving paper. material based upon work supported part National Science FoundationAward NSF IIS 04-13161 part Information Processing Technology Office Defense Advanced Research Projects Agency award HR0011-05-1-0040.opinions, findings, conclusions recommendations expressed publicationauthors necessarily reflect views National ScienceFoundation Defense Advanced Research Projects Agency.Appendix A. Convergence Generative/Discriminative AlgorithmLet map H : Z Z determine algorithm that, given point (0) , generates sequence (t) t=0 iterates iteration (t+1) = H((t) ). iterative algorithm(t)(t)Section 4 generates sequence iterates (t) = [1 , 2 ] Z applying followingmap H:H = H 2 H1 :(A.1)step 1, H1 ([1 , 2 ]) = argmin[w,b]U ([1 ,2 ])kwk ,set U ([1 , 2 ]) defined constraints:(A.2)(A.3)yi (w xi + b) 1 0, = 1, ..,(A.4)c1 (w, b; 2 , 2 ) 0wT +b.conic constraints cs (w, b; , ) ,k1/2 wk(A.6)c1 (w, b; 1 , 1 ) 044(A.5)fiGenerative Prior Knowledge Discriminative Classificationstep 2, H2 (w, b) = argmin(1 ,2 )V(c1 (w, b; 1 , 1 ) + c1 (w, b; 2 , 2 ))(A.7)set V given constraintso(1 ; 1 , t1 ) 0(A.8)o(2 ; 2 , t2 ) 0(A.9)o(; , t) , 1/2 ( t) .Notice H1 H2 functions minima optimization problems(4.10)-(4.14) (4.15)-(4.16) unique. case Step 1 optimizesstrictly convex function convex set, Step 2 optimizes linear non-constant functionstrictly convex set.Convergence objective function ((t) ) , min[w,b]U ([(t) ,(t) ]) kwk algorithm12shown Theorem 4.1. Let denote set points map Hchange value objective function, i.e. (H( )) = ( ).show every accumulation point {(t) } lies . also show every point[1 , 2 ] augmented [w , b ] = H1 ([1 , 2 ]) point feasible descentdirections optimization problem (4.5)-(4.9), equivalently expressed as:min kwk s.t.[1 , 2 ] V ; [w, b] U ([1 , 2 ])1 ,2 ,w,b(A.10)order formally state result, need concepts duality theory.Let constrained optimization problem givenmin f (x) s.t. ci (x) 0, = 1, .., kx(A.11)following conditions, known Karush-Kuhn-Tucker(KKT) conditions necessaryx local minimum:Proposition A.1. x local minimum (A.11), 1 , .., kP1. f (x ) = ki=1 ci (x )2. 0 {1, .., k}3. ci (x ) 0 {1, .., k}4. ci (x ) = 0 {1, .., k}1 , .., k known Lagrange multipliers constraints c1 , .., ck .following well-known result states KKT conditions sufficient xpoint feasible descent directions:Proposition A.2. 1 , .., k following conditions satisfied x :P1. f (x ) = ki=1 ci (x )45fiEpshteyn & DeJong2. 0 {1, .., k}x feasible descent directions problem (A.11)Proof. (sketch) reproduce proof given textbook Fletcher (1987). proposition true Pfeasible direction vector s, sT ci (x) 0 x{1, .., k}. Hence, f (x ) = ki=1 sT ci (x ) 0, descent direction.following lemma characterizes points set :Lemma A.3. Let , let [w , b ] = H1 ( ) optimizer ( ), let= [(A.4),1 , .., (A.4),m , (A.5) , (A.6) ] set Lagrange multipliers correspondingconstraints solution [w , b ]. Define 0 = H( ), let [w 0 , b0 ] optimizer(0 ). 02 6= 2 , (A.6) = 0 . 01 6= 1 , (A.5) = 0 .01 6= 1 02 6= 2 , (A.6) = (A.5) = 0 .Proof. Consider case02 6= 2(A.12)01 = 1(A.13)Since , kw0 k = kw k. Let 0 set Lagrange multipliers correspondingconstraints solution [w 0 , b0 ]. Since w still feasible optimization problemgiven (0 ) (by argument Theorem 4.1) minimum problemunique, happen[w0 , b0 ] = [w , b ].(A.14)[w , b ] 0 must satisfy KKT conditions (0 ). (A.12) impliesc1 (w ; 02 , 2 ) > c1 (w ; 2 , 2 ) argument Theorem 4.1, meansthat, KKT condition (4) (0 ),0(A.6) = 0.(A.15)Therefore, KKT condition (1) (0 ) (A.15), [w, b, 1 , 2 ] = [w = w0 , b =b0 , 1 = 01 , 2 ]"""###c1 (w,b ;1 ,1 )c1 (w,b ;2 ,2 )kwkXxw+ 0(A.5) c1 (ww=0(A.4),i+ 0(A.6) c1 (ww,,b; , )kwk,b;2 ,2 )11yibbi=1bmeans KKT conditions (1),(2) optimization problem ( ) satisfied0point [w , b ] = . KKT condition (3) satisfied feasibility [w , b ]KKT condition (4) satisfied condition (0 ) observations (A.13),(A.14), (A.15).proofs two cases (02 = 2 , 01 6= 1 02 6= 2 , 01 6= 1 )analogous.following theorem states points KKT points (i.e., pointsKKT conditions satisfied) optimization problem given (A.10).46fiGenerative Prior Knowledge Discriminative ClassificationTheorem A.4. let [w , b ] = H1 ( ), [w , b , 1 , 2 ] KKT pointoptimization problem given (A.10).Proof. Let 0 = H( ). like Lemma A.3, consider case02 6= 2 ,(A.16)01 = 1 (A.6) = 0 (by Lemma A.3).(A.17)(the proofs two cases similar).KKT conditions H2 (w , b ), 1 = 01(o(1 ; 1 , t))c1 (w , b ; 1 , 1 )= 0A.80A.8 0.11(A.18)KKT conditions H1 ( ) (A.17), [w, b] = [w , b ]"kwkwkwkb#=Xi=1(A.4),iyi xyi+(A.5)"c1 (w,b ;1 ,1 )wc1 (w ,b;1 ,1 )b#(A.4),1..(A.4),m(A.5)0.(A.19)(A.16),(A.17),(A.18), (A.19), [w, b, 1 , 2 ] = [w , b , 1 = 01 , 2 ]c1 (w,b ; ,1 )kwkkwk1xwwkwkw,b; , )c(w11X1yib 0+=kwk =b+(A.5)(A.4),i 00c1 (w ,b ;1 ,1 )1i=11kwk0002c1 (w,b ;2 ,2 )00wc1 (w ,b;2 ,2 )00+,b0A.8 (A.5)+ (A.6)(o(;,t))1 1(A.6)001(o(2 ;2 ,t))c1 (w ,b ;2 ,2 )022means KKT conditions (1),(2) optimization problem (A.10) satisfied00point [w , b , 1 , 2 ] = [(A.4),1 , .., (A.4),m , (A.5) , (A.6) , 0A.8 (A.5) , (A.6) ].00also satisfies KKT conditions (3),(4) assumption (A.17) KKT conditionsH1 H2 .order prove convergence properties iterates (t) , use following theoremdue Zangwill (1969):Theorem A.5. Let map H : Z Z determine iterative algorithm via (t+1) =H((t) ), let () denote objective function, let set pointsmap H change value objective function, i.e. (H()) = ().Suppose47fiEpshteyn & DeJong1. H uniformly compact Z, i.e. compact subset Z0 ZH() Z0 Z.2. H strictly monotonic Z , i.e. (H()) < ().3. H closed Z , i.e. wi w H(wi ) , = H(w).accumulation points sequence (t) lie .following proposition shows minimization continuous function feasibleset continuous map functions argument forms closed function.Proposition A.6. Given1. real-valued continuous function f B,2. point-to-set map U : 2B continuous respect Hausdorff metric:5dist(X, ) , max(d(X, ), d(Y, X)), d(X, ) , maxxX minyY kx yk,define function F : BF (a) = arg min f (a, b0 ) = {b : f (a, b) < f (a, b0 ) b0 U (a)},b0 U (a)assuming minimum exists unique. Then, function F closed a.Proof. proof minor modification one given Gunawardana Byrne(2005). Let {a(t) } sequencea(t) a, F (a(t) ) b(A.20)function F closed F (a) = b. Suppose case, i.e. b 6= F (a) =arg minb0 U (a) f (a, b0 ). Therefore,b = arg min f (b0 ) f (a, b) > f (a, b)b0 U (a)(A.21)continuity f (, ) (A.20),f (a(t) , F (a(t) )) f (a, b)(A.22)continuity U () (A.20),dist(U (a(t) ), U (a)) 0 b(t) b b(t) U (at ), t.(A.23)(A.22), (A.23), (A.21) implyK f (a(t) , F (a(t) )) > f (a(t) , b(t) ), > K(A.24)contradiction since assumption, F (a(t) ) = arg minb0 U (at ) f (b0 ) (A.24),b(t) U (a(t) ).5. point-to-set map U (a) maps point set points. U (a) continuous respect distancemetric dist iff a(t) implies dist(U (a(t) ), U (a)) 0.48fiGenerative Prior Knowledge Discriminative ClassificationProposition A.7. function H defined (A.1)-(A.7) closed.Proof. Let {(t) } sequence (t) . Since iterates (t) lieclosed feasible region bounded constraints (4.6)-(4.9) boundary U ()piecewise linear , boundary U ((t) ) converges uniformly boundary U ( )(t) , implies Hausdorff distance boundaries convergeszero. Since Hausdorff distance convex sets equal Hausdorff distanceboundaries, dist(U ((t) ), U ( )) also converges zero. Hence, propositionA.6 implies H1 closed. proposition implies H2 closed. compositionclosed functions closed, hence H closed.prove main result Section:Theorem 4.2. Let H function defined (A.1)-(A.7) determines generative/discriminative algorithm via (t+1) = H((t) ). accumulation pointssequence (t) augmented [w , b ] = H1 ( ) feasible descent directionsoriginal optimization problem given (4.5)-(4.9).Proof. proof verifying H satisfies properties Theorem A.5. ClosednessH shown Proposition A.7. Strict monotonicity ((t) ) shown Theorem4.1. Since iterates (t) closed feasible region bounded constraints (4.6)(4.9), H uniformly compact Z. Since accumulation points lie ,KKT points original optimization problem Theorem A.4, and, therefore,feasible descent directions Proposition A.2.Appendix B. Generalization Generative/Discriminative Classifierneed auxiliary results proving Theorem 6.2. first proposition boundsangle rotation two vectors w1 , w2 distance anglerotation vectors reference vector v sufficiently small:Proposition B.1. Let kw1 k = kw2 k = kvk = 1. w1T v 0 w2T v 0,1. w1T w2 22 1p2. kw1 w2 k 2 (1 2 )Proof.1. triangle inequality, arccos(w1T w2 ) arccos(w1T v) + arccos(w2T v) 2 arccos()(since angle two vectors distance measure). Taking cosinessides using trigonometric equalities yields w1T w2 22 1.2. Expand kw1 w2 k2 = kw1 k2 + kw2 k2 2w1T w2 = 2(1 w1T w2 ). Since w1T w2 22 1part 1, kw1 w2 k2 4(1 2 ).next proposition bounds angle rotation two vectorsfar away measured L2 -norm distance:49fiEpshteyn & DeJongProposition B.2. Let ktk = , k tk .tTktkkk2 2(+ ) .Proof. Expanding k tk2 = ktk2 + kk2 2tt using k tk2 2 , get1 ktk2 ( kkkkktk2tTktkkk+ktkkk ). use triangle inequality ktk k tk kkktk + k tk + simplify.following proposition used bound angle rotation normalw separating hyperplane mean vector hyper-prior distribution:wTkwkkkktk2 2ktk(+ktk) ).Proposition B.3. Let= min(,0 k tk ktk.wTkwkktk(22 1),Proof. Follows directly Propositions B.1 (part 1) B.2.prove Theorem 6.2, relies parts well-known proof fatshattering dimension bound large margin classifiers derived Taylor Bartlett(1998).Theorem 6.2. Let F class a-priori constrained functions defined 6.1,let min (P ) max (P ) denote minimum maximum eigenvalues matrix P ,222 ))respectively. set points -shattered F , |S| 4R ( (1,222(1 )(1 )2 k (max (2 )), kt2ktk(,) 2 = min( min= max(1 , 2 ) 1 = min( min2k2 kk1 kmax (2 )) +kt2 k)kt1 k2 (max (1 ))2),kt1 k((max (1 ))2 +kt1 k)assuming 0, kti k kti k,1 ,2= 1, 2.Proof. First, use inequality min (P ) kwk P 1/2 w max (P ) kwk relaxconstraintsw 2w 2min (2 )(B.1)1/2kwk2 w1/2= max (2 ).(B.2)2 (2 t2 ) k2 t2 kmin (12 )1/2wT 1constraints imposed second prior 1/2 , 1 (1 t1 ) relaxedsimilar fashion produce:2 wwT (1 )min (1 )kwk(B.3)k1 t1 k max (1 )(B.4)Now, show assumptions made statement theorem hold,222PPevery subset satisfies k (S S0 )k 4R ( 2(1 ) .Assume -shattered F . argument used Taylor Bartlett (1998)Lemma 1.2 shows that, definition fat-shattering, exists vector w 1XXw1 ((S S0 )) |S| .(B.5)50fiGenerative Prior Knowledge Discriminative ClassificationSimilarly (reversing labeling S0 S1 S0 ), exists vector w2XXw2 ( (S S0 )) |S| .(B.6)Hence, (w1 w2 )(impliesPP(S S0 )) 2 |S| , which, Cauchy-Schwartz inequality,2 |S|Pkw1 w2 k Pk (S S0 )k(B.7)constraints classifier represented B.1 B.2 imply Proposition B.3w1T t2w2T t222kw1 kkt2 k (21 1) kw2 kkt2 k (22 1) . Now, applying Proposition B.1 (part 2)simplifying, getqkw1 w2 k 412 (1 12 ).Applying analysis constraints B.3 B.4, getqkw1 w2 k 4 22 (1 22 ).Combining B.7, B.8, B.9, getXX|S|(S S0 ) p2 2 (1 2 )(B.8)(B.9)(B.10)defined statement theorem.Taylor Bartletts (1998) Lemma 1.3 proves, using probabilistic method,satisfiesXpX(B.11)(S S0 ) |S|R.Combining B.10 B.11 yields |S|4R2 (2 (12 )).2ReferencesBaxter, J. (2000). model inductive bias learning. Journal Artificial IntelligenceResearch, 12, 149198.Bhattacharyya, C., Pannagadatta, K. S., & Smola, A. (2004). second order cone programming formulation classifying missing data. NIPS.Blake,C.,&Merz,C.(1998).20newsgroupshttp://people.csail.mit.edu/people/jrennie/20newsgroups/..database,Campbell, C., Cristianini, N., & Smola, A. (2000). Query learning large margin classifiers. Proceedings Seventeenth International Conference Machine Learning.Carlin, B., & Louis, T. (2000). Bayes Empirical Bayes Methods Data Analysis.Chapman Hall.Collins, M. (2002). Discriminative training methods hidden markov models: Theoryexperiments perceptron algorithms. Proceedings 2002 ConferenceEmpirical Methods Natural Language Processing.51fiEpshteyn & DeJongDuda, R., Hart, P., & Stork, D. (2001). Pattern Classification. John Wiley. 2nd edition.Epshteyn, A., & DeJong, G. (2005). Rotational prior knowledge svms. ProceedingsSixteenth European Conference Machine Learning.Evgeniou, T., & Pontil, M. (2004). Regularized multi-task learning. ProceedingsTenth ACM SIGKDD International Conference Knowledge Discovery DataMining.Fink, M. (2004). Object classification single example utilizing class relevance metrics.Advances Neural Information Processing Systems.Fletcher, R. (1987). Practical Methods Optimization. John Wiley Sons, West Sussex,England.Fung, G., Mangasarian, O., & Shavlik, J. (2002). Knowledge-based support vector machineclassifiers. Advances Neural Information Processing Systems.Greiner, R., & Zhou, W. (2002). Structural extension logistic regression: Discriminativeparameter learning belief net classifiers. Proceedings Eighteenth NationalConference Artificial Intelligence.Gunawardana, A., & Byrne, W. (2005). Convergence theorems generalized alternatingminimization procedures. Journal Machine Learning Research, 6, 20492073.Hansen, P., Jaumard, B., & Savard, G. (1992). New branch-and-bound rules linear bilevelprogramming. SIAM Journal Scientific Statistical Computing, 13, 11941217.Huang, K., King, I., Lyu, M. R., & Chan, L. (2004). minimum error minimax probabilitymachine. Journal Machine Learning Research, 5, 12531286.Jaakkola, T., Meila, M., & Jebara, T. (1999). Maximum entropy discrimination. AdvancesNeural Information Processing Systems.Jebara, T. (2004). Machine Learning: Discriminative Generative. Kluwer AcademicPublishers.Joachims, T. (1998). Text categorization support vector machines: learning manyrelevant features. Proceedings Tenth European Conference Machine Learning.Lanckriet, G. R. G., Ghaoui, L. E., Bhattacharyya, C., & Jordan, M. I. (2001). Minimaxprobability machine. Advances Neural Information Processing Systems.Lobo, M. S., Vandenberghe, L., Boyd, S., & Lebret, H. (1998). Applications second-ordercone programming. Linear Algebra Applications, 284 (13), 193228.Mangasarian, O., Shavlik, J., & Wild, E. (2004). Knowledge-based kernel approximation.Journal Machine Learning Research.Miller, G. (1990). WordNet: online lexical database. International Journal Lexicography, 3 (4).Ng, A. Y., & Jordan, M. I. (2001). discriminative vs. generative classifiers: comparisonlogistic regression naive bayes. Advances Neural Information ProcessingSystems.52fiGenerative Prior Knowledge Discriminative ClassificationRaina, R., Shen, Y., Ng, A. Y., & McCallum, A. (2003). Classification hybrid generative/discriminative models. Advances Neural Information Processing Systems.Roos, T., Wettig, H., Grunwald, P., Myllymaki, P., & Tirri, H. (2005). discriminativebayesian network classifiers logistic regression. Machine Learning, 59, 267296.Scholkopf, B., Simard, P., Vapnik, V., & Smola, A. (2002). Prior knowledge supportvector kernels. Advances kernel methods - support vector learning.Sturm, J. F. (1999). Using SeDuMi 1.02, MATLAB toolbox optimization symmetric cones. Optimization Methods Software, 11, 625653.Sun, Q., & DeJong, G. (2005). Explanation-augmented svm: approach incorporatingdomain knowledge svm learning. Proceedings Twenty Second International Conference Machine Learning.Taylor, J. S., & Bartlett, P. (1998). Generalization performance support vector machinespattern classifiers. Advances kernel methods: support vector learning.Thrun, S. (1995). learning n-th thing easier learning first?. AdvancesNeural Information Processing Systems.Tipping, M. E. (2001). Sparse bayesian learning relevance vector machine. JournalMachine Learning Research, 1, 211244.Tong, S., & Koller, D. (2000a). Restricted bayes optimal classifiers. ProceedingsSeventeenth National Conference Artificial Intelligence.Tong, S., & Koller, D. (2000b). Support vector machine active learning applicationstext classification. Proceedings Seventeenth International ConferenceMachine Learning.Vapnik, V. (1995). Nature Statistical Learning Theory. Springer-Verlag.Wu, X., & Srihari, R. (2004). Incorporating prior knowledge weighted margin supportvector machines. Proceedings Tenth ACM SIGKDD International ConferenceKnowledge Discovery Data Mining.Zangwill, W. (1969). Convergence conditions nonlinear programming algorithms. Management Science, 16, 113.53fi