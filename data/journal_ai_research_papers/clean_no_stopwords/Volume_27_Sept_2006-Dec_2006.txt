Journal Artificial Intelligence Research 27 (2006) 465-503

Submitted 04/06; published 12/06

Preference-based Search using Example-Critiquing Suggestions
Paolo Viappiani
Boi Faltings

PAOLO . VIAPPIANI @ EPFL . CH
BOI . FALTINGS @ EPFL . CH

Artificial Intelligence Laboratory (LIA)
Ecole Polytechnique Federale de Lausanne (EPFL)
Station 14, 1015 Lausanne, Switzerland

Pearl Pu

PEARL . PU @ EPFL . CH

Human Computer Interaction Group (HCI)
Ecole Polytechnique Federale de Lausanne (EPFL)
Station 14, 1015 Lausanne, Switzerland

Abstract
consider interactive tools help users search preferred item large
collection options. particular, examine example-critiquing, technique enabling users
incrementally construct preference models critiquing example options presented
them. present novel techniques improving example-critiquing technology adding
suggestions displayed options. suggestions calculated based analysis users
current preference model potential hidden preferences. evaluate performance
model-based suggestion techniques synthetic real users. Results show
suggestions highly attractive users stimulate express preferences
improve chance identifying preferred item 78%.

1. Introduction
internet makes unprecedented variety opportunities available people. Whether looking
place go vacation, apartment rent, PC buy, potential customer faced
countless possibilities. people difficulty finding exactly looking for,
current tools available searching desired items widely considered inadequate.
Artificial intelligence provides powerful techniques help people address essential problem. Search engines effective locating items users provide correct queries.
However, users know map preferences query find item
closely matches requirements.
Recommender systems (Resnick et al., 1994; Adomavicius & Tuzhilin, 2005; Burke, 2002b)
address problem mapping explicit implicit user preferences items likely fit
preferences. range systems require little input users
user-involved systems. Many collaborative filtering techniques (Konstan et al., 1997), infer user
preferences past actions, previously purchased rated items. hand,
popular comparison websites1 often require users state least preferences desired
attribute values producing list recommended digital cameras, portable computers, etc.
article, consider tools provide recommendations based explicitly stated preferences, task call preference-based search. particular, problem defined as:
1. E.g., www.shopping.com
c
2006
AI Access Foundation. rights reserved.

fiV IAPPIANI , FALTINGS , & P U

Given collection = {o1 , .., } n options, preference-based search (PBS)
interactive process helps users identify preferred option, called target
option ot , based set preferences stated attributes
target.
Tools preference-based search face tradeoff two conflicting design goals:
decision accuracy, measured percentage time user finds target option
using tool,
user effort, measured number interaction cycles task time user takes
find option believes target using tool.
target option, refer option user prefers among available options.
determine accuracy product search tool, measure whether target option user
finds tool corresponds option finds reviewing available options
offline setting. procedure, also known switching task, used consumer decision
making literature (Haubl & Trifts, 2000). Notice procedure used measure
accuracy system. suggest procedure models human decision behavior.
one approach, researchers focus purely accuracy order help users find preferred choice. example, Keeney Raiffa (1976) suggested method obtain precise model
users preferences. method, known value function assessment procedure, asks
user respond long list questions. Consider case search ideal apartment. Suppose decision outcome involves trading preferred values size apartment
distance apartment city center. typical assessment question
form else equal, better: 30 sqm 60 minutes distance 20 sqm 5 minutes distance? Even though results obtained way provide precise model determine
preferred outcome user, process often cognitively arduous. requires
decision maker full knowledge value function order articulate answers
value function assessment questions. Without training expertise, even professionals known
produce incomplete, erroneous, inconsistent answers (Tversky, 1974). Therefore, techniques useful well-informed decision makers, less users need help
recommender system.
Recently, researches made significant improvement method. Chajewska, Koller,
Parr (2000) consider prior probability distribution users utility function ask questions
highest value information attributes give highest expected utility. Even
though developed decision problems uncertainty, adaptive elicitation principle
used preference elicitation product search often modeled decision
multiple objectives (see related work section approach Price & Messinger, 2005).
Boutilier (2002) Boutilier, Patrascu, Poupart, Schuurmans (2005) improved
method taking account value assigned future preference elicitation questions order
reduce user effort modeling maximum possible regret stopping criterion.
another extreme, researchers emphasized providing recommendations little effort possible users. Collaborative filtering techniques (Konstan et al., 1997), example, infer implicit model users preferences items rated. example
technique Amazons people bought item also bought... recommendation. However, users may still make significant effort assigning ratings order obtain accurate
466

fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONS

recommendations, especially new user systems (known new user problem).
techniques produce recommendations based users demographic data (Rich, 1979; Krulwich,
1997).
1.1 Mixed Initiative Based Product Search Recommender Systems
two extremes, mixed-initiative dialogue systems emerged promising solutions flexibly scale users effort specifying preferences according
benefits perceive revealing refining preferences already stated. also
referred utility knowledge-based recommender systems according Burke (2002b),
utility-based decision support interface systems (DSIS) according Spiekermann Paraschiv
(2002). mixed-initiative system, user takes initiative state preferences, typically
reaction example options displayed tool. Thus, user provide explicit preferences
decision-theoretic methods, free flexibly choose information provide,
recommender systems.
success systems depends AI techniques supporting search
recommending task, also effective user-system interaction model motivates users
state complete accurate preferences. must strike right compromise recommendation accuracy offers effort requires users. key criterion evaluate
systems therefore accuracy vs. effort framework favors systems offer maximum accuracy requiring less user effort. framework first proposed
Payne, Bettman, Johnson (1993) studying user behaviors high-stake decision making settings later adapted online user behaviors medium-stake decision making environments Pu Chen (2005) Zhang Pu (2006).
current practice, mixed-initiative product search recommender system computes
display set (i.e., items presented user) based closeness items users
preference model. However, set items likely provide diversity hence may
compromise decision accuracy. Consider example user looking portable
PC gives low price long battery life initial preferences. best matching products
likely standard models 14-inch display weight around 3 kilograms.
user may thus never get impression good variety available weight size, may
never express preferences criteria. Including lighter product display set may
greatly help user identify true choice hence increase decision accuracy.
Recently, need recommending best matches, called candidates, also
diverse set items, called suggestions, recognized. One first recognize
importance suggestive examples ATA (Linden, Hanks, & Lesh, 1997), explicitly
generated examples showed extreme values certain attributes, called extreme examples.
case-based recommender systems, strategy generating similar diverse cases
used (McSherry, 2002; Smyth & McGinty, 2003). Hebrard, Hnich, OSullivan, Walsh (2005) investigated algorithms generating similar diverse solutions constraint programming,
used recommend configurable products. complexity algorithms
analyzed.
far, suggestive examples aim providing diverse set items without analyzing deeply whether variety actually helps users make better decisions. One exception
compromise-driven diversity generation strategy McSherry (2003) proposes suggest
467

fiV IAPPIANI , FALTINGS , & P U

items representative possible compromises user might prepared consider.
Pu Li (2005) pointed out, tradeoff reasoning (making compromises) increase decision accuracy, indicates compromise-driven diversity might high potential
achieve better decision quality users. However, empirical studies carried
prove this.
1.2 Contribution Work
consider mixed-initiative framework explicit preference model, consisting iterative process showing examples, eliciting critiques refining preference model. Users
never forced answer questions preferences yet possess. hand,
preferences volunteered constructed, directly asked. key difference
navigation-by-proposing used mixed-initiative user interaction model opposed
value assessment-by-asking used traditional decision support systems.
set simulated real-user involved experiments, argue including diverse
suggestions among examples shown mixed initiative based product recommender
significant improvement state-of-the-art field. specifically, show
model-based suggestion techniques developed indeed motivate users express
preferences help achieve much higher level decision accuracy without additional
effort.
rest article organized follows. first describe set model-based techniques
generating suggestions preference-based search. novelty method includes: 1)
expands users current preference model, 2) generates set suggestions based analysis
likelihood missing attributes, 3) displays suggested options whose attractiveness
stimulates users preference expression. validate theory, examine suggestion
techniques help users identify target choice simulation environments real
users. base evaluation experiments two main criteria. Firstly, consider
completeness users preference model measured preference enumeration, i.e., number
features user stated preferences. higher enumeration, likely
user considered aspects decision goal, therefore decision likely
rational. Secondly, consider decision accuracy measured contrary switching rate,
number users find target option using tool choose another
product reviewing options detail. smaller switching rate, likely user
content chosen using tool, thus higher decision accuracy.
success suggestion techniques confirmed experimental evaluations. online
evaluation performed real users exploring student housing database. supervised user
study additionally carried 40 users, performed within-subject experiment setup
evaluated quantitative benefits model-based suggestion. results demonstrate
model-based suggestion increased decision accuracy 78%, users effort
using example-critiquing search tool without suggestions. user studies
consider particular criteria accuracy vs. effort never carried researchers
validating suggestion strategies optimal elicitation procedures.
Finally, end reviewing related works followed conclusion.
468

fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONS

Initial
preferences

User revises
preference model
critiquing examples

System shows K
examples

User picks final
choice

Figure 1: Example-critiquing interaction. dark box computers action, boxes show
actions user.

2. Example-critiquing
many cases, users searching products information familiar available
items characteristics. Thus, preferences well established, constructed
learning possibilities (Payne et al., 1993). allow construction take place,
search tool ask questions complete realistic context, abstract way.
good way follow principle implement example critiquing interaction (see
Figure 1). shows examples available options invites users state critique
examples. allows users better understand preferences.
Example-critiquing proposed numerous researchers two main forms: systems
without explicit preference models:
systems without preference models, user proceeds tweaking current best example (I like cheaper,I like French cuisine) make fit
preferences better. preference model represented implicitly currently chosen
example interaction navigation-by-proposing. Examples systems
FindMe systems (Burke, Hammond, & Young, 1997; Burke, 2002a), ExpertClerk
system (Shimazu, 2001), dynamic critiquing systems (Reilly, McCarthy, McGinty, &
Smyth, 2004).
systems preference models, critique added explicit preference model
used refine query. Examples systems explicit preference models include
ATA system (Linden et al., 1997), SmartClient (Pu & Faltings, 2000), recently
incremental critiquing (McCarthy, McGinty, Smyth, & Reilly, 2005).
article, focus example-critiquing explicit preference model advantage effectively resolving users preference conflicts. Moreover, approach helps
users make particular choice, also obtains accurate preference model future purchases
cross-domain recommendations.
469

fiV IAPPIANI , FALTINGS , & P U

2.1 Example
simple example consider student looking housing. Options characterized
following 4 attributes:
1. rent Swiss Francs;
2. type accommodation: room shared apartment, studio, apartment
3. distance university minutes;
4. furnished/unfurnished.
Assume choice among following options:
o1
o2
o3
o4
o5
o6
o7

rent
400
500
600
600
650
700
800

type-of-accommodation
room
room
apartment
studio
apartment
studio
apartment

distance-to-university
17
32
14
5
32
2
7

furnished
yes
yes



yes


Assume user initially articulates preference lowest price. also hidden
preferences unfurnished accomodation, distance less 10 minutes university. None options satisfy preferences, suitable option requires
user make tradeoff among preferences. Let us assume tradeoffs option
o4 would users preferred option. call target option.
user may start search first preference (lowest price), tool would
show k best options according order shown table. Here, let k = 1
option o1 shown.
example-critiquing tool without preference model, user indicates critique
currently shown example, system searches another example similar
possible current one also satisfying critique. case, user might critique
o1 furnished, tool might show o3 similar unfurnished
preference. user might add critique option 10 minutes
university, system would return o7 similar option satisfies critique.
user might critique option expensive, case system would
return o3 similar preference cheaper option. memory
earlier critiques, process stuck cycle, user never discover target o4 .
tool preference model, user able state preference unfurnished
option, making o3 best option. Next, might add additional preference distance
less 10 minutes university, ending o4 target choice. illustrates
explicit preference model ensures convergence process. fact, decision theory
shows preferences expressed, user always able identify
target choice. Note however complex scenarios might require explicit tradeoffs among
preferences locate right target choice (Pu & Kumar, 2004).
470

fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONS

popular approach obtain preference model elicit asking questions user.
However, lead means objectives (Keeney, 1992) distract true target choice.
example, tool might first ask user whether prefers room, studio apartment.
user truly preference, might try translate preference unfurnished option
preference apartment, since likely unfurnished. However,
true preference shift best tradeoff o4 o3 even o7 . illustrates
importance mixed-initiative approach user state preferences order
initiative.
example-critiquing framework raises issues model preferences, generate
solutions shown user, efficiently implement process. briefly
summarize results previous work addressing issues.
2.2 Preference Modeling
tool forces users formulate preferences using particular attributes particular order,
fall prey means objectives (Keeney, 1992) catalog knowledge relate true intentions. Means objectives objectives person believes
correlate positively true objectives. example, manufacturer reputation good
quality may become objective impossible state objective quality itself.
avoid means objectives, require preference model allows users state preferences incrementally using attribute, order wish. Furthermore, preference model
must easy revise critiquing cycle adding removing preferences.
rules commonly used techniques question-answer dialogues selection
fixed set preferences commonly used web today.
effective formalism satisfies criteria formulate preferences using soft constraints. soft constraint function attribute combination attributes number
indicates degree constraint violated. generally, values soft
constraint elements semiring (Bistarelli, Montanari, & Rossi, 1997).
several soft constraints, combined single preference measure. Examples combination operators summing taking maximum. overall preference order outcomes
given combined measure.
example, attribute take values a, b c, soft constraint indicating
preference value b could map c 1, b 0, thus indicating b
violate preference. preference surface area least 30 square meters,
small violation 5 square meters could acceptable, expressed piecewise linear
function:
1
0.2(30 x)
0

x < 25
25 x 30
x > 30

example-critiquing, critique expressed soft constraint, preference
model incrementally constructed simply collecting critiques. Note also possible
user express several preferences involving attributes, example express one
soft constraint surface area least 30 square meters (as above), another
471

fiV IAPPIANI , FALTINGS , & P U

soft constraint 50 square meters. soft constraints combined
summing effects, result leads piecewise linear function:
1

x < 25

0.2(30 x)

25 x 30

0

30 < x < 50

0.2(x 50)

50 x 55

1

x > 55

Thus, soft constraints allow users express relatively complex preferences intuitive manner.
makes soft constraints useful model example-critiquing preference models. Furthermore,
exist numerous algorithms combine branch-and-bound constraint consistency techniques efficiently find preferred options combined order. details
use soft constraints preference models provided Pu & Faltings (2004).
However soft constraints technique allows user partially incrementally specify
preferences. advantage utility functions necessary elicit users
preference every attribute. attributes whose values concern current decision context
elicited. example, user interested certain brand notebooks,
concern stating preferences products. parsimonious approach
similar adaptive elicitation method proposed Chajewska et al. (2000). However,
example-critiquing preference-based search, users preferences volunteered reactions
displayed examples, elicited; users never forced answer questions preferences
without benefit concrete decision context.
2.3 Generating Candidate Choices
general, users able state preferences numerical precision. Instead,
practical tool needs use approximate preference model users specify preferences qualitative way.
good way implement preference model use standardized soft constraints
numerical parameters chosen fit users. models necessarily inaccurate
certain users. However, inaccuracy compensated showing one, set
k best candidate solutions. user chooses preferred one set, thus
compensating preference models inaccuracy. technique commonly used
search engines.
analyzed technique several types preference models: weighted soft constraints, fuzzy-lexicographic soft constraints, simple dominance relations (Faltings, Torrens, &
Pu, 2004).
remarkable result weighted fuzzy-lexicographic constraint models, assuming bound possible error (deviation true value one used application)
soft constraints modeling preferences, probability true preferred solution
within k depends number preferences error bound soft constraints
overall size solution set. Thus, particularly suitable searching
large space items.
also found preference model contains many different soft constraints, probability finding preferred option among k best quickly decreases. Thus, compensating
472

fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONS

model inaccuracy showing many solutions useful preference models relatively
simple. Fortunately, often case preference-based search, people usually lack
patience input complex models.
result, desirable process practice might two-stage process examplecritiquing preference model used first stage narrow set options
large (thousands) space possibilities small (20) promising subset. second phase
would use tweaking interaction preference model maintained find best choice.
Pu Chen (2005) shown tradeoff strategies tweaking interaction provide excellent
decision accuracy even user preferences complex.
2.4 Practical Implementation
Another challenge implementing example-critiquing large scale practical settings
requires solutions computed specifically preference model particular user.
may challenge web sites many users.
However, shown (Torrens, Weigel, & Faltings, 1998; Torrens, Faltings, & Pu, 2002)
computation data necessary computing solutions coded compact form
run applet users computer. allows completely scaleable architecture
load central servers higher conventional web site. Torrens, Faltings &
Pu (2002) describe implementation example-critiquing using architecture tool
planning travel arrangements. commercialized part tool business travelers (Pu
& Faltings, 2000).

3. Suggestions
basic example-critiquing cycle, expect users state additional preference long
perceive bring better solution. process ends users longer see potential
improvements stating additional preferences thus reached optimum. However, since
process one hill-climbing, optimum may local optimum. Consider
example user looking notebook computer low price range. Since
presented products weight, say around 3 kg, might never bother look
lighter products. marketing science literature, called anchoring effect (Tversky, 1974).
Buyers likely make comparisons products reference product, case
set displayed heavy products. Therefore, buyer might consider possibility lighter
notebook might fit requirements better, accept sub-optimal result.
hillclimbing, local minima avoided randomizing search process.
Consequently, several authors proposed including additional examples selected order
educate user opportunities present choice options (Linden et al., 1997;
Shimazu, 2001; McSherry, 2002; Smyth & McClave, 2001). Thus, displayed examples would
include:
candidate examples optimal current preference query,
suggested examples chosen stimulate expression preferences.
473

fiV IAPPIANI , FALTINGS , & P U

Different strategies suggestions proposed literature. Linden (1997) used extreme examples, attribute takes extreme value. Others use diverse examples
suggestions (Smyth & McClave, 2001; Smyth & McGinty, 2003; Shimazu, 2001).
Consider example searching housing mentioned previous section. Recall
choice among following options:
o1
o2
o3
o4
o5
o6
o7

rent
400
500
600
600
650
700
800

type-of-accommodation
room
room
apartment
studio
apartment
studio
apartment

distance-to-university
17
32
14
5
32
2
7

furnished
yes
yes



yes


initial dialogue system, user stated preference lowest price. Consequently, options ordered o1 o2 o3 = o4 o5 o6 o7 .
Assume system shows one candidate, promising option according
known preferences: o1 . options shown suggestions motivate
user express remaining preferences?
Linden et al. (1997) proposed using extreme examples, defined examples attribute
takes extreme value. example, consider distance: o6 example smallest
distance. However, much higher price, furnished satisfy users
hidden preference. Thus, give user impression closer distance achievable
without compromising preferences. user wants distance less 5
minutes option o6 good suggestion, otherwise o4 likely better. Another problem
extreme examples need two examples attribute, usually
user absorb.
Another strategy (Smyth & McClave, 2001; McSherry, 2002, 2003; Smyth & McGinty, 2003;
Shimazu, 2001) select suggestions achieve certain diversity, also observing certain
goodness according currently known preferences. tool already shows o1 optimal example, different example o5 , differs attributes excessive
price. o5 good suggestion? shows user following opportunities:
apartment instead room: however, o3 would cheaper way achieve this.
distance 32 instead 17 minutes: however, o2 would cheaper way achieve this.
unfurnished instead furnished: however, o3 would cheaper way achieve this.
Thus, o5 diverse, give user accurate picture true opportunities are. problem diversity consider already known preferences,
case price, dominance relations imply available options.
mitigated somewhat combining diversity similarity measures, example using linear
combination (Smyth & McClave, 2001; McSherry, 2003), solve problem
effects diversity limited attributes without known preferences similarity
applied attributes known preferences.
474

fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONS

consider strategies generating suggestions based current preference model.
call strategies model-based suggestion strategies.
assume user minimizing effort add preferences
model expects impact solutions. case when:
user see several options differ possible preference,
options relevant, i.e. could acceptable choices,
already optimal already stated preferences.
cases, stating additional preference irrelevant: options would evaluate
way, preference effect options would eligible anyway
already best choices, stating would wasted effort. contrary, upon display
suggested outcome whose optimality becomes clear particular preference stated,
user recognize importance stating preference. seems confirmed
user studies.
led us following principle, call look-ahead principle, basis
model-based suggestion strategies:
Suggestions optimal current preference model, provide high likelihood optimality additional preference added.
stress heuristic principle based assumptions human behavior
cannot formally prove. However, justified fact suggestion strategies based
look-ahead principle work well real user studies, report later article.
example, o4 o3 highest probability satisfying lookahead principle:
currently dominated o1 . o4 becomes Pareto-optimal user wants studio,
unfurnished option, distance less 14 minutes. o3 becomes Pareto-optimal user
wants apartment, unfurnished option, distance less 17 minutes. Thus, give
good illustration possible within set examples.
develop method computing suggestions show generate
suggestions.
3.1 Assumptions Preference Model
show implement model-based suggestion strategies, define preference
models minimal assumptions shape user preferences might take. stress
assumptions made generating suggestions. preference model used
search tool could diverse specific required application.
consider collection options = {o1 , .., } fixed set k attributes =
{A1 , .., Ak }, associated domains D1 , .., Dn . option characterized values
a1 (o), ..., ak (o); ai (o) represents value takes attribute Ai .
qualitative domain (the color, name neighborhood) consists enumerated set
possibilities; numeric domain numerical values (as price, distance center), either discrete
continuous. numeric domains, consider function range(Att) gives range
attribute domain defined. simplicity call qualitative (respectively numeric)
attributes qualitative (numeric) domains.
users preferences assumed independent defined individual attributes:
475

fiV IAPPIANI , FALTINGS , & P U

Definition 1 preference r order relation r values attribute a; r expresses
two values equally preferred. preference model R set preferences {r1 , .., rm }.
Note r might partial total order.
preferences combination attributes, total travel time
journey, assume model includes additional attributes model combinations
make assumption independent preferences attribute. drawback
designer know preferential dependence advance. However, required
designing user interface anyway.
preference ri always applies attribute ai , simplify notation apply
ri ri options directly: o1 ri o2 iff ai (o1 ) ri ai (o2 ). use ri indicate ri
holds ri .
Depending formalism used modeling preferences, different ways combining order relations given individual preferences ri users preference model R
combined order options. example, preference may expressed number,
combination may formed summing numbers corresponding preference
taking minimum maximum.
rational decision maker prefer option another first least good
criteria better least one. concept expressed Pareto-dominance (also
called dominance), partial order relation options.
Definition 2 option Pareto-dominated option o0 respect R
ri R, ri o0 least one rj R, rj o0 . write R o0 (equivalently say
o0 Pareto-dominates write o0 R o).
also say dominated (without specifying o0 ).
Note use symbol individual preferences sets preferences.
, meaning R o0 r R, r o0 .
following, assumption make combination dominancepreserving according definition Pareto-dominance. Pareto dominance general
order relation defined based individual preferences. forms domination
defined extensions Pareto dominance. following, whenever use dominance
without specification, refer Pareto-dominance.
Definition 3 preference combination function dominance-preserving whenever
option dominates another option individual orders, dominates combined
order.
combination functions used practice dominance-preserving. example
combination dominance-preserving case preferences represented
soft constraints combined using Min(), fuzzy CSP (Ruttkay, 1994). case, two
options constraint valuations
o1 (0.3, 0.5, 0.7)
o2 (0.3, 0.4, 0.4)
considered equally preferred combination function in(0.3, 0.5, 0.7) = 0.3 =
in(0.3, 0.4, 0.4), even though o1 dominated o2 .
476

fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONS

3.2 Qualitative Notions Optimality
model-based suggestion strategies going introduce based principle selecting options highest chance becoming optimal. determined considering
possible new preferences characterizing likelihood make option optimal. Since
know weight new preference take users perception, must evaluate
using qualitative notion optimality. present two qualitative notions, one based
Pareto-optimality another based combination function used generating candidate
solutions.
obtain suggestion strategies valid preference modeling formalism,
using qualitative optimality criteria based concept Pareto-dominance introduced before.
Definition 4 option Pareto-optimal (PO) dominated
option.
Since dominance partial order, Pareto optimal options seen maximal elements
O. Pareto-optimality useful applies preference model long combination function dominance-preserving.
dominance-preserving combination function, option preferred
combined preference order Pareto-optimal, since option o0 dominates would
preferred. Therefore, Pareto-optimal solutions optimal combined preference
order, matter combination function is. makes Pareto-optimality useful heuristic
generating suggestions independently true preference combination users mind.
example-critiquing, users initially state subset R eventual preference model
R. preference added, dominated options respect R become Pareto-optimal.
hand, option loose Pareto-optimality preferences added except
option equally preferred respect preferences considered become
dominated.
Note one also consider using weak Pareto-optimality defined Chomicki
(2003), consider options equal respect attributes preference
stated.
introduce notions dominating set equal set:
Definition 5 dominating set option respect set preferences R set
>
options dominate o:
(o) = {o0 : o0 R o}. write O> (o), without specifying R,
set preferences, R clear context.
equal set option respect R set options equally preferred
= (o) = {o0 : o0 o}. also use > = .
o:
R
following observation basis evaluating likelihood dominated option
become Pareto-optimal new preference ri stated.
Proposition 1 dominated option respect R becomes Pareto-optimal respect
R ri
strictly better respect ri options dominate respect R
worse respect ri options equally preferred respect R.
477

fiV IAPPIANI , FALTINGS , & P U

Proof 1 Suppose option o0 dominates respect R strictly
better o0 new preference ri ; o0 would still dominate o, could Paretooptimal. Similarly, suppose equally preferred o00 o00 strictly better
respect ri ; o00 would dominate o, could Pareto-optimal.
Thus, dominating set O> equal set O= given option potential dominators
new preference considered.
Utility-dominance consider forms dominance long imply Paretodominance. particular, might use total order established combination function defined preference modeling formalism, weighted sum. call utility-domination,
utility-optimal option preferred one.
may ask option become utility-optimal. weaker form Proposition 1 holds
utility domination:
Proposition 2 dominance-preserving combination functions, utility-dominated option o0
respect R may become utility-optimal respect R ri o0 strictly better
respect ri options currently utility-dominate worse options
currently equally preferred.
Proof 2 Suppose option became utility-optimal without preferred
according new preference; would violation assumption combination function dominance-preserving.
Even though sufficient condition, Proposition 2 used heuristic characterize
options chance become utility-optimal.
3.3 Model-based Suggestion Strategies
propose model-based suggestion strategies implemented concept
Pareto- utility-dominance. based look-ahead principle discussed earlier:
suggestions optimal current preference model, high
likelihood becoming optimal additional preference added.
assume system knows subset R users preference model R. ideal suggestion
option optimal respect full preference model R dominated R,
current (partial) preference model. optimal full model, Propositions 1 2
know suggestions break dominance relations dominating set.
Model-based strategies order possible suggestions likelihood breaking dominance
relations.
3.3.1 C OUNTING TRATEGY
first suggestion strategy, counting strategy, based assumption dominating
options independently distributed. Proposition 1 compute probability
dominated option becomes Pareto-optimal currently hidden preference as:
478

fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONS



popt (o) =

0

pd (o, )

0



pnw (o, o0 )

o0 O= (o)

O> (o)

pd probability new preference makes escape domination relation
dominating option o0 , i.e. preferred o0 according new preference; similarly pnw
probability worse equally preferred option o0 .
Evaluating probability requires exact probability distribution possible preferences,
general difficult obtain.
strategy assumes pd = pnw constant dominance relations.

popt (o) =
pd
o0 (o)
|O (o)|

= pd

Since pd 1, probability largest smallest set (o). Consequently, best
suggestions lowest value following counting metric:
FC (o) = |O (o)|

(1)

counting strategy selects option lowest value metric best suggestion.
3.3.2 P ROBABILISTIC TRATEGY
probabilistic strategy uses precise estimate chance particular solution
become Pareto-optimal.
General assumptions assume preference ri expressed cost function ci .
order well-defined interface, cost functions usually restricted family
functions parameterized one parameters. assume single parameter ,
method generalized handle cases multiple parameters:
ci = ci (, ai (o)) = ci (, o)
assume possible preferences characterized following probability distributions:
pai , probability user preference attribute ai ,
p(), probability distribution parameter associated cost function
considered attribute
user experiments last section, use uniform distribution both. probability preference attribute makes o1 preferred o2 computed integrating
values cost o1 less o2 . expressed using Heavyside step
function H(x) (x > 0) 1 else 0:
479

fiV IAPPIANI , FALTINGS , & P U

Z
(o1 , o2 ) =



H(ci (, o2 ) ci (, o1 ))p()d

qualitative domain, iterate sum probability contribution cases
value makes o1 preferred o2 :
(o1 , o2 ) =

X

H(ci (, o2 ) ci (, o1 ))p()

Di

determine probability simultaneously breaking dominance relation dominating equal options , aQ
first possibility assume independence options,
thus calculate (o, ) = o0 (o, o0 ), chance breaking one single
domination preference attribute i.
better estimate defined require independence assumption, directly
considers distribution dominating options. breaking dominance relation
options dominating set ai , dominating options must less preferred
value ai considered option.
numeric domains, integrate possible values , check whether given
option lower cost dominators O> weigh probability particular
value .
Z
(o, O> ) = [
H(ci (, o0 ) ci (, o))]p()d
o0 O>

qualitative domains, replace integral summation .
also need consider second condition Proposition 1, namely new dominance
relations options equal set created. done adding second term
integral:
Z


(o, ) =

[



H(ci (, o0 ) ci (, o))



H (ci (, o00 ) ci (, o))]p()d

(2)

o00 O=

o0 O>

H modified Heavyside function assigns value 1 whenever difference
two costs 0 greater. (H (x) (x 0) 1 else 0).
consider overall probability becoming Pareto optimal preference added
combination event new preference particular attribute, chance
preference attribute make option preferred values dominating
options:

FP (o) = 1
(1 Pai (o, ))
(3)
ai Au

assume user one hidden preference, use following simplification:
X
FP (o) =
Pai (o, )
(4)
ai Au

480

fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONS

also good approximation probabilities additional preferences small.
cases, select options highest values suggestions.
computation depends particular choice preference representation many
cases greatly simplified exploiting properties cost functions. general,
designer application consider preferences user express user
interface translate quantitative cost functions. similar approach taken
Kiessling (2002) design PREFERENCE SQL, database system processing queries
preferences.
consider several examples common preference functions show
suggestions computed cases.
Preference single value qualitative domain Let value preferred user;
function ci (, x) gives penalty every value attribute ai except . would allow
express statements like prefer German cars, meaning cars manufactured Germany
preferred cars manufactured another country.
ci (, x) ai (x) = 0 else 1.
probability breaking dominance relation option o1 o2 simplifies
probability value option o1 attribute preferred value, differs
value o2 .

p[ = ai (o1 )] ai (o1 ) 6= ai (o2 )
(o1 , o2 ) =
0
otherwise
1
(meaning value
|Di |
domain equally likely preferred value), probability becomes 1/|Di | ai (o1 ) 6=
ai (o2 ), 0 otherwise.
probability breaking dominance relations set dominators without creating
new dominance relations single dominator, long options
different value ai :

1/|Di | (o0 O> ) ai (o) 6= ai (o0 )
(o, )
(5)
0
otherwise
Assuming uniform distribution, p() =

Note that, given structure preference, (o, ) = (o, O> ), option
break dominance relations ai (o) takes preferred value case,
option strictly better respect preference.
Directional preferences particular case preferences numeric domains preference order assumed known direction, price (cheaper always preferred,
everything else equal). case, (o1 , o2 ) computed simply comparing values options take attribute (Figure 2).

(o1 , o2 )

ai (o1 ) < ai (o2 ) 1 else 0
ai (o1 ) > ai (o2 ) 1 else 0
481

ai numeric, natural preference <
ai numeric, natural preference >

(6)

fiV IAPPIANI , FALTINGS , & P U

Figure 2: directional preference, cost function monotone function attribute value.
case shown here, smaller values preferred.

Figure 3: preference LessThan() represented step function, option preferred
set options minimum value li reference value falls values
given option li .

set options whose values ai lie li hi



(o, )

1 ai (o) < li
0 otherwise

(7)

smaller values always preferred,



(o, )

1 ai (o) > hi
0 otherwise

(8)

larger values always preferred. Note cases, expressions independent
shape cost function long monotonic.
Threshold preferences numeric domains Another commonly used preference expression
numeric domains define smallest largest acceptable threshold, i.e. express preference
LessThan() (the value lower ) GreaterThan() (the value
greater ). preference straightforwardly expressed cost function follows
482

fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONS

Figure 4: preference LessThan() represented graded step function, option preferred set options minimum value li reference value falls interval
ai (o) li , = 1/.

step curve (Figure 3). express fact usually tolerance small violations,
generally graded step function, cost gradually increases, might used (Figure 4).
possible cost function LessThan might following:

Min(1, (x )) x >
clessthan (, x) =
(9)
0
otherwise
assigning penalty option takes value greater reference value ; cost
difference value reference, maximum 1. parameter
expresses degree violations allowed; following computations
convenient use length ramp 0 1 = 1/.
case computation (o1 , o2 ) be, ai (o1 ) < ai (o2 ):
Z ai (o2 )
(o1 , o2 ) =
1p()d = p[(ai (o1 ) t) < < ai (o2 )];
ai (o1 )t

0 otherwise (since lower values preferred Equation 9).
transition phase 0 1 small (the cost function approximates step function
Figure 3), (o1 , o2 ) ' p[ai (o1 )t < < ai (o2 )], approximating probability reference
point falling two options. Assuming uniform distribution, probability evaluates
(ai (o2 )ai (o1 )+t)/range(ai ), range(ai ) difference largest smallest
values ai . reasoning illustrated Figure 4.
probability computed conditioned knowledge polarity users preference (LessThan case), needs weighted probability polarity. Below,
assume polarities equally likely, use weight 1/2.
dominance relations broken simultaneously considered option
value attribute smaller bigger options dominating set.
estimate probability reference value new preference falls way
dominance relations broken, sufficient consider extrema values
dominating options take considered attribute:
hi = maxo0 O> ai (o0 )
483

fiV IAPPIANI , FALTINGS , & P U

Figure 5: example peaked preferences. gi greatest value ai (o) ai option

(o), si smallest value ai (o). m1 = (ai (o) + gi )/2, m2 = (ai (o) + si )/2
two midpoints ai (o) gi , si . make preferred options (o),
fall max(m1 , ai (o) t) min(m2 , ai (o) + t). seen graphically,
case interval ]m1 , ai (o) + t[.

li = mino0 O> ai (o0 )
values current option lies outside interval [li , hi ], consider probability breaking relations single dominance case. proportional
difference current option value minimum/maximum, scaled range
values ai :

(ai (o1 ) hi + t)/2 range(ai ) ai (o1 ) > hi





(li ai (o1 ) + t)/2 range(ai ) ai (o1 ) < li
(o, )





0
otherwise

(10)

Peaked preferences numeric domains Another common case preferences particular numerical value , example prefer arrive around 12am. allow tolerance
deviation, cost function might slope directions:
cpeak (x, ) = |ai (o) |.
case, option preferred another one closer . example, letting
midpoint ai (o1 ) ai (o2 ) supposing ai (o1 ) < ai (o2 ),
(o1 , o2 ) = p[ < m]
calculating probability simultaneously breaking dominance relations without
generating new ones, define gi maximum dominating equal options value
ai less ai (o) si minimum value dominating equal options greater
ai (o). option preferred whenever ai (o) closer , interval
case one half interval si gi , have:
(o, ) =

si gi
range(ai )

484

fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONS

realistic cost function would include saturation point cost always
evaluates 1, shown Figure 5:
cpeakwithsaturation (x, ) = Min(1, |ai (o) |).

(11)

Let = 1/ tolerance preference either side, gi greatest value ai (o)
ai option (o), si smallest value ai (o). define two midpoints
m1 = (ai (o) + gi )/2 m2 = (ai (o) + si )/2, have:
(o, ) = p[max(m1 , ai (o) t) < < min(m2 , ai (o) + t)]
reference point uniformly distributed, evaluates to:
(o, ) =

min(m2 , ai (o) + t) max(m1 , ai (o) t)
range(ai )

(12)

3.4 Example
following table shows relevant values example shown earlier. Recall
earlier identified o4 o3 attractive suggestions.

o1
o2
o3
o4
o5
o6
o7

O+

rent
(a1 )

type
(a2 )

2

distance
(a3 )

3

furnished
(a4 )

4

popt

o1
o1 , o2
o1 , o2
o1 o4
o1 o5
o1 o6

400
500
600
600
650
700
800

room
room
apartment
studio
apartment
studio
apartment

0
0.5
0.5
0
0
0

17
32
14
5
32
2
7

0.25
0.05
0.20
0
0.05
0

yes
yes



yes


0
0.5
0.5
0
0
0

0.125
0.451
0.494
0
0.025
0

counting strategy, options ranked according size set O+ . Thus, o2
highest ranked suggestion, followed o3 o4 .
probabilistic strategy, attribute values option compared range values
present dominators. attribute, leads values indicated table.
assume user equally likely preference attribute, probability
Pai = 0.5, probabilistic strategy scores options shown last column table.
Clearly, o4 best suggestion, followed o3 . o2 also o6 follow behind.
Thus, least example, model-based strategies successful identifying good
suggestions.
3.5 Optimizing Set Several Suggestions
strategies discussed far concern generating single suggestions. However, practice
often possible show set l suggestions simultaneously. Suggestions interdependent,
likely obtain better results choosing suggestions diverse way. need
diversity also observed others (Shimazu, 2001; Smyth & McClave, 2001).
precisely, choose group G suggested options maximizing probability
popt (G) least one suggestions set G become optimal new user
preference:


popt (G) = 1
(1 Pai (1
(1 (o0 , (o0 )))))
(13)
o0 G

ai Au

485

fiV IAPPIANI , FALTINGS , & P U

Explicitly optimizing measure would lead combinatorial complexity. Thus, use
algorithm adds suggestions one one order contribution measure given
already chosen suggestions. similar algorithm used Smyth McClave (2001)
Hebrard et al. (2005) generate diverse solutions.
algorithm first chooses best single suggestion first element set G.
evaluates option much would change combined measure popt (G)
added current G, adds option largest increment. process repeats
desired size set G reached.
3.6 Complexity
Let n number options, k number attributes number preferences,
number dominators, Au attributes user state preference.
three model-based strategies based dominating set option. use straightforward algorithm computes intersection set options better
respect individual preferences. sets, n elements, complexity algorithm O(n2 m). general, dominating set option size O(n)
output procedure size O(n2 ), unlikely find much better
algorithm.
dominating sets known, counting strategy complexity O(nd),
attribute probabilistic strategies complexity O(ndku ), ku = |Au | ku < k.
general, depends data-set. worst case proportional n, resulting
complexity O(n2 ).
utility used domination criterion, dominating set composed options
higher ranking. Therefore process computing dominating set highly
simplified performed computing candidates. However algorithm still
overall worst case complexity O(n2 ): last option ranking n 1 dominators,
= O(n).
several examples selected according diversity, complexity increases since
metrics must recomputed selecting suggestion.
comparison, consider extreme strategy, proposed initially Linden et al. ATA (1997).
selects options either smallest largest value attribute
user initially state preference. strategy needs scan available options
once. complexity O(n), n number options (the size catalog). Thus,
significantly efficient, appear provide benefits model-based
strategy, shall see experiments.
Another strategy considered comparison, generating maximally diverse set options (Hebrard et al., 2005; Smyth & McClave, 2001), exponential complexity number
available options. However, greedy approximations (Hebrard et al., 2005) complexity
O(n2 ) , similar model-based strategies.
greedy algorithm use optimizing set several suggestions add
complexity; distances computed attribute, greedy algorithm
computing set suggestions complexity proportional product number
options, number attributes, square number suggestions computed.
486

fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONS

100

random
diversity
extremes
counting
probabilistic assuming independence
probabilistic assuming independence

fraction users

80

60

40

20

0
1

2

3
4
number preferences

5

6

Figure 6: Simulation results database actual apartment offers. 100 simulated users,
randomly chosen preference model 6 hidden preferences, plot number times
simulation discovered least number preferences shown abscissa. higher
curve, preferences discovered average.

suspect exact optimization would NP-hard number suggestions,
proof this.

4. Experimental Results: Simulations
suggestion strategies presented heuristic, clear performs best
assumptions underlying design. Since evaluations real users carried
specific design, first select best suggestion strategy simulating interaction
computer generated user randomly generated preferences. allows us compare
different techniques much greater detail would possible actual user study, thus
select promising techniques development. followed real user studies
discussed next section.
simulations, users randomly generated set preferences different attributes items stored database. measure accuracy, interested whether
interaction allows system obtain complete model users preferences. tests
design objective suggestion strategies (to motivate user express many preferences
possible) given assumptions user behavior hold. verify assumptions
reasonable study real users reported next section.
simulation starts assigning user set randomly generated preferences selecting
one initial preference. stage interaction, simulated user presented
5 suggestions.
implemented 6 different strategies suggestions, including three model-based strategies described well following three strategies comparison:
random strategy suggests randomly chosen options;
487

fiV IAPPIANI , FALTINGS , & P U

100

random
diversity
extremes
counting
probabilistic assuming independence
probabilistic assuming independence

fraction users

80

60

40

20

0
1

2

3

4
5
number preferences

6

7

8

Figure 7: Simulation results randomly generated catalogs. 100 simulated users, randomly chosen preference model 8 hidden preferences, plot number times
simulation discovered least number preferences shown abscissa. higher
curve, preferences discovered average.

extremes strategy suggests options attributes take extreme values, proposed
Linden (1997);
diversity strategy computes 20 best solutions according current model
generates maximally diverse set 5 them, following proposal McSherry (2002).
simulated user behaves according opportunistic model stating one hidden
preferences whenever suggestions contain option would become optimal preference added model proper weight. interaction continues either
preference model complete, simulated user states preference. Note
complete preference model discovered, user finds target option.
first ran simulation catalog student accommodations 160 options described
using 10 attributes. simulated user shown 5 suggestions, randomly generated
model 7 preferences, one given user initially. results shown Figure 6.
value x, shows percentage runs (out 100) discover least x 6
hidden preferences complete model. Using random suggestions baseline, see
extremes strategy performs slightly better, diversity provides significant improvement.
model-based strategies give best results, counting strategy equally
good diversity, probabilistic strategies providing markedly better results.
another test, ran simulation catalog 50 randomly generated options
9 attributes, random preference model 9 preferences, one known initially.
results shown Figure 7. see much pronounced difference
model-based non model-based strategies. attribute fact attributes
less correlated, thus extreme diversity filters tend produce solutions scat488

fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONS

#P / #A
6/6
6/9
6/12

random
0.12
0.12
0.11

extreme
0.09
0.12
0.13

diversity
0.23
0.27
0.24

counting
0.57
0.65
0.62

prob1
0.59
0.63
0.64

prob2
0.64
0.67
0.63

Table 1: fraction preferences correctly discovered function number attributes;
keeping constant number preferences (6) discovered. attributes integer domains.

#P / #A
3/9
6/9
9/9

random
0.25
0.11
0.041

extreme
0.36
0.12
0.17

diversity
0.28
0.11
0.05

counting
0.70
0.67
0.66

prob1
0.71
0.68
0.70

prob2
0.71
0.68
0.73

Table 2: fraction preferences correctly discovered (on average) function number
preferences discovered. attributes integer domains.

tered space possibilities. Also probabilistic strategy possible implementations
(assuming attributes values independent not) give close results.
investigated impact number preferences, number type attributes,
size data set random data sets. following, prob1 refers probabilistic strategy
independence assumption, prob2 probabilistic strategy without assumption.
Surprisingly discovered varying number attributes slightly changes results. Keeping number preferences constant 6 (one initial preference), ran
simulations number attributes equal 6, 9 12. average fraction discovered preferences varied strategy simulation scenario 5%, shown
Table 1.
impact variation number preferences discover shown Table 2.
model-based strategies perform significatively better random choice, suggestions
extrema, maximization diversity. shows importance considering already
known preferences selecting suggestions.
domain
type
mixed
integer

random
choice
0.048
0.04

extreme

diversity

counting

prob1

prob2

0.30
0.17

0.18
0.05

0.81
0.66

0.87
0.70

0.86
0.72

Table 3: fraction preferences correctly discovered function different kinds
attribute domains: integer domains mix 5 integer, 2 discrete domains 2 domains
natural order. ran 100 simulations 9 attributes 9 preferences.

489

fiV IAPPIANI , FALTINGS , & P U

data
size
50
75
100
200

random
choice
0.25
0.16
0.11
0.05

extreme

diversity

counting

prob1

prob2

0.50
0.42
0.29
0.22

0.56
0.54
0.57
0.54

0.89
0.88
0.90
0.86

0.94
0.97
0.96
0.91

0.93
0.95
0.97
0.93

Table 4: fraction preferences correctly discovered function database size. ran
100 simulations 9 attributes 9 preferences (mixed domains).

performances higher mixed domains numeric domains (Table 3).
easily explained larger outcome space second case.
Interestingly, size item set grows, performance random extreme strategies
significantly degrades model-based strategies maintain performance (Table 4).
simulations, appears probabilistic suggestion strategy best all, sometimes significant margin. thus chose evaluate strategy real user study.

5. Experimental Results: User Study
strategies developed far depend many assumptions user behavior
truly tested evaluating real users. However, many factors
influence user behavior, testing general hypotheses possible. Here, interested
verifying that:
1. using model-based suggestions leads complete preference models.
2. using model-based suggestions leads accurate decisions.
3. complete preference models tend give accurate decisions, reasoning
underlying model-based suggestions correct.
measure decision accuracy percentage users find preferred choice using
tool. preferred choice determined subjects go entire
database offers detail finished using tool. measure decision accuracy,
also called switching rate, commonly accepted measure marketing science (e.g., Haubl
& Trifts, 2000).
performed user studies using FlatFinder, web application finding student housing
uses actual offers university database updated daily. database ideal
contains high enough number - 200 - offers present real search problem,
time small enough feasible go entire list determine
best choice less 1 hour. recruited student subjects interest finding housing
thus quite motivated perform task accurately.
studied two settings:
490

fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONS

unsupervised setting, monitored user behavior publicly accessible examplecritiquing search tool listing. allowed us obtain data hundred
different users; however, possible judge decision accuracy since
able interview users themselves.
supervised setting, 40 volunteer students use tool supervision. Here,
could determine decision accuracy asking subjects carefully examine entire
database offers determine target option end procedure. Thus, could
determine switching rate measure decision accuracy.
10 attributes: type accommodation (room family house, room shared apartment, studio apartment, apartment), rent, number rooms, furnished (or not), type bathroom
(private shared), type kitchen (shared, private), transportation available (none, bus, subway,
commuter train), distance university distance town center.
numerical attributes, preference consists relational operator (less than, equal, greater
than), threshold value importance weight 1-5; example, price less 600
Francs importance 4. qualitative attributes, preference specifies certain value
preferred certain importance value. Preferences combined summing weights
whenever preference satisfied, options ordered highest value
preferred.
Users start stating set PI initial preferences, obtain options pressing
search button. Subsequently, go sequence interaction cycles refine
preferences critiquing displayed examples. system maintains current set
preferences, user state additional preferences, change reference value existing
preferences, even remove one preferences. Finally, process finishes
final set preferences PF , user chooses one displayed examples.
increment preferences | PF PI | number extra preferences stated represents
degree process stimulates preference expression.
search tool made available two versions:
C, showing set 6 candidate apartments without suggestions,
C+S, showing set 3 candidate apartments 3 suggestions selected according
probabilistic strategy utility-dominance criterion.
describe results two experiments.
5.1 Online User Study
FlatFinder hosted laboratory web-server made accessible students looking
accommodation winter 2004-2005. user, anonymously recorded log
interactions later analysis. server presented users alternate versions system,
i.e. (C+S) without (C) suggestions. collected logs 63 active users went
several cycles preference revision.
analyzing results experiments, whenever present hypothesis comparing
users group, show statistical significance using paired test. hypotheses
491

fiV IAPPIANI , FALTINGS , & P U

number critiquing cycles
initial preferences
final preferences
increment

tool without suggestions
2.89
2.39
3.04
0.64

tool suggestions
3.00
2.23
3.69
1.46

Table 5: Average behavior users on-line experiment. collected logs real users looking
student accommodation tool, hosted laboratory website.

comparing users different groups, use impaired student test indicate statistical significance. cases, indicate significance p, probability obtaining observed data
condition null hypothesis true. Values p < 0.05 considered significant, p
< 0.01 highly significant p < 0.001 highly significant.
first considered increment initial preference enumeration | PI | final preference
enumeration | PF |, shown Table 5. increment average 1.46 tool
suggestions C+S 0.64 tool C (128% increase), showing higher involvement
users see suggestions. hypothesis confirmed p = 0.002.
interesting see groups users interacted similar number cycles
(average 2.89 3.00; p = 0.42, null hypothesis cannot rejected), number
initial preferences also close (average 2.39 2.23, null hypothesis cannot rejected p
= 0.37), meaning groups relatively unbiased.
result test (Table 5) shows clearly users likely state preferences
suggestions present, thus verifying Hypothesis 1. However, online experiment,
able measure decision accuracy. order obtain measures, also conducted
supervised user study.
5.2 Supervised User study
supervised user study used tool online user study users followed
interaction.
measure improvement accuracy, instructed users identify preferred item searching database using interface 1. choice recorded called
c1 . users instructed interact database using interface 2 indicate
new choice (c2 ) latter improvement c1 opinion. evaluate whether
second choice better initial one, instructed users review apartments (100
apartments case) tell us whether c1 , c2 , completely different one truly seemed best.
Thus, experiment allowed us measure decision accuracy, since obtained true target
choice user. users stood first choice, indicated found target
choice without help second interface. users stood second choice,
indicated found target choice help second interface. users chose
yet another item, indicated found target choice even though performed
search interfaces.
40 subjects, mostly undergraduate students, 9 different nationalities took part study.
(27 40) searched apartment area used online
492

fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONS

Characteristics
Gender
Male
Female
Age
10s
20s
30s
Education
Undergraduate
Phd
Familiar online apartment search
Yes

Familiar apartments area
Yes


Participants
31
9
2
36
2
36
4
26
14
27
13

Table 6: Demographic characteristics participants supervised user study.

group 1
(C first)

Tool version
Decision Accuracy (mean)
Preference Enumeration (mean)
Interaction cycles (mean)
Interaction time (min.,mean)

Interaction
first interface
C
0.45
5.30
5.60
8:09

group 2
(C+S first)

Tool version
Decision Accuracy (mean)
Preference Enumeration (mean)
Interaction cycles (mean)
Interaction time (mean)

C+S
0.72
5.44
4.05
7.39

Interaction
second interface
C+S
0.80
6.15
4.55
4.33
C
0.67
4.50
6.25
3.33

Table 7: Results supervised experiment. Decision accuracy preference enumeration (the number
preferences stated) higher suggestions provided (interface C+S, showing 3 candidates 3 suggestions) rather suggestions provided (interface C, 6 candidates).

493

fiV IAPPIANI , FALTINGS , & P U

sites (26 40) look accommodations. Table 6 shows demographic characteristics. subjects motivated interest finding better apartment themselves,
meant treated study seriously.
overcome bias due learning fatigue, divided users two groups,
asked interact versions two different orders:
group 1 used tool C (step 1) C+S (step 2)
group 2 used tool C+S (step 1) C (step 2)
groups examined entire list find true preferred option. version
tool group, recorded fraction subjects final choice made using
interface equal target option decision accuracy. groups, refer
accuracy interface 1 acc1 , accuracy interface 2 acc2 .
expected order presenting versions would important. users
realized preferences found satisfactory option, likely consistent
that. Therefore, expected acc2 > acc1 cases. However, expected average
accuracy would significantly increase suggestions, results would show acc2 >>
acc1 first group acc2 slightly higher acc1 group 2.
Table 7 shows results. next section want verify Hypothesis 2 (decision accuracy
improves suggestions) 3 (preference enumeration improves accuracy). Finally
check whether mediation phenomenon present (meaning improvement accuracy
entirely explained fact suggestions lead increase preferences).
Decision Accuracy improves suggestions Figure 8 shows variation decision accuracy
number interaction cycles two groups.
group 1, interaction tool C, average accuracy 45%, interaction
C+S, version suggestions, goes 80%. confirms hypothesis
suggestions improve accuracy p = 0.00076. 10 20 subjects group switched
another choice two versions, 8 reported new choice better.
Clearly, use suggestions significantly improved decision accuracy group.
Users group 2 used C+S straight away achieved average accuracy 72% outset.
expected consequent use tool C would small positive effect accuracy,
reality accuracy decreased 67%. 10 subjects changed final choice using tool
without suggestions, 6 said newly chosen equally good one
originally chose. fact accuracy drop significantly case surprising
users remember preferences using tool suggestions thus state
accurately independently tool. conclude group improved
accuracy simply result performing search second time, due provision
suggestions tool. Also, closeness accuracy levels reached groups
using suggestions interpreted confirmation significance.
also note users interface C+S needed fewer cycles (and thus less effort) make
decisions (average 4.15) interface C (5.92).
Interestingly, price chosen apartment increased first group (average 586.75
C 612.50 C+S; p = 0.04, statistically significant), whereas decreased second group
(average 527.20 C+S 477.25 C; p = 0.18, decrease statically significant).
494

fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONS

User study - Group 2
1

0.8

0.8

0.6

0.6

Accuracy

Accuracy

User study - Group 1
1

0.4

0.2

0.4

0.2

0

0
1) tool without suggestions

2) tool suggestions

1) tool suggestions

2) tool without suggestions

(a) group 1, accuracy dramatically increased (b) group 2, accuracy already high

used version suggestions (C+S).

use version suggestions (C+S).
interaction cycles tool C showing 6 candidates
increase accuracy further.
User study - Group 2
7

6

6

5

5

Interaction cycles

Interaction cycles

User study - Group 1
7

4
3

4
3

2

2

1

1

0

0
1) tool without suggestions

2) tool suggestions

1) tool suggestions

2) tool without suggestions

(c) group 1, users needed less interaction cycles (d) group 2, number interaction cycles sig-

make choice using interface sugges- nificantly increased used version withtions (C+S).
suggestions (C).

Figure 8: Decision accuracy interaction cycles groups users supervised experiment.

495

fiV IAPPIANI , FALTINGS , & P U

found
still found

0.45
0.55
|P | <= 0

0.83
0.17
|P | > 0

Table 8: users find target first use tool, table shows fraction
find target next try, depending whether size preference model
increase. (|P | variation number stated preferences |P |
two uses tool).

believe subjects first group find good choice, thus paid relatively high
price get apartment would feel comfortable. Conditioned high price,
willing spend even discovered interesting features
suggestions. hand, subjects group 2 already found good choice first use
tool, unwilling accept high price find better choice
second search without suggestions.
Thus, conclude Hypothesis 2 confirmed: suggestions indeed increase decision accuracy.
Preference enumeration improves accuracy study, notice suggestions
present, users state higher number preferences (average 5.8 preferences vs. 4.8 without
suggestions, p = 0.021), Hypothesis 1 confirmed.
validate hypothesis 3, higher preference enumeration also leads accurate decisions, compare average size preference model users found
target solution first use tool not. groups, users find
target first try stated average 5.56 preferences (5.56 group 1 5.57 group 2)
users find target stated average 4.88 preferences (5.09 group 1
4.67 group 2). shows increased preference enumeration indeed improves accuracy
unfortunately find statistically significant (p = 0.17). fact, chance
correlation due users informed thus making accurate decisions
stating preferences.
evaluation independent users priori knowledge, considered users
find target first try only. measure correlation preference enumeration
accuracy, considered often increase preference enumeration second try
led finding preferred option second try. Table 8 shows among users whose
preference model grow size, 45% found target, whereas increased
preference model, 83% found target. Again, see significant confirmation higher
preference enumeration leads accurate decision real users (p = 0.038251).
Finally, third confirmation obtained considering influence variations
size preference model decision accuracy, shown Table 9. column corresponds
users size preference model decreased, stayed same, increased. also
shows fraction accuracy increased, stayed decreased (note
accuracy 1 first step, cannot increase). see significant increase
accuracy occurs size preference model increases. cases
496

fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONS

acc > 0
acc = 0
acc < 0

0.23
0.62
0.15
|P | < 0

0.14
0.71
0.14
|P | = 0

0.38
0.62
0.00
|P | > 0

Table 9: Variation accuracy variation number stated preferences |P | two
uses tool.

random variations major increases. statistical test shows hypothesis
increase preference enumeration causes increase accuracy confirmed p = 0.0322.
Thus, conclude hypothesis 3 also validated user study; complete preference model indeed leads accurate decisions.
Mediation analysis Since three hypotheses verified, presence suggestions lead
increase preferences stated consequently increase accuracy. 3-step
mediation analysis want check whether mediation phenomenon, meaning
increase accuracy entirely explained increase preferences.
However, Sobel test show statistical significance (p=0.14), cannot conclude
increase preference enumeration mediator. interpretation suggestions
influence decision accuracy also making users state better preferences.
5.3 Observations
objective measure confidence price people willing pay chosen
option measure satisfaction, since would pay choice satisfies
based attributes. 40 subjects, average rent chosen housing
suggestion CHF 569.85, increase 7% average without suggestions,
CHF532.00. fact, observe general correlation price accuracy, 9
10 subjects find target first interaction finally chose apartment
higher rent.
subjects notably liked interaction (average 4.1 5) significant difference
versions. asked subjects version considered productive.
majority them, 22 40, preferred version suggestions, 13 preferred version
candidates 5 opinion.
Another indication suggestions helpful average time complete decision task:
took subjects average 8:09 minutes find target without suggestions, version
suggestions took 7:39 minutes average. Thus, using suggestions users take less time
obtain accurate decision.

6. Related Work
Example-based search tools Burke others (1997) among first recognize
challenge developing intelligent tools preference-based search. approach, called as497

fiV IAPPIANI , FALTINGS , & P U

sisted browsing combines searching browsing knowledge based assistance recognizes
users integral part search process.
developed FindMe approach, consisting family prototypes implement
intuition variety domains (restaurants, apartments, cars, video, etc.). main features
possibility similarity based retrieval (look restaurant similar this, San
Francisco), support tweaking (look bigger, nicer, closer centre, ..), abstraction high
level features (users might look restaurant casual look, look defined
database directly, decoupled basic features), multiple similarity metrics.
display follows hierarchical sort preferences (described goals: minimize price, find
seafood cuisine) fixed priority. restaurant advisor tested on-line several years.
Another early similar work ATA system Linden et al. (1997). ATA tool
planning travel itineraries based users constraints. followed so-called candidate-critiquing
cycle users could post constraints travel would shown 3 best matching
flights database. ATA tested on-line several months.
recent work, Shearin Lieberman (2001), described AptDecision, examplecritiquing interface user able guide search giving feedback feature (in
form either positive negative weights) time. critiques stored
profile displayed bottom part interface modified stored later
use. Instead providing feedback manually, user might prefer let AptDecision learn
profile weights comparing two sample examples. However, investigate strategies
suggestions.
Improving example selection Techniques induce users state preferences accurately proposed various recommender systems. Suggestion mechanisms include extreme values, diversity, compound critiques.
ATA system Linden et al. (1997) included suggestion strategy showing extreme
examples applied airplane travel domain, example first last flight day.
simulations, compared model-based techniques strategy.
Several researchers (Bridge & Ferguson, 2002; Smyth & McClave, 2001; McSherry, 2002;
McGinty & Smyth, 2003; Smyth & McGinty, 2003; McSherry, 2003) studied issue
achieving good compromise generating similar diverse results case-based retrieval.
consider problem finding cases similar given query case,
time maximize diversity options proposed user. Smyth et. al (2003) improves
common query show like this: adaptive search algorithm alternates
strategy privileges similarity one privileges diversity (refocus). McSherry (2002) took
idea provided selection algorithms maximize diversity similarity
time. McSherry (2003) proposes technique retrieved cases associated set
like cases share identical differences query case. like cases displayed
among examples, accessible users demand. Thus, retrieval set diverse.
Reilly et al. (2004) also uses mixture similarity diversity, goal providing
possible standardized critiques allow trade-offs analysis e-commerce environment. critique is, scope, modification users current preferences narrowing search
indication trade-off. Users select either unit critiques revise preferences
individual attributes, compound critiques revise preferences multiple attributes.
compound critiques organized categories displayed natural language form, ex498

fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONS

ample memory larger heavier. One innovations work automatic
generation sensible critiques involving several features based available items using Apriori
algorithm. simulated real user studies shown compound critiques significantly
reduce number interaction cycles.
approaches, however, differ sense explicit
preference model. recent work Hebrard et al. (2005) investigated computational
problem generating diverse solutions constraint satisfaction problems.
Dialogue-based approaches Many related works try simulate human conversation
order guide customer decision making process. Shimazu (2001) describes ExpertClerk, agent system imitates human salesclerk. first phase, agent tries
narrow possibilities asking questions. optimal discrimination tree built using
information gain (as ID3 algorithm) node represents specific question user,
users answer leads specific portion subtree. fact, node equivalent
crisp constraint, problem getting node compatible examples may occur.
second phase, agent proposes three possible items, chosen one central two
opposite extreme region available product space. shown intelligent use
strategies (asking proposing) efficient one two strategies alone.
Thompson, Goker, Langley (2004) also propose conversational, dialogue-based approach
ADAPTIVE PLACE ADVISOR, conversational recommendation system restaurants
Palo Alto area. approach mimics conversation proceeds questions like type
food would like?; user might either answer particular answer like Chinese, say
care aspect, ask advisor possible choices. User
preferences obtained current conversation treated crisp constraints items
satisfy considered. items satisfy preferences, system
may ask user whether willing relax constraints.
tool also develops long-term user model keeps track preferences expressed
previous interactions. used sort results shown user.
Using prior knowledge also possible optimize set examples given expectation
users preferences, without actually asking users state preferences.
approach described Price Messinger (2005). work differs
consider preferences individual user, average preferences group users.
Preference elicitation optimized using prior distributions possible preferences.
approach proposed Chajewska et al. (2000) produce efficient preference elicitation
procedure. elicitation question-answering interaction questions selected
maximize expected value information. Boutilier (2002) extended work taking
account values future questions optimize decision quality minimizing user effort.
views elicitation procedure decision process uses observable Markov process
(POMDP) obtain elicitation strategy.
approaches require users familiar enough available options answer
question value functions without benefit example outcomes assess them. contrast,
mixed-initiative system described user free furnish information
confident about. also questionable whether one assume prior distribution preferences
personalized recommendation systems users may diverse.
499

fiV IAPPIANI , FALTINGS , & P U

7. Conclusion
considered AI techniques used product search recommender systems based set
preferences explicitly stated users. One challenges recognized field elicitation
accurate preference model user. particular, face dilemma accuracy
cost user effort.
systems may introduce severe errors model users cannot expend
amount effort required state preferences, others may require little effort provide
general recommendations preference model never completely established.
ideal solution one provides users accurate recommendations minimizing
effort stating preferences. Therefore, article also examined user interaction issues
emphasized models motivate users state complete accurate preferences,
requiring least amount effort user.
conjectured benefit discovering attractive recommendations presents strong motivation users state additional preferences. Thus, developed model-based approach
analyzes users current preference model potential hidden preferences order generate
set suggestions would attractive rational user. suggestion set calculated based
look-ahead principle: good suggestion outcome becomes optimal additional
hidden preferences considered. simulations, demonstrated superior performance model-based strategies comparison proposed strategies.
validated hypothesis strategies highly likely stimulate users
express preferences significant within-subject user study involving 40 real users.
measured decision accuracy, defined percentage users actually found
preferred option tool, example-critiquing tool without suggestions.
study showed users able achieve significantly higher level decision accuracy
example-critiquing tool suggestions without suggestions, increasing 45
80%, effort spent tools comparable. shows significant potential
improving tools currently use.
important note performance obtained users bound
particular dialogue, free interact system initiative.
process particularly supports preference expression users unfamiliar
domain, typically decisions require low medium financial commitments. highly
important decisions users understand preferences well, preference elicitation techniques (Keeney & Raiffa, 1976; Boutilier et al., 2005) likely provide superior results.
strategies based general notion Pareto-optimality, applied
broad range preference modeling formalisms, including utility functions, soft constraints
(Bistarelli et al., 1997), CP-networks (Boutilier, Brafman, Domshlak, Hoos, & Poole, 2004).
greatly strengthen performance example-critiquing systems applications ranging
decision support e-commerce.

8. Acknowledgements
authors would like thank Vincent Schickel-Zuber significant contribution development web based interface FlatFinder, Jennifer Graetzel insightful sug500

fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONS

gestions various draft versions manuscript improve readability. work
supported Swiss National Science Foundation contract No. 200020-103421.

References
Adomavicius, G., & Tuzhilin, A. (2005). Toward next generation recommender systems:
survey state-of-the-art possible extensions. IEEE Transactions Knowledge
Data Engineering, 17(6), 734749.
Bistarelli, S., Montanari, U., & Rossi, F. (1997). Semiring-based constraint satisfaction optimization. Journal ACM, 44(2), 201236.
Boutilier, C. (2002). pomdp formulation preference elicitation problems. Proceedings
Eighteenth National Conference Artificial Intelligence (AAAI02), pp. 239246.
Boutilier, C., Brafman, R. I., Domshlak, C., Hoos, H. H., & Poole, D. (2004). CP-nets: tool
representing reasoning conditional ceteris paribus preference statements. Journal
Artificial Intelligence Research, 21, 135191.
Boutilier, C., Patrascu, R., Poupart, P., & Schuurmans, D. (2005). Regret-based utility elicitation
constraint-based decision problems.. Proceedings Nineteenth International Joint
Conference Artificial Intelligence (IJCAI05), pp. 929934.
Bridge, D. G., & Ferguson, A. (2002). Diverse product recommendations using expressive language case retrieval. Proceedings 6th European Conference Advances
Case-Based Reasoning (ECCBR02), pp. 4357.
Burke, R. (2002a). Interactive critiquing catalog navigation e-commerce. Artificial Intelligence Review, 18(3-4), 245267.
Burke, R. D. (2002b). Hybrid recommender systems: Survey experiments. User Model. UserAdapt. Interact., 12(4), 331370.
Burke, R. D., Hammond, K. J., & Young, B. C. (1997). FindMe approach assisted browsing.
IEEE Expert, 12(4), 3240.
Chajewska, U., Koller, D., & Parr, R. (2000). Making rational decisions using adaptive utility
elicitation. Proceedings Seventeenth National Conference Artificial Intelligence
Twelfth Conference Innovative Applications Artificial Intelligence (AAAI00), pp.
363369. AAAI Press / MIT Press.
Chomicki, J. (2003). Preference formulas relational queries. ACM Trans. Database Syst., 28(4),
427466.
Faltings, B., Torrens, M., & Pu, P. (2004). Solution generation qualitative models preferences. Computational Intelligence, pp. 246263(18). ACM.
Haubl, G., & Trifts, V. (2000). Consumer decision making online shopping environments:
effects interactive decision aids. Marketing Science, 19(1), 421.
Hebrard, E., Hnich, B., OSullivan, B., & Walsh, T. (2005). Finding diverse similar solutions
constraint programming. Proceedings Twentieth National Conference Artificial
Intelligence (AAAI05), pp. 372377.
501

fiV IAPPIANI , FALTINGS , & P U

Keeney, R. L. (1992). Value-Focused Thinking. Path Creative Decision Making. Cambridge:
Harvard University Press.
Keeney, R. L., & Raiffa, H. (1976). Decisions Multiple Objectives: Preferences Value
Tradeoffs. John Wiley Sons, New York.
Kiesling, W. (2002). Foundations preferences database systems. Proceedings 28th
International Conference Large Data Bases (VLDB02), pp. 311322.
Konstan, J. A., Miller, B. N., Maltz, D., Herlocker, J. L., Gordon, L. R., & Riedl, J. (1997). Grouplens: Applying collaborative filtering usenet news. Commun. ACM, 40(3), 7787.
Krulwich, B. (1997). Lifestyle finder: Intelligent user profiling using large-scale demographic data.
AI Magazine, 18(2), 3745.
Linden, G., Hanks, S., & Lesh, N. (1997). Interactive assessment user preference models:
automated travel assistant. Proceedings Fifth Internation Conference User Modeling (UM97).
McCarthy, K., McGinty, L., Smyth, B., & Reilly, J. (2005). live-user evaluation incremental dynamic critiquing. Proceedings 6th International Conference Case-Based
Reasoning (ICCBR05), Vol. 3620, pp. 339352. Springer LNAI.
McGinty, L., & Smyth, B. (2003). role diversity conversational recommender system.
Proceedings Fifth International Conference Case-Based Reasoning (ICCBR03),
pp. 276290. LNAI 2689.
McSherry, D. (2002). Diversity-conscious retrieval. Proceedings 6th European Conference
Advances Case-Based Reasoning (ECCBR02), pp. 219233.
McSherry, D. (2003). Similarity compromise. Proceedings 5th International Conference Case-Based Reasoning (ICCBR03), pp. 291305.
Payne, J., Bettman, J., & Johnson, E. (1993). Adaptive Decision Maker. Cambridge University
Press.
Price, R., & Messinger, P. R. (2005). Optimal recommendation sets: Covering uncertainty user
preferences. Proceedings Twentieth National Conference Artificial Intelligence
(AAAI05), pp. 541548.
Pu, P., & Chen, L. (2005). Integrating tradeoff support product search tools e-commerce sites.
Proceedings ACM Conference Electronic Commerce (EC05), pp. 269278.
Pu, P., & Faltings, B. (2000). Enriching buyers experiences: smartclient approach. Proceedings SIGCHI conference Human factors computing systems (CHI00), pp.
289296. ACM Press New York, NY, USA.
Pu, P., & Faltings, B. (2004). Decision tradeoff using example-critiquing constraint programming. Constraints: International Journal, 9(4).
Pu, P., & Kumar, P. (2004). Evaluating example-based search tools. Proceedings ACM
Conference Electronic Commerce (EC04).
Reilly, J., McCarthy, K., McGinty, L., & Smyth, B. (2004). Dynamic critiquing. Proceedings
7th European Conference Advances Case-Based Reasoning (ECCBR04), pp.
763777.
502

fiP REFERENCE - BASED EARCH USING E XAMPLE -C RITIQUING UGGESTIONS

Resnick, P., Iacovou, N., Suchak, M., Bergstorm, P., & Riedl, J. (1994). Grouplens: open architecture collaborative filtering netnews. Proceedings ACM 1994 Conference
Computer Supported Cooperative Work, pp. 175186, Chapel Hill, North Carolina. ACM.
Rich, E. (1979). User modeling via stereotypes. Cognitive Science, 3, 329354.
Ruttkay, Z. (1994). Fuzzy constraint satisfaction. Proceedings 3rd IEEE Conference
Fuzzy Systems, pp. 12631268, Orlando.
Shearin, S., & Lieberman, H. (2001). Intelligent profiling example. Proceedings Intelligent
User Interfaces (IUI 2001), pp. 145151.
Shimazu, H. (2001). Expertclerk: Navigating shoppers buying process combination
asking proposing. Proceedings Seventeenth International Joint Conference
Artificial Intelligence (IJCAI01), Vol. 2, pp. 14431448.
Smyth, B., & McClave, P. (2001). Similarity vs. diversity. Proceedings 4th International
Conference Case-Based Reasoning (ICCBR01), pp. 347361.
Smyth, B., & McGinty, L. (2003). power suggestion. Proceedings Eighteenth
International Joint Conference Artificial Intelligence (IJCAI 2003), Acapulco, Mexico, pp.
127132.
Spiekermann, S., & Paraschiv, C. (2002). Motivating humanagent interaction: Transferring insights
behavioral marketing interface design. Electronic Commerce Research, 2(3), 255
285.
Thompson, C. A., Goker, M. H., & Langley, P. (2004). personalized system conversational
recommendations. Journal Artificial Intelligence Research, 21, 393428.
Torrens, M., Faltings, B., & Pu, P. (2002). Smart clients: Constraint satisfaction paradigm
scaleable intelligent information systems. Special issue Constraints Agents. CONSTRAINTS: Internation Journal. Kluwer Academic Publishers, pp. 4969.
Torrens, M., Weigel, R., & Faltings, B. (1998). Distributing problem solving web using
constraint technology. Proceedings International Conference Tools Artificial
Intelligence (ICTAI98), pp. 4249, Taipei, Taiwan. IEEE Computer Society Press.
Tversky, A. (1974). Judgement uncertainity: Heuristics biases. Science, 185, 11241131.
Zhang, J., & Pu, P. (2006). Performance evaluation consumer decision support systems. International Journal E-Business Research, 2, 2845.

503

fiJournal Artificial Intelligence Research 27 (2006) 577615

Submitted 2/2006; published 12/2006

Understanding Algorithm Performance
Oversubscribed Scheduling Application
Laura Barbulescu

laurabar@cs.cmu.edu

Robotics Institute
Carnegie Mellon University
Pittsburgh, PA 15213 USA

Adele E. Howe
L. Darrell Whitley
Mark Roberts

howe@cs.colostate.edu
whitley@cs.colostate.edu
mroberts@cs.colostate.edu

Computer Science Department
Colorado State University
Fort Collins, CO 80523 USA

Abstract
best performing algorithms particular oversubscribed scheduling application,
Air Force Satellite Control Network (AFSCN) scheduling, appear little common. Yet, careful experimentation modeling performance real problem
instances, relate characteristics best algorithms characteristics
application. particular, find plateaus dominate search spaces (thus favoring algorithms make larger changes solutions) randomization
exploration critical good performance (due lack gradient information
plateaus). Based explanations algorithm performance, develop new
algorithm combines characteristics best performers; new algorithms performance better previous best. show hypothesis driven experimentation
search modeling explain algorithm performance motivate design
new algorithm.

1. Introduction
Effective solution Air Force Satellite Control Network (AFSCN) oversubscribed
scheduling problem runs counter works well similar scheduling problems.
similar oversubscribed problems, e.g., United States Air Force (USAF) Air Mobility Command (AMC) airlift (Kramer & Smith, 2003) scheduling telescope observations (Bresina,
1996), well solved heuristically guided constructive repair based search. best
performing solutions AFSCN genetic algorithm (Genitor), Squeaky Wheel Optimization (SWO) randomized next-descent local search. yet found
constructive repair based solution competitive.
three best performing solutions AFSCN appear little common, making
difficult explain superior performance. Genitor combines two candidate solutions
preserving elements each. SWO creates initial greedy solution attempts
improve scheduling tasks known contribute detrimentally current evaluation. Randomized local search makes incremental changes based observed immediate
gradients schedule evaluation. paper, examine performance differc
2006
AI Access Foundation. rights reserved.

fiBarbulescu, Howe, Whitley, & Roberts

ent algorithms, identify factors help explain performance leverage
explanations design new search algorithm well suited characteristics
application.
target application oversubscribed scheduling application alternative resources. AFSCN (Air Force Satellite Control Network) access scheduling requires assigning
access requests (communication relays U.S.A. government satellites) specific time slots
antenna ground station. oversubscribed tasks accommodated given available resources. considered oversubscribed, least
problem instances need overtax available resources; application though,
appears problem instances specify tasks feasibly scheduled.
application challenging shares characteristics applications
Earth Observing Satellites (EOS). important team human schedulers
laboriously performed task every day least 15 years minimal automated
assistance.
algorithms designed traverse essentially search space: solutions
represented permutations tasks, greedy schedule builder converts
schedule assigning start time resources tasks order
appear permutation. find search space dominated large flat
regions (plateaus). Additionally, size plateaus increases dramatically best
solution approached. presence plateaus indicates algorithm needs
effectively manage order find improving solutions.
explored number different hypotheses explain performance
algorithm. hypotheses include following:
Genitor, genetic algorithm, identifies patterns relative task orderings, similar backbones SAT (Singer, Gent, & Smaill, 2000), preserved members
population. effect type classic building block hypothesis (Goldberg,
1989).
SWO starts extremely close best solution need enact much change.
hypothesis also implies relatively easy modify good greedy solutions
find best known solutions.
Randomized Local Search performs essentially random walk plateaus find
exits leading better solutions; given distribution solutions lack gradient
information, may good strategy any.
tested hypotheses. limited evidence existence building
blocks backbone structure. Squeaky Wheel Optimization quickly find
good solutions, cannot reliably find best known solutions. Therefore, first
two hypotheses somewhat supported data, hypotheses enough
explain observed performance.
third hypothesis appears best explanation particular local
search strategy used works well. light this, formulated another hypothesis:
SWO Genitor make long leaps search space, allow relatively
quickly traverse plateaus.
578

fiUnderstanding Algorithm Performance

last hypothesis appears well explain performance two methods.
genetic algorithm leaps naturally longer early phases search
parent solutions less similar.
Based studies, constructed new search algorithm exploits
learned search space behavior successful algorithms. Attenuated
Leap Local Search makes multiple changes solution evaluating candidate
solution. addition, number changes decreases proportionately expected proximity solution. number multiple changes, length leap, larger
early search, reduces (shortens) better solutions found. find
algorithm performs quite well: quickly finds best known solutions AFSCN
problems.

2. AFSCN Scheduling
U.S.A. Air Force Satellite Control Network currently responsible coordinating
communications civilian military organizations 100 USAF managed satellites. Space-ground communications performed using 16 antennas located
nine tracking stations around globe 1 . Figure 1 shows map current configuration
AFSCN; map shows one fewer tracking station antennae data,
due resources apparently taken off-line recently. Customer organizations submit task requests reserve antenna tracking station specified time
period based visibility windows target satellites tracking stations. Two
types task requests distinguished: low altitude high altitude orbits. low
altitude tasks specify requests access low altitude satellites; requests tend
short (e.g., 15 minutes) tight visibility window. High altitude tasks specify
requests high altitude satellites; durations requests varied
usually longer, large visibility windows.
Approximately 500 requests typically received single day. Separate schedules
produced staff human schedulers Schriever Air Force Base day.
500 requests, often 120 conflicts remain first pass scheduling. Conflicts
defined requests cannot scheduled, since conflict scheduled
requests (this means 120 requests remain unscheduled initial schedule
produced).
real problem data, extract description problem specification terms
task requests scheduled corresponding type (low high altitude), duration,
time windows alternative resources. AFSCN data also include information
satellite revolution numbers, optional site equipment, tracking station maintenance times
(downtimes), possible loss data due antenna problems, various comments, etc.;
incorporate information problem specification. information
type task (low high altitude) well identifier satellite involved
included task specification. However, know satellite identifier
1. U.S.A. government planning make AFSCN core Integrated Satellite Control
Network managing satellite assets U.S.A. government agencies well, e.g., NASA, NOAA,
DoD affiliates. 2011, system first becomes operational, Remote Tracking Stations
increased enhanced accommodate additional load.

579

fiBarbulescu, Howe, Whitley, & Roberts

Figure 1: Map current AFSCN network including tracking stations, control relay.
figure produced U.S.A. Space Missile Systems Center (SMC).

corresponds actual satellite rely precomputed visibility information
present requests.
problem instance consists n task requests. task request , 1 n, specifies
required processing duration TiDur . task request also specifies number j 0
pairs form (Rj , TijWin ), identifying particular alternative resource (antenna
Rj ) time window TijWin task. duration task
possible alternative resources. start end visibility time window specific
alternative resource; therefore duration same, time windows
different alternative resources. resource assigned request,
duration needs allocated within corresponding time window. denote
lower upper bounds time window j corresponding request ijWin (LB)
TijWin (UB), respectively. task, one alternative antennas needs
chosen; also, tasks cannot preempted processing initiated.
requests made specific antenna, often different antenna
tracking station may serve alternate capabilities. assume
antennas tracking station serve alternate resources.
always case practice, assumption made previous research Air
580

fiUnderstanding Algorithm Performance

Force Institute Technology (AFIT) 2 . low altitude request specifies possible resources
antennas present single tracking station (for visibility reasons, one tracking
station accommodate request). Usually two three antennas present
tracking station, therefore, two three possible resources associated
requests. High altitude requests specify antennas present
tracking stations satisfy visibility constraints; many 14 possible alternatives
specified data.
Previous research development AFSCN scheduling focused minimizing
number request conflicts AFSCN scheduling, alternatively, maximizing number
requests scheduled without conflict. requests cannot scheduled
without conflict bumped schedule. happens humans
carry AFSCN scheduling3 . Satellites valuable resources, AFSCN operators
work fit every request. means practice negotiation
customers, requests given less time requested, shifted less desirable,
still usable time slots. effect, requests altered requests least
partially satisfied deferred another day. using evaluation function minimizes
number request conflicts, assumption made fit many
requests possible requiring human schedulers figure place
requests bumped.
However, given requests need eventually scheduled, designed new
evaluation criterion schedules requests allowing overlap minimizing sum overlaps conflicting tasks. appears yield schedules
much closer human schedulers construct. conflicting tasks bumped
schedule, large difficult schedule tasks likely bumped;
placing requests back negotiated schedule means deconstructing minimal
conflict schedule rebuilding new schedule. Thus, schedule minimizes conflicts
may help much constructing negotiated schedule, whereas schedule
minimizes overlaps suggest ways fitting tasks schedule, example
reducing tasks duration two three minutes, shifting start outside
requested window short amount time.
obtained 12 days data AFSCN application 4 . first seven days
week 1992 given us Colonel James Moore Air Force Institute
Technology. data used first research projects AFSCN. obtained
additional five days data schedulers Schriever Air Force Base. Table 2 summarizes
characteristics data. best known solutions obtained performing long
runs hundreds experiments. Using various algorithms allowing hundreds

2. fact, large antennas needed high altitude requests, smaller antennas handle low
altitude requests. Depending type antennas present tracking station, antennas
always serve alternate resources request.
3. met several schedulers Schriever discuss procedure crosscheck solution. appreciate assistance Brian Bayless William Szary setting
meeting giving us data.
4. approval make public some, data.
See http://www.cs.colostate.edu/sched/data.html details obtaining problems.

581

fiBarbulescu, Howe, Whitley, & Roberts

ID
A1
A2
A3
A4
A5
A6
A7
R1
R2
R3
R4
R5

Date
10/12/92
10/13/92
10/14/92
10/15/92
10/16/92
10/17/92
10/18/92
03/07/02
03/20/02
03/26/03
04/02/03
05/02/03

# Requests
322
302
311
318
305
299
297
483
457
426
431
419

# High
169
165
165
176
163
155
155
258
263
243
246
241

# Low
153
137
146
142
142
144
142
225
194
183
185
178

Best Conflicts
8
4
3
2
4
6
6
42
29
17
28
12

Best Overlaps
104
13
28
9
30
45
46
773
486
250
725
146

Table 1: Problem characteristics 12 days AFSCN data used experiments.
ID used tables. Best conflicts best overlaps best known
values problem two objective functions.

thousands evaluations, found better solutions 5 . refer
problems 1992 problems, recent problems, R
problems.

3. Related Scheduling Research
AFSCN application multiple resource, oversubscribed problem. Examples
applications USAF Air Mobility Command (AMC) airlift scheduling (Kramer &
Smith, 2003), NASAs shuttle ground processing (Deale et al., 1994), scheduling telescope
observations (Bresina, 1996) satellite observation scheduling (Frank, Jonsson, Morris,
& Smith, 2001; Globus, Crawford, Lohn, & Pryor, 2003).
AMC scheduling assigns delivery missions air wings (Kramer & Smith, 2003).
system adopts iterative repair approach greedily creating initial schedule ordering
tasks priority attempting insert unscheduled tasks retracting
re-arranging conflicting tasks.
Gerry scheduler designed manage large set tasks needed prepare
space shuttle next mission (Zweben, Daun, & Deale, 1994). Tasks described
terms resource requirements, temporal constraints required time windows.
original version used constructive search dependency-directed backtracking,
adequate task; subsequent version employed constraint-directed iterative repair.
satellite scheduling, customer requests data collection need matched
satellite tracking station resources. requests specify instruments required,
window time request needs executed, location sensing/communication event. task constraints need coordinated resource
5. best known values obtained running Genitor population size increased 400
allowing 50,000 evaluations per run.

582

fiUnderstanding Algorithm Performance

constraints; include windows visibility satellites, maintenance periods
downtimes tracking stations, etc. Typically, requests need scheduled
accommodated available resources. general description satellite
scheduling domain provided Jeremy Frank et al. (2001).
Pemberton (2000) solves simple one-resource satellite scheduling problem
requests priorities, fixed start times fixed durations. objective function
maximizes sum priorities scheduled requests. priority segmentation algorithm proposed, hybrid algorithm combining greedy approach branchand-bound. Wolfe Sorensen (2000) define complex one-resource problem,
window-constrained packing problem (WCP), specifies request earliest
start time, latest final time minimum maximum duration. objective function complex, combining request priority position scheduled request
required window number requests scheduled. Two greedy heuristic approaches
genetic algorithm implemented; genetic algorithm found perform best.
Globus et al. (2003) compare genetic algorithm, simulated annealing, Squeaky Wheel
Optimization (Joslin & Clements, 1999) hill climbing simplified, synthetic form
satellite scheduling problem (two satellites single instrument) find
simulated annealing excels genetic algorithm performs relatively poorly.
general version satellite scheduling (EOS observation scheduling), Frank et al. (2001)
propose constraint-based planner stochastic greedy search algorithm based
Bresinas Heuristic-Biased Stochastic Sampling (HBSS) algorithm (Bresina, 1996). HBSS
originally applied scheduling astronomy observations telescopes.
Lematre et al. (2000) research problem scheduling set photographs Agile
EOS (ROADEF Challenge, 2003). Task constraints include minimal time two
successive acquisitions, pairings requests images acquired twice different
time windows, hard requirements certain images must always acquired.
find local search approach performs better hybrid algorithm combining branchand-bound various domain-specific heuristics.
AFSCN application previously studied researchers Air Force Institute Technology (AFIT). Gooley (1993) Schalck (1993) described algorithms based
mixed-integer programming (MIP) insertion heuristics, achieved good overall performance: 91% 95% requests scheduled. Parish (1994) used Genitor
(Whitley, 1989) genetic algorithm, scheduled roughly 96% task requests, outperforming MIP approaches. three researchers used AFIT benchmark
suite consisting seven problem instances, representing actual AFSCN task request data
visibilities seven consecutive days October 12 18, 1992. Later, Jang (1996)
introduced problem generator employing bootstrap mechanism produce additional
test problems qualitatively similar AFIT benchmark problems. Jang
used generator analyze maximum capacity AFSCN, measured
aggregate number task requests satisfied single-day.
general decision problem AFSCN Scheduling minimal conflicts N Pcomplete, special subclasses AFSCN Scheduling polynomial. Burrowbridge (1999)
considers simplified version AFSCN scheduling, task specifies one resource (antenna) low-altitude satellites present. objective maximize
number scheduled tasks. Due orbital dynamics low-altitude satellites,
583

fiBarbulescu, Howe, Whitley, & Roberts

task requests problem negligible slack ; i.e., window size equal
request duration. Assuming one task scheduled per time window, wellknown greedy activity-selector algorithm (Cormen, Leiserson, & Rivest, 1990) used
schedule requests since yields solution maximal number scheduled tasks.
schedule low altitude requests one multiple antennas present particular
ground station, extended greedy activity-selector algorithm multiple resource
problems. proved extension greedy activity-selector optimally schedules low altitude requests general problem AFSCN Scheduling (Barbulescu,
Watson, Whitley, & Howe, 2004b).

4. Algorithms
implemented variety algorithms AFSCN scheduling: iterative repair, heuristic
constructive search, local search, genetic algorithm (GA), Squeaky Wheel Optimization (SWO). shown Section 5, found randomized next descent local
search, GA SWO work best AFSCN scheduling.
also considered constructive search algorithms based texture (Beck, Davenport,
Davis, & Fox, 1998) slack (Smith & Cheng, 1993) constraint-based scheduling heuristics.
implemented straightforward extensions algorithms application.
results poor; number request tasks combined presence multiple
alternative resources task make application methods impractical.
report performance values constructive search methods
methods depend critically heuristics; uncomfortable concluding
methods poor may found good enough heuristics them.
also tried using commercial off-the-shelf satellite scheduling package similarly
poor results. report performance values commercial system
designed specifically application access
source determine reason poor performance.
4.1 Solution Representation
Permutation based representations frequently used solving scheduling problems
(e.g., Whitley, Starkweather, Fuquay, 1989; Syswerda, 1991; Wolfe, Sorensen, 2000; Aickelin, Dowsland, 2003; Globus et al., 2003). algorithms, except iterative-repair,
encode solutions using permutation n task request IDs (i.e., [1..n]). schedule
builder used generate solutions permutation request IDs. schedule builder
considers task requests order appear . task request assigned
first resource available sequence resource window pairs provided
task description (this first feasible resource sequence); earliest possible
starting time chosen resource. minimizing number conflicts,
request cannot scheduled alternative resources, dropped
schedule (i.e., bumped). minimizing sum overlaps, request cannot
scheduled without conflict alternative resources, assign resource
584

fiUnderstanding Algorithm Performance

overlap requests scheduled far minimized. 6 Note schedule
builder favor order alternative resources specified request,
even though preference specified alternatives.
4.2 Iterative Repair
Iterative repair methods successfully used solve various oversubscribed scheduling problems, e.g., Hubble Space Telescope observations (Johnston & Miller, 1994) space
shuttle payloads (Zweben et al., 1994; Rabideau, Chien, Willis, & Mann, 1999). NASAs
ASPEN (A Scheduling Planning Environment) framework (Chien et al., 2000), employs constructive repair-based methods used model solve
real-world space applications scheduling EOS. recently, Kramer Smith
(2003) used repair-based methods solve airlift scheduling problem USAF Air
Mobility Command.
case, key component implementation domain appropriate ordering heuristic guide repairs. AFSCN scheduling, Gooleys algorithm (1993)
uses domain-specific knowledge implement repair-based approach. implement
improvement Gooleys algorithm guaranteed yield results least good
produced original version.
Gooleys algorithm two phases. first phase, low altitude requests
scheduled, mainly using Mixed Integer Programming (MIP). large number
low altitude requests, requests divided two blocks. MIP procedures
first used schedule requests first block. MIP used schedule
requests second block, inserted schedule around requests
first block. Finally, interchange procedure attempts optimize total number
low altitude requests scheduled. needed low altitude requests
scheduled disjoint blocks. low altitude requests scheduled, start time
assigned resources remain fixed. implementation, replaced first phase
greedy algorithm (Barbulescu et al., 2004b) proven schedule optimal number
low altitude requests7 . greedy algorithm modifies well-known activity-selector
algorithm (Cormen et al., 1990) multiple resource problems: algorithm still schedules
requests increasing order due date, however specifies request
scheduled resource idle time start time minimum.
version accomplishes function Gooleys first phase,
guarantee optimal number low-altitude requests scheduled. Thus, result
guaranteed equal better Gooleys original algorithm.
second phase, high altitude requests inserted schedule (without
rescheduling low altitude requests). order insertion high altitude
requests computed. requests sorted decreasing order ratio duration
request average length time windows (this similar flexibility
measure defined Kramer Smith, 2003 AMC); ties broken based number
alternative resources specified (fewer alternatives scheduled first). high
6. two non-scheduled tasks overlap other, mutual overlap part sum
overlaps. overlap scheduled requests considered.
7. algorithm optimally solves problem scheduling low altitude requests, polynomial
time.

585

fiBarbulescu, Howe, Whitley, & Roberts

altitude requests considered insertion, interchange procedure attempts
accommodate unscheduled requests, rescheduling high altitude requests.
unscheduled high altitude request, list candidate requests rescheduling
computed (such successful rescheduling operation, unscheduled request
placed spot initially occupied candidate). heuristic measure
used determine requests candidate list rescheduled.
chosen candidates, scheduling alternatives available, procedure applied
identify requests rescheduled. interchange procedure defined
two levels recursion called three satellite interchange.
4.3 Randomized Local Search (RLS)
implemented hill-climber call randomized local search, starts randomly generated solution iteratively moves toward better equally good neighboring solution. successfully applied number well-known
scheduling problems, selected domain-independent move operator, shift operator. current solution , neighborhood defined considering (N 1) 2
pairs (x, y) positions , subject restriction 6= x 1. neighbor
0
corresponding position pair (x, y) produced shifting job position
x position y, leaving relative job orders unchanged. x < y,
0 = ((1), ..., (x 1), (x + 1), ..., (y), (x), (y + 1), ..., (n)). x > y,
0 = ((1), ..., (y 1), (x), (y), ..., (x 1), (x + 1), ..., (n)).
Given large neighborhood size, use shift operator conjunction nextdescent hill-climbing. implementation completely randomizes neighbor examine next, replacement: step, x chosen randomly.
general approach termed stochastic hill-climbing Ackley (1987).
value randomly chosen neighbor equal better value current
solution, becomes new current solution.
emphasized Randomized Local Search, stochastic hill-climbing,
sometimes much effective steepest-descent local search next-descent local
search neighbors checked predefined order (as opposed random order).
Forrest Mitchell (1993) showed random mutation hill climber (much like RLS
Ackleys stochastic hill climber) found solutions much faster steepest-descent local
search problem called Royal Road function. random mutation hill
climber also found solutions much faster hill climber generated examined
neighbors systematically (in predefined order). Random mutation hill climber
also much effective genetic algorithm problem despite existence
would appear natural building blocks function. notable
Royal Road function staircase like function, step staircase
plateau.
4.4 Genetic Algorithm
Genetic algorithms found perform well AFSCN scheduling problem
early studies (Parish, 1994). Genetic algorithms also found effective
oversubscribed scheduling applications, scheduling F-14 flight simulators (Syswerda,
586

fiUnderstanding Algorithm Performance

1991) abstraction NASAs EOS problem (Wolfe & Sorensen, 2000). studies,
used version Genitor originally developed warehouse scheduling application
(Starkweather et al., 1991); also version used Parish AFSCN scheduling.
Like genetic algorithms, Genitor maintains population solutions; implementation, fixed population size 200. step algorithm, pair parent
solutions selected, crossover operator used generate single child solution,
replaces worst solution population. Selection parent solutions
based rank fitness, relative solutions population. Following
Parish (1994) Starkweather et al. (1991), used Syswerdas (1991) position-based
crossover operator.
Syswerdas position-based crossover operator starts selecting number random
positions second parent. corresponding selected elements appear exactly
positions offspring. remaining positions offspring filled
elements first parent order appear parent:
Parent 1: B C E F G H J
Parent 2: C F J H G B E
Selected Elements:
* *
*
*
Offspring: C F E G H B J
implementation, randomly choose number positions selected,
larger one third total number positions smaller two
thirds total number positions.
4.5 Squeaky Wheel Optimization
Squeaky Wheel Optimization (SWO) (Joslin & Clements, 1999) repeatedly iterates
cycle composed three phases. First, greedy solution built, based priorities associated elements problem. Then, solution analyzed, elements
causing trouble identified based contribution objective function. Third,
priorities trouble makers modified, considered earlier next iteration. cycle repeated, termination condition
met.
constructed initial greedy permutation SWO sorting requests increasing order flexibility. flexibility measure similar defined
AMC application (Kramer & Smith, 2003): duration request divided
average time window possible alternative resources. break ties based
number alternative resources available. requests equal flexibilities numbers
alternative resources, earlier request scheduled first. multiple runs SWO,
restarted modified permutation created performing 20 random swaps
initial greedy permutation.
minimizing sum overlaps, identified overlapping requests
trouble spots schedule. Note overlap, considered one request
scheduled; request (or requests, two requests involved)
overlapping request. sorted overlapping requests increasing order
contribution sum overlaps. associated request distance
587

fiBarbulescu, Howe, Whitley, & Roberts

move forward, based rank sorted order. fixed minimum distance
moving forward one maximum distance five (this seems work better
possible values tried). distance values equally distributed among ranks.
moved requests forward permutation increasing order contribution
sum overlaps: requests smaller overlaps moved first. tried versions
SWO distance move forward proportional contribution
sum overlaps fixed. However, versions performed worse rank based
distance implementation described above. minimizing conflicts schedule
conflicts equal contribution objective function; therefore decided move
forward fixed distance five (we tried values two seven five
best).
4.6 Heuristic Biased Stochastic Sampling (HBSS)
HBSS (Bresina, 1996) incremental construction algorithm multiple rootto-leaf paths stochastically generated. step, HBSS algorithm needs
heuristically choose next request schedule unscheduled requests. used
flexibility measure described SWO rank unscheduled requests. compute
flexibility request order decreasing order flexibility;
request given rank according ordering (first request rank 1, second
request rank 2, etc.). bias function applied ranks; noted Bresina (1996,
p.271), choice bias function reflects confidence one heuristics accuracy
- higher confidence, stronger bias. flexibility heuristic effective
greedy heuristic constructing solutions AFSCN scheduling. Therefore used
relatively strong bias function, exponential bias. rank r, bias computed:
bias(r) = er . probability select unscheduled request rank r
computed as:
bias(r)
P (r) = P
iUnscheduled bias(rank(i))
Unscheduled represents set unscheduled requests.
implementation HBSS re-compute flexibility unscheduled tasks
every time choose next request scheduled. words, HBSS building
permutation requests schedule builder produces corresponding schedule.
terms CPU time, means time required HBSS build solution
similar algorithms (dominated number evaluations). version
re-computing flexibility unscheduled tasks tasks scheduled would lot
expensive. fact, EOS similar oversubscribed scheduling problem,
Globus et al. (2004) found updating heuristic values HBSS scheduling
hundreds times slower permutation-based techniques, required far
memory, produced poor schedules.

588

fiUnderstanding Algorithm Performance

5. Works Well?
first step understanding best solve problem assess methods perform
best. results running algorithms summarized Tables 2 3
respectively. Genitor, randomized local search (RLS) Squeaky Wheel Optimization
(SWO), report best mean value standard deviation observed 30
runs, 8000 evaluations per run. HBSS, statistics taken 240,000 samples.
Genitor RLS initialized random permutations.
best known values sum overlaps (see Table 2) obtained running
Genitor population size increased 400 50,000 evaluations; hundreds experiments using numerous algorithms, found better solutions
these. report algorithm better Genitor means better
Genitor algorithms limited 8000 evaluations.
exception Gooleys algorithm, CPU times dominated number
evaluations therefore similar. Dell Precision 650 3.06 GHz Xeon
running Linux, 30 runs 8000 evaluations per run take 80 190 seconds (for
precise values, see Barbulescu et al., 2004).
increase number requests received day recent R problems
causes increase number percentage unscheduled requests. problems, eight task requests (or 2.5% tasks) scheduled; 97.5%
99% task requests scheduled. R problems, 42 (or 8.7%
tasks) scheduled; 91.3% 97.2% tasks requests scheduled.
compare algorithm performance, statistical analyses include Genitor, SWO,
RLS. also include analyses algorithms SWO1Move (a variant SWO
explore Section 6.5.2), ALLS (a variant Local Search present Section 7).
judge significant differences final evaluations using ANOVA five algorithms
recent days data. ANOVAs came back significant, justified
performing pair-wise tests. examined single-tailed, two sample t-test well
non-parametric Wilcoxon Rank Sum test. Wilcoxon test significance results
t-test except two pairs, present p-values t-test
close rejection threshold p .005 per pair-wise test 8 .
minimizing conflicts, many algorithms find solutions best known
values. Pair-wise t-tests show Genitor RLS significantly different R1,
R3, R4. Genitor significantly outperforms RLS R2 (p = .0023) R5 (p = .0017).
SWO perform significantly different RLS five days significantly
outperforms Genitor R5. Genitor significantly outperforms SWO R2 R4; however,
adjusting parameters used run SWO may fix problem. fact
surprising well SWO performs minimizing conflicts, given chose
simple implementation, tasks conflict moved forward fixed
distance. HBSS performs well problems; however, fails find best known
values R1, R2 R3. original solution problem, Gooleys, computes
single solution; results improved sampling variant (see Section 6.2.1).
8. Five algorithms imply, worst, 10 pair-wise comparisons per day data. control experimentwise error, use (very conservative, simple) Bonferroni adjustment; adjustment known
increase probability Type II error (favoring false acceptance distributions similar).
= .05, judge two algorithms significantly different p .005.

589

fiBarbulescu, Howe, Whitley, & Roberts

Day
A1
A2
A3
A4
A5
A6
A7
R1
R2
R3
R4
R5

Min
8
4
3
2
4
6
6
42
29
17
28
12

Genitor
Mean
8.6
4
3.03
2.06
4.1
6.03
6
43.7
29.3
17.63
28.03
12.03

SD
0.49
0
0.18
0.25
0.3
0.18
0
0.98
0.46
0.49
0.18
0.18

Min
8
4
3
2
4
6
6
42
29
17
28
12

RLS
Mean
8.7
4.0
3.1
2.2
4.7
6.16
6.06
44.0
29.8
18.0
28.36
12.4

SD
0.46
0
0.3
0.48
0.46
0.37
0.25
1.25
0.71
0.69
0.66
0.56

Min
8
4
3
2
4
6
6
43
29
18
28
12

SWO
Mean
8
4
3
2.06
4
6
6
43.3
29.96
18
28.3
12

SD
0.0
0.0
0.0
0.25
0.0
0.0
0.0
0.46
0.18
0.0
0.46
0

Min
8
4
3
2
4
6
6
45
32
19
28
12

HBSS
Mean
9.76
4.64
3.37
3.09
4.27
6.39
7.35
48.44
35.16
21.08
31.22
12.36

Gooley
SD
0.46
0.66
0.54
0.43
0.45
0.49
0.54
1.15
1.27
0.89
1.10
0.55

11
7
5
4
5
7
6
45
36
20
29
13

Table 2: Performance Genitor, RLS, SWO, HBSS Gooleys algorithm terms
best mean number conflicts. Statistics Genitor, local search
SWO collected 30 independent runs, 8000 evaluations per run.
HBSS, 240,000 samples considered. Min numbers boldface indicate best
known values.

minimizing overlaps, RLS finds best known solutions two
problems. significantly outperforms Genitor R1 R2, significantly under-performs
R3, significantly differ performance R4 R5. RLS SWO
perform significantly different except R3 RLS under-performs. SWO significantly
outperforms Genitor five days. However, run beyond 8000 evaluations, Genitor
continues improve solution quality SWO fails find better solutions. HBSS
finds best known solutions problems. comparison, computed
overlaps corresponding schedules built using Gooleys algorithm present
last column Table 3; however, Gooleys algorithm designed minimize
overlaps.
5.1 Progress Toward Solution
SWO Genitor apply different criteria determine solution modifications. RLS randomly chooses first shift resulting equally good improving solution. assess
effect differences, tracked best value obtained far running
algorithms. problem, collected best value found SWO, Genitor RLS
increments 100 evaluations, 8000 evaluations. averaged values 30
runs SWO, RLS, Genitor, respectively.
typical example objective function presented Figures 2 3.
objective functions, curves similar, relative performance. SWO quickly
finds good solution, performance levels off. RLS progresses quickly
first half search, Genitor exacts smaller improvements. second half
search though, RLS takes longer find better solutions, Genitor continues
steadily progress toward best solution. best far Genitor improve
590

fiUnderstanding Algorithm Performance

Day
A1
A2
A3
A4
A5
A6
A7
R1
R2
R3
R4
R5

Min
104
13
28
9
30
45
46
913
519
275
738
146

Genitor
Mean
106.9
13
28.4
9.2
30.4
45.1
46.1
987.8
540.7
292.3
755.4
146.5

SD
0.6
0.0
1.2
0.7
0.5
0.4
0.6
40.8
13.3
10.9
10.3
1.9

Min
104
13
28
9
30
45
46
798
494
250
725
146

RLS
Mean
106.76
13.66
30.7
10.16
30.83
45.13
49.96
848.66
521.9
327.53
755.46
147.1

SD
1.81
2.59
4.31
2.39
1.36
0.5
5.95
38.42
20.28
55.34
25.42
2.85

Min
104
13
28
9
30
45
46
798
491
265
731
146

SWO
Mean
104
13.4
28.1
13.3
30
45.1
46
841.4
503.8
270.1
736.2
146.0

SD
0.0
2.0
0.6
7.8
0.0
0.3
0.0
14.0
6.5
2.8
3.0
0.0

Min
128
43
28
9
50
45
83
1105
598
416
827
146

HBSS
Mean
158.7
70.1
52.5
45.7
82.6
65.5
126.4
1242.6
681.8
571.0
978.4
164.4

Gooley
SD
28.7
31.1
16.9
13.0
13.2
16.8
12.5
42.1
27.0
46.0
28.7
10.8

687
535
217
216
231
152
260
1713
1047
899
1288
198

Table 3: Performance Genitor, local search, SWO, HBSS Gooleys algorithm
terms best mean sum overlaps. statistics collected 30
independent runs, 8000 evaluations per run. HBSS, 240,000 samples
considered. Min numbers boldface indicate best known values.

quickly best far RLS. unexpected: best solution
Genitor population isnt likely improve frequently beginning run.
sense, tracking evolution median population running Genitor would
indicative progress; use best far allow uniform comparison
three algorithms.
observe two differences objective functions. First, minimizing number conflicts, Genitor RLS eventually equal outperform SWO. minimizing
overlaps, Genitor RLS take longer find good solutions; 8000 evaluations, SWO
found best solutions. Second, minimizing number conflicts, toward
end run, Genitor outperforms RLS. minimizing overlaps, RLS performs better Genitor. Best known solutions R problems minimizing overlaps
obtained running RLS 50,000 evaluations 30 runs. Running SWO 50,000
evaluations 30 runs results small improvements, two problems.

6. Hypotheses Explaining Algorithm Performance
Genitor, SWO RLS successful algorithms tested AFSCN
problem. Although operate search space (permutations), traverse
space rather differently. puzzle three apparently well suited
problem. solve puzzle, first, describe plateaus dominant feature
search space. show greedy schedule builder main reason presence
plateaus. Then, test hypotheses appear follow dominance
plateaus characteristics algorithm.
study, greedy schedule builder well objective function part
problem specification. Therefore, formulating testing hypotheses, consider
search space features (such plateaus number identical solutions) fixed.
591

fi36

Genitor
RLS
SWO

70

Average Best Far Number Bumps

Average Best Far Number Bumps

Barbulescu, Howe, Whitley, & Roberts

60

50

40

30
0

500

1000

1500
2000
2500
Evaluations

3000

3500

34
33
32
31
30
29
4000

4000

Genitor
RLS
SWO

35

4500

5000

5500
6000
6500
Evaluations

7000

7500

8000

Figure 2: Evolutions average best value conflicts obtained SWO, RLS
Genitor 8000 evaluations, 30 runs. left figure depicts improvement average best value first 4000 evaluations. last
4000 evaluations depicted right figure; note scale different
y-axis. curves obtained R2.

850

Genitor
RLS
SWO

1600

Average Best Far Sum Overlaps

Average Best Far Sum Overlaps

1800

1400
1200
1000
800
600
400

0

500

1000

1500
Evaluations

2000

2500

3000

Genitor
RLS
SWO

800
750
700
650
600
550
500
3000

4000

5000
6000
Evaluations

7000

8000

Figure 3: Evolutions average best value sum overlaps obtained SWO, RLS
Genitor 8000 evaluations, 30 runs. left figure depicts
improvement average best value first 3000 evaluations. last
5000 evaluations depicted right figure; note scale different
y-axis. curves obtained R2.

6.1 Redundancy Search Space
third neighbors RLS result exactly schedule
overlaps minimal conflicts evaluation functions (Barbulescu et al., 2004a; Barbulescu,
Whitley, & Howe, 2004c); 62% neighbors RLS result evaluation
(see Section 6.4). AFSCN search space dominated plateaus three reasons.
592

fiUnderstanding Algorithm Performance

main reason presence plateaus greedy schedule builder: request
scheduled first available resource list possible alternatives. example,
consider permutation n1 total n requests. last request X inserted
first position permutation schedule builder applied, schedule
obtained. scan permutation n 1 requests left right, successively
inserting X second position, third on, building corresponding
schedule. long none requests appearing X permutation require
particular spot occupied X first feasible alternative scheduled,
schedule obtained. happens two reasons: 1) requests inserted
schedule order appear permutation 2) greedy
schedule builder considers possible alternatives order specified
accepts first alternative request scheduled. Let k + 1
first position insert X alter S; means first feasible alternative
schedule request position k overlaps spot occupied X S. X
inserted position k + 1, new schedule S1 obtained; schedule S1
built inserting X subsequent positions, encountering request first
feasible alternative overlaps spot occupied X S1, etc. example also
shows shifting permutation might change corresponding schedule.
address presence plateaus search space result greedy
schedule builder, could used randomization scheme diversify scheduler.
However, randomization implementing schedule builder result problems unpredictability value assigned permutation. example, Shaw
Fleming (1997) argue use randomization schedule builder detrimental performance genetic algorithm indirect representation used (for
chromosomes schedules, case Genitor AFSCN scheduling).
support idea noting general, genetic algorithms rely preservation
good fitness values. Also, SWO, randomization schedule builder changes
significance reprioritization one iteration next one. scheduler
randomized, new order requests likely result schedule
repaired version previous one. permutation requests
transformed multiple different schedules nondeterministic nature
scheduler, SWO mechanism operate intended.
second reason plateaus search space presence time windows.
request X needs scheduled sometime end day, even appears
beginning permutation, still occupy spot schedule towards
end (assuming scheduled) therefore, requests (which
appeared X permutation).
third reason discretization objective function. Clearly, range
conflicts small number discrete values (with weak upper bound number
tasks). range overlaps still discrete larger conflicts. Using
overlaps evaluation function, approximately 20 times unique objective function
values observed search compared searches objective minimize
conflicts. effect discretization seen differing results using two
objective functions. Thus, one reason including studies show
effects discretization.
593

fiBarbulescu, Howe, Whitley, & Roberts

6.2 Genitor Learn Patterns Request Ordering?
hypothesize Genitor performs well discovers interactions
requests matter. examine sets permutations correspond schedules
best known values identify chains common request orderings permutations,
similar spirit notion backbone SAT (e.g., Singer et al., 2000). presence
chains would support hypothesis Genitor discovering patterns request
orderings. classic building block hypothesis: pattern present
parent solutions contributes evaluation critical way; patterns
recombined inherited genetic recombination (Goldberg, 1989).
6.2.1 Common Request Orderings
One particular characteristics AFSCN scheduling problem presence
two categories requests. low altitude requests fixed start times specify
one three alternative resources. high altitude requests implicitly specify multiple
possible start times (because corresponding time windows usually longer
duration needs scheduled) 14 possible alternative resources. Clearly
low altitude requests constrained. suggests possible solution pattern,
low altitude requests would scheduled first.
explore viability pattern, implemented heuristic schedules
low altitude requests high altitude ones; call heuristic split
heuristic. incorporated split heuristic schedule builder: given permutation
requests, new schedule builder first schedules low altitude requests,
order appear permutation. Without modifying position low
altitude requests schedule, high altitude requests inserted schedule,
order appear permutation. idea scheduling low
altitude requests high altitude requests basis Gooleys heuristic (1993).
Also, split heuristic similar contention measures defined Frank et al. (2001).
results obtained using split heuristic surprising: minimizing
conflicts, best known valued schedules obtained quickly problems simply
sampling small number random permutations. results obtained sampling 100
random permutations shown Table 4.
performance split heuristic transfer R problems
minimizing number overlaps, results Table 4 offer indication possible
request ordering pattern good solutions. Genitor fact performing well
discovers scheduling low high altitude requests produces good solutions?
general explanation Genitors performance, hypothesize Genitor
discovering patterns request ordering: certain requests must come
requests. test this, identify common request orderings present solutions obtained
multiple runs Genitor. ran 1000 trials Genitor selected solutions
corresponding best known values. First, checked request orderings form
requestA requestB appear permutations corresponding best
known solutions problems corresponding good solutions R problems.
results summarized Table 5. Sol. Value columns show value
solutions chosen analysis (out 1000 solutions). number solutions (out
594

fiUnderstanding Algorithm Performance

Day
A1
A2
A3
A4
A5
A6
A7

Best
Known
8
4
3
2
4
6
6

Random Sampling-S
Min Mean Stdev
8
8.2
0.41
4
4
0
3
3.3
0.46
2
2.43
0.51
4
4.66
0.48
6
6.5
0.51
6
6
0

Table 4: Results running random sampling split heuristic (Random SamplingS) 30 experiments, generating 100 random permutations per experiment
minimizing conflicts.

1000) corresponding chosen value shown # Solutions columns.
analyzing common pairs request orderings minimizing number conflicts,
observed pairs specified low altitude request appearing high altitude
one. Therefore, separate pairs two categories: pairs specifying low altitude
request high altitude requests (column: (Low,High) Pair Count) rest
(column: Pairs). problems, results clearly show common
pairs ordering requests specify low altitude request high altitude request.
R problems, pairs observed. part, might due
small number solutions corresponding value (only 25 1000 R1
minimizing conflicts). small number solutions corresponding value also
reason big pair counts reported minimizing overlaps R problems.
know problems split heuristic results best-known solutions
minimizing conflicts; therefore, results Table 5 somewhat surprising. expected
see low-before-high common pairs requests problems minimizing
number conflicts; instead, pair counts similar two objective functions.
Genitor seems discover patterns request interaction, specify low
altitude request high altitude request.
results Table 5 heavily biased number solutions considered 9 . Indeed,
let denote number solutions identical value (the number column # Solutions).
Also, let n denote total number requests. Suppose preferences orderings
tasks good solutions. request ordering B probability
1/2 present one solutions, therefore, probability 1/2
present solutions. Given exist n (n 1) possible precedences,
expected number common orderings preferences orderings tasks
exist n(n 1)/2s . problems R5, >= 420. expected number
common orderings assuming preferences orderings tasks exist smaller
n(n 1)/2420 , negligible. Therefore, number actually detected common
9. wish thank anonymous reviewer earlier version work insightful observation;
rest paragraph based his/her comments.

595

fiBarbulescu, Howe, Whitley, & Roberts

Day
A1
A2
A3
A4
A5
A6
A7
R1
R2
R3
R4
R5

Sol.
Value
8
4
3
2
4
6
6
43
29
17
28
12

Minimizing Conflicts
#
(Low,High)
Solutions Pair Count
420
77
1000
29
936
86
937
132
862
45
967
101
1000
43
25
2166
573
64
470
78
974
54
892
57


Pairs
1
1
1
3
9
10
3
149
5
21
16
10

Sol.
Value
107
13
28
9
30
45
46
947
530
285
744
146

Minimizing Overlaps
#
(Low,High)
Solutions Pair Count
922
78
959
50
833
72
912
117
646
48
817
124
891
57
15
2815
30
1597
37
1185
31
1240
722
109


Pairs
7
3
10
5
17
10
11
1222
308
400
347
11

Table 5: Common pairs request orderings found permutations corresponding best
known/good Genitor solutions objective functions.

precedences (approximately 30 125 low high pairs anywhere 1
17 others) seem actual request patterns. also case
R problems. Indeed, example, R1, = 15, expected number common
orderings preferences orderings tasks exist 7.1, number
actually detected precedences 2815 low high 1222 pairs.
experiment found evidence support hypothesis Genitor solutions
exhibit patterns low high altitude requests. Given result, next investigate
split heuristic (always scheduling low high altitude requests) enhance
performance Genitor. answer question, run second experiment using Genitor,
split heuristic schedule builder used evaluate every schedule generated
search.
Table 6 shows results using split heuristic Genitor R problems.
Genitor split heuristic fails find best-known solution R2 R3.
surprising: fact, show scheduling low altitude requests
high altitude requests may prevent finding optimal solutions.
results minimizing sum overlaps shown Table 7. exception
A3, A4 A6, Genitor using split heuristic fails find best known solutions
problems. R problems, using split heuristic actually improves results
obtained Genitor R1 R2; noted R1 R2 solutions
good found RLS using 8000 evaluation however. Thus search
hybridizes genetic algorithm schedule builder using split heuristic sometimes
helps sometimes hurts terms finding good solutions.
attempted identify longer chains common request ordering. successful: Genitor seem discover patterns request ordering, multiple different
patterns request orderings result conflicts (or even schedule).
596

fiUnderstanding Algorithm Performance

Day
R1
R2
R3
R4
R5

Best
Known
42
29
17
28
12

Genitor New
Schedule Builder
Min Mean Stdev
42
42
0
30
30
0
18
18
0
28
28
0
12
12
0

Table 6: Minimizing conflicts: results running Genitor split heuristic 30 trials,
8000 evaluations per trial.

Day
A1
A2
A3
A4
A5
A6
A7
R1
R2
R3
R4
R5

Best
Known
104
13
28
9
30
45
46
774
486
250
725
146

Genitor New
Schedule Builder
Min Mean Stdev
119
119
0.0
43
43
0.0
28
28
0.0
9
9
0.0
50
50
0.0
45
45
0.0
69
69
0.0
907 924.33 6.01
513 516.63 5.03
276 276.03 0.18
752 752.03 0.0
146
146
0.0

Table 7: Minimizing sum overlaps: results running Genitor split heuristic
using split heuristic schedule builder evaluate schedule. results
based 30 experiments, 8000 evaluations per experiment.

could think patterns building blocks. Genitor identifies good building blocks
(orderings requests resulting good partial solutions) propagates final
population (and final solution). patterns essential building good solution.
However, patterns ubiquitous (not necessary) and, therefore,
attempts identify across different solutions produced Genitor failed.
597

fiBarbulescu, Howe, Whitley, & Roberts

Day
A1
A2
A3
A4
A5
A6
A7
R1
R2
R3
R4
R5

Minimizing Conflicts
Best Known Min Mean Stdev
8
8
8.0
0.0
4
4
4.0
0.0
3
3
3.16
0.46
2
2
2.13
0.34
4
4
4.03
0.18
6
6
6.23
0.63
6
6
6.0
0.0
42
42* 43.43
0.56
29
30
30.1
0.3
17
17* 17.73
0.44
28
28
28.53
0.57
12
12
13.1
0.4

Minimizing Overlaps
Best Known Min Mean Stdev
104
104 104.46
0.68
13
13
13.83
1.89
28
28
30.13
1.96
9
9
11.66
1.39
30
30
30.33
0.54
45
45
48.3
6.63
46
46
46.26
0.45
774
851 889.96 31.34
486
503
522.2
9.8
250
268
276.4
4.19
725
738 758.26 12.27
146
147 151.03
2.19

Table 8: Statistics results obtained 30 runs SWO initialized random
permutations (i.e., RandomStartSWO), 8000 evaluations per run. mean
best value 30 runs well standard deviations shown.
entries indicate values better corresponding SWO values.
problem, best known solution objective function also
included.

6.3 SWOs Performance Due Initialization?
graphs search progress SWO (Figures 2 3) show starts much
better solutions algorithms. initial greedy solution SWO translated best known values five problems (A2, A3, A5, A6 R5) minimizing
number conflicts two problems (A6 R5) minimizing overlaps.
important initial greedy permutation SWO? answer question,
replaced initial greedy permutation (and variations subsequent iterations SWO)
random permutations used SWO mechanism iteratively move forward
requests conflict. call version SWO RandomStartSWO. compared
results produced RandomStartSWO results SWO assess effects
initial greedy solution. results produced RandomStartSWO presented Table 8.
entries indicate RandomStartSWO produced better result SWO.
exception R2, minimizing number conflicts, best known values
obtained RandomStartSWO problems. fact, R1 R3, best results
obtained slightly better best found SWO. minimizing sum
overlaps, best known values obtained problems; R problems,
performance SWO worsens initialized random permutation. However,
RandomStartSWO still performs better well Genitor (with exception R2
minimizing number conflicts R5 overlaps) objective functions.
results suggest initial greedy permutation main performance factor
SWO: performance RandomStartSWO competitive Genitor.
598

fiUnderstanding Algorithm Performance

Day
A1
A2
A3
A4
A5
A6
A7
R1
R2
R3
R4
R5

Total
Neighbors
103041
90601
96100
100489
92416
88804
87616
232324
207936
180625
184900
174724

Minimizing
Random Perms
Mean
Avg %
87581.1
84.9
79189.3
87.4
82937
86.8
84759
84.3
77952
84.3
74671.5
84.0
76489.6
87.3
189566
81.5
173434
83.4
153207
84.8
157459
85.1
154347
88.3

Conflicts
Optimal Perms
Mean
Avg %
91609.1
88.9
83717.9
92.4
84915.4
88.9
87568.2
87.1
82057.4
88.7
78730.3
88.6
79756.5
91.0
190736
82.0
177264
85.2
156413
86.5
162996
88.1
159581
91.3

Minimizing
Random Perms
Mean
Avg %
75877.4
73.6
70440.9
77.7
73073.3
76.5
72767.7
72.4
67649.3
73.2
63667.4
71.6
67839
77.4
145514
62.6
137568
66.1
126511
70.0
130684
70.6
133672
76.5

Overlaps
Optimal Perms
Mean
Avg %
88621.2
86.0
81141.9
89.5
82407.7
86.3
85290
84.8
79735.9
86.2
75737.9
85.2
77584.3
88.5
160489
69.0
160350
77.1
139012
76.9
145953
78.9
152629
87.3

Table 9: Statistics number neighbors resulting schedules value
original, 30 random optimal permutations, objective
functions

6.4 RLS Performing Random Walk?
RLS spends time traversing plateaus search space (by accepting nonimproving moves). section, study average length random walks
plateaus encountered local search. show search progresses random walks
become longer finding improvement, mirroring progress RLS. note
similar phenomenon observed SAT (Frank, Cheeseman, & Stutz, 1997).
third shifting pairs requests result schedules identical
current solution (Barbulescu et al., 2004a, 2004c). However, even larger number
neighbors result different schedules value current solution.
means accepted moves search non-improving moves; search ends
randomly walking plateau exit found. collected results
number schedules value original schedule, perturbing solutions possible pairwise changes. Note schedules include ones identical
current solution. results summarized Table 9. report average
percentage neighbors identical value original permutation. results show
that: 1) 84% shifts result schedules value original one, minimizing conflicts. minimizing overlaps, 62% (usually
around 70%) shifts result value schedules. 2) Best known solutions
slightly same-value neighbors random permutations; difference statistically significant minimizing overlaps. suggests plateaus corresponding
good values search space might larger size plateaus corresponding
random permutations.
assess size plateaus impact RLS, performed random walks
fixed intervals RLS. every 500 evaluations RLS, identified current
599

fiBarbulescu, Howe, Whitley, & Roberts

solution Crt. Crt, performed 100 iterations local search starting
Crt stopping soon better solution maximum number equally good
solutions encountered. problems, best known solutions often found early
search; 100 iterations local search started Crt would reach
maximum number equally good solutions. Therefore, chose limit 1000 steps
plateau problems 8000 steps R problems. averaged
number equally good solutions encountered 100 trials search performed
Crt; represents average number steps needed find exit plateau.
Figure 4 displays results obtained R4; similar behavior observed rest
problems. Note used log scale axis graph corresponding
minimizing overlaps: 100 walks performed current solution value 729
end taking maximum number steps allowed (8000) without finding exit
plateau. Also, random walk steps counts equal moves; number evaluations
needed RLS (x-axis) considerably higher due needing check detrimental moves
accepting equal ones. results show large plateaus present search
space; improving moves lead longer walks lower plateaus, detrimental
moves factored in, appears mirror performance RLS.
1800

10000

LS

729

729

LS
729 729

1600
29

29

1200
30

29

1000
800

30

30

600
32

31

29

1000
Average number steps plateau

Average number steps plateau

1400

29

30

30

30

782

814
100

794

786

786

777

751

740

864
1068

944

10

400

1450
200
0

33
63
0

45
1000

2000

3000

4000
Evals

5000

6000

7000

8000

1

0

1000

2000

3000

4000
Evals

5000

6000

7000

8000

Figure 4: Average length random walk plateaus minimizing conflicts (left)
overlaps (right) single local search run R4. labels graphs
represent value current solution. Note log scale axis
graph corresponding minimizing overlaps. best known value
problem 28 minimizing conflicts 725 minimizing overlaps.

AFSCN scheduling problems, states plateau least one
neighbor better value (this neighbor represents exit). However, number
exits small percentage total number neighbors, therefore, local
search small probability finding exit. Using terminology introduced
Frank et al. (1997), plateaus encountered search AFSCN domain
would classified benches, meaning exits states lower levels present.
exits plateau, plateau local minimum. Determining
plateaus local minima (by enumerating states plateau neighbors)
600

fiUnderstanding Algorithm Performance

prohibitive large size neighborhoods large number equally
good neighbors present state search space. Instead, focus average
length random walk plateau factor local search performance. length
random walk plateau depends two features: size plateau
number exits plateau. Preliminary investigations show number
improving neighbors solution decreases solution becomes better - therefore
conjecture exits higher level plateaus lower level
ones. would account trend needing steps find exit moving
lower plateaus (corresponding better solutions). also possible plateaus
corresponding better solutions larger size; however, enumerating states
plateau AFSCN domain impractical (following technique developed Frank
et al., 1997, first iteration breadth first search would result approximately
0.8 (n 1)2 states plateau).
6.5 Long Leaps Instrumental?
problems large plateaus (e.g., research published Gent Walsh,
1995 SAT), hypothesize long leaps search space instrumental
algorithm perform well AFSCN scheduling. SWO moving forward multiple requests
known problematic. position crossover mechanism Genitor
viewed applying multiple consecutive shifts first parent, requests
selected positions second parent moved selected positions
first. sense, time crossover operator applied, multiple move proposed
first parent. hypothesize multiple move mechanism present SWO
Genitor allows make long leaps space thus reach solutions fast.
Note knew exactly requests move, moving forward small
number requests (or even one) might needed reach solutions
quickly. Finding requests move difficult; fact studied performance
informed move operator moves requests positions guarantee
schedule changes (Roberts et al., 2005). found surprising results: informed
move operator performs worse random unrestricted shift employed RLS.
argue multiple moves desired algorithm feature make likely
one moves right one.
investigate hypothesis role multiple moves traversing
search space, perform experiments variable number moves step
Genitor SWO. Genitor, vary number crossover positions allowed.
SWO, vary number requests conflict moved forward.
6.5.1 Effect Multiple Moves Genitor
test effect multiple moves Genitor, change Syswerdas position crossover
imposing fixed number selected positions second parent (see Section 4.4
description Syswerdas position crossover). call implementation Genitor-k
k number selected positions. Recall implementation Syswerdas position
crossover randomly selects number positions larger one third smaller
two thirds total number positions. multiple moves indeed factor
601

fiBarbulescu, Howe, Whitley, & Roberts

Average Best Far Sum Overlaps

2000

Genitor
Genitor-10
Genitor-50
Genitor-100
Genitor-150
Genitor-300
Genitor-350

1900
1800
1700
1600
1500
1400
1300
1200

0

500

1000

1500 2000 2500
Evaluations

Average Best Far Sum Overlaps

1600

3000

3500

4000

Genitor
Genitor-10
Genitor-50
Genitor-100
Genitor-150
Genitor-300
Genitor-350

1500
1400
1300
1200
1100
1000
900
4000

4500

5000

5500 6000 6500
Evaluations

7000

7500

8000

Figure 5: Evolutions average best value obtained Genitor versions
fixed number selected positions crossover. 8000 evaluations, 30
runs. graphs obtained R1; best solution value 773.

performance increasing number selected positions point result
finding improvements faster. positions selected, offspring
similar first parent. number selected positions large, close number
total requests, offspring similar second parent. offspring
similar one two parents, expect slower rate finding improvements
current best solution. Therefore, small large k values, expect Genitor-k
602

fiUnderstanding Algorithm Performance

Day
A1
A2
A3
A4
A5
A6
A7
R1
R2
R3
R4
R5

Min
11
5
6
5
5
9
8
57
42
27
36
13

Genitor-10
Mean Stdev
14.93
1.94
7.13
1.77
10.4
2.12
10.66
2.7
9.6
2.29
12.63
1.8
10.6
1.75
66.5
4.38
47.16
3.59
31.1
2.41
41.9
2.74
20.73
2.53

Min
8
4
3
2
4
6
6
47
32
19
28
12

Genitor-50
Mean Stdev
9.26
0.63
4.03
0.18
3.36
0.55
3.13
0.81
4.73
0.69
6.83
0.94
6.1
0.30
52.0
2.82
34.53
1.47
21.6
1.67
30.96
2.04
13.23
0.81

Min
8
4
3
2
4
6
6
42
29
17
28
12

Genitor-100
Mean Stdev
8.66
0.47
4.0
0.0
3.0
0.0
2.23
0.50
4.26
0.44
6.03
0.18
6.0
0.0
45.83
1.68
30.0
0.78
18.03
0.61
28.33
0.47
12.46
0.62

Genitor-150
Min Mean Stdev
8
8.53
0.5
4
4.0
0.0
3
3.0
0.0
2
2.06
0.25
4
4.2
0.4
6
6.06
0.25
6
6.0
0.0
42
44.36
1.24
29
29.6
0.56
17
17.63
0.61
28
28.1
0.4
12
12.2
0.4

Table 10: Performance Genitor-k, k represents fixed number selected positions Syswerdas position crossover, terms best mean number
conflicts. Statistics taken 30 independent runs, 8000 evaluations
per run. Min numbers boldface indicate best known values.

find improvements much slower rate Genitor Genitor-k average k values
(values closer half number requests).
study, run Genitor-k k=10, 50, 100, 150, 200, 250, 300 350.
allowed 8000 evaluations per run performed 30 runs problem. results
summarized Tables 10 11 minimizing number conflicts Tables 12
13 minimizing sum overlaps. Note A6 A7 299 297
requests schedule respectively. Therefore Genitor-k k = 300 k = 350 cannot
run two problems. Also note example, k = 200 mean
200 differences selected positions two parents. offspring likely
similar parents, regardless value k, parents similar.
minimizing number conflicts, worst results produced k = 10.
k = 50, results improve, best knowns found problems; however, R1,
R2, R3, best knowns found. Starting k = 100 k = 250 Genitor-k
finds best known solutions problems. means standard deviations also
similar k values; smallest means standard deviations correspond
k = 200 problems k = 250 R problems (with exception R3
k = 200 produces better results). k = 300, best knowns found
anymore problems; 300 close size five problems
feasible run Genitor-300. decay performance significant R
problems: increase means standard deviations k = 300 k = 350;
however, best knowns still found four five problems. Note k = 400
would lot closer total number requests R problems; believe
performance would degraded R problems larger k values.
minimizing overlaps, observe trends similar ones minimizing
number conflicts. k = 10 produces poor results, followed k = 50. Similar results
603

fiBarbulescu, Howe, Whitley, & Roberts

Day
A1
A2
A3
A4
A5
A6
A7
R1
R2
R3
R4
R5

Min
8
4
3
2
4
6
6
42
29
17
28
12

Genitor-200
Mean Stdev
8.56
0.56
4.0
0.0
3.0
0.0
2.0
0.0
4.3
0.46
6.06
0.25
6.0
0.0
44.03
1.15
29.36
0.49
17.33
0.4
28.03
0.18
12.1
0.3

Min
8
4
3
2
4
6
6
42
29
17
28
12

Genitor-250
Mean Stdev
8.9
0.3
4.03
0.18
3.06
0.25
3.13
0.81
4.73
0.58
6.5
0.57
6.06
0.25
44.03
0.85
29.4
0.49
17.7
0.65
28
0.0
12.06
0.25

Min
9
9
4
4
10
43
29
17
28
12

Genitor-300
Mean Stdev
11.8
1.66
13.66
1.76
9.2
2.1
8.56
1.94
13.86
2.14
44.26
1.01
29.7
0.59
17.73
0.58
28.03
0.18
12.16
0.37

Genitor-350
Min Mean Stdev
43
45.46
1.22
29
30.13
0.86
17
18.63
0.8
28
28.63
0.71
12
12.6
0.81

Table 11: Performance Genitor-k, k represents fixed number selected positions Syswerdas position crossover, terms best mean number
conflicts. Statistics collected 30 independent runs, 8000 evaluations per run. Min numbers boldface indicate best known values.
dashes indicate permutation solutions A6 A7 shorter
300 (299 297, respectively), therefore cannot select 300 positions
permutations.

Day
A1
A2
A3
A4
A5
A6
A7
R1
R2
R3
R4
R5

Min
149
30
51
59
43
94
67
1321
743
480
866
208

Genitor-10
Mean Stdev
221.53
38.85
69.66
29.22
122.86
36.12
124.5
42.25
90.7
32.01
145.06
33.12
115.66
27.96
1531.13 107.35
961.13
81.62
652.5
90.37
1069.23
74.65
309.03
46.3

Min
107
13
28
9
30
45
46
987
557
319
768
146

Genitor-50
Mean Stdev
115.76 11.53
15.73
3.86
36.26
8.19
19.36
9.3
33.06
3.62
49.6
5.54
51.7
7.89
1139.5 76.57
643.86
50.0
391.56 47.31
840.23 38.79
172.13 18.18

Min
107
13
28
9
30
45
46
914
515
268
735
146

Genitor-100
Mean Stdev
107.2
0.76
13.43
1.54
28.9
1.72
9.23
0.72
30.36
0.96
45.36
0.8
46.5
2.23
991.13 38.19
549.1
18.8
305.3 20.63
757.43 15.95
151.53
7.63

Min
107
13
28
9
30
45
46
915
516
269
731
146

Genitor-150
Mean Stdev
107.1
0.54
13.03
0.18
28.16
0.64
9.06
0.36
30.43
0.5
45.16
0.46
47.63
3.9
963.96 26.89
540.86 15.82
291.3 13.36
752.7 14.07
148.23
5.26

Table 12: Performance Genitor-k, k represents fixed number selected positions Syswerdas position crossover, terms best mean sum
overlaps. Statistics collected 30 independent runs, 8000 evaluations
per run. Min numbers boldface indicate best known values.

produced k = 100, 150, 200, 250. k = 150 results smallest means standard
deviations problems, k = 200 k = 250 produce best results R
problems. k = 300 k = 350, similarly minimizing number conflicts,
604

fiUnderstanding Algorithm Performance

Day
A1
A2
A3
A4
A5
A6
A7
R1
R2
R3
R4
R5

Min
107
13
28
9
30
45
46
878
512
268
730
146

Genitor-200
Mean Stdev
107.1
0.74
13.2
0.92
28.9
1.6
9.1
0.4
30.6
1.3
46.33
2.7
47.63
4.2
970.1 38.38
538.43 13.94
287.96 11.05
752.1 12.25
147.633
2.95

Min
107
13
28
9
30
45
46
914
511
270
734
146

Genitor-250
Mean Stdev
108.03
2.22
17.0
5.8
31.63
4.47
10.36
3.41
31.56
2.22
50.96
8.82
49.93
5.39
968.63 31.59
538.93 12.88
292.23 12.85
754.53 11.89
147.96
3.7

Min
113
116
63
37
76
935
526
272
745
146

Genitor-300
Mean Stdev
157.66 26.21
185.56 33.27
106.23 26.21
78.06 25.78
160.0 36.59
986.7
37.9
551.63 12.27
299.43
16.3
764 13.36
148.6
3.84

Min
927
532
299
743
146

Genitor-350
Mean Stdev
1008.8 42.17
559.46
19.7
332.46 20.14
785.36 26.63
157
10.6

Table 13: Performance Genitor-k, k represents fixed number selected positions Syswerdas position crossover, terms best mean sum
overlaps. Statistics taken 30 independent runs, 8000 evaluations
per run. Min numbers boldface indicate best known values.

means standard deviations increase best solutions found; best knowns
found R5.
terms evolution solution, observe similar trends two
objective functions. typical examples presented Figure 5 (minimizing overlaps
R1). Genitor-k k = 10 slower finding improvements k = 50 slower
k = 100. k = 150 k = 250 performing similarly also similar
original Genitor implementation. k = 300 still moving space rate thats
similar Genitors. k = 350 performance start decay.
original implementation crossover operator (with variable number selected position) shown work well domain also scheduling
applications (Syswerda, 1991; Watson, Rana, Whitley, & Howe, 1999; Syswerda & Palmucci, 1991). test problems, results subsection show number
crossover positions influences performance Genitor, terms best solutions
found terms rate finding improvements. small number crossover
positions (10 50), solutions found competitive, improvements
found slower rate original Genitor implementation. Similarity Genitors
original performance obtained k values 100 250. Higher k values result
decay performance. results also offer empirical motivation choice
number crossover positions original Genitor implementation. Indeed,
original implementation, crossover uses number positions randomly selected
one third two thirds total number requests. translates
sizes problems sets number positions approximately 100
300.
605

fiBarbulescu, Howe, Whitley, & Roberts

Day
A1
A2
A3
A4
A5
A6
A7
R1
R2
R3
R4
R5

Minimizing Conflicts
Min Mean Stdev
8
8
0
4
4
0
3
3
0
2
2
0
4
4
0
6
6
0
6
6
0
42* 43.4
0.7
29 29.9
0.3
18 18
0
28 28.1
0.3
12 12
0

Minimizing Overlaps
Min Mean Stdev
104 104
0
13 13
0
28 28
0
9
9
0
30 30
0
45 45
0
46 46
0
872 926.7 22.1
506 522.9 8.9
271 283.0 6.1
745 765.2 10.7
146 146
0

Table 14: Performance modified version SWO one request moved
forward constant distance 5. minimizing conflicts minimizing
sum overlaps, request randomly chosen. statistics collected
30 independent runs, 8000 evaluations per run. indicates
best value better corresponding SWO result. Min numbers boldface
indicate best known values.

6.5.2 Effect Multiple Moves SWO
hypothesize multiple moves present SWO necessary performance.
test hypothesis, start investigating effect moving forward one
request. somewhat similar shifting operator present RLS: request shifted
forward permutation. However, implement SWO reprioritization mechanism,
restrict chosen request moved position gets moved.
minimizing conflicts, one bumped requests randomly chosen; minimizing
overlaps, one requests contributing sum overlaps randomly chosen.
minimizing conflicts minimizing sum overlaps chosen request
moved forward constant distance five 10 . call new algorithm SWO1Move.
results obtained running SWO1Move 30 runs 8000 evaluations per run
presented Table 14. entries indicate value produced SWO1Move
better corresponding SWO result. initial solutions identical
solutions produced using flexibility heuristic initializing SWO.
minimizing conflicts, SWO1Move performs well SWO (in fact, finds
best known solution R1 well). minimizing sum overlaps, performance
SWO R problems worsens significantly one task moved forward. Previously, implemented SWO1Move minimizing overlaps moving forward request
contributes total overlap (Barbulescu et al., 2004c). Randomly choosing
10. tried values; average, value five seems work best.

606

fiUnderstanding Algorithm Performance

Day
R1
R2
R3
R4

Min
840
512
284
764

k=10
Mean
862.5
530.2
291.36
778.57

Stdev
11.28
9.18
4.65
8.45

Min
815
498
266
749

k=20
Mean
829.77
506.53
268.9
757.3

Stdev
8.45
5.25
2.21
6.16

Min
798
493
266
740

k=30
Mean
820.63
508.97
271.07
744.47

Stdev
8.12
5.26
3.52
2.6

Min
825
508
266
737

k=40
Mean
841.13
526.26
273.2
747.2

Stdev
8.02
6.25
3.54
5.06

Table 15: Performance modified version SWO k requests contributing
sum overlaps moved forward constant distance 5. statistics
collected 30 independent runs, 8000 evaluations per run.

request moved forward improved performance SWO1Move. Randomization
useful SWO become trapped cycles (Joslin & Clements, 1999); however,
improvement enough equal performance SWO minimizing overlaps
new days data. fact, longer runs SWO1Move random choice
request moved (30 runs 50,000 evaluations) produce solutions still worse
obtained SWO. results support conjecture performance
SWO due simultaneous moves requests.
attribute discrepancy SWO1Move performance two objective
functions difference discretization two search spaces. minimizing
conflicts, SWO1Move needs identify requests cannot scheduled.
fine tuning needed minimizing sum overlaps; besides identifying requests
cannot scheduled, SWO1Move also needs find positions requests
permutation sum overlaps minimized. conjecture fine
tuning achieved simultaneously moving forward multiple requests.
Next, investigate changes performance increasing number requests
(from requests contributing objective function) moved forward. design
experiment constant number requests involved conflicts moved
forward. this, need decide many requests move ones. Moving
two three requests forward results small improvements results Table 14.
Therefore, run multiple versions SWO moving k requests forward, k = 10, 20,
30, 40. determined empirically moving multiple requests (more five)
forward, choosing random opposed based contribution sum
overlaps hurts algorithm performance. determine requests moved forward,
step sort requests contributing sum overlaps decreasing order
contribution move forward first k (or them, k greater
number requests contributing sum overlaps).
results obtained R1, R2, R3 R4 summarized Table 15.
problems, new SWO versions find best known solutions. include R5
study SWO greedy initial permutation computed R5 corresponds
best known value schedule. results show general performance improvement k
grows 10 20. k = 20 k = 30 produce similar performance R1, R2 R3.
R4, k = 30 results better performance k = 20. k = 40 results worsening
performance R1 R2. Note algorithm performance R3 change
607

fiBarbulescu, Howe, Whitley, & Roberts

k >= 20. surprising; since good solutions (in terms overlaps)
problem correspond schedules small number overlapping tasks, moving forward
20 requests means moving requests conflict good solutions
found. results indicate problems set, minimizing overlaps,
SWO allowed move forward constant number k requests, k = 30 seems
good choice.
results section support hypothesis moving multiple requests forward
necessary obtain good SWO performance. First, showed moving one
request forward (or small number requests, smaller 30 R problems) results
inferior SWO performance. Second, number requests moved forward increased
(from 10 up), performance SWO improves.

7. New Algorithm: Attenuated Leap Local Search
empirical data analyses suggest key competitive performance
application moving quickly possible across plateaus. Two competitive
algorithms, Genitor SWO, perform multiple moves. simpler algorithm, RLS, actually
finds best known solutions 8000 evaluations, even though perform multiple moves. RLS however, perform significant number neutral moves
solutions evaluation. Given this, conjecture version local search
performs multiple moves evaluating result may even better suited
application. intuition behind conjecture search sample greater
distances (i.e., longer single move) quickly find exits plateaus.
modified RLS move operator follows: choose number pairs positions
apply shifting pairs, one another, without building schedule
shift; build schedule shifting applied designated number
pairs. first version, tried static number shifts (10 turned
best value); however, performed better sometimes worse original move
operator. next conjectured search progresses better solutions, number
shifts also decrease probability finding detrimental moves (rather
improving) increases significantly well. better solution, fewer exits
expected harder find.
implemented multiple move hill-climber variable move count operator: given
decay rate, start shifting ten requests, nine, eight etc. chose decrement
number shifts every 800 evaluations; call version hill-climbing Attenuated
Leap Local Search (ALLS). similar idea behind temperature dependent
hill-climbing move operator implemented Globus et al. (2004), number
requests move chosen random biased large number requests
moved early search later requests moved 11 . Hill-climbing
temperature dependent operator produced better results EOS simply choosing
random number requests move.
ALLS performs remarkably well. shown Table 16, finds best known values
problems using conflicts two problems using overlaps (as
11. operator similar temperature dependent behavior simulated annealing; explains
name operator.

608

fiUnderstanding Algorithm Performance

Average Best Far Number Bumps

70

Genitor
RLS
SWO
ALLS

65
60
55
50
45
40
35
30
25

0

500

1000

1500
2000
2500
Evaluations

Average Best Far Number Bumps

32

3000

3500

4000

Genitor
RLS
SWO
ALLS

31.5
31
30.5
30
29.5
29
28.5
28
4000

4500

5000

5500 6000 6500
Evaluations

7000

7500

8000

Figure 6: Evolutions average best value obtained Genitor, RLS, SWO ALLS
8000 evaluations, 30 runs. improvement first 4000
evaluations shown top figure. last 4000 evaluations depicted
bottom figure; note scale different y-axis. graphs
obtained R4; best solution value 28.
RLS). Additionally, finds better best values algorithms set
two problems non-best solutions. fact, single tailed, two sample t-test comparing
ALLS RLS shows ALLS finds statistically significantly better solutions (p < 0.023)
conflicts overlaps five recent days.
609

fiBarbulescu, Howe, Whitley, & Roberts

Average Best Far Number Overlaps

1700

Genitor
RLS
SWO
ALLS

1600
1500
1400
1300
1200
1100
1000
900
800
700

0

500

1000

1500 2000 2500
Evaluations

Average Best Far Number Overlaps

900

3000

3500

4000

Genitor
RLS
SWO
ALLS

880
860
840
820
800
780
760
740
720
4000

4500

5000

5500 6000 6500
Evaluations

7000

7500

8000

Figure 7: Evolutions average best value obtained Genitor, RLS, SWO ALLS
8000 evaluations, 30 runs. improvement first 4000
evaluations shown top figure. last 4000 evaluations depicted
bottom figure; note scale different y-axis.The graphs
obtained R4; best solution value 725.
Section 5, discussed comparison across algorithms (again p < 0.005).
much restrictive performance comparison, ALLS still outperforms RLS,
SWO Genitor pair-wise tests. minimizing conflicts
minimizing overlaps, ALLS significantly outperforms algorithms R1.
610

fiUnderstanding Algorithm Performance

Day
A1
A2
A3
A4
A5
A6
A7
R1
R2
R3
R4
R5

Minimizing Conflicts
Min Mean Stdev
8
8.2
0.4
4
4.0
0.0
3
3.0
0.0
2
2.03
0.18
4
4.1
0.3
6
6.0
0.0
6
6.0
0.0
42 42.63
0.72
29
29.1
0.3
17
17.5
0.57
28 28.07
0.25
12
12.0
0.0

Minimizing Overlaps
Min Mean Stdev
104 107.1
1.24
13
13.0
0.0
28
28.33
1.3
9
9.13
0.73
30
30.23
0.43
45
45.0
0.0
46
46.0
0.0
785 817.83 27.07
490 510.37 19.14
250 273.33 43.68
725 740.07 19.56
146 146.03 0.19

Table 16: Statistics results obtained 30 runs ALLS, 8,000 evaluations per
run. best mean values well standard deviations shown.
Bold indicates best known values.

minimizing conflicts, ALLS outperforms five twelve pair-wise tests
four days (for difference significant). exceptions are: R2, R3,
R4, R5 Genitor R4 RLS. minimizing overlaps, ALLS significantly
outperforms Genitor R2, RLS R3, Genitor R4 SWO R5; rest
pair-wise comparisons statistically significant p < 0.005. clear ALLS
least good best algorithms outperforms days data.
ALLS also finds improving solutions faster Genitor RLS (see Figures 6
7 R4 conflicts overlaps). ALLS achieves good performance
combining power finding good solutions fast using multiple moves beginning
search accuracy locating best solutions using one-move shifting
end search.
6.4 showed solutions improve random walks plateaus become
longer. Two hypotheses support observation: 1) plateaus bigger 2) plateaus
harder escape fewer exits. two hypotheses consistent
missing exits replaced moves equal value. consistent exits
replaced worse moves. ALLS design implicitly assumes latter. exits
replaced equal moves search progresses moves would needed
per large step12 . fact, ran tests increased number moves
search progresses found significantly worsen performance.
example, R1 minimizing overlaps, shifting initially ten requests increasing
number shifted requests 1 every 800 iterations (instead decreasing ALLS)
12. wish thank anonymous reviewer insightful observation.

611

fiBarbulescu, Howe, Whitley, & Roberts

results minimum overlap 885, mean 957.97 standard deviation
51.36, significantly worse corresponding ALLS result.

8. Conclusion
key algorithm characteristic AFSCN appears multiple moves. fact,
observation might hold oversubscribed scheduling problems well. Globus et
al. (Globus et al., 2004) found solving oversubscribed problem scheduling
fleets EOS using hill-climbing, moving one request time inefficient.
temperature dependent hill-climbing operator proved work better simply choosing
random number requests move. domain, permutation representation
greedy deterministic schedule builder used. conjecture schedule builder
also results multiple permutations mapped schedule, therefore
plateaus present EOS search space well. fact moving
one request improved results suggests conjecture could also hold EOS
scheduling: multiple moves might speed plateau traversal domain well.
developed tested four hypotheses explaining performance three competitive algorithms real scheduling application. found hypotheses held
varying degrees. Based evidence, designed new algorithm combined
appeared critical elements best performing algorithms produced
algorithm performed better original ones. results suggest multiple moves useful algorithm feature obtain good performance results AFSCN
scheduling. Alternatively, possible fact one move iteration
would enough obtain good performance, difficult identify request
move. Future research direction examine heuristics combining HBSS
SWO decide request move forward, well heuristics find move
request guarantee change schedule. Also future research, testing
oversubscribed scheduling applications determine extent analyses
results generalize: exhibit characteristics amenable
kind solution?

Acknowledgments

research supported part grant Air Force Office Scientific Research, Air Force Materiel Command, USAF grant number F49620-03-1-0233. Adele
Howe also supported National Science Foundation Grant No. IIS-0138690.
opinions, findings, conclusions recommendations expressed material
author(s) necessarily reflect views National Science
Foundation. U.S. Government authorized reproduce distribute reprints
Governmental purposes notwithstanding copyright notation thereon.
612

fiUnderstanding Algorithm Performance

References
Ackley, D. (1987). Connectionist Machine Genetic Hillclimbing. Kluwer Academic
Publishers.
Aickelin, U., & Dowsland, K. (2003). indirect genetic algorithm nurse scheduling
problem. Computers & Operations Research, 31 (5), 761778.
Barbulescu, L., Howe, A., Whitley, L., & Roberts, M. (2004a). Trading places:
schedule multi-resource oversubscribed scheduling problem. Proceedings
International Conference Planning Scheduling, Whistler, CA.
Barbulescu, L., Watson, J., Whitley, D., & Howe, A. (2004b). Scheduling Space-Ground
Communications Air Force Satellite Control Network. Journal Scheduling,
7, 734.
Barbulescu, L., Whitley, L., & Howe, A. (2004c). Leap look: effective strategy
oversubscribed problem. Proceedings Nineteenth National Artificial
Intelligence Conference, San Jose, CA.
Beck, J., Davenport, A., Davis, E., & Fox, M. (1998). ODO Project: Toward Unified
Basis Constraint-directed Scheduling. Journal Scheduling, 1, 89125.
Bresina, J. (1996). Heuristic-Biased Stochastic Sampling. Proceedings Thirteenth
National Conference Artificial Intelligence, pp. 271278, Portland, OR.
Burrowbridge, S. E. (1999). Optimal Allocation Satellite Network Resources. Masters
Thesis. Virginia Polytechnic Institute State University.
Chien, S., Rabideau, G., Knight, R., Sherwood, R., Engelhardt, B., Mutz, D., Estlin, T.,
Smith, B., Fisher, F., Barrett, T., Stebbins, G., & Tran, D. (2000). ASPEN - Automating space mission operations using automated planning scheduling. 6th
International SpaceOps Symposium (Space Operations), Toulouse (France).
Cormen, T., Leiserson, C., & Rivest, R. (1990). Introduction Algorithms. MIT press,
Cambridge, MA.
Deale, M., Yvanovich, M., Schnitzuius, D., Kautz, D., Carpenter, M., Zweben, M., Davis,
G., & Daun, B. (1994). Space Shuttle ground processing scheduling system.
Zweben, M., & Fox, M. (Eds.), Intelligent Scheduling, pp. 423449. Morgan Kaufmann.
Forrest, S., & Mitchell, M. (1993). Relative Building-Block Fitness Building Block
Hypothesis. Whitley, L. D. (Ed.), Foundations Genetic Algorithms 2, pp. 109
126. Morgan Kaufmann.
Frank, J., Cheeseman, P., & Stutz, J. (1997). gravity fails: Local search topology.
Journal Artificial Intelligence Research, 7, 249281.
Frank, J., Jonsson, A., Morris, R., & Smith, D. (2001). Planning scheduling fleets
earth observing satellites. Proceedings Sixth International Symposium
Artificial Intelligence, Robotics, Automation Space.
Gent, I., & Walsh, T. (1995). Unsatisfied variables local search. Hybrid Problems,
Hybrid Solutions, pp. 7385. IOS Press Amsterdam.
613

fiBarbulescu, Howe, Whitley, & Roberts

Globus, A., Crawford, J., Lohn, J., & Pryor, A. (2003). Scheduling earth observing satellites
evolutionary agorithms. International Conference Space Mission Challenges Information Technology, Pasadena, CA.
Globus, A., Crawford, J., Lohn, J., & Pryor, A. (2004). comparison techniques
scheduling earth observing satellites. Proceedings Sixteenth Innovative Applications Artificial Intelligence Conference, San Jose, CA.
Goldberg, D. (1989). Genetic Algorithms Search, Optimization Machine Learning.
Addison-Wesley, Reading, MA.
Gooley, T. (1993). Automating Satellite Range Scheduling Process. Masters Thesis.
Air Force Institute Technology.
Jang, K. (1996). Capacity Air Force Satellite Control Network. Masters
Thesis. Air Force Institute Technology.
Johnston, M., & Miller, G. (1994). Spike: Intelligent scheduling Hubble space telescope
observations. Morgan, M. B. (Ed.), Intelligent Scheduling, pp. 391422. Morgan
Kaufmann Publishers.
Joslin, D. E., & Clements, D. P. (1999). Squeaky Wheel Optimization. Journal
Artificial Intelligence Research, Vol. 10, pp. 353373.
Kramer, L., & Smith, S. (2003). Maximizing flexibility: retraction heuristic oversubscribed scheduling problems. Proceedings 18th International Joint Conference
Artificial Intelligence, Acapulco, Mexico.
Lematre, M., Verfaillie, G., & Jouhaud, F. (2000). manage new generation
Agile Earth Observation Satellites. 6th International SpaceOps Symposium (Space
Operations), Toulouse, France.
Parish, D. (1994). Genetic Algorithm Approach Automating Satellite Range Scheduling. Masters Thesis. Air Force Institute Technology.
Pemberton, J. (2000). Toward Scheduling Over-Constrained Remote-Sensing Satellites.
Proceedings Second NASA International Workshop Planning Scheduling
Space, San Francisco, CA.
Rabideau, G., Chien, S., Willis, J., & Mann, T. (1999). Using iterative repair automate
planning scheduling shuttle payload operations. Innovative Applications
Artificial Intelligence (IAAI 99), Orlando,FL.
ROADEF Challenge (2003).
French Society Operations Research Decision Analisys ROADEF Challenge 2003.
http://www.prism.uvsq.fr/
vdc/ROADEF/CHALLENGES/2003/.
Roberts, M., Whitley, L., Howe, A., & Barbulescu, L. (2005). Random walks neighborhood bias oversubscribed scheduling. Multidisciplinary International Conference
Scheduling (MISTA-05), New York, NY.
Schalck, S. (1993). Automating Satellite Range Scheduling. Masters Thesis. Air Force
Institute Technology.
614

fiUnderstanding Algorithm Performance

Shaw, K., & Fleming, P. (1997). Use rules preferences schedule builders
genetic algorithms production scheduling. Proceedings AISB97 Workshop
Evolutionary Computation. Lecture Notes Computer Science, 1305, 237250.
Singer, J., Gent, I., & Smaill, A. (2000). Backbone Fragility Local Search Cost
Peak. Journal Artificial Intelligence Research, Vol. 12, pp. 235270.
Smith, S., & Cheng, C. (1993). Slack-based Heuristics Constraint Satisfaction Problems.
Proceedings Eleventh National Conference Artificial Intelligence (AAAI93), pp. 139144, Washington, DC. AAAI Press.
Starkweather, T., McDaniel, S., Mathias, K., Whitley, D., & Whitley, C. (1991). Comparison Genetic Sequencing Operators. Booker, L., & Belew, R. (Eds.), Proc.
4th Intl. Conf. GAs, pp. 6976. Morgan Kaufmann.
Syswerda, G. (1991). Schedule Optimization Using Genetic Algorithms. Davis, L. (Ed.),
Handbook Genetic Algorithms, chap. 21. Van Nostrand Reinhold, NY.
Syswerda, G., & Palmucci, J. (1991). Application Genetic Algorithms Resource
Scheduling. Booker, L., & Belew, R. (Eds.), Proc. 4th Intl. Conf. GAs.
Morgan Kaufmann.
Watson, J. P., Rana, S., Whitley, D., & Howe, A. (1999). Impact Approximate Evaluation Performance Search Algorithms Warehouse Scheduling. Journal
Scheduling, 2(2), 7998.
Whitley, D., Starkweather, T., & Fuquay, D. (1989). Scheduling Problems Traveling
Salesmen: Genetic Edge Recombination Operator. Schaffer, J. D. (Ed.), Proc.
3rd Intl. Conf. GAs. Morgan Kaufmann.
Whitley, L. D. (1989). GENITOR Algorithm Selective Pressure: Rank Based
Allocation Reproductive Trials Best. Schaffer, J. D. (Ed.), Proc. 3rd
Intl. Conf. GAs, pp. 116121. Morgan Kaufmann.
Wolfe, W. J., & Sorensen, S. E. (2000). Three Scheduling Algorithms Applied Earth
Observing Systems Domain. Management Science, Vol. 46(1), pp. 148168.
Zweben, M., Daun, B., & Deale, M. (1994). Scheduling rescheduling iterative
repair. Zweben, M., & Fox, M. (Eds.), Intelligent Scheduling. Morgan Kaufmann.

615

fiJournal Artificial Intelligence Research 27 (2006) 119151

Submitted 1/06; published 10/06

Comparison Different Machine Transliteration Models
Jong-Hoon Oh

rovellia@nict.go.jp

Computational Linguistics Group
National Institute Information Communications Technology (NICT)
3-5 Hikaridai, Seika-cho, Soraku-gun, Kyoto 619-0289 Japan

Key-Sun Choi

kschoi@cs.kaist.ac.kr

Computer Science Division, Department EECS
Korea Advanced Institute Science Technology (KAIST)
373-1 Guseong-dong, Yuseong-gu, Daejeon 305-701 Republic Korea

Hitoshi Isahara

isahara@nict.go.jp

Computational Linguistics Group
National Institute Information Communications Technology (NICT)
3-5 Hikaridai, Seika-cho, Soraku-gun, Kyoto 619-0289 Japan

Abstract
Machine transliteration method automatically converting words one language phonetically equivalent ones another language. Machine transliteration plays
important role natural language applications information retrieval machine translation, especially handling proper nouns technical terms. Four machine
transliteration models grapheme-based transliteration model, phoneme-based transliteration model, hybrid transliteration model, correspondence-based transliteration model
proposed several researchers. date, however, little research
framework multiple transliteration models operate simultaneously. Furthermore, comparison four models within framework
using data. addressed problems 1) modeling four models within
framework, 2) comparing conditions, 3) developing
way improve machine transliteration comparison. comparison showed
hybrid correspondence-based models effective
four models used complementary manner improve machine transliteration
performance.

1. Introduction
advent new technology flood information Web,
become increasingly common adopt foreign words ones language. usually entails adjusting adopted words original pronunciation follow phonological rules
target language, along modification orthographical form. phonetic
translation foreign words called transliteration. example, English word
data transliterated Korean de-i-teo1 Japanese de-e-ta. Transliteration particularly used translate proper names technical terms languages
1. paper, target language transliterations represented Romanized form single
quotation marks hyphens syllables.
c
2006
AI Access Foundation. rights reserved.

fiOh, Choi, & Isahara

using Roman alphabets ones using non-Roman alphabets English
Korean, Japanese, Chinese. transliteration one main causes
out-of-vocabulary (OOV) problem, transliteration means dictionary lookup impractical (Fujii & Tetsuya, 2001; Lin & Chen, 2002). One way solve OOV problem
use machine transliteration. Machine transliteration usually used support machine
translation (MT) (Knight & Graehl, 1997; Al-Onaizan & Knight, 2002) cross-language
information retrieval (CLIR) (Fujii & Tetsuya, 2001; Lin & Chen, 2002). CLIR, machine
transliteration bridges gap transliterated localized form original form
generating possible transliterations original form (or generating possible
original forms transliteration)2 . example, machine transliteration assist
query translation CLIR, proper names technical terms frequently appear
source language queries. area MT, machine transliteration helps preventing translation errors translations proper names technical terms registered
translation dictionary. Machine transliteration therefore improve performance
MT CLIR.
Four machine transliteration models proposed several researchers: grapheme3 -based transliteration model (G ) (Lee & Choi, 1998; Jeong, Myaeng, Lee, &
Choi, 1999; Kim, Lee, & Choi, 1999; Lee, 1999; Kang & Choi, 2000; Kang & Kim, 2000;
Kang, 2001; Goto, Kato, Uratani, & Ehara, 2003; Li, Zhang, & Su, 2004), phoneme4 based transliteration model (P ) (Knight & Graehl, 1997; Lee, 1999; Jung, Hong, &
Paek, 2000; Meng, Lo, Chen, & Tang, 2001), hybrid transliteration model (H ) (Lee,
1999; Al-Onaizan & Knight, 2002; Bilac & Tanaka, 2004), correspondence-based
transliteration model (C ) (Oh & Choi, 2002). models classified terms
units transliterated. G sometimes referred direct method
directly transforms source language graphemes target language graphemes without
phonetic knowledge source language words. P sometimes referred
pivot method uses source language phonemes pivot produces
target language graphemes source language graphemes. P therefore usually
needs two steps: 1) produce source language phonemes source language graphemes;
2) produce target language graphemes source phonemes5 . H C make use
source language graphemes source language phonemes producing target
language transliterations. Hereafter, refer source language grapheme source
2. former process generally called transliteration, latter generally called backtransliteration (Knight & Graehl, 1997)
3. Graphemes refer basic units (or smallest contrastive units) written language: example,
English 26 graphemes letters, Korean 24, German 30.
4. Phonemes simplest significant unit sound (or smallest contrastive units spoken language); example, /M/, /AE/, /TH/ /M AE TH/, pronunciation math. use
ARPAbet symbols represent source phonemes. ARPAbet one methods used coding source
phonemes ASCII characters (http://www.cs.cmu.edu/~laura/pages/arpabet.ps). denote
source phonemes pronunciation two slashes, /AH/, use pronunciation based
CMU Pronunciation Dictionary American Heritage(r) Dictionary English Language.
5. two steps explicit transliteration system produces target language transliterations
producing pronunciations source language words; implicit system uses phonemes
implicitly transliteration stage explicitly learning stage, described elsewhere (Bilac
& Tanaka, 2004)

120

fiA Comparison Machine Transliteration Models

grapheme, source language phoneme source phoneme, target language grapheme
target grapheme.
transliterations produced four models usually differ models use
different information. Generally, transliteration phonetic process, P , rather
orthographic one, G (Knight & Graehl, 1997). However, standard transliterations restricted phoneme-based transliterations. example, standard
Korean transliterations data, amylase, neomycin are, respectively, phonemebased transliteration de-i-teo, grapheme-based transliteration a-mil-la-a-je, neo-ma-i-sin, combination grapheme-based transliteration ne-o
phoneme-based transliteration ma-i-sin. Furthermore, unit transliterated
restricted either source grapheme source phoneme, hard produce correct
transliteration many cases. example, P cannot easily produce grapheme-based
transliteration a-mil-la-a-je, standard Korean transliteration amylase, P
tends produce a-mil-le-i-seu based sequence source phonemes /AE AH
L EY S/. Multiple transliteration models therefore applied better cover
various transliteration processes. date, however, little published research
regarding framework multiple transliteration models operate simultaneously.
Furthermore, reported comparison transliteration models within
framework using data although many English-to-Korean transliteration methods based G compared data (Kang
& Choi, 2000; Kang & Kim, 2000; Oh & Choi, 2002).
address problems, 1) modeled framework four transliteration models operate simultaneously, 2) compared transliteration
models conditions, 3) using results comparison,
developed way improve performance machine transliteration.
rest paper organized follows. Section 2 describes previous work relevant
study. Section 3 describes implementation four transliteration models.
Section 4 describes testing results. Section 5 describes way improve machine
transliteration based results comparison. Section 6 describes transliteration ranking method used improve transliteration performance. Section 7
concludes paper summary look future work.

2. Related Work
Machine transliteration received significant research attention recent years.
cases, source language target language English Asian language, respectively example, English Japanese (Goto et al., 2003), English Chinese (Meng
et al., 2001; Li et al., 2004), English Korean (Lee & Choi, 1998; Kim et al., 1999;
Jeong et al., 1999; Lee, 1999; Jung et al., 2000; Kang & Choi, 2000; Kang & Kim, 2000;
Kang, 2001; Oh & Choi, 2002). section, review previous work related four
transliteration models.
2.1 Grapheme-based Transliteration Model
Conceptually, G direct orthographical mapping source graphemes target
graphemes. Several transliteration methods based model proposed,
121

fiOh, Choi, & Isahara

based source-channel model (Lee & Choi, 1998; Lee, 1999; Jeong et al.,
1999; Kim et al., 1999), decision tree (Kang & Choi, 2000; Kang, 2001), transliteration
network (Kang & Kim, 2000; Goto et al., 2003), joint source-channel model (Li et al.,
2004).
methods based source-channel model deal English-Korean transliteration. use chunk graphemes correspond source phoneme. First,
English words segmented chunk English graphemes. Next, possible chunks
Korean graphemes corresponding chunk English graphemes produced. Finally,
relevant sequence Korean graphemes identified using source-channel
model. advantage approach considers chunk graphemes representing phonetic property source language word. However, errors first step
(segmenting English words) propagate subsequent steps, making difficult
produce correct transliterations steps. Moreover, high time complexity
possible chunks graphemes generated languages.
method based decision tree, decision trees transform source
grapheme target graphemes learned directly applied machine transliteration. advantage approach considers wide range contextual
information, say, left three right three contexts. However, consider
phonetic aspects transliteration.
Kang Kim (2000) Goto et al. (2003) proposed methods based transliteration network for, respectively, English-to-Korean English-to-Japanese transliteration.
frameworks constructing transliteration network similar composed
nodes arcs. node represents chunk source graphemes corresponding
target graphemes. arc represents possible link nodes weight showing
strength. Like methods based source-channel model, methods consider
phonetic aspect form chunks graphemes. Furthermore, segment chunk
graphemes identify relevant sequence target graphemes one step.
means errors propagated one step next, methods based
source-channel model.
method based joint source-channel model simultaneously considers source
language target language contexts (bigram trigram) machine transliteration.
main advantage use bilingual contexts.
2.2 Phoneme-based Transliteration Model
P , transliteration key pronunciation source phoneme rather
spelling source grapheme. model basically source grapheme-to-source phoneme
transformation source phoneme-to-target grapheme transformation.
Knight Graehl (1997) modeled Japanese-to-English transliteration weighted
finite state transducers (WFSTs) combining several parameters including romaji-tophoneme, phoneme-to-English, English word probabilities, on. similar model
developed Arabic-to-English transliteration (Stalls & Knight, 1998). Meng et al. (2001)
proposed English-to-Chinese transliteration method based English grapheme-to-phoneme
conversion, cross-lingual phonological rules, mapping rules English phonemes
Chinese phonemes, Chinese syllable-based character-based language models. Jung
122

fiA Comparison Machine Transliteration Models

et al. (2000) modeled English-to-Korean transliteration extended Markov window.
method transforms English word English pronunciation using pronunciation dictionary. segments English phonemes chunks English phonemes;
chunk corresponds Korean grapheme defined handcrafted rules. Finally,
automatically transforms chunk English phonemes Korean graphemes using
extended Markov window.
Lee (1999) modeled English-to-Korean transliteration two steps. English graphemeto-English phoneme transformation modeled manner similar method based
source-channel model described Section 2.1. English phonemes
transformed Korean graphemes using English-to-Korean standard conversion rules
(EKSCR) (Korea Ministry Culture & Tourism, 1995). rules form
context-sensitive rewrite rules, PA PX PB y, meaning English phoneme PX
rewritten Korean grapheme context PA PB , PX , PA , PB represent English phonemes. example, PA = , PX = /SH/, PB = end si means
English phoneme /SH/ rewritten Korean grapheme si occurs end
word (end) phoneme (). approach suffers propagation
errors limitations EKSCR. first step, grapheme-to-phoneme transformation, usually results errors, errors propagate next step. Propagated errors
make difficult transliteration system work correctly. addition, EKSCR
contain enough rules generate correct Korean transliterations since main focus
mapping English phoneme Korean graphemes without taking account
contexts English grapheme.
2.3 Hybrid Correspondence-based Transliteration Models
Attempts use source graphemes source phonemes machine transliteration
led correspondence-based transliteration model (C ) (Oh & Choi, 2002)
hybrid transliteration model (H ) (Lee, 1999; Al-Onaizan & Knight, 2002; Bilac & Tanaka,
2004). former makes use correspondence source grapheme source
phoneme produces target language graphemes; latter simply combines G
P linear interpolation. Note H combines grapheme-based transliteration probability (P r(G )) phoneme-based transliteration probability (P r(P ))
using linear interpolation.
Oh Choi (2002) considered contexts source grapheme corresponding source phoneme English-to-Korean transliteration. used EKSCR basic rules method. Additional contextual rules semi-automatically constructed
examining cases EKSCR produced incorrect transliterations
lack contexts. contextual rules form context-sensitive rewrite
rules, CA CX CB y, meaning CX rewritten target grapheme context
CA CB . Note CX , CA , CB represent correspondence English grapheme phoneme. example, read CA = ( : /V owel/), CX =
(r : /R/), CB = ( : /Consonant/) NULL English grapheme r corresponding
phoneme /R/ rewritten null Korean graphemes occurs vowel phonemes,
( : /V owel/), consonant phonemes, ( : /Consonant/). main advantage
approach application sophisticated rule reflects context source
123

fiOh, Choi, & Isahara

grapheme source phoneme considering correspondence. However, lack
portability languages rules restricted Korean.
Several researchers (Lee, 1999; Al-Onaizan & Knight, 2002; Bilac & Tanaka, 2004)
proposed hybrid model-based transliteration methods. model G P WFSTs source-channel model combine G P linear interpolation.
P , several parameters considered, source grapheme-to-source phoneme
probability, source phoneme-to-target grapheme probability, target language word probability. G , source grapheme-to-target grapheme probability mainly considered. main disadvantage hybrid model dependence source
grapheme source phoneme taken consideration combining process;
contrast, Oh Chois approach (Oh & Choi, 2002) considers dependence using
correspondence source grapheme phoneme.

3. Modeling Machine Transliteration Models
section, describe implementation four machine transliteration models
(G , P , H , C ) using three machine learning algorithms: memory-based learning,
decision-tree learning, maximum entropy model.
3.1 Framework Four Machine Transliteration Models
Figure 1 summarizes differences among transliteration models component
functions. G directly transforms source graphemes (S) target graphemes (T).
P C transform source graphemes source phonemes generate target
graphemes6 . P uses source phonemes, C uses correspondence
source grapheme source phoneme generates target graphemes.
describe differences two functions, P (SP )T . H represented
linear interpolation P r(G ) P r(P ) means (0 1). Here, P r(P )
probability P produce target graphemes, P r(G ) probability G
produce target graphemes. thus regard H composed component
functions G P (SP , P , ST ). use maximum entropy model
machine learning algorithm H H requires P r(P ) P r(G ),
maximum entropy model among memory-based learning, decision-tree learning,
maximum entropy model produce probabilities.
train component function, need define features represent training
instances data. Table 1 shows five feature types, fS , fP , fStype , fP type , fT .
feature types used depend component functions. modeling component
function feature types explained Sections 3.2 3.3.
3.2 Component Functions Transliteration Model
Table 2 shows definitions four component functions used. defined
terms input output: first last characters notation
correspond respectively input output. role component function
6. According (gf )(x) = g(f (x)), write ((SP )T SP )(x) = (SP )T (SP (x)) (P SP )(x) =
P (SP (x)).

124

fiA Comparison Machine Transliteration Models

ST




(SP)T

SP

P
SS:: Source graphemes
P
P:: Source Phonemes
TT:: Target graphemes

PT
G : ST
P : PT SP
C : ( SP )T SP
H : Pr( P )
+ (1 ) Pr( G )

Figure 1: Graphical representation component function four transliteration
models: set source graphemes (e.g., letters English alphabet), P
set source phonemes defined ARPAbet, set target graphemes.

Feature type
fS
fS,Stype
fStype
fP
fP,P type
fP type
fT

Description possible values
Source graphemes S:
26 letters English alphabet
Source grapheme types:
Consonant (C) Vowel (V)
Source phonemes P
(/AA/, /AE/, on)
Source phoneme types: Consonant (C), Vowel (V),
Semi-vowel (SV), silence (//)
Target graphemes

Table 1: Feature types used transliteration models: fS,Stype indicates fS fStype ,
fP,P type indicates fP fP type .

transliteration model produce relevant output input.
performance transliteration model therefore depends strongly component
functions. words, better modeling component function, better
performance machine transliteration system.
modeling strongly depends feature type. Different feature types used
(SP )T , P , ST functions, shown Table 2. three component
functions thus different strengths weaknesses machine transliteration.
ST function good producing grapheme-based transliterations poor producing
125

fiOh, Choi, & Isahara

Notation
SP
(SP )T
P
ST

Feature types used
fS,Stype , fP
fS,Stype , fP,P type , fT
fP,P type , fT
fS,Stype , fT

Input
si , c(si )
si , pi , c(si ), c(pi )
pi , c(pi )
si , c(si )

Output
pi
ti
ti
ti

Table 2: Definition component function: si , c(si ), pi , c(pi ), ti respectively represent ith source grapheme, context si (sin , , si1 si+1 , , si+n ),
ith source phoneme, context pi (pin , , pi1 pi+1 , , pi+n ),
ith target grapheme.

phoneme-based ones. contrast, P function good producing phoneme-based
transliterations poor producing grapheme-based ones. amylase standard
Korean transliteration, a-mil-la-a-je, grapheme-based transliteration, ST tends
produce correct transliteration; P tends produce wrong ones like ae-meol-le-iseu, derived /AE AH L EY S/, pronunciation amylase. contrast,
P produce de-i-teo, standard Korean transliteration data
phoneme-based transliteration, ST tends give wrong one, like da-ta.
(SP )T function combines advantages ST P utilizing correspondence source grapheme source phoneme. correspondence enables (SP )T produce grapheme-based phoneme-based transliterations. Furthermore, correspondence provides important clues use resolving transliteration
ambiguities7 . example, source phoneme /AH/ produces much ambiguity machine transliteration mapped almost every vowel source
target languages (the underlined graphemes following example corresponds /AH/:
holocaust English, hol-lo-ko-seu-teu Korean counterpart, ho-ro-ko-o-su-to
Japanese counterpart). know correspondence source grapheme
source phoneme, easily infer correct transliteration /AH/
correct target grapheme corresponding /AH/ usually depends source grapheme
corresponding /AH/. Moreover, various Korean transliterations source
grapheme a: a, ae, ei, i, o. case, English phonemes corresponding
English grapheme help component function resolve transliteration ambiguities, shown Table 3. Table 3, underlined example words shown
last column pronounced English phoneme second column. looking
English grapheme corresponding English phoneme, find correct Korean
transliterations easily.
Though (SP )T effective ST P many cases, (SP )T sometimes works poorly standard transliteration strongly biased either graphemebased phoneme-based transliteration. cases, either source grapheme source
phoneme contribute correct transliteration, making difficult (SP )T
produce correct transliteration. ST , P , (SP )T core parts
7. Though contextual information also used reduce ambiguities, limit discussion
feature type.

126

fiA Comparison Machine Transliteration Models

Korean Grapheme

ae
ei



English Phoneme
/AA/
/AE/
/EY/
/IH/
/AO/

Example usage
adagio, safari, vivace
advantage, alabaster, travertine
chamber, champagne, chaos
advantage, average, silage
allspice, ball, chalk

Table 3: Examples Korean graphemes derived English grapheme corresponding English phonemes: underlines example words indicate
English grapheme corresponding English phonemes second column.

G , P , C , respectively, advantages disadvantages three component
functions correspond transliteration models used.
Transliteration usually depends context. example, English grapheme
transliterated Korean graphemes basis context, like ei context
-ation context art. context information used, determining
context window size important. context window narrow degrade
transliteration performance lack context information. example,
English grapheme -tion transliterated Korean, one right English grapheme
insufficient context three right contexts, -ion, necessary get correct
Korean grapheme, s. context window wide also degrade transliteration
performance reduces power resolve transliteration ambiguities. Many
previous studies determined appropriate context window size 3.
paper, use window size 3, previous work (Kang & Choi, 2000; Goto et al.,
2003). effect context window size transliteration performance discussed
Section 4.
Table 4 shows identify relevant output component function using
context information. L3-L1, C0, R1-R3 represent left context, current context
(i.e., transliterated), right context, respectively. SP function produces
relevant source phoneme source grapheme. SW = s1 s2 . . . sn
English word, SW pronunciation represented sequence source phonemes
produced SP ; is, PSW = p1 p2 . . . pn , pi = SP (si , c(si )). SP transforms
source graphemes phonemes two ways. first one search pronunciation
dictionary containing English words pronunciation (CMU, 1997). second one
estimate pronunciation (or automatic grapheme-to-phoneme conversion) (Andersen, Kuhn, Lazarides, Dalsgaard, Haas, & Noth, 1996; Daelemans & van den Bosch, 1996;
Pagel, Lenzo, & Black, 1998; Damper, Marchand, Adamson, & Gustafson, 1999; Chen,
2003). English word registered pronunciation dictionary, must estimate pronunciation. produced pronunciation used P P (SP )T
C . training automatic grapheme-to-phoneme conversion SP , use CMU
Pronouncing Dictionary (CMU, 1997).
ST , P , (SP )T functions produce target graphemes using input. Like
SP , three functions use previous outputs, represented fT .
127

fiOh, Choi, & Isahara

SP

ST

P

(SP )T

ype
fS
fStype
fP
fS
fStype
fT
fP
fP type
fT
fS
fP
fStype
fP type
fT

L3
$
$
$
$
$
$
$
$
$
$
$
$
$
$

L2
$
$
$
$
$
$
$
$
$
$
$
$
$
$

L1
$
$
$
$
$
$
$
$
$
$
$
$
$
$

C0
b
C

R1

V

R2

V

R3
r
C

Output


/B/


V

r
C



b

//
//

/R/
C



b


//
V
//

r
/R/
C
C



b


b
C
/B/
C
b
/B/
C
C


V

/AO/
V


/AO/
V
V


Table 4: Framework component function: $ represents start words means
unused contexts component function.

shown Table 4, ST , P , (SP )T produce target grapheme b source grapheme
b source phoneme /B/ board /B AO R D/. b /B/
first source grapheme board first source phoneme /B AO R D/, respectively,
left context $, represents start words. Source graphemes (o, a, r )
type (V: vowel, V: vowel, C: consonant) right context ST
(SP )T . Source phonemes (/AO/, //, /R/) type (V: vowel, //: silence,
V: vowel) right context P (SP )T . Depending feature type
used component function described Table 2, ST , P , (SP )T produce
sequence target graphemes, TSW = t1 t2 . . . tn , SW = s1 s2 . . . sn
PSW = p1 p2 . . . pn . board, SW , PSW , TSW represented follows.
// represents silence (null source phonemes), represents null target graphemes.
SW = s1 s2 s3 s4 s5 = b r
PSW = p1 p2 p3 p4 p5 = /B/ /AO/ / / /R/ /D/
TSW = t1 t2 t3 t4 t5 = b deu
3.3 Machine Learning Algorithms Component Function
section describe way model component functions using three machine learning algorithms (the maximum entropy model, decision-tree learning, memory-based
learning)8 . four component functions share similar framework, limit
focus (SP )T section.
8. three algorithms typically applied automatic grapheme-to-phoneme conversion (Andersen
et al., 1996; Daelemans & van den Bosch, 1996; Pagel et al., 1998; Damper et al., 1999; Chen, 2003).

128

fiA Comparison Machine Transliteration Models

3.3.1 Maximum entropy model
maximum entropy model (MEM) widely used probability model incorporate heterogeneous information effectively (Berger, Pietra, & Pietra, 1996).
MEM, event (ev) usually composed target event (te) history event (he);
say ev =< te, >. Event ev represented bundle feature functions, f ei (ev),
represent existence certain characteristics event ev. feature function
binary-valued function. activated (f ei (ev) = 1) meets activating condition; otherwise deactivated (f ei (ev) = 0) (Berger et al., 1996). Let source language
word SW composed n graphemes. SW, PSW , TSW represented
SW = s1 , , sn , PSW = p1 , , pn , TSW = t1 , , tn , respectively. PSW TSW
represent pronunciation target language word corresponding SW, pi ti
represent source phoneme target grapheme corresponding si . Function (SP )T
based maximum entropy model represented
P r(TSW |SW, PSW ) = P r(t1 , , tn |s1 , , sn , p1 , , pn )

(1)

assumption (SP )T depends context information window size k,
simplify Formula (1)
P r(TSW |SW, PSW )



P r(ti |tik , , ti1 , pik , , pi+k , sik , , si+k )

(2)



t1 , , tn , s1 , , sn , p1 , , pn represented fT , fS,Stype , fP,P type ,
respectively, rewrite Formula (2)
P r(TSW |SW, PSW )



P r(ti |fT(ik,i1) , fP,P type(ik,i+k) , fS,Stype(ik,i+k) )

(3)



index current source grapheme source phoneme transliterated
fX(l,m) represents features feature type fX located position l position m.
important factor designing model based maximum entropy model
identify feature functions effectively support certain decisions model.
basic philosophy feature function design component function context
information collocated unit interest important. thus designed feature
function collocated features feature type different feature types.
Features used (SP )T listed below. features used activating conditions
history events feature functions.
Feature type features used designing feature functions (SP )T (k = 3)
possible features fS,Stypeik,i+k , fP,P typeik,i+k , fTik,i1 (e.g., fSi1 ,
fPi1 , fTi1 )
possible feature combinations features feature type (e.g.,
{fSi2 , fSi1 , fSi+1 }, {fPi2 , fPi , fPi+2 }, {fTi2 , fTi1 })
possible feature combinations features different feature types (e.g.,
{fSi1 , fPi1 }, {fSi1 , fTi2 } , {fP typei2 , fPi3 , fTi2 })
fS,Stypeik,i+k fP,P typeik,i+k
129

fiOh, Choi, & Isahara

f ej

te
ti

f e1
f e2
f e3
f e4
f e5

b
b
b
b
b


fT(ik,i1)

fS,Stype(ik,i+k)



fTi1 = $

fTi2 = $

fSi+1

fP,P type(ik,i+k)

fSi = b
fSi1 = $
= fStypei+2 = V

fSi+3 = r

fPi = /B/

fPi = /B/
fPi+1 = /AO/
fP typei = C

Table 5: Feature functions (SP )T derived Table 4.

fS,Stypeik,i+k fTik,i1
fP,P typeik,i+k fTik,i1
Generally, conditional maximum entropy model gives conditional probability
P r(y|x) represented Formula (4) (Berger et al., 1996).
P r(y|x) =
Z(x) =

X
1
exp( f ei (x, y))
Z(x)


X

exp(



X

(4)

f ei (x, y))



(SP )T , target event (te) target graphemes assigned, history event
(he) represented tuple < fT(ik,i1) , fS,Stype(ik,i+k) , fP,P type(ik,i+k) >. Therefore,
rewrite Formula (3)
P r(ti |fT(ik,i1) , fS,Stype(ik,i+k) , fP,P type(ik,i+k) )
X
1
exp( f ei (he, te))
= P r(te|he) =
Z(he)


(5)

Table 5 shows example feature functions (SP )T ; Table 4 used derive
functions. example, f e1 represents event (history event) fSi b
fPi /B/ te (target event) fTi b. model component function based
MEM, Zhangs maximum entropy modeling tool used (Zhang, 2004).
3.3.2 Decision-tree learning
Decision-tree learning (DTL) one widely used well-known methods
inductive inference (Quinlan, 1986; Mitchell, 1997). ID3, greedy algorithm
constructs decision trees top-down manner, uses information gain,
measure well given feature (or attribute) separates training examples basis
target class (Quinlan, 1993; Manning & Schutze, 1999). use C4.5 (Quinlan, 1993),
well-known tool DTL implementation Quinlans ID3 algorithm.
training data component function represented features located L3L1, C0, R1-R3, shown Table 4. C4.5 tries construct decision tree looking
regularities training data (Mitchell, 1997). Figure 2 shows part decision
130

fiA Comparison Machine Transliteration Models

tree constructed (SP )T English-to-Korean transliteration. set target classes
decision tree (SP )T set target graphemes. rectangles indicate
leaf nodes, represent target classes, circles indicate decision nodes.
simplify examples, use fS fP . Note feature types
component function, described Table 4, actually used construct decision trees.
Intuitively, effective feature among L3-L1, C0, R1-R3 (SP )T may
located C0 correct outputs (SP )T strongly depend source grapheme
source phoneme C0 position. expected, effective feature
decision tree located C0 position, is, C0(fP ). (Note first feature
tested decision trees effective feature.) Figure 2, decision tree
produces target grapheme (Korean grapheme) instance x(SP ) retrieving
decision nodes C0(fP ) = /AO/ R1(fP ) = / / represented .

C0(f
C0(fPP): /AO/ (*)
C0(fSS): e

C0(fSS):





C0(f
C0(fSS): o(*)

x(SPT)

C0(fSS): others

eu

R1(fPP): /R/

L2(fSS): $

C0(fSS):

L2(fSS):

R1(f
R1(fPP): /~/(*)

R1(fPP): others


(*)
(*)



L2(fSS): r

Feature type L3 L2
fS

$

$

fP

$

$

L1

C0

R1

R2

R3

b





r



(SP)T




/B/ /AO/ /~/ /R/ /D/

Figure 2: Decision tree (SP )T .

3.3.3 Memory-based learning
Memory-based learning (MBL), also called instance-based learning case-based learning, example-based learning method. based k-nearest neighborhood algorithm (Aha, Kibler, & Albert, 1991; Aha, 1997; Cover & Hart, 1967; Devijver & Kittler.,
1982). MBL represents training data vector and, training phase, places
training data examples memory clusters examples basis knearest neighborhood principle. Training data MBL represented form
training data decision tree. Note target classes (SP )T , MBL
outputs, target graphemes. Feature weighting deal features differing importance also done training phase9 . produces output using similarity-based
9. TiMBL (Daelemans, Zavrel, Sloot, & Bosch, 2004) supports gain ratio weighting, information gain
weighting, chi-squared (2 ) weighting, shared variance weighting features.

131

fiOh, Choi, & Isahara

reasoning test data examples memory. test data x
set examples memory , similarity x estimated using
distance function (x, )10 . MBL selects example yi cluster examples
similar x assigns examples target class xs target class. use
MBL tool called TiMBL (Tilburg memory-based learner) version 5.0 (Daelemans et al.,
2004).

4. Experiments
tested four machine transliteration models English-to-Korean English-toJapanese transliteration. test set former (EKSet) (Nam, 1997) consisted
7,172 English-Korean pairs number training items 6,000
blind test items 1,000. EKSet contained transliteration variations, meaning
one transliteration English word. test set latter (EJSet)
contained English-katakana pairs EDICT (Breen, 2003) consisted 10,417 pairs
number training items 9,000 blind test items
1,000. EJSet contained transliteration variations, like <micro, ma-i-ku-ro>, <micro,
mi-ku-ro>; average number Japanese transliterations English word 1.15.
EKSet EJSet covered proper names, technical terms, general terms. used
CMU Pronouncing Dictionary (CMU, 1997) training pronunciation estimation (or
automatic grapheme-to-phoneme conversion) SP . training automatic graphemeto-phoneme conversion done ignoring lexical stress vowels dictionary (CMU,
1997). evaluation done terms word accuracy (W A), evaluation measure
used previous work (Kang & Choi, 2000; Kang & Kim, 2000; Goto et al., 2003; Bilac &
Tanaka, 2004). Here, W represented Formula (6). generated transliteration
English word judged correct exactly matched transliteration
word test data.
WA =

number correct transliterations output system
number transliterations blind test data

(6)

evaluation, used k-fold cross-validation (k=7 EKSet k=10 EJSet).
test set divided k subsets. used turn testing remainder
used training. average W computed across k trials used evaluation
results presented section.
conducted six tests.
Hybrid Model Test: Evaluation hybrid transliteration model changing value
(the parameter hybrid transliteration model)
Comparison Test I: Comparison among four machine transliteration models
Comparison Test II: Comparison four machine transliteration models previously
proposed transliteration methods
10. Modified value difference metric, overlap metric, Jeffrey divergence metric, dot product metric, etc.
used distance function (Daelemans et al., 2004).

132

fiA Comparison Machine Transliteration Models

Dictionary Test: Evaluation transliteration models words registered
registered pronunciation dictionary determine effect pronunciation dictionary
model
Context Window-Size Test: Evaluation transliteration models various sizes
context window
Training Data-Size Test: Evaluation transliteration models various sizes training data sets
4.1 Hybrid Model Test
objective test estimate dependence performance H
parameter . evaluated performance changing 0 1 intervals
0.1 (i.e., =0, 0.1, 0.2, , 0.9, 1.0). Note hybrid model represented
P r(P ) + (1 ) P r(G ). Therefore, H G = 0 P = 1.
shown Table 6, performance H depended G P . example,
performance G exceeded P EKSet. Therefore, H tended perform
better 0.5 > 0.5 EKSet. best performance attained
= 0.4 EKSet = 0.5 EJSet. Hereinafter, use = 0.4
EKSet = 0.5 EJSet linear interpolation parameter H .

0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0

EKSet
58.8%
61.2%
62.0%
63.0%
64.1%
63.4%
61.1%
59.6%
58.2%
57.0%
55.2%

EJSet
58.8%
60.9%
62.6%
64.1%
65.4%
65.8%
65.0%
63.4%
62.1%
61.2%
59.2%

Table 6: Results Hybrid Model Test.

4.2 Comparison Test
objectives first comparison test compare performance among four
transliteration models (G , P , H , C ) compare performance model
combined performance three models (G+P +C ). Table 7 summarizes
performance model English-to-Korean English-to-Japanese transliteration,
133

fiOh, Choi, & Isahara

DTL, MBL11 MEM represent decision-tree learning, memory-based learning,
maximum entropy model.
unit transliterated restricted either source grapheme source
phoneme G P ; dynamically selected basis contexts H
C . means G P could produce incorrect result either source
phoneme source grapheme, which, respectively, consider, holds key
producing correct transliteration result. reason, H C performed better
G P .
Transliteration Model
G
P
H
C
G+P +C

DTL
53.1%
50.8%
N/A
59.5%
72.0%

EKSet
MBL
54.6%
50.6%
N/A
60.3%
71.4%

MEM
58.8%
55.2%
64.1%
65.5%
75.2%

DTL
55.6%
55.8%
N/A
64.0%
73.4%

EJSet
MBL
58.9%
56.1%
N/A
65.8%
74.2%

MEM
58.8%
59.2%
65.8%
69.1%
76.6%

Table 7: Results Comparison Test I.
table, G+P +C means combined results three transliteration models,
G , P , C . exclude H combining implemented
MEM (the performance combining four transliteration models discussed
Section 5). evaluating G+P +C , judged transliteration results correct
least one correct transliteration among results produced three
models. Though C showed best results among three transliteration models due
ability use correspondence source grapheme source phoneme,
source grapheme source phoneme create noise correct transliteration
produced one. words, correct transliteration strongly
biased either grapheme-based phoneme-based transliteration, G P may
suitable producing correct transliteration.
Table 8 shows example transliterations produced transliteration model.
G produced correct transliterations cyclase bacteroid, P
geoid silo. C produced correct transliterations saxhorn bacteroid, H
produced correct transliterations geoid bacteroid. shown results,
transliterations one transliteration model produce correctly. example,
G , P , C produced correct transliterations cyclase, silo, saxhorn,
respectively. Therefore, three transliteration models used complementary
manner improve transliteration performance least one usually produce
correct transliteration. combination increased performance compared G ,
P , C (on average, 30.1% EKSet 24.6% EJSet). short, G , P , C
complementary transliteration models together produce correct transliterations,
11. tested possible combinations (x, ) weighting scheme supported
TiMBL (Daelemans et al., 2004) detect significant differences performance
various combinations. Therefore, used default setting TiMBL (Overlap metric (x, )
gain ratio weighting feature weighting).

134

fiA Comparison Machine Transliteration Models

combining different transliteration models improve transliteration performance.
transliteration results produced G+P +C analyzed detail Section 5.

cyclase
bacteroid
geoid
silo
saxhorn
cyclase
bacteroid
geoid
silo
saxhorn

G
si-keul-la-a-je
bak-te-lo-i-deu
je-o-i-deu
sil-lo
saek-seon
H
sa-i-keul-la-a-je
bak-te-lo-i-deu
ji-o-i-deu
sil-lo
saek-seon

P
sa-i-keul-la-a-je
bak-teo-o-i-deu
ji-o-i-deu
sa-il-lo
saek-seu-ho-leun
C
sa-i-keul-la-a-je
bak-te-lo-i-deu
ge-o-i-deu
sil-lo
saek-seu-hon

Table 8: Example transliterations produced transliteration model ( indicates
incorrect transliteration).
subsequent testing, used maximum entropy model machine learning
algorithm two reasons. First, produced best results three algorithms
tested12 . Second, support H .
4.3 Comparison Test II
test, compared four previously proposed machine transliteration methods (Kang
& Choi, 2000; Kang & Kim, 2000; Goto et al., 2003; Bilac & Tanaka, 2004) four
transliteration models (G , P , H , C ), based MEM. Table 9 shows
results. trained tested previous methods data sets used
four transliteration models. Table 10 shows key features methods models
viewpoint information type usage. Information type indicates type
information considered: source grapheme, source phoneme, correspondence
two. example, first three methods use source grapheme. Information
usage indicates context used whether previous output used.
obvious table information types transliteration model
considers, better performance. Either source phoneme correspondence
considered methods Kang Choi (2000), Kang Kim (2000),
Goto et al. (2003) key higher performance method Bilac
Tanaka (2004) H C .
viewpoint information usage, models methods consider
previous output tended achieve better performance. example, method Goto et
al. (2003) better results Kang Choi (2000). machine translit12. one-tail paired t-test showed results MEM always significantly better (except
G EJSet) DTL MBL (level significance = 0.001).

135

fiOh, Choi, & Isahara

Method/Model
Kang Choi (2000)
Kang Kim (2000)
Previous methods
Goto et al. (2003)
Bilac Tanaka (2004)
G
P
MEM-based models
H
C

EKSet
51.4%
55.1%
55.9%
58.3%
58.8%
55.2%
64.1%
65.5%

EJSet
50.3%
53.2%
56.2%
62.5%
58.8%
59.2%
65.8%
69.1%

Table 9: Results Comparison Test II.

Method/Model
Kang Choi (2000)
Kang Kim (2000)
Goto et al. (2003)
Bilac Tanaka (2004)
G
P
H
C

Info. type
P C
+
+
+
+ +
+
+
+ +
+ + +

Info. usage
Context
< 3 +3 >
Unbounded
< 3 +3 >
Unbounded
< 3 +3 >
< 3 +3 >
< 3 +3 >
< 3 +3 >

PO

+
+

+
+
+
+

Table 10: Information type usage previous methods four transliteration models, S, P, C, PO respectively represent source grapheme, source
phoneme, correspondence P, previous output.

eration sensitive context, reasonable context size usually enhances transliteration
ability. Note size context window previous methods limited 3
context window wider 3 degrades performance (Kang & Choi, 2000)
significantly improve (Kang & Kim, 2000). Experimental results related context
window size given Section 4.5.
Overall, H C better performance previous methods (on average,
17.04% better EKSet 21.78% better EJSet), G (on average, 9.6% better
EKSet 14.4% better EJSet), P (on average, 16.7% better EKSet
19.0% better EJSet). short, good machine transliteration model 1) consider
either correspondence source grapheme source phoneme
source grapheme source phoneme, 2) reasonable context size, 3)
consider previous output. H C satisfy three conditions.
136

fiA Comparison Machine Transliteration Models

4.4 Dictionary Test
Table 11 shows performance transliteration model dictionary test.
test, evaluated four transliteration models according way pronunciation generation
(or grapheme-to-phoneme conversion). Registered represents performance words
registered pronunciation dictionary, Unregistered represents unregistered
words. average, number Registered words EKSet 600,
EJSet 700 k-fold cross-validation test data. words, Registered words
accounted 60% test data EKSet 70% test data
EJSet. correct pronunciation always acquired pronunciation dictionary
Registered words, pronunciation must estimated Unregistered words
automatic grapheme-to-phoneme conversion. However, automatic graphemeto-phoneme conversion always produce correct pronunciations estimated rate
correct pronunciations 70% accuracy.

G
P
H
C


EKSet
Registered Unregistered
60.91%
55.74%
66.70%
38.45%
70.34%
53.31%
73.32%
54.12%
80.78%
68.41%

EJSet
Registered Unregistered
61.18%
50.24%
64.35%
40.78%
70.20%
50.02%
74.04%
51.39%
81.17%
62.31%

Table 11: Results Dictionary Test: means G+P +H+C .

Analysis results showed four transliteration models fall three categories. Since G free need correct pronunciation, is, use
source phoneme, performance affected pronunciation correctness. Therefore,
G regarded baseline performance Registered Unregistered.
P (P SP ), H ( P r(P )+(1 ) P r(G )), C ((SP )T SP ) depend
source phoneme, performance tends affected performance SP .
Therefore, P , H , C show notable differences performance Registered
Unregistered. However, performance gap differs strength dependence. P falls second category: performance strongly depends correct
pronunciation. P tends perform well Registered poorly Unregistered. H
C weakly depend correct pronunciation. Unlike P , make use
source grapheme source phoneme. Therefore, perform reasonably well
without correct pronunciation using source grapheme weakens negative
effect incorrect pronunciation machine transliteration.
Comparing C P , find two interesting things. First, P sensitive
errors SP Unregistered. Second, C showed better results Registered
Unregistered. P C share function, SP , key factor accounting
performance gap component functions, P (SP )T .
results shown Table 11, infer (SP )T (in C ) performed better
P (in P ) Registered Unregistered. (SP )T , source grapheme corre137

fiOh, Choi, & Isahara

sponding source phonemes, P consider, made two contributions
higher performance (SP )T . First, source grapheme correspondence
made possible produce accurate transliterations. (SP )T considers
correspondence, (SP )T powerful transliteration ability P , uses
source phonemes, correspondence needed produce correct transliterations. main reason (SP )T performed better P Registered. Second,
source graphemes correspondence compensated errors produced SP producing target graphemes. main reason (SP )T performed better P
Unregistered. comparison C G , performances similar Unregistered. indicates transliteration power C similar G , even
though pronunciation source language word may correct. Furthermore,
performance C significantly higher G Registered. indicates
transliteration power C greater G correct pronunciation
given.
behavior H similar C . Unregistered, P r(G ) H made
possible H avoid errors caused P r(P ). Therefore, worked better P .
Registered, P r(P ) enabled H perform better G .
results test showed H C perform better G P
complementing G P (and thus overcoming disadvantage) considering either
correspondence source grapheme source phoneme
source grapheme source phoneme.
4.5 Context Window-Size Test
testing effect context window size, varied size 1 5.
Regardless size, H C always performed better G P .
size 4 5, model difficulty identifying regularities training data.
Thus, consistent drops performance models size increased
3 4 5. Although best performance obtained size 3, shown
Table 12, differences performance significant range 2-4. However,
significant difference size 1 size 2. indicates
lack contextual information easily lead incorrect transliteration. example,
produce correct target language grapheme -tion, need right three
graphemes (or least right two) t, -ion (or -io). results testing indicate
context size 1 avoid degraded performance.
4.6 Training Data-Size Test
Table 13 shows results Training Data-Size Test using MEM-based machine
transliteration models. evaluated performance four models
varying size training data 20% 100%. Obviously, training data
used, higher system performance. However, objective test determine whether transliteration models perform reasonably well even small amount
training data. found G sensitive four models amount
training data; largest difference performance 20% 100%.
contrast, showed smallest performance gap. results test shows
138

fiA Comparison Machine Transliteration Models

Context Size
1
2
3
4
5

G
44.9%
57.3%
58.8%
56.1%
53.7%

Context Size
1
2
3
4
5

G
46.4%
58.2%
58.8%
56.4%
53.9%

EKSet
P
44.9%
52.8%
55.2%
54.6%
52.6%
EJSet
P
52.1%
59.5%
59.2%
58.5%
56.4%

H
51.8%
61.7%
64.1%
61.8%
60.4%

C
52.4%
64.4%
65.5%
64.3%
62.5%


65.8%
74.4%
75.8%
74.4%
73.9%

H
58.0%
65.6%
65.8%
64.4%
62.9%

C
62.0%
68.7%
69.1%
68.2%
66.3%


70.4%
76.3%
77.0%
76.0%
75.5%

Table 12: Results Context Window-Size Test: means G+P +H+C .

combining different transliteration models helpful producing correct transliterations
even little training data.

Training Data Size
20%
40%
60%
80%
100%
Training Data Size
20%
40%
60%
80%
100%

EKSet
G
P
46.6% 47.3%
52.6% 51.5%
55.2% 53.0%
58.9% 54.0%
58.8% 55.2%
EJSet
G
P
47.6% 51.2%
52.4% 55.1%
55.2% 57.3%
57.9% 58.8%
58.8% 59.2%

H
53.4%
58.7%
61.5%
62.6%
64.1%

C
57.0%
62.1%
63.3%
64.6%
65.5%


67.5%
71.6%
73.0%
74.7%
75.8%

H
56.4%
60.7%
62.9%
65.4%
65.8%

C
60.4%
64.8%
66.6%
68.0%
69.1%


69.6%
72.6%
74.7%
76.7%
77.0%

Table 13: Results Training Data-Size Test: means G+P +H+C .

5. Discussion
Figures 3 4 show distribution correct transliterations produced
transliteration model combination models, based MEM. G ,
139

fiOh, Choi, & Isahara

P , H , C figures represent set correct transliterations produced
model k-fold validation. example, |G | = 4,220 EKSet |G | = 6,121
EJSet mean G produced 4,220 correct transliterations 7,172 English words
EKSet (|KT G| Figure 3) 6,121 correct ones 10,417 English words EJSet
(|JT G| Figure 4). important factor modeling transliteration model reflect
dynamic transliteration behaviors, means transliteration process dynamically
uses source grapheme source phoneme produce transliterations. Due
dynamic behaviors, transliteration grapheme-based transliteration, phoneme-based
transliteration, combination two. forms transliterations classified
basis information upon transliteration process mainly relies (either
source grapheme source phoneme combination two). Therefore,
effective transliteration system able produce various types transliterations
time. One way accommodate different dynamic transliteration behaviors
combine different transliteration models, handle different behavior.
Synergy achieved combining models one model produce correct
transliteration others cannot. Naturally, models tend produce
transliteration, less synergy realized combining them. Figures 3 4 show
synergy gained combining transliteration models terms size intersection
union transliteration models.
G
407

P
82

680 3,051
344

207
624

C

|KTG-(G P C )|
=1,777

(a) G +P +C

G
188

7

899 3,126
119

H

P

305

374

P
267 129

713 3,423
457
311

H

|KTG-(G P H )|
=2,002

(b) G +P +H

252

C

|KTG-(H P C )|
=1,879

(c) P +H +C

G
393

H
340 369

46 3,685
763

451

C

|KTG-(G H C )|
=1,859

(d) G +H +C

Figure 3: Distributions correct transliterations produced models English-toKorean transliteration. KTG represents Korean Transliterations Gold
standard. Note |G P H C | = 5,439, |G P H C | =
3,047, |KT G| = 7,172.

figures show that, area intersection different transliteration models
becomes smaller, size union tends become bigger. main characteristics
obtained figures summarized Table 14. first thing note
|G P | clearly smaller intersection. main reason
G P use common information (G uses source graphemes P uses source
phonemes). However, others use least one source grapheme source phoneme
(source graphemes information common G , H , C source phonemes
information common P , H , C ). Therefore, infer synergy
derived combining G P greater derived combinations.
140

fiA Comparison Machine Transliteration Models

G
379

P
141

805 4,796
628

261
963

C

G
378

H

P
12

806 4,925
202

222

308

P
267 135

786 5,574
916
647

H

185

C

G
207

H
313 176

183 5,418
649

942

C

|JTG-(G P C )|
=2,444

|JTG-(G P H )|
=2,870

|JTG-(H P C )|
=2,601

|JTG-(G H C )|
=2,529

(a) G +P +C

(b) G +P +H

(c) P +H +C

(d) G +H +C

Figure 4: Distributions correct transliterations produced models English-toJapanese transliteration. JTG represents Japanese Transliterations Gold
standard. Note |G P H C |=8,021, |G P H C |=4,786,
|JT G| = 10,417.

|G |
|P |
|H |
|C |
|G P |
|G C |
|G H |
|C H |
|P C |
|P H |
|G P |
|G C |
|G H |
|C H |
|P C |
|P H |

EKSet
4,202
3,947
4,583
4,680
3,133
3,731
4,025
4,136
3,675
3,583
5,051
5,188
4,796
5,164
4,988
4,982

EJSet
6,118
6,158
6,846
7,189
4,937
5,601
5,731
6,360
5,759
5,841
7,345
7,712
7,239
7,681
7,594
7,169

Table 14: Main characteristics obtained Figures 3 4.

However, size union various pairs transliteration models Table 14
shows |C H | |G C | bigger |G P |. main reason
might higher transliteration power C H compared G P
C H cover KTG JTG G P . second thing
note contribution transliteration model |G P H C |
estimated difference |G P H C | union three
transliteration models. example, measure contribution H
141

fiOh, Choi, & Isahara

difference |G P H C | |G P C |. shown Figures 3(a)
4(a)), H makes smallest contribution C (Figures 3(b) 4(b)) makes
largest contribution. main reason H making smallest contribution
tends produce transliteration others, intersection H
others tends large.
also important rank transliterations produced transliteration system
source language word basis relevance. transliteration system
produce list transliterations, reflecting dynamic transliteration behavior,
fail perform well unless distinguish correct wrong transliterations.
Therefore, transliteration system able produce various kinds transliterations depending dynamic transliteration behaviors able rank
basis relevance. addition, application transliteration results natural
language applications machine translation information retrieval requires
transliterations ranked assigned relevance score.
summary, 1) producing list transliterations reflecting dynamic transliteration behaviors (one way combine results different transliteration models,
reflecting one dynamic transliteration behaviors) 2) ranking transliterations terms relevance necessary improve performance
machine transliteration. next section, describe way calculate relevance
transliterations produced combination four transliteration models.

6. Transliteration Ranking
basic assumption transliteration ranking correct transliterations
frequently used real-world texts incorrect ones. Web data reflecting real-world
usage transliterations thus used language resource rank transliterations.
Transliterations appear frequently web documents given either higher
rank higher score. goal transliteration ranking, therefore, rank correct
transliterations higher rank incorrect ones lower. transliterations produced
given English word four transliteration models (G , P , H , C ), based
MEM, ranked using web data.
transliteration ranking relies web frequency (number web documents).
obtain reliable web frequencies, important consider transliteration corresponding source language word together rather transliteration alone.
aim find correct transliterations corresponding source language word
rather find transliterations frequently used target language. Therefore, best approach transliteration ranking using web data find web documents
transliterations used translations source language word.
bilingual phrasal search (BPS) retrieves Web Web search engine query,
phrase composed transliteration source language word (e.g., {a-milla-a-je amylase}). BPS enables Web search engine find web documents
contain correct transliterations corresponding source language word. Note
phrasal query represented brackets, first part transliteration
second part corresponding source language word. Figure 5 shows Korean Japanese
web documents retrieved using BPS amylase Korean/Japanese transliterations,
142

fiA Comparison Machine Transliteration Models

Retrieved
RetrievedKorean
Koreanweb
webpages
pagesfor
forquery
query
{a-mil-la-a-je
amylase}
{a-mil-la-a-je amylase}

Retrieved
RetrievedJapanese
Japaneseweb
webpages
pagesfor
forquery
query
{a-mi-ra-a-je
amylase}
{a-mi-ra-a-je amylase}

Query


amylase
amylase
(
amylase)
)

amylase
(amylase)

[
amylase]
amylase]
[amylase]
a-mil-la-a-je
a-mil-la-a-jeamylase
amylase
amylase)
a-mil-la-a-je
amylase)
a-mil-la-a-je((amylase)
amylase]
a-mil-la-a-je
amylase]
a-mil-la-a-je[[amylase]


amylase
amylase
(
amylase)
)

amylase
(amylase)

[
amylase]
amylase]
[amylase]
a-mi-ra-a-je
a-mi-ra-a-jeamylase
amylase
amylase)
a-mi-ra-a-je
amylase)
a-mi-ra-a-je((amylase)
amylase]
a-mi-ra-a-je
amylase]
a-mi-ra-a-je[[amylase]

Figure 5: Desirable retrieved web pages transliteration ranking.

a-mil-la-a-je a-mi-ra-a-je. web documents retrieved BPS usually contain
transliteration corresponding source language word translation pair, one
often placed parentheses, shown Figure 5.
dilemma arises, though, regarding quality coverage retrieved web documents. Though BPS generally provides high-quality web documents contain correct
transliterations corresponding source language word, coverage relatively low,
meaning may find web documents transliterations. example, BPS Japanese phrasal query {a-ru-ka-ro-si-su alkalosis} Korean
phrasal query {eo-min ermine} found web documents. Therefore, alternative search
methods necessary BPS fails find relevant web documents. bilingual
keyword search (BKS) (Qu & Grefenstette, 2004; Huang, Zhang, & Vogel, 2005; Zhang,
Huang, & Vogel, 2005) used BPS fails, monolingual keyword search
(MKS) (Grefenstette, Qu, & Evans, 2004) used BPS BKS fail.
Like BPS, BKS makes use two keywords, transliteration source language
word, search engine query. Whereas BPS retrieves web documents containing
two keywords phrase, BKS retrieves web documents containing anywhere
document. means web frequencies noisy transliterations sometimes
higher correct transliterations BKS, especially noisy transliterations one-syllable transliterations. example, mok, Korean transliteration
produced mook one-syllable noisy transliteration, higher web frequency
mu-keu, correct transliteration mook, mok common Korean
143

fiOh, Choi, & Isahara

noun frequently appears Korean texts meaning neck. However, BKS
improve coverage without great loss quality retrieved web documents
transliterations composed two syllables.
Though BKS higher coverage BPS, fail retrieve web documents
cases. cases, MKS (Grefenstette et al., 2004) used. MKS,
transliteration alone used search engine query. BPS BKS act like
translation model, MKS acts like language model. Though MKS cannot give
information whether transliteration correct, provide information
whether transliteration likely target language word. three search methods
used sequentially (BPS, BKS, MKS). one method fails retrieve relevant web
documents, next one used. Table 15 summarizes conditions applying
search method.
Along three search strategies, three different search engines used obtain
web documents. search engines used purpose satisfy two conditions: 1) support Korean/Japanese web document retrieval 2) support phrasal
keyword searches. Google13 , Yahoo14 , MSN15 satisfy conditions, used
search engines.
Search method
BPS
BKS
MKS

Condition

P P
W FBP Sj (e, ck )) 6= 0
Pj Pck C
W FBP Sj (e, ck )) = 0
P j P ck C
W
FBKSj (e, ck )) 6= 0
Pj Pck C
W FBP Sj (e, ck ) = 0
P j P ck C
W
FBKSj (e, ck ) = 0
P j P ck C
j

ck C

W FM KSj (e, ck ) 6= 0

Table 15: Conditions search method applied.

RF (e, ci ) =

X

N W Fj (e, ci ) =

j

X
j

P

W Fj (e, ci )
ck C W Fj (e, ck )

(7)

Web frequencies acquired three search methods three search engines used rank transliterations basis Formula (7), ci ith
transliteration produced four transliteration models, e source language word
ci , RF function ranking transliterations, W F function calculating web
frequency, N W F function normalizing web frequency, C set produced transliterations, j index j th search engine. used normalized web frequency
ranking factor. normalized web frequency web frequency divided
total web frequency produced transliterations corresponding one source language
word. score transliteration calculated summing normalized
13. http://www.google.com
14. http://www.yahoo.com
15. http://www.msn.com

144

fiA Comparison Machine Transliteration Models

web frequencies transliteration given three search engines. Table 16 shows
example ranking English word data possible Korean transliterations, de-iteo, de-i-ta, de-ta, web frequencies obtained using BPS. normalized
W FBP (N W FBP ) search engine calculated follows.
N W FBP (data, de-i-teo) = 94,100 / (94,100 + 67,800 + 54) = 0.5811
N W FBP (data, de-i-ta) = 67,800 / (94,100 + 67,800 + 54) = 0.4186
N W FBP (data, de-ta) = 54 / (94,100 + 67,800 + 54) = 0.0003
ranking score de-i-teo calculated summing N W FBP (data, de-iteo) search engine:
RFBP (data, de-i-teo) = 0.5810 + 0.7957 + 0.3080 = 1.6848

Search Engine

B
C
RF

c1 = de-i-teo
WF
NWF
94,100 0.5811
101,834 0.7957
1,358
0.3080
1.6848

e=data
c2 = de-i-ta
WF
NWF
67,800 0.4186
26,132 0.2042
3,028 0.6868
1.3096

c3 = de-ta
WF NWF
54
0.0003
11
0.0001
23
0.0052
0.0056

Table 16: Example transliteration ranking data transliterations; W F , N W F ,
RF represent W FBP , N W FBP , RFBP , respectively.

6.1 Evaluation
tested performance transliteration ranking two conditions: 1)
test data (ALL) 2) test data least one transliteration model produced
correct transliteration (CTC). Testing showed overall performance
machine transliteration testing CTC showed performance transliteration ranking alone. used performance individual transliteration models
(G , P , H , C ) baseline. results shown Table 17. Top-n means
correct transliteration within Top-n ranked transliterations. average
number produced Korean transliterations 3.87 Japanese ones 4.50;
note P C produced one transliteration pronunciation
variations. results English-to-Korean English-to-Japanese transliteration
indicate ranking method effectively filters noisy transliterations positions
correct transliterations top rank; correct transliterations
Top-1. see transliteration ranking (in Top-1) significantly improved performance
individual models EKSet EJSet16 . overall performance
16. one-tail paired t-test showed performance improvement significant (level significance
= 0.001.

145

fiOh, Choi, & Isahara

transliteration (for ALL) well ranking (for CTC) relatively good. Notably, CTC performance showed web data useful language resource ranking
transliterations.
Test data




CTC

G
P
H
C
Top-1
Top-2
Top-3
Top-1
Top-2
Top-3

EKSet
58.8%
55.2%
64.1%
65.5%
71.5%
75.3%
75.8%
94.3%
99.2%
100%

EJSet
58.8%
59.2%
65.8%
69.1%
74.8%
76.9%
77.0%
97.2%
99.9%
100%

Table 17: Results Transliteration ranking.

6.2 Analysis Results
defined two error types: production errors ranking errors. production error
correct transliteration among produced transliterations. ranking
error correct transliteration appear Top-1 ranked transliterations.
examined relationship search method transliteration ranking. Table 18 shows ranking performance search method. RTC represents
correct transliterations ranked search method. NTC represents test data
ranked, is, coverage search method. ratio RTC NTC represents
upper bound performance difference RTC NTC number
errors.
best performance BPS. BPS handled 5,270 7,172 cases
EKSet 8,829 10,417 cases EJSet. is, best job retrieving
web documents containing transliteration pairs. Analysis ranking errors revealed
main cause errors BPS transliteration variations. variations
contribute ranking errors two ways. First, web frequencies transliteration
variations higher standard ones, variations ranked higher
standard ones, shown examples Table 19. Second, transliterations
include transliteration variations (i.e., correct transliterations), correct
ranking cannot be. case, ranking errors caused production errors.
BPS, 603 cases EKSet 895 cases EJSet.
NTC smaller BKS MKS BPS retrieves web documents
whenever possible. Table 18 shows production errors main reason BPS fails
retrieve web documents. (When BKS MKS used, production errors occurred
146

fiA Comparison Machine Transliteration Models

Top-1
Top-2
Top-3
RTC
NTC

BPS
83.8%
86.6%
86.6%
4,568
5,270

EKSet
BKS
MKS
55.1% 16.7%
58.4% 27.0%
58.2% 31.3%
596
275
1,024
878

BPS
86.2%
88.3%
88.35%
7,800
8,829

EJSet
BKS
19.0%
22.8%
22.9%
188
820

MKS
2.7%
4.2%
4.3%
33
768

Table 18: Ranking performance search method.

compact Korean
pathos Korean
cohen Japanese
criteria Japanese

Transliteration
kom-paek-teu
keom-paek-teu
pa-to-seu
pae-to-seu
ko-o-he-n
ko-o-e-n
ku-ra-i-te-ri-a
ku-ri-te-ri-a

Web Frequency
1,075
1,793
1,615
14,062
23
112
104
1,050

Table 19: Example ranking errors BPS used ( indicates variation).

87117 cases EKSet 22118 cases EJSet). results also show BKS
effective MKS.
trade-off quality coverage retrieved web documents important factor transliteration ranking. BPS provides better quality rather wider
coverage, effective since provides reasonable coverage.

7. Conclusion
tested compared four transliteration models, grapheme-based transliteration
model (G ), phoneme-based transliteration model (P ), hybrid transliteration
model (H ), correspondence-based transliteration model (C ), English-toKorean English-to-Japanese transliteration. modeled framework four
transliteration models compared within framework. Using results,
examined way improve performance machine transliteration.
found H C effective G P . main reason
better performance C uses correspondence source
grapheme source phoneme. use correspondence positively affected
transliteration performance various tests.
17. 596 (RTC BKS EKSet) + 275 (RTC MKS EKSet) = 871
18. 188 (RTC BKS EJSet) + 33 (RTC MKS EJSet) = 221

147

fiOh, Choi, & Isahara

demonstrated G , P , H , C used complementary transliteration models improve chances producing correct transliterations. combination
four models produced correct transliterations English-to-Korean transliteration English-to-Japanese transliteration compared model alone. Given
results, described way improve machine transliteration combines different
transliteration models: 1) produce list transliterations combining transliterations produced multiple transliteration models; 2) rank transliterations
basis relevance.
Testing showed transliteration ranking based web frequency effective way
calculate relevance transliterations. web data reflects real-world
usage, used filter noisy transliterations, used target
language words incorrect transliterations source language word.
several directions future work. Although considered transliteration variations, test sets mainly covered standard transliterations. corpora
web pages, however, routinely find types transliterations misspelled transliterations, transliterations common phrases, etc. along standard transliterations transliteration variations. Therefore, testing using transliterations
needed enable transliteration models compared precisely. achieve
machine transliteration system capable higher performance, need sophisticated transliteration method sophisticated ranking algorithm. Though many
correct transliterations acquired combination four transliteration
models, still transliterations none models produce. need
devise method produce them. transliteration ranking method works well,
but, depends web data, faces limitations correct transliteration
appear web data. need complementary ranking method handle cases.
Moreover, demonstrate effectiveness four transliteration models, need
apply various natural language processing applications.

Acknowledgments
grateful Claire Cardie anonymous reviewers providing constructive
insightful comments earlier drafts paper.

References
Aha, D. W. (1997). Lazy learning: Special issue editorial. Artificial Intelligence Review,
11:710.
Aha, D. W., Kibler, D., & Albert, M. (1991). Instance-based learning algorithms. Machine
Learning, 6 (3766).
Al-Onaizan, Y., & Knight, K. (2002). Translating named entities using monolingual
bilingual resources. Proceedings ACL 2002, pp. 400408.
Andersen, O., Kuhn, R., Lazarides, A., Dalsgaard, P., Haas, J., & Noth, E. (1996). Comparison two tree-structured approaches grapheme-to-phoneme conversion.
Proceedings ICSLP 1996, pp. 18081811.
148

fiA Comparison Machine Transliteration Models

Berger, A. L., Pietra, S. D., & Pietra, V. J. D. (1996). maximum entropy approach
natural language processing. Computational Linguistics, 22 (1), 3971.
Bilac, S., & Tanaka, H. (2004). Improving back-transliteration combining information
sources. Proceedings IJCNLP2004, pp. 542547.
Breen, J. (2003). EDICT Japanese/English dictionary .le. Electronic Dictionary Research Development Group, Monash University. http://www.csse.monash.edu.
au/~jwb/edict.html.
Chen, S. F. (2003). Conditional joint models grapheme-to-phoneme conversion.
Proceedings Eurospeech, pp. 20332036.
CMU (1997). CMU pronouncing dictionary version 0.6. http://www.speech.cs.cmu.
edu/cgi-bin/cmudict.
Cover, T. M., & Hart, P. E. (1967). Nearest neighbor pattern classification. Institute
Electrical Electronics Engineers Transactions Information Theory, 13 (2127).
Daelemans, W., Zavrel, J., Sloot, K. V. D., & Bosch, A. V. D. (2004). TiMBL: Tilburg
Memory-Based Learner - version 5.1 reference guide. Tech. rep. 04-02, ILK Technical
Report Series.
Daelemans, W., & van den Bosch, A. (1996). Language-independent data-oriented
grapheme-to-phoneme conversion. J. Van Santen, R. Sproat, J. O., & Hirschberg,
J. (Eds.), Progress Speech Synthesis, pp. 7790. Springer Verlag, New York.
Damper, R. I., Marchand, Y., Adamson, M. J., & Gustafson, K. (1999). Evaluating
pronunciation component text-to-speech systems English: performance comparison different approaches. Computer Speech Language, 13 (2), 155176.
Devijver, P. A., & Kittler., J. (1982). Pattern recognition: statistical approach. PrenticeHall.
Fujii, A., & Tetsuya, I. (2001). Japanese/English cross-language information retrieval: Exploration query translation transliteration. Computers Humanities,
35 (4), 389420.
Goto, I., Kato, N., Uratani, N., & Ehara, T. (2003). Transliteration considering context
information based maximum entropy method. Proceedings MT-Summit
IX, pp. 125132.
Grefenstette, G., Qu, Y., & Evans, D. A. (2004). Mining web create language
model mapping English names phrases Japanese. Proceedings
Web Intelligence, pp. 110116.
Huang, F., Zhang, Y., & Vogel, S. (2005). Mining key phrase translations web corpora. Proceedings Human Language Technology Conference Conference
Empirical Methods Natural Language Processing, pp. 483490.
Jeong, K. S., Myaeng, S. H., Lee, J. S., & Choi, K. S. (1999). Automatic identification
back-transliteration foreign words information retrieval. Information Processing
Management, 35 (1), 523540.
149

fiOh, Choi, & Isahara

Jung, S. Y., Hong, S., & Paek, E. (2000). English Korean transliteration model
extended markov window. Proceedings 18th conference Computational
linguistics, pp. 383 389.
Kang, B. J. (2001). resolution word mismatch problem caused foreign word transliterations English words Korean information retrieval. Ph.D. thesis, Computer
Science Dept., KAIST.
Kang, B. J., & Choi, K. S. (2000). Automatic transliteration back-transliteration
decision tree learning. Proceedings 2nd International Conference Language
Resources Evaluation, pp. 11351411.
Kang, I. H., & Kim, G. C. (2000). English-to-Korean transliteration using multiple unbounded overlapping phoneme chunks. Proceedings 18th International Conference Computational Linguistics, pp. 418424.
Kim, J. J., Lee, J. S., & Choi, K. S. (1999). Pronunciation unit based automatic EnglishKorean transliteration model using neural network. Proceedings Korea Cognitive
Science Association, pp. 247252.
Knight, K., & Graehl, J. (1997). Machine transliteration. Proceedings 35th Annual
Meetings Association Computational Linguistics, pp. 128135.
Korea Ministry Culture & Tourism (1995). English Korean standard conversion rule.
http://www.hangeul.or.kr/nmf/23f.pdf.
Lee, J. S. (1999). English-Korean transliteration retransliteration model Crosslingual information retrieval. Ph.D. thesis, Computer Science Dept., KAIST.
Lee, J. S., & Choi, K. S. (1998). English Korean statistical transliteration information
retrieval. Computer Processing Oriental Languages, 12 (1), 1737.
Li, H., Zhang, M., & Su, J. (2004). joint source-channel model machine transliteration.
Proceedings ACL 2004, pp. 160167.
Lin, W. H., & Chen, H. H. (2002). Backward machine transliteration learning phonetic similarity. Proceedings Sixth Conference Natural Language Learning
(CoNLL), pp. 139145.
Manning, C., & Schutze, H. (1999). Foundations Statistical natural language Processing.
MIT Press.
Meng, H., Lo, W.-K., Chen, B., & Tang, K. (2001). Generating phonetic cognates
handle named entities English-Chinese cross-language spoken document retrieval.
Proceedings Automatic Speech Recognition Understanding, 2001. ASRU 01,
pp. 311314.
Mitchell, T. M. (1997). Machine learning. New-York: McGraw-Hill.
Nam, Y. S. (1997). Foreign dictionary. Sung Dang.
Oh, J. H., & Choi, K. S. (2002). English-Korean transliteration model using pronunciation contextual rules. Proceedings COLING2002, pp. 758764.
Pagel, V., Lenzo, K., & Black, A. W. (1998). Letter sound rules accented lexicon compression. Proceedings International Conference Spoken Language Processing,
pp. 20152018.
150

fiA Comparison Machine Transliteration Models

Qu, Y., & Grefenstette, G. (2004). Finding ideographic representations Japanese names
written Latin script via language identification corpus validation.. Proc.
ACL, pp. 183190.
Quinlan, J. R. (1986). Induction decision trees. Machine Learning, 1, 81106.
Quinlan, J. R. (1993). C4.5: Programs Machine Learning. Morgan Kauffman.
Stalls, B. G., & Knight, K. (1998). Translating names technical terms arabic text.
Proceedings COLING/ACL Workshop Computational Approaches Semitic
Languages, pp. 3441.
Zhang, L. (2004). Maximum entropy modeling toolkit python C++. http://
homepages.inf.ed.ac.uk/s0450736/software/maxent/manual.pdf.
Zhang, Y., Huang, F., & Vogel, S. (2005). Mining translations OOV terms web
cross-lingual query expansion. Proceedings 28th annual international
ACM SIGIR conference Research development information retrieval, pp.
669670.

151

fiJournal Artificial Intelligence Research 27 (2006) 381-417

Submitted 3/06; published 11/06

Multi-Issue Negotiation Deadlines
Shaheen S. Fatima
Michael Wooldridge

S.S.FATIMA @ CSC . LIV. AC . UK
M.J.W OOLDRIDGE @ CSC . LIV. AC . UK

Department Computer Science,
University Liverpool, Liverpool L69 3BX, U.K.

Nicholas R. Jennings

NRJ @ ECS . SOTON . AC . UK

School Electronics Computer Science,
University Southampton, Southampton SO17 1BJ, U.K.

Abstract
paper studies bilateral multi-issue negotiation self-interested autonomous agents.
Now, number different procedures used process; three main
ones package deal procedure issues bundled discussed together,
simultaneous procedure issues discussed simultaneously independently
other, sequential procedure issues discussed one another. Since
yields different outcome, key problem decide one use
circumstances. Specifically, consider question model agents time
constraints (in form deadlines discount factors) information uncertainty (in
agents know opponents utility function). model, consider issues
independent interdependent determine equilibria case
procedure. doing, show package deal fact optimal procedure
party. go show that, although package deal may computationally complex two procedures, generates Pareto optimal outcomes (unlike two),
similar earliest latest possible times agreement simultaneous procedure (which
better sequential procedure), (like two procedures) generates unique
outcome certain conditions (which define).

1. Introduction
Negotiation key form interaction multiagent systems (Maes, Guttman, & Moukas, 1999;
Sandholm, 2000). process disputing agents decide divide gains
cooperation. Since decision made jointly agents (Rosenschein & Zlotkin,
1994; Raiffa, 1982; Pruitt, 1981; Fisher & Ury, 1981; Young, 1975; Kraus, 2001), agent
obtain prepared allow them. Now, simplest form negotiation
involves two agents single-issue. example, consider scenario buyer
seller negotiate price good. begin, two agents likely differ price
believe trade take place, process joint decision-making
either arrive price mutually acceptable fail reach agreement. Since agents
likely begin different prices, one must move toward other,
series offers counter offers, order obtain mutually acceptable outcome. However,
agents actually perform negotiations, must decide rules making
offers counter offers. is, must set negotiation protocol (Lax & Sebenius, 1986;
Osborne & Rubinstein, 1990; Rosenschein & Zlotkin, 1994; Kraus, Wilkenfeld, & Zlotkin, 1995;
Lomuscio, Wooldridge, & Jennings, 2003).
c
2006
AI Access Foundation. rights reserved.

fiFATIMA , W OOLDRIDGE , & J ENNINGS

basis protocol, agent chooses strategy (i.e., offers make
course negotiation). competitive scenarios self-interested agents, participant defines strategy maximise individual utility. Furthermore, scenarios,
agents optimal strategy depends strongly information opponent (Fatima,
Wooldridge, & Jennings, 2002, 2004). example, strategy buyer would use knew
sellers reserve price differs one would use not. this,
seen outcome single-issue negotiation depends four key factors (Harsanyi, 1977):
negotiation protocol, players strategies, players preferences possible outcomes,
information players other. However, bilateral negotiations,
parties involved need settle one issue. example, agents may need come
agreements objects/services characterised attributes price, delivery time,
quality, reliability, on. multi-issue negotiations, outcome also depends one
additional factor: negotiation procedure (Schelling, 1956, 1960; Fershtman, 1990), specifies issues settled. Broadly speaking, three ways negotiating multiple
issues (Keeney & Raiffa, 1976; Raiffa, 1982):
Package deal: approach links issues discusses together bundle.
Simultaneous negotiation: involves settling issues simultaneously, independently,
other.
Sequential negotiation: involves negotiating issues sequentially, one another.
Now, three different procedures different properties yield different outcomes
negotiators (Fershtman, 2000). key question answer is: best? Here,
since concerned self-interested agents, notion optimal procedure one
maximises agents individual return. However, optimality part story;
given motivations also concerned Pareto optimality solutions
procedures (because Pareto optimality ensures utility go wasted), computational
complexity procedures (because scenarios information uncertainty, agents need
compute equilibrium offers process negotiation, opposed complete information scenario strategies precompiled), actual time agreement (because
scenarios information uncertainty, time depends agents beliefs opponent agreement may occur first time period), uniqueness solutions
generate (because allows agents know actual shares).
One immediate observation vein package deal gives rise possibility
making tradeoffs across issues. tradeoffs possible different agents value different
issues differently. example, two issues one agent values first
second, agent values second issue first, possible make
tradeoffs thereby improve utility agents relative situation without tradeoffs.
contrast, simultaneous sequential approaches, issues settled independently
scope tradeoffs them. Moreover, seek answer question
optimality types situation commonly faced agents real-world contexts.
Thus, consider negotiations are:
1. Time constraints. Agents time constraints form deadlines discount
factors. view deadlines essential element since negotiation cannot go indefinitely, rather must end within reasonable time limit (Livne, 1979). Likewise, discount
382

fiM ULTI -I SSUE N EGOTIATION



EADLINES

factors essential since desirability good traded often declines time.
happens either good perishable due inflation. Moreover, strategic
behaviour agents deadlines discount factors differs without (see Rubinstein, 1982, single issue bargaining without deadlines Sandholm & Vulkan, 1999;
& Manove, 1993; Fershtman & Seidmann, 1993; Kraus, 2001, bargaining deadlines discount factors). instance, presence deadline induces negotiator
play strategy ensures best possible agreement deadline reached.
Likewise, presence discount factor means reaching agreement today
reaching tomorrow. Hence, agents try reach agreement sooner rather
later.
2. Uncertainty opponents negotiation parameters. information agents
negotiation opponent likely uncertain (see Fudenberg & Tirole, 1983;
Fudenberg, Levine, & Tirole, 1985; Rubinstein, 1985, single issue bargaining uncertainty). Moreover, bargaining situations, one players may know something
relevance not. example, bargaining price second
hand car, seller knows quality, buyer not. situations said
asymmetry information players (Muthoo, 1999). hand, symmetric information situations players information. Again, agents
operate situations analyse cases.
3. Interdependence issues. issues negotiation may independent interdependent. former case, agents utility issue depends agreement
reached it, issues settled. latter case, agents
utility issue depends agreement reached also
issues settled (Bar-Yam, 1997; Klein, Faratin, Sayama, & Bar-Yam, 2003).
situations common multiagent systems analyse cases.
Thus study five different settings: i) complete information setting (CI), ii) setting
independent issues symmetric uncertainty agents utilities (SUI ), iii) setting
independent issues asymmetric uncertainty agents utilities (AUI ), iv) setting
interdependent issues symmetric uncertainty agents utilities (SUD ), v) setting
interdependent issues asymmetric uncertainty agents utilities (AUD ).
methodology first derive equilibria procedures
settings, this, determine optimal. see, analysis shows
that, settings, package deal best. go analyse procedures
terms performance metrics. Specifically, show that, settings, package
deal generates Pareto optimal outcome. also show although package deal may computationally complex two procedures, similar earliest latest possible
times agreement simultaneous procedure (which better sequential procedure),
(like two procedures) generates unique outcome certain situations (which
define). key results study summarised Table 1.
previously formal comparison different procedures find optimal
one (see Section 7 details). However, work least one following major
limitations. First, focused comparing procedures negotiation without deadlines. Note
existing work obtained equilibrium negotiation deadlines, single
383

fiFATIMA , W OOLDRIDGE , & J ENNINGS

Information
setting
CI
Time
agreement
tc

Time
compute
equilibrium
Pareto
optimal?
Unique
equilibrium?

SUI , SUD
AUI , AUD
CI
SUI SUD
AUI AUD
CI,
SUI ,SUD ,
AUI , AUD
CI
SUI ,SUD ,
AUI , AUD

Package deal

Simultaneous

Sequential

cth issue
tc = 1
1 c
cth issue
tec = 1
tlc = min(2r 1, n)
1 c

cth issue
tc = 1
1 c
cth issue
tec = 1
tlc = min(2r 1, n)
1 c

cth partition
tc = c
1 c
cth partition
tec = tsc
tlc = tsc + min(2r 1, n)
1 c

O(mn)
O(mr 3 (n T2 ))

O(M n)
O(|Sz |z r 3 (n T2 ))

O(mr3 (n


2)2)

O(|Sz |z r3 (n


2)2

)

O(M n)
O(|Sz |z r 3 (n
O(|Sz |z r3 (n

Yes





C1
C3 C4

C2
C5

C2
C5

Table 1: summary key results. tsc denotes start time cth partition, tec earliest
possible time agreement, tlc latest possible time agreement).

issue case (Sandholm & Vulkan, 1999; Stahl, 1972), special type sequential procedure
multiple issues (Fatima et al., 2004). See Section 7 details. Second, focussed
independent issues asymmetric information settings. Third, focused finding
optimal procedure, considered additional solution properties different procedures.
Given this, paper makes threefold contribution. First, obtain equilibrium
procedure deadlines. Second, analyse multiple issues independent
interdependent. Moreover, analyse symmetric asymmetric information settings.
Finally, basis equilibrium different procedures, provide first comprehensive
comparison solution properties (viz. time complexity, Pareto optimality, uniqueness,
time agreement). taken together, results clearly indicate choices tradeoffs
involved choosing negotiation procedure wide range circumstances. knowledge
used system designer responsible designing mechanism
used moderate negotiation encounters agents choose
arrange interactions. Furthermore, knowledge also tells agents equilibrium
offers negotiation.
remainder paper organised follows. begin giving brief overview
single-issue negotiation Section 2. Section 3, study three multi-issue procedures
setting complete information issues independent. study undertaken
provide foundation Sections 4, 5, 6, treat information agents
utilities uncertain. specifically, Section 4, analyse scenario symmetric uncer384


2


2 ))

) T2 )

fiM ULTI -I SSUE N EGOTIATION



EADLINES

tainty opponents utility. Section 5, analyse scenario asymmetric uncertainty
opponents utility. Sections 4 5 deal independent issues. Section 6,
extend analysis interdependent issues. Section 7 discusses related literature Section 8
concludes. Appendix provides summary notation employed throughout paper.

2. Single-Issue Negotiation
Assume two agents: b. agent time constraints form deadlines
discount factors. Since focus competitive scenarios self-interested agents, model
negotiation using split pie game analysed Osborne Rubinstein (1994), Binmore,
Osborne, Rubinstein (1992). begin introducing complete information game.
Let two agents negotiating single issue (i). issue pie size 1
agents want determine divide themselves. deadline (i.e., number
rounds negotiation must end). Let n N+ denote deadline. agents use
Rubinsteins alternating offers protocol (Osborne & Rubinstein, 1994), proceeds
series time periods. One agents, say a, starts negotiation first time period (i.e., = 1)
making offer (xi ), lies interval [0, 1], b. Agent b either accept reject
offer. accepts, negotiation ends agreement getting share xi b getting
yi = 1 xi . Otherwise, negotiation proceeds next time period, agent b makes
counter-offer. process making offers continues one agents either accepts offer
quits negotiation (resulting conflict). Thus, three possible actions agent take
time period: accept last offer, make new counter-offer, quit negotiation.
essential feature negotiations involving alternating offers pie assumed
shrink time (Rubinstein, 1982). Specifically, shrinks step offer counteroffer.
shrinkage models decrease value pie (representing fact pie perishes
time inflation). shrinkage represented discount factor denoted 0 <
1 both1 agents. = 1, size pie 1, subsequent time periods > 1,
pie shrinks it1 .
denote set real numbers R set real numbers interval [0, 1] R1 .
let [xti , yit ] denote offer made time period xti yit denote share agent
b respectively. Then, given pie, set possible offers is:
{[xti , yit ] : xti 0, yit 0, xti + yit = it1 }
xti R1 yit R1 . players utility function defined set R. Let uai :
R1 N+ R ubi : R1 N+ R denote utility functions two agents. time t,
b receive share xti yit respectively (where xti + yit = it1 ), utilities are:

xi n

ui (xi , t) =
0 otherwise
ubi (yit , t)

=



yit n
0 otherwise

1. different discount factor different agents makes presentation involved without leading
changes analysis strategic behaviour agents time complexity finding equilibrium
offers. Hence single discount factor agents.

385

fiFATIMA , W OOLDRIDGE , & J ENNINGS

conflict utility (i.e., utility received event deal struck) zero
agents. Note shown explicitly agents utility function implicit.
because, time period t, xti yit denote bs actual shares respectively (not
ratios shares) xti + yit = it1 . words included agents share.
become clearer show agents shares Expression 1.
setting, agents reason follows order determine offer. Let agent
denote first mover (i.e., = 1, proposes b split pie). begin, consider
case deadline agents n = 1. b accepts, division occurs agreed; not,
neither agent gets anything (since n = 1 deadline). Here, powerful position
able propose keep 100 percent pie give nothing b 2 . Since deadline n = 1,
b accepts offer agreement takes place first time period.
Now, consider case deadline n = 2. first round, size pie 1
shrinks second round. order decide offer first round, looks
ahead = 2 reasons backwards3 . Agent reasons negotiation proceeds second
round, b take 100 percent shrunken pie offering [0, ] leave nothing a. Thus,
first time period, offers b anything less , b reject offer. Hence,
first time period, agent offers [1 , ]. Agent b accepts agreement occurs first
time period.
general, deadline n, negotiation proceeds follows. before, agent decides
offer first round looking ahead far = n reasoning backwards.
decision making leads make following offer first time period:
n1
n1
[j=0
[(1)j ij ], 1 j=0
[(1)j ij ]]

(1)

Agent b accepts offer negotiation ends first time period. Note equilibrium
outcome depends makes first move. Since two agents either could
move first, get two possible equilibrium outcomes.
basis equilibrium single-issue negotiation complete information,
first obtain equilibrium multiple issues determine optimal negotiation procedure
various settings previously described.

3. Multi-Issue Negotiation Complete Information
mentioned Section 1, existing literature provide analysis multi-issue
procedures negotiation deadlines. Hence, begin analysing complete information
setting. base, extend case information uncertainty.
b negotiate > 1 independent issues (Section 6 deals interdependent
issues). issues distinct pies agents want determine split them.
Let = {1, 2, . . . , m} denote set pies. before, pie size 1. Let discount
factor issue c, 1 c m, 0 < c 1. issue, let n denote agents
2. possible b may reject proposal. practice, propose offer enough
induce b accept. However, keep exposition simple, assume get whole pie making
100 percent proposal.
3. backward reasoning method adopted (Stahl, 1972). model generalisation (Stahl, 1972);
time period t, agent model propose offer zero t1 (because size pie
t1 ), player (Stahl, 1972) given fixed number alternatives choose from.

386

fiM ULTI -I SSUE N EGOTIATION



EADLINES

deadline. offer time period (where 1 n), agent (bs) share


issues represented element vector xt Rm
1 (y R1 ). Thus, agent share
issue c time xtc , agent bs share yct = (ct1 xtc ). shares b together
represented package [xt , ].
define agents cumulative utility using additive form. two reasons this.
First, common form cumulative utilities traditional multi-issue utility theory
(Keeney & Raiffa, 1976). Second, additive cumulative utilities linear problem
+

making tradeoffs becomes computationally tractable4 . functions U : Rm
1 R1 N R
b


+
U : R1 R1 N R give cumulative utilities b respectively time t.
defined follows:
(


c=1 kc uc (xc , t) n
(2)
U ([xt , ], t) =
0
otherwise
U b ([xt , ], t) =

(

b b

c=1 kc uc (yc , t)
0

n
otherwise

(3)

b

ka Rm
+ denotes element vector constants agent k R+ b.
R+ denotes set positive real numbers. vectors indicate agents value different
, agent values issue c issue c + 1. Likewise
issues. example, kca > kc+1
agent b. words, issues perfect substitutes (i.e., matters agent
total utility issues subset Varian, 2003; Mas-Colell,
Whinston, & Green, 1995). settings study, issues perfect substitutes.
agent complete information negotiation parameters (i.e., n, m, kca , kcb , c
1 c m). complete information setting, determine equilibrium
package deal, simultaneous procedure, sequential procedure.

3.1 Package Deal Procedure
procedure, agents use protocol single-issue negotiation (described Section 2). However, offer package deal includes proposal issue negotiation.
Thus, issues, offer includes divisions, one issue. Agents allowed either
accept complete offer (i.e., issues) reject complete offer. agreement therefore
take place either issues none them.
per single-issue negotiation, agent decides offer looking ahead reasoning
backwards. However, since offer package deal includes share issues,
agents make tradeoffs across issues order maximise cumulative utilities.
1 c m, equilibrium offer issue c time denoted [atc , btc ] atc btc denote
shares agent b respectively. denote equilibrium package time [at , bt ]
4. Using form additive one make function nonlinear. Consequently agents tradeoff problem
becomes global optimization problem nonlinear objective function. Due computational complexity,
nonlinear optimization problems solved using approximation methods (Horst & Tuy, 1996; BarYam, 1997; Klein et al., 2003). Moreover, methods general depend cumulative
utilities actually defined. order overcome difficulty, used additive form defining cumulative
utilities. Consequently, tradeoff problem linear optimization problem, exact solution
found polynomial time (as shown Theorems 1 2). Although results apply defined additive
cumulative utilities, Section 6.4 discuss would hold nonlinear utilities.

387

fiFATIMA , W OOLDRIDGE , & J ENNINGS



Rm
1 (b R1 ) element vector denotes (bs) share
issues. Also, 1 n, t1 Rm
1 element vector represents sizes
pies time t. symbol 0 denotes element vector zeroes. Note 1 n,
+ bt = t1 (i.e., sum agents shares (at time t) pie equal size
pie t). Finally, time period (for 1 n) let a(t) (respectively b(t)) denote
equilibrium strategy agent (respectively b).
mentioned Section 1, package deal allows agents make tradeoffs. let TRADEOFFA
(TRADEOFFB ) denote agent (bs) function making tradeoffs. Given this, following theorem characterises equilibrium package deal procedure.

Theorem 1 package deal procedure, following strategies form Nash equilibrium.
equilibrium strategy = n is:

OFFER [n1 , 0] TURN
a(n) =
ACCEPT
bs TURN
b(n) =



OFFER [0, n1 ] bs TURN
ACCEPT
TURN

preceding time periods < n, [xt , ] denotes offer made time t, equilibrium
strategies defined follows:

OFFER tradeoffa(ka , kb , , ub(t), m, t)
TURN
a(t) =



(U ([x , ], t) ua(t)) ACCEPT else REJECT bs TURN
b(t) =



OFFER tradeoffb(ka , kb , , ua(t), m, t)
bs TURN
(U b ([xt , ], t) ub(t)) ACCEPT else REJECT TURN

ua(t) = U ([at+1 , bt+1 ], + 1) ub(t) = U b ([at+1 , bt+1 ], + 1). agreement takes
place = 1.
Proof: look ahead last time period (i.e., = n) reason backwards. begin,
negotiation reaches deadline (n), agent whose turn takes everything leaves
nothing opponent. Hence, get strategies a(n) b(n) given statement
theorem.
preceding time periods (t < n), offering agent proposes package gives
opponent cumulative utility equal opponent would get equilibrium offer
next time period. time period t, either b could offering agent. Consider
case makes offer t. package offers gives b cumulative utility
U b ([at+1 , bt+1 ], + 1). However, since one issue, one package
gives b cumulative utility U b ([at+1 , bt+1 ], + 1). among packages, offers
one maximises cumulative utility (because utility maximiser). Thus, problem
find package [at , bt ] to:
maximise




c=1 kc ac
t1

atc )kcb = ub(t)
c=1 (c

0 atc 1
388

1 c

(4)

fiM ULTI -I SSUE N EGOTIATION



EADLINES

tradeoff problem similar fractional knapsack problem (Martello & Toth, 1990; Cormen, Leiserson, Rivest, & Stein, 2003), optimal solution generated using
greedy approach5 (i.e., filling knapsack items decreasing order value per unit
weight). items knapsack problem analogous issues case. difference fractional knapsack problem starts empty knapsack aims fill
items maximise cumulative value, agents tradeoff problem viewed
starting agent 100 per cent issues aiming give away portions
issues opponent latter gets given cumulative utility, resulting loss
utility minimised. Thus, order find split issues, agent considers
kca /kcb 1 c kca /kcb utility needs give order increase bs utility
one. Since wants maximise utility give b utility U b ([at+1 , bt+1 ], + 1),
divides pies gets maximum possible share issues kca /kcb
high gives agent b maximum possible share issues kca /kcb low. Thus,
begins giving b maximum possible share issue lowest kca /kcb .
issue next lowest kca /kcb repeats process b gets cumulative
utility U b ([at+1 , bt+1 ], + 1). order facilitate process making tradeoffs, individa /k b . function tradeoffa takes six
ual elements kb arranged kca /kcb > kc+1
c+1
parameters: ka , kb , , ub(t), m, uses described greedy method solve
maximisation problem given Equation 4 return corresponding package.
one package solves Equation 4, tradeoffa returns one (because agent
gets equal utility packages agent b). function tradeoffb
agent b analogous a.
hand, equilibrium strategy agent receives offer follows.
time period t, let b denote receiving agent. Then, b accepts [xt , ] ub(t) U b ([xt , ], t), otherwise rejects offer get higher utility next time period. equilibrium
strategy receiving agent defined analogously. Hence get equilibrium strategies
(a(t) b(t)) given statement theorem.
way, reason backwards obtain offers = 1. first mover makes
offer agent accepts it. agreement therefore occurs first time period.
Theorem 2 package deal procedure, time taken determine equilibrium offer
= 1 O(mn) number issues n deadline.
Proof: know Theorem 1 time compute equilibrium offer = n linear
number issues (see strategies a(n) b(n)). Consider time period < n. time
period, function tradeoffa used make tradeoffs. time complexity tradeoffa
(which uses greedy approach described proof Theorem 1) O(m) (Martello & Toth,
1990; Cormen et al., 2003). function needs repeated every time period
(n 1)th first. Hence time complexity finding offer first time period
O(mn).
5. time complexity approach O(m) (Martello & Toth, 1990), denotes number items. Note
greedy method fractional knapsack problem takes O(m) time regardless whether coefficients
kca kcb (for 1 c m) Equation 4 positive negative (Martello & Toth, 1990). present setting
(as mentioned beginning Section 3) coefficients positive. However, come across
negative coefficients deal interdependent issues Section 6.

389

fiFATIMA , W OOLDRIDGE , & J ENNINGS

Theorem 3 package deal procedure generates Pareto optimal outcome.
Proof: Recall consider competitive negotiations. Hence, individual issue c (where
1 c m), increase one agents utility results decrease other. However,
package deal procedure, agent considers cumulative utility issues. Consequently, process backward reasoning, time < n, agent makes tradeoffs
maximises cumulative utility without lowering opponent (with respect
opponent would offer next time period). Hence equilibrium outcome package deal
Pareto optimal.
Theorem 4 given first mover, package deal procedure unique equilibrium outcome
following condition false:
C1 . exists j (where 1 1 j m) (i 6= j)
(kia /kib = kja /kjb ).
Proof: Consider time period < n let denote offering agent. Recall Theorem 1
splits issues increasing order kia /kib . Thus, given j, kia /kib = kja /kjb ,
agent indifferent two issues (i j) splits first. example,
= 2, n = 2, = 0.5, k1a = 1, k2a = 2, k1b = 2, k2b = 4, k1a /k1b = k2a /k2b = 0.5.
offering agent = 1, offer (1, 0) issue 1 (1/4, 3/4) issue 2. gives
cumulative utility 1.5 3 b. Alternatively offer (0, 1) issue 1 (3/4, 1/4)
issue 2 since also results cumulative utilities b.
hand, kia /kib 6= kja /kjb , splits issue first kia /kib < kja /kjb issue j first
kia /kib > kja /kjb . words, one possible equilibrium offer make
time < n. Likewise one possible equilibrium offer b make time < n.
Since unique offer time period, equilibrium outcome unique.
Note uniqueness refer Theorem 4 respect given first mover.
first mover changes, equilibrium outcome may change, following example illustrates.
Let = 2, n = 2, = 0.5, k1a = 1, k2a = 2, k1b = 2, k2b = 1. offering agent
= 1, equilibrium offer (1/4, 3/4) first issue (1, 0) second. results
cumulative 2.25 1.5 b. contrast, b offering agent = 1, equilibrium
offer (0, 1) first issue (3/4, 1/4) second. results cumulative utility
1.5 2.25 b. following discussion, use term unique mean unique
respect given first mover.
3.2 Simultaneous Procedure
procedure, issues partitioned > 1 disjoint subsets. 1 c , let
Sc denote cth partition c=1 Sc = {1, . . . , m}. issues within subset settled
using package deal. Negotiation partitions starts = 1. Thus, = m,
issues settled simultaneously independently other. extreme,
one partition (i.e., = 1) package deal procedure described Section 3.1. Since
issues subset (i.e., Sc ) settled using package deal, equilibrium
partitions obtained Theorem 1. Consequently, get following results.
First, agreement issue occurs first round. negotiation
partition starts = 1. Also, Theorem 1, know agreement package deal
390

fiM ULTI -I SSUE N EGOTIATION



EADLINES

occurs = 1. Hence, simultaneous procedure, agreement partition (and hence
issue) occurs first time period.
Second, simultaneous procedure, time taken determine equilibrium offer
= 1 c=1 O(|Sc |n) |Sc | number issues cth partition n deadline.
explained follows. Since time taken find equilibrium offer = 1
package deal (i.e., = 1) O(mn) (see Theorem 2), time taken compute equilibrium
offer = 1 cth partition O(|Sc |n). Hence, partitions, time complexity
c=1 O(|Sc |n) equal O(M n), denotes number issues largest
partition.
Third, follows Theorem 4 simultaneous procedure unique equilibrium
outcome following condition C2 true:
C2 . partition c (where 1 c ) condition C1 true.
Finally, Theorem 5 shows, simultaneous procedure may generate Pareto optimal
outcome.
Theorem 5 simultaneous procedure may generate Pareto optimal outcome.
Proof: package deal allows tradeoffs made across issues, simultaneous
procedure allows tradeoffs made across issues within partition across partitions.
Hence simultaneous procedure may generate Pareto optimal outcome. show
counter example. Consider case n = 2, = 0.5, = 3, = 2, S1 = {1, 2}, S2 = {3},
k1a = 1, k2a = 2, k3a = 3, k1b = 1, k2b = 0.5, k3b = 0.25. Let denote first mover.
Theorem 1, know equilibrium partition S1 , agent gets share 0.25 issue
1 1 issue 2, b gets share 0.75 issue 1 nothing issue 2. partition S2 ,
agent gets share 1/2. Thus, cumulative utility three issues 3.75
b 0.875.
consider case three issues discussed using package deal. Here, = 1
parameters remain same. equilibrium outcome procedure, gets
cumulative utility 5.125 b gets 0.875. means procedure = 2
generate Pareto optimal outcome.
3.3 Sequential Procedure
procedure, issues partitioned > 1 disjoint subsets. 1 c , let Sc
denote cth partition c=1 Sc = {1, . . . , m}. partitions negotiated sequentially,
one another. issues within subset settled using package deal. Negotiation
first partition starts time = 1. negotiation cth (for 1 c ) partition ends tc ,
negotiation (c + 1)th partition starts time tc + 1. player gets share
issues partition soon partition settled. Thus, = m, issues settled
sequence. extreme, one partition (i.e., = 1) package
deal procedure described Section 3.1. Since issues subset (i.e., Sc ) settled
using package deal, equilibrium subsets obtained Theorem 1
substituting appropriate negotiation start times partition.

391

fiFATIMA , W OOLDRIDGE , & J ENNINGS

Theorem 6 sequential procedure, equilibrium time agreement cth partition
(for 1 c ) Tc = c.
Proof: Theorem 1, know agreement package deal occurs first time
period. Hence, negotiation partition ends time period starts (i.e.,
negotiation cth partition starts = c results agreement time period).
time taken settle issues therefore .
Note time complexity sequential procedure (i.e., time compute equilibrium
offers) simultaneous procedure. Also, like simultaneous procedure,
equilibrium outcome sequential procedure may Pareto optimal. Finally, condition
equilibrium outcome sequential procedure unique
simultaneous procedure.
3.4 Optimal Procedure
obtained equilibrium outcomes three multi-issue procedures, compare
terms utilities generate player. procedure gives player
maximum utility optimal one.
Note that, sequential procedure, equilibrium outcome strongly depends order
partitions settled. ordering called negotiation agenda. two
ways defining agenda (Fershtman, 1990): exogenously endogenously. agenda
determined actual negotiation issues begins, said exogenous.
hand, endogenous agenda, agents decide issue settle next
process negotiation. agenda gives agent maximum utility possible
agendas optimal one (Fatima et al., 2004). objective determine optimal
agenda, consider given agenda compare equilibrium outcome sequential
procedure agenda outcomes simultaneous package deal procedures,
order find optimal procedure. following theorem characterises procedure.
Theorem 7 Irrespective issues split > 1 partitions, package deal
optimal parties.
Proof: order compare agents utility different procedures, important take
account initiates negotiation. package deal, first mover makes offer
issues. Hence compare agents utilities three procedures, given agent
first mover three procedures issues.
first show outcome package deal worse simultaneous
procedure. Consider simultaneous procedure > 1. procedure, n,
offering agent makes tradeoffs across issues partition independently partitions. consider package deal procedure (i.e., = 1 partitions). procedure,
offering agent makes tradeoffs across issues. Since difference procedure
= 1 one > 1 former makes tradeoffs across issues
latter not, agents utility former procedure worse utility
latter.
show given (where > 1), agent, outcome simultaneous
procedure better sequential one (irrespective agenda sequential
procedure). considering partitions.
392

fiM ULTI -I SSUE N EGOTIATION

Time
agreement (tc )
Time compute
equilibrium
Pareto optimal?
Unique equilibrium?



EADLINES

Package deal
cth issue
tc = 1
1 c
O(mn)

Simultaneous
cth issue
tc = 1
1 c
O(M n)

Sequential
cth partition
tc = c
1 c
O(M n)

Yes
C1


C2


C2

Table 2: comparison outcomes three multi-issue procedures complete information setting (CI).

Partition c = 1. Since negotiation first partition starts = 1 simultaneous sequential procedures, outcome partition = 1
> 1. Hence, first partition, agent gets equal utility two procedures.
Partition c > 1. Let agent denote first mover partition c (for 2 c )
U denote cumulative
simultaneous sequential procedures. Also, let Usim
seq
utility partition equilibrium outcome simultaneous sequential
b
b denote bs cumulative utility
procedures respectively. Likewise, let Usim
Useq
partition equilibrium outcome simultaneous sequential procedures
respectively.
simultaneous procedure, negotiation partition starts first time
period. agreement partition also occurs first time period. hand,
sequential procedure, negotiation cth partition starts cth time period
results agreement time period (see Theorem 6). Since pie shrinks

, agent bs cumulative utility
time, agent cumulative utility Usim
greater Useq
b
b .
Usim
greater Useq
Thus, simultaneous procedure better sequential one agents. Furthermore
(as shown above), outcome package deal worse simultaneous
procedure agents. Therefore, agent, package deal optimal procedure.
results summarised Table 2. analysis, negotiation parameters n, c ,
kca , kcb (for 1 c m) common knowledge agents. However, unlikely
case encounters. Therefore extend analysis incomplete information
scenarios uncertainty utility functions6 . Section 4, focus symmetric information setting agent uncertain others utility function. Then, Section 5,
examine asymmetric information setting one two agents uncertain
others utility function, agent knows utility function agents.
6. two sources uncertainty: uncertainty negotiation deadline uncertainty discount
factors. Future work deal uncertainty discount factors. However, independent issues, analysed
case symmetric uncertainty deadlines (Fatima, Wooldridge, & Jennings, 2006). extension
work case interdependent issues another direction future work.

393

fiFATIMA , W OOLDRIDGE , & J ENNINGS

4. Multi-Issue Negotiation Symmetric Uncertainty Opponents Utility
symmetric information setting, agent uncertain opponents utility function:
1 c m, agent (b) uncertain kcb (kca ). Specifically, let K denote vector r vectors
vector Ki Rm
+ (for 1 r) consists constant positive real numbers.
b

7
r vectors possible values ka Rm
+ k R+ . words, r types
agent r types agent b. Let P : N+ R1 denote discrete probability distribution
function ka P b : N+ R1 kb . domain two functions [1..r].
words, 1 r, P (i) (P b (i)) probability agent (b) type i. 1 c m,
let Kic denote cth element vector Ki .
setting, vector K functions P P b common knowledge negotiators. Also, agent knows type, opponent. addition, agent
knows r, , n, m.
Since r types agent r types agent b, define r different cumulative
utility functions two agents. agent (b) type (for 1 r) utility
+

+
b


Uia : Rm
1 R1 N R (Ui : R1 R1 N R) division specified package
[xt , ] time is:
(


c=1 Kic uc (xc , t) n


(5)
Ui ([x , ], t) =
0
otherwise
(
b

c=1 Kic uc (yc , t) n
b

(6)
Ui ([x , ], t) =
0
otherwise
Note that, before, issues perfect substitutes. setting, determine equilibrium outcomes three multi-issue procedures compare them.
4.1 Package Deal Procedure
know Theorem 1 equilibrium outcome complete information setting depends kca kcb (for 1 c m). However, setting, uncertainty kca
kcb . Hence use standard expected utility theory (Neumann & Morgenstern, 1947; Fishburn,
1988; Harsanyi & Selten, 1972) find agents optimal strategy. so, however,
first introduce notation.
1 r, let a(i, t) denote equilibrium strategy agent type
time period t. Analogously, b(i, t) denotes equilibrium strategy agent b type
time period t. Note 1 r, [at , bt ] package offered time equilibrium,
+ bt = t1 (i.e., pie, sum shares two agents equal size
pie time t). Also, 1 r, let a(i, j, t) denote equilibrium strategy
agent type time period t, assuming b type j. Analogously, b(i, j, t) denotes
equilibrium strategy agent b type time period t, assuming type j.
Also, let eua(i, t) denote cumulative utility agent type expects get bs
equilibrium offer time (i.e., receiving agent b offering agent t). Likewise,
eub(i, t) denotes cumulative utility agent b type expects get equilibrium
offer time (i.e., b receiving agent offering agent t). let eua(i, j, t) denote
agent expected cumulative utility equilibrium offer time type i,
7. agents type indicates r vectors corresponds to.

394

fiM ULTI -I SSUE N EGOTIATION



EADLINES

assuming b type j. Note utility offering agent t. let
eub(i, j, t) denote agent bs expected cumulative utility equilibrium offer time b
type assuming type j. Note bs utility offering agent
t.
Recall setting, agent knows type, opponent.
Since r possible types, r possible offers agent make time period
(one offer corresponding opponents types). Among r offers, one gives
agent maximum expected cumulative utility optimal offer. cth offer (1 c r)
gives agent maximum expected cumulative utility, say optimal choice
agent c. time period t, let opta(i, t) (optb(i, t)) denote optimal choice agent
(b) type i.
= n, offering agent gets everything opponent gets zero utility. Thus, = n,
following:
eua(i, n) = 0

1 r

(7)

eub(i, n) = 0

X
Kic ct1
eua(i, j, n) =

1 r

(8)

1 r 1 j r

(9)

1 r 1 j r

(10)

eub(i, j, n) =

c=1

X

Kic ct1

c=1

Note = n, eua(i, j, n) eub(i, j, n) depend j last time period,
offering agent gets 100 percent pies. preceding time periods < n,
following:
eua(i, t) = eua(i, , + 1)

1 r = opta(i, + 1)

(11)

eub(i, t) = eub(i, , + 1)
1 r = optb(i, + 1)
r
X
F (i, j, e, t) P b (e)
1 r 1 j r
eua(i, j, t) =

(12)
(13)

e=1

eub(i, j, t) =

r
X

F b (i, j, e, t) P (e)

1 r 1 j r

(14)

e=1

Fa

function
takes four parameters: i, j, e, t, returns utility agent type
gets offering equilibrium package time t, assuming agent b type j
fact type e. Obviously, agent b accepts offer Ueb (a(i, j, t), t) eub(e, , + 1)
= optb(e, + 1). Otherwise, agent b rejects offer negotiation proceeds next
round case expected utility EUA (i, + 1). Hence, F defined follows:

Ui (a(i, j, t), t) Ueb (a(i, j, t), t) eub(e, , + 1) = optb(e, + 1)

F (i, j, e, t) =
eua(i, + 1)
otherwise
strategy a(i, j, t) = n defined follows:

OFFER [n1 , 0] turn
(i, j, n) =
ACCEPT
otherwise
395

fiFATIMA , W OOLDRIDGE , & J ENNINGS

preceding time periods < n defined as:

OFFER tradeoffa1(K, , eub(j, t), i, j, m, t, P , P b ) turn
(i, j, t) =
Uia ([xt , ], t) EUA (i, t) ACCEPT else REJECT
otherwise
[xt , ] denotes offer made function8 TRADEOFFA 1 defined follows.
Like TRADEOFFA , function TRADEOFFA 1 solves following maximisation problem:
maximise




c=1 Kic ac
t1
atc )Kjc = eub(j, t)

c=1 (c

0 atc 1

1 c

(15)

denotes type j b. However, difference TRADEOFFA 1
TRADEOFFA arises one package maximises cumulative utility (i.e.,


c=1 Kic ac ) giving b cumulative utility eub(j, t). one package,
Theorem 1, matter packages offers b (because agents
complete information). Hence, TRADEOFFA return one package. However,
present setting, uncertainty. Therefore, one package maximises
cumulative utility giving b cumulative utility eub(j, t), TRADEOFFA 1 returns
package maximises expected cumulative utility. instance, let [at , bt ] one
package maximises cumulative utility. expected cumulative utility [at , bt ]
(i.e., eua(i, j, t)) given Equation 13 where:

Ui ([a , b ], t) Ueb ([at , bt ], t) eub(e, , + 1) = optb(e, + 1)
F (i, j, e, t) =
eua(i, + 1) otherwise
Obviously, one package maximises expected cumulative utility
gives b utility eub(j, t) TRADEOFFA 1 returns one package.
turn agent b. agent, F b , B(i, j, t), tradeoffb1 defined analogously
follows:
b
Ui (b(i, j, t), t) Uea (b(i, j, t), t) eua(e, , + 1) = opta(e, + 1)
b
F (i, j, e, t) =
eub(i, + 1)
otherwise
strategy b(i, j, t) = n defined follows:

OFFER [0, n1 ] bs turn
B (i, j, n) =
ACCEPT
otherwise
preceding time periods < n defined as:

OFFER tradeoffb1(K, , eua(j, t), i, j, m, t, P , P b ) bs turn
B (i, j, t) =
Uib ([xt , ], t) EUB (i, t) ACCEPT else REJECT
otherwise
8. method making tradeoffs proposed Faratin, Sierra, Jennings (2002) incomplete information setting, method differs ours. Also, Faratin et al. present method making tradeoffs,
show resulting offer equilibrium. contrast, method shows resulting offer
equilibrium.

396

fiM ULTI -I SSUE N EGOTIATION



EADLINES

Thus, optimal choice agent (i.e., opta(i, t)) agent b (i.e., optb(i, t))
defined follows:
opta(i, t) = arg maxrj=1 eua(i, j, t)

1 r

(16)

maxrj=1 eub(i, j, t)

1 r

(17)

optb(i, t) = arg

Note offering agents optimal choice = n depend opponents type since
offering agent gets pies.
compute optimal choice first time period reasoning backwards = n.
= 1, agent type offering agent, offers package corresponds
agent b type opta(i, 1). Likewise, agent b type offering agent, offers
package corresponds agent type optb(i, 1).
However, since opta(i, 1) optb(i, 1) obtained absence complete information,
agreement may may take place first time period. agreement occur
= 1, agents need update beliefs follows. Let Tta {1, 2, . . . , r} denote
set possible types agent time t. = 1, T1a = {1, 2, . . . , r} T1b =
{1, 2, . . . , r}. Assume agent type makes offer = 1. offer makes
gets rejected, means b type opta(i, 1) updates beliefs b using
Bayes rule. Now, basis offer = 1 (say [x1 , 1 ]), agent b infer possible
types agent a. Thus, agent b updates beliefs using Bayes rule. belief update rules
time defined below.
UPDATE BELIEFS: Agent puts weight posterior distribution bs type
Ttb {optb(i, t)} using Bayes rule. Agent b puts weight posterior
distribution type K using Bayes rule K {1, 2, . . . , r} set
possible types offer [xt , ] equilibrium.
belief update rule case b offers = 1 analogous case
offers = 1.
Thus offer = 1 gets rejected, negotiation goes next round. = 2,
offering agent (say agent type i) finds opta(i, 2) updated beliefs. process
updating beliefs making offers continues agreement reached.
Section 3, used concept Nash equilibrium agents complete information. However, current setting, agent uncertain opponents type
agents optimal strategy depends beliefs opponent. Hence use concept
sequential equilibrium (Kreps & Wilson, 1982; van Damme, 1983) setting. Sequential
equilibrium defined terms two elements: strategy profile system beliefs.
strategy profile comprises pair strategies, one agent. belief system following properties. agent belief opponents type. time period, agents
strategy optimal given current beliefs (during time period) opponents possible
strategies. time period, agents beliefs (about opponent) consistent
offers received. Using concept sequential equilibrium, following theorem characterises
equilibrium package deal procedure.
Theorem 8 package deal procedure, following strategies form sequential equilibrium.
equilibrium strategies = n are:

OFFER [n1 , 0] TURN
a(i, n) =
ACCEPT
bs TURN
397

fiFATIMA , W OOLDRIDGE , & J ENNINGS

b(i, n) =



OFFER [0, n1 ] bs TURN
ACCEPT
TURN

1 r. preceding time periods < n, [xt , ] denotes offer made time t,
equilibrium strategies defined follows:

OFFER tradeoffa1(K, , eub(, t), i, , m, t, P , P b ) TURN



offer gets rejected UPDATE BELIEFS
a(i, t) =
RECEIVE OFFER UPDATE BELIEFS
bs TURN



(Uia ([xt , ], t) eua(i, t)) ACCEPT else REJECT

OFFER tradeoffb1(K, , eua(, t), i, , m, t, P , P b ) bs TURN



offer gets rejected UPDATE BELIEFS
b(i, t) =
RECEIVE OFFER UPDATE BELIEFS
TURN



b


(Ui (x , ], t) eub(i, t)) ACCEPT else REJECT

1 r. Here, = opta(i, t) = optb(i, t). earliest possible time agreement
= 1 latest possible time agreement = min(2r 1, n).
Proof: time = n, offering agent takes pies leaves nothing opponent.
opponent accepts get a(i, n) b(i, n). consider time period < n.
Recall negotiation complete information setting (see Section 3.1), time < n,
offering agent proposes package gives opponent cumulative utility equal
opponent would get equilibrium offer next time period. However,
current incomplete information setting, agent knows type opponent.
Hence, scenario, time < n, offering agent (say a) proposes package gives b
expected cumulative utility equal b would get equilibrium offer next
time period (i.e., eub(, t)). package determined tradeoffa1 function. Likewise,
b offering agent time t, makes tradeoffs using tradeoffb1 offers
expected cumulative utility eua(, t).
obtain equilibrium offer = n 1 reason backwards obtain
equilibrium offer = 1. However, since offers computed absence complete
information (i.e., basis expected utilities), agreement may may take place
= 1. agreement take place = 1, negotiation proceeds follows. Consider
time period 1 < n. Let [xt , ] denote offer made time t. agent
receives offer (say agent a) updates beliefs using Bayes rule: put weight
posterior distribution bs type K K {1, 2, . . . , r} set possible types b
offer [xt , ] equilibrium. proposed offer ([xt , ]) gets rejected, offering
agent (say agent b type i) updates beliefs using Bayes rule: put weight posterior
distribution type Tta {optb(i, t)}. belief update rule case agent
offers time analogous rule. belief update rules incorporated
agents strategies give a(i, t) b(i, t) shown statement theorem.
show beliefs specified consistent. time period < n, let
strategy profile (a(i, t), b(i, t)) assign probability 1 specified posterior beliefs
probability rest support opponents type. 0, strategy pair
converges (a, b). Also, beliefs generated strategy pair converge beliefs described
above. Given beliefs, strategies b sequentially rational.
398

fiM ULTI -I SSUE N EGOTIATION



EADLINES

earliest possible time agreement = 1. show following example. Let
n = 2, = 2, r = 2, = 1/2, K = [1, 2; 5, 1]. Let agent offering agent time = 1.
Assume type 1 (i.e., ka = [1, 2]). Let P b (1) = 0.1 P b (2) = 0.9. Since r = 2, agent
play two possible strategies time = 1: one corresponds case b type 1
corresponds case b type 2. former case, equilibrium
offer = 1 [0, 1] first issue [ 43 , 14 ] second one. Hence eua(1, 1, 1) = 1.5.
latter case, equilibrium offer = 1 [ 52 , 35 ] first issue [1, 0] second
issue. Hence eua(1, 2, 1) = 2.16. Since eua(1, 2, 1) > eua(1, 1, 1), opta(1, 1) = 2 plays
latter strategy. b fact type 2, accepts offer = 1. b fact
type 1, rejects offer = 1 since get higher utility = 2. agreement therefore
occurs = 2. Thus, earliest possible time agreement = 1.
consider case type offers = 1 agreement occur
time. offer gets rejected, knows b type opta(i, 1). Thus number
possible types b reduced r 1. happens every time makes offer (i.e., every
alternate time period) gets rejected. negotiation reaches time period = 2r 1,
one possible type b. Likewise, one possible type agent a. agreement
therefore takes place = 2r 1. However, n < 2r 1 agreement occurs = n (see
a(i, n) b(i, n)). words, agreement occur = 1, occurs
latest = min(2r 1, n).
mentioned earlier, one package solves Equation 15, tradeoffa1
returns one maximises expected cumulative utility. Let paij
(where denotes type
j b) denote set possible packages tradeoffa1 return time t.
set pbij
agent b defined analogously.
Theorem 9 given first mover, package deal procedure unique equilibrium outcome
condition C3 false C4 true.
C3 . exists i, j, c, d, (c 6= d) (i 6= j) (Kic /Kjc = Kid /Kjd )
1 r, 1 j r, 1 c m, 1 m.
ij
C4 . |paij
| = 1 |pbt | = 1 1 r, 1 j r, 6= j, 1 n.

Proof: Let denote agent type j denote bs type 6= j, 1 r, 1 k r.
Note b type, similar preferences different issues. 6= j
agents gain making tradeoffs different types. rest
proof condition C3 follows Theorem 4. Consider C4 . C3 true, know that,
time t, tradeoffa1 returns package solves Equation 15 maximises expected
cumulative utility. Hence paij
contains single element, one possible package
tradeoffa1 return. Likewise, pbij
contains single element, one
possible package tradeoffb1 return. one possible offer time
period 1 n, equilibrium outcome unique.
order determine time complexity package deal, first find complexity
tradeoffa1 function. mentioned before, tradeoffa1 differs tradeoffa
one package solves maximisation problem Equation 15.
know Theorem 9 one package condition C3 true. also
399

fiFATIMA , W OOLDRIDGE , & J ENNINGS

know Theorem 1 using greedy approach, tradeoffa considers issues
increasing order Kic /Kjc denotes type j denotes bs type. Let Spij denote
set issues (where 0 ij < m, 1 p ij , denotes type, j denotes bs type)
that:
|Spij | > 1 1 p ij
and:
c,dSpij

Kic
Kjc

=

Kid
Kjd

words, Spij set issues c belong Spij Kic /Kjc = Kid /Kjd ,
ij number sets satisfy condition. ij = 0 means
one package solves Equation 15. ij > 0 one package solves
Equation 15 among tradeoffa1 must find one maximises expected
cumulative utility. example set issues = {1, 2, 3, 4}, r = 2, K1 = {5, 6, 7, 8},
K2 = {9, 6, 7, 8}, D12 = 1, S112 = {2, 3, 4}, |S112 | = 3. making tradeoffs,
consider issues S112 order three issues needs give
amount utility order increase bs utility 1. three issues S112 ordered
3! different ways resulting 3! different packages. among 3! different packages,
tradeoffa1 must find one maximises expected cumulative utility. general,
ij > 1, let ij denote number9 possible packages tradeoffa1 needs consider
ij is:
ij


ij
|Spij |!
=
p=1

words, type bs type j, ij packages solve Equation 15
among tradeoffa1 must find one maximises expected cumulative
utility. Dij = 0, ij = 1. Let defined as:
=

max

1ir,1jr,i6=j

ij

(18)

words, maximum number packages tradeoffa1 search
find one maximises expected cumulative utility (considering possible types
possible types b). Note that, before, b different types (i.e., 6= j
Equation 18) agents gain making tradeoffs different types.
time complexity tradeoffa1 depends .
Theorem 10 time complexity tradeoffa1 O(m).
Proof: know Theorem 2 time complexity finding one package solves
Equation 15 O(m). However, one package solves Equation 15
tradeoffa1 returns one maximises expected cumulative utility. time compute
expected cumulative utility one package O(m). maximum number
packages needs find expected cumulative utility . Thus time complexity
tradeoffa1 O(m).
9. Note ij defined terms factorial |Spij |, |Spij | independent assumed
|Spij | m.

400

fiM ULTI -I SSUE N EGOTIATION



EADLINES

Corollary 1 ij = 0 1 r, 1 j r, 6= j, time complexity
tradeoffa1 complexity tradeoffa.
Proof: ij = 0 1 r, 1 j r, 6= j, ij = 1 = 1. time
complexity tradeoffa1 O(m).
Theorem 11 time complexity computing equilibrium offers package deal procedure O(mr 3 (n T2 )) = min(2r 1, n).
Proof: Let denote agent offers = 1 assume n even (the proof odd
n analogous). begin last time period reason backwards. Since n even
starts = 1, bs turn offer last time period. = n, time taken find
eub(i, j, t) (for given j) O(m) (see Equation 10). Hence, time taken find eub(i, j, t)
possible types b (i.e., 1 j r) O(mr). Note that, stage, eub(i, 1) known
1 r (see Equation 12).
consider time period = n 1. Since n even, turn offer = n 1.
order find a(i, t), first need find = opta(i, t). Equation 16 know
that, given i, time find opta(i, t) depends time taken find eua(i, j, t)
turn depends time find fa (i, j, e, t) (see Equation 13). time taken fa (i, j, e, t)
depends time taken a(i, j, t). given given j, time taken find a(i, j, t)
time taken function tradeoffa. Since eub(j, t) already known time t, time
taken tradeoffa1 O(m) (see Theorem 10). time taken find fa (i, j, e, t) therefore
O(m). Given this, time find eua(i, j, t) (for given i, j, t) O(mr). Hence,
given i, time find = opta(i, t) O(mr 2 ). stage, EUB (, t) known (see last
sentence first paragraph proof). Consequently, given i, time find a(i, t)
O(mr 2 ). Recall agent knows type opponent. Hence
need determine a(i, t) possible types (i.e., 1 r). takes O(mr 3 ) time.
Note stage eua(i, j, t) known possible values possible values j
(where 1 r 1 j r).
consider time period = n 2 bs turn offer. = n 2 given i,
time find optb(i, t) O(mr 2 ) time find optb(i, t) possible types
b (i.e., 1 r) O(mr 3 ).
way, time required necessary computation time period
< n O(mr 3 ). Hence, total time find equilibrium offer first time period
O((n 1)mr 3 ). However, noted previously, agreement may may occur first
time period. agreement take place = 1, agents update beliefs
compute equilibrium offer = 2 updated beliefs. time compute
equilibrium offer = 2 O((n 2)mr 3 ). process updating beliefs finding
equilibrium offer repeated = min(2r 1, n) times. Hence time complexity
package deal Ti=1 O((n i)mr 3 ) = O(mr 3 (n T2 )) (see Cormen et al., 2003, page 47
details simplify expression form Ti=1 O((n i)mr 3 )).
Theorem 12 package deal procedure generates Pareto optimal outcome.
Proof: follows Theorem 3. difference complete information setting
Theorem 3 current incomplete information setting former setting agents
maximise cumulative utilities, whereas current setting maximise expected
cumulative utilities. Specifically, every time period, offering agent maximises expected
401

fiFATIMA , W OOLDRIDGE , & J ENNINGS

cumulative utility issues opponents expected cumulative utility equal
opponent would get equilibrium offer next time period. Hence,
current setting, equilibrium offer every time period Pareto optimal.
4.2 Simultaneous Procedure
Recall procedure, > 1 partitions discussed parallel independently
other. offers made negotiation one partition affect offers
others. Specifically, negotiation partition starts = 1 partition
settled using package deal procedure. Since partition dealt separately, results
Theorem 8 apply directly partitions.
Let c denote cth partition. Then, Theorem 11, know time taken
cth (for 1 c ) partition O(|Sc |c r 3 (n T2 )). Let partition |Sc |c highest
denoted Sz . time complexity simultaneous procedure O(|Sz |z r 3 (n

2 )). Also, Theorem 5, follows simultaneous procedure may generate Pareto
optimal outcome. Finally, Theorem 9 know simultaneous procedure unique
equilibrium outcome following condition satisfied:
C5 . partition c (where 1 c ) condition (C3 C4 ) false.
4.3 Sequential Procedure
procedure, > 1 partitions discussed independently one another. Also,
1 c , negotiation cth partition starts time period follows agreement
(c 1)th partition. Since package deal used partition, following results
obtained basis Theorem 8.
First, Theorem 8 applies > 1 partitions. Thus, sequential procedure,
negotiation cth (for 1 c ) partition starts time tc , ends earliest
time tc latest tc + min(2r 1, n). Second, follows Theorem 11 time
taken sequential procedure O(|Sz |z r 3 (n T2 )). Third, sequential procedure may
generate Pareto optimal outcome (see Theorem 5). Finally, conditions uniqueness
simultaneous procedure.
4.4 Optimal Procedure
obtained equilibrium outcomes three procedures defined incomplete
information scenario, compare terms expected utilities generate
player. Again, procedure gives player maximum expected utility optimal one.
Theorem 13 package deal optimal agent.
Proof: proof Theorem 7. difference complete
information setting Theorem 7 current incomplete information setting
package deal procedure former setting (during time period < n), offering agent proposes package maximises cumulative utility, giving opponent cumulative
utility equal opponent would get equilibrium offer next time period.
hand, current incomplete information setting, offering agent proposes
package maximises expected cumulative utility giving opponent expected
402

fiM ULTI -I SSUE N EGOTIATION

Time
agreement

Time compute
equilibrium
Pareto optimal?
Unique equilibrium?

Package deal
Earliest: 1
Latest: min(2r 1, n)
issues
O(mr 3 (n T2 ))



EADLINES

Simultaneous
Earliest: 1
Latest: min(2r 1, n)
issues
O(|Sz |z r 3 (n

Yes
C3 C4


C5


2 ))

Sequential
cth partition
tec = tsc
l

tc = tc + min(2r 1, n)
1 c
O(|Sz |z r 3 (n T2 ))

C5

Table 3: comparison expected outcomes three multi-issue procedures symmetric information setting (for sequential procedure, tsc denotes start time
cth partition, tec earliest possible time agreement, tlc latest possible time
agreement).

cumulative utility equal opponent would get equilibrium offer next
time period. Also, agent, package deal maximises expected cumulative utility
issues (since tradeoffs made across issues). simultaneous procedure
maximises agents expected cumulative utility partition (i.e., simultaneous procedure make tradeoffs across partitions). Hence agents expected cumulative utility
issues higher package deal relative simultaneous procedure. Furthermore,
irrespective issues partitioned partitions, know simultaneous
procedure better sequential one agent (see Theorem 7). Hence, package deal
optimal agent.
results summarised Table 3.

5. Multi-Issue Negotiation Asymmetric Uncertainty Opponents
Utility
bargaining situations, one players may know something relevance
may know. example, bargaining price second hand car, seller knows
quality buyer not. situations said asymmetry information
players (Muthoo, 1999). asymmetric information setting differs symmetric one
explored previous section one two agents (say a) complete information,
(say b) uncertain utility function: 1 c m, agent b uncertain
kca . Here, K, P , P b , n, r, defined Section 4. negotiation parameters K, P ,
P b , r, , n, common knowledge negotiators. Furthermore, knows type
b, b knows type a. Finally, definitions cumulative
utility functions remain Section 4. setting, determine equilibrium
three multi-issue procedures.
403

fiFATIMA , W OOLDRIDGE , & J ENNINGS

5.1 Package Deal Procedure
extend analysis Section 4 current setting follows. clear last time
period (t = n), utilities eua(i, t) eub(i, t) per Section 4. Let j denote bs actual
type. Recall agent knows j. Hence basis Equation 13 SUI setting,
get eua(i, j, t) current asymmetric information setting follows:
eua(i, j, t) = F (i, j, j, t)

1 r 1 j r

(19)

hand, since agent b uncertain type, definitions eub(i, t)
eub(i, j, t) given Section 4. Also, definitions F , F b , a(i, j, t), b(i, j, t), opta(i, t),
optb(i, t) time periods remain Section 4.
Finally, setting, belief updating apply agent complete information. agent b updates beliefs a. done way described
Section 4. bs uncertainty, use concept sequential equilibrium setting
well. following theorem characterises equilibrium package deal procedure.
Theorem 14 package deal procedure following strategies form sequential equilibrium. equilibrium strategies = n are:

OFFER [n1 , 0] TURN
a(i, n) =
ACCEPT
bs TURN
b(i, n) =



OFFER [0, n1 ] bs TURN
ACCEPT
TURN

1 r. preceding time periods < n, [xt , ] denotes offer made time t,
equilibrium strategies defined follows:

OFFER tradeoffa1(K, , eub(j, t), i, j, m, t, P , P b ) TURN
a(i, t) =
RECEIVE OFFER
bs TURN

(Uia ([xt , ], t) eua(i, t)) ACCEPT else REJECT

OFFER tradeoffb1(K, , eua(, t), i, , m, t, P , P b ) bs TURN



offer gets rejected UPDATE BELIEFS
b(i, t) =
TURN
RECEIVE OFFER UPDATE BELIEFS


(Uib (xt , ], t) eub(i, t)) ACCEPT else REJECT

1 r. Here, j denotes agent bs type = optb(i, t). earliest possible time
agreement = 1 latest possible time = min(2r 1, n).
Proof: Theorem 8. difference knows bs type (j). Hence information
used parameter tradeoffa1.
earliest possible time agreement = 1. show following example.
Let n = 2, = 2, r = 2, = 1/2, K = [1, 2; 5, 1]. Let b (i.e., agent uncertain
information) offering agent time = 1. Assume b type 2 (i.e., kb = [5, 1]). Let
P (1) = 0.9 P (2) = 0.1. Since r = 2, b play two possible strategies time = 1:
one corresponds case type 1 corresponds case
type 2. former case, bs equilibrium offer = 1 [0, 1] first issue
404

fiM ULTI -I SSUE N EGOTIATION



EADLINES

[ 34 , 14 ] second. Hence eub(1, 1, 1) = 4.725. latter case, bs equilibrium offer
= 1 [ 52 , 35 ] first issue [1, 0] second one. Hence eub(1, 2, 1) = 3. Since
eub(1, 1, 1) > eub(1, 2, 1), optb(1, 1) = 1 b plays former strategy. fact
type 1, accepts bs offer = 1. fact type 2, rejects bs offer = 1
since get higher utility = 2. agreement therefore occurs = 2. Thus, earliest
possible time agreement = 1.
consider case agent b type offers = 1 agreement
occur time. bs offer gets rejected, knows type optb(i, 1). Thus
number possible types reduced r 1. happens every time b makes
offer (i.e., every alternate time period) gets rejected. negotiation reaches time period
= 2r 1, one possible type a. Since knows bs type, agreement therefore
takes place = 2r 1. However, n < 2r 1 agreement occurs = n (see a(i, n)
b(i, n)). words, agreement occur = 1, occurs latest
= min(2r 1, n).
Note latest possible time agreement asymmetric information setting
symmetric information setting Theorem 8. because, asymmetric setting,
although knows bs type, b uncertain type. Also, takes 2r 1 time periods b
come know actual type. Hence, earliest latest time agreement
settings.
Theorem 15 time complexity computing equilibrium offers package deal procedure O(mr 3 T2 (n T2 )) = min(2r 1, n).
Proof: Let denote agent offers = 1 assume n even (the proof odd
n analogous). begin last time period reason backwards. Since n even
agent starts = 1, bs turn offer last time period. = n, time
taken find eub(i, j, t) (for given j) O(m) (see Equation 10). Hence, time taken
find eub(i, j, t) possible types b (i.e., 1 j r) O(mr). Note that, stage,
eub(i, 1) known 1 r (see Equation 12).
consider time period = n 1. Since n even, turn offer = n 1.
order find a(i, t), first need find = opta(i, t). Equation 16 know
that, given i, time find opta(i, t) depends time taken find eua(i, j, t) which,
turn, depends time find fa (i, j, e, t) (see Equation 19). time taken fa (i, j, e, t)
depends time taken a(i, j, t). given given j, time taken find a(i, j, t)
time taken tradeoffa1. Since eub(j, t) already known time t, time taken
function tradeoffa1 O(m) (as Theorem 2). time taken find fa (i, j, e, t) therefore
O(m). Given this, time find eua(i, j, t) (for given i, j, t) O(m) since bs type
known agents see Equation 19. Hence, given i, time find = opta(i, t)
O(mr). stage, EUB (, t) known (see last sentence first paragraph
proof). Consequently, given i, time find a(i, t) O(mr). Recall b know
type. Hence need determine a(i, t) possible types (i.e., 1 r).
takes O(mr 2 ) time. Note stage eua(i, j, t) known possible values
possible values j (where 1 r 1 j r).
consider time period = n 2 bs turn offer. difference
computation = n 1 = n 2 former case, time find eua(i, j, t)
(for given i, j, t) O(m) since bs type known agents. However latter
405

fiFATIMA , W OOLDRIDGE , & J ENNINGS

case, time find eub(i, j, t) (for given i, j, t) O(mr) since type known
b (see Equation 14). Consequently, given i, time find b(i, t) O(mr 2 ). time
determine b(i, t) possible types b (i.e., 1 r) O(mr 3 ) time. Note
stage eub(i, j, t) known possible values possible values j (where 1 r
1 j r).
way, time required necessary computation odd time period
< n O(mr 2 ), even time period O(mr 3 ). Hence, total time find
equilibrium offer first time period O(mr 3 ( n1
2 )). However, noted previously,
agreement may may occur first time period. agreement take place =
1, agents update beliefs compute equilibrium offer = 2 updated
beliefs. time compute equilibrium offer = 2 O(mr 3 ( n2
2 )). process
updating beliefs finding equilibrium offer repeated = min(2r 1, n) times.

3
Hence time complexity package deal Ti=1 O(mr 3 ( ni
2 )) = O(mr (n 2 ) 2 ).
Theorem 16 package deal procedure generates Pareto optimal outcome.
Proof: per Theorem 12.
Theorem 17 given first mover, package deal procedure unique equilibrium outcome
C3 C4 true.
Proof: per Theorem 9.
5.2 Simultaneous Procedure
Theorem 14 applies > 1 partitions. Hence, Theorem 15, know

time taken cth (for 1 c ) partition O(|Sc |c r 3 ( nT
2 ) 2 ). Hence, time complexity

3
simultaneous procedure O(|Sz |z r (n 2 ) 2 ). Also, Theorem 5, follows
simultaneous procedure may generate Pareto optimal outcome. Finally, Theorem 17
know simultaneous procedure unique equilibrium outcome condition C5 true.
5.3 Sequential Procedure
First, Theorem 14 applies > 1 partitions. Thus, sequential procedure,
negotiation cth (for 1 c ) partition starts time tc , ends earliest time
tc latest tc + min(2r 1, n). Second, follows Theorem 15 time taken
sequential procedure O(|Sz |z r 3 (n T2 ) T2 ). Third, sequential procedure may
generate Pareto optimal outcome (see Theorem 5). Finally, conditions uniqueness
simultaneous procedure.
5.4 Optimal Procedure
follows Theorem 13 that, agent, optimal procedure package deal.
results summarised Table 4.

6. Multi-Issue Negotiation Interdependent Issues
independent issues case Section 4, agents utility issue c (for 1 c m) depends
share issue independent issues. However, many cases,
406

fiM ULTI -I SSUE N EGOTIATION

Package deal
Earliest: 1
Latest: min(2r 1, n)
issues

Time
agreement

Time compute
equilibrium
Pareto optimal?
Unique equilibrium?

O(mr 3 T2 (n


2 ))



EADLINES

Simultaneous
Earliest: 1
Latest: min(2r 1, n)
issues
O(|Sz |z r 3 (n

Yes
C3 C4


2)2)

Sequential
cth partition
tec = tsc
l

tc = tc + min(2r 1, n)
1 c
O(|Sz |z r 3 (n T2 ) T2 )


C5


C5

Table 4: comparison expected outcomes three multi-issue procedures asymmetric information setting (for sequential procedure, tsc denotes start time
cth partition, tec earliest possible time agreement, tlc latest possible time
agreement).

agents utility issue depends share issue, also share
others (Klein et al., 2003). Given this, section focus interdependent issues.
Specifically, model interdependence issues follows. Consider package [xt , ].
package, agent type i, utility issue c time form:
(
Kic xc +
j=1 ij (xc xj ) n


(20)
uic ([x , ], t) =
0
otherwise
agent b type i, is:
ubic ([xt , ], t)

(
Kic yc +
j=1 ij (yc yj ) n
=
0
otherwise

(21)

Kic denotes constant positive real number ij constant real number may
either positive negative. before, agents cumulative utility sum utilities
individual issues:
(


c=1 Kic xc n
(22)
Uia ([xt , ], t) =
0
otherwise
(


c=1 Kic yc n
(23)
Uib ([xt , ], t) =
0
otherwise
K denotes vector analogous vector K except individual elements
latter constant positive real numbers, former may positive negative.
Note Equations 5 6, coefficients positive (i.e., Kic > 0 1 r
1 c m). Equations 22 23, coefficient (Kic ) may positive negative real
number.
407

fiFATIMA , W OOLDRIDGE , & J ENNINGS

cumulative utility functions linear (see Pollak, 1976; Charness & Rabin, 2002;
Sobel, 2005, forms utility functions interdependent preferences10 ). mentioned
before, chose linear form reasons computational tractability.
setting vector K functions P P b common knowledge negotiators. Also, agent knows type, opponent. addition, agent
knows r, , n, m. words, symmetric uncertainty opponents utility
(as see Section 6.4, results asymmetric case easily obtained
following analysis symmetric case).
6.1 Package Deal Procedure
cumulative utilities defined Equations 22 23, Theorem 18 characterises equilibrium package deal.
Theorem 18 package deal procedure, following strategies form sequential equilibrium. equilibrium strategies = n are:

OFFER [n1 , 0] TURN
a(i, n) =
ACCEPT
bs TURN

OFFER [0, n1 ] bs TURN
b(i, n) =
ACCEPT
TURN
1 r. preceding time periods < n, [xt , ] denotes offer made time t,
equilibrium strategies defined follows:

OFFER tradeoffa1(K, , eub(, t), i, , m, t, P , P b ) TURN



offer gets rejected UPDATE BELIEFS
a(i, t) =
RECEIVE OFFER UPDATE BELIEFS
bs TURN






(Ui ([x , ], t) eua(i, t)) ACCEPT else REJECT

OFFER tradeoffb1(K, , eua(, t), i, , m, t, P , P b ) bs TURN



offer gets rejected UPDATE BELIEFS
b(i, t) =
RECEIVE OFFER UPDATE BELIEFS
TURN



(Uib (xt , ], t) eub(i, t)) ACCEPT else REJECT

1 r. Here, = opta(i, t) = optb(i, t). earliest possible time agreement
= 1 latest possible time = min(2r 1, n).
Proof: Theorem 8. difference independent issues setting Theorem 8
present interdependent issues one terms definition cumulative utilities:
Equations 5 6, coefficients positive (i.e., Kic > 0 1 r 1 c m).
Equations 22 23, coefficient (Kic ) may positive negative real number.
However, greedy method (given Theorem 1) solving fractional knapsack problem
Equation 15 works positive negative coefficients (Martello & Toth, 1990; Cormen et al.,
2003). Hence, proof Theorem 8 applies setting well.
10. Although (Pollak, 1976; Charness & Rabin, 2002; Sobel, 2005) forms discussed context
agents utility depends utility agents, may equally well interpreted case
agents utility issue depends share issues.

408

fiM ULTI -I SSUE N EGOTIATION



EADLINES

Theorem 19 time complexity computing equilibrium offers package deal procedure O(mr 3 (n T2 )) = min(2r 1, n).
Proof: Theorem 11. Since method making tradeoffs setting
symmetric uncertainty independent issues (i.e., SUI ), time complexity
Theorem 11.
obvious Theorems 9 12 extend setting well.
6.2 Simultaneous Procedure
follows results Section 4.2 apply setting well.
6.3 Sequential Procedure
also follows results Section 4.3 apply setting well.
6.4 Optimal Procedure
follows Theorem 13 package deal remains optimal procedure even issues
interdependent. results setting Section 4 summarised
Table 3.
Finally, consider asymmetric information setting Section 5 current context
interdependent issues. analysis symmetric uncertainty interdependent
issues, clear method making tradeoffs remains irrespective whether
information symmetric asymmetric. Consequently, case asymmetric information
interdependent issues, get results Section 5.
Recall analysis done linear cumulative utilities. discuss
results would hold complex utility functions non-linear11 . cumulative utilities
nonlinear, tradeoff problem becomes global optimization problem nonlinear
objective function. Due computational complexity, nonlinear optimization problems
solved using approximation methods (Horst & Tuy, 1996; Bar-Yam, 1997; Klein et al.,
2003). contrast, tradeoff problem linear optimization problem, exact solution
found polynomial time (as shown Theorems 1 2). Although results
apply linear cumulative utilities, difficult see would hold nonlinear
case. First, time agreement case would hold (nonlinear) functions.
time depends actual definition agents cumulative utilities
information setting (i.e., whether information complete). Second, let O()
denote time complexity TRADEOFFA 1 nonlinear utilities package deal = 1,
O(c ) cth partition. Also, let Sz denote partition O(z )
highest partitions. Then, know Theorem 11 time complexity
package deal setting symmetric uncertainty O(r 3 (n T2 )). Consequently, time
complexity simultaneous sequential procedures O(z r 3 (n T2 )). Third,
package deal outcome additive cumulative utilities Pareto optimal, package
deal outcome nonlinear utilities may Pareto optimal. (as stated above)
11. Note bilateral bargaining players utility functions nonlinear studied Hoel (1986)
context single issue opposed multi-issue case focus study.

409

fiFATIMA , W OOLDRIDGE , & J ENNINGS

nonlinear optimization problems solved using approximation methods linear
optimization problem solved using exact method (as proof Theorem 1). Finally,
since conditions unique solution depend actual definition cumulative utilities,
conditions given Tables 1 2, 3, 4 may hold forms utility functions.

7. Related Work
Since Schelling (1956) first noted fact outcome negotiation depends choice
negotiation procedure, much research effort devoted study different procedures
negotiating multiple issues. instance, Fershtman (1990) extended model developed
Rubinstein (1982), splitting single pie, sequential negotiation two pies. However,
model assumes complete information, imposes agenda exogenously, studies relation
agenda outcome sequential bargaining game. detail, two pies
different sizes, analyses effect going first large small pie.
number researchers also studied negotiations endogenous agenda (Inderst,
2000; & Serrano, 2003; Bac & Raff, 1996). Inderst (2000) players discount factors,
deadlines. independent issues, work assumes complete information studies
three different negotiation procedures: package deal, simultaneous, sequential negotiation
endogenous agenda. main result package deal optimal procedure
procedure exist multiple equilibria. Serrano (2003) extend work finding
conditions equilibrium becomes unique. Note work differs
analyse negotiations discount factors deadlines, consider
much common automated negotiations. Moreover, independent
interdependent issues without making complete information assumption.
Bac Raff (1996) also developed model endogenous agenda. extended
model developed Rubinstein (1985) single pie bargaining incomplete information
adding second pie. model, players discount factors, deadlines.
size pie known agents discounting factor assumed equal
issues agents. Also, asymmetric information: one players knows
discounting factor opponent, player knows discounting
factor, uncertain opponents. detail, factor take one two values, H
probability x, L probability 1 x. probabilities common knowledge.
model, authors determine equilibrium package deal sequential procedure.
show that, certain conditions, sequential procedure optimal one. However,
three key differences model ours. First, analyse symmetric
asymmetric information settings, Bac Raff analyse latter. Second, negotiators
model deadline, Bac Raff not. Again, believe analysis
covers situations often occur automated negotiation settings. Finally, Bac Raff focus
independent issues, analyse independent interdependent issues.
slightly different approach (from ones) taken Busch Horstmann (1997).
Again, extended model developed Rubinstein (1985), adding preliminary period
agents bargain agenda. outcome stage used agenda
negotiating issues. complete information model, two pies bargaining.
Furthermore, two issues become available negotiation different time points. players
discount factors fixed time costs, deadlines. Since two issues, two
410

fiM ULTI -I SSUE N EGOTIATION



EADLINES

possible agendas. outcome two agendas compared package deal.
main result players may conflicting preferences optimal agenda. Note
key difference model issues model available
beginning, model two issues become available different time points.
Furthermore, Busch Horstman assume complete information, not.
models mentioned above, perhaps one closest one developed
Inderst (2000). Unlike work, Inderst assumes complete information independent issues.
Also, model player deadlines, do. However, Inderst model players time
preferences discount factors. Also, like model, issues negotiation available
beginning negotiation. terms results, Inderst shows package deal
optimal procedure. study also shows package deal optimal procedure
agents. Finally, work provides detailed analysis attributes different procedures
(such time agreement, time complexity, Pareto optimality, conditions
uniqueness), Inderst not.
summary, aforementioned models multi-issue negotiation differ
least one three major ways. players model discount factors deadlines,
general characteristic models players discount factors
deadlines12 . Negotiation deadlines studied Sandholm Vulkan (1999) (in
context single issue) Fatima et al. (2004) sequential procedure = m. Given
this, contribution lies firstly finding equilibrium three procedures. Second,
analyse asymmetric symmetric information settings, previous work analyses
former. Third, analyse independent interdependent issues previous work
focuses primarily independent issues. Furthermore, existing literature compare
different multi-issue procedures terms attributes (viz. time complexity, Pareto optimality,
uniqueness, time agreement). considering these, study allows informed choice
made wider range tradeoffs involved determining
appropriate procedure.
Finally, would like point Fatima et al. (2006), considered independent issues
carried study work, symmetric information setting
uncertainty negotiation deadline (as opposed uncertainty agents utility functions focus work). key result (Fatima et al., 2006) similar result
current work, namely optimal procedure (Fatima et al., 2006) package deal.

8. Conclusions Future Work
paper studied bilateral multi-issue negotiation self-interested agents wide range
settings. player time constraints form deadlines discount factors. Specifically,
considered independent interdependent issues studied three main multi-issue
procedures conducting negotiations: package deal, simultaneous procedure,
sequential procedure. determined equilibria procedure two different information
settings. first, symmetric uncertainty opponents utility. second,
asymmetric uncertainty opponents utility. analysed settings
case independent interdependent issues. setting, compared outcomes
12. (Fatima et al., 2004) studies multi-issue model deadlines, focuses determining equilibrium one
specific sequential procedure: one partition single issue.

411

fiFATIMA , W OOLDRIDGE , & J ENNINGS

different procedures showed package deal optimal agent. compared
three procedures terms four attributes: time complexity procedure, Pareto
optimality equilibrium solution, uniqueness equilibrium solution, time
agreement (see Table 1).
detail, study shows package deal fact optimal procedure
party. also showed although package deal may computationally complex
two procedures, generates Pareto optimal outcomes (unlike two procedures),
similar earliest latest possible times agreement simultaneous procedure (which
better sequential procedure), (like two procedures) generates unique
outcome certain conditions (which defined).
several interesting directions extending current analysis. First, work,
modelled players time preferences form discount factors common
basis analysis. However, existing literature (Busch & Horstman, 1997) shows
outcome negotiation discount factors differ outcome negotiation
fixed time costs. will, therefore, interesting extend results negotiations fixed
time costs. Second, present work analysed setting uncertainty utility functions.
Generalisation results scenarios sources uncertainties agents
discount factors another direction future work.
Acknowledgements
grateful Sarit Kraus detailed comments earlier versions paper. also
thank anonymous referees; comments helped us substantially improve readability
accuracy paper.

412

fiM ULTI -I SSUE N EGOTIATION



EADLINES

Appendix A. Summary Notation
a, b two negotiating agents.
n Negotiation deadline agents.
Total number issues.
set issues.
Sc subset (Sc S).
Number issues largest partition.
Number partitions simultaneous sequential procedures.
c Discount factor issue c (for 1 c m).
element vector represents discount factor issues.
xt element vector denotes share issues time t.
element vector denotes bs share issues time t.
[xt , ] package offered time t.
atc Agent share issue c equilibrium offer time period t.
btc Agent bs share issue c equilibrium offer time period t.
element vector denotes share issues equilibrium time t.
bt element vector denotes bs share issues equilibrium time t.
[at , bt ] equilibrium package offered time t.
Uia Cumulative utility function agent type i.
Uib Cumulative utility function agent b type i.
ua(t) Agent cumulative utility equilibrium offer time t.
ub(t) Agent bs cumulative utility equilibrium offer time t.
a(i, j, t) Agent equilibrium offer time type assuming b type j.
b(i, j, t) Agent bs equilibrium offer time b type assuming type j.
a(i, t) Equilibrium strategy agent type time t.
b(i, t) Equilibrium strategy agent b type time t.
eua(i, t) Cumulative utility agent type expects get bs equilibrium offer
time (i.e., receiving agent b offering agent t).
413

fiFATIMA , W OOLDRIDGE , & J ENNINGS

eub(i, t) Cumulative utility agent b type expects get equilibrium offer
time (i.e., b receiving agent offering agent t).
eua(i, j, t) Agent expected cumulative utility equilibrium offer time type
assuming b type j.
eub(i, j, t) Agent bs expected cumulative utility equilibrium offer time b type
assuming type j.
r Number types agent (and also number types agent b).
Tta Set possible types agent time t.
Ttb Set possible types agent b time t.
P probability distribution function ka .
P b probability distribution function kb .
K vector r vectors element turn vector positive reals.
Spij subset (Spij denotes type j b) |Spij | > 1
Kid
Kic
.
=K
c,dSpij K
jc
jd
tradeoffa Agent function making tradeoffs complete information setting.
tradeoffb Agent bs function making tradeoffs complete information setting.
tradeoffa1 Agent function making tradeoffs four incomplete information settings:
SUI , SUD , AUI , AUD .
tradeoffb1 Agent bs function making tradeoffs four incomplete information settings:
SUI , SUD , AUI , AUD .
Maximum number packages tradeoffa1 (or tradeoffb1) search find
one maximises (or bs) expected cumulative utility (considering possible types
b).
paij
set possible packages tradeoffa1 return time (i denotes type
j b).
pbij
set possible packages tradeoffb1 return time (i denotes type
j b).

References
Bac, M., & Raff, H. (1996). Issue-by-issue negotiations: role information time preference.
Games Economic Behavior, 13, 125134.
Bar-Yam, Y. (1997). Dynamics Complex Systems. Addison Wesley.
414

fiM ULTI -I SSUE N EGOTIATION



EADLINES

Binmore, K., Osborne, M. J., & Rubinstein, A. (1992). Noncooperative models bargaining.
Aumann, R. J., & Hart, S. (Eds.), Handbook Game theory Economic Applications,
Vol. 1, pp. 179225. North-Holland.
Busch, L. A., & Horstman, I. J. (1997). Bargaining frictions, bargaining procedures implied
costs multiple-issue bargaining. Economica, 64, 669680.
Charness, G., & Rabin, M. (2002). Understanding social preferences simple tests. Quarterly Journal Economics, 117(3), 817869.
Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2003). introduction algorithms.
MIT Press, Cambridge, Massachusetts.
Faratin, P., Sierra, C., & Jennings, N. R. (2002). Using similarity criteria make trade-offs
automated negotiations. Artificial Intelligence Journal, 142(2), 205237.
Fatima, S. S., Wooldridge, M., & Jennings, N. R. (2002). influence information negotiation equilibrium. Agent Mediated Electronic Commerce IV, Designing Mechanisms
Systems, No. 2531 LNCS, pp. 180 193. Springer Verlag.
Fatima, S. S., Wooldridge, M., & Jennings, N. R. (2004). agenda based framework multiissue negotiation. Artificial Intelligence Journal, 152(1), 145.
Fatima, S. S., Wooldridge, M., & Jennings, N. R. (2006). efficient procedures multi-issue negotiation. Proceedings Eighth International Workshop Agent Mediated Electronic
Commerce (AMEC), pp. 7185, Hakodate, Japan.
Fershtman, C. (1990). importance agenda bargaining. Games Economic Behavior,
2, 224238.
Fershtman, C. (2000). note multi-issue two-sided bargaining: bilateral procedures. Games
Economic Behavior, 30, 216227.
Fershtman, C., & Seidmann, D. J. (1993). Deadline effects inefficient delay bargaining
endogenous commitment. Journal Economic Theory, 60(2), 306321.
Fishburn, P. C. (1988). Normative thoeries decision making risk uncertainty.
Bell, D. E., Raiffa, H., & Tversky, A. (Eds.), Decision making: Descriptive, normative,
prescriptive interactions. Cambridge University Press.
Fisher, R., & Ury, W. (1981). Getting yes: Negotiating agreement without giving in. Houghton
Mifflin, Boston.
Fudenberg, D., Levine, D., & Tirole, J. (1985). Infinite horizon models bargaining one sided
incomplete information. Roth, A. (Ed.), Game Theoretic Models Bargaining. University
Cambridge Press, Cambridge.
Fudenberg, D., & Tirole, J. (1983). Sequential bargaining incomplete information. Review
Economic Studies, 50, 221247.
Harsanyi, J. C. (1977). Rational behavior bargaining equilibrium games social situations. Cambridge University Press.
Harsanyi, J. C., & Selten, R. (1972). generalized Nash solution two-person bargaining games
incomplete information. Management Science, 18(5), 80106.
415

fiFATIMA , W OOLDRIDGE , & J ENNINGS

Hoel, M. (1986). Perfect equilibria sequential bargaining games nonlinear utility functions.
Scandinavian Journal Economics, 88(2), 383400.
Horst, R., & Tuy, H. (1996). Global optimazation: Deterministic approaches. Springer.
In, Y., & Serrano, R. (2003). Agenda restrictions multi-issue bargaining (ii): unrestricted agendas.
Economics Letters, 79, 325331.
Inderst, R. (2000). Multi-issue bargaining endogenous agenda. Games Economic Behavior, 30, 6482.
Keeney, R., & Raiffa, H. (1976). Decisions Multiple Objectives: Preferences Value Tradeoffs. New York: John Wiley.
Klein, M., Faratin, P., Sayama, H., & Bar-Yam, Y. (2003). Negotiating complex contracts. IEEE
Intelligent Systems, 8(6), 3238.
Kraus, S. (2001). Strategic negotiation multi-agent environments. MIT Press, Cambridge,
Massachusetts.
Kraus, S., Wilkenfeld, J., & Zlotkin, G. (1995). Negotiation time constraints. Artificial
Intelligence Journal, 75(2), 297345.
Kreps, D. M., & Wilson, R. (1982). Sequential equilibrium. Econometrica, 50, 863894.
Lax, D. A., & Sebenius, J. K. (1986). manager negotiator: Bargaining cooperation
competitive gain. Free Press, New York.
Livne, Z. A. (1979). role time negotiation. Ph.D. thesis, Massachusetts Institute
Technology.
Lomuscio, A., Wooldridge, M., & Jennings, N. R. (2003). classification scheme negotiation
electronic commerce. International Journal Group Decision Negotiation, 12(1),
3156.
Ma, C. A., & Manove, M. (1993). Bargaining deadlines imperfect player control. Econometrica, 61, 13131339.
Maes, P., Guttman, R., & Moukas, A. (1999). Agents buy sell. Communications
ACM, 42(3), 8191.
Martello, S., & Toth, P. (1990). Knapsack problems: Algorithms computer implementations.
John Wiley Sons. Chapter 2.
Mas-Colell, A., Whinston, M. D., & Green, J. R. (1995). Microeconomic Theory. Oxford University
Press.
Muthoo, A. (1999). Bargaining Theory Applications. Cambridge University Press.
Neumann, J. V., & Morgenstern, O. (1947). Theory Games Economic Behavior. Princeton:
Princeton University Press.
Osborne, M. J., & Rubinstein, A. (1990). Bargaining Markets. Academic Press, San Diego,
California.
Osborne, M. J., & Rubinstein, A. (1994). Course Game Theory. MIT Press.
Pollak, R. A. (1976). Interdependent preferences. American Economic Review, 66(3), 309320.
416

fiM ULTI -I SSUE N EGOTIATION



EADLINES

Pruitt, D. G. (1981). Negotiation Behavior. Academic Press.
Raiffa, H. (1982). Art Science Negotiation. Harvard University Press, Cambridge, USA.
Rosenschein, J. S., & Zlotkin, G. (1994). Rules Encounter. MIT Press.
Rubinstein, A. (1982). Perfect equilibrium bargaining model. Econometrica, 50(1), 97109.
Rubinstein, A. (1985). bargaining model incomplete information time preferences.
Econometrica, 53, 11511172.
Sandholm, T. (2000). Agents electronic commerce: component technologies automated negotiation coalition formation.. Autonomous Agents Multi-Agent Systems, 3(1), 7396.
Sandholm, T., & Vulkan, N. (1999). Bargaining deadlines. AAAI-99, pp. 4451, Orlando,
FL.
Schelling, T. C. (1956). essay bargaining. American Economic Review, 46, 281306.
Schelling, T. C. (1960). strategy conflict. Oxford University Press.
Sobel, J. (2005). Interdependent preferences reciprocity. Journal Economic Literature, XLIII,
392436.
Stahl, I. (1972). Bargaining Theory. Economics Research Institute, Stockholm School Economics, Stockholm.
van Damme, E. (1983). Refinements Nash equilibrium concept. Berlin:Springer-Verlag.
Varian, H. R. (2003). Intermediate Microeconomics. W. W. Norton Company.
Young, O. R. (1975). Bargaining: Formal theories negotiation. Urbana: University Illinois
Press.

417

fiJournal Artificial Intelligence Research 27 (2006) 505549

Submitted 06/06; published 12/06

Resource Allocation Among Agents MDP-Induced
Preferences
Dmitri A. Dolgov

ddolgov@ai.stanford.edu

Technical Research Department (AI & Robotics Group)
Toyota Technical Center
2350 Green Road
Ann Arbor, MI 48105, USA

Edmund H. Durfee

durfee@umich.edu

Electrical Engineering Computer Science
University Michigan
2260 Hayward St.
Ann Arbor, MI 48109, USA

Abstract
Allocating scarce resources among agents maximize global utility is, general, computationally challenging. focus problems resources enable agents execute
actions stochastic environments, modeled Markov decision processes (MDPs),
value resource bundle defined expected value optimal MDP
policy realizable given resources. present algorithm simultaneously solves
resource-allocation policy-optimization problems. allows us avoid explicitly representing utilities exponentially many resource bundles, leading drastic
(often exponential) reductions computational complexity. use algorithm
context self-interested agents design combinatorial auction allocating resources. empirically demonstrate effectiveness approach showing
can, minutes, optimally solve problems straightforward combinatorial
resource-allocation technique would require agents enumerate 2100 resource
bundles auctioneer solve NP-complete problem input size.

1. Introduction
problem resource allocation ubiquitous many diverse research fields
economics, operations research, computer science, applications ranging decentralized scheduling (e.g., Wellman, Walsh, Wurman, & MacKie-Mason, 2001) network routing (e.g., Feldmann, Gairing, Lucking, Monien, & Rode, 2003) transportation
logistics (e.g., Sheffi, 2004; Song & Regan, 2002) bandwidth allocation (e.g., McMillan,
1994; McAfee & McMillan, 1996), name few. core question resource allocation distribute set scarce resources among set agents (either cooperative
self-interested) way maximizes measure global utility, social welfare
(sum agents utilities) one popular criteria.
many domains, agents utility obtaining set resources defined
agent accomplish using resources. example, value vehicle
delivery agent defined additional revenue agent obtain using
vehicle. However, figure best utilize resource (or set resources), agent
c
2006
AI Access Foundation. rights reserved.

fiDolgov & Durfee

Available
Resources

Available
Actions

Resource-Allocation
Problem

Planning Problem
(MDP)

Utility Function
Resources

Best Plan &
Payoff

Figure 1: Dependency Cycle: formulate planning problems, agents need
know resources get, utility functions, define
input resource-allocation problem, depend solutions planning
problems.

often must solve non-trivial planning problem actions might long-term, nondeterministic effects. Therefore, agents value set resources defined solution
planning problem, formulate planning problem agent needs know
resources obtain. leads cyclic dependencies (depicted Figure 1), wherein
input resource allocation problem depends solution planning problem,
vice versa. Unfortunately, anything simplest domains, neither resourceallocation planning problem solved closed form, making impossible
obtain parameterized solutions.
focus paper solving interdependent problems resource allocation
stochastic planning. main question consider allocate resources
way maximizes social welfare agents utility function agent
defined Markov decision process (Puterman, 1994) whose action set parameterized
resources. paper, specifically focus non-consumable resources (such
vehicles) enable actions, consumed action execution.
briefly mention case consumable resources Section 6, refer work
Dolgov (2006) detailed treatment.
assume agents MDPs weakly-coupled, meaning agents interact
resources, resources allocated, transition reward
functions MDPs independent. model weakly-coupled MDPs connected
via shared resources similar Meuleau, Hauskrecht, Kim, Peshkin, Kaelbling,
Dean, Boutilier (1998) Benazera, Brafman, Meuleau, Hansen (2005),
differs assume resources allocated once, prior actions
taken. one-shot allocation assumption limits approach somewhat,
also allows approach apply broadly non-cooperative settings (without
assumption, game-theoretic analysis agents interactions significantly
complex). importantly, allows us avoid state space explosion (due including
resource information MDP states), limits work finding
approximately optimal solutions non-trivial problems.
main result presented paper thus new algorithm that,
conditions, optimally solves resource-allocation policy-optimization problems
simultaneously. considering two problems together, sidesteps dependency cycle
506

fiResource Allocation Among Agents MDP-Induced Preferences

mentioned above, allows us avoid explicit representation utility functions
resource bundles, leading exponential reduction complexity combinatorial
resource allocation flat utility functions. empirically demonstrate resulting
algorithm scales well finding optimal solutions problems involving numerous agents
resources.
algorithm viewed contributing new approach dealing computational complexity resource allocation domains complex utility functions
linearly decomposable resources (due effects substitutability
complementarity). combinatorial allocation problems, finding optimal allocation NP-complete (often exponentially large) space resource bundles (Rothkopf,
Pekec, & Harstad, 1998). Previous approaches addressing complexity included
determining classes utility functions lead tractable problems (as surveyed
de Vries & Vohra, 2003), iterative algorithms resource allocation preference elicitation (as surveyed Sandholm & Boutilier, 2006), concise languages expressing
agents preferences (Sandholm, 1999; Nisan, 2000; Boutilier & Hoos, 2001; Boutilier, 2002).
novelty approach respect explicitly embraces underlying processes define agents utility functions, cases processes
modeled resource-parameterized MDPs. so, approach use
MDP-based models concise language agents utility functions, importantly, directly exploits structure models drastically reduce computational
complexity simultaneously solving planning resource-allocation problems.
context cooperative agents, approach viewed way solving
weakly-coupled multiagent MDPs, agents transition reward functions independent, space joint actions constrained, as, example, models used
Singh Cohn (1998) Meuleau et al. (1998). perspective, concept
resources viewed compact way representing interactions agents,
similarly model used Bererton, Gordon, Thrun (2003); however, work
differs number assumptions. Moreover, algorithms easily modified work
models constraints joint actions modeled directly (for example,
via SAT formulas).
non-cooperative agents, apply resource-allocation algorithm mechanismdesign problem (e.g., Mas-Colell, Whinston, & Green, 1995), goal allocate
resources among agents way maximizes social welfare, given
participating agent selfishly maximizing utility. domains self-interested
agents complex preferences exhibit combinatorial effects resources,
combinatorial auctions (e.g., de Vries & Vohra, 2003) often used resource-allocation.
Generalized Vickrey Auction (GVA) (MacKie-Mason & Varian, 1994), extension Vickrey-Clarke-Groves (VCG) mechanisms (Vickrey, 1961; Clarke, 1971; Groves,
1973) combinatorial auctions, particularly attractive nice analytical
properties (as described Section 4.1). develop variant VCG auction,
agents submit resource-parameterized MDPs bids, auctioneer simultaneously solves resource-allocation policy-optimization problems, thus retaining
compact representation agents preferences throughout process. describe extensions mechanism distributing computation encoding MDP information
reduce revelation private information.
507

fiDolgov & Durfee

remainder paper proceeds follows. brief review MDPs
Section 2, present (in Section 3) model decision-making agent: resourceparameterized MDP capacity constraints. analyze problem optimal policy
formulation resource-parameterized capacity-constrained MDP, study properties, present solution algorithm, based formulation (NP-complete)
problem mixed integer program.
building blocks, move multiagent setting present main
result, algorithm simultaneously allocating resources planning across agents
(Section 4). Based algorithm, design combinatorial auction allocating
resources among self-interested agents. describe distributed implementation
mechanism, discuss techniques preserving information privacy. Section 5,
analyze computational efficiency approach, empirically demonstrating exponential reductions computational complexity, compared straightforward combinatorial
resource-allocation algorithm flat utility functions. Finally, Section 6, conclude
discussion possible generalizations extensions approach. conciseness
better readability, proofs generalizations deferred appendices.

2. Markov Decision Processes
base model agents decision problems infinite-horizon fully-observable MDPs
total expected discounted reward optimization criterion (although results
also applicable classes MDPs, MDPs average per-step rewards).
section introduces notation assumptions, serves brief overview
basic MDP results (see, example, text Puterman (1994) detailed discussion
material section).
classical single-agent, unconstrained, stationary, fully-observable MDP defined
4-tuple hS, A, p, ri, where:
finite set states agent in.
finite set actions agent execute.
p : 7 [0, 1] defines transition function. probability agent
goes state upon execution action state p(|s, a).

P assume that, action, corresponding transition matrix stochastic:
p(|s, a) = 1 S, A.
r : 7 R defines reward function. agent obtains reward r(s, a)
executes action state S. assume rewards bounded.
discrete-time fully-observable MDP, time step, agent observes current
state system chooses action according policy. policy said
Markovian (or history-independent) choice action depend history
states actions encountered past, rather current state
time. If, addition that, policy depend time, called stationary.
definition, stationary policy always Markovian. deterministic policy always prescribes
execution action state, randomized policy chooses actions
according probability distribution.
508

fiResource Allocation Among Agents MDP-Induced Preferences

Following standard notation (Puterman, 1994), refer different classes policies
xy , x = {H, M, S} specifies whether policy History-dependent, Markovian,
Stationary, = {R, D} specifies whether policy Randomized Deterministic
(e.g., class stationary deterministic policies labeled SD ). Obviously, Hy
Sy xR xD , history-dependent randomized policies HR stationary
deterministic policies SD least general, respectively.
stationary randomized policy thus mapping states probability distributions
actions: : 7 [0, 1], (s, a) defines probability action
executed state s. stationary deterministic policy viewed degenerate case
randomized policy one action state nonzero
probability executed.
unconstrained discounted MDP, goal find policy maximizes
total expected discounted reward infinite time horizon:1

hX

U (, ) = E
()t rt (, ) ,
(1)
t=0

[0, 1) discount factor (a unit reward time + 1 worth
agent reward time t), rt (random) reward agent receives time t,
whose distribution depends policy initial distribution state space
: 7 [0, 1].
One important results theory MDPs states that, unconstrained discounted MDP total expected reward optimization criterion, always exists optimal policy stationary, deterministic, uniformly optimal,
latter term means policy optimal distributions starting state.2
several commonly-used ways finding optimal policy, central
concept value function policy, v : 7 R, v (s) expected
cumulative value reward agent would receive started state behaved
according policy . given policy , value every state unique solution
following system |S| linear equations:
X
X
v (s) =
r(s, a)(s, a) +
p(|s, a)v (),
S.
(2)




find optimal policy, handy consider optimal value function v : 7 R,
v (s) represents value state s, given agent behaves optimally.
optimal value function satisfies following system |S| nonlinear equations:
h

X
v (s) = max r(s, a) +
p(|s, a)v () ,
S.
(3)




v,

Given optimal value function
optimal policy simply act greedily respect

v (with method tie-breaking case multiple optimal actions):
h

(
P
1 arg maxa r(s, a) + p(|s, a)v () ,
(s, a) =
(4)
0 otherwise.
1. Notation: (x)y exponent, xy superscript.
2. Uniform optimality policies reason included component textbook MDP.

509

fiDolgov & Durfee

One possible ways solving optimal value function formulate
nonlinear system (3) linear program (LP) |S| optimization variables v(s)
|S||A| constraints:
X
min
(s)v(s)


subject to:

(5)

v(s) r(s, a) +

X

p(|s, a)v(),

S, A,



arbitrary constant vector |S| positive components ((s) > 0 S).3
many problems (including ones focus paper), useful consider equivalent dual LP |S||A| optimization variables x(s, a) |S|
constraints:4
XX
r(s, a)x(s, a)
max
x





subject to:
X
XX
x(, a)
x(s, a)p(|s, a) = (),




(6)
S;



x(s, a) 0

S, A.

optimization variables x(s, a) often called visitation frequencies occupation measure policy. think initial probability distribution, x(s, a)
interpreted
P total expected number times action executed state s.
Then, x(s) = x(s, a) gives total expected flow state s, constraints
LP interpreted conservation flow states.
optimal policy computed solution dual LP as:
x(s, a)
,
(7)
(s, a) = P
x(s, a)
P
non-negativity guarantees x(s, a) > 0 S. general, appears
lead randomized policies. However, bounded LP n constraints always basic
feasible solution (e.g., Bertsimas & Tsitsiklis, 1997), definition
n non-zero components. strictly positive, basic feasible solution LP (7)
precisely |S| nonzero components (one state), guarantees existence
optimal deterministic policy. policy easily obtained LP solvers
(e.g., simplex always produce solutions map deterministic policies).
Furthermore, mentioned above, unconstrained discounted MDPs, always
exist policies uniformly optimal (optimal initial distributions).
dual LP (6) yields uniformly optimal policies strictly positive used. However,
3. overloading objective function coefficients initial probability distribution
MDP earlier intentional explained shortly.
4. Note authors (e.g., Altman, 1996) prefer opposite convention, (6) called dual,
(5), primal.

510

fiResource Allocation Among Agents MDP-Induced Preferences

solution (x) dual LP retains interpretation expected number times state
visited action executed initial probability distribution
used LP.
main benefit dual LP (6) manifested constrained MDPs (Altman, 1999;
Kallenberg, 1983; Heyman & Sobel, 1984), action, addition producing
reward r(s, a), also incurs vector costs k (s, a) : 7 R k [1..K]. problem maximize expected reward, subject constraints expected costs.
Constrained models type arise many domains, telecommunication applications (e.g., Ross & Chen, 1988; Ross & Varadarajan, 1989), often desirable
maximize expected throughput, subject conditions average delay. problems,
constraints imposed expected costs, solved polynomial time
using linear programming simply augmenting dual LP (6) following linear
constraints:
XX
k (s, a)x(s, a) bk ,
k [1..K],
(8)




bk upper bound expected cost type k. resulting constrained MDP
differs standard unconstrained MDP: particular, deterministic policies
longer optimal, uniformly optimal policies not, general, exist problems
(Kallenberg, 1983).
reason easily augmentable constraints, dual LP (6) also
forms basis approach. However, constraints arise resource-allocation
problems focus paper different linear constraints (8),
leading different optimization problems different properties requiring different
solution techniques (as described detail Section 3).
conclude background section introducing simple unconstrained MDP
serve basis running example, refer throughout rest
paper.
Example 1 Consider simple delivery domain, depicted Figure 2, agent
obtain rewards delivering furniture (action a1 ) delivering appliances (action a2 ).
Delivering appliances produces higher rewards (as shown diagram),
damage delivery vehicle. agent delivers furniture, damage vehicle
negligible, whereas agent delivers appliances, vehicle guaranteed function
reliably first year (state s1 ), (state s2 ) 10% probability failure,
per year. vehicle serviced (action a3 ), resetting condition, expense
lowering profits. truck break (state s3 ), repaired (action a4 ),
significant negative impact profits. assume discount factor = 0.9.
optimal value function v (s1 ) 95.3, v (s2 ) 94.7, v (s3 ) 86.7,
corresponding optimal occupation measure (assuming uniform ) following (listing
non-zero elements): x(s1 , a2 ) 4.9, x(s2 , a3 ) 4.8, x(s3 , a4 ) 0.3. maps
optimal policy dictates agent start delivering appliances (action a2
state s1 ), service vehicle first year (action a3 state s2 ), fix
vehicle ever gets broken (a4 s3 ) (the latter zero probability happening
policy agent starts state s1 s2 ).

511

fiDolgov & Durfee

a1: deliver furniture
p=1
r=5

s1
(initial)

a4: fix truck
p=1
r=1

a1: deliver furniture
p=1
r=5

a2: deliver appliances
p=1
r=10
a3: service truck
p=1
r=9

s2
(2nd year)
a2: deliver appliances
p=0.9
r=10
p=0.1
r=10

s3
(truck broken)

Figure 2: Unconstrained MDP example delivery domain. Transition probabilities (p)
rewards (r) shown diagram. Actions shown result transition
state reward. also noop action a0 corresponds
nothing; change state produces zero reward.

3. Agent Model: Resource-Parameterized MDP
section, introduce model decision-making agent, describe
single-agent stochastic policy-optimization problem defines agents preferences
resources. show that, single-agent problem, formulated MDP whose
action set parameterized resources available agent, stationary deterministic
policies optimal, uniformly optimal policies not, general, exist. also show
problem finding optimal policies NP-complete. Finally, present policyoptimization algorithm, based formulation problem mixed integer linear
program (MILP).
model agents resource-parameterized MDP follows. agent set
actions potentially executable, action requires certain combination
resources. capture local constraints sets resources agent use, use
concept capacities: resource capacity costs associated it,
agent capacity constraints. example, delivery company needs vehicles loading
equipment (resources allocated) make deliveries (execute actions). However,
equipment costs money requires manpower operate (the agents local capacity
costs). Therefore, amount equipment agent acquire successfully utilize
constrained factors budget limited manpower (agents local capacity
bounds). two-layer model capacities resources represented separately might
seem unnecessarily complex (why fold together impose constraints directly
resources?), separation becomes evident useful multiagent model
discussed Section 4. emphasize difference here: resources items
allocated among agents, capacities define inherent limitations individual
agent combinations resources usefully possess.
agents optimization problem choose subset available resources
violate capacity constraints, best policy feasible bundle
resources yields highest utility. words, single-agent problem analyzed
512

fiResource Allocation Among Agents MDP-Induced Preferences

section constraints total resource amounts (they introduced
multiagent problem next section), constraints due agents
capacity limits. Adding limited resource amounts single-agent model would
simple matter, since constraints handled simple pruning agents
action space. Further, note without capacity constraints, single-agent problem
would trivial, would always optimal agent simply take resources
potential use. However, presence capacity constraints, face problem
similar cyclic dependency Figure 1: resource-selection problem requires
knowing values resource bundles, defined planning problem,
planning problem ill-defined resource bundle chosen. section,
focus single-agent problem selecting optimal subset resources satisfies
agents capacity constraints assume agent value acquiring additional
resources exceed capacity bounds.
resources model outlined non-consumable, i.e., actions require
resources consume execution. mentioned Introduction,
work focus non-consumable resources, briefly outline case
consumable resources Section 6.
model agents optimization problem n-tuple hS, A, p, r, O, , C, ,
b, i:
hS, A, p, ri standard components MDP, defined earlier Section 2.
set resources (e.g., = {production equipment, vehicle, . . .}). use
refer resource type.
: 7 R function specifies resource requirements actions;
(a, o) defines much resource action needs executable (e.g.,
(a, vehicle) = 1 means action requires one vehicle).
C set capacities agent (e.g., C = {space, money, manpower, . . .}).
use c C refer capacity type.
: C 7 R function specifies capacity costs resources; (o, c) defines
much capacity c C unit resource requires (e.g., (vehicle, money) =
$50000 defines monetary cost vehicle, (vehicle, manpower) = 2 means
two people required operate vehicle).

b : C 7 R specifies upper bound capacities;
b(c) gives upper bound
capacity c C (e.g.,
b(money) = $1,000,000 defines budget constraint,

b(manpower) = 7 specifies size workforce).
: 7 R initial probability distribution; (s) probability agent
starts state s.
goal find policy yields highest expected reward, conditions resource requirements policy exceed capacity bounds
513

fiDolgov & Durfee

agent. words, solve following mathematical program:5
max U (, )


subject to:
n
X
X

(o, c) max (a, o)H
(s, a)
b(c),




(9)
c C,



H Heaviside step function nonnegative argument, defined as:
(
0 z = 0,
H(z) =
1 z > 0.
constraint (9) interpreted follows. argument H nonzero
theP
policy assigns nonzero probability using action least one state. Thus,
function
H( (s, a)) serves indicator

us whether agent plans use
P tells
action policy, max (a, o)H( (s, a)) tells us much resource
agent needs policy. take max respect a, resource
used different actions. Therefore, summed resources o, left-hand
side gives us total requirements policy terms capacity c,
greater bound
b(c).
following example illustrates single-agent model.
Example 2 Let us augment Example 1 follows. Suppose agents needs obtain
truck perform delivery actions (a1 a2 ). truck also required service
repair actions (a3 a4 ). Further, deliver appliances, agent needs acquire
forklift, needs hire mechanic able repair vehicle (a4 ). noop
action a0 requires resources. maps model three resources (truck, forklift,
mechanic): = {ot , , om }, following action resource costs (listing
non-zero ones):
(a1 , ot ) = 1, (a2 , ot ) = 1, (a2 , ) = 1, (a3 , ot ) = 1, (a4 , ot ) = 1, (a4 , om ) = 1.
Moreover, suppose resources (truck ot , forklift , mechanic om )
following capacity costs (there one capacity type, money: C = {c1 })
(ot , c1 ) = 2, (of , c1 ) = 3, (om , c1 ) = 4,
agent limited budget
b = 8. can, therefore acquire two
three resources, means optimal solution unconstrained problem
Example 1 longer feasible.

Let us observe MDP-based model agents preferences presented
fully general discrete indivisible resources, i.e., non-decreasing utility function
resource bundles represented via resource-constrained MDP model described
above.
5. formulation assumes stationary policy, supported argument Section 3.1.

514

fiResource Allocation Among Agents MDP-Induced Preferences

Theorem 1 Consider finite set n indivisible resources = {oi } (i [1, n]),
N available units resource. Then, non-decreasing utility function
defined resource bundles f : [0, m]n 7 R, exists resource-constrained MDP
hS, A, p, r, O, , C, ,
b, (with resource set O) whose induced utility function
resource bundles f . words, every resource bundle z [0, m]n ,
value optimal policy among whose resource requirements exceed z
(call set (z)) f (z):
f : [0, m]n 7 R, hS, A, p, r, O, , C, ,
b, :
n fi
h

X

fi
z [0, m]n , (z) = fi max (a, oi )H
(s, a) zi = max U (, ) = f (z).




(z)

Proof: See Appendix A.1.

Let us comment Theorem 1 establishes generality MDP-based preference model introduced section, construction used proof little practical interest, requires MDP exponentially large state action space. Indeed,
advocate mapping arbitrary unstructured utility functions exponentially-large
MDPs general solution technique. Rather, contention techniques apply domains utility functions induced stochastic decision-making process
(modeled MDP), thus resulting well-structured preferences resources
exploited drastically lower computational complexity resource-allocation
algorithms.
3.1 Properties Single-Agent Constrained MDP
section, analyze constrained policy-optimization problem (9). Namely,
show stationary deterministic policies optimal problem, meaning
necessary consider randomized, history-dependent policies. However, solutions
problem (9) not, general, uniformly optimal (optimal initial distribution).
Furthermore, show (9) NP-hard, unlike unconstrained MDPs,
solved polynomial time (Littman, Dean, & Kaelbling, 1995).
begin showing optimality stationary deterministic policies (9).
following, use HR refer class history-dependent randomized policies (the
general policies), SD HR refer class stationary deterministic
policies.
Theorem 2 Given MDP = hS, A, p, r, O, , C, ,
b, resource capacity
HR
constraints, exists policy
feasible solution , exists
stationary deterministic policy SD SD also feasible, expected total reward
SD less :
HR , SD SD : U ( SD , ) U (, )
Proof: See Appendix A.2.

result Theorem 2 surprising: intuitively, stationary deterministic
policies optimal, history dependence increase utility policy,
515

fiDolgov & Durfee

using randomization increase resource costs. latter true including action policy incurs costs terms resources regardless
probability executing action (or expected number times action
executed). true dealing non-consumable resources; property hold MDPs consumable resources (as discuss detail
Section 6).
show uniformly optimal policies always exist constrained
problem. result well known another class constrained MDPs, constraints
imposed total expected costs proportional expected number
times corresponding actions executed (discussed earlier Section 2). MDPs
constraints arise, example, bounds imposed expected usage
consumable resources, mentioned Section 2, problems solved using
linear programming augmenting dual LP (6) linear constraints expected
costs (8). Below, establish result problems non-consumable resources
capacity constraints.
Observation 1 always exist uniformly optimal solutions (9).
words, exist two constrained MDPs differ initial conditions: =
hS, A, p, r, O, , C, ,
b, 0 = hS, A, p, r, O, , C, ,
b, 0 i, policy
optimal problems simultaneously, i.e., two policies 0
optimal solutions 0 , respectively, following holds:
U (, ) > U ( 0 , ),

U (, 0 ) < U ( 0 , 0 )

(10)

demonstrate observation example.
Example 3 Consider resource-constrained problem Example 2. easy see
initial conditions = [1, 0, 0] (the agent starts state s1 certainty),
optimal policy states s1 s2 Example 1 (s1 a2 s2 a3 ),
which, given initial conditions, results zero probability reaching state s3 (to
noop a0 assigned). policy requires truck forklift. However,
agent starts state s3 ( = [0, 0, 1]), optimal policy fix truck (execute a4
s3 ), resort furniture delivery (do a1 s1 assign noop ao s2 ,
never visited). policy requires mechanic truck. two policies
uniquely optimal corresponding initial conditions, suboptimal initial
conditions, demonstrates uniformly optimal policy exists example.
intuition behind fact uniformly optimal policies not, general, exist
constrained MDPs since resource information part MDP state
space, constraints imposed resource usage, principle Bellman optimality hold (optimal actions different states cannot chosen independently).
Given constrained MDP, possible construct equivalent unconstrained MDP
standard properties optimal solutions (by folding resource information
state space, modeling resource constraints via transition function), resulting
state space exponential number resources.
analyze computational complexity optimization problem (9).
516

fiResource Allocation Among Agents MDP-Induced Preferences

Theorem 3 following decision problem NP-complete. Given instance MDP
hS, A, p, r, O, , C, ,
b, resources capacity constraints, rational number ,
exist feasible policy , whose expected total reward, given , less ?
Proof: See Appendix A.3.

Note complexity result stems limited capacities agents
fact define resource requirements policy set resources
needed carry actions nonzero probability executed. If,
however, defined constraints expected resource requirements, actions
low probability executed would lower resource requirements, optimal policies
would randomized, problem would equivalent knapsack continuously
divisible items, solvable polynomial time via LP formulation MDPs
linear constraints (6,8).
3.2 MILP Solution
analyzed properties optimization problem (9), present
formulation (9) mixed integer linear program (MILP). Given established
NP-completeness (9) previous section, MILP (also NP-complete) reasonable
formulation allows us reap benefits vast selection efficient algorithms
tools (see, example, text Wolsey, 1998 references therein).
section rest paper assume resource requirements
actions binary, i.e., (a, o) = {0, 1}. make assumption simplify
discussion, limit generality results. briefly describe case
non-binary resource costs Appendix B completeness, refer work
Dolgov (2006) detailed discussion examples.
Let us rewrite (9) occupation measure coordinates x adding constraints
(9) standard LP occupancy coordinates (6). Noticing (for states
nonzero probability visited) (s, a) x(s, a) either zero nonzero simultaneously:
X
X


x(s, a) ,
A,
(s, a) = H
H




that, (a, o) = {0, 1}, total resource requirements policy simplified
follows:
X

n
X
X

max (a, o)H
x(s, a) = H
(a, o)
x(s, a) ,
O,
(11)








get following program x:
XX
max
x(s, a)r(s, a)
x





subject to:
X
XX
x(, a)
x(s, a)p(|s, a) = (),


X



(o, c)H



X


S;



(a, o)

X


x(s, a)
b(c),

c C;



x(s, a) 0,

S, A.
517

(12)

fiDolgov & Durfee

challenge solving mathematical program constraints nonlinear
due Heaviside function H.
linearize Heaviside function, augment original
variables
Poptimization
x
P
set |O| binary variables (o) {0, 1}, (o) = H
(a, o)
x(s, a) .
words, (o) indicator variable shows whether policy requires resource o.
Using (o), rewrite resource constraints (12) as:
X
(o, c)(o)
b(c),
c C,
(13)


linear . synchronize x via following linear inequalities:
X
X
1/X
(a, o)
x(s, a) (o),
O,
(14)




P
P
X maxo (a, o) x(s, a) normalization constant, upper bound argument H() used. bound X guaranteed
exist
P
1 max
(a,
o),
since

discounted
problems.

example,


use
X
=
(1

)


P
1
x valid occupation measure MDP
s,a x(s, a) = (1 )
6
discount factor .
Putting together, problem (9) finding optimal policies resource constraints formulated following MILP:
XX
max
x(s, a)r(s, a)
x,





subject to:
X
XX
x(, a)
x(s, a)p(|s, a) = (),


X



S;



(o, c)(o)
b(c),

c C;

X

O;

(15)



1/X

(a, o)



X

x(s, a) (o),



x(s, a) 0,

S, A;

(o) {0, 1},

O.

illustrate MILP construction example.
Example 4 Let us formulate MILP constrained problem Example 3. Recall problem three resources = {ot , , om } (truck, forklift,
mechanic), one capacity type C = {c1 } (money), actions following resource
requirements (again, listing nonzero ones):
(a1 , ot ) = 1, (a2 , ot ) = 1, (a2 , ) = 1, (a3 , ot ) = 1, (a4 , ot ) = 1, (a4 , om ) = 1
P
P
6. Instead using single X resources, different X(o) (a, o) x(s, a) used
every resource, leading uniform normalization potentially better numerical stability
MILP solver.

518

fiResource Allocation Among Agents MDP-Induced Preferences

resources following capacity costs:
(ot , c1 ) = 2,

(of , c1 ) = 3,

(om , c1 ) = 4,

agent limited budget, i.e., capacity bound,
b(c1 ) = 8.
compute optimal policy arbitrary , formulate problem
MILP described above. Using binary variables (o) = {(ot ), (of ), (om )},
express constraint capacity cost following inequality:
2(ot ) + 3(of ) + 4(om ) 8,
constraints synchronizeP
occupation measure x binary indicators (o),
set X = (1 )1 maxo (a, o) = 4(1 )1 . Combining
constraints (15), get MILP 12 continuous 4 binary variables,
|S| + |C| + |O| = 3 + 3 + 1 = 7 constraints (not counting last two sets range constraints).

mentioned earlier, even though solving programs is, general, NP-complete
task, wide variety efficient algorithms tools so. Therefore,
one benefits formulating optimization problem (9) MILP allows
us make use highly efficient existing tools.

4. Multiagent Resource Allocation
consider multiagent problem resource allocation several agents,
resource preferences agents defined constrained MDP model
described previous section. reiterate main assumptions problem:
1. Weak coupling. assume agents weakly-coupled (Meuleau et al., 1998),
i.e., interact shared resources, resources allocated, agents transitions rewards independent. assumption critical
results.7
2. One-shot resource allocation. resources distributed agents
start executing MDPs. reallocation resources MDP
phase. assumption critical results; allowing reallocation resources
would violate weak-coupling assumption.
3. Initial central control resources. assume beginning
resource-allocation phase, resources controlled single authority.
standard sell-auction setting. problems resources distributed
7. agents cooperative, assumption weak coupling relaxed (at expense
increase complexity), MILP-based algorithm simultaneously performing policy optimization resource allocation applied consider joint state spaces interacting
agents. self-interested agents, violation weakly-coupled assumption would mean
agents would playing Markov game (Shapley, 1953) resources allocated, would
significantly complicate strategic analysis agents bidding strategies initial resource
allocation.

519

fiDolgov & Durfee

among agents begin with, face problem designing computationallyefficient combinatorial exchange (Parkes, Kalagnanam, & Eso, 2001),
complicated problem outside scope work. However, many
ideas presented paper could potentially applicable domain well.
4. Binary resource costs. before, assume agents resource costs binary.
assumption limiting. case non-binary resources discussed
Appendix B.
Formally, input resource-allocation problem consists following:
set agents; use refer agent.
{hS, A, pm , rm , , ,
bm i} collection weakly-coupled single-agent MDPs,
defined single-agent model Section 3. simplicity, without loss
generality, assume agents state action spaces A,
transition reward functions pm rm , initial conditions ,
well resource requirements : 7 {0, 1} capacity bounds

bm : C 7 R. also assume agents discount factor ,
assumption trivially relaxed.
C sets resources capacities, defined exactly single-agent
model Section 3.
: C 7 R specifies capacity costs resources, defined exactly
single-agent model Section 3.
b : 7 R specifies upper bound amounts shared resources (this
defines additional bound multiagent problem).
Given above, goal design mechanism allocating resources
agents economically efficient way, i.e., way maximizes social welfare
agents (one often-used criteria mechanism design). would also like
mechanism efficient computational standpoint.
Example 5 Suppose two delivery agents. MDP capacity constraints
first agent exactly defined previously Examples 1 2. MDP
second agent almost first agent, difference
gets slightly higher reward delivering appliances: r2 (s1 , a2 ) = 12 (whereas
r1 (s1 , a2 ) = 10 first agent). Suppose two trucks, one forklift, one
mechanic shared two agents. bounds specified follows:
b(ot ) = 2,

b(of ) = 1,

b(om ) = 1.

problem decide agent get forklift, get
mechanic (trucks plentiful example).

520

fiResource Allocation Among Agents MDP-Induced Preferences

4.1 Combinatorial Auctions
previously mentioned, problem finding optimal resource allocation among
self-interested agents complex valuations combinations resources arises
many different domains (e.g., Ferguson, Nikolaou, Sairamesh, & Yemini, 1996; Wellman
et al., 2001) often called combinatorial allocation problem. natural widely
used mechanism solving problems combinatorial auction (CA) (e.g., de Vries
& Vohra, 2003). CA, agent submits set bids resource bundles
auctioneer, decides resources agent get price.
Consider problem allocating among set agents set indivisible resources O, total quantity resource bounded b(o). earlier
simplifying assumption actions resource requirements binary implies agents
interested bundles contain one unit particular resource.
combinatorial auction, agent submits bid bm
w (specifying much
agent willing pay) every bundle w W value um
w > 0.
cases, possible express bids without enumerating bundles (for example, using
XOR bidding language (Sandholm, 1999) necessary consider bundles
strictly positive value, subset bundle value).
techniques often reduce complexity resource-allocation problem, not,
general, avoid exponential blow number bids. Therefore, describe
simplest combinatorial auction flat bids, noted many concise
bidding languages exist special cases reduce number explicit bids.
collecting bids, auctioneer solves winner-determination problem
(WDP), solution prescribes resources distributed among
, utility um q
agents prices. agent wins bundle w price qw
w
w
(we assuming risk-neutral agents quasi-linear utility functions). Thus, optimal
bidding strategy agent depends auctioneer allocates resources sets
prices.
Vickrey-Clarke-Groves (VCG) mechanisms (Vickrey, 1961; Clarke, 1971; Groves, 1973)
widely used family mechanisms certain attractive properties (discussed detail below). instantiation VCG mechanism context
combinatorial auctions Generalized Vickrey Auction (GVA) (MacKie-Mason & Varian, 1994), allocates resources sets prices follows. Given bids bm
w
agents, auctioneer chooses allocation maximizes sum agents bids.
problem NP-complete (Rothkopf et al., 1998) expressed following inm = {0, 1} indicator variables
teger program, optimization variables zw
show whether bundle w assigned agent m, nwo = {0, 1} specifies whether bundle w
contains o:8

8. related algorithms solving WDP (e.g., Sandholm, 2002), use
integer program (16) representative formulation class algorithms perform search
space binary decisions resource bundles.

521

fiDolgov & Durfee

X

max
z

X


zw
bw

mM wW

subject to:
X

zw
1,

M;

(16)

wW

X

X

mM

wW


zw
nwo b(o),

O.

first constraint (16) says agent receive one bundle,
second constraint ensures total amount resource assigned agents
exceed total amount available. Notice MILP (16) performs summation
exponentially large sets bundles w W . outlined above, auction XOR
bidding, sets would typically smaller, but, general, still exponentially large.
GVA assigns resources according optimal solution ze (16) sets payment
agent to:
X


m0 m0
qw
= Vm

zew
bw ,
(17)
m0 6=m

Vm
value (16) participate auction (the optimal
value submit bids), second term sum agents bids
solution ze WDP participating.
GVA number nice properties. strategy-proof, meaning dominant

strategy every agent bid true value every bundle: bm
w = uw . auction
economically efficient, meaning allocates resources maximize social
welfare agents (because, agents bid true values, objective function
(16) becomes social welfare). Finally, GVA satisfies participation constraint,
meaning agent decreases utility participating auction.
straightforward way implement GVA MDP-based problem following.
Let agent enumerate resource bundles W satisfy local capacity
constraints defined
bm (c) (this sufficient MDP model implies free disposal
resources agents, make assumption auctioneer).
bundle w W , agent would determine feasible action set A(w) formulate
MDP (w) = hS, A(w), pm (w), rm (w), i, pm (w) rm (w) transition
reward functions defined pruned action space A(w). Every agent would
solve (w) corresponding feasible bundle find optimal policy
em (w), whose



expected discounted reward would define value bundle w: uw = U (e
(w), ).
mechanism suffers two major complexity problems. First, agents
enumerate exponential number resource bundles compute value
solving corresponding (possibly large) MDP. Second, auctioneer solve
NP-complete winner-determination problem exponentially large input. following
sections devoted tackling complexity problems.

Example 6 Consider two-agent problem described Example 5, two trucks, one
forklift, services one mechanic auctioned off. Using straightforward
version combinatorial auction outlined above, agent would consider
522

fiResource Allocation Among Agents MDP-Induced Preferences

2|O| = 23 = 8 possible resource bundles (since resource requirements agents
binary, neither agent going bid bundle contains two trucks). every
resource bundle, agent formulate solve corresponding MDP
compute utility bundle.
example, assume agents start state s1 (different initial conditions
would result different expected rewards, thus different utility functions), value
null resource bundle agents would 0 (since action would able
execute noop a0 ). hand, value bundle [ot , , om ] = [1, 1, 1]
contains resources would 95.3 first agent 112.4 second one.
value bundle [1, 1, 0] agent would value [1, 1, 1] (since
optimal policies initial conditions put s1 require mechanic).
agents submit bids auctioneer, solve WDP via
integer program (16) |M|2|O| = 2(2)3 = 16 binary variables. Given above,
optimal way allocate resources would assign truck agents,
forklift second agent, mechanic either (or neither) two. Thus,
agents would receive bundles [1, 0, 0] [1, 1, 0], respectively, resulting social welfare
50 + 112.4 = 162.4. However, least one agents non-zero probability
starting state s3 , value resource bundles involving mechanic would change
drastically, would optimal resource allocation social value.

4.2 Avoiding Bundle Enumeration
avoid enumerating resource bundles non-zero value agent, two things
required: i) mechanism support concise bidding language allows
agent express preferences auctioneer compact manner, ii)
agents able find good representation preferences language.
simple way achieve model create auction agents submit
specifications resource-parameterized MDPs auctioneer bids: language
compact and, given assumption agent formulate planning problem
MDP, require additional computation agents. However,
changes communication protocol agents auctioneer, similarly
concise bidding languages (Sandholm, 1999; Nisan, 2000; Boutilier & Hoos, 2001;
Boutilier, 2002). such, simply moves burden solving valuation problem
agents auctioneer, lead gains computational
efficiency. mechanism also implications information privacy issues,
agents reveal local MDPs auctioneer (which might want
do). Nevertheless, build idea increase efficiency solving
valuation winner-determination problems keeping agents
MDP information private. address ways maintaining information privacy next
section, moment focus improving computational complexity agents
valuation auctioneers winner-determination problems.
question pose section follows. Given bid agent consists MDP, resource information capacity bounds hS, A, pm , rm , , ,
bm i,
auctioneer formulate solve winner-determination problem efficiently
523

fiDolgov & Durfee

simply enumerating agents resource bundles solving standard integer
program (16) exponential number binary variables?
Therefore, goal auctioneer find joint policy (a collection single-agent
policies weak-coupling assumption) maximizes sum expected total
discounted rewards agents, conditions that: i) agent assigned set
resources violates capacity bound
bm (i.e., agent assigned resources
carry), ii) total amounts resources assigned agents exceed
global resource bounds b(o) (i.e., cannot allocate agents resources
available). problem expressed following mathematical program:
X
max
Um ( , )




subject to:
X
X

(o, c)H (a, o)
(s, a)
bm (c),


X

c C, M;

(18)




(a, o)H

X




(s, a) b(o),

O.





Obviously, decision version problem NP-complete, subsumes singleagent MDP capacity constraints, NP-completeness shown Section 3.1.
Moreover, problem remains NP-complete even absence single-agent capacity
constraints. Indeed, global constraint amounts shared resources sufficient
make problem NP-complete, shown straightforward reduction
KNAPSACK, similar one used single-agent case Section 3.1.
linearize (18) similarly single-agent problem Section 3.2, yielding
following MILP, simply multiagent version (15) (recall assumption
section resource requirements binary):
XXX
max
xm (s, a)rm (s, a)
x,







subject to:
X
XX
xm (, a)
xm (s, a)pm (|s, a) = (),


X



S, M;



(o, c) (o)
bm (c),

c C, M;
(19)



X



(o) b(o),

O;



1/X

X

(a, o)



X

xm (s, a) (o),

O, M;



xm (s, a) 0,

S, A, M;



(o) {0, 1},

O, M,

X maxo,m (a, o) xm (s, a) upper bound argument H(),
used normalization. single-agent case, bound guaranteed exist
discounted MDPs easy obtain.
P

P

524

fiResource Allocation Among Agents MDP-Induced Preferences

MILP (19) allows auctioneer solve WDP without enumerate
possible resource bundles. compared standard WDP formulation (16),
order |M|2|O| binary variables, (19) |M||O| binary variables.
exponential reduction attained exploiting knowledge agents MDP-based
valuations simultaneously solving policy-optimization resource-allocation problems. Given worst-case solution time MILPs exponential number
integer variables, reduction significant impact worst-case performance
mechanism. average-case running time also reduced drastically, demonstrated
experiments, presented Section 5.
Example 7 apply mechanism discussed running example alternative straightforward combinatorial auction presented Example 6, winnerdetermination MILP (19) look follows. |M||S||A| = (2)(3)(5) = 30 continuous occupation-measure variables xm , |M||O| = (2)(3) = 6 binary variables (o).
|M||S| = (2)(3) = 6 conservation-of-flow constraints involve continuous
variables only, well |M||C| + |O| + |M||O| = (2)(1) + 3 + (2)(3) = 9 constraints
involve binary variables.
capacity constraints agents exactly single-agent case described
Example 4, global resource constraints be:
1 (ot ) + 2 (ot ) 2,

1 (of ) + 2 (of ) 1,

1 (om ) + 2 (om ) 1.

Notice example one binary decision variable per resource per agent
(yielding 6 variables simple problem). exponentially fewer
number binary variables straightforward CA formulation Example 6,
requires one binary variable per resource bundle per agent (yielding 16 variables
problem). Given MILPs NP-complete number integer variables,
reduction 16 6 variables noticeable even small problem like one
lead drastic speedup larger domains.

mechanism described instantiation GVA, well-known
properties VCG mechanisms, auction strategy-proof (the agents incentive
lie auctioneer MDPs), attains socially optimal resource allocation,
agent decreases utility participating auction.
sum results section: agents submit MDP information auctioneer instead valuations resource bundles, essentially
removed computational burden agents time significantly simplified auctioneers winner-determination problem (the number integer variables
WDP reduced exponentially).
4.3 Distributing Winner-Determination Problem
Unlike straightforward combinatorial auction implementation discussed earlier Section 4.1, agents shared computational burden auctioneer,
mechanism Section 4.2, agents submit information auctioneer
idle waiting solution. suggests potential improvements
computational efficiency. Indeed, given complexity MILPs, would beneficial
525

fiDolgov & Durfee

exploit computational power agents offload computation
auctioneer back agents (we assume agents cost helping
would prefer outcome computed faster).9 Thus, would like distribute
computation winner-determination problem (19), common objective distributed algorithmic mechanism design (Feigenbaum & Shenker, 2002; Parkes & Shneidman,
2004).10
concreteness, base algorithm section branch bound
method solving MILPs (Wolsey, 1998), exactly techniques also work
MILP algorithms (e.g., cutting planes) perform search space LP
relaxations MILP. branch bound MILPs binary variables, LP relaxations created choosing binary variable setting either 0 1, relaxing
integrality constraints binary variables. solution LP relaxation happens integer-valued, provides lower bound value global solution.
non-integer solution provides upper bound current subproblem, (combined
lower bounds) used prune search space.
Thus, simple way auctioneer distribute branch bound algorithm
simply farm LP relaxations agents ask solve LPs. However,
easy see mechanism strategy-proof. Indeed, agent tasked
performing computation determining optimal resource allocation
associated payments could benefit lying outcome computation
auctioneer. common phenomenon distributed mechanism implementations:
whenever WDP calculations offloaded agent participating auction,
agent might able benefit sabotaging computation. several methods
ensuring strategy-proofness distributed implementation. approach best
suited problem based idea redundant computation (Parkes & Shneidman,
2004),11 multiple agents asked task disagreement
carefully punished discourage lying. rest section, demonstrate
easy implement case.
basic idea simple: let auctioneer distribute LP relaxations agents,
check solutions re-solve problems agents return incorrect solutions
(this would make truthful computation weakly-dominant strategy agents,
nonzero punishment used achieve strong dominance). strategy
auctioneer removes incentive agents lie yields exactly solution
centralized algorithm. However, order beneficial, complexity
checking solution must significantly lower complexity solving problem.
Fortunately, true LPs.
Suppose auctioneer solve following LP, written two
equivalent ways (let us refer one left primal, one right
9. observed Parkes Shneidman (2004), assumption bit controversial, since desire
efficient computation implies nonzero cost computation, agents cost helping
modeled. is, nonetheless, common assumption distributed mechanism implementations.
10. describe one simple way distributing mechanism, others also possible.
11. Redundant computation discussed Parkes Shneidman (2004) context ex post Nash
equilibria, whereas interested dominant strategies, high-level idea similar.

526

fiResource Allocation Among Agents MDP-Induced Preferences

dual):
min v

max rT x

subject to:

(20)

subject to:



Ax = ;

v r.

x 0.

strong duality property, primal LP solution v , dual also
solution x , v = rT x . Furthermore, given solution primal LP, easy
compute solution dual: complementary slackness, vT = rT B 1 x = B 1 ,
B square invertible matrix composed columns correspond basic
variables solution.
well-known properties used auctioneer quickly check optimality
solutions returned agents. Suppose agent returns v solution
primal LP. auctioneer calculate dual solution vT = rT B 1 check whether
rT x = v. Thus, expensive operation auctioneer perform
inversion B, done sub-cubic time. matter fact,
implementation perspective, would efficient ask agents return
primal dual solutions, since many popular algorithms compute process
solving LPs.
Thus, provided simple method allows us effectively distribute
winner-determination problem, maintaining strategy-proofness mechanism
negligible computation overhead auctioneer.
4.4 Preserving Information Privacy
mechanism discussed far drawback requires agents
reveal complete information MDPs auctioneer. problem also
exacerbated distributed WDP algorithm previous section, since
agent reveal MDP information auctioneer, information
also spread agents via LP relaxations global MILP. show
alleviate problem.
Let us note that, saying agents prefer reveal local information,
implicitly assuming external factor affects agents utilities
captured agents MDPs. sensible way measure value information
changes ones decision-making process outcomes. Since effect part
model (in fact, contradicts weak-coupling assumption), cannot domainindependent manner define constitutes useful information, bad
agent reveal much MDP. Modeling effects carefully analyzing
interesting research task, outside scope paper. Thus,
purposes section, content mechanism hides enough information
make impossible auctioneer agent uniquely determine transition
reward function agent (in fact, information revealed agent map
infinitely many MDPs agents).12 Many transformations possible;
present one illustrate concept.
12. stringent condition would require agents preferences resource bundles revealed
(Parkes, 2001), set lower bar here.

527

fiDolgov & Durfee

main idea approach modify previous mechanism agents
submit private information auctioneer encrypted form allows
auctioneer solve winner-determination problem, allow infer
agents original MDPs.
First, note that, instead passing MDP auctioneer, agent submit
equivalent LP (6). So, question becomes: agent transform LP
way auctioneer able solve it, able infer transition
reward functions originating MDP? words, problem reduces
following. Given LP L1 (created MDP = hS, A, p, r, via (6)), need
find transformation L1 L2 solution transformed LP L2 uniquely
map solution original LP L1 , L2 reveal transition reward
functions original MDP (p r). show simple change variables suffices.
Suppose agent m1 MDP-originated LP going ask agent m2 solve it.
order maintain linearity problem (to keep simple m2 solve), m1
limit linear transformations. Consider linear, invertible transformation
primal coordinates u = F v, linear, invertible transformation dual coordinates
= Dx. Then, LP (20) transformed (by applying F , switching
dual, applying D) equivalent LP new coordinates y:
max rT D1
subject to:
(F 1 )T AD1 = (F 1 )T ;

(21)

D1 0.
value optimal solution (21) value optimal solution
(20), given optimal solution (21), easy compute solution
original: x = D1 . Indeed, perspective dual, primal transformation F
equivalent linear transformation dual equality constraints Ax = , (given
F non-singular) effect solution objective function. Furthermore,
dual transformation equivalent change variables modifies solution
value objective function.
However, problem transformations gives away D1 . Indeed,
agent m2 able simply read (up set multiplicative constants) transformation constraints D1 0. Therefore, diagonal matrices positive
coefficients (which equivalent stretching coordinate system) trivially deduced m2 , since also map 0. Choosing negative multiplier xi
(inverting axis) pointless, flips non-negativity constraints yi 0,
immediately revealing sign m2 .
Let us demonstrate that, given MDP corresponding LP L1 ,
choose F impossible m2 determine coefficients L1
(or equivalently original transition reward functions p r). agent m2
receives L2 (as (21)), knows L2 created MDP, columns
constraint matrix original LP L1 must sum constant:
X
X
Aji = 1
p(|s, a) = 1 .
(22)
j



528

fiResource Allocation Among Agents MDP-Induced Preferences

a1:
p=1
r=3

a1:
p=1
r=1

s2

s1

a2:
p=1
r=4

a2:
p=0.99
r=9.8

a2:
p=0.5
r=0.02

a1:
p=0.5
r=0.02
a2:
p=0.01
r=0.98

a1:
p=0.5
r=0.02

a1:
p=1
r=1

s2

s1

a2:
p=1
r=2

a2:
p=0.5
r=0.02

(a)

a1:
p=1
r=3

a1:
p=1
r=1

s2

s1

a2:
p=1
r=4

a2:
p=0.99
r=9.8

(b)

Figure 3: Preserving privacy example. Two different MDPs lead LP
constraint matrix.

gives m2 system |S| nonlinear equations diagonal arbitrary F ,
total |S||A| + |S|2 free parameters. everything degenerate
cases (which easily handled appropriate choice F ), equations
hugely under-constrained infinitely many solutions. matter fact,
sacrificing |S| free parameters, m1 choose F way
columns constraints L2 also sum constant 0 (0, 1), would
effect transforming L1 L2 corresponds another valid MDP 2 . Therefore,
given L2 , infinitely many original MDPs transformations F
map LP L2 .
also consider connection resource capacity costs agents occupation measures global WDP (19). two things auctioneer
able do: i) determine value agents policy (to able maximize
social welfare), ii) determine resource requirements policies (to check
resource constraints). So, question is, transformation affect these?
noted earlier, transformation change objective function, first
requirement holds. hand, change occupation measure xm (s, a)
arbitrary multipliers. However, multiplicative factor xm (s, a) effect usage
non-consumable resources, matters whether corresponding xm (s, a) zero
(step function H nullifies scaling effect). Thus, second condition also holds.
Example 8 Consider two-state MDP depicted Figure 3a represents decisionmaking problem sales company, two states corresponding possible market
conditions, two actions two possible sales strategies. Market conditions state
s1 much favorable state s2 (the rewards actions higher).
transitions two states correspond probabilities market conditions changing
rewards reflect expected profitability two states. Obtaining numbers
realistic scenario would require performing costly time-consuming research,
company might want make information public.
Therefore, company participate resource-allocation mechanism described above, would want encrypt MDP submitting auctioneer.
529

a2:
p=0.5
r=0.02

fiDolgov & Durfee

MDP following reward function
r = (1, 19.622, 0.063, 0.084)T ,
following transition function:


1
0
p(a1 ) =
,
0.5 0.5


p(a2 ) =


0.986 0.014
.
0.5
0.5

(23)

(24)

Using = 0.8, corresponds following conservation flow constraint matrix:


0.2 0.212 0.4 0.4
A=
.
(25)
0 0.012 0.6
0.6
submitting LP auctioneer, agent applies following transformations:


2
0
,
(26)
= diag(1, 0.102, 47.619, 47.619), F =
0.084 0.126
yielding following new constraint matrix:


0.1
1
0
0
0
1
1
= (F ) AD =
.
0 0.9 0.1 0.1

(27)

However, constraint matrix A0 corresponds non-transformed conservation
flow constraint different MDP (shown Figure 3b) = 0.9, following
reward function:
r = (1, 2, 3, 4)T ,
(28)
following transition function:


1 0
p(a1 ) =
,
0 1


p(a2 ) =


0 1
.
0 1

(29)

Therefore, auctioneer receives constraint matrix A0 , way knowing whether agent MDP transition function (29) transformed
using (26) MDP transition function (24) transformed. Notice
dynamics two MDPs vary significantly: transition probabilities state
connectivity. second MDP reveal information originating MDP
corresponding market dynamics.

sum up, can, large extent, maintain information privacy mechanism
allowing agents apply linear transformations original LPs. information
revealed mechanism consists agents resource costs (a, o), capacity bounds

bm (c), sizes state action spaces (the latter hidden adding
dummy states actions MDP).
revealed information used infer agents preferences resource requirements. Further, numeric policies revealed, lack information transition
reward functions renders information worthless (as illustrated Example 8,
could multiple originating MDPs different properties).
530

fiResource Allocation Among Agents MDP-Induced Preferences

5. Experimental Results
section present empirical analysis computational complexity
resource-allocation mechanism described Section 4. report results computational complexity mechanism Section 4.2, agents submit
MDPs auctioneer, simultaneously solves resource-allocation policyoptimization problems. far additional speedup achieved distributing WDP,
described Section 4.3, report empirical results, since well-established
parallel programming literature parallel versions branch-and-bound MILP
solvers consistently achieve linear speedup (Eckstein, Phillips, & Hart, 2000). due
fact branch-and-bound algorithms require little inter-process communication.
experiments, implemented multiagent delivery problem, based
multiagent rover domain (Dolgov & Durfee, 2004). problem, agents operate
stochastic grid world delivery locations randomly placed throughout grid.
delivery task requires set resources, limited quantities resources.
random delivery locations grid, location set deliveries
accepts. resource size requirements (capacity cost), delivery agent
bounded space hold resources (limited capacity). agents participate
auction bid delivery resources. setting, value resource depends
resources agent acquires deliveries make. Given
bundle resources, agents policy optimization problem find optimal delivery
plan. exact parameters used experiments critical trends seen
results presented below, sake reproducibility domain described
detail Appendix C.13 resource costs experiments presented
binary.
Computational complexity constrained optimization problems vary greatly
constraints tightened relaxed. Therefore, first step analysis empirical
computational complexity mechanism, investigate running time depends
capacity constraints agent bounds total amounts
resources shared agents. common types constrained optimization
constraint-satisfaction problems, natural expect WDP MILP
easy solve problem over- under-constrained either capacity
resource bounds. empirically verify this, varied local capacity constraint levels 0
(meaning agents cannot use resources) 1 (meaning agent capacity
use enough resources execute optimal unconstrained policy), well global
constraint levels 0 meant resources available agents, 1
meant enough resources assign agent desired resource
bundle. experiments, part MILP solver played CPLEX 8.1
Pentium-4 machine 2GB RAM (RAM bottleneck due use
sparse matrix representations). typical running-time profile shown Figure 4.
problem easy over-constrained, becomes difficult constraints
relaxed abruptly becomes easy capacity resource levels start
approach utopia.
13. also investigated other, randomly generated domains, results qualitatively same.

531

fiDolgov & Durfee

1
0.9
0.8
Local Constraint Level

6

t, sec

4

2

0
1

1

0.5
Local Constraints

0.5
0

0

0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0

Global Constraints

0.2

0.4
0.6
Global Constraint Level

0.8

1

Figure 4: Running time MDP-based winner-determination MILP (19) different levels global (b
) local (b
) constraints. constraint levels fractions
utopian levels needed implement optimal unconstrained policies.
Problems involved 10 agents, operating 5-by-5 grid, 10 shared
resource types. data point shown average ten runs randomlygenerated problems.

following experiments aim avoid easy regions constraint levels.
Therefore, given complexity profiles, set constraint levels 0.5 local
capacity global resource bounds. also set discount factor = 0.95.
value chosen arbitrarily, investigations effect value
running time MILP revealed significant trends.
begin comparing performance MDP-based auction (Section 4.2)
performance straightforward CA flat preferences (as described Section 4.1).
results summarized Figure 5, compares time takes solve
standard winner-determination problem space resource bundles (16)
time needed solve combined MDP-WDP problem (19) used mechanism,
number resources increased (with 5 agents, 5-by-5 grid). Despite fact
algorithms exponential worst-case running time, number integer
variables (16) exponentially larger MILP (19), effect clearly
demonstrated Figure 5. Furthermore, comparison gives extremely optimistic
view performance standard CA, take account additional
complexity valuation problem, requires formulating solving large
number MDPs (one per resource bundle). hand, latter embedded
WDP mechanism (19), thus including time solving valuation problem
comparison would magnify effect. fact, experiments, time
required solve MDPs valuation problem significantly greater
time solving resulting WDP MILP. However, present quantitative results
effect here, difference implementation (iterating resource
bundles solving MDPs done via straightforward implementation Matlab,
532

fiResource Allocation Among Agents MDP-Induced Preferences

Figure 5: Gains computation efficiency: MDP-based WDP versus WDP straightforward CA implementation. latter include time solving
MDPs compute resource-bundle values. Error bars show standard
deviation ten runs.
n=5, |O| = 10
4

10

3

10

2

t, sec

10

1

10

0

10

1

10

5

10
15
Number Agents |M|

20

25

Figure 6: Scaling MDP-based winner-determination MILP (19) agents. Agents
operated 5-by-5 grids shared 10 types resources.

MILPs solved using highly-optimized CPLEX code). parallelization WDP
performed experiments either algorithm.
analyze performance algorithm larger problems infeasible
straightforward CA. Figure 6 illustrates scaling effect number agents
participating auction increased. below, point plot corresponds
single run experiment (with less ten runs performed every value
parameters), solid line mean. Recall size WDP scales linearly
533

fiDolgov & Durfee

n = 10, |M| = 5

n = 5, |M| = 10

2

10

2

10

1

1

10
t, sec

t, sec

10

0

10

0

10

1

10

1

10

0

20

40
60
80
Number Resource Types |O|

2

10

100

(a)

0

20

40
60
80
Number Resource Types |O|

100

(b)

n = 7, |M| = 10
3

10

2

t, sec

10

1

10

0

10

1

10

2

10

0

20

40
60
80
Number Resource Types |O|

100

(c)

(d)

Figure 7: (a)(c): scaling MDP-based winner-determination MILP (19)
number resources three sets problems different grid sizes (n)
different numbers agents (|M|); (d): linear-scale plot tail data
(c).

number agents. graph therefore reflects rather standard scaling effect
NP-complete problem. seen plot, problems 25 agents
10 resource types well within reach method, average taking around
30 minutes.
Next, analyze method scales number resource types. Figure 7
shows solution time function number resource types three different
sets problems. problems, number actions scaled linearly number
resource types, action required constant number resources, i.e., number
534

fiResource Allocation Among Agents MDP-Induced Preferences

n = 5, |M| = 3

80
70
60

t, sec

50
40
30
20
10
0
0

5

10
15
Resources Per Action

20

Figure 8: Complexity MDP-based winner-determination MILP (19) function
number actions resource requirements.

nonzero (a, o) per action constant (two) regardless total number resource
types. problems exhibit interesting trait wherein running time peaks
relatively low numbers resource types, falls quickly, increases much
slowly number resource types increases (as illustrated Figure 7d, uses
linear scale). due fact total number resource types
much higher number resources required action, less contention
particular resource among agents one agents actions. Therefore,
problems become relatively under-constrained solution time increases slowly.
better illustrate effect, ran set experiments inverse ones shown
Figure 7: kept total number resource types constant increased number
resource types required action. results shown Figure 8. running-time
profile similar observed earlier varied local global constraints:
total number resources per action low high, problem under- overconstrained relatively easy solve, complexity increases significantly
number resources required resource range 50-80% total
number resource types.
Based above, would expect actions resource requirements increased
total number resource types, problem would scale gracefully
Figure 7. example, Figure 9 illustrates running time problems number
resources required action scales linearly total number resources. There,
complexity increase significantly faster. However, unreasonable assume
many domains number actions not, fact, increase total
number resource types involved. Indeed, natural assume total number
resource types increases problem becomes complicated number
tasks agent perform increases. However, resource requirements
action increase well? delivery agent running example acquires ability
535

fiDolgov & Durfee

n= 5, |M| = 5
4

10

3

10

2

t, sec

10

1

10

0

10

1

10

2

10

0

10

20
30
40
Number Resource Types |O|

50

Figure 9: Complexity actions resource requirements grow proportionally total
number resource types. number resource types needed action
10% total number resource types |O|.

deliver pizza, might need new resources perform actions related new activity,
one would expect resource requirements delivering furniture appliances
change. Therefore, believe many real applications, method scale
gracefully total number resource types.
experiments illustrate point domains agents preferences defined underlying Markov decision processes, resource-allocation
mechanism developed paper lead significant computational advantages.
shown Figure 7, method successfully applied large problems that,
argue, well beyond reach combinatorial resource-allocation mechanisms flat
preferences. experiments show (Figure 5), even small problems, combinatorial
resource allocation mechanisms flat preferences time-consuming, attempts empirically evaluate simpler mechanisms larger problems proved futile.
instance, method takes one minute solve problem that, standard
CA, requires agents enumerate 2100 bundles auctioneer solve
NP-complete problem input size.

6. Generalizations, Extensions, Conclusions
many possible extensions generalizations work presented here,
briefly outline several below.
treatment paper focused problem resource allocation among
self-interested agents, algorithms also apply cooperative MDPs weaklyinteracting agents. cooperative setting, concept resources viewed
compact way model inter-agent constraints inability include combinations joint actions policies. weakly-coupled MDPs, agents
536

fiResource Allocation Among Agents MDP-Induced Preferences

independent transition reward functions, certain combinations joint actions
feasible widely used model agents interactions (e.g., Singh & Cohn, 1998).
model resource-centric, direct models also certainly possible. example, agents use SAT formulas describe valid combinations joint actions. case
easily handled via simple modifications single multiagent MILPs (15)
(19). Indeed, SAT formula expressed set linear inequalities
binary variables (a) (or (a) multiagent case), directly added
corresponding MILP (see case non-binary resources Appendix B MILP
defined indicators (a), instead (o) used binary case).
mentioned previously, work extended handle consumable resources
used whenever agents execute actions. fact, conditions, problem
considerably simplified domains kinds resources.
important change redefine value particular resource bundle
agent. difficulty that, given policy, total use consumable resources
uncertain, definition value resource bundle becomes ambiguous. One
possibility define value bundle payoff best policy whose expected
resource usage exceed amounts resources bundle. interpretation
(a, o) would also change mean amount resource consumed action
every time executed. would make constraints (19) linear occupation
measure, would tremendously simplify WDP (making polynomial).
analogous models used constrained MDPs (Altman & Shwartz, 1991), briefly
described earlier Section 2. Information privacy handled similarly case
non-consumable resources. However, given transformation = Dx, resource cost
function also scaled D1 (since total consumption consumable
resources proportional occupation measure). additional benefit
hiding resource cost functions (unlike case non-consumable resources
revealed). detailed treatment model consumable resources
presented work Dolgov (2006), including discussion risk-sensitive cases,
value resource bundle defined payoff best policy whose probability
exceeding resource amounts bounded.
work exploited structure agents preferences stems underlying
policy-optimization problems. However, latter modeled using flat MDPs
enumerate possible states actions. flat MDPs scale well due
curse dimensionality (Bellman, 1961). address this, WDP MILP modified
work factored MDPs (Boutilier, Dearden, & Goldszmidt, 1995) using factored
resource-allocation algorithm (Dolgov & Durfee, 2006), based dual ALP
method solving factored MDPs developed Guestrin (2003). method allows us
exploit types structure resource-allocation algorithms: structure agents
preferences induced underlying MDPs, well structure MDPs themselves.
resource-allocation mechanism discussed paper assumed one-shot allocation
resources static population agents. interesting extension work would
consider system agents resources arrive depart dynamically,
online mechanism design work (Parkes & Singh, 2003; Parkes, Singh, & Yanovsky, 2004).
Combining MDP-based model utility functions dynamics online problems
could valuable result thus appears worthwhile direction future work.
537

fiDolgov & Durfee

agent population static, periodic re-allocation resources allowed, techniques
like phasing used solve resulting problem (Wu & Durfee, 2005).
summarize results paper, presented variant combinatorial auction resource allocation among self-interested agents whose valuations resource bundles
defined weakly-coupled constrained MDPs. problems, mechanism,
exploits knowledge structure agents MDP-based preferences, achieves
exponential reduction number integer decision variables, turn leads
tremendous speedup straightforward implementation, confirmed experimental results. mechanism implemented achieve reduction computational
complexity without sacrificing nice properties VCG mechanism (optimal outcomes, strategy-proofness, voluntary participation). also discussed distributed
implementation mechanism retains strategy-proofness (using fact
LP solution easily verified), reveal agents private MDP information
(using transformation agents MDPs).
believe models solution algorithms described paper significantly
applicability combinatorial resource-allocation mechanisms practical problems, utility functions resource bundles defined sequential stochastic
decision-making problems.

7. Acknowledgments
thank anonymous reviewers helpful comments, well colleagues
Satinder Singh, Kang Shin, Michael Wellman, Demothenis Teneketsis, Jianhui Wu,
Jeffrey Cox valuable discussions related work.
material based part upon work supported Honeywell International,
DARPA IPTO COORDINATORs program Air Force Research Laboratory
Contract No. FA875005C0030. views conclusions contained document authors, interpreted representing official
policies, either expressed implied, Defense Advanced Research Projects Agency
U.S. Government.

Appendix A. Proofs
A.1 Proof Theorem 1
Theorem 1 Consider finite set n indivisible resources = {oi } (i [1, n]),
N available units resource. Then, non-decreasing utility function
defined resource bundles f : [0, m]n 7 R, exists resource-constrained MDP
hS, A, p, r, O, , C, ,
b, (with resource set O) whose induced utility function
resource bundles f . words, every resource bundle z [0, m]n ,
value optimal policy among whose resource requirements exceed z
(call set (z)) f (z):
f q : [0, m]n 7 R, hS, A, p, r, O, , C, ,
b, :
h


n fi
X

fi
z [0, m]n , (z) = fi max (a, oi )H
(s, a) zi = max U (, ) = f (z).




538

(z)

fiResource Allocation Among Agents MDP-Induced Preferences

s000
a11
s100
0
a21

a11

a21

a0
r=f(0,0,0)

a31

s010
0
a31

s110 a0
a31

a11

s001
a31

s101 a0
a21

a21

a0
r=f(0,0,1)
a0
r=f(0,1,1)

s0

a0
r=0

s011

a11

a0
r=f(1,1,1)

s111

Figure 10: Creating MDP resources arbitrary non-decreasing utility function.
case shown three binary resources. transitions deterministic.

Proof: statement shown via straightforward construction MDP
exponential number (one per resource bundle) states actions. present
reduction linear number actions exponential number states. choice
due fact that, although reverse mapping requiring two states exponentially
many actions even straightforward, MDP feels somewhat unnatural.
Given arbitrary non-decreasing utility function f , corresponding MDP
constructed follows (illustrated Figure 10 n = 3 = 1). state space
MDP consists (m+1)n +1 states one state (sz ) every resource bundle z [0, m]n ,
plus sink state (s0 ).

action space MDP = a0 {aij }, [1, n], j [1, m] consists mn + 1
actions: actions per resource oi , [1, n], plus additional action a0 .
transition function p deterministic defined follows. Action a0 applicable every state leads sink state s0 . Every action aij applicable
states sz , zi = (j 1) leads certainty states zi = j:

0

1 = aij , = sz , = sz0 , zi = (j 1), zi = j,
p(|s, a) = 1 = a0 , = s0 ,


0 otherwise.
words, aij applies states j 1 units resource leads
state amount ith resource increases j.
reward function r defined follows. rewards state s0 ,
action a0 action produces rewards states:
(
f 0 (z) = ao , = sz , z [0, m]n
r(s, a) =
0
otherwise,
f 0 simple transformation f compensates effects discounting:
f 0 (z) = f (z)()
539

P

zi

.

fiDolgov & Durfee

P
words, takes zi transitions get state sz , contribution
total discounted reward exactly f (z).
resource requirements actions follows: action a0 require
resources, every action aij requires j units resource oi .
Finally, initial conditions (sz=0 ) = 1, meaning agent always starts
state corresponds empty resource bundle (state s000 Figure 10).
capacity costs limits
b used, set C = .
easy see MDP constructed above, given resource bundle z,
policy feasible set (z) zero probability reaching state sz0
z0 > z (for component i). Furthermore, optimal policy set (z)
transition state sz (since f (z) non-decreasing) use action a0 , thus obtaining
total discounted reward f (z).

A.2 Proof Theorem 2
Theorem 2 Given MDP = hS, A, p, r, O, , C, ,
b, resource capacity
constraints, exists policy HR feasible solution , exists
stationary deterministic policy SD SD also feasible, expected total reward
SD less :
HR , SD SD : U ( SD , ) U (, )
Proof: Let us label A0 set actions non-zero probability
executed according , i.e.,
A0 = {a|s : (s, a) > 0}
Let us also construct unconstrained MDP: 0 = hS, A0 , p0 , r0 i, p0 r0
restricted versions p r action domain limited A0 :
p0 : A0 7 [0, 1]
r0 : A0 7 R
p0 (|s, a) = p(|s, a), r0 (s, a) = r(s, a) S, S, A0
Due well-known property unconstrained infinite-horizon MDPs total
expected discounted reward optimization criterion, 0 guaranteed optimal
stationary deterministic solution (e.g., Theorem 6.2.10, Puterman, 1994), label
SD .
Consider SD potential solution . Clearly, SD feasible solution,
actions come set A0 includes actions uses non-zero probability,
means resource requirements (as (9)) SD greater
. Indeed:
n
n
X
X


max0 (a, o)H
(s, a) ,
(30)
SD (s, a) max0 (a, o) = max (a, o)H
aA



aA

aA



first inequality due fact H(z) 1 z, second equality
follows definition A0 .
540

fiResource Allocation Among Agents MDP-Induced Preferences

s1

a1:
r=v(u1),
a1,o1)=1
o1)=c(z1)

a2:
v(u2),

,o
)=1
2 2
o2)=c(z2)

:

r=

s2

a0:
r=0,
,.)=0


r=


...

s3

a0:
r=0,
,.)=0


sm


1-mv(u ),


am,om)=1
om)=c(zm)
a0:
r=0,
,.)=0


sm+1

a0:
r= ,
=0


Figure 11: Reduction KNAPSACK M-OPER-CMDP. transitions deterministic.

Furthermore, observe SD yields total reward 0 . Additionally, since SD uniformly optimal solution 0 , is, particular, optimal
initial conditions constrained MDP . Therefore, SD constitutes feasible
solution whose expected reward greater equal expected reward
feasible policy .

A.3 Proof Theorem 3
Theorem 3 following decision problem NP-complete. Given instance MDP
hS, A, p, r, O, , C, ,
b, resources capacity constraints, rational number ,
exist feasible policy , whose expected total reward, given , less ?
Proof: shown Theorem 2, always exists optimal policy (9)
stationary deterministic. Therefore, presence NP obvious, since can,
polynomial time, guess stationary deterministic policy, verify satisfies resource
constraints, calculate expected total reward (the latter done solving
standard system linear Markov equations (2) values states).
show NP-completeness problem, use reduction KNAPSACK (Garey
& Johnson, 1979). Recall KNAPSACK NP-complete problem, asks
whether, given set items z Z, cost c(z) value v(z),
exists subset Z 0 Z total value items Z 0 less

c, i.e.,
P constant vb,
Pthe total cost items greater another constant b
c(z)

b
c

v(z)

v
b
.

reduction

illustrated

Figure
11

proceeds
0
0
zZ
zZ
follows.
Given instance KNAPSACK |Z| = m, let us number items zi ,
[1, m] notational convenience. instance KNAPSACK, create
MDP + 1 states {s1 , s2 , . . . sm+1 }, + 1 actions {a0 , . . . }, types resources
= {o1 , . . . om }, single capacity C = {c1 }.
transition function states defined follows. Every state si , [1, m]
two transitions it, corresponding actions ai a0 . actions lead state
si+1 probability 1. State sm+1 absorbing transitions lead back
itself.
reward cost functions defined follows. want action ai , [1, m]
(which corresponds item zi KNAPSACK) contribute v(zi ) total discounted
541

fiDolgov & Durfee

reward. Hence, set immediate reward every action ai v(zi )()1i , which, given
transition function implies state si reached exactly step 1, ensures
action ai ever executed, contribution total discounted reward
v(zi )()1i ()i1 = v(zi ). Action a0 produces reward zero states.
resource requirements actions defined follows. Action ai , [1, m]
needs resource oi , i.e., (ai , oj ) = 1 = j. set cost resource oi
cost c(zi ) item KNAPSACK problem. null action a0 requires resources.
order complete construction, set initial distribution = [1, 0, . . .]
agent starts state s1 probability 1. also define decision parameter = vb
upper bound single capacity
b=b
c.
Essentially, construction allows agent choose action ai a0 every state si .
Choosing action ai equivalent putting item zi knapsack, action a0
corresponds choice including zi knapsack. Therefore, exists
policy expected payoff less = vb uses
b = b
c
shared resource exists solution original instance
KNAPSACK.


Appendix B. Non-binary Resource Requirements
describe MILP formulation capacity-constrained single-agent optimization problem (9) arbitrary resource costs : 7 R, opposed binary costs
assumed main parts paper. corresponding multiagent winnerdetermination problem (the non-binary equivalent (19)) follows immediately
single-agent MILP.
arbitrary resource costs, obtain following non-binary equivalent optimization problem (12) occupation measure coordinates:
max
x

XX


x(s, a)r(s, a)



subject to:
X
XX
x(, a)
x(s, a)p(|s, a) = (),


X



S;



n
X

(o, c) max (a, o)H
x(s, a)
b(c),




c C;



x(s, a) 0,

S, A.

linearize sum max operators (31), let us observe inequality
n
X


g(ui ) max f (z, ui ) = g(u1 ) max f (z, u1 ) + . . . + g(un ) max f (z, un )
zZ

zZ

zZ

equivalent following system |Z|n linear inequalities:
g(u1 )f (z1 , u1 ) + g(u2 )f (z2 , u2 ) + . . . + g(un )f (zn , un ) a,
542

z1 , z2 , . . . zn Z.

(31)

fiResource Allocation Among Agents MDP-Induced Preferences

Applying constraints (31), express original system |C| nonlinear
constraints (each max):
X

n
X

(o, c) max (a, o)H
x(s, a)
b(c),




c C



following system |C||A||O| constraints max removed:
X

(o, c)(ao , o)H

X




x(s, a)
b(c),

c C, ao1 , ao2 , . . . A.

(32)



Notice way eliminating maximization exponentially increases number
constraints, expansion enumerates possible actions resource
(i.e., enumerates policies resource used action a1 , used
action a2 , action a3 , etc.) However, many problems resources used
actions. cases, constraints
Q become redundant, number
constraints reduced |C||A||O| |C| |Ao |, Ao number actions
use resource o.
linearize Heaviside function analogously case binary resource costs
Section 3.2: create binary indicator variable corresponds argument
H() tie occupation measure x via linear inequalities. difference
non-binary resource costs, instead using
P indicators resources, use indicators
actions: (a) {0, 1}, (a) = H( x(s, a)) indicator shows whether
action used policy. Using expanding max above, represent
optimization problem (9) following MILP:
max
x,

XX


x(s, a)r(s, a)



subject to:
X
XX
x(, a)
x(s, a)p(|s, a) = (),


X



S;



(o, c)(ao , o)(ao )
b(c),

c C, ao1 , ao2 , . . . A;

(33)



X

x(s, a)/X (a),

A;



x(s, a) 0,

S, A;

(a) {0, 1},

A,

P
X max x(s, a) constant finite upper bound expected number
times action used,
P exists discounted MDP. can, example, let
X = (1 )1 , since s,a x(s, a) = (1 )1 x valid occupation measure
MDP discount factor .
Example 9 Let us formulate MILP constrained problem Example 3. Recall
three resources = {ot , , om } (truck, forklift, mechanic), one capacity
543

fiDolgov & Durfee

type C = {c1 } (money), actions following resource requirements (listing
nonzero ones):
(a1 , ot ) = 1, (a2 , ot ) = 1, (a2 , ) = 1, (a3 , ot ) = 1, (a4 , ot ) = 1, (a4 , om ) = 1
resources following capacity costs:
(ot , c1 ) = 2, (of , c1 ) = 3, (om , c1 ) = 4,
agent limited budget, i.e., capacity bound
b(c1 ) = 8.
compute optimal policy arbitrary , formulate problem
MILP using techniques described above. Using binary variables {(ai )} = {i } =
{1 , 2 , 3 , 4 },14 express constraint capacity cost following system
|C||A||O| = 1(4)3 = 64 linear constraints:
(2)(1)1 + (3)(0)1 + (4)(0)1 8,
(2)(1)1 + (3)(0)1 + (4)(0)2 8,
(2)(1)1 + (3)(0)1 + (4)(0)3 8,
(2)(1)1 + (3)(0)1 + (4)(1)4 8,
(2)(1)1 + (3)(1)2 + (4)(0)1 8,
...
(2)(0)4 + (3)(0)4 + (4)(1)4 8.
easy see constraints redundant, fact action
requires small subset resources allows us prune many constraints.
fact, resource used byQmultiple actions ot . Therefore, accordance
earlier discussion, need |Ao | = 1 4 1 = 4 constraints:
(2)(1)1 + (3)(1)2 + (4)(1)4 8,
(2)(1)2 + (3)(1)2 + (4)(1)4 8,
(2)(1)3 + (3)(1)2 + (4)(1)4 8,
(2)(1)4 + (3)(1)2 + (4)(1)4 8,
four constraints corresponds case first resource (ot ) used
different action.
mentioned earlier, set X = (1 )1 constraints synchronize
occupation measure x binary indicators . Combining constraints
Q
(33), get MILP 12 continuous 4 binary variables, |S|+|C| |Ao |+
|A| = 3 + 4 + 3 = 10 constraints (not counting last two sets range constraints).

Finally, let us observe expanding resource action sets, problem
represented using binary resources only. domain contains mostly binary
requirements, may effective expand non-binary resource requirements
augmenting resource set O, use binary formulation Section 3.2 rather
directly applying more-general formulation described above.
14. create 0 noop action a0 , resource costs zero, drops
expressions.

544

fiResource Allocation Among Agents MDP-Induced Preferences

Appendix C. Experimental Setup
appendix details experimental domains constructed. delivery
domain |M| agents operating n-by-n grid sharing |O| resource types,
used following parameters.
resources enable agents carry delivery tasks. problem |O| resource
types, |O| delivery actions, performing action [1, |O|] requires random
subset resources (where number resources required action
important parameter, whose effect complexity discussed Section 5). probability
task [1, |O|] carried location 0.1+0.4(|O|i)/(|O|1), i.e., uniformly
distributed 0.1 0.5, function action ID (actions lower IDs
rewarding, per definition reward function below, executed
fewer locations).
n2 /5 possible delivery locations randomly placed grid. delivery
location assigned set delivery tasks executed (a single location
used multiple delivery tasks, single task carried several
locations). assignment tasks locations done randomly.
agent 4 + |O| actions: drive four perpendicular directions
execute one delivery tasks. drive actions result movement intended
direction probability 0.8 probability 0.2 produce change location.
movement actions incur negative reward, amount depends size
agent. problem |M| agents, movement penalty incurred agent
[1, |M|] 1 9(m 1)/(|M| 1), i.e., distributed uniformly [1, 10] function
agents ID.
Execution action corresponding delivery task [1, |O|] location
task assigned produces reward 100i/|O| moves agent new random
location grid. new location chosen randomly problem generation (thus
known agent), transition deterministic, induces topology nearby
remote locations. Attempting execution delivery task incorrect location
change state produces zero reward.
agents bid delivery resources |O| types. cglob |M| units
resource, cglob global constraint level (set 0.5 experiments,
described detail Section 5). one capacity type: size. size
requirements making deliveries type [1, |O|] i. capacity limit agent
cloc /2|O|(|O| + 1), cloc local constraint level (set 0.5
experiments, described detail Section 5).
initial location agent randomly selected uniform distribution.
discount factor = 0.95.

References
Altman, E. (1996). Constrained Markov decision processes total cost criteria: Occupation measures primal LP. Methods Models Operations Research, 43 (1),
4572.
545

fiDolgov & Durfee

Altman, E., & Shwartz, A. (1991). Adaptive control constrained Markov chains: Criteria policies. Annals Operations Research, special issue Markov Decision
Processes, 28, 101134.
Altman, E. (1999). Constrained Markov Decision Processes. Chapman HALL/CRC.
Bellman, R. (1961). Adaptive Control Processes: Guided Tour. Princeton University
Press.
Benazera, M. E., Brafman, R. I., Meuleau, N., & Hansen, E. (2005). Planning continuous resources stochastic domains. Proceedings Nineteenth International
Joint Conference Artificial Intelligence (IJCAI-05), pp. 12441251.
Bererton, C., Gordon, G., & Thrun, S. (2003). Auction mechanism design multi-robot
coordination. Thrun, S., Saul, L., & Scholkopf, B. (Eds.), Proceedings Conference
Neural Information Processing Systems (NIPS). MIT Press.
Bertsimas, D., & Tsitsiklis, J. N. (1997). Introduction Linear Optimization. Athena
Scientific.
Boutilier, C. (2002). Solving concisely expressed combinatorial auction problems. Proceedings Eighteenth National Conference Artificial Intelligence (AAAI-02),
pp. 359366.
Boutilier, C., Dearden, R., & Goldszmidt, M. (1995). Exploiting structure policy construction. Proceedings Fourteenth International Joint Conference Artificial
Intelligence (IJCAI-95), pp. 11041111.
Boutilier, C., & Hoos, H. H. (2001). Bidding languages combinatorial auctions. Proceedings Seventeenth International Joint Conference Artificial Intelligence
(IJCAI-01), pp. 12111217.
Clarke, E. H. (1971). Multipart pricing public goods. Public Choice, 18, 1933.
de Vries, S., & Vohra, R. V. (2003). Combinatorial auctions: survey. INFORMS Journal
Computing, 15 (3), 284309.
Dolgov, D. (2006). Integrated Resource Allocation Planning Stochastic Multiagent
Environments. Ph.D. thesis, Computer Science Department, University Michigan.
Dolgov, D. A., & Durfee, E. H. (2004). Optimal resource allocation policy formulation loosely-coupled Markov decision processes. Proceedings Fourteenth
International Conference Automated Planning Scheduling (ICAPS-04), pp.
315324.
Dolgov, D. A., & Durfee, E. H. (2006). Resource allocation among agents preferences
induced factored MDPs. Proceedings Fifth International Joint Conference
Autonomous Agents Multiagent Systems (AAMAS-06), Hakodate, Japan.
Eckstein, J., Phillips, C., & Hart, W. (2000). Pico: object-oriented framework parallel
branch bound. Proceedings Workshop Inherently Parallel Algorithms
Optimization Feasibility Applications.
Feigenbaum, J., & Shenker, S. (2002). Distributed algorithmic mechanism design: Recent
results future directions. Proceedings Sixths International Workshop
546

fiResource Allocation Among Agents MDP-Induced Preferences

Discrete Algorithms Methods Mobile Computing Communications, pp.
113. ACM Press, New York.
Feldmann, R., Gairing, M., Lucking, T., Monien, B., & Rode, M. (2003). Selfish routing
non-cooperative networks: survey. Proceedings Twenty-Eights International
Symposium Mathematical Foundations Computer Science (MFCS-03), pp. 21
45. Springer-Verlag.
Ferguson, D., Nikolaou, C., Sairamesh, J., & Yemini, Y. (1996). Economic models allocating resources computer systems. Clearwater, S. (Ed.), Market-Based Control:
Paradigm Distributed Resource Allocation, pp. 156183, Hong Kong. World
Scientific.
Garey, M. R., & Johnson, D. S. (1979). Computers Intractability: Guide Theory
NP-Completeness. W. H. Freeman & Co.
Groves, T. (1973). Incentives teams. Econometrica, 41 (4), 617631.
Guestrin, C. (2003). Planning Uncertainty Complex Structured Environments.
Ph.D. thesis, Computer Science Department, Stanford University.
Heyman, D. P., & Sobel, M. J. (1984). Volume II: Stochastic Models Operations Research.
McGraw-Hill, New York.
Kallenberg, L. (1983). Linear Programming Finite Markovian Control Problems. Math.
Centrum, Amsterdam.
Littman, M. L., Dean, T. L., & Kaelbling, L. P. (1995). complexity solving Markov
decision problems. Proceedings Eleventh Annual Conference Uncertainty
Artificial Intelligence (UAI95), pp. 394402, Montreal.
MacKie-Mason, J. K., & Varian, H. (1994). Generalized Vickrey auctions. Tech. rep.,
University Michigan.
Mas-Colell, A., Whinston, M. D., & Green, J. R. (1995). Microeconomic Theory. Oxford
University Press, New York.
McAfee, R. P., & McMillan, J. (1996). Analyzing airwaves auction. Journal Economic
Perspectives, 10 (1), 15975.
McMillan, J. (1994). Selling spectrum rights. Journal Economic Perspectives, 8 (3),
14562.
Meuleau, N., Hauskrecht, M., Kim, K.-E., Peshkin, L., Kaelbling, L., Dean, T., & Boutilier,
C. (1998). Solving large weakly coupled Markov decision processes. Proceedings
Fifteenth National Conference Artificial Intelligence (AAAI-98), pp. 165
172.
Nisan, N. (2000). Bidding allocation combinatorial auctions. Electronic Commerce.
Parkes, D. (2001). Iterative Combinatorial Auctions: Achieving Economic Computational Efficiency. Ph.D. thesis, Department Computer Information Science,
University Pennsylvania.
Parkes, D. C., Kalagnanam, J. R., & Eso, M. (2001). Achieving budget-balance
Vickrey-based payment schemes exchanges. Proc. 17th International Joint Conference Artificial Intelligence (IJCAI-01), pp. 11611168.
547

fiDolgov & Durfee

Parkes, D. C., & Shneidman, J. (2004). Distributed implementations Vickrey-ClarkeGroves mechanisms. Proceedings Third International Joint Conference
Autonomous Agents Multi Agent Systems (AAMAS-04), pp. 261268.
Parkes, D. C., & Singh, S. (2003). MDP-based approach Online Mechanism Design.
Proceedings Seventeenths Annual Conference Neural Information Processing
Systems (NIPS-03).
Parkes, D. C., Singh, S., & Yanovsky, D. (2004). Approximately efficient online mechanism
design. Proceedings Eighteenths Annual Conference Neural Information
Processing Systems (NIPS-04).
Puterman, M. L. (1994). Markov Decision Processes. John Wiley & Sons, New York.
Ross, K., & Chen, B. (1988). Optimal scheduling interactive non-interactive traffic
telecommunication systems. IEEE Transactions Automatic Control, 33, 261267.
Ross, K., & Varadarajan, R. (1989). Markov decision processes sample path constraints: communicating case. Operations Research, 37, 780790.
Rothkopf, M. H., Pekec, A., & Harstad, R. M. (1998). Computationally manageable combinational auctions. Management Science, 44 (8), 11311147.
Sandholm, T., & Boutilier, C. (2006). Preference elicitation combinatorial auctions.
Cramton, Shoham, & Steinberg (Eds.), Combinatorial Auctions, chap. 10. MIT Press.
Sandholm, T. (1999). algorithm optimal winner determination combinatorial
auctions. Proceedings Sixteenth International Joint Conference Artificial
Intelligence (IJCAI-99), pp. 542547, San Francisco, CA, USA. Morgan Kaufmann
Publishers Inc.
Sandholm, T. (2002). Algorithm optimal winner determination combinatorial auctions. Artificial Intelligence, 135 (1-2), 154.
Shapley, L. S. (1953). Stochastic games. Proceedings National Academy Science, USA,
39, 10951100.
Sheffi, Y. (2004). Combinatorial auctions procurement transportation services.
Interfaces, 34 (4), 245252.
Singh, S., & Cohn, D. (1998). dynamically merge Markov decision processes.
Jordan, M. I., Kearns, M. J., & Solla, S. A. (Eds.), Advances Neural Information
Processing Systems, Vol. 10, pp. 10571063. MIT Press.
Song, J., & Regan, A. (2002). Combinatorial auctions transportation service procurement: carrier perspective. Transportation Research Record, 1833, 4046.
Vickrey, W. (1961). Counterspeculation, auctions competitive sealed tenders. Journal
Finance, 16, 837.
Wellman, M. P., Walsh, W. E., Wurman, P. R., & MacKie-Mason, J. K. (2001). Auction
protocols decentralized scheduling. Games Economic Behavior, 35, 271303.
Wolsey, L. (1998). Integer Programming. John Wiley & Sons.
548

fiResource Allocation Among Agents MDP-Induced Preferences

Wu, J., & Durfee, E. H. (2005). Automated resource-driven mission phasing techniques
constrained agents. Proceedings Fourth International Joint Conference
Autonomous Agents Multiagent Systems (AAMAS-05), pp. 331338.

549

fiJournal Artificial Intelligence Research 27 (2006) 335-380

Submitted 05/06; published 11/06

Anytime Point-Based Approximations Large POMDPs
Joelle Pineau

JPINEAU @ CS . MCGILL . CA

School Computer Science
McGill University
Montreal QC, H3A 2A7 CANADA

Geoffrey Gordon

GGORDON @ CS . CMU . EDU

Machine Learning Department
Carnegie Mellon University
Pittsburgh PA, 15232 USA

Sebastian Thrun

THRUN @ STANFORD . EDU

Computer Science Department
Stanford University
Stanford CA, 94305 USA

Abstract
Partially Observable Markov Decision Process long recognized rich framework real-world planning control problems, especially robotics. However exact solutions framework typically computationally intractable smallest problems.
well-known technique speeding POMDP solving involves performing value backups
specific belief points, rather entire belief simplex. efficiency approach,
however, depends greatly selection points. paper presents set novel techniques
selecting informative belief points work well practice. point selection procedure
combined point-based value backups form effective anytime POMDP algorithm called
Point-Based Value Iteration (PBVI). first aim paper introduce algorithm
present theoretical analysis justifying choice belief selection technique. second aim
paper provide thorough empirical comparison PBVI state-of-the-art
POMDP methods, particular Perseus algorithm, effort highlight similarities
differences. Evaluation performed using standard POMDP domains realistic robotic
tasks.

1. Introduction
concept planning long tradition AI literature (Fikes & Nilsson, 1971; Chapman,
1987; McAllester & Roseblitt, 1991; Penberthy & Weld, 1992; Blum & Furst, 1997). Classical
planning generally concerned agents operate environments fully observable,
deterministic, finite, static, discrete. techniques able solve increasingly
large state-space problems, basic assumptions classical planningfull observability, static
environment, deterministic actionsmake unsuitable robotic applications.
Planning uncertainty aims improve robustness explicitly reasoning type
uncertainty arise. Partially Observable Markov Decision Process (POMDP) (Astrom,
1965; Sondik, 1971; Monahan, 1982; White, 1991; Lovejoy, 1991b; Kaelbling, Littman, & Cassandra, 1998; Boutilier, Dean, & Hanks, 1999) emerged possibly general representation
(single-agent) planning uncertainty. POMDP supersedes frameworks terms
c
2006
AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiP INEAU , G ORDON & HRUN

representational power simply combines essential features planning
uncertainty.
First, POMDPs handle uncertainty action effects state observability, whereas many
frameworks handle neither these, handle stochastic action effects. handle partial state observability, plans expressed information states, instead world states,
since latter ones directly observable. space information states space
beliefs system might regarding world state. Information states easily calculated
measurements noisy imperfect sensors. POMDPs, information states typically
represented probability distributions world states.
Second, many POMDP algorithms form plans optimizing value function. powerful approach plan optimization, since allows one numerically trade alternative
ways satisfy goal, compare actions different costs/rewards, well plan multiple
interacting goals. value function optimization used planning approachesfor example Markov Decision Processes (MDPs) (Bellman, 1957)POMDPs unique expressing
value function information states, rather world states.
Finally, whereas classical conditional planners produce sequence actions, POMDPs
produce full policy action selection, prescribes choice action possible
information state. producing universal plan, POMDPs alleviate need re-planning,
allow fast execution. Naturally, main drawback optimizing universal plan computational complexity so. precisely seek alleviate work described
paper
known algorithms exact planning POMDPs operate optimizing value function
possible information states (also known beliefs). algorithms run wellknown curse dimensionality, dimensionality planning problem directly related
number states (Kaelbling et al., 1998). also suffer lesser known curse
history, number belief-contingent plans increases exponentially planning
horizon. fact, exact POMDP planning known PSPACE-complete, whereas propositional
planning NP-complete (Littman, 1996). result, many POMDP domains
states, actions sensor observations computationally intractable.
commonly used technique speeding POMDP solving involves selecting finite set
belief points performing value backups set (Sondik, 1971; Cheng, 1988; Lovejoy,
1991a; Hauskrecht, 2000; Zhang & Zhang, 2001). usefulness belief point updates
well acknowledged, backups applied thoroughly
explored.
paper describes class Point-Based Value Iteration (PBVI) POMDP approximations
value function estimated based strictly point-based updates. context,
choice points integral part algorithm, approach interleaves value backups
steps belief point selection. One key contributions paper presentation
analysis set heuristics selecting informative belief points. range naive
version combines point-based value updates random belief point selection, sophisticated algorithm combines standard point-based value update estimate error
bound approximate exact solutions select belief points. Empirical theoretical evaluation techniques reveals importance taking distance points
consideration selecting belief points. result approach exhibits good perfor336

fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDP

mance belief points (sometimes less number states), thereby overcoming
curse history.
PBVI class algorithms number important properties, discussed
greater length paper:
Theoretical guarantees. present bound error value function obtained
point-based approximation, respect exact solution. bound applies number
point-based approaches, including PBVI, Perseus (Spaan & Vlassis, 2005),
others.
Scalability. able handle problems order 103 states, order magnitude larger problems solved traditional POMDP techniques.
empirical performance evaluated extensively realistic robot tasks, including search-formissing-person scenario.
Wide applicability. approach makes assumptions nature structure
domain. PBVI framework assume known discrete state/ action/observation spaces
known model (i.e., state-to-state transitions, observation probabilities, costs/rewards),
additional specific structure (e.g., constrained policy class, factored model).
Anytime performance. anytime solution achieved gradually alternating phases
belief point selection phases point-based value updates. allows effective
trade-off planning time solution quality.
PBVI many important properties, number recent POMDP approaches exhibit competitive performance (Braziunas & Boutilier, 2004; Poupart & Boutilier,
2004; Smith & Simmons, 2004; Spaan & Vlassis, 2005). provide overview techniques later part paper. also provide comparative evaluation algorithms
PBVI using standard POMDP domains, effort guide practitioners choice
algorithm. One algorithms, Perseus (Spaan & Vlassis, 2005), closely related PBVI
design performance. therefore provide direct comparison two approaches
using realistic robot task, effort shed light comparative strengths weaknesses two approaches.
paper organized follows. Section 2 begins exploring basic concepts POMDP
solving, including representation, inference, exact planning. Section 3 presents general
anytime PBVI algorithm theoretical properties. Section 4 discusses novel strategies select good belief points. Section 6 presents empirical comparison POMDP algorithms using
standard simulation problems. Section 7 pursues empirical evaluation tackling complex robot
domains directly comparing PBVI Perseus. Finally, Section 5 surveys number existing
POMDP approaches closely related PBVI.

2. Review POMDPs
Partially Observable Markov Decision Processes provide general planning decision-making
framework acting optimally partially observable domains. well-suited great
number real-world problems decision-making required despite prevalent uncertainty.
generally assume complete correct world model, stochastic state transitions, imperfect state tracking, reward structure. Given information, goal find action
337

fiP INEAU , G ORDON & HRUN

strategy maximizes expected reward gains. section first establishes basic terminology essential concepts pertaining POMDPs, reviews optimal techniques POMDP
planning.
2.1 Basic POMDP Terminology
Formally, POMDP defined six distinct quantities, denoted {S, A, Z, T, O, R}. first three
are:
States. state world denoted s, finite set states denoted =
{s0 , s1 , . . .}. state time denoted st , discrete time index. state
directly observable POMDPs, agent compute belief state
space S.
Observations. infer belief regarding worlds state s, agent take sensor measurements. set measurements, observations, denoted Z = {z0 , z1 , . . .}.
observation time denoted zt . Observation zt usually incomplete projection
world state st , contaminated sensor noise.
Actions. act world, agent given finite set actions, denoted =
{a0 , a1 , . . .}. Actions stochastically affect state world. Choosing right action
function history core problem POMDPs.
Throughout paper, assume states, actions observations discrete finite.
mathematical convenience, also assume actions observations alternated
time.
fully define POMDP, specify probabilistic laws describe state transitions
observations. laws given following distributions:
state transition probability distribution,
(s, a, s0 ) := P r(st = s0 | st1 = s, at1 = a) t,

(1)

probability transitioning state s0 , given agent state selects action a, (s, a, s0 ). Since conditional probability distribution,
P
0
s0 (s, a, ) = 1, (s, a). notation suggests, time-invariant.
observation probability distribution,
O(s, a, z) := P r(zt = z | st1 = s, at1 = a) t,

(2)

probability agent perceive observation z upon executing action state s.
P
conditional probability defined (s, a, z) triplets, zZ O(s, a, z) =
1, (s, a). probability function also time-invariant.
Finally, objective POMDP planning optimize action selection, agent given
reward function describing performance:
338

fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDP

reward function. R(s, a) : <, assigns numerical value quantifying
utility performing action state s. assume reward bounded, Rmin <
R < Rmax . goal agent collect much reward possible time.
precisely, wants maximize sum:
E[


X

tt0 rt ],

(3)

t=t0

rt reward time t, E[ ] mathematical expectation, 0 < 1
discount factor, ensures sum Equation 3 finite.
items together, states S, actions A, observations Z, reward R, probability
distributions, O, define probabilistic world model underlies POMDP.
2.2 Belief Computation
POMDPs instances Markov processes, implies current world state, st , sufficient predict future, independent past {s0 , s1 , ..., st1 }. key characteristic
sets POMDPs apart many probabilistic models (such MDPs) fact state
st directly observable. Instead, agent perceive observations {z1 , . . . , zt },
convey incomplete information worlds state.
Given state directly observable, agent instead maintain complete trace
observations actions ever executed, use select actions. action/observation trace known history. formally define
ht := {a0 , z1 , . . . , zt1 , at1 , zt }

(4)

history time t.
history trace get long time goes on. well-known fact history
need represented explicitly, instead summarized via belief distribution (Astrom, 1965), following posterior probability distribution:
bt (s) := P r(st = | zt , at1 , zt1 , . . . , a0 , b0 ).

(5)

course requires knowing initial state probability distribution:
b0 (s) := P r(s0 = s),

(6)

defines probability domain state time = 0. common either
specify initial belief part model, give runtime system tracks
beliefs selects actions. work, assume initial belief (or set possible
initial beliefs) available planner.
belief distribution bt sufficient statistic history, suffices condition
selection actions bt , instead ever-growing sequence past observations
actions. Furthermore, belief bt time calculated recursively, using belief one time
step earlier, bt1 , along recent action at1 observation zt .
339

fiP INEAU , G ORDON & HRUN

define belief update equation, (), as:
(bt1 , at1 , zt ) = bt (s0 )
X

=

O(s0 , at1 , zt ) (s, at1 , s0 ) bt1 (s)

s0

P r(zt |bt1 , at1 )

(7)

denominator normalizing constant.
equation equivalent decades-old Bayes filter (Jazwinski, 1970), commonly
applied context hidden Markov models (Rabiner, 1989), known forward
algorithm. continuous generalization forms basis Kalman filters (Kalman, 1960).
interesting consider nature belief distributions. Even finite state spaces,
belief continuous quantity. defined simplex describing space distributions
state space S. large state spaces, calculating belief update (Eqn 7) computationally challenging. Recent research led efficient techniques belief state computation
exploit structure domain (Dean & Kanazawa, 1988; Boyen & Koller, 1998; Poupart &
Boutilier, 2000; Thrun, Fox, Burgard, & Dellaert, 2000). However, far complex aspect POMDP planning generation policy action selection, described next.
example robotics, calculating beliefs state spaces 106 states easily done realtime (Burgard et al., 1999). contrast, calculating optimal action selection policies exactly appears
infeasible environments dozen states (Kaelbling et al., 1998),
directly size state space, complexity optimal policies.
Hence assume throughout paper belief computed accurately, instead
focus problem finding good approximations optimal policy.
2.3 Optimal Policy Computation
central objective POMDP perspective compute policy selecting actions.
policy form:
(b) a,

(8)

b belief distribution action chosen policy .
particular interest notion optimal policy, policy maximizes expected future discounted cumulative reward:


(bt0 ) = argmax E



X

t=t0

fi
fi
fi
tt0 rt fibt0 .
fi

(9)

two distinct interdependent reasons computing optimal policy challenging. widely-known reason so-called curse dimensionality: problem
n physical states, defined belief states (n 1)-dimensional continuous space.
less-well-known reason curse history: POMDP solving many ways like search
space possible POMDP histories. starts searching short histories (through
select best short policies), gradually considers increasingly long histories. Unfortunately number distinct possible action-observation histories grows exponentially
planning horizon.
340

fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDP

two cursesdimensionality historyoften act independently: planning complexity
grow exponentially horizon even problems states, problems
large number physical states may still small number relevant histories. curse
predominant depends problem hand, solution technique. example,
belief point methods focus paper specifically target curse history, leaving
vulnerable curse dimensionality. Exact algorithms hand typically
suffer far curse history. goal therefore find techniques offer best
balance both.
describe straightforward approach finding optimal policies Sondik (1971).
overall idea apply multiple iterations dynamic programming, compute increasingly
accurate values belief state b. Let V value function maps belief states values
<. Beginning initial value function:
V0 (b) = max


X

R(s, a)b(s),

(10)

sS

t-th value function constructed (t 1)-th following recursive equation:
"

Vt (b) = max


#
X

X

R(s, a)b(s) +

sS

P r(z | a, b)Vt1 ( (b, a, z)) ,

(11)

zZ

(b, a, z) belief updating function defined Equation 7. value function update
maximizes expected sum (possibly discounted) future pay-offs agent receives
next time steps, belief state b. Thus, produces policy optimal planning
horizon t. optimal policy also directly extracted previous-step value function:
#

"

(b)

= argmax


X

R(s, a)b(s) +

X

P r(z | a, b)Vt1 ( (b, a, z)) .

(12)

zZ

sS

Sondik (1971) showed value function finite horizon expressed set
vectors: = {0 , 1 , . . . , }. -vector represents |S|-dimensional hyper-plane,
defines value function bounded region belief:
X

Vt (b) = max


(s)b(s).

(13)

sS

addition, -vector associated action, defining best immediate policy
assuming optimal behavior following (t 1) steps (as defined respectively sets
{Vt1 , ..., V0 }).
t-horizon solution set, , computed follows. First, rewrite Equation 11 as:


Vt (b) = max
aA


X

sS

R(s, a)b(s) +

X
zZ

max

t1

XX
sS

(s, a, s0 )O(s0 , a, z)(s0 )b(s) . (14)

s0

Notice representation Vt (b), nonlinearity term P (z|a, b) Equation 11
cancels nonlinearity term (b, a, z), leaving linear function b(s) inside max
operator.
341

fiP INEAU , G ORDON & HRUN

value Vt (b) cannot computed directly belief b B (since infinitely
many beliefs), corresponding set generated sequence operations
set t1 .
a,z
first operation generate intermediate sets a,
, A, z Z (Step 1):
a, (s) = R(s, a)
a,

a,z




ia,z (s)

=

X

(15)
0

0

0

(s, a, )O(s , a, z)i (s ), t1

s0

a, ia,z |S|-dimensional hyper-plane.
Next create (a A), cross-sum observations1 , includes one a,z
a,z
(Step 2):
a,z1
2
...
a,z
= a,

+

(16)

Finally take union sets (Step 3):
= aA .

(17)

forms pieces backup solution horizon t. actual value function Vt
extracted set described Equation 13.
Using approach, bounded-time POMDP problems finite state, action, observation
spaces solved exactly given choice horizon . environment
agent might able bound planning horizon advance, policy (b) approximation optimal one whose quality improves expectation planning horizon (assuming
0 < 1).
mentioned above, value function Vt extracted directly set . important aspect algorithm (and optimal finite-horizon POMDP solutions)
value function guaranteed piecewise linear, convex, continuous function belief (Sondik, 1971). piecewise-linearity continuous properties direct result fact
Vt composed finitely many linear -vectors. convexity property result
a,

maximization operator (Eqn 13). worth pointing intermediate sets a,z
,
also represent functions belief composed entirely linear segments. property
holds intermediate representations incorporate expectation observation
probabilities (Eqn 15).
worst case, exact value update procedure described could require time doubly exponential planning horizon (Kaelbling et al., 1998). better understand complexity
exact update, let |S| number states, |A| number actions, |Z| number
observations, |t1 | number -vectors previous solution set. Step 1 creates
|A| |Z| |t1 | projections Step 2 generates |A| |t1 ||Z| cross-sums. So, worst case,
new solution requires:
|t | = O(|A||t1 ||Z| )

(18)

1. symbol denotes cross-sum operator. cross-sum operation defined two sets, =
{a1 , a2 , . . . , } B = {b1 , b2 , . . . , bn }, produces third set, C = {a1 + b1 , a1 + b2 , . . . , a1 + bn , a2 +
b1 , a2 + b2 , . . . , . . . , + bn }.

342

fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDP

-vectors represent value function horizon t; computed time
O(|S|2 |A| |t1 ||Z| ).
often case vector completely dominated another vector
entire belief simplex:
b < j b, b.
(19)
Similarly, vector may fully dominated set vectors (e.g., 2 Fig. 1 dominated combination 1 3 ). vector pruned away without affecting
solution. Finding dominated vectors expensive. Checking whether single vector
dominated requires solving linear program |S| variables |t | constraints. Nonetheless
time-effective apply pruning iteration prevent explosion solution
size. practice, |t | often appears grow singly exponentially t, given clever mechanisms
pruning unnecessary linear functions. enormous computational complexity long
key impediment toward applying POMDPs practical problems.

V={ 0 , 1 , 2 , 3 }

Figure 1: POMDP value function representation

2.4 Point-Based Value Backup
Exact POMDP solving, outlined above, optimizes value function beliefs. Many
approximate POMDP solutions, including PBVI approach proposed paper, gain computational advantage applying value updates specific (and few) belief points, rather
beliefs (Cheng, 1988; Zhang & Zhang, 2001; Poon, 2001). approaches differ significantly
(and great consequence) select belief points, set points selected,
procedure updating value standard. describe procedure updating
value function set known belief points.
Section 2.3, value function update implemented sequence operations
set -vectors. assume interested updating value function fixed
set belief points, B = {b0 , b1 , ..., bq }, follows value function contain
one -vector belief point. point-based value function therefore represented
corresponding set {0 , 1 , . . . , q }.
Given solution set t1 , simply modify exact backup operator (Eqn 14)
one -vector per belief point maintained. point-based backup gives -vector
valid region around b. assumes belief points region
action choice lead facets Vt1 point b. key idea behind
algorithms presented paper, reason large computational savings associated
class algorithms.
343

fiP INEAU , G ORDON & HRUN

obtain solution set previous set t1 , begin generating intera,z
mediate sets a,
, A, z Z (exactly Eqn 15) (Step 1):
a,
a, (s) = R(s, a)

a,z




ia,z (s)

=

(20)
0

X

0

0

(s, a, )O(s , a, z)i (s ), t1 .

s0

Next, whereas performing exact value update requires cross-sum operation (Eqn 16),
operating finite set points, instead use simple summation. construct ,
(Step 2):
ba = a,
+

X

argmax(

a,z
zZ

X

(s)b(s)), b B.

(21)

sS

Finally, find best action belief point (Step 3):
b = argmax(

X


,aA sS

(s)b(s)), b B.

= bB b

(22)
(23)

operations preserve best -vector belief point b B, estimate
value function belief simplex (including b
/ B) extracted set
before:
X

Vt (b) = max


(s)b(s).

(24)

sS

better understand complexity updating value set points B, let |S|
number states, |A| number actions, |Z| number observations, |t1 | number
-vectors previous solution set. exact update, Step 1 creates |A| |Z| |t1 |
projections (in time |S|2 |A| |Z| |t1 |). Steps 2 3 reduce set |B| components
(in time |S| |A| |t1 | |Z| |B|). Thus, full point-based value update takes polynomial time,
even crucially, size solution set remains constant every iteration.
point-based value backup algorithm summarized Table 1.
Note algorithm outlined Table 1 includes trivial pruning step (lines 13-14),
whereby refrain adding vector already included it. result, often
case |t | |B|. situation arises whenever multiple nearby belief points support
vector. pruning step computed rapidly (without solving linear programs) clearly
advantageous terms reducing set .
point-based value backup found many POMDP solvers, general serves improve estimates value function. also integral part PBVI framework.

3. Anytime Point-Based Value Iteration
describe algorithmic framework new class fast approximate POMDP algorithms called Point-Based Value Iteration (PBVI). PBVI-class algorithms offer anytime solution
large-scale discrete POMDP domains. key achieving anytime solution interleave
344

fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDP

=BACKUP(B, t1 )
action
observation z Z
solution vector t1
P
ia,z (s) = s0 (s, a, s0 )O(s0 , a, z)i (s0 ),
End
a,z
a,z
=
End
End
=
belief point hb B

P
P
P
b = argmaxaA
[
(s)b(s)]
sS R(s, a)b(s) +
zZ maxa,z
sS

If(b
/ )
= b
End
Return

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16

Table 1: Point-based value backup

two main components: point-based update described Table 1 steps belief set selection. approximate value function find guaranteed bounded error (compared
optimal) discrete POMDP domain.
current section focuses overall anytime algorithm theoretical properties, independent belief point selection process. Section 4 discusses detail various novel
techniques belief point selection.
overall PBVI framework simple. start (small) initial set belief points
applied first series backup operations. set belief points grown,
new series backup operations applied belief points (old new), on,
satisfactory solution obtained. interleaving value backup iterations expansions
belief set, PBVI offers range solutions, gradually trading computation time solution
quality.
full algorithm presented Table 2. algorithm accepts input initial belief point
set (BInit ), initial value (0 ), number desired expansions (N ), planning horizon
(T ). common choice BInit initial belief b0 ; alternately, larger set could used,
especially cases sample trajectories available. initial value, 0 , typically set
min
purposefully low (e.g., 0 (s) = R1
, S). this, show pointbased solution always lower-bound exact solution (Lovejoy, 1991a). follows
simple observation failing compute -vector lower value function.
problems finite horizon, run value backups expansion
belief set. infinite-horizon problems, select horizon
[Rmax Rmin ] < ,
Rmax = maxs,a R(s, a) Rmin = mins,a R(s, a).
345

(25)

fiP INEAU , G ORDON & HRUN

complete algorithm terminates fixed number expansions (N ) completed. Alternately, algorithm could terminate value function approximation reaches
given performance criterion. discussed below.
algorithm uses BACKUP routine described Table 1. assume moment
EXPAND subroutine (line 8) selects belief points random. performs reasonably
well small problems easy achieve good coverage entire belief simplex.
However scales poorly larger domains exponentially many points needed guarantee
good coverage belief simplex. sophisticated approaches selecting belief points
presented Section 4. Overall, PBVI framework described offers simple yet flexible
approach solving large-scale POMDPs.
=PBVI-MAIN(BInit , 0 , N , )
B=BInit
= 0
N expansions
iterations
=BACKUP(B,)
End
Bnew =EXPAND(B,)
B = B Bnew
End
Return

1
2
3
4
5
6
7
8
9
10
11

Table 2: Algorithm Point-Based Value Iteration (PBVI)
belief set B horizon t, algorithm Table 2 produce estimate value
function, denoted VtB . show error VtB optimal value function V
bounded. bound depends densely B samples belief simplex ; denser
sampling, VtB converges Vt , t-horizon optimal solution, turn bounded error
respect V , optimal solution. cutting PBVI iterations sufficiently large
horizon, show difference VtB optimal infinite-horizon V
large. overall error PBVI bounded, according triangle inequality, by:
kVtB V k kVtB Vt k + kVt V k .

(26)

second term bounded kV0 V k (Bertsekas & Tsitsiklis, 1996). remainder
section states proves bound first term, denote .
Begin assuming H denotes exact value backup, H denotes PBVI backup.
define (b) error introduced specific belief b performing one iteration
point-based backup:
(b) = |HV B (b) HV B (b)| .
Next define maximum total error introduced one iteration point-based backup:
= |HV B HV B |
= max (b).
b

346

fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDP

Finally define density B set belief points B maximum distance belief
simplex belief set B. precisely:
B = max
min kb b0 k1 .
0
b bB

(27)

prove following lemma:
Lemma 1. error introduced PBVI performing one iteration value backup B,
instead , bounded
(Rmax Rmin )B

1
Proof: Let b0 point PBVI makes worst error value update, b B
closest (1-norm) sampled belief b0 . Let vector maximal b, 0
vector would maximal b0 . failing include 0 solution set, PBVI makes error
0 b0 b0 . hand, since maximal b, 0 b b. So,
0 b 0 b0
=

=



0 b0 b0 + (0 b 0 b)
0 b0 b 0 + b 0 b
(0 ) (b0 b)
k0 k kb0 bk1
k0 k B



(Rmax Rmin )B
1

Add zero
Assume optimal b
Re-arrange terms
Holder inequality
definition B

last inequality holds -vector represents reward achievable starting
state following sequence actions observations. Therefore sum rewards
min
max
must fall R1
R1
.
Lemma 1 states bound approximation error introduced one iteration point-based
value updates within PBVI framework. look bound multiple value updates.
Theorem 3.1. belief set B horizon t, error PBVI algorithm = kVtB
Vt k bounded
(Rmax Rmin )B

(1 )2
Proof:
= ||VtB Vt ||
B HV ||
= ||HVt1
t1




=


definition H

B HV B || + ||HV B HV ||
||HVt1
t1
t1
t1
(Rmax Rmin )B
B

+ ||HVt1 HVt1 ||
1
(Rmax Rmin )B
B V ||
+ ||Vt1
t1
1

triangle inequality

(Rmax Rmin )B
1
(Rmax Rmin )B
(1)2

definition t1

+ t1

lemma 1
contraction exact value backup

sum geometric series
347

fiP INEAU , G ORDON & HRUN

bound described section depends densely B samples belief simplex .
case beliefs reachable, PBVI need sample densely,
(Fig. 2). error bounds convergence results
replace set reachable beliefs
0


hold . simply need re-define b lemma 1.
side note, worth pointing PBVI makes assumption regarding
initial value function V0B , point-based solution V B guaranteed improve
addition belief points. Nonetheless, theorem presented section shows bound
error VtB (the point-based solution) V (the optimal solution) guaranteed
decrease (or stay same) addition belief points. cases VtB initialized
min
pessimistically (e.g., V0B (s) = R1
, S, suggested above), VtB improve (or stay
same) value backup addition belief points.
section thus far skirted issue belief point selection, however bound presented
section clearly argues favor dense sampling belief simplex. randomly
selecting points according uniform distribution may eventually accomplish this, generally
inefficient, particular high dimensional cases. Furthermore, take advantage
fact error bound holds dense sampling reachable beliefs. Thus seek
efficient ways generate belief points random entire simplex. issue
explored next section.

4. Belief Point Selection
section 3, outlined prototypical PBVI algorithm, conveniently avoiding question
belief points selected. clear trade-off including fewer
beliefs (which would favor fast planning good performance), versus including many beliefs
(which would slow planning, ensure better bound performance). brings
question many belief points included. However number points
consideration. likely collections belief points (e.g., frequently encountered)
likely produce good value function others. brings question
beliefs included.
number approaches proposed literature. example, exact value
function approaches use linear programs identify points value function needs
improved (Cheng, 1988; Littman, 1996; Zhang & Zhang, 2001), however typically
expensive. value function also approximated learning value regular points,
using fixed-resolution (Lovejoy, 1991a), variable-resolution (Zhou & Hansen, 2001) grid.
less expensive solving LPs, scales poorly number states increases. Alternately, one use heuristics generate grid-points (Hauskrecht, 2000; Poon, 2001). tends
scalable, though significant experimentation required establish heuristics
useful.
section presents five heuristic strategies selecting belief points, fast naive
random sampling, increasingly sophisticated stochastic simulation techniques.
effective strategy propose one carefully selects points likely largest
impact reducing error bound (Theorem 3.1).
strategies consider focus selecting reachable beliefs, rather getting
uniform coverage entire belief simplex. Therefore useful begin discussion
looking reachability assessed.
348

fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDP

exact POMDP value iteration solutions optimal initial belief, PBVI (and
related techniques) assume known initial belief b0 . shown Figure 2, use
initial belief build tree reachable beliefs. representation, path tree
corresponds sequence belief space, increasing depth corresponds increasing plan
horizon. selecting set belief points PBVI, including reachable beliefs would guarantee optimal performance (conditioned initial belief), expense computational
grow exponentially planning horitractability, since set reachable beliefs, ,
sufficiently small computational
zon. Therefore, best select subset B
tractability, sufficiently large good value function approximation.2

b0

...
ba z ba z

ba z

0 q

0 0 a0 z0

1 1

ba z

1 q

...

ba z

1 0

...
...

...

...

ba z ba z

...
ba z ba z
p 0

p 1

ba z

p q

...

0 1

...

...
...

0 0

...

...
ba z

0 0 ap zq

ba z

0 1 a0 z0

ba z

0 1 ap zq

...

...

...

...

Figure 2: set reachable beliefs
domains initial belief known (or unique), still possible use reachability analysis sampling initial beliefs (or using set known initial beliefs) seed
multiple reachability trees.
discuss five strategies selecting belief points, used within
PBVI framework perform expansion belief set.
4.1 Random Belief Selection (RA)
first strategy also simplest. consists sampling belief points uniform distribution entire belief simplex. sample simplex, cannot simply sample
P
b(s) independently [0, 1] (this would violate constraint b(s) = 1). Instead, use
algorithm described Table 3 (see Devroye, 1986, details including proof uniform
coverage).
random point selection strategy, unlike strategies presented below, focus
reachable beliefs. reason, necessarily advocate approach. However
include obvious choice, far simplest implement, used
related work Hauskrecht (2000) Poon (2001). smaller domains (e.g., <20 states),
2. strategies discussed assume belief point set, B, approximately doubles size belief
expansion. ensures number rounds value iteration logarithmic (in final number belief
points needed). Alternately, strategy could used (with little modification) add fixed number new
belief points, may require many rounds value iteration. Since value iteration much expensive
belief computation, seems appropriate double size B expansion.

349

fiP INEAU , G ORDON & HRUN

Bnew =EXPANDRA (B, )
Bnew = B
Foreach b B
:= number states
= 0 :
btmp [i]=randuniform (0,1)
End
Sort btmp ascending order
= 1 : 1
bnew [i]=btmp [i + 1] btmp [i]
End
Bnew = Bnew bnew
End
Return Bnew

1
2
3
4
5
6
7
8
9
10
11
12
13
14

Table 3: Algorithm belief expansion random action selection

performs reasonably well, since belief simplex relatively low-dimensional. large domains
(e.g., 100+ states), cannot provide good coverage belief simplex reasonable number
points, therefore exhibits poor performance. demonstrated experimental results
presented Section 6.
remaining belief selection strategies make use belief tree (Figure 2) focus
reachable beliefs, rather trying cover entire belief simplex.
4.2 Stochastic Simulation Random Action (SSRA)
generate points along belief tree, use technique called stochastic simulation. involves
running single-step forward trajectories belief points already B. Simulating single-step
forward trajectory given b B requires selecting action observation pair (a, z),
computing new belief (b, a, z) using Bayesian update rule (Eqn 7). case
Stochastic Simulation Random Action (SSRA), action selected forward simulation
picked (uniformly) random full action set. Table 4 summarizes belief expansion
procedure SSRA. First, state drawn belief distribution b. Second, action
drawn random full action set. Next, posterior state s0 drawn transition
model (s, a, s0 ). Finally, observation z drawn observation model O(s0 , a, z). Using
triple (b, a, z), calculate new belief bnew = (b, a, z) (according Equation 7),
add set belief points Bnew .
strategy better picking points random (as described above), restricts
Bnew belief tree (Fig. 2). However belief tree still large, especially
branching factor high, due large numbers actions/observations. selective
paths belief tree explored, one hope effectively restrict belief set
further.
350

fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDP

Bnew =EXPANDSSRA (B, )
Bnew = B
Foreach b B
s=randmultinomial (b)
a=randuniform (A)
s0 =randmultinomial (T (s, a, ))
z=randmultinomial (O(s0 , a, ))
bnew = (b, a, z) (see Eqn 7)
Bnew = Bnew bnew
End
Return Bnew

1
2
3
4
5
6
7
8
9
10
11

Table 4: Algorithm belief expansion random action selection

similar technique stochastic simulation discussed Poon (2001), however belief set initialized differently (not using b0 ), therefore stochastic simulations
restricted set reachable beliefs.
4.3 Stochastic Simulation Greedy Action (SSGA)
procedure generating points using Stochastic Simulation Greedy Action (SSGA)
based well-known -greedy exploration strategy used reinforcement learning (Sutton &
Barto, 1998). strategy similar SSRA procedure, except rather choosing
action randomly, SSEA choose greedy action (i.e., current best action given belief
b) probability 1 , chose random action probability (we use = 0.1).
action selected, perform single-step forward simulation SSRA yield new belief
point. Table 5 summarizes belief expansion procedure SSGA.
similar technique, featuring stochastic simulation using greedy actions, outlined
Hauskrecht (2000). However case, belief set included extreme points belief
simplex, stochastic simulation done extreme points, rather initial
belief.
4.4 Stochastic Simulation Exploratory Action (SSEA)
error bound Section 3 suggests PBVI performs best belief set uniformly dense
set reachable beliefs. belief point strategies proposed thus far ignore information.
next approach propose gradually expands B greedily choosing new reachable beliefs
improve worst-case density.
Unlike SSRA SSGA select single action simulate forward trajectory
given b B, Stochastic Sampling Exploratory Action (SSEA) one step forward
simulation action, thus producing new beliefs {ba0 , ba1 , ...}. However accept
new beliefs {ba0 , ba1 , ...}, rather calculates L1 distance ba closest
neighbor B. keep point ba farthest away point already B.
351

fiP INEAU , G ORDON & HRUN

Bnew =EXPANDSSGA (B, )
Bnew = B
Foreach b B
s=randmultinomial (b)
randuniform [0, 1] <
a=randuniform (A)
Else
P
a=argmax sS (s)b(s)
End
s0 =randmultinomial (T (s, a, ))
z=randmultinomial (O(s0 , a, ))
bnew = (b, a, z) (see Eqn 7)
Bnew = Bnew bnew
End
Return Bnew

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15

Table 5: Algorithm belief expansion greedy action selection

use L1 norm calculate distance belief points consistent error bound
Theorem 3.1. Table 6 summarizes SSEA expansion procedure.
Bnew =EXPANDSSEA (B, )
Bnew = B
Foreach b B
Foreach
s=randmultinomial (b)
s0 =randmultinomial (T (s, a, ))
z=randmultinomial (O(s0 , a, ))
ba = (b, a, z) (see Eqn 7)
End
P
bnew = maxaA minb0 Bnew sS |ba (s) b0 (s)|
Bnew = Bnew bnew (see Eqn 7)
End
Return Bnew

1
2
3
4
5
6
7
8
9
10
11
12
13

Table 6: Algorithm belief expansion exploratory action selection

4.5 Greedy Error Reduction (GER)
SSEA strategy able improve worst-case density reachable beliefs,
directly minimize expected error. would like directly minimize
352

fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDP

error, measure bound error (Lemma 1). therefore propose final strategy
greedily adds candidate beliefs effectively reduce error bound.
empirical results, presented below, show strategy successful one discovered
thus far.
understand expand belief set GER strategy, useful re-consider
belief tree, reproduce Figure 3. node tree corresponds specific belief.
divide nodes three sets. Set 1 includes belief points already B,
case b0 ba0 z0 . Set 2 contains belief points immediate descendants points
B (i.e., nodes grey zone). candidates select new
points added B. call set envelope (denoted B). Set 3 contains reachable
beliefs.

b0

...
ba z ba z

0 q

1 q

...

...

1 1

...
...

0

0 a0 z0

...

...

ba z

1 0

...
ba z

...

ba z ba z
p 0

p 1

ba z

p q

...

0 1

ba z ba z

...
...

0 0

...

ba z

ba z

0 0 ap zq

...

...

Figure 3: set reachable beliefs
need decide belief b removed envelope B added set
active belief points B. Every point added B improve estimate value
function. new point reduce error bounds (as defined Section 3 points
already B; however, error bound new point might quite large. means
largest error bound points B monotonically decrease; however, particular
point B (such initial belief b0 ) error bound decreasing.
find point reduce error bound, look analysis
Lemma 1. Lemma 1 bounds amount additional error single point-based backup introduces. Write b0 new belief considering adding, write b belief
already B. Write value hyper-plane b, write 0 b0 . lemma
points out,
(b0 ) (0 ) (b0 b)
evaluating error, need minimize b B. Also, since know
0 done backups b0 , make conservative assumption choose
worst-case value 0 [Rmin /(1 ), Rmax /(1 )]|S| . Thus, evaluate:
(

(b0 ) min
bB

X
sS

max
(s))(b0 (s) b(s)) b0 (s) b(s)
( R1
Rmin
( 1 (s))(b0 (s) b(s)) b0 (s) < b(s)

353

(28)

fiP INEAU , G ORDON & HRUN

one could simply pick candidate b0 B currently largest error bound,3
would ignore reachability considerations. Rather, evaluate error b B,
weighing error fringe nodes reachability probability:
(b0 ),

X

(b) = max
aA

O(b, a, z) ( (b, a, z))


X

= max
aA

(29)

zZ


XX


zZ

(s, a, s0 )O(s0 , a, z)b(s) ( (b, a, z)),

sS s0

noting (b, a, z) B, ( (b, a, z)) evaluated according Equation 28.
Using Equation 29, find existing point b B largest error bound.
directly reduce error adding set one descendants. select next-step belief
(b, a, z) maximizes error bound reduction:
B

=

B (b, a, z),

b, := argmax

(30)
X

O(b, a, z) ( (b, a, z))

(31)

bB,aA zZ

z := argmax O(b, a, z) ( (b, a, z))

(32)

zZ

Table 7 summarizes GER approach belief point selection.
Bnew =EXPANDGER (B, )
Bnew = B
N =|B|
= 1 : N
P
b, := argmaxbB,aA zZ O(b, a, z) ( (b, a, z))
z := argmaxzZ O(b, a, z) ( (b, a, z))
bnew = (b, a, z)
Bnew = Bnew bnew
End
Return Bnew

1
2
3
4
5
6
7
8
9
10

Table 7: Algorithm belief expansion

complexity adding one new points GER O(SAZB) (where S=#states,
A=#actions, Z=#observations, B=#beliefs already selected). comparison, value backup (for
one point) O(S 2 AZB), point typically needs updated several times. point
empirical results below, belief selection (even GER) takes minimal time compared
value backup.
concludes presentation belief selection techniques PBVI framework.
summary, three factors consider picking belief point: (1) likely
3. tried this, however perform well empirically suggest Equation 29,
consider probability reaching belief.

354

fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDP

occur? (2) far belief points already selected? (3) current approximate
value point? simplest heuristic (RA) accounts none these, whereas
others (SSRA, SSGA, SSEA) account one, GER incorporates three factors.
4.6 Belief Expansion Example
consider simple example, shown Figure 4, illustrate difference various
belief expansion techniques outlined above. 1D POMDP (Littman, 1996) four states, one
goal (indicated star). two actions, left right, expected
(deterministic) effect. goal state fully observable (observation=goal), three
states aliased (observation=none). reward +1 received goal state,
otherwise reward zero. assume discount factor = 0.75. initial distribution
uniform non-goal states, system resets distribution whenever goal reached.

Figure 4: 1D POMDP
belief set B always initialized contain initial belief b0 . Figure 5 shows part
belief tree, including original belief set (top node), envelope (leaf nodes).
consider belief expansion method might do.
b0=[ 1/ 3 1/ 3 0 1/ 3 ]
a=left

a=right

[ 2/ 3 0 1/ 3 0 ]

Pr(z=none)=2/3

b1=[ 1 0 0 0 ]

[ 0 1/ 3 1/ 3 1/ 3 ]

Pr(z=goal) = 1/3

Pr(z=none)=2/3

b2=[ 0 0 1 0 ]

b3=[ 0 0.5 0 0.5 ]

Pr(z=goal) = 1/3

b4=[ 0 0 1 0 ]

Figure 5: 1D POMDP belief tree
Random heuristic pick belief point (with equal probability) entire belief
simplex. directly expand branches belief tree, eventually put samples
nearby.
Stochastic Simulation Random Action 50% chance picking action.
Then, regardless action picked, theres 2/3 chance seeing observation none,
1/3 chance seeing observation goal. result, SSRA select: P r(bnew = b1) = 0.5 32 ,
P r(bnew = b2) = 0.5 13 , P r(bnew = b3) = 0.5 23 , P r(bnew = b4) = 0.5 31 .
355

fiP INEAU , G ORDON & HRUN

Stochastic Simulation Greedy Action first needs know policy b0 .
iterations point-based updates (Section 2.4) applied initial (single point) belief set reveal
(b0 ) = lef t.4 result, expansion belief greedily select action lef proba
bility 1 + |A|
= 0.95 (assuming = 0.1 |A| = 2). Action right selected belief

expansion probability |A|
= 0.05. Combining along observation probabilities,
tell SSGA expand follows: P r(bnew = b1) = 0.95 32 , P r(bnew = b2) = 0.95 13 ,
P r(bnew = b3) = 0.05 23 , P r(bnew = b4) = 0.05 13 .
Predicting choice Stochastic Simulation Exploratory Action slightly complicated. Four cases occur, depending outcomes random forward simulation b0 :
1. action left goes b1 (P r = 2/3) action right goes b3 (P r = 2/3), b1
selected ||b0 b1 ||1 = 4/3 whereas ||b0 b3 ||1 = 2/3. case occur
P r = 4/9.
2. action left goes b1 (P r = 2/3) action right goes b4 (P r = 1/3), b4
selected ||b0 b4 ||1 = 2. case occur P r = 2/9.
3. action left goes b2 (P r = 1/3) action right goes b3 (P r = 2/3), b2
selected ||b0 b2 ||1 = 2. case occur P r = 2/9.
4. action left goes b2 (P r = 1/3) action right goes b4 (P r = 1/3), either
selected (since equidistant b0 ). case b2 b4 P r = 1/18
selected.
told, P r(bnew = b1) = 4/9, P r(bnew = b2) = 5/18, P r(bnew = b3) = 0, P r(bnew = b4) =
5/18.
looking belief expansion using Greedy Error Reduction, need compute
error ( (b0 , a, z)), a, z. consider Equation 28: since B one point, b0 , necessarily b = b0 . estimate , apply multiple steps value backup b0 obtain
= [0.94 0.94 0.92 1.74]. Using b such, estimate error candidate belief: (b1 ) = 2.93, (b2 ) = 4.28, (b3 ) = 1.20, (b4 ) = 4.28. Note B
one point, dominating factor distance b0 . Next, factor observation
probabilities, Eqns 31-32, allows us determine = lef z = none,
therefore select bnew = b1 .
summary, note SSGA, SSEA GER favor selecting b1 , whereas SSRA picks
option equal probability (considering b2 b4 actually same). general,
problem size, reasonable expand entire belief tree. techniques
discussed quickly, except RA pick exact nodes belief
tree, select equally good nearby beliefs. example provided simply illustrate
different choices made strategy.

5. Review Point-Based Approaches POMDP Solving
previous section describes new class point-based algorithms POMDP solving. idea
using point-based updates POMDPs explored previously literature,
4. may obvious reader, follows directly repeated application equations 2023.

356

fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDP

section summarize main results. approaches discussed below, procedure
updating value function given point remains unchanged (as outlined Section 2.4).
Rather, approaches mainly differentiated belief points selected,
updates ordered.
5.1 Exact Point-Based Algorithms
earlier exact POMDP techniques use point-based backups optimize value function limited regions belief simplex (Sondik, 1971; Cheng, 1988). techniques
typically require solving multiple linear programs find candidate belief points value
function sub-optimal, expensive operation. Furthermore, guarantee exact solution found, relevant beliefs must generated systematically, meaning reachable
beliefs must considered. result, methods typically cannot scale beyond handful
states/actions/observations.
work Zhang Zhang (2001), point-based updates interleaved standard dynamic programming updates accelerate planning. case points generated
systematically, rather backups applied set witness points LP points.
witness points identified result standard dynamic programming updates, whereas
LP points identified solving linear programs identify beliefs value
yet improved. procedures significantly expensive belief selection heuristics presented paper results limited domains dozen
states/actions/observations. Nonetheless approach guaranteed converge optimal solution.
5.2 Grid-Based Approximations
exists many approaches approximate value function using finite set belief points
along values. points often distributed according grid pattern belief
space, thus name grid-based approximation. interpolation-extrapolation rule specifies
value non-grid points function value neighboring grid-points. approaches
ignore convexity POMDP value function.
Performing value backups grid-points relatively straightforward: dynamic programming
updates specified Equation 11 adapted grid-points simple polynomial-time
algorithm. Given set grid points G, value bG G defined by:
"
G

V (b ) = max


#
X

X

G

b (s)R(s, a) +

sS

P r(z | a, b)V ( (b, a, z)) .

(33)

zZ

(b, a, z) part grid, V ( (b, a, z)) defined value backups. Otherwise,
V ( (b, a, z)) approximated using interpolation rule as:
V ( (b, a, z) =

|G|
X

(i)V (bG
),

(34)

i=1

P|G|

(i) 0 i=1 (i) = 1. produces convex combination grid-points.
two interesting questions respect grid-based approximations (1) calculate
interpolation function; (2) select grid points.
357

fiP INEAU , G ORDON & HRUN

general, find interpolation leads best value function approximation point
b requires solving following linear program:
Minimize

|G|
X

(i)V (bG
)

(35)

i=1

Subject

b=

|G|
X

(i)bG


(36)

i=1
|G|
X

(i) = 1

(37)

i=1

0 (i) 1, 1 |G|.

(38)

Different approaches proposed select grid points. Lovejoy (1991a) constructs
fixed-resolution regular grid entire belief space. benefit value interpolations
calculated quickly considering neighboring grid-points. disadvantage number
grid points grows exponentially dimensionality belief (i.e., number
states). simpler approach would select random points belief space (Hauskrecht,
1997). requires slower interpolation estimating value new points.
methods less ideal beliefs encountered uniformly distributed.
particular, many problems characterized dense beliefs edges simplex (i.e.,
probability mass focused states, states zero probability), low
belief density middle simplex. distribution grid-points better reflects
actual distribution belief points therefore preferable.
Alternately, Hauskrecht (1997) also proposes using corner points belief simplex (e.g.,
[1 0 0 . . . ], [0 1 0 . . . ], . . . , [0 0 0 . . . 1]), generating additional successor belief points
one-step stochastic simulations (Eqn 7) corner points. also proposes approximate
interpolation algorithm uses values |S|1 critical points plus one non-critical point
grid. alternative approach Brafman (1997), builds grid also starting
critical points belief simplex, uses heuristic estimate usefulness gradually
adding intermediate points (e.g., bk = 0.5bi + 0.5bj , pair points). Hauskrechts
Brafmans methodsgenerally referred non-regular grid approximationsrequire fewer
points Lovejoys regular grid approach. However interpolation rule used calculate
value non-grid points typically expensive compute, since involves searching
grid points, rather neighboring sub-simplex.
Zhou Hansen (2001) propose grid-based approximation combines advantages
regular non-regular grids. idea sub-sample regular fixed-resolution grid
proposed Lovejoy. gives variable resolution grid since parts beliefs
densely sampled others restricting grid points lie fixed-resolution grid
approach guarantee fast value interpolation non-grid points. Nonetheless, algorithm
often requires large number grid points achieve good performance.
Finally, Bonet (2002) proposes first grid-based algorithm POMDPs -optimality
(for > 0). approach requires thorough coverage belief space every point
within grid-point. value update grid point fast implement, since
interpolation rule depends nearest neighbor one-step successor belief
grid point (which pre-computed). main limitation fact -coverage belief
358

fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDP

space attained using exponentially many grid points. Furthermore, method
requires good coverage entire belief space, opposed algorithms Section 4,
focus coverage reachable beliefs.
5.3 Approximate Point-Based Algorithms
similar PBVI-class algorithms approaches update value
gradient grid point (Lovejoy, 1991a; Hauskrecht, 2000; Poon, 2001). methods able
preserve piecewise linearity convexity value function, define value function
entire belief simplex. methods use random beliefs, and/or require inclusion large number fixed beliefs corners probability simplex. contrast,
PBVI-class algorithms propose (with exception PBVI+RA) select reachable beliefs,
particular belief points improve error bounds quickly possible. idea
using reachability analysis (also known stochastic simulation) generate new points explored earlier approaches (Hauskrecht, 2000; Poon, 2001). However analysis
indicated stochastic simulation superior random point placements. re-visit
question (and conclude otherwise) empirical evaluation presented below.
recently, technique closely related PBVI called Perseus proposed (Vlassis
& Spaan, 2004; Spaan & Vlassis, 2005). Perseus uses point-based backups similar ones
used PBVI, two approaches differ two ways. First, Perseus uses randomly generated
trajectories belief space select set belief points. contrast beliefpoint selection heuristics outlined PBVI. Second, whereas PBVI systematically updates
value belief points every epoch value iteration, Perseus selects subset points
update every epoch. method used select points following: points randomly
sampled one time value updated. continues value points
improved. insight resides observing updating -vector one point often also
improves value estimate nearby points (which removed sampling set).
approach conceptually simple empirically effective.
HSVI algorithm (Smith & Simmons, 2004) another point-based algorithm, differs
PBVI picks belief points, orders value updates. maintains lower
upper bound value function approximation, uses select belief points.
updating upper bound requires solving linear programs generally expensive
step. ordering value update follows: whenever belief point expanded
belief tree, HSVI updates value direct ancestors (parents, grand-parents, etc.,
way back initial belief head node). contrast PBVI performs batch
belief point expansions, followed batch value updates points. respects,
HSVI PBVI share many similarities: offer anytime performance, theoretical guarantees,
scalability; finally HSVI also takes reachability account. evaluate empirical
differences HSVI PBVI next section.
Finally, RTBSS algorithm (Paquet, 2005) offers online version point-based algorithms.
idea construct belief reachability tree similar Figure 2, using current belief
top node, terminating tree fixed depth d. value node
computed recursively finite planning horizon d. algorithm eliminate subtrees
calculating bound value, comparing value computed subtrees.
RTBSS fact combined offline algorithms PBVI, offline algorithm
359

fiP INEAU , G ORDON & HRUN

used pre-compute lower bound exact value function; used increase subtree
pruning, thereby increasing depth online tree construction thus also quality
solution. online algorithm yield fast results large POMDP domains. However
overall solution quality achieve error guarantees offline approaches.

6. Experimental Evaluation
section looks variety simulated POMDP domains evaluate empirical performance
PBVI. first three domainsTiger-grid, Hallway, Hallway2are extracted established POMDP literature (Cassandra, 1999). fourthTagwas introduced
earlier work new challenge POMDP algorithms.
first goal experiments establish scalability PBVI framework;
accomplished showing PBVI-type algorithms successfully solve problems excess
800 states. also demonstrate PBVI algorithms compare favorably alternative approximate
value iteration methods. Finally, following example Section 4.6, study larger scale
impact belief selection strategy, confirms superior performance GER
strategy.
6.1 Maze Problems
exists set benchmark problems commonly used evaluate POMDP planning algorithms (Cassandra, 1999). section presents results demonstrating performance PBVIclass algorithms problems. benchmark problems relatively small
(at 92 states, 5 actions, 17 observations) compared robotics planning domains,
useful analysis point view comparison previous work.
initial performance analysis focuses three well-known problems POMDP literature: Tiger-grid (also known Maze33), Hallway, Hallway2. three maze navigation
problems various sizes. problems fully described Littman, Cassandra, Kaelbling
(1995a); parameterization available Cassandra (1999).
Figure 6a presents results Tiger-grid domain. Replicating earlier experiments Brafman (1997), test runs terminate 500 steps (theres automatic reset every time goal
reached) results averaged 151 runs.
Figures 6b 6c present results Hallway Hallway2 domains, respectively.
case, test runs terminated goal reached 251 steps (whichever occurs first),
results averaged 251 runs. consistent earlier experiments Littman,
Cassandra, Kaelbling (1995b).
three figures compare performance three different algorithms:
1. PBVI Greedy Error Reduction (GER) belief point selection (Section 4.5).
2. QMDP (Littman et al., 1995b),
3. Incremental Pruning (Cassandra, Littman, & Zhang, 1997),
QMDP heuristic (Littman et al., 1995b) takes account partial observability current step, assumes full observability subsequent steps:
QM DP (b) = argmax
aA

360

X
sS

b(s)QM DP (s, a).

(39)

fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDP

resulting policy ability resolve uncertainty, cannot benefit long-term
information gathering, compare actions different information potential. QMDP seen
providing good performance baseline. three problems considered, finds policy
extremely quickly, policy clearly sub-optimal.
end spectrum, Incremental Pruning algorithm (Zhang & Liu, 1996; Cassandra et al., 1997) direct extension enumeration algorithm described above. principal insight pruning dominated -vectors (Eqn 19) interleaved directly
cross-sum operator (Eqn 16). resulting value function same, algorithm
efficient discards unnecessary vectors earlier on. Incremental Pruning algorithm
theoretically find optimal policy, three problems considered would take far
long. fact, iterations exact backups completed reasonable time. three
problems, resulting short-horizon policy worse corresponding PBVI policy.
shown Figure 6, PBVI+GER provides much better time/performance trade-off. finds
policies better obtained QMDP, matter seconds, thereby
demonstrating suffer paralyzing complexity Incremental Pruning.
take closer look results may surprised see performance
PBVI actually decreases points (e.g., dip Fig. 6c), unexpected.
important remember theoretical properties PBVI guarantee bound
estimate value function, shown here, necessarily imply policy
needs improve monotonically. Nonetheless, value function converges, policy
(albeit slower rate).
6.2 Tag Problem
previous section establishes good performance PBVI well-known simulation problems, quite small fully demonstrate scalability algorithm.
provide better understanding PBVIs effectiveness large problems, section presents
results obtained applying PBVI Tag problem, robot version popular game
lasertag. problem, agent must navigate environment goal searching for,
tagging, moving target (Rosencrantz, Gordon, & Thrun, 2003). Real-world versions
problem take many forms, Section 7 present similar problem domain
interactive service robot must find elderly patient roaming corridors nursing home.
synthetic scenario considered order magnitude larger (870 states)
POMDP benchmarks literature (Cassandra, 1999). formulated POMDP problem, goal robot optimize policy allowing quickly find person, assuming
person moves (stochastically) according fixed policy. spatial configuration
environment used throughout experiment illustrated Figure 7.
state space described cross-product two position features, Robot =
{s0 , . . . , s29 } Person = {s0 , . . . , s29 , sf ound }. start independently-selected random
positions, scenario finishes Person = sf ound . robot select five actions:
{North, South, East, West, Tag}. reward 1 imposed motion action; Tag action
results +10 reward robot person cell, 10 otherwise. Throughout scenario, Robots position fully observable, Move action predictable
deterministic effect, e. g.:
P r(Robot = s10 | Robot = s0 , N orth) = 1,
361

fiP INEAU , G ORDON & HRUN

2.5

0.7
PBVI+GER
QMDP
IncPrune

PBVI+GER
QMDP
IncPrune

0.6

2

1.5

REWARD

REWARD

0.5

1

0.4
0.3
0.2

0.5
0.1
0 2
10

1

0

10

1

2

10
10
TIME (secs)

0 2
10

3

10

10

1

0

10

1

10
10
TIME (secs)

(a) Tiger-grid

2

10

3

10

(b) Hallway

0.45
0.4

PBVI+GER
QMDP
IncPrune

0.35

REWARD

0.3
0.25
0.2
0.15
0.1
0.05
0 2
10

1

0

10

1

10
TIME (secs)

2

10

10

(c) Hallway2

Figure 6: PBVI performance well-known POMDP problems. figure shows sum
discounted reward function computation time different problem domain.

26

27

28

23

24

25

20

21

22

10

11

12

13

14

15

16

17

18

19

0

1

2

3

4

5

6

7

8

9

Figure 7: Spatial configuration domain

362

fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDP

adjacent cell direction. position person, hand,
completely unobservable unless agents cell. Meanwhile step,
person (with omniscient knowledge) moves away robot P r = 0.8 stays place
P r = 0.2, e. g.:
P r(P erson = s16 | P erson = s15 &Robot = s0 ) = 0.4
P r(P erson = s20 | P erson = s15 &Robot = s0 ) = 0.4
P r(P erson = s15 | P erson = s15 &Robot = s0 ) = 0.2.
Figure 8 shows performance PBVI Greedy Error Reduction Tag domain. Results averaged 1000 runs, using different (randomly chosen) start positions run.
QMDP approximation also tested provide baseline comparison. results show gradual improvement PBVIs performance samples added (each shown data point represents
new expansion belief set value backups). also confirms computation time directly related number belief points. PBVI requires fewer 100 belief points overcome
QMDP, performance keeps improving points added. Performance appears
converging approximately 250 belief points. results show PBVI-class algorithm
effectively tackle problem 870 states.
6
PBVI+GER
QMDP
8

REWARD

10
12
14
16
18
20 0
10

1

10

2

3

10
10
TIME (secs)

4

10

5

10

Figure 8: PBVI performance Tag problem. show sum discounted reward function
computation time.

problem far beyond reach Incremental Pruning algorithm. single iteration
optimal value iteration problem size could produce 1020 -vectors pruning.
Therefore, applied.
section describes one version Tag problem, used simulation purposes
work others (Braziunas & Boutilier, 2004; Poupart & Boutilier, 2004; Smith &
Simmons, 2004; Vlassis & Spaan, 2004). fact, problem re-formulated variety
ways accommodate different environments, person motion models, observation models.
Section 7 discusses variations problem using realistic robot person models,
presents results validated onboard independently developed robot simulator.
363

fiP INEAU , G ORDON & HRUN

6.3 Empirical Comparison PBVI-Class Algorithms
establish good performance PBVI+GER number problems, consider
empirical results different PBVI-class algorithms. allows us compare effects
various belief expansion heuristics. repeat experiments Tiger-grid, Hallway,
Hallway2 Tag domains, outlined above, case compare performance five
different PBVI-class algorithms:
1. PBVI+RA: PBVI belief points selected randomly belief simplex (Section 4.1).
2. PBVI+SSRA: PBVI belief points selected using stochastic simulation random action (Section 4.2).
3. PBVI+SSGA: PBVI belief points selected using stochastic simulation greedy action
(Section 4.3).
4. PBVI+SSEA: PBVI belief points selected using stochastic simulation exploratory
action (Section 4.4).
5. PBVI+GER: PBVI belief points selected using greedy error reduction (Section 4.5).
PBVI-class algorithms converge optimal value function given sufficiently large
set belief points. rate converge depends ability generally pick
useful points, leave points containing less information. Since computation time
directly proportional number belief points, algorithm best performance
generally one find good solution fewest belief points.
Figure 9 shows comparison performance five PBVI-class algorithms
enumerated four problem domains. pictures, present performance
results function computation time.5
seen results, smallest domainTiger-gridPBVI+GER similar performance random approach PBVI+RA. Hallway domain, PBVI+GER reaches nearoptimal performance earlier algorithms. Hallway2, unclear five
algorithms best, though GER seems converge earlier.
larger Tag domain, situation interesting. PBVI+GER combination
clearly superior others. reason believe PBVI+SSEA could match performance, would require order twice many points so. Nonetheless, PBVI+SSEA
performs better either PBVI+SSRA PBVI+SSGA. random heuristic (PBVI+RA),
reward improve regardless many belief points added (4000+), therefore include results. results presented Figure 9 suggest choice
belief points crucial dealing large problems. general, believe GER (and
SSEA lesser degree) superior heuristics solving domains large numbers
action/observation pairs, ability selectively chooses branches
reachability tree explore.
side note, surprised SSGAs poor performance (in comparison SSRA)
Tiger-grid Tag domains. could due poorly tuned greedy bias ,
5. Nearly identical graphs produced showing performance results function number belief points.
confirms complexity analysis showing computation time directly related number belief
points.

364

fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDP

2.5

0.7
RA
SSRA
SSGA
SSEA
GER

0.5

1.5

REWARD

REWARD

2

0.6

1

RA
SSRA
SSGA
SSEA
GER

0.4
0.3
0.2

0.5
0.1
0 2
10

1

0

10

1

10
10
TIME (secs)

2

10

0 2
10

3

10

1

10

(a) Tiger-grid

0

1

10
TIME (secs)

2

10

10

(b) Hallway
6

0.45

REWARD

0.3

8

SSRA
SSGA
SSEA
GER

10
REWARD

0.4
0.35

RA
SSRA
SSGA
SSEA
GER

0.25
0.2
0.15

12
14
16

0.1
18

0.05
0 2
10

1

10

0

10
TIME (secs)

1

10

20 0
10

2

10

(c) Hallway2

1

10

2

3

10
10
TIME (secs)

4

10

5

10

(d) Tag

Figure 9: Belief expansion results showing execution performance function computation
time.

investigate length. Future investigations using problems larger number actions may
shed better light issue.
terms computational requirement, GER expensive compute, followed
SSEA. However cases, time perform belief expansion step generally negligible
(< 1%) compared cost value update steps. Therefore seems best use
effective (though expensive) heuristic.
PBVI framework accommodate wide variety strategies, past described
paper. example, one could extract belief points directly sampled experimental traces.
subject future investigations.
6.4 Comparative Analysis
results outlined show PBVI-type algorithms able handle wide spectrum
large-scale POMDP domains, sufficient compare performance PBVI
365

fiP INEAU , G ORDON & HRUN

QMDP Incremental Pruningthe two ends spectrumas done Section 6.1. fact
significant activity recent years development fast approximate POMDP
algorithms, worthwhile spend time comparing PBVI framework
alternative approaches. made easy fact many validated using
set problems described above.
Table 8 summarizes performance large number recent POMDP approximation algorithms, including PBVI, four target domains: Tiger-grid, Hallway, Hallway2, Tag.
algorithms listed selected based availability comparable published results available
code, cases algorithm could re-implemented easily.
compare empirical performance, terms execution performance versus planning,
set simulation domains. However often case, results show
single algorithm best solving problems. therefore also compile summary
attributes characteristics algorithm, attempt tell algorithm may best
types problems. Table 8 includes (whenever possible) goal completion rates, sum
rewards, policy computation time, number required belief points, policy size (number
-vectors, number nodes finite state controllers). number belief points policy
size often identical, however latter smaller single -vector best multiple
belief points.
results marked [*] computed us 3GHz Pentium 4; results likely
computed different platforms, therefore time comparisons may approximate best.
Nonetheless number samples size final policy useful indicators
computation time. results reported PBVI correspond earliest data point Figures 6 8 PBVI+GER achieves top performance.
Algorithms listed order performance, starting algorithm(s) achieving highest reward. results assume standard (not lookahead) controller (see Hauskrecht, 2000,
definition).
Overall, results indicate algorithms achieve sub-par performance terms
expected reward. case QMDP, fundamental limitations algorithm.
Incremental Pruning exact value-directed compression theoretically reach optimal
performance, would require longer computation time so. grid method (see Tiger-grid
results), BPI (see Tiger-grid, Hallway Tag results) PBUA (see Tag results) suffer
similar problem, offer much graceful performance degradation. worth noting none
approaches assumes known initial belief, effect solving harder problems.
results BBSLS sufficiently extensive comment length, appears able
find reasonable policies small controllers (see Tag results).
remaining algorithmsHSVI, Perseus, PBVI+GERall offer comparable
performance relatively large POMDP domains. HSVI seems offer good control performance full range tasks, requires bigger controllers, therefore probably slower,
especially domains high stochasticity (e.g., Tiger-grid, Hallway, Hallway2). trade-offs
Perseus PBVI+GER less clear: planning time, controller size performance
quality quite comparable, fact two approaches similar. Similarities
differences two approaches explored Section 7.

366

fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDP

Method
Tiger-Grid (Maze33)
HSVI (Smith & Simmons, 2004)
Perseus (Vlassis & Spaan, 2004)
PBUA (Poon, 2001)
PBVI+GER[*]
BPI (Poupart & Boutilier, 2004)
Grid (Brafman, 1997)
QMDP (Littman et al., 1995b)[*]
IncPrune (Cassandra et al., 1997)[*]
Exact VDC (Poupart & Boutilier, 2003)[*]
Hallway
PBUA (Poon, 2001)
HSVI (Smith & Simmons, 2004)
PBVI+GER[*]
Perseus (Vlassis & Spaan, 2004)
BPI (Poupart & Boutilier, 2004)
QMDP (Littman et al., 1995b)[*]
Exact VDC (Poupart & Boutilier, 2003)[*]
IncPrune (Cassandra et al., 1997)[*]
Hallway2
PBVI+GER[*]
Perseus (Vlassis & Spaan, 2004)
HSVI (Smith & Simmons, 2004)
PBUA (Poon, 2001)
BPI (Poupart & Boutilier, 2004)
Grid (Brafman, 1997)
QMDP (Littman et al., 1995b)[*]
Exact VDC (Poupart & Boutilier, 2003)[*]
IncPrune (Cassandra et al., 1997)[*]
Tag
HSVI (Smith & Simmons, 2004)
PBVI+GER[*]
Perseus (Vlassis & Spaan, 2004)
BBSLS (Braziunas & Boutilier, 2004)
BPI (Poupart & Boutilier, 2004)
QMDP (Littman et al., 1995b)[*]
PBUA (Poon, 2001)[*]
IncPrune (Cassandra et al., 1997)[*]

Goal%

Reward Conf.Int.

Time(s)

|B|

||

n.a.
n.a.
n.a.
n.a.
n.a.
n.a.
n.a.
n.a.
n.a.

2.35
2.34
2.30
2.27 0.13
1.81
0.94
0.276
0.0
0.0

10341
104
12116
397
163420
n.v.
0.02
24hrs+
24hrs+

n.v.
10000
660
512
n.a.
174
n.a.
n.a.
n.a.

4860
134
n.v.
508
1500
n.a.
5
n.v.
n.v.

100
100
100
n.v.
n.v.
51
39
39

0.53
0.52
0.51 0.03
0.51
0.51
0.265
0.161
0.161

450
10836
19
35
249730
0.03
24hrs+
24hrs+

300
n.v.
64
10000
n.a.
n.a.
n.a.
n.a.

n.v.
1341
64
55
1500
5
n.v.
n.v.

100
n.v.
100
100
n.v.
98
22
48
48

0.37 0.04
0.35
0.35
0.35
0.28
n.v.
0.109
0.137
0.137

6
10
10010
27898
274280
n.v.
1.44
24hrs+
24hrs+

32
10000
n.v.
1840
n.a.
337
n.a.
n.a.
n.a.

31
56
1571
n.v.
1500
n.a.
5
n.v.
n.v.

100
100
n.v.
n.v.
n.v.
19
0
0

-6.37
-6.75 0.39
-6.85
-8.31
-9.18
-16.62
-19.9
-19.9

10113
8946
3076
100054
59772
1.33
24hrs+
24hrs+

n.v.
256
10000
n.a.
n.a.
n.a.
4096
n.a.

1657
203
205
30
940
5
n.v.
n.v.

n.a.=not applicable

n.v.=not available

[*]=results computed us

Table 8: Results PBVI standard POMDP domains

367

fiP INEAU , G ORDON & HRUN

6.5 Error Estimates
results presented thus far suggest PBVI framework performs best using
Greedy Error Reduction (GER) technique selecting belief points. scheme, decide belief points included, estimate error bound set candidate points
pick one largest error estimate. error bound estimated described
Equation 28. consider question estimate evolves points
added. natural intuition first points, error estimates large,
density belief set increases, error estimates become much smaller.
Figure 10 reconsiders four target domains: Tiger-grid, Hallway, Hallway2 Tag.
case, present reward performance function number belief points (top
row graphs), error estimate point selected according order points
picked (bottom row graphs). addition, bottom graphs also show (in dashed line) trivial
Rmin
bound error ||Vt Vt || Rmax1
, valid t-step value function arbitrary
policy. expected, bound typically tighter trivial bound. Tag, occurs
number belief points exceeds number states, surprising, given
bound depends distance reachable beliefs, states reachable beliefs
domain. Overall, seems reasonably good correspondence improvement
performance decrease error estimates. conclude figure even
though PBVI error quite loose, fact informative guiding exploration belief
simplex.
note significant variance error estimates one belief point next,
illustrated non-monotonic behavior curves bottom graphs Figure 10.
behavior attributed possibilities. First, fact error estimate
given belief approximate. value function used calculate error estimate
approximate. addition, fact new belief points always selected
envelope reachable beliefs, set reachable beliefs. suggests GER could
improved maintaining deeper envelope candidate belief points. Currently envelope
contains points 1-step forward simulations points already selected. may
useful consider points 23 steps ahead. predict would reduce jaggedness seen
Figure 10, importantly, also reduce number points necessary good performance.
course, tradeoff time spent selecting points time spent planning would
re-evaluated light.

7. Robotic Applications
overall motivation behind work described paper desire provide high-quality
robust planning real-world autonomous systems, particular robots. practical side, search robust robot controller large part guided Nursebot
project (Pineau, Montermerlo, Pollack, Roy, & Thrun, 2003). overall goal project
develop personalized robotic technology play active role providing improved care
services non-institutionalized elderly people. Pearl, shown Figure 11, main robotic
platform used project.
many services nursing-assistant robot could provide (Engelberger, 1999; Lacey
& Dawson-Howe, 1998), much work date focused providing timely cognitive reminders (e.g., medications take, appointments attend, etc.) elderly subjects (Pollack, 2002).
368

fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDP

Tigergrid

Hallway

2.5

Reward

2

Hallway2

0.8

0.4

0.6

0.3

0.4

0.2

0.2

0.1

Tag
5

10

1.5
1

15

0.5
0
0
10

1

10

2

10

3

10

0
0
10

# belief points
60

1

10

2

10

0
0
10

3

10

# belief points

1

10

2

10

20

20

Error

2

10

3

10

# belief points

400

15
40

15

300

10

20

200

10
5

100

10
0
0
10

1

10

500

50

30

20
3
0
10 10

# belief points

1

10

2

10

# belief points

0
3
0
10 10

1

10

2

10

3

10

# belief points

5
0
10

1

10

2

10

# belief points

3

10

0
0
10

1

10

2

10

3

10

# belief points

Figure 10: Sum discounted reward (top graphs) estimate bound error (bottom
graphs) function number selected belief points.

Figure 11: Pearl Nursebot, interacting elderly people nursing facility
important component task finding patient whenever time issue reminder.
task shares many similarities Tag problem presented Section 6.2. case,
however, robot-generated map real physical environment used basis spatial
configuration domain. map shown Figure 12. white areas correspond free
space, black lines indicate walls (or obstacles) dark gray areas visible
accessible robot. One easily imagine patients room physiotherapy unit lying
either end corridor, common area shown upper-middle section.
overall goal robot traverse domain order find missing patient
deliver message. robot must systematically explore environment, reasoning
spatial coverage human motion patterns, order find person.
369

fiP INEAU , G ORDON & HRUN

Figure 12: Map environment
7.1 POMDP Modeling
problem domain represented jointly two state features: RobotPosition, PersonPosition.
feature expressed discretization environment. experiments
assume discretization 2 meters, means 26 discrete cells feature, total
676 states.
assumed person robot move freely throughout space. robots
motion deterministically controlled choice action (North, South, East, West). robot
fifth action (DeliverMessage), concludes scenario used appropriately (i.e.,
robot person location).
persons motion stochastic falls one two modes. Part time, person
moves according Brownian motion (e.g., moves cardinal direction P r = 0.1, otherwise stays put). times, person moves directly away robot. Tag domain
Section 6.2 assumes person always moves always moves away robot. realistic person cannot see robot. current experiment instead assumes person
moves according Brownian motion robot far away, moves away robot
closer (e.g., < 4m). person policy designed way encourage robot
find robust policy.
terms state observability, two components: robot sense
position, sense persons position. first case, assumption
robot knows position times. may seem like generous (or
optimistic) assumption, substantial experience domains size maps quality
demonstrated robust localization abilities (Thrun et al., 2000). especially true
planning operates relatively coarse resolution (2 meters) compared localization precision
(10 cm). exact position information assumed planning domain, execution
phase (during actually measure performance) update belief using full localization
information, includes positional uncertainty whenever appropriate.
Regarding detection person, assumption robot knowledge
persons position unless s/he within range 2 meters. plausible given robots
sensors. However, even short-range, small probability (P r = 0.01) robot
miss person therefore return false negative.
general, one could make sensible assumptions persons likely position (e.g., based
knowledge daily activities), however currently information therefore assume uniform distribution initial positions. persons subsequent movements
370

fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDP

expressed motion model described (i.e., mix Brownian motion purposeful avoidance).
reward function straightforward: R = 1 motion action, R = 10
robot decides DeliverMessage cell person, R = 100
robot decides DeliverMessage persons absence. task terminates robot
successfully delivers message (i.e., = DeliverM essage srobot = sperson ). assume
discount factor 0.95.
assume known initial belief, b0 , consisting uniform distribution states.
used selecting belief points planning, subsequently executing testing
final policy.
initial map (Fig. 12) domain collected mobile robot, slightly cleaned
hand remove artifacts (e.g., people walking by). assumed model parameters
described here, applied PBVI planning problem such. Value updates belief point
expansions applied alternation (in simulation) policy able find person
99% trials (trials terminated person found 100 execution steps).
final policy implemented tested onboard publicly available CARMEN robot simulator (Montemerlo, Roy, & Thrun, 2003).
7.2 Comparative Evaluation PBVI Perseus
subtask described here, 626 states, beyond capabilities exact POMDP solvers.
Furthermore, demonstrated below, MDP-type approximations equipped handle
uncertainty type exhibited task. main purpose analysis evaluate
effectiveness point-based approach described paper address problem.
results Tag domain (Section 6.2) hint fact PBVI algorithms may able
handle task, realistic map modified motion model provide new challenges.
begin investigation directly comparing performance PBVI (with GER belief points selection) Perseus algorithm complex robot domain. Perseus
described Section 5; results presented produced using code provided authors (Perseus, 2004). Results algorithms assume fixed POMDP model generated
robot simulator. model stored solved offline algorithm.
PBVI Perseus parameters set. PBVI requires: number new belief
points add expansion (Badd ) planning horizon expansion (H). Perseus
requires: number belief points generate random walk (B) maximum planning
time (T ). Results presented assume following parameter settings: Badd = 30, H = 25,
B=10,000, =1500. algorithms fairly robust changes parameters.6
Figure 13 summarizes results experiment. suggest number observations.
shown Figure 13(a), algorithms find best solution similar time,
PBVI+GER better anytime performance Perseus (e.g., much better policy found
given 100 sec).
shown Figure 13(b), algorithms require similar number -vectors.
shown Figure 13(c), PBVI+GER requires many fewer beliefs.
6. 25% change parameter value yielded sensibly similar results terms reward number vectors,
though course time, memory, number beliefs varied.

371

fiP INEAU , G ORDON & HRUN

5
10

120
PBVI+GER
GER
Perseus
QMDP

PBVI+GER
Perseus
100

15
# alpha vectors

REWARD

20
25
30
35

80
60
40

40
20
45
50 1
10

0

1

10

2

3

10
10
TIME (secs)

10

0 0
10

4

10

1

10

5

10

PBVI+GER
Perseus
4

10

# beliefs

3

10

2

10

1

10

0

10 0
10

1

10

2

10
TIME (secs)

3

10

4

10

(b)
Memory requirement = (#alphas + #beliefs)*#states

(a)

2

10
TIME (secs)

3

10

4

10

(c)

8

10

PBVI+GER
Perseus
7

10

6

10

5

10

4

10

0

10

1

10

2

10
TIME (secs)

3

10

4

10

(d)

Figure 13: Comparison PBVI Perseus robot simulation domain
requires fewer beliefs, PBVI+GER much lower memory requirements;
quantified Figure 13(d).
new results suggest PBVI Perseus similar performance objective
find near-optimal solution, time memory constrained. cases one willing
trade accuracy time, PBVI may provide superior anytime performance. cases
memory limited, PBVIs conservative approach respect belief point selection
advantageous. properties suggest PBVI may scale better large domains.
7.3 Experimental Results Robot Simulator
results presented assume POMDP model used planning testing (i.e., compute reward Figure 13(a)). useful carry large number
experiments. model however cannot entirely capture dynamics realistic robot system,
therefore concern policy learned point-based methods perform
well realistic robot. verify robustness approach, final PBVI control policy
implemented tested onboard publicly available CARMEN robot simulator (Montemerlo
et al., 2003).
372

fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDP

resulting policy illustrated Figure 14. figure shows five snapshots obtained
single run. particular scenario, person starts far end left corridor.
persons location shown figures since observable robot.
figure instead shows belief person positions, represented distribution point samples
(grey dots Fig. 14). point represents plausible hypothesis persons position.
figure shows robot starting far right end corridor (Fig. 14a). robot moves toward
left rooms entrance (Fig. 14b). proceeds check entire room (Fig. 14c).
relatively certain person nowhere found, exits room (Fig. 14d),
moves left branch corridor, finally finds person end
corridor (Fig. 14e).
policy optimized start position (for person robot). scenario
shown Figure 14 one longer execution traces since robot ends searching entire
environment finding person. interesting compare choice action
snapshots (b) (d). robot position practically identical. Yet (b) robot chooses
go room, whereas (d) robot chooses move toward left. direct
result planning beliefs, rather states. belief distribution person positions
clearly different two cases, therefore policy specifies different course
action.
Figure 15 looks policy obtained solving problem using QMDP heuristic. Four snapshots offered different stages specific scenario, assuming person
started far left side robot far right side (Fig. 15a). proceeding
room entrance (Fig. 15b), robot continues corridor almost reaches end
(Fig. 15c). turns around comes back toward room entrance, stations
(Fig. 15d) scenario forcibly terminated. result, robot cannot find person
s/he left edge corridor room. Whats more, runningaway behavior adopted subject, even person starts elsewhere corridor,
robot approaches person gradually retreat left similarly escape robot.
Even though QMDP explicitly plan beliefs, generate different policy actions
cases state identical belief different. seen comparing Figure 15 (b) (d). these, robot identically located, however belief person
positions different. (b), probability mass left robot, therefore travels direction. (d), probability mass distributed evenly three branches
(left corridor, room, right corridor). robot equally pulled directions therefore stops
there. scenario illustrates strength QMDP. Namely, many cases
necessary explicitly reduce uncertainty. However, also shows sophisticated
approaches needed handle cases.
results show PBVI perform outside bounds simple maze domains,
able handle realistic problem domains. particular, throughout evaluation, robot
simulator way constrained behave described POMDP model (Sec. 7.1).
means robots actions often stochastic effects, robots position always
fully observable, belief tracking performed asynchronously (i.e., always
straightforward ordering actions observations). Despite misalignment model
assumed planning, execution environment, control policy optimized PBVI could
successfully used complete task.

373

fiP INEAU , G ORDON & HRUN

(a) t=1

(b) t=7

(c) t=12

(d) t=17

(e) t=29
Figure 14: Example PBVI policy successfully finding person

374

fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDP

(a) t=1

(b) t=7

(c) t=17

(d) t=27
Figure 15: Example QMDP policy failing find person

375

fiP INEAU , G ORDON & HRUN

8. Discussion
paper describes class anytime point-based POMDP algorithms called PBVI, combines point-based value updates strategic selection belief points, solve large POMDPs.
extensions PBVI framework, whereby value updates applied groups belief
points according spatial distribution, described (Pineau, Gordon, & Thrun, 2004).
main contributions pertaining PBVI framework summarized.
Scalability. PBVI framework important step towards truly scalable POMDP solutions.
achieved bounding policy size selection small set belief points.
Anytime planning. PBVI-class algorithms alternates steps value updating steps
belief point selection. new points added, solution improves, expense increased
computational time. trade-off controlled adjusting number points. algorithm terminated either satisfactory solution found, planning time
elapsed.
Bounded error. provide theoretical bound error approximation introduced
PBVI framework. result holds range belief point selection methods, lead
directly development new PBVI-type algorithm: PBVI+GER, estimates
error bound used directly select belief points. Furthermore find bounds
useful assessing stop adding belief points.
Exploration. proposed set new point selection heuristics, explore tree
reachable beliefs select useful belief points. successful technique described, Greedy
Error Reduction (GER), uses estimate error bound candidate belief points select
useful points.
Improved empirical performance. PBVI demonstrated ability reduce planning time
number well-known POMDP problems, including Tiger-grid, Hallway, Hallway2.
operating set discrete points, PBVI algorithms perform polynomial-time value updates,
thereby overcoming curse history paralyzes exact algorithms. GER technique used
select points allows us solve large problems fewer belief points alternative approaches.
New problem domain. PBVI applied new POMDP planning domain (Tag),
generated approximate solution outperformed baseline algorithms QMDP Incremental
Pruning. new domain since adopted test case algorithms (Vlassis &
Spaan, 2004; Smith & Simmons, 2004; Braziunas & Boutilier, 2004; Poupart & Boutilier, 2004).
fosters increased ease comparison new techniques. comparative analysis
provided Section 7.2 highlighting similarities differences PBVI Perseus.
Demonstrated performance. PBVI applied context robotic search-and-rescue
type scenario, mobile robot required search environment find non-stationary
individual. PBVIs performance evaluated using realistic, independently-developed, robot
simulator.
significant portion paper dedicated thorough comparative analysis point-based
methods. includes evaluating range point-based selection methods, well evaluating
mechanisms ordering value updates. comparison point-based selection techniques suggest GER method presented Section 4.5 superior naive techniques. terms
ordering value updates, randomized strategy used Perseus algorithm appears
effective accelerate planning. natural next step would combine GER belief selection
heuristic Perseuss random value updates. performed experiments along lines,
376

fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDP

achieve significant speed-up current performance PBVI Perseus (e.g.,
reported Figure 13(a)). likely belief points chosen carefully (as GER),
points needs updated systematically therefore additional benefit
using randomized value updates.
Looking towards future, important remember demonstrated
ability solve problems large POMDP standards, many real-world domains far exceed
complex domains considered paper. particular, unusual problem
expressed number multi-valued state features, case number states grows
exponentially number features. concern belief point
-vector dimensionality |S| (where |S| number states) dimensions updated
simultaneously. important issue address improve scalability point-based value
approaches general.
various existing attempts overcoming curse dimensionality POMDPs.
thesee. g. belief compression techniques Roy Gordon (2003)cannot
incorporated within PBVI framework without compromising theoretical properties (as discussed Section 3). Others, particular exact compression algorithm Poupart Boutilier
(2003), combined PBVI. However, preliminary experiments direction
yielded little performance improvement. reason believe approximate value compression would yield better results, expense forgoing PBVIs theoretical properties. challenge therefore devise function-approximation techniques reduce
dimensionality effectively, maintaining convexity properties solution.
secondary (but less important) issue concerning scalability PBVI pertains
number belief points necessary obtain good solution. problems addressed thus far
usually solved O(|S|) belief points, need true. worse case, number
belief points necessary may exponential plan length. PBVI framework accommodate wide variety strategies generating belief points, Greedy Error Reduction
technique seems particularly effective. However unlikely definitive answer belief
point selection. general terms, relates closely well-known issue exploration
versus exploitation, arises across wide array problem-solving techniques.
promising opportunities future research aside, PBVI framework already
pushed envelope POMDP problems solved existing computational resources.
field POMDPs matures, finding ways computing policies efficiently likely continue
major bottleneck. hope point based algorithms PBVI play leading
role search efficient algorithms.

Acknowledgments
authors wish thank Craig Boutilier, Michael Littman, Andrew Moore Matthew Mason
many thoughtful comments discussions regarding work. also thank Darius Braziunas,
Pascal Poupart, Trey Smith Nikos Vlassis, conversations regarding algorithms
results. contributions Michael Montemerlo Nicholas Roy conducting empirical
robot evaluations gratefully acknowledged. Finally, thank three anonymous reviewers
one dedicated editor (Sridhar Mahadevan) whose feedback significantly improved paper.
work funded DARPA MARS program NSFs ITR program (Project: Robotic
Assistants Elderly, PI: J. Dunbar-Jacob).
377

fiP INEAU , G ORDON & HRUN

References
Astrom, K. J. (1965). Optimal control markov decision processes incomplete state estimation. Journal Mathematical Analysis Applications, 10, 174205.
Bellman, R. (1957). Dynamic Programming. Princeton University Press.
Bertsekas, D. P., & Tsitsiklis, J. (1996). Neuro-Dynamic Programming. Athena Scientific.
Blum, A. L., & Furst, M. L. (1997). Fast planning planning graph analysis. Artificial
Intelligence, 90(1-2), 281300.
Bonet, B. (2002). epsilon-optimal grid-based algorithm partially obserable Markov decision
processes. Machine Learning: Proceedings 2002 International Conference (ICML),
pp. 5158.
Boutilier, C., Dean, T., & Hanks, S. (1999). Decision-theoretic planning: Structural assumptions
computational leverage. Journal Artificial Intelligence Research, 11, 194.
Boyen, X., & Koller, D. (1998). Tractable inference complex stochastic processes. Proceedings Fourteenth Conference Uncertainty Artificial Intelligence (UAI), pp. 3342.
Brafman, R. I. (1997). heuristic variable grid solution method POMDPs. Proceedings
Fourteenth National Conference Artificial Intelligence (AAAI), pp. 727733.
Braziunas, D., & Boutilier, C. (2004). Stochastic local search POMDP controllers. Proceedings Nineteenth National Conference Artificial Intelligence (AAAI), pp. 690696.
Burgard, W., Cremers, A. B., Fox, D., Hahnel, D., Lakemeyer, G., Schulz, D., Steiner, W., & Thrun,
S. (1999). Experiences interactive museum tour-guide robot. Artificial Intelligence,
114, 355.
Cassandra, A. (1999).
Tonys
research/ai/pomdp/code/index.html.

POMDP

page.

http://www.cs.brown.edu/

Cassandra, A., Littman, M. L., & Zhang, N. L. (1997). Incremental pruning: simple, fast, exact
method partially observable Markov decision processes. Proceedings Thirteenth
Conference Uncertainty Artificial Intelligence (UAI), pp. 5461.
Chapman, D. (1987). Planning conjunctive goals. Artificial Intelligence, 32(3), 333377.
Cheng, H.-T. (1988). Algorithms Partially Observable Markov Decision Processes. Ph.D. thesis,
University British Columbia.
Dean, T., & Kanazawa, K. (1988). Probabilistic temporal reasoning. Proceedings Seventh
National Conference Artificial Intelligence (AAAI), pp. 524528.
Devroye, L. (1986). Non-Uniform Random Variate Generation. Springer-Verlag, New York.
Engelberger, G. (1999). Handbook Industrial Robotics. John Wiley Sons.
Fikes, R. E., & Nilsson, N. J. (1971). STRIPS: new approach application theorem
proving problem solving. Artificial Intelligence, 2, 189208.
Hauskrecht, M. (1997). Incremental methods computing bounds partially observable Markov
decision processes. Proceedings Fourteenth National Conference Artificial Intelligence (AAAI), pp. 734739.
378

fiA NYTIME P OINT-BASED PPROXIMATIONS L ARGE POMDP

Hauskrecht, M. (2000). Value-function approximations partially observable Markov decision
processes. Journal Artificial Intelligence Research, 13, 3394.
Jazwinski, A. M. (1970). Stochastic Processes Filtering Theory. Academic, New York.
Kaelbling, L. P., Littman, M. L., & Cassandra, A. R. (1998). Planning acting partially
observable stochastic domains. Artificial Intelligence, 101, 99134.
Kalman, R. E. (1960). new approach linear filtering prediction problems. Transactions
ASME, Journal Basic Engineering, 82, 3545.
Lacey, G., & Dawson-Howe, K. M. (1998). application robotics mobility aid
elderly blind. Robotics Autonomous Systems, 23, 245252.
Littman, M. L. (1996). Algorithms Sequential Decision Making. Ph.D. thesis, Brown University.
Littman, M. L., Cassandra, A. R., & Kaelbling, L. P. (1995a). Learning policies partially obsevable environments: Scaling up. Tech. rep. CS-95-11, Brown University, Department
Computer Science.
Littman, M. L., Cassandra, A. R., & Kaelbling, L. P. (1995b). Learning policies partially obsevable environments: Scaling up. Proceedings Twelfth International Conference
Machine Learning, pp. 362370.
Lovejoy, W. S. (1991a). Computationally feasible bounds partially observed Markov decision
processes. Operations Research, 39(1), 162175.
Lovejoy, W. S. (1991b). survey algorithmic methods partially observable Markov decision
processes. Annals Operations Research, 28, 4766.
McAllester, D., & Roseblitt, D. (1991). Systematic nonlinear planning. Proceedings Ninth
National Conference Artificial Intelligence (AAAI), pp. 634639.
Monahan, G. E. (1982). survey partially observable Markov decision processes: Theory, models, algorithms. Management Science, 28(1), 116.
Montemerlo, M., Roy, N., & Thrun, S. (2003). Perspectives standardization mobile robot
programming: Carnegie Mellon navigation (CARMEN) toolkit. Proceedings
IEEE/RSJ International Conference Intelligent Robots Systems (IROS), Vol. 3, pp. pp
24362441.
Paquet, S. (2005). Distributed Decision-Making Task Coordination Dynamic, Uncertain
Real-Time Multiagent Environments. Ph.D. thesis, Universite Laval.
Penberthy, J. S., & Weld, D. (1992). UCPOP: sound, complete, partial order planning ADL.
Proceedings Third International Conference Knowledge Representation Reasoning, pp. 103114.
Perseus (2004) http://staff.science.uva.nl/mtjspaan/software/approx.
Pineau, J., Gordon, G., & Thrun, S. (2004). Applying metric-trees belief-point POMDPs.
Neural Information Processing Systems (NIPS), Vol. 16.
Pineau, J., Montermerlo, M., Pollack, M., Roy, N., & Thrun, S. (2003). Towards robotic assistants
nursing homes: challenges results. Robotics Autonomous Systems, 42(3-4), 271281.
Pollack, M. (2002). Planning technology intelligent cognifitve orthotics. Proceedings
6th International Conference AI Planning & Scheduling (AIPS).
379

fiP INEAU , G ORDON & HRUN

Poon, K.-M. (2001). fast heuristic algorithm decision-theoretic planning. Masters thesis,
Hong-Kong University Science Technology.
Poupart, P., & Boutilier, C. (2000). Value-directed belief state approximation POMDPs.
Proceedings Sixteenth Conference Uncertainty Artificial Intelligence (UAI), pp.
409416.
Poupart, P., & Boutilier, C. (2003). Value-directed compression POMDPs. Advances Neural
Information Processing Systems (NIPS), Vol. 15.
Poupart, P., & Boutilier, C. (2004). Bounded finite state controllers. Advances Neural Information Processing Systems (NIPS), Vol. 16.
Rabiner, L. R. (1989). tutorial hidden Markov models selected applications speech
recognition. Proceedings IEEE, 77(2), 257285.
Rosencrantz, M., Gordon, G., & Thrun, S. (2003). Locating moving entities dynamic indoor
environments teams mobile robots. Second International Joint Conference
Autonomous Agents MultiAgent Systems (AAMAS), pp. 233240.
Roy, N., & Gordon, G. (2003). Exponential family PCA belief compression POMDPs.
Advances Neural Information Processing Systems (NIPS), Vol. 15, pp. 10431049.
Smith, T., & Simmons, R. (2004). Heuristic search value iteration POMDPs. Proceedings
Twentieth Conference Uncertainty Artificial Intelligence (UAI).
Sondik, E. J. (1971). Optimal Control Partially Observable Markov Processes. Ph.D. thesis,
Stanford University.
Spaan, M., & Vlassis, N. (2005). Perseus: Randomized point-based value iteration POMDPs.
Journal Artificial Intelligence Research (JAIR), 195220.
Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MIT Press.
Thrun, S., Fox, D., Burgard, W., & Dellaert, F. (2000). Robust Monte Carlo localization mobile
robots. Artificial Intelligence, 128(1-2), 99141.
Vlassis, N., & Spaan, M. T. J. (2004). fast point-based algorithm POMDPs. Proceedings
Belgian-Dutch Conference Machine Learning.
White, C. C. (1991). survey solution techniques partially observed Markov decision
process. Annals Operations Research, 32, 215230.
Zhang, N. L., & Liu, W. (1996). Planning stochastic domains: Problem characteristics approximation. Tech. rep. HKUST-CS96-31, Dept. Computer Science, Hong Kong University Science Technology.
Zhang, N. L., & Zhang, W. (2001). Speeding convergence value iteration partially
observable Markov decision processes. Journal Artificial Intelligence Research, 14, 29
51.
Zhou, R., & Hansen, E. A. (2001). improved grid-based approximation algorithm POMDPs.
Proceedings 17th International Joint Conference Artificial Intelligence (IJCAI),
pp. 707716.

380

fiJournal Artificial Intelligence Research 27 (2006) 203-233

Submitted 01/06; published 10/06

Active Learning Multiple Views
Ion Muslea

imuslea@languageweaver.com

Language Weaver, Inc.
4640 Admiralty Way, Suite 1210
Marina del Rey, CA 90292

Steven Minton

minton@fetch.com

Fetch Technologies, Inc.
2041 Rosecrans Ave., Suite 245
El Segundo, CA 90245

Craig A. Knoblock

knoblock@isi.edu

University Southern California
4676 Admiralty Way
Marina del Rey, CA 90292

Abstract
Active learners alleviate burden labeling large amounts data detecting
asking user label informative examples domain. focus
active learning multi-view domains, several disjoint subsets
features (views), sufficient learn target concept. paper
make several contributions. First, introduce Co-Testing, first approach
multi-view active learning. Second, extend multi-view learning framework
also exploiting weak views, adequate learning concept
general/specific target concept. Finally, empirically show Co-Testing
outperforms existing active learners variety real world domains wrapper
induction, Web page classification, advertisement removal, discourse tree parsing.

1. Introduction
Labeling training data machine learning algorithm tedious, time consuming,
error prone process; furthermore, application domains, labeling example
may also extremely expensive (e.g., may require running costly laboratory tests).
Active learning algorithms (Cohn, Atlas, & Ladner, 1994; Roy & McCallum, 2001; Tong
& Koller, 2001) cope problem detecting asking user label
informative examples domain, thus reducing users involvement data
labeling process.
paper, introduce Co-Testing, active learning technique multi-view
learning tasks; i.e., tasks several disjoint subsets features (views),
sufficient learn concepts interest. instance, Web page classification
multi-view task Web pages classified based words appear
either documents hyperlinks pointing (Blum & Mitchell, 1998);
similarly, one classify segments televised broadcast based either video
audio information, one perform speech recognition based either sound lip
motion features (de Sa & Ballard, 1998).
c
2006
AI Access Foundation. rights reserved.

fiMuslea, Minton, & Knoblock

Co-Testing two-step iterative algorithm requires input labeled
many unlabeled examples. First, Co-Testing uses labeled examples learn
hypothesis view. applies learned hypotheses unlabeled examples
detects set contention points (i.e., unlabeled examples views predict
different label); finally, queries (i.e., asks user label) one contention
points, adds newly labeled example training set, repeats whole process.
Intuitively, Co-Testing relies following observation: if, unlabeled example,
hypotheses learned view predict different label, least one makes
mistake particular prediction. asking user label contention point,
Co-Testing guaranteed provide useful information view made mistake.
paper make several contributions. First, introduce Co-Testing, family
active learners multi-view learning tasks. Second, extend traditional multi-view
learning framework also allowing use weak views, one adequately learn
concept strictly general specific target concept (all
previous multi-view work makes strong view assumption view adequate
learning target concept). Last least, show that, practice, Co-Testing clearly
outperforms existing active learners variety real world domains wrapper
induction, Web page classification, advertisement removal, discourse tree parsing.
Compared previous work, Co-Testing unique several ways:
1. existing multi-view approaches (Blum & Mitchell, 1998; Collins & Singer, 1999; Pierce
& Cardie, 2001), also use small set labeled large set unlabeled
examples, based idea bootstrapping views other. contrast, Co-Testing first algorithm exploits multiple views active learning
purposes. Furthermore, Co-Testing allows simultaneous use strong weak
views without additional data engineering costs.
2. existing active learners, pool domain features together, typically designed
exploit properties specific particular (type of) base learner (i.e., algorithm used learn target concept); example, uncertainty reduction methods
assume base learner provides reliable estimate confidence
prediction. contrast, Co-Testing uses multiple views detect contention
points, among chooses next query. approach several advantages:
- converges quickly target concept based idea learning
mistakes (remember contention point guaranteed represent
mistake least one views). contrast, existing active learners often
times query examples classified correctly, low confidence.
- simplest form (i.e., Naive Co-Testing, described section 4),
makes assumptions properties base learner. precisely,
simply querying arbitrary contention point, Co-Testing guaranteed
provide mistaken view highly informative example.
- considering contention points query candidates, allows use
query selection heuristics - computationally - expensive applied
entire set unlabeled examples.
204

fiActive Learning Multiple Views

remainder paper organized follows. First, introduce concepts
notation, followed comprehensive survey literature active multi-view
learning. formally introduce Co-Testing family algorithms present
empirical evaluation variety real-world domains.

2. Preliminaries: Terminology Notation
given learning task, set possible domain examples called instance
space denoted X. x X represents particular example instance.
paper concerned mostly examples represented feature vectors
store values various attributes features describe example.
concept learned called target concept, seen function
c : X {l1 , l2 , . . . , lN } classifies instance x member one N classes
interest l1 , l2 , . . . , lN . order learn target concept, user provides set training
examples, consists instance x X label, c(x). notation
hx, c(x)i denotes training example. symbol L used denote set labeled
training examples (also known training set).
Given training set L target concept c, inductive learning algorithm L
searches function h : X {l1 , l2 , . . . , lN } x X, h(x) = c(x). learner
L searches h within set H possible hypotheses, (typically) determined
person designs learning algorithm. hypothesis h consistent
training set L hx, c(x)i L, h(x) = c(x). Finally, version space V H,L
represents subset hypotheses H consistent training set L.
definition, passive learning algorithm takes input randomly chosen training
set L. contrast, active learning algorithms ability choose examples L.
is, detect informative examples instance space X ask
user label them; examples chosen labeling called queries.
paper focus selective sampling algorithms, active learners choose
queries given working set unlabeled examples U (we use notation hx, ?i
denote unlabeled examples). paper terms active learning selective
sampling used interchangeably.
traditional, single-view machine learning scenario, learner access entire
set domain features. contrast, multi-view setting one partition domains
features subsets (views) sufficient learning target concept. Existing multiview learners semi-supervised algorithms: exploit unlabeled examples boost
accuracy classifiers learned view bootstrapping views other.
multi-view learning, example x described different set features
view. example, domain k views V1 , V2 , . . . Vk , labeled example seen
tuple hx1 , x2 , . . . , xk , li, l label, x1 , x2 , . . . , xk descriptions
k views. Similarly, k-view unlabeled example denoted hx1 , x2 , . . . , xk , ?i.
example x, Vi (x) denotes descriptions xi x Vi . Similarly, Vi (L) consists
descriptions Vi examples L.
205

fiMuslea, Minton, & Knoblock

3. Background Active Multi-view Learning
Active learning seen natural development earlier work optimum
experimental design (Fedorov, 1972). early 1980s, machine learning community
started recognizing advantages inductive systems capable querying
instructors. example, order detect errors Prolog programs, Algorithmic
Debugging System (Shapiro, 1981, 1982) allowed ask user several types queries.
Similarly, concept learning systems Marvin (Sammut & Banerji, 1986) cat
(Gross, 1991) used queries integral part respective learning strategies.
literature review structured follows. First, discuss early, mostly
theoretical results query construction. focus selective sampling algorithms,
select next query one unlabeled examples working set. Finally,
conclude reviewing existing multi-view learning algorithms.
3.1 Active Learning Query Construction
earliest approaches formalizing active learning appeared seminal papers
Angluin (1982, 1988) Valiant (1984), focused exact concept induction
learning pac framework, respectively. theoretic work focused learning classes
concepts regular sets, monotone dnf expressions, expressions. Besides
membership queries example target concept?, Angluin also used
sophisticated types queries equivalence queries (is concept equivalent
target concept?) superset queries (is concept superset target concept?).
early active learners took constructive approach query generation
sense query (artificially) constructed setting values attributes
query informative possible. practice, may raise serious
problems; example, consider hand-writing recognizer must discriminate
10 digits (Lang & Baum, 1992). scenario, informative query may consist
image represents fusion two similarly-looking digits, 3 5.
presented image, user cannot label properly represent
recognizable digit. Consequently, query wasted totally irrelevant image.
Similar situations appear many real world tasks text classification, information
extraction, speech recognition: whenever active learner artificially builds query
domain, highly unlikely newly created object meaning
human user.
Despite practical applicability issue, constructive approach active learning
leads interesting theoretical insights merits various types queries.
example, researchers considered learning with:
- incomplete queries, querys answer may dont know. (Angluin &
Slonim, 1991; Goldman & Mathias, 1992; Sloan & Turan, 1994; Blum, Chalasani,
Goldman, & Slonim, 1998);
- malicious queries, answer queries may erroneous (Angluin, Krikis,
Sloan, & Turan, 1997; Angluin & Krikis, 1994; Angluin, 1994).
New learning problems also considered, unrestricted dnf expressions (Jackson, 1994; Blum, Furst, Jackson, Kearns, Mansour, & Rudich, 1994) unions boxes
206

fiActive Learning Multiple Views

(Goldberg, Goldman, & Mathias, 1994) tree patterns (Amoth, Cull, & Tadepalli, 1998,
1999) Horn clauses (Reddy & Tadepalli, 1997). Researchers also reported results
applying active learning neural networks (Hwang, Choi, Oh, & Marks, 1991; Baum, 1991;
Watkin & Rau, 1992; Hasenjager & Ritter, 1998) combining declarative bias (prior
knowledge) active learning (Tadepalli, 1993; Tadepalli & Russell, 1998).
3.2 Selective Sampling
Selective sampling represents alternative active learning approach. typically applies
classification tasks learner access large number unlabeled examples.
scenario, rather constructing informative query, active learner asks
user label one existing unlabeled examples. Depending source unlabeled
examples, two main types sampling algorithms: stream- pool- based.
former assumes active learner access (infinite) stream unlabeled
examples (Freund, Seung, Shamir, & Tishby, 1997; Argamon-Engelson & Dagan, 1999;
Dagan & Engelson, 1995); successive examples presented it, active learner
must decide labeled user. contrast, pool-based
scenario (Lewis & Gale, 1994; Lewis & Catlett, 1994; McCallum & Nigam, 1998; Muslea,
Minton, & Knoblock, 2000, 2002a), learner presented working set unlabeled
examples; order make query, active learner goes entire pool
selects example labeled next.
Based criterion used select next query, selective sampling algorithms fall
three main categories:
- uncertainty reduction: system queries example current hypothesis
makes least confident prediction;
- expected-error minimization: system queries example maximizes expected
reduction classification error;
- version space reduction: system queries example that, labeled, removes
much possible version space.
uncertainty reduction approach selective sampling works follows: first, one uses
labeled examples learn classifier; system queries unlabeled example
classifier makes least confident prediction. straightforward idea
applied base learner one reliably estimate confidence
predictions. Confidence-estimation heuristics proposed variety base learners
logistic regression (Lewis & Gale, 1994; Lewis & Catlett, 1994), partially hidden
Markov Models (Scheffer & Wrobel, 2001), support vector machines (Schohn & Cohn, 2000;
Campbell, Cristianini, & Smola, 2000), inductive logic programming (Thompson, Califf,
& Mooney, 1999).
second, sophisticated approach selective sampling, expected-error minimization, based statistically optimal solution active learning problem.
scenario, intuition query unlabeled example minimizes error rate
(future) classifier test set. Even though (extremely simple) base
learners one find optimal queries (Cohn, Ghahramani, & Jordan, 1996),
207

fiMuslea, Minton, & Knoblock

true inductive learners. Consequently, researchers proposed methods estimate
error reduction various types base learners. example, Roy McCallum
(2001) use sample estimation method Naive Bayes classifier; similar approaches
also described parameter learning Bayesian nets (Tong & Koller, 2000)
nearest neighbor classifiers (Lindenbaum, Markovitch, & Rusakov, 2004).
heuristic approach expected-error minimization summarized follows.
First, one chooses loss function (Roy & McCallum, 2001) used estimate
future error rate. unlabeled example x working set considered
possible next query, system estimates expected reduction error rate
possible label x may take. Finally, system queries unlabeled example
leads largest estimated reduction error rate.
Finally, typical version space reduction active learner works follows: generates
committee several hypotheses, queries unlabeled examples
disagreement within committee greatest. two-class learning problem,
strategy translates making queries remove approximately half version space.
Depending method used generate committee, one distinguish several types
active learners:
- Query-by-Committee selects committee randomly sampling hypotheses
version space. Query-by-Committee applied variety base learners
perceptrons (Freund et al., 1997), Naive Bayes (McCallum & Nigam, 1998), Winnow (Liere & Tadepalli, 1997). Furthermore, Argamon-Engelson Dagan (1999,
1995) introduce extension Query-by-Committee Bayesian learning.
Bayesian framework, one create committee sampling classifiers according
posterior distributions; is, better hypothesis explains training
data, likely sampled. main limitation Query-by-Committee
applied base learners feasible randomly sample hypotheses version space.
- sg-net (Cohn et al., 1994) creates 2-hypothesis committee consists mostgeneral most-specific classifier. two hypotheses generated modifying base learner learns classifier labels many possible
unlabeled examples working set positive negative, respectively.
approach obvious drawback: requires user modify base learner
generate most-general most-specific classifiers.
- Active-Decorate (Melville & Mooney, 2004) seen generalization
improvement sg-net. generates large diverse committee successively
augmenting original training set additional sets artificially-generated examples. precisely, generates artificial examples keeping distribution
instance space; applies current committee example,
labels artificial example label contradicts committees
predictions. new classifier learned augmented dataset,
entire process repeated desired committee size reached. Active-Decorate
successfully used domains nominal numeric features, unclear
could applied domains text classification extraction,
generating artificial examples may problematic.
208

fiActive Learning Multiple Views

- Query-by-Bagging Query-by-Boosting (Abe & Mamitsuka, 1998) create committee using well-known bagging (Breiman, 1996) boosting (Schapire, 1990)
algorithms, respectively. algorithms introduced c4.5 base learner,
bagging boosting known work extremely well.
general, committee-based sampling tends associated version space
reduction approach. However, base learners support vector machines, one
use single hypothesis make queries remove (approximately) half version
space (Tong & Koller, 2001). Conversely, committee-based sampling also seen
relying uncertainty reduction principle: all, unlabeled example
disagreement within committee greatest also seen example
least certain classification.
3.3 Multi-view, Semi-supervised Learning
already mentioned, Blum Mitchell (1998) provided first formalization learning
multi-view framework. Previously, topic largely ignored, though idea
clearly shows applications word sense disambiguation (Yarowsky, 1995)
speech recognition (de Sa & Ballard, 1998). Blum Mitchell proved two independent, compatible views used pac-learn (Valiant, 1984) concept based
labeled many unlabeled examples. also introduced Co-Training, first
general-purpose, multi-view algorithm.
Collins Singer (1999) proposed version Co-Training biased towards
learning hypotheses predict label unlabeled examples.
introduce explicit objective function measures compatibility learned
hypotheses use boosting algorithm optimize objective function. related
paper (Dasgupta, Littman, & McAllester, 2001), authors provide pac-like guarantees
novel Co-Training algorithm (the assumption is, again, views
independent compatible). Intuitively, Dasgupta et al. (2001) show ratio
contention points unlabeled examples upper-bound error rate classifiers
learned two views.
Abney (2002) extends work Dasgupta et al. relaxing view independence
assumption. precisely, author shows even views weakly dependent, ratio contention points unlabeled examples still represents upper-bound
two views error rate. Unfortunately, paper introduces theoretical definition weak dependence views, without providing intuitive explanation
practical consequences.
Researchers proposed two main types extensions original Co-Training algorithm: modifications actual algorithm changes aiming extend practical
applicability. former cover wide variety scenarios:
- Co-EM (Nigam & Ghani, 2000; Brefeld & Scheffer, 2004) uses Expectation Maximization
(Dempster, Laird, & Rubin, 1977) multi-view learning. Co-EM seen
closest implementation theoretical framework proposed Blum Mitchell
(1998).
209

fiMuslea, Minton, & Knoblock

- Ghani (2002) uses Error-Correcting Output Codes allow Co-Training Co-EM
scale problems large number classes.
- Corrected Co-Training (Pierce & Cardie, 2001) asks user manually correct
labels bootstrapped examples. approach motivated observation
quality bootstrapped data crucial Co-Trainings convergence.
- Co-Boost (Collins & Singer, 1999) Greedy Agreement (Abney, 2002) Co-Training
algorithms explicitly aim minimize number contention points.
second group extensions Co-Training motivated fact that, practice,
one also encounters many problems straightforward way split
features two views. order cope problem, Goldman Zhou (2000)
advocate use multiple biases instead multiple views. authors introduce
algorithm similar Co-Training, bootstraps hypotheses learned
two different base learners; approach relies assumption base learners
generate hypotheses partition instance space equivalence classes. recent
paper, Zhou Goldman (2004) use idea multi-biased committee active
learning; i.e., use various types base learners obtain diverse committee,
query examples committee disagree most.
Within multi-view framework, Nigam Ghani (2000) show that, bag-ofwords text classification, one create two views arbitrarily splitting original set
features two sub-sets. approach fits well text classification domain,
features abundant, unlikely work types problems.
alternative solution proposed Raskutti, Ferra, Kowalczyk (2002),
authors create second view consists variety features measure examples
similarity N largest clusters domain. Finally, Muslea, Minton, Knoblock
(2002b) propose meta-learning approach uses past experiences predict whether
given views appropriate new, unseen learning task.

4. Co-Testing Family Algorithms
section, discuss detail Co-Testing family algorithms. already
mentioned, Co-Testing seen two-step iterative process: first, uses
labeled examples learn hypothesis view; queries unlabeled example
views predict different labels. adding queried example training
set, entire process repeated number iterations.
remainder section organized follows: first, formally present CoTesting family algorithms discuss several members. introduce
concepts strong weak views, analyze Co-Testing exploit types
views (previous multi-view learners could use strong views). Finally, compare
contrast Co-Testing related approaches.
4.1 Family Algorithms
Table 1 provides formal description Co-Testing family algorithms. input
consists k views V1 , V2 , . . . , Vk , base learner L, sets L U labeled
210

fiActive Learning Multiple Views

Table 1: Co-Testing family algorithms: repeatedly learn classifier view
query example predict different labels.
Given:
- base learner L
- learning domain features V = {a1 , a2 , . . . , }
- k views V1 , V2 , . . . , Vk V =

k
[

i=1

Vi i, j {1, 2, . . . , k}, 6= j, Vi Vj =

- sets L U labeled unlabeled examples, respectively
- number N queries made
- LOOP N iterations
- use L learn classifiers h1 , h2 , . . . , hk views V1 , V2 , . . . , Vk , respectively
- let ContentionP oints = { hx1 , x2 , . . . , xk , ?i U | i, j hi (xi ) 6= hj (xj ) }
- let hx1 , x2 , . . . , xk , ?i = SelectQuery(ContentionP oints)
- remove hx1 , x2 , . . . , xk , ?i U ask label l
- add hx1 , x2 , . . . , xk , li L
- hOU = CreateOutputHypothesis( h1 , h2 , . . . , hk )

unlabeled examples, respectively. Co-Testing algorithms work follows: first, learn
classifiers h1 , h2 , . . . , hk applying algorithm L projection examples
L onto view. apply h1 , h2 , . . . , hk unlabeled examples U create
set contention points, consists unlabeled examples least two
hypotheses predict different label. Finally, query one contention points
repeat whole process number iterations. making allowed
number queries, Co-Testing creates output hypothesis used make actual
predictions.
various members Co-Testing family differ two respects:
strategy used select next query, manner output hypothesis
constructed. words, Co-Testing algorithm uniquely defined choice
functions SelectQuery() CreateOutputHypothesis().
paper consider three types query selection strategies:
- naive: choose random one contention points. straightforward strategy
appropriate base learners lack capability reliably estimating
confidence predictions. naive query selection strategy independent
domain base learner properties, follows used
solving multi-view learning task.
- aggressive: choose query contention point Q least confident
hypotheses h1 , h2 , . . . , hk makes confident prediction; formally,
211

fiMuslea, Minton, & Knoblock

Q=

arg max

min

xContentionP oints i{1,2,...,k}

Conf idence(hi (x))

Aggressive Co-Testing designed high accuracy domains, little
noise. domains, discovering unlabeled examples misclassified
high confidence translates queries remove significantly half
version space.
- conservative: choose contention point confidence predictions
made h1 , h2 , . . . , hk close possible (ideally, would equally confident
predicting different labels); is,
Q=

arg min
xContentionP oints

max

f {h1 ,...,hk }

Conf idence(f (x))

min

g{h1 ,...,hk }

Conf idence(g(x))

!

Conservative Co-Testing appropriate noisy domains, aggressive strategy may end querying mostly noisy examples.
Creating output hypothesis also allows user choose variety alternatives, as:
- weighted vote: combines vote hypothesis, weighted confidence
respective predictions.
X

hOU (x) = arg max
lLabels

Conf idence(g(x))

g {h1 , . . . , hk }
g(x) = l

- majority vote: Co-Testing chooses label predicted hypotheses
learned k views.
hOU (x) = arg max
lLabels

X

1

g {h1 , . . . , hk }
g(x) = l

strategy appropriate least three views, base learner
cannot reliably estimate confidence predictions.
- winner-takes-all: output hypothesis one learned view makes
smallest number mistakes N queries. obvious solution
2-view learning tasks base learner cannot (reliably) estimate confidence predictions. denote istakes(h1 ), istakes(h2 ), . . . , istakes(hk )
number mistakes made hypotheses learned k views N
queries,
hOU (x) = arg min istakes(g)
g{h1 ,...,hk }

212

fiActive Learning Multiple Views

4.2 Learning Strong Weak Views
original multi-view setting (Blum & Mitchell, 1998; Muslea et al., 2000), one makes
strong views assumption view sufficient learn target concept. However,
practice, one also encounters views one accurately learn concept
strictly general specific concept interest (Muslea, Minton, &
Knoblock, 2003). often case domains involve hierarchical classification,
information extraction email classification. example, may extremely
easy discriminate (with high accuracy) work personal emails based solely
emails sender; however, information may insufficient predicting
work personal sub-folder email stored.
introduce notion weak view, one accurately learn
concept strictly general specific target concept. Note
learning weak view qualitatively different learning approximation
target concept: latter represents learning imperfect features, former
typically refers (easily) learnable concept strict generalization/specialization
target concept (note that, real world, imperfect features noisy labels affect
learning strong weak views).
context learning strong weak views, redefine contention points
unlabeled examples strong views predict different label.
necessary step two reasons: first, weak view inadequate learning
target concept, typically disagrees strong views large number unlabeled
examples; turn, would increase number contention points skew
distribution. Second, interested fixing mistakes made weak view,
rather using view additional information source allows faster learning
strong views (i.e., fewer examples).
Even though weak views inadequate learning target concept,
exploited Co-Testing SelectQuery() CreateOutputHypothesis()
functions. particular, weak views extremely useful domains two
strong views:
- weak view used CreateOutputHypothesis() tie-breaker
two strong views predict different label.
- SelectQuery() designed that, ideally, query would represent mistake
strong views. done first detecting contention points -
- weak view disagrees strong views; among these, next
query one weak view makes confident prediction.
queries likely represent mistake strong views, rather one
them; turn, implies simultaneous large cuts strong version spaces,
thus leading faster convergence.
section 5.2.2 describe Co-Testing algorithm exploits strong weak views
wrapper induction domains (Muslea et al., 2003; Muslea, Minton, & Knoblock, 2001).
Note learning strong weak views clearly extends beyond wrapper induction
tasks: example, idea exploiting complementary information sources (i.e., different
213

fiMuslea, Minton, & Knoblock

types features) appears two multi-strategy learners (Kushmerick, Johnston, &
McGuinness, 2001; Nahm & Mooney, 2000) discussed section 4.3.2.
4.3 Co-Testing vs. Related Approaches
already mentioned section 3.3, existing multi-view approaches typically semisupervised learners bootstrap views other. two exceptions (Muslea
et al., 2002a; Jones, Ghani, Mitchell, & Riloff, 2003) interleave Co-Testing Co-EM
(Nigam & Ghani, 2000), thus combining best worlds: semi-supervised learning
provides active learner accurate hypotheses, lead informative queries; active learning provides semi-supervised learner informative
training set, thus leading faster convergence.
4.3.1 Co-Testing vs. Existing Active Learners
Intuitively, Co-Testing seen committee-based active learner generates
committee consists one hypothesis view. Also note Co-Testing
combined virtually existing single-view active learners: among contention
points, Co-Testing select next query based heuristics discussed
section 3.2.
two main differences Co-Testing active learners:
- except Co-Testing variants (Muslea et al., 2002a; Jones et al., 2003),
active learners work single-view framework (i.e., pool together
domain features).
- single-view active learners typically designed particular (class of) base learner(s).
example, Query-by-Committee (Seung, Opper, & Sompolinski, 1992) assumes
one randomly sample hypotheses version space, Uncertainty
Sampling (Lewis & Gale, 1994; Lewis & Catlett, 1994) relies base learners
ability reliably evaluate confidence predictions. contrast, basic
idea Co-Testing (i.e., querying contention points) applies multi-view problem,
independently base learner used.
Co-Testing approach active learning advantages disadvantages.
one hand, Co-Testing cannot applied problems least two
views. hand, multi-view problem, Co-Testing used
best base learner particular task. contrast, single-view framework, one
often must either create new active learning method particular base learner or, even
worse, modify existing base learner used conjunction existing
sampling algorithm.
illustrate last point, let us briefly consider learning information extraction,
goal use machine learning extracting relevant strings collection
documents (e.g., extract perpetrators, weapons, victims corpus news
stories terrorist attacks). information extraction different nature typical
classification task, existing active learners cannot applied straightforward manner:
- information extraction free text (ie), existing active learners (Thompson
et al., 1999; Soderland, 1999; Scheffer & Wrobel, 2001) crafted based heuristics
214

fiActive Learning Multiple Views

specific respective base learners, rapier, whisk, Partially Hidden Markov
Models. alternative discussed Finn Kushmerick (2003), explore
variety ie-specific heuristics used active learning purposes
analyze trade-offs related using heuristics.
- wrapper induction, goal extract data Web pages share
underlying structure, reported results applying (singleview) active learning. typical wrapper induction algorithms (Muslea
et al., 2001; Kushmerick, 2000; Hsu & Dung, 1998) base learners lack
properties exploited single-view active learners reviewed section 3.2.:
determinist learners noise sensitive, provide confidence predictions,
make mistakes training set.
contrast, Co-Testing applies naturally wrapper induction (Muslea et al., 2000,
2003) information extraction free text (Jones et al., 2003). due
fact Co-Testing rely base learners properties identify highly
informative set candidate queries; instead, focuses contention points, which,
definition, guaranteed represent mistakes views.
4.3.2 Exploiting Weak Views
briefly discuss two learning tasks seen learning strong
weak views, even though formalized such, views used
active learning. additional application domain strong weak views, wrapper
induction, discussed length section 5.2.
discotex (Nahm & Mooney, 2000) system designed extract job titles,
salaries, locations, etc computer science job postings newsgroup austin.jobs.
discotex proceeds four steps: first, uses rapier (Califf & Mooney, 1999) learn
extraction rules item interest. Second, applies learned rules large,
unlabeled corpus job postings creates database populated extracted
data. Third, text mining database, discotex learns predict value item
based values fields; e.g., may discover job requires c++
corba development platforms include Windows. Finally, system
deployed rapier rules fail extract item, mined rules used predict
items content.
scenario, rapier rules represent strong view sufficient
extracting data interest. contrast, mined rules represent weak view
cannot learned used themselves. Furthermore, discotex discards
accurate mined rules, highly-specific, follows
weak view used learn concepts specific target concept. Nahm
Mooney (2000) show mined rules improve extraction accuracy capturing
information complements rapier extraction rules.
Another domain strong weak views presented Kushmerick et al. (2001).
learning task classify lines text business card persons name,
affiliation, address, phone number, etc. domain, strong view consists
words appear line, based Naive Bayes text classifier learned.
weak view, one exploit relative order lines card learning
215

fiMuslea, Minton, & Knoblock

Hidden Markov Model predicts probability particular ordering lines
business card (e.g., name followed address, followed phone number).
weak view defines class concepts general target concept:
line orderings possible, even though equally probable. Even though
order text lines cannot used accurately classify lines,
combined strong view, ordering information leads classifier clearly
outperforms stand-alone strong view (Kushmerick et al., 2001).
Note approaches use strong weak views passive, rather
active learning. is, given fixed set labeled unlabeled examples,
algorithms learn one weak one strong hypothesis used craft domainspecific predictor outperforms individual hypothesis. contrast, Co-Testing
active learner seamlessly integrates weak strong hypotheses without requiring
additional, domain-specific data engineering.

5. Empirical Validation
section empirically compare Co-Testing state art learners.
goal test following hypothesis: given multi-view learning problem, Co-Testing
converges faster single-view counterparts.
begin presenting results three real-world classification domains: Webpage classification, discourse tree parsings, advertisement removal. focus
important industrial application, wrapper induction (Muslea et al., 2001; Kushmerick,
2000; Hsu & Dung, 1998), goal learn rules extract relevant data
collection documents (e.g., extract book titles prices Web site).
results classification wrapper induction analyzed separately because:
- three classification tasks, two strong views available;
contrast, wrapper induction two strong one weak views,
allows us explore wider range options.
- classification domain, exactly one available dataset. contrast,
wrapper induction use testbed 33 distinct tasks. imbalance number
available datasets requires different presentation styles results.
- contrast typical classification, major requirement wrapper induction learn
(close to) 100%-accurate extraction rules handful examples (Muslea,
2002, pages 3-6). requirement leads significant differences experimental setup interpretation results (e.g., results excellent
classification tasks may unacceptable wrapper induction).

5.1 Co-Testing Classification
begin empirical study using three classification tasks compare Co-Testing
existing active learners. first introduce three domains respective views;
discuss learners used evaluation analyze experimental results.
216

fiActive Learning Multiple Views

Domain

L

ad
tf

ib
mc4
Naive
Bayes

courses

Co-Testing
Query
Output
Selection
Hypothesis
naive
winner
naive
winner
naive
weighted
conservative
vote

Single-view Algorithms
QBC



qBag



qBst



US












Rnd




Table 2: algorithms used classification. last five columns denote Query-byCommittee/-Bagging/-Boosting, Uncertainty Sampling Random Sampling.

5.1.1 Views used Co-Testing
applied Co-Testing three real-world classification domains natural,
intuitive way create two views:
- ad (Kushmerick, 1999) classification problem two classes, 1500 attributes,
3279 examples. ad, images appear Web pages classified ads
non-ads. view V1 consists textual features describe image; e.g.,
1-grams 2-grams caption, url page contains
image, url page image points to, etc. turn, V2 describes
properties image itself: length, width, aspect ratio, origin (i.e.,
image page contains coming Web server?).
- courses (Blum & Mitchell, 1998) domain two classes, 2206 features, 1042
examples. learning task consists classifying Web pages course homepages
pages. courses two views consist words appear page
words appear hyperlinks pointing them, respectively.
- tf (Marcu, Carlson, & Watanabe, 2000) classification problem seven classes, 99
features 11,193 examples. context machine translation system, uses
shift-reduce parsing paradigm learn rewrite Japanese discourse trees
English-like discourse trees. case, V1 uses features specific shift-reduce
parser: elements input list partial trees stack. V2 consists
features specific Japanese tree given input.
5.1.2 Algorithms used Evaluation
Table 2 shows learners used empirical comparison. implemented
active learners extensions MLC++ library (Kohavi, Sommerfield, & Dougherty,
1997). domain, choose base learner follows: applying primitive
learners MLC ++ dataset (10-fold cross-validation), select one obtains
best performance. precisely, using following base learners: ib (Aha,
1992) ad, Naive Bayes (Blum & Mitchell, 1998) courses, mc4,
implementation c4.5, tf.
217

fiMuslea, Minton, & Knoblock

five single-view algorithms Table 2 use available features (i.e., V 1 V2 )
learn target concept.1 three domains, Random Sampling (Rnd) used
strawman; Query-by-Bagging -Boosting, denoted qBag qBst, also run
three domains. contrast, Uncertainty Sampling (US) applied ad
courses mc4, base learner tf, provide estimate
confidence prediction.
known method randomly sampling ib mc4 version spaces,
Query-by-Committee (QBC) applied ad tf. However, apply QBC
courses borrowing idea McCallum Nigam (1998): create committee sampling hypotheses according (Gamma) distribution Naive Bayes
parameters estimated training set L.
Query-by-Committee use typical 2-hypothesis committee. Query-byBagging -Boosting, use relatively small 5-hypothesis committees
cpu constraints: running time increases linearly number learned hypotheses,
and, domains, takes 50 cpu hours complete experiments even
5-hypothesis committees.
limitations respective base learners (i.e., above-mentioned
issue estimating confidence prediction), ad tf use Naive Co-Testing
winner-takes-all output hypothesis; is, query randomly selected among
contention points, output hypothesis one learned view makes
fewest mistakes queries. contrast, courses follow methodology
original Co-Training paper (Blum & Mitchell, 1998), output hypothesis
consists weighted vote classifiers learned view.
courses investigate two Co-Testing query selection strategies: naive
conservative. third, aggressive query selection strategy appropriate courses
hyperlink view significantly less accurate one (after all, one
rarely encounters handful words hyperlink). Consequently,
high-confidence contention points unfixable mistakes hyperlink view,
means even seeing correct label, cannot classified correctly
view.
5.1.3 Experimental Results
learners performance evaluated based 10-fold, stratified cross validation. ad,
algorithm starts 150 randomly chosen examples makes 10 queries
40 learning episodes, total 550 labeled examples. courses, algorithms
start 6 randomly chosen examples make one query 175 learning
episodes. Finally, tf algorithms start 110 randomly chosen examples make
20 queries 100 learning episodes.
Figures 1 2 display learning curves various algorithms ad, tf,
course. three domains, Co-Testing reaches highest accuracy (i.e., smallest error
rate). Table 3 summarizes statistical significance results (t-test confidence least
1. preliminary experiment, also ran algorithms individual views. results
V1 V2 either worse V1 V2 differences statistically insignificant.
Consequently, sake simplicity, decided show single-view results V 1 V2 .

218

fiActive Learning Multiple Views

error rate (%)

AD
9
Naive Co-Testing
8.5
Uncertainty Sampling
8
Rnd
7.5
7
6.5
6
5.5
5
4.5
4
3.5
150 200 250 300 350 400 450 500
labeled examples
AD
10
Naive Co-Testing
qBag
qBst
Rnd

error rate (%)

9
8
7
6
5
4

3
150 200 250 300 350 400 450 500
labeled examples
TF
32
Naive Co-Testing
qBag
qBst
Rnd

error rate (%)

30
28
26
24
22
20
18
110

510

910

1310

1710

2110

labeled examples

Figure 1: Empirical results ad tf problems
219

fiMuslea, Minton, & Knoblock

courses
12
Conservative Co-Testing
Uncertainty Sampling
QBC
Rnd

error rate (%)

10
8
6
4
2
20

60

100

140

180

labeled examples
courses
12
Conservative Co-Testing
qBag
qBst
Rnd

error rate (%)

10
8
6
4
2
20

60

100

140

180

labeled examples
courses
12
Conservative Co-Testing
Naive Co-Testing

error rate (%)

10
8
6
4
2
20

60

100

140

180

labeled examples

Figure 2: Empirical results courses problem
220

fiActive Learning Multiple Views

Naive Co-Testing

Algorithm
Random Sampling
Uncertainty Sampling
Query-by-Committee
Query-by-Bagging
Query-by-Boosting
Naive Co-Testing

ad

Conservative Co-Testing

tf

courses

Loss

Tie

Win

Loss

Tie

Win

Loss

Tie

Win

0
0
0
0
-

0
2
18
15
-

19
17
1
4
-

0
0
0
0
0
-

21
2
60
6
0
-

70
89
31
85
91
-

0
0
0
0

0
28
0
21

49
21
49
28

Table 3: Statistical significance results empirical (pair-wise) comparison various
algorithms three domains.

95%) obtained pair-wise comparison various algorithms. comparisons
performed right-most half learning curve (i.e., towards convergence).
best way explain results Table 3 via examples: results comparing Naive
Co-Testing Random Sampling ad appear first three columns first
row. three numbers (i.e., 0, 0, 19) mean (all) 19 comparison points Naive
Co-Testing outperforms Random Sampling statistically significant manner. Similarly,
comparing Naive Conservative Co-Testing courses (the last three columns
last row) leads following results: 28 comparison points Conservative CoTesting outperforms Naive Co-Testing statistically significant manner; 21
points differences statistically insignificant; finally, comparison point Naive
Co-Testing outperforms Conservative counterpart.
results Table 3 summarized follows. First all, single-view algorithm
outperforms Co-Testing statistically significant manner comparison points.
Furthermore, except comparison Query-by-Bagging -Boosting ad,
difference accuracy statistically insignificant almost comparison points, CoTesting clearly outperform algorithms domains.
Finally, let us briefly comment applying multi-view, semi-supervised learners
three tasks above. mentioned section 3.3, algorithms bootstrap views
training view examples labeled high-confidence
view. ad tf, could use multi-view, semi-supervised learning
base learners ib mc4 provide (reliable) estimate confidence
predictions. precisely, mc4 provides estimate all, ibs estimates
extremely poor training data scarce (e.g., see poor performance
Uncertainty Sampling ad, barely outperforms Random Sampling).
courses, applied Co-Training Co-EM conjunction
Naive Bayes base learner. multi-view learners reach maximum accuracy
(close 95%) based solely 12 labeled 933 unlabeled examples,
221

fiMuslea, Minton, & Knoblock

R2

R1

Name:<i>Ginos</i><p>Phone:<i> (800)111-1717 </i><p>Cuisine:
Figure 3: forward backward rules detect beginning phone number.
performance improve statistically significant manner.2 shown Figure 2,
training data scarce (i.e., 40 labeled examples), Co-Testings accuracy
less 95%; however, making additional queries, Co-Testing reaches 98% accuracy,
Co-Training Co-EM remain 95% even trained 180 labeled 765
unlabeled examples. results consistent different goals active
semi-supervised learning: former focuses learning perfect target concept
minimal amount labeled data, latter uses unlabeled examples boost
accuracy hypothesis learned handful labeled examples.
5.2 Co-Testing Wrapper Induction
focus different type learning application, wrapper induction (Muslea et al.,
2001; Kushmerick, 2000), goal learn rules extract relevant sub-strings
collection documents. Wrapper induction key component commercial
systems integrate data variety Web-based information sources.
5.2.1 Views used Co-Testing
Consider illustrative task extracting phone numbers documents similar
fragment Figure 3. find phone number begins,3 one use rule
R1 = SkipT o( Phone:<i> )
rule applied forward, beginning page, ignores everything
finds string Phone:<i>. Note forward-going rules represent
way detect phone number begins: alternative approach use rule
R2 = BackT o( Cuisine ) BackT o( ( Number ) )
applied backward, end document. R2 ignores everything
finds Cuisine then, again, skips first number parentheses.
Forward backward rules R1 R2 learned user-provided
examples state art wrapper induction system stalker (Muslea et al., 2001),
use base learner Co-Testing. Intuitively, stalker creates forward
2. recent paper (Brefeld & Scheffer, 2004) shows - text classification - svm appropriate
Naive Bayes base learner Co-EM, though necessarily Co-Training. MLC ++
library provide svm base learner, could compare results Brefeld
Scheffer (2004), Co-EM + svm reaches 99% accuracy based 12 labeled 933 unlabeled
examples. However, fairness, unlikely Co-Testing could lead even faster convergence.
3. shown Muslea et al. (2001), end phone number found similar manner.

222

fiActive Learning Multiple Views

backward rule consumes tokens precede follow extraction point,
respectively. follows rules R1 R2 represent descriptions
concept (i.e., beginning phone number) learned two different views:
sequences tokens precede follow beginning item, respectively.
views strong views sufficient accurately extract items
interest (Muslea et al., 2001, 2000).
addition two views, rely mostly context item
extracted (i.e., text surrounding item), one use third view describes
content item extracted. example, phone numbers described
simple grammar: ( Number ) Number - Number; similarly, urls start
http://www., end .html, contain html tags.
content-based view weak view often represents concept
general target one. example, phone number grammar cannot discriminate home, office, cell, fax numbers appear within Web
page; similarly, url grammar cannot distinguish urls interest (e.g.,
products review) ones (e.g., advertisements).
weak view, use base learner version DataPro (Lerman, Minton, &
Knoblock, 2003) described elsewhere (Muslea et al., 2003). DataPro learns -
positives examples - prototypes items extracted; i.e., finds statistically significant sequences tokens (1) highly unlikely generated
chance (2) describe content many positive examples. features used
base learner consist length range (in tokens) seen examples, token
types appear training set (e.g., Number, AllCaps, etc), start- endpattern (e.g., http://www. AlphaNum .html, respectively).
5.2.2 Algorithms used Evaluation
extraction rules learned two strong views provide estimate
confidence extractions, Co-Testing algorithm implemented
based solely forward backward views Naive Co-Testing winner-takes-all
output hypothesis:
- query randomly chosen (Naive Co-Testing) among contention points,
documents learned rules extract different strings.
- output hypothesis rule learned view makes fewest mistakes
allowed number queries (i.e., winner-takes-all).
Given additional, content-based view, also implement aggressive version
Co-Testing wrapper induction:
- contention points are, again, unlabeled examples rules learned
strong views extract string.
- aggressive query selection strategy works selecting contention point
hypothesis learned weak view maximally confident stalker
rules extracting incorrect strings. formally, contention point, let 1
s2 strings extracted strong views; let us also denote n1 n2
223

fiMuslea, Minton, & Knoblock

number constraints learned weak views violated s1 s2 .
Using notation, next query contention point min(n1 , n2 )
largest value.
- output hypothesis obtained following majority voting scheme: strings
extracted strong views identical, represent extracted item;
otherwise result one two strings violates fewer constraints
learned weak view.
empirical evaluation below, compare two Co-Testing algorithms
Random Sampling Query-by-Bagging. former used strawman,
latter general-purpose active learner applied straightforward
manner wrapper induction (for details, see discussion section 4.3.1). Finally,
existing multi-view, semi-supervised learners cannot used wrapper induction
base learners provide estimate confidence extraction; even
estimate could obtained, wrapper induction algorithms extremely sensitive
mislabeled examples, would make bootstrapping process unacceptably brittle.
paper, implementation Random Sampling identical Naive
Co-Testing winner takes all, except randomly queries one unlabeled
examples working set. Query-by-Bagging, committee hypotheses
created repeatedly re-sampling (with substitution) examples original training
set L. use relatively small committee (i.e., 10 extraction rules) learning
handful examples, re-sampling replacement leads distinct
training sets. order make fair comparison Co-Testing, run Query-by-Bagging
strong view report best obtained results.
5.2.3 Experimental Results
empirical comparison, use 33 difficult wrapper induction tasks
testbed introduced Kushmerick (1998, 2000). tasks, previously used
literature (Muslea et al., 2003; Muslea, 2002), briefly described Table 4. use
20-fold cross-validation compare performance Naive Aggressive Co-Testing,
Random Sampling, Query-by-Bagging 33 tasks. algorithm starts two
randomly chosen examples makes 18 successive queries.
results summarized follows: 12 tasks, two Co-Testing
algorithms learn 100% accurate rules; another 18 tasks, Co-Testing least another
algorithm reach 100% accuracy, Co-Testing requires smallest number queries.
Finally, remaining three tasks, algorithm learns 100% accurate rule.
Figure 4 shows aggregate performance four algorithms 33 tasks.
six graphs, X axis shows number queries made algorithm,
axis shows number tasks 100% accurate rule learned based
exactly X queries. mentioned earlier, algorithms start 2 random examples
make 18 additional queries, total 20 labeled examples. convention, rightmost point X axis, labeled 19 queries, represents number tasks
require allowed 18 queries learn 100% accurate rule. additional
19 queries data-point allows us summarize results without dramatically extending
X axis beyond 18 queries: extraction tasks Random Sampling
224

fiActive Learning Multiple Views

Task
ID
S1-0
S1-1
S1-2
S2-0
S2-1
S2-2
S2-3
S3-0
S3-1
S3-3
S3-4
S3-5
S6-1
S9-10
S9-11
S11-1
S11-2

Source
name
Computer
ESP
CNN/Time
AllPolitics

Film.com
Search
PharmaWeb
Internet
Travel Net.
Internet
Address

Item
name
Price
URL
Item
URL
Source
Title
Date
URL
Name
Size
Date
Time
University
Arrival Time
Availability
Email
Update

Task
ID
S11-3
S15-1
S19-1
S19-3
S20-3
S20-5
S24-0
S24-1
S24-3
S25-0
S26-3
S26-4
S26-5
S28-0
S28-1
S30-1

Nmb
exs
404
404
404
501
501
499
492
175
175
175
175
175
27
44
39
91
91

Source
name
Finder
NewJour
Shops.Net
Democratic
Party Online
Foreign
Languages
Travelers
us Tax Code
CD Club
Web Server
Cyberider
Cycling www
Congress
Quarterly

Item
name
Organization
Name
Score
Item Name
Score
File Type
Language
URL
Translation
URL
Price
Artist
Album
URL
Relevance
Person Name

Nmb
exs
72
355
201
201
91
328
690
424
690
328
377
377
377
751
751
30

Table 4: 33 wrapper induction tasks used empirical evaluation.

Query-by-Bagging need hundreds queries learn correct rules, histograms would
become difficult read entire X axis shown.
shown Figure 4, two Co-Testing algorithms clearly outperform single-view
counterparts, Aggressive Co-Testing significantly better Naive Co-Testing
(the results statistically significant confidence least 99%). Aggressive CoTesting learns 100%-accurate rules 30 33 tasks; tasks, extraction
rules learned seven queries. Naive Co-Testing learns 100% accurate rules
28 33 tasks. 26 28 tasks, extraction rules learned based
six queries. contrast, Random Sampling Query-by-Bagging learn 100%
accurate rules seven twelve tasks, respectively. words,
Co-Testing algorithms learn correct target concept twice many tasks
Query-by-Bagging Random Sampling.
must emphasize power Aggressive Co-Testing high-accuracy tasks
wrapper induction: 11 33 tasks, single, aggressively-chosen query sufficient
learn correct extraction rule. contrast, Naive Co-Testing converges single
query four 33 tasks, two learners never converge single
query.
three tasks Aggressive Co-Testing learn 100% accurate rules,
failure due fact one views significantly less accurate
one. leads majority contention points mislabeled bad view,
- turn - skews distribution queries towards mistakes bad view.
Consequently, Co-Testings performance suffers queries uninformative
225

fi20
15
10
5
0
1

extraction task converged

extraction task converged

Aggressive Co-Testing

25

4

7

10
13
queries

16

20
15
10
5
0
1

4

7

10
13
queries

16

20
15
10
5
0
1

Query-by-Bagging (FB)

25

Naive Co-Testing

25

19

extraction task converged

extraction task converged

Muslea, Minton, & Knoblock

19

4

7

10
13
queries

16

19

16

19

Random Sampling

25
20
15
10
5
0
1

4

7

10
13
queries

Figure 4: Convergence results 33 wrapper induction tasks.

views: good view makes correct prediction them, bad view
inadequate learn target concept. order cope problem, introduced
view validation algorithm (Muslea et al., 2002b) predicts whether views
appropriate particular task.
Finally, let us briefly compare results ones obtained wien (Kushmerick, 2000), wrapper induction system evaluated
extraction tasks used here. two experimental setups identical (i.e., crossvalidation vs. random splits) informal comparison; however, puts
results perspective contrasting Co-Testing another state art approach
wrapper induction.
results summarized follows: wien fails 18 33 task; 18 tasks
include three Aggressive Naive Co-Testing failed learn perfect rules.
remaining 15 tasks, wien requires 25 90 examples 4 learn correct
rule. 15 tasks, Aggressive Naive Co-Testing learn 100% accurate
rules based eight examples (two random plus six queries).
4. wien framework, example consists document items interest labeled.
example, page contains list 100 names, labeled, represents single labeled example.
contrast, stalker labeled document represents 100 distinct labeled examples. order
compare wien stalker results, convert wien data stalker-like data multiplying
number labeled wien pages average number item occurrences page.

226

fiActive Learning Multiple Views

6. Conclusion
paper introduce Co-Testing, active learning technique multi-view
learning tasks. novel approach active learning based idea learning
mistakes; i.e., Co-Testing queries unlabeled examples views predict different
label (such contention points guaranteed represent mistakes made one views).
analyzed several members Co-Testing family (e.g., Naive, Conservative
Aggressive Co-Testing). also introduced evaluated Co-Testing algorithm
simultaneously exploits strong weak views.
empirical results show Co-Testing powerful approach active learning. experiments use four extremely different base learners (i.e., stalker, ib, Naive
Bayes, mc4) four different types domains: wrapper induction, text classification (courses), ad removal (ad), discourse tree parsing (tf). scenarios,
Co-Testing clearly outperforms single-view, state art active learning algorithms.
Furthermore, except Query-by-Bagging, Co-Testing algorithm
applied problems considered empirical evaluation. contrast Queryby-Bagging, poor performance courses wrapper induction, Co-Testing
obtains highest accuracy among considered algorithms.
Co-Testings success due ability discover mistakes made view.
contention point represents mistake (i.e., erroneous prediction) least one
views, follows query extremely informative view misclassified
example; is, mistakes informative correctly labeled examples.
particularly true base learners stalker, improve current
hypothesis unless provided examples misclassified instances.
limitation, Co-Testing applied multi-view tasks; is, unless
user provide two views, Co-Testing cannot used all. However, researchers
shown besides four problems above, multiple views exist variety real world
problems, named entity classification (Collins & Singer, 1999), statistical parsing
(Sarkar, 2001), speech recognition (de Sa & Ballard, 1998), word sense disambiguation
(Yarowsky, 1995), base noun phrase bracketing (Pierce & Cardie, 2001).
concern Co-Testing related potential violations two
multi-view assumptions, require views uncorrelated compatible.
example, case correlated views, hypotheses learned view may
similar contention points among select next query. terms
view incompatibility, remember that, three 33 wrapper induction tasks, one
views inaccurate Co-Testing could outperform Random Sampling.
two companion papers (Muslea et al., 2002a, 2002b) proposed practical solutions
problems.

Acknowledgments
research based upon work supported part National Science Foundation
Award No. IIS-0324955 grant number 0090978, part Defense Advanced
Research Projects Agency (DARPA), Department Interior, NBC, Acquisition Services Division, Contract No. NBCHD030010, part Air Force
227

fiMuslea, Minton, & Knoblock

Office Scientific Research grant number FA9550-04-1-0105. U.S.Government
authorized reproduce distribute reports Governmental purposes notwithstanding
copy right annotation thereon. views conclusions contained herein
authors interpreted necessarily representing official policies
endorsements, either expressed implied, organizations person
connected them.

References
Abe, N., & Mamitsuka, H. (1998). Query learning using boosting bagging. Proceedings 15th International Conference Machine Learning (ICML-98), pp.
110.
Abney, S. (2002). Bootstrapping. Proceedings 40th Annual Meeting Association Computational Linguistics, pp. 360367.
Aha, D. (1992). Tolerating noisy, irrelevant novel attributes instance-based learning
algorithms. International Journal Man-Machine Studies, 36 (1), 267287.
Amoth, T., Cull, P., & Tadepalli, P. (1998). Exact learning tree patterns queries
counterexamples. Proceedings Conference Computational Learing
Theory, pp. 175186.
Amoth, T., Cull, P., & Tadepalli, P. (1999). Exact learning unordered tree patterns
queries. Proceedings Conference Computational Learing Theory, pp.
323332.
Angluin, D. (1982). note number queries needed identify regular languages.
Information Control, 51, 7687.
Angluin, D. (1988). Queries concept learning. Machine Learning, 2, 319342.
Angluin, D. (1994). Exact learning DNF formulas malicious membership queries.
Tech. rep. YALEU/DCS/TR-1020, Yale University.
Angluin, D., & Krikis, M. (1994). Malicious membership queries exceptions. Tech. rep.
YALEU/DCS/TR-1019, Yale University.
Angluin, D., Krikis, M., Sloan, R., & Turan, G. (1997). Malicious omissions errors
answers membership queries. Machine Learning, 28, 211255.
Angluin, D., & Slonim, D. (1991). Randomly fallible teachers: learning monotone DNF
incomplete membership oracle. Machine Learning, 14 (1), 726.
Argamon-Engelson, S., & Dagan, I. (1999). Committee-based sample selection probabilistic classifiers. Journal Artificial Intelligence Research, 11, 335360.
Baum, E. (1991). Neural net algorithms learn polynomial time examples
queries. IEEE Transactions Neural Networks, 2, 519.
Blum, A., Chalasani, P., Goldman, S., & Slonim, D. (1998). Learning unreliable
boundary queries. Journal Computer System Sciences, 56 (2), 209222.
228

fiActive Learning Multiple Views

Blum, A., Furst, M., Jackson, J., Kearns, M., Mansour, Y., & Rudich, S. (1994). Weakly
learning DNF characterizing statistical query learning using Fourier analysis.
Proceedings 26th ACM Symposium Theory Computing, pp. 253262.
Blum, A., & Mitchell, T. (1998). Combining labeled unlabeled data co-training.
Proceedings 1988 Conference Computational Learning Theory, pp. 92100.
Brefeld, U., & Scheffer, T. (2004). Co-EM support vector learning. Proceedings
21st International Conference Machine Learning (ICML-2004), pp. 121128.
Breiman, L. (1996). Bagging predictors. Machine Learning, 24(2), 123140.
Califf, M. E., & Mooney, R. (1999). Relational learning pattern-match rules information extraction. Proceedings Sixteenth National Conference Artificial
Intelligence (AAAI-99), pp. 328334.
Campbell, C., Cristianini, N., & Smola, A. (2000). Query learning large margin classifiers. Proceedings 17th International Conference Machine Learning
(ICML-2000), pp. 111118.
Cohn, D., Atlas, L., & Ladner, R. (1994). Improving generalization active learning.
Machine Learning, 15, 201221.
Cohn, D., Ghahramani, Z., & Jordan, M. (1996). Active learning statistical models.
Advances Neural Information Processing Systems, Vol. 9, pp. 705712.
Collins, M., & Singer, Y. (1999). Unsupervised models named entity classification.
Proceedings Empirical NLP Large Corpora Conference, pp. 100110.
Dagan, I., & Engelson, S. (1995). Committee-based sampling training probabilistic
classifiers. Proceedings 12th International Conference Machine Learning,
pp. 150157.
Dasgupta, S., Littman, M., & McAllester, D. (2001). PAC generalization bounds cotraining. Neural Information Processing Systems, pp. 375382.
de Sa, V., & Ballard, D. (1998). Category learning multi-modality. Neural Computation, 10 (5), 10971117.
Dempster, A., Laird, N., & Rubin, D. (1977). Maximum likelihood incomplete data
vie em algorithm. Journal Royal Statistical Society, 39, 138.
Fedorov, V. V. (1972). Theory optimal experiment. Academic Press.
Finn, A., & Kushmerick, N. (2003). Active learning selection strategies information
extraction. Proceedings ECML-2004 Workshop Adaptive Text Extraction
Mining (ATEM-2003).
Freund, Y., Seung, H. S., Shamir, E., & Tishby, N. (1997). Selective sampling using
query committee algorithm. Machine Learning, 28, 133168.
Ghani, R. (2002). Combining labeled unlabeled data multiclass text classification.
Proceedings 19th International Conference Machine Learning (ICML-2002),
pp. 187194.
229

fiMuslea, Minton, & Knoblock

Goldberg, P., Goldman, S., & Mathias, D. (1994). Learning unions boxes membership equivalence queries. Proceedings Conference Computational
Learing Theory, pp. 198207.
Goldman, S., & Mathias, D. (1992). Learning k -term DNF formulas incomplete
membership oracle. Proceedings Conference Computational Learing Theory, pp. 7784.
Goldman, S., & Zhou, Y. (2000). Enhancing supervised learning unlabeled data.
Proceedings 17th International Conference Machine Learning (ICML-2000),
pp. 327334.
Gross, K. (1991). Concept acquisition attribute evolution experiment selection.
Ph.D. thesis, School Computer Science, Carnegie Mellon University.
Hasenjager, M., & Ritter, H. (1998). Active learning local models. Neural Processing
Letters, 7, 107117.
Hsu, C.-N., & Dung, M.-T. (1998). Generating finite-state transducers semi-structured
data extraction web. Journal Information Systems, 23(8), 521538.
Hwang, J.-N., Choi, J., Oh, S., & Marks, R. (1991). Query-based learning applied
partially trained multilayer perceptrons. IEEE Transactions Neural Networks, 2,
131 136.
Jackson, J. (1994). efficient membership-query algorithm learning DNF respect
uniform distribution. Proceedings IEEE Symposium Foundations
Computer Science, pp. 4253.
Jones, R., Ghani, R., Mitchell, T., & Riloff, E. (2003). Active learning information extraction multiple view feature sets. Proceedings ECML-2004 Workshop
Adaptive Text Extraction Mining (ATEM-2003).
Kohavi, R., Sommerfield, D., & Dougherty, J. (1997). Data mining using MLC++, machine learning library C++. International Journal AI Tools, 6(4), 537566.
Kushmerick, N. (1999). Learning remove internet advertisements. Proceedings
Third International Conference Autonomous Agents (Agents-99), pp. 175181.
Kushmerick, N. (2000). Wrapper induction: efficiency expressiveness. Artificial Intelligence Journal, 118 (1-2), 1568.
Kushmerick, N., Johnston, E., & McGuinness, S. (2001). Information extraction text
classification. IJCAI-2001 Workshop Adaptive Text Extraction Mining.
Lang, K., & Baum, E. (1992). Query learning work poorly human oracle
used. Proceedings IEEE International Joint Conference Neural Networks.
Lerman, K., Minton, S., & Knoblock, C. (2003). Wrapper maintenance: machine learning
approach. Journal Artificial Intelligence Research, 18, 149181.
Lewis, D., & Catlett, J. (1994). Heterogeneous uncertainty sampling supervised learning.
Proceedings 11th International Conference Machine Learning (ICML-94),
pp. 148156.
230

fiActive Learning Multiple Views

Lewis, D., & Gale, W. (1994). sequential algorithm training text classifiers.
Proceedings Research Development Information Retrieval, pp. 312.
Liere, R., & Tadepalli, P. (1997). Active learning committees text categorization.
14th National Conference Artificial Intelligence (AAAI-97), pp. 591596.
Lindenbaum, M., Markovitch, S., & Rusakov, D. (2004). Selective sampling nearest
neighbor classifiers. Machine Learning, 54 (2), 125152.
Marcu, D., Carlson, L., & Watanabe, M. (2000). automatic translation discourse
structures. Proceedings 1st Annual Meeting North American Chapter
Association Computational Linguistics (NAACL-2000), pp. 917.
McCallum, A., & Nigam, K. (1998). Employing EM pool-based active learning
text classification. Proceedings 15th International Conference Machine
Learning, pp. 359367.
Melville, P., & Mooney, R. J. (2004). Diverse ensembles active learning. Proceedings
International Conference Machine Learning, pp. 584591.
Muslea, I. (2002). Active Learning Multiple Views. Ph.D. thesis, Department Computer Science, University Southern California.
Muslea, I., Minton, S., & Knoblock, C. (2000). Selective sampling redundant views.
Proceedings National Conference Artificial Intelligence (AAAI-2000), pp.
621626.
Muslea, I., Minton, S., & Knoblock, C. (2001). Hierarchical wrapper induction semistructured sources. Journal Autonomous Agents Multi-Agent Systems, 4, 93114.
Muslea, I., Minton, S., & Knoblock, C. (2002a). Active + Semi-supervised Learning = Robust Multi-view Learning. 19th International Conference Machine Learning
(ICML-2002), pp. 435442.
Muslea, I., Minton, S., & Knoblock, C. (2002b). Adaptive view validation: first step
towards automatic view detection. 19th International Conference Machine
Learning (ICML-2002), pp. 443450.
Muslea, I., Minton, S., & Knoblock, C. (2003). Active learning strong weak views:
case study wrapper induction. Proceedings International Joint Conference
Atificial Intelligence (IJCAI-2003), pp. 415420.
Nahm, U.-Y., & Mooney, R. (2000). mutually beneficial integration data mining
information extraction. 17th National Conference Artificial Intelligence
(AAAI-2000), pp. 627632.
Nigam, K., & Ghani, R. (2000). Analyzing effectiveness applicability co-training.
Proceedings Information Knowledge Management, pp. 8693.
Pierce, D., & Cardie, C. (2001). Limitations co-training natural language learning
large datasets. Proceedings Empirical Methods Natural Language Processing
(EMNLP-2001), pp. 110.
Raskutti, B., Ferra, H., & Kowalczyk, A. (2002). Combining clustering co-training
enhance text classification using unlabeled data. Proceedings SIGKDD
International Conference Knowledge Discovery Data Mining, pp. 620625.
231

fiMuslea, Minton, & Knoblock

Reddy, C., & Tadepalli, P. (1997). Learning horn definitions equivalence membership queries. Proceedings 7th International Workshop Inductive Logic
Programming, pp. 243255.
Roy, N., & McCallum, A. (2001). Toward optimal active learning sampling estimation error reduction. Proceedings 18th International Conference
Machine Learning (ICML-2001), pp. 441448.
Sammut, C., & Banerji, R. B. (1986). Learning concepts asking questions. Carbonell,
R. S. M., Carbonell, J., & 2), T. M. M. V. (Eds.), Machine Learning: Artificial
Intelligence Approach, pp. 167192. Morgan Kaufmann.
Sarkar, A. (2001). Applying co-training methods statistical parsing. Proceedings
2nd Annual Meeting North American Chapter Association
Computational Linguistics (NAACL-2001), pp. 175182.
Schapire, R. (1990). strength weak learnability. Machine Learning, 5(2), 197227.
Scheffer, T., & Wrobel, S. (2001). Active learning partially hidden Markov models.
Proceedings ECML/PKDD-2001 Workshop Active Learning, Database
Sampling, Experimental Design: Views Instance Selection.
Schohn, G., & Cohn, D. (2000). Less more: Active learning support vector machines.
Proceedings 17th International Conference Machine Learning (ICML2000), pp. 839846.
Seung, H. S., Opper, M., & Sompolinski, H. (1992). Query committee. Proceedings
1988 Conference Computational Learning Theory (COLT-72), pp. 287294.
Shapiro, E. (1981). general incremental algorithm infers theories facts.
Proceedings 7th International Joint Conference Artificial Intelligence, pp.
446451.
Shapiro, E. (1982). Algorithmic program diagnosis. Proceedings 9th ACM Symposium Principles Programming Languages, pp. 299308.
Sloan, R., & Turan, G. (1994). Learning queries incomplete information (extended
abstract). Proceedings Conference Computational Learing Theory, pp.
237245.
Soderland, S. (1999). Learning extraction rules semi-structured free text. Machine
Learning, 34, 233272.
Tadepalli, P. (1993). Learning queries examples tree-structured bias.
Proceedings 10th International Conference Machine Learning (ICML-93),
pp. 322329.
Tadepalli, P., & Russell, S. (1998). Learning queries examples structured
determinations. Machine Learning, 245295.
Thompson, C., Califf, M. E., & Mooney, R. (1999). Active learning natural language
parsing information extraction. Proceedings 16th International Conference Machine Learning (ICML-99), pp. 406414.
Tong, S., & Koller, D. (2000). Active learning parameter estimation Bayesian networks. Advances Neural Information Processing Systems, Vol. 13, pp. 647653.
232

fiActive Learning Multiple Views

Tong, S., & Koller, D. (2001). Support vector machine active learning applications
text classification. Journal Machine Learning Research, 2, 4566.
Valiant, L. (1984). theory learnable. Communications ACM, 27 (11), 1134
1142.
Watkin, T., & Rau, A. (1992). Selecting examples perceptrons. Journal Physics A:
Mathematical General, 25 (1), 113121.
Yarowsky, D. (1995). Unsupervised word sense disambiguation rivaling supervised methods. Proceedings 33rd annual meeting Association Computational
Linguistics, pp. 189196.
Zhou, Y., & Goldman, S. (2004). Democratic co-learning. Proceedings International
Conference Tools Artificial Intelligence, pp. 594602.

233

fiJournal Artificial Intelligence Research 27 (2006) 441-464

Submitted 03/06; published 12/06

Set Intersection Consistency Constraint Networks
Yuanlin Zhang

yzhang@cs.ttu.edu

Department Computer Science, Texas Tech University
Lubbock, TX 79414 USA

Roland H. C. Yap

ryap@comp.nus.edu.sg

Department Computer Science, National University Singapore
3 Science Drive 2, Singapore 117543

Abstract
paper, show close relation consistency constraint
network set intersection. proof schema provided generic way obtain consistency properties properties set intersection. approach simplifies
understanding unifies many existing consistency results, also directs study
consistency set intersection properties many situations, demonstrated
results convexity tightness constraints paper. Specifically,
identify new class tree convex constraints local consistency ensures global
consistency. generalizes row convex constraints. Various consistency results also
obtained constraint networks some, contrast existing work,
constraints tight.

1. Introduction
constraint network consists set variables finite domains system
constraints variables. important task find assignment
variables constraints network satisfied. assignment
exists, network satisfiable globally consistent, assignment called solution.
problem determining global consistency general constraint network NPcomplete. Usually search procedure employed find solution. practice, due
efficiency considerations, search usually equipped filtering algorithm
prunes values variable combinations values certain number variables
cannot part solution. filtering algorithm make constraint network
locally consistent sense consistent assignment variables always
extensible new variable. important interesting question local consistency is:
local consistency obtained sufficient determine global consistency
network without search? filtering algorithm polynomial
complexity, positive answer would mean network solved
polynomial time.
Much work done explore relationship local global consistency particular properties local consistency general. One direction
make use topological structure constraint network. classical result
graph constraint network tree, arc consistency network sufficient
ensure global consistency (Freuder, 1982).
c
2006
AI Access Foundation. rights reserved.

fiZhang & Yap

second direction1 makes use semantic properties constraints. monotone
constraints, path consistency implies global consistency (Montanari, 1974). Van Beek
Dechter (1995) generalize monotone constraints larger class row convex constraints.
Dechter (1992) shows certain level consistency constraint network whose
domains limited size ensures global consistency. Later, Van Beek Dechter (1997)
study consistency constraint networks tight loose constraints.
existing work along two approaches used specific different techniques
study local global consistency. particular, little commonality details
existing work. much existing work, techniques consequently
proofs given developed specifically results concerned.
paper, show much work connected together
new approach studying consistency constraint network. unite two seemingly
disparate areas: study set intersection special sets study k-consistency
constraint networks. fact, k-consistency expressed terms set intersection,
allows one obtain relationships local global consistency constraint
network properties set intersection special sets. main result
approach proof schema used lift results set intersection,
rather general, particular consistency results constraint networks. One benefit
proof schema lies provides modular way greatly simplify understanding
proofs consistency results. benefit considerable often proofs many
existing results complex hard-wired. Using new approach, show
precisely various properties set intersection key results.
Furthermore, proofs become mechanical.
following sketch illustrates briefly use approach. One property set
intersection intersection every pair (2) tree convex sets (see Section 3)
empty, intersection whole collection sets empty too.
property, see local information intersection every pair sets gives
rise global information intersection sets. Intuitively, relationship
local global information corresponds obtaining global consistency
local consistency. proof schema used lift result tree convex sets
following consistency result. binary constraint network tree convex constraints,
(2+1)-consistency (path consistency) implies global consistency network.
usefulness new set-based approach twofold. Firstly, gives clear picture
many existing results. example, many well known results second direction
based semantic properties constraints (including van Beek & Dechter, 1995, 1997),
well results first direction, shown easy proofs make use
set intersection properties. Secondly, directing study consistency set
intersection properties, helps improve existing results derive new results
demonstrated sections 57.
paper organized follows. Section 2, present necessary notations
concepts. Section 3, focus properties intersection tree convex sets sets
1. difference work concerned studying tractability constraint
languages (e.g., Schaefer, 1978; Jeavons, Cohen, & Gyssens, 1997). latter considers problems
whose constraints fixed set relations former studies constraint networks
special properties.

442

fiSet Intersection Consistency Constraint Networks

cardinality restrictions. Section 4, develop characterization k-consistency
utilizing set intersection proof schema offers generic way obtain consistency
results set intersection properties. power new approach demonstrated
new consistency results convexity tightness constraints. Tree convex
constraints studied Section 5. constraint network tree convex constraints,
local consistency ensures global consistency, result intersection property tree
convex sets. tightness constraints studied Section 6. Thanks intersection
properties sets cardinality restriction, relation local global consistency
identified weakly tight constraint networks Section 6.1. networks require
some, rather all, constraints m-tight, improving tightness result van Beek
Dechter (1997). help relational consistency, show global consistency
achieved local consistency weakly tight constraint networks Section 6.2.
type result tightness known before. Section 6.3, explore
constraint network weakly m-tight present several results number
tight constraints sufficient necessary network weakly tight. make full use
tightness constraints network, propose dually adaptive consistency
Section 6.4. Dually adaptive consistency constraint network determined
topology tightest relevant constraint variable. completeness, include
Section 7 results tightness tree convexity based relational consistency.
conclude Section 8.

2. Preliminaries
constraint network R defined set variables N = {x1 , x2 , . . . , xn }; set finite
domains = {D1 , D2 , . . . , Dn } domain Di , 1..n, set values
variable xi take; set constraints C = {cS1 , cS2 , . . . , cSe } Si , 1..e,
subset {x1 , x2 , . . . , xn } constraint cSi relation defined domains
variables Si . Without loss generality, assume that, two constraints
cSi , cSj C (i 6= j), Si 6= Sj . arity constraint cSi number variables Si .
variable x, Dx denotes domain. rest paper, often use network
mean constraint network.
instantiation variables = {x1 , . . . , xj } denoted = (a1 , . . . , aj )
ai Di 1..j. extension variable x(
/ ) denoted (a, u)
u Dx . instantiation set variables consistent satisfies constraints
R involve variables outside .
constraint network R k-consistent consistent instantiation
distinct k 1 variables, new variable x, exists u Dx
(a, u) consistent instantiation k variables. R strongly k-consistent
j-consistent j k. strongly n-consistent network called globally consistent.
information constraint networks consistency, reader referred
work Mackworth (1977), Freuder (1978) Dechter (2003).

443

fiZhang & Yap

3. Properties Set Intersection
section, develop number set intersection results used later
derive results consistency. set intersection property concerned is:
Given collection l finite sets, conditions intersection
l sets empty?
Here, particularly interested intersection property sets two interesting useful restrictions: convexity cardinality.
3.1 Tree Convex Sets
Given collection sets, structures associated elements sets
obtain interesting useful set intersection results. study
sets whose elements form tree. first introduce concept tree convex set.
Definition 1 Given discrete set U tree vertices U , set U tree
convex exists subtree whose vertices A.
subtree tree subgraph tree. Next define say
collection sets tree convex.
Definition 2 Given collection discrete sets S, let union sets U .
sets tree convex tree U every set tree convex .
collection sets said tree convex exists tree sets
collection tree convex tree.
b



........ ......
....... ... ............
.....
......
......
......
.
.
.
.
.
......
......
......
.....
......
.
.
.
.
.
......
...
.
.
.
.
..
.
..

..
...... ...........
......
......
......
......
......
......
......
......
.
.
.
.
.
......
...
.
.
.
.
......
.
...
.....
......

b

c

....
.....
....
....
.
.
.
.
.
.....
....
....



c........





.
..................
........
....
..
... .....
...
..
...
...
...
.
.
...
...
...
..
.
.
.
.
.
...
...
.
... ....
... .....
... ...
... ...
......
......

e

e

(a)

f

(b)

Figure 1: (a) tree nodes {a, b, c, d, e} (b) partial order nodes {a, b, c, d, e, f }

Example 1 Consider set U = {a, b, c, d, e} tree given Figure 1. subset
{a, b, c, d} tree convex given tree. set {b, a, c, e} since elements
set subtree. However, {b, c, e} tree convex elements form
subtree given tree.
Example 2 Consider = {{1, 9}, {3, 9}, {5, 9}}. construct tree {1, 3, 5, 9}
9 root 1, 3, 5 children, set covers nodes exactly one
branch tree. Hence, sets tree convex.
444

fiSet Intersection Consistency Constraint Networks

Tree convex sets following intersection property.
Lemma 1 (Tree Convex Sets Intersection)
Given finite collection
finite sets S,

assume sets tree convex.
E 6= iff E1 , E2 S, E1 E2 6= .
ES
Proof. Let l number sets S, tree that, Ei S, Ei
vertices subtree Ti . Assuming rooted tree, every Ti (i 1..l) rooted
tree whose root exactly node nearest root . Let ri denote root Ti
1..l.
prove
Ei 6= , want show intersection trees {Ti | 1..l}
i1..l

empty. following propositions subtrees necessary main proof.
Proposition 1 Let T1 , T2 two subtrees tree , = T1 T2 . tree.
= , trivial tree. let 6= . Since portion T1 , circuit
it. necessary prove connected. show, two nodes u, v ,
path them. u, v T1 u, v T2 respectively imply exist
paths P1 : u, . . . , v T1 P2 : u, . . . , v T2 respectively. Recall unique
path u v T1 T2 subtrees . Therefore, P1 P2 cover
nodes edges, thus , intersection T1 T2 . P1
path want.
Proposition 2 Let T1 , T2 two subtrees tree , = T1 T2 . empty
least one roots T1 T2 .
Let r1 r2 roots T1 T2 respectively. r1 , proposition correct.
Otherwise, show r2 . Assume contrary r2
/ . Clearly, r1 6= r2 . Let r
first common ancestor r1 r2 v root (T tree Proposition 1).
paths P1 : r1 , . . . , v T1 ; P2 : r2 , . . . , v T2 ; P3 : r, . . . , r1 , P4 : r, . . . , r2
. Since v descendant r1 r2 , P1 P2 share vertex v. Since r
first common ancestor r1 r2 , P3 P4 share vertex r. also
verified P3 P1 share r1 , P2 P4 share r2 , vertex shared
either P1 P4 P2 P3 . Hence, closed walk P3 P1 P20 P40 , P20 P40
reverse P2 P4 respectively, simple circuit. contradicts circuit
.
Further, following observation.
Proposition 3 Let tree root r, T1 T2 two subtrees roots r1
r2 respectively. Let r1 closer r r2 , intersection T1 T2 .
r1 root empty.
proposition true r1 = r2 . let r1 farther r r2 . Clearly r2
/ T1
thus r2
/T
.

Proposition
2,
r


root


.
1

Let =
Ti . ready prove main result 6= . Select tree Tmax
i1..l

T1 , T2 , . . . , Tl root rmax farthest away r among roots
445

fiZhang & Yap

concerned trees. accordance Proposition 3, Tmax intersect every
tree implies rmax node every Ti (i 1..l). Therefore, rmax . 2
Remark. partial order represented acyclic directed graph. tempting generalize tree convexity partial convexity following way.
Given set U partial order it, set U partially convex
set nodes connected subgraph partial order. Given collection sets S,
let union sets U . sets partially convex partial
order U every set partially convex partial order.
However, generalization, get result similar Lemma 1,
illustrated following example. Consider three sets {c, b, d}, {d, f, a} {a, e, c}
nodes diagram given Figure 1(b). sets partially convex
intersect pairwise. However, intersection three sets empty.
3.2 Sets Cardinality Restrictions
Another useful restriction place sets restrict cardinalities.
special case, consider set one element a. intersection every set
empty, able conclude every set contains a, thus intersection
sets empty. Generally, set elements, following
result.
Lemma 2 Consider finite collection l sets S={E1 , E2 , . . . , El } number < l.
Assume one set E1 elements.
\
E 6=
ES
iff intersection E1 sets empty.
Proof. necessary condition immediate.
prove sufficient condition, show intersection E1
k (m k l 1) sets empty induction k. k = m, lemma
true according assumption. Assuming intersection E1
k 1 ( m) sets empty, show intersection E1 k
sets empty. Without loss generality, subscripts k sets numbered
2 k + 1. 2 k + 1, let Ai intersection E1 k sets except Ei :
Ai = E1 . . . Ei1 Ei+1 . . . Ek+1 .
First, show contradiction exist i, j 2..k + 1, 6= j
Ai Aj 6= . Assume Ai Aj = distinct j. According construction
Ai s,
[
E1
Ai ,
i2..k+1

446

fiSet Intersection Consistency Constraint Networks

|Ai | 1 induction assumption. Hence,
X
|E1 |
|Ai | k > m,
i2..k+1

contradicts |E1 | m.
Since Ai Aj 6= i, j 2..k + 1, 6= j,
\
Ei 6= .
Ai Aj =
i1..k+1

2
lemma leads following corollary intersection every + 1 sets
empty.
Corollary 1 (Small Set Intersection) Consider finite collection l sets
number < l. Assume one set elements.
\
E 6=
ES
iff intersection + 1 sets empty.
specialized versions (Zhang & Yap, 2003) Lemma 2
existing works van Beek Dechter (1997) David (1993) based.
sets concern cardinality larger certain number, intersection
sets empty conditions. reader may refer Large Sets
Intersection lemma (Zhang & Yap, 2003) details.

4. Set Intersection Consistency
section, first relate consistency constraint networks set intersection. Using
result, present proof schema allows us study relationship local
global consistency properties set intersection.
Underlying concept k-consistency whether instantiation variables
extended new variable relevant constraints new variable
satisfied. relevant constraint variable xi respect constraint contains
xi variables . Given instantiation , relevant constraint allows
set (possibly empty) values new variable. call set extension set.
satisfiability relevant constraints depends whether intersection extension
sets non-empty (see Lemma 3).
Definition 3 Given constraint cSi , variable x Si , instantiation Si {x},
extension set x respect cSi defined
Ei,x (a) = {b Dx | (a, b) satisf ies cSi }.
extension set trivial empty; otherwise non-trivial.
447

fiZhang & Yap

Recall Dx refers domain variable x. Throughout paper, often
case instantiation {x} already given, {x} superset
Si {x}. Let b instantiation obtained restricting variables
Si {x}. ease presentation, continue use Ei,x (a), rather Ei,x (b), denote
extension b x constraint cSi . make presentation easy follow,
three parameters i, a, x may omitted expression hereafter whenever
clear context. example, given instantiation new variable
x, emphasize different extension sets respect different constraints cSi , write
Ei instead Ei,x (a) simply denote extension set.
Example 3 Consider network variables {x1 , x2 , x3 , x4 , x5 }:
cS1 =
cS2 =
cS3 =
cS4 =
D1 = D4

{(a, b, d), (a, b, a)}, S1 = {x1 , x2 , x3 };
{(b, a, d), (b, a, b)}, S2 = {x2 , x4 , x3 };
{(b, d), (b, c)},
S3 = {x2 , x3 };
{(b, a, d), (b, a, a)}, S4 = {x2 , x5 , x3 };
= D5 = {a}, D2 = {b}, D3 = {a, b, c, d}.

Let = (a, b, a) instantiation variables = {x1 , x2 , x4 }. relevant constraints
x3 cS1 , cS2 , cS3 . cS4 relevant since contains x5 outside . extension
sets x3 respect relevant constraints are:
E1 (a) = {d, a}, E2 (a) = {d, b}, E3 (a) = {d, c}.
intersection extension sets empty, implying extended
satisfy relevant constraints cS1 , cS2 cS3 .
Let = (b, c) instantiation {x2 , x3 }. E1,x1 (a) = thus trivial.
words, trivial extension set, instantiation extended satisfy
constraint concern.
relationship k-consistency set intersection characterized following lemma.
Lemma 3 (Set Intersection Consistency; Lifting) constraint network R kconsistent consistent instantiation (k 1) distinct variables
= {x1 , x2 , . . . , xk1 }, new variable xk ,
\
Eij 6=
j1..l

Eij extension set xk respect cSij , cSi1 , . . . , cSil relevant
constraints.
Proof. follows directly definition k-consistency Section 2
definition extension set. 2
insight behind lemma examine consistency perspective set
intersection.
448

fiSet Intersection Consistency Constraint Networks

Example 4 Consider Example 3. would like check whether network 4consistent. Consider instantiation again. trivial consistent instantiation
since network doesnt constraint among variables . extend x,
need check first three constraints cS1 cS3 . extension feasible
intersection E1 , E2 , E3 empty. show network 4-consistent,
exhausting consistent instantiations three variables. Conversely, know
network 4-consistent, immediately say intersection three extension
sets x empty.
usefulness lemma allows consistency information obtained
intersection extension sets, vice versa. point view consistency
set intersection, results set intersection properties, including Section 3,
lifted get various consistency results constraint network following
proof schema.
Proof Schema
1. (Consistency Set) certain level consistency constraint network,
derive information intersection extension sets Lemma 3.
2. (Set Set) local intersection information sets, information may
obtained intersection sets.
3. (Set Consistency) new information intersection extension sets,
higher level consistency obtained Lemma 3.
4. (Formulate conclusion consistency constraint network). 2
proof schema, step 1 (consistency set), step 3 (set consistency), step 4
straightforward many cases. So, Lemma 3 also called lifting lemma
set intersection result (step 3), easily consistency results network
(step 4). proof schema establishes direct relationship set intersection
consistency properties constraint network.
following sections, demonstrate set intersection properties
proof schema used obtain new results consistency constraint network.

5. Global Consistency Tree Convex Constraints
notion extension set plays role bridge restrictions set(s)
properties special constraints. section, consider constraints arising
tree convex sets (Lemma 1). constraint tree convex extension sets respect
constraint tree convex.
Definition 4 constraint cS tree convex respect xi tree Ti Di
sets
= {ES,xi | ES,xi non-trivial extension instantiation {xi }}
tree convex Ti . constraint cS tree convex tree union
domains variables S, tree convex respect every x .
Example 5 Tree convex constraints occur relationship among
values variable. Consider constraint accessibility set facilities
449

fiZhang & Yap

set persons. personnel include network engineer, web server engineer, application
engineer, team leader. relationship among staff team leader
manages rest, forms tree structure shown Figure 2(b). different
accessibilities system includes basic access, access network routers, access
web server, access file server. order access routers servers,
one basic access right, implying tree structure (Figure 2(c)) access
rights. constraint team leader able access facilities
engineer access corresponding facility (e.g., web server engineer access
web server). tree convex constraint shown Figure 2(a) rows
named initials engineers columns initials access rights.
tree union personnel accessibilities obtained respective
trees (in Figure 2(b) (c)) adding edge, say web server leader. Note
constraint Figure 2(a) row convex.

n
w

l

r
*

w

f

*
*

*

(a)

*
*

b
*
*
*
*

leader

network
engineer

web application
engineer engineer routers

(b)

basic access

web
server

file
server

(c)

Figure 2: tree convex constraint accessibilities staffs
Example 6 Tree convex constraints also used model scene labeling problems
naturally shown Zhang Freuder (2004).
Definition 5 constraint network tree convex exists tree union
variable domains constraints tree convex .
Tree convex constraints generalize row convex constraints introduced van Beek
Dechter (1995).
Definition 6 constraint cS row convex respect x sets
= {ES,x | ES,x non-trivial extension instantiation {x}}
tree convex tree node one child. tree called
total ordering. constraint cS row convex if, total ordering union
involved domains, row convex respect every x S.
Example 7 constraint c Example 5 row convex, b (basic access)
neighbor r (routers), w (web server), f (file server). However, total ordering,
value neighbor two values. Hence, c row convex
tree convex.
property set intersection tree convex sets proof schema,
following consistency results tree convex constraints.
450

fiSet Intersection Consistency Constraint Networks

Theorem 1 (Tree Convexity) Let R network constraints arity r
strongly 2(r 1) + 1 consistent. R tree convex globally consistent.
Proof. network strongly 2(r 1) + 1 consistent assumption. prove
network k consistent k {2r, . . . , n}.
Consider instantiation k 1 variables new variable x. Let
number relevant constraints l. relevant constraint, one extension set
x. So, l extension sets. intersection l sets empty,
value x extended instantiation satisfies relevant constraints.
(Consistency Set) Consider two l extension sets: E1 E2 . two
corresponding constraints involve 2(r1)+1 variables since arity constraint
r two constraints x variable. consistency lemma,
R (2(r 1) + 1)-consistent implies intersection E1 E2 empty.
(Set Set) Since relevant constraints tree convex given tree,
extension sets x tree convex. Henceforth, fact every two extension
sets intersect shows intersection l extension sets empty, tree
convex sets intersection lemma.
(Set Consistency) consistency lemma, R k-consistent. 2
Since row convex constraint tree convex, result generalizes consistency result
row convex constraints reported van Beek Dechter (1995). interesting
observe latter lifted set intersection results convex sets (Zhang
& Yap, 2003).
question raised Theorem 1 efficient check whether constraint
network tree convex. Yosiphon (2003) proposed algorithm recognize tree
convex constraint network polynomial time.

6. Consistency Tightness Constraints
section, present various consistency results networks m-tight
constraints.
6.1 Global Consistency Weakly Tight Networks
tightness constraints related consistency constraint network
van Beek Dechter (1997). m-tightness constraint characterized
cardinality extension sets following way.
Definition 7 (van Beek & Dechter, 1997) constraint cSi m-tight respect x Si
iff instantiation Si {x},
|Ei,x | |Ei,x | = |Dx |.
constraint cSi m-tight iff m-tight respect every x Si .
Given instantiation, extension set respect x domain
variable x, i.e., |Ei,x | = |Dx |, instantiation supported values x thus
easy satisfiable. Hence, definition above, instantiations affect
m-tightness constraint.
451

fiZhang & Yap



x




b

b

c

c

.......
.......
....... ............
....... ............
.....
.....
...
.
...
...
...............................................................................................................
..
.............
.
.
...
.
.
.
.
.
.......
... ...............
...
...
............ ..................... ....
...
...
.
.
.
.
.
....
.
...
...
....... ................... ...
.
.
.
.
.
.
.
.
...
.
.............
... ...........
...
.
.
.
.
.
.
.
.
...
.
.
.
.....
..
.......
...
....
.
........... ...
...
... ............
..
.
.
..
....
.
.
...
.
.
.
.
..
.
.
.
.
.
.
.
.
.
.
.
.
........ ...
...
.
.
.
.
.
..
.
.
.
.
.
.
.
.
.
.
.
...
...
.......
...
...
.........................
...
..
...
...
.................
...
...
...
.....
...
...
.....
.
.
.
.
.
.
.
.
.
.
.
..................
..................

Figure 3: constraint cxy 2-tight 3-tight
Example 8 Consider constraint cxy Figure 3 Dx = Dy = {a, b, c}. edge
graph denotes ends allowed cxy . verified values
x, extension sets cardinality 2, values y, extension sets
cardinality 1 3. Hence, cxy said 2-tight 3-tight 1-tight.
specially interested following tightness.
Definition 8 constraint cSi properly m-tight respect x Si iff instantiation Si {x},
|Ei,x | m.
constraint cSi properly m-tight iff properly m-tight respect every x Si .
constraint m-tight properly m-tight. converse might true.
example, constraint x y, x {1, 2, . . . , 10} {1, 2, . . . , 10}, 9-tight
properly 9-tight. properly 10-tight since |Ex (10)| = 10 = 10.
Next, define special constraint network allows us make accurate
connection tightness constraints consistency network.
Definition 9 constraint network weakly m-tight level k iff every set variables
{x1 , x2 , . . . , xl }(k l < n) new variable x, exists properly m-tight constraint
among relevant constraints x respect {x1 , x2 , . . . , xl }.

x1

x2

y1

x3

x4

y3

y2

y4
(b)

(a)

Figure 4: Two constraint networks. thin edge represents properly m-tight constraint
thick one represents non properly m-tight constraint

452

fiSet Intersection Consistency Constraint Networks

Example 9 network Figure 4(a) weakly tight level 3 three
variables fourth variable, one relevant constraints properly m-tight.
network Figure 4(b) weakly tight level 3 since {y1 , y3 , y4 } y2 , none
relevant constraints cy1 y2 cy4 y2 properly m-tight.
small set intersection corollary (Corollary 1), following consistency
result weakly m-tight network.
Theorem 2 (Weak Tightness) constraint network R constraints arity
r strongly ((m+1)(r1)+1)-consistent weakly m-tight level ((m+1)(r1)+1),
globally consistent.
Proof. Let j = (m+1)(r1)+1. constraint network R shown k-consistent
k (j < k n).
Let = {x1 , . . . , xk1 } set k 1 variables, instantiation
variables . Consider additional variable xk . Without loss generality, let
relevant constraints cS1 , . . . , cSl , Ei extension set xk respect
cSi l.
(Consistency Set) Consider + 1 l extension sets. corresponding
+ 1 constraints contain (m + 1)(r 1) + 1 variables including xk . Since R
((m+1)(r1)+1)-consistent, set intersection consistency lemma, intersection
+ 1 extension sets empty.
(Set Set) network weakly m-tight level ((m + 1)(r 1) + 1). So, must
properly m-tight constraint among relevant constraints cS1 , . . . , cSl . Let cSi .
know extension set |Ei | m. Since intersection every + 1 extension
sets empty, l extension sets share common element small set intersection
corollary.
(Set Consistency) lifting lemma, R k-consistent. 2
similar fashion, main tightness result van Beek Dechter (1997),
constraints required m-tight, lifted small sets intersection
corollary Zhang Yap (2003). uniform treatment lifting set intersection results
consistency results absent existing works (e.g., Dechter, 1992; van Beek &
Dechter, 1995, 1997; David, 1993).
tightness result van Beek Dechter (1997) requires every constraint
m-tight. weak tightness theorem, hand, require constraints
properly m-tight. following example illustrates difference.
Example 10 weakly m-tight network, interested topological structure.
Thus omitted domains variables here. Consider network five variables
labeled {1, 2, 3, 4, 5}. network, pair variables three variables,
constraint. Assume network already strongly 4-consistent.
Since network already strongly 4-consistent, simply ignore instantiations
less 4 variables. introduce level network weakly
m-tight. interesting level 4. Table 1 shows relevant constraints
possible extension four instantiated variables one. first row, 1234 5
453

fiZhang & Yap

Extension
1234 5,
2345 1,
3451 2,
4512 3,
5123 4,

125*,
231 ,
132 ,
123 ,
124 ,

135 ,
241 ,
142 ,
143*,
134*,

145 ,
251*,
152*,
153 ,
154 ,

Relevant constraints
235, 245, 345, 15+,
341, 351, 451, 21 ,
342, 352, 452, 12 ,
243, 253, 453, 13 ,
234, 254, 354, 14 ,

25 ,
31 ,
32+,
23+,
24 ,

35 ,
41 ,
42 ,
43 ,
34+,

45
51+
52
53
54

Table 1: Relevant constraints extending instantiation four variables new variable

stands extending instantiation variables {1, 2, 3, 4} variable 5. Entries
second column denote constraint. example, 125 denotes c125 . constraints
{1, 2, 5} {1, 3, 4} (suffixed * table) properly m-tight, network weakly
m-tight level 4. Alternatively, constraints {1, 5}, {2, 3} {3, 4} (suffixed +)
properly m-tight, network also weakly m-tight. tightness result van
Beek Dechter (1997) requires binary ternary constraints m-tight.
6.2 Making Weakly Tight Networks Globally Consistent
Consider weak tightness theorem previous section. Generally, weakly m-tight
network might level local consistency required theorem. tempting
enforce level consistency network make globally consistent. However,
procedure may result constraints higher arity.
Example 11 Consider network variables {x, x1 , x2 , x3 }. Let domains x1 , x2 , x3
{1, 2, 3}, domain x {1, 2, 3, 4}, constraints variables
take different values: x 6= x1 , x 6= x2 , x 6= x3 , x1 6= x2 , x1 6= x3 , x2 6= x3 . network
strongly path consistent. checking 4-consistency network, know
instantiation (1, 2, 3) {x1 , x2 , x} consistent extended x3 . enforce 4-consistency, necessary introduce ternary constraint {x1 , x2 , x} make
(1, 2, 3) longer valid instantiation.
make new network globally consistent, newly introduced constraints
higher arity may turn require higher local consistency accordance Theorem 2.
Therefore, difficult predict exact level consistency (variable based) enforce
network make globally consistent.
section, relational consistency used make constraint network globally
consistent.
Definition 10 (van Beek & Dechter, 1997) constraint network relationally m-consistent
iff given (1) distinct constraints cS1 , . . . , cSm , (2) x
i=1 Si , (3)

consistent instantiation variables (i=1 Si {x}), exists extension
x extension consistent relations. network strongly
relationally m-consistent relationally j-consistent every j m.
454

fiSet Intersection Consistency Constraint Networks

Variables longer concern relational consistency. Instead, constraints
basic unit consideration. Intuitively, relational m-consistency concerns whether
constraints agree every one shared variables. makes sense different
constraints interact exactly shared variables.
Relational 1-, 2-consistency also called relational arc, path consistency,
respectively.
Using relational consistency, able obtain global consistency enforcing local
consistency network.
Proposition 4 weak m-tightness level k constraint network preserved
process enforcing relational consistency network.
Proof. Let R constraint network relational consistency enforcing R1
network consistency enforcing. Clearly, R R1 set variables.
Consider set variables {x1 , x2 , . . . , xl } (k l < n) new variable x. Since
R weakly m-tight level k, exists properly m-tight constraint c among
relevant constraints x respect {x1 , x2 , . . . , xl }. Enforcing relational consistency
constraint network tighten constraint. So, proper m-tightness c
preserved. Hence, R1 weakly m-tight level k. 2
main result subsection.
Theorem 3 constraint network weakly m-tight level (m + 1)(r 1) + 1, r
maximal arity constraints network, globally consistent made
strongly relationally (m + 1)-consistent.
Proof. Proposition 4, network still weakly m-tight (m + 1)(r 1) + 1
enforcing strong relational (m + 1)-consistency it. Let r1 maximal arity
constraints new network consistency enforcing. Clearly, r1 r. So, network
m-tight (m + 1)(r1 1) + 1 Proposition 6. theorem follows immediately
Theorem 8 Section 7. 2
implication theorem long certain properly m-tight constraints certain combinations variables, network made globally consistent
enforcing relational (m + 1)-consistency.
following observation weak m-tightness network.
Proposition 5 constraint network weakly m-tight level constraint
every two variables network properly m-tight.
Proof. Consider level k, set variables = {x1 , x2 , . . . , xl }(k l n),
new variable x
/ . Since constraint two variables properly m-tight,
constraint c{x1 ,x} x1 x properly m-tight. Therefore, properly m-tight
constraint c{x1 ,x} among relevant constraints instantiation . 2
observation shows proper m-tightness constraints every two
variables sufficient determine level local consistency needed ensure global
consistency constraint network.
Remark. Proposition 5 assumes constraint every two variables.
constraint two variables, universal constraint introduced.
455

fiZhang & Yap

case, enforce path consistency constraint network make binary
constraints tighter lower level relational consistency needed make network
globally consistent.
6.3 Properties Weakly Tight Constraint Networks
Since weakly m-tight constraint network global consistency achieved
local consistency, interesting important investigate conditions network
weakly m-tight. Although Proposition 5 shows sufficient condition, requires every
binary constraint tight. see Example 9(a), required number
tight constraints constraint network weakly tight reduced.
subsection focused understanding relationship number tight
constraints weak tightness constraint network.
strong relationship among different levels weak tightness network.
Proposition 6 constraint network weakly m-tight level k m, weakly
m-tight level j > k.
Proof. j > k, prove network weakly tight level j. is,
set variables = {x1 , . . . , xj }(k j < n) new variable x, show
exists m-tight relevant constraint x respect . Since network weakly
tight k < j, exists m-tight relevant constraint x respect subset
. constraint still relevant x respect , thus one look for. 2
following, present two results sufficient conditions constraint network
weakly m-tight.
Theorem 4 Given constraint network (V, D, C) number m, every x V ,
least n 2 properly m-tight binary constraints it, network weakly
m-tight level 2.
Proof. two variables {x, y} third variable z, relevant constraints
z respect {x, y} cxz cyz . know number relevant binary
constraints z respect V n 1. n 2 properly m-tight means
either cxz cyz must properly m-tight. 2
fact, weak tightness higher level, need fewer constraints m-tight
shown following result.
Theorem 5 constraint network (V, D, C) weakly m-tight level k every x V ,
least n k properly m-tight binary constraints it.
Proof. set k variables new variable z, show
properly m-tight relevant constraint z respect . Otherwise, none k
binary constraints z properly m-tight. Since total number relevant binary
constraints z n 1, number properly m-tight binary constraints z
(n1)k, contradicts z involved nk properly m-tight binary constraints.
2
456

fiSet Intersection Consistency Constraint Networks

result reveals constraint network weakly tight level k, could
need n(n k + 1)/2 properly m-tight binary constraints, contrast result
Theorem 3 binary constraints required properly m-tight.
immediate question is: minimum number m-tight constraints required
network weakly tight? answered following result weak
tightness level 2.
Theorem 6 Given number m, constraint network weakly m-tight level 2,
needs least
n(n 1)/2 2bn/3c n = 0, 1 (mod 3)
otherwise
(n 2)(3n 1)/6
m-tight binary ternary constraints.
Proof.
Given network, weak m-tightness level 2 depends tightness
binary ternary constraints. Among weakly m-tight (at level 3) constraint
networks n variables, let R1 network minimal set properly m-tight
binary ternary constraints.
following exposition, constraint denoted scope. example,
use {u, v, w} {u, v} denote ternary constraint c{u,v,w} binary constraint cuv
respectively. constraint non-properly-m-tight properly m-tight.
proof consists three steps.
Step 1. preserving weak m-tightness R1 number properly mtight constraints R1 , modify, necessary, proper m-tightness constraints
R1 that, properly weak m-tight constraint {u, v, w}, none binary
constraints {u, v}, {v, w}, {u, w} properly m-tight.
modify proper m-tightness constraint c R1 remove c network
introduce new constraint set variables c desirable proper
m-tightness.
claim that, properly m-tight constraint {u, v, w}, one {u, v},
{v, w}, {u, w} properly m-tight. Otherwise, least two properly mtight, means {u, v, w} modified properly m-tight, contradicting
minimality number properly m-tight constraints R1 .
Assume {u, v} properly m-tight. Since {u, v, w} properly m-tight,
reason {u, v} properly m-tight. reason exists another
variable z one {u, z} {v, z} properly m-tight, {u, v, z}
properly m-tight, too. See Figure 5. Without loss generality, let {u, z} properly mtight, implying constraint {v, z} properly m-tight. constraint {z, v, w}
properly m-tight {v, z} {v, w} properly m-tight.
modify constraints {u, v, w} {z, v, w} properly m-tight
modify constraints {z, v} {v, w} properly m-tight. modification preserves
number properly m-tight constraints R1 weak m-tightness R1 .
Step 2. preserving weak m-tightness R1 number properly m-tight
constraints R1 , next modify, necessary, proper m-tightness constraints
R1 two properly m-tight ternary constraints share variables.
457

fiZhang & Yap

....................
.........
......
......
....... ................................
....
....
......
.....
..
..................................
.
.........
....... .... ..... .. ....
........
....
... ........................
........... .........
.
....
.
......
... ...............
..
...
.
. . ..
.
...
........
..
...
...
....
......
...
.....
....
.
.......
.
.
.
.
.......................

z

u

w

v

Figure 5: circle represents properly m-tight ternary constraint {u, v, w}. edge
two variables indicates binary constraint. tick besides edge means
properly m-tight cross means not.

Case 1: Two properly m-tight constraints {u, v, w} {u, v, z} share two variables
{u, v}. See Figure 6(a). Since {w, u} {u, z} properly m-tight (in terms step
1), {w, u, z} properly m-tight. Since {w, v} {v, z} m-tight, {w, v, z}
m-tight.
modify four ternary constraints properly m-tight modify four
binary constraints {w, u}, {u, z}, {z, v} {v, w} properly m-tight. preserves
weak m-tightness R1 number properly m-tight constraints R1 .

w
v

u

x

z

z

v
w

w

v

u

u

v

u

w

x





(b)

(a)

Figure 6: dotted ellipse together three variables inside represents ternary
constraint. (a) Left: Two ternary constraints share two variables {u, v}. Right:
ternary constraints properly m-tight. (b) Left: Two ternary
constraints share one variable w. Right: ternary constraints
properly m-tight.
Case 2: Two properly m-tight constraints {u, v, w}, {w, x, y} share one variable
w. Since {u, w} {w, x} properly m-tight, {u, w, x} properly m-tight.
Since {v, w} {w, y} properly m-tight, {v, w, y} properly m-tight.
Similarly, {u, w, y} {v, w, x} properly m-tight. Now, modify four
binary constraints {u, w}, {w, x}, {v, w}, {w, y} properly m-tight six
ternary constraints non-properly-m-tight, new network still weakly m-tight
fewer m-tight constraints. contradicts minimality number properly
m-tight constraints R1 . Hence, case 2 possible.
Step 3. result first two steps, network R1 , scopes properly
m-tight ternary constraints disjoint, binary constraint two variables
properly m-tight ternary constraint properly m-tight.
458

fiSet Intersection Consistency Constraint Networks

Let B (and respectively) set properly m-tight binary (and ternary
respectively) constraints R1 .
Assume |T | = k. Since difficult count B, count maximum number
non-properly-m-tight binary constraints R1 . 3k non-properly-m-tight binary
constraints due . non-properly-m-tight binary constraints
variable variable outside . Let V 0 variables outside .
|V 0 | = n 3k. non-properly-m-tight constraints fall variables
V 0 . Since R1 weakly tight level 2, two non-properly-m-tight constraints
variable V 0 . Hence, (n 3k)/2 non-properly-m-tight constraints
n 3k even, otherwise (n 3k 1)/2 ones. number, denoted ,
properly m-tight constraints R1 would sum cardinality B:
= k + (n(n 1)/2 3k b(n 3k)/2c) = n(n 1)/2 2k b(n 3k)/2c.
fact minimal implies k maximized. n multiple 3,
number properly m-tight constraints n(n 1)/2 2n/3; n 1 multiple
3, number n(n 1)/2 2(n 1)/3; otherwise number (n 1)(3n 1)/6. 2
result shows concept k-consistency still need significant
number constraints properly m-tight predict global consistency network
terms constraint tightness.
6.4 Dually Adaptive Consistency
main purpose characterization weak m-tightness network help identify
consistency condition solution network found without backtracking, i.e., efficiently. studied constraint tightness concept k-consistency
previous subsections. subsection, introduce dually adaptive consistency
achieve backtrack free search taking account tightness constraints
topological structure network.
idea adaptive consistency (Dechter & Pearl, 1987) enforce necessary
level consistency part network ensure global consistency. assumes
ordering variables. variable x, requires consistent instantiation
relevant variables x consistently extensible x. variables
play direct role x thus ignored dealing x.
first introduce notations used adaptive consistency.
width variable respect variable ordering number constraints
involving x variables x. See Figure 7 example.
Given network, variable ordering, variable x, directionally relevant constraints x involving x variables x. following, DR(x)
used denote directionally relevant constraints x, used denote variables
occurring constraints DR(x).
constraints DR(x) consistent x if, consistent instantiation {x}, exists u Dx (a, u) satisfies constraints
DR(x).
next define adaptive consistency network.

459

fiZhang & Yap

x

1
...... ..........
.....
....
...
.....
...
...
.
.
.
...
..
...
...
.. ........ 2
.
...
.... ....
.
... ....
...
..
.... ...
.
3 .....
... ...
.
... ...
....
....
...
...... ..........
...
.
...
...
4
...
.....
.....
......

x
x
x

x5

Figure 7: variables {x1 , x2 , . . . , x5 } ordered according subscripts. example, x1 x2 . width x2 1.

Definition 11 Given constraint network ordering variables, network
adaptively consistent variable x, directionally relevant constraints
consistent x.
adaptive consistency presented algorithm Dechter (2003) although,
purpose paper, prefer declarative characterization.
adaptively consistent network, solution found without backtracking.
Proposition 7 Given constraint network ordering variables, backtrack
free search ensured network adaptively consistent.
Proof. Assume found consistent instantiation first k variables (in terms
given ordering). consistently extended xk+1 directionally
relevant constraints xk+1 consistent xk+1 . 2
network adaptively consistent, algorithm Dechter (2003, p. 105)
used enforce adaptive consistency it.
Adaptive consistency accurate estimating local consistency
ensures global consistency, also makes intuitive algorithms enforce consistency
find solution.
knowledge constraint tightness presented previous subsections,
know network adaptively consistent, sufficient make sure
some, all, directionally relevant constraints variable consistent.
position define dually adaptive consistency constraint network.
Definition 12 Consider constraint network ordering variables.
variable x network, let cx one tightest directionally relevant constraints
x cx properly mx -tight. network dually adaptively consistent
1) variable x whose width greater mx , directionally relevant
constraints consistent it,
2) variable x whose width greater mx , cx consistent every
mx directionally relevant constraints x.
Thanks set intersection result Lemma 2, main result dually
adaptive consistency.
460

fiSet Intersection Consistency Constraint Networks

Theorem 7 Given constraint network ordering variables, backtrack free
search ensured dually adaptively consistent.
Proof. need prove network adaptively consistent:
variable x, directionally relevant constraints DR(x) consistent x. Let
variables involved DR(x). Consider consistent instantiation {x}. show
exists u Dx (a, u) satisfies constraints DR(x). Let l number
constraints DR(x), let cx one tightest constraint DR(x) proper
tightness mx . constraint ci DR(x), let extension set x ci Ei .
sufficient show
c DR(x) Ei 6= .


know cx consistent every mx constraints. Hence, Ex , extension set
cx , intersects every mx extension sets a. Lemma 2 implies
c DR(x) Ei 6= .


2
theorem, need tightest directionally relevant constraint
variable, totally n 1 constraints, predict global consistency network.
could considered significant improvement results previous two
subsections.
Compared result Dechter Pearl (1987), theorem also provides
lower level (the smaller tightness width) consistency ensuring global consistency.
constraint network dually adaptively consistent respect variable
ordering, made enforcing required consistency variable,
reverse order given variable ordering. make procedure efficient,
chose better variable ordering, depending topological structure
network tightness constraints.

7. Tightness Convexity Revisited
consistency results derived small set intersection tree convex set intersection
Section 5 Section 6.1 rephrased relational consistency setting.
example, new version weak tightness based relational consistency given follows.
Theorem 8 (Weak Tightness) constraint network R constraints arity
r strongly relationally (m + 1)-consistent weakly m-tight level (m + 1)(r
1) + 1, globally consistent.
Proof. Let j = (m + 1)(r 1) + 1. constraint network R shown
k-consistent k (j < k n).
Let = {x1 , . . . , xk1 } set k 1 variables, consistent instantiation
variables . Consider new variable xk . Without loss generality, let cS1 , . . . , cSl
relevant constraints xk , Ei extension set xk respect cSi
l.

461

fiZhang & Yap

(Consistency Set) Consider + 1 l extension sets. Since R relationally
(m + 1)-consistent, intersection + 1 extension sets empty.
(Set Set) network weakly m-tight. So, must properly m-tight
constraint relevant constraints cS1 , . . . , cSl . Let cSi . extension set |Ei | m.
Since every + 1 extension sets non-empty intersection, l extension sets
share common element small set intersection result (Corollary 1).
(Set Consistency) lifting lemma, R k-consistent. 2
Compared weak tightness theorem Section 6.1, exposition result
neater proof simpler.
completeness, also include new version tree convex theorem using
relational consistency. proof omitted since simplified version one
Section 5 hinted proof above.
Theorem 9 (Tree Convexity) Let R tree convex constraint network. R globally
consistent strongly relationally path consistent.

8. Conclusion
lifting lemma proof schema, shown set intersection results
easily lifted consistency results constraint network. advantages
approach studying consistency.
Firstly, although approach offer completely new way prove consistency results, provide uniform way understand many seemingly different results
impact convexity tightness global consistency. addition results
shown here, results also obtained easily lifting lemma proof
schema. example, work David (1993) obtained lifting corollary
Lemma 2 (Zhang & Yap, 2003). work Sam-Haroud Faltings (1996) convex
constraint networks continuous domains lifted Hellys theorem (Eckhoff,
1993) intersection convex sets Euclidean spaces.
Secondly, establishment relationship set intersection consistency
constraint network makes easier communicate consistency results researchers outside constraint network community. also made possible
contribute consistency results exploiting knowledge set intersection properties.
importantly, approach singles fact set intersection properties play
fundamental role determining consistency constraint network. perspective
helps us focus properties set intersection discover generalize intersection
properties tree convex sets sets cardinality restrictions. corresponding
consistency results extended understanding convexity tightness constraints since Dechter van Beeks work (1995, 1997). identify new class tree
convex constraints global consistency ensured certain level local consistency. generalizes row convex constraints van Beek Dechter (1995). also
show weakly m-tight constraint network made globally consistent enforcing
local consistency. type result tightness new. Detailed study carried
constraint network weakly m-tight. make full use tightness
constraints, propose dually adaptive consistency exploits topology
462

fiSet Intersection Consistency Constraint Networks

semantics constraint network, results relation set
intersection consistency. dually adaptive consistency, topology network
tightest relevant constraint variable determine local consistency
ensures backtrack-free search.

Acknowledgments
indebted Dr. Peter van Beek Dr. Fengming Dong helpful discussions.
constructive comments anonymous referees various versions paper
improved quality. material based works partially supported grant
Academic Research Fund National University Singapore Science
Foundation Ireland Grant 00/PI.1/C075. materials paper appeared
Proceedings International Joint Conference Artificial Intelligence 2003 (Zhang
& Yap, 2003) Proceedings Principles Practice Constraint Programming
2004 (Zhang, 2004).

References
David, P. (1993). functional bijective constraints make CSP polynomial.
Proceedings Thirteenth International Joint Conference Artificial Intelligence,
Vol. 1, pp. 224229 Chambery, France. IJCAI, Inc.
Dechter, R. (1992). local global consistency. Artificial Intelligence, 55, 87107.
Dechter, R. (2003). Constraint Processing. Morgan Kaufmann, San Francisco, CA.
Dechter, R., & Pearl, J. (1987). Network-based heuristics constraint satisfaction problems. Artificial Intelligence, 34, 138.
Eckhoff, J. (1993). Helly, Radon, Caratheodory type theorems. Gruber, P. M.,
& Wills, J. M. (Eds.), Handbook Convex Geometry, pp. 389448. North Holland,
Amsterdam.
Freuder, E. (1978). Synthesizing constraint expressions. Communications ACM, 21 (11),
958966.
Freuder, E. (1982). sufficient condition backtrack-free search. Journal ACM,
29 (1), 2432.
Jeavons, P. G., Cohen, D. A., & Gyssens, M. (1997). Closure properties constraints.
Journal ACM, 44 (4), 527548.
Mackworth, A. K. (1977). Consistency networks relations. Artificial Intelligence, 8 (1),
118126.
Montanari, U. (1974). Networks constraints: fundamental properties applications.
Information Science, 7 (2), 95132.
Sam-Haroud, D., & Faltings, B. V. (1996). Solving non-binary convex CSPs continous
domains. Proceedings International Conference Principles Practice
Constraint Programming 1996, pp. 410424 Cambridge, Massachusetts. Springer.

463

fiZhang & Yap

Schaefer, T. J. (1978). complexity satisfiability problems. Proceedings 10th
ACM Symposium Theory Computing, pp. 216226.
van Beek, P., & Dechter, R. (1995). minimality global consistency row-convex
constraint networks. Journal ACM, 42 (3), 543561.
van Beek, P., & Dechter, R. (1997). Constraint tightness looseness versus local
global consistency. Journal ACM, 44 (4), 549566.
Yosiphon, G. (2003). Efficient algorithm identifying tree convex constraints. Manuscript.
Zhang, Y. (2004). tightness constraints. Proceedings Principles Practice
Constraint Programming 2004, pp. 777781 Toronto, Canada. Springer.
Zhang, Y., & Freuder, E. C. (2004). Tractable tree convex constraints. Proceedings
National Conference Artificial Intelligence 2004, pp. 197202 San Jose, CA, USA.
AAAI press.
Zhang, Y., & Yap, R. H. C. (2003). Consistency set intersection. Proceedings
International Joint Conference Artificial Intelligence 2003, pp. 263268 Acapulco,
Mexico. IJCAI Inc.

464

fiJournal Artificial Intelligence Research 27 (2006) 1-23

Submitted 02/06; published 09/06

Variational Inference Procedure Allowing Internal
Structure Overlapping Clusters Deterministic
Constraints
Dan Geiger

dang@cs.technion.ac.il

Computer Science Dept., Technion,
Haifa, 32000, Israel

Christopher Meek

meek@microsoft.com

Microsoft Research, Microsoft Corporation,
Redmond, WA 98052, USA

Ydo Wexler

ywex@cs.technion.ac.il

Computer Science Dept., Technion,
Haifa, 32000, Israel

Abstract
develop novel algorithm, called VIP*, structured variational approximate
inference. algorithm extends known algorithms allow efficient multiple potential
updates overlapping clusters, overcomes difficulties imposed deterministic
constraints. algorithms convergence proven applicability demonstrated
genetic linkage analysis.

1. Introduction
Probabilistic graphical models elegant framework represent joint probability distributions compact manner. independence relationships random variables
nodes graph represented absence arcs model.
intuitively appealing presentation also naturally enables design efficient generalpurpose algorithms computing marginal probabilities, called inference algorithms.
general inference problem NP-hard (Cooper, 1990; Dagum & Luby, 1993),
although many cases model small (or, precisely, small
treewidth) exact inference algorithms feasible, others time
space complexity makes use algorithms infeasible. cases fast yet
accurate approximations desired.
focus variational algorithms: powerful tool efficient approximate inference
offers guarantees form lower bound marginal probabilities.
family approaches aims minimize KL divergence distribution Q
target distribution P finding best distribution Q family distributions
inference feasible. particular, joint distribution P (X) set
discrete variables X goal compute marginal probability P (Y = y)
X. assume exact computation feasible. idea replace
P distribution Q used compute lower bound P (Y = y).
c
2006
AI Access Foundation. rights reserved.

fiGeiger, Meek & Wexler

let H = X \ . Then, using Jensens inequality get following bound:
log P (y) = log

X
h

Q(h)

P (y, h) X
P (y, h)

Q(h) log
= D(Q(H) || P (Y = y, H))
Q(h)
Q(h)
h

D( || ) denotes KL divergence two probability distributions. quantity D(Q || P ) often called free-energy P Q possibly un-normalized
distributions. Variational techniques aim choose distribution Q lower
bound high possible, equivalently, KL divergence Q(h)
P (h|Y = y) minimized.
Variational approaches mean field, generalized mean field, structured
mean field differ respect family approximating distributions
used, structural mean field approach subsuming remaining approaches
special cases. research several authors guided work: Saul & Jordan (1996),
Ghahramani & Jordan (1997), Wiegerinck (2000) Bishop & Winn (2003).
contributions paper threefold. First develop extension
algorithm Wiegerinck (2000), call vip? , allows set potentials
approximating distribution Q updated simultaneously even clusters Q overlap. Algorithm vip? N -fold faster Wiegerincks algorithm N N grid-like models
yields two orders magnitude improvement large graphs genetic linkage
analysis model large pedigrees. Note simultaneous updates first presented
phylogenic trees Jojic et al. (2004). Second, prove convergence vip? previous variational methods via novel proof method, using properties KL divergence.
Third, extend vip? allow deterministic constraints model demonstrate
applicability extension genetic linkage analysis.

2. Background
background section based primarily paper Weigerinck (2000),
turn builds pioneering works papers Saul & Jordan (1996) Ghahramani
& Jordan (1997). review provides new exposition material.
denote distributions P (x) Q(x) related un-normalized distributions
P (x) P (x) Q(x) Q(x). Let
X finite set variables x instantiation
1 Q
variables. Let P (x) = ZP (di ) di projection instantiation
x variables Di X non-negative function, commonly called
potential. constant ZP normalizes product potentials subsets {Di }Ii=1
allowed overlap. often suppress arguments potential distribution,
using instead (di ) P instead P (X).
goal find distribution Q minimizes Q
KL divergence Q P .
constrain Q form Q(x) = Z1Q j j (cj ) ZQ normalizing
constant C1 , . . . , CJ possibly overlapping subsets X, call clusters. Finding optimum Q, however, difficult. modest common goal
devising iterative converging algorithms iteration KL divergence
approximating distribution Q P decreases unless Q stationary point.
Throughout, define Q(w|u) = |W1\U | instantiations U = u Q(u) = 0.
Consequently, terms equality Q(w, u) = Q(u)Q(w|u) well defined even
2

fiA Variational Inference Procedure

P
Q(u) = 0. Moreover, convention maintains properties
W \U Q(w|u) = 1
1
1
1
Q(w, z|u) = Q(w|z, u)Q(z|u) = |W \{U Z}| |Z\U | = |{W Z}\U | . also note
Q(x) log Q(x) = 0 whenever Q(x) = 0 thus KL divergence
D(Q || P ) =

X

Q(x) log

x

Q(x)
P (x)

finite P (x) = 0 Q(x) > 0 instance x.
starting point algorithm developed Wiegerinck (2000). algorithm finds
distribution Q follows: iterates clusters Cj instantiations cj
update potentials j (cj ) = ej (cj ) via following update equation:

j (cj )

X

X

Q(ck |cj ) log k (ck ) +

{k:gkj =1} Ck \Cj

X

X

Q(di |cj ) log (di )

(1)

{i:fij =1} Di \Cj

gkj fij two indicator functions defined via gkj = 0 Q(Ck |cj ) = Q(Ck )
every instance cj Cj 1 otherwise, fij = 0 Q(Di |cj ) = Q(Di ) every instance
cj Cj 1 otherwise. Wiegerinck (2000) proved convergence algorithm stationary point using Lagrangians. Throughout call iterative procedure, Wiegerincks
algorithm.
Wiegerincks algorithm relies step algorithm compute conditional
probabilities Q(ck |cj ) Q(di |cj ) un-normalized distribution Q represented
set potentials j (cj ). accomplished inference algorithm
bucket elimination algorithm sum-product algorithm described Dechter (1999)

Q
Kschischang, Frey & Loeliger (2001) . important note Q(x) = j j (cj )
computation conditionals affected multiplying j constant
.
Wiegerincks algorithm generalizes mean field (MF) algorithm generalized
mean field (GMF) algorithm (Xing, Jordan & Russell, 2003, 2004). mean field algorithm special case Wiegerincks algorithm Cj contains single
variable. Similarly, generalized mean field algorithm special case Cj
disjoint subsets variables. Cj disjoint clusters, formula j Eq. 1
simplifies GMF equations follows (first term drops out):
j (cj )

X

X

Q(di |cj ) log (di ).

(2)

{i:fij =1} Di \Cj

term Q(di |cj ) made explicit Cj disjoint clusters (Bishop & Winn
2003). particular, set Di \ Cj partitions Dik = (Di \ Cj ) Ck Q
k = 1, . . . , J
k 6= j. Note Dik = Di Ck . Using notation, Q(di |cj ) = k Q(dki )
Q(dki ) = 1 whenever Dik = . factorization simplifies formula j
follows:
X
X X
j (cj )
Q(d1i ) . . .
Q(dJi ) log (di ).
(3)
{i:fij =1} Di1

DiJ

3

fiGeiger, Meek & Wexler

simplification achieved automatically using bucket elimination computing
j . iterated sums Eq. 3 fact buckets formed bucket elimination
Cj disjoint.
Eq. 1 requires repeated computation quantities Q(ck |cj ) Q(di |cj ). repetition significant could many indices k Q(Ck |cj ) 6= Q(Ck ),
many indices Q(Di |cj ) 6= Q(Di ). computations share many subcomputations therefore reasonable add data structure facilitate efficient
implementation function calls. particular, possible save computations
sets C1 , . . . , CJ form junction tree.
set clusters C1 , . . . , CJ forms junction tree iff exists set trees JT one node, called Cj , cluster variables Cj , every two nodes Ci
Cj JT, connected path JT, node Ck path,
Ci Cj Ck holds. set trees mean undirected graph, necessarily
connected, cycles. Note definition allows junction tree disconnected graph.

Q
Q C1 , . . . , CJ form junction tree, Q(x) decomposable form
Q(x) = j j (cj )/ e e (se ), j marginals subsets Cj X,
e marginals intersections Se = Ci Cj , one two neighboring clusters
junction tree (Jensen 1996).
Wiegerinck (2000) enhanced basic algorithm maintains
consistent
junction
P
P
tree JT distribution Q(x). Consistency means Cj \Ck j = Ck \Cj k
every two clusters. consistent junction tree, potential j (Cj ) proportional
Q(Cj ). update potential algorithm may yield inconsistent junction
tree, however, consistency maintained applying DistributeEvidence(j ) (Jensen
1996) update potential. procedure DistributeEvidence(0j ) accepts
input consistent junction tree new cluster marginal 0j Cj , updates
potential every neighboring cluster Ck Cj via
Cj \Ck

0j (cj )

Cj \Ck

j (cj )

P
0k (ck )

k (ck ) P

(4)

neighboring cluster recursively propagates update applying Eq. 4
neighbors except one update came. output procedure
consistent junction tree, clusters, 0j (possibly un-normalized)
marginal probability Q Cj , conditional probability Q(X|Cj ) remains
unchanged (Jensen 1996, pp. 74).
Wiegerincks enhanced algorithm, uses junction tree, iteratively updates
potential cluster (node junction tree), using potentials clusters
separators. However, since junction tree may consistent update,
algorithm applies procedure DistributeEvidence(j ) junction tree,
update. Note description omits normalization step Wiegerinck (2000)
needed convergence.
time consuming computation variational algorithms computing conditional probabilities form Q(ck |cj ) Q(di |cj ). distinguish among conditional probabilities follows.

4

fiA Variational Inference Procedure

Definition: conditional probability Q(A|cj ) subsumed Q set target variables subset cluster Ck Q (i.e., (A \ Cj ) Ck ).
Wiegerincks enhanced algorithm substantial computational benefits conditional probabilities subsumed. cases needed quantities Eq. 1, Q(di |cj )
Q(ck |cj ), obtained mere lookup junction tree, one call
DistributeEvidence made update.
Weigerincks basic enhanced algorithms assume structure j , namely,
algorithms hold tables j explicit entry every instantiation Cj . Since
computations Q(ck |cj ) Q(di |cj ) grow exponentially size Di Ck ,
algorithms become infeasible large cliques clusters. simplification, additional
structure j suggested Wiegerinck (2000, Section 4) form,

j (cj ) =

nj


jl (cjl ),

(5)

l=1

sets Cjl , l = 1, . . . , nj , possibly overlapping subsets Cj , cjl
projection instantiation cj variables Cjl . Using structure sufficient
hold tables subsets Cjl considerably smaller. Note j
entry instantiation cj , nj = 1 j (cj ) = j1 (cj1 ). Weigerinck uses
structure potentials j following assumptions:
Definition [SelfQ
compatibility]: distribution Q clusters Cj subsets Cjl
1
form Q(x) = ZQ j j (cj ), clusters factor according Eq. 5, self compatible
every Cj Ck set indices Njk = {l : Q(Ck |cj ) = Q(Ck |cjl )} non-empty
regardless values potentials j , cj arbitrary instantiation Cj
cjl projection cj Cjl .
Definition [Compatibility
wrt P ]: distribution Q clusters Cj subsets Cjl
Q
form Q(x) = Z1Q j j (cj ), clusters factor according Eq. 5, compatible
Q
wrt distribution P sets Di form P (x) = Z1P (di ) every Di Cj
set indices Mij = {l : Q(Di |cj ) = Q(Di |cjl )} non-empty, cj arbitrary
instantiation Cj cjl projection cj Cjl .
Note self-compatibility compatibility wrt P depend form Q
particular realization potentials j .
assumptions Weigerinck states considerable simplifications deduced, provides examples statement.
note algorithms Bishop & Winn (2003) Jojic et al. (2004) use
stronger assumption clusters Cj approximating distribution Q disjoint
Q(Ck |cj ) = Q(Ck ). assumption, implies Q(Ck |cj ) = Q(Ck |cjl )
Q(Di |cj ) = Q(Di |cjl ) every index l, relaxed requiring equalities
hold single index l (but possibly multiple indices).
5

fiGeiger, Meek & Wexler

3. Multiple Potential Update using Overlapping Clusters
section develop new algorithm, called vip? , uses additional structure
potentials offered Eq. 5 speed computations. particular, rather updatnj
ing potential jl separately, offer way update set potentials {jl }l=1
simultaneously, saving considerable computations. Furthermore, simultaneous update
enhanced using junction tree, despite fact sets {Cjl } need form
junction tree, {Cj } form junction tree.
algorithm uses definitions self compatibility compatibility wrt P , defined
earlier, following definition indices.
Definition: Let indicator function gjk (l) equal 1 single fixed index l Njk
0 indices Njk Q(Ck |cj ) 6= Q(Ck ), equal 0 otherwise. Let
indicator function fij (l) equal 1 single fixed index l Mij 0 indices
Mij Q(Di |cj ) 6= Q(Di ), equal 0 otherwise.
Algorithm vip? given Figure 1. convergence proved Section 4. proof
requires Q self-compatible, compatible wrt P , addition, satisfy (P (x) = 0)
(Q(x) = 0). Note D(Q || P ) = distributions Q satisfy last
assumption.
main improvement algorithm efficient update potentials. potentials j factorize smaller potentials jl according Eq. 5, algorithm vip?
updates jl instead updating whole potential j , done Weigerincks algorithms.
update potentials jl done vip? equivalent updating j according
Eq. 1, irrelevant constant, require compute update equation
instance cluster Cj . proposed change considerably speeds previous
algorithms.
algorithm gets input target distribution P sets Di form P (x) =
1 Q
(di ) approximating distribution Q clusters Cj self-compatible,
ZP
compatible wrt P satisfies
condition (P (x) = 0) (Q(x) = 0). Distribution Q
Q
form Q(x) = Z1Q j j (cj ) potential every cluster Cj factors according
Qnj
jl (cjl ) clusters form consistent junction tree. algorithm
j (cj ) = l=1
iterates clusters, updating potential every instantiation subsets
Cjl according Eq. 6. apply update equation, quantities Q(di |cjl ) computed
via variable propagation (Jensen, pp 69-80) junction tree. quantities
subsumed, obtained mere lookup junction tree. Then, updating
potentials subsets Cjl cluster Cj , procedure DistributeEvidence applied
make junction tree consistent respect j . Since clusters Cj form
junction tree via subsets Cjl , Eq. 4 replaced Eq. 7. convergence,
algorithm vip? outputs approximating distribution Q revised potentials.
Example 1 target distribution P N N grid pairwise potentials (see Figure 2a)
approximating family defined single row set columns grid,
augmented edges middle vertex (see Figure 2b) C7 row
grid Ci (i = 1, . . . , N = 6) columns. Using notation Xi,j denote
vertex row column j grid, cluster C7 associated N 1 subsets
6

fiA Variational Inference Procedure

Algorithm VIP? (Q,P)
Q
Q
Input: Two probability distributions P (x) = Z1P (di ) Q(x) = Z1Q j j (cj )
Qnj
initial potentials j (cj ) = l=1
jl (cjl ) form consistent junction tree, Q
self-compatible, compatible wrt P , satisfies (P (x) = 0) (Q(x) = 0).
Output:
revised set potentials jl (cj ) defining probability distribution Q via Q(x)
Q

(c
j,l jl jl ) Q stationary point D(Q || P ).
Iterate clusters Cj convergence
Step 1.
l = 1, . . . , nj :
every instantiation cjl Cjl apply following update equation:
jl (cjl )

X

X

X

Q(ck |cjl ) log k (ck ) +

{k:gjk (l)=1} Ck \Cjl

X

Q(di |cjl ) log (di ) (6)

{i:fij (l)=1} Di \Cjl

jl (cjl ) ejl (cjl )
Note: Q(di |cjl ) computed via variable propagation (Jensen, pp 69-80) junction
tree JT. However, quantities subsumed, obtained mere lookup
JT.
Step 2. Make JT consistent respect j :

DistributeEvidence(JT, j )

DistributeEvidence(JT, 0j )
Input: junction tree JT nodes Ck potentials k (ck ) =
node Cj revised potential 0j .
Output: consistent junction tree.

Qnk

l=1 kl (ckl ).

starting

initialization source(j) 0; updated {j}
(updated6= )
first element updated; updated updated\{}
neighboring nodes Ck C JT k 6= source()
P
Qn 0
C
\C
l=1 l (cl )
0km (ckm ) km (ckm ) P k Qn
C \Ck
l=1 l (cl )
single subset Ck (C Ck ) Ckm
source(k)
updated updated{k}
Figure 1: Algorithm vip?
7

(7)

fiGeiger, Meek & Wexler

(a)

(b)

(c)

Figure 2: (a) Grid-like P distribution (b) & (c) Approximating distributions Q.
C7l = {X3,l , X3,l+1 }. column cluster Cj associated 2N-4=8 subsets Cjl
Cjl = {Xl,j , Xl+1,j } N-1 subsets (l = 1, . . . , 5), Cjl = {X1,j , X3,j } l = N ,
Cjl = {XlN +4,j , X3,j } additional N-4 subsets (l = 7, 8).
choice induces self-compatible approximating distribution Q; every column cluster
Cj independent another cluster given subset contains X3,j (such Cj2 ).
addition, row cluster C7 independent every column cluster Cj given C7j .
induced distribution also compatible wrt P ; vertical edge Dv = {Xi,j , Xi+1,j }
P , distribution Q satisfies Q(Dv |ck ) = Q(Dv |ck2 ) column cluster Ck
k 6= j, Q(Dv |c7 ) = Q(Dv |c7j ). addition, horizontal edge Dh = {Xi,j , Xi,j+1 }
P , distribution Q satisfies Q(Dh |c7 ) = Q(Dh |c7j ), Q(Dh |ck ) = Q(Dh |ck2 ) k 6=
j, j + 1. Finally, edge Dh k = j, j + 1, approximating distribution satisfies
Q(Dh |ck ) = Q(Dh |ckl ) Ckl = {Xi,k , X3,k }, due additional N 3 edges added
column cluster.
Like Wiegerincks enhanced algorithm, algorithm vip? substantial computational
benefits conditional probabilities Q(di |cjl ) subsumed. cases needed
quantities, Q(di |cjl ) Q(ck |cjl ), obtained mere lookup junction tree
step 1 algorithm, one call DistributeEvidence made step 2,
demonstrated next paragraph. computational efficiency vip? achieved
even quantities Q(di |cjl ) subsumed factor subsumed probabilities.
Disjoint clusters one special case, quantities Q(di |cjl ) factor
subsumed probabilities Q(dki |cjl ), Dik = Di Ck , obtainable lookup
junction tree.
Consider Example 1 compare computational cost vip? versus Wiegerincks
basic enhanced algorithms. Assume Wiegerincks basic algorithm (Eq. 1), uses
distribution Q given Figure 2c, 35 clusters Cj0 60 sets Di . Therefore,
junction tree used, 4 (60 + 34) = 376 conditionals computed cluster Cj0
(edge) boundary grid, 94 four possible values edge
cluster Cj0 . Clearly, additional clusters introduced, shown example Figure 2b,
computational cost grows. using junction tree, done Wiegerincks enhanced algorithm, subsumed conditional probabilities, computed separately
Wiegerincks basic algorithm, computed single call DistributeEvidence.
computation covers subsets Figure 2c. conditionals sub8

fiA Variational Inference Procedure

(a)

(b)

(c)

Figure 3: target distribution P grid pairwise potentials (a). Two different
partitions grid clusters shown Figures (b) (c), contain
subsets.

sumed Q(di |cj ) horizontal edges Di contained single cluster, namely,
edges 2a 2c. factor two subsumed probabilities, one computed
single call described earlier requires second call DistributeEvidence.
example, let Di = {X1 , X2 } horizontal edge P overlap Cj0 ,
Q(x1 , x2 |c0j ) = Q(x1 |c0j , x2 )Q(x2 |c0j ). two conditionals subsumed, second
call DistributeEvidence needed obtain Q(x1 |c0j , x2 ). yields 25 calls DistributeEvidence. However, Example 1, one call DistributeEvidence sufficient
compute conditionals two adjacent horizontal edges, yielding need
15 calls. Therefore, since 4 15 = 60 calls DistributeEvidence, since
cost junction tree algorithm typically twice cost computing conditional
probabilities without using junction tree, yields 3-fold speedup Wiegerincks
enhanced algorithm versus Wiegerincks basic algorithm. edges boundary,
speedup factor less 3. size grid grows, smaller fraction edges
boundary, and, thus, speedup approaches 3-fold speedup.
significant speedup obtained using algorithm vip? clusters Cj subsets
described Figure 2b. Note additional subsets needed meet compatibility assumption vip? . Algorithm vip? makes one call DistributeEvidence
per cluster Cj non-subsumed conditional, rather every edge cluster Cj0 .
Since vip? uses N + 1 clusters Cj , speedup compared Wiegerincks enhanced
algorithm approaches N N N grid grows. O(N ) speedup confirmed
experiments section (Figure 9).
Another potential benefit vip? possibility alternating different
choices clusters contain identical subsets Cjl . simple example grid
Figure 3a, two choices illustrated Figures 3b 3c. two sets clusters update potentials j differently therefore yield better approximations
distance D(Q || P ) reduced every alternation. general, iterate
set choices clusters execute vip? one choice using initial potentials
potentials jl found earlier choice clusters. practical benefit option
added flexibility remains tested application.
9

fiGeiger, Meek & Wexler

4. Proof Convergence
develop several lemmas culminate proof convergence algorithm vip? .
Lemma 1 states two un-normalized probability distributions P (x) Q(x)
KL divergence minimized Q(x) proportional P (x). Lemma 2 rewrites
KL divergence D(Q || P ) terms potentials P
Q P using quantity j (cj )
which, according Lemma 3, differs j (cj ) = l jl (cjl ) constant. Finally,
Theorem 1 asserts KL divergence Q P decreases iteration
Algorithm vip? unless Q stationary point. proof exploits new form
D(Q || P ) provided Lemma 2, replaces term j (cj ) terms jl (cjl ) used
update equation vip? . final observation, uses Lemma 1, closes proof
showing potentials updated algorithm vip? , KL divergence
minimized wrt j .
first lemma provides variant well known property KL. Recall
every two probability distributions Q(x) P (x), KL divergence D(Q(x) || P (x)) 0
equality holds Q(x) = P (x) (Cover & Thomas 1991; Theorem 2.6.3).
similar result holds also un-normalized probability distributions.
Lemma 1 Let Q(x) P (x) non-negative functions
let
Q(x) =
D(Q(x) || P (x))
P min
{Q|

x

P

x P (x)

= ZP > 0,

Q(x)=ZQ }

ZQ positive constant. Q(x) =

ZQ
ZP P (x).

Proof. observe
P (x)
D(Q(x) || P (x)) = ZQ D( Q(x)
ZQ || ZP ) + ZQ log

ZQ
ZP

implies, using cited result normalized distributions, minimum
P (x)
obtained Q(x)
ZQ = ZP , yielding desired claim.
next lemma rewrites KL divergence optimizing update equation
cluster Cj becomes readily available.
Lemma 2 Let P (x) =
tions. Then,

1
ZP

Q

(di )

D(Q || P ) =

X
Cj

Q(x) =

Q(cj ) log

1
ZQ

Q

j

j (cj ) two probability distribu-

j (cj )
+ log(ZP ) log(ZQ )
j (cj )

(8)

j (cj ) = ej (cj ) ,
j (cj ) =

X X

Q(ck |cj ) log k (ck ) +

X X


k Ck \Cj

10

Di \Cj

Q(di |cj ) log (di )

(9)

fiA Variational Inference Procedure

Proof: Recall
D(Q || P ) =

X

Q(x) log

X

Q(x)
= [H(Q) + EQ [log P (x)]]
P (x)

(10)

H(Q) denotes entropy Q(x) EQ denotes expectation respect Q.
entropy term written
X X
H(Q) =
Q(cj )Q(x|cj ) [log Q(cj ) + log Q(x|cj )]
Cj X\Cj

=

P

Cj

Q(cj ) log Q(cj )

P

Cj

Q(cj )

P

X\Cj

Q(x|cj ) log Q(x|cj ).

variation well known form H(Q) derived splitting
summation
P
X summation Cj X \ Cj , using fact Q(cj ) X\Cj Q(x|cj ) =
Q(cj ) holds every distribution. split sum X \ Cj Q(cj ) > 0 use
1 Q
X
k k (ck )
ZQ
=
log k (ck ) log Q(cj ) log(ZQ )
log Q(x|cj ) = log
Q(cj )
k

Thus,
X

Q(x|cj ) log Q(x|cj ) =

X\Cj

P P

P
Q(ck |cj )Q(x|ck , cj ) log k (ck ) X\Cj Q(x|cj ) [log Q(cj ) + log(ZQ )]
P
using Q(ck , cj ) X\{Ck Cj } Q(x|ck , cj ) = Q(ck , cj ) term rewritten
X
H(Q) =
Q(cj ) log Q(cj )
k

X\Cj

Cj



P

Cj Q(cj )

hP

k6=j

P

Ck \Cj Q(ck |cj ) log k (ck ) + log

j (cj )
Q(cj )



+ log(ZQ )

Note Q(cj ) = 0 bracketed term multiplied zero, due equality
0 log 0 = 0, product also zero.

second term Eq. 10 similarly written
XX
X
EQ [log P (x)] =
Q(cj )
Q(x|cj ) log (di ) log(ZP )


=

X

Q(cj )

Cj

X X


Cj

(11)

X\Cj

Q(di |cj ) log (di ) log(ZP )

Di \Cj

Hence Eq. 10 rewritten
X
D(Q || P ) =
Q(cj ) log Q(cj )
Cj




X
Cj

Q(cj )


X X

Q(ck |cj ) log k (ck ) +

X X


k Ck \Cj

11

Di \Cj

Q(di |cj ) log (di )

fiGeiger, Meek & Wexler



X
Cj

Q(cj ) log

Q(cj )
+ log(ZP ) log(ZQ )
j (cj )

Denoting bracketed term j (cj ), letting j (cj ) = ej (cj ) , get
D(Q || P ) =

X
Cj

Q(cj ) log

j (cj )
+ log(ZP ) log(ZQ ).
j (cj )



P
next lemma shows j (cj ), defined Eq. 9, j (cj ) = l jl (cjl ), used
update potentials Q vip? , differ additive constant depend
cj . argued Theorem 1, fact difference constant enables vip?
use latter form, efficient representation.
Q
Q
Q
Lemma 3 Let P (x) = Z1P (di ) Q(x) = Z1Q j j (cj ) j (cj ) = l jl (cjl ),
two probability distributions Q self-compatible compatible wrt P . Let
X
X
X
X
jl (cjl ) =
Q(ck |cjl ) log k (ck ) +
Q(di |cjl ) log (di ) (12)
{k:gjk (l)=1} Ck \Cjl

{i:fij (l)=1} Di \Cjl

Then, difference j (cj ) defined Eq. 9 j (cj ) =
depend cj .

P

l

jl (cjl ) constant

P
Proof: first argue term form Ck \Cj Q(ck |cj ) log k (ck ) term
P
form Di \Cj Q(di |cj ) log (di ) Eq. 9 depends cj appears exactly
single subset Cjl Eq. 12. argue every term Eq. 12 appears
Eq. 9.
Since Q self-compatible, follows every cluster Ck depends Cj
function gkj (l) equalsPone single subset Cjl , namely Q(ck |cj ) = Q(ck |cjl ),
case expression
Ck \Cj Q(ck |cjl ) log k (ck ) appears Eq. 12. Similarly, since Q
compatible wrt P follows every set Di depends Cj function fij (l)
equals
one single subset Cjl , namely Q(di |cj ) = Q(di |cjl ), case expression
P
Di \Cj Q(di |cjl ) log (di ) appears second term Eq. 12.
remains show every term Eq. 12 appears Eq. 9. Since Q selfcompatible, implied Ck Cj Cjl thus summing Ck \ Cj equivalent
summing Ck \ Cjl . Therefore, every k gjk (l) = 1, first term
Eq. 12 appears Eq. 9. Similarly, since Q compatible wrt P , implied
Di Cj Cjl thus summing Di \ Cj equivalent summing Di \ Cjl
therefore every fij (l) = 1 second term Eq. 12 appears Eq. 9.


Theorem 1 (Convergence vip? ) Let initial approximating distribution Q selfcompatible compatible wrt given distribution P , assume (P (x) = 0)
(Q(x) = 0). Then, revised distribution Q retains properties, iteration
Algorithm vip? KL divergence Q P decreases unless Q stationary
point.
12

fiA Variational Inference Procedure

Q
Proof. Let Q(x) = Z1Q jl jl (cjl ) jl (cjl ) = ejl (cjl ) . need show
0
?
start
Q of0 iteration vip function Q defined revised potentials
0
j (cj ) = l jl (cjl ) probability distribution listed properties
closer P KL divergence Q start previous iteration.
First, show Q0 maintains properties listed theorem throughout
updates done vip? . properties self-compatibility compatibility wrt P
derived form Q thus affected updates done vip? .
property
(P (x) = 0) (Q(x) = 0), consider instance x P (x) = 0. Since
1 Q
P (x) = ZP (di ) exists potential P (di ) = 0, di
Q
projection x set Di . Since Q(x) = 0 Q(x) = Z1Q jl jl (cjl ) exists
subset Cjl Q(cjl ) = 0, cjl projection x Cjl . Algorithm vip?
1
convention,
updates jl (cjl ) log (di ) = Q(di |cjl ) = |Di \C
jl |
0
yielding Q (x) = 0, claimed.
Now, show additional zeroes introduced Q whenever (P (x) = 0)
(Q(x) = 0). Hence, normalizing constant ZQ > 0 therefore revised Q0
probability distribution. instances cjl Q(cjl ) > 0 terms Q(ck |cjl ) log (ck )
Q(di |cjl ) log (di ) finite long (P (x) = 0) (Q(x) = 0). implies jl (cjl )
updated positive value thus, additional zeroes introduced Q.
Using given form Q,


1 X
Q(cj ) =
k (ck ) j (cj ).
(13)
ZQ
X\Cj k6=j

denote bracketed coefficient j (cj ) Bj (cj ) note constant
sense depend quantity j optimized.
use Eq. 13 rewrite KL divergence justified Eq. 8 Lemma 2:


j (cj )Bj (cj )
1 X
D(Q || P ) =
j (cj )Bj (cj ) log
+ log(ZP ) log(ZQ ).
(14)
ZQ
j (cj )Bj (cj )
Cj

Due Lemma 3, distance D(Q || P
j (cj )
P) changes constant replacing

(c
)
?
j
j
j (cj ) = e
, j (cj ) = l jl (cjl ) computed via Eq. 6 vip . Note
j (cj ) depend (cj ) function Q(x) conditional
distribution X \ Cj given Cj (via Q(ck |cj )). Hence, Lemma 1 states minimum
D(Q || P ) wrt j achieved j (cj ) proportional j (cj ). potential j
held implicitly partial potentials jl , step 1 vip? updates j (cj ) via
Eq. 6 proportional j (cj ) setting potential jl (cjl ) proportional
jl (cjl ). proportionality constant matter j multiplied ,
arbitrary constraining constant ZQ also multiplied , influences cancel
Eq. 14. simplicity, algorithm uses = 1 therefore j (cj ) ej (cj ) . Algorithm
vip? implicitly computes j (cj ) according formula hence decreases D(Q || P )
iteration improving j (cj ) holding cluster potentials fixed. Since
KL divergence lower bounded zero, vip? converges.

13

fiGeiger, Meek & Wexler

properties Q required Theorem 1 self-compatibility compatibility wrt
P derived form Q satisfied setting clusters Cj appropriately.
addition, condition (P (x) = 0) (Q(x) = 0) trivially satisfied strictly positive
distributions P .
Note difference j (cj ) defined Eq. 9 j (cj ) defined Eq. 1
constant depend cj . Consequently, convergence proof also applies
Wiegerincks algorithm, algorithm special case vip? every cluster
Cj single subset Cj1 = Cj .

5. Handling Deterministic Potentials
distribution P strictly positive property (P (x) = 0) (Q(x) = 0)
must hold convergence proof vip? apply. section provide sufficient
condition Q retain property.
Definition: instantiation W = w feasible (wrt distribution P ) P (W = w) > 0.
Otherwise, instantiation infeasible.
Q
Definition: constraining set wrt distribution P (x) = Z1P (di ) sets Di
minimal set variables Di infeasible instantiation .
Q
Definition: distribution Q(x) = Z1Q j j (cj ) clusters Cj containable wrt
Q
distribution P (x) = Z1P (di ), every constraining set P exists least
one cluster Cj Cj .
Q
Q
Theorem 2 Let P (x) = Z1P (di ) Q(x) = Z1Q j j (cj ) two distributions
Q
j (cj ) = l jl (cjl ) Q containable compatible wrt P strictly positive. Then, vip? iterates clusters Cj , revised distribution Q satisfies
(P (x) = 0) (Q(x) = 0).
Proof: definition constraining set, every infeasible instantiation x,
exists infeasible instantiation constraining set projection x
. show vip? updates Q(x) = 0 instantiations. Since Q containable
wrt P exists cluster Cj contains . Furthermore, since Di Di
set P since Q compatible wrt P , exists subset Cjl contains .
every instantiation cjl projection Cjl expression jl (cjl ) updated
according Q
Eq. 6 vip? . true Q(di |cjl ) > 0 log (di ) = .
1
Since Q(x) = ZQ j,l jl (cjl ) update implies Q(x) = 0.
Whenever first two compatibility conditions Theorem 1 hold, follows vip?
converges containable distributions. Note since every iteration vip? decreases
KL divergence, following iterations change Q greater zero instantiation
infeasible wrt P , leads infinite distance. However, containability
implies stronger property stated next theorem.

14

fiA Variational Inference Procedure

Q
Q
Theorem 3 Let P (x) = Z1P (di ) Q(x) = Z1Q j j (cj ) two distributions
Q
j (cj ) = l jl (cjl ) Q containable wrt P (P (x) = 0) (Q(x) = 0). Then,
vip? iterates clusters Cj , revised distribution Q satisfies (Q(x) = 0)
(P (x) = 0).
Proof: Consider instantiation x P (x)
> 0. show Eq. 6 vip? upQ
dates Q(x) positive value. Since Q(x) = Z1Q j,l jl (cjl ), sufficient show
revised potential jl (cjl ) positive subset Cjl instance cjl
projection x Cjl . instances cjl value jl (cjl ) set Eq. 6
finite value since (di ) > 0 every instance di projection x set Di ,
k (ck ) = 0 implies Q(ck |cjl ) = 0. Therefore, jl (cjl ) = ejl (cjl ) > 0 Q(x) > 0.
consequence Theorem 3 Q(x) = 0 iff P (x) = 0. Conditions weaker
containability may sufficient ensure requirement needed convergence, however,
containability easily satisfiable applications variational techniques explicated
next section.

6. Genetic Linkage Analysis via Variational Algorithms
Genetic linkage analysis takes input family pedigree individuals
affected genetic disease, affection status members pedigree, marker readings
across genome, mode inheritance. output likelihood data function location disease gene given pedigree. Locations yielding maximum
close maximum likelihood singled suspect regions scrutiny.
exact computation likelihood often complex approximations needed.
Algorithm vip? developed facilitate likelihood computations. particular, vip? allows overlapping clusters minimizes loss valuable
information and, importantly, handle deterministic constraints common models. section, describe standard probabilistic model
genetic linkage, several approximate distributions use applying vip?
genetic linkage model, demonstrate vip? real-world data set large pedigree
115 individuals.
standard probabilistic model genetic linkage based pedigree contains several variables person location conditional probability tables
variable Xm given set variables called parents Xm denoted (Xm ).
distribution P (x) represents joint distribution variables pedigree
written using multiple indices; one set indices persons (i), one loci (j),
another type variable (t) follows:
P (x) =

YY
j

i,t
P (xi,t
j |(xj )) =



t{ps,ms,pg,mg,f }

1 YY
ZP
j



t{ps,ms,pg,mg,f }

15

i,t
i,t
i,t
j (xj |(xj ))

(15)

fiGeiger, Meek & Wexler

five possible types variables are: paternal selector (ps), maternal selector (ms),
paternal genotype (pg), maternal genotype (mg) phenotype (f). Thus, set Dji,t
equals {Xji,t , (Xji,t )}.
denote variables different types, ps, ms, pg, mg f, individual
i,m
locus j Sji,p , Sji,m , Gi,p
Fji respectively. notation possible potentials
j , Gj
a,p
a,m
i,p
i,m
b,p
b,m
i,m
i,p
i,p
i,m
i,m
P (Gi,p
j , Gj , Gj , Sj ), (Gj , Gj , Gj , Sj ), (Sj , Sj1 ), (Sj , Sj1 )
i,m
(Fji , Gi,p
j , Gj ) b father mother pedigree, respectively.
i,p
a,p
a,m
i,ms
i,m
exemplifying sets Dji,pg = {Gi,p
= {Sji,m , Sj1
}, Dji,f =
j , Sj , Gj , Gj }, Dj
i,m
{Fji , Gi,p
j , Gj }, father individual pedigree. note first
two types potentials possibly last one deterministic potentials equal
zero instantiations.
directed
Q acyclic graph along probability distribution R factors according
R(Z) = R(zi |(zi )) called Bayesian network. Bayesian network defined
Eq. 15, describes parents-offspring interaction simple genetic analysis problem
two siblings parents across 3 loci, given Figure 4. dashed boxes
contain variables describe variables single location. example
assume phenotype variable depends genotype single locus.
reflected fact edges single locus point phenotype variable.
full semantics variables details regarding conditional probability
tables found paper Fishelson & Geiger (2002); details needed
here.
use several choices cluster Bayesian network P (x) Q selfcompatible compatible wrt P . addition, since potentials P constrained
(e.g. i,pg
j ), choose clusters Q containable wrt P . According Theorem 2
choice ensures Q satisfies conditions necessary convergence vip? ,
particular (P (x) = 0) (Q(x) = 0).
Consider partition network slots, containing set consecutive loci.
simple case every slot single locus subsets Cji contains
variables related one individual genotypes parents slot. set

(i)
Cji = {Gj , Sji } Cj = {Cji } (i) denotes union parents.
illustration setting pedigree two siblings parents three
loci given Figure 5. setting, self-compatibility trivially satisfied
clusters Cj Q disjoint, Q containable wrt P since sets Dji,ps Dji,ms ,
potentials constrained, span across single locus. remains
show compatibility Q wrt P satisfied. sets Dji,t contained single subset

Cji trivial Q(Dji,t |cj ) = Q(Dji,t |cji ) = 1. Otherwise, equals ps ms without
i,p
i,p
i,p
i,p
loss generality, Q(Sj1
, Sji,p |cj ) = Q(Sj1
|cj ) = Q(Sj1
|cji ) = Q(Sj1
, Sji,p |cji ).
complex setup, similar Example 1, add cluster CJ+1
cuts across loci selector variables individual r, shown Figure 6.

(i)
subset Cji set Cji = {GjS , Sji , Sjr } clusters Cj = {Cji }, j = 1 . . . J.
r
addition, set CJ+1 = l {CJ+1,l } subsets CJ+1,l = {Sl,l+1
}, single
chosen individual r. verify Q still satisfies conditions Theorem 1. Selfcompatibility maintained since Q(Cj |cJ+1 ) = Q(Cj |cJ+1,j ), Q(CJ+1 |cj ) = Q(CJ+1 |cjr ),

16

fiA Variational Inference Procedure

Figure 4: Bayesian network representation pedigree two siblings parents
3-loci model. circles, squares diamond shapes represent genotype,
phenotype selector variables respectively.

Q(Ck |cj ) = Q(Ck |cjr ) every two clusters Cj , Ck j, k J. Sets Dji,t
6= ms, ps contained cluster Cj thus maintain independence given
subset. = ms, ps sets Dji,t connect two adjacent loci independent CJ+1
given CJ+1,j , independent clusters Cj given subset Cji , maintaining
compatibility Q wrt P . Finally, Q containable wrt P since clusters previous
option remain.
Immediate extensions clustering schemes allow every slot contain several
consecutive loci set possibly one individual R cut across loci.
maintain compatibility Q wrt P latter extension, subsets CjR set
(R)
CjR = {Gj , SjR }, (R) denotes union individuals R parents.
describe experiments performed using large pedigree 115 individuals
spanning across 21 locations, studied Narkis et al. (2004) locate area
contains gene causes fatal neurological disorder (LCCS type 2). First,
proximity disease gene markers tested two-point analysis
- model-selection method two loci considered simultaneously, one
disease locus. method, loci yield likelihood maxima suggest
probable locations disease locus. Two-point analysis abovementioned pedigree
took several days using exact inference software superlink v1.5 designed genetic
linkage analysis.
17

fiGeiger, Meek & Wexler

Figure 5: schematic division pedigree clusters, locus cluster.
cluster C3 variables every individual separate ellipse
number individual written. two clusters marked areas
C14 C23 .

log-likelihood probabilities obtained vip? using abovementioned extended
clustering scheme 5 clusters across loci cluster cutting across
loci, shown Figure 7. figure shows clearly exact approximate loglikelihood curves similar shape almost identical extremum points,
major difference absolute value.
Next, tested vip? three-point analysis problems pedigree,
two markers considered simultaneously along one disease locus. note
exact inference task specified pedigree hard single PC, taking several
weeks. Since exact location disease gene known high probability,
wished test whether lower-bounds found vip? indicate location.
considered two nearby markers (number 4 6) seven models differ
location speculated disease gene: first two, disease locus positioned
left marker 4 distances 0.01 0.02 centi-Morgan (cM), remaining five
positioned right marker 4 distances 0.01 0.05 cM 0.01 cM difference
locations. location disease gene 0.01cM right marker 4.
algorithm run three times model random initial potentials, taking
account maximum value obtained. results test plotted Figure 8
versus approximation found sampling software simwalk2 introduced Sobel,
Papp & Lange (2002) designed approximate pedigree analysis. shown,
probabilities found vip? higher approach location disease gene.
true probabilities found simwalk2. However, note vip?
18

fiA Variational Inference Procedure

ln-likelihood

Figure 6: pedigree partitioned clusters, locus cluster additional cluster C4 , striped area, contains variables one individuals.

0
-20
-40
-60
-80
-100
-120
-140
-160
-180
-200
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21

Exact

locus

VIP* - 5 clusters across loci
VIP* - disjoint clusters

Figure 7: Approximations log-likelihood two-point analysis using vip? .

much slower problem simwalk2, taking several hours run. addition,
19

fiGeiger, Meek & Wexler

note ln-likelihood probabilities Figures 8(a) (b) drawn different
scales due markedly different output two methods.

-182

-77
-78

-186

ln-likelihood

ln-likelihood

-184

-188
-190
-192
-194

-79
-80
-81
-82

-0.02

-0.01

0.01

0.02

0.03

0.04

0.05

-0.02

location (relative marker 4)

-0.01

0.01

0.02

0.03

0.04

0.05

location (relative marker 4)

(a) using vip?

(b) using simwalk2

Figure 8: Approximations log-likelihood three-point analysis.
compared convergence times vip? Wiegerincks algorithm various size
problems genetic linkage analysis. original network performed test
includes 332 variables represents pedigree 28 individuals four loci. create
various sized problems, subsets original pedigree increasing number individuals
considered. addition, fair comparison, clusters Wiegerincks algorithm
chosen subset subsets used vip? . Since number iterations
convergence vary significantly two algorithms, report ratio
iteration times also tests theoretical speedup predicted Section 3 vip?
Wiegerincks algorithm. Figure 9 illustrates ratio time update iteration
two algorithms, evident ratio increases linearly problem size.
ratios indicated averaged 5 runs 10 iterations every problem size.
Finally examine convergence vip? Figure 10 using six representatives
original 21 two-point analysis runs described earlier, different network.
algorithm halted change lower-bound smaller 105
3 iterations. Although runs converge rate, seems obey
certain pattern convergence first iterations show significant improvements
lower-bound, followed slow convergence local maximum, another
moderate improvement better maximum point.

7. Discussion
paper present efficient algorithm called vip? structured variational approximate inference. algorithm, extends known algorithms, handle overlapping
clusters overcome difficulties imposed deterministic constraints. show
N N grid-like models, algorithm vip? N fold faster Wiegerincks algorithm,
20

fiA Variational Inference Procedure

20
18

ratio iteration times

16
14
12
10
8
6
4
2
0
10

12

14

16

18

20

22

24

26

28

number individuals

Figure 9: Speedup vip? Wiegerincks algorithm.

-70
-90

ln-likelihood

-110
-130
-150
-170
-190
-210
-230
1

3

5

7

9

11

13

15

17

19

21

23

iteration

Figure 10: Convergence vip? 6 runs two-point analysis.
junction tree used. addition, prove convergence vip? previous
variational methods via novel proof method, using properties KL divergence.
Finally, algorithm vip? tested Bayesian networks model genetic linkage analysis problems. graphs resemble grid-like models notoriously difficult
approximate due numerous deterministic constraints. results show linear
improvement speed vip? versus Wiegerincks algorithm, approximation
21

fiGeiger, Meek & Wexler

follows shape real likelihood probabilities. Nevertheless, Figure 7 shows variational methods Wiegerincks algorithm vip? still appropriate produce
accurate approximation likelihood genetic linkage analysis.

Acknowledgments
paper extension paper originally appeared 10th workshop
Artificial Intelligence Statistics (Geiger & Meek 2005). thank D. Heckerman, N.
Jojic V. Jojic helpful discussions. also thank two anonymous reviewers
correcting several errors appeared early version well improving
presentation. Part work done first author visitor Microsoft
Research. work supported Israeli Science Foundation Israeli Science
Ministry.

References
Bishop, C. & Winn, J. (2003). Structured variational distributions VIBES. Artificial
Intelligence Statistics. Society Artificial Intelligence Statistics.
Cooper, G. (1990). Probabilistic inference using belief networks NP-hard. Artificial
Intelligence, 42, 393405.
Cover, T. M. & Thomas, J. A. (1991). Elements Information Theory. Wiley.
Dagum, P. & Luby, M. (1993). Approximating probabilistic inference Bayesian belief
networks NP-hard. Artificial Intelligence, 60 (1), 141153.
Dechter, R. (1999). Bucket elimination: unifying framework reasoning. Artificial
Intelligence, 113 (1-2), 4185.
Fishelson, M. & Geiger, D. (2002). Exact genetic linkage computations general pedigrees.
Bioinformatics, 18, S189S198.
Geiger, D. & Meek, C. (2005). Structured variational inference procedures realizations. Proceedings Tenth International Workshop Artificial Intelligence
Statistics, Barbados. Society Artificial Intelligence Statistics.
Ghahramani, Z. & Jordan, M. I. (1997). Factorial hidden Markov models. Machine Learning, 29, 245273.
Jensen, F. V. (1996). Introduction Bayesian Networks. Springer.
Jojic, V., Jojic, N., Meek, C., Geiger, D., Siepel, A., Haussler, D., & Heckerman, D.
(2004). Efficient approximations learning phylogenetic HMM models data.
Bioinformatics, 20, 161168.
Kschischang, F. R., Frey, B. J., & Loeliger, H. A. (2001). Factor graphs sum-product
algorithm. IEEE Transactions information theory, 47 (2), 498519.
22

fiA Variational Inference Procedure

Narkis, G., Landau, D., Manor, E., Elbedour, K., Tzemach, A., Fishelson, M., Geiger, D.,
Ofir, R., Carmi, R., & Birk, O. (2004). Homozygosity mapping lethal congenital
contractural syndrome type 2 (LCCS2) 6 cM interval chromosome 12q13.
American Journal Medical Genetics, 130 (3), 272276.
Saul, L. & Jordan, M. I. (1996). Exploiting tractable substructures intractable networks.
Advances Neural Information Processing Systems (NIPS). MIT Press.
Sobel, E., Papp, J., & Lange, K. (2002). Detection integration genotyping errors
statistical genetics. American Journal Human Genetics, 70, 496508.
Wiegerinck, W. (2000). Variational approximations mean field theory junction tree algorithm. Uncertainty Artificial Intelligence, (pp. 626633). Morgan
Kaufmann.
Xing, E. P., Jordan, M. I., & Russell, S. (2003). generalized mean field algorithm
variational inference exponential families. Uncertainty Artificial Intelligence,
(pp. 583591). Morgan Kaufmann.
Xing, E. P., Jordan, M. I., & Russell, S. (2004). Graph partition strategies generalized
mean field inference. Uncertainty Artificial Intelligence, (pp. 602 610). Morgan
Kaufmann.

23

fiJournal Artificial Intelligence Research 27 (2006) 551-575

Submitted 03/06; published 12/06

Causes Ineradicable Spurious Predictions Qualitative Simulation
zgr Ylmaz
A. C. Cem Say
Department Computer Engineering
Boazii University
Bebek 34342 stanbul, Turkey

YILMOZGU@BOUN.EDU.TR
SAY@BOUN.EDU.TR

Abstract
recently proved sound complete qualitative simulator exist, is,
long input-output vocabulary state-of-the-art QSIM algorithm used,
always input models cause simulator coverage guarantee make spurious
predictions output. paper, examine whether meaningfully expressive restriction
vocabulary possible one build simulator soundness
completeness properties. prove several negative results: sound qualitative simulators,
employing subsets QSIM representation retain operating region transition feature,
support least addition constancy constraints, shown inherently incomplete.
Even simulations restricted run single operating region, constraint
vocabulary containing addition, constancy, derivative, multiplication relations makes
construction sound complete qualitative simulators impossible.

1. Introduction
recently proved (Say & Akn, 2003) sound complete qualitative simulator
exist, is, long input-output vocabulary state-of-the-art QSIM algorithm
(Kuipers, 1994) used, always input models cause simulator
coverage guarantee make spurious predictions output. paper, examine whether
meaningfully expressive restriction vocabulary possible one build
simulator always output consistent solutions input model.
prove several negative results: sound qualitative simulators, employing subsets QSIM
representation retain operating region transition feature, support least
addition constancy constraints, shown inherently incomplete. problem persists
variables forced change continuously region transitions slightly larger
set constraint types allowed. Even simulations restricted run single
operating region, constraint vocabulary containing addition, constancy, derivative,
multiplication relations makes construction sound complete qualitative simulators
impossible. findings may helpful researchers interested constructing qualitative
simulators improved theoretical coverage guarantees using weaker representations.

2. Background
start brief overview qualitative simulation, concentrating representations used
input-output vocabularies qualitative simulators. Subsection 2.2 summarizes previous
work two theoretical properties qualitative simulators interest us. Subsection 2.3
short requirements specification hypothetical sound complete qualitative simulator.

2006 AI Access Foundation. rights reserved.

fiYILMAZ & SAY

2.1 Qualitative Simulation
many domains, scientists engineers incomplete amount information
model governing dynamic system consideration, renders formulating
exact ordinary differential equation (ODE) impossible. Incompletely specified differential
equations may also appear contexts aim find collective proofs behavioral
properties infinite set systems sharing most, all, structure ODEs
describing them. proceed reasoning task cases, mathematical tools embodying
methods making use available information obtain (hopefully small) set
possible solutions matching model needed. Qualitative reasoning (QR) researchers
develop AI programs use weak representations (like intervals rather point values
quantities, general shape descriptions rather exact formulae functional relationships)
vocabularies perform various reasoning tasks systems incomplete
specifications. following, use notation terminology QSIM (Kuipers, 1994),
state-of-the art qualitative simulation methodology, although noted
incompleteness results proving valid reasoners whose input-output
vocabularies rich enough support representational techniques used
proofs.
qualitative simulator takes input qualitative differential equation model system
terms constraints representing relations systems variables. addition
model, qualitative values variables time point simulation
start also given. algorithm produces list possible future behaviors may
exhibited systems whose ordinary differential equations match input model.
variables system modeled QSIM continuously differentiable functions time.
limits variable first derivatives exist approach endpoints
domains. variable quantity space; totally ordered collection symbols (landmarks)
representing important values take. Zero standard landmark common
variables. Quantity spaces allowed landmarks - ends, functional
relationships asymptotic shapes explicitly represented. appropriate, quantity
space declared span proper subset extended reals; instance, makes
sense bound quantity space variable certainly nonnegative (like pressure)
0 left. necessary, user specify one bounds quantity space
unreachable; example, unreachable value variables models
discussed paper. (reachable) points intervals quantity space make set
possible qualitative magnitudes variable. qualitative direction variable defined
sign derivative; therefore possible values are: inc (+), dec () std (0).
variables qualitative value pair consisting qualitative magnitude qualitative
direction. collection qualitative values variables makes state system.
laws according system operates represented constraints describing
time-independent relations variables. step simulation, QSIM uses set
transition rules implicitly generate possible next values variables.
combinations values filtered constitute complete states,
every constraint still satisfied new values variables, remain.
seven basic types constraints QSIM. (See Table 1.) type constraint
imposes different kind relation arguments. example, constraint
A(t) = B(t), combination variable values variables B
(nonzero) sign magnitudes directions filtered out. Sometimes, additional
knowledge constraints allows filtering. example, know
B landmark values a1 b1 moment time past,
552

fiCAUSES INERADICABLE SPURIOUS PREDICTIONS QUALITATIVE SIMULATION

eliminate value combinations B magnitudes less (or greater)
landmarks. a1 b1 called corresponding values constraint,
equation a1 = b1 correspondence. constraint model (except derivative
type) correspondence equations. sign algebra (Kuipers, 1994) employed
implement arithmetic relations using qualitative magnitudes. Note that, since + ( )
relationship corresponds infinite number possible quantitative functions
monotonicity property, single QSIM model containing constraints correspond
infinitely many ODEs.
CONSTRAINT NAME
add

NOTATION
X(t) + Y(t) = Z(t)

constant

X(t) = landmark

derivative

d/dt(X,Y)

M+

X(t) = f(Y(t)), f +



X(t) = f(Y(t)), f

minus
mult

X(t) = Y(t)
X(t) Y(t) = Z(t)

EXPLANATION

X(t) = 0
dt

X(t) = Y(t)
dt
f X(t) = f(Y(t)), f > 0
f domain
f X(t) = f(Y(t)), f < 0
f domain

Table 1: Qualitative Constraint Types
QSIM input vocabulary enables user describe complicated models terms
several different constraint sets representing different operating regions system
consideration. user specifies boundaries applicability ranges operating
regions terms conditions indicate simulator effect transition
another operating region obtained.
operating region transition occur, one specify
following possible transition:
Boolean expressions composed primitives form VariableName=QualitativeValue,
trigger transition satisfied,
name target operating region,
names variables inherit qualitative magnitudes and/or directions
first state transition last state transition,
Value assignments variables explicitly specified values first state
transition.
provided qualitative system model, name initial operating region,
description qualitative values variables initial state, QSIM starts simulation,
generates tree system states represent solutions qualitative differential
equation composed constraints input. root tree input initial state
time-point label t0, representing numerical value initial instant. Every path
553

fiYILMAZ & SAY

root leaf predicted behavior system. qualitative format,
behavior usually corresponds infinite set trajectories sharing qualitative
structure phase space. Time-point interval states appear alternately behaviors long
operating region valid. Operating region transitions reflected behaviors two
time-point states following other.
2.2 Related Work Soundness Incompleteness
important property qualitative simulators coverage guarantee: qualitative
simulation algorithm sound guaranteed that, ODE initial state matches
simulators input, behavior output matches ODEs solution.
Kuipers (1986) proved exists qualitative simulator (namely, QSIM)
soundness property. guarantee makes qualitative simulation valuable design diagnosis
method (Kuipers, 1994): design, set simulation predictions model
contain catastrophic failure, proof modeled system exhibit failure
(Shults & Kuipers, 1997). diagnosis, none behaviors simulation output
model exhibited particular system, 100% sure actual system
governed model.
Another property one would wish ones qualitative simulator possess completeness;
is, guarantee every behavior output corresponds solution least one
ODE matching input. early days QR research, conjectured (de Kleer & Brown,
1984) qualitative simulators employing local constraint satisfaction methods (Weld & de
Kleer, 1990) complete. However, paper contained guaranteed
coverage theorem, Kuipers (1986) also showed version QSIM described there, and,
indeed, qualitative simulators day, incomplete, demonstrating
simulation frictionless mass-spring oscillator predicts unrealizable (spurious) behaviors,
amplitude decreases periods increases others. lack guarantee
predicted behaviors real negative impact potential applications: design,
set simulation predictions model contain catastrophic failure,
necessarily point error mechanism; maybe prediction question
spurious behavior. similar problem occurs diagnosis applications.
Several types spurious qualitative simulation predictions discovered
following years: Struss (1990) pointed that, whenever variable appeared
arithmetic constraint, spurious states could pass filter. instance, filters add
constraint unable delete states involving nonzero values variable Z equation
A(t) + Z(t) = A(t) nonzero. Clearly, sound complete qualitative simulator
would possess algebraic manipulation capabilities enable us conclude Z = 0
case. Say Kuru (1993) discovered class spurious predictions caused rigidity
internal representation correspondences, unnecessarily weak implementation
subtraction. Say (1998) showed spurious behaviors due lack explicit
enforcement lHpitals rule original algorithm. Yet another family inconsistent
predictions found caused weaknesses methods used distinguish finite
infinite time intervals behaviors (Say, 2001, also see Missier, 1991). Knik Say
(2003) proved model behavior descriptions could encode information
relative (finite) lengths intervals contain, failure check overall
consistency pieces information yields another class spurious predictions. Finally,
Say (2003) showed similar encoding could occur exact numerical values
landmarks, sound complete qualitative simulator would support capability

554

fiCAUSES INERADICABLE SPURIOUS PREDICTIONS QUALITATIVE SIMULATION

comparing magnitudes two elements rich subset real numbers
avoid particular set spurious predictions.
Interestingly, discoveries actually good news users qualitative
simulators: order able say particular predicted behavior spurious, therefore
suitable elimination simulator output without forsaking soundness property, one
first proves behavior mathematically inconsistent simulated model
starting state. instance, aforementioned spurious oscillations frictionless massspring system shown violate conservation constraint follows directly
structure input equations. proof seen specification new
filter routine would eliminate exactly set behaviors violate law
establishes. kinetic energy constraint (Fouch & Kuipers, 1992) filter
developed fashion eliminate class spurious predictions exemplified ones
mass-spring system (Kuipers 1994). spurious prediction classes mentioned
previous paragraph had, fact, discovered simultaneously cures.
question whether exists sound complete qualitative simulator finally
settled Say Akn (2003). proved that, sound qualitative simulator using
input-output representation task specification QSIM methodology, exist input
models initial states whose simulation output contain spurious predictions. (Note
say present QSIM algorithm augmented filters make
sound complete; refutes existence program whatsoever perform
job.)
proof Say Akn (2003) shows sound complete qualitative simulator
employing vocabulary mentioned above, existed, could used solve given
instance Hilberts Tenth Problem, famously undecidable (Matiyasevich, 1993).
procedure involves building QSIM model representing given problem, simulating several
times starting carefully constructed initial states representing candidate solutions,
examining output read solution. model set contain inconsistency
answer considered problem no, existence one
behaviors output means yes. Since impossible make decision correctly
general case, follows would input models giving rise behavior predictions
whose consistency status determined simulator, whose best course action
would include output, keep soundness guarantee intact. cases
correct answer no, would result prediction spurious behaviors. Note
ineradicable spurious predictions, unlike ones discussed earlier.
important note proof necessarily mean hope constructing
sound complete qualitative simulator lost. One may try weaken input-output
representation longer possesses problematic power enables one
unambiguously encode instances Hilberts Tenth Problem QSIM model. (Of course,
weakening must kept minimum possible level resulting program useful
reasoner; instance, removing programs ability distinguish negative
nonnegative numbers would possibly yield sound complete simulator, output
program would state everything possible want
methods.) one examine incompleteness proof (Say & Akn, 2003) see
exactly features QSIM representation used construction reduction;
future qualitative simulator supporting vocabulary subset would incorporating
problem start.
listing QSIM representational items used proof: M+,
derivative, mult, constant constraint types utilized. (Note absence add
constraint, implemented using others, list.) Qualitative interval
555

fiYILMAZ & SAY

magnitudes like (0, ), one might call infinite uncertainty actual value
represented number, used initializing several variables, form essential part
argument. QSIMs ability explicitly represent infinite limits utilized equating
landmark number , stating twice limit function arctan x x nears
infinity. Finally, operating region transition feature used heavily, since thanks
characteristic sine function two dependent variables represented
qualitative vocabulary.
Section 3, examine several different ways weakening QSIM vocabulary try
understand combinations features responsible problem ineradicable
spurious predictions.
2.3 Desiderata Sound Complete Qualitative Simulator
important point clarify exactly one would expect hypothetical sound
complete qualitative simulator. input model yields finite behavior tree genuine
solutions, obvious program supposed print descriptions behaviors
forming branches tree, nothing else, finite time. input model initial
state inconsistent, i.e., correct output empty tree, program report
inconsistency finite time.
Finally, input yields behavior tree infinitely many branches, program
supposed run forever, adding new state output every while. formally,
every positive i, integer program printed first
states behavior tree (according ordering root, i.e. initial state,
state number 1, descendants particular state printed state itself)
end sth step execution. Note requirements mean sound
complete simulator would able decide whether initial system state description
given consistent input model within finite time. necessity used
proofs incompleteness Section 3.

3. New Incompleteness Results Qualitative Simulators
section, examine two different ways restricting qualitative vocabulary
hope obtaining representation allows construction sound complete
simulators. Subsection 3.1 considers usage several reduced sets qualitative constraint
types, retaining operating region transition feature. also examine possible
restriction way variable values handled operating region transitions. Subsection
3.2 investigation capabilities qualitative simulators restricted input
models single operating region. variants shown exhibit problem
ineradicable spurious predictions soundness guarantee present.
3.1 Reduced Constraint Sets
results subsection based undecidability properties abstract computational
devices called unlimited register machines (URMs). first present brief introduction
URMs, proceed proofs.

556

fiCAUSES INERADICABLE SPURIOUS PREDICTIONS QUALITATIVE SIMULATION

3.1.1 UNLIMITED REGISTER MACHINES
easiest way thinking URM see computer infinite memory
supports particularly simple programming language. URM (Cutland, 1980) program P
consists finite sequence instructions I1, I2, ..., I|P|. instructions refer machines
registers Ri, store arbitrarily big natural number. use notation r1, r2,
r3, ... register contents.
purposes, sufficient consider three types URM instructions:
succ(n): Increment content register n one.
Rn rn + 1
zero(n): Set content register n zero.
Rn 0
jump(m, n, q): Compare registers n. equal, continue instruction q.
rm = rn jump Iq
URM program starts execution first instruction. current instruction
jump whose equality condition satisfied, followed next instruction list.
program ends attempts continue beyond last instruction, jump nonexistent
address attempted. assume without loss generality jumps address I|P|+1.
P = I1, ..., I|P| URM program, computes function P(k) : Nk N. P(k)(a1, ..., ak)
computed follows:
- Initialization: Store a1, ..., ak registers R1, ..., Rk, respectively, set registers
referenced program 0.
- Iteration: Starting I1, execute instructions order described above.
- Output: program ends, computed value function number r1
contained register R1. program never stops, P(k)(a1, ..., ak) undefined.
Table 2 contains example URM program computes function f(x, y) = x + y. Note
function N2 N, input values x stored registers R1 R2,
output function expected stored R1 end program.
I1:

zero(3)

I2:

jump(2, 3, 6)

I3:

succ(1)

I4:

succ(3)

I5:

jump(1, 1, 2)

Table 2: URM Program Computing f(x, y) = x +
program first sets R3 zero. checks see R2 = R3 (in case = 0).
Otherwise, increments R1 R3. continues x incremented times,
value R1 returned.
URM model computation equivalent numerous alternative models
Turing machine model, Gdel-Kleene partial recursive functions model Churchs lambda
557

fiYILMAZ & SAY

calculus, (Cutland, 1980; Shepherdson & Sturgis, 1963) sense set functions
computable URMs identical set functions computed
models. means device simulate given URM powerful
Turing machine, since simulate given Turing machine. proofs
incompleteness QSIM vocabulary reduced constraint sets, make use
fact halting problem URMs undecidable (Cutland, 1980).
3.1.2 SOUND COMPLETE QSIM REDUCED CONSTRAINT SETS SOLVES HALTING
PROBLEM
incompleteness results new subsets QSIM vocabulary presented
subsection based following theorem, shows QSIM simulate
URM, thereby Turing-equivalent computational power.
Theorem 1: execution URM program P |P| instructions given input
represented simulation QSIM model |P|+2 operating regions.
Proof: proof construction. Suppose given URM program P
instructions I1, ..., I|P|. Let R1, ..., RN registers mentioned instructions P.
Ri, define QSIM variable NRi represent it, and, case Ri
nonzero initial value ai, set auxiliary QSIM variables representing ai. Table 3 describes
idea behind representation. four variables named U, W, Z, B. U
represents clock rises 0 1 every computational step. W derivative U.
Z constant zero every operating region. B additional auxiliary variable.
CONSTRAINTS

INITIAL VALUES

CONCLUSIONS

ONE(t) ONE(t) = ONE(t)
ONE(t) + ONE(t) = TWO(t)
ONE(t) + TWO(t) = THREE(t)

ONE(t0) = one (0, )

ONE constant 1
TWO constant 2
THREE constant 3

Table 3: QSIM Model Fragment Demonstrating Representability Exact Integer Values
QSIM model |P|+2 operating regions: instruction Ii P
corresponding operating region named OpRegi. two remaining regions OpReg0,
corresponding initialization stage P, OpReg|P|+1, corresponding end.
specification operating region must contain constraints valid
region, Boolean conditions (if any) composed primitives form
Variable = <qualitative magnitude, qualitative direction> would trigger transitions
operating regions obtained, lists detail variables inherit
previous magnitudes and/or directions transition, initialized
new values switch. Tables 4-9 describe prepare items operating
regions target model, based program P. five different operating region
templates (or types) used construction; one URM instruction type, one
OpReg0, one OpReg|P|+1.
model OpReg0 depicted Table 4. simulation P start.
NRi variables equated proper initial values specified user P: ones
initialized zero handled constant 0 constraints. ones positive initial values
558

fiCAUSES INERADICABLE SPURIOUS PREDICTIONS QUALITATIVE SIMULATION

specified constant values using add constraints link number
variables exemplified Table 3; instance, NR2 initialized three,
constraint THREE(t) + Z(t) = NR2(t). add constraint B, U, ONE serves express
fact landmark named one Us quantity space also equal 1. (Note
add constraints mentioned paragraph exist OpReg0, since would disrupt
intended behavior operating regions.)
seen Tables 4-8, exactly variables keep values transition depends
type target operating region. Regions corresponding instructions type zero(n)
inherit value Rn predecessors, since involve replacement
value zero anyway. types regions, including succ(n) type, inherit
register contents predecessors. (Although value Rn change succ
instruction, new value depends old one, unlike case zero(n). corresponding
QSIM variable NRn increases continuously simulation region type succ(n),
new region transition occurs exactly moment increased one unit.)
Operating Region: OpReg0
{Type: Initialization}
Constraint Set: d/dt(U, W)
B(t) + U(t) = ONE(t) correspondence 0 + one = one
required number representation constraints (see Table 3)
add constraints linking NRi relevant number variables (see text)
variables except U B constant.
Possible Transition:
Trigger: ( U = <one, inc> )
New operating region: OpReg1
Variables inheriting magnitudes directions: See Table 5, indexed type OpReg1
Variables new asserted values: U <0, inc>

Table 4: Model Operating Region OpReg0, Corresponding Initialization URM

TYPE TARGET
REGION
jump(m, n, q)

VARIABLES INHERITING
QUALITATIVE MAGNITUDES
variables except U B

VARIABLES INHERITING
QUALITATIVE DIRECTIONS
variables except U, B, NRi

succ(n)

variables except U B

variables except U, B, NRi

zero(n)

variables except U NRn

variables except U, B, NRi

End

variables except U

variables except U NRi

Table 5: Variables Inherit Magnitudes and/or Directions According Type
Target Operating Region

559

fiYILMAZ & SAY

simulation given URM program proceeds follows: described previous
subsection, URM starts initial configuration, registers R1, ..., Rk store
nonnegative integers a1, ..., ak, form input program, respectively. Nk
registers set 0. Correspondingly, NRi variables QSIM model
quantity space [0, ). NRi variables nonzero initial values start simulation
qualitative values <(0, ), std>, whereas ones start <0, std>. quantity space
variable U [0, one], landmark one equated 1, mentioned above. U starts
initially qualitative value <0, inc>. derivative U, W, quantity space [0, speed, ),
speed also equated 1. starts qualitative value <speed, std> constant
whole simulation. variable B quantity space (-, 0, ) starts <(0, ), dec>.
started OpReg0, QSIM compute single qualitative behavior segment, ends
transition OpReg1 U reaches <one, inc> time-point t1.
Operating Region: OpRegi
{Type: zero(n)}
Constraint Set: d/dt(U, W)
NRn(t) = 0
variables except U constant.
Possible Transition:
Trigger: ( U = <one, inc> )
New operating region: OpRegi+1
Variables inheriting magnitudes directions: See Table 5, indexed type OpRegi+1
Variables new asserted values: U <0, inc>

Table 6: Model Template Operating Regions Corresponding zero(n) Instructions

Operating Region: OpRegi
{Type: succ(n)}
Constraint Set: d/dt(U, W)
B(t) + U(t) = NRn(t)
variables except U NRn constant.
Possible Transition:
Trigger: ( U = <one, inc> )
New operating region: OpRegi+1
Variables inheriting magnitudes directions: See Table 5, indexed type OpRegi+1
Variables new asserted values: U <0, inc>

Table 7: Model Template Operating Regions Corresponding succ(n) Instructions

560

fiCAUSES INERADICABLE SPURIOUS PREDICTIONS QUALITATIVE SIMULATION

Note zero uncertainty values variables, even ones initial
magnitude (0, ), start simulation.
model constrained sound complete qualitative simulator guaranteed
produce exactly one behavior prediction initial state corresponding valid URM input.
see this, sufficient observe that, step simulation, sufficient
information available simulator compute exact numerical value every variable
model. (This corresponds tracing URM program keeping note register
contents step.) modeled URM halts particular input given initial
state, QSIM behavior supposed finite one, ending variable U attempts
exceed one OpReg|P|+1. URM computation halt, QSIM behavior
supposed single infinite sequence states, never visits OpReg|P|+1.
Operating Region: OpRegi
{Type: jump(m, n, q)}
Constraint Set: d/dt(U, W)
NRm(t) + B(t) = NRn(t)
variables except U constant.
Possible Transition:
Trigger: ( U = <one, inc> ) ( B <0, std> )
New operating region: OpRegi+1
Variables inheriting magnitudes directions: See Table 5, indexed type OpRegi+1
Variables new asserted values: U <0, inc>
Possible Transition:
Trigger: ( U = <one, inc> ) ( B = <0, std> )
New operating region: OpRegq
Variables inheriting magnitudes directions: See Table 5, indexed type OpRegq
Variables new asserted values: U <0, inc>

Table 8: Model Template Operating Regions Corresponding jump(m, n, q) Instructions

Operating Region: OpReg|P|+1
{Type: End}
Constraint Set: d/dt(U, W)
variables except U constant.

Table 9: Model Operating Region OpReg|P|+1, Corresponding End URM
Program
ready state new version incompleteness theorem.
561

fiYILMAZ & SAY

Theorem 2: Even qualitative representation narrowed derivative, add,
mult, constant constraints used QDEs, variable forced start finite
value zero uncertainty initial state, still impossible build sound complete
qualitative simulator based input-output vocabulary.
Proof: Assume sound complete simulator exists. show solve
halting problem URMs using algorithm subroutine.
Construct corresponding QSIM model described Theorem 1 URM program P
whose halting status particular input supposed decided. define new variable
quantity space [0, one, ), landmark one equated number 1. starts
value <one, std> initial state. Add constraints indicating constant
operating regions, specify value inherited possible transitions. Insert
new constraint S(t) = 0 OpReg|P|+1. Consider simulator supposed
checking initial state consistency. Note would inconsistency
simulation ever enters OpReg|P|+1, since new constraint inserted region says
zero, would contradict inherited value one. simulator
supposed make spurious predictions expected reject initial state time t0
inconsistent simulation going enter OpReg|P|+1, words, URM program
consideration going halt. sound complete simulator reject
initial state due inconsistency, goes simulation, conclude
program P halt. forms decision procedure halting problem. Since
halting problem undecidable, obtained contradiction, conclude sound
complete simulator using representation exist.
fact possible remove derivative constraint (which used proof
ensure behavior tree one branch) representation well,
incompleteness result shown would still stand:
Theorem 3: Even qualitative representation narrowed add, mult,
constant constraints used QDEs, variable forced start finite value
zero uncertainty initial state, still impossible build sound complete
qualitative simulator based input-output vocabulary.
Proof: make minor modification proof Theorem 2. observe
construction Theorem 1, U always starts every operating region <0, inc> fact
derivative positive constant forces reach value <one, inc> next time point.
transition next operating region occurs, U receives value <0, inc>.
happens remove variable W derivative constraints model? case,
since Us derivative fixed, three possible states U second time point
simulation operating region: <one, inc>, <one, std>, <(0, one), std>. fix
problem inserting another possible region transition specification regions,
except OpReg|P|+1. transition triggered U one values <one, std>,
<(0, one), std>, target OpReg|P|+1. variable proof Theorem 2,
well variables, inherited completely transition. unwanted
behaviors would created due elimination Us derivative end OpReg|P|+1,
therefore eliminated spurious accordance argument previous
proof. Hence, again, simulator supposed accept initial state consistent
P halt, meaning sound complete simulation impossible
representation well.

562

fiCAUSES INERADICABLE SPURIOUS PREDICTIONS QUALITATIVE SIMULATION

Interestingly, one even restrict representation nonnegative numbers
supported, incompleteness result proved still stands:
Theorem 4: Even qualitative representation narrowed add, mult,
constant constraints used QDEs, variable forced start finite value
zero uncertainty initial state, variable allowed negative value time
simulation, still impossible build sound complete qualitative simulator
based input-output vocabulary.
Proof: previous proof, variable B ever possibility negative value,
occur jump region. replace definition jump region template
Table 10, introduce new variables C Y. insert constraints say
variables constant operating regions. C start zero, inherited
transitions, except target region type jump. seen Table 10, B gets
value 1 two compared register values equal. unequal, B
positive value different 1. setup, Bs quantity space defined [0, one, ),
one equated 1, variable ever negative value simulation. B starts
simulation value <one, dec> satisfy add constraint seen Table 4. rest
argument identical Theorem 3.
Operating Region: OpRegi
{Type: jump(m, n, q)}
Constraint Set: NRm(t) + ONE(t) = C(t)
NRn(t) + ONE(t) = Y(t)
B(t) C(t) = Y(t)
variables except U constant.
Possible Transition:
Trigger: ( U = <one, inc> ) ( B <one, std> )
New operating region: OpRegi+1
Variables inheriting magnitudes directions: Depends type OpRegi+1,
Variables new asserted values: U <0, inc>
Possible Transition:
Trigger: ( U = <one, inc> ) ( B = <one, std> )
New operating region: OpRegq
Variables inheriting magnitudes directions: Depends type OpRegq,
Variables new asserted values: U <0, inc>

Table 10: Alternative Model Template Operating Regions Corresponding jump(m, n, q)
Instructions Avoids Negative Numbers
Alternatively, keep negative numbers remove mult constraint
representation, drop requirement variable starts simulation value zero
uncertainty.

563

fiYILMAZ & SAY

Theorem 5: Even qualitative representation narrowed add constant
constraints used QDEs, still impossible build sound complete qualitative
simulator based input-output vocabulary.
Proof: used mult constraint proofs Theorems 1-3 equating variable
landmark values unambiguous integers. Assume delete mult constraints
model Theorem 3. number variables Table 3 replaced setup shown
Table 11. Ri supposed initialized positive integer ai P, equate NRi
aiunit variable OpReg0 using method explained proof Theorem 1. Note
use constant add constraints (and lot auxiliary variables) purpose.
CONSTRAINTS
ONEUNIT(t) = unit
ONEUNIT(t) + ONEUNIT(t) = TWOUNITS(t)
ONEUNIT(t) + TWOUNITS(t) = THREEUNITS(t)

CONCLUSIONS
TWOUNITS constant 2unit
THREEUNITS constant 3unit

Table 11: Sample Model Fragment Equating Variables Integer Multiples Positive
Landmark unit
landmarks previously named one variables quantity spaces equated
unit. new model, execution succ(n) instruction increments NRns value one unit.
jump instruction compares landmarks whose values equal uunit vunit instead
comparing two landmarks whose values equal natural numbers u v. zero instruction
sets target register 0, previous construction. modeled machine
original URM does, since multiplication values coefficient unit
change flow program, and, particular, whether halts input not. rest
argument identical proof Theorem 3.
observe variables change qualitative magnitudes directions
discontinuously operating region transitions proofs previous theorems.
next theorem proves maintaining soundness completeness simultaneously impossible
even allow qualitative variable perform change, force
variables magnitude direction inherited next operating region.
Theorem 6: Even qualitative representation narrowed derivative, add
constant constraints used QDEs, variables magnitude direction allowed
perform discontinuous changes operating region transitions, still impossible build
sound complete qualitative simulator based input-output vocabulary.
Proof: again, make changes QSIM models used simulating given
URM previous theorems. always, QSIM variable NRi N
registers Ri appearing URM program. addition that, define variables Dij
i, j {1, ...,N} j. satisfies equation Dij = NRi NRj throughout
simulation; is, keep track differences pairs register values. clearly
achieved inserting several add constraints operating regions model.
difference variables enable us compare two register values operating regions type
jump.
564

fiCAUSES INERADICABLE SPURIOUS PREDICTIONS QUALITATIVE SIMULATION

Furthermore, define auxiliary variables TRi {1, ..., N}. TRi initialized
values corresponding NRi, using technique NRi.
instruction type given URM program, define two operating regions.
clock variable U increase first operating regions value <unit, std>,
decrease next one <unit, std> <0, std>, performing discontinuous jump
program. order obtain variable behavior, make use simple harmonic
oscillator model given Table 12, variable X (denoting displacement
rest position oscillating object) oscillates values unit/2 unit/2,
variable U equated X + unit/2, oscillating 0 unit. model template given
Table 12 added every operating region. (That table contains variable names used
constructions previous proofs. variables treated previously described
manner, unless proof specifies otherwise.) following lemma establishes correctness
construction.
CONSTRAINTS

CORRESPONDENCES

MEANING

HALFUNIT(t) + HALFUNIT(t) = ONEUNIT(t)

c1 + c1 = unit

c1 = unit / 2

HALFUNIT(t) + V(t) = E(t)

c1 + v1 = 0

v1 = unit / 2

d/dt(X, V)

dX
=V
dt

d/dt(V, A)

d2X
=A
dt

X(t) + A(t) = Z(t)

d2X
+ X =0
dt

X(t) + HALFUNIT(t) = U(t)

U = X+unit/2

Table 12: Model Template Obtain Desired Behavior Variable U Clock
Oscillating Qualitative Values <0, std> <unit, std> (This Template Inserted
Constructed Operating Regions.)
Lemma 7: number r represented QSIM landmark, QSIM variable X
equated function r sin(t t0) using derivative, add constant constraints.
Proof Lemma 7:
seen Table 12, equation
d2
X (t ) + X (t ) = 0
dt

expressed using derivative, add constant constraints. equation general
solution form
X (t ) = c1 sin + c2 cos ,
565

(1)

fiYILMAZ & SAY

hence time derivative V form
V (t ) = c1 cos c2 sin .

Assume X V initialized follows:
X (t0 ) = 0
V (t0 ) = r .

substituting values equations above, one obtains equation system
0 = c1 sin t0 + c2 cos t0
r = c1 cos t0 c2 sin t0 ,

whose solution (Ylmaz, 2005) yields c1 = r cos t0 c2 = r sin t0. Substituting c1 c2
Equation (1), get X (t ) = r (cos 0 sin sin 0 cos ) = r sin (t 0 ) , thereby proving
lemma.
Proof Theorem 6 (continued):
Therefore, equate landmark v1 V unit/2 shown Table 12, initialize X
V 0 v1, respectively, ensure
X (t ) =

unit
sin(t t0 ) ,
2

i.e., variable X oscillates values unit/2 unit/2, desired.
consistent Lemma 7, oscillating variables Table 12 start simulation
qualitative values listed Table 13. variables, except B, starts value
<(0, ), inc>, initialized previously described.
VARIABLE

QUANTITY SPACE

INITIAL VALUE

U

[0, unit]

<(0, unit), dec>

E

(-, 0, )

<0, std>

X

(-, 0, )

<0, dec>

V

(-, v1, 0, )

<v1, std>



(-, 0, )

<0, inc>

Table 13: Quantity Spaces Initial Values Oscillating Variables
going denote two operating regions corresponding ith instruction
URM program OpRegi,1 OpRegi,2. variables qualitative values inherited
possible transitions, variable ever undergoes discontinuous change. Looking
carefully Tables 14-21, correspond initialization, instruction types, ending
URM, see simulation flows unique branch exception zero type
566

fiCAUSES INERADICABLE SPURIOUS PREDICTIONS QUALITATIVE SIMULATION

operating regions, possibility simulation branches one
behavior, behaviors correspond expected trajectory actual
URM directed OpReg|P|+1,1. (Note transitions infinite landmarks need
considered, since assume infinite landmarks specified unreachable values
variables models.) registers stay constant OpReg|P|+1,1, single operating
region corresponding end URM program, reached. rest proof
Theorem 2. contradiction variable ensures behavior nonhalting URM leads consistent initial state, hence determining consistency initial
state equivalent deciding halting problem, leading contradiction.
Operating Region: OpReg0
{Type: Initialization}
Constraint Set: required input value representation constraints (see Table 11)
B(t) + U(t) = ONEUNIT(t) correspondence 0 + unit = unit
add constraints linking NRi TRi relevant nunit variables
add constraints defining Dij variables
clock constraints (Table 12)
variables except B, U, X, V, E, constant.
Possible Transition:
Trigger: ( U = <0, std> )
New operating region: OpReg1,1
Variables inheriting qualitative values: variables

Table 14: Template Single Operating Region Corresponding Initialization Stage
3.2 Simulation within Single Operating Region
incompleteness proofs subsection 3.1 (as well Say & Akn, 2003) depend
capability turning constraints necessary, provided
operating region transition feature. Would problem persist forsook feature,
focused simulation qualitative models single operating region? show
answer question affirmative.
3.2.1 HILBERTS TENTH PROBLEM
name suggests, Hilberts Tenth Problem tenth 23 problems
announced 1900 famous mathematician David Hilbert challenge
mathematicians 20th century. asks algorithm deciding whether given
multivariate polynomial integer coefficients integer solutions. proven
algorithm exists (Matiyasevich, 1993). fact used Say Akn (2003)
original proof existence ineradicable spurious predictions outputs qualitative
simulators employing operating region transition feature larger set constraint types
deal paper.

567

fiYILMAZ & SAY

proof presented shortly, use undecidability slightly modified variant
setup described Hilbert: assume guarantee none variables given
polynomial zero solution whose existence question. clear modified
problem unsolvable well, following argument: Assume algorithm
takes multivariate polynomial integer coefficients input, announces
whether solution variables nonzero integer values exists finite time.
use subroutine construction algorithm sought Hilberts original
problem follows: systematically produce 2n polynomials input polynomial n
variables, new polynomials corresponds different subset
variables original polynomial replaced zero. run new
polynomials. easy see find one polynomials nonzero
integer solutions original polynomial integer solutions.
Operating Region: OpRegi,1
{Type: zero(n)}
Constraint Set: add constraints defining Dij variables
clock constraints (Table 12)
variables except U, X, V, E, A, NRn, Dij n {i,j} constant.
Possible Transition:
Trigger: ( U = <unit, std> ) ( NRn = <0, std> )
New operating region: OpRegi,2
Variables inheriting qualitative values: variables
Possible Transition:
Trigger: (( U = <unit, std> ) ( NRn <0, std> )) ( NRn = <(0, ), std> ) ( NRn = <(-, 0), std> )
New operating region: OpReg|P|+1, 1
Variables inheriting qualitative values: variables

Table 15: Template First Operating Region Corresponding zero(n) Instructions
3.2.2 SOUND COMPLETE QSIM WITHIN SINGLE OPERATING REGION SOLVES HILBERTS
TENTH PROBLEM
Theorem 8: Even qualitative representation narrowed derivative, add,
mult constant constraints used QDEs, simulation proceeds single
operating region, still impossible build sound complete qualitative simulator based
input-output vocabulary.
going start proof preliminary lemmata, first
reminiscent Lemma 7 previous subsection:
Lemma 9: real constant equated QSIM variable Xi, QSIM variable Yi
equated function sin ( X (t t0 )) using derivative, add, mult, constant constraints.
Proof: case Xi = 0 trivial, handled single constant constraint.
remaining case, consider following equation set:
568

fiCAUSES INERADICABLE SPURIOUS PREDICTIONS QUALITATIVE SIMULATION

Operating Region: OpRegi,2
{Type: zero(n)}
Constraint Set: add constraints defining Dij variables
clock constraints (Table 12)
variables except U, X, V, E, A, TRn constant.
Possible Transition:
Trigger: ( U = <0, std> ) ( TRn = <0, std> )
New operating region: OpRegi+1,1
Variables inheriting qualitative values: variables
Possible Transition:
Trigger: (( U = <0, std> ) ( TRn <0, std> ) ) ( TRn = <(0, ), std> ) ( TRn = <(-, 0), std> )
New operating region: OpReg|P|+1, 1
Variables inheriting qualitative values: variables

Table 16: Template Second Operating Region Corresponding zero(n) Instructions

Operating Region: OpRegi,1
{Type: succ(n)}
Constraint Set: TRn(t)+ U(t)= NRn(t)
add constraints defining Dij variables
clock constraints (Table 12)
variables except U, X, V, E, A, NRn, Dij n {i,j} constant.
Possible Transition:
Trigger: ( U = <unit, std> )
New operating region: OpRegi,2
Variables inheriting qualitative values: variables

Table 17: Template First Operating Region Corresponding succ(n) Instructions
d2
Yi (t ) + Wi Yi (t ) = 0
dt

Xi > 0
X ,
Wi = X i2 , Wi =
X , X < 0.

initial values
Yi (t0 ) = 0

569

(2)

(3)

fiYILMAZ & SAY

Operating Region: OpRegi,2
{Type: succ(n)}
Constraint Set: TRn(t)+ U(t)= NRn(t)
add constraints defining Dij variables
clock constraints (Table 12)
variables except U, X, V, E, A, TRn constant.
Possible Transition:
Trigger: ( U = <0, std> )
New operating region: OpRegi+1,1
Variables inheriting qualitative values: variables

Table 18: Template Second Operating Region Corresponding succ(n) Instructions

Operating Region: OpRegi,1
{Type: jump(m, n, q)}
Constraint Set: add constraints defining Dij variables
clock constraints (Table 12)
variables except U, X, V, E, constant.
Possible Transition:
Trigger: ( U = <unit, std> )
New operating region: OpRegi,2
Variables inheriting qualitative values: variables

Table 19: Template First Operating Region Corresponding jump(m, n, q) Instructions
Vi (t0 ) = X ,

Vi(t) time derivative Yi(t).
general solution Equation (2) is:

(

)

(

)

Yi (t ) = c1 sin Wi + c2 cos Wi .

Substituting Wi Equation (3) initial values equations Yi Vi,
solving equation systems results following (Ylmaz, 2005):
Xi > 0, c1 = cos(Xit0) c2 = sin(Xit0).
Xi < 0, c1 = cos(Xit0) c2 = sin(Xit0).
substitute formula Yi(t), obtain:
Yi (t ) = cos( X t0 )sin ( X ) sin ( X t0 ) cos( X ) = sin ( X (t t0 )) ,
570

Xi > 0,

fiCAUSES INERADICABLE SPURIOUS PREDICTIONS QUALITATIVE SIMULATION

Operating Region: OpRegi,2
{Type: jump(m, n, q)}
Constraint Set: add constraints defining Dij variables
clock constraints (Table 12)
variables except U, X, V, E, constant.
Possible Transition:
Trigger: ( Dmn = <0, std> ) ( U = <0, std> )
New operating region: OpRegq,1
Variables inheriting qualitative values: variables
Possible Transition:
Trigger: ( Dmn <0, std> ) ( U = <0, std> )
New operating region: OpRegi+1,1
Variables inheriting qualitative values: variables

Table 20: Template Second Operating Region Corresponding jump(m, n, q) Instructions

Operating Region: OpReg|P|+1, 1
{Type: End}
Constraint Set: S(t) = 0
variables except U, X, V, E, constant.

Table 21: Model Operating Region Corresponding End URM Program
Yi (t ) = cos( X t0 )sin (( X ) ) sin ( X t0 ) cos(( X ) ) = sin ( X (t t0 )) ,

Xi < 0.

Hence, Yi(t) = sin ( X (t t0 )) Xi 0.
Table 22 shows Equations (2) (3) initial values given representable
using derivative, add, mult, constant constraints. Note Xi kept constant
initialized either (0, ) (, 0), depending intended sign number, Yi
Ci must start zero, consistent construction above.
Lemma 10: Starting t0, function = sin(tt0) reaches value 0 first time time
point tE = t0 + . Moreover function Yi = sin(Xi(tt0)) reaches 0 time point tE
Xi integer.
Proof: equation sin(tt0) = 0 implies tt0 = n, n , since interested first
time point t0 becomes 0, get tE = t0 + . part second
statement, assume function Yi = sin(Xi(tt0)) reaches 0 tE = t0 + .
sin ( X (t 0 + 0 )) = sin ( X ) = 0 implies Xi integer. part, use
knowledge Xi integer conclude Yi(tE) = sin(Xi(t0 + t0)) = sin(Xi) = 0.
571

fiYILMAZ & SAY

CONSTRAINTS

MEANING

Z=0
Xi(t) + Ci(t) = Vi(t)

Vi(t0) = Xi

d/dt(Yi, Vi)

dYi
= Vi (t )
dt

d/dt(Vi, Ai)

2Yi
= Ai (t )
dt

Xi(t) Xi(t) = Wi(t)

Wi = X i2

Wi(t) Yi(t) = Li(t)

Li (t ) = Wi Yi (t )

Ai(t) + Li(t) = Z(t)

2Yi
+ Wi Yi (t ) = 0
dt

Table 22: Model Fragment Used Obtain Relationship Yi = sin ( X (t t0 ))
Proof Theorem 8: already mentioned, proof relies contradiction, namely
sound complete simulator, existed, could used construct algorithm solving
Hilberts Tenth Problem, follows:
Assume given polynomial P(x1, x2, x3, ..., xn) integer coefficients. start
constructing QSIM model fragment says P(x1, x2, x3, ..., xn) = 0: already
seen Section 3.1 equate desired integer QSIM variable. Represent integers
appearing coefficients polynomial manner. Introduce QSIM variable Xi
xi, declare Xi constant, use add mult constraints equate sum
products P(X1, X2, X3, ..., Xn) QSIM variable P, initialized 0. Note
tantamount saying present values Xi form solution polynomial.
clearly done single operating region, constraints types mult, add
constant.
extend model necessary constraints auxiliary variables equate
new variable function sin(tt0). (Either Lemma 7 Lemma 9 used
purpose.) specify Ys quantity space [0, ), simulation guaranteed finish
= tE = t0 + . Xi, define associated auxiliary variables Ci, Li, Wi, Vi, Ai Yi,
add template Table 22 model express relationship Yi = sin(Xi(tt0)). also

equate variable YS sum squares Yi, i.e. YS =

n





2

. Note YS = 0,

=1

Yi 0.
Finally, need make sure consistent behaviors ones Xi
integers (that is, relying Lemma 10, behaviors variable YS becomes 0 tE).
serve aim, add constraint F(t) Y(t) = YS(t) model.
simulate model 2n times, run corresponding different way initializing
Xi magnitudes selected set {(0, ), (, 0)}. sound complete simulator
572

fiCAUSES INERADICABLE SPURIOUS PREDICTIONS QUALITATIVE SIMULATION

would accept initial states Xi whose values cause
inconsistency model. Xi correspond exactly integer solutions
given polynomial, following reasoning variable F:
Note F defined YS/Y F(t) Y(t) = YS(t) constraint. know Y, Yi,
hence YS initially 0, meaning one use lHpitals rule find initial
value F. important, since Fs initial magnitude derivative infinite, QSIM
even supposed consider successors initial state. (We declare infinite landmarks
unreachable values variables, mentioned earlier. Even Fs magnitude finite
derivative infinite, simulation supposed continue, continuity
requirement would violated.) Fortunately,
n

sin ( X (t ))
2

F (t ) =

0



=1

sin (t t0 )

finite magnitude derivative t0: = t0, use lHpitals rule find
n

0
F (t0 ) = =
0

2X



sin ( X (t 0 t0 )) cos( X (t0 t0 ))

=1

= 0.

cos(t0 t0 )

Fs qualitative direction;
dF
(t ) =
dt

2 X sin ( X (t t0 )) cos( X (t t0 )) sin 2 ( X (t t0 )) cos(t t0 )

,



sin (t t0 )
sin 2 (t t0 )
=1

n



turns out, several applications lHpitals rule,
dF
(t0 ) =
dt

n

X

2


,

=1

clearly finite positive number, Fs initial qualitative value therefore <0, inc>.
Obviously, F = YS/Y guaranteed finite tE, reaches 0. variable YS
nonzero (implying least one Yi nonzero, Lemma 10 corresponding
Xi integer) tE, F(tE) equal , impossible since infinity declared
unreachable, states would eliminated spurious. If, hand, YS(tE) = 0,
then, see lHpitals rule, knowledge Xi integers,
n

0
F (t E ) = =
0


=1

n

2 X sin ( X (t E t0 ))cos ( X (t E t0 ))
=

cos (t E t0 )

2X
=1



sin ( X ) cos( X )
cos( )

= 0,

behaviors ending states supposed included simulation output.
supposedly complete sound simulator rejects initial states model due
inconsistency 2n runs, reason behavior predictions considered
simulator ended F(tE) = , inconsistency propagated back initial state led
rejection cases. conclude polynomial integer solutions.
hand, even one simulations prints initial state goes
successors, conclude solution exists. forms decision procedure required
573

fiYILMAZ & SAY

Hilberts Tenth Problem, leading contradiction. Therefore, sound complete simulation
impossible even one restricts oneself single operating region limited constraint
vocabulary mentioned statement theorem.

4. Conclusion
paper, considered several alternative subsets qualitative representation,
showed ineradicable spurious prediction problem persists even add
constant constraints allowed. one allows mult constraint well, resulting
qualitative simulator inherently incomplete even representation negative numbers
forbidden every variable forced specified zero uncertainty (i.e. single
unambiguous real number) initial state. final proof shows even ability
handling models multiple operating regions removed representation,
incompleteness problem would still persist, provided add, constant, derivative, mult
constraints allowed vocabulary. Note none vocabularies include
monotonic function constraint, relation type native qualitative
representation.
Although results paper demonstrated using QSIM representation input
output, valid qualitative simulators whose input output vocabularies
expressive specified subsets QSIM. (Also note proofs apply
automatically semi-quantitative simulators, whose representations extension
pure QSIM.) believe results important sense provide deeper
insight causes spurious predictions, helpful researchers aiming
construct provably sound complete simulators using weaker representations.
Finally, wish stress findings amount bad piece news
usefulness qualitative simulators practical domains usually utilized
may seem uninitiated eye. ones model specified level precision
involved models paper, one employ qualitative reasoner anyway.
really annoys users qualitative simulators occasional prediction eradicable
spurious behaviors, strengthening algorithms additional filters increasing
mathematical sophistication get rid continues important line
research.

References
Cutland, N. J. (1980). Computability: Introduction Recursive Function Theory. Cambridge,
UK: Cambridge University Press.
de Kleer, J., & Brown, J. S. (1984). qualitative physics based confluences. Artificial
Intelligence, 24, 7-83.
Fouch, P., & Kuipers, B. J. (1992). Reasoning energy qualitative simulation. IEEE
Transactions Systems, Man, Cybernetics, 22, 47-63.
Knik, T., & Say, A. C. C. (2003). Duration consistency filtering qualitative simulation.
Annals Mathematics Artificial Intelligence, 38, 269-309.
Kuipers, B. J., (1986). Qualitative simulation. Artificial Intelligence, 29, 289-338.

574

fiCAUSES INERADICABLE SPURIOUS PREDICTIONS QUALITATIVE SIMULATION

Kuipers, B. J. (1994). Qualitative Reasoning: Modeling Simulation Incomplete
Knowledge. Cambridge, MA: MIT Press.
Matiyasevich, Y. (1993). Hilberts Tenth Problem. Cambridge, MA: MIT Press.
Missier, A. (1991). Mathematical structures qualitative calculus, contribution qualitative
simulation. (In French) Ph.D. thesis, Institut National des Sciences Appliques de Toulouse.
Say, A. C. C. (1998). LHpitals filter QSIM. IEEE Transactions Pattern Analysis
Machine Intelligence, 20, 1-8.
Say, A. C. C. (2001). Improved reasoning infinity using qualitative simulation. Computing
Informatics, 20, 487-507.
Say, A. C. C. (2003). Sound complete qualitative simulation requires quantitative filtering.
Annals Mathematics Artificial Intelligence, 38, 257-267.
Say, A. C. C., & Akn, H. L. (2003). Sound complete qualitative simulation impossible.
Artificial Intelligence, 149, 251-266.
Say, A. C. C., & Kuru, S. (1993). Improved filtering QSIM algorithm. IEEE Transactions
Pattern Analysis Machine Intelligence, 15, 967-971.
Shepherdson, J. C., & Sturgis, H. E. (1963). Computability recursive functions. Journal
ACM, 10, 217-255.
Shults, B., & Kuipers, B. (1997). Proving properties continuous systems: Qualitative
simulation temporal logic. Artificial Intelligence, 92, 91-129.
Struss, P. (1990). Problems interval-based qualitative reasoning. Weld, D. S., & de Kleer, J.
(Eds.) Readings Qualitative Reasoning Physical Systems. San Mateo, CA: Morgan
Kaufmann, 288-305.
Weld, D. S., & de Kleer, J. (Eds.) (1990). Readings Qualitative Reasoning Physical
Systems. San Mateo, CA: Morgan Kaufmann.
Ylmaz, . (2005). Computability-theoretic limitations qualitative simulation. M. S. Thesis,
Boazii University, stanbul, Turkey.
(http://www.cmpe.boun.edu.tr/graduate/allthesis/m_3.pdf)

575

fiJournal Artificial Intelligence Research 27 (2006) 617-674

Submitted 07/06; published 12/06

Uncertainty Soft Temporal Constraint Problems: General
Framework Controllability Algorithms Fuzzy Case
Francesca Rossi
Kristen Brent Venable

FROSSI @ MATH . UNIPD .
KVENABLE @ MATH . UNIPD .

University Padova, Department Pure Applied Mathematics,
Via Trieste, 63 35121 PADOVA ITALY

Neil Yorke-Smith

NYSMITH @ AI . SRI . COM

SRI International,
333 Ravenswood Ave, Menlo Park, CA 94025 USA

Abstract
real-life temporal scenarios, uncertainty preferences often essential coexisting
aspects. present formalism quantitative temporal constraints preferences
uncertainty defined. show three classical notions controllability (that is, strong,
weak, dynamic), developed uncertain temporal problems, generalized handle preferences well. defining general framework, focus problems
preferences follow fuzzy approach, properties assure tractability.
problems, propose algorithms check presence controllability properties. particular, show setting dealing simultaneously preferences uncertainty
increase complexity controllability testing. also develop dynamic execution algorithm,
polynomial complexity, produces temporal plans uncertainty optimal
respect fuzzy preferences.

1. Introduction
Current research temporal constraint reasoning, exposed difficulties real-life problems, found lacking expressiveness flexibility. rich application domains
often necessary simultaneously handle temporal constraints, also preferences
uncertainty.
need seen many scheduling domains. motivation line research
described paper domain planning scheduling NASA space missions. NASA
tackled many scheduling problems temporal constraints used reasonable success, showing limitations lack capability deal uncertainty
preferences. example, Remote Agent (Rajan, Bernard, Dorais, Gamble, Kanefsky, Kurien,
Millar, Muscettola, Nayak, Rouquette, Smith, Taylor, & Tung, 2000; Muscettola, Morris, Pell, &
Smith, 1998) experiments, consisted placing AI system on-board plan execute
spacecraft activities, represents one interesting examples this. Remote Agent worked
high level goals specified, example, duration frequency time windows
within spacecraft take asteroid images used orbit determination
on-board navigator. Remote Agent dealt flexible time intervals uncontrollable events;
however, deal preferences: temporal constraints hard. benefit
adding preferences framework would allow planner handle uncontrollable events
time maximizing mission managers preferences.
c
2006
AI Access Foundation. rights reserved.

fiROSSI , V ENABLE ,& YORKE -S MITH

recent NASA application rovers domain (Dearden, Meuleau, Ramakrishnan,
Smith, & Washington, 2002; Bresina, Jonsson, Morris, & Rajan, 2005). NASA interested
generation optimal plans rovers designed explore planetary surface (e.g. Spirit
Opportunity Mars) (Bresina et al., 2005). Dearden et al. (2002) describe problem generating plans planetary rovers handle uncertainty time resources. approach
involves first constructing seed plan, incrementally adding contingent branches
plan order improve utility. Again, preferences could used embed utilities directly
temporal model.
third space application, used several times paper running example,
concerns planning fleets Earth Observing Satellites (EOS) (Frank, Jonsson, Morris, & Smith,
2001). planning problem involves multiple satellites, hundreds requests, constraints
serve request, resources instruments, recording devices, transmitters
ground stations. response requests placed scientists, image data acquired EOS.
data either downlinked real time recorded board playback later time.
Ground stations satellites available receive downlinked images. Different satellites
may able communicate subset resources, transmission rates differ
satellite satellite station station. Further, may different financial costs
associated using different communication resources. (Frank et al., 2001) EOS scheduling problem dealt using constraint-based interval representation. Candidate plans
represented variables constraints, reflect temporal relationship actions
constraints parameters states actions. Also, temporal constraints necessary
model duration ordering constraints associated data collection, recording, downlinking tasks. Solutions preferred based objectives (such maximizing number high
priority requests served, maximizing expected quality observations, minimizing
cost downlink operations). Uncertainty present due weather: specifically due duration
persistence cloud cover, since image quality obviously affected amount clouds
target. addition, events need observed may happen unpredictable
times uncertain durations (e.g. fires volcanic eruptions).
existing frameworks, Simple Temporal Problems Preferences (STPPs) (Khatib,
Morris, Morris, & Rossi, 2001), address lack expressiveness hard temporal constraints
adding preferences temporal framework, take account uncertainty. models, Simple Temporal Problems Uncertainty (STPUs) (Vidal & Fargier, 1999), account
contingent events, notion preferences. paper introduce framework
allows us handle preferences uncertainty Simple Temporal Problems.
proposed model, called Simple Temporal Problems Preferences Uncertainty (STPPUs),
merges two pre-existing models STPPs STPUs.
STPPU instance represents quantitative temporal problem preferences uncertainty
via set variables, representing starting ending times events (which controllable
agent not), set soft temporal constraints variables, includes interval containing allowed durations event allowed times events.
preference function associating element interval value specifies much
value preferred. soft constraints defined controllable uncontrollable
events. order clarify modeled STPPU, let us emphasize graduality
allowed terms preferences uncertainty. sense, uncertainty represented contingent STPPU constraints contingent STPU constraints:
618

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

durations assumed equally possible. addition expressing uncertainty, STPPUs, contingent constraints soft different preference levels associated different durations
contingent events.
problems, consider notions controllability similar defined STPUs,
used instead consistency presence uncertainty, adapt
handle preferences. notions, usually called strong, weak, dynamic controllability, refer
possibility controlling problem, is, executing agent assigning values
controllable variables, way optimal respect Nature decided,
decide, uncontrollable variables. word optimal crucial, since STPUs,
preferences, need care controllability, optimality. fact,
notions define paper directly correspond STPUs called strong, weak,
dynamic optimal controllability.
defining controllability notions proving properties, consider
restrictions shown make temporal problems preferences tractable
(Khatib et al., 2001; Rossi, Sperduti, Venable, Khatib, Morris, & Morris, 2002), i.e, semi-convex
preference functions totally ordered preferences combined idempotent operator.
context, controllability notions, give algorithms check whether
hold, show adding preferences make complexity testing
properties worse case without preferences. Moreover, dealing different levels
preferences, also define testing algorithms refer possibility controlling problem
maintaining preference least certain level (called -controllability). Finally,
context dynamic controllability, also consider execution dynamic optimal plans.
Parts content paper appeared (Venable & Yorke-Smith, 2003; Rossi, Venable, & Yorke-Smith, 2003; Yorke-Smith, Venable, & Rossi, 2003; Rossi, Venable, & Yorke-Smith,
2004). paper extends previous work least two directions. First, papers optimal controllability (strong dynamic) checked separately, check
optimal (strong dynamic) controllability and, hold, algorithm return
highest given problem -strong -dynamic controllable. Moreover, results
presented uniform technical environment, providing thorough theoretical study properties algorithms computational aspects, makes use several unpublished
proofs.
paper structured follows. Section 2 give background temporal constraints
preference uncertainty. Section 3 define formalism Simple Temporal
Problems preferences uncertainty and, Section 4, describe new notions
controllability. Algorithms test notions described respectively Section 5 Optimal
Strong Controllability, Section 6 Optimal Weak Controllability, Section 7 Optimal
Dynamic Controllability. Section 8 give general strategy using notions. Finally, Section 9, discuss related work, Section 10 summarize main results
point directions future developments. make paper readable, proofs
theorems contained Appendix.

2. Background
section give main notions temporal constraints (Dechter, Meiri, & Pearl, 1991)
framework Temporal Constraint Satisfaction Problems Preferences (TCSPPs) (Khatib

619

fiROSSI , V ENABLE ,& YORKE -S MITH

et al., 2001; Rossi et al., 2002), extend quantitative temporal constraints (Dechter et al., 1991)
semiring-based preferences (Bistarelli, Montanari, & Rossi, 1997). also describe Simple
Temporal Problems Uncertainty (STPUs) (Vidal & Fargier, 1999; Morris, Muscettola, & Vidal,
2001), extend tractable subclass temporal constraints model agent-uncontrollable
contingent events, define corresponding notions controllability, introduced (Vidal
& Fargier, 1999).
2.1 Temporal Constraint Satisfaction Problems
One requirements temporal reasoning system planning scheduling problems
ability deal metric information; words, handle quantitative information
duration events (such take ten twenty minutes get home). Quantitative
temporal networks provide convenient formalism deal information. consider
instantaneous events variables problem, whose domains entire timeline.
variable may represent either beginning ending point event, neutral point
time. effective representation quantitative temporal networks, based constraints, within
framework Temporal Constraint Satisfaction Problems (TCSPs) (Dechter et al., 1991).
paper interested particular subclass TCSPs, known Simple Temporal
Problems (STPs) (Dechter et al., 1991). problem, constraint time-points X
Xj represented constraint graph edge X Xj , labeled single interval [aij , bij ]
represents constraint aij Xj Xi bij . Solving STP means finding assignment
values variables temporal constraints satisfied.
Whereas complexity general TCSP comes one interval
constraint, STPs solved polynomial time. Despite restriction single interval per
constraint, STPs shown valuable many practical applications. STPs
attracted attention literature.
STP associated directed weighted graph G = (V, Ed ), called distance
graph. set nodes constraint graph twice number edges:
binary constraint variables X Xj , distance graph edge Xi Xj
labeled weight bij , representing linear inequality X j Xi bij , well edge Xj Xi
labeled weight aij , representing linear inequality X Xj aij .
path Xi Xj distance graph Gd , say variables Xi0 = Xi , Xi1 , Xi2 , . . .
P
, Xik = Xj induces following path constraint: X j Xi kh=1 bih1 ih . intersection
induced path constraints yields inequality X j Xi dij , dij length shortest
path Xi Xj , length defined, i.e. negative cycles distance
graph. STP consistent distance graph negative cycles (Shostak, 1981;
Leiserson & Saxe, 1988). means enforcing path consistency, algorithm
PC-2, sufficient solving STPs (Dechter et al., 1991). follows given STP effectively specified another complete directed graph, called d-graph, edge Xi Xj
labeled shortest path length ij distance graph Gd .
(Dechter et al., 1991) shown consistent STP backtrack-free (that is, decomposable) relative constraints d-graph. Moreover, set temporal constraints
form [dji , dij ] minimal STP corresponding original STP possible find one
solutions using backtrack-free search simply assigns variable value
satisfies minimal network constraints compatibly previous assignments. Two specific solu-

620

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

tions (usually called latest earliest assignments) given L = {d01 , . . . , d0n }
SE = {d10 , . . . , dn0 }, assign variable respectively latest earliest possible time
(Dechter et al., 1991).
d-graph (and thus minimal network) STP found applying FloydWarshalls Pairs Shortest Path algorithm (Floyd, 1962) distance graph complexity
O(n3 ) n number variables. graph sparse, Bellman-Ford Single Source
Shortest Path algorithm used instead, complexity equal O(nE), E
number edges. refer (Dechter et al., 1991; Xu & Choueiry, 2003) details
efficient STP solving.
2.2 Temporal CSPs Preferences
Although expressive, TCSPs model hard temporal constraints. means constraints
satisfied, solutions constraint equally satisfying. However,
many real-life situations solutions preferred others and, thus, global problem
find way satisfy constraints optimally, according preferences specified.
address need, TCSP framework generalized (Khatib et al., 2001)
associate temporal constraint preference function specifies preference
distance allowed constraint. framework merges TCSPs semiring-based soft
constraints (Bistarelli et al., 1997).
Definition 1 (soft temporal constraint) soft temporal constraint 4-tuple h{X, }, I, A, f
consisting
set two variables {X, } integers, called scope constraint;
set disjoint intervals = {[a1 , b1 ], . . . , [an , bn ]}, ai , bi Z, ai bi
= 1, . . . , n;
set preferences A;
preference function f : A, mapping elements preference
values, taken set A.
Given assignment variables X , X = v x = vy , say assignment
satisfies constraint h{X, }, I, A, f iff exists [a , bi ] ai vy vx bi .
case, preference associated assignment constraint f (v vx ) = p.2
variables preference set STPP apparent, omit write
soft temporal constraint pair hI, f i.
Following soft constraint approach (Bistarelli et al., 1997), preference set carrier
algebraic structure known c-semiring. Informally c-semiring = hA, +, , 0, 1i
set equipped two operators satisfying proscribed properties (for details, see Bistarelli
et al., 1997)). additive operator + used induce ordering preference set A; given
two elements a, b A, b iff + b = a. multiplicative operator used combine
preferences.

621

fiROSSI , V ENABLE ,& YORKE -S MITH

Definition 2 (TCSPP) Given semiring = hA, +, , 0, 1i, Temporal Constraint Satisfaction
Problems Preferences (TCSPP) pair hV, Ci, V set variables C
set soft temporal constraint pairs variables V preferences A.2
Definition 3 (solution) Given TCSPP hV, Ci semiring S, solution complete assignment variables V . solution said satisfy constraint c C preference p
projection pair variables cs scope satisfies c preference p. write
pref (t, c) = p.2
solution global preference value, obtained combining, via operator,
preference levels solution satisfies constraints C.
Definition 4 (preference solution) Given TCSPP hV, Ci semiring S, preference
solution = hv1 , . . . , vn i, denoted val(t), computed cC pref (s, c).2
optimal solutions TCSPP solutions best global preference
value, best determined ordering values semiring.
Definition 5 (optimal solutions) Given TCSPP P = hV, Ci semiring S, solution
P optimal every solution 0 P , t0 6S t.2
Choosing specific semiring means selecting class preferences. example, semiring
SF CSP = h[0, 1], max, min, 0, 1i
allows one model so-called fuzzy preferences (Ruttkay, 1994; Schiex, 1992), associate
element allowed constraint preference 0 1 (with 0 worst
1 best preferences), gives complete assignment minimal among preferences selected constraints. optimal solutions solutions maximal
preference. Another example semiring CSP = h{f alse, true}, , , f alse, truei,
allows one model classical TCSPs, without preferences, general TCSPP framework.
paper refer fuzzy temporal constraints. However, absence preferences
temporal constraints always modelled using two elements 0 1
constraints. Thus preferences always coexists hard constraints.
special case occurs constraint TCSPP contains single interval. analogy
done case without preferences, problems called Simple Temporal Problems
Preferences (STPPs). class temporal problems interesting because, noted above,
STPs polynomially solvable general TCSPs NP-hard, computational effect
adding preferences STPs immediately obvious.
Example 1 Consider EOS example given Section 1. Figure 1 show STPP
models scenario three events scheduled satellite: start time (Ss)
ending time (Se) slewing procedure starting time (Is) image retrieval.
slewing activity example take 3 10 units time, ideally 3 5 units
time, shortest time possible otherwise. image taking start time 3
20 units time slewing initiated. third constraint, variables Se,
models fact better image taking start soon slewing stopped.2
622

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

11 1
0.9

0.8
0.7
0.6
0.5

3 4 5 6 7

8 9 10

Ss

Se

1

1 1 1
0.9

0.9
0.8

0.8

0.7

0.7

0.6

0.6
3

20


4 3 2 1

0 1 2 3

4

5

6

Figure 1: STPP Example 1.
following example, instead, consider STPP uses set-based semiring:
Sset = h(A), , , , Ai. Notice that, fuzzy semiring, multiplicative operator, i.e.,
intersection, idempotent, order induced additive operator, i.e., union, partial.
Example 2 Consider scenario three friends, Alice, Bob, Carol, want meet drink
dinner must decide time meet reserve dinner depending
long takes get restaurant. variables involved problem are: global
start time X0 , value 0 domain, start time drink (Ds), time
leave dinner (De), time arrival restaurant (Rs). meet, drink,
8 9:00pm leave dinner half hour. Moreover, depending
restaurant choose, take 20 40 minutes get dinner. Alice prefers
meet early dinner early, like Carol. Bob prefers meet 8:30 go best
restaurant farthest. Thus, following two soft temporal constraints. first
constraint defined variable pair (X0 , Ds), interval [8:00,9:00] preference
function, fs , that, fs (8 : 00) = {Alice, Carol}, fs (8 : 30) = {Bob} fs (9 : 00) = .
second constraint binary constraint pair (De,Rs), interval [20, 40] preference
function fse , that, fse (20) = {Alice, Carol} fse (20) = fse (20) = {Bob}.
additional hard constraint variable pair (Ds, De), modeled
interval [30, 30] single preference equal {Alice, Carol, Bob}. optimal solution
(X0 = 0, Ds = 8 : 00, De = 8 : 30, Rs = 8 : 50), preference {Alice, Carol}. 2
Although TCSPPs STPPs NP-hard, (Khatib et al., 2001) tractable subclass
STPPs described. tractability assumptions are: semi-convexity preference functions,
idempotence combination operator semiring, totally ordered preference set.
preference function f soft temporal constraint hI, f semi-convex iff < + , set
{x I, f (x) y} forms interval. Notice semi-convex functions include linear, convex,
also step functions. aggregation operator totally ordered set idempotent
min (Dubois & Prade, 1985), i.e. combination operator F CSP semiring.
tractability assumptions met, STPPs solved polynomial time. (Rossi
et al., 2002) two polynomial solvers tractable subclass STPPs proposed. One solver

623

fiROSSI , V ENABLE ,& YORKE -S MITH

based extension path consistency TCSPPs. second solver decomposes problem
solving set hard STPs.
2.3 Simple Temporal Problems Uncertainty
reasoning concerns activities agent performs interacting external world, uncertainty often unavoidable. TCSPs assume activities durations control
agent. Simple Temporal Problems Uncertainty (STPUs) (Vidal & Fargier, 1999) extend
STPs distinguishing contingent events, whose occurrence controlled exogenous factors
often referred Nature.
STPs, activity durations STPUs modelled intervals. start times activities assumed controlled agent (this brings loss generality). end times,
however, fall two classes: requirement (free Vidal & Fargier, 1999) contingent.
former, STPs, decided agent, agent control latter:
observe occurrence event; observation supposed known immediately
event. information known prior observation time-point nature respect
interval duration. Durations contingent links assumed independent.
STPU, variables thus divided two sets depending type time-points
represent.
Definition 6 (variables) variables STPU divided into:
executable time-points: points, b , whose time assigned executing agent;
contingent time-points: points, e , whose time assigned external world.2
distinction variables leads constraints also divided two sets, requirement contingent, depending type variables constrain. Note STPs
constraints binary. Formally:
Definition 7 constraints STPU divided into:
requirement constraint (or link) r ij , generic time-points ti tj 1 , interval Iij =
[lij , uij ] lij (tj ) (ti ) uij (ti ) value assigned variable ti
contingent link ghk , executable point bh contingent point ek , interval Ihk =
[lij , uij ] contains possible durations contingent event represented b h
ek .2
formal definition STPU following:
Definition 8 (STPU) Simple Temporal Problem Uncertainty (STPU) 4-tuple N =
{Xe , Xc , Rr , Rc } that:
Xe = {b1 , . . . , bne }: set executable time-points;
Xc = {e1 , . . . , enc }: set contingent time-points;
1. general ti tj either contingent executable time-points.

624

fiU NCERTAINTY

Start
Cooking

SOFT TEMPORAL CONSTRAINT PROBLEMS

[20,40]
End
Cooking

[0,10]

requirement constr.

[30,60]

contingent constr.

Start
Dinner

contingent timepoint

End
Dinner

executable timepoint

Figure 2: STPU Example 3.
Rr = {ci1 j1 , . . . , ciC jC }: set C requirement constraints;
Rc = {gi1 j1 , . . . , giG jG }: set G contingent constraints.2
Example 3 example taken (Vidal & Fargier, 1999), describes scenario
modeled using STPU. Consider two activities Cooking dinner. Assume
dont want eat dinner cold. Also, assume control start cooking
dinner starts finish cooking dinner over.
STPU modeling example depicted Figure 2. two executable time-points {Startcooking, Start-dinner} two contingent time-points {End-cooking, End-dinner}. Moreover,
contingent constraint variables {Start-cooking, End-cooking} models uncontrollable duration
fixing dinner take anywhere 20 40 minutes; contingent constraint
variables {Start-dinner, End-dinner} models uncontrollable duration dinner last
30 60 minutes. Finally, requirement constraint variables {End-cooking, Startdinner} simply bounds 10 minutes time food ready
dinner starts.2
Assignments executable variables assignments contingent variables distinguished:
Definition 9 (control sequence) control sequence assignment executable time-points.
said partial assigns values proper subset executables, otherwise complete.2
Definition 10 (situation) situation set durations contingent constraints.
contingent constraints assigned duration said partial, otherwise complete.2
Definition 11 (schedule) schedule complete assignment time-points X e Xc .
schedule identifies control sequence, , consisting assignments executable
time-points, situation, , set durations identified assignments
contingent constraints. Sol(P ) denotes set schedules STPU.2
easy see situation corresponds STP. fact, durations
contingent constraints fixed, uncertainty problem, becomes
STP, called underlying STP. formalized notion projection.
Definition 12 (projection) projection P , corresponding situation , STP obtained
leaving requirement constraints unchanged replacing contingent constraint g hk

625

fiROSSI , V ENABLE ,& YORKE -S MITH

constraint h[hk , hk ]i, hk duration event represented g hk . P roj(P )
set projections STPU P .2
2.4 Controllability
clear order solve problem uncertainty possible situations must considered.
notion consistency defined STPs apply since requires existence single
schedule, sufficient case since situations equally possible.2
reason, (Vidal & Fargier, 1999), notion controllability introduced. Controllability
STPU is, sense, analogue consistency STP. Controllable means agent
means execute time-points control, subject constraints. notion
controllability expressed, terms ability agent find, given situation,
appropriate control sequence. ability identified strategy:
Definition 13 (strategy) strategy map : P roj(P ) Sol(P ), every projection P , S(P ) schedule induces durations contingent constraints.
Further, strategy viable if, every projection P , S(P ) solution P .2
write [S(P )]x indicate value assigned executable time-point x schedule
S(P ), [S(P )]<x history x S(P ), is, set durations contingent constraints occurred S(P ) execution x, i.e. partial solution far.
(Vidal & Fargier, 1999), three notions controllability introduced STPUs.
2.4.1 TRONG C ONTROLLABILITY
first notion is, name suggests, restrictive terms requirements
control sequence must satisfy.
Definition 14 (Strong Controllability) STPU P Strongly Controllable (SC) iff
execution strategy s.t. P P roj(P ), S(P ) solution P , [S(P1 )]x = [S(P2 )]x ,
P1 , P2 projections every executable time-point x.2
words, STPU strongly controllable fixed execution strategy works
situations. means fixed control sequence consistent possible
scenario world. Thus, notion strong controllability related conformant
planning. clearly strong requirement. Vidal Fargier (1999) suggest, SC may
relevant applications situation observable complete
control sequence must known beforehand (for example cases activities depend
control sequence, production planning area).
(Vidal & Fargier, 1999) polynomial time algorithm checking STPU strongly
controllable proposed. main idea rewrite STPU given input equivalent STP
executable variables. important notice, contents paper,
algorithm StronglyControllable takes input STPU P = {X e , Xc , Rr , Rc } returns
output STP defined variables Xe . STPU input strongly controllable iff derived
STP consistent. Moreover, every solution STP control sequence guarantees
2. Tsamardinos (2002) augmented STPUs include probability distributions possible situations;
paper implicitly assume uniform, independent distribution link.

626

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

strong controllability STPU. STP consistent, output StronglyControllable
minimal form.
(Vidal & Fargier, 1999) shown complexity StronglyControllable O(n 3 ),
n number variables.
2.4.2 W EAK C ONTROLLABILITY
hand, notion controllability fewest restrictions control sequences
Weak Controllability.
Definition 15 (Weak Controllability) STPU P said Weakly Controllable (WC) iff
P P roj(P ) strategy s.t. (P ) solution P .2
words, STPU weakly controllable viable global execution strategy:
exists least one schedule every situation. seen minimum requirement since,
property hold, situations way execute
controllable events consistent way. also looks attractive since, STPU shown
WC, soon one knows situation, one pick apply control sequence
matches situation. Unfortunately (Vidal & Fargier, 1999) shown property
useful classical planning. Nonetheless, WC may relevant specific applications (as largescale warehouse scheduling) actual situation totally observable (possibly
before) execution starts, one wants know advance that, whatever situation,
always least one feasible control sequence.
(Vidal & Fargier, 1999) conjectured (Morris & Muscettola, 1999) proven
complexity checking weak controllability co-NP-hard. algorithm proposed
testing WC (Vidal & Fargier, 1999) based classical enumerative process lookahead
technique.
Strong Controllability implies Weak Controllability (Vidal & Fargier, 1999). Moreover,
STPU seen STP uncertainty ignored. enforcing path consistency removes
elements contingent intervals, elements belong solution. so,
possible conclude STPU weakly controllable.
Definition 16 (pseudo-controllability) STPU pseudo-controllable applying path consistency leaves intervals contingent constraints unchanged.2
Unfortunately, path consistency leaves contingent intervals untouched, cannot conclude STPU weakly controllable. is, WC implies pseudo-controllability
converse false. fact, weak controllability requires given possible combination durations contingent constraints STP corresponding projection must consistent.
Pseudo-controllability, instead, guarantees possible duration contingent constraint least one projection contains duration consistent STP.
2.4.3 DYNAMIC C ONTROLLABILITY
dynamic applications domains, planning, situation observed time. Thus
decisions made even situation remains partially unknown. Indeed distinction
Strong Dynamic Controllability equivalent conformant conditional planning. final notion controllability defined (Vidal & Fargier, 1999) address
627

fiROSSI , V ENABLE ,& YORKE -S MITH

Pseudocode DynamicallyControllable
1. input STPU W;
2. W pseudo-controllable write DC stop;
3. Select triangles ABC, C uncontrollable, C,
upper bound BC interval, v, non-negative.
4. Introduce tightenings required Precede case
waits required Unordered case.
5. possible regressions waits,
converting unconditional waits lower bounds.
Also introduce lower bounds provided general reduction.
6. steps 3 4 produce new (or tighter)
constraints, return true, otherwise go 2.
Figure 3: Algorithm DynamicallyControllable proposed (Morris et al., 2001) checking DC
STPU.
[x,y]



C

requirement constr.
contingent constr.
contingent timepoint

[p,q]

[u,v]

executable timepoint

B

Figure 4: triangular STPU.
case. give definition provided (Morris et al., 2001) equivalent
compact.
Definition 17 (Dynamic Controllability) STPU P Dynamically Controllable (DC) iff
strategy P1 , P2 P roj(P ) executable time-point x:
1. [S(P1 )]<x = [S(P2 )]<x [S(P1 )]x = [S(P2 )]x ;
2. S(P1 ) solution P1 S(P2 ) solution P2 .2
words, STPU dynamically controllable exists viable strategy built,
step-by-step, depending observed events step. SC = DC DC =
WC. Dynamic Controllability, seen useful controllability notion practice, also
one requires complicated algorithm. Surprisingly, Morris et al. (2001) Morris
Muscettola (2005) proved DC polynomial size STPU representation. Figure 3
pseudocode algorithm DynamicallyControllable shown.
paper extend notion dynamic controllability order deal preferences. algorithm propose test extended property require good (even
complete) understanding DynamicallyControllable algorithm. Thus, give
necessary details algorithm.
628

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

seen, algorithm based considerations triangles constraints.
triangle shown Figure 4 triangular STPU one contingent constraint, AC, two executable
time-points, B, contingent time-point C. Based sign u v, three different
cases occur:
Follow case (v < 0): B always follow C. STPU path consistent also DC
since, given time C occurs A, definition path consistency, always
possible find consistent value B.
Precede case (u 0): B always precede happen simultaneously C.
STPU dynamically controllable v x u, interval [p, q] AB
replaced interval [y v, x u], sub-interval containing elements
[p, q] consistent element [x, y].
Unordered case (u < 0 v 0): B either follow precede C. ensure dynamic
controllability, B must wait either C occur first, = v units time go
A. words, either C occurs B executed first value consistent
Cs time, B safely executed units time execution. described
additional constraint expressed wait AB written < C, >,
= v. course x v raise lower bound AB, p, v
(Unconditional Unordered Reduction), case raise x x > p (General
Unordered reduction) .
shown waits propagated (in Morris et al., 2001, term regressedis used
) one constraint another: wait AB induces wait another constraint involving A,
e.g. AD, depending type constraint DB. particular, two possible ways
waits regressed.
Regression 1: assume AB constraint wait hC, ti. Then, DB
constraint (including AB itself) upper bound, w, possible deduce wait hC,
wi AD. Figure 5(a) shows type regression.
Regression 2: assume AB constraint wait hC, ti, 0. Then,
contingent constraint DB lower bound, z, B 6= C, possible
deduce wait hC, zi AD. Figure 5(b) shows type regression.
Assume simplicity without loss generality executed time 0. Then, B
executed wait C executed first. wait expires, B safely
executed time left interval. Figure 6 shows, possible consider Follow
Precede cases special cases Unordered. Follow case put dummy wait
end interval, meaning B must wait C executed case (Figure 6
(a)). Precede case, set wait expires first element interval meaning
B executed C element interval consistent C (Figure 6
(b)). Unordered case thus seen combination two previous states. part
interval wait seen Follow case (in fact, B must wait C wait
expires), second part including following wait seen Precede case (after
wait expired, B executed assignment B corresponds element
part interval AB consistent possible future value assigned C).
629

fiROSSI , V ENABLE ,& YORKE -S MITH

[x,y]


[x,y]
C

Contingent

<C,t>

<C,tw>

C



[u,v]

Contingent

<C,t>

<C,tz>

[p,q]



[u,v]

[p,q]

B

B



[z,w]

[z,w]

requirement constr.
contingent constr.
controllable timepoint

requirement constr.
contingent constr.
controllable timepoint

contingent timepoint

contingent timepoint

(a) Regression 1

(b) Regression 2

Figure 5: Regressions algorithm DynamicallyControllable.

Follow Case

wait C executed
wait

execute regardless C

Precede Case

wait

Unordered Case

wait fo C executed

execute regardless C

wait

Figure 6: resulting AB interval constraint three cases considered
DynamicallyControllable algorithm.

DynamicallyControllable algorithm applies rules triangles STPU
regresses possible waits. inconsistency found, requirement interval becomes
empty contingent interval squeezed, STPU DC algorithm returns STPU
constraints may waits satisfy, intervals contain elements appear
least one possible dynamic strategy. STPU given execution algorithm
dynamically assigns values executables according current situation.
pseudocode execution algorithm, DC-Execute, shown Figure 7. execution
algorithm observes, time goes by, occurrence contingent events accordingly
executes controllables. controllable B, execution triggered (1) live,
630

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

Pseudocode DC-Execute
1. input STPU P ;
2. Perform initial propagation start time-point;
3. repeat
4. immediately execute executable time-points
reached upper bounds;
5. arbitrarily pick executable time-point x
live enabled yet executed, whose waits,
any, satisfied;
6. execute x;
7. propagate effect execution;
8. network execution complete return;
9. else advance current time,
propagating effect contingent time-points occur;
10. false;
Figure 7: Algorithm executes dynamic strategy STPU.
is, current time within bounds, (2) enabled, is, executables constrained
happen occurred, (3) waits imposed contingent time-points B
expired.
DC-Execute produces dynamically consistent schedule every STPU algorithm
DynamicallyControllable reports success (Morris et al., 2001). complexity algorithm
O(n3 r), n number variables r number elements interval. Since
polynomial complexity relies assumption bounded maximum interval size, Morris et al.
(2001) conclude DynamicallyControllable pseudo-polynomial. DC algorithm strong
polynomial complexity presented (Morris & Muscettola, 2005). new algorithm differs
previous one mainly manipulates distance graph rather constraint
graph STPU. complexity O(n 5 ). important notice purposes that,
distance graph produced output new algorithm, possible directly recover
intervals waits STPU produced output original algorithm described (Morris
et al., 2001).

3. Simple Temporal Problems Preferences Uncertainty (STPPUs)
Consider temporal problem would model naturally preferences addition hard
constraints, one also features uncertainty. Neither STPP STPU adequate model
problem. Therefore propose call Simple Temporal Problems Preferences Uncertainty, STPPUs short.
Intuitively, STPPU STPP time-points partitioned two classes, requirement contingent, STPU. Since time-points controllable
agent, notion consistency STP(P) replaced controllability,
STPU. Every solution STPPU global preference value, STPP, seek
solution maximizes value, satisfying controllability requirements.

631

fiROSSI , V ENABLE ,& YORKE -S MITH

precisely, extend definitions given STPPs STPUs fit STPPUs
following way.
Definition 18 context preferences:
executable time-point variable, x , whose time assigned agent;
contingent time-point variable, e , whose time assigned external world;
soft requirement link rij , generic time-points ti tj 3 , pair hIij , fij i, Iij =
[lij , uij ] lij (tj ) (ti ) uij (ti ) value assigned variable ti ,
fij : Iij preference function mapping element interval element
preference set, A, semiring = hA, +, , 0, 1i;
soft contingent link ghk , executable point bh contingent point ek , pair hIhk , fhk
interval Ihk = [lhk , uhk ] contains possible durations contingent event
represented bh ek fhk : Ihk preference function maps element
interval element preference set A.2
types constraints, preference function represents preference agent
duration event distance two events. However, soft requirement
constraints agent control guided preferences choosing values
time-points, soft contingent constraints preference represents merely desire agent
possible outcomes Nature: control outcomes. noticed
STPPUs uncertainty modeled, like STPUs, assuming complete ignorance
events likely happen. Thus, durations contingent events assumed equally
possible (or plausible) different levels plausibility allowed.
state formally definition STPPUs, combines preferences
definition STPP contingency definition STPU.
Definition 19 (STPPU) Simple Temporal Problem Preferences Uncertainty (STPPU)
tuple P = (Ne , Nc , Lr , Lc , S) where:
Ne set executable time-points;
Nc set contingent time-points;
= hA, +, , 0, 1i c-semiring;
Lr set soft requirement constraints S;
Lc set soft contingent constraints S.2
Note that, STPPs, also STPPUs model hard constraints soft constraints
element interval mapped maximal element preference set. Further, without
loss generality, following assumptions made STPUs (Morris et al., 2001), assume
two contingent constraints end time-point.
3. Again, general ti tj either contingent executable time-points.

632

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

complete assignment time-points compute global preference,
STPPs. done according semiring-based soft constraint schema: first project
assignment soft constraint, obtaining element interval preference
associated element; combine preferences obtained constraints
multiplicative operator semiring. Given two assignments preference, best
chosen using additive operator. assignment optimal assignment
preference better semirings ordering.
following summarize definitions given STPUs, extending directly
STPPUs.
Definition 20 Given STPPU P :
schedule complete assignment time-points N e Nc ;
Sched(P) set schedules P ; Sol(P) set schedules P
consistent constraints P (see Definition 1, Section 2.2);
Given schedule P , situation (usually written ) set durations contingent constraints s;
Given schedule P , control sequence (usually written set assignments
executable time-points s;
T, schedule [T, ]x = []x 4 , x Ne , every contingent constraint,
ghk Lc , defined executable bh contingent time-point ek , [T, ]ek -[T, ]bh = hk ,
hk duration ghk ;
projection P corresponding situation STPP obtained P leaving
requirement constraints unchanged replacing contingent constraint g hk soft
constraint h[hk , hk ], f (hk )i, hk duration event represented g hk
, f (hk ) preference associated duration;
Given projection P indicate Sol(P ) set solutions P define
OptSol(P ) = {s Sol(P )| 6 s0 Sol(P ), pref (s0 ) > pref (s)}; set preferences totally ordered indicate opt(P ) preference optimal solution
P ;
Proj(P) set projections STPPU P;
strategy map : P roj(P ) Sched(P ) every projection P , s(P )
schedule includes ;
strategy viable , S(P ) solution P , is, satisfies soft temporal
constraints. Thus viable strategy mapping : P roj(P ) Sol(P ). case
indicate pref (S(P )) global preference associated schedule S(P ) STPP
P .2
4. Regarding notation, case hard constraints, given executable time-point x, write [S(P )]x
indicate value assigned x S(P ), [S(P )]<x indicate durations contingent events
finish prior x S(P ).

633

fiROSSI , V ENABLE ,& YORKE -S MITH

1

0.9
0.5

x=1

8=y

EC

SC
1

1

0.9

p=1

0.9

0.6

0.6

u=6

5=q

4=v

SA
requirement constr.

1

contingent constr.

0.6

contingent timepoint

0.8

EA

executable timepoint

s=2

5=t

Figure 8: Example STPPU Earth Observing Satellites domain.
Example 4 Consider example following scenario Earth Observing Satellites
domain (Frank et al., 2001) described Section 1. Suppose request observing region
interest received accepted. collect data, instrument must aimed
target images taken. might be, however, certain period time
window allocated observation, region interest covered clouds. earlier
cloud coverage ends better, since maximise quality quantity retrieved
data; coverage controllable.
Suppose time window reserved observation 1 8 units time
start counting time cloud occlusion region interest observable. Also, suppose,
order observation succeed, aiming procedure must start 5 units
starting time, ideally 3 units, actually begin least 1 time unit
weather becomes observable. Ideally aiming procedure start slightly cloud
coverage end. starts early, then, since instrument activated immediately
aimed, clouds might still occlude region image quality poor. hand,
waits long clouds disappeared precious time
occlusion wasted aiming instrument instead taking images. aiming procedure
controlled mission manager take anywhere 2 5 units time.
ideal duration 3 4 units, since short time 2 units would put instrument pressure,
long duration, like 5 units, would waste energy.
scenario, rather tedious describe words, compactly represented STPPU
shown Figure 8 following features:
set executable time-points SC (Start Clouds), SA (Start Aiming), EA (End Aiming);
contingent time-point EC (End Clouds);
set soft requirement constraints {SC SA, SA EC, SA EA};
soft contingent constraint {SC EC};

634

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

fuzzy semiring SFCSP = h[0, 1], max, min, 0, 1i.
solution STPPU Figure 8 schedule = {SC = 0, SA = 2, EC = 5, EA = 7}.
situation associated projection contingent constraint, SC EC,
i.e. = 5, control sequence assignment executable time-points, i.e. =
{SC = 0, SA = 2, EA = 7}. global preference obtained considering preferences
associated projections constraints, pref(2) = 1 SC SA, pref(3) = 0.6
SA EC, pref(5) = 0.9 SA EA, pref(5) = 0.8 SC EC. preferences
must combined using multiplicative operator semiring, min,
global preference 0.6. Another solution 0 = {SC = 0, SA = 4, EC = 5, EA = 9}
global preference 0.8. Thus s0 better solution according semiring ordering since
max(0.6, 0.8) = 0.8.2

4. Controllability Preferences
consider possible extend notion controllability accommodate preferences. general interested ability agent execute time-points
control, subject constraints also best possible way respect preferences.
transpires meaning best possible way depends types controllability
required. particular, concept optimality must reinterpreted due presence uncontrollable events. fact, distinction nature events induces difference
meaning preferences expressed them, mentioned previous section. scenario given certain level desirability, expressing much agent likes
situation. Then, agent often several choices events controls consistent
scenario. choices might preferable respect others. expressed
preferences requirement constraints information guide agent
choosing best possible actions take. Thus, concept optimality relative
specific scenario. final preference complete assignment overall value combines
much corresponding scenario desirable agent well agent reacted
scenario.
concepts controllability propose are, thus, based possibility
agent execute events control best possible way given actual situation. Acting optimal way seen lowering preference given uncontrollable
events.
4.1 Strong Controllability Preferences
start considering strongest notion controllability. extend notion, taking
account preferences, two ways, obtaining Optimal Strong Controllability -Strong Controllability, preference level. see, first notion corresponds stronger
requirement, since assumes existence fixed unique assignment executable timepoints optimal every projection. second notion requires fixed assignment
optimal projections maximum preference value greater ,
yield preference 6< cases.

635

fiROSSI , V ENABLE ,& YORKE -S MITH

Definition 21 (Optimal Strong Controllability) STPPU P Optimally Strongly Controllable
(OSC) iff viable execution strategy s.t.
1. [S(P1 )]x = [S(P2 )]x , P1 , P2 P roj(P ) every executable time-point x;
2. S(P ) OptSol(P ), P P roj(P ). 2
words, STPPU OSC fixed control sequence works possible
situations optimal them. definition, optimal means
assignment agent choose executable time-points could yield higher preference
situation. Since powerful restriction, mentioned before, instead look
reaching certain quality threshold:
Definition 22 (-Strong Controllability) STPPU P -Strongly Controllable (-SC),
preference, iff viable strategy s.t.
1. [S(P1 )]x = [S(P2 )]x , P1 , P2 P roj(P ) every executable time-point x;
2. S(P ) OptSol(P ),P P roj(P ) 6 s0 OptSol(P ) pref (s0 ) > ;
3. pref (S(P )) 6< otherwise.2
words, STPPU -SC fixed control sequence works situations results optimal schedules situations optimal preference level
projection > schedule preference smaller cases.
4.2 Weak Controllability Preferences
Secondly, extend similarly least restrictive notion controllability. Weak Controllability requires existence solution possible situation, possibly different one situation.
extend definition requiring existence optimal solution every situation.
Definition 23 (Optimal Weak Controllability) STPPU P Optimally Weakly Controllable
(OWC) iff P P roj(P ) strategy s.t. (P ) optimal solution P .2
words, STPPU OWC if, every situation, control sequence results
optimal schedule situation.
Optimal Weak Controllability STPPU equivalent Weak Controllability corresponding STPU obtained ignoring preferences, formally prove Section 6.
reason projection P least one solution must optimal solution.
Moreover, STPPU underlying STPU either WC not. Hence
make sense define notion -Weak Controllability.
4.3 Dynamic Controllability Preferences
Dynamic Controllability (DC) addresses ability agent execute schedule choosing
incrementally values assigned executable time-points, looking past.
preferences available, desirable agent acts way guaranteed
consistent possible future outcome also way ensures absence regrets
w.r.t. preferences.
636

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

Definition 24 (Optimal Dynamic Controllability) STPPU P Optimally Dynamically Controllable (ODC) iff viable strategy P 1 , P2 P roj(P ) executable
time-point x:
1. [S(P1 )]<x = [S(P2 )]<x [S(P1 )]x = [S(P2 )]x ;
2. S(P1 ) OptSol(P1 ) S(P2 ) = OptSol(P2 ).2
words, STPPU ODC exists means extending current partial control
sequence complete control sequence future way resulting schedule
optimal. before, also soften optimality requirement preference reaching
certain threshold.
Definition 25 (-Dynamic Controllability) STPPU P -Dynamically Controllable (-DC)
iff viable strategy P 1 , P2 P roj(P ) every executable time-point x:
1. [S(P1 )]<x = [S(P2 )]<x [S(P1 )]x = [S(P2 )]x ;
2. S(P1 ) OptSol(P1 ) S(P2 ) OptSol(P2 ) 6 s1 OptSol(P1 ) pref (s1 ) >
6 s2 OptSol(P2 ) pref (s2 ) > ;
3. pref(S(P1 )) 6< pref(S(P2 )) 6< otherwise.2
words, STPPU -DC means extending current partial control
sequence complete sequence; optimality guaranteed situations preference
6> . projections resulting dynamic schedule preference smaller
.
4.4 Comparing Controllability Notions
consider relation among different notions controllability STPPUs.
Recall STPUs, SC = DC = W C (see Section 2). start giving similar
result holds definitions optimal controllability preferences. Intuitively,
single control sequence optimal situations, clearly executed
dynamically, assigning values control sequence current time reaches them.
Moreover if, whatever final situation be, know consistently assign values
executables, looking past assignments, never backtrack preferences,
clear every situation least optimal solution.
Theorem 1 STPPU P OSC, ODC; ODC, OWC.
Proofs theorems given appendix. opposite implications Theorem 1
hold general. fact sufficient recall hard constraints special case soft
constraints use known result STPUs (Morris et al., 2001).
examples consider following two, defined fuzzy semiring. Figure 9 shows
STPPU OWC ODC. is, fact, easy see assignment C,
projection STPPU consistently extended assignment B. However,
show Section 7 STPPU depicted ODC.
637

fiROSSI , V ENABLE ,& YORKE -S MITH

11 1
0.9

0.8
0.7
0.6
0.5

x=3 4

5 6



7

8

9 10=y

C

contingent

1
0.9

1 1 1
0.9

0.8

0.9
0.8

0.8

0.7

0.7

0.7

0.6

0.6

0.6
p=3 4 5

6 7=q

requirement constr.

u=4 3 2 1

B

contingent constr.

0 1

2

3

contingent timepoint
executable timepoint

Figure 9: STPPU OWC ODC.

1

1



2

C

1

2

1

3

B

1

requirement constr.
contingent constr.
contingent timepoint
executable timepoint

Figure 10: STPPU ODC OSC.

638

4

5

6=v

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

Figure 10, instead, shows ODC STPPU OSC. B two executable timepoints C contingent time-point. two projections, say P 1 P2 , corresponding respectively point 1 point 2 AC interval. optimal preference level 1.
fact, hA = 0, C = 1, B = 2i solution P 1 preference 1 hA = 0, C = 2, B = 3i
solution P2 preference 1. STPPU ODC. fact, dynamic strategy
assigns B value 2, C occurs 1, value 3, C occurs 2 (assuming always assigned
0). However single value B optimal scenarios.
Similar results apply case -controllability, following formal treatment shows.
Theorem 2 given preference level , STPPU P -SC -DC.
Again, converse hold general. example consider STPPU shown
Figure 10 = 1. Assuming = 1, STPPU 1-DC but, shown above,
1-SC.
Another useful result controllability property holds given preference level, say ,
holds also < , stated following theorem.
Theorem 3 Given STPPU P preference level , P -SC (resp. -DC), -SC
(resp. -DC), < .
Let us consider case preference set totally ordered. eliminate
uncertainty STPPU, regarding contingent time-points executables, obtain
STPP. STPP solved obtaining optimal preference value opt. preference level,
opt, useful relate optimal controllability -controllability. stated following
theorem, STPPU optimally strongly dynamically controllable satisfies
corresponding notion -controllability = opt.
Theorem 4 Given STPPU P defined c-semiring totally ordered preferences, let opt =
maxT Sol(P ) pref (T ). Then, P OSC (resp. ODC) iff opt-SC (resp. opt-DC).
OWC, formally prove Section 6 STPPU OWC iff STPU obtained
ignoring preference functions WC. relation min -controllability
controllability without preferences, recall considering elements intervals mapped
preference min coincides definition considering underlying STPU obtained
ignoring preference functions STPPU. Thus, min -X holds iff X holds, X either
SC DC.
Figure 11 summarize relationships holding among various controllability notions
preferences totally ordered. instead partially ordered, relationships
opt X min X, X controllability notion, make sense. fact,
partially ordered case, several optimal elements several minimal elements,
one.

5. Determining Optimal Strong Controllability -Strong Controllability
next sections give methods determine levels controllability hold STPPU.
Strong Controllability fits off-line scheduling allowed, sense fixed optimal
control sequence computed execution begins. approach reasonable planning
639

fiROSSI , V ENABLE ,& YORKE -S MITH

OSC


ODC

/ opt-SC

/ opt-DC

/ -SC


/ -DC

/ min -SC

/ min -DC



OWC

/ SC


/ DC


/ WC

Figure 11: Comparison controllability notions total orders. min smallest preference
constraint: opt min .
algorithm knowledge possible outcomes, agents preferences.
situation requires us find fixed way execute controllable events consistent
possible outcome uncontrollables give best possible final preference.
5.1 Algorithm Best-SC
algorithm described section checks whether STPPU OSC. OSC,
algorithm detect also return highest preference level problem
-SC.
algorithms present paper rely following tractability assumptions,
inherited STPPs: (1) underlying semiring fuzzy semiring F CSP defined Section 2.2, (2) preference functions semi-convex, (3) set preferences [0, 1] discretized finite number elements according given granularity.
algorithm Best-SC based simple idea: preference level , finds
control sequences guarantee strong controllability projections optimal
preference , optimality optimal preference . Then, keeps
control sequences preference levels > .
pseudocode shown Figure 12. algorithm takes input STPPU P (line 1).
first step, lowest preference min computed. Notice that, efficiently, analytical
structure preference functions (semi-convexity) exploited.
line 3 STPU obtained P cutting preference level min considered.
STPU obtained applying function min -Cut(STPPU G) G=P 5 . general, result
-Cut(P ) STPU Q (i.e., temporal problem uncertainty preferences) defined
follows:
Q variables domains P;
every soft temporal constraint (requirement contingent) P variables X , Xj ,
say c = hI, f i, is, Q , simple temporal constraint variables defined
{x I|f (x) }.
Notice semi-convexity preference functions guarantees set {x I|f (x) }
forms interval. intervals Q contain durations requirement contingent events
local preference least .
5. Notice function -Cut applied STPPs STPPUs: first case output STP,
latter case STPU. Notice also that, -Cut known concept fuzzy literature.

640

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

Pseudocode Best-SC
1. input STPPU P ;
2. compute min ;
3. STPU Qmin min -Cut(P );
4. (StronglyControllable (Qmin ) inconsistent) write min -SC stop;
5. else {
6. STP P min StronglyControllable (Qmin );
7. preference min + 1;
8. bool OSCfalse, bool -SCfalse;
9. {
10.
STPU Q -Cut(P );
11.
(PC(Q ) inconsistent) OSCtrue;
12.
else {
13.
(StronglyControllable(PC(Q )) inconsistent) -SC true;
14.
else {
N
15.
STP P P 1
StronglyControllable(PC(Q )) ;

16.
(P inconsistent) { -SC true };
17.
else { + 1 };
18.
}
19.
}
20.
}while (OSC=false -SC=false);
21. (OSC=true) write P OSC;
22. (-SC=true) write P ( 1) -SC;
23. se =Earliest-Solution(P 1 ), sl =Latest-Solution(P 1 );
24. return P 1 , se , sl ;
25. };
Figure 12: Algorithm Best-SC: tests STPPU OSC finds highest
STPPU P -SC.

641

fiROSSI , V ENABLE ,& YORKE -S MITH

STPU Qmin obtained, algorithm checks strongly controllable. STP
obtained applying algorithm StronglyControllable (Vidal & Fargier, 1999) STPU Q min
consistent, then, according Theorem 3, hope higher preference, algorithm stop (line 4), reporting STPPU -SC 0 thus OSC well.
If, instead, inconsistency found, Best-SC stores resulting STP (lines 5-6) proceeds
moving next preference level min + 1 6 (line 7).
remaining part algorithm (lines 9-21), three steps performed preference
level considered:
Cut STPPU P obtain STPU Q (line 10);
Apply path consistency Q considering STP: PC(Q ) (line 11);
Apply strong controllability STPU PC(Q ) (line 13).
Let us consider last two steps detail.
Applying path consistency STPU Q means considering STP, is, treating contingent constraints requirement constraints. denote algorithm PC algorithm enforcing
path-consistency temporal network (see Section 2.1 Dechter et al., 1991). returns
minimal network leaving intervals values contained least one solution.
allows us identify situations, , correspond contingent durations locally
preference consistent least one control sequence elements Q .
words, applying path consistency Q leaves contingent intervals durations
belong situations corresponding projections optimal value least .
test gives inconsistency, means given STPU, seen STP, solution,
hence projections corresponding scenarios STPPU P optimal preference <
(line 11).
third last step applies StronglyControllable path-consistent STPU PC(Q ), reintroducing information uncertainty contingent constraints. Recall algorithm
rewrites contingent constraints terms constraints executable time-points.
STPU strongly controllable, StronglyControllable leave requirement intervals
elements identify control sequences consistent possible situation. case,
applying StronglyControllable PC(Q ) find, any, control sequences PC(Q )
consistent possible situation PC(Q ).
However, STPU PC(Q ) strongly controllable, control sequences found might
optimal scenarios optimal preference lower . order keep
control sequences guarantee optimal strong controllability preference levels ,
STP obtained StronglyControllable(PC(Q )) intersected corresponding STP found
previous step (at preference level 1), P 1 (line 15). recall given two
two STPs, P1 P2 , defined set variables, STP P3 = P1 P2
variables P1 P2 temporal constraint, c3ij = c1ij c2ij , intersection
corresponding intervals P1 P2 . intersection becomes empty constraint
STP obtained inconsistent, conclude control sequence guarantee
strong controllability optimality preference level and, time, preferences
6. writing min + 1 mean next preference level higher min defined terms granularity
preferences [0,1] interval.

642

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

Table 1: table row corresponds preference level represents intervals
STPU Q obtained cutting STPPU Figure 8 level .
STPU

(SC EC)

(SC SA)

(SA EC)

Q0.5
Q0.6
Q0.7
Q0.8
Q0.9
Q1

[1, 8]
[1, 7]
[1, 6]
[1, 5]
[1, 4]
[1, 2]

[1, 5]
[1, 5]
[1, 5]
[1, 5]
[1, 5]
[1, 3]

[6, 4]
[6, 4]
[5, 2]
[4, 1]
[3, 0]
[2, 1]

Table 2: table row corresponds preference level represents intervals
STPU PC(Q ) obtained applying path consistency STPUs Table 1.
STPU
0.5

PC(Q )
PC(Q0.6 )
PC(Q0.7 )
PC(Q0.8 )
PC(Q0.9 )
PC(Q1 )

(SC EC)

(SC SA)

(SA EC)

[1, 8]
[1, 7]
[1, 6]
[1, 5]
[1, 4]
[1, 2]

[1, 5]
[1, 5]
[1, 5]
[1, 5]
[1, 5]
[2, 3]

[4, 4]
[4, 4]
[4, 2]
[4, 1]
[3, 0]
[2, 1]

< (line 16). If, instead, STP obtained consistent, algorithm Best-SC considers next
preference level, + 1, performs three steps again.
output algorithm STP, P 1 , obtained iteration previous one
causing execution stop (lines 23-24) two solutions, e sl . STP,
show shortly, contains control sequences guarantee -SC = 1.
1 highest preference level cutting gives consistent problem, STPPU
OSC. solutions provided algorithm respectively earliest, e , latest, sl ,
solutions P 1 . fact, proved (Dechter et al., 1991) mentioned Section 2.1, since
P 1 minimal, earliest (resp. latest) solution corresponds assigning variable
lower (resp. upper) bound interval constraint defined X0 variable.
indicated algorithm procedures Earliest-Solution Latest-Solution. Let us also recall
every solution found P 1 without backtracking.
formally proving correctness algorithm Best-SC, give example.
Example 5 Consider STPPU described Example 4, depicted Figure 8. simplicity
focus triangular sub-problem variables SC, SA, EC. example, min = 0.5.
Table 1 shows STPUs Q obtained cutting problem preference level = 0.5, . . . , 1.
Table 2 shows result applying path consistency (line 11) STPUs shown
Table 1. seen, STPUs consistent. Finally, Table 3 shows STPs defined
executable variables, SC SA, obtained applying StronglyControllable
STPUs Table 2.

643

fiROSSI , V ENABLE ,& YORKE -S MITH

Table 3: table row corresponds preference level represents intervals
STP StronglyControllable PC(Q ) obtained applying strong controllability check
STPUs Table 2.
(SC SA)

STP
0.5

StronglyControllable(PC(Q ))
StronglyControllable(PC(Q0.6 ))
StronglyControllable(PC(Q0.7 ))
StronglyControllable(PC(Q0.8 ))
StronglyControllable(PC(Q0.9 ))
StronglyControllable(PC(Q1 ))

[4, 5]
[3, 5]
[4, 5]
[4, 5]
[4, 4]
[3, 3]

looking Tables 2 3 easy deduce Best-SC stop preference level
1. fact, looking carefully Table 3, see STP P 0.9 consists interval [4, 4]
constraint SC SA, StronglyControllable(PC(Q 1 )) consist interval [3, 3]
constraint. Obviously intersecting two gives inconsistency, causing condition
line 16 Figure 12 satisfied.
conclusion executing Best-SC example depicted Figure8 0.9-SC
OSC. Let us see correct. Without loss generality assume SC
assigned value 0. last line Table 3 observe value assigned
SA optimal scenarios optimal preference 1 (that EC assigned
1 2) 3. However, assigning 3 SA optimal EC happens 6, since scenario
optimal preference value 0.7 (e.g. SA assigned 5) case would global
preference 0.6 (given constraint SA EC) 7 .2
5.2 Properties Best-SC
prove algorithm Best-SC correctly identifies whether STPPU P OSC, and,
not, finds highest preference level P -SC. Let us first consider events
Best-SC stops.
Event 1. StronglyControllable(Q min ) inconsistent (line 4);
Event 2. PC(Q ) returns inconsistency (line 11);
Event 3. PC(Q ) consistent strongly controllable (line 13);
Event 4. PC(Q ) strongly controllable, however intersection STP obtained
StronglyControllable(PC(Q )) STP obtained previous preference level,
P 1 , inconsistent (line 16).
First notice algorithm terminates.
Theorem 5 Given STPPU P finite number preference levels, execution algorithm Best-SC P terminates.
7. Recall fuzzy semiring context global preference assignment computed taking minimum
preference assigned projections.

644

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

Intuitively, either one termination events occur preference levels exhausted.
Next, let us show Best-DC sound complete algorithm checking STPPU
OSC finding highest preference level -SC.
said before, cutting STPPU P preference level gives STPU Q .
Moreover, every situation = {1 , . . . , l } Q seen situation P
fj (j ) , j. implies every projection P P roj(Q ), STP, corresponds projection P P roj(P ) STPP. situations Q , follows
write always P interpreted STP seen projection Q
STPP seen projection P . following lemmas state properties
relate solutions projections two contexts: without preferences.
Theorem 6 Consider STPPU P = hNe , Nc , Lr , Lc , SF CSP preference level , consider STPU Q = hNe , Nc , L0r , L0c obtained cutting P , STPU PC(Q )=hNe , Nc ,
L00r , L00c i. Then:
1. situation P , P P roj(PC(Q )) iff optP (P ) ;
2. every control sequence , solution = StronglyControllable(PC(Q ), iff P
Proj(PC (Q )), T, Sol(P ) pref (T, ) .
first part theorem states that, applying path consistency STPU Q , remove
situations cannot extended complete solutions Q , thus correspond projections optimal preference strictly less . second part lemma considers
STP obtained applying StronglyControllable path consistency. particular stated
solutions result, projections PC (Q ), solutions preference
least . Notice implies result optimal solutions projections P
optimal preference exactly . might optimal, however, projections
optimal preference strictly greater .
theorem, get following corollary, clarifies relation
STPU obtained cutting STPPU preference level , -SC STPPU.
Corollary 1 Consider STPPU P preference level assume , situation P ,
opt(P ) , P corresponding projection. Then, STPU PC(Q ), obtained
cutting P , applying path consistency, SC P -SC.
consider preference levels min , compute corresponding
STPs, say min , . . . , , STP identify assignments executable variables guaranteeing strong controllability optimality level. intersecting STPs keep
common solutions thus guarantee strong controllability optimality
situations P optimal preference smaller equal .
Theorem 7 Consider STPPU P , preference levels min , assume
corresponding STPs, min , . . . , obtained cutting P preference levels N
min , . . . , ,
enforcing strong controllability consistent. Then, Sol(P ), P = i=min ,..., ,
iff P P roj(P ): T, Sol(P ), opt(P ) , pref (T, ) = opt(P ), otherwise
pref (T, ) .
645

fiROSSI , V ENABLE ,& YORKE -S MITH

consider events Best-SC stop prove
strong controllability properties hold.
Theorem 8 execution algorithm Best-SC STPPU P stops due occurrence
Event 1 (line 4), P -SC 0.
case underlying STPU obtained STPPU ignoring preference
functions strongly controllable. Since cutting higher preferences give even smaller
intervals hope controllability level execution halt.
Theorem 9 execution algorithm Best-SC STPPU P stops due occurrence
Event 2 (line 11) preference level ,
1 = opt = maxT Sol(P ) pref (T );
P OSC control sequence solution STP P opt (returned algorithm) iff
optimal scenario P .
event occurs algorithm cuts STPPU given preference level STPU
obtained, seen STP, inconsistent. particular, means projection P roj(P )
optimal preference equal greater preference level. However, level
reached, previous level, assignments guaranteeing SC optimality
found. Moreover, previous level must also highest preference solution
P , opt(P ). means opt(P )-SC established, Theorem 4 equivalent
OSC.
Theorem 10 execution algorithm Best-SC STPPU P stops due occurrence
Event 3 (line 13) Event 4 (line 16) preference level , P OSC ( 1)SC solution STP P 1 (returned algorithm) that, P P roj(P ):
T, Sol(P ), opt(P ) 1, pref (T, ) = opt(P ), otherwise pref (T, ) 1.
Intuitively, algorithm reaches stops line 13, projections P
optimal preference corresponding set situations SC. Notice exactly
situation considered Corollary 1. instead stops line 16, set situations SC,
none assignments guaranteeing SC situations optimal
situations preference levels . cases problem -SC. However, assuming
first level execution stopped problem 1-SC.
conclude section considering complexity Best-SC.
Theorem 11 Determining OSC highest preference level -SC STPPU n
variables ` preference levels achieved time O(n 3 `).
Notice cannot use binary search preference levels (in contrast algorithms
STPPs), since correctness procedure based intersection result obtained
given preference level, , obtained preference levels < .
theorem allows us conclude cost adding preferences, thus considerable expressive power, low. fact, complexity still polynomial grown
factor equal number preference levels.
646

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

6. Determining Optimal Weak Controllability
Optimal Weak Controllability least useful property practice also property
adding preferences smallest impact terms expressiveness. OWC requires
existence optimal solution every possible scenario. equivalent requiring
existence solution every situation, stated following theorem.
Theorem 12 STPPU P OWC iff STPU Q, obtained simply ignoring preference functions constraints WC.
ignoring preference functions mean mapping soft constraint hI, f hard
constraint hIi defined variables. theorem allows us conclude that, check
OWC, enough apply algorithm WeaklyControllable proposed (Vidal & Ghallab, 1996)
described Section 2. If, instead, given scenario , find optimal
solution projection, STPP P roj(), using one solvers described (Rossi et al.,
2002).
Let us consider Example 4 again. Section 5 showed STPU obtained cutting
STPPU Figure 8 preference level min strongly controllable. Since SC implies WC,
conclude STPU weakly controllable and, thus, STPPU Figure 8 Optimally
Weakly Controllable.

7. Determining Optimal Dynamic Controllability -Dynamic Controllability
Optimal Dynamic Controllability (ODC) interesting useful property practice.
described Section 1, many industrial applications solved dynamic fashion,
making decisions response occurrences events execution plan.
true space application domains, planning mission handled decomposing
problem set scheduling subproblems, depend occurrence semipredictable, contingent events (Frank et al., 2001).
section describe algorithm tests whether STPPU P ODC and, ODC,
finds highest P -DC. algorithm presented bears similarities
Best-SC, sense decomposes problem STPUs corresponding different preference
levels performs bottom search dynamically controllable problems space.
Notice algorithm attractive also practice, since output minimal form
problem assignments belonging least one optimal solution left domains
executable time-points. minimal form given input execution algorithm,
also describe, assigns feasible values executable time-points dynamically
observing current situation (i.e., values contingent time-points occurred).
7.1 Necessary Sufficient Condition Testing ODC
define necessary sufficient condition ODC, defined intervals
STPPU. propose algorithm tests condition, show
sound complete algorithm testing ODC.
first claim that, given STPPU, dynamic controllability STPUs obtained
cutting STPPU applying PC every preference level necessary sufficient
condition optimal dynamic controllability given STPPU.
647

fiROSSI , V ENABLE ,& YORKE -S MITH

Theorem 13 Given STPPU P , consider preference level STPU Q , obtained
cutting P , consistent. STPU PC(Q ) DC P ODC -DC,
.
Unfortunately condition sufficient, since STPPU still ODC even
every preference level STPU obtained PC DC. example shown Figure 9
described below.
Example 6 Another potential application STPPUs scheduling aircraft analysis airborne
particles (Coggiola, Shi, & Young, 2000). example consider aircraft equipped
instruments Small Ice Detector Nevzorov probe, used discriminate liquid ice given types clouds. analysis important prediction
evolution precipitatory systems occurrence severity aircraft icing (Field,
Hogan, Brown, Illingworth, Choularton, Kaye, Hirst, & Greenaway, 2004). instruments need
uncertain amount time determine predominant state, liquid ice,
activated inside cloud.
example shown Figure 9 consider sensing event represented variables
C start time maneuver aircraft represented variable B. Due
instruments function, aircraft maneuver impact analysis. example constraint AC
represents duration sensing event preference function models fact
earlier predominant state determined better. Constraint AB models instead fact
maneuver start soon possible, example, due time constraints imposed
aircrafts fuel availability. Constraint BC models fact maneuver ideally start
sensing event ended.
Let us call P STPPU depicted Figure 9. order determine highest preference level
schedule P can, example use algorithm Chop-solver (Rossi et al., 2002).
highest preference level cutting functions gives consistent STP 1 (interval [3, 3]
AB, [3, 5] AC interval [0, 2] BC consistent STP). optimal solutions P , regarded
STPP, global preference 1.
Consider STPUs obtained cutting every preference level highest, 1,
lowest 0.5. minimum preference constraint P min = 0.5 and, easy see,
STPUs obtained cutting P applying PC preference levels 0.5 1
DC. However, P ODC. fact, dynamic assignment B belongs optimal
solution projections corresponding elements 3, 4 5 [x, y] 3. executing B 3
cause inconsistency C happens 10, since 10 3 = 7 doesnt belong [u, v].2
elaborate example find sufficient condition ODC. Consider intervals
AB, [p , q ], waits < C, > obtained applying DC checking algorithm preference
level . shown Table 4.
look first last intervals, resp., = 1 = 0.5, way assign
value B time induces preference 1 constraints AB BC, C occurs 3, 4
5, also satisfies wait < C, 4 >, ensuring consistency C occurs 10. depends
fact intersection [p 1 , q 1 ], i.e., [3], sub interval [p 0.5 , q 0.5 ] satisfies
< C, 4 >, is, [4, 7], empty.
claim non-emptiness intersection, together DC STPUs
obtained cutting problem preference levels necessary sufficient condition
648

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

Table 4: table row corresponds preference level represents corresponding
interval wait AB constraint STPPU shown Figure 9.


[p , q ]

wait

1
0.9
0.8
0.7
0.6
0.5

[3, 3]
[3, 4]
[3, 5]
[3, 6]
[3, 7]
[3, 7]

< C, 3 >
< C, 3 >
< C, 3 >
< C, 3 >
< C, 4 >

ODC. following section describe algorithm tests condition. Then,
Section 7.3, prove algorithm sound complete w.r.t. testing ODC
finding highest level -DC.
7.2 Algorithm Best-DC
algorithm Best-DC echoes Section 5s algorithm checking Optimal Strong Controllability.
done Best-SC, considers STPUs obtained cutting STPPU various preference
levels. preference level, first tests whether STPU obtained considering STP
path consistent. Then, checks path consistent STPU obtained dynamically controllable,
using algorithm proposed (Morris et al., 2001). Thus, control sequences guarantee
DC scenarios different optimal preferences found. next step select
sequences satisfy DC requirement optimal preference levels.
pseudocode given Figure 13. Algorithm Best-DC takes input STPPU P (line 1)
computes minimum preference, min , assigned constraint (line 2).
min known, STPU obtained cutting P min computed (line 3).
STPU seen STPPU P variables intervals constraints P
preferences. STPU, denoted Q min , given input algorithm
DynamicallyControllable. Qmin dynamically controllable, P ODC DC (for min , hence ), shown Theorem 13. algorithm detects
inconsistency halts (line 4). If, instead, Q min dynamically controllable, STPU
returned output DynamicallyControllable saved denoted P min (line 6). Notice
STPU minimal, sense intervals elements belonging
least one dynamic schedule (Morris et al., 2001). addition, since preferences,
elements requirement intervals, well belonging least one dynamic schedule,
part optimal schedules scenarios projection optimal preference equal
min 8 .
line 7 preference level updated next value ordering considered (according given preference granularity). line 8 two Boolean flags, ODC -DC
defined. Setting flag ODC true signal algorithm established problem ODC, setting flag -DC true signal algorithm found highest
preference level STPPU -DC.
8. fact, preference least min definition.

649

fiROSSI , V ENABLE ,& YORKE -S MITH

Pseudocode Best-DC
1. input STPPU P ;
2. compute min ;
3. STPU Qmin min -Cut(P );
4. (DynamicallyControllable(Q min ) inconsistent) write min -DC stop;
5. else {
6. STP P min DynamicallyControllable(Qmin );
7. preference min + 1;
8. bool ODC false, bool -DC false;
9. {
10.
STPU Q -Cut(P );
11.
(PC(Q ) inconsistent) ODC true;
12.
else {
13.
(DynamicallyControllable(PC(Q )) inconsistent) -DC true;
14.
else {
15.
STPU DynamicallyControllable(PC(Q ));
16.
if(Merge(P 1 , ) FAILS) { -DC true }
17.
else {
18.
STPU P Merge(P 1 , );
19.
+ 1;
20.
};
21.
};
22.
};
23. }while (ODC=false -DC=false);
24. (ODC=true) write P ODC;
25. (-DC=true) write P ( 1) -DC;
26. return STPPU F 1 resulting STPPU(P ,P 1 );
27. };
Figure 13: Algorithm tests STPPU ODC and, not, finds highest STPPU
P -DC.

650

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

Pseudocode Merge
1. input (STPU , STPU +1 );
2. STPU P +1 ;
3. constraint AB, B executables, P +1
define interval [p0 , q 0 ] wait t0 ,
given { interval [p , q ], wait }
{ interval [p+1 , q +1 ], wait t+1 +1 }, follows:;
4. (t = p t+1 = p+1 ) (Precede - Precede)
5. p0 max(p , p+1 ), q 0 min(q , q +1 ), t0 max(t , t+1 );
6. (q 0 < p0 ) return FAILED;
7. (p < < q p+1 t+1 < q +1 ) (Unordered - Unordered Precede)
8. t0 max(t , t+1 ), q 0 min(q , q +1 );
9. (q 0 < t0 ) return FAILED;
10. output P +1 .
Figure 14: Algorithm Merge.
Lines 9-25 contain main loop algorithm. short, time loop executed,
cuts P current preference level looks cutting produced path consistent STPU
(seen STP). so, checks path consistent version STPU also dynamically
controllable and, also test passed, new STPU created merging current
results previous levels.
describe step detail. Line 10 cuts P current preference level . line 11
consistency STPU Q tested applying algorithm PC. PC returns inconsistency,
conclude P schedule preference (or greater).
next step check STPU PC(Q ) DC. Notice required preference
levels optimal level order P ODC, order P -DC
(Theorem 13). applying algorithm DynamicallyControllable detects PC(Q ) dynamically controllable, algorithm sets flag -DC true. If, instead, PC(Q ) dynamically
controllable resulting minimal STPU saved denoted (line 15).
line 16, output procedure Merge tested. procedure used combine
results preference 1 preference , applying STPU obtained
end previous iteration, P 1 , STPU . pseudocode Merge
shown Figure 14, describe detail shortly. inconsistency found, new
STPU obtained merging procedure denoted P (line 18) new preference level
considered (line 19).
Lines 24-27 take care output. Lines 24 25 write output P ODC or, not,
highest -DC. line 27 final STPPU, F , given output, obtained
STPU P 1 , is, STPU obtained last iteration cycle
completed success (i.e., reached line 20). Function Resulting STPPU restores
preferences intervals P 1 setting P . show
requirement constraints F contain elements corresponding dynamic schedules
always optimal, result P ODC, optimal scenarios corresponding
projections optimal preference guarantee global preference level least
others, result P -DC.
651

fiROSSI , V ENABLE ,& YORKE -S MITH

pseudocode procedure Merge given Figure 14. input consists two STPUs
defined set variables. describing Merge works, assume given
input two STPUs, +1 , obtained cutting two STPPUs preference levels + 1
applying, hypothesis success, PC DynamicallyControllable (line 1 Figure 14).
line 2, Merge initializes STPU given output . formally proven Theorem 14, due semi-convexity preference functions
P roj(T +1 ) P roj(T ). Notice Merge leaves contingent constraints unaltered. Thus,
projection optimal preference + 1 contained set projections P +1 .
Merge considers every requirement constraint defined two executables, say B,
respectively +1 . Since assuming algorithm DynamicallyControllable
applied STPUs, waits intervals. Figure 6 illustrates three
cases interval AB be. wait expires upper bound interval
(Figure 6 (a)), execution B must follow execution every contingent time-point
(Follow case). wait coincides lower bound interval (Figure 6 (b)),
execution B must precede contingent time-point (Precede case). Finally, shown
Figure 6 (c), wait within interval, B Unordered case least
contingent time-point, say C.
Merge considers case corresponding intervals +1 (line 3).
intervals respectively indicated [p , q ], wait , [p+1 , q +1 ], wait t+1 .
Merge obtains new interval [p0 , q 0 ] new wait t0 , replace old wait +1 .
Interval [p0 q 0 ] contain values projections AB constraint
optimal solution STPP corresponding situation +1 . Wait t0 wait
respected dynamic execution order guarantee solution obtained
optimal, projection corresponding final scenario preference + 1.
Due semi-convexity preference functions cannot case that:
AB Follow Precede case Unordered case +1 ;
AB Follow case Precede case +1 ;
AB Precede case Follow case +1 ;
means cases considered are:
AB Follow case +1 ;
AB Precede case +1 ;
AB Unordered case Precede Unordered case +1 ;
first two cases AB interval left T+1 . formal motivation
contained proof Theorem 14. However, informally, say AB interval
+1 already satisfies desired property.
lines 4 5 case AB Precede case STPUs examined. Here, B
always occur contingent time-point. values [p , q ] (resp. [p+1 , q +1 ])
assignments B consistent future occurrence C mapped preference (resp. + 1). Clearly intersection taken order lower

652

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

preference C occurs preference + 1. Line 6 considers event intersection empty. means common assignment B, given A,
optimal scenarios optimal preference scenarios optimal preference + 1.
lines 7 8 two scenarios considered: AB Unordered case
Precede case +1 AB Unordered case STPUs. Figure 15
shows second case. Merge takes union parts intervals preceding wait
intersection parts following wait. intuition underlying execution
B identifying element either [p , [ [p+1 , t+1 [ preceded execution
contingent time-points wait. means B executed,
contingent time-point C, time C executed, say C ,
associated preference, say fAC (tC ), constraint AC STPPU P known. propagation
information allow us identify elements [p , [ (resp. [p+1 , t+1 [)
preference fAC (tC ) thus optimal assignment B. means elements
interval [p , [ interval [p+1 , t+1 [ eligible chosen. example, f AC (tC ) =
might values B preference equal optimal case would
C occurred time fAC (tC ) > . since case know
preference C occurred, propagation step prune non-optimal choices B.
short, leaving elements allows flexibility propagation step. Moreover,
proven Theorem 14, p p+1 .
instead consider elements interval [t , q ], know identify assignments
B executed regardless C happen (however know happen
preference greater ). means must take intersection part
corresponding one, [t+1 , q +1 ], order guarantee consistency optimality also
C occurs time preference = + 1. easy way see interval [t , q ]
may contain elements P mapped preference . elements optimal
scenarios C happens time associated preference = AC constraint;
however, cannot optimal scenarios C occurring time preference + 1.
Line 9 handles case two parts intervals, following waits,
empty intersection. case, optimality cannot guaranteed neither level + 1,
particular contingent events occur waits expire.
7.3 Properties Best-DC
show Best-DC sound complete algorithm testing ODC finding
highest preference level STPPU given input -DC. recall, more,
results follow rely tractability assumptions requiring semi-convex preference
functions fuzzy semiring h[0, 1], max, min, 0, 1i underlying structure.
Let us consider STPPU P STPUs +1 , defined previous section. Then,
STPU P +1 =Merge (T , +1 ) contingent constraints 9 requirement constraints defined merging procedure. start proving Merge sound
complete algorithm testing existence viable dynamic strategy, common
STPUs, optimal projections optimal preference equal either + 1.
9. recall projections coincide projections STPPU P optimal preference (see
Theorem 6), that, due semi-convexity preference functions, P roj(T +1 ) P roj(T ).

653

fiROSSI , V ENABLE ,& YORKE -S MITH

Interval AB
STPU +1

Interval AB
STPU

(a)
+1

+1

+1

p



q







p

q



Merged interval AB




p



(b)

+1

(c)

q

Figure 15: Merging two intervals Unordered case.
Theorem 14 Consider STPPU P STPUs, +1 , obtained cutting P respectively
level + 1 applying PC, without finding inconsistencies, DynamicallyControllable
success. Consider STPU P +1 = Merge(T , +1 ).
Then, Merge(T , +1 ) fail
P +1 dynamically controllable
viable dynamic strategy every projection P P roj(P +1 ),
opt(Pi ) = opt(Pi ) = + 1 P , pref (S(Pi )) = opt(Pi );
otherwise pref (S(Pi )) + 1.
following theorem extends result merging procedure two preference
levels, particular preference levels smaller equal given threshold .
Theorem 15 Consider STPPU P every preference level, , define STPU obtained
cutting P , applying PC DynamicallyControllable. Assume ,
DC. Consider STPU P :
P = Merge(Merge(. . . Merge(Merge(T min , min +1 ), min +2 ), . . . ), )
min minimum preference constraint P. Assume that, applied, Merge
always returned consistent STPU. Then, viable dynamic strategy S, P
P roj(P ), opt(Pi ) S(Pi ) optimal solution Pi , otherwise pref (S(Pi )) + 1.
Theorem 15 allows us prove main result. Informally, Best-DC applies Merge
lowest preference highest threshold , returned problem becomes inconsistent. projection STPPU optimal solution higher , then, using
Theorem 15, conclude STPPU ODC; otherwise -DC.
Let us start enumerating conditions Best-DC terminates:
654

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

Event 1. Best-DC stops STPU obtained level min DC (line 4);
Event 2. Best-DC exits reached preference level STPU (seen
STP) path consistent (line 11);
Event 3. Best-DC stops reached preference level path consistent STPU dynamically controllable (line 13);
Event 4. Best-DC stops procedure Merge found inconsistency (line 16).
following theorem shows execution Best-DC always terminates.
Theorem 16 Given STPPU P, execution algorithm Best-DC P terminates.
Best-DC considers preference level, starting lowest moving time
one level according granularity preference set. stops either inconsistency
found levels, assumed finite, precessed.
ready prove soundness completeness Best-DC. split proof
three theorems, considering different terminating condition. first theorem considers
case underlying STPU obtained P , ignoring preferences, DC.
case output STPPU -DC level thus ODC.
Theorem 17 Given STPPU P input, Best-DC terminates line 4 iff 6 0 P
-DC.
next theorem considers case highest preference level reached success
merging procedure also highest optimal preference projection P .
case, problem ODC.
Theorem 18 Given STPPU P input, Best-DC terminates line 11 iff P ODC.
last result considers case least projection optimal preference strictly higher highest reached success merging procedure. case
problem ODC Best-DC found highest level STPPU -DC.
Theorem 19 Given STPPU P input, Best-DC stops lines 13 16 preference level iff P
( 1)-DC ODC.
mentioned Section 2.3, (Morris & Muscettola, 2005), proven checking DC
STPU done O(n5 ), n number variables. revised algorithm processes distance graph STPU, rather constraint graph. also maintains additional
information, form additional labeled edges correspond waits. main feature
new algorithm, noted earlier, strongly polynomial algorithm determining
dynamic controllability STPU. important context stress fact
output two algorithms, presented (Morris et al., 2001) (Morris & Muscettola, 2005),
essentially same. fact easy obtain, polynomial time O(n 2 ), constraint graph
waits produced DynamicallyControllable starting distance graph produced
new algorithm, vice versa.

655

fiROSSI , V ENABLE ,& YORKE -S MITH

Theorem 20 complexity determining ODC highest preference level -DC
STPPU n variables, bounded number preference levels ` time O(n 5 `).
complexity result given Theorem 20 unexpectedly good. fact, shows cost
adding considerable expressive power preferences STPUs factor equal
number different preference levels. implies solving optimization problem and,
time, controllability problem, remains P, number different preference levels
bounded.
7.4 Execution Algorithm
execution algorithm propose similar STPUs presented (Morris et al.,
2001), described Section 2 shown Figure 7. course execution algorithm
STPPUs take input STPPU Best-DC successfully applied.
line 2 Figure 7, algorithm performs initial propagation starting point. main
difference STPPU execution algorithm STPU algorithm (Morris et al., 2001)
definition propagation also involves preferences.
Definition 26 (soft temporal propagation) Consider STPPU P variable P
value vY D(Y ). propagating assignment = v P , means:
constraints, cXY involving X already assigned value v X D(X):
replace interval cXY interval h[vY vX , vY vX ]i;
cut P preference level minX {fcXY (vY vX )}.2
call ODC-Execute algorithm DC-Execute propagation defined
Definition 26. Assume apply ODC-Execute ODC -DC STPPU P Best-DC
applied. If, given time , preference partial schedule ,
know P ODC -DC , Theorem 14 Theorem 15, execution
algorithm assigning values +1 . Assume contingent event occurs
lowers preference 2. propagated STPPU cut preference
level 2. on, execution algorithm assign values 2 and, Theorem 14
Theorem 15, new waits imposed assignments executables
optimal situation optimal preference 2. situations
assignments guarantee preference least 2.

8. Using Algorithms
Section 4.4 described relations notions controllability. general strategy,
given STPPU, first property consider OSC. holds, solution obtained feasible
optimal possible scenarios. However, OSC strong property holds infrequently.
STPPU OSC, still need control sequence execution begins,
Best-SC find best solution consistent possible future situations.
commonly, dynamic controllability useful. control sequence needs
known execution begins, ODC ideal. Notice that, results Section 4.4,
STPPU may OSC still ODC. If, however, STPPU even ODC,

656

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

Best-DC give dynamic solution highest preference. Recall, shown
Section 4.4, given preference level , -SC implies -DC vice versa. Thus,
may given STPPU -SC -DC > . -SC means fixed
way assign values executables optimal situations optimal
preference give preference least cases. hand, -DC
implies solution obtained dynamically, ODC-Execute algorithm, optimal
situations best solution preference yield preference
cases. Thus, > , using dynamic strategy guarantee optimality situations
higher preference others.
last possibility check OWC. least allow executing agent know
advance situation solution. Moreover, situation revealed
execution begins, using solvers STPPs described (Rossi et al., 2002)
allow us find optimal assignment scenario.

9. Related Work
section survey work regard closely related ours. Temporal uncertainty
studied before, defined different ways according different contexts
used.
start considering work proposed Vila Godo (1994). propose Fuzzy Temporal Constraint Networks, STPs interval constraint mapped
possibility distribution. fact, handle temporal uncertainty using possibility theory (Zadeh,
1975), using term uncertainty describe vagueness temporal information available.
aim model statements called less hour ago, uncertainty
lack precise information temporal event. goal thus completely different
ours. fact, scenario agent must execute activities certain times,
activities constrained temporal relations uncertain events. goal find way
execute agents control way consistent whatever nature decides
future.
(Vila & Godo, 1994), instead, assume imprecise temporal information events
happened past. aim check information consistent, is,
contradictions implied study entailed set constraints. order model
imprecise knowledge, possibilities used. Every element interval mapped
value indicates possible event certain is. Thus, another major difference
approach consider preferences, possibilities. hand,
work presented allow express information possible probable value
contingent time-point. one lines research want pursue future.
Moreover, (Vila & Godo, 1994), concerned classical notion consistency
(consistency level) rather controllability.
Another work related way handle uncertainty Badaloni Giacomin (2000).
introduce Flexible Temporal Constraints soft constraints used express preferences
among feasible solutions prioritized constraints used express degree necessity
constraints satisfaction. particular, consider qualitative Allen-style temporal relations
associate relation preference. uncertainty deal time
occurrence event whether constraint belongs constraint problem.

657

fiROSSI , V ENABLE ,& YORKE -S MITH

model, information coming plausibility information coming preferences
mixed distinguishable solver. words, possible say whether
solution bad due poor preference relation due violating constraint
high priority. approach, instead, uncertainty preferences separated. compatibility
uncertain event change preference assignment executable.
robustness temporal uncertainty handled intrinsically different degrees controllability.
(Dubois, HadjAli, & Prade, 2003b) authors consider fuzziness uncertainty temporal reasoning introducing Fuzzy Allen Relations. precisely, present extension
Allen relational calculus, based fuzzy comparators expressing linguistic tolerance. Dubois
et al. (2003b) want handle situations information dates relative positions
intervals complete but, reason, interest describing precise manner. example, one wants speak terms approximate equality, proximity
rather terms precise equality. Secondly, want able deal available information pervaded imprecision, vagueness uncertainty. framework presented
restrict uncertainty event occur within range. hand, put
complete ignorance position, would equivalent, context (Dubois
et al., 2003b), setting 1 possibilities contingent events. Moreover, (Dubois et al.,
2003b) allow preferences address controllability. Instead, consider, similarly
(Vila & Godo, 1994), notions consistency entailment. first notion checked
computing transitive closure fuzzy temporal relations using inference rules appropriately
defined. second notion checked defining several patterns inference.
Another work addresses also temporal uncertainty presented (Dubois, Fargier, &
Prade, 1995) (Dubois, Fargier, & Prade, 2003a). work preferences activities
ill-known durations classical job-shop scheduling problem handled using fuzzy
framework. three types constraints: precedence constraints, capacity constraints
due dates, release time constraints. order model unpredictable events use possibility theory. authors mention (Dubois et al., 1995), possibility distributions viewed
modeling uncertainty well preference (see Dubois, Fargier, & Prade, 1993). Everything depends whether variable X possibility distribution defined controllable
not. Thus Dubois et al. (1995) distinguish controllable uncontrollable variables. However allow specify preferences uncontrollable events. preference functions
contingent constraints would interpreted possibility distributions framework.
sense, work complementary theirs. assume constraint possibility distribution
contingent events always equal 1 allow representation information
less possible values; hand, allow specify preferences also uncontrollable events. They, contrary, allow put possibility distributions contingent events,
preferences.
Finally, Dubois et al. (1995) show scheduling problem uncertain durations
formally expressed kind constraints problem involving call flexible
durations (i.e. durations fuzzy preferences). However interpretation quite different:
case flexible durations, fuzzy information comes specifications preferences
represents possible values assigned variable representing duration.
case imprecisely known durations, fuzzy information comes uncertainty real
value durations. formal correspondence two constraints close
authors distinguish among describing solving procedure. Further, problem
658

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

solve find starting times activities activities take place within
global feasibility window whatever actual values unpredictable durations be. Clearly
equivalent Optimal Strong Controllability. address problem dynamic
weak controllability preferences.

10. Summary Future Work
defined formalism model problems quantitative temporal constraints
preferences uncertainty, generalized formalism three classical notions
controllability (that is, strong, weak dynamic). focused tractable class
problems, developed algorithms check presence properties.
work advances state art temporal reasoning uncertainty since provides
way handle preferences context, select best solution (rather feasible one)
presence uncontrollable events. Moreover, shows computational properties
controllability checking algorithms change adding preferences. particular, dynamic
controllability still checked polynomial time considered class problems, producing dynamically temporal plans uncertainty optimal respect preferences.
Among future directions want pursue within line research, first deeper
study methods algorithms adding preferences different fuzzy ones. Notice
framework proposed able represent kind preference within
soft constraint framework. However, algorithms apply fuzzy preferences semiconvex functions. particular, would like consider impact design complexity
algorithms uncontrollable events underlying preference structures
weighted probabilistic semiring. semirings characterized non-idempotent
multiplicative operators. problem applying constraint propagation (Bistarelli
et al., 1997), path-consistency, constraints. Thus search propagation techniques
adapted environment featuring uncertainty well. noticed
(Peintner & Pollack, 2005) algorithms finding optimal solutions STPs preferences
weighted semiring proposed. Another interesting class preferences utilitarian
ones. context preference represents utility goal maximize sum
utilities. preferences used temporal context without uncertainty example
(Morris, Morris, Khatib, Ramakrishnan, & Bachmann, 2004).
Recently, another approach handling temporal uncertainty introduced (Tsamardinos, 2002; Tsamardinos, Pollack, & Ramakrishnan, 2003a): Probabilistic Simple Temporal Problems (PSTPs); similar ideas presented (Lau, Ou, & Sim, 2005). PSTP framework,
rather bounding occurrence uncontrollable event within interval, STPUs,
probability distribution describing event likely occur defined entire set
reals. STPUs, way problem solved depends assumptions made regarding
knowledge uncontrollable variables. particular define Static Scheduling
Optimization Problem, equivalent finding execution satisfying SC STPUs,
Dynamic Scheduling Optimization Problem, equivalent finding dynamic execution strategy
context STPUs. framework, optimal means highest probability
satisfying constraints. Preferences considered framework. believe
would interesting add preferences also approach. first step could consists keeping,
strategy, separately global preference probability success. way

659

fiROSSI , V ENABLE ,& YORKE -S MITH

could use existing frameworks handling two aspects. Then, order strategies
giving priority preferences, thus taking sense risky attitude, or, contrary,
giving priority probabilities, adopting cautious attitude. step direction
recently proposed (Morris, Morris, Khatib, & Yorke-Smith, 2005), where, however, authors,
rather actually extending notions consistency PSTPs handle preferences, consider
inducing preferences probabilities. contrast, approach preliminary advanced (Pini,
Rossi, & Venable, 2005).
focused attention non-disjunctive temporal problems, is,
one interval per constraint. would like consider adding uncertainty Disjunctive Temporal Problems (Stergiou & Koubarakis, 2000), consider scenarios
preferences uncertainty. problems polynomial even without preferences uncertainty shown cost adding preferences small (Peintner & Pollack,
2004), hope hold environments uncertainty well. Surprisingly,
uncertainty Disjoint Temporal Problems considered yet, although easy see
allowing multiple intervals constraint form uncontrollability. We, thus, plan
start defining DTPUs (preliminary results Venable Yorke-Smith, 2005) merge
approach existing one DTPPs.
Extending Conditional Temporal Problems, framework proposed (Tsamardinos, Vidal, &
Pollack, 2003b), also topic interest us. model Boolean formula attached
temporal variable. formulae represent conditions must satisfied order
execution events enabled. framework uncertainty temporal
variables executed. believe would interesting extend approach order
allow conditional preferences: allowing preference functions constraints different
shapes according truth values formulas, occurrence event
time. would provide additional gain expressiveness, allowing one express dynamic
aspect preferences change time.

Appendix
Theorem 1 STPPU P OSC, ODC; ODC, OWC.
Proof: Let us assume P OSC. viable execution strategy that, P 1 , P2
P roj(P ) every executable time-point x, [S(P 1 )]x = [S(P2 )]x S(P1 ) OptSol(P1 )
S(P2 ) OptSol(P2 ). Thus, particular, [S(P1 )]x = [S(P2 )]x every pair f projections
[S(P1 )]<x = [S(P2 )]<x . allows us conclude P OSC also ODC
strategy witness OSC also witness ODC.
Let us assume P ODC. Then, particular, viable dynamic strategy
P1 P roj(P ), S(P1 ) optimal solution P1 . clearly means every projection
least optimal solution. Thus P OWC. 2
Theorem 2 given preference level , STPPU P -SC -DC.
Proof: Assume P -SC. viable strategy that: [S(P 1 )]x = [S(P2 )]x ,
P1 , P2 P roj(P ) every executable time-point x, S(P ) optimal solution
projection P , optimal solution P preference > pref (S(P )) 6< ,
otherwise.
660

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

Thus, [S(P1 )]x = [S(P2 )]x also pairs projections, P 1 P2 [S(P1 )]<x =
[S(P2 )]<x . implies P -DC. 2
Theorem 3 Given STPPU P preference level , P -SC (resp. -DC), -SC
(resp. -DC), < .
Proof: P -SC viable strategy that: [S(P 1 )]x = [S(P2 )]x , P1 , P2
P roj(P ) every executable time-point x, S(P ) optimal solution P
optimal solution P preference > pref (S(P )) 6< , otherwise. But, course,
< set projections optimal solution preference > included
projections optimal solution preference > . Moreover, projections,
Pz , pref (S(Pz )) 6< implies pref (S(Pz )) 6< since > . Similarly -DC.2
Theorem 4 Given STPPU P , let opt = max Sol(P ) pref (T ). Then, P OSC (resp. ODC) iff
opt-SC (resp. opt-DC).
Proof: result comes directly fact P P roj(P ), opt(Pi ) opt,
always least projection, Pj , opt(Pj ) = opt.2
Theorem 5 Given STPPU P finite number preference levels, execution algorithm Best-SC P terminates.
Proof: Consider STPPU P optimal preference value opt = max Sol(P ) pref (T ), is,
highest preference assigned solutions. definition, Qopt+1 consistent.
means algorithm reaches level opt + 1 (that is, next preference level higher opt
granularity preferences) condition line 11 satisfied execution
halt. looking lines 9-20 see either one events cause execution
terminate occurs preference level incremented line 16. Since finite number
preference levels, allows us conclude algorithm terminate finite number
steps. 2
Theorem 6 Consider STPPU P = hNe , Nc , Lr , Lc , SF CSP preference level , consider STPU Q = hNe , Nc , L0r , L0c obtained cutting P , STPU PC(Q )=hNe , Nc ,
L00r , L00c i. Then:
1. situation P , P P roj(PC(Q )) iff optP (P ) ;
2. every control sequence , solution = StronglyControllable(PC(Q ) iff, P
Proj(PC (Q )), T, Sol(P ) pref (T, ) .
Proof: prove item theorem.
1. (): Consider situation P P roj(PC(Q )). Since PC(Q ) path consistent, consistent partial assignment (e.g. defined ) extended complete
consistent assignment, say T, PC(Q ). Moreover, T, Sol(P ), pref (T, ) ,
since preference functions semi-convex every interval PC(Q ) subinterval
corresponding one Q . Thus, opt(P ) P . (): Consider situation
opt(P ) . implies T, Sol(P ) pref (T, ) . Since
661

fiROSSI , V ENABLE ,& YORKE -S MITH

fuzzy semiring, happens iff min cij Lr Lc fij (T, ) cij ) . Thus must
fij (T, cij ) , cij Lr Lc thus (T, ) cij c0ij , c0ij L0r L0c .
implies P P roj(Q ). Moreover, since T, consistent solution P Q ,
P P roj(PC(Q )).
2. construction , Sol(T ) iff, P P roj(PC(Q )), T, Sol(P )
Sol(PC(Q )). Notice fact T, Sol(PC(Q )) implies pref (T, ) . 2
Corollary 1 Consider STPPU P preference level assume , situation P ,
opt(P ) , P corresponding projection. Then, STPU PC(Q ), obtained
cutting P , applying path consistency, SC P -SC.
Proof: item 1 Theorem 6 get P projection P opt(P )
iff P P roj(PC(Q )). Thus, complete assignments controllable contingent
variables P global preference iff PC(Q ) consistent, i.e., iff Q path consistent. Let
us assume PC(Q ) SC. item 2 Theorem 6, fixed assignment
controllable variables solution every projection P roj(PC(Q )) and, every
projection, gives global preference .
means either set projections common solution P every common
solution gives preference strictly lower . Thus, P -SC since requires existence
fixed assignment controllable variables must optimal solution projections
preference (Definition 22, Item 1 2) give preference
projections (Definition 22, Item 3).
Theorem 7 Consider STPPU P , preference levels min , assume
corresponding STPs, min , . . . , obtained cutting P preference levels N
min , . . . , ,


enforcing strong controllability consistent. Then, Sol(P ), P = i=min ,..., ,
iff P P roj(P ): T, Sol(P ), opt(P ) , pref (T, ) = opt(P ), otherwise
pref (T, ) .
Proof: (): Let us first recall given two STPs, P1 P2 , defined set variables,
STP P3 = P1 P2 variables P1 P2 temporal constraint c3ij =
c1ij c2ij , is, intervals P3 intersection corresponding intervals P 1
P2 . Given this, fact set projections P set projections
STPU obtained cutting P min , immediately derive Theorem 6
solution P satisfies condition. (): Let us consider control sequence P
6 Sol(P ). Then, j {min . . . } 6 Sol(T j ). Theorem 6 conclude
P opt(P ) = j T, optimal solution P . 2
Theorem 8 execution algorithm Best-SC STPPU P stops due occurrence
Event 1 (line 4), P -SC 0.
Proof: every preference level min , Q =-Cut(P ), =min -Cut(P )=Qmin . occurrence Event 1 implies Qmin strongly controllable. must
Q , min . thus P -SC min . Theorem 3 allows us conclude
> min . 2

662

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

Theorem 9 execution algorithm Best-SC STPPU P stops due occurrence
Event 2 (line 11) preference level ,
1 = opt = maxT Sol(P ) pref (T );
P OSC control sequence solution STP P opt (returned algorithm) iff
optimal scenario P .
Proof: condition line 11 satisfied STPU Q , means schedules
P preference . However, condition satisfied previous preference
level, 1, means schedules preference 1. allows us conclude
1 optimal preference STPPU P seen STPP, is, 1 = opt =
maxT Sol(P ) pref (T ). Since assuming line 11 executed Best-SC level opt + 1,
conditions lines 13 16 must satisfied preference opt. means
level opt STP P opt (line 15) consistent. looking line 15, see STP P opt
satisfies hypothesis Theorem 7 preference min preference opt. allows us
conclude solution P opt optimal scenario P vice versa. Thus, P opt-SC
and, Theorem 4, OSC. 2
Theorem 10 execution algorithm Best-SC STPPU P stops due occurrence
Event 3 (line 13) Event 4 (line 16) preference level P OSC ( 1)SC solution STP P 1 (returned algorithm) that, P P roj(P ):
T, Sol(P ), opt(P ) 1, pref (T, ) = opt(P ), otherwise pref (T, ) 1.
Proof: Event 3 Event 4 occurs condition line 11 must satisfied preference level . means STPU PC(Q ) consistent thus schedules P
preference . Event 3 occurs, condition line 13 must satisfied. STPU obtained
cutting P preference level applying path consistency strongly controllable.
thus conclude, using Corollary 1, P OSC. However since algorithm executed
line 11 preference level , 1 must reached line 18. looking line 15
see STP P 1 satisfies hypothesis Theorem 7 preference min preference level
1. allows us conclude P 1-SC.
instead Event 4 occurs P inconsistent (by Theorem 7) means
common assignment executables optimal scenarios preference <
time preference equal . However since execution reached line
16 preference level , assume successfully completed loop preference
1 conclude P 1-SC.2
Theorem 11 Determining optimal strong controllability highest preference level -SC
STPPU n variables ` preference levels achieved O(n 3 `).
Proof: Notice first complexity procedure -Cut (lines 3 10) intersecting two
STPs (line 15) linear number constraints thus O(n 2 ). Assuming `
different preference levels, conclude complexity Best-SC bounded
applying ` times StronglyControllable, O(n 3 `) (see Section 2).2
Theorem 12 STPPU P OWC iff STPU Q, obtained simply ignoring preference functions constraints WC.
663

fiROSSI , V ENABLE ,& YORKE -S MITH

Proof: P OWC, every situation P exists control sequence
schedule T, consistent optimal projection P . every projection P P
corresponding projection Q, say Q , STP obtained P ignoring
preference functions. easy see Definition 1 Section 2.2 implies assignment
optimal solution P solution Q . STPU Q WC every projection
Q exists control sequence schedule , solution Q . Definition 1 Section 2.2 conclude corresponding STPP P least solution thus
must least optimal solution, solution solution higher
preference. 2
Theorem 13 Given STPPU P , consider preference level STPU Q , obtained
cutting P , consistent. STPU PC(Q ) DC P ODC -DC,
.
Proof: Assume preference level PC(Q ) DC. means
viable execution strategy : P roj(PC(Q )) Sol(PC(Q )) P1 , P2
P roj(Q ) executable x, [S(P1 )]<x = [S(P2 )]<x [S(P1 )]x = [S(P2 )]x .
Let us recall that, due semi-convexity preference functions, cutting STPPU
given preference level return smaller intervals constraints. Thus, every
projection P roj(Q ) (which STP) corresponds projection P roj(P )
STPP obtained STP restoring preference functions P.
Let us assume, contrary, P ODC and, thus, exists viable strategy
0
: P roj(P ) Sol(P ) P1 , P2 P roj(P ), [S 0 (P1 )]<x = [S 0 (P2 )]<x
[S 0 (P1 )]x = [S 0 (P2 )]x , pref (S 0 (Pi )) = opt(Pi ), = 1, 2. Consider, restriction
0 projections P roj(PC(Q )). Since pref (S 0 (P ) = opt(P ) every P , must
P P roj((PC(Q )), 0 (P ) Sol((PC(Q )). Thus restriction 0 satisfies
requirements strategy definition DC. contradiction fact
PC(Q ) DC. Thus P cannot ODC.
Theorem 6, P P roj(P ), P P roj(PC(Q )) iff opt(P ) . allows us
conclude P -DC. Finally, Theorem 3 allows conclude P -DC, .
2
Lemma 1 (useful proof Theorem 14) Consider STPU Q DynamicallyCo
ntrollable reported success Q. Consider constraint AB, B executables
execution always precedes B, defined interval [p, q] wait max 10 . Then,
exists viable dynamic strategy Q P roj(Q), [S(Qi )]B [S(Qi )]A tmax .
Proof: dynamic strategy produced algorithm DC-Execute shown Figure 7, Section 2. fact, line 5 stated executable B executed soon as, current
time, three following conditions satisfied: (1) B live, i.e. current time must lie lower upper bounds, (2) B enabled, i.e. variables must precede B
executed, (3) waits B satisfied. Let us denote current time ,
assume B live enabled . Thus, ([S(Q )]A ) [p, q]. third requirement satisfied
one two following scenarios: either last contingent time-point B
wait occurred thus B executed immediately, waits contingent
10. Notice tmax longest wait B must satisfy imposed contingent time-point C constraint AB.

664

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

time-points, among B wait, yet occurred expired .
cases must tmax + [S(Qi )A ]. Thus, ([S(Qi )]B = ) [S(Qi )]A tmax . 2
Theorem 14 Consider STPPU P STPUs, +1 , obtained cutting P respectively
level + 1 applying PC, without finding inconsistencies, DynamicallyControllable
success. Consider STPU P +1 = Merge(T , +1 ).
Then, Merge(T , +1 ) fail
P +1 dynamically controllable
viable dynamic strategy every projection P P roj(P +1 ),
opt(Pi ) = opt(Pi ) = + 1 P , pref (S(Pi )) = opt(Pi );
otherwise pref (S(Pi )) + 1.
Proof: following constructive proof which, assuming Merge failed, strategy
S, satisfying requirements theorem, defined.
First notice P roj(P +1 ) = P roj(T ). fact, line 2 Merge, P +1 initialized

. Merge changes requirement intervals leaving contingent intervals unaltered.
Furthermore, P roj(T +1 ) P roj(T ). seen using first claim Theorem 6
Section 5.
Let 0 00 viable dynamic execution strategies obtained running DC-Execute respectively +1 . Now, since P roj(T +1 ) P roj(T ), projections
mapped two, possibly different, schedules: one 0 one 00 . every projection
Pi P roj(P +1 ) every executable B, notice 00 [Pi ]<B exists equal
0 [Pi ]<B . thus define history B (which recall set durations contingent events finished prior B) new strategy S[Pi ]<B = 0 [Pi ]<B every
projection Pi P roj(P +1 ) . Notice 00 [Pi ]<B defined history B Pi contains
duration mapped preference exactly equal thus P cannot projection
+1 .
consider define depending case AB constraint
+1 .
Constraint AB Follow Unordered Follow +1 . cases, Merge
change interval AB, leaving .
Let us first analyze scenario AB Follow case STPUs.
case, execution B always follow contingent time point C
problems. Thus, every projection P P roj(P +1 ), S[P ]<B = . Since
problems dynamically controllable [p , q ] 6= [p+1 , q +1 ] 6= . Furthermore,
since path consistency enforced problems, constraints minimal
form (see Section 2), is, every value AB [p , q ] (resp. [p+1 , q +1 ])
situation (resp. +1 ) T, Sol(P ) AB = AB . Finally, since
P roj(T +1 ) P roj(T ), must [p+1 , q +1 ] [p , q ].
Next consider scenario AB Unordered case +1 . Let us start
proving that, case, must [p +1 , q +1 ] [p , ]. First, show
665

fiROSSI , V ENABLE ,& YORKE -S MITH

p+1 p . definition, p+1 situation P P roj(T +1 )
schedule T, Sol(P ) AB = p+1 . Since P roj(T +1 )
P roj(T ), p+1 [p , q ]. Next let us prove must > q +1 . Notice
wait induces partition situations two sets: that, every
contingent point C, AC < , contingent point C 0 , AC 0 .
first case, contingent events occurred expiration wait
B executed tA + (where tA execution time A). second
case safe execute B tA + . Given P roj(T +1 ) P roj(T ), B
constrained follow execution every contingent time-point +1 , must
projections +1 belong first set partition thus q+1 < .
cases is, hence, sufficient define new strategy follows: projections,
Pi , Pj P roj(P +1 ) [S(Pi )]<B = [S(Pj )]<B [S(Pi )]B = [S(Pj )]B =
[S 00 (Pi )]B [S 00 (Pi )]B exists, otherwise [S(Pi )]B = [S(Pj )]B = [S 0 (Pi )]B . assignment
guarantees identify projections constraints mapped preferences +1 [S 00 (Pi )]B
exists thus Pi P roj(T +1 ), otherwise projections P roj(T )
P roj(T +1 ).
Constraint AB Precede case +1 . B must precede contingent timepoint C. means assignment B corresponding value [p , q ] (resp.
[p+1 , q +1 ]) extended complete solution projection P roj(T ) (resp.
P roj(T +1 )). Interval [p0 , q 0 ] is, fact, obtained Merge, intersecting two intervals.
Since assuming Merge failed, intersection cannot empty (line 6
Figure 14). can, thus, example, define follows: pair projections
Pi , Pj P roj(P +1 ) [S(Pi )]<B = [S(Pj )]<B [S(Pi )]B (= [S(Pj )]B ) = p0 .
Constraint AB Unordered Unordered Precede +1 . First let us recall
result applying Merge interval [p 0 , q 0 ], p0 = p , q 0 = min(q , q +1 )
wait t0 = max(t , t+1 ). Since, hypothesis, Merge failed, must 0 q 0
(line 9, Figure 14.
Notice that, due semi-convexity preference functions, p p+1 . fact, B
executed tA + p (where tA time executed)
contingent time-points B wait occurred. Let us indicate x mlb

+1 ),
(resp. x+1
mlb ) maximum lower bound AC constraint (resp.

+1
B wait C. must p xmlb (resp. p+1 xmlb ). However due
semi-convexity preference functions x mlb x+1
mlb .
case define strategy follows. pair projections Pi , Pj
P roj(P +1 ), [S(Pi )]<B =[S(Pj )]<B [S(Pi )]B = [S(Pj )]B = max([S 00 (Pi )]B ,
[S 0 (Pi )]B ) whenever [S 00 (Pi )]B defined. Otherwise [S(Pi )]B =[S(Pj )]B = [S 0 (Pi )]B .
Lemma 1 max([S 00 (Pi )]B , [S 0 (Pi )]B ) t0 , hence [S(Pi )]B = ([S(Pj )]B )
[p0 , q 0 ].
Let us consider preferences induced constraints assignment. First
let us consider case max([S 00 (Pi )]B , [S 0 (Pi )]B ) = [S 00 (Pi )]B . Since 00
dynamic strategy +1 assignment identify projections preference + 1.
instead max([S 00 (Pi )]B , [S 0 (Pi )]B ) = [S 0 (Pi )]B , must [S 0 (Pi )]B > [S 00 (Pi )]B .
666

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

However know, Lemma 1 [S 00 (Pi )]B t+1 t0 [S 0 (Pi )]B t0 .
implies [S 0 (Pi )]B [p+1 , t0 ] thus assignment preference +
1. Finally, [S 00 (Pi )]B defined, noted above, Pi 6 P roj(T +1 ) thus
opt(Pi ) = (since Theorem 6 Section 5 P P roj(T ) opt(Pi )
). Thus, [S(Pi )]B =[S(Pj )]B = [S 0 (Pi )]B , which, assignment , identifies
preferences = opt(Pi ).
shown that, Merge fail, dynamic strategy (with
required additional properties) certifies P+1 dynamically controllable.
Assume, instead, Merge fails constraint. two cases
happen. first one AB Precede case +1 [p , q ] [p+1 , q +1 ]
= . proven (Morris et al., 2001), projection AB viable dynamic strategy
[p , q ] projection AB viable dynamic strategy +1 [p+1 , q +1 ].
dynamic viable strategies give optimal solutions projections optimal preference
equal . dynamic viable strategies +1 give optimal solutions projections
optimal preference equal + 1. Since projections +1 subset ,
[p , q ] [p+1 , q +1 ] = strategy either optimal projection
+1 vice-versa.
second case occurs Merge fails constraint AB either Unordered
case +1 Unordered case precede case +1 .
cases failure due fact [t , q ] [t+1 , q +1 ] = . must either q +1 <
q < t+1 . upper bound interval AB q +1 must least
contingent time-point C executing B q +1 either inconsistent
assignment C gives preference lower + 1. side, wait
constraint AB must least contingent time-point C 0 executing B
either inconsistent optimal future occurrences C.
way define viable dynamic strategy simultaneously optimal projections optimal
value equal optimal value + 1. 2
Lemma 2 (Useful proof Theorem 15) Consider strategies 0 , 00 defined
Theorem 14.
1. projection P +1 , Pi , pref (S(Pi )) pref (S 0 (Pi )) every projection, Pz ,
+1 , pref (S(Pz )) + 1;
2. constraint AB, [S(Pi )]B t0 .
Proof:
1. Obvious, since cases either [S(P )]B = [S 0 (Pi )]B [S(Pi )]B = [S 00 (Pi ) ]B
pref (S 00 (Pi )) pref (S 0 (Pi )) since every executable B [S 00 (Pi )]B +1 . Moreover,
every projection Pz +1 , every executable B, [S(Pz )]B = [S 00 (Pz )]B .
2. Derives directly fact either [S(P )]B = [S 0 (Pi )]B [S(Pi )]B = [S 00 (Pi )]B
Lemma 1 2.

667

fiROSSI , V ENABLE ,& YORKE -S MITH

Theorem 15 Consider STPPU P every preference level, , define STPU obtained
cutting P , applying PC DynamicallyControllable. Assume ,
DC. Consider STPU P :
P = Merge(Merge(. . . Merge(Merge(T min , min +1 ), min +2 ), . . . ), )
min minimum preference constraint P. Assume that, applied, Merge
always returned consistent STPU. Then, viable dynamic strategy S, P
P roj(P ), opt(Pi ) S(Pi ) optimal solution Pi , otherwise pref (S(Pi )) + 1.
Proof: prove theorem induction. First, notice that, construction P roj (T min ) =
P roj(P ). allows us conclude P roj(P ) = P roj(P ), since, every time Merge
applied, new STPU contingent constraints STPU given first argument.
Now, since min dynamically controllable viable dynamic strategies, say min
min (Pi ) optimal opt(Pi ) = min and, otherwise, pref (S(Pi )) min .
Consider P min +1 =Merge (T min ,T min +1 ). Theorem 14, know
strategy, min +1 , min +1 (Pi ) optimal solution Pi opt(Pi ) min + 1
pref (S(PI )) min + 1 otherwise.
Let us assume STPU P min +k , defined hypothesis, satisfies thesis
P min +k+1 , defined hypothesis, min + k + 1 , not. Notice
implies strategy, min +k , min +k (Pi ) optimal solution Pi
opt(Pi ) min + k pref (S(Pi )) min + k projections. Since min +
k + 1 , then, hypothesis also min +k+1 DC. Moreover, construction,
P min +k+1 =Merge (P min +k ,T min +k+1 ), since Merge doesnt fail. Thus, using Theorem 14
using strategy min +k P min +k construction Theorem 14, Lemma 2,
obtain dynamic strategy, min +k+1 , every projection Pi , pref (S min +k+1 (Pi ))
pref (S min +k (Pi )) min +k+1 (Pj ) optimal solution projections P j
opt(Pj ) = min + k + 1 pref (S(Pj )) min + k + 1 projections.
allows us conclude min +k+1 (Ph ) optimal solution projections P h
opt(Ph ) min + k + 1. contradiction assumption P min +k+1 doesnt satisfy
thesis theorem. 2
Theorem 16 Given STPPU P, execution algorithm Best-DC P terminates.
Proof: assume preference set discretized finite number different
preferences. Best-DC starts lowest preference cuts level P. If, given level,
STPU obtained consistent dynamically controllable merging procedure fails,
Best-DC stops level. Assume, instead, that, moves preference ordering,
none events occur. However certain point cutting level higher
maximum preference function (or outside preference set) case
cutting problem give inconsistent STP.2
Theorem 17 Given STPPU P input, Best-DC terminates line 4 iff 6 0 P
-DC.
Proof: . Assume Best-DC terminates line 4. Then, STPU obtained cutting P
minimum preference, min , constraint DC. However cutting minimum
668

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

preference constraint preference level 0 gives STPU. Theorem 13
conclude P -DC 0 and, thus, ODC.
. Assume P -DC preferences 0. cutting P minimum preference
min cannot give dynamically controllable problem, otherwise, P would min -DC. Hence,
Best-DC exit line 4. 2
Theorem 18 Given STPPU P input, Best-DC terminates line 11 iff P ODC.
Proof: . Assume Best-DC terminates line 11 considering preference level . Then,
STPU Q obtained cutting STPPU P level path consistent. immediately conclude projection P P roj(Pi ) opt(Pi ) .
Since Best-DC terminate before, must assume preference 1,
tests (path consistency, dynamic controllability, Merge) successful.
consider STPU P 1 obtained end iteration corresponding preference
level 1. easy see P 1 satisfies hypothesis Theorem 15. allows us
conclude viable dynamic strategy every projection P ,
opt(Pi ) 1, S(Pi ) optimal solution Pi . However since know projections
P opt(Pi ) < , allows us conclude P ODC.
. P ODC viable strategy every pair projections, P , Pj
P roj(P ), executable B, [S(P )]<B = [S(Pj )]<B [S(Pi )]B = [S(Pj )]B
S(Pi ) optimal solution Pi S(Pj ) optimal solution Pj .
Theorem 17 know Best-DC cannot stop line 4.
Let us consider line 13 show Best-DC sets -DC true line P
cannot ODC. fact condition setting -DC true line 13 STPU obtained
cutting P preference level path consistent dynamically controllable. means
projections, e.g. Pj , P opt(Pj ) = . However, dynamic strategy
set projections. Thus, P cannot ODC.
Let us consider line 16, show that, P ODC Best-DC cannot set -DC true.
Best-DC sets -DC true Merge failed. Using Theorem 14, conclude
dynamic viable strategy every projection P , P , (remember P roj(P 1 ) =
P roj(P )) S(Pi ) optimal solution opt(Pi ) . However, know projections
P optimal preference equal (since assuming Best-DC stopping line 16
11). Thus, P cannot ODC.2
Theorem 19 Given STPPU P input, Best-DC stops lines 13 16 preference level iff P
( 1)-DC ODC.
Proof: . Assume Best-DC sets -DC true line 13, considering preference level
. Thus, STPU obtained cutting P level path consistent DC. However since
must first preference level happens, otherwise Best-DC would stopped
sooner, conclude iteration preference level 1 successful. Considering
P 1 using Theorem 15 conclude viable dynamic strategy that,
every projection P , Pi , opt(Pi ) 1 S(Pi ) optimal solution Pi
pref (S(Pi )) 1 otherwise. definition 1-dynamic controllability.
Best-DC terminates line 16, Theorem 15 Theorem 14 conclude that,
viable dynamic strategy every projection P , P , opt(Pi ) 1
669

fiROSSI , V ENABLE ,& YORKE -S MITH

S(Pi ) optimal solution Pi pref (S(Pi )) 1 otherwise, strategy
guaranteeing optimality also projections optimal preference . Again, P 1-DC.
. P -DC, 0 Theorem 17, Best-DC stop line 4. P
-DC, ODC, 0 Theorem 18, Best-DC stop line 11.
Theorem 16, Best-DC always terminates, must stop line 13 16.2
Theorem 20 complexity determining ODC highest preference level -DC
STPPU n variables, bounded number preference levels l O(n 5 `).
Proof: Consider pseudocode algorithm Best-DC Figure 13.
complexity min -Cut(P ) line 3 O(n2 ), since every constraint must considered,
O(n2 ) constraints, constraint time finding interval
elements mapped preference min constant. complexity checking STPU obtained DC O(n5 ). Thus, lines 3 4, always performed, overall complexity
O(n5 ). Lines 7 8, clearly, take constant time.
Let us consider fixed preference level compute cost complete iteration .
(line 10) complexity -Cut(P ) O(n 2 );
(line 11) complexity applying PC testing path consistency O(n 3 ) (see Section 2.1,
(Dechter et al., 1991));
(line 13) complexity testing DC using DynamicallyControllable O(n 5 ), (see Section 2 Morris Muscettola, 2005);
(line 15) constant time;
(line 16-18) complexity Merge O(n 2 ), since O(n2 ) constraints must
considered constraint merging two intervals constant cost;
(line 19) constant time.
conclude complexity complete iteration given preference level O(n 5 ).
worst case, cycle performed ` times. can, thus, conclude total
complexity Best-DC O(n5 `) since complexity operations performed lines 24-27
constant. 2

References
Badaloni, S., & Giacomin, M. (2000). Flexible temporal constraints. 8th Conference Information Processing Management Uncertainty knowledge-Based System (IPMU 2000),
pp. 12621269.
Bistarelli, S., Montanari, U., & Rossi, F. (1997). Semiring-based constraint solving optimization. Journal ACM, 44(2), 201236.
Bresina, J., Jonsson, A., Morris, P., & Rajan, K. (2005). Activity planning mars exploration
rovers. 15th International Conference Automated Planning Scheduling (ICAPS
2005), pp. 4049.
670

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

Coggiola, M., Shi, Z., & Young, S. (2000). Airborne deployment instrument real-time
analysis single aerosol particles. Aerosol Science Technology, 33, 2029.
Dearden, R., Meuleau, N., Ramakrishnan, S., Smith, D., & Washington, R. (2002). Contingency
planning planetary rovers. 3rd Intl. Workshop Planning Scheduling Space.
Dechter, R., Meiri, I., & Pearl, J. (1991). Temporal constraint networks. Artificial Intelligence,
49(1-3), 6195.
Dubois, D., Fargier, H., & Prade, H. (1993). Flexible constraint satisfaction problems application scheduling problems. Tech. rep. Report IRIT/93-30-R, I.R.I.T., Universite P.
Sabatier.
Dubois, D., Fargier, H., & Prade, H. (1995). Fuzzy constraints job shop-scheduling. Journal
Intelligent Manufacturing, 6, 215234.
Dubois, D., Fargier, H., & Prade, H. (2003a). Fuzzy scheduling: Modelling flexible constraints
vs. coping incomplete knowledge. European Journal Operational Research, 147,
231252.
Dubois, D., HadjAli, A., & Prade, H. (2003b). Fuzziness uncertainty temporal reasoning.
Journal Universal Computer Science, 9(9), 1168.
Dubois, D., & Prade, H. (1985). review fuzzy set aggregation connectives. Journal Information Science, 36(1-2), 85121.
Field, P., Hogan, R., Brown, P., Illingworth, A., Choularton, T., Kaye, P., Hirst, E., & Greenaway,
R. (2004). Simultaneous radar aircraft observations mixed-phase cloud 100m
scale. Quarterly Journal Royal Meteorological Society, 130, 18771904.
Floyd, R. W. (1962). Algorithm 97: Shortest path. Communication ACM, 36(6), 345.
Frank, J., Jonsson, A., Morris, R., & Smith, D. (2001). Planning scheduling fleets earth
observing satellites. 6th Intl. Symposium AI, Robotics, Automation Space (iSAIRAS01).
Khatib, L., Morris, P., Morris, R. A., & Rossi, F. (2001). Temporal constraint reasoning
preferences. Nebel, B. (Ed.), 17th International Joint Conference Artificial Intelligence,
(IJCAI 2001), pp. 322327. Morgan Kaufmann.
Lau, H. C., Ou, T., & Sim, M. (2005). Robust temporal constraint networks. Proc. 17th IEEE
Conf. Tools Artificial Intelligence (ICTAI05), pp. 8288 Hong Kong.
Leiserson, C. E., & Saxe, J. B. (1988). mixed-integer linear programming problem
efficiently solvable. Journal Algorithms, 9(1), 114128.
Morris, P., Morris, R., Khatib, L., Ramakrishnan, S., & Bachmann, A. (2004). Strategies global
optimization temporal preferences. Wallace, M. (Ed.), Proceeding 10th International Conference Principles Practice Constraint Programming (CP-04), Vol. 3258
Lecture Notes Computer Science, pp. 588603. Springer.
671

fiROSSI , V ENABLE ,& YORKE -S MITH

Morris, P. H., Muscettola, N., & Vidal, T. (2001). Dynamic control plans temporal uncertainty. Nebel, B. (Ed.), 17th International Joint Conference Artificial Intelligence
(IJCAI 2001), pp. 494502. Morgan Kaufmann.
Morris, P. H., & Muscettola, N. (1999). Managing temporal uncertainty waypoint controllability. Dean, T. (Ed.), 16th International Joint Conference Artificial Intelligence
(IJCAI99), pp. 12531258. Morgan Kaufmann.
Morris, P. H., & Muscettola, N. (2005). Temporal dynamic controllability revisited. 20th National
Conference Artificial Intelligence (AAAI 2005), pp. 11931198. AAAI Press / MIT
Press.
Morris, R. A., Morris, P. H., Khatib, L., & Yorke-Smith, N. (2005). Temporal planning preferences probabilities. ICAPS05 Workshop Constraint Programming Planning
Scheduling.
Muscettola, N., Morris, P. H., Pell, B., & Smith, B. D. (1998). Issues temporal reasoning
autonomous control systems. Agents, pp. 362368.
Peintner, B., & Pollack, M. E. (2004). Low-cost addition preferences DTPs TCSPs.
McGuinness, D. L., & Ferguson, G. (Eds.), 19th National Conference Artificial Intelligence, pp. 723728. AAAI Press / MIT Press.
Peintner, B., & Pollack, M. E. (2005). Anytime, complete algorithm finding utilitarian optimal
solutions STPPs. 20th National Conference Artificial Intelligence (AAAI 2005), pp.
443448. AAAI Press / MIT Press.
Pini, M. S., Rossi, F., & Venable, K. B. (2005). Possibility theory reasoning uncertain
soft constraints. Godo, L. (Ed.), 8th European Conference Symbolic Quantitative
Approaches Reasoning Uncertainty (ECSQARU 2005), Vol. 3571 LNCS, pp. 800
811. Springer.
Rajan, K., Bernard, D. E., Dorais, G., Gamble, E. B., Kanefsky, B., Kurien, J., Millar, W., Muscettola, N., Nayak, P. P., Rouquette, N. F., Smith, B. D., Taylor, W., & Tung, Y. W. (2000).
Remote Agent: autonomous control system new millennium. Horn, W. (Ed.),
14th European Conference Artificial Intelligence, ECAI 2000, pp. 726730. IOS Press.
Rossi, F., Sperduti, A., Venable, K., Khatib, L., Morris, P., & Morris, R. (2002). Learning solving soft temporal constraints: experimental study. Van Hentenryck, P. (Ed.), Principles
Practice Constraint Programming, 8th International Conference (CP 2002), Vol. 2470
LNCS, pp. 249263. Springer.
Rossi, F., Venable, K. B., & Yorke-Smith, N. (2004). Controllability soft temporal constraint
problems. 10th International Conference Principles Practice Constraint Programming (CP-04), Vol. 3258 LNCS, pp. 588603.
Rossi, F., Venable, K., & Yorke-Smith, N. (2003). Preferences uncertainty simple temporal problems. Proc. CP03 Workshop: Online-2003 (International Workshop Online
Constraints Solving - Handling Change Uncertainty).
672

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

Ruttkay, Z. (1994). Fuzzy constraint satisfaction. Proceedings 1st IEEE Conference Evolutionary Computing, pp. 542547 Orlando.
Schiex, T. (1992). Possibilistic Constraint Satisfaction problems handle soft constraints?. Dubois, D., & Wellman, M. P. (Eds.), 8th Annual Conference Uncertainty
Artificial Intelligence (UAI92), pp. 268275. Morgan Kaufmann.
Shostak, R. E. (1981). Deciding linear inequalities computing loop residues. Journal
ACM, 28(4), 769779.
Stergiou, K., & Koubarakis, M. (2000). Backtracking algorithms disjunctions temporal constraints. Artificial Intelligence, 120(1), 81117.
Tsamardinos, I. (2002). probabilistic approach robust execution temporal plans uncertainty. Vlahavas, I. P., & Spyropoulos, C. D. (Eds.), Methods Applications Artificial
Intelligence, Second Hellenic Conference AI (SETN 2002), Vol. 2308 LNCS, pp. 97
108. Springer.
Tsamardinos, I., Pollack, M. E., & Ramakrishnan, S. (2003a). Assessing probability legal execution plans temporal uncertainty. Workshop Planning Uncertainty
Incomplete Information Thirteenth International Conference Automated Planning
Scheduling (ICAPS 2003).
Tsamardinos, I., Vidal, T., & Pollack, M. E. (2003b). CTP: new constraint-based formalism
conditional, temporal planning. Constraints, 8(4), 365388.
Venable, K., & Yorke-Smith, N. (2003). Simple Temporal Problems Preferences Uncertainty. Doctoral Consortium 13th International Conference Automated Planning
Scheduling (ICAPS 2003). AAAI Press.
Venable, K., & Yorke-Smith, N. (2005). Disjunctive temporal planning uncertainty. 19th
International Joint Conference Artificial Intelligence (IJCAI 2005), pp. 172122. Morgan
Kaufmann.
Vidal, T., & Fargier, H. (1999). Handling contingency temporal constraint networks: consistency controllabilities. Journal Experimental Theoretical Artificial Intelligence,
11(1), 2345.
Vidal, T., & Ghallab, M. (1996). Dealing uncertain durations temporal constraint networks
dedicated planning. Wahlster, W. (Ed.), 12th European Conference Artificial Intelligence (ECAI96), pp. 4854. John Wiley Sons.
Vila, L., & Godo, L. (1994). fuzzy temporal constraint networks. Mathware Soft Computing,
3, 315334.
Xu, L., & Choueiry, B. Y. (2003). new efficient algorithm solving simple temporal problem. 10th Intl. Symposium Temporal Representation Reasoning Fourth Intl.
Conf. Temporal Logic (TIME-ICTP03), pp. 212222.

673

fiROSSI , V ENABLE ,& YORKE -S MITH

Yorke-Smith, N., Venable, K. B., & Rossi, F. (2003). Temporal reasoning preferences uncertainty. Gottlob, G., & Walsh, T. (Eds.), 18th International Joint Conference Artificial
Intelligence (IJCAI03), pp. 13851386. Morgan Kaufmann.
Zadeh, L. A. (1975). Calculus fuzzy restrictions. Fuzzy Sets Applications Cognitive
Decision Processes, 140.

674

fiJournal Artificial Intelligence Research 27 (2006) 299-334

Submitted 01/06; published 11/06

Properties Applications Programs Monotone Convex
Constraints
Lengning Liu
Mirosaw Truszczynski

LLIU 1@ CS . UKY. EDU
MIREK @ CS . UKY. EDU

Department Computer Science, University Kentucky,
Lexington, KY 40506-0046, USA

Abstract
study properties programs monotone convex constraints. extend
formalisms concepts results normal logic programming. include notions
strong uniform equivalence characterizations, tight programs Fages Lemma,
program completion loop formulas. results provide abstract account properties
recent extensions logic programming aggregates, especially formalism lparse
programs. imply method compute stable models lparse programs means off-theshelf solvers pseudo-boolean constraints, often much faster smodels system.

1. Introduction
study programs monotone constraints (Marek & Truszczy nski, 2004; Marek, Niemela,
& Truszczynski, 2004, 2006) introduce related class programs convex constraints.
formalisms allow constraints appear heads program rules, sets apart
recent proposals integrating constraints logic programs (Pelov, 2004; Pelov,
Denecker, & Bruynooghe, 2004, 2006; DellArmi, Faber, Ielpa, Leone, & Pfeifer, 2003; Faber,
Leone, & Pfeifer, 2004), makes suitable abstract basis formalisms lparse
programs (Simons, Niemela, & Soininen, 2002).
show several results normal logic programming generalize programs monotone constraints. also discuss techniques results extended
setting programs convex constraints. apply general results design
implement method compute stable models lparse programs show often
much effective smodels (Simons et al., 2002).
Normal logic programming semantics stable models effective knowledge representation formalism, mostly due ability express default assumptions (Baral, 2003; Gelfond
& Leone, 2002). However, modeling numeric constraints sets normal logic programming
cumbersome, requires auxiliary atoms leads large programs hard process efficiently. Since
constraints, often called aggregates, ubiquitous, researchers proposed extensions normal
logic programming explicit means express aggregates, generalized stable-model semantics extended settings.
Aggregates imposing bounds weights sets atoms literals, called weight constraints,
especially common practical applications included recent extensions logic
programs aggregates. Typically, extensions allow aggregates appear
c
2006
AI Access Foundation. rights reserved.

fi
L IU & RUSZCZY NSKI

heads rules. notable exception formalism programs weight constraints (Niemel a,
Simons, & Soininen, 1999; Simons et al., 2002), refer lparse programs 1 .
Lparse programs logic programs whose rules weight constraints heads
whose bodies conjunctions weight constraints. Normal logic programs viewed
subclass lparse programs semantics lparse programs generalizes stable-model
semantics normal logic programs (Gelfond & Lifschitz, 1988). Lparse programs one
commonly used extensions logic programming weight constraints.
Since rules lparse programs may weight constraints heads, concept onestep provability nondeterministic, hides direct parallels lparse normal logic
programs. explicit connection emerged Marek Truszczy nski (2004) Marek et al.
(2004, 2006) introduced logic programs monotone constraints. programs allow aggregates heads rules support nondeterministic computations. Marek Truszczy nski
(2004) Marek et al. (2004, 2006) proposed generalization van Emden-Kowalski onestep provability operator account nondeterminism, defined supported stable models
programs monotone constraints mirror normal logic programming counterparts,
showed encodings smodels programs programs monotone constraints.
paper, continue investigations programs monotone constraints. show
notions uniform strong equivalence programs (Lifschitz, Pearce, & Valverde, 2001;
Lin, 2002; Turner, 2003; Eiter & Fink, 2003) extend programs monotone constraints,
characterizations (Turner, 2003; Eiter & Fink, 2003) generalize, too.
adapt programs monotone constraints notion tight program (Erdem & Lifschitz, 2003) generalize Fages Lemma (Fages, 1994).
introduce extensions propositional logic monotone constraints. define completion monotone-constraint program respect logic, generalize notion
loop formula. prove loop-formula characterization stable models programs
monotone constraints, extending setting monotone-constraint programs results obtained
normal logic programs Clark (1978) Lin Zhao (2002).
Programs monotone constraints make explicit references default negation operator.
show allowing general class constraints, called convex, default negation
eliminated language. argue results paper extend programs convex
constraints.
paper shows programs monotone convex constraints rich theory
closely follows normal logic programming. implies programs monotone convex constraints form abstract generalization extensions normal logic programs. particular, results obtain abstract setting programs monotone convex constraints
specialize lparse programs and, cases, yield results new.
results practical implications. properties program completion loop
formulas, specialized class lparse programs, yield method compute stable models
lparse programs means solvers pseudo-boolean constraints, developed propositional satisfiability integer programming communities (Een & Sorensson, 2003; Aloul, Ramani,
Markov, & Sakallah, 2002; Walser, 1997; Manquinho & Roussel, 2005; Liu & Truszczy nski, 2003).
describe method detail present experimental results performance. results
show method problems used testing typically outperforms smodels.
1. Aggregates heads rules also studied recently Son Pontelli (2006) Son, Pontelli,
Tu (2006).

300

fiP ROPERTIES PPLICATIONS P ROGRAMS ONOTONE C ONVEX C ONSTRAINTS

2. Preliminaries
consider propositional case assume fixed set propositional atoms.
lead loss generality, common interpret programs variables terms
propositional groundings.
definitions results present section come papers Marek Truszczynski (2004) Marek et al. (2006). general allow constraints
infinite domains programs inconsistent constraints heads.
Constraints. constraint expression = (X, C), X C P(X) (P(X)
denotes powerset X). call set X domain constraint = (X, C) denote
Dom(A). Informally speaking, constraint (X, C) describes property subsets domain,
C consisting precisely subsets X satisfy constraint (have property) C.
paper, identify truth assignments (interpretations) sets atoms assign
truth value true. is, given interpretation At, |= .
say interpretation satisfies constraint = (X, C) (M |= A), X C.
Otherwise, satisfy A, (M 6|= A).
constraint = (X, C) consistent |= A. Clearly, constraint
= (X, C) consistent C 6= .
note propositional atoms regarded constraints. Let At.
define C(a) = ({a}, {{a}}). evident |= C(a) |= a. Therefore,
paper often write shorthand constraint C(a).
Constraint programs. Constraints building blocks rules programs. Marek Truszczynski (2004) defined constraint programs sets constraint rules
A1 , . . . , Ak , not(Ak+1 ), . . . , not(Am )

(1)

A, A1 , . . . , constraints default negation operator.
context constraint programs, refer constraints negated constraints literals.
Given rule r form (1), constraint (literal) head r set {A 1 , . . . ,
Ak , . . . , not(Ak+1 ), . . . , not(Am )} literals body r 2 . denote head body
r hd (r) bd (r), respectively. define headset r, written hset(r), domain
head r. is, hset(r) = Dom(hd (r)).
constraint program P , denote At(P ) set atoms appear domains
constraints P . define headset P , written hset(P ), union headsets
rules P .
Models. concept satisfiability extends standard way literals not(A) (M |= not(A)
6|= A), sets (conjunctions) literals and, finally, constraint programs.
M-applicable rules. Let interpretation. rule (1) -applicable satisfies
every literal bd (r). denote P (M ) set -applicable rules P .
Supported models. Supportedness property models. Intuitively, every atom supported
model must reasons in. reasons -applicable rules whose heads contain domains. Formally, let P constraint program subset At(P ). model
P supported hset(P (M )).
Examples. illustrate concept examples. Let P constraint program consists
following two rules:
2. Sometimes view body rule conjunction literals.

301

fi
L IU & RUSZCZY NSKI

({c, d, e}, {{c}, {d}, {e}, {c, d, e}})
({a, b}, {{a}, {b}}) ({c, d}, {{c}, {c, d}}), not(({e}, {{e}}))
set = {a, c} model P satisfies heads two rules. rules P
-applicable. first provides support c, second one a. Thus,
supported model.
set 0 = {a, c, d, e} also model P . However, support P . Indeed,
appears headset second rule. rule 0 -applicable so, support
a. Therefore, 0 supported model P .
4
Nondeterministic one-step provability. Let P constraint program set atoms. set
0 nondeterministically one-step provable means P , 0 hset(P (M ))
0 |= hd (r), every rule r P (M ).
nondeterministic one-step provability operator TPnd program P operator
P(At) every At, TPnd (M ) consists sets nondeterministically
one-step provable means P .
operator TPnd nondeterministic assigns family subsets At,
possible outcome applying P . general, Pnd partial, since may
sets TPnd (M ) = (no set derived means P ). instance,
P (M ) contains rule r hd (r) inconsistent, TPnd (M ) = .
Monotone constraints. constraint (X, C) monotone C closed superset, is,
every W, X, W C W C.
Cardinality weight constraints provide examples monotone constraints. Let X finite
set let Ck (X) = {Y : X, k |Y |}, k non-negative integer. (X, C k (X))
constraint expressing property subset X least k elements. call lowerbound cardinality constraint X denote kX.
general class constraints weight constraints. Let X finite set, say X =
{x1 , . . . , xn }, let w, w1 , . . . , wn non-negative reals. interpret wi weight assigned xi . lower-bound weight constraint constraint form (X, C w ), Cw consists subsets X whose total weight (the sum weights elements subset)
least w. write
w[x1 = w1 , . . . , xn = wn ].
weights equal 1 w integer, weight constraints become cardinality constraints. also note constraint C(a) cardinality constraint 1{a} also weight
constraint 1[a = 1]. Finally, observe lower-bound cardinality weight constraints
monotone.
Cardinality weight constraints (in somewhat general form) appear language
lparse programs (Simons et al., 2002), discuss later paper. notation adopted
constraints paper follows one proposed Simons et al. (2002).
use cardinality weight constraints examples. also focus
last part paper, use abstract results design new algorithm compute
models lparse programs.
Monotone-constraint programs. call constraint programs built monotone constraints
monotone-constraint programs programs monotone constraints. is, monotone-constraint
programs consist rules rules form (1), A, 1 , . . . , monotone constraints.
302

fiP ROPERTIES PPLICATIONS P ROGRAMS ONOTONE C ONVEX C ONSTRAINTS

on, unless explicitly stated otherwise, programs consider monotone-constraint
programs.
2.1 Horn Programs Bottom-up Computations
Since allow constraints infinite domains inconsistent constraints heads rules,
results given subsection general counterparts Marek Truszczy nski
(2004) Marek et al. (2004, 2006). Thus, sake completeness, present
proofs.
rule (1) Horn k = (no occurrences negation operator body or, equivalently,
monotone constraints). constraint program Horn every rule program Horn.
Horn constraint program associate bottom-up computations, generalizing corresponding notion bottom-up computation normal Horn program.
Definition 1. Let P Horn program. P -computation (transfinite) sequence hX

1. X0 = ,
2. every ordinal number , X X+1 X+1 TPnd (X ),

3. every limit ordinal , X = < X .
Let = hX P -computation. Since every < 0 , X X 0 At, least
ordinal number Xt +1 = Xt , words, least ordinal P -computation
stabilizes. refer length P -computation t.
Examples. simple example showing programs computations length
exceeding so, transfinite induction definition cannot avoided. Let P
program consisting following rules:
({a0 }, {{a0 }}) .
({ai }, {{ai }}) (Xi1 , {Xi1 }), = 1, 2, . . .
({a}, {{a}}) (X , {X }),
Xi = {a0 , . . . ai }, 0 i, X = {a0 , a1 , . . .}. Since body last rule contains constraint infinite domain X , become applicable finite step
computation. However, become applicable step so, X +1 . Consequently,
X+1 6= X .
4

P -computation = hX i, call X result computation denote
Rt . Directly definitions, follows Rt = Xt .
Proposition 1. Let P Horn constraint program P -computation. R supported
model P .
Proof. Let = Rt result P -computation = hX i. need show that: (1)
model P ; (2) hset(P (M )).
(1) Let us consider rule r P |= bd (r). Since = Rt = Xt (where
length t), Xt |= bd (r). Thus, Xt +1 |= hd (r). Since = Xt +1 , model r and,
consequently, P , well.
303

fi
L IU & RUSZCZY NSKI

(2) prove induction that, every set X computation t, X hset(P (M )).
base case holds since X0 = hset(P (M )).
= + 1, X TPnd (X ). follows X hset(P (X )). Since P Horn
program X , hset(P (X )) Shset(P (M )). Therefore, X hset(P (M )).
limit ordinal, X = < X . induction hypothesis, every < ,
X hset(P (M )). Thus, X hset(P (M )). induction, hset(P (M )).
Derivable models. use computations define derivable models Horn constraint programs.
set atoms derivable model Horn constraint program P P -computation
t, = Rt . Proposition 1, derivable models P supported models P so,
also models P .
Derivable models similar least model normal Horn program
derived program means bottom-up computation. However, due nondeterminism
bottom-up computations Horn constraint programs, derivable models general unique
minimal.
Examples. example, let P following Horn constraint program:
P = {1{a, b} }
{a}, {b} {a, b} derivable models. derivable models {a} {b} minimal
models P . third derivable model, {a, b}, minimal model P .
4
Since inconsistent monotone constraints may appear heads Horn rules, Horn
programs P sets X At, TPnd (X) = . Thus, Horn constraint programs
computations derivable models. However, Horn constraint program models,
existence computations derivable models guaranteed.
see this, let model Horn constraint program P . define canonical computation tP,M = hXP,M specifying choice next set computation part (2)
Definition 1. Namely, every ordinal , set
P,M
X+1
= hset(P (XP,M )) M.

is, include XP,M atoms occurring heads XP,M -applicable rules
belong . denote result tP,M Can(P, ). Canonical computations indeed
P -computations.
Proposition 2. Let P Horn constraint program. model P , sequence P,M
P -computation.
Proof. P fixed, simplify notation proof write X instead
XP,M .
prove assertion, suffices show (1) hset(P (X )) TPnd (X ), (2)
X hset(P (X )) , every ordinal .
(1) Let X r P (X). Since constraints bd (r) monotone, X |= bd (r), |=
bd (r), well. fact model P follows |= hd (r). Consequently,
hset(P (X)) |= hd (r) every r P (X). Since hset(P (X)) hset(P (X)),
hset(P (X)) TPnd (X).
304

fiP ROPERTIES PPLICATIONS P ROGRAMS ONOTONE C ONVEX C ONSTRAINTS

Directly definition canonical computation P obtain every
ordinal , X . Thus, (1), follows.
(2) proceed induction. basis evident X0 = . Let us consider ordinal > 0
let us assume (2) holds every ordinal < . = + 1, X = X+1 =
hset(P (X )) . Thus, induction hypothesis, X X . Since P Horn constraint
program, follows P (X ) P (X ). Thus
X = X+1 = hset(P (X )) hset(P (X )) M.
limit ordinal every < , X X and, before, also P (X ) P (X ). Thus,
induction hypothesis every < ,
X hset(P (X )) hset(P (X )) M,
implies
X =

[

X hset(P (X )) M.

<

Canonical computations following fixpoint property.
Proposition 3. Let P Horn constraint program. every model P ,
hset(P (Can(P, ))) = Can(P, ).
P,M
= XP,M = Can(P, ).
Proof. Let length canonical computation tP,M . Then, X+1
Since X+1 = hset(X ) , assertion follows.

gather properties derivable models extend properties least model normal
Horn logic programs.
Proposition 4. Let P Horn constraint program. Then:
1. every model P , Can(P, ) greatest derivable model P contained
2. model P derivable model = Can(P, )
3. minimal model P derivable model P .
Proof. (1) Let 0 derivable model P 0 . Let = hX P -derivation
0 = Rt . prove every ordinal , X XP,M . proceed transfinite
induction. Since X0 = X0P,M = , basis induction evident. Let us consider ordinal
> 0 assume every ordinal < , X XP,M .
= + 1, X TPnd (X ) so, X hset(P (X )). induction hypothesis
monotonicity constraints bodies rules P , X hset(P (XP,M )). Thus,
since X Rt = 0 ,
P,M
X hset(P (XP,M )) = X+1
= XP,M .

305

fi
L IU & RUSZCZY NSKI



case limit ordinal straightforward X = < X XP,M = < XP,M .
(2) () = Can(P, ), result canonical P -derivation P .
particular, derivable model P .
() derivable model P , also model P . (1) follows
Can(P, ) greatest derivable model P contained . Since derivable,
= Can(P, ).
(3) (1) follows Can(P, ) derivable model P Can(P, ) . Since
minimal model, Can(P, ) = and, (2), derivable model P .
2.2 Stable Models
section, recall adapt setting definition stable models proposed
studied Marek Truszczynski (2004) Marek et al. (2004, 2006) Let P monotoneconstraint program subset At(P ). reduct P , denoted P , program
obtained P by:
1. removing P rules whose body contains literal not(B) |= B;
2. removing literals not(B) bodies remaining rules.
reduct monotone-constraint program Horn since contains occurrences default
negation. Therefore, following definition sound.
Definition 2. Let P monotone-constraint program. set atoms stable model P
derivable model P . denote set stable models P St(P ).
definitions reduct stable models follow generalize proposed normal
logic programs, since setting Horn constraint programs, derivable models play role
least model.
normal logic programming standard extensions, stable models monotoneconstraint programs supported models and, consequently, models.
Proposition 5. Let P monotone-constraint program. At(P ) stable model P ,
supported model P .
Proof. Let stable model P . Then, derivable model P and, Proposition 1,
supported model P . follows model P . Directly definition
reduct follows model P .
also follows hset(P (M )). every rule r P (M ), rule r 0 P (M ),
head non-negated literals body r. Thus, hset(P (M ))
hset(P (M )) and, consequently, hset(P (M )). follows supported model
P.
Examples. example stable models monotone-constraint program. Let P
monotone-constraint program contains following rules:
2{a, b, c} 1{a, d}, not(1{c})
1{b, c, d} 1{a}, not(3{a, b, d}))
1{a}
306

fiP ROPERTIES PPLICATIONS P ROGRAMS ONOTONE C ONVEX C ONSTRAINTS

Let = {a, b}. Therefore, 6|= 1{c} 6|= 3{a, b, d}. Hence reduct P contains
following three Horn rules:
2{a, b, c} 1{a, d}
1{b, c, d} 1{a}
1{a}
Since = {a, b} derivable model P , stable model P .
0
Let 0 = {a, b, c}. 0 |= 1{c} 6|= 3{a, b, d}. Therefore, reduct P contains
two Horn rules:
1{b, c, d} 1{a}
1{a}
0

Since 0 = {a, b, c} derivable models P , 0 also stable model P . note
stable models monotone-constraint program, general, form anti-chain.
4
normal logic program Horn least model (only) stable model.
analogous situation.
Proposition 6. Let P Horn monotone-constraint program. At(P ) derivable
model P stable model P .
Proof. every set atoms P = P . Thus, derivable model P
derivable model P or, equivalently, stable model P .
next four sections paper show several fundamental results concerning
normal logic programs extend class monotone-constraint programs.

3. Strong Uniform Equivalence Monotone-constraint Programs
Strong equivalence uniform equivalence concern problem replacing rules logic
program others without changing overall semantics program. specifically,
strong equivalence concerns replacement rules within arbitrary programs, uniform
equivalence concerns replacements non-fact rules. case, stipulation
resulting program must stable models original one. Strong (and uniform)
equivalence important concept due potential uses program rewriting optimization.
Strong uniform equivalence studied literature mostly normal logic
programs (Lifschitz et al., 2001; Lin, 2002; Turner, 2003; Eiter & Fink, 2003).
Turner (2003) presented elegant characterization strong equivalence smodels programs,
Eiter Fink (2003) described similar characterization uniform equivalence normal
disjunctive logic programs. show characterizations adapted case
monotone-constraint programs. fact, one show representations normal logic
programs monotone-constraint programs (Marek et al., 2004, 2006) definitions characterizations strong uniform equivalence reduce introduced developed originally
normal logic programs.
307

fi
L IU & RUSZCZY NSKI

3.1 M-maximal Models
key role approach played models Horn constraint programs satisfying certain
maximality condition.
Definition 3. Let P Horn constraint program let model P . set N
N model P hset(P (N )) N -maximal model P , written N |= P .
Intuitively, N -maximal model P N satisfies rule r P (N ) maximally
respect . is, every r P (N ), N contains atoms belong hset(r)
domain head r.
illustrate notion, let us consider Horn constraint program P consisting single rule:
1{p, q, r} 1{s, t}.
Let = {p, q, s, t} N = {p, q, s}. One verify N models P .
Moreover, since rule P N -applicable, {p, q, r} N , N -maximal
model P . hand, N 0 = {p, s} -maximal even though N 0 model P
contained .
several similarities properties models normal Horn programs maximal models Horn constraint programs. state prove one turns
especially relevant study strong uniform equivalence.
Proposition 7. Let P Horn constraint program let model P .
-maximal model P Can(P, ) least -maximal model P .
Proof. first claim follows directly definition. prove second one, simplify
notation: write N Can(P, ) X XP,M .
first show N -maximal model P . Clearly, N . Moreover, Proposition
3, hset(P (N )) = N . Thus, N indeed -maximal model P .
show N least -maximal model P .
Let N 0 -maximal model P . show transfinite induction N N 0 .
Since X0 = , basis induction holds. Let us consider ordinal > 0 let us assume
X N 0 , every < . show N N 0 , sufficient show X N 0 .
Let us assume = + 1 < . Then, since X N 0 P Horn constraint
program, P (X ) P (N 0 ). Consequently,
X = X+1 = hset(P (X )) hset(P (N 0 )) N 0 ,
last inclusion follows factS
thatN 0 -maximal model P .
limit ordinal, X = < X inclusion X N 0 follows directly
induction hypothesis.
3.2 Strong Equivalence SE-models
Monotone-constraint programs P Q strongly equivalent, denoted P Q, every
monotone-constraint program R, P R Q R set stable models.
study strong equivalence monotone-constraint programs, generalize concept
SE-model due Turner (2003).
308

fiP ROPERTIES PPLICATIONS P ROGRAMS ONOTONE C ONVEX C ONSTRAINTS

close connections strong equivalence normal logic programs logic
here-and-there. semantics logic here-and-there given terms Kripke models
two words which, rephrased terms pairs interpretations (pairs sets propositional
atoms), give rise SE-models.
Definition 4. Let P monotone-constraint program let X, sets atoms. say
(X, ) SE-model P following conditions hold: (1) X ; (2) |= P ; (3)
X |=Y P . denote SE(P ) set SE-models P .
Examples. illustrate notion SE-model monotone-constraint program, let P consist
following two rules:
2{p, q, r} 1{q, r}, not(3{p, q, r})}
1{p, s} 1{p, r}, not(2{p, r})
observe = {p, q} model P . Let N = . N P (N ) empty.
follows hset(P (N )) = N so, N |=M P . Hence, (N, ) SE-models
P .
Next, let N 0 = {p}. clear N 0 . Moreover, P (N 0 ) = {1{p, s} 1{p, r}}.
Hence hset(P (N 0 )) = {p} N 0 so, N 0 |=M P . is, (N 0 , ) another SEmodel P .
4
SE-models yield simple characterization strong equivalence monotone-constraint programs. state prove it, need several auxiliary results.
Lemma 1. Let P monotone-constraint program let model P . (M, )
(Can(P , ), ) SE-models P .
Proof. requirements (1) (2) SE-model hold (M, ). Furthermore, since
model P , |= P . Finally, also hset(P (M )) . Thus, |=M P .
Similarly, definition canonical computation Proposition 1, imply first two requirements definition SE-models (Can(P , ), ). third requirement follows
Proposition 7.
Lemma 2. Let P Q two monotone-constraint programs SE(P ) = SE(Q).
St(P ) = St(Q).
Proof. St(P ), model P and, Lemma 1, (M, ) SE(P ). Hence,
(M, ) SE(Q) and, particular, |= Q. Lemma 1 again,
(Can(QM , ), ) SE(Q).
assumption,
(Can(QM , ), ) SE(P )
so, Can(QM , ) |=M P or, terms, Can(QM , ) -maximal model P .
Since St(P ), = Can(P , ). Proposition 7, least -maximal model
P . Thus, Can(QM , ). hand, Can(QM , ) so,
= Can(QM , ). follows stable model Q. inclusion proved
way.
309

fi
L IU & RUSZCZY NSKI

Lemma 3. Let P R two monotone-constraint programs. SE(P R) = SE(P )
SE(R).
Proof. assertion follows following two simple observations. First, every set
atoms, |= (P R) |= P |= R. Second, every two sets X
atoms, X |=Y (P R)Y X |=Y P X |=Y RY .
Lemma 4. Let P , Q two monotone-constraint programs. P Q, P Q
models.
Proof. Let model P . r denote constraint rule (M, {M }) . Then,
St(P {r}). Since P Q strongly equivalent, St(Q {r}). follows
model Q {r} so, also model Q. converse inclusion proved
way.
Theorem 1. Let P Q monotone-constraint programs. P Q SE(P ) =
SE(Q).
Proof. () Let R arbitrary monotone-constraint program. Lemma 3 implies SE(P
R) = SE(P ) SE(R) SE(Q R) = SE(Q) SE(R). Since SE(P ) = SE(Q),
SE(P R) = SE(Q R). Lemma 2, P R Q R stable models.
Hence, P Q holds.
() Let us assume SE(P ) \ SE(Q) 6= let us consider (X, ) SE(P ) \ SE(Q). follows
X |= P . Lemma 4, |= Q. Since (X, )
/ SE(Q), X 6|= QY . follows
X 6|= QY hset(QY (X)) 6 X. first case, rule r QY (X)
X 6|= hd (r). Since X QY Horn constraint program, r QY (Y ). Let us recall
|= Q so, also |= QY . follows |= hd (r). Since hset(r) hset(QY (X)),
hset(QY (X)) |= hd (r). Thus, hset(QY (X)) 6 X (otherwise, monotonicity
hd (r), would X |= hd (r)).
property holds second case. Thus, follows
(hset(QY (X)) ) \ X 6= .
define
X 0 = (hset(QY (X)) ) \ X.
Let R constraint program consisting following two rules:
(X, {X})
(Y, {Y }) (X 0 , {X 0 }).
Let us consider program Q0 = Q R. Since |= Q X , |= Q0 . Thus, |= QY0 and,
particular, Can(QY0 , ) well defined. Since R QY0 , X Can(QY0 , ). Thus,
hset(QY0 (X)) hset(QY0 (Can(QY0 , ))) = Can(QY0 , )
(the last equality follows Proposition 3). also Q Q 0 so,
X 0 hset(QY (X)) hset(QY0 (X)) Y.
310

fiP ROPERTIES PPLICATIONS P ROGRAMS ONOTONE C ONVEX C ONSTRAINTS

Thus, X 0 Can(QY0 , ). Consequently, Proposition 3, Can(QY0 , ). Since Can(QY0 , )
, = Can(QY0 , ) so, St(Q0 ).
Since P Q strongly equivalent, St(P0 ), P0 = P R. Let us recall
(X, ) SE(P ). Proposition 7, Can(P , ) least -maximal model P . Since X
-maximal model P (as X |=Y P ), follows Can(P , ) X. Since X 0 6 X,
Can(P0Y , ) X. Finally, since X 0 , 6 X. Thus, 6= Can(P0Y , ), contradiction.
follows SE(P ) \ SE(Q) = . symmetry, SE(Q) \ SE(P ) = , too. Thus, SE(P ) =
SE(Q).
3.3 Uniform Equivalence UE-models
Let set atoms. rD denote monotone-constraint rule
rD = (D, {D}) .
Adding rule rD program forces atoms true (independently program).
Monotone-constraint programs P Q uniformly equivalent, denoted P u Q,
every set atoms D, P {rD } Q {rD } stable models.
SE-model (X, ) monotone-constraint program P UE-model P every
SE-model (X 0 , ) P X X 0 , either X = X 0 X 0 = holds. write U E(P )
denote set UE-models P . notion UE-model generalization notion
UE-model due Eiter Fink (2003) setting monotone-constraint programs.
Examples. Let us look program used illustrate concept SE-model.
showed (, {p, q}) ({p}, {p, q}) SE-models P . Directly definition
UE-models follows ({p}, {p, q}) UE-model P .
4
present characterization uniform equivalence monotone-constraint programs
assumption sets atoms finite. One prove characterization uniform
equivalence arbitrary monotone-constraint programs, generalizing one results Eiter
Fink (2003). However, characterization proof complex and, brevity,
restrict attention finite case only.
start auxiliary result, allows us focus atoms At(P ) deciding whether pair (X, ) sets atoms SE-model monotone-constraint program
P.
Lemma 5. Let P monotone-constraint program, X two sets atoms. (X, )
SE(P ) (X At(P ), At(P )) SE(P ).
Proof. Since X given, X implies X At(P ) At(P ), first condition
definition SE-model holds sides equivalence.
Next, note every constraint C, |= C Dom(C) |= C. Therefore,
|= P At(P ) |= P . is, second condition definition SE-model
holds (X, ) holds (X At(P ), At(P )).
Finally, observe P = P At(P ) P (X) = P (X At(P )). Therefore,
hset(P (X)) = hset(P At(P ) (X At(P ))).
Since hset(P At(P ) (X At(P ))) At(P ), follows
hset(P (X)) X
311

fi
L IU & RUSZCZY NSKI


At(P ) hset(P At(P ) (X At(P ))) X At(P ).
Thus, X |=Y P X At(P ) |=Y At(P ) P At(P ) . is, third condition
definition SE-model holds (X, ) holds (X At(P ), At(P )).
Lemma 6. Let P monotone-constraint program At(P ) finite. every
(X, ) SE(P ) X 6= , set
{X 0 : X X 0 Y, X 0 6= Y, (X 0 , ) SE(P )}

(2)

maximal element.
Proof. At(P )X = At(P )Y , every element \X, \{y} maximal element
set (2). Indeed, since (X, ) SE(P ), Lemma 5, (X At(P ), At(P )) SE(P ).
Since X At(P ) = At(P ) 6 At(P ), X At(P ) = (Y \ {y}) At(P ). Therefore,
((Y \{y})At(P ), At(P )) SE(P ). Lemma 5 fact \{y} ,
(Y \ {y}, ) SE(P ). Therefore, \ {y} belongs set (2) so, maximal element
set.
Thus, let us assume At(P ) X 6= At(P ) . Let us define X 0 = X (Y \ At(P )).
X X 0 X 0 6= . Moreover, element X 0 \ X belongs At(P ). is,
X 0 At(P ) = X At(P ). Thus, Lemma 5, (X 0 , ) SE(P ) so, X 0 belongs set
(2). Since \ X 0 At(P ), finiteness At(P ) follows set (2) contains maximal
element containing X 0 . particular, contains maximal element.
Theorem 2. Let P Q two monotone-constraint programs At(P ) At(Q) finite.
P u Q U E(P ) = U E(Q).
Proof. () Let arbitrary set atoms stable model P {r }.
model P {rD }. particular, model P so, (Y, ) U E(P ). follows
(Y, ) U E(Q), too. Thus, model Q. Since model r , . Consequently,
model Q {rD } thus, also (Q {rD })Y .
Let X = Can((Q {rD })Y , ). X and, Proposition 7, X -maximal
model (Q {rD })Y . Consequently, X -maximal model QY . Since X |= Q,
(X, ) SE(Q).
Let us assume X 6= . Then, Lemma 6, maximal set X 0 X X 0
, X 0 6= (X 0 , ) SE(Q). follows (X 0 , ) U E(Q). Thus, (X 0 , ) U E(P )
so, X 0 |=Y P . Since X 0 , X 0 |=Y (P {rD })Y . recall stable model
P {rD }. Thus, = Can((P {rD })Y , ). Proposition 7, X 0 get X 0 = ,
contradiction. follows X = and, consequently, stable model Q {r }.
symmetry, every stable model Q {rD } also stable model P {rD }.
() First, note (Y, ) U E(P ) model P . Next, note P
Q models. Indeed, argument used proof Lemma 4 works also
assumption P u Q. Thus, (Y, ) U E(P ) (Y, ) U E(Q).
let us assume U E(P ) 6= U E(Q). Let (X, ) element (U E(P ) \ U E(Q))
(U E(Q) \ U E(P )). Without loss generality, assume (X, ) U E(P ) \ U E(Q).
Since (X, ) U E(P ), follows
312

fiP ROPERTIES PPLICATIONS P ROGRAMS ONOTONE C ONVEX C ONSTRAINTS

1. X
2. |= P and, consequently, |= Q
3. X 6= (otherwise, earlier observations, (X, ) would belong U E(Q)).
Let R = (Q {rX })Y . Clearly, R Horn constraint program. Moreover, since |= Q
X , |= R. Thus, Can(R, ) defined. X Can(R, ) . claim
Can(R, ) 6= . Let us assume contrary Can(R, ) = . St(Q {r X }).
Hence, St(P {rX }), is, = Can((P {rX })Y , ). Proposition 7,
least -maximal model (P {rX })Y X -maximal model (P {rX })Y (since
(X, ) SE(P ), X |=Y P so, X |=Y (P {rX })Y , too). Consequently, X and,
X , X = , contradiction.
Thus, Can(R, ) 6= . Proposition 7, Can(R, ) -maximal model R. Since
QY R, follows Can(R, ) -maximal model QY so, (Can(R, ), )
SE(Q). Since Can(R, ) 6= , Lemma 6 follows maximal set X 0
Can(R, ) X 0 , X 0 6= (X 0 , ) SE(Q). definition, (X 0 , ) U E(Q).
Since (X, )
/ U E(Q). X 6= X 0 . Consequently, since X X 0 , X 0 6= (X, ) U E(P ),
(X 0 , )
/ U E(P ).
Thus, (X 0 , ) U E(Q) \ U E(P ). applying argument (X 0 , )
show existence X 00 X 0 X 00 , X 0 6= X 00 , X 00 6= (X 00 , ) SE(P ).
Consequently, X X 00 , X 6= X 00 6= X 00 , contradicts fact (X, )
U E(P ). follows U E(P ) = U E(Q).
Examples. Let P = {1{p, q} not(2{p, q})}, Q = {p not(q), q not(p)}.
P Q strongly equivalent. note programs {p}, {q}, {p, q} models.
Furthermore, ({p}, {p}), ({q}, {q}), ({p}, {p, q}), ({q}, {p, q}), ({p, q}, {p, q}) (, {p, q})
SE-models two programs 3 .
Thus, Theorem 1, P Q strongly equivalent.
also observe first five SE-models precisely UE-models P Q. Therefore,
Theorem 2, P Q also uniformly equivalent.
possible two monotone-constraint programs uniformly strongly equivalent.
add rule p P , rule p q Q, two resulting programs, say P 0 Q0 ,
uniformly equivalent. However, strongly equivalent. programs P 0 {q p}
Q0 {q p} different stable models. Another way show observing (, {p, q})
SE-model Q0 SE-model P 0 .
4

4. Fages Lemma
general, supported models stable models logic program (both normal case
monotone-constraint case) coincide. Fages Lemma (Fages, 1994), later extended Erdem
Lifschitz (2003), establishes sufficient condition supported model normal logic program stable. section, show Fages Lemma extends programs
monotone constraints.
3. Lemma 5 Theorem 1, follows SE-models contain atoms At(P ) At(Q)
essential ones.

313

fi
L IU & RUSZCZY NSKI

Definition 5. monotone-constraint program P called tight set At(P ) atoms,
exists mapping ordinals every rule 1 , . . . , Ak , not(Ak+1 ),
. . . , not(Am ) P (M ), X domain
Xi domain Ai , 1 k,
every x X every ki=1 Xi , (a) < (x).
show tightness provides sufficient condition supported model
stable. order prove general result, first establish Horn case.
Lemma 7. Let P Horn monotone-constraint program let supported model P .
P tight , stable model P .
Proof. Let arbitrary supported model P P tight . Let mapping
showing tightness P . show every ordinal every atom x
(x) , x Can(P, ). proceed induction.
basis induction, let us consider atom x (x) = 0. Since
supported model P x , exists rule r P (M ) x hset(r). Moreover,
since P tight , every bd (r) every Dom(A) , (y) < (x) = 0.
Thus, every bd (r), Dom(A) = . Since |= bd (r) since P Horn monotoneconstraint program, follows |= bd (r). Consequently, hset(r) Can(P, ) so,
x Can(P, ).
Let us assume assertion holds every ordinal < let us consider x
(x) = . before, since supported model P , exists rule r P (M )
x hset(r). assumption, P tight and, consequently, every bd (r)
every Dom(A) , (y) < (x) = . induction hypothesis, every bd (r),
Dom(A) Can(P, ). Since P Horn monotone-constraint program, Can(P, ) |=
bd (r). Proposition 3, hset(r) Can(P, ) so, x Can(P, ).
follows Can(P, ). definition canonical computation,
Can(P, ) . Thus, = Can(P, ). Proposition 6, stable model P .
Given lemma, general result follows easily.
Theorem 3. Let P monotone-constraint program let supported model P . P
tight , stable model P .
Proof. One check supported model P , supported model reduct
P . Since P tight , reduct P tight , too. Thus, stable model P
(by Lemma 7) and, consequently, derivable model P (by Proposition 6). follows
stable model P .

5. Logic PLmc Completion Monotone-constraint Program
completion normal logic program (Clark, 1978) propositional theory whose models
precisely supported models program. Thus, supported models normal logic programs
computed means SAT solvers. conditions, instance, assumptions
Fages Lemma hold, supported models stable. Thus, computing models completion
yield stable models, idea implemented first version cmodels software (Babovich &
Lifschitz, 2002).
314

fiP ROPERTIES PPLICATIONS P ROGRAMS ONOTONE C ONVEX C ONSTRAINTS

goal extend concept completion programs monotone constraints.
completion, define it, retains much structure monotone-constraint rules allow
us, restricted setting lparse programs, use pseudo-boolean constraint solvers compute
supported models programs. section define completion prove result
relating supported models programs models completion. discuss extensions
result next section practical computational applications Section 8.
define completion, first introduce extension propositional logic monotone
constraints, formalism denote PLmc . formula logic PLmc expression built
monotone constraints means boolean connectives , (and infinitary counterparts),
. notion model constraint, discussed earlier, extends standard
way class formulas logic PLmc .
set L = {A1 , . . . , Ak , not(Ak+1 ), . . . , not(Am )} literals, define
L = A1 . . . Ak Ak+1 . . . .
Let P monotone-constraint program. form completion P , denoted Comp(P ),
follows:
1. every rule r P include Comp(P ) PLmc formula
[bd (r)] hd (r)
2. every atom x At(P ), include Comp(P ) PLmc formula
_
x {[bd (r)] : r P, x hset(r)}
(we note set rules P infinite, disjunction may infinitary).
following theorem generalizes fundamental result program completion normal
logic programming (Clark, 1978) case programs monotone constraints.
Theorem 4. Let P monotone-constraint program. set At(P ) supported model
P model Comp(P ).
Proof. () Let us suppose supported model P . model P , is,
rule r P , |= bd (r) |= hd (r). Since |= bd (r) |= [bd (r)] ,
follows formulas Comp(P ) first type satisfied .
Moreover, since supported model P , hset(P (M )). is, every atom
x , exists least one rule r P x hset(r) |= bd (r). Therefore,
formulas Comp(P ) second type satisfied , too.
() Let us suppose model Comp(P ). Since |= bd (r) |=
[bd (r)] , since satisfies formulas first type
W Comp(P ), model P .
Let x . W
Since satisfies formula x {[bd (r)] : r P, x hset(r)}, follows
satisfies {[bd (r)] : r P, x hset(r)}. is, r P satisfies
[bd (r)] (and so, bd (r), too) x hset(r). Thus, x hset(P (M )). Hence, supported
model P .
Theorems 3 4 following corollary.
315

fi
L IU & RUSZCZY NSKI

Corollary 5. Let P monotone-constraint program. set At(P ) stable model P
P tight model Comp(P ).
observe material section necessary require constraints
appearing bodies program rules monotone. However, since interested
case, adopted monotonicity assumption here, well.

6. Loops Loop Formulas Monotone-constraint Programs
completion alone quite satisfactory relates supported stable models monotoneconstraint programs models PLmc theories. Loop formulas, proposed Lin Zhao
(2002), provide way eliminate supported models normal logic programs,
stable. Thus, allow us use SAT solvers compute stable models arbitrary normal logic
programs those, supported stable models coincide.
extend idea monotone-constraint programs. section, restrict
considerations programs P finitary, is, At(P ) finite. restriction implies
monotone constraints appear finitary programs finite domains.
Let P finitary monotone-constraint program. positive dependency graph P
directed graph GP = (V, E), V = At(P ) hu, vi edge E exists rule
r P u hset(r) v Dom(A) monotone constraint bd (r) (that is,
appears non-negated bd (r)). note positive dependency graphs finitary programs
finite.
Let G = (V, E) directed graph. set L V loop G subgraph G induced
L strongly connected. loop maximal proper subset loop G.
Thus, maximal loops vertex sets strongly connected components G. maximal loop
terminating edge G L maximal loop.
concepts extended case programs. loop (maximal loop, terminating
loop) monotone-constraint program P , mean loop (maximal loop, terminating loop)
positive dependency graph GP P . observe every finitary monotone-constraint
program P terminating loop, since GP finite.
Let X At(P ). GP [X] denote subgraph GP induced X. observe
X 6= every loop GP [X] loop GP .
Let P monotone-constraint program P . every model P (in particular, every
model Comp(P )), define = \ Can(P , ). Since model P ,
model P . Thus, Can(P , ) well defined .
every loop graph GP define corresponding loop formula. First,
constraint = (X, C) set L At, set A|L = (X, {Y C : L = }) call A|L
restriction L. Next, let r monotone-constraint rule, say
r = A1 , . . . , Ak , not(Ak+1 ), . . . , not(Am ).
L At, define PLmc formula L (r) setting
L (r) = A1 |L . . . Ak |L Ak+1 . . . .
Let L loop monotone-constraint program P . Then, loop formula L, denoted
LP (L), PLmc formula
_
_
LP (L) =
L {L (r) : r P L hset(r) 6= }
316

fiP ROPERTIES PPLICATIONS P ROGRAMS ONOTONE C ONVEX C ONSTRAINTS

(we recall use convention write constraint C(a) = ({a}, {{a}}). loop
completion finitary monotone-constraint program P PL mc theory
LComp(P ) = Comp(P ) {LP (L) : L loop GP }.
following theorem exploits concept loop formula provide necessary sufficient condition model stable model. transfinite one.
Theorem 6. Let P finitary monotone-constraint program. set At(P ) stable model
P model LComp(P ).
Proof. () Let stable model P . supported model P and, Theorem 4,
|= Comp(P ).
Let L loop P . L = |= LP (L). Thus, let us assume L 6= .
Since stable model P , derivable model P , is, = Can(P , ).
Let (Xn )n=0,1,... canonical P -derivation respect (since assume P
finite constraint P finite domain, P -derivations reach results finitely many
steps). Since Can(P , ) L = L 6= , smallest index n Xn L 6= .
particular, follows n > 0 (as X0 = ) L Xn1 = .
Since Xn = hset(P (Xn1 ) Xn L 6= , rule r P (Xn1 )
hset(r) L 6= , is, L hset(r)) 6= . Let r 0 rule P , contributes r
P . Then, every literal not(A) bd (r 0 ), |= not(A). Let bd (r 0 ). bd (r)
so, Xn1 |= A. Since Xn1 L = , Xn1 |= A|L , too, monotonicity A|L , |= A|L .
Thus, |= L (r0 ). Since hset(r 0 ) L 6= , L hset(r)) 6= so, |= LP (L). Thus,
|= LComp(P ).
() Let us consider set At(P ) stable model P .
supported model P 6|= Comp(P ) model LComp(P ). Thus, let us
assume supported model P . follows 6= . Let L terminating
loop GP [M ].
Let r0 arbitrary rule P Lhset(r 0 )) 6= , let r rule obtained r 0
removing negated constraints body. Now, let us assume |= r0 (L). follows
every literal not(A) bd (r 0 ), |= not(A). Thus, r P . Moreover, since L terminating
loop GP [M ], every constraint bd (r 0 ), Dom(A)M L. Since |= A|L , follows
Can(P , ) |= A. Consequently, hset(r 0 ) LW hset(r 0 ) Can(P , ) so,
0
0
0
L Can(P
W, ) 6= , contradiction. Thus, 6|= {r (L) : r P L hset(r )) 6= }.
Since |= L, follows 6|= LP (L) so, 6|= LComp(P ).
following result follows directly proof Theorem 6 provides us way
filter specific non-stable supported models Comp(P ).
Theorem 7. Let P finitary monotone-constraint program model Comp(P ).
empty, violates loop formula every terminating loop G P [M ].
Finally, point that, Theorem 6 hold program P contains infinitely many
rules. counterexample:
Examples. Let P set following rules:
317

fi
L IU & RUSZCZY NSKI

1{a0 } 1{a1 }
1{a1 } 1{a2 }

1{an } 1{an+1 }

Let = {a0 , . . . , , . . .}. supported model P . stable model P
. However, = \ contain terminating loop. problem arises
infinite simple path GP [M ]. Therefore, GP [M ] sink, yet
terminating loop either.
4
results section, concerning program completion loop formulas importantly, loop-completion theorem form basis new software system compute
stable models lparse programs. discuss matter Section 8.

7. Programs Convex Constraints
discuss programs convex constraints, closely related programs
monotone constraints. Programs convex constraints interest involve explicit occurrences default negation operator not, yet expressive programs
monotone-constraints. Moreover, directly subsume essential fragment class lparse
programs (Simons et al., 2002).
constraint (X, C) convex, every W, Y, Z X W Z W, Z C,
C. constraint rule form (1) convex-constraint rule A, 1 , . . . ,
convex constraints = k. Similarly, constraint program built convex-constraint rules
convex-constraint program.
concept model discussed Section 2 applies convex-constraint programs. define
supported stable models convex-constraint programs, view special programs
monotone-constraints.
end, define upward downward closures constraint = (X, C)
constraints A+ = (X, C + ) = (X, C ), respectively,
C + = {Y X : W C, W },
C = {Y X : W C, W }.
note constraint A+ monotone. call constraint (X, C) antimonotone C closed
subset, is, every W, X, C W W C. clear
constraint antimonotone.
upward downward closures allow us represent convex constraint conjunction monotone constraint antimonotone constraint.Namely, following
property convex constraints.
Proposition 8. constraint (X, C) convex C = C + C .
Proof. () Let us assume C = C + C let us consider set 0 00 ,
0 , 00 C. follows 0 C + 00 C . Thus, C + C .
Consequently, C, implies (X, C) convex.
318

fiP ROPERTIES PPLICATIONS P ROGRAMS ONOTONE C ONVEX C ONSTRAINTS

() definitions directly imply C C + C C . Thus, C C + C . Let us
consider C + C . sets 0 , 00 C 0 00 . Since
C convex, C. Thus, C + C C so, C = C + C .
Proposition 8 suggests encoding convex-constraint programs monotone-constraint programs. present it, need notation. constraint = (X, C), call constraint
(X, C), C = P(X) \ C, dual constraint A. denote A. direct consequence definitions constraint monotone dual antimonotone.
Let C convex constraint. set mc(C) = {C} C monotone. set mc(C) =
{not(C)}, C antimonotone. define mc(C) = {C + , not(C )}, C neither monotone
antimonotone. Clearly, C mc(C) models.
Let P convex-constraint program. mc(P ) denote program monotone constraints obtained replacing every rule r P rule r 0
[
hd (r0 ) = hd (r)+ bd (r 0 ) = {mc(A) : bd (r)}
and, hd (r) monotone, also additional rule r 00
hd (r00 ) = (, ) bd (r 00 ) = {hd (r) } bd (r 0 ).
observation above, constraints appearing rules mc(P ) indeed monotone, is,
mc(P ) program monotone constraints.
follows Proposition 8 model P model mc(P ).
extend correspondence supported stable models convex constraint program P
monotone-constraint program mc(P ).
Definition 6. Let P convex constraint program. set atoms supported (or
stable) model P supported (or stable) model mc(P ).
definitions, monotone-constraint programs viewed (almost) directly convexconstraint programs. Namely, note monotone antimonotone constraints convex.
Next, observe monotone constraint, expression not(A) meaning
antimonotone constraint sense every interpretation , |= not(A)
|= A.
Let P monotone-constraint program. cc(P ) denote program obtained P
replacing every rule r form (1) P r 0
[
[
hd (r0 ) = hd (r) bd (r 0 ) = {Ai : = 1, . . . , k} {Aj : j = k + 1, . . . , m}
One show programs P cc(P ) models, supported models stable
models. fact, every monotone-constraint program P P = mc(cc(P )).
Remark. Another consequence discussion default negation operator eliminated syntax price allowing antimonotone constraints using antimonotone
constraints negated literals.
2
Due correspondences established above, one extend convex-constraint
programs concepts results discussed earlier context monotone-constraint programs. many cases, also stated directly language convex-constraints.
319

fi
L IU & RUSZCZY NSKI

important us notions completion loop formulas, lead new
algorithms computing stable models lparse programs. Therefore, discuss
detail.
mentioned, could use Comp(mc(P )) definition completion Comp(P )
convex-constraint logic program P . definition Theorems 9 extends case
convex-constraint programs. However, Comp(mc(P )) involves monotone constraints
negations convex constraints appear P . Therefore, propose another
approach, preserves convex constraints P .
end, first extend logic PLmc convex constraints. extension,
denote PLcc refer propositional logic convex-constraints, formulas
boolean combinations convex constraints. semantics formulas given notion
model obtained extending boolean connectives concept model convex
constraint.
Thus, difference logic PLmc , used define completion
loop completion monotone-convex programs logic PL cc former uses monotone constraints building blocks formulas, whereas latter based convex constraints.
fact, since monotone constraints special convex constraints, logic PL mc fragment
logic PLcc .
Let P convex-constraint program. completion P , denoted
Comp(P ), following set PLcc formulas:
1. every rule r P include Comp(P ) PLcc formula
[bd (r)] hd (r)
(as before, set convex constraints L, L denotes conjunction constraints
L)
2. every atom x At(P ), include Comp(P ) PLcc formula
_
x {[bd (r)] : r P, x hset(r)}
(again, note set rules P infinite, disjunction may infinitary).
One show following theorem.
Theorem 8. Let P convex-constraint program let At(P ). supported
model P model Comp(P ).
Proof. (Sketch) definition, supported model P supported
model mc(P ). matter routine checking Comp(mc(P )) Comp(P )
models. Thus assertion follows Theorem 4.
Next, restrict attention finitary convex-constraint programs, is, programs finite
set atoms, extend class programs notions positive dependency graph
loops. end, exploit representation monotone-constraint program mc(P ). is,
define positive dependency graph, loops loop formulas P positive dependency
graph, loops loop formulas mc(P ), respectively. particular, L loop P
320

fiP ROPERTIES PPLICATIONS P ROGRAMS ONOTONE C ONVEX C ONSTRAINTS

L loop mc(P ) loop formula L, respect convex-constraint program P ,
defined loop formula LP (L) respect program mc(P ) 4 . note since loop
formulas monotone-constraint programs modify non-negated literals bodies rules
leave negated literals intact, seems simple way extend notion loop
formula case convex-constraint program P without making references mc(P ).
define loop completion finitary convex-constraint program P PL cc theory
LComp(P ) = Comp(P ) {LP (L) : L loop P }.
following theorem provides necessary sufficient condition set
atoms stable model convex-constraint program.
Theorem 9. Let P finitary convex-constraint program. set At(P ) stable model
P model LComp(P ).
Proof. (Sketch) Since stable model P stable model mc(P ), Theorem 6 implies stable model P stable model LComp(mc(P )).
matter routine checking LComp(mc(P )) LComp(P ) models.
Thus, result follows.
similar way, Theorem 7 implies following result convex-constraint programs.
Theorem 10. Let P finitary convex-constraint program model Comp(P ).
empty, violates loop formula every terminating loop G P [M ].
emphasize one could simply use LComp(mc(P )) definition loop completion
convex-constraint logic program. However, definition completion component
loop completion retains structure constraints program P , important using
loop completion computation stable models, topic address next section
paper.

8. Applications
section, use theoretical results program completion, loop formulas loop
completion programs convex constraints design implement new method computing stable models lparse programs (Simons et al., 2002).
8.1 Lparse Programs
Simons et al. (2002) introduced studied extension normal logic programming weight
atoms. Formally, weight atom expression
= l[a1 = w1 , . . . , ak = wk ]u,
ai , 1 k propositional atoms, l, u wi , 1 k non-negative integers.
weights wi equal 1, cardinality atom, written l{a1 , . . . , ak }u.
4. one minor simplification one might employ. monotone constraint A, equivalent
antimonotone so, convex. Thus, eliminate operator loop formulas convex-constraint
programs writing instead A.

321

fi
L IU & RUSZCZY NSKI

lparse rule expression form
1 , . . . ,
A, A1 , . . . , weight atoms. refer sets lparse rules lparse programs. Simons
et al. (2002) defined lparse programs semantics stable models.
set atoms model (or satisfies) weight atom l[a1 = w1 , . . . , ak = wk ]u
l

k
X
{wi : ai } u.
i=1

semantics weight atom l[a1 = w1 , . . . , ak = wk ]u identified constraint
(X, C), X = {a1 , . . . , ak }
k
X
{wi : ai } u}.
C = {Y X : l
i=1

notice weights weight atom W non-negative. Therefore, 0 00
00 models W , 0 also model W . follows constraint
(X, C) define convex.
Since (X, C) convex, weight atoms represent class convex constraints lparse programs syntactically class programs convex constraints. relationship extends
stable-model semantics. Namely, Marek Truszczy nski (2004) Marek et al. (2004, 2006)
showed lparse programs encoded programs monotone constraints
concept stable model preserved. transformation used coincides encoding
mc described previous section, restrict latter lparse programs. Thus,
following theorem.
Theorem 11. Let P lparse program. set stable model P according
definition Simons et al. (2002) stable model P according definition
given previous section (when P viewed convex-constraint program).
follows compute stable models lparse programs use results obtained
earlier paper, specifically results program completion loop formulas convexconstraint programs.
Remark. precise, syntax lparse programs general. allows atoms
negated atoms appear within weight atoms. also allows weights negative. However,
negative weights lparse programs treated notational convenience. Specifically,
expression form = w within weight atom (where w < 0) represents expression
not(a) = w (eliminating negative weights way weight atom requires modifications bounds associated weight atom). Moreover, introducing new propositional
variables one remove occurrences negative literals programs. transformations preserve stable models (modulo new atoms). Marek Truszczy nski (2004) Marek et al. (2004,
2006) provide detailed discussion transformation.
addition weight atoms, bodies lparse rules may contain propositional literals (atoms
negated atoms) conjuncts. replace propositional literals weight atoms
322

fiP ROPERTIES PPLICATIONS P ROGRAMS ONOTONE C ONVEX C ONSTRAINTS

follows: atom replaced cardinality atom 1{a}, literal not(a)
cardinality atom {a}0. transformation preserves stable models, too. Moreover,
size resulting program increase constant factor. Thus,
transformations discussed here, monotone- convex-constraint programs capture arbitrary lparse
programs.
2
8.2 Computing Stable Models Lparse Programs
section present algorithm computing stable models lparse programs. method
uses results obtained Section 7 reduce problem computing models
loop completion lparse program. loop completion formula logic PL cc ,
class convex constraints restricted weight constraints, defined previous
subsection. denote fragment logic PLcc consisting formulas PLwa .
make method practical, need programs compute models theories logic
PLwa . show general way adapt task off-the-shelf pseudo-boolean constraint
solvers (Een & Sorensson, 2003; Aloul et al., 2002; Walser, 1997; Manquinho & Roussel, 2005; Liu
& Truszczynski, 2003).
Pseudo-boolean constraints (PB short) integer programming constraints variables 0-1 domains. write inequalities
w1 x1 + . . . + wk xk comp w,

(3)

comp stands one relations , , < >, w w integer coefficients
(not necessarily non-negative), xi integers taking value 0 1. set pseudo-boolean
constraints pseudo-boolean theory.
Pseudo-boolean constraints viewed constraints. basic idea treat 0-1 variable x propositional atom (which denote letter). correspondence,
pseudo-boolean constraint (3) equivalent constraint (X, C), X = {x 1 , . . . , xk }
C = {Y X :

k
X

{wi : xi } comp w}

i=1

sense solutions (3) correspond models (X, C) (x = 1 solution
xi true corresponding model). particular, coefficients w bound w (3)
non-negative, comp = , constraint (3) equivalent monotone lower-bound
weight atom w[x1 = w1 , . . . , xn = wn ].
follows arbitrary weight atom represented one two pseudo-boolean constraints. generally, arbitrary PLwa formula F encoded set PB constraints.
describe translation two-step process.
first step consists converting F clausal form cl (F )5 . control size
translation, introduce auxiliary propositional atoms. Below, describe translation F 7
cl (F ) assumption F formula loop completion lparse program P .
main motivation compute stable models logic programs end algorithms
computing models loop completions sufficient.
5. PLwa clause formula B1 . . . Bm H1 . . . Hn , Bi Hj weight atoms.

323

fi
L IU & RUSZCZY NSKI

Let F formula loop completion lparse-program P . define cl (F ) follows
(in transformation, use propositional atom x shorthand cardinality atom C(x) =
1{x}).
1. F form A1 . . . A, cl (F ) = F
2. F form x ([bd (r1 )] ) . . . ([bd (rl )] ), introduce new propositional
atoms br,1 , . . . , br,l set cl (F ) consist following PLwa clauses:
x br,1 . . . br,l
[bd (ri )] br,i , every bd (ri )
br,i Aj , every bd (ri ) Aj bd (ri )
W
3. F form L r {L (r)}, L set atoms, every L (r) conjunction weight
W atoms, introduce new propositional atoms bdf L,r every L (r) F
represent L weight atom WL = 1[li = 1 : li L]. define cl (F ) consist
following clauses:
_
WL
bdfL,r
W

L (r) bdfL,r , every L (r) F
bdfL,r Aj , every L (r) F Aj L (r).
clear size cl (F ) linear size F .
second step translation, converts PLwa formula C clausal form set
PB constraints, pb (C). define translation C pb (C), let us consider PLwa clause C
form
B1 . . . B H 1 . . . H n ,
(4)
Bi Hi weight atoms.
introduce new propositional atoms b1 , . . . , bm h1 , . . . , hn represent weight atom
clause. noted earlier paper, simply write x weight atoms form 1[x =
1]. new atoms, clause (4) becomes propositional clause b 1 . . . bm h1 . . . hn .
represent following PB constraint:
b1 . . . bm + h1 + . . . + hn 1 m.

(5)

later paper, use symbols denote propositional variables corresponding 0-1 integer variables. context always imply correct meaning symbols.
convention, easy see propositional clause b 1 . . . bm h1 . . . hn
PB constraint (5) models.
introduce next PB constraints enforce equivalence newly introduced atoms
bi (or hi ) corresponding weight atoms Bi (or Hi ).
Let B = l[a1 = w1 , . . . , ak = wk ]u weight atom b propositional atom. split B
B + B introduce two atoms b+ b . model B b, model pseudoboolean constraints following three equivalences: b b + b , b+ B + , b B .
1. first equivalence captured three propositional clauses. Hence following three
PB constraints model equivalence:
b + b+ 0
324

(6)

fiP ROPERTIES PPLICATIONS P ROGRAMS ONOTONE C ONVEX C ONSTRAINTS

b + b 0

(7)

b+ b + b 1

(8)

2. second equivalence, b+ B + , modeled following two PB constraints
(l) b+ +

k
X

(ai wi ) 0

(9)

i=1

(

k
X

wi l + 1) b+ +

k
X

3. Similarly, third equivalence,
k
X

(10)

i=1

i=1

(

(ai wi ) l 1

b



B,

modeled following two PB constraints

wi u) b +

k
X
i=1

i=1

(u + 1) b +

k
X

(ai wi )

k
X

wi

(11)

i=1

(ai wi ) u + 1

(12)

i=1

PLwa

define pb (C),
clause C, set pseudo-boolean constraints (5)
(6), (7), (8), (11), (12), (9), (10) constructed every weight atom occurring C. One verify
size pb (C) linear size C. Therefore, pb (cl (F )) size linear size
F.
special case Bi Hj weight atoms form 1[bi = 1] 1[hj = 1],
need introduce new atoms PB constraints (6), (7), (8), (11), (12), (9), (10).
pb (C) consists single PB constraint (5).
following theorem establishing correctness transformation . proof
theorem straightforward.
Theorem 12. Let F loop completion formula logic PLwa , set atoms,
At(F ). model F PLwa logic unique extension 0
new atoms At(pb (cl (F ))) 0 model pseudo-boolean theory
pb (cl (F )).
note use solvers designed PLwa theories, translation pb longer
needed. benefit using solvers need split weight atoms PL wa
theories need auxiliary atoms introduced pb .
8.2.1 LGORITHM
follow approach proposed Lin Zhao (2002). paper, first compute
completion lparse program. Then, iteratively compute models completion using
PB solver. Whenever model found, test stability. model stable model
program, extend completion loop formulas identified Theorem 10. Often, adding
single loop formula filters several models Comp(P ) stable models P .
results given previous section ensure algorithm correct. present
Figure 1. note may happen worst case exponentially many loop formulas
325

fi
L IU & RUSZCZY NSKI

Input: P lparse program;
pseudo-boolean solver
BEGIN
compute completion Comp(P ) P ;
:= pb (cl (Comp(P )));

(solver finds models )
output stable models found terminate;
:= model found A;
(M stable) output terminate;
compute reduct P P respect ;
compute greatest stable model 0 , contained , P ;
:= \ 0 ;
find terminating loops ;
compute loop formulas convert PB constraints using
pb cl ;
add PB constraints computed previous step ;
(true);
END

Figure 1: Algorithm pbmodels
needed first stable model found determine stable models exist (Lin &
Zhao, 2002). However, problem arises rarely practical situations 6 .
implementation pbmodels supports several PB solvers satzoo (Een & Sorensson,
2003), pbs (Aloul et al., 2002), wsatoip (Walser, 1997). also supports program wsatcc (Liu &
Truszczynski, 2003) computing models PLwa theories. last program used,
transformation, clausal PLwa theories pseudo-boolean theories needed. first
two four programs complete PB solvers. latter two local-search solvers based
wsat (Selman, Kautz, & Cohen, 1994).
output message stable model found first line loop simply
stable models exist since case local-search algorithm, failure find model
completion (extended loop formulas iteration two subsequent ones)
imply models exist.
8.3 Performance
section, present experimental results concerning performance pbmodels. experiments compared pbmodels, combined several PB solvers, smodels (Simons et al., 2002)
cmodels (Babovich & Lifschitz, 2002). focused experiments problems whose state6. fact, many cases programs turn tight respect supported models. Therefore, supported
models stable loop formulas necessary all.

326

fiP ROPERTIES PPLICATIONS P ROGRAMS ONOTONE C ONVEX C ONSTRAINTS

ments explicitly involve pseudo-boolean constraints, designed pbmodels problems
mind.
benchmark problems tried cmodels perform well. one case (vertexcover benchmark) performance cmodels competitive, although even case
best performer. Therefore, report results compiled cmodels.
complete set results obtained experiments refer http://www.cs.uky.edu/
ai/pbmodels.
experiments used instances following problems: traveling salesperson, weighted
n-queens, weighted Latin square, magic square, vertex cover, Towers Hanoi. lparse
programs used first four problems involve general pseudo-boolean constraints. Programs
modeling last two problems contain cardinality constraints only.
Traveling salesperson problem (TSP). instance consists weighted complete graph n
vertices, bound w. edge weights w non-negative integers. solution instance
Hamiltonian cycle whose total weight (the sum weights edges) less
equal w.
randomly generated 50 weighted complete graphs 20 vertices, end, case
assign every edge complete undirected graph integer weight selected uniformly
random range [1..19]. setting w 100 obtained set easy instances, denoted
TSP-e (the bound high enough every instance set solution).
collection graphs, also created set hard instances, denoted TSP-h, setting w 62.
Since requirement total weight stronger, instances set general take
time.
Weighted n-queens problem (WNQ). instance problem consists weighted n n
chess board bound w. weights bound non-negative integers. solution
instance placement n queens chess board two queens attack
weight placement (the sum weights squares queens) greater
w.
randomly generated 50 weighted chess boards size 20 20, chess board
represented set n n integer weights wi,j , 1 i, j n, selected uniformly random
range [1..19]. created two sets instances, easy (denoted wnq-e) hard
(denoted wnq-h), setting bound w 70 50, respectively.
Weighted Latin square problem (WLSQ). instance consists n n array weights w i,j ,
bound w. weights wi,j w non-negative integers. solution instance
n n array L entries {1, . . . , n}
P thatPeach element {1, . . . , n} occurs
exactly row column L, ni=1 nj=1 L[i, j] wi,j w.
set n = 10 randomly generated 50 sets integer weights, selecting uniformly
random range [1..9]. created two families instances, easy (wlsq-e) hard
(wlsq-h), setting w 280 225, respectively.
Magic square problem. instance consists positive integer n. goal construct
n n array using integer 1, . . . n2 entry array exactly way
entries row, column main diagonals sum n(n 2 + 1)/2.
experiments used magic square problem n = 4, 5 6.
Vertex cover problem. instance consists graph n vertices edges, nonnegative integer k bound. solution instance subset vertices graph
k vertices least one end vertex every edge graph subset.
327

fi
L IU & RUSZCZY NSKI

randomly generated 50 graphs, 80 vertices 400 edges. graph, set
k smallest integer vertex cover many elements still exists.
Towers Hanoi problem. slight generalization original problem. considered
case six disks three pegs. instance consists initial configuration disks
satisfies constraint problem (larger disk must top smaller one)
necessarily requires disks one peg. initial configurations selected
31, 36, 41 63 steps away goal configuration (all disks largest
smallest third peg), respectively. also considered standard version problem
seven disks, initial configuration 127 steps away goal.
encoded problems program general syntax lparse, allows
use relation symbols variables (Syrjanen, 1999). programs available http:
//www.cs.uky.edu/ai/pbmodels. used programs combination appropriate instances inputs lparse (Syrjanen, 1999). way, problem
set instances generated family ground (propositional) lparse programs stable
models programs represent solutions corresponding instances problem (if stable models, solutions). used families lparse programs inputs solvers testing. ground programs also available http:
//www.cs.uky.edu/ai/pbmodels.
tests, used pbmodels following four PB solvers: satzoo (Een & Sorensson,
2003), pbs (Aloul et al., 2002), wsatcc (Liu & Truszczynski, 2003), wsatoip (Walser, 1997).
particular, wsatcc deals PLwa theories directly.
experiments run machines 3.2GHz Pentium 4 CPU, 1GB memory, running
Linux kernel version 2.6.11, gcc version 3.3.4. cases, used 1000 seconds
timeout limit.
first show results magic square towers Hanoi problems. Table 1,
solver instance, report corresponding running time seconds. Local-search
solvers unable solve instances two problems included
table.
Benchmark
magic square (4 4)
magic square (5 5)
magic square (6 6)
towers Hanoi (d = 6, = 31)
towers Hanoi (d = 6, = 36)
towers Hanoi (d = 6, = 41)
towers Hanoi (d = 6, = 63)
towers Hanoi (d = 7, = 127)

smodels
1.36
> 1000
> 1000
16.19
32.21
296.32
> 1000
> 1000

pbmodels-satzoo
1.70
28.13
75.58
18.47
31.72
49.90
> 1000
> 1000

pbmodels-pbs
2.41
0.31
> 1000
1.44
1.54
3.12
3.67
22.83

Table 1: Magic square towers Hanoi problems
pbmodels-satzoo pbmodels-pbs perform better smodels programs obtained
instances problems. observe pbmodels-pbs performs exceptionally well
tower Hanoi problem. solver compute plan 7 disks,
requires 127 steps. Magic square Towers Hanoi problems highly regular. problems
328

fiP ROPERTIES PPLICATIONS P ROGRAMS ONOTONE C ONVEX C ONSTRAINTS

TSP-e
TSP-h
wnq-e
wnq-h
wlsq-e
wlsq-h
vtxcov

# SAT instances
50
31
49
29
45
8
50

# UNSAT instances
0
1
0
0
4
41
0

# UNKNOWN instances
0
18
1
21
1
1
0

Table 2: Summary Instances

TSP-e
TSP-h
wnq-e
wnq-h
wlsq-e
wlsq-h
vtxcov
sum

smodels
45/17
7/3
11/5
2/2
21/1
0/0
50/40
136/68

pbmodels-satzoo
50/30
16/14
26/23
0/0
49/29
47/26
50/1
238/123

pbmodels-pbs
18/3
0/0
0/0
0/0
46/19
47/23
47/3
158/48

Table 3: Summary instances
often challenge local-search problems, may explain poor performance observed
pbmodels-wsatcc pbmodels-wsatoip two benchmarks.
remaining four problems, used 50-element families instances, generated randomly way discussed above. studied performance complete solvers
(smodels, pbmodels-satzoo pbmodels-pbs) instances. included local-search
solvers (pbmodels-wsatcc pbmodelswsatoip) comparisons restricted attention
instances determined satisfiable (as local-search solvers are, design, unable decide unsatisfiability). Table 2, family list many instances
satisfiable, unsatisfiable, many instances none solvers tried able
decide satisfiability.
Table 3, seven families instances complete solver, report
two values s/w, number instances solved solver w number
times fastest among three.
results Table 3 show overall pbmodels-satzoo solved instances pbmodelspbs, followed smodels. look number times solver fastest one,
pbmodels-satzoo clear winner overall, followed smodels pbmodels-pbs.
Looking seven families tests individually, see pbmodels-satzoo performed better
two solvers five families. two smodels best performer
(although, clear winner vertex-cover benchmark; solvers essentially
ineffective wnq-h).
also studied performance pbmodels combined local-search solvers wsatcc (Liu
& Truszczynski, 2003) wsatoip (Walser, 1997). study, considered instances seven families knew satisfiable. Table 4 presents results solvers
329

fi
L IU & RUSZCZY NSKI

TSP-e
TSP-h
wnq-e
wnq-h
wlsq-e
wlsq-h
vtxcov
sum

smodels
45/3
7/0
11/0
2/0
21/0
0/0
50/0
136/3

pbmd-satzoo
50/5
16/2
26/0
0/0
45/0
7/0
50/0
194/7

pbmd-pbs
18/2
0/0
0/0
0/0
44/0
8/0
47/0
117/2

pbmd-wsatcc
32/7
19/6
49/45
29/15
45/33
7/1
50/36
231/143

pbmd-wsatoip
47/34
28/22
49/4
29/14
45/14
8/7
50/15
256/110

Table 4: Summary SAT instances
studied (including complete ones). before, entry provides pair numbers s/w,
number solved instances w number times solver performed better
competitors.
results show superior performance pbmodels combined local-search solvers.
solve instances complete solvers (including smodels). addition, significantly
faster, winning much frequently complete solvers (complete solvers faster
12 instances, local-search solvers faster 253 instances).
results demonstrate pbmodels solvers pseudo-boolean constraints outperforms
smodels several types search problems involving pseudo-boolean (weight) constraints).
note also analyzed run-time distributions families instances.
run-time distribution regarded accurate detailed measure performance
algorithms randomly generated instances7 . results consistent summary results
presented confirm conclusions. discussion run-time distributions requires
much space, include analysis here. available website http://www.
cs.uky.edu/ai/pbmodels.

9. Related work
Extensions logic programming means model properties sets (typically consisting
ground terms) extensively studied. Usually, extensions referred common term logic programming aggregates. term comes fact properties
sets practical interest defined aggregate operations sum, count, maximum, minimum average. chose term constraint stress speak abstract
properties define constraints truth assignments (which view sets atoms).
Mumick, Pirahesh, Ramakrishnan (1990), Kemp Stuckey (1991) among
first study logic programs aggregates. Recently, Niemela et al. (1999) Simons et al.
(2002) introduced class lparse programs. discussed formalism detail earlier
paper.
Pelov (2004) Pelov et al. (2006) studied general class aggregates developed systematic theory aggregates logic programming based approximation theory
(Denecker, Marek, & Truszczynski, 2000). resulting theory covers stable models
semantics also supported-model semantics extensions 3-valued Kripke-Kleene
7. Hoos Stutzle (2005) provide detailed discussion matter context local-search methods.

330

fiP ROPERTIES PPLICATIONS P ROGRAMS ONOTONE C ONVEX C ONSTRAINTS

well-founded semantics. formalism introduced studied Pelov (2004) Pelov et al.
(2006) allows arbitrary aggregates (not monotone ones) appear bodies rules.
However, allow aggregates appear heads program clauses. Due differences syntax scope semantics studied simple way relate Pelovs
(2004) Pelov et al.s (2006) formalism programs monotone (convex) constraints.
note though programs abstract monotone constraints heads rules form
C(a) viewed almost literally programs formalism Pelov (2004) Pelov et al.
(2006) stable models according definitions used paper
Pelov (2004) Pelov et al. (2006).
Faber et al. (2004) developed theory disjunctive logic programs aggregates. Similarly
Pelov (2004) Pelov et al. (2006), Faber et al. (2004) allow aggregates appear
heads program clauses. one differences approach programs
monotone (convex) constraints studied here. major difference related
postulate minimality stable models (called answer sets context formalism
considered Faber et al., 2004). keeping spirit original answer-set semantics
(Gelfond & Lifschitz, 1991), answer sets disjunctive programs aggregates, defined
Faber et al. (2004), minimal models. Stable models programs abstract constraints
property. However, class programs abstract monotone constraints
heads rules form C(a) semantics answer sets defined Faber et al. (2004)
coincides semantics stable models Marek Truszczy nski (2004) Marek et al.
(2004, 2006).
Yet another approach aggregates logic programming presented Son Pontelli
(2006). approach considered programs syntax similar programs monotone abstract constraints. allowed arbitrary constraints (not monotone ones) scope
operator. general principle behind definition stable-model semantics Son
Pontelli (2006) view program constraints concise representation set
instances, normal logic program. Stable models program constraints
defined stable models instances quite different operator-based definition
Marek Truszczynski (2004) Marek et al. (2004, 2006). However, programs
monotone constraint atoms fall scope formalism Son Pontelli (2006)
approaches coincide.
also note recently Son et al. (2006) presented conservative extension syntax
proposed Marek Truszczynski (2004) Marek et al. (2006), clauses built
arbitrary constraint atoms.
Finally, point work Ferraris Lifschitz (2004) Ferraris (2005) treats
aggregates nested expressions. particular, Ferraris (2005) introduces propositional logic
certain nonclassical semantics, shows extends several approaches programs
aggregates, including Simons et al. (2002) (restricted core lparse programs) Faber
et al. (2004). nature relationship formalism Ferraris (2005) programs
abstract constraints remains open problem.

10. Conclusions
work shows concepts, techniques results normal logic programming, concerning
strong uniform equivalence, tightness Fages lemma, program completion loop formu331

fi
L IU & RUSZCZY NSKI

las, generalize abstract setting programs monotone convex constraints.
general properties specialize new results lparse programs (with exception characterization strong equivalence lparse programs, first obtained Turner, 2003).
Given results implemented new software pbmodels computing stable models
lparse programs. approach reduces problem computing models theories consisting pseudo-boolean constraints, several fast solvers exist (Manquinho & Roussel,
2005). experimental results show pbmodels PB solvers, especially local search PB
solvers, performs better smodels several types search problems tested. Moreover,
new efficient solvers pseudo-boolean constraints become available (the problem receiving much attention satisfiability integer programming communities), performance
pbmodels improve accordingly.

Acknowledgments
acknowledge support NSF grants IIS-0097278 IIS-0325063. grateful
reviewers useful comments suggestions.
paper combines extends results included conference papers (Liu & Truszczy nski,
2005b, 2005a).

References
Aloul, F., Ramani, A., Markov, I., & Sakallah, K. (2002). PBS: backtrack-search pseudo-boolean solver
optimizer. Proceedings 5th International Symposium Theory Applications
Satisfiability, pp. 346 353.
Babovich, Y., & Lifschitz, V. (2002). Cmodels package.. http://www.cs.utexas.edu/users/
tag/cmodels.html.
Baral, C. (2003). Knowledge representation, reasoning declarative problem solving. Cambridge University Press.
Clark, K. (1978). Negation failure. Gallaire, H., & Minker, J. (Eds.), Logic data bases, pp. 293322.
Plenum Press, New York-London.
DellArmi, T., Faber, W., Ielpa, G., Leone, N., & Pfeifer, G. (2003). Aggregate functions disjunctive logic
programming: semantics, complexity, implementation DLV. Proceedings 18th International Joint Conference Artificial Intelligence (IJCAI-2003), pp. 847852. Morgan Kaufmann.
Denecker, M., Marek, V., & Truszczy
nski, M. (2000). Approximations, stable operators, well-founded fixpoints applications nonmonotonic reasoning. Minker, J. (Ed.), Logic-Based Artificial Intelligence, pp. 127144. Kluwer Academic Publishers.
E
en, N., & Sorensson, N. (2003). extensible SAT solver. Theory Applications Satisfiability
Testing, 6th International Conference, SAT-2003, Vol. 2919 LNCS, pp. 502518. Springer.
Eiter, T., & Fink, M. (2003). Uniform equivalence logic programs stable model semantics.
Proceedings 2003 International Conference Logic Programming, Vol. 2916 Lecture Notes
Computer Science, pp. 224238, Berlin. Springer.
Erdem, E., & Lifschitz, V. (2003). Tight logic programs. Theory Practice Logic Programming, 3(4-5),
499518.
Faber, W., Leone, N., & Pfeifer, G. (2004). Recursive aggregates disjunctive logic programs: Semantics
complexity.. Proceedings 9th European Conference Artificial Intelligence (JELIA
2004), Vol. 3229 LNAI, pp. 200 212. Springer.
332

fiP ROPERTIES PPLICATIONS P ROGRAMS ONOTONE C ONVEX C ONSTRAINTS

Fages, F. (1994). Consistency Clarks completion existence stable models. Journal Methods
Logic Computer Science, 1, 5160.
Ferraris, P. (2005). Answer sets propositional theories. Logic Programming Nonmonotonic Reasoning, 8th International Conference, LPNMR 2005, Vol. 3662 LNAI, pp. 119131. Springer.
Ferraris, P., & Lifschitz, V. (2004). Weight constraints ans nested expressions. Theory Practice Logic
Programming, 5, 4574.
Gelfond, M., & Leone, N. (2002). Logic programming knowledge representation A-prolog perspective. Artificial Intelligence, 138, 338.
Gelfond, M., & Lifschitz, V. (1988). stable semantics logic programs. Proceedings 5th
International Conference Logic Programming, pp. 10701080. MIT Press.
Gelfond, M., & Lifschitz, V. (1991). Classical negation logic programs disjunctive databases. New
Generation Computing, 9, 365385.
Hoos, H., & Stutzle, T. (2005). Stochastic Local Search Algorithms Foundations Applications.
Morgan-Kaufmann.
Kemp, D., & Stuckey, P. (1991). Semantics logic programs aggregates. Logic Programming,
Proceedings 1991 International Symposium, pp. 387401. MIT Press.
Lifschitz, V., Pearce, D., & Valverde, A. (2001). Strongly equivalent logic programs. ACM Transactions
Computational Logic, 2(4), 526541.
Lin, F. (2002). Reducing strong equivalence logic programs entailment classical propositional logic.
Principles Knowledge Representation Reasoning, Proceedings 8th International Conference (KR2002). Morgan Kaufmann Publishers.
Lin, F., & Zhao, Y. (2002). ASSAT: Computing answer sets logic program SAT solvers. Proceedings 18th National Conference Artificial Intelligence (AAAI-2002), pp. 112117. AAAI
Press.
Liu, L., & Truszczy
nski, M. (2003). Local-search techniques propositional logic extended cardinality
atoms. Rossi, F. (Ed.), Proceedings 9th International Conference Principles Practice
Constraint Programming, CP-2003, Vol. 2833 LNCS, pp. 495509. Springer.
Liu, L., & Truszczy
nski, M. (2005a). Pbmodels - software compute stable models pseudoboolean
solvers. Logic Programming Nonmonotonic Reasoning, Proceedings 8th International
Conference (LPNMR-05), LNAI 3662, pp. 410415. Springer.
Liu, L., & Truszczy
nski, M. (2005b). Properties programs monotone convex constraints.
Proceedings 20th National Conference Artificial Intelligence (AAAI-05), pp. 701706. AAAI
Press.
Manquinho, V., & Roussel, O. (2005).
univ-artois.fr/PB05/.

Pseudo boolean evaluation 2005..

http://www.cril.

Marek, V., Niemel
a, I., & Truszczy
nski, M. (2004). Characterizing stable models logic programs
cardinality constraints. Proceedings 7th International Conference Logic Programming
Nonmonotonic Reasoning, Vol. 2923 Lecture Notes Artificial Intelligence, pp. 154166.
Springer.
Marek, V., Niemel
a, I., & Truszczy
nski, M. (2006). Logic programs monotone abstract constraint atoms.
Theory Practice Logic Programming. Submitted.
Marek, V., & Truszczy
nski, M. (2004). Logic programs abstract constraint atoms. Proceedings
19th National Conference Artificial Intelligence (AAAI-04), pp. 8691. AAAI Press.
Mumick, I., Pirahesh, H., & Ramakrishnan, R. (1990). magic duplicates aggregates. Proceedings 16th International Conference Large Data Bases, VLDB 1990, pp. 264277.
Morgan Kaufmann.
333

fi
L IU & RUSZCZY NSKI

Niemel
a, I., Simons, P., & Soininen, T. (1999). Stable model semantics weight constraint rules. Proceedings LPNMR-1999, Vol. 1730 LNAI, pp. 317331. Springer.
Pelov, N. (2004). Semantics logic programs aggregates. PhD Thesis. Department Computer
Science, K.U.Leuven, Leuven, Belgium.
Pelov, N., Denecker, M., & Bruynooghe, M. (2004). Partial stable models logic programs aggregates.
Lifschitz, V., & Niemel
a, I. (Eds.), Logic programming Nonmonotonic Reasoning, Proceedings
7th International Conference, Vol. 2923, pp. 207219. Springer.
Pelov, N., Denecker, M., & Bruynooghe, M. (2006). Well-founded stable semantics logic programs
aggregates. Theory Practice Logic Programming. Accepted (available http://www.
cs.kuleuven.ac.be/dtai/projects/ALP/TPLP/).
Selman, B., Kautz, H., & Cohen, B. (1994). Noise strategies improving local search. Proceedings
12th National Conference Artificial Intelligence (AAAI-1994), pp. 337343, Seattle, USA.
AAAI Press.
Simons, P., Niemel
a, I., & Soininen, T. (2002). Extending implementing stable model semantics.
Artificial Intelligence, 138, 181234.
Son, T., & Pontelli, E. (2006). constructive semantic characterization aggregates anser set programming. Theory Practice Logic Programming. Accepted (available http://arxiv.org/
abs/cs.AI/0601051).
Son, T., Pontelli, E., & Tu, P. (2006). Answer sets logic programs arbitrary abstract constraint atoms.
Proceedings 21st National Conference Artificial Intelligence (AAAI-06). AAAI Press.
Syrj
anen, T. (1999). lparse, procedure grounding domain restricted logic programs. http://www.
tcs.hut.fi/Software/smodels/lparse/.
Turner, H. (2003). Strong equivalence made easy: Nested expressions weight constraints. Theory
Practice Logic Programming, 3, (4&5), 609622.
Walser, J. (1997). Solving linear pseudo-boolean constraints local search. Proceedings 14th
National Conference Artificial Intelligence (AAAI-97), pp. 269274. AAAI Press.

334

fiJournal Artificial Intelligence Research 27 (2006) 55-83

Submitted 10/05; published 09/06

Cognitive Principles Robust Multimodal Interpretation
Joyce Y. Chai
Zahar Prasov
Shaolin Qu

jchai@cse.msu.edu
prasovza@cse.msu.edu
qushaoli@cse.msu.edu

Department Computer Science Engineering
Michigan State University
East Lansing, MI 48824 USA

Abstract
Multimodal conversational interfaces provide natural means users communicate computer systems multiple modalities speech gesture.
build eective multimodal interfaces, automated interpretation user multimodal inputs
important. Inspired previous investigation cognitive status multimodal
human machine interaction, developed greedy algorithm interpreting user
referring expressions (i.e., multimodal reference resolution). algorithm incorporates
cognitive principles Conversational Implicature Givenness Hierarchy applies constraints various sources (e.g., temporal, semantic, contextual) resolve
references. empirical results shown advantage algorithm eciently
resolving variety user references. simplicity generality, approach
potential improve robustness multimodal input interpretation.

1. Introduction
Multimodal systems provide natural eective way users interact computers
multiple modalities speech, gesture, gaze. Since rst appearance
Put-That-There system (Bolt, 1980), number multimodal systems
built, among systems combine speech, pointing (Neal & Shapiro, 1991;
Stock, 1993), gaze (Koons, Sparrell, & Thorisson, 1993), systems integrate speech
pen inputs (e.g., drawn graphics) (Cohen, Johnston, McGee, Oviatt, Pittman, Smith,
Chen, & Clow, 1996; Wahlster, 1998), systems combine multimodal inputs outputs
(Cassell, Bickmore, Billinghurst, Campbell, Chang, Vilhjalmsson, & Yan, 1999), systems
mobile environments (Oviatt, 1999a), systems engage users intelligent
conversation (Gustafson, Bell, Beskow, Boye, Carlson, Edlund, Granstrom, House, & Wiren,
2000; Stent, Dowding, Gawron, Bratt, & Moore, 1999). Earlier studies shown
multimodal interfaces enable users interact computers naturally eectively
(Oviatt, 1996, 1999b).
One important aspect building multimodal systems multimodal interpretation,
process identies meanings user inputs. particular, key element
multimodal interpretation known reference resolution, process nds
proper referents referring expressions. referring expression phrase
given user inputs (most likely speech inputs) refer specic
entity entities. referent entity (e.g., specic object) user refers.
Suppose user points House 6 screen says much one.
c
2006
AI Access Foundation. rights reserved.

fiChai, Prasov, & Qu

case, reference resolution must infer referent House 6 assigned
referring expression one. paper particularly addresses problem reference
resolution multimodal interpretation.
multimodal conversation, way users communicate system depends
available interaction channels situated context (e.g., conversation focus, visual
feedback). dependencies form rich set constraints various aspects (e.g.,
semantic, temporal, contextual). correct interpretation attained
simultaneously considering constraints.
Previous studies shown user referring behavior multimodal conversation
occur randomly, rather follows certain linguistic cognitive principles.
human machine interaction, earlier work shown strong correlations
cognitive status Givenness Hierarchy form referring expressions (Kehler, 2000).
Inspired early work, developed greedy algorithm multimodal reference
resolution. algorithm incorporates principles Conversational Implicature
Givenness Hierarchy applies constraints various sources (e.g., gesture, conversation
context, visual display). empirical results shown promise algorithm
eciently resolving variety user references. One major advantage greedy
algorithm prior linguistic cognitive knowledge used guide
search prune search space constraint satisfaction. simplicity
generality, approach potential improve robustness interpretation
provide practical solution multimodal reference resolution (Chai, Prasov, Blaim,
& Jin, 2005).
following sections, rst demonstrate dierent types referring behavior
observed studies. briey introduce underlying cognitive principles
human-human communication describe principles used computational model eciently resolve multimodal references. Finally, present
experimental results.

2. Multimodal Reference Resolution
previous work (Chai, Hong, & Zhou, 2004b; Chai, Hong, Zhou, & Prasov, 2004),
multimodal conversational system developed users acquire real estate information1 .
Figure 1 snapshot graphical user interface. Users interact interface
speech gesture. Table 1 shows fragment conversation.
fragment, user exhibits dierent types referring behavior. example,
input U1 considered simple input. type simple input one
referring expression spoken utterance one accompanying gesture. Multimodal
fusion combines information speech gesture likely resolve
refers to. second user input (U2 ), accompanying gesture referring
expression explicitly used speech utterance. time, system needs
use conversation context infer object interest house mentioned
previous turn conversation. third user input, multiple referring
expressions multiple gestures. types inputs considered complex inputs.
1. first prototype system developed IBM T. J. Watson Research Center P. Hong,
M. Zhou, colleagues Intelligent Multimedia Interaction group.

56

fiMinimizing Conflicts: Heuristic Repair Method

Figure 1: snapshot multimodal conversational system.

U1
S1
U2
S2
U3
S3

Speech: much cost?
Gesture: point position screen
Speech: price 400K
Graphics: highlight house discussion
Speech: large?
Speech: 2500 square feet
Speech: Compare house one
Gesture: ....circle....cirle (put two consecutive circles screen)
Speech: comparison results
Graphics: show table comparison

Table 1: fragment demonstrating interaction dierent types referring behavior
Complex inputs dicult resolve. need consider temporal relations
referring expressions gestures, semantic constraints specied
referring expressions, contextual constraints prior conversation.
example, case U3 , system needs understand refers house
focus previous turn; house one aligned
two consecutive gestures. subtle variations constraints, including
temporal ordering, semantic compatibility, gesture recognition results lead
dierent interpretations.
example, see multimodal conversation, way user interacts system dependent available input channels (e.g., speech
gesture), also upon his/her conversation goals, state conversation,
multimedia feedback system. words, rich context involves
57

fiChai, Prasov, & Qu

dependencies many dierent aspects established interaction. Interpreting
user inputs situated rich context. example, temporal relations
speech gesture important criteria determine information
two modalities combined. focus attention prior conversation
shapes users refer objects, thus, inuences interpretation referring
expressions. Therefore, need simultaneously consider temporal relations
referring expressions gestures, semantic constraints specied referring expressions, contextual constraints prior conversation. paper,
present ecient approach driven cognitive principles combine temporal,
semantic, contextual constraints multimodal reference resolution.

3. Related Work
Considerable eort devoted studying user multimodal behavior (Cohen, 1984;
Oviatt, 1999a) mechanisms interpret user multimodal inputs (Chai et al., 2004b;
Gustafson et al., 2000; Huls, Bos, & Classen, 1995; Johnston, Cohen, McGee, Oviatt,
Pittman, & Smith, 1997; Johnston, 1998; Johnston & Bangalore, 2000; Kehler, 2000; Koons
et al., 1993; Neal & Shapiro, 1991; Oviatt, DeAngeli, & Kuhn, 1997; Stent et al., 1999; Stock,
1993; Wahlster, 1998; Wu & Oviatt, 1999; Zancanaro, Stock, & Strapparava, 1997).
multimodal reference resolution, early work keeps track focus space
dialog (Grosz & Sidner, 1986) display model capture objects visible
graphical display (Neal, Thielman, Dobes, M., & Shapiro, 1998). checks semantic
constraints type candidate objects referenced properties
reference resolution. modied centering model multimodal reference resolution
also introduced previous work (Zancanaro et al., 1997). idea based
centering movement turns, segments discourse constructed.
discourse entities appearing segment accessible current turn
used constrain referents referring expressions. Another approach introduced
use contextual factors multimodal reference resolution (Huls et al., 1995).
approach, salience value assigned instance based contextual factors.
determine referents multimodal referring expressions, approach retrieves
salient referent satises semantic restrictions referring expressions.
earlier approaches greedy nature, largely dependent semantic
constraints and/or constraints conversation context.
resolve multimodal references, two important issues. First mechanism combine information various sources modalities. second capability obtain best interpretation (among possible alternatives) given set
temporal, semantic, contextual constraints. section, give brief introduction
three recent approaches address issues.
3.1 Multimodal Fusion
Approaches multimodal fusion (Johnston, 1998; Johnston & Bangalore, 2000), although
focus dierent problem overall input interpretation, provide eective solutions
reference resolution. two major approaches multimodal fusion: unication58

fiMinimizing Conflicts: Heuristic Repair Method

based approaches (Johnston, 1998) nite state approaches (Johnston & Bangalore,
2000).
unication-based approach identies referents referring expressions unifying
feature structures generated speech utterances gestures using multimodal grammar (Johnston et al., 1997; Johnston, 1998). multimodal grammar combines
temporal spatial constraints. Temporal constraints encode absolute temporal relations speech gesture (Johnston, 1998),. grammar rules predened
based empirical studies multimodal interaction (Oviatt et al., 1997). example, one
rule indicates speech gesture combined speech either overlaps
gesture follows gesture within certain time frame. unication approach
also process certain complex cases (as long satisfy predened multimodal
grammar) speech utterance accompanied one gesture dierent
types (Johnston, 1998). Using approach accommodate various situations
described Figure 1 require adding dierent rules cope situation.
specic user referring behavior exactly match existing integration rules
(e.g., temporal relations), unication would fail therefore references would
resolved.
nite state approach applies nite-state transducers multimodal parsing
understanding (Johnston & Bangalore, 2000). Unlike unication-based approach
chart parsing subject signicant computational complexity concerns (Johnston
& Bangalore, 2000), nite state approach provides ecient, tight-coupling
multimodal understanding speech recognition. approach, multimodal contextfree grammar dened transform syntax multimodal inputs semantic
meanings. domain-specic semantics directly encoded grammar. Based
grammars, multi-tape nite state automata constructed. automata
used identifying semantics combined inputs. Rather absolute temporal
constraints unication-based approach, approach relies temporal order
dierent modalities. parsing stage, gesture input gesture
tape (e.g., pointing particular person) combined speech expression
speech tape (e.g., person) considered referent expression.
problem approach multi-tape structure takes input speech
gesture incorporate conversation history consideration.
3.2 Decision List
identify potential referents, previous work investigated Givenness Hierarchy (to
introduced later) multimodal interaction (Kehler, 2000). Based data collected
Wizard Oz experiments, investigation suggests users tend tailor
expressions perceive systems beliefs concerning cognitive status
referents prominence (e.g., highlight) display. tailored referring
expressions resolved high accuracy based following decision list:
1. object gestured to, choose object.
2. Otherwise, currently selected object meets semantic type constraints imposed
referring expression, choose object.
59

fiChai, Prasov, & Qu

3. Otherwise, visible object semantically compatible, choose
object.
4. Otherwise, full NP (such proper name) used uniquely identify referent.
studies (Chai, Prasov, & Hong, 2004a), found decision list
following limitations:
Depending interface design, ambiguities (from systems perspective) could
occur. example, given interface one object (e.g., house) sometimes
created top another object (e.g., town), pointing gesture could result
multiple potential objects. Furthermore, given interface crowded objects,
nger point could also result multiple objects dierent probabilities.
decision list able handle ambiguous cases.
User inputs always simple (consisting one referring expression
one gesture indicated decision list). fact, study (Chai et al.,
2004a), found user inputs also complex, consisting multiple referring
expressions and/or multiple gestures. referents referring expressions
could come dierent sources, gesture inputs conversation context.
temporal alignment speech gesture also important determining
correct referent given expression. decision list able handle
types complex inputs.
Nevertheless, previous ndings (Kehler, 2000) inspired work provided
basis algorithm described paper.
3.3 Optimization
Recently, probabilistic approach developed optimizing reference resolution based
graph matching (Chai et al., 2004b). graph-matching approach, information
gathered multiple input modalities conversation context represented
attributed relational graphs (ARGs) (Tsai & Fu, 1979). Specically, two graphs used.
One graph represents referring expressions speech utterances (i.e., called referring
graph). referring graph contains referring expressions used speech utterance
relations expressions. node corresponds one referring expression
consists semantic temporal information extracted expression.
edge represents semantic temporal relation two referring expressions.
resulting graph fully connected, undirected, graph. example, shown
Figure 2(a), speech input compare house, green house, brown one,
three nodes generated referring graph representing three referring expressions.
node contains semantic temporal features related corresponding referring
expression. include expressions semantic type (house, town, etc.), number
potential referents, type dependent features (size, price, etc.), syntactic category
expression, timestamp expression produced. edge contains
features describing semantic temporal relations pair nodes. semantic
features simply indicate whether two nodes share semantic type
60

fiMinimizing Conflicts: Heuristic Repair Method

Figure 2: Reference resolution probabilistic graph-matching

inferred utterance. Otherwise, semantic type relation deemed
unknown. temporal features indicate two expressions uttered rst.
Similarly, another graph represents potential referents gathered gestures, history, visual display (i.e., called referent graph). node referent graph
captures semantic temporal information potential referent, together
selection probability. selection probability particularly applied objects indicated gesture. gesture pointing circle potentially introduce
ambiguity terms intended referents, selection probability used indicate
likely object selected particular gesture. selection probability
derived function distance location entity focus point
recognized gesture display. referring graph, edge referent
graph captures semantic temporal relations two potential referents
whether two referents share semantic type temporal order
two referents introduced discourse. example, since gesture input
consists two pointings, referent graph (Figure 2b) consists potential referents
two pointings. objects rst dashed rectangle potential referents
selected rst pointing, second dashed rectangle correspond
second pointing. Furthermore, salient objects prior conversation also included referent graph since could potential referents well (e.g.,
rightmost dashed rectangle Figure 2b).
Given graph representations, reference resolution problem becomes probabilistic graph-matching problem (Gold & Rangarajan, 1996). goal nd match
referring graph Gs referent graph Gc 2 achieves maximum
compatibility (i.e., maximizes Q(Gc , Gs )) described following equation:
2. subscription Gs refers speech referring expressions c Gc refers candidate referents.

61

fiChai, Prasov, & Qu

Q(Gc , Gs ) =


(x , )N odeSim(x , )
x
P




+

x





n P (x , )P (y , n )EdgeSim(xy , mn )

(1)

P (x , ) matching probability referent node x referring node
. overall compatibility Q(Gc , Gs ) depends node compatibility N odeSim
edge compatibility EdgeSim, dened temporal semantic
constraints (Chai et al., 2004). algorithm converges, P (x , ) gives matching
probabilities referent node x referring node maximizes overall
compatibility function. Using matching probabilities, system able identify
probable referent x referring node . Specically, referring expression
matches potential referent assigned referent probability match
exceeds empirically computed threshold. threshold met, referring
expression remains unresolved.
Theoretically, approach provides solution maximizes overall satisfaction
semantic, temporal, contextual constraints. However, like many optimization
approaches, algorithm non-polynomial. relies expensive matching process,
attempts every possible assignment, order converge optimal interpretation
based constraints. However, previous linguistic cognitive studies indicate
user language behavior occur randomly, rather follows certain cognitive principles. Therefore, question arises whether knowledge cognitive principles
used guide matching process reduce complexity.

4. Cognitive Principles
Motivated previous work (Kehler, 2000), specically focus two principles: Conversational Implicature Givenness Hierarchy.
4.1 Conversational Implicature
Grices Conversational Implicature Theory indicates interpretation inference
utterance communication guided set four maxims (Grice, 1975). Among
four maxims, Maxim Quantity Maxim Manner particularly useful
purpose.
Maxim Quantity two components: (1) make contribution informative required (for current purposes exchange), (2) make
contribution informative required. context multimodal conversation,
maxim indicates users generally make unnecessary gestures speech
utterances. especially true pen-based gestures since usually require special
eort user. Therefore, pen-based gesture intentionally delivered user,
information conveyed often crucial component used interpretation.
Grices Maxim Manner four components: (1) avoid obscurity expression, (2)
avoid ambiguity, (3) brief, (4) orderly. maxim indicates users
intentionally make ambiguous references. use expressions (either speech
gesture) believe uniquely describe object interest listeners (in
case computer system) understand. expressions choose depend
62

fiMinimizing Conflicts: Heuristic Repair Method

Status
Expression Form
f ocus


Activated
that, this, N

F amiliar
N

U nique identif iable
N

Ref erential
indef inite N

Identif iable

Figure 3: Givenness Hierarchy

information mental models current state conversation. However,
information users mental model might dierent information system
possesses. information gap happens, dierent ambiguities could occur
system point view. fact, ambiguities intentionally caused
human speakers, rather systems incapability choosing among alternatives
given incomplete knowledge representation, limited capability contextual inference,
factors (e.g., interface design issues). Therefore, system anticipate
deliberate ambiguities users (e.g., user utters house refer particular
house screen), rather focus dealing types ambiguities
caused systems limitations (e.g., gesture ambiguity due interface design
speech ambiguity due incorrect recognition).
two maxims help positioning role gestures reference resolution.
particular, maxims put potential referents indicated gesture
important position, described Section 5.
4.2 Givenness Hierarchy
Givenness Hierarchy proposed Gundel et al. explains dierent determiners
pronominal forms signal dierent information memory attention state (i.e.,
cognitive status) (Gundel, Hedberg, & Zacharski, 1993). Figure 3, six
cognitive statuses hierarchy. example, focus indicates highest attentional
state likely continue topic. Activated indicates entities short term
memory. statuses associated forms referring expressions.
hierarchy, cognitive status implies statuses list. example, focus
implies Activated, Familiar, etc. use particular expression form signals
associated cognitive status met, also signals lower statuses
met. words, given form used describe lower status also used
refer higher status, vice versa. Cognitive statuses necessary conditions
63

fiChai, Prasov, & Qu

appropriate use dierent forms referring expressions. Gundel et al. found dierent
referring expressions almost exclusively correlate six statuses hierarchy.
Givenness Hierarchy investigated earlier algorithms resolving pronouns demonstratives spoken dialog systems (Eckert & Strube, 2000; Byron, 2002)
multimodal interaction (Kehler, 2000). particular, would like extend previous work (Kehler, 2000) investigate whether Conversational Implicature Givenness Hierarchy used resolve variety references simple complex,
precise ambiguous. Furthermore, decision list used Kehler (2000) proposed based data analysis implemented evaluated real-time
system. Therefore, second goal design implement ecient algorithm
incorporating cognitive principles empirically compare performance
optimization approach (Chai et al., 2004), nite state approach (Johnston & Bangalore,
2000), decision list approach (Kehler, 2000).

5. Greedy Algorithm
greedy algorithm always makes choice looks best moment processing.
is, makes locally optimal choice hope choice lead globally optimal solution. Simple ecient greedy algorithms used approximate
many optimization problems. explore use Conversational Implicature
Givenness Hierarchy designing ecient greedy algorithm. particular, extend
decision list Kehler (2000) utilize concepts two cognitive principles
following way:
Corresponding Givenness Hierarchy, following hierarchy holds potential
referents: F ocus > V isible. hierarchy indicates objects focus higher
status terms attention states objects visual display. Focus
corresponds cognitive statuses focus Activated Givenness Hierarchy,
Visible corresponds statuses Familiar Uniquely identifiable. Note
Givenness Hierarchy ne grained terms dierent statuses. application
may able distinguish dierence statuses (e.g., focus
Activated) eectively use them. Therefore, Focus Visible introduced
group similar statuses (with respect application) together. Since
need dierentiate objects mentioned recently (e.g.,
focus activated) objects accessible either graph display
domain model (e.g., familiar unique identiable), assign
dierent modied statuses (e.g., Focus Visible).
Based Conversational Implicature, since pen-based gesture takes special effort deliver, must convey certain useful information. fact, objects indicated
gesture highest attentional state since deliberately singled
user. Therefore, combining (1) (2), derive modied hierarchy
Gesture > F ocus > V isible > Others. Others corresponds indenite cases
Givenness Hierarchy. modied hierarchy coincides processing order
Kehlers decision list (2000). modied hierarchy guide greedy
64

fiMinimizing Conflicts: Heuristic Repair Method

algorithm search solutions. Next, describe detail algorithm
related representations functions.
5.1 Representation
turn3 (i.e., receiving user input) conversation, use three vectors
represent rst three statuses modied hierarchy: objects selected gesture,
objects focus, objects visible display follows:
Gesture vector (g ) captures objects selected series gestures. element gi
object potentially selected gesture. elements gi gj < j,
gesture selects objects gi should: 1) temporally precede gesture selects
gj 2) gesture selects gj since one gesture could result
multiple objects.
Focus vector (f) captures objects focus selected
gesture. element represents object considered focus attention
previous turn conversation. temporal precedence relation
elements. consider corresponding objects simultaneously
accessible current turn conversation.
captures objects visible display neither
Display vector (d)
selected gesture (i.e., g) focus (f). also temporal precedence relation elements. elements simultaneously accessible.
Based representations, object domain interest belongs either
one vectors Others. object vectors consists
following attributes:
Semantic type object. example, semantic type could House
Town.
attributes object. domain dependent feature. set attributes
associated semantic type. example, house object Price, Size,
Year Built, etc. attributes. Furthermore, object visual properties
reect appearance object display Color object icon.
identier object. object unique name.
selection probability. refers probability given object selected.
Depending interface design, gesture could result list potential referents.
use selection probability indicate likelihood object selected
gesture. calculation selection probability described later. objects
focus vector display vector, selection probabilities set 1/N
N total number objects respective vector.
3. Currently, user inactivity (i.e., 2 seconds input either speech gesture) used
boundary decide interaction turn.

65

fiChai, Prasov, & Qu

Temporal information. relative temporal ordering information corresponding gesture. Instead applying time stamps previous work (Chai et al.,
2004b), use index gestures according order occurrences. object selected rst gesture, temporal information
would 1.
addition vectors capture potential referents, user input, vector
represents referring expressions speech utterance (r) also maintained.
element (i.e., referring expression) following information:
identier potential referent indicated referring expression.
example, identier potential referent expression house number eight
house object identier Eight.
semantic type potential referents indicated expression. example,
semantic type referring expression house House.
number potential referents indicated referring expression
utterance context. example, singular noun phrase refers one object.
phrase like three houses provides exact number referents (i.e., 3).
Type dependent features. features associated potential referents,
Color Price, extracted referring expression.
temporal ordering information indicating order referring expressions
uttered. Again, instead specic time stamp, use
temporal ordering information. utterance consists N consecutive referring
expressions, temporal ordering information would 1, 2,
N .
syntactic categories referring expressions. Currently, referring
expression, assign one six syntactic categories (e.g., demonstrative
pronoun). Details explained later.
four vectors updated user turn conversation based current
user input system state (e.g., shown screen identied
focus previous turn conversation).
5.2 Algorithm
ow chart pseudo code algorithm shown Figure 4.
multimodal input particular turn conversation, algorithm takes inputs
vector (r) referring expressions size k, gesture vector (g ) size m, focus
size l. rst creates three matrices
vector (f ) size n, display vector (d)
G[i][j], F [i][j], D[i][j] capture scores matching referring expression
r object three vectors. Calculation matching score described later.
Note that, g ,f, empty, corresponding matrix (i.e., G, F ,
D) empty.
66

fiMinimizing Conflicts: Heuristic Repair Method

InitializeMatchMatrix (,,,){
(i = 1..m; j = 1..k) G[i][j] = Match(gi, rj)
(i = 1..n; j = 1..k) F[i][j] = Match(fi, rj)
(i = 1..l; j = 1..k) D[i][j] = Match(di, rj)
}

Yes

G empty


GreedySortingGesture {
index_max = 1; //index column
(i = 1..m) {
find j index_max, G[i][j] largest among elements row i.
add mark * G[i][j];
index_max = j; } //complete finding best match view object
AssignReferentsFromMatrix (G);
}

references resolved?



Yes

Yes
F empty



Return results

GreedySortingFocus{
(j = 1..k)
(rj resolved)
Cross column j F //only keep ones resolved
( = 1..n){
find j F[i][j] largest among elements row i.
mark * F[i][j]; }
AssignReferentsFromMatrix (F);
}

references resolved?



GreedySortingDisplay{
(j = 1..k)
(rj resolved)
Cross column j D;
( = 1..l){
find j D[i][j] largest among elements row i.
mark * D[i][j]; }
AssignReferentsFromMatrix (D);
}

Return results

AssignReferentsFromMatrix (Matrix X){
(i = 1..k) // i.e., expression ri column
(ri indicates specific number N N elements
ith column X *)
assign N largest elements * ri referents.
else assign elements * ri referents;
}

Figure 4: greedy algorithm multimodal reference resolution

67

Yes

Return results

fiChai, Prasov, & Qu

Based matching scores three matrices, algorithm applies greedy
search guided modied hierarchy described earlier. Since Gesture
highest status, algorithm rst searches Gesture Matrix (G) keeps track
matching scores referring expressions objects gestures. identies
highest (or multiple highest) matching scores assigns possible objects
gestures expressions (GreedySortingGesture).
referring expressions left resolved gestures processed,
algorithm looks objects Focus Matrix (F ) since Focus next highest cognitive status (GreedySortingFocus). still expressions resolved,
algorithm looks objects Display Matrix (D) (GreedySortingDisplay). Currently,
algorithm focuses three statuses. Certainly, still expressions
resolved steps, algorithm consult proper name resolution.
referring expressions resolved, system output results.
next multimodal input, system generate four new vectors apply greedy
algorithm again.
Note GreedySortingGesture, use index-max keep track column index
corresponds largest matching value. algorithm incrementally processes
row matrix, index-max incrementally increase. referring expressions gesture aligned according order occurrences.
Since objects Focus Matrix Display Matrix temporal precedence
relations, GreedySortingFocus GreedySortingDisplay use constraint.
reason call algorithm greedy always nds best assignment
referring expression given cognitive status hierarchy. words, algorithm
always makes best choice referring expression one time according
order occurrence utterance. One imagine mistaken assignment
made expression aect assignment following expressions. Therefore,
greedy algorithm may lead globally optimal solution. Nevertheless, general
user behavior following guiding principles makes greedy algorithm useful.
One major advantage greedy algorithm use modied hierarchy signicantly prune search space compared graph-matching approach.
Given referring expressions n potential referents various sources (e.g., gesture,
conversation context, visual display), algorithm nd solution O(mn).
Furthermore, algorithm goes beyond simple precise inputs illustrated
decision list Kehler (2000). scoring mechanism (described later) greedy
sorting process accommodate complex ambiguous user inputs.
5.3 Matching Functions
important component algorithm matching score object (o)
referring expression (e). use following equation calculate matching score:
atch(o, e) = [



P (o|S) P (S|e)] Compatibility(o, e)

(2)

S{G,F,D}

formula, represents possible associated status object o. could
three potential values: G (representing Gesture), F (Focus), (Display).
function determined three components:
68

fiMinimizing Conflicts: Heuristic Repair Method

rst, P (o|S), object selectivity component measures probability
object referent given status (S) object (i.e., gesture, focus,
visual display).
second, P (S|e), likelihood status component measures likelihood
status potential referent given particular type referring expression.
third, Compatibility(o, e), compatibility component measures
semantic temporal compatibility object referring expression
e.
Next explain three components detail.
5.3.1 Object Selectivity
calculate P (o|S = Gesture), use function takes consideration
distance object focus point gesture display (Chai et al.,
2004b).
Given object Focus (i.e., selected gesture), P (o|S = F ocus) = 1/N ,
N total number objects Focus vector. object neither
selected gesture, focus, visible screen, P (o|S = Display) =
1/M , total number objects Display vector. Currently,
applied simplest uniform distribution objects focus graphical
display. future, intend incorporate recency conversation discourse
model P (o|S = F ocus) use visual prominence (e.g., based visual characteristics)
model P (o|S = Display). Note that, discussed earlier Section 5.1, object
associated one three statuses. words, given object o,
one P (o|S = Gesture), P (o|S = F ocus), P (o|S = Display) non-zero.
5.3.2 Likelihood Status
Motivated Givenness Hierarchy earlier work (Kehler, 2000) form
referring expressions reect cognitive status referred entities users mental
model, use likelihood status measure probability reected status given
particular type referring expression. particular, use data reported Kehler
(2000) derive likelihood status potential referents given particular type
referring expression P (S|e). categorize referring expressions following six
categories:
Empty: referring expression used utterance.
Pronouns: it, they,
Locative adverbs:
Demonstratives: this, that, these,
Denite Noun Phrases: noun phrases denite article
Full noun phrases: types proper nouns.
69

fiChai, Prasov, & Qu

P (S|E)
Visible
Focus
Gesture
Sum

Empty
0
0.56
0.44
1

Pronoun
0
0.85
0.15
1

Locative
0
0.57
0.43
1

Demonstratives
0
0.33
0.67
1

Definite
0
0.07
0.67
1

Full
0
0.47
0.16
1

Table 2: Likelihood status referents given particular type expression
Table 2 shows estimated P (S|e). Note that, original data provided Kehler
(2000), zero count certain combination referring type referent status.
zero counts result zero probability table. use smoothing
techniques re-distribute probability mass. Furthermore, probability mass
assigned status Others.
5.3.3 Compatibility Measurement
term Compatibility(o, e) measures compatibility object referring
expression e. Similar compatibility measurement earlier work (Chai et al.,
2004), dened multiplication many factors following equation:
Compatibility(o, e) = Id(o, e) Sem(o, e)



Attrk (o, e) emp(o, e)

(3)

k

equation:
Id(o, e) captures compatibility identier (or name) identier
(or name) specied e. indicates identier potential referent,
expressed referring expression, match identier true referent.
particularly useful resolving proper nouns. example, referring
expression house number eight, correct referent identier
number eight. Id(o, e) = 0 identities e dierent. Id(o, e) = 1
identities e either one/both unknown.
Sem(o, e) captures semantic type compatibility e. indicates
semantic type potential referent expressed referring expression
match semantic type correct referent. Sem(o, e) = 0 semantic types
e dierent. Sem(o, e) = 1 unknown.
Attrk (o, e) captures type-specic constraint concerning particular semantic feature
(indicated subscript k). constraint indicates expected features
potential referent expressed referring expression compatible
features associated true referent. example, referring expression
Victorian house, style feature Victorian. Therefore, object
possible referent style object Victorian. Thus, dene following:
Attrk (o, e) = 0 e feature k values feature k
equal. Otherwise, Attrk (o, e) = 1.
70

fiMinimizing Conflicts: Heuristic Repair Method

(House 3
(House 9 (House 1
Town 1)
Town 2) Town 2)
Gesture input: ... ..i..i...i
Speech input: Compare houses.
Time

Figure 5: example complex input

emp(o, e) captures temporal compatibility e. consider temporal ordering speech gesture. Specically, temporal
compatibility dened following:
emp(o, e) = exp(|OrderIndex(o) OrderIndex(e)|)

(4)

order speech accompanying gestures occur important
deciding gestures aligned referring expressions.
order accompanying gestures introduced discourse
consistent order corresponding referring expressions
uttered. example, suppose user input consists three gestures g1 , g2 , g3
two referring expressions, s1 , s2 . possible g3 align s1
g2 align s2 . Note that, status object either Focus Visible,
emp(o, e) = 1. denition temporal compatibility dierent
function used previous work (Chai et al., 2004) takes real time stamps
consideration. Section 6.2 shows dierent performance results based dierent
temporal compatibility functions.
5.4 Example
Figure 5 shows example complex input involves multiple referring expressions
multiple gestures. interface displays house icons top town icons,
point (or circle) could result house town object. example, rst
gesture results House 3 Town 1. second gesture results House 9
Town 2, third results House 1 Town 2. Suppose input takes
place, House 8 highlighted screen previous turn conversation (i.e.,
House 8 focus). Furthermore, eight objects visible screen.
resolve referents expressions houses, greedy algorithm takes
following steps:
r created lengths 6, 1, 8, 2, respectively
1. four input vectors, g ,f, d,
represent six objects gesture vector, one object focus, eight objects
graphical display, two referring expressions used utterance.
2. Gesture Matrix G62 , Focus Matrix F12 , Display Matrix D82 created.
3. three matrixes initialized Equation 2. Figure 6 shows resulting
Gesture Matrix. probability values P (S|e) come Table 2. dierence
71

fiChai, Prasov, & Qu

Status
(G)

Referring Expression Match

Potential
Referent

j = 1:



j = 2: houses

1 0.15 1 = 0.15

= 1: House 3

1 0.67 0.37 = 0.25*

Gesture 1
= 2: Town 2

1 0.15 0 = 0

1 0.67 0 = 0

= 3: House 9

1 0.15 0.37 = 0.055

1 0.67 1 = 0.67*

= 4: Town 2

1 0.15 0 = 0

1 0.67 0 = 0

Gesture 2
= 5: House 1

1 0.15 0.14 = 0.02

1 0.67 0.37 = 0.25*

= 6: Town 2

1 0.15 0 = 0

1 0.67 0 = 0

Gesture 3

(a) Gesture Matrix
Status
(F)

Potential
Referent

Referring Expression Match

Focus

= 1: House 8

j = 1:



j = 2: houses

1 0.85 1= 0.85*

(b) Focus Matrix

Figure 6: Gesture Matrix (a) Focus Matrix (b) processing example Figure 5.
cell Referring Expression Match columns corresponds instantiation
matching function.

compatibility values house objects Gesture Matrix mainly due
temporal ordering compatibilities.
4. Next GreedySortingGesture procedure executed. row Gesture Matrix, algorithm nds largest legitimate value marks corresponding cell
*. legitimate means corresponding cell row + 1
either column column right corresponding cell
row i. values shown bold Figure 6(a). Next, starting
column, algorithm checks referring expression whether exists
corresponding column. so, objects assigned referring
expressions based number constraints. case, since specic number
given referring expression houses, three marked objects assigned
houses.
5. houses, still left resolved. algorithm continues
execute GreedySortingFocus. Focus Matrix prior executing GreedySortingFocus
shown Figure 6(b). Note since houses longer considered,
corresponding column deleted Focus Matrix. Similar previous step,
largest non-zero match value marked (shown bold Figure 6(b)) assigned
remaining referring expression it.
6. resulting Display Matrix shown point, referring expressions resolved.
72

fiMinimizing Conflicts: Heuristic Repair Method

s1 : the(adj) (N |N s)
s2 : (this|that)(adj )N
s3 : (these|those)(num+ )(adj )N
s4 : it|this|that|(this|that|the)adj one
s5 : (these|those)num+ adj ones|them
s6 : here|there
s7 : empty expression
s8 : proper nouns
s9 : multiple expressions
Total Num:

g1

gest.
2
4
0
3
0
1
1
1
1
13

g2
one
pt
8
43
0
8
0
1
1
5
0
66

g3
mult.
pts
0
3
0
0
0
0
0
3
4
10

g4
one
cir
2
33
31
10
2
5
1
3
11
98

g5
mult.
cirs
0
1
0
0
0
0
0
0
13
14

g6
pts &
cirs
1
7
5
0
0
0
0
3
2
18

Total
Num
13
91
36
21
2
7
3
15
31
219

Table 3: Detailed description user referring behavior

6. Evaluation
use data collected previous work (Chai et al., 2004) evaluate greedy
algorithm. questions addressed evaluation following:
impact temporal alignment speech gesture performance greedy algorithm?
role modeling cognitive status greedy algorithm?
eective greedy algorithm compared graph matching algorithm
(Section 3.3)?
error sources contribute failure real-time reference resolution?
greedy algorithm compared nite state approach (Section 3.1)
decision list approach (Section 3.2)?
6.1 Experiment Setup
evaluation data collected eleven subjects participated study.
subjects asked interact system using speech gestures
(e.g., pointing circle) accomplish tasks related real estate information seeking.
rst task nd least expensive house populated town. order
accomplish task, user would rst nd town highest
population nd least expensive house town. next task involved
obtaining description house located previous task. next task
compare house located rst task houses particular
town terms price. Additionally, least expensive house second town
determined. Another task nd expensive house particular town.
73

fiChai, Prasov, & Qu

S0 : referring expression
S1 : One referring expression
S2 : Multiple referring expressions
Total Num:

G0 :
Gesture
1 (a)
11 (a)
1 (c)
13

G1 : One
Gesture
2 (a)
151 (b)
11 (c)
164

G2 : MultiGesture
0 (c)
23 (c)
19 (c)
42

Total
Num
3
185
31
219

Table 4: Summary user referring behavior
last task involved comparing resulting houses previous four tasks.
last task, previous four tasks may completely partially repeated.
tasks designed users required explore interface acquire various
types information.
acoustic model subject trained individually minimize speech recognition errors. study session videotaped capture audio video
screen movement (including gestures system responses). IBM Viavoice speech
recognizer used process speech input.
Table 3 provides detailed description referring behavior observed study.
columns indicate whether gesture, one gesture (pointing circle), multiple gestures involved multimodal input. rows indicate type referring expressions
speech utterance. table entry shows number particular combination
speech gesture inputs.
Table 4 summarizes Table 3 terms whether gesture, one gesture, multiple
gestures (shown columns) whether referring expression, one referring expression,
multiple referring expressions (shown rows) involved input. Note
table intended input counted one input even input may split
turns system run time.
Based Table 4, categorize user inputs following three categories:
Simple Inputs One-Zero Alignment: inputs contain speech referring
expression gesture (i.e.,< S0 , G0 >), one referring expression zero gesture
(i.e.,< S1 , G0 >), referring expression one gesture (i.e., < S0 , G1 >).
types inputs require conversation context visual context resolve
references. One example type U2 Table 1. data, total
14 inputs belong category (marked (a) Table 4).
Simple Inputs One-One Alignment: inputs contain exactly one referring
expression one gesture (i.e., < S1 , G1 >). types inputs resolved
mostly combining gesture speech using multimodal fusion. total 151
inputs belong category (marked (b) Table 4).
Complex Inputs: inputs contain one referring expression and/or gesture. corresponds entry < S1 , G2 >, < S2 , G0 >,< S2 , G1 >,
< S2 , G2 > Table 4. One example type U3 Table 1. total 54
74

fiMinimizing Conflicts: Heuristic Repair Method

No. Correctly Resolved
Simple One-Zero Alignment
Simple One-One Alignment
Complex
Total
Accuracy

Ordering
5
104
24
133
60.7%

Absolute
5
104
19
128
58.4%

Combined
5
104
23
132
60.3%

Table 5: Performance comparison based dierent temporal compatibility functions
inputs belong category (marked (c) Table 4). types inputs
particularly challenging resolve.
section, focus dierent performance evaluations based three
types referring behaviors.
6.2 Temporal Alignment Speech Gesture
multimodal interpretation, align speech gesture based temporal
information important question. especially case complex inputs
multimodal input consists multiple referring expressions multiple gestures.
evaluated dierent temporal compatibility functions greedy approach. particular,
compared following three functions:
ordering temporal constraint Equation 4.
absolute temporal constraint dened following formula:
emp(o, e) = exp(|BeginT ime(o) BeginT ime(e)|)

(5)

Here, absolute timestamps potential referents (e.g., indicated gesture)
referring expressions used instead relative orders relevant entities
user input.
combined temporal constraint combines two aforementioned constraints,
giving equal weight determining compatibility score object
referring expression.
results shown Table 5. Dierent temporal constraints aect processing complex inputs. ordering temporal constraint worked slightly better
absolute temporal constraint. fact, temporal alignment speech gesture often one problems may aect interpretation results. Previous studies found
gestures tend occur corresponding speech unit takes place (Oviatt et al.,
1997). ndings suggest users tend tap screen rst start
speech utterance. behavior observed simple command based system (Oviatt
et al., 1997) speech unit corresponds single gesture (i.e., simple inputs
work).
75

fiChai, Prasov, & Qu

Non-overlap
Overlap
Total :

Speech First
7%
8%
15%

Gesture First
45%
40%
85%

Total
52%
48%
100%

Table 6: Overall temporal relations speech gesture

study, found temporal alignment gesture corresponding
speech units still issue needs investigated order improve
robustness multimodal interpretation. Table 6 shows percentage dierent
temporal relations observed study. rows indicate whether overlap
speech referring expressions accompanied gestures. columns indicate
whether speech (more precisely, referring expressions) gesture occurred rst.
Consistent previous ndings (Oviatt et al., 1997), cases (85% time),
gestures occurred referring expressions uttered. However, 15% cases
speech referring expressions uttered corresponding gesture occurred.
Among cases, 8% overlap referring expressions gesture
7% overlap.
Furthermore, although multimodal behaviors sequential (i.e., non-overlap)
simultaneous (e.g., overlap) integration quite consistent course interaction (Oviatt, Coulston, Tomko, Xiao, Bunsford, Wesson, & Carmichael, 2003),
exceptions. Figure 7 shows temporal alignments individual users study.
User 2 , User 6, User 8 maintained consistent behavior User 2s gesture always
happened overlapped corresponding speech referring expressions; User
6s gesture always occurred ahead speech expressions without overlapping; User
8s speech referring expressions always occurred corresponding gestures (without
overlap). users exhibited varied temporal alignment speech
gesture interaction. dicult system using pre-dened temporal
constraints anticipate accommodate dierent behaviors. Therefore,
desirable mechanism automatically learn user behavior alignment
automatically adjust behavior.
One potential approach introduce calibration process real human computer
interaction. calibration process, two tasks performed user. rst
task, user asked describe objects graph display speech
deictic gestures. second task, user asked respond system
questions using speech deictic gestures. reason users perform
two tasks identify whether dierence user initiated inputs
system initiated user responses. Based tasks, temporal relations
speech units corresponding gestures captured used real-time
interaction.
76

fiMinimizing Conflicts: Heuristic Repair Method

Percentage Occurance

Non-overlap Speech First
Overlap Speech First

Non-overlap Gesture First
Overlap Gesture First

1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
1

2

3

4

5

6

7

8

9

10

11

User Index

Figure 7: Temporal alignment behavior user study

No. Correctly Resolved
Simple One-Zero Alignment
Simple One-One Alignment
Complex
Total

Cognitive Principles
5
104
24
133

without Cognitive Principles
5
92
18
115

Table 7: role cognitive principles greedy algorithm

6.3 Role Cognitive Principles
examine role modeling cognitive status multimodal reference, compared two congurations greedy algorithm. rst conguration based
matching score dened Equation 2, incorporates cognitive principles described
earlier. second conguration uses matching score completely dependent compatibility referring expression gesture (i.e., Section 5.3.3)
without using cognitive principles (i.e., P (o|S) P (S|e) included Equation
2).
Table 7 shows comparison results terms two congurations. algorithm
using cognitive principles outperforms algorithm use cognitive
principles 15%. performance dierence applies simple inputs
one-one alignment complex inputs. results indicate modeling cognitive
status potentially improve reference resolution performance.
77

fiChai, Prasov, & Qu

Total Num
Total
Simple One-Zero Alignment
Simple One-One Alignment
Complex

219
14
151
54

Graph-matching
Num %
130
59.4%
7
50.0%
104
68.9%
19
35.2%

Greedy
Num %
133
60.7%
5
35.7%
104
68.9%
24
44.4%

Table 8: Performance comparison graph-matching algorithm greedy
algorithm

6.4 Greedy Algorithm versus Graph-matching Algorithm
compared greedy algorithm graph-matching algorithm terms
performance runtime. Table 8 shows performance comparison. Overall, greedy
algorithm performs comparably graph-matching algorithm.
compare runtime, ran algorithm user 10 times input
run 100 times. words, user input run 1000 times algorithm
get average runtime measurement. experiment done UltraSPARC-III
server 750MHz 64bit.
greedy algorithm graph-matching algorithm function
calls process speech inputs (e.g., parsing) gesture inputs (e.g., identify potentially
intended objects). dierence algorithms specic implementations
regarding graph creation matching graph-matching algorithm greedy
search greedy algorithm. result, average time greedy algorithm
process simple inputs complex inputs 17.3 milliseconds 21.2 milliseconds
respectively. average time graph matching algorithm process simple
complex inputs 22.3 milliseconds 24.8 milliseconds respectively. results show
average greedy algorithm runs slightly faster graph-matching algorithm
given current implementation, although worst case, graph-matching algorithm
asymptotically complex.
6.5 Real-time Error Analysis
understand bottleneck real-time multimodal reference resolution, examined
error cases algorithm failed provide correct referents.
Like spoken dialog systems, speech recognition major bottleneck. Although
trained users acoustic model individually, speech recognition rate still
low. 127 inputs correctly recognized referring expressions. Among
inputs, 103 resolved correct referents. Fusing inputs multiple
modalities together sometimes compensate recognition errors (Oviatt, 1996).
Among 92 inputs referring expressions incorrectly recognized, 29
correctly assigned referents due mutual disambiguation. mechanism reduce
78

fiMinimizing Conflicts: Heuristic Repair Method

recognition errors, especially utilizing information modalities,
important provide robust solution real time multimodal reference resolution.
second source errors comes another common problem spoken dialog
systems, namely out-of-vocabulary words. example, area vocabulary.
additional semantic constraint expressed area captured. Therefore,
system could identify whether house town referred user uttered
area. important system capability acquire knowledge (e.g.,
vocabulary) dynamically utilizing information modalities interaction
context. Furthermore, errors also came lack understanding spatial relations
(as house close red one) superlatives (as expensive house).
Algorithms aligning visual features resolve spatial references desirable (Gorniak
& Roy, 2004).
addition two main sources, errors caused unsynchronized inputs.
Currently, use idle status (i.e., 2 seconds input either speech gesture)
boundary delimit interaction turn. Two types synchronization
observed. rst type unsynchronized inputs user (such big pause
speech gesture) comes underlying system implementation.
system captures speech inputs gesture inputs two dierent servers
TCP/IP protocol. communication delay sometimes split one synchronized input
two separate turns inputs (e.g., one turn speech input alone turn
gesture input alone). better engineering mechanism synchronizing inputs desired.
disuencies users also accounted small number errors. current algorithm incapable distinguishing disuent cases normal cases. Fortunately,
disuent situations occur frequently study (only 6 inputs disuency). consistent previous ndings speech disuency rate lower
human machine conversation spontaneous speech (Brennan, 2000). humancomputer conversation, users tend speak carefully utterances tend short. Recent
ndings indicated gesture patterns could used additional source identify
dierent types speech disuencies human-human conversation (Chen, Harper, &
Quek, 2002). Based limited cases, found gesture patterns could indicators
speech disuencies occur. example, user says show red
house (point house A), green house (still point house A), behavior
pointing house dierent speech description usually indicates repair. Furthermore, gestures also involve disuencies; example, repeatedly pointing object
gesture repetition. Failure identifying disuencies caused problems reference
resolution. ideal mechanism identify disuencies using
multimodal information.
6.6 Comparative Evaluation Two Approaches
examine greedy algorithm compared nite state approach
(Section 3.1) decision list approach (Section 3.2), conducted comparative evaluation. original nite state approach, N-best speech hypotheses maintained
speech tape. data here, best speech hypothesis speech
input. Therefore, manually updated incorrectly recognized words nite
79

fiChai, Prasov, & Qu

No. Correctly Resolved
Simple Inputs one-one alighment
Simple Inputs zero-one alighment
Complex Inputs
Total

Greedy
116
8
24
148

Finite State
115
0
13
128

Decision List
88
12
0
100

Table 9: Performance comparison two approaches
state approach would penalized lack N-best speech hypotheses 4 .
modied data used three approaches. Table 9 shows comparison results.
shown table, greedy algorithm correctly resolved inputs
nite state approach decision list approach. major problem nite state
approach incorporate conversation context nite state transducer.
problem contributes failure resolving simple inputs zero-one alignment
complex inputs. major problem decision list approach,
described earlier, lack capabilities process ambiguous gestures complex
inputs.
Note greedy algorithm algorithm obtain full semantic interpretation multimodal input. rather algorithm specically reference
resolution, uses information context gesture resolve speech referring expressions. regard, greedy algorithm dierent nite state approach
whose goal get full interpretation user inputs reference resolution
part process.

7. Conclusion
Motivated earlier investigation cognitive status human machine interaction,
paper describes greedy algorithm incorporates cognitive principles underlying human referring behavior resolve variety references human machine multimodal
interaction. particular, algorithm relies theories Conversation Implicature
Givenness Hierarchy eectively guide system searching potential referents. empirical studies shown modeling form referring experssions
implication cognitive status achieve better results algorithm
considers compatibility referring expressions potential referents.
greedy algorithm eciently achieve comparable performance previous optimization
approach based graph-matching. Furthermore, greedy algorithm handles
variety user inputs ranging precise ambiguous simple complex,
outperforms nite state approach decision list approach experiments.
simplicity generality, approach potential improve robustness multimodal interpretation. learned investigation prior
4. Note corrected inputs direct correspondence recognized
words transcribed words maintain consistency timestamps.

80

fiMinimizing Conflicts: Heuristic Repair Method

knowledge linguistic cognitive studies benecial designing ecient
practical algorithms enabling multimodal human machine communication.

Acknowledgments
work supported NSF CAREER award IIS-0347548. authors would like
thank anonymous reviewers valuable comments suggestions.

References
Bolt, R. (1980). Put there: Voice gesture graphics interface. Computer
Graphics, 14 (3), 262270.
Brennan, S. (2000). Processes shape conversation implications computational linguistics. Proceedings 38th Annual Meeting ACL, pp. 18.
Byron, D. (2002). Resolving pronominal reference abstract entities. Proceedings
40th Annual Meeting ACL, pp. 8087.
Cassell, J., Bickmore, T., Billinghurst, M., Campbell, L., Chang, K., Vilhjalmsson, H., &
Yan, H. (1999). Embodiment conversational interfaces: Rea. Proceedings
CHI99, pp. 520527.
Chai, J., Hong, P., Zhou, M., & Prasov, Z. (2004). Optimization multimodal interpretation. Proceedings 42nd Annual Meeting Association Computational
Linguistics (ACL), pp. 18.
Chai, J., Prasov, Z., Blaim, J., & Jin, R. (2005). Linguistic theories ecient multimodal
reference resolution: empirical study. Proceedings 10th International
Conference Intelligent User Interfaces(IUI), pp. 4350.
Chai, J., Prasov, Z., & Hong, P. (2004a). Performance evaluation error analysis
multimodal reference resolution conversational system. Proceedings HLTNAACL 2004 (Companion Volumn), pp. 4144.
Chai, J. Y., Hong, P., & Zhou, M. X. (2004b). probabilistic approach reference resolution multimodal user interfaces. Proceedings 9th International Conference
Intelligent User Interfaces (IUI), pp. 7077.
Chen, L., Harper, M., & Quek, F. (2002). Gesture patterns speech repairs.
Proceedings International Conference Multimodal Interfaces (ICMI), pp. 155
160.
Cohen, P. (1984). pragmatics referring modality communication. Computational Linguistics, 10, 97146.
Cohen, P., Johnston, M., McGee, D., Oviatt, S., Pittman, J., Smith, I., Chen, L., & Clow, J.
(1996). Quickset: Multimodal interaction distributed applications. Proceedings
ACM Multimedia, pp. 3140.
Eckert, M., & Strube, M. (2000). Dialogue acts, synchronising units anaphora resolution. Journal Semantics, Vol. 17(1), pp. 5189.
81

fiChai, Prasov, & Qu

Gold, S., & Rangarajan, A. (1996). graduated assignment algorithm graph-matching.
IEEE Trans. Pattern Analysis Machine Intelligence, 18 (4), 377388.
Gorniak, P., & Roy, D. (2004). Grounded semantic composition visual scenes. Journal
Artificial Intelligence Research, 21, 429470.
Grice, H. P. (1975). Logic conversation. Cole, P., & Morgan, J. (Eds.), Speech Acts,
pp. 4158. New York: Academic Press.
Grosz, B. J., & Sidner, C. (1986). Attention, intention, structure discourse.
Computational Linguistics, 12 (3), 175204.
Gundel, J. K., Hedberg, N., & Zacharski, R. (1993). Cognitive status form
referring expressions discourse. Language, 69 (2), 274307.
Gustafson, J., Bell, L., Beskow, J., Boye, J., Carlson, R., Edlund, J., Granstrom, B., House,
D., & Wiren, M. (2000). Adapt - multimodal conversational dialogue system
apartment domain. Proceedings 6th International Conference Spoken
Language Processing (ICSLP), Vol. 2, pp. 134137.
Huls, C., Bos, E., & Classen, W. (1995). Automatic referent resolution deictic
anaphoric expressions. Computational Linguistics, 21 (1), 5979.
Johnston, M. (1998). Unication-based multimodal parsing. Proceedings COLINGACL98, pp. 624630.
Johnston, M., & Bangalore, S. (2000). Finite-state multimodal parsing understanding.
Proceedings COLING00, pp. 369375.
Johnston, M., Cohen, P., McGee, D., Oviatt, S., Pittman, J., & Smith, I. (1997). Unicationbased multimodal integration. Proceedings ACL97, pp. 281288.
Kehler, A. (2000). Cognitive status form reference multimodal human-computer
interaction. Proceedings AAAI00, pp. 685689.
Koons, D. B., Sparrell, C. J., & Thorisson, K. R. (1993). Integrating simultaneous input
speech, gaze, hand gestures. Maybury, M. (Ed.), Intelligent Multimedia
Interfaces, pp. 257276. MIT Press.
Neal, J. G., & Shapiro, S. C. (1991). Intelligent multimedia interface technology. Sullivan,
J., & Tyler, S. (Eds.), Intelligent User Interfaces, pp. 4568. ACM: New York.
Neal, J. G., Thielman, C. Y., Dobes, Z. H., M., S., & Shapiro, S. C. (1998). Natural language
integrated deictic graphic gestures. Maybury, M., & Wahlster, W. (Eds.),
Intelligent User Interfaces, pp. 3851. CA: Morgan Kaufmann Press.
Oviatt, S., Coulston, R., Tomko, S., Xiao, B., Bunsford, R., Wesson, M., & Carmichael, L.
(2003). Toward theory organized multimodal integration patterns humancomputer interaction. Proceedings Fifth International Conference Multimodal
Interfaces, pp. 4451.
Oviatt, S., DeAngeli, A., & Kuhn, K. (1997). Integration synchronization input
modes multimodal human-computer interaction. Proceedings Conference
Human Factors Computing Systems: CHI97, pp. 415422.
82

fiMinimizing Conflicts: Heuristic Repair Method

Oviatt, S. L. (1996). Multimodal interfaces dynamic interactive maps. Proceedings
Conference Human Factors Computing Systems: CHI96, pp. 95102.
Oviatt, S. L. (1999a). Multimodal system processing mobile environments. Proceedings
Thirteenth Annual ACM Symposium User Interface Software Technology
(UIST2000), pp. 2130.
Oviatt, S. L. (1999b). Mutual disambiguation recognition errors multimodal architecture. Proceedings Conference Human Factors Computing Systems:
CHI99, pp. 576583.
Stent, A., Dowding, J., Gawron, J. M., Bratt, E. O., & Moore, R. (1999). commandtalk
spoken dialog system. Proceedings ACL99, pp. 183190.
Stock, O. (1993). Alfresco: Enjoying combination natural language processing
hypermedia information exploration. Maybury, M. (Ed.), Intelligent Multimedia
Interfaces, pp. 197224. MIT Press.
Tsai, W. H., & Fu, K. S. (1979). Error-correcting isomorphism attributed relational
graphs pattern analysis. IEEE Trans. Sys., Man Cyb., 9, 757768.
Wahlster, W. (1998). User discourse models multimodal communication. Maybury, M., & Wahlster, W. (Eds.), Intelligent User Interfaces, pp. 359370. ACM Press.
Wu, L., & Oviatt, S. (1999). Multimodal integration - statistical view. IEEE Transactions
Multimedia, 1 (4), 334341.
Zancanaro, M., Stock, O., & Strapparava, C. (1997). Multimodal interaction information
access: Exploiting cohesion. Computational Intelligence, 13 (7), 439464.

83

fiJournal Artificial Intelligence Research 27 (2006) 153201

Submitted 05/06; published 10/06

Solving Factored MDPs Hybrid State Action
Variables
Branislav Kveton

bkveton@cs.pitt.edu

Intelligent Systems Program
5406 Sennott Square
University Pittsburgh
Pittsburgh, PA 15260

Milos Hauskrecht

milos@cs.pitt.edu

Department Computer Science
5329 Sennott Square
University Pittsburgh
Pittsburgh, PA 15260

Carlos Guestrin

guestrin@cs.cmu.edu

Machine Learning Department
Computer Science Department
5313 Wean Hall
Carnegie Mellon University
Pittsburgh, PA 15213

Abstract
Efficient representations solutions large decision problems continuous
discrete variables among important challenges faced designers automated decision support systems. paper, describe novel hybrid factored Markov
decision process (MDP) model allows compact representation problems,
new hybrid approximate linear programming (HALP) framework permits
efficient solutions. central idea HALP approximate optimal value function
linear combination basis functions optimize weights linear programming.
analyze theoretical computational aspects approach, demonstrate
scale-up potential several hybrid optimization problems.

1. Introduction
dynamic decision problem components uncertainty often formulated
Markov decision process (MDP). MDP represents controlled stochastic process whose
dynamics described state transitions. Objectives control modeled rewards
(or costs), assigned state-action configurations. simplest form, states
actions MDP discrete unstructured. models solved efficiently
standard dynamic programming methods (Bellman, 1957; Puterman, 1994; Bertsekas &
Tsitsiklis, 1996).
Unfortunately, textbook models rarely meet practice needs. First, real-world
decision problems naturally described factored form may involve combination
discrete continuous variables. Second, guarantees compact forms
optimal value function policy problems exist. Therefore, hybrid optimization
problems usually discretized solved approximately methods discrete-state
c
2006
AI Access Foundation. rights reserved.

fiKveton, Hauskrecht, & Guestrin

MDPs. contribution work principled, sound, efficient approach solving
large-scale factored MDPs avoids discretization step.
framework based approximate linear programming (ALP) (Schweitzer & Seidmann, 1985), already applied solve decision problems discrete state
action variables efficiently (Schuurmans & Patrascu, 2002; de Farias & Van Roy, 2003;
Guestrin et al., 2003). applications include context-specific planning (Guestrin et al.,
2002), multiagent planning (Guestrin et al., 2002), relational MDPs (Guestrin et al., 2003),
first-order MDPs (Sanner & Boutilier, 2005). work, show adapt ALP
solving large-scale factored MDPs hybrid state action spaces.
presented approach combines factored MDP representations (Sections 3 4)
optimization techniques solving large-scale structured linear programs (Section 6).
leads various benefits. First, quality complexity value function approximations
controlled using basis functions (Section 3.2). Therefore, prevent exponential
blowup complexity computations techniques cannot. Second, always
guarantee HALP returns solution. quality naturally depends choice basis
functions. analyzed Section 5.1, selected appropriately, achieve close
approximation optimal value function V . Third, well-chosen class basis functions
yields closed-form solutions backprojections value functions (Section 5.2).
step important solving hybrid optimization problems efficiently. Finally, solving
hybrid factored MDPs reduces building satisfying relaxed formulations original
problem (Section 6). formulations solved efficiently cutting plane method,
studied extensively applied mathematics operations research.
better readability paper, proofs deferred Appendix A. following
notation adopted throughout work. Sets members represented capital
small italic letters s, respectively. Sets variables, subsets, members
sets denoted capital letters X, Xi , Xi . general, corresponding small
letters represent value assignments objects. subscripted indices C denote
discrete continuous variables variable set value assignment. function
Dom() computes domain variable domain function. function Par()
returns parent set variable graphical model (Howard & Matheson, 1984; Dean
& Kanazawa, 1989).

2. Markov Decision Processes
Markov decision processes (Bellman, 1957) provide elegant mathematical framework
modeling solving sequential decision problems presence uncertainty. Formally,
finite-state Markov decision process (MDP) given 4-tuple = (S, A, P, R),
= {s1 , . . . , sn } set states, = {a1 , . . . , } set actions, P : [0, 1]
stochastic transition function state dynamics conditioned preceding state
action, R : R reward function assigning immediate payoffs state-action
configurations. Without loss generality, reward function assumed nonnegative
bounded constant Rmax (Puterman, 1994). Moreover, assume
transition reward models stationary known priori.
decision problem formulated MDP, goal find policy :
maximizes objective function. paper, quality policy measured
154

fiSolving Factored MDPs Hybrid State Action Variables

infinite horizon discounted reward :

#
"

X

(t)
(t) (0)
R(s , (s )) ,
E


(1)

t=0

[0, 1) discount factor, s(t) state time step t, expectation
taken respect state-action trajectories start states s(0) follow
policy thereafter. states s(0) chosen according distribution . optimality
criterion assures exists optimal policy stationary deterministic
(Puterman, 1994). policy greedy respect optimal value function V ,
fixed point Bellman equation (Bellman, 1957):
"
#
X



V (s) = max R(s, a) +
P (s | s, a)V (s ) .
(2)




Bellman equation plays fundamental role dynamic programming (DP) methods
solving MDPs (Puterman, 1994; Bertsekas & Tsitsiklis, 1996), including value iteration,
policy iteration, linear programming. focus paper linear programming
methods refinements. Briefly, well known optimal value function V
solution linear programming (LP) formulation (Manne, 1960):
X
minimize
(s)V (s)
(3)


subject to: V (s) R(s, a) +

X

P (s | s, a)V (s ) S, A;



V (s) represents variables LP, one state s, (s) > 0 strictly
positive weighting state space S. number constraints equals cardinality
cross product state action spaces |S A|.
Linear programming efficient solutions studied extensively applied
mathematics operations research (Bertsimas & Tsitsiklis, 1997). simplex algorithm
common way solving LPs. worst-case time complexity exponential number
variables. ellipsoid method (Khachiyan, 1979) offers polynomial time guarantees
impractical solving LPs even moderate size.
LP formulation (3) solved compactly cutting plane method (Bertsimas
& Tsitsiklis, 1997) objective function constraint space structured. Briefly,
method searches violated constraints relaxed formulations original LP. every
step, start relaxed solution V (t) , find violated constraint given V (t) , add
LP, resolve new vector V (t+1) . method iterated violated constraint
found, V (t) optimal solution LP. approach potential solve
large structured linear programs identify violated constraints efficiently (Bertsimas
& Tsitsiklis, 1997). violated constraint method found often referred
separating hyperplane separation oracle, respectively.
Delayed column generation based similar idea cutting plane method,
applied column space variables instead row space constraints. Benders
Dantzig-Wolfe decompositions reflect structure constraint space often
used solving large structured linear programs.
155

fiKveton, Hauskrecht, & Guestrin

3. Discrete-State Factored MDPs
Many real-world decision problems naturally described factored form. Discrete-state
factored MDPs (Boutilier et al., 1995) allow compact representation structure.
3.1 Factored Transition Reward Models
discrete-state factored MDP (Boutilier et al., 1995) 4-tuple = (X, A, P, R),
X = {X1 , . . . , Xn } state space described set state variables, = {a1 , . . . , }
set actions1 , P (X | X, A) stochastic transition model state dynamics conditioned
preceding state action, R reward function assigning immediate payoffs
state-action configurations. state system completely observed represented
vector value assignments x = (x1 , . . . , xn ). assume values every state
variable Xi restricted finite domain Dom(Xi ).
Transition model: transition model given conditional probability distribution P (X | X, A), X X denote state variables two successive time steps.
Since complete tabular representation P (X | X, A) infeasible, assume
transition model factors along X as:


P (X | X, a) =

n


P (Xi | Par(Xi ), a)

(4)

i=1

described compactly dynamic Bayesian network (DBN) (Dean & Kanazawa,
1989). DBN representation captures independencies among state variables X
X given action a. One-step dynamics every state variable modeled conditional
probability distribution P (Xi | Par(Xi ), a), Par(Xi ) X denotes parent set Xi .
Typically, parent set subset state variables simplifies parameterization
model. principle, parent set extended state variables X .
extension poses new challenges solving new problems efficiently (Guestrin,
2003). Therefore, omit discussion modeling intra-layer dependencies
paper.
Reward model: reward model
factors similarly transition model. particular,
P
reward function R(x, a) = j Rj (xj , a) additive function local reward functions
defined subsets Xj A. graphical models, local functions described
compactly reward nodes Rj , conditioned parent sets Par(Rj ) = Xj A.
allow representation, formally extend DBN influence diagram (Howard
& Matheson, 1984).
Example 1 (Guestrin et al., 2001) illustrate concept factored MDP, consider network administration problem, computers unreliable fail.
failures computers propagate network connections whole network.
instance, server X1 (Figure 1a) down, chance neighboring computer X2
1. simplicity exposition, discuss simpler model, assumes single action variable instead
factored action space = {A1 , . . . , }. conclusions Sections 3.1 3.3 extend MDPs
factored action spaces (Guestrin et al., 2002).

156

fiSolving Factored MDPs Hybrid State Action Variables

(a)

(b)

(c)

Figure 1: a. Four computers ring topology. Direction propagating failures denoted
arrows. b. graphical representation factored transition reward models
taking action a1 4-ring topology. future state server X1
independent rest network server rebooted. Reward
nodes R1 Rj (j 2) denote components 2x1 xj (j 2) reward
model. c. graphical
representation linear value function approximation
P
V w (x) = w0 + 4i=1 wi xi 4-ring topology. Reward nodes H0 Hi (i 1)
denote value function components w0 wi xi (i 1).
crashes increases. administrator prevent propagation failures rebooting
computers already crashed.
network administration problem formulated factored MDP. state
network completely observable represented n binary variables X = {X1 , . . . , Xn },
variable Xi denotes state i-th computer: 0 (being down) 1 (running).
time step, administrator selects action set = {a1 , . . . , an+1 }.
action ai (i n) corresponds rebooting i-th computer. last action an+1 dummy.
transition function reflects propagation failures network encoded
locally conditioning parent set every computer. natural metric evaluating
performance administrator total number running computers. metric
factors along computer states xi represented compactly additive reward
function:
R(x, a) = 2x1 +

n
X

xj .

j=2

weighting states establishes preferences maintaining server X1 workstations X2 , . . . , Xn . example transition reward models taking action a1
4-ring topology (Figure 1a) given Figure 1b.
3.2 Solving Discrete-State Factored MDPs
Markov decision processes solved exact DP methods polynomial time size
state space X (Puterman, 1994). Unfortunately, factored state spaces exponential
number state variables. Therefore, DP methods unsuitable solving large
157

fiKveton, Hauskrecht, & Guestrin

factored MDPs. Since factored representation MDP (Section 3.1) may guarantee
structure optimal value function policy (Koller & Parr, 1999), resort value
function approximations alleviate concern.
Value function approximations successfully applied variety real-world
domains, including backgammon (Tesauro, 1992, 1994, 1995), elevator dispatching (Crites
& Barto, 1996), job-shop scheduling (Zhang & Dietterich, 1995, 1996). partial
successes suggest approximate dynamic programming powerful tool solving
large optimization problems.
work, focus linear value function approximation (Bellman et al., 1963; Van
Roy, 1998):
V w (x) =

X

wi fi (x).

(5)



approximation restricts form value function V w linear combination
|w| basis functions fi (x), w vector optimized weights. Every basis function
defined complete state space X, usually limited small subset state
variables Xi (Bellman et al., 1963; Koller & Parr, 1999). role basis functions similar
features machine learning. often provided domain experts, although
growing amount work learning basis functions automatically (Patrascu et al., 2002;
Mahadevan, 2005; Kveton & Hauskrecht, 2006a; Mahadevan & Maggioni, 2006; Mahadevan
et al., 2006).
Example 2 demonstrate concept linear value function model, consider
network administration problem (Example 1) assume low chance single computer
failing. value function Figure 1c sufficient derive close-to-optimal policy
4-ring topology (Figure 1a) indicator functions fi (x) = xi capture changes
states individual computers. instance, computer Xi fails, linear policy:
"
#
X

w
u(x) = arg max R(x, a) +
P (x | x, a)V (x )


x

immediately leads rebooting it. failure already propagated computer Xi+1 ,
policy recovers next step. procedure repeated spread initial
failure stopped.
3.3 Approximate Linear Programming
Various methods fitting linear value function approximation proposed
analyzed (Bertsekas & Tsitsiklis, 1996). focus approximate linear programming
(ALP) (Schweitzer & Seidmann, 1985), recasts problem linear program:
minimizew

X
x

subject to:

X


(x)

X

wi fi (x)



wi fi (x) R(x, a) +

(6)
X

P (x | x, a)

x

158

X


wi fi (x )

x X, A;

fiSolving Factored MDPs Hybrid State Action Variables

w represents variables theP
LP, (x) 0
Pstate relevance weights weighting
quality approximation, x P (x | x, a) wi fi (x ) discounted backprojection value function V w (Equation 5). ALP formulation easily derived
standard LP formulation (3) substituting V w (x) V (x). formulation
feasible set basis functions contains constant function f0 (x) 1. assume
basis function always present. Note state relevance weights longer
enforced strictly positive (Section 1). Comparing standard LP formulation (3),
solved optimal value function V arbitrary weights (s) > 0, solution
e ALP formulation depends weights (x). Intuitively, higher weights,
w
e
higher quality approximation V w
corresponding state.
Since basis functions usually restricted subsets state variables (Section 3.2),
summation terms ALP formulation computed efficiently (Guestrin et al., 2001;
Schuurmans & Patrascu, 2002).
Pexample, order summation backprojection
P
term rearranged wi x P (xi | x, a)fi (xi ), allows aggregation

space Xi instead X. Similarly, factored form (x) yields efficiently computable
objective function (Guestrin, 2003).
number constraints ALP formulation exponential number state
variables. Fortunately, constraints structured. results combining factored
transition reward models (Section 3.1) linear approximation (Equation 5).
consequence, constraints satisfied without enumerating exhaustively.
Example 3 notion factored constraint space important compact satisfaction
exponentially many constraints. illustrate concept, let us consider linear value
function (Example 2) 4-ring network administration problem (Example 1). Intuitively,
combining graphical representations P (x | x, a1 ), R(x, a1 ) (Figure 1b), V w (x)
(Figure 1c), obtain factored model constraint violations:
X
P (x | x, a1 )V w (x ) R(x, a1 )
w (x, a1 ) = V w (x)
=

X

x

wi fi (x)



= w0 +

X

wi



4
X

X

P (xi | x, a1 )fi (xi ) R(x, a1 )

xi

wi xi w0 w1 P (x1 = 1 | a1 )

i=1



4
X

wi P (xi = 1 | xi , xi1 , a1 ) 2x1

4
X

xj .

j=2

i=2

arbitrary solution w (Figure 2a). Note cost function:
w (x, a1 ) = w +

4
X

w (xi ) +

4
X

w (xi , xi1 )

i=2

i=1

linear combination constant w x, univariate bivariate functions w (xi )
w (xi , xi1 ). represented compactly cost network (Guestrin et al., 2001),
undirected graph set variables X. Two nodes graph connected
159

fiKveton, Hauskrecht, & Guestrin

(a)

(b)

Figure 2: a. graphical representation combining factored transition reward models
(Figure 1b) linear approximation (Figure 1c). Reward nodes G0 Gi
(i 1) represent discounted backprojection terms w0 wi xi (i 1).
Gray regions cost components constraint space. b. cost network
corresponding factored constraint space (Figure 2a). network captures
pairwise dependencies X1 X2 , X2 X3 , X3 X4 . treewidth cost
network 1.

cost terms depends variables. Therefore, cost network corresponding
function w (x, a1 ) must contain edges X1 X2 , X2 X3 , X3 X4 (Figure 2b).
Savings achieved compact representation constraints related efficiency
computing arg minx w (x, a1 ) (Guestrin, 2003). computation done variable
elimination complexity increases exponentially width tree decomposition
cost network. smallest width tree decompositions referred treewidth.
Inspired factorization, Guestrin et al. (2001) proposed variable-elimination method
(Dechter, 1996) rewrites constraint space ALP compactly. Schuurmans Patrascu (2002) solved problem cutting plane method. method iteratively
searches violated constraint:



X
X (t)
P (xi | x, a)fi (xi ) R(x, a)
(7)
arg min
wi fi (xi )
x,a



xi

respect solution w(t) relaxed ALP. constraint added LP,
resolved new solution w(t+1) . procedure iterated violated constraint
found, w(t) optimal solution ALP.
quality ALP formulation studied de Farias Van Roy (2003).
e
Based work, conclude ALP yields close approximation V w
optimal


w
value function V weighted max-norm error kV V k,1/L minimized.
return theoretical result Section 5.1.

160

fiSolving Factored MDPs Hybrid State Action Variables

e solution ALP formulation
Theorem 1 (de Farias & Van Roy, 2003) Let w
e
(6). expected error value function V w
bounded as:


2 L

e
min kV V w k,1/L ,

V V w
1 w
1,
P
kk1, L1 -norm weighted state relevance weights , L(x) = wiL fi (x)
Lyapunov function inequality L(x) supa EP (x |x,a) [L(x )] holds, [0, 1)
denotes contraction factor, kk,1/L max-norm reweighted reciprocal 1/L.




e
e
V V w

Note L1 -norm distance V V w
equals


expectation
E

1,
state space X respect state relevance weights . Similarly Theorem 1,
utilize L1 L norms rest work measure expected worst-case
errors value functions. norms defined follows.
Definition
1 L1 (Manhattan) L (infinity) norms typically defined kf k1 =
P
x |f (x)| kf k = maxx |f (x)|. state space X represented discrete
continuous variables XD XC , definition norms changes accordingly:
XZ
kf k1 =
|f (x)| dxC kf k = sup |f (x)| .
(8)
xD

x

xC

following definitions:
XZ
kf k1, =
(x) |f (x)| dxC
xD



xC

kf k, = sup (x) |f (x)|

(9)

x

correspond L1 L norms reweighted function (x).

4. Hybrid Factored MDPs
Discrete-state factored MDPs (Section 3) permit compact representation decision problems discrete states. However, real-world domains often involve continuous quantities,
temperature pressure. sufficient discretization quantities may require
hundreds points single dimension, renders representation transition
model (Equation 4) infeasible. addition, rough uninformative discretization impacts
quality policies. Therefore, want avoid discretization defer necessary.
step direction, discuss formalism representing hybrid decision problems
domains discrete continuous variables.
4.1 Factored Transition Reward Models
hybrid factored MDP (HMDP) 4-tuple = (X, A, P, R), X = {X1 , . . . , Xn }
state space described state variables, = {A1 , . . . , } action space described
action variables, P (X | X, A) stochastic transition model state dynamics conditioned
preceding state action, R reward function assigning immediate payoffs
state-action configurations.2
2. General state action space MDP alternative term hybrid MDP. term hybrid
refer dynamics model, discrete-time.

161

fiKveton, Hauskrecht, & Guestrin

P(X2 | X2 = 0)

P(X1 )

P(X2 | X2 = 1, X1 = 0)

P(X2 | X2 = 1, X1 = 1)

Probability density

8
6
4
2
0

0

0.5
X1

1

4

4

4

3

3

3

2

2

2

1

1

1

0

0

0.5
X2

0

1

0

0.5
X2

1

0

0

0.5
X2

1

Figure 3: Transition functions continuous variables X1 X2 taking action a1
4-ring topology (Example 4). densities shown extreme values
parent variables X1 X2 .

State variables: State variables either discrete continuous. Every discrete variable
Xi takes values finite domain Dom(Xi ). Following Hauskrecht Kveton (2004),
assume every continuous variable bounded [0, 1] subspace. general,
assumption mild permits modeling closed interval R. state
system completely observed described vector value assignments x = (xD , xC )
partitions along discrete continuous components xD xC .
Action variables: action space distributed represented action variables A.
composite action defined vector individual action choices = (aD , aC )
partitions along discrete continuous components aD aC .
Transition model: transition model given conditional probability distribution P (X | X, A), X X denote state variables two Q
successive time steps.
assume distribution factors along X P (X | X, A) = ni=1 P (Xi | Par(Xi ))
described compactly DBN (Dean & Kanazawa, 1989). Typically, parent
set Par(Xi ) X small subset state action variables allows local
parameterization transition model.
Parameterization transition model: One-step dynamics every state variable
described conditional probability distribution P (Xi | Par(Xi )). Xi continuous
variable, transition function represented mixture beta distributions (Hauskrecht
& Kveton, 2004):
X
P (Xi = x | Par(Xi )) =
ij Pbeta (x | j , j )
(10)
j

( + ) 1
x
(1 x)1 ,
Pbeta (x | , ) =
()()

ij weight assigned j-th component mixture, j = ij (Par(Xi ))
j = ij (Par(Xi )) arbitrary positive functions parent set. mixture beta
distributions provides general class transition functions yet allows closed-form
162

fiSolving Factored MDPs Hybrid State Action Variables

solutions3 expectation terms HALP (Section 5). every j = 1, Equation 10 turns
polynomial Xi . Due Weierstrass approximation theorem (Jeffreys & Jeffreys,
1988), polynomial sufficient approximate continuous transition density
Xi precision. Xi discrete variable, transition model parameterized
|Dom(Xi )| nonnegative discriminant functions j = ij (Par(Xi )) (Guestrin et al., 2004):
j
P (Xi = j | Par(Xi )) = P
|Dom(Xi )|
j=1

.

(11)

j

Note parameters j , j , j (Equations 10 11) functions instantiated
value assignments variables Par(Xi ) X A. keep separate parameters every
state variable Xi although indexing reflect explicitly. restriction
functions return valid parameters state-action pairs (x, a). Hence,
P|Dom(X )|
assume j (x, a) 0, j (x, a) 0, j (x, a) 0, j=1 j (x, a) > 0.
Reward model: reward P
model factors similarly transition model. particular,
reward function R(x, a) = j Rj (xj , aj ) additive function local reward functions
defined subsets Xj Aj . graphical models, local functions described
compactly reward nodes Rj , conditioned parent sets Par(Rj ) = Xj Aj .
allow representation, formally extend DBN influence diagram (Howard
& Matheson, 1984). Note form reward functions Rj (xj , aj ) restricted.
Optimal value function policy: optimal policy defined greedily
respect optimal value function V , fixed point Bellman equation:



(12)
V (x) = sup R(x, a) + EP (x |x,a) V (x )



XZ

P (x | x, a)V (x ) dxC .
= sup R(x, a) +


xC

xD

Accordingly, hybrid Bellman operator given by:



V (x) = sup R(x, a) + EP (x |x,a) V (x ) .

(13)



rest paper, denote expectation terms discrete continuous variables
unified form:
XZ
EP (x) [f (x)] =
P (x)f (x) dxC .
(14)
xD

xC

Example 4 (Hauskrecht & Kveton, 2004) Continuous-state network administration
variation Example 1, computer states represented continuous variables
interval 0 (being down) 1 (running). time step, administrator
3. term closed-form refers generally accepted set closed-form operations functions extended
gamma incomplete beta functions.

163

fiKveton, Hauskrecht, & Guestrin

selects single action set = {a1 , . . . , an+1 }. action ai (i n) corresponds
rebooting i-th computer. last action an+1 dummy. transition model captures
propagation failures network encoded locally beta distributions:
= 20
a=i
=2
6
= 2 + 13xi 5xi E[Par(Xi )] =

= 10 2xi 6xi E[Par(Xi )]

P (Xi = x | Par(Xi )) = Pbeta (x | , )

variables xi E[Par(Xi )] denote state i-th computer expected
state parents. Note transition function similar Example 1. instance,
4-ring topology, modes transition densities continuous variables X1 X2
taking action a1 (Figure 3):
Pb(X2

Pb(X1 | = a1 ) = 0.95 Pb(X2 | X2 = 1, X1 = 0, = a1 ) 0.67
| X2 = 0, = a1 ) = 0.10 Pb(X2 | X2 = 1, X1 = 1, = a1 ) = 0.90

equal expected values discrete counterparts (Figure 1b). reward function
additive:
R(x, a) =

2x21

+

n
X

x2j

j=2

establishes preferences maintaining server X1 workstations X2 , . . . , Xn .
4.2 Solving Hybrid Factored MDPs
Value iteration, policy iteration, linear programming fundamental dynamic
programming methods solving MDPs (Puterman, 1994; Bertsekas & Tsitsiklis, 1996).
Unfortunately, none techniques suitable solving hybrid factored MDPs. First,
complexity exponential number state variables variables discrete.
Second, methods assume finite support optimal value function policy,
may exist continuous variables present. Therefore, feasible approach solving
arbitrary HMDPs likely approximate. rest section, review two major
classes methods approximating value functions hybrid domains.
Grid-based approximation: Grid-based methods (Chow & Tsitsiklis, 1991;
Rust, 1997)
transform initial state space X set grid points G = x(1) , . . . , x(N ) . points
used estimate optimal value function VG grid, turn approximates
V . Bellman operator grid defined (Rust, 1997):


N
X
PG (x(j) | x(i) , a)V (x(j) ) ,
(15)
TG V (x(i) ) = max R(x(i) , a) +


j=1

(i)
(j) | x(i) , a) transition function, normalwhere PG (x(j) | x(i) , a) = 1
aP(x )P (x
(j) | x(i) , a). operator allows computation
ized term (x(i) ) = N
j=1 P (x
G

value function VG standard techniques solving discrete-state MDPs.

164

fiSolving Factored MDPs Hybrid State Action Variables

Inputs:
hybrid factored MDP = (X, A, P, R)
basis functions f0 (x), f1 (x), f2 (x), . . .
initial basis function weights w(0)
set states G = x(1) , . . . , x(N )

Algorithm:
t=0
stopping criterion met
every state x(j)
every basis function fi (x)
Xji = fhi (x(j) )

h (t)
ii
yj = maxa R(x(j) , a) + EP (x |x(j) ,a) V w (x )

w(t+1) = (XT X)1 XT
t=t+1

Outputs:
basis function weights w(t)

Figure 4: Pseudo-code implementation least-squares value iteration (L2 VI)
linear value function approximation (Equation 5).
often

stopping criterion
(t)

w(t)
V w measured
based number steps L2 -norm error V
2
set G. discussion Sections 5.2 6 provides recipe efficient
(t)
implementation backup operation V w (x(j) ).

Rust (1997) analyzed convergence methods random pseudo-random
samples. Clearly, uniform discretization increasing precision guarantees convergence
VG V causes exponential blowup state space (Chow & Tsitsiklis, 1991).
overcome concern, Munos Moore (2002) proposed adaptive algorithm nonuniform discretization based Kuhn triangulation. Ferns et al. (2005) analyzed metrics
aggregating states continuous-state MDPs based notion bisimulation. Trick
Zin (1993) used linear programming solve low-dimensional problems continuous
variables. continuous variables discretized manually.
Parametric value function approximation: alternative approach solving factored
MDPs continuous-state components approximation optimal value function
V parameterized model V (Bertsekas & Tsitsiklis, 1996; Van Roy, 1998; Gordon,
1999). parameters typically optimized iteratively
applying
backup operator


finite set states. least-squares error V V 2 commonly minimized
error metric (Figure 4). Online updating gradient methods (Bertsekas & Tsitsiklis, 1996;
Sutton & Barto, 1998) another way optimizing value functions. limitation
techniques solutions often unstable may diverge (Bertsekas, 1995).
hand, generate high-quality approximations.

165

fiKveton, Hauskrecht, & Guestrin

Parametric approximations often assume fixed value function models. However,
cases, possible derive flexible forms V combine well backup operator
. instance, Sondik (1971) showed convex piecewise linear functions sufficient
represent value functions DP backups partially-observable MDPs (POMDPs)
(Astrom, 1965; Hauskrecht, 2000). Based idea, Feng et al. (2004) proposed method
solving MDPs continuous variables. obtain full DP backups, value function
approximation restricted rectangular piecewise linear convex (RPWLC) functions.
restrictions placed transition reward models MDPs. advantage
approach adaptivity. major disadvantages restrictions solved MDPs
complexity RPWLC value functions, may grow exponentially number
backups. result, without modifications, approach less likely succeed
solving high-dimensional distributed decision problems.

5. Hybrid Approximate Linear Programming
overcome limitations existing methods solving HMDPs (Section 4.2), extend
discrete-state ALP (Section 3.3) hybrid state action spaces. refer novel
framework hybrid approximate linear programming (HALP).
Similarly discrete-state ALP, HALP optimizes linear value function approximation (Equation 5). Therefore, transforms initially intractable problem computing
V hybrid state space X lower dimensional space w. HALP formulation
given linear program4 :
minimizew

X

wi

(16)



subject to:

X

wi Fi (x, a) R(x, a) 0 x X, A;



w represents variables LP, denotes basis function relevance weight:
= E(x) [fi (x)]
XZ
=
(x)fi (x) dxC ,
xD

(17)

xC

(x) 0 state relevance density function weights quality approximation,
Fi (x, a) = fi (x) gi (x, a) denotes difference basis function fi (x)
discounted backprojection:


gi (x, a) = EP (x |x,a) fi (x )
XZ
P (x | x, a)fi (x ) dxC .
=
xD

(18)

xC

4. precisely, HALP formulation (16) linear semi-infinite optimization problem infinite
number constraints. number basis functions finite. brevity, refer optimization
problem linear programming.

166

fiSolving Factored MDPs Hybrid State Action Variables

Vectors xD (xD ) xC (xC ) discrete continuous components value assignments x (x ) state variables X (X ). linear program rewritten compactly:
minimizew

E [V w ]

subject to: V

w

(19)


V

w

0

using Bellman operator .
HALP formulation reduces discrete-state ALP (Section 3.3) state
action variables discrete, continuous-state ALP (Hauskrecht & Kveton, 2004)
state variables continuous. formulation feasible set basis functions
contains constant function f0 (x) 1. assume basis function present.
rest paper, address several concerns related HALP formulation.
First, analyze quality approximation relate minimization
max-norm error kV V w k , commonly-used metric (Section 5.1). Second,
present rich classes basis functions lead closed-form solutions expectation
terms objective function constraints (Equations 17 18). terms involve
sums integrals complete state space X (Section 5.2), therefore hard
evaluate. Finally, discuss approximations constraint space HALP introduce
framework solving HALP formulations unified way (Section 6). Note complete
satisfaction constraint space may possible since every state-action pair (x, a)
induces constraint.
5.1 Error Bounds
quality ALP approximation (Section 3.3) studied de Farias Van
Roy (2003). follow work extend structured state action spaces
continuous variables. proceed, demonstrate solution HALP
formulation (16) constitutes upper bound optimal value function V .
e
e solution HALP formulation (16). V w
Proposition 1 Let w
V .

result allows us restate objective E [V w ] HALP.

e solution HALP formulation (16):
Proposition 2 Vector w
minimizew

E [V w ]

subject to:

V w V w 0

minimizew

kV V w k1,

subject to:

V w V w 0;

solves:

kk1, L1 -norm weighted state relevance density function
hybrid Bellman operator.
167

fiKveton, Hauskrecht, & Guestrin

Based Proposition 2, conclude HALP optimizes linear value function approximation respect reweighted L1 -norm error kV V w k1, . following theorem
draws parallel minimizing objective max-norm error kV V w k .
e
precisely, theorem says HALP yields close approximation V w
optimal value


function V V close span basis functions fi (x).
e optimal solution HALP formulation (16). expected
Theorem 2 Let w
e
error value function V w
bounded as:


2

e
w
V

V
min kV V w k ,


1 w
1,

kk1, L1 -norm weighted state relevance density function kk
max-norm.


e
Unfortunately, Theorem 2 rarely yields tight bound V V w
. First, hard
1,
guarantee uniformly low max-norm error kV V w k dimensionality problem
grows basis functions fi (x) local. Second, bound ignores state relevance
density function (x) although one impacts quality HALP solutions. address
concerns, introduce non-uniform weighting max-norm error Theorem 3.
e optimal solution HALP formulation (16). expected
Theorem 3 Let w
e
error value function V w
bounded as:



e

V V w

1,



2E [L]
min kV V w k,1/L ,
1 w

P
kk1, L1 -norm weighted state relevance density , L(x) = wiL fi (x)
Lyapunov function inequality L(x) supa EP (x |x,a) [L(x )] holds, [0, 1)
denotes contraction factor, kk,1/L max-norm reweighted reciprocal 1/L.
Note Theorem 2 special form Theorem 3 L(x) 1 = . Therefore,
Lyapunov function L(x) permits least good bounds Theorem 2. make
bounds tight, function L(x) return large values regions state space,
unimportant modeling. turn, reciprocal 1/L(x) close zero
undesirable regions, makes impact max-norm error kV V w k,1/L less
likely. Since state relevance density function (x) reflects importance states,
term E [L] remain small. two factors contribute tighter bounds
Theorem 2.
P
Since Lyapunov function L(x) = wiL fi (x) lies span basis functions fi (x),
Theorem 3 provides recipe achieving high-quality approximations. Intuitively, good
set basis functions always involves two types functions. first type guarantees small
errors |V (x) V w (x)| important regions state space, state relevance
density (x) high. second type returns high values state relevance density
(x) low, vice versa. latter functions allow satisfaction constraint space
V w V w unimportant regions state space without impacting optimized
objective function kV V w k1, . Note trivial value function V w (x) = (1)1 Rmax
168

fiSolving Factored MDPs Hybrid State Action Variables

satisfies constraints HALP unlikely leads good policies. comprehensive
discussion selecting appropriate (x) L(x), refer case studies de Farias
Van Roy (2003).
discussion concluded clarifying notion state relevance density (x).
demonstrated Theorem 4, choice closely related quality greedy policy
e
value function V w
(de Farias & Van Roy, 2003).
e optimal solution HALP formulation (16). expected
Theorem 4 Let w
error greedy policy:
h
h
ii
e
u(x) = arg sup R(x, a) + EP (x |x,a) V w
(x )


bounded as:
kV V u k1,


1

e
,
V V w

1
1,u,

kk1, kk1,u, weighted L1 -norms, V u value function greedy policy
u, u, expected frequency state visits generated following policy u given
initial state distribution .
Based Theorem 4, may conclude expected error greedy policies HALP
approximations bounded = u, . Note distribution u, unknown
e
optimizing V w
function optimized quantity itself. break cycle,
de Farias Van Roy (2003) suggested iterative procedure solves several LPs
adapts u, accordingly. addition, real-world control problems exhibit lot structure,
permits guessing u, .
Finally, important realize although bounds (Theorems 3 4) build
foundation better HALP approximations, rarely used practice
optimal value function V generally unknown. all, known, need
approximate it. Moreover, note optimization kV V w k,1/L (Theorem 3)
hard problem methods would minimize error directly (Patrascu
et al., 2002). Despite facts, bounds provide loose guidance empirical choices
basis functions. Section 7, use intuition propose basis functions
closely approximate unknown optimal value functions V .
5.2 Expectation Terms
Since basis functions often restricted small subsets state variables, expectation
terms (Equations 17 18) HALP formulation (16) efficiently computable.
unify analysis expectation terms, E(x) [fi (x)] EP (x |x,a) [fi (x )], show
evaluation constitutes computational problem EP (x) [fi (x)], P (x)
denotes factored distribution.
discuss expectation terms constraints, note transition function
P (x | x, a) factored parameterization determined state-action pair (x, a).
keep pair (x, a) fixed rest section, corresponds choosing single
constraint (x, a). Based selection, rewrite expectation terms EP (x |x,a) [fi (x )]
169

fiKveton, Hauskrecht, & Guestrin

simpler notation EP (x ) [fi (x )], P (x ) = P (x | x, a) denotes factored distribution
fixed parameters.
also assume state relevance density function (x) factors along X as:
(x) =

n


(xi ),

(20)

i=1

(xi ) distribution random state variable Xi . Based assumption,
rewrite expectation terms E(x) [fi (x)] objective function new notation
EP (x) [fi (x)], P (x) = (x) denotes factored distribution. line discussion
last two paragraphs, efficient solutions expectation terms HALP obtained
solving generalized term EP (x) [fi (x)] efficiently. address problem rest
section.
computing expectation term EP (x) [fi (x)] complete state space X,
recall basis function fi (x) defined subset state variables Xi . Therefore,
may conclude EP (x) [fi (x)] = EP (xi ) [fi (xi )], P (xi ) denotes factored distribution
lower dimensional space Xi . assumptions made, local expectation
term EP (xi ) [fi (xi )] may still hard compute. Although estimated variety
numerical methods, instance Monte Carlo (Andrieu et al., 2003), techniques
imprecise sample size small, quite computationally expensive high precision
needed. Consequently, try avoid approximation step. Instead, introduce
appropriate form basis functions leads closed-form solutions expectation
term EP (xi ) [fi (xi )].
particular, let us assume every basis function fi (xi ) factors as:
fi (xi ) = fiD (xiD )fiC (xiC )

(21)

along discrete continuous components fiD (xiD ) fiC (xiC ), continuous
component decouples product:

fiC (xiC ) =
fij (xj )
(22)
Xj XiC

univariate basis function factors fij (xj ). Note basis functions remain multivariate
despite two independence assumptions. make presumptions computational
purposes relaxed later section.
Based Equation 21, conclude expectation term:
EP (xi ) [fi (xi )] = EP (xi ) [fiD (xiD )fiC (xiC )]
= EP (xi



) [fiD (xiD )] EP (xiC ) [fiC (xiC )]

(23)

decomposes along discrete continuous variables XiD XiC , xi = (xiD , xiC )
P (xi ) = P (xiD )P (xiC ). evaluation discrete part EP (xi ) [fiD (xiD )] requires

aggregation subspace XiD :
X
(24)
P (xiD )fiD (xiD ),
EP (xi ) [fiD (xiD )] =


xiD

170

fiSolving Factored MDPs Hybrid State Action Variables

Probability density

fpoly (x2 )

fpwl (x2 )

fbeta (x2 )

4

4

4

3

3

3

2

2

2

1

1

1

0

0

0.5
X2

1

0

0

0.5
X2

1

0

0

0.5
X2

1

Figure 5: Expectation three basis functions f (x2 ) (Example 5) respect transition function P (X2 | X2 = 1, X1 = 0, = a1 ) Figure 3. Every basis function
f (x2 ) depicted thick black line. transition function shown light
gray color. Darker gray lines represent values product P (x2 | x, a1 )f (x2 ).
area corresponds expectation terms EP (x2 |x,a1 ) [f (x2 )].
Q
carried efficiently O( Xj Xi |Dom(Xj )|) time (Section 3.3). Following

Equation 22, continuous term EP (xi ) [fiC (xiC )] decouples product:
C



EP (xi ) [fiC (xiC )] = EP (xi )
C

C

=





Xj XiC



fij (xj )

EP (xj ) [fij (xj )] ,

(25)

Xj XiC

EP (xj ) [fij (xj )] represents expectation terms individual random variables Xj .
Consequently, efficient solution local expectation term EP (xi ) [fi (xi )] guaranteed
efficient solutions univariate components EP (xj ) [fij (xj )].
paper, consider three univariate basis function factors fij (xj ): piecewise linear
functions, polynomials, beta distributions. factors support general class
basis functions yet allow closed-form solutions expectation terms EP (xj ) [fij (xj )].
solutions provided following propositions demonstrated Example 5.
Proposition 3 (Polynomial basis functions) Let:
P (x) = Pbeta (x | , )
beta distribution X and:
f (x) = xn (1 x)m
polynomial x (1 x). EP (x) [f (x)] closed-form solution:
EP (x) [f (x)] =

( + ) ( + n)( + m)
.
()() ( + + n + m)
171

fiKveton, Hauskrecht, & Guestrin

Corollary 1 (Beta basis functions) Let:
P (x) = Pbeta (x | , )
f (x) = Pbeta (x | f , f )
beta distributions X. EP (x) [f (x)] closed-form solution:
EP (x) [f (x)] =

( + ) (f + f ) ( + f 1)( + f 1)
.
()() (f )(f ) ( + f + + f 2)

Proof: direct consequence Proposition 3. Since integration distributive operation,
claim straightforwardly generalizes mixture beta distributions P (x).
Proposition 4 (Piecewise linear basis functions) Let:
P (x) = Pbeta (x | , )
beta distribution X and:
f (x) =

X

1[li ,ri ] (x)(ai x + bi )



piecewise linear (PWL) function x, 1[li ,ri ] (x) represents indicator function
interval [li , ri ]. EP (x) [f (x)] closed-form solution:

X

+
+
(F (ri ) F (li )) + bi (F (ri ) F (li )) ,
ai
EP (x) [f (x)] =
+


F (u) = Fbeta (u | , ) F + (u) = Fbeta (u | + 1, ) denote cumulative density
functions beta distributions.
Example 5 Efficient closed-form solutions expectation terms HALP illustrated
4-ring network administration problem (Example 4) three hypothetical univariate
basis functions:
fpoly (x2 ) = x4
2
fbeta (x2 ) = Pbeta (x2 | 2, 6)
fpwl (x2 ) = 1[0.3,0.5] (x2 )(5x2 1.5) + 1[0.5,0.7] (x2 )(5x2 + 3.5)
Suppose goal evaluate expectation terms single constraint corresponds
network state x = (0, 1, 0, 0) administrator rebooting server. Based
assumptions, expectation terms constraint (x, a1 ) simplify as:




EP (x |x,a1 ) f (x2 ) = EP (x2 |x,a1 ) f (x2 ) ,
transition function P (x2 | x, a1 ) given by:

P (x2 | x, a1 ) = P (X2 = x2 | X2 = 1, X1 = 0, = a1 )
= Pbeta (x2 | 15, 8).
172

fiSolving Factored MDPs Hybrid State Action Variables

Closed-form solutions simplified expectation terms EP (x2 |x,a1 ) [f (x2 )] computed as:
Z




Pbeta (x2 | 15, 8)x4
EP (x2 |x,a1 ) fpoly (x2 ) =
2 dx2
x2

(15 + 8) (15 + 4)(8)
(15)(8) (15 + 8 + 4)
0.20
Z


Pbeta (x2 | 15, 8)Pbeta (x2 | 2, 6) dx2
EP (x2 |x,a1 ) fbeta (x2 ) =
(Proposition 3)

=

x2

(15 + 8) (2 + 6) (15 + 2 1)(8 + 6 1)
(15)(8) (2)(6) (15 + 2 + 8 + 6 2)
0.22
Z



Pbeta (x2 | 15, 8)1[0.3,0.5] (x2 )(5x2 1.5) dx2 +
EP (x2 |x,a1 ) fpwl (x2 ) =
(Corollary 1)

=

x2

Z

x2

(Proposition 4)

Pbeta (x2 | 15, 8)1[0.5,0.7] (x2 )(5x2 + 3.5) dx2

15
(F + (0.5) F + (0.3)) 1.5(F (0.5) F (0.3))
15 + 8
15
(F + (0.7) F + (0.5)) + 3.5(F (0.7) F (0.5))
5
15 + 8
0.30

= 5

F (u) = Fbeta (u | 15, 8) F + (u) = Fbeta (u | 15+1, 8) denote cumulative density
functions beta distributions. graphical interpretation computations presented
Figure 5. Brief inspection verifies term EP (x2 |x,a1 ) [fpwl (x2 )] indeed largest
one.
point, obtained efficient closed-form solutions factored basis functions
state relevance densities. Unfortunately, factorization assumptions Equations 20, 21,
22 rarely justified practice. rest section, show relax them.
Section 6, apply current results propose several methods approximately
satisfy constraint space HALP.
5.2.1 Factored State Relevance Density Functions
Note state relevance density function (x) unlikely completely factored
(Section 5.1). Therefore, independence assumption Equation 20 extremely
P limiting.

relax assumption, approximate (x)
Q linear combination (x) = (x)
factored state relevance densities (x) = ni=1 (xi ). result, expectation terms
objective function decompose as:
E (x) [fi (x)] = EP (x) [fi (x)]
X
E (x) [fi (x)] ,
=


173

(26)

fiKveton, Hauskrecht, & Guestrin

factored terms E (x) [fi (x)] evaluated efficiently (Equation 23). Moreover,
assume factored densities (x) polynomials, linear combination (x)
polynomial. Due Weierstrass approximation theorem (Jeffreys & Jeffreys, 1988),
polynomial sufficient approximate state relevance density (x) precision.
follows linear combinations permit state relevance densities reflect arbitrary
dependencies among state variables X.
5.2.2 Factored Basis Functions
P
line previous discussion, note linear value function V w (x) = wi fi (x)
factored basis functions (Equations 21 22) sufficient approximate optimal
value function V within max-norm error kV V w k . Based Theorem
know

2, wew
e

set basis functions guarantees bound L1 -norm error V V 1, .
Therefore, despite independence assumptions (Equations 21 22), potential
e
obtain arbitrarily close HALP approximation V w
V .

6. Constraint Space Approximations
e HALP formulation (16) determined finite set active
optimal solution w
constraints vertex feasible region. Unfortunately, identification active set
hard computational problem. particular, requires searching exponential
number constraints, state action variables discrete, infinite number
constraints, variables continuous. result, general infeasible
e HALP formulation. Hence, resort approximations
find optimal solution w
b close w.
e notion
constraint space HALP whose optimal solution w
approximation formalized follows.
Definition 2 HALP formulation relaxed:
X
wi
minimizew

(27)



subject to:

X

wi Fi (x, a) R(x, a) 0

(x, a) C;



subset C constraints satisfied.
HALP formulation (16) solved approximately solving relaxed formulations
(27). Several methods building solving approximate LPs proposed:
Monte Carlo sampling constraints, (Hauskrecht & Kveton, 2004), -grid discretization
constraint space (Guestrin et al., 2004), adaptive search violated constraint
(Kveton & Hauskrecht, 2005). remainder section, introduce methods.
on, denote optimal solutions complete relaxed HALP formulations
e w,
b respectively.
symbols w
e
proceed, note V w
upper bound optimal value function
b

V (Figure 6a), relaxed value function V w
(Figure 6b). reason
b
b
relaxed HALP formulation guarantee constraint V w
V w

b
w
satisfied states x. result, cannot simply use Proposition 1 prove V V .
174

fiSolving Factored MDPs Hybrid State Action Variables

e
Vw

V

0
1

1
X1
0 0

1

b
Vw

V

0
1

1
X1

X2

e w
b
w
Objective value

1

b
V Vw

Value function

Value function

e
V Vw

(a)

0 0

X2

1

e
w

b
w
0
1

1
w1
0 0

(b)

w2

(c)

Figure 6: a. Graphical relation value function V HALP approximation
e
e
Vw
. function V w
guaranteed upper bound V . b. relaxed
b
HALP approximation V w
may lead upper bound. c. Graphical relation
e w.
b feasible regions
optimal relaxed solutions w
complete relaxed HALP formulations shown dark light gray colors.
e
b
value function approximations V w
V w
typically nonlinear state
space X always linear space parameters w.
b
e
Furthermore, note inequality E V w
E V w
always holds optimal
e feasible relaxed HALP (Figure 6c). observations become helpful
solution w
understanding rest section.
6.1 MC-HALP
simplest case, constraint space HALP approximated Monte Carlo
(MC) sample. relaxation, set constraints C selected respect
proposal distribution state-action pairs (x, a). Since set C finite, establishes
relaxed formulation (27), solved LP solver. algorithm builds
satisfies relaxed MC-HALP formulations outlined Figure 7.
Constraint sampling easily applied continuous domains space complexity
proportional number state action components. Hauskrecht Kveton (2004)
used solve continuous-state factored MDPs refined heuristics (Kveton
& Hauskrecht, 2004). discrete-state domains, quality sampled approximations
analyzed de Farias Van Roy (2004). result summarized Theorem 5.
e solution ALP formulation
Theorem 5 (de Farias & Van Roy, 2004) Let w
b solution relaxed formulation whose constraints sampled respect
(6) w
proposal distribution state-action pairs (x, a). exist distribution
sample size:
N




(1 )


K ln
175

1

+ ln
(1 )




fiKveton, Hauskrecht, & Guestrin

Inputs:
hybrid factored MDP = (X, A, P, R)
basis functions f0 (x), f1 (x), f2 (x), . . .
proposal distribution
Algorithm:
initialize relaxed HALP formulation empty set constraints
t=0
stopping criterion met
sample (x, a)
add constraint (x, a) relaxed HALP
t=t+1
solve relaxed MC-HALP formulation
Outputs:
basis function weights w

Figure 7: Pseudo-code implementation MC-HALP solver.
probability least 1 :






e
b

V V w
V V w
1,

1,

+ kV k1, ,

kk1, L1 -norm weighted state relevance weights , problem-specific
constant, K denote numbers actions basis functions, scalars
interval (0, 1).
Unfortunately, proposing sampling distribution guarantees polynomial bound
sample size hard knowing optimal policy (de Farias & Van Roy, 2004).
conclusion parallel importance sampling. Note uniform Monte Carlo
sampling guarantee low probability constraints violated sufficient
bound magnitude violation (de Farias & Van Roy, 2004).
6.2 -HALP
Another way approximating constraint space HALP discretizing continuous
variables XC AC uniform -grid. new discretized constraint space preserves
original factored structure spans discrete variables only. Therefore, compactly
satisfied methods discrete-state ALP (Section 3.3). algorithm builds
satisfies relaxed -HALP formulations outlined Figure 8. Note new constraint
space involves exponentially many constraints O(1/ + 1|XC |+|AC | ) number state
action variables XC AC .
6.2.1 Error Bounds
Recall -HALP formulation approximates constraint space HALP finite
set equally-spaced grid points. section, study quality approximation
176

fiSolving Factored MDPs Hybrid State Action Variables

Inputs:
hybrid factored MDP = (X, A, P, R)
basis functions f0 (x), f1 (x), f2 (x), . . .
grid resolution
Algorithm:
discretize continuous variables XC AC 1/ + 1 equally-spaced values
identify subsets Xi Ai (Xj Aj ) corresponding domains Fi (x, a) (Rj (x, a))
evaluate Fi (xi , ai ) (Rj (xj , aj )) configurations xi ai (xj aj ) -grid
calculate basis function relevance weights
solve relaxed -HALP formulation (Section 3.3)
Outputs:
basis function weights w

Figure 8: Pseudo-code implementation -HALP solver.
bound terms violating constraints complete HALP. precisely, prove
b violates constraints complete HALP small
relaxed HALP solution w
b
e
amount, quality approximation V w
close V w
. next section, extend
b
w
result relate V grid resolution . proceed, quantify notion
constraint violation.
b optimal solution relaxed HALP formulation (27). vector
Definition 3 Let w
b -infeasible if:
w
b
b
Vw
V w
,

(28)

hybrid Bellman operator.

b closer quality
Intuitively, lower -infeasibility relaxed HALP solution w,
b
e
approximation V w
V w
. Proposition 5 states intuition formally. particular,
b
says relaxed HALP formulation leads close approximation V w
optimal

b violates constraints
value function V complete HALP solution w
small amount.
e optimal solution HALP formulation (16) w
b
Proposition 5 Let w
optimal -infeasible solution relaxed formulation (27). expected error
b
value function V w
bounded as:




2


b
e
,
V V w
V V w
+
1
1,
1,
kk1, L1 -norm weighted state relevance density function .

Based Proposition 5, generalize conclusions Section 5.1 relaxed HALP
formulations.
instance, may draw parallel optimizing relaxed objective
b
E V w
max-norm error kV V w k,1/L .
177

fiKveton, Hauskrecht, & Guestrin

b optimal -infeasible solution relaxed HALP formulation (27).
Theorem 6 Let w
b
expected error value function V w
bounded as:



b

V V w

1,



2E [L]
2
min kV V w k,1/L +
,
w
1
1

P
kk1, L1 -norm weighted state relevance density , L(x) = wiL fi (x)
Lyapunov function inequality L(x) supa EP (x |x,a) [L(x )] holds, [0, 1)
denotes contraction factor, kk,1/L max-norm reweighted reciprocal 1/L.
Proof: Direct combination Theorem 3 Proposition 5.
6.2.2 Grid Resolution
Section 6.2.1, bounded error relaxed HALP formulation -infeasibility
(Theorem 6), measure constraint violation complete HALP. However, unclear
grid resolution relates -infeasibility. section, analyze relationship
. Moreover, show exploit factored structure constraint
b efficiently.
space achieve -infeasibility relaxed HALP solution w
b optimal -infeasible solution -HALP formulation
First, let us assume w
Z = XA joint set state action variables. derive bound
P relating
b
w
bi Fi (z) R(z)
, assume magnitudes constraint violations (z) = w
Lipschitz continuous.
Definition 4 function f (x) Lipschitz continuous if:




f (x) f (x ) K x x
x, x X;


(29)

K referred Lipschitz constant.

Based -grid discretization constraint space, know distance
point z closest grid point zG = arg minz kz z k bounded as:

kz zG k < .
2

(30)

b
Lipschitz continuity w
(z), conclude:



K
w

b
.
(z) K kzG zk
b (zG ) w
2

(31)

b
Since every constraint relaxed -HALP formulation satisfied, w
(zG ) nonnegative
b
grid points zG . result, Equation 31 yields w
(z) > K/2 every state-action
b -infeasible K/2.
pair z = (x, a). Therefore, based Definition 3, solution w
b guaranteed choosing 2/K.
Conversely, -infeasibility w
Unfortunately, K may increase rapidly dimensionality function. address
issue, use structure constraint space demonstrate
case. First, observe global Lipschitz constant Kglob additive local Lipschitz
constants correspond terms w
bi Fi (z) Rj (z). Moreover, Kglob N Kloc ,

178

fiSolving Factored MDPs Hybrid State Action Variables

Inputs:
hybrid factored MDP = (X, A, P, R)
basis functions f0 (x), f1 (x), f2 (x), . . .
initial basis function weights w(0)
separation oracle
Algorithm:
initialize relaxed HALP formulation empty set constraints
t=0
stopping criterion met
query oracle violated constraint (xO , aO ) respect w(t)
constraint (xO , aO ) violated
add constraint relaxed HALP
resolve LP new vector w(t+1)
t=t+1
Outputs:
basis function weights w(t)

Figure 9: Pseudo-code implementation HALP solver cutting plane method.
N denotes total number terms Kloc maximum local constants.
b achieved
Finally, parallel Equation 31, -infeasibility relaxed HALP solution w
discretization:


2
2

.
N Kloc
Kglob

(32)

Since factors w
bi Fi (z) Rj (z) often restricted small subsets state action
variables, Kloc change little size problem increases structure
fixed. prove Kloc bounded, bound weights w
bi . basis functions
unit magnitude, weights w
bi intuitively bounded |w
bi | (1)1 Rmax ,
Rmax denotes maximum one-step reward HMDP.
Based Equation 32, conclude number discretization points single
dimension 1/ + 1 bounded polynomial N , Kloc , 1/. Hence, constraint
space relaxed -HALP formulation involves O([N Kloc (1/)]|X|+|A| ) constraints,
|X| |A| denote number state action variables. idea variable elimination
used write constraints compactly O([N Kloc (1/)]T +1 (|X|+|A|)) constraints
(Example 3), treewidth corresponding cost network. Therefore, satisfying
constraint space polynomial N , Kloc , 1/, |X|, |A|, still exponential .
6.3 Cutting Plane Method
MC -HALP formulations (Sections 6.1 6.2) approximate constraint space
HALP finite set constraints C. Therefore, solved directly linear
programming solver. However, number constraints large, formulating solving
179

fiKveton, Hauskrecht, & Guestrin

Inputs:
hybrid factored MDP = (X, A, P, R)
basis functions f0 (x), f1 (x), f2 (x), . . .
basis function weights w
grid resolution
Algorithm:
discretize continuous variables XC AC (1/ + 1) equally-spaced values
identify subsets Xi Ai (Xj Aj ) corresponding domains Fi (x, a) (Rj (x, a))
evaluate Fi (xi , ai ) (Rj (xj , aj )) configurations xi ai (xj aj ) -grid
build cost network
P factored cost function:
w (x, a) = wi Fi (x, a) R(x, a)
find violated constraint cost network:
(xO , aO ) = arg minx,a w (x, a)
Outputs:
state-action pair (xO , aO )

Figure 10: Pseudo-code implementation -HALP separation oracle .
LPs complete set constraints infeasible. section, show build
relaxed HALP approximations efficiently cutting plane method.
cutting plane method solving HALP formulations outlined Figure 9. Briefly,
approach builds set LP constraints incrementally adding violated constraint
set every step. remainder paper, refer method returns
b separation oracle. Formally, every HALP
violated constraint arbitrary vector w
oracle approaches optimization problem:
h


h
b
b
arg min V w
(x) EP (x |x,a) V w
(x ) R(x, a) .
(33)
x,a

Consequently, problem solving hybrid factored MDPs efficiently reduces design
efficient separation oracles. Note cutting plane method (Figure 9) applied
suboptimal solutions Equation 33 correspond violated constraints.
presented approach directly used satisfy constraints relaxed -HALP
formulations (Schuurmans & Patrascu, 2002). Briefly, solver Figure 9 iterates
violated constraint found -HALP separation oracle (Figure 10) returns
violated constraint discretized cost network given intermediate solution w(t) .
Note although search violated constraint polynomial |X| |A|
(Section 6.2.2), running time solver (Guestrin, 2003). fact,
number generated cuts exponential |X| |A| worst case. However,
oracle embedded ellipsoid method (Khachiyan, 1979) yields polynomial-time
algorithm (Bertsimas & Tsitsiklis, 1997). Although technique impractical solving
large LPs, may conclude approach indeed polynomial-time implemented
particular way.
Finally, note searching violated constraint (Equation 33) application beyond satisfying constraint space HALP. instance, computation greedy
180

fiSolving Factored MDPs Hybrid State Action Variables

b
policy value function V w
:

h
ii
h
b
u(x) = arg max R(x, a) + EP (x |x,a) V w
(x )

h
ii
h
b
= arg min R(x, a) EP (x |x,a) V w
(x )


(34)

almost identical optimization problem, state variables X fixed. Moreover,
magnitude violated constraint equal lowest relaxed
b -infeasible (Equation 28):
HALP solution w
h
h
h
iii
b
b
= min V w
(x) max R(x, a) + EP (x |x,a) V w
(x )
x

h
ii
h
b
b
= min V w
(x) R(x, a) EP (x |x,a) V w
(x ) .
(35)
x,a

6.4 MCMC-HALP
practice, MC -HALP formulations (Sections 6.1 6.2) built blindly
selected set constraints C. specifically, constraints MC-HALP formulation
chosen randomly (with respect prior distribution ) -HALP formulation
based uniform -grid. discretized constraint space preserves original factored
structure, allows compact satisfaction. However, complexity solving
-HALP formulation exponential treewidth discretized constraint space. Note
discretized constraint space represented binary variables only, treewidth
increases multiplicative factor log2 1/ + 1, 1/ + 1 denotes number
discretization points single dimension. Consequently, even treewidth problem
relatively small, solving -HALP formulation becomes intractable small values .
address issues discussed approximations (Sections 6.1 6.2), propose
novel Markov chain Monte Carlo (MCMC) method finding violated constraint
relaxed HALP. procedure directly operates domains continuous variables,
takes account structure factored MDPs, space complexity proportional
number variables. separation oracle easily embedded ellipsoid
cutting plane method solving linear programs (Section 6.3), therefore constitutes
key step towards solving HALP efficiently. proceed, represent constraint
space HALP compactly state optimization problem finding violated constraints
factored representation.
6.4.1 Compact Representation Constraints
Section 3.3, showed factored representation constraint space allows
compact satisfaction. Following idea, define violation magnitude w (x, a):




(36)
w (x, a) = V w (x) EP (x |x,a) V w (x ) R(x, a)
X
=
wi [fi (x) gi (x, a)] + R(x, a),


measures amount solution w violates constraints complete
HALP. represent magnitude violation w (x, a) compactly influence diagram
181

fiKveton, Hauskrecht, & Guestrin

(ID), X decision nodes, X random variables. representation
built transition model P (X | X, A), factored captures independencies
among variables X, X , A. extend diagram three types reward nodes,
one term Equation 36: Hi = wi fi (x) every basis function, Gi = wi fi (x )
every backprojection, Rj = Rj (xj , aj ) every local reward function. construction
completed adding arcs graphically represent dependencies reward nodes
variables. Finally, verify that:


X
X
w (x, a) = EP (x |x,a) (Hi + Gi ) +
Rj .
(37)


j

Consequently, decision maximizes expected utility ID corresponds
violated constraint. graphical representation violation magnitude w (x, a)
4-ring network administration problem (Example 4) given Figure 2a. structure
constraint space identical Example 3 basis functions univariate.
conclude algorithm solving IDs applied find violated
constraint. However, methods (Cooper, 1988; Jensen et al., 1994; Ortiz, 2002)
restricted discrete variables. Fortunately, special properties ID representation
allow simplification. basis functions chosen conjugate transition
model (Section 5.2), obtain closed-form solution expectation term EP (x |x,a) [Gi ]
(Equation 18), random variables X marginalized diagram. new
representation contains random variables known cost network (Section 3.3).
Note problem finding violated constraint ID representation
also identical finding maximum posteriori (MAP) configuration random variables
Bayesian networks (Dechter, 1996; Park & Darwiche, 2001, 2003; Yuan et al., 2004).
latter problem difficult alternating summation maximization operators.
Since marginalized random variables X , solve maximization problem
standard large-scale optimization techniques.
6.4.2 Separation Oracle OMCMC
find violated constraint cost network, apply Metropolis-Hastings
(MH) algorithm (Metropolis et al., 1953; Hastings, 1970) propose Markov chain whose
invariant distribution converges vicinity arg maxz w (z), z = (x, a) value
assignment joint set state action variables Z = X A.
short, Metropolis-Hastings algorithm defines Markov chain transits
existing state z proposed state z acceptance probability:


p(z )q(z | z )

A(z, z ) = min 1,
,
(38)
p(z)q(z | z)
q(z | z) p(z) proposal distribution target density, respectively.
mild restrictions p(z) q(z | z), frequency state visits generated Markov
chain always converges target function p(z) (Andrieu et al., 2003). remainder
section, discuss choices p(z) q(z | z) solve optimization problem.5
5. introduction Markov chain Monte Carlo (MCMC) methods, refer work Andrieu et al.
(2003).

182

fiSolving Factored MDPs Hybrid State Action Variables

Target density: violation magnitude w (z) turned density transformation p(z) = exp[ w (z)]. Due monotonic character, p(z) retains set global
maxima w (z). Therefore, search arg maxz w (z)
PcanRbe done new function
p(z). prove p(z) density, demonstrate zD zC p(z) dzC normalizing
constant, zD zC discrete continuous parts value assignment z.
|ZC | . result, integral
RFirst, note integrand zC restricted space [0, 1]
zC p(z) dzC proper p(z) bounded, hence Riemann integrable finite.
prove p(z) = exp[ w (z)] bounded, bound magnitude violation w (z).
basis functions unit magnitude, weights w
bi bounded |w
bi | (1)1 Rmax
w
1
(Section 6.2.2), turn yields bound | (z)| (|w| (1) +1)Rmax . Therefore,
p(z) bounded treated density function.
find mode p(z), employ simulating annealing (Kirkpatrick et al., 1983)
generate non-homogeneous Markov chain whose invariant distribution equal p1/Tt (z),
Tt cooling schedule limt Tt = 0. weak regularity assumptions
p(z), p (z) probability density concentrates set global maxima
p(z) (Andrieu et al., 2003). cooling schedule Tt decreases Tt c/ ln(t + 1),
c problem-specific constant, chain Equation 38 converges vicinity
arg maxz w (z) probability converging 1 (Geman & Geman, 1984). However,
logarithmic cooling schedule slow practice, especially high initial temperature
c. overcome problem, select smaller value c (Geman & Geman, 1984)
required convergence criterion. Therefore, convergence chain global
optimum arg maxz w (z) longer guaranteed.
Proposal distribution: take advantage factored character Z adopt
following proposal distribution (Geman & Geman, 1984):


q(z | z) =



p(zi | zi ) zi = zi
,
0
otherwise

(39)

zi zi value assignments variables Zi original proposed
states. Zi discrete variable, conditional:
p(z1 , . . . , zi1 , zi , zi+1 , . . . , zn+m )
p(zi | zi ) = P
zi p(z1 , . . . , zi1 , zi , zi+1 , . . . , zn+m )

(40)

derived closed form. Zi continuous variable, closed form cumulative
density function unlikely exist. sample conditional, embed another MH
step within original chain. experimental section, use Metropolis algorithm
acceptance probability:


p(zi | zi )
,
A(zi , zi ) = min 1,
p(zi | zi )

(41)

zi zi original proposed values variable Zi . Note sampling
conditionals performed space w (z) locally.
183

fiKveton, Hauskrecht, & Guestrin

Inputs:
hybrid factored MDP = (X, A, P, R)
basis functions f0 (x), f1 (x), f2 (x), . . .
basis function weights w
Algorithm:
initialize state-action pair z(t)
t=0
stopping criterion met
every variable Zi
sample u U[0,1]
(t)
sample zi
| zi )
p(Z1/T

1 (z |z(t) )
p


u < min 1, 1/Tt 1 (t)
(t)
(zi |zi )

p

(t+1)

zi

= zi

else
(t+1)

(t)

zi
= zi
update Tt+1 according cooling schedule
t=t+1
(xO , aO ) = z(t)
Outputs:
state-action pair (xO , aO )

Figure 11: Pseudo-code implementation MCMC-HALP oracle OMCMC . symbol
U[0,1] denotes uniform distribution interval [0, 1]. Since testing
violated constraints (Figure 9) inexpensive, implementation MCMCHALP solver Section 7 tests constraints z(t) generated Markov chain
last one. Therefore, separation oracle OMCMC returns
one constraint per chain.

Finally, assuming zi = zi (Equation 39), derive non-homogenous Markov
chain acceptance probability:


A(z, z ) =
=
=
=

(

)
p1/Tt (z )q(z | z )
min 1, 1/T
p (z)q(z | z)
(
p1/Tt (z | zi )p1/Tt (zi )p(zi
min 1, 1/T
p (zi | zi )p1/Tt (zi )p(zi
(
p1/Tt (z | zi )p1/Tt (zi )p(zi
min 1, 1/T
p (zi | zi )p1/Tt (zi )p(zi
)
(
p1/Tt 1 (zi | zi )
,
min 1, 1/T 1
p (zi | zi )
184

| zi )
| zi )
| zi )
| zi )

)
)
(42)

fiSolving Factored MDPs Hybrid State Action Variables

converges vicinity violated constraint. Yuan et al. (2004) proposed
similar chain finding MAP configuration random variables Bayesian networks.
6.4.3 Constraint Satisfaction
MCMC-HALP separation oracle OMCMC (Figure 11) converges violated constraint
(not necessarily violated) polynomial time, ellipsoid method guaranteed
solve HALP formulations polynomial time (Bertsimas & Tsitsiklis, 1997). Unfortunately,
convergence chain within arbitrary precision requires exponential number steps
(Geman & Geman, 1984). Although bound loose practical interest, suggests
time complexity proposing violated constraints dominates time complexity
solving relaxed HALP formulations. Therefore, oracle OMCMC search violated
constraints efficiently. Convergence speedups directly apply work include hybrid
Monte Carlo (HMC) (Duane et al., 1987), Rao-Blackwellization (Casella & Robert, 1996),
slice sampling (Higdon, 1998).

7. Experiments
Experimental section divided three parts. First, show HALP solve simple
HMDP problem least efficiently alternative approaches. Second, demonstrate
scale-up potential framework compare several approaches satisfy constraint
space HALP (Section 6). Finally, argue solving constraint satisfaction problem
domains continuous variables without discretizing them.
experiments performed Dell Precision 380 workstation 3.2GHz Pentium
4 CPU 2GB RAM. Linear programs solved simplex method LP SOLVE
package. expected return policies estimated Monte Carlo simulation 100
trajectories. results randomized methods additionally averaged 10 randomly
initialized runs. Whenever necessary, present errors expected values. errors
correspond standard deviations measured quantities. discount factor 0.95.
7.1 Simple Example
illustrate ability HALP solve factored MDPs, compare L2 (Figure 4)
grid-based value iteration (Section 4.2) 4-ring topology network administration
problem (Example 4). experiments conducted uniform non-uniform grids
varying sizes. Grid points kept fixed compared methods, allows fair
comparison. value iteration methods iterated 100 steps terminated earlier
Bellman error drops 106 . L2 HALP methods approximate
optimal value function V linear combination basis functions, one computer
Xi (fi (x) = xi ), one every connection Xi Xj ring topology (fij (x) = xi xj ).
assume basis functions sufficient derive one-step lookahead policy
reboots least efficient computer. believe policy close-to-optimal
ring topology. constraint space complete HALP formulation approximated
MC-HALP -HALP formulations (Sections 6.1 6.2). state relevance density
function (x) uniform. experimental results reported Figure 12.
185

fiKveton, Hauskrecht, & Guestrin

N
8
91
625
561

-HALP
Reward Time
52.1 2.2
<1
52.1 2.2
<1
52.1 2.2
<1
52.1 2.2
2

Uniform -grid
L2 VI
Reward Time
52.1 2.2
2
52.1 2.2
7
52.1 2.2
55
52.1 2.2
577

47.6 2.2
<1
51.5 2.2
20
52.0 2.3 2 216

N
10
50
250
1 250

MC-HALP
Reward Time
45.2 5.1
<1
50.2 2.4
<1
51.5 2.4
<1
51.8 2.3
<1

Non-uniform grid
L2 VI
Reward Time
45.9 5.8
1
51.8 2.2
4
51.9 2.2
22
51.9 2.2
110

Grid-based VI
Reward Time
47.5 2.8
<1
48.7 2.5
<1
50.4 2.3
2
51.6 2.2
60


1
1/2
1/4
1/8 6

Heuristics
Policy
Reward
Dummy 25.0 2.8
Random 42.1 3.3
Server
47.6 2.2
Utopian 83.0

Grid-based VI
Reward Time

Figure 12: Comparison three approaches solving hybrid MDPs 4-ring topology
network administration problem (Example 4). methods compared
uniform non-uniform grids varying size (N ) expected discounted
reward policies computation time (in seconds).

verify solutions non-trivial, compare three heuristic policies:
dummy, random, server. dummy policy dummy (x) = a5 always takes dummy
action a5 . Therefore, establishes lower bound performance administrator.
random policy behaves randomly. server policy server (x) = a1 protects server
X1 . performance heuristics shown Figure 12. Assuming reboot
computers time step, utopian upper bound performance policy
derived as:
"
#


X
1


E
R(xt , (xt ))
max R(x , )
max E
1 x,a P (x |x,a)
t=0
Z
4
X
1

=
P (xj | x, a)x2
2P (x1 | x, a)x2
+
max
j dx
1
1 x,a x
j=2
Z
5
Pbeta (x | 20, 2)x2 dx

1 x
83.0.
(43)
analyze quality HALP solutions respect optimal value function
V (Section 5.1) one unknown.
Based results, draw following conclusions. First, grid-based value iteration
practical solving hybrid optimization problems even small size. main reason
space complexity method, quadratic number grid points N .
state space discretized uniformly, N exponential number state variables.
Second, quality HALP policies close L2 VI policies. result positive
since L2 value iteration commonly applied approximate dynamic programming. Third,
186

fiSolving Factored MDPs Hybrid State Action Variables

L2 HALP approaches yield better policies grid-based value iteration.
result due quality value function estimator. extremely good performance
= 1 explained monotonicity reward basis functions. Finally,
computation time L2 VI policies significantly longer computation time
HALP policies. Since step L2 value iteration (Figure 4) hard formulating
corresponding relaxed HALP, result comes surprise.
7.2 Scale-up Potential
illustrate scale-up potential HALP, apply three relaxed HALP approximations
(Section 6) solve two irrigation network problems varying complexity. problems
challenging state-of-the-art MDP solvers due factored state action spaces.
Example 6 (Irrigation network operator) irrigation network system irrigation channels connected regulation devices (Figure 13). goal irrigation network
operator route water channels optimize water levels whole system.
optimal levels determined type planted crop. simplicity exposition,
assume irrigation channels oriented size.
optimization problem formulated factored MDP. state network
completely observable represented n continuous variables X = {X1 , . . . , Xn },
variable Xi denotes water level i-th channel. time step, irrigation
network operator regulates devices Ai pump water every pair inbound
outbound channels. operation modes devices described discrete action
variables = {A1 , . . . , }. Inflow outflow devices (no inbound outbound channels)
controlled pump water network.
transition model reflects water flows irrigation network encoded locally
conditioning operation modes A:


P (Xij
= x | Par(Xij
)) Pbeta (x | , )

ij = ij +

X

= 46ij + 2
= 46(1 ij ) + 2

1ahij (Ai ) min(1 ij , min(xhi , ))

h

ij = xij

X

1aijk (Aj ) min(xij , j )

k

Xij represents water level regulation devices Ai Aj , 1ahij (Ai )
1aijk (Aj ) denote indicator functions water routing actions ahij aijk
devices Ai Aj , j highest tolerated flows devices.
short, transition model conserves water mass network adds variance

resulting state Xij
. introduced indexing state action variables explained
6-ring irrigation network Figure 14a. rest paper, assume inflow
0.1 inflow device Ai (i = 0.1), outflow 1 outflow device Aj (j = 1),
highest tolerated flow 1/3
P remaining devices Ak (k = 1/3).
reward function R(x, a) = j Rj (xj ) factored along individual irrigation channels
described univariate function:
Rj (xj ) = 2xj
187

fiKveton, Hauskrecht, & Guestrin

(a)

(b)

(c)

Figure 13: Illustrations three irrigation network topologies: a. 6-ring, b. 6-ring-of-rings,
c. 33 grid. Irrigation channels regulation devices represented
arrows rectangles. Inflow outflow nodes colored light dark
gray. ring ring-of-rings networks parameterized total number
regulation devices except last four (n).

outflow channel (one regulation devices must outflow), function:
Rj (xj ) =

N (xj | 0.4, 0.025) N (xj | 0.55, 0.05)
+
25.6
32

remaining channels (Figure 14b). Therefore, reward maintaining optimal
water levels pumping water irrigation network. Several examples irrigation
network topologies shown Figure 13.
Similarly Equation 43, derive utopian upper bound performance policy
arbitrary irrigation network as:
#
"
"
X
1

R(xt , (xt ))
E
0.2nin + (n nout )
1
t=0
#
Z
Pbeta (x | 46x + 2, 46(1 x) + 2)R(x ) dx ,
(44)
max
x

x

n total number irrigation channels, nin nout denote number inflow
outflow channels, respectively, R(x ) = N (x | 0.4, 0.025)/25.6+N (x | 0.55, 0.05)/32.
analyze quality HALP solutions respect optimal value function
V (Section 5.1) one unknown.
rest section, illustrate performance three HALP approximations,
MC-HALP, -HALP, MCMC-HALP (Section 6), ring ring-of-rings topologies
(Figure 13) irrigation network problem. constraints MC-HALP formulation
sampled uniformly random. establishes baseline HALP approximations.
-HALP MCMC-HALP formulations generated iteratively cutting plane
188

fiSolving Factored MDPs Hybrid State Action Variables

fi (xi )

0.6

Density

Reward

Nonoutflow channel

0.4
0.2
0

0

0.5

1

1

0.5

0.5

0

1

0

0

(a)

Density

Reward

1

0

0.5
Xj

1

(b)

0.5

0

1

0

fi+2n (xi )

Outflow channel
2

fi+n (xi )

1

1

0.5

0.5

0

0

0.5
Xi

0.5

1

fi+3n (xi )

0

1

0

0.5
Xi

1

(c)

Figure 14: a. Indexing used description transition function Example 6.
parameters h, i, j, k equal 6, 7, 10, 1, respectively. b. Univariate
reward functions water levels Xj (Example 6). c. Univariate basis functions
water levels Xi .

method. MCMC oracle OMCMC simulated 500 steps initial temperature
c = 0.2, leads decreasing cooling schedule T0 = 0.2 T500 0.02.
parameters selected empirically demonstrate characteristics oracle OMCMC
rather maximize performance. value function V approximated linear
combination four univariate piecewise linear basis functions channel (Figure 14c).
assume basis functions sufficient derive one-step lookahead policy
routes water channels water levels high low (Figure 14b).
believe policy close-to-optimal irrigation networks. state relevance
density function (x) uniform. experimental results reported Figures 1517.
Based results, draw following conclusions. First, HALP approximations
scale dimensionality solved problems. shown Figure 16, return
policies grows linearly n. Moreover, time complexity computing polynomial
n. Therefore, problem approximate solution structured, take advantage
structure avoid exponential blowup computation time. time,
quality policies deteriorating increasing problem size n.
Second, MCMC solver (N = 250) achieves highest objective values solved
problems. Higher objective values interpreted closer approximations constraint
space HALP since solvers operate relaxed formulations HALP. Third, quality
MCMC-HALP policies (N = 250) surpasses MC-HALP policies (N = 106 )
solvers consume approximately computation time. result due
informative search violated constraints MCMC-HALP solver. Fourth, quality
MCMC-HALP policies (N = 250) close -HALP policies ( = 1/16) although
significant difference objective values. analysis shows
shape value functions similar (Figure 17) differ weight
189

fiKveton, Hauskrecht, & Guestrin

Ring
topology
-HALP 1/4
=
1/8
1/16
MCMC
10
N=
50
250
MC
102
N=
104
106
Utopian

OV
24.3
55.4
59.1
60.9
70.1
70.7
16.2
40.8
51.2

n=6
n = 12
Reward Time
OV
Reward
34.6 2.0
11 36.2 53.9 2.7
39.6 2.5
41 88.1 61.5 3.5
40.3 2.6
281 93.2 62.6 3.4
30.3 4.9
38 86.3 47.6 6.3
40.2 2.6
194 110.3 62.4 3.5
40.2 2.6
940 112.0 63.0 3.4
25.0 5.1
< 1 16.9 41.9 5.6
37.9 2.8
10 52.8 58.8 3.5
39.4 2.7
855 67.1 60.3 3.8
49.1
79.2

Ring-of-rings
topology
-HALP 1/4
=
1/8
1/16
MCMC
10
N=
50
250
MC
102
N=
104
106
Utopian

OV
28.4
65.4
68.9
66.9
80.9
81.7
13.7
44.3
55.8

n=6
Reward
40.4 2.5
47.5 3.0
47.0 2.9
35.3 6.1
47.1 2.9
47.2 2.9
31.0 4.9
43.3 3.2
45.1 3.1
59.1

Time
85
495
4 417
60
309
1 522
<1
12
1 026

OV
44.1
107.9
113.1
94.6
131.9
134.1
15.4
59.0
75.1

Time
44
107
665
62
328
1 609
<1
18
1 415

OV
48.0
118.8
126.1
109.5
148.8
151.7
17.2
63.8
81.1

n = 18
Reward
74.3 2.9
84.3 3.8
86.3 3.8
56.8 7.4
85.0 3.6
85.4 3.8
51.8 8.8
75.9 6.6
82.9 3.8
109.2

Time
87
178
1 119
87
483
2 280
<1
31
1 938

n = 12
n = 18
Reward Time
OV
Reward Time
66.5 3.2
382 59.8 93.0 3.8
931
76.1 4.1 2 379 148.8 105.3 4.2 5 877
77.3 4.2 19 794 156.9 107.8 4.1 53 655
54.4 9.4
107 110.6 47.8 13.2
157
76.6 3.6
571 181.4 104.6 4.4
859
77.3 3.5 2 800 186.0 106.6 3.9 4 291
46.1 6.4
< 1 16.8 66.6 9.4
1
68.9 5.4
26 71.5 92.2 6.8
49
74.3 3.8 1 738 92.0 103.1 4.2 2 539
99.2
139.3

Figure 15: Comparison three HALP solvers two irrigation network topologies varying sizes (n). solvers compared objective value relaxed HALP
(OV), expected discounted reward corresponding policy, computation time (in seconds). -HALP, MCMC-HALP, MC-HALP solvers
parameterized resolution -grid (), number MCMC chains (N ),
number samples (N ). Note quality policies improves
higher grid resolution (1/) larger sample size (N ). Upper bounds
expected returns shown last rows tables.

constant basis function f0 (x) 1. Note increasing w0 affect quality
greedy policy V w . However, trick allows satisfaction constraint space
HALP (Section 5.1).
Finally, computation time -HALP solver seriously affected topologies
irrigation networks, explained follows. small large n,
time complexity formulating cost networks ring ring-of-rings topologies grows
rates 1/ + 12 1/ + 13 , respectively. Since -HALP method consumes
significant amount time constructing cost networks, quadratic (in 1/ + 1) time
complexity ring topology worsens cubic (in 1/ + 1) ring-of-rings topology.
hand, similar cross-topology comparison MCMC-HALP solver shows
computation times differ multiplicative factor 2. difference due
190

fiSolving Factored MDPs Hybrid State Action Variables

Ring topology
HALP
Reward

125
100

MCMC
125

f(n) = 3.823n + c
R2 = 1.000

100

125

f(n) = 3.766n + c
R2 = 1.000

100

75

75

75

50

50

50

6

9

12

15

18

1
0.75
Time

MC

0.5

9

12

15

18

1
f(n) = 0.019n + c
R2 = 0.998

0.75
0.5

0.25
0

6

9

12
n

15

18

0

6

9

12

15

18

15

18

15

18

15

18

1
f(n) = 0.031n + c
R2 = 0.999

0.75
0.5

0.25
6

f(n) = 3.594n + c
R2 = 0.999

f(n) = 0.025n + c
R2 = 0.999

0.25
6

9

12
n

15

18

0

6

9

12
n

Ring-of-rings topology
HALP
Reward

125
100

MCMC
125

f(n) = 5.092n + c
R2 = 1.000

100

75

9

12

15

18

24
Time

100

50
6

9

12

15

18

2
f(n) = 0.002n3 + c
R2 = 0.997

1.5
1

6

0.5

0

0

6

9

12
n

15

18

f(n) = 4.838n + c
R2 = 1.000

75

50
6

12

f(n) = 4.964n + c
R2 = 1.000

75

50

18

MC
125

6

9

12

2
f(n) = 0.064n + c
R2 = 0.998

1.5
1

f(n) = 0.035n + c
R2 = 0.998

0.5
6

9

12
n

15

18

0

6

9

12
n

Figure 16: Scale-up potential -HALP, MCMC-HALP, MC-HALP solvers two
irrigation network topologies varying sizes (n). graphs show expected
discounted reward policies computation time (in hours) functions
n. HALP solvers parameterized resolution -grid ( = 1/16),
number MCMC chains (N = 250), number samples (N = 106 ).
Note trends approximated polynomial f (n) (gray line)
high degree confidence (the coefficient determination R2 ), c denotes
constant independent n.

increased complexity sampling p(zi | zi ), results complex local
dependencies ring-of-rings topology treewidth.
proceed, note relaxed formulations (Figure 15) significantly less
constraints complete sets (Section 6.3). instance, MC-HALP formulation
(N = 106 ) 6-ring irrigation network problem originally established 106 randomly
sampled constraints. Based empirical results, constraints satisfied greedily
191

fiKveton, Hauskrecht, & Guestrin

MCHALP MCMCHALP

HALP

b (x)|
w
b
w
b
w
b
w
b
w
b
w
b
w
b
w
b
w
b
Vw
X1 V (x)| X2 V (x)| X3 V (x)| X4 V (x)| X5 V (x)| X6 V (x)| X7 V (x)| X8 V (x)| X9 V (x)| X10
2
1
0
2
1
0
2
1
0

0 0.5 1 0 0.5 1 0 0.5 1 0 0.5 1 0 0.5 1 0 0.5 1 0 0.5 1 0 0.5 1 0 0.5 1 0 0.5 1
X1
X2
X3
X4
X5
X6
X7
X8
X9
X10

b
Figure 17: Univariate projections V w
(x)|Xj =
b
w

P

i:Xj =Xi

w
bi fi (xi ) approximate value func-

tions V 6-ring irrigation network problem (Figure 13a). functions
learned 40 basis functions (Figure 14c) -HALP, MCMC-HALP,
MC-HALP solvers. solvers parameterized resolution -grid
( = 1/16), number MCMC chains (N = 250), number samples
b
(N = 106 ). Note univariate projections V w
(x)|Xj similar.
proximity greedy policies explained based observation.

-HALP
OV
Reward Time
1 30.4 48.3 3.0
9
1/2 42.9 58.7 3.1
342
1/4 49.1 61.9 3.1 9 443

MCMC
N
OV
Reward Time
10 45.3 43.6 6.5
83
50 116.2 72.2 3.6
458
250 118.5 73.2 3.7 2 012

MC
N OV
Reward Time
102 12.8 56.6 4.5
<1
104 49.9 53.4 5.9
19
106 71.7 70.3 3.9 1 400

Figure 18: Comparison three HALP solvers 3 3 grid irrigation network problem
(Figure 13). solvers compared objective value relaxed HALP
(OV), expected discounted reward corresponding policy, computation time (in seconds). -HALP, MCMC-HALP, MC-HALP solvers
parameterized resolution -grid (), number MCMC chains (N ),
number samples (N ). Note quality policies improves
higher grid resolution (1/) larger sample size (N ). upper bound
expected returns 87.2.

subset 400 constraints average (Kveton & Hauskrecht, 2004). Similarly, oracle
OMCMC MCMC-HALP formulation (N = 250) iterates 250500(10+10) =
2, 500, 000 state-action configurations (Figure 11). However, corresponding LP formulations
involve 700 constraints average.
7.3 Curse Treewidth
ring ring-of-rings topologies, treewidth constraint space (in continuous
variables) 2 3, respectively. result, oracle perform variable elimination
192

fiSolving Factored MDPs Hybrid State Action Variables

small , -HALP solver returns close-to-optimal policies. Unfortunately, small
treewidth atypical real-world domains. instance, treewidth complex
3 3 grid irrigation network (Figure 13c) 6. perform variable elimination = 1/16,
separation oracle requires space 1/ + 17 228 , memory limit
existing PCs. analyze behavior separation oracles (Section 6) setting,
repeat experiments Section 7.2 3 3 grid irrigation network.
Based results Figure 18, conclude time complexity -HALP
solver grows rate 1/ + 17 . Therefore, approximate constraint space satisfaction
(MC-HALP MCMC-HALP) generates better results combinatorial optimization
insufficiently discretized -grid (-HALP). conclusion parallel large
structured optimization problems continuous variables. believe combination
exact approximate steps delivers best tradeoff quality complexity
solutions (Section 6.4).

8. Conclusions
Development scalable algorithms solving real-world decision problems challenging
task. paper, presented theoretically sound framework allows compact
representation efficient solutions hybrid factored MDPs. believe results
applied variety optimization problems robotics, manufacturing, financial
mathematics. work extended several interesting directions.
First, note concept closed-form solutions expectations terms HALP
limited choices Section 5.2. instance, show P (x) f (x)
normal densities, EP (x) [f (x)] closed-form solution (Kveton & Hauskrecht, 2006b).
Therefore, directly reason normal transition functions instead approximating
mixture beta distributions. Similar conclusions true piecewise constant,
piecewise linear, gamma transition basis functions. Note efficient solutions
apply approach solving hybrid factored MDPs approximates optimal value
function linear combination basis functions (Equation 5).
Second, constraint space HALP (16) V w V w 0 exhibits structure
constraint space approximate policy iteration (API) (Guestrin et al., 2001; Patrascu
et al., 2002) kV w V w k , variable subject minimization. result,
work provides recipe solving API formulations hybrid state action domains.
discrete-state spaces, Patrascu et al. (2002) Guestrin (2003) showed API returns
better policies ALP set basis functions. Note API complex
ALP every step API involves satisfying constraint kV w V w k
fixed .
Third, automatic learning basis functions seems critical application HALP
real-world domains. Patrascu et al. (2002) analyzed problem discrete-state spaces
proposed greedy approach learning basis functions. Kveton Hauskrecht (2006a)
generalized ideas showed learn parametric basis functions hybrid spaces.
believe combination greedy search state space analysis (Mahadevan,
2005; Mahadevan & Maggioni, 2006) yield even better basis functions.
Finally, proposed several bounds (Section 5.1 6.2.1) may explain quality
complete relaxed HALP formulations. future, plan empirically evaluate
193

fiKveton, Hauskrecht, & Guestrin

tightness variety low-dimensional hybrid optimization problems (Bresina et al.,
2002; Munos & Moore, 2002) known optimal value functions.

Acknowledgment
work supported part National Science Foundation grants CMS-0416754
ANI-0325353. first author supported Andrew Mellon Predoctoral Fellowships
academic years 2004-06. first author also recognizes support Intel Corporation
summer 2005 2006.

Appendix A. Proofs
Proof Proposition 1: Bellman operator known contraction mapping.
Based monotonicity, value function V , V V implies V V V .
e
e
e
Since constraints HALP formulation (16) enforce V w
V w
, conclude V w
V .

Proof Proposition 2: Based Proposition 1, note constraint V w V w
guarantees V w V . Subsequently, claim proved realizing:
arg min E [V w ] = arg min E [V w V ]
w

w


E [V w V ] = E |V w V |
= E |V V w |
= kV V w k1, .
proof generalizes discrete-state case (de Farias & Van Roy, 2003) without
alternations.
Proof Theorem 2: Similarly Theorem 2 (de Farias & Van Roy, 2003), claim
proved three steps. First, find point w feasible region HALP

V w within O() distance V w , where:
w = arg min kV V w k
w




= V V w .


point w given by:

w = w +

(1 + )
e,
1

e = (1, 0, . . . , 0) indicator constant basis function f0 (x) 1. point
satisfies requirements feasibility handily verified solving:


(1 + )
(1 + )
w
w
w
w
V V
= V
+
V
+
1
1




= V w V w + (1 + )

0,
194

fiSolving Factored MDPs Hybrid State Action Variables

last step follows inequality:






w

w

w
w
V + V V
V V
V






w
w
= V V + V V




(1 + ).

Subsequently, bound max-norm error V w using triangle inequality:






w
w

w
V V w
+
V

V
V

V








1+

= 1+
1
2
,
=
1
e
yields bound weighted L1 -norm error V w
:





e
V V w 1,
V V w

1,


V V w
2

.
1

proof generalizes discrete-state case (de Farias & Van Roy, 2003) without
alternations.
Proof Theorem 3: Similarly Theorem 2, claim proved three steps: finding
point w feasible region HALP, bounding max-norm error V w ,
e
turn yields bound L1 -norm error V w
. comprehensive proof discretestate case done de Farias Van Roy (2003). proof generalizes structured
state action spaces continuous variables.
Proof Proposition 3: proposition proved sequence steps:
Z
Pbeta (x | , )xn (1 x)m dx
EP (x) [f (x)] =
Zx
( + ) 1
x
(1 x)1 xn (1 x)m dx
=
()()
x
Z
( + )
=
x+n1 (1 x)+m1 dx
()() x
Z
( + ) ( + n)( + m)
( + + n + m) +n1
=
x
(1 x)+m1 dx
()() ( + + n + m) x ( + n)( + m)
Z
( + ) ( + n)( + m)
=
Pbeta (x | + n, + m) dx .
()() ( + + n + m) x
{z
}
|
1

195

fiKveton, Hauskrecht, & Guestrin

Since integration distributive operation, claim straightforwardly generalizes
mixture beta distributions P (x).
Proof Proposition 4: proposition proved sequence steps:
Z
X
Pbeta (x | , )
1[li ,ri ] (x)(ai x + bi ) dx
EP (x) [f (x)] =
x

=

XZ




ri

Pbeta (x | , )(ai x + bi ) dx
li

X Z
=
ai


X
ai
=


X
ai
=


ri

Pbeta (x | , )x dx + bi

li


+

Z

Z

ri

li

ri


Pbeta (x | , ) dx

Pbeta (x | + 1, ) dx + bi
li

Z

ri

li


Pbeta (x | , ) dx



+
+
(F (ri ) F (li )) + bi (F (ri ) F (li )) .
+

Since integration distributive operation, claim straightforwardly generalizes
mixture beta distributions P (x).
Proof Proposition 5: claim proved three steps. First, construct point
b
w feasible region HALP V w within O() distance V w
.
point w given by:
b+
w=w


e,
1

e = (1, 0, . . . , 0) indicator constant basis function f0 (x) 1. point
satisfies requirements feasibility handily verified solving:




b
b
w
w
w
w
V V
= V +
V +
1
1
b
b
= Vw
V w
+

0,

b
b
inequality V w
V w
holds -infeasibility
w.
optimal
b
b eSince

e feasible relaxed HALP, conclude E V w
solution w
E V w
. Subsequently,
inequality yields bound weighted L1 -norm error V w :



w



b
w

V V
= E V +
V
1,
1
h


b
= E V w
+
E [V ]
1
h


e
E [V ]
E V w
+
1




e
.
= V V w
+
1
1,

196

fiSolving Factored MDPs Hybrid State Action Variables

Finally, combine result triangle inequality:







w
b
b
w
w
w

V V 1, + V V
V V
1,
1,


2

e
V V w
,
+
1
1,
b
leads bound weighted L1 -norm error V w
.

References
Andrieu, C., de Freitas, N., Doucet, A., & Jordan, M. (2003). introduction MCMC
machine learning. Machine Learning, 50, 543.
Astrom, K. (1965). Optimal control Markov processes incomplete state information.
Journal Mathematical Analysis Applications, 10 (1), 174205.
Bellman, R. (1957). Dynamic Programming. Princeton University Press, Princeton, NJ.
Bellman, R., Kalaba, R., & Kotkin, B. (1963). Polynomial approximation new computational technique dynamic programming: Allocation processes. Mathematics
Computation, 17 (82), 155161.
Bertsekas, D. (1995). counterexample temporal differences learning. Neural Computation, 7 (2), 270279.
Bertsekas, D., & Tsitsiklis, J. (1996). Neuro-Dynamic Programming. Athena Scientific,
Belmont, MA.
Bertsimas, D., & Tsitsiklis, J. (1997). Introduction Linear Optimization. Athena Scientific, Belmont, MA.
Boutilier, C., Dearden, R., & Goldszmidt, M. (1995). Exploiting structure policy construction. Proceedings 14th International Joint Conference Artificial
Intelligence, pp. 11041111.
Bresina, J., Dearden, R., Meuleau, N., Ramakrishnan, S., Smith, D., & Washington, R.
(2002). Planning continuous time resource uncertainty: challenge AI.
Proceedings 18th Conference Uncertainty Artificial Intelligence, pp.
7784.
Casella, G., & Robert, C. (1996). Rao-Blackwellisation sampling schemes. Biometrika,
83 (1), 8194.
Chow, C.-S., & Tsitsiklis, J. (1991). optimal one-way multigrid algorithm discretetime stochastic control. IEEE Transactions Automatic Control, 36 (8), 898914.
Cooper, G. (1988). method using belief networks influence diagrams. Proceedings
Workshop Uncertainty Artificial Intelligence, pp. 5563.
Crites, R., & Barto, A. (1996). Improving elevator performance using reinforcement learning. Advances Neural Information Processing Systems 8, pp. 10171023.
de Farias, D. P., & Van Roy, B. (2003). linear programming approach approximate
dynamic programming. Operations Research, 51 (6), 850856.
197

fiKveton, Hauskrecht, & Guestrin

de Farias, D. P., & Van Roy, B. (2004). constraint sampling linear programming approach approximate dynamic programming. Mathematics Operations
Research, 29 (3), 462478.
Dean, T., & Kanazawa, K. (1989). model reasoning persistence causation.
Computational Intelligence, 5, 142150.
Dechter, R. (1996). Bucket elimination: unifying framework probabilistic inference.
Proceedings 12th Conference Uncertainty Artificial Intelligence, pp.
211219.
Duane, S., Kennedy, A. D., Pendleton, B., & Roweth, D. (1987). Hybrid Monte Carlo.
Physics Letters B, 195 (2), 216222.
Feng, Z., Dearden, R., Meuleau, N., & Washington, R. (2004). Dynamic programming
structured continuous Markov decision problems. Proceedings 20th Conference Uncertainty Artificial Intelligence, pp. 154161.
Ferns, N., Panangaden, P., & Precup, D. (2005). Metrics Markov decision processes
infinite state spaces. Proceedings 21st Conference Uncertainty
Artificial Intelligence.
Geman, S., & Geman, D. (1984). Stochastic relaxation, Gibbs distribution, Bayesian
restoration images. IEEE Transactions Pattern Analysis Machine Intelligence, 6 (6), 721741.
Gordon, G. (1999). Approximate Solutions Markov Decision Processes. Ph.D. thesis,
Carnegie Mellon University.
Guestrin, C. (2003). Planning Uncertainty Complex Structured Environments.
Ph.D. thesis, Stanford University.
Guestrin, C., Hauskrecht, M., & Kveton, B. (2004). Solving factored MDPs continuous discrete variables. Proceedings 20th Conference Uncertainty
Artificial Intelligence, pp. 235242.
Guestrin, C., Koller, D., Gearhart, C., & Kanodia, N. (2003). Generalizing plans new
environments relational MDPs. Proceedings 18th International Joint
Conference Artificial Intelligence, pp. 10031010.
Guestrin, C., Koller, D., & Parr, R. (2001). Max-norm projections factored MDPs.
Proceedings 17th International Joint Conference Artificial Intelligence, pp.
673682.
Guestrin, C., Koller, D., & Parr, R. (2002). Multiagent planning factored MDPs.
Advances Neural Information Processing Systems 14, pp. 15231530.
Guestrin, C., Koller, D., Parr, R., & Venkataraman, S. (2003). Efficient solution algorithms
factored MDPs. Journal Artificial Intelligence Research, 19, 399468.
Guestrin, C., Venkataraman, S., & Koller, D. (2002). Context specific multiagent coordination planning factored MDPs. Proceedings 18th National Conference
Artificial Intelligence, pp. 253259.
Hastings, W. K. (1970). Monte Carlo sampling methods using Markov chains
application. Biometrika, 57, 97109.
198

fiSolving Factored MDPs Hybrid State Action Variables

Hauskrecht, M. (2000). Value-function approximations partially observable Markov
decision processes. Journal Artificial Intelligence Research, 13, 3394.
Hauskrecht, M., & Kveton, B. (2004). Linear program approximations factored
continuous-state Markov decision processes. Advances Neural Information Processing Systems 16, pp. 895902.
Higdon, D. (1998). Auxiliary variable methods Markov chain Monte Carlo applications. Journal American Statistical Association, 93 (442), 585595.
Howard, R., & Matheson, J. (1984). Influence diagrams. Readings Principles
Applications Decision Analysis, Vol. 2, pp. 719762. Strategic Decisions Group,
Menlo Park, CA.
Jeffreys, H., & Jeffreys, B. (1988). Methods Mathematical Physics. Cambridge University
Press, Cambridge, United Kingdom.
Jensen, F., Jensen, F., & Dittmer, S. (1994). influence diagrams junction trees.
Proceedings 10th Conference Uncertainty Artificial Intelligence, pp.
367373.
Khachiyan, L. (1979). polynomial algorithm linear programming. Doklady Akademii
Nauk SSSR, 244, 10931096.
Kirkpatrick, S., Gelatt, C. D., & Vecchi, M. P. (1983). Optimization simulated annealing.
Science, 220 (4598), 671680.
Koller, D., & Parr, R. (1999). Computing factored value functions policies structured MDPs. Proceedings 16th International Joint Conference Artificial
Intelligence, pp. 13321339.
Kveton, B., & Hauskrecht, M. (2004). Heuristic refinements approximate linear programming factored continuous-state Markov decision processes. Proceedings
14th International Conference Automated Planning Scheduling, pp. 306314.
Kveton, B., & Hauskrecht, M. (2005). MCMC approach solving hybrid factored
MDPs. Proceedings 19th International Joint Conference Artificial Intelligence, pp. 13461351.
Kveton, B., & Hauskrecht, M. (2006a). Learning basis functions hybrid domains.
Proceedings 21st National Conference Artificial Intelligence, pp. 11611166.
Kveton, B., & Hauskrecht, M. (2006b). Solving factored MDPs exponential-family
transition models. Proceedings 16th International Conference Automated
Planning Scheduling, pp. 114120.
Mahadevan, S. (2005). Samuel meets Amarel: Automating value function approximation
using global state space analysis. Proceedings 20th National Conference
Artificial Intelligence, pp. 10001005.
Mahadevan, S., & Maggioni, M. (2006). Value function approximation diffusion
wavelets Laplacian eigenfunctions. Advances Neural Information Processing
Systems 18, pp. 843850.
199

fiKveton, Hauskrecht, & Guestrin

Mahadevan, S., Maggioni, M., Ferguson, K., & Osentoski, S. (2006). Learning representation control continuous Markov decision processes. Proceedings 21st
National Conference Artificial Intelligence.
Manne, A. (1960). Linear programming sequential decisions. Management Science,
6 (3), 259267.
Metropolis, N., Rosenbluth, A., Rosenbluth, M., Teller, A., & Teller, E. (1953). Equation
state calculations fast computing machines. Journal Chemical Physics, 21,
10871092.
Munos, R., & Moore, A. (2002). Variable resolution discretization optimal control. Machine Learning, 49, 291323.
Ortiz, L. (2002). Selecting Approximately-Optimal Actions Complex Structured Domains.
Ph.D. thesis, Brown University.
Park, J., & Darwiche, A. (2001). Approximating MAP using local search. Proceedings
17th Conference Uncertainty Artificial Intelligence, pp. 403410.
Park, J., & Darwiche, A. (2003). Solving MAP exactly using systematic search. Proceedings 19th Conference Uncertainty Artificial Intelligence, pp. 459468.
Patrascu, R., Poupart, P., Schuurmans, D., Boutilier, C., & Guestrin, C. (2002). Greedy
linear value-approximation factored Markov decision processes. Proceedings
18th National Conference Artificial Intelligence, pp. 285291.
Puterman, M. (1994). Markov Decision Processes: Discrete Stochastic Dynamic Programming. John Wiley & Sons, New York, NY.
Rust, J. (1997). Using randomization break curse dimensionality. Econometrica,
65 (3), 487516.
Sanner, S., & Boutilier, C. (2005). Approximate linear programming first-order MDPs.
Proceedings 21st Conference Uncertainty Artificial Intelligence.
Schuurmans, D., & Patrascu, R. (2002). Direct value-approximation factored MDPs.
Advances Neural Information Processing Systems 14, pp. 15791586.
Schweitzer, P., & Seidmann, A. (1985). Generalized polynomial approximations Markovian decision processes. Journal Mathematical Analysis Applications, 110,
568582.
Sondik, E. (1971). Optimal Control Partially Observable Markov Decision Processes.
Ph.D. thesis, Stanford University.
Sutton, R., & Barto, A. (1998). Reinforcement Learning: Introduction. MIT Press,
Cambridge, MA.
Tesauro, G. (1992). Practical issues temporal difference learning. Machine Learning,
8 (3-4), 257277.
Tesauro, G. (1994). TD-Gammon, self-teaching backgammon program, achieves masterlevel play. Neural Computation, 6 (2), 215219.
Tesauro, G. (1995). Temporal difference learning TD-Gammon. Communications
ACM, 38 (3), 5868.
200

fiSolving Factored MDPs Hybrid State Action Variables

Trick, M., & Zin, S. (1993). linear programming approach solving stochastic dynamic
programs. Tech. rep., Carnegie Mellon University.
Van Roy, B. (1998). Planning Uncertainty Complex Structured Environments.
Ph.D. thesis, Massachusetts Institute Technology.
Yuan, C., Lu, T.-C., & Druzdzel, M. (2004). Annealed MAP. Proceedings 20th
Conference Uncertainty Artificial Intelligence, pp. 628635.
Zhang, W., & Dietterich, T. (1995). reinforcement learning approach job-shop scheduling. Proceedings 14th International Joint Conference Artificial Intelligence, pp. 11141120.
Zhang, W., & Dietterich, T. (1996). High-performance job-shop scheduling timedelay TD() network. Advances Neural Information Processing Systems 8, pp.
10241030.

201

fiJournal Artificial Intelligence Research 27 (2006) 419-439

Submitted 12/05; published 12/06

Engineering Note
FluCaP: Heuristic Search Planner First-Order MDPs
Steffen Holldobler
Eldar Karabaev
Olga Skvortsova

sh@iccl.tu-dresden.de
eldar@iccl.tu-dresden.de
skvortsova@iccl.tu-dresden.de

International Center Computational Logic
Technische Universitat Dresden, Dresden, Germany

Abstract
present heuristic search algorithm solving first-order Markov Decision Processes (FOMDPs). approach combines first-order state abstraction avoids evaluating states individually, heuristic search avoids evaluating states. Firstly,
contrast existing systems, start propositionalizing FOMDP
perform state abstraction propositionalized version apply state abstraction directly FOMDP avoiding propositionalization. kind abstraction referred
first-order state abstraction. Secondly, guided admissible heuristic, search
restricted states reachable initial state. demonstrate usefulness techniques solving FOMDPs system, referred FluCaP
(formerly, FCPlanner), entered probabilistic track 2004 International Planning Competition (IPC2004) demonstrated advantage planners
problems represented first-order terms.

1. Introduction
Markov decision processes (MDPs) adopted representational computational model decision-theoretic planning problems much recent work, e.g., Barto,
Bradtke, Singh (1995). basic solution techniques MDPs rely dynamic
programming (DP) principle (Boutilier, Dean, & Hanks, 1999). Unfortunately, classical dynamic programming algorithms require explicit enumeration state space grows
exponentially number variables relevant planning domain. Therefore,
algorithms scale complex AI planning problems.
However, several methods avoid explicit state enumeration developed
recently. One technique, referred state abstraction, exploits structure factored MDP representation solve problems efficiently, circumventing explicit state space
enumeration (Boutilier et al., 1999). Another technique, referred heuristic search,
restricts computation states reachable initial state, e.g., RTDP
Barto et al. (1995), envelope DP Dean, Kaelbling, Kirman, Nicholson (1995)
LAO Feng Hansen (2002). One existing approach combines techniques symbolic LAO algorithm Feng Hansen (2002) performs heuristic
search symbolically factored MDPs. exploits state abstraction, i.e., manipulates sets
states instead individual states. precisely, following SPUDD approach Hoey,
St-Aubin, Hu, Boutilier (1999), MDP components, value functions, policies,
admissible heuristic functions compactly represented using algebraic decision diagrams
c
2006
AI Access Foundation. rights reserved.

fiHolldobler, Karabaev & Skvortsova

(ADDs). allows computations LAO algorithm performed efficiently using
ADDs.
Following ideas symbolic LAO , given initial state, use admissible heuristic
restrict search states reachable initial state. Moreover,
exploit state abstraction order avoid evaluating states individually. Thus,
work much spirit symbolic LAO extends important way.
Whereas symbolic LAO algorithm starts propositionalization FOMDP,
performs state abstraction propositionalized version means
propositional ADDs, apply state abstraction directly structure FOMDP,
avoiding propositionalization. kind abstraction referred first-order state
abstraction.
Recently, following work Boutilier, Reiter, Price (2001), Holldobler Skvortsova
(2004) developed algorithm, referred first-order value iteration (FOVI)
exploits first-order state abstraction. dynamics MDP specified Probabilistic Fluent Calculus established Holldobler Schneeberger (1990),
first-order language reasoning states actions. precisely, FOVI produces
logical representation value functions policies constructing first-order formulae
partition state space clusters, referred abstract states. effect,
algorithm performs value iteration top clusters, obviating need explicit
state enumeration. allows problems represented first-order terms
solved without requiring explicit state enumeration propositionalization.
Indeed, propositionalizing FOMDPs impractical: number propositions grows considerably number domain objects relations.
dramatic impact complexity algorithms depends directly number propositions. Finally, systems solving FOMDPs rely propositionalizing
states also propositionalize actions problematic first-order domains,
number ground actions also grows dramatically domain size.
paper, address limitations proposing approach solving FOMDPs
combines first-order state abstraction heuristic search novel way, exploiting
power logical representations. algorithm viewed first-order generalization LAO , contribution show perform heuristic search
first-order MDPs, circumventing propositionalization. fact, show
improve performance symbolic LAO providing compact first-order MDP representation using Probabilistic Fluent Calculus instead propositional ADDs. Alternatively,
approach considered way improve efficiency FOVI algorithm
using heuristic search together symbolic dynamic programming.

2. First-order Representation MDPs
Recently, several representations propositionally-factored MDPs proposed,
including dynamic Bayesian networks Boutilier et al. (1999) ADDs Hoey et al.
(1999). instance, SPUDD algorithm Hoey et al. (1999) used solve
MDPs hundreds millions states optimally, producing logical descriptions value
functions involve hundreds distinct values. work demonstrates large
420

fiFluCaP: Heuristic Search Planner First-Order MDPs

MDPs, described logical fashion, often solved optimally exploiting logical
structure problem.
Meanwhile, many realistic planning domains best represented first-order terms.
However, existing implemented solutions first-order MDPs rely propositionalization, i.e., eliminate variables outset solution attempt instantiating terms
possible combinations domain objects. technique impractical
number propositions grows dramatically number domain objects
relations.
example, consider following goal statement taken colored Blocksworld
scenario, blocks, addition unique identifiers, associated colors.
G = X0 . . . X7 . red(X0 ) green(X1 ) blue(X2 ) red(X3 ) red(X4 )
red(X5 ) green(X6 ) green(X7 ) ower(X0 , . . . , X7 ) ,
ower(X0 , . . . , X7 ) represents fact eight blocks comprise one tower.
assume number blocks domain color distribution agrees
goal statement, namely eight blocks a, b, . . . , h domain,
four red, three green one blue. Then, full propositionalization
goal statement G results 4!3!1! = 144 different ground towers,
exactly many ways arranging four red, three green one blue block tower
eight blocks required color characteristics.
number ground combinations, hence, complexity reasoning propositional planner, depends dramatically number blocks and, importantly,
number colors domain. fewer colors domain contains, harder
solve propositional planner. example, goal statement G0 , G
above, eight blocks color, results 8! = 40320 ground towers,
grounded.
address limitations, propose concise representation FOMDPs within
Probabilistic Fluent Calculus logical approach modelling dynamically changing
systems based first-order logic. first, briefly describe basics theory
MDPs.
2.1 MDPs
Markov decision process (MDP), tuple (Z, A, P, R, C), Z finite set
states, finite set actions, P : Z Z [0, 1], written P(z 0 |z, a), specifies
transition probabilities. particular, P(z 0 |z, a) denotes probability ending
state z 0 given agent state z action executed. R : Z R realvalued reward function associating state z immediate utility R(z). C : R
real-valued cost function associating cost C(a) action a. sequential
decision problem consists MDP problem finding policy : Z
maximizes total expected discounted reward received executing policy
infinite (or indefinite) horizon.
value state z, starting z following policy afterwards,
computed following system linear equations:
X
V (z) = R(z) + C((z)) +
P(z 0 |z, (z))V (z 0 ),
z 0 Z

421

fiHolldobler, Karabaev & Skvortsova

0 1 discount factor. take equal 1 indefinite-horizon problems
only, i.e., goal reached system enters absorbing state
rewards costs accrued. optimal value function V satisfies:
X
V (z) = R(z) + max{C(a) +
P(z 0 |z, a)V (z 0 )} ,
aA

z 0 Z

z Z.
competition, expected total reward model used optimality criterion. Without discounting, care required design planning problems
ensure expected total reward bounded optimal policy. following
restrictions made problems used planning competition:
1. problem goal statement, identifying set absorbing goal states.
2. positive reward associated transitioning goal state.
3. cost associated action.
4. done action available states, could used end accumulation reward.
conditions ensure MDP model planning problem positive bounded
model described Puterman (1994). positive reward transitioning
goal state. Since goal states absorbing, is, outgoing transitions,
maximum value state bounded goal reward. Furthermore, done action
ensures action available state guarantees non-negative future
reward.
2.2 Probabilistic Fluent Calculus
Fluent Calculus (FC) Holldobler Schneeberger (1990) originally set
first-order logic program equality using SLDE-resolution sole inference rule.
Probabilistic Fluent Calculus (PFC) extension original FC expressing
planning domains actions probabilistic effects.
States
Formally, let denote set function symbols. distinguish two function symbols
, namely binary function symbol , associative, commutative, admits
unit element, constant 1. Let = \ {, 1}. Non-variable -terms
called fluents. function names fluents referred fluent names. example,
on(X, table) fluent meaning informally block X table,
fluent name. Fluent terms defined inductively follows: 1 fluent term;
fluent fluent term; F G fluent term, F G fluent terms. example,
on(b, table) holding(X) fluent term denoting informally block b table
block X robots gripper. words, freely occurring variables
assumed existentially quantified.
422

fiFluCaP: Heuristic Search Planner First-Order MDPs

assume fluent may occur state. Moreover, function
symbols, except binary operator, constant 1, fluent names constants,
disallowed. addition, binary function symbol allowed appear
outermost connective fluent term. denote set fluents F set fluent
terms LF , respectively. abstract state defined pair (P, N ), P LF
N LF . denote individual states z, z1 , z2 etc., abstract states Z, Z1 , Z2 etc.
set abstract states LP N .
interpretation F, denoted I, pair (, ), domain set
finite sets ground fluents F; interpretation function assigns
fluent term F set F abstract state Z = (P, N ) set Z
follows:
F = {d | .F d}
Z = {d | .P N N .
/ (N )I },
substitution. example, Figure 1 depicts interpretation abstract
state Z
Z = (on(X, a) on(a, table), {on(Y, X), holding(X 0 )})
informally read: exists block X block
table, block X exists block X 0
robot holds. Since Z contains finite sets ground fluents satisfy
P -part satisfy elements N -part, subtract sets ground
fluents belong Ni N set ground fluents correspond
P -part. Thus, bold area Figure 1 contains exactly sets ground
fluents (or, individual states) satisfy P -part Z none elements
N -part. example, individual state z1 = {on(b, a), on(a, table)} belongs Z ,
whereas z2 = {on(b, a), on(a, table), holding(c)} not. words, abstract states
characterized means conditions must hold ground instance thereof
and, thus, represent clusters individual states. way, abstract states embody
form state space abstraction. kind abstraction referred first-order state
abstraction.
Actions
Actions first-order terms starting action function symbol. example,
action picking block X another block might denoted pickup (X, ).
Formally, let Na denote set action names disjoint . action space tuple
= (A, Pre , Eff ), set terms form a(p1 , . . . , pn ), referred
actions, Na pi either variable, constant; Pre : LP N
precondition a; Eff : LP N effect a.
far, described deterministic actions only. actions PFC may
probabilistic effects well. Similar work Boutilier et al. (2001), decompose
stochastic action deterministic primitives natures control, referred natures
choices. use relation symbol choice/2 model natures choice. Consider action
pickup (X, ):
choice (pickup (X, ), A)
(A = pickupS (X, ) = pickupF (X, )) ,
423

fiHolldobler, Karabaev & Skvortsova

{on(b,a), on(a,table)}
{on(c,a), on(a,table), on(b,d)}
{on(b,a), on(a,table), holding(c)}
{on(c,a), on(a,table), on(b,c)}
{on(b,a), on(a,table)}
{on(c,a), on(a,table), on(b,d)}
{on(b,a), on(a,table), holding(c)}
{on(c,a), on(a,table), on(b,c)}

(b)

(a)
{on(b,a), on(a,table)}

{on(c,a), on(a,table), on(b,d)}
{on(b,a), on(a,table), holding(c)}
{on(c,a), on(a,table), on(b,c)}

(c)
Figure 1: (a) Interpretation fluent term F = on(X, a) on(a, table); (b) Bold area
interpretation abstract state Z 0 = (on(X, a) on(a, table), {on(Y, X)});
(c) Bold area interpretation abstract state Z = (on(X, a)
on(a, table), {on(Y, X), holding(X 0 )}).

424

fiFluCaP: Heuristic Search Planner First-Order MDPs

pickupS (X, ) pickupF (X, ) define two natures choices action pickup (X, ),
viz., succeeds fails. example, natures choice pickupS defined
follows:
Pre (pickupS (X, )) := (on(X, ) e, {on(W, X)})
Eff (pickupS (X, )) := (holding(X), {on(X, )}) ,
fluent e denotes empty robots gripper. simplicity, denote set
natures choices action Ch (a) := {aj |choice (a, aj )}. Please note nowhere
action descriptions restrict domain discourse pre-specified set
blocks.
natures choices aj associated action define probability
prob (aj , a, Z) denoting probability one natures choices aj chosen
state Z. example,
prob (pickupS (X, ), pickup (X, ), Z) = .75
states probability successful execution pickup action state Z
.75.
next step, define reward function state. example, might
want give reward 500 states block X block 0,
otherwise:
reward (Z) = 500 Z v (on(X, a), )
reward (Z) = 0 Z 6v (on(X, a), ) ,
v denotes subsumption relation, described detail Section 3.2.1.
One observe specified reward function without explicit state enumeration. Instead, state space divided two abstract states depending whether
not, block X block a. Likewise, value functions specified respect
abstract states only. contrast classical DP algorithms, states
explicitly enumerated. Action costs analogously defined follows:
cost(pickup (X, )) = 3
penalizing execution pickup -action value 3.
Inference Mechanism
Herein, show perform inferences, i.e., compute successors given abstract state,
action schemata directly, avoiding unnecessary grounding. note computation
predecessors performed similar way.
Let Z = (P, N ) abstract state, a(p1 , . . . , pn ) action parameters
p1 , . . . , pn , preconditions Pre (a) = (Pp , Np ) effects Eff (a) = (Pe , Ne ). Let
substitutions. action a(p1 , . . . , pn ) forward applicable, simply applicable, Z
, denoted forward (Z, a, , ), following conditions hold:
(f1) (Pp U1 ) =AC1 P
(f2) Np Np .N N .(P N U2 ) =AC1 (P Np ) ,
425

fiHolldobler, Karabaev & Skvortsova

U1 U2 new AC1-variables AC1 equational theory
represented following system associativity, commutativity, unit element
equations:
EAC1 = { (X, Y, Z) X (Y Z) = (X ) Z
(X, ) X = X
(X) X 1 = X
}.
words, conditions (f1) (f2) guarantee Z contains positive
negative preconditions action a. action forward applicable Z
Zsucc = (P 0 , N 0 ),
P 0 := (Pe U1 )
N 0 := N \ Np Ne

(1)

referred a-successor Z denoted succ(Z, a, , ).
example, consider action pickupS (X, ) defined above, take Z = (P, N ) =
(on(b, table) on(X1 , b) e, {on(X2 , X1 )}). action pickupS (X, ) forward applicable
Z = {X 7 X1 , 7 b, U1 7 on(b, table)} = {X2 7 W, U2 7 1}. Thus,
Zsucc = succ(Z, pickupS (X, ), , ) = (P 0 , N 0 )
P 0 = holding(X1 ) on(b, table) N 0 = {on(X1 , b)} .

3. First-Order LAO*
present generalization symbolic LAO algorithm Feng Hansen (2002),
referred first-order LAO (FOLAO ), solving FOMDPs. Symbolic LAO
heuristic search algorithm exploits state abstraction solving factored MDPs. Given
initial state, symbolic LAO uses admissible heuristic focus computation
parts state space reachable initial state. Moreover, specifies MDP
components, value functions, policies, admissible heuristics using propositional ADDs.
allows symbolic LAO manipulate sets states instead individual states.
Despite fact symbolic LAO shows advantageous behaviour comparison
classical non-symbolic LAO Hansen Zilberstein (2001) evaluates states
individually, suffers important drawback. solving FOMDPs, symbolic
LAO propositionalizes problem. approach impractical large FOMDPs.
intention show improve performance symbolic LAO providing
compact first-order representation MDPs heuristic search performed
without propositionalization. precisely, propose switch representational
formalism FOMDPs symbolic LAO propositional ADDs Probabilistic Fluent
Calculus. FOLAO algorithm presented Figure 2.
symbolic LAO , FOLAO two phases alternate complete solution
found, guaranteed optimal. First, expands best partial policy
evaluates states fringe using admissible heuristic function. performs
dynamic programming states visited best partial policy, update values
possibly revise current best partial policy. note focus partial policies
map subcollection states actions.
426

fiFluCaP: Heuristic Search Planner First-Order MDPs

policyExpansion(, 0 , G)
E := F :=
f rom := 0
repeat

{succ(Z, aj , , )},
:=
Zf rom aj Ch(a)

(a, , ) := (Z)
F := F (to G)
E := E f rom
f rom := G E
(f rom = )
E := E F
G := G F
return (E, F, G)
FOVI(E, A, prob, reward, cost, , V )
repeat
V 0 := V
loop Z E
loop
loop , forward (Z, a, , )
Q(Z, a, ,
P) := reward(Z) + cost(a)+

prob(aj , a, Z) V 0 (succ(Z, aj , , ))
aj Ch(a)

end loop
end loop
V (Z) := max Q(Z, a, , )
(a,,)

end loop
V := normalize(V )
r := kV V 0 k
stopping criterion
:= extractP olicy(V )
return (V, , r)
FOLAO (A, prob, reward, cost, , 0 , h, )
V := h
G :=
Z 0 , initialize arbitrary action
repeat
(E, F, G) := policyExpansion(, 0 , G)
(V, , r) := FOVI(E, A, prob, reward, cost, , V )
(F = ) r
return (, V )

Figure 2: First-order LAO algorithm.
policy expansion step, perform reachability analysis find set F states
yet expanded, reachable set 0 initial states
following partial policy . set states G contains states expanded
far. expanding partial policy mean defined larger set
states dynamic programming step. symbolic LAO , reachability analysis ADDs
performed means image operator symbolic model checking, computes
427

fiHolldobler, Karabaev & Skvortsova

set successor states following best current policy. Instead, FOLAO , apply
succ-operator, defined Equation 1. One observe since reachability
analysis FOLAO performed abstract states defined first-order entities,
reasoning successor states kept first-order level. contrast, symbolic
LAO would first instantiate 0 possible combinations objects, order
able perform computations using propositional ADDs later on.
contrast symbolic LAO , dynamic programming step performed using
modified version SPUDD, employ modified first-order value iteration algorithm
(FOVI). original FOVI Holldobler Skvortsova (2004) performs value iteration
entire state space. modify computes states reachable
initial states, precisely, set E states visited best current partial policy. way, improve efficiency original FOVI algorithm
using reachability analysis together symbolic dynamic programming. FOVI produces
PFC representation value functions policies constructing first-order formulae
partition state space abstract states. effect, performs value iteration
top abstract states, obviating need explicit state enumeration.
Given FOMDP value function represented PFC, FOVI returns best partial
value function V , best partial policy residual r. order update values
states Z E, assign values current value function successors
Z. compute successors respect natures choices aj . residual r
computed absolute value largest difference current newly
computed value functions V 0 V , respectively. note newly computed value
function V taken normalized form, i.e., result normalize procedure
described Section 3.2.1. Extraction best partial policy straightforward:
One simply needs extract maximizing actions best partial value function V .
symbolic LAO , FOLAO converges -optimal policy three conditions met: (1) current policy unexpanded states, (2) residual
r less predefined threshold , (3) value function initialized admissible heuristic. original convergence proofs LAO symbolic LAO Hansen
Zilberstein (2001) carry straightforward way FOLAO .
calling FOLAO , initialize value function admissible heuristic
function h focuses search subset reachable states. simple way create
admissible heuristic use dynamic programming compute approximate value
function. Therefore, order obtain admissible heuristic h FOLAO , perform
several iterations original FOVI. start algorithm initial value function
admissible. Since step FOVI preserves admissibility, resulting value
function admissible well. initial value function assigns goal reward
state thereby overestimating optimal value, since goal reward maximal possible
reward.
Since computations FOLAO performed abstract states instead individual
states, FOMDPs solved avoiding explicit state action enumeration propositionalization. first-order reasoning leads better performance FOLAO comparison
symbolic LAO , shown Section 4.
428

fiFluCaP: Heuristic Search Planner First-Order MDPs

= { Z 0 }
Z0

a11

a12

Z1
F,G
Z2

= { Z 1 , Z 2 }
F = {Z1,Z 2 }
E = { Z 0 , Z 1 , Z 2}
G = {Z1,Z 2 }

= { Z 0 }

Z1

Z0

G

FOVIA ({ Z 0 , Z 1 , Z 2})

a)

a21

Z2

a22

F
Z3

= { Z 2 }
Z0

= { Z 2 , Z 3 }
F = {Z3}
E = {Z0}

b)

= { Z 4 , Z 5 }
Z 1 F = { Z , Z ,Z }
4
5
3
,
,
{
Z
Z
Z
=
E
2
3 ,Z 4 ,Z 5 }
0
,
,
{
Z
=
Z
Z
G
G
3 ,Z 4 ,Z 5 }
2
1
a11

Z2
Z3

Z4
a12

F

c)

Z5

FOVIA ( { Z 0 , Z 2 , Z 3 , Z 4 , Z 5 } )

Figure 3: Policy Expansion.

3.1 Policy Expansion
policy expansion step FOLAO similar one symbolic LAO
algorithm. Therefore, illustrate expansion procedure means example. Assume start initial state Z0 two nondeterministic actions a1 a2
applicable Z0 , two outcomes a11 , a12 a21 , a22 , respectively. Without loss
generality, assume current best policy chooses a1 optimal action
state Z0 . construct successors Z1 Z2 Z0 respect outcomes a11
a12 action a1 .
fringe set F well set G states expanded far contain states Z1
Z2 only, whereas, set E states visited best current partial policy gets
state Z0 addition. See Figure 3a. next step, FOVI performed set E.
assume values updated way a2 becomes optimal action
Z0 . Thus, successors Z0 recomputed respect optimal action
a2 . See Figure 3b.
One observe one a2 -successors Z0 , namely Z2 , element
set G thus, contained already fringe F previous expansion
step. Hence, state Z2 expanded value recomputed. shown
Figure 3c, states Z4 Z5 a1 -successors Z2 , assumption a1
optimal action Z2 . result, fringe set F contains newly discovered
states Z3 , Z4 Z5 perform FOVI E = {Z0 , Z2 , Z3 , Z4 , Z5 }. state Z1
contained E, belong best current partial policy,
429

fiHolldobler, Karabaev & Skvortsova

dynamic programming step performed states visited best
current partial policy.
3.2 First-Order Value Iteration
FOLAO , first-order value iteration algorithm (FOVI) serves two purposes: First,
perform several iterations FOVI order create admissible heuristic h FOLAO .
Second, dynamic programming step FOLAO , apply FOVI states visited
best partial policy order update values possibly revise current
best partial policy.
original FOVI Holldobler Skvortsova (2004) takes finite state space
abstract states, finite set stochastic actions, real-valued reward cost functions,
initial value function input. produces first-order representation optimal
value function policy exploiting logical structure FOMDP. Thus, FOVI
seen first-order counterpart classical value iteration algorithm Bellman
(1957).
3.2.1 Normalization
Following ideas Boutilier et al. (2001), FOVI relies normalization state
space represents value function. normalization state space, mean
equivalence-preserving procedure reduces size state space. would
effect state space contains redundant entries, usually case symbolic
computations.
Although normalization considered important issue, done
hand far. best knowledge, preliminary implementation approach Boutilier et al. (2001) performs rudimentary logical simplifications
authors suggest using automated first-order theorem prover normalization task.
Holldobler Skvortsova (2004) developed automated normalization procedure
FOVI that, given state space, delivers equivalent one contains redundancy.
technique employs notion subsumption relation.
formally, let Z1 = (P1 , N1 ) Z2 = (P2 , N2 ) abstract states. Z1 said
subsumed Z2 , written Z1 v Z2 , exist substitutions
following conditions hold:
(s1) (P2 U1 ) =AC1 P1
(s2) N2 N2 .N1 N1 .(P1 N1 U2 ) =AC1 (P1 N2 ) ,
U1 U2 new AC1-variables. motivation notion subsumption
abstract states inherited notion -subsumption first-order clauses
Robinson (1965) difference abstract states contain complicated negative parts contrast first-order clauses.
example, consider two abstract states Z1 Z2 defined follows:
Z1 = (on(X1 , a) on(a, table), {red(Y1 )})
Z2 = (on(X2 , a), {red(X2 )}) ,
430

fiFluCaP: Heuristic Search Planner First-Order MDPs

N
0
1
2
3
4
5
6
7
8
9

Number states
Supdate
Snorm
9
6
24
14
94
23
129
33
328
39
361
48
604
52
627
54
795
56
811
59

Time, msec
Update Norm
144
1
393
3
884
12
1377
16
2079
46
2519
51
3268
107
3534
110
3873
157
4131
154

Runtime, msec

Runtime w/o norm, msec

145
396
896
1393
2125
2570
3375
3644
4030
4285

144
593
2219
13293
77514
805753
n/a
n/a
n/a
n/a

Table 1: Representative timing results first ten iterations FOVI.
Z1 informally asserts block X1 block table
blocks red. Whereas Z2 informally states block X2 block
X2 red. show Z1 v Z2 . relation holds since conditions (s1)
(s2) satisfied. Indeed,
(on(X2 , a) U1 ) =AC1 on(X1 , a) on(a, table)

(on(X1 , a) on(a, table) red(Y1 ) U2 ) = (on(X1 , a) on(a, table) red(X2 ))
= {X2 7 X1 , U1 7 on(a, table)} = {Y1 7 X1 , U2 7 1}.
One note subsumption language abstract states inherits complexity bounds -subsumption (Kapur & Narendran, 1986). Namely, deciding subsumption two abstract states NP-complete, general. However, Karabaev et al.
(2006) recently developed efficient algorithm delivers solutions subsumption problem case abstract states fluent terms.
purpose normalization, convenient represent value function
set pairs form hZ, i, Z abstract state real value. essence,
normalization algorithm seen exhaustive application following simplification rule value function V .
hZ1 , hZ2 ,
Z1 v Z2
hZ2 ,
Table 1 illustrates importance normalization algorithm providing representative timing results first ten iterations FOVI. experiments carried
problem taken colored Blocksworld scenario consisting ten blocks.
Even relatively simple problem FOVI normalization switched
scale beyond sixth iteration.
results Table 1 demonstrate normalization iteration
FOVI dramatically shrinks computational effort next iterations. columns
labelled Supdate Snorm show size state space performing value updates
431

fiHolldobler, Karabaev & Skvortsova

normalization, respectively. example, normalization factor, i.e., ratio
number Supdate states obtained performing one update step
number Snorm states obtained performing normalization step, seventh
iteration 11.6. means ninety percent state space contained
redundant information. fourth fifth columns Table 1 contain time Update
Norm spent performing value updates normalization, respectively.
total runtime Runtime, normalization switched on, given sixth column.
seventh column labelled Runtime w/o norm depicts total runtime FOVI
normalization switched off. would sum values seventh column
values sixth column sixth iteration inclusively, subtract latter
former divide result total time Norm needed performing normalization
first six iterations, would obtain normalization gain three
orders magnitude.

4. Experimental Evaluation
demonstrate advantages combining heuristic search together first-order
state abstraction system, referred FluCaP, successfully entered
probabilistic track 2004 International Planning Competition (IPC2004). experimental results obtained using RedHat Linux running 3.4GHz Pentium IV
machine 3GB RAM.
Table 2, present performance comparison FluCaP together symbolic
LAO examples taken colored Blocksworld (BW) scenario introduced
IPC2004.
main objective investigate whether first-order state abstraction using logic
could improve computational behaviour planning system solving FOMDPs.
colored BW problems main interest since ones represented
first-order terms hence ones allowed us make use first-order
state abstraction. Therefore, concentrated design domain-dependent
planning system tuned problems taken Blocksworld scenario.
colored BW problems differ classical BW ones that, along
unique identifier, block assigned specific color. goal formula, specified firstorder terms, provides arrangement colors instead arrangement blocks.
outset solving colored BW problem, symbolic LAO starts propositionalizing components, namely, goal statement actions. that, abstraction
using propositional ADDs applied. contrast, FluCaP performs first-order abstraction colored BW problem directly, avoiding unnecessary grounding. following,
show abstraction technique affects computation heuristic function.
create admissible heuristic, FluCaP performs twenty iterations FOVI symbolic
LAO performs twenty iterations approximate value iteration algorithm similar
APRICODD St-Aubin, Hoey, Boutilier (2000). columns labelled H.time
NAS show time needed computing heuristic function number abstract
states covers, respectively. comparison FluCaP, symbolic LAO needs evaluate
fewer abstract states heuristic function takes considerably time. One
432

fiFluCaP: Heuristic Search Planner First-Order MDPs

FluCaP

FluCaP

31.1
8.7
25.1
9.5
16.5
12.7
285.4
76.7
128.5 85.0
63.3
135.0
n/a
757.0
2813
718.3
443.6 1241
n/a
n/a
n/a
n/a
n/a
n/a
n/a
n/a
n/a
n/a

LAO*

LAO*

FluCaP

FOVI

FluCaP

LAO*

FluCaP

494 22.3 22.0 23.4
496 23.1 17.8 22.7
495 27.3 11.7 15.7
493 137.6 78.5 261.6
492 150.5 33.0 119.1
496 221.3 16.6 56.4
491 1644 198.1 2776
494 1265 161.6 1809
494 2210 27.3 317.7
n/a n/a 1212 n/a
n/a n/a 598.5 n/a
n/a n/a 215.3 1908
n/a n/a 1809 n/a
n/a n/a 3548 n/a

4.2
1.3
0.3
21.0
9.3
1.2
171.3
143.6
12.3
804.1
301.2
153.2
1733
1751

35
34
32
68
82
46
143
112
101
n/a
n/a
n/a
n/a
n/a

410
172
55
1061
539
130
2953
2133
425
8328
3956
2019
7276
15225

1077
687
278
3847
1738
902
12014
7591
2109
n/a
n/a
7251
n/a
n/a

0.86
0.86
0.86
7.05
7.05
7.05
65.9
65.9
65.9
n/a
n/a
n/a
n/a
n/a

0.82
0.68
0.66
4.24
6.50
6.24
23.6
51.2
61.2
66.6
379.7
1121
1.2 107
2.5 107

2.7
2.1
1.9
3.1
2.3
2.0
3.5
2.4
2.0
4.1
3.0
2.3
5.7
6.1

Table 2: Performance comparison FluCaP (denoted FluCaP) symbolic LAO
(denoted LAO*), cells n/a denote fact planner
deliver solution within time limit one hour. NAS NGS number
abstract ground states, respectively.

conclude abstract states symbolic LAO enjoy complex structure
FluCaP.
note that, comparison FOVI, FluCaP restricts value iteration smaller
state space. Intuitively, value function, delivered FOVI, covers larger
state space, time allocated heuristic search FluCaP
used performing additional iterations FOVI. results column labelled %
justify harder problem (that is, colors contains), higher
percentage runtime spent normalization. Almost test problems, effort spent
normalization takes three percent total runtime average.
order compare heuristic accuracy, present column labelled NGS
number ground states heuristic assigns non-zero values to. One see
heuristics returned FluCaP symbolic LAO similar accuracy, FluCaP
takes much less time compute them. reflects advantage plain first-order
abstraction comparison marriage propositionalization abstraction using
propositional ADDs. examples, gain several orders magnitude H.time.
column labelled Total time presents time needed solve problem.
time, planner must execute 30 runs initial state goal state. one-hour block
allocated problem. note that, comparison FluCaP, time required
heuristic search symbolic LAO (i.e., difference Total time H.time) grows
considerably faster size problem. reflects potential employing
433

%

FOVI

15
17

494
495
495
493
493
495
491
494
494
n/a
n/a
n/a
n/a
n/a

NGS, 103

NAS
FluCaP

8

494
495
495
493
492
494
491
494
494
490
490
492
486
481

H.time, sec.
LAO*

7

494
496
496
493
493
495
492
494
494
n/a
n/a
n/a
n/a
n/a

Total time, sec.

FluCaP

6

FOVI

5

C
4
3
2
4
3
2
4
3
2
4
3
2
3
4

FluCaP

B

Total av. reward
LAO*

Problem

fiHolldobler, Karabaev & Skvortsova

B
20
22
24
26
28
30
32
34
36

Total av. reward, 500
489.0
487.4
492.0
482.8
493.0
491.2
476.0
475.6
n/a

Total time, sec.
137.5
293.8
757.3
817.0
2511.3
3580.4
3953.8
3954.1
n/a

H.time, sec.
56.8
110.2
409.8
117.2
823.3
1174.0
781.8
939.4
n/a

NAS
711
976
1676
1141
2832
4290
2811
3248
n/a

NGS 1021
1.7
1.1 103
1.0 106
4.6 108
8.6 1011
1.1 1015
7.4 1017
9.6 1020
n/a

Table 3: Performance FluCaP larger instances one-color Blocksworld problems,
cells n/a denote fact planner deliver solution within
time limit.

first-order abstraction instead abstraction based propositional ADDs heuristic
search.
average reward obtained 30 runs, shown column Total av. reward,
planners evaluation score. reward value close 500 (which maximum possible
reward) simply indicates planner found reasonably good policy. time
number blocks B increases 1, running time symbolic LAO increases roughly
10 times. Thus, could scale problems seven blocks.
contrast FluCaP could solve problems seventeen blocks. note
number colors C problem affects efficiency abstraction technique.
FluCaP, C decreases, abstraction rate increases which, turn, reflected
dramatic decrease runtime. opposite holds symbolic LAO .
addition, compare FluCaP two variants. first one, denoted FOVI,
performs heuristic search all, rather, employs FOVI compute -optimal
total value function policy extracted. second one, denoted FluCaP ,
performs trivial heuristic search starting initial value function admissible
heuristic. expected, FluCaP combines heuristic search FOVI demonstrates
advantage plain FOVI trivial heuristic search. results illustrate
significance heuristic search general (FluCaP vs. FOVI) importance heuristic
accuracy, particular (FluCaP vs. FluCaP ). FOVI FluCaP scale problems
seven blocks.
Table 3 presents performance results FluCaP larger instances one-color
BW problems number blocks varying twenty thirty four. believe
FluCaP scale problems larger size implementation yet
well optimized. general, believe FluCaP system sensitive
size problem propositional planners are.
experiments targeted one-color problems are,
one hand, simplest ones us and, hand, bottleneck propositional
planners. structure one-color problems allows us apply first-order state abstraction full power. example, 34-blocks problem FluCaP operates
3.3 thousand abstract states explode 9.6 1041 individual states proposition434

fiFluCaP: Heuristic Search Planner First-Order MDPs

Total av. reward, 500
UMass

Michigan

Purdue1

Purdue2

Purdue3

Caracas

Toulouse

C
3
3
5
0
0
0
0
0
0

Dresden

B
5
8
11
5
8
11
15
18
21

Canberra

Problem

494.6
486.5
479.7
494.6
489.7
479.1
467.5
351.8
285.7

496.4
492.8
486.3
494.6
489.9
n/a
n/a
n/a
n/a

n/a
n/a
n/a
494.8
n/a
n/a
n/a
n/a
n/a

n/a
n/a
n/a
n/a
n/a
n/a
n/a
n/a
n/a

496.5
486.6
481.3
494.1
488.7
480.3
469.4
462.4
455.7

496.5
486.4
481.5
494.6
490.3
479.7
467.7
-54.9
455.1

495.8
487.2
481.9
494.4
490
481.1
486.3
n/a
459

n/a
n/a
n/a
494.9
488.8
465.7
397.2
n/a
n/a

n/a
n/a
n/a
494.1
n/a
n/a
n/a
n/a
n/a

Table 4: Official competition results colored non-colored Blocksworld scenarios.
May, 2004. n/a-entries table indicate either planner
successful solving problem attempt solve it.

alization. propositional planner must highly optimized order cope
non-trivial state space.
note additional colors larger instances (more 20 blocks) BW problems
cause dramatic increase computational time, consider problems
unsolved. One also observe number abstract states NAS increases
number blocks non-monotonically problems generated randomly.
example, 30-blocks problem happens harder 34-blocks one. Finally,
note results appear Tables 2 3 obtained using new version
evaluation software rely propositionalization contrast initial
version used competition.
Table 4 presents competition results IPC2004, FluCaP competitive
comparison planners colored BW problems. FluCaP perform
well non-colored BW problems problems propositional ones (that
is, goal statements initial states ground) FluCaP yet incorporate
optimization techniques applied modern propositional planners. contestants
indicated origin. example, Dresden - FluCaP, UMass - symbolic LAO etc.
pickup action cost 1, gain five points total reward means
plan contains ten fewer actions average. competition domains log files
available online appendix Younes, Littman, Weissman, Asmuth (2005).
Although empirical results presented work obtained
domain-dependent version FluCaP, recently developed (Karabaev et al.,
2006) efficient domain-independent inference mechanism core domainindependent version FluCaP.
435

fiHolldobler, Karabaev & Skvortsova

5. Related Work
follow symbolic DP (SDP) approach within Situation Calculus (SC) Boutilier
et al. (2001) using first-order state abstraction FOMDPs. One difference
representation language: use PFC instead SC. course symbolic value iteration, state space may contain redundant abstract states dramatically affect
algorithms efficiency. order achieve computational savings, normalization must performed remove redundancy. However, original work Boutilier et al. (2001)
done hand. best knowledge, preliminary implementation
SDP approach within SC uses human-provided rewrite rules logical simplification.
contrast, Holldobler Skvortsova (2004) developed automated normalization
procedure FOVI incorporated competition version FluCaP brings
computational gain several orders magnitude. Another crucial difference
algorithm uses heuristic search limit number states policy computed.
ReBel algorithm Kersting, van Otterlo, De Raedt (2004) relates FOLAO
also uses representation language simpler Situation Calculus.
feature makes state space normalization computationally feasible.
motivation, approach closely connected Relational Envelope-based Planning
(REBP) Gardiol Kaelbling (2003) represents MDP dynamics compact set
relational rules extends envelope method Dean et al. (1995). However, REBP
propositionalizes actions first, afterwards employs abstraction using equivalenceclass sampling. contrast, FOLAO directly applies state action abstraction
first-order structure MDP. respect, REBP closer symbolic LAO
FOLAO . Moreover, contrast PFC, action descriptions REBP allow negation
appear preconditions effects. organization, FOLAO , symbolic LAO ,
similar real-time DP Barto et al. (1995) online search algorithm MDPs.
contrast, FOLAO works offline.
algorithms classified deductive approaches solving FOMDPs.
characterized following features: (1) model-based, (2)
aim exact solutions, (3) logical reasoning methods used compute abstractions.
note FOVI aims exact solution FOMDP, whereas FOLAO , due
heuristic search avoids evaluating states, seeks approximate solution.
Therefore, would appropriate classify FOLAO approximate deductive
approach FOMDPs.
another vein, research developing inductive approaches solving
FOMDPs, e.g., Fern, Yoon, Givan (2003). authors propose approximate
policy iteration (API) algorithm, replace use cost-function approximations
policy representations API direct, compact state-action mappings, use
standard relational learner learn mappings. effect, Fern et al. provide policylanguage biases enable solution large relational MDPs. inductive approaches
characterized following features: (1) model-free, (2) aim
approximate solutions, (3) abstract model used generate biased samples
underlying FOMDP abstract model altered based them.
recent approach Gretton Thiebaux (2004) proposes inductive policy construction algorithm strikes middle-ground deductive inductive tech436

fiFluCaP: Heuristic Search Planner First-Order MDPs

niques. idea use reasoning, particular first-order regression, automatically
generate hypothesis language, used input inductive solver.
approach Gretton Thiebaux related SDP approach sense
first-order domain specification language well logical reasoning employed.

6. Conclusions
proposed approach combines heuristic search first-order state abstraction solving FOMDPs efficiently. approach seen two-fold:
First, use dynamic programming compute approximate value function serves
admissible heuristic. heuristic search performed find exact solution
states reachable initial state. phases, exploit
power first-order state abstraction order avoid evaluating states individually.
experimental results show, approach breaks new ground exploring efficiency
first-order representations solving MDPs. comparison existing MDP planners
must propositionalize domain, e.g., symbolic LAO , solution scales better larger
FOMDPs.
However, plenty remaining done. example, interested
question extent optimization techniques applied modern propositional
planners combined first-order state abstraction. future competitions,
would like face problems goal and/or initial states partially defined
underlying domain contains infinitely many objects.
current version FOLAO targeted problems allow efficient
first-order state abstraction. precisely, problems polynomially translated PFC. example colored BW domain, existentially-closed
goal descriptions linearly translated equivalent PFC representation. Whereas
universally-closed goal descriptions would require full propositionalization. Thus, current version PFC less first-order expressive than, e.g., Situation Calculus. future,
would interesting study extensions PFC language, particular, find
trade-off PFCs expressive power tractability solution methods
FOMDPs based PFC.

Acknowledgements
grateful anonymous reviewers thorough reading previous versions paper. also thank Zhengzhu Feng fruitful discussions
providing us executable symbolic LAO planner. greatly appreciate
David E. Smith patience encouragement. valuable comments helped
us improve paper. Olga Skvortsova supported grant within Graduate Programme GRK 334 Specification discrete processes systems processes
operational models logics auspices Deutsche Forschungsgemeinschaft
(DFG).
437

fiHolldobler, Karabaev & Skvortsova

References
Barto, A. G., Bradtke, S. J., & Singh, S. P. (1995). Learning act using real-time dynamic
programming. Artificial Intelligence, 72 (1-2), 81138.
Bellman, R. E. (1957). Dynamic programming. Princeton University Press, Princeton, NJ,
USA.
Boutilier, C., Dean, T., & Hanks, S. (1999). Decision-theoretic planning: Structural assumptions computational leverage. Journal Artificial Intelligence Research,
11, 194.
Boutilier, C., Reiter, R., & Price, B. (2001). Symbolic Dynamic Programming FirstOrder MDPs. Nebel, B. (Ed.), Proceedings Seventeenth International Conference Artificial Intelligence (IJCAI2001), pp. 690700. Morgan Kaufmann.
Dean, T., Kaelbling, L., Kirman, J., & Nicholson, A. (1995). Planning time constraints
stochastic domains. Artificial Intelligence, 76, 3574.
Feng, Z., & Hansen, E. (2002). Symbolic heuristic search factored Markov Decision Processes. Dechter, R., Kearns, M., & Sutton, R. (Eds.), Proceedings Eighteenth
National Conference Artificial Intelligence (AAAI2002), pp. 455460, Edmonton,
Canada. AAAI Press.
Fern, A., Yoon, S., & Givan, R. (2003). Approximate policy iteration policy language
bias. Thrun, S., Saul, L., & Scholkopf, B. (Eds.), Proceedings Seventeenth Annual Conference Neural Information Processing Systems (NIPS2003), Vancouver,
Canada. MIT Press.
Gardiol, N., & Kaelbling, L. (2003). Envelope-based planning relational MDPs. Thrun,
S., Saul, L., & Scholkopf, B. (Eds.), Proceedings Seventeenth Annual Conference
Neural Information Processing Systems (NIPS2003), Vancouver, Canada. MIT
Press.
Gretton, C., & Thiebaux, S. (2004). Exploiting first-order regression inductive policy
selection. Chickering, M., & Halpern, J. (Eds.), Proceedings Twentieth Conference Uncertainty Artificial Intelligence (UAI2004), Banff, Canada. Morgan
Kaufmann.
Hansen, E., & Zilberstein, S. (2001). LAO*: heuristic search algorithm finds solutions
loops. Artificial Intelligence, 129, 3562.
Hoey, J., St-Aubin, R., Hu, A., & Boutilier, C. (1999). SPUDD: Stochastic Planning using
Decision Diagrams. Laskey, K. B., & Prade, H. (Eds.), Proceedings Fifteenth Conference Uncertainty Artificial Intelligence (UAI1999), pp. 279288,
Stockholm. Morgan Kaufmann.
Holldobler, S., & Schneeberger, J. (1990). new deductive approach planning. New
Generation Computing, 8, 225244.
Holldobler, S., & Skvortsova, O. (2004). Logic-Based Approach Dynamic Programming.
Proceedings Workshop Learning Planning Markov Processes
Advances Challenges Nineteenth National Conference Artificial Intelligence (AAAI04), pp. 3136, San Jose, CA. AAAI Press.
438

fiFluCaP: Heuristic Search Planner First-Order MDPs

Kapur, D., & Narendran, P. (1986). NP-completeness set unification matching
problems. Siekmann, J. H. (Ed.), Proceedings Eighth International Conference Automated Deduction (CADE1986), pp. 489495, Oxford, England. Springer
Verlag.
Karabaev, E., Ramme, G., & Skvortsova, O. (2006). Efficient symbolic reasoning firstorder MDPs. Proceedings Workshop Planning, Learning Monitoring
Uncertainty Dynamic Worlds Seventeenth European Conference
Artificial Intelligence (ECAI2006), Riva del Garda, Italy. appear.
Kersting, K., van Otterlo, M., & De Raedt, L. (2004). Bellman goes relational. Brodley,
C. E. (Ed.), Proceedings Twenty-First International Conference Machine
Learning (ICML2004), pp. 465472, Banff, Canada. ACM.
Puterman, M. L. (1994). Markov Decision Processes - Discrete Stochastic Dynamic Programming. John Wiley & Sons, Inc., New York, NY.
Robinson, J. (1965). machine-learning logic based resolution principle. Journal
Association Computing Machinery, 12 (1), 2341.
St-Aubin, R., Hoey, H., & Boutilier, C. (2000). APRICODD: Approximate policy construction using decision diagrams. Leen, T. K., Dietterich, T. G., & Tresp, V. (Eds.),
Proceedings Fourteenth Annual Conference Neural Information Processing
Systems (NIPS2000), pp. 10891095, Denver. MIT Press.
Younes, H., Littman, M., Weissman, D., & Asmuth, J. (2005). first probabilistic track
International Planning Competition. Journal Artificial Intelligence Research,
24, 851887.

439

fiJournal Artificial Intelligence Research 27 (2006) 235297

Submitted 03/06; published 10/06

Modelling Mixed Discrete-Continuous Domains Planning
Maria Fox
Derek Long

maria.fox@cis.strath.ac.uk
derek.long@cis.strath.ac.uk

Department Computer Information Sciences
University Strathclyde,
26 Richmond Street, Glasgow, G1 1XH, UK

Abstract
paper present pddl+, planning domain description language modelling
mixed discrete-continuous planning domains. describe syntax modelling style
pddl+, showing language makes convenient modelling complex timedependent effects. provide formal semantics pddl+ mapping planning instances
constructs hybrid automata. Using syntax semantic model
construct semantic mapping labelled transition systems complete formal
interpretation pddl+ planning instances.
advantage building mapping pddl+ HA theory forms bridge
Planning Real Time Systems research communities. One consequence
expect make use theoretical properties HAs.
example, restricted class Reachability problem (which equivalent
Plan Existence) decidable.
pddl+ provides alternative continuous durative action model pddl2.1,
adding flexible robust model time-dependent behaviour.

1. Introduction
paper describes pddl+, extension pddl (McDermott & AIPS98 Planning Competition Committee, 1998; Fox & Long, 2003; Hoffmann & Edelkamp, 2005) family
deterministic planning modelling languages. pddl+ intended support representation mixed discrete-continuous planning domains. pddl developed McDermott (McDermott & AIPS98 Planning Competition Committee, 1998) standard
modelling language planning domains. later extended (Fox & Long, 2003)
allow temporal structure modelled certain restricting assumptions. resulting language, pddl2.1, extended include domain axioms timed initial
literals, resulting pddl2.2 (Hoffmann & Edelkamp, 2005). pddl2.1, durative actions
fixed-length duration discrete effects modelled. limited capability
model continuous change within durative action framework also provided.
pddl+ provides flexible model continuous change use autonomous processes events. modelling continuous processes also considered McDermott (2005), Herrmann Thielscher (1996), Reiter (1996), Shanahan (1990), Sandewall (1989) others knowledge representation reasoning
communities, well Henzinger (1996), Rasmussen, Larsen Subramani (2004),
Haroud Faltings (1994) others real time systems constraint-reasoning
communities.
c
2006
AI Access Foundation. rights reserved.

fiFox & Long

frequently used subset pddl2.1 fragment modelling discretised change.
part used 3rd International Planning Competition used basis
pddl2.2. continuous modelling constructs pddl2.1 adopted
community large, partly considered attractive natural
way represent certain kinds continuous change (McDermott, 2003a; Boddy, 2003).
wrapping continuous change inside durative actions pddl2.1 forces episodes change
variable coincide logical state changes. important limitation continuous
durative actions pddl2.1 therefore planning agent must take full control
change world, change without direct action part
agent.
key extension pddl+ provides ability model interaction
agents behaviour changes initiated world. Processes run time
continuous effect numeric values. initiated terminated either
direct action agent events triggered world. refer
three-part structure start-process-stop model. make distinction logical
numeric state, say transitions logical states instantaneous whilst
occupation given logical state endure time. approach takes transition
system view modelling change allows direct mapping languages
real time systems community modelling approach used (Yi, Larsen,
& Pettersson, 1997; Henzinger, 1996).
paper provide detailed discussion features pddl+, reasons
addition. develop formal semantics primitives terms formal
mapping pddl+ Henzingers theory hybrid automata (Henzinger, 1996).
Henzinger provides formal semantics means labelled transition system.
therefore adopt labelled transition semantics planning instances going
route. explain means plan valid showing plan
interpreted accepting run corresponding labelled transition system.
note that, certain constraints, Plan Existence problem pddl+ planning
instances (which corresponds Reachability problem corresponding hybrid automaton) remains decidable. discuss constraints utility modelling
mixed discrete-continuous planning problems.

2. Motivation
Many realistic contexts planning applied feature mixture discrete
continuous behaviours. example, management refinery (Boddy & Johnson,
2004), start-up procedure chemical plant (Aylett, Soutter, Petley, Chung, & Edwards, 2001), control autonomous vehicle (Leaute & Williams, 2005)
coordination activities planetary lander (Blake et al., 2004) problems
reasoning continuous change fundamental planning process.
problems also contain discrete change modelled traditional planning
formalisms. situations motivate need model mixed discrete-continuous domains
planning problems.
236

fiModelling Mixed Discrete-Continuous Domains Planning

present two motivating examples demonstrate discrete continuous behaviours interact yield interesting planning problems. Boddy Johnsons
petroleum refinery domain battery power model Beagle 2.
2.1 Petroleum refinery production planning
Boddy Johnson (2004) describe planning scheduling problem arising management petroleum refinement operations. objects problem include materials,
form hydrocarbon mixtures fractions, tanks processing units.
operation refinery mixtures fractions pass series processing
units including distillation units, desulphurisation units cracking units. Inside
units converted combined produce desired materials remove waste
products. Processes include filling emptying tanks, cases
happen simultaneously tank, treatment materials transfer
tanks. continuous components problem include process unit control settings,
flow volumes rates, material properties volumes time-dependent properties
materials combined tanks consequence refinement operations.
example demonstrating utility continuous model arises construction
gasoline blend. success gasoline blend depends chemical balance
constituents. Blending results materials pumped tanks
pipelines rates enable exact quantities required chemical constituents
controlled. example, diluting crude oil less sulphrous material
rate in-flow diluting material, volume tank, balanced
out-flow diluted crude oil perhaps refinement operations.
Boddy Johnson treat problem planning scheduling refinery operations
optimisation problem. Approximations based discretisation lead poor solutions,
leading financial motivation Boddy Johnsons application. observe,
moderately large refinery produce order half million barrels per day.
calculate 1% decrease efficiency, resulting approximation, could result
loss quarter million dollars per day. accurate model continuous
dynamics efficient cost-effective refinery.
Boddy Johnsons planning scheduling approach based dynamic constraint
satisfaction involving continuous, non-linear, constraints. domain-specific solver
constructed, demonstrating direct handling continuous problem components
realistic. Boddy Johnson describe applying solver real problem involving 18,000 continuous constraints including 2,700 quadratic constraints, 14,000 continuous
variables around 40 discrete decisions (Lamba, Dietz, Johnson, & Boddy, 2003; Boddy
& Johnson, 2002). interesting observe scale problem solvable,
optimality, reasonable computational effort.
2.2 Planning Activities Planetary Lander
Beagle 2, ill-fated probe intended surface Mars, designed operate within
tight resource constraints. constraint payload mass, desire maximise science
return rigours hostile Martian environment combine make essential
squeeze high performance limited energy time available mission.
237

fiFox & Long

One tightest constraints operations energy. Beagle 2, energy
stored battery, recharged solar power consumed instruments, on-board
processor, communications equipment heater required protect sensitive components
extreme cold Martian nights. features Beagle 2 common
deep space planetary landers.
performance battery solar panels subject variations due
ageing, atmospheric dust conditions temperature. Nevertheless, long periods
communication windows, lander achieve dense scientific data-gathering
activities carefully planned planning must performed nominal
model behaviour battery, solar panels instruments. state charge
battery lander falls within envelope defined maximum level capacity
battery minimum level dictated safety requirements lander.
safety requirement ensures enough power nightfall power heater
night operations achieve next communications session.
operations change state battery charge, causing follow continuous
curve within envelope. order achieve dense performance, operations
lander must pushed envelope tightly possible. equations
govern physical behaviour energy curve complex, approximation
possible tractable accurate discretised model
curve would be. refinery domain, approximation cost: coarser
approximation model, less accurately possible determine limits
performance plan.
paper refer simplified model domain, call Planetary
Lander Domain. details model presented Appendix C, discussed
Section 4.3.

2.3 Remarks
two examples plans must interact background continuous behaviours
triggered world. refinery domain concurrent episodes continuous change
(such filling emptying tank) affect variable (such sulphur
content crude oil tank), flow tank must carefully
controlled achieve mixture right chemical composition. Beagle 2 domain
power generation consumption processes act concurrently power supply
way must controlled avoid supply dropping critical minimal
threshold. domains continuous processes subject discontinuous first
derivative effects, resulting events triggered, actions executed processes
interacting. events trigger discontinuities might coincide end-points
actions. planner needs explicit model events might triggered
order able reason effects.
argue discretisation represents inappropriate simplification domains,
adequate modelling continuous dynamics necessary capture critical
features planning.
238

fiModelling Mixed Discrete-Continuous Domains Planning

3. Layout Paper
Section 4 explain pddl+ builds foundations pddl family languages. describe syntactic elements new pddl+ remind
reader representation language used expressing temporal plans family.
develop detailed example domain, battery power model planetary lander,
continuous modelling required properly capture behaviours
plan must interact. complete section formal proof showing pddl+
strictly expressive pddl2.1.
Section 5 explain theory hybrid automata relevant work,
provide key automaton constructs use development
semantics pddl+. Section 6 present mapping planning instances HAs.
using syntactic constructs HA semantic model.
Section 7 discuss subset Reachability problem decidable,
might interested models context planning. conclude
paper discussion related work.

4. Formalism
section present syntactic foundations pddl+, clarifying extend
foregoing line development pddl family languages. rely definitions
syntactic structures pddl2.1, call Core Definitions.
published 2003 (Fox & Long, 2003) repeat Appendix ease
reference.
pddl+ includes timed initial literal construct pddl2.2 (which provides syntactically convenient way expressing class events predicted
initial state). Although derived predicates powerful modelling concept,
far included pddl+. work required explore relationship
derived predicates start-process-stop model consider
paper.
4.1 Syntactic Foundations
pddl+ builds directly discrete fragment pddl2.1: is, fragment containing fixed-length durative actions. supplemented timed initial literals
pddl2.2 (Hoffmann & Edelkamp, 2005). introduces two new constructs: events processes. represented similar syntactic frames actions. elements
formal syntax relevant given (these read conjunction
BNF description pddl2.1 given Fox & Long, 2003).
<structure-def>
<structure-def>

::=:events <event-def>
::=:events <process-def>

following event Planetary Lander Domain. models transition
night day occurs clock variable daytime reaches zero.

239

fiFox & Long

(:event daybreak
:parameters ()
:precondition (and (not (day)) (>= (daytime) 0))
:effect (day)
)

BNF event identical actions, processes modified
allowing conjunction process effects effects field. process effect
structure continuous effect pddl2.1:
<process-effect>

::=(<assign-op-t> <f-head> <f-exp-t>)

following process taken Planetary Lander Domain. describes
battery state charge, soc, affected power demand exceeds supply.
interpretation process effects explained Section 4.2.
(:process discharging
:parameters ()
:precondition (> (demand) (supply))
:effect (decrease soc (* #t (- (demand) (supply))))
)

provide basic abstract syntactic structures form core pddl+
planning domain problem semantic mappings constructed.
Core Definition 1 defines simple planning instance actions structures describing state change. Definition 1 extends Core Definition 1 include events
processes. avoid repeating parts core definition unchanged
extended version.
Definition 1 Planning Instance planning instance defined pair
= (Dom, P rob)
Dom = (F s, Rs, As, Es, P s, arity) tuple consisting finite sets function
symbols, relation symbols, actions, function arity mapping symbols
respective arities, described Core Definition 1. addition contains finite sets
events Es processes P s.
Ground events, E, defined obvious generalisation Core Definition 6
defines ground actions. fact events required least one numeric
precondition makes special case actions. details ground processes, P,
given Definition 2. Processes continuous effects primitive numeric expressions
(PNEs). Core Definition 1 defines PNEs ground instances metric function expressions.
Definition 2 Ground Process p P ground process following
components:
Name process schema name together actual parameters.
240

fiModelling Mixed Discrete-Continuous Domains Planning

Time
0.01:
0.01:
0.71
0.9
15.02:
18.03:
19.51:
21.04:

Action
Action 1
Action 2
Action 3
Action 4
Action 5
Action 6
Action 7
Action 8

Duration
[13.000]

[1.000]
[1.000]
[1.000]

Figure 1: example pddl+ plan showing time stamp duration associated
action, applicable. Actions 2, 3, 4 7 instantaneous,
associated duration.

Precondition proposition, P rep , atoms either ground
atoms planning domain else comparisons terms constructed
arithmetic operations applied PNEs real values.
Numeric Postcondition numeric postcondition conjunction additive assignment propositions, NPp , rvalues1 expressions assumed
form (* #t exp) exp #t-free.
Definition 3 Plan plan, planning instance ground action set A, finite
set pairs Q>0 (where Q>0 denotes set positive rationals).
pddl family languages imposes restrictive formalism representation
plans. temporal members family, pddl2.1 (Fox & Long, 2003), pddl2.2 (Hoffmann & Edelkamp, 2005) pddl+, plans expressed collections time-stamped
actions. Definition 3 makes precise. actions durative plan also records
durations must execute. Figure 1 shows abstract example
pddl+ plan actions fixed-length durative actions (their durations shown square brackets action name). Plans report events
processes.
plans time stamps interpreted amount time elapsed since
start plan, whatever units used modelling durations timedependent effects.
Definition 4 Happening happening time point one discrete
changes occurs, including activation deactivation one continuous processes.
term used denote set discrete changes associated single time point.
1. Core Definition 3 defines rvalues right-hand sides assignment propositions.

241

fiFox & Long

4.2 Expressing Continuous Change
pddl2.1 time-dependent effect continuous change numeric variable expressed means intervals durative activity. Continuous effects represented
update expressions refer special variable #t. variable syntactic device marks update time-dependent. example, consider following two
processes:
(:process heatwater
:parameters ()
:precondition (and (< (temperature) 100) (heating-on))
:effect (increase (temperature) (* #t (heating-rate)))
)
(:process superheat
:parameters ()
:precondition (and (< (temperature) 100) (secondaryburner-on))
:effect (increase (temperature) (* #t (additional-heating-rate)))
)

processes active (that is, water heating secondary
burner applied water yet boiling) lead combined effect equivalent
to:
dtemperature
= (heating-rate) + (additional-heating-rate)
dt
Actions continuous update expressions effects represent increased
level modelling power provided fixed length, discrete, durative actions.
pddl+ continuous update expressions restricted occur process effects.
Actions events, instantaneous, restricted expression discrete
change. introduces three-part modelling periods continuous change: action
event starts period continuous change numeric variable expressed means
process. action event finally stops execution process terminates
effect numeric variable. goals plan might achieved active
process stopped.
Notwithstanding limitations durative actions, observed Boddy (2003)
McDermott (2003a), modelling continuous change, durative action model
convenient capturing activities endure time whose internal structure
irrelevant plan. includes actions whose fixed duration might depend
values parameters. example, continuous activities riding bicycle (whose
duration might depend start destination ride), cleaning window
eating meal might conveniently modelled using fixed-length durative actions. pddl+
force modeller represent change lower level abstraction
required adequate capture domain. activities need modelled
fixed duration actions might suffice.
following durative action, taken Planetary Lander Domain, illustrates durative actions used alongside processes events unnecessary expose internal structure associated activity. case, action
models preparation activity represents pre-programmed behaviour. constants
242

fiModelling Mixed Discrete-Continuous Domains Planning

partTime1 B-rate defined initial state duration schedule effects
within specified interval behaviour known advance application
prepareObs1 action.
(:durative-action prepareObs1
:parameters ()
:duration (= ?duration (partTime1))
:condition (and (at start (available unit))
(over (> (soc) (safelevel))))
:effect (and
(at start (not (available unit)))
(at start (increase (demand) (B-rate)))
(at end (available unit))
(at end (decrease (demand) (B-rate)))
(at end (readyForObs1)))
)

4.3 Planetary Lander Example
present example pddl+ domain description, illustrating continuous
functions, driven interacting processes, events actions, constrain structure
plans. example based simplified model solar-powered lander. actions
system durative actions draw fixed power throughout operation.
two observation actions, observe1 observe2, observe two different
phenomena. system must prepare these, either using single long action,
called fullPrepare, using two shorter actions, called prepareObs1 prepareObs2,
specific one observation actions. shorter actions higher power
requirements execution single preparation action. lander required
execute observation actions communication link established (controlled
timed initial literal), sets deadline activities.
activities carried background fluctuating power supply.
lander equipped solar panels generate electrical power. generation
process governed position sun, night power generated,
rising smoothly peak midday falling back zero dusk. curve power
generation shown Figure 2. Two key events affect power generation: nightfall
generation process ends lander enters night operational mode. mode draws
constant power requirement heater used protect instruments, addition
requirements instruments. dawn night operations end generation restarts.
events triggered simple clock driven twin processes
power generation night operations reset events.
lander equipped battery, allowing store electrical energy charge.
solar panels producing power required instruments
lander, excess directed recharging battery (the charging process),
demand instruments exceeds solar power shortfall must
supplied battery (the discharging process). charging process follows
inverse exponential function, since rate charging proportional power devoted
charging also proportional difference maximum current levels
charge. Discharge occurs linearly rate determined current demands
lander activities. Since solar generation process non-linear function time
243

fiFox & Long

20
18
16

Power (Watts)

14
12
10
8
6
4
2
0
0

2

4

6
8
Time (hours dawn)

10

12

14

Figure 2: Graph power generated solar panels.
Charging
(Supply exceeds demand)
Supply


ff



ff




Discharging
(Demand exceeds supply)



ff






ff






ff






ff






ff






ff






ff




Demand



ff






Start plan

End plan


ff








ff








ff








ff








ff






Action


















fi






ff












fi
























ff












fi






















































ff









fi



















































ff












fi

Action B


ff




Action C



fi



ff



Dawn

Nightfall

Figure 3: abstracted example lander plan showing demand curve supply curve
period execution.

day, state charge battery follows complex curve discontinuities
rate change caused instantaneous initiation termination durative
instrument actions. Figure 3 shows example plan demand curve generates
compared supply period.
Figures 5 6 show graphs battery state charge two alternative plans
shown Figure 4. plans start hour dawn deadline set 10
hours later. parameters set ensure 15 hours daylight,
244

fiModelling Mixed Discrete-Continuous Domains Planning

2.6:
4.7:
6.8:
7.9:

0.1: (fullPrepare) [5]
5.2: (observe1) [2]
7.3: (observe2) [2]

(prepareObs1) [2]
(observe1) [2]
(prepareObs2) [1]
(observe2) [2]

Figure 4: Two alternative plans complete observations deadline.
plan must complete within two hours midday. battery begins 45% fully
charged.
Value

6
99.5197

15
fullPrepare

0
0

daybreak

d>s

observe1
5.1

observe2

-Time
10

Figure 5: Graph battery state charge (as percentage full charge) first plan.
timepoint marked > first point demand exceeds supply,
battery begins recharge. vertical lines mark points
processes affected. state charge falling interval
discharge process active rising charge process active.

lander subject critical constraint throughout activities: battery state
charge may never fall safety threshold. typical requirement remote
systems protect system failures unexpected problems intended
ensure always enough power survive human operators
opportunity intervene. threshold marked Figure 5, seen
state charge drops approximately 20%. lowest point graph
time 2.95 hours dawn, solar power generation matches instrument
demand. point discharging process ends generation process starts.
time point correspond start end activities lander
point explicitly selected planner. is, instead, point defined
intersection two continuous functions. order confirm satisfaction constraint,
state charge may never fall safety threshold, state charge must
monitored throughout activity. sufficient consider value
end points, state charge well minimum required, since curve
might dip well values middle.
use example illustrate points later paper. complete domain description initial state problem instance found Appendix C,
245

fiFox & Long

Value

6
98.1479

pObs1

0
0

obs1

daybreak

pObs2

obs2 -Time
10

Figure 6: Graph battery state charge (as percentage full charge) second plan.
previous case, discontinuities gradient state charge
correspond points charge discharge process changed
action (start end point) event.

two reports generated Val (Howey, Long, & Fox, 2004) available
online appendices associated paper.
4.4 Expressive Power pddl+
consider whether pddl+ represents real extension expressive power
pddl2.1. course, fragment pddl2.1 used competition
widely used since (the fragment restricted discrete durative actions) include parts express continuous change, without elements pddl2.1
certainly less expressive pddl+. section discuss differences
modelling continuous change using continuous durative action constructs pddl2.1,
modelling using start-process-stop model.
pddl2.1, complete continuous durative actions, comprises powerful modelling
language. Allowing continuous effects within flexible duration actions offers expressive
combination appears close processes events pddl+. essential difference languages arises separation, pddl+, changes
world directly enacted executive indirect changes
due physical processes consequences.
model physical processes consequences pddl2.1 requires addition
domain model artificial actions simulate way processes events
interact eachother direct actions executive. example, force
intervals abut, triggering event correctly modelled, requires artificial
actions force corresponding end points intervals synchronise. actions
must applied planner, since dynamic force indirect events
coincide way would coincide nature. earlier work (Fox & Long,
2004) show clips constructed pddl2.1 used achieve effect.
Clips prevent time passing end points actions modelling background
246

fiModelling Mixed Discrete-Continuous Domains Planning

Supply














































Start plan

End plan


























Demand















fi


fi


fi


fi


fi


fi


fi


fi


fi


fi


fi


fi






Action



fi


fi


fi







fi


fi


fi













fi


fi


fi


fi


fi


fi


fi


fi


fi















ff



ff



ff



ff



ff



ff



ff

Action B


ff



ff






ff

Plan activities





ff



ff



ff



ff



ff



ff



ff



ff



ff



















ff



ff



ff



ff



ff



ff



ff



ff



ff



ff



ff



ff



ff























C





C





Initiation action

C



C




Charging
Clip actions

N

C



Termination action
Discharging

Generation
Night operations

N
Simulation activities

Figure 7: illustration structure simulation activities required model
simple pddl+ plan pddl2.1. B actions, C charging
discharging processes, respectively.

behaviour world. example shown Figure 7 illustrates clips used
model interacting continuous effects pddl2.1 representation Planetary Lander
Domain.
example shows two activities executing backdrop continuous charging
discharging battery. bell-shaped curve represents solar power production, starts daybreak, reaches peak midday drops zero
nightfall. Two concurrent power-consuming activities, B, executing
daylight hours. stepped curve shows (cumulative) power requirements. pddl+
representation plan would contain two actions B processes
events governing power consumption production would triggered autonomously
would explicit plan. contrast, pddl2.1 representation
plan would contain durative actions episodes charge, C, discharge, D,
need precisely positioned (using clips) respect two activities
B. Clips required actions C fixed durations
joined together force respect underlying timeline. two dotted
rectangles figure depict pddl2.1 plan containing 28 action instances addition
B. these, four points simulating intersections supply
demand curves correspond end points actions B.
planner using pddl2.1 model forced construct points simulation
background behaviours. necessary clip actions would explicit plan.
seen, construction accurate simulation pddl2.1 far trivial.
Indeed, although issue highlight example, cases
247

fiFox & Long

simulation constructed consistent use -separation interfering
action effects. occurs events process interactions occur arbitrarily small
temporal separations. Even simulations constructed, lack distinction
direct indirect causes change means planner forced construct
simulated process event sequences though part plan constructing.
means planner required consider simulation components though
choice points plan construction, leading combinatorial blow
cost constructing plans.
explicit distinction actions events yields compact plan representation
pddl+. pddl2.1 plan, using simulation events processes, would contain
explicit representations every happening execution trace pddl+ plan.
fact pddl2.1 plan represents form constructive proof existence
execution trace pddl+ plan one way understand Theorem 1 below: work
validating pddl+ plan required construct proof pddl2.1 plan would
supply explicitly.
distinguishing direct action executive continuous behaviours physical world facilitate decomposition planning problem
discrete continuous components. decomposition admits use hybrid
reasoning techniques, including Mixed Integer Non-Linear Programming (MINLP) (Grossmann, 2002), Benders Decomposition (Benders, 1962), Branch-and-Bound approaches
relax discrete components domain continuous representations (Androulakis,
2001), techniques proved promising mixed discrete-continuous
problem-solving (Wu & Chow, 1995). contrast, trying treat hybrid problem using
purely discrete reasoning techniques seems likely result unmanageable combinatorial explosion. course, trade-offs cannot fully understood planners exist
tackling mixed discrete-continuous domains featuring complex non-linear change.
prove pddl+ formally greater expressive power pddl2.1.
Theorem 1 pddl+ strictly expressive pddl2.1.
Proof: demonstrate showing encode computation arbitrary
register machine (RM) language pddl+. instructions RM encoded
pddl+ events correct execution plan made depend termination
corresponding RM program. means general plan validation problem
pddl+ plans undecidable, pddl2.1 plans decidable.
pddl2.1 plans explicitly list points plan state transition occurs (as
actions) checked validity simulated execution. contrast, pddl+
plan leaves events implicit, plan cannot tested without identifying events
triggered confirming outcomes.
simulate arbitrary RM program, need action initiate execution
program:
(:action start
:parameters ()
:precondition ()
:effect (started))
248

fiModelling Mixed Discrete-Continuous Domains Planning

construct family events simulate execution program. use
encoding register machine three instructions: inc(j,k) increments
register j jumps instruction k, dec(j,k,z), tests register j jumps
instruction z zero otherwise decrements jumps instruction k,
HALT terminates program. assume instructions labelled 0, . . . , n
registers used labelled 0, . . . , m. also assume instruction 0 start
program.
(:event beginExection
:parameters ()
:precondition (started)
:effect
(and (not (started))
(in 0)))

instruction form: l:

inc(j,k) l label, construct:

(:event dol
:parameters ()
:precondition (in l)
:effect
(and (not (in l))
(in k)
(increase (reg j) 1)))

instruction form: l:

dec(j,k,z) construct:

(:event dol
:parameters ()
:precondition (in l)
:effect
(and (not (in l))
(when (= (reg j) 0) (in z))
(when (> (reg j) 0) (and (decrease (reg j) 1)
(in k)))))

Finally, instruction l:

HALT have:

(:event dol
:parameters ()
:precondition (in l)
:effect
(and (not (in l))
(halted)))

create initial state registers reg 0. . .reg initialised 0
goal halted. apparent plan:
1:

(beginExecution)

valid computation embedded RM halts. Therefore, general plan
validation system pddl+ would able solve halting problem.

Theorem 1 formal demonstration increase expressive power offered
pddl+. depends fact pddl+ plan defined exclude explicit indication
events processes triggered execution plan. might
argued artificial problem, two points consider. Firstly,
249

fiFox & Long

avoiding requirement events processes captured explicitly plan
remain agnostic nature reasoning planner might perform
phenomena. might planner synthesise approximation continuous process simplifies reasoning sufficiently accurate allow place
actions around process behaviour, would insufficient determine
precise moments process triggers events. Secondly, planner might able
determine collection processes events irrelevant valid execution
plan constructed solve problem, even though apparent pattern
processes events triggered execution plan. case,
requirement plan correctly explicitly captures background activity
unreasonable additional demand.
undecidability pddl+ validation problem need confronted practice.
certain restrictions imposed (no cascading events, functions restricted polynomials
exponentials), undermine ability capture realistic domains,
processes events underlying pddl+ plan efficiently simulated using well-known
numerical methods. (Fox, Howey, & Long, 2006) show numerical simulation
achieved pddl+ plan validator, VAL. validation procedure must simulate
processes events ensure critical values remain acceptable ranges throughout
plan (and satisfy conditions planned actions). restrictions sensible
apply, particular sequences events may triggered time point,
also forms continuous functions arise domain, prevent us
achieving close approximations realistic behaviours. Boddy Johnson (2004)
Hofmann Williams (2006) use linear quadratic approximations model complex
non-linear functions. use quartic approximation inverse exponential function
represent power dynamics model planetary lander (see Appendix C).
practice, although formal separation expressive power pddl+
pddl2.1, conceptual separation activities executive
world important feature pddl+.
present simple family domains illustrate pddl2.2 encodings grow
larger pddl+ domains encoding equivalent behaviours. difference arises
fact durative actions encapsulate way process starts,
also way concludes. means domains significant choice
different ways start end process, pddl2.1 encoding expands faster
corresponding pddl+ encoding. Consider pddl+ domain containing following
action process schemas:
(:action Ai
:parameters ()
:precondition (and (not (started)) (ai ))
:effect (and (started) (not (ai )) (assign (dur) dAi ))
)
(:action Bj
:parameters ()
:precondition (and (bj ) (= (C) (* (dur) dBj ))
250

fiModelling Mixed Discrete-Continuous Domains Planning

:effect (and (not (started)) (done))
)
(:process P
:parameters ()
:precondition (started)
:effect (increase (C) (* #t 1))
)
action schemas families Ai Bj , indexed j take values
{1, ..., n} j {1, ..., m} respectively. values dAi dBj (different) actioninstance-dependent constants. plan starting initial state {(ax ), (by )}, C = 0,
achieves done, must contain actions Ax , , separated exactly dAx .dBy .
encode equivalent durative action model requires action schema:

(:durative-action ABi,j
:parameters ()
:duration (= ?duration (* dAi dBj ))
:condition (and (at start (ai )) (at end (bj )))
:effect (and (at start (not (ai ))) (at end (done)))
)
seen, size encoding family pddl+ domains grows
O(n + m), corresponding size pddl2.2 encodings grows O(n.m).
need couple possible initiation process possible conclusion
process leads multiplicative growth. Reification propositions durative
action encoding used reduce encoding O(n + m) encoding,
ground action set continues grow O(n.m) compared O(n + m) growth
ground actions processes pddl+ model.
clear easier build plan given O(n.m) encoding,
provides ready-made solutions problem. However, trade-off explored lies
large representation tolerated obtain advantage general. always
possible compile parts solution problem problem representation,
price paid size encoding effort required construct it.
basis argue compact representation preferable. example
presented artificial example demonstrating theoretical difference expressive
powers pddl2.2 pddl+. remains seen whether phenomenon arises
practice realistic domains.

5. pddl+ Hybrid Automata
section discuss role Hybrid Automata relation pddl+. motivate
interest Hybrid Automata proceed describe detail.
251

fiFox & Long

5.1 Relevance HA Theory
Researchers concerned modelling real-time systems developed techniques
modelling reasoning mixed discrete-continuous systems (Yi et al., 1997; Henzinger, Ho, & Wong-Toi, 1995; Rasmussen et al., 2004). techniques become
well-established. theory hybrid automata (Henzinger, 1996; Gupta, Henziner, &
Jagadeesan, 1997; Henzinger & Raskin, 2000), focus interest
model-checking community years, provides underlying theoretical basis
work. discussed Section 2, central motivation extensions introduced
pddl+ enable representation mixed discrete-continuous domains. Therefore, theory hybrid automata provides ideal formal basis development
semantics pddl+.
Henzinger (1996) describes digital controller analogue plant paradigmatic
example mixed discrete-continuous system. discrete states (control modes)
dynamics (control switches) controller modelled vertices edges
graph. continuous states dynamics plant modelled vectors real
numbers differential equations. behaviour plant depends state
controller, vice versa: controller switches modes update
variables describe continuous behaviour plant hence bring
discrete changes state plant. continuous change state plant
affect invariant conditions control mode controller result control
switch.
similar way, pddl+ distinguishes processes, responsible continuous change,
events actions, responsible discrete change. Further, constraint pddl+,
numeric values appear values functions whose arguments drawn finite
domains, corresponds requirement made hybrid automata dimension
automaton finite.
important contribution work demonstrate pddl+ support succinct encodings deterministic hybrid automata use planning. expect
formal (semantics formal properties) practical (model-checking techniques) results Hybrid Automata theory able exploited planning community
addressing problem planning discrete-continuous planning domains. Indeed,
cross-fertilisation already beginning (Dierks, 2005; Rasmussen et al., 2004; Edelkamp,
2003).
5.2 Hybrid Automata
present relevant definition Hybrid Automaton Henzingers theory (Henzinger, 1996) used construction formal semantics
pddl+ planning domains.
Definition 5 Hybrid Automaton Hybrid Automaton H consists following components:
Variables. finite set X = {x1 , . . . , xn } real-valued variables. number n
called dimension H. write X set {x1 , . . . , xn } dotted variables,
252

fiModelling Mixed Discrete-Continuous Domains Planning

representing first derivatives continuous change, X 0 set {x01 , . . . , x0n }
primed variables, representing values conclusion discrete change.
Control Graph. finite directed graph hV, Ei. vertices V control modes.
edges E control switches.
Initial, invariant flow conditions. Three vertex labelling functions, init, inv,
f low, assign control mode v V three predicates. initial
condition init(v) predicate whose free variables X. invariant
condition inv(v) predicate whose free variables X. flow condition
f low(v) predicate whose free variables X X.
Jump conditions. edge labelling function jump assigns control
switch e E predicate. jump condition jump(e) predicate whose free
variables X X 0 .
H-Events. finite set h-events function, hevent : E , assigns
control switch h-event.
h-event referred Henzinger event, changed name
avoid terminological confusion events pddl+.
Figure 8 shows simple dynamic system expressed hybrid automaton.
initial, jump flow conditions necessarily satisfied unique valuations.
multiple valuations satisfy conditions possible behaviour
automaton non-deterministic.
observed Henzingers model needs extended, simple way,
include undefined value, , real-valued variables. pddl+ states
contain unassigned real-valued variables, shown Core Definition 2 defines
metric valuation state. role value allow situations
metric fluent created domain, given initial value. fluent
given undefined value attempts inspect assigned value
considered yield error. introduces semantic difficulties left
details modification implicit.
input language finite automaton defined set
sequences symbols alphabet, possible define input language
Hybrid Automaton. case, elements language called traces:
Definition 6 Trace Given Hybrid Automaton, H, h-event set , trace H
element language (R0 ) .
Informally, trace consists sequence h-events interleaved real values corresponding time periods h-events applied. time
h-event applied readily determined summing values time periods sequence point h-event appears: h-events take time execute. Note
definition require trace accepted Hybrid Automaton:
property traces consider Section 6.4.
minor point note definition trace allows traces
first transition occurs time 0. convention semantics pddl2.1 forbid
253

fiFox & Long

pumpon
pumprate measures flow rate tank
(0 pump off, P pump on)
maxthreshold = 10

.
waterlevel = pumprate

turn pump
Jump: waterlevel = waterlevel

.

Inv:
waterlevel < 10
Flow:

waterlevel = 0
pumpoff

.

waterlevel = P
pumpon

Inv:
waterlevel < 10
Flow:

turn pump
Jump: waterlevel = waterlevel
Inv:

flood
Jump:
waterlevel = 10
waterlevel = waterlevel

Flow:

.
waterlevel = 0
flooded

Figure 8: simple tank-filling situation modelled hybrid automaton. three
control modes three control switches. control switch flood jump
condition requires level exceed bath capacity. Flow conditions
govern change water level.

254

fiModelling Mixed Discrete-Continuous Domains Planning

THA

implies

Traces

interpretation
interpretation
representation
Planning
instance

Plans
implies

Figure 9: semantic mapping plans traces
actions occur time 0. reason discussed (Fox & Long, 2003), but,
briefly, order consistent model states hold interval
closed left open right, initial state (which holds time 0) must
persist non-zero interval. consequence, interested traces
action transitions time 0.

6. Semantics
section present semantics pddl+. begin explaining approach
proceed develop semantics incrementally.
6.1 Semantics pddl+
present semantics two stages. Section 6.2 give semantics planning instances terms Hybrid Automata, defining formal mapping planning
constructs constructs corresponding automata. Figure 9 illustrates syntactic
relationship pddl+ planning instance plans implies,
semantic relationships pddl+ instance corresponding Hybrid
Automaton plans implied model traces implied
automaton. pddl+ instance plans syntactic constructs HA
traces provide formal semantics. show that, whilst plans interpreted
traces, traces represented plans means abstraction events appearing
traces. figure represents first stage development formalisation. summarise, Section 6.3, Henzingers interpretation Hybrid Automata
terms labelled transition systems accompanying transition semantics. use
semantic step basis second stage formalism, shown Figure 13.
important distinction make planning models actions
events requires us introduce time-slip monitoring process (explained below),
used ensure events executed immediately preconditions satisfied.
Core Definition 4 define PNEs mapped vector position-indexed
~ = hX1 , ..., Xn i. purpose mapping allow us define manipvariables, X
ulate entire collection PNEs consistent way. collection given valuation
state shown Core Definition 2 logical metric components state
identified. updating function defined Core Definition 8 specifies relationship
255

fiFox & Long

must hold valuations PNEs application action.
Normalisation expressions use PNEs involves replacing PNEs
corresponding position-indexed variable denoting position valuation held within
state. performed semantic function N . Update expressions constructed
using primed form position-indexed variable lvalue2 effect, distinguish pre- post-condition values variable. mapping planning instances
Hybrid Automata make use collection position-indexed variables form
set metric variables constructed automaton. Definition 5, Henzinger uses
names X, X 0 X vectors variables, post-condition variables following
discrete updates derivatives variables continuous change, respectively.
order reduce potential confusion following, note use X, X 0
X Henzinger does, X1 , . . . , Xn names position-indexed variables
planning instance interpreted Xn+1 extra variable used represent
time-slip.
6.2 Semantics Planning Instance
following present semantics planning instance stages order
facilitate understanding. begin definition uniprocess planning instance
event-free uniprocess planning instance. introduce general concept
planning instance. definitions rely concept relevance actions, events
processes, present.
following definition uses interpretation preconditions defined Core Definition 9. core definition explains how, given proposition P logical state s,
truth proposition determined. N um(s, P ) predicate PNEs
domain. explained Core Definition 9, determine truth proposition
state, respect vector numeric values ~x, formal numeric parameters
proposition substituted values ~x resulting proposition evaluated
logical state. purpose Definition 7 identify actions, events processes
could applicable given logical state, values metric fluents appropriate
satisfy preconditions.
Definition 7 Relevance Actions, Events Processes ground action (event
e, process p) planning instance dimension n, relevant logical state
value ~x Rn N um(s, P rea )(~x) (N um(s, P ree )(~x) N um(s, P rep )(~x),
respectively).
Ps (Es ) set ground processes (events) relevant state s.
general, action, event process relevant particular (logical) state might
actually become applicable, since valuations numeric state arise
system logical state might include satisfy preconditions
corresponding transition.
construction HA, mappings described below, vertices control
graph subsets ground atoms therefore equivalent logical states. use
2. lvalue update expression variable left expression, value
expression right assigned.

256

fiModelling Mixed Discrete-Continuous Domains Planning

variable v denote vertex Pv (Ev ) denote processes (events) relevant
corresponding logical state.
given logical state subset relevant processes active, according
precise valuation metric fluents current state. first consider
restricted case one active process affects value variable
time, call uniprocess planning instance. proposition unary-contextflow(i,), defined below, used describe effects ith variable process ,
active. later extend definition concurrent case multiple
processes may contribute behaviour variable.
Definition 8 Uniprocess Planning Instance planning instance uniprocess planning instance if, metric variable, Xi , set processes affect value
Xi relevant state v, denoted Pv |Xi , contains processes whose preconditions pairwise
mutually exclusive. is, 1 , 2 Pv |Xi (1 6= 2 ) numeric state
N (P re1 ) N (P re2 ).
Definition 9 Unary-context-flow v logical state uniprocess planning instance
dimension n Pv |Xi unary-context-flow proposition defined follows.
Let effect Xi take form (increase Xi (* #t Qi )) expression Qi .
unary-context-flowv (i, ) = (N (P ) Xi = Qi )
begin presenting semantics event-free uniprocess planning instance
is, uniprocess planning instance contains events. extend definition
include events, present semantics uniprocess planning instance. Finally
introduce concurrent process effects definition semantics planning
instance.
Definition 10 Semantics Event-free Uniprocess Planning Instance eventfree uniprocess planning instance, = (Dom, P rob), interpreted Hybrid Automaton,
HI , follows:
Variables. variables HI X = {X1 , . . . , Xn }, n dimension
planning problem.
Control Graph. set vertices V formed subsets ground atoms
planning instance. set edges E contains edge e v v 0
iff action, a, relevant v and:
v 0 = (v Dela ) Adda
action associated edge e.
Initial, invariant flow conditions. vertex labelling function init defined
as:

f alse
v 6= Initlogical
V
init(v) =
N (Initnumeric ) {Xi = |Xi 6 N (Initnumeric )} otherwise
257

fiFox & Long

vertex labelling function inv proposition True.
vertex labelling function flow defined:
f low(v) = (

n
^

i=1

^

unary-context-flowv (i, ) (

Pv |Xi

^


N (P ) Xi = 0) )

Pv |Xi

Jump conditions. edge labelling function jump defined follows. Given
edge e vertex v, associated action a:
jump(e) = N (P rea ) U Fa (X) = X 0
U Fa updating function action a, defined Core Definition 8
specifies relationship must hold valuations PNEs
application action.
H-events. set names ground actions. edge labelling function
hevent : E assigns edge name action associated edge.
flow condition states that, variable, precondition one processes
could affect true process defines rate change (through unarycontext-flow proposition), else, none process preconditions satisfied
rate change variable zero.
illustrate construction present simple example. planetary lander
domain requires events cannot used example event-free model.
Consider pddl+ domain containing following actions process:
(:action startEngine
:precondition (stopped)
:effect (and (not (stopped))
(running))
)
(:action accelerate
:precondition (running)
:effect (increase (a) 1)
)
(:action decelerate
:precondition (running)
:effect (decrease (a) 1)
)
(:action stop
:precondition (and (= (v) 0) (running))
:effect (and (not (running))
(stopped)
(assign (a) 0))
)

258

fiModelling Mixed Discrete-Continuous Domains Planning

Inv: True
Flow:

startEngine
Jump: =
v = 0
= 0

d=0
v=0
a=0

accelerate
Jump: =
v = v
= +1
Inv: True
Flow:

d=v
v=a
a=0
running

stopped

stop
Jump:

v=0
=
v = 0
= 0
decelerate
Jump: =
v = v
= 1

Figure 10: hybrid automaton constructed translation event-free uniprocess
planning instance. ignore init function, simply asserts appropriate initial state particular problem instance.

(:process moving
:precondition (running)
:effect (and (increase (d) (* #t (v)))
(increase (v) (* #t (a))))
)

translation process described Definition 10 leads hybrid automaton shown
Figure 10. seen, two vertices, corresponding logical states
{stopped} {running}. four actions translate edges, edge linking vertex
action relevant one logical effects enacted.
metric effects actions encoded jump conditions associated edge, using
convention primed versions variables refer state following
transition. Note variables explicitly affected action constrained
take value transition transition:
metric equivalent strips assumption. stop action metric precondition
expressed jump condition transition, requiring velocity variable,
v, zero transition. stopped state process affect variables,
flow conditions simply assert variables zero rate change.
running state moving process relevant indeed, since preconditions,
active whenever system state. effect process expressed
flow conditions state show distance variable, d, changes
value velocity, v, changes turn value acceleration, a. constraints
create system differential equations describing simultaneous effects velocity
acceleration system.
259

fiFox & Long

consider case events included one process
active one fluent one time.
planning domains important distinguish state changes deliberately planned, called actions, those, called events, brought spontaneously world. distinction HA, control switches
called events. distinction complicates relationship plans traces,
plans contain control switches correspond actions. events
triggered evolution domain influence planned actions must
inferred added sequence actions order arrive corresponding traces.
Henzinger et al. (1998) discuss use -moves, transitions
labelled corresponding control-switch, special label . significance
transitions appear traces. trace corresponds
accepting run using -moves contain transitions labelled
elements . -moves appear time transitions, lengths
transitions accumulated single transition corresponding trace.
purpose silent transitions allow special book-keeping transitions
inserted automata used simulate automata syntactically richer
constraints, allowing various reducibility results demonstrated. convenient aspect
-moves affect traces transferred original
automata simulations.
pddl+, events similar -moves appear explicitly plans.
However, contrast -moves, applicable events always forced occur
actions may applied state.
extending event-free planning instances include events require mechanism
capturing fact events occur instant triggered
world, convenience planner. time must allowed pass
satisfaction event preconditions triggering event.
semantic models use variable measure amount time elapses
preconditions event becoming true event triggering. Obviously quantity,
call time-slip, must 0 valid planning instance. HA
construct associate invariant vertex control graph enforce
requirement. might appear simpler way handle events would simply assert
invariant condition state preconditions events false,
event represented outgoing transition jump condition specifying
precondition corresponding event. However, possible jump condition
transition inconsistent invariant state leaves since must
hold simultaneously time transition made.
variable used monitor time-slip planning instance dimension n
variable Xn+1 . variable operates clock tracking passage time event
becomes applicable. define time-slippage proposition switch clock whenever
preconditions event become true state. event applicable
clock switched off.
260

fiModelling Mixed Discrete-Continuous Domains Planning

Definition 11 Time-slippage planning instance dimension n variable Xn+1
called time-slip variable time-slippage defined follows.
_
time-slippage(R) = (Xn+1 = 0 Xn+1 = 1) (
N (P ree ) Xn+1 = 1)
eR

R set ground events.
use time-slip allows us model pddl+ domains directly Hybrid Automata
standard form. alternative would introduce modified definition Hybrid Automata makes explicit distinction controllable uncontrollable transitions
(actions events respectively) require uncontrollable transitions
always occur immediately jump conditions satisfied. approach would
lead essentially equivalent formalism, would complicate opportunity draw
existing body research Hybrid Automata, followed
time-slip approach.
interpretation Uniprocess Planning Instance extends interpretation
Event-free Uniprocess Planning Instance. added components underlined ease
comparison.
Definition 12 Semantics Uniprocess Planning Instance unary process planning instance = (Dom, P rob) interpreted Hybrid Automaton, HI , follows:
Variables. variables HI X = {X1 , . . . , Xn+1 }, n dimension
planning problem.
n + 1th variable special control variable used measure time-slip.
Control Graph. set vertices V formed subsets ground atoms
planning instance. set edges E contains edge e v v 0
iff action event, a, relevant v and:
v 0 = (v Dela ) Adda
action event associated edge e.
Initial, invariant flow conditions. vertex labelling function init defined
as:

f alse
v 6= Initlogical
V
init(v) =
N (Initnumeric ) {Xi = |Xi 6 N (Initnumeric )} otherwise
vertex labelling function inv simple proposition ensures time-slip zero.
inv(v) = (Xn+1 = 0)
vertex labelling function flow defined:
V
V
f low(v) = ( ni=1
unary-context-flowv (i, )

V Pv |Xi
( Pv |X N (P ) Xi = 0) time-slippage(Ev ))


261

fiFox & Long

Jump conditions. edge labelling function jump defined follows. Given
edge e vertex v, associated action a:
^
jump(e) = N (P rea ) U Fa (X) = X 0
N (P reev )
evEv

Given edge e vertex v, associated event ev:
jump(e) = N (P reev ) U Fev (X) = X 0
U Fa (U Fev ) updating function action (event ev) respectively.
H-events. set names ground actions events. edge
labelling function hevent : E assigns edge name action event
associated edge.
case, flow condition says thing event-free uniprocess planning
instance, additional constraint whenever precondition event
satisfied, time-slip variable must increase rate 1 (and may increase rate zero
otherwise). Since invariant condition every state insists time-slip variable
never greater 0, valid trace machine cannot rest state period
time preconditions event become true. also seen
jump condition action transitions asserts event preconditions must false.
ensures events always applied action transitions permitted.
extend preceding simple example domain include event, illustrate
construction described Definition 12:
(:event engineExplode
:parameters ()
:precondition (and (running) (>= (a) 1) (>= (v) 100))
:effect (and (not (running)) (assign (a) 0) (engineBlown))
)
corresponding machine shown Figure 11. structure machine
similar previous example, includes extra state, reachable event transition. addition event also requires addition time-slip variable, .
behaviour variable controlled, particular, new flow constraint
running state ensures event precondition becomes true time-slip
starts increase soon time passes. addition variable control
also propagates jump flow conditions states.
Finally consider case concurrent process effects occur must
combined. general case refer rest paper.
given logical state subset relevant processes active, according
precise valuation metric fluents current state. proposition context-flow(i,)
asserts rate change ith variable defined precisely processes
, provided (and they) active, affected
process. following definition explains contributions rate change
262

fiModelling Mixed Discrete-Continuous Domains Planning

Inv: = 0
Flow:

d=0
a=0 v=0
=0 =1
stopped

startEngine
Jump: =
v = 0
= 0
=
Inv: = 0

accelerate
Jump: =
v = v
= +1
< 0 v < 100
=
1 v 100 = 1

Flow:
d=v v=a a=0
=0 =1
running

stop
Jump:

v=0
=
v = 0
= 0
=

Inv: = 0
Flow:

d=0
v=0
=0 =1
engineBlown
a=0

engineExplode
decelerate
Jump: =
v = v
= 1
< 0 v < 100
=

Jump: 1
v 100
= 0
v = v
=
=

Figure 11: hybrid automaton constructed translation uniprocess planning
instance.

variable several different concurrent processes combined (see also Section 4.2).
simply involves summing contributions active instant. assume
without loss generality contributions increasing effects. Decreasing effects
handled simply negating contributions made effects.
Definition 13 Combined Concurrent Effects Given finite set process effects, E =
e1 . . . ek , ei form (increase Pi (* #t Qi )), combined concurrent
effect E PNE P , called C(P, E), defined
X

{Qi | = 1, . . . k, P = Pi }

Given set processes, , combined concurrent effect PNE P , denoted
C(P, ), C(P, E), E set effects processes .
noted E contains processes affect specific variable, P ,
C(P, E) = 0.
Definition 14 Context-flow v logical state planning instance dimension
n subset Pv , context-flow proposition defined follows.
^
^
context-flowv (i, ) = (
N (P rep )
N (P rep )) Xi = C(Xi , )
p

pPv \

1 n.
263

fiFox & Long

empty context flow proposition asserts Xi = 0 i.
interpretation Planning Instance extends interpretation Uniprocess
Planning Instance. Again, added components underlined convenience.
Definition 15 Semantics Planning Instance planning instance = (Dom, P rob)
interpreted Hybrid Automaton, HI , follows:
Variables. variables HI X = {X1 , . . . , Xn+1 }, n dimension
planning problem. n + 1th variable special control variable used
measure time-slip .
Control Graph. set vertices V formed subsets ground atoms
planning instance. set edges E contains edge e v v 0
iff action event, a, relevant v and:
v 0 = (v Dela ) Adda
action event associated edge e.
Initial, invariant flow conditions. vertex labelling function init defined
as:

f alse
v 6= Initlogical
V
init(v) =
N (Initnumeric ) {Xi = |Xi 6 N (Initnumeric )} otherwise
vertex labelling function inv simple proposition ensures time-slip
zero.
inv(v) = (Xn+1 = 0)
vertex labelling function flow defined:
f low(v) = (

n
^

^

context-flowv (i, )) time-slippage(Ev )

i=1 P(Pv )

Jump conditions. edge labelling function jump defined follows. Given
edge e vertex v, associated action a:
^
jump(e) = N (P rea ) U Fa (X) = X 0
N (P reev )
evEv

Given edge e vertex v, associated event ev:
jump(e) = N (P reev ) U Fev (X) = X 0
H-events. set names ground actions events. edge
labelling function hevent : E assigns edge name action
event associated edge.
264

fiModelling Mixed Discrete-Continuous Domains Planning

final conjunct jump definition actions ensures state cannot
left action event preconditions satisfied. possible
one event simultaneously applicable state. discussed
Section 6.4.
illustration final extension sequence definitions, add one
process preceding example:
(:process windResistance
:parameters ()
:precondition (and (running) (>= (v) 50))
:effect (decrease (v) (* #t (* 0.1 (* (- (v) 50) (- (v) 50)))))
)
process causes vehicle slowed wind resistance becomes effective
50mph, proportional square speed excess 50mph. leads
flow constraint running state two new clauses replace original
constraint rate change velocity. new clauses shown second
box right Figure 12. observed, velocity vehicle
governed two different differential equations, according whether v < 50 v 50.
equations are:
dv
v < 50
dt = a,
dv
2 , v 50
=


0.1(v

50)
dt
solution first is: v = + v0 v0 velocity point
equation first applies (and measured point). solution second is:


c0 ( 10a 50)ec1 + 50 + 10a
v=
1 c0 ec1


c0 constant determined initial value velocity
c1 = 10a
5
process first applies (and, again, measured point). shown
example, simple differential equations expressed pddl+ lead
complex expressions. course, significant difference provision
semantics expressiveness finding planning algorithm manage
paper concerned former. anticipate planning
require sensible constraints extent expressive power pddl+
exploited.
definition semantics planning instance constructed around basic
framework discrete state space model domain. follows familiar discrete
planning model semantics. continuous dimensions model constructed
ensure Hybrid Automaton always start initial state consistent
planning instance (modelled init labelling function). state invariants ensure
time-slip occurs model that, therefore, events always occur
preconditions satisfied. noted since negation event preconditions
added jump conditions exiting transitions, impossible state
exited way triggered event. Finally, flow models effect
265

fiFox & Long

Inv: = 0
Flow:

d=0
a=0 v=0
=0 =1
stopped

startEngine
Jump: =
v = 0
= 0
=
Inv: = 0

accelerate
Jump: =
v = v
= +1
< 0 v < 100
=
1 v 100 = 1

Flow:
d=v a=0
=0 =1
running

stop
Jump:

v=0
=
v = 0
= 0
=

v 50 v = 0.1 (v 50)
v < 50 v =

2

Inv: = 0
Flow:
engineExplode
decelerate
Jump: =
v = v
= 1
< 0 v < 100
=

Jump: 1
v 100
= 0
v = v
=
=

d=0
v=0
=0 =1
engineBlown
a=0

Figure 12: hybrid automaton constructed translation planning instance.

real values active processes state. flow function assigns
proposition state determines piece-wise continuous behaviour
real values planning domain. function piece-wise differentiable,
finite number segments within finite interval. reason possible
behaviour metric fluent undergoing continuous change affect precondition
process cause continuous change metric fluents change.
change cannot cause discontinuity value metric fluents themselves,
cause discontinuity derivatives. consequence time
interval two successive actions events might include finite sequence distinct
periods continuous change. seen following section, requires
acceptable trace describing behaviour explicitly subdivide interval
sequence subintervals continuous change governed stable set
differential equations.
6.3 Semantics
Henzinger gives semantics constructing mapping Labelled Transition Systems (Keller, 1976). Figure 13 shows complete semantic relationship planning
instances labelled transition systems plans accepting runs. top
half figure shows relationship already constructed Henzinger give semantics Hybrid Automata. completes bridge planning instances
labelled transition systems. details mapping Hybrid Automata labelled
transition semantics provided section.
following definitions repeated Henzingers paper (1996).
266

fiModelling Mixed Discrete-Continuous Domains Planning

Labelled
transition
systems

Accepting
runs

implies

interpretation

THA

interpretation
implies

Traces

interpretation
interpretation
representation
Planning
instance

Plans
implies

Figure 13: semantic mapping LTS
Definition 16 Labelled Transition System labelled transition system, S, consists
following components:
State Space. (possibly infinite) set, Q, states subset, Q0 Q initial
states.
Transition Relation. (possibly infinite) set, A, labels. label


binary relation state space Q. triple q q 0 called transition.
Definition 17 Transition Semantics Hybrid Automata timed transition
Hybrid Automaton H labelled transition system components
system SH

0
Q, Q , , A, defined follows:
Define Q, Q0 V Rn , (v, ~x) Q iff closed proposition inv(v)[X := ~x]
true, (v, ~x) Q0 iff init(v)[X := ~x] inv(v)[X := ~x] true.
set Q called state space H.
= R0 .


event , define (v, ~x) (v 0 , ~x0 ) iff control switch e E
that: (1) source e v target e v 0 , (2) closed proposition
jump(e)[X, X 0 := ~x, ~x0 ] true, (3) hevent(e) = .


non-negative real R0 , define (v, ~x) (v 0 , ~x0 ) iff v = v 0
differentiable function f : [0, ] Rn , first derivative f : (0, ) Rn
that: (1) f (0) = ~x f () = ~x0 (2) reals (0, ), inv(v)[X := f ()]
f low(v)[X, X := f (), f()] true. function f called witness


transition (v, ~x) (v 0 , ~x0 ).
last definition see requirement interval continuous change timed transition system governed single set differential
267

fiFox & Long

equations, single solution exhibited (continuous differentiable) witness
function.
labelled transition system allows transitions arbitrary non-negative intervals time, processes execute dictated witness function
corresponding period. definition plans (Definition 3) allow rational times
associated actions, consequence rational intervals elapse
actions. means plans restricted expressing subset
transitions possible labelled transition system. return discussion
point following section, consider relationship plans accepting runs explicitly.
6.4 Interpretation Plans Traces
complete two-layered semantics presented Figure 13 showing plan interpreted using Henzingers notion trace acceptance. conclude presentation
formal semantics pddl+.
Using Henzingers syntax semantic model, first map plans traces
rely interpretation traces terms accepting runs. plan set timestamped actions (Definition 3): neither events processes appear specification
plan, even though planned actions initiate them. contrast, since Henzinger
distinguish actions events, trace HA contains control
switches might actions events, together explicit time intervals
them. Plans finite, concerned finite traces, plans normally
subsets traces, missing events possible subdivision intervals
actions distinct subintervals continuous activity.
define new structure, plantrace, contains sequence control switches
corresponding actions plan interpreted. map plantraces sets
traces proceed indicated above.
Definition 18 Plantrace Let H Hybrid Automaton, h-event set partitioned
two subsets, A, actions, E, events. plantrace H element
language (Q>0 A+ ) .
plantrace consists sequences one action control switches (denoted A+ ),
following single time interval must greater 0 length (0 length
intervals allowed actions either side would actually
occurring simultaneously). example, sequence h3 a0 a1 a2 2.7 a3 a4 plantrace.
Note allowed rational valued intervals actions.
consistent history pddl irrational time points considered.
semantics Hybrid Automata actions occur time point
considered sequenced according ordering recorded
trace. reality, possible execute actions time yet ensure
somehow ordered respect possible consequences interaction. order
respect constraint introduce additional element interpretation plans:
consider impact ordering actions time stamp plan possible
permutations order confirm possible interactions them.
motivates following definition:
268

fiModelling Mixed Discrete-Continuous Domains Planning

Definition 19 Permutation equivalent plantraces Two plantraces 1 2 , permutation equivalent, written 1 2 1 transformed 2 permuting
subsequence contains actions.
Definition 20 Plan projection projection plan, P , yields plantrace proj(P )
follows. Assume plan (a sequence pairs times action instance names)
given sorted time:
proj(P )
= proj2(0, P )
proj2(t, hi)
= hi
proj2(t, h(t1 , a), resti) = hai + proj2(t1 , rest), = t1
= ht1 t, ai + proj2(t1 , rest), otherwise
Plan projection functional description process plans interpreted
plantraces. process involves constructing sequence intervals collections
actions share time execution, interleaved sequences actions
occur together execution time. significant point make
actions given time execution, order occur
plantrace determined simply (arbitrary) order listed plan.
affect interpretation plan see following definition.
Definition 21 Interpretation plan interpretation plan P planning
instance set P TP plantraces HI permutation equivalent proj(P ).
taking plantraces permutation equivalent projection plan
remove dependency interpretation plan ordering actions
time stamp. objective link validity plans acceptance
traces, consider trace acceptance.
Henzinger defines trace acceptance trace HA. definition equivalent
following:
Definition 22 Trace Acceptance trace, = hai ii=1,...,n ai R accepted
H sequence r = hqi ii=0,...,n , qi states timed transition
H, and:
system SH
q0 Q0 .


.
= 1, . . . , n, qi1 qi transition SH

r called accepting run H and, qn = (v, ~x), say ends state v
final values ~x.
plan contain transitions represent events. reason, make
following definition:
Definition 23 Trace abstraction trace, , Hybrid Automaton h-events partitioned two sets, actions events E, abstracted create plantrace
removing events replacing maximal contiguous sequence numbers
single number equal sum sequence. Finally, last value
modified trace number removed.
269

fiFox & Long

use definitions interpretation plantraces. avoid unnecessary multiplication terms, reuse term accepted rely context disambiguate
form acceptance intend use.
Definition 24 Plantrace Acceptance Given Hybrid Automaton, H, h-event set
partitioned action events E, plantrace, , accepted H
trace 0 accepted H abstraction 0 .
important observe definition implies checking acceptance
plantrace could computationally significantly harder checking standard trace
acceptance. test requires discovery events could complete
gaps actions plantrace. However, since events constrained
applicable forced applied, provided restrict attention commuting events, problem determining plantrace acceptance
involve searching alternative event sequences. reasonable constraints placed
kinds event cascades may interleave actions, problem checking
plantrace acceptance becomes straightforward.
Finally, return plans consider plans actually valid.
Definition 25 Validity Plan plan P , planning instance I, valid
plantraces P TP accepted Hybrid Automaton HI . plan achieves goal
G every accepted trace abstraction P TP ends state satisfies G.
constraint simultaneously executed actions non-mutex sufficient ensure
necessary consider one representative set permutation
equivalent plantraces order confirm validity plan.
definitions constructed demonstrate relationship plans, plantraces,
traces accepting runs. observed definitions leave open possibility
events trigger non-deterministic way. possibility arises
one event applicable state events commute. case,
non-deterministic choice made, accepting run, applicable
events. possible action execute events state
time-slip process, process affect events
applied. non-deterministic choice applicable events would allow pddl+
capture actions non-deterministic outcomes. purposes paper restrict
attention event-deterministic planning instances.
Definition 26 Event-deterministic Planning Instances pddl+ planning instance,
I, event-deterministic every state HI two events, e1 e2 , applicable,
transition sequences e1 followed e2 e2 followed e1 valid reach
resulting state. case e1 e2 said commute.
every pair events ever applicable state commute planning
instance event-deterministic. general, deciding whether planning instance eventdeterministic expensive operation entire state space must enumerated.
However, much easier construct event-deterministic planning instances
necessary consider whether pairs events commute. particular, non-mutex
events always commute.
270

fiModelling Mixed Discrete-Continuous Domains Planning

conclude making observations relationship plans
accepting runs. Firstly, every valid plan corresponds collection accepting runs
labelled transition system corresponds HA interpretation
planning instance. difference accepting runs corresponding given
plan order events actions executed given single time point.
contrast, accepting runs corresponding plan.
situation arises domain admits accepting runs actions occurring irrational
time points. would possible extend plans allow irrational timestamps actions.
restriction rationals based fact explicit report plan generated
planner make use timestamps finite representation,
countably many plans expressed. fact uncountably many
possible transitions based use arbitrary real time values use us
planner cannot express all. point relevance observation, discussed
(Gupta et al., 1997), constructing plans execution practical interest
rely measurement time arbitrary precision. Instead, appropriate
look plans form core fuzzy tube traces accepted.
case, difference rational irrational timestamps becomes irrelevant, since
irrational value lies arbitrarily close rational value, robust plan represented
using rational timestamps alone. consider important direction future
exploration, planning problems require additional specification metric
size fuzzy tube solution plan must define, traces tube
high probability acceptance (Fox, Howey, & Long, 2005).

7. Analysis
previous sections constructed semantics pddl+ mapping Hybrid
Automata constructed formal relationship plans traces.
consequence, demonstrate general pddl+ domains provide succinct encodings
corresponding Hybrid Automata, since pddl+ model state space
exponential size encoding.
established relationship pddl+ domains Hybrid Automata,
benefit large body research Hybrid Automata subclasses. One issue widely addressed boundary decidable
undecidable classes Hybrid Automata boundary reinterpreted
reachability question interesting subsets pddl+ language.
following consider subsets pddl+ interesting sense
modelling different kinds restricted continuous temporal behaviours.
7.1 Reachability within Hybrid Automata
Reachability problem Hybrid Automata problem determining, given
, visits
automaton H, whether trajectory timed transition system, SH
state form (v, x). context Hybrid Automata, v typically error state,
Reachability questions posed determine whether automaton safe.
context planning, Reachability question equivalent Plan Existence.
discussed Henzingers paper (1996), general Reachability question Hybrid Au271

fiFox & Long

tomata undecidable. unsurprising, since introducing metric fluents arbitrary
behaviours language results sufficient expressive power model Turing Machine
computations. Indeed, Helmert shown (2002) even relatively simple operations
discrete metric variables sufficient create undecidable planning problems. However, various constraints, Reachability decidable several kinds hybrid system,
including Initialised Rectangular Automata (Henzinger et al., 1998). following discussion restrict attention deterministic Initialised Rectangular Automata, focussing
particularly Timed Automata (Alur & Dill, 1994), Priced Timed Automata (Rasmussen
et al., 2004) Initialised Singular Automata (Henzinger, 1996) relationships
fragments pddl family languages.
simplify definition Rectangular Automata introduce following definition:
Definition 27 Interval Constraint constraint variable x form x ./ c
rational constant c ./ {, <, =, >, } interval constraint. conjunction
interval constraints also interval constraint.
Rectangular Automata Hybrid Automata initial, invariant flow
conditions interval constraints, whose flow conditions refer variables X
whose jump conditions conjunction interval constraints constraints form
x0i = xi . Rectangular Automata may non-deterministic interval constraints
determine initial, flow jump conditions might determine unique values
variables constrain. Initialised Rectangular Automata meet additional
constraint control switch, e, v w, f low(v)i 6= f low(w)i x0i = xi
appear jump(e).
Initialised Rectangular Automata important represent boundary
decidability Hybrid Automata (Henzinger et al., 1998).
Since pddl deterministic language, interested deterministic
version Rectangular Automata. Singular Automaton Rectangular Automaton
deterministic jumps variables finite slope (that is, flow conditions determine
unique constant rate change variable). initialised continuous
variable reset every time rate change altered flow function. fact
variables finite slope allows rates change modified. Initialised Singular
Automata allow modelling linear continuous change rate change
modified provided corresponding variable reset occurs. constraint
prevents modelling stopwatches (Alur & Dill, 1994), ensures decidability
Reachability problem. Whilst quite expressive, automata cannot capture dynamics
arise many continuous planning domains. example, would possible
model effect, level water tank, adding second water supply time
filling process. According reset constraint level value would
reset zero second water source introduced.
Timed Automaton Singular Automaton every variable clock (a
one-slope variable). automata used model timed behaviour express
constraints temporal separation events (Alur & Dill, 1994). However, cannot
used model continuous change quantities clocks cannot used
store intermediate values. stopped reset zero, cannot operate
memory cells. Alur Dill (1994) prove reachability decidable Timed Automata
272

fiModelling Mixed Discrete-Continuous Domains Planning

infinite part model (the behaviour clocks) decomposed
finite number regions. demonstrates infinite character Timed
Automata characterised underlying finite behaviour. Helmert (2002) used
similar regionalisation technique proving plan existence question planning
models including certain combinations metric conditions effects remains decidable.
Priced Timed Automaton Timed Automaton costs associated
edges locations automaton. Costs accumulated traces enable
preference ordering traces. PTAs used solve simple Linear Programming
scheduling problems (Rasmussen et al., 2004). Costs behave like clocks except
stopped, rates changed, without reset. retain decidability
despite addition cost variables use restricted: costs cannot referred
jump conditions although updated following edge delay transitions.
PTAs used model planning problems actions associated
linearly changing costs. example, Airplane scheduling bench mark, planes
incur cost penalties late early landing, expressed syntax pddl+
solved using PTA solution techniques (Rasmussen et al., 2004). models
restrictive: dependence logical dynamics domain cost values cannot
expressed costs cannot, example, used keep track resource levels
planning resources over-subscribed. However, capable expressing
class problems require modelling continuous change therefore
seen fundamental step towards modelling mixed discrete-continuous domains.
Since PTAs allow modelling non-trivial planning domains continuous change
begin constructing fragment pddl+ yields state-space models exactly equivalent PTAs. remainder section discuss relationships
richer pddl+ fragments different automata.
7.2 pddl+ Priced Timed Automata
Rasmussen et al. (2004) describe components Priced Timed Automaton (PTA)
follows. contains set real-valued clocks, C, constraints expressed
set clock constraints, B(C). set actions, Act. PTA given 5-tuple
(L, l0 , E, I, P ), L finite set locations (that is, states), l0 initial location,
E L B(C) Act 2C L, : L B(C) function assigning invariants locations
P : (L E) N assigns prices edges locations. edge, E = (l, b, a, r, l0 )
transition locations l l0 using action a, jump condition b (over
clocks) resets clocks r zero. price function represents discrete cost
transitions continuous cost associated staying location.
modelling arbitrary Priced Timed Automata define pddl+ fragment
refer pddl+P . following definition fragment unique.
subsets pddl+ exist expressive power, including subsets directly
relying processes events. excluding events fragment trivially
guaranteed deterministic language.
pddl+P fragment uses standard pddl+ language features, subject
following constraints:
273

fiFox & Long

1. Processes may logical preconditions exactly one process must active
state except, possibly, one special state, error.
2. process must increase metric fluents rate 1, except one special
variable, c, may increased constant rate.
3. action may preconditions refer metric fluents except
c. preconditions must appear forms (called clock constraints)
conforming following: (./ xi n) (./ (- xi xj ) m) n, natural
numbers ./ {<, , =, , >}.
4. action may reset value metric fluent, c, zero. may
increase value c constant value.
5. domain may contain events whose precondition may include literals clock
constraints. effect every event must leave system special state
error, transitions possible.
6. plan metric form: (:metric minimize (c)).
constraints ensure state space yielded pddl+P description,
transition behaviour, equivalent (within constant multiple encoding size) PTA.
cannot demonstrate direct equivalence pddl+P PTAs pddl+P
models exponentially compact explicit PTA corresponds.
compaction similar obtained factorising PTA models (Dierks,
2005). demonstrate indirect equivalence two languages Theorem 2.
Definition 28 Indirectly Equivalent Expressiveness Given two languages, L1 L2 ,
L1 indirectly equivalent expressive power L2 sentence, s1 , L1 defines
model, Ms1 , L2 express Ms1 polynomial increase encoding size
(in size Ms1 ) sentence, s2 , L2 expressed L1
polynomial increase size encoding (in size s2 ).
note definition asymmetric: sentences L1 define models
expressed efficiently L2 , sentences L2 efficiently expressed directly
L1 . sentences L1 might compact encodings corresponding models
therefore cannot claim direct equivalence expressiveness L1 L2 .
intentional allows us exploit pddl property compact encoding
language state spaces transition behaviours planning domains defines.
Theorem 2 pddl+P indirectly equivalent expressive power Priced Timed Automata.
proof theorem found Appendix B.
Lemma 1 sentence, s, pddl+ defines transition system doubly
exponential size s.
274

fiModelling Mixed Discrete-Continuous Domains Planning

straightforward: set literals defined pddl+ problem instance
exponential number parameters predicate highest arity
state space defines exponential size set literals.

Corollary 1 Reachability pddl+P decidable.
follows Theorem 2, Lemma 1 decidability PTAs (Larsen, Behrmann,
Brinksma, Fehnker, Hune, Pettersson, & Romijn, 2001).

pddl+P extended, remaining decidable, allowing additional metric
fluents whose (non-continuous) behaviour constrained according one decidable
subsets identified Helmert (2002), provided fluents distinct clock
cost variables.
similarly define language fragment expressive power equivalent Initialised Singular Automata. Initialised Singular Automata represent expressive
form deterministic automaton decidable Reachability problem. constraints
limit extent reason dependence behaviour temporal
metric quantities.
Initialised Singular Automaton continuous change restricted variables
slope 1, contrast clocks Timed Automata. variables finite slope (that
is, rates change take one finite set different values), must
initialised given constant whenever rates change altered. values
variables referred jump conditions automaton.
modelling Initialised Singular Automata define pddl+ fragment
refer pddl+ISA . fragment contains syntactic components pddl+P
subject slightly different constraints:
1. Processes may logical preconditions exactly one process must active
state except, possibly, one special state, error.
2. process must increase metric fluents constant rates.
3. action may preconditions refer metric fluents.
preconditions must appear forms (called clock constraints): (./ xi n)
(./ (- xi xj ) m) n, natural numbers ./ {<, , =, , >}.
4. action may reset value metric fluent constant natural number
value. action causes transition state new process active
must also reset metric fluents whose rates change different new
process.
5. domain may contain events whose precondition may include literals clock
constraints. effect every event must leave system special state
error, transitions possible.
275

fiFox & Long

fragment contain special plan metric: problems pddl+ISA interest
plan existence problem.
Theorem 3 pddl+ISA indirectly equivalent expressive power Initialised Singular
Automata.
proof result analogous Theorem 2. constraints ensure
behaviour Initialised Singular Automata captured language language contains expressions effectively modelled within Initialised Singular
Automata.
interest review domains considered paper, planetary
lander domain accelerating vehicle domain, respect modelling power
pddl+P pddl+ISA . first instance, since domains involve non-linear
change, power generation state charge curves distance travelled
vehicle acceleration non-zero, clear domains lie outside
modelling power constrained languages. feasible consider approximating
non-linear behaviour cases. example, generation curve might approximated small set linear functions (with corresponding loss opportunities
exploit margins model). generation curve tied absolute points
timeline values points linear functions would required
meet order approximate original curve identified advance. order
create reasonable approximation, functions would require different slopes (shallow
start, steeper shallower again, approximate first half bell
curve), cannot achieved using pddl+P , since allows clock variables.
pddl+ISA powerful enough express differently sloped linearly changing variables
kind. Unfortunately, state charge curve, even approximations, beyond
expressive power either language. pddl+ISA problem must
memory old state charge slope charge curve changes.
pddl+P cost variable could used model state charge, since
capacity used memory different rates change. However,
cost variable cannot used preconditions actions, means attempt
model battery way would force decoupling battery state
charge actions use power. realistic model battery management
lies outside power pddl+P pddl+ISA .
However, interesting problems involving continuous change perfectly amenable,
Dierks (2005) Behrmann et al. (2005) shown. Aircraft Landing problem (Beasley, Krishnamoorthy, Sharaiha, & Abramson, 2000) modelled PTA
one source continuous change modelled cost variable.
domain, number aircraft must land single airport, sometime
earliest latest landing time close target time possible. earliest, latest
target times defined aircraft. cost associated problem
charge associated landing plane early late, charge decreases
linearly earliest landing time towards target time increases linearly
target latest landing time. behaviour aircraft dependent
value cost variable, although quality landing schedule determined
276

fiModelling Mixed Discrete-Continuous Domains Planning

Deterministic Hybrid Automata

Hybrid Automata

Linear Automata

PDDL+

Undecidable
Deterministic Linear Automata

PDDL+

metric fluents
besides clock
cost variables
satisfy one
Helmerts
constraint sets.

#t lin

Rectangular Automata

PDDL+ ISA

Initialised Singular Automata

PDDL+ PTA

Priced Timed Automata

Deterministic Timed Automata
DPDDLTT+SE
DPDDLTT
DPDDLSE

Initialised Rectangular Automata

Decidable
Nondeterministic TA

Finite Automata

Deterministic

Nondeterministic

DPDDL
NPDDL

Figure 14: Mapping pddl fragments corresponding deterministic automata. pddl
family deterministic languages. However, extension support temporal,
numeric logical non-determinism would give access automata
right hand side figure.

it. Aircraft Landing problem optimisation problem quantity
optimized changes continuously time.
Figure 14 present formal relationships pddl+ fragments classes
hybrid automata. bottom half figure concerns decidable fragments pddl+
whilst top half concerns undecidable fragments. figure, dpddl pddl+
fragment fixed duration durative actions allowed (and events processes),
restricted start effects npddl (non-temporal pddl) fragment
occur. Initial effects significant make
possible create domains problems solved exploiting
concurrency. reason effects restricted end points
actions, always possible find sequential plan solve problem
concurrent solution. cases concurrency required solve problem,
durative actions sequentialised durations simply summed discrete end
effects. actions initial effects possible effects
added start action deleted end, creating windows opportunity
actions must fitted concurrently exploit effects.
concurrency matters necessary monitor passage time requires
power timed automata. language variants show follows:
277

fiFox & Long

dpddlSE allows start effects, raising need concurrency explained
above.
dpddlT , dpddl together use plan metrics using term
total-time: also requires concurrency since time required plan depends
extent non-interfering actions selected reduce make-span
plan.
dpddlT +SE dpddl together total-time allowing use start
effects.
pddl+#t lin pddl+ restricted linear rates change metric fluents.
restriction insufficient ensure decidability, use linear rates change
makes possible apply linear constraint solvers problems. consequence,
subset pddl+ captures continuous planning problems planning
technology already applied (Shin & Davis, 2005; McDermott, 2003b; Wolfman & Weld, 1999; Penberthy & Weld, 1994) (in first these, particular,
models actually expressed pddl+).
bottom half figure npddl dpddl include metric conditions effects constrained occur decidable combinations defined Helmert (2002). Helmert
demonstrated adding (discrete) metric effects conditions propositional pddl
fragment already adds dramatically expressive power language. particular,
quite limited set (discrete) metric effects conditions decidability already
lost. However, restrictions use metric variables leave decidable
fragment. order extensions discussing retain decidability must not,
course, sacrifice adopting rich set discrete metric effects preconditions.
lower half figure work within constraints. results
extend Helmerts introducing continuous metric change, demonstrating boundaries
retain decidability. top half figure constraints lifted. lefthand half figure concerns deterministic models: pddl+ language expressing
deterministic domains, restricted attention side. right-hand half
concerns non-deterministic variants models considered. include
provide general context results.

8. Related Work
section discuss relationship pddl+ several related formalisms literature. addition, consider extent pddl+ addresses
inadequacies pddl2.1 terms expressive power convenience. paper
pddl2.1 published Journal Artificial Intelligence Research Special Issue
3rd IPC (Fox & Long, 2003). editors special issue invited five influential
members planning community contribute short commentaries language, indicating support for, objections to, choices made modelling time
time-dependent change. Fahiem Bacchus, Mark Boddy, Hector Geffner,
Drew McDermott David Smith. discuss parts commentaries
relevant modelling durative behaviour continuous change explain
278

fiModelling Mixed Discrete-Continuous Domains Planning

believe pddl+ addresses issues raised. interesting note many
objections raised commentaries addressed start-process-stop model
pddl+. begin considering commentaries go discuss related
formalisms.
8.1 pddl+ versus pddl2.1
commentators invited comment decisions made pddl2.1,
limitations impose temporal domain modelling. issues raised
commentators addressed pddl+. section identify issues
raised relevant development pddl+ explain think pddl+
resolves them.
Bacchus (2003) proposes alternative continuous durative actions pddl2.1
similarities start-process-stop model pddl+. approaches recognise durative activity sometimes best modelled using underlying, interruptible
process. Whilst Bacchus proposes initiation running processes
wrapped durative actions conditional effects, pddl+ achieves effect
cleanly separated continuous autonomous processes events. pddl+ express
behaviours dependent continuous variables time, Bacchus proposal limited purely time-dependent processes (he allow interacting processes
consider forms continuous change).
McDermott Boddy consistently supported use autonomous processes
representation continuous change. commentary McDermott (2003a) identifies weaknesses durative action-based representation change argues
continuous durative actions pddl2.1, allow modelling duration inequalities time-dependent effects, headed extinction favour straightforward
autonomous processes. start-process-stop model pddl+ replaces continuous
durative actions pddl2.1 constructs fully exploit autonomous processes support richer natural models continuous domains. shown
paper, modelling events adds expressive power Boddy anticipates (Boddy, 2003).
commentary Smith (2003) raises philosophical objections durative
action model pddl2.1 argues restrictive support convenient models
interesting durative behaviours. pddl2.1 actions specify effects start
end points, although conditions required remain invariant whole
durative interval. Smith proposes durative action model richer proposed
pddl2.1, effects occur arbitrary points within durative interval
conditions might also required hold identified timepoints start
end action. Although, principle, possible decompose pddl2.1 durative
actions sequences actions achieve effects, Smith correctly observes
would generally result inconvenient impractical models. argues action
representations encapsulate many consequences application way
frees planner burden reasoning minutiae. observes
computational effort involved, stringing together sub-actions required
realise complex activity, would normally prohibitive.
279

fiFox & Long

agree pddl2.1 durative action model restrictive forcing effects
occur end points actions. Smiths rich durative model seen
encapsulating effects starting ending one processes, together
effects processes, action-based representation. committing activity
certain amount time actions abstract time-dependent details avoid
need planner reason interactions. simplification
doubt sufficient many practical contexts (and indeed, sufficient
satellite domain discusses commentary). might indeed interest
provide representations abstractions start-process-stop model.
point goes heart contribution paper: provided
set primitives building modelling constructs. providing formal semantics
primitives provided way interpreting abstract constructs built
primitives. argue that, combination natural modelling concepts like fixedlength durative actions, start-process-stop primitives provide usable planning domain
description language. However, concerned formal underpinnings
language rather modelling convenience provides. agree Smith
abstract modelling constructs, built primitives, might enhance modelling
experience way abstract programming constructs enhance programming
experience programming machine code level.
8.2 Related Formalisms
number representational formalisms proposed expressing temporal
metric activity planning. closest recent counterpart pddl+ modelling
language, Opt, Optop planner (McDermott, 2004). language developed independently, Drew McDermott, time pddl+ first proposed,
similarities Opt pddl+ due discussions developers
two languages time. Opt pddl-like dialect strongly influenced
work McDermott authors pddl family languages. Opt supports autonomous processes run preconditions satisfied
control planner. Unlike pddl+, Opt contain explicit events embedded inside processes run long preconditions remain
true. Opt also retains durative actions alternative explicit modelling continuous change models timed initial literals derived predicates. planner, Optop,
developed McDermott (McDermott, 2005) subset Opt models linear
continuous change. Planners already exist handling interesting subsets pddl+,
directly (Shin & Davis, 2005) indirectly (Dierks, 2005). later case, language
PTA solver UPPAAL-cora (Behrmann et al., 2005) used, modelling
power equivalent pddl+P .
semantics Opt processes given terms infinitely many situations occurring within finite time, associated different fluent values continuously
changing variables. Opt pddl+ fundamentally related Reiters work continuous dynamics situation calculus (Reiter, 2001). McDermott developed situation
calculus semantics Opt, whereas constructed explicit relationship
pddl+ theory Hybrid Automata order make explicit relationship be280

fiModelling Mixed Discrete-Continuous Domains Planning

tween pddl+ planning control theory. similar relationship drawn CIRCA
architecture (Musliner, Durfee, & Shin, 1993), integrates planning real time
control using probabilistic timed automata.
qualitative reasoning community proposed hybrid state-based models dynamic physical systems (Forbus, 1984; de Kleer & Brown, 1984; Kuipers, 1984). Kuipers (1984)
considers qualitative simulation physical systems described terms continuously
varying parameters. proposes qualitative representation differential equations
governing behaviour system, expressed systems constraints key
parameters describing state system discrete points time. representation supports commonsense reasoning evolution physical systems
quantitative reasoning would computationally prohibitive.
formalisms developed within fields planning reasoning
action change. Temporal resource management provided HSTS Europa (Frank & Jonsson, 2003; Jonsson, Morris, Muscettola, Rajan, & Smith, 2000), IxTeT (Laborie & Ghallab, 1995), CIRCA (Musliner et al., 1993), LPSAT (Wolfman & Weld,
1999), Zeno (Penberthy & Weld, 1994) HAO* (Benazera, Brafman, Meuleau, Mausam,
& Hansen, 2005) mention systems planning literature.
part, systems plan-generation systems using representation languages support
restricted modelling continuous change metric time. contrast, pddl+ proposes unrestricted representation language, semantics, without describing specific
search algorithms construction plans. Finding efficient algorithms reasoning
pddl+ domains separate topic, already progress (Shin
& Davis, 2005; Dierks, 2005; McDermott, 2004) mentioned above. course, demands practical planning restrict ambitious one using pddl+ model
real planning applications, reason impose artificial restrictions
expressiveness language.
key objective HSTS (Heuristic Scheduling Testbed System) (Muscettola, 1993)
maintain much flexibility possible development plan, plan
robustly executed face unexpected events environment. HSTS embodies
close integration planning scheduling, enabling representation complex
resource-intensive planning problems dynamic constraint satisfaction problems (DCSP).
DDL, Domain Description Language HSTS, distinction made domain
attributes (ie: components domain exhibit behaviours) states,
activity attribute represented separate time line. distinction
made states actions: actions added time lines inserting tokens
representing predicates holding flexible intervals time. token associated
set compatibilities explain constrained respect activities
time lines. Compatibilities express relations similar
TIMELOGIC constructs Allen Koomen (Allen & Koomen, 1983). Choices
development plan explored heuristic search inconsistencies
DCSPs representing corresponding partial plans result pruning.
Events kind provided pddl+ expressed disjuncts compatibility
constraints associated actions produce them. example, action
opening water source fill tank would expressed token constrained meet
either event flooding interval water source closed. Then, whether
281

fiFox & Long

tank floods depends long interval filling lasts, flooding
event avoided expressing constraint end water level exceeds
tank capacity. process water level increases tank filling
expressed using sequence compatibilities, allow variables take arbitrarily many
contiguous values sequence interval. actual water level end
interval identified, using linear programming techniques, one values
sequence. notion procedural reasoning (Frank, Jonsson, & Morris, 2000)
introduced framework support efficient reasoning rates change
continuous variables interactions within plan.
HSTS therefore supports representation interaction actions, processes
events exploitation development flexible plan/schedules.
respect, DDL somewhat expressive pddl+ flexibility
temporal database. Allowing intervals last amount time specified lower
upper bound introduces bounded temporal flexibility reasoning framework.
IxTeT (Laborie & Ghallab, 1995) partial order causal link planner uses
task representation similar discrete durative actions pddl2.1. key
difference pddl2.1 discrete durative actions restricted representation
step function change start end points interval, whilst IxTeT tasks
effects specified point interval. allows piecewise continuous change
represented. Continuous change cannot modelled (except means small
intervals piecewise representation appropriate function). Furthermore,
durative actions IxTeT fixed duration endure amount time
within specified interval. Thus, IxTeT also models bounded temporal flexibility able
construct flexible plans. IxTeT continues traditions POCL planning (McAllester
& Rosenblitt, 1991; Penberthy & Weld, 1992) plan built partially
ordered graph activities complex flexible temporal constraints. Simple Temporal
Network (Dechter, Meiri, & Pearl, 1991) used determine consistency given
temporal constraint set. STNs, also used HSTS, powerful technique temporal
reasoning restricted reasoning discrete time points.
important difference modelling continuous process change
computing values continuous-valued variables planning. systems,
continuous change explicitly modelled, trajectories constructed
variables throughout timeline plan. systems, continuous processes
determine behaviour metric variables implicit, values variables
available, computation, certain times along trajectories.
Zeno (Penberthy & Weld, 1994) uses explicit representation processes differential
equations solves determine whether temporal metric constraints
problem met partial plan (and identify values continuous-valued
resources action preconditions require them). LPSAT (Wolfman & Weld, 1999) also
uses explicit model processes govern continuous change (although use
linear constraint solving limits linear processes). different approach,
processes explicitly modelled, seen HAO* (Benazera et al., 2005). Here,
although continuous-valued resources modelled, way change time
not. different possible metric outcomes action discretised associated
probabilities. Plan construction seen terms policy construction within
282

fiModelling Mixed Discrete-Continuous Domains Planning

hybrid MDP framework. Time managed way metric
resource (a certain action take time units probability 1 p) need
model passage time directly. Whilst time-dependent nature metric effects
actions captured way, actions cannot interact passage time
order exploit control episodes continuous change.

9. Conclusions
paper presented planning domain description language, pddl+,
supports modelling continuous dynamics. provided formal semantics
specifying mapping pddl+ constructs deterministic hybrid automata.
also related fragments pddl+ automata different levels expressive
power. goal develop pddl extension properly models passage
time, continuous change quantities time, support modelling mixed
discrete-continuous planning domains.
primary goal establish baseline mixed discrete-continuous modelling, provide formal semantics resulting language. Additionally wanted
make strong connection planning automata theory order facilitate
cross-fertilisation ideas planning real-time systems modelchecking communities. explored relationship fragments pddl+
automata-theoretic models boundary decidability order better understand gained lost expressive power addition removal modelling
constructs.
focussed make pddl+ convenient modelling modelling convenience related expressive power. agree might desirable
build abstract modelling constructs top baseline language order enhance
modelling convenience. Nevertheless, pddl+ used experimental purposes, development technology mixed discrete-continuous planning,
presented usable language builds directly upon current standard modelling
language temporal domains. presented two examples domain models
exploit processes, events durative actions succinct representation continuous
change. Future work consider powerful modelling constructs might built
support convenient modelling larger scale mixed discrete-continuous domains.

Acknowledgments
would like extend special thanks David Smith detailed critical analysis
earlier drafts paper many insightful comments suggestions. would
also like thank Subbarao Kambhampati anonymous referees helping us
organise clarify presentation work, Jeremy Frank, Stefan Edelkamp,
Nicola Muscettola, Drew McDermott, Brian Williams Mark Boddy, helped
us refine sharpen ideas formulations.
283

fiFox & Long

Appendix A. pddl2.1 Core Definitions
appendix present definitions (Fox & Long, 2003) relevant
paper, ease reference. detailed discussions definitions
relationships see original source.
Core Definition 1 Simple Planning Instance simple planning instance defined
pair
= (Dom, P rob)
Dom = (F s, Rs, As, arity) 4-tuple consisting (finite sets ) function symbols,
relation symbols, actions (non-durative), function arity mapping symbols
respective arities. P rob = (Os, Init, G) triple consisting objects
domain, initial state specification goal state specification.
primitive numeric expressions planning instance, P N Es, terms constructed function symbols domain applied (an appropriate number )
objects drawn Os. dimension planning instance, dim, number
distinct primitive numeric expressions constructed instance.
atoms planning instance, Atms, (finitely many) expressions formed
applying relation symbols Rs objects Os (respecting arities).
Init consists two parts: Initlogical set literals formed atoms Atms.
Initnumeric set propositions asserting initial values subset primitive
numeric expressions domain. assertions assign single primitive
numeric expression constant real value. goal condition proposition
include atoms formed relation symbols objects planning instance
numeric propositions primitive numeric expressions numbers.
collection action schemas (non-durative actions) expressed syntax
pddl. primitive numeric expression schemas atom schemas used action
schemas formed function symbols relation symbols (used appropriate
arities) defined domain applied objects Os schema variables.
Core Definition 2 Logical States States Given finite collection atoms
planning instance I, AtmsI , logical state subset AtmsI . planning instance
dimension dim, state tuple (R, P(AtmsI ), Rdim
) R = R {}
denotes undefined value. first value time state, second
logical state third value vector dim values dim primitive numeric
expressions planning instance.
initial state planning instance (0, Initlogical , ~x) ~x vector values
R corresponding initial assignments given Initnumeric (treating unspecified
values ).
Core Definition 3 Assignment Proposition syntactic form numeric effect
consists assignment operator (assign, increase, decrease, scale-up scale-down),
one primitive numeric expression, referred lvalue, numeric expression (which
arithmetic expression whose terms numbers primitive numeric expressions),
referred rvalue.
284

fiModelling Mixed Discrete-Continuous Domains Planning

assignment proposition corresponding numeric effect formed replacing
assignment operator equivalent arithmetic operation (that (increase p q)
becomes (= p (+ p q)) on) annotating lvalue prime.
numeric effect assignment operator either increase decrease
called additive assignment effect, one operator either scale-up scale-down
called scaling assignment effect others called simple assignment effects.
Core Definition 4 Normalisation Let planning instance dimension dimI
let
indexI : P N EsI {1, . . . , dim}
(instance-dependent) correspondence primitive numeric expressions

integer indices elements vector dimI real values, Rdim
.

normalised form ground proposition, p, defined result substituting primitive numeric expression f p, literal XindexI (f ) . normalised
form p referred N (p). Numeric effects normalised first converting
assignment propositions. Primed primitive numeric expressions replaced
~ used represent vector hX1 . . . Xn i.
corresponding primed literals. X
Core Definition 5 Flattening Actions Given planning instance, I, containing action schema AsI , set action schemas f latten(A), defined set S,
initially containing constructed follows:
contains action schema, X, conditional effect, (when P Q), create
two new schemas copies X, without conditional effect, conjoin
condition P precondition one copy Q effects copy,
conjoin (not P) precondition copy. Add modified copies S.
contains action schema, X, formula containing quantifier, replace
X version quantified formula ( Q ( var1 . . . vark ) P) X
replaced conjunction (if quantifier, Q, forall) disjunction (if Q
exists) propositions formed substituting objects variable
var1 . . . vark P possible ways.
steps repeated neither step applicable.
Core Definition 6 Ground Action Given planning instance, I, containing action
schema AsI , set ground actions A, GAA , defined set
structures, a, formed substituting objects schema variables schema,
X, f latten(A) components are:
Name name action schema, X, together values substituted
parameters X forming a.
Prea , precondition a, propositional precondition a. set ground
atoms appear Prea referred GPrea .
Adda , positive postcondition a, set ground atoms asserted
positive literals effect a.
285

fiFox & Long

Dela , negative postcondition a,is set ground atoms asserted
negative literals effect a.
NPa , numeric postcondition a, set assignment propositions corresponding numeric effects a.
following sets primitive numeric expressions defined ground action,
GAA :
La = {f |f appears lvalue a}
Ra = {f |f PNE rvalue appears P rea }
La = {f |f appears lvalue additive assignment effect a}
Core Definition 7 Valid Ground Action Let ground action. valid
primitive numeric expression appears lvalue one simple assignment
effect, one different type assignment effect.
Core Definition 8 Updating Function Let valid ground action. updating
function composition set functions:
dim
{NPFp : Rdim
R | p N P }

NPFp (~x) = ~x0 primitive numeric expression x0i appear
~ 0 := ~x0 , X
~ := ~x] satisfied.
lvalue N (p), x0i = xi N (p)[X
~ 0 := ~x0 , X
~ := ~x] read result normalising p
notation N (p)[X
~ 0 actual values ~x
substituting vector actual values ~x0 parameters X
~
formal parameters X.
Core Definition 9 Satisfaction Propositions Given logical state, s, ground
propositional formula pddl2.1, p, defines predicate Rdim
, Num(s, p), follows:
Num(s, p)(~x)

iff

~ := ~x]
|= N (p)[X

|= q means q true interpretation atom, a,
numeric comparison, assigned true iff s, numeric comparison interpreted
using standard equality ordering reals logical connectives given usual
interpretations. p satisfied state (t, s, ~x) Num(s, p)(~x).
Comparisons involving , including direct equality two values undefined, enclosing propositions also undefined satisfied state.
Core Definition 10 Applicability Action Let ground action. applicable state P rea satisfied s.
286

fiModelling Mixed Discrete-Continuous Domains Planning

Appendix B. Proof theorem
Theorem 2 pddl+P indirectly equivalent expressive power Priced Timed Automata.
begin showing arbitrary PTA expressed pddl+P domain
without blow-up size encoding. show converse also
case.
Given PTA hL, l0 , E, I, P construct pddl+P model follows. edge
e = (li , g, a, r, lj ), g clock constraint, action r subset clock
variables reset edge, construct following instantaneous action schema, called
transition action, models instantaneous transition li lj .
(:action transitione
:parameters ()
:precondition (and (in li ) g)
:effect (and {x r (assign (x) 0)}
(increase (c) P(e))
(not (in li ))
(in lj )))

also construct, location li , following process schema:
(:process process-locationli
:parameters ()
:precondition (in li )
:effect
(and (increase (c) (* #t P(li ))
{x C (increase (x) (* #t 1))}
))

Finally, construct event location:
(:event event-locationli
:parameters ()
:precondition (and (in li ) (not (I(li ))))
:effect
(not (in li )))

initial state specifies clock variable cost variable starts value
0. asserts (in l0 ). special error state empty state (if event triggered
remove current location proposition, leaving impossible progress).
Note domain valid pddl+P . two actions applied parallel
system ever satisfy one condition form (in li ).
construction correctly capture PTA, remains shown PTA
trajectory corresponds pddl+P plan domain plan corresponds
trajectory.
Consider (valid) PTA trajectory,




1
2
(l0 , u0 )
(l1 , u1 )
. . . (ln , un )

287

fiFox & Long

ui clock valuation transition may either edge
positive time delay. case time delay transitions, location remains
clock valuation updated delay duration, edge transitions location
updated clock valuation remains same. trajectory mapped plan
creating action instance edge transition (using corresponding action
pddl+P description). action set applied time corresponding
sum time delay transitions precede transition trajectory.
valid plan since processes active exactly times pddl model
corresponding time transitions trajectory.
Similarly, given valid pddl plan domain, plan defines trajectory
mapping instantaneous actions corresponding edge transitions
gaps time delay transitions. trajectory valid one
construction actions process models. Note valid plan trigger
event, since leave system state cannot progressed, preventing
satisfaction goal. means invariant conditions location always
maintained.
consider opposite direction proof: pddl+P planning instances
yield state space transition models expressed PTAs constant
factor transformation. observe constraints pddl+P language ensures
clock variables cost variable distinguished behave exactly required
PTA. ground state space, states correspond directly locations PTA
legal actions transition states correspond edges corresponding
PTA. exception event transitions leading exceptional error state,
edge pddl+P transition system will, constraints defining language, always
correspond instantaneous action action determines clock constraints
reset effects corresponding PTA edge. Exactly one process active state,
causes variables behave clocks (except cost variable). events govern
invariants states, causing violation invariant condition trigger
transition error state.
correspondence trajectories PTA defined way plans
pddl+P transition system immediate, subject observations made
above.


Appendix C. Planetary Lander Domain pddl+
following domain encoding shows pddl+ model Planetary Lander problem
discussed Section 2.2. According implementation details systems designed handle
pddl+ models, might necessary introduce events manage transition
charging discharging, imprecision system measuring
values demand supply might lead difficulties boundary supply
demand equal.
(define (domain power)
(:requirements :typing :durative-actions :fluents :time
288

fiModelling Mixed Discrete-Continuous Domains Planning

:negative-preconditions :timed-initial-literals)
(:types equipment)
(:constants unit - equipment)
(:predicates (day) (commsOpen) (readyForObs1) (readyForObs2)
(gotObs1) (gotObs2)
(available ?e - equipment))
(:functions (demand) (supply) (soc) (charge-rate) (daytime)
(heater-rate) (dusk) (dawn)
(fullTime) (partTime1) (partTime2)
(obs1Time) (obs2Time) (obs1-rate) (obs2-rate)
(A-rate) (B-rate) (C-rate) (D-rate) (safeLevel)
(solar-const))

(:process charging
:parameters ()
:precondition (and (< (demand) (supply)) (day))
:effect (and (increase (soc) (* #t (* (* (- (supply) (demand))
(charge-rate))
(- 100 (soc)))
)))
)
(:process discharging
:parameters ()
:precondition (> (demand) (supply))
:effect (decrease soc (* #t (- (demand) (supply))))
)
(:process generating
:parameters ()
:precondition (day)
:effect (and (increase (supply)
(* #t (* (* (solar-const) (daytime))
(+ (* (daytime)
(- (* 4 (daytime)) 90)) 450))))
(increase (daytime) (* #t 1)))
)
(:process night-operations
:parameters ()
:precondition (not (day))
:effect (and (increase (daytime) (* #t 1))
(decrease (soc) (* #t (heater-rate))))
)
(:event nightfall
:parameters ()
:precondition (and (day) (>= (daytime) (dusk)))
:effect (and (assign (daytime) (- (dawn)))
(not (day)))
289

fiFox & Long

)
(:event daybreak
:parameters ()
:precondition (and (not (day)) (>= (daytime) 0))
:effect (day)
)
(:durative-action fullPrepare
:parameters ()
:duration (= ?duration (fullTime))
:condition (and (at start (available unit))
(over (> (soc) (safelevel))))
:effect (and (at start (not (available unit)))
(at start (increase (demand) (A-rate)))
(at end (available unit))
(at end (decrease (demand) (A-rate)))
(at end (readyForObs1))
(at end (readyForObs2)))
)
(:durative-action prepareObs1
:parameters ()
:duration (= ?duration (partTime1))
:condition (and (at start (available unit))
(over (> (soc) (safelevel))))
:effect (and (at start (not (available unit)))
(at start (increase (demand) (B-rate)))
(at end (available unit))
(at end (decrease (demand) (B-rate)))
(at end (readyForObs1)))
)
(:durative-action prepareObs2
:parameters ()
:duration (= ?duration (partTime2))
:condition (and (at start (available unit))
(over (> (soc) (safelevel))))
:effect (and (at start (not (available unit)))
(at start (increase (demand) (C-rate)))
(at end (available unit))
(at end (decrease (demand) (C-rate)))
(at end (readyForObs2)))
)
(:durative-action observe1
:parameters ()
:duration (= ?duration (obs1Time))
:condition (and (at start (available unit))
(at start (readyForObs1))
(over (> (soc) (safelevel)))
290

fiModelling Mixed Discrete-Continuous Domains Planning

(over (not (commsOpen))))
:effect (and (at start (not (available unit)))
(at start (increase (demand) (obs1-rate)))
(at end (available unit))
(at end (decrease (demand) (obs1-rate)))
(at end (not (readyForObs1)))
(at end (gotObs1)))
)
(:durative-action observe2
:parameters ()
:duration (= ?duration (obs2Time))
:condition (and (at start (available unit))
(at start (readyForObs2))
(over (> (soc) (safelevel)))
(over (not (commsOpen))))
:effect (and (at start (not (available unit)))
(at start (increase (demand) (obs2-rate)))
(at end (available unit))
(at end (decrease (demand) (obs2-rate)))
(at end (not (readyForObs2)))
(at end (gotObs2)))
)
)

Appendix D. Durative Actions pddl+
syntax durative actions seen purely syntactic convenience. order
support view, durative actions must mapped directly equivalent startprocess-stop representation using basic syntax pddl+. reason performing
mapping order give durative actions semantics terms underlying
structures pddl+, given meaning terms hybrid automata
discussed Section 6. mapping follows.
Consider following generic structure pddl2.1 durative action, excluding use
duration inequalities continuous effects. Conditional effects ignored, since
handled flattening actions described Core Definition 5. complication
conditional effects combine initial final conditions discussed (Fox & Long,
2003) affect basic principles demonstrate translation give
here. Similarly, convenience, consider duration constraints referring end
state extension treatment manage constraints straightforward.
(:durative-action name
:parameters (~
p)
:duration (= ?duration Dur[~
p])
:condition (and (at start P reS ) (at end P reE ) (over Inv))
:effect (and (at start P ostS )(at end P ostE [?duration]))
)
construct following structures pddl+:
291

fiFox & Long

(:action name-start
:parameters (~
p)
:precondition (and P reS (not (name clock started p~)))
:effect (and P ostS
(name clock started p~)
(assign (name clock p~) 0)
(assign (name duration p~) Dur[~
p])
(increase (clock count) 1))
(:process name-process
:parameters (~
p)
:precondition (name clock started p~)
:effect (increase (name clock p~) (* #t 1))
(:event name-failure
:parameters (~
p)
:precondition (and (name clock started p~)
(not (= (name clock p~) (name duration p~)))
(not Inv))
:effect (assign (name clock p~) (+ (name duration p~) 1)))
(:action name-end
:parameters (~
p)
:precondition (and P reE (name clock started p~)
(= (name clock p~) (name duration p~)))
:effect (and P ostE [(name duration p~)]
(not (name clock started p~))
(decrease (clock count) 1)))
complete transformation, initial state (= (clock count) 0) added
goal condition (= (clock count) 0) added it.
Note clock uniquely determined name arguments durative
action, clock shared different durative actions. Also note
one action start clock one terminate it. plan
makes use durative action transformed domain durative action
simulated actions start stop clock. order actions execute
successfully conditions must identical stipulated durative action
effects equivalent original durative action. Furthermore, end action
executed clock reached correct duration value (which recorded
start). clock driven process active start action
executed end action executed. event used monitor
invariant conditions. ever invariant becomes false clock running
event sets clock duration durative action. makes
impossible complete action terminate clock, valid execution trace
constructed achieve goal event triggered. Every time clock
292

fiModelling Mixed Discrete-Continuous Domains Planning

starts count incremented decremented clock stops. count must
zero end, meaning every clock must stopped therefore every durative
action must ended plan complete.
duration action managed using metric fluent store duration
outset order use value conclusion action. value fixed
constant simplified replacing metric fluent appropriate
constant.
Packaging actions, events processes durative action abstracts details
interval ends whether action event. example, durative
action used represent activity filling bath, end point represent
action turning taps, whilst durative action representing ball dropped,
end action event ball landing. However, syntactic
difference structures encoding examples allows distinction
drawn end point action one event. mapping
durative actions actions, processes events requires arbitrary decision
made handle end points durative actions. chosen use
actions, alternative formulation possible using events.
mapping converts every durative action family pddl+ constructs shown
two actions start end interval, process execute interval,and monitoring event invariant. action always used end
interval planner must always choose apply order obtain goal state. final
plan terminating action appear, chosen planner, even though application
fact forced, point application must consistent duration constraint
original durative action. Thus, although planner free choose whether
apply action, order construct valid plan forced apply action
point exactly meets appropriate temporal constraints. course, end points
simulated durative actions trivially post-processed make plan containing
durative actions instead underlying components.

References
Allen, J., & Koomen, J. A. (1983). Planning Temporal World Model. Proceedings
Eigth International Joint Conference Artificial Intelligence, pp. 741747.
Alur, R., & Dill, D. L. (1994). Theory Timed Automata. Theoretical Computer Science,
126, 183235.
Androulakis, I. P. (2001). MINLP: Branch Bound Methods. Floudas, C. A., &
Pardalos, P. M. (Eds.), Encyclopaedia Optimisation, Vol. 3, pp. 325331. Kluwer
Academic.
Aylett, R., Soutter, J., Petley, G., Chung, P., & Edwards, D. (2001). Planning plant operating procedures chemical plant. Engineering Applications Artificial Intelligence,
14(3).
Bacchus, F. (2003). power modelinga response PDDL2.1. Journal AI Research, 20, 125132.
293

fiFox & Long

Beasley, J., Krishnamoorthy, M., Sharaiha, Y., & Abramson, D. (2000). Scheduling Aircraft
Landings: Static Case. Transportation Science, 34 (2), 180197.
Behrmann, G., Larsen, K., & Rasmussen, J. (2005). Optimal Scheduling Using Priced
Timed Automata. SIGMETRICS Perform. Eval. Rev., 32 (4), 3440.
Benazera, E., Brafman, R., Meuleau, N., Mausam, & Hansen, E. A. (2005). AO*
Algorithm Planning Continuous Resources. Workshop Planning
Uncertainty Autonomous Systems, associated International Conference
AI Planning Scheduling (ICAPS).
Benders, J. F. (1962). Partitioning Procedures Solving Mixed-Variables Programming
Problems. Numerische Mathematik, 4, 238252.
Blake, O., Bridges, J., Chester, E., Clemmet, J., Hall, S., Hannington, M., Hurst, S., Johnson, G., Lewis, S., Malin, M., Morison, I., Northey, D., Pullan, D., Rennie, G., Richter,
L., Rothery, D., Shaughnessy, B., Sims, M., Smith, A., Townend, M., & Waugh, L.
(2004). Beagle2 Mars: Mission Report. Lander Operations Control Centre, National
Space Centre, University Leicester.
Boddy, M. (2003). Imperfect match: PDDL2. real applications. Journal AI Research,
20, 133137.
Boddy, M., & Johnson, D. (2002). new method solution large systems continuous constraints. Proceedings 1st International Workshop Global Constrained
Optimization Constraint Satisfaction (COCOS-02).
Boddy, M., & Johnson, D. (2004). Integrated planning scheduling petroleum refinery operations. Proceedings ICAPS Workshop Integrating Planning
Scheduling (WIPIS).
de Kleer, J., & Brown, J. S. (1984). Qualitative Physics based Confluences. Artificial
Intelligence, 24, 783.
Dechter, R., Meiri, I., & Pearl, J. (1991). Temporal constraint networks. Artificial Intelligence, 49.
Dierks, H. (2005). Finding Optimal Plans Domains Restricted Continuous Effects
UPPAAL-cora. First Workshop Validation Verification Planning,
ICAPS-05.
Edelkamp, S. (2003). Promela Planning. Proceedings 10th International SPIN Workshop Model Checking Software, pp. 197212.
Forbus, K. (1984). Qualitative Process Theory. Artificial Intelligence, 24, 85168.
Fox, M., Howey, R., & Long, D. (2005). Exploration Robustness Plans. Workshop
Verification Validation Model-based Planning Scheduling Systems, associated International Conference AI Planning Scheduling (ICAPS)).
Fox, M., Howey, R., & Long, D. (2006). Exploration Robustness Plans. Proceedings 21st National Conference Artificial Intelligence (AAAI-06).
Fox, M., & Long, D. (2003). PDDL2.1: Extension PDDL Expressing Temporal
Planning Domains. Journal AI Research, 20, 61124.
294

fiModelling Mixed Discrete-Continuous Domains Planning

Fox, M., & Long, D. (2004). Investigation Expressive Power PDDL2.1.
Proceedings Sixteenth European Conference Artificial Intelligence.
Frank, J., & Jonsson, A. (2003). Constraint-based Attribute Interval Planning. Journal
Constraints, 8 (Special Issue Constraints Planning)(4), 339364.
Frank, J., Jonsson, A., & Morris, P. (2000). Reformulating Planning Dynamic Constraint Satisfaction (Extended Abstract). Symposium Abstraction, Reformulation Approximation (SARA).
Grossmann, I. E. (2002). Review Nonlinear, Mixed-Integer Disjunctive Programming
Techniques. Optimization Engineering, 3, 227252.
Gupta, V., Henziner, T., & Jagadeesan, R. (1997). Robust Timed Automata. HART97:
Hybrid Real-time Systems, LNCS 1201, pp. 331345. Springer-Verlag.
Haroud, D., & Faltings, B. (1994). Global Consistency Continuous Constraints.
Principles Practice Constraint Programming, pp. 4050.
Helmert, M. (2002). Decidability undecidability results planning numerical
state variables. Proceedings sixth conference AI Planning Systems (AIPS).
Henzinger, T. (1996). Theory Hybrid Automata. Proceedings 11th Annual Symposium ogic Computer Science. Invited tutorial., pp. 278292. IEEE
Computer Society Press.
Henzinger, T., Ho, P.-H., & Wong-Toi, H. (1995). user guide HYTECH. E.
Brinksma, W.R. Cleaveland, K.G. Larsen, T. Margaria, B. Steffen, editors, Tool
Algorithms Construction Analysis Systems: (TACAS 95), volume
1019 Lecture Notes Computer Science, pp. 4171.
Henzinger, T., & Raskin, J.-F. (2000). Robust Undecidability Timed Hybrid Systems.
Proceedings 3rd International Workshop Hybrid Systems: Computation
Control. LNCS 1790., pp. 145159. Springer-Verlag.
Henzinger, T. A., Kopke, P. W., Puri, A., & Varaiya, P. (1998). Whats Decidable
Hybrid Automata?. Journal Computer System Sciences, 57, 94124.
Herrmann, C. S., & Thielscher, M. (1996). Reasoning continuous processes.
Clancey, B., & Weld, D. (Eds.), Proceedings Thirteenth National Conference
Artificial Intelligence (AAAI), pp. 639644, Portland, OR. MIT Press.
Hoffmann, J., & Edelkamp, S. (2005). Classical Part IPC-4: Overview. Journal
AI Research, appear.
Hofmann, A., & Williams, B. (2006). Robust execution temporally flexible plans
bipedal walking devices. Proceedings 16th International Conference Automated Planning Scheduling (ICAPS), pp. 386389.
Howey, R., Long, D., & Fox, M. (2004). Val: Automatic plan validation, continuous effects
mixed initiative planning using pddl. Proceedings 16th IEEE International
Conference Tools Artificial Intelligence.
Jonsson, A., & Frank, J. (2000). Framework Dynamic Constraint Reasoning using
Procedural Constraints. Proceedings 14th European Conference AI, pp. 9397.
295

fiFox & Long

Jonsson, A., Morris, P., Muscettola, N., Rajan, K., & Smith, B. (2000). Planning Interplanetary Space: Theory Practice. Proceedings 5th International Conference
AI Planning Systems, pp. 177186.
Keller, R. (1976). Formal Verification Parallel Programs. Communications ACM,
19 (7), 371384.
Kuipers, B. (1984). Commonsense Reasoning Causality: Deriving Behaviour
Structure. Artificial Intelligence, 24, 169203.
Laborie, P., & Ghallab, M. (1995). Planning sharable resource constraints. Proc.
14th International Joint Conference AI. Morgan Kaufmann.
Lamba, N., Dietz, M., Johnson, D., & Boddy, M. (2003). method global optimization
large systems quadratic constraints. Proceedings 2nd International Workshop
Global Constrained Optimization Constraint Satisfaction (COCOS-03).
Larsen, K. G., Behrmann, G., Brinksma, E., Fehnker, A., Hune, T., Pettersson, P., &
Romijn, J. (2001). use optimistic pessimistic resource profiles inform
search activity based planner. Proceedings 13th Conference Computer
Aided Verification (CAV-01)). Springer Verlag, Lecture Notes Computer Science
2102.
Leaute, T., & Williams, B. (2005). Coordinating Agile Systems Model-based
Execution Temporal Plans. Proceedings 20th National Conference AI
(AAAI), pp. 114120.
McAllester, D., & Rosenblitt, D. (1991). Systematic Nonlinear Planning. Proceedings
Ninth National Conference Artificial Intelligence (AAAI-91), Vol. 2, pp.
634639, Anaheim, California, USA. AAAI Press/MIT Press.
McDermott, D. (2003a). PDDL2.1 Art Possible? Commentary Fox
Long. Journal AI Research, 20, 145148.
McDermott, D. (2003b). Reasoning autonomous processes estimated-regression
planner. Proceedings International Conference Automated Planning
Scheduling (ICAPS03).
McDermott, D. (2005). Reasoning Autonomous Processes Estimated Regression
Planner. Proceedings 13th International Conference Automated Planning
Scheduling (ICAPS), pp. 143152. AAAI-Press.
McDermott, D., & AIPS98 Planning Competition Committee (1998). PDDLthe planning domain definition language. Tech. rep., Available at: www.cs.yale.edu/homes/dvm.
McDermott, D. (2004). Opt Optop API. Tech. rep., Yale University.
Muscettola, N. (1993). HSTS: Integrating Planning Scheduling. Zweben, M., & Fox,
M. (Eds.), Intelligent Scheduling, pp. 169212. Morgan Kaufmann, San Mateo, CA.
Musliner, D. J., Durfee, E. H., & Shin, K. G. (1993). CIRCA: Cooperative Intelligent
Real-time Control Archtecture. IEEE Transactions Systems, Man Cybernetics,
23 (6), 15611574.
296

fiModelling Mixed Discrete-Continuous Domains Planning

Penberthy, J., & Weld, D. (1992). UCPOP: sound, complete, partial-order planner
ADL. Proc. Int. Conf. Principles Knowledge Representation Reasoning,
pp. 103114, Los Altos, CA. Kaufmann.
Penberthy, S., & Weld, D. (1994). Temporal Planning Continuous Change. Proceedings Twelfth National Conference Artificial Intelligence (AAAI), pp.
10101015. AAAI/MIT Press.
Rasmussen, J. I., Larsen, K. G., & Subramani, K. (2004). Resource Optimal Scheduling
using Priced Timed Automata. Proceedings 10th International Conference
Tools Algorithms Construction Analysis Systems (TACAS), pp.
220235. Springer-Verlag, Lecture Notes Computer Science, 2988.
Reiter, R. (1996). Natural Actions, Concurrency Continuous Time Situation
Calculus. Aiello, L., Doyle, J., & Shapiro, S. (Eds.), KR-96: Principles Knowledge
Representation Reasoning, pp. 213. Morgan Kaufmann.
Reiter, R. (2001). Knowledge Action: Logical Foundations Secifying Implementing
Dynamical Systems. MIT Press.
Sandewall, E. (1989). Combining Logic Differential Equations describing Real World
Systems. Proceedings Knowledge Representation (KR), pp. 412420.
Shanahan, M. (1990). Representing Continuous Change Event Calculus. Proceedings 9th European Conference AI, pp. 598603.
Shin, J.-A., & Davis, E. (2005). Processes Continuous Change SAT-based Planner.
Artificial Intelligence, 166, 194253.
Smith, D. (2003). case durative actions: commentary PDDL2.1. Journal
AI Research, 20, 149154.
Wolfman, S., & Weld, D. (1999). LPSAT System Application Resource
Planning. Proceedings Sixteenth International Joint Conference Artificial
Intelligence.
Wu, S. J., & Chow, P. T. (1995). Genetic Algorithms Nonlinear Mixed Discrete-Integer
Optimization Problems via Meta-Genetic Parameter Optimization. Engineering Optimization, 24 (2), 137159.
Yi, W., Larsen, K., & Pettersson, P. (1997). UPPAAL Nutshell. International Journal
Software Tools Technology Transfer, 1 (1).

297

fiJournal Artificial Intelligence Research 27 (2006) 85117

Submitted 01/06; published 09/06

Learning Sentence-internal Temporal Relations
MLAP @ INF. ED . AC . UK

Mirella Lapata
Alex Lascarides

ALEX @ INF. ED . AC . UK

School Informatics,
University Edinburgh,
2 Buccleuch Place,
Edinburgh, EH8 9LW,
Scotland, UK

Abstract
paper propose data intensive approach inferring sentence-internal temporal
relations. Temporal inference relevant practical NLP applications either extract synthesize temporal information (e.g., summarisation, question answering). method bypasses
need manual coding exploiting presence markers like after, overtly signal
temporal relation. first show models trained main subordinate clauses connected
temporal marker achieve good performance pseudo-disambiguation task simulating
temporal inference (during testing temporal marker treated unseen models must
select right marker set possible candidates). Secondly, assess whether proposed
approach holds promise semi-automatic creation temporal annotations. Specifically,
use model trained noisy approximate data (i.e., main subordinate clauses) predict
intra-sentential relations present TimeBank, corpus annotated rich temporal information.
experiments compare contrast several probabilistic models differing feature space, linguistic assumptions data requirements. evaluate performance gold standard corpora
also human subjects.

1. Introduction
computational treatment temporal information recently attracted much attention, part
increasing importance potential applications. multidocument summarization,
example, information included summary must extracted various
documents synthesized meaningful text. Knowledge temporal order events
important determining content communicated correctly merging
presenting information summary. Indeed, ignoring temporal relations either information
extraction summary generation phase may result summary misleading
respect temporal information original documents. question answering, one often
seeks information temporal properties events (e.g., X resign? ) events
relate (e.g., X resign Y? ).
important first step towards automatic handling temporal phenomena analysis
identification time expressions. expressions include absolute date time specifications (e.g., October 19th, 2000 ), descriptions intervals (e.g., thirty years ), indexical expressions
(e.g., last week ), etc. therefore surprising much previous work focused recog-

c 2006 AI Access Foundation. rights reserved.

fiL APATA & L ASCARIDES

nition, interpretation, normalization time expressions 1 (Wilson, Mani, Sundheim, & Ferro,
2001; Schilder & Habel, 2001; Wiebe, OHara, Ohrstrom Sandgren, & McKeever, 1998). Reasoning
time, however, goes beyond temporal expressions; also involves drawing inferences
temporal relations among events temporal elements discourse. additional challenge
task stems nature temporal information itself, often implicit (i.e.,
overtly verbalized) must inferred using linguistic non-linguistic knowledge.
Consider examples (1) taken Katz Arosio (2001). Native speakers infer
John first met kissed girl; left party kissing girl walked
home; events talking asking name temporally overlap (and
occurred left party).
(1)

a.

John kissed girl met party.

b.

Leaving party, John walked home.

c.

remembered talking asking name.

temporal relations described part interpretation text, even though
overt markers, while, signaling them. inferable variety
cues, including order clauses, compositional semantics (e.g., information
tense aspect), lexical semantics world knowledge. paper describe data intensive
approach automatically captures information pertaining temporal relations among events
like ones illustrated (1).
standard approach task would acquire model temporal relations
corpus annotated temporal information. Although efforts underway develop treebanks
marked temporal relations (Katz & Arosio, 2001) devise annotation schemes suitable coding temporal relations (Saur, Littman, Gaizauskas, Setzer, & Pustejovsky, 2004; Ferro,
Mani, Sundheim, & Wilson, 2000; Setzer & Gaizauskas, 2001), existing corpora small
size amenable supervised machine learning techniques normally require thousands training examples. TimeBank 2 corpus, example, contains set 186 news report
documents annotated TimeML mark-up language temporal events expressions (for
details, see Sections 2 7). corpus consists 68.5K words total. Contrast
Penn Treebank, corpus often used many NLP tasks contains approximately 1M
words (i.e., 16 times larger TimeBank). annotation temporal information
time-consuming also error prone. particular, n kinds temporal relations,
number possible relations annotate polynomial factor n number events
text. Pustejovsky, Mani, Belanger, Boguraev, Knippen, Litman, Rumshisky, See, Symonen, van
Guilder, van Guilder, Verhagen (2003) found evidence annotation task sufficiently
complex human annotators realistically identify small number temporal relations text, thus compromising recall.
default large volumes data labeled temporal information, turn unannotated
texts nevertheless contain expressions overtly convey information want models learn. Although temporal relations often underspecified, sometimes temporal
markers, before, after, while, make relations among events explicit:
1. See also Time Expression Recognition Normalisation (TERN) evaluation exercise (http://timex2.mitre.
org/tern.html).
2. Available http://www.cs.brandeis.edu/jamesp/arda/time/timebank.html

86

fiL EARNING ENTENCE - INTERNAL EMPORAL R ELATIONS

(2)

a.

Leonard Shane, 65 years old, held post president William Shane, 37,
elected last year.

b.

results announced market closed.

c.

Investors markets sat awaiting U.S. trade figures.

precisely type data exploit making predictions temporal
relationships among events text. assess feasibility approach initially
focusing sentence-internal temporal relations. large corpus, obtain sentences like
ones shown (2), main clause connected subordinate clause temporal
marker, develop probabilistic framework temporal relations inferred
gathering informative features two clauses. models view marker
sentence training corpus label learned. test corpus marker
removed models task pick likely labelor equivalently marker.
also examine whether models trained data containing main subordinate clauses
together temporal connectives used infer relations among events temporal
information underspecified overt temporal markers absent (as three sentences (1)). purpose, resort TimeBank corpus. latter contains detailed
annotations events temporal relations irrespectively whether connectives present
not. Using TimeBank annotations solely test data, assess whether approach
put forward generalizes different structures corpora. evaluation study also highlight
whether model learned unannotated examples could alleviate data acquisition bottleneck
involved creation temporal annotations. example, automatically creating high
volume annotations could subsequently corrected manually.
attempting infer temporal relations probabilistically, consider several classes models varying degrees faithfulness linguistic theory. models differ along two dimensions:
employed feature space underlying independence assumptions. compare contrast models utilize word-co-occurrences models exploit linguistically motivated
features (such verb classes, argument relations, on). Linguistic features typically allow
models form generalizations classes words, thereby requiring less training data
word co-occurrence models. also compare contrast two kinds models: one assumes
properties two clauses mutually independent; makes slightly realistic assumptions dependence. (Details models features used given Sections 3
4). furthermore explore benefits ensemble learning methods temporal interpretation task show improved performance achieved different learners (modeling
sufficiently distinct knowledge sources) combined. machine learning experiments complemented study investigate human performance interpretation task thereby
assessing feasibility providing ceiling model performance.
next section gives overview previous work area computing temporal information discusses related work utilizes overt markers means avoiding manual
labeling training data. Section 3 describes probabilistic models Section 4 discusses
features motivation behind selection. experiments presented Sections 57.
Section 8 offers discussion concluding remarks.

87

fiL APATA & L ASCARIDES

2. Related Work
Traditionally, methods inferring temporal relations among events discourse utilized
semantics inference-based approach. involves complex reasoning variety rich information sources, including elaborate domain knowledge detailed logical form representations
(e.g., Dowty, 1986; Hwang & Schubert, 1992; Hobbs et al., 1993; Lascarides & Asher, 1993; Kamp
& Reyle, 1993; Kehler, 2002). approach, theoretically elegant, impractical except
applications narrow domains. (at least) two reasons. First, grammars produce
detailed semantic representations inevitably lack linguistic coverage brittle face
natural data; similarly, representations domain knowledge lack coverage. Secondly,
complex reasoning required rich information sources typically involves nonmonotonic
inferences (e.g., Hobbs et al., 1993; Lascarides & Asher, 1993), become intractable except
toy examples.
Allen (1995), Hitzeman, Moens, Grover (1995), Han Lavie (2004) propose
computationally tractable approaches infer temporal information text, hand-crafting algorithms integrate shallow versions knowledge sources exploited
theoretical literature (e.g., Hobbs et al., 1993; Kamp & Reyle, 1993). type symbolic
approach promising, overcomes impracticalities utilizing full logical forms
complex reasoning rich domain knowledge sources, grounded empirical evidence
way various linguistic features contribute temporal semantics discourse;
algorithms evaluated real data. Moreover, approach typically domain-dependent
robustness compromised porting new domains applications.
Acquiring model temporal relations via machine learning training corpus promises
provide systems precise, robust, grounded empirical evidence. number
markup languages recently emerged greatly facilitate annotation efforts creating suitable corpora. notable example TimeML (Pustejovsky, Ingria, Sauri, Castano, Littman,
Gaizauskas, & Setzer, 2004; see also annotation scheme Katz & Arosio, 2001), metadata
standard expressing information temporal properties events temporal relations
them. scheme used annotate variety temporal expressions, including
tensed verbs, adjectives nominals correspond times, events states. type temporal information expressed various linguistic expressions includes class
event, tense, grammatical aspect, polarity (positive negative), time denoted (e.g., one
annotate yesterday denoting day document date), temporal relations
pairs eventualities events times. TimeMLs expressive capabilities illustrated
TimeBank corpus contains temporal annotations news report documents (for details,
see Section 7).
Mani, Schiffman, Zhang (2003) Mani Schiffman (2005) demonstrate
TimeML-compliant annotations useful learning model temporal relations news text.
focus problem ordering pairs successively described events. decision tree classifier trained corpus temporal relations provided human subjects. Using features
position sentence within paragraph (and position paragraph text),
discourse connectives, temporal prepositions temporal modifiers, tense features, aspect
shifts tense shifts, best model achieves 75.4% accuracy identifying temporal order
events. Boguraev Ando (2005) use semi-supervised learning recognizing events inferring temporal relations (between event time expression). method exploits TimeML
88

fiL EARNING ENTENCE - INTERNAL EMPORAL R ELATIONS

annotations TimeBank corpus large amounts unannotated data. first build
classifier TimeML annotations using variety features based syntactic analysis
identification temporal expressions. original feature vectors next augmented
unlabeled data sharing structural similarities training data. algorithm yields performances well baseline tasks.
Conceivably, existing corpus data annotated discourse structure, RST treebank (Carlson et al., 2001), might reused train temporal relations classifier. instance,
text spans connected RESULT, implied semantics relation events
first span temporally precede second; thus, classifier rhetorical relations could indirectly contribute classifier temporal relations. Corpus-based methods computing discourse structure beginning emerge (e.g., Marcu, 1999; Soricut & Marcu, 2003; Baldridge &
Lascarides, 2005). currently automatic mapping discourse structures
temporal consequences; although potential eventually using linguistic resources labeled discourse structure acquire model temporal relations, potential cannot
presently realized.
Continuing topic discourse relations, worth mentioning Marcu Echihabi
(2002) whose approach bypasses altogether need manual coding supervised learning
setting. key insight work rhetorical relations (e.g., EXPLANATION CONTRAST)
sometimes signaled discourse connective (e.g., EXPLANATION
CONTRAST). extract sentences containing markers corpus, (automatically) identify text spans connected marker, remove marker replace
rhetorical relation signals. Naive Bayes classifier trained automatically labeled data.
model designed maximally simple employs solely word bigrams features. Specifically, bigrams constructed cartesian product words occurring two text spans
assumed word pairs conditionally independent. Marcu Echihabi demonstrate
knowledge-lean approach performs well, achieving accuracy 49.70% distinguishing six relations (over baseline 16.67%). However, since model relies exlusively
word-co-occurrences, extremely large training corpus (in order 40 sentences) required
avoid sparse data (see Sporleder & Lascarides, 2005 detailed discussion tradeoff
training size feature space discourse-based models).
sense, considering complexity various models used infer temporal
discourse relations, Marcu Echihabis (2002) model lies simple extreme spectrum,
whereas semantics inference-based approaches discourse interpretation (e.g., Hobbs et al.,
1993; Asher & Lascarides, 2003) lie extreme, latter theories assume independence among properties spans, exploit linguistic non-linguistic features
full. paper, aim explore number probabilistic models lie
two extremes, thereby giving us opportunity study tradeoff complexity
model one hand, amount training data required other. particularly interested assessing performance models smaller training sets used
Marcu Echihabi (2002); models useful classifiers trained data sets
relatively rare temporal markers exploited.
work differs Mani et al. (2003) Boguraev Ando (2005)
exploit manual annotations way. aim however similar, since also infer temporal
relations pairs events. share Marcu Echihabi (2002) use data
overt markers proxy hand coded relations. Apart fact interpretation task
89

fiL APATA & L ASCARIDES

different theirs, work departs Marcu Echihabi (2002) three important
ways. First, propose alternative models explore contribution linguistic information
inference task, investigating enables one train considerably smaller data sets.
Secondly, proposed models used infer relations events realistic setting,
temporal markers naturally absent (i.e., test data simulated removing
markers question). finally, evaluate models human subjects performing
task, well gold standard corpus.

3. Problem Formulation



Given main clause subordinate clause attached it, task infer temporal marker
linking two clauses. P SM j SS represents probability marker j relates main clause
SM subordinate clause SS . aim identify marker j set possible markers
maximizes joint probability P j SS :













ff fififi
ff

ff fififi
ff
ff fififi
ff

ff fififi
ff
argmax P SM j SS



(3)

tj

argmax P SM P SS SM P j SM SS



tj

ignore terms P SM P SS SM (3) constant. use Bayes Rule calculate
P j SM SS :


argmax P j SM SS

(4)

tj



argmax P j P SM SS j



argmax P j P 1

tj

n tj

tj

SM SS vectors features 1
n 1
n characteristic propositions
occurring marker j (our features described detail Section 4.2). Estimating
different P 1
n j terms feasible unless large set training
data. therefore make simplifying assumption temporal marker j determined
observing feature pairs representative main subordinate clause. assume
feature pairs conditionally independent given temporal marker arbitrary:
rather considering pairs cartesian product 1
n (see Marcu & Echihabi,
2002), restrict feature pairs belong class i. Thus, probability
observing conjunction 1
n given j is:


ff fififi
ff


fffififi
ff



ff
ff


argmax P j
tj



ff
ff

n

1

(5)

P tj

example, assuming feature space consisted solely nouns verbs, would
estimate P j taking account noun-noun verb-verb bigrams
attested SS SM co-occur j .
model (4) simplified assuming likelihood subordinate
clause SS conditionally independent main clause (i.e., P SS SM j
P SS j P SM j ).



90



fiL EARNING ENTENCE - INTERNAL EMPORAL R ELATIONS





assumption clearly simplification makes estimation probabilities P j
P SS j reliable face sparse data:






ff fififi
ff
ff fififi
ff


ff
ff

ff


argmax P j P SM j P SS j

(6)

tj

SM SS vectors features 1
n 1
n representing clauses
co-occurring marker j . individual features (instead feature pairs) assumed
conditionally independent given temporal marker, therefore:




argmax P j
tj

n

(7)

P tj P tj

1


ff

Returning example feature space nouns verbs, P j P j
estimated considering often verbs nouns co-occur j . co-occurrences
estimated separately main subordinate clauses.
Throughout paper use terms conjunctive model (5) disjunctive
model (7). effectively treat temporal interpretation problem disambiguation task.
(confusion) set temporal markers, e.g., after, before, since , select one maximizes (5) (7) (see Section 4 details confusion set corpus). conjunctive model
explicitly captures dependencies main subordinate clauses, whereas disjunctive
model somewhat simplistic relationships features across two clauses
represented directly. However, two values features main subordinate clauses
co-occur frequently particular marker, conditional probability features
marker approximate right biases.
conjunctive model closely related kinds symbolic rules inferring
temporal relations used semantics inference-based accounts (e.g., Hobbs et al., 1993).
Many rules typically draw relationships verbs clauses, nouns
clauses, on. disjunctive conjunctive models different Marcu
Echihabis (2002) model several respects. utilize linguistic features rather word
bigrams. conjunctive models features two-dimensional dimension belonging
feature class. disjunctive model added difference assumes independence
features attested two clauses.




4. Parameter Estimation


ff
ff

ff

ff

estimate parameters models large corpus. simplest form,
features words making main subordinate clauses. order extract
relevant features, first identify clauses hypotactic relation, i.e., main clauses
subordinate clause constituent. training phase, estimate probabilities P j
P j disjunctive model simply counting occurrence features
marker j (i.e., f j ) ( f j ). essence, assume model
corpus representative way various temporal markers used English.
conjunctive model estimate co-occurrence frequencies f j . Features zero
counts smoothed models; adopt m-estimate uniform priors, equal
size feature space (Cestnik, 1990).


ff


ff

91


ff

ff


ff
ff

fiL APATA & L ASCARIDES

(S1 (S (NP (DT The) (NN company))
(VP (VBD said)
(S (NP (NNS employees))
(VP (MD will)
(VP (VB lose)
(NP (PRP their) (NNS jobs))
(SBAR-TMP (IN after)
(S (NP (DT the) (NN sale))
(VP (AUX is) (VP (VBN completed)))
))))))))

Figure 1: Extraction main subordinate clause parse tree
4.1 Data Extraction
order obtain training testing data models described previous section, subordinate clauses (and main clause counterparts) extracted B LLIP corpus (30
words). latter Treebank-style, machine-parsed version Wall Street Journal (WSJ,
years 198789) produced using Charniaks (2000) parser. study focused following (confusion) set temporal markers: after, before, while, when, as, once, until, since .
initially compiled list temporal markers discussed Quirk, Greenbaum, Leech, Svartvik
(1985) eliminated markers frequency less 10 per million corpus.
extract main subordinate clauses connected temporal discourse markers, first
traversing tree top-down identify tree node bearing subordinate clause label
interested extract subtree dominates. Assuming want extract
subordinate clauses, would subtree dominated SBAR-TMP Figure 1 indicated
arrow pointing (see sale completed ). found subordinate clause,
proceed extract main clause traversing tree upwards identifying node immediately dominating subordinate clause node (see arrow pointing Figure 1, employees
lose jobs ). cases subordinate clause sentence initial, first identify
SBAR-TMP node extract subtree dominated it, traverse tree downwards
order extract S-tree immediately dominating it.
experiments described focus solely subordinate clauses immediately dominated S, thus ignoring cases nouns related clauses via temporal marker (e.g., John
left lunch ). Note one main clause qualify attachment sites
subordinate clause. Figure 1 subordinate clause sale completed attached either said loose. similar structural ambiguities identifying
subordinate clause; example see (8), conjunction lie within scope
subordinate -clause (and indeed, parser disambiguates structural ambiguity correctly
case):




(8)

[ Mr. Grambling made $250,000 banks money [ Colonial caught
denied remaining $100,000. ] ]

relying parser providing relatively accurate resolutions structural ambiguities, unavoidably create noise data. estimate extent noise,
manually inspected 30 randomly selected examples temporal discourse markers
92

fiL EARNING ENTENCE - INTERNAL EMPORAL R ELATIONS

TMark






since

TOTAL

Frequency
35,895
15,904
13,228
6,572
5,307
3,524
2,742
638
83,810

Distribution (%)
42 83
19 00
15 79
7 84
6 33
4 20
3 27
0 76
100 00

Table 1: Subordinate clauses extracted B LLIP corpus
i.e., 240 examples total. examples inspected true positives temporal discourse markers save one, parser assumed took sentential complement whereas
reality NP complement (i.e., anti-poverty worker ):
(9)

[ first moved West Virginia [ anti-poverty worker, decided stay start
political career, eventually serving two terms governor. ] ]

cases noise due fact parser either overestimates underestimates
extent text span two clauses. 98.3% main clauses 99.6% subordinate clauses accurately identified data set. Sentence (10) example parser
incorrectly identifies main clause: predicts -clause attached denationalise
countrys water industry. Note, however, subordinate clause (as managers resisted
move workers threatened lawsuits ) correctly identified.
(10) [ Last July, government postponed plans [ denationalise countrys water industry
[ managers resisted move workers threatened lawsuits. ] ] ]
size corpus obtain extraction methods detailed Table 1.
83,810 instances overall (i.e., 0.20% size corpus used Marcu Echihabi,
2002). Also note distribution temporal markers ranges 0.76% (for ) 42.83%
(for ).
discourse markers confusion set underspecify temporal semantic information.
example, entail temporal overlap (see (11a), Kamp & Reyle, 1993), temporal
progression (see (11c), Moens & Steedman, 1988). true once, since, :
(11) a.
b.
(12) a.
b.

Mary left Bill preparing dinner.

(temporal overlap)

built bridge, solved traffic problems. (temporal progression)
John moved London, got job council.
John living London, got job council.

93

(temporal progression)
(temporal overlap)

fiL APATA & L ASCARIDES

(13) a.
b.
(14) a.
b.

John worked council since hes living London.
John moved London since got job council there.
temporal precedence)

(temporal overlap)
(cause hence

Grand melodies poured contemplated Caesars conquest Egypt. (temporal overlap)
went bank ran cash.

(cause, hence temporal precedence)

means model chooses when, once, since likely marker
main subordinate clause, temporal relation events described left underspecified. course semantics limits range possible relations,
model identify specific relation conveyed markers given example. Similarly, ambiguous temporal use signals eventualities
temporally overlap (see (15a)) contrastive use convey particular temporal
relation (although relations may conveyed features sentence, tense,
aspect world knowledge; see (15b)).
(15) a.

stock market rising steadily, even companies stuffed cash rushed
issue equity.

b.

point history directly opposed Liberal Theology, appeal
spirit somehow detachable Jesus history run much along similar
lines Liberal approach.

inspected 30 randomly-selected examples markers underspecified readings
(i.e., when, once, since, ). marker entails temporal overlap interpretation 70% time entails temporal overlap 75% time, whereas since
likely entail temporal progression (74% 80%, respectively). markers
receive predominantly temporal interpretations corpus. Specifically, non-temporal
uses 13.3% instances sample 25%. interpretation model
applied, could use biases disambiguate, albeit coarsely, markers underspecified meanings. Indeed, demonstrate Experiment 3 (see Section 7) model useful
estimating unambiguous temporal relations, even original sentence temporal
marker, ambiguous otherwise.
4.2 Model Features
number knowledge sources involved inferring temporal ordering including tense, aspect, temporal adverbials, lexical semantic information, world knowledge (Asher & Lascarides,
2003). selecting features represent knowledge sources, notwithstanding indirectly
imperfectly, aim empirically assess contribution temporal inference task.
introduce features provide motivation behind selection.
Temporal Signature (T) well known verbal tense aspect impose constraints
temporal order events also choice temporal markers. constraints perhaps
best illustrated system Dorr Gaasterland (1995) examine inherent (i.e., states
events) non-inherent (i.e., progressive, perfective) aspectual features interact time
stamps eventualities order generate clauses markers relate them.
94

fiL EARNING ENTENCE - INTERNAL EMPORAL R ELATIONS

FINITE

NON - FINITE
MODALITY
ASPECT
VOICE
NEGATION

=
=
=
=
=
=


past, present
0, infinitive, ing-form, en-form
/ future, ability, possibility, obligation
0,
imperfective, perfective, progressive
active, passive
affirmative, negative






















Table 2: Temporal signatures
Feature
FIN
PAST
ACT
MOD
NEG

onceM
0.69
0.28
0.87
0.22
0.97

onceS
0.72
0.34
0.51
0.02
0.98

sinceM
0.75
0.35
0.85
0.07
0.95

sinceS
0.79
0.71
0.81
0.05
0.97

Table 3: Relative frequency counts temporal features main (subscript M) subordinate
(subscript S) clauses

Although cannot infer inherent aspectual features verb surface form (for would
need dictionary verbs aspectual classes together process assigns aspectual
classes given context), extract non-inherent features parse trees. first
identify verb complexes including modals auxiliaries classify tensed non-tensed
expressions along following dimensions: finiteness, non-finiteness, modality, aspect, voice,
polarity. values features shown Table 2. features finiteness non-finiteness
mutually exclusive.
Verbal complexes identified parse trees heuristically devising set 30 patterns search sequences auxiliaries verbs. parser output verbs classified
passive active building set 10 passive identifying patterns requiring passive
auxiliary (some form get ) past participle.
illustrate example, consider parse tree Figure 1. identify verbal
groups lose completed main subordinate clause respectively. former
mapped features present, 0, future, imperfective, active, affirmative , whereas latter
/ imperfective, passive, affirmative , 0 indicates verb form finite
mapped present, 0, 0,
0/ indicates absence modal. Table 3 show relative frequencies corpus
finiteness (FIN), past tense (PAST), active voice (ACT), negation (NEG) main subordinate
clauses conjoined markers since. seen differences
distribution counts main subordinate clauses different markers.
instance, past tense frequent since subordinate clauses modal verbs
often attested since main clauses compared main clauses. Also,
main clauses likely active, whereas subordinate clauses either active
passive.








95

fiL APATA & L ASCARIDES

TMark




since




VerbM
sell
come
say
become
rise
protect
make
wait

VerbS
leave
acquire
announce
complete
expect
pay
sell
complete

SupersenseM
communication
motion
stative
stative
stative
communication
stative
communication

SupersenseS
communication
motion
stative
stative
change
possession
motion
social

LevinM
say
say
say
say
say
say
characterize
say

LevinS
say
begin
begin
get
begin
get
get
amuse

Table 4: frequent verbs verb classes main (subscript M) subordinate clauses (subscript M)

Verb Identity (V) Investigations interpretation narrative discourse shown specific lexical information plays important role determining temporal interpretation (e.g., Asher
& Lascarides, 2003). example, fact verbs like push cause movement object
verbs like fall describe movement subject used interpret discourse
(16) pushing causing falling, thus making linear order events mismatch
temporal order.
(16) Max fell. John pushed him.
operationalize lexical relationships among verbs data counting occurrence
main subordinate clauses lemmatized version B LLIP corpus. Verbs extracted
parse trees containing main subordinate clauses. Consider tree Figure 1.
Here, identify lose complete, without preserving information tense passivisation
explicitly represented temporal signatures. Table 4 lists frequent verbs
attested main (VerbM ) subordinate (VerbS ) clauses conjoined temporal markers after,
as, before, once, since, until, when, (TMark).
Verb Class (VW , VL ) verb identity feature capture meaning regularities concerning
types verbs entering temporal relations. example, Table 4 sell pay possession
verbs, say announce communication verbs, come rise motion verbs. Asher
Lascarides (2003) argue many rules inferring temporal relations specified
terms semantic class verbs, opposed verb forms themselves, maximize
linguistic generalizations captured model temporal relations. purposes,
additional empirical motivation utilizing verb classes well verbs themselves: reduces
risk sparse data. Accordingly, use two well-known semantic classifications obtaining
degree generalization extracted verb occurrences, namely WordNet (Fellbaum,
1998) verb classification proposed Levin (1995).
Verbs WordNet classified 15 broad semantic domains (e.g., verbs change, verbs
cognition, etc.) often referred supersenses (Ciaramita & Johnson, 2003). therefore mapped
verbs occurring main subordinate clauses WordNet supersenses (feature V W ). Semantically ambiguous verbs correspond one semantic class. resolve ambiguity
96

fiL EARNING ENTENCE - INTERNAL EMPORAL R ELATIONS

TMark




since




NounN
year
market
time
stock
company
president
act
group

NounS
company
dollar
year
place
month
year
act
act

SupersenseM
act
act
act
act
act
act
year
chairman

SupersenseS
act
act
group
act
act
act
year
plan

AdjM
last
recent
long

first
new
last
first

AdjS
new
previous
new
new
last
next
last


Table 5: frequent nouns, noun classes, adjectives main (subscript M) subordinate
clauses (subscript M)

heuristically always defaulting verbs prime sense (as indicated WordNet) selecting corresponding supersense. cases verb listed WordNet default
lemmatized form.
Levin (1995) focuses relation verbs arguments hypothesizes
verbs behave similarly respect expression interpretation arguments
share certain meaning components therefore organized semantically coherent classes
(200 total). Asher Lascarides (2003) argue classes provide important information
identifying semantic relationships clauses. Verbs data mapped
corresponding Levin classes (feature V L ); polysemous verbs disambiguated method
proposed Lapata Brew (2004). 3 Again, verbs included Levin, lemmatized verb
form used. Examples frequent Levin classes main subordinate clauses
well WordNet supersenses given Table 4.
Noun Identity (N) verbs, also nouns provide important information
semantic relation two clauses; Asher Lascarides (2003) discuss example
noun meal one sentence salmon serves trigger inferences
events part-whole relation (eating salmon part meal). example
corpus concerns nouns share market. former typically found main clauses
preceding latter often subordinate clause. Table 5 shows frequently attested nouns (excluding proper names) main (Noun ) subordinate (NounS ) clauses
temporal marker. Notice time denoting nouns (e.g., year, month ) relatively frequent
data set.
Nouns extracted lemmatized version B LLIP corpus. Figure 1 nouns
employees, jobs sales relevant Noun feature. cases noun compounds,
compound head (i.e., rightmost noun) taken account. small set rules used
identify organizations (e.g., United Laboratories Inc.), person names (e.g., Jose Y. Campos ),
3. Lapata Brew (2004) develop simple probabilistic model determines given polysemous verb
frame likely meaning overall (i.e., across corpus), without relying availability disambiguated
corpus. model combines linguistic knowledge form Levin (1995) classes frame frequencies acquired parsed corpus.

97

fiL APATA & L ASCARIDES

locations (e.g., New England ) subsequently substituted general categories
person, organization, location.
Noun Class (NW ) verbs, Asher Lascarides (2003) argue favor symbolic rules
inferring temporal relations utilize semantic classes nouns wherever possible,
maximize linguistic generalizations captured. example, argue one
infer causal relation (17) basis noun bruise cause via act-on predicate
underspecified agent (other nouns class include injury, sinking, construction ):
(17) John hit Susan. bruise enormous.
Similarly, inferring salmon part meal (18) rests fact noun salmon,
one sense least, denotes edible substance.
(18) John ate wonderful meal. devoured lots salmon.
case verbs, nouns also represented supersenses WordNet taxonomy. Nouns WordNet form single hierarchy; instead partitioned according
set semantic primitives 25 supersenses (e.g., nouns cognition, events, plants, substances,
etc.), treated unique beginners separate hierarchies. nouns extracted
parser mapped WordNet classes. Ambiguity handled way verbs.
Examples frequent noun classes attested main subordinate clauses illustrated
Table 5.
Adjective (A) motivation including adjectives feature set twofold. First, hypothesize temporal adjectives (e.g., old, new, later ) frequent subordinate clauses
introduced temporal markers before, after, therefore may provide clues
relations signaled markers. Secondly, similarly verbs nouns, adjectives carry important lexical information used inferring semantic relation holds two
clauses. example, antonyms often provide clues temporal sequence two events
(see incoming outgoing (19)).
(19) incoming president delivered inaugural speech. outgoing president resigned last
week.
verbs nouns, adjectives extracted parsers output. frequent
adjectives main (AdjM ) subordinate (AdjS ) clauses given Table 4.
Syntactic Signature (S) syntactic differences main subordinate clauses captured
syntactic signature feature. feature viewed measure tree complexity,
encodes main subordinate clause number NPs, VPs, PPs, ADJPs,
ADVPs contains. feature easily read parse tree. syntactic signature
main clause Figure 1 [NP:2 VP:2 ADJP:0 ADVP:0 PP:0] subordinate
clause [NP:1 VP:1 ADJP:0 ADVP:0 PP:0]. frequent syntactic signature main clauses
[NP:2 VP:1 PP:0 ADJP:0 ADVP:0]; subordinate clauses typically contain adverbial phrase [NP:2
VP:1 ADJP:0 ADVP:1 PP:0]. One motivating case using syntactic feature involves verbs
describing propositional attitudes (e.g., said, believe, realize ). set temporal discourse markers
varying distributions relative semantic scope verbs. example, one
98

fiL EARNING ENTENCE - INTERNAL EMPORAL R ELATIONS

would expect take narrow semantic scope (i.e., until-clause would typically attach
verb sentential complement propositional attitude verb, rather propositional
attitude verb itself), situation might different once.
Argument Signature (R) feature captures argument structure profile main subordinate clauses. applies verbs encodes whether verb direct indirect object,
whether modified preposition adverbial. rules inferring temporal relations
Hobbs et al. (1993) Asher Lascarides (2003) attest, predicate argument structure
clauses crucial making correct temporal inferences many cases. take simple example, observe inferring causal relation (16) crucially depends fact subject
fall denotes person direct object push ; without this, relation causal
one would inferred.
syntactic signature, feature read main subordinate clause parsetrees. parsed version B LLIP corpus contains information subjects. NPs whose
nearest ancestor VP identified objects. Modification relations recovered
parse trees finding PPs ADVPs immediately dominated VP. Figure 1
argument signature main clause [SUBJ OBJ] subordinate [OBJ].
Position (P) feature simply records position two clauses parse tree,
i.e., whether subordinate clause precedes follows main clause. majority main
clauses data sentence initial (80.8%). However, differences among individual
markers. example, clauses equally frequent positions. 30% clauses
sentence initial whereas 90% clauses found second position. statistics clearly show relative positions main vs. subordinate clauses going
relatively informative interpretation task.
following sections describe experiments models introduced Section 3. first investigate performance temporal interpretation context pseudodisambiguation task (Experiment 1). also describe study humans (Experiment 2)
enables us examine depth models behavior difficulty inference task.
Finally, evaluate proposed approach realistic setting, using sentences
contain explicit temporal markers (Experiment 3).

5. Experiment 1: Temporal Inference Pseudo-disambiguation
Method models trained main subordinate clauses extracted B LLIP
corpus detailed Section 4. testing phase, occurrences relevant temporal markers
removed models used select marker originally attested
corpus. experimental setup admittedly artificial, important revealing difficulty
task hand. model performs deficiently pseudo-disambiguation task, little
hope inferring temporal relations natural setting events neither connected via
temporal markers found main-subordinate relationship.
Recall obtained 83,810 main-subordinate pairs. randomly partitioned
training (80%), development (10%) test data (10%). Eighty randomly selected pairs
test data reserved human study reported Experiment 2. performed parameter
tuning development set; results reported unseen test set, unless otherwise
stated. compare performance conjunctive disjunctive models, thereby assessing
99

fiL APATA & L ASCARIDES

Symbols

$

&
#

Meaning
significantly different Majority Baseline
significantly different Word-based Baseline
significantly different Conjunctive Model
significantly different Disjunctive Model
significantly different Conjunctive Ensemble
significantly different Disjunctive Ensemble

Table 6: Meaning diacritics indicating statistical significance ( 2 tests, p


0 05)

effect feature (in)dependence temporal interpretation task. Furthermore, compare
performance two proposed models baseline disjunctive model employs
w j ) P
w j ). model
word-based feature space (see (7) P
resembles Marcu Echihabis (2002)s model make use linguistically
motivated features presented previous section; needed estimating parameters
corpus main-subordinate clause pairs. also report performance majority baseline
(i.e., always select when, frequent marker data set).
order assess impact feature classes (see Section 4.2) interpretation task,
feature space exhaustively evaluated development set. nine classes,
results 9 9!k ! combinations k arity combination (unary, binary, ternary, etc.).
measured accuracy class combinations (1,023 total) development set.
these, selected best performing ones evaluating models test set.


ff
ff


ff
ff







Results results shown Table 7. report accuracy F-score. set diacritics
used indicate significance (on accuracy) throughout paper (see Table 6). best performing disjunctive model test set (accuracy 62.6%) observed combination verbs
(V) syntactic signatures (S). combination verbs (V), verb classes (V L , VW ), syntactic signatures (S) clause position (P) yielded highest accuracy (60.3%) conjunctive
model. conjunctive disjunctive models performed significantly better majority
baseline word-based model also significantly outperformed majority baseline.
disjunctive model (SV) significantly outperformed conjunctive one (V W VL PSV).
attribute conjunctive models worse performance data sparseness. clearly
trade-off reflecting true complexity task inferring temporal relations
amount training data available. size data set favors simpler model
complex one. difference performance models relying linguistically-motivated
features word-based model also shows linguistic abstractions useful overcoming
sparse data.
analyzed data requirements models varying amount instances
trained. Figure 2 shows learning curves best conjunctive disjunctive
models (VW VL PSV SV). comparison, also examine training data size affects
(disjunctive) word-based baseline model. seen, disjunctive model advantage
conjunctive one; difference pronounced smaller amounts training data.
small performance gains obtained increased training data word baseline model.
considerably larger training set required model competitive lin100

fiL EARNING ENTENCE - INTERNAL EMPORAL R ELATIONS

Model
Majority Baseline
Word-based Baseline
Conjunctive (VW VL PSV)
Disjunctive (SV)

Accuracy
42 6$#&
48 2 $#&
60 3 #&
62 6 $#&

Ensemble (Conjunctive)
Ensemble (Disjunctive)

64 5
70 6






F-score
NA
44.7
53.3
62.3

$&
$#

59.9
69.1

Table 7: Summary results temporal pseudo-disambiguation task; comparison baseline
models conjunctive disjunctive models ensembles (V: verbs, V W :
WordNet verb supersenses, VL : Levin verb classes, P: clause position, S: syntactic signature)
70

Accuracy (%)

65

Word-based Baseline
Conjunctive Model
Disjunctive Model

60
55
50
45
40

K K K K K K K K K K K K K K K K K K K K
3.3 6.7 10 13.4 16.8 20.1 23.4 26.8 30.1 33.5 36.840.2 43.6 46.9 50.3 53.6 56.9 60.3 63.6 67.1

Number instances training data

Figure 2: Learning curve conjunctive, disjunctive, word-based models.
guistically aware models. result agreement Marcu Echihabi (2002) employ
large corpus (1 billion words, extract 40 million training examples)
training word-based model.
analysis models output revealed feature combinations performed reasonably well individual markers disjunctive conjunctive model, even though
overall accuracy match best feature combinations either model class.
accuracies combinations shown Table 8. example, NPRSTV one best
combinations generating disjunctive model, whereas SV better
(feature abbreviations introduced Section 4.2). Given complementarity different
models, obvious question whether combined. important finding machine
learning set classifiers whose individual decisions combined way (an ensemble ) accurate component classifiers errors individual
101

fiL APATA & L ASCARIDES

TMark

Disjunctive Model
Features
Accuracy

Conjunctive Model
Features
Accuracy





since




NPRSTV
ANNW PSV
SV
PRS
PRST
VL PS
PST
VL VW RT

VW PTV
VW VL SV
TV
VW P
VL V
VL NV
VL PV
VW VL PV

69 9
57 0
42 1
40 7
25 1
85 5
49 0
69 4

79 6
57 0
11 3
37
10
86 5
96
95

Table 8: Best feature combinations individual markers (development set; V: verbs, V W : WordNet verb supersenses, VL : Levin verb classes, N: nouns, NW : WordNet noun supersenses,
P: clause position, R: argument signature, S: syntactic signature, T: tense signature)

classifiers sufficiently uncorrelated (Dietterich, 1997). next section reports ensemble
learning experiments.
Ensemble Learning ensemble classifiers set classifiers whose individual decisions
combined classify new examples. simple idea applied variety classification problems ranging optical character recognition medical diagnosis part-of-speech
tagging (for overviews, see Dietterich, 1997; van Halteren, Zavrel, & Daelemans, 2001). Ensemble
learners often yield superior results individual learners provided component learners
accurate diverse (Hansen & Salamon, 1990).
ensemble typically built two steps: first multiple component learners trained
next predictions combined. Multiple classifiers generated either using subsamples
training data (Breiman, 1996a; Freund & Shapire, 1996) manipulating set input
features available component learners (Cherkauer, 1996). Weighted unweighted voting
method choice combining individual classifiers ensemble. sophisticated
combination method stacking learner trained predict correct output class
given input outputs ensemble classifiers (Wolpert, 1992; Breiman, 1996b; van Halteren
et al., 2001). words, second-level learner trained select output basis
patterns co-occurrence output several component learners.
generated multiple classifiers (for combination ensemble) varying number
type features available conjunctive disjunctive models discussed previous
section. outputs models next combined using c5.0 (Quinlan, 1993), decision-tree
second level-learner. Decision trees among widely used machine learning algorithms.
perform general specific search feature space, adding informative features
tree structure search proceeds. objective select minimal set features
efficiently partitions feature space classes observations assemble tree
(for details, see Quinlan, 1993). classification test case made traversing tree
either leaf node found branches match test case, returning
frequent class last node.
102

fiL EARNING ENTENCE - INTERNAL EMPORAL R ELATIONS

Conjunctive Ensemble
PSVVWNW VL NPVVW VL
PRTVVWVL
NSVVW
PSVVW PVVW NW PSVVL
NSV
PSV
PV
Disjunctive Ensemble
ANW NPSV APSV
ASV
PRSVW
PRS
PRST
PRSV
PSV
APTV
SVVW VL
NPV

PSVWVL PSVVWVL PVVWVL
PSVL
PVVL
NPSV
SV
TV
V
PSVN
SV

SVL

NPRSTV

Table 9: Component models ensemble learning (A: adjectives, V: verbs, V W : WordNet verb
supersenses, VL : Levin verb classes, N: nouns, NW : WordNet noun supersenses, P: clause
position, R: argument signature, S: syntactic signature, T: tense signature)

Learning framework requires primary training set training component learners;
secondary training set training second-level learner test set assessing stacked
classifier. trained decision-tree learner development set using 10-fold cross-validation.
experimented 133 different conjunctive models 65 disjunctive models; best results
development set obtained combination 22 conjunctive models 12 disjunctive models. component models presented Table 9. ensembles performance
test set reported Table 7.
seen, types ensemble significantly outperform word-based baseline,
best performing individual models. Furthermore, disjunctive ensemble significantly outperforms conjunctive one. Table 10 details performance two ensembles individual
marker. ensembles difficulty inferring markers since, ; difficulty
pronounced conjunctive ensemble. believe worse performance predicting relations due combination sparse data ambiguity. First, observe
three classes fewest examples data set (see Table 1). Secondly, temporally
ambiguous, conveying temporal progression temporal overlap (see example (12)).
ambiguity observed since (see example (13)). Finally, although temporal sense
always conveys temporal overlap, non-temporal, contrastive sense potentially
creates noise training data, discussed Section 4.1. Another contributing factor
poor performance lack sufficient training data. Note extracted instances
marker constitute 4.2% data. fact, model often confuses marker since
semantically similar while. could explained fact majority training
examples since interpretations imply temporal overlap, thereby matching temporal
relation implied while, turn also majority interpretation training corpus
(the non-temporal, contrastive sense accounting 13.3% training examples).
Let us examine classes features impact interpretation task
observing component learners selected ensembles. shown Table 8, verbs either
lexical forms (V) classes (VW , VL ), syntactic structure main subordinate clauses
(S) position (P) important features interpretation. Verb-based features
present component learners making conjunctive ensemble 10 (out 12) learners
disjunctive ensemble. argument structure feature (R) seems influence
(it present five 12 component (disjunctive) models), however suspect
overlap S. Nouns, adjectives temporal signatures seem small impact
103

fiL APATA & L ASCARIDES

TMark




since





Disjunctive Ensemble
Accuracy
F-score
66 4
62 5
51 4
24 6
26 2
91 0
28 8
47 8
70 6

63 9
62 0
50 6
35 3
38 2
86 9
41 2
52 4
69 1

Conjunctive Ensemble
Accuracy
F-score
59 3
59 0
17 1
00
39
90 5
11 5
17 3
64 5

57 6
55 1
22 3
00
45
84 7
15 8
24 4
59 9

Table 10: Ensemble results sentence interpretation individual markers (test set)
interpretation task, least WSJ domain. results far point importance
lexicon inferring temporal relations also indicate syntactic complexity
two clauses another key predictor. Asher Lascarides (2003) symbolic theory discourse
interpretation also emphasizes importance lexical information inferring temporal relations,
Soricut Marcu (2003) find syntax trees useful inferring discourse relations,
temporal consequences.

6. Experiment 2: Human Evaluation
Method assessed temporal interpretation model comparing performance
human judges. Participants asked perform multiple choice task. given
set 40 main-subordinate pairs (five marker) randomly chosen test data.
marker linking two clauses removed participants asked select missing word
set eight temporal markers, thus mimicking models task. Examples materials
participants saw given Apendix A.
study conducted remotely Internet. Subjects first read set instructions
explained task, fill short questionnaire including basic demographic information.
random order main-subordinate pairs random order markers per pair generated
subject. study completed 198 volunteers, native speakers English. Subjects
recruited via postings local Email lists.
Results results summarized Table 11. measured well subjects (Human)
agree gold standard (Gold)i.e., corpus experimental items
selectedand well agree (Human-Human). also show well
disjunctive ensemble (Ensemble) agrees subjects (Ensemble-Human) gold standard (Ensemble-Gold). measured agreement using Kappa coefficient (Siegel & Castellan,
1988) also report percentage agreement facilitate comparison model. cases
compute pairwise agreements report mean.

104

fiL EARNING ENTENCE - INTERNAL EMPORAL R ELATIONS

Human-Human
Human-Gold
Ensemble-Human
Ensemble-Gold

K
.410
.421
.390
.413

%
45.0
46.9
44.3
47.5

Table 11: Agreement figures subjects disjunctive ensemble (Human-Human: inter-subject
agreement, Human-Gold: agreement subjects gold standard corpus,
Ensemble-Human: agreement ensemble subjects, Ensemble-Gold: agreement ensemble gold standard corpus)





since





.55
.14
.05
.17
.10
.06
.20
.16


.06
.33
.05
.06
.09
.03
.07
.05


.03
.02
.52
.10
.04
.05
.09
.08


.10
.02
.08
.35
.04
.10
.09
.03

since
.04
.03
.03
.07
.63
.03
.04
.04


.01
.03
.15
.03
.03
.65
.03
.02


.20
.20
.08
.17
.06
.05
.45
.10


.01
.23
.04
.05
.01
.03
.03
.52

Table 12: Confusion matrix based percent agreement subjects

shown Table 11 moderate agreement 4 among humans selecting appropriate temporal marker main subordinate clause. ensembles agreement gold
standard approximates human performance interpretation task (K
413 Ensemble-Gold
vs. K
421 Human-Gold). agreement ensemble subjects also close
upper bound, i.e., inter-subject agreement (see Ensemble-Human Human-Human Table 11).
analysis revealed majority disagreements among subjects arose
clauses. also problematic ensemble model (see Table 10). inter-subject
agreement 33% clauses 35% clauses. markers, subject
agreement around 55%. highest agreement observed since (63%
65% respectively). confusion matrix summarizing resulting inter-subject agreement
interpretation task shown Table 12.
moderate agreement entirely unexpected given markers semantically similar cases one marker compatible temporal implicatures
arise joining two clauses. example, compatible after, as, before,
once, since. Besides when, compatible since, while. Consider example
following sentence experimental materials: older women divorcing
husbands retire. Although right connective according corpus,





4. Landis Koch (1977) give following five qualifications different values Kappa: .00.20 slight, .21.40
fair, .41.60 moderate, .61.80 substantial, whereas .811.00 almost perfect.

105

fiL APATA & L ASCARIDES

also valid choices. Indeed often chosen instead subjects (see
Table 12). Also note neither model subjects access context surrounding
sentence whose marker must inferred. sentence lot want get
get kicked (again taken materials), knowing referents important selecting right relation. cases, substantial background knowledge required
make valid temporal inference. sentence certified deaths required
FDA acts? (see Appendix A), one must know FDA stands (i.e., Federal, Food, Drug,
Cosmetic Act). less strict evaluation setting one connective considered
correct (on basis semantic compatibility), inter-subject agreement K
640 (67.7%).
Moreover, ensembles agreement subjects K
609 (67%).
next evaluate performance ensemble model challenging task. test
data far somewhat artificially created removing temporal marker connecting
main subordinate clause. Although experimental setup allows develop evaluate temporal inference models relatively straightforwardly, remains unsatisfactory. cases temporal model would required interpreting events attested main-subordinate
clauses variety constructions (e.g., parataxis indirect speech) may contain
temporal markers. use annotations TimeBank corpus investigating whether
model, trained automatically annotated data, performs well realistic test set.





7. Experiment 3: Predicting TimeML Relations
Method mentioned earlier TimeBank corpus manually annotated
TimeML coding scheme. scheme, verbs, adjectives, nominals annotated EVENTs
marked attributes class event (e.g., state, reporting), tense
(e.g., present, past), aspect (e.g., perfective, progressive), polarity (positive negative).
TLINK tag used represent temporal relationships events, event
time. relationships inter- intra-sentential. Table 13 illustrates TLINK relationships sentences taken TimeBank corpus. focus solely intra-sentential temporal
relations events; Table 13 include IDENTITY relationship commonly
attested inter-sententially.
intent use model presented previous sections interpret temporal
relationships events like shown Table 13 absence overtly verbalized temporal information (e.g., temporal markers). However, one stumbling block performing kind
evaluation corpus model trained uses different labels
Table 13 (e.g., (ambiguous) temporal markers like ). Fortunately, temporal markers considered TimeML relations less semantically compatible, mapping
devised. First notice relations Table 13 redundant. instance
inverse AFTER, INCLUDED inverse INCLUDES, on. Furthermore,
semantic distinctions fine-grained model identify accurately (e.g.,
IBEFORE (immediately before), SIMULTANEOUS DURING). therefore reduced relations
Table 13 smaller set collapsing BEFORE, IBEFORE, IAFTER (immediately
after) one relationship. Analogously, collapsed SIMULTANEOUSLY DURING, INCLUDES
INCLUDED, BEGINS BEGUN BY, ENDS ENDED BY. reduced relation set
also shown Table 13 (within parentheses).

106

fiL EARNING ENTENCE - INTERNAL EMPORAL R ELATIONS



(BEFORE)

IBEFORE

(BEFORE)



(BEFORE)

IAFTER

(BEFORE)

INCLUDES

(INCLUDES )

INCLUDED

(INCLUDES )



(INCLUDES)

ENDS

(ENDS)

ENDED

(ENDS)

BEGINS

(BEGINS)

BEGUN

(BEGINS)

SIMULTANEOUS

Table 13:

Pacific First Financial Corp. said shareholders approved acquisition Royal Trusstco Ltd. Toronto $27 share,
$212 million.
first would launch much-feared direct invasion
Saudi Arabia, hoping seize Saudi oil fields improve
bargaining position.
Washington today Federal Aviation Administration released air traffic control tapes night TWA flight eight
hundred went down.
addition, Hewlett-Packard acquired two-year option buy
extra 10%, half may sold directly HewlettPackard Octel.
offer, shareholders receive one right 105
common shares owned.
purchase price disclosed preliminary prospectus issued connection MGM Grands planned offering six
million common shares.
According Jordanian officials, smaller line Jordan remained operating.
government may move seize money Mr. Antar
using pay legal fees.
Financial Times 100-share index shed 47.3 points close
2082.1, 4.5% previous Friday.
DPC, investor group led New York-based Crescott Investment Associates, filed suit state court Los Angeles seeking nullify agreement.
Saddam said begin withdrawing troops Iranian territory Friday release Iranian prisoners war.
Nearly 200 Israeli soldiers killed fighting Hezbollah
guerrillas guerrillas.

relationships TimeBank; events participating relationship marked
boldface; coarse-grained set relationships shown within parentheses.
TILINK

next defined mapping temporal connectives reduced set TimeML
relations (see Table 14). mapping cannot one-to-one, since connectives
compatible one temporal relationship (see Section 4.1). instance
indicate INCLUDES relationship. also expect mapping relatively noisy
given temporal markers entail non-temporal relationships (e.g., ). Table 14 includes
additional relation, namely no-temp-rel. thus option assigning temporal
relation, thereby avoiding pitfall making wrong prediction cases non-temporal

107

fiL APATA & L ASCARIDES

TMark
after,before,once,when
as,when,while
as,when,while
since

no-temp-rel

TimeMLRel

INCLUDES
SIMULTANEOUS
BEGINS
ENDS

- TEMP - REL

TrainInst
31 643
21 859
22 165
2 810
5 333
22 523






TestInst
877
246
360
19
64
967

Table 14: Mapping temporal markers coarse-grained set TimeML relations; number
training test instances per relation.

inferences entailed two events. next describe training test instances
generated experiments.
disjunctive ensemble model Experiment 1 trained B LLIP corpus using
features component learners described Sections 4.2 5. training data consisted
original 83,810 main-subordinate clause pairs labeled temporal relations Table 14 (second column). added 22,523 instances representative - TEMP - REL
relation. instances gathered randomly concatenating main subordinate clauses
belonging different documents (for similar method, see Marcu & Echihabi, 2002). hypothesize two clauses trigger temporal relations, since neither syntactically
semantically related. Instances connectives since mapped labels BEGINS
ENDS, respectively. addition BEGINS, since signal BEFORE, INCLUDES, SIMULTANE OUS temporal relations. However, experiments instances since used exclusively
learn BEGINS relation. far perfect, felt necessary since BEGINS represented temporal marker. training instances equally split
relationships INCLUDES SIMULTANEOUS. Similarly, data equally
split among BEFORE, INCLUDES, SIMULTANEOUS. Instances after, before,
exclusively used learning relation. number training instances per relation
(TrainInst) given Table 14.
test data, used sentences TimeBank corpus. tested ensemble model
intra-sentential event-event relations. Furthermore, excluded sentences overt temporal
connectives, want positively influence models performance. TimeBank
corpus explicitly annotated - TEMP - REL relation. however sentences
corpus whose events participate temporal relationship. therefore hypothesized sentences representative - TEMP - REL . total number test instances
(TestInst) used experiment given Table 14.
Results results summarized Table 15. compare performance disjunctive
ensemble Section 5 naive word-based model. models trained
main subordinate clauses B LLIP corpus. also report accuracy majority
baseline defaults frequent class B LLIP training data (i.e., BEFORE). Finally,
report performance (disjunctive) ensemble model trained tested
TimeBank corpus (see column TestInst Table 14) using leave-one-out crossvalidation.
Comparison latter model B LLIP-trained ensemble indicate whether unan108

fiL EARNING ENTENCE - INTERNAL EMPORAL R ELATIONS

Model
Majority Baseline
Word-based Baseline
Ensemble (Disjunctive)
Ensemble (Disjunctive)

TrainCorpus
B LLIP
B LLIP
B LLIP
TimeBank

Accuracy
34 7
39 1
53 0
42 7



F-score
NA
21.1
45.8
40.5

Table 15: Results predicting TimeML event-event relationships; comparison wordbased baseline disjunctive ensemble models.

TimeMLRel

BEGINS
ENDS
INCLUDES
SIMULTANEOUS
- TEMP - REL



B LLIP
Accuracy F-score
46.4
47 6
10.5
78
14.1
37
50.0
51 5
46.7
47 8
62.8
66 1
53.0
45 8

TimeBank
Accuracy F-score
63 2
53 2
00
00
47
77
85
98
67
89
49 6
53 5
42 7
40 5

Table 16: Ensemble results inferring individual temporal relations; comparison ensemble model trained B LLIP TimeBank corpora.

notated data indeed useful reducing annotation effort training requirements temporal
interpretation models.
seen, disjunctive model trained B LLIP corpus significantly outperforms
two baseline models. also outperforms ensemble model trained TimeBank wide
margin.5 find results encouraging considering approximations temporal interpretation model noise inherent B LLIP training data. Also note that, despite
linguistically informed, feature space encodes basic semantic temporal distinctions.
example, aspectual information taken account, temporal expressions analyzed detail. One would hope extensive feature engineering would result improved
results.
examined performance varies class. Table 16 provides comparison
two ensemble models trained B LLIP TimeBank corpus, respectively.
models difficulty BEGINS ENDS classes. entirely surprising, since
classes represented relatively small number training instances (see Table 14). two
models yield comparable results BEFORE, whereas B LLIP-trained ensemble delivers better
performance INCLUDES, SIMULTANEOUS, - TEMP - REL .
5. Unfortunately, cannot use 2 test assess whether differences two ensembles statistically
significant due leave-one-out crossvalidation methodology employed training testing TimeBank corpus. necessary given small size event-event relation data extracted TimeBank (2,533
instances total, see Table 14).

109

fiL APATA & L ASCARIDES

aware previous work attempts similar task. However, worth
mentioning Boguraev Ando (2005) consider interpretation event-time temporal relations inter- intra-sententially. report accuracies ranging 53.1% 58.8% depending
intervening distance events times question (performance better
events times occurring close other). Interestingly, interpretation model exploits
unannotated corpora conjunction TimeML annotations increase amount labeled
data training. method identifies unannotated instances distributionally similar
manually annotated corpus. contrast, rely solely unannotated data training
exploiting instances explicitly marked temporal information. interesting future direction
combination data TimeML annotations basis devising improved models
(for details, see Section 8).

8. General Discussion
paper proposed data intensive approach temporal inference. introduced models
learn temporal relations sentences temporal information made explicit via temporal markers assessed potential inferring relations cases overt temporal markers
absent. Previous work focused automatic tagging temporal expressions (Wilson
et al., 2001), learning ordering events manually annotated data (Mani et al., 2003),
inferring temporal relations events time expressions annotated
unannotated data (Boguraev & Ando, 2005).
models bypass need manual annotation training exclusively instances
temporal relations made explicit presence temporal markers. compared
contrasted several models varying linguistic assumptions employed feature space.
also explored tradeoff model complexity data requirements. results indicate
less sophisticated models (e.g., disjunctive model) tend perform reasonably utilizing
expressive features training data sets relatively modest size. experimented
variety linguistically motivated features ranging verbs semantic classes temporal
signatures argument structure. Many features inspired symbolic theories
temporal interpretation, often exploit semantic representations (e.g., two clauses)
well complex inferences world knowledge (e.g., Hobbs et al., 1993; Lascarides & Asher,
1993; Kehler, 2002).
best model achieved F-score 69.1% inferring temporal relations trained
tested B LLIP corpus context pseudo-disambiguation task. performance
significant improvement baseline compares favorably human performance
task. Detailed exploration feature space revealed lexical
also syntactic information important temporal inference. result agreement
Soricut Marcu (2003) find syntax trees encode sufficient information enable accurate
derivation discourse relations.
also evaluated models performance realistic task predicting temporal
relations explicitly signaled text. end, evaluated B LLIP-trained
model TimeBank, corpus manually annotated temporal relations according TimeML specifications. experimental set-up challenging many perspectives. First, temporal markers used study received multiple meanings. ambiguity unavoidably introduced certain amount noise estimating parameters model
110

fiL EARNING ENTENCE - INTERNAL EMPORAL R ELATIONS

defining mapping markers TimeML relations. Second, guarantee
relations signaled temporal markers connecting main subordinate clauses hold events
attested syntactic configurations non-temporal subordination coordination. Given
approximations, model performed reasonably, reaching overall F-score 45.8%
temporal inference task showing best performance relations BEFORE, INCLUDES, SIMUL TANEOUS - TEMP - REL . results show possible infer temporal information
corpora even semantically annotated way hold promise relieving
data acquisition bottleneck associated creating temporal annotations.
important future direction lies modeling temporal relations events across sentences. order achieve full-scale temporal reasoning, current model must extended
number ways. involve incorporation extra-sentential information modeling
task well richer temporal information (e.g., tagged time expressions; see Mani et al., 2003).
current models perform inference task independently surrounding context. Experiment 2 revealed rather difficult task; even humans cannot easily make decisions regarding
temporal relations out-of-context. future work, plan take account contextual (lexical syntactic) well discourse-based features (e.g., coreference resolution). Many linguists
also observed identifying discourse structure text, conceptualized hierarchical structure rhetorically connected segments, identifying temporal relations among
events logically co-dependent tasks (e.g., Kamp & Reyle, 1993; Hobbs et al., 1993; Lascarides
& Asher, 1993). example, fact interpret (1a) forming narrative (1c)
(1c) providing background information (1b) yields temporal relations among events
described Section 1: namely, temporal progression kissing girl walking
home, temporal overlap remembering talking walking home.
(1)

a.
b.
c.

John kissed girl met party.
Leaving party, John walked home.
remembered talking asking name.

logical relationship discourse structure temporal structure suggests
output discourse parser (e.g., Marcu, 1999; Soricut & Marcu, 2003; Baldridge & Lascarides,
2005) could used informative source features inferring temporal relations across
sentence boundaries. would analogous discourse level use made
sentential parser source features experiments inferring sentence-internal temporal
relations.
approach presented paper also combined annotations present
TimeML corpus semi-supervised setting similar Boguraev Ando (2005) yield
improved performance. Another interesting direction future work would use models
proposed bootstrapping approach. Initially, model learned unannotated data
output manually edited following annotate automatically, correct manually methodology
used provide high volume annotation Penn Treebank project. iteration model
retrained progressively accurate representative data. Another issue related nature
training data concerns temporal information entailed markers
ambiguous. could remedied either heuristically discussed Section 4.1 using
models trained unambiguous markers (e.g., before, ) disambiguate instances multiple
readings. Another possibility apply separate disambiguation procedure training data
(i.e., prior learning temporal inference models).
111

fiL APATA & L ASCARIDES

Finally, would like investigate utility temporal inference models within
context specific natural language processing applications. thus intend explore
potential improving performance multi-document summarisation system. example,
temporal reasoning component could useful extracting temporally congruent events,
also structuring output summaries, i.e., temporally ordering extracted sentences.
Although models presented target primarily interpretation tasks, could also adapted
generation tasks, e.g., inferring temporal marker generated
placed.

Acknowledgments
work supported EPSRC (Lapata, grant GR/T04540/01; Lascarides,
grant GR/R40036/01). grateful Regina Barzilay Frank Keller helpful
comments suggestions. Thanks anonymous referees whose feedback helped substantially improve present paper. preliminary version work published
proceedings NAACL 2004; also thank anonymous reviewers paper
comments.

112

fiL EARNING ENTENCE - INTERNAL EMPORAL R ELATIONS

Appendix A. Experimental Materials Human Evaluation
following list materials used human evaluation study reported Experiment 2
(Section 6). sentences extracted B LLIP corpus following procedure described
Section 4.1.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20

addition, agencies werent always efficient getting word agencies
company
barred.

Mr. Reagan learned news
National Security Adviser Frank Carlucci called tell hed
seen television.

instance, National Geographic caused uproar
used computer neatly move two
Egyptian pyramids closer together photo.

Rowes Wharf looks best
seen new Airport Water Shuttle speeding across Boston
harbor.

older women divorcing
husbands retire.

Together prepared head Fortune company
enjoying tranquil country life.
estimated 190,000 legal abortions adolescents occurred, unknown number
illegal unreported abortions took place well.

Mr. Rough, late 40s, allegedly leaked information
served New York
Federal Reserve Bank director January 1982 December 1984.

contest became obsession Fumio Hirai, 30-year-old mechanical engineer, whose wife took
ignoring
two men tinkered months dancing house plants.
calls whole experience wonderful, enlightening, fulfilling proud MCI functioned
well
gone.

lot want get
get kicked out.

prices started falling, market $1.5 billion week new issues, says head
investment banking major Wall Street firm.


start feeling sorry fair sex, note Bundys, Bunkers.

Organization Petroleum Exporting Countries travel rocky road
Persian Gulf
members rule world oil markets.

certified deaths required
FDA acts?

Currently, large store built
smaller merchants area approve it, difficult
time consuming process.

review began last week
Robert L. Starer named president.

lower rate came
nations central bank, Bank Canada, cut weekly bank rate
7.2% 7.54%.

Black residents Washingtons low-income Anacostia section forced three-month closing
Chinese-owned restaurant
owner threatened elderly black woman customer pistol.

Laurie Massas back hurt months
delivery truck slammed car 1986.


Table 17: Materials temporal pseudo-disambiguation task; markers bodlface indicate
gold standard completion; subjects asked select missing word set
temporal markers after, before, while, when, as, once, until, since




113

fiL APATA & L ASCARIDES

21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40

Donald Lasater, 62, chairman chief executive office, assume posts Mr. Farrell vacates
successor found.

council said national assembly replaced appointed legislators
new elections held
U.S. lifts economic sanctions.

problems disappear, Mr. Melzer suggests working base, raw material
forms money supply.

green-coffee importer said sufficient supply Brazil
harvest gets full swing
next month.

pump
fire hand out.

gene inserted human TIL cells, another safety check would made.

part bus system subject market discipline, entire operation tends respond.
China contrast,
joint ventures legal, hundreds created.

company said problem goes away
car warms up.

Toronto merger complete, combined entity 352 lawyers.

justices ruled admission could used
clearly chosen speech silence.
since
Milosevics popularity risen
became party chief Serbia, Yugoslavias biggest republic,
1986.
since
government says already eliminated 600 million hours paperwork year
Congress
passed Paperwork Reduction Act 1980.
since
serious rebellion Conservative ranks
Mr. Mulroney elected four years
ago.
since
least eight settlement attempts
Texas court handed multi-billion
dollar judgment two years ago.
since
Brud LeTourneau, Seattle management consultant Merit smoker, laughs

keeps trying flick non-existent ashes ashtray.

Britains airports disrupted
24-hour strike air traffic control assistants resulted
cancellation thank 500 flights lengthy delays travelers.

Stocks plunged
investors ignored cuts European interest rates dollar bond rallies.
Bostons Logan Airport, Delta plane landed wrong runway
another jet taking
off.

Polish strikers shut Gdansks port
Warsaw rushed riot police city.


Table 17: (continued)

114

fiL EARNING ENTENCE - INTERNAL EMPORAL R ELATIONS

References
Allen, J. (1995). Natural Language Understanding. Benjamin Cummins.
Asher, N., & Lascarides, A. (2003). Logics Conversation. Cambridge University Press.
Baldridge, J., & Lascarides, A. (2005). Probabilistic head-driven parsing discourse structure.
Proceedings Ninth Conference Computational Natural Language Learning, pp.
96103, Ann Arbor, MI.
Boguraev, B., & Ando, R. K. (2005). TimeML-compliant text analysis temporal reasoning.
Proceedings 19th International Joint Conference Artificial Intelligence, pp. 997
1003, Edingburgh, UK.
Breiman, L. (1996a). Bagging predictors. Machine Learning, 2(24), 123140.
Breiman, L. (1996b). Stacked regressions. Machine Learning, 3(24), 4964.
Carlson, L., Marcu, D., & Okurowski, M. (2001). Building discourse-tagged corpus framework Rhetorical Structure Theory. Proceedings 2nd SIGDIAL Workshop Discourse Dialogue, Eurospeech 2001, Aalborg, Denmark.
Cestnik, B. (1990). Estimating probabilities: crucial task machine learning. Proceedings
16th European Conference Artificial Intelligence, pp. 147149, Stockholm, Sweden.
Charniak, E. (2000). maximum-entropy-inspired parser. Proceedings 1st Conference
North American Chapter Assocation Computational Linguistics, pp. 132139,
Seattle, WA.
Cherkauer, K. J. (1996). Human expert-level performance scientific image analysis task
system using combined artificial neural networks. Working Notes AAAI Workshop
Integrating Multiple Learned Models, pp. 1521, Portland, OR.
Ciaramita, M., & Johnson, M. (2003). Supersense tagging unknown words WordNet.
Proceedings 8th Conference Empirical Methods Natural Language Processing,
pp. 168175, Sapporo, Japan.
Dietterich, T. G. (1997). Machine learning research: Four current directions. AI Magazine, 18(4),
97136.
Dorr, B., & Gaasterland, T. (1995). Selecting tense aspect connective words language generation. Proceedings 14th International Joint Conference Artificial Intelligence,
pp. 12991307, Montreal, Canada.
Dowty, D. (1986). effects aspectual class temporal sturcture discourse: Semantics
pragmatics?. Linguistics Philosophy, 9(1), 3761.
Fellbaum, C. (Ed.). (1998). WordNet: Electronic Database. MIT Press, Cambridge, MA.
Ferro, L., Mani, I., Sundheim, B., & Wilson, G. (2000). TIDES temporal annotation guidelines.
Tech. rep., MITRE Corporation.
Freund, Y., & Shapire, R. E. (1996). Experiments new boosting algorithm. Proceedings
13th International Conference Machine Learning, pp. 148156, Stanford, CA.
Han, B., & Lavie, A. (2004). framework resolution time natural language. ACM Transactions Asian Language Information Processing (TALIP), 3(1), 1132.
115

fiL APATA & L ASCARIDES

Hansen, L. K., & Salamon, P. (1990). Neural network ensembles. IEEE Transactions Pattern
Analysis Machine Intelligence, 12, 9931001.
Hitzeman, J., Moens, M., & Grover, C. (1995). Algorithms analyzing temporal structure
discourse. Proceedings 7th Meeting European Chapter Association
Computational Linguistics, pp. 253260, Dublin, Ireland.
Hobbs, J. R., Stickel, M., Appelt, D., & Martin, P. (1993). Interpretation abduction. Artificial
Intelligence, 63(12), 69142.
Hwang, C., & Schubert, L. (1992). Tense trees finite structure discourse. Proceedings
30th Annual Meeting Association Computational Linguistics, pp. 232240,
Newark, DE.
Kamp, H., & Reyle, U. (1993). Discourse Lexicon: Introduction Modeltheoretic
Semantics Natural Language, Formal Logic Discourse Representation Theory. Kluwer
Academic Publishers.
Katz, G., & Arosio, F. (2001). annotation temporal information natural language sentences.
Proceedings ACL Workshop Temporal Spatial Information Processing, pp. 104
111, Toulouse, France.
Kehler, A. (2002). Coherence, Reference Theory Grammar. CSLI Publications, Cambridge University Press.
Landis, J. R., & Koch, G. G. (1977). measurement observer agreement categorical data.
Biometrics, 33, 159174.
Lapata, M., & Brew, C. (2004). Verb class disambiguation using informative priors. Computational
Linguistics, 30(1), 4573.
Lascarides, A., & Asher, N. (1993). Temporal interpretation, discourse relations commonsense
entailment. Linguistics Philosophy, 16(5), 437493.
Levin, B. (1995). English Verb Classes Alternations. Chicago University Press.
Mani, I., & Schiffman, B. (2005). Temporally anchoring ordering events news. Pustejovsky, J., & Gaizauskas, R. (Eds.), Time Event Recognition Natural Language. John
Benjamins.
Mani, I., Schiffman, B., & Zhang, J. (2003). Inferring temporal ordering events news.
Proceedings 1st Human Language Technology Conference Annual Meeting
North American Chapter Association Computational Linguistics, pp. 5557, Edmonton, Canada.
Marcu, D. (1999). decision-based approach rhetorical parsing. Proceedings 37th
Annual Meeting Association Computational Linguistics, pp. 365372, College Park,
MD.
Marcu, D., & Echihabi, A. (2002). unsupervised approach recognizing discourse relations.
Proceedings 40th Annual Meeting Association Computational Linguistics,
pp. 368375, Philadelphia, PA.
Moens, M., & Steedman, M. J. (1988). Temporal ontology temporal reference. Computational
Linguistics, 14(2), 1528.
116

fiL EARNING ENTENCE - INTERNAL EMPORAL R ELATIONS

Pustejovsky, J., Ingria, B., Sauri, R., Castano, J., Littman, J., Gaizauskas, R., & Setzer, A. (2004).
specification TimeML. Mani, I., Pustejovsky, J., & Gaizauskas, R. (Eds.),
Language Time: reader, pp. 545558. Oxford University Press.
Pustejovsky, J., Mani, I., Belanger, L., Boguraev, B., Knippen, B., Litman, J., Rumshisky, A., See,
A., Symonen, S., van Guilder, J., van Guilder, L., & Verhagen, M. (2003). ARDA summer
workshop graphical annotation toolkit TimeML. Tech. rep..
Quinlan, R. J. (1993). C4.5: Programs Machine Learning. Series Machine Learning. Morgan
Kaufman, San Mateo, CA.
Quirk, R., Greenbaum, S., Leech, G., & Svartvik, J. (1985). Comprehensive Grammar
English Language. Longman, London.
Saur, R., Littman, J., Gaizauskas, R., Setzer, A., & Pustejovsky, J. (2004). TimeML Annotation
Guidelines. TERQAS Workshop. Version 1.1.
Schilder, F., & Habel, C. (2001). temporal expressions temporal information: Semantic
tagging news messages. Proceedings ACL Workshop Temporal Spatial Information Processing, pp. 6572, Toulouse, France.
Setzer, A., & Gaizauskas, R. (2001). pilot study annotating temporal relations text.
Proceedings ACL Workshop Temporal Spatial Information Processing, pp. 7380,
Toulouse, France.
Siegel, S., & Castellan, N. J. (1988).
McGraw-Hill, New York.

Non Parametric Statistics Behavioral Sciences.

Soricut, R., & Marcu, D. (2003). Sentence level discourse parsing using syntactic lexical information. Proceedings 1st Human Language Technology Conference Annual
Meeting North American Chapter Association Computational Linguistics, pp.
228235, Edmonton, Canada.
Sporleder, C., & Lascarides, A. (2005). Exploiting linguistic cues classify rhetorical relations.
Proceedings Recent Advances Natural Language Processing, pp. 532539, Borovets,
Bulgaria.
van Halteren, H., Zavrel, J., & Daelemans, W. (2001). Improving accuracy word class tagging
combination machine learning systems. Computational Linguistics, 27(2), 199
230.
Wiebe, J. M., OHara, T. P., Ohrstrom Sandgren, T., & McKeever, K. J. (1998). empirical
approach temporal reference resolution. Journal Artifical Intelligence Research, 9, 247
293.
Wilson, G., Mani, I., Sundheim, B., & Ferro, L. (2001). multilingual approach annotating
extracting temporal information. Proceedings ACL Workshop Temporal Spatial
Information Processing, pp. 8187, Toulouse, France.
Wolpert, D. H. (1992). Stacked generalization. Neural Networks, 5, 241259.

117

fiJournal Artificial Intelligence Research 27 (2006) 25-53

Submitted 10/05; published 9/06

Generative Prior Knowledge Discriminative Classification
Arkady Epshteyn
Gerald DeJong

aepshtey@uiuc.edu
dejong@uiuc.edu

Department Computer Science
University Illinois Urbana-Champaign
201 N. Goodwin
Urbana, IL, 61801 USA

Abstract
present novel framework integrating prior knowledge discriminative classifiers. framework allows discriminative classifiers Support Vector Machines
(SVMs) utilize prior knowledge specified generative setting. dual objective
fitting data respecting prior knowledge formulated bilevel program,
solved (approximately) via iterative application second-order cone programming.
test approach, consider problem using WordNet (a semantic database
English language) improve low-sample classification accuracy newsgroup categorization. WordNet viewed approximate, readily available source background
knowledge, framework capable utilizing flexible way.

1. Introduction
SVM (Vapnik, 1995) classification accuracy many classification tasks often
competitive human subjects, number training examples required
achieve accuracy prohibitively large domains. Intelligent user interfaces,
example, must adopt behavior individual user limited amount
interaction order useful. Medical systems diagnosing rare diseases generalize
well seeing examples. natural language processing task performs
processing level n-grams phrases (which frequent translation systems)
cannot expect see sequence words sufficient number times even large
training corpora. Moreover, supervised classification methods rely manually labeled
data, expensive obtain. Thus, important improve classification
performance small datasets. classifiers competitive humans
ability generalize seeing examples. Various techniques
proposed address problem, active learning (Tong & Koller, 2000b; Campbell,
Cristianini, & Smola, 2000), hybrid generative-discriminative classification (Raina, Shen,
Ng, & McCallum, 2003), learning-to-learn extracting common information related
learning tasks (Thrun, 1995; Baxter, 2000; Fink, 2004), using prior knowledge.
work, concentrate improving small-sample classification accuracy
prior knowledge. prior knowledge proven useful classification (Scholkopf,
Simard, Vapnik, & Smola, 2002; Wu & Srihari, 2004; Fung, Mangasarian, & Shavlik, 2002;
Epshteyn & DeJong, 2005; Sun & DeJong, 2005), notoriously hard apply practice
mismatch form prior knowledge employed
classification algorithms (either prior probabilities explicit constraints hypothesis
c
2006
AI Access Foundation. rights reserved.

fiEpshteyn & DeJong

space classifier) domain theories articulated human experts.
unfortunate various ontologies domain theories available abundance,
considerable amount manual effort required incorporate existing prior knowledge
native learning bias chosen algorithm. would take apply
existing domain theory automatically classification task specifically
designed? work, take first steps towards answering question.
experiments, domain theory exemplified WordNet, linguistic
database semantic connections among English words (Miller, 1990). apply WordNet standard benchmark task newsgroup categorization. Conceptually, generative
model describes world works, discriminative model inextricably linked
specific classification task. Thus, reason believe generative interpretation
domain theory would seem natural generalize better across different
classification tasks. Section 2 present empirical evidence is, indeed,
case WordNet context newsgroup classification. reason, interpret
domain theory generative setting. However, many successful learning algorithms
(such support vector machines) discriminative. present framework allows
use generative prior discriminative classification setting.
algorithm assumes generative distribution data given
Bayesian framework: P rob(data|model) prior P rob0 (model) known. However,
instead performing Bayesian model averaging, assume single model
selected a-priori, observed data manifestation model (i.e.,
drawn according P rob(data|M )). goal learning algorithm estimate
. estimation performed two-player sequential game full information.
bottom (generative) player chooses Bayes-optimal discriminator function f (M )
probability distribution P rob(data|model = ) (without taking training data
account) given model . model chosen top (discriminative) player
way prior probability occurring, given P rob0 (M ), high, forces
bottom player minimize training-set error Bayes-optimal discriminator
f (M ). estimation procedure gives rise bilevel program. show that,
problem known NP-hard, approximation solved efficiently iterative
application second-order cone programming.
remaining issue construct generative prior P rob0 (model) automatically domain theory. describe solve problem Section 2,
also argue generative setting appropriate capturing expert knowledge, employing WordNet illustrative example. Section 3, give necessary
preliminary information important known facts definitions. framework incorporating generative prior discriminative classification described detail Section
4. demonstrate efficacy approach experimentally presenting results
using WordNet newsgroup classification Section 5. theoretical explanation
improved generalization ability discriminative classifier constrained generative
prior knowledge appears Section 6. Section 7 describes related work. Section 8 concludes
paper outlines directions future research.
26

fiGenerative Prior Knowledge Discriminative Classification

2. Generative vs. Discriminative Interpretation Domain Knowledge
WordNet viewed network, nodes representing words links representing
relationships two words (such synonyms, hypernyms (is-a), meronyms (partof), etc.). important property WordNet semantic distance - length
(in links) shortest path two words. Semantic distance approximately
captures degree semantic relatedness two words. set experiment
evaluate usefulness WordNet task newsgroup categorization. posting
represented bag-of-words, binary feature representing presence
corresponding word. evaluation done pairwise classification tasks
following two settings:
1. generative framework assumes posting x = [x1 , .., xn ] generated
distinct probability distribution newsgroup. simplest version
Linear Discriminan Analysis (LDA) classifier posits x|(y = 1) N ( 1 , I)
x|(y = 1) N (2 , I) posting x given label {1, 1}, R(nn)
identity matrix. Classification done assigning probable label
x: y(x) = 1 P rob(x|1) > P rob(x| 1). well-known (e.g. see Duda, Hart, &
Stork, 2001) decision rule equivalent one given hyperplane
c1 , ..,
cn ] estimated via
(2 1 )T x 21 (T2 2 T1 1 ) > 0. means bi = [


1
maximum likelihood training data [x1 , y1 ], .., [xm , ym ] .

2. discriminative SVM classifier sets separating hyperplane directly minimize
number errors training data:
c1 , .., w
cn ], bb] = arg minw,b kwk s.t. yi (wT xi + b) 1, = 1, .., m.
[w
b = [w

experiment conducted learning-to-learn framework (Thrun, 1995; Baxter,
2000; Fink, 2004). first stage, classifier trained using training data
training task (e.g., classifying postings newsgroups atheism guns).
second stage, classifier generalized using WordNets semantic information.
third stage, generalized classifier applied different, test task (e.g., classifying
postings newsgroups atheism vs. mideast) without seeing data new
classification task. way classifier generalize setting use
original sample acquire information WordNet, exploit information
help label examples test sample. learning perform task,
system also learns utilize classification knowledge implicit WordNet.
describe second third stages two classifiers detail:

1. intuitive interpret information embedded WordNet follows: title
newsgroup guns, words semantic distance
gun (e.g., artillery, shooter, ordnance distance two) provide
similar degree classification information. quantify intuition, let li,train =
j
1
n
[li,train
, .., li,train
, .., li,train
] vector semantic distances WordNet
feature word j label training task newsgroup {1, 2}. Define
1. standard LDA classifier assumes x|(y = 1) N (1 , ) x|(y = 1) N (2 , )
estimates covariance matrix well means 1 , 2 training data. experiments,
take = I.

27

fiEpshteyn & DeJong

1)Train: atheism vs. guns
2)Train: atheism vs. guns
3)Train: guns vs. mideast
Test: atheism vs. mideast
Test: guns vs. mideast
Test: atheism vs. mideast
1

1

0.9

1

0.9

0.9

0.8

0.8

0.8

0.7

0.7

0.7

0.6

0.6

0.6

0.5

0.5

0.5
0

200 400 600 800 1000 1200 1400 1600 1800

0

200 400 600 800 1000 1200 1400 1600 1800

0

200 400 600 800 1000 1200 1400 1600 1800

Legend:

Generative
Discriminative

Figure 2.1: Test set accuracy percentage versus number training points 3
different classification experiments. classification task, random test
set chosen full set articles 20 different ways. Error bars
based 95% confidence intervals.

P

(v) ,

c
j
j
=v
i,train
j
=v|
|j:li,train
j:l

, = 1, 2, | | denotes cardinality set. compresses

information bi based assumption words equidistant newsgroup
label equally likely appear posting newsgroup. test
performance compressed classifier new task semantic distances given
j
). Notice
li,test , generative distributions reconstructed via ji := (li,test
classifier trained tested task, applying function
equivalent averaging components means generative distribution
corresponding equivalence classes words equidistant label.
classifier tested different classification task, reconstruction process reassigns
averages based semantic distances new labels.
2. less intuitive interpret WordNet discriminative setting. One possible
interpretation coefficients w j separating hyperplane governed
semantic distances labels, captured compression function 0 (v, u) ,
P

cj

w
j
j
=u
=v,l
2,train
1,train
j
j
|j:l1,train
=v,l2,train
=u|
j:l

j
j
reconstructed via w j := 0 (l1,test
, l2,test
).

Note LDA generative classifier SVM discriminative classifier
hypothesis space separating hyperplanes. resulting test set classification
accuracy classifier classification tasks 20-newsgroup dataset
28

fiGenerative Prior Knowledge Discriminative Classification

(Blake & Merz, 1998) presented Figure 2.1. x-axis graph represents
size training task sample, y-axis - classifiers performance test
classification task. generative classifier consistently outperforms discriminative
classifier. converges much faster, two three tasks discriminative classifier
able use prior knowledge nearly effectively generative classifier even
seeing 90% available training data. generative classifier also
consistent performance - note error bars much smaller
discriminative classifier. results clearly show potential using background
knowledge vehicle sharing information tasks. effective sharing
contingent appropriate task decomposition, supplied tuned generative
model.
evidence Figure 2.1 seemingly contradicts conventional wisdom discriminative training outperforms generative sufficiently large training samples. However,
experiment evaluates two frameworks context using ontology transfer
information learning tasks. never done before. experiment demonstrates interpretation semantic distance WordNet intuitive
generative classification setting, probably better reflects human intuitions
behind WordNet.
However, goal construct classifier performs well without seeing
examples test classification task. also want classifier improves
behavior sees new labeled data test classification task. presents us
problem: one best-performing classifiers (and certainly best text
classification task according study Joachims, 1998) SVM, discriminative
classifier. Therefore, rest work, focus incorporating generative prior
knowledge discriminative classification framework support vector machines.

3. Preliminaries
observed constraints probability measure half-space
captured second-order cone constraints Gaussian distributions (see, e.g., tutorial
Lobo, Vandenberghe, Boyd, & Lebret, 1998). allows efficient processing
constraints within framework second-order cone programming (SOCP). intend
model prior knowledge elliptical distributions, family probability distributions
generalizes Gaussians. follows, give brief overview second-order
cone programming relationship constraints imposed Gaussian probability
distribution. also note possible extend argument presented Lobo et
al. (1998) elliptical distributions.
Second-order cone program mathematical program form:
min v x

(3.1)

x

s.t. kAi x + bi k cTi x + di , = 1, ..., N

(3.2)

x Rn optimization variable v Rn , Ai R(ki xn) , bi Rki , ci Rn ,
di R problem parameters (kk represents usual L2 -norm paper). SOCPs
solved efficiently interior-point methods, described Lobo et al. (1998)
tutorial contains excellent overview theory applications SOCP.
29

fiEpshteyn & DeJong

use elliptical distribution model distribution data a-priori. Elliptical
distributions distributions ellipsoidally-shaped equiprobable contours. density
function n-variate elliptical distribution form f,,g (x) = c(det )1 g((x
)T 1 (x )), x Rn random variable, Rn location parameter,
R(nxn) positive definite (n n)-matrix representing scale parameter, function
g() density generator, c normalizing constant. use notation X E(, , g) denote random variable X elliptical distribution
parameters , , g. Choosing appropriate density generator functions g, Gaussian
distribution, Student-t distribution, Cauchy distribution, Laplace distribution,
logistic distribution seen special cases elliptical distribution. Using elliptical distribution relaxes restrictive assumptions user make
imposing Gaussian prior, keeping many desirable properties Gaussians, as:
1. X E(, , g), R(kn) , B Rk , AX + B E(A + B, AAT , g)
2. X E(, , g), E(X) = .
3. X E(, , g), V ar(X) = g , g constant depends
density generator g.
following proposition shows elliptical distributions, constraint P (w x+b
0) (i.e., probability X takes values half-space {w x + b 0} less
) equivalent second-order cone constraint 21 :
Proposition
3.1. X E(, , g), P rob(w x + b 0) 12 equivalent (w +
1/2
b)/g, w , g, constant depends g .
Proof. proof identical one given Lobo (1998) Lanckriet et al. (2001)
Gaussian distributions provided completeness:
Assume P rob(w x + b 0) .

(3.3)

Let u = w x+b. Let u denote mean u, denote variance. constraint
3.3 written
uu
u
(3.4)
P rob( ) .





properties elliptical distributions, u = w + b, = g 1/2 w , uu




)
E(0, 1, g). Thus, statement 3.4 expressed P robXE(0,1,g) (X w +b
1/2 w
k
gk

, equivalent w +b
1 (), (z) = P robXE(0,1,g) (X z).
1/2 w
k
gk

proposition follows g, = g 1 ().

Proposition 3.2. monotonically decreasing g, P robXE(,,g) (x) equivalent


1/2 (x ) g,c, , g,c,, = g 1 ( ||
c ) constant depends
g, c, , .
Proof. Follows directly definition P robXE(,,g) (x).
30

fiGenerative Prior Knowledge Discriminative Classification

4. Generative Prior via Bilevel Programming
deal binary classification task: classifier function f (x) maps
instances x Rn labels {1, 1}. generative setting, probability densities
P rob(x|y = 1; 1 ) P rob(x|y = 1; 2 ) parameterized = [1 , 2 ] provided (or
estimated data), along prior probabilities class labels (y = 1)
(y = 1), Bayes optimal decision rule given classifier
f (x|) = sign(P rob(x|y = 1; 1 )(y = 1) P rob(x|y = 1; 2 )(y = 1)),
sign(x) := 1 x 0 1 otherwise. LDA, instance, parameters 1
2 means two Gaussian distributions generating data given label.
Informally, approach incorporating prior knowledge straightforward: assume
two-level hierarchical generative probability distribution model. low-level probability
distribution data given label P rob(x|y; ) parameterized , which, turn,
known probability distribution P rob0 (). goal classifier estimate
values parameter vector training set labeled points [x 1 , y1 ]...[xm , ym ].
estimation performed two-player sequential game full information.
bottom (generative) player, given , selects Bayes optimal decision rule f (x|).
top (discriminative) player selects value high probability occurring
(according P rob0 ()) force bottom player select decision rule
minimizes discriminative error training set. give formal
specification training problem formulate bilevel program.
assumptions subsequently relaxed enforce tractability flexibility.
use elliptical distribution E(1 , 1 , g) model X|y = 1, another elliptical
distribution E(2 , 2 , g) model X|y = 1. parameters , , = 1, 2 known,
Bayes optimal decision rule restricted class linear classifiers 2 form
fw,b (x) = sign(w x + b) given f (x) minimizes probability error among
linear discriminants: P rob(error) = P rob(w x + b 0|y = 1)(y = 1) + P rob(w x + b
0|y = 1)(y = 1) = 12 (P robXE(1 ,1 ,g) (wT x + b 0) + P robXE(2 ,2 ,g) (wT x + b 0)),
assuming equal prior probabilities classes. model uncertainty
means elliptical distributions , = 1, 2 imposing elliptical prior distributions
locations means: E(ti , , g), = 1, 2. addition, ensure optimization
problem well-defined, maximize margin hyperplane subject imposed
generative probability constraints:
min kwk

(4.1)

1 ,2

s.t.yi (wT xi + b) 1, = 1, ..,

P robi E(ti ,i ,g) (i ) , = 1, 2

(4.2)
(4.3)




[w, b] solves min[P robXE(1 ,1 ,g) (w x + b 0) + P robXE(2 ,2 ,g) (w x + b 0)]
w,b

(4.4)
bilevel mathematical program (i.e., optimization problem
constraint region implicitly defined another optimization problem), strongly
2. decision rule restricted class classifiers H optimal probability error larger
classifier H (Tong & Koller, 2000a).

31

fiEpshteyn & DeJong

NP-hard even constraints objectives linear (Hansen, Jaumard,
& Savard, 1992). However, show possible solve reasonable approximation problem efficiently several iterations second-order cone programming.
First, relax second-level minimization (4.4) breaking two constraints:
P robXE(1 ,1 ,g) (wT x + b 0) P robXE(2 ,2 ,g) (wT x + b 0) . Thus, instead looking Bayes optimal decision boundary, algorithm looks decision
boundary low probability error, low error quantified choice .
Propositions 3.1 3.2 enable us rewrite optimization problem resulting
relaxation follows :
min kwk

(4.5)

1 ,2 ,w,b

s.t.yi (wT xi + b) 1, = 1, ..,




1/2
(i ti ) , = 1, 2
P robi E(ti ,i ,g) (i ) , = 1, 2

w 1 + b

P robXE(1 ,1 ,g) (wT x + b 0)
1/2
1 w

w 2 + b

P robXE(2 ,2 ,g) (wT x + b 0)
1/2
2 w

(4.6)
(4.7)
(4.8)

(4.9)

Notice form program depend generator function g
elliptical distribution - constants depend it. defines far system
willing deviate prior choice generative model, bounds
tail probabilities error (Type Type II) system tolerate assuming
chosen generative model correct. constants depend specific generator
g amount error user willing tolerate. experiments, select
values constants optimize performance. Unless user wants control
probability bounds constants, sufficient assume a-priori
probability distributions (both prior hyper-prior) elliptical, without making
commitments.
algorithm solves problem repeating following two steps:
1. Fix top-level optimization parameters 1 2 . step combines objectives maximizing margin classifier training data ensuring
decision boundary (approximately) Bayes optimal respect given
generative probability densities specified 1 , 2 .
2. Fix bottom-level optimization parameters w, b. Expand feasible region
program step 1 function 1 , 2 . step fixes decision boundary
pushes means generative distribution far away boundary
constraint (4.7) allow.
steps repeated convergence (in practice, convergence detected
optimization parameters change appreciably one iteration next).
step algorithm formulated second-order cone program:
32

fiGenerative Prior Knowledge Discriminative Classification

Step 1. Fix 1 2 . Removing unnecessary constraints mathematical
program pushing objective constraints, get following SOCP:
min

(4.10)

w,b

s.t. kwk

(4.11)

yi (wT xi + b) 1, = 1, ..,

(4.12)

wT

1+b


1/2
1 w

(4.13)

w 2 + b


1/2
2 w

(4.14)

Step 2. Fix w, b expand span feasible region, measured

w 1 +b .
1/2
1 w


w 2 +b
1/2
2 w



Removing unnecessary constraints, get:
w 2 + b w 1 + b


max
1/2
1 ,2 1/2
2 w
1 w



1/2
(i ti ) , = 1, 2
s.t.

(4.15)
(4.16)

behavior algorithm illustrated Figure 4.1.
following theorems state algorithm converges.
Theorem
4.1. Suppose
n
algorithm produces sequence iterates


(t) (t)
(t)
(t)
, quality iterate evaluated margin w(t) .
1 , 2 , w , b
t=0
evaluation function converges.
(t)

(t)

(t)

(t)

Proof. Let 1 , 2 values prior location parameters, w1 , b1
minimum error hyperplane algorithm finds end t-th step. end
(t+1) (t+1)
(t + 1)-st step, w1
, b1
still feasible region t-th step SOCP.
(t) )T

(t)
2 +b
1/2 (t)
w

2

true function f ( (w

(t) )T

(t)
1 +b
1/2 (t)
w

1

, (w

)=

(w(t) )T 2 +b(t)
1/2 (t)
2 w



(w(t) )T 1 +b(t)
1/2 (t)
1 w

monotonically increasing one arguments argument fixed,
(t+1) (t+1)
fixing 1 (or 2 ) fixes exactly one argument. solution 1
, 2
end
(t+1)

(t + 1)-st step
(t+1)

fixing 1

(t)


(t)
(w(t)
+b

) 2
1/2 (t)
2 w

< , f could increased

(t)

using value 2 beginning step ensures

(t) )T
(t)
(w
2 +b

1/2 (t)
2 w

, contradicts observation f maximized end
(t+1)

second step. contradiction reached


(t)
(w(t)
+b

) 1
1/2 (t)
1 w

< . Since

minimum error hyperplane previous
iteration feasible region start

(t)


must decrease monotonically one iteration
next iteration, objective w
next. Since bounded zero, algorithm converges.
33

fiEpshteyn & DeJong

1)

2)

5

5

4

4

3

3

2

2

1

1

0

0

1
1

0

1

2

3

4

5

1
1

0

1

2

3

3)
5

4

4

3

3

2

2

1

1

0

0

0

5

4)

5

1
1

4

1

2

3

4

5

1
1

0

1

2

3

4

5

Figure 4.1: Steps iterative (hard-margin) SOCP procedure:
(The region hyperprior probability larger shaded prior
distribution. covariance matrices represented equiprobable elliptical contours.
example, covariance matrices hyperprior prior distributions
multiples other. Data points two different classes represented diamonds
squares.)
1. Data, prior, hyperprior algorithm executed.
2. Hyperplane discriminator end step 1, iteration 1
3. Priors end step 2, iteration 1
4. Hyperplane discriminator end step 2, iteration 2
algorithm converges end step 2 problem (step 3 move
hyperplane).
addition convergence objective function, accumulation points
sequence iterates characterized following theorem:
n

(t) (t)
Theorem 4.2. accumulation points sequence 1 , 2 , w(t) , b(t) (i.e., limiting
points convergent subsequences) feasible descent directions original
optimization problem given (4.5)-(4.9).
Proof. See Appendix A.
34

fiGenerative Prior Knowledge Discriminative Classification

point feasible descent directions, sufficiently small step along
directional vector either increase objective function, leave unchanged, take
algorithm outside feasible region. set points feasible descent directions
subset set local minima. Hence, convergence point somewhat
weaker result convergence local minimum.
practice, observed rapid convergence usually within 2-4 iterations.
Finally, may want relax strict assumptions correctness prior/linear
separability data introducing slack variables optimization problem above.
results following program:
min

1 ,2 ,w,b,i ,1 ,2 ,1 ,2

kwk + C1


X

+ C2 (1 + 2 ) + C3 (1 + 2 )

(4.17)

i=1

s.t.yi (wT xi + b) 1 , = 1, ..,


1/2

(i ti ) + , = 1, 2


w 1 + b
1/2
1 w 1




w 2 + b
1/2
2 w 2

0, = 1, ..,
0, = 1, 2

0, = 1, 2

(4.18)
(4.19)
(4.20)
(4.21)
(4.22)
(4.23)
(4.24)

before, problem solved two-step iterative SOCP procedure.
Imposing generative prior soft constraints ensures that, amount training
data increases, data overwhelms prior algorithm converges maximummargin separating hyperplane.

5. Experiments
experiments designed demonstrate usefulness proposed approach
incorporation generative prior discriminative classification, address
broader question showing possible use existing domain theory aid
classification task specifically designed. order construct
generative prior, generative LDA classifier trained data training
classification task estimate Gaussian location parameters bi , = 1, 2, described
Section 2. compression function (v) subsequently computed (also described
j
Section 2), used set hyperprior parameters via ji := (li,test
), = 1, 2.
order apply domain theory effectively task specifically
designed, algorithm must able estimate confidence decomposition
domain theory respect new learning task. order model uncertainty
applicability WordNet newsgroup categorization, system estimated confidence
homogeneity equivalence classes semantic distances computing variance
35

fiEpshteyn & DeJong

0.85
Bilevel Gen/Discr

0.8
0.75
0.7
0.65
0.6
0.55
0.5
0.5

0.55

0.6

0.65 0.7
SVM

0.75

0.8

0.85

Figure 5.1: Performance bilevel discriminative classifier constrained generative
prior knowledge versus performance SVM. point represents unique
pair training/test tasks, 0.5% test task data used training.
results averaged 100 experiments.

P

random variable (v) follows: (v) ,

j:l

c
(ji (v))2
j
i,train=v
j
|j:li,tran
=v|

. hyperprior confidence

matrices , = 1, 2 reconstructed
respect test task semantic distances

j
(li,test
), k = j
. Identity matrices used
li,test , = 1, 2 follows: [i ]j,k :=
0, k 6= j
covariance matrices lower-level prior: 1 = 2 := I. rest parameters
set follows: := 0.2, := 0.01, C1 = C2 := 1, C3 := . constants
chosen manually optimize performance Experiment 1 (for training task: atheism
vs. guns, test task: guns vs. mideast, see Figure 5.2) without observing data
classification tasks.
resulting classifier evaluated different experimental setups (with different
pairs newsgroups chosen training test tasks) justify following
claims:
1. bilevel generative/discriminative classifier WordNet-derived prior knowledge good low-sample performance, showing feasibility automatically
interpreting knowledge embedded WordNet efficacy proposed
algorithm.
2. bilevel classifiers performance improves increasing training sample size.
3. Integrating generative prior discriminative classification framework results
better performance integrating prior directly generative
framework via Bayes rule.
36

fiGenerative Prior Knowledge Discriminative Classification

4. bilevel classifier outperforms state-of-the-art discriminative multitask classifier
proposed Evgeniou Pontil (2004) taking advantage WordNet domain
theory.
order evaluate low-sample performance proposed classifier, four newsgroups
20-newsgroup dataset selected experiments: atheism, guns, middle east,
auto. Using categories, thirty experimental setups created possible
ways assigning newsgroups training test tasks (with pair newsgroups assigned
task, constraint training test pairs cannot identical) 3 .
experiment, compared following two classifiers:
1. bilevel generative-discriminative classifier knowledge transfer functions
(v), (v), = 1, 2 learned labeled training data provided training task (using 90% available data task). resulting prior
subsequently introduced discriminative classification framework via approximate bilevel programming approach
2. vanilla SVM classifier minimizes regularized empirical risk:
min

w,b,i


X
i=1

+ C1 kwk2

s.t.yi (wT xi + b) 1 , = 1, ..,

(5.1)
(5.2)

classifiers trained 0.5% available data test classification
task4 , evaluated remaining 99.5% test task data. results, averaged
one hundred randomly selected datasets, presented Figure 5.1, shows
plot accuracy bilevel generative/discriminative classifier versus accuracy
SVM classifier, evaluated thirty experimental setups. points
lie 45o line, indicating improvement performance due incorporation prior
knowledge via bilevel programming framework. amount improvement ranges
10% 30%, improvements statistically significant 5%
level.
next experiment conducted evaluate effect increasing training data
(from test task) performance system. experiment, selected
three newsgroups (atheism, guns, middle east) generated six experimental setups
based possible ways splitting newsgroups unique training/test pairs.
addition classifiers 1 2 above, following classifiers evaluated:
3. state-of-the art multi-task classifier designed Evgeniou Pontil (2004).
classifier learns set related classification functions ft (x) = wtT x + bt classification tasks {training task, test task} given m(t) data points [x1t , y1t ], .., [xm(t)t , ym(t)t ]
3. Newsgroup articles preprocessed removing words could interpreted nouns
WordNet. preprocessing ensured one part WordNet domain theory exercised
resulted virtually reduction classification accuracy.
4. SeDuMi software (Sturm, 1999) used solve iterative SOCP programs.

37

fiEpshteyn & DeJong

task minimizing regularized empirical risk:
min

w0 ,wt ,bt ,it

X
X m(t)


i=1

+

C1 X
kwt w0 k2 + C1 kw0 k2
C2

s.t. yit (wtT xit + bt ) 1 , = 1, .., m(t),
0, = 1, .., m(t),

(5.3)
(5.4)
(5.5)

regularization constraint captures tradeoff final models w close
average model w0 large margin training data. 90%
training task data made available classifier. Constant C1 := 1 chosen,
C2 := 1000 selected set {.1, .5, 1, 2, 10, 1000, 105 , 1010 } optimize
classifiers performance Experiment 1 (for training task: atheism vs. guns,
test task: guns vs. mideast, see Figure 5.2) observing .05% test task data
(in addition training task data).
4. LDA classifier described Section 2 trained 90% test task data. Since
classifier bottom-level generative classifier used bilevel
algorithm, performance gives upper bound performance bottomlevel classifier trained generative fashion.
Figure 5.2 shows performance classifiers 1-3 function size training
data test task (evaluation done remaining test-task data). results
averaged one hundred randomly selected datasets. performance bilevel
classifier improves increasing training data discriminative portion
classifier aims minimize training error generative prior imposed
soft constraints. expected, performance curves classifiers converge
amount available training data increases. Even though constants used mathematical program selected single experimental setup, classifiers performance
reasonable wide range data sets across different experimental setups,
possible exception Experiment 4 (training task: guns vs. mideast, testing task: atheism
vs. mideast), means constructed elliptical priors much closer
experiments. Thus, prior imposed greater confidence
warranted, adversely affecting classifiers performance.
multi-task classifier 3 outperforms vanilla SVM generalizing data points
across classification tasks. However, take advantage prior knowledge,
classifier does. gain performance bilevel generative/discriminative classifier
due fact relationship classification tasks captured much
better WordNet simple linear averaging weight vectors.
constants involved bilevel classifier generative classifiers Bayesian priors, hard fair comparison classifiers constrained
generative priors two frameworks. Instead, generatively trained classifier 4
gives empirical upper bound performance achievable bottom-level classifier
trained generatively test task data. accuracy classifier shown
horizontal plots Figure 5.2. Since discriminative classification known
superior generative classification problem, SVM classifier outperforms
38

fiGenerative Prior Knowledge Discriminative Classification

1) Train:atheism vs. guns

2) Train:atheism vs. guns

3) Train:guns vs. mideast

Test:atheism vs. mideast

Test:guns vs. mideast

Test:atheism vs. guns

1

1

1

0.95

0.95

0.95

0.9

0.9

0.9

0.85

0.85

0.85

0.8

0.8

0.8

0.75

0.75

0.75

0.7

0.7

0.7

0.65

0.65

0.65

0.6

0.6

0.6

0.55

0.55
0

0

10 20 30 40 50 60 70 80 90 100

4) Train: guns vs. mideast

10

20

30

40

50

60

70

80

90

5) Train: atheism vs. mideast

0.55
0

1

1

1

0.95

0.95

0.9

0.9

0.9

0.85

0.85

0.85

0.8

0.8

0.8

0.75

0.75

0.75

0.7

0.7

0.7

0.65

0.65

0.65

0.6

0.6
0

10

20

30

40

50

60

70

80

90

30

40

50

60

70

80

90

Test:atheism vs. guns

0.95

0.55

20

6) Train: atheism vs. mideast

Test:guns vs. mideast

Test:atheism vs. mideast

10

0.6

0.55

0.55
0

10 20 30 40 50 60 70 80 90 100

0

10

20

30

40

50

60

70

80

90

Legend:

LDA,max performance
Bilevel Gen/Discr
SVM
Multitask SVM

Figure 5.2: Test set accuracy percentage versus number test task training points
two classifiers (SVM Bilevel Gen/Discr) tested six different classification
tasks. classification experiment, data set split randomly
training test sets 100 different ways. error bars based 95%
confidence intervals.

generative classifier given enough data four six experimental setups.
interesting, that, range training sample sizes, bilevel classifier constrained
generative prior outperforms SVM trained sample
generative classifier trained much larger sample four setups. means that,
unless prior knowledge outweighs effect learning, cannot enable LDA classifier
compete bilevel classifier problems.
Finally, set experiments performed determine effect varying mathematical program parameters generalization error. parameter
varied set values, rest parameters held fixed ( increased
maximum feasible value). evaluation done setup Experiment 1 (for
39

fiEpshteyn & DeJong

1) Accuracy function

2) Accuracy function

0.18

0.18

0.16

0.16

0.14

0.14

0.12

0.12

0.1

0.1

0.08

0.08

0.06

0.06

0.04

0.04

0.02

0.02

0

0
0

0.05

0.1

0.15

0.2

0

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

1

Figure 5.3: Plots test set accuracy percentage versus mathematical program parameter
values. classification task, random training set size 9 chosen
full set test task articles 100 different ways. Error bars based
95% confidence intervals. experiments performed training
task: atheism vs. guns, test task: guns vs. mideast.

training task:atheism vs. guns, test task: guns vs. mideast), training set size
9 points. results presented Figure 5.3. Increasing value equivalent
requiring hyperplane separator smaller error given prior. Decreasing
value equivalent increasing confidence hyperprior. actions
tighten constraints (i.e., decrease feasible region). good prior knowledge,
effect improving generalization performance small training samples
since prior imposed higher confidence. precisely observe
plots Figure 5.3.

6. Generalization Performance
algorithm generalize well low sample sizes? section, derive
theorem demonstrates convergence rate generalization error
constrained generative-discriminative classifier depends parameters mathematical program margin, would expected case large-margin
classification without prior. particular, show certainty generative prior knowledge increases, upper bound generalization error classifier
constrained prior decreases. increasing certainty prior, mean
either hyper-prior becomes peaked (i.e., confidence locations
prior means increases) desired upper bounds Type Type II probabilities
error classifier decrease (i.e., requirement lower-level discriminative
player choose restricted Bayes-optimal hyperplane strictly enforced).
argument proceeds bounding fat-shattering dimension classifier constrained prior knowledge. fat-shattering dimension large margin classifier
given following definition (Taylor & Bartlett, 1998):
Definition 6.1. set points = {x1 ...xm } -shattered set functions F
mapping domain X R real numbers r 1 , ..., rm that,
b {1, 1}m , function fb F b(fb (xi ) ri ) , = 1..m. say
40

fiGenerative Prior Knowledge Discriminative Classification

r 1 , ..., rm witness shattering. fat-shattering dimension F function
fatF () maps cardinality largest -shattered set S.
Specifically, consider class functions
F = {x w x : kxk R, kwk = 1,

(6.1)





wT (1 )
w 2
1/2


1/2
,




,
(


)
(


)



,



1
1
2
2 }.
1
2
1/2
1/2
1 w
2 w

following theorem bounds fat-shattering dimension classifier:

Theorem 6.2. Let F class a-priori constrained functions defined (6.1),
let min (P ) max (P ) denote minimum maximum eigenvalues matrix P ,
2
2
2 ))
,
respectively. set points -shattered F , |S| 4R ( (1
2
2

2

(1 )
(1 )
2 k (max (2 ))
, kt2ktk(
,
= max(1 , 2 ) 1 = min( min
) 2 = min( min
2
k2 k
k1 k
max (2 )) +kt2 k)
kt1 k2 (max (1 ))2
),
kt1 k((max (1 ))2 +kt1 k)

assuming 0, kti k kti k,

1 ,
2

= 1, 2.

Proof. See Appendix B.
following corollary follows directly Taylor Bartletts (1998)
Theorem 1.5 bounds classifiers generalization error based fat-shattering
dimension:
Corollary 6.3. Let G class real-valued functions. Then, probability least
1 independently generated examples z, classifier h = sgn(g) sgn(G)
2
margin least examples z, error h
(d

8m
)log(32m)
+
log(
))


=
f

(
).

G
=
F


class

functions
log( 8em
G
G


16
2

2

2

defined (6.1), dF 265R (4( 2 (1 ))) . G = F 0 usual class large margin
classifiers (without prior), result (Taylor & Bartlett, 1998) shows F 0
265R2
.
2
2

Notice bounds depend R
. However, bound classifier constrained
2
generative prior also depends term 4( 2 (1 2 )). particular, increases, tightening constraints, bound decreases, ensuring, expected,
quicker convergence generalization error. Similarly, decreasing also tightens
constraints decreases upper bound generalization error. > 12 ,
factor 4(2 (1 2 )) less 1 upper bound fat-shattering dimension dF
tighter usual bound no-prior case dF 0 .
Since controls amount deviation decision boundary Bayesoptimal hyperplane depends variance hyper-prior distribution, tightening
constraints corresponds increasing confidence prior. Note high
value represents high level user confidence generative elliptical model. Also
note two ways increasing tightness hyperprior constraint (4.7)
- one user-defined parameter , automatically
estimated covariance matrices , = 1, 2. matrices estimate extent
41

fiEpshteyn & DeJong

equivalence classes defined WordNet create appropriate decomposition domain
theory newsgroup categorization task. Thus, tight constraint (4.7) represents
high level user confidence means generative classification model (estimated
WordNet) good correspondence partition words imposed
semantic distance WordNet elliptical generative model data.
approaches zero approaches highest feasible value, solution bilevel
mathematical program reduces restricted Bayes optimal decision boundary computed
solely generative prior distributions, without using data.
Hence, shown that, prior imposed increasing level confidence
(which means elliptical generative model deemed good, estimates
means good, turn implies domain theory well-suited
classification task hand), convergence rate generalization error classifier
increases. Intuitively, precisely desired effect increased confidence prior
since benefit derived training data outweighed benefit derived
prior knowledge. low data samples, result improved accuracy assuming
domain theory good, plots Figure 5.3 show.

7. Related Work
number approaches combining generative discriminative models. Several focus deriving discriminative classifiers generative distributions (Tong
& Koller, 2000a; Tipping, 2001) learning parameters generative classifiers via
discriminative training methods (Greiner & Zhou, 2002; Roos, Wettig, Grunwald, Myllymaki, & Tirri, 2005). closest spirit approach Maximum Entropy
Discrimination framework (Jebara, 2004; Jaakkola, Meila, & Jebara, 1999), performs
discriminative estimation parameters generative model, taking account constraints fitting data respecting prior. One important difference
framework that, estimating parameters, maximum entropy discrimination minimizes distance generative model prior, subject satisfying
discriminative constraint training data classified correctly given margin.
framework, hand, maximizes margin training data subject
constraint generative model far prior. emphasis
maximizing margin allows us derive a-priori bounds generalization error
classifier based confidence prior (yet) available maximum entropy framework. Another difference approach performs classification
via single generative model, maximum entropy discrimination averages set
generative models weighted probabilities. similar distinction
maximum-a-posteriori Bayesian estimation repercussions tractability. Maximum entropy discrimination, however, general framework sense
allowing richer set behaviors based different priors.
Ng et al. (2003, 2001) explore relative advantages discriminative generative
classification propose hybrid approach improves classification accuracy
low-sample high-sample scenarios. Collins (2002) proposes use Viterbi
algorithm HMMs inferencing (which based generative assumptions), combined
discriminative learning algorithm HMM parameter estimation. research
42

fiGenerative Prior Knowledge Discriminative Classification

directions orthogonal work since explicitly consider question
integration prior knowledge learning problem.
context support vector classification, various forms prior knowledge
explored. Scholkopf et al. (2002) demonstrate integrate prior knowledge
invariance transformations importance local structure kernel function.
Fung et al. (2002) use domain knowledge form labeled polyhedral sets augment
training data. Wu Srihari (2004) allow domain experts specify confidence
examples label, varying effect example separating hyperplane
proportionately confidence. Epshteyn DeJong (2005) explore effects rotational constraints normal separating hyperplane. Sun DeJong (2005)
propose algorithm uses domain knowledge (such WordNet) identify relevant
features examples incorporate resulting information form soft constraints
hypothesis space SVM classifier. Mangasarian et al. (2004) suggest use prior
knowledge support vector regression. approaches, prior knowledge takes
form explicit constraints hypothesis space large-margin classifier.
work, emphasis generating constraints automatically domain knowledge
interpreted generative setting. demonstrate WordNet application,
generative interpretation background knowledge intuitive natural language
processing problems.
Second-order cone constraints applied extensively model probability constraints robust convex optimization (Lobo et al., 1998; Bhattacharyya, Pannagadatta, &
Smola, 2004) constraints distribution data minimax machines (Lanckriet
et al., 2001; Huang, King, Lyu, & Chan, 2004). work, far know, first one
models prior knowledge constraints. resulting optimization problem
connection Bayes optimal classification different approaches
mentioned above.
work also related empirical Bayes estimation (Carlin & Louis, 2000). empirical Bayes estimation, hyper-prior parameters generative model estimated
using statistical estimation methods (usually maximum likelihood method moments)
marginal distribution data, approach learns parameters
discriminatively using training data.

8. Conclusions Future Work.
Since many sources domain knowledge (such WordNet) readily available, believe
significant benefit achieved developing algorithms automatically applying
information new classification problems. paper, argued generative paradigm interpreting background knowledge preferable discriminative
interpretation, presented novel algorithm enables discriminative classifiers
utilize generative prior knowledge. algorithm evaluated context complete system which, faced newsgroup classification task, able estimate
parameters needed construct generative prior domain theory, use
construction achieve improved performance new newsgroup classification tasks.
work, restricted hypothesis class linear classifiers. Extending
form prior distribution distributions elliptical and/or looking
43

fiEpshteyn & DeJong

Bayes-optimal classifiers restricted expressive class linear separators
may result improvement classification accuracy non linearly-separable domains.
However, obvious approximate expressive form prior knowledge
convex constraints. kernel trick may helpful handling nonlinear problems,
assuming possible represent optimization problem exclusively terms
dot products data points constraints. important issue requires
study.
demonstrated interpreting domain theory generative setting
intuitive produces good empirical results. However, usually multiple ways
interpreting domain theory. WordNet, instance, semantic distance
words one measure information contained domain theory. Other,
complicated, interpretations might, example, take account types links
path words (hypernyms, synonyms, meronyms, etc.) exploit commonsense observations WordNet words closer category label
likely informative words farther away. Comparing multiple ways
constructing generative prior domain theory and, ultimately, selecting one
interpretations automatically fruitful direction research.

Acknowledgments
authors thank anonymous reviewers valuable suggestions improving paper. material based upon work supported part National Science Foundation
Award NSF IIS 04-13161 part Information Processing Technology Office Defense Advanced Research Projects Agency award HR0011-05-1-0040.
opinions, findings, conclusions recommendations expressed publication
authors necessarily reflect views National Science
Foundation Defense Advanced Research Projects Agency.

Appendix A. Convergence Generative/Discriminative Algorithm
Let map H : Z Z determine algorithm that, given point (0) , generates se
quence (t) t=0 iterates iteration (t+1) = H((t) ). iterative algorithm
(t)

(t)

Section 4 generates sequence iterates (t) = [1 , 2 ] Z applying following
map H:
H = H 2 H1 :
(A.1)
step 1, H1 ([1 , 2 ]) = arg

min

[w,b]U ([1 ,2 ])

kwk ,

set U ([1 , 2 ]) defined constraints:


(A.2)
(A.3)

yi (w xi + b) 1 0, = 1, ..,

(A.4)

c1 (w, b; 2 , 2 ) 0


wT +b
.
conic constraints cs (w, b; , ) ,
k1/2 wk

(A.6)

c1 (w, b; 1 , 1 ) 0

44

(A.5)

fiGenerative Prior Knowledge Discriminative Classification

step 2, H2 (w, b) = arg

min

(1 ,2 )V

(c1 (w, b; 1 , 1 ) + c1 (w, b; 2 , 2 ))

(A.7)

set V given constraints
o(1 ; 1 , t1 ) 0

(A.8)

o(2 ; 2 , t2 ) 0

(A.9)



o(; , t) , 1/2 ( t) .
Notice H1 H2 functions minima optimization problems
(4.10)-(4.14) (4.15)-(4.16) unique. case Step 1 optimizes
strictly convex function convex set, Step 2 optimizes linear non-constant function
strictly convex set.
Convergence objective function ((t) ) , min[w,b]U ([(t) ,(t) ]) kwk algorithm
1
2
shown Theorem 4.1. Let denote set points map H
change value objective function, i.e. (H( )) = ( ).
show every accumulation point {(t) } lies . also show every point
[1 , 2 ] augmented [w , b ] = H1 ([1 , 2 ]) point feasible descent
directions optimization problem (4.5)-(4.9), equivalently expressed as:
min kwk s.t.[1 , 2 ] V ; [w, b] U ([1 , 2 ])

1 ,2 ,w,b

(A.10)

order formally state result, need concepts duality theory.
Let constrained optimization problem given
min f (x) s.t. ci (x) 0, = 1, .., k
x

(A.11)

following conditions, known Karush-Kuhn-Tucker(KKT) conditions necessary
x local minimum:
Proposition A.1. x local minimum (A.11), 1 , .., k
P
1. f (x ) = ki=1 ci (x )
2. 0 {1, .., k}

3. ci (x ) 0 {1, .., k}
4. ci (x ) = 0 {1, .., k}
1 , .., k known Lagrange multipliers constraints c1 , .., ck .
following well-known result states KKT conditions sufficient x
point feasible descent directions:
Proposition A.2. 1 , .., k following conditions satisfied x :
P
1. f (x ) = ki=1 ci (x )
45

fiEpshteyn & DeJong

2. 0 {1, .., k}
x feasible descent directions problem (A.11)
Proof. (sketch) reproduce proof given textbook Fletcher (1987). proposition true P
feasible direction vector s, sT ci (x) 0 x


{1, .., k}. Hence, f (x ) = ki=1 sT ci (x ) 0, descent direction.
following lemma characterizes points set :

Lemma A.3. Let , let [w , b ] = H1 ( ) optimizer ( ), let
= [(A.4),1 , .., (A.4),m , (A.5) , (A.6) ] set Lagrange multipliers corresponding
constraints solution [w , b ]. Define 0 = H( ), let [w 0 , b0 ] optimizer
(0 ). 02 6= 2 , (A.6) = 0 . 01 6= 1 , (A.5) = 0 .
01 6= 1 02 6= 2 , (A.6) = (A.5) = 0 .
Proof. Consider case
02 6= 2

(A.12)

01 = 1

(A.13)


Since , kw0 k = kw k. Let 0 set Lagrange multipliers corresponding
constraints solution [w 0 , b0 ]. Since w still feasible optimization problem
given (0 ) (by argument Theorem 4.1) minimum problem
unique, happen
[w0 , b0 ] = [w , b ].
(A.14)
[w , b ] 0 must satisfy KKT conditions (0 ). (A.12) implies
c1 (w ; 02 , 2 ) > c1 (w ; 2 , 2 ) argument Theorem 4.1, means
that, KKT condition (4) (0 ),
0(A.6) = 0.

(A.15)

Therefore, KKT condition (1) (0 ) (A.15), [w, b, 1 , 2 ] = [w = w0 , b =
b0 , 1 = 01 , 2 ]
"
"
"
#
#
#



c1 (w,b ;1 ,1 )
c1 (w,b ;2 ,2 )
kwk
X

x


w
+ 0(A.5) c1 (ww
=
0(A.4),i
+ 0(A.6) c1 (ww
,
,b; , )
kwk
,b;2 ,2 )
1
1
yi
b

b

i=1

b

means KKT conditions (1),(2) optimization problem ( ) satisfied
0
point [w , b ] = . KKT condition (3) satisfied feasibility [w , b ]
KKT condition (4) satisfied condition (0 ) observations (A.13),
(A.14), (A.15).
proofs two cases (02 = 2 , 01 6= 1 02 6= 2 , 01 6= 1 )
analogous.
following theorem states points KKT points (i.e., points
KKT conditions satisfied) optimization problem given (A.10).
46

fiGenerative Prior Knowledge Discriminative Classification

Theorem A.4. let [w , b ] = H1 ( ), [w , b , 1 , 2 ] KKT point
optimization problem given (A.10).
Proof. Let 0 = H( ). like Lemma A.3, consider case
02 6= 2 ,

(A.16)

01 = 1 (A.6) = 0 (by Lemma A.3).

(A.17)

(the proofs two cases similar).
KKT conditions H2 (w , b ), 1 = 01


(o(1 ; 1 , t))
c1 (w , b ; 1 , 1 )
= 0A.8
0A.8 0.
1
1

(A.18)

KKT conditions H1 ( ) (A.17), [w, b] = [w , b ]
"

kwk
w
kwk
b

#

=


X
i=1

(A.4),i



yi x
yi



+

(A.5)

"

c1 (w,b ;1 ,1 )
w
c1 (w ,b;1 ,1 )
b

#








(A.4),1
..
(A.4),m
(A.5)





0.


(A.19)

(A.16),(A.17),(A.18), (A.19), [w, b, 1 , 2 ] = [w , b , 1 = 01 , 2 ]


c1 (w,b ; ,1 )
kwk


kwk
1

x
w


w
kwk
w
,b; , )


c
(w
1
1
X
1
yi
b 0



+

=
kwk =
b

+


(A.5)
(A.4),i 0
0

c1 (w ,b ;1 ,1 )


1
i=1
1
kwk
0
0
0
2








c1 (w,b ;2 ,2 )
0
0
w

c1 (w ,b;2 ,2 )




0
0


+
,
b
0A.8 (A.5)
+ (A.6)
(o(
;
,t))
1 1
(A.6)




0


0
1
(o(2 ;2 ,t))
c1 (w ,b ;2 ,2 )
0
2

2

means KKT conditions (1),(2) optimization problem (A.10) satisfied
00
point [w , b , 1 , 2 ] = [(A.4),1 , .., (A.4),m , (A.5) , (A.6) , 0A.8 (A.5) , (A.6) ].
00

also satisfies KKT conditions (3),(4) assumption (A.17) KKT conditions
H1 H2 .
order prove convergence properties iterates (t) , use following theorem
due Zangwill (1969):
Theorem A.5. Let map H : Z Z determine iterative algorithm via (t+1) =
H((t) ), let () denote objective function, let set points
map H change value objective function, i.e. (H()) = ().
Suppose
47

fiEpshteyn & DeJong

1. H uniformly compact Z, i.e. compact subset Z0 Z
H() Z0 Z.
2. H strictly monotonic Z , i.e. (H()) < ().
3. H closed Z , i.e. wi w H(wi ) , = H(w).
accumulation points sequence (t) lie .
following proposition shows minimization continuous function feasible
set continuous map functions argument forms closed function.
Proposition A.6. Given
1. real-valued continuous function f B,
2. point-to-set map U : 2B continuous respect Hausdorff metric:5
dist(X, ) , max(d(X, ), d(Y, X)), d(X, ) , maxxX minyY kx yk,
define function F : B
F (a) = arg min f (a, b0 ) = {b : f (a, b) < f (a, b0 ) b0 U (a)},
b0 U (a)

assuming minimum exists unique. Then, function F closed a.
Proof. proof minor modification one given Gunawardana Byrne
(2005). Let {a(t) } sequence
a(t) a, F (a(t) ) b

(A.20)

function F closed F (a) = b. Suppose case, i.e. b 6= F (a) =
arg minb0 U (a) f (a, b0 ). Therefore,
b = arg min f (b0 ) f (a, b) > f (a, b)
b0 U (a)

(A.21)

continuity f (, ) (A.20),
f (a(t) , F (a(t) )) f (a, b)

(A.22)

continuity U () (A.20),
dist(U (a(t) ), U (a)) 0 b(t) b b(t) U (at ), t.

(A.23)

(A.22), (A.23), (A.21) imply
K f (a(t) , F (a(t) )) > f (a(t) , b(t) ), > K

(A.24)

contradiction since assumption, F (a(t) ) = arg minb0 U (at ) f (b0 ) (A.24),
b(t) U (a(t) ).
5. point-to-set map U (a) maps point set points. U (a) continuous respect distance
metric dist iff a(t) implies dist(U (a(t) ), U (a)) 0.

48

fiGenerative Prior Knowledge Discriminative Classification

Proposition A.7. function H defined (A.1)-(A.7) closed.
Proof. Let {(t) } sequence (t) . Since iterates (t) lie
closed feasible region bounded constraints (4.6)-(4.9) boundary U ()
piecewise linear , boundary U ((t) ) converges uniformly boundary U ( )
(t) , implies Hausdorff distance boundaries converges
zero. Since Hausdorff distance convex sets equal Hausdorff distance
boundaries, dist(U ((t) ), U ( )) also converges zero. Hence, proposition
A.6 implies H1 closed. proposition implies H2 closed. composition
closed functions closed, hence H closed.
prove main result Section:
Theorem 4.2. Let H function defined (A.1)-(A.7) determines generative/discriminative algorithm via (t+1) = H((t) ). accumulation points
sequence (t) augmented [w , b ] = H1 ( ) feasible descent directions
original optimization problem given (4.5)-(4.9).
Proof. proof verifying H satisfies properties Theorem A.5. Closedness
H shown Proposition A.7. Strict monotonicity ((t) ) shown Theorem
4.1. Since iterates (t) closed feasible region bounded constraints (4.6)(4.9), H uniformly compact Z. Since accumulation points lie ,
KKT points original optimization problem Theorem A.4, and, therefore,
feasible descent directions Proposition A.2.

Appendix B. Generalization Generative/Discriminative Classifier
need auxiliary results proving Theorem 6.2. first proposition bounds
angle rotation two vectors w1 , w2 distance angle
rotation vectors reference vector v sufficiently small:
Proposition B.1. Let kw1 k = kw2 k = kvk = 1. w1T v 0 w2T v 0,
1. w1T w2 22 1
p
2. kw1 w2 k 2 (1 2 )

Proof.

1. triangle inequality, arccos(w1T w2 ) arccos(w1T v) + arccos(w2T v) 2 arccos()
(since angle two vectors distance measure). Taking cosines
sides using trigonometric equalities yields w1T w2 22 1.
2. Expand kw1 w2 k2 = kw1 k2 + kw2 k2 2w1T w2 = 2(1 w1T w2 ). Since w1T w2 22 1
part 1, kw1 w2 k2 4(1 2 ).

next proposition bounds angle rotation two vectors
far away measured L2 -norm distance:
49

fiEpshteyn & DeJong

Proposition B.2. Let ktk = , k tk .

tT
ktkkk



2 2
(+ ) .

Proof. Expanding k tk2 = ktk2 + kk2 2tt using k tk2 2 , get
1 ktk
2 ( kk

kk
ktk

2

tT
ktkkk



+
ktkkk ). use triangle inequality ktk k tk kk
ktk + k tk + simplify.

following proposition used bound angle rotation normal
w separating hyperplane mean vector hyper-prior distribution:
wT
kwkkk
ktk2 2
ktk(+ktk) ).

Proposition B.3. Let
= min(,

0 k tk ktk.

wT
kwkktk

(22 1),

Proof. Follows directly Propositions B.1 (part 1) B.2.
prove Theorem 6.2, relies parts well-known proof fatshattering dimension bound large margin classifiers derived Taylor Bartlett
(1998).
Theorem 6.2. Let F class a-priori constrained functions defined 6.1,
let min (P ) max (P ) denote minimum maximum eigenvalues matrix P ,
2
2
2 ))
respectively. set points -shattered F , |S| 4R ( (1
,
2
2

2

(1 )
(1 )
2 k (max (2 ))
, kt2ktk(
,
) 2 = min( min
= max(1 , 2 ) 1 = min( min
2
k2 k
k1 k
max (2 )) +kt2 k)
kt1 k2 (max (1 ))2
),
kt1 k((max (1 ))2 +kt1 k)

assuming 0, kti k kti k,

1 ,
2

= 1, 2.



Proof. First, use inequality min (P ) kwk P 1/2 w max (P ) kwk relax
constraints
w 2
w 2


min (2 )
(B.1)
1/2
kwk
2 w



1/2

= max (2 ).
(B.2)
2 (2 t2 ) k2 t2 k
min (1
2 )



1/2
wT 1

constraints imposed second prior 1/2 , 1 (1 t1 ) relaxed

similar fashion produce:

2 w

wT (1 )
min (1 )
kwk

(B.3)

k1 t1 k max (1 )

(B.4)

Now, show assumptions made statement theorem hold,
2
2
2
P
P
every subset satisfies k (S S0 )k 4R ( 2(1 ) .
Assume -shattered F . argument used Taylor Bartlett (1998)
Lemma 1.2 shows that, definition fat-shattering, exists vector w 1

X
X
w1 (

(S S0 )) |S| .
(B.5)
50

fiGenerative Prior Knowledge Discriminative Classification

Similarly (reversing labeling S0 S1 S0 ), exists vector w2
X
X
w2 ( (S S0 )
) |S| .
(B.6)
Hence, (w1 w2 )(
implies

P



P

(S S0 )) 2 |S| , which, Cauchy-Schwartz inequality,

2 |S|
P
kw1 w2 k P
k (S S0 )k

(B.7)

constraints classifier represented B.1 B.2 imply Proposition B.3
w1T t2
w2T t2
2
2
kw1 kkt2 k (21 1) kw2 kkt2 k (22 1) . Now, applying Proposition B.1 (part 2)
simplifying, get
q
kw1 w2 k 4

12 (1 12 ).

Applying analysis constraints B.3 B.4, get
q
kw1 w2 k 4 22 (1 22 ).
Combining B.7, B.8, B.9, get
X

X
|S|



(S S0 ) p

2 2 (1 2 )

(B.8)

(B.9)

(B.10)

defined statement theorem.
Taylor Bartletts (1998) Lemma 1.3 proves, using probabilistic method,
satisfies
X
p
X


(B.11)

(S S0 ) |S|R.

Combining B.10 B.11 yields |S|

4R2 (2 (12 ))
.
2

References
Baxter, J. (2000). model inductive bias learning. Journal Artificial Intelligence
Research, 12, 149198.
Bhattacharyya, C., Pannagadatta, K. S., & Smola, A. (2004). second order cone programming formulation classifying missing data. NIPS.
Blake,
C.,
&
Merz,
C.
(1998).
20
newsgroups
http://people.csail.mit.edu/people/jrennie/20newsgroups/..

database,

Campbell, C., Cristianini, N., & Smola, A. (2000). Query learning large margin classifiers. Proceedings Seventeenth International Conference Machine Learning.
Carlin, B., & Louis, T. (2000). Bayes Empirical Bayes Methods Data Analysis.
Chapman Hall.
Collins, M. (2002). Discriminative training methods hidden markov models: Theory
experiments perceptron algorithms. Proceedings 2002 Conference
Empirical Methods Natural Language Processing.
51

fiEpshteyn & DeJong

Duda, R., Hart, P., & Stork, D. (2001). Pattern Classification. John Wiley. 2nd edition.
Epshteyn, A., & DeJong, G. (2005). Rotational prior knowledge svms. Proceedings
Sixteenth European Conference Machine Learning.
Evgeniou, T., & Pontil, M. (2004). Regularized multi-task learning. Proceedings
Tenth ACM SIGKDD International Conference Knowledge Discovery Data
Mining.
Fink, M. (2004). Object classification single example utilizing class relevance metrics.
Advances Neural Information Processing Systems.
Fletcher, R. (1987). Practical Methods Optimization. John Wiley Sons, West Sussex,
England.
Fung, G., Mangasarian, O., & Shavlik, J. (2002). Knowledge-based support vector machine
classifiers. Advances Neural Information Processing Systems.
Greiner, R., & Zhou, W. (2002). Structural extension logistic regression: Discriminative
parameter learning belief net classifiers. Proceedings Eighteenth National
Conference Artificial Intelligence.
Gunawardana, A., & Byrne, W. (2005). Convergence theorems generalized alternating
minimization procedures. Journal Machine Learning Research, 6, 20492073.
Hansen, P., Jaumard, B., & Savard, G. (1992). New branch-and-bound rules linear bilevel
programming. SIAM Journal Scientific Statistical Computing, 13, 11941217.
Huang, K., King, I., Lyu, M. R., & Chan, L. (2004). minimum error minimax probability
machine. Journal Machine Learning Research, 5, 12531286.
Jaakkola, T., Meila, M., & Jebara, T. (1999). Maximum entropy discrimination. Advances
Neural Information Processing Systems.
Jebara, T. (2004). Machine Learning: Discriminative Generative. Kluwer Academic
Publishers.
Joachims, T. (1998). Text categorization support vector machines: learning many
relevant features. Proceedings Tenth European Conference Machine Learning.
Lanckriet, G. R. G., Ghaoui, L. E., Bhattacharyya, C., & Jordan, M. I. (2001). Minimax
probability machine. Advances Neural Information Processing Systems.
Lobo, M. S., Vandenberghe, L., Boyd, S., & Lebret, H. (1998). Applications second-order
cone programming. Linear Algebra Applications, 284 (13), 193228.
Mangasarian, O., Shavlik, J., & Wild, E. (2004). Knowledge-based kernel approximation.
Journal Machine Learning Research.
Miller, G. (1990). WordNet: online lexical database. International Journal Lexicography, 3 (4).
Ng, A. Y., & Jordan, M. I. (2001). discriminative vs. generative classifiers: comparison
logistic regression naive bayes. Advances Neural Information Processing
Systems.
52

fiGenerative Prior Knowledge Discriminative Classification

Raina, R., Shen, Y., Ng, A. Y., & McCallum, A. (2003). Classification hybrid generative/discriminative models. Advances Neural Information Processing Systems.
Roos, T., Wettig, H., Grunwald, P., Myllymaki, P., & Tirri, H. (2005). discriminative
bayesian network classifiers logistic regression. Machine Learning, 59, 267296.
Scholkopf, B., Simard, P., Vapnik, V., & Smola, A. (2002). Prior knowledge support
vector kernels. Advances kernel methods - support vector learning.
Sturm, J. F. (1999). Using SeDuMi 1.02, MATLAB toolbox optimization symmetric cones. Optimization Methods Software, 11, 625653.
Sun, Q., & DeJong, G. (2005). Explanation-augmented svm: approach incorporating
domain knowledge svm learning. Proceedings Twenty Second International Conference Machine Learning.
Taylor, J. S., & Bartlett, P. (1998). Generalization performance support vector machines
pattern classifiers. Advances kernel methods: support vector learning.
Thrun, S. (1995). learning n-th thing easier learning first?. Advances
Neural Information Processing Systems.
Tipping, M. E. (2001). Sparse bayesian learning relevance vector machine. Journal
Machine Learning Research, 1, 211244.
Tong, S., & Koller, D. (2000a). Restricted bayes optimal classifiers. Proceedings
Seventeenth National Conference Artificial Intelligence.
Tong, S., & Koller, D. (2000b). Support vector machine active learning applications
text classification. Proceedings Seventeenth International Conference
Machine Learning.
Vapnik, V. (1995). Nature Statistical Learning Theory. Springer-Verlag.
Wu, X., & Srihari, R. (2004). Incorporating prior knowledge weighted margin support
vector machines. Proceedings Tenth ACM SIGKDD International Conference
Knowledge Discovery Data Mining.
Zangwill, W. (1969). Convergence conditions nonlinear programming algorithms. Management Science, 16, 113.

53

fi
